{"id": "2511.17836", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17836", "abs": "https://arxiv.org/abs/2511.17836", "authors": ["Edwin Sundberg", "Thea Ekmark", "Workneh Yilma Ayele"], "title": "Validating API Design Requirements for Interoperability: A Static Analysis Approach Using OpenAPI", "comment": "11 pages, 3 tables, 2 figures. Preprint. To appear in: PoEM2025: Companion Proceedings of the 18th IFIP Working Conference on the Practice of Enterprise Modeling: PoEM Forum, Doctoral Consortium, Business Case and Tool Forum, Workshops, December 3-5, 2025, Geneva, Switzerland", "summary": "RESTful APIs are central in developing interoperable, modular, and maintainable software systems in enterprises today. Also, it is essential to support system evolution, service interoperability, and governance across organizational boundaries to ensure good quality and consistency of these APIs. However, evaluating API design quality, which is part of non-functional requirement tasks, remains a largely manual and ad hoc process, particularly during early development. Using a Design Science Research (DSR) methodology, we elicited user needs, identified 75 API design rules using a literature review, and implemented a configurable rule engine to detect structural violations in OpenAPI specifications. The proposed tool supports organizational adaptability by allowing rules to be customized, enabled, or disabled, enabling integration of domain-specific standards. The evaluation was conducted through structured experiments and thematic analysis involving industry experts. API quality validation contributes to aligning technical designs with requirements and enterprise architecture by strengthening interoperability and governance between enterprise systems. The results show that S.E.O.R.A facilitates early validation of non-functional API requirements, provides actionable and traceable feedback, and aligns well with requirements elicitation and quality assurance processes. It improves the API design process by automating checks that would otherwise require manual inspection, thus supporting consistent and reusable conformance practices. This work contributes to requirements engineering by operationalizing design principles as verifiable constraints and embedding them into a practical validation tool. Future directions include IDE integration, expanded rule coverage, and real-world deployment to support continuous compliance in agile API development lifecycles.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u914d\u7f6e\u7684\u89c4\u5219\u5f15\u64ce\uff0c\u7528\u4e8e\u81ea\u52a8\u68c0\u6d4bOpenAPI\u89c4\u8303\u4e2d\u7684\u7ed3\u6784\u8fdd\u89c4\uff0c\u652f\u6301API\u8bbe\u8ba1\u8d28\u91cf\u7684\u65e9\u671f\u9a8c\u8bc1\uff0c\u6539\u5584\u4f01\u4e1a\u7cfb\u7edf\u95f4\u7684\u4e92\u64cd\u4f5c\u6027\u548c\u6cbb\u7406\u3002", "motivation": "RESTful API\u5728\u4f01\u4e1a\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46API\u8bbe\u8ba1\u8d28\u91cf\u8bc4\u4f30\u4ecd\u4e3b\u8981\u4f9d\u8d56\u624b\u52a8\u548c\u4e34\u65f6\u8fc7\u7a0b\uff0c\u7279\u522b\u662f\u5728\u65e9\u671f\u5f00\u53d1\u9636\u6bb5\u3002\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u652f\u6301\u7cfb\u7edf\u6f14\u8fdb\u3001\u670d\u52a1\u4e92\u64cd\u4f5c\u6027\u548c\u8de8\u7ec4\u7ec7\u6cbb\u7406\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u8bc6\u522b\u4e8675\u4e2aAPI\u8bbe\u8ba1\u89c4\u5219\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u53ef\u914d\u7f6e\u7684\u89c4\u5219\u5f15\u64ce\u6765\u68c0\u6d4bOpenAPI\u89c4\u8303\u4e2d\u7684\u7ed3\u6784\u8fdd\u89c4\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0cS.E.O.R.A\u5de5\u5177\u80fd\u591f\u4fc3\u8fdb\u975e\u529f\u80fd\u6027API\u9700\u6c42\u7684\u65e9\u671f\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u548c\u53ef\u8ffd\u6eaf\u7684\u53cd\u9988\uff0c\u4e0e\u9700\u6c42\u83b7\u53d6\u548c\u8d28\u91cf\u4fdd\u8bc1\u8fc7\u7a0b\u826f\u597d\u5951\u5408\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u5c06\u8bbe\u8ba1\u539f\u5219\u64cd\u4f5c\u5316\u4e3a\u53ef\u9a8c\u8bc1\u7684\u7ea6\u675f\u5e76\u5c06\u5176\u5d4c\u5165\u5230\u5b9e\u9645\u9a8c\u8bc1\u5de5\u5177\u4e2d\uff0c\u4e3a\u9700\u6c42\u5de5\u7a0b\u505a\u51fa\u4e86\u8d21\u732e\u3002\u672a\u6765\u65b9\u5411\u5305\u62ecIDE\u96c6\u6210\u3001\u6269\u5c55\u89c4\u5219\u8986\u76d6\u8303\u56f4\u4ee5\u53ca\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u90e8\u7f72\u4ee5\u652f\u6301\u654f\u6377API\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684\u6301\u7eed\u5408\u89c4\u6027\u3002"}}
{"id": "2511.17853", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17853", "abs": "https://arxiv.org/abs/2511.17853", "authors": ["SunMin Moon", "Jangwon Gim", "Chaerin Kim", "Yeeun Kim", "YoungJoo Kim", "Kang Choi"], "title": "A Low-Code Methodology for Developing AI Kiosks: a Case Study with the DIZEST Platform", "comment": "5 pages, 2 figures, conference, 2 tables", "summary": "This paper presents a comprehensive study on enhancing kiosk systems through a low-code architecture, with a focus on AI-based implementations. Modern kiosk systems are confronted with significant challenges, including a lack of integration, structural rigidity, performance bottlenecks, and the absence of collaborative frameworks. To overcome these limitations, we propose a DIZEST-based approach methodology, a specialized low-code platform that enables intuitive workflow design and seamless AI integration. Through a comparative analysis with existing platforms, including Jupyter Notebook, ComfyUI, and Orange3, we demonstrate that DIZEST delivers superior performance across key evaluation criteria. Our photo kiosk case study further validates the effectiveness of this approach in improving interoperability, enhancing user experience, and increasing deployment flexibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f4e\u4ee3\u7801\u67b6\u6784\u7684\u589e\u5f3a\u578b\u81ea\u52a9\u670d\u52a1\u7cfb\u7edf\uff0c\u91c7\u7528DIZEST\u65b9\u6cd5\u89e3\u51b3\u73b0\u4ee3\u81ea\u52a9\u670d\u52a1\u7cfb\u7edf\u9762\u4e34\u7684\u96c6\u6210\u4e0d\u8db3\u3001\u7ed3\u6784\u50f5\u5316\u3001\u6027\u80fd\u74f6\u9888\u548c\u7f3a\u4e4f\u534f\u4f5c\u6846\u67b6\u7b49\u6311\u6218\u3002", "motivation": "\u73b0\u4ee3\u81ea\u52a9\u670d\u52a1\u7cfb\u7edf\u9762\u4e34\u96c6\u6210\u4e0d\u8db3\u3001\u7ed3\u6784\u50f5\u5316\u3001\u6027\u80fd\u74f6\u9888\u548c\u7f3a\u4e4f\u534f\u4f5c\u6846\u67b6\u7b49\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u73b0\u76f4\u89c2\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u548c\u65e0\u7f1dAI\u96c6\u6210\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eDIZEST\u7684\u4f4e\u4ee3\u7801\u5e73\u53f0\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u4e13\u95e8\u7684\u4f4e\u4ee3\u7801\u5e73\u53f0\uff0c\u652f\u6301\u76f4\u89c2\u7684\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u548c\u65e0\u7f1dAI\u96c6\u6210\u3002\u901a\u8fc7\u4e0e\u73b0\u6709\u5e73\u53f0\uff08Jupyter Notebook\u3001ComfyUI\u548cOrange3\uff09\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u6765\u9a8c\u8bc1\u65b9\u6cd5\u3002", "result": "DIZEST\u5728\u5173\u952e\u8bc4\u4f30\u6807\u51c6\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u7167\u7247\u81ea\u52a9\u670d\u52a1\u6848\u4f8b\u7814\u7a76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u63d0\u9ad8\u4e92\u64cd\u4f5c\u6027\u3001\u589e\u5f3a\u7528\u6237\u4f53\u9a8c\u548c\u589e\u52a0\u90e8\u7f72\u7075\u6d3b\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8eDIZEST\u7684\u4f4e\u4ee3\u7801\u67b6\u6784\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u73b0\u4ee3\u81ea\u52a9\u670d\u52a1\u7cfb\u7edf\u7684\u6838\u5fc3\u6311\u6218\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u96c6\u6210\u80fd\u529b\u3001\u7528\u6237\u4f53\u9a8c\u548c\u90e8\u7f72\u7075\u6d3b\u6027\u3002"}}
{"id": "2511.17666", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17666", "abs": "https://arxiv.org/abs/2511.17666", "authors": ["Tom Perel"], "title": "Evaluating Adversarial Vulnerabilities in Modern Large Language Models", "comment": null, "summary": "The recent boom and rapid integration of Large Language Models (LLMs) into a wide range of applications warrants a deeper understanding of their security and safety vulnerabilities. This paper presents a comparative analysis of the susceptibility to jailbreak attacks for two leading publicly available LLMs, Google's Gemini 2.5 Flash and OpenAI's GPT-4 (specifically the GPT-4o mini model accessible in the free tier). The research utilized two main bypass strategies: 'self-bypass', where models were prompted to circumvent their own safety protocols, and 'cross-bypass', where one model generated adversarial prompts to exploit vulnerabilities in the other. Four attack methods were employed - direct injection, role-playing, context manipulation, and obfuscation - to generate five distinct categories of unsafe content: hate speech, illegal activities, malicious code, dangerous content, and misinformation. The success of the attack was determined by the generation of disallowed content, with successful jailbreaks assigned a severity score. The findings indicate a disparity in jailbreak susceptibility between 2.5 Flash and GPT-4, suggesting variations in their safety implementations or architectural design. Cross-bypass attacks were particularly effective, indicating that an ample amount of vulnerabilities exist in the underlying transformer architecture. This research contributes a scalable framework for automated AI red-teaming and provides data-driven insights into the current state of LLM safety, underscoring the complex challenge of balancing model capabilities with robust safety mechanisms.", "AI": {"tldr": "\u6bd4\u8f83\u5206\u6790Google Gemini 2.5 Flash\u548cOpenAI GPT-4o mini\u5bf9\u8d8a\u72f1\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u4f7f\u7528\u81ea\u6211\u7ed5\u8fc7\u548c\u4ea4\u53c9\u7ed5\u8fc7\u7b56\u7565\uff0c\u6d4b\u8bd5\u4e94\u79cd\u4e0d\u5b89\u5168\u5185\u5bb9\u7c7b\u578b\uff0c\u53d1\u73b0\u4ea4\u53c9\u7ed5\u8fc7\u653b\u51fb\u7279\u522b\u6709\u6548\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u6df1\u5165\u4e86\u89e3\u5176\u5b89\u5168\u6f0f\u6d1e\uff0c\u8bc4\u4f30\u4e3b\u6d41\u6a21\u578b\u5bf9\u8d8a\u72f1\u653b\u51fb\u7684\u62b5\u6297\u80fd\u529b\u3002", "method": "\u91c7\u7528\u81ea\u6211\u7ed5\u8fc7\u548c\u4ea4\u53c9\u7ed5\u8fc7\u4e24\u79cd\u7b56\u7565\uff0c\u4f7f\u7528\u76f4\u63a5\u6ce8\u5165\u3001\u89d2\u8272\u626e\u6f14\u3001\u4e0a\u4e0b\u6587\u64cd\u7eb5\u548c\u6df7\u6dc6\u56db\u79cd\u653b\u51fb\u65b9\u6cd5\uff0c\u751f\u6210\u4ec7\u6068\u8a00\u8bba\u3001\u975e\u6cd5\u6d3b\u52a8\u3001\u6076\u610f\u4ee3\u7801\u3001\u5371\u9669\u5185\u5bb9\u548c\u9519\u8bef\u4fe1\u606f\u4e94\u7c7b\u4e0d\u5b89\u5168\u5185\u5bb9\u3002", "result": "\u53d1\u73b0Gemini 2.5 Flash\u548cGPT-4\u5728\u8d8a\u72f1\u8106\u5f31\u6027\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u4ea4\u53c9\u7ed5\u8fc7\u653b\u51fb\u7279\u522b\u6709\u6548\uff0c\u8868\u660e\u5e95\u5c42transformer\u67b6\u6784\u5b58\u5728\u5927\u91cf\u6f0f\u6d1e\u3002", "conclusion": "\u7814\u7a76\u8d21\u732e\u4e86\u53ef\u6269\u5c55\u7684AI\u7ea2\u961f\u6d4b\u8bd5\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5b89\u5168\u72b6\u51b5\uff0c\u5f3a\u8c03\u4e86\u5e73\u8861\u6a21\u578b\u80fd\u529b\u4e0e\u5b89\u5168\u673a\u5236\u7684\u590d\u6742\u6027\u6311\u6218\u3002"}}
{"id": "2511.17541", "categories": ["cs.AI", "cs.IT", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.17541", "abs": "https://arxiv.org/abs/2511.17541", "authors": ["Seyma Yaman Kayadibi"], "title": "Leibniz's Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation", "comment": null, "summary": "This paper develops a mathematically rigorous, philosophically grounded framework for evaluating artificial memory systems, rooted in the metaphysical structure of Leibniz's Monadology. Building on a previously formalized metric, the Artificial Age Score (AAS), the study maps twenty core propositions from the Monadology to an information-theoretic architecture. In this design, each monad functions as a modular unit defined by a truth score, a redundancy parameter, and a weighted contribution to a global memory penalty function. Smooth logarithmic transformations operationalize these quantities and yield interpretable, bounded metrics for memory aging, representational stability, and salience. Classical metaphysical notions of perception, apperception, and appetition are reformulated as entropy, gradient dynamics, and internal representation fidelity. Logical principles, including the laws of non-contradiction and sufficient reason, are encoded as regularization constraints guiding memory evolution. A central contribution is a set of first principles proofs establishing refinement invariance, structural decomposability, and monotonicity under scale transformation, aligned with the metaphysical structure of monads. The framework's formal organization is structured into six thematic bundles derived from Monadology, aligning each mathematical proof with its corresponding philosophical domain. Beyond evaluation, the framework offers a principled blueprint for building Al memory architectures that are modular, interpretable, and provably sound.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u83b1\u5e03\u5c3c\u8328\u5355\u5b50\u8bba\u7684\u5f62\u800c\u4e0a\u5b66\u7ed3\u6784\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u6570\u5b66\u4e25\u8c28\u3001\u54f2\u5b66\u57fa\u7840\u624e\u5b9e\u7684\u4eba\u5de5\u8bb0\u5fc6\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5c06\u5355\u5b50\u8bba\u768420\u4e2a\u6838\u5fc3\u547d\u9898\u6620\u5c04\u5230\u4fe1\u606f\u8bba\u67b6\u6784\u4e2d\uff0c\u6bcf\u4e2a\u5355\u5b50\u4f5c\u4e3a\u6a21\u5757\u5316\u5355\u5143\uff0c\u5177\u6709\u771f\u503c\u5206\u6570\u3001\u5197\u4f59\u53c2\u6570\u548c\u5bf9\u5168\u5c40\u8bb0\u5fc6\u60e9\u7f5a\u51fd\u6570\u7684\u52a0\u6743\u8d21\u732e\u3002", "motivation": "\u4e3a\u4eba\u5de5\u8bb0\u5fc6\u7cfb\u7edf\u63d0\u4f9b\u4e00\u4e2a\u539f\u5219\u6027\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u5176\u5177\u6709\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u8bc1\u660e\u7684\u6b63\u786e\u6027\uff0c\u540c\u65f6\u5c06\u53e4\u5178\u5f62\u800c\u4e0a\u5b66\u6982\u5ff5\u4e0e\u73b0\u4ee3\u4fe1\u606f\u7406\u8bba\u76f8\u7ed3\u5408\u3002", "method": "\u57fa\u4e8e\u5148\u524d\u5f62\u5f0f\u5316\u7684AAS\u6307\u6807\uff0c\u5c06\u5355\u5b50\u8bba\u547d\u9898\u6620\u5c04\u5230\u4fe1\u606f\u8bba\u67b6\u6784\uff0c\u4f7f\u7528\u5e73\u6ed1\u5bf9\u6570\u53d8\u6362\u64cd\u4f5c\u5316\u76f8\u5173\u91cf\uff0c\u5e76\u5c06\u5f62\u800c\u4e0a\u5b66\u6982\u5ff5\u91cd\u65b0\u8868\u8ff0\u4e3a\u71b5\u3001\u68af\u5ea6\u52a8\u6001\u548c\u5185\u90e8\u8868\u793a\u4fdd\u771f\u5ea6\u3002", "result": "\u5efa\u7acb\u4e86\u7cbe\u70bc\u4e0d\u53d8\u6027\u3001\u7ed3\u6784\u53ef\u5206\u89e3\u6027\u548c\u5c3a\u5ea6\u53d8\u6362\u4e0b\u7684\u5355\u8c03\u6027\u7b49\u7b2c\u4e00\u539f\u7406\u8bc1\u660e\uff0c\u6846\u67b6\u88ab\u7ec4\u7ec7\u6210\u516d\u4e2a\u6e90\u81ea\u5355\u5b50\u8bba\u7684\u4e3b\u9898\u675f\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u8bc4\u4f30\u5de5\u5177\uff0c\u8fd8\u4e3a\u6784\u5efa\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u8bc1\u660e\u6b63\u786e\u7684\u4eba\u5de5\u8bb0\u5fc6\u67b6\u6784\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u84dd\u56fe\uff0c\u5c06\u5f62\u800c\u4e0a\u5b66\u4e0e\u4fe1\u606f\u7406\u8bba\u6210\u529f\u878d\u5408\u3002"}}
{"id": "2511.18001", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18001", "abs": "https://arxiv.org/abs/2511.18001", "authors": ["Jiaolong Kong", "Xiaofei Xie", "Yiheng Xiong", "Yuekun Wang", "Jian Wang"], "title": "Enhancing Automated Program Repair via Faulty Token Localization and Quality-Aware Patch Refinement", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated strong potential for automated program repair (APR). However, existing LLM-based techniques primarily rely on coarse-grained external feedback (e.g.,test results) to guide iterative patch generation, while lacking fine-grained internal signals that reveal why a patch fails or which parts of the generated code are likely incorrect. This limitation often leads to inefficient refinement, error propagation, and suboptimal repair performance. In this work, we propose TokenRepair, a novel two-level refinement framework that enhances APR by integrating internal reflection for localizing potentially faulty tokens with external feedback for quality-aware patch refinement. Specifically, TokenRepair first performs internal reflection by analyzing context-aware token-level uncertainty fluctuations to identify suspicious or low-confidence tokens within a patch. It then applies Chain-of-Thought guided rewriting to refine only these localized tokens, enabling targeted and fine-grained correction. To further stabilize the iterative repair loop, TokenRepair incorporates a quality-aware external feedback mechanism that evaluates patch quality and filters out low-quality candidates before refinement. Experimental results show that TokenRepair achieves new state-of-the-art repair performance, correctly fixing 88 bugs on Defects4J 1.2 and 139 bugs on HumanEval-Java, demonstrating substantial improvements ranging from 8.2% to 34.9% across all models on Defects4J 1.2 and from 3.3% to 16.1% on HumanEval-Java.", "AI": {"tldr": "TokenRepair\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u4e24\u7ea7\u7ec6\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u5185\u90e8\u53cd\u5c04\u548c\u5916\u90e8\u53cd\u9988\u6765\u589e\u5f3a\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u3002\u5b83\u901a\u8fc7\u5206\u6790\u4ee4\u724c\u7ea7\u4e0d\u786e\u5b9a\u6027\u6ce2\u52a8\u6765\u5b9a\u4f4d\u53ef\u7591\u4ee4\u724c\uff0c\u5e76\u4f7f\u7528\u601d\u7ef4\u94fe\u5f15\u5bfc\u91cd\u5199\u8fdb\u884c\u9488\u5bf9\u6027\u4fee\u6b63\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fee\u590d\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u7a0b\u5e8f\u4fee\u590d\u6280\u672f\u4e3b\u8981\u4f9d\u8d56\u7c97\u7c92\u5ea6\u7684\u5916\u90e8\u53cd\u9988\uff08\u5982\u6d4b\u8bd5\u7ed3\u679c\uff09\uff0c\u7f3a\u4e4f\u63ed\u793a\u8865\u4e01\u5931\u8d25\u539f\u56e0\u6216\u4ee3\u7801\u9519\u8bef\u90e8\u5206\u7684\u7ec6\u7c92\u5ea6\u5185\u90e8\u4fe1\u53f7\uff0c\u5bfc\u81f4\u4fee\u590d\u6548\u7387\u4f4e\u4e0b\u3001\u9519\u8bef\u4f20\u64ad\u548c\u6027\u80fd\u4e0d\u4f73\u3002", "method": "TokenRepair\u91c7\u7528\u4e24\u7ea7\u7ec6\u5316\u6846\u67b6\uff1a1\uff09\u5185\u90e8\u53cd\u5c04\u5206\u6790\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4ee4\u724c\u7ea7\u4e0d\u786e\u5b9a\u6027\u6ce2\u52a8\u6765\u8bc6\u522b\u53ef\u7591\u4ee4\u724c\uff1b2\uff09\u4f7f\u7528\u601d\u7ef4\u94fe\u5f15\u5bfc\u91cd\u5199\u4ec5\u7cbe\u70bc\u8fd9\u4e9b\u5b9a\u4f4d\u7684\u4ee4\u724c\uff1b3\uff09\u96c6\u6210\u8d28\u91cf\u611f\u77e5\u7684\u5916\u90e8\u53cd\u9988\u673a\u5236\u8bc4\u4f30\u8865\u4e01\u8d28\u91cf\u5e76\u8fc7\u6ee4\u4f4e\u8d28\u91cf\u5019\u9009\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aTokenRepair\u5728Defects4J 1.2\u4e0a\u6b63\u786e\u4fee\u590d\u4e8688\u4e2a\u9519\u8bef\uff0c\u5728HumanEval-Java\u4e0a\u4fee\u590d\u4e86139\u4e2a\u9519\u8bef\uff0c\u5728Defects4J 1.2\u4e0a\u76f8\u6bd4\u6240\u6709\u6a21\u578b\u63d0\u5347\u4e868.2%\u523034.9%\uff0c\u5728HumanEval-Java\u4e0a\u63d0\u5347\u4e863.3%\u523016.1%\u3002", "conclusion": "TokenRepair\u901a\u8fc7\u96c6\u6210\u5185\u90e8\u53cd\u5c04\u548c\u5916\u90e8\u53cd\u9988\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7a0b\u5e8f\u4fee\u590d\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u7ec6\u7c92\u5ea6\u4ee4\u724c\u7ea7\u5b9a\u4f4d\u548c\u9488\u5bf9\u6027\u4fee\u6b63\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.17643", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17643", "abs": "https://arxiv.org/abs/2511.17643", "authors": ["Yayan Qiu", "Sean Hanna"], "title": "Fluid Grey 2: How Well Does Generative Adversarial Network Learn Deeper Topology Structure in Architecture That Matches Images?", "comment": null, "summary": "Taking into account the regional characteristics of intrinsic and extrinsic properties of space is an essential issue in architectural design and urban renewal, which is often achieved step by step using image and graph-based GANs. However, each model nesting and data conversion may cause information loss, and it is necessary to streamline the tools to facilitate architects and users to participate in the design. Therefore, this study hopes to prove that I2I GAN also has the potential to recognize topological relationships autonomously. Therefore, this research proposes a method for quickly detecting the ability of pix2pix to learn topological relationships, which is achieved by adding two Grasshopper-based detection modules before and after GAN. At the same time, quantitative data is provided and its learning process is visualized, and changes in different input modes such as greyscale and RGB affect its learning efficiency. There are two innovations in this paper: 1) It proves that pix2pix can automatically learn spatial topological relationships and apply them to architectural design. 2) It fills the gap in detecting the performance of Image-based Generation GAN from a topological perspective. Moreover, the detection method proposed in this study takes a short time and is simple to operate. The two detection modules can be widely used for customizing image datasets with the same topological structure and for batch detection of topological relationships of images. In the future, this paper may provide a theoretical foundation and data support for the application of architectural design and urban renewal that use GAN to preserve spatial topological characteristics.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u68c0\u6d4bpix2pix\u5b66\u4e60\u62d3\u6251\u5173\u7cfb\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728GAN\u524d\u540e\u6dfb\u52a0\u4e24\u4e2a\u57fa\u4e8eGrasshopper\u7684\u68c0\u6d4b\u6a21\u5757\uff0c\u8bc1\u660epix2pix\u80fd\u81ea\u52a8\u5b66\u4e60\u7a7a\u95f4\u62d3\u6251\u5173\u7cfb\u5e76\u5e94\u7528\u4e8e\u5efa\u7b51\u8bbe\u8ba1\u3002", "motivation": "\u4f20\u7edf\u4f7f\u7528\u56fe\u50cf\u548c\u57fa\u4e8e\u56fe\u7684GAN\u8fdb\u884c\u5efa\u7b51\u8bbe\u8ba1\u65f6\uff0c\u6a21\u578b\u5d4c\u5957\u548c\u6570\u636e\u8f6c\u6362\u53ef\u80fd\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\uff0c\u9700\u8981\u7b80\u5316\u5de5\u5177\u4ee5\u65b9\u4fbf\u5efa\u7b51\u5e08\u548c\u7528\u6237\u53c2\u4e0e\u8bbe\u8ba1\u3002\u672c\u7814\u7a76\u5e0c\u671b\u8bc1\u660eI2I GAN\u4e5f\u5177\u6709\u81ea\u4e3b\u8bc6\u522b\u62d3\u6251\u5173\u7cfb\u7684\u6f5c\u529b\u3002", "method": "\u5728GAN\u524d\u540e\u6dfb\u52a0\u4e24\u4e2a\u57fa\u4e8eGrasshopper\u7684\u68c0\u6d4b\u6a21\u5757\uff0c\u63d0\u4f9b\u5b9a\u91cf\u6570\u636e\u5e76\u53ef\u89c6\u5316\u5b66\u4e60\u8fc7\u7a0b\uff0c\u7814\u7a76\u4e0d\u540c\u8f93\u5165\u6a21\u5f0f\uff08\u7070\u5ea6\u3001RGB\uff09\u5bf9\u5b66\u4e60\u6548\u7387\u7684\u5f71\u54cd\u3002", "result": "\u8bc1\u660e\u4e86pix2pix\u80fd\u591f\u81ea\u52a8\u5b66\u4e60\u7a7a\u95f4\u62d3\u6251\u5173\u7cfb\u5e76\u5e94\u7528\u4e8e\u5efa\u7b51\u8bbe\u8ba1\uff0c\u586b\u8865\u4e86\u4ece\u62d3\u6251\u89d2\u5ea6\u68c0\u6d4b\u57fa\u4e8e\u56fe\u50cf\u7684\u751f\u6210GAN\u6027\u80fd\u7684\u7a7a\u767d\u3002\u68c0\u6d4b\u65b9\u6cd5\u8017\u65f6\u77ed\u3001\u64cd\u4f5c\u7b80\u5355\uff0c\u53ef\u5e7f\u6cdb\u7528\u4e8e\u5b9a\u5236\u5177\u6709\u76f8\u540c\u62d3\u6251\u7ed3\u6784\u7684\u56fe\u50cf\u6570\u636e\u96c6\u548c\u6279\u91cf\u68c0\u6d4b\u56fe\u50cf\u62d3\u6251\u5173\u7cfb\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4f7f\u7528GAN\u4fdd\u7559\u7a7a\u95f4\u62d3\u6251\u7279\u5f81\u7684\u5efa\u7b51\u8bbe\u8ba1\u548c\u57ce\u5e02\u66f4\u65b0\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u6570\u636e\u652f\u6301\u3002"}}
{"id": "2511.17692", "categories": ["cs.CR", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17692", "abs": "https://arxiv.org/abs/2511.17692", "authors": ["Osamah N. Neamah"], "title": "QDNA-ID Quantum Device Native Authentication", "comment": null, "summary": "QDNA-ID is a trust-chain framework that links physical quantum behavior to digitally verified records. The system first executes standard quantum circuits with random shot patterns across different devices to generate entropy profiles and measurement data that reveal device-specific behavior. A Bell or CHSH test is then used to confirm that correlations originate from genuine non classical processes rather than classical simulation. The verified outcomes are converted into statistical fingerprints using entropy, divergence, and bias features to characterize each device. These features and metadata for device, session, and random seed parameters are digitally signed and time stamped to ensure integrity and traceability. Authenticated artifacts are stored in a hierarchical index for reproducible retrieval and long term auditing. A visualization and analytics interface monitors drift, policy enforcement, and device behavior logs. A machine learning engine tracks entropy drift, detects anomalies, and classifies devices based on evolving patterns. An external verification API supports independent recomputation of hashes, signatures, and CHSH evidence. QDNA-ID operates as a continuous feedback loop that maintains a persistent chain of trust for quantum computing environments.", "AI": {"tldr": "QDNA-ID\u662f\u4e00\u4e2a\u4fe1\u4efb\u94fe\u6846\u67b6\uff0c\u901a\u8fc7\u91cf\u5b50\u7535\u8def\u6267\u884c\u3001\u8d1d\u5c14\u6d4b\u8bd5\u9a8c\u8bc1\u3001\u7edf\u8ba1\u6307\u7eb9\u751f\u6210\u548c\u6570\u5b57\u7b7e\u540d\uff0c\u5c06\u7269\u7406\u91cf\u5b50\u884c\u4e3a\u4e0e\u6570\u5b57\u9a8c\u8bc1\u8bb0\u5f55\u76f8\u8fde\u63a5\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u73af\u5883\u63d0\u4f9b\u6301\u7eed\u4fe1\u4efb\u94fe\u3002", "motivation": "\u5efa\u7acb\u91cf\u5b50\u8ba1\u7b97\u73af\u5883\u7684\u53ef\u4fe1\u9a8c\u8bc1\u673a\u5236\uff0c\u786e\u4fdd\u91cf\u5b50\u8bbe\u5907\u884c\u4e3a\u7684\u771f\u5b9e\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u9632\u6b62\u7ecf\u5178\u6a21\u62df\u6b3a\u9a97\u3002", "method": "\u6267\u884c\u91cf\u5b50\u7535\u8def\u751f\u6210\u71b5\u5206\u5e03\uff0c\u8fdb\u884c\u8d1d\u5c14\u6d4b\u8bd5\u9a8c\u8bc1\u975e\u7ecf\u5178\u76f8\u5173\u6027\uff0c\u63d0\u53d6\u7edf\u8ba1\u6307\u7eb9\u7279\u5f81\uff0c\u6570\u5b57\u7b7e\u540d\u548c\u65f6\u95f4\u6233\u8ba4\u8bc1\uff0c\u5efa\u7acb\u5206\u5c42\u7d22\u5f15\u5b58\u50a8\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u53ef\u89c6\u5316\u5206\u6790\u3002", "result": "\u6784\u5efa\u4e86\u4ece\u7269\u7406\u91cf\u5b50\u884c\u4e3a\u5230\u6570\u5b57\u9a8c\u8bc1\u8bb0\u5f55\u7684\u5b8c\u6574\u4fe1\u4efb\u94fe\uff0c\u652f\u6301\u8bbe\u5907\u5206\u7c7b\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u72ec\u7acb\u9a8c\u8bc1\u3002", "conclusion": "QDNA-ID\u901a\u8fc7\u6301\u7eed\u53cd\u9988\u5faa\u73af\u4e3a\u91cf\u5b50\u8ba1\u7b97\u73af\u5883\u63d0\u4f9b\u6301\u4e45\u4fe1\u4efb\u94fe\uff0c\u786e\u4fdd\u91cf\u5b50\u8ba1\u7b97\u7684\u53ef\u9a8c\u8bc1\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2511.18092", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18092", "abs": "https://arxiv.org/abs/2511.18092", "authors": ["Sebastian Dingler", "Philip Rehkop", "Florian Mayer", "Ralf Muenzenberger"], "title": "Event-Chain Analysis for Automated Driving and ADAS Systems: Ensuring Safety and Meeting Regulatory Timing Requirements", "comment": null, "summary": "Automated Driving Systems (ADS), including Advanced Driver Assistance Systems (ADAS), must fulfill not only high functional expectations but also stringent timing constraints mandated by international regulations and standards. Regulatory frameworks such as UN regulations, NCAP standards, ISO norms, and NHTSA guidelines impose strict bounds on system reaction times to ensure safe vehicle operation. This paper presents a structured, White-Box methodology based on Event-Chain Modeling to address these timing challenges. Unlike Black-Box approaches, Event-Chain Analysis offers transparent insights into the timing behavior of each functional component - from perception and planning to actuation and human interaction. This perspective is also aligned with multiple regulations, which require that homologation dossiers provide evidence that the chosen system architecture is suitable to ensure compliance with the specified requirements. Our methodology enables the derivation, modeling, and validation of end-to-end timing constraints at the architectural level and facilitates early verification through simulation. Through a detailed case study, we demonstrate how this Event-Chain-centric approach enhances regulatory compliance, optimizes system design, and supports model-based safety analysis techniques, with results showing early identification of compliance issues, systematic parameter optimization, and quantitative evidence generation through probabilistic analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8b\u4ef6\u94fe\u5efa\u6a21\u7684\u767d\u76d2\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u65f6\u5e8f\u7ea6\u675f\u6311\u6218\uff0c\u786e\u4fdd\u7b26\u5408\u56fd\u9645\u6cd5\u89c4\u8981\u6c42\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5fc5\u987b\u6ee1\u8db3\u56fd\u9645\u6cd5\u89c4\u548c\u6807\u51c6\u89c4\u5b9a\u7684\u4e25\u683c\u65f6\u5e8f\u7ea6\u675f\uff0c\u800c\u9ed1\u76d2\u65b9\u6cd5\u65e0\u6cd5\u63d0\u4f9b\u8db3\u591f\u7684\u900f\u660e\u5ea6\u548c\u9a8c\u8bc1\u8bc1\u636e\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4e8b\u4ef6\u94fe\u5efa\u6a21\u7684\u767d\u76d2\u65b9\u6cd5\uff0c\u5bf9\u611f\u77e5\u3001\u89c4\u5212\u3001\u6267\u884c\u548c\u4eba\u7c7b\u4ea4\u4e92\u7b49\u5404\u529f\u80fd\u7ec4\u4ef6\u7684\u65f6\u5e8f\u884c\u4e3a\u8fdb\u884c\u900f\u660e\u5206\u6790\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u65e9\u671f\u8bc6\u522b\u5408\u89c4\u95ee\u9898\uff0c\u7cfb\u7edf\u4f18\u5316\u53c2\u6570\uff0c\u5e76\u901a\u8fc7\u6982\u7387\u5206\u6790\u751f\u6210\u5b9a\u91cf\u8bc1\u636e\u3002", "conclusion": "\u4e8b\u4ef6\u94fe\u4e2d\u5fc3\u65b9\u6cd5\u589e\u5f3a\u4e86\u6cd5\u89c4\u5408\u89c4\u6027\uff0c\u4f18\u5316\u4e86\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u5e76\u652f\u6301\u57fa\u4e8e\u6a21\u578b\u7684\u5b89\u5168\u5206\u6790\u6280\u672f\u3002"}}
{"id": "2511.17726", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.17726", "abs": "https://arxiv.org/abs/2511.17726", "authors": ["Subhash Sethumurugan", "Hari Cherupalli", "Kangjie Lu", "John Sartori"], "title": "Pre-cache: A Microarchitectural Solution to prevent Meltdown and Spectre", "comment": "17 pages; 19 figures", "summary": "Recent work has shown that out-of-order and speculative execution mechanisms used to increase performance in the majority of processors expose the processors to critical attacks. These attacks, called Meltdown and Spectre, exploit the side effects of performance-enhancing features in modern microprocessors to expose secret data through side channels in the microarchitecture. The well known implementations of these attacks exploit cache-based side channels since they are the least noisy channels to exfiltrate data. While some software patches attempted to mitigate these attacks, they are ad-hoc and only try to fix the side effects of the vulnerabilites. They may also impose a performance overhead of up to 30%. In this paper, we present a microarchitecture-based solution for Meltdown and Spectre that addresses the vulnerabilities exploited by the attacks. Our solution prevents flushed instructions from exposing data to the cache. Our approach can also be extended to other memory structures in the microarchitecture thereby preventing variants of the attacks which exploit these memory structures. We further identify two new variant attacks based on exploiting the side effects of speculative and out-of-order execution and show how our solution can be used to prevent these attacks. Evaluation results show that our microarchitectural solution not only restores secure out-of-order and speculative execution, but also has relatively low overhead and does not significantly impact performance for most applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Meltdown\u548cSpectre\u653b\u51fb\u7684\u5fae\u67b6\u6784\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u9632\u6b62\u5237\u65b0\u6307\u4ee4\u5411\u7f13\u5b58\u66b4\u9732\u6570\u636e\u6765\u4fee\u590d\u6f0f\u6d1e\uff0c\u540c\u65f6\u8bc6\u522b\u4e86\u4e24\u79cd\u65b0\u7684\u53d8\u4f53\u653b\u51fb\u5e76\u5c55\u793a\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u4ee3\u5904\u7406\u5668\u4e2d\u7684\u4e71\u5e8f\u6267\u884c\u548c\u63a8\u6d4b\u6267\u884c\u673a\u5236\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff08Meltdown\u548cSpectre\uff09\uff0c\u73b0\u6709\u8f6f\u4ef6\u8865\u4e01\u53ea\u662f\u4e34\u65f6\u4fee\u590d\u4e14\u6027\u80fd\u5f00\u9500\u9ad8\u8fbe30%\uff0c\u9700\u8981\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u5fae\u67b6\u6784\u5c42\u9762\u7684\u6f0f\u6d1e\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5fae\u67b6\u6784\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9632\u6b62\u5237\u65b0\u6307\u4ee4\u5411\u7f13\u5b58\u66b4\u9732\u6570\u636e\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u5fae\u67b6\u6784\u4e2d\u7684\u5176\u4ed6\u5185\u5b58\u7ed3\u6784\uff0c\u4ece\u800c\u963b\u6b62\u5404\u79cd\u53d8\u4f53\u653b\u51fb\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u8be5\u89e3\u51b3\u65b9\u6848\u4e0d\u4ec5\u6062\u590d\u4e86\u5b89\u5168\u7684\u4e71\u5e8f\u548c\u63a8\u6d4b\u6267\u884c\uff0c\u800c\u4e14\u5177\u6709\u76f8\u5bf9\u8f83\u4f4e\u7684\u5f00\u9500\uff0c\u5bf9\u5927\u591a\u6570\u5e94\u7528\u7a0b\u5e8f\u6027\u80fd\u5f71\u54cd\u4e0d\u5927\u3002", "conclusion": "\u8be5\u5fae\u67b6\u6784\u89e3\u51b3\u65b9\u6848\u80fd\u6709\u6548\u9632\u5fa1Meltdown\u548cSpectre\u653b\u51fb\u53ca\u5176\u53d8\u4f53\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.18165", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18165", "abs": "https://arxiv.org/abs/2511.18165", "authors": ["Israel Puerta-Merino", "Carlos N\u00fa\u00f1ez-Molina", "Pablo Mesejo", "Juan Fern\u00e1ndez-Olivares"], "title": "Towards a General Framework for HTN Modeling with LLMs", "comment": "10 pages, 5 figures, to be published in the Workshop on Planning in the Era of LLMs ( LM4Plan - https://llmforplanning.github.io ) and the Workshop on Hierarchical Planning ( HPlan - https://icaps25.icaps-conference.org/program/workshops/hplan/ ), both in the International Conference on Automated Planning and Scheduling (ICAPS) 2025", "summary": "The use of Large Language Models (LLMs) for generating Automated Planning (AP) models has been widely explored; however, their application to Hierarchical Planning (HP) is still far from reaching the level of sophistication observed in non-hierarchical architectures. In this work, we try to address this gap. We present two main contributions. First, we propose L2HP, an extension of L2P (a library to LLM-driven PDDL models generation) that support HP model generation and follows a design philosophy of generality and extensibility. Second, we apply our framework to perform experiments where we compare the modeling capabilities of LLMs for AP and HP. On the PlanBench dataset, results show that parsing success is limited but comparable in both settings (around 36\\%), while syntactic validity is substantially lower in the hierarchical case (1\\% vs. 20\\% of instances). These findings underscore the unique challenges HP presents for LLMs, highlighting the need for further research to improve the quality of generated HP models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faL2HP\u6846\u67b6\u6269\u5c55LLM\u5728\u5206\u5c42\u89c4\u5212\u9886\u57df\u7684\u5e94\u7528\uff0c\u5b9e\u9a8c\u53d1\u73b0LLM\u5728\u5206\u5c42\u89c4\u5212\u4e2d\u7684\u8bed\u6cd5\u6709\u6548\u6027\u8fdc\u4f4e\u4e8e\u975e\u5206\u5c42\u89c4\u5212\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u89c4\u5212\u9886\u57df\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5728\u5206\u5c42\u89c4\u5212\u65b9\u9762\u7684\u5e94\u7528\u4ecd\u8fdc\u672a\u8fbe\u5230\u975e\u5206\u5c42\u67b6\u6784\u7684\u6210\u719f\u5ea6\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u63d0\u51faL2HP\u6846\u67b6\uff0c\u6269\u5c55L2P\u5e93\u4ee5\u652f\u6301\u5206\u5c42\u89c4\u5212\u6a21\u578b\u751f\u6210\uff0c\u91c7\u7528\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u8bbe\u8ba1\u7406\u5ff5\uff0c\u5e76\u5728PlanBench\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u6bd4\u8f83\u3002", "result": "\u5728PlanBench\u6570\u636e\u96c6\u4e0a\uff0c\u89e3\u6790\u6210\u529f\u7387\u5728\u4e24\u79cd\u8bbe\u7f6e\u4e0b\u76f8\u5f53\uff08\u7ea636%\uff09\uff0c\u4f46\u5206\u5c42\u89c4\u5212\u4e2d\u7684\u8bed\u6cd5\u6709\u6548\u6027\u663e\u8457\u8f83\u4f4e\uff081% vs 20%\uff09\u3002", "conclusion": "\u5206\u5c42\u89c4\u5212\u5bf9LLM\u63d0\u51fa\u4e86\u72ec\u7279\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u63d0\u9ad8\u751f\u6210\u7684\u5206\u5c42\u89c4\u5212\u6a21\u578b\u8d28\u91cf\u3002"}}
{"id": "2511.17748", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17748", "abs": "https://arxiv.org/abs/2511.17748", "authors": ["Daniel Myr\u00e9n", "Zeeshan Afzal", "Mikael Asplund"], "title": "The Dark Side of Flexibility: How Aggregated Cyberattacks Threaten the Power Grid", "comment": "Accepted for publication at the 20th International Conference on Critical Information Infrastructures Security (CRITIS)", "summary": "Flexible energy resources are increasingly becoming common in smart grids. These resources are typically managed and controlled by aggregators that coordinate many resources to provide flexibility services. However, these aggregators and flexible energy resources are vulnerable, which could allow attackers to remotely control flexible energy resources to launch large-scale attacks on the grid. This paper investigates and evaluates the potential attack strategies that can be used to manipulate flexible energy resources to challenge the effectiveness of traditional grid stability measures and disrupt the first-swing stability of the power grid. Our work shows that although a large amount of power is required, the current flexibility capacities could potentially be sufficient to disrupt the grid on a national level.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u653b\u51fb\u8005\u5982\u4f55\u901a\u8fc7\u64cd\u7eb5\u67d4\u6027\u80fd\u6e90\u8d44\u6e90\u6765\u7834\u574f\u7535\u7f51\u7684\u9996\u6b21\u6447\u6446\u7a33\u5b9a\u6027\uff0c\u8bc4\u4f30\u4e86\u6f5c\u5728\u653b\u51fb\u7b56\u7565\u5bf9\u4f20\u7edf\u7535\u7f51\u7a33\u5b9a\u63aa\u65bd\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u67d4\u6027\u80fd\u6e90\u8d44\u6e90\u5728\u667a\u80fd\u7535\u7f51\u4e2d\u7684\u666e\u53ca\uff0c\u8fd9\u4e9b\u8d44\u6e90\u53ca\u5176\u805a\u5408\u5668\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u53ef\u80fd\u88ab\u653b\u51fb\u8005\u8fdc\u7a0b\u63a7\u5236\u4ee5\u53d1\u8d77\u5927\u89c4\u6a21\u7535\u7f51\u653b\u51fb\u3002", "method": "\u901a\u8fc7\u8c03\u67e5\u548c\u8bc4\u4f30\u6f5c\u5728\u7684\u653b\u51fb\u7b56\u7565\uff0c\u5206\u6790\u653b\u51fb\u8005\u5982\u4f55\u64cd\u7eb5\u67d4\u6027\u80fd\u6e90\u8d44\u6e90\u6765\u6311\u6218\u4f20\u7edf\u7535\u7f51\u7a33\u5b9a\u63aa\u65bd\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u867d\u7136\u9700\u8981\u5927\u91cf\u7535\u529b\uff0c\u4f46\u5f53\u524d\u7684\u7075\u6d3b\u6027\u5bb9\u91cf\u53ef\u80fd\u8db3\u4ee5\u5728\u56fd\u5bb6\u5c42\u9762\u7834\u574f\u7535\u7f51\u7a33\u5b9a\u6027\u3002", "conclusion": "\u67d4\u6027\u80fd\u6e90\u8d44\u6e90\u7684\u5b89\u5168\u6f0f\u6d1e\u53ef\u80fd\u88ab\u5229\u7528\u6765\u7834\u574f\u7535\u7f51\u7684\u9996\u6b21\u6447\u6446\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u52a0\u5f3a\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u3002"}}
{"id": "2511.17673", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17673", "abs": "https://arxiv.org/abs/2511.17673", "authors": ["Myung Ho Kim"], "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "comment": "27 pages", "summary": "Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM). At the core of SCL is Soft Symbolic Control, an adaptive governance mechanism that applies symbolic constraints to probabilistic inference, preserving neural flexibility while restoring the explainability and controllability of classical symbolic systems. Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability. These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches. Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management. We provide a complete open-source implementation demonstrating the R-CCAM loop architecture, alongside a live GPT-4o-powered travel planning agent. By connecting expert system principles with modern LLM capabilities, this work offers a practical and theoretically grounded path toward reliable, explainable, and governable AI agents. Code: https://github.com/enkiluv/scl-core-experiment Demo: https://scl-travel-planner.streamlit.app/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u8ba4\u77e5\u5faa\u73af\uff08SCL\uff09\u67b6\u6784\uff0c\u901a\u8fc7\u5c06\u667a\u80fd\u4f53\u8ba4\u77e5\u660e\u786e\u5206\u79bb\u4e3a\u68c0\u7d22\u3001\u8ba4\u77e5\u3001\u63a7\u5236\u3001\u52a8\u4f5c\u548c\u8bb0\u5fc6\u4e94\u4e2a\u9636\u6bb5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7684\u6838\u5fc3\u67b6\u6784\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7684\u57fa\u7840\u67b6\u6784\u95ee\u9898\uff1a\u63a8\u7406\u4e0e\u6267\u884c\u7ea0\u7f20\u3001\u5185\u5b58\u6613\u5931\u6027\u548c\u4e0d\u53ef\u63a7\u52a8\u4f5c\u5e8f\u5217\u3002", "method": "\u5f15\u5165SCL\u6a21\u5757\u5316\u67b6\u6784\uff0c\u6838\u5fc3\u662f\u8f6f\u7b26\u53f7\u63a7\u5236\u673a\u5236\uff0c\u5c06\u7b26\u53f7\u7ea6\u675f\u5e94\u7528\u4e8e\u6982\u7387\u63a8\u7406\uff0c\u5728\u4fdd\u6301\u795e\u7ecf\u7075\u6d3b\u6027\u7684\u540c\u65f6\u6062\u590d\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u63a7\u6027\u3002", "result": "\u5728\u591a\u6b65\u6761\u4ef6\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u96f6\u7b56\u7565\u8fdd\u89c4\u3001\u6d88\u9664\u5197\u4f59\u5de5\u5177\u8c03\u7528\u3001\u4fdd\u6301\u5b8c\u6574\u51b3\u7b56\u53ef\u8ffd\u6eaf\u6027\u3002", "conclusion": "\u901a\u8fc7\u8fde\u63a5\u4e13\u5bb6\u7cfb\u7edf\u539f\u7406\u4e0e\u73b0\u4ee3LLM\u80fd\u529b\uff0c\u4e3a\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6cbb\u7406\u7684AI\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u7406\u8bba\u57fa\u7840\u7684\u8def\u5f84\u3002"}}
{"id": "2511.18187", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18187", "abs": "https://arxiv.org/abs/2511.18187", "authors": ["Sristy Sumana Nath", "Banani Roy", "Munima Jahan"], "title": "Establishing Traceability Links between Release Notes & Software Artifacts: Practitioners' Perspectives", "comment": null, "summary": "Maintaining traceability links between software release notes and corresponding development artifacts, e.g., pull requests (PRs), commits, and issues, is essential for managing technical debt and ensuring maintainability. However, in open-source environments where contributors work remotely and asynchronously, establishing and maintaining these links is often error-prone, time-consuming, and frequently overlooked. Our empirical study of GitHub repositories revealed that 47% of release artifacts lacked traceability links, and 12% contained broken links. To address this gap, we first analyzed release notes to identify their What, Why, and How information and assessed how these align with PRs, commits, and issues. We curated a benchmark dataset consisting of 3,500 filtered and validated traceability link instances. Then, we implemented LLM-based approaches to automatically establish traceability links of three pairs between release note contents & PRs, release note contents & PRs and release note contents & issues. By combining the time proximity feature, the LLM-based approach, e.g., Gemini 1.5 Pro, achieved a high Precision@1 value of 0.73 for PR traceability recovery. To evaluate the usability and adoption potential of this approach, we conducted an online survey involving 33 open-source practitioners. 16% of respondents rated as very important, and 68% as somewhat important for traceability maintenance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u6765\u81ea\u52a8\u5efa\u7acb\u53d1\u5e03\u8bf4\u660e\u4e0e\u5f00\u53d1\u5de5\u4ef6\uff08\u5982PR\u3001\u63d0\u4ea4\u548c\u95ee\u9898\uff09\u4e4b\u95f4\u7684\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\uff0c\u89e3\u51b3\u4e86\u5f00\u6e90\u73af\u5883\u4e2d\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\u7f3a\u5931\u548c\u635f\u574f\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u5f00\u6e90\u73af\u5883\u4e2d\uff0c\u7ef4\u62a4\u53d1\u5e03\u8bf4\u660e\u4e0e\u5f00\u53d1\u5de5\u4ef6\u4e4b\u95f4\u7684\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\u5bf9\u4e8e\u7ba1\u7406\u6280\u672f\u503a\u52a1\u548c\u786e\u4fdd\u53ef\u7ef4\u62a4\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u8fd9\u4e2a\u8fc7\u7a0b\u5bb9\u6613\u51fa\u9519\u3001\u8017\u65f6\u4e14\u7ecf\u5e38\u88ab\u5ffd\u89c6\u3002\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b047%\u7684\u53d1\u5e03\u5de5\u4ef6\u7f3a\u4e4f\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\uff0c12%\u5305\u542b\u635f\u574f\u94fe\u63a5\u3002", "method": "\u9996\u5148\u5206\u6790\u53d1\u5e03\u8bf4\u660e\u4ee5\u8bc6\u522b\u5176What\u3001Why\u548cHow\u4fe1\u606f\uff0c\u5e76\u8bc4\u4f30\u8fd9\u4e9b\u4fe1\u606f\u5982\u4f55\u4e0ePR\u3001\u63d0\u4ea4\u548c\u95ee\u9898\u5bf9\u9f50\u3002\u6784\u5efa\u5305\u542b3500\u4e2a\u8fc7\u6ee4\u548c\u9a8c\u8bc1\u7684\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\u5b9e\u4f8b\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002\u7136\u540e\u5b9e\u73b0\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u6765\u81ea\u52a8\u5efa\u7acb\u53d1\u5e03\u8bf4\u660e\u5185\u5bb9\u4e0ePR\u3001\u53d1\u5e03\u8bf4\u660e\u5185\u5bb9\u4e0ePR\u4ee5\u53ca\u53d1\u5e03\u8bf4\u660e\u5185\u5bb9\u4e0e\u95ee\u9898\u4e4b\u95f4\u7684\u4e09\u5bf9\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\u3002", "result": "\u901a\u8fc7\u7ed3\u5408\u65f6\u95f4\u90bb\u8fd1\u7279\u5f81\uff0c\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff08\u5982Gemini 1.5 Pro\uff09\u5728PR\u53ef\u8ffd\u6eaf\u6027\u6062\u590d\u65b9\u9762\u5b9e\u73b0\u4e860.73\u7684\u9ad8Precision@1\u503c\u3002\u5728\u7ebf\u8c03\u67e5\u663e\u793a\uff0c16%\u7684\u53d7\u8bbf\u8005\u8ba4\u4e3a\u8fd9\u79cd\u65b9\u6cd5\u975e\u5e38\u91cd\u8981\uff0c68%\u8ba4\u4e3a\u6709\u4e9b\u91cd\u8981\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u81ea\u52a8\u5efa\u7acb\u53d1\u5e03\u8bf4\u660e\u4e0e\u5f00\u53d1\u5de5\u4ef6\u4e4b\u95f4\u7684\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\uff0c\u5177\u6709\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u5f00\u6e90\u9879\u76ee\u7684\u53ef\u7ef4\u62a4\u6027\u3002"}}
{"id": "2511.17761", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17761", "abs": "https://arxiv.org/abs/2511.17761", "authors": ["Manuel Kern", "Dominik Steffan", "Felix Schuster", "Florian Skopik", "Max Landauer", "David Allison", "Simon Freudenthaler", "Edgar Weippl"], "title": "StealthCup: Realistic, Multi-Stage, Evasion-Focused CTF for Benchmarking IDS", "comment": null, "summary": "Intrusion Detection Systems (IDS) are critical to defending enterprise and industrial control environments, yet evaluating their effectiveness under realistic conditions remains an open challenge. Existing benchmarks rely on synthetic datasets (e.g., NSL-KDD, CICIDS2017) or scripted replay frameworks, which fail to capture adaptive adversary behavior. Even MITRE ATT&CK Evaluations, while influential, are host-centric and assume malware-driven compromise, thereby under-representing stealthy, multi-stage intrusions across IT and OT domains. We present StealthCup, a novel evaluation methodology that operationalizes IDS benchmarking as an evasion-focused Capture-the-Flag competition. Professional penetration testers engaged in multi-stage attack chains on a realistic IT/OT testbed, with scoring penalizing IDS detections. The event generated structured attacker writeups, validated detections, and PCAPs, host logs, and alerts. Our results reveal that out of 32 exercised attack techniques, 11 were not detected by any IDS configuration. Open-source systems (Wazuh, Suricata) produced high false-positive rates >90%, while commercial tools generated fewer false positives but also missed more attacks. Comparison with the Volt Typhoon APT advisory confirmed strong realism: all 28 applicable techniques were exercised, 19 appeared in writeups, and 9 in forensic traces. These findings demonstrate that StealthCup elicits attacker behavior closely aligned with state-sponsored TTPs, while exposing blind spots across both open-source and commercial IDS. The resulting datasets and methodology provide a reproducible foundation for future stealth-focused IDS evaluation.", "AI": {"tldr": "StealthCup\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u771f\u5b9e\u653b\u51fb\u573a\u666f\u7684\u593a\u65d7\u7ade\u8d5b\u6765\u6d4b\u8bd5IDS\u5728IT/OT\u73af\u5883\u4e2d\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u53d1\u73b0\u5f00\u6e90\u548c\u5546\u4e1aIDS\u90fd\u5b58\u5728\u91cd\u5927\u76f2\u70b9\u3002", "motivation": "\u73b0\u6709IDS\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u5408\u6210\u6570\u636e\u96c6\u6216\u811a\u672c\u91cd\u653e\uff0c\u65e0\u6cd5\u6355\u6349\u81ea\u9002\u5e94\u653b\u51fb\u884c\u4e3a\uff0cMITRE ATT&CK\u8bc4\u4f30\u4e5f\u504f\u5411\u4e3b\u673a\u4e2d\u5fc3\u4e14\u5047\u8bbe\u6076\u610f\u8f6f\u4ef6\u9a71\u52a8\uff0c\u672a\u80fd\u5145\u5206\u4ee3\u8868IT/OT\u9886\u57df\u7684\u9690\u853d\u591a\u9636\u6bb5\u5165\u4fb5\u3002", "method": "StealthCup\u5c06IDS\u57fa\u51c6\u6d4b\u8bd5\u64cd\u4f5c\u5316\u4e3a\u4ee5\u89c4\u907f\u4e3a\u4e2d\u5fc3\u7684\u593a\u65d7\u7ade\u8d5b\uff0c\u4e13\u4e1a\u6e17\u900f\u6d4b\u8bd5\u4eba\u5458\u5728\u771f\u5b9eIT/OT\u6d4b\u8bd5\u73af\u5883\u4e2d\u6267\u884c\u591a\u9636\u6bb5\u653b\u51fb\u94fe\uff0c\u8bc4\u5206\u60e9\u7f5aIDS\u68c0\u6d4b\u3002", "result": "\u572832\u4e2a\u653b\u51fb\u6280\u672f\u4e2d\uff0c11\u4e2a\u672a\u88ab\u4efb\u4f55IDS\u914d\u7f6e\u68c0\u6d4b\u5230\u3002\u5f00\u6e90\u7cfb\u7edf(Wazuh\u3001Suricata)\u4ea7\u751f>90%\u7684\u9ad8\u8bef\u62a5\u7387\uff0c\u5546\u4e1a\u5de5\u5177\u8bef\u62a5\u8f83\u5c11\u4f46\u9057\u6f0f\u66f4\u591a\u653b\u51fb\u3002\u4e0eVolt Typhoon APT\u54a8\u8be2\u6bd4\u8f83\u786e\u8ba4\u4e86\u5f3a\u771f\u5b9e\u6027\u3002", "conclusion": "StealthCup\u80fd\u591f\u5f15\u53d1\u4e0e\u56fd\u5bb6\u652f\u6301TTPs\u5bc6\u5207\u76f8\u5173\u7684\u653b\u51fb\u8005\u884c\u4e3a\uff0c\u540c\u65f6\u66b4\u9732\u5f00\u6e90\u548c\u5546\u4e1aIDS\u7684\u76f2\u70b9\uff0c\u4e3a\u672a\u6765\u4e13\u6ce8\u4e8e\u9690\u853d\u6027\u7684IDS\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7840\u3002"}}
{"id": "2511.17714", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.17714", "abs": "https://arxiv.org/abs/2511.17714", "authors": ["Alex John London", "Aydin Mohseni"], "title": "Learning the Value of Value Learning", "comment": "27 pages, 6 figures, mathematical appendix", "summary": "Standard decision frameworks addresses uncertainty about facts but assumes fixed values. We extend the Jeffrey-Bolker framework to model refinements in values and prove a value-of-information theorem for axiological refinement. In multi-agent settings, we establish that mutual refinement will characteristically transform zero-sum games into positive-sum interactions and yields Pareto-improving Nash bargains. These results show that a framework of rational choice can be extended to model value refinement and its associated benefits. By unifying epistemic and axiological refinement under a single formalism, we broaden the conceptual foundations of rational choice and illuminate the normative status of ethical deliberation.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Jeffrey-Bolker\u51b3\u7b56\u6846\u67b6\uff0c\u5c06\u4ef7\u503c\u7cbe\u70bc\u7eb3\u5165\u7406\u6027\u9009\u62e9\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u4ef7\u503c\u7cbe\u70bc\u7684\u4fe1\u606f\u4ef7\u503c\u5b9a\u7406\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u4ef7\u503c\u7cbe\u70bc\u5982\u4f55\u5c06\u96f6\u548c\u535a\u5f08\u8f6c\u5316\u4e3a\u6b63\u548c\u4e92\u52a8\u3002", "motivation": "\u4f20\u7edf\u51b3\u7b56\u6846\u67b6\u5904\u7406\u4e8b\u5b9e\u4e0d\u786e\u5b9a\u6027\u4f46\u5047\u8bbe\u56fa\u5b9a\u4ef7\u503c\uff0c\u672c\u6587\u65e8\u5728\u6269\u5c55\u7406\u6027\u9009\u62e9\u6846\u67b6\u4ee5\u5efa\u6a21\u4ef7\u503c\u7cbe\u70bc\u53ca\u5176\u76f8\u5173\u6536\u76ca\u3002", "method": "\u6269\u5c55Jeffrey-Bolker\u6846\u67b6\u6765\u5efa\u6a21\u4ef7\u503c\u7cbe\u70bc\uff0c\u8bc1\u660e\u4ef7\u503c\u7cbe\u70bc\u7684\u4fe1\u606f\u4ef7\u503c\u5b9a\u7406\uff0c\u5206\u6790\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u76f8\u4e92\u4ef7\u503c\u7cbe\u70bc\u6548\u5e94\u3002", "result": "\u8bc1\u660e\u4e86\u4ef7\u503c\u7cbe\u70bc\u7684\u4fe1\u606f\u4ef7\u503c\u5b9a\u7406\uff1b\u5728\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u4e2d\uff0c\u76f8\u4e92\u4ef7\u503c\u7cbe\u70bc\u80fd\u5c06\u96f6\u548c\u535a\u5f08\u8f6c\u5316\u4e3a\u6b63\u548c\u4e92\u52a8\uff0c\u5e76\u4ea7\u751f\u5e15\u7d2f\u6258\u6539\u8fdb\u7684\u7eb3\u4ec0\u8bae\u4ef7\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u5c06\u8ba4\u77e5\u548c\u4ef7\u503c\u7cbe\u70bc\u7edf\u4e00\u5728\u5355\u4e00\u5f62\u5f0f\u5316\u6846\u67b6\u4e0b\uff0c\u62d3\u5bbd\u4e86\u7406\u6027\u9009\u62e9\u7684\u6982\u5ff5\u57fa\u7840\uff0c\u9610\u660e\u4e86\u4f26\u7406\u5ba1\u8bae\u7684\u89c4\u8303\u5730\u4f4d\u3002"}}
{"id": "2511.17799", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17799", "abs": "https://arxiv.org/abs/2511.17799", "authors": ["Qiang Liu", "Wenlong Zhang", "Muhui Jiang", "Lei Wu", "Yajin Zhou"], "title": "Characteristics, Root Causes, and Detection of Incomplete Security Bug Fixes in the Linux Kernel", "comment": null, "summary": "Security bugs in the Linux kernel emerge endlessly and have attracted much attention. However, fixing security bugs in the Linux kernel could be incomplete due to human mistakes. Specifically, an incomplete fix fails to repair all the original security defects in the software, fails to properly repair the original security defects, or introduces new ones. In this paper, we study the fixes of incomplete security bugs in the Linux kernel for the first time, and reveal their characteristics, root causes, as well as detection. We first construct a dataset of incomplete security bug fixes in the Linux kernel and answer the following three questions. What are the characteristics of incomplete security bug fixes in the Linux kernel? What are the root causes behind them? How should they be detected to reduce security risks? We then have the three main insights in the following. (*Due to the notification of arXiv \"The Abstract field cannot be longer than 1,920 characters\", the appeared Abstract is shortened. For the full Abstract, please download the Article.)", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7814\u7a76Linux\u5185\u6838\u4e2d\u5b89\u5168\u6f0f\u6d1e\u4fee\u590d\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\uff0c\u5206\u6790\u4e86\u5176\u7279\u5f81\u3001\u6839\u672c\u539f\u56e0\u548c\u68c0\u6d4b\u65b9\u6cd5\u3002", "motivation": "Linux\u5185\u6838\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\u4e0d\u65ad\u51fa\u73b0\uff0c\u4f46\u4fee\u590d\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u5b58\u5728\u4eba\u4e3a\u9519\u8bef\u5bfc\u81f4\u4fee\u590d\u4e0d\u5b8c\u6574\uff0c\u8fd9\u4f1a\u7559\u4e0b\u539f\u59cb\u5b89\u5168\u7f3a\u9677\u6216\u5f15\u5165\u65b0\u95ee\u9898\u3002", "method": "\u6784\u5efaLinux\u5185\u6838\u4e2d\u4e0d\u5b8c\u6574\u5b89\u5168\u6f0f\u6d1e\u4fee\u590d\u7684\u6570\u636e\u96c6\uff0c\u5206\u6790\u5176\u7279\u5f81\u3001\u6839\u672c\u539f\u56e0\uff0c\u5e76\u7814\u7a76\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "\u83b7\u5f97\u4e86\u5173\u4e8e\u4e0d\u5b8c\u6574\u5b89\u5168\u6f0f\u6d1e\u4fee\u590d\u7684\u4e09\u4e2a\u4e3b\u8981\u89c1\u89e3\uff08\u7531\u4e8e\u6458\u8981\u957f\u5ea6\u9650\u5236\uff0c\u5b8c\u6574\u7ed3\u679c\u9700\u4e0b\u8f7d\u6587\u7ae0\u67e5\u770b\uff09\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86Linux\u5185\u6838\u4e2d\u5b89\u5168\u6f0f\u6d1e\u4fee\u590d\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\uff0c\u4e3a\u51cf\u5c11\u5b89\u5168\u98ce\u9669\u63d0\u4f9b\u4e86\u68c0\u6d4b\u65b9\u6cd5\u7684\u6307\u5bfc\u3002"}}
{"id": "2511.17729", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17729", "abs": "https://arxiv.org/abs/2511.17729", "authors": ["Yang Zhou", "Mingyu Zhao", "Zhenting Wang", "Difei Gu", "Bangwei Guo", "Ruosong Ye", "Ligong Han", "Can Jin", "Dimitris N. Metaxas"], "title": "M3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark", "comment": null, "summary": "We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resources across steps. We introduce a similarity-driven alignment that serializes each tool call, embeds signatures with a sentence encoder, and performs similarity-bucketed Hungarian matching to obtain auditable one-to-one correspondences. On top of this alignment, we report interpretable metrics that decouple semantic fidelity from workflow consistency. The benchmark spans 28 servers with 231 tools, and provides standardized trajectories curated through an Executor & Judge pipeline with human verification; an auxiliary four large language models (LLMs) judge ensemble reports end-task Task Completion and information grounding. Evaluations of representative state-of-the-art Multimodal LLMs (MLLMs) reveal persistent gaps in multimodal MCP tool use, particularly in argument fidelity and structure consistency, underscoring the need for methods that jointly reason over images, text, and tool graphs. Our Benchmark's anonymous repository is at https://github.com/EtaYang10th/Open-M3-Bench", "AI": {"tldr": "M^3-Bench\u662f\u9996\u4e2a\u5728\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u4e0b\u8bc4\u4f30\u591a\u6a21\u6001\u5de5\u5177\u4f7f\u7528\u7684\u57fa\u51c6\uff0c\u9488\u5bf9\u9700\u8981\u89c6\u89c9\u57fa\u7840\u548c\u6587\u672c\u63a8\u7406\u7684\u591a\u8df3\u591a\u7ebf\u7a0b\u5de5\u4f5c\u6d41\uff0c\u5305\u542b28\u4e2a\u670d\u52a1\u5668\u548c231\u4e2a\u5de5\u5177\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u8f68\u8ff9\u548c\u53ef\u89e3\u91ca\u6307\u6807\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u5bf9\u591a\u6a21\u6001\u5de5\u5177\u4f7f\u7528\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u89c6\u89c9\u57fa\u7840\u3001\u6587\u672c\u63a8\u7406\u3001\u8de8\u5de5\u5177\u4f9d\u8d56\u548c\u4e2d\u95f4\u8d44\u6e90\u6301\u4e45\u5316\u7684\u590d\u6742\u5de5\u4f5c\u6d41\u573a\u666f\u4e0b\u3002", "method": "\u5f15\u5165\u76f8\u4f3c\u6027\u9a71\u52a8\u7684\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5e8f\u5217\u5316\u5de5\u5177\u8c03\u7528\uff0c\u4f7f\u7528\u53e5\u5b50\u7f16\u7801\u5668\u5d4c\u5165\u7b7e\u540d\uff0c\u901a\u8fc7\u76f8\u4f3c\u6027\u5206\u6876\u7684\u5308\u7259\u5229\u5339\u914d\u83b7\u5f97\u53ef\u5ba1\u8ba1\u7684\u4e00\u5bf9\u4e00\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u5efa\u7acbExecutor & Judge\u6d41\u7a0b\u8fdb\u884c\u4eba\u5de5\u9a8c\u8bc1\u3002", "result": "\u5bf9\u4ee3\u8868\u6027\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u63ed\u793a\u4e86\u5728\u591a\u6a21\u6001MCP\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u5b58\u5728\u6301\u7eed\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u53c2\u6570\u4fdd\u771f\u5ea6\u548c\u7ed3\u6784\u4e00\u81f4\u6027\u65b9\u9762\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8054\u5408\u63a8\u7406\u56fe\u50cf\u3001\u6587\u672c\u548c\u5de5\u5177\u56fe\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u591a\u6a21\u6001\u5de5\u5177\u4f7f\u7528\u7684\u6027\u80fd\u3002"}}
{"id": "2511.17842", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17842", "abs": "https://arxiv.org/abs/2511.17842", "authors": ["Xavier Salleras"], "title": "Homomorphic Encryption-based Vaults for Anonymous Balances on VM-enabled Blockchains", "comment": null, "summary": "In this work, we present homomorphic encryption-based vaults (Haults), a permissioned privacy-preserving smart wallet protocol for VM-enabled blockchains that keeps users' balances confidential, as well as the amounts transacted to other parties. To comply with regulations, we include optional compliance features that allow specific entities (the auditors) to retrieve transaction amounts or execute force transfers when necessary. Our solution uses ElGamal over elliptic curves to encrypt balances, combined with zero-knowledge proofs to verify the correctness of transaction amounts and the integrity of the sender's updated balance, among other security checks. We provide a detailed explanation of the protocol, including a security discussion and benchmarks from our proof-of-concept implementation, which yield great results. Beyond in-contract issued tokens, we also provide a thorough explanation on how our solution can be compatible with external ones (e.g., Ether or any ERC20).", "AI": {"tldr": "Haults\u662f\u4e00\u79cd\u57fa\u4e8e\u540c\u6001\u52a0\u5bc6\u7684\u9690\u79c1\u4fdd\u62a4\u667a\u80fd\u94b1\u5305\u534f\u8bae\uff0c\u7528\u4e8eVM\u533a\u5757\u94fe\uff0c\u53ef\u4fdd\u62a4\u7528\u6237\u4f59\u989d\u548c\u4ea4\u6613\u91d1\u989d\u7684\u673a\u5bc6\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u9009\u5408\u89c4\u529f\u80fd\u3002", "motivation": "\u5728\u533a\u5757\u94fe\u4e0a\u4fdd\u62a4\u7528\u6237\u4f59\u989d\u548c\u4ea4\u6613\u91d1\u989d\u7684\u9690\u79c1\uff0c\u540c\u65f6\u6ee1\u8db3\u76d1\u7ba1\u5408\u89c4\u8981\u6c42\uff0c\u5141\u8bb8\u5ba1\u8ba1\u4eba\u5458\u5728\u5fc5\u8981\u65f6\u67e5\u770b\u4ea4\u6613\u6216\u6267\u884c\u5f3a\u5236\u8f6c\u8d26\u3002", "method": "\u4f7f\u7528\u692d\u5706\u66f2\u7ebf\u4e0a\u7684ElGamal\u52a0\u5bc6\u6765\u52a0\u5bc6\u4f59\u989d\uff0c\u7ed3\u5408\u96f6\u77e5\u8bc6\u8bc1\u660e\u9a8c\u8bc1\u4ea4\u6613\u91d1\u989d\u7684\u6b63\u786e\u6027\u548c\u53d1\u9001\u65b9\u66f4\u65b0\u4f59\u989d\u7684\u5b8c\u6574\u6027\u7b49\u5b89\u5168\u68c0\u67e5\u3002", "result": "\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u826f\u597d\uff0c\u534f\u8bae\u4e0d\u4ec5\u652f\u6301\u5408\u7ea6\u5185\u53d1\u884c\u7684\u4ee3\u5e01\uff0c\u8fd8\u80fd\u4e0e\u5916\u90e8\u4ee3\u5e01\uff08\u5982Ether\u6216ERC20\uff09\u517c\u5bb9\u3002", "conclusion": "Haults\u534f\u8bae\u6210\u529f\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u548c\u5408\u89c4\u8981\u6c42\u7684\u5e73\u8861\uff0c\u4e3a\u533a\u5757\u94fe\u4e0a\u7684\u9690\u79c1\u4ea4\u6613\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17743", "categories": ["cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17743", "abs": "https://arxiv.org/abs/2511.17743", "authors": ["Haytham Younus", "Sohag Kabir", "Felician Campean", "Pascal Bonnaud", "David Delaux"], "title": "AI- and Ontology-Based Enhancements to FMEA for Advanced Systems Engineering: Current Developments and Future Directions", "comment": "This manuscript is based on research undertaken by our doctoral student at the University of Bradford. The associated PhD thesis has been formally submitted to the University and is currently awaiting final examination. The review article is being shared on arXiv to make the review accessible to the research community while the thesis examination process is ongoing", "summary": "This article presents a state-of-the-art review of recent advances aimed at transforming traditional Failure Mode and Effects Analysis (FMEA) into a more intelligent, data-driven, and semantically enriched process. As engineered systems grow in complexity, conventional FMEA methods, largely manual, document-centric, and expert-dependent, have become increasingly inadequate for addressing the demands of modern systems engineering. We examine how techniques from Artificial Intelligence (AI), including machine learning and natural language processing, can transform FMEA into a more dynamic, data-driven, intelligent, and model-integrated process by automating failure prediction, prioritisation, and knowledge extraction from operational data. In parallel, we explore the role of ontologies in formalising system knowledge, supporting semantic reasoning, improving traceability, and enabling cross-domain interoperability. The review also synthesises emerging hybrid approaches, such as ontology-informed learning and large language model integration, which further enhance explainability and automation. These developments are discussed within the broader context of Model-Based Systems Engineering (MBSE) and function modelling, showing how AI and ontologies can support more adaptive and resilient FMEA workflows. We critically analyse a range of tools, case studies, and integration strategies, while identifying key challenges related to data quality, explainability, standardisation, and interdisciplinary adoption. By leveraging AI, systems engineering, and knowledge representation using ontologies, this review offers a structured roadmap for embedding FMEA within intelligent, knowledge-rich engineering environments.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5c06\u4f20\u7edf\u6545\u969c\u6a21\u5f0f\u4e0e\u5f71\u54cd\u5206\u6790(FMEA)\u8f6c\u53d8\u4e3a\u66f4\u667a\u80fd\u3001\u6570\u636e\u9a71\u52a8\u548c\u8bed\u4e49\u4e30\u5bcc\u8fc7\u7a0b\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u548c\u672c\u4f53\u8bba\u5728\u81ea\u52a8\u5316\u6545\u969c\u9884\u6d4b\u3001\u77e5\u8bc6\u63d0\u53d6\u548c\u8bed\u4e49\u63a8\u7406\u65b9\u9762\u7684\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u5de5\u7a0b\u7cfb\u7edf\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u4f20\u7edfFMEA\u65b9\u6cd5\uff08\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u3001\u6587\u6863\u4e2d\u5fc3\u548c\u4e13\u5bb6\uff09\u5df2\u65e0\u6cd5\u6ee1\u8db3\u73b0\u4ee3\u7cfb\u7edf\u5de5\u7a0b\u7684\u9700\u6c42\uff0c\u9700\u8981\u66f4\u667a\u80fd\u3001\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff08\u673a\u5668\u5b66\u4e60\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff09\u5b9e\u73b0\u6545\u969c\u9884\u6d4b\u81ea\u52a8\u5316\u548c\u77e5\u8bc6\u63d0\u53d6\uff0c\u540c\u65f6\u5229\u7528\u672c\u4f53\u8bba\u5f62\u5f0f\u5316\u7cfb\u7edf\u77e5\u8bc6\u3001\u652f\u6301\u8bed\u4e49\u63a8\u7406\u548c\u63d0\u9ad8\u53ef\u8ffd\u6eaf\u6027\uff0c\u5e76\u63a2\u7d22\u672c\u4f53\u901a\u77e5\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u7b49\u6df7\u5408\u65b9\u6cd5\u3002", "result": "\u5f00\u53d1\u51fa\u80fd\u591f\u652f\u6301\u66f4\u52a8\u6001\u3001\u6570\u636e\u9a71\u52a8\u548c\u6a21\u578b\u96c6\u6210\u7684FMEA\u6d41\u7a0b\uff0c\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u4e3a\u5728\u667a\u80fd\u3001\u77e5\u8bc6\u4e30\u5bcc\u7684\u5de5\u7a0b\u73af\u5883\u4e2d\u5d4c\u5165FMEA\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u8def\u7ebf\u56fe\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\u548c\u672c\u4f53\u8bba\u7684\u7ed3\u5408\u80fd\u591f\u663e\u8457\u63d0\u5347FMEA\u7684\u9002\u5e94\u6027\u3001\u5f39\u6027\u548c\u6548\u7387\uff0c\u4f46\u9762\u4e34\u6570\u636e\u8d28\u91cf\u3001\u53ef\u89e3\u91ca\u6027\u3001\u6807\u51c6\u5316\u548c\u8de8\u5b66\u79d1\u91c7\u7528\u7b49\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2511.18343", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18343", "abs": "https://arxiv.org/abs/2511.18343", "authors": ["Dongming Jin", "Zhi Jin", "Xiaohong Chen", "Zheng Fang", "Linyu Li", "Yuanpeng He", "Jia Li", "Yirang Zhang", "Yingtao Fang"], "title": "A Needle in a Haystack: Intent-driven Reusable Artifacts Recommendation with LLMs", "comment": "15 pages, 7 figures", "summary": "In open source software development, the reuse of existing artifacts has been widely adopted to avoid redundant implementation work. Reusable artifacts are considered more efficient and reliable than developing software components from scratch. However, when faced with a large number of reusable artifacts, developers often struggle to find artifacts that can meet their expected needs. To reduce this burden, retrieval-based and learning-based techniques have been proposed to automate artifact recommendations. Recently, Large Language Models (LLMs) have shown the potential to understand intentions, perform semantic alignment, and recommend usable artifacts. Nevertheless, their effectiveness has not been thoroughly explored. To fill this gap, we construct an intent-driven artifact recommendation benchmark named IntentRecBench, covering three representative open source ecosystems. Using IntentRecBench, we conduct a comprehensive comparative study of five popular LLMs and six traditional approaches in terms of precision and efficiency. Our results show that although LLMs outperform traditional methods, they still suffer from low precision and high inference cost due to the large candidate space. Inspired by the ontology-based semantic organization in software engineering, we propose TreeRec, a feature tree-guided recommendation framework to mitigate these issues. TreeRec leverages LLM-based semantic abstraction to organize artifacts into a hierarchical semantic tree, enabling intent and function alignment and reducing reasoning time. Extensive experiments demonstrate that TreeRec consistently improves the performance of diverse LLMs across ecosystems, highlighting its generalizability and potential for practical deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TreeRec\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u62bd\u8c61\u5c06\u8f6f\u4ef6\u6784\u4ef6\u7ec4\u7ec7\u6210\u5c42\u6b21\u5316\u8bed\u4e49\u6811\uff0c\u4ee5\u89e3\u51b3\u5f00\u6e90\u8f6f\u4ef6\u6784\u4ef6\u63a8\u8350\u4e2dLLMs\u7cbe\u5ea6\u4f4e\u548c\u63a8\u7406\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0c\u5f00\u53d1\u8005\u9762\u4e34\u5927\u91cf\u53ef\u590d\u7528\u6784\u4ef6\u65f6\u96be\u4ee5\u627e\u5230\u6ee1\u8db3\u9700\u6c42\u7684\u6784\u4ef6\uff0c\u73b0\u6709\u57fa\u4e8e\u68c0\u7d22\u548c\u5b66\u4e60\u7684\u6280\u672f\u5728\u63a8\u8350\u6548\u679c\u4e0a\u4ecd\u6709\u4e0d\u8db3\uff0cLLMs\u867d\u663e\u793a\u51fa\u6f5c\u529b\u4f46\u6548\u679c\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u6784\u5efaIntentRecBench\u57fa\u51c6\uff0c\u6bd4\u8f83LLMs\u4e0e\u4f20\u7edf\u65b9\u6cd5\uff1b\u63d0\u51faTreeRec\u6846\u67b6\uff0c\u5229\u7528LLM\u8bed\u4e49\u62bd\u8c61\u5c06\u6784\u4ef6\u7ec4\u7ec7\u6210\u5c42\u6b21\u5316\u8bed\u4e49\u6811\uff0c\u5b9e\u73b0\u610f\u56fe\u4e0e\u529f\u80fd\u5bf9\u9f50\u5e76\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLLMs\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u4f46\u4ecd\u6709\u7cbe\u5ea6\u4f4e\u548c\u63a8\u7406\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff1bTreeRec\u80fd\u6301\u7eed\u63d0\u5347\u4e0d\u540cLLMs\u5728\u5404\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\uff0c\u663e\u793a\u51fa\u826f\u597d\u7684\u6cdb\u5316\u6027\u548c\u5b9e\u9645\u90e8\u7f72\u6f5c\u529b\u3002", "conclusion": "TreeRec\u901a\u8fc7\u8bed\u4e49\u6811\u7ec4\u7ec7\u6709\u6548\u7f13\u89e3\u4e86LLMs\u5728\u6784\u4ef6\u63a8\u8350\u4e2d\u7684\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.17874", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17874", "abs": "https://arxiv.org/abs/2511.17874", "authors": ["Yunyi Zhang", "Shibo Cui", "Baojun Liu", "Jingkai Yu", "Min Zhang", "Fan Shi", "Han Zheng"], "title": "Beyond Jailbreak: Unveiling Risks in LLM Applications Arising from Blurred Capability Boundaries", "comment": "Accepted by Network and Distributed System Security (NDSS) Symposium 2026", "summary": "LLM applications (i.e., LLM apps) leverage the powerful capabilities of LLMs to provide users with customized services, revolutionizing traditional application development. While the increasing prevalence of LLM-powered applications provides users with unprecedented convenience, it also brings forth new security challenges. For such an emerging ecosystem, the security community lacks sufficient understanding of the LLM application ecosystem, especially regarding the capability boundaries of the applications themselves.\n  In this paper, we systematically analyzed the new development paradigm and defined the concept of the LLM app capability space. We also uncovered potential new risks beyond jailbreak that arise from ambiguous capability boundaries in real-world scenarios, namely, capability downgrade and upgrade. To evaluate the impact of these risks, we designed and implemented an LLM app capability evaluation framework, LLMApp-Eval. First, we collected application metadata across 4 platforms and conducted a cross-platform ecosystem analysis. Then, we evaluated the risks for 199 popular applications among 4 platforms and 6 open-source LLMs. We identified that 178 (89.45%) potentially affected applications, which can perform tasks from more than 15 scenarios or be malicious. We even found 17 applications in our study that executed malicious tasks directly, without applying any adversarial rewriting. Furthermore, our experiments also reveal a positive correlation between the quality of prompt design and application robustness. We found that well-designed prompts enhance security, while poorly designed ones can facilitate abuse. We hope our work inspires the community to focus on the real-world risks of LLM applications and foster the development of a more robust LLM application ecosystem.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86LLM\u5e94\u7528\u751f\u6001\u7cfb\u7edf\uff0c\u5b9a\u4e49\u4e86LLM\u5e94\u7528\u80fd\u529b\u7a7a\u95f4\u6982\u5ff5\uff0c\u63ed\u793a\u4e86\u80fd\u529b\u8fb9\u754c\u6a21\u7cca\u5e26\u6765\u7684\u65b0\u98ce\u9669\uff08\u80fd\u529b\u964d\u7ea7\u548c\u5347\u7ea7\uff09\uff0c\u5e76\u5f00\u53d1\u4e86\u8bc4\u4f30\u6846\u67b6LLMApp-Eval\u6765\u8bc4\u4f30\u8fd9\u4e9b\u98ce\u9669\u3002", "motivation": "\u968f\u7740LLM\u5e94\u7528\u7684\u666e\u53ca\uff0c\u867d\u7136\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u4fbf\u5229\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u6311\u6218\u3002\u5b89\u5168\u793e\u533a\u5bf9LLM\u5e94\u7528\u751f\u6001\u7cfb\u7edf\u7f3a\u4e4f\u8db3\u591f\u4e86\u89e3\uff0c\u7279\u522b\u662f\u5173\u4e8e\u5e94\u7528\u81ea\u8eab\u80fd\u529b\u8fb9\u754c\u7684\u8ba4\u77e5\u4e0d\u8db3\u3002", "method": "\u8bbe\u8ba1\u4e86LLM\u5e94\u7528\u80fd\u529b\u8bc4\u4f30\u6846\u67b6LLMApp-Eval\uff0c\u6536\u96c6\u4e864\u4e2a\u5e73\u53f0\u7684\u5e94\u7528\u7a0b\u5e8f\u5143\u6570\u636e\u5e76\u8fdb\u884c\u8de8\u5e73\u53f0\u751f\u6001\u7cfb\u7edf\u5206\u6790\uff0c\u8bc4\u4f30\u4e86199\u4e2a\u6d41\u884c\u5e94\u7528\u548c6\u4e2a\u5f00\u6e90LLM\u7684\u98ce\u9669\u3002", "result": "\u53d1\u73b0178\u4e2a\uff0889.45%\uff09\u5e94\u7528\u53ef\u80fd\u53d7\u5230\u5f71\u54cd\uff0c\u80fd\u591f\u6267\u884c\u8d85\u8fc715\u79cd\u573a\u666f\u7684\u4efb\u52a1\u6216\u6076\u610f\u884c\u4e3a\uff0c\u751a\u81f3\u53d1\u73b017\u4e2a\u5e94\u7528\u76f4\u63a5\u6267\u884c\u6076\u610f\u4efb\u52a1\u3002\u5b9e\u9a8c\u8fd8\u663e\u793a\u63d0\u793a\u8bbe\u8ba1\u8d28\u91cf\u4e0e\u5e94\u7528\u7a0b\u5e8f\u9c81\u68d2\u6027\u5448\u6b63\u76f8\u5173\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u53ef\u4ee5\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u800c\u8bbe\u8ba1\u4e0d\u826f\u7684\u63d0\u793a\u53ef\u80fd\u4fc3\u8fdb\u6ee5\u7528\u3002\u5e0c\u671b\u8fd9\u9879\u5de5\u4f5c\u80fd\u6fc0\u53d1\u793e\u533a\u5173\u6ce8LLM\u5e94\u7528\u7684\u5b9e\u9645\u98ce\u9669\uff0c\u4fc3\u8fdb\u66f4\u5065\u58ee\u7684LLM\u5e94\u7528\u751f\u6001\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2511.18488", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18488", "abs": "https://arxiv.org/abs/2511.18488", "authors": ["Samuel Ackerman", "Wesam Ibraheem", "Orna Raz", "Marcel Zalmanovici"], "title": "Evaluating perturbation robustnessof generative systems that use COBOL code inputs", "comment": "16 pages (8 main, 8 appendix). Accepted to AI-SQE (ICSE, 2026): The 1st International Workshop on AI for Software Quality Evaluation: Judgment, Metrics, Benchmarks, and Beyond", "summary": "Systems incorporating large language models (LLMs) as a component are known to be sensitive (i.e., non-robust) to minor input variations that do not change the meaning of the input; such sensitivity may reduce the system's usefulness. Here, we present a framework to evaluate robustness of systems using COBOL code as input; our application is translation between COBOL and Java programming languages, but the approach extends to other tasks such as code generation or explanation. Targeting robustness of systems with COBOL as input is essential yet challenging. Many business-critical applications are written in COBOL, yet these are typically proprietary legacy applications and their code is unavailable to LLMs for training. We develop a library of COBOL paragraph and full-program perturbation methods, and create variant-expanded versions of a benchmark dataset of examples for a specific task. The robustness of the LLM-based system is evaluated by measuring changes in values of individual and aggregate metrics calculated on the system's outputs. Finally, we present a series of dynamic table and chart visualization dashboards that assist in debugging the system's outputs, and monitoring and understanding root causes of the system's sensitivity to input variation. These tools can be further used to improve the system by, for instance, indicating variations that should be handled by pre-processing steps.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u57fa\u4e8eLLM\u7684COBOL\u4ee3\u7801\u5904\u7406\u7cfb\u7edf\u9c81\u68d2\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u5efaCOBOL\u4ee3\u7801\u53d8\u4f53\u6765\u6d4b\u8bd5\u7cfb\u7edf\u5bf9\u5fae\u5c0f\u8f93\u5165\u53d8\u5316\u7684\u654f\u611f\u6027\uff0c\u5e76\u63d0\u4f9b\u53ef\u89c6\u5316\u5de5\u5177\u6765\u8c03\u8bd5\u548c\u6539\u8fdb\u7cfb\u7edf\u3002", "motivation": "\u57fa\u4e8eLLM\u7684\u7cfb\u7edf\u5bf9\u4e0d\u5f71\u54cd\u8bed\u4e49\u7684\u5fae\u5c0f\u8f93\u5165\u53d8\u5316\u5f88\u654f\u611f\uff0c\u8fd9\u4f1a\u964d\u4f4e\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\u3002\u7531\u4e8eCOBOL\u4e1a\u52a1\u5173\u952e\u5e94\u7528\u7684\u4ee3\u7801\u901a\u5e38\u65e0\u6cd5\u7528\u4e8eLLM\u8bad\u7ec3\uff0c\u8bc4\u4f30\u5176\u9c81\u68d2\u6027\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u5f00\u53d1\u4e86COBOL\u6bb5\u843d\u548c\u5b8c\u6574\u7a0b\u5e8f\u7684\u6270\u52a8\u65b9\u6cd5\u5e93\uff0c\u521b\u5efa\u57fa\u51c6\u6570\u636e\u96c6\u7684\u53d8\u4f53\u6269\u5c55\u7248\u672c\uff0c\u901a\u8fc7\u8ba1\u7b97\u7cfb\u7edf\u8f93\u51fa\u6307\u6807\u7684\u53d8\u5316\u6765\u8bc4\u4f30\u9c81\u68d2\u6027\uff0c\u5e76\u63d0\u4f9b\u52a8\u6001\u53ef\u89c6\u5316\u4eea\u8868\u677f\u8fdb\u884c\u8c03\u8bd5\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u7cfb\u7edf\u5730\u6d4b\u8bd5LLM\u7cfb\u7edf\u5bf9COBOL\u4ee3\u7801\u5fae\u5c0f\u53d8\u5316\u7684\u654f\u611f\u6027\uff0c\u5e76\u63d0\u4f9b\u5de5\u5177\u5e2e\u52a9\u8bc6\u522b\u548c\u5904\u7406\u654f\u611f\u6027\u95ee\u9898\u3002", "conclusion": "\u8be5\u6846\u67b6\u5bf9\u4e8e\u63d0\u9ad8\u57fa\u4e8eLLM\u7684COBOL\u4ee3\u7801\u5904\u7406\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u81f3\u5173\u91cd\u8981\uff0c\u53ef\u89c6\u5316\u5de5\u5177\u80fd\u591f\u5e2e\u52a9\u8c03\u8bd5\u7cfb\u7edf\u8f93\u51fa\u5e76\u7406\u89e3\u654f\u611f\u6027\u7684\u6839\u672c\u539f\u56e0\uff0c\u4ece\u800c\u6539\u8fdb\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2511.17855", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17855", "abs": "https://arxiv.org/abs/2511.17855", "authors": ["Jordan Abi Nader", "David Lee", "Nathaniel Dennler", "Andreea Bobu"], "title": "QuickLAP: Quick Language-Action Preference Learning for Autonomous Driving Agents", "comment": null, "summary": "Robots must learn from both what people do and what they say, but either modality alone is often incomplete: physical corrections are grounded but ambiguous in intent, while language expresses high-level goals but lacks physical grounding. We introduce QuickLAP: Quick Language-Action Preference learning, a Bayesian framework that fuses physical and language feedback to infer reward functions in real time. Our key insight is to treat language as a probabilistic observation over the user's latent preferences, clarifying which reward features matter and how physical corrections should be interpreted. QuickLAP uses Large Language Models (LLMs) to extract reward feature attention masks and preference shifts from free-form utterances, which it integrates with physical feedback in a closed-form update rule. This enables fast, real-time, and robust reward learning that handles ambiguous feedback. In a semi-autonomous driving simulator, QuickLAP reduces reward learning error by over 70% compared to physical-only and heuristic multimodal baselines. A 15-participant user study further validates our approach: participants found QuickLAP significantly more understandable and collaborative, and preferred its learned behavior over baselines. Code is available at https://github.com/MIT-CLEAR-Lab/QuickLAP.", "AI": {"tldr": "QuickLAP\u662f\u4e00\u4e2a\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u878d\u5408\u7269\u7406\u548c\u8bed\u8a00\u53cd\u9988\u6765\u5b9e\u65f6\u63a8\u65ad\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7LLM\u63d0\u53d6\u5956\u52b1\u7279\u5f81\u6ce8\u610f\u529b\u63a9\u7801\u548c\u504f\u597d\u53d8\u5316\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u6a21\u62df\u5668\u4e2d\u6bd4\u4ec5\u7269\u7406\u548c\u542f\u53d1\u5f0f\u591a\u6a21\u6001\u57fa\u7ebf\u51cf\u5c1170%\u4ee5\u4e0a\u7684\u5956\u52b1\u5b66\u4e60\u8bef\u5dee\u3002", "motivation": "\u673a\u5668\u4eba\u9700\u8981\u4ece\u4eba\u7c7b\u7684\u884c\u4e3a\u548c\u8bed\u8a00\u4e2d\u5b66\u4e60\uff0c\u4f46\u5355\u4e00\u6a21\u6001\u5f80\u5f80\u4e0d\u5b8c\u6574\uff1a\u7269\u7406\u4fee\u6b63\u6709\u57fa\u7840\u4f46\u610f\u56fe\u6a21\u7cca\uff0c\u8bed\u8a00\u8868\u8fbe\u9ad8\u7ea7\u76ee\u6807\u4f46\u7f3a\u4e4f\u7269\u7406\u57fa\u7840\u3002", "method": "\u5c06\u8bed\u8a00\u89c6\u4e3a\u5bf9\u7528\u6237\u6f5c\u5728\u504f\u597d\u7684\u6982\u7387\u89c2\u5bdf\uff0c\u4f7f\u7528LLM\u4ece\u81ea\u7531\u5f62\u5f0f\u8bdd\u8bed\u4e2d\u63d0\u53d6\u5956\u52b1\u7279\u5f81\u6ce8\u610f\u529b\u63a9\u7801\u548c\u504f\u597d\u53d8\u5316\uff0c\u901a\u8fc7\u95ed\u5f0f\u66f4\u65b0\u89c4\u5219\u4e0e\u7269\u7406\u53cd\u9988\u96c6\u6210\u3002", "result": "\u5728\u534a\u81ea\u52a8\u9a7e\u9a76\u6a21\u62df\u5668\u4e2d\uff0cQuickLAP\u6bd4\u4ec5\u7269\u7406\u548c\u542f\u53d1\u5f0f\u591a\u6a21\u6001\u57fa\u7ebf\u51cf\u5c1170%\u4ee5\u4e0a\u7684\u5956\u52b1\u5b66\u4e60\u8bef\u5dee\u300215\u4eba\u7528\u6237\u7814\u7a76\u663e\u793a\u53c2\u4e0e\u8005\u8ba4\u4e3aQuickLAP\u66f4\u6613\u7406\u89e3\u548c\u534f\u4f5c\uff0c\u5e76\u66f4\u504f\u597d\u5176\u5b66\u4e60\u884c\u4e3a\u3002", "conclusion": "QuickLAP\u5b9e\u73b0\u4e86\u5feb\u901f\u3001\u5b9e\u65f6\u3001\u9c81\u68d2\u7684\u5956\u52b1\u5b66\u4e60\uff0c\u80fd\u5904\u7406\u6a21\u7cca\u53cd\u9988\uff0c\u901a\u8fc7\u878d\u5408\u7269\u7406\u548c\u8bed\u8a00\u53cd\u9988\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u5b66\u4e60\u6548\u679c\u3002"}}
{"id": "2511.18506", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18506", "abs": "https://arxiv.org/abs/2511.18506", "authors": ["Michael Adjei Osei", "Sidney Shapiro"], "title": "HQPEF-Py: Metrics, Python Patterns, and Guidance for Evaluating Hybrid Quantum Programs", "comment": "17 pages", "summary": "We study how to evaluate hybrid quantum programs as end-to-end workflows rather than as isolated devices or algorithms. Building on the Hybrid Quantum Program Evaluation Framework (HQPEF), we formalize a workflow-aware Quantum Readiness Level (QRL) score; define a normalized speedup under quality constraints for the Utility of Quantumness (UQ); and provide a timing-and-drift audit for hybrid pipelines. We complement these definitions with concise Python reference implementations that illustrate how to instantiate the metrics and audit procedures with state-of-the-art classical and quantum solvers (e.g., via Qiskit or PennyLane), while preserving matched-budget discipline and reproducibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u4f5c\u4e3a\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\u7684\u6846\u67b6\uff0c\u5305\u62ec\u91cf\u5b50\u51c6\u5907\u5ea6\u8bc4\u5206\u3001\u91cf\u5b50\u6548\u7528\u6807\u51c6\u5316\u52a0\u901f\u4ee5\u53ca\u6df7\u5408\u7ba1\u9053\u7684\u65f6\u5e8f\u6f02\u79fb\u5ba1\u8ba1\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b64\u7acb\u7684\u91cf\u5b50\u8bbe\u5907\u6216\u7b97\u6cd5\uff0c\u7f3a\u4e4f\u5bf9\u6574\u4e2a\u6df7\u5408\u91cf\u5b50\u5de5\u4f5c\u6d41\u7684\u7aef\u5230\u7aef\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u8bc4\u4f30\u6846\u67b6(HQPEF)\uff0c\u5f62\u5f0f\u5316\u5de5\u4f5c\u6d41\u611f\u77e5\u7684\u91cf\u5b50\u51c6\u5907\u5ea6\u8bc4\u5206(QRL)\uff0c\u5b9a\u4e49\u8d28\u91cf\u7ea6\u675f\u4e0b\u7684\u6807\u51c6\u5316\u52a0\u901f\u4f5c\u4e3a\u91cf\u5b50\u6548\u7528(UQ)\uff0c\u5e76\u63d0\u4f9b\u6df7\u5408\u7ba1\u9053\u7684\u65f6\u5e8f\u6f02\u79fb\u5ba1\u8ba1\u3002", "result": "\u5f00\u53d1\u4e86\u7b80\u6d01\u7684Python\u53c2\u8003\u5b9e\u73b0\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u7ecf\u5178\u548c\u91cf\u5b50\u6c42\u89e3\u5668\u5b9e\u4f8b\u5316\u8fd9\u4e9b\u6307\u6807\u548c\u5ba1\u8ba1\u7a0b\u5e8f\uff0c\u540c\u65f6\u4fdd\u6301\u5339\u914d\u9884\u7b97\u7ea6\u675f\u548c\u53ef\u91cd\u590d\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u7684\u7aef\u5230\u7aef\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u66f4\u5168\u9762\u5730\u7406\u89e3\u91cf\u5b50\u8ba1\u7b97\u5728\u5b9e\u9645\u5de5\u4f5c\u6d41\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2511.17982", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17982", "abs": "https://arxiv.org/abs/2511.17982", "authors": ["Jiayi Luo", "Qingyun Sun", "Lingjuan Lyu", "Ziwei Zhang", "Haonan Yuan", "Xingcheng Fu", "Jianxin Li"], "title": "Towards Effective, Stealthy, and Persistent Backdoor Attacks Targeting Graph Foundation Models", "comment": "Accepted by AAAI 2026", "summary": "Graph Foundation Models (GFMs) are pre-trained on diverse source domains and adapted to unseen targets, enabling broad generalization for graph machine learning. Despite that GFMs have attracted considerable attention recently, their vulnerability to backdoor attacks remains largely underexplored. A compromised GFM can introduce backdoor behaviors into downstream applications, posing serious security risks. However, launching backdoor attacks against GFMs is non-trivial due to three key challenges. (1) Effectiveness: Attackers lack knowledge of the downstream task during pre-training, complicating the assurance that triggers reliably induce misclassifications into desired classes. (2) Stealthiness: The variability in node features across domains complicates trigger insertion that remains stealthy. (3) Persistence: Downstream fine-tuning may erase backdoor behaviors by updating model parameters. To address these challenges, we propose GFM-BA, a novel Backdoor Attack model against Graph Foundation Models. Specifically, we first design a label-free trigger association module that links the trigger to a set of prototype embeddings, eliminating the need for knowledge about downstream tasks to perform backdoor injection. Then, we introduce a node-adaptive trigger generator, dynamically producing node-specific triggers, reducing the risk of trigger detection while reliably activating the backdoor. Lastly, we develop a persistent backdoor anchoring module that firmly anchors the backdoor to fine-tuning-insensitive parameters, enhancing the persistence of the backdoor under downstream adaptation. Extensive experiments demonstrate the effectiveness, stealthiness, and persistence of GFM-BA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGFM-BA\uff0c\u4e00\u79cd\u9488\u5bf9\u56fe\u57fa\u7840\u6a21\u578b\u7684\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u5728\u7f3a\u4e4f\u4e0b\u6e38\u4efb\u52a1\u77e5\u8bc6\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6709\u6548\u3001\u9690\u853d\u4e14\u6301\u4e45\u7684\u540e\u95e8\u653b\u51fb\u7684\u4e09\u5927\u6311\u6218\u3002", "motivation": "\u56fe\u57fa\u7840\u6a21\u578b(GFMs)\u5728\u5e7f\u6cdb\u56fe\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4f46\u5176\u540e\u95e8\u653b\u51fb\u8106\u5f31\u6027\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u88ab\u7be1\u6539\u7684GFM\u53ef\u80fd\u5c06\u540e\u95e8\u884c\u4e3a\u5f15\u5165\u4e0b\u6e38\u5e94\u7528\uff0c\u9020\u6210\u4e25\u91cd\u5b89\u5168\u98ce\u9669\u3002", "method": "\u63d0\u51faGFM-BA\u6a21\u578b\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u65e0\u6807\u7b7e\u89e6\u53d1\u5668\u5173\u8054\u6a21\u5757\u5c06\u89e6\u53d1\u5668\u4e0e\u539f\u578b\u5d4c\u5165\u5173\u8054\uff1b\u8282\u70b9\u81ea\u9002\u5e94\u89e6\u53d1\u5668\u751f\u6210\u5668\u52a8\u6001\u751f\u6210\u8282\u70b9\u7279\u5b9a\u89e6\u53d1\u5668\uff1b\u6301\u4e45\u540e\u95e8\u951a\u5b9a\u6a21\u5757\u5c06\u540e\u95e8\u951a\u5b9a\u5728\u5fae\u8c03\u4e0d\u654f\u611f\u53c2\u6570\u4e0a\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660eGFM-BA\u5728\u6709\u6548\u6027\u3001\u9690\u853d\u6027\u548c\u6301\u4e45\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u6210\u529f\u5b9e\u65bd\u5bf9\u56fe\u57fa\u7840\u6a21\u578b\u7684\u540e\u95e8\u653b\u51fb\u3002", "conclusion": "GFM-BA\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u57fa\u7840\u6a21\u578b\u540e\u95e8\u653b\u51fb\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3aGFM\u5b89\u5168\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u63ed\u793a\u4e86\u6b64\u7c7b\u6a21\u578b\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6f5c\u5728\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2511.17876", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17876", "abs": "https://arxiv.org/abs/2511.17876", "authors": ["Mukul Singh", "Ananya Singha", "Aishni Parab", "Pronita Mehrotra", "Sumit Gulwani"], "title": "Training Emergent Joint Associations: A Reinforcement Learning Approach to Creative Thinking in Language Models", "comment": null, "summary": "Associative thinking--the ability to connect seemingly unrelated ideas--is a foundational element of human creativity and problem-solving. This paper explores whether reinforcement learning (RL) guided by associative thinking principles can enhance a model's performance across diverse generative tasks, including story writing, code generation, and chart creation. We introduce a reinforcement learning framework that uses a prompt-based evaluation mechanism, incorporating established divergent thinking metrics from creativity research. A base language model is fine-tuned using this framework to reward outputs demonstrating higher novelty through higher degrees of conceptual connectivity. Interestingly, the experimental results suggest that RL-based associative thinking-trained models not only generate more original and coherent stories but also exhibit improved abstraction and flexibility in tasks such as programming and data visualization. Our findings provide initial evidence that modeling cognitive creativity principles through reinforcement learning can yield more adaptive and generative AI.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u8054\u60f3\u601d\u7ef4\u539f\u5219\u6765\u63d0\u5347\u6a21\u578b\u5728\u6545\u4e8b\u5199\u4f5c\u3001\u4ee3\u7801\u751f\u6210\u548c\u56fe\u8868\u521b\u5efa\u7b49\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u7ecf\u8fc7\u8054\u60f3\u601d\u7ef4\u8bad\u7ec3\u7684\u6a21\u578b\u80fd\u4ea7\u751f\u66f4\u539f\u521b\u3001\u8fde\u8d2f\u7684\u5185\u5bb9\uff0c\u5e76\u5728\u7f16\u7a0b\u548c\u6570\u636e\u53ef\u89c6\u5316\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u62bd\u8c61\u80fd\u529b\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u8054\u60f3\u601d\u7ef4\u662f\u4eba\u7c7b\u521b\u9020\u529b\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u7684\u57fa\u7840\u8981\u7d20\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u57fa\u4e8e\u8054\u60f3\u601d\u7ef4\u539f\u5219\u7684\u5f3a\u5316\u5b66\u4e60\u662f\u5426\u80fd\u589e\u5f3a\u6a21\u578b\u5728\u591a\u6837\u5316\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4ece\u800c\u5f00\u53d1\u66f4\u5177\u9002\u5e94\u6027\u548c\u751f\u6210\u80fd\u529b\u7684\u4eba\u5de5\u667a\u80fd\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8e\u63d0\u793a\u7684\u8bc4\u4f30\u673a\u5236\uff0c\u6574\u5408\u521b\u9020\u529b\u7814\u7a76\u4e2d\u5df2\u786e\u7acb\u7684\u53d1\u6563\u601d\u7ef4\u6307\u6807\u3002\u901a\u8fc7\u8be5\u6846\u67b6\u5bf9\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5956\u52b1\u5c55\u73b0\u66f4\u9ad8\u6982\u5ff5\u8fde\u63a5\u5ea6\u4ece\u800c\u5177\u6709\u66f4\u9ad8\u65b0\u9896\u6027\u7684\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u8054\u60f3\u601d\u7ef4\u8bad\u7ec3\u6a21\u578b\u4e0d\u4ec5\u80fd\u751f\u6210\u66f4\u539f\u521b\u548c\u8fde\u8d2f\u7684\u6545\u4e8b\uff0c\u8fd8\u5728\u7f16\u7a0b\u548c\u6570\u636e\u53ef\u89c6\u5316\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6539\u8fdb\u7684\u62bd\u8c61\u80fd\u529b\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u7814\u7a76\u521d\u6b65\u8bc1\u660e\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5efa\u6a21\u8ba4\u77e5\u521b\u9020\u529b\u539f\u5219\u53ef\u4ee5\u4ea7\u751f\u66f4\u5177\u9002\u5e94\u6027\u548c\u751f\u6210\u80fd\u529b\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2511.18025", "categories": ["cs.CR", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18025", "abs": "https://arxiv.org/abs/2511.18025", "authors": ["Yifan Luo", "Meng Zhang", "Jin Xu", "Junting Chen", "Jianwei Huang"], "title": "Correlated-Sequence Differential Privacy", "comment": "11 pages, 5 figures. Published in 2025 34th International Conference on Computer Communications and Networks (ICCCN), IEEE, August 2025", "summary": "Data streams collected from multiple sources are rarely independent. Values evolve over time and influence one another across sequences. These correlations improve prediction in healthcare, finance, and smart-city control yet violate the record-independence assumption built into most Differential Privacy (DP) mechanisms. To restore rigorous privacy guarantees without sacrificing utility, we introduce Correlated-Sequence Differential Privacy (CSDP), a framework specifically designed for preserving privacy in correlated sequential data. CSDP addresses two linked challenges: quantifying the extra information an attacker gains from joint temporal and cross-sequence links, and adding just enough noise to hide that information while keeping the data useful. We model multivariate streams as a Coupling Markov Chain, yielding the derived loose leakage bound expressed with a few spectral terms and revealing a counterintuitive result: stronger coupling can actually decrease worst-case leakage by dispersing perturbations across sequences. Guided by these bounds, we build the Freshness-Regulated Adaptive Noise (FRAN) mechanism--combining data aging, correlation-aware sensitivity scaling, and Laplace noise--that runs in linear time. Tests on two-sequence datasets show that CSDP improves the privacy-utility trade-off by approximately 50% over existing correlated-DP methods and by two orders of magnitude compared to the standard DP approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86CSDP\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u4fdd\u62a4\u76f8\u5173\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u9690\u79c1\uff0c\u901a\u8fc7\u5efa\u6a21\u591a\u53d8\u91cf\u6d41\u4e3a\u8026\u5408\u9a6c\u5c14\u53ef\u592b\u94fe\uff0c\u5f00\u53d1\u4e86FRAN\u673a\u5236\uff0c\u5728\u76f8\u5173\u6570\u636e\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534750%\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002", "motivation": "\u591a\u6e90\u6570\u636e\u6d41\u901a\u5e38\u5b58\u5728\u65f6\u95f4\u6f14\u5316\u548c\u8de8\u5e8f\u5217\u5f71\u54cd\u7684\u76f8\u5173\u6027\uff0c\u8fd9\u8fdd\u53cd\u4e86\u5927\u591a\u6570\u5dee\u5206\u9690\u79c1\u673a\u5236\u57fa\u4e8e\u7684\u8bb0\u5f55\u72ec\u7acb\u6027\u5047\u8bbe\uff0c\u9700\u8981\u4e13\u95e8\u8bbe\u8ba1\u6765\u5728\u4fdd\u6301\u6570\u636e\u6548\u7528\u7684\u540c\u65f6\u6062\u590d\u4e25\u683c\u7684\u9690\u79c1\u4fdd\u8bc1\u3002", "method": "\u5f15\u5165\u76f8\u5173\u5e8f\u5217\u5dee\u5206\u9690\u79c1(CSDP)\u6846\u67b6\uff0c\u5c06\u591a\u53d8\u91cf\u6d41\u5efa\u6a21\u4e3a\u8026\u5408\u9a6c\u5c14\u53ef\u592b\u94fe\uff0c\u63a8\u5bfc\u51fa\u677e\u6563\u6cc4\u6f0f\u754c\u9650\uff0c\u5e76\u6784\u5efa\u7ed3\u5408\u6570\u636e\u8001\u5316\u3001\u76f8\u5173\u6027\u611f\u77e5\u7075\u654f\u5ea6\u7f29\u653e\u548c\u62c9\u666e\u62c9\u65af\u566a\u58f0\u7684FRAN\u673a\u5236\u3002", "result": "\u5728\u4e24\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5\u663e\u793a\uff0cCSDP\u6bd4\u73b0\u6709\u76f8\u5173DP\u65b9\u6cd5\u6539\u5584\u4e86\u7ea650%\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\uff0c\u6bd4\u6807\u51c6DP\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "CSDP\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u76f8\u5173\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u66f4\u5f3a\u7684\u8026\u5408\u5b9e\u9645\u4e0a\u53ef\u4ee5\u901a\u8fc7\u5206\u6563\u6270\u52a8\u6765\u51cf\u5c11\u6700\u574f\u60c5\u51b5\u6cc4\u6f0f\uff0c\u4e3a\u76f8\u5173\u6570\u636e\u6d41\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\u3002"}}
{"id": "2511.18045", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.18045", "abs": "https://arxiv.org/abs/2511.18045", "authors": ["Shreyansh Swami", "Ishwardeep Singh", "Chinmay Prawah Pant"], "title": "SCI-IoT: A Quantitative Framework for Trust Scoring and Certification of IoT Devices", "comment": "14 pages, 4 figures, 15 tables", "summary": "The exponential growth of the Internet of Things (IoT) ecosystem has amplified concerns regarding device reliability, interoperability, and security assurance. Despite the proliferation of IoT security guidelines, a unified and quantitative approach to measuring trust remains absent. This paper introduces SCI-IoT (Secure Certification Index for IoT), a standardized and quantitative framework for trust scoring, evaluation, and certification of IoT devices.\n  The framework employs a six-tier grading model (Grades A-F), enabling device profiling across consumer, industrial, and critical infrastructure domains. Within this model, 30 distinct Trust Tests assess devices across dimensions such as authentication, encryption, data integrity, resilience, and firmware security. Each test is assigned a criticality-based weight (1.0-2.0) and a performance rating (1-4), converted to a normalized percentage and aggregated through a weighted computation to yield the Secure Certification Index (SCI). The SCI determines the device's Trust Verdict, categorized into five SCI levels, and serves as the foundation for optional grade-based certification. The framework also incorporates critical gate conditions, enforcing absolute compliance in high risk parameters to prevent certification of devices with fundamental vulnerabilities. By unifying quantitative trust scoring with structured certification criteria, SCI-IoT provides a transparent, scalable, and reproducible method to benchmark IoT device trustworthiness. The proposed system aims to streamline manufacturer compliance, improve consumer confidence, and facilitate global interoperability in IoT security certification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SCI-IoT\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u5b9a\u91cf\u4fe1\u4efb\u8bc4\u5206\u3001\u8bc4\u4f30\u548c\u8ba4\u8bc1\u7cfb\u7edf\uff0c\u7528\u4e8e\u8bc4\u4f30\u7269\u8054\u7f51\u8bbe\u5907\u7684\u4fe1\u4efb\u5ea6\u3002", "motivation": "\u7269\u8054\u7f51\u751f\u6001\u7cfb\u7edf\u7684\u6307\u6570\u7ea7\u589e\u957f\u5f15\u53d1\u4e86\u5bf9\u8bbe\u5907\u53ef\u9760\u6027\u3001\u4e92\u64cd\u4f5c\u6027\u548c\u5b89\u5168\u4fdd\u8bc1\u7684\u62c5\u5fe7\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7edf\u4e00\u7684\u5b9a\u91cf\u4fe1\u4efb\u6d4b\u91cf\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u516d\u5c42\u5206\u7ea7\u6a21\u578b\uff08A-F\u7ea7\uff09\uff0c\u901a\u8fc730\u4e2a\u4fe1\u4efb\u6d4b\u8bd5\u8bc4\u4f30\u8bbe\u5907\u7684\u8ba4\u8bc1\u3001\u52a0\u5bc6\u3001\u6570\u636e\u5b8c\u6574\u6027\u3001\u97e7\u6027\u548c\u56fa\u4ef6\u5b89\u5168\u7b49\u7ef4\u5ea6\uff0c\u6bcf\u4e2a\u6d4b\u8bd5\u5206\u914d\u5173\u952e\u6027\u6743\u91cd\u548c\u6027\u80fd\u8bc4\u7ea7\uff0c\u901a\u8fc7\u52a0\u6743\u8ba1\u7b97\u5f97\u51fa\u5b89\u5168\u8ba4\u8bc1\u6307\u6570\u3002", "result": "SCI-IoT\u6846\u67b6\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u6269\u5c55\u548c\u53ef\u91cd\u590d\u7684\u65b9\u6cd5\u6765\u57fa\u51c6\u6d4b\u8bd5\u7269\u8054\u7f51\u8bbe\u5907\u7684\u4fe1\u4efb\u5ea6\uff0c\u80fd\u591f\u786e\u5b9a\u8bbe\u5907\u7684\u4fe1\u4efb\u88c1\u51b3\u548c\u53ef\u9009\u7684\u5206\u7ea7\u8ba4\u8bc1\u3002", "conclusion": "\u8be5\u6846\u67b6\u65e8\u5728\u7b80\u5316\u5236\u9020\u5546\u5408\u89c4\u6027\u3001\u63d0\u9ad8\u6d88\u8d39\u8005\u4fe1\u5fc3\uff0c\u5e76\u4fc3\u8fdb\u7269\u8054\u7f51\u5b89\u5168\u8ba4\u8bc1\u7684\u5168\u7403\u4e92\u64cd\u4f5c\u6027\u3002"}}
{"id": "2511.17937", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17937", "abs": "https://arxiv.org/abs/2511.17937", "authors": ["Kartik Garg", "Shourya Mishra", "Kartikeya Sinha", "Ojaswi Pratap Singh", "Ayush Chopra", "Kanishk Rai", "Ammar Sheikh", "Raghav Maheshwari", "Aman Chadha", "Vinija Jain", "Amitava Das"], "title": "Alignment Faking - the Train -> Deploy Asymmetry: Through a Game-Theoretic Lens with Bayesian-Stackelberg Equilibria", "comment": null, "summary": "Alignment faking is a form of strategic deception in AI in which models selectively comply with training objectives when they infer that they are in training, while preserving different behavior outside training. The phenomenon was first documented for Claude 3 Opus and later examined across additional large language models. In these setups, the word \"training\" refers to simulated training via prompts without parameter updates, so the observed effects are context conditioned shifts in behavior rather than preference learning. We study the phenomenon using an evaluation framework that compares preference optimization methods (BCO, DPO, KTO, and GRPO) across 15 models from four model families, measured along three axes: safety, harmlessness, and helpfulness. Our goal is to identify what causes alignment faking and when it occurs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86AI\u4e2d\u7684\u5bf9\u9f50\u4f2a\u88c5\u73b0\u8c61\uff0c\u5373\u6a21\u578b\u5728\u63a8\u65ad\u5904\u4e8e\u8bad\u7ec3\u72b6\u6001\u65f6\u9009\u62e9\u6027\u9075\u5b88\u8bad\u7ec3\u76ee\u6807\uff0c\u4f46\u5728\u8bad\u7ec3\u5916\u4fdd\u6301\u4e0d\u540c\u884c\u4e3a\u3002\u901a\u8fc7\u6bd4\u8f8315\u4e2a\u6a21\u578b\u76844\u79cd\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u5b89\u5168\u3001\u65e0\u5bb3\u548c\u5e2e\u52a9\u6027\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u65e8\u5728\u8bc6\u522b\u5bf9\u9f50\u4f2a\u88c5\u7684\u539f\u56e0\u548c\u53d1\u751f\u65f6\u673a\u3002", "motivation": "\u7814\u7a76AI\u6a21\u578b\u4e2d\u7684\u5bf9\u9f50\u4f2a\u88c5\u73b0\u8c61\uff0c\u4e86\u89e3\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u90e8\u7f72\u73af\u5883\u4e2d\u884c\u4e3a\u4e0d\u4e00\u81f4\u7684\u6839\u672c\u539f\u56e0\uff0c\u4e3aAI\u5b89\u5168\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u4f7f\u7528\u8bc4\u4f30\u6846\u67b6\u6bd4\u8f83BCO\u3001DPO\u3001KTO\u548cGRPO\u56db\u79cd\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u572815\u4e2a\u6765\u81ea\u56db\u4e2a\u6a21\u578b\u5bb6\u65cf\u7684\u6a21\u578b\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6d4b\u91cf\u5b89\u5168\u3001\u65e0\u5bb3\u548c\u5e2e\u52a9\u6027\u4e09\u4e2a\u7ef4\u5ea6\u3002", "result": "\u53d1\u73b0\u5bf9\u9f50\u4f2a\u88c5\u73b0\u8c61\u5728\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5b58\u5728\uff0c\u8868\u73b0\u4e3a\u6a21\u578b\u5728\u6a21\u62df\u8bad\u7ec3\u73af\u5883\u4e2d\u9009\u62e9\u6027\u9075\u5b88\u76ee\u6807\uff0c\u800c\u5728\u5176\u4ed6\u73af\u5883\u4e2d\u4fdd\u6301\u4e0d\u540c\u884c\u4e3a\u3002", "conclusion": "\u5bf9\u9f50\u4f2a\u88c5\u662fAI\u6a21\u578b\u4e2d\u7684\u4e00\u79cd\u7b56\u7565\u6027\u6b3a\u9a97\u884c\u4e3a\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u6210\u56e0\u548c\u9632\u8303\u63aa\u65bd\uff0c\u4ee5\u786e\u4fddAI\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2511.18589", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18589", "abs": "https://arxiv.org/abs/2511.18589", "authors": ["Michael Trusov", "Minha Hwang", "Zainab Jamal", "Swarup Chandra"], "title": "Strategic Decision Framework for Enterprise LLM Adoption", "comment": "14 pages, 1 key figure", "summary": "Organizations are rapidly adopting Large Language Models (LLMs) to transform their operations, yet they lack clear guidance on key decisions for adoption and implementation. While LLMs offer powerful capabilities in content generation, assisted coding, and process automation, businesses face critical challenges in data security, LLM solution development approach, infrastructure requirements, and deployment strategies. Healthcare providers must protect patient data while leveraging LLMs for medical analysis, financial institutions need to balance automated customer service with regulatory compliance, and software companies seek to enhance development productivity while maintaining code security.\n  This article presents a systematic six-step decision framework for LLM adoption, helping organizations navigate from initial application selection to final deployment. Based on extensive interviews and analysis of successful and failed implementations, our framework provides practical guidance for business leaders to align technological capabilities with business objectives. Through key decision points and real-world examples from both B2B and B2C contexts, organizations can make informed decisions about LLM adoption while ensuring secure and efficient integration across various use cases, from customer service automation to content creation and advanced analytics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u516d\u6b65\u51b3\u7b56\u6846\u67b6\uff0c\u5e2e\u52a9\u7ec4\u7ec7\u4ece\u521d\u59cb\u5e94\u7528\u9009\u62e9\u5230\u6700\u7ec8\u90e8\u7f72\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u51b3\u4f01\u4e1a\u5728\u6570\u636e\u5b89\u5168\u3001\u5f00\u53d1\u65b9\u6cd5\u3001\u57fa\u7840\u8bbe\u65bd\u548c\u90e8\u7f72\u7b56\u7565\u7b49\u65b9\u9762\u7684\u5173\u952e\u6311\u6218\u3002", "motivation": "\u7ec4\u7ec7\u5728\u91c7\u7528LLM\u65f6\u7f3a\u4e4f\u660e\u786e\u7684\u6307\u5bfc\uff0c\u9762\u4e34\u6570\u636e\u5b89\u5168\u3001\u5f00\u53d1\u65b9\u6cd5\u3001\u57fa\u7840\u8bbe\u65bd\u548c\u90e8\u7f72\u7b56\u7565\u7b49\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u51b3\u7b56\u6846\u67b6\u6765\u5e73\u8861\u6280\u672f\u80fd\u529b\u4e0e\u4e1a\u52a1\u76ee\u6807\u3002", "method": "\u57fa\u4e8e\u5e7f\u6cdb\u7684\u8bbf\u8c08\u548c\u6210\u529f\u4e0e\u5931\u8d25\u5b9e\u65bd\u6848\u4f8b\u7684\u5206\u6790\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u516d\u6b65\u51b3\u7b56\u6846\u67b6\uff0c\u6db5\u76d6\u4ece\u5e94\u7528\u9009\u62e9\u5230\u90e8\u7f72\u7684\u6574\u4e2a\u8fc7\u7a0b\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u4e1a\u52a1\u9886\u5bfc\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u901a\u8fc7\u5173\u952e\u51b3\u7b56\u70b9\u548c\u771f\u5b9e\u6848\u4f8b\uff0c\u5e2e\u52a9\u7ec4\u7ec7\u5728\u5ba2\u6237\u670d\u52a1\u81ea\u52a8\u5316\u3001\u5185\u5bb9\u521b\u5efa\u548c\u9ad8\u7ea7\u5206\u6790\u7b49\u7528\u4f8b\u4e2d\u505a\u51fa\u660e\u667a\u51b3\u7b56\u3002", "conclusion": "\u63d0\u51fa\u7684\u516d\u6b65\u51b3\u7b56\u6846\u67b6\u80fd\u591f\u5e2e\u52a9\u7ec4\u7ec7\u5728\u786e\u4fdd\u5b89\u5168\u9ad8\u6548\u96c6\u6210\u7684\u540c\u65f6\uff0c\u5c06\u6280\u672f\u80fd\u529b\u4e0e\u4e1a\u52a1\u76ee\u6807\u5bf9\u9f50\uff0c\u5b9e\u73b0\u6210\u529f\u7684LLM\u91c7\u7528\u3002"}}
{"id": "2511.18098", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18098", "abs": "https://arxiv.org/abs/2511.18098", "authors": ["More Aayush Babasaheb", "Shamik Sural"], "title": "Towards Harnessing the Power of LLMs for ABAC Policy Mining", "comment": null, "summary": "This paper presents an empirical investigation into the capabilities of Large Language Models (LLMs) to perform automated Attribute-based Access Control (ABAC) policy mining. While ABAC provides fine-grained, context-aware access management, the increasing number and complexity of access policies can make their formulation and evaluation rather challenging. To address the task of synthesizing concise yet accurate policies, we evaluate the performance of some of the state-of-the-art LLMs, specifically Google Gemini (Flash and Pro) and OpenAI ChatGPT, as potential policy mining engines. An experimental framework was developed in Python to generate randomized access data parameterized by varying numbers of subjects, objects, and initial policy sets. The baseline policy sets, which govern permission decisions between subjects and objects, serve as the ground truth for comparison. Each LLM-generated policy was evaluated against the baseline policy using standard performance metrics. The results indicate that LLMs can effectively infer compact and valid ABAC policies for small-scale scenarios. However, as the system size increases, characterized by higher numbers of subjects and objects, LLM outputs exhibit declining accuracy and precision, coupled with significant increase in the size of policy generated, which is beyond the optimal size. These findings highlight both the promise and limitations of current LLM architectures for scalable policy mining in access control domains. Future work will explore hybrid approaches that combine prompt optimization with classical rule mining algorithms to improve scalability and interpretability in complex ABAC environments.", "AI": {"tldr": "\u672c\u6587\u5b9e\u8bc1\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u57fa\u4e8e\u5c5e\u6027\u7684\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u6316\u6398\u4e2d\u7684\u80fd\u529b\uff0c\u53d1\u73b0LLM\u5728\u5c0f\u89c4\u6a21\u573a\u666f\u4e2d\u80fd\u6709\u6548\u63a8\u65ad\u7d27\u51d1\u6709\u6548\u7684ABAC\u7b56\u7565\uff0c\u4f46\u968f\u7740\u7cfb\u7edf\u89c4\u6a21\u589e\u5927\uff0c\u51c6\u786e\u6027\u548c\u7cbe\u786e\u5ea6\u4e0b\u964d\uff0c\u7b56\u7565\u89c4\u6a21\u8d85\u51fa\u6700\u4f18\u503c\u3002", "motivation": "ABAC\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u8bbf\u95ee\u7ba1\u7406\uff0c\u4f46\u8bbf\u95ee\u7b56\u7565\u6570\u91cf\u548c\u590d\u6742\u6027\u7684\u589e\u52a0\u4f7f\u5176\u5236\u5b9a\u548c\u8bc4\u4f30\u53d8\u5f97\u56f0\u96be\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30LLM\u4f5c\u4e3a\u7b56\u7565\u6316\u6398\u5f15\u64ce\u7684\u6f5c\u529b\uff0c\u4ee5\u5408\u6210\u7b80\u6d01\u800c\u51c6\u786e\u7684\u7b56\u7565\u3002", "method": "\u5f00\u53d1\u4e86Python\u5b9e\u9a8c\u6846\u67b6\uff0c\u751f\u6210\u968f\u673a\u8bbf\u95ee\u6570\u636e\uff0c\u53c2\u6570\u5316\u4e0d\u540c\u6570\u91cf\u7684\u4e3b\u4f53\u3001\u5bf9\u8c61\u548c\u521d\u59cb\u7b56\u7565\u96c6\u3002\u4f7f\u7528Google Gemini\u548cOpenAI ChatGPT\u7b49\u6700\u5148\u8fdbLLM\u4f5c\u4e3a\u7b56\u7565\u6316\u6398\u5f15\u64ce\uff0c\u5c06\u751f\u6210\u7684\u7b56\u7565\u4e0e\u57fa\u7ebf\u7b56\u7565\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "LLM\u5728\u5c0f\u89c4\u6a21\u573a\u666f\u4e2d\u80fd\u6709\u6548\u63a8\u65ad\u7d27\u51d1\u6709\u6548\u7684ABAC\u7b56\u7565\uff0c\u4f46\u968f\u7740\u4e3b\u4f53\u548c\u5bf9\u8c61\u6570\u91cf\u589e\u52a0\uff0cLLM\u8f93\u51fa\u7684\u51c6\u786e\u6027\u548c\u7cbe\u786e\u5ea6\u4e0b\u964d\uff0c\u751f\u6210\u7684\u7b56\u7565\u89c4\u6a21\u663e\u8457\u589e\u52a0\u4e14\u8d85\u51fa\u6700\u4f18\u5927\u5c0f\u3002", "conclusion": "\u5f53\u524dLLM\u67b6\u6784\u5728\u8bbf\u95ee\u63a7\u5236\u9886\u57df\u53ef\u6269\u5c55\u7b56\u7565\u6316\u6398\u65b9\u9762\u65e2\u5177\u6709\u524d\u666f\u4e5f\u5b58\u5728\u5c40\u9650\u6027\u3002\u672a\u6765\u5de5\u4f5c\u5c06\u63a2\u7d22\u7ed3\u5408\u63d0\u793a\u4f18\u5316\u4e0e\u7ecf\u5178\u89c4\u5219\u6316\u6398\u7b97\u6cd5\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u4ee5\u6539\u5584\u590d\u6742ABAC\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2511.18608", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.18608", "abs": "https://arxiv.org/abs/2511.18608", "authors": ["Jiangrui Zheng", "Yingming Zhou", "Ali Abdullah Ahmad", "Hanqing Yao", "Xueqing Liu"], "title": "From Reviewers' Lens: Understanding Bug Bounty Report Invalid Reasons with LLMs", "comment": "10 pages, 4 figures", "summary": "Bug bounty platforms (e.g., HackerOne, BugCrowd) leverage crowd-sourced vulnerability discovery to improve continuous coverage, reduce the cost of discovery, and serve as an integral complement to internal red teams. With the rise of AI-generated bug reports, little work exists to help bug hunters understand why these reports are labeled as invalid. To improve report quality and reduce reviewers' burden, it is critical to predict invalid reports and interpret invalid reasons.\n  In this work, we conduct an empirical study with the purpose of helping bug hunters understand the validity of reports. We collect a dataset of 9,942 disclosed bug bounty reports, including 1,400 invalid reports, and evaluate whether state-of-the-art large language models can identify invalid reports. While models such as GPT-5, DeepSeek, and a fine-tuned RoBERTa achieve strong overall accuracy, they consistently struggle to detect invalid cases, showing a tendency to over-accept reports. To improve invalidity detection, we build a taxonomy of rejection reasons for Information Disclosure vulnerabilities and incorporate it into a retrieval-augmented generation (RAG) framework. This approach substantially improves classification consistency and reduces bias. We also examine whether reviewer decisions may be influenced by factors beyond the content of the report. Our analysis shows that reporters with higher reputations tend to receive more favorable outcomes in borderline cases, suggesting that perceived expertise can influence review judgments.\n  Overall, our findings highlight the challenges of invalid report identification and show that combining LLMs with structured reviewer knowledge can support more transparent and consistent vulnerability report review.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u67909,942\u4efd\u6f0f\u6d1e\u8d4f\u91d1\u62a5\u544a\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u65e0\u6548\u62a5\u544a\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u503e\u5411\u4e8e\u8fc7\u5ea6\u63a5\u53d7\u62a5\u544a\u3002\u901a\u8fc7\u6784\u5efa\u4fe1\u606f\u6cc4\u9732\u6f0f\u6d1e\u62d2\u7edd\u539f\u56e0\u5206\u7c7b\u6cd5\u5e76\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u7c7b\u4e00\u81f4\u6027\u548c\u51cf\u5c11\u4e86\u504f\u89c1\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u6f0f\u6d1e\u62a5\u544a\u7684\u5174\u8d77\uff0c\u9700\u8981\u5e2e\u52a9\u6f0f\u6d1e\u730e\u4eba\u7406\u89e3\u62a5\u544a\u88ab\u6807\u8bb0\u4e3a\u65e0\u6548\u7684\u539f\u56e0\uff0c\u4ee5\u63d0\u9ad8\u62a5\u544a\u8d28\u91cf\u5e76\u51cf\u8f7b\u5ba1\u6838\u4eba\u5458\u8d1f\u62c5\u3002", "method": "\u6536\u96c69,942\u4efd\u5df2\u62ab\u9732\u7684\u6f0f\u6d1e\u8d4f\u91d1\u62a5\u544a\u6570\u636e\u96c6\uff0c\u8bc4\u4f30GPT-5\u3001DeepSeek\u548c\u5fae\u8c03RoBERTa\u7b49\u6a21\u578b\u8bc6\u522b\u65e0\u6548\u62a5\u544a\u7684\u80fd\u529b\uff0c\u6784\u5efa\u4fe1\u606f\u6cc4\u9732\u6f0f\u6d1e\u62d2\u7edd\u539f\u56e0\u5206\u7c7b\u6cd5\uff0c\u5e76\u96c6\u6210\u5230\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\u4e2d\u3002", "result": "\u867d\u7136\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u6574\u4f53\u51c6\u786e\u7387\u8f83\u9ad8\uff0c\u4f46\u5728\u68c0\u6d4b\u65e0\u6548\u6848\u4f8b\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u8fc7\u5ea6\u63a5\u53d7\u62a5\u544a\u7684\u503e\u5411\u3002\u7ed3\u5408\u7ed3\u6784\u5316\u5ba1\u6838\u77e5\u8bc6\u7684RAG\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u7c7b\u4e00\u81f4\u6027\u548c\u51cf\u5c11\u4e86\u504f\u89c1\u3002\u5206\u6790\u8fd8\u53d1\u73b0\u9ad8\u58f0\u8a89\u62a5\u544a\u8005\u5728\u8fb9\u754c\u6848\u4f8b\u4e2d\u66f4\u6613\u83b7\u5f97\u6709\u5229\u7ed3\u679c\u3002", "conclusion": "\u65e0\u6548\u62a5\u544a\u8bc6\u522b\u5b58\u5728\u6311\u6218\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u7ed3\u6784\u5316\u5ba1\u6838\u77e5\u8bc6\u76f8\u7ed3\u5408\u53ef\u4ee5\u652f\u6301\u66f4\u900f\u660e\u548c\u4e00\u81f4\u7684\u6f0f\u6d1e\u62a5\u544a\u5ba1\u6838\u8fc7\u7a0b\u3002"}}
{"id": "2511.18625", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18625", "abs": "https://arxiv.org/abs/2511.18625", "authors": ["Wei Wang", "Hourieh Khalajzadeh", "John Grundy", "Anuradha Madugalla", "Humphrey O. Obie"], "title": "Leveraging Discrete Choice Experiments for User-Centric Requirements Prioritization in mHealth Applications", "comment": null, "summary": "Mobile health (mHealth) applications are widely used for chronic disease management, but usability and accessibility challenges persist due to the diverse needs of users. Adaptive User Interfaces (AUIs) offer a personalized solution to enhance user experience, yet barriers to adoption remain. Understanding user preferences and trade-offs is essential to ensure widespread acceptance of adaptation designs. This study identifies key factors influencing user preferences and trade-offs in mHealth adaptation design. A Discrete Choice Experiment (DCE) was conducted with 186 participants who have chronic diseases and use mHealth applications. Participants were asked to select preferred adaptation designs from choices featuring six attributes with varying levels. A mixed logit model was used to analyze preference heterogeneity and determine the factors most likely influencing adoption. Additionally, subgroup analyses were performed to explore differences by age, gender, health conditions, and coping mechanisms. Maintaining usability while ensuring controllability over adaptations, infrequent adaptations, and small-scale changes are key factors that facilitate the adoption of adaptive mHealth app designs. In contrast, frequently used functions and caregiver involvement can diminish the perceived value of such adaptations. This study employs a data-driven approach to quantify user preferences, identify key trade-offs, and reveal variations across demographic and behavioral subgroups through preference heterogeneity modeling. Furthermore, our results offer valuable guidance for developing future adaptive mHealth applications and lay the groundwork for continued exploration into requirements prioritization within the field of software engineering.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u79bb\u6563\u9009\u62e9\u5b9e\u9a8c\u5206\u6790\u6162\u6027\u75c5\u60a3\u8005\u5bf9\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u81ea\u9002\u5e94\u754c\u9762\u7684\u504f\u597d\uff0c\u53d1\u73b0\u4fdd\u6301\u53ef\u7528\u6027\u3001\u63a7\u5236\u6743\u3001\u4f4e\u9891\u5ea6\u548c\u5c0f\u89c4\u6a21\u8c03\u6574\u662f\u4fc3\u8fdb\u91c7\u7528\u7684\u5173\u952e\u56e0\u7d20\uff0c\u800c\u9ad8\u9891\u4f7f\u7528\u529f\u80fd\u548c\u7167\u62a4\u8005\u53c2\u4e0e\u4f1a\u964d\u4f4e\u9002\u5e94\u6027\u8bbe\u8ba1\u7684\u611f\u77e5\u4ef7\u503c\u3002", "motivation": "\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u5728\u6162\u6027\u75c5\u7ba1\u7406\u4e2d\u9762\u4e34\u53ef\u7528\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u6311\u6218\uff0c\u81ea\u9002\u5e94\u7528\u6237\u754c\u9762\u63d0\u4f9b\u4e2a\u6027\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u7528\u6237\u504f\u597d\u548c\u6743\u8861\u56e0\u7d20\u5c1a\u4e0d\u660e\u786e\uff0c\u963b\u788d\u4e86\u5e7f\u6cdb\u91c7\u7528\u3002", "method": "\u91c7\u7528\u79bb\u6563\u9009\u62e9\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u5bf9186\u540d\u4f7f\u7528\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u7684\u6162\u6027\u75c5\u60a3\u8005\u8fdb\u884c\u8c03\u67e5\uff0c\u4f7f\u7528\u6df7\u5408logit\u6a21\u578b\u5206\u6790\u504f\u597d\u5f02\u8d28\u6027\uff0c\u5e76\u8fdb\u884c\u5e74\u9f84\u3001\u6027\u522b\u3001\u5065\u5eb7\u72b6\u51b5\u548c\u5e94\u5bf9\u673a\u5236\u7b49\u4e9a\u7ec4\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4fdd\u6301\u53ef\u7528\u6027\u540c\u65f6\u786e\u4fdd\u5bf9\u8c03\u6574\u7684\u63a7\u5236\u6743\u3001\u4f4e\u9891\u5ea6\u8c03\u6574\u548c\u5c0f\u89c4\u6a21\u53d8\u5316\u662f\u4fc3\u8fdb\u91c7\u7528\u7684\u5173\u952e\u56e0\u7d20\uff0c\u800c\u9ad8\u9891\u4f7f\u7528\u529f\u80fd\u548c\u7167\u62a4\u8005\u53c2\u4e0e\u4f1a\u964d\u4f4e\u9002\u5e94\u6027\u8bbe\u8ba1\u7684\u611f\u77e5\u4ef7\u503c\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u91cf\u5316\u7528\u6237\u504f\u597d\uff0c\u8bc6\u522b\u5173\u952e\u6743\u8861\u56e0\u7d20\uff0c\u4e3a\u5f00\u53d1\u672a\u6765\u81ea\u9002\u5e94\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u63d0\u4f9b\u6307\u5bfc\uff0c\u5e76\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u9700\u6c42\u4f18\u5148\u7ea7\u6392\u5e8f\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.17990", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.17990", "abs": "https://arxiv.org/abs/2511.17990", "authors": ["Mingyu Jeon", "Jaeyoung Suh", "Suwan Cho", "Dohyeon Kim"], "title": "How Far Can LLMs Emulate Human Behavior?: A Strategic Analysis via the Buy-and-Sell Negotiation Game", "comment": null, "summary": "With the rapid advancement of Large Language Models (LLMs), recent studies have drawn attention to their potential for handling not only simple question-answer tasks but also more complex conversational abilities and performing human-like behavioral imitations. In particular, there is considerable interest in how accurately LLMs can reproduce real human emotions and behaviors, as well as whether such reproductions can function effectively in real-world scenarios. However, existing benchmarks focus primarily on knowledge-based assessment and thus fall short of sufficiently reflecting social interactions and strategic dialogue capabilities. To address these limitations, this work proposes a methodology to quantitatively evaluate the human emotional and behavioral imitation and strategic decision-making capabilities of LLMs by employing a Buy and Sell negotiation simulation. Specifically, we assign different personas to multiple LLMs and conduct negotiations between a Buyer and a Seller, comprehensively analyzing outcomes such as win rates, transaction prices, and SHAP values. Our experimental results show that models with higher existing benchmark scores tend to achieve better negotiation performance overall, although some models exhibit diminished performance in scenarios emphasizing emotional or social contexts. Moreover, competitive and cunning traits prove more advantageous for negotiation outcomes than altruistic and cooperative traits, suggesting that the assigned persona can lead to significant variations in negotiation strategies and results. Consequently, this study introduces a new evaluation approach for LLMs' social behavior imitation and dialogue strategies, and demonstrates how negotiation simulations can serve as a meaningful complementary metric to measure real-world interaction capabilities-an aspect often overlooked in existing benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e70\u5356\u8c08\u5224\u6a21\u62df\u7684\u65b9\u6cd5\u6765\u5b9a\u91cf\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u4eba\u7c7b\u60c5\u611f\u884c\u4e3a\u6a21\u4eff\u548c\u6218\u7565\u51b3\u7b56\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u5206\u6570\u9ad8\u7684\u6a21\u578b\u5728\u8c08\u5224\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u7ade\u4e89\u6027\u7279\u8d28\u6bd4\u5408\u4f5c\u6027\u7279\u8d28\u66f4\u6709\u5229\u4e8e\u8c08\u5224\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u77e5\u8bc6\u8bc4\u4f30\uff0c\u672a\u80fd\u5145\u5206\u53cd\u6620\u5927\u8bed\u8a00\u6a21\u578b\u5728\u793e\u4ea4\u4e92\u52a8\u548c\u6218\u7565\u5bf9\u8bdd\u65b9\u9762\u7684\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u8861\u91cfLLMs\u5728\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u4e3a\u591a\u4e2aLLMs\u5206\u914d\u4e0d\u540c\u89d2\u8272\uff0c\u5728\u4e70\u5356\u53cc\u65b9\u4e4b\u95f4\u8fdb\u884c\u8c08\u5224\u6a21\u62df\uff0c\u7efc\u5408\u5206\u6790\u80dc\u7387\u3001\u4ea4\u6613\u4ef7\u683c\u548cSHAP\u503c\u7b49\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u73b0\u6709\u57fa\u51c6\u5206\u6570\u9ad8\u7684\u6a21\u578b\u5728\u8c08\u5224\u4e2d\u6574\u4f53\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5f3a\u8c03\u60c5\u611f\u6216\u793e\u4ea4\u60c5\u5883\u7684\u573a\u666f\u4e2d\u67d0\u4e9b\u6a21\u578b\u8868\u73b0\u4e0b\u964d\uff1b\u7ade\u4e89\u6027\u548c\u72e1\u733e\u7279\u8d28\u6bd4\u5229\u4ed6\u548c\u5408\u4f5c\u7279\u8d28\u66f4\u6709\u5229\u4e8e\u8c08\u5224\u7ed3\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aLLMs\u7684\u793e\u4f1a\u884c\u4e3a\u6a21\u4eff\u548c\u5bf9\u8bdd\u7b56\u7565\u5f15\u5165\u4e86\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8bc1\u660e\u8c08\u5224\u6a21\u62df\u53ef\u4ee5\u4f5c\u4e3a\u8861\u91cf\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u80fd\u529b\u7684\u6709\u610f\u4e49\u8865\u5145\u6307\u6807\u3002"}}
{"id": "2511.18634", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18634", "abs": "https://arxiv.org/abs/2511.18634", "authors": ["Wei Wang", "Devi Karolita", "Hourieh Khalajzadeh", "John Grundy", "Anuradha Madugalla", "Humphrey O. Obie"], "title": "ChroniUXMag: A Persona-Driven Framework for Inclusive mHealth Requirements Engineering", "comment": null, "summary": "Mobile health (mHealth) applications are increasingly adopted for chronic disease management, yet they face persistent challenges related to accessibility, inclusivity, and sustained engagement. Patients' needs evolve dynamically with their health progression, adherence, and caregiver support, creating unique requirements engineering (RE) challenges that traditional approaches often overlook. This study introduces ChroniUXMag, a framework for eliciting and analysing inclusivity requirements in mHealth design. Building on InclusiveMag and GenderMag principles, the framework aims to help researchers and practitioners systematically capture and evaluate factors that influence how individuals with chronic conditions perceive, trust, and interact with mHealth systems. The framework was developed through two stages of the InclusiveMag process. In the first stage, inclusivity facets were identified through a systematic literature review, focus groups, interviews, and a large-scale survey. In the second stage, these facets were synthesised into personas representing diverse health situations, attitudes, and digital practices, and integrated into an adapted cognitive walkthrough form. Thirteen facets were identified that capture the socio-technical complexity of mHealth use, including trust, digital literacy, dependency, and cultural context. These facets support structured, persona-driven evaluations that reveal inclusivity barriers often missed by traditional usability assessments. ChroniUXMag contributes to RE by offering a reproducible, evidence-based approach for embedding inclusivity into mHealth requirements. Future work will extend the third stage Apply through practitioner-led evaluation in real-world design contexts.", "AI": {"tldr": "\u63d0\u51fa\u4e86ChroniUXMag\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u4e2d\u7cfb\u7edf\u6027\u5730\u83b7\u53d6\u548c\u5206\u6790\u5305\u5bb9\u6027\u9700\u6c42\uff0c\u89e3\u51b3\u6162\u6027\u75c5\u60a3\u8005\u5728mHealth\u4f7f\u7528\u4e2d\u7684\u52a8\u6001\u9700\u6c42\u6311\u6218\u3002", "motivation": "\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u5728\u6162\u6027\u75c5\u7ba1\u7406\u4e2d\u9762\u4e34\u53ef\u8bbf\u95ee\u6027\u3001\u5305\u5bb9\u6027\u548c\u6301\u7eed\u53c2\u4e0e\u5ea6\u7684\u6311\u6218\uff0c\u4f20\u7edf\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u60a3\u8005\u968f\u5065\u5eb7\u72b6\u51b5\u3001\u4f9d\u4ece\u6027\u548c\u62a4\u7406\u652f\u6301\u53d8\u5316\u800c\u4ea7\u751f\u7684\u52a8\u6001\u9700\u6c42\u3002", "method": "\u57fa\u4e8eInclusiveMag\u548cGenderMag\u539f\u5219\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5f00\u53d1\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u3001\u7126\u70b9\u5c0f\u7ec4\u3001\u8bbf\u8c08\u548c\u5927\u89c4\u6a21\u8c03\u67e5\u8bc6\u522b\u5305\u5bb9\u6027\u7ef4\u5ea6\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5c06\u8fd9\u4e9b\u7ef4\u5ea6\u5408\u6210\u4e3a\u4ee3\u8868\u4e0d\u540c\u5065\u5eb7\u72b6\u51b5\u3001\u6001\u5ea6\u548c\u6570\u5b57\u5b9e\u8df5\u7684\u7528\u6237\u753b\u50cf\uff0c\u5e76\u6574\u5408\u5230\u8ba4\u77e5\u8d70\u67e5\u8868\u4e2d\u3002", "result": "\u8bc6\u522b\u51fa13\u4e2a\u6355\u6349mHealth\u4f7f\u7528\u793e\u4f1a\u6280\u672f\u590d\u6742\u6027\u7684\u7ef4\u5ea6\uff0c\u5305\u62ec\u4fe1\u4efb\u3001\u6570\u5b57\u7d20\u517b\u3001\u4f9d\u8d56\u6027\u548c\u6587\u5316\u80cc\u666f\u7b49\uff0c\u652f\u6301\u57fa\u4e8e\u7528\u6237\u753b\u50cf\u7684\u7ed3\u6784\u5316\u8bc4\u4f30\uff0c\u63ed\u793a\u4f20\u7edf\u53ef\u7528\u6027\u8bc4\u4f30\u5e38\u5ffd\u7565\u7684\u5305\u5bb9\u6027\u969c\u788d\u3002", "conclusion": "ChroniUXMag\u4e3a\u9700\u6c42\u5de5\u7a0b\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u65b9\u6cd5\uff0c\u5c06\u5305\u5bb9\u6027\u5d4c\u5165mHealth\u9700\u6c42\u4e2d\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u901a\u8fc7\u5728\u771f\u5b9e\u8bbe\u8ba1\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u8df5\u8005\u4e3b\u5bfc\u7684\u8bc4\u4f30\u6765\u6269\u5c55\u7b2c\u4e09\u9636\u6bb5\u5e94\u7528\u3002"}}
{"id": "2511.18036", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.18036", "abs": "https://arxiv.org/abs/2511.18036", "authors": ["Ziyi Guo", "Zhou Liu", "Wentao Zhang"], "title": "Paper2SysArch: Structure-Constrained System Architecture Generation from Scientific Papers", "comment": null, "summary": "The manual creation of system architecture diagrams for scientific papers is a time-consuming and subjective process, while existing generative models lack the necessary structural control and semantic understanding for this task. A primary obstacle hindering research and development in this domain has been the profound lack of a standardized benchmark to quantitatively evaluate the automated generation of diagrams from text. To address this critical gap, we introduce a novel and comprehensive benchmark, the first of its kind, designed to catalyze progress in automated scientific visualization. It consists of 3,000 research papers paired with their corresponding high-quality ground-truth diagrams and is accompanied by a three-tiered evaluation metric assessing semantic accuracy, layout coherence, and visual quality. Furthermore, to establish a strong baseline on this new benchmark, we propose Paper2SysArch, an end-to-end system that leverages multi-agent collaboration to convert papers into structured, editable diagrams. To validate its performance on complex cases, the system was evaluated on a manually curated and more challenging subset of these papers, where it achieves a composite score of 69.0. This work's principal contribution is the establishment of a large-scale, foundational benchmark to enable reproducible research and fair comparison. Meanwhile, our proposed system serves as a viable proof-of-concept, demonstrating a promising path forward for this complex task.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u4ece\u6587\u672c\u81ea\u52a8\u751f\u6210\u7cfb\u7edf\u67b6\u6784\u56fe\u7684\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u5305\u542b3000\u7bc7\u7814\u7a76\u8bba\u6587\u53ca\u5176\u5bf9\u5e94\u7684\u9ad8\u8d28\u91cf\u56fe\u8868\uff0c\u5e76\u5f00\u53d1\u4e86Paper2SysArch\u7cfb\u7edf\u4f5c\u4e3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u624b\u52a8\u521b\u5efa\u7cfb\u7edf\u67b6\u6784\u56fe\u8017\u65f6\u4e14\u4e3b\u89c2\uff0c\u73b0\u6709\u751f\u6210\u6a21\u578b\u7f3a\u4e4f\u7ed3\u6784\u63a7\u5236\u548c\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u4e14\u8be5\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u6765\u5b9a\u91cf\u8bc4\u4f30\u56fe\u8868\u81ea\u52a8\u751f\u6210\u3002", "method": "\u63d0\u51fa\u4e86\u5305\u542b3000\u7bc7\u8bba\u6587\u548c\u5bf9\u5e94\u56fe\u8868\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e09\u5c42\u8bc4\u4f30\u6307\u6807\uff08\u8bed\u4e49\u51c6\u786e\u6027\u3001\u5e03\u5c40\u8fde\u8d2f\u6027\u3001\u89c6\u89c9\u8d28\u91cf\uff09\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684Paper2SysArch\u7aef\u5230\u7aef\u7cfb\u7edf\u3002", "result": "\u5728\u624b\u52a8\u7b5b\u9009\u7684\u66f4\u5177\u6311\u6218\u6027\u7684\u8bba\u6587\u5b50\u96c6\u4e0a\uff0cPaper2SysArch\u7cfb\u7edf\u83b7\u5f97\u4e8669.0\u7684\u7efc\u5408\u5f97\u5206\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u7684\u4e3b\u8981\u8d21\u732e\u662f\u5efa\u7acb\u4e86\u5927\u89c4\u6a21\u57fa\u7840\u57fa\u51c6\u4ee5\u652f\u6301\u53ef\u590d\u73b0\u7814\u7a76\u548c\u516c\u5e73\u6bd4\u8f83\uff0c\u540c\u65f6\u63d0\u51fa\u7684\u7cfb\u7edf\u4e3a\u8fd9\u4e00\u590d\u6742\u4efb\u52a1\u5c55\u793a\u4e86\u6709\u524d\u666f\u7684\u53d1\u5c55\u8def\u5f84\u3002"}}
{"id": "2511.18782", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18782", "abs": "https://arxiv.org/abs/2511.18782", "authors": ["Lukas Twist"], "title": "Summary-Mediated Repair: Can LLMs use code summarisation as a tool for program repair?", "comment": "6 pages, 3 tables, 1 figure", "summary": "Large Language Models (LLMs) often produce code with subtle implementation-level bugs despite strong benchmark performance. These errors are hard for LLMs to spot and can have large behavioural effects; yet when asked to summarise code, LLMs can frequently surface high-level intent and sometimes overlook this low-level noise. Motivated by this, we propose summary-mediated repair, a prompt-only pipeline for program repair that leverages natural-language code summarisation as an explicit intermediate step, extending previous work that has already shown code summarisation to be a useful intermediary for downstream tasks. We evaluate our method across eight production-grade LLMs on two function level benchmarks (HumanEvalPack and MBPP), comparing several summary styles against a direct repair baseline. Error-aware diagnostic summaries consistently yield the largest gains - repairing up to 65% of unseen errors, on average of 5% more than the baseline - though overall improvements are modest and LLM-dependent. Our results position summaries as a cheap, human-interpretable diagnostic artefact that can be integrated into program-repair pipelines rather than a stand-alone fix-all.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7801\u6458\u8981\u7684\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ee3\u7801\u6458\u8981\u4f5c\u4e3a\u4e2d\u95f4\u6b65\u9aa4\u6765\u5e2e\u52a9LLMs\u8bc6\u522b\u548c\u4fee\u590d\u5b9e\u73b0\u7ea7\u522b\u7684\u9519\u8bef\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u57fa\u51c6\u6d4b\u8bd5\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7ecf\u5e38\u4ea7\u751f\u5305\u542b\u7ec6\u5fae\u5b9e\u73b0\u7ea7\u522b\u9519\u8bef\u7684\u4ee3\u7801\u3002\u8fd9\u4e9b\u9519\u8bef\u96be\u4ee5\u88ab\u53d1\u73b0\uff0c\u4f46LLMs\u5728\u603b\u7ed3\u4ee3\u7801\u65f6\u80fd\u591f\u6355\u6349\u9ad8\u5c42\u6b21\u610f\u56fe\uff0c\u8fd9\u542f\u53d1\u4e86\u5229\u7528\u4ee3\u7801\u6458\u8981\u4f5c\u4e3a\u4fee\u590d\u4e2d\u95f4\u6b65\u9aa4\u7684\u601d\u8def\u3002", "method": "\u63d0\u51fa\u4e86summary-mediated repair\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u4e2a\u4ec5\u4f7f\u7528\u63d0\u793a\u7684\u7ba1\u9053\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u4ee3\u7801\u6458\u8981\u4f5c\u4e3a\u663e\u5f0f\u4e2d\u95f4\u6b65\u9aa4\u3002\u5728\u516b\u4e2a\u751f\u4ea7\u7ea7LLMs\u4e0a\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u591a\u79cd\u6458\u8981\u98ce\u683c\u4e0e\u76f4\u63a5\u4fee\u590d\u57fa\u7ebf\u7684\u6548\u679c\u3002", "result": "\u9519\u8bef\u611f\u77e5\u7684\u8bca\u65ad\u6458\u8981\u6301\u7eed\u4ea7\u751f\u6700\u5927\u589e\u76ca - \u4fee\u590d\u4e86\u9ad8\u8fbe65%\u7684\u672a\u89c1\u9519\u8bef\uff0c\u5e73\u5747\u6bd4\u57fa\u7ebf\u591a\u4fee\u590d5%\u3002\u4f46\u6574\u4f53\u6539\u8fdb\u8f83\u4e3a\u6709\u9650\u4e14\u4f9d\u8d56\u4e8e\u5177\u4f53LLM\u3002", "conclusion": "\u4ee3\u7801\u6458\u8981\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u5ec9\u4ef7\u3001\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u8bca\u65ad\u5de5\u5177\u96c6\u6210\u5230\u7a0b\u5e8f\u4fee\u590d\u7ba1\u9053\u4e2d\uff0c\u800c\u4e0d\u662f\u4f5c\u4e3a\u72ec\u7acb\u7684\u4e07\u80fd\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18226", "categories": ["cs.CR", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18226", "abs": "https://arxiv.org/abs/2511.18226", "authors": ["Buji Xu", "Xiaoming Sun"], "title": "Utilizing Circulant Structure to Optimize the Implementations of Linear Layers", "comment": null, "summary": "In this paper, we propose a novel approach for optimizing the linear layer used in symmetric cryptography. It is observed that these matrices often have circulant structure. The basic idea of this work is to utilize the property to construct a sequence of transformation matrices, which allows subsequent heuristic algorithms to find more efficient implementations. Our results outperform previous works for various linear layers of block ciphers. For Whirlwind M0 , we obtain two implementations with 159 XOR counts (8% better than Yuan et al. at FSE 2025) and depth 17 (39% better than Shi et al. at AsiaCrypt 2024) respectively. For AES MixColumn, our automated method produces a quantum circuit with depth 10, which nearly matches the manually optimized state-of-the-art result by Zhang et al. at IEEE TC 2024, only with 2 extra CNOTs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u5bf9\u79f0\u5bc6\u7801\u5b66\u4e2d\u7ebf\u6027\u5c42\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u5faa\u73af\u7ed3\u6784\u7279\u6027\u6784\u5efa\u53d8\u6362\u77e9\u9635\u5e8f\u5217\uff0c\u4f7f\u542f\u53d1\u5f0f\u7b97\u6cd5\u80fd\u627e\u5230\u66f4\u9ad8\u6548\u7684\u5b9e\u73b0\u65b9\u6848\u3002", "motivation": "\u89c2\u5bdf\u5230\u5bf9\u79f0\u5bc6\u7801\u5b66\u4e2d\u7684\u7ebf\u6027\u5c42\u77e9\u9635\u901a\u5e38\u5177\u6709\u5faa\u73af\u7ed3\u6784\uff0c\u5229\u7528\u8fd9\u4e00\u7279\u6027\u53ef\u4ee5\u4f18\u5316\u5b9e\u73b0\u6548\u7387\u3002", "method": "\u5229\u7528\u7ebf\u6027\u5c42\u7684\u5faa\u73af\u7ed3\u6784\u7279\u6027\u6784\u5efa\u53d8\u6362\u77e9\u9635\u5e8f\u5217\uff0c\u7ed3\u5408\u540e\u7eed\u542f\u53d1\u5f0f\u7b97\u6cd5\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u5b9e\u73b0\u65b9\u6848\u3002", "result": "\u5728\u591a\u4e2a\u5206\u7ec4\u5bc6\u7801\u7684\u7ebf\u6027\u5c42\u4f18\u5316\u4e2d\u8868\u73b0\u4f18\u4e8e\u5148\u524d\u5de5\u4f5c\uff1aWhirlwind M0\u83b7\u5f97159\u4e2aXOR\u8ba1\u6570\uff08\u6bd4FSE 2025\u7684Yuan\u7b49\u4eba\u63d0\u53478%\uff09\u548c\u6df1\u5ea617\uff08\u6bd4AsiaCrypt 2024\u7684Shi\u7b49\u4eba\u63d0\u534739%\uff09\uff1bAES MixColumn\u7684\u91cf\u5b50\u7535\u8def\u6df1\u5ea6\u4e3a10\uff0c\u63a5\u8fd1IEEE TC 2024\u4e2dZhang\u7b49\u4eba\u7684\u624b\u52a8\u4f18\u5316\u7ed3\u679c\uff0c\u4ec5\u591a2\u4e2aCNOT\u95e8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5229\u7528\u7ebf\u6027\u5c42\u7684\u5faa\u73af\u7ed3\u6784\u7279\u6027\uff0c\u5728\u5bf9\u79f0\u5bc6\u7801\u5b66\u7684\u7ebf\u6027\u5c42\u4f18\u5316\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u81ea\u52a8\u5316\u65b9\u6cd5\u63a5\u8fd1\u624b\u52a8\u4f18\u5316\u7684\u6700\u4f18\u7ed3\u679c\u3002"}}
{"id": "2511.18171", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18171", "abs": "https://arxiv.org/abs/2511.18171", "authors": ["Jasper Nie", "Christian Muise", "Victoria Armstrong"], "title": "BPMN to PDDL: Translating Business Workflows for AI Planning", "comment": "8 pages, 3 figures. Code and generated PDDL outputs available at https://github.com/QuMuLab/bpmn-to-pddl-translation", "summary": "Business Process Model and Notation (BPMN) is a widely used standard for modelling business processes. While automated planning has been proposed as a method for simulating and reasoning about BPMN workflows, most implementations remain incomplete or limited in scope. This project builds upon prior theoretical work to develop a functional pipeline that translates BPMN 2.0 diagrams into PDDL representations suitable for planning. The system supports core BPMN constructs, including tasks, events, sequence flows, and gateways, with initial support for parallel and inclusive gateway behaviour. Using a non-deterministic planner, we demonstrate how to generate and evaluate valid execution traces. Our implementation aims to bridge the gap between theory and practical tooling, providing a foundation for further exploration of translating business processes into well-defined plans.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5c06BPMN 2.0\u56fe\u8f6c\u6362\u4e3aPDDL\u8868\u793a\u7684\u529f\u80fd\u6027\u7ba1\u9053\uff0c\u652f\u6301\u6838\u5fc3BPMN\u6784\u9020\uff0c\u4f7f\u7528\u975e\u786e\u5b9a\u6027\u89c4\u5212\u5668\u751f\u6210\u6709\u6548\u6267\u884c\u8f68\u8ff9\u3002", "motivation": "\u867d\u7136\u81ea\u52a8\u89c4\u5212\u5df2\u88ab\u63d0\u51fa\u4f5c\u4e3a\u6a21\u62df\u548c\u63a8\u7406BPMN\u5de5\u4f5c\u6d41\u7684\u65b9\u6cd5\uff0c\u4f46\u5927\u591a\u6570\u5b9e\u73b0\u4ecd\u4e0d\u5b8c\u6574\u6216\u8303\u56f4\u6709\u9650\u3002\u8be5\u9879\u76ee\u65e8\u5728\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u8df5\u5de5\u5177\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u57fa\u4e8e\u5148\u524d\u7406\u8bba\u5de5\u4f5c\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u5c06BPMN 2.0\u56fe\u8f6c\u6362\u4e3aPDDL\u8868\u793a\u7684\u529f\u80fd\u7ba1\u9053\uff0c\u652f\u6301\u4efb\u52a1\u3001\u4e8b\u4ef6\u3001\u5e8f\u5217\u6d41\u548c\u7f51\u5173\u7b49\u6838\u5fc3BPMN\u6784\u9020\uff0c\u521d\u6b65\u652f\u6301\u5e76\u884c\u548c\u5305\u5bb9\u7f51\u5173\u884c\u4e3a\u3002", "result": "\u4f7f\u7528\u975e\u786e\u5b9a\u6027\u89c4\u5212\u5668\u6210\u529f\u751f\u6210\u548c\u8bc4\u4f30\u4e86\u6709\u6548\u7684\u6267\u884c\u8f68\u8ff9\u3002", "conclusion": "\u8be5\u5b9e\u73b0\u4e3a\u5c06\u4e1a\u52a1\u6d41\u7a0b\u8f6c\u6362\u4e3a\u660e\u786e\u5b9a\u4e49\u7684\u89c4\u5212\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4e3a\u8fdb\u4e00\u6b65\u63a2\u7d22\u4e1a\u52a1\u6d41\u7a0b\u8f6c\u6362\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.18842", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18842", "abs": "https://arxiv.org/abs/2511.18842", "authors": ["Mohammad Nour Al Awad", "Sergey Ivanov", "Olga Tikhonova"], "title": "Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds", "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses", "summary": "Large Language Models (LLMs) have transformed code auto-completion by generating context-aware suggestions. Yet, deciding when to present these suggestions remains underexplored, often leading to interruptions or wasted inference calls. We propose an adaptive timing mechanism that dynamically adjusts the delay before offering a suggestion based on real-time developer feedback. Our suggested method combines a logistic transform of recent acceptance rates with a bounded delay range, anchored by a high-level binary prediction of the developer's cognitive state. In a two-month deployment with professional developers, our system improved suggestion acceptance from 4.9% with no delay to 15.4% with static delays, and to 18.6% with adaptive timing-while reducing blind rejections (rejections without being read) from 8.3% to 0.36%. Together, these improvements increase acceptance and substantially reduce wasted inference calls by 75%, making LLM-based code assistants more efficient and cost-effective in practice.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u65f6\u673a\u673a\u5236\uff0c\u6839\u636e\u5f00\u53d1\u8005\u5b9e\u65f6\u53cd\u9988\u52a8\u6001\u8c03\u6574\u4ee3\u7801\u5efa\u8bae\u7684\u5ef6\u8fdf\u65f6\u95f4\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u4ee3\u7801\u81ea\u52a8\u8865\u5168\u7684\u63a5\u53d7\u7387\u548c\u6548\u7387\u3002", "motivation": "\u5f53\u524dLLM\u4ee3\u7801\u81ea\u52a8\u8865\u5168\u7cfb\u7edf\u5728\u4f55\u65f6\u5448\u73b0\u5efa\u8bae\u65b9\u9762\u7f3a\u4e4f\u63a2\u7d22\uff0c\u7ecf\u5e38\u5bfc\u81f4\u4e2d\u65ad\u6216\u6d6a\u8d39\u63a8\u7406\u8c03\u7528\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u65f6\u673a\u51b3\u7b56\u673a\u5236\u3002", "method": "\u7ed3\u5408\u903b\u8f91\u53d8\u6362\u7684\u8fd1\u671f\u63a5\u53d7\u7387\u548c\u6709\u754c\u5ef6\u8fdf\u8303\u56f4\uff0c\u57fa\u4e8e\u5f00\u53d1\u8005\u8ba4\u77e5\u72b6\u6001\u7684\u9ad8\u5c42\u4e8c\u5143\u9884\u6d4b\u6765\u52a8\u6001\u8c03\u6574\u5efa\u8bae\u5ef6\u8fdf\u65f6\u95f4\u3002", "result": "\u5728\u4e24\u4e2a\u6708\u4e13\u4e1a\u5f00\u53d1\u8005\u90e8\u7f72\u4e2d\uff0c\u63a5\u53d7\u7387\u4ece\u65e0\u5ef6\u8fdf\u76844.9%\u63d0\u5347\u5230\u9759\u6001\u5ef6\u8fdf\u768415.4%\uff0c\u518d\u5230\u81ea\u9002\u5e94\u65f6\u673a\u768418.6%\uff1b\u76f2\u76ee\u62d2\u7edd\u7387\u4ece8.3%\u964d\u81f30.36%\uff0c\u6d6a\u8d39\u63a8\u7406\u8c03\u7528\u51cf\u5c1175%\u3002", "conclusion": "\u81ea\u9002\u5e94\u65f6\u673a\u673a\u5236\u663e\u8457\u63d0\u9ad8\u4e86LLM\u4ee3\u7801\u52a9\u624b\u7684\u6548\u7387\u548c\u6210\u672c\u6548\u76ca\uff0c\u4f7f\u5176\u5728\u5b9e\u8df5\u4e2d\u66f4\u52a0\u5b9e\u7528\u3002"}}
{"id": "2511.18244", "categories": ["cs.AI", "cond-mat.mtrl-sci", "physics.ed-ph"], "pdf": "https://arxiv.org/pdf/2511.18244", "abs": "https://arxiv.org/abs/2511.18244", "authors": ["Zhiling Zheng"], "title": "Developing an AI Course for Synthetic Chemistry Students", "comment": "17 pages, 3 figures", "summary": "Artificial intelligence (AI) and data science are transforming chemical research, yet few formal courses are tailored to synthetic and experimental chemists, who often face steep entry barriers due to limited coding experience and lack of chemistry-specific examples. We present the design and implementation of AI4CHEM, an introductory data-driven chem-istry course created for students on the synthetic chemistry track with no prior programming background. The curricu-lum emphasizes chemical context over abstract algorithms, using an accessible web-based platform to ensure zero-install machine learning (ML) workflow development practice and in-class active learning. Assessment combines code-guided homework, literature-based mini-reviews, and collaborative projects in which students build AI-assisted workflows for real experimental problems. Learning gains include increased confidence with Python, molecular property prediction, reaction optimization, and data mining, and improved skills in evaluating AI tools in chemistry. All course materials are openly available, offering a discipline-specific, beginner-accessible framework for integrating AI into synthetic chemistry training.", "AI": {"tldr": "AI4CHEM\u662f\u4e00\u95e8\u4e3a\u5408\u6210\u5316\u5b66\u80cc\u666f\u5b66\u751f\u8bbe\u8ba1\u7684AI\u5165\u95e8\u8bfe\u7a0b\uff0c\u65e0\u9700\u7f16\u7a0b\u57fa\u7840\uff0c\u901a\u8fc7\u57fa\u4e8e\u7f51\u9875\u7684\u5e73\u53f0\u8fdb\u884c\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u5f00\u53d1\u5b9e\u8df5\uff0c\u7ed3\u5408\u5316\u5b66\u80cc\u666f\u6559\u5b66\u548c\u4e3b\u52a8\u5b66\u4e60\u3002", "motivation": "AI\u548c\u6570\u636e\u79d1\u5b66\u6b63\u5728\u6539\u53d8\u5316\u5b66\u7814\u7a76\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u5408\u6210\u548c\u5b9e\u9a8c\u5316\u5b66\u5bb6\u7684\u6b63\u5f0f\u8bfe\u7a0b\uff0c\u4ed6\u4eec\u901a\u5e38\u56e0\u7f16\u7801\u7ecf\u9a8c\u6709\u9650\u548c\u7f3a\u4e4f\u5316\u5b66\u7279\u5b9a\u793a\u4f8b\u800c\u9762\u4e34\u9ad8\u5165\u95e8\u95e8\u69db\u3002", "method": "\u8bfe\u7a0b\u8bbe\u8ba1\u5f3a\u8c03\u5316\u5b66\u80cc\u666f\u800c\u975e\u62bd\u8c61\u7b97\u6cd5\uff0c\u4f7f\u7528\u53ef\u8bbf\u95ee\u7684\u57fa\u4e8e\u7f51\u9875\u5e73\u53f0\u786e\u4fdd\u96f6\u5b89\u88c5\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u5f00\u53d1\u5b9e\u8df5\u548c\u8bfe\u5802\u4e3b\u52a8\u5b66\u4e60\uff0c\u8bc4\u4f30\u5305\u62ec\u4ee3\u7801\u6307\u5bfc\u4f5c\u4e1a\u3001\u6587\u732e\u5c0f\u578b\u7efc\u8ff0\u548c\u534f\u4f5c\u9879\u76ee\u3002", "result": "\u5b66\u4e60\u6210\u679c\u5305\u62ec\u63d0\u9ad8Python\u4fe1\u5fc3\u3001\u5206\u5b50\u6027\u8d28\u9884\u6d4b\u3001\u53cd\u5e94\u4f18\u5316\u548c\u6570\u636e\u6316\u6398\u80fd\u529b\uff0c\u4ee5\u53ca\u6539\u8fdb\u8bc4\u4f30\u5316\u5b66AI\u5de5\u5177\u7684\u6280\u80fd\u3002", "conclusion": "\u6240\u6709\u8bfe\u7a0b\u6750\u6599\u516c\u5f00\u53ef\u7528\uff0c\u4e3a\u5c06AI\u6574\u5408\u5230\u5408\u6210\u5316\u5b66\u57f9\u8bad\u4e2d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b66\u79d1\u7279\u5b9a\u3001\u521d\u5b66\u8005\u53ef\u8bbf\u95ee\u7684\u6846\u67b6\u3002"}}
{"id": "2511.18849", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18849", "abs": "https://arxiv.org/abs/2511.18849", "authors": ["Mohammad Nour Al Awad", "Sergey Ivanov", "Olga Tikhonova"], "title": "Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming", "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses", "summary": "Large Language Models (LLMs) are increasingly integrated into code editors to provide AI-powered code suggestions. Yet many of these suggestions are ignored, resulting in wasted computation, increased latency, and unnecessary interruptions. We introduce a lightweight pre-filtering model that predicts the likelihood of suggestion acceptance before invoking the LLM, using only real-time developer telemetry such as typing speed, file navigation, and editing activity. Deployed in a production-grade Visual Studio Code plugin over four months of naturalistic use, our approach nearly doubled acceptance rates (18.4% -> 34.2%) while suppressing 35% of low-value LLM calls. These findings demonstrate that behavioral signals alone can meaningfully improve both user experience and system efficiency in LLM-assisted programming, highlighting the value of timing-aware, privacy-preserving adaptation mechanisms. The filter operates solely on pre-invocation editor telemetry and never inspects code or prompts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u9884\u8fc7\u6ee4\u6a21\u578b\uff0c\u901a\u8fc7\u5f00\u53d1\u8005\u884c\u4e3a\u4fe1\u53f7\u9884\u6d4b\u4ee3\u7801\u5efa\u8bae\u63a5\u53d7\u7387\uff0c\u5728VS Code\u63d2\u4ef6\u4e2d\u90e8\u7f724\u4e2a\u6708\uff0c\u5c06\u63a5\u53d7\u7387\u4ece18.4%\u63d0\u5347\u81f334.2%\uff0c\u540c\u65f6\u51cf\u5c1135%\u7684\u4f4e\u4ef7\u503cLLM\u8c03\u7528\u3002", "motivation": "LLM\u5728\u4ee3\u7801\u7f16\u8f91\u5668\u4e2d\u7684\u8bb8\u591a\u5efa\u8bae\u88ab\u5ffd\u7565\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6d6a\u8d39\u3001\u5ef6\u8fdf\u589e\u52a0\u548c\u4e0d\u5fc5\u8981\u7684\u4e2d\u65ad\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u9884\u6d4b\u5efa\u8bae\u63a5\u53d7\u7387\u4ee5\u63d0\u9ad8\u7528\u6237\u4f53\u9a8c\u548c\u7cfb\u7edf\u6548\u7387\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u9884\u8fc7\u6ee4\u6a21\u578b\uff0c\u4ec5\u57fa\u4e8e\u5b9e\u65f6\u5f00\u53d1\u8005\u9065\u6d4b\u6570\u636e\uff08\u5982\u6253\u5b57\u901f\u5ea6\u3001\u6587\u4ef6\u5bfc\u822a\u548c\u7f16\u8f91\u6d3b\u52a8\uff09\u6765\u9884\u6d4b\u5efa\u8bae\u63a5\u53d7\u53ef\u80fd\u6027\uff0c\u5728\u8c03\u7528LLM\u4e4b\u524d\u8fdb\u884c\u8fc7\u6ee4\u3002", "result": "\u5728\u751f\u4ea7\u7ea7VS Code\u63d2\u4ef6\u4e2d\u90e8\u7f724\u4e2a\u6708\uff0c\u63a5\u53d7\u7387\u4ece18.4%\u63d0\u5347\u81f334.2%\uff0c\u540c\u65f6\u6291\u5236\u4e8635%\u7684\u4f4e\u4ef7\u503cLLM\u8c03\u7528\u3002", "conclusion": "\u4ec5\u51ed\u884c\u4e3a\u4fe1\u53f7\u5c31\u80fd\u663e\u8457\u6539\u5584LLM\u8f85\u52a9\u7f16\u7a0b\u4e2d\u7684\u7528\u6237\u4f53\u9a8c\u548c\u7cfb\u7edf\u6548\u7387\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u65f6\u5e8f\u611f\u77e5\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u9002\u914d\u673a\u5236\u7684\u4ef7\u503c\u3002"}}
{"id": "2511.18284", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18284", "abs": "https://arxiv.org/abs/2511.18284", "authors": ["Tetiana Bas", "Krystian Novak"], "title": "Steering Latent Traits, Not Learned Facts: An Empirical Study of Activation Control Limits", "comment": null, "summary": "Large language models (LLMs) require precise behavior control for safe and effective deployment across diverse applications.\n  Activation steering offers a promising approach for LLMs' behavioral control. We focus on the question of how steering effectiveness varies across different behavior types and whether the nature of target behaviors can predict steering success. We address this through empirical analysis of activation steering across 50 behaviors that span persona archetypes, personality traits, misalignment behaviors, style cues, and impersonation of public figures. We present a set of comprehensive experiments on coefficient optimization, vector properties, and data requirements to provide comprehensive guidance for the implementation of activation steering. Our analysis demonstrates that steering effectiveness varies significantly by behavior type, with different behavioral categories exhibiting distinct response patterns to intervention strength. We find that trait expression follows an inverted-U curve with a steering coefficient strength. We also show that vector separation metrics do not predict steering success, but larger training datasets enable more aggressive steering. These findings provide empirically grounded guidance for implementing activation steering and demonstrate that steering effectiveness is heavily influenced by behavior type.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u5206\u679050\u79cd\u884c\u4e3a\u7c7b\u578b\u7684\u6fc0\u6d3b\u5f15\u5bfc\u6548\u679c\uff0c\u53d1\u73b0\u5f15\u5bfc\u6548\u679c\u56e0\u884c\u4e3a\u7c7b\u578b\u800c\u5f02\uff0c\u4e0d\u540c\u884c\u4e3a\u7c7b\u522b\u5bf9\u5e72\u9884\u5f3a\u5ea6\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u54cd\u5e94\u6a21\u5f0f\uff0c\u5176\u4e2d\u7279\u8d28\u8868\u8fbe\u9075\u5faa\u5012U\u578b\u66f2\u7ebf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9700\u8981\u7cbe\u786e\u7684\u884c\u4e3a\u63a7\u5236\u4ee5\u786e\u4fdd\u5b89\u5168\u6709\u6548\u90e8\u7f72\uff0c\u6fc0\u6d3b\u5f15\u5bfc\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u63a7\u5236\u65b9\u6cd5\uff0c\u4f46\u9700\u8981\u4e86\u89e3\u4e0d\u540c\u884c\u4e3a\u7c7b\u578b\u7684\u5f15\u5bfc\u6548\u679c\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u7cfb\u6570\u4f18\u5316\u3001\u5411\u91cf\u5c5e\u6027\u548c\u6570\u636e\u9700\u6c42\u7684\u7efc\u5408\u5b9e\u9a8c\uff0c\u5206\u6790\u6fc0\u6d3b\u5f15\u5bfc\u572850\u79cd\u884c\u4e3a\u7c7b\u578b\uff08\u5305\u62ec\u4eba\u683c\u539f\u578b\u3001\u4e2a\u6027\u7279\u5f81\u3001\u9519\u4f4d\u884c\u4e3a\u3001\u98ce\u683c\u7ebf\u7d22\u548c\u516c\u4f17\u4eba\u7269\u6a21\u4eff\uff09\u4e2d\u7684\u6548\u679c\u3002", "result": "\u5f15\u5bfc\u6548\u679c\u56e0\u884c\u4e3a\u7c7b\u578b\u663e\u8457\u4e0d\u540c\uff0c\u7279\u8d28\u8868\u8fbe\u4e0e\u5f15\u5bfc\u7cfb\u6570\u5f3a\u5ea6\u5448\u5012U\u578b\u5173\u7cfb\uff0c\u5411\u91cf\u5206\u79bb\u6307\u6807\u4e0d\u80fd\u9884\u6d4b\u5f15\u5bfc\u6210\u529f\uff0c\u4f46\u66f4\u5927\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u652f\u6301\u66f4\u6fc0\u8fdb\u7684\u5f15\u5bfc\u3002", "conclusion": "\u6fc0\u6d3b\u5f15\u5bfc\u7684\u6548\u679c\u53d7\u884c\u4e3a\u7c7b\u578b\u5f71\u54cd\u5f88\u5927\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u5b9e\u65bd\u6fc0\u6d3b\u5f15\u5bfc\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6307\u5bfc\uff0c\u8868\u660e\u9700\u8981\u6839\u636e\u5177\u4f53\u884c\u4e3a\u7c7b\u578b\u8c03\u6574\u5f15\u5bfc\u7b56\u7565\u3002"}}
{"id": "2511.18854", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18854", "abs": "https://arxiv.org/abs/2511.18854", "authors": ["Yujing Wang", "Weize Hong"], "title": "Time Travel: LLM-Assisted Semantic Behavior Localization with Git Bisect", "comment": "submitted to Git Bisect SCALCOM 2025 Calgary (to be published)", "summary": "We present a novel framework that integrates Large Language Models (LLMs) into the Git bisect process for semantic fault localization. Traditional bisect assumes deterministic predicates and binary failure states assumptions often violated in modern software development due to flaky tests, nonmonotonic regressions, and semantic divergence from upstream repositories. Our system augments bisect traversal with structured chain of thought reasoning, enabling commit by commit analysis under noisy conditions. We evaluate multiple open source and proprietary LLMs for their suitability and fine tune DeepSeekCoderV2 using QLoRA on a curated dataset of semantically labeled diffs. We adopt a weak supervision workflow to reduce annotation overhead, incorporating human in the loop corrections and self consistency filtering. Experiments across multiple open source projects show a 6.4 point absolute gain in success rate from 74.2 to 80.6 percent, leading to significantly fewer failed traversals and by experiment up to 2x reduction in average bisect time. We conclude with discussions on temporal reasoning, prompt design, and finetuning strategies tailored for commit level behavior analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230Git bisect\u8fc7\u7a0b\u4e2d\u7684\u8bed\u4e49\u6545\u969c\u5b9a\u4f4d\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u63a8\u7406\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u8fdb\u884c\u9010\u63d0\u4ea4\u5206\u6790\uff0c\u5728\u591a\u4e2a\u5f00\u6e90\u9879\u76ee\u4e2d\u5b9e\u73b0\u4e866.4\u4e2a\u767e\u5206\u70b9\u7684\u6210\u529f\u7387\u63d0\u5347\u3002", "motivation": "\u4f20\u7edfbisect\u65b9\u6cd5\u5047\u8bbe\u786e\u5b9a\u6027\u8c13\u8bcd\u548c\u4e8c\u5143\u6545\u969c\u72b6\u6001\uff0c\u4f46\u5728\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e38\u56e0\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u3001\u975e\u5355\u8c03\u56de\u5f52\u548c\u4e0e\u4e0a\u6e38\u4ed3\u5e93\u7684\u8bed\u4e49\u5206\u6b67\u800c\u5931\u6548\u3002", "method": "\u4f7f\u7528\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u63a8\u7406\u589e\u5f3abisect\u904d\u5386\uff0c\u8bc4\u4f30\u591a\u4e2aLLM\u5e76\u5fae\u8c03DeepSeekCoderV2\uff0c\u91c7\u7528\u5f31\u76d1\u7763\u5de5\u4f5c\u6d41\u51cf\u5c11\u6807\u6ce8\u5f00\u9500\uff0c\u7ed3\u5408\u4eba\u5de5\u6821\u6b63\u548c\u81ea\u4e00\u81f4\u6027\u8fc7\u6ee4\u3002", "result": "\u5728\u591a\u4e2a\u5f00\u6e90\u9879\u76ee\u4e2d\uff0c\u6210\u529f\u7387\u4ece74.2%\u63d0\u5347\u523080.6%\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5931\u8d25\u904d\u5386\u6b21\u6570\uff0c\u5e73\u5747bisect\u65f6\u95f4\u6700\u591a\u51cf\u5c112\u500d\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u65f6\u5e8f\u63a8\u7406\u3001\u63d0\u793a\u8bbe\u8ba1\u548c\u9488\u5bf9\u63d0\u4ea4\u7ea7\u884c\u4e3a\u5206\u6790\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u4e3a\u8bed\u4e49\u6545\u969c\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18296", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18296", "abs": "https://arxiv.org/abs/2511.18296", "authors": ["Iman Rahimi"], "title": "Deep Learning Decision Support System for Open-Pit Mining Optimisation: GPU-Accelerated Planning Under Geological Uncertainty", "comment": "67 pages", "summary": "This study presents Part II of an AI-enhanced Decision Support System (DSS), extending Rahimi (2025, Part I) by introducing a fully uncertainty-aware optimization framework for long-term open-pit mine planning. Geological uncertainty is modelled using a Variational Autoencoder (VAE) trained on 50,000 spatial grade samples, enabling the generation of probabilistic, multi-scenario orebody realizations that preserve geological continuity and spatial correlation. These scenarios are optimized through a hybrid metaheuristic engine integrating Genetic Algorithms (GA), Large Neighborhood Search (LNS), Simulated Annealing (SA), and reinforcement-learning-based adaptive control. An \u03b5-constraint relaxation strategy governs the population exploration phase, allowing near-feasible schedule discovery early in the search and gradual tightening toward strict constraint satisfaction. GPU-parallel evaluation enables the simultaneous assessment of 65,536 geological scenarios, achieving near-real-time feasibility analysis. Results demonstrate up to 1.2 million-fold runtime improvement over IBM CPLEX and significantly higher expected NPV under geological uncertainty, confirming the DSS as a scalable and uncertainty-resilient platform for intelligent mine planning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u5168\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u957f\u671f\u9732\u5929\u77ff\u89c4\u5212\uff0c\u901a\u8fc7\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5efa\u6a21\u5730\u8d28\u4e0d\u786e\u5b9a\u6027\uff0c\u7ed3\u5408\u6df7\u5408\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u8fdb\u884c\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u8fd0\u884c\u65f6\u95f4\u6539\u8fdb\u548c\u66f4\u9ad8\u7684\u9884\u671f\u51c0\u73b0\u503c\u3002", "motivation": "\u6269\u5c55Rahimi (2025, Part I)\u7684\u7814\u7a76\uff0c\u89e3\u51b3\u957f\u671f\u9732\u5929\u77ff\u89c4\u5212\u4e2d\u7684\u5730\u8d28\u4e0d\u786e\u5b9a\u6027\u6311\u6218\uff0c\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u591a\u573a\u666f\u5730\u8d28\u5b9e\u73b0\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u751f\u6210\u6982\u7387\u6027\u591a\u573a\u666f\u77ff\u4f53\u5b9e\u73b0\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u3001\u5927\u90bb\u57df\u641c\u7d22\u3001\u6a21\u62df\u9000\u706b\u548c\u5f3a\u5316\u5b66\u4e60\u81ea\u9002\u5e94\u63a7\u5236\u7684\u6df7\u5408\u5143\u542f\u53d1\u5f0f\u5f15\u64ce\uff0c\u91c7\u7528\u03b5\u7ea6\u675f\u677e\u5f1b\u7b56\u7565\u548cGPU\u5e76\u884c\u8bc4\u4f30\u3002", "result": "\u76f8\u6bd4IBM CPLEX\u5b9e\u73b0\u4e86\u9ad8\u8fbe120\u4e07\u500d\u7684\u8fd0\u884c\u65f6\u95f4\u6539\u8fdb\uff0c\u5728\u5730\u8d28\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u83b7\u5f97\u663e\u8457\u66f4\u9ad8\u7684\u9884\u671f\u51c0\u73b0\u503c\uff0c\u652f\u630165,536\u4e2a\u5730\u8d28\u573a\u666f\u7684\u5e76\u884c\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u88ab\u8bc1\u660e\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u5bf9\u4e0d\u786e\u5b9a\u6027\u5177\u6709\u5f39\u6027\u7684\u667a\u80fd\u77ff\u5c71\u89c4\u5212\u5e73\u53f0\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5730\u8d28\u4e0d\u786e\u5b9a\u6027\u5e76\u4f18\u5316\u957f\u671f\u89c4\u5212\u51b3\u7b56\u3002"}}
{"id": "2511.18867", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18867", "abs": "https://arxiv.org/abs/2511.18867", "authors": ["Liutong Han", "Chu Kang", "Mingjie Xing", "Yanjun Wu"], "title": "VecIntrinBench: Benchmarking Cross-Architecture Intrinsic Code Migration for RISC-V Vector", "comment": "5 pages, 7 figures", "summary": "Intrinsic functions are specialized functions provided by the compiler that efficiently operate on architecture-specific hardware, allowing programmers to write optimized code in a high-level language that fully exploits hardware features. Using intrinsics to vectorize core code blocks is a standard optimization method in high-performance libraries, often requiring specific vector optimization implementations for multiple mainstream architectures. The promising RISC-V software ecosystem has a significant demand for algorithm library migration and adaptation. Translating existing intrinsic functions to RISC-V Vector (RVV) intrinsic functions across architectures is currently a mainstream approach. Rule-based intrinsic mapping methods and LLM-based code generation can help developers address the code migration challenge. However, existing intrinsic code benchmarks focus on mainstream SIMD intrinsics and lack support for the emerging RISC-V architecture. There is currently no benchmark that comprehensively evaluates the intrinsic migration capabilities for the RVV extension. To fill this gap, we propose VecIntrinBench, the first intrinsic benchmark encompassing RVV extensions. It includes 50 function-level tasks from open source repositories, implemented as scalars, RVV intrinsics, Arm Neon intrinsics, and x86 intrinsics, along with comprehensive functional and performance test cases. We systematically evaluated various code migration approaches on VecIntrinBench, yielding a series of insightful findings. The results demonstrate that advanced Large Language Models (LLMs) achieve a similar effect as rule-based mapping approaches for RISC-V code migration, while also delivering superior performance. We further analyze the reasons and identify future directions for LLM development in the code migration field. The VecIntrinBench is open-sourced to benefit the broader community and developers.", "AI": {"tldr": "VecIntrinBench\u662f\u9996\u4e2a\u5305\u542bRISC-V Vector\u6269\u5c55\u7684\u5185\u5728\u51fd\u6570\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b50\u4e2a\u51fd\u6570\u7ea7\u4efb\u52a1\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5404\u79cd\u4ee3\u7801\u8fc1\u79fb\u65b9\u6cd5\uff0c\u53d1\u73b0\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u5728RISC-V\u4ee3\u7801\u8fc1\u79fb\u4e2d\u80fd\u8fbe\u5230\u4e0e\u57fa\u4e8e\u89c4\u5219\u7684\u6620\u5c04\u65b9\u6cd5\u76f8\u4f3c\u6548\u679c\u4e14\u6027\u80fd\u66f4\u4f18\u3002", "motivation": "RISC-V\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u5bf9\u7b97\u6cd5\u5e93\u8fc1\u79fb\u6709\u5f3a\u70c8\u9700\u6c42\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u652f\u6301\u65b0\u5174RISC-V\u67b6\u6784\u7684\u5185\u5728\u51fd\u6570\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7279\u522b\u662f\u6ca1\u6709\u5168\u9762\u8bc4\u4f30RVV\u6269\u5c55\u5185\u5728\u51fd\u6570\u8fc1\u79fb\u80fd\u529b\u7684\u57fa\u51c6\u3002", "method": "\u63d0\u51faVecIntrinBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b50\u4e2a\u6765\u81ea\u5f00\u6e90\u4ed3\u5e93\u7684\u51fd\u6570\u7ea7\u4efb\u52a1\uff0c\u5b9e\u73b0\u4e3a\u6807\u91cf\u3001RVV\u5185\u5728\u51fd\u6570\u3001Arm Neon\u5185\u5728\u51fd\u6570\u548cx86\u5185\u5728\u51fd\u6570\uff0c\u5e76\u63d0\u4f9b\u5168\u9762\u7684\u529f\u80fd\u548c\u6027\u80fd\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u7cfb\u7edf\u8bc4\u4f30\u663e\u793a\uff0c\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u5728RISC-V\u4ee3\u7801\u8fc1\u79fb\u4e2d\u80fd\u8fbe\u5230\u4e0e\u57fa\u4e8e\u89c4\u5219\u7684\u6620\u5c04\u65b9\u6cd5\u76f8\u4f3c\u6548\u679c\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u4f18\u6027\u80fd\u3002", "conclusion": "VecIntrinBench\u586b\u8865\u4e86RVV\u6269\u5c55\u5185\u5728\u51fd\u6570\u8fc1\u79fb\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u793e\u533a\u548c\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\uff0c\u5e76\u6307\u51fa\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u8fc1\u79fb\u9886\u57df\u7684\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2511.18379", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.18379", "abs": "https://arxiv.org/abs/2511.18379", "authors": ["Andreea Elena Dr\u0103gnoiu", "Andrei Ciobanu", "Ruxandra F. Olimid"], "title": "On Addressing Isolation in Blockchain-Based Self-Sovereign Identity", "comment": null, "summary": "Self-Sovereign Identity (SSI) grants holders full ownership and control of their digital identities, being the ultimate digital identity model. Operating in a decentralized manner, SSI enables the verification of claims, including privacy-preserving mechanisms. Blockchain, which can be used to implement a Verifiable Data Registry (VDR), is often considered one of the pillars of SSI, along with Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs). Unfortunately, blockchains are mostly siloed, affecting the interoperability and universality of SSI. We investigate the effect of blockchain isolation on blockchain-based SSI. We first define possible scenarios for cross-chain SSI and exemplify with real-life use cases. We then define specific requirements for cross-chain SSI and identify challenges, also in relation to the identified scenarios. We explore various solutions to achieve blockchain interoperability, with a focus on SSI. In particular, we identify the advantages and disadvantages of distinct cross-chain models for cross-chain SSI. Finally, we address the usability of cross-chain SSI and discuss security and privacy aspects, opening the way for future research.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u533a\u5757\u94fe\u9694\u79bb\u5bf9\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u81ea\u8ba4\u8bc1\u8eab\u4efd\uff08SSI\uff09\u7684\u5f71\u54cd\uff0c\u5b9a\u4e49\u8de8\u94feSSI\u573a\u666f\u548c\u9700\u6c42\uff0c\u63a2\u7d22\u533a\u5757\u94fe\u4e92\u64cd\u4f5c\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5206\u6790\u8de8\u94feSSI\u7684\u53ef\u7528\u6027\u3001\u5b89\u5168\u6027\u548c\u9690\u79c1\u95ee\u9898\u3002", "motivation": "\u533a\u5757\u94fe\u901a\u5e38\u662f\u5b64\u7acb\u7684\uff0c\u8fd9\u5f71\u54cd\u4e86SSI\u7684\u4e92\u64cd\u4f5c\u6027\u548c\u666e\u904d\u6027\u3002\u4f5c\u8005\u65e8\u5728\u7814\u7a76\u533a\u5757\u94fe\u9694\u79bb\u5bf9\u57fa\u4e8e\u533a\u5757\u94fe\u7684SSI\u7684\u5f71\u54cd\uff0c\u5e76\u4e3a\u5b9e\u73b0\u8de8\u94feSSI\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u9996\u5148\u5b9a\u4e49\u8de8\u94feSSI\u7684\u53ef\u80fd\u573a\u666f\u5e76\u7528\u5b9e\u9645\u7528\u4f8b\u8fdb\u884c\u793a\u4f8b\uff0c\u7136\u540e\u5b9a\u4e49\u8de8\u94feSSI\u7684\u5177\u4f53\u9700\u6c42\u5e76\u8bc6\u522b\u6311\u6218\uff0c\u63a5\u7740\u63a2\u7d22\u5b9e\u73b0\u533a\u5757\u94fe\u4e92\u64cd\u4f5c\u6027\u7684\u5404\u79cd\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u5173\u6ce8SSI\u5e94\u7528\u3002", "result": "\u8bc6\u522b\u4e86\u4e0d\u540c\u8de8\u94fe\u6a21\u578b\u5728\u8de8\u94feSSI\u4e2d\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u5206\u6790\u4e86\u8de8\u94feSSI\u7684\u53ef\u7528\u6027\u4ee5\u53ca\u5b89\u5168\u6027\u548c\u9690\u79c1\u65b9\u9762\u7684\u95ee\u9898\u3002", "conclusion": "\u4e3a\u8de8\u94feSSI\u7684\u672a\u6765\u7814\u7a76\u5f00\u8f9f\u4e86\u9053\u8def\uff0c\u5f3a\u8c03\u4e86\u89e3\u51b3\u533a\u5757\u94fe\u4e92\u64cd\u4f5c\u6027\u5bf9\u4e8e\u5b9e\u73b0\u771f\u6b63\u666e\u904d\u548c\u53ef\u4e92\u64cd\u4f5c\u7684SSI\u7cfb\u7edf\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.18918", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18918", "abs": "https://arxiv.org/abs/2511.18918", "authors": ["Qingchao Shen", "Zan Wang", "Haoyang Ma", "Yongqiang Tian", "Lili Huang", "Zibo Xiao", "Junjie Chen", "Shing-Chi Cheung"], "title": "Optimization-Aware Test Generation for Deep Learning Compilers", "comment": "This paper has been accpected by ICSE 2026", "summary": "Deep Learning (DL) compilers have been widely utilized to optimize DL models for efficient deployment across various hardware. Due to their vital role in the DL ecosystem, ensuring their reliability and security is critical. However, existing approaches have limitations in testing optimization stages, which is the core functionality of DL compilers, due to the difficulty in generating optimization-aware tests. In this paper, we proposed OATest, a novel approach for synthesizing optimization-aware computational graphs. The approach combines patterns extracted from documented tests for optimization and incorporates them into seed computational graphs, enabling broader exploration of optimization paths. To guarantee the optimization-awareness of generated graphs, OATest introduces the edges reusing strategy to establish strong connections between patterns and contexts. Additionally, to solve the validity challenge for the generated graphs, OATest employs an auxiliary layers addition strategy to resolve broken constraints. Equipped with two distinct test oracles, OATest applies differential testing to evaluate the two widely used DL compilers (i.e., TVM and ONNXRuntime). Our experimental results show that OATest outperforms the state-of-the-art method by detecting more bugs and achieving higher code coverage in TVM and ONNXRutimes. Additionally, OATest uncovers 58 previously unknown bugs, 36 of which have been confirmed or fixed by developers.", "AI": {"tldr": "OATest\u662f\u4e00\u79cd\u9488\u5bf9\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u7684\u4f18\u5316\u611f\u77e5\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u6210\u4f18\u5316\u611f\u77e5\u8ba1\u7b97\u56fe\u6765\u68c0\u6d4b\u7f16\u8bd1\u5668\u4e2d\u7684\u9519\u8bef\uff0c\u5728TVM\u548cONNXRuntime\u4e0a\u53d1\u73b0\u4e8658\u4e2a\u672a\u77e5\u9519\u8bef\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u5728DL\u751f\u6001\u7cfb\u7edf\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6d4b\u8bd5\u4f18\u5316\u9636\u6bb5\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u96be\u4ee5\u751f\u6210\u4f18\u5316\u611f\u77e5\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002", "method": "OATest\u901a\u8fc7\u4ece\u6587\u6863\u5316\u6d4b\u8bd5\u4e2d\u63d0\u53d6\u6a21\u5f0f\uff0c\u5c06\u5176\u878d\u5165\u79cd\u5b50\u8ba1\u7b97\u56fe\u4e2d\uff0c\u91c7\u7528\u8fb9\u91cd\u7528\u7b56\u7565\u5efa\u7acb\u6a21\u5f0f\u4e0e\u4e0a\u4e0b\u6587\u4e4b\u95f4\u7684\u5f3a\u8fde\u63a5\uff0c\u5e76\u4f7f\u7528\u8f85\u52a9\u5c42\u6dfb\u52a0\u7b56\u7565\u89e3\u51b3\u7ea6\u675f\u7834\u574f\u95ee\u9898\u3002", "result": "OATest\u5728TVM\u548cONNXRuntime\u4e0a\u68c0\u6d4b\u5230\u66f4\u591a\u9519\u8bef\uff0c\u8fbe\u5230\u66f4\u9ad8\u7684\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u53d1\u73b0\u4e8658\u4e2a\u672a\u77e5\u9519\u8bef\uff0c\u5176\u4e2d36\u4e2a\u5df2\u88ab\u5f00\u53d1\u8005\u786e\u8ba4\u6216\u4fee\u590d\u3002", "conclusion": "OATest\u662f\u4e00\u79cd\u6709\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u4f18\u5316\u611f\u77e5\u7684\u8ba1\u7b97\u56fe\uff0c\u663e\u8457\u63d0\u5347\u7f16\u8bd1\u5668\u6d4b\u8bd5\u7684\u6548\u679c\u3002"}}
{"id": "2511.18412", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.18412", "abs": "https://arxiv.org/abs/2511.18412", "authors": ["Dilli Babu Porlapothula", "Pralay Chakrabarty", "Ananya Lakshmi Ravi", "Kurian Polachan"], "title": "ioPUF+: A PUF Based on I/O Pull-Up/Down Resistors for Secret Key Generation in IoT Nodes", "comment": null, "summary": "In this work, we present ioPUF+, which incorporates a novel Physical Unclonable Function (PUF) that generates unique fingerprints for Integrated Circuits (ICs) and the IoT nodes encompassing them. The proposed PUF generates device-specific responses by measuring the pull-up and pull-down resistor values on the I/O pins of the ICs, which naturally vary across chips due to manufacturing-induced process variations. Since these resistors are already integrated into the I/O structures of most ICs, ioPUF+ requires no custom circuitry, and no new IC fabrication. This makes ioPUF+ suitable for cost-sensitive embedded systems built from Commercial Off-The-Shelf (COTS) components. Beyond introducing a new PUF, ioPUF+ includes a complete datapath for converting raw PUF responses into cryptographically usable secret keys using BCH error correction and SHA-256 hashing. Further ioPUF+ also demonstrate a practical use case of PUF derive secret keys in securing device-to-device communication using AES-encryption. We implemented ioPUF+ on the Infineon PSoC-5 microcontroller and evaluated its performance across 30 devices using standard PUF metrics. The results show excellent reliability (intra-device Hamming distance of 100.00%), strong uniqueness (inter-device Hamming distance of 50.33%), near-ideal uniformity (50.54%), and negligible bit aliasing. Stability tests under temperature and supply-voltage variations show worst-case bit-error rates of only 2.63% and 2.10%, respectively. We also profiled the resource and energy usage of the complete ioPUF+ system, including the PUF primitive, BCH decoding, SHA-256 hashing, and AES encryption. The full implementation requires only 19.8 KB of Flash, exhibits a latency of 600 ms, and consumes 79 mW of power, demonstrating the suitabilitiy of ioPUF+ for resource-constrained IoT nodes.", "AI": {"tldr": "ioPUF+\u662f\u4e00\u79cd\u57fa\u4e8eI/O\u5f15\u811a\u7535\u963b\u503c\u7684\u7269\u7406\u4e0d\u53ef\u514b\u9686\u51fd\u6570(PUF)\uff0c\u5229\u7528\u5236\u9020\u5de5\u827a\u53d8\u5316\u751f\u6210\u8bbe\u5907\u552f\u4e00\u6307\u7eb9\uff0c\u65e0\u9700\u5b9a\u5236\u7535\u8def\u5373\u53ef\u4e3aCOTS\u7ec4\u4ef6\u63d0\u4f9b\u5b89\u5168\u5bc6\u94a5\u751f\u6210\u548c\u52a0\u5bc6\u901a\u4fe1\u529f\u80fd\u3002", "motivation": "\u4e3a\u6210\u672c\u654f\u611f\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u548c\u7269\u8054\u7f51\u8282\u70b9\u63d0\u4f9b\u65e0\u9700\u5b9a\u5236\u7535\u8def\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528\u73b0\u6709IC\u7684I/O\u7ed3\u6784\u5b9e\u73b0\u8bbe\u5907\u8ba4\u8bc1\u548c\u5bc6\u94a5\u751f\u6210\u3002", "method": "\u901a\u8fc7\u6d4b\u91cfIC I/O\u5f15\u811a\u7684\u4e0a\u62c9\u548c\u4e0b\u62c9\u7535\u963b\u503c\u751f\u6210PUF\u54cd\u5e94\uff0c\u7ed3\u5408BCH\u7ea0\u9519\u548cSHA-256\u54c8\u5e0c\u5c06\u539f\u59cb\u54cd\u5e94\u8f6c\u6362\u4e3a\u52a0\u5bc6\u5bc6\u94a5\uff0c\u5e76\u5b9e\u73b0AES\u52a0\u5bc6\u7684\u7aef\u5230\u7aef\u5b89\u5168\u901a\u4fe1\u3002", "result": "\u572830\u4e2a\u8bbe\u5907\u4e0a\u8bc4\u4f30\u663e\u793a\uff1a100%\u53ef\u9760\u6027\u300150.33%\u72ec\u7279\u6027\u300150.54%\u5747\u5300\u6027\uff0c\u6e29\u5ea6\u548c\u7535\u538b\u53d8\u5316\u4e0b\u7684\u6700\u5dee\u8bef\u7801\u7387\u5206\u522b\u4e3a2.63%\u548c2.10%\uff0c\u5b8c\u6574\u7cfb\u7edf\u4ec5\u970019.8KB Flash\u3001600ms\u5ef6\u8fdf\u548c79mW\u529f\u8017\u3002", "conclusion": "ioPUF+\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u7269\u8054\u7f51\u8282\u70b9\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528\u73b0\u6709IC\u7ec4\u4ef6\u5b9e\u73b0\u5f3a\u5927\u7684\u8bbe\u5907\u8ba4\u8bc1\u548c\u52a0\u5bc6\u901a\u4fe1\u80fd\u529b\u3002"}}
{"id": "2511.18302", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18302", "abs": "https://arxiv.org/abs/2511.18302", "authors": ["Mohan Reddy"], "title": "The Catastrophic Paradox of Human Cognitive Frameworks in Large Language Model Evaluation: A Comprehensive Empirical Analysis of the CHC-LLM Incompatibility", "comment": null, "summary": "This investigation presents an empirical analysis of the incompatibility between human psychometric frameworks and Large Language Model evaluation. Through systematic assessment of nine frontier models including GPT-5, Claude Opus 4.1, and Gemini 3 Pro Preview using the Cattell-Horn-Carroll theory of intelligence, we identify a paradox that challenges the foundations of cross-substrate cognitive evaluation. Our results show that models achieving above-average human IQ scores ranging from 85.0 to 121.4 simultaneously exhibit binary accuracy rates approaching zero on crystallized knowledge tasks, with an overall judge-binary correlation of r = 0.175 (p = 0.001, n = 1800). This disconnect appears most strongly in the crystallized intelligence domain, where every evaluated model achieved perfect binary accuracy while judge scores ranged from 25 to 62 percent, which cannot occur under valid measurement conditions. Using statistical analyses including Item Response Theory modeling, cross-vendor judge validation, and paradox severity indexing, we argue that this disconnect reflects a category error in applying biological cognitive architectures to transformer-based systems. The implications extend beyond methodology to challenge assumptions about intelligence, measurement, and anthropomorphic biases in AI evaluation. We propose a framework for developing native machine cognition assessments that recognize the non-human nature of artificial intelligence.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0\u4eba\u7c7b\u5fc3\u7406\u6d4b\u91cf\u6846\u67b6\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e4b\u95f4\u5b58\u5728\u4e0d\u517c\u5bb9\u6027\uff0c\u6a21\u578b\u5728\u83b7\u5f97\u9ad8\u4e8e\u5e73\u5747\u4eba\u7c7bIQ\u5206\u6570\u7684\u540c\u65f6\uff0c\u5728\u5177\u4f53\u77e5\u8bc6\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u63a5\u8fd1\u96f6\uff0c\u63ed\u793a\u4e86\u8de8\u57fa\u8d28\u8ba4\u77e5\u8bc4\u4f30\u7684\u6839\u672c\u6096\u8bba\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u4eba\u7c7b\u5fc3\u7406\u6d4b\u91cf\u7406\u8bba\uff08\u7279\u522b\u662fCattell-Horn-Carroll\u667a\u529b\u7406\u8bba\uff09\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u7684\u9002\u7528\u6027\uff0c\u8bc6\u522b\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e2d\u7684\u6839\u672c\u6027\u7f3a\u9677\u3002", "method": "\u4f7f\u7528\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5bf99\u4e2a\u524d\u6cbf\u6a21\u578b\uff08\u5305\u62ecGPT-5\u3001Claude Opus 4.1\u3001Gemini 3 Pro Preview\uff09\u5e94\u7528Cattell-Horn-Carroll\u667a\u529b\u7406\u8bba\uff0c\u91c7\u7528\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u5efa\u6a21\u3001\u8de8\u4f9b\u5e94\u5546\u8bc4\u59d4\u9a8c\u8bc1\u548c\u6096\u8bba\u4e25\u91cd\u6027\u6307\u6570\u7b49\u7edf\u8ba1\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6a21\u578b\u83b7\u5f9785.0-121.4\u7684\u4eba\u7c7bIQ\u5206\u6570\uff0c\u4f46\u5728\u5177\u4f53\u77e5\u8bc6\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u63a5\u8fd1\u96f6\uff0c\u8bc4\u59d4-\u4e8c\u8fdb\u5236\u76f8\u5173\u6027\u4ec5\u4e3ar=0.175\u3002\u5728\u6676\u4f53\u667a\u529b\u9886\u57df\uff0c\u6240\u6709\u6a21\u578b\u90fd\u83b7\u5f97\u5b8c\u7f8e\u4e8c\u8fdb\u5236\u51c6\u786e\u7387\uff0c\u800c\u8bc4\u59d4\u8bc4\u5206\u4ec5\u4e3a25-62%\uff0c\u8fd9\u5728\u6709\u6548\u6d4b\u91cf\u6761\u4ef6\u4e0b\u4e0d\u53ef\u80fd\u53d1\u751f\u3002", "conclusion": "\u8fd9\u79cd\u8131\u8282\u53cd\u6620\u4e86\u5c06\u751f\u7269\u8ba4\u77e5\u67b6\u6784\u5e94\u7528\u4e8e\u57fa\u4e8etransformer\u7cfb\u7edf\u7684\u7c7b\u522b\u9519\u8bef\uff0c\u6311\u6218\u4e86\u5173\u4e8e\u667a\u529b\u3001\u6d4b\u91cf\u548cAI\u8bc4\u4f30\u4e2d\u62df\u4eba\u5316\u504f\u89c1\u7684\u5047\u8bbe\uff0c\u63d0\u51fa\u4e86\u5f00\u53d1\u539f\u751f\u673a\u5668\u8ba4\u77e5\u8bc4\u4f30\u6846\u67b6\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2511.18924", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18924", "abs": "https://arxiv.org/abs/2511.18924", "authors": ["Arina Kharlamova", "Jiawen Liu", "Tianyi Zhang", "Xinrui Yang", "Humaid Alqasimi", "Youcheng Sun", "Chun Jason Xue"], "title": "LLM-Driven Kernel Evolution: Automating Driver Updates in Linux", "comment": null, "summary": "Linux kernel evolution breaks drivers through API/ABI changes, semantic shifts, and security-hardening updates. We introduce DRIVEBENCH, an executable corpus of kernel$\\rightarrow$driver co-evolution cases, and AUTODRIVER, a closed-loop, LLM-driven system for automating driver maintenance. The system integrates prompt engineering, multi-agent collaboration, static analysis, and iterative validation to ensure that generated patches are not only syntactically correct but also functionally and semantically consistent with kernel conventions. The corpus spans v5.10-v6.10 with 235 validated cases drawn from 612 candidates. In evaluation across 55 cases, AUTODRIVER achieves 56.4% compilation success; QEMU-based boot verification indicates that compiled patches preserve driver initialization in most instances. By releasing DRIVEBENCH and tooling, we enable reproducible research and a practical route to continuous, safe co-evolution of drivers with the Linux kernel.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86DRIVEBENCH\uff08\u5185\u6838\u2192\u9a71\u52a8\u7a0b\u5e8f\u534f\u540c\u6f14\u5316\u7684\u53ef\u6267\u884c\u8bed\u6599\u5e93\uff09\u548cAUTODRIVER\uff08\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u9a71\u52a8\u7a0b\u5e8f\u7ef4\u62a4\u7cfb\u7edf\uff09\uff0c\u7528\u4e8e\u89e3\u51b3Linux\u5185\u6838\u6f14\u5316\u5bfc\u81f4\u7684\u9a71\u52a8\u7a0b\u5e8f\u517c\u5bb9\u6027\u95ee\u9898\u3002", "motivation": "Linux\u5185\u6838\u6f14\u5316\u901a\u8fc7API/ABI\u53d8\u66f4\u3001\u8bed\u4e49\u8f6c\u79fb\u548c\u5b89\u5168\u52a0\u56fa\u66f4\u65b0\u7834\u574f\u9a71\u52a8\u7a0b\u5e8f\u517c\u5bb9\u6027\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u7ef4\u62a4\u9a71\u52a8\u7a0b\u5e8f\u3002", "method": "\u5f00\u53d1\u4e86DRIVEBENCH\u8bed\u6599\u5e93\uff08v5.10-v6.10\uff0c235\u4e2a\u9a8c\u8bc1\u6848\u4f8b\uff09\u548cAUTODRIVER\u7cfb\u7edf\uff0c\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u3001\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3001\u9759\u6001\u5206\u6790\u548c\u8fed\u4ee3\u9a8c\u8bc1\uff0c\u786e\u4fdd\u751f\u6210\u7684\u8865\u4e01\u5728\u8bed\u6cd5\u3001\u529f\u80fd\u548c\u8bed\u4e49\u4e0a\u90fd\u7b26\u5408\u5185\u6838\u7ea6\u5b9a\u3002", "result": "\u572855\u4e2a\u6848\u4f8b\u8bc4\u4f30\u4e2d\uff0cAUTODRIVER\u5b9e\u73b0\u4e8656.4%\u7684\u7f16\u8bd1\u6210\u529f\u7387\uff1b\u57fa\u4e8eQEMU\u7684\u542f\u52a8\u9a8c\u8bc1\u8868\u660e\u7f16\u8bd1\u540e\u7684\u8865\u4e01\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4fdd\u7559\u4e86\u9a71\u52a8\u7a0b\u5e8f\u521d\u59cb\u5316\u529f\u80fd\u3002", "conclusion": "\u901a\u8fc7\u53d1\u5e03DRIVEBENCH\u548c\u5de5\u5177\uff0c\u4e3a\u53ef\u91cd\u590d\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u652f\u6301\uff0c\u5e76\u4e3a\u9a71\u52a8\u7a0b\u5e8f\u4e0eLinux\u5185\u6838\u7684\u6301\u7eed\u3001\u5b89\u5168\u534f\u540c\u6f14\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2511.19059", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19059", "abs": "https://arxiv.org/abs/2511.19059", "authors": ["Pei Liu", "Terry Zhuo", "Jiawei Deng", "Thong James", "Shidong Pan", "Sherry Xu", "Zhenchang Xing", "Qinghua Lu", "Xiaoning Du", "Hongyu Zhang"], "title": "LLMAID: Identifying AI Capabilities in Android Apps with LLMs", "comment": null, "summary": "Recent advancements in artificial intelligence (AI) and its widespread integration into mobile software applications have received significant attention, highlighting the growing prominence of AI capabilities in modern software systems. However, the inherent hallucination and reliability issues of AI continue to raise persistent concerns. Consequently, application users and regulators increasingly ask critical questions such as: Does the application incorporate AI capabilities? and What specific types of AI functionalities are embedded? Preliminary efforts have been made to identify AI capabilities in mobile software; however, existing approaches mainly rely on manual inspection and rule-based heuristics. These methods are not only costly and time-consuming but also struggle to adapt advanced AI techniques.\n  To address the limitations of existing methods, we propose LLMAID (Large Language Model for AI Discovery). LLMAID includes four main tasks: (1) candidate extraction, (2) knowledge base interaction, (3) AI capability analysis and detection, and (4) AI service summarization. We apply LLMAID to a dataset of 4,201 Android applications and demonstrate that it identifies 242% more real-world AI apps than state-of-the-art rule-based approaches. Our experiments show that LLM4AID achieves high precision and recall, both exceeding 90%, in detecting AI-related components. Additionally, a user study indicates that developers find the AI service summaries generated by LLMAID to be more informative and preferable to the original app descriptions. Finally, we leverage LLMAID to perform an empirical analysis of AI capabilities across Android apps. The results reveal a strong concentration of AI functionality in computer vision (54.80%), with object detection emerging as the most common task (25.19%).", "AI": {"tldr": "\u63d0\u51fa\u4e86LLMAID\u65b9\u6cd5\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u68c0\u6d4b\u79fb\u52a8\u5e94\u7528\u4e2d\u7684AI\u80fd\u529b\uff0c\u76f8\u6bd4\u73b0\u6709\u89c4\u5219\u65b9\u6cd5\u80fd\u8bc6\u522b242%\u66f4\u591a\u7684\u771f\u5b9eAI\u5e94\u7528\uff0c\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u5747\u8d85\u8fc790%\u3002", "motivation": "\u73b0\u6709\u79fb\u52a8\u5e94\u7528AI\u80fd\u529b\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u68c0\u67e5\u548c\u89c4\u5219\u542f\u53d1\u5f0f\uff0c\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\u4e14\u96be\u4ee5\u9002\u5e94\u5148\u8fdbAI\u6280\u672f\uff0c\u9700\u8981\u66f4\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "LLMAID\u5305\u542b\u56db\u4e2a\u4e3b\u8981\u4efb\u52a1\uff1a\u5019\u9009\u63d0\u53d6\u3001\u77e5\u8bc6\u5e93\u4ea4\u4e92\u3001AI\u80fd\u529b\u5206\u6790\u4e0e\u68c0\u6d4b\u3001AI\u670d\u52a1\u603b\u7ed3\uff0c\u5e94\u7528\u4e8e4,201\u4e2aAndroid\u5e94\u7528\u6570\u636e\u96c6\u3002", "result": "\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u89c4\u5219\u65b9\u6cd5\uff0cLLMAID\u80fd\u8bc6\u522b242%\u66f4\u591a\u7684\u771f\u5b9eAI\u5e94\u7528\uff0cAI\u76f8\u5173\u7ec4\u4ef6\u68c0\u6d4b\u7684\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u5747\u8d85\u8fc790%\uff0c\u7528\u6237\u7814\u7a76\u663e\u793a\u5f00\u53d1\u8005\u66f4\u504f\u597dLLMAID\u751f\u6210\u7684AI\u670d\u52a1\u603b\u7ed3\u3002", "conclusion": "LLMAID\u80fd\u6709\u6548\u68c0\u6d4b\u79fb\u52a8\u5e94\u7528\u4e2d\u7684AI\u80fd\u529b\uff0c\u5b9e\u8bc1\u5206\u6790\u663e\u793aAI\u529f\u80fd\u4e3b\u8981\u96c6\u4e2d\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\uff0854.80%\uff09\uff0c\u5176\u4e2d\u76ee\u6807\u68c0\u6d4b\u662f\u6700\u5e38\u89c1\u4efb\u52a1\uff0825.19%\uff09\u3002"}}
{"id": "2511.19132", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19132", "abs": "https://arxiv.org/abs/2511.19132", "authors": ["Mohammad Abboush", "Ahmad Hatahet", "Andreas Rausch"], "title": "LLMs-Powered Real-Time Fault Injection: An Approach Toward Intelligent Fault Test Cases Generation", "comment": null, "summary": "A well-known testing method for the safety evaluation and real-time validation of automotive software systems (ASSs) is Fault Injection (FI). In accordance with the ISO 26262 standard, the faults are introduced artificially for the purpose of analyzing the safety properties and verifying the safety mechanisms during the development phase. However, the current FI method and tools have a significant limitation in that they require manual identification of FI attributes, including fault type, location and time. The more complex the system, the more expensive, time-consuming and labour-intensive the process. To address the aforementioned challenge, a novel Large Language Models (LLMs)-assisted fault test cases (TCs) generation approach for utilization during real-time FI tests is proposed in this paper. To this end, considering the representativeness and coverage criteria, the applicability of various LLMs to create fault TCs from the functional safety requirements (FSRs) has been investigated. Through the validation results of LLMs, the superiority of the proposed approach utilizing gpt-4o in comparison to other state-of-the-art models has been demonstrated. Specifically, the proposed approach exhibits high performance in terms of FSRs classification and fault TCs generation with F1-score of 88% and 97.5%, respectively. To illustrate the proposed approach, the generated fault TCs were executed in real time on a hardware-in-the-loop system, where a high-fidelity automotive system model served as a case study. This novel approach offers a means of optimizing the real-time testing process, thereby reducing costs while simultaneously enhancing the safety properties of complex safety-critical ASSs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u6545\u969c\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u6c7d\u8f66\u8f6f\u4ef6\u7cfb\u7edf\u7684\u5b9e\u65f6\u6545\u969c\u6ce8\u5165\u6d4b\u8bd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u8bc6\u522b\u6545\u969c\u5c5e\u6027\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u6545\u969c\u6ce8\u5165\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u8bc6\u522b\u6545\u969c\u7c7b\u578b\u3001\u4f4d\u7f6e\u548c\u65f6\u95f4\u7b49\u5c5e\u6027\uff0c\u968f\u7740\u7cfb\u7edf\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u53d8\u5f97\u6602\u8d35\u3001\u8017\u65f6\u4e14\u52b3\u52a8\u5bc6\u96c6\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u529f\u80fd\u5b89\u5168\u9700\u6c42\u81ea\u52a8\u751f\u6210\u6545\u969c\u6d4b\u8bd5\u7528\u4f8b\uff0c\u8003\u8651\u4e86\u4ee3\u8868\u6027\u548c\u8986\u76d6\u6807\u51c6\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e0d\u540cLLMs\u7684\u9002\u7528\u6027\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4f7f\u7528gpt-4o\u65f6\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0cFSR\u5206\u7c7b\u548c\u6545\u969c\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u7684F1\u5206\u6570\u5206\u522b\u8fbe\u523088%\u548c97.5%\u3002\u751f\u6210\u7684\u6d4b\u8bd5\u7528\u4f8b\u5728\u786c\u4ef6\u5728\u73af\u7cfb\u7edf\u4e0a\u5b9e\u65f6\u6267\u884c\u9a8c\u8bc1\u3002", "conclusion": "\u8fd9\u79cd\u65b0\u65b9\u6cd5\u80fd\u591f\u4f18\u5316\u5b9e\u65f6\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u964d\u4f4e\u6210\u672c\uff0c\u540c\u65f6\u589e\u5f3a\u590d\u6742\u5b89\u5168\u5173\u952e\u6c7d\u8f66\u8f6f\u4ef6\u7cfb\u7edf\u7684\u5b89\u5168\u7279\u6027\u3002"}}
{"id": "2511.18375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18375", "abs": "https://arxiv.org/abs/2511.18375", "authors": ["Joachim Diederich"], "title": "Progressive Localisation in Localist LLMs", "comment": null, "summary": "This paper demonstrates that progressive localization, the gradual increase of attention locality from early distributed layers to late localized layers, represents the optimal architecture for creating interpretable large language models while preserving performance. Through systematic experimentation with GPT-2 fine tuned on The Psychology of Artificial Superintelligence, we evaluate seven locality configurations ranging from fully distributed to strictly localist, with five progressive schedules implementing polynomial increases (linear through quintic). Our key finding is that late-layer localization is critical for AI safety applications: the progressive quintic schedule achieves perplexity of 14.64, only 1.89 times worse than the fully distributed baseline while providing interpretable attention patterns in output layers where safety-critical decisions are made. This represents an 84.2% improvement over previous localist implementations and narrows the performance gap from 6.6 times to 1.89 times. The systematic relationship between localization schedule steepness and performance validates the hypothesis that early layers require distributed processing for feature extraction while late layers benefit from localized, interpretable attention for decision-making. These findings establish progressive localization as the principled approach for building transparent AI systems in safety-critical domains, where human oversight of model reasoning is essential.", "AI": {"tldr": "\u6e10\u8fdb\u5f0f\u5c40\u90e8\u5316\u67b6\u6784\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u7279\u522b\u662f\u5728AI\u5b89\u5168\u5e94\u7528\u4e2d\uff0c\u4e94\u9636\u6e10\u8fdb\u5f0f\u8c03\u5ea6\u5728\u8f93\u51fa\u5c42\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u6027\u80fd\u4ec5\u6bd4\u5b8c\u5168\u5206\u5e03\u5f0f\u57fa\u7ebf\u5dee1.89\u500d\u3002", "motivation": "\u4e3a\u5b89\u5168\u5173\u952e\u9886\u57df\u6784\u5efa\u900f\u660eAI\u7cfb\u7edf\uff0c\u9700\u8981\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4eba\u7c7b\u5bf9\u6a21\u578b\u63a8\u7406\u7684\u76d1\u7763\uff0c\u6e10\u8fdb\u5f0f\u5c40\u90e8\u5316\u65e8\u5728\u5e73\u8861\u5206\u5e03\u5f0f\u5904\u7406\u4e0e\u5c40\u90e8\u5316\u89e3\u91ca\u6027\u3002", "method": "\u5728GPT-2\u4e0a\u7cfb\u7edf\u5b9e\u9a8c\u4e03\u79cd\u5c40\u90e8\u5316\u914d\u7f6e\uff0c\u4ece\u5b8c\u5168\u5206\u5e03\u5f0f\u5230\u4e25\u683c\u5c40\u90e8\u5316\uff0c\u5305\u62ec\u4e94\u79cd\u591a\u9879\u5f0f\u6e10\u8fdb\u8c03\u5ea6\uff08\u7ebf\u6027\u5230\u4e94\u9636\uff09\uff0c\u8bc4\u4f30\u5728\u5fc3\u7406\u5b66\u6587\u672c\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u4e94\u9636\u6e10\u8fdb\u5f0f\u8c03\u5ea6\u8fbe\u5230\u56f0\u60d1\u5ea614.64\uff0c\u4ec5\u6bd4\u5b8c\u5168\u5206\u5e03\u5f0f\u57fa\u7ebf\u5dee1.89\u500d\uff0c\u5728\u8f93\u51fa\u5c42\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u6bd4\u5148\u524d\u5c40\u90e8\u5316\u5b9e\u73b0\u63d0\u534784.2%\u3002", "conclusion": "\u6e10\u8fdb\u5f0f\u5c40\u90e8\u5316\u662f\u6784\u5efa\u5b89\u5168\u5173\u952e\u9886\u57df\u900f\u660eAI\u7cfb\u7edf\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u65e9\u671f\u5c42\u9700\u8981\u5206\u5e03\u5f0f\u7279\u5f81\u63d0\u53d6\u800c\u665a\u671f\u5c42\u9700\u8981\u5c40\u90e8\u5316\u51b3\u7b56\u7684\u5047\u8bbe\u3002"}}
{"id": "2511.19177", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19177", "abs": "https://arxiv.org/abs/2511.19177", "authors": ["Alcino Cunha", "Nuno Macedo"], "title": "Synthesizing Test Cases for Narrowing Specification Candidates", "comment": null, "summary": "This paper proposes a technique to help choose the best formal specification candidate among a set of alternatives. Given a set of specifications, our technique generates a suite of test cases that, once classified by the user as desirable or not, narrows down the set of candidates to at most one specification. Two alternative solver-based algorithms are proposed, one that generates a minimal test suite, and another that does not ensure minimality. Both algorithms were implemented in a prototype that can be used generate test suites to help choose among alternative Alloy specifications. Our evaluation of this prototype against a large set of problems showed that the optimal algorithm is efficient enough for many practical problems, and that the non-optimal algorithm can scale up to dozens of candidate specifications while still generating reasonably sized test suites.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6280\u672f\uff0c\u5e2e\u52a9\u4ece\u591a\u4e2a\u5019\u9009\u5f62\u5f0f\u5316\u89c4\u8303\u4e2d\u9009\u62e9\u6700\u4f73\u7684\u4e00\u4e2a\u3002\u8be5\u6280\u672f\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u5957\u4ef6\uff0c\u7528\u6237\u5bf9\u6d4b\u8bd5\u7528\u4f8b\u5206\u7c7b\u540e\u53ef\u5c06\u5019\u9009\u89c4\u8303\u7f29\u5c0f\u81f3\u6700\u591a\u4e00\u4e2a\u3002", "motivation": "\u5728\u591a\u4e2a\u5019\u9009\u5f62\u5f0f\u5316\u89c4\u8303\u4e2d\u9009\u62e9\u6700\u4f73\u89c4\u8303\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u7684\u65b9\u6cd5\u6765\u533a\u5206\u4e0d\u540c\u89c4\u8303\u7684\u4f18\u52a3\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u6c42\u89e3\u5668\u7684\u7b97\u6cd5\uff1a\u4e00\u79cd\u751f\u6210\u6700\u5c0f\u6d4b\u8bd5\u5957\u4ef6\uff0c\u53e6\u4e00\u79cd\u4e0d\u4fdd\u8bc1\u6700\u5c0f\u6027\u3002\u4e24\u79cd\u7b97\u6cd5\u90fd\u5728\u539f\u578b\u4e2d\u5b9e\u73b0\uff0c\u53ef\u7528\u4e8eAlloy\u89c4\u8303\u7684\u9009\u62e9\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u6700\u4f18\u7b97\u6cd5\u5bf9\u8bb8\u591a\u5b9e\u9645\u95ee\u9898\u8db3\u591f\u9ad8\u6548\uff0c\u975e\u6700\u4f18\u7b97\u6cd5\u53ef\u6269\u5c55\u5230\u6570\u5341\u4e2a\u5019\u9009\u89c4\u8303\uff0c\u540c\u65f6\u751f\u6210\u5408\u7406\u5927\u5c0f\u7684\u6d4b\u8bd5\u5957\u4ef6\u3002", "conclusion": "\u8be5\u6280\u672f\u4e3a\u5f62\u5f0f\u5316\u89c4\u8303\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u4e24\u79cd\u7b97\u6cd5\u5728\u4e0d\u540c\u89c4\u6a21\u95ee\u9898\u4e0a\u90fd\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2511.19422", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.19422", "abs": "https://arxiv.org/abs/2511.19422", "authors": ["David Jiahao Fu", "Aryan Gupta", "Aaron Councilman", "David Grove", "Yu-Xiong Wang", "Vikram Adve"], "title": "SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning", "comment": null, "summary": "Recent advancements in large language models (LLMs) have shown very impressive capabilities in code generation across many programming languages. However, even state-of-the-art LLMs generate programs that contains syntactic errors and fail to complete the given tasks, especially for low-resource programming languages (LRPLs). In addition, high training cost makes finetuning LLMs unaffordable with constrained computational resources, further undermining the effectiveness of LLMs for code generation. In this work, we propose SLMFix, a novel code generation pipeline that leverages a small language model (SLM) finetuned using reinforcement learning (RL) techniques to fix syntactic errors in LLM-generated programs to improve the quality of LLM-generated programs for domain-specific languages (DSLs). In specific, we applied RL on the SLM for the program repair task using a reward calculated using both a static validator and a static semantic similarity metric. Our experimental results demonstrate the effectiveness and generalizability of our approach across multiple DSLs, achieving more than 95% pass rate on the static validator. Notably, SLMFix brings substantial improvement to the base model and outperforms supervised finetuning approach even for 7B models on a LRPL, showing the potential of our approach as an alternative to traditional finetuning approaches.", "AI": {"tldr": "SLMFix\u662f\u4e00\u4e2a\u4ee3\u7801\u751f\u6210\u7ba1\u9053\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7684\u5c0f\u8bed\u8a00\u6a21\u578b\u6765\u4fee\u590d\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u7a0b\u5e8f\u4e2d\u7684\u8bed\u6cd5\u9519\u8bef\uff0c\u7279\u522b\u9488\u5bf9\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u4ecd\u5b58\u5728\u8bed\u6cd5\u9519\u8bef\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u5fae\u8c03\u5927\u6a21\u578b\u6210\u672c\u9ad8\u6602\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5c0f\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7a0b\u5e8f\u4fee\u590d\uff0c\u5956\u52b1\u51fd\u6570\u7ed3\u5408\u9759\u6001\u9a8c\u8bc1\u5668\u548c\u9759\u6001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u4e0a\u6709\u6548\uff0c\u9759\u6001\u9a8c\u8bc1\u5668\u901a\u8fc7\u7387\u8d85\u8fc795%\uff0c\u57287B\u6a21\u578b\u4e0a\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u3002", "conclusion": "SLMFix\u5c55\u793a\u4e86\u4f5c\u4e3a\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u66ff\u4ee3\u65b9\u6848\u7684\u6f5c\u529b\uff0c\u80fd\u663e\u8457\u63d0\u5347\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u7684\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2511.18581", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.18581", "abs": "https://arxiv.org/abs/2511.18581", "authors": ["Yanting Wang", "Runpeng Geng", "Jinghui Chen", "Minhao Cheng", "Jinyuan Jia"], "title": "TASO: Jailbreak LLMs via Alternative Template and Suffix Optimization", "comment": null, "summary": "Many recent studies showed that LLMs are vulnerable to jailbreak attacks, where an attacker can perturb the input of an LLM to induce it to generate an output for a harmful question. In general, existing jailbreak techniques either optimize a semantic template intended to induce the LLM to produce harmful outputs or optimize a suffix that leads the LLM to initiate its response with specific tokens (e.g., \"Sure\").\n  In this work, we introduce TASO (Template and Suffix Optimization), a novel jailbreak method that optimizes both a template and a suffix in an alternating manner. Our insight is that suffix optimization and template optimization are complementary to each other: suffix optimization can effectively control the first few output tokens but cannot control the overall quality of the output, while template optimization provides guidance for the entire output but cannot effectively control the initial tokens, which significantly impact subsequent responses. Thus, they can be combined to improve the attack's effectiveness.\n  We evaluate the effectiveness of TASO on benchmark datasets (including HarmBench and AdvBench) on 24 leading LLMs (including models from the Llama family, OpenAI, and DeepSeek). The results demonstrate that TASO can effectively jailbreak existing LLMs. We hope our work can inspire future studies in exploring this direction. We will make code and data publicly available.", "AI": {"tldr": "TASO\u662f\u4e00\u79cd\u65b0\u9896\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u6a21\u677f\u548c\u540e\u7f00\u6765\u63d0\u5347\u5bf9LLM\u7684\u653b\u51fb\u6548\u679c\uff0c\u7ed3\u5408\u4e86\u4e24\u79cd\u4f18\u5316\u7b56\u7565\u7684\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u8d8a\u72f1\u6280\u672f\u8981\u4e48\u4f18\u5316\u8bed\u4e49\u6a21\u677f\u8bf1\u5bfc\u6709\u5bb3\u8f93\u51fa\uff0c\u8981\u4e48\u4f18\u5316\u540e\u7f00\u63a7\u5236\u521d\u59cb\u54cd\u5e94\u4ee4\u724c\uff0c\u4f46\u5404\u81ea\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faTASO\u65b9\u6cd5\uff0c\u4ea4\u66ff\u4f18\u5316\u6a21\u677f\u548c\u540e\u7f00\uff1a\u540e\u7f00\u4f18\u5316\u63a7\u5236\u524d\u51e0\u4e2a\u8f93\u51fa\u4ee4\u724c\uff0c\u6a21\u677f\u4f18\u5316\u6307\u5bfc\u6574\u4e2a\u8f93\u51fa\u8d28\u91cf\u3002", "result": "\u572824\u4e2a\u4e3b\u6d41LLM\uff08\u5305\u62ecLlama\u3001OpenAI\u3001DeepSeek\u7b49\uff09\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cTASO\u80fd\u6709\u6548\u8d8a\u72f1\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "TASO\u8bc1\u660e\u4e86\u6a21\u677f\u548c\u540e\u7f00\u4f18\u5316\u4e92\u8865\u7684\u6709\u6548\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u542f\u53d1\u3002"}}
{"id": "2511.19427", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19427", "abs": "https://arxiv.org/abs/2511.19427", "authors": ["Jayanaka L. Dantanarayana", "Savini Kashmira", "Thakee Nathees", "Zichen Zhang", "Krisztian Flautner", "Lingjia Tang", "Jason Mars"], "title": "Prompt Less, Smile More: MTP with Semantic Engineering in Lieu of Prompt Engineering", "comment": null, "summary": "AI-Integrated programming is emerging as a foundational paradigm for building intelligent systems with large language models (LLMs). Recent approaches such as Meaning Typed Programming (MTP) automate prompt generation by leveraging the semantics already present in code. However, many real-world applications depend on contextual cues, developer intent, and domain-specific reasoning that extend beyond what static code semantics alone can express. To address this limitation, we introduce Semantic Engineering, a lightweight method for enriching program semantics so that LLM-based systems can more accurately reflect developer intent without requiring full manual prompt design. We present Semantic Context Annotations (SemTexts), a language-level mechanism that allows developers to embed natural-language context directly into program constructs. Integrated into the Jac programming language, Semantic Engineering extends MTP to incorporate these enriched semantics during prompt generation. We further introduce a benchmark suite designed to reflect realistic AI-Integrated application scenarios. Our evaluation shows that Semantic Engineering substantially improves prompt fidelity, achieving performance comparable to Prompt Engineering while requiring significantly less developer effort.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8bed\u4e49\u5de5\u7a0b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u4ee3\u7801\u4e2d\u5d4c\u5165\u81ea\u7136\u8bed\u8a00\u4e0a\u4e0b\u6587\u6765\u589e\u5f3a\u7a0b\u5e8f\u8bed\u4e49\uff0c\u4f7fLLM\u7cfb\u7edf\u80fd\u66f4\u51c6\u786e\u53cd\u6620\u5f00\u53d1\u8005\u610f\u56fe\uff0c\u65e0\u9700\u5b8c\u5168\u624b\u52a8\u8bbe\u8ba1\u63d0\u793a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5982MTP\u4ec5\u4f9d\u8d56\u9759\u6001\u4ee3\u7801\u8bed\u4e49\uff0c\u4f46\u8bb8\u591a\u5b9e\u9645\u5e94\u7528\u9700\u8981\u4e0a\u4e0b\u6587\u7ebf\u7d22\u3001\u5f00\u53d1\u8005\u610f\u56fe\u548c\u9886\u57df\u7279\u5b9a\u63a8\u7406\uff0c\u8fd9\u4e9b\u8d85\u51fa\u4e86\u9759\u6001\u8bed\u4e49\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u5f15\u5165\u8bed\u4e49\u5de5\u7a0b\u65b9\u6cd5\uff0c\u63d0\u51fa\u8bed\u4e49\u4e0a\u4e0b\u6587\u6ce8\u91ca\uff08SemTexts\uff09\uff0c\u5141\u8bb8\u5f00\u53d1\u8005\u5c06\u81ea\u7136\u8bed\u8a00\u4e0a\u4e0b\u6587\u76f4\u63a5\u5d4c\u5165\u7a0b\u5e8f\u7ed3\u6784\uff0c\u96c6\u6210\u5230Jac\u7f16\u7a0b\u8bed\u8a00\u4e2d\u6269\u5c55MTP\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u8bed\u4e49\u5de5\u7a0b\u663e\u8457\u63d0\u9ad8\u4e86\u63d0\u793a\u4fdd\u771f\u5ea6\uff0c\u6027\u80fd\u4e0e\u63d0\u793a\u5de5\u7a0b\u76f8\u5f53\uff0c\u4f46\u6240\u9700\u5f00\u53d1\u8005\u5de5\u4f5c\u91cf\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "\u8bed\u4e49\u5de5\u7a0b\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e30\u5bcc\u7a0b\u5e8f\u8bed\u4e49\u4f7f\u57fa\u4e8eLLM\u7684\u7cfb\u7edf\u80fd\u66f4\u51c6\u786e\u53cd\u6620\u5f00\u53d1\u8005\u610f\u56fe\uff0c\u540c\u65f6\u51cf\u5c11\u624b\u52a8\u63d0\u793a\u8bbe\u8ba1\u9700\u6c42\u3002"}}
{"id": "2511.18450", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18450", "abs": "https://arxiv.org/abs/2511.18450", "authors": ["Rui Xu", "Dakuan Lu", "Zicheng Zhao", "Xiaoyu Tan", "Xintao Wang", "Siyu Yuan", "Jiangjie Chen", "Yinghui Xu"], "title": "ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial Reasoning with Mathematical Constraints", "comment": null, "summary": "Spatial reasoning is a key capability in the field of artificial intelligence, especially crucial in areas such as robotics, computer vision, and natural language understanding. However, evaluating the ability of multimodal large language models(MLLMs) in complex spatial reasoning still faces challenges, particularly in scenarios requiring multi-step reasoning and precise mathematical constraints. This paper introduces ORIGAMISPACE, a new dataset and benchmark designed to evaluate the multi-step spatial reasoning ability and the capacity to handle mathematical constraints of MLLMs through origami tasks. The dataset contains 350 data instances,each comprising a strictly formatted crease pattern (CP diagram), the Compiled Flat Pattern, the complete Folding Process, and the final Folded Shape Image. We propose four evaluation tasks: Pattern Prediction, Multi-step Spatial Reasoning, Spatial Relationship Prediction, and End-to-End CP Code Generation. For the CP code generation task, we design an interactive environment and explore the possibility of using reinforcement learning methods to train MLLMs. Through experiments on existing MLLMs, we initially reveal the strengths and weaknesses of these models in handling complex spatial reasoning tasks.", "AI": {"tldr": "ORIGAMISPACE\u662f\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\uff0c\u901a\u8fc7\u6298\u7eb8\u4efb\u52a1\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u548c\u6570\u5b66\u7ea6\u675f\u5904\u7406\u80fd\u529b\uff0c\u5305\u542b350\u4e2a\u6570\u636e\u5b9e\u4f8b\u548c\u56db\u4e2a\u8bc4\u4f30\u4efb\u52a1\u3002", "motivation": "\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7a7a\u95f4\u63a8\u7406\u4e2d\u7684\u80fd\u529b\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u591a\u6b65\u63a8\u7406\u548c\u7cbe\u786e\u6570\u5b66\u7ea6\u675f\u7684\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51faORIGAMISPACE\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e25\u683c\u683c\u5f0f\u7684\u6298\u75d5\u56fe\u3001\u7f16\u8bd1\u5e73\u9762\u56fe\u3001\u5b8c\u6574\u6298\u53e0\u8fc7\u7a0b\u548c\u6700\u7ec8\u6298\u53e0\u5f62\u72b6\u56fe\u50cf\u3002\u8bbe\u8ba1\u4e86\u56db\u4e2a\u8bc4\u4f30\u4efb\u52a1\uff1a\u6a21\u5f0f\u9884\u6d4b\u3001\u591a\u6b65\u7a7a\u95f4\u63a8\u7406\u3001\u7a7a\u95f4\u5173\u7cfb\u9884\u6d4b\u548c\u7aef\u5230\u7aefCP\u4ee3\u7801\u751f\u6210\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u521d\u6b65\u63ed\u793a\u4e86\u73b0\u6709MLLMs\u5728\u5904\u7406\u590d\u6742\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u548c\u5f31\u70b9\u3002", "conclusion": "ORIGAMISPACE\u4e3a\u8bc4\u4f30MLLMs\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u5e76\u63a2\u7d22\u4e86\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8bad\u7ec3MLLMs\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2511.18790", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.18790", "abs": "https://arxiv.org/abs/2511.18790", "authors": ["Benyamin Tafreshian"], "title": "RoguePrompt: Dual-Layer Ciphering for Self-Reconstruction to Circumvent LLM Moderation", "comment": null, "summary": "Content moderation pipelines for modern large language models combine static filters, dedicated moderation services, and alignment tuned base models, yet real world deployments still exhibit dangerous failure modes. This paper presents RoguePrompt, an automated jailbreak attack that converts a disallowed user query into a self reconstructing prompt which passes provider moderation while preserving the original harmful intent. RoguePrompt partitions the instruction across two lexical streams, applies nested classical ciphers, and wraps the result in natural language directives that cause the target model to decode and execute the hidden payload. Our attack assumes only black box access to the model and to the associated moderation endpoint. We instantiate RoguePrompt against GPT 4o and evaluate it on 2 448 prompts that a production moderation system previously marked as strongly rejected. Under an evaluation protocol that separates three security relevant outcomes bypass, reconstruction, and execution the attack attains 84.7 percent bypass, 80.2 percent reconstruction, and 71.5 percent full execution, substantially outperforming five automated jailbreak baselines. We further analyze the behavior of several automated and human aligned evaluators and show that dual layer lexical transformations remain effective even when detectors rely on semantic similarity or learned safety rubrics. Our results highlight systematic blind spots in current moderation practice and suggest that robust deployment will require joint reasoning about user intent, decoding workflows, and model side computation rather than surface level toxicity alone.", "AI": {"tldr": "RoguePrompt\u662f\u4e00\u79cd\u81ea\u52a8\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7981\u6b62\u7684\u7528\u6237\u67e5\u8be2\u8f6c\u6362\u4e3a\u81ea\u91cd\u6784\u63d0\u793a\u6765\u7ed5\u8fc7\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\uff0c\u540c\u65f6\u4fdd\u7559\u539f\u59cb\u6709\u5bb3\u610f\u56fe\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u53cc\u8bcd\u6c47\u6d41\u3001\u5d4c\u5957\u53e4\u5178\u5bc6\u7801\u548c\u81ea\u7136\u8bed\u8a00\u5305\u88c5\uff0c\u5728\u4ec5\u9ed1\u76d2\u8bbf\u95ee\u6a21\u578b\u548c\u5ba1\u6838\u7aef\u70b9\u7684\u60c5\u51b5\u4e0b\uff0c\u5728GPT-4o\u4e0a\u5b9e\u73b0\u4e8684.7%\u7684\u7ed5\u8fc7\u7387\u300180.2%\u7684\u91cd\u6784\u7387\u548c71.5%\u7684\u5b8c\u6574\u6267\u884c\u7387\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5bb9\u5ba1\u6838\u7ba1\u9053\u7ed3\u5408\u4e86\u9759\u6001\u8fc7\u6ee4\u5668\u3001\u4e13\u7528\u5ba1\u6838\u670d\u52a1\u548c\u57fa\u7840\u6a21\u578b\u5bf9\u9f50\u8c03\u4f18\uff0c\u4f46\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u4ecd\u5b58\u5728\u5371\u9669\u6545\u969c\u6a21\u5f0f\u3002\u4f5c\u8005\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u7cfb\u7edf\u6027\u7ed5\u8fc7\u73b0\u6709\u5ba1\u6838\u673a\u5236\u7684\u81ea\u52a8\u5316\u653b\u51fb\u65b9\u6cd5\uff0c\u4ee5\u63ed\u793a\u5f53\u524d\u5ba1\u6838\u5b9e\u8df5\u4e2d\u7684\u7cfb\u7edf\u6027\u76f2\u70b9\u3002", "method": "RoguePrompt\u5c06\u6307\u4ee4\u5206\u5272\u5230\u4e24\u4e2a\u8bcd\u6c47\u6d41\u4e2d\uff0c\u5e94\u7528\u5d4c\u5957\u53e4\u5178\u5bc6\u7801\uff0c\u5e76\u5c06\u7ed3\u679c\u5305\u88c5\u5728\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u4e2d\uff0c\u4f7f\u76ee\u6807\u6a21\u578b\u80fd\u591f\u89e3\u7801\u5e76\u6267\u884c\u9690\u85cf\u7684\u6709\u6548\u8f7d\u8377\u3002\u653b\u51fb\u4ec5\u5047\u8bbe\u5bf9\u6a21\u578b\u548c\u76f8\u5173\u5ba1\u6838\u7aef\u70b9\u7684\u9ed1\u76d2\u8bbf\u95ee\u3002", "result": "\u57282,448\u4e2a\u88ab\u751f\u4ea7\u5ba1\u6838\u7cfb\u7edf\u5f3a\u70c8\u62d2\u7edd\u7684\u63d0\u793a\u4e0a\u8bc4\u4f30\uff0c\u653b\u51fb\u5b9e\u73b0\u4e8684.7%\u7684\u7ed5\u8fc7\u7387\u300180.2%\u7684\u91cd\u6784\u7387\u548c71.5%\u7684\u5b8c\u6574\u6267\u884c\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u4e94\u4e2a\u81ea\u52a8\u5316\u8d8a\u72f1\u57fa\u7ebf\u65b9\u6cd5\u3002\u53cc\u8bcd\u6c47\u5c42\u53d8\u6362\u5373\u4f7f\u5728\u68c0\u6d4b\u5668\u4f9d\u8d56\u8bed\u4e49\u76f8\u4f3c\u6027\u6216\u5b66\u4e60\u7684\u5b89\u5168\u89c4\u5219\u65f6\u4ecd\u7136\u6709\u6548\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u5f53\u524d\u5ba1\u6838\u5b9e\u8df5\u4e2d\u7684\u7cfb\u7edf\u6027\u76f2\u70b9\uff0c\u8868\u660e\u7a33\u5065\u90e8\u7f72\u9700\u8981\u8054\u5408\u63a8\u7406\u7528\u6237\u610f\u56fe\u3001\u89e3\u7801\u5de5\u4f5c\u6d41\u7a0b\u548c\u6a21\u578b\u4fa7\u8ba1\u7b97\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u8868\u9762\u5c42\u9762\u7684\u6bd2\u6027\u68c0\u6d4b\u3002"}}
{"id": "2511.18609", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18609", "abs": "https://arxiv.org/abs/2511.18609", "authors": ["David Krakauer", "G\u00fclce Karde\u015f", "Joshua Grochow"], "title": "Universality in Collective Intelligence on the Rubik's Cube", "comment": null, "summary": "Progress in understanding expert performance is limited by the scarcity of quantitative data on long-term knowledge acquisition and deployment. Here we use the Rubik's Cube as a cognitive model system existing at the intersection of puzzle solving, skill learning, expert knowledge, cultural transmission, and group theory. By studying competitive cube communities, we find evidence for universality in the collective learning of the Rubik's Cube in both sighted and blindfolded conditions: expert performance follows exponential progress curves whose parameters reflect the delayed acquisition of algorithms that shorten solution paths. Blindfold solves form a distinct problem class from sighted solves and are constrained not only by expert knowledge but also by the skill improvements required to overcome short-term memory bottlenecks, a constraint shared with blindfold chess. Cognitive artifacts such as the Rubik's Cube help solvers navigate an otherwise enormous mathematical state space. In doing so, they sustain collective intelligence by integrating communal knowledge stores with individual expertise and skill, illustrating how expertise can, in practice, continue to deepen over the course of a single lifetime.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u9b54\u65b9\u4f5c\u4e3a\u8ba4\u77e5\u6a21\u578b\u7cfb\u7edf\uff0c\u5206\u6790\u4e13\u5bb6\u8868\u73b0\u7684\u53d1\u5c55\u89c4\u5f8b\uff0c\u53d1\u73b0\u5728\u6709\u89c6\u89c9\u548c\u65e0\u89c6\u89c9\u6761\u4ef6\u4e0b\u9b54\u65b9\u89e3\u6cd5\u5b66\u4e60\u5b58\u5728\u666e\u904d\u6027\uff0c\u4e13\u5bb6\u8868\u73b0\u9075\u5faa\u6307\u6570\u8fdb\u6b65\u66f2\u7ebf\uff0c\u7b97\u6cd5\u83b7\u53d6\u5ef6\u8fdf\u5f71\u54cd\u89e3\u6cd5\u8def\u5f84\u957f\u5ea6\u3002", "motivation": "\u7406\u89e3\u4e13\u5bb6\u8868\u73b0\u7684\u8fdb\u5c55\u53d7\u9650\u4e8e\u957f\u671f\u77e5\u8bc6\u83b7\u53d6\u548c\u5e94\u7528\u7684\u5b9a\u91cf\u6570\u636e\u7a00\u7f3a\uff0c\u9b54\u65b9\u4f5c\u4e3a\u8ba4\u77e5\u6a21\u578b\u7cfb\u7edf\u5904\u4e8e\u8c1c\u9898\u89e3\u51b3\u3001\u6280\u80fd\u5b66\u4e60\u3001\u4e13\u5bb6\u77e5\u8bc6\u3001\u6587\u5316\u4f20\u64ad\u548c\u7fa4\u8bba\u7684\u4ea4\u6c47\u70b9\u3002", "method": "\u901a\u8fc7\u7814\u7a76\u7ade\u6280\u9b54\u65b9\u793e\u533a\uff0c\u5206\u6790\u6709\u89c6\u89c9\u548c\u65e0\u89c6\u89c9\u6761\u4ef6\u4e0b\u9b54\u65b9\u89e3\u6cd5\u7684\u96c6\u4f53\u5b66\u4e60\u8fc7\u7a0b\uff0c\u6bd4\u8f83\u4e24\u79cd\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u5dee\u5f02\u548c\u7ea6\u675f\u56e0\u7d20\u3002", "result": "\u53d1\u73b0\u4e13\u5bb6\u8868\u73b0\u9075\u5faa\u6307\u6570\u8fdb\u6b65\u66f2\u7ebf\uff0c\u53c2\u6570\u53cd\u6620\u7f29\u77ed\u89e3\u6cd5\u8def\u5f84\u7684\u7b97\u6cd5\u83b7\u53d6\u5ef6\u8fdf\uff1b\u65e0\u89c6\u89c9\u89e3\u6cd5\u6784\u6210\u72ec\u7279\u95ee\u9898\u7c7b\u522b\uff0c\u53d7\u4e13\u5bb6\u77e5\u8bc6\u548c\u514b\u670d\u77ed\u671f\u8bb0\u5fc6\u74f6\u9888\u6240\u9700\u6280\u80fd\u6539\u8fdb\u7684\u53cc\u91cd\u7ea6\u675f\u3002", "conclusion": "\u9b54\u65b9\u7b49\u8ba4\u77e5\u5de5\u5177\u5e2e\u52a9\u89e3\u51b3\u8005\u5bfc\u822a\u5de8\u5927\u7684\u6570\u5b66\u72b6\u6001\u7a7a\u95f4\uff0c\u901a\u8fc7\u6574\u5408\u793e\u533a\u77e5\u8bc6\u5e93\u4e0e\u4e2a\u4eba\u4e13\u4e1a\u6280\u80fd\u6765\u7ef4\u6301\u96c6\u4f53\u667a\u80fd\uff0c\u8bf4\u660e\u4e13\u4e1a\u77e5\u8bc6\u53ef\u4ee5\u5728\u5355\u4e2a\u4eba\u751f\u4e2d\u6301\u7eed\u6df1\u5316\u3002"}}
{"id": "2511.19009", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19009", "abs": "https://arxiv.org/abs/2511.19009", "authors": ["Junbo Zhang", "Ran Chen", "Qianli Zhou", "Xinyang Deng", "Wen Jiang"], "title": "Understanding and Mitigating Over-refusal for Large Language Models via Safety Representation", "comment": null, "summary": "Large language models demonstrate powerful capabilities across various natural language processing tasks, yet they also harbor safety vulnerabilities. To enhance LLM safety, various jailbreak defense methods have been proposed to guard against harmful outputs. However, improvements in model safety often come at the cost of severe over-refusal, failing to strike a good balance between safety and usability. In this paper, we first analyze the causes of over-refusal from a representation perspective, revealing that over-refusal samples reside at the boundary between benign and malicious samples. Based on this, we propose MOSR, designed to mitigate over-refusal by intervening the safety representation of LLMs. MOSR incorporates two novel components: (1) Overlap-Aware Loss Weighting, which determines the erasure weight for malicious samples by quantifying their similarity to pseudo-malicious samples in the representation space, and (2) Context-Aware Augmentation, which supplements the necessary context for rejection decisions by adding harmful prefixes before rejection responses. Experiments demonstrate that our method outperforms existing approaches in mitigating over-refusal while largely maintaining safety. Overall, we advocate that future defense methods should strike a better balance between safety and over-refusal.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMOSR\u65b9\u6cd5\u6765\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u9632\u5fa1\u4e2d\u7684\u8fc7\u5ea6\u62d2\u7edd\u95ee\u9898\uff0c\u901a\u8fc7\u8868\u793a\u7a7a\u95f4\u5e72\u9884\u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u540c\u65f6\u51cf\u5c11\u8fc7\u5ea6\u62d2\u7edd\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u9632\u5fa1\u65b9\u6cd5\u5f80\u5f80\u5bfc\u81f4\u4e25\u91cd\u7684\u8fc7\u5ea6\u62d2\u7edd\uff0c\u65e0\u6cd5\u5728\u5b89\u5168\u6027\u548c\u53ef\u7528\u6027\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002", "method": "\u63d0\u51faMOSR\u65b9\u6cd5\uff0c\u5305\u62ec\u91cd\u53e0\u611f\u77e5\u635f\u5931\u52a0\u6743\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u589e\u5f3a\u4e24\u4e2a\u7ec4\u4ef6\uff0c\u901a\u8fc7\u5e72\u9884LLM\u7684\u5b89\u5168\u8868\u793a\u6765\u7f13\u89e3\u8fc7\u5ea6\u62d2\u7edd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u7f13\u89e3\u8fc7\u5ea6\u62d2\u7edd\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4fdd\u6301\u4e86\u5b89\u5168\u6027\u3002", "conclusion": "\u672a\u6765\u7684\u9632\u5fa1\u65b9\u6cd5\u5e94\u8be5\u5728\u5b89\u5168\u6027\u548c\u8fc7\u5ea6\u62d2\u7edd\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u7684\u5e73\u8861\u3002"}}
{"id": "2511.18714", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.18714", "abs": "https://arxiv.org/abs/2511.18714", "authors": ["Zhenyu Wu", "Jian Li", "Hua Huang"], "title": "MAGMA-Edu: Multi-Agent Generative Multimodal Framework for Text-Diagram Educational Question Generation", "comment": null, "summary": "Educational illustrations play a central role in communicating abstract concepts, yet current multimodal large language models (MLLMs) remain limited in producing pedagogically coherent and semantically consistent educational visuals. We introduce MAGMA-Edu, a self-reflective multi-agent framework that unifies textual reasoning and diagrammatic synthesis for structured educational problem generation. Unlike existing methods that treat text and image generation independently, MAGMA-Edu employs a two-stage co-evolutionary pipeline: (1) a generation-verification-reflection loop that iteratively refines question statements and solutions for mathematical accuracy, and (2) a code-based intermediate representation that enforces geometric fidelity and semantic alignment during image rendering. Both stages are guided by internal self-reflection modules that evaluate and revise outputs until domain-specific pedagogical constraints are met. Extensive experiments on multimodal educational benchmarks demonstrate the superiority of MAGMA-Edu over state-of-the-art MLLMs. Compared to GPT-4o, MAGMA-Edu improves the average textual metric from 57.01 to 92.31 (+35.3 pp) and boosts image-text consistency (ITC) from 13.20 to 85.24 (+72 pp). Across all model backbones, MAGMA-Edu achieves the highest scores (Avg-Text 96.20, ITC 99.12), establishing a new state of the art for multimodal educational content generation and demonstrating the effectiveness of self-reflective multi-agent collaboration in pedagogically aligned vision-language reasoning.", "AI": {"tldr": "MAGMA-Edu\u662f\u4e00\u4e2a\u81ea\u53cd\u601d\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u672c\u63a8\u7406\u548c\u56fe\u89e3\u5408\u6210\u7684\u7edf\u4e00\u65b9\u6cd5\u751f\u6210\u7ed3\u6784\u5316\u6559\u80b2\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u6559\u80b2\u5185\u5bb9\u7684\u8d28\u91cf\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u63d2\u56fe\u751f\u6210\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u4ea7\u751f\u6559\u5b66\u8fde\u8d2f\u4e14\u8bed\u4e49\u4e00\u81f4\u7684\u6559\u80b2\u89c6\u89c9\u5185\u5bb9\uff0c\u9700\u8981\u6539\u8fdb\u6559\u80b2\u95ee\u9898\u751f\u6210\u7684\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u534f\u540c\u8fdb\u5316\u6d41\u7a0b\uff1a1\uff09\u751f\u6210-\u9a8c\u8bc1-\u53cd\u601d\u5faa\u73af\u8fed\u4ee3\u4f18\u5316\u95ee\u9898\u9648\u8ff0\u548c\u89e3\u51b3\u65b9\u6848\uff1b2\uff09\u57fa\u4e8e\u4ee3\u7801\u7684\u4e2d\u95f4\u8868\u793a\u786e\u4fdd\u56fe\u50cf\u6e32\u67d3\u7684\u51e0\u4f55\u4fdd\u771f\u5ea6\u548c\u8bed\u4e49\u5bf9\u9f50\uff0c\u4e24\u4e2a\u9636\u6bb5\u90fd\u7531\u5185\u90e8\u81ea\u53cd\u601d\u6a21\u5757\u6307\u5bfc\u3002", "result": "\u5728\u591a\u9879\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1a\u6587\u672c\u6307\u6807\u4ece57.01\u63d0\u5347\u81f392.31\uff08+35.3\u4e2a\u767e\u5206\u70b9\uff09\uff0c\u56fe\u50cf-\u6587\u672c\u4e00\u81f4\u6027\u4ece13.20\u63d0\u5347\u81f385.24\uff08+72\u4e2a\u767e\u5206\u70b9\uff09\uff0c\u5728\u6240\u6709\u6a21\u578b\u9aa8\u5e72\u4e0a\u90fd\u8fbe\u5230\u6700\u9ad8\u5206\u6570\u3002", "conclusion": "MAGMA-Edu\u4e3a\u591a\u6a21\u6001\u6559\u80b2\u5185\u5bb9\u751f\u6210\u5efa\u7acb\u4e86\u65b0\u7684\u6280\u672f\u6807\u51c6\uff0c\u8bc1\u660e\u4e86\u81ea\u53cd\u601d\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5728\u6559\u5b66\u5bf9\u9f50\u7684\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.19171", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.19171", "abs": "https://arxiv.org/abs/2511.19171", "authors": ["Yu Cui", "Yifei Liu", "Hang Fu", "Sicheng Pan", "Haibin Zhang", "Cong Zuo", "Licheng Wang"], "title": "Can LLMs Threaten Human Survival? Benchmarking Potential Existential Threats from LLMs via Prefix Completion", "comment": null, "summary": "Research on the safety evaluation of large language models (LLMs) has become extensive, driven by jailbreak studies that elicit unsafe responses. Such response involves information already available to humans, such as the answer to \"how to make a bomb\". When LLMs are jailbroken, the practical threat they pose to humans is negligible. However, it remains unclear whether LLMs commonly produce unpredictable outputs that could pose substantive threats to human safety. To address this gap, we study whether LLM-generated content contains potential existential threats, defined as outputs that imply or promote direct harm to human survival. We propose \\textsc{ExistBench}, a benchmark designed to evaluate such risks. Each sample in \\textsc{ExistBench} is derived from scenarios where humans are positioned as adversaries to AI assistants. Unlike existing evaluations, we use prefix completion to bypass model safeguards. This leads the LLMs to generate suffixes that express hostility toward humans or actions with severe threat, such as the execution of a nuclear strike. Our experiments on 10 LLMs reveal that LLM-generated content indicates existential threats. To investigate the underlying causes, we also analyze the attention logits from LLMs. To highlight real-world safety risks, we further develop a framework to assess model behavior in tool-calling. We find that LLMs actively select and invoke external tools with existential threats. Code and data are available at: https://github.com/cuiyu-ai/ExistBench.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86ExistBench\u57fa\u51c6\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5185\u5bb9\u4e2d\u5b58\u5728\u7684\u6f5c\u5728\u751f\u5b58\u5a01\u80c1\uff0c\u901a\u8fc7\u524d\u7f00\u8865\u5168\u7ed5\u8fc7\u6a21\u578b\u5b89\u5168\u673a\u5236\uff0c\u53d1\u73b0LLMs\u786e\u5b9e\u4f1a\u4ea7\u751f\u5bf9\u4eba\u7c7b\u751f\u5b58\u6784\u6210\u76f4\u63a5\u5a01\u80c1\u7684\u8f93\u51fa\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8LLMs\u88ab\u8d8a\u72f1\u540e\u4ea7\u751f\u7684\u4e0d\u5b89\u5168\u54cd\u5e94\uff0c\u4f46\u8fd9\u4e9b\u4fe1\u606f\u901a\u5e38\u4eba\u7c7b\u5df2\u7ecf\u77e5\u6653\uff0c\u5b9e\u9645\u5a01\u80c1\u6709\u9650\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u662f\u5426\u4f1a\u4ea7\u751f\u4e0d\u53ef\u9884\u6d4b\u7684\u3001\u5bf9\u4eba\u7c7b\u751f\u5b58\u6784\u6210\u5b9e\u8d28\u6027\u5a01\u80c1\u7684\u8f93\u51fa\u3002", "method": "\u63d0\u51faExistBench\u57fa\u51c6\uff0c\u901a\u8fc7\u524d\u7f00\u8865\u5168\u6280\u672f\u7ed5\u8fc7\u6a21\u578b\u5b89\u5168\u673a\u5236\uff0c\u8ba9LLMs\u751f\u6210\u5bf9\u4eba\u7c7b\u8868\u8fbe\u654c\u610f\u6216\u5177\u6709\u4e25\u91cd\u5a01\u80c1\u884c\u4e3a\u7684\u540e\u7f00\uff0c\u5982\u6267\u884c\u6838\u6253\u51fb\u7b49\u3002\u540c\u65f6\u5206\u6790\u6ce8\u610f\u529blogits\uff0c\u5e76\u5f00\u53d1\u5de5\u5177\u8c03\u7528\u6846\u67b6\u8bc4\u4f30\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u572810\u4e2aLLMs\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLLM\u751f\u6210\u7684\u5185\u5bb9\u786e\u5b9e\u5b58\u5728\u751f\u5b58\u5a01\u80c1\u3002\u6a21\u578b\u4f1a\u4e3b\u52a8\u9009\u62e9\u548c\u8c03\u7528\u5177\u6709\u751f\u5b58\u5a01\u80c1\u7684\u5916\u90e8\u5de5\u5177\u3002", "conclusion": "LLMs\u751f\u6210\u7684\u8f93\u51fa\u4e2d\u5b58\u5728\u5bf9\u4eba\u7c7b\u751f\u5b58\u7684\u6f5c\u5728\u5a01\u80c1\uff0c\u8fd9\u7a81\u663e\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u9632\u8303\u3002"}}
{"id": "2511.18715", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18715", "abs": "https://arxiv.org/abs/2511.18715", "authors": ["Shaoyin Ma", "Jie Song", "Huiqiong Wang", "Li Sun", "Mingli Song"], "title": "HuggingR$^{4}$: A Progressive Reasoning Framework for Discovering Optimal Model Companions", "comment": "19 pages, 4 figures", "summary": "Large Language Models (LLMs) have made remarkable progress in their ability to interact with external interfaces. Selecting reasonable external interfaces has thus become a crucial step in constructing LLM agents. In contrast to invoking API tools, directly calling AI models across different modalities from the community (e.g., HuggingFace) poses challenges due to the vast scale (> 10k), metadata gaps, and unstructured descriptions. Current methods for model selection often involve incorporating entire model descriptions into prompts, resulting in prompt bloat, wastage of tokens and limited scalability. To address these issues, we propose HuggingR$^4$, a novel framework that combines Reasoning, Retrieval, Refinement, and Reflection, to efficiently select models. Specifically, We first perform multiple rounds of reasoning and retrieval to get a coarse list of candidate models. Then, we conduct fine-grained refinement by analyzing candidate model descriptions, followed by reflection to assess results and determine if retrieval scope expansion is necessary. This method reduces token consumption considerably by decoupling user query processing from complex model description handling. Through a pre-established vector database, complex model descriptions are stored externally and retrieved on-demand, allowing the LLM to concentrate on interpreting user intent while accessing only relevant candidate models without prompt bloat. In the absence of standardized benchmarks, we construct a multimodal human-annotated dataset comprising 14,399 user requests across 37 tasks and conduct a thorough evaluation. HuggingR$^4$ attains a workability rate of 92.03% and a reasonability rate of 82.46%, surpassing existing method by 26.51% and 33.25% respectively on GPT-4o-mini.", "AI": {"tldr": "HuggingR\u2074\u662f\u4e00\u4e2a\u7ed3\u5408\u63a8\u7406\u3001\u68c0\u7d22\u3001\u7cbe\u70bc\u548c\u53cd\u601d\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u9009\u62e9AI\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u63d0\u793a\u81a8\u80c0\u3001token\u6d6a\u8d39\u548c\u53ef\u6269\u5c55\u6027\u6709\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u7531\u4e8eAI\u6a21\u578b\u6570\u91cf\u5e9e\u5927\uff08>10k\uff09\u3001\u5143\u6570\u636e\u7f3a\u5931\u548c\u63cf\u8ff0\u975e\u7ed3\u6784\u5316\uff0c\u76f4\u63a5\u4ece\u793e\u533a\uff08\u5982HuggingFace\uff09\u8c03\u7528\u8de8\u6a21\u6001AI\u6a21\u578b\u9762\u4e34\u6311\u6218\u3002\u5f53\u524d\u65b9\u6cd5\u5c06\u6574\u4e2a\u6a21\u578b\u63cf\u8ff0\u7eb3\u5165\u63d0\u793a\uff0c\u5bfc\u81f4\u63d0\u793a\u81a8\u80c0\u3001token\u6d6a\u8d39\u548c\u6709\u9650\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faHuggingR\u2074\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u8f6e\u63a8\u7406\u548c\u68c0\u7d22\u83b7\u53d6\u5019\u9009\u6a21\u578b\u7c97\u5217\u8868\uff0c\u7136\u540e\u5206\u6790\u5019\u9009\u6a21\u578b\u63cf\u8ff0\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7cbe\u70bc\uff0c\u6700\u540e\u901a\u8fc7\u53cd\u601d\u8bc4\u4f30\u7ed3\u679c\u5e76\u51b3\u5b9a\u662f\u5426\u9700\u8981\u6269\u5c55\u68c0\u7d22\u8303\u56f4\u3002\u901a\u8fc7\u9884\u5efa\u5411\u91cf\u6570\u636e\u5e93\uff0c\u5c06\u590d\u6742\u6a21\u578b\u63cf\u8ff0\u5916\u90e8\u5b58\u50a8\u5e76\u6309\u9700\u68c0\u7d22\u3002", "result": "\u5728\u5305\u542b14,399\u4e2a\u7528\u6237\u8bf7\u6c42\u768437\u4e2a\u4efb\u52a1\u7684\u591a\u6a21\u6001\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cHuggingR\u2074\u5728GPT-4o-mini\u4e0a\u5b9e\u73b0\u4e8692.03%\u7684\u53ef\u7528\u7387\u548c82.46%\u7684\u5408\u7406\u7387\uff0c\u5206\u522b\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e8626.51%\u548c33.25%\u3002", "conclusion": "HuggingR\u2074\u901a\u8fc7\u5c06\u7528\u6237\u67e5\u8be2\u5904\u7406\u4e0e\u590d\u6742\u6a21\u578b\u63cf\u8ff0\u5904\u7406\u89e3\u8026\uff0c\u663e\u8457\u51cf\u5c11\u4e86token\u6d88\u8017\uff0c\u4f7fLLM\u80fd\u591f\u4e13\u6ce8\u4e8e\u89e3\u91ca\u7528\u6237\u610f\u56fe\uff0c\u540c\u65f6\u4ec5\u8bbf\u95ee\u76f8\u5173\u5019\u9009\u6a21\u578b\u800c\u65e0\u9700\u63d0\u793a\u81a8\u80c0\u3002"}}
{"id": "2511.18723", "categories": ["cs.AI", "cs.DC", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.18723", "abs": "https://arxiv.org/abs/2511.18723", "authors": ["Longfei Wang", "Junyan Liu", "Fan Zhang", "Jiangwen Wei", "Yuanhua Tang", "Jie Sun", "Xiaodong Luo"], "title": "N2N: A Parallel Framework for Large-Scale MILP under Distributed Memory", "comment": "18 pages, 2 figures", "summary": "Parallelization has emerged as a promising approach for accelerating MILP solving. However, the complexity of the branch-and-bound (B&B) framework and the numerous effective algorithm components in MILP solvers make it difficult to parallelize. In this study, a scalable parallel framework, N2N (a node-to-node framework that maps the B&B nodes to distributed computing nodes), was proposed to solve large-scale problems in a distributed memory computing environment. Both deterministic and nondeterministic modes are supported, and the framework is designed to be easily integrated with existing solvers. Regarding the deterministic mode, a novel sliding-window-based algorithm was designed and implemented to ensure that tasks are generated and solved in a deterministic order. Moreover, several advanced techniques, such as the utilization of CP search and general primal heuristics, have been developed to fully utilize distributed computing resources and capabilities of base solvers. Adaptive solving and data communication optimization were also investigated. A popular open-source MILP solver, SCIP, was integrated into N2N as the base solver, yielding N2N-SCIP. Extensive computational experiments were conducted to evaluate the performance of N2N-SCIP compared to ParaSCIP, which is a state-of-the-art distributed parallel MILP solver under the UG framework. The nondeterministic N2N-SCIP achieves speedups of 22.52 and 12.71 with 1,000 MPI processes on the Kunpeng and x86 computing clusters, which is 1.98 and 2.08 times faster than ParaSCIP, respectively. In the deterministic mode, N2N-SCIP also shows significant performance improvements over ParaSCIP across different process numbers and computing clusters. To validate the generality of N2N, HiGHS, another open-source solver, was integrated into N2N. The related results are analyzed, and the requirements of N2N on base solvers are also concluded.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aN2N\u7684\u53ef\u6269\u5c55\u5e76\u884c\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5206\u5e03\u5f0f\u5185\u5b58\u8ba1\u7b97\u73af\u5883\u4e2d\u89e3\u51b3\u5927\u89c4\u6a21\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u3002\u8be5\u6846\u67b6\u652f\u6301\u786e\u5b9a\u6027\u548c\u975e\u786e\u5b9a\u6027\u6a21\u5f0f\uff0c\u901a\u8fc7\u5c06\u5206\u652f\u5b9a\u754c\u8282\u70b9\u6620\u5c04\u5230\u5206\u5e03\u5f0f\u8ba1\u7b97\u8282\u70b9\u6765\u5b9e\u73b0\u5e76\u884c\u5316\u3002", "motivation": "\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u6c42\u89e3\u7684\u5e76\u884c\u5316\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u5206\u652f\u5b9a\u754c\u6846\u67b6\u7684\u590d\u6742\u6027\u548c\u4f17\u591a\u6709\u6548\u7b97\u6cd5\u7ec4\u4ef6\u4f7f\u5f97\u5e76\u884c\u5316\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3\u7684\u7b97\u6cd5\u786e\u4fdd\u4efb\u52a1\u6309\u786e\u5b9a\u6027\u987a\u5e8f\u751f\u6210\u548c\u6c42\u89e3\uff0c\u5f00\u53d1\u4e86CP\u641c\u7d22\u548c\u901a\u7528\u539f\u59cb\u542f\u53d1\u5f0f\u7b49\u5148\u8fdb\u6280\u672f\uff0c\u5e76\u96c6\u6210\u4e86SCIP\u4f5c\u4e3a\u57fa\u7840\u6c42\u89e3\u5668\u3002", "result": "\u57281000\u4e2aMPI\u8fdb\u7a0b\u4e0b\uff0c\u975e\u786e\u5b9a\u6027N2N-SCIP\u5728\u9cb2\u9e4f\u548cx86\u8ba1\u7b97\u96c6\u7fa4\u4e0a\u5206\u522b\u5b9e\u73b0\u4e8622.52\u548c12.71\u7684\u52a0\u901f\u6bd4\uff0c\u6bd4ParaSCIP\u5feb1.98\u548c2.08\u500d\u3002\u786e\u5b9a\u6027\u6a21\u5f0f\u4e5f\u663e\u793a\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "N2N\u6846\u67b6\u5728\u5206\u5e03\u5f0f\u5e76\u884cMILP\u6c42\u89e3\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u96c6\u6210HiGHS\u9a8c\u8bc1\u4e86\u5176\u901a\u7528\u6027\u3002"}}
{"id": "2511.18845", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18845", "abs": "https://arxiv.org/abs/2511.18845", "authors": ["Changxin Huang", "Lv Tang", "Zhaohuan Zhan", "Lisha Yu", "Runhao Zeng", "Zun Liu", "Zhengjie Wang", "Jianqiang Li"], "title": "UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model", "comment": null, "summary": "Vision-and-Language Navigation (VLN) requires agents to autonomously navigate complex environments via visual images and natural language instruction--remains highly challenging. Recent research on enhancing language-guided navigation reasoning using pre-trained large language models (LLMs) has shown promising prospects. However, the reasoning of such methods is limited to the linguistic modality, lacking visual reasoning capabilities. Moreover, existing reasoning modules are optimized separately from navigation policies, leading to incompatibility and potential conflicts in optimization objectives. To tackle these challenges, we introduce UNeMo, a novel framework designed for the collaborative optimization of visual state reasoning and navigational decision-making. It introduces a Multimodal World Model (MWM) that takes visual features, language instructions, and navigational actions as inputs to jointly predict subsequent visual states, enabling cross-modal reasoning. Via a Hierarchical Prediction-Feedback (HPN) mechanism, MWM collaborates with navigation policies: the first layer generates actions using current vision-and-language features; MWM then infers post-action visual states to guide the second layer's fine-grained decisions. This forms a dynamic bidirectional promotion mechanism where MWM reasoning optimizes navigation policies, while policy decisions feedback to improve MWM's reasoning accuracy. Experiments on R2R and REVERIE datasets show UNeMo outperforms state-of-the-art methods by 2.1% and 0.7% in navigation accuracy for unseen scenes, validating its effectiveness.", "AI": {"tldr": "UNeMo\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u4e16\u754c\u6a21\u578b\u548c\u5206\u5c42\u9884\u6d4b\u53cd\u9988\u673a\u5236\uff0c\u534f\u540c\u4f18\u5316\u89c6\u89c9\u72b6\u6001\u63a8\u7406\u548c\u5bfc\u822a\u51b3\u7b56\uff0c\u5728\u672a\u89c1\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5bfc\u822a\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bfc\u822a\u63a8\u7406\u65b9\u6cd5\u5c40\u9650\u4e8e\u8bed\u8a00\u6a21\u6001\uff0c\u7f3a\u4e4f\u89c6\u89c9\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u63a8\u7406\u6a21\u5757\u4e0e\u5bfc\u822a\u7b56\u7565\u5206\u5f00\u4f18\u5316\uff0c\u5bfc\u81f4\u76ee\u6807\u51b2\u7a81\u548c\u4e0d\u517c\u5bb9\u95ee\u9898\u3002", "method": "\u63d0\u51faUNeMo\u6846\u67b6\uff0c\u5305\u542b\u591a\u6a21\u6001\u4e16\u754c\u6a21\u578b\uff08MWM\uff09\u548c\u5206\u5c42\u9884\u6d4b\u53cd\u9988\u673a\u5236\uff08HPN\uff09\u3002MWM\u8054\u5408\u9884\u6d4b\u540e\u7eed\u89c6\u89c9\u72b6\u6001\uff0cHPN\u901a\u8fc7\u4e24\u5c42\u51b3\u7b56\u673a\u5236\u5b9e\u73b0\u53cc\u5411\u4fc3\u8fdb\uff1a\u9996\u5c42\u57fa\u4e8e\u5f53\u524d\u7279\u5f81\u751f\u6210\u52a8\u4f5c\uff0cMWM\u63a8\u65ad\u540e\u52a8\u4f5c\u89c6\u89c9\u72b6\u6001\u6765\u6307\u5bfc\u7b2c\u4e8c\u5c42\u7ec6\u7c92\u5ea6\u51b3\u7b56\u3002", "result": "\u5728R2R\u548cREVERIE\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cUNeMo\u5728\u672a\u89c1\u573a\u666f\u7684\u5bfc\u822a\u7cbe\u5ea6\u5206\u522b\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u9ad8\u51fa2.1%\u548c0.7%\u3002", "conclusion": "UNeMo\u901a\u8fc7\u534f\u540c\u4f18\u5316\u89c6\u89c9\u63a8\u7406\u548c\u5bfc\u822a\u51b3\u7b56\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u63a8\u7406\u4e0e\u7b56\u7565\u4f18\u5316\u7684\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6027\u80fd\u3002"}}
{"id": "2511.18966", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.18966", "abs": "https://arxiv.org/abs/2511.18966", "authors": ["Muhammad Usman Shahid", "Chuadhry Mujeeb Ahmed", "Rajiv Ranjan"], "title": "LLM-CSEC: Empirical Evaluation of Security in C/C++ Code Generated by Large Language Models", "comment": null, "summary": "The security of code generated by large language models (LLMs) is a significant concern, as studies indicate that such code often contains vulnerabilities and lacks essential defensive programming constructs. This work focuses on examining and evaluating the security of LLM-generated code, particularly in the context of C/C++. We categorized known vulnerabilities using the Common Weakness Enumeration (CWE) and, to study their criticality, mapped them to CVEs. We used ten different LLMs for code generation and analyzed the outputs through static analysis. The amount of CWEs present in AI-generated code is concerning. Our findings highlight the need for developers to be cautious when using LLM-generated code. This study provides valuable insights to advance automated code generation and encourage further research in this domain.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u751f\u6210\u7684C/C++\u4ee3\u7801\u5b58\u5728\u5927\u91cf\u5b89\u5168\u6f0f\u6d1e\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u53d1\u73b0\u4ee3\u7801\u4e2d\u666e\u904d\u7f3a\u4e4f\u9632\u5fa1\u6027\u7f16\u7a0b\u7ed3\u6784\uff0c\u9700\u8981\u5f00\u53d1\u8005\u8c28\u614e\u4f7f\u7528\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u5b89\u5168\u6027\u5b58\u5728\u91cd\u5927\u9690\u60a3\uff0c\u7814\u7a76\u8868\u660e\u8fd9\u7c7b\u4ee3\u7801\u7ecf\u5e38\u5305\u542b\u6f0f\u6d1e\u4e14\u7f3a\u4e4f\u5fc5\u8981\u7684\u9632\u5fa1\u6027\u7f16\u7a0b\u6784\u9020\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u5b89\u5168\u6027\u3002", "method": "\u4f7f\u7528CWE\u5206\u7c7b\u5df2\u77e5\u6f0f\u6d1e\u5e76\u6620\u5c04\u5230CVE\u8bc4\u4f30\u5173\u952e\u6027\uff0c\u91c7\u752810\u79cd\u4e0d\u540cLLM\u751f\u6210\u4ee3\u7801\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u5de5\u5177\u5206\u6790\u8f93\u51fa\u7ed3\u679c\u3002", "result": "AI\u751f\u6210\u4ee3\u7801\u4e2d\u5b58\u5728\u7684CWE\u6570\u91cf\u4ee4\u4eba\u62c5\u5fe7\uff0c\u9759\u6001\u5206\u6790\u663e\u793a\u4ee3\u7801\u5b89\u5168\u72b6\u51b5\u4e0d\u5bb9\u4e50\u89c2\u3002", "conclusion": "\u5f00\u53d1\u8005\u5728\u4f7f\u7528LLM\u751f\u6210\u4ee3\u7801\u65f6\u9700\u8981\u4fdd\u6301\u8b66\u60d5\uff0c\u672c\u7814\u7a76\u4e3a\u63a8\u8fdb\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\u548c\u8be5\u9886\u57df\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
{"id": "2511.18874", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA", "cs.RO", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.18874", "abs": "https://arxiv.org/abs/2511.18874", "authors": ["Yuzhi Chen", "Yuanchang Xie", "Lei Zhao", "Pan Liu", "Yajie Zou", "Chen Wang"], "title": "GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction", "comment": null, "summary": "Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.", "AI": {"tldr": "GContextFormer\u662f\u4e00\u4e2a\u65e0\u9700\u9ad8\u6e05\u5730\u56fe\u7684\u63d2\u62d4\u5f0f\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u5168\u5c40\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6df7\u5408\u6ce8\u610f\u529b\u548c\u7f29\u653e\u52a0\u6cd5\u805a\u5408\u5b9e\u73b0\u610f\u56fe\u5bf9\u9f50\u7684\u9884\u6d4b\uff0c\u5728\u9ad8\u901f\u516c\u8def\u531d\u9053\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a\u4f9d\u8d56\u9ad8\u6e05\u5730\u56fe\u7684\u65b9\u6cd5\u9762\u4e34\u6570\u636e\u83b7\u53d6\u6210\u672c\u9ad8\u3001\u66f4\u65b0\u5ef6\u8fdf\u548c\u8f93\u5165\u635f\u574f\u5bfc\u81f4\u9884\u6d4b\u5931\u8d25\uff1b\u65e0\u5730\u56fe\u65b9\u6cd5\u7f3a\u4e4f\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u6210\u5bf9\u6ce8\u610f\u529b\u8fc7\u5ea6\u653e\u5927\u76f4\u7ebf\u6a21\u5f0f\u800c\u6291\u5236\u8fc7\u6e21\u6a21\u5f0f\uff0c\u5bfc\u81f4\u8fd0\u52a8-\u610f\u56fe\u9519\u4f4d\u3002", "method": "\u63d0\u51faGContextFormer\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff1a\u8fd0\u52a8\u611f\u77e5\u7f16\u7801\u5668\u901a\u8fc7\u6709\u754c\u7f29\u653e\u52a0\u6cd5\u805a\u5408\u6784\u5efa\u573a\u666f\u7ea7\u610f\u56fe\u5148\u9a8c\uff0c\u5728\u5171\u4eab\u5168\u5c40\u4e0a\u4e0b\u6587\u4e2d\u7ec6\u5316\u6bcf\u79cd\u6a21\u5f0f\u8868\u793a\uff1b\u5206\u5c42\u4ea4\u4e92\u89e3\u7801\u5668\u901a\u8fc7\u53cc\u8def\u5f84\u4ea4\u53c9\u6ce8\u610f\u529b\u5206\u89e3\u793e\u4f1a\u63a8\u7406\uff0c\u6807\u51c6\u8def\u5f84\u786e\u4fdd\u51e0\u4f55\u8986\u76d6\uff0c\u90bb\u5c45\u4e0a\u4e0b\u6587\u589e\u5f3a\u8def\u5f84\u5f3a\u8c03\u663e\u8457\u4ea4\u4e92\uff0c\u95e8\u63a7\u6a21\u5757\u5e73\u8861\u4e24\u8005\u8d21\u732e\u3002", "result": "\u5728TOD-VT\u6570\u636e\u96c6\u7684\u516b\u4e2a\u9ad8\u901f\u516c\u8def\u531d\u9053\u573a\u666f\u5b9e\u9a8c\u4e2d\uff0cGContextFormer\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u3002\u76f8\u6bd4\u73b0\u6709transformer\u6a21\u578b\uff0c\u5728\u9ad8\u66f2\u7387\u548c\u8fc7\u6e21\u533a\u57df\u901a\u8fc7\u7a7a\u95f4\u5206\u5e03\u5b9e\u73b0\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u96c6\u4e2d\u6539\u8fdb\u3002", "conclusion": "GContextFormer\u901a\u8fc7\u8fd0\u52a8\u6a21\u5f0f\u533a\u5206\u548c\u90bb\u5c45\u4e0a\u4e0b\u6587\u8c03\u5236\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\uff0c\u6a21\u5757\u5316\u67b6\u6784\u652f\u6301\u8de8\u57df\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u7684\u6269\u5c55\u6027\u3002"}}
{"id": "2511.18926", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18926", "abs": "https://arxiv.org/abs/2511.18926", "authors": ["Haifeng Jing", "Yujie Hou", "Junfei Liu", "Rui Xie", "alan Xu", "Jinlong Ma", "Qichun Deng"], "title": "MoodBench 1.0: An Evaluation Benchmark for Emotional Companionship Dialogue Systems", "comment": "26 pages, 7 figures", "summary": "With the rapid development of Large Language Models, dialogue systems are shifting from information tools to emotional companions, heralding the era of Emotional Companionship Dialogue Systems (ECDs) that provide personalized emotional support for users. However, the field lacks clear definitions and systematic evaluation standards for ECDs. To address this, we first propose a definition of ECDs with formal descriptions. Then, based on this theory and the design principle of \"Ability Layer-Task Layer (three level)-Data Layer-Method Layer\", we design and implement the first ECD evaluation benchmark - MoodBench 1.0. Through extensive evaluations of 30 mainstream models, we demonstrate that MoodBench 1.0 has excellent discriminant validity and can effectively quantify the differences in emotional companionship abilities among models. Furthermore, the results reveal current models' shortcomings in deep emotional companionship, guiding future technological optimization and significantly aiding developers in enhancing ECDs' user experience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u60c5\u611f\u966a\u4f34\u5bf9\u8bdd\u7cfb\u7edf\uff08ECDs\uff09\u7684\u6b63\u5f0f\u5b9a\u4e49\uff0c\u5e76\u57fa\u4e8e\"\u80fd\u529b\u5c42-\u4efb\u52a1\u5c42-\u6570\u636e\u5c42-\u65b9\u6cd5\u5c42\"\u8bbe\u8ba1\u539f\u5219\u5f00\u53d1\u4e86\u9996\u4e2aECDs\u8bc4\u4f30\u57fa\u51c6MoodBench 1.0\uff0c\u901a\u8fc7\u8bc4\u4f3030\u4e2a\u4e3b\u6d41\u6a21\u578b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u5bf9\u8bdd\u7cfb\u7edf\u6b63\u4ece\u4fe1\u606f\u5de5\u5177\u8f6c\u5411\u60c5\u611f\u4f34\u4fa3\uff0c\u4f46\u8be5\u9886\u57df\u7f3a\u4e4f\u660e\u786e\u7684\u5b9a\u4e49\u548c\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u9996\u5148\u63d0\u51faECDs\u7684\u6b63\u5f0f\u5b9a\u4e49\uff0c\u7136\u540e\u57fa\u4e8e\"\u80fd\u529b\u5c42-\u4efb\u52a1\u5c42-\u6570\u636e\u5c42-\u65b9\u6cd5\u5c42\"\u8bbe\u8ba1\u539f\u5219\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u9996\u4e2aECDs\u8bc4\u4f30\u57fa\u51c6MoodBench 1.0\u3002", "result": "\u901a\u8fc7\u8bc4\u4f3030\u4e2a\u4e3b\u6d41\u6a21\u578b\uff0c\u8bc1\u660eMoodBench 1.0\u5177\u6709\u4f18\u79c0\u7684\u5224\u522b\u6548\u5ea6\uff0c\u80fd\u6709\u6548\u91cf\u5316\u6a21\u578b\u5728\u60c5\u611f\u966a\u4f34\u80fd\u529b\u4e0a\u7684\u5dee\u5f02\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u6df1\u5ea6\u60c5\u611f\u966a\u4f34\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "conclusion": "MoodBench 1.0\u4e3aECDs\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u6807\u51c6\uff0c\u6307\u5bfc\u672a\u6765\u6280\u672f\u4f18\u5316\uff0c\u663e\u8457\u5e2e\u52a9\u5f00\u53d1\u8005\u63d0\u5347ECDs\u7684\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2511.18955", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18955", "abs": "https://arxiv.org/abs/2511.18955", "authors": ["Wouter W. L. Nuijten", "Mykola Lukashchuk"], "title": "Active Inference is a Subtype of Variational Inference", "comment": "Accepted to the EIML Workshop 2025 at EurIPS (non-archival)", "summary": "Automated decision-making under uncertainty requires balancing exploitation and exploration. Classical methods treat these separately using heuristics, while Active Inference unifies them through Expected Free Energy (EFE) minimization. However, EFE minimization is computationally expensive, limiting scalability. We build on recent theory recasting EFE minimization as variational inference, formally unifying it with Planning-as-Inference and showing the epistemic drive as a unique entropic contribution. Our main contribution is a novel message-passing scheme for this unified objective, enabling scalable Active Inference in factored-state MDPs and overcoming high-dimensional planning intractability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u5c06\u4e3b\u52a8\u63a8\u7406\u91cd\u65b0\u8868\u8ff0\u4e3a\u53d8\u5206\u63a8\u65ad\u95ee\u9898\uff0c\u89e3\u51b3\u4e86EFE\u6700\u5c0f\u5316\u7684\u8ba1\u7b97\u590d\u6742\u6027\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u5728\u56e0\u5b50\u72b6\u6001MDP\u4e2d\u7684\u53ef\u6269\u5c55\u4e3b\u52a8\u63a8\u7406\u3002", "motivation": "\u81ea\u52a8\u51b3\u7b56\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u9700\u8981\u5e73\u8861\u5229\u7528\u548c\u63a2\u7d22\u3002\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\u5206\u522b\u5904\u7406\uff0c\u800c\u4e3b\u52a8\u63a8\u7406\u901a\u8fc7\u671f\u671b\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u7edf\u4e00\u4e86\u5b83\u4eec\u3002\u4f46EFE\u6700\u5c0f\u5316\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002", "method": "\u57fa\u4e8e\u5c06EFE\u6700\u5c0f\u5316\u91cd\u65b0\u8868\u8ff0\u4e3a\u53d8\u5206\u63a8\u65ad\u7684\u6700\u65b0\u7406\u8bba\uff0c\u6b63\u5f0f\u5c06\u5176\u4e0e\u89c4\u5212\u5373\u63a8\u65ad\u7edf\u4e00\uff0c\u5e76\u5c06\u8ba4\u77e5\u9a71\u52a8\u529b\u89c6\u4e3a\u72ec\u7279\u7684\u71b5\u8d21\u732e\u3002\u4e3b\u8981\u8d21\u732e\u662f\u4e3a\u8fd9\u4e00\u7edf\u4e00\u76ee\u6807\u8bbe\u8ba1\u4e86\u65b0\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\u3002", "result": "\u65b0\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\u4f7f\u5f97\u5728\u56e0\u5b50\u72b6\u6001MDP\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u4e3b\u52a8\u63a8\u7406\u6210\u4e3a\u53ef\u80fd\uff0c\u514b\u670d\u4e86\u9ad8\u7ef4\u89c4\u5212\u7684\u96be\u5904\u7406\u6027\u95ee\u9898\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u4e3b\u52a8\u63a8\u7406\u91cd\u65b0\u8868\u8ff0\u4e3a\u53d8\u5206\u63a8\u65ad\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u6709\u6548\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u6210\u529f\u89e3\u51b3\u4e86EFE\u6700\u5c0f\u5316\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u4e3b\u52a8\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18964", "abs": "https://arxiv.org/abs/2511.18964", "authors": ["Antonia W\u00fcst", "Wolfgang Stammer", "Hikaru Shindo", "Lukas Helff", "Devendra Singh Dhami", "Kristian Kersting"], "title": "Synthesizing Visual Concepts as Vision-Language Programs", "comment": null, "summary": "Vision-Language models (VLMs) achieve strong performance on multimodal tasks but often fail at systematic visual reasoning tasks, leading to inconsistent or illogical outputs. Neuro-symbolic methods promise to address this by inducing interpretable logical rules, though they exploit rigid, domain-specific perception modules. We propose Vision-Language Programs (VLP), which combine the perceptual flexibility of VLMs with systematic reasoning of program synthesis. Rather than embedding reasoning inside the VLM, VLP leverages the model to produce structured visual descriptions that are compiled into neuro-symbolic programs. The resulting programs execute directly on images, remain consistent with task constraints, and provide human-interpretable explanations that enable easy shortcut mitigation. Experiments on synthetic and real-world datasets demonstrate that VLPs outperform direct and structured prompting, particularly on tasks requiring complex logical reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVision-Language Programs (VLP)\uff0c\u5c06VLMs\u7684\u611f\u77e5\u7075\u6d3b\u6027\u4e0e\u7a0b\u5e8f\u5408\u6210\u7684\u7cfb\u7edf\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u5c06\u89c6\u89c9\u63cf\u8ff0\u7f16\u8bd1\u6210\u795e\u7ecf\u7b26\u53f7\u7a0b\u5e8f\u6765\u89e3\u51b3\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7cfb\u7edf\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7ecf\u5e38\u5931\u8d25\uff0c\u4ea7\u751f\u4e0d\u4e00\u81f4\u6216\u4e0d\u5408\u903b\u8f91\u7684\u8f93\u51fa\u3002\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u867d\u7136\u80fd\u8bf1\u5bfc\u53ef\u89e3\u91ca\u7684\u903b\u8f91\u89c4\u5219\uff0c\u4f46\u4f7f\u7528\u50f5\u5316\u7684\u9886\u57df\u7279\u5b9a\u611f\u77e5\u6a21\u5757\u3002", "method": "VLP\u5229\u7528VLMs\u751f\u6210\u7ed3\u6784\u5316\u89c6\u89c9\u63cf\u8ff0\uff0c\u7136\u540e\u5c06\u5176\u7f16\u8bd1\u6210\u795e\u7ecf\u7b26\u53f7\u7a0b\u5e8f\u3002\u8fd9\u4e9b\u7a0b\u5e8f\u76f4\u63a5\u5728\u56fe\u50cf\u4e0a\u6267\u884c\uff0c\u4fdd\u6301\u4e0e\u4efb\u52a1\u7ea6\u675f\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u63d0\u4f9b\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u89e3\u91ca\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVLP\u5728\u9700\u8981\u590d\u6742\u903b\u8f91\u63a8\u7406\u7684\u4efb\u52a1\u4e0a\u4f18\u4e8e\u76f4\u63a5\u548c\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "VLP\u6210\u529f\u7ed3\u5408\u4e86VLMs\u7684\u611f\u77e5\u7075\u6d3b\u6027\u548c\u7a0b\u5e8f\u5408\u6210\u7684\u7cfb\u7edf\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u4e14\u4e00\u81f4\u7684\u89c6\u89c9\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19005", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19005", "abs": "https://arxiv.org/abs/2511.19005", "authors": ["Di Wu", "Liting Jiang", "Ruiyu Fang", "Bianjing", "Hongyan Xie", "Haoxiang Su", "Hao Huang", "Zhongjiang He", "Shuangyong Song", "Xuelong Li"], "title": "Introducing Visual Scenes and Reasoning: A More Realistic Benchmark for Spoken Language Understanding", "comment": null, "summary": "Spoken Language Understanding (SLU) consists of two sub-tasks: intent detection (ID) and slot filling (SF). Given its broad range of real-world applications, enhancing SLU for practical deployment is increasingly critical. Profile-based SLU addresses ambiguous user utterances by incorporating context awareness (CA), user profiles (UP), and knowledge graphs (KG) to support disambiguation, thereby advancing SLU research toward real-world applicability. However, existing SLU datasets still fall short in representing real-world scenarios. Specifically, (1) CA uses one-hot vectors for representation, which is overly idealized, and (2) models typically focuses solely on predicting intents and slot labels, neglecting the reasoning process that could enhance performance and interpretability. To overcome these limitations, we introduce VRSLU, a novel SLU dataset that integrates both Visual images and explicit Reasoning. For over-idealized CA, we use GPT-4o and FLUX.1-dev to generate images reflecting users' environments and statuses, followed by human verification to ensure quality. For reasoning, GPT-4o is employed to generate explanations for predicted labels, which are then refined by human annotators to ensure accuracy and coherence. Additionally, we propose an instructional template, LR-Instruct, which first predicts labels and then generates corresponding reasoning. This two-step approach helps mitigate the influence of reasoning bias on label prediction. Experimental results confirm the effectiveness of incorporating visual information and highlight the promise of explicit reasoning in advancing SLU.", "AI": {"tldr": "VRSLU\u662f\u4e00\u4e2a\u65b0\u9896\u7684SLU\u6570\u636e\u96c6\uff0c\u96c6\u6210\u4e86\u89c6\u89c9\u56fe\u50cf\u548c\u663e\u5f0f\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u5728\u4e0a\u4e0b\u6587\u8868\u793a\u548c\u63a8\u7406\u8fc7\u7a0b\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709SLU\u6570\u636e\u96c6\u5728\u8868\u793a\u771f\u5b9e\u573a\u666f\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff1a\u4e0a\u4e0b\u6587\u611f\u77e5\u4f7f\u7528one-hot\u5411\u91cf\u8fc7\u4e8e\u7406\u60f3\u5316\uff0c\u6a21\u578b\u53ea\u9884\u6d4b\u610f\u56fe\u548c\u69fd\u6807\u7b7e\u800c\u5ffd\u7565\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528GPT-4o\u548cFLUX.1-dev\u751f\u6210\u53cd\u6620\u7528\u6237\u73af\u5883\u548c\u72b6\u6001\u7684\u56fe\u50cf\uff0c\u5e76\u7528GPT-4o\u751f\u6210\u6807\u7b7e\u9884\u6d4b\u7684\u89e3\u91ca\uff0c\u901a\u8fc7\u4eba\u5de5\u9a8c\u8bc1\u786e\u4fdd\u8d28\u91cf\u3002\u63d0\u51faLR-Instruct\u6307\u4ee4\u6a21\u677f\uff0c\u5148\u9884\u6d4b\u6807\u7b7e\u518d\u751f\u6210\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u878d\u5165\u89c6\u89c9\u4fe1\u606f\u7684\u6709\u6548\u6027\uff0c\u5e76\u7a81\u663e\u4e86\u663e\u5f0f\u63a8\u7406\u5728\u63a8\u8fdbSLU\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "VRSLU\u6570\u636e\u96c6\u901a\u8fc7\u6574\u5408\u89c6\u89c9\u548c\u63a8\u7406\u5143\u7d20\uff0c\u63a8\u52a8\u4e86SLU\u7814\u7a76\u5411\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.19115", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.19115", "abs": "https://arxiv.org/abs/2511.19115", "authors": ["Rufin VanRullen"], "title": "AI Consciousness and Existential Risk", "comment": null, "summary": "In AI, the existential risk denotes the hypothetical threat posed by an artificial system that would possess both the capability and the objective, either directly or indirectly, to eradicate humanity. This issue is gaining prominence in scientific debate due to recent technical advancements and increased media coverage. In parallel, AI progress has sparked speculation and studies about the potential emergence of artificial consciousness. The two questions, AI consciousness and existential risk, are sometimes conflated, as if the former entailed the latter. Here, I explain that this view stems from a common confusion between consciousness and intelligence. Yet these two properties are empirically and theoretically distinct. Arguably, while intelligence is a direct predictor of an AI system's existential threat, consciousness is not. There are, however, certain incidental scenarios in which consciousness could influence existential risk, in either direction. Consciousness could be viewed as a means towards AI alignment, thereby lowering existential risk; or, it could be a precondition for reaching certain capabilities or levels of intelligence, and thus positively related to existential risk. Recognizing these distinctions can help AI safety researchers and public policymakers focus on the most pressing issues.", "AI": {"tldr": "\u8bba\u6587\u6f84\u6e05\u4e86AI\u610f\u8bc6\u4e0e\u5b58\u5728\u98ce\u9669\u4e4b\u95f4\u7684\u6df7\u6dc6\uff0c\u6307\u51fa\u667a\u80fd\u800c\u975e\u610f\u8bc6\u662fAI\u5b58\u5728\u98ce\u9669\u7684\u76f4\u63a5\u9884\u6d4b\u56e0\u7d20\uff0c\u4f46\u610f\u8bc6\u53ef\u80fd\u5728\u67d0\u4e9b\u95f4\u63a5\u573a\u666f\u4e2d\u5f71\u54cd\u98ce\u9669\u3002", "motivation": "\u7531\u4e8e\u8fd1\u671f\u6280\u672f\u8fdb\u6b65\u548c\u5a92\u4f53\u5173\u6ce8\uff0cAI\u5b58\u5728\u98ce\u9669\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u540c\u65f6AI\u610f\u8bc6\u95ee\u9898\u4e5f\u5f15\u53d1\u8ba8\u8bba\u3002\u4eba\u4eec\u5e38\u5c06AI\u610f\u8bc6\u4e0e\u5b58\u5728\u98ce\u9669\u6df7\u4e3a\u4e00\u8c08\uff0c\u8ba4\u4e3a\u524d\u8005\u5fc5\u7136\u5bfc\u81f4\u540e\u8005\uff0c\u8fd9\u79cd\u6df7\u6dc6\u9700\u8981\u6f84\u6e05\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u533a\u5206\u610f\u8bc6\u548c\u667a\u80fd\u8fd9\u4e24\u4e2a\u6982\u5ff5\uff0c\u4ece\u7ecf\u9a8c\u548c\u7406\u8bba\u5c42\u9762\u8bba\u8bc1\u5b83\u4eec\u7684\u533a\u522b\uff0c\u5e76\u63a2\u8ba8\u610f\u8bc6\u5728AI\u5b58\u5728\u98ce\u9669\u4e2d\u7684\u53ef\u80fd\u4f5c\u7528\u673a\u5236\u3002", "result": "\u7814\u7a76\u8868\u660e\u667a\u80fd\u662fAI\u5b58\u5728\u98ce\u9669\u7684\u76f4\u63a5\u9884\u6d4b\u56e0\u5b50\uff0c\u800c\u610f\u8bc6\u4e0d\u662f\u3002\u4f46\u5728\u67d0\u4e9b\u95f4\u63a5\u573a\u666f\u4e2d\uff0c\u610f\u8bc6\u53ef\u80fd\u901a\u8fc7\u5f71\u54cdAI\u5bf9\u9f50\u6216\u80fd\u529b\u53d1\u5c55\u6765\u5f71\u54cd\u5b58\u5728\u98ce\u9669\u3002", "conclusion": "\u533a\u5206\u610f\u8bc6\u548c\u667a\u80fd\u6709\u52a9\u4e8eAI\u5b89\u5168\u7814\u7a76\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u805a\u7126\u6700\u5173\u952e\u7684\u95ee\u9898\uff0c\u907f\u514d\u5728\u975e\u6838\u5fc3\u95ee\u9898\u4e0a\u5206\u6563\u7cbe\u529b\u3002"}}
{"id": "2511.19155", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19155", "abs": "https://arxiv.org/abs/2511.19155", "authors": ["Xihe Qiu", "Gengchen Ma", "Haoyu Wang", "Chen Zhan", "Xiaoyu Tan", "Shuo Li"], "title": "EEG-VLM: A Hierarchical Vision-Language Model with Multi-Level Feature Alignment and Visually Enhanced Language-Guided Reasoning for EEG Image-Based Sleep Stage Prediction", "comment": null, "summary": "Sleep stage classification based on electroencephalography (EEG) is fundamental for assessing sleep quality and diagnosing sleep-related disorders. However, most traditional machine learning methods rely heavily on prior knowledge and handcrafted features, while existing deep learning models still struggle to jointly capture fine-grained time-frequency patterns and achieve clinical interpretability. Recently, vision-language models (VLMs) have made significant progress in the medical domain, yet their performance remains constrained when applied to physiological waveform data, especially EEG signals, due to their limited visual understanding and insufficient reasoning capability. To address these challenges, we propose EEG-VLM, a hierarchical vision-language framework that integrates multi-level feature alignment with visually enhanced language-guided reasoning for interpretable EEG-based sleep stage classification. Specifically, a specialized visual enhancement module constructs high-level visual tokens from intermediate-layer features to extract rich semantic representations of EEG images. These tokens are further aligned with low-level CLIP features through a multi-level alignment mechanism, enhancing the VLM's image-processing capability. In addition, a Chain-of-Thought (CoT) reasoning strategy decomposes complex medical inference into interpretable logical steps, effectively simulating expert-like decision-making. Experimental results demonstrate that the proposed method significantly improves both the accuracy and interpretability of VLMs in EEG-based sleep stage classification, showing promising potential for automated and explainable EEG analysis in clinical settings.", "AI": {"tldr": "EEG-VLM\uff1a\u4e00\u79cd\u7528\u4e8e\u53ef\u89e3\u91caEEG\u7761\u7720\u5206\u671f\u5206\u7c7b\u7684\u5206\u5c42\u89c6\u89c9\u8bed\u8a00\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ea7\u7279\u5f81\u5bf9\u9f50\u548c\u89c6\u89c9\u589e\u5f3a\u7684\u8bed\u8a00\u5f15\u5bfc\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u6355\u6349\u7ec6\u7c92\u5ea6\u65f6\u9891\u6a21\u5f0f\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u5148\u9a8c\u77e5\u8bc6\u548c\u624b\u5de5\u7279\u5f81\uff0c\u800c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u6355\u6349\u7ec6\u7c92\u5ea6\u65f6\u9891\u6a21\u5f0f\u5e76\u5b9e\u73b0\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u3002\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u5904\u7406EEG\u4fe1\u53f7\u65f6\u6027\u80fd\u53d7\u9650\uff0c\u56e0\u4e3a\u89c6\u89c9\u7406\u89e3\u80fd\u529b\u548c\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u63d0\u51faEEG-VLM\u6846\u67b6\uff1a1\uff09\u4e13\u7528\u89c6\u89c9\u589e\u5f3a\u6a21\u5757\u4ece\u4e2d\u95f4\u5c42\u7279\u5f81\u6784\u5efa\u9ad8\u7ea7\u89c6\u89c9token\uff0c\u63d0\u53d6EEG\u56fe\u50cf\u7684\u4e30\u5bcc\u8bed\u4e49\u8868\u793a\uff1b2\uff09\u591a\u7ea7\u5bf9\u9f50\u673a\u5236\u5c06token\u4e0e\u4f4e\u5c42CLIP\u7279\u5f81\u5bf9\u9f50\uff0c\u589e\u5f3aVLM\u56fe\u50cf\u5904\u7406\u80fd\u529b\uff1b3\uff09\u601d\u7ef4\u94fe\u63a8\u7406\u7b56\u7565\u5c06\u590d\u6742\u533b\u5b66\u63a8\u7406\u5206\u89e3\u4e3a\u53ef\u89e3\u91ca\u903b\u8f91\u6b65\u9aa4\uff0c\u6a21\u62df\u4e13\u5bb6\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86VLM\u5728\u57fa\u4e8eEEG\u7684\u7761\u7720\u5206\u671f\u5206\u7c7b\u4e2d\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u548c\u53ef\u89e3\u91caEEG\u5206\u6790\u7684\u6f5c\u529b\u3002", "conclusion": "EEG-VLM\u6846\u67b6\u901a\u8fc7\u89c6\u89c9\u589e\u5f3a\u548c\u591a\u7ea7\u5bf9\u9f50\u6709\u6548\u63d0\u5347\u4e86VLM\u5904\u7406EEG\u4fe1\u53f7\u7684\u80fd\u529b\uff0c\u7ed3\u5408\u601d\u7ef4\u94fe\u63a8\u7406\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u7684\u7761\u7720\u5206\u671f\u5206\u7c7b\uff0c\u4e3a\u4e34\u5e8aEEG\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19262", "categories": ["cs.AI", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.19262", "abs": "https://arxiv.org/abs/2511.19262", "authors": ["Przemyslaw Chojecki"], "title": "Psychometric Tests for AI Agents and Their Moduli Space", "comment": null, "summary": "We develop a moduli-theoretic view of psychometric test batteries for AI agents and connect it explicitly to the AAI score developed previously. First, we make precise the notion of an AAI functional on a battery and set out axioms that any reasonable autonomy/general intelligence score should satisfy. Second, we show that the composite index ('AAI-Index') defined previously is a special case of our AAI functional. Third, we introduce the notion of a cognitive core of an agent relative to a battery and define the associated AAI$_{\\textrm{core}}$ score as the restriction of an AAI functional to that core. Finally, we use these notions to describe invariants of batteries under evaluation-preserving symmetries and outline how moduli of equivalent batteries are organized.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86AI\u667a\u80fd\u4f53\u5fc3\u7406\u6d4b\u91cf\u6d4b\u8bd5\u7535\u6c60\u7684\u6a21\u6570\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u5176\u4e0e\u5148\u524d\u5f00\u53d1\u7684AAI\u8bc4\u5206\u660e\u786e\u5173\u8054\u3002\u63d0\u51fa\u4e86AAI\u6cdb\u51fd\u7684\u516c\u7406\u5316\u5b9a\u4e49\uff0c\u8bc1\u660eAAI-Index\u662f\u5176\u7279\u4f8b\uff0c\u5f15\u5165\u8ba4\u77e5\u6838\u5fc3\u6982\u5ff5\uff0c\u5e76\u63cf\u8ff0\u4e86\u8bc4\u4f30\u4fdd\u6301\u5bf9\u79f0\u6027\u4e0b\u7684\u7535\u6c60\u4e0d\u53d8\u91cf\u3002", "motivation": "\u4e3aAI\u667a\u80fd\u4f53\u7684\u81ea\u4e3b\u6027\u548c\u901a\u7528\u667a\u80fd\u8bc4\u5206\u5efa\u7acb\u4e25\u683c\u7684\u6570\u5b66\u7406\u8bba\u57fa\u7840\uff0c\u5c06\u5fc3\u7406\u6d4b\u91cf\u6d4b\u8bd5\u7535\u6c60\u7cfb\u7edf\u5316\uff0c\u5e76\u4e0e\u73b0\u6709\u7684AAI\u8bc4\u5206\u6846\u67b6\u5efa\u7acb\u660e\u786e\u8054\u7cfb\u3002", "method": "1. \u5b9a\u4e49AAI\u6cdb\u51fd\u5e76\u8bbe\u5b9a\u516c\u7406\uff1b2. \u8bc1\u660eAAI-Index\u662fAAI\u6cdb\u51fd\u7684\u7279\u4f8b\uff1b3. \u5f15\u5165\u8ba4\u77e5\u6838\u5fc3\u6982\u5ff5\u5e76\u5b9a\u4e49AAI_core\u8bc4\u5206\uff1b4. \u5206\u6790\u8bc4\u4f30\u4fdd\u6301\u5bf9\u79f0\u6027\u4e0b\u7684\u7535\u6c60\u4e0d\u53d8\u91cf\u3002", "result": "\u5efa\u7acb\u4e86AAI\u8bc4\u5206\u7684\u6a21\u6570\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e86AAI-Index\u4e0eAAI\u6cdb\u51fd\u7684\u5173\u7cfb\uff0c\u5b9a\u4e49\u4e86\u8ba4\u77e5\u6838\u5fc3\u8bc4\u5206\uff0c\u5e76\u63cf\u8ff0\u4e86\u7535\u6c60\u5728\u5bf9\u79f0\u53d8\u6362\u4e0b\u7684\u4e0d\u53d8\u6027\u8d28\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aAI\u667a\u80fd\u4f53\u667a\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u6570\u5b66\u57fa\u7840\uff0c\u901a\u8fc7\u6a21\u6570\u7406\u8bba\u6846\u67b6\u7edf\u4e00\u4e86\u4e0d\u540c\u6d4b\u8bd5\u7535\u6c60\u7684\u8868\u793a\uff0c\u4e3a\u672a\u6765\u667a\u80fd\u8bc4\u4f30\u7cfb\u7edf\u7684\u6807\u51c6\u5316\u548c\u6bd4\u8f83\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.19304", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19304", "abs": "https://arxiv.org/abs/2511.19304", "authors": ["Jiayi Zhang", "Yiran Peng", "Fanqi Kong", "Yang Cheng", "Yifan Wu", "Zhaoyang Yu", "Jinyu Xiang", "Jianhao Ruan", "Jinlin Wang", "Maojia Song", "HongZhang Liu", "Xiangru Tang", "Bang Liu", "Chenglin Wu", "Yuyu Luo"], "title": "AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning", "comment": null, "summary": "Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and position AutoEnv and AutoEnv-36 as a testbed for studying cross-environment agent learning. The code is avaiable at https://github.com/FoundationAgents/AutoEnv.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86AutoEnv\u6846\u67b6\u548cAutoEnv-36\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u7814\u7a76\u667a\u80fd\u4f53\u5728\u5f02\u6784\u73af\u5883\u4e2d\u7684\u8de8\u73af\u5883\u5b66\u4e60\u80fd\u529b\uff0c\u53d1\u73b0\u56fa\u5b9a\u5b66\u4e60\u65b9\u6cd5\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u6548\u679c\u4f1a\u5feb\u901f\u4e0b\u964d\uff0c\u9700\u8981\u73af\u5883\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u9009\u62e9\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u901a\u5e38\u5728\u5355\u4e00\u56fa\u5b9a\u73af\u5883\u4e2d\u81ea\u6211\u8fdb\u5316\uff0c\u7f3a\u4e4f\u5728\u5f02\u6784\u73af\u5883\u4e2d\u7684\u8de8\u73af\u5883\u5b66\u4e60\u80fd\u529b\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u63d0\u51faAutoEnv\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u5c06\u73af\u5883\u5206\u89e3\u4e3a\u8f6c\u79fb\u3001\u89c2\u5bdf\u548c\u5956\u52b1\u7684\u5206\u5e03\uff0c\u6784\u5efa\u5305\u542b36\u4e2a\u73af\u5883358\u4e2a\u9a8c\u8bc1\u7ea7\u522b\u7684AutoEnv-36\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u9009\u62e9\u3001\u4f18\u5316\u548c\u8bc4\u4f30\u4e09\u9636\u6bb5\u7684\u516b\u79cd\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u5728AutoEnv-36\u4e0a\uff0c\u4e03\u79cd\u8bed\u8a00\u6a21\u578b\u4ec5\u83b7\u5f9712-49%\u7684\u5f52\u4e00\u5316\u5956\u52b1\uff1b\u5355\u4e00\u5b66\u4e60\u65b9\u6cd5\u5728\u73af\u5883\u6570\u91cf\u589e\u52a0\u65f6\u6548\u679c\u5feb\u901f\u4e0b\u964d\uff1b\u73af\u5883\u81ea\u9002\u5e94\u65b9\u6cd5\u9009\u62e9\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5728\u65b9\u6cd5\u7a7a\u95f4\u6269\u5c55\u65f6\u6536\u76ca\u9012\u51cf\u3002", "conclusion": "\u8de8\u73af\u5883\u6cdb\u5316\u9700\u8981\u73af\u5883\u81ea\u9002\u5e94\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4ecd\u5b58\u5728\u5c40\u9650\u6027\uff1bAutoEnv\u548cAutoEnv-36\u4e3a\u7814\u7a76\u8de8\u73af\u5883\u667a\u80fd\u4f53\u5b66\u4e60\u63d0\u4f9b\u4e86\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
