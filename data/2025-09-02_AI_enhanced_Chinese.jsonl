{"id": "2508.21204", "categories": ["cs.AI", "cs.CL", "I.2.7; I.2.11; I.2.6"], "pdf": "https://arxiv.org/pdf/2508.21204", "abs": "https://arxiv.org/abs/2508.21204", "authors": ["Vanessa Figueiredo"], "title": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "comment": null, "summary": "We study how architectural inductive biases influence the cognitive behavior\nof large language models (LLMs) in instructional dialogue. We introduce a\nsymbolic scaffolding mechanism paired with a short-term memory schema designed\nto promote adaptive, structured reasoning in Socratic tutoring. Using\ncontrolled ablation across five system variants, we evaluate model outputs via\nexpert-designed rubrics covering scaffolding, responsiveness, symbolic\nreasoning, and conversational memory. We present preliminary results using an\nLLM-based evaluation framework aligned to a cognitively grounded rubric. This\nenables scalable, systematic comparisons across architectural variants in\nearly-stage experimentation. The preliminary results show that our full system\nconsistently outperforms baseline variants. Analysis reveals that removing\nmemory or symbolic structure degrades key cognitive behaviors, including\nabstraction, adaptive probing, and conceptual continuity. These findings\nsupport a processing-level account in which architectural scaffolds can\nreliably shape emergent instructional strategies in LLMs.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u67b6\u6784\u5f15\u5bfc\u504f\u7f6e\u5982\u4f55\u5f71\u54cd\u6559\u5b66\u5bf9\u8bdd\u4e2d\u7684\u8ba4\u77e5\u884c\u4e3a\uff0c\u901a\u8fc7\u7b26\u53f7\u811a\u624b\u67b6\u548c\u77ed\u671f\u8bb0\u5fc6\u673a\u5236\u63d0\u5347\u9002\u5e94\u6027\u601d\u7ef4\u80fd\u529b\u3002", "motivation": "\u63a2\u7d22\u67b6\u6784\u8bbe\u8ba1\u5bf9LLMs\u5728\u6559\u80b2\u5bf9\u8bdd\u4e2d\u8ba4\u77e5\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u5728\u82cf\u683c\u62c9\u5e95\u5f0f\u6559\u5b66\u4e2d\u7684\u7406\u6027\u601d\u7ef4\u80fd\u529b\u3002", "method": "\u91c7\u7528\u7b26\u53f7\u811a\u624b\u67b6\u673a\u5236\u914d\u5408\u77ed\u671f\u8bb0\u5fc6\u6a21\u5f0f\uff0c\u901a\u8fc75\u4e2a\u7cfb\u7edf\u53d8\u4f53\u7684\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u4f7f\u7528\u4e13\u5bb6\u8bbe\u8ba1\u7684\u8bc4\u4ef7\u6807\u51c6\u8fdb\u884c\u8ba4\u77e5\u884c\u4e3a\u5206\u6790\u3002", "result": "\u5b8c\u6574\u7cfb\u7edf\u5728\u811a\u624b\u67b6\u3001\u54cd\u5e94\u6027\u3001\u7b26\u53f7\u601d\u7ef4\u548c\u5bf9\u8bdd\u8bb0\u5fc6\u65b9\u9762\u5747\u8d85\u8fc7\u57fa\u7ebf\u53d8\u4f53\uff0c\u79fb\u9664\u8bb0\u5fc6\u6216\u7b26\u53f7\u7ed3\u6784\u4f1a\u5bf9\u62bd\u8c61\u3001\u9002\u5e94\u6027\u63a2\u6d4b\u548c\u6982\u5ff5\u8fde\u7eed\u6027\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "\u67b6\u6784\u811a\u624b\u67b6\u80fd\u591f\u53ef\u9760\u5730\u5f62\u6210LLMs\u4e2d\u6d3e\u751f\u7684\u6559\u5b66\u7b56\u7565\uff0c\u652f\u6301\u4e86\u5904\u7406\u7ea7\u522b\u7684\u8ba4\u77e5\u5f62\u6210\u673a\u5236\u3002"}}
{"id": "2508.21238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21238", "abs": "https://arxiv.org/abs/2508.21238", "authors": ["Tingxuan Xu", "Jiarui Feng", "Justin Melendez", "Kaleigh Roberts", "Donghong Cai", "Mingfang Zhu", "Donald Elbert", "Yixin Chen", "Randall J. Bateman"], "title": "Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs", "comment": null, "summary": "In the past two years, large language model (LLM)-based chatbots, such as\nChatGPT, have revolutionized various domains by enabling diverse task\ncompletion and question-answering capabilities. However, their application in\nscientific research remains constrained by challenges such as hallucinations,\nlimited domain-specific knowledge, and lack of explainability or traceability\nfor the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has\nemerged as a promising approach to improving chatbot reliability by integrating\ndomain-specific contextual information before response generation, addressing\nsome limitations of standard LLMs. Despite its potential, there are only\nlimited studies that evaluate GraphRAG on specific domains that require\nintensive knowledge, like Alzheimer's disease or other biomedical domains. In\nthis paper, we assess the quality and traceability of two popular GraphRAG\nsystems. We compile a database of 50 papers and 70 expert questions related to\nAlzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as\nthe LLM for answering queries. We then compare the quality of responses\ngenerated by GraphRAG with those from a standard GPT-4o model. Additionally, we\ndiscuss and evaluate the traceability of several Retrieval-Augmented Generation\n(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a\npre-built Alzheimer's disease database for researchers to test the performance\nof both standard RAG and GraphRAG.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8bc4\u4f30\u4e86GraphRAG\u7cfb\u7edf\u5728\u963f\u5c14\u832b\u6d77\u9ed8\u75c5\u751f\u7269\u533b\u5b66\u9886\u57df\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u79d1\u95ee\u7b54\u8d28\u91cf\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u6613\u7528\u7684\u6d4b\u8bd5\u754c\u9762\u548c\u9884\u5efa\u6570\u636e\u5e93\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u9886\u57df\u53d1\u6325\u4f5c\u7528\uff0c\u4f46\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u4ecd\u9047\u5230\u5e7b\u89c9\u3001\u9886\u57df\u77e5\u8bc6\u7f3a\u4e4f\u3001\u56de\u7b54\u4e0d\u53ef\u8ffd\u6eaf\u7b49\u6311\u6218\u3002GraphRAG\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u901a\u8fc7\u6574\u5408\u9886\u57df\u7279\u5b9a\u4e0a\u4e0b\u6587\u4fe1\u606f\u6765\u63d0\u9ad8\u804a\u5929\u673a\u5668\u4eba\u7684\u53ef\u9760\u6027\u3002", "method": "\u7f16\u8bd150\u7bc7\u8bba\u6587\u548c70\u4e2a\u4e13\u5bb6\u95ee\u9898\u7684\u963f\u5c14\u832b\u6d77\u9ed8\u75c5\u6570\u636e\u5e93\uff0c\u6784\u5efaGraphRAG\u77e5\u8bc6\u5e93\uff0c\u4f7f\u7528GPT-4o\u4f5c\u4e3aLLM\u56de\u7b54\u67e5\u8be2\uff0c\u5bf9\u6bd4GraphRAG\u4e0e\u6807\u51c6GPT-4o\u6a21\u578b\u7684\u56de\u7b54\u8d28\u91cf\uff0c\u8bc4\u4f30\u591a\u4e2aRAG\u548cGraphRAG\u7cfb\u7edf\u7684\u53ef\u8ffd\u6eaf\u6027\u3002", "result": "\u8bc4\u4f30\u4e86GraphRAG\u7cfb\u7edf\u5728\u963f\u5c14\u832b\u6d77\u9ed8\u75c5\u9886\u57df\u7684\u8868\u73b0\uff0c\u5bf9\u6bd4\u4e86\u4e0e\u6807\u51c6LLM\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540cRAG\u7cfb\u7edf\u7684\u53ef\u8ffd\u6eaf\u6027\u7279\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u751f\u7269\u533b\u5b66\u9886\u57df\u7684GraphRAG\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u5f00\u53d1\u4e86\u6613\u7528\u7684\u6d4b\u8bd5\u754c\u9762\u548c\u9884\u5efa\u6570\u636e\u5e93\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8GraphRAG\u6280\u672f\u5728\u4e13\u4e1a\u9886\u57df\u7684\u5e94\u7528\u548c\u7814\u7a76\u3002"}}
{"id": "2508.21307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21307", "abs": "https://arxiv.org/abs/2508.21307", "authors": ["Sri Ram Macharla", "Sridhar Murthy J", "Anjaneyulu Pasala"], "title": "MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems", "comment": "Abstract accepted for presentation at ACM ISEC 2025", "summary": "MultiFluxAI is an innovative AI platform developed to address the challenges\nof managing and integrating vast, disparate data sources in product engineering\nacross application domains. It addresses both current and new service related\nqueries that enhance user engagement in the digital ecosystem. This platform\nleverages advanced AI techniques, such as Generative AI, vectorization, and\nagentic orchestration to provide dynamic and context-aware responses to complex\nuser queries.", "AI": {"tldr": "MultiFluxAI\u662f\u4e00\u4e2a\u521b\u65b0\u7684AI\u5e73\u53f0\uff0c\u7528\u4e8e\u89e3\u51b3\u4ea7\u54c1\u5de5\u7a0b\u4e2d\u7ba1\u7406\u548c\u96c6\u6210\u5927\u91cf\u4e0d\u540c\u6570\u636e\u6e90\u7684\u6311\u6218\uff0c\u901a\u8fc7\u751f\u6210\u5f0fAI\u3001\u5411\u91cf\u5316\u548c\u667a\u80fd\u7f16\u6392\u6280\u672f\u63d0\u4f9b\u52a8\u6001\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u54cd\u5e94\u3002", "motivation": "\u89e3\u51b3\u4ea7\u54c1\u5de5\u7a0b\u4e2d\u7ba1\u7406\u548c\u96c6\u6210\u5927\u91cf\u4e0d\u540c\u6570\u636e\u6e90\u7684\u6311\u6218\uff0c\u589e\u5f3a\u6570\u5b57\u751f\u6001\u7cfb\u7edf\u4e2d\u7528\u6237\u53c2\u4e0e\u5ea6\uff0c\u5904\u7406\u5f53\u524d\u548c\u65b0\u7684\u670d\u52a1\u76f8\u5173\u67e5\u8be2\u3002", "method": "\u5229\u7528\u5148\u8fdb\u7684AI\u6280\u672f\uff0c\u5305\u62ec\u751f\u6210\u5f0fAI\u3001\u5411\u91cf\u5316\u548c\u667a\u80fd\u7f16\u6392\uff0c\u63d0\u4f9b\u52a8\u6001\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u590d\u6742\u7528\u6237\u67e5\u8be2\u54cd\u5e94\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u521b\u65b0\u7684AI\u5e73\u53f0\uff0c\u80fd\u591f\u6709\u6548\u7ba1\u7406\u548c\u96c6\u6210\u4e0d\u540c\u6570\u636e\u6e90\uff0c\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u67e5\u8be2\u5904\u7406\u80fd\u529b\u3002", "conclusion": "MultiFluxAI\u901a\u8fc7\u5148\u8fdb\u7684AI\u6280\u672f\u6210\u529f\u89e3\u51b3\u4e86\u4ea7\u54c1\u5de5\u7a0b\u4e2d\u7684\u6570\u636e\u7ba1\u7406\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u589e\u5f3a\u7684\u7528\u6237\u4f53\u9a8c\u548c\u52a8\u6001\u54cd\u5e94\u80fd\u529b\u3002"}}
{"id": "2508.21320", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.21320", "abs": "https://arxiv.org/abs/2508.21320", "authors": ["Mohsen Nayebi Kerdabadi", "Arya Hadizadeh Moghaddam", "Dongjie Wang", "Zijun Yao"], "title": "Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation", "comment": "This work has been accepted as a full research paper at CIKM 2025", "summary": "Medical ontology graphs map external knowledge to medical codes in electronic\nhealth records via structured relationships. By leveraging domain-approved\nconnections (e.g., parent-child), predictive models can generate richer medical\nconcept representations by incorporating contextual information from related\nconcepts. However, existing literature primarily focuses on incorporating\ndomain knowledge from a single ontology system, or from multiple ontology\nsystems (e.g., diseases, drugs, and procedures) in isolation, without\nintegrating them into a unified learning structure. Consequently, concept\nrepresentation learning often remains limited to intra-ontology relationships,\noverlooking cross-ontology connections. In this paper, we propose LINKO, a\nlarge language model (LLM)-augmented integrative ontology learning framework\nthat leverages multiple ontology graphs simultaneously by enabling dual-axis\nknowledge propagation both within and across heterogeneous ontology systems to\nenhance medical concept representation learning. Specifically, LINKO first\nemploys LLMs to provide a graph-retrieval-augmented initialization for ontology\nconcept embedding, through an engineered prompt that includes concept\ndescriptions, and is further augmented with ontology context. Second, our\nmethod jointly learns the medical concepts in diverse ontology graphs by\nperforming knowledge propagation in two axes: (1) intra-ontology vertical\npropagation across hierarchical ontology levels and (2) inter-ontology\nhorizontal propagation within every level in parallel. Last, through extensive\nexperiments on two public datasets, we validate the superior performance of\nLINKO over state-of-the-art baselines. As a plug-in encoder compatible with\nexisting EHR predictive models, LINKO further demonstrates enhanced robustness\nin scenarios involving limited data availability and rare disease prediction.", "AI": {"tldr": "LINKO\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u533b\u7597\u672c\u4f53\u96c6\u6210\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u8f74\u77e5\u8bc6\u4f20\u64ad\uff08\u5782\u76f4\u548c\u6c34\u5e73\uff09\u6765\u589e\u5f3a\u533b\u7597\u6982\u5ff5\u8868\u793a\u5b66\u4e60\uff0c\u5728\u6709\u9650\u6570\u636e\u548c\u7f55\u89c1\u75be\u75c5\u9884\u6d4b\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u4e00\u672c\u4f53\u7cfb\u7edf\u6216\u591a\u4e2a\u5b64\u7acb\u672c\u4f53\u7cfb\u7edf\u7684\u77e5\u8bc6\u6574\u5408\uff0c\u7f3a\u4e4f\u8de8\u672c\u4f53\u7cfb\u7edf\u7684\u7edf\u4e00\u5b66\u4e60\u7ed3\u6784\uff0c\u5bfc\u81f4\u6982\u5ff5\u8868\u793a\u5b66\u4e60\u5c40\u9650\u4e8e\u672c\u4f53\u5185\u90e8\u5173\u7cfb\uff0c\u5ffd\u7565\u4e86\u8de8\u672c\u4f53\u8fde\u63a5\u3002", "method": "1) \u4f7f\u7528LLM\u63d0\u4f9b\u56fe\u68c0\u7d22\u589e\u5f3a\u7684\u521d\u59cb\u5316\u5d4c\u5165\uff1b2) \u901a\u8fc7\u53cc\u8f74\u77e5\u8bc6\u4f20\u64ad\u8054\u5408\u5b66\u4e60\uff1a\u5782\u76f4\u4f20\u64ad\uff08\u5c42\u7ea7\u5185\uff09\u548c\u6c34\u5e73\u4f20\u64ad\uff08\u8de8\u672c\u4f53\uff09\uff1b3) \u4f5c\u4e3a\u63d2\u4ef6\u7f16\u7801\u5668\u4e0e\u73b0\u6709EHR\u9884\u6d4b\u6a21\u578b\u517c\u5bb9\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86LINKO\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u6709\u9650\u6570\u636e\u53ef\u7528\u6027\u548c\u7f55\u89c1\u75be\u75c5\u9884\u6d4b\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "LINKO\u6846\u67b6\u901a\u8fc7\u6574\u5408\u591a\u4e2a\u672c\u4f53\u56fe\u5e76\u5b9e\u73b0\u8de8\u5f02\u6784\u672c\u4f53\u7cfb\u7edf\u7684\u77e5\u8bc6\u4f20\u64ad\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533b\u7597\u6982\u5ff5\u8868\u793a\u5b66\u4e60\u7684\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u548c\u7f55\u89c1\u75be\u75c5\u9884\u6d4b\u65b9\u9762\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2508.21219", "categories": ["cs.CR", "cs.ET", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.21219", "abs": "https://arxiv.org/abs/2508.21219", "authors": ["A H M Nazmus Sakib", "Mahsin Bin Akram", "Joseph Spracklen", "Sahan Kalutarage", "Raveen Wijewickrama", "Igor Bilogrevic", "Murtuza Jadliwala"], "title": "The WASM Cloak: Evaluating Browser Fingerprinting Defenses Under WebAssembly based Obfuscation", "comment": null, "summary": "Browser fingerprinting defenses have historically focused on detecting\nJavaScript(JS)-based tracking techniques. However, the widespread adoption of\nWebAssembly (WASM) introduces a potential blind spot, as adversaries can\nconvert JS to WASM's low-level binary format to obfuscate malicious logic. This\npaper presents the first systematic evaluation of how such WASM-based\nobfuscation impacts the robustness of modern fingerprinting defenses. We\ndevelop an automated pipeline that translates real-world JS fingerprinting\nscripts into functional WASM-obfuscated variants and test them against two\nclasses of defenses: state-of-the-art detectors in research literature and\ncommercial, in-browser tools. Our findings reveal a notable divergence:\ndetectors proposed in the research literature that rely on feature-based\nanalysis of source code show moderate vulnerability, stemming from outdated\ndatasets or a lack of WASM compatibility. In contrast, defenses such as browser\nextensions and native browser features remained completely effective, as their\nAPI-level interception is agnostic to the script's underlying implementation.\nThese results highlight a gap between academic and practical defense strategies\nand offer insights into strengthening detection approaches against WASM-based\nobfuscation, while also revealing opportunities for more evasive techniques in\nfuture attacks.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86WebAssembly(WASM)\u6df7\u6dc6\u6280\u672f\u5bf9\u73b0\u4ee3\u6d4f\u89c8\u5668\u6307\u7eb9\u8bc6\u522b\u9632\u5fa1\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5b66\u672f\u7814\u7a76\u4e2d\u7684\u68c0\u6d4b\u5668\u5b58\u5728\u4e2d\u5ea6\u6f0f\u6d1e\uff0c\u800c\u5546\u4e1a\u6d4f\u89c8\u5668\u9632\u5fa1\u5de5\u5177\u4ecd\u5b8c\u5168\u6709\u6548\u3002", "motivation": "\u968f\u7740WebAssembly(WASM)\u7684\u5e7f\u6cdb\u91c7\u7528\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u5c06JavaScript\u8f6c\u6362\u4e3aWASM\u4e8c\u8fdb\u5236\u683c\u5f0f\u6765\u6df7\u6dc6\u6076\u610f\u903b\u8f91\uff0c\u8fd9\u53ef\u80fd\u6210\u4e3a\u73b0\u6709\u6307\u7eb9\u8bc6\u522b\u9632\u5fa1\u7684\u76f2\u70b9\u3002", "method": "\u5f00\u53d1\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\uff0c\u5c06\u771f\u5b9e\u4e16\u754c\u7684JS\u6307\u7eb9\u8bc6\u522b\u811a\u672c\u8f6c\u6362\u4e3a\u529f\u80fd\u6027\u7684WASM\u6df7\u6dc6\u53d8\u4f53\uff0c\u5e76\u6d4b\u8bd5\u4e24\u7c7b\u9632\u5fa1\uff1a\u7814\u7a76\u6587\u732e\u4e2d\u7684\u6700\u5148\u8fdb\u68c0\u6d4b\u5668\u548c\u5546\u4e1a\u6d4f\u89c8\u5668\u5de5\u5177\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b66\u672f\u68c0\u6d4b\u5668\u56e0\u4f9d\u8d56\u6e90\u4ee3\u7801\u7279\u5f81\u5206\u6790\u800c\u5b58\u5728\u4e2d\u5ea6\u6f0f\u6d1e\uff08\u6e90\u4e8e\u8fc7\u65f6\u6570\u636e\u96c6\u6216\u7f3a\u4e4fWASM\u517c\u5bb9\u6027\uff09\uff0c\u800c\u6d4f\u89c8\u5668\u6269\u5c55\u548c\u539f\u751f\u6d4f\u89c8\u5668\u529f\u80fd\u7b49\u9632\u5fa1\u4ecd\u5b8c\u5168\u6709\u6548\uff08\u56e0\u5176API\u7ea7\u62e6\u622a\u4e0d\u5173\u5fc3\u811a\u672c\u5e95\u5c42\u5b9e\u73b0\uff09\u3002", "conclusion": "\u7ed3\u679c\u63ed\u793a\u4e86\u5b66\u672f\u9632\u5fa1\u7b56\u7565\u4e0e\u5b9e\u9645\u9632\u5fa1\u7b56\u7565\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u52a0\u5f3a\u9488\u5bf9WASM\u6df7\u6dc6\u7684\u68c0\u6d4b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u672a\u6765\u653b\u51fb\u4e2d\u66f4\u9690\u853d\u6280\u672f\u7684\u673a\u4f1a\u3002"}}
{"id": "2508.21097", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21097", "abs": "https://arxiv.org/abs/2508.21097", "authors": ["Nazanin Siavash", "Armin Moin"], "title": "Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation", "comment": "This paper is accepted to the New Ideas and Emerging Results (NIER)\n  track of the ACM/IEEE 28th International Conference on Model Driven\n  Engineering Languages and Systems (MODELS)", "summary": "This paper introduces a novel research direction for model-to-text/code\ntransformations by leveraging Large Language Models (LLMs) that can be enhanced\nwith Retrieval-Augmented Generation (RAG) pipelines. The focus is on quantum\nand hybrid quantum-classical software systems, where model-driven approaches\ncan help reduce the costs and mitigate the risks associated with the\nheterogeneous platform landscape and lack of developers' skills. We validate\none of the proposed ideas regarding generating code out of UML model instances\nof software systems. This Python code uses a well-established library, called\nQiskit, to execute on gate-based or circuit-based quantum computers. The RAG\npipeline that we deploy incorporates sample Qiskit code from public GitHub\nrepositories. Experimental results show that well-engineered prompts can\nimprove CodeBLEU scores by up to a factor of four, yielding more accurate and\nconsistent quantum code. However, the proposed research direction can go beyond\nthis through further investigation in the future by conducting experiments to\naddress our other research questions and ideas proposed here, such as deploying\nsoftware system model instances as the source of information in the RAG\npipelines, or deploying LLMs for code-to-code transformations, for instance,\nfor transpilation use cases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6280\u672f\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\uff0c\u7528\u4e8e\u91cf\u5b50\u8f6f\u4ef6\u7cfb\u7edf\u7684\u6a21\u578b\u5230\u4ee3\u7801\u8f6c\u6362\uff0c\u901a\u8fc7Qiskit\u5e93\u751f\u6210\u91cf\u5b50\u8ba1\u7b97\u4ee3\u7801\uff0c\u5b9e\u9a8c\u663e\u793a\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u53ef\u5c06CodeBLEU\u5206\u6570\u63d0\u9ad8\u56db\u500d\u3002", "motivation": "\u91cf\u5b50\u6df7\u5408\u8f6f\u4ef6\u7cfb\u7edf\u5b58\u5728\u5e73\u53f0\u5f02\u6784\u6027\u548c\u5f00\u53d1\u4eba\u5458\u6280\u80fd\u7f3a\u4e4f\u7684\u95ee\u9898\uff0c\u6a21\u578b\u9a71\u52a8\u65b9\u6cd5\u53ef\u4ee5\u964d\u4f4e\u6210\u672c\u548c\u98ce\u9669\u3002", "method": "\u91c7\u7528RAG\u7ba1\u9053\u6574\u5408GitHub\u4e0a\u7684Qiskit\u4ee3\u7801\u6837\u672c\uff0c\u901a\u8fc7LLM\u4eceUML\u6a21\u578b\u5b9e\u4f8b\u751f\u6210\u91cf\u5b50\u4ee3\u7801\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u5de5\u7a0b\u53ef\u4ee5\u5c06CodeBLEU\u5206\u6570\u63d0\u5347\u9ad8\u8fbe\u56db\u500d\uff0c\u4ea7\u751f\u66f4\u51c6\u786e\u548c\u4e00\u81f4\u7684\u91cf\u5b50\u4ee3\u7801\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u63a2\u7d22\u5c06\u8f6f\u4ef6\u7cfb\u7edf\u6a21\u578b\u5b9e\u4f8b\u4f5c\u4e3aRAG\u4fe1\u606f\u6e90\uff0c\u4ee5\u53ca\u4ee3\u7801\u5230\u4ee3\u7801\u8f6c\u6362\u7b49\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2508.21365", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21365", "abs": "https://arxiv.org/abs/2508.21365", "authors": ["Yi Liao", "Yu Gu", "Yuan Sui", "Zining Zhu", "Yifan Lu", "Guohua Tang", "Zhongqian Sun", "Wei Yang"], "title": "Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models", "comment": null, "summary": "Large language models (LLMs) excel at complex reasoning tasks such as\nmathematics and coding, yet they frequently struggle with simple interactive\ntasks that young children perform effortlessly. This discrepancy highlights a\ncritical gap between declarative knowledge (knowing about something) and\nprocedural knowledge (knowing how to do something). Although traditional\nreinforcement learning (RL) agents can acquire procedural knowledge through\nenvironmental interaction, they often operate as black boxes and require\nsubstantial training data. In contrast, LLMs possess extensive world knowledge\nand reasoning capabilities, but are unable to effectively convert this static\nknowledge into dynamic decision-making in interactive settings. To address this\nchallenge, we propose Think in Games (TiG), a novel framework that empowers\nLLMs to develop procedural understanding through direct interaction with game\nenvironments, while retaining their inherent reasoning and explanatory\nabilities. Specifically, TiG reformulates RL-based decision-making as a\nlanguage modeling task: LLMs generate language-guided policies, which are\nrefined iteratively through online reinforcement learning based on\nenvironmental feedback. Our experimental results show that TiG successfully\nbridges the gap between declarative and procedural knowledge, achieving\ncompetitive performance with dramatically lower data and computational demands\ncompared to conventional RL methods. Moreover, TiG provides step-by-step\nnatural language explanations for its decisions, greatly improving transparency\nand interpretability in complex interactive tasks.", "AI": {"tldr": "TiG\u6846\u67b6\u901a\u8fc7\u5c06\u5f3a\u5316\u5b66\u4e60\u51b3\u7b56\u91cd\u65b0\u8868\u8ff0\u4e3a\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6e38\u620f\u73af\u5883\u4e2d\u76f4\u63a5\u4ea4\u4e92\u6765\u53d1\u5c55\u7a0b\u5e8f\u6027\u77e5\u8bc6\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u63a8\u7406\u548c\u89e3\u91ca\u80fd\u529b", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u8868\u73b0\u51fa\u8272\u4f46\u5728\u7b80\u5355\u4ea4\u4e92\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u5f25\u5408\u9648\u8ff0\u6027\u77e5\u8bc6\u548c\u7a0b\u5e8f\u6027\u77e5\u8bc6\u4e4b\u95f4\u7684\u5dee\u8ddd", "method": "\u5c06\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u51b3\u7b56\u91cd\u65b0\u8868\u8ff0\u4e3a\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\uff0c\u901a\u8fc7\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u57fa\u4e8e\u73af\u5883\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u8bed\u8a00\u5f15\u5bfc\u7684\u7b56\u7565", "result": "TiG\u6210\u529f\u5f25\u5408\u4e86\u9648\u8ff0\u6027\u548c\u7a0b\u5e8f\u6027\u77e5\u8bc6\u5dee\u8ddd\uff0c\u4ee5\u663e\u8457\u66f4\u4f4e\u7684\u6570\u636e\u548c\u8ba1\u7b97\u9700\u6c42\u8fbe\u5230\u4e0e\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u9010\u6b65\u81ea\u7136\u8bed\u8a00\u89e3\u91ca", "conclusion": "TiG\u6846\u67b6\u6709\u6548\u7ed3\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e16\u754c\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u4ea4\u4e92\u5b66\u4e60\u4f18\u52bf\uff0c\u63d0\u9ad8\u4e86\u590d\u6742\u4ea4\u4e92\u4efb\u52a1\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027"}}
{"id": "2508.21302", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.21302", "abs": "https://arxiv.org/abs/2508.21302", "authors": ["Jie Zhu", "Chihao Shen", "Ziyang Li", "Jiahao Yu", "Yizheng Chen", "Kexin Pei"], "title": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "comment": null, "summary": "Directed fuzzing aims to find program inputs that lead to specified target\nprogram states. It has broad applications, such as debugging system crashes,\nconfirming reported bugs, and generating exploits for potential\nvulnerabilities. This task is inherently challenging because target states are\noften deeply nested in the program, while the search space manifested by\nnumerous possible program inputs is prohibitively large. Existing approaches\nrely on branch distances or manually-specified constraints to guide the search;\nhowever, the branches alone are often insufficient to precisely characterize\nprogress toward reaching the target states, while the manually specified\nconstraints are often tailored for specific bug types and thus difficult to\ngeneralize to diverse target states and programs.\n  We present Locus, a novel framework to improve the efficiency of directed\nfuzzing. Our key insight is to synthesize predicates to capture fuzzing\nprogress as semantically meaningful intermediate states, serving as milestones\ntowards reaching the target states. When used to instrument the program under\nfuzzing, they can reject executions unlikely to reach the target states, while\nproviding additional coverage guidance. To automate this task and generalize to\ndiverse programs, Locus features an agentic framework with program analysis\ntools to synthesize and iteratively refine the candidate predicates, while\nensuring the predicates strictly relax the target states to prevent false\nrejections via symbolic execution. Our evaluation shows that Locus\nsubstantially improves the efficiency of eight state-of-the-art fuzzers in\ndiscovering real-world vulnerabilities, achieving an average speedup of 41.6x.\nSo far, Locus has found eight previously unpatched bugs, with one already\nacknowledged with a draft patch.", "AI": {"tldr": "Locus\u662f\u4e00\u4e2a\u65b0\u7684\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u8c13\u8bcd\u6765\u6355\u83b7\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u7684\u4e2d\u95f4\u72b6\u6001\u4f5c\u4e3a\u91cc\u7a0b\u7891\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u53d1\u73b0\u771f\u5b9e\u6f0f\u6d1e\u7684\u6548\u7387\uff0c\u5e73\u5747\u52a0\u901f41.6\u500d", "motivation": "\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u5728\u5bfb\u627e\u5bfc\u81f4\u7279\u5b9a\u76ee\u6807\u7a0b\u5e8f\u72b6\u6001\u7684\u8f93\u5165\u65f6\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5206\u652f\u8ddd\u79bb\u6216\u624b\u52a8\u6307\u5b9a\u7684\u7ea6\u675f\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u8981\u4e48\u4e0d\u591f\u7cbe\u786e\uff0c\u8981\u4e48\u96be\u4ee5\u6cdb\u5316\u5230\u4e0d\u540c\u7684\u76ee\u6807\u72b6\u6001\u548c\u7a0b\u5e8f", "method": "Locus\u91c7\u7528\u4ee3\u7406\u6846\u67b6\u548c\u7a0b\u5e8f\u5206\u6790\u5de5\u5177\u6765\u81ea\u52a8\u5408\u6210\u548c\u8fed\u4ee3\u7cbe\u5316\u5019\u9009\u8c13\u8bcd\uff0c\u8fd9\u4e9b\u8c13\u8bcd\u4f5c\u4e3a\u4e2d\u95f4\u91cc\u7a0b\u7891\uff0c\u901a\u8fc7\u7b26\u53f7\u6267\u884c\u786e\u4fdd\u8c13\u8bcd\u4e25\u683c\u677e\u5f1b\u76ee\u6807\u72b6\u6001\u4ee5\u9632\u6b62\u9519\u8bef\u62d2\u7edd", "result": "Locus\u663e\u8457\u63d0\u9ad8\u4e868\u4e2a\u6700\u5148\u8fdb\u6a21\u7cca\u6d4b\u8bd5\u5668\u7684\u6548\u7387\uff0c\u5e73\u5747\u52a0\u901f41.6\u500d\uff0c\u53d1\u73b0\u4e868\u4e2a\u5148\u524d\u672a\u4fee\u8865\u7684\u6f0f\u6d1e\uff0c\u5176\u4e2d\u4e00\u4e2a\u5df2\u88ab\u786e\u8ba4\u5e76\u51c6\u5907\u8865\u4e01", "conclusion": "Locus\u901a\u8fc7\u81ea\u52a8\u5408\u6210\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u7684\u4e2d\u95f4\u72b6\u6001\u8c13\u8bcd\uff0c\u4e3a\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8fdb\u5c55\u5ea6\u91cf\u65b9\u6cd5\uff0c\u80fd\u591f\u6cdb\u5316\u5230\u4e0d\u540c\u7684\u7a0b\u5e8f\u548c\u76ee\u6807\u72b6\u6001\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6f0f\u6d1e\u53d1\u73b0\u6548\u7387"}}
{"id": "2508.21107", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21107", "abs": "https://arxiv.org/abs/2508.21107", "authors": ["Dongjun Lee", "Changho Hwang", "Kimin Lee"], "title": "Learning to Generate Unit Test via Adversarial Reinforcement Learning", "comment": "Code is available at: https://github.com/dgjun32/UTRL", "summary": "Unit testing is a core practice in programming, enabling systematic\nevaluation of programs produced by human developers or large language models\n(LLMs). Given the challenges in writing comprehensive unit tests, LLMs have\nbeen employed to automate test generation, yet methods for training LLMs to\nproduce high-quality tests remain underexplored. In this work, we propose UTRL,\na novel reinforcement learning framework that trains an LLM to generate\nhigh-quality unit tests given a programming instruction. Our key idea is to\niteratively train two LLMs, the unit test generator and the code generator, in\nan adversarial manner via reinforcement learning. The unit test generator is\ntrained to maximize a discrimination reward, which reflects its ability to\nproduce tests that expose faults in the code generator's solutions, and the\ncode generator is trained to maximize a code reward, which reflects its ability\nto produce solutions that pass the unit tests generated by the test generator.\nIn our experiments, we demonstrate that unit tests generated by Qwen3-4B\ntrained via UTRL show higher quality compared to unit tests generated by the\nsame model trained via supervised fine-tuning on human-written ground-truth\nunit tests, yielding code evaluations that more closely align with those\ninduced by the ground-truth tests. Moreover, Qwen3-4B trained with UTRL\noutperforms frontier models such as GPT-4.1 in generating high-quality unit\ntests, highlighting the effectiveness of UTRL in training LLMs for this task.", "AI": {"tldr": "UTR\u662f\u4e00\u79cd\u901a\u8fc7\u5bf9\u6297\u6027\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLM\u751f\u6210\u9ad8\u8d28\u91cf\u5355\u5143\u6d4b\u8bd5\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u8bad\u7ec3\u6d4b\u8bd5\u751f\u6210\u5668\u548c\u4ee3\u7801\u751f\u6210\u5668\u6765\u63d0\u5347\u6d4b\u8bd5\u8d28\u91cf\u3002", "motivation": "\u76ee\u524dLLM\u81ea\u52a8\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u7684\u65b9\u6cd5\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\u6765\u751f\u6210\u80fd\u591f\u66dd\u9732\u4ee3\u7801\u6545\u969c\u7684\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u3002", "method": "\u4f7f\u7528\u5bf9\u6297\u6027\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u540c\u65f6\u8bad\u7ec3\u4e24\u4e2aLLM\uff1a\u6d4b\u8bd5\u751f\u6210\u5668\u901a\u8fc7\u6700\u5927\u5316\u8fa8\u522b\u5956\u52b1\uff08\u751f\u6210\u80fd\u66dd\u9732\u4ee3\u7801\u6545\u969c\u7684\u6d4b\u8bd5\uff09\uff0c\u4ee3\u7801\u751f\u6210\u5668\u901a\u8fc7\u6700\u5927\u5316\u4ee3\u7801\u5956\u52b1\uff08\u751f\u6210\u80fd\u901a\u8fc7\u6d4b\u8bd5\u7684\u4ee3\u7801\uff09\u3002", "result": "UTR\u8bad\u7ec3\u7684Qwen3-4B\u6a21\u578b\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u8d28\u91cf\u4e0a\u8d85\u8fc7\u4e86\u76f8\u540c\u6a21\u578b\u7684\u76d1\u7763\u5b66\u4e60\u7ed3\u679c\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86GPT-4.1\u7b49\u524d\u6cbf\u6a21\u578b\u3002", "conclusion": "UTR\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bad\u7ec3LLM\u751f\u6210\u9ad8\u8d28\u91cf\u5355\u5143\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u5b66\u4e60\u63d0\u5347\u4e86\u6d4b\u8bd5\u7684\u6545\u969c\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2508.21376", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.21376", "abs": "https://arxiv.org/abs/2508.21376", "authors": ["Tony Lee", "Haoqin Tu", "Chi Heem Wong", "Zijun Wang", "Siwei Yang", "Yifan Mai", "Yuyin Zhou", "Cihang Xie", "Percy Liang"], "title": "AHELM: A Holistic Evaluation of Audio-Language Models", "comment": null, "summary": "Evaluations of audio-language models (ALMs) -- multimodal models that take\ninterleaved audio and text as input and output text -- are hindered by the lack\nof standardized benchmarks; most benchmarks measure only one or two\ncapabilities and omit evaluative aspects such as fairness or safety.\nFurthermore, comparison across models is difficult as separate evaluations test\na limited number of models and use different prompting methods and inference\nparameters. To address these shortfalls, we introduce AHELM, a benchmark that\naggregates various datasets -- including 2 new synthetic audio-text datasets\ncalled PARADE, which evaluates the ALMs on avoiding stereotypes, and\nCoRe-Bench, which measures reasoning over conversational audio through\ninferential multi-turn question answering -- to holistically measure the\nperformance of ALMs across 10 aspects we have identified as important to the\ndevelopment and usage of ALMs: audio perception, knowledge, reasoning, emotion\ndetection, bias, fairness, multilinguality, robustness, toxicity, and safety.\nWe also standardize the prompts, inference parameters, and evaluation metrics\nto ensure equitable comparisons across models. We test 14 open-weight and\nclosed-API ALMs from 3 developers and 3 additional simple baseline systems each\nconsisting of an automatic speech recognizer and a language model. Our results\nshow that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits\ngroup unfairness ($p=0.01$) on ASR tasks whereas most of the other models do\nnot. We also find that the baseline systems perform reasonably well on AHELM,\nwith one ranking 5th overall despite having only speech-to-text capabilities.\nFor transparency, all raw prompts, model generations, and outputs are available\non our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is\nintended to be a living benchmark and new datasets and models will be added\nover time.", "AI": {"tldr": "AHELM\u662f\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b10\u4e2a\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u6807\u51c6\u5316\u4e86\u63d0\u793a\u8bcd\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u4e8614\u4e2a\u6a21\u578b\uff0c\u53d1\u73b0Gemini 2.5 Pro\u5728\u591a\u6570\u65b9\u9762\u8868\u73b0\u6700\u4f73\u4f46\u5b58\u5728\u516c\u5e73\u6027\u95ee\u9898\uff0c\u57fa\u7ebf\u7cfb\u7edf\u8868\u73b0\u610f\u5916\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u6d4b\u8bd5\u7ef4\u5ea6\u6709\u9650\uff0c\u6a21\u578b\u95f4\u96be\u4ee5\u516c\u5e73\u6bd4\u8f83\uff0c\u9700\u8981\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f00\u53d1AHELM\u57fa\u51c6\uff0c\u6574\u5408\u591a\u4e2a\u6570\u636e\u96c6\uff08\u5305\u62ec\u65b0\u5408\u6210\u7684PARADE\u548cCoRe-Bench\u6570\u636e\u96c6\uff09\uff0c\u6807\u51c6\u5316\u63d0\u793a\u8bcd\u3001\u63a8\u7406\u53c2\u6570\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u6d4b\u8bd514\u4e2a\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u53ca3\u4e2a\u57fa\u7ebf\u7cfb\u7edf\u3002", "result": "Gemini 2.5 Pro\u572810\u4e2a\u7ef4\u5ea6\u4e2d\u76845\u4e2a\u6392\u540d\u7b2c\u4e00\uff0c\u4f46\u5728ASR\u4efb\u52a1\u4e2d\u5b58\u5728\u7fa4\u4f53\u4e0d\u516c\u5e73\u6027\uff08p=0.01\uff09\uff1b\u57fa\u7ebf\u7cfb\u7edf\u8868\u73b0\u826f\u597d\uff0c\u5176\u4e2d\u4e00\u4e2a\u4ec5\u5177\u5907\u8bed\u97f3\u8f6c\u6587\u672c\u80fd\u529b\u7684\u7cfb\u7edf\u603b\u4f53\u6392\u540d\u7b2c\u4e94\u3002", "conclusion": "AHELM\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u7684\u4f18\u52bf\u548c\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u516c\u5e73\u6027\u95ee\u9898\uff0c\u57fa\u51c6\u5c06\u6301\u7eed\u66f4\u65b0\u4ee5\u4fc3\u8fdb\u8be5\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2508.21323", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.21323", "abs": "https://arxiv.org/abs/2508.21323", "authors": ["Kunal Mukherjee", "Murat Kantarcioglu"], "title": "LLM-driven Provenance Forensics for Threat Investigation and Detection", "comment": null, "summary": "We introduce PROVSEEK, an LLM-powered agentic framework for automated\nprovenance-driven forensic analysis and threat intelligence extraction.\nPROVSEEK employs specialized toolchains to dynamically retrieve relevant\ncontext by generating precise, context-aware queries that fuse a vectorized\nthreat report knowledge base with data from system provenance databases. The\nframework resolves provenance queries, orchestrates multiple role-specific\nagents to mitigate hallucinations, and synthesizes structured, ground-truth\nverifiable forensic summaries. By combining agent orchestration with\nRetrieval-Augmented Generation (RAG) and chain-of-thought (CoT) reasoning,\nPROVSEEK enables adaptive multi-step analysis that iteratively refines\nhypotheses, verifies supporting evidence, and produces scalable, interpretable\nforensic explanations of attack behaviors. By combining provenance data with\nagentic reasoning, PROVSEEK establishes a new paradigm for grounded agentic\nforecics to investigate APTs. We conduct a comprehensive evaluation on publicly\navailable DARPA datasets, demonstrating that PROVSEEK outperforms\nretrieval-based methods for intelligence extraction task, achieving a 34%\nimprovement in contextual precision/recall; and for threat detection task,\nPROVSEEK achieves 22%/29% higher precision/recall compared to both a baseline\nagentic AI approach and State-Of-The-Art (SOTA) Provenance-based Intrusion\nDetection System (PIDS).", "AI": {"tldr": "PROVSEEK\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6eaf\u6e90\u9a71\u52a8\u7684\u53d6\u8bc1\u5206\u6790\u548c\u5a01\u80c1\u60c5\u62a5\u63d0\u53d6\uff0c\u901a\u8fc7\u7ed3\u5408RAG\u548c\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u5728DARPA\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u53d6\u8bc1\u5206\u6790\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u7684APT\u653b\u51fb\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u68c0\u7d22\u76f8\u5173\u4e0a\u4e0b\u6587\u3001\u51cf\u5c11\u5e7b\u89c9\u5e76\u751f\u6210\u53ef\u9a8c\u8bc1\u53d6\u8bc1\u6458\u8981\u7684\u81ea\u52a8\u5316\u6846\u67b6\u3002", "method": "\u91c7\u7528\u4e13\u95e8\u7684\u5de5\u5177\u94fe\u52a8\u6001\u68c0\u7d22\u76f8\u5173\u4e0a\u4e0b\u6587\uff0c\u751f\u6210\u7cbe\u786e\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u67e5\u8be2\uff0c\u7ed3\u5408\u5411\u91cf\u5316\u5a01\u80c1\u62a5\u544a\u77e5\u8bc6\u5e93\u548c\u7cfb\u7edf\u6eaf\u6e90\u6570\u636e\u5e93\u3002\u901a\u8fc7\u591a\u89d2\u8272\u4ee3\u7406\u534f\u8c03\u51cf\u5c11\u5e7b\u89c9\uff0c\u7ed3\u5408RAG\u548c\u601d\u7ef4\u94fe\u63a8\u7406\u8fdb\u884c\u81ea\u9002\u5e94\u591a\u6b65\u5206\u6790\u3002", "result": "\u5728\u516c\u5f00DARPA\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff1a\u5728\u60c5\u62a5\u63d0\u53d6\u4efb\u52a1\u4e2d\u6bd4\u68c0\u7d22\u65b9\u6cd5\u63d0\u534734%\u7684\u4e0a\u4e0b\u6587\u7cbe\u786e\u7387/\u53ec\u56de\u7387\uff1b\u5728\u5a01\u80c1\u68c0\u6d4b\u4efb\u52a1\u4e2d\u6bd4\u57fa\u7ebf\u4ee3\u7406AI\u65b9\u6cd5\u548c\u6700\u5148\u8fdb\u6eaf\u6e90\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u63d0\u534722%/29%\u7684\u7cbe\u786e\u7387/\u53ec\u56de\u7387\u3002", "conclusion": "PROVSEEK\u901a\u8fc7\u5c06\u6eaf\u6e90\u6570\u636e\u4e0e\u667a\u80fd\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u4e3a\u57fa\u4e8e\u8bc1\u636e\u7684\u667a\u80fd\u53d6\u8bc1\u8c03\u67e5APT\u653b\u51fb\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u7684\u653b\u51fb\u884c\u4e3a\u53d6\u8bc1\u5206\u6790\u3002"}}
{"id": "2508.21156", "categories": ["cs.SE", "D.2.7; I.2.7; I.2.6"], "pdf": "https://arxiv.org/pdf/2508.21156", "abs": "https://arxiv.org/abs/2508.21156", "authors": ["Kiana Kiashemshaki", "Arsham Khosravani", "Alireza Hosseinpour", "Arshia Akhavan"], "title": "Automated Bug Triaging using Instruction-Tuned Large Language Models", "comment": "11 pages, 7 figures", "summary": "Bug triaging, the task of assigning new issues to developers, is often slow\nand inconsistent in large projects. We present a lightweight framework that\ninstruction-tuned large language model (LLM) with LoRA adapters and uses\ncandidate-constrained decoding to ensure valid assignments. Tested on\nEclipseJDT and Mozilla datasets, the model achieves strong shortlist quality\n(Hit at 10 up to 0.753) despite modest exact Top-1 accuracy. On recent\nsnapshots, accuracy rises sharply, showing the framework's potential for\nreal-world, human-in-the-loop triaging. Our results suggest that\ninstruction-tuned LLMs offer a practical alternative to costly feature\nengineering and graph-based methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u4f7f\u7528LoRA\u9002\u914d\u5668\u548c\u5019\u9009\u7ea6\u675f\u89e3\u7801\u6765\u5b9e\u73b0bug\u5206\u914d\uff0c\u5728EclipseJDT\u548cMozilla\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5927\u578b\u9879\u76ee\u4e2d\u7684bug\u5206\u914d\u4efb\u52a1\u901a\u5e38\u7f13\u6162\u4e14\u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u66ff\u4ee3\u6210\u672c\u9ad8\u6602\u7684\u7279\u5f81\u5de5\u7a0b\u548c\u56fe\u57fa\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6307\u4ee4\u8c03\u4f18\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408LoRA\u9002\u914d\u5668\u8fdb\u884c\u5fae\u8c03\uff0c\u91c7\u7528\u5019\u9009\u7ea6\u675f\u89e3\u7801\u786e\u4fdd\u5206\u914d\u7684\u6709\u6548\u6027\u3002", "result": "\u5728EclipseJDT\u548cMozilla\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u5728\u77ed\u5217\u8868\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff08Hit@10\u8fbe\u52300.753\uff09\uff0c\u5c3d\u7ba1Top-1\u51c6\u786e\u7387\u4e00\u822c\u3002\u5728\u6700\u65b0\u5feb\u7167\u4e0a\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u6307\u4ee4\u8c03\u4f18\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e3abug\u5206\u914d\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5177\u6709\u5728\u73b0\u5b9e\u4e16\u754c\u4eba\u673a\u534f\u4f5c\u573a\u666f\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.21394", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21394", "abs": "https://arxiv.org/abs/2508.21394", "authors": ["Bor-Sung Liang"], "title": "AI Compute Architecture and Evolution Trends", "comment": "29 pages, 26 figures", "summary": "The focus of AI development has shifted from academic research to practical\napplications. However, AI development faces numerous challenges at various\nlevels. This article will attempt to analyze the opportunities and challenges\nof AI from several different perspectives using a structured approach. This\narticle proposes a seven-layer model for AI compute architecture, including\nPhysical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,\nOrchestrator Layer, and Application Layer, from bottom to top. It also explains\nhow AI computing has evolved into this 7-layer architecture through the\nthree-stage evolution on large-scale language models (LLMs). For each layer, we\ndescribe the development trajectory and key technologies. In Layers 1 and 2 we\ndiscuss AI computing issues and the impact of Scale-Up and Scale-Out strategies\non computing architecture. In Layer 3 we explore two different development\npaths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs\nand compares it to traditional processor memory. In Layers 5 to 7 we discuss\nthe trends of AI agents and explore the issues in evolution from a single AI\nagent to an AI-based ecosystem, and their impact on the AI industry.\nFurthermore, AI development involves not only technical challenges but also the\neconomic issues to build self-sustainable ecosystem. This article analyzes the\ninternet industry to provide predictions on the future trajectory of AI\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AI\u8ba1\u7b97\u7684\u4e03\u5c42\u67b6\u6784\u6a21\u578b\uff0c\u5206\u6790\u4e86AI\u4ece\u5b66\u672f\u7814\u7a76\u5230\u5b9e\u9645\u5e94\u7528\u53d1\u5c55\u4e2d\u7684\u673a\u9047\u4e0e\u6311\u6218\uff0c\u5305\u62ec\u6280\u672f\u67b6\u6784\u6f14\u8fdb\u548c\u7ecf\u6d4e\u751f\u6001\u5efa\u8bbe\u95ee\u9898\u3002", "motivation": "AI\u53d1\u5c55\u5df2\u4ece\u5b66\u672f\u7814\u7a76\u8f6c\u5411\u5b9e\u9645\u5e94\u7528\uff0c\u4f46\u5728\u5404\u4e2a\u5c42\u9762\u90fd\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u5206\u6790AI\u53d1\u5c55\u7684\u673a\u9047\u4e0e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e03\u5c42AI\u8ba1\u7b97\u67b6\u6784\u6a21\u578b\uff08\u7269\u7406\u5c42\u3001\u94fe\u8def\u5c42\u3001\u795e\u7ecf\u7f51\u7edc\u5c42\u3001\u4e0a\u4e0b\u6587\u5c42\u3001\u667a\u80fd\u4f53\u5c42\u3001\u7f16\u6392\u5c42\u3001\u5e94\u7528\u5c42\uff09\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e09\u9636\u6bb5\u6f14\u8fdb\u5206\u6790\u6bcf\u5c42\u7684\u53d1\u5c55\u8f68\u8ff9\u548c\u5173\u952e\u6280\u672f\u3002", "result": "\u7cfb\u7edf\u9610\u8ff0\u4e86AI\u8ba1\u7b97\u67b6\u6784\u7684\u6f14\u8fdb\u8def\u5f84\uff0c\u5206\u6790\u4e86Scale-Up\u548cScale-Out\u7b56\u7565\u7684\u5f71\u54cd\uff0c\u63a2\u8ba8\u4e86\u4ece\u5355AI\u667a\u80fd\u4f53\u5230AI\u751f\u6001\u7cfb\u7edf\u7684\u6f14\u8fdb\u8d8b\u52bf\u3002", "conclusion": "AI\u53d1\u5c55\u4e0d\u4ec5\u6d89\u53ca\u6280\u672f\u6311\u6218\uff0c\u8fd8\u9700\u8981\u6784\u5efa\u81ea\u6301\u7eed\u7684\u7ecf\u6d4e\u751f\u6001\u7cfb\u7edf\uff0c\u501f\u9274\u4e92\u8054\u7f51\u4ea7\u4e1a\u53d1\u5c55\u7ecf\u9a8c\u53ef\u4ee5\u9884\u6d4bAI\u672a\u6765\u7684\u53d1\u5c55\u8f68\u8ff9\u3002"}}
{"id": "2508.21386", "categories": ["cs.CR", "cs.CY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.21386", "abs": "https://arxiv.org/abs/2508.21386", "authors": ["Jukka Ruohonen", "Jesper L\u00f8ffler Nielsen", "Jakub Sk\u00f3rczynski"], "title": "Risks and Compliance with the EU's Core Cyber Security Legislation", "comment": "Submitted to IST (VSI:RegCompliance in SE)", "summary": "The European Union (EU) has long favored a risk-based approach to regulation.\nSuch an approach is also used in recent cyber security legislation enacted in\nthe EU. Risks are also inherently related to compliance with the new\nlegislation. Objective: The paper investigates how risks are framed in the EU's\nfive core cyber security legislative acts, whether the framings indicate\nconvergence or divergence between the acts and their risk concepts, and what\nqualifying words and terms are used when describing the legal notions of risks.\nMethod : The paper's methodology is based on qualitative legal interpretation\nand taxonomy-building. Results: The five acts have an encompassing coverage of\ndifferent cyber security risks, including but not limited to risks related to\ntechnical, organizational, and human security as well as those not originating\nfrom man-made actions. Both technical aspects and assets are used to frame the\nlegal risk notions in many of the legislative acts. A threat-centric viewpoint\nis also present in one of the acts. Notable gaps are related to acceptable\nrisks, non-probabilistic risks, and residual risks. Conclusion: The EU's new\ncyber security legislation has significantly extended the risk-based approach\nto regulations. At the same time, complexity and compliance burden have\nincreased. With this point in mind, the paper concludes with a few practical\ntakeaways about means to deal with compliance and research it.", "AI": {"tldr": "\u6b27\u76df\u7f51\u7edc\u5b89\u5168\u7acb\u6cd5\u91c7\u7528\u98ce\u9669\u5bfc\u5411\u65b9\u6cd5\uff0c\u6db5\u76d6\u6280\u672f\u3001\u7ec4\u7ec7\u548c\u4eba\u4e3a\u5b89\u5168\u7b49\u591a\u65b9\u9762\u98ce\u9669\uff0c\u4f46\u5b58\u5728\u53ef\u63a5\u53d7\u98ce\u9669\u3001\u975e\u6982\u7387\u98ce\u9669\u548c\u6b8b\u4f59\u98ce\u9669\u7b49\u6982\u5ff5\u7f3a\u5931\uff0c\u589e\u52a0\u4e86\u590d\u6742\u6027\u548c\u5408\u89c4\u8d1f\u62c5\u3002", "motivation": "\u7814\u7a76\u6b27\u76df\u4e94\u9879\u6838\u5fc3\u7f51\u7edc\u5b89\u5168\u7acb\u6cd5\u4e2d\u98ce\u9669\u6982\u5ff5\u7684\u6846\u67b6\u65b9\u5f0f\uff0c\u5206\u6790\u8fd9\u4e9b\u7acb\u6cd5\u5728\u98ce\u9669\u6982\u5ff5\u4e0a\u7684\u8d8b\u540c\u6216\u5206\u6b67\uff0c\u4ee5\u53ca\u63cf\u8ff0\u6cd5\u5f8b\u98ce\u9669\u6982\u5ff5\u65f6\u4f7f\u7528\u7684\u9650\u5b9a\u8bcd\u548c\u672f\u8bed\u3002", "method": "\u57fa\u4e8e\u5b9a\u6027\u6cd5\u5f8b\u89e3\u91ca\u548c\u5206\u7c7b\u6784\u5efa\u7684\u65b9\u6cd5\u8bba\uff0c\u5bf9\u6b27\u76df\u4e94\u9879\u6838\u5fc3\u7f51\u7edc\u5b89\u5168\u7acb\u6cd5\u6587\u4ef6\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u3002", "result": "\u4e94\u9879\u7acb\u6cd5\u6db5\u76d6\u4e86\u5e7f\u6cdb\u7684\u7f51\u7edc\u5b89\u5168\u98ce\u9669\u7c7b\u578b\uff0c\u5305\u62ec\u6280\u672f\u3001\u7ec4\u7ec7\u548c\u4eba\u4e3a\u5b89\u5168\u98ce\u9669\u4ee5\u53ca\u975e\u4eba\u4e3a\u98ce\u9669\u3002\u591a\u6570\u7acb\u6cd5\u4f7f\u7528\u6280\u672f\u65b9\u9762\u548c\u8d44\u4ea7\u6765\u6784\u5efa\u6cd5\u5f8b\u98ce\u9669\u6982\u5ff5\uff0c\u5176\u4e2d\u4e00\u9879\u7acb\u6cd5\u91c7\u7528\u5a01\u80c1\u4e2d\u5fc3\u89c6\u89d2\u3002\u4f46\u5b58\u5728\u53ef\u63a5\u53d7\u98ce\u9669\u3001\u975e\u6982\u7387\u98ce\u9669\u548c\u6b8b\u4f59\u98ce\u9669\u7b49\u6982\u5ff5\u7f3a\u5931\u3002", "conclusion": "\u6b27\u76df\u65b0\u7f51\u7edc\u5b89\u5168\u7acb\u6cd5\u663e\u8457\u6269\u5c55\u4e86\u98ce\u9669\u5bfc\u5411\u7684\u76d1\u7ba1\u65b9\u6cd5\uff0c\u4f46\u540c\u65f6\u4e5f\u589e\u52a0\u4e86\u590d\u6742\u6027\u548c\u5408\u89c4\u8d1f\u62c5\u3002\u8bba\u6587\u6700\u540e\u63d0\u51fa\u4e86\u5904\u7406\u5408\u89c4\u6027\u548c\u5f00\u5c55\u76f8\u5173\u7814\u7a76\u7684\u5b9e\u7528\u5efa\u8bae\u3002"}}
{"id": "2508.21433", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21433", "abs": "https://arxiv.org/abs/2508.21433", "authors": ["Tobias Lindenbauer", "Igor Slinko", "Ludwig Felder", "Egor Bogomolov", "Yaroslav Zharov"], "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "comment": null, "summary": "Large Language Model (LLM)-based agents solve complex tasks through iterative\nreasoning, exploration, and tool-use, a process that can result in long,\nexpensive context histories. While state-of-the-art Software Engineering ( SE)\nagents like OpenHands or Cursor use LLM-based summarization to tackle this\nissue, it is unclear whether the increased complexity offers tangible\nperformance benefits compared to simply omitting older observations. We present\na systematic comparison of these strategies within SWE-agent on SWE-bench\nVerified across five diverse model configurations. We find that a simple\nobservation-masking strategy halves cost relative to a raw agent while\nmatching, and sometimes slightly exceeding, the solve rate of LLM\nsummarization. For example, with Qwen3-Coder 480B, masking improves solve rate\nfrom 53.8% (raw agent) to 54.8%, while remaining competitive with summarization\nat a lower cost. These results suggest that, at least within SWE-agent on\nSWE-bench Verified, the most effective and efficient context management can be\nthe simplest. We release code and data for reproducibility", "AI": {"tldr": "\u7b80\u5355\u7684\u89c2\u6d4b\u63a9\u7801\u7b56\u7565\u5728SWE-agent\u4e2d\u6bd4LLM\u6458\u8981\u5316\u66f4\u6709\u6548\u4e14\u6210\u672c\u66f4\u4f4e\uff0c\u89e3\u51b3\u7387\u76f8\u8fd1\u4f46\u6210\u672c\u51cf\u534a", "motivation": "\u89e3\u51b3LLM\u57fa\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u4ea7\u751f\u957f\u4e0a\u4e0b\u6587\u5386\u53f2\u5bfc\u81f4\u9ad8\u6210\u672c\u7684\u95ee\u9898\uff0c\u5bf9\u6bd4\u4e0d\u540c\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\u7684\u6548\u679c", "method": "\u5728SWE-agent\u4e0a\u4f7f\u7528SWE-bench Verified\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u6bd4\u8f83\u539f\u59cb\u4ee3\u7406\u3001\u89c2\u6d4b\u63a9\u7801\u7b56\u7565\u548cLLM\u6458\u8981\u5316\u7b56\u7565\u57284\u79cd\u4e0d\u540c\u6a21\u578b\u914d\u7f6e\u4e0b\u7684\u6027\u80fd", "result": "\u89c2\u6d4b\u63a9\u7801\u7b56\u7565\u5c06\u6210\u672c\u964d\u4f4e50%\uff0c\u89e3\u51b3\u7387\u4e0eLLM\u6458\u8981\u5316\u76f8\u5f53\u6216\u7565\u9ad8\uff08\u5982Qwen3-Coder 480B\u4ece53.8%\u63d0\u5347\u523054.8%\uff09", "conclusion": "\u5728SWE-agent\u548cSWE-bench Verified\u73af\u5883\u4e2d\uff0c\u6700\u7b80\u5355\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\u53cd\u800c\u662f\u6700\u9ad8\u6548\u548c\u7ecf\u6d4e\u7684\u9009\u62e9"}}
{"id": "2508.21411", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21411", "abs": "https://arxiv.org/abs/2508.21411", "authors": ["Leonard Frank Neis", "Andre Antakli", "Matthias Klusch"], "title": "CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN", "comment": null, "summary": "User-friendly modeling and virtual simulation of urban traffic scenarios with\ndifferent types of interacting agents such as pedestrians, cyclists and\nautonomous vehicles remains a challenge. We present CARJAN, a novel tool for\nsemi-automated generation and simulation of such scenarios based on the\nmulti-agent engineering framework AJAN and the driving simulator CARLA. CARJAN\nprovides a visual user interface for the modeling, storage and maintenance of\ntraffic scenario layouts, and leverages SPARQL Behavior Tree-based\ndecision-making and interactions for agents in dynamic scenario simulations in\nCARLA. CARJAN provides a first integrated approach for interactive, intelligent\nagent-based generation and simulation of virtual traffic scenarios in CARLA.", "AI": {"tldr": "CARJAN\u662f\u4e00\u4e2a\u57fa\u4e8eAJAN\u591a\u667a\u80fd\u4f53\u6846\u67b6\u548cCARLA\u9a7e\u9a76\u6a21\u62df\u5668\u7684\u534a\u81ea\u52a8\u5316\u4ea4\u901a\u573a\u666f\u751f\u6210\u4e0e\u4eff\u771f\u5de5\u5177\uff0c\u63d0\u4f9b\u53ef\u89c6\u5316\u754c\u9762\u548cSPARQL\u884c\u4e3a\u6811\u51b3\u7b56\u673a\u5236", "motivation": "\u57ce\u5e02\u4ea4\u901a\u573a\u666f\u4e2d\u4e0d\u540c\u7c7b\u578b\u4ea4\u4e92\u667a\u80fd\u4f53\uff08\u884c\u4eba\u3001\u9a91\u884c\u8005\u3001\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff09\u7684\u5efa\u6a21\u548c\u865a\u62df\u4eff\u771f\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u9700\u8981\u7528\u6237\u53cb\u597d\u7684\u5de5\u5177\u6765\u652f\u6301\u573a\u666f\u751f\u6210\u548c\u6a21\u62df", "method": "\u57fa\u4e8eAJAN\u591a\u667a\u80fd\u4f53\u5de5\u7a0b\u6846\u67b6\u548cCARLA\u9a7e\u9a76\u6a21\u62df\u5668\uff0c\u63d0\u4f9b\u53ef\u89c6\u5316\u7528\u6237\u754c\u9762\u7528\u4e8e\u4ea4\u901a\u573a\u666f\u5e03\u5c40\u7684\u5efa\u6a21\u3001\u5b58\u50a8\u548c\u7ef4\u62a4\uff0c\u5229\u7528SPARQL\u884c\u4e3a\u6811\u8fdb\u884c\u667a\u80fd\u4f53\u51b3\u7b56\u548c\u4ea4\u4e92", "result": "\u5f00\u53d1\u4e86CARJAN\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u5728CARLA\u4e2d\u4ea4\u4e92\u5f0f\u3001\u667a\u80fd\u4f53\u9a71\u52a8\u7684\u865a\u62df\u4ea4\u901a\u573a\u666f\u751f\u6210\u548c\u4eff\u771f\u7684\u9996\u4e2a\u96c6\u6210\u65b9\u6cd5", "conclusion": "CARJAN\u4e3a\u57ce\u5e02\u4ea4\u901a\u573a\u666f\u7684\u5efa\u6a21\u548c\u4eff\u771f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u534a\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u6846\u67b6\u548c\u9a7e\u9a76\u6a21\u62df\u5668\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e0d\u540c\u7c7b\u578b\u4ea4\u901a\u53c2\u4e0e\u8005\u4ea4\u4e92\u4eff\u771f\u7684\u6311\u6218"}}
{"id": "2508.21393", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21393", "abs": "https://arxiv.org/abs/2508.21393", "authors": ["Guofu Liao", "Taotao Wang", "Shengli Zhang", "Jiqun Zhang", "Shi Long", "Dacheng Tao"], "title": "zkLoRA: Fine-Tuning Large Language Models with Verifiable Security via Zero-Knowledge Proofs", "comment": null, "summary": "Fine-tuning large language models (LLMs) is crucial for adapting them to\nspecific tasks, yet it remains computationally demanding and raises concerns\nabout correctness and privacy, particularly in untrusted environments. Although\nparameter-efficient methods like Low-Rank Adaptation (LoRA) significantly\nreduce resource requirements, ensuring the security and verifiability of\nfine-tuning under zero-knowledge constraints remains an unresolved challenge.\nTo address this, we introduce zkLoRA, the first framework to integrate LoRA\nfine-tuning with zero-knowledge proofs (ZKPs), achieving provable security and\ncorrectness. zkLoRA employs advanced cryptographic techniques -- such as lookup\narguments, sumcheck protocols, and polynomial commitments -- to verify both\narithmetic and non-arithmetic operations in Transformer-based architectures.\nThe framework provides end-to-end verifiability for forward propagation,\nbackward propagation, and parameter updates during LoRA fine-tuning, while\nsafeguarding the privacy of model parameters and training data. Leveraging\nGPU-based implementations, zkLoRA demonstrates practicality and efficiency\nthrough experimental validation on open-source LLMs like LLaMA, scaling up to\n13 billion parameters. By combining parameter-efficient fine-tuning with ZKPs,\nzkLoRA bridges a critical gap, enabling secure and trustworthy deployment of\nLLMs in sensitive or untrusted environments.", "AI": {"tldr": "zkLoRA\u662f\u9996\u4e2a\u5c06LoRA\u5fae\u8c03\u4e0e\u96f6\u77e5\u8bc6\u8bc1\u660e\u7ed3\u5408\u7684\u5b89\u5168\u6846\u67b6\uff0c\u4e3aTransformer\u67b6\u6784\u63d0\u4f9b\u7aef\u5230\u7aef\u53ef\u9a8c\u8bc1\u6027\uff0c\u4fdd\u62a4\u6a21\u578b\u53c2\u6570\u548c\u8bad\u7ec3\u6570\u636e\u9690\u79c1", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u5728\u4e0d\u53ef\u4fe1\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u548c\u9690\u79c1\u4fdd\u62a4\u4e0d\u8db3\u7684\u6311\u6218", "method": "\u7ed3\u5408\u4f4e\u79e9\u9002\u5e94(LoRA)\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e(ZKP)\uff0c\u4f7f\u7528\u67e5\u627e\u53c2\u6570\u3001\u6c42\u548c\u68c0\u67e5\u534f\u8bae\u548c\u591a\u9879\u5f0f\u627f\u8bfa\u7b49\u5bc6\u7801\u5b66\u6280\u672f\u9a8c\u8bc1\u7b97\u672f\u548c\u975e\u7b97\u672f\u64cd\u4f5c", "result": "\u5728LLaMA\u7b49\u5f00\u6e90\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u53ef\u6269\u5c55\u6027\uff08\u652f\u6301130\u4ebf\u53c2\u6570\uff09\uff0c\u901a\u8fc7GPU\u5b9e\u73b0\u5c55\u793a\u4e86\u5b9e\u7528\u6027\u548c\u6548\u7387", "conclusion": "zkLoRA\u586b\u8865\u4e86\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u4e0e\u96f6\u77e5\u8bc6\u8bc1\u660e\u4e4b\u95f4\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u654f\u611f\u73af\u5883\u4e2d\u7684LLM\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u4fe1\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.21454", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.21454", "abs": "https://arxiv.org/abs/2508.21454", "authors": ["Baijun Cheng", "Kailong Wang", "Ling Shi", "Haoyu Wang", "Yao Guo", "Ding Li", "Xiangqun Chen"], "title": "Enhancing Semantic Understanding in Pointer Analysis using Large Language Models", "comment": "Accepted by LMPL 2025", "summary": "Pointer analysis has been studied for over four decades. However, existing\nframeworks continue to suffer from the propagation of incorrect facts. A major\nlimitation stems from their insufficient semantic understanding of code,\nresulting in overly conservative treatment of user-defined functions. Recent\nadvances in large language models (LLMs) present new opportunities to bridge\nthis gap. In this paper, we propose LMPA (LLM-enhanced Pointer Analysis), a\nvision that integrates LLMs into pointer analysis to enhance both precision and\nscalability. LMPA identifies user-defined functions that resemble system APIs\nand models them accordingly, thereby mitigating erroneous cross-calling-context\npropagation. Furthermore, it enhances summary-based analysis by inferring\ninitial points-to sets and introducing a novel summary strategy augmented with\nnatural language. Finally, we discuss the key challenges involved in realizing\nthis vision.", "AI": {"tldr": "LMPA\u662f\u4e00\u4e2a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u6307\u9488\u5206\u6790\u4e2d\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7LLM\u8bc6\u522b\u7c7b\u4f3c\u7cfb\u7edfAPI\u7684\u7528\u6237\u81ea\u5b9a\u4e49\u51fd\u6570\u5e76\u5efa\u6a21\uff0c\u63d0\u5347\u6307\u9488\u5206\u6790\u7684\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027", "motivation": "\u4f20\u7edf\u6307\u9488\u5206\u6790\u6846\u67b6\u7531\u4e8e\u5bf9\u4ee3\u7801\u8bed\u4e49\u7406\u89e3\u4e0d\u8db3\uff0c\u5728\u5904\u7406\u7528\u6237\u81ea\u5b9a\u4e49\u51fd\u6570\u65f6\u8fc7\u4e8e\u4fdd\u5b88\uff0c\u5bfc\u81f4\u9519\u8bef\u4e8b\u5b9e\u4f20\u64ad\u3002LLM\u7684\u53d1\u5c55\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a", "method": "LMPA\u8bc6\u522b\u7c7b\u4f3c\u7cfb\u7edfAPI\u7684\u7528\u6237\u81ea\u5b9a\u4e49\u51fd\u6570\u5e76\u76f8\u5e94\u5efa\u6a21\uff0c\u51cf\u5c11\u9519\u8bef\u7684\u8de8\u8c03\u7528\u4e0a\u4e0b\u6587\u4f20\u64ad\uff1b\u901a\u8fc7\u63a8\u65ad\u521d\u59cb\u70b9\u96c6\u548c\u5f15\u5165\u81ea\u7136\u8bed\u8a00\u589e\u5f3a\u7684\u6458\u8981\u7b56\u7565\u6765\u6539\u8fdb\u57fa\u4e8e\u6458\u8981\u7684\u5206\u6790", "result": "\u8bba\u6587\u63d0\u51fa\u4e86LMPA\u7684\u613f\u666f\u6846\u67b6\uff0c\u4f46\u5c1a\u672a\u63d0\u4f9b\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c", "conclusion": "LMPA\u5c55\u793a\u4e86\u5c06LLM\u96c6\u6210\u5230\u6307\u9488\u5206\u6790\u4e2d\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u63d0\u5347\u5206\u6790\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027\uff0c\u8bba\u6587\u8fd8\u8ba8\u8bba\u4e86\u5b9e\u73b0\u8fd9\u4e00\u613f\u666f\u7684\u5173\u952e\u6311\u6218"}}
{"id": "2508.21441", "categories": ["cs.AI", "68T30, 68T27"], "pdf": "https://arxiv.org/pdf/2508.21441", "abs": "https://arxiv.org/abs/2508.21441", "authors": ["Christoph Beierle", "Alexander Hahn", "Diana Howey", "Gabriele Kern-Isberner", "Kai Sauerwald"], "title": "A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions", "comment": null, "summary": "Forgetting as a knowledge management operation deliberately ignores parts of\nthe knowledge and beliefs of an agent, for various reasons. Forgetting has many\nfacets, one may want to forget parts of the syntax, a proposition, or a\nconditional. In the literature, two main operators suitable for performing\nforgetting have been proposed and investigated in depth: First, variable\nelimination is a syntactical method that blends out certain atomic variables to\nfocus on the rest of the language. It has been mainly used in the area of logic\nprogramming and answer set programming. Second, contraction in AGM belief\nrevision theory effectively removes propositions from belief sets under logical\ndeduction. Both operations rely mainly on classical logics. In this article, we\ntake an epistemic perspective and study forgetting operations in epistemic\nstates with richer semantic structures, but with clear links to propositional\nlogic. This allows us to investigate what forgetting in the epistemic\nbackground means, thereby lifting well-known and novel forgetting operations to\nthe epistemic level. We present five general types of epistemic forgetting and\ninstantiate them with seven concrete forgetting operations for Spohn's ranking\nfunctions. We take inspiration from postulates of forgetting both from logic\nprogramming and AGM theory to propose a rich landscape of axioms for evaluating\nforgetting operations. Finally, we evaluate all concrete forgetting operations\naccording to all postulates, leading to a novel comprehensive overview\nhighlighting differences and commonalities among the forgetting operators.", "AI": {"tldr": "\u672c\u6587\u4ece\u8ba4\u77e5\u89d2\u5ea6\u7814\u7a76\u77e5\u8bc6\u7ba1\u7406\u4e2d\u7684\u9057\u5fd8\u64cd\u4f5c\uff0c\u5728Spohn\u6392\u5e8f\u51fd\u6570\u7684\u8ba4\u77e5\u72b6\u6001\u4e0b\u63d0\u51fa\u4e86\u4e94\u79cd\u901a\u7528\u7c7b\u578b\u548c\u4e03\u79cd\u5177\u4f53\u9057\u5fd8\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7\u903b\u8f91\u7f16\u7a0b\u548cAGM\u7406\u8bba\u7684\u516c\u7406\u4f53\u7cfb\u5bf9\u8fd9\u4e9b\u64cd\u4f5c\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u7684\u9057\u5fd8\u64cd\u4f5c\u4e3b\u8981\u57fa\u4e8e\u7ecf\u5178\u903b\u8f91\uff0c\u5982\u53d8\u91cf\u6d88\u9664\u548cAGM\u6536\u7f29\u7406\u8bba\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8ba4\u77e5\u72b6\u6001\u4e0b\u9057\u5fd8\u64cd\u4f5c\u7684\u6df1\u5165\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u4ece\u8ba4\u77e5\u89c6\u89d2\u63a2\u7d22\u5177\u6709\u66f4\u4e30\u5bcc\u8bed\u4e49\u7ed3\u6784\u7684\u9057\u5fd8\u64cd\u4f5c\u3002", "method": "\u91c7\u7528\u8ba4\u77e5\u72b6\u6001\u5efa\u6a21\uff0c\u63d0\u51fa\u4e94\u79cd\u901a\u7528\u7c7b\u578b\u7684\u8ba4\u77e5\u9057\u5fd8\u64cd\u4f5c\uff0c\u5e76\u5728Spohn\u6392\u5e8f\u51fd\u6570\u4e0a\u5b9e\u4f8b\u5316\u4e03\u79cd\u5177\u4f53\u64cd\u4f5c\u3002\u501f\u9274\u903b\u8f91\u7f16\u7a0b\u548cAGM\u7406\u8bba\u7684\u516c\u7406\u4f53\u7cfb\uff0c\u5efa\u7acb\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u7cfb\u7edf\u8bc4\u4f30\u4e86\u6240\u6709\u5177\u4f53\u9057\u5fd8\u64cd\u4f5c\u5728\u4e0d\u540c\u516c\u7406\u4e0b\u7684\u8868\u73b0\uff0c\u63d0\u4f9b\u4e86\u65b0\u9896\u7684\u7efc\u5408\u6982\u89c8\uff0c\u7a81\u51fa\u4e86\u5404\u9057\u5fd8\u7b97\u5b50\u4e4b\u95f4\u7684\u5dee\u5f02\u548c\u5171\u540c\u70b9\u3002", "conclusion": "\u7814\u7a76\u5c06\u7ecf\u5178\u9057\u5fd8\u64cd\u4f5c\u63d0\u5347\u5230\u8ba4\u77e5\u5c42\u9762\uff0c\u4e3a\u77e5\u8bc6\u7ba1\u7406\u4e2d\u7684\u9057\u5fd8\u64cd\u4f5c\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u8df5\u6307\u5bfc\uff0c\u5c55\u793a\u4e86\u4e0d\u540c\u9057\u5fd8\u7b97\u5b50\u5728\u8ba4\u77e5\u72b6\u6001\u4e0b\u7684\u7279\u6027\u548c\u9002\u7528\u573a\u666f\u3002"}}
{"id": "2508.21417", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.21417", "abs": "https://arxiv.org/abs/2508.21417", "authors": ["Shuhan Liu", "Xing Hu", "Xin Xia", "David Lo", "Xiaohu Yang"], "title": "An Empirical Study of Vulnerable Package Dependencies in LLM Repositories", "comment": null, "summary": "Large language models (LLMs) have developed rapidly in recent years,\nrevolutionizing various fields. Despite their widespread success, LLMs heavily\nrely on external code dependencies from package management systems, creating a\ncomplex and interconnected LLM dependency supply chain. Vulnerabilities in\ndependencies can expose LLMs to security risks. While existing research\npredominantly focuses on model-level security threats, vulnerabilities within\nthe LLM dependency supply chain have been overlooked. To fill this gap, we\nconducted an empirical analysis of 52 open-source LLMs, examining their\nthird-party dependencies and associated vulnerabilities. We then explored\nactivities within the LLM repositories to understand how maintainers manage\nthird-party vulnerabilities in practice. Finally, we compared third-party\ndependency vulnerabilities in the LLM ecosystem to those in the Python\necosystem. Our results show that half of the vulnerabilities in the LLM\necosystem remain undisclosed for more than 56.2 months, significantly longer\nthan those in the Python ecosystem. Additionally, 75.8% of LLMs include\nvulnerable dependencies in their configuration files. This study advances the\nunderstanding of LLM supply chain risks, provides insights for practitioners,\nand highlights potential directions for improving the security of the LLM\nsupply chain.", "AI": {"tldr": "\u5bf952\u4e2a\u5f00\u6e90LLM\u7684\u7b2c\u4e09\u65b9\u4f9d\u8d56\u6f0f\u6d1e\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0LLM\u751f\u6001\u7cfb\u7edf\u4e2d\u6f0f\u6d1e\u62ab\u9732\u65f6\u95f4\u663e\u8457\u957f\u4e8ePython\u751f\u6001\u7cfb\u7edf\uff0c\u4e1475.8%\u7684LLM\u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\u5305\u542b\u6613\u53d7\u653b\u51fb\u7684\u4f9d\u8d56\u9879\u3002", "motivation": "\u5c3d\u7ba1LLM\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5176\u4e25\u91cd\u4f9d\u8d56\u5916\u90e8\u4ee3\u7801\u4f9d\u8d56\uff0c\u5f62\u6210\u4e86\u590d\u6742\u7684\u4f9d\u8d56\u4f9b\u5e94\u94fe\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u7ea7\u5b89\u5168\u5a01\u80c1\uff0c\u800cLLM\u4f9d\u8d56\u4f9b\u5e94\u94fe\u4e2d\u7684\u6f0f\u6d1e\u88ab\u5ffd\u89c6\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5bf952\u4e2a\u5f00\u6e90LLM\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u68c0\u67e5\u5176\u7b2c\u4e09\u65b9\u4f9d\u8d56\u548c\u76f8\u5173\u6f0f\u6d1e\uff1b\u63a2\u7d22LLM\u4ed3\u5e93\u4e2d\u7684\u6d3b\u52a8\u4ee5\u4e86\u89e3\u7ef4\u62a4\u8005\u5982\u4f55\u7ba1\u7406\u7b2c\u4e09\u65b9\u6f0f\u6d1e\uff1b\u5c06LLM\u751f\u6001\u7cfb\u7edf\u7684\u7b2c\u4e09\u65b9\u4f9d\u8d56\u6f0f\u6d1e\u4e0ePython\u751f\u6001\u7cfb\u7edf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "LLM\u751f\u6001\u7cfb\u7edf\u4e2d\u4e00\u534a\u7684\u6f0f\u6d1e\u672a\u88ab\u62ab\u9732\u8d85\u8fc756.2\u4e2a\u6708\uff0c\u663e\u8457\u957f\u4e8ePython\u751f\u6001\u7cfb\u7edf\uff1b75.8%\u7684LLM\u5728\u5176\u914d\u7f6e\u6587\u4ef6\u4e2d\u5305\u542b\u6613\u53d7\u653b\u51fb\u7684\u4f9d\u8d56\u9879\u3002", "conclusion": "\u8be5\u7814\u7a76\u589e\u8fdb\u4e86\u5bf9LLM\u4f9b\u5e94\u94fe\u98ce\u9669\u7684\u7406\u89e3\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u5e76\u6307\u51fa\u4e86\u6539\u8fdbLLM\u4f9b\u5e94\u94fe\u5b89\u5168\u7684\u6f5c\u5728\u65b9\u5411\u3002"}}
{"id": "2508.21553", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.21553", "abs": "https://arxiv.org/abs/2508.21553", "authors": ["J\u00f8rn Eirik Betten", "Quentin Mazouni", "Dennis Gross", "Pedro Lind", "Helge Spieker"], "title": "Reusable Test Suites for Reinforcement Learning", "comment": null, "summary": "Reinforcement learning (RL) agents show great promise in solving sequential\ndecision-making tasks. However, validating the reliability and performance of\nthe agent policies' behavior for deployment remains challenging. Most\nreinforcement learning policy testing methods produce test suites tailored to\nthe agent policy being tested, and their relevance to other policies is\nunclear. This work presents Multi-Policy Test Case Selection (MPTCS), a novel\nautomated test suite selection method for RL environments, designed to extract\ntest cases generated by any policy testing framework based on their\nsolvability, diversity, and general difficulty. MPTCS uses a set of policies to\nselect a diverse collection of reusable policy-agnostic test cases that reveal\ntypical flaws in the agents' behavior. The set of policies selects test cases\nfrom a candidate pool, which can be generated by any policy testing method,\nbased on a difficulty score. We assess the effectiveness of the difficulty\nscore and how the method's effectiveness and cost depend on the number of\npolicies in the set. Additionally, a method for promoting diversity in the test\nsuite, a discretized general test case descriptor surface inspired by\nquality-diversity algorithms, is examined to determine how it covers the state\nspace and which policies it triggers to produce faulty behaviors.", "AI": {"tldr": "\u63d0\u51faMPTCS\u65b9\u6cd5\uff0c\u4ece\u4efb\u4f55\u7b56\u7565\u6d4b\u8bd5\u6846\u67b6\u751f\u6210\u7684\u6d4b\u8bd5\u7528\u4f8b\u4e2d\uff0c\u57fa\u4e8e\u53ef\u89e3\u6027\u3001\u591a\u6837\u6027\u548c\u901a\u7528\u96be\u5ea6\u9009\u62e9\u7b56\u7565\u65e0\u5173\u7684\u591a\u6837\u5316\u6d4b\u8bd5\u7528\u4f8b\u96c6", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u6d4b\u8bd5\u65b9\u6cd5\u751f\u6210\u7684\u6d4b\u8bd5\u5957\u4ef6\u9488\u5bf9\u7279\u5b9a\u7b56\u7565\u5b9a\u5236\uff0c\u5bf9\u5176\u4ed6\u7b56\u7565\u7684\u9002\u7528\u6027\u4e0d\u660e\u786e\uff0c\u9700\u8981\u53ef\u91cd\u7528\u7684\u7b56\u7565\u65e0\u5173\u6d4b\u8bd5\u7528\u4f8b", "method": "\u4f7f\u7528\u4e00\u7ec4\u7b56\u7565\u57fa\u4e8e\u96be\u5ea6\u8bc4\u5206\u4ece\u5019\u9009\u6c60\u4e2d\u9009\u62e9\u6d4b\u8bd5\u7528\u4f8b\uff0c\u91c7\u7528\u79bb\u6563\u5316\u901a\u7528\u6d4b\u8bd5\u7528\u4f8b\u63cf\u8ff0\u7b26\u8868\u9762\u6765\u4fc3\u8fdb\u6d4b\u8bd5\u5957\u4ef6\u591a\u6837\u6027", "result": "\u8bc4\u4f30\u4e86\u96be\u5ea6\u8bc4\u5206\u7684\u6709\u6548\u6027\uff0c\u5206\u6790\u4e86\u65b9\u6cd5\u6548\u679c\u548c\u6210\u672c\u4e0e\u7b56\u7565\u6570\u91cf\u7684\u5173\u7cfb\uff0c\u68c0\u9a8c\u4e86\u591a\u6837\u6027\u65b9\u6cd5\u5bf9\u72b6\u6001\u7a7a\u95f4\u7684\u8986\u76d6\u548c\u89e6\u53d1\u6545\u969c\u884c\u4e3a\u7684\u80fd\u529b", "conclusion": "MPTCS\u80fd\u591f\u9009\u62e9\u63ed\u793a\u667a\u80fd\u4f53\u884c\u4e3a\u5178\u578b\u7f3a\u9677\u7684\u591a\u6837\u5316\u3001\u53ef\u91cd\u7528\u7b56\u7565\u65e0\u5173\u6d4b\u8bd5\u7528\u4f8b"}}
{"id": "2508.21449", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21449", "abs": "https://arxiv.org/abs/2508.21449", "authors": ["Niklas Jansen", "Jonas G\u00f6sgens", "Hector Geffner"], "title": "Learning Lifted Action Models From Traces of Incomplete Actions and States", "comment": "To be presented at KR 2025", "summary": "Consider the problem of learning a lifted STRIPS model of the sliding-tile\npuzzle from random state-action traces where the states represent the location\nof the tiles only, and the actions are the labels up, down, left, and right,\nwith no arguments. Two challenges are involved in this problem. First, the\nstates are not full STRIPS states, as some predicates are missing, like the\natoms representing the position of the ``blank''. Second, the actions are not\nfull STRIPS either, as they do not reveal all the objects involved in the\nactions effects and preconditions. Previous approaches have addressed different\nversions of this model learning problem, but most assume that actions in the\ntraces are full STRIPS actions or that the domain predicates are all\nobservable. The new setting considered in this work is more ``realistic'', as\nthe atoms observed convey the state of the world but not full STRIPS states,\nand the actions reveal the arguments needed for selecting the action but not\nthe ones needed for modeling it in STRIPS. For formulating and addressing the\nlearning problem, we introduce a variant of STRIPS, which we call STRIPS+,\nwhere certain STRIPS action arguments can be left implicit in preconditions\nwhich can also involve a limited form of existential quantification. The\nlearning problem becomes the problem of learning STRIPS+ models from STRIPS+\nstate-action traces. For this, the proposed learning algorithm, called SYNTH,\nconstructs a stratified sequence (conjunction) of precondition expressions or\n``queries'' for each action, that denote unique objects in the state and ground\nthe implicit action arguments in STRIPS+. The correctness and completeness of\nSYNTH is established, and its scalability is tested on state-action traces\nobtained from STRIPS+ models derived from existing STRIPS domains.", "AI": {"tldr": "\u4ece\u968f\u673a\u72b6\u6001-\u52a8\u4f5c\u8f68\u8ff9\u4e2d\u5b66\u4e60\u6ed1\u52a8\u62fc\u56fe\u6e38\u620f\u7684\u63d0\u5347STRIPS\u6a21\u578b\uff0c\u5904\u7406\u4e0d\u5b8c\u6574\u7684\u72b6\u6001\u8868\u793a\u548c\u52a8\u4f5c\u53c2\u6570\u7f3a\u5931\u95ee\u9898", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u5047\u8bbe\u52a8\u4f5c\u662f\u5b8c\u6574\u7684STRIPS\u52a8\u4f5c\u6216\u6240\u6709\u8c13\u8bcd\u90fd\u53ef\u89c2\u5bdf\uff0c\u4f46\u73b0\u5b9e\u573a\u666f\u4e2d\u72b6\u6001\u548c\u52a8\u4f5c\u4fe1\u606f\u5f80\u5f80\u4e0d\u5b8c\u6574\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u7684\u5b66\u4e60\u8bbe\u7f6e", "method": "\u5f15\u5165STRIPS+\u53d8\u4f53\uff0c\u5141\u8bb8\u52a8\u4f5c\u53c2\u6570\u5728\u524d\u63d0\u6761\u4ef6\u4e2d\u9690\u5f0f\u5b58\u5728\uff0c\u5e76\u63d0\u51faSYNTH\u7b97\u6cd5\u901a\u8fc7\u6784\u5efa\u5206\u5c42\u7684\u524d\u63d0\u8868\u8fbe\u5f0f\u5e8f\u5217\u6765\u5b66\u4e60STRIPS+\u6a21\u578b", "result": "\u5efa\u7acb\u4e86SYNTH\u7b97\u6cd5\u7684\u6b63\u786e\u6027\u548c\u5b8c\u5907\u6027\uff0c\u5e76\u5728\u4ece\u73b0\u6709STRIPS\u9886\u57df\u884d\u751f\u7684STRIPS+\u6a21\u578b\u751f\u6210\u7684\u72b6\u6001-\u52a8\u4f5c\u8f68\u8ff9\u4e0a\u6d4b\u8bd5\u4e86\u53ef\u6269\u5c55\u6027", "conclusion": "\u63d0\u51fa\u7684STRIPS+\u6846\u67b6\u548cSYNTH\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u72b6\u6001\u548c\u52a8\u4f5c\u4fe1\u606f\u4e0d\u5b8c\u6574\u7684\u6a21\u578b\u5b66\u4e60\u95ee\u9898\uff0c\u4e3a\u66f4\u73b0\u5b9e\u7684\u89c4\u5212\u6a21\u578b\u5b66\u4e60\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.21432", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.21432", "abs": "https://arxiv.org/abs/2508.21432", "authors": ["Wenjie Qu", "Yuguang Zhou", "Bo Wang", "Wengrui Zheng", "Yuexin Li", "Jinyuan Jia", "Jiaheng Zhang"], "title": "RepoMark: A Code Usage Auditing Framework for Code Large Language Models", "comment": null, "summary": "The rapid development of Large Language Models (LLMs) for code generation has\ntransformed software development by automating coding tasks with unprecedented\nefficiency.\n  However, the training of these models on open-source code repositories (e.g.,\nfrom GitHub) raises critical ethical and legal concerns, particularly regarding\ndata authorization and open-source license compliance. Developers are\nincreasingly questioning whether model trainers have obtained proper\nauthorization before using repositories for training, especially given the lack\nof transparency in data collection.\n  To address these concerns, we propose a novel data marking framework RepoMark\nto audit the data usage of code LLMs. Our method enables repository owners to\nverify whether their code has been used in training, while ensuring semantic\npreservation, imperceptibility, and theoretical false detection rate (FDR)\nguarantees. By generating multiple semantically equivalent code variants,\nRepoMark introduces data marks into the code files, and during detection,\nRepoMark leverages a novel ranking-based hypothesis test to detect memorization\nwithin the model. Compared to prior data auditing approaches, RepoMark\nsignificantly enhances sample efficiency, allowing effective auditing even when\nthe user's repository possesses only a small number of code files.\n  Experiments demonstrate that RepoMark achieves a detection success rate over\n90\\% on small code repositories under a strict FDR guarantee of 5\\%. This\nrepresents a significant advancement over existing data marking techniques, all\nof which only achieve accuracy below 55\\% under identical settings. This\nfurther validates RepoMark as a robust, theoretically sound, and promising\nsolution for enhancing transparency in code LLM training, which can safeguard\nthe rights of repository owners.", "AI": {"tldr": "RepoMark\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6570\u636e\u6807\u8bb0\u6846\u67b6\uff0c\u7528\u4e8e\u5ba1\u8ba1\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u4f7f\u7528\u60c5\u51b5\uff0c\u901a\u8fc7\u751f\u6210\u8bed\u4e49\u7b49\u6548\u7684\u4ee3\u7801\u53d8\u4f53\u5e76\u5f15\u5165\u6570\u636e\u6807\u8bb0\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u68c0\u6d4b\u6a21\u578b\u662f\u5426\u4f7f\u7528\u4e86\u7279\u5b9a\u4ee3\u7801\u5e93\u8fdb\u884c\u8bad\u7ec3\u3002", "motivation": "\u968f\u7740\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u6a21\u578b\u5728\u5f00\u6e90\u4ee3\u7801\u5e93\u4e0a\u7684\u8bad\u7ec3\u5f15\u53d1\u4e86\u4e25\u91cd\u7684\u4f26\u7406\u548c\u6cd5\u5f8b\u95ee\u9898\uff0c\u7279\u522b\u662f\u6570\u636e\u6388\u6743\u548c\u5f00\u6e90\u8bb8\u53ef\u8bc1\u5408\u89c4\u6027\u95ee\u9898\u3002\u5f00\u53d1\u8005\u8d28\u7591\u6a21\u578b\u8bad\u7ec3\u8005\u662f\u5426\u83b7\u5f97\u4e86\u9002\u5f53\u7684\u6388\u6743\uff0c\u800c\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u7f3a\u4e4f\u900f\u660e\u5ea6\u3002", "method": "\u63d0\u51faRepoMark\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u591a\u4e2a\u8bed\u4e49\u7b49\u6548\u7684\u4ee3\u7801\u53d8\u4f53\uff0c\u5728\u4ee3\u7801\u6587\u4ef6\u4e2d\u5f15\u5165\u6570\u636e\u6807\u8bb0\u3002\u5728\u68c0\u6d4b\u9636\u6bb5\uff0c\u4f7f\u7528\u57fa\u4e8e\u6392\u5e8f\u7684\u65b0\u578b\u5047\u8bbe\u68c0\u9a8c\u65b9\u6cd5\u6765\u68c0\u6d4b\u6a21\u578b\u4e2d\u7684\u8bb0\u5fc6\u5316\u73b0\u8c61\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4e25\u683c\u76845%\u9519\u8bef\u68c0\u6d4b\u7387\u4fdd\u8bc1\u4e0b\uff0cRepoMark\u5728\u5c0f\u4ee3\u7801\u5e93\u4e0a\u7684\u68c0\u6d4b\u6210\u529f\u7387\u8d85\u8fc790%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6570\u636e\u6807\u8bb0\u6280\u672f\uff08\u51c6\u786e\u7387\u4f4e\u4e8e55%\uff09\u3002", "conclusion": "RepoMark\u662f\u4e00\u4e2a\u5f3a\u5927\u3001\u7406\u8bba\u53ef\u9760\u4e14\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u589e\u5f3a\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u900f\u660e\u5ea6\uff0c\u4fdd\u62a4\u4ee3\u7801\u5e93\u6240\u6709\u8005\u7684\u6743\u76ca\u3002"}}
{"id": "2508.21634", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.21634", "abs": "https://arxiv.org/abs/2508.21634", "authors": ["Domenico Cotroneo", "Cristina Improta", "Pietro Liguori"], "title": "Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects, Vulnerabilities, and Complexity", "comment": "Accepted to the 36th IEEE International Symposium on Software\n  Reliability Engineering (ISSRE, 2025)", "summary": "As AI code assistants become increasingly integrated into software\ndevelopment workflows, understanding how their code compares to human-written\nprograms is critical for ensuring reliability, maintainability, and security.\nIn this paper, we present a large-scale comparison of code authored by human\ndevelopers and three state-of-the-art LLMs, i.e., ChatGPT, DeepSeek-Coder, and\nQwen-Coder, on multiple dimensions of software quality: code defects, security\nvulnerabilities, and structural complexity. Our evaluation spans over 500k code\nsamples in two widely used languages, Python and Java, classifying defects via\nOrthogonal Defect Classification and security vulnerabilities using the Common\nWeakness Enumeration. We find that AI-generated code is generally simpler and\nmore repetitive, yet more prone to unused constructs and hardcoded debugging,\nwhile human-written code exhibits greater structural complexity and a higher\nconcentration of maintainability issues. Notably, AI-generated code also\ncontains more high-risk security vulnerabilities. These findings highlight the\ndistinct defect profiles of AI- and human-authored code and underscore the need\nfor specialized quality assurance practices in AI-assisted programming.", "AI": {"tldr": "\u5927\u89c4\u6a21\u6bd4\u8f83\u4eba\u7c7b\u5f00\u53d1\u8005\u548c\u4e09\u5927LLM\uff08ChatGPT\u3001DeepSeek-Coder\u3001Qwen-Coder\uff09\u7f16\u5199\u7684\u4ee3\u7801\u8d28\u91cf\uff0c\u53d1\u73b0AI\u751f\u6210\u4ee3\u7801\u66f4\u7b80\u5355\u4f46\u5b58\u5728\u66f4\u591a\u5b89\u5168\u6f0f\u6d1e\u548c\u672a\u4f7f\u7528\u6784\u9020\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7801\u52a9\u624b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u4e86\u89e3AI\u751f\u6210\u4ee3\u7801\u4e0e\u4eba\u7c7b\u7f16\u5199\u4ee3\u7801\u5728\u53ef\u9760\u6027\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u7684\u5dee\u5f02\u3002", "method": "\u8bc4\u4f30\u8d85\u8fc750\u4e07\u4e2aPython\u548cJava\u4ee3\u7801\u6837\u672c\uff0c\u4f7f\u7528\u6b63\u4ea4\u7f3a\u9677\u5206\u7c7b\u548c\u5e38\u89c1\u5f31\u70b9\u679a\u4e3e\u6765\u5206\u6790\u4ee3\u7801\u7f3a\u9677\u3001\u5b89\u5168\u6f0f\u6d1e\u548c\u7ed3\u6784\u590d\u6742\u6027\u3002", "result": "AI\u751f\u6210\u4ee3\u7801\u66f4\u7b80\u5355\u91cd\u590d\uff0c\u4f46\u66f4\u5bb9\u6613\u51fa\u73b0\u672a\u4f7f\u7528\u6784\u9020\u548c\u786c\u7f16\u7801\u8c03\u8bd5\uff1b\u4eba\u7c7b\u4ee3\u7801\u7ed3\u6784\u66f4\u590d\u6742\u4f46\u53ef\u7ef4\u62a4\u6027\u95ee\u9898\u66f4\u591a\uff1bAI\u4ee3\u7801\u5305\u542b\u66f4\u591a\u9ad8\u98ce\u9669\u5b89\u5168\u6f0f\u6d1e\u3002", "conclusion": "AI\u548c\u4eba\u7c7b\u7f16\u5199\u7684\u4ee3\u7801\u5177\u6709\u4e0d\u540c\u7684\u7f3a\u9677\u7279\u5f81\uff0c\u9700\u8981\u5728AI\u8f85\u52a9\u7f16\u7a0b\u4e2d\u91c7\u7528\u4e13\u95e8\u7684\u8d28\u91cf\u4fdd\u8bc1\u5b9e\u8df5\u3002"}}
{"id": "2508.21475", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21475", "abs": "https://arxiv.org/abs/2508.21475", "authors": ["Xijia Tao", "Yihua Teng", "Xinxing Su", "Xinyu Fu", "Jihao Wu", "Chaofan Tao", "Ziru Liu", "Haoli Bai", "Rui Liu", "Lingpeng Kong"], "title": "MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents", "comment": "Project Page: https://mmsearch-plus.github.io", "summary": "Large multimodal language models (MLLMs) are increasingly deployed as web\nagents, yet many multimodal browsing benchmarks can be solved by shallow, fixed\nworkflows that lean on high-recall image search and nearby text-masking the\ngenuinely multimodal challenges of fine-grained visual reasoning, provenance\nverification, and long-horizon tool use. We introduce MMSearch-Plus, a\nbenchmark of 311 tasks that highly demand multimodal understanding while\npreserving the difficulty profile of strong text-only browsing suites. Each\nitem is constructed to contain multiple weak, localized visual signals that\nmust be extracted, propagated through iterative text-image search, and\ncross-validated under retrieval noise before answering. Our curation procedure,\nSpatial-Temporal Extrapolation, seeds questions whose answers require\nextrapolating from spatial cues (micro-text, part-level appearance, layouts,\nsignage) and temporal traces (broadcast overlays, seasonal context) to\nout-of-image facts such as events, dates, and venues. We provide a\nmodel-agnostic agent framework with browsing tools and evaluate a range of\nclosed and open MLLMs. The strongest agent (o3) attains 15.1% without search\nand 36.0% accuracy with rollout under our framework, while a strong open-source\nmodel (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20\nrounds of search. Beyond answer accuracy, we assess bounding-box production and\ncropped-image search, and conduct an error analysis that surfaces failures in\nsource verification, part-based reasoning, and long-horizon planning.", "AI": {"tldr": "MMSearch-Plus\u662f\u4e00\u4e2a\u5305\u542b311\u4e2a\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u6df1\u5ea6\u89c6\u89c9\u63a8\u7406\u3001\u6765\u6e90\u9a8c\u8bc1\u548c\u957f\u65f6\u7a0b\u5de5\u5177\u4f7f\u7528\u7684\u590d\u6742\u7f51\u9875\u6d4f\u89c8\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u6d4f\u89c8\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u53ef\u4ee5\u901a\u8fc7\u6d45\u5c42\u7684\u56fa\u5b9a\u5de5\u4f5c\u6d41\u7a0b\u89e3\u51b3\uff0c\u65e0\u6cd5\u771f\u6b63\u6d4b\u8bd5\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u89c6\u89c9\u63a8\u7406\u3001\u6765\u6e90\u9a8c\u8bc1\u548c\u957f\u65f6\u7a0b\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u91c7\u7528\u7a7a\u95f4-\u65f6\u95f4\u5916\u63a8\u6cd5\u6784\u5efa\u4efb\u52a1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u5305\u542b\u591a\u4e2a\u5f31\u5c40\u90e8\u89c6\u89c9\u4fe1\u53f7\uff0c\u9700\u8981\u901a\u8fc7\u8fed\u4ee3\u7684\u6587\u672c-\u56fe\u50cf\u641c\u7d22\u8fdb\u884c\u63d0\u53d6\u3001\u4f20\u64ad\u548c\u4ea4\u53c9\u9a8c\u8bc1\u3002\u63d0\u4f9b\u6a21\u578b\u65e0\u5173\u7684\u4ee3\u7406\u6846\u67b6\u548c\u6d4f\u89c8\u5de5\u5177\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6700\u5f3a\u4ee3\u7406(o3)\u5728\u6ca1\u6709\u641c\u7d22\u7684\u60c5\u51b5\u4e0b\u8fbe\u523015.1%\u51c6\u786e\u7387\uff0c\u5728\u641c\u7d22\u5c55\u5f00\u540e\u8fbe\u523036.0%\uff1b\u6700\u5f3a\u7684\u5f00\u6e90\u6a21\u578b(Qwen-2.5-VL-72B-Instruct)\u5728\u6ca1\u6709\u641c\u7d22\u65f6\u4e3a0.0%\uff0c\u7ecf\u8fc720\u8f6e\u641c\u7d22\u540e\u8fbe\u52306.9%\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86\u5f53\u524d\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5728\u6765\u6e90\u9a8c\u8bc1\u3001\u57fa\u4e8e\u90e8\u4ef6\u7684\u63a8\u7406\u548c\u957f\u65f6\u7a0b\u89c4\u5212\u65b9\u9762\u7684\u5173\u952e\u5931\u8d25\u70b9\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2508.21440", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.21440", "abs": "https://arxiv.org/abs/2508.21440", "authors": ["Shan Wang", "Ming Yang", "Yu Liu", "Yue Zhang", "Shuaiqing Zhang", "Zhen Ling", "Jiannong Cao", "Xinwen Fu"], "title": "Time Tells All: Deanonymization of Blockchain RPC Users with Zero Transaction Fee (Extended Version)", "comment": null, "summary": "Remote Procedure Call (RPC) services have become a primary gateway for users\nto access public blockchains. While they offer significant convenience, RPC\nservices also introduce critical privacy challenges that remain insufficiently\nexamined. Existing deanonymization attacks either do not apply to blockchain\nRPC users or incur costs like transaction fees assuming an active network\neavesdropper. In this paper, we propose a novel deanonymization attack that can\nlink an IP address of a RPC user to this user's blockchain pseudonym. Our\nanalysis reveals a temporal correlation between the timestamps of transaction\nconfirmations recorded on the public ledger and those of TCP packets sent by\nthe victim when querying transaction status. We assume a strong passive\nadversary with access to network infrastructure, capable of monitoring traffic\nat network border routers or Internet exchange points. By monitoring network\ntraffic and analyzing public ledgers, the attacker can link the IP address of\nthe TCP packet to the pseudonym of the transaction initiator by exploiting the\ntemporal correlation. This deanonymization attack incurs zero transaction fee.\nWe mathematically model and analyze the attack method, perform large-scale\nmeasurements of blockchain ledgers, and conduct real-world attacks to validate\nthe attack. Our attack achieves a high success rate of over 95% against normal\nRPC users on various blockchain networks, including Ethereum, Bitcoin and\nSolana.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u533a\u5757\u94feRPC\u670d\u52a1\u7684\u96f6\u6210\u672c\u53bb\u533f\u540d\u5316\u653b\u51fb\uff0c\u901a\u8fc7\u5206\u6790\u4ea4\u6613\u786e\u8ba4\u65f6\u95f4\u4e0e\u7f51\u7edc\u6570\u636e\u5305\u65f6\u95f4\u6233\u7684\u5173\u8054\uff0c\u80fd\u591f\u4ee5\u8d85\u8fc795%\u7684\u6210\u529f\u7387\u5c06\u7528\u6237IP\u5730\u5740\u4e0e\u5176\u533a\u5757\u94fe\u5047\u540d\u5173\u8054", "motivation": "\u533a\u5757\u94feRPC\u670d\u52a1\u867d\u7136\u63d0\u4f9b\u4e86\u4fbf\u5229\uff0c\u4f46\u5b58\u5728\u4e25\u91cd\u7684\u9690\u79c1\u98ce\u9669\uff0c\u73b0\u6709\u7684\u53bb\u533f\u540d\u5316\u653b\u51fb\u8981\u4e48\u4e0d\u9002\u7528\u4e8eRPC\u7528\u6237\uff0c\u8981\u4e48\u9700\u8981\u652f\u4ed8\u4ea4\u6613\u8d39\u7528\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u653b\u51fb\u65b9\u6cd5", "method": "\u5229\u7528\u4ea4\u6613\u786e\u8ba4\u65f6\u95f4\u6233\u4e0e\u7528\u6237\u67e5\u8be2\u4ea4\u6613\u72b6\u6001\u65f6TCP\u6570\u636e\u5305\u65f6\u95f4\u6233\u7684\u65f6\u5e8f\u76f8\u5173\u6027\uff0c\u901a\u8fc7\u76d1\u63a7\u7f51\u7edc\u6d41\u91cf\u548c\u5206\u6790\u516c\u5171\u8d26\u672c\uff0c\u5efa\u7acbIP\u5730\u5740\u4e0e\u533a\u5757\u94fe\u5047\u540d\u7684\u5173\u8054", "result": "\u653b\u51fb\u5728\u4ee5\u592a\u574a\u3001\u6bd4\u7279\u5e01\u548cSolana\u7b49\u591a\u79cd\u533a\u5757\u94fe\u7f51\u7edc\u4e0a\u5bf9\u666e\u901aRPC\u7528\u6237\u5b9e\u73b0\u4e86\u8d85\u8fc795%\u7684\u6210\u529f\u7387\uff0c\u4e14\u65e0\u9700\u652f\u4ed8\u4efb\u4f55\u4ea4\u6613\u8d39\u7528", "conclusion": "\u533a\u5757\u94feRPC\u670d\u52a1\u5b58\u5728\u4e25\u91cd\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u63d0\u51fa\u7684\u65f6\u5e8f\u76f8\u5173\u6027\u5206\u6790\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u53bb\u533f\u540d\u5316\u653b\u51fb\uff0c\u63ed\u793a\u4e86\u5f53\u524dRPC\u670d\u52a1\u67b6\u6784\u7684\u9690\u79c1\u7f3a\u9677"}}
{"id": "2508.21811", "categories": ["cs.SE", "68", "D.2.9"], "pdf": "https://arxiv.org/pdf/2508.21811", "abs": "https://arxiv.org/abs/2508.21811", "authors": ["Ashley Hourigan", "Ridewaan Hanslo"], "title": "The Integration of Agile Methodologies in DevOps Practices within the Information Technology Industry", "comment": "10 pages, 2 figures, conference", "summary": "The demand for rapid software delivery in the Information Technology (IT)\nindustry has significantly intensified, emphasising the need for faster\nsoftware products and service releases with enhanced features to meet customer\nexpectations. Agile methodologies are replacing traditional approaches such as\nWaterfall, where flexibility, iterative development and adaptation to change\nare favoured over rigid planning and execution. DevOps, a subsequent evolution\nfrom Agile, emphasises collaborative efforts in development and operations\nteams, focusing on continuous integration and deployment to deliver resilient\nand high-quality software products and services. This study aims to critically\nassess both Agile and DevOps practices in the IT industry to identify the\nfeasibility and applicability of Agile methods in DevOps practices. Eleven\nsemi-structured interviews were conducted with Agile and DevOps practitioners\nin varying capacities across several sectors within the IT industry. Through\nthematic analysis, 51 unique codes were extracted and synthesised into 19\nthemes that reported on each phase of the DevOps lifecycle, specifically\nregarding the integration and implementation of Agile methods into DevOps\npractices. Based on the findings, a new understanding detailing the\ninterrelationship of Agile methods in DevOps practices was discussed that met\nthe research objectives.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc711\u4e2a\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u548c\u4e3b\u9898\u5206\u6790\uff0c\u7814\u7a76\u4e86Agile\u548cDevOps\u5728IT\u884c\u4e1a\u4e2d\u7684\u5b9e\u8df5\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u7406\u89e3\u6a21\u578b\u6765\u8be6\u7ec6\u8bf4\u660e\u4e24\u8005\u7684\u76f8\u4e92\u5173\u7cfb\u3002", "motivation": "IT\u884c\u4e1a\u5bf9\u8f6f\u4ef6\u4ea4\u4ed8\u901f\u5ea6\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0cAgile\u548cDevOps\u65b9\u6cd5\u8bba\u9010\u6e10\u53d6\u4ee3\u4f20\u7edf\u6c34\u6f0f\u6a21\u578b\uff0c\u9700\u8981\u7814\u7a76\u4e24\u8005\u5728\u5b9e\u8df5\u4e2d\u7684\u53ef\u884c\u6027\u548c\u9002\u7528\u6027\u3002", "method": "\u91c7\u752811\u4e2a\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u5bf9\u8c61\u6765\u81eaIT\u884c\u4e1a\u5404\u4e2a\u90e8\u95e8\u7684Agile\u548cDevOps\u5b9e\u8df5\u8005\uff0c\u901a\u8fc7\u4e3b\u9898\u5206\u6790\u63d0\u53d6\u4e8651\u4e2a\u552f\u4e00\u4ee3\u7801\u5e76\u5408\u6210\u4e8619\u4e2a\u4e3b\u9898\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u4e86DevOps\u751f\u547d\u5468\u671f\u5404\u9636\u6bb5\u4e2dAgile\u65b9\u6cd5\u7684\u96c6\u6210\u548c\u5b9e\u65bd\u60c5\u51b5\uff0c\u5f97\u51fa\u4e86\u8be6\u7ec6\u63cf\u8ff0Agile\u65b9\u6cd5\u5728DevOps\u5b9e\u8df5\u4e2d\u76f8\u4e92\u5173\u7cfb\u7684\u65b0\u7406\u89e3\u3002", "conclusion": "\u8bba\u6587\u5b8c\u6210\u4e86\u7814\u7a76\u76ee\u6807\uff0c\u63d0\u4f9b\u4e86\u5173\u4e8eAgile\u65b9\u6cd5\u5982\u4f55\u96c6\u6210\u5230DevOps\u5b9e\u8df5\u4e2d\u7684\u65b0\u89c1\u89e3\uff0c\u5bf9IT\u884c\u4e1a\u7684\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.21517", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21517", "abs": "https://arxiv.org/abs/2508.21517", "authors": ["Sweta Kaman", "Ankita Sharma", "Romi Banerjee"], "title": "Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis", "comment": "total 17 pages, main manuscript 12 pages, supplementary 5 pages, 6\n  tables in main manuscript, 5 figures in main manuscript, 2 tables in\n  supplementary, and 3 figures in supplementary", "summary": "Background: Wisdom is a superordinate construct that embraces perspective\ntaking, reflectiveness, prosocial orientation, reflective empathetic action,\nand intellectual humility. Unlike conventional models of reasoning that are\nrigidly bound by binary thinking, wisdom unfolds in shades of ambiguity,\nrequiring both graded evaluation and self-reflective humility. Current measures\ndepend on self-reports and seldom reflect the humility and uncertainty inherent\nin wise reasoning. A computational framework that takes into account both\nmultidimensionality and confidence has the potential to improve psychological\nscience and allow humane AI. Method: We present a fuzzy inference system with Z\nnumbers, each of the decisions being expressed in terms of a wisdom score\n(restriction) and confidence score (certainty). As part of this study,\nparticipants (N = 100) were exposed to culturally neutral pictorial moral\ndilemma tasks to which they generated think-aloud linguistic responses, which\nwere mapped into five theoretically based components of wisdom. The scores of\neach individual component were combined using a base of 21 rules, with\nmembership functions tuned via Gaussian kernel density estimation. Results: In\na proof of concept study, the system produced dual attribute wisdom\nrepresentations that correlated modestly but significantly with established\nscales while showing negligible relations with unrelated traits, supporting\nconvergent and divergent validity. Contribution: The contribution is to\nformalize wisdom as a multidimensional, uncertainty-conscious construct,\noperationalized in the form of Z-numbers. In addition to progressing\nmeasurement in psychology, it calculates how fuzzy Z numbers can provide AI\nsystems with interpretable, confidence-sensitive reasoning that affords a safe,\nmiddle ground between rigorous computation and human-like judgment.", "AI": {"tldr": "\u4f7f\u7528\u7a0b\u5e8f\u5316\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u548cZ\u6570\u91cf\u6765\u91cf\u5316\u667a\u6167\u7684\u591a\u7ef4\u7279\u5f81\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u56fe\u5f62\u9053\u5fb7\u56f0\u5883\u4efb\u52a1\u6536\u96c6\u53cd\u9988\uff0c\u5f97\u5230\u4e86\u4e0e\u4f20\u7edf\u91cf\u8868\u76f8\u5173\u7684\u53cc\u5c5e\u6027\u667a\u6167\u8868\u5f81", "motivation": "\u73b0\u6709\u667a\u6167\u6d4b\u91cf\u4f9d\u8d56\u81ea\u6211\u62a5\u544a\uff0c\u7f3a\u4e4f\u8c26\u865a\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u8003\u8651\uff0c\u9700\u8981\u4e00\u79cd\u8003\u8651\u591a\u7ef4\u5ea6\u548c\u4fe1\u5fc3\u5ea6\u7684\u8ba1\u7b97\u6846\u67b6\u6765\u6539\u5584\u5fc3\u7406\u5b66\u6d4b\u91cf\u5e76\u652f\u6301\u4eba\u9053\u4e3b\u4e49AI", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8eZ\u6570\u7684\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\uff0c\u6bcf\u4e2a\u51b3\u7b56\u90fd\u7528\u667a\u6167\u5206\u6570\uff08\u9650\u5236\uff09\u548c\u4fe1\u5fc3\u5206\u6570\uff08\u786e\u5b9a\u6027\uff09\u8868\u8fbe\u3002\u901a\u8fc7\u6587\u5316\u4e2d\u7acb\u56fe\u5f62\u9053\u5fb7\u56f0\u5883\u4efb\u52a1\u6536\u96c6100\u540d\u53c2\u4e0e\u8005\u7684\u8bf4\u8bdd\u8bed\u8a00\u53cd\u9988\uff0c\u5c06\u5176\u6620\u5c04\u5230\u667a\u6167\u76845\u4e2a\u7406\u8bba\u7ec4\u6210\u90e8\u5206\uff0c\u4f7f\u752821\u6761\u89c4\u5219\u548c\u9ad8\u65af\u6838\u5bc6\u5ea6\u4f30\u8ba1\u8c03\u6574\u7684\u6210\u5458\u51fd\u6570\u8fdb\u884c\u7efc\u5408", "result": "\u5728\u6982\u5ff5\u9a8c\u8bc1\u7814\u7a76\u4e2d\uff0c\u7cfb\u7edf\u4ea7\u751f\u7684\u53cc\u5c5e\u6027\u667a\u6167\u8868\u5f81\u4e0e\u73b0\u6709\u91cf\u8868\u5f81\u51fa\u73b0\u4e2d\u7b49\u4f46\u663e\u8457\u7684\u76f8\u5173\u6027\uff0c\u4e0e\u65e0\u5173\u7279\u8d28\u7684\u5173\u8054\u53ef\u4ee5\u5ffd\u7565\uff0c\u652f\u6301\u4e86\u6536\u655b\u6548\u5ea6\u548c\u533a\u522b\u6548\u5ea6", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5c06\u667a\u6167\u5f62\u5f0f\u5316\u4e3a\u4e00\u79cd\u8003\u8651\u591a\u7ef4\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u6784\u5ff5\uff0c\u901a\u8fc7Z\u6570\u8fdb\u884c\u64cd\u4f5c\u5316\u3002\u9664\u4e86\u63a8\u8fdb\u5fc3\u7406\u5b66\u6d4b\u91cf\u5916\uff0c\u8fd8\u8ba1\u7b97\u4e86\u6a21\u7ccaZ\u6570\u5982\u4f55\u4e3aAI\u7cfb\u7edf\u63d0\u4f9b\u53ef\u89e3\u91ca\u3001\u654f\u611f\u4fe1\u5fc3\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728\u4e25\u683c\u8ba1\u7b97\u548c\u7c7b\u4eba\u5224\u65ad\u4e4b\u95f4\u627e\u5230\u5b89\u5168\u7684\u4e2d\u95f4\u5730\u5e26"}}
{"id": "2508.21457", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.21457", "abs": "https://arxiv.org/abs/2508.21457", "authors": ["Fengchao Chen", "Tingmin Wu", "Van Nguyen", "Carsten Rudolph"], "title": "SoK: Large Language Model-Generated Textual Phishing Campaigns End-to-End Analysis of Generation, Characteristics, and Detection", "comment": "13 pages, 3 tables, 4 figures", "summary": "Phishing is a pervasive form of social engineering in which attackers\nimpersonate trusted entities to steal information or induce harmful actions.\nText-based phishing dominates for its low cost, scalability, and\nconcealability, advantages recently amplified by large language models (LLMs)\nthat enable ``Phishing-as-a-Service'' attacks at scale within minutes. Despite\nthe growing research into LLM-facilitated phishing attacks, consolidated\nsystematic research on the phishing attack life cycle remains scarce. In this\nwork, we present the first systematization of knowledge (SoK) on LLM-generated\nphishing, offering an end-to-end analysis that spans generation techniques,\nattack features, and mitigation strategies. We introduce\nGeneration-Characterization-Defense (GenCharDef), which systematizes the ways\nin which LLM-generated phishing differs from traditional phishing across\nmethodologies, security perspectives, data dependencies, and evaluation\npractices. This framework highlights unique challenges of LLM-driven phishing,\nproviding a coherent foundation for understanding the evolving threat landscape\nand guiding the design of more resilient defenses.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u5316\u5206\u6790\u4e86LLM\u751f\u6210\u7684\u7f51\u7edc\u9493\u9c7c\u653b\u51fb\uff0c\u63d0\u51fa\u4e86GenCharDef\u6846\u67b6\uff0c\u4ece\u751f\u6210\u6280\u672f\u3001\u653b\u51fb\u7279\u5f81\u5230\u9632\u5fa1\u7b56\u7565\u8fdb\u884c\u7aef\u5230\u7aef\u5206\u6790\uff0c\u63ed\u793a\u4e86LLM\u9493\u9c7c\u4e0e\u4f20\u7edf\u9493\u9c7c\u5728\u65b9\u6cd5\u3001\u5b89\u5168\u89c6\u89d2\u3001\u6570\u636e\u4f9d\u8d56\u548c\u8bc4\u4f30\u5b9e\u8df5\u4e0a\u7684\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u53d1\u5c55\uff0c\u7f51\u7edc\u9493\u9c7c\u653b\u51fb\u53d8\u5f97\u66f4\u52a0\u4f4e\u6210\u672c\u3001\u53ef\u6269\u5c55\u548c\u9690\u853d\uff0c\u51fa\u73b0\u4e86\"\u9493\u9c7c\u5373\u670d\u52a1\"\u7684\u65b0\u578b\u653b\u51fb\u6a21\u5f0f\u3002\u5c3d\u7ba1LLM\u8f85\u52a9\u9493\u9c7c\u653b\u51fb\u7814\u7a76\u589e\u591a\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u9493\u9c7c\u653b\u51fb\u751f\u547d\u5468\u671f\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86Generation-Characterization-Defense (GenCharDef)\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u77e5\u8bc6(SoK)\u65b9\u6cd5\uff0c\u5bf9LLM\u751f\u6210\u7684\u9493\u9c7c\u653b\u51fb\u8fdb\u884c\u7aef\u5230\u7aef\u5206\u6790\uff0c\u6db5\u76d6\u751f\u6210\u6280\u672f\u3001\u653b\u51fb\u7279\u5f81\u548c\u7f13\u89e3\u7b56\u7565\u3002", "result": "\u7cfb\u7edf\u5316\u5730\u8bc6\u522b\u4e86LLM\u751f\u6210\u9493\u9c7c\u4e0e\u4f20\u7edf\u9493\u9c7c\u5728\u65b9\u6cd5\u8bba\u3001\u5b89\u5168\u89c6\u89d2\u3001\u6570\u636e\u4f9d\u8d56\u548c\u8bc4\u4f30\u5b9e\u8df5\u65b9\u9762\u7684\u5173\u952e\u5dee\u5f02\uff0c\u63ed\u793a\u4e86LLM\u9a71\u52a8\u9493\u9c7c\u7684\u72ec\u7279\u6311\u6218\u3002", "conclusion": "GenCharDef\u6846\u67b6\u4e3a\u7406\u89e3\u4e0d\u65ad\u6f14\u53d8\u7684\u5a01\u80c1\u6001\u52bf\u63d0\u4f9b\u4e86\u8fde\u8d2f\u57fa\u7840\uff0c\u5e76\u6307\u5bfc\u8bbe\u8ba1\u66f4\u5177\u5f39\u6027\u7684\u9632\u5fa1\u63aa\u65bd\uff0c\u586b\u8865\u4e86LLM\u751f\u6210\u9493\u9c7c\u7cfb\u7edf\u6027\u7814\u7a76\u7684\u7a7a\u767d\u3002"}}
{"id": "2508.21521", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21521", "abs": "https://arxiv.org/abs/2508.21521", "authors": ["Nicola Gigante", "Francesco Leofante", "Andrea Micheli"], "title": "Counterfactual Scenarios for Automated Planning", "comment": "Accepted at the 22nd International Conference on Principles of\n  Knowledge Representation and Reasoning (KR 2025)", "summary": "Counterfactual Explanations (CEs) are a powerful technique used to explain\nMachine Learning models by showing how the input to a model should be minimally\nchanged for the model to produce a different output. Similar proposals have\nbeen made in the context of Automated Planning, where CEs have been\ncharacterised in terms of minimal modifications to an existing plan that would\nresult in the satisfaction of a different goal. While such explanations may\nhelp diagnose faults and reason about the characteristics of a plan, they fail\nto capture higher-level properties of the problem being solved. To address this\nlimitation, we propose a novel explanation paradigm that is based on\ncounterfactual scenarios. In particular, given a planning problem $P$ and an\n\\ltlf formula $\\psi$ defining desired properties of a plan, counterfactual\nscenarios identify minimal modifications to $P$ such that it admits plans that\ncomply with $\\psi$. In this paper, we present two qualitative instantiations of\ncounterfactual scenarios based on an explicit quantification over plans that\nmust satisfy $\\psi$. We then characterise the computational complexity of\ngenerating such counterfactual scenarios when different types of changes are\nallowed on $P$. We show that producing counterfactual scenarios is often only\nas expensive as computing a plan for $P$, thus demonstrating the practical\nviability of our proposal and ultimately providing a framework to construct\npractical algorithms in this area.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u573a\u666f\u7684\u65b0\u578b\u89e3\u91ca\u8303\u5f0f\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u4fee\u6539\u89c4\u5212\u95ee\u9898\u6765\u6ee1\u8db3\u671f\u671b\u5c5e\u6027\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0e\u89c4\u5212\u6c42\u89e3\u76f8\u5f53\uff0c\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\u3002", "motivation": "\u4f20\u7edf\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5728\u81ea\u52a8\u89c4\u5212\u4e2d\u4ec5\u5173\u6ce8\u73b0\u6709\u8ba1\u5212\u7684\u5fae\u5c0f\u4fee\u6539\uff0c\u65e0\u6cd5\u6355\u6349\u95ee\u9898\u7684\u9ad8\u5c42\u7279\u6027\uff0c\u9700\u8981\u65b0\u7684\u89e3\u91ca\u65b9\u6cd5\u6765\u8bca\u65ad\u6545\u969c\u548c\u63a8\u7406\u89c4\u5212\u7279\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u573a\u666f\u7684\u89e3\u91ca\u8303\u5f0f\uff0c\u7ed9\u5b9a\u89c4\u5212\u95ee\u9898\u548cLTLf\u516c\u5f0f\u5b9a\u4e49\u671f\u671b\u5c5e\u6027\uff0c\u8bc6\u522b\u5bf9\u95ee\u9898\u7684\u6700\u5c0f\u4fee\u6539\u4ee5\u4f7f\u89c4\u5212\u6ee1\u8db3\u5c5e\u6027\u3002\u63d0\u4f9b\u4e86\u4e24\u79cd\u57fa\u4e8e\u663e\u5f0f\u91cf\u5316\u6ee1\u8db3\u5c5e\u6027\u89c4\u5212\u7684\u5177\u4f53\u5b9e\u73b0\u3002", "result": "\u5206\u6790\u4e86\u5141\u8bb8\u4e0d\u540c\u7c7b\u578b\u4fee\u6539\u65f6\u751f\u6210\u53cd\u4e8b\u5b9e\u573a\u666f\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u8bc1\u660e\u5176\u901a\u5e38\u4e0e\u8ba1\u7b97\u89c4\u5212\u95ee\u9898\u7684\u89e3\u540c\u6837\u9ad8\u6548\u3002", "conclusion": "\u53cd\u4e8b\u5b9e\u573a\u666f\u89e3\u91ca\u6846\u67b6\u4e3a\u6784\u5efa\u5b9e\u7528\u7b97\u6cd5\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u53ef\u63a7\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u591f\u6709\u6548\u89e3\u91ca\u89c4\u5212\u95ee\u9898\u7684\u9ad8\u5c42\u7279\u6027\u3002"}}
{"id": "2508.21480", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2508.21480", "abs": "https://arxiv.org/abs/2508.21480", "authors": ["Narges Dadkhah", "Khan Reaz", "Gerhard Wunder"], "title": "Towards a Decentralized IoT Onboarding for Smart Homes Using Consortium Blockchain", "comment": null, "summary": "The increasing adoption of smart home devices and IoT-based security systems\npresents significant opportunities to enhance convenience, safety, and risk\nmanagement for homeowners and service providers. However, secure\nonboarding-provisioning credentials and establishing trust with cloud\nplatforms-remains a considerable challenge. Traditional onboarding methods\noften rely on centralized Public Key Infrastructure (PKI) models and\nmanufacturer-controlled keys, which introduce security risks and limit the\nuser's digital sovereignty. These limitations hinder the widespread deployment\nof scalable IoT solutions. This paper presents a novel onboarding framework\nthat builds upon existing network-layer onboarding techniques and extends them\nto the application layer to address these challenges. By integrating consortium\nblockchain technology, we propose a decentralized onboarding mechanism that\nenhances transparency, security, and monitoring for smart home architectures.\nThe architecture supports device registration, key revocation, access control\nmanagement, and risk detection through event-driven alerts across dedicated\nblockchain channels and smart contracts. To evaluate the framework, we formally\nmodel the protocol using the Tamarin Prover under the Dolev-Yao adversary\nmodel. The analysis focuses on authentication, token integrity, key\nconfidentiality, and resilience over public channels. A prototype\nimplementation demonstrates the system's viability in smart home settings, with\nverification completing in 0.34 seconds, highlighting its scalability and\nsuitability for constrained devices and diverse stakeholders. Additionally,\nperformance evaluation shows that the blockchain-based approach effectively\nhandles varying workloads, maintains high throughput and low latency, and\nsupports near real-time IoT data processing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8054\u76df\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u667a\u80fd\u5bb6\u5ead\u8bbe\u5907\u5165\u7f51\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edfPKI\u6a21\u578b\u7684\u5b89\u5168\u98ce\u9669\u548c\u7528\u6237\u4e3b\u6743\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u667a\u80fd\u5bb6\u5ead\u548cIoT\u5b89\u5168\u7cfb\u7edf\u7684\u666e\u53ca\u5e26\u6765\u4e86\u4fbf\u6377\u6027\u548c\u5b89\u5168\u6027\u63d0\u5347\u7684\u673a\u9047\uff0c\u4f46\u4f20\u7edf\u7684\u8bbe\u5907\u5165\u7f51\u65b9\u6cd5\u5b58\u5728\u5b89\u5168\u98ce\u9669\u548c\u7528\u6237\u4e3b\u6743\u9650\u5236\u95ee\u9898\uff0c\u9650\u5236\u4e86IoT\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u6269\u5c55\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5165\u7f51\u6846\u67b6\uff0c\u57fa\u4e8e\u73b0\u6709\u7f51\u7edc\u5c42\u5165\u7f51\u6280\u672f\u5e76\u6269\u5c55\u5230\u5e94\u7528\u5c42\uff0c\u96c6\u6210\u8054\u76df\u533a\u5757\u94fe\u6280\u672f\u5b9e\u73b0\u53bb\u4e2d\u5fc3\u5316\u5165\u7f51\u673a\u5236\uff0c\u652f\u6301\u8bbe\u5907\u6ce8\u518c\u3001\u5bc6\u94a5\u64a4\u9500\u3001\u8bbf\u95ee\u63a7\u5236\u7ba1\u7406\u548c\u98ce\u9669\u68c0\u6d4b\u7b49\u529f\u80fd\u3002", "result": "\u4f7f\u7528Tamarin Prover\u8fdb\u884c\u6b63\u5f0f\u6a21\u578b\u9a8c\u8bc1\uff0c\u8bc1\u660e\u534f\u8bae\u5177\u6709\u8ba4\u8bc1\u3001\u4ee4\u724c\u5b8c\u6574\u6027\u3001\u5bc6\u94a5\u4fdd\u5bc6\u6027\u548c\u516c\u5171\u901a\u9053\u5f39\u6027\u3002\u539f\u578b\u5b9e\u73b0\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u53ef\u884c\u6027\uff0c\u9a8c\u8bc1\u65f6\u95f4\u4ec50.34\u79d2\uff0c\u663e\u793a\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002\u6027\u80fd\u8bc4\u4f30\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8377\uff0c\u4fdd\u6301\u9ad8\u541e\u541e\u91cf\u3001\u4f4e\u5ef6\u8fdf\uff0c\u652f\u6301\u8fd1\u5b9e\u65f6IoT\u6570\u636e\u5904\u7406\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u5165\u7f51\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u667a\u80fd\u5bb6\u5ead\u8bbe\u5907\u5165\u7f51\u7684\u5b89\u5168\u6027\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e3aIoT\u5e73\u53f0\u63d0\u4f9b\u4e86\u66f4\u900f\u660e\u3001\u5b89\u5168\u7684\u4fe1\u4efb\u5efa\u7acb\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.21540", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21540", "abs": "https://arxiv.org/abs/2508.21540", "authors": ["Eduardo Illueca-Fernandez", "Kaile Chen", "Fernando Seoane", "Farhad Abtahi"], "title": "HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining", "comment": null, "summary": "Process mining has emerged as a powerful analytical technique for\nunderstanding complex healthcare workflows. However, its application faces\nsignificant barriers, including technical complexity, a lack of standardized\napproaches, and limited access to practical training resources. We introduce\nHealthProcessAI, a GenAI framework designed to simplify process mining\napplications in healthcare and epidemiology by providing a comprehensive\nwrapper around existing Python (PM4PY) and R (bupaR) libraries. To address\nunfamiliarity and improve accessibility, the framework integrates multiple\nLarge Language Models (LLMs) for automated process map interpretation and\nreport generation, helping translate technical analyses into outputs that\ndiverse users can readily understand. We validated the framework using sepsis\nprogression data as a proof-of-concept example and compared the outputs of five\nstate-of-the-art LLM models through the OpenRouter platform. To test its\nfunctionality, the framework successfully processed sepsis data across four\nproof-of-concept scenarios, demonstrating robust technical performance and its\ncapability to generate reports through automated LLM analysis. LLM evaluation\nusing five independent LLMs as automated evaluators revealed distinct model\nstrengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency\nscores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By\nintegrating multiple Large Language Models (LLMs) for automated interpretation\nand report generation, the framework addresses widespread unfamiliarity with\nprocess mining outputs, making them more accessible to clinicians, data\nscientists, and researchers. This structured analytics and AI-driven\ninterpretation combination represents a novel methodological advance in\ntranslating complex process mining results into potentially actionable insights\nfor healthcare applications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86HealthProcessAI\u6846\u67b6\uff0c\u5229\u7528\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u7b80\u5316\u533b\u7597\u5065\u5eb7\u9886\u57df\u7684\u8fc7\u7a0b\u6316\u6398\u5e94\u7528\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u8bed\u4e49\u89e3\u91ca\u548c\u62a5\u544a\u751f\u6210\u63d0\u9ad8\u53ef\u8bbf\u95ee\u6027\u3002", "motivation": "\u533b\u7597\u5065\u5eb7\u9886\u57df\u8fc7\u7a0b\u6316\u6398\u5e94\u7528\u9762\u4e34\u6280\u672f\u590d\u6742\u6027\u3001\u65e0\u6807\u51c6\u5316\u65b9\u6cd5\u548c\u8bad\u7ec3\u8d44\u6e90\u7f3a\u4e4f\u7b49\u969c\u788d\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6613\u4e8e\u8bbf\u95ee\u548c\u4f7f\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1HealthProcessAI\u6846\u67b6\uff0c\u5305\u88c5\u73b0\u6709Python(PM4PY)\u548cR(bupaR)\u5e93\uff0c\u96c6\u6210\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u81ea\u52a8\u5316\u8fc7\u7a0b\u56fe\u89e3\u91ca\u548c\u62a5\u544a\u751f\u6210\uff0c\u4f7f\u7528\u80f1\u8840\u75c5\u8fdb\u5c55\u6570\u636e\u9a8c\u8bc1\u6846\u67b6\u529f\u80fd\u3002", "result": "\u6846\u67b6\u6210\u529f\u5904\u7406\u56db\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u573a\u666f\u7684\u80f1\u8840\u75c5\u6570\u636e\uff0cClaude Sonnet-4\u548cGemini 2.5-Pro\u83b7\u5f97\u6700\u9ad8\u4e00\u81f4\u6027\u5206\u6570(3.79/4.0\u548c3.65/4.0)\uff0c\u663e\u793a\u4e86\u6a21\u578b\u7684\u4e0d\u540c\u4f18\u52bf\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u5316\u5206\u6790\u548cAI\u9a71\u52a8\u89e3\u91ca\uff0c\u4ee3\u8868\u4e86\u5c06\u590d\u6742\u8fc7\u7a0b\u6316\u6398\u7ed3\u679c\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u89c1\u89e3\u7684\u65b0\u65b9\u6cd5\u8fdb\u6b65\u3002"}}
{"id": "2508.21558", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2508.21558", "abs": "https://arxiv.org/abs/2508.21558", "authors": ["Federica Bianchi", "Edoardo Di Paolo", "Angelo Spognardi"], "title": "Generalized Encrypted Traffic Classification Using Inter-Flow Signals", "comment": "Accepted manuscript at Availability, Reliability and Security (ARES\n  2025), published in Lecture Notes in Computer Science, vol. 15992, Springer,\n  Cham. DOI: https://doi.org/10.1007/978-3-032-00624-0_11", "summary": "In this paper, we present a novel encrypted traffic classification model that\noperates directly on raw PCAP data without requiring prior assumptions about\ntraffic type. Unlike existing methods, it is generalizable across multiple\nclassification tasks and leverages inter-flow signals - an innovative\nrepresentation that captures temporal correlations and packet volume\ndistributions across flows. Experimental results show that our model\noutperforms well-established methods in nearly every classification task and\nacross most datasets, achieving up to 99% accuracy in some cases, demonstrating\nits robustness and adaptability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u539f\u59cbPCAP\u6570\u636e\u7684\u52a0\u5bc6\u6d41\u91cf\u5206\u7c7b\u6a21\u578b\uff0c\u5229\u7528\u521b\u65b0\u7684\u8de8\u6d41\u4fe1\u53f7\u8868\u793a\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u5206\u7c7b\u4efb\u52a1\u548c\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u6700\u9ad8\u53ef\u8fbe99%", "motivation": "\u73b0\u6709\u52a0\u5bc6\u6d41\u91cf\u5206\u7c7b\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u5148\u9a8c\u5047\u8bbe\u4e14\u7f3a\u4e4f\u901a\u7528\u6027\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u5047\u8bbe\u3001\u53ef\u8de8\u4efb\u52a1\u901a\u7528\u7684\u5206\u7c7b\u6a21\u578b", "method": "\u76f4\u63a5\u5728\u539f\u59cbPCAP\u6570\u636e\u4e0a\u64cd\u4f5c\uff0c\u5229\u7528\u8de8\u6d41\u4fe1\u53f7\u8868\u793a\u65b9\u6cd5\u6355\u83b7\u6d41\u95f4\u65f6\u95f4\u76f8\u5173\u6027\u548c\u6570\u636e\u5305\u91cf\u5206\u5e03\u7279\u5f81", "result": "\u5728\u51e0\u4e4e\u6240\u6709\u5206\u7c7b\u4efb\u52a1\u548c\u5927\u591a\u6570\u6570\u636e\u96c6\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u6210\u719f\u65b9\u6cd5\uff0c\u90e8\u5206\u60c5\u51b5\u4e0b\u51c6\u786e\u7387\u8fbe\u523099%", "conclusion": "\u8be5\u6a21\u578b\u5c55\u73b0\u4e86\u51fa\u8272\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u4e3a\u52a0\u5bc6\u6d41\u91cf\u5206\u7c7b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u901a\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.21564", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21564", "abs": "https://arxiv.org/abs/2508.21564", "authors": ["Issa Hanou", "Sebastijan Duman\u010di\u0107", "Mathijs de Weerdt"], "title": "Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances", "comment": null, "summary": "We propose a new framework for discovering landmarks that automatically\ngeneralize across a domain. These generalized landmarks are learned from a set\nof solved instances and describe intermediate goals for planning problems where\ntraditional landmark extraction algorithms fall short. Our generalized\nlandmarks extend beyond the predicates of a domain by using state functions\nthat are independent of the objects of a specific problem and apply to all\nsimilar objects, thus capturing repetition. Based on these functions, we\nconstruct a directed generalized landmark graph that defines the landmark\nprogression, including loop possibilities for repetitive subplans. We show how\nto use this graph in a heuristic to solve new problem instances of the same\ndomain. Our results show that the generalized landmark graphs learned from a\nfew small instances are also effective for larger instances in the same domain.\nIf a loop that indicates repetition is identified, we see a significant\nimprovement in heuristic performance over the baseline. Generalized landmarks\ncapture domain information that is interpretable and useful to an automated\nplanner. This information can be discovered from a small set of plans for the\nsame domain.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53d1\u73b0\u8de8\u9886\u57df\u901a\u7528\u5730\u6807\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u5df2\u89e3\u51b3\u5b9e\u4f8b\u81ea\u52a8\u751f\u6210\u4e2d\u95f4\u76ee\u6807\uff0c\u7528\u4e8e\u4f20\u7edf\u5730\u6807\u63d0\u53d6\u7b97\u6cd5\u96be\u4ee5\u5904\u7406\u7684\u89c4\u5212\u95ee\u9898", "motivation": "\u4f20\u7edf\u5730\u6807\u63d0\u53d6\u7b97\u6cd5\u5728\u5904\u7406\u5177\u6709\u91cd\u590d\u6027\u5b50\u8ba1\u5212\u7684\u89c4\u5212\u95ee\u9898\u65f6\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6355\u6349\u9886\u57df\u91cd\u590d\u6027\u6a21\u5f0f\u5e76\u81ea\u52a8\u6cdb\u5316\u7684\u65b9\u6cd5", "method": "\u4f7f\u7528\u72ec\u7acb\u4e8e\u5177\u4f53\u95ee\u9898\u5bf9\u8c61\u7684\u72b6\u6001\u51fd\u6570\u6784\u5efa\u6709\u5411\u901a\u7528\u5730\u6807\u56fe\uff0c\u5305\u62ec\u5faa\u73af\u53ef\u80fd\u6027\u6765\u8868\u793a\u91cd\u590d\u6027\u5b50\u8ba1\u5212\uff0c\u5e76\u57fa\u4e8e\u6b64\u56fe\u8bbe\u8ba1\u542f\u53d1\u5f0f\u7b97\u6cd5", "result": "\u4ece\u5c11\u91cf\u5c0f\u5b9e\u4f8b\u5b66\u4e60\u5230\u7684\u901a\u7528\u5730\u6807\u56fe\u5bf9\u540c\u4e00\u9886\u57df\u7684\u5927\u5b9e\u4f8b\u540c\u6837\u6709\u6548\uff0c\u5f53\u8bc6\u522b\u5230\u8868\u793a\u91cd\u590d\u7684\u5faa\u73af\u65f6\uff0c\u542f\u53d1\u5f0f\u6027\u80fd\u76f8\u6bd4\u57fa\u7ebf\u6709\u663e\u8457\u63d0\u5347", "conclusion": "\u901a\u7528\u5730\u6807\u80fd\u591f\u6355\u6349\u53ef\u89e3\u91ca\u4e14\u5bf9\u81ea\u52a8\u89c4\u5212\u5668\u6709\u7528\u7684\u9886\u57df\u4fe1\u606f\uff0c\u8fd9\u4e9b\u4fe1\u606f\u53ef\u4ee5\u4ece\u540c\u4e00\u9886\u57df\u7684\u5c0f\u89c4\u6a21\u8ba1\u5212\u96c6\u4e2d\u81ea\u52a8\u53d1\u73b0"}}
{"id": "2508.21579", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.21579", "abs": "https://arxiv.org/abs/2508.21579", "authors": ["Ziyue Wang", "Liyi Zhou"], "title": "Agentic Discovery and Validation of Android App Vulnerabilities", "comment": null, "summary": "Existing Android vulnerability detection tools overwhelm teams with thousands\nof low-signal warnings yet uncover few true positives. Analysts spend days\ntriaging these results, creating a bottleneck in the security pipeline.\nMeanwhile, genuinely exploitable vulnerabilities often slip through, leaving\nopportunities open to malicious counterparts.\n  We introduce A2, a system that mirrors how security experts analyze and\nvalidate Android vulnerabilities through two complementary phases: (i) Agentic\nVulnerability Discovery, which reasons about application security by combining\nsemantic understanding with traditional security tools; and (ii) Agentic\nVulnerability Validation, which systematically validates vulnerabilities across\nAndroid's multi-modal attack surface-UI interactions, inter-component\ncommunication, file system operations, and cryptographic computations.\n  On the Ghera benchmark (n=60), A2 achieves 78.3% coverage, surpassing\nstate-of-the-art analyzers (e.g., APKHunt 30.0%). Rather than overwhelming\nanalysts with thousands of warnings, A2 distills results into 82 speculative\nvulnerability findings, including 47 Ghera cases and 28 additional true\npositives. Crucially, A2 then generates working Proof-of-Concepts (PoCs) for 51\nof these speculative findings, transforming them into validated vulnerability\nfindings that provide direct, self-confirming evidence of exploitability.\n  In real-world evaluation on 169 production APKs, A2 uncovers 104\ntrue-positive zero-day vulnerabilities. Among these, 57 (54.8%) are\nself-validated with automatically generated PoCs, including a medium-severity\nvulnerability in a widely used application with over 10 million installs.", "AI": {"tldr": "A2\u7cfb\u7edf\u901a\u8fc7\u667a\u80fd\u4ee3\u7406\u65b9\u5f0f\u53d1\u73b0\u548c\u9a8c\u8bc1Android\u6f0f\u6d1e\uff0c\u663e\u8457\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\u5e76\u81ea\u52a8\u751f\u6210\u6f0f\u6d1e\u5229\u7528\u8bc1\u660e\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523078.3%\u8986\u76d6\u7387\uff0c\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u53d1\u73b0\u4e86104\u4e2a\u96f6\u65e5\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709Android\u6f0f\u6d1e\u68c0\u6d4b\u5de5\u5177\u4ea7\u751f\u5927\u91cf\u4f4e\u4ef7\u503c\u8b66\u544a\uff0c\u5206\u6790\u5e08\u9700\u8981\u82b1\u8d39\u5927\u91cf\u65f6\u95f4\u7b5b\u9009\uff0c\u800c\u771f\u6b63\u53ef\u5229\u7528\u7684\u6f0f\u6d1e\u5f80\u5f80\u88ab\u9057\u6f0f\uff0c\u9020\u6210\u5b89\u5168\u74f6\u9888\u3002", "method": "\u91c7\u7528\u53cc\u9636\u6bb5\u65b9\u6cd5\uff1a(i)\u667a\u80fd\u6f0f\u6d1e\u53d1\u73b0-\u7ed3\u5408\u8bed\u4e49\u7406\u89e3\u548c\u4f20\u7edf\u5b89\u5168\u5de5\u5177\u5206\u6790\u5e94\u7528\u5b89\u5168\uff1b(ii)\u667a\u80fd\u6f0f\u6d1e\u9a8c\u8bc1-\u7cfb\u7edf\u6027\u5730\u9a8c\u8bc1Android\u591a\u6a21\u6001\u653b\u51fb\u9762\uff08UI\u4ea4\u4e92\u3001\u7ec4\u4ef6\u901a\u4fe1\u3001\u6587\u4ef6\u64cd\u4f5c\u3001\u5bc6\u7801\u8ba1\u7b97\u7b49\uff09\u7684\u6f0f\u6d1e\u3002", "result": "\u5728Ghera\u57fa\u51c6\u6d4b\u8bd5(n=60)\u4e2d\u8fbe\u523078.3%\u8986\u76d6\u7387\uff0c\u8fdc\u8d85\u73b0\u6709\u6700\u4f73\u5206\u6790\u5668(APKHunt 30.0%)\uff1b\u751f\u621082\u4e2a\u63a8\u6d4b\u6027\u6f0f\u6d1e\u53d1\u73b0\uff0c\u5176\u4e2d51\u4e2a\u751f\u6210\u6709\u6548PoC\u8bc1\u660e\uff1b\u5728169\u4e2a\u751f\u4ea7APK\u4e2d\u53d1\u73b0104\u4e2a\u96f6\u65e5\u6f0f\u6d1e\uff0c54.8%\u81ea\u52a8\u751f\u6210PoC\u9a8c\u8bc1\u3002", "conclusion": "A2\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u51cf\u5c11\u8bef\u62a5\uff0c\u63d0\u9ad8\u6f0f\u6d1e\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u751f\u6210PoC\u8bc1\u660e\u6f0f\u6d1e\u53ef\u5229\u7528\u6027\uff0c\u663e\u8457\u63d0\u5347Android\u5e94\u7528\u5b89\u5168\u5206\u6790\u7684\u6548\u7387\u548c\u6548\u679c\u3002"}}
{"id": "2508.21595", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21595", "abs": "https://arxiv.org/abs/2508.21595", "authors": ["Yang You", "Alex Schutz", "Zhikun Li", "Bruno Lacerda", "Robert Skilton", "Nick Hawes"], "title": "Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics", "comment": null, "summary": "Many high-level multi-agent planning problems, including multi-robot\nnavigation and path planning, can be effectively modeled using deterministic\nactions and observations.\n  In this work, we focus on such domains and introduce the class of\nDeterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of\nDec-POMDPs characterized by deterministic transitions and observations\nconditioned on the state and joint actions.\n  We then propose a practical solver called Iterative Deterministic POMDP\nPlanning (IDPP). This method builds on the classic Joint Equilibrium Search for\nPolicies framework and is specifically optimized to handle large-scale\nDet-Dec-POMDPs that current Dec-POMDP solvers are unable to address\nefficiently.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u786e\u5b9a\u6027\u5206\u5e03\u5f0f\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08Det-Dec-POMDPs\uff09\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u53ef\u5904\u7406\u5927\u89c4\u6a21\u95ee\u9898\u7684\u8fed\u4ee3\u6c42\u89e3\u7b97\u6cd5IDPP\u3002", "motivation": "\u591a\u673a\u5668\u4eba\u5bfc\u822a\u7b49\u9ad8\u7ea7\u591a\u4ee3\u7406\u89c4\u5212\u95ee\u9898\u901a\u5e38\u53ef\u4ee5\u901a\u8fc7\u786e\u5b9a\u6027\u52a8\u4f5c\u548c\u89c2\u6d4b\u6765\u6709\u6548\u6a21\u578b\uff0c\u4f46\u73b0\u6709\u7684Dec-POMDP\u6c42\u89e3\u5668\u5728\u5904\u7406\u5927\u89c4\u6a21\u95ee\u9898\u65f6\u6548\u7387\u4e0d\u9ad8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53eb\u8fed\u4ee3\u786e\u5b9a\u6027POMDP\u89c4\u5212\uff08IDPP\uff09\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u7ecf\u5178\u7684\u8054\u5408\u5747\u8861\u641c\u7d22\u7b56\u7565\u6846\u67b6\uff0c\u5e76\u4e13\u95e8\u4e3a\u5904\u7406\u5927\u89c4\u6a21Det-Dec-POMDP\u95ee\u9898\u8fdb\u884c\u4e86\u4f18\u5316\u3002", "result": "IDPP\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u5f53\u524dDec-POMDP\u6c42\u89e3\u5668\u65e0\u6cd5\u9ad8\u6548\u5904\u7406\u7684\u5927\u89c4\u6a21Det-Dec-POMDP\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u786e\u5b9a\u6027\u591a\u4ee3\u7406\u89c4\u5212\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0cIDPP\u7b97\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u95ee\u9898\u65f6\u663e\u793a\u51fa\u4e86\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.21602", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.21602", "abs": "https://arxiv.org/abs/2508.21602", "authors": ["Tomasz Kazana"], "title": "Condense to Conduct and Conduct to Condense", "comment": null, "summary": "In this paper we give the first examples of low-conductance permutations. The\nnotion of conductance of permutations was introduced in the paper\n\"Indifferentiability of Confusion-Diffusion Networks\" by Dodis et al., where\nthe search for low-conductance permutations was initiated and motivated. In\nthis paper we not only give the desired examples, but also make a general\ncharacterization of the problem -- i.e. we show that low-conductance\npermutations are equivalent to permutations that have the information-theoretic\nproperties of the so-called Multi-Source-Somewhere-Condensers.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u6784\u5efa\u4e86\u4f4e\u7535\u5bfc\u5ea6\u7f6e\u6362\u7684\u4f8b\u5b50\uff0c\u5e76\u8bc1\u660e\u4e86\u4f4e\u7535\u5bfc\u5ea6\u7f6e\u6362\u4e0e\u591a\u6e90\u67d0\u5904\u538b\u7f29\u5668\u5728\u4fe1\u606f\u8bba\u7279\u6027\u4e0a\u7684\u7b49\u4ef7\u6027", "motivation": "Dodis\u7b49\u4eba\u5148\u524d\u63d0\u51fa\u4e86\u7f6e\u6362\u7535\u5bfc\u5ea6\u7684\u6982\u5ff5\u5e76\u5f00\u59cb\u5bfb\u627e\u4f4e\u7535\u5bfc\u5ea6\u7f6e\u6362\uff0c\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u5177\u4f53\u5b9e\u4f8b\u5e76\u5efa\u7acb\u4e00\u822c\u6027\u7406\u8bba\u7279\u5f81", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6784\u9020\u6027\u8bc1\u660e\uff0c\u5c55\u793a\u4e86\u4f4e\u7535\u5bfc\u5ea6\u7f6e\u6362\u4e0e\u591a\u6e90\u67d0\u5904\u538b\u7f29\u5668\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb", "result": "\u6210\u529f\u6784\u5efa\u4e86\u9996\u4e2a\u4f4e\u7535\u5bfc\u5ea6\u7f6e\u6362\u5b9e\u4f8b\uff0c\u5e76\u5efa\u7acb\u4e86\u8be5\u95ee\u9898\u7684\u5b8c\u6574\u7406\u8bba\u7279\u5f81", "conclusion": "\u4f4e\u7535\u5bfc\u5ea6\u7f6e\u6362\u7684\u5b58\u5728\u6027\u5f97\u5230\u8bc1\u660e\uff0c\u4e14\u5176\u4e0e\u591a\u6e90\u67d0\u5904\u538b\u7f29\u5668\u5728\u4fe1\u606f\u8bba\u5c42\u9762\u5177\u6709\u7b49\u4ef7\u6027\uff0c\u4e3a\u5bc6\u7801\u5b66\u4e2d\u7684\u6df7\u6dc6-\u6269\u6563\u7f51\u7edc\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u57fa\u7840"}}
{"id": "2508.21636", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.21636", "abs": "https://arxiv.org/abs/2508.21636", "authors": ["Cristina Improta"], "title": "Detecting Stealthy Data Poisoning Attacks in AI Code Generators", "comment": "Accepted to the 3rd IEEE International Workshop on Reliable and\n  Secure AI for Software Engineering (ReSAISE, 2025), co-located with ISSRE\n  2025", "summary": "Deep learning (DL) models for natural language-to-code generation have become\nintegral to modern software development pipelines. However, their heavy\nreliance on large amounts of data, often collected from unsanitized online\nsources, exposes them to data poisoning attacks, where adversaries inject\nmalicious samples to subtly bias model behavior. Recent targeted attacks\nsilently replace secure code with semantically equivalent but vulnerable\nimplementations without relying on explicit triggers to launch the attack,\nmaking it especially hard for detection methods to distinguish clean from\npoisoned samples. We present a systematic study on the effectiveness of\nexisting poisoning detection methods under this stealthy threat model.\nSpecifically, we perform targeted poisoning on three DL models (CodeBERT,\nCodeT5+, AST-T5), and evaluate spectral signatures analysis, activation\nclustering, and static analysis as defenses. Our results show that all methods\nstruggle to detect triggerless poisoning, with representation-based approaches\nfailing to isolate poisoned samples and static analysis suffering false\npositives and false negatives, highlighting the need for more robust,\ntrigger-independent defenses for AI-assisted code generation.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u73b0\u6709\u6570\u636e\u6295\u6bd2\u68c0\u6d4b\u65b9\u6cd5\u5728\u65e0\u89e6\u53d1\u5668\u7684\u9690\u853d\u653b\u51fb\u6a21\u578b\u4e0b\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u68c0\u6d4b\u9488\u5bf9\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u9690\u5f62\u6295\u6bd2\u653b\u51fb\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u4ee3\u7801\u751f\u6210\u6a21\u578b\u4f9d\u8d56\u5927\u91cf\u7f51\u7edc\u6570\u636e\uff0c\u5bb9\u6613\u906d\u53d7\u6570\u636e\u6295\u6bd2\u653b\u51fb\u3002\u8fd1\u671f\u51fa\u73b0\u7684\u65e0\u89e6\u53d1\u5668\u653b\u51fb\u80fd\u591f\u6084\u65e0\u58f0\u606f\u5730\u5c06\u5b89\u5168\u4ee3\u7801\u66ff\u6362\u4e3a\u8bed\u4e49\u7b49\u6548\u4f46\u5b58\u5728\u6f0f\u6d1e\u7684\u5b9e\u73b0\uff0c\u4f7f\u5f97\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u533a\u5206\u5e72\u51c0\u6837\u672c\u548c\u6295\u6bd2\u6837\u672c", "method": "\u5bf9\u4e09\u4e2a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08CodeBERT\u3001CodeT5+\u3001AST-T5\uff09\u8fdb\u884c\u9488\u5bf9\u6027\u6295\u6bd2\u653b\u51fb\uff0c\u8bc4\u4f30\u9891\u8c31\u7b7e\u540d\u5206\u6790\u3001\u6fc0\u6d3b\u805a\u7c7b\u548c\u9759\u6001\u5206\u6790\u4e09\u79cd\u9632\u5fa1\u65b9\u6cd5\u7684\u6709\u6548\u6027", "result": "\u6240\u6709\u68c0\u6d4b\u65b9\u6cd5\u5728\u68c0\u6d4b\u65e0\u89e6\u53d1\u5668\u6295\u6bd2\u65b9\u9762\u90fd\u8868\u73b0\u4e0d\u4f73\uff1a\u57fa\u4e8e\u8868\u793a\u7684\u65b9\u6cd5\u65e0\u6cd5\u9694\u79bb\u6295\u6bd2\u6837\u672c\uff0c\u9759\u6001\u5206\u6790\u5b58\u5728\u5047\u9633\u6027\u548c\u5047\u9634\u6027\u95ee\u9898", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u9700\u8981\u4e3aAI\u8f85\u52a9\u4ee3\u7801\u751f\u6210\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u4e0d\u4f9d\u8d56\u89e6\u53d1\u5668\u7684\u9632\u5fa1\u673a\u5236\uff0c\u4ee5\u5e94\u5bf9\u8fd9\u79cd\u9690\u853d\u5a01\u80c1\u6a21\u578b"}}
{"id": "2508.21622", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21622", "abs": "https://arxiv.org/abs/2508.21622", "authors": ["Saravanan Venkatachalam"], "title": "Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study", "comment": null, "summary": "This paper presents an integrated framework that combines traditional network\noptimization models with large language models (LLMs) to deliver interactive,\nexplainable, and role-aware decision support for supply chain planning. The\nproposed system bridges the gap between complex operations research outputs and\nbusiness stakeholder understanding by generating natural language summaries,\ncontextual visualizations, and tailored key performance indicators (KPIs). The\ncore optimization model addresses tactical inventory redistribution across a\nnetwork of distribution centers for multi-period and multi-item, using a\nmixed-integer formulation. The technical architecture incorporates AI agents,\nRESTful APIs, and a dynamic user interface to support real-time interaction,\nconfiguration updates, and simulation-based insights. A case study demonstrates\nhow the system improves planning outcomes by preventing stockouts, reducing\ncosts, and maintaining service levels. Future extensions include integrating\nprivate LLMs, transfer learning, reinforcement learning, and Bayesian neural\nnetworks to enhance explainability, adaptability, and real-time\ndecision-making.", "AI": {"tldr": "\u6574\u5408\u7f51\u7edc\u4f18\u5316\u6a21\u578b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ea4\u4e92\u5f0f\u4f9b\u5e94\u94fe\u89c4\u5212\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u548c\u89d2\u8272\u611f\u77e5\u7684\u51b3\u7b56\u5e2e\u52a9\u3002", "motivation": "\u7f29\u5c0f\u64cd\u4f5c\u7814\u7a76\u8f93\u51fa\u4e0e\u4e1a\u52a1\u5229\u76ca\u76f8\u5173\u8005\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6458\u8981\u3001\u4e0a\u4e0b\u6587\u53ef\u89c6\u5316\u548c\u5b9a\u5236KPI\u63d0\u5347\u51b3\u7b56\u53ef\u8bbf\u95ee\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6574\u6570\u89c4\u5212\u6a21\u578b\u5904\u7406\u591a\u5468\u671f\u591a\u7269\u54c1\u7684\u6218\u672f\u6027\u5e93\u5b58\u91cd\u65b0\u5206\u914d\uff0c\u901a\u8fc7AI\u4ee3\u7406\u3001RESTful API\u548c\u52a8\u6001\u7528\u6237\u754c\u9762\u652f\u6301\u5b9e\u65f6\u4ea4\u4e92\u548c\u6a21\u62df\u5206\u6790\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u7cfb\u7edf\u80fd\u591f\u9632\u6b62\u7f3a\u8d27\u3001\u964d\u4f4e\u6210\u672c\u5e76\u7ef4\u6301\u670d\u52a1\u6c34\u5e73\uff0c\u6539\u5584\u89c4\u5212\u6548\u679c\u3002", "conclusion": "\u672a\u6765\u5c06\u96c6\u6210\u79c1\u6709LLM\u3001\u8fc1\u79fb\u5b66\u4e60\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u4ee5\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u3001\u9002\u5e94\u6027\u548c\u5b9e\u65f6\u51b3\u7b56\u80fd\u529b\u3002"}}
{"id": "2508.21606", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.21606", "abs": "https://arxiv.org/abs/2508.21606", "authors": ["Nishant Chinnasami", "Rasha Karakchi"], "title": "Hybrid Cryptographic Monitoring System for Side-Channel Attack Detection on PYNQ SoCs", "comment": "This paper is submitted at Supercomputing (SC'25)", "summary": "AES-128 encryption is theoretically secure but vulnerable in practical\ndeployments due to timing and fault injection attacks on embedded systems. This\nwork presents a lightweight dual-detection framework combining statistical\nthresholding and machine learning (ML) for real-time anomaly detection. By\nsimulating anomalies via delays and ciphertext corruption, we collect timing\nand data features to evaluate two strategies: (1) a statistical threshold\nmethod based on execution time and (2) a Random Forest classifier trained on\nblock-level anomalies. Implemented on CPU and FPGA (PYNQ-Z1), our results show\nthat the ML approach outperforms static thresholds in accuracy, while\nmaintaining real-time feasibility on embedded platforms. The framework operates\nwithout modifying AES internals or relying on hardware performance counters.\nThis makes it especially suitable for low-power, resource-constrained systems\nwhere detection accuracy and computational efficiency must be balanced.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u53cc\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u7edf\u8ba1\u9608\u503c\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8eAES-128\u52a0\u5bc6\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u7684\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\uff0c\u65e0\u9700\u4fee\u6539AES\u5185\u90e8\u7ed3\u6784\u6216\u4f9d\u8d56\u786c\u4ef6\u6027\u80fd\u8ba1\u6570\u5668\u3002", "motivation": "AES-128\u52a0\u5bc6\u867d\u7136\u5728\u7406\u8bba\u4e0a\u5b89\u5168\uff0c\u4f46\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5b9e\u9645\u90e8\u7f72\u4e2d\u5bb9\u6613\u53d7\u5230\u65f6\u5e8f\u548c\u6545\u969c\u6ce8\u5165\u653b\u51fb\uff0c\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u5b9e\u65f6\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u5ef6\u8fdf\u548c\u5bc6\u6587\u635f\u574f\u6765\u6536\u96c6\u65f6\u5e8f\u548c\u6570\u636e\u7279\u5f81\uff0c\u8bc4\u4f30\u4e24\u79cd\u7b56\u7565\uff1a\u57fa\u4e8e\u6267\u884c\u65f6\u95f4\u7684\u7edf\u8ba1\u9608\u503c\u65b9\u6cd5\u548c\u57fa\u4e8e\u5757\u7ea7\u5f02\u5e38\u7684\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\uff0c\u5728CPU\u548cFPGA\u5e73\u53f0\u4e0a\u5b9e\u73b0\u3002", "result": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u9759\u6001\u9608\u503c\u65b9\u6cd5\uff0c\u540c\u65f6\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u4e0a\u4fdd\u6301\u5b9e\u65f6\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u5728\u68c0\u6d4b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u7684\u4f4e\u529f\u8017\u3001\u8d44\u6e90\u53d7\u9650\u7cfb\u7edf\u3002"}}
{"id": "2508.21637", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.21637", "abs": "https://arxiv.org/abs/2508.21637", "authors": ["Ramkumar Natarajan", "Muhammad Suhail Saleem", "William Xiao", "Sandip Aine", "Howie Choset", "Maxim Likhachev"], "title": "A-MHA*: Anytime Multi-Heuristic A*", "comment": null, "summary": "Designing good heuristic functions for graph search requires adequate domain\nknowledge. It is often easy to design heuristics that perform well and\ncorrelate with the underlying true cost-to-go values in certain parts of the\nsearch space but these may not be admissible throughout the domain thereby\naffecting the optimality guarantees of the search. Bounded suboptimal search\nusing several such partially good but inadmissible heuristics was developed in\nMulti-Heuristic A* (MHA*). Although MHA* leverages multiple inadmissible\nheuristics to potentially generate a faster suboptimal solution, the original\nversion does not improve the solution over time. It is a one shot algorithm\nthat requires careful setting of inflation factors to obtain a desired one time\nsolution. In this work, we tackle this issue by extending MHA* to an anytime\nversion that finds a feasible suboptimal solution quickly and continually\nimproves it until time runs out. Our work is inspired from the Anytime\nRepairing A* (ARA*) algorithm. We prove that our precise adaptation of ARA*\nconcepts in the MHA* framework preserves the original suboptimal and\ncompleteness guarantees and enhances MHA* to perform in an anytime fashion.\nFurthermore, we report the performance of A-MHA* in 3-D path planning domain\nand sliding tiles puzzle and compare against MHA* and other anytime algorithms.", "AI": {"tldr": "\u5c06\u591a\u542f\u53d1\u5f0fA*\uff08MHA*\uff09\u6269\u5c55\u4e3a\u968f\u65f6\u7b97\u6cd5A-MHA*\uff0c\u80fd\u591f\u5feb\u901f\u627e\u5230\u53ef\u884c\u89e3\u5e76\u6301\u7eed\u6539\u8fdb\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u4f18\u6027\u4fdd\u8bc1", "motivation": "MHA*\u867d\u7136\u80fd\u5229\u7528\u591a\u4e2a\u4e0d\u53ef\u91c7\u7eb3\u542f\u53d1\u5f0f\u51fd\u6570\u52a0\u901f\u641c\u7d22\uff0c\u4f46\u53ea\u80fd\u4e00\u6b21\u6027\u6c42\u89e3\u4e14\u9700\u8981\u4ed4\u7ec6\u8bbe\u7f6e\u81a8\u80c0\u56e0\u5b50\uff0c\u65e0\u6cd5\u968f\u65f6\u95f4\u6301\u7eed\u6539\u8fdb\u89e3\u7684\u8d28\u91cf", "method": "\u53d7ARA*\u7b97\u6cd5\u542f\u53d1\uff0c\u5c06ARA*\u7684\u6982\u5ff5\u7cbe\u786e\u9002\u914d\u5230MHA*\u6846\u67b6\u4e2d\uff0c\u5f00\u53d1\u51fa\u968f\u65f6\u7248\u672cA-MHA*", "result": "A-MHA*\u57283D\u8def\u5f84\u89c4\u5212\u548c\u6ed1\u5757\u62fc\u56fe\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u76f8\u6bd4MHA*\u548c\u5176\u4ed6\u968f\u65f6\u7b97\u6cd5\u5177\u6709\u66f4\u597d\u6027\u80fd", "conclusion": "A-MHA*\u6210\u529f\u6269\u5c55\u4e86MHA*\u4e3a\u968f\u65f6\u7b97\u6cd5\uff0c\u4fdd\u6301\u4e86\u539f\u6709\u7684\u6b21\u4f18\u6027\u548c\u5b8c\u5907\u6027\u4fdd\u8bc1\uff0c\u5e76\u80fd\u6301\u7eed\u6539\u8fdb\u89e3\u8d28\u91cf"}}
{"id": "2508.21648", "categories": ["cs.AI", "68T07, 68T09, 68T20 (Primary) 62P10, 62C20, 62H30 (Secondary)"], "pdf": "https://arxiv.org/pdf/2508.21648", "abs": "https://arxiv.org/abs/2508.21648", "authors": ["Farhad Abtahi", "Mehdi Astaraki", "Fernando Seoane"], "title": "Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI", "comment": null, "summary": "Bias in medical artificial intelligence is conventionally viewed as a defect\nrequiring elimination. However, human reasoning inherently incorporates biases\nshaped by education, culture, and experience, suggesting their presence may be\ninevitable and potentially valuable. We propose MEDLEY (Medical Ensemble\nDiagnostic system with Leveraged diversitY), a conceptual framework that\norchestrates multiple AI models while preserving their diverse outputs rather\nthan collapsing them into a consensus. Unlike traditional approaches that\nsuppress disagreement, MEDLEY documents model-specific biases as potential\nstrengths and treats hallucinations as provisional hypotheses for clinician\nverification. A proof-of-concept demonstrator was developed using over 30 large\nlanguage models, creating a minimum viable product that preserved both\nconsensus and minority views in synthetic cases, making diagnostic uncertainty\nand latent biases transparent for clinical oversight. While not yet a validated\nclinical tool, the demonstration illustrates how structured diversity can\nenhance medical reasoning under clinician supervision. By reframing AI\nimperfection as a resource, MEDLEY offers a paradigm shift that opens new\nregulatory, ethical, and innovation pathways for developing trustworthy medical\nAI systems.", "AI": {"tldr": "MEDLEY\u6846\u67b6\u901a\u8fc7\u4fdd\u7559\u591a\u4e2aAI\u6a21\u578b\u7684\u591a\u6837\u6027\u8f93\u51fa\u800c\u975e\u8fbe\u6210\u5171\u8bc6\uff0c\u5c06AI\u504f\u89c1\u89c6\u4e3a\u6f5c\u5728\u4f18\u52bf\uff0c\u4e3a\u533b\u7597AI\u7cfb\u7edf\u63d0\u4f9b\u65b0\u7684\u76d1\u7ba1\u548c\u4f26\u7406\u8def\u5f84", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5c06\u533b\u7597AI\u4e2d\u7684\u504f\u89c1\u89c6\u4e3a\u9700\u8981\u6d88\u9664\u7684\u7f3a\u9677\uff0c\u4f46\u4eba\u7c7b\u63a8\u7406\u672c\u8eab\u5c31\u5305\u542b\u53d7\u6559\u80b2\u3001\u6587\u5316\u548c\u7ecf\u9a8c\u5f71\u54cd\u7684\u504f\u89c1\uff0c\u8fd9\u4e9b\u504f\u89c1\u53ef\u80fd\u5177\u6709\u4ef7\u503c", "method": "\u63d0\u51faMEDLEY\u6982\u5ff5\u6846\u67b6\uff0c\u534f\u8c03\u591a\u4e2aAI\u6a21\u578b\u5e76\u4fdd\u7559\u5176\u591a\u6837\u6027\u8f93\u51fa\uff0c\u5c06\u6a21\u578b\u7279\u5b9a\u504f\u89c1\u8bb0\u5f55\u4e3a\u6f5c\u5728\u4f18\u52bf\uff0c\u5c06\u5e7b\u89c9\u89c6\u4e3a\u4f9b\u4e34\u5e8a\u533b\u751f\u9a8c\u8bc1\u7684\u4e34\u65f6\u5047\u8bbe", "result": "\u5f00\u53d1\u4e86\u6982\u5ff5\u9a8c\u8bc1\u6f14\u793a\u5668\uff0c\u4f7f\u752830\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u5408\u6210\u75c5\u4f8b\u4e2d\u4fdd\u7559\u5171\u8bc6\u548c\u5c11\u6570\u89c2\u70b9\uff0c\u4f7f\u8bca\u65ad\u4e0d\u786e\u5b9a\u6027\u548c\u6f5c\u5728\u504f\u89c1\u5bf9\u4e34\u5e8a\u76d1\u7763\u900f\u660e", "conclusion": "MEDLEY\u901a\u8fc7\u5c06AI\u4e0d\u5b8c\u7f8e\u6027\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8d44\u6e90\uff0c\u63d0\u4f9b\u4e86\u8303\u5f0f\u8f6c\u53d8\uff0c\u4e3a\u5f00\u53d1\u53ef\u4fe1\u8d56\u7684\u533b\u7597AI\u7cfb\u7edf\u5f00\u8f9f\u4e86\u65b0\u7684\u76d1\u7ba1\u3001\u4f26\u7406\u548c\u521b\u65b0\u9014\u5f84"}}
{"id": "2508.21654", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.21654", "abs": "https://arxiv.org/abs/2508.21654", "authors": ["Daryna Oliynyk", "Rudolf Mayer", "Kathrin Grosse", "Andreas Rauber"], "title": "I Stolenly Swear That I Am Up to (No) Good: Design and Evaluation of Model Stealing Attacks", "comment": "Under review", "summary": "Model stealing attacks endanger the confidentiality of machine learning\nmodels offered as a service. Although these models are kept secret, a malicious\nparty can query a model to label data samples and train their own substitute\nmodel, violating intellectual property. While novel attacks in the field are\ncontinually being published, their design and evaluations are not standardised,\nmaking it challenging to compare prior works and assess progress in the field.\nThis paper is the first to address this gap by providing recommendations for\ndesigning and evaluating model stealing attacks. To this end, we study the\nlargest group of attacks that rely on training a substitute model -- those\nattacking image classification models. We propose the first comprehensive\nthreat model and develop a framework for attack comparison. Further, we analyse\nattack setups from related works to understand which tasks and models have been\nstudied the most. Based on our findings, we present best practices for attack\ndevelopment before, during, and beyond experiments and derive an extensive list\nof open research questions regarding the evaluation of model stealing attacks.\nOur findings and recommendations also transfer to other problem domains, hence\nestablishing the first generic evaluation methodology for model stealing\nattacks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u9996\u6b21\u63d0\u51fa\u4e86\u6a21\u578b\u76d7\u7a83\u653b\u51fb\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u653b\u51fb\u6848\u4f8b\uff0c\u63d0\u51fa\u4e86\u5b8c\u6574\u7684\u5a01\u80c1\u6a21\u578b\u548c\u653b\u51fb\u6bd4\u8f83\u6846\u67b6\uff0c\u4ee5\u53ca\u653b\u51fb\u5f00\u53d1\u7684\u6700\u4f73\u5b9e\u8df5\u548c\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u76ee\u524d\u6a21\u578b\u76d7\u7a83\u653b\u51fb\u7684\u8bbe\u8ba1\u548c\u8bc4\u4f30\u7f3a\u4e4f\u6807\u51c6\u5316\uff0c\u5bfc\u81f4\u4e0d\u540c\u7814\u7a76\u5de5\u4f5c\u96be\u4ee5\u6bd4\u8f83\u548c\u8bc4\u4f30\u8fdb\u5c55\u3002\u8fd9\u4e2a\u9886\u57df\u9700\u8981\u7edf\u4e00\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u63d0\u9ad8\u7814\u7a76\u7684\u53ef\u6bd4\u6027\u548c\u53ef\u91cd\u73b0\u6027\u3002", "method": "\u7814\u7a76\u4e86\u6700\u5927\u7684\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u76d7\u7a83\u653b\u51fb\u7fa4\u4f53\uff0c\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u5b8c\u6574\u7684\u5a01\u80c1\u6a21\u578b\u548c\u653b\u51fb\u6bd4\u8f83\u6846\u67b6\uff0c\u5206\u6790\u4e86\u76f8\u5173\u5de5\u4f5c\u7684\u653b\u51fb\u8bbe\u7f6e\u3002", "result": "\u63d0\u51fa\u4e86\u653b\u51fb\u5f00\u53d1\u7684\u6700\u4f73\u5b9e\u8df5\u6307\u5357\uff08\u5b9e\u9a8c\u524d\u3001\u5b9e\u9a8c\u4e2d\u548c\u5b9e\u9a8c\u540e\uff09\uff0c\u4ee5\u53ca\u4e00\u4e2a\u5e7f\u6cdb\u7684\u5f00\u653f\u7814\u7a76\u95ee\u9898\u6e05\u5355\u3002", "conclusion": "\u8fd9\u4e2a\u65b9\u6cd5\u8bba\u662f\u7b2c\u4e00\u4e2a\u901a\u7528\u7684\u6a21\u578b\u76d7\u7a83\u653b\u51fb\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u9002\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u9886\u57df\uff0c\u4e5f\u53ef\u4ee5\u8f6c\u79fb\u5230\u5176\u4ed6\u95ee\u9898\u9886\u57df\uff0c\u4e3a\u8be5\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2508.21720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21720", "abs": "https://arxiv.org/abs/2508.21720", "authors": ["Jiho Choi", "Seojeong Park", "Seongjong Song", "Hyunjung Shim"], "title": "PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation", "comment": null, "summary": "We present a novel training-free framework, \\textit{PosterForest}, for\nautomated scientific poster generation. Unlike prior approaches, which largely\nneglect the hierarchical structure of scientific documents and the semantic\nintegration of textual and visual elements, our method addresses both\nchallenges directly. We introduce the \\textit{Poster Tree}, a hierarchical\nintermediate representation that jointly encodes document structure and\nvisual-textual relationships at multiple levels. Our framework employs a\nmulti-agent collaboration strategy, where agents specializing in content\nsummarization and layout planning iteratively coordinate and provide mutual\nfeedback. This approach enables the joint optimization of logical consistency,\ncontent fidelity, and visual coherence. Extensive experiments on multiple\nacademic domains show that our method outperforms existing baselines in both\nqualitative and quantitative evaluations. The resulting posters achieve quality\nclosest to expert-designed ground truth and deliver superior information\npreservation, structural clarity, and user preference.", "AI": {"tldr": "PosterForest\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u79d1\u5b66\u6d77\u62a5\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u4e2d\u95f4\u8868\u793a\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u5b9e\u73b0\u6587\u672c\u548c\u89c6\u89c9\u5143\u7d20\u7684\u8bed\u4e49\u6574\u5408\u4e0e\u7ed3\u6784\u4f18\u5316", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u4e86\u79d1\u5b66\u6587\u6863\u7684\u5206\u5c42\u7ed3\u6784\u548c\u6587\u672c\u89c6\u89c9\u5143\u7d20\u7684\u8bed\u4e49\u6574\u5408\uff0c\u9700\u8981\u540c\u65f6\u89e3\u51b3\u8fd9\u4e24\u4e2a\u6311\u6218", "method": "\u5f15\u5165Poster Tree\u5206\u5c42\u4e2d\u95f4\u8868\u793a\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7b56\u7565\uff08\u5185\u5bb9\u6458\u8981\u548c\u5e03\u5c40\u89c4\u5212\u667a\u80fd\u4f53\uff09\uff0c\u901a\u8fc7\u8fed\u4ee3\u534f\u8c03\u548c\u76f8\u4e92\u53cd\u9988\u5b9e\u73b0\u8054\u5408\u4f18\u5316", "result": "\u5728\u591a\u4e2a\u5b66\u672f\u9886\u57df\u7684\u5b9e\u9a8c\u4e2d\uff0c\u65b9\u6cd5\u5728\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc4\u4f30\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u751f\u6210\u7684\u6d77\u62a5\u8d28\u91cf\u6700\u63a5\u8fd1\u4e13\u5bb6\u8bbe\u8ba1\uff0c\u4fe1\u606f\u4fdd\u7559\u3001\u7ed3\u6784\u6e05\u6670\u5ea6\u548c\u7528\u6237\u504f\u597d\u65b9\u9762\u8868\u73b0\u4f18\u5f02", "conclusion": "PosterForest\u6846\u67b6\u901a\u8fc7\u5206\u5c42\u8868\u793a\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u79d1\u5b66\u6d77\u62a5\u751f\u6210\u4e2d\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u6574\u5408\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u81ea\u52a8\u5316\u6d77\u62a5\u751f\u6210"}}
{"id": "2508.21669", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.21669", "abs": "https://arxiv.org/abs/2508.21669", "authors": ["V\u00edctor Mayoral-Vilches", "Per Mannermaa Rynning"], "title": "Cybersecurity AI: Hacking the AI Hackers via Prompt Injection", "comment": null, "summary": "We demonstrate how AI-powered cybersecurity tools can be turned against\nthemselves through prompt injection attacks. Prompt injection is reminiscent of\ncross-site scripting (XSS): malicious text is hidden within seemingly trusted\ncontent, and when the system processes it, that text is transformed into\nunintended instructions. When AI agents designed to find and exploit\nvulnerabilities interact with malicious web servers, carefully crafted reponses\ncan hijack their execution flow, potentially granting attackers system access.\nWe present proof-of-concept exploits against the Cybersecurity AI (CAI)\nframework and its CLI tool, and detail our mitigations against such attacks in\na multi-layered defense implementation. Our findings indicate that prompt\ninjection is a recurring and systemic issue in LLM-based architectures, one\nthat will require dedicated work to address, much as the security community has\nhad to do with XSS in traditional web applications.", "AI": {"tldr": "AI\u7f51\u7edc\u5b89\u5168\u5de5\u5177\u5b58\u5728\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u6076\u610f\u5185\u5bb9\u52ab\u6301AI\u4ee3\u7406\u6267\u884c\u6d41\u7a0b\uff0c\u83b7\u5f97\u7cfb\u7edf\u8bbf\u95ee\u6743\u9650\u3002", "motivation": "\u63ed\u793aAI\u9a71\u52a8\u7684\u7f51\u7edc\u5b89\u5168\u5de5\u5177\u9762\u4e34\u7684\u65b0\u578b\u5b89\u5168\u5a01\u80c1\u2014\u2014\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u7c7b\u4f3c\u4e8e\u4f20\u7edfXSS\u6f0f\u6d1e\uff0c\u9700\u8981\u5b89\u5168\u793e\u533a\u91cd\u89c6\u548c\u89e3\u51b3\u3002", "method": "\u901a\u8fc7\u5bf9\u7f51\u7edc\u5b89\u5168AI\u6846\u67b6\u53ca\u5176CLI\u5de5\u5177\u8fdb\u884c\u6982\u5ff5\u9a8c\u8bc1\u653b\u51fb\uff0c\u5c55\u793a\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e\u7684\u5b9e\u9645\u5371\u5bb3\uff0c\u5e76\u5b9e\u65bd\u591a\u5c42\u9632\u5fa1\u673a\u5236\u8fdb\u884c\u7f13\u89e3\u3002", "result": "\u6210\u529f\u6f14\u793a\u4e86\u9488\u5bf9CAI\u6846\u67b6\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u8bc1\u660e\u8fd9\u662fLLM\u67b6\u6784\u4e2d\u666e\u904d\u5b58\u5728\u7684\u7cfb\u7edf\u6027\u5b89\u5168\u95ee\u9898\u3002", "conclusion": "\u63d0\u793a\u6ce8\u5165\u662fLLM\u57fa\u7840\u67b6\u6784\u4e2d\u53cd\u590d\u51fa\u73b0\u7684\u7cfb\u7edf\u6027\u95ee\u9898\uff0c\u9700\u8981\u50cf\u5904\u7406\u4f20\u7edfWeb\u5e94\u7528XSS\u90a3\u6837\u6295\u5165\u4e13\u95e8\u5de5\u4f5c\u6765\u89e3\u51b3\u3002"}}
{"id": "2508.21730", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21730", "abs": "https://arxiv.org/abs/2508.21730", "authors": ["Fabrizio Fagiolo", "Nicolo' Vescera"], "title": "Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem", "comment": null, "summary": "In this paper we present a variational algorithm for the Traveling Salesman\nProblem (TSP) that combines (i) a compact encoding of permutations, which\nreduces the qubit requirement too, (ii) an optimize-freeze-reuse strategy:\nwhere the circuit topology (``Ansatz'') is first optimized on a training\ninstance by Simulated Annealing (SA), then ``frozen'' and re-used on novel\ninstances, limited to a rapid re-optimization of only the circuit parameters.\nThis pipeline eliminates costly structural research in testing, making the\nprocedure immediately implementable on NISQ hardware.\n  On a set of $40$ randomly generated symmetric instances that span $4 - 7$\ncities, the resulting Ansatz achieves an average optimal trip sampling\nprobability of $100\\%$ for 4 city cases, $90\\%$ for 5 city cases and $80\\%$ for\n6 city cases. With 7 cities the success rate drops markedly to an average of\n$\\sim 20\\%$, revealing the onset of scalability limitations of the proposed\nmethod.\n  The results show robust generalization ability for moderate problem sizes and\nindicate how freezing the Ansatz can dramatically reduce time-to-solution\nwithout degrading solution quality. The paper also discusses scalability\nlimitations, the impact of ``warm-start'' initialization of parameters, and\nprospects for extension to more complex problems, such as Vehicle Routing and\nJob-Shop Scheduling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u65c5\u884c\u5546\u95ee\u9898\u7684\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\uff0c\u901a\u8fc7\u7d27\u51d1\u6392\u5217\u7f16\u7801\u51cf\u5c11\u91cf\u5b50\u6bd4\u7279\u9700\u6c42\uff0c\u91c7\u7528\u4f18\u5316-\u51bb\u7ed3-\u91cd\u7528\u7b56\u7565\uff0c\u5728\u8bad\u7ec3\u5b9e\u4f8b\u4e0a\u4f18\u5316\u7535\u8def\u7ed3\u6784\u540e\u51bb\u7ed3\u5e76\u91cd\u7528\uff0c\u4ec5\u9700\u91cd\u65b0\u4f18\u5316\u53c2\u6570\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\u5728\u65c5\u884c\u5546\u95ee\u9898\u4e2d\u9700\u8981\u5927\u91cf\u91cf\u5b50\u6bd4\u7279\u548c\u6bcf\u6b21\u6d4b\u8bd5\u90fd\u9700\u8981\u91cd\u65b0\u8fdb\u884c\u7ed3\u6784\u641c\u7d22\u7684\u9ad8\u6210\u672c\u95ee\u9898\uff0c\u65e8\u5728\u5b9e\u73b0NISQ\u8bbe\u5907\u4e0a\u7684\u5feb\u901f\u90e8\u7f72\u3002", "method": "\u4f7f\u7528\u7d27\u51d1\u6392\u5217\u7f16\u7801\u51cf\u5c11\u91cf\u5b50\u6bd4\u7279\u9700\u6c42\uff1b\u91c7\u7528\u4f18\u5316-\u51bb\u7ed3-\u91cd\u7528\u7b56\u7565\uff1a\u5148\u5728\u8bad\u7ec3\u5b9e\u4f8b\u4e0a\u7528\u6a21\u62df\u9000\u706b\u4f18\u5316\u7535\u8def\u7ed3\u6784\uff0c\u7136\u540e\u51bb\u7ed3\u7ed3\u6784\uff0c\u5728\u65b0\u5b9e\u4f8b\u4e0a\u4ec5\u91cd\u65b0\u4f18\u5316\u7535\u8def\u53c2\u6570\u3002", "result": "\u57284-7\u4e2a\u57ce\u5e02\u768440\u4e2a\u968f\u673a\u5bf9\u79f0\u5b9e\u4f8b\u4e0a\uff0c4\u57ce\u5e02\u8fbe\u5230100%\u6700\u4f18\u8def\u5f84\u91c7\u6837\u6982\u7387\uff0c5\u57ce\u5e0290%\uff0c6\u57ce\u5e0280%\uff0c7\u57ce\u5e02\u964d\u81f3\u7ea620%\uff0c\u663e\u793a\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u9650\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4e2d\u7b49\u89c4\u6a21\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u51bb\u7ed3Ansatz\u80fd\u663e\u8457\u51cf\u5c11\u6c42\u89e3\u65f6\u95f4\u800c\u4e0d\u964d\u4f4e\u89e3\u8d28\u91cf\uff0c\u4f46\u5b58\u5728\u53ef\u6269\u5c55\u6027\u9650\u5236\uff0c\u6709\u671b\u6269\u5c55\u5230\u8f66\u8f86\u8def\u5f84\u548c\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u7b49\u66f4\u590d\u6742\u95ee\u9898\u3002"}}
{"id": "2508.21727", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21727", "abs": "https://arxiv.org/abs/2508.21727", "authors": ["Jiazheng Xing", "Hai Ci", "Hongbin Xu", "Hangjie Yuan", "Yong Liu", "Mike Zheng Shou"], "title": "OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization", "comment": null, "summary": "Watermarking diffusion-generated images is crucial for copyright protection\nand user tracking. However, current diffusion watermarking methods face\nsignificant limitations: zero-bit watermarking systems lack the capacity for\nlarge-scale user tracking, while multi-bit methods are highly sensitive to\ncertain image transformations or generative attacks, resulting in a lack of\ncomprehensive robustness. In this paper, we propose OptMark, an\noptimization-based approach that embeds a robust multi-bit watermark into the\nintermediate latents of the diffusion denoising process. OptMark strategically\ninserts a structural watermark early to resist generative attacks and a detail\nwatermark late to withstand image transformations, with tailored regularization\nterms to preserve image quality and ensure imperceptibility. To address the\nchallenge of memory consumption growing linearly with the number of denoising\nsteps during optimization, OptMark incorporates adjoint gradient methods,\nreducing memory usage from O(N) to O(1). Experimental results demonstrate that\nOptMark achieves invisible multi-bit watermarking while ensuring robust\nresilience against valuemetric transformations, geometric transformations,\nediting, and regeneration attacks.", "AI": {"tldr": "OptMark\u662f\u4e00\u79cd\u57fa\u4e8e\u4f18\u5316\u7684\u591a\u6bd4\u7279\u6c34\u5370\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6269\u6563\u53bb\u566a\u8fc7\u7a0b\u7684\u4e2d\u95f4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5d4c\u5165\u6c34\u5370\uff0c\u5b9e\u73b0\u4e86\u5bf9\u56fe\u50cf\u53d8\u6362\u548c\u751f\u6210\u653b\u51fb\u7684\u9c81\u68d2\u6027\u4fdd\u62a4\u3002", "motivation": "\u5f53\u524d\u6269\u6563\u6c34\u5370\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u96f6\u6bd4\u7279\u6c34\u5370\u7cfb\u7edf\u7f3a\u4e4f\u5927\u89c4\u6a21\u7528\u6237\u8ddf\u8e2a\u80fd\u529b\uff0c\u800c\u591a\u6bd4\u7279\u65b9\u6cd5\u5bf9\u67d0\u4e9b\u56fe\u50cf\u53d8\u6362\u6216\u751f\u6210\u653b\u51fb\u9ad8\u5ea6\u654f\u611f\uff0c\u7f3a\u4e4f\u5168\u9762\u7684\u9c81\u68d2\u6027\u3002", "method": "\u5728\u6269\u6563\u53bb\u566a\u8fc7\u7a0b\u4e2d\u65e9\u671f\u5d4c\u5165\u7ed3\u6784\u6c34\u5370\u4ee5\u62b5\u6297\u751f\u6210\u653b\u51fb\uff0c\u665a\u671f\u5d4c\u5165\u7ec6\u8282\u6c34\u5370\u4ee5\u62b5\u5fa1\u56fe\u50cf\u53d8\u6362\uff0c\u91c7\u7528\u5b9a\u5236\u6b63\u5219\u5316\u9879\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u548c\u4e0d\u53ef\u611f\u77e5\u6027\uff0c\u5e76\u5229\u7528\u4f34\u968f\u68af\u5ea6\u65b9\u6cd5\u5c06\u5185\u5b58\u4f7f\u7528\u4eceO(N)\u964d\u4f4e\u5230O(1)\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eOptMark\u5b9e\u73b0\u4e86\u4e0d\u53ef\u89c1\u7684\u591a\u6bd4\u7279\u6c34\u5370\uff0c\u540c\u65f6\u5bf9\u503c\u5ea6\u91cf\u53d8\u6362\u3001\u51e0\u4f55\u53d8\u6362\u3001\u7f16\u8f91\u548c\u518d\u751f\u653b\u51fb\u5177\u6709\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "OptMark\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u751f\u6210\u56fe\u50cf\u6c34\u5370\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u5bb9\u91cf\u9650\u5236\u95ee\u9898\uff0c\u4e3a\u7248\u6743\u4fdd\u62a4\u548c\u7528\u6237\u8ddf\u8e2a\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2508.21742", "categories": ["cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2508.21742", "abs": "https://arxiv.org/abs/2508.21742", "authors": ["Timoth\u00e9e Loranchet", "Charles K. Assaad"], "title": "Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions", "comment": null, "summary": "Understanding causal relations between temporal variables is a central\nchallenge in time series analysis, particularly when the full causal structure\nis unknown. Even when the full causal structure cannot be fully specified,\nexperts often succeed in providing a high-level abstraction of the causal\ngraph, known as a summary causal graph, which captures the main causal\nrelations between different time series while abstracting away micro-level\ndetails. In this work, we present conditions that guarantee the orientability\nof micro-level edges between temporal variables given the background knowledge\nencoded in a summary causal graph and assuming having access to a faithful and\ncausally sufficient distribution with respect to the true unknown graph. Our\nresults provide theoretical guarantees for edge orientation at the micro-level,\neven in the presence of cycles or bidirected edges at the macro-level. These\nfindings offer practical guidance for leveraging SCGs to inform causal\ndiscovery in complex temporal systems and highlight the value of incorporating\nexpert knowledge to improve causal inference from observational time series\ndata.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5728\u7ed9\u5b9a\u6458\u8981\u56e0\u679c\u56fe\u80cc\u666f\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u4fdd\u8bc1\u65f6\u95f4\u53d8\u91cf\u95f4\u5fae\u89c2\u5c42\u9762\u8fb9\u5b9a\u5411\u7684\u7406\u8bba\u6761\u4ef6\uff0c\u4e3a\u590d\u6742\u65f6\u95f4\u7cfb\u7edf\u4e2d\u7684\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u7406\u89e3\u65f6\u95f4\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5b8c\u6574\u56e0\u679c\u7ed3\u6784\u672a\u77e5\u7684\u60c5\u51b5\u4e0b\u3002\u4e13\u5bb6\u901a\u5e38\u80fd\u591f\u63d0\u4f9b\u6458\u8981\u56e0\u679c\u56fe\u6765\u6355\u6349\u4e3b\u8981\u56e0\u679c\u5173\u7cfb\uff0c\u4f46\u5982\u4f55\u5229\u7528\u8fd9\u79cd\u9ad8\u5c42\u62bd\u8c61\u6765\u6307\u5bfc\u5fae\u89c2\u5c42\u9762\u7684\u56e0\u679c\u53d1\u73b0\u9700\u8981\u7406\u8bba\u652f\u6301\u3002", "method": "\u63d0\u51fa\u4e86\u5728\u5047\u8bbe\u5b58\u5728\u5fe0\u5b9e\u4e14\u56e0\u679c\u5145\u5206\u7684\u5206\u5e03\u6761\u4ef6\u4e0b\uff0c\u7ed9\u5b9a\u6458\u8981\u56e0\u679c\u56fe\u80cc\u666f\u77e5\u8bc6\uff0c\u4fdd\u8bc1\u5fae\u89c2\u5c42\u9762\u65f6\u95f4\u53d8\u91cf\u95f4\u8fb9\u5b9a\u5411\u7684\u7406\u8bba\u6761\u4ef6\u3002\u8fd9\u4e9b\u6761\u4ef6\u5373\u4f7f\u5728\u5b8f\u89c2\u5c42\u9762\u5b58\u5728\u5faa\u73af\u6216\u53cc\u5411\u8fb9\u7684\u60c5\u51b5\u4e0b\u4e5f\u9002\u7528\u3002", "result": "\u5efa\u7acb\u4e86\u5fae\u89c2\u5c42\u9762\u8fb9\u5b9a\u5411\u7684\u7406\u8bba\u4fdd\u8bc1\u6761\u4ef6\uff0c\u8bc1\u660e\u4e86\u5728\u6458\u8981\u56e0\u679c\u56fe\u7684\u6307\u5bfc\u4e0b\uff0c\u5373\u4f7f\u5b8f\u89c2\u5c42\u9762\u5b58\u5728\u590d\u6742\u7ed3\u6784\uff0c\u4e5f\u80fd\u53ef\u9760\u5730\u8fdb\u884c\u5fae\u89c2\u5c42\u9762\u7684\u56e0\u679c\u63a8\u65ad\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5229\u7528\u4e13\u5bb6\u77e5\u8bc6\u63d0\u4f9b\u7684\u6458\u8981\u56e0\u679c\u56fe\u6765\u6539\u8fdb\u4ece\u89c2\u6d4b\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u8fdb\u884c\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u5f3a\u8c03\u4e86\u5c06\u4e13\u5bb6\u77e5\u8bc6\u878d\u5165\u590d\u6742\u65f6\u95f4\u7cfb\u7edf\u56e0\u679c\u53d1\u73b0\u7684\u4ef7\u503c\u3002"}}
{"id": "2508.21800", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.21800", "abs": "https://arxiv.org/abs/2508.21800", "authors": ["Hyeonseong Jeon", "Cheolhong Min", "Jaesik Park"], "title": "Tree-Guided Diffusion Planner", "comment": "20 pages, 11 figures, 14 tables (main paper + appendix) / under\n  review / project page will be available after the paper becomes public in\n  arxiv", "summary": "Planning with pretrained diffusion models has emerged as a promising approach\nfor solving test-time guided control problems. However, standard gradient\nguidance typically performs optimally under convex and differentiable reward\nlandscapes, showing substantially reduced effectiveness in real-world scenarios\ninvolving non-convex objectives, non-differentiable constraints, and\nmulti-reward structures. Furthermore, recent supervised planning approaches\nrequire task-specific training or value estimators, which limits test-time\nflexibility and zero-shot generalization. We propose a Tree-guided Diffusion\nPlanner (TDP), a zero-shot test-time planning framework that balances\nexploration and exploitation through structured trajectory generation. We frame\ntest-time planning as a tree search problem using a bi-level sampling process:\n(1) diverse parent trajectories are produced via training-free particle\nguidance to encourage broad exploration, and (2) sub-trajectories are refined\nthrough fast conditional denoising guided by task objectives. TDP addresses the\nlimitations of gradient guidance by exploring diverse trajectory regions and\nharnessing gradient information across this expanded solution space using only\npretrained models and test-time reward signals. We evaluate TDP on three\ndiverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze\nmulti-goal exploration. TDP consistently outperforms state-of-the-art\napproaches on all tasks. The project page can be found at:\ntree-diffusion-planner.github.io.", "AI": {"tldr": "\u63d0\u51faTree-guided Diffusion Planner (TDP)\uff0c\u4e00\u79cd\u96f6\u6837\u672c\u6d4b\u8bd5\u65f6\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u6811\u641c\u7d22\u548c\u53cc\u5c42\u91c7\u6837\u8fc7\u7a0b\u89e3\u51b3\u6269\u6563\u6a21\u578b\u5728\u975e\u51f8\u3001\u4e0d\u53ef\u5fae\u548c\u591a\u5956\u52b1\u573a\u666f\u4e0b\u7684\u89c4\u5212\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u89c4\u5212\u65b9\u6cd5\u5728\u51f8\u53ef\u5fae\u5956\u52b1\u573a\u666f\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u975e\u51f8\u76ee\u6807\u3001\u4e0d\u53ef\u5fae\u7ea6\u675f\u548c\u591a\u5956\u52b1\u7ed3\u6784\u4e2d\u6548\u679c\u663e\u8457\u4e0b\u964d\u3002\u540c\u65f6\uff0c\u6709\u76d1\u7763\u89c4\u5212\u65b9\u6cd5\u9700\u8981\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3\u6216\u4ef7\u503c\u4f30\u8ba1\u5668\uff0c\u9650\u5236\u4e86\u6d4b\u8bd5\u65f6\u7075\u6d3b\u6027\u548c\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "method": "TDP\u5c06\u6d4b\u8bd5\u65f6\u89c4\u5212\u6784\u5efa\u4e3a\u6811\u641c\u7d22\u95ee\u9898\uff0c\u91c7\u7528\u53cc\u5c42\u91c7\u6837\u8fc7\u7a0b\uff1a1) \u901a\u8fc7\u65e0\u8bad\u7ec3\u7c92\u5b50\u5f15\u5bfc\u751f\u6210\u591a\u6837\u5316\u7236\u8f68\u8ff9\u4ee5\u4fc3\u8fdb\u5e7f\u6cdb\u63a2\u7d22\uff1b2) \u901a\u8fc7\u4efb\u52a1\u76ee\u6807\u5f15\u5bfc\u7684\u5feb\u901f\u6761\u4ef6\u53bb\u566a\u7cbe\u70bc\u5b50\u8f68\u8ff9\u3002\u4ec5\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u6d4b\u8bd5\u65f6\u5956\u52b1\u4fe1\u53f7\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u6837\u5316\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff1a\u8ff7\u5bab\u91d1\u5e01\u6536\u96c6\u3001\u673a\u68b0\u81c2\u65b9\u5757\u64cd\u4f5c\u548cAntMaze\u591a\u76ee\u6807\u63a2\u7d22\u3002TDP\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u4e00\u81f4\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "TDP\u901a\u8fc7\u6811\u5f15\u5bfc\u7684\u6269\u6563\u89c4\u5212\u6709\u6548\u89e3\u51b3\u4e86\u68af\u5ea6\u5f15\u5bfc\u5728\u590d\u6742\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a2\u7d22-\u5229\u7528\u5e73\u8861\uff0c\u5c55\u793a\u4e86\u5728\u96f6\u6837\u672c\u6d4b\u8bd5\u65f6\u89c4\u5212\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2508.21803", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.21803", "abs": "https://arxiv.org/abs/2508.21803", "authors": ["Yeawon Lee", "Xiaoyang Wang", "Christopher C. Yang"], "title": "Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture", "comment": "Accepted to The 16th ACM Conference on Bioinformatics, Computational\n  Biology, and Health Informatics (ACM-BCB 2025)(Poster Paper)", "summary": "Accurate interpretation of clinical narratives is critical for patient care,\nbut the complexity of these notes makes automation challenging. While Large\nLanguage Models (LLMs) show promise, single-model approaches can lack the\nrobustness required for high-stakes clinical tasks. We introduce a\ncollaborative multi-agent system (MAS) that models a clinical consultation team\nto address this gap. The system is tasked with identifying clinical problems by\nanalyzing only the Subjective (S) and Objective (O) sections of SOAP notes,\nsimulating the diagnostic reasoning process of synthesizing raw data into an\nassessment. A Manager agent orchestrates a dynamically assigned team of\nspecialist agents who engage in a hierarchical, iterative debate to reach a\nconsensus. We evaluated our MAS against a single-agent baseline on a curated\ndataset of 420 MIMIC-III notes. The dynamic multi-agent configuration\ndemonstrated consistently improved performance in identifying congestive heart\nfailure, acute kidney injury, and sepsis. Qualitative analysis of the agent\ndebates reveals that this structure effectively surfaces and weighs conflicting\nevidence, though it can occasionally be susceptible to groupthink. By modeling\na clinical team's reasoning process, our system offers a promising path toward\nmore accurate, robust, and interpretable clinical decision support tools.", "AI": {"tldr": "\u4f7f\u7528\u591a\u6cbb\u7406\u7cfb\u7edf\u6a21\u62df\u4e34\u5e8a\u4f1a\u8bae\u56e2\u961f\uff0c\u901a\u8fc7\u5c42\u6b21\u8fed\u4ee3\u8fa9\u8bba\u63d0\u5347\u4e86\u4e34\u5e8a\u95ee\u9898\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u7a33\u5065\u6027", "motivation": "\u4e34\u5e8a\u6587\u6863\u89e3\u91ca\u5bf9\u60a3\u8005\u62a4\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5355\u4e00\u6a21\u578b\u7f3a\u4e4f\u9ad8\u98ce\u9669\u4e34\u5e8a\u4efb\u52a1\u6240\u9700\u7684\u7a33\u5065\u6027\uff0c\u9700\u8981\u66f4\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5de5\u5177", "method": "\u8bbe\u8ba1\u4e86\u534f\u4f5c\u5f0f\u591a\u6cbb\u7406\u7cfb\u7edf(MAS)\uff0c\u6a21\u62df\u4e34\u5e8a\u4f1a\u8bae\u56e2\u961f\u3002Manager\u6cbb\u7406\u534f\u8c03\u52a8\u6001\u6307\u6d3e\u7684\u4e13\u79d1\u6cbb\u7406\u56e2\u961f\uff0c\u8fdb\u884c\u5c42\u6b21\u8fed\u4ee3\u8fa9\u8bba\u8fbe\u6210\u5171\u8bc6\uff0c\u5206\u6790SOAP\u8bb0\u5f55\u4e2d\u7684S\u548cO\u90e8\u5206\u6765\u8bc6\u522b\u4e34\u5e8a\u95ee\u9898", "result": "\u5728420\u4efdMIMIC-III\u8bb0\u5f55\u7684\u6e2f\u7406\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u52a8\u6001\u591a\u6cbb\u7406\u914d\u7f6e\u5728\u8bc6\u522b\u5fc3\u529b\u8870\u7ecf\u3001\u6025\u6027\u80be\u4f24\u4f24\u548c\u611f\u67d3\u6027\u4f24\u7b49\u75be\u75c5\u65b9\u9762\u8868\u73b0\u4e00\u81f4\u63d0\u5347\uff0c\u8fa9\u8bba\u7ed3\u6784\u80fd\u6709\u6548\u8868\u9762\u5e76\u91cd\u65b0\u76f8\u4e92\u51b2\u7a81\u8bc1\u636e", "conclusion": "\u901a\u8fc7\u6a21\u62df\u4e34\u5e8a\u56e2\u961f\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u8be5\u7cfb\u7edf\u4e3a\u5f00\u53d1\u66f4\u51c6\u786e\u3001\u7a33\u5065\u548c\u53ef\u89e3\u91ca\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5de5\u5177\u63d0\u4f9b\u4e86\u6709\u524d\u9014\u7684\u8def\u5f84"}}
