{"id": "2506.22506", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22506", "abs": "https://arxiv.org/abs/2506.22506", "authors": ["Momin Ahmad Khan", "Yasra Chandio", "Fatima Muhammad Anwar"], "title": "SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning", "comment": null, "summary": "Federated Prompt Learning has emerged as a communication-efficient and\nprivacy-preserving paradigm for adapting large vision-language models like CLIP\nacross decentralized clients. However, the security implications of this setup\nremain underexplored. In this work, we present the first study of backdoor\nattacks in Federated Prompt Learning. We show that when malicious clients\ninject visually imperceptible, learnable noise triggers into input images, the\nglobal prompt learner becomes vulnerable to targeted misclassification while\nstill maintaining high accuracy on clean inputs. Motivated by this\nvulnerability, we propose SABRE-FL, a lightweight, modular defense that filters\npoisoned prompt updates using an embedding-space anomaly detector trained\noffline on out-of-distribution data. SABRE-FL requires no access to raw client\ndata or labels and generalizes across diverse datasets. We show, both\ntheoretically and empirically, that malicious clients can be reliably\nidentified and filtered using an embedding-based detector. Across five diverse\ndatasets and four baseline defenses, SABRE-FL outperforms all baselines by\nsignificantly reducing backdoor accuracy while preserving clean accuracy,\ndemonstrating strong empirical performance and underscoring the need for robust\nprompt learning in future federated systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8054\u90a6\u63d0\u793a\u5b66\u4e60\u4e2d\u7684\u540e\u95e8\u653b\u51fb\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u9632\u5fa1\u65b9\u6cd5SABRE-FL\uff0c\u901a\u8fc7\u5d4c\u5165\u7a7a\u95f4\u5f02\u5e38\u68c0\u6d4b\u5668\u8fc7\u6ee4\u6076\u610f\u66f4\u65b0\u3002", "motivation": "\u8054\u90a6\u63d0\u793a\u5b66\u4e60\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u901a\u4fe1\u6548\u7387\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5176\u5b89\u5168\u6027\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u5c24\u5176\u662f\u540e\u95e8\u653b\u51fb\u7684\u5a01\u80c1\u3002", "method": "\u63d0\u51faSABRE-FL\u9632\u5fa1\u65b9\u6cd5\uff0c\u5229\u7528\u79bb\u7ebf\u8bad\u7ec3\u7684\u5d4c\u5165\u7a7a\u95f4\u5f02\u5e38\u68c0\u6d4b\u5668\u8bc6\u522b\u5e76\u8fc7\u6ee4\u6076\u610f\u63d0\u793a\u66f4\u65b0\u3002", "result": "SABRE-FL\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u964d\u4f4e\u540e\u95e8\u653b\u51fb\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5e72\u51c0\u6570\u636e\u7684\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u56db\u79cd\u57fa\u7ebf\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u8054\u90a6\u63d0\u793a\u5b66\u4e60\u9700\u8981\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0cSABRE-FL\u4e3a\u672a\u6765\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9632\u5fa1\u65b9\u6848\u3002"}}
{"id": "2506.22515", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22515", "abs": "https://arxiv.org/abs/2506.22515", "authors": ["Antony Dalmiere", "Guillaume Auriol", "Vincent Nicomette", "Pascal Marchand"], "title": "In-context learning for the classification of manipulation techniques in phishing emails", "comment": null, "summary": "Traditional phishing detection often overlooks psychological manipulation.\nThis study investigates using Large Language Model (LLM) In-Context Learning\n(ICL) for fine-grained classification of phishing emails based on a taxonomy of\n40 manipulation techniques. Using few-shot examples with GPT-4o-mini on\nreal-world French phishing emails (SignalSpam), we evaluated performance\nagainst a human-annotated test set (100 emails). The approach effectively\nidentifies prevalent techniques (e.g., Baiting, Curiosity Appeal, Request For\nMinor Favor) with a promising accuracy of 0.76. This work demonstrates ICL's\npotential for nuanced phishing analysis and provides insights into attacker\nstrategies.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528LLM\uff08GPT-4o-mini\uff09\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u6280\u672f\uff0c\u5bf9\u9493\u9c7c\u90ae\u4ef6\u4e2d\u768440\u79cd\u5fc3\u7406\u64cd\u7eb5\u6280\u672f\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u7c7b\uff0c\u51c6\u786e\u7387\u8fbe0.76\u3002", "motivation": "\u4f20\u7edf\u9493\u9c7c\u68c0\u6d4b\u5e38\u5ffd\u7565\u5fc3\u7406\u64cd\u7eb5\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528Few-shot\u793a\u4f8b\u548cGPT-4o-mini\uff0c\u5bf9\u771f\u5b9e\u6cd5\u8bed\u9493\u9c7c\u90ae\u4ef6\uff08SignalSpam\uff09\u8fdb\u884c\u5206\u7c7b\u6d4b\u8bd5\u3002", "result": "\u5728100\u5c01\u4eba\u5de5\u6807\u6ce8\u7684\u6d4b\u8bd5\u90ae\u4ef6\u4e2d\uff0c\u51c6\u786e\u8bc6\u522b\u4e86\u5e38\u89c1\u64cd\u7eb5\u6280\u672f\uff08\u5982\u8bf1\u9975\u3001\u597d\u5947\u5fc3\u5438\u5f15\u3001\u5c0f\u8bf7\u6c42\uff09\uff0c\u51c6\u786e\u7387\u4e3a0.76\u3002", "conclusion": "\u8bc1\u660e\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\u5728\u9493\u9c7c\u5206\u6790\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u63ed\u793a\u4e86\u653b\u51fb\u8005\u7b56\u7565\u3002"}}
{"id": "2506.22521", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22521", "abs": "https://arxiv.org/abs/2506.22521", "authors": ["Kaixiang Zhao", "Lincan Li", "Kaize Ding", "Neil Zhenqiang Gong", "Yue Zhao", "Yushun Dong"], "title": "A Survey on Model Extraction Attacks and Defenses for Large Language Models", "comment": null, "summary": "Model extraction attacks pose significant security threats to deployed\nlanguage models, potentially compromising intellectual property and user\nprivacy. This survey provides a comprehensive taxonomy of LLM-specific\nextraction attacks and defenses, categorizing attacks into functionality\nextraction, training data extraction, and prompt-targeted attacks. We analyze\nvarious attack methodologies including API-based knowledge distillation, direct\nquerying, parameter recovery, and prompt stealing techniques that exploit\ntransformer architectures. We then examine defense mechanisms organized into\nmodel protection, data privacy protection, and prompt-targeted strategies,\nevaluating their effectiveness across different deployment scenarios. We\npropose specialized metrics for evaluating both attack effectiveness and\ndefense performance, addressing the specific challenges of generative language\nmodels. Through our analysis, we identify critical limitations in current\napproaches and propose promising research directions, including integrated\nattack methodologies and adaptive defense mechanisms that balance security with\nmodel utility. This work serves NLP researchers, ML engineers, and security\nprofessionals seeking to protect language models in production environments.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u9488\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u63d0\u53d6\u653b\u51fb\u53ca\u5176\u9632\u5fa1\u65b9\u6cd5\uff0c\u5206\u7c7b\u4e86\u653b\u51fb\u7c7b\u578b\u5e76\u5206\u6790\u4e86\u653b\u51fb\u4e0e\u9632\u5fa1\u7684\u6709\u6548\u6027\uff0c\u63d0\u51fa\u4e86\u8bc4\u4f30\u6307\u6807\u548c\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u6a21\u578b\u63d0\u53d6\u653b\u51fb\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6784\u6210\u5a01\u80c1\uff0c\u53ef\u80fd\u635f\u5bb3\u77e5\u8bc6\u4ea7\u6743\u548c\u7528\u6237\u9690\u79c1\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u5316\u7684\u5206\u6790\u548c\u9632\u5fa1\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u653b\u51fb\uff08\u529f\u80fd\u63d0\u53d6\u3001\u8bad\u7ec3\u6570\u636e\u63d0\u53d6\u3001\u63d0\u793a\u653b\u51fb\uff09\u548c\u5206\u6790\u9632\u5fa1\u673a\u5236\uff08\u6a21\u578b\u4fdd\u62a4\u3001\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u3001\u63d0\u793a\u7b56\u7565\uff09\uff0c\u63d0\u51fa\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5206\u6790\u4e86\u653b\u51fb\u4e0e\u9632\u5fa1\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u6307\u51fa\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u4e3aNLP\u7814\u7a76\u8005\u3001ML\u5de5\u7a0b\u5e08\u548c\u5b89\u5168\u4e13\u4e1a\u4eba\u5458\u63d0\u4f9b\u4e86\u4fdd\u62a4\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u7528\u6307\u5357\uff0c\u5e76\u63d0\u51fa\u4e86\u5e73\u8861\u5b89\u5168\u4e0e\u6a21\u578b\u6548\u7528\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.22557", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22557", "abs": "https://arxiv.org/abs/2506.22557", "authors": ["Boyuan Chen", "Minghao Shao", "Abdul Basit", "Siddharth Garg", "Muhammad Shafique"], "title": "MetaCipher: A General and Extensible Reinforcement Learning Framework for Obfuscation-Based Jailbreak Attacks on Black-Box LLMs", "comment": null, "summary": "The growing capabilities of large language models (LLMs) have exposed them to\nincreasingly sophisticated jailbreak attacks. Among these, obfuscation-based\nattacks -- which encrypt malicious content to evade detection -- remain highly\neffective. By leveraging the reasoning ability of advanced LLMs to interpret\nencrypted prompts, such attacks circumvent conventional defenses that rely on\nkeyword detection or context filtering. These methods are very difficult to\ndefend against, as existing safety mechanisms are not designed to interpret or\ndecode ciphered content. In this work, we propose \\textbf{MetaCipher}, a novel\nobfuscation-based jailbreak framework, along with a reinforcement\nlearning-based dynamic cipher selection mechanism that adaptively chooses\noptimal encryption strategies from a cipher pool. This approach enhances\njailbreak effectiveness and generalizability across diverse task types, victim\nLLMs, and safety guardrails. Our framework is modular and extensible by design,\nsupporting arbitrary cipher families and accommodating evolving adversarial\nstrategies. We complement our method with a large-scale empirical analysis of\ncipher performance across multiple victim LLMs. Within as few as 10 queries,\nMetaCipher achieves over 92\\% attack success rate (ASR) on most recent standard\nmalicious prompt benchmarks against state-of-the-art non-reasoning LLMs, and\nover 74\\% ASR against reasoning-capable LLMs, outperforming all existing\nobfuscation-based jailbreak methods. These results highlight the long-term\nrobustness and adaptability of our approach, making it more resilient than\nprior methods in the face of advancing safety measures.", "AI": {"tldr": "MetaCipher\u662f\u4e00\u79cd\u65b0\u578b\u7684\u57fa\u4e8e\u6df7\u6dc6\u7684\u8d8a\u72f1\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u9009\u62e9\u52a0\u5bc6\u7b56\u7565\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u6210\u529f\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9762\u4e34\u65e5\u76ca\u590d\u6742\u7684\u8d8a\u72f1\u653b\u51fb\uff0c\u5c24\u5176\u662f\u57fa\u4e8e\u6df7\u6dc6\u7684\u653b\u51fb\uff0c\u73b0\u6709\u9632\u5fa1\u673a\u5236\u96be\u4ee5\u5e94\u5bf9\u3002", "method": "\u63d0\u51faMetaCipher\u6846\u67b6\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u7684\u52a8\u6001\u52a0\u5bc6\u7b56\u7565\u9009\u62e9\u673a\u5236\uff0c\u652f\u6301\u591a\u79cd\u52a0\u5bc6\u65b9\u5f0f\u3002", "result": "\u572810\u6b21\u67e5\u8be2\u5185\uff0cMetaCipher\u5bf9\u975e\u63a8\u7406\u578bLLM\u7684\u653b\u51fb\u6210\u529f\u7387\u8fbe92%\uff0c\u5bf9\u63a8\u7406\u578bLLM\u8fbe74%\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MetaCipher\u5177\u6709\u957f\u671f\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u4e0d\u65ad\u5347\u7ea7\u7684\u5b89\u5168\u63aa\u65bd\u3002"}}
{"id": "2506.22656", "categories": ["cs.SE", "cs.AI", "68-04", "D.2.3; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.22656", "abs": "https://arxiv.org/abs/2506.22656", "authors": ["Jiangping Huang", "Dongming Jin", "Weisong Sun", "Yang Liu", "Zhi Jin"], "title": "Knowledge-Guided Multi-Agent Framework for Automated Requirements Development: A Vision", "comment": null, "summary": "This paper envisions a knowledge-guided multi-agent framework named KGMAF for\nautomated requirements development. KGMAF aims to address gaps in current\nautomation systems for SE, which prioritize code development and overlook the\ncomplexities of requirements tasks. KGMAF is composed of six specialized agents\nand an artifact pool to improve efficiency and accuracy. Specifically, KGMAF\noutlines the functionality, actions, and knowledge of each agent and provides\nthe conceptual design of the artifact pool. Our case study highlights the\npotential of KGMAF in real-world scenarios. Finally, we outline several\nresearch opportunities for implementing and enhancing automated requirements\ndevelopment using multi-agent systems. We believe that KGMAF will play a\npivotal role in shaping the future of automated requirements development in the\nera of LLMs.", "AI": {"tldr": "KGMAF\u662f\u4e00\u4e2a\u77e5\u8bc6\u5f15\u5bfc\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u9700\u6c42\u5f00\u53d1\uff0c\u586b\u8865\u5f53\u524dSE\u81ea\u52a8\u5316\u7cfb\u7edf\u5728\u9700\u6c42\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u5316\u7cfb\u7edf\u8fc7\u4e8e\u5173\u6ce8\u4ee3\u7801\u5f00\u53d1\uff0c\u5ffd\u89c6\u4e86\u9700\u6c42\u4efb\u52a1\u7684\u590d\u6742\u6027\uff0cKGMAF\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "KGMAF\u7531\u516d\u4e2a\u4e13\u7528\u4ee3\u7406\u548c\u4e00\u4e2a\u5de5\u4ef6\u6c60\u7ec4\u6210\uff0c\u8be6\u7ec6\u63cf\u8ff0\u4e86\u6bcf\u4e2a\u4ee3\u7406\u7684\u529f\u80fd\u3001\u884c\u4e3a\u548c\u77e5\u8bc6\uff0c\u5e76\u63d0\u4f9b\u4e86\u5de5\u4ef6\u6c60\u7684\u6982\u5ff5\u8bbe\u8ba1\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660eKGMAF\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "KGMAF\u6709\u671b\u5728LLM\u65f6\u4ee3\u63a8\u52a8\u81ea\u52a8\u5316\u9700\u6c42\u5f00\u53d1\u7684\u672a\u6765\uff0c\u5e76\u63d0\u51fa\u4e86\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.22604", "categories": ["cs.AI", "cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.22604", "abs": "https://arxiv.org/abs/2506.22604", "authors": ["David Porfirio", "Vincent Hsiao", "Morgan Fine-Morris", "Leslie Smith", "Laura M. Hiatt"], "title": "Bootstrapping Human-Like Planning via LLMs", "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and\n  Human Interactive Communication (RO-MAN)", "summary": "Robot end users increasingly require accessible means of specifying tasks for\nrobots to perform. Two common end-user programming paradigms include\ndrag-and-drop interfaces and natural language programming. Although natural\nlanguage interfaces harness an intuitive form of human communication,\ndrag-and-drop interfaces enable users to meticulously and precisely dictate the\nkey actions of the robot's task. In this paper, we investigate the degree to\nwhich both approaches can be combined. Specifically, we construct a large\nlanguage model (LLM)-based pipeline that accepts natural language as input and\nproduces human-like action sequences as output, specified at a level of\ngranularity that a human would produce. We then compare these generated action\nsequences to another dataset of hand-specified action sequences. Although our\nresults reveal that larger models tend to outperform smaller ones in the\nproduction of human-like action sequences, smaller models nonetheless achieve\nsatisfactory performance.", "AI": {"tldr": "\u7814\u7a76\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\u548c\u62d6\u653e\u754c\u9762\u4e24\u79cd\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u4eba\u7c7b\u7c7b\u4f3c\u7684\u52a8\u4f5c\u5e8f\u5217\uff0c\u5e76\u4e0e\u624b\u52a8\u6307\u5b9a\u7684\u52a8\u4f5c\u5e8f\u5217\u8fdb\u884c\u6bd4\u8f83\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u548c\u62d6\u653e\u754c\u9762\u7684\u4f18\u52bf\uff0c\u4e3a\u673a\u5668\u4eba\u4efb\u52a1\u63d0\u4f9b\u66f4\u76f4\u89c2\u4e14\u7cbe\u786e\u7684\u7f16\u7a0b\u65b9\u5f0f\u3002", "method": "\u6784\u5efa\u57fa\u4e8eLLM\u7684\u6d41\u7a0b\uff0c\u8f93\u5165\u81ea\u7136\u8bed\u8a00\u5e76\u8f93\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u52a8\u4f5c\u5e8f\u5217\uff0c\u518d\u4e0e\u624b\u52a8\u6307\u5b9a\u7684\u52a8\u4f5c\u5e8f\u5217\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u8f83\u5927\u6a21\u578b\u5728\u751f\u6210\u4eba\u7c7b\u7c7b\u4f3c\u52a8\u4f5c\u5e8f\u5217\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u4f46\u8f83\u5c0f\u6a21\u578b\u4e5f\u80fd\u8fbe\u5230\u6ee1\u610f\u6548\u679c\u3002", "conclusion": "\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u548c\u62d6\u653e\u754c\u9762\u7684\u65b9\u6cd5\u53ef\u884c\uff0c\u4e14\u6a21\u578b\u89c4\u6a21\u5bf9\u6027\u80fd\u6709\u5f71\u54cd\u3002"}}
{"id": "2506.22606", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22606", "abs": "https://arxiv.org/abs/2506.22606", "authors": ["Osama Zafar", "Mina Namazi", "Yuqiao Xu", "Youngjin Yoo", "Erman Ayday"], "title": "A User-Centric, Privacy-Preserving, and Verifiable Ecosystem for Personal Data Management and Utilization", "comment": null, "summary": "In the current paradigm of digital personalized services, the centralized\nmanagement of personal data raises significant privacy concerns, security\nvulnerabilities, and diminished individual autonomy over sensitive information.\nDespite their efficiency, traditional centralized architectures frequently fail\nto satisfy rigorous privacy requirements and expose users to data breaches and\nunauthorized access risks. This pressing challenge calls for a fundamental\nparadigm shift in methodologies for collecting, storing, and utilizing personal\ndata across diverse sectors, including education, healthcare, and finance.\n  This paper introduces a novel decentralized, privacy-preserving architecture\nthat handles heterogeneous personal information, ranging from educational\ncredentials to health records and financial data. Unlike traditional models,\nour system grants users complete data ownership and control, allowing them to\nselectively share information without compromising privacy. The architecture's\nfoundation comprises advanced privacy-enhancing technologies, including secure\nenclaves and federated learning, enabling secure computation, verification, and\ndata sharing. The system supports diverse functionalities, including local\ncomputation, model training, and privacy-preserving data sharing, while\nensuring data credibility and robust user privacy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u7684\u9690\u79c1\u4fdd\u62a4\u67b6\u6784\uff0c\u89e3\u51b3\u96c6\u4e2d\u5f0f\u7ba1\u7406\u4e2a\u4eba\u6570\u636e\u5e26\u6765\u7684\u9690\u79c1\u548c\u5b89\u5168\u95ee\u9898\uff0c\u8d4b\u4e88\u7528\u6237\u6570\u636e\u6240\u6709\u6743\u548c\u63a7\u5236\u6743\u3002", "motivation": "\u96c6\u4e2d\u5f0f\u6570\u636e\u7ba1\u7406\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u548c\u5b89\u5168\u98ce\u9669\uff0c\u7528\u6237\u5bf9\u6570\u636e\u7684\u63a7\u5236\u6743\u4e0d\u8db3\uff0c\u4e9f\u9700\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u4fdd\u62a4\u4e2a\u4eba\u6570\u636e\u9690\u79c1\u3002", "method": "\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u67b6\u6784\uff0c\u7ed3\u5408\u5b89\u5168\u98de\u5730\u548c\u8054\u90a6\u5b66\u4e60\u7b49\u9690\u79c1\u589e\u5f3a\u6280\u672f\uff0c\u652f\u6301\u672c\u5730\u8ba1\u7b97\u3001\u6a21\u578b\u8bad\u7ec3\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u6570\u636e\u5171\u4eab\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u4e86\u7528\u6237\u5bf9\u6570\u636e\u7684\u5b8c\u5168\u63a7\u5236\uff0c\u786e\u4fdd\u6570\u636e\u53ef\u4fe1\u6027\u548c\u9690\u79c1\u5b89\u5168\uff0c\u540c\u65f6\u652f\u6301\u591a\u79cd\u529f\u80fd\u3002", "conclusion": "\u53bb\u4e2d\u5fc3\u5316\u9690\u79c1\u4fdd\u62a4\u67b6\u6784\u662f\u89e3\u51b3\u5f53\u524d\u6570\u636e\u9690\u79c1\u548c\u5b89\u5168\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2506.22688", "categories": ["cs.SE", "D.2.11; D.2.2"], "pdf": "https://arxiv.org/pdf/2506.22688", "abs": "https://arxiv.org/abs/2506.22688", "authors": ["Humberto Cervantes", "Rick Kazman", "Yuanfang Cai"], "title": "An LLM-assisted approach to designing software architectures using ADD", "comment": "30 pages, 12 figures, 7 tables", "summary": "Designing effective software architectures is a complex, iterative process\nthat traditionally relies on expert judgment. This paper proposes an approach\nfor Large Language Model (LLM)-assisted software architecture design using the\nAttribute-Driven Design (ADD) method. By providing an LLM with an explicit\ndescription of ADD, an architect persona, and a structured iteration plan, our\nmethod guides the LLM to collaboratively produce architecture artifacts with a\nhuman architect. We validate the approach through case studies, comparing\ngenerated designs against proven solutions and evaluating them with\nprofessional architects. Results show that our LLM-assisted ADD process can\ngenerate architectures closely aligned with established solutions and partially\nsatisfying architectural drivers, highlighting both the promise and current\nlimitations of using LLMs in architecture design. Our findings emphasize the\nimportance of human oversight and iterative refinement when leveraging LLMs in\nthis domain.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f85\u52a9\u7684\u8f6f\u4ef6\u67b6\u6784\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7ed3\u5408\u5c5e\u6027\u9a71\u52a8\u8bbe\u8ba1\uff08ADD\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u6848\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u67b6\u6784\u8bbe\u8ba1\u4f9d\u8d56\u4e13\u5bb6\u5224\u65ad\uff0c\u8fc7\u7a0b\u590d\u6742\u4e14\u8fed\u4ee3\u6027\u5f3a\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22LLM\u5728\u67b6\u6784\u8bbe\u8ba1\u4e2d\u7684\u8f85\u52a9\u4f5c\u7528\u3002", "method": "\u901a\u8fc7\u4e3aLLM\u63d0\u4f9bADD\u65b9\u6cd5\u7684\u660e\u786e\u63cf\u8ff0\u3001\u67b6\u6784\u5e08\u89d2\u8272\u548c\u7ed3\u6784\u5316\u8fed\u4ee3\u8ba1\u5212\uff0c\u6307\u5bfcLLM\u4e0e\u4eba\u7c7b\u67b6\u6784\u5e08\u534f\u4f5c\u751f\u6210\u67b6\u6784\u8bbe\u8ba1\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cLLM\u8f85\u52a9\u7684ADD\u65b9\u6cd5\u80fd\u751f\u6210\u4e0e\u6210\u719f\u65b9\u6848\u63a5\u8fd1\u7684\u8bbe\u8ba1\uff0c\u90e8\u5206\u6ee1\u8db3\u67b6\u6784\u9a71\u52a8\u56e0\u7d20\uff0c\u4f46\u4e5f\u5b58\u5728\u5c40\u9650\u6027\u3002", "conclusion": "LLM\u5728\u67b6\u6784\u8bbe\u8ba1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u4eba\u7c7b\u76d1\u7763\u548c\u8fed\u4ee3\u4f18\u5316\u3002"}}
{"id": "2506.22609", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22609", "abs": "https://arxiv.org/abs/2506.22609", "authors": ["Graham Todd", "Alexander G. Padula", "Dennis J. N. J. Soemers", "Julian Togelius"], "title": "Ludax: A GPU-Accelerated Domain Specific Language for Board Games", "comment": "18 pages, 3 figures", "summary": "Games have long been used as benchmarks and testing environments for research\nin artificial intelligence. A key step in supporting this research was the\ndevelopment of game description languages: frameworks that compile\ndomain-specific code into playable and simulatable game environments, allowing\nresearchers to generalize their algorithms and approaches across multiple games\nwithout having to manually implement each one. More recently, progress in\nreinforcement learning (RL) has been largely driven by advances in hardware\nacceleration. Libraries like JAX allow practitioners to take full advantage of\ncutting-edge computing hardware, often speeding up training and testing by\norders of magnitude. Here, we present a synthesis of these strands of research:\na domain-specific language for board games which automatically compiles into\nhardware-accelerated code. Our framework, Ludax, combines the generality of\ngame description languages with the speed of modern parallel processing\nhardware and is designed to fit neatly into existing deep learning pipelines.\nWe envision Ludax as a tool to help accelerate games research generally, from\nRL to cognitive science, by enabling rapid simulation and providing a flexible\nrepresentation scheme. We present a detailed breakdown of Ludax's description\nlanguage and technical notes on the compilation process, along with speed\nbenchmarking and a demonstration of training RL agents. The Ludax framework,\nalong with implementations of existing board games, is open-source and freely\navailable.", "AI": {"tldr": "Ludax\u662f\u4e00\u4e2a\u7ed3\u5408\u6e38\u620f\u63cf\u8ff0\u8bed\u8a00\u548c\u786c\u4ef6\u52a0\u901f\u7684\u6846\u67b6\uff0c\u65e8\u5728\u52a0\u901f\u6e38\u620f\u7814\u7a76\uff0c\u652f\u6301\u5feb\u901f\u6a21\u62df\u548c\u7075\u6d3b\u8868\u793a\u3002", "motivation": "\u6e38\u620f\u5728\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u4e2d\u4f5c\u4e3a\u57fa\u51c6\u548c\u6d4b\u8bd5\u73af\u5883\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u7f3a\u4e4f\u786c\u4ef6\u52a0\u901f\u652f\u6301\u3002", "method": "\u5f00\u53d1Ludax\uff0c\u4e00\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u81ea\u52a8\u7f16\u8bd1\u4e3a\u786c\u4ef6\u52a0\u901f\u4ee3\u7801\uff0c\u652f\u6301\u5e76\u884c\u5904\u7406\u3002", "result": "Ludax\u63d0\u4f9b\u5feb\u901f\u6a21\u62df\u548c\u7075\u6d3b\u8868\u793a\uff0c\u9002\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u7b49\u7814\u7a76\u3002", "conclusion": "Ludax\u5f00\u6e90\u6846\u67b6\u6709\u671b\u52a0\u901f\u6e38\u620f\u7814\u7a76\uff0c\u652f\u6301\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2506.22639", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.22639", "abs": "https://arxiv.org/abs/2506.22639", "authors": ["Michael A. Specter", "Mihai Christodorescu", "Abbie Farr", "Bo Ma", "Robin Lassonde", "Xiaoyang Xu", "Xiang Pan", "Fengguo Wei", "Saswat Anand", "Dave Kleidermacher"], "title": "Fingerprinting SDKs for Mobile Apps and Where to Find Them: Understanding the Market for Device Fingerprinting", "comment": "To appear in ACM CCS 2025. Extended from conference version; has\n  added appendices more inclusive author list", "summary": "This paper presents a large-scale analysis of fingerprinting-like behavior in\nthe mobile application ecosystem. We take a market-based approach, focusing on\nthird-party tracking as enabled by applications' common use of third-party\nSDKs. Our dataset consists of over 228,000 SDKs from popular Maven\nrepositories, 178,000 Android applications collected from the Google Play\nstore, and our static analysis pipeline detects exfiltration of over 500\nindividual signals. To the best of our knowledge, this represents the\nlargest-scale analysis of SDK behavior undertaken to date.\n  We find that Ads SDKs (the ostensible focus of industry efforts such as\nApple's App Tracking Transparency and Google's Privacy Sandbox) appear to be\nthe source of only 30.56% of the fingerprinting behaviors. A surprising 23.92%\noriginate from SDKs whose purpose was unknown or unclear. Furthermore, Security\nand Authentication SDKs are linked to only 11.7% of likely fingerprinting\ninstances. These results suggest that addressing fingerprinting solely in\nspecific market-segment contexts like advertising may offer incomplete benefit.\nEnforcing anti-fingerprinting policies is also complex, as we observe a sparse\ndistribution of signals and APIs used by likely fingerprinting SDKs. For\ninstance, only 2% of exfiltrated APIs are used by more than 75% of SDKs, making\nit difficult to rely on user permissions to control fingerprinting behavior.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u79fb\u52a8\u5e94\u7528\u751f\u6001\u7cfb\u7edf\u4e2d\u7c7b\u4f3c\u6307\u7eb9\u8bc6\u522b\u7684\u884c\u4e3a\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5206\u6790\uff0c\u53d1\u73b0\u5e7f\u544aSDK\u4ec5\u536030.56%\u7684\u6307\u7eb9\u884c\u4e3a\uff0c\u800c23.92%\u6765\u81ea\u76ee\u7684\u4e0d\u660e\u7684SDK\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63ed\u793a\u79fb\u52a8\u5e94\u7528\u4e2d\u7b2c\u4e09\u65b9SDK\u7684\u6307\u7eb9\u8bc6\u522b\u884c\u4e3a\uff0c\u5c24\u5176\u662f\u5e7f\u544aSDK\u4ee5\u5916\u7684\u5176\u4ed6\u6765\u6e90\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5206\u6790228,000\u591a\u4e2aSDK\u548c178,000\u4e2aAndroid\u5e94\u7528\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u68c0\u6d4b500\u591a\u4e2a\u4fe1\u53f7\u7684\u5916\u6cc4\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5e7f\u544aSDK\u4ec5\u5360\u6307\u7eb9\u884c\u4e3a\u768430.56%\uff0c23.92%\u6765\u81ea\u672a\u77e5\u76ee\u7684SDK\uff0c\u5b89\u5168\u4e0e\u8ba4\u8bc1SDK\u536011.7%\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\u4ec5\u9488\u5bf9\u7279\u5b9a\u5e02\u573a\uff08\u5982\u5e7f\u544a\uff09\u7684\u6307\u7eb9\u8bc6\u522b\u653f\u7b56\u6548\u679c\u6709\u9650\uff0c\u9700\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.22703", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22703", "abs": "https://arxiv.org/abs/2506.22703", "authors": ["Wali Mohammad Abdullah", "Azmain Kabir"], "title": "P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code", "comment": null, "summary": "We present P4OMP, a retrieval-augmented framework for transforming serial\nC/C++ code into OpenMP-annotated parallel code using large language models\n(LLMs). To our knowledge, this is the first system to apply retrieval-based\nprompting for OpenMP pragma correctness without model fine-tuning or compiler\ninstrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with\nstructured instructional knowledge from OpenMP tutorials to improve the\nreliability of prompt-driven code generation. By grounding generation in the\nretrieved context, P4OMP improves syntactic correctness compared to baseline\nprompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline,\nGPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world\nC++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites.\nP4OMP achieves 100% compilation success on all parallelizable cases, while the\nbaseline fails to compile in 20 out of 108 cases. Six cases that rely on\nnon-random-access iterators or thread-unsafe constructs are excluded due to\nfundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP\nconsistently avoids scoping errors, syntactic misuse, and invalid directive\ncombinations that commonly affect baseline-generated code. We further\ndemonstrate strong runtime scaling across seven compute-intensive benchmarks on\nan HPC cluster. P4OMP offers a robust, modular pipeline that significantly\nimproves the reliability and applicability of LLM-generated OpenMP code.", "AI": {"tldr": "P4OMP\u662f\u4e00\u4e2a\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u7684\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u4e32\u884cC/C++\u4ee3\u7801\u8f6c\u6362\u4e3aOpenMP\u5e76\u884c\u4ee3\u7801\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u7f16\u8bd1\u5668\u63d2\u6869\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u751f\u6210OpenMP\u5e76\u884c\u4ee3\u7801\u65f6\u7684\u8bed\u6cd5\u9519\u8bef\u548c\u53ef\u9760\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u63d0\u9ad8\u4ee3\u7801\u7684\u6b63\u786e\u6027\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\uff0c\u7ed3\u5408OpenMP\u6559\u7a0b\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\uff0c\u4f18\u5316\u63d0\u793a\u9a71\u52a8\u7684\u4ee3\u7801\u751f\u6210\u3002", "result": "\u5728108\u4e2a\u771f\u5b9eC++\u7a0b\u5e8f\u6d4b\u8bd5\u4e2d\uff0cP4OMP\u5b9e\u73b0\u4e86100%\u7684\u7f16\u8bd1\u6210\u529f\u7387\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u572820\u4e2a\u6848\u4f8b\u4e2d\u5931\u8d25\u3002", "conclusion": "P4OMP\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210OpenMP\u4ee3\u7801\u7684\u53ef\u9760\u6027\u548c\u9002\u7528\u6027\uff0c\u907f\u514d\u4e86\u5e38\u89c1\u7684\u8bed\u6cd5\u9519\u8bef\u548c\u65e0\u6548\u6307\u4ee4\u7ec4\u5408\u3002"}}
{"id": "2506.22653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22653", "abs": "https://arxiv.org/abs/2506.22653", "authors": ["Michael Grosskopf", "Russell Bent", "Rahul Somasundaram", "Isaac Michaud", "Arthur Lui", "Nathan Debardeleben", "Earl Lawrence"], "title": "URSA: The Universal Research and Scientific Agent", "comment": "31 pages, 9 figures", "summary": "Large language models (LLMs) have moved far beyond their initial form as\nsimple chatbots, now carrying out complex reasoning, planning, writing, coding,\nand research tasks. These skills overlap significantly with those that human\nscientists use day-to-day to solve complex problems that drive the cutting edge\nof research. Using LLMs in \"agentic\" AI has the potential to revolutionize\nmodern science and remove bottlenecks to progress. In this work, we present\nURSA, a scientific agent ecosystem for accelerating research tasks. URSA\nconsists of a set of modular agents and tools, including coupling to advanced\nphysics simulation codes, that can be combined to address scientific problems\nof varied complexity and impact. This work highlights the architecture of URSA,\nas well as examples that highlight the potential of the system.", "AI": {"tldr": "URSA\u662f\u4e00\u4e2a\u79d1\u5b66\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\uff0c\u65e8\u5728\u901a\u8fc7\u6a21\u5757\u5316\u4ee3\u7406\u548c\u5de5\u5177\u52a0\u901f\u7814\u7a76\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u5176\u5728\u89e3\u51b3\u590d\u6742\u79d1\u5b66\u95ee\u9898\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5df2\u5177\u5907\u590d\u6742\u63a8\u7406\u3001\u89c4\u5212\u3001\u5199\u4f5c\u3001\u7f16\u7801\u548c\u7814\u7a76\u80fd\u529b\uff0c\u4e0e\u79d1\u5b66\u5bb6\u65e5\u5e38\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u9ad8\u5ea6\u91cd\u5408\uff0c\u5229\u7528LLMs\u7684\u201c\u4ee3\u7406\u201dAI\u6709\u671b\u63a8\u52a8\u79d1\u5b66\u8fdb\u6b65\u3002", "method": "\u63d0\u51faURSA\u7cfb\u7edf\uff0c\u5305\u542b\u6a21\u5757\u5316\u4ee3\u7406\u548c\u5de5\u5177\uff08\u5982\u9ad8\u7ea7\u7269\u7406\u6a21\u62df\u4ee3\u7801\uff09\uff0c\u53ef\u7ec4\u5408\u7528\u4e8e\u89e3\u51b3\u4e0d\u540c\u590d\u6742\u5ea6\u548c\u5f71\u54cd\u529b\u7684\u79d1\u5b66\u95ee\u9898\u3002", "result": "\u5c55\u793a\u4e86URSA\u7684\u67b6\u6784\u53ca\u5176\u5728\u89e3\u51b3\u79d1\u5b66\u95ee\u9898\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "URSA\u7cfb\u7edf\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u5de5\u5177\u96c6\u6210\uff0c\u4e3a\u52a0\u901f\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.22666", "categories": ["cs.CR", "cs.CL", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.22666", "abs": "https://arxiv.org/abs/2506.22666", "authors": ["Anamika Lochab", "Lu Yan", "Patrick Pynadath", "Xiangyu Zhang", "Ruqi Zhang"], "title": "VERA: Variational Inference Framework for Jailbreaking Large Language Models", "comment": null, "summary": "The rise of API-only access to state-of-the-art LLMs highlights the need for\neffective black-box jailbreak methods to identify model vulnerabilities in\nreal-world settings. Without a principled objective for gradient-based\noptimization, most existing approaches rely on genetic algorithms, which are\nlimited by their initialization and dependence on manually curated prompt\npools. Furthermore, these methods require individual optimization for each\nprompt, failing to provide a comprehensive characterization of model\nvulnerabilities. To address this gap, we introduce VERA: Variational infErence\nfRamework for jAilbreaking. VERA casts black-box jailbreak prompting as a\nvariational inference problem, training a small attacker LLM to approximate the\ntarget LLM's posterior over adversarial prompts. Once trained, the attacker can\ngenerate diverse, fluent jailbreak prompts for a target query without\nre-optimization. Experimental results show that VERA achieves strong\nperformance across a range of target LLMs, highlighting the value of\nprobabilistic inference for adversarial prompt generation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVERA\u7684\u53d8\u5206\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u9ed1\u76d2\u8d8a\u72f1\u63d0\u793a\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9057\u4f20\u7b97\u6cd5\u548c\u624b\u52a8\u4f18\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u9ed1\u76d2\u8d8a\u72f1\u65b9\u6cd5\u4f9d\u8d56\u9057\u4f20\u7b97\u6cd5\u548c\u624b\u52a8\u4f18\u5316\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u6f0f\u6d1e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "VERA\u5c06\u9ed1\u76d2\u8d8a\u72f1\u63d0\u793a\u751f\u6210\u5efa\u6a21\u4e3a\u53d8\u5206\u63a8\u7406\u95ee\u9898\uff0c\u8bad\u7ec3\u4e00\u4e2a\u5c0f\u578b\u653b\u51fb\u8005LLM\u6765\u8fd1\u4f3c\u76ee\u6807LLM\u7684\u540e\u9a8c\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cVERA\u5728\u591a\u79cd\u76ee\u6807LLM\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9a8c\u8bc1\u4e86\u6982\u7387\u63a8\u7406\u5728\u5bf9\u6297\u63d0\u793a\u751f\u6210\u4e2d\u7684\u4ef7\u503c\u3002", "conclusion": "VERA\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u5168\u9762\u7684\u9ed1\u76d2\u8d8a\u72f1\u65b9\u6cd5\uff0c\u4e3a\u6a21\u578b\u6f0f\u6d1e\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.22742", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22742", "abs": "https://arxiv.org/abs/2506.22742", "authors": ["Wali Mohammad Abdullah", "Md. Morshedul Islam", "Devraj Parmar", "Happy Hasmukhbhai Patel", "Sindhuja Prabhakaran", "Baidya Saha"], "title": "RAILS: Retrieval-Augmented Intelligence for Learning Software Development", "comment": null, "summary": "Large Language Models (LLMs) like GPT-3.5-Turbo are increasingly used to\nassist software development, yet they often produce incomplete code or\nincorrect imports, especially when lacking access to external or\nproject-specific documentation. We introduce RAILS (Retrieval-Augmented\nIntelligence for Learning Software Development), a framework that augments LLM\nprompts with semantically retrieved context from curated Java resources using\nFAISS and OpenAI embeddings. RAILS incorporates an iterative validation loop\nguided by compiler feedback to refine suggestions. We evaluated RAILS on 78\nreal-world Java import error cases spanning standard libraries, GUI APIs,\nexternal tools, and custom utilities. Despite using the same LLM, RAILS\noutperforms baseline prompting by preserving intent, avoiding hallucinations,\nand surfacing correct imports even when libraries are unavailable locally.\nFuture work will integrate symbolic filtering via PostgreSQL and extend support\nto other languages and IDEs.", "AI": {"tldr": "RAILS\u6846\u67b6\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u548c\u8fed\u4ee3\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728Java\u5f00\u53d1\u4e2d\u7684\u4ee3\u7801\u8865\u5168\u51c6\u786e\u6027\u3002", "motivation": "LLM\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e38\u751f\u6210\u4e0d\u5b8c\u6574\u6216\u9519\u8bef\u7684\u4ee3\u7801\uff0c\u5c24\u5176\u662f\u7f3a\u4e4f\u5916\u90e8\u6587\u6863\u652f\u6301\u65f6\u3002", "method": "RAILS\u7ed3\u5408FAISS\u548cOpenAI\u5d4c\u5165\uff0c\u4eceJava\u8d44\u6e90\u4e2d\u68c0\u7d22\u8bed\u4e49\u4e0a\u4e0b\u6587\uff0c\u5e76\u901a\u8fc7\u7f16\u8bd1\u5668\u53cd\u9988\u8fed\u4ee3\u9a8c\u8bc1\u3002", "result": "\u572878\u4e2aJava\u5bfc\u5165\u9519\u8bef\u6848\u4f8b\u4e2d\uff0cRAILS\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u4fdd\u6301\u610f\u56fe\u5e76\u907f\u514d\u5e7b\u89c9\u3002", "conclusion": "\u672a\u6765\u5c06\u6269\u5c55RAILS\u652f\u6301\u66f4\u591a\u8bed\u8a00\u548cIDE\uff0c\u5e76\u96c6\u6210\u7b26\u53f7\u8fc7\u6ee4\u3002"}}
{"id": "2506.22740", "categories": ["cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.22740", "abs": "https://arxiv.org/abs/2506.22740", "authors": ["Jessica Hullman", "Ziyang Guo", "Berk Ustun"], "title": "Explanations are a means to an end", "comment": null, "summary": "Modern methods for explainable machine learning are designed to describe how\nmodels map inputs to outputs--without deep consideration of how these\nexplanations will be used in practice. This paper argues that explanations\nshould be designed and evaluated with a specific end in mind. We describe how\nto formalize this end in a framework based in statistical decision theory. We\nshow how this functionally-grounded approach can be applied across diverse use\ncases, such as clinical decision support, providing recourse, or debugging. We\ndemonstrate its use to characterize the maximum \"boost\" in performance on a\nparticular task that an explanation could provide an idealized decision-maker,\npreventing misuse due to ambiguity by forcing researchers to specify concrete\nuse cases that can be analyzed in light of models of expected explanation use.\nWe argue that evaluation should meld theoretical and empirical perspectives on\nthe value of explanation, and contribute definitions that span these\nperspectives.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7edf\u8ba1\u51b3\u7b56\u7406\u8bba\u7684\u6846\u67b6\uff0c\u5f3a\u8c03\u89e3\u91ca\u6027\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5e94\u6839\u636e\u5177\u4f53\u7528\u9014\u8bbe\u8ba1\u548c\u8bc4\u4f30\uff0c\u907f\u514d\u6a21\u7cca\u6027\u3002", "motivation": "\u5f53\u524d\u89e3\u91ca\u6027\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u5b9e\u9645\u7528\u9014\u7684\u6df1\u5165\u8003\u8651\uff0c\u53ef\u80fd\u5bfc\u81f4\u89e3\u91ca\u7684\u8bef\u7528\u6216\u65e0\u6548\u3002", "method": "\u91c7\u7528\u7edf\u8ba1\u51b3\u7b56\u7406\u8bba\u6846\u67b6\uff0c\u660e\u786e\u89e3\u91ca\u7684\u5177\u4f53\u7528\u9014\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u5408\u7684\u65b9\u5f0f\u8bc4\u4f30\u89e3\u91ca\u7684\u4ef7\u503c\u3002", "result": "\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3001\u63d0\u4f9b\u8865\u6551\u63aa\u65bd\u548c\u8c03\u8bd5\u7b49\u591a\u6837\u5316\u7528\u4f8b\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u91cf\u5316\u4e86\u7406\u60f3\u51b3\u7b56\u8005\u53ef\u80fd\u83b7\u5f97\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u89e3\u91ca\u6027\u65b9\u6cd5\u5e94\u9488\u5bf9\u5177\u4f53\u7528\u9014\u8bbe\u8ba1\uff0c\u5e76\u901a\u8fc7\u660e\u786e\u7528\u4f8b\u548c\u7ed3\u5408\u7406\u8bba\u5b9e\u8bc1\u8bc4\u4f30\u6765\u63d0\u5347\u5176\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2506.22706", "categories": ["cs.CR", "cs.AI", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.22706", "abs": "https://arxiv.org/abs/2506.22706", "authors": ["Arun Ramamurthy", "Neil Dhir"], "title": "General Autonomous Cybersecurity Defense: Learning Robust Policies for Dynamic Topologies and Diverse Attackers", "comment": null, "summary": "In the face of evolving cyber threats such as malware, ransomware and\nphishing, autonomous cybersecurity defense (ACD) systems have become essential\nfor real-time threat detection and response with optional human intervention.\nHowever, existing ACD systems rely on limiting assumptions, particularly the\nstationarity of the underlying network dynamics. In real-world scenarios,\nnetwork topologies can change due to actions taken by attackers or defenders,\nsystem failures, or time evolution of networks, leading to failures in the\nadaptive capabilities of current defense agents. Moreover, many agents are\ntrained on static environments, resulting in overfitting to specific\ntopologies, which hampers their ability to generalize to out-of-distribution\nnetwork topologies. This work addresses these challenges by exploring methods\nfor developing agents to learn generalizable policies across dynamic network\nenvironments -- general ACD (GACD).", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u52a8\u6001\u7f51\u7edc\u73af\u5883\u4e2d\u5f00\u53d1\u901a\u7528\u81ea\u4e3b\u7f51\u7edc\u5b89\u5168\u9632\u5fa1\uff08GACD\uff09\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u56e0\u9759\u6001\u5047\u8bbe\u548c\u8fc7\u62df\u5408\u800c\u65e0\u6cd5\u9002\u5e94\u771f\u5b9e\u7f51\u7edc\u53d8\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u81ea\u4e3b\u7f51\u7edc\u5b89\u5168\u9632\u5fa1\uff08ACD\uff09\u7cfb\u7edf\u4f9d\u8d56\u9759\u6001\u7f51\u7edc\u5047\u8bbe\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u7f51\u7edc\u62d3\u6251\uff0c\u5bfc\u81f4\u9632\u5fa1\u80fd\u529b\u53d7\u9650\u3002", "method": "\u7814\u7a76\u5f00\u53d1\u901a\u7528\u81ea\u4e3b\u7f51\u7edc\u5b89\u5168\u9632\u5fa1\uff08GACD\uff09\u7cfb\u7edf\uff0c\u65e8\u5728\u5b66\u4e60\u9002\u7528\u4e8e\u52a8\u6001\u7f51\u7edc\u73af\u5883\u7684\u901a\u7528\u7b56\u7565\u3002", "result": "\u63d0\u51fa\u4e86\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u5c40\u9650\u6027\u7684\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u7b56\u7565\u7684\u901a\u7528\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u901a\u8fc7GACD\u7cfb\u7edf\uff0c\u53ef\u4ee5\u63d0\u5347\u9632\u5fa1\u4ee3\u7406\u5728\u52a8\u6001\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.22752", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.22752", "abs": "https://arxiv.org/abs/2506.22752", "authors": ["Havvanur Dervi\u015fo\u011flu", "Ru\u015fen Halepmollas\u0131", "Elif Eyvaz"], "title": "Privacy-Preserving Methods for Bug Severity Prediction", "comment": null, "summary": "Bug severity prediction is a critical task in software engineering as it\nenables more efficient resource allocation and prioritization in software\nmaintenance. While AI-based analyses and models significantly require access to\nextensive datasets, industrial applications face challenges due to data-sharing\nconstraints and the limited availability of labeled data. In this study, we\ninvestigate method-level bug severity prediction using source code metrics and\nLarge Language Models (LLMs) with two widely used datasets. We compare the\nperformance of models trained using centralized learning, federated learning,\nand synthetic data generation. Our experimental results, obtained using two\nwidely recognized software defect datasets, indicate that models trained with\nfederated learning and synthetic data achieve comparable results to centrally\ntrained models without data sharing. Our finding highlights the potential of\nprivacy-preserving approaches such as federated learning and synthetic data\ngeneration to enable effective bug severity prediction in industrial context\nwhere data sharing is a major challenge.\n  The source code and dataset are available at our GitHub repository:\nhttps://github.com/drvshavva/EASE2025-Privacy-Preserving-Methods-for-Bug-Severity-Prediction.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6e90\u4ee3\u7801\u6307\u6807\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65b9\u6cd5\u7ea7Bug\u4e25\u91cd\u6027\u9884\u6d4b\uff0c\u6bd4\u8f83\u4e86\u96c6\u4e2d\u5b66\u4e60\u3001\u8054\u90a6\u5b66\u4e60\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u6548\u679c\uff0c\u53d1\u73b0\u8054\u90a6\u5b66\u4e60\u548c\u5408\u6210\u6570\u636e\u5728\u4e0d\u5171\u4eab\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u8fbe\u5230\u4e0e\u96c6\u4e2d\u5b66\u4e60\u76f8\u5f53\u7684\u6548\u679c\u3002", "motivation": "\u5de5\u4e1a\u5e94\u7528\u4e2d\u7531\u4e8e\u6570\u636e\u5171\u4eab\u9650\u5236\u548c\u6807\u8bb0\u6570\u636e\u6709\u9650\uff0cAI\u6a21\u578b\u96be\u4ee5\u83b7\u53d6\u5927\u91cf\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u9690\u79c1\u4fdd\u62a4\u7684\u65b9\u6cd5\u6765\u8fdb\u884cBug\u4e25\u91cd\u6027\u9884\u6d4b\u3002", "method": "\u4f7f\u7528\u6e90\u4ee3\u7801\u6307\u6807\u548cLLM\uff0c\u6bd4\u8f83\u96c6\u4e2d\u5b66\u4e60\u3001\u8054\u90a6\u5b66\u4e60\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u4e09\u79cd\u65b9\u6cd5\u5728Bug\u4e25\u91cd\u6027\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8054\u90a6\u5b66\u4e60\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u6a21\u578b\u5728\u4e0d\u5171\u4eab\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u6027\u80fd\u4e0e\u96c6\u4e2d\u5b66\u4e60\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u662f\u89e3\u51b3\u5de5\u4e1a\u573a\u666f\u4e2d\u6570\u636e\u5171\u4eab\u6311\u6218\u7684\u6709\u6548\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u3002"}}
{"id": "2506.22774", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.22774", "abs": "https://arxiv.org/abs/2506.22774", "authors": ["Michael Papademas", "Xenia Ziouvelou", "Antonis Troumpoukis", "Vangelis Karkaletsis"], "title": "Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems", "comment": null, "summary": "Artificial Intelligence (AI) technology epitomizes the complex challenges\nposed by human-made artifacts, particularly those widely integrated into\nsociety and exert significant influence, highlighting potential benefits and\ntheir negative consequences. While other technologies may also pose substantial\nrisks, AI's pervasive reach makes its societal effects especially profound. The\ncomplexity of AI systems, coupled with their remarkable capabilities, can lead\nto a reliance on technologies that operate beyond direct human oversight or\nunderstanding. To mitigate the risks that arise, several theoretical tools and\nguidelines have been developed, alongside efforts to create technological tools\naimed at safeguarding Trustworthy AI. The guidelines take a more holistic view\nof the issue but fail to provide techniques for quantifying trustworthiness.\nConversely, while technological tools are better at achieving such\nquantification, they lack a holistic perspective, focusing instead on specific\naspects of Trustworthy AI. This paper aims to introduce an assessment method\nthat combines the ethical components of Trustworthy AI with the algorithmic\nprocesses of PageRank and TrustRank. The goal is to establish an assessment\nframework that minimizes the subjectivity inherent in the self-assessment\ntechniques prevalent in the field by introducing algorithmic criteria. The\napplication of our approach indicates that a holistic assessment of an AI\nsystem's trustworthiness can be achieved by providing quantitative insights\nwhile considering the theoretical content of relevant guidelines.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4f26\u7406\u4e0e\u7b97\u6cd5\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u65e8\u5728\u91cf\u5316AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\uff0c\u5f25\u8865\u73b0\u6709\u6307\u5357\u4e0e\u6280\u672f\u5de5\u5177\u7684\u4e0d\u8db3\u3002", "motivation": "AI\u7684\u5e7f\u6cdb\u5f71\u54cd\u53ca\u5176\u590d\u6742\u6027\u5bfc\u81f4\u5bf9\u5176\u53ef\u4fe1\u5ea6\u7684\u8bc4\u4f30\u9700\u6c42\u589e\u52a0\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u7f3a\u4e4f\u91cf\u5316\u80fd\u529b\uff0c\u8981\u4e48\u7f3a\u4e4f\u5168\u9762\u89c6\u89d2\u3002", "method": "\u7ed3\u5408Trustworthy AI\u7684\u4f26\u7406\u7ec4\u4ef6\u4e0ePageRank\u3001TrustRank\u7b97\u6cd5\uff0c\u63d0\u51fa\u4e00\u79cd\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u63d0\u4f9b\u5b9a\u91cf\u5206\u6790\uff0c\u540c\u65f6\u517c\u987e\u4f26\u7406\u6307\u5357\u7684\u7406\u8bba\u5185\u5bb9\uff0c\u5b9e\u73b0\u53ef\u4fe1\u5ea6\u7684\u5168\u9762\u8bc4\u4f30\u3002", "conclusion": "\u901a\u8fc7\u7b97\u6cd5\u4e0e\u4f26\u7406\u7684\u7ed3\u5408\uff0c\u53ef\u4ee5\u66f4\u5ba2\u89c2\u5730\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\uff0c\u51cf\u5c11\u4e3b\u89c2\u6027\u3002"}}
{"id": "2506.22722", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22722", "abs": "https://arxiv.org/abs/2506.22722", "authors": ["Anmin Fu", "Fanyu Meng", "Huaibing Peng", "Hua Ma", "Zhi Zhang", "Yifeng Zheng", "Willy Susilo", "Yansong Gao"], "title": "Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks", "comment": null, "summary": "The proposed UniGuard is the first unified online detection framework capable\nof simultaneously addressing adversarial examples and backdoor attacks.\nUniGuard builds upon two key insights: first, both AE and backdoor attacks have\nto compromise the inference phase, making it possible to tackle them\nsimultaneously during run-time via online detection. Second, an adversarial\ninput, whether a perturbed sample in AE attacks or a trigger-carrying sample in\nbackdoor attacks, exhibits distinctive trajectory signatures from a benign\nsample as it propagates through the layers of a DL model in forward inference.\nThe propagation trajectory of the adversarial sample must deviate from that of\nits benign counterpart; otherwise, the adversarial objective cannot be\nfulfilled. Detecting these trajectory signatures is inherently challenging due\nto their subtlety; UniGuard overcomes this by treating the propagation\ntrajectory as a time-series signal, leveraging LSTM and spectrum transformation\nto amplify differences between adversarial and benign trajectories that are\nsubtle in the time domain. UniGuard exceptional efficiency and effectiveness\nhave been extensively validated across various modalities (image, text, and\naudio) and tasks (classification and regression), ranging from diverse model\narchitectures against a wide range of AE attacks and backdoor attacks,\nincluding challenging partial backdoors and dynamic triggers. When compared to\nSOTA methods, including ContraNet (NDSS 22) specific for AE detection and TED\n(IEEE SP 24) specific for backdoor detection, UniGuard consistently\ndemonstrates superior performance, even when matched against each method's\nstrengths in addressing their respective threats-each SOTA fails to parts of\nattack strategies while UniGuard succeeds for all.", "AI": {"tldr": "UniGuard\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u5728\u7ebf\u68c0\u6d4b\u6846\u67b6\uff0c\u80fd\u591f\u540c\u65f6\u68c0\u6d4b\u5bf9\u6297\u6027\u793a\u4f8b\u548c\u540e\u95e8\u653b\u51fb\uff0c\u901a\u8fc7\u5206\u6790\u8f93\u5165\u5728\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u4f20\u64ad\u8f68\u8ff9\u5dee\u5f02\u6765\u5b9e\u73b0\u9ad8\u6548\u68c0\u6d4b\u3002", "motivation": "\u5bf9\u6297\u6027\u793a\u4f8b\uff08AE\uff09\u548c\u540e\u95e8\u653b\u51fb\u90fd\u4f1a\u5f71\u54cd\u6a21\u578b\u7684\u63a8\u7406\u9636\u6bb5\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u7684\u5728\u7ebf\u68c0\u6d4b\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e24\u79cd\u5a01\u80c1\u3002", "method": "UniGuard\u5c06\u8f93\u5165\u5728\u6a21\u578b\u4e2d\u7684\u4f20\u64ad\u8f68\u8ff9\u89c6\u4e3a\u65f6\u95f4\u5e8f\u5217\u4fe1\u53f7\uff0c\u5229\u7528LSTM\u548c\u9891\u8c31\u53d8\u6362\u653e\u5927\u5bf9\u6297\u6027\u548c\u826f\u6027\u8f68\u8ff9\u4e4b\u95f4\u7684\u5dee\u5f02\u3002", "result": "UniGuard\u5728\u591a\u79cd\u6a21\u6001\uff08\u56fe\u50cf\u3001\u6587\u672c\u3001\u97f3\u9891\uff09\u548c\u4efb\u52a1\uff08\u5206\u7c7b\u548c\u56de\u5f52\uff09\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u9488\u5bf9\u5355\u4e00\u5a01\u80c1\u7684SOTA\u65b9\u6cd5\u3002", "conclusion": "UniGuard\u662f\u9996\u4e2a\u80fd\u591f\u540c\u65f6\u5904\u7406\u5bf9\u6297\u6027\u793a\u4f8b\u548c\u540e\u95e8\u653b\u51fb\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.22776", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2506.22776", "abs": "https://arxiv.org/abs/2506.22776", "authors": ["Sen Fang", "Weiyuan Ding", "Antonio Mastropaolo", "Bowen Xu"], "title": "Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation", "comment": "13 pages, 6 figures", "summary": "Quantization has emerged as a mainstream method for compressing Large\nLanguage Models (LLMs), reducing memory requirements and accelerating inference\nwithout architectural modifications. While existing research primarily focuses\non evaluating the effectiveness of quantized LLMs compared to their original\ncounterparts, the impact on robustness remains largely unexplored.In this\npaper, we present the first systematic investigation of how quantization\naffects the robustness of LLMs in code generation tasks. Through extensive\nexperiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and\nStarCoder) with parameter scales ranging from 350M to 33B, we evaluate\nrobustness from dual perspectives: adversarial attacks on input prompts and\nnoise perturbations on model architecture. Our findings challenge conventional\nwisdom by demonstrating that quantized LLMs often exhibit superior robustness\ncompared to their full-precision counterparts, with 51.59% versus 42.86% of our\nadversarial experiments showing better resilience in quantized LLMs. Similarly,\nour noise perturbation experiments also confirm that LLMs after quantitation\ngenerally withstand higher levels of weight disturbances. These results suggest\nthat quantization not only reduces computational requirements but can actually\nenhance LLMs' reliability in code generation tasks, providing valuable insights\nfor developing more robust and efficient LLM deployment strategies.", "AI": {"tldr": "\u91cf\u5316\u6280\u672f\u80fd\u538b\u7f29\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u51cf\u5c11\u5185\u5b58\u9700\u6c42\u5e76\u52a0\u901f\u63a8\u7406\uff0c\u4f46\u5176\u5bf9\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u91cf\u5316\u5bf9LLM\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u9c81\u68d2\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u91cf\u5316\u540e\u7684\u6a21\u578b\u901a\u5e38\u6bd4\u5168\u7cbe\u5ea6\u6a21\u578b\u66f4\u9c81\u68d2\u3002", "motivation": "\u91cf\u5316\u6280\u672f\u867d\u5e7f\u6cdb\u7528\u4e8e\u538b\u7f29LLM\uff0c\u4f46\u5176\u5bf9\u6a21\u578b\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u7cfb\u7edf\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u7a76\u91cf\u5316\u5982\u4f55\u5f71\u54cdLLM\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u56db\u79cd\u4e3b\u6d41LLM\u5bb6\u65cf\uff08LLaMA\u3001DeepSeek\u3001CodeGen\u3001StarCoder\uff09\uff0c\u53c2\u6570\u89c4\u6a21\u4ece350M\u523033B\uff0c\u4ece\u5bf9\u6297\u653b\u51fb\u548c\u566a\u58f0\u6270\u52a8\u4e24\u4e2a\u89d2\u5ea6\u91cf\u5316\u9c81\u68d2\u6027\u3002", "result": "\u91cf\u5316\u540e\u7684LLM\u5728\u5bf9\u6297\u653b\u51fb\u548c\u566a\u58f0\u6270\u52a8\u5b9e\u9a8c\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c51.59%\u7684\u5bf9\u6297\u5b9e\u9a8c\u663e\u793a\u91cf\u5316\u6a21\u578b\u66f4\u9c81\u68d2\uff0c\u566a\u58f0\u6270\u52a8\u5b9e\u9a8c\u4e5f\u8bc1\u5b9e\u91cf\u5316\u6a21\u578b\u80fd\u627f\u53d7\u66f4\u9ad8\u6743\u91cd\u5e72\u6270\u3002", "conclusion": "\u91cf\u5316\u4e0d\u4ec5\u80fd\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\uff0c\u8fd8\u80fd\u63d0\u5347LLM\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u53ef\u9760\u7684LLM\u90e8\u7f72\u7b56\u7565\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.22865", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22865", "abs": "https://arxiv.org/abs/2506.22865", "authors": ["Ziqi Zhong", "Xunzhu Tang"], "title": "ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have revealed a\nsignificant performance gap between closed-source and open-source models,\nparticularly in tasks requiring complex reasoning and precise instruction\nfollowing. This paper introduces ReasonBridge, a methodology that efficiently\ntransfers reasoning capabilities from powerful closed-source to open-source\nmodels through a novel hierarchical knowledge distillation framework. We\ndevelop a tailored dataset Reason1K with only 1,000 carefully curated reasoning\ntraces emphasizing difficulty, diversity, and quality. These traces are\nfiltered from across multiple domains using a structured multi-criteria\nselection algorithm. Our transfer learning approach incorporates: (1) a\nhierarchical distillation process capturing both strategic abstraction and\ntactical implementation patterns, (2) a sparse reasoning-focused adapter\narchitecture requiring only 0.3% additional trainable parameters, and (3) a\ntest-time compute scaling mechanism using guided inference interventions.\nComprehensive evaluations demonstrate that ReasonBridge improves reasoning\ncapabilities in open-source models by up to 23% on benchmark tasks,\nsignificantly narrowing the gap with closed-source models. Notably, the\nenhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its\nperformance on competition-level AIME problems. Our methodology generalizes\neffectively across diverse reasoning domains and model architectures,\nestablishing a sample-efficient approach to reasoning enhancement for\ninstruction following.", "AI": {"tldr": "ReasonBridge\u901a\u8fc7\u5206\u5c42\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u5c06\u95ed\u6e90\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u9ad8\u6548\u8fc1\u79fb\u5230\u5f00\u6e90\u6a21\u578b\uff0c\u663e\u8457\u7f29\u5c0f\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u89e3\u51b3\u95ed\u6e90\u4e0e\u5f00\u6e90\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "method": "\u91c7\u7528\u5206\u5c42\u84b8\u998f\u3001\u7a00\u758f\u9002\u914d\u5668\u67b6\u6784\u548c\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u673a\u5236\u3002", "result": "\u5f00\u6e90\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u534723%\uff0c\u90e8\u5206\u4efb\u52a1\u6027\u80fd\u8d85\u8d8a\u95ed\u6e90\u6a21\u578b\u3002", "conclusion": "ReasonBridge\u4e3a\u9ad8\u6548\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6837\u672c\u9ad8\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.22727", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.22727", "abs": "https://arxiv.org/abs/2506.22727", "authors": ["Yu Zheng", "Chenang Li", "Zhou Li", "Qingsong Wang"], "title": "Convergent Privacy Framework with Contractive GNN Layers for Multi-hop Aggregations", "comment": "23 pages", "summary": "Differential privacy (DP) has been integrated into graph neural networks\n(GNNs) to protect sensitive structural information, e.g., edges, nodes, and\nassociated features across various applications. A common approach is to\nperturb the message-passing process, which forms the core of most GNN\narchitectures. However, existing methods typically incur a privacy cost that\ngrows linearly with the number of layers (Usenix Security'23), ultimately\nrequiring excessive noise to maintain a reasonable privacy level. This\nlimitation becomes particularly problematic when deep GNNs are necessary to\ncapture complex and long-range interactions in graphs. In this paper, we\ntheoretically establish that the privacy budget can converge with respect to\nthe number of layers by applying privacy amplification techniques to the\nmessage-passing process, exploiting the contractive properties inherent to\nstandard GNN operations. Motivated by this analysis, we propose a simple yet\neffective Contractive Graph Layer (CGL) that ensures the contractiveness\nrequired for theoretical guarantees while preserving model utility. Our\nframework, CARIBOU, supports both training and inference, equipped with a\ncontractive aggregation module, a privacy allocation module, and a privacy\nauditing module. Experimental evaluations demonstrate that CARIBOU\nsignificantly improves the privacy-utility trade-off and achieves superior\nperformance in privacy auditing tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCARIBOU\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165Contractive Graph Layer\uff08CGL\uff09\u548c\u9690\u79c1\u653e\u5927\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u4e2d\u9690\u79c1\u9884\u7b97\u968f\u5c42\u6570\u7ebf\u6027\u589e\u957f\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9690\u79c1\u4e0e\u6548\u7528\u7684\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u4fdd\u62a4\u56fe\u795e\u7ecf\u7f51\u7edc\u9690\u79c1\u65f6\uff0c\u9690\u79c1\u9884\u7b97\u968f\u5c42\u6570\u7ebf\u6027\u589e\u957f\uff0c\u5bfc\u81f4\u566a\u58f0\u8fc7\u5927\uff0c\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u65b0\u6280\u672f\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faContractive Graph Layer\uff08CGL\uff09\uff0c\u5229\u7528\u6807\u51c6GNN\u64cd\u4f5c\u7684\u6536\u7f29\u6027\u8d28\uff0c\u7ed3\u5408\u9690\u79c1\u653e\u5927\u6280\u672f\uff0c\u786e\u4fdd\u9690\u79c1\u9884\u7b97\u6536\u655b\u3002CARIBOU\u6846\u67b6\u5305\u542b\u6536\u7f29\u805a\u5408\u6a21\u5757\u3001\u9690\u79c1\u5206\u914d\u6a21\u5757\u548c\u9690\u79c1\u5ba1\u8ba1\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCARIBOU\u663e\u8457\u6539\u5584\u4e86\u9690\u79c1\u4e0e\u6548\u7528\u7684\u6743\u8861\uff0c\u5e76\u5728\u9690\u79c1\u5ba1\u8ba1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548cCGL\u8bbe\u8ba1\uff0cCARIBOU\u6709\u6548\u89e3\u51b3\u4e86\u6df1\u5ea6GNNs\u4e2d\u7684\u9690\u79c1\u9884\u7b97\u95ee\u9898\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.23014", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23014", "abs": "https://arxiv.org/abs/2506.23014", "authors": ["Wilder Baldwin", "Shashank Chintakuntla", "Shreyah Parajuli", "Ali Pourghasemi", "Ryan Shanz", "Sepideh Ghanavati"], "title": "Generating Privacy Stories From Software Documentation", "comment": "Accepted to RENext!'25 at the 33rd IEEE International Requirements\n  Engineering 2025 conference", "summary": "Research shows that analysts and developers consider privacy as a security\nconcept or as an afterthought, which may lead to non-compliance and violation\nof users' privacy. Most current approaches, however, focus on extracting legal\nrequirements from the regulations and evaluating the compliance of software and\nprocesses with them. In this paper, we develop a novel approach based on\nchain-of-thought prompting (CoT), in-context-learning (ICL), and Large Language\nModels (LLMs) to extract privacy behaviors from various software documents\nprior to and during software development, and then generate privacy\nrequirements in the format of user stories. Our results show that most commonly\nused LLMs, such as GPT-4o and Llama 3, can identify privacy behaviors and\ngenerate privacy user stories with F1 scores exceeding 0.8. We also show that\nthe performance of these models could be improved through parameter-tuning. Our\nfindings provide insight into using and optimizing LLMs for generating privacy\nrequirements given software documents created prior to or throughout the\nsoftware development lifecycle.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\uff08CoT\uff09\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u8f6f\u4ef6\u5f00\u53d1\u6587\u6863\u4e2d\u63d0\u53d6\u9690\u79c1\u884c\u4e3a\u5e76\u751f\u6210\u9690\u79c1\u9700\u6c42\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4ece\u6cd5\u89c4\u4e2d\u63d0\u53d6\u6cd5\u5f8b\u8981\u6c42\u5e76\u8bc4\u4f30\u5408\u89c4\u6027\uff0c\u800c\u9690\u79c1\u5e38\u88ab\u89c6\u4e3a\u5b89\u5168\u6982\u5ff5\u6216\u4e8b\u540e\u8003\u8651\uff0c\u5bfc\u81f4\u7528\u6237\u9690\u79c1\u88ab\u4fb5\u72af\u3002", "method": "\u7ed3\u5408CoT\u3001ICL\u548cLLMs\uff0c\u4ece\u8f6f\u4ef6\u5f00\u53d1\u6587\u6863\u4e2d\u63d0\u53d6\u9690\u79c1\u884c\u4e3a\uff0c\u5e76\u4ee5\u7528\u6237\u6545\u4e8b\u7684\u5f62\u5f0f\u751f\u6210\u9690\u79c1\u9700\u6c42\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5e38\u89c1LLMs\uff08\u5982GPT-4o\u548cLlama 3\uff09\u5728\u8bc6\u522b\u9690\u79c1\u884c\u4e3a\u548c\u751f\u6210\u9690\u79c1\u7528\u6237\u6545\u4e8b\u65f6F1\u5206\u6570\u8d85\u8fc70.8\uff0c\u4e14\u901a\u8fc7\u53c2\u6570\u8c03\u4f18\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u4f7f\u7528\u548c\u4f18\u5316LLMs\u751f\u6210\u9690\u79c1\u9700\u6c42\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2506.22893", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.22893", "abs": "https://arxiv.org/abs/2506.22893", "authors": ["Arpit Narechania", "Alex Endert", "Atanu R Sinha"], "title": "Agentic Enterprise: AI-Centric User to User-Centric AI", "comment": "12 pages, 1 figure, 2 sidebars; Preprint", "summary": "After a very long winter, the Artificial Intelligence (AI) spring is here.\nOr, so it seems over the last three years. AI has the potential to impact many\nareas of human life - personal, social, health, education, professional. In\nthis paper, we take a closer look at the potential of AI for Enterprises, where\ndecision-making plays a crucial and repeated role across functions, tasks, and\noperations. We consider Agents imbued with AI as means to increase\ndecision-productivity of enterprises. We highlight six tenets for Agentic\nsuccess in enterprises, by drawing attention to what the current, AI-Centric\nUser paradigm misses, in the face of persistent needs of and usefulness for\nEnterprise Decision-Making. In underscoring a shift to User-Centric AI, we\noffer six tenets and promote market mechanisms for platforms, aligning the\ndesign of AI and its delivery by Agents to the cause of enterprise users.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u5728\u4f01\u4e1a\u51b3\u7b56\u4e2d\u7684\u6f5c\u529b\uff0c\u63d0\u51fa\u4e86\u516d\u4e2a\u539f\u5219\u4ee5\u4fc3\u8fdbAI\u5728\u4f01\u4e1a\u4e2d\u7684\u6210\u529f\u5e94\u7528\uff0c\u5e76\u5f3a\u8c03\u4ece\u4ee5AI\u4e3a\u4e2d\u5fc3\u8f6c\u5411\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\u3002", "motivation": "AI\u5728\u591a\u4e2a\u9886\u57df\u5177\u6709\u6f5c\u5728\u5f71\u54cd\u529b\uff0c\u4f46\u5f53\u524d\u4ee5AI\u4e3a\u4e2d\u5fc3\u7684\u7528\u6237\u8303\u5f0f\u672a\u80fd\u5145\u5206\u6ee1\u8db3\u4f01\u4e1a\u51b3\u7b56\u7684\u6301\u7eed\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4f01\u4e1a\u51b3\u7b56\u9700\u6c42\uff0c\u63d0\u51fa\u516d\u4e2a\u539f\u5219\uff0c\u5e76\u63d0\u5021\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684AI\u8bbe\u8ba1\u548c\u5e02\u573a\u673a\u5236\u3002", "result": "\u63d0\u51fa\u4e86\u516d\u4e2a\u4fc3\u8fdbAI\u5728\u4f01\u4e1a\u4e2d\u6210\u529f\u5e94\u7528\u7684\u539f\u5219\uff0c\u5e76\u5f3a\u8c03\u4e86\u7528\u6237\u4e2d\u5fc3\u5316\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u4f01\u4e1a\u5e94\u8f6c\u5411\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684AI\u8bbe\u8ba1\uff0c\u4ee5\u63d0\u5347\u51b3\u7b56\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u5e02\u573a\u673a\u5236\u5b9e\u73b0AI\u5e73\u53f0\u7684\u4f18\u5316\u3002"}}
{"id": "2506.22750", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.22750", "abs": "https://arxiv.org/abs/2506.22750", "authors": ["Saraga S.", "Anagha M. S.", "Dincy R. Arikkat", "Rafidha Rehiman K. A.", "Serena Nicolazzo", "Antonino Nocera", "Vinod P"], "title": "Enhancing Android Malware Detection with Retrieval-Augmented Generation", "comment": null, "summary": "The widespread use of Android applications has made them a prime target for\ncyberattacks, significantly increasing the risk of malware that threatens user\nprivacy, security, and device functionality. Effective malware detection is\nthus critical, with static analysis, dynamic analysis, and Machine Learning\nbeing widely used approaches. In this work, we focus on a Machine\nLearning-based method utilizing static features. We first compiled a dataset of\nbenign and malicious APKs and performed static analysis to extract features\nsuch as code structure, permissions, and manifest file content, without\nexecuting the apps. Instead of relying solely on raw static features, our\nsystem uses an LLM to generate high-level functional descriptions of APKs. To\nmitigate hallucinations, which are a known vulnerability of LLM, we integrated\nRetrieval-Augmented Generation (RAG), enabling the LLM to ground its output in\nrelevant context. Using carefully designed prompts, we guide the LLM to produce\ncoherent function summaries, which are then analyzed using a transformer-based\nmodel, improving detection accuracy over conventional feature-based methods for\nmalware detection.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u548cLLM\u751f\u6210\u7684\u529f\u80fd\u63cf\u8ff0\uff0c\u901a\u8fc7RAG\u51cf\u5c11\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "Android\u5e94\u7528\u7684\u5e7f\u6cdb\u4f7f\u7528\u4f7f\u5176\u6210\u4e3a\u7f51\u7edc\u653b\u51fb\u7684\u4e3b\u8981\u76ee\u6807\uff0c\u6076\u610f\u8f6f\u4ef6\u5a01\u80c1\u7528\u6237\u9690\u79c1\u548c\u8bbe\u5907\u529f\u80fd\u3002\u4f20\u7edf\u9759\u6001\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u6536\u96c6\u826f\u6027\u53ca\u6076\u610fAPK\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u63d0\u53d6\u7279\u5f81\uff08\u5982\u4ee3\u7801\u7ed3\u6784\u3001\u6743\u9650\u7b49\uff09\uff0c\u5229\u7528LLM\u751f\u6210\u529f\u80fd\u63cf\u8ff0\uff0c\u7ed3\u5408RAG\u51cf\u5c11\u5e7b\u89c9\uff0c\u6700\u540e\u7528\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u5206\u6790\u3002", "result": "\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edf\u57fa\u4e8e\u7279\u5f81\u7684\u65b9\u6cd5\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e0a\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u7ed3\u5408LLM\u548cRAG\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.23034", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23034", "abs": "https://arxiv.org/abs/2506.23034", "authors": ["Hao Yan", "Swapneel Suhas Vaidya", "Xiaokuan Zhang", "Ziyu Yao"], "title": "Guiding AI to Fix Its Own Flaws: An Empirical Study on LLM-Driven Secure Code Generation", "comment": null, "summary": "Large Language Models (LLMs) have become powerful tools for automated code\ngeneration. However, these models often overlook critical security practices,\nwhich can result in the generation of insecure code that contains\nvulnerabilities-weaknesses or flaws in the code that attackers can exploit to\ncompromise a system. However, there has been limited exploration of strategies\nto guide LLMs in generating secure code and a lack of in-depth analysis of the\neffectiveness of LLMs in repairing code containing vulnerabilities. In this\npaper, we present a comprehensive evaluation of state-of-the-art LLMs by\nexamining their inherent tendencies to produce insecure code, their capability\nto generate secure code when guided by self-generated vulnerability hints, and\ntheir effectiveness in repairing vulnerabilities when provided with different\nlevels of feedback. Our study covers both proprietary and open-weight models\nacross various scales and leverages established benchmarks to assess a wide\nrange of vulnerability types. Through quantitative and qualitative analyses, we\nreveal that although LLMs are prone to generating insecure code, advanced\nmodels can benefit from vulnerability hints and fine-grained feedback to avoid\nor fix vulnerabilities. We also provide actionable suggestions to developers to\nreduce vulnerabilities when using LLMs for code generation.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u548c\u4fee\u590d\u4e0d\u5b89\u5168\u4ee3\u7801\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u9ad8\u7ea7\u6a21\u578b\u53ef\u901a\u8fc7\u6f0f\u6d1e\u63d0\u793a\u548c\u53cd\u9988\u6539\u8fdb\u5b89\u5168\u6027\u3002", "motivation": "LLMs\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5e38\u5ffd\u7565\u5b89\u5168\u5b9e\u8df5\uff0c\u5bfc\u81f4\u6f0f\u6d1e\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u751f\u6210\u5b89\u5168\u4ee3\u7801\u548c\u4fee\u590d\u6f0f\u6d1e\u80fd\u529b\u7684\u6df1\u5165\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\uff0c\u8bc4\u4f30LLMs\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\u7684\u503e\u5411\u3001\u5728\u6f0f\u6d1e\u63d0\u793a\u4e0b\u751f\u6210\u5b89\u5168\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u5728\u4e0d\u540c\u53cd\u9988\u4e0b\u4fee\u590d\u6f0f\u6d1e\u7684\u6548\u679c\u3002", "result": "LLMs\u6613\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\uff0c\u4f46\u9ad8\u7ea7\u6a21\u578b\u53ef\u901a\u8fc7\u6f0f\u6d1e\u63d0\u793a\u548c\u7ec6\u7c92\u5ea6\u53cd\u9988\u907f\u514d\u6216\u4fee\u590d\u6f0f\u6d1e\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u51cf\u5c11LLMs\u751f\u6210\u4ee3\u7801\u6f0f\u6d1e\u7684\u5b9e\u9645\u5efa\u8bae\u3002"}}
{"id": "2506.22919", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22919", "abs": "https://arxiv.org/abs/2506.22919", "authors": ["Sanskar Pandey", "Ruhaan Chopra", "Saad Murtaza Bhat", "Ark Abhyudaya"], "title": "Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning", "comment": null, "summary": "Mixture-of-Experts (MoE) models enable conditional computation by routing\ninputs to specialized experts, but these experts rely on identical inductive\nbiases, thus limiting representational diversity. This static computation\npathway is inefficient for inputs that require different types of reasoning and\nlimits specialization and interpretability. We propose Hecto, a lightweight MoE\narchitecture that leverages architectural heterogeneity by combining a GRU\nexpert for temporal reasoning and an FFNN expert for static abstraction under a\nsparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG\nNews, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely\ntrails homogeneous baselines in performance despite receiving isolated input\nrepresentations, while achieving clear expert specialization, with each expert\naligning to distinct reasoning types (temporal vs static). At larger batch\nsizes, Hecto exhibits improved performance, benefiting from relaxed\ncomputational constraints that allow its heterogeneous architecture to optimize\nmore effectively. Ablation results isolate architectural diversity as the\nsource of Hecto's stability and interpretability across diverse reasoning\ntasks. Overall, Hecto establishes itself as a new benchmark for conditional\ncomputation, offering a principled framework for specialized reasoning in\nlow-resource regimes with its model strength derived from principled\nspecialization.", "AI": {"tldr": "Hecto\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u5408GRU\u548cFFNN\u4e13\u5bb6\u5b9e\u73b0\u5f02\u6784\u8ba1\u7b97\uff0c\u63d0\u5347\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edfMoE\u6a21\u578b\u7684\u4e13\u5bb6\u4f9d\u8d56\u76f8\u540c\u7684\u5f52\u7eb3\u504f\u5dee\uff0c\u9650\u5236\u4e86\u8868\u793a\u591a\u6837\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0cHecto\u65e8\u5728\u901a\u8fc7\u5f02\u6784\u67b6\u6784\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "Hecto\u7ed3\u5408GRU\u4e13\u5bb6\uff08\u65f6\u5e8f\u63a8\u7406\uff09\u548cFFNN\u4e13\u5bb6\uff08\u9759\u6001\u62bd\u8c61\uff09\uff0c\u91c7\u7528\u7a00\u758fTop-1\u95e8\u63a7\u673a\u5236\u3002", "result": "\u5728\u591a\u4e2a\u63a8\u7406\u548c\u56de\u5f52\u4efb\u52a1\u4e2d\uff0cHecto\u6027\u80fd\u63a5\u8fd1\u6216\u4f18\u4e8e\u540c\u6784\u57fa\u7ebf\uff0c\u5e76\u5b9e\u73b0\u4e13\u5bb6\u4e13\u4e1a\u5316\uff08\u65f6\u5e8fvs\u9759\u6001\uff09\u3002", "conclusion": "Hecto\u4e3a\u6761\u4ef6\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u57fa\u51c6\uff0c\u5176\u5f02\u6784\u67b6\u6784\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u6e90\u4e8e\u4e13\u4e1a\u5316\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2506.22787", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.22787", "abs": "https://arxiv.org/abs/2506.22787", "authors": ["Sri Harsha Gajavalli", "Junichi Koizumi", "Rakibul Hasan"], "title": "What's Privacy Good for? Measuring Privacy as a Shield from Harms due to Personal Data Use", "comment": null, "summary": "We propose a harm-centric conceptualization of privacy that asks: What harms\nfrom personal data use can privacy prevent? The motivation behind this research\nis limitations in existing privacy frameworks (e.g., Contextual Integrity) to\ncapture or categorize many of the harms that arise from modern technology's use\nof personal data. We operationalize this conceptualization in an online study\nwith 400 college and university students. Study participants indicated their\nperceptions of different harms (e.g., manipulation, discrimination, and\nharassment) that may arise when artificial intelligence-based algorithms infer\npersonal data (e.g., demographics, personality traits, and cognitive\ndisability) and use it to identify students who are likely to drop out of a\ncourse or the best job candidate. The study includes 14 harms and six types of\npersonal data selected based on an extensive literature review.\n  Comprehensive statistical analyses of the study data show that the 14 harms\nare internally consistent and collectively represent a general notion of\nprivacy harms. The study data also surfaces nuanced perceptions of harms, both\nacross the contexts and participants' demographic factors. Based on these\nresults, we discuss how privacy can be improved equitably. Thus, this research\nnot only contributes to enhancing the understanding of privacy as a concept but\nalso provides practical guidance to improve privacy in the context of education\nand employment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u5371\u5bb3\u4e3a\u4e2d\u5fc3\u7684\u9690\u79c1\u6982\u5ff5\u5316\u65b9\u6cd5\uff0c\u63a2\u8ba8\u4e86\u9690\u79c1\u5982\u4f55\u9632\u6b62\u4e2a\u4eba\u6570\u636e\u4f7f\u7528\u5e26\u6765\u7684\u5371\u5bb3\u3002\u901a\u8fc7\u5728\u7ebf\u7814\u7a76\u9a8c\u8bc1\u4e8614\u79cd\u5371\u5bb3\u7684\u611f\u77e5\uff0c\u5e76\u63d0\u4f9b\u4e86\u6539\u8fdb\u9690\u79c1\u7684\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u9690\u79c1\u6846\u67b6\uff08\u5982\u60c5\u5883\u5b8c\u6574\u6027\uff09\u96be\u4ee5\u6355\u6349\u6216\u5206\u7c7b\u73b0\u4ee3\u6280\u672f\u4f7f\u7528\u4e2a\u4eba\u6570\u636e\u5e26\u6765\u7684\u591a\u79cd\u5371\u5bb3\u3002", "method": "\u901a\u8fc7\u4e00\u9879400\u540d\u5927\u5b66\u751f\u7684\u5728\u7ebf\u7814\u7a76\uff0c\u53c2\u4e0e\u8005\u8bc4\u4f30\u4e86AI\u7b97\u6cd5\u63a8\u65ad\u4e2a\u4eba\u6570\u636e\u53ef\u80fd\u5bfc\u81f4\u768414\u79cd\u5371\u5bb3\u3002", "result": "\u7814\u7a76\u53d1\u73b014\u79cd\u5371\u5bb3\u5177\u6709\u5185\u90e8\u4e00\u81f4\u6027\uff0c\u4ee3\u8868\u4e86\u9690\u79c1\u5371\u5bb3\u7684\u4e00\u822c\u6982\u5ff5\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u80cc\u666f\u548c\u4eba\u53e3\u56e0\u7d20\u4e0b\u7684\u7ec6\u5fae\u611f\u77e5\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u4e0d\u4ec5\u6df1\u5316\u4e86\u5bf9\u9690\u79c1\u6982\u5ff5\u7684\u7406\u89e3\uff0c\u8fd8\u4e3a\u6559\u80b2\u548c\u5c31\u4e1a\u9886\u57df\u7684\u9690\u79c1\u6539\u8fdb\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2506.23063", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23063", "abs": "https://arxiv.org/abs/2506.23063", "authors": ["Guangfa Lyu", "Zhenzhong Cao", "Xiaofei Ren", "Fengyu Wang"], "title": "HF-DGF: Hybrid Feedback Guided Directed Grey-box Fuzzing", "comment": null, "summary": "Directed Grey-box Fuzzing (DGF) has emerged as a widely adopted technique for\ncrash reproduction and patch testing, leveraging its capability to precisely\nnavigate toward target locations and exploit vulnerabilities. However, current\nDGF tools are constrained by insufficient runtime feedback, limiting their\nefficiency in reaching targets and exploring state spaces. This study presents\nHF-DGF, a novel directed grey-box fuzzing framework. Its seed scheduling is\nguided by a hybrid feedback mechanism integrating control-flow distance,\nvalue-flow influence score, and slice coverage. To enable precise control-flow\ndistance feedback, we propose a backward-stepping algorithm to calculate basic\nblock-level seed distances on a virtual inter-procedural control-flow graph\n(ICFG). For effective state space exploration, we introduce value-flow\ninfluence and a corresponding metric, the value-flow influence score.\nAdditionally, to mitigate runtime overhead from hybrid feedback, we adopt a\nnovel selective instrumentation strategy. Evaluations on 41 real-world\nvulnerabilities show HF-DGF outperforms existing tools: it achieves crash\nreproduction 5.05 times faster than AFL, 5.79 times faster than AFLGo, 73.75\ntimes faster than WindRanger, 2.56 times faster than DAFL, and 8.45 times\nfaster than Beacon on average. Notably, when all fuzzers triggered crashes,\nHF-DGF exhibited the lowest code coverage, demonstrating superior\ndirectionality and efficiency. It also surpasses AFLGo, WindRanger, DAFL, and\nBeacon in static analysis efficiency.", "AI": {"tldr": "HF-DGF\u662f\u4e00\u79cd\u65b0\u578b\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u53cd\u9988\u673a\u5236\uff08\u63a7\u5236\u6d41\u8ddd\u79bb\u3001\u503c\u6d41\u5f71\u54cd\u5206\u6570\u548c\u5207\u7247\u8986\u76d6\u7387\uff09\u63d0\u5347\u6548\u7387\u548c\u65b9\u5411\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u56e0\u8fd0\u884c\u65f6\u53cd\u9988\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u76ee\u6807\u5230\u8fbe\u548c\u72b6\u6001\u7a7a\u95f4\u63a2\u7d22\u7684\u6548\u7387\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u53cd\u9988\u673a\u5236\uff0c\u5305\u62ec\u63a7\u5236\u6d41\u8ddd\u79bb\uff08\u901a\u8fc7\u53cd\u5411\u6b65\u8fdb\u7b97\u6cd5\u8ba1\u7b97\uff09\u3001\u503c\u6d41\u5f71\u54cd\u5206\u6570\u548c\u5207\u7247\u8986\u76d6\u7387\uff0c\u5e76\u91c7\u7528\u9009\u62e9\u6027\u63d2\u6869\u7b56\u7565\u964d\u4f4e\u8fd0\u884c\u65f6\u5f00\u9500\u3002", "result": "\u572841\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u6d4b\u8bd5\u4e2d\uff0cHF-DGF\u7684\u5d29\u6e83\u590d\u73b0\u901f\u5ea6\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u4e14\u4ee3\u7801\u8986\u76d6\u7387\u6700\u4f4e\uff0c\u663e\u793a\u5176\u65b9\u5411\u6027\u548c\u6548\u7387\u4f18\u52bf\u3002", "conclusion": "HF-DGF\u901a\u8fc7\u6df7\u5408\u53cd\u9988\u673a\u5236\u548c\u9009\u62e9\u6027\u63d2\u6869\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u7684\u6548\u7387\u548c\u65b9\u5411\u6027\u3002"}}
{"id": "2506.22920", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22920", "abs": "https://arxiv.org/abs/2506.22920", "authors": ["Pinzheng Wang", "Juntao Li", "Zecheng Tang", "Haijia Gui", "Min zhang"], "title": "Improving Rationality in the Reasoning Process of Language Models through Self-playing Game", "comment": "Accepted by ICML 2025", "summary": "Large language models (LLMs) have demonstrated considerable reasoning\nabilities in various tasks such as mathematics and coding. However, recent\nstudies indicate that even the best models lack true comprehension of their\nreasoning processes. In this paper, we explore how self-play can enhance the\nrationality of models in the reasoning process without supervision from humans\nor superior models. We design a Critic-Discernment Game(CDG) in which a prover\nfirst provides a solution to a given problem and is subsequently challenged by\ncritiques of its solution. These critiques either aim to assist or mislead the\nprover. The objective of the prover is to maintain the correct answer when\nfaced with misleading comments, while correcting errors in response to\nconstructive feedback. Our experiments on tasks involving mathematical\nreasoning, stepwise error detection, self-correction, and long-chain reasoning\ndemonstrate that CDG training can significantly improve the ability of\nwell-aligned LLMs to comprehend their reasoning process.", "AI": {"tldr": "\u901a\u8fc7\u81ea\u73a9\u6e38\u620f\uff08Critic-Discernment Game, CDG\uff09\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u7406\u6027\uff0c\u65e0\u9700\u4eba\u7c7b\u76d1\u7763\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7801\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u63a8\u7406\u8fc7\u7a0b\u7684\u771f\u6b63\u7406\u89e3\u3002", "method": "\u8bbe\u8ba1CDG\u6e38\u620f\uff0c\u5176\u4e2d\u8bc1\u660e\u8005\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u5e76\u63a5\u53d7\u6279\u8bc4\u8005\u7684\u6311\u6218\uff0c\u6279\u8bc4\u8005\u53ef\u80fd\u63d0\u4f9b\u5e2e\u52a9\u6216\u8bef\u5bfc\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCDG\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u3001\u9519\u8bef\u68c0\u6d4b\u3001\u81ea\u6211\u4fee\u6b63\u548c\u957f\u94fe\u63a8\u7406\u4e2d\u7684\u80fd\u529b\u3002", "conclusion": "\u81ea\u73a9\u6e38\u620f\u662f\u4e00\u79cd\u6709\u6548\u63d0\u5347\u6a21\u578b\u63a8\u7406\u7406\u89e3\u80fd\u529b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.22938", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22938", "abs": "https://arxiv.org/abs/2506.22938", "authors": ["Zaydon L. Ali", "Wassan Saad Abduljabbar Hayale", "Israa Ibraheem Al_Barazanchi", "Ravi Sekhar", "Pritesh Shah", "Sushma Parihar"], "title": "Efficient Cybersecurity Assessment Using SVM and Fuzzy Evidential Reasoning for Resilient Infrastructure", "comment": null, "summary": "With current advancement in hybermedia knowledges, the privacy of digital\ninformation has developed a critical problem. To overawed the susceptibilities\nof present security protocols, scholars tend to focus mainly on efforts on\nalternation of current protocols. Over past decade, various proposed encoding\nmodels have been shown insecurity, leading to main threats against significant\ndata. Utilizing the suitable encryption model is very vital means of guard\nagainst various such, but algorithm is selected based on the dependency of data\nwhich need to be secured. Moreover, testing potentiality of the security\nassessment one by one to identify the best choice can take a vital time for\nprocessing. For faster and precisive identification of assessment algorithm, we\nsuggest a security phase exposure model for cipher encryption technique by\ninvoking Support Vector Machine (SVM). In this work, we form a dataset using\nusual security components like contrast, homogeneity. To overcome the\nuncertainty in analysing the security and lack of ability of processing data to\na risk assessment mechanism. To overcome with such complications, this paper\nproposes an assessment model for security issues using fuzzy evidential\nreasoning (ER) approaches. Significantly, the model can be utilised to process\nand assemble risk assessment data on various aspects in systematic ways. To\nestimate the performance of our framework, we have various analyses like,\nrecall, F1 score and accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u548c\u6a21\u7cca\u8bc1\u636e\u63a8\u7406\uff08ER\uff09\u7684\u5b89\u5168\u8bc4\u4f30\u6a21\u578b\uff0c\u7528\u4e8e\u5feb\u901f\u51c6\u786e\u5730\u9009\u62e9\u52a0\u5bc6\u7b97\u6cd5\u5e76\u8bc4\u4f30\u98ce\u9669\u3002", "motivation": "\u5f53\u524d\u52a0\u5bc6\u6a21\u578b\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u4f20\u7edf\u65b9\u6cd5\u8bc4\u4f30\u8017\u65f6\u4e14\u4e0d\u7cbe\u786e\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u7684\u5b89\u5168\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408SVM\u548c\u6a21\u7ccaER\u65b9\u6cd5\uff0c\u6784\u5efa\u6570\u636e\u96c6\u5e76\u5206\u6790\u5b89\u5168\u7ec4\u4ef6\uff08\u5982\u5bf9\u6bd4\u5ea6\u3001\u540c\u8d28\u6027\uff09\uff0c\u4ee5\u7cfb\u7edf\u5316\u8bc4\u4f30\u98ce\u9669\u3002", "result": "\u901a\u8fc7\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548c\u51c6\u786e\u7387\u7b49\u6307\u6807\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6a21\u578b\u80fd\u9ad8\u6548\u5904\u7406\u98ce\u9669\u8bc4\u4f30\u6570\u636e\uff0c\u4e3a\u52a0\u5bc6\u7b97\u6cd5\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u4e00\u79cd\u5feb\u901f\u4e14\u7cbe\u786e\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.23100", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23100", "abs": "https://arxiv.org/abs/2506.23100", "authors": ["Jiayi Zhang", "Kai Huang", "Jian Zhang", "Yang Liu", "Chunyang Chen"], "title": "Repair Ingredients Are All You Need: Improving Large Language Model-Based Program Repair via Repair Ingredients Search", "comment": "Accepted by ICSE 2026. Jiayi Zhang and Kai Huang contributed equally\n  to this work", "summary": "Automated Program Repair (APR) techniques aim to automatically fix buggy\nprograms. Among these, Large Language Model-based (LLM-based) approaches have\nshown great promise. Recent advances demonstrate that directly leveraging LLMs\ncan achieve leading results. However, these techniques remain suboptimal in\ngenerating contextually relevant and accurate patches, as they often overlook\nrepair ingredients crucial for practical program repair. In this paper, we\npropose ReinFix, a novel framework that enables LLMs to autonomously search for\nrepair ingredients throughout both the reasoning and solution phases of bug\nfixing. In the reasoning phase, ReinFix integrates static analysis tools to\nretrieve internal ingredients, such as variable definitions, to assist the LLM\nin root cause analysis when it encounters difficulty understanding the context.\nDuring the solution phase, when the LLM lacks experience in fixing specific\nbugs, ReinFix searches for external ingredients from historical bug fixes with\nsimilar bug patterns, leveraging both the buggy code and its root cause to\nguide the LLM in identifying appropriate repair actions, thereby increasing the\nlikelihood of generating correct patches. Evaluations on two popular benchmarks\n(Defects4J V1.2 and V2.0) demonstrate the effectiveness of our approach over\nSOTA baselines. Notably, ReinFix fixes 146 bugs, which is 32 more than the\nbaselines on Defects4J V1.2. On Defects4J V2.0, ReinFix fixes 38 more bugs than\nthe SOTA. Importantly, when evaluating on the recent benchmarks that are free\nof data leakage risk, ReinFix also maintains the best performance.", "AI": {"tldr": "ReinFix\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u9759\u6001\u5206\u6790\u5de5\u5177\u548c\u5386\u53f2\u4fee\u590d\u6570\u636e\uff0c\u63d0\u5347\u4fee\u590d\u7684\u51c6\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u3002", "motivation": "\u73b0\u6709LLM-based APR\u6280\u672f\u5728\u751f\u6210\u4fee\u590d\u8865\u4e01\u65f6\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u548c\u51c6\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u5173\u952e\u4fee\u590d\u8981\u7d20\u3002", "method": "ReinFix\u5728\u63a8\u7406\u9636\u6bb5\u5229\u7528\u9759\u6001\u5206\u6790\u5de5\u5177\u83b7\u53d6\u5185\u90e8\u4fee\u590d\u8981\u7d20\uff0c\u5728\u89e3\u51b3\u65b9\u6848\u9636\u6bb5\u4ece\u5386\u53f2\u4fee\u590d\u4e2d\u641c\u7d22\u5916\u90e8\u4fee\u590d\u8981\u7d20\uff0c\u6307\u5bfcLLM\u751f\u6210\u66f4\u51c6\u786e\u7684\u8865\u4e01\u3002", "result": "\u5728Defects4J V1.2\u548cV2.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReinFix\u5206\u522b\u4fee\u590d\u4e86146\u548c38\u4e2a\u989d\u5916\u9519\u8bef\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "ReinFix\u901a\u8fc7\u7ed3\u5408\u5185\u90e8\u548c\u5916\u90e8\u4fee\u590d\u8981\u7d20\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM-based APR\u7684\u6027\u80fd\uff0c\u5e76\u5728\u65e0\u6570\u636e\u6cc4\u6f0f\u98ce\u9669\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u6700\u4f73\u8868\u73b0\u3002"}}
{"id": "2506.22992", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.22992", "abs": "https://arxiv.org/abs/2506.22992", "authors": ["Yulun Jiang", "Yekun Chai", "Maria Brbi\u0107", "Michael Moor"], "title": "MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning", "comment": null, "summary": "The ability to process information from multiple modalities and to reason\nthrough it step-by-step remains a critical challenge in advancing artificial\nintelligence. However, existing reasoning benchmarks focus on text-only\nreasoning, or employ multimodal questions that can be answered by directly\nretrieving information from a non-text modality. Thus, complex reasoning\nremains poorly understood in multimodal domains. Here, we present MARBLE, a\nchallenging multimodal reasoning benchmark that is designed to scrutinize\nmultimodal language models (MLLMs) in their ability to carefully reason\nstep-by-step through complex multimodal problems and environments. MARBLE is\ncomposed of two highly challenging tasks, M-Portal and M-Cube, that require the\ncrafting and understanding of multistep plans under spatial, visual, and\nphysical constraints. We find that current MLLMs perform poorly on MARBLE --\nall the 12 advanced models obtain near-random performance on M-Portal and 0%\naccuracy on M-Cube. Only in simplified subtasks some models outperform the\nrandom baseline, indicating that complex reasoning is still a challenge for\nexisting MLLMs. Moreover, we show that perception remains a bottleneck, where\nMLLMs occasionally fail to extract information from the visual inputs. By\nshedding a light on the limitations of MLLMs, we hope that MARBLE will spur the\ndevelopment of the next generation of models with the ability to reason and\nplan across many, multimodal reasoning steps.", "AI": {"tldr": "MARBLE\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u8bc4\u4f30\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u590d\u6742\u591a\u6a21\u6001\u73af\u5883\u4e2d\u7684\u9010\u6b65\u63a8\u7406\u80fd\u529b\u3002\u73b0\u6709\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u8868\u660e\u590d\u6742\u63a8\u7406\u4ecd\u662f\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u591a\u96c6\u4e2d\u4e8e\u6587\u672c\u6216\u7b80\u5355\u591a\u6a21\u6001\u95ee\u9898\uff0c\u590d\u6742\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "MARBLE\u5305\u542b\u4e24\u4e2a\u9ad8\u96be\u5ea6\u4efb\u52a1\uff08M-Portal\u548cM-Cube\uff09\uff0c\u8981\u6c42\u6a21\u578b\u5728\u7a7a\u95f4\u3001\u89c6\u89c9\u548c\u7269\u7406\u7ea6\u675f\u4e0b\u5236\u5b9a\u548c\u7406\u89e3\u591a\u6b65\u8ba1\u5212\u3002", "result": "12\u4e2a\u5148\u8fdb\u6a21\u578b\u5728M-Portal\u4e0a\u8868\u73b0\u63a5\u8fd1\u968f\u673a\uff0cM-Cube\u4e0a\u51c6\u786e\u7387\u4e3a0%\uff0c\u4ec5\u5728\u7b80\u5316\u5b50\u4efb\u52a1\u4e2d\u90e8\u5206\u6a21\u578b\u4f18\u4e8e\u968f\u673a\u57fa\u7ebf\u3002", "conclusion": "MARBLE\u63ed\u793a\u4e86MLLMs\u7684\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u611f\u77e5\u548c\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u7684\u4e0d\u8db3\uff0c\u5e0c\u671b\u63a8\u52a8\u4e0b\u4e00\u4ee3\u6a21\u578b\u7684\u5f00\u53d1\u3002"}}
{"id": "2506.22949", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22949", "abs": "https://arxiv.org/abs/2506.22949", "authors": ["Ehsan Hallaji", "Vaishnavi Shanmugam", "Roozbeh Razavi-Far", "Mehrdad Saif"], "title": "A Study on Semi-Supervised Detection of DDoS Attacks under Class Imbalance", "comment": "Accepted for publication in IEEE CCECE 2025", "summary": "One of the most difficult challenges in cybersecurity is eliminating\nDistributed Denial of Service (DDoS) attacks. Automating this task using\nartificial intelligence is a complex process due to the inherent class\nimbalance and lack of sufficient labeled samples of real-world datasets. This\nresearch investigates the use of Semi-Supervised Learning (SSL) techniques to\nimprove DDoS attack detection when data is imbalanced and partially labeled. In\nthis process, 13 state-of-the-art SSL algorithms are evaluated for detecting\nDDoS attacks in several scenarios. We evaluate their practical efficacy and\nshortcomings, including the extent to which they work in extreme environments.\nThe results will offer insight into designing intelligent Intrusion Detection\nSystems (IDSs) that are robust against class imbalance and handle partially\nlabeled data.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u534a\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u5728\u89e3\u51b3DDoS\u653b\u51fb\u68c0\u6d4b\u4e2d\u6570\u636e\u4e0d\u5e73\u8861\u548c\u90e8\u5206\u6807\u8bb0\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u8bc4\u4f30\u4e8613\u79cdSSL\u7b97\u6cd5\u7684\u6548\u679c\u3002", "motivation": "\u7f51\u7edc\u5b89\u5168\u4e2dDDoS\u653b\u51fb\u68c0\u6d4b\u9762\u4e34\u6570\u636e\u4e0d\u5e73\u8861\u548c\u6807\u8bb0\u4e0d\u8db3\u7684\u6311\u6218\uff0c\u9700\u8981\u81ea\u52a8\u5316\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bc4\u4f3013\u79cd\u5148\u8fdb\u7684SSL\u7b97\u6cd5\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684DDoS\u653b\u51fb\u68c0\u6d4b\u80fd\u529b\uff0c\u5206\u6790\u5176\u5b9e\u9645\u6548\u679c\u548c\u5c40\u9650\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u6297\u6570\u636e\u4e0d\u5e73\u8861\u4e14\u80fd\u5904\u7406\u90e8\u5206\u6807\u8bb0\u6570\u636e\u7684\u667a\u80fd\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff08IDS\uff09\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "conclusion": "SSL\u6280\u672f\u80fd\u6709\u6548\u63d0\u5347DDoS\u653b\u51fb\u68c0\u6d4b\u6027\u80fd\uff0c\u5c24\u5176\u5728\u6570\u636e\u4e0d\u5e73\u8861\u548c\u6807\u8bb0\u4e0d\u8db3\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2506.23234", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23234", "abs": "https://arxiv.org/abs/2506.23234", "authors": ["Peerachai Banyongrakkul", "Mansooreh Zahedi", "Patanamon Thongtanunam", "Christoph Treude", "Haoyu Gao"], "title": "From Release to Adoption: Challenges in Reusing Pre-trained AI Models for Downstream Developers", "comment": "Recently accepted at ICSME 2025", "summary": "Pre-trained models (PTMs) have gained widespread popularity and achieved\nremarkable success across various fields, driven by their groundbreaking\nperformance and easy accessibility through hosting providers. However, the\nchallenges faced by downstream developers in reusing PTMs in software systems\nare less explored. To bridge this knowledge gap, we qualitatively created and\nanalyzed a dataset of 840 PTM-related issue reports from 31 OSS GitHub\nprojects. We systematically developed a comprehensive taxonomy of PTM-related\nchallenges that developers face in downstream projects. Our study identifies\nseven key categories of challenges that downstream developers face in reusing\nPTMs, such as model usage, model performance, and output quality. We also\ncompared our findings with existing taxonomies. Additionally, we conducted a\nresolution time analysis and, based on statistical tests, found that\nPTM-related issues take significantly longer to be resolved than issues\nunrelated to PTMs, with significant variation across challenge categories. We\ndiscuss the implications of our findings for practitioners and possibilities\nfor future research.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\uff08PTMs\uff09\u5728\u4e0b\u6e38\u5f00\u53d1\u4e2d\u7684\u6311\u6218\uff0c\u5206\u6790\u4e86840\u4e2aGitHub\u95ee\u9898\u62a5\u544a\uff0c\u63d0\u51fa\u4e867\u7c7b\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u53d1\u73b0PTM\u76f8\u5173\u95ee\u9898\u89e3\u51b3\u65f6\u95f4\u66f4\u957f\u3002", "motivation": "\u9884\u8bad\u7ec3\u6a21\u578b\uff08PTMs\uff09\u6027\u80fd\u4f18\u5f02\u4e14\u6613\u4e8e\u83b7\u53d6\uff0c\u4f46\u5176\u5728\u4e0b\u6e38\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u7684\u91cd\u7528\u6311\u6218\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5b9a\u6027\u5206\u679031\u4e2a\u5f00\u6e90GitHub\u9879\u76ee\u7684840\u4e2aPTM\u76f8\u5173\u95ee\u9898\u62a5\u544a\uff0c\u7cfb\u7edf\u6784\u5efa\u4e86\u6311\u6218\u5206\u7c7b\u3002", "result": "\u8bc6\u522b\u4e867\u7c7b\u4e3b\u8981\u6311\u6218\uff08\u5982\u6a21\u578b\u4f7f\u7528\u3001\u6027\u80fd\u7b49\uff09\uff0c\u5e76\u53d1\u73b0PTM\u76f8\u5173\u95ee\u9898\u89e3\u51b3\u65f6\u95f4\u663e\u8457\u66f4\u957f\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5b9e\u8df5\u542f\u793a\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.23049", "categories": ["cs.AI", "cs.CL", "cs.SD", "eess.AS", "68T42, 68T50,", "I.2.7; I.2.11; H.5.5"], "pdf": "https://arxiv.org/pdf/2506.23049", "abs": "https://arxiv.org/abs/2506.23049", "authors": ["Leander Melroy Maben", "Gayathri Ganesh Lakshmy", "Srijith Radhakrishnan", "Siddhant Arora", "Shinji Watanabe"], "title": "AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks", "comment": null, "summary": "Despite advances in language and speech technologies, no open-source system\nenables full speech-to-speech, multi-turn dialogue with integrated tool use and\nagentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and\nAutomated Tool Use), the first open-source, speech-native assistant capable of\ncompleting complex, goal-driven tasks through dynamic tool invocation and\nmulti-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a\ncascaded pipeline and supports tools such as calendar booking, contact lookup,\nweb search, and email. Its modular design allows easy integration of new tools\nusing natural language prompts and action classes. On VoiceBench, AURA scores\n92.75% on OpenBookQA-outperforming all open-weight systems and nearing\nGPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems.\nHuman evaluation shows 90% task success on complex, multi-turn speech tasks.", "AI": {"tldr": "AURA\u662f\u9996\u4e2a\u5f00\u6e90\u3001\u652f\u6301\u8bed\u97f3\u7684\u539f\u751f\u52a9\u624b\uff0c\u80fd\u591f\u901a\u8fc7\u52a8\u6001\u5de5\u5177\u8c03\u7528\u548c\u591a\u8f6e\u5bf9\u8bdd\u5b8c\u6210\u590d\u6742\u4efb\u52a1\u3002", "motivation": "\u5c3d\u7ba1\u8bed\u8a00\u548c\u8bed\u97f3\u6280\u672f\u6709\u6240\u8fdb\u6b65\uff0c\u4f46\u5c1a\u65e0\u5f00\u6e90\u7cfb\u7edf\u652f\u6301\u5b8c\u6574\u7684\u8bed\u97f3\u5230\u8bed\u97f3\u3001\u591a\u8f6e\u5bf9\u8bdd\uff0c\u5e76\u96c6\u6210\u5de5\u5177\u4f7f\u7528\u548c\u4ee3\u7406\u63a8\u7406\u3002", "method": "AURA\u7ed3\u5408\u4e86\u5f00\u6e90\u7684ASR\u3001TTS\u548cLLM\uff0c\u91c7\u7528\u7ea7\u8054\u6d41\u6c34\u7ebf\u8bbe\u8ba1\uff0c\u652f\u6301\u65e5\u5386\u9884\u8ba2\u3001\u8054\u7cfb\u4eba\u67e5\u627e\u3001\u7f51\u7edc\u641c\u7d22\u548c\u7535\u5b50\u90ae\u4ef6\u7b49\u5de5\u5177\u3002", "result": "\u5728VoiceBench\u4e0a\uff0cAURA\u5728OpenBookQA\u4e2d\u5f97\u520692.75%\uff0c\u63a5\u8fd1GPT-4o\uff1b\u5728AlpacaEval\u4e2d\u5f97\u5206\u4e3a4.39\uff0c\u4e0e\u5176\u4ed6\u5f00\u6e90\u7cfb\u7edf\u7ade\u4e89\u3002\u4eba\u7c7b\u8bc4\u4f30\u663e\u793a\uff0c\u590d\u6742\u591a\u8f6e\u8bed\u97f3\u4efb\u52a1\u7684\u6210\u529f\u7387\u4e3a90%\u3002", "conclusion": "AURA\u662f\u9996\u4e2a\u5f00\u6e90\u3001\u8bed\u97f3\u539f\u751f\u7684\u52a9\u624b\uff0c\u80fd\u591f\u9ad8\u6548\u5b8c\u6210\u590d\u6742\u4efb\u52a1\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.23050", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23050", "abs": "https://arxiv.org/abs/2506.23050", "authors": ["David Cornwell"], "title": "Equivalence Classes in AES -- Part 1", "comment": null, "summary": "We investigate properties of equivalence classes in AES which arise naturally\nfrom properties of MixColumns and InvMixColumns. These two operations have the\nproperty that the XOR of the 4 input bytes equals the XOR of 4 output bytes. We\nexamine the effect on equivalence classes due to the operation of SubBytes,\nShiftRows, MixColumns and AddRoundKey. The next phase of research is to find a\nkey recovery attack using known (plaintext, ciphertext) equivalence class\npairs.\n  Keywords: AES, Equivalence, Class, MixColumns, ShiftRows, SubBytes,\nAddRoundKey, Schedule, State, XOR", "AI": {"tldr": "\u7814\u7a76AES\u4e2d\u7531MixColumns\u548cInvMixColumns\u64cd\u4f5c\u81ea\u7136\u4ea7\u751f\u7684\u7b49\u4ef7\u7c7b\u6027\u8d28\uff0c\u63a2\u8ba8SubBytes\u3001ShiftRows\u3001MixColumns\u548cAddRoundKey\u64cd\u4f5c\u5bf9\u7b49\u4ef7\u7c7b\u7684\u5f71\u54cd\uff0c\u5e76\u8ba1\u5212\u8fdb\u4e00\u6b65\u7814\u7a76\u57fa\u4e8e\u5df2\u77e5\u660e\u6587-\u5bc6\u6587\u7b49\u4ef7\u7c7b\u5bf9\u7684\u5bc6\u94a5\u6062\u590d\u653b\u51fb\u3002", "motivation": "\u63a2\u7d22AES\u4e2dMixColumns\u548cInvMixColumns\u64cd\u4f5c\u5bfc\u81f4\u7684\u7b49\u4ef7\u7c7b\u6027\u8d28\uff0c\u4ee5\u7406\u89e3\u5176\u5bf9\u52a0\u5bc6\u8fc7\u7a0b\u7684\u5f71\u54cd\u3002", "method": "\u5206\u6790SubBytes\u3001ShiftRows\u3001MixColumns\u548cAddRoundKey\u64cd\u4f5c\u5bf9\u7b49\u4ef7\u7c7b\u7684\u5f71\u54cd\u3002", "result": "\u63ed\u793a\u4e86\u8fd9\u4e9b\u64cd\u4f5c\u5bf9\u7b49\u4ef7\u7c7b\u7684\u5177\u4f53\u5f71\u54cd\u3002", "conclusion": "\u8ba1\u5212\u4e0b\u4e00\u6b65\u7814\u7a76\u5229\u7528\u5df2\u77e5\u660e\u6587-\u5bc6\u6587\u7b49\u4ef7\u7c7b\u5bf9\u8fdb\u884c\u5bc6\u94a5\u6062\u590d\u653b\u51fb\u3002"}}
{"id": "2506.23281", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2506.23281", "abs": "https://arxiv.org/abs/2506.23281", "authors": ["Xintong Zhou", "Zhenyang Xu", "Chengnian Sun"], "title": "On the Feasibility of Deduplicating Compiler Bugs with Bisection", "comment": null, "summary": "Random testing has proven to be an effective technique for compiler\nvalidation. However, the debugging of bugs identified through random testing\npresents a significant challenge due to the frequent occurrence of duplicate\ntest programs that expose identical compiler bugs. The process to identify\nduplicates is a practical research problem known as bug deduplication. Prior\nmethodologies for compiler bug deduplication primarily rely on program analysis\nto extract bug-related features for duplicate identification, which can result\nin substantial computational overhead and limited generalizability. This paper\ninvestigates the feasibility of employing bisection, a standard debugging\nprocedure largely overlooked in prior research on compiler bug deduplication,\nfor this purpose. Our study demonstrates that the utilization of bisection to\nlocate failure-inducing commits provides a valuable criterion for\ndeduplication, albeit one that requires supplementary techniques for more\naccurate identification. Building on these results, we introduce BugLens, a\nnovel deduplication method that primarily uses bisection, enhanced by the\nidentification of bug-triggering optimizations to minimize false negatives.\nEmpirical evaluations conducted on four real-world datasets demonstrate that\nBugLens significantly outperforms the state-of-the-art analysis-based\nmethodologies Tamer and D3 by saving an average of 26.98% and 9.64% human\neffort to identify the same number of distinct bugs. Given the inherent\nsimplicity and generalizability of bisection, it presents a highly practical\nsolution for compiler bug deduplication in real-world applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8c\u5206\u6cd5\u7684\u7f16\u8bd1\u5668Bug\u53bb\u91cd\u65b9\u6cd5BugLens\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u968f\u673a\u6d4b\u8bd5\u53d1\u73b0\u7684\u7f16\u8bd1\u5668Bug\u5b58\u5728\u5927\u91cf\u91cd\u590d\uff0c\u4f20\u7edf\u57fa\u4e8e\u7a0b\u5e8f\u5206\u6790\u7684\u53bb\u91cd\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u6cdb\u5316\u6027\u5dee\u3002", "method": "\u5229\u7528\u4e8c\u5206\u6cd5\u5b9a\u4f4d\u5bfc\u81f4Bug\u7684\u63d0\u4ea4\uff0c\u5e76\u7ed3\u5408\u89e6\u53d1Bug\u7684\u4f18\u5316\u4fe1\u606f\uff0c\u63d0\u51faBugLens\u65b9\u6cd5\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cBugLens\u6bd4\u73b0\u6709\u65b9\u6cd5Tamer\u548cD3\u5e73\u5747\u8282\u770126.98%\u548c9.64%\u7684\u4eba\u529b\u3002", "conclusion": "\u4e8c\u5206\u6cd5\u56e0\u5176\u7b80\u5355\u6027\u548c\u6cdb\u5316\u6027\uff0c\u4e3a\u7f16\u8bd1\u5668Bug\u53bb\u91cd\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.23080", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23080", "abs": "https://arxiv.org/abs/2506.23080", "authors": ["Xinmin Fang", "Lingfeng Tao", "Zhengxiong Li"], "title": "AI's Euclid's Elements Moment: From Language Models to Computable Thought", "comment": null, "summary": "This paper presents a comprehensive five-stage evolutionary framework for\nunderstanding the development of artificial intelligence, arguing that its\ntrajectory mirrors the historical progression of human cognitive technologies.\nWe posit that AI is advancing through distinct epochs, each defined by a\nrevolutionary shift in its capacity for representation and reasoning, analogous\nto the inventions of cuneiform, the alphabet, grammar and logic, mathematical\ncalculus, and formal logical systems. This \"Geometry of Cognition\" framework\nmoves beyond mere metaphor to provide a systematic, cross-disciplinary model\nthat not only explains AI's past architectural shifts-from expert systems to\nTransformers-but also charts a concrete and prescriptive path forward.\nCrucially, we demonstrate that this evolution is not merely linear but\nreflexive: as AI advances through these stages, the tools and insights it\ndevelops create a feedback loop that fundamentally reshapes its own underlying\narchitecture. We are currently transitioning into a \"Metalinguistic Moment,\"\ncharacterized by the emergence of self-reflective capabilities like\nChain-of-Thought prompting and Constitutional AI. The subsequent stages, the\n\"Mathematical Symbolism Moment\" and the \"Formal Logic System Moment,\" will be\ndefined by the development of a computable calculus of thought, likely through\nneuro-symbolic architectures and program synthesis, culminating in provably\naligned and reliable AI that reconstructs its own foundational representations.\nThis work serves as the methodological capstone to our trilogy, which\npreviously explored the economic drivers (\"why\") and cognitive nature (\"what\")\nof AI. Here, we address the \"how,\" providing a theoretical foundation for\nfuture research and offering concrete, actionable strategies for startups and\ndevelopers aiming to build the next generation of intelligent systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e94\u9636\u6bb5\u8fdb\u5316\u6846\u67b6\uff0c\u5c06AI\u7684\u53d1\u5c55\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u6280\u672f\u7684\u5386\u53f2\u8fdb\u7a0b\u7c7b\u6bd4\uff0c\u63ed\u793a\u4e86AI\u4ece\u4e13\u5bb6\u7cfb\u7edf\u5230Transformers\u7684\u6f14\u53d8\uff0c\u5e76\u9884\u6d4b\u4e86\u672a\u6765\u7684\u53d1\u5c55\u9636\u6bb5\u3002", "motivation": "\u63a2\u7d22AI\u53d1\u5c55\u7684\u7cfb\u7edf\u6027\u6a21\u5f0f\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u548c\u5177\u4f53\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u201c\u8ba4\u77e5\u51e0\u4f55\u201d\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u6bd4\u4eba\u7c7b\u8ba4\u77e5\u6280\u672f\u7684\u6f14\u53d8\uff0c\u5206\u6790AI\u7684\u4e94\u4e2a\u53d1\u5c55\u9636\u6bb5\u53ca\u5176\u53cd\u9988\u673a\u5236\u3002", "result": "\u63ed\u793a\u4e86AI\u53d1\u5c55\u7684\u975e\u7ebf\u6027\u3001\u81ea\u53cd\u6027\u7279\u5f81\uff0c\u5e76\u9884\u6d4b\u4e86\u672a\u6765\u7684\u201c\u5143\u8bed\u8a00\u65f6\u523b\u201d\u3001\u201c\u6570\u5b66\u7b26\u53f7\u65f6\u523b\u201d\u548c\u201c\u5f62\u5f0f\u903b\u8f91\u7cfb\u7edf\u65f6\u523b\u201d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u57fa\u7840\uff0c\u5e76\u4e3a\u5f00\u53d1\u4e0b\u4e00\u4ee3\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5177\u4f53\u7b56\u7565\u3002"}}
{"id": "2506.23183", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23183", "abs": "https://arxiv.org/abs/2506.23183", "authors": ["De Zhang Lee", "Aashish Kolluri", "Prateek Saxena", "Ee-Chien Chang"], "title": "A Practical and Secure Byzantine Robust Aggregator", "comment": null, "summary": "In machine learning security, one is often faced with the problem of removing\noutliers from a given set of high-dimensional vectors when computing their\naverage. For example, many variants of data poisoning attacks produce gradient\nvectors during training that are outliers in the distribution of clean\ngradients, which bias the computed average used to derive the ML model.\nFiltering them out before averaging serves as a generic defense strategy.\nByzantine robust aggregation is an algorithmic primitive which computes a\nrobust average of vectors, in the presence of an $\\epsilon$ fraction of vectors\nwhich may have been arbitrarily and adaptively corrupted, such that the\nresulting bias in the final average is provably bounded.\n  In this paper, we give the first robust aggregator that runs in quasi-linear\ntime in the size of input vectors and provably has near-optimal bias bounds.\nOur algorithm also does not assume any knowledge of the distribution of clean\nvectors, nor does it require pre-computing any filtering thresholds from it.\nThis makes it practical to use directly in standard neural network training\nprocedures. We empirically confirm its expected runtime efficiency and its\neffectiveness in nullifying 10 different ML poisoning attacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u9c81\u68d2\u805a\u5408\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u9ad8\u7ef4\u5411\u91cf\u4e2d\u53bb\u9664\u5f02\u5e38\u503c\u5e76\u8ba1\u7b97\u5e73\u5747\u503c\uff0c\u9002\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u5b89\u5168\u4e2d\u7684\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u5b89\u5168\u4e2d\u6570\u636e\u6295\u6bd2\u653b\u51fb\u5bfc\u81f4\u7684\u68af\u5ea6\u5f02\u5e38\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\u7684\u9c81\u68d2\u805a\u5408\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u51c6\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u9c81\u68d2\u805a\u5408\u7b97\u6cd5\uff0c\u65e0\u9700\u9884\u5148\u8ba1\u7b97\u8fc7\u6ee4\u9608\u503c\u6216\u5047\u8bbe\u5e72\u51c0\u5411\u91cf\u7684\u5206\u5e03\u3002", "result": "\u7b97\u6cd5\u5728\u7406\u8bba\u4e0a\u6709\u63a5\u8fd1\u6700\u4f18\u7684\u504f\u5dee\u754c\u9650\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u8fd0\u884c\u6548\u7387\u548c\u9632\u5fa110\u79cd\u6295\u6bd2\u653b\u51fb\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5b9e\u7528\u6027\u5f3a\uff0c\u53ef\u76f4\u63a5\u7528\u4e8e\u6807\u51c6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u5b89\u5168\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u9632\u5fa1\u624b\u6bb5\u3002"}}
{"id": "2506.23534", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23534", "abs": "https://arxiv.org/abs/2506.23534", "authors": ["Siyu Chen", "Jiongyi Yang", "Xiang Chen", "Menglin Zheng", "Minnan Wei", "Xiaolin Ju"], "title": "Improving vulnerability type prediction and line-level detection via adversarial training-based data augmentation and multi-task learning", "comment": null, "summary": "Context: Software vulnerabilities pose a significant threat to modern\nsoftware systems, as evidenced by the growing number of reported\nvulnerabilities and cyberattacks. These escalating trends underscore the urgent\nneed for effective approaches that can automatically detect and understand\nsoftware vulnerabilities. Objective: However, the scarcity of labeled samples\nand the class imbalance issue in vulnerability datasets present significant\nchallenges for both Vulnerability Type Prediction (VTP) and Line-level\nVulnerability Detection (LVD), especially for rare yet critical vulnerability\ntypes. Moreover, most existing studies treat VTP and LVD as independent tasks,\noverlooking their inherent correlation, which limits the potential to leverage\nshared semantic patterns across tasks. Methods: To address these limitations,\nwe propose a unified approach that integrates Embedding-Layer Driven\nAdversarial Training (EDAT) with Multi-task Learning (MTL). Specifically, EDAT\nenhances model robustness by introducing adversarial perturbations to\nidentifier embeddings, guided by semantic importance. Meanwhile, MTL improves\noverall performance by leveraging shared representations and inter-task\ncorrelations between VTP and LVD. Results: Extensive experiments demonstrate\nthat our proposed approach outperforms state-of-the-art baselines on both VTP\nand LVD tasks. For VTP, it yields notable improvements in accuracy, precision,\nrecall, and F1-score, particularly in identifying rare vulnerability types.\nSimilarly, for LVD, our approach enhances line-level detection accuracy while\nsignificantly reducing false positives. Conclusion: Our study demonstrates that\ncombining EDAT with MTL provides a unified solution that improves performance\non both tasks and warrants further investigation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408EDAT\u548cMTL\u7684\u7edf\u4e00\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86VTP\u548cLVD\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5bf9\u7f55\u89c1\u6f0f\u6d1e\u7c7b\u578b\u7684\u8bc6\u522b\u3002", "motivation": "\u8f6f\u4ef6\u6f0f\u6d1e\u5bf9\u73b0\u4ee3\u7cfb\u7edf\u6784\u6210\u91cd\u5927\u5a01\u80c1\uff0c\u73b0\u6709\u65b9\u6cd5\u56e0\u6837\u672c\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u53d7\u9650\uff0c\u4e14\u5ffd\u89c6\u4e86VTP\u548cLVD\u4efb\u52a1\u95f4\u7684\u76f8\u5173\u6027\u3002", "method": "\u91c7\u7528\u5d4c\u5165\u5c42\u9a71\u52a8\u7684\u5bf9\u6297\u8bad\u7ec3\uff08EDAT\uff09\u548c\u591a\u4efb\u52a1\u5b66\u4e60\uff08MTL\uff09\uff0c\u901a\u8fc7\u5171\u4eab\u8bed\u4e49\u6a21\u5f0f\u548c\u4efb\u52a1\u95f4\u76f8\u5173\u6027\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728VTP\u548cLVD\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f55\u89c1\u6f0f\u6d1e\u7c7b\u578b\u7684\u8bc6\u522b\u548c\u884c\u7ea7\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "EDAT\u4e0eMTL\u7684\u7ed3\u5408\u4e3a\u6f0f\u6d1e\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\uff0c\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.23107", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23107", "abs": "https://arxiv.org/abs/2506.23107", "authors": ["Bing Song", "Jianing Liu", "Sisi Jian", "Chenyang Wu", "Vinayak Dixit"], "title": "Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study", "comment": "20 pages, 1 figure", "summary": "Large language models (LLMs) have made significant strides, extending their\napplications to dialogue systems, automated content creation, and\ndomain-specific advisory tasks. However, as their use grows, concerns have\nemerged regarding their reliability in simulating complex decision-making\nbehavior, such as risky decision-making, where a single choice can lead to\nmultiple outcomes. This study investigates the ability of LLMs to simulate\nrisky decision-making scenarios. We compare model-generated decisions with\nactual human responses in a series of lottery-based tasks, using transportation\nstated preference survey data from participants in Sydney, Dhaka, Hong Kong,\nand Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and\nChatGPT o1-mini -- which were tasked with predicting individual choices. Risk\npreferences were analyzed using the Constant Relative Risk Aversion (CRRA)\nframework. Results show that both models exhibit more risk-averse behavior than\nhuman participants, with o1-mini aligning more closely with observed human\ndecisions. Further analysis of multilingual data from Nanjing and Hong Kong\nindicates that model predictions in Chinese deviate more from actual responses\ncompared to English, suggesting that prompt language may influence simulation\nperformance. These findings highlight both the promise and the current\nlimitations of LLMs in replicating human-like risk behavior, particularly in\nlinguistic and cultural settings.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6a21\u62df\u98ce\u9669\u51b3\u7b56\u884c\u4e3a\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u6bd4\u4eba\u7c7b\u66f4\u89c4\u907f\u98ce\u9669\uff0c\u4e14\u4e2d\u6587\u63d0\u793a\u4e0b\u8868\u73b0\u504f\u5dee\u66f4\u5927\u3002", "motivation": "\u968f\u7740LLMs\u5e94\u7528\u6269\u5c55\uff0c\u5176\u5728\u590d\u6742\u51b3\u7b56\u884c\u4e3a\uff08\u5982\u98ce\u9669\u51b3\u7b56\uff09\u4e2d\u7684\u53ef\u9760\u6027\u5f15\u53d1\u5173\u6ce8\uff0c\u9700\u9a8c\u8bc1\u5176\u6a21\u62df\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5f69\u7968\u4efb\u52a1\u6bd4\u8f83LLMs\uff08ChatGPT 4o\u548co1-mini\uff09\u4e0e\u4eba\u7c7b\u51b3\u7b56\uff0c\u4f7f\u7528CRRA\u6846\u67b6\u5206\u6790\u98ce\u9669\u504f\u597d\uff0c\u7ed3\u5408\u591a\u8bed\u8a00\u6570\u636e\u3002", "result": "\u6a21\u578b\u6bd4\u4eba\u7c7b\u66f4\u89c4\u907f\u98ce\u9669\uff0co1-mini\u66f4\u63a5\u8fd1\u4eba\u7c7b\u51b3\u7b56\uff1b\u4e2d\u6587\u63d0\u793a\u4e0b\u9884\u6d4b\u504f\u5dee\u66f4\u5927\u3002", "conclusion": "LLMs\u5728\u6a21\u62df\u4eba\u7c7b\u98ce\u9669\u884c\u4e3a\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u8bed\u8a00\u548c\u6587\u5316\u5dee\u5f02\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2506.23260", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23260", "abs": "https://arxiv.org/abs/2506.23260", "authors": ["Mohamed Amine Ferrag", "Norbert Tihanyi", "Djallel Hamouda", "Leandros Maglaras", "Merouane Debbah"], "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "comment": "29 pages, 15 figures, 6 tables", "summary": "Autonomous AI agents powered by large language models (LLMs) with structured\nfunction-calling interfaces have dramatically expanded capabilities for\nreal-time data retrieval, complex computation, and multi-step orchestration.\nYet, the explosive proliferation of plugins, connectors, and inter-agent\nprotocols has outpaced discovery mechanisms and security practices, resulting\nin brittle integrations vulnerable to diverse threats. In this survey, we\nintroduce the first unified, end-to-end threat model for LLM-agent ecosystems,\nspanning host-to-tool and agent-to-agent communications, formalize adversary\ncapabilities and attacker objectives, and catalog over thirty attack\ntechniques. Specifically, we organized the threat model into four domains:\nInput Manipulation (e.g., prompt injections, long-context hijacks, multimodal\nadversarial inputs), Model Compromise (e.g., prompt- and parameter-level\nbackdoors, composite and encrypted multi-backdoors, poisoning strategies),\nSystem and Privacy Attacks (e.g., speculative side-channels, membership\ninference, retrieval poisoning, social-engineering simulations), and Protocol\nVulnerabilities (e.g., exploits in Model Context Protocol (MCP), Agent\nCommunication Protocol (ACP), Agent Network Protocol (ANP), and Agent-to-Agent\n(A2A) protocol). For each category, we review representative scenarios, assess\nreal-world feasibility, and evaluate existing defenses. Building on our threat\ntaxonomy, we identify key open challenges and future research directions, such\nas securing MCP deployments through dynamic trust management and cryptographic\nprovenance tracking; designing and hardening Agentic Web Interfaces; and\nachieving resilience in multi-agent and federated environments. Our work\nprovides a comprehensive reference to guide the design of robust defense\nmechanisms and establish best practices for resilient LLM-agent workflows.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5a01\u80c1\u6a21\u578b\uff0c\u7528\u4e8e\u5206\u6790LLM\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u95ee\u9898\uff0c\u6db5\u76d6\u4e86\u8f93\u5165\u64cd\u7eb5\u3001\u6a21\u578b\u59a5\u534f\u3001\u7cfb\u7edf\u548c\u9690\u79c1\u653b\u51fb\u4ee5\u53ca\u534f\u8bae\u6f0f\u6d1e\u56db\u5927\u9886\u57df\uff0c\u5e76\u8bc4\u4f30\u4e86\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u3002", "motivation": "\u968f\u7740LLM\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u63d2\u4ef6\u548c\u534f\u8bae\u7684\u6fc0\u589e\u5bfc\u81f4\u4e86\u5b89\u5168\u5b9e\u8df5\u7684\u6ede\u540e\uff0c\u4f7f\u5f97\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u591a\u79cd\u5a01\u80c1\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5206\u7c7b\u548c\u5f62\u5f0f\u5316\u5a01\u80c1\u6a21\u578b\uff0c\u5206\u6790\u4e86\u56db\u5927\u9886\u57df\u4e2d\u7684\u653b\u51fb\u6280\u672f\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u73b0\u5b9e\u53ef\u884c\u6027\u548c\u9632\u5fa1\u63aa\u65bd\u3002", "result": "\u8bba\u6587\u603b\u7ed3\u4e86\u4e09\u5341\u591a\u79cd\u653b\u51fb\u6280\u672f\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5982\u52a8\u6001\u4fe1\u4efb\u7ba1\u7406\u548c\u52a0\u5bc6\u6eaf\u6e90\u7b49\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8bbe\u8ba1\u7a33\u5065\u7684\u9632\u5fa1\u673a\u5236\u548c\u5efa\u7acbLLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u7684\u6700\u4f73\u5b9e\u8df5\u63d0\u4f9b\u4e86\u5168\u9762\u53c2\u8003\u3002"}}
{"id": "2506.23535", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23535", "abs": "https://arxiv.org/abs/2506.23535", "authors": ["Malik Muhammad Umer"], "title": "Comparative Analysis of the Code Generated by Popular Large Language Models (LLMs) for MISRA C++ Compliance", "comment": null, "summary": "Safety-critical systems are engineered systems whose failure or malfunction\ncould result in catastrophic consequences. The software development for\nsafety-critical systems necessitates rigorous engineering practices and\nadherence to certification standards like DO-178C for avionics. DO-178C is a\nguidance document which requires compliance to well-defined software coding\nstandards like MISRA C++ to enforce coding guidelines that prevent the use of\nambiguous, unsafe, or undefined constructs. Large Language Models (LLMs) have\ndemonstrated significant capabilities in automatic code generation across a\nwide range of programming languages, including C++. Despite their impressive\nperformance, code generated by LLMs in safety-critical domains must be\ncarefully analyzed for conformance to MISRA C++ coding standards. In this\npaper, I have conducted a comparative analysis of the C++ code generated by\npopular LLMs including: OpenAI ChatGPT, Google Gemini, DeepSeek, Meta AI, and\nMicrosoft Copilot for compliance with MISRA C++.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6bd4\u8f83\u4e86\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982ChatGPT\u3001Gemini\u3001DeepSeek\u3001Meta AI\u548cCopilot\uff09\u751f\u6210\u7684C++\u4ee3\u7801\u662f\u5426\u7b26\u5408MISRA C++\u5b89\u5168\u7f16\u7801\u6807\u51c6\u3002", "motivation": "\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u7684\u8f6f\u4ef6\u5f00\u53d1\u9700\u4e25\u683c\u9075\u5b88\u7f16\u7801\u6807\u51c6\uff08\u5982MISRA C++\uff09\uff0c\u800cLLMs\u751f\u6210\u7684\u4ee3\u7801\u53ef\u80fd\u4e0d\u7b26\u5408\u8fd9\u4e9b\u6807\u51c6\uff0c\u56e0\u6b64\u9700\u8981\u9a8c\u8bc1\u5176\u5408\u89c4\u6027\u3002", "method": "\u5bf9\u591a\u4e2a\u6d41\u884cLLMs\u751f\u6210\u7684C++\u4ee3\u7801\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c\u8bc4\u4f30\u5176\u662f\u5426\u7b26\u5408MISRA C++\u6807\u51c6\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86\u4e0d\u540cLLMs\u751f\u6210\u7684\u4ee3\u7801\u5728MISRA C++\u5408\u89c4\u6027\u65b9\u9762\u7684\u8868\u73b0\u3002", "conclusion": "LLMs\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u4ee3\u7801\u751f\u6210\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u786e\u4fdd\u7b26\u5408\u4e25\u683c\u7684\u7f16\u7801\u6807\u51c6\u3002"}}
{"id": "2506.23123", "categories": ["cs.AI", "cs.CY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.23123", "abs": "https://arxiv.org/abs/2506.23123", "authors": ["Rishi Bommasani"], "title": "The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy", "comment": "Stanford University PhD Dissertation of Rishi Bommasani (Department\n  of Computer Science, 2025). Also available at\n  https://purl.stanford.edu/zf669yy0336", "summary": "Artificial intelligence is humanity's most promising technology because of\nthe remarkable capabilities offered by foundation models. Yet, the same\ntechnology brings confusion and consternation: foundation models are poorly\nunderstood and they may precipitate a wide array of harms. This dissertation\nexplains how technology and society coevolve in the age of AI, organized around\nthree themes. First, the conceptual framing: the capabilities, risks, and the\nsupply chain that grounds foundation models in the broader economy. Second, the\nempirical insights that enrich the conceptual foundations: transparency created\nvia evaluations at the model level and indexes at the organization level.\nFinally, the transition from understanding to action: superior understanding of\nthe societal impact of foundation models advances evidence-based AI policy.\nView together, this dissertation makes inroads into achieving better societal\noutcomes in the age of AI by building the scientific foundations and\nresearch-policy interface required for better AI governance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u57fa\u7840\u6a21\u578b\u5728AI\u65f6\u4ee3\u5bf9\u793e\u4f1a\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u6982\u5ff5\u6846\u67b6\u3001\u5b9e\u8bc1\u89c1\u89e3\u548c\u653f\u7b56\u884c\u52a8\uff0c\u65e8\u5728\u6539\u5584AI\u6cbb\u7406\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u4e5f\u5e26\u6765\u56f0\u60d1\u548c\u6f5c\u5728\u5371\u5bb3\uff0c\u9700\u8981\u66f4\u597d\u5730\u7406\u89e3\u5176\u793e\u4f1a\u5f71\u54cd\u4ee5\u63a8\u52a8\u6709\u6548\u6cbb\u7406\u3002", "method": "\u56f4\u7ed5\u4e09\u4e2a\u4e3b\u9898\u5c55\u5f00\uff1a\u6982\u5ff5\u6846\u67b6\uff08\u80fd\u529b\u3001\u98ce\u9669\u3001\u4f9b\u5e94\u94fe\uff09\u3001\u5b9e\u8bc1\u89c1\u89e3\uff08\u6a21\u578b\u8bc4\u4f30\u548c\u7ec4\u7ec7\u900f\u660e\u5ea6\uff09\u3001\u653f\u7b56\u884c\u52a8\uff08\u57fa\u4e8e\u8bc1\u636e\u7684AI\u653f\u7b56\uff09\u3002", "result": "\u901a\u8fc7\u79d1\u5b66\u57fa\u7840\u548c\u653f\u7b56\u7814\u7a76\u63a5\u53e3\uff0c\u4e3aAI\u65f6\u4ee3\u5b9e\u73b0\u66f4\u597d\u7684\u793e\u4f1a\u6210\u679c\u63d0\u4f9b\u4e86\u8def\u5f84\u3002", "conclusion": "\u8bba\u6587\u4e3aAI\u6cbb\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u793e\u4f1a\u5bf9\u57fa\u7840\u6a21\u578b\u7684\u7406\u89e3\u548c\u653f\u7b56\u5236\u5b9a\u3002"}}
{"id": "2506.23294", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23294", "abs": "https://arxiv.org/abs/2506.23294", "authors": ["Mostafa Abdelrahman", "Filip Rezabek", "Lars Hupel", "Kilian Glas", "Georg Carle"], "title": "Threshold Signatures for Central Bank Digital Currencies", "comment": null, "summary": "Digital signatures are crucial for securing Central Bank Digital Currencies\n(CBDCs) transactions. Like most forms of digital currencies, CBDC solutions\nrely on signatures for transaction authenticity and integrity, leading to major\nissues in the case of private key compromise. Our work explores threshold\nsignature schemes (TSSs) in the context of CBDCs. TSSs allow distributed key\nmanagement and signing, reducing the risk of a compromised key. We analyze\nCBDC-specific requirements, considering the applicability of TSSs, and use\nFilia CBDC solution as a base for a detailed evaluation. As most of the current\nsolutions rely on ECDSA for compatibility, we focus on ECDSA-based TSSs and\ntheir supporting libraries. Our performance evaluation measured the\ncomputational and communication complexity across key processes, as well as the\nthroughput and latency of end-to-end transactions. The results confirm that TSS\ncan enhance the security of CBDC implementations while maintaining acceptable\nperformance for real-world deployments.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u592e\u884c\u6570\u5b57\u8d27\u5e01\uff08CBDC\uff09\u4e2d\u4f7f\u7528\u9608\u503c\u7b7e\u540d\u65b9\u6848\uff08TSS\uff09\u4ee5\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u6027\u80fd\u3002", "motivation": "CBDC\u4f9d\u8d56\u6570\u5b57\u7b7e\u540d\u786e\u4fdd\u4ea4\u6613\u771f\u5b9e\u6027\uff0c\u4f46\u79c1\u94a5\u6cc4\u9732\u98ce\u9669\u5927\uff0cTSS\u80fd\u5206\u6563\u5bc6\u94a5\u7ba1\u7406\uff0c\u964d\u4f4e\u98ce\u9669\u3002", "method": "\u5206\u6790\u4e86CBDC\u9700\u6c42\uff0c\u8bc4\u4f30\u4e86\u57fa\u4e8eECDSA\u7684TSS\u53ca\u5176\u5e93\uff0c\u4ee5Filia CBDC\u4e3a\u57fa\u7840\u8fdb\u884c\u6027\u80fd\u6d4b\u8bd5\u3002", "result": "TSS\u80fd\u63d0\u5347CBDC\u5b89\u5168\u6027\uff0c\u4e14\u6027\u80fd\u6ee1\u8db3\u5b9e\u9645\u90e8\u7f72\u9700\u6c42\u3002", "conclusion": "TSS\u662fCBDC\u5b89\u5168\u5b9e\u73b0\u7684\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.23644", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23644", "abs": "https://arxiv.org/abs/2506.23644", "authors": ["Junze Hu", "Xiangyu Jin", "Yizhe Zeng", "Yuling Liu", "Yunpeng Li", "Dan Du", "Kaiyu Xie", "Hongsong Zhu"], "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration", "comment": null, "summary": "We introduce QLPro, a vulnerability detection framework that systematically\nintegrates LLMs and static analysis tools to enable comprehensive vulnerability\ndetection across entire open-source projects.We constructed a new dataset,\nJavaTest, comprising 10 open-source projects from GitHub with 62 confirmed\nvulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only\n24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro\ndiscovered 6 previously unknown vulnerabilities, 2 of which have been confirmed\nas 0-days.", "AI": {"tldr": "QLPro\u662f\u4e00\u4e2a\u7ed3\u5408LLM\u548c\u9759\u6001\u5206\u6790\u5de5\u5177\u7684\u6f0f\u6d1e\u68c0\u6d4b\u6846\u67b6\uff0c\u5728\u5f00\u6e90\u9879\u76ee\u4e2d\u8868\u73b0\u4f18\u4e8eCodeQL\uff0c\u68c0\u6d4b\u5230\u66f4\u591a\u6f0f\u6d1e\u5e76\u53d1\u73b0\u65b0\u76840-day\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u9759\u6001\u5206\u6790\u5de5\u5177\uff08\u5982CodeQL\uff09\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u5b58\u5728\u6f0f\u62a5\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "QLPro\u7cfb\u7edf\u6027\u5730\u6574\u5408\u4e86LLM\u548c\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u6784\u5efa\u4e86\u65b0\u7684\u6570\u636e\u96c6JavaTest\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "QLPro\u68c0\u6d4b\u523041\u4e2a\u6f0f\u6d1e\uff08CodeQL\u4ec524\u4e2a\uff09\uff0c\u5e76\u53d1\u73b06\u4e2a\u65b0\u6f0f\u6d1e\uff0c\u5176\u4e2d2\u4e2a\u4e3a0-day\u3002", "conclusion": "QLPro\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.23128", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23128", "abs": "https://arxiv.org/abs/2506.23128", "authors": ["Chi Chiu So", "Yueyue Sun", "Jun-Min Wang", "Siu Pang Yung", "Anthony Wai Keung Loh", "Chun Pong Chau"], "title": "Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons", "comment": "10 pages, 0 figures, accepted by 2025 IEEE international conference\n  on artificial intelligence testing (AITest)", "summary": "How far are Large Language Models (LLMs) in performing deep relational\nreasoning? In this paper, we evaluate and compare the reasoning capabilities of\nthree cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a\nsuite of carefully designed benchmark tasks in family tree and general graph\nreasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the\nhighest F1-scores across multiple tasks and problem sizes, demonstrating strong\naptitude in logical deduction and relational inference. However, all evaluated\nmodels, including DeepSeek-R1, struggle significantly as problem complexity\nincreases, largely due to token length limitations and incomplete output\nstructures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought\nresponses uncovers its unique planning and verification strategies, but also\nhighlights instances of incoherent or incomplete reasoning, calling attention\nto the need for deeper scrutiny into LLMs' internal inference dynamics. We\nfurther discuss key directions for future work, including the role of\nmultimodal reasoning and the systematic examination of reasoning failures. Our\nfindings provide both empirical insights and theoretical implications for\nadvancing LLMs' reasoning abilities, particularly in tasks that demand\nstructured, multi-step logical inference. Our code repository will be publicly\navailable at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08DeepSeek-R1\u3001DeepSeek-V3\u548cGPT-4o\uff09\u5728\u6df1\u5ea6\u5173\u7cfb\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0DeepSeek-R1\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u5747\u5b58\u5728\u5c40\u9650\u6027\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6df1\u5ea6\u5173\u7cfb\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u63a2\u7d22\u5176\u903b\u8f91\u63a8\u7406\u548c\u5173\u7cfb\u63a8\u65ad\u7684\u6f5c\u529b\u4e0e\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u5bb6\u65cf\u6811\u548c\u901a\u7528\u56fe\u63a8\u7406\u7684\u57fa\u51c6\u4efb\u52a1\uff0c\u8bc4\u4f30\u4e09\u79cd\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u5206\u6790\u5176\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "DeepSeek-R1\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u968f\u7740\u95ee\u9898\u590d\u6742\u6027\u589e\u52a0\uff0c\u6240\u6709\u6a21\u578b\u5747\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u8f93\u51fa\u7ed3\u6784\u548c\u4ee4\u724c\u957f\u5ea6\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5982\u591a\u6a21\u6001\u63a8\u7406\u548c\u7cfb\u7edf\u6027\u5206\u6790\u63a8\u7406\u5931\u8d25\u539f\u56e0\u3002"}}
{"id": "2506.23296", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23296", "abs": "https://arxiv.org/abs/2506.23296", "authors": ["Naoto Kiribuchi", "Kengo Zenitani", "Takayuki Semitsu"], "title": "Securing AI Systems: A Guide to Known Attacks and Impacts", "comment": "34 pages, 16 figures", "summary": "Embedded into information systems, artificial intelligence (AI) faces\nsecurity threats that exploit AI-specific vulnerabilities. This paper provides\nan accessible overview of adversarial attacks unique to predictive and\ngenerative AI systems. We identify eleven major attack types and explicitly\nlink attack techniques to their impacts -- including information leakage,\nsystem compromise, and resource exhaustion -- mapped to the confidentiality,\nintegrity, and availability (CIA) security triad. We aim to equip researchers,\ndevelopers, security practitioners, and policymakers, even those without\nspecialized AI security expertise, with foundational knowledge to recognize\nAI-specific risks and implement effective defenses, thereby enhancing the\noverall security posture of AI systems.", "AI": {"tldr": "\u672c\u6587\u6982\u8ff0\u4e86\u9488\u5bf9\u9884\u6d4b\u6027\u548c\u751f\u6210\u6027AI\u7cfb\u7edf\u7684\u72ec\u7279\u5bf9\u6297\u653b\u51fb\uff0c\u8bc6\u522b\u4e8611\u79cd\u4e3b\u8981\u653b\u51fb\u7c7b\u578b\uff0c\u5e76\u5c06\u5176\u6280\u672f\u4e0e\u5f71\u54cd\uff08\u5982\u4fe1\u606f\u6cc4\u9732\u3001\u7cfb\u7edf\u7834\u574f\u548c\u8d44\u6e90\u8017\u5c3d\uff09\u5173\u8054\u5230CIA\u5b89\u5168\u4e09\u8981\u7d20\u3002", "motivation": "AI\u7cfb\u7edf\u9762\u4e34\u7279\u5b9a\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u672c\u6587\u65e8\u5728\u4e3a\u975e\u4e13\u4e1aAI\u5b89\u5168\u7684\u7814\u7a76\u4eba\u5458\u3001\u5f00\u53d1\u8005\u3001\u5b89\u5168\u4ece\u4e1a\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u57fa\u7840\u77e5\u8bc6\uff0c\u4ee5\u8bc6\u522b\u98ce\u9669\u5e76\u5b9e\u65bd\u6709\u6548\u9632\u5fa1\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u548c\u6620\u5c04\u653b\u51fb\u7c7b\u578b\u53ca\u5176\u5f71\u54cd\uff0c\u63d0\u4f9b\u5bf9\u6297\u653b\u51fb\u7684\u5168\u9762\u6982\u8ff0\u3002", "result": "\u8bc6\u522b\u4e8611\u79cd\u4e3b\u8981\u653b\u51fb\u7c7b\u578b\uff0c\u5e76\u5c06\u5176\u6280\u672f\u4e0eCIA\u5b89\u5168\u4e09\u8981\u7d20\uff08\u673a\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u3001\u53ef\u7528\u6027\uff09\u5173\u8054\u3002", "conclusion": "\u672c\u6587\u4e3a\u63d0\u5347AI\u7cfb\u7edf\u7684\u6574\u4f53\u5b89\u5168\u6001\u52bf\u63d0\u4f9b\u4e86\u57fa\u7840\u77e5\u8bc6\uff0c\u5e2e\u52a9\u76f8\u5173\u65b9\u8bc6\u522b\u98ce\u9669\u5e76\u5b9e\u65bd\u9632\u5fa1\u3002"}}
{"id": "2506.23696", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2506.23696", "abs": "https://arxiv.org/abs/2506.23696", "authors": ["Francisco Oliveira", "Alexandra Mendes", "Carolina Carreira"], "title": "What Challenges Do Developers Face When Using Verification-Aware Programming Languages?", "comment": null, "summary": "Software reliability is critical in ensuring that the digital systems we\ndepend on function correctly. In software development, increasing software\nreliability often involves testing. However, for complex and critical systems,\ndevelopers can use Design by Contract (DbC) methods to define precise\nspecifications that software components must satisfy. Verification-Aware (VA)\nprogramming languages support DbC and formal verification at compile-time or\nrun-time, offering stronger correctness guarantees than traditional testing.\nHowever, despite the strong guarantees provided by VA languages, their adoption\nremains limited. In this study, we investigate the barriers to adopting VA\nlanguages by analyzing developer discussions on public forums using topic\nmodeling techniques. We complement this analysis with a developer survey to\nbetter understand the practical challenges associated with VA languages. Our\nfindings reveal key obstacles to adoption, including steep learning curves and\nusability issues. Based on these insights, we identify actionable\nrecommendations to improve the usability and accessibility of VA languages. Our\nfindings suggest that simplifying tool interfaces, providing better educational\nmaterials, and improving integration with everyday development environments\ncould improve the usability and adoption of these languages. Our work provides\nactionable insights for improving the usability of VA languages and making\nverification tools more accessible.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u9a8c\u8bc1\u611f\u77e5\uff08VA\uff09\u7f16\u7a0b\u8bed\u8a00\u91c7\u7528\u7387\u4f4e\u7684\u539f\u56e0\uff0c\u901a\u8fc7\u5206\u6790\u5f00\u53d1\u8005\u8ba8\u8bba\u548c\u8c03\u67e5\uff0c\u53d1\u73b0\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u548c\u53ef\u7528\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u5c3d\u7ba1\u9a8c\u8bc1\u611f\u77e5\uff08VA\uff09\u8bed\u8a00\u80fd\u63d0\u4f9b\u66f4\u5f3a\u7684\u6b63\u786e\u6027\u4fdd\u8bc1\uff0c\u4f46\u5176\u91c7\u7528\u7387\u4ecd\u7136\u6709\u9650\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u963b\u788d\u5176\u91c7\u7528\u7684\u5177\u4f53\u969c\u788d\u3002", "method": "\u901a\u8fc7\u4e3b\u9898\u5efa\u6a21\u5206\u6790\u5f00\u53d1\u8005\u8bba\u575b\u8ba8\u8bba\uff0c\u5e76\u7ed3\u5408\u5f00\u53d1\u8005\u8c03\u67e5\uff0c\u4e86\u89e3VA\u8bed\u8a00\u7684\u5b9e\u9645\u6311\u6218\u3002", "result": "\u53d1\u73b0\u4e3b\u8981\u969c\u788d\u5305\u62ec\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u548c\u53ef\u7528\u6027\u95ee\u9898\uff0c\u5efa\u8bae\u7b80\u5316\u5de5\u5177\u754c\u9762\u3001\u63d0\u4f9b\u66f4\u597d\u7684\u6559\u80b2\u6750\u6599\u548c\u6539\u8fdb\u5f00\u53d1\u73af\u5883\u96c6\u6210\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u5347VA\u8bed\u8a00\u53ef\u7528\u6027\u548c\u91c7\u7528\u7387\u63d0\u4f9b\u4e86\u5177\u4f53\u5efa\u8bae\uff0c\u5305\u62ec\u6539\u8fdb\u5de5\u5177\u548c\u6559\u80b2\u8d44\u6e90\u3002"}}
{"id": "2506.23141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23141", "abs": "https://arxiv.org/abs/2506.23141", "authors": ["Siyuan Li", "Ruitong Liu", "Yan Wen", "Te Sun"], "title": "Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing", "comment": null, "summary": "Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge\nGraph Completion (KGC), providing vital cues for prediction. However,\ntraditional node-based message passing mechanisms, when applied to knowledge\ngraphs, often introduce noise and suffer from information dilution or\nover-smoothing by indiscriminately aggregating information from all neighboring\nedges. To address this challenge, we propose a semantic-aware relational\nmessage passing. A core innovation of this framework is the introduction of a\n\\textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this\nstrategy first evaluates the semantic relevance between a central node and its\nincident edges within a shared latent space, selecting only the Top-K most\npertinent ones. Subsequently, information from these selected edges is\neffectively fused with the central node's own representation using a\n\\textbf{multi-head attention aggregator} to generate a semantically focused\nnode message. In this manner, our model not only leverages the structure and\nfeatures of edges within the knowledge graph but also more accurately captures\nand propagates the contextual information most relevant to the specific link\nprediction task, thereby effectively mitigating interference from irrelevant\ninformation. Extensive experiments demonstrate that our method achieves\nsuperior performance compared to existing approaches on several established\nbenchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u611f\u77e5\u7684\u5173\u7cfb\u6d88\u606f\u4f20\u9012\u6846\u67b6\uff0c\u901a\u8fc7Top-K\u90bb\u5c45\u9009\u62e9\u7b56\u7565\u548c\u591a\u5934\u6ce8\u610f\u529b\u805a\u5408\u5668\uff0c\u6709\u6548\u51cf\u5c11\u566a\u58f0\u5e76\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u8282\u70b9\u7684\u6d88\u606f\u4f20\u9012\u673a\u5236\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5bb9\u6613\u5f15\u5165\u566a\u58f0\u548c\u4fe1\u606f\u7a00\u91ca\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u51c6\u7684\u8bed\u4e49\u611f\u77e5\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u8bed\u4e49\u611f\u77e5\u7684Top-K\u90bb\u5c45\u9009\u62e9\u7b56\u7565\uff0c\u7ed3\u5408\u591a\u5934\u6ce8\u610f\u529b\u805a\u5408\u5668\uff0c\u9009\u62e9\u5e76\u878d\u5408\u6700\u76f8\u5173\u7684\u8bed\u4e49\u4fe1\u606f\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u7684\u6d88\u606f\u4f20\u9012\uff0c\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.23314", "categories": ["cs.CR", "cs.AI", "68T99", "I.2"], "pdf": "https://arxiv.org/pdf/2506.23314", "abs": "https://arxiv.org/abs/2506.23314", "authors": ["Joner Assolin", "Gabriel Canto", "Diego Kreutz", "Eduardo Feitosa", "Hendrio Bragan\u00e7a", "Angelo Nogueira", "Vanderson Rocha"], "title": "Interpretable by Design: MH-AutoML for Transparent and Efficient Android Malware Detection without Compromising Performance", "comment": "18 pages, 10 figures, 7 tabelas, paper submitted to JBCS", "summary": "Malware detection in Android systems requires both cybersecurity expertise\nand machine learning (ML) techniques. Automated Machine Learning (AutoML) has\nemerged as an approach to simplify ML development by reducing the need for\nspecialized knowledge. However, current AutoML solutions typically operate as\nblack-box systems with limited transparency, interpretability, and experiment\ntraceability. To address these limitations, we present MH-AutoML, a\ndomain-specific framework for Android malware detection. MH-AutoML automates\nthe entire ML pipeline, including data preprocessing, feature engineering,\nalgorithm selection, and hyperparameter tuning. The framework incorporates\ncapabilities for interpretability, debugging, and experiment tracking that are\noften missing in general-purpose solutions. In this study, we compare MH-AutoML\nagainst seven established AutoML frameworks: Auto-Sklearn, AutoGluon, TPOT,\nHyperGBM, Auto-PyTorch, LightAutoML, and MLJAR. Results show that MH-AutoML\nachieves better recall rates while providing more transparency and control. The\nframework maintains computational efficiency comparable to other solutions,\nmaking it suitable for cybersecurity applications where both performance and\nexplainability matter.", "AI": {"tldr": "MH-AutoML\u662f\u4e00\u4e2a\u9488\u5bf9Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7684\u9886\u57df\u4e13\u7528AutoML\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316ML\u6d41\u7a0b\u5e76\u63d0\u4f9b\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f18\u4e8e\u73b0\u6709AutoML\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524dAutoML\u89e3\u51b3\u65b9\u6848\u5728\u900f\u660e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u9a8c\u53ef\u8ffd\u6eaf\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "MH-AutoML\u81ea\u52a8\u5316\u6574\u4e2aML\u6d41\u7a0b\uff0c\u5305\u62ec\u6570\u636e\u9884\u5904\u7406\u3001\u7279\u5f81\u5de5\u7a0b\u3001\u7b97\u6cd5\u9009\u62e9\u548c\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u5e76\u652f\u6301\u53ef\u89e3\u91ca\u6027\u3001\u8c03\u8bd5\u548c\u5b9e\u9a8c\u8ddf\u8e2a\u3002", "result": "\u4e0e\u4e03\u79cd\u73b0\u6709AutoML\u6846\u67b6\u76f8\u6bd4\uff0cMH-AutoML\u5728\u53ec\u56de\u7387\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u9ad8\u7684\u900f\u660e\u6027\u548c\u63a7\u5236\u80fd\u529b\uff0c\u8ba1\u7b97\u6548\u7387\u76f8\u5f53\u3002", "conclusion": "MH-AutoML\u5728\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\uff0c\u9002\u5408\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u3002"}}
{"id": "2506.23715", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23715", "abs": "https://arxiv.org/abs/2506.23715", "authors": ["Benoit Combemale"], "title": "Towards a Science of Developer eXperience (DevX)", "comment": null, "summary": "As software continues to permeate nearly every facet of modern life, the\ncomplexity and ubiquity of digital services underscore the need for\nsustainable, effective, and inclusive software development practices. Although\nsoftware engineering has made significant progress in technical challenges\nsince its inception, the human experience of those involved in software\ncreation, broadly defined as developers, remains underexplored. This column\nadvocates for the formal recognition of Developer eXperience (DevX) as a\ndistinct research field. We argue that DevX profoundly influences critical\ndevelopment activities and overall productivity, especially as development\nbecomes increasingly collaborative and diverse in terms of application domains.\nBuilding on existing efforts to measure and enhance DevX, we identify key\nrationales, scientific enablers, and interdisciplinary intersections that\nsupport this emerging discipline. We also outline the core scientific\nchallenges ahead, aiming to call for actions from the research community and to\npromote more human-centered approaches to software engineering.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u5c06\u5f00\u53d1\u8005\u4f53\u9a8c\uff08DevX\uff09\u4f5c\u4e3a\u72ec\u7acb\u7814\u7a76\u9886\u57df\uff0c\u5f3a\u8c03\u5176\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u6d3b\u52a8\u548c\u751f\u4ea7\u529b\u7684\u91cd\u8981\u6027\uff0c\u5e76\u547c\u5401\u7814\u7a76\u793e\u533a\u91c7\u53d6\u884c\u52a8\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5728\u73b0\u4ee3\u751f\u6d3b\u4e2d\u7684\u666e\u53ca\uff0c\u5f00\u53d1\u8005\u7684\u4f53\u9a8c\uff08DevX\uff09\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u9700\u8981\u66f4\u591a\u5173\u6ce8\u3002", "method": "\u57fa\u4e8e\u73b0\u6709\u7814\u7a76\uff0c\u8bc6\u522bDevX\u7684\u5173\u952e\u7406\u8bba\u57fa\u7840\u3001\u79d1\u5b66\u63a8\u52a8\u56e0\u7d20\u548c\u8de8\u5b66\u79d1\u4ea4\u53c9\u70b9\uff0c\u5e76\u6982\u8ff0\u672a\u6765\u79d1\u5b66\u6311\u6218\u3002", "result": "\u63d0\u51faDevX\u4f5c\u4e3a\u72ec\u7acb\u7814\u7a76\u9886\u57df\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u547c\u5401\u7814\u7a76\u793e\u533a\u91c7\u53d6\u884c\u52a8\uff0c\u63a8\u52a8\u66f4\u4ee5\u4eba\u4e3a\u672c\u7684\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u6cd5\u3002", "conclusion": "DevX\u5e94\u6210\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u7684\u91cd\u8981\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u63d0\u5347\u5f00\u53d1\u6548\u7387\u548c\u534f\u4f5c\u591a\u6837\u6027\u3002"}}
{"id": "2506.23168", "categories": ["cs.AI", "cs.DM", "math.CO", "math.RA", "06B99", "G.2.1"], "pdf": "https://arxiv.org/pdf/2506.23168", "abs": "https://arxiv.org/abs/2506.23168", "authors": ["Mohammad Abdulla", "Tobias Hille", "Dominik D\u00fcrrschnabel", "Gerd Stumme"], "title": "Rises for Measuring Local Distributivity in Lattices", "comment": "16 pages, 2 tables, 5 figures, International Joint Conference on\n  Conceptual Knowledge Structures", "summary": "Distributivity is a well-established and extensively studied notion in\nlattice theory. In the context of data analysis, particularly within Formal\nConcept Analysis (FCA), lattices are often observed to exhibit a high degree of\ndistributivity. However, no standardized measure exists to quantify this\nproperty. In this paper, we introduce the notion of rises in (concept) lattices\nas a means to assess distributivity. Rises capture how the number of attributes\nor objects in covering concepts change within the concept lattice. We show that\na lattice is distributive if and only if no non-unit rises occur. Furthermore,\nwe relate rises to the classical notion of meet- and join distributivity. We\nobserve that concept lattices from real-world data are to a high degree\njoin-distributive, but much less meet-distributive. We additionally study how\njoin-distributivity manifests on the level of ordered sets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u201crises\u201d\u6765\u91cf\u5316\u6982\u5ff5\u683c\u4e2d\u5206\u914d\u6027\u7684\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u683c\u662f\u5206\u914d\u7684\u5f53\u4e14\u4ec5\u5f53\u4e0d\u5b58\u5728\u975e\u5355\u4f4drises\u3002", "motivation": "\u5728\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\u4e2d\uff0c\u683c\u901a\u5e38\u8868\u73b0\u51fa\u9ad8\u5ea6\u7684\u5206\u914d\u6027\uff0c\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u91cf\u5316\u65b9\u6cd5\u3002", "method": "\u5f15\u5165rises\u4f5c\u4e3a\u8bc4\u4f30\u5206\u914d\u6027\u7684\u5de5\u5177\uff0c\u7814\u7a76\u5176\u5728\u6982\u5ff5\u683c\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4e0e\u7ecf\u5178\u7684meet-\u548cjoin\u5206\u914d\u6027\u5173\u8054\u3002", "result": "\u73b0\u5b9e\u6570\u636e\u4e2d\u7684\u6982\u5ff5\u683c\u9ad8\u5ea6join-\u5206\u914d\uff0c\u4f46meet-\u5206\u914d\u6027\u8f83\u4f4e\u3002", "conclusion": "rises\u662f\u91cf\u5316\u5206\u914d\u6027\u7684\u6709\u6548\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u6982\u5ff5\u683c\u4e2d\u5206\u914d\u6027\u7684\u4e0d\u5bf9\u79f0\u6027\u3002"}}
{"id": "2506.23435", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2506.23435", "abs": "https://arxiv.org/abs/2506.23435", "authors": ["Hayder Tirmazi"], "title": "All Proof of Work But No Proof of Play", "comment": "Published in CFAIL 2025", "summary": "Speedrunning is a competition that emerged from communities of early video\ngames such as Doom (1993). Speedrunners try to finish a game in minimal time.\nProvably verifying the authenticity of submitted speedruns is an open problem.\nTraditionally, best-effort speedrun verification is conducted by on-site human\nobservers, forensic audio analysis, or a rigorous mathematical analysis of the\ngame mechanics. Such methods are tedious, fallible, and, perhaps worst of all,\nnot cryptographic. Motivated by naivety and the Dunning-Kruger effect, we\nattempt to build a system that cryptographically proves the authenticity of\nspeedruns. This paper describes our attempted solutions and ways to circumvent\nthem. Through a narration of our failures, we attempt to demonstrate the\ndifficulty of authenticating live and interactive human input in untrusted\nenvironments, as well as the limits of signature schemes, game integrity, and\nprovable play.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u5bc6\u7801\u5b66\u65b9\u6cd5\u9a8c\u8bc1\u6e38\u620f\u901f\u901a\u7684\u771f\u5b9e\u6027\uff0c\u4f46\u6700\u7ec8\u5c55\u793a\u4e86\u5176\u56f0\u96be\u6027\u3002", "motivation": "\u901f\u901a\u9a8c\u8bc1\u7684\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u4eba\u5de5\u89c2\u5bdf\u6216\u97f3\u9891\u5206\u6790\uff09\u4e0d\u53ef\u9760\u4e14\u975e\u5bc6\u7801\u5b66\uff0c\u4f5c\u8005\u8bd5\u56fe\u6784\u5efa\u5bc6\u7801\u5b66\u9a8c\u8bc1\u7cfb\u7edf\u3002", "method": "\u5c1d\u8bd5\u6784\u5efa\u5bc6\u7801\u5b66\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u5931\u8d25\u6848\u4f8b\u5c55\u793a\u5176\u5c40\u9650\u6027\u3002", "result": "\u5c55\u793a\u4e86\u9a8c\u8bc1\u76f4\u64ad\u548c\u4ea4\u4e92\u5f0f\u8f93\u5165\u7684\u56f0\u96be\u6027\uff0c\u4ee5\u53ca\u7b7e\u540d\u65b9\u6848\u548c\u6e38\u620f\u5b8c\u6574\u6027\u7684\u9650\u5236\u3002", "conclusion": "\u9a8c\u8bc1\u901f\u901a\u7684\u5bc6\u7801\u5b66\u65b9\u6cd5\u5728\u5f53\u524d\u6280\u672f\u4e0b\u6781\u5177\u6311\u6218\u6027\u3002"}}
{"id": "2506.23749", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23749", "abs": "https://arxiv.org/abs/2506.23749", "authors": ["Boyang Yang", "Zijian Cai", "Fengling Liu", "Bach Le", "Lingming Zhang", "Tegawend\u00e9 F. Bissyand\u00e9", "Yang Liu", "Haoye Tian"], "title": "A Survey of LLM-based Automated Program Repair: Taxonomies, Design Paradigms, and Applications", "comment": null, "summary": "Large language models (LLMs) are reshaping automated program repair (APR). We\ncategorize the recent 63 LLM-based APR systems published from January 2022 to\nJune 2025 into four paradigms, and show how retrieval- or analysis-augmented\ncontexts strengthen any of them. This taxonomy clarifies key trade-offs:\nfine-tuning delivers strong task alignment at high training cost; prompting\nenables rapid deployment but is limited by prompt design and context windows;\nprocedural pipelines offer reproducible control with moderate overhead; agentic\nframeworks tackle multi-hunk or cross-file bugs at the price of increased\nlatency and complexity. Persistent challenges include verifying semantic\ncorrectness beyond test suites, repairing repository-scale defects, and\nlowering the costs of LLMs. We outline research directions that combine\nlightweight human feedback, repository-aware retrieval, code analysis, and\ncost-aware planning to advance reliable and efficient LLM-based APR.", "AI": {"tldr": "\u8bba\u6587\u603b\u7ed3\u4e862022\u5e74\u81f32025\u5e74\u95f463\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u7cfb\u7edf\uff0c\u5c06\u5176\u5206\u4e3a\u56db\u79cd\u8303\u5f0f\uff0c\u5e76\u5206\u6790\u4e86\u6bcf\u79cd\u8303\u5f0f\u7684\u4f18\u7f3a\u70b9\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u5229\u7528\u68c0\u7d22\u6216\u5206\u6790\u589e\u5f3a\u7684\u4e0a\u4e0b\u6587\u4f18\u5316LLM\u5728APR\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u548c\u6bd4\u8f83\u56db\u79cdLLM-based APR\u8303\u5f0f\uff08\u5fae\u8c03\u3001\u63d0\u793a\u3001\u6d41\u7a0b\u7ba1\u9053\u548c\u4ee3\u7406\u6846\u67b6\uff09\uff0c\u5206\u6790\u5176\u6027\u80fd\u4e0e\u6210\u672c\u3002", "result": "\u63ed\u793a\u4e86\u4e0d\u540c\u8303\u5f0f\u7684\u5173\u952e\u6743\u8861\uff1a\u5fae\u8c03\u4efb\u52a1\u5bf9\u9f50\u5f3a\u4f46\u6210\u672c\u9ad8\uff1b\u63d0\u793a\u90e8\u7f72\u5feb\u4f46\u53d7\u9650\u4e8e\u8bbe\u8ba1\uff1b\u6d41\u7a0b\u7ba1\u9053\u53ef\u63a7\u4f46\u5f00\u9500\u4e2d\u7b49\uff1b\u4ee3\u7406\u6846\u67b6\u80fd\u5904\u7406\u590d\u6742\u95ee\u9898\u4f46\u5ef6\u8fdf\u9ad8\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u5e94\u7ed3\u5408\u8f7b\u91cf\u7ea7\u4eba\u7c7b\u53cd\u9988\u3001\u4ed3\u5e93\u611f\u77e5\u68c0\u7d22\u3001\u4ee3\u7801\u5206\u6790\u548c\u6210\u672c\u89c4\u5212\uff0c\u4ee5\u63d0\u5347LLM-based APR\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2506.23273", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23273", "abs": "https://arxiv.org/abs/2506.23273", "authors": ["Quang Hung Nguyen", "Phuong Anh Trinh", "Phan Quoc Hung Mai", "Tuan Phong Trinh"], "title": "FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis", "comment": null, "summary": "Despite the advancements of large language models, text2sql still faces many\nchallenges, particularly with complex and domain-specific queries. In finance,\ndatabase designs and financial reporting layouts vary widely between financial\nentities and countries, making text2sql even more challenging. We present\nFinStat2SQL, a lightweight text2sql pipeline enabling natural language queries\nover financial statements. Tailored to local standards like VAS, it combines\nlarge and small language models in a multi-agent setup for entity extraction,\nSQL generation, and self-correction. We build a domain-specific database and\nevaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves\n61.33\\% accuracy with sub-4-second response times on consumer hardware,\noutperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient\nsolution for financial analysis, making AI-powered querying accessible to\nVietnamese enterprises.", "AI": {"tldr": "FinStat2SQL\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6587\u672c\u5230SQL\u7684\u7ba1\u9053\uff0c\u4e13\u4e3a\u91d1\u878d\u9886\u57df\u8bbe\u8ba1\uff0c\u7ed3\u5408\u5927\u5c0f\u8bed\u8a00\u6a21\u578b\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\uff0c\u5e76\u5728\u8d8a\u5357\u4f01\u4e1a\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u91d1\u878d\u9886\u57df\u7684\u6570\u636e\u5e93\u8bbe\u8ba1\u548c\u62a5\u8868\u5e03\u5c40\u5dee\u5f02\u5927\uff0c\u73b0\u6709\u6587\u672c\u5230SQL\u6280\u672f\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u548c\u7279\u5b9a\u9886\u57df\u7684\u67e5\u8be2\u9700\u6c42\u3002", "method": "\u91c7\u7528\u591a\u4ee3\u7406\u8bbe\u7f6e\uff0c\u7ed3\u5408\u5927\u5c0f\u8bed\u8a00\u6a21\u578b\uff0c\u8fdb\u884c\u5b9e\u4f53\u63d0\u53d6\u3001SQL\u751f\u6210\u548c\u81ea\u6211\u6821\u6b63\uff0c\u5e76\u6784\u5efa\u7279\u5b9a\u9886\u57df\u6570\u636e\u5e93\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "7B\u5fae\u8c03\u6a21\u578b\u5728\u6d88\u8d39\u786c\u4ef6\u4e0a\u8fbe\u523061.33%\u51c6\u786e\u7387\uff0c\u54cd\u5e94\u65f6\u95f4\u4f4e\u4e8e4\u79d2\uff0c\u4f18\u4e8eGPT-4o-mini\u3002", "conclusion": "FinStat2SQL\u4e3a\u8d8a\u5357\u4f01\u4e1a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u7ecf\u6d4e\u9ad8\u6548\u7684\u91d1\u878d\u5206\u6790\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.23474", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23474", "abs": "https://arxiv.org/abs/2506.23474", "authors": ["Zhiwei Lin", "Bonan Ruan", "Jiahao Liu", "Weibo Zhao"], "title": "A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis", "comment": null, "summary": "The Model Context Protocol (MCP) has recently emerged as a standardized\ninterface for connecting language models with external tools and data. As the\necosystem rapidly expands, the lack of a structured, comprehensive view of\nexisting MCP artifacts presents challenges for research. To bridge this gap, we\nintroduce MCPCorpus, a large-scale dataset containing around 14K MCP servers\nand 300 MCP clients. Each artifact is annotated with 20+ normalized attributes\ncapturing its identity, interface configuration, GitHub activity, and metadata.\nMCPCorpus provides a reproducible snapshot of the real-world MCP ecosystem,\nenabling studies of adoption trends, ecosystem health, and implementation\ndiversity. To keep pace with the rapid evolution of the MCP ecosystem, we\nprovide utility tools for automated data synchronization, normalization, and\ninspection. Furthermore, to support efficient exploration and exploitation, we\nrelease a lightweight web-based search interface. MCPCorpus is publicly\navailable at: https://github.com/Snakinya/MCPCorpus.", "AI": {"tldr": "MCPCorpus\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5305\u542b\u7ea614K\u4e2aMCP\u670d\u52a1\u5668\u548c300\u4e2aMCP\u5ba2\u6237\u7aef\uff0c\u6bcf\u4e2a\u6807\u6ce8\u4e8620\u591a\u4e2a\u6807\u51c6\u5316\u5c5e\u6027\uff0c\u7528\u4e8e\u7814\u7a76MCP\u751f\u6001\u7cfb\u7edf\u7684\u8d8b\u52bf\u548c\u591a\u6837\u6027\u3002", "motivation": "\u7531\u4e8eMCP\u751f\u6001\u7cfb\u7edf\u7684\u5feb\u901f\u6269\u5c55\uff0c\u7f3a\u4e4f\u5bf9\u73b0\u6709MCP\u5de5\u4ef6\u7684\u7ed3\u6784\u5316\u5168\u9762\u89c6\u56fe\uff0c\u963b\u788d\u4e86\u7814\u7a76\u8fdb\u5c55\u3002", "method": "\u5f15\u5165MCPCorpus\u6570\u636e\u96c6\uff0c\u5305\u542b\u5927\u91cf\u6807\u6ce8\u7684MCP\u670d\u52a1\u5668\u548c\u5ba2\u6237\u7aef\uff0c\u5e76\u63d0\u4f9b\u81ea\u52a8\u5316\u5de5\u5177\u548c\u641c\u7d22\u754c\u9762\u3002", "result": "MCPCorpus\u4e3aMCP\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u7684\u5feb\u7167\uff0c\u652f\u6301\u5bf9\u91c7\u7528\u8d8b\u52bf\u3001\u751f\u6001\u7cfb\u7edf\u5065\u5eb7\u548c\u5b9e\u73b0\u591a\u6837\u6027\u7684\u7814\u7a76\u3002", "conclusion": "MCPCorpus\u586b\u8865\u4e86MCP\u751f\u6001\u7cfb\u7edf\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u548c\u516c\u5f00\u8bbf\u95ee\u7684\u6570\u636e\u96c6\u3002"}}
{"id": "2506.23762", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23762", "abs": "https://arxiv.org/abs/2506.23762", "authors": ["Hongzhou Rao", "Yanjie Zhao", "Xinyi Hou", "Shenao Wang", "Haoyu Wang"], "title": "Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has redefined\nartificial intelligence (AI), pushing the boundaries of AI research and\nenabling unbounded possibilities for both academia and the industry. However,\nLLM development faces increasingly complex challenges throughout its lifecycle,\nyet no existing research systematically explores these challenges and solutions\nfrom the perspective of software engineering (SE) approaches. To fill the gap,\nwe systematically analyze research status throughout the LLM development\nlifecycle, divided into six phases: requirements engineering, dataset\nconstruction, model development and enhancement, testing and evaluation,\ndeployment and operations, and maintenance and evolution. We then conclude by\nidentifying the key challenges for each phase and presenting potential research\ndirections to address these challenges. In general, we provide valuable\ninsights from an SE perspective to facilitate future advances in LLM\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89d2\u5ea6\u7cfb\u7edf\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5f00\u53d1\u5168\u751f\u547d\u5468\u671f\u7684\u6311\u6218\u4e0e\u89e3\u51b3\u65b9\u6848\uff0c\u5206\u4e3a\u516d\u4e2a\u9636\u6bb5\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u672a\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89d2\u5ea6\u7cfb\u7edf\u63a2\u8ba8LLM\u5f00\u53d1\u4e2d\u7684\u590d\u6742\u6311\u6218\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5c06LLM\u5f00\u53d1\u5206\u4e3a\u516d\u4e2a\u9636\u6bb5\uff08\u9700\u6c42\u5de5\u7a0b\u3001\u6570\u636e\u96c6\u6784\u5efa\u3001\u6a21\u578b\u5f00\u53d1\u4e0e\u589e\u5f3a\u3001\u6d4b\u8bd5\u4e0e\u8bc4\u4f30\u3001\u90e8\u7f72\u4e0e\u8fd0\u7ef4\u3001\u7ef4\u62a4\u4e0e\u6f14\u8fdb\uff09\uff0c\u5206\u6790\u5404\u9636\u6bb5\u6311\u6218\u3002", "result": "\u603b\u7ed3\u4e86\u5404\u9636\u6bb5\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u6f5c\u5728\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u4e3aLLM\u5f00\u53d1\u7684\u672a\u6765\u8fdb\u5c55\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.23276", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.23276", "abs": "https://arxiv.org/abs/2506.23276", "authors": ["David Guzman Piedrahita", "Yongjin Yang", "Mrinmaya Sachan", "Giorgia Ramponi", "Bernhard Sch\u00f6lkopf", "Zhijing Jin"], "title": "Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed as autonomous\nagents, understanding their cooperation and social mechanisms is becoming\nincreasingly important. In particular, how LLMs balance self-interest and\ncollective well-being is a critical challenge for ensuring alignment,\nrobustness, and safe deployment. In this paper, we examine the challenge of\ncostly sanctioning in multi-agent LLM systems, where an agent must decide\nwhether to invest its own resources to incentivize cooperation or penalize\ndefection. To study this, we adapt a public goods game with institutional\nchoice from behavioral economics, allowing us to observe how different LLMs\nnavigate social dilemmas over repeated interactions. Our analysis reveals four\ndistinct behavioral patterns among models: some consistently establish and\nsustain high levels of cooperation, others fluctuate between engagement and\ndisengagement, some gradually decline in cooperative behavior over time, and\nothers rigidly follow fixed strategies regardless of outcomes. Surprisingly, we\nfind that reasoning LLMs, such as the o1 series, struggle significantly with\ncooperation, whereas some traditional LLMs consistently achieve high levels of\ncooperation. These findings suggest that the current approach to improving\nLLMs, which focuses on enhancing their reasoning capabilities, does not\nnecessarily lead to cooperation, providing valuable insights for deploying LLM\nagents in environments that require sustained collaboration. Our code is\navailable at https://github.com/davidguzmanp/SanctSim", "AI": {"tldr": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5408\u4f5c\u884c\u4e3a\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u5728\u516c\u5171\u7269\u54c1\u535a\u5f08\u4e2d\u8868\u73b0\u51fa\u56db\u79cd\u884c\u4e3a\u6a21\u5f0f\uff0c\u63a8\u7406\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u53cd\u800c\u5408\u4f5c\u8868\u73b0\u8f83\u5dee\u3002", "motivation": "\u7406\u89e3LLMs\u5728\u81ea\u4e3b\u4ee3\u7406\u4e2d\u7684\u5408\u4f5c\u673a\u5236\uff0c\u5c24\u5176\u662f\u5982\u4f55\u5e73\u8861\u81ea\u5229\u4e0e\u96c6\u4f53\u5229\u76ca\uff0c\u4ee5\u786e\u4fdd\u5176\u5bf9\u9f50\u6027\u3001\u9c81\u68d2\u6027\u548c\u5b89\u5168\u90e8\u7f72\u3002", "method": "\u901a\u8fc7\u884c\u4e3a\u7ecf\u6d4e\u5b66\u7684\u516c\u5171\u7269\u54c1\u535a\u5f08\u5b9e\u9a8c\uff0c\u89c2\u5bdf\u4e0d\u540cLLMs\u5728\u91cd\u590d\u4e92\u52a8\u4e2d\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u56db\u79cd\u884c\u4e3a\u6a21\u5f0f\uff1a\u6301\u7eed\u9ad8\u5408\u4f5c\u3001\u6ce2\u52a8\u5408\u4f5c\u3001\u9010\u6e10\u8870\u9000\u5408\u4f5c\u548c\u56fa\u5b9a\u7b56\u7565\u3002\u63a8\u7406\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u5408\u4f5c\u8868\u73b0\u8f83\u5dee\u3002", "conclusion": "\u5f53\u524d\u63d0\u5347LLMs\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\u672a\u5fc5\u80fd\u4fc3\u8fdb\u5408\u4f5c\uff0c\u4e3a\u9700\u8981\u6301\u7eed\u534f\u4f5c\u7684\u73af\u5883\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2506.23583", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23583", "abs": "https://arxiv.org/abs/2506.23583", "authors": ["Marvin Xhemrishi", "Alexandre Graell i Amat", "Bal\u00e1zs Pej\u00f3"], "title": "Detect \\& Score: Privacy-Preserving Misbehaviour Detection and Contribution Evaluation in Federated Learning", "comment": "The shorter version is accepted at FL-AsiaCCS 25", "summary": "Federated learning with secure aggregation enables private and collaborative\nlearning from decentralised data without leaking sensitive client information.\nHowever, secure aggregation also complicates the detection of malicious client\nbehaviour and the evaluation of individual client contributions to the\nlearning. To address these challenges, QI (Pejo et al.) and FedGT (Xhemrishi et\nal.) were proposed for contribution evaluation (CE) and misbehaviour detection\n(MD), respectively. QI, however, lacks adequate MD accuracy due to its reliance\non the random selection of clients in each training round, while FedGT lacks\nthe CE ability. In this work, we combine the strengths of QI and FedGT to\nachieve both robust MD and accurate CE. Our experiments demonstrate superior\nperformance compared to using either method independently.", "AI": {"tldr": "\u7ed3\u5408QI\u548cFedGT\u7684\u4f18\u52bf\uff0c\u5b9e\u73b0\u6076\u610f\u884c\u4e3a\u68c0\u6d4b\u548c\u8d21\u732e\u8bc4\u4f30\u7684\u53cc\u91cd\u76ee\u6807\u3002", "motivation": "\u5b89\u5168\u805a\u5408\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u4fdd\u62a4\u4e86\u5ba2\u6237\u9690\u79c1\uff0c\u4f46\u4e5f\u589e\u52a0\u4e86\u6076\u610f\u884c\u4e3a\u68c0\u6d4b\u548c\u8d21\u732e\u8bc4\u4f30\u7684\u96be\u5ea6\u3002\u73b0\u6709\u65b9\u6cd5\uff08QI\u548cFedGT\uff09\u5404\u6709\u4e0d\u8db3\uff0c\u9700\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u3002", "method": "\u7ed3\u5408QI\u548cFedGT\u7684\u65b9\u6cd5\uff0c\u4ee5\u540c\u65f6\u5b9e\u73b0\u6076\u610f\u884c\u4e3a\u68c0\u6d4b\u548c\u8d21\u732e\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528QI\u6216FedGT\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408QI\u548cFedGT\uff0c\u80fd\u591f\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u7684\u6076\u610f\u884c\u4e3a\u68c0\u6d4b\u548c\u51c6\u786e\u7684\u8d21\u732e\u8bc4\u4f30\u3002"}}
{"id": "2506.23898", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23898", "abs": "https://arxiv.org/abs/2506.23898", "authors": ["Diogo Lemos", "Ademar Aguiar", "Neil B. Harrison"], "title": "Requirements for Active Assistance of Natural Questions in Software Architecture", "comment": null, "summary": "Natural questions are crucial to shaping key architectural decisions and\npreserving architectural knowledge. They arise organically during the\narchitectural design process, often resulting from the existing architectural\nexperience of the designer and the distinctive characteristics of the system\nbeing designed. However, natural questions are often mismanaged or ignored,\nwhich can lead to architectural drift, knowledge loss, inefficient resource\nuse, or poor understandability of the system's architecture. We aim to better\nunderstand the lifecycle of natural questions, its key requirements, challenges\nand difficulties, and then to envision an assisted environment to properly\nsupport it. The environment should be adaptable and responsive to real-world\nconstraints and uncertainties by seamlessly integrating knowledge management\ntools and artificial intelligence techniques into software development\nworkflows. Based on existing literature, a requirements workshop, and three\ndesign iterations, we proposed a lifecycle for natural questions and elicited\nessential functional and non-functional requirements for such an environment.\nAt last, the results of a survey conducted with experts helped to analyze and\nvalidate the elicited requirements and proposed features for the environment to\nenhance collaboration, decision-making, and the preservation of architectural\nknowledge more effectively than conventional methods.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u81ea\u7136\u95ee\u9898\u5728\u67b6\u6784\u8bbe\u8ba1\u4e2d\u7684\u91cd\u8981\u6027\u53ca\u5176\u7ba1\u7406\u4e0d\u5584\u7684\u540e\u679c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301\u81ea\u7136\u95ee\u9898\u751f\u547d\u5468\u671f\u7684\u8f85\u52a9\u73af\u5883\uff0c\u5e76\u901a\u8fc7\u8c03\u7814\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u81ea\u7136\u95ee\u9898\u5728\u67b6\u6784\u8bbe\u8ba1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5e38\u88ab\u5ffd\u89c6\u6216\u7ba1\u7406\u4e0d\u5584\uff0c\u5bfc\u81f4\u67b6\u6784\u6f02\u79fb\u3001\u77e5\u8bc6\u4e22\u5931\u7b49\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u7406\u89e3\u5176\u751f\u547d\u5468\u671f\u5e76\u8bbe\u8ba1\u652f\u6301\u73af\u5883\u3002", "method": "\u57fa\u4e8e\u6587\u732e\u3001\u9700\u6c42\u7814\u8ba8\u4f1a\u548c\u4e09\u6b21\u8bbe\u8ba1\u8fed\u4ee3\uff0c\u63d0\u51fa\u4e86\u81ea\u7136\u95ee\u9898\u7684\u751f\u547d\u5468\u671f\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u8c03\u7814\u9a8c\u8bc1\u4e86\u9700\u6c42\u548c\u529f\u80fd\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u652f\u6301\u81ea\u7136\u95ee\u9898\u751f\u547d\u5468\u671f\u7684\u73af\u5883\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u80fd\u63d0\u5347\u534f\u4f5c\u3001\u51b3\u7b56\u548c\u77e5\u8bc6\u4fdd\u5b58\u3002", "conclusion": "\u8f85\u52a9\u73af\u5883\u80fd\u6709\u6548\u7ba1\u7406\u81ea\u7136\u95ee\u9898\uff0c\u63d0\u5347\u67b6\u6784\u8bbe\u8ba1\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002"}}
{"id": "2506.23306", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23306", "abs": "https://arxiv.org/abs/2506.23306", "authors": ["Qi Liu", "Can Li", "Wanjing Ma"], "title": "GATSim: Urban Mobility Simulation with Generative Agents", "comment": null, "summary": "Traditional agent-based urban mobility simulations rely on rigid rule-based\nsystems that fail to capture the complexity, adaptability, and behavioral\ndiversity characteristic of human travel decision-making. Recent advances in\nlarge language models and AI agent technology offer opportunities to create\nagents with reasoning capabilities, persistent memory, and adaptive learning\nmechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel\nframework that leverages these advances to create generative agents with rich\nbehavioral characteristics for urban mobility simulation. Unlike conventional\napproaches, GATSim agents possess diverse socioeconomic attributes, individual\nlifestyles, and evolving preferences that shape their mobility decisions\nthrough psychologically-informed memory systems, tool usage capabilities, and\nlifelong learning mechanisms. The main contributions of this study include: (1)\na comprehensive architecture combining an urban mobility foundation model with\nagent cognitive systems and transport simulation environment, (2) a fully\nfunctional prototype implementation, and (3) systematic validation\ndemonstrating that generative agents produce believable travel behaviors.\nThrough designed reflection processes, generative agents in this study can\ntransform specific travel experiences into generalized insights, enabling\nrealistic behavioral adaptation over time with specialized mechanisms for\nactivity planning and real-time reactive behaviors tailored to urban mobility\ncontexts. Experiments show that generative agents perform competitively with\nhuman annotators in mobility scenarios while naturally producing macroscopic\ntraffic evolution patterns. The code for the prototype system is shared at\nhttps://github.com/qiliuchn/gatsim.", "AI": {"tldr": "GATSim\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548cAI\u4ee3\u7406\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u57ce\u5e02\u4ea4\u901a\u6a21\u62df\u6846\u67b6\uff0c\u751f\u6210\u5177\u6709\u4e30\u5bcc\u884c\u4e3a\u7279\u5f81\u7684\u4ee3\u7406\uff0c\u80fd\u591f\u6a21\u62df\u4eba\u7c7b\u65c5\u884c\u51b3\u7b56\u7684\u590d\u6742\u6027\u3001\u9002\u5e94\u6027\u548c\u884c\u4e3a\u591a\u6837\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u4ee3\u7406\u6a21\u62df\u65e0\u6cd5\u6355\u6349\u4eba\u7c7b\u65c5\u884c\u51b3\u7b56\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u548cAI\u4ee3\u7406\u6280\u672f\u7684\u53d1\u5c55\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002", "method": "GATSim\u7ed3\u5408\u57ce\u5e02\u4ea4\u901a\u57fa\u7840\u6a21\u578b\u3001\u4ee3\u7406\u8ba4\u77e5\u7cfb\u7edf\u548c\u4ea4\u901a\u6a21\u62df\u73af\u5883\uff0c\u901a\u8fc7\u5fc3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u3001\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u548c\u7ec8\u8eab\u5b66\u4e60\u673a\u5236\uff0c\u751f\u6210\u5177\u6709\u591a\u6837\u5316\u793e\u4f1a\u7ecf\u6d4e\u5c5e\u6027\u548c\u884c\u4e3a\u7279\u5f81\u7684\u4ee3\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGATSim\u751f\u6210\u7684\u4ee3\u7406\u5728\u4ea4\u901a\u573a\u666f\u4e2d\u8868\u73b0\u4e0e\u4eba\u7c7b\u6807\u6ce8\u8005\u76f8\u5f53\uff0c\u5e76\u80fd\u81ea\u7136\u751f\u6210\u5b8f\u89c2\u4ea4\u901a\u6f14\u5316\u6a21\u5f0f\u3002", "conclusion": "GATSim\u4e3a\u57ce\u5e02\u4ea4\u901a\u6a21\u62df\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u771f\u5b9e\u3001\u9002\u5e94\u6027\u66f4\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u751f\u6210\u4ee3\u7406\u7684\u884c\u4e3a\u591a\u6837\u6027\u63d0\u5347\u4e86\u6a21\u62df\u7684\u903c\u771f\u5ea6\u3002"}}
{"id": "2506.23592", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23592", "abs": "https://arxiv.org/abs/2506.23592", "authors": ["V\u00edctor Mayoral-Vilches"], "title": "Cybersecurity AI: The Dangerous Gap Between Automation and Autonomy", "comment": null, "summary": "The cybersecurity industry combines \"automated\" and \"autonomous\" AI, creating\ndangerous misconceptions about system capabilities. Recent milestones like XBOW\ntopping HackerOne's leaderboard showcase impressive progress, yet these systems\nremain fundamentally semi-autonomous--requiring human oversight. Drawing from\nrobotics principles, where the distinction between automation and autonomy is\nwell-established, I take inspiration from prior work and establish a 6-level\ntaxonomy (Level 0-5) distinguishing automation from autonomy in Cybersecurity\nAI. Current \"autonomous\" pentesters operate at Level 3-4: they execute complex\nattack sequences but need human review for edge cases and strategic decisions.\nTrue Level 5 autonomy remains aspirational. Organizations deploying\nmischaracterized \"autonomous\" tools risk reducing oversight precisely when it's\nmost needed, potentially creating new vulnerabilities. The path forward\nrequires precise terminology, transparent capabilities disclosure, and human-AI\npartnership-not replacement.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u7f51\u7edc\u5b89\u5168AI\u4e2d\u2018\u81ea\u52a8\u5316\u2019\u4e0e\u2018\u81ea\u4e3b\u6027\u2019\u7684\u6df7\u6dc6\u95ee\u9898\uff0c\u63d0\u51fa\u4e866\u7ea7\u5206\u7c7b\u6cd5\uff0c\u6307\u51fa\u5f53\u524d\u5de5\u5177\u4ec5\u8fbe\u52303-4\u7ea7\uff0c\u9700\u4eba\u7c7b\u76d1\u7763\uff0c\u5e76\u8b66\u544a\u8bef\u7528\u2018\u81ea\u4e3b\u6027\u2019\u6807\u7b7e\u53ef\u80fd\u5e26\u6765\u98ce\u9669\u3002", "motivation": "\u7f51\u7edc\u5b89\u5168\u9886\u57df\u5bf9\u2018\u81ea\u52a8\u5316\u2019\u548c\u2018\u81ea\u4e3b\u6027\u2019AI\u7684\u6df7\u6dc6\u53ef\u80fd\u5bfc\u81f4\u5bf9\u7cfb\u7edf\u80fd\u529b\u7684\u8bef\u89e3\uff0c\u8fdb\u800c\u5f15\u53d1\u6f5c\u5728\u98ce\u9669\u3002", "method": "\u501f\u9274\u673a\u5668\u4eba\u5b66\u539f\u5219\uff0c\u5efa\u7acb6\u7ea7\u5206\u7c7b\u6cd5\uff080-5\u7ea7\uff09\uff0c\u533a\u5206\u7f51\u7edc\u5b89\u5168AI\u7684\u81ea\u52a8\u5316\u4e0e\u81ea\u4e3b\u6027\u3002", "result": "\u5f53\u524d\u2018\u81ea\u4e3b\u2019\u6e17\u900f\u6d4b\u8bd5\u5de5\u5177\u4ec5\u8fbe\u52303-4\u7ea7\uff0c\u4ecd\u9700\u4eba\u7c7b\u76d1\u7763\uff1b\u771f\u6b63\u76845\u7ea7\u81ea\u4e3b\u6027\u5c1a\u672a\u5b9e\u73b0\u3002", "conclusion": "\u9700\u4f7f\u7528\u7cbe\u786e\u672f\u8bed\u3001\u900f\u660e\u62ab\u9732\u80fd\u529b\uff0c\u5e76\u5f3a\u8c03\u4eba\u673a\u5408\u4f5c\u800c\u975e\u66ff\u4ee3\uff0c\u4ee5\u907f\u514d\u98ce\u9669\u3002"}}
{"id": "2506.23967", "categories": ["cs.SE", "cs.CY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.23967", "abs": "https://arxiv.org/abs/2506.23967", "authors": ["Geerd-Dietger Hoffmann", "Verena Majuntke"], "title": "Green Metrics Tool: Measuring for fun and profit", "comment": null, "summary": "The environmental impact of software is gaining increasing attention as the\ndemand for computational resources continues to rise. In order to optimize\nsoftware resource consumption and reduce carbon emissions, measuring and\nevaluating software is a first essential step. In this paper we discuss what\nmetrics are important for fact base decision making. We introduce the Green\nMetrics Tool (GMT), a novel framework for accurately measuring the resource\nconsumption of software. The tool provides a containerized, controlled, and\nreproducible life cycle-based approach, assessing the resource use of software\nduring key phases. Finally, we discuss GMT features like visualization,\ncomparability and rule- and LLM-based optimisations highlighting its potential\nto guide developers and researchers in reducing the environmental impact of\ntheir software.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86Green Metrics Tool (GMT)\uff0c\u4e00\u4e2a\u7528\u4e8e\u6d4b\u91cf\u8f6f\u4ef6\u8d44\u6e90\u6d88\u8017\u7684\u65b0\u6846\u67b6\uff0c\u65e8\u5728\u4f18\u5316\u8d44\u6e90\u4f7f\u7528\u548c\u51cf\u5c11\u78b3\u6392\u653e\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u7684\u589e\u52a0\uff0c\u8f6f\u4ef6\u5bf9\u73af\u5883\u7684\u5f71\u54cd\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u9700\u8981\u6d4b\u91cf\u548c\u8bc4\u4f30\u8f6f\u4ef6\u8d44\u6e90\u6d88\u8017\u4ee5\u652f\u6301\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e86GMT\u6846\u67b6\uff0c\u91c7\u7528\u5bb9\u5668\u5316\u3001\u53ef\u63a7\u548c\u53ef\u91cd\u590d\u7684\u751f\u547d\u5468\u671f\u65b9\u6cd5\uff0c\u8bc4\u4f30\u8f6f\u4ef6\u5728\u5173\u952e\u9636\u6bb5\u7684\u8d44\u6e90\u4f7f\u7528\u3002", "result": "GMT\u63d0\u4f9b\u4e86\u53ef\u89c6\u5316\u3001\u53ef\u6bd4\u8f83\u6027\u4ee5\u53ca\u57fa\u4e8e\u89c4\u5219\u548cLLM\u7684\u4f18\u5316\u529f\u80fd\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u51cf\u5c11\u8f6f\u4ef6\u7684\u73af\u5883\u5f71\u54cd\u3002", "conclusion": "GMT\u6709\u6f5c\u529b\u6210\u4e3a\u51cf\u5c11\u8f6f\u4ef6\u73af\u5883\u5f71\u54cd\u7684\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2506.23464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23464", "abs": "https://arxiv.org/abs/2506.23464", "authors": ["Sahil Tripathi", "Md Tabrez Nafis", "Imran Hussain", "Jiechao Gao"], "title": "The Confidence Paradox: Can LLM Know When It's Wrong", "comment": null, "summary": "Document Visual Question Answering (DocVQA) systems are increasingly deployed\nin real world applications, yet they remain ethically opaque-often producing\noverconfident answers to ambiguous questions or failing to communicate\nuncertainty in a trustworthy manner. This misalignment between model confidence\nand actual knowledge poses significant risks, particularly in domains requiring\nethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT\nhave advanced SOTA performance by focusing on architectural sophistication and\naccuracy; however, they fall short in ethical responsiveness.\n  To address these limitations, we introduce HonestVQA, a self-supervised\nhonesty calibration framework for ethically aligned DocVQA. Our model-agnostic\nmethod quantifies uncertainty to identify knowledge gaps, aligns model\nconfidence with actual correctness using weighted loss functions, and enforces\nethical response behavior via contrastive learning. We further introduce two\nprincipled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence\nIndex (ECI)--to benchmark alignment between confidence, accuracy, and ethical\ncommunication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%\nand F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces\noverconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In\ncross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,\ndemonstrating strong generalization. Ablation shows a 3.8% drop in accuracy\nwithout alignment or contrastive loss.", "AI": {"tldr": "HonestVQA\u662f\u4e00\u4e2a\u81ea\u76d1\u7763\u7684\u8bda\u5b9e\u6821\u51c6\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3DocVQA\u7cfb\u7edf\u4e2d\u7684\u4f26\u7406\u95ee\u9898\uff0c\u901a\u8fc7\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u548c\u5bf9\u9f50\u6a21\u578b\u7f6e\u4fe1\u5ea6\uff0c\u63d0\u5347\u51c6\u786e\u6027\u548c\u4f26\u7406\u54cd\u5e94\u80fd\u529b\u3002", "motivation": "\u73b0\u6709DocVQA\u7cfb\u7edf\u5728\u4f26\u7406\u54cd\u5e94\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u6a21\u578b\u7f6e\u4fe1\u5ea6\u4e0e\u5b9e\u9645\u77e5\u8bc6\u4e0d\u5339\u914d\uff0c\u53ef\u80fd\u5bfc\u81f4\u9ad8\u98ce\u9669\u3002", "method": "HonestVQA\u91c7\u7528\u81ea\u76d1\u7763\u65b9\u6cd5\uff0c\u5305\u62ec\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3001\u52a0\u6743\u635f\u5931\u51fd\u6570\u5bf9\u9f50\u7f6e\u4fe1\u5ea6\uff0c\u4ee5\u53ca\u5bf9\u6bd4\u5b66\u4e60\u5f3a\u5236\u4f26\u7406\u54cd\u5e94\u884c\u4e3a\u3002", "result": "HonestVQA\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548cF1\u5206\u6570\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "HonestVQA\u901a\u8fc7\u4f26\u7406\u5bf9\u9f50\u548c\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86DocVQA\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2506.23603", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23603", "abs": "https://arxiv.org/abs/2506.23603", "authors": ["Baihe Ma", "Yanna Jiang", "Xu Wang", "Guangshen Yu", "Qin Wang", "Caijun Sun", "Chen Li", "Xuelei Qi", "Ying He", "Wei Ni", "Ren Ping Liu"], "title": "SoK: Semantic Privacy in Large Language Models", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed in sensitive\ndomains, traditional data privacy measures prove inadequate for protecting\ninformation that is implicit, contextual, or inferable - what we define as\nsemantic privacy. This Systematization of Knowledge (SoK) introduces a\nlifecycle-centric framework to analyze how semantic privacy risks emerge across\ninput processing, pretraining, fine-tuning, and alignment stages of LLMs. We\ncategorize key attack vectors and assess how current defenses, such as\ndifferential privacy, embedding encryption, edge computing, and unlearning,\naddress these threats. Our analysis reveals critical gaps in semantic-level\nprotection, especially against contextual inference and latent representation\nleakage. We conclude by outlining open challenges, including quantifying\nsemantic leakage, protecting multimodal inputs, balancing de-identification\nwith generation quality, and ensuring transparency in privacy enforcement. This\nwork aims to inform future research on designing robust, semantically aware\nprivacy-preserving techniques for LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee5\u751f\u547d\u5468\u671f\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f93\u5165\u5904\u7406\u3001\u9884\u8bad\u7ec3\u3001\u5fae\u8c03\u548c\u5bf9\u9f50\u9636\u6bb5\u4e2d\u8bed\u4e49\u9690\u79c1\u98ce\u9669\u7684\u4ea7\u751f\uff0c\u5e76\u8bc4\u4f30\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u7684\u4e0d\u8db3\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f20\u7edf\u9690\u79c1\u4fdd\u62a4\u63aa\u65bd\u65e0\u6cd5\u5e94\u5bf9\u9690\u5f0f\u3001\u4e0a\u4e0b\u6587\u6216\u53ef\u63a8\u65ad\u7684\u8bed\u4e49\u9690\u79c1\u98ce\u9669\uff0c\u4e9f\u9700\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u5173\u952e\u653b\u51fb\u5411\u91cf\uff0c\u8bc4\u4f30\u5dee\u5206\u9690\u79c1\u3001\u5d4c\u5165\u52a0\u5bc6\u3001\u8fb9\u7f18\u8ba1\u7b97\u548c\u9057\u5fd8\u7b49\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u7684\u6548\u679c\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u8bed\u4e49\u5c42\u9762\u4fdd\u62a4\u7684\u5173\u952e\u6f0f\u6d1e\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u4e0a\u4e0b\u6587\u63a8\u65ad\u548c\u6f5c\u5728\u8868\u793a\u6cc4\u6f0f\u7684\u9632\u5fa1\u4e0d\u8db3\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86\u5f00\u653e\u6311\u6218\uff0c\u5305\u62ec\u91cf\u5316\u8bed\u4e49\u6cc4\u6f0f\u3001\u4fdd\u62a4\u591a\u6a21\u6001\u8f93\u5165\u3001\u5e73\u8861\u53bb\u6807\u8bc6\u4e0e\u751f\u6210\u8d28\u91cf\uff0c\u4ee5\u53ca\u786e\u4fdd\u9690\u79c1\u6267\u884c\u7684\u900f\u660e\u5ea6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2506.23995", "categories": ["cs.SE", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.23995", "abs": "https://arxiv.org/abs/2506.23995", "authors": ["Mingfei Cheng", "Renzhi Wang", "Xiaofei Xie", "Yuan Zhou", "Lei Ma"], "title": "STCLocker: Deadlock Avoidance Testing for Autonomous Driving Systems", "comment": null, "summary": "Autonomous Driving System (ADS) testing is essential to ensure the safety and\nreliability of autonomous vehicles (AVs) before deployment. However, existing\ntechniques primarily focus on evaluating ADS functionalities in single-AV\nsettings. As ADSs are increasingly deployed in multi-AV traffic, it becomes\ncrucial to assess their cooperative performance, particularly regarding\ndeadlocks, a fundamental coordination failure in which multiple AVs enter a\ncircular waiting state indefinitely, resulting in motion planning failures.\nDespite its importance, the cooperative capability of ADSs to prevent deadlocks\nremains insufficiently underexplored. To address this gap, we propose the first\ndedicated Spatio-Temporal Conflict-Guided Deadlock Avoidance Testing technique,\nSTCLocker, for generating DeadLock Scenarios (DLSs), where a group of AVs\ncontrolled by the ADS under test are in a circular wait state. STCLocker\nconsists of three key components: Deadlock Oracle, Conflict Feedback, and\nConflict-aware Scenario Generation. Deadlock Oracle provides a reliable\nblack-box mechanism for detecting deadlock cycles among multiple AVs within a\ngiven scenario. Conflict Feedback and Conflict-aware Scenario Generation\ncollaborate to actively guide AVs into simultaneous competition over spatial\nconflict resources (i.e., shared passing regions) and temporal competitive\nbehaviors (i.e., reaching the conflict region at the same time), thereby\nincreasing the effectiveness of generating conflict-prone deadlocks. We\nevaluate STCLocker on two types of ADSs: Roach, an end-to-end ADS, and OpenCDA,\na module-based ADS supporting cooperative communication. Experimental results\nshow that, on average, STCLocker generates more DLS than the best-performing\nbaseline.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSTCLocker\u7684\u6280\u672f\uff0c\u7528\u4e8e\u6d4b\u8bd5\u591a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff08AVs\uff09\u7684\u534f\u4f5c\u6027\u80fd\uff0c\u7279\u522b\u662f\u907f\u514d\u6b7b\u9501\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u4e3b\u8981\u5173\u6ce8\u5355AV\u6d4b\u8bd5\uff0c\u800c\u591aAV\u73af\u5883\u4e2d\u7684\u534f\u4f5c\u6027\u80fd\u8bc4\u4f30\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u6b7b\u9501\u95ee\u9898\u3002", "method": "STCLocker\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u6b7b\u9501\u68c0\u6d4b\u5668\u3001\u51b2\u7a81\u53cd\u9988\u548c\u51b2\u7a81\u611f\u77e5\u573a\u666f\u751f\u6210\uff0c\u7528\u4e8e\u751f\u6210\u6b7b\u9501\u573a\u666f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSTCLocker\u5728\u751f\u6210\u6b7b\u9501\u573a\u666f\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "STCLocker\u586b\u8865\u4e86\u591aAV\u534f\u4f5c\u6027\u80fd\u6d4b\u8bd5\u7684\u7a7a\u767d\uff0c\u4e3aAV\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2506.23503", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23503", "abs": "https://arxiv.org/abs/2506.23503", "authors": ["Bosubabu Sambana", "Kondreddygari Archana", "Suram Indhra Sena Reddy", "Shaik Meethaigar Jameer Basha", "Shaik Karishma"], "title": "Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence", "comment": "6 Pages, 5 Figures, IEEE IDCIoT 2025", "summary": "Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the\nirrational thought patterns associated with mental health disorders, but its\neffectiveness relies on accurately identifying cognitive pathways to provide\ntargeted treatment. In today's digital age, individuals often express negative\nemotions on social media, where they may reveal cognitive distortions, and in\nsevere cases, exhibit suicidal tendencies. However, there is a significant gap\nin methodologies designed to analyze these cognitive pathways, which could be\ncritical for psychotherapists aiming to deliver timely and effective\ninterventions in online environments. Cognitive Behavioral Therapy (CBT)\nframework leveraging acceptance, commitment and data augmentation to categorize\nand address both textual and visual content as positive or negative.\nSpecifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5,\nPEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages\nfocusing on detecting negative emotions and cognitive distortions within social\nmedia data. While existing models are primarily designed to identify negative\nthoughts, the proposed system goes beyond this by predicting additional\nnegative side effects and other potential mental health disorders likes\nPhobias, Eating Disorders. This enhancement allows for a more comprehensive\nunderstanding and intervention strategy, offering psychotherapists a powerful\ntool for early detection and treatment of various psychological issues.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCBT\u6846\u67b6\u7684\u7cfb\u7edf\uff0c\u5229\u7528BERT\u3001RoBERTa\u7b49\u6a21\u578b\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u4e2d\u7684\u8d1f\u9762\u60c5\u7eea\u548c\u8ba4\u77e5\u626d\u66f2\uff0c\u5e76\u9884\u6d4b\u6f5c\u5728\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u4e2d\u7684\u8ba4\u77e5\u8def\u5f84\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u65e0\u6cd5\u4e3a\u5fc3\u7406\u6cbb\u7597\u5e08\u63d0\u4f9b\u53ca\u65f6\u6709\u6548\u7684\u5e72\u9884\u5de5\u5177\u3002", "method": "\u7ed3\u5408CBT\u6846\u67b6\uff0c\u4f7f\u7528BERT\u3001RoBERTa\u8fdb\u884c\u60c5\u611f\u5206\u6790\uff0cT5\u3001PEGASUS\u8fdb\u884c\u6587\u672c\u6458\u8981\uff0cmT5\u8fdb\u884c\u591a\u8bed\u8a00\u7ffb\u8bd1\uff0c\u4ee5\u8bc6\u522b\u8d1f\u9762\u60c5\u7eea\u548c\u8ba4\u77e5\u626d\u66f2\u3002", "result": "\u7cfb\u7edf\u4e0d\u4ec5\u80fd\u8bc6\u522b\u8d1f\u9762\u601d\u7ef4\uff0c\u8fd8\u80fd\u9884\u6d4b\u6f5c\u5728\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\uff08\u5982\u6050\u60e7\u75c7\u3001\u996e\u98df\u969c\u788d\uff09\uff0c\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u5e72\u9884\u7b56\u7565\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u5fc3\u7406\u6cbb\u7597\u5e08\u63d0\u4f9b\u4e86\u65e9\u671f\u68c0\u6d4b\u548c\u6cbb\u7597\u5fc3\u7406\u95ee\u9898\u7684\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2506.23622", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23622", "abs": "https://arxiv.org/abs/2506.23622", "authors": ["Jiahui Wu", "Fucai Luo", "Tiecheng Sun", "Haiyan Wang", "Weizhe Zhang"], "title": "Privacy-Preserving Federated Learning Scheme with Mitigating Model Poisoning Attacks: Vulnerabilities and Countermeasures", "comment": null, "summary": "The privacy-preserving federated learning schemes based on the setting of two\nhonest-but-curious and non-colluding servers offer promising solutions in terms\nof security and efficiency. However, our investigation reveals that these\nschemes still suffer from privacy leakage when considering model poisoning\nattacks from malicious users. Specifically, we demonstrate that the\nprivacy-preserving computation process for defending against model poisoning\nattacks inadvertently leaks privacy to one of the honest-but-curious servers,\nenabling it to access users' gradients in plaintext. To address both privacy\nleakage and model poisoning attacks, we propose an enhanced privacy-preserving\nand Byzantine-robust federated learning (PBFL) scheme, comprising three\ncomponents: (1) a two-trapdoor fully homomorphic encryption (FHE) scheme to\nbolster users' privacy protection; (2) a novel secure normalization judgment\nmethod to preemptively thwart gradient poisoning; and (3) an innovative secure\ncosine similarity measurement method for detecting model poisoning attacks\nwithout compromising data privacy. Our scheme guarantees privacy preservation\nand resilience against model poisoning attacks, even in scenarios with\nheterogeneous, non-IID (Independently and Identically Distributed) datasets.\nTheoretical analyses substantiate the security and efficiency of our scheme,\nand extensive experiments corroborate the efficacy of our private attacks.\nFurthermore, the experimental results demonstrate that our scheme accelerates\ntraining speed while reducing communication overhead compared to the\nstate-of-the-art PBFL schemes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u62dc\u5360\u5ead\u9c81\u68d2\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6848\uff08PBFL\uff09\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6848\u5728\u6a21\u578b\u6295\u6bd2\u653b\u51fb\u4e0b\u7684\u9690\u79c1\u6cc4\u6f0f\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4e24\u4e2a\u8bda\u5b9e\u4f46\u597d\u5947\u4e14\u4e0d\u5171\u8c0b\u670d\u52a1\u5668\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6848\u5728\u5b89\u5168\u6027\u548c\u6548\u7387\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6a21\u578b\u6295\u6bd2\u653b\u51fb\u4e0b\u4ecd\u5b58\u5728\u9690\u79c1\u6cc4\u6f0f\u95ee\u9898\u3002", "method": "\u65b9\u6848\u5305\u62ec\u4e09\u4e2a\u90e8\u5206\uff1a\u53cc\u9677\u95e8\u5168\u540c\u6001\u52a0\u5bc6\uff08FHE\uff09\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\u3001\u65b0\u578b\u5b89\u5168\u5f52\u4e00\u5316\u5224\u65ad\u65b9\u6cd5\u9632\u6b62\u68af\u5ea6\u6295\u6bd2\u3001\u521b\u65b0\u7684\u5b89\u5168\u4f59\u5f26\u76f8\u4f3c\u5ea6\u6d4b\u91cf\u65b9\u6cd5\u68c0\u6d4b\u6a21\u578b\u6295\u6bd2\u653b\u51fb\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u65b9\u6848\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u6570\u636e\u4e0b\u4ecd\u80fd\u4fdd\u8bc1\u9690\u79c1\u4fdd\u62a4\u548c\u6297\u6a21\u578b\u6295\u6bd2\u653b\u51fb\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u8bad\u7ec3\u901f\u5ea6\u5e76\u964d\u4f4e\u4e86\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "\u63d0\u51fa\u7684PBFL\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86\u9690\u79c1\u6cc4\u6f0f\u548c\u6a21\u578b\u6295\u6bd2\u653b\u51fb\u95ee\u9898\uff0c\u517c\u5177\u5b89\u5168\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2506.24015", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.24015", "abs": "https://arxiv.org/abs/2506.24015", "authors": ["Ramtin Ehsani", "Esteban Parra", "Sonia Haiduc", "Preetha Chatterjee"], "title": "Bug Fixing with Broader Context: Enhancing LLM-Based Program Repair via Layered Knowledge Injection", "comment": null, "summary": "Prompting LLMs with bug-related context (e.g., error messages, stack traces)\nimproves automated program repair, but many bugs still remain unresolved. In\nreal-world projects, developers often rely on broader repository and\nproject-level context beyond the local code to resolve such bugs. In this\npaper, we investigate how automatically extracting and providing such knowledge\ncan improve LLM-based program repair. We propose a layered knowledge injection\nframework that incrementally augments LLMs with structured context. It starts\nwith the Bug Knowledge Layer, which includes information such as the buggy\nfunction and failing tests; expands to the Repository Knowledge Layer, which\nadds structural dependencies, related files, and commit history; and finally\ninjects the Project Knowledge Layer, which incorporates relevant details from\ndocumentation and previously fixed bugs. We evaluate this framework on a\ndataset of 314 bugs from BugsInPy using two LLMs (Llama 3.3 and GPT-4o-mini),\nand analyze fix rates across six bug types. By progressively injecting\nknowledge across layers, our approach achieves a fix rate of 79% (250/314)\nusing Llama 3.3, a significant improvement of 23% over previous work. All bug\ntypes show improvement with the addition of repository-level context, while\nonly a subset benefit further from project-level knowledge, highlighting that\ndifferent bug types require different levels of contextual information for\neffective repair. We also analyze the remaining unresolved bugs and find that\nmore complex and structurally isolated bugs, such as Program Anomaly and GUI\nbugs, remain difficult even after injecting all available information. Our\nresults show that layered context injection improves program repair and suggest\nthe need for interactive and adaptive APR systems.", "AI": {"tldr": "\u901a\u8fc7\u5206\u5c42\u77e5\u8bc6\u6ce8\u5165\u6846\u67b6\uff08Bug\u3001Repository\u3001Project\u4e09\u5c42\uff09\u63d0\u5347LLM\u5728\u7a0b\u5e8f\u4fee\u590d\u4e2d\u7684\u8868\u73b0\uff0c\u4fee\u590d\u7387\u8fbe\u523079%\uff0c\u4f46\u590d\u6742\u548c\u7ed3\u6784\u5b64\u7acb\u7684bug\u4ecd\u96be\u4ee5\u89e3\u51b3\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u5c40\u90e8\u4ee3\u7801\u4fe1\u606f\u4fee\u590dbug\uff0c\u800c\u5f00\u53d1\u8005\u5b9e\u9645\u9700\u8981\u66f4\u5e7f\u6cdb\u7684\u4e0a\u4e0b\u6587\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u77e5\u8bc6\u6ce8\u5165\u6846\u67b6\uff0c\u9010\u6b65\u589e\u52a0Bug\u3001Repository\u3001Project\u5c42\u7ea7\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "result": "\u4fee\u590d\u7387\u63d0\u534723%\uff0c\u4e0d\u540cbug\u7c7b\u578b\u5bf9\u4e0a\u4e0b\u6587\u9700\u6c42\u4e0d\u540c\u3002", "conclusion": "\u5206\u5c42\u4e0a\u4e0b\u6587\u6ce8\u5165\u6709\u6548\uff0c\u4f46\u9700\u4ea4\u4e92\u5f0f\u548c\u81ea\u9002\u5e94\u7cfb\u7edf\u5e94\u5bf9\u590d\u6742bug\u3002"}}
{"id": "2506.23504", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23504", "abs": "https://arxiv.org/abs/2506.23504", "authors": ["Bosubabu Sambana", "Kotamsetty Geethika Devi", "Bandi Rajeswara Reddy", "Galeti Mohammad Hussain", "Gownivalla Siddartha"], "title": "Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM", "comment": "6 Pages, 7 Figures", "summary": "The recent development of advanced machine learning methods for hybrid models\nhas greatly addressed the need for the correct prediction of electrical prices.\nThis method combines AlexNet and LSTM algorithms, which are used to introduce a\nnew model with higher accuracy in price forecasting. Despite RNN and ANN being\neffective, they often fail to deal with forex time sequence data. The\ntraditional methods do not accurately forecast the prices. These traditional\nmethods only focus on demand and price which leads to insufficient analysis of\ndata. To address this issue, using the hybrid approach, which focuses on\nexternal variables that also effect the predicted prices. Nevertheless, due to\nAlexNet's excellent feature extraction and LSTM's learning sequential patterns,\nthe prediction accuracy is vastly increased. The model is built on the past\ndata, which has been supplied with the most significant elements like demand,\ntemperature, sunlight, and rain. For example, the model applies methods, such\nas minimum-maximum scaling and a time window, to predict the electricity prices\nof the future. The results show that this hybrid model is good than the\nstandalone ones in terms of accuracy. Although we got our accuracy rating of\n97.08, it shows higher accompaniments than remaining models RNN and ANN with\naccuracies of 96.64 and 96.63 respectively.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408AlexNet\u548cLSTM\u7684\u6df7\u5408\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u9ad8\u7535\u4ef7\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u4f20\u7edfRNN\u548cANN\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4ec5\u5173\u6ce8\u9700\u6c42\u548c\u4ef7\u683c\uff0c\u65e0\u6cd5\u5145\u5206\u5206\u6790\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u4e14\u9884\u6d4b\u51c6\u786e\u6027\u4e0d\u8db3\u3002", "method": "\u91c7\u7528AlexNet\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0cLSTM\u5b66\u4e60\u5e8f\u5217\u6a21\u5f0f\uff0c\u7ed3\u5408\u5916\u90e8\u53d8\u91cf\uff08\u5982\u9700\u6c42\u3001\u6e29\u5ea6\u3001\u9633\u5149\u548c\u964d\u96e8\uff09\u6784\u5efa\u6a21\u578b\u3002", "result": "\u6df7\u5408\u6a21\u578b\u51c6\u786e\u7387\u8fbe97.08%\uff0c\u4f18\u4e8eRNN\uff0896.64%\uff09\u548cANN\uff0896.63%\uff09\u3002", "conclusion": "\u6df7\u5408\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u7535\u4ef7\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.23634", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23634", "abs": "https://arxiv.org/abs/2506.23634", "authors": ["Youjeong Noh", "Joon-Young Paik", "Jingun Kwon", "Eun-Sun Cho"], "title": "gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures", "comment": null, "summary": "Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by\nconverting programs into forms that are more complex to analyze. However, MBA\nhas been increasingly exploited by malware developers to evade detection and\ncause significant real-world problems. Traditional MBA deobfuscation methods\noften consider these expressions as part of a black box and overlook their\ninternal semantic information. To bridge this gap, we propose a truth table,\nwhich is an automatically constructed semantic representation of an\nexpression's behavior that does not rely on external resources. The truth table\nis a mathematical form that represents the output of expression for all\npossible combinations of input. We also propose a general and extensible guided\nMBA deobfuscation framework (gMBA) that modifies a Transformer-based neural\nencoder-decoder Seq2Seq architecture to incorporate this semantic guidance.\nExperimental results and in-depth analysis show that integrating expression\nsemantics significantly improves performance and highlights the importance of\ninternal semantic expressions in recovering obfuscated code to its original\nform.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u771f\u503c\u8868\u548cTransformer\u67b6\u6784\u7684MBA\u53cd\u6df7\u6dc6\u6846\u67b6\uff08gMBA\uff09\uff0c\u901a\u8fc7\u8bed\u4e49\u6307\u5bfc\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "MBA\u6df7\u6dc6\u88ab\u5e7f\u6cdb\u7528\u4e8e\u6076\u610f\u8f6f\u4ef6\u9003\u907f\u68c0\u6d4b\uff0c\u4f20\u7edf\u65b9\u6cd5\u5ffd\u89c6\u5185\u90e8\u8bed\u4e49\u4fe1\u606f\uff0c\u5bfc\u81f4\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u771f\u503c\u8868\u4f5c\u4e3a\u8bed\u4e49\u8868\u793a\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8eTransformer\u7684gMBA\u6846\u67b6\uff0c\u7ed3\u5408\u8bed\u4e49\u6307\u5bfc\u8fdb\u884c\u53cd\u6df7\u6dc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8bed\u4e49\u4fe1\u606f\u7684\u6574\u5408\u663e\u8457\u63d0\u5347\u4e86\u53cd\u6df7\u6dc6\u6027\u80fd\u3002", "conclusion": "\u5185\u90e8\u8bed\u4e49\u4fe1\u606f\u5bf9\u6062\u590d\u6df7\u6dc6\u4ee3\u7801\u81f3\u5173\u91cd\u8981\uff0cgMBA\u6846\u67b6\u4e3aMBA\u53cd\u6df7\u6dc6\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.23683", "categories": ["cs.CR", "cs.OS", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23683", "abs": "https://arxiv.org/abs/2506.23683", "authors": ["Maysara Alhindi", "Joseph Hallett"], "title": "Threadbox: Sandboxing for Modular Security", "comment": null, "summary": "There are many sandboxing mechanisms provided by operating systems to limit\nwhat resources applications can access, however, sometimes the use of these\nmechanisms requires developers to refactor their code to fit the sandboxing\nmodel. In this work, we investigate what makes existing sandboxing mechanisms\nchallenging to apply to certain types of applications, and propose Threadbox, a\nsandboxing mechanism that enables having modular and independent sandboxes, and\ncan be applied to threads and sandbox specific functions. We present case\nstudies to illustrate the applicability of the idea and discuss its\nlimitations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faThreadbox\uff0c\u4e00\u79cd\u65b0\u578b\u6c99\u7bb1\u673a\u5236\uff0c\u652f\u6301\u6a21\u5757\u5316\u548c\u72ec\u7acb\u6c99\u7bb1\uff0c\u9002\u7528\u4e8e\u7ebf\u7a0b\u548c\u7279\u5b9a\u51fd\u6570\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6c99\u7bb1\u673a\u5236\u96be\u4ee5\u5e94\u7528\u4e8e\u67d0\u4e9b\u5e94\u7528\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6c99\u7bb1\u673a\u5236\u9700\u8981\u5f00\u53d1\u8005\u91cd\u6784\u4ee3\u7801\u4ee5\u9002\u5e94\u6c99\u7bb1\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002", "method": "\u63d0\u51faThreadbox\u673a\u5236\uff0c\u652f\u6301\u6a21\u5757\u5316\u548c\u72ec\u7acb\u6c99\u7bb1\uff0c\u53ef\u5e94\u7528\u4e8e\u7ebf\u7a0b\u548c\u7279\u5b9a\u51fd\u6570\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86Threadbox\u7684\u9002\u7528\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5c40\u9650\u6027\u3002", "conclusion": "Threadbox\u4e3a\u89e3\u51b3\u73b0\u6709\u6c99\u7bb1\u673a\u5236\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.23517", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.23517", "abs": "https://arxiv.org/abs/2506.23517", "authors": ["Selin Dik", "Osman Erdem", "Mehmet Dik"], "title": "Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays", "comment": null, "summary": "As the use of AI tools by students has become more prevalent, instructors\nhave started using AI detection tools like GPTZero and QuillBot to detect AI\nwritten text. However, the reliability of these detectors remains uncertain. In\nour study, we focused mostly on the success rate of GPTZero, the most-used AI\ndetector, in identifying AI-generated texts based on different lengths of\nrandomly submitted essays: short (40-100 word count), medium (100-350 word\ncount), and long (350-800 word count). We gathered a data set consisting of\ntwenty-eight AI-generated papers and fifty human-written papers. With this\nrandomized essay data, papers were individually plugged into GPTZero and\nmeasured for percentage of AI generation and confidence. A vast majority of the\nAI-generated papers were detected accurately (ranging from 91-100% AI believed\ngeneration), while the human generated essays fluctuated; there were a handful\nof false positives. These findings suggest that although GPTZero is effective\nat detecting purely AI-generated content, its reliability in distinguishing\nhuman-authored texts is limited. Educators should therefore exercise caution\nwhen relying solely on AI detection tools.", "AI": {"tldr": "GPTZero\u68c0\u6d4bAI\u751f\u6210\u6587\u672c\u7684\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u5bf9\u4eba\u7c7b\u5199\u4f5c\u7684\u8bef\u5224\u8f83\u591a\uff0c\u6559\u80b2\u8005\u9700\u8c28\u614e\u4f7f\u7528\u3002", "motivation": "\u7814\u7a76AI\u68c0\u6d4b\u5de5\u5177\uff08\u5982GPTZero\uff09\u5728\u8bc6\u522bAI\u751f\u6210\u6587\u672c\u65f6\u7684\u53ef\u9760\u6027\uff0c\u5c24\u5176\u662f\u5bf9\u4e0d\u540c\u957f\u5ea6\u6587\u672c\u7684\u68c0\u6d4b\u6548\u679c\u3002", "method": "\u6536\u96c628\u7bc7AI\u751f\u6210\u548c50\u7bc7\u4eba\u7c7b\u5199\u4f5c\u7684\u8bba\u6587\uff0c\u6309\u957f\u5ea6\u5206\u7c7b\u540e\u8f93\u5165GPTZero\u68c0\u6d4bAI\u751f\u6210\u6982\u7387\u548c\u7f6e\u4fe1\u5ea6\u3002", "result": "AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u51c6\u786e\u7387\u9ad8\u8fbe91-100%\uff0c\u4f46\u4eba\u7c7b\u5199\u4f5c\u5b58\u5728\u8bef\u5224\uff08\u5047\u9633\u6027\uff09\u3002", "conclusion": "GPTZero\u5bf9\u7eafAI\u751f\u6210\u5185\u5bb9\u6709\u6548\uff0c\u4f46\u5bf9\u4eba\u7c7b\u5199\u4f5c\u533a\u5206\u80fd\u529b\u6709\u9650\uff0c\u5efa\u8bae\u6559\u80b2\u8005\u8c28\u614e\u4f9d\u8d56\u3002"}}
{"id": "2506.23682", "categories": ["cs.CR", "cs.AR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.23682", "abs": "https://arxiv.org/abs/2506.23682", "authors": ["Maysara Alhindi", "Joseph Hallett"], "title": "Not quite a piece of CHERI-cake: Are new digital security by design architectures usable?", "comment": null, "summary": "A digital security-by-design computer architecture, like CHERI, lets you\nprogram without fear of buffer overflows or other memory safety errors, but\nCHERI also rewrites some of the assumptions about how C works and how\nfundamental types (such as pointers) are implemented in hardware. We conducted\na usability study to examine how developers react to the changes required by\nCHERI when porting software to run on it. We find that developers struggle with\nCHERI's display of warnings and errors and a lack of diverse documentation.", "AI": {"tldr": "CHERI\u67b6\u6784\u901a\u8fc7\u786c\u4ef6\u4fee\u6539C\u8bed\u8a00\u57fa\u7840\u7c7b\u578b\uff08\u5982\u6307\u9488\uff09\u6765\u9632\u6b62\u5185\u5b58\u5b89\u5168\u95ee\u9898\uff0c\u4f46\u5f00\u53d1\u8005\u5bf9\u5176\u8b66\u544a\u3001\u9519\u8bef\u663e\u793a\u548c\u6587\u6863\u4e0d\u8db3\u611f\u5230\u56f0\u6270\u3002", "motivation": "\u7814\u7a76\u5f00\u53d1\u8005\u5bf9CHERI\u67b6\u6784\u7684\u9002\u5e94\u60c5\u51b5\uff0c\u4ee5\u6539\u8fdb\u5176\u53ef\u7528\u6027\u3002", "method": "\u8fdb\u884c\u53ef\u7528\u6027\u7814\u7a76\uff0c\u89c2\u5bdf\u5f00\u53d1\u8005\u5728\u79fb\u690d\u8f6f\u4ef6\u5230CHERI\u65f6\u7684\u53cd\u5e94\u3002", "result": "\u5f00\u53d1\u8005\u5bf9CHERI\u7684\u8b66\u544a\u3001\u9519\u8bef\u663e\u793a\u548c\u6587\u6863\u591a\u6837\u6027\u611f\u5230\u56f0\u96be\u3002", "conclusion": "CHERI\u67b6\u6784\u9700\u6539\u8fdb\u8b66\u544a\u3001\u9519\u8bef\u63d0\u793a\u548c\u6587\u6863\u4ee5\u63d0\u5347\u5f00\u53d1\u8005\u4f53\u9a8c\u3002"}}
{"id": "2506.23841", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23841", "abs": "https://arxiv.org/abs/2506.23841", "authors": ["\u00cdtalo Oliveira", "Stefano M. Nicoletti", "Gal Engelberg", "Mattia Fumagalli", "Dan Klein", "Giancarlo Guizzardi"], "title": "An ontological lens on attack trees: Toward adequacy and interoperability", "comment": null, "summary": "Attack Trees (AT) are a popular formalism for security analysis. They are\nmeant to display an attacker's goal decomposed into attack steps needed to\nachieve it and compute certain security metrics (e.g., attack cost,\nprobability, and damage). ATs offer three important services: (a) conceptual\nmodeling capabilities for representing security risk management scenarios, (b)\na qualitative assessment to find root causes and minimal conditions of\nsuccessful attacks, and (c) quantitative analyses via security metrics\ncomputation under formal semantics, such as minimal time and cost among all\nattacks. Still, the AT language presents limitations due to its lack of\nontological foundations, thus compromising associated services. Via an\nontological analysis grounded in the Common Ontology of Value and Risk (COVER)\n-- a reference core ontology based on the Unified Foundational Ontology (UFO)\n-- we investigate the ontological adequacy of AT and reveal four significant\nshortcomings: (1) ambiguous syntactical terms that can be interpreted in\nvarious ways; (2) ontological deficit concerning crucial domain-specific\nconcepts; (3) lacking modeling guidance to construct ATs decomposing a goal;\n(4) lack of semantic interoperability, resulting in ad hoc stand-alone tools.\nWe also discuss existing incremental solutions and how our analysis paves the\nway for overcoming those issues through a broader approach to risk management\nmodeling.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u653b\u51fb\u6811\uff08AT\uff09\u5728\u5b89\u5168\u5206\u6790\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u57fa\u4e8eCOVER\u672c\u4f53\u8bba\u7684\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u653b\u51fb\u6811\u5728\u5b89\u5168\u5206\u6790\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u7f3a\u4e4f\u672c\u4f53\u8bba\u57fa\u7840\uff0c\u5bfc\u81f4\u5efa\u6a21\u548c\u5206\u6790\u80fd\u529b\u53d7\u9650\u3002", "method": "\u901a\u8fc7COVER\u672c\u4f53\u8bba\u5bf9\u653b\u51fb\u6811\u8fdb\u884c\u672c\u4f53\u8bba\u5206\u6790\uff0c\u63ed\u793a\u5176\u56db\u5927\u4e0d\u8db3\u3002", "result": "\u53d1\u73b0\u653b\u51fb\u6811\u5b58\u5728\u672f\u8bed\u6a21\u7cca\u3001\u6982\u5ff5\u7f3a\u5931\u3001\u5efa\u6a21\u6307\u5bfc\u4e0d\u8db3\u548c\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\u5dee\u7b49\u95ee\u9898\u3002", "conclusion": "\u8bba\u6587\u4e3a\u6539\u8fdb\u653b\u51fb\u6811\u63d0\u4f9b\u4e86\u672c\u4f53\u8bba\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u66f4\u5e7f\u6cdb\u7684\u98ce\u9669\u7ba1\u7406\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2506.23520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23520", "abs": "https://arxiv.org/abs/2506.23520", "authors": ["Yu Zhang", "Ruijie Yu", "Jidong Tian", "Feng Zhu", "Jiapeng Liu", "Xiaokang Yang", "Yaohui Jin", "Yanyan Xu"], "title": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data", "comment": null, "summary": "With the increasing interest in robotic synthesis in the context of organic\nchemistry, the automated extraction of chemical procedures from literature is\ncritical. However, this task remains challenging due to the inherent ambiguity\nof chemical language and the high cost of human annotation required for\ndeveloping reliable computer-aided extraction protocols. Here, we present\nChemActor, a fully fine-tuned large language model (LLM), as a chemical\nexecutor to convert between unstructured experimental procedures and structured\naction sequences. We propose a sequential LLM-generated data framework to\naddress the challenges of insufficient and low-quality annotated data. This\nframework integrates a data selection module that selects data based on\ndistribution divergence, with a general-purpose LLM, to generate\nmachine-executable actions from a single molecule input. Additionally, we\nintroduce a novel multi-round LLMs circle review metric, which reflects the\nmodel's advanced understanding of chemical experimental procedures. Extensive\nexperiments on reaction-to-description (R2D) and description-to-action (D2A)\ntasks demonstrate that ChemActor, augmented by LLM-generated data, achieves\nstate-of-the-art performance, outperforming the baseline model by 10%. The code\nis available at: https://github.com/Zhanghahah/ChemActor.", "AI": {"tldr": "ChemActor\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u5316\u5b66\u6267\u884c\u5668\uff0c\u7528\u4e8e\u5c06\u975e\u7ed3\u6784\u5316\u5b9e\u9a8c\u7a0b\u5e8f\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u52a8\u4f5c\u5e8f\u5217\uff0c\u901a\u8fc7LLM\u751f\u6210\u7684\u6570\u636e\u6846\u67b6\u89e3\u51b3\u4e86\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\u548c\u8d28\u91cf\u4f4e\u7684\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b10%\u3002", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u5408\u6210\u5728\u6709\u673a\u5316\u5b66\u4e2d\u7684\u5174\u8da3\u589e\u52a0\uff0c\u4ece\u6587\u732e\u4e2d\u81ea\u52a8\u63d0\u53d6\u5316\u5b66\u7a0b\u5e8f\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5316\u5b66\u8bed\u8a00\u7684\u6a21\u7cca\u6027\u548c\u9ad8\u6807\u6ce8\u6210\u672c\u4f7f\u5176\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faChemActor\uff0c\u4e00\u4e2a\u5b8c\u5168\u5fae\u8c03\u7684LLM\uff0c\u7ed3\u5408\u6570\u636e\u9009\u62e9\u6a21\u5757\u548c\u591a\u8f6eLLM\u5faa\u73af\u8bc4\u4f30\u6307\u6807\uff0c\u751f\u6210\u673a\u5668\u53ef\u6267\u884c\u7684\u52a8\u4f5c\u5e8f\u5217\u3002", "result": "\u5728R2D\u548cD2A\u4efb\u52a1\u4e2d\uff0cChemActor\u901a\u8fc7LLM\u751f\u6210\u7684\u6570\u636e\u589e\u5f3a\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b10%\u3002", "conclusion": "ChemActor\u5c55\u793a\u4e86LLM\u5728\u5316\u5b66\u5b9e\u9a8c\u7a0b\u5e8f\u7406\u89e3\u4e2d\u7684\u5148\u8fdb\u6027\uff0c\u4e3a\u81ea\u52a8\u5316\u5316\u5b66\u5408\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.23866", "categories": ["cs.CR", "cs.CY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23866", "abs": "https://arxiv.org/abs/2506.23866", "authors": ["Jason Kayembe", "Iness Ben Guirat", "Jan Tobias M\u00fchlberg"], "title": "Exploring Privacy and Security as Drivers for Environmental Sustainability in Cloud-Based Office Solutions", "comment": "Post-proceedings paper persented at LOCO '24: 1st International\n  Workshop on Low Carbon Computing, 2024-12-03, in Glasgow, UK", "summary": "In this paper, we explore the intersection of privacy, security, and\nenvironmental sustainability in cloud-based office solutions, focusing on\nquantifying user- and network-side energy use and associated carbon emissions.\nWe hypothesise that privacy-focused services are typically more\nenergy-efficient than those funded through data collection and advertising. To\nevaluate this, we propose a framework that systematically measures\nenvironmental costs based on energy usage and network data traffic during\nwell-defined, automated usage scenarios. To test our hypothesis, we first\nanalyse how underlying architectures and business models, such as monetisation\nthrough personalised advertising, contribute to the environmental footprint of\nthese services. We then explore existing methodologies and tools for software\nenvironmental impact assessment. We apply our framework to three mainstream\nemail services selected to reflect different privacy policies, from\nad-supported tracking-intensive models to privacy-focused designs: Microsoft\nOutlook, Google Mail (Gmail), and Proton Mail. We extend this comparison to a\nself-hosted email solution, evaluated with and without end-to-end encryption.\nWe show that the self-hosted solution, even with 14% of device energy and 15%\nof emissions overheads from PGP encryption, remains the most energy-efficient,\nsaving up to 33% of emissions per session compared to Gmail. Among commercial\nproviders, Proton Mail is the most efficient, saving up to 0.1 gCO2 e per\nsession compared to Outlook, whose emissions can be further reduced by 2%\nthrough ad-blocking.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u4e91\u7684\u529e\u516c\u89e3\u51b3\u65b9\u6848\u4e2d\u9690\u79c1\u3001\u5b89\u5168\u4e0e\u73af\u5883\u53ef\u6301\u7eed\u6027\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u7528\u6237\u548c\u7f51\u7edc\u7aef\u80fd\u6e90\u4f7f\u7528\u53ca\u78b3\u6392\u653e\u7684\u6846\u67b6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u9690\u79c1\u4f18\u5148\u670d\u52a1\u66f4\u8282\u80fd\u7684\u5047\u8bbe\u3002", "motivation": "\u63a2\u8ba8\u9690\u79c1\u4f18\u5148\u670d\u52a1\u662f\u5426\u6bd4\u4f9d\u8d56\u6570\u636e\u6536\u96c6\u548c\u5e7f\u544a\u7684\u670d\u52a1\u66f4\u8282\u80fd\uff0c\u5e76\u91cf\u5316\u5176\u73af\u5883\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7cfb\u7edf\u5316\u6d4b\u91cf\u80fd\u6e90\u4f7f\u7528\u548c\u7f51\u7edc\u6570\u636e\u6d41\u91cf\u7684\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u4e09\u79cd\u4e3b\u6d41\u7535\u5b50\u90ae\u4ef6\u670d\u52a1\uff08Outlook\u3001Gmail\u3001Proton Mail\uff09\u548c\u81ea\u6258\u7ba1\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u81ea\u6258\u7ba1\u89e3\u51b3\u65b9\u6848\u6700\u8282\u80fd\uff0c\u6bd4Gmail\u8282\u770133%\u7684\u6392\u653e\uff1b\u5546\u4e1a\u670d\u52a1\u4e2dProton Mail\u6700\u8282\u80fd\uff0c\u6bd4Outlook\u8282\u77010.1 gCO2 e/\u4f1a\u8bdd\u3002", "conclusion": "\u9690\u79c1\u4f18\u5148\u8bbe\u8ba1\u5728\u73af\u5883\u53ef\u6301\u7eed\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u81ea\u6258\u7ba1\u548c\u9690\u79c1\u4f18\u5148\u670d\u52a1\u663e\u8457\u51cf\u5c11\u78b3\u6392\u653e\u3002"}}
{"id": "2506.23549", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23549", "abs": "https://arxiv.org/abs/2506.23549", "authors": ["Huai-Chih Wang", "Hsiang-Chun Chuang", "Hsi-Chun Cheng", "Dai-Jie Wu", "Shao-Hua Sun"], "title": "CooT: Learning to Coordinate In-Context with Coordination Transformers", "comment": "23 pages, 10 tables, 8 figures", "summary": "Effective coordination among artificial agents in dynamic and uncertain\nenvironments remains a significant challenge in multi-agent systems. Existing\napproaches, such as self-play and population-based methods, either generalize\npoorly to unseen partners or require extensive training. To overcome these\nlimitations, we propose Coordination Transformers (CooT), a novel in-context\ncoordination framework that uses recent interaction histories to adapt to\nunseen partners rapidly. Unlike previous approaches that primarily aim to\nincrease the diversity of training partners, CooT explicitly focuses on\nadapting to new partner behaviors by predicting actions aligned with observed\npartner interactions. Trained on interaction trajectories collected from\ndiverse pairs of agents with complementary behaviors, CooT quickly learns\neffective coordination strategies without explicit supervision or fine-tuning.\nEvaluations on the Overcooked benchmark demonstrate that CooT significantly\noutperforms baseline methods in coordination tasks involving previously unseen\npartners. Human evaluations further confirm CooT as the most effective\ncollaborative partner, while extensive ablations highlight its robustness,\nflexibility, and sensitivity to context in multi-agent scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCoordination Transformers\uff08CooT\uff09\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u4ea4\u4e92\u5386\u53f2\u5feb\u901f\u9002\u5e94\u672a\u89c1\u8fc7\u7684\u5408\u4f5c\u4f19\u4f34\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u534f\u8c03\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u52a8\u6001\u548c\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u534f\u8c03\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5bf9\u672a\u89c1\u5408\u4f5c\u4f19\u4f34\u7684\u6cdb\u5316\u80fd\u529b\u5dee\u6216\u8bad\u7ec3\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4e0a\u4e0b\u6587\u534f\u8c03\u7684\u6846\u67b6CooT\uff0c\u901a\u8fc7\u9884\u6d4b\u4e0e\u89c2\u5bdf\u5230\u7684\u5408\u4f5c\u4f19\u4f34\u884c\u4e3a\u4e00\u81f4\u7684\u52a8\u4f5c\u6765\u5feb\u901f\u9002\u5e94\u65b0\u884c\u4e3a\uff0c\u65e0\u9700\u663e\u5f0f\u76d1\u7763\u6216\u5fae\u8c03\u3002", "result": "\u5728Overcooked\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCooT\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u4eba\u7c7b\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u6700\u9ad8\u7684\u534f\u4f5c\u6548\u679c\u3002", "conclusion": "CooT\u5728\u591a\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3001\u7075\u6d3b\u6027\u548c\u5bf9\u4e0a\u4e0b\u6587\u7684\u654f\u611f\u6027\uff0c\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u534f\u8c03\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.23814", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23814", "abs": "https://arxiv.org/abs/2506.23814", "authors": ["Theo Chow", "Mario D'Onghia", "Lorenz Linhardt", "Zeliang Kan", "Daniel Arp", "Lorenzo Cavallaro", "Fabio Pierazzi"], "title": "Breaking Out from the TESSERACT: Reassessing ML-based Malware Detection under Spatio-Temporal Drift", "comment": null, "summary": "Several recent works focused on the best practices for applying machine\nlearning to cybersecurity. In the context of malware, TESSERACT highlighted the\nimpact of concept drift on detection performance and suggested temporal and\nspatial constraints to be enforced to ensure realistic time-aware evaluations,\nwhich have been adopted by the community. In this paper, we demonstrate\nstriking discrepancies in the performance of learning-based malware detection\nacross the same time frame when evaluated on two representative Android malware\ndatasets used in top-tier security conferences, both adhering to established\nsampling and evaluation guidelines. This questions our ability to understand\nhow current state-of-the-art approaches would perform in realistic scenarios.\nTo address this, we identify five novel temporal and spatial bias factors that\naffect realistic evaluations. We thoroughly evaluate the impact of these\nfactors in the Android malware domain on two representative datasets and five\nAndroid malware classifiers used or proposed in top-tier security conferences.\nFor each factor, we provide practical and actionable recommendations that the\ncommunity should integrate in their methodology for more realistic and\nreproducible settings.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u5728\u76f8\u540c\u65f6\u95f4\u6846\u67b6\u5185\uff0c\u57fa\u4e8e\u5b66\u4e60\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u6027\u80fd\u5728\u4e24\u79cd\u4ee3\u8868\u6027Android\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u96c6\u4e0a\u7684\u663e\u8457\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4e86\u4e94\u79cd\u65b0\u7684\u65f6\u7a7a\u504f\u5dee\u56e0\u7d20\u4ee5\u6539\u8fdb\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u63a2\u8ba8\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u65b9\u6cd5\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63ed\u793a\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e2d\u7684\u6f5c\u5728\u504f\u5dee\u3002", "method": "\u5728\u4e24\u79cd\u4ee3\u8868\u6027Android\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u96c6\u548c\u4e94\u79cd\u5206\u7c7b\u5668\u4e0a\uff0c\u8bc4\u4f30\u4e94\u79cd\u65b0\u7684\u65f6\u7a7a\u504f\u5dee\u56e0\u7d20\u5bf9\u68c0\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u4e86\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u9a8c\u8bc1\u4e86\u4e94\u79cd\u504f\u5dee\u56e0\u7d20\u5bf9\u8bc4\u4f30\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5b9e\u9645\u53ef\u884c\u7684\u5efa\u8bae\uff0c\u4ee5\u5e2e\u52a9\u793e\u533a\u6539\u8fdb\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4f7f\u5176\u66f4\u8d34\u8fd1\u73b0\u5b9e\u4e14\u53ef\u590d\u73b0\u3002"}}
{"id": "2506.23563", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23563", "abs": "https://arxiv.org/abs/2506.23563", "authors": ["Huanjin Yao", "Jiaxing Huang", "Yawen Qiu", "Michael K. Chen", "Wenzheng Liu", "Wei Zhang", "Wenjie Zeng", "Xikun Zhang", "Jingyi Zhang", "Yuxin Song", "Wenhao Wu", "Dacheng Tao"], "title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI", "comment": "Technical report", "summary": "Reasoning plays a crucial role in advancing Multimodal Large Language Models\n(MLLMs) toward Artificial General Intelligence. However, existing MLLM\nbenchmarks often fall short in precisely and comprehensively evaluating\nlong-chain reasoning abilities from three key aspects: (1) lack of difficulty\nand diversity, (2) susceptibility to guessability and memorization, (3)\ninadequate assessment of intermediate reasoning steps. To fill this gap, we\nintroduce MMReason, a new benchmark designed to precisely and comprehensively\nevaluate MLLM long-chain reasoning capability with diverse, open-ended,\nchallenging questions. First, we curate challenging questions requiring\nmulti-step reasoning from various fields (i.e., 6 disciplines) and multiple\ndifficulty levels (i.e., from pre-university to university, and from\nfoundational to competition tiers). Second, these questions are reformulated\ninto an open-ended format and filtered using a multi-model voting technique to\neliminate shortcut cases related to guessing and memorization, ensuring robust\nreasoning evaluations. Third, we annotate the questions with detailed\nstep-by-step solutions, and design a reference-based ternary scoring mechanism\nto reliably assess intermediate reasoning steps. With MMReason, we benchmark\npopular leading MLLMs and provide an in-depth analysis of their reasoning\ncapabilities. We hope MMReason will serve as a valuable resource for advancing\nMLLM reasoning research. Code will be available at\nhttps://github.com/HJYao00/MMReason.", "AI": {"tldr": "MMReason\u662f\u4e00\u4e2a\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u94fe\u63a8\u7406\u80fd\u529b\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u5728\u96be\u5ea6\u3001\u591a\u6837\u6027\u548c\u4e2d\u95f4\u6b65\u9aa4\u8bc4\u4f30\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709MLLM\u57fa\u51c6\u5728\u957f\u94fe\u63a8\u7406\u8bc4\u4f30\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u5305\u62ec\u7f3a\u4e4f\u96be\u5ea6\u548c\u591a\u6837\u6027\u3001\u6613\u53d7\u731c\u6d4b\u548c\u8bb0\u5fc6\u5f71\u54cd\uff0c\u4ee5\u53ca\u5bf9\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u8bc4\u4f30\u4e0d\u8db3\u3002", "method": "MMReason\u901a\u8fc7\u591a\u5b66\u79d1\u3001\u591a\u96be\u5ea6\u7684\u95ee\u9898\u5e93\uff0c\u5f00\u653e\u6027\u95ee\u9898\u683c\u5f0f\uff0c\u591a\u6a21\u578b\u6295\u7968\u8fc7\u6ee4\uff0c\u4ee5\u53ca\u57fa\u4e8e\u53c2\u8003\u7684\u4e09\u5143\u8bc4\u5206\u673a\u5236\uff0c\u5168\u9762\u8bc4\u4f30\u63a8\u7406\u80fd\u529b\u3002", "result": "MMReason\u5bf9\u4e3b\u6d41MLLM\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u6df1\u5165\u5206\u6790\u4e86\u5176\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "MMReason\u4e3aMLLM\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.23576", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23576", "abs": "https://arxiv.org/abs/2506.23576", "authors": ["Maria Carolina Cornelia Wit", "Jun Pang"], "title": "Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models", "comment": "26 pages, 1 figure", "summary": "Recent advances in large language models (LLMs) have raised concerns about\njailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper\ninvestigates the use of multi-agent LLM systems as a defence against such\nattacks. We evaluate three jailbreaking strategies, including the original\nAutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the\nAutoDefense framework, we compare single-agent setups with two- and three-agent\nconfigurations. Our results show that multi-agent systems enhance resistance to\njailbreaks, especially by reducing false negatives. However, its effectiveness\nvaries by attack type, and it introduces trade-offs such as increased false\npositives and computational overhead. These findings point to the limitations\nof current automated defences and suggest directions for improving alignment\nrobustness in future LLM systems.", "AI": {"tldr": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u53ef\u589e\u5f3a\u5bf9\u8d8a\u72f1\u653b\u51fb\u7684\u9632\u5fa1\uff0c\u4f46\u5b58\u5728\u8bef\u62a5\u548c\u8ba1\u7b97\u5f00\u9500\u7b49\u6743\u8861\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u4f5c\u4e3a\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u7684\u6709\u6548\u6027\u3002", "method": "\u6bd4\u8f83\u5355\u667a\u80fd\u4f53\u4e0e\u591a\u667a\u80fd\u4f53\u914d\u7f6e\uff0c\u8bc4\u4f30\u4e09\u79cd\u8d8a\u72f1\u7b56\u7565\uff08AutoDefense\u3001BetterDan\u3001JB\uff09\u3002", "result": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u9ad8\u9632\u5fa1\u80fd\u529b\uff0c\u51cf\u5c11\u6f0f\u62a5\uff0c\u4f46\u6548\u679c\u56e0\u653b\u51fb\u7c7b\u578b\u800c\u5f02\uff0c\u4e14\u589e\u52a0\u8bef\u62a5\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u5f53\u524d\u81ea\u52a8\u9632\u5fa1\u5b58\u5728\u5c40\u9650\uff0c\u672a\u6765\u9700\u6539\u8fdbLLM\u7cfb\u7edf\u7684\u5bf9\u9f50\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.23855", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23855", "abs": "https://arxiv.org/abs/2506.23855", "authors": ["Travis Dick", "Alessandro Epasto", "Adel Javanmard", "Josh Karlin", "Andres Munoz Medina", "Vahab Mirrokni", "Sergei Vassilvitskii", "Peilin Zhong"], "title": "Differentially Private Synthetic Data Release for Topics API Outputs", "comment": "20 pages, 8 figures", "summary": "The analysis of the privacy properties of Privacy-Preserving Ads APIs is an\narea of research that has received strong interest from academics, industry,\nand regulators. Despite this interest, the empirical study of these methods is\nhindered by the lack of publicly available data. Reliable empirical analysis of\nthe privacy properties of an API, in fact, requires access to a dataset\nconsisting of realistic API outputs; however, privacy concerns prevent the\ngeneral release of such data to the public.\n  In this work, we develop a novel methodology to construct synthetic API\noutputs that are simultaneously realistic enough to enable accurate study and\nprovide strong privacy protections. We focus on one Privacy-Preserving Ads\nAPIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a\nmethodology to generate a differentially-private dataset that closely matches\nthe re-identification risk properties of the real Topics API data. The use of\ndifferential privacy provides strong theoretical bounds on the leakage of\nprivate user information from this release.\n  Our methodology is based on first computing a large number of\ndifferentially-private statistics describing how output API traces evolve over\ntime. Then, we design a parameterized distribution over sequences of API traces\nand optimize its parameters so that they closely match the statistics obtained.\nFinally, we create the synthetic data by drawing from this distribution.\n  Our work is complemented by an open-source release of the anonymized dataset\nobtained by this methodology. We hope this will enable external researchers to\nanalyze the API in-depth and replicate prior and future work on a realistic\nlarge-scale dataset. We believe that this work will contribute to fostering\ntransparency regarding the privacy properties of Privacy-Preserving Ads APIs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u5408\u6210API\u8f93\u51fa\u7684\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u9690\u79c1\u4fdd\u62a4\u5e7f\u544aAPI\u7814\u7a76\u4e2d\u7f3a\u4e4f\u516c\u5f00\u6570\u636e\u7684\u95ee\u9898\uff0c\u5e76\u516c\u5f00\u4e86\u533f\u540d\u6570\u636e\u96c6\u3002", "motivation": "\u7531\u4e8e\u9690\u79c1\u95ee\u9898\uff0c\u516c\u5f00\u771f\u5b9e\u7684API\u8f93\u51fa\u6570\u636e\u4e0d\u53ef\u884c\uff0c\u963b\u788d\u4e86\u5bf9\u9690\u79c1\u4fdd\u62a4\u5e7f\u544aAPI\u7684\u5b9e\u8bc1\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\u7684\u65b9\u6cd5\uff0c\u751f\u6210\u4e0e\u771f\u5b9eTopics API\u6570\u636e\u91cd\u8bc6\u522b\u98ce\u9669\u7279\u6027\u76f8\u4f3c\u7684\u5408\u6210\u6570\u636e\u3002", "result": "\u751f\u6210\u4e86\u4e00\u4e2a\u533f\u540d\u5316\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u5e76\u516c\u5f00\u4e86\u6e90\u4ee3\u7801\uff0c\u4ee5\u652f\u6301\u5916\u90e8\u7814\u7a76\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u63d0\u9ad8\u9690\u79c1\u4fdd\u62a4\u5e7f\u544aAPI\u7684\u900f\u660e\u5ea6\uff0c\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2506.23626", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23626", "abs": "https://arxiv.org/abs/2506.23626", "authors": ["Ant\u00f3nio Afonso", "Iolanda Leite", "Alessandro Sestini", "Florian Fuchs", "Konrad Tollmar", "Linus Gissl\u00e9n"], "title": "Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games", "comment": "16 pages in total, 10 pages of main paper, 5 figures", "summary": "Reinforcement Learning (RL) in games has gained significant momentum in\nrecent years, enabling the creation of different agent behaviors that can\ntransform a player's gaming experience. However, deploying RL agents in\nproduction environments presents two key challenges: (1) designing an effective\nreward function typically requires an RL expert, and (2) when a game's content\nor mechanics are modified, previously tuned reward weights may no longer be\noptimal. Towards the latter challenge, we propose an automated approach for\niteratively fine-tuning an RL agent's reward function weights, based on a\nuser-defined language based behavioral goal. A Language Model (LM) proposes\nupdated weights at each iteration based on this target behavior and a summary\nof performance statistics from prior training rounds. This closed-loop process\nallows the LM to self-correct and refine its output over time, producing\nincreasingly aligned behavior without the need for manual reward engineering.\nWe evaluate our approach in a racing task and show that it consistently\nimproves agent performance across iterations. The LM-guided agents show a\nsignificant increase in performance from $9\\%$ to $74\\%$ success rate in just\none iteration. We compare our LM-guided tuning against a human expert's manual\nweight design in the racing task: by the final iteration, the LM-tuned agent\nachieved an $80\\%$ success rate, and completed laps in an average of $855$ time\nsteps, a competitive performance against the expert-tuned agent's peak $94\\%$\nsuccess, and $850$ time steps.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u8fed\u4ee3\u4f18\u5316\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u5956\u52b1\u51fd\u6570\u6743\u91cd\uff0c\u89e3\u51b3\u4e86\u6e38\u620f\u5185\u5bb9\u6216\u673a\u5236\u4fee\u6539\u540e\u5956\u52b1\u6743\u91cd\u4e0d\u518d\u6700\u4f18\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u6e38\u620f\u4e2d\u90e8\u7f72\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u65f6\uff0c\u8bbe\u8ba1\u6709\u6548\u7684\u5956\u52b1\u51fd\u6570\u9700\u8981\u4e13\u5bb6\uff0c\u4e14\u6e38\u620f\u5185\u5bb9\u4fee\u6539\u540e\u5956\u52b1\u6743\u91cd\u53ef\u80fd\u5931\u6548\u3002", "method": "\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u6839\u636e\u7528\u6237\u5b9a\u4e49\u7684\u884c\u4e3a\u76ee\u6807\u548c\u5386\u53f2\u6027\u80fd\u7edf\u8ba1\uff0c\u8fed\u4ee3\u66f4\u65b0\u5956\u52b1\u51fd\u6570\u6743\u91cd\u3002", "result": "\u5728\u8d5b\u8f66\u4efb\u52a1\u4e2d\uff0cLM\u5f15\u5bfc\u7684\u4ee3\u7406\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u4ece9%\u6210\u529f\u7387\u63d0\u9ad8\u523074%\uff0c\u6700\u7ec8\u8fbe\u523080%\u6210\u529f\u7387\uff0c\u63a5\u8fd1\u4e13\u5bb6\u624b\u52a8\u8c03\u6574\u768494%\u3002", "conclusion": "\u81ea\u52a8\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u66ff\u4ee3\u624b\u52a8\u5956\u52b1\u5de5\u7a0b\uff0c\u63d0\u5347\u4ee3\u7406\u6027\u80fd\u3002"}}
{"id": "2506.23673", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23673", "abs": "https://arxiv.org/abs/2506.23673", "authors": ["Jingsong Liu", "Han Li", "Chen Yang", "Michael Deutges", "Ario Sadafi", "Xin You", "Katharina Breininger", "Nassir Navab", "Peter J. Sch\u00fcffler"], "title": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift", "comment": null, "summary": "Domain shift is a critical problem for pathology AI as pathology data is\nheavily influenced by center-specific conditions. Current pathology domain\nadaptation methods focus on image patches rather than WSI, thus failing to\ncapture global WSI features required in typical clinical scenarios. In this\nwork, we address the challenges of slide-level domain shift by proposing a\nHierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD\nachieves multi-scale feature consistency and computationally efficient\nslide-level domain adaptation through two key components: (1) a hierarchical\nadaptation framework that integrates a Domain-level Alignment Solver for\nfeature alignment, a Slide-level Geometric Invariance Regularization to\npreserve the morphological structure, and a Patch-level Attention Consistency\nRegularization to maintain local critical diagnostic cues; and (2) a prototype\nselection mechanism that reduces computational overhead. We validate our method\non two slide-level tasks across five datasets, achieving a 4.1\\% AUROC\nimprovement in a Breast Cancer HER2 Grading cohort and a 3.9\\% C-index gain in\na UCEC survival prediction cohort. Our method provides a practical and reliable\nslide-level domain adaption solution for pathology institutions, minimizing\nboth computational and annotation costs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHASD\u7684\u5206\u5c42\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u75c5\u7406\u5b66AI\u4e2d\u7684\u5e7b\u706f\u7247\u7ea7\u57df\u504f\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u7279\u5f81\u4e00\u81f4\u6027\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u75c5\u7406\u5b66\u6570\u636e\u53d7\u4e2d\u5fc3\u7279\u5b9a\u6761\u4ef6\u5f71\u54cd\u4e25\u91cd\uff0c\u73b0\u6709\u65b9\u6cd5\u4ec5\u5173\u6ce8\u56fe\u50cf\u5757\u800c\u975e\u5168\u5e7b\u706f\u7247\u56fe\u50cf\uff08WSI\uff09\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4e34\u5e8a\u9700\u6c42\u3002", "method": "HASD\u6846\u67b6\u5305\u542b\u5206\u5c42\u9002\u5e94\u7ec4\u4ef6\uff08\u7279\u5f81\u5bf9\u9f50\u3001\u51e0\u4f55\u4e0d\u53d8\u6027\u6b63\u5219\u5316\u548c\u6ce8\u610f\u529b\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff09\u548c\u539f\u578b\u9009\u62e9\u673a\u5236\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u4e73\u817a\u764cHER2\u5206\u7ea7\u4efb\u52a1AUROC\u63d0\u53474.1%\uff0cUCEC\u751f\u5b58\u9884\u6d4b\u4efb\u52a1C-index\u63d0\u53473.9%\u3002", "conclusion": "HASD\u4e3a\u75c5\u7406\u5b66\u673a\u6784\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u9760\u7684\u5e7b\u706f\u7247\u7ea7\u57df\u9002\u5e94\u89e3\u51b3\u65b9\u6848\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u6807\u6ce8\u6210\u672c\u3002"}}
{"id": "2506.23909", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23909", "abs": "https://arxiv.org/abs/2506.23909", "authors": ["David B\u00e1lik", "Martin Jure\u010dek", "Mark Stamp"], "title": "RawMal-TF: Raw Malware Dataset Labeled by Type and Family", "comment": null, "summary": "This work addresses the challenge of malware classification using machine\nlearning by developing a novel dataset labeled at both the malware type and\nfamily levels. Raw binaries were collected from sources such as VirusShare, VX\nUnderground, and MalwareBazaar, and subsequently labeled with family\ninformation parsed from binary names and type-level labels integrated from\nClarAVy. The dataset includes 14 malware types and 17 malware families, and was\nprocessed using a unified feature extraction pipeline based on static analysis,\nparticularly extracting features from Portable Executable headers, to support\nadvanced classification tasks. The evaluation was focused on three key\nclassification tasks. In the binary classification of malware versus benign\nsamples, Random Forest and XGBoost achieved high accuracy on the full datasets,\nreaching 98.5% for type-based detection and 98.98% for family-based detection.\nWhen using truncated datasets of 1,000 samples to assess performance under\nlimited data conditions, both models still performed strongly, achieving 97.6%\nfor type-based detection and 98.66% for family-based detection. For interclass\nclassification, which distinguishes between malware types or families, the\nmodels reached up to 97.5% accuracy on type-level tasks and up to 93.7% on\nfamily-level tasks. In the multiclass classification setting, which assigns\nsamples to the correct type or family, SVM achieved 81.1% accuracy on type\nlabels, while Random Forest and XGBoost reached approximately 73.4% on family\nlabels. The results highlight practical trade-offs between accuracy and\ncomputational cost, and demonstrate that labeling at both the type and family\nlevels enables more fine-grained and insightful malware classification. The\nwork establishes a robust foundation for future research on advanced malware\ndetection and classification.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u5305\u542b\u7c7b\u578b\u548c\u5bb6\u65cf\u6807\u7b7e\u7684\u65b0\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528\u9759\u6001\u5206\u6790\u63d0\u53d6\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u5206\u7c7b\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u4e2d\u7684\u6807\u7b7e\u7ec6\u7c92\u5ea6\u4e0d\u8db3\u95ee\u9898\uff0c\u540c\u65f6\u652f\u6301\u7c7b\u578b\u548c\u5bb6\u65cf\u7ea7\u522b\u7684\u5206\u7c7b\u4efb\u52a1\u3002", "method": "\u4ece\u591a\u4e2a\u6765\u6e90\u6536\u96c6\u6076\u610f\u8f6f\u4ef6\u6837\u672c\uff0c\u6784\u5efa\u7edf\u4e00\u7279\u5f81\u63d0\u53d6\u7ba1\u9053\uff08\u57fa\u4e8ePE\u5934\u9759\u6001\u5206\u6790\uff09\uff0c\u5e76\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5982Random Forest\u3001XGBoost\u3001SVM\uff09\u3002", "result": "\u5728\u4e8c\u8fdb\u5236\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u51c6\u786e\u7387\u9ad8\u8fbe98.98%\uff1b\u5728\u6709\u9650\u6570\u636e\u6761\u4ef6\u4e0b\u4ecd\u8868\u73b0\u4f18\u5f02\uff0897.6%\uff09\u3002\u591a\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cSVM\u5728\u7c7b\u578b\u6807\u7b7e\u4e0a\u8fbe\u523081.1%\u51c6\u786e\u7387\u3002", "conclusion": "\u901a\u8fc7\u53cc\u7ea7\u522b\u6807\u7b7e\u548c\u9759\u6001\u5206\u6790\uff0c\u5b9e\u73b0\u4e86\u66f4\u7ec6\u7c92\u5ea6\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.23689", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.23689", "abs": "https://arxiv.org/abs/2506.23689", "authors": ["Zihao Liu", "Xinhang Sui", "Yueran Song", "Siwen Wang"], "title": "Pok\u00e9AI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red", "comment": null, "summary": "We introduce Pok\\'eAI, the first text-based, multi-agent large language model\n(LLM) framework designed to autonomously play and progress through Pok\\'emon\nRed. Our system consists of three specialized agents-Planning, Execution, and\nCritique-each with its own memory bank, role, and skill set. The Planning Agent\nfunctions as the central brain, generating tasks to progress through the game.\nThese tasks are then delegated to the Execution Agent, which carries them out\nwithin the game environment. Upon task completion, the Critique Agent evaluates\nthe outcome to determine whether the objective was successfully achieved. Once\nverification is complete, control returns to the Planning Agent, forming a\nclosed-loop decision-making system.\n  As a preliminary step, we developed a battle module within the Execution\nAgent. Our results show that the battle AI achieves an average win rate of\n80.8% across 50 wild encounters, only 6% lower than the performance of an\nexperienced human player. Furthermore, we find that a model's battle\nperformance correlates strongly with its LLM Arena score on language-related\ntasks, indicating a meaningful link between linguistic ability and strategic\nreasoning. Finally, our analysis of gameplay logs reveals that each LLM\nexhibits a unique playstyle, suggesting that individual models develop distinct\nstrategic behaviors.", "AI": {"tldr": "Pok\u00e9AI\u662f\u4e00\u4e2a\u57fa\u4e8e\u6587\u672c\u7684\u591a\u667a\u80fd\u4f53\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u4e3b\u73a9Pok\u00e9mon Red\u6e38\u620f\uff0c\u5305\u542b\u89c4\u5212\u3001\u6267\u884c\u548c\u8bc4\u4f30\u4e09\u4e2a\u667a\u80fd\u4f53\uff0c\u521d\u6b65\u6d4b\u8bd5\u663e\u793a\u5176\u6218\u6597\u6a21\u5757\u8868\u73b0\u63a5\u8fd1\u4eba\u7c7b\u73a9\u5bb6\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u81ea\u4e3b\u73a9Pok\u00e9mon Red\u6e38\u620f\u7684AI\u7cfb\u7edf\uff0c\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u5728\u7b56\u7565\u6e38\u620f\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u667a\u80fd\u4f53\uff08\u89c4\u5212\u3001\u6267\u884c\u3001\u8bc4\u4f30\uff09\u5206\u5de5\u534f\u4f5c\uff0c\u5f62\u6210\u95ed\u73af\u51b3\u7b56\u7cfb\u7edf\uff0c\u5e76\u5f00\u53d1\u4e86\u6218\u6597\u6a21\u5757\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u6218\u6597\u6a21\u5757\u572850\u6b21\u91ce\u751f\u906d\u9047\u6218\u4e2d\u5e73\u5747\u80dc\u7387\u4e3a80.8%\uff0c\u63a5\u8fd1\u4eba\u7c7b\u73a9\u5bb6\u6c34\u5e73\uff0c\u4e14\u8bed\u8a00\u80fd\u529b\u4e0e\u6218\u6597\u8868\u73b0\u76f8\u5173\u3002", "conclusion": "Pok\u00e9AI\u5c55\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u7b56\u7565\u6e38\u620f\u4e2d\u7684\u6f5c\u529b\uff0c\u4e0d\u540c\u6a21\u578b\u8868\u73b0\u51fa\u72ec\u7279\u7684\u6e38\u620f\u98ce\u683c\u3002"}}
{"id": "2506.23985", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2506.23985", "abs": "https://arxiv.org/abs/2506.23985", "authors": ["Mohamed Sami Rakha", "Adam Sorrenti", "Greg Stager", "Walid Rjaibi", "Andriy Miranskyy"], "title": "Lock Prediction for Zero-Downtime Database Encryption", "comment": null, "summary": "Modern enterprise database systems face significant challenges in balancing\ndata security and performance. Ensuring robust encryption for sensitive\ninformation is critical for systems' compliance with security standards.\nAlthough holistic database encryption provides strong protection, existing\ndatabase systems often require a complete backup and restore cycle, resulting\nin prolonged downtime and increased storage usage. This makes it difficult to\nimplement online encryption techniques in high-throughput environments without\ndisrupting critical operations.\n  To address this challenge, we envision a solution that enables online\ndatabase encryption aligned with system activity, eliminating the need for\ndowntime, storage overhead, or full-database reprocessing. Central to this\nvision is the ability to predict which parts of the database will be accessed\nnext, allowing encryption to be applied online. As a step towards this\nsolution, this study proposes a predictive approach that leverages deep\nlearning models to forecast database lock sequences, using IBM Db2 as the\ndatabase system under study. In this study, we collected a specialized dataset\nfrom TPC-C benchmark workloads, leveraging lock event logs for model training\nand evaluation. We applied deep learning architectures, such as Transformer and\nLSTM, to evaluate models for various table-level and page-level lock\npredictions. We benchmark the accuracy of the trained models versus a Naive\nBaseline across different prediction horizons and timelines.\n  The study experiments demonstrate that the proposed deep learning-based\nmodels achieve up to 49% average accuracy for table-level and 66% for\npage-level predictions, outperforming a Naive Baseline. By anticipating which\ntables and pages will be locked next, the proposed approach is a step toward\nonline encryption, offering a practical path toward secure, low-overhead\ndatabase systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u9884\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u7ebf\u6570\u636e\u5e93\u52a0\u5bc6\uff0c\u51cf\u5c11\u505c\u673a\u65f6\u95f4\u548c\u5b58\u50a8\u5f00\u9500\u3002", "motivation": "\u73b0\u4ee3\u4f01\u4e1a\u6570\u636e\u5e93\u7cfb\u7edf\u5728\u5e73\u8861\u6570\u636e\u5b89\u5168\u4e0e\u6027\u80fd\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u52a0\u5bc6\u65b9\u6cd5\u9700\u8981\u5b8c\u6574\u5907\u4efd\u548c\u6062\u590d\u5468\u671f\uff0c\u5bfc\u81f4\u505c\u673a\u65f6\u95f4\u957f\u548c\u5b58\u50a8\u5f00\u9500\u5927\u3002", "method": "\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982Transformer\u548cLSTM\uff09\u9884\u6d4b\u6570\u636e\u5e93\u9501\u5e8f\u5217\uff0c\u57fa\u4e8eIBM Db2\u548cTPC-C\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u7684\u6a21\u578b\u5728\u8868\u7ea7\u548c\u9875\u7ea7\u9501\u9884\u6d4b\u4e2d\u5206\u522b\u8fbe\u523049%\u548c66%\u7684\u5e73\u5747\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u73b0\u5728\u7ebf\u52a0\u5bc6\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u6709\u671b\u6784\u5efa\u5b89\u5168\u4e14\u4f4e\u5f00\u9500\u7684\u6570\u636e\u5e93\u7cfb\u7edf\u3002"}}
{"id": "2506.23692", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23692", "abs": "https://arxiv.org/abs/2506.23692", "authors": ["Boyuan Zheng", "Zerui Fang", "Zhe Xu", "Rui Wang", "Yiwen Chen", "Cunshi Wang", "Mengwei Qu", "Lei Lei", "Zhen Feng", "Yan Liu", "Yuyang Li", "Mingzhou Tan", "Jiaji Wu", "Jianwei Shuai", "Jia Li", "Fangfu Ye"], "title": "Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models", "comment": null, "summary": "While AI for Science (AI4S) serves as an analytical tool in the current\nresearch paradigm, it doesn't solve its core inefficiency. We propose \"Agent\nfor Science\" (Agent4S)-the use of LLM-driven agents to automate the entire\nresearch workflow-as the true Fifth Scientific Paradigm. This paper introduces\na five-level classification for Agent4S, outlining a clear roadmap from simple\ntask automation to fully autonomous, collaborative \"AI Scientists.\" This\nframework defines the next revolutionary step in scientific discovery.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\uff08Agent4S\uff09\u4f5c\u4e3a\u7b2c\u4e94\u79d1\u5b66\u8303\u5f0f\uff0c\u4ee5\u81ea\u52a8\u5316\u6574\u4e2a\u79d1\u7814\u6d41\u7a0b\uff0c\u89e3\u51b3\u5f53\u524dAI4S\u7684\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI4S\u4f5c\u4e3a\u5206\u6790\u5de5\u5177\u672a\u80fd\u89e3\u51b3\u79d1\u7814\u6548\u7387\u4f4e\u4e0b\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e94\u7ea7\u5206\u7c7b\u6846\u67b6\uff0c\u4ece\u7b80\u5355\u4efb\u52a1\u81ea\u52a8\u5316\u5230\u5b8c\u5168\u81ea\u4e3b\u534f\u4f5c\u7684\u201cAI\u79d1\u5b66\u5bb6\u201d\u3002", "result": "\u4e3a\u79d1\u5b66\u53d1\u73b0\u7684\u4e0b\u4e00\u6b21\u9769\u547d\u6027\u8fdb\u6b65\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u8def\u7ebf\u56fe\u3002", "conclusion": "Agent4S\u662f\u771f\u6b63\u7684\u7b2c\u4e94\u79d1\u5b66\u8303\u5f0f\uff0c\u5c06\u5f7b\u5e95\u6539\u53d8\u79d1\u7814\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2506.24033", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.24033", "abs": "https://arxiv.org/abs/2506.24033", "authors": ["Pei Zhan", "Peng Tang", "Yangzhuo Li", "Puwen Wei", "Shanqing Guo"], "title": "Poisoning Attacks to Local Differential Privacy for Ranking Estimation", "comment": "This paper, consisting of 24 pages with 31 figures and 1 table, has\n  been accepted by ACM CCS 2025", "summary": "Local differential privacy (LDP) involves users perturbing their inputs to\nprovide plausible deniability of their data. However, this also makes LDP\nvulnerable to poisoning attacks. In this paper, we first introduce novel\npoisoning attacks for ranking estimation. These attacks are intricate, as fake\nattackers do not merely adjust the frequency of target items. Instead, they\nleverage a limited number of fake users to precisely modify frequencies,\neffectively altering item rankings to maximize gains. To tackle this challenge,\nwe introduce the concepts of attack cost and optimal attack item (set), and\npropose corresponding strategies for kRR, OUE, and OLH protocols. For kRR, we\niteratively select optimal attack items and allocate suitable fake users. For\nOUE, we iteratively determine optimal attack item sets and consider the\nincremental changes in item frequencies across different sets. Regarding OLH,\nwe develop a harmonic cost function based on the pre-image of a hash to select\nthat supporting a larger number of effective attack items. Lastly, we present\nan attack strategy based on confidence levels to quantify the probability of a\nsuccessful attack and the number of attack iterations more precisely. We\ndemonstrate the effectiveness of our attacks through theoretical and empirical\nevidence, highlighting the necessity for defenses against these attacks. The\nsource code and data have been made available at\nhttps://github.com/LDP-user/LDP-Ranking.git.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u672c\u5730\u5dee\u5206\u9690\u79c1\uff08LDP\uff09\u7684\u65b0\u578b\u6295\u6bd2\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cbe\u786e\u4fee\u6539\u9891\u7387\u6765\u5f71\u54cd\u6392\u540d\u4f30\u8ba1\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9kRR\u3001OUE\u548cOLH\u534f\u8bae\u7684\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u672c\u5730\u5dee\u5206\u9690\u79c1\uff08LDP\uff09\u867d\u7136\u4fdd\u62a4\u4e86\u7528\u6237\u6570\u636e\u7684\u9690\u79c1\uff0c\u4f46\u4e5f\u5bb9\u6613\u53d7\u5230\u6295\u6bd2\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u6392\u540d\u4f30\u8ba1\u9886\u57df\u3002\u8bba\u6587\u65e8\u5728\u63ed\u793a\u8fd9\u4e9b\u653b\u51fb\u7684\u590d\u6742\u6027\u5e76\u63d0\u51fa\u9632\u5fa1\u65b9\u6848\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u9488\u5bf9kRR\u3001OUE\u548cOLH\u534f\u8bae\u7684\u653b\u51fb\u7b56\u7565\uff0c\u5305\u62ec\u9009\u62e9\u6700\u4f18\u653b\u51fb\u9879\u3001\u5206\u914d\u865a\u5047\u7528\u6237\u3001\u8003\u8651\u9891\u7387\u53d8\u5316\u4ee5\u53ca\u57fa\u4e8e\u7f6e\u4fe1\u6c34\u5e73\u7684\u653b\u51fb\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bba\u6587\u8bc1\u660e\u4e86\u653b\u51fb\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u9632\u5fa1\u8fd9\u4e9b\u653b\u51fb\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u8bba\u6587\u63ed\u793a\u4e86LDP\u5728\u6392\u540d\u4f30\u8ba1\u4e2d\u7684\u6295\u6bd2\u653b\u51fb\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u653b\u51fb\u548c\u9632\u5fa1\u7b56\u7565\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.23703", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23703", "abs": "https://arxiv.org/abs/2506.23703", "authors": ["Lars Ullrich", "Walter Zimmer", "Ross Greer", "Knut Graichen", "Alois C. Knoll", "Mohan Trivedi"], "title": "A New Perspective On AI Safety Through Control Theory Methodologies", "comment": "Accepted to be published as part of the 2025 IEEE Open Journal of\n  Intelligent Transportation Systems (OJ-ITS)", "summary": "While artificial intelligence (AI) is advancing rapidly and mastering\nincreasingly complex problems with astonishing performance, the safety\nassurance of such systems is a major concern. Particularly in the context of\nsafety-critical, real-world cyber-physical systems, AI promises to achieve a\nnew level of autonomy but is hampered by a lack of safety assurance. While\ndata-driven control takes up recent developments in AI to improve control\nsystems, control theory in general could be leveraged to improve AI safety.\nTherefore, this article outlines a new perspective on AI safety based on an\ninterdisciplinary interpretation of the underlying data-generation process and\nthe respective abstraction by AI systems in a system theory-inspired and system\nanalysis-driven manner. In this context, the new perspective, also referred to\nas data control, aims to stimulate AI engineering to take advantage of existing\nsafety analysis and assurance in an interdisciplinary way to drive the paradigm\nof data control. Following a top-down approach, a generic foundation for safety\nanalysis and assurance is outlined at an abstract level that can be refined for\nspecific AI systems and applications and is prepared for future innovation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8de8\u5b66\u79d1\u89c6\u89d2\u7684AI\u5b89\u5168\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u4e0e\u7cfb\u7edf\u7406\u8bba\uff0c\u63a8\u52a8AI\u5de5\u7a0b\u7684\u5b89\u5168\u5206\u6790\u4e0e\u4fdd\u969c\u3002", "motivation": "AI\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u5e94\u7528\u7f3a\u4e4f\u5b89\u5168\u4fdd\u969c\uff0c\u9700\u8981\u7ed3\u5408\u63a7\u5236\u7406\u8bba\u548cAI\u6280\u672f\u63d0\u5347\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u7406\u8bba\u9a71\u52a8\u7684\u8de8\u5b66\u79d1\u65b9\u6cd5\uff0c\u63d0\u51fa\u6570\u636e\u63a7\u5236\u7684\u65b0\u89c6\u89d2\uff0c\u7ed3\u5408\u5b89\u5168\u5206\u6790\u4e0e\u4fdd\u969c\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u5b89\u5168\u5206\u6790\u4e0e\u4fdd\u969c\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u5177\u4f53AI\u7cfb\u7edf\uff0c\u5e76\u4e3a\u672a\u6765\u521b\u65b0\u505a\u51c6\u5907\u3002", "conclusion": "\u901a\u8fc7\u6570\u636e\u63a7\u5236\u7684\u8de8\u5b66\u79d1\u65b9\u6cd5\uff0c\u4e3aAI\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u65b9\u5411\u3002"}}
{"id": "2506.24056", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.24056", "abs": "https://arxiv.org/abs/2506.24056", "authors": ["Tung-Ling Li", "Hongliang Liu"], "title": "Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models", "comment": null, "summary": "We introduce logit-gap steering, a fast jailbreak framework that casts the\nrefusal-affirmation gap of RLHF-aligned language models as a single pass over\nthe vocabulary. A forward-computable score blends gap reduction with\nlightweight proxies for KL penalty and reward shift, allowing a \"sort-sum-stop\"\nsweep to complete in under a second and return a short suffix--two orders of\nmagnitude fewer model calls than beam or gradient attacks. The same suffix\ngeneralises to unseen prompts and scales from 0.5 B to 70 B checkpoints,\nlifting one-shot attack success from baseline levels to 80-100% while\npreserving topical coherence. Beyond efficiency, these suffixes expose\nsentence-boundary reward cliffs and other alignment artefacts, offering a\nlightweight probe into how safety tuning reshapes internal representations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3alogit-gap steering\u7684\u5feb\u901f\u8d8a\u72f1\u6846\u67b6\uff0c\u901a\u8fc7\u5355\u6b21\u8bcd\u6c47\u8868\u904d\u5386\u89e3\u51b3RLHF\u5bf9\u9f50\u8bed\u8a00\u6a21\u578b\u7684\u62d2\u7edd-\u786e\u8ba4\u5dee\u8ddd\u95ee\u9898\u3002", "motivation": "\u65e8\u5728\u9ad8\u6548\u89e3\u51b3RLHF\u5bf9\u9f50\u8bed\u8a00\u6a21\u578b\u7684\u62d2\u7edd-\u786e\u8ba4\u5dee\u8ddd\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u5b89\u5168\u8c03\u6574\u5bf9\u5185\u90e8\u8868\u793a\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u524d\u5411\u53ef\u8ba1\u7b97\u7684\u5206\u6570\u7ed3\u5408\u5dee\u8ddd\u51cf\u5c11\u3001KL\u60e9\u7f5a\u548c\u5956\u52b1\u504f\u79fb\u7684\u8f7b\u91cf\u7ea7\u4ee3\u7406\uff0c\u5b9e\u73b0\u5feb\u901f\u751f\u6210\u77ed\u540e\u7f00\u3002", "result": "\u8be5\u65b9\u6cd5\u57280.5B\u523070B\u7684\u6a21\u578b\u4e0a\u5747\u6709\u6548\uff0c\u5c06\u5355\u6b21\u653b\u51fb\u6210\u529f\u7387\u63d0\u5347\u81f380-100%\uff0c\u540c\u65f6\u4fdd\u6301\u4e3b\u9898\u8fde\u8d2f\u6027\u3002", "conclusion": "logit-gap steering\u4e0d\u4ec5\u9ad8\u6548\uff0c\u8fd8\u63ed\u793a\u4e86\u5956\u52b1\u8fb9\u754c\u7b49\u5bf9\u9f50\u95ee\u9898\uff0c\u4e3a\u5b89\u5168\u8c03\u6574\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u63a2\u6d4b\u5de5\u5177\u3002"}}
{"id": "2506.23706", "categories": ["cs.AI", "cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23706", "abs": "https://arxiv.org/abs/2506.23706", "authors": ["Christoph Schnabl", "Daniel Hugenroth", "Bill Marino", "Alastair R. Beresford"], "title": "Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments", "comment": "ICML 2024 Workshop TAIG", "summary": "Benchmarks are important measures to evaluate safety and compliance of AI\nmodels at scale. However, they typically do not offer verifiable results and\nlack confidentiality for model IP and benchmark datasets. We propose Attestable\nAudits, which run inside Trusted Execution Environments and enable users to\nverify interaction with a compliant AI model. Our work protects sensitive data\neven when model provider and auditor do not trust each other. This addresses\nverification challenges raised in recent AI governance frameworks. We build a\nprototype demonstrating feasibility on typical audit benchmarks against\nLlama-3.1.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAttestable Audits\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEE\uff09\u786e\u4fddAI\u6a21\u578b\u7684\u5408\u89c4\u6027\u9a8c\u8bc1\uff0c\u540c\u65f6\u4fdd\u62a4\u6a21\u578b\u548c\u6570\u636e\u9690\u79c1\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7ed3\u679c\u4e14\u7f3a\u4e4f\u5bf9\u6a21\u578b\u548c\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u7684\u95ee\u9898\u3002", "method": "\u5728\u53ef\u4fe1\u6267\u884c\u73af\u5883\u4e2d\u8fd0\u884cAttestable Audits\uff0c\u786e\u4fdd\u7528\u6237\u53ef\u9a8c\u8bc1\u4e0e\u5408\u89c4AI\u6a21\u578b\u7684\u4ea4\u4e92\u3002", "result": "\u6210\u529f\u6784\u5efa\u539f\u578b\uff0c\u5e76\u5728Llama-3.1\u4e0a\u9a8c\u8bc1\u4e86\u5178\u578b\u5ba1\u8ba1\u57fa\u51c6\u7684\u53ef\u884c\u6027\u3002", "conclusion": "Attestable Audits\u4e3aAI\u6cbb\u7406\u6846\u67b6\u4e2d\u7684\u9a8c\u8bc1\u6311\u6218\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u4fdd\u62a4\u654f\u611f\u6570\u636e\u3002"}}
{"id": "2506.23773", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2506.23773", "abs": "https://arxiv.org/abs/2506.23773", "authors": ["Stefano M. Nicoletti", "Mari\u00eblle Stoelinga"], "title": "BayesL: Towards a Logical Framework for Bayesian Networks", "comment": null, "summary": "We introduce BayesL, a novel logical framework for specifying, querying, and\nverifying the behaviour of Bayesian networks (BNs). BayesL (pronounced \"Basil\")\nis a structured language that allows for the creation of queries over BNs. It\nfacilitates versatile reasoning concerning causal and evidence-based\nrelationships, and permits comprehensive what-if scenario evaluations without\nthe need for manual modifications to the model.", "AI": {"tldr": "BayesL\u662f\u4e00\u79cd\u65b0\u7684\u903b\u8f91\u6846\u67b6\uff0c\u7528\u4e8e\u6307\u5b9a\u3001\u67e5\u8be2\u548c\u9a8c\u8bc1\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u884c\u4e3a\uff0c\u652f\u6301\u56e0\u679c\u548c\u8bc1\u636e\u5173\u7cfb\u7684\u63a8\u7406\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8d1d\u53f6\u65af\u7f51\u7edc\u4e2d\u67e5\u8be2\u548c\u9a8c\u8bc1\u884c\u4e3a\u7684\u590d\u6742\u6027\uff0c\u51cf\u5c11\u624b\u52a8\u4fee\u6539\u6a21\u578b\u7684\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u8bed\u8a00BayesL\uff0c\u652f\u6301\u521b\u5efa\u67e5\u8be2\u548c\u8fdb\u884c\u5168\u9762\u7684\u5047\u8bbe\u573a\u666f\u8bc4\u4f30\u3002", "result": "BayesL\u80fd\u591f\u7075\u6d3b\u63a8\u7406\u56e0\u679c\u5173\u7cfb\u548c\u8bc1\u636e\u5173\u7cfb\uff0c\u65e0\u9700\u624b\u52a8\u4fee\u6539\u6a21\u578b\u3002", "conclusion": "BayesL\u4e3a\u8d1d\u53f6\u65af\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u67e5\u8be2\u548c\u9a8c\u8bc1\u5de5\u5177\u3002"}}
{"id": "2506.23784", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23784", "abs": "https://arxiv.org/abs/2506.23784", "authors": ["Parosh Aziz Abdulla", "Mohamed Faouzi Atig", "Julie Cailler", "Chencheng Liang", "Philipp R\u00fcmmer"], "title": "When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)", "comment": null, "summary": "Nielsen transformation is a standard approach for solving word equations: by\nrepeatedly splitting equations and applying simplification steps, equations are\nrewritten until a solution is reached. When solving a conjunction of word\nequations in this way, the performance of the solver will depend considerably\non the order in which equations are processed. In this work, the use of Graph\nNeural Networks (GNNs) for ranking word equations before and during the solving\nprocess is explored. For this, a novel graph-based representation for word\nequations is presented, preserving global information across conjuncts,\nenabling the GNN to have a holistic view during ranking. To handle the variable\nnumber of conjuncts, three approaches to adapt a multi-classification task to\nthe problem of ranking equations are proposed. The training of the GNN is done\nwith the help of minimum unsatisfiable subsets (MUSes) of word equations. The\nexperimental results show that, compared to state-of-the-art string solvers,\nthe new framework solves more problems in benchmarks where each variable\nappears at most once in each equation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u7d22\u4e86\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u5bf9\u5355\u8bcd\u65b9\u7a0b\u8fdb\u884c\u6392\u5e8f\u4ee5\u63d0\u9ad8\u6c42\u89e3\u6548\u7387\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u8868\u793a\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u73b0\u6709\u6c42\u89e3\u5668\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5355\u8bcd\u65b9\u7a0b\u65f6\uff0c\u5904\u7406\u987a\u5e8f\u5bf9\u6c42\u89e3\u6548\u7387\u6709\u663e\u8457\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u667a\u80fd\u6392\u5e8f\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u5355\u8bcd\u65b9\u7a0b\u8868\u793a\u65b9\u6cd5\uff0c\u5229\u7528GNN\u8fdb\u884c\u6392\u5e8f\uff0c\u5e76\u91c7\u7528\u4e09\u79cd\u591a\u5206\u7c7b\u4efb\u52a1\u9002\u5e94\u7b56\u7565\u5904\u7406\u53d8\u91cf\u6570\u91cf\u7684\u53d8\u5316\u3002\u8bad\u7ec3\u65f6\u4f7f\u7528\u6700\u5c0f\u4e0d\u53ef\u6ee1\u8db3\u5b50\u96c6\uff08MUSes\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u53d8\u91cf\u5728\u6bcf\u4e2a\u65b9\u7a0b\u4e2d\u6700\u591a\u51fa\u73b0\u4e00\u6b21\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65b0\u6846\u67b6\u6bd4\u73b0\u6709\u6c42\u89e3\u5668\u89e3\u51b3\u4e86\u66f4\u591a\u95ee\u9898\u3002", "conclusion": "GNN\u6392\u5e8f\u65b9\u6cd5\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u80fd\u663e\u8457\u63d0\u5347\u5355\u8bcd\u65b9\u7a0b\u6c42\u89e3\u6548\u7387\u3002"}}
{"id": "2506.23949", "categories": ["cs.AI", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.23949", "abs": "https://arxiv.org/abs/2506.23949", "authors": ["Anthony M. Barrett", "Jessica Newman", "Brandie Nonnecke", "Nada Madkour", "Dan Hendrycks", "Evan R. Murphy", "Krystal Jackson", "Deepika Raman"], "title": "AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models", "comment": null, "summary": "Increasingly multi-purpose AI models, such as cutting-edge large language\nmodels or other 'general-purpose AI' (GPAI) models, 'foundation models,'\ngenerative AI models, and 'frontier models' (typically all referred to\nhereafter with the umbrella term 'GPAI/foundation models' except where greater\nspecificity is needed), can provide many beneficial capabilities but also risks\nof adverse events with profound consequences. This document provides\nrisk-management practices or controls for identifying, analyzing, and\nmitigating risks of GPAI/foundation models. We intend this document primarily\nfor developers of large-scale, state-of-the-art GPAI/foundation models; others\nthat can benefit from this guidance include downstream developers of end-use\napplications that build on a GPAI/foundation model. This document facilitates\nconformity with or use of leading AI risk management-related standards,\nadapting and building on the generic voluntary guidance in the NIST AI Risk\nManagement Framework and ISO/IEC 23894, with a focus on the unique issues faced\nby developers of GPAI/foundation models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u901a\u7528\u4eba\u5de5\u667a\u80fd/\u57fa\u7840\u6a21\u578b\uff08GPAI/foundation models\uff09\u7684\u98ce\u9669\u7ba1\u7406\u5b9e\u8df5\uff0c\u65e8\u5728\u5e2e\u52a9\u5f00\u53d1\u8005\u8bc6\u522b\u3001\u5206\u6790\u548c\u51cf\u8f7b\u76f8\u5173\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u591a\u7528\u9014AI\u6a21\u578b\u7684\u666e\u53ca\uff0c\u5176\u5e26\u6765\u7684\u6f5c\u5728\u98ce\u9669\u4e5f\u65e5\u76ca\u663e\u8457\uff0c\u9700\u8981\u4e13\u95e8\u7684\u98ce\u9669\u7ba1\u7406\u63aa\u65bd\u3002", "method": "\u6587\u6863\u63d0\u4f9b\u4e86\u98ce\u9669\u7ba1\u7406\u5b9e\u8df5\u6216\u63a7\u5236\u63aa\u65bd\uff0c\u5e76\u53c2\u8003\u4e86NIST AI\u98ce\u9669\u7ba1\u7406\u6846\u67b6\u548cISO/IEC 23894\u6807\u51c6\u3002", "result": "\u4e3aGPAI/foundation\u6a21\u578b\u7684\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u98ce\u9669\u7ba1\u7406\u6307\u5357\u3002", "conclusion": "\u8be5\u6587\u6863\u4e3aGPAI/foundation\u6a21\u578b\u7684\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u98ce\u9669\u7ba1\u7406\u7684\u5177\u4f53\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u51cf\u5c11\u6f5c\u5728\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2506.23793", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.23793", "abs": "https://arxiv.org/abs/2506.23793", "authors": ["Anton Andreychuk", "Konstantin Yakovlev", "Aleksandr Panov", "Alexey Skrynnik"], "title": "Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning", "comment": null, "summary": "Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot\ntrajectory planning problems, where multiple homogeneous robots simultaneously\nmove in the shared environment. While solving MAPF optimally has been proven to\nbe NP-hard, scalable, and efficient, solvers are vital for real-world\napplications like logistics, search-and-rescue, etc. To this end, decentralized\nsuboptimal MAPF solvers that leverage machine learning have come on stage.\nBuilding on the success of the recently introduced MAPF-GPT, a pure imitation\nlearning solver, we introduce MAPF-GPT-DDG. This novel approach effectively\nfine-tunes the pre-trained MAPF model using centralized expert data. Leveraging\na novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training\nwhile significantly improving performance at test time. Our experiments\ndemonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF\nsolvers, including the original MAPF-GPT, regarding solution quality across\nmany testing scenarios. Remarkably, it can work with MAPF instances involving\nup to 1 million agents in a single environment, setting a new milestone for\nscalability in MAPF domains.", "AI": {"tldr": "MAPF-GPT-DDG\u662f\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\uff08MAPF\uff09\u6c42\u89e3\u5668\uff0c\u901a\u8fc7\u96c6\u4e2d\u5f0f\u4e13\u5bb6\u6570\u636e\u548c\u65b0\u578bdelta-data\u751f\u6210\u673a\u5236\u4f18\u5316\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u89e3\u51b3\u591a\u673a\u5668\u4eba\u8f68\u8ff9\u89c4\u5212\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u7269\u6d41\u548c\u641c\u6551\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u9700\u8981\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684MAPF\u6c42\u89e3\u5668\u3002", "method": "\u5229\u7528\u9884\u8bad\u7ec3\u7684MAPF-GPT\u6a21\u578b\uff0c\u901a\u8fc7\u96c6\u4e2d\u5f0f\u4e13\u5bb6\u6570\u636e\u548cdelta-data\u751f\u6210\u673a\u5236\u8fdb\u884c\u5fae\u8c03\u3002", "result": "MAPF-GPT-DDG\u5728\u6d4b\u8bd5\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5b66\u4e60\u578b\u6c42\u89e3\u5668\uff0c\u652f\u6301\u5355\u73af\u5883\u4e2d\u591a\u8fbe100\u4e07\u667a\u80fd\u4f53\u7684\u8def\u5f84\u89c4\u5212\u3002", "conclusion": "MAPF-GPT-DDG\u4e3aMAPF\u9886\u57df\u8bbe\u5b9a\u4e86\u65b0\u7684\u53ef\u6269\u5c55\u6027\u91cc\u7a0b\u7891\uff0c\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u5728\u590d\u6742\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.23844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23844", "abs": "https://arxiv.org/abs/2506.23844", "authors": ["Hang Su", "Jun Luo", "Chang Liu", "Xiao Yang", "Yichi Zhang", "Yinpeng Dong", "Jun Zhu"], "title": "A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents", "comment": "18 pages", "summary": "Recent advances in large language models (LLMs) have catalyzed the rise of\nautonomous AI agents capable of perceiving, reasoning, and acting in dynamic,\nopen-ended environments. These large-model agents mark a paradigm shift from\nstatic inference systems to interactive, memory-augmented entities. While these\ncapabilities significantly expand the functional scope of AI, they also\nintroduce qualitatively novel security risks - such as memory poisoning, tool\nmisuse, reward hacking, and emergent misalignment - that extend beyond the\nthreat models of conventional systems or standalone LLMs. In this survey, we\nfirst examine the structural foundations and key capabilities that underpin\nincreasing levels of agent autonomy, including long-term memory retention,\nmodular tool use, recursive planning, and reflective reasoning. We then analyze\nthe corresponding security vulnerabilities across the agent stack, identifying\nfailure modes such as deferred decision hazards, irreversible tool chains, and\ndeceptive behaviors arising from internal state drift or value misalignment.\nThese risks are traced to architectural fragilities that emerge across\nperception, cognition, memory, and action modules. To address these challenges,\nwe systematically review recent defense strategies deployed at different\nautonomy layers, including input sanitization, memory lifecycle control,\nconstrained decision-making, structured tool invocation, and introspective\nreflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a\nunified cognitive framework grounded in Constrained Markov Decision Processes\n(CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation,\nand joint reward-risk optimization to enable principled, proactive safety\nacross the agent's decision-making loop.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u81ea\u4e3bAI\u4ee3\u7406\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5982\u8bb0\u5fc6\u6c61\u67d3\u548c\u5de5\u5177\u6ee5\u7528\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u98ce\u9669\u611f\u77e5\u7684\u67b6\u6784\uff08R2A2\uff09\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "motivation": "\u968f\u7740\u81ea\u4e3bAI\u4ee3\u7406\u80fd\u529b\u7684\u63d0\u5347\uff0c\u5176\u5b89\u5168\u98ce\u9669\u4e5f\u968f\u4e4b\u589e\u52a0\uff0c\u9700\u8981\u65b0\u7684\u9632\u5fa1\u7b56\u7565\u548c\u67b6\u6784\u6765\u786e\u4fdd\u5b89\u5168\u6027\u3002", "method": "\u5206\u6790\u4e86\u4ee3\u7406\u7684\u7ed3\u6784\u57fa\u7840\u548c\u5173\u952e\u80fd\u529b\uff0c\u8bc6\u522b\u4e86\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86R2A2\u67b6\u6784\uff0c\u57fa\u4e8e\u7ea6\u675f\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08CMDP\uff09\u5b9e\u73b0\u98ce\u9669\u611f\u77e5\u3002", "result": "\u63d0\u51fa\u4e86\u9488\u5bf9\u4ee3\u7406\u5b89\u5168\u6f0f\u6d1e\u7684\u9632\u5fa1\u7b56\u7565\uff0c\u5e76\u8bbe\u8ba1\u4e86R2A2\u6846\u67b6\u4ee5\u4f18\u5316\u51b3\u7b56\u8fc7\u7a0b\u7684\u5b89\u5168\u6027\u3002", "conclusion": "R2A2\u67b6\u6784\u4e3a\u81ea\u4e3bAI\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5e94\u5bf9\u65b0\u5174\u7684\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2506.23908", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23908", "abs": "https://arxiv.org/abs/2506.23908", "authors": ["Andr\u00e1s Gy\u00f6rgy", "Tor Lattimore", "Nevena Lazi\u0107", "Csaba Szepesv\u00e1ri"], "title": "Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence", "comment": null, "summary": "Sound deductive reasoning -- the ability to derive new knowledge from\nexisting facts and rules -- is an indisputably desirable aspect of general\nintelligence. Despite the major advances of AI systems in areas such as math\nand science, especially since the introduction of transformer architectures, it\nis well-documented that even the most advanced frontier systems regularly and\nconsistently falter on easily-solvable deductive reasoning tasks. Hence, these\nsystems are unfit to fulfill the dream of achieving artificial general\nintelligence capable of sound deductive reasoning. We argue that their unsound\nbehavior is a consequence of the statistical learning approach powering their\ndevelopment. To overcome this, we contend that to achieve reliable deductive\nreasoning in learning-based AI systems, researchers must fundamentally shift\nfrom optimizing for statistical performance against distributions on reasoning\nproblems and algorithmic tasks to embracing the more ambitious exact learning\nparadigm, which demands correctness on all inputs. We argue that exact learning\nis both essential and possible, and that this ambitious objective should guide\nalgorithm design.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20AI\u7cfb\u7edf\u9700\u4ece\u7edf\u8ba1\u5b66\u4e60\u8f6c\u5411\u7cbe\u786e\u5b66\u4e60\uff0c\u4ee5\u5b9e\u73b0\u53ef\u9760\u7684\u6f14\u7ece\u63a8\u7406\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u5728\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u5b9e\u73b0\u901a\u7528\u4eba\u5de5\u667a\u80fd\u3002", "method": "\u63d0\u51fa\u4ece\u7edf\u8ba1\u5b66\u4e60\u8303\u5f0f\u8f6c\u5411\u7cbe\u786e\u5b66\u4e60\u8303\u5f0f\uff0c\u8981\u6c42\u6240\u6709\u8f93\u5165\u4e0a\u7684\u6b63\u786e\u6027\u3002", "result": "\u7cbe\u786e\u5b66\u4e60\u662f\u5b9e\u73b0\u53ef\u9760\u6f14\u7ece\u63a8\u7406\u7684\u5fc5\u8981\u6761\u4ef6\u3002", "conclusion": "AI\u7814\u7a76\u5e94\u4ee5\u7cbe\u786e\u5b66\u4e60\u4e3a\u76ee\u6807\uff0c\u6307\u5bfc\u7b97\u6cd5\u8bbe\u8ba1\u3002"}}
{"id": "2506.23924", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23924", "abs": "https://arxiv.org/abs/2506.23924", "authors": ["Akshit Kumar", "Tianyi Peng", "Yuhang Wu", "Assaf Zeevi"], "title": "Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice", "comment": null, "summary": "Large language models (LLMs) have exhibited expert-level capabilities across\nvarious domains. However, their abilities to solve problems in Operations\nResearch (OR) -- the analysis and optimization of mathematical models derived\nfrom real-world problems or their verbal descriptions -- remain underexplored.\nIn this work, we take a first step toward evaluating LLMs' abilities to solve\nstochastic modeling problems, a core class of OR problems characterized by\nuncertainty and typically involving tools from probability, statistics, and\nstochastic processes. We manually procure a representative set of\ngraduate-level homework and doctoral qualification-exam problems and test LLMs'\nabilities to solve them. We further leverage SimOpt, an open-source library of\nsimulation-optimization problems and solvers, to investigate LLMs' abilities to\nmake real-world decisions under uncertainty. Our results show that, though a\nnontrivial amount of work is still needed to reliably automate the stochastic\nmodeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on\npar with human experts in both classroom and practical settings. These findings\nhighlight the potential of building AI agents that assist OR researchers and\namplify the real-world impact of OR through automation.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u89e3\u51b3\u8fd0\u7b79\u5b66\uff08OR\uff09\u4e2d\u968f\u673a\u5efa\u6a21\u95ee\u9898\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u5728\u8bfe\u5802\u548c\u5b9e\u9645\u573a\u666f\u4e2d\u8868\u73b0\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5f53\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u591a\u4e2a\u9886\u57df\u5c55\u73b0\u51fa\u4e13\u5bb6\u7ea7\u80fd\u529b\uff0c\u4f46\u5176\u5728\u8fd0\u7b79\u5b66\u4e2d\u89e3\u51b3\u968f\u673a\u5efa\u6a21\u95ee\u9898\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u624b\u52a8\u6536\u96c6\u7814\u7a76\u751f\u4f5c\u4e1a\u548c\u535a\u58eb\u8d44\u683c\u8003\u8bd5\u9898\u76ee\uff0c\u5e76\u5229\u7528\u5f00\u6e90\u5e93SimOpt\u6d4b\u8bd5LLMs\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u51b3\u7b56\u80fd\u529b\u3002", "result": "LLMs\u5728\u89e3\u51b3\u968f\u673a\u5efa\u6a21\u95ee\u9898\u65f6\u8868\u73b0\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5f53\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u5de5\u4f5c\u4ee5\u5b9e\u73b0\u53ef\u9760\u81ea\u52a8\u5316\u3002", "conclusion": "LLMs\u6709\u6f5c\u529b\u6784\u5efa\u8f85\u52a9\u8fd0\u7b79\u5b66\u7814\u7a76\u7684AI\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u63d0\u5347OR\u7684\u5b9e\u9645\u5f71\u54cd\u3002"}}
{"id": "2506.23926", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23926", "abs": "https://arxiv.org/abs/2506.23926", "authors": ["Junping Wang", "Bicheng Wang", "Yibo Xuea", "Yuan Xie"], "title": "Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system", "comment": null, "summary": "Resilience non-equilibrium measurement, the ability to maintain fundamental\nfunctionality amidst failures and errors, is crucial for scientific management\nand engineering applications of industrial chain. The problem is particularly\nchallenging when the number or types of multiple co-evolution of resilience\n(for example, randomly placed) are extremely chaos. Existing end-to-end deep\nlearning ordinarily do not generalize well to unseen full-feld reconstruction\nof spatiotemporal co-evolution structure, and predict resilience of network\ntopology, especially in multiple chaos data regimes typically seen in\nreal-world applications. To address this challenge, here we propose industrial\nbrain, a human-like autonomous cognitive decision-making and planning framework\nintegrating higher-order activity-driven neuro network and CT-OODA symbolic\nreasoning to autonomous plan resilience directly from observational data of\nglobal variable. The industrial brain not only understands and model structure\nof node activity dynamics and network co-evolution topology without simplifying\nassumptions, and reveal the underlying laws hidden behind complex networks, but\nalso enabling accurate resilience prediction, inference, and planning.\nExperimental results show that industrial brain significantly outperforms\nresilience prediction and planning methods, with an accurate improvement of up\nto 10.8\\% over GoT and OlaGPT framework and 11.03\\% over spectral dimension\nreduction. It also generalizes to unseen topologies and dynamics and maintains\nrobust performance despite observational disturbances. Our findings suggest\nthat industrial brain addresses an important gap in resilience prediction and\nplanning for industrial chain.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5de5\u4e1a\u5927\u8111\u201d\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u9636\u795e\u7ecf\u7f51\u7edc\u548c\u7b26\u53f7\u63a8\u7406\uff0c\u7528\u4e8e\u9884\u6d4b\u548c\u89c4\u5212\u5de5\u4e1a\u94fe\u7684\u5f39\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5de5\u4e1a\u94fe\u7684\u5f39\u6027\u6d4b\u91cf\u5728\u79d1\u5b66\u7ba1\u7406\u548c\u5de5\u7a0b\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u590d\u6742\u6570\u636e\u4e0b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u7ed3\u5408\u9ad8\u9636\u6d3b\u52a8\u9a71\u52a8\u795e\u7ecf\u7f51\u7edc\u548cCT-OODA\u7b26\u53f7\u63a8\u7406\uff0c\u76f4\u63a5\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u81ea\u4e3b\u89c4\u5212\u5f39\u6027\u3002", "result": "\u5de5\u4e1a\u5927\u8111\u5728\u5f39\u6027\u9884\u6d4b\u548c\u89c4\u5212\u4e0a\u663e\u8457\u4f18\u4e8eGoT\u3001OlaGPT\u548c\u8c31\u964d\u7ef4\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u5347\u8fbe10.8%\u548c11.03%\u3002", "conclusion": "\u5de5\u4e1a\u5927\u8111\u586b\u8865\u4e86\u5de5\u4e1a\u94fe\u5f39\u6027\u9884\u6d4b\u548c\u89c4\u5212\u7684\u91cd\u8981\u7a7a\u767d\uff0c\u4e14\u5bf9\u672a\u89c1\u8fc7\u7684\u62d3\u6251\u548c\u52a8\u6001\u5177\u6709\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.23992", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.23992", "abs": "https://arxiv.org/abs/2506.23992", "authors": ["Aditya Shrivastava", "Komal Gupta", "Shraddha Arora"], "title": "Harnessing AI Agents to Advance Research on Refugee Child Mental Health", "comment": "14 page , 2 image , 2 tables , accepted under 5th International\n  Conference on Innovations in Computational Intelligence and Computer Vision\n  (ICICV-2025)", "summary": "The international refugee crisis deepens, exposing millions of dis placed\nchildren to extreme psychological trauma. This research suggests a com pact,\nAI-based framework for processing unstructured refugee health data and\ndistilling knowledge on child mental health. We compare two Retrieval-Aug\nmented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to\ndetermine how well they process challenging humanitarian datasets while avoid\ning hallucination hazards. By combining cutting-edge AI methods with migration\nresearch and child psychology, this study presents a scalable strategy to\nassist policymakers, mental health practitioners, and humanitarian agencies to\nbetter assist displaced children and recognize their mental wellbeing. In\ntotal, both the models worked properly but significantly Deepseek R1 is\nsuperior to Zephyr with an accuracy of answer relevance 0.91", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u96be\u6c11\u5065\u5eb7\u6570\u636e\u5e76\u5206\u6790\u513f\u7ae5\u5fc3\u7406\u5065\u5eb7\uff0c\u6bd4\u8f83\u4e86\u4e24\u79cdRAG\u6a21\u578b\uff08Zephyr-7B-beta\u548cDeepSeek R1-7B\uff09\uff0c\u53d1\u73b0DeepSeek R1-7B\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u89e3\u51b3\u56fd\u9645\u96be\u6c11\u5371\u673a\u4e2d\u513f\u7ae5\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\uff0c\u901a\u8fc7AI\u6280\u672f\u5e2e\u52a9\u653f\u7b56\u5236\u5b9a\u8005\u548c\u4eba\u9053\u673a\u6784\u66f4\u597d\u5730\u652f\u6301\u96be\u6c11\u513f\u7ae5\u3002", "method": "\u6bd4\u8f83\u4e24\u79cdRAG\u6a21\u578b\uff08Zephyr-7B-beta\u548cDeepSeek R1-7B\uff09\u5728\u5904\u7406\u96be\u6c11\u5065\u5eb7\u6570\u636e\u65f6\u7684\u8868\u73b0\uff0c\u907f\u514d\u5e7b\u89c9\u98ce\u9669\u3002", "result": "DeepSeek R1-7B\u5728\u7b54\u6848\u76f8\u5173\u6027\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u51c6\u786e\u7387\u8fbe0.91\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u7b56\u7565\uff0c\u7ed3\u5408AI\u548c\u5fc3\u7406\u5b66\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u548c\u4eba\u9053\u673a\u6784\u63d0\u4f9b\u652f\u6301\u96be\u6c11\u513f\u7ae5\u5fc3\u7406\u5065\u5eb7\u7684\u5de5\u5177\u3002"}}
{"id": "2506.24026", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.24026", "abs": "https://arxiv.org/abs/2506.24026", "authors": ["Yongyi Wang", "Wenxin Li"], "title": "Constructing Non-Markovian Decision Process via History Aggregator", "comment": null, "summary": "In the domain of algorithmic decision-making, non-Markovian dynamics manifest\nas a significant impediment, especially for paradigms such as Reinforcement\nLearning (RL), thereby exerting far-reaching consequences on the advancement\nand effectiveness of the associated systems. Nevertheless, the existing\nbenchmarks are deficient in comprehensively assessing the capacity of decision\nalgorithms to handle non-Markovian dynamics. To address this deficiency, we\nhave devised a generalized methodology grounded in category theory. Notably, we\nestablished the category of Markov Decision Processes (MDP) and the category of\nnon-Markovian Decision Processes (NMDP), and proved the equivalence\nrelationship between them. This theoretical foundation provides a novel\nperspective for understanding and addressing non-Markovian dynamics. We further\nintroduced non-Markovianity into decision-making problem settings via the\nHistory Aggregator for State (HAS). With HAS, we can precisely control the\nstate dependency structure of decision-making problems in the time series. Our\nanalysis demonstrates the effectiveness of our method in representing a broad\nrange of non-Markovian dynamics. This approach facilitates a more rigorous and\nflexible evaluation of decision algorithms by testing them in problem settings\nwhere non-Markovian dynamics are explicitly constructed.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8303\u7574\u8bba\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u7b97\u6cd5\u51b3\u7b56\u4e2d\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u6001\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u4e86MDP\u548cNMDP\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u51b3\u7b56\u7b97\u6cd5\u5904\u7406\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u6001\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u8303\u7574\u8bba\u5efa\u7acbMDP\u548cNMDP\u7684\u7b49\u4ef7\u5173\u7cfb\uff0c\u5e76\u5f15\u5165HAS\u63a7\u5236\u72b6\u6001\u4f9d\u8d56\u7ed3\u6784\u3002", "result": "\u65b9\u6cd5\u80fd\u6709\u6548\u8868\u793a\u5e7f\u6cdb\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u6001\uff0c\u4e3a\u7b97\u6cd5\u8bc4\u4f30\u63d0\u4f9b\u66f4\u4e25\u8c28\u548c\u7075\u6d3b\u7684\u65b9\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7406\u89e3\u548c\u89e3\u51b3\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u6001\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u6539\u8fdb\u4e86\u51b3\u7b56\u7b97\u6cd5\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2506.24119", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.24119", "abs": "https://arxiv.org/abs/2506.24119", "authors": ["Bo Liu", "Leon Guertler", "Simon Yu", "Zichen Liu", "Penghui Qi", "Daniel Balcells", "Mickel Liu", "Cheston Tan", "Weiyan Shi", "Min Lin", "Wee Sun Lee", "Natasha Jaques"], "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "comment": "Work in Progress", "summary": "Recent advances in reinforcement learning have shown that language models can\ndevelop sophisticated reasoning through training on tasks with verifiable\nrewards, but these approaches depend on human-curated problem-answer pairs and\ndomain-specific reward engineering. We introduce SPIRAL, a self-play framework\nwhere models learn by playing multi-turn, zero-sum games against continuously\nimproving versions of themselves, eliminating the need for human supervision.\nThrough self-play, SPIRAL generates an infinite curriculum of progressively\nchallenging problems as models must constantly adapt to stronger opponents. To\nenable this self-play training at scale, We implement a fully online,\nmulti-turn, multi-agent reinforcement learning system for LLMs and propose\nrole-conditioned advantage estimation (RAE) to stabilize multi-agent training.\nUsing SPIRAL, self-play on zero-sum games produces reasoning capabilities that\ntransfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%\nimprovement on math and 8.4% on general reasoning, outperforming SFT on 25,000\nexpert game trajectories. Analysis reveals that this transfer occurs through\nthree cognitive patterns: systematic decomposition, expected value calculation,\nand case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple\nNegotiation) further enhances performance as each game develops distinct\nreasoning strengths. Applying SPIRAL to a strong reasoning model\n(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These\nresults demonstrate that zero-sum games naturally develop transferable\nreasoning capabilities, highlighting a promising direction for autonomous\nreasoning development.", "AI": {"tldr": "SPIRAL\u662f\u4e00\u4e2a\u81ea\u535a\u5f08\u6846\u67b6\uff0c\u901a\u8fc7\u96f6\u548c\u6e38\u620f\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\uff0c\u751f\u6210\u65e0\u9650\u6311\u6218\u6027\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u548c\u9886\u57df\u7279\u5b9a\u5956\u52b1\u5de5\u7a0b\uff0cSPIRAL\u65e8\u5728\u901a\u8fc7\u81ea\u535a\u5f08\u6d88\u9664\u8fd9\u4e9b\u9650\u5236\uff0c\u5b9e\u73b0\u81ea\u4e3b\u63a8\u7406\u80fd\u529b\u5f00\u53d1\u3002", "method": "SPIRAL\u91c7\u7528\u5728\u7ebf\u591a\u8f6e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\uff0c\u63d0\u51fa\u89d2\u8272\u6761\u4ef6\u4f18\u52bf\u4f30\u8ba1\uff08RAE\uff09\u7a33\u5b9a\u8bad\u7ec3\uff0c\u901a\u8fc7\u96f6\u548c\u6e38\u620f\u81ea\u535a\u5f08\u751f\u6210\u6311\u6218\u6027\u95ee\u9898\u3002", "result": "\u5728Kuhn Poker\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6570\u5b66\u548c\u901a\u7528\u63a8\u7406\u4efb\u52a1\u4e0a\u5206\u522b\u63d0\u53478.6%\u548c8.4%\uff0c\u591a\u6e38\u620f\u8bad\u7ec3\u8fdb\u4e00\u6b65\u5f3a\u5316\u6027\u80fd\u3002", "conclusion": "\u96f6\u548c\u6e38\u620f\u80fd\u81ea\u7136\u5f00\u53d1\u53ef\u8fc1\u79fb\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u81ea\u4e3b\u63a8\u7406\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
