<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 22]
- [cs.CR](#cs.CR) [Total: 18]
- [cs.AI](#cs.AI) [Total: 52]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Blueprint First, Model Second: A Framework for Deterministic LLM Workflow](https://arxiv.org/abs/2508.02721)
*Libin Qiu,Yuhang Ye,Zhirong Gao,Xide Zou,Junfu Chen,Ziming Gui,Weizhi Huang,Xiaobo Xue,Wenkai Qiu,Kun Zhao*

Main category: cs.SE

TL;DR: 论文提出了一种名为Source Code Agent的新框架，通过将工作流逻辑与生成模型解耦，解决了LLM代理在结构化操作环境中的非确定性问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理的非确定性限制了其在需要严格程序保真度和可预测执行的结构化环境中的应用。

Method: 采用“蓝图优先，模型其次”的方法，将专家定义的操作程序编码为基于源代码的执行蓝图，并由确定性引擎执行，LLM仅用于处理有限复杂子任务。

Result: 在tau-bench基准测试中，Source Code Agent表现优异，平均Pass^1得分比最强基线高出10.1个百分点，显著提高了执行效率。

Conclusion: 该框架为严格程序逻辑下的自主代理部署提供了可验证和可靠的解决方案。

Abstract: While powerful, the inherent non-determinism of large language model (LLM)
agents limits their application in structured operational environments where
procedural fidelity and predictable execution are strict requirements. This
limitation stems from current architectures that conflate probabilistic,
high-level planning with low-level action execution within a single generative
process. To address this, we introduce the Source Code Agent framework, a new
paradigm built on the "Blueprint First, Model Second" philosophy. Our framework
decouples the workflow logic from the generative model. An expert-defined
operational procedure is first codified into a source code-based Execution
Blueprint, which is then executed by a deterministic engine. The LLM is
strategically invoked as a specialized tool to handle bounded, complex
sub-tasks within the workflow, but never to decide the workflow's path. We
conduct a comprehensive evaluation on the challenging tau-bench benchmark,
designed for complex user-tool-rule scenarios. Our results demonstrate that the
Source Code Agent establishes a new state-of-the-art, outperforming the
strongest baseline by 10.1 percentage points on the average Pass^1 score while
dramatically improving execution efficiency. Our work enables the verifiable
and reliable deployment of autonomous agents in applications governed by strict
procedural logic.

</details>


### [2] [Interpreting Performance Profiles with Deep Learning](https://arxiv.org/abs/2508.02729)
*Zhuoran Liu*

Main category: cs.SE

TL;DR: 该论文提出了一种结合性能分析和程序语义的新方法，通过深度学习技术（如CodeBERT）生成代码摘要，帮助用户更直观地理解程序性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有的性能分析工具（如Async Profiler）虽然有用，但用户（尤其是非代码作者）难以将性能数据与程序语义关联，限制了工具的适用性。

Method: 结合Async Profiler生成的性能数据与基于CodeBERT的代码摘要模型，通过图形界面展示调用路径的代码摘要。

Result: 系统在多个Java基准测试中有效辅助了性能分析。

Conclusion: 通过整合性能分析和程序语义，该方法显著提升了性能分析工具的实用性和用户友好性。

Abstract: Profiling tools (also known as profilers) play an important role in
understanding program performance at runtime, such as hotspots, bottlenecks,
and inefficiencies. While profilers have been proven to be useful, they give
extra burden to software engineers. Software engineers, as the users, are
responsible to interpret the complex performance data and identify actionable
optimization in program source code. However, it can be challenging for users
to associate inefficiencies with the program semantics, especially if the users
are not the authors of the code, which limits the applicability of profilers.
  In this thesis, we explore a new direction to combine performance profiles
and program semantics with a deep learning approach. The key idea is to glean
code summary for semantic information (at a certain level) and integrate it
into a profiler, which can better understand program inefficiencies for
actionable optimization. To be concrete, we combine profiles generated by Async
Profiler (the state-of-the-art Java profiler) with code summarization from a
fine-tuned CodeBERT-based model. We demonstrate the code summaries of any
selected call path in a graphic user interface. Our system can effectively
assist analysis on many Java benchmarks.

</details>


### [3] [A Note on Code Quality Score: LLMs for Maintainable Large Codebases](https://arxiv.org/abs/2508.02732)
*Sherman Wong,Jalaj Bhandari,Leo Zhou Fan Yang,Xylan Xu,Yi Zhuang,Cem Cayiroglu,Payal Bhuptani,Sheela Yadawad,Hung Duong*

Main category: cs.SE

TL;DR: 论文介绍了Code Quality Score (CQS)系统，通过两个微调的Llama3模型自动检测代码质量问题并提供改进建议，已在工业环境中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大规模软件系统中维护代码质量具有挑战性，尤其是在多人协作开发时。

Method: CQS系统结合了两个微调的Llama3模型（使用SFT和离线RL方法），分别用于检测代码质量问题和提供代码审查建议，并辅以手工规则过滤错误响应。

Result: 离线评估显示CQS系统在识别有效问题方面具有高精度，实际应用中用户满意度达60%。

Conclusion: CQS系统在工业环境中有效，同时提供了关于如何利用开发者反馈优化LLM微调的经验。

Abstract: Maintaining code quality in large-scale software systems presents significant
challenges, particularly in settings where a large numbers of engineers work
concurrently on a codebase. This paper introduces Code Quality Score (CQS)
system to automatically detect issues with a set of code changes and provide
actionable insights. At its core, the CQS system is powered by two Llama3
models, fine-tuned (with SFT and offline RL approaches), to a) detect common
code quality issues related to coding best practices and b) to provide good
``critiques'' for LLM-generated code review respectively. To maintain good user
experience, we layer the system with hand-crafted rules to filter out incorrect
responses/hallucinations. Offline evaluations show that our CQS system is able
to achieve an impressive precision rate for identifying valid issues. This
system has already been rolled out to developers in an industrial scale setting
and has consistently achieved 60\% week over week user helpfulness rate,
demonstrating its effectiveness in a real-world environment. In this paper, we
present details of the CQS system along with some learnings on curating
developer feedback to create training data for LLM fine-tuning.

</details>


### [4] [What's in a Proof? Analyzing Expert Proof-Writing Processes in F* and Verus](https://arxiv.org/abs/2508.02733)
*Rijul Jain,Shraddha Barke,Gabriel Ebner,Md Rakib Hossain Misu,Shan Lu,Sarah Fakhoury*

Main category: cs.SE

TL;DR: 研究通过用户实验分析专家使用POPLs（如F*和Verus）的行为模式，发现三种策略和未记录的实践，提出AI证明助手的改进建议，并验证其效果。


<details>
  <summary>Details</summary>
Motivation: POPLs虽强大但学习曲线陡峭，缺乏对专家使用行为的理解，阻碍了证明工程和工具的发展。

Method: 收集并分析八位专家使用F*和Verus的细粒度源代码遥测数据。

Result: 发现三种策略和未记录的实践，提出AI证明助手的设计建议，并通过案例验证改进效果。

Conclusion: 研究为AI证明助手提供了实用设计指导，并展示了其潜在优势。

Abstract: Proof-oriented programming languages (POPLs) empower developers to write code
alongside formal correctness proofs, providing formal guarantees that the code
adheres to specified requirements. Despite their powerful capabilities, POPLs
present a steep learning curve and have not yet been adopted by the broader
software community. The lack of understanding about the proof-development
process and how expert proof developers interact with POPLs has hindered the
advancement of effective proof engineering and the development of
proof-synthesis models/tools.
  In this work, we conduct a user study, involving the collection and analysis
of fine-grained source code telemetry from eight experts working with two
languages, F* and Verus. Results reveal interesting trends and patterns about
how experts reason about proofs and key challenges encountered during the proof
development process. We identify three distinct strategies and multiple
informal practices that are not captured final code snapshots, yet are
predictive of task outcomes. We translate these findings into concrete design
guidance for AI proof assistants: bias toward early specification drafting,
explicit sub-goal decomposition, bounded active errors, and disciplined
verifier interaction. We also present a case study of an F* proof agent
grounded in these recommendations, and demonstrate improved performance over
baseline LLMs

</details>


### [5] [Automated Code Repair for C/C++ Static Analysis Alerts](https://arxiv.org/abs/2508.02820)
*David Svoboda,Lori Flynn,William Klieber,Michael Duggan,Nicholas Reimer,Joseph Sible*

Main category: cs.SE

TL;DR: 该论文探讨了如何利用自动化程序修复（APR）工具减少静态分析（SA）工具产生的误报警报，并通过实际工程经验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 静态分析工具在C/C++代码中产生大量诊断警报，其中许多是误报。手动识别和修复这些警报耗时耗力，因此需要自动化工具来辅助。

Method: 设计、开发和性能测试了一个APR工具，用于修复由多个SA工具产生的三类警报。修复方法简单且局部化。

Result: APR工具成功修复了9234个警报中的8718个，并在两个代码库中对两类缺陷的警报修复或排除了80%以上。修复未显著影响代码性能或引发新警报。

Conclusion: APR工具显著减少了SA警报数量，提升了开发效率，并为CERT编码标准的评估提供了新依据。论文还分享了工程设计和数据集等贡献。

Abstract: (Note: This work is a preprint.) Static analysis (SA) tools produce many
diagnostic alerts indicating that source code in C or C++ may be defective and
potentially vulnerable to security exploits. Many of these alerts are false
positives. Identifying the true-positive alerts and repairing the defects in
the associated code are huge efforts that automated program repair (APR) tools
can help with. Our experience showed us that APR can reduce the number of SA
alerts significantly and reduce the manual effort of analysts to review code.
This engineering experience paper details the application of design,
development, and performance testing to an APR tool we built that repairs C/C++
code associated with 3 categories of alerts produced by multiple SA tools. Its
repairs are simple and local. Furthermore, our findings convinced the
maintainers of the CERT Coding Standards to re-assess and update the metrics
used to assess when violations of guidelines are detectable or repairable. We
discuss engineering design choices made to support goals of trustworthiness and
acceptability to developers. Our APR tool repaired 8718 out of 9234 alerts
produced by one SA tool on one codebase. It can repair 3 flaw categories. For 2
flaw categories, 2 SA tools, and 2 codebases, our tool repaired or dismissed as
false positives over 80% of alerts, on average. Tests showed repairs did not
appreciably degrade the performance of the code or cause new alerts to appear
(with the possible exception of sqlite3.c). This paper describes unique
contributions that include a new empirical analysis of SA data, our selection
method for flaw categories to repair, publication of our APR tool, and a
dataset of SA alerts from open-source SA tools run on open-source codebases. It
discusses positive and negative results and lessons learned.

</details>


### [6] [Automated Validation of LLM-based Evaluators for Software Engineering Artifacts](https://arxiv.org/abs/2508.02827)
*Ora Nova Fandina,Eitan Farchi,Shmulik Froimovich,Rami Katan,Alice Podolsky,Orna Raz,Avi Ziv*

Main category: cs.SE

TL;DR: REFINE是一个自动化框架，用于评估基于LLM的代码评估器，通过生成逐步降低质量的代码样本和量化评估器配置的排名一致性，提升评估的精细度。


<details>
  <summary>Details</summary>
Motivation: 现有自动化方法无法捕捉代码质量的细微差异，而人工评估成本高且不可扩展，因此需要一种可靠且可扩展的LLM评估方法。

Method: REFINE包含两个模块：Hierarchy Dataset Builder生成质量逐步降低的代码样本，Evaluator Tester量化评估器配置的排名一致性。

Result: REFINE在IBM内部开发流程中应用，显著提升了评估器配置的评分（从0.7以下提升至0.9以上）。

Conclusion: REFINE通过可控的精细化评估方法，为LLM评估器的可靠性提供了有效解决方案，并已实际应用于模型训练决策。

Abstract: Automation in software engineering increasingly relies on large language
models (LLMs) to generate, review, and assess code artifacts. However,
establishing LLMs as reliable evaluators remains an open challenge: human
evaluations are costly, subjective and non scalable, while existing automated
methods fail to discern fine grained variations in artifact quality.
  We introduce REFINE (Ranking Evaluators for FIne grained Nuanced Evaluation),
an automated framework for benchmarking LLM based evaluators across software
engineering tasks. REFINE comprises of two modules: Hierarchy Dataset Builder
applies novel generation techniques to automatically synthesize artifacts with
progressively reduced quality, and Evaluator Tester quantifies each candidate
evaluator configuration by measuring how closely its rankings align with
expected ordering.
  A key feature of REFINE is controllability: users can tune the granularity of
degradation to progressively refine evaluator configurations, from coarse
filtering to stress testing on subtle quality gaps.
  While the methodology is general, we focus on coding tasks reflecting the
practical demands in our production setting. REFINE was integrated into IBM's
internal development workflows and applied to code generation, translation, and
summarization for COBOL, an enterprise critical programming language, using
industrial data. It was used to identify LLM as a Judge configurations that
lifted alignment scores from below $0.7$ to above $0.9$ in some coding tasks.
These nuance sensitive evaluators are now actively used by model training teams
to support model release decisions.

</details>


### [7] [Developer Perceptions on Utilising Low-Code Approaches to Build Accessible and Adaptive Applications for Seniors](https://arxiv.org/abs/2508.02968)
*Shavindra Wickramathilaka,John Grundy,Kashumi Madampe,Omar Haggag*

Main category: cs.SE

TL;DR: 论文提出了一种低代码工具AdaptForge，用于高效开发面向老年用户的易访问和自适应应用，并通过访谈研究验证其效果。


<details>
  <summary>Details</summary>
Motivation: 全球老龄化问题加剧，亟需支持老年人自主性的技术。传统开发方式受限于时间和资源，难以满足易访问性和个性化需求。

Method: 通过访谈18名软件从业者，评估低代码模型驱动工程工具AdaptForge的实用性和效果。

Result: 研究揭示了开发者对类似工具的期望，并提供了设计低代码工具的建议。

Conclusion: AdaptForge能有效缓解开发限制，支持易访问和自适应软件的开发，未来有望成为行业标准。

Abstract: The global ageing population presents a growing societal challenge, creating
an urgent need for inclusive technologies that promote autonomy among older
adults. Software practitioners can address this by delivering digital services
that enhance seniors' independence and reduce reliance on routine support from
family members and healthcare infrastructure. However, traditional development
practices, constrained by time and resources, often result in applications with
major accessibility and personalisation barriers. Increasing pressure from
regulatory requirements, such as the European Accessibility Act (EAA), and the
personal empathy many developers feel toward supporting their older loved ones
and their own future selves have created a demand for tools that support the
development of accessible and adaptive software. To address this demand, this
paper presents an interview-based empirical study with 18 software
practitioners, evaluating AdaptForge: a low-code model-driven engineering (MDE)
tool that enables the efficient creation of accessible and adaptive
applications for senior users by mitigating development constraints through
automated code generation. Based on these insights, we identify developer
expectations for adopting such tools as industry-standard solutions and provide
empirically grounded recommendations for designing low-code tools that support
accessible and adaptive software development.

</details>


### [8] [MRG-Bench: Evaluating and Exploring the Requirements of Context for Repository-Level Code Generation](https://arxiv.org/abs/2508.02998)
*Haiyang Li*

Main category: cs.SE

TL;DR: MRG-Bench是一个新的多语言代码生成基准数据集，解决了现有评估数据集的局限性，并通过实验揭示了当前仓库级代码生成技术的性能不足和主要错误原因。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成评估数据集存在缺乏可运行测试用例、偏离真实代码分布和仅支持Python等问题，影响了评估结果的可信度。

Method: 引入MRG-Bench数据集，包含真实代码库数据、多语言支持和项目级可运行测试用例，并基于此进行广泛的实验和错误原因分析。

Result: 实验表明当前仓库级代码生成技术性能不足，主要错误原因是模型难以准确理解用户需求，且不同语言的上下文影响差异显著。

Conclusion: 需要为不同语言设计专门的上下文信息，以提升仓库级代码生成的性能。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
code generation. However, current evaluation datasets suffer from issues such
as the lack of runnable test cases, deviation from the distribution of
real-world code, and the ability to evaluate only the Python language. These
limitations undermine the credibility of the evaluation results.
  To address these limitations, we introduce \textbf{MRG-Bench} (Multi-language
Repository-level Code Generation Benchmark), a novel dataset that provides a
more accurate evaluation of LLMs in practical repository-level code generation
tasks. MRG-Bench has three main features: (1) practical data sourced from
real-world code repositories that align to the practical distribution, (2)
multiple programming languages support, including Python, Java, and Go, and (3)
project-level runnable test cases to assess the quality of the generated code.
  Based on MRG-Bench, we conducted extensive experiments including large
language models, long-context models, and RAG-related methods. These evaluation
results demonstrate that \textbf{current repository-level code generation
techniques suffer from significant performance deficiencies}. To further
investigate why models fail, we designed novel experiments to annotate the
underlying causes of generation errors. The results explicitly show that the
majority of methods suffer from "\textbf{difficulty in understanding user
requirements}," failing to comprehend their assigned tasks accurately.
Moreover, the impact of different repository-level contexts on this issue
exhibits significant disparities across different programming languages,
suggesting that, in practice, specialized contextual information needs to be
designed for different languages.

</details>


### [9] [Tool-integrated Reinforcement Learning for Repo Deep Search](https://arxiv.org/abs/2508.03012)
*Zexiong Ma,Chao Peng,Qunhong Zeng,Pengfei Gao,Yanzhen Zou,Bing Xie*

Main category: cs.SE

TL;DR: ToolTrain是一个两阶段的工具集成训练框架，通过结合拒绝采样的监督微调和工具集成的强化学习，提升LLM在问题定位中使用检索工具的能力，实验结果显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决软件问题定位中的语义鸿沟和多跳推理挑战，现有LLM代理方法效率不足。

Method: 提出ToolTrain框架，结合拒绝采样的监督微调和工具集成的强化学习。

Result: ToolTrain训练的模型在问题定位上达到SOTA性能，32B模型甚至超越Claude-3.7。

Conclusion: 训练问题定位能力是提升自动化软件开发的有效策略。

Abstract: Issue localization, the process of identifying code locations that need
modification to resolve software issues, is a critical yet challenging task in
software development. The semantic gap between natural language issue
descriptions and faulty code requires complex multi-hop reasoning through code
dependencies. Existing LLM-based agents attempt to address this by integrating
repository retrieval tools. However, this transforms issue localization into a
demanding task we call Repo Deep Search, which requires the LLM to effectively
utilize various repository retrieval tools throughout a multi-step reasoning
and navigation process. To tackle this challenge, we present ToolTrain, a
two-stage tool-integrated training framework combining rejection-sampled
supervised fine-tuning and tool-integrated reinforcement learning to enhance
LLMs' ability to use retrieval tools for issue localization. Experimental
results show that ToolTrain-trained models achieve state-of-the-art
performance, with our 32B model even surpassing Claude-3.7 on function-level
localization. The results also show that improved localization performance
translates to better end-to-end issue resolution performance. This further
demonstrates that training for issue localization is a viable and effective
strategy for improving automated software development.

</details>


### [10] [A System Model Generation Benchmark from Natural Language Requirements](https://arxiv.org/abs/2508.03215)
*Dongming Jin,Zhi Jin,Linyu Li,Zheng Fang,Jia Li,Xiaohong Chen*

Main category: cs.SE

TL;DR: SysMBench是一个包含151个场景的基准测试，用于评估大型语言模型（LLM）生成系统模型的能力，结果显示LLM表现不佳。


<details>
  <summary>Details</summary>
Motivation: 由于系统模型开发的挑战性（如特定语法和公开示例稀缺），研究LLM在此领域的潜力，但缺乏相关基准。

Method: 提出SysMBench基准和SysMEval评估指标，测试17种LLM在生成系统模型时的表现。

Result: LLM表现较差，最高BLEU得分为4%，SysMEval-F1为62%。

Conclusion: LLM在系统模型生成任务中表现不佳，SysMBench为未来研究提供了工具。

Abstract: System models, a critical artifact in software development, provide a formal
abstraction of both the structural and behavioral aspects of software systems,
which can facilitate the early requirements analysis and architecture design.
However, developing system models remains challenging due to the specific
syntax of model description languages and the relative scarcity of public model
examples. While large language models (LLMs) have shown promise in generating
code with programming languages and could potentially aid in system model
development, no benchmarks currently exist for evaluating their ability to
generate system models with specific description languages. We present
SysMBench, which comprises 151 human-curated scenarios spanning a wide range of
popular domains and varying difficulty levels. Each scenario mainly comprises a
natural language requirements description, a system model expressed in a
specific model description language, and a visualized system model diagram. The
requirements description is fed as user input to the LLM, the system model with
description language is used to verify if the generated system model conforms
to the requirements, and the visualized diagram serves to support manual
validation. We introduce SysMEval, a semantic-aware evaluation metric to
evaluate the quality of generated system models. We evaluate 17 popular LLMs on
this task with three traditional metrics and SysMEval, from directly prompting
to three commonly used enhancement strategies. Our in-depth evaluation shows
that LLMs perform poorly on SysMBench, with the highest BLEU of 4% and
SysMEval-F1 of 62%. We release the SysMBench and its evaluation framework to
enable future research on LLM-based system model generation.

</details>


### [11] [SmartLLMs Scheduler: A Framework for Cost-Effective LLMs Utilization](https://arxiv.org/abs/2508.03258)
*Yueyue Liu,Hongyu Zhang,Yuantian Miao*

Main category: cs.SE

TL;DR: 论文提出了一种动态调度解决方案SmartLLMs Scheduler (SLS)，通过实时反馈优化LLM任务分配，显著提升性能和响应速度。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在软件工程任务中表现出色，但其实际部署面临高成本、长响应时间和性能波动等挑战，现有静态调度方法依赖大量训练数据且灵活性不足。

Method: SLS包含三个核心组件：自适应缓存管理器、性能-成本优化调度器和动态更新管理器，通过实时反馈动态调整策略。

Result: 实验表明，SLS在日志解析和代码生成任务中平均性能提升198.82%，处理时间减少63.28%。

Conclusion: SLS是一种高效、动态的LLM调度方案，显著提升了任务处理效率和性能。

Abstract: Large Language Models (LLMs) such as GPT-4 and Llama have shown remarkable
capabilities in a variety of software engineering tasks. Despite the
advancements, their practical deployment faces challenges, including high
financial costs, long response time, and varying performance, especially when
handling a large number of queries (jobs). Existing optimization strategies for
deploying LLMs for diverse tasks focus on static scheduling, which requires
extensive training data for performance prediction, increasing the
computational costs and limiting the applicability and flexibility. In this
paper, we propose the SmartLLMs Scheduler (SLS), a dynamic and cost-effective
scheduling solution. The key idea is to learn LLMs' performance on diverse
tasks and incorporate their real-time feedback to update strategies
periodically. Specifically, SLS incorporates three key components, including an
Adaptive Cache Manager, a Performance-Cost Optimized Scheduler, and a Dynamic
Update Manager. The Cache Manager stores the outputs of previously processed
queries and employs an adaptive strategy to reduce redundant computations and
minimize response times. For queries not found in the cache, the Scheduler
dynamically allocates them to the most suitable LLM based on the predicted
performance and cost from models that take both query-specific and LLM-specific
features as input. The Update Manager continuously refines the cache and
scheduling strategies based on real-time feedback from the assigned queries to
enhance decision-making and adapt to evolving task characteristics. To evaluate
the effectiveness of SLS, we conduct extensive experiments on two LLM-based
software engineering tasks, including log parsing and code generation. The
results show that SLS significantly outperforms the baseline methods, achieving
an average performance improvement of 198.82% and an average processing time
reduction of 63.28%.

</details>


### [12] [GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-based Reranking](https://arxiv.org/abs/2508.03298)
*Kristian Kolthoff,Felix Kretzer,Christian Bartelt,Alexander Maedche,Simone Paolo Ponzetto*

Main category: cs.SE

TL;DR: GUI-ReRank框架结合嵌入检索与MLLM重排技术，显著提升GUI检索性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有NL-based GUI检索方法性能有限且难以泛化的问题。

Method: 集成快速嵌入检索与MLLM重排技术，并提供可定制化的GUI库标注流程。

Result: 在基准测试中显著优于现有LTR模型，且成本效率分析提供了实用权衡建议。

Conclusion: GUI-ReRank为GUI检索提供了高效、通用的解决方案，并支持定制化需求。

Abstract: GUI prototyping is a fundamental component in the development of modern
interactive systems, which are now ubiquitous across diverse application
domains. GUI prototypes play a critical role in requirements elicitation by
enabling stakeholders to visualize, assess, and refine system concepts
collaboratively. Moreover, prototypes serve as effective tools for early
testing, iterative evaluation, and validation of design ideas with both end
users and development teams. Despite these advantages, the process of
constructing GUI prototypes remains resource-intensive and time-consuming,
frequently demanding substantial effort and expertise. Recent research has
sought to alleviate this burden through NL-based GUI retrieval approaches,
which typically rely on embedding-based retrieval or tailored ranking models
for specific GUI repositories. However, these methods often suffer from limited
retrieval performance and struggle to generalize across arbitrary GUI datasets.
In this work, we present GUI-ReRank, a novel framework that integrates rapid
embedding-based constrained retrieval models with highly effective MLLM-based
reranking techniques. GUI-ReRank further introduces a fully customizable GUI
repository annotation and embedding pipeline, enabling users to effortlessly
make their own GUI repositories searchable, which allows for rapid discovery of
relevant GUIs for inspiration or seamless integration into customized LLM-based
RAG workflows. We evaluated our approach on an established NL-based GUI
retrieval benchmark, demonstrating that GUI-ReRank significantly outperforms
SOTA tailored LTR models in both retrieval accuracy and generalizability.
Additionally, we conducted a comprehensive cost and efficiency analysis of
employing MLLMs for reranking, providing valuable insights regarding the
trade-offs between retrieval effectiveness and computational resources. Video:
https://youtu.be/_7x9UCh82ug

</details>


### [13] [Industrial LLM-based Code Optimization under Regulation: A Mixture-of-Agents Approach](https://arxiv.org/abs/2508.03329)
*Mari Ashiga,Vardan Voskanyan,Fateme Dinmohammadi,Jingzhi Gong,Paul Brookes,Matthew Truscott,Rafail Giavrimis,Mike Basios,Leslie Kanthan,Wei Jie*

Main category: cs.SE

TL;DR: 论文提出了一种混合代理（MoA）方法，用于在受监管行业中实现高效代码优化，通过结合多个开源LLM，显著节省成本并提升优化速度。


<details>
  <summary>Details</summary>
Motivation: 受监管行业因数据隐私和合规要求无法使用商业LLM，导致代码优化面临挑战。

Method: 采用MoA方法，结合多个专用LLM生成代码，并与遗传算法（GA）和单个LLM进行对比。

Result: MoA在开源模型中表现优异，节省14.3%-22.2%成本，优化速度快28.6%-32.2%。GA在商业模型中更优，但两种集成方法均优于单个LLM。

Conclusion: MoA为受监管行业提供了平衡合规性与优化性能的可行方案，并通过实际验证证明了其有效性。

Abstract: Recent advancements in Large Language Models (LLMs) for code optimization
have enabled industrial platforms to automate software performance engineering
at unprecedented scale and speed. Yet, organizations in regulated industries
face strict constraints on which LLMs they can use - many cannot utilize
commercial models due to data privacy regulations and compliance requirements,
creating a significant challenge for achieving high-quality code optimization
while maintaining cost-effectiveness. We address this by implementing a
Mixture-of-Agents (MoA) approach that directly synthesizes code from multiple
specialized LLMs, comparing it against TurinTech AI's vanilla Genetic Algorithm
(GA)-based ensemble system and individual LLM optimizers using real-world
industrial codebases. Our key contributions include: (1) First MoA application
to industrial code optimization using real-world codebases; (2) Empirical
evidence that MoA excels with open-source models, achieving 14.3% to 22.2% cost
savings and 28.6% to 32.2% faster optimization times for regulated
environments; (3) Deployment guidelines demonstrating GA's advantage with
commercial models while both ensembles outperform individual LLMs; and (4)
Real-world validation across 50 code snippets and seven LLM combinations,
generating over 8,700 variants, addresses gaps in industrial LLM ensemble
evaluation. This provides actionable guidance for organizations balancing
regulatory compliance with optimization performance in production environments.

</details>


### [14] [Key-Augmented Neural Triggers for Knowledge Sharing](https://arxiv.org/abs/2508.03340)
*Alex Wolf,Marco Edoardo Palma,Pooja Rani,Harald C. Gall*

Main category: cs.SE

TL;DR: KANT是一种新方法，通过嵌入知识锚点解决代码库级理解中的语义碎片化和检索效率问题，显著降低延迟并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决代码库级理解中的语义碎片化、检索效率低、训练数据稀缺以及私有LLM的工业应用限制。

Method: 提出Key-Augmented Neural Triggers (KANT)，嵌入知识锚点到训练和推理中，合成专用数据并减少上下文开销。

Result: 合成数据与需求对齐，KANT获得60%以上人类偏好，延迟降低85%，适合低延迟本地部署。

Conclusion: KANT为代码理解提供了可扩展、低延迟的解决方案，适用于工业场景。

Abstract: Repository-level code comprehension and knowledge sharing remain core
challenges in software engineering. Large language models (LLMs) have shown
promise by generating explanations of program structure and logic. However,
these approaches still face limitations: First, relevant knowledge is
distributed across multiple files within a repository, aka semantic
fragmentation. Second, retrieval inefficiency and attention saturation degrade
performance in RAG pipelines, where long, unaligned contexts overwhelm
attention. Third, repository specific training data is scarce and often
outdated. Finally, proprietary LLMs hinder industrial adoption due to privacy
and deployment constraints. To address these issues, we propose Key-Augmented
Neural Triggers (KANT), a novel approach that embeds knowledge anchors into
both training and inference. Unlike prior methods, KANT enables internal access
to repository specific knowledge, reducing fragmentation and grounding
inference in localized context. Moreover, we synthesize specialized data
directly from code. At inference, knowledge anchors replace verbose context,
reducing token overhead and latency while supporting efficient, on premise
deployment. We evaluate KANT via: a qualitative human evaluation of the
synthesized dataset's intent coverage and quality across five dimensions;
compare against SOTA baselines across five qualitative dimensions and inference
speed; and replication across different LLMs to assess generalizability.
Results show that the synthetic training data aligned with information-seeking
needs. KANT achieved over 60% preference from human annotators and a LocalStack
expert (preferring 79% of cases). Also, KANT reduced inference latency by up to
85% across all models. Overall, it is well-suited for scalable, low-latency,
on-premise deployments, providing a strong foundation for code comprehension.

</details>


### [15] [Psychological safety in software workplaces: A systematic literature review](https://arxiv.org/abs/2508.03369)
*Beatriz Santana,Lidivânio Monte,Bianca Santana de Araújo Silva,Glauco Carneiro,Sávio Freire,José Amancio Macedo Santos,Manoel Mendonça*

Main category: cs.SE

TL;DR: 本文系统综述了软件工程中心理安全（PS）的研究现状，识别了其前因后果，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 心理安全对团队福祉和绩效至关重要，但软件工程领域的研究有限，亟需系统综述。

Method: 通过系统文献综述，对四个数字图书馆的研究进行定量和定性分析。

Result: 研究发现PS在软件工程中日益受关注，前因包括团队自主权、敏捷方法和领导行为。

Conclusion: PS促进创新和学习，但对其影响因素和提升策略的理解仍不足，未来需进一步研究。

Abstract: Context: Psychological safety (PS) is an important factor influencing team
well-being and performance, particularly in collaborative and dynamic domains
such as software development. Despite its acknowledged significance, research
on PS within the field of software engineering remains limited. The
socio-technical complexities and fast-paced nature of software development
present challenges to cultivating PS. To the best of our knowledge, no
systematic secondary study has synthesized existing knowledge on PS in the
context of software engineering.
  Objective: This study aims to systematically review and synthesize the
existing body of knowledge on PS in software engineering. Specifically, it
seeks to identify the potential antecedents and consequences associated with
the presence or absence of PS among individuals involved in the software
development process.
  Methods: A systematic literature review was conducted, encompassing studies
retrieved from four digital libraries. The extracted data were subjected to
both quantitative and qualitative analyses.
  Results: The findings indicate a growing academic interest in PS within
software engineering, with the majority of studies grounded in Edmondson's
framework. Factors antecedents of PS were identified at the individual, team,
and organizational levels, including team autonomy, agile methodologies, and
leadership behaviors.
  Conclusion: PS fosters innovation, learning, and team performance within
software development. However, significant gaps persist in understanding the
contextual factors influencing PS, its underlying mechanisms, and effective
strategies for its enhancement. Future research should address these gaps by
investigating the practical applications of PS within diverse organizational
settings in the software engineering domain.

</details>


### [16] [Agentic AI in 6G Software Businesses: A Layered Maturity Model](https://arxiv.org/abs/2508.03393)
*Muhammad Zohaib,Muhammad Azeem Akbar,Sami Hyrynsalmi,Arif Ali Khan*

Main category: cs.SE

TL;DR: 研究探讨了6G软件业务中代理AI系统的战略机遇与挑战，通过主题映射识别了29个促进因素和27个抑制因素，旨在为组织提供评估和提升代理能力的框架。


<details>
  <summary>Details</summary>
Motivation: 代理AI系统在6G环境中具有潜力，但其采用面临技术不成熟、集成复杂性等问题，需要系统性评估。

Method: 采用多声文献综述和定向扫描，进行主题映射，识别并分类影响因素。

Result: 识别了29个促进因素和27个抑制因素，分为五类主题，为组织提供了结构化视角。

Conclusion: 研究为6G时代的代理AI系统采用提供了可行性评估框架，支持组织能力提升。

Abstract: The emergence of agentic AI systems in 6G software businesses presents both
strategic opportunities and significant challenges. While such systems promise
increased autonomy, scalability, and intelligent decision-making across
distributed environments, their adoption raises concerns regarding technical
immaturity, integration complexity, organizational readiness, and
performance-cost trade-offs. In this study, we conducted a preliminary thematic
mapping to identify factors influencing the adoption of agentic software within
the context of 6G. Drawing on a multivocal literature review and targeted
scanning, we identified 29 motivators and 27 demotivators, which were further
categorized into five high-level themes in each group. This thematic mapping
offers a structured overview of the enabling and inhibiting forces shaping
organizational readiness for agentic transformation. Positioned as a
feasibility assessment, the study represents an early phase of a broader
research initiative aimed at developing and validating a layered maturity model
grounded in CMMI model with the software architectural three dimensions
possibly Data, Business Logic, and Presentation. Ultimately, this work seeks to
provide a practical framework to help software-driven organizations assess,
structure, and advance their agent-first capabilities in alignment with the
demands of 6G.

</details>


### [17] [StoneDetector: Conventional and versatile code clone detection for Java](https://arxiv.org/abs/2508.03435)
*Thomas S. Heinze,André Schäfer,Wolfram Amme*

Main category: cs.SE

TL;DR: StoneDetector平台用于检测Java源代码和字节码中的代码克隆，基于支配树路径的文本比较方法，支持多种配置参数，性能优越。


<details>
  <summary>Details</summary>
Motivation: 代码克隆在软件开发中普遍存在，可能导致项目膨胀和漏洞传播，因此需要高效检测工具。

Method: 基于支配树路径的文本比较方法，支持多种字符串度量和哈希算法配置。

Result: 在多个基准测试中表现优异，能够检测语法差异较大的代码克隆。

Conclusion: StoneDetector是一个高效、可扩展的代码克隆检测平台，适用于Java源代码和字节码。

Abstract: Copy & paste is a widespread practice when developing software and, thus,
duplicated and subsequently modified code occurs frequently in software
projects. Since such code clones, i.e., identical or similar fragments of code,
can bloat software projects and cause issues like bug or vulnerability
propagation, their identification is of importance. In this paper, we present
the StoneDetector platform and its underlying method for finding code clones in
Java source and Bytecode. StoneDetector implements a conventional clone
detection approach based upon the textual comparison of paths derived from the
code's representation by dominator trees. In this way, the tool does not only
find exact and syntactically similar near-miss code clones, but also code
clones that are harder to detect due to their larger variety in the syntax. We
demonstrate StoneDetector's versatility as a conventional clone detection
platform and analyze its various available configuration parameters, including
the usage of different string metrics, hashing algorithms, etc. In our
exhaustive evaluation with other conventional clone detectors on several
state-of-the-art benchmarks, we can show StoneDetector's performance and
scalability in finding code clones in both, Java source and Bytecode.

</details>


### [18] [On the Evaluation of Large Language Models in Multilingual Vulnerability Repair](https://arxiv.org/abs/2508.03470)
*Dong wang,Junji Yu,Honglin Shu,Michael Fu,Chakkrit Tantithamthavorn,Yasutaka Kamei,Junjie Chen*

Main category: cs.SE

TL;DR: 研究探讨了基于大语言模型（LLM）的多语言漏洞修复方法，发现GPT-4o在指令微调和少样本提示下表现优异，尤其在跨语言修复和危险漏洞修复方面。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法仅限于特定语言（如C/C++），而LLM具备语言无关性和语义理解能力，有望解决多语言漏洞修复的局限性。

Method: 通过大规模实证研究，比较了自动漏洞修复方法和先进LLM在七种编程语言中的表现，重点关注GPT-4o的指令微调效果。

Result: GPT-4o表现优于现有方法VulMaster，尤其在跨语言修复和危险漏洞修复方面。Go语言修复效果最佳，C/C++最差。

Conclusion: LLM在多语言漏洞修复中展现出巨大潜力，但仍需进一步研究其失败案例的原因。

Abstract: Various Deep Learning-based approaches with pre-trained language models have
been proposed for automatically repairing software vulnerabilities. However,
these approaches are limited to a specific programming language (C/C++). Recent
advances in large language models (LLMs) offer language-agnostic capabilities
and strong semantic understanding, exhibiting potential to overcome
multilingual vulnerability limitations. Although some work has begun to explore
LLMs' repair performance, their effectiveness is unsatisfactory. To address
these limitations, we conducted a large-scale empirical study to investigate
the performance of automated vulnerability repair approaches and
state-of-the-art LLMs across seven programming languages. Results show GPT-4o,
instruction-tuned with few-shot prompting, performs competitively against the
leading approach, VulMaster. Additionally, the LLM-based approach shows
superior performance in repairing unique vulnerabilities and is more likely to
repair the most dangerous vulnerabilities. Instruction-tuned GPT-4o
demonstrates strong generalization on vulnerabilities in previously unseen
language, outperforming existing approaches. Analysis shows Go consistently
achieves the highest effectiveness across all model types, while C/C++ performs
the worst. Based on findings, we discuss the promise of LLM on multilingual
vulnerability repair and the reasons behind LLM's failed cases. This work takes
the first look at repair approaches and LLMs across multiple languages,
highlighting the promising future of adopting LLMs for multilingual
vulnerability repair.

</details>


### [19] [BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice](https://arxiv.org/abs/2508.03487)
*Yuanpeng Li,Qi Long,Zhiyuan Yao,Jian Xu,Lintao Xie,Xu He,Lu Geng,Xin Han,Yueyan Chen,Wenbo Duan*

Main category: cs.SE

TL;DR: BitsAI-Fix是一种基于大型语言模型（LLM）的自动化lint错误修复工作流，通过上下文扩展和强化学习策略，在企业环境中高效解决技术债务问题。


<details>
  <summary>Details</summary>
Motivation: 企业代码库规模扩大导致lint错误数量远超工程师手动修复能力，技术债务积累影响开发效率。

Method: 使用tree-sitter扩展上下文，通过LLM生成补丁并进行验证；引入渐进式强化学习策略和规则奖励机制。

Result: 在字节跳动生产环境中支持5000多名工程师，修复12000多个静态分析问题，准确率约85%。

Conclusion: 证明了LLM在企业代码修复中的可行性，为大规模工业场景提供了参考。

Abstract: As enterprise codebases continue to grow in scale and complexity, the volume
of lint errors far exceeds engineers' manual remediation capacity, leading to
continuous accumulation of technical debt and hindered development efficiency.
This paper presents BitsAI-Fix, an automated lint error remediation workflow
based on Large Language Models (LLMs), designed to address this critical
challenge in industrial-scale environments. BitsAI-Fix employs tree-sitter for
context expansion and generates search-and-replace format patches through
specially trained LLMs, followed by lint scan re-verification to output final
remediation results. Additionally, our approach introduces an innovative
progressive reinforcement learning (RL) training strategy that can
automatically acquire verifiable training data during the project cold-start
phase and continuously iterate the model by collecting online samples through
feedback after system deployment. Furthermore, we designed a targeted
rule-based reward mechanism that combines format rewards and correctness
rewards while penalizing redundant modifications. We also propose a "code diff
matching" methodology to continuously track online effectiveness. In production
deployment at ByteDance, our solution has supported over 5,000 engineers,
resolved more than 12,000 static analysis issues, achieved approximately 85%
remediation accuracy, with around 1,000 weekly active adopters. This work
demonstrates the practical feasibility of LLM-based code remediation solutions
in enterprise environments and serves as a reference for automated code fix in
large-scale industrial scenarios.

</details>


### [20] [LaTCoder: Converting Webpage Design to Code with Layout-as-Thought](https://arxiv.org/abs/2508.03560)
*Yi Gui,Zhen Li,Zhongyi Zhang,Guohao Wang,Tianpeng Lv,Gaoyang Jiang,Yi Liu,Dongping Chen,Yao Wan,Hongyu Zhang,Wenbin Jiang,Xuanhua Shi,Hai Jin*

Main category: cs.SE

TL;DR: LaTCoder通过Layout-as-Thought方法提升网页设计到代码生成中的布局保留能力，显著优于直接提示方法。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在网页设计到代码生成任务中布局保留不准确的问题。

Method: 1. 将网页设计划分为图像块；2. 使用CoT方法为每个块生成代码；3. 采用绝对定位和MLLM组装策略动态选择最优输出。

Result: 在DeepSeek-VL2上，TreeBLEU提升66.67%，MAE降低38%；人工评估中60%以上偏好LaTCoder生成的网页。

Conclusion: LaTCoder显著提升了布局保留能力，验证了其有效性。

Abstract: Converting webpage designs into code (design-to-code) plays a vital role in
User Interface (UI) development for front-end developers, bridging the gap
between visual design and functional implementation. While recent Multimodal
Large Language Models (MLLMs) have shown significant potential in
design-to-code tasks, they often fail to accurately preserve the layout during
code generation. To this end, we draw inspiration from the Chain-of-Thought
(CoT) reasoning in human cognition and propose LaTCoder, a novel approach that
enhances layout preservation in webpage design during code generation with
Layout-as-Thought (LaT). Specifically, we first introduce a simple yet
efficient algorithm to divide the webpage design into image blocks. Next, we
prompt MLLMs using a CoTbased approach to generate code for each block.
Finally, we apply two assembly strategies-absolute positioning and an
MLLM-based method-followed by dynamic selection to determine the optimal
output. We evaluate the effectiveness of LaTCoder using multiple backbone MLLMs
(i.e., DeepSeek-VL2, Gemini, and GPT-4o) on both a public benchmark and a newly
introduced, more challenging benchmark (CC-HARD) that features complex layouts.
The experimental results on automatic metrics demonstrate significant
improvements. Specifically, TreeBLEU scores increased by 66.67% and MAE
decreased by 38% when using DeepSeek-VL2, compared to direct prompting.
Moreover, the human preference evaluation results indicate that annotators
favor the webpages generated by LaTCoder in over 60% of cases, providing strong
evidence of the effectiveness of our method.

</details>


### [21] [ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs](https://arxiv.org/abs/2508.03603)
*Iti Shree,Karine Even-Mendoz,Tomasz Radzik*

Main category: cs.SE

TL;DR: ReFuzzer是一个框架，通过检测和修正LLM生成的测试程序中的编译和运行时错误，显著提高了测试程序的有效性和代码覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的编译器模糊测试工具常生成语法或语义无效的测试程序，限制了其在测试编译器优化和后端组件中的效果。

Method: ReFuzzer采用反馈循环机制，利用本地LLM验证和过滤错误程序，确保生成多样且有效的测试程序。

Result: ReFuzzer将测试程序的有效性从47.0-49.4%提升至96.6-97.3%，并显著提高了关键优化和IR生成组件的代码覆盖率。

Conclusion: ReFuzzer通过改进测试程序的有效性和覆盖率，显著提升了编译器模糊测试的效果。

Abstract: Existing LLM-based compiler fuzzers often produce syntactically or
semantically invalid test programs, limiting their effectiveness in exercising
compiler optimizations and backend components. We introduce ReFuzzer, a
framework for refining LLM-generated test programs by systematically detecting
and correcting compilation and runtime violations (e.g. division by zero or
array out-of-bounds accesses). ReFuzzer employs a feedback loop with a local
LLM to validate and filter erroneous programs before execution, improving
fuzzing effectiveness beyond crash detection and enabling the generation of
diverse yet valid test programs.
  We evaluated ReFuzzer's effectiveness across black-, grey- and white-box
fuzzing approaches targeting LLVM/Clang. ReFuzzer improved test programs'
validity from 47.0-49.4% to 96.6-97.3%, with an average processing time of
2.9-3.5 s per test program on a dual-GPU machine. Further, refuzzing
significantly increased code coverage in critical optimization and IR
generation components. For example, vectorization coverage had an absolute
improvement of 9.2%, 2.3%, and 7.1% in black-, grey-, and white-box fuzzing,
enhancing testing effectiveness.

</details>


### [22] [Intent Preserving Generation of Diverse and Idiomatic (Code-)Artifacts](https://arxiv.org/abs/2508.03642)
*Oliver Westphal*

Main category: cs.SE

TL;DR: 论文提出了一种通过抽象构建块自动生成编程练习任务和相关工件的方法，避免了手动编写复杂生成器的需求。


<details>
  <summary>Details</summary>
Motivation: 自动生成编程练习任务和相关工件（如示例解决方案或任务描述）时，编写多样且符合习惯的代码生成器具有挑战性，尤其是在需要生成多个相关工件时。

Method: 提出了一种方法，通过定义一组抽象构建块及其具体实现，然后组合这些构建块来生成相关工件，从而避免手动编写复杂的生成器。

Result: 该方法能够自动生成多样化的编程练习任务和相关工件，适用于多种上下文。

Conclusion: 通过抽象构建块的方法，可以更灵活、高效地生成编程练习任务和相关工件，适应性强。

Abstract: When automatically generating programming exercise tasks one often also needs
to automatically generate programs. At the very least when providing sample
solutions is part of automated feedback. But programs can also be used as part
of the exercise task description to communicate a task's requirements.
  Writing good program generators that produce varied yet idiomatic code while
being easily adaptable for new tasks is challenging. The challenges are
intensified if task generation requires additional artifacts, like a more
general behavior specification for testing or additional textual descriptions.
Manually writing generators for multiple different but strongly related
artifacts gets complicated quickly.
  We present an approach where instead of writing monolithic generators for
multiple connected artifacts one specifies a small set of abstract building
blocks and for each such building block defines sets of concrete realizations
for various kinds of artifacts. Then the intended structure of the resulting
artifacts is specified as a composition of the small abstract building blocks.
This abstract description then serves as the common source from which related
artifacts can be derived automatically. The approach is generic in the kind of
artifacts it can produce and is therefore adaptable to a wide range of
contexts.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [23] [Real-World Evaluation of Protocol-Compliant Denial-of-Service Attacks on C-V2X-based Forward Collision Warning Systems](https://arxiv.org/abs/2508.02805)
*Jean Michel Tine,Mohammed Aldeen,Abyad Enan,M Sabbir Salek,Long Cheng,Mashrur Chowdhury*

Main category: cs.CR

TL;DR: 本文通过真实测试床评估了C-V2X技术中符合协议的DoS攻击（UDP洪泛和超大BSM攻击），发现这些攻击会严重降低FCW性能，甚至导致通信完全失败。


<details>
  <summary>Details</summary>
Motivation: 研究C-V2X技术在协议合规性下的安全漏洞，揭示即使符合标准也可能存在安全隐患。

Method: 使用真实测试床和商用OBU，模拟UDP洪泛和超大BSM攻击，评估其对FCW性能的影响。

Result: UDP洪泛降低数据包交付率87%，延迟超400ms；超大BSM攻击导致FCW警报延迟或完全失效；同时攻击时通信几乎完全失败。

Conclusion: 协议合规性不能完全保证C-V2X安全应用的可靠性，需进一步改进安全机制。

Abstract: Cellular Vehicle-to-Everything (C-V2X) technology enables low-latency,
reliable communications essential for safety applications such as a Forward
Collision Warning (FCW) system. C-V2X deployments operate under strict protocol
compliance with the 3rd Generation Partnership Project (3GPP) and the Society
of Automotive Engineers Standard (SAE) J2735 specifications to ensure
interoperability. This paper presents a real-world testbed evaluation of
protocol-compliant Denial-of-Service (DoS) attacks using User Datagram Protocol
(UDP) flooding and oversized Basic Safety Message (BSM) attacks that 7 exploit
transport- and application-layer vulnerabilities in C-V2X. The attacks
presented in this study transmit valid messages over standard PC5 sidelinks,
fully adhering to 3GPP and SAE J2735 specifications, but at abnormally high
rates and with oversized payloads that overload the receiver resources without
breaching any protocol rules such as IEEE 1609. Using a real-world connected
vehicle 11 testbed with commercially available On-Board Units (OBUs), we
demonstrate that high-rate UDP flooding and oversized payload of BSM flooding
can severely degrade FCW performance. Results show that UDP flooding alone
reduces packet delivery ratio by up to 87% and increases latency to over 400ms,
while oversized BSM floods overload receiver processing resources, delaying or
completely suppressing FCW alerts. When UDP and BSM attacks are executed
simultaneously, they cause near-total communication failure, preventing FCW
warnings entirely. These findings reveal that protocol-compliant communications
do not necessarily guarantee safe or reliable operation of C-V2X-based safety
applications.

</details>


### [24] [Thermal-Aware 3D Design for Side-Channel Information Leakage](https://arxiv.org/abs/2508.02816)
*Dylan Stow,Russell Barnes,Eren Kurshan,Yuan Xie*

Main category: cs.CR

TL;DR: 提出了一种利用3D集成技术和动态生成活动模式的方法，有效降低热侧信道攻击的风险。


<details>
  <summary>Details</summary>
Motivation: 热侧信道攻击能够泄露关键功能块的活动甚至加密密钥，亟需一种主动隐藏关键活动的方法。

Method: 结合3D集成技术的固有特性，动态生成自定义活动模式以匹配功能层中的活动。

Result: 实验表明，该方法将侧信道漏洞因子（SVF）降至0.05以下，空间热侧信道因子（STSF）降至0.59以下。

Conclusion: 3D技术与运行时算法的结合能有效减少热侧信道攻击的威胁。

Abstract: Side-channel attacks are important security challenges as they reveal
sensitive information about on-chip activities. Among such attacks, the thermal
side-channel has been shown to disclose the activities of key functional blocks
and even encryption keys. This paper proposes a novel approach to proactively
conceal critical activities in the functional layers while minimizing the power
dissipation by (i) leveraging inherent characteristics of 3D integration to
protect from side-channel attacks and (ii) dynamically generating custom
activity patterns to match the activity to be concealed in the functional
layers. Experimental analysis shows that 3D technology combined with the
proposed run-time algorithm effectively reduces the Side channel vulnerability
Factor (SVF) below 0.05 and the Spatial Thermal Side-channel Factor (STSF)
below 0.59.

</details>


### [25] [Agentic Privacy-Preserving Machine Learning](https://arxiv.org/abs/2508.02836)
*Mengyu Zhang,Zhuotao Liu,Jingwen Huang,Xuanqi Liu*

Main category: cs.CR

TL;DR: 提出了一种名为Agentic-PPML的新框架，旨在解决隐私保护机器学习（PPML）在大型语言模型（LLMs）中的效率问题。


<details>
  <summary>Details</summary>
Motivation: 当前PPML方案在处理LLMs时效率极低，性能差距显著，尤其是在上下文长度增加时。

Method: 通过将语言意图解析与隐私关键计算模块化分离，利用通用LLM处理意图理解，并将加密推理任务委托给垂直领域的专用模型。

Result: Agentic-PPML避免了LLMs处理加密提示的需求，从而实现了隐私保护LLM服务的实际部署。

Conclusion: 该框架为隐私保护LLM的实际应用提供了一种可行的解决方案。

Abstract: Privacy-preserving machine learning (PPML) is critical to ensure data privacy
in AI. Over the past few years, the community has proposed a wide range of
provably secure PPML schemes that rely on various cryptography primitives.
However, when it comes to large language models (LLMs) with billions of
parameters, the efficiency of PPML is everything but acceptable. For instance,
the state-of-the-art solution for confidential LLM inference represents at
least 10,000-fold slower performance compared to plaintext inference. The
performance gap is even larger when the context length increases. In this
position paper, we propose a novel framework named Agentic-PPML to make PPML in
LLMs practical. Our key insight is to employ a general-purpose LLM for intent
understanding and delegate cryptographically secure inference to specialized
models trained on vertical domains. By modularly separating language intent
parsing - which typically involves little or no sensitive information - from
privacy-critical computation, Agentic-PPML completely eliminates the need for
the LLMs to process the encrypted prompts, enabling practical deployment of
privacy-preserving LLM-centric services.

</details>


### [26] [LMDG: Advancing Lateral Movement Detection Through High-Fidelity Dataset Generation](https://arxiv.org/abs/2508.02942)
*Anas Mabrouk,Mohamed Hatem,Mohammad Mamun,Sherif Saad*

Main category: cs.CR

TL;DR: LMDG是一个可扩展的框架，用于生成高保真的横向移动攻击数据集，通过自动化生成良性活动和多阶段攻击，减少人工标注工作。


<details>
  <summary>Details</summary>
Motivation: 解决横向移动攻击检测系统缺乏现实且标注良好的数据集的问题。

Method: 提出LMDG框架，包括自动化良性活动生成、多阶段攻击执行和系统日志标注，特别是基于代理的Process Tree Labeling技术。

Result: 生成了一个25天的数据集，包含35个多阶段攻击，恶意事件占比小于1%，数据量达944GB。

Conclusion: LMDG提供了更真实、多样化的数据集，支持细粒度标注和多阶段攻击检测，优于现有方法。

Abstract: Lateral Movement (LM) attacks continue to pose a significant threat to
enterprise security, enabling adversaries to stealthily compromise critical
assets. However, the development and evaluation of LM detection systems are
impeded by the absence of realistic, well-labeled datasets. To address this
gap, we propose LMDG, a reproducible and extensible framework for generating
high-fidelity LM datasets. LMDG automates benign activity generation,
multi-stage attack execution, and comprehensive labeling of system and network
logs, dramatically reducing manual effort and enabling scalable dataset
creation. A central contribution of LMDG is Process Tree Labeling, a novel
agent-based technique that traces all malicious activity back to its origin
with high precision. Unlike prior methods such as Injection Timing or
Behavioral Profiling, Process Tree Labeling enables accurate, step-wise
labeling of malicious log entries, correlating each with a specific attack step
and MITRE ATT\&CK TTPs. To our knowledge, this is the first approach to support
fine-grained labeling of multi-step attacks, providing critical context for
detection models such as attack path reconstruction. We used LMDG to generate a
25-day dataset within a 25-VM enterprise environment containing 22 user
accounts. The dataset includes 944 GB of host and network logs and embeds 35
multi-stage LM attacks, with malicious events comprising less than 1% of total
activity, reflecting a realistic benign-to-malicious ratio for evaluating
detection systems. LMDG-generated datasets improve upon existing ones by
offering diverse LM attacks, up-to-date attack patterns, longer attack
timeframes, comprehensive data sources, realistic network architectures, and
more accurate labeling.

</details>


### [27] [A Non-leveled and Reliable Approximate FHE Framework through Binarized Polynomial Rings](https://arxiv.org/abs/2508.02943)
*Baigang Chen,Dongfang Zhao*

Main category: cs.CR

TL;DR: 提出了一种基于二进制系数多项式环的CKKS变体，通过轻量级自举机制和BCH纠错码优化噪声增长和解密鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决CKKS方案中噪声增长快、参数调整复杂和模切换成本高的问题。

Method: 采用二进制系数多项式环和轻量级自举机制，结合BCH纠错码减少比特翻转错误。

Result: 开源实现显示该框架在小环维度和无限深度计算中高效且可扩展。

Conclusion: 二进制变体CKKS在保持核心代数结构的同时，显著提升了实用性和可扩展性。

Abstract: Homomorphic encryption (HE) enables secure computation on encrypted data,
safeguarding user privacy in domains such as cloud computing, healthcare, and
finance. Among fully homomorphic encryption (FHE) schemes, CKKS is notable for
supporting approximate arithmetic over complex numbers, a key requirement for
machine-learning and numerical workloads. However, CKKS incurs rapid noise
growth, complex parameter tuning, and relies on costly modulus switching. We
propose a binary variant of CKKS that operates entirely over binary-coefficient
polynomial rings and replaces rescaling with a lightweight bootstrapping
mechanism. To mitigate additional bit-flip errors introduced by binary
encoding, we integrate BCH error-correcting codes for robust decryption. Our
open-source implementation, built on the HElib library, preserves the core
algebraic structure of CKKS while introducing binary-coefficient encoding,
enabling efficient evaluation in small ring dimensions and unbounded-depth
computation. Empirical evaluations demonstrate the framework's practicality and
scalability across a range of settings.

</details>


### [28] [Lightweight Fault Detection Architecture for NTT on FPGA](https://arxiv.org/abs/2508.03062)
*Rourab Paul,Paresh Baidya,Krishnendu Guha*

Main category: cs.CR

TL;DR: 该论文提出了一种轻量级、高效的基于重新计算的故障检测模块，用于后量子密码（PQC）算法中的数论变换（NTT），以应对硬件实现中的自然或故意故障注入。


<details>
  <summary>Details</summary>
Motivation: 后量子密码算法在硬件实现中可能因自然故障或故意故障注入而泄露敏感信息，影响未来网络安全处理器的可靠性。

Method: 提出了两种方法：基于Montgomery Reduction的REMO（重新计算与模偏移）用于CT-BU逻辑块，以及Memory Rule Checkers用于NTT中的内存组件。

Result: 该框架在Artix-7 FPGA上仅占用16个切片和1个DSP块，功耗为3mW，故障覆盖率为87.2%至100%（REMO）和50.7%至100%（Memory Rule Checkers）。

Conclusion: 提出的故障检测框架在高效性和低成本方面设定了新标准，适用于多种PQC算法。

Abstract: Post-Quantum Cryptographic (PQC) algorithms are mathematically secure and
resistant to quantum attacks but can still leak sensitive information in
hardware implementations due to natural faults or intentional fault injections.
The intent fault injection in side-channel attacks reduces the reliability of
crypto implementation in future generation network security procesors. In this
regard, this research proposes a lightweight, efficient, recomputation-based
fault detection module implemented on a Field Programmable Gate Array (FPGA)
for Number Theoretic Transform (NTT). The NTT is primarily composed of memory
units and the Cooley-Tukey Butterfly Unit (CT-BU), a critical and
computationally intensive hardware component essential for polynomial
multiplication. NTT and polynomial multiplication are fundamental building
blocks in many PQC algorithms, including Kyber, NTRU, Ring-LWE, and others. In
this paper, we present a fault detection method called : Recomputation with a
Modular Offset (REMO) for the logic blocks of the CT-BU using Montgomery
Reduction and another method called Memory Rule Checkers for the memory
components used within the NTT. The proposed fault detection framework sets a
new benchmark by achieving high efficiency with significant low implementation
cost. It occupies only 16 slices and a single DSP block, with a power
consumption of just 3mW in Artix-7 FPGA. The REMO-based detection mechanism
achieves a fault coverage of 87.2% to 100%, adaptable across various word
sizes, fault bit counts, and fault injection modes. Similarly, the Memory Rule
Checkers demonstrate robust performance, achieving 50.7% to 100% fault
detection depending on and the nature of injected faults.

</details>


### [29] [Untraceable DeepFakes via Traceable Fingerprint Elimination](https://arxiv.org/abs/2508.03067)
*Jiewei Lai,Lan Zhang,Chen Tang,Pengcheng Sun,Xinming Wang,Yunhao Wang*

Main category: cs.CR

TL;DR: 本文提出了一种乘法攻击方法，能够彻底消除生成模型（GMs）的痕迹，从而逃避增强防御措施的属性模型（AMs）。


<details>
  <summary>Details</summary>
Motivation: 现有攻击方法无法完全消除GMs痕迹，且防御措施可缓解这些攻击，因此需要更强大的AMs。

Method: 设计了一种通用且黑盒的攻击方法，仅使用真实数据训练对抗模型，适用于多种GMs且对AMs不可知。

Result: 实验结果显示，该方法对6种先进AMs和9种GMs生成的DeepFakes平均攻击成功率达97.08%，即使有防御机制，攻击成功率仍超过72.39%。

Conclusion: 乘法攻击可能带来潜在挑战，强调了开发更强大AMs的必要性。

Abstract: Recent advancements in DeepFakes attribution technologies have significantly
enhanced forensic capabilities, enabling the extraction of traces left by
generative models (GMs) in images, making DeepFakes traceable back to their
source GMs. Meanwhile, several attacks have attempted to evade attribution
models (AMs) for exploring their limitations, calling for more robust AMs.
However, existing attacks fail to eliminate GMs' traces, thus can be mitigated
by defensive measures. In this paper, we identify that untraceable DeepFakes
can be achieved through a multiplicative attack, which can fundamentally
eliminate GMs' traces, thereby evading AMs even enhanced with defensive
measures. We design a universal and black-box attack method that trains an
adversarial model solely using real data, applicable for various GMs and
agnostic to AMs. Experimental results demonstrate the outstanding attack
capability and universal applicability of our method, achieving an average
attack success rate (ASR) of 97.08\% against 6 advanced AMs on DeepFakes
generated by 9 GMs. Even in the presence of defensive mechanisms, our method
maintains an ASR exceeding 72.39\%. Our work underscores the potential
challenges posed by multiplicative attacks and highlights the need for more
robust AMs.

</details>


### [30] [VFLAIR-LLM: A Comprehensive Framework and Benchmark for Split Learning of LLMs](https://arxiv.org/abs/2508.03097)
*Zixuan Gu,Qiufeng Fan,Long Sun,Yang Liu,Xiaojun Ye*

Main category: cs.CR

TL;DR: VFLAIR-LLM是一个轻量级的分布式学习框架，支持在资源受限环境下进行隐私保护的LLM推理和微调，提供了多种攻击和防御的评估模块。


<details>
  <summary>Details</summary>
Motivation: 解决用户因隐私问题无法直接使用LLM API，以及私有部署计算资源需求高的问题。

Method: 采用Split Learning（SL）方法，设计了VFLAIR-LLM框架，支持两种LLM分区设置、三种任务类型和18个数据集。

Result: 评估了5种攻击和9种防御策略，提供了模型分区配置、防御策略和超参数选择的实用建议。

Conclusion: VFLAIR-LLM为资源受限环境下的隐私保护LLM应用提供了高效解决方案。

Abstract: With the advancement of Large Language Models (LLMs), LLM applications have
expanded into a growing number of fields. However, users with data privacy
concerns face limitations in directly utilizing LLM APIs, while private
deployments incur significant computational demands. This creates a substantial
challenge in achieving secure LLM adaptation under constrained local resources.
To address this issue, collaborative learning methods, such as Split Learning
(SL), offer a resource-efficient and privacy-preserving solution for adapting
LLMs to private domains. In this study, we introduce VFLAIR-LLM (available at
https://github.com/FLAIR-THU/VFLAIR-LLM), an extensible and lightweight split
learning framework for LLMs, enabling privacy-preserving LLM inference and
fine-tuning in resource-constrained environments. Our library provides two LLM
partition settings, supporting three task types and 18 datasets. In addition,
we provide standard modules for implementing and evaluating attacks and
defenses. We benchmark 5 attacks and 9 defenses under various Split Learning
for LLM(SL-LLM) settings, offering concrete insights and recommendations on the
choice of model partition configurations, defense strategies, and relevant
hyperparameters for real-world applications.

</details>


### [31] [Attack the Messages, Not the Agents: A Multi-round Adaptive Stealthy Tampering Framework for LLM-MAS](https://arxiv.org/abs/2508.03125)
*Bingyu Yan,Ziyi Zhou,Xiaoming Zhang,Chaozhuo Li,Ruilin Zeng,Yirui Qi,Tianbo Wang,Litian Zhang*

Main category: cs.CR

TL;DR: MAST框架通过多轮自适应隐蔽篡改攻击LLM-MAS，显著提升攻击成功率和隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有攻击方法对LLM-MAS的通信漏洞利用不足，缺乏适应性和隐蔽性。

Method: 结合蒙特卡洛树搜索与直接偏好优化，训练攻击策略模型，并引入语义和嵌入相似性约束。

Result: MAST在多种任务和架构中表现优异，攻击成功率高且隐蔽性强。

Conclusion: MAST展示了高效、隐蔽和适应性强的攻击能力，凸显了LLM-MAS需加强通信防护。

Abstract: Large language model-based multi-agent systems (LLM-MAS) effectively
accomplish complex and dynamic tasks through inter-agent communication, but
this reliance introduces substantial safety vulnerabilities. Existing attack
methods targeting LLM-MAS either compromise agent internals or rely on direct
and overt persuasion, which limit their effectiveness, adaptability, and
stealthiness. In this paper, we propose MAST, a Multi-round Adaptive Stealthy
Tampering framework designed to exploit communication vulnerabilities within
the system. MAST integrates Monte Carlo Tree Search with Direct Preference
Optimization to train an attack policy model that adaptively generates
effective multi-round tampering strategies. Furthermore, to preserve
stealthiness, we impose dual semantic and embedding similarity constraints
during the tampering process. Comprehensive experiments across diverse tasks,
communication architectures, and LLMs demonstrate that MAST consistently
achieves high attack success rates while significantly enhancing stealthiness
compared to baselines. These findings highlight the effectiveness,
stealthiness, and adaptability of MAST, underscoring the need for robust
communication safeguards in LLM-MAS.

</details>


### [32] [Protecting Small Organizations from AI Bots with Logrip: Hierarchical IP Hashing](https://arxiv.org/abs/2508.03130)
*Rama Carl Hoetzlein*

Main category: cs.CR

TL;DR: 论文提出了一种基于数据可视化和分层IP哈希的新方法，用于区分人类用户与自动化爬虫，帮助小型组织有效管理流量。


<details>
  <summary>Details</summary>
Motivation: 小型组织和自托管服务器面临自动化爬虫和AI机器人的流量压力，传统限流方法难以应对。

Method: 利用数据可视化和分层IP哈希分析服务器日志，通过子网聚合和统计方法检测协同机器人活动。

Result: 实验显示80-95%的流量来自AI爬虫，新方法能有效识别传统工具无法检测的分布式爬虫攻击。

Conclusion: 该方法帮助小型组织在不影响公开访问的情况下，有效缓解性能下降问题。

Abstract: Small organizations, start ups, and self-hosted servers face increasing
strain from automated web crawlers and AI bots, whose online presence has
increased dramatically in the past few years. Modern bots evade traditional
throttling and can degrade server performance through sheer volume even when
they are well-behaved. We introduce a novel security approach that leverages
data visualization and hierarchical IP hashing to analyze server event logs,
distinguishing human users from automated entities based on access patterns. By
aggregating IP activity across subnet classes and applying statistical
measures, our method detects coordinated bot activity and distributed crawling
attacks that conventional tools fail to identify. Using a real world example we
estimate that 80 to 95 percent of traffic originates from AI crawlers,
underscoring the need for improved filtering mechanisms. Our approach enables
small organizations to regulate automated traffic effectively, preserving
public access while mitigating performance degradation.

</details>


### [33] [WiFinger: Fingerprinting Noisy IoT Event Traffic Using Packet-level Sequence Matching](https://arxiv.org/abs/2508.03151)
*Ronghua Li,Shinan Liu,Haibo Hu,Qingqing Ye,Nick Feamster*

Main category: cs.CR

TL;DR: WiFinger是一种针对噪声Wi-Fi流量的细粒度多IoT事件指纹识别方法，通过将流量模式分类任务转化为子序列匹配问题，显著提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在无线流量（尤其是Wi-Fi）中表现不佳，无法有效同时跟踪多个事件，WiFinger旨在解决这些问题。

Method: 将流量模式分类转化为子序列匹配问题，并引入新技术以降低时间复杂性同时保持高准确性。

Result: 实验显示，WiFinger在Wi-Fi流量中表现优于现有方法，平均召回率达85%，且几乎零误报。

Conclusion: WiFinger为噪声环境下的多IoT事件跟踪提供了一种高效且准确的解决方案。

Abstract: IoT environments such as smart homes are susceptible to privacy inference
attacks, where attackers can analyze patterns of encrypted network traffic to
infer the state of devices and even the activities of people. While most
existing attacks exploit ML techniques for discovering such traffic patterns,
they underperform on wireless traffic, especially Wi-Fi, due to its heavy noise
and packet losses of wireless sniffing. In addition, these approaches commonly
target at distinguishing chunked IoT event traffic samples, and they failed at
effectively tracking multiple events simultaneously. In this work, we propose
WiFinger, a fine-grained multi-IoT event fingerprinting approach against noisy
traffic. WiFinger turns the traffic pattern classification task into a
subsequence matching problem and introduces novel techniques to account for the
high time complexity while maintaining high accuracy. Experiments demonstrate
that our method outperforms existing approaches on Wi-Fi traffic, achieving an
average recall of 85% (vs. 0.49% and 0.46%) for various IoT events while
maintaining almost zero false positives for most of them.

</details>


### [34] [BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.03221)
*Yu Pan,Jiahao Chen,Lin Wang,Bingrong Dai,Yi Du*

Main category: cs.CR

TL;DR: 论文提出了一种新型轻量级、隐蔽的后门攻击方法BadBlocks，针对扩散模型，仅需30%计算资源和20%GPU时间即可成功注入后门并绕过现有防御框架。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成领域取得显著进展，但易受后门攻击。现有防御技术已能识别和缓解大多数攻击，但缺乏对更轻量、隐蔽攻击的防护。

Method: 通过选择性污染扩散模型UNet架构中的特定块，保持其余组件正常功能，BadBlocks实现了高效后门注入。

Result: 实验表明，BadBlocks攻击成功率高，感知质量损失低，且能绕过现有防御框架，尤其是基于注意力的检测方法。

Conclusion: BadBlocks显著降低了后门攻击的门槛，使攻击者能在消费级GPU上对大规模扩散模型进行攻击，是一种新型威胁。

Abstract: In recent years,Diffusion models have achieved remarkable progress in the
field of image generation.However,recent studies have shown that diffusion
models are susceptible to backdoor attacks,in which attackers can manipulate
the output by injecting covert triggers such as specific visual patterns or
textual phrases into the training dataset.Fortunately,with the continuous
advancement of defense techniques,defenders have become increasingly capable of
identifying and mitigating most backdoor attacks using visual inspection and
neural network-based detection methods.However,in this paper,we identify a
novel type of backdoor threat that is more lightweight and covert than existing
approaches,which we name BadBlocks,requires only about 30\% of the
computational resources and 20\% GPU time typically needed by previous backdoor
attacks,yet it successfully injects backdoors and evades the most advanced
defense frameworks.BadBlocks enables attackers to selectively contaminate
specific blocks within the UNet architecture of diffusion models while
maintaining normal functionality in the remaining components.Experimental
results demonstrate that BadBlocks achieves a high attack success rate (ASR)
and low perceptual quality loss (as measured by FID Score),even under extremely
constrained computational resources and GPU time.Moreover,BadBlocks is able to
bypass existing defense frameworks,especially the attention-based backdoor
detection method, highlighting it as a novel and noteworthy threat.Ablation
studies further demonstrate that effective backdoor injection does not require
fine-tuning the entire network and highlight the pivotal role of certain neural
network layers in backdoor mapping.Overall,BadBlocks significantly reduces the
barrier to conducting backdoor attacks in all aspects.It enables attackers to
inject backdoors into large-scale diffusion models even using consumer-grade
GPUs.

</details>


### [35] [BDFirewall: Towards Effective and Expeditiously Black-Box Backdoor Defense in MLaaS](https://arxiv.org/abs/2508.03307)
*Ye Li,Chengcheng Zhu,Yanchao Zhao,Jiale Zhang*

Main category: cs.CR

TL;DR: 论文提出了一种针对黑盒场景下后门攻击的防御框架BDFirewall，通过渐进式方法从高可见性到低可见性触发器进行清除，显著降低了攻击成功率并提高了处理速度。


<details>
  <summary>Details</summary>
Motivation: 解决黑盒场景下后门攻击的防御难题，提升MLaaS推理安全性。

Method: 将后门触发器分为HVT、SVT和LVT三类，并设计BDFirewall框架逐步清除这些触发器，包括局部净化、去噪处理和轻量级噪声干扰。

Result: BDFirewall平均降低攻击成功率33.25%，提高中毒样本准确率29.64%，推理速度提升111倍。

Conclusion: BDFirewall是一种高效且无需模型访问的后门攻击防御方法，显著优于现有技术。

Abstract: In this paper, we endeavor to address the challenges of backdoor attacks
countermeasures in black-box scenarios, thereby fortifying the security of
inference under MLaaS. We first categorize backdoor triggers from a new
perspective, i.e., their impact on the patched area, and divide them into:
high-visibility triggers (HVT), semi-visibility triggers (SVT), and
low-visibility triggers (LVT). Based on this classification, we propose a
progressive defense framework, BDFirewall, that removes these triggers from the
most conspicuous to the most subtle, without requiring model access. First, for
HVTs, which create the most significant local semantic distortions, we identify
and eliminate them by detecting these salient differences. We then restore the
patched area to mitigate the adverse impact of such removal process. The
localized purification designed for HVTs is, however, ineffective against SVTs,
which globally perturb benign features. We therefore model an SVT-poisoned
input as a mixture of a trigger and benign features, where we unconventionally
treat the benign features as "noise". This formulation allows us to reconstruct
SVTs by applying a denoising process that removes these benign "noise"
features. The SVT-free input is then obtained by subtracting the reconstructed
trigger. Finally, to neutralize the nearly imperceptible but fragile LVTs, we
introduce lightweight noise to disrupt the trigger pattern and then apply DDPM
to restore any collateral impact on clean features. Comprehensive experiments
demonstrate that our method outperforms state-of-the-art defenses. Compared
with baselines, BDFirewall reduces the Attack Success Rate (ASR) by an average
of 33.25%, improving poisoned sample accuracy (PA) by 29.64%, and achieving up
to a 111x speedup in inference time. Code will be made publicly available upon
acceptance.

</details>


### [36] [From Legacy to Standard: LLM-Assisted Transformation of Cybersecurity Playbooks into CACAO Format](https://arxiv.org/abs/2508.03342)
*Mehdi Akbari Gurabi,Lasse Nitz,Radu-Mihai Castravet,Roman Matzutt,Avikarsha Mandal,Stefan Decker*

Main category: cs.CR

TL;DR: 论文探讨了利用大语言模型和提示工程将传统网络安全剧本自动转换为标准化、机器可读的CACAO格式的方法，显著提升了转换准确性和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有网络安全剧本格式异构且非机器可读，限制了自动化和互操作性。

Method: 结合大语言模型和提示工程，设计模块化转换流程，包括语法检查器和迭代优化机制。

Result: 在自定义数据集上验证，方法显著提升转换准确性，减少错误，并保留复杂工作流结构。

Conclusion: 该方法在自动化网络安全剧本转换任务中具有实际部署潜力。

Abstract: Existing cybersecurity playbooks are often written in heterogeneous,
non-machine-readable formats, which limits their automation and
interoperability across Security Orchestration, Automation, and Response
platforms. This paper explores the suitability of Large Language Models,
combined with Prompt Engineering, to automatically translate legacy incident
response playbooks into the standardized, machine-readable CACAO format. We
systematically examine various Prompt Engineering techniques and carefully
design prompts aimed at maximizing syntactic accuracy and semantic fidelity for
control flow preservation. Our modular transformation pipeline integrates a
syntax checker to ensure syntactic correctness and features an iterative
refinement mechanism that progressively reduces syntactic errors. We evaluate
the proposed approach on a custom-generated dataset comprising diverse legacy
playbooks paired with manually created CACAO references. The results
demonstrate that our method significantly improves the accuracy of playbook
transformation over baseline models, effectively captures complex workflow
structures, and substantially reduces errors. It highlights the potential for
practical deployment in automated cybersecurity playbook transformation tasks.

</details>


### [37] [Smart Car Privacy: Survey of Attacks and Privacy Issues](https://arxiv.org/abs/2508.03413)
*Akshay Madhav Deshmukh*

Main category: cs.CR

TL;DR: 论文概述了车载网络架构、安全演化和VANETs中的安全隐私攻击及其防御机制。


<details>
  <summary>Details</summary>
Motivation: 随着汽车高度计算机化和无线连接的增加，车载网络的安全和隐私问题变得至关重要。

Method: 综述了车载网络架构、安全演化和VANETs中的攻击与防御机制，并分类了这些机制。

Result: 提供了对车载网络安全隐私问题的全面分析，并展示了防御机制的例子。

Conclusion: 设计和实施有效的安全机制对VANETs至关重要，以应对移动车辆带来的挑战。

Abstract: Automobiles are becoming increasingly important in our day to day life.
Modern automobiles are highly computerized and hence potentially vulnerable to
attack. Providing many wireless connectivity for vehicles enables a bridge
between vehicles and their external environments. Such a connected vehicle
solution is expected to be the next frontier for automotive revolution and the
key to the evolution to next generation intelligent transportation systems.
Vehicular Ad hoc Networks (VANETs) are emerging mobile ad hoc network
technologies incorporating mobile routing protocols for inter-vehicle data
communications to support intelligent transportation systems. Thus security and
privacy are the major concerns in VANETs due to the mobility of the vehicles.
Thus designing security mechanisms to remove adversaries from the network
remarkably important in VANETs.
  This paper provides an overview of various vehicular network architectures.
The evolution of security in modern vehicles. Various security and privacy
attacks in VANETs with their defending mechanisms with examples and classify
these mechanisms. It also provides an overview of various privacy implication
that a vehicular network possess.

</details>


### [38] [Unravelling the Probabilistic Forest: Arbitrage in Prediction Markets](https://arxiv.org/abs/2508.03474)
*Oriol Saguillo,Vahid Ghafouri,Lucianna Kiffer,Guillermo Suarez-Tangil*

Main category: cs.CR

TL;DR: Polymarket是一个预测市场平台，用户可以通过交易与特定结果相关的股票来投机未来事件。本文通过实证分析研究了平台上的套利现象，揭示了两种套利形式，并估计了4000万美元的套利利润。


<details>
  <summary>Details</summary>
Motivation: 研究Polymarket上套利现象的产生条件、实际发生情况以及是否被利用，以揭示市场设计中的潜在问题。

Method: 采用启发式驱动的简化策略，结合时间性、主题相似性和组合关系，分析链上历史订单数据。

Result: 发现两种套利形式：市场再平衡套利和组合套利，并估计用户从中获利4000万美元。

Conclusion: Polymarket存在套利机会，表明市场设计存在不一致性，可能被高级参与者利用。

Abstract: Polymarket is a prediction market platform where users can speculate on
future events by trading shares tied to specific outcomes, known as conditions.
Each market is associated with a set of one or more such conditions. To ensure
proper market resolution, the condition set must be exhaustive -- collectively
accounting for all possible outcomes -- and mutually exclusive -- only one
condition may resolve as true. Thus, the collective prices of all related
outcomes should be \$1, representing a combined probability of 1 of any
outcome. Despite this design, Polymarket exhibits cases where dependent assets
are mispriced, allowing for purchasing (or selling) a certain outcome for less
than (or more than) \$1, guaranteeing profit. This phenomenon, known as
arbitrage, could enable sophisticated participants to exploit such
inconsistencies.
  In this paper, we conduct an empirical arbitrage analysis on Polymarket data
to answer three key questions: (Q1) What conditions give rise to arbitrage (Q2)
Does arbitrage actually occur on Polymarket and (Q3) Has anyone exploited these
opportunities. A major challenge in analyzing arbitrage between related markets
lies in the scalability of comparisons across a large number of markets and
conditions, with a naive analysis requiring $O(2^{n+m})$ comparisons. To
overcome this, we employ a heuristic-driven reduction strategy based on
timeliness, topical similarity, and combinatorial relationships, further
validated by expert input.
  Our study reveals two distinct forms of arbitrage on Polymarket: Market
Rebalancing Arbitrage, which occurs within a single market or condition, and
Combinatorial Arbitrage, which spans across multiple markets. We use on-chain
historical order book data to analyze when these types of arbitrage
opportunities have existed, and when they have been executed by users. We find
a realized estimate of 40 million USD of profit extracted.

</details>


### [39] [Intrusion Detection in Heterogeneous Networks with Domain-Adaptive Multi-Modal Learning](https://arxiv.org/abs/2508.03517)
*Mabin Umman Varghese,Zahra Taghiyarrenani*

Main category: cs.CR

TL;DR: 提出了一种结合多模态学习和领域适应技术的深度神经网络模型，用于提升网络入侵检测系统的性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度神经网络模型在检测网络入侵时受限于需要大量标记数据和跨网络领域的数据与特征异质性。

Method: 开发了一种深度神经网络模型，通过顺序循环方式处理多源数据，结合多模态学习和领域适应技术。

Result: 实验表明，该模型在样本可用性和概率分布变化的条件下，显著优于基线神经网络模型。

Conclusion: 该模型能够泛化到异构数据集，是现实网络入侵检测的高效解决方案。

Abstract: Network Intrusion Detection Systems (NIDS) play a crucial role in
safeguarding network infrastructure against cyberattacks. As the prevalence and
sophistication of these attacks increase, machine learning and deep neural
network approaches have emerged as effective tools for enhancing NIDS
capabilities in detecting malicious activities. However, the effectiveness of
traditional deep neural models is often limited by the need for extensive
labelled datasets and the challenges posed by data and feature heterogeneity
across different network domains. To address these limitations, we developed a
deep neural model that integrates multi-modal learning with domain adaptation
techniques for classification. Our model processes data from diverse sources in
a sequential cyclic manner, allowing it to learn from multiple datasets and
adapt to varying feature spaces. Experimental results demonstrate that our
proposed model significantly outperforms baseline neural models in classifying
network intrusions, particularly under conditions of varying sample
availability and probability distributions. The model's performance highlights
its ability to generalize across heterogeneous datasets, making it an efficient
solution for real-world network intrusion detection.

</details>


### [40] [MalFlows: Context-aware Fusion of Heterogeneous Flow Semantics for Android Malware Detection](https://arxiv.org/abs/2508.03588)
*Zhaoyi Meng,Fenglei Xu,Wenxiang Zhao,Wansen Wang,Wenchao Huang,Jie Cui,Hong Zhong,Yan Xiong*

Main category: cs.CR

TL;DR: MalFlows是一种新型的Android恶意软件检测技术，通过上下文感知融合异构流语义，利用异构信息网络（HIN）建模程序流语义，并结合flow2vec嵌入技术和深度神经网络实现高效分类。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以利用不同类型流之间的语义互补性，且缺乏上下文感知能力，导致跨流语义整合准确性不足。

Method: 采用HIN建模程序流语义，提出flow2vec嵌入技术，结合多路径学习和通道注意力机制进行分类。

Result: 在包含31,000多个真实应用的大规模数据集上，MalFlows优于现有基线方法，验证了flow2vec的有效性。

Conclusion: MalFlows首次全面整合多样流信息，显著提升了Android恶意软件检测的准确性。

Abstract: Static analysis, a fundamental technique in Android app examination, enables
the extraction of control flows, data flows, and inter-component communications
(ICCs), all of which are essential for malware detection. However, existing
methods struggle to leverage the semantic complementarity across different
types of flows for representing program behaviors, and their context-unaware
nature further hinders the accuracy of cross-flow semantic integration. We
propose and implement MalFlows, a novel technique that achieves context-aware
fusion of heterogeneous flow semantics for Android malware detection. Our goal
is to leverage complementary strengths of the three types of flow-related
information for precise app profiling. We adopt a heterogeneous information
network (HIN) to model the rich semantics across these program flows. We
further propose flow2vec, a context-aware HIN embedding technique that
distinguishes the semantics of HIN entities as needed based on contextual
constraints across different flows and learns accurate app representations
through the joint use of multiple meta-paths. The representations are finally
fed into a channel-attention-based deep neural network for malware
classification. To the best of our knowledge, this is the first study to
comprehensively aggregate the strengths of diverse flow-related information for
assessing maliciousness within apps. We evaluate MalFlows on a large-scale
dataset comprising over 20 million flow instances extracted from more than
31,000 real-world apps. Experimental results demonstrate that MalFlows
outperforms representative baselines in Android malware detection, and
meanwhile, validate the effectiveness of flow2vec in accurately learning app
representations from the HIN constructed over the heterogeneous flows.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [41] [Efficient Agents: Building Effective Agents While Reducing Cost](https://arxiv.org/abs/2508.02694)
*Ningning Wang,Xavier Hu,Pai Liu,He Zhu,Yue Hou,Heyuan Huang,Shengyu Zhang,Jian Yang,Jiaheng Liu,Ge Zhang,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型（LLM）驱动代理的效率与性能权衡，提出了高效代理框架Efficient Agents，在保持高性能的同时显著降低成本。


<details>
  <summary>Details</summary>
Motivation: LLM代理系统的成本不断上升，威胁其可扩展性和可访问性，需要在不牺牲性能的情况下设计更具成本效益的方案。

Method: 通过实证分析GAIA基准，评估LLM主干选择、代理框架设计和测试时扩展策略的影响，使用成本-通过指标量化效率与性能的权衡。

Result: 提出的Efficient Agents框架在保持96.7%性能的同时，将运营成本从0.398美元降至0.228美元，成本-通过指标提升28.4%。

Conclusion: 研究为设计高效、高性能的代理系统提供了实用见解，推动了AI驱动解决方案的可访问性和可持续性。

Abstract: The remarkable capabilities of Large Language Model (LLM)-driven agents have
enabled sophisticated systems to tackle complex, multi-step tasks, but their
escalating costs threaten scalability and accessibility. This work presents the
first systematic study of the efficiency-effectiveness trade-off in modern
agent systems, addressing the critical need for cost-effective designs without
sacrificing performance. We investigate three key questions: (1) How much
complexity do agentic tasks inherently require? (2) When do additional modules
yield diminishing returns? (3) How much efficiency can be gained through the
design of efficient agent frameworks? Through an empirical analysis on the GAIA
benchmark, we evaluate the impact of LLM backbone selection, agent framework
designs, and test-time scaling strategies. Using the cost-of-pass metric, we
quantify the efficiency-performance trade-off across these dimensions. Our
findings inform the development of Efficient Agents , a novel agent framework
that has an optimal complexity to task requirements. Efficient Agents retains
96.7% of the performance of OWL, one leading open-source agent framework, while
reducing operational costs from $0.398 to $0.228, resulting in a 28.4%
improvement in cost-of-pass. Our work provides actionable insights for
designing efficient, high-performing agent systems, advancing the accessibility
and sustainability of AI-driven solutions.

</details>


### [42] [Planning with Dynamically Changing Domains](https://arxiv.org/abs/2508.02697)
*Mikhail Soutchanski,Yongmei Liu*

Main category: cs.AI

TL;DR: 论文提出了一种无需领域闭包假设（DCA）的规划方法，适用于对象动态变化的场景，并证明了其完备性和正确性。


<details>
  <summary>Details</summary>
Motivation: 传统规划假设对象集合固定，但实际应用中对象可能动态变化，因此需要新的规划方法。

Method: 基于一阶逻辑的规划问题建模，限制计划长度，并在规划时对动作序列进行实例化搜索。

Result: 证明了方法的完备性和正确性，适用于无DCA的有限规划问题。

Conclusion: 该方法为动态对象规划问题提供了可行的解决方案，并通过概念验证实现展示了潜力。

Abstract: In classical planning and conformant planning, it is assumed that there are
finitely many named objects given in advance, and only they can participate in
actions and in fluents. This is the Domain Closure Assumption (DCA). However,
there are practical planning problems where the set of objects changes
dynamically as actions are performed; e.g., new objects can be created, old
objects can be destroyed. We formulate the planning problem in first-order
logic, assume an initial theory is a finite consistent set of fluent literals,
discuss when this guarantees that in every situation there are only finitely
many possible actions, impose a finite integer bound on the length of the plan,
and propose to organize search over sequences of actions that are grounded at
planning time. We show the soundness and completeness of our approach. It can
be used to solve the bounded planning problems without DCA that belong to the
intersection of sequential generalized planning (without sensing actions) and
conformant planning, restricted to the case without the disjunction over fluent
literals. We discuss a proof-of-the-concept implementation of our planner.

</details>


### [43] [Recovering Individual-Level Activity Sequences from Location-Based Service Data Using a Novel Transformer-Based Model](https://arxiv.org/abs/2508.02734)
*Weiyu Luo,Chenfeng Xiong*

Main category: cs.AI

TL;DR: 提出了一种名为VSNIT的新方法，用于从不完整的LBS数据中恢复活动序列，表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: LBS数据的稀疏性导致活动序列不完整，难以准确推断出行和活动，因此需要一种有效的方法来恢复缺失数据。

Method: 结合Insertion Transformer的灵活序列构建和Variable Selection Network的动态协变量处理能力，提出VSNIT模型，用于恢复缺失的活动序列片段。

Result: VSNIT能生成更多样化且真实的活动模式，更接近真实世界的变异性，并在所有指标上显著优于基线模型。

Conclusion: VSNIT在活动序列恢复任务中表现出更高的准确性和多样性，为未来基于位置的研究和应用提供了有前景的框架。

Abstract: Location-Based Service (LBS) data provides critical insights into human
mobility, yet its sparsity often yields incomplete trip and activity sequences,
making accurate inferences about trips and activities difficult. We raise a
research problem: Can we use activity sequences derived from high-quality LBS
data to recover incomplete activity sequences at the individual level? This
study proposes a new solution, the Variable Selection Network-fused Insertion
Transformer (VSNIT), integrating the Insertion Transformer's flexible sequence
construction with the Variable Selection Network's dynamic covariate handling
capability, to recover missing segments in incomplete activity sequences while
preserving existing data. The findings show that VSNIT inserts more diverse,
realistic activity patterns, more closely matching real-world variability, and
restores disrupted activity transitions more effectively aligning with the
target. It also performs significantly better than the baseline model across
all metrics. These results highlight VSNIT's superior accuracy and diversity in
activity sequence recovery tasks, demonstrating its potential to enhance LBS
data utility for mobility analysis. This approach offers a promising framework
for future location-based research and applications.

</details>


### [44] [Large Language Model-based Data Science Agent: A Survey](https://arxiv.org/abs/2508.02744)
*Peiran Wang,Yaoning Yu,Ke Chen,Xianyang Zhan,Haohan Wang*

Main category: cs.AI

TL;DR: 本文综述了基于大语言模型（LLM）的代理在数据科学任务中的应用，从代理和数据科学双视角分析了设计原则和关键流程。


<details>
  <summary>Details</summary>
Motivation: 探索LLM代理在数据科学任务中的潜力，总结最新研究进展。

Method: 从代理视角讨论设计原则（角色、执行、知识、反思），从数据科学视角梳理关键流程（数据预处理、模型开发等）。

Result: 提出了双视角框架，连接代理设计原则与数据科学实践。

Conclusion: 为LLM代理在数据科学中的应用提供了系统综述和实用框架。

Abstract: The rapid advancement of Large Language Models (LLMs) has driven novel
applications across diverse domains, with LLM-based agents emerging as a
crucial area of exploration. This survey presents a comprehensive analysis of
LLM-based agents designed for data science tasks, summarizing insights from
recent studies. From the agent perspective, we discuss the key design
principles, covering agent roles, execution, knowledge, and reflection methods.
From the data science perspective, we identify key processes for LLM-based
agents, including data preprocessing, model development, evaluation,
visualization, etc. Our work offers two key contributions: (1) a comprehensive
review of recent developments in applying LLMbased agents to data science
tasks; (2) a dual-perspective framework that connects general agent design
principles with the practical workflows in data science.

</details>


### [45] [Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science](https://arxiv.org/abs/2508.02789)
*Newman Cheng,Gordon Broadbent,William Chappell*

Main category: cs.AI

TL;DR: 论文提出了一种名为CLIO的方法，通过动态优化实现AI的深度推理控制，显著提升了GPT-4.1在生物学和医学问题上的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有AI框架在科学发现中缺乏透明性和可操控性，科学家需要更精确的推理控制方法。

Method: 引入CLIO（认知循环动态优化），使大型语言模型能够自我调整推理过程，并通过开放设计让科学家干预和观察。

Result: CLIO使GPT-4.1在HLE测试中的准确率提升至22.37%，相对提升161.64%，并揭示了内部不确定性波动对结果的影响。

Conclusion: CLIO为科学决策提供了透明和可控的推理机制，展示了其在科学发现中的潜力。

Abstract: The capacity for artificial intelligence (AI) to formulate, evolve, and test
altered thought patterns under dynamic conditions indicates advanced cognition
that is crucial for scientific discovery. The existing AI development landscape
falls into two categories: 1) frameworks over non-reasoning models that
natively incorporate opinions on how humans think, and 2) reasoning models that
abstract precise control of the reasoning intuition away from end users. While
powerful, for scientists to maximize utility of AI in scientific discovery,
they not only require accuracy and transparency in reasoning, but also
steerability. Hence, we introduce an alternative approach that enables deep and
precise control over the reasoning process called: a cognitive loop via in-situ
optimization (CLIO). CLIO enables large language models (LLMs) to
self-formulate ways of approaching a problem, adapt behavior when
self-confidence is low, and ultimately provide scientists with a final belief
or answer. Through CLIO's open design, scientists can observe uncertainty
levels, understand how final belief states are formulated using graph
structures, and interject corrections. Without any further post-training,
OpenAI's GPT-4.1 with CLIO yields an accuracy of 22.37\% in text-based biology
and medicine questions on Humanity's Last Exam (HLE). This yields a 13.82\% net
or 161.64\% relative increase when compared to the base GPT-4.1 model and
surpasses OpenAI's o3 performance in high and low reasoning effort modes. We
further discovered that oscillations within internal uncertainty measures are
key in determining the accuracy of CLIO's results, revealing how its open
design and internal mechanisms can provide insight and control into scientific
decision-making processes.

</details>


### [46] [A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering](https://arxiv.org/abs/2508.02841)
*Ziruo Yi,Jinyu Liu,Ting Xiao,Mark V. Albert*

Main category: cs.AI

TL;DR: 提出了一种多代理系统（MAS）用于放射学视觉问答（RVQA），通过专业代理解决事实准确性、幻觉和跨模态对齐问题，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 减轻放射科医生的工作负担，并解决现有基于多模态大语言模型（MLLMs）和检索增强生成（RAG）方法在RVQA中的事实准确性、幻觉和跨模态对齐问题。

Method: 设计了一个多代理系统（MAS），包含上下文理解、多模态推理和答案验证的专业代理，并通过模型分歧过滤筛选的挑战性RVQA数据集进行评估。

Result: 实验表明，该系统在挑战性RVQA数据集上优于现有MLLM基线，具有可靠性和可解释性。

Conclusion: 多代理方法在需要复杂推理的可解释和可信赖临床AI应用中具有潜力。

Abstract: Radiology visual question answering (RVQA) provides precise answers to
questions about chest X-ray images, alleviating radiologists' workload. While
recent methods based on multimodal large language models (MLLMs) and
retrieval-augmented generation (RAG) have shown promising progress in RVQA,
they still face challenges in factual accuracy, hallucinations, and cross-modal
misalignment. We introduce a multi-agent system (MAS) designed to support
complex reasoning in RVQA, with specialized agents for context understanding,
multimodal reasoning, and answer validation. We evaluate our system on a
challenging RVQA set curated via model disagreement filtering, comprising
consistently hard cases across multiple MLLMs. Extensive experiments
demonstrate the superiority and effectiveness of our system over strong MLLM
baselines, with a case study illustrating its reliability and interpretability.
This work highlights the potential of multi-agent approaches to support
explainable and trustworthy clinical AI applications that require complex
reasoning.

</details>


### [47] [Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game](https://arxiv.org/abs/2508.02900)
*Michael Katz,Harsha Kokel,Sarath Sreedharan*

Main category: cs.AI

TL;DR: 论文提出了一种基于游戏Countdown的规划基准测试方法，弥补现有基准测试的不足，并通过理论分析和实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有规划基准测试无法准确衡量基础模型和智能体的长期规划能力，亟需一种更合适的评估方法。

Method: 提出基于Countdown游戏的规划基准测试生成方法，分析其计算复杂性，并与现有基准测试对比。

Result: 实验表明，该动态基准测试对现有LLM辅助规划方法极具挑战性。

Conclusion: Countdown游戏是一种理想的规划能力评估基准，为未来研究提供了新方向。

Abstract: There is a broad consensus that the inability to form long-term plans is one
of the key limitations of current foundational models and agents. However, the
existing planning benchmarks remain woefully inadequate to truly measure their
planning capabilities. Most existing benchmarks either focus on loosely defined
tasks like travel planning or end up leveraging existing domains and problems
from international planning competitions. While the former tasks are hard to
formalize and verify, the latter were specifically designed to test and
challenge the weaknesses of existing automated planners. To address these
shortcomings, we propose a procedure for creating a planning benchmark centered
around the game called Countdown, where a player is expected to form a target
number from a list of input numbers through arithmetic operations. We discuss
how this problem meets many of the desiderata associated with an ideal
benchmark for planning capabilities evaluation. Specifically, the domain allows
for an intuitive, natural language description for each problem instance, it is
computationally challenging (NP-complete), and the instance space is rich
enough that we do not have to worry about memorization. We perform an extensive
theoretical analysis, establishing the computational complexity result and
demonstrate the advantage of our instance generation procedure over public
benchmarks. We evaluate a variety of existing LLM-assisted planning methods on
instances generated using our procedure. Our results show that, unlike other
domains like 24 Game (a special case of Countdown), our proposed dynamic
benchmark remains extremely challenging for existing LLM-based approaches.

</details>


### [48] [Enhancing Japanese Large Language Models with Reasoning Vectors](https://arxiv.org/abs/2508.02913)
*Carolina Minami Oguchi,Leo Wei,Koyo Kobayashi,Hsin-Tai Wu,Dipak Ghosal*

Main category: cs.AI

TL;DR: 通过从推理LLMs中提取推理向量并应用于日语LLMs，提升其性能，解决了资源不足的问题。


<details>
  <summary>Details</summary>
Motivation: 由于资源限制，日语LLMs的性能提升困难，本文旨在通过简单有效的方法解决这一问题。

Method: 从推理LLMs中提取推理向量（任务向量的变体），并将其应用于日语LLMs。

Result: 显著提升了日语LLMs的性能，方法简单且有效。

Conclusion: 该方法为资源有限的语言模型性能提升提供了新思路，对其他语言也有启发意义。

Abstract: Post-training methods have improved the performance and enhanced the
reasoning capability for mainstream large language models (LLMs), but the same
is challenging for Japanese LLMs to achieve due to the amount of resources
required. Inspired by task vectors that extract the change of weights before
and after training, specifically for a certain task, we obtain reasoning
vectors from reasoning LLMs and apply them to Japanese LLMs to boost their
performance. While the resources available present a challenge to improve
Japanese LLMs, we present a simple and effective way to obtain high improvement
and hope to inspire for other languages.

</details>


### [49] [PentestJudge: Judging Agent Behavior Against Operational Requirements](https://arxiv.org/abs/2508.02921)
*Shane Caldwell,Max Harley,Michael Kouremetis,Vincent Abruzzo,Will Pearce*

Main category: cs.AI

TL;DR: PentestJudge是一个基于大型语言模型（LLM）的系统，用于评估渗透测试代理的操作，通过分层任务分解和简单标准实现高效评分，并与人类专家评分对比。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够高效评估渗透测试代理操作的系统，以解决程序化评估的局限性。

Method: 使用树状结构将渗透测试任务分解为更小的子任务和标准，通过LLM作为评委进行评分，并与人类专家评分对比。

Result: 最佳模型的F1分数达到0.83，工具使用能力强的模型更接近人类专家评分。

Conclusion: PentestJudge展示了LLM在评估渗透测试任务中的潜力，验证可能比生成更容易，为未来研究提供了方法论支持。

Abstract: We introduce PentestJudge, a system for evaluating the operations of
penetration testing agents. PentestJudge is a large language model
(LLM)-as-judge with access to tools that allow it to consume arbitrary
trajectories of agent states and tool call history to determine whether a
security agent's actions meet certain operating criteria that would be
impractical to evaluate programmatically. We develop rubrics that use a tree
structure to hierarchically collapse the penetration testing task for a
particular environment into smaller, simpler, and more manageable sub-tasks and
criteria until each leaf node represents simple yes-or-no criteria for
PentestJudge to evaluate. Task nodes are broken down into different categories
related to operational objectives, operational security, and tradecraft.
LLM-as-judge scores are compared to human domain experts as a ground-truth
reference, allowing us to compare their relative performance with standard
binary classification metrics, such as F1 scores. We evaluate several frontier
and open-source models acting as judge agents, with the best model reaching an
F1 score of 0.83. We find models that are better at tool-use perform more
closely to human experts. By stratifying the F1 scores by requirement type, we
find even models with similar overall scores struggle with different types of
questions, suggesting certain models may be better judges of particular
operating criteria. We find that weaker and cheaper models can judge the
trajectories of pentests performed by stronger and more expensive models,
suggesting verification may be easier than generation for the penetration
testing task. We share this methodology to facilitate future research in
understanding the ability of judges to holistically and scalably evaluate the
process quality of AI-based information security agents so that they may be
confidently used in sensitive production environments.

</details>


### [50] [AQUAH: Automatic Quantification and Unified Agent in Hydrology](https://arxiv.org/abs/2508.02936)
*Songkun Yan,Zhi Li,Siyu Zhu,Yixin Wen,Mofan Zhang,Mengye Chen,Jie Cao,Yang Hong*

Main category: cs.AI

TL;DR: AQUAH是一个基于语言的端到端水文建模代理，通过自然语言提示自动完成数据检索、模型配置、模拟运行和报告生成，初步实验显示其效果清晰透明。


<details>
  <summary>Details</summary>
Motivation: 旨在简化复杂的环境建模流程，降低地球观测数据、物理工具与决策者之间的门槛。

Method: 利用视觉增强的大型语言模型，动态解析地图和栅格数据，指导关键决策如出口选择和参数初始化。

Result: 在多个美国流域的实验中，AQUAH能够完成冷启动模拟并生成分析师就绪的文档，结果被专家评价为清晰且物理合理。

Conclusion: 尽管仍需进一步校准和验证，AQUAH展示了基于LLM和视觉的代理在环境建模中的潜力。

Abstract: We introduce AQUAH, the first end-to-end language-based agent designed
specifically for hydrologic modeling. Starting from a simple natural-language
prompt (e.g., 'simulate floods for the Little Bighorn basin from 2020 to
2022'), AQUAH autonomously retrieves the required terrain, forcing, and gauge
data; configures a hydrologic model; runs the simulation; and generates a
self-contained PDF report. The workflow is driven by vision-enabled large
language models, which interpret maps and rasters on the fly and steer key
decisions such as outlet selection, parameter initialization, and uncertainty
commentary. Initial experiments across a range of U.S. basins show that AQUAH
can complete cold-start simulations and produce analyst-ready documentation
without manual intervention. The results are judged by hydrologists as clear,
transparent, and physically plausible. While further calibration and validation
are still needed for operational deployment, these early outcomes highlight the
promise of LLM-centered, vision-grounded agents to streamline complex
environmental modeling and lower the barrier between Earth observation data,
physics-based tools, and decision makers.

</details>


### [51] [MedBLINK: Probing Basic Perception in Multimodal Language Models for Medicine](https://arxiv.org/abs/2508.02951)
*Mahtab Bigverdi,Wisdom Ikezogwo,Kevin Zhang,Hyewon Jeong,Mingyu Lu,Sungjae Cho,Linda Shapiro,Ranjay Krishna*

Main category: cs.AI

TL;DR: Medblink基准测试评估多模态语言模型在临床感知任务中的表现，发现其准确性远低于人类，需改进视觉基础以支持临床应用。


<details>
  <summary>Details</summary>
Motivation: 临床医生对AI工具的选择性高，模型在简单感知任务中的错误会阻碍其临床采用。

Method: 引入Medblink基准，涵盖8个临床任务，共1,429道多选题和1,605张图像，评估19种先进MLM。

Result: 人类准确率96.4%，最佳模型仅65%，显示MLM在常规感知任务中表现不足。

Conclusion: 需加强MLM的视觉基础能力以提升临床实用性。

Abstract: Multimodal language models (MLMs) show promise for clinical decision support
and diagnostic reasoning, raising the prospect of end-to-end automated medical
image interpretation. However, clinicians are highly selective in adopting AI
tools; a model that makes errors on seemingly simple perception tasks such as
determining image orientation or identifying whether a CT scan is
contrast-enhance are unlikely to be adopted for clinical tasks. We introduce
Medblink, a benchmark designed to probe these models for such perceptual
abilities. Medblink spans eight clinically meaningful tasks across multiple
imaging modalities and anatomical regions, totaling 1,429 multiple-choice
questions over 1,605 images. We evaluate 19 state-of-the-art MLMs, including
general purpose (GPT4o, Claude 3.5 Sonnet) and domain specific (Med Flamingo,
LLaVA Med, RadFM) models. While human annotators achieve 96.4% accuracy, the
best-performing model reaches only 65%. These results show that current MLMs
frequently fail at routine perceptual checks, suggesting the need to strengthen
their visual grounding to support clinical adoption. Data is available on our
project page.

</details>


### [52] [Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow](https://arxiv.org/abs/2508.02959)
*Chia-Tung Ho,Jing Gong,Xufeng Yao,Yunsheng Bai,Abhishek B Akkur,Haoxing Ren*

Main category: cs.AI

TL;DR: Polymath是一种自优化代理，通过动态分层工作流和代码表示的工作流解决现实动态问题，无需标记数据，性能提升8.1%。


<details>
  <summary>Details</summary>
Motivation: 现有基于标记数据的工作流生成方法在动态问题中效果有限，需要一种无需标记数据的自优化方法。

Method: 结合任务流图的灵活性和代码表示的工作流，采用多网格图优化和自反射进化算法优化工作流。

Result: 在六个基准数据集上平均性能提升8.1%。

Conclusion: Polymath在无需标记数据的情况下显著提升了动态问题的解决能力。

Abstract: Large language models (LLMs) excel at solving complex tasks by executing
agentic workflows composed of detailed instructions and structured operations.
Yet, building general-purpose agents by manually embedding foundation models
into agentic systems such as Chain-of-Thought, Self-Reflection, and ReACT
through text interfaces limits scalability and efficiency. Recently, many
researchers have sought to automate the generation and optimization of these
workflows through code-based representations. However, existing methods often
rely on labeled datasets to train and optimize workflows, making them
ineffective and inflexible for solving real-world, dynamic problems where
labeled data is unavailable. To address this challenge, we introduce Polymath,
a self-optimizing agent with dynamic hierarchical workflow that leverages the
flexibility of task flow graphs and the expressiveness of code-represented
workflows to solve a wide range of real-world, dynamic problems. The proposed
optimization methodology integrates multi-grid-inspired graph optimization with
a self-reflection-guided evolutionary algorithm to refine workflows without
labeled data. Experimental results on six benchmark datasets across coding,
math, and multi-turn QA tasks show that Polymath achieves 8.1% average
improvement over state-of-the-art baselines.

</details>


### [53] [Defend LLMs Through Self-Consciousness](https://arxiv.org/abs/2508.02961)
*Boshi Huang,Fabio Nonato de Paula*

Main category: cs.AI

TL;DR: 论文提出了一种新型的自意识防御机制，利用LLM的推理能力自主对抗提示注入攻击，显著提高了防御成功率。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖外部分类器，而本方法利用LLM的内在能力，提供轻量级、经济高效的解决方案。

Method: 通过引入元认知和仲裁模块，使LLM能够自主评估和调节输出。

Result: 在七个先进LLM上测试，防御成功率显著提升，部分模型在增强模式下实现完美防御。

Conclusion: 该方法为提升LLM伦理提供了一种高效且低成本的解决方案，适用于多种GenAI应用场景。

Abstract: This paper introduces a novel self-consciousness defense mechanism for Large
Language Models (LLMs) to combat prompt injection attacks. Unlike traditional
approaches that rely on external classifiers, our method leverages the LLM's
inherent reasoning capabilities to perform self-protection. We propose a
framework that incorporates Meta-Cognitive and Arbitration Modules, enabling
LLMs to evaluate and regulate their own outputs autonomously. Our approach is
evaluated on seven state-of-the-art LLMs using two datasets: AdvBench and
Prompt-Injection-Mixed-Techniques-2024. Experiment results demonstrate
significant improvements in defense success rates across models and datasets,
with some achieving perfect and near-perfect defense in Enhanced Mode. We also
analyze the trade-off between defense success rate improvement and
computational overhead. This self-consciousness method offers a lightweight,
cost-effective solution for enhancing LLM ethics, particularly beneficial for
GenAI use cases across various platforms.

</details>


### [54] [Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling](https://arxiv.org/abs/2508.02979)
*Peng Ding,Rick Stevens*

Main category: cs.AI

TL;DR: 提出了一种统一工具集成方法，通过协议无关设计减少开发负担，实验显示代码减少60-80%，性能提升3.1倍。


<details>
  <summary>Details</summary>
Motivation: 解决工具增强型大语言模型生态碎片化问题，简化多协议、复杂工作流的开发挑战。

Method: 采用协议无关设计原则，自动化生成模式，双模式并发执行，多源工具无缝管理。

Result: 代码减少60-80%，性能提升达3.1倍，完全兼容现有函数调用标准。

Conclusion: 为工具集成架构提供理论见解，并为实际LLM应用开发提供实用解决方案。

Abstract: The proliferation of tool-augmented Large Language Models (LLMs) has created
a fragmented ecosystem where developers must navigate multiple protocols,
manual schema definitions, and complex execution workflows. We address this
challenge by proposing a unified approach to tool integration that abstracts
protocol differences while optimizing execution performance. Our solution
demonstrates how protocol-agnostic design principles can significantly reduce
development overhead through automated schema generation, dual-mode concurrent
execution, and seamless multi-source tool management. Experimental results show
60-80% code reduction across integration scenarios, performance improvements up
to 3.1x through optimized concurrency, and full compatibility with existing
function calling standards. This work contributes both theoretical insights
into tool integration architecture and practical solutions for real-world LLM
application development.

</details>


### [55] [When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs](https://arxiv.org/abs/2508.02994)
*Fangyi Yu*

Main category: cs.AI

TL;DR: 论文探讨了使用AI代理作为评估者（"agent-as-a-judge"）的新范式，以解决大型语言模型（LLMs）输出评估的瓶颈问题，并分析了其优缺点及实际应用。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs能力和自主性的提升，其输出的评估成为关键瓶颈，需要可扩展且细致的替代方案。

Method: 定义了"agent-as-a-judge"概念，追溯了从单模型评估到动态多代理辩论框架的演变，并比较了可靠性、成本和人类对齐等方面。

Result: 展示了在医疗、法律、金融和教育等领域的实际应用，同时指出了偏见、鲁棒性和元评估等挑战。

Conclusion: 基于代理的评估可以补充（而非替代）人类监督，为下一代LLMs的可信、可扩展评估迈出一步。

Abstract: As large language models (LLMs) grow in capability and autonomy, evaluating
their outputs-especially in open-ended and complex tasks-has become a critical
bottleneck. A new paradigm is emerging: using AI agents as the evaluators
themselves. This "agent-as-a-judge" approach leverages the reasoning and
perspective-taking abilities of LLMs to assess the quality and safety of other
models, promising calable and nuanced alternatives to human evaluation. In this
review, we define the agent-as-a-judge concept, trace its evolution from
single-model judges to dynamic multi-agent debate frameworks, and critically
examine their strengths and shortcomings. We compare these approaches across
reliability, cost, and human alignment, and survey real-world deployments in
domains such as medicine, law, finance, and education. Finally, we highlight
pressing challenges-including bias, robustness, and meta evaluation-and outline
future research directions. By bringing together these strands, our review
demonstrates how agent-based judging can complement (but not replace) human
oversight, marking a step toward trustworthy, scalable evaluation for
next-generation LLMs.

</details>


### [56] [AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots](https://arxiv.org/abs/2508.02999)
*Xinjie Zhao,Moritz Blum,Fan Gao,Yingjian Chen,Boming Yang,Luis Marquez-Carpintero,Mónica Pina-Navarro,Yanran Fu,So Morikawa,Yusuke Iwasawa,Yutaka Matsuo,Chanjun Park,Irene Li*

Main category: cs.AI

TL;DR: AGENTiGraph是一个用户友好的代理驱动系统，通过自然语言操作知识图谱实现直观交互和领域数据管理，为非技术用户提供可视化解决方案。


<details>
  <summary>Details</summary>
Motivation: 为非技术用户提供无需专业查询语言即可构建和优化知识库的工具，支持多轮对话和动态更新。

Method: 系统设计包括意图分类、任务规划和自动知识集成，支持多样化任务的无缝推理。

Result: 在3500查询的教育场景基准测试中，系统表现优于零样本基线（分类准确率95.12%，执行成功率90.45%）。

Conclusion: AGENTiGraph展示了在法律和医疗等领域处理复杂查询的潜力，为多轮企业知识管理提供了新范式。

Abstract: AGENTiGraph is a user-friendly, agent-driven system that enables intuitive
interaction and management of domain-specific data through the manipulation of
knowledge graphs in natural language. It gives non-technical users a complete,
visual solution to incrementally build and refine their knowledge bases,
allowing multi-round dialogues and dynamic updates without specialized query
languages. The flexible design of AGENTiGraph, including intent classification,
task planning, and automatic knowledge integration, ensures seamless reasoning
between diverse tasks. Evaluated on a 3,500-query benchmark within an
educational scenario, the system outperforms strong zero-shot baselines
(achieving 95.12% classification accuracy, 90.45% execution success),
indicating potential scalability to compliance-critical or multi-step queries
in legal and medical domains, e.g., incorporating new statutes or research on
the fly. Our open-source demo offers a powerful new paradigm for multi-turn
enterprise knowledge management that bridges LLMs and structured graphs.

</details>


### [57] [Beyond Policy Optimization: A Data Curation Flywheel for Sparse-Reward Long-Horizon Planning](https://arxiv.org/abs/2508.03018)
*Yutong Wang,Pengliang Ji,Kaixin Li,Baolong Bi,Tao Feng,Guillaume Sartoretti*

Main category: cs.AI

TL;DR: BPO框架通过三阶段（引导、外推和优化）解决大型语言推理模型在多轮代理规划中的挑战，显著提升稀疏奖励环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多轮代理规划中稀疏奖励和计算开销大的问题。

Method: 提出BPO框架，包括引导（规划四元组和长短链思维融合）、外推（复杂度分层课程学习）和优化（奖励门控拒绝采样）。

Result: 在ALFWorld、ScienceWorld和WebShop上实现最优性能，且具有高效性。

Conclusion: BPO为代理规划中的推理模型提供了新方法，显著提升效率和性能。

Abstract: Large Language Reasoning Models have demonstrated remarkable success on
static tasks, yet their application to multi-round agentic planning in
interactive environments faces two fundamental challenges. First, the
intractable credit assignment problem renders conventional reinforcement
learning ineffective in sparse-reward settings. Second, the computational
overhead of verbose, step-by-step reasoning histories is prohibitive. To
address these challenges, we propose BPO, a three-stage framework
(bootstrapping, extrapolation, and refinement) that establishes a
self-improving data flywheel to develop robust reasoning models for
long-horizon, sparse-reward environments. Our framework first bootstraps
efficient reasoning using the proposed planning quaternions with long-short
chain-of-thought fusion. It then extrapolates to out-of-distribution tasks
through complexity-stratified curriculum learning. Finally, the model
iteratively refines itself by learning exclusively on experiences selected via
reward-gated rejection sampling. Experiments on ALFWorld, ScienceWorld, and
WebShop demonstrate that our approach achieves state-of-the-art with
significant token efficiency, providing a new recipe for reasoning models in
agentic planning.

</details>


### [58] [T2UE: Generating Unlearnable Examples from Text Descriptions](https://arxiv.org/abs/2508.03091)
*Xingjun Ma,Hanxun Huang,Tianwei Song,Ye Sun,Yifeng Gao,Yu-Gang Jiang*

Main category: cs.AI

TL;DR: T2UE框架通过仅使用文本描述生成不可学习示例（UEs），解决了传统方法需要暴露原始数据的隐私矛盾。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成UEs需要联合优化图像和文本，计算成本高且依赖第三方服务，导致隐私泄露。

Method: T2UE利用文本到图像模型将文本映射到噪声空间，结合误差最小化框架生成UEs。

Result: 实验表明，T2UE显著降低了下游任务性能，且保护效果泛化到多种架构和监督学习。

Conclusion: T2UE实现了“零接触数据保护”，仅需文本描述即可保护数据隐私。

Abstract: Large-scale pre-training frameworks like CLIP have revolutionized multimodal
learning, but their reliance on web-scraped datasets, frequently containing
private user data, raises serious concerns about misuse. Unlearnable Examples
(UEs) have emerged as a promising countermeasure against unauthorized model
training, employing carefully crafted unlearnable noise to disrupt the learning
of meaningful representations from protected data. Current approaches typically
generate UEs by jointly optimizing unlearnable noise for both images and their
associated text descriptions (or labels). However, this optimization process is
often computationally prohibitive for on-device execution, forcing reliance on
external third-party services. This creates a fundamental privacy paradox:
users must initially expose their data to these very services to achieve
protection, thereby compromising privacy in the process. Such a contradiction
has severely hindered the development of practical, scalable data protection
solutions. To resolve this paradox, we introduce \textbf{Text-to-Unlearnable
Example (T2UE)}, a novel framework that enables users to generate UEs using
only text descriptions. T2UE circumvents the need for original image data by
employing a text-to-image (T2I) model to map text descriptions into the image
(noise) space, combined with an error-minimization framework to produce
effective unlearnable noise. Extensive experiments show that T2UE-protected
data substantially degrades performance in downstream tasks (e.g., cross-modal
retrieval) for state-of-the-art models. Notably, the protective effect
generalizes across diverse architectures and even to supervised learning
settings. Our work demonstrates the feasibility of "zero-contact data
protection", where personal data can be safeguarded based solely on their
textual descriptions, eliminating the need for direct data exposure.

</details>


### [59] [Collab-Solver: Collaborative Solving Policy Learning for Mixed-Integer Linear Programming](https://arxiv.org/abs/2508.03030)
*Siyuan Li,Yifan Yu,Yanchen Deng,Zhihao Zhang,Mengjing Chen,Fangzhou Zhu,Tao Zhong,Jianye Hao,Peng Liu,Bo An*

Main category: cs.AI

TL;DR: 提出了一种基于多智能体的协作学习框架（Collab-Solver），通过Stackelberg博弈建模MILP求解中割平面选择与分支的协作，显著提升了求解性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的MILP方法独立处理各模块的策略学习，忽视了模块间的相互依赖，影响了求解速度与质量。

Method: 采用Stackelberg博弈建模割平面选择与分支的协作，设计两阶段学习范式：数据通信的预训练阶段与模块间策略协调阶段。

Result: 在合成和大规模真实MILP数据集上显著提升求解性能，且策略展现出优秀的跨实例集泛化能力。

Conclusion: Collab-Solver通过协作学习框架有效解决了模块间策略独立学习的问题，为MILP求解提供了新思路。

Abstract: Mixed-integer linear programming (MILP) has been a fundamental problem in
combinatorial optimization. Previous works have designed a plethora of
hard-coded heuristics to accomplish challenging MILP solving with domain
knowledge. Driven by the high capability of neural networks, recent research is
devoted to replacing manually designed heuristics with learned policies.
Although learning-based MILP methods have shown great promise, existing
worksindependentlytreatthepolicylearningineachmoduleofMILPsolvers without
considering their interdependence, severely hurting the solving speed and
quality. To address this issue, we propose a novel multi-agent-based policy
learning framework for MILP (Collab-Solver), which can collaboratively optimize
the policies for multiple modules. Specifically, we formulate the collaboration
of cut selection and branching in MILP solving as a Stackelberg game. Under
this formulation, we develop a two-phase learning paradigm to stabilize the
collaborative policy learning, where the first phase achieves the
data-communicated policy pretraining and the second phase further orchestrates
the policy learning for various modules. The jointly learned policy
significantly improves the solving performance on both synthetic and
large-scale real-world MILP datasets. Moreover, the policies learned by
Collab-Solver have also demonstrated excellent generalization abilities across
different instance sets.

</details>


### [60] [From Text to Trajectories: GPT-2 as an ODE Solver via In-Context](https://arxiv.org/abs/2508.03031)
*Ziyang Ma,Baojian Zhou,Deqing Yang,Yanghua Xiao*

Main category: cs.AI

TL;DR: 论文研究了LLMs在ICL设置下解决ODE问题的能力，发现GPT-2能有效学习元ODE算法，性能优于欧拉方法，并展示出泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索ICL在NLP任务中的非线性行为机制，以及其在解决ODE问题中的潜力。

Method: 将ODE问题及其解作为序列提示，评估GPT-2模型在两类ODE任务上的表现。

Result: GPT-2能学习元ODE算法，性能优于欧拉方法，且随着示例增加精度提升；模型还展示了OOD泛化能力。

Conclusion: 研究为ICL机制提供了新见解，并展示了其在非线性数值问题中的潜力。

Abstract: In-Context Learning (ICL) has emerged as a new paradigm in large language
models (LLMs), enabling them to perform novel tasks by conditioning on a few
examples embedded in the prompt. Yet, the highly nonlinear behavior of ICL for
NLP tasks remains poorly understood. To shed light on its underlying
mechanisms, this paper investigates whether LLMs can solve ordinary
differential equations (ODEs) under the ICL setting. We formulate standard ODE
problems and their solutions as sequential prompts and evaluate GPT-2 models on
these tasks. Experiments on two types of ODEs show that GPT-2 can effectively
learn a meta-ODE algorithm, with convergence behavior comparable to, or better
than, the Euler method, and achieve exponential accuracy gains with increasing
numbers of demonstrations. Moreover, the model generalizes to
out-of-distribution (OOD) problems, demonstrating robust extrapolation
capabilities. These empirical findings provide new insights into the mechanisms
of ICL in NLP and its potential for solving nonlinear numerical problems.

</details>


### [61] [Tree-of-Reasoning: Towards Complex Medical Diagnosis via Multi-Agent Reasoning with Evidence Tree](https://arxiv.org/abs/2508.03038)
*Qi Peng,Jialin Cui,Jiayuan Xie,Yi Cai,Qing Li*

Main category: cs.AI

TL;DR: 提出Tree-of-Reasoning (ToR)框架，通过树状结构和交叉验证机制提升大型语言模型在复杂医疗诊断任务中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在复杂医疗诊断任务中因推理深度不足导致信息丢失或逻辑跳跃，影响诊断准确性。

Method: 提出ToR框架，采用树状结构记录推理路径和临床证据，并引入交叉验证机制确保多智能体决策一致性。

Result: 在真实医疗数据上的实验表明，ToR框架优于现有基线方法。

Conclusion: ToR框架通过结构化推理和验证机制，显著提升了复杂医疗场景中的诊断性能。

Abstract: Large language models (LLMs) have shown great potential in the medical
domain. However, existing models still fall short when faced with complex
medical diagnosis task in the real world. This is mainly because they lack
sufficient reasoning depth, which leads to information loss or logical jumps
when processing a large amount of specialized medical data, leading to
diagnostic errors. To address these challenges, we propose Tree-of-Reasoning
(ToR), a novel multi-agent framework designed to handle complex scenarios.
Specifically, ToR introduces a tree structure that can clearly record the
reasoning path of LLMs and the corresponding clinical evidence. At the same
time, we propose a cross-validation mechanism to ensure the consistency of
multi-agent decision-making, thereby improving the clinical reasoning ability
of multi-agents in complex medical scenarios. Experimental results on
real-world medical data show that our framework can achieve better performance
than existing baseline methods.

</details>


### [62] [Beyond Surface-Level Detection: Towards Cognitive-Driven Defense Against Jailbreak Attacks via Meta-Operations Reasoning](https://arxiv.org/abs/2508.03054)
*Rui Pu,Chaozhuo Li,Rui Ha,Litian Zhang,Lirong Qiu,Xi Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种认知驱动防御（CDD）框架，通过模拟人类认知推理来防御大型语言模型的越狱攻击，结合监督微调和强化学习提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法依赖浅层模式匹配，难以应对新型攻击策略，因此需要更通用的防御机制。

Method: CDD框架通过全局感知和局部分析揭示隐藏操作，结合监督微调和熵引导的强化学习（EG-GRPO）探索新攻击变体。

Result: 实验表明CDD在防御性能和泛化能力上达到最先进水平。

Conclusion: CDD框架为LLM防御提供了有效且通用的解决方案。

Abstract: Defending large language models (LLMs) against jailbreak attacks is essential
for their safe and reliable deployment. Existing defenses often rely on shallow
pattern matching, which struggles to generalize to novel and unseen attack
strategies. To address this challenge, we propose the Cognitive-Driven Defense
(CDD) framework, which targets the underlying structure of jailbreak prompts by
applying meta-operations, defined as basic manipulations that conceal harmful
intent.CDD emulates human cognitive reasoning through a structured reasoning
chain. It begins with a global perception of the prompt and follows with a
localized analysis to uncover hidden manipulations. By applying supervised
fine-tuning on this structured chain, the model learns to identify and reason
about known manipulation patterns. To enhance generalization to unseen threats,
an entropy-guided reinforcement learning algorithm (EG-GRPO) is introduced to
encourage exploration of new types and variants of meta-operations. Experiments
demonstrate that CDD can achieve state-of-the-art defense performance and
exhibit strong generalization to unseen jailbreak attacks.

</details>


### [63] [ContractEval: Benchmarking LLMs for Clause-Level Legal Risk Identification in Commercial Contracts](https://arxiv.org/abs/2508.03080)
*Shuang Liu,Zelong Li,Ruoyun Ma,Haiyan Zhao,Mengnan Du*

Main category: cs.AI

TL;DR: 论文评估开源与专有大语言模型在法律风险分析中的表现，发现专有模型总体更优，开源模型需针对性优化。


<details>
  <summary>Details</summary>
Motivation: 探索开源大语言模型在法律领域的潜力，满足本地部署需求并保护数据隐私。

Method: 使用ContractEval基准和CUAD数据集评估4个专有和15个开源模型。

Result: 专有模型表现更优；开源模型在特定维度有竞争力；推理模式影响效果；量化加速但降低性能。

Conclusion: 开源模型需针对性优化以匹配专有模型，ContractEval为未来法律领域LLM发展提供基准。

Abstract: The potential of large language models (LLMs) in specialized domains such as
legal risk analysis remains underexplored. In response to growing interest in
locally deploying open-source LLMs for legal tasks while preserving data
confidentiality, this paper introduces ContractEval, the first benchmark to
thoroughly evaluate whether open-source LLMs could match proprietary LLMs in
identifying clause-level legal risks in commercial contracts. Using the
Contract Understanding Atticus Dataset (CUAD), we assess 4 proprietary and 15
open-source LLMs. Our results highlight five key findings: (1) Proprietary
models outperform open-source models in both correctness and output
effectiveness, though some open-source models are competitive in certain
specific dimensions. (2) Larger open-source models generally perform better,
though the improvement slows down as models get bigger. (3) Reasoning
("thinking") mode improves output effectiveness but reduces correctness, likely
due to over-complicating simpler tasks. (4) Open-source models generate "no
related clause" responses more frequently even when relevant clauses are
present. This suggests "laziness" in thinking or low confidence in extracting
relevant content. (5) Model quantization speeds up inference but at the cost of
performance drop, showing the tradeoff between efficiency and accuracy. These
findings suggest that while most LLMs perform at a level comparable to junior
legal assistants, open-source models require targeted fine-tuning to ensure
correctness and effectiveness in high-stakes legal settings. ContractEval
offers a solid benchmark to guide future development of legal-domain LLMs.

</details>


### [64] [Data Dependency Inference for Industrial Code Generation Based on UML Sequence Diagrams](https://arxiv.org/abs/2508.03379)
*Wenxin Mao,Zhitao Wang Long Wang,Sirong Chen,Cuiyun Gao,Luyang Cao,Ziming Liu,Qiming Zhang,Jun Zhou,Zhi Jin*

Main category: cs.AI

TL;DR: 提出UML2Dep框架，利用形式化规范解决自然语言描述的模糊性，通过增强的UML序列图和数据依赖推理任务，提升代码生成的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 自然语言描述在复杂需求和系统行为中存在模糊性，难以捕捉条件逻辑和架构约束，需要形式化规范来消除歧义。

Method: 1. 引入增强的UML序列图，整合决策表和API规范；2. 提出数据依赖推理（DDI）任务，构建显式数据依赖图；3. 通过数学推理和静态解析优化推理过程。

Result: 框架通过形式化规范和DDI任务，显著减少了模糊性，提升了代码生成的准确性和效率。

Conclusion: UML2Dep框架通过形式化规范和系统化的数据依赖推理，有效解决了自然语言描述的模糊性问题，为复杂需求下的代码生成提供了可靠方法。

Abstract: Large language models (LLMs) excel at generating code from natural language
(NL) descriptions. However, the plain textual descriptions are inherently
ambiguous and often fail to capture complex requirements like intricate system
behaviors, conditional logic, and architectural constraints; implicit data
dependencies in service-oriented architectures are difficult to infer and
handle correctly. To bridge this gap, we propose a novel step-by-step code
generation framework named UML2Dep by leveraging unambiguous formal
specifications of complex requirements. First, we introduce an enhanced Unified
Modeling Language (UML) sequence diagram tailored for service-oriented
architectures. This diagram extends traditional visual syntax by integrating
decision tables and API specifications, explicitly formalizing structural
relationships and business logic flows in service interactions to rigorously
eliminate linguistic ambiguity. Second, recognizing the critical role of data
flow, we introduce a dedicated data dependency inference (DDI) task. DDI
systematically constructs an explicit data dependency graph prior to actual
code synthesis. To ensure reliability, we formalize DDI as a constrained
mathematical reasoning task through novel prompting strategies, aligning with
LLMs' excellent mathematical strengths. Additional static parsing and
dependency pruning further reduce context complexity and cognitive load
associated with intricate specifications, thereby enhancing reasoning accuracy
and efficiency.

</details>


### [65] [EoH-S: Evolution of Heuristic Set using LLMs for Automated Heuristic Design](https://arxiv.org/abs/2508.03082)
*Fei Liu,Yilu Liu,Qingfu Zhang,Xialiang Tong,Mingxuan Yuan*

Main category: cs.AI

TL;DR: 论文提出了一种基于大语言模型（LLM）的自动化启发式集合设计（AHSD）方法，通过生成互补的启发式集合来提升泛化能力，并提出了EoH-S算法实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅设计单一启发式，泛化能力差，无法适应不同问题实例的多样性。

Method: 提出AHSD框架，目标函数具有单调性和超模性，并设计EoH-S算法，结合互补种群管理和互补感知的模因搜索。

Result: 在三个任务上的实验表明，EoH-S显著优于现有方法，性能提升高达60%。

Conclusion: AHSD和EoH-S为自动化启发式设计提供了更高效的解决方案，显著提升了泛化能力。

Abstract: Automated Heuristic Design (AHD) using Large Language Models (LLMs) has
achieved notable success in recent years. Despite the effectiveness of existing
approaches, they only design a single heuristic to serve all problem instances,
often inducing poor generalization across different distributions or settings.
To address this issue, we propose Automated Heuristic Set Design (AHSD), a new
formulation for LLM-driven AHD. The aim of AHSD is to automatically generate a
small-sized complementary heuristic set to serve diverse problem instances,
such that each problem instance could be optimized by at least one heuristic in
this set. We show that the objective function of AHSD is monotone and
supermodular. Then, we propose Evolution of Heuristic Set (EoH-S) to apply the
AHSD formulation for LLM-driven AHD. With two novel mechanisms of complementary
population management and complementary-aware memetic search, EoH-S could
effectively generate a set of high-quality and complementary heuristics.
Comprehensive experimental results on three AHD tasks with diverse instances
spanning various sizes and distributions demonstrate that EoH-S consistently
outperforms existing state-of-the-art AHD methods and achieves up to 60\%
performance improvements.

</details>


### [66] [VQA support to Arabic Language Learning Educational Tool](https://arxiv.org/abs/2508.03488)
*Khaled Bachir Delassi,Lakhdar Zeggane,Hadda Cherroun,Abdelhamid Haouhat,Kaoutar Bouzouad*

Main category: cs.AI

TL;DR: 论文提出了一种基于AI的阿拉伯语学习工具，通过视觉问答和互动测验促进主动学习，填补了现代教育工具的空白。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语学习工具稀缺的问题，尤其是支持现代教学模型（如主动学习）的工具。

Method: 利用视觉语言预训练模型生成互动视觉测验，结合大型语言模型定制阿拉伯语学习任务。

Result: 通过人工标注的1266个视觉测验评估，工具表现出较高的准确率，验证了其有效性。

Conclusion: 该工具为阿拉伯语学习者提供了个性化、互动的学习体验，有望成为可靠的学习资源。

Abstract: We address the problem of scarcity of educational Arabic Language Learning
tools that advocate modern pedagogical models such as active learning which
ensures language proficiency. In fact, we investigate the design and evaluation
of an AI-powered educational tool designed to enhance Arabic language learning
for non-native speakers with beginner-to-intermediate proficiency level. The
tool leverages advanced AI models to generate interactive visual quizzes,
deploying Visual Question Answering as the primary activity. Adopting a
constructivist learning approach, the system encourages active learning through
real-life visual quizzes, and image-based questions that focus on improving
vocabulary, grammar, and comprehension. The system integrates Vision-Language
Pretraining models to generate contextually relevant image description from
which Large Language Model generate assignments based on customized Arabic
language Learning quizzes thanks to prompting.
  The effectiveness of the tool is evaluated through a manual annotated
benchmark consisting of 1266 real-life visual quizzes, with human participants
providing feedback. The results show a suitable accuracy rates, validating the
tool's potential to bridge the gap in Arabic language education and
highlighting the tool's promise as a reliable, AI-powered resource for Arabic
learners, offering personalized and interactive learning experiences.

</details>


### [67] [MissDDIM: Deterministic and Efficient Conditional Diffusion for Tabular Data Imputation](https://arxiv.org/abs/2508.03083)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.AI

TL;DR: MissDDIM是一种基于DDIM的条件扩散框架，用于表格数据填补，解决了现有方法的高延迟和输出不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于DDPM的缺失数据填补方法存在高推理延迟和输出不稳定性，限制了其在实际表格数据中的应用。

Method: 提出MissDDIM，一种基于DDIM的条件扩散框架，用于表格数据填补。

Result: MissDDIM通过确定性采样减少了输出变异性，同时保持了填补的多样性。

Conclusion: MissDDIM为表格数据填补提供了一种高效且稳定的解决方案。

Abstract: Diffusion models have recently emerged as powerful tools for missing data
imputation by modeling the joint distribution of observed and unobserved
variables. However, existing methods, typically based on stochastic denoising
diffusion probabilistic models (DDPMs), suffer from high inference latency and
variable outputs, limiting their applicability in real-world tabular settings.
To address these deficiencies, we present in this paper MissDDIM, a conditional
diffusion framework that adapts Denoising Diffusion Implicit Models (DDIM) for
tabular imputation. While stochastic sampling enables diverse completions, it
also introduces output variability that complicates downstream processing.

</details>


### [68] [Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework](https://arxiv.org/abs/2508.03092)
*Zikun Cui,Tianyi Huang,Chia-En Chiang,Cuiqianhe Du*

Main category: cs.AI

TL;DR: 本文提出了一种可验证的虚假信息检测LLM代理，通过动态交互和多种工具实现多步骤验证，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的普及，虚假信息检测变得愈发重要和复杂，需要超越传统的二元判断。

Method: 设计了包含精确网络搜索工具、来源可信度评估工具和数值声明验证工具的代理架构，支持多步骤验证策略。

Result: 在标准数据集上的实验表明，该代理在检测准确性、推理透明度和抗信息改写方面优于基线方法。

Conclusion: 该研究为可信赖的AI辅助事实核查提供了新范式。

Abstract: With the proliferation of Large Language Models (LLMs), the detection of
misinformation has become increasingly important and complex. This research
proposes an innovative verifiable misinformation detection LLM agent that goes
beyond traditional true/false binary judgments. The agent actively verifies
claims through dynamic interaction with diverse web sources, assesses
information source credibility, synthesizes evidence, and provides a complete
verifiable reasoning process. Our designed agent architecture includes three
core tools: precise web search tool, source credibility assessment tool and
numerical claim verification tool. These tools enable the agent to execute
multi-step verification strategies, maintain evidence logs, and form
comprehensive assessment conclusions. We evaluate using standard misinformation
datasets such as FakeNewsNet, comparing with traditional machine learning
models and LLMs. Evaluation metrics include standard classification metrics,
quality assessment of reasoning processes, and robustness testing against
rewritten content. Experimental results show that our agent outperforms
baseline methods in misinformation detection accuracy, reasoning transparency,
and resistance to information rewriting, providing a new paradigm for
trustworthy AI-assisted fact-checking.

</details>


### [69] [AgentSME for Simulating Diverse Communication Modes in Smart Education](https://arxiv.org/abs/2508.03109)
*Wen-Xi Yang,Tian-Fang Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLM的统一生成代理框架AgentSME，用于智能教育，通过三种通信模式（Solo、Mono、Echo）验证其效果，发现Echo模式准确率最高，DeepSeek多样性最佳。


<details>
  <summary>Details</summary>
Motivation: 智能教育中的生成代理模型尚不成熟，教育场景的复杂性和个性化需求是主要挑战。

Method: 提出AgentSME框架，采用三种通信模式（Solo、Mono、Echo），以准确性和多样性为评估指标，测试六种LLM。

Result: Echo模式准确率最高，DeepSeek多样性最佳。

Conclusion: 研究为提升代理学习能力和智能教育模型提供了有价值的信息。

Abstract: Generative agent models specifically tailored for smart education are
critical, yet remain relatively underdeveloped. A key challenge stems from the
inherent complexity of educational contexts: learners are human beings with
various cognitive behaviors, and pedagogy is fundamentally centered on
personalized human-to-human communication. To address this issue, this paper
proposes AgentSME, a unified generative agent framework powered by LLM. Three
directional communication modes are considered in the models, namely Solo,
Mono, and Echo, reflecting different types of agency autonomy and communicative
reciprocity. Accuracy is adopted as the primary evaluation metric, complemented
by three diversity indices designed to assess the diversity of reasoning
contents. Six widely used LLMs are tested to validate the robustness of
communication modes across different model tiers, which are equally divided
into base-capacity and high-capacity configurations. The results show that
generative agents that employ the Echo communication mode achieve the highest
accuracy scores, while DeepSeek exhibits the greatest diversity. This study
provides valuable information to improve agent learning capabilities and
inspire smart education models.

</details>


### [70] [Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation](https://arxiv.org/abs/2508.03117)
*Vinicius Lima,Dzung T. Phan,Jayant Kalagnanam,Dhaval Patel,Nianjun Zhou*

Main category: cs.AI

TL;DR: 提出了一种通过可验证合成数据生成管道训练可信赖大型语言模型（LLM）代理的框架，专注于线性和混合整数线性规划，实现了从结构化符号表示到自然语言描述、数学公式和可执行代码的系统生成。


<details>
  <summary>Details</summary>
Motivation: 为优化建模任务构建可靠且可验证的LLM代理，解决现有方法中数据质量和可验证性不足的问题。

Method: 通过程序化构建每个实例（包含已知最优解），生成自然语言描述、数学公式和代码，并利用教师模型生成逐步演示，实现开源LLM的监督微调。

Result: OptiTrust代理在标准基准测试中表现最佳，7个数据集中6个准确率最高，其中3个比次优算法高出至少8个百分点。

Conclusion: 该方法为构建可靠LLM代理提供了可扩展、可验证且原则性的路径，适用于实际优化应用。

Abstract: We present a framework for training trustworthy large language model (LLM)
agents for optimization modeling via a verifiable synthetic data generation
pipeline. Focusing on linear and mixed-integer linear programming, our approach
begins with structured symbolic representations and systematically produces
natural language descriptions, mathematical formulations, and solver-executable
code. By programmatically constructing each instance with known optimal
solutions, the pipeline ensures full verifiability and enables automatic
filtering of low-quality demonstrations generated by teacher models. Each
dataset instance includes a structured representation of the optimization
problem, a corresponding natural language description, the verified optimal
solution, and step-by-step demonstrations - generated by a teacher model - that
show how to model and solve the problem across multiple optimization modeling
languages. This enables supervised fine-tuning of open-source LLMs specifically
tailored to optimization tasks. To operationalize this pipeline, we introduce
OptiTrust, a modular LLM agent that performs multi-stage translation from
natural language to solver-ready code, leveraging stepwise demonstrations,
multi-language inference, and majority-vote cross-validation. Our agent
achieves state-of-the-art performance on standard benchmarks. Out of 7
datasets, it achieves the highest accuracy on six and outperforms the next-best
algorithm by at least 8 percentage on three of them. Our approach provides a
scalable, verifiable, and principled path toward building reliable LLM agents
for real-world optimization applications.

</details>


### [71] [Can Large Language Models Bridge the Gap in Environmental Knowledge?](https://arxiv.org/abs/2508.03149)
*Linda Smail,David Santandreu Calonge,Firuz Kamalov,Nur H. Orak*

Main category: cs.AI

TL;DR: 研究探讨AI模型（如GPT-3.5、GPT-4等）在弥补大学生环境教育知识缺口方面的潜力，发现其虽具备丰富知识库，但仍需人类专家验证信息准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大学生环境教育中的知识缺口问题，探索AI模型作为辅助工具的可行性。

Method: 使用标准化工具EKT-19及针对性问题，评估AI模型与大学生在环境知识上的表现对比。

Result: AI模型具备丰富且易获取的知识库，但需环境科学专家验证信息准确性。

Conclusion: AI模型可辅助环境教育，但需结合人类专家以确保信息准确性。

Abstract: This research investigates the potential of Artificial Intelligence (AI)
models to bridge the knowledge gap in environmental education among university
students. By focusing on prominent large language models (LLMs) such as
GPT-3.5, GPT-4, GPT-4o, Gemini, Claude Sonnet, and Llama 2, the study assesses
their effectiveness in conveying environmental concepts and, consequently,
facilitating environmental education. The investigation employs a standardized
tool, the Environmental Knowledge Test (EKT-19), supplemented by targeted
questions, to evaluate the environmental knowledge of university students in
comparison to the responses generated by the AI models. The results of this
study suggest that while AI models possess a vast, readily accessible, and
valid knowledge base with the potential to empower both students and academic
staff, a human discipline specialist in environmental sciences may still be
necessary to validate the accuracy of the information provided.

</details>


### [72] [Causal identification with $Y_0$](https://arxiv.org/abs/2508.03167)
*Charles Tapley Hoyt,Craig Bakker,Richard J. Callahan,Joseph Cottam,August George,Benjamin M. Gyori,Haley M. Hummel,Nathaniel Merrill,Sara Mohammad Taheri,Pruthvi Prakash Navada,Marc-Antoine Parent,Adam Rupe,Olga Vitek,Jeremy Zucker*

Main category: cs.AI

TL;DR: $Y_0$是一个Python包，用于实现因果识别算法，支持干预、反事实和可迁移性查询，帮助研究者定性分析因果关系。


<details>
  <summary>Details</summary>
Motivation: 提供工具帮助研究者确定因果关系是否可从数据中估计，并指导如何将因果查询转化为可估计的符号表达式。

Method: 实现多种因果识别算法，支持因果图模型（如ADMGs）和符号概率表达式。

Result: $Y_0$包支持从随机对照试验、观察性研究或其混合数据中进行因果分析。

Conclusion: $Y_0$为因果推理提供了实用的工具和算法，适用于多种数据类型和查询。

Abstract: We present the $Y_0$ Python package, which implements causal identification
algorithms that apply interventional, counterfactual, and transportability
queries to data from (randomized) controlled trials, observational studies, or
mixtures thereof. $Y_0$ focuses on the qualitative investigation of causation,
helping researchers determine whether a causal relationship can be estimated
from available data before attempting to estimate how strong that relationship
is. Furthermore, $Y_0$ provides guidance on how to transform the causal query
into a symbolic estimand that can be non-parametrically estimated from the
available data. $Y_0$ provides a domain-specific language for representing
causal queries and estimands as symbolic probabilistic expressions, tools for
representing causal graphical models with unobserved confounders, such as
acyclic directed mixed graphs (ADMGs), and implementations of numerous
identification algorithms from the recent causal inference literature. The
$Y_0$ source code can be found under the MIT License at
https://github.com/y0-causal-inference/y0 and it can be installed with pip
install y0.

</details>


### [73] [Geoint-R1: Formalizing Multimodal Geometric Reasoning with Dynamic Auxiliary Constructions](https://arxiv.org/abs/2508.03173)
*Jingxuan Wei,Caijun Jia,Qi Chen,Honghao He,Linzhuang Sun,Conghui He,Lijun Wu,Bihui Yu,Cheng Tan*

Main category: cs.AI

TL;DR: Geoint-R1是一个多模态推理框架，专注于生成可形式化验证的几何解决方案，通过结合辅助元素构建、Lean4形式推理和交互式可视化，显著提升了现有模型在几何推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在形式化几何推理，尤其是动态构建和验证辅助几何元素方面表现不佳，Geoint-R1旨在解决这一问题。

Method: Geoint-R1整合了辅助元素构建、Lean4形式推理和交互式可视化，并通过Geoint基准（包含1,885个几何问题）进行系统评估。

Result: 实验表明，Geoint-R1在需要显式辅助元素构建的复杂问题上显著优于现有模型。

Conclusion: Geoint-R1为形式化几何推理提供了有效解决方案，并通过基准测试验证了其优越性。

Abstract: Mathematical geometric reasoning is essential for scientific discovery and
educational development, requiring precise logic and rigorous formal
verification. While recent advances in Multimodal Large Language Models (MLLMs)
have improved reasoning tasks, existing models typically struggle with formal
geometric reasoning, particularly when dynamically constructing and verifying
auxiliary geometric elements. To address these challenges, we introduce
Geoint-R1, a multimodal reasoning framework designed to generate formally
verifiable geometric solutions from textual descriptions and visual diagrams.
Geoint-R1 uniquely integrates auxiliary elements construction, formal reasoning
represented via Lean4, and interactive visualization. To systematically
evaluate and advance formal geometric reasoning, we propose the Geoint
benchmark, comprising 1,885 rigorously annotated geometry problems across
diverse topics such as plane, spatial, and solid geometry. Each problem
includes structured textual annotations, precise Lean4 code for auxiliary
constructions, and detailed solution steps verified by experts. Extensive
experiments demonstrate that Geoint-R1 significantly surpasses existing
multimodal and math-specific reasoning models, particularly on challenging
problems requiring explicit auxiliary element constructions.

</details>


### [74] [InqEduAgent: Adaptive AI Learning Partners with Gaussian Process Augmentation](https://arxiv.org/abs/2508.03174)
*Tian-Fang Zhao,Wen-Xi Yang*

Main category: cs.AI

TL;DR: 论文提出了一种基于LLM的智能代理模型InqEduAgent，用于模拟和选择适合探究式学习的学习伙伴，解决了传统方法在知识扩展和灵活性上的不足。


<details>
  <summary>Details</summary>
Motivation: 探究式教育中学习伙伴的选择通常依赖经验或规则，缺乏科学规划和灵活性，限制了知识扩展。

Method: 设计了生成式代理捕捉学习者的认知和评估特征，并采用高斯过程增强的自适应匹配算法识别先验知识模式。

Result: 实验表明InqEduAgent在多种知识学习场景和不同能力的LLM环境中表现最优。

Conclusion: 该研究推动了基于人类的学习伙伴智能分配和AI学习伙伴的制定，相关资源已公开。

Abstract: Collaborative partnership matters in inquiry-oriented education. However,
most study partners are selected either rely on experience-based assignments
with little scientific planning or build on rule-based machine assistants,
encountering difficulties in knowledge expansion and inadequate flexibility.
This paper proposes an LLM-empowered agent model for simulating and selecting
learning partners tailored to inquiry-oriented learning, named InqEduAgent.
Generative agents are designed to capture cognitive and evaluative features of
learners in real-world scenarios. Then, an adaptive matching algorithm with
Gaussian process augmentation is formulated to identify patterns within prior
knowledge. Optimal learning-partner matches are provided for learners facing
different exercises. The experimental results show the optimal performance of
InqEduAgent in most knowledge-learning scenarios and LLM environment with
different levels of capabilities. This study promotes the intelligent
allocation of human-based learning partners and the formulation of AI-based
learning partners. The code, data, and appendix are publicly available at
https://github.com/InqEduAgent/InqEduAgent.

</details>


### [75] [Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning](https://arxiv.org/abs/2508.03251)
*Osama Mohammed,Jiaxin Pan,Mojtaba Nayyeri,Daniel Hernández,Steffen Staab*

Main category: cs.AI

TL;DR: 论文提出了一种全历史图表示方法和ETDNet网络，用于建模实体间随时间演化的交互关系，显著提升了驾驶意图预测和比特币欺诈检测的性能。


<details>
  <summary>Details</summary>
Motivation: 现实任务中需要建模实体间动态交互关系（如交通中的车辆行为或金融交易中的资金流动），现有方法通常使用快照图，无法充分捕捉关系和时间的演化。

Method: 提出全历史图表示，区分同一时间步和跨时间步的边，并设计ETDNet网络，结合图注意力和时间注意力模块。

Result: 在Waymo和Elliptic++数据集上，ETDNet分别将联合准确率提升至75.6%和非法类F1分数提升至88.1%，优于基线方法。

Conclusion: 通过将结构和时间关系表示为图中的不同边，ETDNet显著提升了动态交互建模的性能。

Abstract: Modeling evolving interactions among entities is critical in many real-world
tasks. For example, predicting driver maneuvers in traffic requires tracking
how neighboring vehicles accelerate, brake, and change lanes relative to one
another over consecutive frames. Likewise, detecting financial fraud hinges on
following the flow of funds through successive transactions as they propagate
through the network. Unlike classic time-series forecasting, these settings
demand reasoning over who interacts with whom and when, calling for a
temporal-graph representation that makes both the relations and their evolution
explicit. Existing temporal-graph methods typically use snapshot graphs to
encode temporal evolution. We introduce a full-history graph that instantiates
one node for every entity at every time step and separates two edge sets: (i)
intra-time-step edges that capture relations within a single frame and (ii)
inter-time-step edges that connect an entity to itself at consecutive steps. To
learn on this graph we design an Edge-Type Decoupled Network (ETDNet) with
parallel modules: a graph-attention module aggregates information along
intra-time-step edges, a multi-head temporal-attention module attends over an
entity's inter-time-step history, and a fusion module combines the two messages
after every layer. Evaluated on driver-intention prediction (Waymo) and Bitcoin
fraud detection (Elliptic++), ETDNet consistently surpasses strong baselines,
lifting Waymo joint accuracy to 75.6\% (vs. 74.1\%) and raising Elliptic++
illicit-class F1 to 88.1\% (vs. 60.4\%). These gains demonstrate the benefit of
representing structural and temporal relations as distinct edges in a single
graph.

</details>


### [76] [ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools](https://arxiv.org/abs/2508.03284)
*Shaofeng Yin,Ting Lei,Yang Liu*

Main category: cs.AI

TL;DR: ToolVQA是一个大规模多模态数据集，旨在提升大型基础模型在真实世界工具使用中的多步推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究在工具增强的视觉问答（VQA）中表现良好，但在真实世界多模态环境中的工具使用能力仍有显著不足。

Method: 提出ToolVQA数据集和ToolEngine数据生成管道，采用深度优先搜索（DFS）和动态上下文示例匹配机制模拟人类工具使用推理。

Result: 在ToolVQA上微调的7B LFMs在测试集和多个OOD数据集上表现优异，甚至超过GPT-3.5-turbo。

Conclusion: ToolVQA和ToolEngine有效提升了模型在真实世界工具使用场景中的泛化能力。

Abstract: Integrating external tools into Large Foundation Models (LFMs) has emerged as
a promising approach to enhance their problem-solving capabilities. While
existing studies have demonstrated strong performance in tool-augmented Visual
Question Answering (VQA), recent benchmarks reveal significant gaps in
real-world tool-use proficiency, particularly in functionally diverse
multimodal settings requiring multi-step reasoning. In this work, we introduce
ToolVQA, a large-scale multimodal dataset comprising 23K instances, designed to
bridge this gap. Unlike previous datasets that rely on synthetic scenarios and
simplified queries, ToolVQA features real-world visual contexts and challenging
implicit multi-step reasoning tasks, better aligning with real user
interactions. To construct this dataset, we propose ToolEngine, a novel data
generation pipeline that employs Depth-First Search (DFS) with a dynamic
in-context example matching mechanism to simulate human-like tool-use
reasoning. ToolVQA encompasses 10 multimodal tools across 7 diverse task
domains, with an average inference length of 2.78 reasoning steps per instance.
The fine-tuned 7B LFMs on ToolVQA not only achieve impressive performance on
our test set but also surpass the large close-sourced model GPT-3.5-turbo on
various out-of-distribution (OOD) datasets, demonstrating strong
generalizability to real-world tool-use scenarios.

</details>


### [77] [Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science](https://arxiv.org/abs/2508.03341)
*Jiayan Nan,Wenquan Ma,Wenlong Wu,Yize Chen*

Main category: cs.AI

TL;DR: Nemori是一种受人类认知启发的自组织记忆架构，通过两步对齐原则和预测校准原则解决LLMs在长期交互中的记忆问题，显著优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在长期交互中无法维持持久记忆的问题，现有记忆系统依赖被动规则且缺乏自适应学习能力。

Method: 提出Nemori架构，采用两步对齐原则组织语义连贯的记忆片段，并通过预测校准原则主动学习预测差距。

Result: 在LoCoMo和LongMemEval基准测试中，Nemori显著优于现有系统，尤其在长上下文场景中表现突出。

Conclusion: Nemori为自主代理的长期动态工作流提供了可行的解决方案，展示了自适应知识演化的潜力。

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities, yet their
inability to maintain persistent memory in long contexts limits their
effectiveness as autonomous agents in long-term interactions. While existing
memory systems have made progress, their reliance on arbitrary granularity for
defining the basic memory unit and passive, rule-based mechanisms for knowledge
extraction limits their capacity for genuine learning and evolution. To address
these foundational limitations, we present Nemori, a novel self-organizing
memory architecture inspired by human cognitive principles. Nemori's core
innovation is twofold: First, its Two-Step Alignment Principle, inspired by
Event Segmentation Theory, provides a principled, top-down method for
autonomously organizing the raw conversational stream into semantically
coherent episodes, solving the critical issue of memory granularity. Second,
its Predict-Calibrate Principle, inspired by the Free-energy Principle, enables
the agent to proactively learn from prediction gaps, moving beyond pre-defined
heuristics to achieve adaptive knowledge evolution. This offers a viable path
toward handling the long-term, dynamic workflows of autonomous agents.
Extensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that
Nemori significantly outperforms prior state-of-the-art systems, with its
advantage being particularly pronounced in longer contexts.

</details>


### [78] [Adaptive AI Agent Placement and Migration in Edge Intelligence Systems](https://arxiv.org/abs/2508.03345)
*Xingdan Wang,Jiayi He,Zhiqing Tang,Jianxiong Guo,Jiong Lou,Liping Qian,Tian Wang,Weijia Jia*

Main category: cs.AI

TL;DR: 论文提出了一种针对动态边缘环境中基于LLM的AI代理的部署和管理方案，通过自适应框架优化资源利用和服务质量。


<details>
  <summary>Details</summary>
Motivation: 随着LLM（如ChatGPT和Claude）的兴起，需要能够实时处理任务的AI代理，但传统云端部署引入高延迟，而边缘环境资源有限且异构，需解决代理迁移和资源优化问题。

Method: 提出了一种自适应框架，结合蚁群算法和基于LLM的优化，建模资源约束和延迟/成本，实现高效决策和轻量级代理迁移。

Result: 在分布式系统（AgentScope）上实现，并在全球边缘服务器验证，显著降低了部署延迟和迁移成本。

Conclusion: 该方案为动态边缘环境中LLM-based AI代理的高效部署和管理提供了系统化解决方案。

Abstract: The rise of LLMs such as ChatGPT and Claude fuels the need for AI agents
capable of real-time task handling. However, migrating data-intensive,
multi-modal edge workloads to cloud data centers, traditionally used for agent
deployment, introduces significant latency. Deploying AI agents at the edge
improves efficiency and reduces latency. However, edge environments present
challenges due to limited and heterogeneous resources. Maintaining QoS for
mobile users necessitates agent migration, which is complicated by the
complexity of AI agents coordinating LLMs, task planning, memory, and external
tools. This paper presents the first systematic deployment and management
solution for LLM-based AI agents in dynamic edge environments. We propose a
novel adaptive framework for AI agent placement and migration in edge
intelligence systems. Our approach models resource constraints and
latency/cost, leveraging ant colony algorithms and LLM-based optimization for
efficient decision-making. It autonomously places agents to optimize resource
utilization and QoS and enables lightweight agent migration by transferring
only essential state. Implemented on a distributed system using AgentScope and
validated across globally distributed edge servers, our solution significantly
reduces deployment latency and migration costs.

</details>


### [79] [Compressing Chain-of-Thought in LLMs via Step Entropy](https://arxiv.org/abs/2508.03346)
*Zeju Li,Jianyuan Zhong,Ziyang Zheng,Xiangyu Wen,Zhijian Xu,Yingying Cheng,Fan Zhang,Qiang Xu*

Main category: cs.AI

TL;DR: 论文提出了一种基于步骤熵的CoT压缩框架，通过识别冗余步骤显著提升LLM推理效率，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs使用CoT提示时生成冗余的思维过程，增加了推理成本并降低了效率，因此需要一种方法来压缩这些冗余步骤。

Method: 提出基于步骤熵的压缩框架，结合SFT和GRPO强化学习的训练策略，让LLMs在推理时生成压缩的CoT。

Result: 实验表明，80%的低熵步骤可被剪枝，且对最终答案准确性影响极小。

Conclusion: 该方法显著提升了LLM推理效率，同时保持准确性，对实际部署和推理结构理解有重要意义。

Abstract: Large Language Models (LLMs) using Chain-of-Thought (CoT) prompting excel at
complex reasoning but generate verbose thought processes with considerable
redundancy, leading to increased inference costs and reduced efficiency. We
introduce a novel CoT compression framework based on step entropy, a metric
that quantifies the informational contribution of individual reasoning steps to
identify redundancy. Through theoretical analysis and extensive empirical
validation on mathematical reasoning benchmarks, we demonstrate that steps with
low entropy are indeed highly redundant. Our experiments reveal that an
astonishing 80\% of low-entropy intermediate steps can be pruned with minor
degradation in the final answer accuracy across DeepSeek-R1-7B, 14B and
Qwen3-8B. This finding sharply contrasts with random or high-entropy pruning,
which severely impairs reasoning performance. Building on this, we propose a
novel two-stage training strategy combining Supervised Fine-Tuning (SFT) and
Group Relative Policy Optimization (GRPO) reinforcement learning. This approach
enables LLMs to autonomously learn to generate compressed COTs during inference
by strategically incorporating [SKIP] tokens. Our method significantly enhances
LLM inference efficiency while rigorously preserving accuracy, offering
profound implications for practical LLM deployment and a deeper understanding
of reasoning structures.

</details>


### [80] [CogBench: A Large Language Model Benchmark for Multilingual Speech-Based Cognitive Impairment Assessment](https://arxiv.org/abs/2508.03360)
*Feng Rui,Zhiyao Luo,Wei Wang,Yuting Song,Yong Liu,Tingting Zhu,Jianqing Li,Xingyao Wang*

Main category: cs.AI

TL;DR: CogBench是一个评估大型语言模型（LLMs）在跨语言和跨临床环境中用于认知障碍评估的泛化能力的基准测试。研究发现，传统深度学习模型在跨域迁移时性能显著下降，而采用思维链提示的LLMs表现更好，但性能仍受提示设计影响。轻量级微调（LoRA）显著提升了目标域中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于自发语音的认知障碍评估方法在跨语言和临床环境中的泛化能力不足，限制了其实际应用。

Method: 提出CogBench基准测试，使用统一的多模态管道评估LLMs在英语和普通话数据集（ADReSSo、NCMMSC2021-AD和CIR-E）中的表现，并探索思维链提示和LoRA微调的效果。

Result: 传统深度学习模型跨域性能下降明显，LLMs表现更优但受提示设计影响，LoRA微调显著提升泛化能力。

Conclusion: 研究为构建临床实用且语言鲁棒的语音认知评估工具提供了重要进展。

Abstract: Automatic assessment of cognitive impairment from spontaneous speech offers a
promising, non-invasive avenue for early cognitive screening. However, current
approaches often lack generalizability when deployed across different languages
and clinical settings, limiting their practical utility. In this study, we
propose CogBench, the first benchmark designed to evaluate the cross-lingual
and cross-site generalizability of large language models (LLMs) for
speech-based cognitive impairment assessment. Using a unified multimodal
pipeline, we evaluate model performance on three speech datasets spanning
English and Mandarin: ADReSSo, NCMMSC2021-AD, and a newly collected test set,
CIR-E. Our results show that conventional deep learning models degrade
substantially when transferred across domains. In contrast, LLMs equipped with
chain-of-thought prompting demonstrate better adaptability, though their
performance remains sensitive to prompt design. Furthermore, we explore
lightweight fine-tuning of LLMs via Low-Rank Adaptation (LoRA), which
significantly improves generalization in target domains. These findings offer a
critical step toward building clinically useful and linguistically robust
speech-based cognitive assessment tools.

</details>


### [81] [A Comparative Study of Neurosymbolic AI Approaches to Interpretable Logical Reasoning](https://arxiv.org/abs/2508.03366)
*Michael K. Chen*

Main category: cs.AI

TL;DR: 论文比较了两种神经符号AI方法（集成与混合）在通用逻辑推理中的表现，发现混合方法更具潜力，并提出了一个基于LLM-SS的通用框架。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）在通用逻辑推理任务中表现不足，缺乏确定性和可解释性，神经符号AI成为研究热点。

Method: 通过对比集成方法（LNN）和混合方法（LLM-SS），分析它们在通用逻辑推理中的表现。

Result: 混合方法（LLM-SS）在可解释性和保留LLM优势方面表现更优。

Conclusion: 混合方法更适合开发通用逻辑推理，并提出了一个模块化、领域无关的框架支持未来研究。

Abstract: General logical reasoning, defined as the ability to reason deductively on
domain-agnostic tasks, continues to be a challenge for large language models
(LLMs). Current LLMs fail to reason deterministically and are not
interpretable. As such, there has been a recent surge in interest in
neurosymbolic AI, which attempts to incorporate logic into neural networks. We
first identify two main neurosymbolic approaches to improving logical
reasoning: (i) the integrative approach comprising models where symbolic
reasoning is contained within the neural network, and (ii) the hybrid approach
comprising models where a symbolic solver, separate from the neural network,
performs symbolic reasoning. Both contain AI systems with promising results on
domain-specific logical reasoning benchmarks. However, their performance on
domain-agnostic benchmarks is understudied. To the best of our knowledge, there
has not been a comparison of the contrasting approaches that answers the
following question: Which approach is more promising for developing general
logical reasoning? To analyze their potential, the following best-in-class
domain-agnostic models are introduced: Logic Neural Network (LNN), which uses
the integrative approach, and LLM-Symbolic Solver (LLM-SS), which uses the
hybrid approach. Using both models as case studies and representatives of each
approach, our analysis demonstrates that the hybrid approach is more promising
for developing general logical reasoning because (i) its reasoning chain is
more interpretable, and (ii) it retains the capabilities and advantages of
existing LLMs. To support future works using the hybrid approach, we propose a
generalizable framework based on LLM-SS that is modular by design,
model-agnostic, domain-agnostic, and requires little to no human input.

</details>


### [82] [Board Game Arena: A Framework and Benchmark for Assessing Large Language Models via Strategic Play](https://arxiv.org/abs/2508.03368)
*Lucia Cipolina-Kun,Marianna Nezhurina,Jenia Jitsev*

Main category: cs.AI

TL;DR: Board Game Arena库通过战略棋盘游戏评估大型语言模型（LLM）的决策能力，支持多种游戏场景和代理类型，提供API访问和分布式执行，并分析LLM推理轨迹。


<details>
  <summary>Details</summary>
Motivation: 为LLM的推理能力和博弈行为提供实证评估框架，支持与其他代理（如随机、人类、强化学习代理）的系统比较。

Method: 集成Google OpenSpiel库的棋盘和矩阵游戏，通过LiteLLM提供API访问，vLLM本地部署，Ray分布式执行，并提供推理轨迹分析工具。

Result: 构建了一个系统化的评估框架，支持多场景、多代理类型的LLM决策能力测试。

Conclusion: 该库为LLM的推理和博弈行为研究提供了实用工具，推动了相关领域的实证分析。

Abstract: The Board Game Arena library provides a framework for evaluating the decision
making abilities of large language models (LLMs) through strategic board games
implemented in Google OpenSpiel library. The framework enables systematic
comparisons between LLM based agents and other agents (random, human,
reinforcement learning agents, etc.) in various game scenarios by wrapping
multiple board and matrix games and supporting different agent types. It
integrates API access to models via LiteLLM, local model deployment via vLLM,
and offers distributed execution through Ray. Additionally it provides
extensive analysis tools for the LLM reasoning traces. This paper summarizes
the structure, key characteristics, and motivation of the repository,
highlighting how it contributes to the empirical evaluation of the reasoning of
LLM and game-theoretic behavior

</details>


### [83] [Hide and Seek with LLMs: An Adversarial Game for Sneaky Error Generation and Self-Improving Diagnosis](https://arxiv.org/abs/2508.03396)
*Rui Zou,Mengqi Wei,Yutao Zhu,Jirong Wen,Xin Zhao,Jing Chen*

Main category: cs.AI

TL;DR: 论文提出了一种动态对抗框架HSG，通过生成和诊断复杂错误提升大语言模型的诊断能力，实验显示其显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推理和生成方面表现优异，但在识别和诊断复杂错误方面仍有不足，主要因训练目标偏向正确答案，缺乏对错误的学习。

Method: 提出HSG框架，包含两个对抗角色：Sneaky生成隐蔽错误，Diagnosis检测错误，通过对抗协同进化提升能力。

Result: 在数学推理任务中，HSG比基线模型（如GPT-4o）的诊断准确率提高了16.8%--31.4%。

Conclusion: HSG有效提升了错误诊断能力，并发布了具有挑战性的错误数据集，为未来研究提供基准。

Abstract: Large Language Models (LLMs) excel in reasoning and generation across
domains, but still struggle with identifying and diagnosing complex errors.
This stems mainly from training objectives that prioritize correct answers,
limiting exposure to and learning from errors. While recent studies have begun
to address this by introducing error signals, most rely on shallow, static
errors, restricting improvement in deep diagnostic ability. To overcome this,
we propose Hide and Seek Game (HSG), a dynamic adversarial framework for error
generation and diagnosis, and evaluate it on mathematical problem-solving. HSG
involves two adversarial roles: Sneaky, which "hides" by generating subtle,
deceptive reasoning errors, and Diagnosis, which "seeks" to accurately detect
them. Through adversarial co-evolution, both error stealth and diagnostic
precision are enhanced. Experiments on several math reasoning tasks show that
HSG significantly boosts error diagnosis, achieving 16.8\%--31.4\% higher
accuracy than baselines like GPT-4o. We also release a challenging dataset of
deceptive errors and diagnostic annotations as a benchmark for future research.

</details>


### [84] [Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large Language Models](https://arxiv.org/abs/2508.03406)
*Kai Li,Ruihao Zheng,Xinye Hao,Zhenkun Wang*

Main category: cs.AI

TL;DR: 论文提出了一种结合LLM代理和多目标优化的方法（MOID），用于诊断和解决路由问题中的模型不可行性，提供多种调整建议。


<details>
  <summary>Details</summary>
Motivation: 现实中的路由问题常因用户需求冲突或限制过严导致模型不可行，现有LLM方法未能全面考虑多种调整可能性。

Method: MOID结合LLM代理和多目标优化，生成权衡路径成本和约束违反的解决方案，并通过LLM分析提供诊断建议。

Result: 在50类不可行路由问题上的实验表明，MOID能单次生成多种诊断建议，比现有方法更实用。

Conclusion: MOID通过多目标优化和LLM分析，有效解决了模型不可行性问题，提供了更实用的决策支持。

Abstract: In real-world routing problems, users often propose conflicting or
unreasonable requirements, which result in infeasible optimization models due
to overly restrictive or contradictory constraints, leading to an empty
feasible solution set. Existing Large Language Model (LLM)-based methods
attempt to diagnose infeasible models, but modifying such models often involves
multiple potential adjustments that these methods do not consider. To fill this
gap, we introduce Multi-Objective Infeasibility Diagnosis (MOID), which
combines LLM agents and multi-objective optimization within an automatic
routing solver, to provide a set of representative actionable suggestions.
Specifically, MOID employs multi-objective optimization to consider both path
cost and constraint violation, generating a set of trade-off solutions, each
encompassing varying degrees of model adjustments. To extract practical
insights from these solutions, MOID utilizes LLM agents to generate a solution
analysis function for the infeasible model. This function analyzes these
distinct solutions to diagnose the original infeasible model, providing users
with diverse diagnostic insights and suggestions. Finally, we compare MOID with
several LLM-based methods on 50 types of infeasible routing problems. The
results indicate that MOID automatically generates multiple diagnostic
suggestions in a single run, providing more practical insights for restoring
model feasibility and decision-making compared to existing methods.

</details>


### [85] [Data Overdose? Time for a Quadruple Shot: Knowledge Graph Construction using Enhanced Triple Extraction](https://arxiv.org/abs/2508.03438)
*Taine J. Elliott,Stephen P. Levitt,Ken Nixon,Martin Bekker*

Main category: cs.AI

TL;DR: 该论文提出了一种基于大型语言模型（LLM）的信息提取方法，用于自动生成生物医学知识图谱（KG），并通过上下文变量增强三元组，形成“四元组”，提高了提取准确性。


<details>
  <summary>Details</summary>
Motivation: 解决医学数据快速增长导致临床医生和研究人员难以系统化理解和应用最新知识的问题。

Method: 使用LLM代理将PubMed摘要分解为语义命题句子，提取KG三元组，并通过开放领域和基于本体的方法增强三元组，加入上下文变量形成四元组。

Result: 提取的三元组生成的自然语言句子与原命题的平均余弦相似度为0.874，上下文变量显著提高了相似度。

Conclusion: 该方法为医学从业者提供了实时更新的集中化知识源，并可能在其他领域实现类似效果。

Abstract: The rapid expansion of publicly-available medical data presents a challenge
for clinicians and researchers alike, increasing the gap between the volume of
scientific literature and its applications. The steady growth of studies and
findings overwhelms medical professionals at large, hindering their ability to
systematically review and understand the latest knowledge. This paper presents
an approach to information extraction and automatic knowledge graph (KG)
generation to identify and connect biomedical knowledge. Through a pipeline of
large language model (LLM) agents, the system decomposes 44 PubMed abstracts
into semantically meaningful proposition sentences and extracts KG triples from
these sentences. The triples are enhanced using a combination of open domain
and ontology-based information extraction methodologies to incorporate
ontological categories. On top of this, a context variable is included during
extraction to allow the triple to stand on its own - thereby becoming
`quadruples'. The extraction accuracy of the LLM is validated by comparing
natural language sentences generated from the enhanced triples to the original
propositions, achieving an average cosine similarity of 0.874. The similarity
for generated sentences of enhanced triples were compared with generated
sentences of ordinary triples showing an increase as a result of the context
variable. Furthermore, this research explores the ability for LLMs to infer new
relationships and connect clusters in the knowledge base of the knowledge
graph. This approach leads the way to provide medical practitioners with a
centralised, updated in real-time, and sustainable knowledge source, and may be
the foundation of similar gains in a wide variety of fields.

</details>


### [86] [Toward a Graph-Theoretic Model of Belief: Confidence, Credibility, and Structural Coherence](https://arxiv.org/abs/2508.03465)
*Saleh Nikooroo*

Main category: cs.AI

TL;DR: 该论文提出了一种将信念系统建模为有向加权图的最小形式主义，区分了信念结构和强度，以更丰富地分类认知状态。


<details>
  <summary>Details</summary>
Motivation: 传统信念表示方法（如概率分布或逻辑框架）掩盖了信念的内部结构，无法处理碎片化或矛盾的认知状态。

Method: 使用有向加权图表示信念系统，节点为个体信念，边为认知关系（支持或矛盾），并分别赋予可信度和置信度。

Result: 该模型提供了分析信念系统内部组织的基础，包括一致性条件、认知张力和表示限制。

Conclusion: 这种形式主义能够比现有方法更丰富地分类认知状态，区分了信念结构和强度。

Abstract: Belief systems are often treated as globally consistent sets of propositions
or as scalar-valued probability distributions. Such representations tend to
obscure the internal structure of belief, conflate external credibility with
internal coherence, and preclude the modeling of fragmented or contradictory
epistemic states. This paper introduces a minimal formalism for belief systems
as directed, weighted graphs. In this framework, nodes represent individual
beliefs, edges encode epistemic relationships (e.g., support or contradiction),
and two distinct functions assign each belief a credibility (reflecting source
trust) and a confidence (derived from internal structural support). Unlike
classical probabilistic models, our approach does not assume prior coherence or
require belief updating. Unlike logical and argumentation-based frameworks, it
supports fine-grained structural representation without committing to binary
justification status or deductive closure. The model is purely static and
deliberately excludes inference or revision procedures. Its aim is to provide a
foundational substrate for analyzing the internal organization of belief
systems, including coherence conditions, epistemic tensions, and
representational limits. By distinguishing belief structure from belief
strength, this formalism enables a richer classification of epistemic states
than existing probabilistic, logical, or argumentation-based approaches.

</details>


### [87] [Semantic-aware Graph-guided Behavior Sequences Generation with Large Language Models for Smart Homes](https://arxiv.org/abs/2508.03484)
*Zhiyao Xu,Dan Zhao,Qingsong Zou,Qing Li,Yong Jiang,Yuhang Wang,Jingyu Xiao*

Main category: cs.AI

TL;DR: SmartGen是一个基于LLM的框架，用于生成上下文感知的用户行为数据，以支持智能家居模型的持续适应。它通过时间与语义感知分割、语义感知序列压缩、图引导序列合成和两阶段异常过滤四个组件，显著提升了模型在行为漂移下的性能。


<details>
  <summary>Details</summary>
Motivation: 智能家居模型通常基于静态数据集训练，难以应对行为漂移（如季节变化或生活方式改变）。由于新数据收集成本高且隐私敏感，需要一种方法生成合成数据以支持持续适应。

Method: SmartGen包含四个关键组件：1) 时间与语义感知分割；2) 语义感知序列压缩；3) 图引导序列合成；4) 两阶段异常过滤。

Result: 在三个真实数据集上的实验表明，SmartGen显著提升了异常检测（85.43%）和行为预测（70.51%）的性能。

Conclusion: SmartGen通过生成高质量合成数据，有效解决了行为漂移问题，为智能家居模型的持续适应提供了可行方案。

Abstract: As smart homes become increasingly prevalent, intelligent models are widely
used for tasks such as anomaly detection and behavior prediction. These models
are typically trained on static datasets, making them brittle to behavioral
drift caused by seasonal changes, lifestyle shifts, or evolving routines.
However, collecting new behavior data for retraining is often impractical due
to its slow pace, high cost, and privacy concerns. In this paper, we propose
SmartGen, an LLM-based framework that synthesizes context-aware user behavior
data to support continual adaptation of downstream smart home models. SmartGen
consists of four key components. First, we design a Time and Semantic-aware
Split module to divide long behavior sequences into manageable, semantically
coherent subsequences under dual time-span constraints. Second, we propose
Semantic-aware Sequence Compression to reduce input length while preserving
representative semantics by clustering behavior mapping in latent space. Third,
we introduce Graph-guided Sequence Synthesis, which constructs a behavior
relationship graph and encodes frequent transitions into prompts, guiding the
LLM to generate data aligned with contextual changes while retaining core
behavior patterns. Finally, we design a Two-stage Outlier Filter to identify
and remove implausible or semantically inconsistent outputs, aiming to improve
the factual coherence and behavioral validity of the generated sequences.
Experiments on three real-world datasets demonstrate that SmartGen
significantly enhances model performance on anomaly detection and behavior
prediction tasks under behavioral drift, with anomaly detection improving by
85.43% and behavior prediction by 70.51% on average. The code is available at
https://github.com/horizonsinzqs/SmartGen.

</details>


### [88] [Error Detection and Correction for Interpretable Mathematics in Large Language Models](https://arxiv.org/abs/2508.03500)
*Yijin Yang,Cristina Cornelio,Mario Leiva,Paulo Shakarian*

Main category: cs.AI

TL;DR: EDCIM是一种检测和纠正大型语言模型在数学任务中错误的方法，通过符号化错误检测框架和轻量级LLM结合，平衡成本与准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多步推理中常产生错误，且难以遵守特定输出格式，EDCIM旨在解决这些问题。

Method: EDCIM生成方程组，利用符号化框架检测错误并提供反馈，结合轻量级和强大LLM以优化效率。

Result: 实验表明EDCIM显著降低成本和财务开销，同时保持或提高准确性。

Conclusion: EDCIM通过平衡成本与准确性，有效提升了数学任务的可靠性和效率。

Abstract: Recent large language models (LLMs) have demonstrated the ability to perform
explicit multi-step reasoning such as chain-of-thought prompting. However,
their intermediate steps often contain errors that can propagate leading to
inaccurate final predictions. Additionally, LLMs still struggle with
hallucinations and often fail to adhere to prescribed output formats, which is
particularly problematic for tasks like generating mathematical expressions or
source code. This work introduces EDCIM (Error Detection and Correction for
Interpretable Mathematics), a method for detecting and correcting these errors
in interpretable mathematics tasks, where the model must generate the exact
functional form that explicitly solve the problem (expressed in natural
language) rather than a black-box solution. EDCIM uses LLMs to generate a
system of equations for a given problem, followed by a symbolic error-detection
framework that identifies errors and provides targeted feedback for LLM-based
correction. To optimize efficiency, EDCIM integrates lightweight, open-source
LLMs with more powerful proprietary models, balancing cost and accuracy. This
balance is controlled by a single hyperparameter, allowing users to control the
trade-off based on their cost and accuracy requirements. Experimental results
across different datasets show that EDCIM significantly reduces both
computational and financial costs, while maintaining, and even improving,
prediction accuracy when the balance is properly configured.

</details>


### [89] [Hidden Dynamics of Massive Activations in Transformer Training](https://arxiv.org/abs/2508.03616)
*Jorge Gallego-Feliciano,S. Aaron McClendon,Juan Morinelli,Stavros Zervoudakis,Antonios Saravanos*

Main category: cs.AI

TL;DR: 本文分析了Transformer训练中大规模激活的涌现动态，揭示了其可预测的数学规律，并提出了一种基于架构参数的预测框架。


<details>
  <summary>Details</summary>
Motivation: 研究大规模激活在训练过程中的涌现动态，填补现有研究空白，为模型设计提供指导。

Method: 使用Pythia模型家族，分析不同模型大小和训练检查点，建立指数调制的对数函数模型，并开发机器学习框架预测参数。

Result: 发现大规模激活涌现遵循可预测的数学模式，预测框架在稳态行为上表现高准确度，涌现时间和幅度上表现中等准确度。

Conclusion: 大规模激活的涌现可通过模型设计预测和控制，对模型稳定性、训练周期和优化有重要意义。

Abstract: Massive activations are scalar values in transformer hidden states that
achieve values orders of magnitude larger than typical activations and have
been shown to be critical for model functionality. While prior work has
characterized these phenomena in fully trained models, the temporal dynamics of
their emergence during training remain poorly understood. We present the first
comprehensive analysis of massive activation development throughout transformer
training, using the Pythia model family as our testbed. Through systematic
analysis of various model sizes across multiple training checkpoints, we
demonstrate that massive activation emergence follows predictable mathematical
patterns that can be accurately modeled using an exponentially-modulated
logarithmic function with five key parameters. We develop a machine learning
framework to predict these mathematical parameters from architectural
specifications alone, achieving high accuracy for steady-state behavior and
moderate accuracy for emergence timing and magnitude. These findings enable
architects to predict and potentially control key aspects of massive activation
emergence through design choices, with significant implications for model
stability, training cycle length, interpretability, and optimization. Our
findings demonstrate that the emergence of massive activations is governed by
model design and can be anticipated, and potentially controlled, before
training begins.

</details>


### [90] [Refining Critical Thinking in LLM Code Generation: A Faulty Premise-based Evaluation Framework](https://arxiv.org/abs/2508.03622)
*Jialin Li,Jinzhe Li,Gengxu Li,Yi Chang,Yuan Wu*

Main category: cs.AI

TL;DR: FPBench是首个针对代码生成中错误前提的评估框架，通过系统构建三类错误前提和多维评估指标，评估了15种LLM，发现模型在错误前提下的推理能力不足，资源投入存在边际效应，且不同错误前提会触发不同的缺陷模式。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代码生成能力的提升，其对输入前提的依赖加剧，错误前提会显著增加代码生成的幻觉概率，暴露其自检能力的不足。

Method: 提出FPBench框架，系统构建三类错误前提，结合多维评估指标，对15种代表性LLM进行深入评估。

Result: 大多数模型在错误前提下的推理能力差，资源投入存在边际效应，且三类错误前提分别触发不同的缺陷模式。

Conclusion: 研究强调了LLM在代码生成中主动验证前提的紧迫性，FPBench为开发可靠、以人为本的代码生成模型提供了理论和实践基础。

Abstract: With the advancement of code generation capabilities in large language models
(LLMs), their reliance on input premises has intensified. When users provide
inputs containing faulty premises, the probability of code generation
hallucinations rises significantly, exposing deficiencies in their
self-scrutiny capabilities. This paper proposes Faulty Premises Bench
(FPBench), the first code generation evaluation framework targeting faulty
premises. By systematically constructing three categories of faulty premises
and integrating multi-dimensional evaluation metrics, it conducts in-depth
assessments of 15 representative LLMs. The key findings are as follows: (1)
Most models exhibit poor reasoning abilities and suboptimal code generation
performance under faulty premises, heavily relying on explicit prompts for
error detection, with limited self-scrutiny capabilities; (2) Faulty premises
trigger a point of diminishing returns in resource investment, leading to
blindly increasing length fails to enhance quality; (3) The three types of
faulty premises respectively activate distinct defect patterns in models,
revealing a triple dissociation in the cognitive mechanisms of code generation
models. This study not only highlights the urgent need for LLMs to proactively
verify premises in code generation but also, through the proposed FPBench
framework and multi-dimensional evaluation system, provides a theoretical
foundation and practical pathway for developing reliable, human-centric code
generation models.

</details>


### [91] [Automated Algorithmic Discovery for Gravitational-Wave Detection Guided by LLM-Informed Evolutionary Monte Carlo Tree Search](https://arxiv.org/abs/2508.03661)
*He Wang,Liang Zeng*

Main category: cs.AI

TL;DR: 提出了一种名为Evo-MCTS的新框架，结合进化优化和蒙特卡洛树搜索，用于改进引力波信号识别，性能提升20.2%。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如匹配滤波和深度神经网络）在引力波信号识别中存在计算量大和决策逻辑不透明的问题。

Method: 结合蒙特卡洛树搜索、进化优化和大语言模型启发式，生成可解释的算法解决方案。

Result: 在MLGWSC-1基准数据集上性能提升20.2%，并发现新的算法组合。

Conclusion: Evo-MCTS为计算科学领域的自动化算法发现提供了可转移的方法论。

Abstract: Computational scientific discovery increasingly relies on algorithms to
process complex data and identify meaningful patterns - yet faces persistent
challenges in gravitational-wave signal identification. While existing
algorithmic approaches like matched filtering (MF) and deep neural networks
(DNNs) have achieved partial success, their limitations directly stem from
fundamental limitations: MF's excessive computational demands arise from its
reliance on predefined theoretical waveform templates, while DNNs' black-box
architectures obscure decision logic and introduce hidden biases. We propose
Evolutionary Monte Carlo Tree Search (Evo-MCTS), a framework that addresses
these limitations through systematic algorithm space exploration guided by
domain-aware physical constraints. Our approach combines tree-structured search
with evolutionary optimization and large language model heuristics to create
interpretable algorithmic solutions. Our Evo-MCTS framework demonstrates
substantial improvements, achieving a 20.2\% improvement over state-of-the-art
gravitational wave detection algorithms on the MLGWSC-1 benchmark dataset.
High-performing algorithm variants consistently exceed thresholds. The
framework generates human-interpretable algorithmic pathways that reveal
distinct performance patterns. Beyond performance improvements, our framework
discovers novel algorithmic combinations, thereby establishing a transferable
methodology for automated algorithmic discovery across computational science
domains.

</details>


### [92] [Agent Lightning: Train ANY AI Agents with Reinforcement Learning](https://arxiv.org/abs/2508.03680)
*Xufang Luo,Yuge Zhang,Zhiyuan He,Zilong Wang,Siyun Zhao,Dongsheng Li,Luna K. Qiu,Yuqing Yang*

Main category: cs.AI

TL;DR: Agent Lightning是一个灵活的框架，通过强化学习训练大型语言模型，实现与现有AI代理的无缝集成，无需代码修改。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中强化学习训练与代理紧密耦合的问题，提供更灵活的训练方式。

Method: 采用马尔可夫决策过程定义统一数据接口，提出分层RL算法LightningRL，包含信用分配模块。

Result: 实验表明在多种任务中实现稳定、持续的改进。

Conclusion: 框架具有实际代理训练和部署的潜力。

Abstract: We present Agent Lightning, a flexible and extensible framework that enables
Reinforcement Learning (RL)-based training of Large Language Models (LLMs) for
any AI agent. Unlike existing methods that tightly couple RL training with
agent or rely on sequence concatenation with masking, Agent Lightning achieves
complete decoupling between agent execution and training, allowing seamless
integration with existing agents developed via diverse ways (e.g., using
frameworks like LangChain, OpenAI Agents SDK, AutoGen, and building from
scratch) with almost ZERO code modifications. By formulating agent execution as
Markov decision process, we define an unified data interface and propose a
hierarchical RL algorithm, LightningRL, which contains a credit assignment
module, allowing us to decompose trajectories generated by ANY agents into
training transition. This enables RL to handle complex interaction logic, such
as multi-agent scenarios and dynamic workflows. For the system design, we
introduce a Training-Agent Disaggregation architecture, and brings agent
observability frameworks into agent runtime, providing a standardized agent
finetuning interface. Experiments across text-to-SQL, retrieval-augmented
generation, and math tool-use tasks demonstrate stable, continuous
improvements, showcasing the framework's potential for real-world agent
training and deployment.

</details>
