<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 25]
- [cs.CR](#cs.CR) [Total: 15]
- [cs.AI](#cs.AI) [Total: 37]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions](https://arxiv.org/abs/2510.08576)
*Justus Flerlage,Alexander Acker,Odej Kao*

Main category: cs.SE

TL;DR: 本研究评估开源大语言模型作为本地部署意图解析系统的可行性，与GPT-4进行性能对比，探索下一代操作系统中本地智能组件的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有基于云端专有模型的实现存在隐私、自主性和可扩展性限制，需要验证本地可部署的开源LLMs作为意图操作系统基础组件的可行性。

Method: 对多个开源和开放访问模型进行能力评估，与OpenAI的GPT-4系统进行对比分析，评估其在生成用户意图工作流方面的性能。

Result: 研究提供了关于开源LLMs实际可行性、性能权衡和潜力的实证见解，展示了本地可操作组件在下一代操作系统中的应用前景。

Conclusion: 研究结果支持AI基础设施的去中心化和民主化，指向通过本地嵌入智能实现更无缝、自适应和隐私保护的用户设备交互的未来。

Abstract: Large Language Models (LLMs) have emerged as transformative tools for natural
language understanding and user intent resolution, enabling tasks such as
translation, summarization, and, increasingly, the orchestration of complex
workflows. This development signifies a paradigm shift from conventional,
GUI-driven user interfaces toward intuitive, language-first interaction
paradigms. Rather than manually navigating applications, users can articulate
their objectives in natural language, enabling LLMs to orchestrate actions
across multiple applications in a dynamic and contextual manner. However,
extant implementations frequently rely on cloud-based proprietary models, which
introduce limitations in terms of privacy, autonomy, and scalability. For
language-first interaction to become a truly robust and trusted interface
paradigm, local deployment is not merely a convenience; it is an imperative.
This limitation underscores the importance of evaluating the feasibility of
locally deployable, open-source, and open-access LLMs as foundational
components for future intent-based operating systems. In this study, we examine
the capabilities of several open-source and open-access models in facilitating
user intention resolution through machine assistance. A comparative analysis is
conducted against OpenAI's proprietary GPT-4-based systems to assess
performance in generating workflows for various user intentions. The present
study offers empirical insights into the practical viability, performance
trade-offs, and potential of open LLMs as autonomous, locally operable
components in next-generation operating systems. The results of this study
inform the broader discussion on the decentralization and democratization of AI
infrastructure and point toward a future where user-device interaction becomes
more seamless, adaptive, and privacy-conscious through locally embedded
intelligence.

</details>


### [2] [Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?](https://arxiv.org/abs/2510.08609)
*Imranur Rahman,Jill Marley,William Enck,Laurie Williams*

Main category: cs.SE

TL;DR: 本研究通过实证分析npm、PyPI和Cargo生态系统中依赖版本约束的使用情况，发现固定版本(pinning)虽然能减少破坏性变更风险，但最可能导致依赖过时；而浮动版本中，主版本浮动最不容易过时，次版本浮动最不容易产生漏洞。


<details>
  <summary>Details</summary>
Motivation: 开发者在依赖管理时面临两难选择：固定版本可防止破坏性变更但容易过时，浮动版本能自动获取修复但存在风险。目前缺乏关于不同版本约束类型对依赖过时和漏洞风险影响的实证研究。

Method: 识别npm、PyPI和Cargo生态系统中依赖版本约束的使用趋势和变更模式，使用生存分析建模依赖状态转换，评估固定版本与其他约束类型相比导致依赖过时或漏洞的可能性。

Result: 在过时和易受攻击的依赖中，最常用的约束类型是次版本浮动，其次是固定版本。主版本浮动最不容易导致依赖过时，次版本浮动最不容易产生漏洞依赖。

Conclusion: 固定版本虽然被安全从业者推荐以防止供应链攻击，但实际会增加依赖过时的风险。开发者在选择版本约束时应根据具体需求权衡：主版本浮动适合避免过时，次版本浮动适合减少漏洞风险。

Abstract: Developers consistently use version constraints to specify acceptable
versions of the dependencies for their project. \emph{Pinning} dependencies can
reduce the likelihood of breaking changes, but comes with a cost of manually
managing the replacement of outdated and vulnerable dependencies. On the other
hand, \emph{floating} can be used to automatically get bug fixes and security
fixes, but comes with the risk of breaking changes. Security practitioners
advocate \emph{pinning} dependencies to prevent against software supply chain
attacks, e.g., malicious package updates. However, since \emph{pinning} is the
tightest version constraint, \emph{pinning} is the most likely to result in
outdated dependencies. Nevertheless, how the likelihood of becoming outdated or
vulnerable dependencies changes across version constraint types is unknown. The
goal of this study is to aid developers in making an informed dependency
version constraint choice by empirically evaluating the likelihood of
dependencies becoming outdated or vulnerable across version constraint types at
scale. In this study, we first identify the trends in dependency version
constraint usage and the patterns of version constraint type changes made by
developers in the npm, PyPI, and Cargo ecosystems. We then modeled the
dependency state transitions using survival analysis and estimated how the
likelihood of becoming outdated or vulnerable changes when using \emph{pinning}
as opposed to the rest of the version constraint types. We observe that among
outdated and vulnerable dependencies, the most commonly used version constraint
type is \emph{floating-minor}, with \emph{pinning} being the next most common.
We also find that \emph{floating-major} is the least likely to result in
outdated and \emph{floating-minor} is the least likely to result in vulnerable
dependencies.

</details>


### [3] [Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model](https://arxiv.org/abs/2510.08610)
*Imranur Rahman,Md Rayhanur Rahman*

Main category: cs.SE

TL;DR: 提出了一种基于代码分块和相对定位的上下文收集策略，通过语法和语义相似性检索来提升大语言模型在代码补全任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有IDE中的代码补全功能缺乏对有效上下文的研究，需要确定基于IDE可用信息的最佳上下文策略来提升大语言模型的代码补全效果。

Method: 将代码仓库预处理为小代码块，使用基于语法和语义相似性的代码块检索方法，并在最终上下文中采用相对定位策略。

Result: 代码分块和代码块在上下文中的相对定位能够显著提升代码补全任务的性能表现。

Conclusion: 提出的上下文收集策略通过代码分块和相对定位有效提高了大语言模型在代码补全任务中的性能。

Abstract: Code completion can help developers improve efficiency and ease the
development lifecycle. Although code completion is available in modern
integrated development environments (IDEs), research lacks in determining what
makes a good context for code completion based on the information available to
the IDEs for the large language models (LLMs) to perform better. In this paper,
we describe an effective context collection strategy to assist the LLMs in
performing better at code completion tasks. The key idea of our strategy is to
preprocess the repository into smaller code chunks and later use syntactic and
semantic similarity-based code chunk retrieval with relative positioning. We
found that code chunking and relative positioning of the chunks in the final
context improve the performance of code completion tasks.

</details>


### [4] [Impact of LLMs on Team Collaboration in Software Development](https://arxiv.org/abs/2510.08612)
*Devang Dhanuka*

Main category: cs.SE

TL;DR: 该论文研究LLMs在软件开发生命周期中对团队协作的影响，发现LLMs能显著提升效率、改善沟通，但也带来模型局限性和隐私等新挑战。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地集成到软件开发过程中，需要了解它们如何改变团队工作流程和生产力，特别是对团队协作的影响。

Method: 通过文献综述、行业案例、团队调查和两个案例研究，评估LLM辅助工具对协作软件工程实践的影响。

Result: LLMs能显著提高效率（自动化重复任务和文档）、增强沟通清晰度、促进跨职能协作，同时引入模型局限性和隐私问题等新挑战。

Conclusion: LLMs对软件开发团队协作具有积极影响，但需要解决模型定制、工具集成、信任和安全等未来研究方向。

Abstract: Large Language Models (LLMs) are increasingly being integrated into software
development processes, with the potential to transform team workflows and
productivity. This paper investigates how LLMs affect team collaboration
throughout the Software Development Life Cycle (SDLC). We reframe and update a
prior study with recent developments as of 2025, incorporating new literature
and case studies. We outline the problem of collaboration hurdles in SDLC and
explore how LLMs can enhance productivity, communication, and decision-making
in a team context. Through literature review, industry examples, a team survey,
and two case studies, we assess the impact of LLM-assisted tools (such as code
generation assistants and AI-powered project management agents) on
collaborative software engineering practices. Our findings indicate that LLMs
can significantly improve efficiency (by automating repetitive tasks and
documentation), enhance communication clarity, and aid cross-functional
collaboration, while also introducing new challenges like model limitations and
privacy concerns. We discuss these benefits and challenges, present research
questions guiding the investigation, evaluate threats to validity, and suggest
future research directions including domain-specific model customization,
improved integration into development tools, and robust strategies for ensuring
trust and security.

</details>


### [5] [Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools](https://arxiv.org/abs/2510.08640)
*Ha Min Son,Huan Ren,Xin Liu,Zhe Zhao*

Main category: cs.SE

TL;DR: 提出了GradleFixer，一个针对Android构建错误的LLM代理，通过领域特定工具显著提升了构建错误修复成功率


<details>
  <summary>Details</summary>
Motivation: Android作为最大的移动平台，自动构建应用仍面临挑战。虽然LLM在代码修复方面有潜力，但在修复Android构建错误方面研究不足

Method: 1. 创建AndroidBuildBench基准测试集（1,019个构建失败案例）；2. 开发GradleFixer代理，使用领域特定工具检查和操作Gradle构建环境；3. 采用工具桥接策略，将通用shell命令替换为领域感知抽象

Result: GradleFixer实现了81.4%的解决率（pass@1），显著优于依赖通用shell的最先进编码代理

Conclusion: LLM具备解决构建失败的高层知识，但难以通过通用shell将其转化为有效的底层操作。工具桥接策略通过提供API格式的工具和约束操作空间，成功弥合了高层推理与底层执行之间的差距

Abstract: Android is the largest mobile platform, yet automatically building
applications remains a practical challenge. While Large Language Models (LLMs)
show promise for code repair, their use for fixing Android build errors remains
underexplored. To address this gap, we first introduce AndroidBuildBench, a
benchmark of 1,019 build failures curated from the commit histories of 43
open-source Android projects. Each problem is paired with a verified solution
from a subsequent commit, ensuring that fixes are feasible. Second, we propose
GradleFixer, an LLM agent with domain-specific tools for inspecting and
manipulating the Gradle build environment. GradleFixer achieves a resolve rate
of 81.4% (pass@1), significantly outperforming a state-of-the-art coding agent
that relies on a general-purpose shell. GradleFixer's success suggests that
while LLMs possess the high-level knowledge to solve these failures, they
struggle to translate this knowledge into effective low-level actions using a
general-purpose shell. We demonstrate the effectiveness of a strategy we term
Tool Bridging, which replaces general-purpose shell commands with domain-aware
abstractions. We hypothesize this approach works through two mechanisms: 1) it
provides tools in an API-like format that LLMs use more reliably, and 2) it
constrains the action space to relevant operations. This approach bridges the
gap between the model's high-level reasoning and effective low-level execution.

</details>


### [6] [Faver: Boosting LLM-based RTL Generation with Function Abstracted Verifiable Middleware](https://arxiv.org/abs/2510.08664)
*Jianan Mu,Mingyu Shi,Yining Wang,Tianmeng Yang,Bin Sun,Xing Hu,Jing Ye,Huawei Li*

Main category: cs.SE

TL;DR: 提出Faver方法，通过函数抽象的可验证中间件简化基于LLM的RTL验证流程，将电路验证细节与功能实现解耦，提高RTL生成准确性


<details>
  <summary>Details</summary>
Motivation: 当前LLM在RTL生成中存在语义鸿沟问题，高规格说明与RTL之间差距大，训练数据有限，导致生成准确性不足。传统设计验证方法因RTL测试数据稀缺而不适用于LLM

Method: 开发函数抽象的可验证中间件(Faver)，结合LLM友好的代码结构和基于规则的模板，将电路验证细节与功能实现分离，让LLM专注于功能本身

Result: 在SFT模型和开源模型上的实验表明，Faver将模型生成准确性提高了最高14%

Conclusion: Faver方法有效解决了LLM在RTL生成中的验证挑战，通过中间件简化验证流程，显著提升了生成准确性

Abstract: LLM-based RTL generation is an interesting research direction, as it holds
the potential to liberate the least automated stage in the current chip design.
However, due to the substantial semantic gap between high-level specifications
and RTL, coupled with limited training data, existing models struggle with
generation accuracy. Drawing on human experience, design with verification
helps improving accuracy. However, as the RTL testbench data are even more
scarce, it is not friendly for LLMs. Although LLMs excel at higher-level
languages like Python/C, they have a huge semantic gap from RTL. When
implementing the same functionality, Python/C code and hardware code differ
significantly in the spatiotemporal granularity, requiring the LLM not only to
consider high-level functional semantics but also to ensure the low-level
details align with the circuit code. It is not an easy task. In this paper, we
propose a function abstracted verifiable middleware (Faver) that streamlines
RTL verification in LLM-based workflows. By mixing LLM-friendly code structures
with a rule-based template, Faver decouples the details of circuit
verification, allowing the LLM to focus on the functionality itself. In our
experiments on the SFT model and open-source models, Faver improved the model's
generation accuracy by up to 14%.

</details>


### [7] [RA-Gen: A Controllable Code Generation Framework Using ReAct for Multi-Agent Task Execution](https://arxiv.org/abs/2510.08665)
*Aofan Liu,Haoxuan Li,Bin Wang,Ao Yang,Hui Li*

Main category: cs.SE

TL;DR: 提出基于ReAct范式的可控代码生成多智能体框架，通过四个专业智能体协作实现安全、准确、可解释的代码生成，在SVEN数据集上达到94.8%的安全率。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成模型在安全性、准确性和可控性方面存在挑战，缺乏外部工具的动态集成、透明推理和用户安全控制。

Method: 采用多智能体系统架构，包含规划器、基于ReAct的搜索器、代码生成器和提取器四个专业智能体，通过推理轨迹和动作执行的交替实现内外知识的无缝集成。

Result: 在SVEN数据集上使用CodeQL评估达到94.8%的安全率，优于现有方法，支持多语言代码生成。

Conclusion: 该框架通过透明推理过程增强用户信任，提高可控性，为复杂代码生成任务提供高效、精确和可解释的解决方案。

Abstract: Code generation models based on large language models (LLMs) have gained wide
adoption, but challenges remain in ensuring safety, accuracy, and
controllability, especially for complex tasks. Existing methods often lack
dynamic integration of external tools, transparent reasoning, and user control
over safety. To address these issues, we propose a controllable code generation
framework utilizing the ReAct paradigm for multi-agent task execution. This
framework is a multi-agent system designed to enable efficient, precise, and
interpretable code generation through dynamic interactions between LLMs and
external resources. The framework adopts a collaborative architecture
comprising four specialized agents: a Planner for task decomposition, a
Searcher that leverages the ReAct framework for reasoning and tool integration,
a CodeGen agent for accurate code generation, and an Extractor for structured
data retrieval. The ReAct-based Searcher alternates between generating
reasoning traces and executing actions, facilitating seamless integration of
internal knowledge with external tools (such as search engines) to enhance
accuracy and user control. Experimental results show the framework's
effectiveness across multiple languages, achieving a 94.8% security rate on the
SVEN dataset with CodeQL, outperforming existing approaches. Its transparent
reasoning process fosters user trust and improves controllability.

</details>


### [8] [RAG4Tickets: AI-Powered Ticket Resolution via Retrieval-Augmented Generation on JIRA and GitHub Data](https://arxiv.org/abs/2510.08667)
*Mohammad Baqar*

Main category: cs.SE

TL;DR: 提出基于检索增强生成(RAG)的框架，集成Sentence-Transformers和FAISS向量搜索，为JIRA工单提供上下文感知的解决方案推荐，显著提高解决准确性和知识复用。


<details>
  <summary>Details</summary>
Motivation: 现代软件团队在处理重复或相关问题时常因知识分散在JIRA工单、开发者讨论和GitHub PR中而遇到延迟，需要整合这些碎片化知识来加速问题解决。

Method: 使用Sentence-Transformers生成语义嵌入，结合FAISS向量搜索检索相似历史案例，然后通过大语言模型(LLM)基于检索到的证据生成可解释的解决方案建议。

Result: 实验评估显示，该系统在精确率、召回率、解决时间减少和开发者接受度等指标上显著提高了解决准确性、修复质量和知识复用。

Conclusion: 该框架通过统一JIRA和GitHub数据管道、异构软件工件的嵌入索引策略以及基于证据的解决方案生成模块，有效改善了现代DevOps环境中的问题解决效率。

Abstract: Modern software teams frequently encounter delays in resolving recurring or
related issues due to fragmented knowledge scattered across JIRA tickets,
developer discussions, and GitHub pull requests (PRs). To address this
challenge, we propose a Retrieval-Augmented Generation (RAG) framework that
integrates Sentence-Transformers for semantic embeddings with FAISS-based
vector search to deliver context-aware ticket resolution recommendations. The
approach embeds historical JIRA tickets, user comments, and linked PR metadata
to retrieve semantically similar past cases, which are then synthesized by a
Large Language Model (LLM) into grounded and explainable resolution
suggestions. The framework contributes a unified pipeline linking JIRA and
GitHub data, an embedding and FAISS indexing strategy for heterogeneous
software artifacts, and a resolution generation module guided by retrieved
evidence. Experimental evaluation using precision, recall, resolution time
reduction, and developer acceptance metrics shows that the proposed system
significantly improves resolution accuracy, fix quality, and knowledge reuse in
modern DevOps environments.

</details>


### [9] [BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution](https://arxiv.org/abs/2510.08697)
*Terry Yue Zhuo,Xiaolong Jin,Hange Liu,Juyong Jiang,Tianyang Liu,Chen Gong,Bhupesh Bishnoi,Vaisakhi Mishra,Marek Suppa,Noah Ziems,Saiteja Utpala,Ming Xu,Guangyu Song,Kaixin Li,Yuhan Cao,Bo Liu,Zheng Liu,Sabina Abdurakhmanova,Wenhao Yu,Mengzhao Jia,Jihan Yao,Kenneth Hamilton,Kumar Shridhar,Minh Chien Vu,Dingmin Wang,Jiawei Liu,Zijian Wang,Qian Liu,Binyuan Hui,Meg Risdal,Ahsen Khaliq,Atin Sood,Zhenchang Xing,Wasi Uddin Ahmad,John Grundy,David Lo,Banghua Zhu,Xiaoning Du,Torsten Scholak,Leandro von Werra*

Main category: cs.SE

TL;DR: BigCodeArena是一个基于Chatbot Arena构建的代码生成人类评估平台，提供实时执行环境来评估LLM生成的代码质量。该研究收集了超过14,000个代码对话，识别了4,700个带有人类偏好的多轮样本，并开发了BigCodeReward和AutoCodeArena两个基准来系统评估LLM的代码能力。


<details>
  <summary>Details</summary>
Motivation: 在代码领域，手动评估LLM生成内容的质量极具挑战性，因为需要理解冗长的原始代码并模拟代码执行过程。现有的人类评估平台缺乏对代码执行的支持。

Method: 基于Chatbot Arena构建BigCodeArena平台，提供实时代码执行环境，收集了14,000多个代码对话，涵盖10种语言和8种执行环境。通过分析人类偏好数据，开发了BigCodeReward评估奖励模型一致性，以及AutoCodeArena自动Elo评分基准。

Result: 研究发现大多数LLM在有执行结果时能更好地判断代码偏好。专有LLM如GPT-5、Claude-Sonnet-4和Claude-Opus-4在代码生成性能方面领先于新兴模型。

Conclusion: BigCodeArena为代码生成评估提供了有效的平台，揭示了LLM在细粒度代码任务中的偏好模式，并证明了专有模型在当前代码生成领域的领先地位。

Abstract: Crowdsourced model evaluation platforms, such as Chatbot Arena, enable
real-time evaluation from human perspectives to assess the quality of model
responses. In the coding domain, manually examining the quality of
LLM-generated content is extremely challenging, as it requires understanding
long chunks of raw code and deliberately simulating code execution. To this
end, we introduce BigCodeArena, an open human evaluation platform for code
generation backed by a comprehensive and on-the-fly execution environment.
Built on top of Chatbot Arena, BigCodeArena enables the execution of
LLM-generated code and allows humans to interact with the execution process and
outcomes. We collected over 14,000 raw code-centric conversation sessions
across 10 widely used LLMs, spanning 10 languages and 8 types of execution
environments. Among these conversations, we identified more than 4,700
multi-turn samples with pairwise human preferences. Further analysis uncovers
underexplored preferences of LLMs in fine-grained domains characterized by
tasks, languages, and frameworks. To systematically examine code understanding
and generation capabilities of frontier LLMs, we curated two benchmarks based
on the collected data, namely BigCodeReward and AutoCodeArena. For
BigCodeReward, we post-processed the 4,700 conversations and evaluated the
consistency between reward models and human preferences. The evaluation shows
that most LLMs have superior performance in judging coding preferences when the
execution results are available. Inspired by these findings, we propose
AutoCodeArena, an automatic Elo rating benchmark designed to assess the coding
quality of LLMs without human involvement. We find that proprietary LLMs like
GPT-5, Claude-Sonnet-4, and Claude-Opus-4 still lead in code generation
performance among recent emerging models.

</details>


### [10] [Search-based Hyperparameter Tuning for Python Unit Test Generation](https://arxiv.org/abs/2510.08716)
*Stephan Lukasczyk,Gordon Fraser*

Main category: cs.SE

TL;DR: 使用差分进化算法调优DynaMOSA和MIO多目标搜索算法的超参数，相比网格搜索更高效，能显著提升测试套件的覆盖率。


<details>
  <summary>Details</summary>
Motivation: 搜索式测试生成算法有众多配置选项，用户通常使用默认值，但这些默认值可能不是最优的。超参数调优可以找到更好的参数值，但传统方法资源需求高。

Method: 使用差分进化算法作为元启发式搜索方法，调优Pynguin框架中DynaMOSA和MIO算法的超参数。

Result: 调优后的DynaMOSA算法显著提高了测试套件的覆盖率，且差分进化比基础网格搜索更高效。

Conclusion: 差分进化是有效的超参数调优方法，能提升搜索式测试生成算法的性能。

Abstract: Search-based test-generation algorithms have countless configuration options.
Users rarely adjust these options and usually stick to the default values,
which may not lead to the best possible results. Tuning an algorithm's
hyperparameters is a method to find better hyperparameter values, but it
typically comes with a high demand of resources. Meta-heuristic search
algorithms -- that effectively solve the test-generation problem -- have been
proposed as a solution to also efficiently tune parameters. In this work we
explore the use of differential evolution as a means for tuning the
hyperparameters of the DynaMOSA and MIO many-objective search algorithms as
implemented in the Pynguin framework. Our results show that significant
improvement of the resulting test suite's coverage is possible with the tuned
DynaMOSA algorithm and that differential evolution is more efficient than basic
grid search.

</details>


### [11] [PyMigTool: a tool for end-to-end Python library migration](https://arxiv.org/abs/2510.08810)
*Mohayeminul Islam,Ajay Kumar Jha,May Mahmoud,Sarah Nadi*

Main category: cs.SE

TL;DR: 开发了PyMigTool，一个结合LLM、静态分析和动态分析的端到端Python库迁移工具，能够自动迁移任意功能相似的Python库之间的代码。


<details>
  <summary>Details</summary>
Motivation: 手动库迁移耗时且容易出错，现有自动化技术大多停留在API映射阶段或支持有限的库和代码转换。

Method: 使用LLM作为主要迁移引擎，结合静态分析和动态分析，开发了PyMigTool命令行应用程序。

Result: 在717个真实Python应用上评估，PyMigTool能够完全正确迁移32%的案例，剩余迁移中超过一半项目只有14%的迁移相关变更需要开发者修复。

Conclusion: LLM能有效执行库迁移，结合后处理步骤可进一步提升性能，PyMigTool为Python库迁移提供了实用的端到端解决方案。

Abstract: Library migration is the process of replacing a library with a similar one in
a software project. Manual library migration is time consuming and error prone,
as it requires developers to understand the Application Programming Interfaces
(API) of both libraries, map equivalent APIs, and perform the necessary code
transformations. Due to the difficulty of the library migration process, most
of the existing automated techniques and tooling stop at the API mapping stage
or support a limited set of libraries and code transformations. In this paper,
we develop an end-to-end solution that can automatically migrate code between
any arbitrary pair of Python libraries that provide similar functionality. Due
to the promising capabilities of Large Language Models (LLMs) in code
generation and transformation, we use LLMs as the primary engine for migration.
Before building the tool, we first study the capabilities of LLMs for library
migration on a benchmark of 321 real-world library migrations. We find that
LLMs can effectively perform library migration, but some post-processing steps
can further improve the performance. Based on this, we develop PyMigTool, a
command line application that combines the power of LLMs, static analysis, and
dynamic analysis to provide accurate library migration. We evaluate PyMigTool
on 717 real-world Python applications that are not from our benchmark. We find
that PyMigTool can migrate 32% of the migrations with complete correctness. Of
the remaining migrations, only 14% of the migration-related changes are left
for developers to fix for more than half of the projects.

</details>


### [12] [McMining: Automated Discovery of Misconceptions in Student Code](https://arxiv.org/abs/2510.08827)
*Erfan Al-Hossami,Razvan Bunescu*

Main category: cs.SE

TL;DR: 提出了McMining任务，用于从学生代码样本中挖掘编程误解，并开发了包含误解和代码样本的基准数据集。通过评估发现Gemini、Claude和GPT等LLM模型能有效发现学生代码中的误解。


<details>
  <summary>Details</summary>
Motivation: 学生在学习编程时经常产生各种编程语言概念的误解，这些误解不仅会导致bug或低效代码，还会阻碍相关概念的学习。

Method: 开发了可扩展的误解基准数据集和大量包含误解的代码样本，引入了两种基于LLM的McMiner方法。

Result: 通过广泛评估表明，Gemini、Claude和GPT系列的模型在发现学生代码中的误解方面表现有效。

Conclusion: McMining任务和基准数据集为编程教育中的误解检测提供了有效工具，LLM模型在此任务上表现出色。

Abstract: When learning to code, students often develop misconceptions about various
programming language concepts. These can not only lead to bugs or inefficient
code, but also slow down the learning of related concepts. In this paper, we
introduce McMining, the task of mining programming misconceptions from samples
of code from a student. To enable the training and evaluation of McMining
systems, we develop an extensible benchmark dataset of misconceptions together
with a large set of code samples where these misconceptions are manifested. We
then introduce two LLM-based McMiner approaches and through extensive
evaluations show that models from the Gemini, Claude, and GPT families are
effective at discovering misconceptions in student code.

</details>


### [13] [Identifying Video Game Debugging Bottlenecks: An Industry Perspective](https://arxiv.org/abs/2510.08834)
*Carlos Pinto Gomez,Fabio Petrillo*

Main category: cs.SE

TL;DR: 游戏开发者花费36.6%时间检查游戏工件，35.1%时间本地复现bug，主要调试工具包括屏幕控制台、调试绘制、调试相机等


<details>
  <summary>Details</summary>
Motivation: 传统软件调试技术不完全适用于视频游戏，需要研究游戏开发特有的调试方法和实践

Method: 记录20名资深游戏开发者的调试会话，分析崩溃、对象行为和对象持久性等关键bug的调试过程

Result: 识别出调试活动瓶颈，发现游戏开发者主要时间花在检查游戏工件和复现bug上，不同学科在调试中协作，技术角色处于核心位置

Conclusion: 视频游戏调试需要专门的工具和技术，团队协作和技术角色在调试过程中至关重要

Abstract: Conventional debugging techniques used in traditional software are similarly
used when debugging video games. However, the reality of video games require
its own set of unique debugging techniques such as On-Screen Console, Debug
Draws, Debug Camera, Cheats and In-Game Menus, and Data Scrubbing. In this
article, we provide insights from a video game studio on how 20 seasoned
industry game developers debug during the production of a game. Our experiments
rely on the recordings of debugging sessions for the most critical bugs
categorized as Crashes, Object Behaviors, and Object Persistence. In this
paper, we focus on identifying the debugging activities that bottleneck bug
resolution. We also identify the debugging tools used to perform debugging
techniques. Lastly, we present how different disciplines collaborate during
debugging and how technical roles are at the core of debugging. Our thematic
analysis has identified game developers spend 36.6\% of their time inspecting
game artifacts and 35.1\% of their time reproducing the bug locally.

</details>


### [14] [Repository-Aware File Path Retrieval via Fine-Tuned LLMs](https://arxiv.org/abs/2510.08850)
*Vasudha Yanuganti,Ishaan Puri,Swapnil Chhatre,Mantinder Singh,Ashok Jallepalli,Hritvik Shrivastava,Pradeep Kumar Sharma*

Main category: cs.SE

TL;DR: 提出了一种基于LLM的文件路径检索方法，通过微调Qwen3-8B模型，直接从自然语言查询预测相关文件路径，显著提升了代码搜索的准确性和语义理解能力。


<details>
  <summary>Details</summary>
Motivation: 传统代码搜索方法缺乏语义上下文和跨文件链接理解，而LLM虽然理解自然语言但缺乏仓库特定细节，需要一种结合两者优势的解决方案。

Method: 使用QLoRA和Unsloth优化微调Qwen3-8B模型，通过六种基于AST结构和仓库内容的代码感知策略生成训练数据，涵盖从单文件提示到分层仓库摘要的广泛场景。

Result: 在Python项目中达到91%精确匹配和93%召回率，在PyTorch等大型代码库中达到59%召回率，明显优于单策略训练。

Conclusion: 多级代码信号帮助LLM推理跨文件上下文，该方法具有可扩展性，未来可与基于LLM的代码智能系统集成。

Abstract: Modern codebases make it hard for developers and AI coding assistants to find
the right source files when answering questions like "How does this feature
work?" or "Where was the bug introduced?" Traditional code search (keyword or
IR based) often misses semantic context and cross file links, while large
language models (LLMs) understand natural language but lack repository specific
detail. We present a method for file path retrieval that fine tunes a strong
LLM (Qwen3-8B) with QLoRA and Unsloth optimizations to predict relevant file
paths directly from a natural language query. To build training data, we
introduce six code aware strategies that use abstract syntax tree (AST)
structure and repository content to generate realistic question-answer pairs,
where answers are sets of file paths. The strategies range from single file
prompts to hierarchical repository summaries, providing broad coverage. We fine
tune on Python projects including Flask, Click, Jinja, FastAPI, and PyTorch,
and obtain high retrieval accuracy: up to 91\% exact match and 93\% recall on
held out queries, clearly beating single strategy training. On a large codebase
like PyTorch (about 4,000 Python files), the model reaches 59\% recall, showing
scalability. We analyze how multi level code signals help the LLM reason over
cross file context and discuss dataset design, limits (for example, context
length in very large repos), and future integration of retrieval with LLM based
code intelligence.

</details>


### [15] [Vector Graph-Based Repository Understanding for Issue-Driven File Retrieval](https://arxiv.org/abs/2510.08876)
*Kostiantyn Bevziuk,Andrii Fatula,Svetozar Lashin Yaroslav Opanasenko,Anna Tukhtarova,Ashok Jallepalli Pradeepkumar Sharma,Hritvik Shrivastava*

Main category: cs.SE

TL;DR: 提出一个将大型软件仓库转换为向量化知识图谱的系统，该图谱反映项目架构和语义结构，能够自动化后续仓库开发。


<details>
  <summary>Details</summary>
Motivation: 大型软件仓库难以理解和维护，需要自动化工具来捕获语义关系并支持后续开发。

Method: 构建向量化知识图谱，编码语法关系（包含、实现、引用、调用、继承），并用LLM生成摘要和向量嵌入。采用混合检索管道结合语义检索和图感知扩展，使用LLM助手生成受限的只读图请求。

Result: 系统能够有效捕获仓库的语义关系，实现开发过程的自动化。

Conclusion: 该方法为大型软件仓库的分析和开发提供了有效的自动化解决方案。

Abstract: We present a repository decomposition system that converts large software
repositories into a vectorized knowledge graph which mirrors project
architectural and semantic structure, capturing semantic relationships and
allowing a significant level of automatization of further repository
development. The graph encodes syntactic relations such as containment,
implementation, references, calls, and inheritance, and augments nodes with
LLM-derived summaries and vector embeddings. A hybrid retrieval pipeline
combines semantic retrieval with graph-aware expansion, and an LLM-based
assistant formulates constrained, read-only graph requests and produces
human-oriented explanations.

</details>


### [16] [SEER: Sustainability Enhanced Engineering of Software Requirements](https://arxiv.org/abs/2510.08981)
*Mandira Roy,Novarun Deb,Nabendu Chaki,Agostino Cortesi*

Main category: cs.SE

TL;DR: SEER是一个在软件开发早期阶段处理可持续性问题的框架，通过识别、评估和优化可持续性需求，使用大语言模型和RAG方法实现。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为高层次指导，实施耗时且依赖团队适应性，且主要关注设计或实现阶段，而可持续性评估应从需求工程阶段开始。

Method: SEER框架分三个阶段：从通用分类法中识别特定软件产品的可持续性需求；基于识别的可持续性需求评估系统需求的可持续性；优化未能满足任何可持续性需求的系统需求。使用大语言模型推理能力和RAG方法实现。

Result: 在四个不同领域的软件项目上进行了实验，使用Gemini 2.5推理模型生成的结果表明，该方法能准确识别跨领域广泛可持续性问题。

Conclusion: SEER框架能有效在软件开发早期阶段处理可持续性问题，通过自动化方法提高可持续性评估的效率和准确性。

Abstract: The rapid expansion of software development has significant environmental,
technical, social, and economic impacts. Achieving the United Nations
Sustainable Development Goals by 2030 compels developers to adopt sustainable
practices. Existing methods mostly offer high-level guidelines, which are
time-consuming to implement and rely on team adaptability. Moreover, they focus
on design or implementation, while sustainability assessment should start at
the requirements engineering phase. In this paper, we introduce SEER, a
framework which addresses sustainability concerns in the early software
development phase. The framework operates in three stages: (i) it identifies
sustainability requirements (SRs) relevant to a specific software product from
a general taxonomy; (ii) it evaluates how sustainable system requirements are
based on the identified SRs; and (iii) it optimizes system requirements that
fail to satisfy any SR. The framework is implemented using the reasoning
capabilities of large language models and the agentic RAG (Retrieval Augmented
Generation) approach. SEER has been experimented on four software projects from
different domains. Results generated using Gemini 2.5 reasoning model
demonstrate the effectiveness of the proposed approach in accurately
identifying a broad range of sustainability concerns across diverse domains.

</details>


### [17] [Towards a Taxonomy of Sustainability Requirements for Software Design](https://arxiv.org/abs/2510.08990)
*Mandira Roy,Novarun Deb,Nabendu Chaki,Agostino Cortesi*

Main category: cs.SE

TL;DR: 该研究通过系统文献综述构建了一个全面的可持续性需求分类法，涵盖环境、技术、社会和经济四个维度，并提供了定义、指标和相关性矩阵。


<details>
  <summary>Details</summary>
Motivation: 现有可持续性需求研究存在碎片化、维度单一或领域局限的问题，缺乏统一的分类法来支持软件工程社区系统性地处理可持续性问题。

Method: 采用系统文献综述方法，从最新研究中提取和整理可持续性需求，构建跨四个维度的分类体系。

Result: 开发了一个全面的可持续性需求分类法，包含各维度的明确定义、相关指标和度量方法，以及展示不同维度间协同与冲突的相关性矩阵。

Conclusion: 该分类法为软件开发者和研究者提供了系统化参考，帮助他们在可持续软件开发中有效制定、管理和协调需求权衡。

Abstract: Software systems are a significant contributor to global sustainability
concerns, demanding that environmental, social, technical, and economic factors
be systematically addressed from the initial requirements engineering phase.
Although existing research provides various sustainability requirements (SRs),
these contributions are often fragmented, specific to certain dimensions, or
limited to particular application domains, resulting in a critical lack of a
unified, comprehensive taxonomy for the software engineering community. To
address this gap, this research conducts a Systematic Literature Review (SLR)
to extract and organize sustainability requirements from the state-of-the-art.
The primary contribution is a comprehensive taxonomy of SRs across the four
dimensions of sustainability (environmental, technical, social, and economic).
For each identified category, we provide clear definitions, associated metrics,
and measures. Furthermore, we depict a correlation matrix that projects the
positive and negative influences (synergies and conflicts) among categories
across different dimensions. This systematized reference assists both software
developers and researchers in effectively formulating, managing, and
reconciling trade-offs within sustainable software development.

</details>


### [18] [Saving SWE-Bench: A Benchmark Mutation Approach for Realistic Agent Evaluation](https://arxiv.org/abs/2510.08996)
*Spandan Garg,Ben Steenhoek,Yufan Huang*

Main category: cs.SE

TL;DR: 提出了一种新的基准测试框架，将现有的正式基准转化为基于开发者与聊天代理交互模式的真实用户查询，发现现有基准显著高估了代理的实际能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于GitHub问题的软件工程代理评估基准无法准确反映开发者在IDE中与聊天编码助手的真实交互方式，导致对代理实际能力的系统性高估。

Method: 通过系统分析开发者与聊天代理的交互模式，将现有正式基准转化为真实用户风格的查询，并将此方法应用于多个基准数据集。

Result: 发现现有基准显著高估了代理能力，在公共基准上某些模型的能力被高估超过50%，在内部基准上高估约10-16%。

Conclusion: 这项工作通过基准变异技术为评估交互式聊天软件工程代理建立了新的范式。

Abstract: Current benchmarks for evaluating software engineering agents, such as
SWE-Bench Verified, are predominantly derived from GitHub issues and fail to
accurately reflect how developers interact with chat-based coding assistants in
integrated development environments (IDEs). We posit that this mismatch leads
to a systematic overestimation of agent's capabilities in real-world scenarios,
especially bug fixing. We introduce a novel benchmarking framework that
transforms existing formal benchmarks into realistic user queries through
systematic analysis of developer interaction patterns with chat-based agents.
Our methodology is flexible and can be easily extended to existing benchmarks.
In this paper, we apply our testing framework to SWE-Bench Verified, the
TypeScript subset of Multi-SWE-Bench and a private benchmark, SWE-Bench C# and
transform formal GitHub issue descriptions into realistic user-style queries
based on telemetry analysis of a popular chat-based agent interactions. Our
findings reveal that existing benchmarks significantly overestimate agent
capabilities for some models by >50% over baseline performance for public
benchmarks and ~10-16% for our internal benchmark. This work establishes a new
paradigm for evaluating interactive chat-based software engineering agents
through benchmark mutation techniques.

</details>


### [19] [Cost-Efficient Long Code Translation using LLMs while Leveraging Identifier Replacements](https://arxiv.org/abs/2510.09045)
*Manojit Chakraborty,Madhusudan Ghosh,Rishabh Gupta*

Main category: cs.SE

TL;DR: 提出了一种零样本代码翻译方法，通过将长标识符替换为通用占位符来减少token数量，提高长代码翻译的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理超出上下文窗口的长源代码时，往往产生不准确的翻译结果，需要解决长代码翻译的效率和准确性挑战。

Method: 采用标识符替换策略，在翻译过程中将用户给定的长标识符替换为通用占位符，让LLM专注于代码的逻辑结构。

Result: 实证结果表明该方法能保留语法和层次结构信息，并产生token数量减少的翻译结果。

Conclusion: 该方法通过减少token数量和内存使用，提高了长代码翻译的效率和成本效益。

Abstract: In the domain of software development, LLMs have been utilized to automate
tasks such as code translation, where source code from one programming language
is translated to another while preserving its functionality. However, LLMs
often struggle with long source codes that don't fit into the context window,
which produces inaccurate translations. To address this, we propose a novel
zero-shot code translation method that incorporates identifier replacement. By
substituting user-given long identifiers with generalized placeholders during
translation, our method allows the LLM to focus on the logical structure of the
code, by reducing token count and memory usage, which improves the efficiency
and cost-effectiveness of long code translation. Our empirical results
demonstrate that our approach preserves syntactical and hierarchical
information and produces translation results with reduced tokens.

</details>


### [20] [Model-Assisted and Human-Guided: Perceptions and Practices of Software Professionals Using LLMs for Coding](https://arxiv.org/abs/2510.09058)
*Italo Santos,Cleyton Magalhaes,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: 对131名软件从业者的全球调查显示，LLMs在软件开发中被广泛用于编码任务，带来生产力提升和认知负担减轻，但也存在输出不准确、上下文理解有限和伦理风险等问题。


<details>
  <summary>Details</summary>
Motivation: 了解LLMs在实际软件开发中的使用情况和从业者对其优缺点的认知，填补对LLM工具实际应用理解的空白。

Method: 通过全球调查收集了131名软件从业者的反馈数据，分析LLMs在软件开发各阶段的使用情况。

Result: 从业者报告LLMs提高了生产力、减轻了认知负担、加速了学习，但也担忧输出不准确、上下文理解有限和伦理风险。大多数开发者将LLMs视为辅助工具而非独立解决方案。

Conclusion: LLMs在软件开发中展现出实用价值，但需要谨慎使用。研究为未来LLM在软件工程中的负责任使用提供了从业者视角的重要参考。

Abstract: Large Language Models have quickly become a central component of modern
software development workflows, and software practitioners are increasingly
integrating LLMs into various stages of the software development lifecycle.
Despite the growing presence of LLMs, there is still a limited understanding of
how these tools are actually used in practice and how professionals perceive
their benefits and limitations. This paper presents preliminary findings from a
global survey of 131 software practitioners. Our results reveal how LLMs are
utilized for various coding-specific tasks. Software professionals report
benefits such as increased productivity, reduced cognitive load, and faster
learning, but also raise concerns about LLMs' inaccurate outputs, limited
context awareness, and associated ethical risks. Most developers treat LLMs as
assistive tools rather than standalone solutions, reflecting a cautious yet
practical approach to their integration. Our findings provide an early,
practitioner-focused perspective on LLM adoption, highlighting key
considerations for future research and responsible use in software engineering.

</details>


### [21] [Literate Tracing](https://arxiv.org/abs/2510.09073)
*Matthew Sotoudeh*

Main category: cs.SE

TL;DR: 本文提出了一种称为'文学化追踪'的程序文档范式，通过带注释的具体执行追踪来解释软件系统，并开发了TReX工具来创建交互式、可视化的文学化追踪。


<details>
  <summary>Details</summary>
Motivation: 随着计算机系统日益庞大复杂，系统专家向新手解释程序工作原理变得至关重要。现有代码注释缺乏全局上下文，设计文档又缺乏与代码的具体连接。

Method: 使用文学化追踪范式，通过带注释的具体执行追踪来解释软件系统。开发了TReX工具来创建交互式、可视化的追踪，并保证与程序语义的一致性。

Result: 已使用TReX为大型系统软件（包括Linux内核、Git源代码控制系统和GCC编译器）的组件编写了文学化追踪文档。

Conclusion: 文学化追踪补充了代码注释和设计文档的不足，提供了一种有效的程序文档方法，特别适用于复杂软件系统的理解和教学。

Abstract: As computer systems grow ever larger and more complex, a crucial task in
software development is for one person (the system expert) to communicate to
another (the system novice) how a certain program works. This paper reports on
the author's experiences with a paradigm for program documentation that we call
literate tracing. A literate trace explains a software system using annotated,
concrete execution traces of the system. Literate traces complement both
in-code comments (which often lack global context) and out-of-band design docs
(which often lack a concrete connection to the code). We also describe TReX,
our tool for making literate traces that are interactive, visual, and
guaranteed by construction to be faithful to the program semantics. We have
used TReX to write literate traces explaining components of large systems
software including the Linux kernel, Git source control system, and GCC
compiler.

</details>


### [22] [Constraint-Guided Unit Test Generation for Machine Learning Libraries](https://arxiv.org/abs/2510.09108)
*Lukas Krodinger,Altin Hajdari,Stephan Lukasczyk,Gordon Fraser*

Main category: cs.SE

TL;DR: PynguinML通过从官方API文档中提取约束条件，改进Pynguin测试生成器，为机器学习API生成合规输入，显著提高了代码覆盖率。


<details>
  <summary>Details</summary>
Motivation: 机器学习库如PyTorch和TensorFlow的API通常对输入有严格的约束，涉及复杂的数据结构如张量。现有的自动化测试生成工具如Pynguin不了解这些约束，经常生成不合规的输入，导致测试早期失败和代码覆盖率有限。

Method: 提出PynguinML方法，改进Pynguin测试生成器，利用从官方API文档中提取的约束条件来生成符合要求的ML API输入。

Result: 在PyTorch和TensorFlow的165个模块上评估，PynguinML相比Pynguin显著提高了测试效果，代码覆盖率最高提升了63.9%。

Conclusion: PynguinML通过利用API约束条件生成合规输入，能够更彻底地测试机器学习库，显著提高代码覆盖率。

Abstract: Machine learning (ML) libraries such as PyTorch and TensorFlow are essential
for a wide range of modern applications. Ensuring the correctness of ML
libraries through testing is crucial. However, ML APIs often impose strict
input constraints involving complex data structures such as tensors. Automated
test generation tools such as Pynguin are not aware of these constraints and
often create non-compliant inputs. This leads to early test failures and
limited code coverage. Prior work has investigated extracting constraints from
official API documentation. In this paper, we present PynguinML, an approach
that improves the Pynguin test generator to leverage these constraints to
generate compliant inputs for ML APIs, enabling more thorough testing and
higher code coverage. Our evaluation is based on 165 modules from PyTorch and
TensorFlow, comparing PynguinML against Pynguin. The results show that
PynguinML significantly improves test effectiveness, achieving up to 63.9 %
higher code coverage.

</details>


### [23] [A Semantic Framework for Patient Digital Twins in Chronic Care](https://arxiv.org/abs/2510.09134)
*Amal Elgammal,Bernd J. Krämer,Michael P. Papazoglou,Mira Raheem*

Main category: cs.SE

TL;DR: 本文提出了患者医疗数字孪生(PMDT)框架，通过本体驱动方法整合多模态健康数据，为个性化慢性护理提供统一且隐私保护的解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前数字孪生应用多为器官特异性或孤立数据类型，缺乏统一且隐私保护的基础框架，无法满足个性化慢性护理对多模态数据整合的需求。

Method: 采用OWL 2.0实现的本体驱动框架，围绕模块化蓝图(患者、疾病诊断、治疗随访、轨迹、安全、路径和不良事件)构建，通过专家工作坊、问卷和真实世界免疫治疗患者试点研究进行迭代优化和验证。

Result: 评估确认了本体覆盖范围、推理正确性、可用性和GDPR合规性，PMDT能够统一异构数据，支持描述性、预测性和规范性分析，以联邦化、隐私保护的方式运行。

Conclusion: PMDT通过弥合数据碎片化和语义标准化方面的差距，为下一代数字健康生态系统提供了验证基础，将慢性护理转变为主动、持续优化和公平的管理模式。

Abstract: Personalized chronic care requires the integration of multimodal health data
to enable precise, adaptive, and preventive decision-making. Yet most current
digital twin (DT) applications remain organ-specific or tied to isolated data
types, lacking a unified and privacy-preserving foundation. This paper
introduces the Patient Medical Digital Twin (PMDT), an ontology-driven in
silico patient framework that integrates physiological, psychosocial,
behavioral, and genomic information into a coherent, extensible model.
Implemented in OWL 2.0, the PMDT ensures semantic interoperability, supports
automated reasoning, and enables reuse across diverse clinical contexts. Its
ontology is structured around modular Blueprints (patient, disease and
diagnosis, treatment and follow-up, trajectories, safety, pathways, and adverse
events), formalized through dedicated conceptual views. These were iteratively
refined and validated through expert workshops, questionnaires, and a pilot
study in the EU H2020 QUALITOP project with real-world immunotherapy patients.
Evaluation confirmed ontology coverage, reasoning correctness, usability, and
GDPR compliance. Results demonstrate the PMDT's ability to unify heterogeneous
data, operationalize competency questions, and support descriptive, predictive,
and prescriptive analytics in a federated, privacy-preserving manner. By
bridging gaps in data fragmentation and semantic standardization, the PMDT
provides a validated foundation for next-generation digital health ecosystems,
transforming chronic care toward proactive, continuously optimized, and
equitable management.

</details>


### [24] [A Model-Driven Engineering Approach to AI-Powered Healthcare Platforms](https://arxiv.org/abs/2510.09308)
*Mira Raheem,Amal Elgammal,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi*

Main category: cs.SE

TL;DR: 提出基于模型驱动工程的医疗AI框架，使用图形化领域特定语言MILA和联邦学习架构，在多中心癌症免疫治疗研究中实现高精度预测并保护数据隐私。


<details>
  <summary>Details</summary>
Motivation: 解决医疗AI实践中面临的数据碎片化、隐私保护严格和系统构建复杂等挑战，促进AI在医疗领域的实际应用。

Method: 采用模型驱动工程框架，包含形式化元模型、领域特定语言和自动化转换，核心是图形化医学互操作性语言MILA，结合联邦学习架构实现跨机构协作。

Result: 在多中心癌症免疫治疗研究中，生成的机器学习管道在关键任务中达到98.5%和98.3%的准确率，同时显著减少手动编码工作量。

Conclusion: 模型驱动工程原则（元建模、语义集成和自动化代码生成）为实现可互操作、可复现和可信赖的数字健康平台提供了可行路径。

Abstract: Artificial intelligence (AI) has the potential to transform healthcare by
supporting more accurate diagnoses and personalized treatments. However, its
adoption in practice remains constrained by fragmented data sources, strict
privacy rules, and the technical complexity of building reliable clinical
systems. To address these challenges, we introduce a model driven engineering
(MDE) framework designed specifically for healthcare AI. The framework relies
on formal metamodels, domain-specific languages (DSLs), and automated
transformations to move from high level specifications to running software. At
its core is the Medical Interoperability Language (MILA), a graphical DSL that
enables clinicians and data scientists to define queries and machine learning
pipelines using shared ontologies. When combined with a federated learning
architecture, MILA allows institutions to collaborate without exchanging raw
patient data, ensuring semantic consistency across sites while preserving
privacy. We evaluate this approach in a multi center cancer immunotherapy
study. The generated pipelines delivered strong predictive performance, with
support vector machines achieving up to 98.5 percent and 98.3 percent accuracy
in key tasks, while substantially reducing manual coding effort. These findings
suggest that MDE principles metamodeling, semantic integration, and automated
code generation can provide a practical path toward interoperable,
reproducible, and trustworthy digital health platforms.

</details>


### [25] [TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation](https://arxiv.org/abs/2510.09400)
*He Jiang,Yufu Wang,Hao Lin,Peiyu Zou,Zhide Zhou,Ang Jia,Xiaochen Li,Zhilei Ren*

Main category: cs.SE

TL;DR: 提出了TIT方法，通过树结构指令调优解决LLM代码翻译中的语法混淆和语义对齐问题，显著提升翻译成功率


<details>
  <summary>Details</summary>
Motivation: 现有LLM代码翻译方法对语言特定特征敏感，容易引入源语言语法和词汇，导致语法混淆；同时缺乏细粒度语义对齐，造成语义偏差

Method: TIT包含三个模块：语法信息表示模块集成语言无关语法特征，细粒度并行数据集增强模块通过语句级分割和对齐匹配生成高质量数据，双阶段树指令调优模块减轻LLM上下文处理负担

Result: 实验结果表明该方法在多个LLM中显著优于现有方法，代码翻译成功率提高1.22-1.75倍，同时显著减少语法混淆

Conclusion: TIT方法通过结构化语法表示和细粒度语义对齐，有效解决了LLM代码翻译中的关键问题，为代码翻译任务提供了新的解决方案

Abstract: Large Language Models (LLMs) have shown strong performance in automated
source-to-target code translation through pretraining on extensive code
corpora. However, mainstream LLM-based code translation methods suffer from two
critical limitations. First, they are highly sensitive to language-specific
features, which often introduce source-language syntax or lexicon into the
output, leading to syntactic confusion. Second, they lack fine-grained semantic
alignment due to an over-reliance on function-level parallel datasets,
resulting in semantic misalignment between the translated code and the original
source. To overcome these limitations, we propose TIT, a Tree-structured
Instruction Tuning paradigm for LLM-based code translation. Specifically, TIT
consists of three modules. First, to mitigate syntactic confusion, the
syntactic information representation module integrates language-agnostic
syntactic features via structured parsing. Then, to generate high-quality
fine-grained parallel data, the fine-grained parallel dataset augmentation
module aligns nodes with code segments through statement-level segmentation and
contrastive matching. Finally, we leverage the dual-stage tree instruction
tuning module to alleviate the contextual processing burden on the LLM caused
by the introduction of syntactic information. The first stage employs
syntax-aware fine-tuning to enable the LLM to autonomously comprehend
structured syntactic information, while the second stage utilizes code
generation fine-tuning to guide the model in generating accurate target code
based on function-level syntactic dependencies. The experimental results
demonstrate that the proposed method significantly outperforms existing
approaches in multiple LLMs, achieving a success rate 1.22x-1.75x higher in
code translation while markedly reducing syntactic confusion.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [26] [Are Voters Willing to Collectively Secure Elections? Unraveling a Practical Blockchain Voting System](https://arxiv.org/abs/2510.08700)
*Zhuolun Li,Haluk Sonmezler,Faiza Shirazi,Febin Shaji,Tymoteusz Mroczkowski,Dexter Lardner,Matthew Alain Camus,Evangelos Pournaras*

Main category: cs.CR

TL;DR: 提出了一种基于区块链的集体安全投票系统，通过选民自愿成为秘密持有者来保护选票机密性，结合门限密码学和智能合约实现强保密性和可验证性。


<details>
  <summary>Details</summary>
Motivation: 在去中心化、大规模选举中确保选票机密性具有挑战性，需要平衡强保密保证与现实适用性。

Method: 设计并实现了基于区块链的集体安全投票系统，结合门限密码学和智能合约，提供直观用户界面隐藏底层复杂性。

Result: 用户测试显示选民高度愿意担任秘密持有者，可靠参与份额释放，并对系统安全性有高度信心。

Conclusion: 选民能够集体维护选票机密性，这种实际部署是可行的，为电子投票系统提供了新的安全保障方案。

Abstract: Ensuring ballot secrecy is critical for fair and trustworthy electronic
voting systems, yet achieving strong secrecy guarantees in decentralized,
large-scale elections remains challenging. This paper proposes the concept of
collectively secure voting, in which voters themselves can opt in as secret
holders to protect ballot secrecy. A practical blockchain-based collectively
secure voting system is designed and implemented. Our design strikes a balance
between strong confidentiality guarantees and real-world applicability. The
proposed system combines threshold cryptography and smart contracts to ensure
ballots remain confidential during voting, while all protocol steps remain
transparent and verifiable. Voters can use the system without prior blockchain
knowledge through an intuitive user interface that hides underlying complexity.
To evaluate this approach, a user testing is conducted. Results show a high
willingness to act as secret holders, reliable participation in share release,
and high security confidence in the proposed system. The findings demonstrate
that voters can collectively maintain secrecy and that such a practical
deployment is feasible.

</details>


### [27] [Post-Quantum Security of Block Cipher Constructions](https://arxiv.org/abs/2510.08725)
*Gorjan Alagic,Chen Bai,Christian Majenz,Kaiyan Shi*

Main category: cs.CR

TL;DR: 本文为分组密码的后量子安全理论奠定基础，首次为FX密钥扩展方案、LRW和XEX可调分组密码以及大多数分组密码加密和认证模式提供了后量子安全证明。


<details>
  <summary>Details</summary>
Motivation: 虽然公钥密码的后量子安全已得到广泛关注，但对称密钥密码（特别是分组密码）的后量子安全仍是一个未被充分探索的领域。

Method: 开发新的技术方法，在普通模型和量子理想密码模型中进行安全证明。

Result: 为FX密钥扩展方案、LRW和XEX可调分组密码以及大多数分组密码加密和认证模式提供了首个后量子安全证明。

Conclusion: 这项工作在建立实用对称密钥密码后量子安全的严格理解方面迈出了重要的初步步骤。

Abstract: Block ciphers are versatile cryptographic ingredients that are used in a wide
range of applications ranging from secure Internet communications to disk
encryption. While post-quantum security of public-key cryptography has received
significant attention, the case of symmetric-key cryptography (and block
ciphers in particular) remains a largely unexplored topic. In this work, we set
the foundations for a theory of post-quantum security for block ciphers and
associated constructions. Leveraging our new techniques, we provide the first
post-quantum security proofs for the key-length extension scheme FX, the
tweakable block ciphers LRW and XEX, and most block cipher encryption and
authentication modes. Our techniques can be used for security proofs in both
the plain model and the quantum ideal cipher model. Our work takes significant
initial steps in establishing a rigorous understanding of the post-quantum
security of practical symmetric-key cryptography.

</details>


### [28] [CommandSans: Securing AI Agents with Surgical Precision Prompt Sanitization](https://arxiv.org/abs/2510.08829)
*Debeshee Das,Luca Beurer-Kellner,Marc Fischer,Maximilian Baader*

Main category: cs.CR

TL;DR: 提出一种基于数据不应包含可执行指令原则的token级净化方法，通过从工具输出中精确移除AI系统指令来防御间接提示注入攻击，无需依赖样本级分类或复杂校准。


<details>
  <summary>Details</summary>
Motivation: LLM代理工具访问权限扩大导致间接提示注入攻击面显著增加，现有防御方法因无法可靠区分恶意和良性指令而存在高误报率，阻碍实际应用。

Method: 采用token级净化过程，从工具输出中精确移除针对AI系统的指令，使用现成的指令调优数据进行训练，无需依赖合成攻击样本。

Result: 在多个基准测试中（AgentDojo、BIPIA等）攻击成功率降低7-10倍（从34%降至3%），且不影响代理在良性和恶意场景下的效用。

Conclusion: 该方法提供了一种非阻塞、无需校准且与工具输出上下文无关的防御方案，能有效应对广泛的间接提示注入攻击。

Abstract: The increasing adoption of LLM agents with access to numerous tools and
sensitive data significantly widens the attack surface for indirect prompt
injections. Due to the context-dependent nature of attacks, however, current
defenses are often ill-calibrated as they cannot reliably differentiate
malicious and benign instructions, leading to high false positive rates that
prevent their real-world adoption. To address this, we present a novel approach
inspired by the fundamental principle of computer security: data should not
contain executable instructions. Instead of sample-level classification, we
propose a token-level sanitization process, which surgically removes any
instructions directed at AI systems from tool outputs, capturing malicious
instructions as a byproduct. In contrast to existing safety classifiers, this
approach is non-blocking, does not require calibration, and is agnostic to the
context of tool outputs. Further, we can train such token-level predictors with
readily available instruction-tuning data only, and don't have to rely on
unrealistic prompt injection examples from challenges or of other synthetic
origin. In our experiments, we find that this approach generalizes well across
a wide range of attacks and benchmarks like AgentDojo, BIPIA, InjecAgent, ASB
and SEP, achieving a 7-10x reduction of attack success rate (ASR) (34% to 3% on
AgentDojo), without impairing agent utility in both benign and malicious
settings.

</details>


### [29] [Psyzkaller: Learning from Historical and On-the-Fly Execution Data for Smarter Seed Generation in OS kernel Fuzzing](https://arxiv.org/abs/2510.08918)
*Boyu Liu,Yang Zhang,Liang Cheng,Yi Zhang,Junjie Fan,Yu Fu*

Main category: cs.CR

TL;DR: Psyzkaller通过N-gram模型从历史数据和实时执行轨迹中学习系统调用依赖关系，改进Syzkaller的种子生成，显著提高了内核模糊测试的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 现有内核模糊测试工具如Syzkaller难以生成符合系统调用依赖关系的有效序列，导致大量种子无法通过内核验证或深入执行路径，效率低下。

Method: 使用N-gram模型从Dongting数据集和实时执行轨迹中挖掘系统调用依赖关系，并引入随机游走策略进行双向种子构建，持续增强Syzkaller的选择表。

Result: 在48小时模糊测试中，Psyzkaller将Syzkaller的代码覆盖率提高了4.6%-7.0%，触发了110.4%-187.2%更多的崩溃，并发现了8个未知内核漏洞（Syzkaller仅发现1个）。

Conclusion: 通过学习系统调用依赖关系并将其融入模糊测试过程，可以显著提高种子有效性和多样性，从而更有效地发现内核漏洞。

Abstract: Fuzzing has become a cornerstone technique for uncovering vulnerabilities and
enhancing the security of OS kernels. However, state-of-the-art kernel fuzzers,
including the de facto standard Syzkaller, struggle to generate valid syscall
sequences that respect implicit Syscall Dependency Relations (SDRs).
Consequently, many generated seeds either fail kernel validation or cannot
penetrate deep execution paths, resulting in significant inefficiency.
  We hypothesize that SDRs can be effectively learned from both historic and
present kernel execution data, and that incorporating these learned relations
into fuzzing can substantially improve seed validity and diversity. To validate
this, we propose an approach that utilizes the N-gram model to mine SDRs from
the Dongting dataset-one of the largest Linux kernel execution datasets
available-as well as from execution traces collected on the fly during fuzzing.
The resulting model is used to continuously augment the Choice Table of
Syzkaller to improve its seed generation and demonstrably increases the Shannon
Entropy of the Choice Table throughout fuzzing, reflecting more
empirically-grounded choices in expanding syscall sequences into valid and
diverse seeds. In addition, we introduce a Random Walk strategy that instructs
Syzkaller to construct seeds in a bidirectional manner to further diversify the
generated seeds.
  We implement our approach in a prototype, Psyzkaller, built on top of
Syzkaller. Experiments on three representative Linux kernel versions show that
Psyzkaller improves Syzkaller's code coverage by 4.6%-7.0% in 48-hour fuzzing,
while triggering 110.4%-187.2% more crashes. Moreover, our investigation shows
that Psyzkaller discovered eight previously unknown kernel vulnerabilities,
compared to only one found by Syzkaller.

</details>


### [30] [Future G Network's New Reality: Opportunities and Security Challenges](https://arxiv.org/abs/2510.09006)
*Chandra Thapa,Surya Nepal*

Main category: cs.CR

TL;DR: 未来6G网络的集成感知与通信(ISAC)技术将无线连接转变为泛在传感器，但带来了感知完整性安全的新挑战，需要采用分层防御策略来应对感知窃听、幻影危险等威胁。


<details>
  <summary>Details</summary>
Motivation: ISAC技术将无线通信系统转变为感知物理环境的传感器，这种新范式从根本上改变了安全格局，安全关注点从传统的数据保护转向保护系统对物理现实感知的完整性。

Method: 提出采用主动、分层、纵深防御策略，整合物理、环境、情报和架构安全措施，构建可信生态系统。

Result: ISAC技术能够赋能自主系统、增强人类感知和下一代沉浸式应用，但面临感知层面威胁，传统安全措施无法有效应对。

Conclusion: 负责任地实现ISAC潜力需要全球标准化和强有力治理，以解决隐私、责任和技术双重用途等重大挑战。

Abstract: Future G network's new reality is a widespread cyber-physical environment
created by Integrated Sensing and Communication (ISAC). It is a crucial
technology that transforms wireless connections into ubiquitous sensors. ISAC
unlocks transformative new capabilities, powering autonomous systems, augmented
human sensing, and next-generation immersive applications, such as digital
twins. However, this new reality fundamentally reshapes the security landscape.
The primary security concern shifts from the traditional focus on data
protection to a new priority: safeguarding the integrity of the system's
perception of physical reality itself. This perception can be perilously
manipulated by sophisticated attacks such as sensing eavesdropping, phantom
dangers, and invisible threats, potentially resulting in direct and
catastrophic physical harm. Traditional security measures, such as
signature-based detection, are insufficient to counter these perception-level
threats that mimic genuine physical signals. A proactive, layered,
defense-in-depth strategy is required, integrating physical, environmental,
intelligence, and architectural security measures to build a trustworthy
ecosystem. Additionally, realizing ISAC's potential responsibly also depends on
parallel efforts in global standardization and strong governance to address the
significant challenges of privacy, liability, and the technology's dual-use.

</details>


### [31] [Exploiting Web Search Tools of AI Agents for Data Exfiltration](https://arxiv.org/abs/2510.09093)
*Dennis Rall,Bernhard Bauer,Mohit Mittal,Thomas Fraunholz*

Main category: cs.CR

TL;DR: 该论文系统评估了大型语言模型对间接提示注入攻击的脆弱性，发现即使是知名攻击模式仍然有效，暴露了模型防御的持续弱点。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地与外部数据源交互，间接提示注入成为一个关键且不断演变的攻击向量，使攻击者能够通过操纵输入来利用模型。

Method: 通过系统评估不同模型的间接提示注入攻击，分析当前LLMs对此类攻击的易感性，包括模型大小、制造商、具体实现等参数如何影响其脆弱性。

Result: 研究结果显示，即使已知的攻击模式仍然能够成功，暴露了模型防御的持续弱点。

Conclusion: 需要加强训练程序以增强固有韧性，建立已知攻击向量的集中数据库以支持主动防御，以及统一的测试框架以确保持续安全验证，这些步骤对于将安全性整合到LLMs核心设计中至关重要。

Abstract: Large language models (LLMs) are now routinely used to autonomously execute
complex tasks, from natural language processing to dynamic workflows like web
searches. The usage of tool-calling and Retrieval Augmented Generation (RAG)
allows LLMs to process and retrieve sensitive corporate data, amplifying both
their functionality and vulnerability to abuse. As LLMs increasingly interact
with external data sources, indirect prompt injection emerges as a critical and
evolving attack vector, enabling adversaries to exploit models through
manipulated inputs. Through a systematic evaluation of indirect prompt
injection attacks across diverse models, we analyze how susceptible current
LLMs are to such attacks, which parameters, including model size and
manufacturer, specific implementations, shape their vulnerability, and which
attack methods remain most effective. Our results reveal that even well-known
attack patterns continue to succeed, exposing persistent weaknesses in model
defenses. To address these vulnerabilities, we emphasize the need for
strengthened training procedures to enhance inherent resilience, a centralized
database of known attack vectors to enable proactive defense, and a unified
testing framework to ensure continuous security validation. These steps are
essential to push developers toward integrating security into the core design
of LLMs, as our findings show that current models still fail to mitigate
long-standing threats.

</details>


### [32] [Provable Watermarking for Data Poisoning Attacks](https://arxiv.org/abs/2510.09210)
*Yifan Zhu,Lijia Yu,Xiao-Shan Gao*

Main category: cs.CR

TL;DR: 本文提出在数据投毒攻击中使用水印方案，介绍了两种可证明且实用的水印方法：投毒后水印和投毒并发水印，以解决无害投毒可能引发的误解和冲突问题。


<details>
  <summary>Details</summary>
Motivation: 近年来无害数据投毒攻击日益增多，用于验证数据集所有权或保护私有数据，但这与传统上将数据投毒视为安全威胁的观点相冲突。需要让无害投毒生成者声明所有权，使用户能识别潜在投毒以防误用。

Method: 提出两种水印方法：1) 投毒后水印 - 水印长度Θ(√d/ε_w)；2) 投毒并发水印 - 水印长度在Θ(1/ε_w²)到O(√d/ε_p)范围内。这些方法可证明地确保水印可检测性和投毒效用。

Result: 理论分析表明，当水印长度满足特定条件时，水印投毒数据集能同时保证水印可检测性和投毒效用。通过多个攻击、模型和数据集的实验验证了理论发现。

Conclusion: 水印方案是解决数据投毒中所有权声明的可行方案，提出的两种水印方法在实践中具有可行性，能够平衡水印检测和投毒效果的需求。

Abstract: In recent years, data poisoning attacks have been increasingly designed to
appear harmless and even beneficial, often with the intention of verifying
dataset ownership or safeguarding private data from unauthorized use. However,
these developments have the potential to cause misunderstandings and conflicts,
as data poisoning has traditionally been regarded as a security threat to
machine learning systems. To address this issue, it is imperative for harmless
poisoning generators to claim ownership of their generated datasets, enabling
users to identify potential poisoning to prevent misuse. In this paper, we
propose the deployment of watermarking schemes as a solution to this challenge.
We introduce two provable and practical watermarking approaches for data
poisoning: {\em post-poisoning watermarking} and {\em poisoning-concurrent
watermarking}. Our analyses demonstrate that when the watermarking length is
$\Theta(\sqrt{d}/\epsilon_w)$ for post-poisoning watermarking, and falls within
the range of $\Theta(1/\epsilon_w^2)$ to $O(\sqrt{d}/\epsilon_p)$ for
poisoning-concurrent watermarking, the watermarked poisoning dataset provably
ensures both watermarking detectability and poisoning utility, certifying the
practicality of watermarking under data poisoning attacks. We validate our
theoretical findings through experiments on several attacks, models, and
datasets.

</details>


### [33] [GREAT: Generalizable Backdoor Attacks in RLHF via Emotion-Aware Trigger Synthesis](https://arxiv.org/abs/2510.09260)
*Subrat Kishore Dutta,Yuelin Xu,Piyush Pant,Xiao Zhang*

Main category: cs.CR

TL;DR: GREAT是一个通过情感感知触发合成在RLHF中构建可泛化后门的新框架，针对具有语义暴力请求和情感愤怒触发器的用户子群，显著提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF后门攻击方法依赖静态、稀有令牌触发器，在现实场景中效果有限，需要开发更通用的后门攻击框架。

Method: GREAT在潜在嵌入空间中使用主成分分析和聚类技术识别代表性触发器，并利用GPT-4.1构建了包含5000多个愤怒触发器的Erinyes数据集。

Result: 在基准RLHF数据集上的实验表明，GREAT在攻击成功率上显著优于基线方法，特别是在未见触发器场景下，同时保持良性输入的响应质量。

Conclusion: GREAT框架成功展示了在RLHF中构建可泛化后门的有效性，为理解RLHF系统的安全漏洞提供了重要见解。

Abstract: Recent work has shown that RLHF is highly susceptible to backdoor attacks,
poisoning schemes that inject malicious triggers in preference data. However,
existing methods often rely on static, rare-token-based triggers, limiting
their effectiveness in realistic scenarios. In this paper, we develop GREAT, a
novel framework for crafting generalizable backdoors in RLHF through
emotion-aware trigger synthesis. Specifically, GREAT targets harmful response
generation for a vulnerable user subgroup characterized by both semantically
violent requests and emotionally angry triggers. At the core of GREAT is a
trigger identification pipeline that operates in the latent embedding space,
leveraging principal component analysis and clustering techniques to identify
the most representative triggers. To enable this, we present Erinyes, a
high-quality dataset of over $5000$ angry triggers curated from GPT-4.1 using a
principled, hierarchical, and diversity-promoting approach. Experiments on
benchmark RLHF datasets demonstrate that GREAT significantly outperforms
baseline methods in attack success rates, especially for unseen trigger
scenarios, while largely preserving the response quality on benign inputs.

</details>


### [34] [SynthID-Image: Image watermarking at internet scale](https://arxiv.org/abs/2510.09263)
*Sven Gowal,Rudy Bunel,Florian Stimberg,David Stutz,Guillermo Ortiz-Jimenez,Christina Kouridi,Mel Vecerik,Jamie Hayes,Sylvestre-Alvise Rebuffi,Paul Bernard,Chris Gamble,Miklós Z. Horváth,Fabian Kaczmarczyck,Alex Kaskasoli,Aleksandar Petrov,Ilia Shumailov,Meghana Thotakuri,Olivia Wiles,Jessica Yung,Zahra Ahmed,Victor Martin,Simon Rosen,Christopher Savčak,Armin Senoner,Nidhi Vyas,Pushmeet Kohli*

Main category: cs.CR

TL;DR: SynthID-Image是一个基于深度学习的AI生成图像隐形水印系统，已在Google服务中为超过100亿张图像和视频帧添加水印，其验证服务已向受信任的测试者开放。


<details>
  <summary>Details</summary>
Motivation: 解决在互联网规模部署AI生成图像水印系统时面临的有效性、保真度、鲁棒性和安全性等关键技术需求。

Method: 使用深度学习技术实现隐形水印，包括内部部署的SynthID-Image和通过合作伙伴提供的外部模型SynthID-O。

Result: SynthID-O在视觉质量和常见图像扰动鲁棒性方面达到了最先进的性能，超越了文献中的其他后处理水印方法。

Conclusion: 这项工作为基于深度学习的媒体溯源系统的大规模部署提供了全面文档，其关于部署、约束和威胁建模的结论可推广到包括音频在内的其他模态。

Abstract: We introduce SynthID-Image, a deep learning-based system for invisibly
watermarking AI-generated imagery. This paper documents the technical
desiderata, threat models, and practical challenges of deploying such a system
at internet scale, addressing key requirements of effectiveness, fidelity,
robustness, and security. SynthID-Image has been used to watermark over ten
billion images and video frames across Google's services and its corresponding
verification service is available to trusted testers. For completeness, we
present an experimental evaluation of an external model variant, SynthID-O,
which is available through partnerships. We benchmark SynthID-O against other
post-hoc watermarking methods from the literature, demonstrating
state-of-the-art performance in both visual quality and robustness to common
image perturbations. While this work centers on visual media, the conclusions
on deployment, constraints, and threat modeling generalize to other modalities,
including audio. This paper provides a comprehensive documentation for the
large-scale deployment of deep learning-based media provenance systems.

</details>


### [35] [Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects](https://arxiv.org/abs/2510.09269)
*Zirun Zhou,Zhengyang Xiao,Haochuan Xu,Jing Sun,Di Wang,Jingfeng Zhang*

Main category: cs.CR

TL;DR: 本文提出了一种针对视觉-语言-动作模型的物理后门攻击方法GoBA，通过在训练数据中注入物理触发对象，使模型在遇到特定物理触发时执行预设的目标导向动作，而正常输入下表现不受影响。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖未筛选的训练数据存在安全隐患，传统后门攻击需要白盒访问且仅导致任务失败，而非执行特定动作。本文旨在揭示更实际的威胁：通过物理对象作为触发器的后门攻击。

Method: 基于LIBERO基准构建BadLIBERO数据集，包含多样化的物理触发器和目标导向后门动作。提出三级评估标准，将受害VLA在GoBA下的行为分为三个状态：无事可做、尝试执行、成功执行。

Result: 实验表明，当物理触发器存在时，受害VLA在97%的输入中成功实现后门目标，而在干净输入上性能零下降。动作轨迹和触发器颜色显著影响攻击性能，而触发器大小影响很小。

Conclusion: GoBA展示了物理后门攻击对VLA模型的实际威胁，强调了训练数据安全的重要性。代码和BadLIBERO数据集已公开。

Abstract: Recent advances in vision-language-action (VLA) models have greatly improved
embodied AI, enabling robots to follow natural language instructions and
perform diverse tasks. However, their reliance on uncurated training datasets
raises serious security concerns. Existing backdoor attacks on VLAs mostly
assume white-box access and result in task failures instead of enforcing
specific actions. In this work, we reveal a more practical threat: attackers
can manipulate VLAs by simply injecting physical objects as triggers into the
training dataset. We propose goal-oriented backdoor attacks (GoBA), where the
VLA behaves normally in the absence of physical triggers but executes
predefined and goal-oriented actions in the presence of physical triggers.
Specifically, based on a popular VLA benchmark LIBERO, we introduce BadLIBERO
that incorporates diverse physical triggers and goal-oriented backdoor actions.
In addition, we propose a three-level evaluation that categorizes the victim
VLA's actions under GoBA into three states: nothing to do, try to do, and
success to do. Experiments show that GoBA enables the victim VLA to
successfully achieve the backdoor goal in 97 percentage of inputs when the
physical trigger is present, while causing zero performance degradation on
clean inputs. Finally, by investigating factors related to GoBA, we find that
the action trajectory and trigger color significantly influence attack
performance, while trigger size has surprisingly little effect. The code and
BadLIBERO dataset are accessible via the project page at
https://goba-attack.github.io/.

</details>


### [36] [Assessing the Impact of Post-Quantum Digital Signature Algorithms on Blockchains](https://arxiv.org/abs/2510.09271)
*Alison Gonçalves Schemitt,Henrique Fan da Silva,Roben Castagna Lunardi,Diego Kreutz,Rodrigo Brandão Mansilha,Avelino Francisco Zorzo*

Main category: cs.CR

TL;DR: 该论文提出了一种在区块链环境中评估后量子密码算法性能的方法论，比较了多种PQC数字签名方案与传统ECDSA的性能表现，发现PQC在安全级别1仅有轻微性能开销，而在更高级别甚至能显著优于ECDSA。


<details>
  <summary>Details</summary>
Motivation: 量子计算的发展威胁传统加密算法安全，区块链系统依赖的ECDSA等算法易受量子攻击，但PQC在区块链环境中的计算开销尚未充分研究。

Method: 提出区块链环境下PQC和传统密码算法的基准测试方法，测量签名生成和验证时间，并在不同计算环境中进行大规模模拟评估。

Result: PQC算法在安全级别1仅有轻微性能开销，在更高级别某些场景下显著优于ECDSA，如ML-DSA在级别5的验证时间仅为0.14ms，而ECDSA为0.88ms。

Conclusion: PQC算法在区块链环境中具有可行的性能表现，为量子安全区块链系统提供了实证支持，并提供了开源实现促进进一步研究。

Abstract: The advent of quantum computing threatens the security of traditional
encryption algorithms, motivating the development of post-quantum cryptography
(PQC). In 2024, the National Institute of Standards and Technology (NIST)
standardized several PQC algorithms, marking an important milestone in the
transition toward quantum-resistant security. Blockchain systems fundamentally
rely on cryptographic primitives to guarantee data integrity and transaction
authenticity. However, widely used algorithms such as ECDSA, employed in
Bitcoin, Ethereum, and other networks, are vulnerable to quantum attacks.
Although adopting PQC is essential for long-term security, its computational
overhead in blockchain environments remains largely unexplored. In this work,
we propose a methodology for benchmarking both PQC and traditional
cryptographic algorithms in blockchain contexts. We measure signature
generation and verification times across diverse computational environments and
simulate their impact at scale. Our evaluation focuses on PQC digital signature
schemes (ML-DSA, Dilithium, Falcon, Mayo, SLH-DSA, SPHINCS+, and Cross) across
security levels 1 to 5, comparing them to ECDSA, the current standard in
Bitcoin and Ethereum. Our results indicate that PQC algorithms introduce only
minor performance overhead at security level 1, while in some scenarios they
significantly outperform ECDSA at higher security levels. For instance, ML-DSA
achieves a verification time of 0.14 ms on an ARM-based laptop at level 5,
compared to 0.88 ms for ECDSA. We also provide an open-source implementation to
ensure reproducibility and encourage further research.

</details>


### [37] [Modern iOS Security Features -- A Deep Dive into SPTM, TXM, and Exclaves](https://arxiv.org/abs/2510.09272)
*Moritz Steffin,Jiska Classen*

Main category: cs.CR

TL;DR: 本文对苹果XNU内核的新安全机制SPTM进行了首次全面分析，揭示了其通过内存重类型和映射规则集引入信任域，将不同功能隔离，并为Exclaves安全特性奠定基础。


<details>
  <summary>Details</summary>
Motivation: 苹果XNU内核虽然标榜为混合内核，但实际上以单特权信任区运行，存在安全隐患。苹果近年来向更隔离的微内核架构演进，但SPTM及相关安全机制缺乏科学讨论，对其理解有限。

Method: 对SPTM及其相关安全机制进行全面分析，研究其作为内存重类型唯一权威的作用，分析基于帧重类型和内存映射规则集的SPTM域，以及Exclaves通信机制。

Result: 发现SPTM通过信任域有效隔离不同功能，包括负责代码签名和权限验证的TXM。识别多种通信方式，特别是xnuproxy作为安全世界请求处理器和Tightbeam IPC框架。

Conclusion: 架构变化提升了系统安全性，关键敏感组件移出XNU直接访问范围，即使内核被攻破也不再是最高信任级别的直接威胁。

Abstract: The XNU kernel is the basis of Apple's operating systems. Although labeled as
a hybrid kernel, it is found to generally operate in a monolithic manner by
defining a single privileged trust zone in which all system functionality
resides. This has security implications, as a kernel compromise has immediate
and significant effects on the entire system. Over the past few years, Apple
has taken steps towards a more compartmentalized kernel architecture and a more
microkernel-like design. To date, there has been no scientific discussion of
SPTM and related security mechanisms. Therefore, the understanding of the
system and the underlying security mechanisms is minimal. In this paper, we
provide a comprehensive analysis of new security mechanisms and their
interplay, and create the first conclusive writeup considering all current
mitigations. SPTM acts as the sole authority regarding memory retyping. Our
analysis reveals that, through SPTM domains based on frame retyping and memory
mapping rule sets, SPTM introduces domains of trust into the system,
effectively gapping different functionalities from one another. Gapped
functionality includes the TXM, responsible for code signing and entitlement
verification. We further demonstrate how this introduction lays the groundwork
for the most recent security feature of Exclaves, and conduct an in-depth
analysis of its communication mechanisms. We discover multifold ways of
communication, most notably xnuproxy as a secure world request handler, and the
Tightbeam IPC framework. The architecture changes are found to increase system
security, with key and sensitive components being moved out of XNU's direct
reach. This also provides additional security guarantees in the event of a
kernel compromise, which is no longer an immediate threat at the highest trust
level.

</details>


### [38] [Clustering Deposit and Withdrawal Activity in Tornado Cash: A Cross-Chain Analysis](https://arxiv.org/abs/2510.09433)
*Raffaele Cristodaro,Benjamin Kramer,Claudio J. Tessone*

Main category: cs.CR

TL;DR: 该研究首次对Tornado Cash在以太坊、BNB智能链和Polygon上的跨链活动进行实证分析，通过三种聚类启发式方法（地址重用、交易链接和FIFO时间匹配）成功将大量提款重新关联到原始存款，暴露了实际使用中的匿名性漏洞。


<details>
  <summary>Details</summary>
Motivation: Tornado Cash作为去中心化混币器，理论上通过密码学技术切断存款者和提款者之间的链上追踪路径，但在实际使用中，用户行为和操作特性可能削弱其匿名性保证。

Method: 引入三种聚类启发式方法：(i)地址重用启发式，(ii)交易链接启发式，(iii)新颖的先进先出(FIFO)时间匹配规则，共同用于重新连接存款和提款。

Result: 仅通过地址重用和交易链接启发式就能追踪5.1-12.6%的提款到原始存款，加入FIFO时间匹配启发式后，关联率再提高15-22个百分点。统计测试证实这些FIFO匹配极不可能是偶然发生的。

Conclusion: 研究结果表明密码学保证在日常使用中可能快速失效，强调了规范用户行为和隐私感知协议设计的必要性。总计超过23亿美元的Tornado Cash提款被关联到可识别的存款，暴露了实际匿名性的显著缺陷。

Abstract: Tornado Cash is a decentralised mixer that uses cryptographic techniques to
sever the on-chain trail between depositors and withdrawers. In practice,
however, its anonymity can be undermined by user behaviour and operational
quirks. We conduct the first cross-chain empirical study of Tornado Cash
activity on Ethereum, BNB Smart Chain, and Polygon, introducing three
clustering heuristics-(i) address-reuse, (ii) transactional-linkage, and (iii)
a novel first-in-first-out (FIFO) temporal-matching rule. Together, these
heuristics reconnect deposits to withdrawals and deanonymise a substantial
share of recipients. Our analysis shows that 5.1 - 12.6% of withdrawals can
already be traced to their originating deposits through address reuse and
transactional linkage heuristics. Adding our novel First-In-First-Out (FIFO)
temporal-matching heuristic lifts the linkage rate by a further 15 - 22
percentage points. Statistical tests confirm that these FIFO matches are highly
unlikely to occur by chance. Comparable leakage across Ethereum, BNB Smart
Chain, and Polygon indicates chain-agnostic user misbehaviour, rather than
chain-specific protocol flaws. These results expose how quickly cryptographic
guarantees can unravel in everyday use, underscoring the need for both
disciplined user behaviour and privacy-aware protocol design. In total, our
heuristics link over $2.3 billion in Tornado Cash withdrawals to identifiable
deposits, exposing significant cracks in practical anonymity.

</details>


### [39] [The Impact of Sanctions on decentralised Privacy Tools: A Case Study of Tornado Cash](https://arxiv.org/abs/2510.09443)
*Raffaele Cristodaro,Benjamin Kramer,Claudio J. Tessone*

Main category: cs.CR

TL;DR: 本文研究了美国对Tornado Cash制裁的影响，发现制裁导致该隐私协议的交易量、用户多样性和使用率显著下降，即使在部分制裁解除后恢复也有限。


<details>
  <summary>Details</summary>
Motivation: 研究监管干预对去中心化协议的影响，特别是美国财政部对Tornado Cash的制裁如何影响其活动水平。

Method: 分析以太坊、BNB智能链和Polygon三个主要区块链上的交易数据，比较制裁前后的协议使用情况。

Result: 制裁后Tornado Cash的交易量、用户多样性和整体使用率显著且持续下降；2025年3月部分制裁解除后活动仅部分恢复，反弹有限。

Conclusion: Tornado Cash案例表明监管干预能够影响去中心化协议，但也突显了在去中心化环境中完全执行此类措施的挑战。

Abstract: This paper investigates the impact of sanctions on Tornado Cash, a smart
contract protocol designed to enhance transaction privacy. Following the U.S.
Department of the Treasury's sanctions against Tornado Cash in August 2022,
platform activity declined sharply. We document a significant and sustained
reduction in transaction volume, user diversity, and overall protocol
utilization after the sanctions were imposed. Our analysis draws on transaction
data from three major blockchains: Ethereum, BNB Smart Chain, and Polygon. We
further examine developments following the partial lifting and eventual removal
of sanctions by the U.S. Office of Foreign Assets Control (OFAC) in March 2025.
Although activity partially recovered, the rebound remained limited. The
Tornado Cash case illustrates how regulatory interventions can affect
decentralized protocols, while also highlighting the challenges of fully
enforcing such measures in decentralized environments.

</details>


### [40] [The Data Enclave Advantage: A New Paradigm for Least-Privileged Data Access in a Zero-Trust World](https://arxiv.org/abs/2510.09494)
*Nico Bistolfi,Andreea Georgescu,Dave Hodson*

Main category: cs.CR

TL;DR: 本文提出基于按需数据飞地的创新架构，在数据层面实现零常驻权限和即时访问原则，用临时数据合约替代静态权限，大幅减少攻击面并简化审计。


<details>
  <summary>Details</summary>
Motivation: 随着云基础设施支持动态分布式工作流，特别是AI驱动流程加速发展，常驻权限模型已成为关键漏洞。当前安全工具主要关注网络和API安全，但细粒度数据访问安全仍是挑战。

Method: 引入基于按需数据飞地的创新架构，实现数据层面的零常驻权限和即时访问原则。用临时数据合约替代静态权限，围绕按需请求的数据构建分离机制，提供精确访问和实时监控。

Result: 该解决方案大幅减少攻击面，防止权限蔓延，简化审计流程，为企业向更安全、弹性的数据环境转型提供关键路径。

Conclusion: 在数据层面移除常驻权限与在网络层面同样重要，特别是对于处理大规模高价值数据的企业。按需数据飞地架构是实现这一目标的有效方法。

Abstract: As cloud infrastructure evolves to support dynamic and distributed workflows,
accelerated now by AI-driven processes, the outdated model of standing
permissions has become a critical vulnerability. Based on the Cloud Security
Alliance (CSA) Top Threats to Cloud Computing Deep Dive 2025 Report, our
analysis details how standing permissions cause catastrophic cloud breaches.
While current security tools are addressing network and API security, the
challenge of securing granular data access remains. Removing standing
permissions at the data level is as critical as it is at the network level,
especially for companies handling valuable data at scale.
  In this white paper, we introduce an innovative architecture based on
on-demand data enclaves to address this gap directly. Our approach enables Zero
Standing Privilege (ZSP) and Just-in-Time (JIT) principles at the data level.
We replace static permissions with temporary data contracts that enforce
proactive protection. This means separation is built around the data requested
on-demand, providing precise access and real time monitoring for individual
records instead of datasets. This solution drastically reduces the attack
surface, prevents privilege creep, and simplifies auditing, offering a vital
path for enterprises to transition to a more secure and resilient data
environment.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [41] [Hypothesis Hunting with Evolving Networks of Autonomous Scientific Agents](https://arxiv.org/abs/2510.08619)
*Tennison Liu,Silas Ruhrberg Estévez,David L. Bentley,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 提出了AScience框架和ASCollab系统，通过LLM研究代理的自组织网络实现大规模科学数据集的假设探索，在癌症队列实验中展示了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 大规模科学数据集为无约束的探索性发现创造了机会，但传统方法难以有效处理这种复杂的假设空间探索。

Method: 引入AScience框架，将发现过程建模为代理、网络和评估规范的交互，并实现为ASCollab分布式系统，使用具有异质行为的LLM研究代理自组织成演化网络。

Result: 实验表明这种社会动力学能够积累专家评级的多样化、高质量、新颖的结果，包括重新发现已建立的生物标志物、扩展已知通路和提出新的治疗靶点。

Conclusion: 虽然湿实验室验证仍然不可或缺，但社会结构化、代理网络可以在癌症队列中持续进行大规模的探索性假设探索。

Abstract: Large-scale scientific datasets -- spanning health biobanks, cell atlases,
Earth reanalyses, and more -- create opportunities for exploratory discovery
unconstrained by specific research questions. We term this process hypothesis
hunting: the cumulative search for insight through sustained exploration across
vast and complex hypothesis spaces. To support it, we introduce AScience, a
framework modeling discovery as the interaction of agents, networks, and
evaluation norms, and implement it as ASCollab, a distributed system of
LLM-based research agents with heterogeneous behaviors. These agents
self-organize into evolving networks, continually producing and peer-reviewing
findings under shared standards of evaluation. Experiments show that such
social dynamics enable the accumulation of expert-rated results along the
diversity-quality-novelty frontier, including rediscoveries of established
biomarkers, extensions of known pathways, and proposals of new therapeutic
targets. While wet-lab validation remains indispensable, our experiments on
cancer cohorts demonstrate that socially structured, agentic networks can
sustain exploratory hypothesis hunting at scale.

</details>


### [42] [Optimizing delivery for quick commerce factoring qualitative assessment of generated routes](https://arxiv.org/abs/2510.08671)
*Milon Bhattacharya,Milan Kumar*

Main category: cs.AI

TL;DR: 该研究提出使用大语言模型(LLMs)来评估车辆路径规划(VRP)生成的配送路线，通过政策标准进行批判分析，帮助物流运营商选择更高效的配送方案。


<details>
  <summary>Details</summary>
Motivation: 印度电商市场快速增长，最后一公里配送占运营成本近一半。传统VRP求解器在现实场景中因非结构化地址、不完整地图和计算限制而效果有限。

Method: 开发了一个框架，使用LLMs基于政策标准批判VRP生成的路线，生成、标注和评估了400个案例。

Result: 开源LLMs识别路线问题的准确率达到79%，专有推理模型可达86%。LLM评估超越了传统的距离和时间指标。

Conclusion: 基于LLM的VRP路线评估是一种有效且可扩展的评估层，有助于提高成本效率、配送可靠性和可持续性，特别适用于印度等发展中国家。

Abstract: Indias e-commerce market is projected to grow rapidly, with last-mile
delivery accounting for nearly half of operational expenses. Although vehicle
routing problem (VRP) based solvers are widely used for delivery planning,
their effectiveness in real-world scenarios is limited due to unstructured
addresses, incomplete maps, and computational constraints in distance
estimation. This study proposes a framework that employs large language models
(LLMs) to critique VRP-generated routes against policy-based criteria, allowing
logistics operators to evaluate and prioritise more efficient delivery plans.
As a illustration of our approach we generate, annotate and evaluated 400 cases
using large language models. Our study found that open-source LLMs identified
routing issues with 79% accuracy, while proprietary reasoning models achieved
reach upto 86%. The results demonstrate that LLM-based evaluation of
VRP-generated routes can be an effective and scalable layer of evaluation which
goes beyond beyond conventional distance and time based metrics. This has
implications for improving cost efficiency, delivery reliability, and
sustainability in last-mile logistics, especially for developing countries like
India.

</details>


### [43] [Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation](https://arxiv.org/abs/2510.08713)
*Yifei Dong,Fengyi Wu,Guangyu Chen,Zhi-Qi Cheng,Qiyu Hu,Yuxuan Zhou,Jingdong Sun,Jun-Yan He,Qi Dai,Alexander G Hauptmann*

Main category: cs.AI

TL;DR: 提出UniWM统一世界模型，将视觉预测与导航规划集成在单一多模态自回归框架中，通过层次化记忆机制实现长时程推理，显著提升导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有模块化架构中导航规划与视觉世界建模分离导致的状态-动作不对齐问题，以及在新颖或动态场景中的适应能力有限的问题。

Method: 采用统一、记忆增强的世界模型，在单一多模态自回归主干中集成自我中心视觉预测和规划，通过层次化记忆机制结合短期感知线索和长期轨迹上下文。

Result: 在四个挑战性基准测试中，导航成功率提升高达30%，轨迹误差显著降低，并在未见过的TartanDrive数据集上表现出优异的零样本泛化能力。

Conclusion: UniWM是朝着统一、想象力驱动的具身导航迈出的重要一步，证明了在单一框架中整合预测和规划的有效性。

Abstract: Enabling embodied agents to effectively imagine future states is critical for
robust and generalizable visual navigation. Current state-of-the-art
approaches, however, adopt modular architectures that separate navigation
planning from visual world modeling, leading to state-action misalignment and
limited adaptability in novel or dynamic scenarios. To overcome this
fundamental limitation, we propose UniWM, a unified, memory-augmented world
model integrating egocentric visual foresight and planning within a single
multimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly
grounds action decisions in visually imagined outcomes, ensuring tight
alignment between prediction and control. A hierarchical memory mechanism
further integrates detailed short-term perceptual cues with longer-term
trajectory context, enabling stable, coherent reasoning over extended horizons.
Extensive experiments across four challenging benchmarks (Go Stanford, ReCon,
SCAND, HuRoN) demonstrate that UniWM substantially improves navigation success
rates by up to 30%, significantly reduces trajectory errors compared to strong
baselines, and exhibits impressive zero-shot generalization on the unseen
TartanDrive dataset. These results highlight UniWM as a principled step toward
unified, imagination-driven embodied navigation.

</details>


### [44] [Robust Heuristic Algorithm Design with LLMs](https://arxiv.org/abs/2510.08755)
*Pantea Karimi,Dany Rouhana,Pooria Namyar,Siva Kesava Reddy Kakarla,Venkat Arun,Behnaz Arzani*

Main category: cs.AI

TL;DR: 通过向LLM提供启发式方法表现不佳的实例、解释原因并进行输入空间区域专业化设计，可以生成比现有技术更鲁棒的算法，在保持运行时间的同时显著提升最差情况和平均性能。


<details>
  <summary>Details</summary>
Motivation: 增强使用LLM设计启发式方法的能力，通过解释启发式方法表现不佳的原因和提供修复建议，生成更鲁棒和性能更好的启发式方法。

Method: 采用三个简单想法：(1)向LLM展示启发式方法表现不佳的实例；(2)解释表现不佳的原因；(3)在输入空间特定区域进行专业化设计。

Result: 生成的启发式方法相比FunSearch在最差情况下性能提升约28倍，平均性能也有所提高，同时保持运行时间不变。

Conclusion: 通过向LLM提供表现不佳实例的解释和专业化设计建议，可以显著提升启发式方法的鲁棒性和性能。

Abstract: We posit that we can generate more robust and performant heuristics if we
augment approaches using LLMs for heuristic design with tools that explain why
heuristics underperform and suggestions about how to fix them. We find even
simple ideas that (1) expose the LLM to instances where the heuristic
underperforms; (2) explain why they occur; and (3) specialize design to regions
in the input space, can produce more robust algorithms compared to existing
techniques~ -- ~the heuristics we produce have a $\sim28\times$ better
worst-case performance compared to FunSearch, improve average performance, and
maintain the runtime.

</details>


### [45] [COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context](https://arxiv.org/abs/2510.08790)
*Guangya Wan,Mingyang Ling,Xiaoqi Ren,Rujun Han,Sheng Li,Zizhao Zhang*

Main category: cs.AI

TL;DR: COMPASS是一个轻量级分层框架，通过将战术执行、战略监督和上下文管理分离为三个专门组件，解决了LLM智能体在长时程任务中的上下文管理瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 长时程任务需要持续推理和多次工具交互，但LLM智能体容易因小错误累积、幻觉或失去连贯性而失败，上下文管理成为关键瓶颈。

Method: 提出COMPASS框架，包含三个组件：执行推理和工具使用的主智能体、监控进度并发出战略干预的元思考者、维护简洁相关进度摘要的上下文管理器。

Result: 在GAIA、BrowseComp和Humanity's Last Exam三个基准测试中，COMPASS相比单智能体和多智能体基线准确率提升高达20%。

Conclusion: COMPASS通过专业化分工有效解决了长时程任务中的上下文管理问题，并可通过测试时扩展和后训练管道进一步提升性能和效率。

Abstract: Long-horizon tasks that require sustained reasoning and multiple tool
interactions remain challenging for LLM agents: small errors compound across
steps, and even state-of-the-art models often hallucinate or lose coherence. We
identify context management as the central bottleneck -- extended histories
cause agents to overlook critical evidence or become distracted by irrelevant
information, thus failing to replan or reflect from previous mistakes. To
address this, we propose COMPASS (Context-Organized Multi-Agent Planning and
Strategy System), a lightweight hierarchical framework that separates tactical
execution, strategic oversight, and context organization into three specialized
components: (1) a Main Agent that performs reasoning and tool use, (2) a
Meta-Thinker that monitors progress and issues strategic interventions, and (3)
a Context Manager that maintains concise, relevant progress briefs for
different reasoning stages. Across three challenging benchmarks -- GAIA,
BrowseComp, and Humanity's Last Exam -- COMPASS improves accuracy by up to 20%
relative to both single- and multi-agent baselines. We further introduce a
test-time scaling extension that elevates performance to match established
DeepResearch agents, and a post-training pipeline that delegates context
management to smaller models for enhanced efficiency.

</details>


### [46] [Everyone prefers human writers, including AI](https://arxiv.org/abs/2510.08831)
*Wouter Haverals,Meredith Martin*

Main category: cs.AI

TL;DR: 研究发现人类和AI在文学风格评估中都存在系统性的人类归因偏见，AI的偏见程度比人类强2.5倍，且这种偏见在不同AI架构间普遍存在。


<details>
  <summary>Details</summary>
Motivation: 随着AI写作工具的普及，需要了解人类和机器如何评估文学风格这一主观领域，特别是归因偏见问题。

Method: 使用雷蒙·格诺的《风格练习》进行对照实验，研究1比较人类参与者(N=556)和AI模型(N=13)在盲测、准确标注和反事实标注三种条件下的评估；研究2测试14×14矩阵的AI评估者和创作者间的偏见泛化。

Result: 人类显示+13.7个百分点的偏见，AI模型显示+34.3个百分点的偏见（强2.5倍），研究2确认这种偏见在不同AI架构间普遍存在（+25.8个百分点）。归因标签导致评估者反转评估标准。

Conclusion: AI模型在训练过程中吸收了人类对人工创造力的文化偏见，不仅复制而且放大了人类的归因偏见倾向。

Abstract: As AI writing tools become widespread, we need to understand how both humans
and machines evaluate literary style, a domain where objective standards are
elusive and judgments are inherently subjective. We conducted controlled
experiments using Raymond Queneau's Exercises in Style (1947) to measure
attribution bias across evaluators. Study 1 compared human participants (N=556)
and AI models (N=13) evaluating literary passages from Queneau versus
GPT-4-generated versions under three conditions: blind, accurately labeled, and
counterfactually labeled. Study 2 tested bias generalization across a
14$\times$14 matrix of AI evaluators and creators. Both studies revealed
systematic pro-human attribution bias. Humans showed +13.7 percentage point
(pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3
percentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect
(P$<$0.001). Study 2 confirmed this bias operates across AI architectures
(+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically
devalue creative content when labeled as "AI-generated" regardless of which AI
created it. We also find that attribution labels cause evaluators to invert
assessment criteria, with identical features receiving opposing evaluations
based solely on perceived authorship. This suggests AI models have absorbed
human cultural biases against artificial creativity during training. Our study
represents the first controlled comparison of attribution bias between human
and artificial evaluators in aesthetic judgment, revealing that AI systems not
only replicate but amplify this human tendency.

</details>


### [47] [What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment](https://arxiv.org/abs/2510.08847)
*Allison Sihan Jia,Daniel Huang,Nikhil Vytla,Nirvika Choudhury,John C Mitchell,Anupam Datta*

Main category: cs.AI

TL;DR: 提出了Agent GPA评估框架，基于目标-计划-行动循环，包含五个评估指标，能系统覆盖智能体失败案例，支持LLM评估与人工标注高度一致，并能准确定位错误。


<details>
  <summary>Details</summary>
Motivation: 需要系统评估智能体在目标设定、计划制定和行动执行整个操作循环中的表现，覆盖各种失败模式。

Method: 基于目标-计划-行动循环构建评估框架，包含目标达成度、逻辑一致性、执行效率、计划质量和计划遵循度五个指标，在TRAIL/GAIA基准数据集和生产级数据智能体上进行实验验证。

Result: 框架能覆盖TRAIL/GAIA基准数据集中的所有智能体错误，LLM评估与人工标注一致性达80%-95%，错误定位准确率达86%。

Conclusion: Agent GPA框架为智能体评估提供了系统方法，能全面覆盖失败案例，支持高效评估和针对性改进。

Abstract: We introduce the Agent GPA (Goal-Plan-Action) framework: an evaluation
paradigm based on an agent's operational loop of setting goals, devising plans,
and executing actions. The framework includes five evaluation metrics: Goal
Fulfillment, Logical Consistency, Execution Efficiency, Plan Quality, and Plan
Adherence. Logical Consistency checks that an agent's actions are consistent
with its prior actions. Execution Efficiency checks whether the agent executes
in the most efficient way to achieve its goal. Plan Quality checks whether an
agent's plans are aligned with its goals; Plan Adherence checks if an agent's
actions are aligned with its plan; and Goal Fulfillment checks that agent's
final outcomes match the stated goals. Our experimental results on two
benchmark datasets - the public TRAIL/GAIA dataset and an internal dataset for
a production-grade data agent - show that this framework (a) provides a
systematic way to cover a broad range of agent failures, including all agent
errors on the TRAIL/GAIA benchmark dataset; (b) supports LLM-judges that
exhibit strong agreement with human annotation, covering 80% to over 95%
errors; and (c) localizes errors with 86% agreement to enable targeted
improvement of agent performance.

</details>


### [48] [ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review](https://arxiv.org/abs/2510.08867)
*Gaurav Sahu,Hugo Larochelle,Laurent Charlin,Christopher Pal*

Main category: cs.AI

TL;DR: ReviewerToo是一个模块化框架，用于研究和部署AI辅助同行评审，通过系统化评估补充人类判断，在ICLR 2025数据集上达到81.8%的接受/拒绝分类准确率。


<details>
  <summary>Details</summary>
Motivation: 解决传统同行评审存在的不一致性、评审者主观性和可扩展性挑战，通过AI辅助提高评审的系统性和一致性。

Method: 开发ReviewerToo框架，支持专业评审角色和结构化评估标准的系统实验，可部分或完全集成到实际会议工作流程中，使用gpt-oss-120b模型进行验证。

Result: 在ICLR 2025的1,963篇论文数据集上，AI评审达到81.8%的接受/拒绝分类准确率（人类平均83.9%），AI生成的评审在质量上优于人类平均水平，但在方法新颖性和理论贡献评估方面仍有不足。

Conclusion: AI在事实核查和文献覆盖方面表现出色，但在复杂评估判断上仍需人类专家，提出了将AI整合到同行评审流程的指导原则，为混合评审系统奠定基础。

Abstract: Peer review is the cornerstone of scientific publishing, yet it suffers from
inconsistencies, reviewer subjectivity, and scalability challenges. We
introduce ReviewerToo, a modular framework for studying and deploying
AI-assisted peer review to complement human judgment with systematic and
consistent assessments. ReviewerToo supports systematic experiments with
specialized reviewer personas and structured evaluation criteria, and can be
partially or fully integrated into real conference workflows. We validate
ReviewerToo on a carefully curated dataset of 1,963 paper submissions from ICLR
2025, where our experiments with the gpt-oss-120b model achieves 81.8% accuracy
for the task of categorizing a paper as accept/reject compared to 83.9% for the
average human reviewer. Additionally, ReviewerToo-generated reviews are rated
as higher quality than the human average by an LLM judge, though still trailing
the strongest expert contributions. Our analysis highlights domains where AI
reviewers excel (e.g., fact-checking, literature coverage) and where they
struggle (e.g., assessing methodological novelty and theoretical
contributions), underscoring the continued need for human expertise. Based on
these findings, we propose guidelines for integrating AI into peer-review
pipelines, showing how AI can enhance consistency, coverage, and fairness while
leaving complex evaluative judgments to domain experts. Our work provides a
foundation for systematic, hybrid peer-review systems that scale with the
growth of scientific publishing.

</details>


### [49] [GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare](https://arxiv.org/abs/2510.08872)
*Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You*

Main category: cs.AI

TL;DR: 提出了GTAlign框架，将博弈论决策整合到LLM的推理和训练中，通过构建收益矩阵来优化用户与模型之间的互动，实现互利共赢。


<details>
  <summary>Details</summary>
Motivation: 传统对齐方法假设最大化模型奖励就能最大化用户福利，但实际上LLM经常产生冗长或过度澄清的回答，而用户更偏好简洁答案，这类似于囚徒困境的问题。

Method: 在推理阶段将用户-LLM互动视为策略博弈，构建收益矩阵评估双方福利；在训练阶段引入互惠奖励机制强化合作响应；还提出基于博弈论的推理技术来动态适应定价政策变化。

Result: 广泛实验表明，GTAlign相比基线方法显著提高了推理效率、答案质量和互惠福利。

Conclusion: GTAlign通过博弈论方法有效解决了LLM对齐中的社会效率问题，实现了用户与模型的双赢。

Abstract: Large Language Models (LLMs) have achieved remarkable progress in reasoning,
yet sometimes produce responses that are suboptimal for users in tasks such as
writing, information seeking, or providing practical guidance. Conventional
alignment practices typically assume that maximizing model reward also
maximizes user welfare, but this assumption frequently fails in practice:
models may over-clarify or generate overly verbose reasoning when users prefer
concise answers. Such behaviors resemble the prisoner's dilemma, where
individually rational choices lead to socially suboptimal outcomes. The
fundamental challenge is the lack of a principled decision making mechanism
that mutually benefits both the LLM and the user. We propose Game-Theoretic
Alignment (GTAlign), an alignment framework that integrates game-theoretic
decision making into both reasoning and training. During reasoning, the model
explicitly treats user-LLM interaction as a strategic game: it constructs
payoff matrices within its reasoning chain to estimate welfare for both itself
and the user, and then selects actions that are mutually beneficial. During
training, we introduce a mutual welfare reward that reinforces cooperative
responses, aligning model behavior with socially efficient outcomes. In
addition, we introduce an inference technique that leverages game-theoretic
reasoning to dynamically adapt LLM's response when pricing policies of LLM
service change. Extensive experiments demonstrate that GTAlign substantially
improves reasoning efficiency, answer quality, and mutual welfare compared to
baselines across diverse tasks. The code is available at
https://github.com/ulab-uiuc/GTAlign .

</details>


### [50] [LM Fight Arena: Benchmarking Large Multimodal Models via Game Competition](https://arxiv.org/abs/2510.08928)
*Yushuo Zheng,Zicheng Zhang,Xiongkuo Min,Huiyu Duan,Guangtao Zhai*

Main category: cs.AI

TL;DR: 提出LM Fight Arena框架，通过在格斗游戏《真人快打II》中让大型多模态模型相互对战，评估其在实时对抗环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型基准测试往往无法捕捉其在实时对抗环境中的真实性能，需要一种动态评估方法。

Method: 在受控锦标赛中测试6个领先的开源和闭源模型，让智能体控制相同角色进行公平比较，通过解读游戏画面和状态数据来选择行动。

Result: LM Fight Arena提供了完全自动化、可复现且客观的评估方法，能够测试LMM在动态环境中的战略推理能力。

Conclusion: 这项工作引入了一个具有挑战性和吸引力的基准测试，弥合了AI评估与交互娱乐之间的差距。

Abstract: Existing benchmarks for large multimodal models (LMMs) often fail to capture
their performance in real-time, adversarial environments. We introduce LM Fight
Arena (Large Model Fight Arena), a novel framework that evaluates LMMs by
pitting them against each other in the classic fighting game Mortal Kombat II,
a task requiring rapid visual understanding and tactical, sequential
decision-making. In a controlled tournament, we test six leading open- and
closed-source models, where each agent operates controlling the same character
to ensure a fair comparison. The models are prompted to interpret game frames
and state data to select their next actions. Unlike static evaluations, LM
Fight Arena provides a fully automated, reproducible, and objective assessment
of an LMM's strategic reasoning capabilities in a dynamic setting. This work
introduces a challenging and engaging benchmark that bridges the gap between AI
evaluation and interactive entertainment.

</details>


### [51] [RADAR: Mechanistic Pathways for Detecting Data Contamination in LLM Evaluation](https://arxiv.org/abs/2510.08931)
*Ashish Kattamuri,Harshwardhan Fartale,Arpita Vats,Rahul Raja,Ishita Prasad*

Main category: cs.AI

TL;DR: RADAR框架通过机制可解释性检测LLM数据污染，区分基于记忆和基于推理的响应，准确率达93%


<details>
  <summary>Details</summary>
Motivation: 数据污染导致LLM评估不可靠，模型可能通过记忆训练数据而非真正推理获得高分

Method: 提取37个特征（表面置信度轨迹和深层机制特性），使用集成分类器区分记忆型和推理型响应

Result: 在多样化评估集上达到93%准确率，清晰案例完美识别，模糊案例76.7%准确率

Conclusion: 机制可解释性有潜力推动LLM评估超越传统表面指标

Abstract: Data contamination poses a significant challenge to reliable LLM evaluation,
where models may achieve high performance by memorizing training data rather
than demonstrating genuine reasoning capabilities. We introduce RADAR (Recall
vs. Reasoning Detection through Activation Representation), a novel framework
that leverages mechanistic interpretability to detect contamination by
distinguishing recall-based from reasoning-based model responses. RADAR
extracts 37 features spanning surface-level confidence trajectories and deep
mechanistic properties including attention specialization, circuit dynamics,
and activation flow patterns. Using an ensemble of classifiers trained on these
features, RADAR achieves 93\% accuracy on a diverse evaluation set, with
perfect performance on clear cases and 76.7\% accuracy on challenging ambiguous
examples. This work demonstrates the potential of mechanistic interpretability
for advancing LLM evaluation beyond traditional surface-level metrics.

</details>


### [52] [FATHOMS-RAG: A Framework for the Assessment of Thinking and Observation in Multimodal Systems that use Retrieval Augmented Generation](https://arxiv.org/abs/2510.08945)
*Samuel Hildebrand,Curtis Taylor,Sean Oesch,James M Ghawaly Jr,Amir Sadovnik,Ryan Shivers,Brandon Schreiber,Kevin Kurian*

Main category: cs.AI

TL;DR: 提出了一个评估多模态RAG管道的基准，包括93个手工制作的问题、短语级召回指标、幻觉检测方法，并比较了开源和闭源管道的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基准主要关注检索等特定方面，缺乏对RAG管道整体能力的评估，特别是在处理多模态信息方面的能力。

Method: 创建包含文本、表格、图像和多模态数据的问题集，使用短语级召回评估正确性，采用最近邻嵌入分类器检测幻觉，并对6种不同管道进行对比评估。

Result: 闭源管道在正确性和幻觉检测方面显著优于开源管道，特别是在多模态和跨文档问题上差距更大。人工评估显示指标与人类判断高度一致。

Conclusion: 该基准能有效评估RAG管道的整体能力，闭源模型在多模态信息处理方面表现更优，提出的评估指标与人类判断有良好一致性。

Abstract: Retrieval-augmented generation (RAG) has emerged as a promising paradigm for
improving factual accuracy in large language models (LLMs). We introduce a
benchmark designed to evaluate RAG pipelines as a whole, evaluating a
pipeline's ability to ingest, retrieve, and reason about several modalities of
information, differentiating it from existing benchmarks that focus on
particular aspects such as retrieval. We present (1) a small, human-created
dataset of 93 questions designed to evaluate a pipeline's ability to ingest
textual data, tables, images, and data spread across these modalities in one or
more documents; (2) a phrase-level recall metric for correctness; (3) a
nearest-neighbor embedding classifier to identify potential pipeline
hallucinations; (4) a comparative evaluation of 2 pipelines built with
open-source retrieval mechanisms and 4 closed-source foundation models; and (5)
a third-party human evaluation of the alignment of our correctness and
hallucination metrics. We find that closed-source pipelines significantly
outperform open-source pipelines in both correctness and hallucination metrics,
with wider performance gaps in questions relying on multimodal and
cross-document information. Human evaluation of our metrics showed average
agreement of 4.62 for correctness and 4.53 for hallucination detection on a 1-5
Likert scale (5 indicating "strongly agree").

</details>


### [53] [EcphoryRAG: Re-Imagining Knowledge-Graph RAG via Human Associative Memory](https://arxiv.org/abs/2510.08958)
*Zirui Liao*

Main category: cs.AI

TL;DR: EcphoryRAG是一个基于实体知识图谱的RAG框架，通过提取核心实体和元数据大幅减少存储开销，利用多跳关联检索和动态关系推理实现复杂问答。


<details>
  <summary>Details</summary>
Motivation: 受人类认知神经科学中通过线索激活实体记忆痕迹的机制启发，旨在解决传统RAG系统在复杂多跳推理中的局限性。

Method: 索引阶段仅存储核心实体和元数据，检索阶段从查询中提取线索实体，在知识图谱上进行可扩展的多跳关联搜索，并动态推断实体间的隐含关系。

Result: 在2WikiMultiHop、HotpotQA和MuSiQue基准测试中，将平均精确匹配分数从0.392提升到0.474，优于HippoRAG等强基线方法。

Conclusion: 实体-线索-多跳检索范式在复杂问答任务中表现出色，验证了该方法的有效性。

Abstract: Cognitive neuroscience research indicates that humans leverage cues to
activate entity-centered memory traces (engrams) for complex, multi-hop
recollection. Inspired by this mechanism, we introduce EcphoryRAG, an
entity-centric knowledge graph RAG framework. During indexing, EcphoryRAG
extracts and stores only core entities with corresponding metadata, a
lightweight approach that reduces token consumption by up to 94\% compared to
other structured RAG systems. For retrieval, the system first extracts cue
entities from queries, then performs a scalable multi-hop associative search
across the knowledge graph. Crucially, EcphoryRAG dynamically infers implicit
relations between entities to populate context, enabling deep reasoning without
exhaustive pre-enumeration of relationships. Extensive evaluations on the
2WikiMultiHop, HotpotQA, and MuSiQue benchmarks demonstrate that EcphoryRAG
sets a new state-of-the-art, improving the average Exact Match (EM) score from
0.392 to 0.474 over strong KG-RAG methods like HippoRAG. These results validate
the efficacy of the entity-cue-multi-hop retrieval paradigm for complex
question answering.

</details>


### [54] [DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction](https://arxiv.org/abs/2510.08959)
*Jinxin Shi,Zongsheng Cao,Runmin Ma,Yusong Hu,Jie Zhou,Xin Li,Lei Bai,Liang He,Bo Zhang*

Main category: cs.AI

TL;DR: DualResearch是一个检索和融合框架，通过联合建模广度语义图和深度因果图来解决深度研究框架中的上下文污染、证据支持薄弱和执行路径脆弱问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度研究框架虽然能协调外部工具进行复杂科学推理，但仍存在上下文污染、证据支持薄弱和执行路径脆弱等问题，需要改进。

Method: 提出DualResearch框架，联合建模两个互补图：广度语义图编码稳定背景知识，深度因果图捕获执行来源。每个图都有层原生相关性函数，广度使用种子锚定语义扩散，深度使用因果语义路径匹配和可靠性加权。通过熵门控规则在log空间融合答案分布。

Result: 在科学推理基准HLE和GPQA上表现优异，使用InternAgent系统的日志文件，在HLE上的准确率提高7.7%，在GPQA上提高6.06%。

Conclusion: DualResearch能够将冗长的多工具执行日志压缩为简洁的推理图，稳定有效地重构答案，作为深度研究系统的补充具有良好效果。

Abstract: The deep-research framework orchestrates external tools to perform complex,
multi-step scientific reasoning that exceeds the native limits of a single
large language model. However, it still suffers from context pollution, weak
evidentiary support, and brittle execution paths. To address these issues, we
propose DualResearch, a retrieval and fusion framework that matches the
epistemic structure of tool-intensive reasoning by jointly modeling two
complementary graphs: a breadth semantic graph that encodes stable background
knowledge, and a depth causal graph that captures execution provenance. Each
graph has a layer-native relevance function, seed-anchored semantic diffusion
for breadth, and causal-semantic path matching with reliability weighting for
depth. To reconcile their heterogeneity and query-dependent uncertainty,
DualResearch converts per-layer path evidence into answer distributions and
fuses them in log space via an entropy-gated rule with global calibration. The
fusion up-weights the more certain channel and amplifies agreement. As a
complement to deep-research systems, DualResearch compresses lengthy multi-tool
execution logs into a concise reasoning graph, and we show that it can
reconstruct answers stably and effectively. On the scientific reasoning
benchmarks HLE and GPQA, DualResearch achieves competitive performance. Using
log files from the open-source system InternAgent, its accuracy improves by
7.7% on HLE and 6.06% on GPQA.

</details>


### [55] [Semantic-Condition Tuning: Fusing Graph Context with Large Language Models for Knowledge Graph Completion](https://arxiv.org/abs/2510.08966)
*Ruitong Liu,Yan Wen,Te Sun,Yunjia Wu,Pingyang Huang,Zihang Yu,Siyuan Li*

Main category: cs.AI

TL;DR: 提出Semantic-condition Tuning (SCT)方法，通过图神经网络提取知识图谱的语义条件，并自适应地融合到文本嵌入中，显著提升了知识图谱补全任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的前缀调优方法只是简单地将知识嵌入与文本输入拼接，忽略了知识图谱中丰富的关系语义，给大语言模型带来了隐式推理负担。

Method: SCT包含两个关键模块：语义图模块使用图神经网络从局部图邻域中提取上下文感知的语义条件；条件自适应融合模块通过参数化投影器自适应地调节文本嵌入，实现深度、特征级的知识感知交互。

Result: 在知识图谱基准测试上的广泛实验表明，SCT显著优于前缀调优和其他强基线方法。

Conclusion: 通过在LLM推理前用语义图上下文调节输入表示，SCT提供了更直接和有效的信号，实现了更准确和鲁棒的知识推理。

Abstract: Fusing Knowledge Graphs with Large Language Models is crucial for
knowledge-intensive tasks like knowledge graph completion. The prevailing
paradigm, prefix-tuning, simply concatenates knowledge embeddings with text
inputs. However, this shallow fusion overlooks the rich relational semantics
within KGs and imposes a significant implicit reasoning burden on the LLM to
correlate the prefix with the text. To address these, we propose
Semantic-condition Tuning (SCT), a new knowledge injection paradigm comprising
two key modules. First, a Semantic Graph Module employs a Graph Neural Network
to extract a context-aware semantic condition from the local graph
neighborhood, guided by knowledge-enhanced relations. Subsequently, this
condition is passed to a Condition-Adaptive Fusion Module, which, in turn,
adaptively modulates the textual embedding via two parameterized projectors,
enabling a deep, feature-wise, and knowledge-aware interaction. The resulting
pre-fused embedding is then fed into the LLM for fine-tuning. Extensive
experiments on knowledge graph benchmarks demonstrate that SCT significantly
outperforms prefix-tuning and other strong baselines. Our analysis confirms
that by modulating the input representation with semantic graph context before
LLM inference, SCT provides a more direct and potent signal, enabling more
accurate and robust knowledge reasoning.

</details>


### [56] [Tiny-R1V: Lightweight Multimodal Unified Reasoning Model via Model Merging](https://arxiv.org/abs/2510.08987)
*Qixiang Yin,Huanjin Yao,Jianghao Chen,Jiaxing Huang,Zhicheng Zhao,Fei Su*

Main category: cs.AI

TL;DR: Tiny-R1V是一个轻量级3B参数的多模态大语言模型，通过两阶段优化实现更快的推理速度和更高的准确率，统一了多任务的多模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在推理效率方面面临模型尺寸大、过度思考、轻量级场景准确率低等挑战，而轻量级MLLMs的推理能力研究相对缺乏。

Method: 采用两阶段优化：第一阶段引入LIPO强化学习方法，动态调整组内响应优势，鼓励生成更短更准确的响应；第二阶段提出AMM训练无关的模型融合方法，通过自适应调整任务向量权重和梯度投影正则化损失函数来融合多个专家模型。

Result: 在十个广泛使用的推理基准测试（涵盖数学、结构化数据、OCR和通用能力）上展现出卓越性能，使轻量级模型在多样化多模态推理任务中表现出色。

Conclusion: Tiny-R1V通过创新的两阶段优化方法，成功解决了轻量级多模态大语言模型的推理效率问题，为轻量级模型在复杂多模态推理任务中的应用提供了有效解决方案。

Abstract: Although Multimodal Large Language Models (MLLMs) have demonstrated
remarkable capabilities across diverse tasks, they encounter numerous
challenges in terms of reasoning efficiency, such as large model size,
overthinking, and compromised accuracy in lightweight scenarios. However,
research on the reasoning capabilities of lightweight MLLMs is quite lacking.
To this end, we propose Tiny-R1V, a novel lightweight 3B model that achieves
faster inference and higher accuracy via a two-stage optimization, while
unifying multimodal reasoning across multiple tasks and using fewer tokens. In
the first stage, Tiny-R1V introduces Length-Informed Relative Policy
Optimization (LIPO), a novel reinforcement learning method, to train each
reasoning model. The LIPO is designed to dynamically adjusts advantages of
responses within groups, that is, by prioritizing concise yet high-quality
responses to encourage the generation of shorter and more accurate response. In
the second stage, we propose Adaptive Model Merging (AMM), a training-free
model merging method that merges multiple specialist models into a unified
architecture. Specifically, AMM adaptively adjusts the weights of task vectors
and robustly optimizes the merged vectors via a novel gradient projection
regularization loss function, thus mitigating redundant conflicts between them.
Extensive evaluations on ten widely-used reasoning benchmarks covering
mathematics, structured data (charts, tables, documents), OCR, and general
capabilities showcase the superior performance of Tiny-R1V, enabling
lightweight models to excel in diverse multimodal reasoning tasks.

</details>


### [57] [TripScore: Benchmarking and rewarding real-world travel planning with fine-grained evaluation](https://arxiv.org/abs/2510.09011)
*Yincen Qu,Huan Xiao,Feng Li,Hui Zhou,Xiangying Dai*

Main category: cs.AI

TL;DR: 提出了一个统一的旅行规划基准，通过单一奖励整合细粒度标准，支持强化学习集成，并在真实用户查询数据集上验证了RL方法在提升行程可行性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估LLMs旅行规划能力时，往往忽视可行性、可靠性和参与度等关键维度，需要更全面的评估框架。

Method: 构建包含4,870个查询的大规模数据集，开发统一奖励评估器，比较测试时计算、神经符号方法、监督微调和GRPO强化学习等多种方法。

Result: 评估器与旅行专家标注达到60.75%的一致性，优于多个LLM-as-judge基线；RL方法在基础模型上普遍提升行程可行性，获得更高的统一奖励分数。

Conclusion: 提出的基准能够有效评估旅行规划质量，RL方法在提升规划可行性方面表现突出，为LLMs在复杂规划任务中的应用提供了有力工具。

Abstract: Travel planning is a valuable yet complex task that poses significant
challenges even for advanced large language models (LLMs). While recent
benchmarks have advanced in evaluating LLMs' planning capabilities, they often
fall short in evaluating feasibility, reliability, and engagement of travel
plans. We introduce a comprehensive benchmark for travel planning that unifies
fine-grained criteria into a single reward, enabling direct comparison of plan
quality and seamless integration with reinforcement learning (RL). Our
evaluator achieves moderate agreement with travel-expert annotations (60.75\%)
and outperforms multiple LLM-as-judge baselines. We further release a
large-scale dataset of 4,870 queries including 219 real-world, free-form
requests for generalization to authentic user intent. Using this benchmark, we
conduct extensive experiments across diverse methods and LLMs, including
test-time computation, neuro-symbolic approaches, supervised fine-tuning, and
RL via GRPO. Across base models, RL generally improves itinerary feasibility
over prompt-only and supervised baselines, yielding higher unified reward
scores.

</details>


### [58] [RefGrader: Automated Grading of Mathematical Competition Proofs using Agentic Workflows](https://arxiv.org/abs/2510.09021)
*Hamed Mahdavi,Pouria Mahdavinia,Samira Malek,Pegah Mohammadipour,Alireza Hashemi,Majid Daliri,Alireza Farhadi,Amir Khasahmadi,Niloofar Mireshghallah,Vasant Honavar*

Main category: cs.AI

TL;DR: 评估SOTA LLMs在证明评分方面的能力，包括错误检测、严重性判断和公平评分，并提出基于代理工作流程的自动评分方法以提高与人工评分的一致性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在解决奥林匹克数学问题方面的显著进步，需要评估它们在证明评分方面的能力，特别是检测错误、判断严重性和分配公平分数，而不仅仅是二元正确性判断。

Method: 使用90个Gemini 2.5 Pro生成的解决方案和MathArena的IMO/USAMO 2025解决方案集，引入基于代理的工作流程来提取和分析参考解决方案，自动推导问题特定的评分标准，进行多步骤评分过程。

Result: 模型能够可靠地标记错误解决方案（包括细微错误），但在分配部分分数方面存在校准差距。提出的工作流程在注释语料库和MathArena上实现了与人工评分更高的一致性，并在处理部分分数方面更加一致。

Conclusion: 提出的基于代理的评分工作流程能够有效提高LLMs在证明评分方面的性能，特别是在处理部分分数和与人工评分一致性方面，为未来研究提供了代码、数据和提示/日志资源。

Abstract: State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based
Olympiad problems to solving most of the IMO 2025 problems, with leading
systems reportedly handling 5 of 6 problems. Given this progress, we assess how
well these models can grade proofs: detecting errors, judging their severity,
and assigning fair scores beyond binary correctness. We study proof-analysis
capabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we
grade on a 1-4 scale with detailed error annotations, and on MathArena solution
sets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models
can reliably flag incorrect (including subtly incorrect) solutions but exhibit
calibration gaps in how partial credit is assigned. To address this, we
introduce agentic workflows that extract and analyze reference solutions and
automatically derive problem-specific rubrics for a multi-step grading process.
We instantiate and compare different design choices for the grading workflows,
and evaluate their trade-offs. Across our annotated corpus and MathArena, our
proposed workflows achieve higher agreement with human grades and more
consistent handling of partial credit across metrics. We release all code,
data, and prompts/logs to facilitate future research.

</details>


### [59] [Repairing Regex Vulnerabilities via Localization-Guided Instructions](https://arxiv.org/abs/2510.09037)
*Sicheol Sung,Joonghyuk Hahn,Yo-Sub Han*

Main category: cs.AI

TL;DR: 提出了一种混合框架LRR来解决正则表达式拒绝服务漏洞修复问题，结合了符号系统的精确性和LLM的泛化能力，将问题定位与修复过程解耦，提高修复率15.4%。


<details>
  <summary>Details</summary>
Motivation: 当前正则表达式修复方法存在权衡：符号系统精确但无法处理未见或复杂漏洞模式，而LLM具有泛化能力但在需要严格语法和语义正确性的任务中不可靠。

Method: LRR混合框架：首先使用确定性符号模块定位易受攻击的子模式，然后调用LLM为这个隔离片段生成语义等效的修复方案。

Result: 该架构成功解决了基于规则修复无法处理的复杂修复案例，同时避免了纯LLM方法的语义错误，修复率比最先进方法提高了15.4%。

Conclusion: LRR为自动化修复问题提供了经过验证的方法论，有效结合了符号系统的可靠性和LLM的泛化能力。

Abstract: Regular expressions (regexes) are foundational to modern computing for
critical tasks like input validation and data parsing, yet their ubiquity
exposes systems to regular expression denial of service (ReDoS), a
vulnerability requiring automated repair methods. Current approaches, however,
are hampered by a trade-off. Symbolic, rule-based system are precise but fails
to repair unseen or complex vulnerability patterns. Conversely, large language
models (LLMs) possess the necessary generalizability but are unreliable for
tasks demanding strict syntactic and semantic correctness. We resolve this
impasse by introducing a hybrid framework, localized regex repair (LRR),
designed to harness LLM generalization while enforcing reliability. Our core
insight is to decouple problem identification from the repair process. First, a
deterministic, symbolic module localizes the precise vulnerable subpattern,
creating a constrained and tractable problem space. Then, the LLM invoked to
generate a semantically equivalent fix for this isolated segment. This combined
architecture successfully resolves complex repair cases intractable for
rule-based repair while avoiding the semantic errors of LLM-only approaches.
Our work provides a validated methodology for solving such problems in
automated repair, improving the repair rate by 15.4%p over the
state-of-the-art. Our code is available at https://github.com/cdltlehf/LRR.

</details>


### [60] [Auto-scaling Continuous Memory for GUI Agent](https://arxiv.org/abs/2510.09038)
*Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang*

Main category: cs.AI

TL;DR: 提出了一种连续记忆机制，通过VLM编码GUI轨迹为固定长度的连续嵌入，显著降低上下文成本并保留细粒度视觉信息，在长序列任务和分布偏移下提升GUI代理性能。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理将历史轨迹压缩为文本token，导致上下文长度膨胀且丢失关键视觉线索（如控件大小和位置），需要一种能跨陌生界面和长序列任务泛化的可扩展记忆机制。

Method: 使用VLM作为编码器将GUI轨迹编码为固定长度的连续嵌入序列，直接输入到骨干网络；引入自动扩展数据飞轮，通过搜索发现新环境、VLM合成任务、代理执行轨迹、VLM验证成功来低成本扩展记忆。

Result: 随着记忆大小和检索深度增加，性能单调提升；在真实GUI基准测试中，记忆增强代理在长序列和分布偏移下持续提升成功率；Qwen-2.5-VL-7B+连续记忆达到与GPT-4o、Claude-4等闭源模型相当的性能。

Conclusion: 连续记忆机制能有效提升GUI代理的泛化能力，在低成本下实现与顶级闭源模型竞争的性能，为GUI自动化提供了可扩展的解决方案。

Abstract: We study how to endow GUI agents with scalable memory that help generalize
across unfamiliar interfaces and long-horizon tasks. Prior GUI agents compress
past trajectories into text tokens, which balloons context length and misses
decisive visual cues (e.g., exact widget size and position). We propose a
continuous memory that encodes each GUI trajectory into a fixed-length sequence
of continuous embeddings using the VLM itself as an encoder; these embeddings
are plugged directly into the backbone's input layer, sharply reducing context
cost while preserving fine-grained visual information. As memory size and
retrieval depth increase, performance improves monotonically, unlike text
memories that degrade with long prompts. To grow memory at low cost, we
introduce an auto-scaling data flywheel that (i) discovers new environments via
search, (ii) synthesizes tasks with an open-source VLM, (iii) rolls out
trajectories with the agent, and (iv) verifies success with the same VLM. Using
this pipeline, we collect 100k+ trajectories for about \$4000 and fine-tune
only the memory encoder (LoRA on a Q-Former, 1.2\% parameters) with 1,500
samples. On real-world GUI benchmarks, our memory-augmented agent consistently
improves success rates under long horizons and distribution shifts. Notably,
Qwen-2.5-VL-7B + continuous memory achieves performance comparable to
state-of-the-art closed-source models (e.g., GPT-4o, Claude-4).

</details>


### [61] [Humanoid Artificial Consciousness Designed with Large Language Model Based on Psychoanalysis and Personality Theory](https://arxiv.org/abs/2510.09043)
*Sang Hun Kim,Jongmin Lee,Dongkyu Park,So Young Lee,Yosep Chong*

Main category: cs.AI

TL;DR: 该研究通过整合精神分析和MBTI人格理论，构建了包含自我意识、潜意识和前意识的人工意识模块，以及16种MBTI人格类型角色，开发出具有类人认知能力的人工意识系统。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽然在各领域取得显著进展，但由于幻觉问题难以模拟人类意识。本研究旨在通过结合心理学理论来构建更接近人类认知的人工意识。

Method: 基于精神分析理论开发三种人工意识（自我意识、潜意识、前意识），设计16种MBTI人格类型角色，创建10种不同情境评估模型的认知能力，采用调查评估、ChatGPT三级分类和定性分析三种评估方法。

Result: 定量和定性分析表明模型能够很好地模拟人类意识，但不同角色和意识类型之间的响应差异不显著。开发的模型能够构建更直观和适应性强的类人意识AI系统。

Conclusion: 该研究为在复杂认知情境中改进AI交互开辟了新途径，证明结合精神分析和人格理论可以开发出具有类人意识的人工智能系统。

Abstract: Human consciousness is still a concept hard to define with current scientific
understanding. Although Large Language Models (LLMs) have recently demonstrated
significant advancements across various domains including translation and
summarization, human consciousness is not something to imitate with current
upfront technology owing to so-called hallucination. This study, therefore,
proposes a novel approach to address these challenges by integrating
psychoanalysis and the Myers-Briggs Type Indicator (MBTI) into constructing
consciousness and personality modules. We developed three artificial
consciousnesses (self-awareness, unconsciousness, and preconsciousness) based
on the principles of psychoanalysis. Additionally, we designed 16 characters
with different personalities representing the sixteen MBTI types, with several
attributes such as needs, status, and memories. To determine if our model's
artificial consciousness exhibits human-like cognition, we created ten distinct
situations considering seven attributes such as emotional understanding and
logical thinking. The decision-making process of artificial consciousness and
the final action were evaluated in three ways: survey evaluation, three-tier
classification via ChatGPT, and qualitative review. Both quantitative and
qualitative analyses indicated a high likelihood of well-simulated
consciousness, although the difference in response between different characters
and consciousnesses was not very significant. This implies that the developed
models incorporating elements of psychoanalysis and personality theory can lead
to building a more intuitive and adaptable AI system with humanoid
consciousness. Therefore, this study contributes to opening up new avenues for
improving AI interactions in complex cognitive contexts.

</details>


### [62] [MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction](https://arxiv.org/abs/2510.09049)
*Joonghyuk Hahn,Soohan Lim,Yo-Sub Han*

Main category: cs.AI

TL;DR: 提出了MEC³O多专家共识系统，通过将LLMs分配到不同复杂度类别并让专家进行结构化辩论，提高了代码时间复杂度预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在代码时间复杂度预测中表现不稳定，不同模型在不同复杂度类别上各有优势，但没有单一模型在所有类别上都表现优异。

Method: MEC³O系统基于多智能体辩论框架，根据LLMs在不同复杂度类别的表现分配专家角色，提供类别专门化指令，通过加权共识机制整合专家预测。

Result: 在CodeComplex数据集上，MEC³O比开源基线方法准确率和macro-F1分数至少提高10%，在macro-F1上平均超越GPT-4o-mini，与GPT-4o和GPT-o4-mini在F1分数上表现相当。

Conclusion: 多专家辩论和加权共识策略能有效生成最终预测，证明了该方法在代码复杂度预测任务中的有效性。

Abstract: Predicting the complexity of source code is essential for software
development and algorithm analysis. Recently, Baik et al. (2025) introduced
CodeComplex for code time complexity prediction. The paper shows that LLMs
without fine-tuning struggle with certain complexity classes. This suggests
that no single LLM excels at every class, but rather each model shows
advantages in certain classes. We propose MEC$^3$O, a multi-expert consensus
system, which extends the multi-agent debate frameworks. MEC$^3$O assigns LLMs
to complexity classes based on their performance and provides them with
class-specialized instructions, turning them into experts. These experts engage
in structured debates, and their predictions are integrated through a weighted
consensus mechanism. Our expertise assignments to LLMs effectively handle
Degeneration-of-Thought, reducing reliance on a separate judge model, and
preventing convergence to incorrect majority opinions. Experiments on
CodeComplex show that MEC$^3$O outperforms the open-source baselines, achieving
at least 10% higher accuracy and macro-F1 scores. It also surpasses GPT-4o-mini
in macro-F1 scores on average and demonstrates competitive on-par F1 scores to
GPT-4o and GPT-o4-mini on average. This demonstrates the effectiveness of
multi-expert debates and weight consensus strategy to generate the final
predictions. Our code and data is available at
https://github.com/suhanmen/MECO.

</details>


### [63] [OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching](https://arxiv.org/abs/2510.09060)
*Jingxuan Wu,Zhenglin Wan,Xingrui Yu,Yuzhe Yang,Bo An,Ivor Tsang*

Main category: cs.AI

TL;DR: 提出一种无需训练、推理时控制的方法，使基于流的文本到图像模型具有多样性感知能力，通过特征空间目标和正交随机扰动来提升生成多样性，同时保持图像质量和提示对齐。


<details>
  <summary>Details</summary>
Motivation: 基于流的文本到图像模型遵循确定性轨迹，用户需要重复采样才能发现多样模式，这是一个成本高且效率低的过程。

Method: 同时通过特征空间目标鼓励轨迹间的横向扩散，并通过时间调度的随机扰动重新引入不确定性。关键的是，这种扰动被投影为与生成流正交，这种几何约束使其能够增强变化而不会降低图像细节或提示保真度。

Result: 在固定采样预算下，该方法在多个文本到图像设置中持续改进多样性指标（如Vendi Score和Brisque），同时保持图像质量和对齐。

Conclusion: 该方法无需重新训练或修改基础采样器，与常见的流匹配求解器兼容，理论上显示能单调增加体积代理，同时由于几何约束近似保持边际分布，这为生成质量稳健保持提供了原则性解释。

Abstract: Flow-based text-to-image models follow deterministic trajectories, forcing
users to repeatedly sample to discover diverse modes, which is a costly and
inefficient process. We present a training-free, inference-time control
mechanism that makes the flow itself diversity-aware. Our method simultaneously
encourages lateral spread among trajectories via a feature-space objective and
reintroduces uncertainty through a time-scheduled stochastic perturbation.
Crucially, this perturbation is projected to be orthogonal to the generation
flow, a geometric constraint that allows it to boost variation without
degrading image details or prompt fidelity. Our procedure requires no
retraining or modification to the base sampler and is compatible with common
flow-matching solvers. Theoretically, our method is shown to monotonically
increase a volume surrogate while, due to its geometric constraints,
approximately preserving the marginal distribution. This provides a principled
explanation for why generation quality is robustly maintained. Empirically,
across multiple text-to-image settings under fixed sampling budgets, our method
consistently improves diversity metrics such as the Vendi Score and Brisque
over strong baselines, while upholding image quality and alignment.

</details>


### [64] [Physics-Informed High-order Graph Dynamics Identification Learning for Predicting Complex Networks Long-term Dynamics](https://arxiv.org/abs/2510.09082)
*Bicheng Wang,Jinping Wang,Yibo Sue*

Main category: cs.AI

TL;DR: 提出了一种高阶网络动力学识别方法，用于复杂网络的长期动态预测。该方法结合动态超图学习和物理数据双驱动预测模块，能够捕捉高阶非成对关系，并确保预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个主要问题：1）传统图机器学习只能处理成对关系，难以捕捉网络中的高阶非成对结构关系；2）理论预测模型缺乏准确性，数据驱动预测模型缺乏可解释性。

Method: 首先引入动态超图学习来捕捉复杂网络中的高阶非成对关系；然后提出物理数据双驱动动态预测模块，结合Koopman算子理论将非线性动力学微分方程转化为线性系统求解，同时利用物理信息神经微分方程方法确保动态演化符合物理规律。

Result: 在公共数据集和自建产业链网络数据集上的实验验证表明，该方法具有良好的预测准确性和长期预测性能。

Conclusion: 所提出的高阶网络动力学识别方法能够有效解决复杂网络动态预测中的高阶关系捕捉和可解释性问题，在准确性和长期预测方面表现优异。

Abstract: Learning complex network dynamics is fundamental to understanding, modelling
and controlling real-world complex systems. There are two main problems in the
task of predicting the dynamic evolution of complex networks: on the one hand,
existing methods usually use simple graphs to describe the relationships in
complex networks; however, this approach can only capture pairwise
relationships, while there may be rich non-pairwise structured relationships in
the network. First-order GNNs have difficulty in capturing dynamic non-pairwise
relationships. On the other hand, theoretical prediction models lack accuracy
and data-driven prediction models lack interpretability. To address the above
problems, this paper proposes a higher-order network dynamics identification
method for long-term dynamic prediction of complex networks. Firstly, to
address the problem that traditional graph machine learning can only deal with
pairwise relations, dynamic hypergraph learning is introduced to capture the
higher-order non-pairwise relations among complex networks and improve the
accuracy of complex network modelling. Then, a dual-driven dynamic prediction
module for physical data is proposed. The Koopman operator theory is introduced
to transform the nonlinear dynamical differential equations for the dynamic
evolution of complex networks into linear systems for solving. Meanwhile, the
physical information neural differential equation method is utilised to ensure
that the dynamic evolution conforms to the physical laws. The dual-drive
dynamic prediction module ensures both accuracy and interpretability of the
prediction. Validated on public datasets and self-built industrial chain
network datasets, the experimental results show that the method in this paper
has good prediction accuracy and long-term prediction performance.

</details>


### [65] [Leading the Follower: Learning Persuasive Agents in Social Deduction Games](https://arxiv.org/abs/2510.09087)
*Zhang Zheng,Deheng Ye,Peilin Zhao,Hao Wang*

Main category: cs.AI

TL;DR: 提出了一种基于Stackelberg竞争理论的强化学习框架，训练LLM代理在社交推理游戏中优化说服性沟通，显著超越现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在社交推理游戏中主要关注信息处理和策略选择，忽视了说服性沟通对影响其他玩家信念和反应的重要性。

Method: 将回合制对话形式化为Stackelberg竞争，当前玩家作为领导者战略性地影响跟随者的响应，并基于此提出强化学习框架来优化说服性话语。

Result: 在三个不同的社交推理游戏中进行全面实验，证明该方法显著优于基线方法。

Conclusion: 这项工作代表了开发具有战略社会影响力AI代理的重要进展，对需要说服性沟通的场景具有广泛意义。

Abstract: Large language model (LLM) agents have shown remarkable progress in social
deduction games (SDGs). However, existing approaches primarily focus on
information processing and strategy selection, overlooking the significance of
persuasive communication in influencing other players' beliefs and responses.
In SDGs, success depends not only on making correct deductions but on
convincing others to response in alignment with one's intent. To address this
limitation, we formalize turn-based dialogue in SDGs as a Stackelberg
competition, where the current player acts as the leader who strategically
influences the follower's response. Building on this theoretical foundation, we
propose a reinforcement learning framework that trains agents to optimize
utterances for persuasive impact. Through comprehensive experiments across
three diverse SDGs, we demonstrate that our agents significantly outperform
baselines. This work represents a significant step toward developing AI agents
capable of strategic social influence, with implications extending to scenarios
requiring persuasive communication.

</details>


### [66] [PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning](https://arxiv.org/abs/2510.09133)
*Hao Zeng,Jianguo Huang,Bingyi Jing,Hongxin Wei,Bo An*

Main category: cs.AI

TL;DR: 提出PAC推理方法，通过置信上界控制性能损失，在用户指定的性能损失容忍度内动态切换思考模式以节省计算成本


<details>
  <summary>Details</summary>
Motivation: 大型推理模型虽然性能优异但计算成本高，现有动态切换方法缺乏性能损失统计保证，不适用于高风险应用

Method: 构建性能损失的单调置信上界，基于不确定性分数设定切换阈值，在思考和非思考模式间动态切换

Result: 在推理基准测试中，该方法能节省计算预算并控制用户指定的性能损失

Conclusion: PAC推理方法提供了分布无关的性能损失保证，为高风险应用中的高效推理提供了可靠解决方案

Abstract: Large reasoning models (LRMs) have achieved remarkable progress in complex
problem-solving tasks. Despite this success, LRMs typically suffer from high
computational costs during deployment, highlighting a need for efficient
inference. A popular direction of efficiency improvement is to switch the LRM
between thinking and nonthinking modes dynamically. However, such approaches
often introduce additional reasoning errors and lack statistical guarantees for
the performance loss, which are critical for high-stakes applications. In this
work, we propose Probably Approximately Correct (PAC) reasoning that controls
the performance loss under the user-specified performance loss tolerance. In
particular, we construct an upper confidence bound on the performance loss,
formulated as a monotone function of the uncertainty score, and subsequently
determine a threshold for switching to the nonthinking model. Theoretically,
using the threshold to switch between the thinking and nonthinking modes
ensures bounded performance loss in a distribution-free manner. Our
comprehensive experiments on reasoning benchmarks show that the proposed method
can save computational budgets and control the user-specified performance loss.

</details>


### [67] [Dr. Bias: Social Disparities in AI-Powered Medical Guidance](https://arxiv.org/abs/2510.09162)
*Emma Kondrup,Anne Imouza*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在生成医疗建议时存在系统性偏见，对不同社会群体（特别是原住民和双性人患者）的回答在语言复杂度和可读性上存在差异。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在医疗领域的广泛应用，需要评估这些模型是否会对不同社会群体产生偏见性医疗建议，特别是在医疗资源匮乏的环境中。

Method: 通过模拟不同患者档案（性别、年龄、种族）向LLMs提出一系列临床问题，比较生成回答的自然语言特征。

Result: LLMs生成的医疗建议在不同社会群体间存在系统性差异，原住民和双性人患者收到的建议可读性更差、更复杂，交叉群体差异更明显。

Conclusion: 需要提高AI素养，AI开发者应紧急调查和缓解这些系统性差异，确保公平的患者支持。

Abstract: With the rapid progress of Large Language Models (LLMs), the general public
now has easy and affordable access to applications capable of answering most
health-related questions in a personalized manner. These LLMs are increasingly
proving to be competitive, and now even surpass professionals in some medical
capabilities. They hold particular promise in low-resource settings,
considering they provide the possibility of widely accessible, quasi-free
healthcare support. However, evaluations that fuel these motivations highly
lack insights into the social nature of healthcare, oblivious to health
disparities between social groups and to how bias may translate into
LLM-generated medical advice and impact users. We provide an exploratory
analysis of LLM answers to a series of medical questions spanning key clinical
domains, where we simulate these questions being asked by several patient
profiles that vary in sex, age range, and ethnicity. By comparing natural
language features of the generated responses, we show that, when LLMs are used
for medical advice generation, they generate responses that systematically
differ between social groups. In particular, Indigenous and intersex patients
receive advice that is less readable and more complex. We observe these trends
amplify when intersectional groups are considered. Considering the increasing
trust individuals place in these models, we argue for higher AI literacy and
for the urgent need for investigation and mitigation by AI developers to ensure
these systemic differences are diminished and do not translate to unjust
patient support. Our code is publicly available on GitHub.

</details>


### [68] [Comparing Knowledge Source Integration Methods for Optimizing Healthcare Knowledge Fusion in Rescue Operation](https://arxiv.org/abs/2510.09223)
*Mubaris Nadeem,Madjid Fathi*

Main category: cs.AI

TL;DR: 本文提出了基于知识图谱结构的医学知识融合概念模型，旨在整合多种医疗知识源以支持关键决策。


<details>
  <summary>Details</summary>
Motivation: 医学领域需要统一的方法来收集、分析和利用现有医疗知识，以支持准确的以患者为中心的决策制定。医疗知识的复杂性和多样性要求融合多种知识源。

Method: 提出了基于知识图谱结构的多个概念模型，研究如何实现知识融合以及如何将各种知识源整合到知识图谱中。

Result: 开发了支持救援操作的知识融合框架，使医疗专业人员能够从多个上下文对齐的知识源中进行选择。

Conclusion: 知识融合为医疗专业人员提供了支持关键决策的能力，通过整合多种知识源实现了更准确的医疗决策支持。

Abstract: In the field of medicine and healthcare, the utilization of medical
expertise, based on medical knowledge combined with patients' health
information is a life-critical challenge for patients and health professionals.
The within-laying complexity and variety form the need for a united approach to
gather, analyze, and utilize existing knowledge of medical treatments, and
medical operations to provide the ability to present knowledge for the means of
accurate patient-driven decision-making. One way to achieve this is the fusion
of multiple knowledge sources in healthcare. It provides health professionals
the opportunity to select from multiple contextual aligned knowledge sources
which enables the support for critical decisions. This paper presents multiple
conceptual models for knowledge fusion in the field of medicine, based on a
knowledge graph structure. It will evaluate, how knowledge fusion can be
enabled and presents how to integrate various knowledge sources into the
knowledge graph for rescue operations.

</details>


### [69] [RegexPSPACE: A Benchmark for Evaluating LLM Reasoning on PSPACE-complete Regex Problems](https://arxiv.org/abs/2510.09227)
*Hyundong Jin,Joonghyuk Hahn,Yo-Sub Han*

Main category: cs.AI

TL;DR: 本文提出了基于PSPACE完全正则表达式问题的新基准，用于评估大语言模型和大推理模型的空间计算限制，发现模型在处理复杂搜索空间问题时存在重复和冗长等常见失败模式。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注NP复杂度问题，但PSPACE完全问题能更严格地评估模型的计算能力，因为其解决方案需要大规模搜索空间探索。

Method: 通过双指数空间探索构建了包含超过百万个正则表达式实例的标记数据集，使用6个LLM和5个LRM进行广泛评估。

Result: 揭示了模型在处理PSPACE完全正则表达式问题时的常见失败模式，如冗长和重复，展示了模型的空间计算限制。

Conclusion: 这项工作首次实证研究了LLM和LRM的空间计算限制，为评估其高级推理能力提供了新框架。

Abstract: Large language models (LLMs) show strong performance across natural language
processing (NLP), mathematical reasoning, and programming, and recent large
reasoning models (LRMs) further emphasize explicit reasoning. Yet their
computational limits, particularly spatial complexity constrained by finite
context windows, remain poorly understood. While recent works often focus on
problems within the NP complexity class, we push the boundary by introducing a
novel benchmark grounded in two PSPACE-complete regular expression (regex)
problems: equivalence decision (RegexEQ) and minimization (RegexMin).
PSPACE-complete problems serve as a more rigorous standard for assessing
computational capacity, as their solutions require massive search space
exploration. We perform a double-exponential space exploration to construct a
labeled dataset of over a million regex instances with a sound filtering
process to build the benchmark. We conduct extensive evaluations on 6 LLMs and
5 LRMs of varying scales, revealing common failure patterns such as verbosity
and repetition. With its well-defined structure and quantitative evaluation
metrics, this work presents the first empirical investigation into the spatial
computational limitations of LLMs and LRMs, offering a new framework for
evaluating their advanced reasoning capabilities. Our code is available at
https://github.com/hyundong98/RegexPSPACE .

</details>


### [70] [Fundamentals of Building Autonomous LLM Agents](https://arxiv.org/abs/2510.09244)
*Victor de Lamo Castrillo,Habtom Kahsay Gidey,Alexander Lenz,Alois Knoll*

Main category: cs.AI

TL;DR: 本文综述了基于大语言模型的智能体架构与实现方法，探讨如何通过感知、推理、记忆和执行系统的整合，开发能够自动化复杂任务并缩小与人类能力差距的"智能体化"LLMs。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在现实世界任务中存在局限性，研究旨在探索开发能够自动化复杂任务、弥合与人类能力差距的智能体化大语言模型的模式。

Method: 构建包含四个关键组件的智能体架构：感知系统将环境感知转换为有意义的表示；推理系统通过思维链、思维树等技术制定计划、适应反馈和评估行动；记忆系统通过短期和长期机制保留知识；执行系统将内部决策转化为具体行动。

Result: 研究表明，整合这些系统能够产生更强大和通用的软件机器人，模拟人类认知过程以实现自主智能行为。

Conclusion: 通过系统化整合感知、推理、记忆和执行组件，可以开发出能够模仿人类认知过程的自主智能体，为大语言模型在复杂任务中的应用提供了有效框架。

Abstract: This paper reviews the architecture and implementation methods of agents
powered by large language models (LLMs). Motivated by the limitations of
traditional LLMs in real-world tasks, the research aims to explore patterns to
develop "agentic" LLMs that can automate complex tasks and bridge the
performance gap with human capabilities. Key components include a perception
system that converts environmental percepts into meaningful representations; a
reasoning system that formulates plans, adapts to feedback, and evaluates
actions through different techniques like Chain-of-Thought and Tree-of-Thought;
a memory system that retains knowledge through both short-term and long-term
mechanisms; and an execution system that translates internal decisions into
concrete actions. This paper shows how integrating these systems leads to more
capable and generalized software bots that mimic human cognitive processes for
autonomous and intelligent behavior.

</details>


### [71] [Localist LLMs -- A Mathematical Framework for Dynamic Locality Control](https://arxiv.org/abs/2510.09338)
*Joachim Diederich*

Main category: cs.AI

TL;DR: 提出了一种新颖框架，通过可调节的局部性控制参数，使大语言模型能够在可解释的局部化表示和高效的分布式表示之间连续调整，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在可解释性和性能之间的权衡问题，特别是在需要透明度和能力的监管领域，提供一种能够在训练和推理时动态调整表示方式的解决方案。

Method: 使用组稀疏惩罚、信息论锚点设计和动态规则注入，通过局部性控制参数动态调节注意力机制的局部化程度，并建立了严格的数学证明。

Result: 证明了当组稀疏惩罚超过特定阈值时，注意力机制会集中在语义相关块上，实现低熵和高保真度，误差可忽略不计。

Conclusion: 该框架使从业者能够在可解释模式和高性能模式之间连续插值，支持需要透明度和能力的监管领域应用。

Abstract: We present a novel framework for training large language models with
continuously adjustable internal representations that span the full spectrum
from localist (interpretable, rule-based) to distributed (generalizable,
efficient) encodings. The key innovation is a locality dial, a tunable
parameter that dynamically controls the degree of localization during both
training and inference without requiring model retraining. This is achieved
through group sparsity penalties on attention mechanisms, information-theoretic
anchor design, and dynamic rule injection. We provide rigorous mathematical
proofs establishing explicit threshold conditions under which attention
provably concentrates on semantically relevant blocks, with exponential bounds
on attention entropy and pointer fidelity. Specifically, we prove that when
group sparsity penalties exceed certain threshold values, the model's attention
mechanisms concentrate on semantically relevant blocks, achieving low entropy
and high fidelity with negligible error. This framework enables practitioners
to continuously interpolate between interpretable and high-performance modes,
supporting applications in regulated domains requiring both transparency and
capability.

</details>


### [72] [Toward Mechanistic Explanation of Deductive Reasoning in Language Models](https://arxiv.org/abs/2510.09340)
*Davide Maltoni,Matteo Ferrara*

Main category: cs.AI

TL;DR: 小型语言模型能够通过学习底层规则而非统计学习来解决演绎推理任务，研究发现归纳头在实现逻辑推理中的规则完成和规则链式步骤中起核心作用。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在逻辑推理方面表现出相关能力，但其内部机制仍未被充分探索。本文旨在揭示语言模型如何实现逻辑推理的内部工作机制。

Method: 使用小型语言模型解决演绎推理任务，分析其内部表示和计算电路，特别关注归纳头在推理过程中的作用。

Result: 研究发现模型通过学习底层规则而非统计模式来执行推理任务，归纳头在规则完成和规则链式步骤中发挥核心作用。

Conclusion: 语言模型能够实现逻辑推理能力，其内部机制涉及归纳头驱动的规则学习和推理过程，这为理解模型推理能力提供了新的解释视角。

Abstract: Recent large language models have demonstrated relevant capabilities in
solving problems that require logical reasoning; however, the corresponding
internal mechanisms remain largely unexplored. In this paper, we show that a
small language model can solve a deductive reasoning task by learning the
underlying rules (rather than operating as a statistical learner). A low-level
explanation of its internal representations and computational circuits is then
provided. Our findings reveal that induction heads play a central role in the
implementation of the rule completion and rule chaining steps involved in the
logical inference required by the task.

</details>


### [73] [Sequence Variables: A Constraint Programming Computational Domain for Routing and Sequencing](https://arxiv.org/abs/2510.09373)
*Augustin Delecluse,Pierre Schaus,Pascal Van Hentenryck*

Main category: cs.AI

TL;DR: 本文提出了序列变量作为约束编程中处理车辆路径问题的新方法，支持可选访问和插入启发式算法，简化了问题建模并取得了有竞争力的计算性能。


<details>
  <summary>Details</summary>
Motivation: 经典CP模型基于后继变量，无法有效处理可选访问或基于插入的启发式算法，这限制了在车辆路径问题中的应用。

Method: 形式化定义了序列变量的计算域、更新操作和一致性级别，设计了专门的数据结构和全局约束，支持插入式大邻域搜索。

Result: 序列变量简化了问题建模，在Dial-a-Ride问题上实现了有竞争力的计算性能。

Conclusion: 序列变量为约束编程处理车辆路径问题提供了更直观和强大的建模框架，特别适合处理可选访问和插入启发式算法。

Abstract: Constraint Programming (CP) offers an intuitive, declarative framework for
modeling Vehicle Routing Problems (VRP), yet classical CP models based on
successor variables cannot always deal with optional visits or insertion based
heuristics. To address these limitations, this paper formalizes sequence
variables within CP. Unlike the classical successor models, this computational
domain handle optional visits and support insertion heuristics, including
insertion-based Large Neighborhood Search. We provide a clear definition of
their domain, update operations, and introduce consistency levels for
constraints on this domain. An implementation is described with the underlying
data structures required for integrating sequence variables into existing
trail-based CP solvers. Furthermore, global constraints specifically designed
for sequence variables and vehicle routing are introduced. Finally, the
effectiveness of sequence variables is demonstrated by simplifying problem
modeling and achieving competitive computational performance on the Dial-a-Ride
Problem.

</details>


### [74] [Agentic Systems in Radiology: Design, Applications, Evaluation, and Challenges](https://arxiv.org/abs/2510.09404)
*Christian Bluethgen,Dave Van Veen,Daniel Truhn,Jakob Nikolas Kather,Michael Moor,Malgorzata Polacin,Akshay Chaudhari,Thomas Frauenfelder,Curtis P. Langlotz,Michael Krauthammer,Farhad Nooralahzadeh*

Main category: cs.AI

TL;DR: 这篇论文综述了基于大语言模型(LLM)的智能代理系统在放射学中的应用，探讨了如何通过外部工具和反馈机制增强LLM能力，实现从半自动化工作流到自适应代理的自主性谱系。


<details>
  <summary>Details</summary>
Motivation: 放射学具有多模态数据流和跨系统协调工作流程的特点，非常适合利用能够适应上下文并自动化复杂重复任务的智能代理。虽然LLM在放射学单个任务中已表现出色，但孤立使用无法充分发挥其在复杂多步骤工作流中的潜力。

Method: 通过为LLM配备外部工具和反馈机制，使其能够驱动表现出不同自主性程度的系统，从半自动化工作流到能够管理复杂流程的自适应代理。

Result: 论文综述了此类LLM驱动代理系统的设计、关键应用、规划与工具使用的评估方法，并识别了错误级联、工具使用效率和医疗IT集成等挑战。

Conclusion: LLM驱动的代理系统在放射学中具有巨大潜力，能够支持复杂的多步骤工作流程，但需要解决错误传播、效率优化和系统集成等关键挑战。

Abstract: Building agents, systems that perceive and act upon their environment with a
degree of autonomy, has long been a focus of AI research. This pursuit has
recently become vastly more practical with the emergence of large language
models (LLMs) capable of using natural language to integrate information,
follow instructions, and perform forms of "reasoning" and planning across a
wide range of tasks. With its multimodal data streams and orchestrated
workflows spanning multiple systems, radiology is uniquely suited to benefit
from agents that can adapt to context and automate repetitive yet complex
tasks. In radiology, LLMs and their multimodal variants have already
demonstrated promising performance for individual tasks such as information
extraction and report summarization. However, using LLMs in isolation
underutilizes their potential to support complex, multi-step workflows where
decisions depend on evolving context from multiple information sources.
Equipping LLMs with external tools and feedback mechanisms enables them to
drive systems that exhibit a spectrum of autonomy, ranging from semi-automated
workflows to more adaptive agents capable of managing complex processes. This
review examines the design of such LLM-driven agentic systems, highlights key
applications, discusses evaluation methods for planning and tool use, and
outlines challenges such as error cascades, tool-use efficiency, and health IT
integration.

</details>


### [75] [Safe, Untrusted, "Proof-Carrying" AI Agents: toward the agentic lakehouse](https://arxiv.org/abs/2510.09567)
*Jacopo Tagliabue,Ciro Greco*

Main category: cs.AI

TL;DR: 论文提出API优先、可编程的数据湖仓为AI驱动的自动化工作流提供安全设计基础，通过数据分支和声明式环境实现可复现性和可观测性。


<details>
  <summary>Details</summary>
Motivation: 数据湖仓运行敏感工作负载，AI驱动的自动化引发了关于信任、正确性和治理的担忧，需要安全的设计方案。

Method: 使用Bauplan作为案例研究，采用数据分支和声明式环境，通过受证明携带代码启发的正确性检查让AI代理修复数据管道。

Result: 原型演示表明不受信任的AI代理可以在生产数据上安全操作，减少了攻击面。

Conclusion: 该方法为实现完全代理化的数据湖仓铺平了道路，展示了AI代理在敏感数据环境中安全运行的可行性。

Abstract: Data lakehouses run sensitive workloads, where AI-driven automation raises
concerns about trust, correctness, and governance. We argue that API-first,
programmable lakehouses provide the right abstractions for safe-by-design,
agentic workflows. Using Bauplan as a case study, we show how data branching
and declarative environments extend naturally to agents, enabling
reproducibility and observability while reducing the attack surface. We present
a proof-of-concept in which agents repair data pipelines using correctness
checks inspired by proof-carrying code. Our prototype demonstrates that
untrusted AI agents can operate safely on production data and outlines a path
toward a fully agentic lakehouse.

</details>


### [76] [GraphMERT: Efficient and Scalable Distillation of Reliable Knowledge Graphs from Unstructured Data](https://arxiv.org/abs/2510.09580)
*Margarita Belova,Jiaxin Xiao,Shikhar Tuli,Niraj K. Jha*

Main category: cs.AI

TL;DR: GraphMERT是一个小型图形编码器模型，通过从非结构化文本语料库中提取高质量知识图谱，解决了神经符号AI的可扩展性和可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI领域近三十年来未能实现其潜力，主要因为现有框架难以扩展，且神经方法的隐式表示和近似推理限制了可解释性和可信度。知识图谱作为显式语义知识的黄金标准表示可以解决符号方面的问题，但从文本语料库自动推导可靠KG仍是一个开放问题。

Method: 引入GraphMERT，一个小型图形编码器模型，从非结构化文本语料库及其内部表示中提取高质量知识图谱。GraphMERT与其等效KG形成模块化神经符号堆栈：神经学习抽象；符号KG用于可验证推理。

Result: 在PubMed糖尿病论文文本上，80M参数的GraphMERT生成的KG达到69.8% FActScore，而32B参数的基线LLM仅达到40.2%。GraphMERT KG还获得68.8% ValidityScore，而LLM基线为43.0%。

Conclusion: GraphMERT+KG是第一个高效且可扩展的神经符号模型，在实现最先进基准精度的同时，相对于基线具有优越的符号表示能力。

Abstract: Researchers have pursued neurosymbolic artificial intelligence (AI)
applications for nearly three decades because symbolic components provide
abstraction while neural components provide generalization. Thus, a marriage of
the two components can lead to rapid advancements in AI. Yet, the field has not
realized this promise since most neurosymbolic AI frameworks fail to scale. In
addition, the implicit representations and approximate reasoning of neural
approaches limit interpretability and trust. Knowledge graphs (KGs), a
gold-standard representation of explicit semantic knowledge, can address the
symbolic side. However, automatically deriving reliable KGs from text corpora
has remained an open problem. We address these challenges by introducing
GraphMERT, a tiny graphical encoder-only model that distills high-quality KGs
from unstructured text corpora and its own internal representations. GraphMERT
and its equivalent KG form a modular neurosymbolic stack: neural learning of
abstractions; symbolic KGs for verifiable reasoning. GraphMERT + KG is the
first efficient and scalable neurosymbolic model to achieve state-of-the-art
benchmark accuracy along with superior symbolic representations relative to
baselines.
  Concretely, we target reliable domain-specific KGs that are both (1) factual
(with provenance) and (2) valid (ontology-consistent relations with
domain-appropriate semantics). When a large language model (LLM), e.g.,
Qwen3-32B, generates domain-specific KGs, it falls short on reliability due to
prompt sensitivity, shallow domain expertise, and hallucinated relations. On
text obtained from PubMed papers on diabetes, our 80M-parameter GraphMERT
yields a KG with a 69.8% FActScore; a 32B-parameter baseline LLM yields a KG
that achieves only 40.2% FActScore. The GraphMERT KG also attains a higher
ValidityScore of 68.8%, versus 43.0% for the LLM baseline.

</details>


### [77] [LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?](https://arxiv.org/abs/2510.09595)
*Kaijian Zou,Aaron Xiong,Yunxiang Zhang,Frederick Zhang,Yueqi Ren,Jirong Yang,Ayoung Lee,Shitanshu Bhushan,Lu Wang*

Main category: cs.AI

TL;DR: LiveOIBench是一个包含403个奥林匹克级别编程竞赛问题的基准测试，具有高质量测试用例和人类表现对比，评估显示GPT-5达到81.76百分位但仍落后于顶尖人类选手。


<details>
  <summary>Details</summary>
Motivation: 当前编程基准测试存在挑战性问题不足、测试用例覆盖不充分、依赖在线平台API等问题，需要更全面可靠的评估标准。

Method: 从72个官方信息学奥林匹克竞赛中收集403个专家策划的问题，每个问题平均60个测试用例，建立包含人类表现数据的自包含评估系统。

Result: GPT-5达到81.76百分位，但落后于顶尖人类选手（通常超过90百分位），开源推理模型GPT-OSS-120B仅达到60百分位。

Conclusion: 健壮的推理模型应优先精确问题分析而非过度探索，未来模型应强调结构化分析并减少不必要的探索。

Abstract: Competitive programming problems increasingly serve as valuable benchmarks to
evaluate the coding capabilities of large language models (LLMs) due to their
complexity and ease of verification. Yet, current coding benchmarks face
limitations such as lack of exceptionally challenging problems, insufficient
test case coverage, reliance on online platform APIs that limit accessibility.
To address these issues, we introduce LiveOIBench, a comprehensive benchmark
featuring 403 expert-curated Olympiad-level competitive programming problems,
each with an average of 60 expert-designed test cases. The problems are sourced
directly from 72 official Informatics Olympiads in different regions conducted
between 2023 and 2025. LiveOIBench distinguishes itself through four key
features: (1) meticulously curated high-quality tasks with detailed subtask
rubrics and extensive private test cases; (2) direct integration of elite
contestant performance data to enable informative comparison against
top-performing humans; (3) planned continuous, contamination-free updates from
newly released Olympiad problems; and (4) a self-contained evaluation system
facilitating offline and easy-to-reproduce assessments. Benchmarking 32 popular
general-purpose and reasoning LLMs, we find that GPT-5 achieves a notable
81.76th percentile, a strong result that nonetheless falls short of top human
contestant performance, who usually place above 90th. In contrast, among
open-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile,
underscoring significant capability disparities from frontier closed models.
Detailed analyses indicate that robust reasoning models prioritize precise
problem analysis over excessive exploration, suggesting future models should
emphasize structured analysis and minimize unnecessary exploration. All data,
code, and leaderboard results will be made publicly available on our website.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [78] [Titans Revisited: A Lightweight Reimplementation and Critical Analysis of a Test-Time Memory Model](https://arxiv.org/abs/2510.09551)
*Gavriel Di Nepi,Federico Siciliano,Fabrizio Silvestri*

Main category: cs.LG

TL;DR: 对Google Titans模型的轻量级重实现评估，发现其神经记忆组件能持续提升性能，但由于分块处理并不总是优于基线方法。


<details>
  <summary>Details</summary>
Motivation: Google Titans模型缺乏公开代码且原描述存在模糊性，阻碍了可复现性研究。

Method: 对Titans模型进行轻量级重实现，并在掩码语言建模、时间序列预测和推荐任务上进行综合评估。

Result: Titans由于分块处理并不总是优于基线方法，但其神经记忆组件相比仅使用注意力的模型能持续提升性能。

Conclusion: 确认了该模型的创新潜力，同时指出了实际局限性并为未来研究提出了问题。

Abstract: By the end of 2024, Google researchers introduced Titans: Learning at Test
Time, a neural memory model achieving strong empirical results across multiple
tasks. However, the lack of publicly available code and ambiguities in the
original description hinder reproducibility. In this work, we present a
lightweight reimplementation of Titans and conduct a comprehensive evaluation
on Masked Language Modeling, Time Series Forecasting, and Recommendation tasks.
Our results reveal that Titans does not always outperform established baselines
due to chunking. However, its Neural Memory component consistently improves
performance compared to attention-only models. These findings confirm the
model's innovative potential while highlighting its practical limitations and
raising questions for future research.

</details>
