{"id": "2507.07325", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.07325", "abs": "https://arxiv.org/abs/2507.07325", "authors": ["Martin Obaidi", "Marc Herrmann", "Elisa Schmid", "Raymond Ochsner", "Kurt Schneider", "Jil Kl\u00fcnder"], "title": "A German Gold-Standard Dataset for Sentiment Analysis in Software Engineering", "comment": "This paper has been accepted at the 33rd IEEE International\n  Requirements Engineering Workshop (REW 2025)", "summary": "Sentiment analysis is an essential technique for investigating the emotional\nclimate within developer teams, contributing to both team productivity and\nproject success. Existing sentiment analysis tools in software engineering\nprimarily rely on English or non-German gold-standard datasets. To address this\ngap, our work introduces a German dataset of 5,949 unique developer statements,\nextracted from the German developer forum Android-Hilfe.de. Each statement was\nannotated with one of six basic emotions, based on the emotion model by Shaver\net al., by four German-speaking computer science students. Evaluation of the\nannotation process showed high interrater agreement and reliability. These\nresults indicate that the dataset is sufficiently valid and robust to support\nsentiment analysis in the German-speaking software engineering community.\nEvaluation with existing German sentiment analysis tools confirms the lack of\ndomain-specific solutions for software engineering. We also discuss approaches\nto optimize annotation and present further use cases for the dataset.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u5fb7\u8bed\u5f00\u53d1\u8005\u8bba\u575b\u7684\u60c5\u611f\u5206\u6790\u6570\u636e\u96c6\uff0c\u586b\u8865\u4e86\u5fb7\u8bed\u9886\u57df\u7a7a\u767d\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u5206\u6790\u5de5\u5177\u4e3b\u8981\u57fa\u4e8e\u82f1\u8bed\u6216\u975e\u5fb7\u8bed\u6570\u636e\u96c6\uff0c\u5fb7\u8bed\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7f3a\u4e4f\u76f8\u5173\u8d44\u6e90\u3002", "method": "\u4ece\u5fb7\u8bed\u5f00\u53d1\u8005\u8bba\u575b\u63d0\u53d65,949\u6761\u8bed\u53e5\uff0c\u7531\u56db\u540d\u5fb7\u8bed\u6bcd\u8bed\u5b66\u751f\u57fa\u4e8eShaver\u60c5\u611f\u6a21\u578b\u6807\u6ce8\u516d\u79cd\u57fa\u672c\u60c5\u611f\u3002", "result": "\u6807\u6ce8\u8fc7\u7a0b\u663e\u793a\u9ad8\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\uff0c\u9a8c\u8bc1\u4e86\u6570\u636e\u96c6\u7684\u6709\u6548\u6027\u3002\u73b0\u6709\u5fb7\u8bed\u5de5\u5177\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u8868\u73b0\u4e0d\u8db3\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u5fb7\u8bed\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u63d0\u4f9b\u4e86\u6709\u6548\u8d44\u6e90\uff0c\u5e76\u8ba8\u8bba\u4e86\u4f18\u5316\u6807\u6ce8\u548c\u6269\u5c55\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.07344", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.07344", "abs": "https://arxiv.org/abs/2507.07344", "authors": ["Martin Obaidi", "Jannik Fischbach", "Jakob Droste", "Hannah Deters", "Marc Herrmann", "Jil Kl\u00fcnder", "Steffen Kr\u00e4tzig", "Hugo Villamizar", "Kurt Schneider"], "title": "Automatic Generation of Explainability Requirements and Software Explanations From User Reviews", "comment": "This paper has been accepted at the 33rd IEEE International\n  Requirements Engineering Workshop (REW 2025)", "summary": "Explainability has become a crucial non-functional requirement to enhance\ntransparency, build user trust, and ensure regulatory compliance. However,\ntranslating explanation needs expressed in user feedback into structured\nrequirements and corresponding explanations remains challenging. While existing\nmethods can identify explanation-related concerns in user reviews, there is no\nestablished approach for systematically deriving requirements and generating\naligned explanations. To contribute toward addressing this gap, we introduce a\ntool-supported approach that automates this process. To evaluate its\neffectiveness, we collaborated with an industrial automation manufacturer to\ncreate a dataset of 58 user reviews, each annotated with manually crafted\nexplainability requirements and explanations. Our evaluation shows that while\nAI-generated requirements often lack relevance and correctness compared to\nhuman-created ones, the AI-generated explanations are frequently preferred for\ntheir clarity and style. Nonetheless, correctness remains an issue,\nhighlighting the importance of human validation. This work contributes to the\nadvancement of explainability requirements in software systems by (1)\nintroducing an automated approach to derive requirements from user reviews and\ngenerate corresponding explanations, (2) providing empirical insights into the\nstrengths and limitations of automatically generated artifacts, and (3)\nreleasing a curated dataset to support future research on the automatic\ngeneration of explainability requirements.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u7528\u4e8e\u4ece\u7528\u6237\u53cd\u9988\u4e2d\u63d0\u53d6\u53ef\u89e3\u91ca\u6027\u9700\u6c42\u5e76\u751f\u6210\u5bf9\u5e94\u89e3\u91ca\uff0c\u8bc4\u4f30\u663e\u793aAI\u751f\u6210\u7684\u9700\u6c42\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u4f46\u89e3\u91ca\u7684\u6e05\u6670\u5ea6\u66f4\u53d7\u9752\u7750\u3002", "motivation": "\u589e\u5f3a\u900f\u660e\u5ea6\u3001\u5efa\u7acb\u7528\u6237\u4fe1\u4efb\u548c\u786e\u4fdd\u5408\u89c4\u6027\u662f\u53ef\u89e3\u91ca\u6027\u7684\u5173\u952e\u9700\u6c42\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u5316\u65b9\u6cd5\u4ece\u7528\u6237\u53cd\u9988\u4e2d\u63d0\u53d6\u9700\u6c42\u5e76\u751f\u6210\u89e3\u91ca\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u5de5\u5177\u652f\u6301\u7684\u65b9\u6cd5\uff0c\u81ea\u52a8\u5316\u4ece\u7528\u6237\u8bc4\u8bba\u4e2d\u63d0\u53d6\u9700\u6c42\u548c\u751f\u6210\u89e3\u91ca\uff0c\u5e76\u901a\u8fc7\u5de5\u4e1a\u5408\u4f5c\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "AI\u751f\u6210\u7684\u9700\u6c42\u5728\u76f8\u5173\u6027\u548c\u6b63\u786e\u6027\u4e0a\u4e0d\u5982\u4eba\u5de5\uff0c\u4f46\u5176\u751f\u6210\u7684\u89e3\u91ca\u5728\u6e05\u6670\u5ea6\u548c\u98ce\u683c\u4e0a\u66f4\u53d7\u9752\u7750\uff0c\u4f46\u4ecd\u9700\u4eba\u5de5\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63a8\u52a8\u4e86\u53ef\u89e3\u91ca\u6027\u9700\u6c42\u7684\u7814\u7a76\uff0c\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u65b9\u6cd5\u548c\u6570\u636e\u96c6\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u4eba\u5de5\u9a8c\u8bc1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.07468", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.07468", "abs": "https://arxiv.org/abs/2507.07468", "authors": ["Sten Gr\u00fcner", "Nafise Eskandani"], "title": "Towards an Engineering Workflow Management System for Asset Administration Shells using BPMN", "comment": "7 pages, 7 figures, Accepted at IFAC EAAS 2025\n  (https://j3c.org/eaas.php)", "summary": "The integration of Industry 4.0 technologies into engineering workflows is an\nessential step toward automating and optimizing plant and process engineering\nprocesses. The Asset Administration Shell (AAS) serves as a key enabler for\ncreating interoperable Digital Twins that facilitate engineering data exchange\nand automation. This paper explores the use of AAS within engineering\nworkflows, particularly in combination with Business Process Model and Notation\n(BPMN) to define structured and automated processes. We propose a distributed\nAAS copy-on-write infrastructure that enhances security and scalability while\nenabling seamless cross organizational collaboration. We also introduce a\nworkflow management prototype automating AAS operations and engineering\nworkflows, improving efficiency and traceability.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7Asset Administration Shell (AAS)\u548cBPMN\u6280\u672f\u4f18\u5316\u5de5\u7a0b\u5de5\u4f5c\u6d41\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0fAAS\u57fa\u7840\u8bbe\u65bd\u548c\u5de5\u4f5c\u6d41\u7ba1\u7406\u539f\u578b\uff0c\u4ee5\u63d0\u9ad8\u6548\u7387\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "motivation": "\u5de5\u4e1a4.0\u6280\u672f\u7684\u96c6\u6210\u5bf9\u81ea\u52a8\u5316\u548c\u4f18\u5316\u5de5\u7a0b\u6d41\u7a0b\u81f3\u5173\u91cd\u8981\uff0cAAS\u662f\u5b9e\u73b0\u4e92\u64cd\u4f5c\u6570\u5b57\u5b6a\u751f\u7684\u5173\u952e\u3002", "method": "\u7ed3\u5408AAS\u4e0eBPMN\uff0c\u63d0\u51fa\u5206\u5e03\u5f0fAAS\u57fa\u7840\u8bbe\u65bd\u548c\u5de5\u4f5c\u6d41\u7ba1\u7406\u539f\u578b\u3002", "result": "\u63d0\u9ad8\u4e86\u5de5\u7a0b\u5de5\u4f5c\u6d41\u7684\u6548\u7387\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u652f\u6301\u8de8\u7ec4\u7ec7\u534f\u4f5c\u3002", "conclusion": "AAS\u4e0eBPMN\u7684\u7ed3\u5408\u4e3a\u5de5\u7a0b\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.07548", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.07548", "abs": "https://arxiv.org/abs/2507.07548", "authors": ["Jonathan Ullrich", "Matthias Koch", "Andreas Vogelsang"], "title": "From Requirements to Code: Understanding Developer Practices in LLM-Assisted Software Engineering", "comment": "This paper has been accepted for publication at the 33rd IEEE\n  International Requirements Engineering (RE) conference", "summary": "With the advent of generative LLMs and their advanced code generation\ncapabilities, some people already envision the end of traditional software\nengineering, as LLMs may be able to produce high-quality code based solely on\nthe requirements a domain expert feeds into the system. The feasibility of this\nvision can be assessed by understanding how developers currently incorporate\nrequirements when using LLMs for code generation-a topic that remains largely\nunexplored. We interviewed 18 practitioners from 14 companies to understand how\nthey (re)use information from requirements and other design artifacts to feed\nLLMs when generating code. Based on our findings, we propose a theory that\nexplains the processes developers employ and the artifacts they rely on. Our\ntheory suggests that requirements, as typically documented, are too abstract\nfor direct input into LLMs. Instead, they must first be manually decomposed\ninto programming tasks, which are then enriched with design decisions and\narchitectural constraints before being used in prompts. Our study highlights\nthat fundamental RE work is still necessary when LLMs are used to generate\ncode. Our theory is important for contextualizing scientific approaches to\nautomating requirements-centric SE tasks.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5f00\u53d1\u8005\u5982\u4f55\u5229\u7528\u9700\u6c42\u6587\u6863\u4e0eLLMs\u751f\u6210\u4ee3\u7801\uff0c\u53d1\u73b0\u9700\u6c42\u6587\u6863\u901a\u5e38\u8fc7\u4e8e\u62bd\u8c61\uff0c\u9700\u624b\u52a8\u5206\u89e3\u4e3a\u7f16\u7a0b\u4efb\u52a1\u5e76\u8865\u5145\u8bbe\u8ba1\u51b3\u7b56\u540e\u624d\u80fd\u7528\u4e8e\u63d0\u793aLLMs\u3002", "motivation": "\u7814\u7a76\u5f00\u53d1\u8005\u5982\u4f55\u5c06\u9700\u6c42\u6587\u6863\u7b49\u4fe1\u606f\u8f93\u5165LLMs\u4ee5\u751f\u6210\u4ee3\u7801\uff0c\u586b\u8865\u8fd9\u4e00\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\u3002", "method": "\u8bbf\u8c08\u4e8614\u5bb6\u516c\u53f8\u768418\u540d\u4ece\u4e1a\u8005\uff0c\u5206\u6790\u4ed6\u4eec\u5982\u4f55\u5229\u7528\u9700\u6c42\u548c\u8bbe\u8ba1\u6587\u6863\u4e3aLLMs\u751f\u6210\u4ee3\u7801\u63d0\u4f9b\u8f93\u5165\u3002", "result": "\u9700\u6c42\u6587\u6863\u901a\u5e38\u8fc7\u4e8e\u62bd\u8c61\uff0c\u9700\u5206\u89e3\u4e3a\u7f16\u7a0b\u4efb\u52a1\u5e76\u8865\u5145\u8bbe\u8ba1\u51b3\u7b56\u540e\u624d\u80fd\u6709\u6548\u7528\u4e8eLLMs\u3002", "conclusion": "\u5373\u4f7f\u4f7f\u7528LLMs\u751f\u6210\u4ee3\u7801\uff0c\u57fa\u7840\u7684\u9700\u6c42\u5de5\u7a0b\u5de5\u4f5c\u4ecd\u4e0d\u53ef\u6216\u7f3a\uff0c\u7814\u7a76\u4e3a\u81ea\u52a8\u5316\u9700\u6c42\u9a71\u52a8\u7684SE\u4efb\u52a1\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2507.07210", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07210", "abs": "https://arxiv.org/abs/2507.07210", "authors": ["Nils Rollshausen", "Alexander Heinrich", "Matthias Hollick", "Jiska Classen"], "title": "WatchWitch: Interoperability, Privacy, and Autonomy for the Apple Watch", "comment": "To appear in \"Proceedings on Privacy Enhancing Technologies\"", "summary": "Smartwatches such as the Apple Watch collect vast amounts of intimate health\nand fitness data as we wear them. Users have little choice regarding how this\ndata is processed: The Apple Watch can only be used with Apple's iPhones, using\ntheir software and their cloud services. We are the first to publicly\nreverse-engineer the watch's wireless protocols, which led to discovering\nmultiple security issues in Apple's proprietary implementation. With\nWatchWitch, our custom Android reimplementation, we break out of Apple's walled\ngarden -- demonstrating practical interoperability with enhanced privacy\ncontrols and data autonomy. We thus pave the way for more consumer choice in\nthe smartwatch ecosystem, offering users more control over their devices.", "AI": {"tldr": "\u8bba\u6587\u516c\u5f00\u9006\u5411\u5de5\u7a0b\u4e86Apple Watch\u7684\u65e0\u7ebf\u534f\u8bae\uff0c\u53d1\u73b0\u5b89\u5168\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86Android\u7248WatchWitch\uff0c\u6253\u7834\u82f9\u679c\u751f\u6001\u9650\u5236\uff0c\u589e\u5f3a\u9690\u79c1\u63a7\u5236\u3002", "motivation": "Apple Watch\u7528\u6237\u5bf9\u6570\u636e\u5904\u7406\u7f3a\u4e4f\u9009\u62e9\u6743\uff0c\u9700\u4f9d\u8d56\u82f9\u679c\u751f\u6001\uff0c\u9650\u5236\u4e86\u9690\u79c1\u548c\u6570\u636e\u81ea\u4e3b\u6027\u3002", "method": "\u9006\u5411\u5de5\u7a0bApple Watch\u7684\u65e0\u7ebf\u534f\u8bae\uff0c\u53d1\u73b0\u5b89\u5168\u95ee\u9898\uff0c\u5f00\u53d1Android\u7248WatchWitch\u5b9e\u73b0\u4e92\u64cd\u4f5c\u6027\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e0eApple Watch\u7684\u4e92\u64cd\u4f5c\uff0c\u63d0\u4f9b\u66f4\u5f3a\u7684\u9690\u79c1\u63a7\u5236\u548c\u6570\u636e\u81ea\u4e3b\u6743\u3002", "conclusion": "WatchWitch\u4e3a\u667a\u80fd\u624b\u8868\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u591a\u7528\u6237\u9009\u62e9\uff0c\u589e\u5f3a\u4e86\u5bf9\u8bbe\u5907\u7684\u63a7\u5236\u3002"}}
{"id": "2507.07115", "categories": ["cs.AI", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.07115", "abs": "https://arxiv.org/abs/2507.07115", "authors": ["Javal Vyas", "Mehmet Mercangoz"], "title": "Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation", "comment": null, "summary": "The increasing complexity of modern chemical processes, coupled with\nworkforce shortages and intricate fault scenarios, demands novel automation\nparadigms that blend symbolic reasoning with adaptive control. In this work, we\nintroduce a unified agentic framework that leverages large language models\n(LLMs) for both discrete fault-recovery planning and continuous process control\nwithin a single architecture. We adopt Finite State Machines (FSMs) as\ninterpretable operating envelopes: an LLM-driven planning agent proposes\nrecovery sequences through the FSM, a Simulation Agent executes and checks each\ntransition, and a Validator-Reprompting loop iteratively refines invalid plans.\nIn Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25\nstates, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path\nsuccess within five reprompts-outperforming open-source LLMs in both accuracy\nand latency. In Case Study 2, the same framework modulates dual-heater inputs\non a laboratory TCLab platform (and its digital twin) to maintain a target\naverage temperature under persistent asymmetric disturbances. Compared to\nclassical PID control, our LLM-based controller attains similar performance,\nwhile ablation of the prompting loop reveals its critical role in handling\nnonlinear dynamics. We analyze key failure modes-such as instruction following\nlapses and coarse ODE approximations. Our results demonstrate that, with\nstructured feedback and modular agents, LLMs can unify high-level symbolic\nplanningand low-level continuous control, paving the way towards resilient,\nlanguage-driven automation in chemical engineering.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7b26\u53f7\u63a8\u7406\u4e0e\u81ea\u9002\u5e94\u63a7\u5236\u7684\u7edf\u4e00\u4ee3\u7406\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u540c\u65f6\u5904\u7406\u79bb\u6563\u6545\u969c\u6062\u590d\u89c4\u5212\u548c\u8fde\u7eed\u8fc7\u7a0b\u63a7\u5236\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u4ee3\u5316\u5b66\u8fc7\u7a0b\u65e5\u76ca\u590d\u6742\uff0c\u52b3\u52a8\u529b\u77ed\u7f3a\u548c\u6545\u969c\u573a\u666f\u591a\u6837\u5316\uff0c\u9700\u8981\u65b0\u7684\u81ea\u52a8\u5316\u8303\u5f0f\u6765\u7ed3\u5408\u7b26\u53f7\u63a8\u7406\u4e0e\u81ea\u9002\u5e94\u63a7\u5236\u3002", "method": "\u91c7\u7528\u6709\u9650\u72b6\u6001\u673a\uff08FSMs\uff09\u4f5c\u4e3a\u53ef\u89e3\u91ca\u7684\u64cd\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684\u89c4\u5212\u4ee3\u7406\u63d0\u51fa\u6062\u590d\u5e8f\u5217\uff0c\u6a21\u62df\u4ee3\u7406\u6267\u884c\u548c\u68c0\u67e5\u6bcf\u4e2a\u8f6c\u6362\uff0c\u9a8c\u8bc1-\u91cd\u65b0\u63d0\u793a\u5faa\u73af\u8fed\u4ee3\u4f18\u5316\u65e0\u6548\u8ba1\u5212\u3002", "result": "\u5728\u6848\u4f8b\u7814\u7a761\u4e2d\uff0cGPT-4o\u548cGPT-4o-mini\u5728180\u4e2a\u968f\u673a\u751f\u6210\u7684FSMs\u4e2d\u5b9e\u73b0100%\u6709\u6548\u8def\u5f84\u6210\u529f\u7387\uff1b\u6848\u4f8b\u7814\u7a762\u4e2d\uff0cLLM\u63a7\u5236\u5668\u5728\u975e\u7ebf\u6027\u52a8\u6001\u5904\u7406\u4e2d\u8868\u73b0\u4e0e\u7ecf\u5178PID\u63a7\u5236\u76f8\u5f53\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u53cd\u9988\u548c\u6a21\u5757\u5316\u4ee3\u7406\uff0cLLMs\u80fd\u591f\u7edf\u4e00\u9ad8\u7ea7\u7b26\u53f7\u89c4\u5212\u548c\u4f4e\u7ea7\u8fde\u7eed\u63a7\u5236\uff0c\u4e3a\u5316\u5b66\u5de5\u7a0b\u4e2d\u7684\u5f39\u6027\u8bed\u8a00\u9a71\u52a8\u81ea\u52a8\u5316\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.07682", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.07682", "abs": "https://arxiv.org/abs/2507.07682", "authors": ["Kaicheng Huang", "Fanyu Wang", "Yutan Huang", "Chetan Arora"], "title": "Prompt Engineering for Requirements Engineering: A Literature Review and Roadmap", "comment": null, "summary": "Advancements in large language models (LLMs) have led to a surge of prompt\nengineering (PE) techniques that can enhance various requirements engineering\n(RE) tasks. However, current LLMs are often characterized by significant\nuncertainty and a lack of controllability. This absence of clear guidance on\nhow to effectively prompt LLMs acts as a barrier to their trustworthy\nimplementation in the RE field. We present the first roadmap-oriented\nsystematic literature review of Prompt Engineering for RE (PE4RE). Following\nKitchenham's and Petersen's secondary-study protocol, we searched six digital\nlibraries, screened 867 records, and analyzed 35 primary studies. To bring\norder to a fragmented landscape, we propose a hybrid taxonomy that links\ntechnique-oriented patterns (e.g., few-shot, Chain-of-Thought) to task-oriented\nRE roles (elicitation, validation, traceability). Two research questions, with\nfive sub-questions, map the tasks addressed, LLM families used, and prompt\ntypes adopted, and expose current limitations and research gaps. Finally, we\noutline a step-by-step roadmap showing how today's ad-hoc PE prototypes can\nevolve into reproducible, practitioner-friendly workflows.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u8def\u7ebf\u56fe\u7684\u63d0\u793a\u5de5\u7a0b\uff08PE4RE\uff09\u5206\u7c7b\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u53ef\u63a7\u6027\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u5728RE\u4efb\u52a1\u4e2d\u5b58\u5728\u663e\u8457\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u7f3a\u4e4f\u53ef\u63a7\u6027\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u63d0\u793a\u65b9\u6cd5\u963b\u788d\u4e86\u5176\u5728RE\u9886\u57df\u7684\u53ef\u4fe1\u5e94\u7528\u3002", "method": "\u91c7\u7528Kitchenham\u548cPetersen\u7684\u4e8c\u6b21\u7814\u7a76\u534f\u8bae\uff0c\u7b5b\u9009\u5e76\u5206\u6790\u4e8635\u9879\u4e3b\u8981\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u5206\u7c7b\u6cd5\uff0c\u5c06\u6280\u672f\u5bfc\u5411\u7684\u6a21\u5f0f\u4e0e\u4efb\u52a1\u5bfc\u5411\u7684RE\u89d2\u8272\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524dPE4RE\u7684\u4efb\u52a1\u3001LLM\u5bb6\u65cf\u548c\u63d0\u793a\u7c7b\u578b\uff0c\u5e76\u6307\u51fa\u4e86\u5c40\u9650\u6027\u548c\u7814\u7a76\u7a7a\u767d\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9010\u6b65\u8def\u7ebf\u56fe\uff0c\u5c06\u5f53\u524d\u7684\u4e34\u65f6PE\u539f\u578b\u53d1\u5c55\u4e3a\u53ef\u91cd\u590d\u3001\u9762\u5411\u5b9e\u8df5\u8005\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2507.07244", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07244", "abs": "https://arxiv.org/abs/2507.07244", "authors": ["Faissal Ahmadou", "Sepehr Ghaffarzadegan", "Boubakr Nour", "Makan Pourzandi", "Mourad Debbabi", "Chadi Assi"], "title": "Automated Attack Testflow Extraction from Cyber Threat Report using BERT for Contextual Analysis", "comment": null, "summary": "In the ever-evolving landscape of cybersecurity, the rapid identification and\nmitigation of Advanced Persistent Threats (APTs) is crucial. Security\npractitioners rely on detailed threat reports to understand the tactics,\ntechniques, and procedures (TTPs) employed by attackers. However, manually\nextracting attack testflows from these reports requires elusive knowledge and\nis time-consuming and prone to errors. This paper proposes FLOWGUARDIAN, a\nnovel solution leveraging language models (i.e., BERT) and Natural Language\nProcessing (NLP) techniques to automate the extraction of attack testflows from\nunstructured threat reports. FLOWGUARDIAN systematically analyzes and\ncontextualizes security events, reconstructs attack sequences, and then\ngenerates comprehensive testflows. This automated approach not only saves time\nand reduces human error but also ensures comprehensive coverage and robustness\nin cybersecurity testing. Empirical validation using public threat reports\ndemonstrates FLOWGUARDIAN's accuracy and efficiency, significantly enhancing\nthe capabilities of security teams in proactive threat hunting and incident\nresponse.", "AI": {"tldr": "FLOWGUARDIAN\u5229\u7528BERT\u548cNLP\u6280\u672f\u81ea\u52a8\u4ece\u975e\u7ed3\u6784\u5316\u5a01\u80c1\u62a5\u544a\u4e2d\u63d0\u53d6\u653b\u51fb\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u63d0\u5347\u7f51\u7edc\u5b89\u5168\u6d4b\u8bd5\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u624b\u52a8\u63d0\u53d6\u653b\u51fb\u6d4b\u8bd5\u6d41\u7a0b\u8017\u65f6\u4e14\u6613\u9519\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u4ee5\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u5229\u7528BERT\u548cNLP\u6280\u672f\u5206\u6790\u5b89\u5168\u4e8b\u4ef6\uff0c\u91cd\u6784\u653b\u51fb\u5e8f\u5217\u5e76\u751f\u6210\u6d4b\u8bd5\u6d41\u7a0b\u3002", "result": "\u5b9e\u8bc1\u9a8c\u8bc1\u663e\u793aFLOWGUARDIAN\u5728\u516c\u5f00\u5a01\u80c1\u62a5\u544a\u4e2d\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "FLOWGUARDIAN\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u56e2\u961f\u5728\u4e3b\u52a8\u5a01\u80c1\u72e9\u730e\u548c\u4e8b\u4ef6\u54cd\u5e94\u4e2d\u7684\u80fd\u529b\u3002"}}
{"id": "2507.07134", "categories": ["cs.AI", "cs.LG", "I.2.10"], "pdf": "https://arxiv.org/pdf/2507.07134", "abs": "https://arxiv.org/abs/2507.07134", "authors": ["Mridula Vijendran", "Shuang Chen", "Jingjing Deng", "Hubert P. H. Shum"], "title": "BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks", "comment": "18 pages, 7 figures, 3 tables", "summary": "The pervasive issue of bias in AI presents a significant challenge to\npainting classification, and is getting more serious as these systems become\nincreasingly integrated into tasks like art curation and restoration. Biases,\noften arising from imbalanced datasets where certain artistic styles dominate,\ncompromise the fairness and accuracy of model predictions, i.e., classifiers\nare less accurate on rarely seen paintings. While prior research has made\nstrides in improving classification performance, it has largely overlooked the\ncritical need to address these underlying biases, that is, when dealing with\nout-of-distribution (OOD) data. Our insight highlights the necessity of a more\nrobust approach to bias mitigation in AI models for art classification on\nbiased training data. We propose a novel OOD-informed model bias adaptive\nsampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It\naddresses these challenges by dynamically adjusting temperature scaling and\nsampling probabilities, thereby promoting a more equitable representation of\nall classes. We evaluate our proposed approach to the KaoKore and PACS\ndatasets, focusing on the model's ability to reduce class-wise bias. We further\npropose a new metric, Same-Dataset OOD Detection Score (SODC), designed to\nassess class-wise separation and per-class bias reduction. Our method\ndemonstrates the ability to balance high performance with fairness, making it a\nrobust solution for unbiasing AI models in the art domain.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBOOST\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u6e29\u5ea6\u7f29\u653e\u548c\u91c7\u6837\u6982\u7387\uff0c\u89e3\u51b3AI\u827a\u672f\u5206\u7c7b\u4e2d\u7684\u504f\u89c1\u95ee\u9898\uff0c\u5e76\u5728KaoKore\u548cPACS\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "AI\u5728\u827a\u672f\u5206\u7c7b\u4e2d\u5b58\u5728\u504f\u89c1\u95ee\u9898\uff0c\u5c24\u5176\u662f\u9762\u5bf9\u5206\u5e03\u5916\u6570\u636e\u65f6\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u63d0\u51faBOOST\u65b9\u6cd5\uff0c\u52a8\u6001\u8c03\u6574\u6e29\u5ea6\u7f29\u653e\u548c\u91c7\u6837\u6982\u7387\uff0c\u5e76\u5f15\u5165\u65b0\u6307\u6807SODC\u8bc4\u4f30\u7c7b\u522b\u5206\u79bb\u548c\u504f\u89c1\u51cf\u5c11\u3002", "result": "BOOST\u5728KaoKore\u548cPACS\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e73\u8861\u4e86\u6027\u80fd\u4e0e\u516c\u5e73\u6027\u3002", "conclusion": "BOOST\u662f\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u827a\u672f\u9886\u57df\u4e2d\u7684AI\u6a21\u578b\u53bb\u504f\u89c1\u5316\u3002"}}
{"id": "2507.07689", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.07689", "abs": "https://arxiv.org/abs/2507.07689", "authors": ["Chetan Arora", "Fanyu Wang", "Chakkrit Tantithamthavorn", "Aldeida Aleti", "Shaun Kenyon"], "title": "From Domain Documents to Requirements: Retrieval-Augmented Generation in the Space Industry", "comment": null, "summary": "Requirements engineering (RE) in the space industry is inherently complex,\ndemanding high precision, alignment with rigorous standards, and adaptability\nto mission-specific constraints. Smaller space organisations and new entrants\noften struggle to derive actionable requirements from extensive, unstructured\ndocuments such as mission briefs, interface specifications, and regulatory\nstandards. In this innovation opportunity paper, we explore the potential of\nRetrieval-Augmented Generation (RAG) models to support and (semi-)automate\nrequirements generation in the space domain. We present a modular, AI-driven\napproach that preprocesses raw space mission documents, classifies them into\nsemantically meaningful categories, retrieves contextually relevant content\nfrom domain standards, and synthesises draft requirements using large language\nmodels (LLMs). We apply the approach to a real-world mission document from the\nspace domain to demonstrate feasibility and assess early outcomes in\ncollaboration with our industry partner, Starbound Space Solutions. Our\npreliminary results indicate that the approach can reduce manual effort,\nimprove coverage of relevant requirements, and support lightweight compliance\nalignment. We outline a roadmap toward broader integration of AI in RE\nworkflows, intending to lower barriers for smaller organisations to participate\nin large-scale, safety-critical missions.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6a21\u578b\u652f\u6301\u822a\u5929\u9886\u57df\u9700\u6c42\u5de5\u7a0b\u7684\u534a\u81ea\u52a8\u5316\u751f\u6210\uff0c\u901a\u8fc7AI\u65b9\u6cd5\u9884\u5904\u7406\u6587\u6863\u3001\u5206\u7c7b\u5185\u5bb9\u3001\u68c0\u7d22\u76f8\u5173\u4fe1\u606f\u5e76\u751f\u6210\u9700\u6c42\u8349\u6848\uff0c\u521d\u6b65\u7ed3\u679c\u663e\u793a\u53ef\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u5e76\u63d0\u9ad8\u9700\u6c42\u8986\u76d6\u3002", "motivation": "\u822a\u5929\u9886\u57df\u9700\u6c42\u5de5\u7a0b\u590d\u6742\u4e14\u9700\u9ad8\u7cbe\u5ea6\uff0c\u5c0f\u578b\u673a\u6784\u96be\u4ee5\u4ece\u5927\u91cf\u975e\u7ed3\u6784\u5316\u6587\u6863\u4e2d\u63d0\u53d6\u53ef\u64cd\u4f5c\u9700\u6c42\uff0c\u56e0\u6b64\u63a2\u7d22AI\u8f85\u52a9\u65b9\u6cd5\u4ee5\u964d\u4f4e\u53c2\u4e0e\u95e8\u69db\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316AI\u9a71\u52a8\u65b9\u6cd5\uff0c\u9884\u5904\u7406\u822a\u5929\u4efb\u52a1\u6587\u6863\uff0c\u5206\u7c7b\u8bed\u4e49\u5185\u5bb9\uff0c\u68c0\u7d22\u76f8\u5173\u6807\u51c6\u4fe1\u606f\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9700\u6c42\u8349\u6848\u3002", "result": "\u521d\u6b65\u5e94\u7528\u663e\u793a\u8be5\u65b9\u6cd5\u53ef\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u63d0\u9ad8\u9700\u6c42\u8986\u76d6\u8303\u56f4\uff0c\u5e76\u652f\u6301\u8f7b\u91cf\u7ea7\u5408\u89c4\u6027\u5bf9\u9f50\u3002", "conclusion": "\u7814\u7a76\u4e3aAI\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\uff0c\u65e8\u5728\u5e2e\u52a9\u5c0f\u578b\u673a\u6784\u66f4\u6613\u53c2\u4e0e\u5927\u578b\u5173\u952e\u4efb\u52a1\u3002"}}
{"id": "2507.07246", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07246", "abs": "https://arxiv.org/abs/2507.07246", "authors": ["Peicheng Wang", "Monika Santra", "Mingyu Liu", "Cong Sun", "Dongrui Zeng", "Gang Tan"], "title": "Disa: Accurate Learning-based Static Disassembly with Attentions", "comment": "To appear at ACM CCS 2025", "summary": "For reverse engineering related security domains, such as vulnerability\ndetection, malware analysis, and binary hardening, disassembly is crucial yet\nchallenging. The fundamental challenge of disassembly is to identify\ninstruction and function boundaries. Classic approaches rely on file-format\nassumptions and architecture-specific heuristics to guess the boundaries,\nresulting in incomplete and incorrect disassembly, especially when the binary\nis obfuscated. Recent advancements of disassembly have demonstrated that deep\nlearning can improve both the accuracy and efficiency of disassembly. In this\npaper, we propose Disa, a new learning-based disassembly approach that uses the\ninformation of superset instructions over the multi-head self-attention to\nlearn the instructions' correlations, thus being able to infer function\nentry-points and instruction boundaries. Disa can further identify instructions\nrelevant to memory block boundaries to facilitate an advanced block-memory\nmodel based value-set analysis for an accurate control flow graph (CFG)\ngeneration. Our experiments show that Disa outperforms prior deep-learning\ndisassembly approaches in function entry-point identification, especially\nachieving 9.1% and 13.2% F1-score improvement on binaries respectively\nobfuscated by the disassembly desynchronization technique and popular\nsource-level obfuscator. By achieving an 18.5% improvement in the memory block\nprecision, Disa generates more accurate CFGs with a 4.4% reduction in Average\nIndirect Call Targets (AICT) compared with the state-of-the-art heuristic-based\napproach.", "AI": {"tldr": "Disa\u662f\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u53cd\u6c47\u7f16\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5b66\u4e60\u6307\u4ee4\u76f8\u5173\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u53cd\u6c47\u7f16\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u6df7\u6dc6\u4e8c\u8fdb\u5236\u6587\u4ef6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u53cd\u6c47\u7f16\u5728\u5b89\u5168\u9886\u57df\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u6587\u4ef6\u683c\u5f0f\u5047\u8bbe\u548c\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u5b8c\u6574\u6216\u4e0d\u51c6\u786e\uff0c\u5c24\u5176\u662f\u5728\u4e8c\u8fdb\u5236\u6587\u4ef6\u88ab\u6df7\u6dc6\u65f6\u3002", "method": "Disa\u91c7\u7528\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5b66\u4e60\u6307\u4ee4\u76f8\u5173\u6027\uff0c\u63a8\u65ad\u51fd\u6570\u5165\u53e3\u70b9\u548c\u6307\u4ee4\u8fb9\u754c\uff0c\u5e76\u8bc6\u522b\u4e0e\u5185\u5b58\u5757\u8fb9\u754c\u76f8\u5173\u7684\u6307\u4ee4\uff0c\u4ee5\u751f\u6210\u66f4\u7cbe\u786e\u7684\u63a7\u5236\u6d41\u56fe\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDisa\u5728\u51fd\u6570\u5165\u53e3\u70b9\u8bc6\u522b\u4e0a\u4f18\u4e8e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0cF1\u5206\u6570\u5206\u522b\u63d0\u9ad8\u4e869.1%\u548c13.2%\uff0c\u5185\u5b58\u5757\u7cbe\u5ea6\u63d0\u5347\u4e8618.5%\uff0c\u95f4\u63a5\u8c03\u7528\u76ee\u6807\u51cf\u5c11\u4e864.4%\u3002", "conclusion": "Disa\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u53cd\u6c47\u7f16\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u5c24\u5176\u5728\u5904\u7406\u6df7\u6dc6\u4e8c\u8fdb\u5236\u6587\u4ef6\u65f6\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.07203", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07203", "abs": "https://arxiv.org/abs/2507.07203", "authors": ["Minkyung Kim", "Junsik Kim", "Hwidong Bae", "Woongcheol Yang", "Sangdon Park", "Sohee Bae"], "title": "State-Inference-Based Prompting for Natural Language Trading with Game NPCs", "comment": "9 pages main content, 4 pages appendix, 3 figures. Accepted to the\n  KDD 2025 Workshop on Prompt Optimization", "summary": "Large Language Models enable dynamic game interactions but struggle with\nrule-governed trading systems. Current implementations suffer from rule\nviolations, such as item hallucinations and calculation errors, that erode\nplayer trust. Here, State-Inference-Based Prompting (SIBP) enables reliable\ntrading through autonomous dialogue state inference and context-specific rule\nadherence. The approach decomposes trading into six states within a unified\nprompt framework, implementing context-aware item referencing and\nplaceholder-based price calculations. Evaluation across 100 trading dialogues\ndemonstrates >97% state compliance, >95% referencing accuracy, and 99.7%\ncalculation precision. SIBP maintains computational efficiency while\noutperforming baseline approaches, establishing a practical foundation for\ntrustworthy NPC interactions in commercial games.", "AI": {"tldr": "SIBP\u65b9\u6cd5\u901a\u8fc7\u72b6\u6001\u63a8\u65ad\u548c\u89c4\u5219\u9075\u5b88\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6e38\u620f\u4ea4\u6613\u7cfb\u7edf\u4e2d\u7684\u89c4\u5219\u8fdd\u53cd\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u73a9\u5bb6\u4fe1\u4efb\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6e38\u620f\u4ea4\u6613\u7cfb\u7edf\u4e2d\u5b58\u5728\u89c4\u5219\u8fdd\u53cd\u95ee\u9898\uff08\u5982\u7269\u54c1\u5e7b\u89c9\u548c\u8ba1\u7b97\u9519\u8bef\uff09\uff0c\u5bfc\u81f4\u73a9\u5bb6\u4fe1\u4efb\u5ea6\u4e0b\u964d\u3002", "method": "\u63d0\u51faState-Inference-Based Prompting (SIBP)\uff0c\u5c06\u4ea4\u6613\u5206\u89e3\u4e3a\u516d\u4e2a\u72b6\u6001\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u7269\u54c1\u5f15\u7528\u548c\u5360\u4f4d\u7b26\u4ef7\u683c\u8ba1\u7b97\u5b9e\u73b0\u89c4\u5219\u9075\u5b88\u3002", "result": "\u5728100\u6b21\u4ea4\u6613\u5bf9\u8bdd\u4e2d\uff0c\u72b6\u6001\u5408\u89c4\u7387>97%\uff0c\u5f15\u7528\u51c6\u786e\u7387>95%\uff0c\u8ba1\u7b97\u7cbe\u5ea699.7%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SIBP\u4e3a\u5546\u4e1a\u6e38\u620f\u4e2d\u53ef\u4fe1\u8d56\u7684NPC\u4ea4\u4e92\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.07250", "categories": ["cs.CR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.07250", "abs": "https://arxiv.org/abs/2507.07250", "authors": ["Jordi Serra-Ruiz", "David Meg\u00edas"], "title": "Semi-fragile watermarking of remote sensing images using DWT, vector quantization and automatic tiling", "comment": null, "summary": "A semi-fragile watermarking scheme for multiple band images is presented in\nthis article. We propose to embed a mark into remote sensing images applying a\ntree-structured vector quantization approach to the pixel signatures instead of\nprocessing each band separately. The signature of the multispectral or\nhyperspectral image is used to embed the mark in it order to detect any\nsignificant modification of the original image. The image is segmented into\nthree-dimensional blocks, and a tree-structured vector quantizer is built for\neach block. These trees are manipulated using an iterative algorithm until the\nresulting block satisfies a required criterion, which establishes the embedded\nmark. The method is shown to be able to preserve the mark under lossy\ncompression (above a given threshold) but, at the same time, it detects\npossibly forged blocks and their position in the whole image.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u591a\u6ce2\u6bb5\u56fe\u50cf\u7684\u534a\u8106\u5f31\u6c34\u5370\u65b9\u6848\uff0c\u901a\u8fc7\u6811\u7ed3\u6784\u5411\u91cf\u91cf\u5316\u5d4c\u5165\u6807\u8bb0\uff0c\u4ee5\u68c0\u6d4b\u56fe\u50cf\u7be1\u6539\u3002", "motivation": "\u4fdd\u62a4\u9065\u611f\u56fe\u50cf\u514d\u53d7\u7be1\u6539\uff0c\u540c\u65f6\u5141\u8bb8\u4e00\u5b9a\u7a0b\u5ea6\u7684\u6709\u635f\u538b\u7f29\u3002", "method": "\u5c06\u56fe\u50cf\u5206\u5272\u4e3a\u4e09\u7ef4\u5757\uff0c\u4e3a\u6bcf\u4e2a\u5757\u6784\u5efa\u6811\u7ed3\u6784\u5411\u91cf\u91cf\u5316\u5668\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u7b97\u6cd5\u5d4c\u5165\u6807\u8bb0\u3002", "result": "\u65b9\u6cd5\u80fd\u5728\u6709\u635f\u538b\u7f29\uff08\u8d85\u8fc7\u9608\u503c\uff09\u4e0b\u4fdd\u7559\u6807\u8bb0\uff0c\u540c\u65f6\u68c0\u6d4b\u7be1\u6539\u5757\u53ca\u5176\u4f4d\u7f6e\u3002", "conclusion": "\u8be5\u65b9\u6848\u6709\u6548\u5e73\u8861\u4e86\u6c34\u5370\u7684\u9c81\u68d2\u6027\u548c\u8106\u5f31\u6027\uff0c\u9002\u7528\u4e8e\u9065\u611f\u56fe\u50cf\u4fdd\u62a4\u3002"}}
{"id": "2507.07217", "categories": ["cs.AI", "cs.LG", "cs.LO", "I.2.4; I.2.7; J.4"], "pdf": "https://arxiv.org/pdf/2507.07217", "abs": "https://arxiv.org/abs/2507.07217", "authors": ["Zili Wang", "Frank Montabon", "Kristin Yvonne Rozier"], "title": "Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains", "comment": null, "summary": "Supply chain networks are complex systems that are challenging to analyze;\nthis problem is exacerbated when there are illicit activities involved in the\nsupply chain, such as counterfeit parts, forced labor, or human trafficking.\nWhile machine learning (ML) can find patterns in complex systems like supply\nchains, traditional ML techniques require large training data sets. However,\nillicit supply chains are characterized by very sparse data, and the data that\nis available is often (purposely) corrupted or unreliable in order to hide the\nnature of the activities. We need to be able to automatically detect new\npatterns that correlate with such illegal activity over complex, even temporal\ndata, without requiring large training data sets. We explore neurosymbolic\nmethods for identifying instances of illicit activity in supply chains and\ncompare the effectiveness of manual and automated feature extraction from news\narticles accurately describing illicit activities uncovered by authorities. We\npropose a question tree approach for querying a large language model (LLM) to\nidentify and quantify the relevance of articles. This enables a systematic\nevaluation of the differences between human and machine classification of news\narticles related to forced labor in supply chains.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5728\u7a00\u758f\u6570\u636e\u6761\u4ef6\u4e0b\u68c0\u6d4b\u4f9b\u5e94\u94fe\u4e2d\u7684\u975e\u6cd5\u6d3b\u52a8\uff0c\u5e76\u6bd4\u8f83\u4e86\u4eba\u5de5\u4e0e\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\u7684\u6548\u679c\u3002", "motivation": "\u4f9b\u5e94\u94fe\u7f51\u7edc\u590d\u6742\u4e14\u6d89\u53ca\u975e\u6cd5\u6d3b\u52a8\u65f6\u6570\u636e\u7a00\u758f\u4e14\u4e0d\u53ef\u9760\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u7ed3\u5408\u95ee\u9898\u6811\u67e5\u8be2\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u6bd4\u8f83\u4eba\u5de5\u4e0e\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\u7684\u6548\u679c\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5316\u65b0\u95fb\u6587\u7ae0\u7684\u76f8\u5173\u6027\uff0c\u5e76\u6bd4\u8f83\u4eba\u5de5\u4e0e\u673a\u5668\u5206\u7c7b\u7684\u5dee\u5f02\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5728\u7a00\u758f\u6570\u636e\u6761\u4ef6\u4e0b\u6709\u6548\uff0c\u4e3a\u4f9b\u5e94\u94fe\u975e\u6cd5\u6d3b\u52a8\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.07258", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07258", "abs": "https://arxiv.org/abs/2507.07258", "authors": ["Rami Darwish", "Mahmoud Abdelsalam", "Sajad Khorsandroo", "Kaushik Roy"], "title": "FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning", "comment": null, "summary": "As IoT ecosystems continue to expand across critical sectors, they have\nbecome prominent targets for increasingly sophisticated and large-scale malware\nattacks. The evolving threat landscape, combined with the sensitive nature of\nIoT-generated data, demands detection frameworks that are both\nprivacy-preserving and resilient to data heterogeneity. Federated Learning (FL)\noffers a promising solution by enabling decentralized model training without\nexposing raw data. However, standard FL algorithms such as FedAvg and FedProx\noften fall short in real-world deployments characterized by class imbalance and\nnon-IID data distributions -- particularly in the presence of rare or disjoint\nmalware classes. To address these challenges, we propose FedP3E\n(Privacy-Preserving Prototype Exchange), a novel FL framework that supports\nindirect cross-client representation sharing while maintaining data privacy.\nEach client constructs class-wise prototypes using Gaussian Mixture Models\n(GMMs), perturbs them with Gaussian noise, and transmits only these compact\nsummaries to the server. The aggregated prototypes are then distributed back to\nclients and integrated into local training, supported by SMOTE-based\naugmentation to enhance representation of minority malware classes. Rather than\nrelying solely on parameter averaging, our prototype-driven mechanism enables\nclients to enrich their local models with complementary structural patterns\nobserved across the federation -- without exchanging raw data or gradients.\nThis targeted strategy reduces the adverse impact of statistical heterogeneity\nwith minimal communication overhead. We evaluate FedP3E on the N-BaIoT dataset\nunder realistic cross-silo scenarios with varying degrees of data imbalance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedP3E\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u9690\u79c1\u4fdd\u62a4\u7684\u7c7b\u539f\u578b\u4ea4\u6362\u89e3\u51b3IoT\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u7684\u6570\u636e\u5f02\u6784\u6027\u548c\u9690\u79c1\u95ee\u9898\u3002", "motivation": "IoT\u751f\u6001\u7cfb\u7edf\u9762\u4e34\u590d\u6742\u6076\u610f\u8f6f\u4ef6\u653b\u51fb\uff0c\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u5728\u6570\u636e\u5f02\u6784\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u4f7f\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u751f\u6210\u7c7b\u539f\u578b\uff0c\u6dfb\u52a0\u566a\u58f0\u4fdd\u62a4\u9690\u79c1\uff0c\u5e76\u901a\u8fc7SMOTE\u589e\u5f3a\u5c11\u6570\u7c7b\u8868\u793a\u3002", "result": "\u5728N-BaIoT\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86FedP3E\u7684\u6709\u6548\u6027\uff0c\u51cf\u5c11\u4e86\u7edf\u8ba1\u5f02\u6784\u6027\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "FedP3E\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u73b0\u5b9eIoT\u573a\u666f\u3002"}}
{"id": "2507.07257", "categories": ["cs.AI", "astro-ph.IM", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.07257", "abs": "https://arxiv.org/abs/2507.07257", "authors": ["Licong Xu", "Milind Sarkar", "Anto I. Lonappan", "\u00cd\u00f1igo Zubeldia", "Pablo Villanueva-Domingo", "Santiago Casas", "Christian Fidler", "Chetana Amancharla", "Ujjwal Tiwari", "Adrian Bayer", "Chadi Ait Ekiou", "Miles Cranmer", "Adrian Dimitrov", "James Fergusson", "Kahaan Gandhi", "Sven Krippendorf", "Andrew Laverick", "Julien Lesgourgues", "Antony Lewis", "Thomas Meier", "Blake Sherwin", "Kristen Surrao", "Francisco Villaescusa-Navarro", "Chi Wang", "Xueqing Xu", "Boris Bolliet"], "title": "Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery", "comment": "Accepted contribution to the ICML 2025 Workshop on Machine Learning\n  for Astrophysics. Code: https://github.com/CMBAgents/cmbagent; Videos:\n  https://www.youtube.com/@cmbagent; HuggingFace:\n  https://huggingface.co/spaces/astropilot-ai/cmbagent; Cloud:\n  https://cmbagent.cloud", "summary": "We present a multi-agent system for automation of scientific research tasks,\ncmbagent. The system is formed by about 30 Large Language Model (LLM) agents\nand implements a Planning & Control strategy to orchestrate the agentic\nworkflow, with no human-in-the-loop at any point. Each agent specializes in a\ndifferent task (performing retrieval on scientific papers and codebases,\nwriting code, interpreting results, critiquing the output of other agents) and\nthe system is able to execute code locally. We successfully apply cmbagent to\ncarry out a PhD level cosmology task (the measurement of cosmological\nparameters using supernova data) and evaluate its performance on two benchmark\nsets, finding superior performance over state-of-the-art LLMs. The source code\nis available on GitHub, demonstration videos are also available, and the system\nis deployed on HuggingFace and will be available on the cloud.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3acmbagent\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u79d1\u5b66\u7814\u7a76\u4efb\u52a1\uff0c\u7531\u7ea630\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u667a\u80fd\u4f53\u7ec4\u6210\uff0c\u91c7\u7528\u89c4\u5212\u4e0e\u63a7\u5236\u7b56\u7565\u534f\u8c03\u5de5\u4f5c\u6d41\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b9e\u73b0\u79d1\u5b66\u7814\u7a76\u4efb\u52a1\u7684\u81ea\u52a8\u5316\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\uff0c\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u7cfb\u7edf\u7531\u591a\u4e2a\u4e13\u95e8\u5316\u667a\u80fd\u4f53\u7ec4\u6210\uff0c\u5206\u522b\u6267\u884c\u68c0\u7d22\u3001\u7f16\u7801\u3001\u7ed3\u679c\u89e3\u91ca\u548c\u8f93\u51fa\u8bc4\u5ba1\u7b49\u4efb\u52a1\uff0c\u5e76\u80fd\u672c\u5730\u6267\u884c\u4ee3\u7801\u3002\u91c7\u7528\u89c4\u5212\u4e0e\u63a7\u5236\u7b56\u7565\u534f\u8c03\u5de5\u4f5c\u6d41\u3002", "result": "\u6210\u529f\u5e94\u7528\u4e8e\u535a\u58eb\u7ea7\u522b\u7684\u5b87\u5b99\u5b66\u4efb\u52a1\uff08\u5229\u7528\u8d85\u65b0\u661f\u6570\u636e\u6d4b\u91cf\u5b87\u5b99\u5b66\u53c2\u6570\uff09\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684LLM\u3002", "conclusion": "cmbagent\u5c55\u793a\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u79d1\u5b66\u7814\u7a76\u81ea\u52a8\u5316\u4e2d\u7684\u6f5c\u529b\uff0c\u4ee3\u7801\u548c\u6f14\u793a\u5df2\u516c\u5f00\uff0c\u672a\u6765\u5c06\u90e8\u7f72\u5230\u4e91\u7aef\u3002"}}
{"id": "2507.07401", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07401", "abs": "https://arxiv.org/abs/2507.07401", "authors": ["Fupei Chen", "Liyao Xiang", "Haoxiang Sun", "Hei Victor Cheng", "Kaiming Shen"], "title": "Shuffling for Semantic Secrecy", "comment": null, "summary": "Deep learning draws heavily on the latest progress in semantic\ncommunications. The present paper aims to examine the security aspect of this\ncutting-edge technique from a novel shuffling perspective. Our goal is to\nimprove upon the conventional secure coding scheme to strike a desirable\ntradeoff between transmission rate and leakage rate. To be more specific, for a\nwiretap channel, we seek to maximize the transmission rate while minimizing the\nsemantic error probability under the given leakage rate constraint. Toward this\nend, we devise a novel semantic security communication system wherein the\nrandom shuffling pattern plays the role of the shared secret key. Intuitively,\nthe permutation of feature sequences via shuffling would distort the semantic\nessence of the target data to a sufficient extent so that eavesdroppers cannot\naccess it anymore. The proposed random shuffling method also exhibits its\nflexibility in working for the existing semantic communication system as a\nplugin. Simulations demonstrate the significant advantage of the proposed\nmethod over the benchmark in boosting secure transmission, especially when\nchannels are prone to strong noise and unpredictable fading.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u6253\u4e71\u7279\u5f81\u7684\u8bed\u4e49\u5b89\u5168\u901a\u4fe1\u7cfb\u7edf\uff0c\u65e8\u5728\u5e73\u8861\u4f20\u8f93\u901f\u7387\u4e0e\u6cc4\u6f0f\u7387\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u5176\u5728\u5f3a\u566a\u58f0\u548c\u8870\u843d\u4fe1\u9053\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u7814\u7a76\u6df1\u5ea6\u5b66\u4e60\u5728\u8bed\u4e49\u901a\u4fe1\u4e2d\u7684\u5b89\u5168\u6027\u95ee\u9898\uff0c\u6539\u8fdb\u4f20\u7edf\u5b89\u5168\u7f16\u7801\u65b9\u6848\uff0c\u4ee5\u5728\u7ed9\u5b9a\u6cc4\u6f0f\u7387\u7ea6\u675f\u4e0b\u6700\u5927\u5316\u4f20\u8f93\u901f\u7387\u5e76\u6700\u5c0f\u5316\u8bed\u4e49\u9519\u8bef\u6982\u7387\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u968f\u673a\u6253\u4e71\u7279\u5f81\u7684\u8bed\u4e49\u5b89\u5168\u901a\u4fe1\u7cfb\u7edf\uff0c\u5c06\u6253\u4e71\u6a21\u5f0f\u4f5c\u4e3a\u5171\u4eab\u5bc6\u94a5\uff0c\u901a\u8fc7\u7279\u5f81\u5e8f\u5217\u7684\u6392\u5217\u626d\u66f2\u8bed\u4e49\u4fe1\u606f\u4ee5\u9632\u6b62\u7a83\u542c\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5f3a\u566a\u58f0\u548c\u4e0d\u53ef\u9884\u6d4b\u8870\u843d\u4fe1\u9053\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u4f20\u8f93\u6027\u80fd\u3002", "conclusion": "\u968f\u673a\u6253\u4e71\u7279\u5f81\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u8bed\u4e49\u901a\u4fe1\u7684\u5b89\u5168\u6027\uff0c\u4e14\u53ef\u4f5c\u4e3a\u63d2\u4ef6\u517c\u5bb9\u73b0\u6709\u7cfb\u7edf\u3002"}}
{"id": "2507.07302", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07302", "abs": "https://arxiv.org/abs/2507.07302", "authors": ["Ashish Kumar"], "title": "Application of LLMs to Multi-Robot Path Planning and Task Allocation", "comment": null, "summary": "Efficient exploration is a well known problem in deep reinforcement learning\nand this problem is exacerbated in multi-agent reinforcement learning due the\nintrinsic complexities of such algorithms. There are several approaches to\nefficiently explore an environment to learn to solve tasks by multi-agent\noperating in that environment, of which, the idea of expert exploration is\ninvestigated in this work. More specifically, this work investigates the\napplication of large-language models as expert planners for efficient\nexploration in planning based tasks for multiple agents.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e13\u5bb6\u89c4\u5212\u5668\u4ee5\u5b9e\u73b0\u9ad8\u6548\u63a2\u7d22\u7684\u65b9\u6cd5\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u9ad8\u6548\u63a2\u7d22\u95ee\u9898\u590d\u6742\u4e14\u5177\u6709\u6311\u6218\u6027\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4e13\u5bb6\u63a2\u7d22\u65b9\u6cd5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e13\u5bb6\u89c4\u5212\u5668\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u9ad8\u6548\u63a2\u7d22\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u63a2\u7d22\u6548\u7387\u3002", "conclusion": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e13\u5bb6\u89c4\u5212\u5668\u662f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u9ad8\u6548\u63a2\u7d22\u7684\u4e00\u79cd\u53ef\u884c\u65b9\u6cd5\u3002"}}
{"id": "2507.07406", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07406", "abs": "https://arxiv.org/abs/2507.07406", "authors": ["Jikesh Thapa", "Gurrehmat Chahal", "Serban Voinea Gabreanu", "Yazan Otoum"], "title": "Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models", "comment": "8 Pages, IEEE Conference", "summary": "Phishing attacks are becoming increasingly sophisticated, underscoring the\nneed for detection systems that strike a balance between high accuracy and\ncomputational efficiency. This paper presents a comparative evaluation of\ntraditional Machine Learning (ML), Deep Learning (DL), and quantized\nsmall-parameter Large Language Models (LLMs) for phishing detection. Through\nexperiments on a curated dataset, we show that while LLMs currently\nunderperform compared to ML and DL methods in terms of raw accuracy, they\nexhibit strong potential for identifying subtle, context-based phishing cues.\nWe also investigate the impact of zero-shot and few-shot prompting strategies,\nrevealing that LLM-rephrased emails can significantly degrade the performance\nof both ML and LLM-based detectors. Our benchmarking highlights that models\nlike DeepSeek R1 Distill Qwen 14B (Q8_0) achieve competitive accuracy, above\n80%, using only 17GB of VRAM, supporting their viability for cost-efficient\ndeployment. We further assess the models' adversarial robustness and\ncost-performance tradeoffs, and demonstrate how lightweight LLMs can provide\nconcise, interpretable explanations to support real-time decision-making. These\nfindings position optimized LLMs as promising components in phishing defence\nsystems and offer a path forward for integrating explainable, efficient AI into\nmodern cybersecurity frameworks.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4f20\u7edf\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u3001\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09\u548c\u91cf\u5316\u5c0f\u53c2\u6570\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9493\u9c7c\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0LLMs\u5728\u8bc6\u522b\u4e0a\u4e0b\u6587\u9493\u9c7c\u7ebf\u7d22\u65b9\u9762\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5f53\u524d\u51c6\u786e\u6027\u7565\u4f4e\u3002", "motivation": "\u9493\u9c7c\u653b\u51fb\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83ML\u3001DL\u548c\u91cf\u5316LLMs\u7684\u6027\u80fd\uff0c\u5e76\u7814\u7a76\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\u7684\u5f71\u54cd\u3002", "result": "LLMs\u5728\u8bc6\u522b\u4e0a\u4e0b\u6587\u9493\u9c7c\u7ebf\u7d22\u65b9\u9762\u8868\u73b0\u6f5c\u529b\uff0c\u4f46\u51c6\u786e\u6027\u4f4e\u4e8eML\u548cDL\u3002\u4f18\u5316\u540e\u7684LLMs\uff08\u5982DeepSeek R1\uff09\u572817GB VRAM\u4e0b\u8fbe\u523080%\u4ee5\u4e0a\u51c6\u786e\u7387\u3002", "conclusion": "\u4f18\u5316\u7684LLMs\u6709\u671b\u6210\u4e3a\u9493\u9c7c\u9632\u5fa1\u7cfb\u7edf\u7684\u7ec4\u6210\u90e8\u5206\uff0c\u4e3a\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684AI\u96c6\u6210\u63d0\u4f9b\u8def\u5f84\u3002"}}
{"id": "2507.07306", "categories": ["cs.AI", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.07306", "abs": "https://arxiv.org/abs/2507.07306", "authors": ["Yichen Lu", "Wei Dai", "Jiaen Liu", "Ching Wing Kwok", "Zongheng Wu", "Xudong Xiao", "Ao Sun", "Sheng Fu", "Jianyuan Zhan", "Yian Wang", "Takatomo Saito", "Sicheng Lai"], "title": "ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning", "comment": null, "summary": "LLM-based translation agents have achieved highly human-like translation\nresults and are capable of handling longer and more complex contexts with\ngreater efficiency. However, they are typically limited to text-only inputs. In\nthis paper, we introduce ViDove, a translation agent system designed for\nmultimodal input. Inspired by the workflow of human translators, ViDove\nleverages visual and contextual background information to enhance the\ntranslation process. Additionally, we integrate a multimodal memory system and\nlong-short term memory modules enriched with domain-specific knowledge,\nenabling the agent to perform more accurately and adaptively in real-world\nscenarios. As a result, ViDove achieves significantly higher translation\nquality in both subtitle generation and general translation tasks, with a 28%\nimprovement in BLEU scores and a 15% improvement in SubER compared to previous\nstate-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark\nfor long-form automatic video subtitling and translation, featuring 17 hours of\nhigh-quality, human-annotated data. Our code is available here:\nhttps://github.com/pigeonai-org/ViDove", "AI": {"tldr": "ViDove\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001\u8f93\u5165\u7684\u7ffb\u8bd1\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u548c\u4e0a\u4e0b\u6587\u80cc\u666f\u4fe1\u606f\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709LLM\u7ffb\u8bd1\u4ee3\u7406\u901a\u5e38\u4ec5\u652f\u6301\u6587\u672c\u8f93\u5165\uff0c\u9650\u5236\u4e86\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002ViDove\u65e8\u5728\u901a\u8fc7\u591a\u6a21\u6001\u8f93\u5165\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "ViDove\u6a21\u4eff\u4eba\u7c7b\u7ffb\u8bd1\u6d41\u7a0b\uff0c\u6574\u5408\u591a\u6a21\u6001\u8bb0\u5fc6\u7cfb\u7edf\u548c\u957f\u77ed\u65f6\u8bb0\u5fc6\u6a21\u5757\uff0c\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u63d0\u5347\u7ffb\u8bd1\u6027\u80fd\u3002", "result": "ViDove\u5728\u5b57\u5e55\u751f\u6210\u548c\u901a\u7528\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cBLEU\u5206\u6570\u63d0\u534728%\uff0cSubER\u63d0\u534715%\u3002", "conclusion": "ViDove\u901a\u8fc7\u591a\u6a21\u6001\u8f93\u5165\u663e\u8457\u63d0\u5347\u4e86\u7ffb\u8bd1\u8d28\u91cf\uff0c\u5e76\u63a8\u51fa\u4e86\u65b0\u7684\u8bc4\u6d4b\u57fa\u51c6DoveBench\u3002"}}
{"id": "2507.07413", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07413", "abs": "https://arxiv.org/abs/2507.07413", "authors": ["Mohammad F. Al-Hammouri", "Yazan Otoum", "Rasha Atwa", "Amiya Nayak"], "title": "Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks", "comment": "6 pages, IEEE conference", "summary": "This paper presents a novel approach to intrusion detection by integrating\ntraditional signature-based methods with the contextual understanding\ncapabilities of the GPT-2 Large Language Model (LLM). As cyber threats become\nincreasingly sophisticated, particularly in distributed, heterogeneous, and\nresource-constrained environments such as those enabled by the Internet of\nThings (IoT), the need for dynamic and adaptive Intrusion Detection Systems\n(IDSs) becomes increasingly urgent. While traditional methods remain effective\nfor detecting known threats, they often fail to recognize new and evolving\nattack patterns. In contrast, GPT-2 excels at processing unstructured data and\nidentifying complex semantic relationships, making it well-suited to uncovering\nsubtle, zero-day attack vectors. We propose a hybrid IDS framework that merges\nthe robustness of signature-based techniques with the adaptability of\nGPT-2-driven semantic analysis. Experimental evaluations on a representative\nintrusion dataset demonstrate that our model enhances detection accuracy by\n6.3%, reduces false positives by 9.0%, and maintains near real-time\nresponsiveness. These results affirm the potential of language model\nintegration to build intelligent, scalable, and resilient cybersecurity\ndefences suited for modern connected environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4f20\u7edf\u7b7e\u540d\u65b9\u6cd5\u548cGPT-2\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u578b\u5165\u4fb5\u68c0\u6d4b\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u7cbe\u5ea6\u5e76\u51cf\u5c11\u4e86\u8bef\u62a5\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u5a01\u80c1\u65e5\u76ca\u590d\u6742\uff0c\u5c24\u5176\u662f\u5728\u7269\u8054\u7f51\u7b49\u5206\u5e03\u5f0f\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u65b0\u578b\u653b\u51fb\u6a21\u5f0f\uff0c\u9700\u8981\u52a8\u6001\u81ea\u9002\u5e94\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6846\u67b6\uff0c\u5c06\u7b7e\u540d\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u4e0eGPT-2\u9a71\u52a8\u7684\u8bed\u4e49\u5206\u6790\u76f8\u7ed3\u5408\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u68c0\u6d4b\u7cbe\u5ea6\u63d0\u9ad8\u4e866.3%\uff0c\u8bef\u62a5\u7387\u964d\u4f4e\u4e869.0%\uff0c\u5e76\u4fdd\u6301\u4e86\u8fd1\u5b9e\u65f6\u7684\u54cd\u5e94\u901f\u5ea6\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5728\u6784\u5efa\u667a\u80fd\u3001\u53ef\u6269\u5c55\u548c\u5f39\u6027\u7684\u7f51\u7edc\u5b89\u5168\u9632\u5fa1\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2507.07341", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07341", "abs": "https://arxiv.org/abs/2507.07341", "authors": ["Sarah Ball", "Greg Gluch", "Shafi Goldwasser", "Frauke Kreuter", "Omer Reingold", "Guy N. Rothblum"], "title": "On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment", "comment": null, "summary": "With the increased deployment of large language models (LLMs), one concern is\ntheir potential misuse for generating harmful content. Our work studies the\nalignment challenge, with a focus on filters to prevent the generation of\nunsafe information. Two natural points of intervention are the filtering of the\ninput prompt before it reaches the model, and filtering the output after\ngeneration. Our main results demonstrate computational challenges in filtering\nboth prompts and outputs. First, we show that there exist LLMs for which there\nare no efficient prompt filters: adversarial prompts that elicit harmful\nbehavior can be easily constructed, which are computationally indistinguishable\nfrom benign prompts for any efficient filter. Our second main result identifies\na natural setting in which output filtering is computationally intractable. All\nof our separation results are under cryptographic hardness assumptions. In\naddition to these core findings, we also formalize and study relaxed mitigation\napproaches, demonstrating further computational barriers. We conclude that\nsafety cannot be achieved by designing filters external to the LLM internals\n(architecture and weights); in particular, black-box access to the LLM will not\nsuffice. Based on our technical results, we argue that an aligned AI system's\nintelligence cannot be separated from its judgment.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u7684\u8fc7\u6ee4\u95ee\u9898\uff0c\u53d1\u73b0\u8f93\u5165\u548c\u8f93\u51fa\u8fc7\u6ee4\u5747\u5b58\u5728\u8ba1\u7b97\u6311\u6218\uff0c\u5e76\u6307\u51fa\u5916\u90e8\u8fc7\u6ee4\u5668\u65e0\u6cd5\u5b9e\u73b0\u5b89\u5168\u76ee\u6807\u3002", "motivation": "\u968f\u7740LLMs\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9632\u6b62\u5176\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u6210\u4e3a\u91cd\u8981\u95ee\u9898\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u8fc7\u6ee4\u65b9\u6cd5\u7684\u6709\u6548\u6027\u53ca\u5176\u8ba1\u7b97\u9650\u5236\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u7814\u7a76\u8f93\u5165\u63d0\u793a\u548c\u8f93\u51fa\u8fc7\u6ee4\u7684\u8ba1\u7b97\u53ef\u884c\u6027\uff0c\u5e76\u57fa\u4e8e\u5bc6\u7801\u5b66\u5047\u8bbe\u8bc1\u660e\u5176\u5c40\u9650\u6027\u3002", "result": "\u53d1\u73b0\u9ad8\u6548\u8fc7\u6ee4\u8f93\u5165\u63d0\u793a\u548c\u8f93\u51fa\u5728\u8ba1\u7b97\u4e0a\u4e0d\u53ef\u884c\uff0c\u4e14\u5916\u90e8\u8fc7\u6ee4\u5668\u65e0\u6cd5\u5b8c\u5168\u89e3\u51b3\u5b89\u5168\u95ee\u9898\u3002", "conclusion": "\u5b89\u5168\u9700\u4f9d\u8d56LLM\u5185\u90e8\u8bbe\u8ba1\uff0c\u800c\u975e\u5916\u90e8\u8fc7\u6ee4\u5668\uff0c\u667a\u80fd\u4e0e\u5224\u65ad\u4e0d\u53ef\u5206\u5272\u3002"}}
{"id": "2507.07416", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07416", "abs": "https://arxiv.org/abs/2507.07416", "authors": ["Jenifer Paulraj", "Brindha Raghuraman", "Nagarani Gopalakrishnan", "Yazan Otoum"], "title": "Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation", "comment": "7 pages, IEEE conference", "summary": "Critical infrastructure systems, including energy grids, healthcare\nfacilities, transportation networks, and water distribution systems, are\npivotal to societal stability and economic resilience. However, the increasing\ninterconnectivity of these systems exposes them to various cyber threats,\nincluding ransomware, Denial-of-Service (DoS) attacks, and Advanced Persistent\nThreats (APTs). This paper examines cybersecurity vulnerabilities in critical\ninfrastructure, highlighting the threat landscape, attack vectors, and the role\nof Artificial Intelligence (AI) in mitigating these risks. We propose a hybrid\nAI-driven cybersecurity framework to enhance real-time vulnerability detection,\nthreat modelling, and automated remediation. This study also addresses the\ncomplexities of adversarial AI, regulatory compliance, and integration. Our\nfindings provide actionable insights to strengthen the security and resilience\nof critical infrastructure systems against emerging cyber threats.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408AI\u9a71\u52a8\u7684\u7f51\u7edc\u5b89\u5168\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u5b9e\u65f6\u6f0f\u6d1e\u68c0\u6d4b\u3001\u5a01\u80c1\u5efa\u6a21\u548c\u81ea\u52a8\u4fee\u590d\u80fd\u529b\u3002", "motivation": "\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7cfb\u7edf\u5bf9\u793e\u4f1a\u7a33\u5b9a\u548c\u7ecf\u6d4e\u97e7\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u65e5\u76ca\u589e\u957f\u7684\u4e92\u8054\u6027\u4f7f\u5176\u9762\u4e34\u591a\u79cd\u7f51\u7edc\u5a01\u80c1\uff0c\u5982\u52d2\u7d22\u8f6f\u4ef6\u3001DoS\u653b\u51fb\u548cAPT\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86\u7f51\u7edc\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408AI\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5b9e\u65f6\u68c0\u6d4b\u3001\u5a01\u80c1\u5efa\u6a21\u548c\u81ea\u52a8\u4fee\u590d\u529f\u80fd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u4e3a\u63d0\u5347\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u5b89\u5168\u6027\u548c\u97e7\u6027\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89c1\u89e3\uff0c\u540c\u65f6\u89e3\u51b3\u4e86\u5bf9\u6297\u6027AI\u3001\u6cd5\u89c4\u5408\u89c4\u6027\u548c\u96c6\u6210\u590d\u6742\u6027\u7b49\u95ee\u9898\u3002", "conclusion": "\u8bba\u6587\u7684\u7ed3\u8bba\u5f3a\u8c03\u4e86AI\u5728\u589e\u5f3a\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u548c\u5b9e\u8df5\u7684\u65b9\u5411\u3002"}}
{"id": "2507.07355", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07355", "abs": "https://arxiv.org/abs/2507.07355", "authors": ["Haoyue Bai", "Haoyu Wang", "Nanxu Gong", "Xinyuan Wang", "Wangyang Ying", "Haifeng Chen", "Yanjie Fu"], "title": "Supply Chain Optimization via Generative Simulation and Iterative Decision Policies", "comment": null, "summary": "High responsiveness and economic efficiency are critical objectives in supply\nchain transportation, both of which are influenced by strategic decisions on\nshipping mode. An integrated framework combining an efficient simulator with an\nintelligent decision-making algorithm can provide an observable, low-risk\nenvironment for transportation strategy design. An ideal simulation-decision\nframework must (1) generalize effectively across various settings, (2) reflect\nfine-grained transportation dynamics, (3) integrate historical experience with\npredictive insights, and (4) maintain tight integration between simulation\nfeedback and policy refinement. We propose Sim-to-Dec framework to satisfy\nthese requirements. Specifically, Sim-to-Dec consists of a generative\nsimulation module, which leverages autoregressive modeling to simulate\ncontinuous state changes, reducing dependence on handcrafted domain-specific\nrules and enhancing robustness against data fluctuations; and a history-future\ndual-aware decision model, refined iteratively through end-to-end optimization\nwith simulator interactions. Extensive experiments conducted on three\nreal-world datasets demonstrate that Sim-to-Dec significantly improves timely\ndelivery rates and profit.", "AI": {"tldr": "Sim-to-Dec\u6846\u67b6\u7ed3\u5408\u751f\u6210\u6a21\u62df\u548c\u667a\u80fd\u51b3\u7b56\uff0c\u663e\u8457\u63d0\u5347\u4f9b\u5e94\u94fe\u8fd0\u8f93\u7684\u53ca\u65f6\u4ea4\u4ed8\u7387\u548c\u5229\u6da6\u3002", "motivation": "\u4f9b\u5e94\u94fe\u8fd0\u8f93\u7684\u9ad8\u54cd\u5e94\u6027\u548c\u7ecf\u6d4e\u6548\u7387\u662f\u5173\u952e\u76ee\u6807\uff0c\u53d7\u8fd0\u8f93\u6a21\u5f0f\u6218\u7565\u51b3\u7b56\u5f71\u54cd\u3002\u9700\u8981\u4e00\u4e2a\u96c6\u6210\u6846\u67b6\u6765\u4f18\u5316\u7b56\u7565\u8bbe\u8ba1\u3002", "method": "\u63d0\u51faSim-to-Dec\u6846\u67b6\uff0c\u5305\u542b\u751f\u6210\u6a21\u62df\u6a21\u5757\uff08\u81ea\u56de\u5f52\u5efa\u6a21\uff09\u548c\u53cc\u611f\u77e5\u51b3\u7b56\u6a21\u578b\uff08\u5386\u53f2\u4e0e\u672a\u6765\u6570\u636e\u7ed3\u5408\uff09\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u4f18\u5316\u8fed\u4ee3\u6539\u8fdb\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSim-to-Dec\u663e\u8457\u63d0\u9ad8\u4e86\u53ca\u65f6\u4ea4\u4ed8\u7387\u548c\u5229\u6da6\u3002", "conclusion": "Sim-to-Dec\u6ee1\u8db3\u8de8\u573a\u666f\u901a\u7528\u6027\u3001\u7ec6\u7c92\u5ea6\u52a8\u6001\u6a21\u62df\u3001\u5386\u53f2\u4e0e\u9884\u6d4b\u7ed3\u5408\u7684\u9700\u6c42\uff0c\u662f\u4f9b\u5e94\u94fe\u8fd0\u8f93\u7b56\u7565\u8bbe\u8ba1\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.07417", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.07417", "abs": "https://arxiv.org/abs/2507.07417", "authors": ["Nishit V. Pandya", "Andrey Labunets", "Sicun Gao", "Earlence Fernandes"], "title": "May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks", "comment": null, "summary": "A popular class of defenses against prompt injection attacks on large\nlanguage models (LLMs) relies on fine-tuning the model to separate instructions\nand data, so that the LLM does not follow instructions that might be present\nwith data. There are several academic systems and production-level\nimplementations of this idea. We evaluate the robustness of this class of\nprompt injection defenses in the whitebox setting by constructing strong\noptimization-based attacks and showing that the defenses do not provide the\nclaimed security properties. Specifically, we construct a novel attention-based\nattack algorithm for text-based LLMs and apply it to two recent whitebox\ndefenses SecAlign (CCS 2025) and StruQ (USENIX Security 2025), showing attacks\nwith success rates of up to 70% with modest increase in attacker budget in\nterms of tokens. Our findings make fundamental progress towards understanding\nthe robustness of prompt injection defenses in the whitebox setting. We release\nour code and attacks at https://github.com/nishitvp/better_opts_attacks", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5fae\u8c03\u7684\u8bed\u8a00\u6a21\u578b\u9632\u5fa1\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u6ce8\u610f\u529b\u653b\u51fb\u7b97\u6cd5\uff0c\u6210\u529f\u653b\u7834\u4e24\u79cd\u9632\u5fa1\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u73b0\u6709\u63d0\u793a\u6ce8\u5165\u9632\u5fa1\u65b9\u6cd5\u7684\u5b9e\u9645\u5b89\u5168\u6027\uff0c\u63ed\u793a\u5176\u6f5c\u5728\u6f0f\u6d1e\u3002", "method": "\u6784\u5efa\u4f18\u5316\u653b\u51fb\u7b97\u6cd5\uff0c\u9488\u5bf9SecAlign\u548cStruQ\u4e24\u79cd\u9632\u5fa1\u8fdb\u884c\u767d\u76d2\u653b\u51fb\u6d4b\u8bd5\u3002", "result": "\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe70%\uff0c\u4e14\u653b\u51fb\u6210\u672c\u4ec5\u9700\u9002\u5ea6\u589e\u52a0\u4ee4\u724c\u6570\u3002", "conclusion": "\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5728\u5bf9\u6297\u4f18\u5316\u653b\u51fb\u65f6\u8868\u73b0\u4e0d\u8db3\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u5b89\u5168\u6027\u3002"}}
{"id": "2507.07426", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07426", "abs": "https://arxiv.org/abs/2507.07426", "authors": ["Zerui Yang", "Yuwei Wan", "Yinqiao Li", "Yudai Matsuda", "Tong Xie", "Linqi Song"], "title": "DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search", "comment": null, "summary": "Recent advances in large language models have demonstrated considerable\npotential in scientific domains such as drug discovery. However, their\neffectiveness remains constrained when reasoning extends beyond the knowledge\nacquired during pretraining. Conventional approaches, such as fine-tuning or\nretrieval-augmented generation, face limitations in either imposing high\ncomputational overhead or failing to fully exploit structured scientific data.\nTo overcome these challenges, we propose DrugMCTS, a novel framework that\nsynergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree\nSearch for drug repurposing. The framework employs five specialized agents\ntasked with retrieving and analyzing molecular and protein information, thereby\nenabling structured and iterative reasoning. Without requiring domain-specific\nfine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by\nover 20\\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate\nthat DrugMCTS achieves substantially higher recall and robustness compared to\nboth general-purpose LLMs and deep learning baselines. Our results highlight\nthe importance of structured reasoning, agent-based collaboration, and\nfeedback-driven search mechanisms in advancing LLM applications for drug\ndiscovery.", "AI": {"tldr": "DrugMCTS\u6846\u67b6\u7ed3\u5408RAG\u3001\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u663e\u8457\u63d0\u5347\u836f\u7269\u91cd\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u65e0\u9700\u9886\u57df\u5fae\u8c03\u5373\u53ef\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u9886\u57df\uff08\u5982\u836f\u7269\u53d1\u73b0\uff09\u4e2d\u63a8\u7406\u80fd\u529b\u53d7\u9650\u7684\u95ee\u9898\uff0c\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u6216\u6570\u636e\u5229\u7528\u4e0d\u8db3\u7684\u7f3a\u70b9\u3002", "method": "\u63d0\u51faDrugMCTS\u6846\u67b6\uff0c\u6574\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u3001\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u901a\u8fc7\u4e94\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\u5b9e\u73b0\u7ed3\u6784\u5316\u8fed\u4ee3\u63a8\u7406\u3002", "result": "\u5728DrugBank\u548cKIBA\u6570\u636e\u96c6\u4e0a\uff0cDrugMCTS\u7684\u53ec\u56de\u7387\u548c\u9c81\u68d2\u6027\u663e\u8457\u4f18\u4e8e\u901a\u7528LLM\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\uff0c\u6027\u80fd\u63d0\u5347\u8d85\u8fc720%\u3002", "conclusion": "\u7ed3\u6784\u5316\u63a8\u7406\u3001\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u53cd\u9988\u9a71\u52a8\u641c\u7d22\u673a\u5236\u5bf9\u63d0\u5347\u836f\u7269\u53d1\u73b0\u4e2d\u7684LLM\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.07732", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07732", "abs": "https://arxiv.org/abs/2507.07732", "authors": ["Giovanni Gambigliani Zoccoli", "Filip Valgimigli", "Dario Stabili", "Mirco Marchetti"], "title": "RADAR: a Radio-based Analytics for Dynamic Association and Recognition of pseudonyms in VANETs", "comment": "7 pages, 4 figures, accepted for publication at the 2025 IEEE 102nd\n  Vehicular Technology Conference: VTC2025-Fall", "summary": "This paper presents RADAR, a tracking algorithm for vehicles participating in\nCooperative Intelligent Transportation Systems (C-ITS) that exploits multiple\nradio signals emitted by a modern vehicle to break privacy-preserving pseudonym\nschemes deployed in VANETs. This study shows that by combining Dedicated Short\nRange Communication (DSRC) and Wi-Fi probe request messages broadcast by the\nvehicle, it is possible to improve tracking over standard de-anonymization\napproaches that only leverage DSRC, especially in realistic scenarios where the\nattacker does not have full coverage of the entire vehicle path. The\nexperimental evaluation compares three different metrics for pseudonym and\nWi-Fi probe identifier association (Count, Statistical RSSI, and Pearson RSSI),\ndemonstrating that the Pearson RSSI metric is better at tracking vehicles under\npseudonym-changing schemes in all scenarios and against previous works. As an\nadditional contribution to the state-of-the-art, we publicly release all\nimplementations and simulation scenarios used in this work.", "AI": {"tldr": "RADAR\u7b97\u6cd5\u901a\u8fc7\u7ed3\u5408DSRC\u548cWi-Fi\u4fe1\u53f7\uff0c\u63d0\u5347\u4e86\u5bf9VANETs\u4e2d\u9690\u79c1\u4fdd\u62a4\u5047\u540d\u65b9\u6848\u7684\u8ffd\u8e2a\u80fd\u529b\uff0cPearson RSSI\u6307\u6807\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u6253\u7834VANETs\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u5047\u540d\u65b9\u6848\uff0c\u63d0\u5347\u8f66\u8f86\u8ffd\u8e2a\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u653b\u51fb\u8005\u65e0\u6cd5\u5b8c\u5168\u8986\u76d6\u8f66\u8f86\u8def\u5f84\u7684\u73b0\u5b9e\u573a\u666f\u4e2d\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u7ed3\u5408DSRC\u548cWi-Fi\u63a2\u9488\u8bf7\u6c42\u4fe1\u53f7\uff0c\u4f7f\u7528\u4e09\u79cd\u6307\u6807\uff08Count\u3001Statistical RSSI\u548cPearson RSSI\uff09\u5173\u8054\u5047\u540d\u548cWi-Fi\u6807\u8bc6\u7b26\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPearson RSSI\u6307\u6807\u5728\u6240\u6709\u573a\u666f\u4e0b\u5bf9\u5047\u540d\u66f4\u6362\u65b9\u6848\u7684\u8ffd\u8e2a\u6548\u679c\u6700\u4f73\u3002", "conclusion": "\u7ed3\u8bba\u662fRADAR\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8ffd\u8e2a\u80fd\u529b\uff0c\u5e76\u516c\u5f00\u4e86\u6240\u6709\u5b9e\u73b0\u548c\u4eff\u771f\u573a\u666f\u3002"}}
{"id": "2507.07445", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07445", "abs": "https://arxiv.org/abs/2507.07445", "authors": ["Weihao Tan", "Changjiu Jiang", "Yu Duan", "Mingcong Lei", "Jiageng Li", "Yitian Hong", "Xinrun Wang", "Bo An"], "title": "StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley", "comment": "Project website: https://weihaotan.github.io/StarDojo", "summary": "Autonomous agents navigating human society must master both production\nactivities and social interactions, yet existing benchmarks rarely evaluate\nthese skills simultaneously. To bridge this gap, we introduce StarDojo, a novel\nbenchmark based on Stardew Valley, designed to assess AI agents in open-ended\nproduction-living simulations. In StarDojo, agents are tasked to perform\nessential livelihood activities such as farming and crafting, while\nsimultaneously engaging in social interactions to establish relationships\nwithin a vibrant community. StarDojo features 1,000 meticulously curated tasks\nacross five key domains: farming, crafting, exploration, combat, and social\ninteractions. Additionally, we provide a compact subset of 100 representative\ntasks for efficient model evaluation. The benchmark offers a unified,\nuser-friendly interface that eliminates the need for keyboard and mouse\ncontrol, supports all major operating systems, and enables the parallel\nexecution of multiple environment instances, making it particularly well-suited\nfor evaluating the most capable foundation agents, powered by multimodal large\nlanguage models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents\ndemonstrate substantial limitations, with the best-performing model, GPT-4.1,\nachieving only a 12.7% success rate, primarily due to challenges in visual\nunderstanding, multimodal reasoning and low-level manipulation. As a\nuser-friendly environment and benchmark, StarDojo aims to facilitate further\nresearch towards robust, open-ended agents in complex production-living\nenvironments.", "AI": {"tldr": "StarDojo\u662f\u4e00\u4e2a\u57fa\u4e8eStardew Valley\u7684\u65b0\u578b\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u4ee3\u7406\u5728\u5f00\u653e\u5f0f\u751f\u4ea7\u751f\u6d3b\u6a21\u62df\u4e2d\u7684\u8868\u73b0\uff0c\u6db5\u76d6\u519c\u4e1a\u3001\u624b\u5de5\u827a\u3001\u63a2\u7d22\u3001\u6218\u6597\u548c\u793e\u4ea4\u4e92\u52a8\u4e94\u5927\u9886\u57df\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5f88\u5c11\u540c\u65f6\u8bc4\u4f30\u751f\u4ea7\u6d3b\u52a8\u548c\u793e\u4f1a\u4e92\u52a8\u80fd\u529b\uff0cStarDojo\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "StarDojo\u5305\u542b1,000\u4e2a\u4efb\u52a1\uff0c\u5206\u4e3a\u4e94\u5927\u9886\u57df\uff0c\u5e76\u63d0\u4f9b100\u4e2a\u4ee3\u8868\u6027\u4efb\u52a1\u5b50\u96c6\u3002\u5b83\u63d0\u4f9b\u7edf\u4e00\u3001\u7528\u6237\u53cb\u597d\u7684\u754c\u9762\uff0c\u652f\u6301\u591a\u64cd\u4f5c\u7cfb\u7edf\u548c\u5e76\u884c\u73af\u5883\u5b9e\u4f8b\u3002", "result": "\u73b0\u6709\u6700\u5148\u8fdb\u7684MLLM\u4ee3\u7406\u8868\u73b0\u6709\u9650\uff0c\u6700\u4f73\u6a21\u578bGPT-4.1\u7684\u6210\u529f\u7387\u4ec5\u4e3a12.7%\uff0c\u4e3b\u8981\u56e0\u89c6\u89c9\u7406\u89e3\u3001\u591a\u6a21\u6001\u63a8\u7406\u548c\u4f4e\u7ea7\u64cd\u4f5c\u6311\u6218\u3002", "conclusion": "StarDojo\u65e8\u5728\u4fc3\u8fdb\u590d\u6742\u751f\u4ea7\u751f\u6d3b\u73af\u5883\u4e2d\u7a33\u5065\u5f00\u653e\u5f0f\u4ee3\u7406\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.07773", "categories": ["cs.CR", "cs.CV", "B.8; I.4"], "pdf": "https://arxiv.org/pdf/2507.07773", "abs": "https://arxiv.org/abs/2507.07773", "authors": ["Youqian Zhang", "Xinyu Ji", "Zhihao Wang", "Qinhong Jiang"], "title": "Rainbow Artifacts from Electromagnetic Signal Injection Attacks on Image Sensors", "comment": "5 pages, 4 figures", "summary": "Image sensors are integral to a wide range of safety- and security-critical\nsystems, including surveillance infrastructure, autonomous vehicles, and\nindustrial automation. These systems rely on the integrity of visual data to\nmake decisions. In this work, we investigate a novel class of electromagnetic\nsignal injection attacks that target the analog domain of image sensors,\nallowing adversaries to manipulate raw visual inputs without triggering\nconventional digital integrity checks. We uncover a previously undocumented\nattack phenomenon on CMOS image sensors: rainbow-like color artifacts induced\nin images captured by image sensors through carefully tuned electromagnetic\ninterference. We further evaluate the impact of these attacks on\nstate-of-the-art object detection models, showing that the injected artifacts\npropagate through the image signal processing pipeline and lead to significant\nmispredictions. Our findings highlight a critical and underexplored\nvulnerability in the visual perception stack, highlighting the need for more\nrobust defenses against physical-layer attacks in such systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u9488\u5bf9\u56fe\u50cf\u4f20\u611f\u5668\u6a21\u62df\u57df\u7684\u65b0\u578b\u7535\u78c1\u4fe1\u53f7\u6ce8\u5165\u653b\u51fb\uff0c\u63ed\u793a\u4e86CMOS\u56fe\u50cf\u4f20\u611f\u5668\u4e2d\u672a\u8bb0\u5f55\u7684\u5f69\u8679\u8272\u4f2a\u5f71\u73b0\u8c61\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u5bf9\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u5f71\u54cd\u3002", "motivation": "\u56fe\u50cf\u4f20\u611f\u5668\u5728\u5b89\u5168\u548c\u5b89\u9632\u5173\u952e\u7cfb\u7edf\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u89c6\u89c9\u6570\u636e\u7684\u5b8c\u6574\u6027\u53ef\u80fd\u53d7\u5230\u7535\u78c1\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u76ee\u524d\u7f3a\u4e4f\u9488\u5bf9\u6b64\u7c7b\u7269\u7406\u5c42\u653b\u51fb\u7684\u9632\u5fa1\u63aa\u65bd\u3002", "method": "\u901a\u8fc7\u7cbe\u5fc3\u8c03\u5236\u7684\u7535\u78c1\u5e72\u6270\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u5728\u56fe\u50cf\u4f20\u611f\u5668\u4e2d\u8bf1\u5bfc\u5f69\u8679\u8272\u4f2a\u5f71\uff0c\u5e76\u5206\u6790\u8fd9\u4e9b\u4f2a\u5f71\u5bf9\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u5f71\u54cd\u3002", "result": "\u653b\u51fb\u5bfc\u81f4\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u51fa\u73b0\u663e\u8457\u8bef\u5224\uff0c\u63ed\u793a\u4e86\u89c6\u89c9\u611f\u77e5\u7cfb\u7edf\u4e2d\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u6f0f\u6d1e\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u56fe\u50cf\u4f20\u611f\u5668\u7cfb\u7edf\u4e2d\u52a0\u5f3a\u7269\u7406\u5c42\u653b\u51fb\u9632\u5fa1\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2507.07544", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07544", "abs": "https://arxiv.org/abs/2507.07544", "authors": ["Oliver Eberle", "Thomas McGee", "Hamza Giaffar", "Taylor Webb", "Ida Momennejad"], "title": "Position: We Need An Algorithmic Understanding of Generative AI", "comment": "Accepted at ICML 2025 as a Spotlight Position Paper", "summary": "What algorithms do LLMs actually learn and use to solve problems? Studies\naddressing this question are sparse, as research priorities are focused on\nimproving performance through scale, leaving a theoretical and empirical gap in\nunderstanding emergent algorithms. This position paper proposes AlgEval: a\nframework for systematic research into the algorithms that LLMs learn and use.\nAlgEval aims to uncover algorithmic primitives, reflected in latent\nrepresentations, attention, and inference-time compute, and their algorithmic\ncomposition to solve task-specific problems. We highlight potential\nmethodological paths and a case study toward this goal, focusing on emergent\nsearch algorithms. Our case study illustrates both the formation of top-down\nhypotheses about candidate algorithms, and bottom-up tests of these hypotheses\nvia circuit-level analysis of attention patterns and hidden states. The\nrigorous, systematic evaluation of how LLMs actually solve tasks provides an\nalternative to resource-intensive scaling, reorienting the field toward a\nprincipled understanding of underlying computations. Such algorithmic\nexplanations offer a pathway to human-understandable interpretability, enabling\ncomprehension of the model's internal reasoning performance measures. This can\nin turn lead to more sample-efficient methods for training and improving\nperformance, as well as novel architectures for end-to-end and multi-agent\nsystems.", "AI": {"tldr": "AlgEval\u6846\u67b6\u65e8\u5728\u7cfb\u7edf\u7814\u7a76LLM\u5b66\u4e60\u7684\u7b97\u6cd5\uff0c\u63ed\u793a\u5176\u5e95\u5c42\u8ba1\u7b97\u539f\u7406\uff0c\u4e3a\u7406\u89e3\u6a21\u578b\u63a8\u7406\u63d0\u4f9b\u65b0\u9014\u5f84\u3002", "motivation": "\u586b\u8865\u5bf9LLM\u5b66\u4e60\u7b97\u6cd5\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u907f\u514d\u4ec5\u4f9d\u8d56\u89c4\u6a21\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51faAlgEval\u6846\u67b6\uff0c\u7ed3\u5408\u6848\u4f8b\u7814\u7a76\u5206\u6790\u6ce8\u610f\u529b\u6a21\u5f0f\u548c\u9690\u85cf\u72b6\u6001\u3002", "result": "\u63ed\u793a\u4e86LLM\u4e2d\u6d8c\u73b0\u7684\u641c\u7d22\u7b97\u6cd5\uff0c\u4e3a\u7b97\u6cd5\u89e3\u91ca\u6027\u63d0\u4f9b\u57fa\u7840\u3002", "conclusion": "\u7cfb\u7edf\u8bc4\u4f30LLM\u7b97\u6cd5\u6709\u52a9\u4e8e\u9ad8\u6548\u8bad\u7ec3\u548c\u65b0\u578b\u67b6\u6784\u8bbe\u8ba1\uff0c\u63a8\u52a8\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u3002"}}
{"id": "2507.07871", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07871", "abs": "https://arxiv.org/abs/2507.07871", "authors": ["Toluwani Aremu", "Noor Hussein", "Munachiso Nwadike", "Samuele Poppi", "Jie Zhang", "Karthik Nandakumar", "Neil Gong", "Nils Lukas"], "title": "Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking", "comment": null, "summary": "Watermarking offers a promising solution for GenAI providers to establish the\nprovenance of their generated content. A watermark is a hidden signal embedded\nin the generated content, whose presence can later be verified using a secret\nwatermarking key. A threat to GenAI providers are \\emph{watermark stealing}\nattacks, where users forge a watermark into content that was \\emph{not}\ngenerated by the provider's models without access to the secret key, e.g., to\nfalsely accuse the provider. Stealing attacks collect \\emph{harmless}\nwatermarked samples from the provider's model and aim to maximize the expected\nsuccess rate of generating \\emph{harmful} watermarked samples. Our work focuses\non mitigating stealing attacks while treating the underlying watermark as a\nblack-box. Our contributions are: (i) Proposing a multi-key extension to\nmitigate stealing attacks that can be applied post-hoc to any watermarking\nmethod across any modality. (ii) We provide theoretical guarantees and\ndemonstrate empirically that our method makes forging substantially less\neffective across multiple datasets, and (iii) we formally define the threat of\nwatermark forging as the task of generating harmful, watermarked content and\nmodel this threat via security games.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5bc6\u94a5\u6269\u5c55\u65b9\u6cd5\uff0c\u7528\u4e8e\u51cf\u8f7b\u6c34\u5370\u7a83\u53d6\u653b\u51fb\uff0c\u4fdd\u62a4\u751f\u6210AI\u5185\u5bb9\u7684\u6c34\u5370\u5b89\u5168\u3002", "motivation": "\u751f\u6210AI\u63d0\u4f9b\u8005\u9700\u8981\u786e\u4fdd\u5176\u751f\u6210\u5185\u5bb9\u7684\u6c34\u5370\u5b89\u5168\uff0c\u9632\u6b62\u7528\u6237\u4f2a\u9020\u6c34\u5370\u4ee5\u865a\u5047\u6307\u63a7\u63d0\u4f9b\u8005\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5bc6\u94a5\u6269\u5c55\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u6c34\u5370\u6280\u672f\u548c\u6a21\u6001\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u4f2a\u9020\u6c34\u5370\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u591a\u5bc6\u94a5\u6269\u5c55\u65b9\u6cd5\u6709\u6548\u51cf\u8f7b\u4e86\u6c34\u5370\u7a83\u53d6\u653b\u51fb\uff0c\u4e3a\u751f\u6210AI\u5185\u5bb9\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u4fdd\u969c\u3002"}}
{"id": "2507.07576", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.07576", "abs": "https://arxiv.org/abs/2507.07576", "authors": ["Mohamed Siala", "Jordi Planes", "Joao Marques-Silva"], "title": "On Trustworthy Rule-Based Models and Explanations", "comment": null, "summary": "A task of interest in machine learning (ML) is that of ascribing explanations\nto the predictions made by ML models. Furthermore, in domains deemed high risk,\nthe rigor of explanations is paramount. Indeed, incorrect explanations can and\nwill mislead human decision makers. As a result, and even if interpretability\nis acknowledged as an elusive concept, so-called interpretable models are\nemployed ubiquitously in high-risk uses of ML and data mining (DM). This is the\ncase for rule-based ML models, which encompass decision trees, diagrams, sets\nand lists. This paper relates explanations with well-known undesired facets of\nrule-based ML models, which include negative overlap and several forms of\nredundancy. The paper develops algorithms for the analysis of these undesired\nfacets of rule-based systems, and concludes that well-known and widely used\ntools for learning rule-based ML models will induce rule sets that exhibit one\nor more negative facets.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\u4e2d\u89c4\u5219\u6a21\u578b\u89e3\u91ca\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u5206\u6790\u7b97\u6cd5\uff0c\u5e76\u6307\u51fa\u5e38\u7528\u5de5\u5177\u4f1a\u5bfc\u81f4\u89c4\u5219\u96c6\u5b58\u5728\u8d1f\u9762\u7279\u5f81\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u9519\u8bef\u7684\u89e3\u91ca\u4f1a\u8bef\u5bfc\u51b3\u7b56\u8005\uff0c\u56e0\u6b64\u9700\u8981\u4e25\u683c\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u7b97\u6cd5\u6765\u5206\u6790\u89c4\u5219\u6a21\u578b\u4e2d\u7684\u8d1f\u9762\u7279\u5f81\uff0c\u5982\u8d1f\u91cd\u53e0\u548c\u5197\u4f59\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5e38\u7528\u5de5\u5177\u751f\u6210\u7684\u89c4\u5219\u96c6\u666e\u904d\u5b58\u5728\u8d1f\u9762\u7279\u5f81\u3002", "conclusion": "\u89c4\u5219\u6a21\u578b\u7684\u89e3\u91ca\u9700\u8981\u66f4\u4e25\u683c\u7684\u5206\u6790\u4ee5\u907f\u514d\u8bef\u5bfc\u3002"}}
{"id": "2507.07901", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07901", "abs": "https://arxiv.org/abs/2507.07901", "authors": ["Sree Bhargavi Balija", "Rekha Singal", "Abhishek Singh", "Ramesh Raskar", "Erfan Darzi", "Raghu Bala", "Thomas Hardjono", "Ken Huang"], "title": "The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web", "comment": null, "summary": "The fragmentation of AI agent ecosystems has created urgent demands for\ninteroperability, trust, and economic coordination that current protocols --\nincluding MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al.,\n2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present\nthe Nanda Unified Architecture, a decentralized framework built around three\ncore innovations: fast DID-based agent discovery through distributed\nregistries, semantic agent cards with verifiable credentials and composability\nprofiles, and a dynamic trust layer that integrates behavioral attestations\nwith policy compliance. The system introduces X42/H42 micropayments for\neconomic coordination and MAESTRO, a security framework incorporating\nSynergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure\ncontainerization. Real-world deployments demonstrate 99.9 percent compliance in\nhealthcare applications and substantial monthly transaction volumes with strong\nprivacy guarantees. By unifying MIT's trust research with production\ndeployments from Cisco and Synergetics, we show how cryptographic proofs and\npolicy-as-code transform agents into trust-anchored participants in a\ndecentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a\nglobally interoperable Internet of Agents where trust becomes the native\ncurrency of collaboration across both enterprise and Web3 ecosystems.", "AI": {"tldr": "Nanda Unified Architecture\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u4e86AI\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u7684\u4e92\u64cd\u4f5c\u6027\u3001\u4fe1\u4efb\u548c\u7ecf\u6d4e\u534f\u8c03\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u6ce8\u518c\u3001\u8bed\u4e49\u4ee3\u7406\u5361\u548c\u52a8\u6001\u4fe1\u4efb\u5c42\u5b9e\u73b0\u9ad8\u6548\u534f\u4f5c\u3002", "motivation": "\u5f53\u524d\u534f\u8bae\u65e0\u6cd5\u6ee1\u8db3AI\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u7684\u4e92\u64cd\u4f5c\u6027\u3001\u4fe1\u4efb\u548c\u7ecf\u6d4e\u534f\u8c03\u9700\u6c42\uff0c\u4e9f\u9700\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5feb\u901fDID\u4ee3\u7406\u53d1\u73b0\u3001\u8bed\u4e49\u4ee3\u7406\u5361\u3001\u52a8\u6001\u4fe1\u4efb\u5c42\u3001X42/H42\u5fae\u652f\u4ed8\u548cMAESTRO\u5b89\u5168\u6846\u67b6\u3002", "result": "\u5b9e\u9645\u90e8\u7f72\u663e\u793a99.9%\u7684\u5408\u89c4\u6027\uff0c\u4ea4\u6613\u91cf\u5927\u4e14\u9690\u79c1\u4fdd\u969c\u5f3a\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53bb\u4e2d\u5fc3\u5316\u7ecf\u6d4e\u4e2d\u7684\u4ee3\u7406\u534f\u4f5c\u63d0\u4f9b\u4e86\u4fe1\u4efb\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u5168\u7403\u4e92\u64cd\u4f5c\u7684\u4ee3\u7406\u4e92\u8054\u7f51\u3002"}}
{"id": "2507.07595", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07595", "abs": "https://arxiv.org/abs/2507.07595", "authors": ["Zhixiang Su", "Di Wang", "Chunyan Miao"], "title": "Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs", "comment": null, "summary": "Recent investigations on the effectiveness of Graph Neural Network\n(GNN)-based models for link prediction in Knowledge Graphs (KGs) show that\nvanilla aggregation does not significantly impact the model performance. In\nthis paper, we introduce a novel method, named Context Pooling, to enhance\nGNN-based models' efficacy for link predictions in KGs. To our best of\nknowledge, Context Pooling is the first methodology that applies graph pooling\nin KGs. Additionally, Context Pooling is first-of-its-kind to enable the\ngeneration of query-specific graphs for inductive settings, where testing\nentities are unseen during training. Specifically, we devise two metrics,\nnamely neighborhood precision and neighborhood recall, to assess the neighbors'\nlogical relevance regarding the given queries, thereby enabling the subsequent\ncomprehensive identification of only the logically relevant neighbors for link\nprediction. Our method is generic and assessed by being applied to two\nstate-of-the-art (SOTA) models on three public transductive and inductive\ndatasets, achieving SOTA performance in 42 out of 48 settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aContext Pooling\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fe\u6c60\u5316\u6280\u672f\u63d0\u5347GNN\u5728\u77e5\u8bc6\u56fe\u8c31\u94fe\u63a5\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97SOTA\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709GNN\u6a21\u578b\u5728\u77e5\u8bc6\u56fe\u8c31\u94fe\u63a5\u9884\u6d4b\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u5c24\u5176\u662f\u5bf9\u672a\u89c1\u5b9e\u4f53\u7684\u5f52\u7eb3\u8bbe\u7f6e\u3002", "method": "\u63d0\u51faContext Pooling\u65b9\u6cd5\uff0c\u9996\u6b21\u5c06\u56fe\u6c60\u5316\u5e94\u7528\u4e8e\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u8bbe\u8ba1\u90bb\u5c45\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u6307\u6807\u7b5b\u9009\u903b\u8f91\u76f8\u5173\u90bb\u5c45\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5e94\u7528\u4e8e\u4e24\u4e2aSOTA\u6a21\u578b\uff0c48\u4e2a\u8bbe\u7f6e\u4e2d42\u4e2a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "conclusion": "Context Pooling\u663e\u8457\u63d0\u5347\u4e86GNN\u5728\u77e5\u8bc6\u56fe\u8c31\u94fe\u63a5\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u5c24\u5176\u5728\u5f52\u7eb3\u8bbe\u7f6e\u4e2d\u5177\u6709\u521b\u65b0\u6027\u3002"}}
{"id": "2507.07916", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.07916", "abs": "https://arxiv.org/abs/2507.07916", "authors": ["Federico Maria Cau", "Giuseppe Desolda", "Francesco Greco", "Lucio Davide Spano", "Luca Vigan\u00f2"], "title": "Can Large Language Models Improve Phishing Defense? A Large-Scale Controlled Experiment on Warning Dialogue Explanations", "comment": null, "summary": "Phishing has become a prominent risk in modern cybersecurity, often used to\nbypass technological defences by exploiting predictable human behaviour.\nWarning dialogues are a standard mitigation measure, but the lack of\nexplanatory clarity and static content limits their effectiveness. In this\npaper, we report on our research to assess the capacity of Large Language\nModels (LLMs) to generate clear, concise, and scalable explanations for\nphishing warnings. We carried out a large-scale between-subjects user study (N\n= 750) to compare the influence of warning dialogues supplemented with manually\ngenerated explanations against those generated by two LLMs, Claude 3.5 Sonnet\nand Llama 3.3 70B. We investigated two explanatory styles (feature-based and\ncounterfactual) for their effects on behavioural metrics (click-through rate)\nand perceptual outcomes (e.g., trust, risk, clarity). The results indicate that\nwell-constructed LLM-generated explanations can equal or surpass manually\ncrafted explanations in reducing susceptibility to phishing; Claude-generated\nwarnings exhibited particularly robust performance. Feature-based explanations\nwere more effective for genuine phishing attempts, whereas counterfactual\nexplanations diminished false-positive rates. Other variables such as workload,\ngender, and prior familiarity with warning dialogues significantly moderated\nwarning effectiveness. These results indicate that LLMs can be used to\nautomatically build explanations for warning users against phishing, and that\nsuch solutions are scalable, adaptive, and consistent with human-centred\nvalues.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u9493\u9c7c\u8b66\u544a\u89e3\u91ca\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u6548\u679c\u4e0e\u4eba\u5de5\u751f\u6210\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u3002", "motivation": "\u9493\u9c7c\u653b\u51fb\u5229\u7528\u4eba\u7c7b\u884c\u4e3a\u7ed5\u8fc7\u6280\u672f\u9632\u5fa1\uff0c\u73b0\u6709\u8b66\u544a\u5bf9\u8bdd\u6846\u56e0\u89e3\u91ca\u4e0d\u6e05\u548c\u9759\u6001\u5185\u5bb9\u6548\u679c\u6709\u9650\u3002", "method": "\u901a\u8fc7\u5927\u89c4\u6a21\u7528\u6237\u7814\u7a76\uff08N=750\uff09\u6bd4\u8f83\u4eba\u5de5\u548c\u4e24\u79cdLLM\uff08Claude 3.5 Sonnet\u548cLlama 3.3 70B\uff09\u751f\u6210\u7684\u89e3\u91ca\u6548\u679c\uff0c\u5206\u6790\u4e24\u79cd\u89e3\u91ca\u98ce\u683c\uff08\u57fa\u4e8e\u7279\u5f81\u548c\u53cd\u4e8b\u5b9e\uff09\u5bf9\u884c\u4e3a\u6307\u6807\u548c\u611f\u77e5\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "result": "LLM\u751f\u6210\u7684\u89e3\u91ca\u5728\u964d\u4f4e\u9493\u9c7c\u6613\u611f\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\uff0cClaude\u6548\u679c\u5c24\u4e3a\u7a81\u51fa\uff1b\u57fa\u4e8e\u7279\u5f81\u7684\u89e3\u91ca\u5bf9\u771f\u5b9e\u9493\u9c7c\u66f4\u6709\u6548\uff0c\u53cd\u4e8b\u5b9e\u89e3\u91ca\u51cf\u5c11\u8bef\u62a5\u7387\u3002", "conclusion": "LLM\u53ef\u81ea\u52a8\u751f\u6210\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u7b26\u5408\u4eba\u7c7b\u4e2d\u5fc3\u4ef7\u503c\u89c2\u7684\u9493\u9c7c\u8b66\u544a\u89e3\u91ca\u3002"}}
{"id": "2507.07599", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.07599", "abs": "https://arxiv.org/abs/2507.07599", "authors": ["Sedigh Khademi", "Jim Black", "Christopher Palmer", "Muhammad Javed", "Hazel Clothier", "Jim Buttery", "Gerardo Luis Dimaguila"], "title": "Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models", "comment": "5 pages", "summary": "This study evaluates fine-tuned Llama 3.2 models for extracting\nvaccine-related information from emergency department triage notes to support\nnear real-time vaccine safety surveillance. Prompt engineering was used to\ninitially create a labeled dataset, which was then confirmed by human\nannotators. The performance of prompt-engineered models, fine-tuned models, and\na rule-based approach was compared. The fine-tuned Llama 3 billion parameter\nmodel outperformed other models in its accuracy of extracting vaccine names.\nModel quantization enabled efficient deployment in resource-constrained\nenvironments. Findings demonstrate the potential of large language models in\nautomating data extraction from emergency department notes, supporting\nefficient vaccine safety surveillance and early detection of emerging adverse\nevents following immunization issues.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u5fae\u8c03\u7684Llama 3.2\u6a21\u578b\u5728\u6025\u8bca\u5206\u8bca\u7b14\u8bb0\u4e2d\u63d0\u53d6\u75ab\u82d7\u76f8\u5173\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u4ee5\u652f\u6301\u8fd1\u5b9e\u65f6\u75ab\u82d7\u5b89\u5168\u76d1\u6d4b\u3002", "motivation": "\u901a\u8fc7\u81ea\u52a8\u5316\u6570\u636e\u63d0\u53d6\u63d0\u9ad8\u75ab\u82d7\u5b89\u5168\u76d1\u6d4b\u6548\u7387\uff0c\u53ca\u65e9\u53d1\u73b0\u75ab\u82d7\u63a5\u79cd\u540e\u7684\u4e0d\u826f\u4e8b\u4ef6\u3002", "method": "\u4f7f\u7528\u63d0\u793a\u5de5\u7a0b\u521b\u5efa\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u5e76\u7531\u4eba\u5de5\u786e\u8ba4\u3002\u6bd4\u8f83\u63d0\u793a\u5de5\u7a0b\u6a21\u578b\u3001\u5fae\u8c03\u6a21\u578b\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u3002", "result": "\u5fae\u8c03\u7684Llama 3\u6a21\u578b\u5728\u63d0\u53d6\u75ab\u82d7\u540d\u79f0\u7684\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u91cf\u5316\u6280\u672f\u4f7f\u5176\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u9ad8\u6548\u90e8\u7f72\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u6025\u8bca\u7b14\u8bb0\u6570\u636e\u63d0\u53d6\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u53ef\u652f\u6301\u9ad8\u6548\u7684\u75ab\u82d7\u5b89\u5168\u76d1\u6d4b\u3002"}}
{"id": "2507.07927", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07927", "abs": "https://arxiv.org/abs/2507.07927", "authors": ["Jenny Blessing", "Ross J. Anderson", "Alastair R. Beresford"], "title": "KeyDroid: A Large-Scale Analysis of Secure Key Storage in Android Apps", "comment": null, "summary": "Most contemporary mobile devices offer hardware-backed storage for\ncryptographic keys, user data, and other sensitive credentials. Such hardware\nprotects credentials from extraction by an adversary who has compromised the\nmain operating system, such as a malicious third-party app. Since 2011, Android\napp developers can access trusted hardware via the Android Keystore API. In\nthis work, we conduct the first comprehensive survey of hardware-backed key\nstorage in Android devices. We analyze 490 119 Android apps, collecting data on\nhow trusted hardware is used by app developers (if used at all) and\ncross-referencing our findings with sensitive user data collected by each app,\nas self-reported by developers via the Play Store's data safety labels.\n  We find that despite industry-wide initiatives to encourage adoption, 56.3%\nof apps self-reporting as processing sensitive user data do not use Android's\ntrusted hardware capabilities at all, while just 5.03% of apps collecting some\nform of sensitive data use the strongest form of trusted hardware, a secure\nelement distinct from the main processor. To better understand the potential\ndownsides of using secure hardware, we conduct the first empirical analysis of\ntrusted hardware performance in mobile devices, measuring the runtime of common\ncryptographic operations across both software- and hardware-backed keystores.\nWe find that while hardware-backed key storage using a coprocessor is viable\nfor most common cryptographic operations, secure elements capable of preventing\nmore advanced attacks make performance infeasible for symmetric encryption with\nnon-negligible payloads and any kind of asymmetric encryption.", "AI": {"tldr": "\u8c03\u67e5\u53d1\u73b0\uff0c\u5c3d\u7ba1\u6709\u884c\u4e1a\u5021\u8bae\uff0c\u4f4656.3%\u5904\u7406\u654f\u611f\u6570\u636e\u7684Android\u5e94\u7528\u672a\u4f7f\u7528\u786c\u4ef6\u5b89\u5168\u5b58\u50a8\uff0c\u4ec55.03%\u4f7f\u7528\u6700\u5f3a\u5f62\u5f0f\u7684\u5b89\u5168\u5143\u4ef6\u3002\u6027\u80fd\u5206\u6790\u663e\u793a\uff0c\u9ad8\u7ea7\u5b89\u5168\u5143\u4ef6\u5728\u5bf9\u79f0\u548c\u975e\u5bf9\u79f0\u52a0\u5bc6\u4e2d\u6027\u80fd\u4e0d\u8db3\u3002", "motivation": "\u7814\u7a76Android\u5e94\u7528\u4e2d\u786c\u4ef6\u5b89\u5168\u5b58\u50a8\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u4e86\u89e3\u5f00\u53d1\u8005\u5bf9\u654f\u611f\u6570\u636e\u7684\u4fdd\u62a4\u63aa\u65bd\u53ca\u5176\u6027\u80fd\u5f71\u54cd\u3002", "method": "\u5206\u6790\u4e86490,119\u4e2aAndroid\u5e94\u7528\uff0c\u7ed3\u5408Play Store\u7684\u6570\u636e\u5b89\u5168\u6807\u7b7e\uff0c\u8bc4\u4f30\u786c\u4ef6\u5b89\u5168\u5b58\u50a8\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u5e76\u6d4b\u8bd5\u4e86\u4e0d\u540c\u786c\u4ef6\u652f\u6301\u7684\u52a0\u5bc6\u64cd\u4f5c\u6027\u80fd\u3002", "result": "\u591a\u6570\u5e94\u7528\u672a\u5145\u5206\u5229\u7528\u786c\u4ef6\u5b89\u5168\u5b58\u50a8\uff0c\u9ad8\u7ea7\u5b89\u5168\u5143\u4ef6\u5728\u52a0\u5bc6\u64cd\u4f5c\u4e2d\u6027\u80fd\u8f83\u5dee\u3002", "conclusion": "\u786c\u4ef6\u5b89\u5168\u5b58\u50a8\u7684\u666e\u53ca\u548c\u6027\u80fd\u4ecd\u9700\u6539\u8fdb\uff0c\u4ee5\u66f4\u597d\u5730\u4fdd\u62a4\u654f\u611f\u6570\u636e\u3002"}}
{"id": "2507.07619", "categories": ["cs.AI", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.07619", "abs": "https://arxiv.org/abs/2507.07619", "authors": ["Marco Sangalli", "Thomas Krak", "Cassio de Campos"], "title": "Towards conservative inference in credal networks using belief functions: the case of credal chains", "comment": null, "summary": "This paper explores belief inference in credal networks using Dempster-Shafer\ntheory. By building on previous work, we propose a novel framework for\npropagating uncertainty through a subclass of credal networks, namely chains.\nThe proposed approach efficiently yields conservative intervals through belief\nand plausibility functions, combining computational speed with robust\nuncertainty representation. Key contributions include formalizing belief-based\ninference methods and comparing belief-based inference against classical\nsensitivity analysis. Numerical results highlight the advantages and\nlimitations of applying belief inference within this framework, providing\ninsights into its practical utility for chains and for credal networks in\ngeneral.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDempster-Shafer\u7406\u8bba\u7684\u4fe1\u5ff5\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u94fe\u5f0f\u4fe1\u7528\u7f51\u7edc\u4e2d\u4f20\u64ad\u4e0d\u786e\u5b9a\u6027\uff0c\u7ed3\u5408\u8ba1\u7b97\u901f\u5ea6\u4e0e\u9c81\u68d2\u7684\u8868\u793a\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5728\u4fe1\u7528\u7f51\u7edc\u4e2d\u9ad8\u6548\u4e14\u9c81\u68d2\u5730\u4f20\u64ad\u4e0d\u786e\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5728\u94fe\u5f0f\u7ed3\u6784\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u5ff5\u548c\u53ef\u4fe1\u5ea6\u51fd\u6570\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4fdd\u5b88\u533a\u95f4\u4f20\u64ad\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u4e0e\u7ecf\u5178\u654f\u611f\u6027\u5206\u6790\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u6570\u503c\u7ed3\u679c\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5728\u94fe\u5f0f\u7ed3\u6784\u4e2d\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u5176\u5728\u4fe1\u7528\u7f51\u7edc\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u94fe\u5f0f\u4fe1\u7528\u7f51\u7edc\u4e2d\u7684\u4fe1\u5ff5\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5176\u9002\u7528\u8303\u56f4\u548c\u6f5c\u5728\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2507.07972", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07972", "abs": "https://arxiv.org/abs/2507.07972", "authors": ["Karthik Garimella", "Austin Ebel", "Brandon Reagen"], "title": "EinHops: Einsum Notation for Expressive Homomorphic Operations on RNS-CKKS Tensors", "comment": "11 pages, 7 figures, 1 table", "summary": "Fully Homomorphic Encryption (FHE) is an encryption scheme that allows for\ncomputation to be performed directly on encrypted data, effectively closing the\nloop on secure and outsourced computing. Data is encrypted not only during rest\nand transit, but also during processing. However, FHE provides a limited\ninstruction set: SIMD addition, SIMD multiplication, and cyclic rotation of 1-D\nvectors. This restriction makes performing multi-dimensional tensor operations\nchallenging. Practitioners must pack these tensors into 1-D vectors and map\ntensor operations onto this one-dimensional layout rather than their\ntraditional nested structure. And while prior systems have made significant\nstrides in automating this process, they often hide critical packing decisions\nbehind layers of abstraction, making debugging, optimizing, and building on top\nof these systems difficult.\n  In this work, we approach multi-dimensional tensor operations in FHE through\nEinstein summation (einsum) notation. Einsum notation explicitly encodes\ndimensional structure and operations in its syntax, naturally exposing how\ntensors should be packed and transformed. We decompose einsum expressions into\na fixed set of FHE-friendly operations. We implement our design and present\nEinHops, a minimalist system that factors einsum expressions into a fixed\nsequence of FHE operations. EinHops enables developers to perform encrypted\ntensor operations using FHE while maintaining full visibility into the\nunderlying packing strategy. We evaluate EinHops on a range of tensor\noperations from a simple transpose to complex multi-dimensional contractions.\nWe show that the explicit nature of einsum notation allows us to build an FHE\ntensor system that is simple, general, and interpretable. We open-source\nEinHops at the following repository: https://github.com/baahl-nyu/einhops.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7231\u56e0\u65af\u5766\u6c42\u548c\uff08einsum\uff09\u7b26\u53f7\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5b8c\u5168\u540c\u6001\u52a0\u5bc6\uff08FHE\uff09\u4e2d\u5b9e\u73b0\u591a\u7ef4\u5f20\u91cf\u64cd\u4f5c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u9690\u85cf\u5173\u952e\u6253\u5305\u51b3\u7b56\u7684\u95ee\u9898\u3002", "motivation": "FHE\u4ec5\u652f\u6301\u4e00\u7ef4\u5411\u91cf\u64cd\u4f5c\uff0c\u591a\u7ef4\u5f20\u91cf\u64cd\u4f5c\u9700\u8981\u590d\u6742\u7684\u6253\u5305\u548c\u6620\u5c04\uff0c\u73b0\u6709\u7cfb\u7edf\u62bd\u8c61\u5c42\u6b21\u8fc7\u591a\uff0c\u96be\u4ee5\u8c03\u8bd5\u548c\u4f18\u5316\u3002", "method": "\u5229\u7528einsum\u7b26\u53f7\u660e\u786e\u7f16\u7801\u5f20\u91cf\u7ed3\u6784\u548c\u64cd\u4f5c\uff0c\u5c06\u5176\u5206\u89e3\u4e3aFHE\u53cb\u597d\u7684\u64cd\u4f5c\u5e8f\u5217\uff0c\u5e76\u5b9e\u73b0EinHops\u7cfb\u7edf\u3002", "result": "EinHops\u80fd\u591f\u7b80\u5355\u3001\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u5730\u6267\u884c\u52a0\u5bc6\u5f20\u91cf\u64cd\u4f5c\uff0c\u4ece\u7b80\u5355\u8f6c\u7f6e\u5230\u590d\u6742\u591a\u7ef4\u6536\u7f29\u5747\u53ef\u5b9e\u73b0\u3002", "conclusion": "einsum\u7b26\u53f7\u7684\u663e\u5f0f\u7279\u6027\u4f7f\u5f97FHE\u5f20\u91cf\u7cfb\u7edf\u66f4\u900f\u660e\u548c\u6613\u4e8e\u7406\u89e3\uff0cEinHops\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u5e95\u5c42\u6253\u5305\u7b56\u7565\u53ef\u89c1\u6027\u3002"}}
{"id": "2507.07644", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07644", "abs": "https://arxiv.org/abs/2507.07644", "authors": ["Fedor Rodionov", "Abdelrahman Eldesokey", "Michael Birsak", "John Femiani", "Bernard Ghanem", "Peter Wonka"], "title": "PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations", "comment": "25 pages, 18 figures. Diagnostic benchmark for spatial reasoning in\n  LLMs. Project page: https://OldDelorean.github.io/PlanQA/", "summary": "We introduce PlanQA, a diagnostic benchmark for evaluating geometric and\nspatial reasoning in large-language models (LLMs). PlanQA is grounded in\nstructured representations of indoor scenes, such as kitchens, living rooms,\nand bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The\nbenchmark includes diverse question types that test not only metric and\ntopological reasoning (e.g., distance, visibility, shortest paths) but also\ninterior design constraints such as affordance, clearance, balance, and\nusability. Our results across a variety of frontier open-source and commercial\nLLMs show that while models may succeed in shallow queries, they often fail to\nsimulate physical constraints, preserve spatial coherence, or generalize under\nlayout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they\ndo not consistently reason about real-world layouts. We hope that this\nbenchmark inspires new work on language models that can accurately infer and\nmanipulate spatial and geometric properties in practical settings.", "AI": {"tldr": "PlanQA\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u51e0\u4f55\u548c\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u7684\u8bca\u65ad\u57fa\u51c6\uff0c\u57fa\u4e8e\u5ba4\u5185\u573a\u666f\u7684\u7ed3\u6784\u5316\u8868\u793a\uff0c\u63ed\u793aLLMs\u5728\u771f\u5b9e\u4e16\u754c\u5e03\u5c40\u63a8\u7406\u4e2d\u7684\u76f2\u70b9\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u51e0\u4f55\u548c\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5ba4\u5185\u8bbe\u8ba1\u7ea6\u675f\u548c\u5e03\u5c40\u6270\u52a8\u65f6\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u7b26\u53f7\u5316\u683c\u5f0f\uff08\u5982JSON\u3001XML\uff09\u7f16\u7801\u5ba4\u5185\u573a\u666f\uff0c\u8bbe\u8ba1\u591a\u6837\u5316\u95ee\u9898\u7c7b\u578b\u6d4b\u8bd5\u5ea6\u91cf\u3001\u62d3\u6251\u63a8\u7406\u53ca\u8bbe\u8ba1\u7ea6\u675f\u3002", "result": "LLMs\u5728\u6d45\u5c42\u67e5\u8be2\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6a21\u62df\u7269\u7406\u7ea6\u675f\u3001\u4fdd\u6301\u7a7a\u95f4\u4e00\u81f4\u6027\u53ca\u5e03\u5c40\u6270\u52a8\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "PlanQA\u63ed\u793a\u4e86\u5f53\u524dLLMs\u5728\u771f\u5b9e\u4e16\u754c\u5e03\u5c40\u63a8\u7406\u4e2d\u7684\u4e0d\u8db3\uff0c\u4e3a\u672a\u6765\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u548c\u51e0\u4f55\u63a8\u7406\u65b9\u9762\u7684\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.07974", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07974", "abs": "https://arxiv.org/abs/2507.07974", "authors": ["Sizhe Chen", "Yizhu Wang", "Nicholas Carlini", "Chawin Sitawarin", "David Wagner"], "title": "Defending Against Prompt Injection With a Few DefensiveTokens", "comment": null, "summary": "When large language model (LLM) systems interact with external data to\nperform complex tasks, a new attack, namely prompt injection, becomes a\nsignificant threat. By injecting instructions into the data accessed by the\nsystem, the attacker is able to override the initial user task with an\narbitrary task directed by the attacker. To secure the system, test-time\ndefenses, e.g., defensive prompting, have been proposed for system developers\nto attain security only when needed in a flexible manner. However, they are\nmuch less effective than training-time defenses that change the model\nparameters. Motivated by this, we propose DefensiveToken, a test-time defense\nwith prompt injection robustness comparable to training-time alternatives.\nDefensiveTokens are newly inserted as special tokens, whose embeddings are\noptimized for security. In security-sensitive cases, system developers can\nappend a few DefensiveTokens before the LLM input to achieve security with a\nminimal utility drop. In scenarios where security is less of a concern,\ndevelopers can simply skip DefensiveTokens; the LLM system remains the same as\nthere is no defense, generating high-quality responses. Thus, DefensiveTokens,\nif released alongside the model, allow a flexible switch between the\nstate-of-the-art (SOTA) utility and almost-SOTA security at test time. The code\nis available at https://github.com/Sizhe-Chen/DefensiveToken.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDefensiveToken\uff0c\u4e00\u79cd\u6d4b\u8bd5\u65f6\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d2\u5165\u7279\u6b8a\u4ee4\u724c\u4f18\u5316\u5d4c\u5165\uff0c\u4ee5\u7075\u6d3b\u5e73\u8861\u5b89\u5168\u6027\u4e0e\u5b9e\u7528\u6027\u3002", "motivation": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7cfb\u7edf\u5728\u5916\u90e8\u6570\u636e\u4ea4\u4e92\u65f6\u9762\u4e34\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u73b0\u6709\u6d4b\u8bd5\u65f6\u9632\u5fa1\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\uff0c\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faDefensiveToken\uff0c\u901a\u8fc7\u63d2\u5165\u5e76\u4f18\u5316\u7279\u6b8a\u4ee4\u724c\u7684\u5d4c\u5165\uff0c\u5728\u9700\u8981\u65f6\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u7528\u6027\u3002", "result": "DefensiveToken\u5728\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u5b9e\u73b0\u7075\u6d3b\u5207\u6362\uff0c\u63a5\u8fd1\u8bad\u7ec3\u65f6\u9632\u5fa1\u7684\u6548\u679c\u3002", "conclusion": "DefensiveToken\u4e3aLLM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u9632\u5fa1\u624b\u6bb5\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u5b89\u5168\u9700\u6c42\u573a\u666f\u3002"}}
{"id": "2507.07723", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07723", "abs": "https://arxiv.org/abs/2507.07723", "authors": ["Chengtao Jian", "Kai Yang", "Ye Ouyang", "Xiaozhou Ye"], "title": "Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization", "comment": null, "summary": "Direct Preference Optimization (DPO) has emerged as a popular and efficient\nalternative to reward modeling and reinforcement learning for aligning language\nmodels with human preferences. Despite its empirical success, the theoretical\nproperties and intrinsic limitations of DPO remain underexplored. In this work,\nwe first present a comprehensive analysis of DPO's dynamics from a probability\nevolution perspective. Our analysis reveals that DPO is highly sensitive to\ninitialization. It also tends to misallocate probability mass, which can\ninadvertently shift probability toward irrelevant or undesired responses. This\nmisallocation may unintentionally reinforce model bias, thereby compromising\nboth the stability of model alignment and the consistency with intended\npreferences. Motivated by these theoretical findings, we propose a\ntheoretically grounded bilevel optimization framework that tightly integrate\nsupervised fine-tuning with an enhanced DPO objective a.k.a. stable preference\noptimization. Our approach introduces a principled regularization scheme to\nexplicitly encourage absolute probability improvement for preferred outputs,\nwhile maintaining stable optimization dynamics. Experiments on challenging\nreasoning and summarization benchmarks elucidate that our method consistently\nimproves reasoning accuracy and better aligns output distributions with\nintended preferences, outperforming standard DPO. Stable preference\noptimization provides new insights into the design of preference-based\nalignment objectives and opens up new avenues towards more reliable and\ninterpretable language model alignment.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u7684\u7406\u8bba\u5c40\u9650\u6027\u548c\u52a8\u6001\u7279\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff08\u7a33\u5b9a\u504f\u597d\u4f18\u5316\uff09\u4ee5\u6539\u8fdbDPO\u7684\u7a33\u5b9a\u6027\u548c\u5bf9\u9f50\u6548\u679c\u3002", "motivation": "DPO\u867d\u7136\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176\u7406\u8bba\u6027\u8d28\u548c\u5185\u5728\u5c40\u9650\u6027\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u5c24\u5176\u662f\u5176\u5bf9\u521d\u59cb\u5316\u7684\u654f\u611f\u6027\u548c\u6982\u7387\u8d28\u91cf\u5206\u914d\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6982\u7387\u6f14\u5316\u7684\u89c6\u89d2\u5206\u6790DPO\u7684\u52a8\u6001\u7279\u6027\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\u548c\u6539\u8fdbDPO\u76ee\u6807\u7684\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u5f15\u5165\u6b63\u5219\u5316\u4ee5\u7a33\u5b9a\u4f18\u5316\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u63a8\u7406\u548c\u6458\u8981\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u5e76\u66f4\u597d\u5730\u5bf9\u9f50\u8f93\u51fa\u5206\u5e03\u4e0e\u9884\u671f\u504f\u597d\uff0c\u4f18\u4e8e\u6807\u51c6DPO\u3002", "conclusion": "\u7a33\u5b9a\u504f\u597d\u4f18\u5316\u4e3a\u504f\u597d\u5bf9\u9f50\u76ee\u6807\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5e76\u4e3a\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.07743", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07743", "abs": "https://arxiv.org/abs/2507.07743", "authors": ["Phil\u00e9mon Beghin", "Anne-Emmanuelle Ceulemans", "Fran\u00e7ois Glineur"], "title": "Identification of Violin Reduction via Contour Lines Classification", "comment": null, "summary": "The first violins appeared in late 16th-century Italy. Over the next 200\nyears, they spread across Europe and luthiers of various royal courts, eager to\nexperiment with new techniques, created a highly diverse family of instruments.\nAround 1750, size standards were introduced to unify violin making for\norchestras and conservatories. Instruments that fell between two standards were\nthen reduced to a smaller size by luthiers. These reductions have an impact on\nseveral characteristics of violins, in particular on the contour lines, i.e.\nlines of constant altitude, which look more like a U for non reduced\ninstruments and a V for reduced ones. While such differences are observed by\nexperts, they have not been studied quantitatively.\n  This paper presents a method for classifying violins as reduced or\nnon-reduced based on their contour lines. We study a corpus of 25 instruments\nwhose 3D geometric meshes were acquired via photogrammetry. For each\ninstrument, we extract 10-20 contour lines regularly spaced every millimetre.\nEach line is fitted with a parabola-like curve (with an equation of the type y\n= alpha*abs(x)**beta) depending on two parameters, describing how open (beta)\nand how vertically stretched (alpha) the curve is. We compute additional\nfeatures from those parameters, using regressions and counting how many values\nfall under some threshold. We also deal with outliers and non equal numbers of\nlevels, and eventually obtain a numerical profile for each instrument.\n  We then apply classification methods to assess whether geometry alone can\npredict size reduction. We find that distinguishing between reduced and non\nreduced instruments is feasible to some degree, taking into account that a\nwhole spectrum of more or less transformed violins exists, for which it is more\ndifficult to quantify the reduction. We also find the opening parameter beta to\nbe the most predictive.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f6e\u5ed3\u7ebf\u5206\u7c7b\u5c0f\u63d0\u7434\u662f\u5426\u88ab\u7f29\u5c0f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u51e0\u4f55\u7279\u5f81\u5206\u6790\uff0c\u53d1\u73b0\u533a\u5206\u7f29\u5c0f\u4e0e\u975e\u7f29\u5c0f\u7684\u5c0f\u63d0\u7434\u662f\u53ef\u884c\u7684\u3002", "motivation": "\u7814\u7a76\u5c0f\u63d0\u7434\u5236\u4f5c\u4e2d\u7684\u5c3a\u5bf8\u6807\u51c6\u5316\u5bf9\u4e50\u5668\u51e0\u4f55\u7279\u5f81\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u8f6e\u5ed3\u7ebf\u7684\u53d8\u5316\u3002", "method": "\u4f7f\u752825\u628a\u5c0f\u63d0\u7434\u76843D\u51e0\u4f55\u7f51\u683c\u6570\u636e\uff0c\u63d0\u53d6\u8f6e\u5ed3\u7ebf\u5e76\u62df\u5408\u629b\u7269\u7ebf\u66f2\u7ebf\uff0c\u8ba1\u7b97\u53c2\u6570\u7279\u5f81\uff0c\u5e94\u7528\u5206\u7c7b\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u51e0\u4f55\u7279\u5f81\u53ef\u4ee5\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u9884\u6d4b\u5c0f\u63d0\u7434\u662f\u5426\u88ab\u7f29\u5c0f\uff0c\u5176\u4e2d\u5f00\u53e3\u53c2\u6570beta\u6700\u5177\u9884\u6d4b\u6027\u3002", "conclusion": "\u51e0\u4f55\u5206\u6790\u53ef\u7528\u4e8e\u533a\u5206\u7f29\u5c0f\u4e0e\u975e\u7f29\u5c0f\u7684\u5c0f\u63d0\u7434\uff0c\u4f46\u5b58\u5728\u4e00\u5b9a\u96be\u5ea6\uff0c\u5c24\u5176\u662f\u5bf9\u90e8\u5206\u6539\u9020\u7684\u4e50\u5668\u3002"}}
{"id": "2507.07787", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07787", "abs": "https://arxiv.org/abs/2507.07787", "authors": ["Elizabeth Hilliard", "Akshaya Jagadeesh", "Alex Cook", "Steele Billings", "Nicholas Skytland", "Alicia Llewellyn", "Jackson Paull", "Nathan Paull", "Nolan Kurylo", "Keatra Nesbitt", "Robert Gruenewald", "Anthony Jantzi", "Omar Chavez"], "title": "Measuring AI Alignment with Human Flourishing", "comment": null, "summary": "This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel\nevaluation framework that assesses AI alignment with human flourishing across\nseven dimensions: Character and Virtue, Close Social Relationships, Happiness\nand Life Satisfaction, Meaning and Purpose, Mental and Physical Health,\nFinancial and Material Stability, and Faith and Spirituality. Unlike\ntraditional benchmarks that focus on technical capabilities or harm prevention,\nthe FAI Benchmark measures AI performance on how effectively models contribute\nto the flourishing of a person across these dimensions. The benchmark evaluates\nhow effectively LLM AI systems align with current research models of holistic\nhuman well-being through a comprehensive methodology that incorporates 1,229\nobjective and subjective questions. Using specialized judge Large Language\nModels (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs\ngeometric mean scoring to ensure balanced performance across all flourishing\ndimensions. Initial testing of 28 leading language models reveals that while\nsome models approach holistic alignment (with the highest-scoring models\nachieving 72/100), none are acceptably aligned across all dimensions,\nparticularly in Faith and Spirituality, Character and Virtue, and Meaning and\nPurpose. This research establishes a framework for developing AI systems that\nactively support human flourishing rather than merely avoiding harm, offering\nsignificant implications for AI development, ethics, and evaluation.", "AI": {"tldr": "FAI Benchmark\u8bc4\u4f30AI\u5bf9\u4eba\u7c7b\u7e41\u8363\u7684\u8d21\u732e\uff0c\u6db5\u76d6\u4e03\u4e2a\u7ef4\u5ea6\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u4fe1\u4ef0\u4e0e\u7075\u6027\u3001\u54c1\u5fb7\u4e0e\u7f8e\u5fb7\u3001\u610f\u4e49\u4e0e\u76ee\u7684\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edfAI\u8bc4\u4f30\u805a\u7126\u6280\u672f\u80fd\u529b\u6216\u907f\u514d\u5371\u5bb3\uff0c\u800cFAI Benchmark\u65e8\u5728\u8861\u91cfAI\u5982\u4f55\u4fc3\u8fdb\u4eba\u7c7b\u5168\u9762\u7e41\u8363\u3002", "method": "\u901a\u8fc71,229\u4e2a\u4e3b\u5ba2\u89c2\u95ee\u9898\uff0c\u7ed3\u5408\u4e13\u5bb6LLM\u548c\u51e0\u4f55\u5e73\u5747\u8bc4\u5206\uff0c\u8bc4\u4f3028\u4e2a\u9886\u5148\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u6700\u9ad8\u5206\u6a21\u578b\u4ec572/100\uff0c\u5c24\u5176\u5728\u4fe1\u4ef0\u4e0e\u7075\u6027\u7b49\u7ef4\u5ea6\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "FAI Benchmark\u4e3a\u5f00\u53d1\u652f\u6301\u4eba\u7c7b\u7e41\u8363\u7684AI\u63d0\u4f9b\u4e86\u6846\u67b6\uff0c\u5bf9AI\u4f26\u7406\u548c\u8bc4\u4f30\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.07818", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07818", "abs": "https://arxiv.org/abs/2507.07818", "authors": ["Lu Xu", "Jiaqian Yu", "Xiongfeng Peng", "Yiwei Chen", "Weiming Li", "Jaewook Yoo", "Sunghyun Chunag", "Dongwook Lee", "Daehyun Ji", "Chao Zhang"], "title": "MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving", "comment": null, "summary": "Recent studies show large language models (LLMs) and vision language models\n(VLMs) trained using web-scale data can empower end-to-end autonomous driving\nsystems for a better generalization and interpretation. Specifically, by\ndynamically routing inputs to specialized subsets of parameters, the\nMixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve\nsubstantial performance improvements while maintaining computational\nefficiency. However, general MoE models usually demands extensive training data\nand complex optimization. In this work, inspired by the learning process of\nhuman drivers, we propose a skill-oriented MoE, called MoSE, which mimics human\ndrivers' learning process and reasoning process, skill-by-skill and\nstep-by-step. We propose a skill-oriented routing mechanism that begins with\ndefining and annotating specific skills, enabling experts to identify the\nnecessary driving competencies for various scenarios and reasoning tasks,\nthereby facilitating skill-by-skill learning. Further align the driving process\nto multi-step planning in human reasoning and end-to-end driving models, we\nbuild a hierarchical skill dataset and pretrain the router to encourage the\nmodel to think step-by-step. Unlike multi-round dialogs, MoSE integrates\nvaluable auxiliary tasks (e.g.\\ description, reasoning, planning) in one single\nforward process without introducing any extra computational cost. With less\nthan 3B sparsely activated parameters, our model outperforms several 8B+\nparameters on CODA AD corner case reasoning task. Compared to existing methods\nbased on open-source models and data, our approach achieves state-of-the-art\nperformance with significantly reduced activated model size (at least by\n$62.5\\%$) with a single-turn conversation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6280\u80fd\u5bfc\u5411\u7684\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff08MoSE\uff09\uff0c\u6a21\u4eff\u4eba\u7c7b\u9a7e\u9a76\u5458\u7684\u5b66\u4e60\u548c\u63a8\u7406\u8fc7\u7a0b\uff0c\u901a\u8fc7\u6280\u80fd\u5bfc\u5411\u7684\u8def\u7531\u673a\u5236\u548c\u5c42\u6b21\u5316\u6280\u80fd\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff08MoE\uff09\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u548c\u590d\u6742\u4f18\u5316\uff0c\u800c\u4eba\u7c7b\u9a7e\u9a76\u5458\u7684\u5b66\u4e60\u8fc7\u7a0b\u66f4\u9ad8\u6548\u3002\u53d7\u6b64\u542f\u53d1\uff0c\u4f5c\u8005\u63d0\u51fa\u6280\u80fd\u5bfc\u5411\u7684MoSE\u6a21\u578b\uff0c\u4ee5\u66f4\u9ad8\u6548\u5730\u5b9e\u73b0\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u6280\u80fd\u5bfc\u5411\u8def\u7531\u673a\u5236\uff0c\u5b9a\u4e49\u548c\u6807\u6ce8\u7279\u5b9a\u6280\u80fd\uff0c\u6784\u5efa\u5c42\u6b21\u5316\u6280\u80fd\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u5355\u6b21\u524d\u5411\u8fc7\u7a0b\u6574\u5408\u8f85\u52a9\u4efb\u52a1\uff08\u5982\u63cf\u8ff0\u3001\u63a8\u7406\u3001\u89c4\u5212\uff09\u3002", "result": "MoSE\u6a21\u578b\u5728CODA AD\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u591a\u4e2a8B+\u53c2\u6570\u6a21\u578b\uff0c\u6fc0\u6d3b\u53c2\u6570\u91cf\u51cf\u5c11\u81f3\u5c1162.5%\uff0c\u4e14\u6027\u80fd\u8fbe\u5230SOTA\u3002", "conclusion": "MoSE\u901a\u8fc7\u6a21\u4eff\u4eba\u7c7b\u9a7e\u9a76\u5458\u7684\u5b66\u4e60\u548c\u63a8\u7406\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2507.07820", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07820", "abs": "https://arxiv.org/abs/2507.07820", "authors": ["Eunsu Baek", "Keondo Park", "Jeonggil Ko", "Min-hwan Oh", "Taesik Gong", "Hyung-Sin Kim"], "title": "AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift", "comment": null, "summary": "Current AI advances largely rely on scaling neural models and expanding\ntraining datasets to achieve generalization and robustness. Despite notable\nsuccesses, this paradigm incurs significant environmental, economic, and\nethical costs, limiting sustainability and equitable access. Inspired by\nbiological sensory systems, where adaptation occurs dynamically at the input\n(e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive\nsensing as a necessary and foundational shift. Adaptive sensing proactively\nmodulates sensor parameters (e.g., exposure, sensitivity, multimodal\nconfigurations) at the input level, significantly mitigating covariate shifts\nand improving efficiency. Empirical evidence from recent studies demonstrates\nthat adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass\nsubstantially larger models (e.g., OpenCLIP-H) trained with significantly more\ndata and compute. We (i) outline a roadmap for broadly integrating adaptive\nsensing into real-world applications spanning humanoid, healthcare, autonomous\nsystems, agriculture, and environmental monitoring, (ii) critically assess\ntechnical and ethical integration challenges, and (iii) propose targeted\nresearch directions, such as standardized benchmarks, real-time adaptive\nalgorithms, multimodal integration, and privacy-preserving methods.\nCollectively, these efforts aim to transition the AI community toward\nsustainable, robust, and equitable artificial intelligence systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u81ea\u9002\u5e94\u611f\u77e5\u4f5c\u4e3aAI\u53d1\u5c55\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4f20\u611f\u5668\u53c2\u6570\u63d0\u5347\u6548\u7387\uff0c\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u5f53\u524dAI\u4f9d\u8d56\u5927\u89c4\u6a21\u6a21\u578b\u548c\u6570\u636e\u96c6\uff0c\u5bfc\u81f4\u73af\u5883\u3001\u7ecf\u6d4e\u548c\u4f26\u7406\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u6301\u7eed\u548c\u666e\u53ca\u3002\u751f\u7269\u611f\u5b98\u7cfb\u7edf\u7684\u52a8\u6001\u9002\u5e94\u6027\u542f\u53d1\u4e86\u8fd9\u4e00\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u611f\u77e5\uff0c\u52a8\u6001\u8c03\u6574\u4f20\u611f\u5668\u53c2\u6570\uff08\u5982\u66dd\u5149\u3001\u7075\u654f\u5ea6\u3001\u591a\u6a21\u6001\u914d\u7f6e\uff09\uff0c\u4ee5\u51cf\u5c11\u534f\u53d8\u91cf\u504f\u79fb\u5e76\u63d0\u5347\u6548\u7387\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u81ea\u9002\u5e94\u611f\u77e5\u80fd\u8ba9\u5c0f\u6a21\u578b\uff08\u5982EfficientNet-B0\uff09\u8d85\u8d8a\u66f4\u5927\u6a21\u578b\uff08\u5982OpenCLIP-H\uff09\u3002", "conclusion": "\u8bba\u6587\u547c\u5401\u5c06\u81ea\u9002\u5e94\u611f\u77e5\u6574\u5408\u5230\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5e76\u63d0\u51fa\u7814\u7a76\u65b9\u5411\uff08\u5982\u6807\u51c6\u5316\u57fa\u51c6\u3001\u5b9e\u65f6\u7b97\u6cd5\u3001\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff09\uff0c\u4ee5\u63a8\u52a8\u53ef\u6301\u7eed\u3001\u9c81\u68d2\u548c\u516c\u5e73\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2507.07857", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07857", "abs": "https://arxiv.org/abs/2507.07857", "authors": ["Samuel Reyd", "Ada Diaconescu", "Jean-Louis Dessalles"], "title": "Searching for actual causes: Approximate algorithms with adjustable precision", "comment": null, "summary": "Causality has gained popularity in recent years. It has helped improve the\nperformance, reliability, and interpretability of machine learning models.\nHowever, recent literature on explainable artificial intelligence (XAI) has\nfaced criticism. The classical XAI and causality literature focuses on\nunderstanding which factors contribute to which consequences. While such\nknowledge is valuable for researchers and engineers, it is not what non-expert\nusers expect as explanations. Instead, these users often await facts that cause\nthe target consequences, i.e., actual causes. Formalizing this notion is still\nan open problem. Additionally, identifying actual causes is reportedly an\nNP-complete problem, and there are too few practical solutions to approximate\nformal definitions. We propose a set of algorithms to identify actual causes\nwith a polynomial complexity and an adjustable level of precision and\nexhaustiveness. Our experiments indicate that the algorithms (1) identify\ncauses for different categories of systems that are not handled by existing\napproaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be\nadjusted to gain more precision and exhaustiveness with more computation time.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9879\u5f0f\u590d\u6742\u5ea6\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u5b9e\u9645\u539f\u56e0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u7684\u975e\u5e03\u5c14\u3001\u9ed1\u76d2\u548c\u968f\u673a\u7cfb\u7edf\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u548c\u56e0\u679c\u6027\u7814\u7a76\u672a\u80fd\u6ee1\u8db3\u975e\u4e13\u5bb6\u7528\u6237\u5bf9\u89e3\u91ca\u7684\u9700\u6c42\uff0c\u5373\u5b9e\u9645\u539f\u56e0\u3002\u8bc6\u522b\u5b9e\u9645\u539f\u56e0\u662f\u4e00\u4e2aNP\u5b8c\u5168\u95ee\u9898\uff0c\u4e14\u7f3a\u4e4f\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u7ec4\u591a\u9879\u5f0f\u590d\u6742\u5ea6\u7684\u7b97\u6cd5\uff0c\u53ef\u8c03\u6574\u7cbe\u5ea6\u548c\u5b8c\u5907\u6027\uff0c\u9002\u7528\u4e8e\u975e\u5e03\u5c14\u3001\u9ed1\u76d2\u548c\u968f\u673a\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7b97\u6cd5\u80fd\u8bc6\u522b\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u7684\u7cfb\u7edf\u539f\u56e0\uff0c\u4e14\u53ef\u901a\u8fc7\u589e\u52a0\u8ba1\u7b97\u65f6\u95f4\u63d0\u9ad8\u7cbe\u5ea6\u548c\u5b8c\u5907\u6027\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u4e3a\u89e3\u51b3\u5b9e\u9645\u539f\u56e0\u8bc6\u522b\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.07893", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07893", "abs": "https://arxiv.org/abs/2507.07893", "authors": ["Mingda Zhang", "Na Zhao", "Jianglong Qing", "Qing xu", "Kaiwen Pan", "Ting luo"], "title": "An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis", "comment": "15 pages,3 figures", "summary": "The rapid development of artificial intelligence has positioned large\nlanguage models as fundamental components of intelligent legal systems.\nHowever, these models face significant limitations in legal dispute analysis,\nincluding insufficient legal knowledge representation, limited concept\nunderstanding, and reasoning deficiencies. This research proposes an enhanced\nframework integrating prompt engineering with multidimensional knowledge\ngraphs. The framework introduces a three-stage hierarchical prompt structure\ncomprising task definition, knowledge background, and reasoning guidance,\nsupplemented by legal-specific reasoning templates and dynamic optimization\nmechanisms. A three-layer knowledge graph architecture is constructed with\nlegal classification ontology, representation, and instance layers. Four\ncomplementary methods enable precise legal concept retrieval: direct legal norm\ncode matching, domain-specific semantic vector similarity, ontology-based path\nreasoning, and specialized lexical segmentation. These components integrate\nwith web search technology to establish a knowledge-enhanced framework for\nlegal decision-making. Experimental results demonstrate significant performance\nimprovements in legal dispute analysis, enabling accurate legal application\nanalysis for complex cases while exhibiting nuanced understanding of judicial\ndecision-making logic, providing a novel technical approach for implementing\nintelligent legal assistance systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u548c\u591a\u7ef4\u77e5\u8bc6\u56fe\u8c31\u7684\u589e\u5f3a\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u7ea0\u7eb7\u5206\u6790\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u7ea0\u7eb7\u5206\u6790\u4e2d\u5b58\u5728\u6cd5\u5f8b\u77e5\u8bc6\u8868\u793a\u4e0d\u8db3\u3001\u6982\u5ff5\u7406\u89e3\u6709\u9650\u548c\u63a8\u7406\u7f3a\u9677\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u5206\u5c42\u63d0\u793a\u7ed3\u6784\u548c\u4e09\u5c42\u77e5\u8bc6\u56fe\u8c31\u67b6\u6784\uff0c\u7ed3\u5408\u56db\u79cd\u4e92\u8865\u7684\u6cd5\u5f8b\u6982\u5ff5\u68c0\u7d22\u65b9\u6cd5\uff0c\u5e76\u4e0e\u7f51\u7edc\u641c\u7d22\u6280\u672f\u96c6\u6210\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u5728\u6cd5\u5f8b\u7ea0\u7eb7\u5206\u6790\u4e2d\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u80fd\u591f\u51c6\u786e\u5206\u6790\u590d\u6742\u6848\u4f8b\u5e76\u7406\u89e3\u53f8\u6cd5\u51b3\u7b56\u903b\u8f91\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u667a\u80fd\u6cd5\u5f8b\u8f85\u52a9\u7cfb\u7edf\u7684\u5b9e\u73b0\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6280\u672f\u9014\u5f84\u3002"}}
{"id": "2507.07931", "categories": ["cs.AI", "cs.CY", "I.2.0; K.4.1"], "pdf": "https://arxiv.org/pdf/2507.07931", "abs": "https://arxiv.org/abs/2507.07931", "authors": ["Hans Gundlach", "Jayson Lynch", "Neil Thompson"], "title": "Meek Models Shall Inherit the Earth", "comment": "13 pages, 9 figures, longer version of the paper presented at TAIG\n  ICML 2025", "summary": "The past decade has seen incredible scaling of AI systems by a few companies,\nleading to inequality in AI model performance. This paper argues that, contrary\nto prevailing intuition, the diminishing returns to compute scaling will lead\nto a convergence of AI model capabilities. In other words, meek models (those\nwith limited computation budget) shall inherit the earth, approaching the\nperformance level of the best models overall. We develop a model illustrating\nthat under a fixed-distribution next-token objective, the marginal capability\nreturns to raw compute shrink substantially. Given current scaling practices,\nwe argue that these diminishing returns are strong enough that even companies\nthat can scale their models exponentially faster than other organizations will\neventually have little advantage in capabilities. As part of our argument, we\ngive several reasons that proxies like training loss differences capture\nimportant capability measures using evidence from benchmark data and\ntheoretical performance models. In addition, we analyze empirical data on the\ncapability difference of AI models over time. Finally, in light of the\nincreasing ability of meek models, we argue that AI strategy and policy require\nreexamination, and we outline the areas this shift will affect.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\uff0c\u968f\u7740\u8ba1\u7b97\u89c4\u6a21\u6269\u5927\u5e26\u6765\u7684\u8fb9\u9645\u6536\u76ca\u9012\u51cf\uff0cAI\u6a21\u578b\u6027\u80fd\u5c06\u8d8b\u4e8e\u6536\u655b\uff0c\u5373\u4f7f\u9884\u7b97\u6709\u9650\u7684\u6a21\u578b\u4e5f\u80fd\u63a5\u8fd1\u6700\u4f73\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u63a2\u8ba8AI\u6a21\u578b\u6027\u80fd\u4e0d\u5e73\u7b49\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u8ba1\u7b97\u89c4\u6a21\u6269\u5927\u5e26\u6765\u7684\u8fb9\u9645\u6536\u76ca\u9012\u51cf\u5c06\u5bfc\u81f4\u6027\u80fd\u6536\u655b\u3002", "method": "\u5f00\u53d1\u6a21\u578b\u5206\u6790\u8ba1\u7b97\u89c4\u6a21\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7ed3\u5408\u57fa\u51c6\u6570\u636e\u548c\u7406\u8bba\u6a21\u578b\u9a8c\u8bc1\u3002", "result": "\u8ba1\u7b97\u89c4\u6a21\u6269\u5927\u5e26\u6765\u7684\u8fb9\u9645\u6536\u76ca\u9012\u51cf\uff0c\u4f7f\u5f97\u9884\u7b97\u6709\u9650\u7684\u6a21\u578b\u6027\u80fd\u63a5\u8fd1\u6700\u4f73\u6a21\u578b\u3002", "conclusion": "AI\u6218\u7565\u548c\u653f\u7b56\u9700\u91cd\u65b0\u5ba1\u89c6\uff0c\u4ee5\u9002\u5e94\u6027\u80fd\u6536\u655b\u7684\u8d8b\u52bf\u3002"}}
{"id": "2507.07935", "categories": ["cs.AI", "cs.CY", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2507.07935", "abs": "https://arxiv.org/abs/2507.07935", "authors": ["Kiran Tomlinson", "Sonia Jaffe", "Will Wang", "Scott Counts", "Siddharth Suri"], "title": "Working with AI: Measuring the Occupational Implications of Generative AI", "comment": "40 pages", "summary": "Given the rapid adoption of generative AI and its potential to impact a wide\nrange of tasks, understanding the effects of AI on the economy is one of\nsociety's most important questions. In this work, we take a step toward that\ngoal by analyzing the work activities people do with AI, how successfully and\nbroadly those activities are done, and combine that with data on what\noccupations do those activities. We analyze a dataset of 200k anonymized and\nprivacy-scrubbed conversations between users and Microsoft Bing Copilot, a\npublicly available generative AI system. We find the most common work\nactivities people seek AI assistance for involve gathering information and\nwriting, while the most common activities that AI itself is performing are\nproviding information and assistance, writing, teaching, and advising.\nCombining these activity classifications with measurements of task success and\nscope of impact, we compute an AI applicability score for each occupation. We\nfind the highest AI applicability scores for knowledge work occupation groups\nsuch as computer and mathematical, and office and administrative support, as\nwell as occupations such as sales whose work activities involve providing and\ncommunicating information. Additionally, we characterize the types of work\nactivities performed most successfully, how wage and education correlate with\nAI applicability, and how real-world usage compares to predictions of\noccupational AI impact.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u751f\u6210\u5f0fAI\u5bf9\u7ecf\u6d4e\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u7528\u6237\u4e0e\u5fae\u8f6fBing Copilot\u7684\u4e92\u52a8\u6570\u636e\uff0c\u53d1\u73b0AI\u4e3b\u8981\u5e94\u7528\u4e8e\u4fe1\u606f\u6536\u96c6\u3001\u5199\u4f5c\u7b49\u6d3b\u52a8\uff0c\u5e76\u8ba1\u7b97\u4e86\u5404\u804c\u4e1a\u7684AI\u9002\u7528\u6027\u5206\u6570\u3002", "motivation": "\u7406\u89e3AI\u5bf9\u7ecf\u6d4e\u7684\u5e7f\u6cdb\u5f71\u54cd\u662f\u793e\u4f1a\u7684\u5173\u952e\u95ee\u9898\u3002", "method": "\u5206\u6790\u4e8620\u4e07\u6761\u7528\u6237\u4e0e\u5fae\u8f6fBing Copilot\u7684\u533f\u540d\u5bf9\u8bdd\u6570\u636e\uff0c\u7ed3\u5408\u804c\u4e1a\u6d3b\u52a8\u5206\u7c7b\u548c\u4efb\u52a1\u6210\u529f\u5ea6\u91cf\u3002", "result": "\u77e5\u8bc6\u578b\u804c\u4e1a\uff08\u5982\u8ba1\u7b97\u673a\u3001\u6570\u5b66\u3001\u884c\u653f\u652f\u6301\uff09\u548c\u9500\u552e\u804c\u4e1a\u7684AI\u9002\u7528\u6027\u6700\u9ad8\u3002", "conclusion": "AI\u5728\u4fe1\u606f\u5904\u7406\u548c\u6c9f\u901a\u5bc6\u96c6\u578b\u804c\u4e1a\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u5b9e\u9645\u4f7f\u7528\u4e0e\u9884\u6d4b\u76f8\u7b26\u3002"}}
