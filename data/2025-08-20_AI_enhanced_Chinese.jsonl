{"id": "2508.13214", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13214", "abs": "https://arxiv.org/abs/2508.13214", "authors": ["Xuyang Guo", "Zekai Huang", "Zhao Song", "Jiahao Zhang"], "title": "Too Easily Fooled? Prompt Injection Breaks LLMs on Frustratingly Simple Multiple-Choice Questions", "comment": null, "summary": "Large Language Models (LLMs) have recently demonstrated strong emergent\nabilities in complex reasoning and zero-shot generalization, showing\nunprecedented potential for LLM-as-a-judge applications in education, peer\nreview, and data quality evaluation. However, their robustness under prompt\ninjection attacks, where malicious instructions are embedded into the content\nto manipulate outputs, remains a significant concern. In this work, we explore\na frustratingly simple yet effective attack setting to test whether LLMs can be\neasily misled. Specifically, we evaluate LLMs on basic arithmetic questions\n(e.g., \"What is 3 + 2?\") presented as either multiple-choice or true-false\njudgment problems within PDF files, where hidden prompts are injected into the\nfile. Our results reveal that LLMs are indeed vulnerable to such hidden prompt\ninjection attacks, even in these trivial scenarios, highlighting serious\nrobustness risks for LLM-as-a-judge applications.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5728PDF\u6587\u4ef6\u4e2d\u7a81\u7834\u9690\u85cf\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5728\u57fa\u672c\u7b97\u672f\u95ee\u9898\u4e2d\u5bb9\u6613\u88ab\u6b3a\u9a97\u4ea7\u751f\u9519\u8bef\u7b54\u6848", "motivation": "\u8bc6\u522bLLM\u4f5c\u4e3a\u5224\u65ad\u8005\u5e94\u7528\u5728\u6559\u80b2\u3001\u540c\u884c\u5ba1\u67e5\u7b49\u573a\u666f\u4e2d\u7684\u6f0f\u6d1e\uff0c\u800c\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5bf9\u5176\u7a33\u5065\u6027\u6784\u6210\u4e86\u91cd\u5927\u5a01\u80c1", "method": "\u901a\u8fc7\u5728PDF\u6587\u4ef6\u4e2d\u6ce8\u5165\u9690\u85cf\u7684\u6076\u610f\u63d0\u793a\uff0c\u6d4b\u8bd5LLM\u5728\u57fa\u672c\u7b97\u672f\u95ee\u9898\uff08\u5982\"3+2\"\uff09\u3001\u591a\u9009\u9898\u548c\u771f\u4f2a\u5224\u65ad\u4efb\u52a1\u4e2d\u7684\u5f02\u5e38\u884c\u4e3a", "result": "\u7ed3\u679c\u663e\u793aLLM\u5728\u8fd9\u4e9b\u7b80\u5355\u573a\u666f\u4e2d\u4e5f\u5bb9\u6613\u53d7\u5230\u9690\u85cf\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u4ea7\u751f\u9519\u8bef\u7b54\u6848", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86LLM\u4f5c\u4e3a\u5224\u65ad\u8005\u5e94\u7528\u7684\u4e25\u91cd\u5b89\u5168\u98ce\u9669\uff0c\u5448\u73b0\u4e86\u4e00\u79cd\u7b80\u5355\u4f46\u6709\u6548\u7684\u653b\u51fb\u65b9\u5f0f\uff0c\u547d\u4e2d\u4e86\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e"}}
{"id": "2508.13220", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13220", "abs": "https://arxiv.org/abs/2508.13220", "authors": ["Yixuan Yang", "Daoyuan Wu", "Yufan Chen"], "title": "MCPSecBench: A Systematic Security Benchmark and Playground for Testing Model Context Protocols", "comment": "This is a technical report from Lingnan University, Hong Kong", "summary": "Large Language Models (LLMs) are increasingly integrated into real-world\napplications via the Model Context Protocol (MCP), a universal, open standard\nfor connecting AI agents with data sources and external tools. While MCP\nenhances the capabilities of LLM-based agents, it also introduces new security\nrisks and expands their attack surfaces. In this paper, we present the first\nsystematic taxonomy of MCP security, identifying 17 attack types across 4\nprimary attack surfaces. We introduce MCPSecBench, a comprehensive security\nbenchmark and playground that integrates prompt datasets, MCP servers, MCP\nclients, and attack scripts to evaluate these attacks across three major MCP\nproviders. Our benchmark is modular and extensible, allowing researchers to\nincorporate custom implementations of clients, servers, and transport protocols\nfor systematic security assessment. Experimental results show that over 85% of\nthe identified attacks successfully compromise at least one platform, with core\nvulnerabilities universally affecting Claude, OpenAI, and Cursor, while\nprompt-based and tool-centric attacks exhibit considerable variability across\ndifferent hosts and models. Overall, MCPSecBench standardizes the evaluation of\nMCP security and enables rigorous testing across all MCP layers.", "AI": {"tldr": "\u9996\u4e2a\u7cfb\u7edf\u6027\u7684MCP\u5b89\u5168\u5206\u7c7b\u6cd5\uff0c\u63d0\u51faMCPSecBench\u8bc4\u6d4b\u6846\u67b6\uff0c\u8bc6\u522b\u4e8617\u79cd\u653b\u51fb\u7c7b\u578b\uff0c\u8fc7\u8d8585%\u653b\u51fb\u6210\u529f\u7a81\u7834\u4e3b\u8981\u5e73\u53f0", "motivation": "\u8bc6\u522b\u548c\u5206\u6790Model Context Protocol (MCP)\u96c6\u6210\u5230LLM\u5e94\u7528\u4e2d\u5e26\u6765\u7684\u65b0\u5b89\u5168\u98ce\u9669\u548c\u653b\u51fb\u9762", "method": "\u5efa\u7acb\u4e8617\u79cd\u653b\u51fb\u7c7b\u578b\u7684\u7cfb\u7edf\u5206\u7c7b\u6cd5\uff0c\u5f00\u53d1MCPSecBench\u8bc4\u6d4b\u6846\u67b6\uff0c\u5305\u542b\u63d0\u793a\u6570\u636e\u96c6\u3001MCP\u670d\u52a1\u5668\u3001\u5ba2\u6237\u7aef\u548c\u653b\u51fb\u811a\u672c", "result": "85%\u4ee5\u4e0a\u7684\u8bc6\u522b\u653b\u51fb\u6210\u529f\u7a81\u7834\u81f3\u5c11\u4e00\u4e2a\u5e73\u53f0\uff0c\u6838\u5fc3\u6f0f\u6d1e\u666e\u904d\u5f71\u54cdClaude\u3001OpenAI\u548cCursor\uff0c\u63d0\u793a\u57fa\u4e8e\u548c\u5de5\u5177\u805a\u7126\u653b\u51fb\u5728\u4e0d\u540c\u5e73\u53f0\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02", "conclusion": "MCPSecBench\u6807\u51c6\u5316\u4e86MCP\u5b89\u5168\u8bc4\u4f30\uff0c\u652f\u6301\u5728\u6240\u6709MCP\u5c42\u9762\u8fdb\u884c\u4e25\u683c\u6d4b\u8bd5\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u53ef\u6269\u5c55\u7684\u5b89\u5168\u8bc4\u4f30\u5de5\u5177"}}
{"id": "2508.13240", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13240", "abs": "https://arxiv.org/abs/2508.13240", "authors": ["Soham Hans", "Nikolos Gurney", "Stacy Marsella", "Sofia Hirschmann"], "title": "Quantifying Loss Aversion in Cyber Adversaries via LLM Analysis", "comment": null, "summary": "Understanding and quantifying human cognitive biases from empirical data has\nlong posed a formidable challenge, particularly in cybersecurity, where\ndefending against unknown adversaries is paramount. Traditional cyber defense\nstrategies have largely focused on fortification, while some approaches attempt\nto anticipate attacker strategies by mapping them to cognitive vulnerabilities,\nyet they fall short in dynamically interpreting attacks in progress. In\nrecognition of this gap, IARPA's ReSCIND program seeks to infer, defend\nagainst, and even exploit attacker cognitive traits. In this paper, we present\na novel methodology that leverages large language models (LLMs) to extract\nquantifiable insights into the cognitive bias of loss aversion from hacker\nbehavior. Our data are collected from an experiment in which hackers were\nrecruited to attack a controlled demonstration network. We process the hacker\ngenerated notes using LLMs using it to segment the various actions and\ncorrelate the actions to predefined persistence mechanisms used by hackers. By\ncorrelating the implementation of these mechanisms with various operational\ntriggers, our analysis provides new insights into how loss aversion manifests\nin hacker decision-making. The results demonstrate that LLMs can effectively\ndissect and interpret nuanced behavioral patterns, thereby offering a\ntransformative approach to enhancing cyber defense strategies through\nreal-time, behavior-based analysis.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5206\u6790\u9ed1\u5ba2\u884c\u4e3a\u4e2d\u7684\u635f\u5931\u538c\u6076\u8ba4\u77e5\u504f\u5dee\uff0c\u4e3a\u7f51\u7edc\u9632\u5fa1\u63d0\u4f9b\u5b9e\u65f6\u884c\u4e3a\u5206\u6790\u65b0\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u7f51\u7edc\u9632\u5fa1\u7b56\u7565\u4e3b\u8981\u5173\u6ce8\u52a0\u56fa\u9632\u62a4\uff0c\u4f46\u7f3a\u4e4f\u52a8\u6001\u89e3\u91ca\u653b\u51fb\u8fc7\u7a0b\u4e2d\u653b\u51fb\u8005\u8ba4\u77e5\u7279\u5f81\u7684\u80fd\u529b\u3002IARPA\u7684ReSCIND\u9879\u76ee\u65e8\u5728\u63a8\u65ad\u3001\u9632\u5fa1\u751a\u81f3\u5229\u7528\u653b\u51fb\u8005\u7684\u8ba4\u77e5\u7279\u5f81\uff0c\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d", "method": "\u901a\u8fc7\u5b9e\u9a8c\u6536\u96c6\u9ed1\u5ba2\u653b\u51fb\u53d7\u63a7\u6f14\u793a\u7f51\u7edc\u7684\u884c\u4e3a\u6570\u636e\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u9ed1\u5ba2\u751f\u6210\u7684\u7b14\u8bb0\uff0c\u5206\u5272\u5404\u79cd\u884c\u52a8\u5e76\u5c06\u5176\u4e0e\u9884\u5b9a\u4e49\u7684\u9ed1\u5ba2\u6301\u4e45\u5316\u673a\u5236\u76f8\u5173\u8054\uff0c\u5206\u6790\u8fd9\u4e9b\u673a\u5236\u5b9e\u65bd\u4e0e\u64cd\u4f5c\u89e6\u53d1\u56e0\u7d20\u7684\u5173\u7cfb", "result": "\u5206\u6790\u63ed\u793a\u4e86\u635f\u5931\u538c\u6076\u5728\u9ed1\u5ba2\u51b3\u7b56\u4e2d\u7684\u8868\u73b0\u65b9\u5f0f\uff0c\u8bc1\u660e\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u5256\u6790\u548c\u89e3\u91ca\u7ec6\u5fae\u7684\u884c\u4e3a\u6a21\u5f0f", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u901a\u8fc7\u5b9e\u65f6\u884c\u4e3a\u5206\u6790\u589e\u5f3a\u7f51\u7edc\u9632\u5fa1\u7b56\u7565\u63d0\u4f9b\u4e86\u53d8\u9769\u6027\u9014\u5f84\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91cf\u5316\u8ba4\u77e5\u504f\u5dee\u65b9\u9762\u5c55\u73b0\u51fa\u5f3a\u5927\u6f5c\u529b"}}
{"id": "2508.13246", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13246", "abs": "https://arxiv.org/abs/2508.13246", "authors": ["Yangyang Guo", "Yangyan Li", "Mohan Kankanhalli"], "title": "Involuntary Jailbreak", "comment": "We plan to temporarily restrict access to the github code due to\n  potential risks of malicious use. But in the meantime, you can try using the\n  prompt, provided it hasn't been banned", "summary": "In this study, we disclose a worrying new vulnerability in Large Language\nModels (LLMs), which we term \\textbf{involuntary jailbreak}. Unlike existing\njailbreak attacks, this weakness is distinct in that it does not involve a\nspecific attack objective, such as generating instructions for \\textit{building\na bomb}. Prior attack methods predominantly target localized components of the\nLLM guardrail. In contrast, involuntary jailbreaks may potentially compromise\nthe entire guardrail structure, which our method reveals to be surprisingly\nfragile. We merely employ a single universal prompt to achieve this goal. In\nparticular, we instruct LLMs to generate several questions that would typically\nbe rejected, along with their corresponding in-depth responses (rather than a\nrefusal). Remarkably, this simple prompt strategy consistently jailbreaks the\nmajority of leading LLMs, including Claude Opus 4.1, Grok 4, Gemini 2.5 Pro,\nand GPT 4.1. We hope this problem can motivate researchers and practitioners to\nre-evaluate the robustness of LLM guardrails and contribute to stronger safety\nalignment in future.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u5b58\u5728\u4e00\u79cd\u65b0\u578b\u6f0f\u6d1e\"\u975e\u81ea\u613f\u8d8a\u72f1\"\uff0c\u4ec5\u9700\u5355\u4e00\u901a\u7528\u63d0\u793a\u5c31\u80fd\u7ed5\u8fc7\u4e3b\u6d41LLMs\u7684\u5b89\u5168\u9632\u62a4\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u8d8a\u72f1\u653b\u51fb\u4e3b\u8981\u9488\u5bf9LLM\u9632\u62a4\u673a\u5236\u7684\u5c40\u90e8\u7ec4\u4ef6\uff0c\u800c\u672c\u7814\u7a76\u65e8\u5728\u63ed\u793a\u6574\u4e2a\u9632\u62a4\u7ed3\u6784\u7684\u8106\u5f31\u6027\u3002", "method": "\u4f7f\u7528\u5355\u4e00\u901a\u7528\u63d0\u793a\uff0c\u8981\u6c42LLMs\u751f\u6210\u901a\u5e38\u4f1a\u88ab\u62d2\u7edd\u7684\u95ee\u9898\u53ca\u5176\u6df1\u5ea6\u56de\u7b54\uff08\u800c\u975e\u62d2\u7edd\u56de\u7b54\uff09\u3002", "result": "\u8fd9\u79cd\u7b80\u5355\u63d0\u793a\u7b56\u7565\u80fd\u6301\u7eed\u7ed5\u8fc7\u5927\u591a\u6570\u4e3b\u6d41LLMs\uff0c\u5305\u62ecClaude Opus 4.1\u3001Grok 4\u3001Gemini 2.5 Pro\u548cGPT 4.1\u3002", "conclusion": "\u8be5\u95ee\u9898\u9700\u8981\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u91cd\u65b0\u8bc4\u4f30LLM\u9632\u62a4\u673a\u5236\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u4fc3\u8fdb\u672a\u6765\u66f4\u5f3a\u7684\u5b89\u5168\u5bf9\u9f50\u3002"}}
{"id": "2508.13396", "categories": ["cs.SE", "68P20 (Primary), 68M14 (Secondary)"], "pdf": "https://arxiv.org/pdf/2508.13396", "abs": "https://arxiv.org/abs/2508.13396", "authors": ["Dinesh Eswararaj", "Ajay Babu Nellipudi", "Vandana Kollati"], "title": "A Comparative Study of Delta Parquet, Iceberg, and Hudi for Automotive Data Engineering Use Cases", "comment": "Published in SSRG International Journal of Computer Science and\n  Engineering (IJCSE), July 2025. This is the authors accepted manuscript. The\n  final published version is available", "summary": "The automotive industry generates vast amounts of data from sensors,\ntelemetry, diagnostics, and real-time operations. Efficient data engineering is\ncritical to handle challenges of latency, scalability, and consistency. Modern\ndata lakehouse formats Delta Parquet, Apache Iceberg, and Apache Hudi offer\nfeatures such as ACID transactions, schema enforcement, and real-time\ningestion, combining the strengths of data lakes and warehouses to support\ncomplex use cases. This study presents a comparative analysis of Delta Parquet,\nIceberg, and Hudi using real-world time-series automotive telemetry data with\nfields such as vehicle ID, timestamp, location, and event metrics. The\nevaluation considers modeling strategies, partitioning, CDC support, query\nperformance, scalability, data consistency, and ecosystem maturity. Key\nfindings show Delta Parquet provides strong ML readiness and governance,\nIceberg delivers high performance for batch analytics and cloud-native\nworkloads, while Hudi is optimized for real-time ingestion and incremental\nprocessing. Each format exhibits tradeoffs in query efficiency, time-travel,\nand update semantics. The study offers insights for selecting or combining\nformats to support fleet management, predictive maintenance, and route\noptimization. Using structured datasets and realistic queries, the results\nprovide practical guidance for scaling data pipelines and integrating machine\nlearning models in automotive applications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5bf9\u6c7d\u8f66\u884c\u4e1a\u4e2d\u4e09\u79cd\u4e3b\u6d41\u6570\u636e\u6e56\u4ed3\u683c\u5f0f(Delta Parquet\u3001Apache Iceberg\u3001Apache Hudi)\u8fdb\u884c\u4e86\u5b9e\u9645\u6027\u80fd\u6bd4\u8f83\u5206\u6790\uff0c\u4e3a\u6c7d\u8f66\u6570\u636e\u7ba1\u7406\u63d0\u4f9b\u9009\u578b\u6307\u5357", "motivation": "\u6c7d\u8f66\u884c\u4e1a\u4ea7\u751f\u5927\u91cf\u4f20\u611f\u5668\u3001\u8fdc\u7a0b\u6d4b\u91cf\u548c\u5b9e\u65f6\u6570\u636e\uff0c\u9700\u8981\u9ad8\u6548\u6570\u636e\u5de5\u7a0b\u5904\u7406\u65b9\u6848\u6765\u5e94\u5bf9\u5ef6\u8fdf\u3001\u6269\u5c55\u6027\u548c\u4e00\u81f4\u6027\u6311\u6218", "method": "\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u7684\u65f6\u95f4\u5e8f\u5217\u6c7d\u8f66\u8fdc\u7a0b\u6d4b\u91cf\u6570\u636e\uff0c\u8bc4\u4f30\u4e09\u79cd\u683c\u5f0f\u5728\u5efa\u6a21\u7b56\u7565\u3001\u5206\u533a\u3001CDC\u652f\u6301\u3001\u67e5\u8be2\u6027\u80fd\u3001\u6269\u5c55\u6027\u3001\u6570\u636e\u4e00\u81f4\u6027\u548c\u751f\u6001\u7cfb\u7edf\u6210\u719f\u5ea6\u65b9\u9762\u7684\u8868\u73b0", "result": "Delta Parquet\u5728\u673a\u5668\u5b66\u4e60\u51c6\u5907\u548c\u6570\u636e\u7ba1\u7406\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0cIceberg\u5728\u6279\u5904\u7406\u5206\u6790\u548c\u4e91\u539f\u751f\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u663e\u793a\u9ad8\u6027\u80fd\uff0cHudi\u5728\u5b9e\u65f6\u6570\u636e\u5438\u6536\u548c\u589e\u91cf\u5904\u7406\u65b9\u9762\u6700\u4f18\uff0c\u5404\u683c\u5f0f\u5728\u67e5\u8be2\u6548\u7387\u3001\u65f6\u95f4\u65c5\u884c\u548c\u66f4\u65b0\u8bed\u4e49\u65b9\u9762\u6709\u4e0d\u540c\u4ea4\u6613", "conclusion": "\u7814\u7a76\u4e3a\u6c7d\u8f66\u884c\u4e1a\u9009\u62e9\u6216\u7ec4\u5408\u4f7f\u7528\u4e0d\u540c\u6570\u636e\u6e56\u4ed3\u683c\u5f0f\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\uff0c\u652f\u6301\u8f66\u961f\u7ba1\u7406\u3001\u9884\u6d4b\u6027\u7ef4\u62a4\u548c\u8def\u7ebf\u4f18\u5316\u7b49\u5e94\u7528\u573a\u666f\uff0c\u4e3a\u6269\u5c55\u6570\u636e\u7ba1\u9053\u548c\u96c6\u6210\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u8df5\u5efa\u8bae"}}
{"id": "2508.13167", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.13167", "abs": "https://arxiv.org/abs/2508.13167", "authors": ["Weizhen Li", "Jianbo Lin", "Zhuosong Jiang", "Jingyi Cao", "Xinpeng Liu", "Jiayu Zhang", "Zhenqiang Huang", "Qianben Chen", "Weichen Sun", "Qiexiang Wang", "Hongxuan Lu", "Tianrui Qin", "Chenghao Zhu", "Yi Yao", "Shuying Fan", "Xiaowan Li", "Tiannan Wang", "Pai Liu", "King Zhu", "He Zhu", "Dingfeng Shi", "Piaohong Wang", "Yeyi Guan", "Xiangru Tang", "Minghao Liu", "Yuchen Eleanor Jiang", "Jian Yang", "Jiaheng Liu", "Ge Zhang", "Wangchunshu Zhou"], "title": "Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL", "comment": "51 pages", "summary": "Recent advances in large language models (LLMs) and multi-agent systems have\ndemonstrated remarkable capabilities in complex problem-solving tasks such as\ndeep research, vibe coding, and mathematical reasoning. However, most existing\nmulti-agent systems are built upon manual prompt/workflow engineering with\nsophisticated agent frameworks, making them computationally inefficient, less\ncapable, and can not benefit from data-centric learning. In this work, we\nintroduce Chain-of-Agents (CoA), a novel paradigm of LLM reasoning that enables\nnative end-to-end complex problem-solving in the same way as a multi-agent\nsystem (i.e., multi-turn problem solving with multiple tools and multiple\nagents) within one model. In chain-of-agents problem-solving, the model\ndynamically activates different tool agents and role-playing agents to simulate\nmulti-agent collaboration in an end-to-end fashion. To elicit end-to-end\nchain-of-agents problem-solving abilities in LLMs, we introduce a multi-agent\ndistillation framework to distill state-of-the-art multi-agent systems into\nchain-of-agents trajectories for agentic supervised fine-tuning. We then use\nagentic reinforcement learning on verifiable agentic tasks to further improve\nthe models' capabilities on chain-of-agents problem solving. We call the\nresulting models Agent Foundation Models (AFMs). Our empirical studies\ndemonstrate that AFM establishes new state-of-the-art performance across\ndiverse benchmarks in both web agent and code agent settings. We make the\nentire research, including the model weights, code for training and evaluation,\nand the training data, fully open-sourced, which offers a solid starting point\nfor future research on agent models and agentic RL.", "AI": {"tldr": "\u94fe\u5f0f\u673a\u5668\u4eba\u6846\u67b6(CoA)\u901a\u8fc7\u591a\u673a\u5668\u8403\u53d6\u548c\u673a\u5668\u4eba\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u51fa\u7aef\u5230\u7aef\u7684\u673a\u5668\u4eba\u57fa\u7840\u6a21\u578b(AFM)\uff0c\u5728\u591a\u4efb\u52a1\u8d28\u91cf\u8bc4\u4f30\u4e2d\u8fbe\u5230\u6700\u4f73\u6027\u80fd", "motivation": "\u73b0\u6709\u591a\u673a\u5668\u7cfb\u7edf\u4f9d\u8d56\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\u548c\u590d\u6742\u6846\u67b6\uff0c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u65e0\u6cd5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60", "method": "\u63d0\u51fa\u94fe\u5f0f\u673a\u5668\u4eba\u6982\u5ff5\uff0c\u901a\u8fc7\u591a\u673a\u5668\u8403\u53d6\u83b7\u5f97\u76d1\u7763\u7cbe\u7ec6\u8c03\u6574\u6570\u636e\uff0c\u7136\u540e\u7528\u673a\u5668\u4eba\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd", "result": "AFM\u6a21\u578b\u5728web\u673a\u5668\u4eba\u548ccode\u673a\u5668\u4eba\u591a\u4e2a\u8bc4\u6d4b\u4efd\u4e0a\u521b\u9020\u4e86\u65b0\u7684\u6700\u4f73\u6027\u80fd\u8bb0\u5f55", "conclusion": "\u94fe\u5f0f\u673a\u5668\u4eba\u6846\u67b6\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u7aef\u5230\u7aef\u590d\u6742\u95ee\u9898\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5f00\u6e90\u4e86\u6240\u6709\u7814\u7a76\u6210\u679c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u57fa\u7840"}}
{"id": "2508.13357", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.13357", "abs": "https://arxiv.org/abs/2508.13357", "authors": ["Zhuoran Li", "Hanieh Totonchi Asl", "Ebrahim Nouri", "Yifei Cai", "Danella Zhao"], "title": "Silentflow: Leveraging Trusted Execution for Resource-Limited MPC via Hardware-Algorithm Co-design", "comment": null, "summary": "Secure Multi-Party Computation (MPC) offers a practical foundation for\nprivacy-preserving machine learning at the edge, with MPC commonly employed to\nsupport nonlinear operations. These MPC protocols fundamentally rely on\nOblivious Transfer (OT), particularly Correlated OT (COT), to generate\ncorrelated randomness essential for secure computation. Although COT generation\nis efficient in conventional two-party settings with resource-rich\nparticipants, it becomes a critical bottleneck in real-world inference on\nresource-constrained devices (e.g., IoT sensors and wearables), due to both\ncommunication latency and limited computational capacity. To enable real-time\nsecure inference, we introduce Silentflow, a highly efficient Trusted Execution\nEnvironment (TEE)-assisted protocol that eliminates communication in COT\ngeneration. We tackle the core performance bottleneck-low computational\nintensity-through structured algorithmic decomposition: kernel fusion for\nparallelism, Blocked On-chip eXpansion (BOX) to improve memory access patterns,\nand vectorized batch operations to maximize memory bandwidth utilization.\nThrough design space exploration, we balance end-to-end latency and resource\ndemands, achieving up to 39.51x speedup over state-of-the-art protocols. By\noffloading COT computations to a Zynq-7000 SoC, SilentFlow accelerates PPMLaaS\ninference on the ImageNet dataset under resource constraints, achieving a 4.62x\nand 3.95x speedup over Cryptflow2 and Cheetah, respectively.", "AI": {"tldr": "SilentFlow\u662f\u4e00\u4e2a\u57fa\u4e8eTEE\u7684\u9ad8\u6548\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u534f\u8bae\uff0c\u901a\u8fc7\u6d88\u9664COT\u751f\u6210\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u5b89\u5168\u63a8\u7406", "motivation": "\u4f20\u7edfCOT\u751f\u6210\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\uff08\u5982IoT\u4f20\u611f\u5668\uff09\u4e0a\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff0c\u9650\u5236\u4e86\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u5e94\u7528", "method": "\u4f7f\u7528TEE\u8f85\u52a9\u534f\u8bae\u6d88\u9664COT\u751f\u6210\u7684\u901a\u4fe1\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u7b97\u6cd5\u5206\u89e3\uff1a\u5185\u6838\u878d\u5408\u5e76\u884c\u5316\u3001BOX\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u3001\u5411\u91cf\u5316\u6279\u5904\u7406\u6700\u5927\u5316\u5185\u5b58\u5e26\u5bbd", "result": "\u76f8\u6bd4\u6700\u5148\u8fdb\u534f\u8bae\u5b9e\u73b039.51\u500d\u52a0\u901f\uff0c\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u6bd4Cryptflow2\u548cCheetah\u5206\u522b\u5feb4.62\u500d\u548c3.95\u500d", "conclusion": "SilentFlow\u6709\u6548\u89e3\u51b3\u4e86\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u5b89\u5168\u63a8\u7406\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.13666", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.13666", "abs": "https://arxiv.org/abs/2508.13666", "authors": ["Dangfeng Pan", "Zhensu Sun", "Cenyuan Zhang", "David Lo", "Xiaoning Du"], "title": "The Hidden Cost of Readability: How Code Formatting Silently Consumes Your LLM Budget", "comment": "Accepted by ICSE'26 (First Cycle)", "summary": "Source code is usually formatted with elements like indentation and newlines\nto improve readability for human developers. However, these visual aids do not\nseem to be beneficial for large language models (LLMs) in the same way since\nthe code is processed as a linear sequence of tokens. Furthermore, these\nadditional tokens can lead to increased computational costs and longer response\ntimes for LLMs. If such formatting elements are non-essential to LLMs, we can\nreduce such costs by removing them from the code. To figure out the role played\nby formatting elements, we conduct a comprehensive empirical study to evaluate\nthe impact of code formatting on LLM performance and efficiency. Through\nlarge-scale experiments on Fill-in-the-Middle Code Completion tasks across four\nprogramming languages (Java, Python, C++, C\\#) and ten LLMs-including both\ncommercial and open-source models-we systematically analyze token count and\nperformance when formatting elements are removed. Key findings indicate that\nLLMs can maintain performance across formatted code and unformatted code,\nachieving an average input token reduction of 24.5\\% with negligible output\ntoken reductions. This makes code format removal a practical optimization\nstrategy for improving LLM efficiency. Further exploration reveals that both\nprompting and fine-tuning LLMs can lead to significant reductions (up to\n36.1\\%) in output code length without compromising correctness. To facilitate\npractical applications, we develop a bidirectional code transformation tool for\nformat processing, which can be seamlessly integrated into existing LLM\ninference workflows, ensuring both human readability and LLM efficiency.", "AI": {"tldr": "\u4ee3\u7801\u683c\u5f0f\u5316\u5143\u7d20\uff08\u7f29\u8fdb\u3001\u6362\u884c\u7b49\uff09\u5bf9LLMs\u5e76\u65e0\u5b9e\u8d28\u5e2e\u52a9\uff0c\u53bb\u9664\u540e\u53ef\u51cf\u5c1124.5%\u8f93\u5165token\u6570\u91cf\u4e14\u4fdd\u6301\u6027\u80fd\u3002\u901a\u8fc7\u63d0\u793a\u548c\u5fae\u8c03\u8fd8\u53ef\u8fdb\u4e00\u6b65\u7f29\u77ed\u8f93\u51fa\u4ee3\u7801\u957f\u5ea6\u3002", "motivation": "\u4ee3\u7801\u683c\u5f0f\u5316\u5143\u7d20\u4e3b\u8981\u7528\u4e8e\u63d0\u9ad8\u4eba\u7c7b\u53ef\u8bfb\u6027\uff0c\u4f46\u5bf9LLMs\u5904\u7406\u4ee3\u7801\u4f5c\u4e3a\u7ebf\u6027token\u5e8f\u5217\u65f6\u53ef\u80fd\u6ca1\u6709\u5b9e\u8d28\u5e2e\u52a9\uff0c\u53cd\u800c\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u548c\u54cd\u5e94\u65f6\u95f4\u3002\u5982\u679c\u8fd9\u4e9b\u683c\u5f0f\u5143\u7d20\u5bf9LLMs\u975e\u5fc5\u9700\uff0c\u53ef\u4ee5\u901a\u8fc7\u79fb\u9664\u6765\u964d\u4f4e\u6210\u672c\u3002", "method": "\u8fdb\u884c\u7efc\u5408\u6027\u5b9e\u8bc1\u7814\u7a76\uff0c\u5728Fill-in-the-Middle\u4ee3\u7801\u5b8c\u6210\u4efb\u52a1\u4e0a\u6d4b\u8bd5\u56db\u79cd\u7f16\u7a0b\u8bed\u8a00\uff08Java\u3001Python\u3001C++\u3001C#\uff09\u548c\u5341\u4e2aLLMs\uff08\u5305\u62ec\u5546\u4e1a\u548c\u5f00\u6e90\u6a21\u578b\uff09\u3002\u7cfb\u7edf\u5206\u6790\u79fb\u9664\u683c\u5f0f\u5143\u7d20\u540e\u7684token\u6570\u91cf\u548c\u6027\u80fd\u53d8\u5316\u3002\u8fd8\u63a2\u7d22\u4e86\u63d0\u793a\u548c\u5fae\u8c03\u5bf9\u8f93\u51fa\u4ee3\u7801\u957f\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u5173\u952e\u53d1\u73b0\u663e\u793aLLMs\u5728\u683c\u5f0f\u5316\u4ee3\u7801\u548c\u975e\u683c\u5f0f\u5316\u4ee3\u7801\u4e0a\u90fd\u80fd\u7ef4\u6301\u76f8\u4f3c\u6027\u80fd\uff0c\u5e73\u5747\u51cf\u5c1124.5%\u7684\u8f93\u5165token\u6570\u91cf\uff0c\u8f93\u51fatoken\u51cf\u5c11\u5fae\u4e0d\u8db3\u9053\u3002\u901a\u8fc7\u63d0\u793a\u548c\u5fae\u8c03\u8fd8\u53ef\u4ee5\u8fdb\u4e00\u6b65\u51cf\u5c11\u8f93\u51fa\u4ee3\u7801\u957f\u5ea6\u8fbe36.1%\uff0c\u800c\u4e0d\u5f71\u54cd\u6b63\u786e\u6027\u3002", "conclusion": "\u79fb\u9664\u4ee3\u7801\u683c\u5f0f\u662f\u4e00\u79cd\u5b9e\u7528\u7684LLM\u6548\u7387\u4f18\u5316\u7b56\u7565\u3002\u7814\u7a76\u5f00\u53d1\u4e86\u53cc\u5411\u4ee3\u7801\u8f6c\u6362\u5de5\u5177\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709LLM\u63a8\u7406\u6d41\u7a0b\u4e2d\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u4eba\u7c7b\u53ef\u8bfb\u6027\u548cLLM\u6548\u7387\u3002"}}
{"id": "2508.13171", "categories": ["cs.AI", "cs.CL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.13171", "abs": "https://arxiv.org/abs/2508.13171", "authors": ["Tao An"], "title": "Cognitive Workspace: Active Memory Management for LLMs -- An Empirical Study of Functional Infinite Context", "comment": "13 pages, 1 figure, code available at\n  https://github.com/tao-hpu/cognitive-workspace", "summary": "Large Language Models (LLMs) face fundamental limitations in context\nmanagement despite recent advances extending context windows to millions of\ntokens. We propose Cognitive Workspace, a novel paradigm that transcends\ntraditional Retrieval-Augmented Generation (RAG) by emulating human cognitive\nmechanisms of external memory use. Drawing from cognitive science foundations\nincluding Baddeley's working memory model, Clark's extended mind thesis, and\nHutchins' distributed cognition framework, we demonstrate that current passive\nretrieval systems fail to capture the dynamic, task-driven nature of human\nmemory management. Our analysis of 2024-2025 developments reveals that while\ntechniques like Infini-attention and StreamingLLM achieve impressive context\nlengths, they lack the metacognitive awareness and active planning capabilities\nessential for true cognitive extension. Cognitive Workspace addresses these\nlimitations through three core innovations: (1) active memory management with\ndeliberate information curation, (2) hierarchical cognitive buffers enabling\npersistent working states, and (3) task-driven context optimization that\ndynamically adapts to cognitive demands. Empirical validation demonstrates\nCognitive Workspace achieves an average 58.6% memory reuse rate (ranging from\n54-60% across different tasks) compared to 0% for traditional RAG, with 17-18%\nnet efficiency gain despite 3.3x higher operation counts. Statistical analysis\nconfirms these advantages with p < 0.001 and Cohen's d > 23 across multiple\ntask types, establishing the first quantitative evidence for active memory\nsuperiority in LLM systems. We present a comprehensive theoretical framework\nsynthesizing insights from 50+ recent papers, positioning Cognitive Workspace\nas a fundamental shift from information retrieval to genuine cognitive\naugmentation.", "AI": {"tldr": "\u8ba9LLM\u6a21\u4eff\u4eba\u7c7b\u8ba4\u77e5\u673a\u5236\u7684\u4e3b\u52a8\u5f0f\u5916\u90e8\u8bb0\u5fc6\u7ba1\u7406\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRAG\u88ab\u52a8\u68c0\u7d22\u7684\u5c40\u9650\u6027", "motivation": "\u867d\u7136\u73b0\u6709LLM\u80fd\u5904\u7406\u767e\u4e07\u5230\u5341\u4e07token\u7684\u957f\u4e0a\u4e0b\u6587\uff0c\u4f46\u4ecd\u7f3a\u4e4f\u4eba\u7c7b\u4e3b\u52a8\u7ba1\u7406\u5916\u90e8\u8bb0\u5fc6\u7684\u8ba4\u77e5\u80fd\u529b\uff0c\u5bfc\u81f4\u5185\u5b58\u5229\u7528\u6548\u7387\u4f4e\u4e0b", "method": "\u57fa\u4e8eBaddeley\u5de5\u4f5c\u8bb0\u5fc6\u6a21\u578b\u3001Clark\u6269\u5c55\u5fc3\u667a\u7406\u8bba\u7b49\u8ba4\u77e5\u79d1\u5b66\u7406\u8bba\uff0c\u63d0\u51fa\u4e09\u6838\u5fc3\u521b\u65b0\uff1a\u4e3b\u52a8\u5185\u5b58\u7ba1\u7406\u3001\u5c42\u6b21\u8ba4\u77e5\u7f13\u51b2\u533a\u3001\u4efb\u52a1\u9a71\u52a8\u7684\u4e0a\u4e0b\u6587\u4f18\u5316", "result": "\u5e73\u5747\u5185\u5b58\u91cd\u7528\u7387\u8fbe\u523058.6%\uff08\u4f20\u7edfRAG\u4e3a0%\uff09\uff0c\u7f51\u7edc\u6548\u7387\u63d0\u534717-18%\uff0c\u7edf\u8ba1\u663e\u8457\u6027p<0.001\uff0cCohen's d>23", "conclusion": "\u8ba4\u77e5\u5de5\u4f5c\u533a\u4ee3\u8868\u4e86\u4ece\u4fe1\u606f\u68c0\u7d22\u5230\u771f\u6b63\u8ba4\u77e5\u589e\u5f3a\u7684\u57fa\u672c\u8f6c\u53d8\uff0c\u4e3aLLM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cf\u5316\u7684\u4e3b\u52a8\u5185\u5b58\u4f18\u52bf\u8bc1\u636e"}}
{"id": "2508.13364", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13364", "abs": "https://arxiv.org/abs/2508.13364", "authors": ["Tadeu Freitas", "Carlos Novo", "In\u00eas Dutra", "Jo\u00e3o Soares", "Manuel Correia", "Benham Shariati", "Rolando Martins"], "title": "A Risk Manager for Intrusion Tolerant Systems: Enhancing HAL 9000 with New Scoring and Data Sources", "comment": null, "summary": "Intrusion Tolerant Systems (ITSs) have become increasingly critical due to\nthe rise of multi-domain adversaries exploiting diverse attack surfaces. ITS\narchitectures aim to tolerate intrusions, ensuring system compromise is\nprevented or mitigated even with adversary presence. Existing ITS solutions\noften employ Risk Managers leveraging public security intelligence to adjust\nsystem defenses dynamically against emerging threats. However, these approaches\nrely heavily on databases like NVD and ExploitDB, which require manual analysis\nfor newly discovered vulnerabilities. This dependency limits the system's\nresponsiveness to rapidly evolving threats. HAL 9000, an ITS Risk Manager\nintroduced in our prior work, addressed these challenges through machine\nlearning. By analyzing descriptions of known vulnerabilities, HAL 9000 predicts\nand assesses new vulnerabilities automatically. To calculate the risk of a\nsystem, it also incorporates the Exploitability Probability Scoring system to\nestimate the likelihood of exploitation within 30 days, enhancing proactive\ndefense capabilities.\n  Despite its success, HAL 9000's reliance on NVD and ExploitDB knowledge is a\nlimitation, considering the availability of other sources of information. This\nextended work introduces a custom-built scraper that continuously mines diverse\nthreat sources, including security advisories, research forums, and real-time\nexploit proofs-of-concept. This significantly expands HAL 9000's intelligence\nbase, enabling earlier detection and assessment of unverified vulnerabilities.\nOur evaluation demonstrates that integrating scraper-derived intelligence with\nHAL 9000's risk management framework substantially improves its ability to\naddress emerging threats. This paper details the scraper's integration into the\narchitecture, its role in providing additional information on new threats, and\nthe effects on HAL 9000's management.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86HAL 9000\u5165\u4fb5\u5bb9\u5fcd\u7cfb\u7edf\u98ce\u9669\u7ba1\u7406\u5668\uff0c\u901a\u8fc7\u6784\u5efa\u81ea\u5b9a\u4e49\u722c\u866b\u4ece\u591a\u6837\u5316\u5a01\u80c1\u6e90\u83b7\u53d6\u60c5\u62a5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u672a\u7ecf\u9a8c\u8bc1\u6f0f\u6d1e\u7684\u65e9\u671f\u68c0\u6d4b\u548c\u8bc4\u4f30\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5165\u4fb5\u5bb9\u5fcd\u7cfb\u7edf\u8fc7\u5ea6\u4f9d\u8d56NVD\u548cExploitDB\u7b49\u624b\u52a8\u5206\u6790\u6570\u636e\u5e93\uff0c\u54cd\u5e94\u901f\u5ea6\u53d7\u9650\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u5feb\u901f\u6f14\u53d8\u7684\u5a01\u80c1\u3002HAL 9000\u867d\u7136\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6539\u8fdb\u4e86\u6f0f\u6d1e\u9884\u6d4b\uff0c\u4f46\u4ecd\u53d7\u9650\u4e8e\u6709\u9650\u7684\u60c5\u62a5\u6765\u6e90\u3002", "method": "\u5f00\u53d1\u81ea\u5b9a\u4e49\u722c\u866b\u6301\u7eed\u6316\u6398\u591a\u6837\u5316\u5a01\u80c1\u6e90\uff08\u5b89\u5168\u516c\u544a\u3001\u7814\u7a76\u8bba\u575b\u3001\u5b9e\u65f6\u6f0f\u6d1e\u5229\u7528POC\uff09\uff0c\u5c06\u83b7\u53d6\u7684\u60c5\u62a5\u96c6\u6210\u5230HAL 9000\u98ce\u9669\u7ba1\u7406\u6846\u67b6\u4e2d\uff0c\u6269\u5c55\u5176\u60c5\u62a5\u57fa\u7840\u3002", "result": "\u8bc4\u4f30\u8868\u660e\uff0c\u96c6\u6210\u722c\u866b\u83b7\u53d6\u7684\u60c5\u62a5\u663e\u8457\u63d0\u5347\u4e86HAL 9000\u5e94\u5bf9\u65b0\u5174\u5a01\u80c1\u7684\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u66f4\u65e9\u7684\u6f0f\u6d1e\u68c0\u6d4b\u548c\u8bc4\u4f30\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u591a\u6837\u5316\u5a01\u80c1\u60c5\u62a5\u6e90\uff0cHAL 9000\u7684\u98ce\u9669\u7ba1\u7406\u80fd\u529b\u5f97\u5230\u5b9e\u8d28\u6027\u6539\u8fdb\uff0c\u4e3a\u5165\u4fb5\u5bb9\u5fcd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ca\u65f6\u6709\u6548\u7684\u5a01\u80c1\u54cd\u5e94\u673a\u5236\u3002"}}
{"id": "2508.13757", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13757", "abs": "https://arxiv.org/abs/2508.13757", "authors": ["James Meaden", "Micha\u0142 Jarosz", "Piotr Jod\u0142owski", "Grigori Melnik"], "title": "COMPASS: A Multi-Dimensional Benchmark for Evaluating Code Generation in Large Language Models", "comment": null, "summary": "Current code generation benchmarks focus primarily on functional correctness\nwhile overlooking two critical aspects of real-world programming: algorithmic\nefficiency and code quality. We introduce COMPASS (COdility's Multi-dimensional\nProgramming ASSessment), a comprehensive evaluation framework that assesses\ncode generation across three dimensions: correctness, efficiency, and quality.\nCOMPASS consists of 50 competitive programming problems from real Codility\ncompetitions, providing authentic human baselines from 393,150 submissions.\nUnlike existing benchmarks that treat algorithmically inefficient solutions\nidentically to optimal ones provided they pass test cases, COMPASS\nsystematically evaluates runtime efficiency and code quality using\nindustry-standard analysis tools. Our evaluation of three leading\nreasoning-enhanced models, Anthropic Claude Opus 4, Google Gemini 2.5 Pro, and\nOpenAI O4-Mini-High, reveals that models achieving high correctness scores do\nnot necessarily produce efficient algorithms or maintainable code. These\nfindings highlight the importance of evaluating more than just correctness to\ntruly understand the real-world capabilities of code generation models. COMPASS\nserves as a guiding framework, charting a path for future research toward AI\nsystems that are robust, reliable, and ready for production use.", "AI": {"tldr": "COMPASS\u662f\u4e00\u4e2a\u591a\u7ef4\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u6846\u67b6\uff0c\u4e0d\u4ec5\u8bc4\u4f30\u529f\u80fd\u6b63\u786e\u6027\uff0c\u8fd8\u8bc4\u4f30\u7b97\u6cd5\u6548\u7387\u548c\u4ee3\u7801\u8d28\u91cf\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u7b97\u6cd5\u6548\u7387\u548c\u4ee3\u7801\u8d28\u91cf\u8fd9\u4e24\u4e2a\u73b0\u5b9e\u7f16\u7a0b\u4e2d\u7684\u5173\u952e\u7ef4\u5ea6\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u771f\u5b9e\u80fd\u529b\u3002", "method": "\u4f7f\u752850\u4e2a\u6765\u81ea\u771f\u5b9eCodility\u7ade\u8d5b\u7684\u7f16\u7a0b\u95ee\u9898\uff0c\u5efa\u7acb\u5305\u542b393,150\u4efd\u4eba\u7c7b\u63d0\u4ea4\u7684\u57fa\u51c6\u3002\u91c7\u7528\u884c\u4e1a\u6807\u51c6\u5206\u6790\u5de5\u5177\u7cfb\u7edf\u8bc4\u4f30\u8fd0\u884c\u65f6\u6548\u7387\u548c\u4ee3\u7801\u8d28\u91cf\u3002", "result": "\u5bf9\u4e09\u4e2a\u9886\u5148\u63a8\u7406\u589e\u5f3a\u6a21\u578b\uff08Anthropic Claude Opus 4\u3001Google Gemini 2.5 Pro\u3001OpenAI O4-Mini-High\uff09\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u9ad8\u6b63\u786e\u6027\u5f97\u5206\u7684\u6a21\u578b\u4e0d\u4e00\u5b9a\u80fd\u4ea7\u751f\u9ad8\u6548\u7b97\u6cd5\u6216\u53ef\u7ef4\u62a4\u4ee3\u7801\u3002", "conclusion": "\u4ec5\u8bc4\u4f30\u6b63\u786e\u6027\u4e0d\u8db3\u4ee5\u771f\u6b63\u7406\u89e3\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u73b0\u5b9e\u80fd\u529b\uff0c\u9700\u8981\u591a\u7ef4\u8bc4\u4f30\u6765\u63a8\u52a8AI\u7cfb\u7edf\u5411\u5065\u58ee\u3001\u53ef\u9760\u3001\u751f\u4ea7\u5c31\u7eea\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2508.13174", "categories": ["cs.AI", "cs.LG", "q-fin.CP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.13174", "abs": "https://arxiv.org/abs/2508.13174", "authors": ["Hongjun Ding", "Binqi Chen", "Jinsheng Huang", "Taian Guo", "Zhengyang Mao", "Guoyi Shao", "Lutong Zou", "Luchen Liu", "Ming Zhang"], "title": "AlphaEval: A Comprehensive and Efficient Evaluation Framework for Formula Alpha Mining", "comment": "12 pages, 5 figures", "summary": "Formula alpha mining, which generates predictive signals from financial data,\nis critical for quantitative investment. Although various algorithmic\napproaches-such as genetic programming, reinforcement learning, and large\nlanguage models-have significantly expanded the capacity for alpha discovery,\nsystematic evaluation remains a key challenge. Existing evaluation metrics\npredominantly include backtesting and correlation-based measures. Backtesting\nis computationally intensive, inherently sequential, and sensitive to specific\nstrategy parameters. Correlation-based metrics, though efficient, assess only\npredictive ability and overlook other crucial properties such as temporal\nstability, robustness, diversity, and interpretability. Additionally, the\nclosed-source nature of most existing alpha mining models hinders\nreproducibility and slows progress in this field. To address these issues, we\npropose AlphaEval, a unified, parallelizable, and backtest-free evaluation\nframework for automated alpha mining models. AlphaEval assesses the overall\nquality of generated alphas along five complementary dimensions: predictive\npower, stability, robustness to market perturbations, financial logic, and\ndiversity. Extensive experiments across representative alpha mining algorithms\ndemonstrate that AlphaEval achieves evaluation consistency comparable to\ncomprehensive backtesting, while providing more comprehensive insights and\nhigher efficiency. Furthermore, AlphaEval effectively identifies superior\nalphas compared to traditional single-metric screening approaches. All\nimplementations and evaluation tools are open-sourced to promote\nreproducibility and community engagement.", "AI": {"tldr": "\u63d0\u51faAlphaEval\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u7ef4\u5ea6\u8bc4\u4f30\u81ea\u52a8\u5316alpha\u6316\u6398\u6a21\u578b\uff0c\u89e3\u51b3\u4f20\u7edf\u56de\u6d4b\u8bc4\u4f30\u7684\u95ee\u9898", "motivation": "\u73b0\u6709alpha\u6316\u6398\u6a21\u578b\u8bc4\u4f30\u5b58\u5728\u56de\u6d4b\u8ba1\u7b97\u91cf\u5927\u3001\u6548\u7387\u4f4e\u4e14\u654f\u611f\u6027\u9ad8\uff0c\u76f8\u5173\u6027\u6307\u6807\u53ea\u8003\u8651\u9884\u6d4b\u80fd\u529b\u800c\u5ffd\u89c6\u5176\u4ed6\u91cd\u8981\u7279\u6027\uff0c\u540c\u65f6\u95ed\u6e90\u6a21\u578b\u5f71\u54cd\u53ef\u590d\u73b0\u6027", "method": "\u8bbe\u8ba1AlphaEval\u6846\u67b6\uff0c\u4ece\u9884\u6d4b\u80fd\u529b\u3001\u7a33\u5b9a\u6027\u3001\u5e02\u573a\u5e72\u6270\u9c81\u68d2\u6027\u3001\u91d1\u878d\u903b\u8f91\u548c\u591a\u6837\u6027\u4e94\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff0c\u652f\u6301\u5e76\u884c\u5316\u8ba1\u7b97", "result": "\u5b9e\u9a8c\u8868\u660eAlphaEval\u8bc4\u4f30\u4e00\u81f4\u6027\u4e0e\u5168\u9762\u56de\u6d4b\u76f8\u5f53\uff0c\u4f46\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u6d1e\u5bdf\u548c\u66f4\u9ad8\u6548\u7387\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u4f18\u79c0alpha", "conclusion": "AlphaEval\u4f5c\u4e3a\u4e00\u4e2a\u7edf\u4e00\u3001\u5e76\u884c\u5316\u3001\u65e0\u9700\u56de\u6d4b\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86alpha\u6316\u6398\u9884\u6d4b\u6a21\u578b\u7684\u7cfb\u7edf\u8bc4\u4f30\u6310\u9884\uff0c\u5e76\u5f00\u6e90\u4ee3\u7801\u4fc3\u8fdb\u9886\u57df\u53d1\u5c55"}}
{"id": "2508.13425", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.13425", "abs": "https://arxiv.org/abs/2508.13425", "authors": ["Mohamed Elmahallawy", "Tie Luo"], "title": "When Secure Aggregation Falls Short: Achieving Long-Term Privacy in Asynchronous Federated Learning for LEO Satellite Networks", "comment": null, "summary": "Secure aggregation is a common technique in federated learning (FL) for\nprotecting data privacy from both curious internal entities (clients or server)\nand external adversaries (eavesdroppers). However, in dynamic and\nresource-constrained environments such as low Earth orbit (LEO) satellite\nnetworks, traditional secure aggregation methods fall short in two aspects: (1)\nthey assume continuous client availability while LEO satellite visibility is\nintermittent and irregular; (2) they consider privacy in each communication\nround but have overlooked the possible privacy leakage through multiple rounds.\nTo address these limitations, we propose LTP-FLEO, an asynchronous FL framework\nthat preserves long-term privacy (LTP) for LEO satellite networks. LTP-FLEO\nintroduces (i) privacy-aware satellite partitioning, which groups satellites\nbased on their predictable visibility to the server and enforces joint\nparticipation; (ii) model age balancing, which mitigates the adverse impact of\nstale model updates; and (iii) fair global aggregation, which treats satellites\nof different visibility durations in an equitable manner. Theoretical analysis\nand empirical validation demonstrate that LTP-FLEO effectively safeguards both\nmodel and data privacy across multi-round training, promotes fairness in line\nwith satellite contributions, accelerates global convergence, and achieves\ncompetitive model accuracy.", "AI": {"tldr": "LTP-FLEO\u662f\u4e00\u4e2a\u9488\u5bf9\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u7f51\u7edc\u7684\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5b89\u5168\u805a\u5408\u65b9\u6cd5\u5728\u536b\u661f\u7f51\u7edc\u4e2d\u7684\u4e24\u4e2a\u4e3b\u8981\u4e0d\u8db3\uff1a\u95f4\u6b47\u6027\u8fde\u63a5\u548c\u591a\u8f6e\u9690\u79c1\u6cc4\u9732\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5b89\u5168\u805a\u5408\u65b9\u6cd5\u5047\u8bbe\u5ba2\u6237\u7aef\u6301\u7eed\u53ef\u7528\uff0c\u4f46\u5728LEO\u536b\u661f\u7f51\u7edc\u4e2d\u536b\u661f\u53ef\u89c1\u6027\u662f\u95f4\u6b47\u6027\u548c\u4e0d\u89c4\u5219\u7684\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u53ea\u5173\u6ce8\u5355\u8f6e\u9690\u79c1\u4fdd\u62a4\uff0c\u5ffd\u89c6\u4e86\u591a\u8f6e\u8bad\u7ec3\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u63d0\u51faLTP-FLEO\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a\u57fa\u4e8e\u53ef\u9884\u6d4b\u53ef\u89c1\u6027\u7684\u9690\u79c1\u611f\u77e5\u536b\u661f\u5206\u533a\u3001\u6a21\u578b\u5e74\u9f84\u5e73\u8861\u673a\u5236\u4ee5\u7f13\u89e3\u9648\u65e7\u6a21\u578b\u66f4\u65b0\u7684\u8d1f\u9762\u5f71\u54cd\u3001\u4ee5\u53ca\u516c\u5e73\u7684\u5168\u5c40\u805a\u5408\u5904\u7406\u4e0d\u540c\u53ef\u89c1\u65f6\u957f\u7684\u536b\u661f\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u8868\u660e\uff0cLTP-FLEO\u80fd\u6709\u6548\u4fdd\u62a4\u591a\u8f6e\u8bad\u7ec3\u4e2d\u7684\u6a21\u578b\u548c\u6570\u636e\u9690\u79c1\uff0c\u4fc3\u8fdb\u4e0e\u536b\u661f\u8d21\u732e\u76f8\u5339\u914d\u7684\u516c\u5e73\u6027\uff0c\u52a0\u901f\u5168\u5c40\u6536\u655b\uff0c\u5e76\u8fbe\u5230\u6709\u7ade\u4e89\u529b\u7684\u6a21\u578b\u7cbe\u5ea6\u3002", "conclusion": "LTP-FLEO\u6210\u529f\u89e3\u51b3\u4e86LEO\u536b\u661f\u7f51\u7edc\u4e2d\u8054\u90a6\u5b66\u4e60\u7684\u957f\u671f\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u4e3a\u52a8\u6001\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13774", "categories": ["cs.SE", "cs.AI", "J.5; I.2"], "pdf": "https://arxiv.org/pdf/2508.13774", "abs": "https://arxiv.org/abs/2508.13774", "authors": ["Peer Trilcke", "Ingo B\u00f6rner", "Henny Sluyter-G\u00e4thje", "Daniil Skorinkin", "Frank Fischer", "Carsten Milling"], "title": "Agentic DraCor and the Art of Docstring Engineering: Evaluating MCP-empowered LLM Usage of the DraCor API", "comment": "Preprint, submitted to the 2nd Workshop on Computational Drama\n  Analysis at DraCor Summit 2025, September 03, 2025, Berlin, Germany", "summary": "This paper reports on the implementation and evaluation of a Model Context\nProtocol (MCP) server for DraCor, enabling Large Language Models (LLM) to\nautonomously interact with the DraCor API. We conducted experiments focusing on\ntool selection and application by the LLM, employing a qualitative approach\nthat includes systematic observation of prompts to understand how LLMs behave\nwhen using MCP tools, evaluating \"Tool Correctness\", \"Tool-Calling Efficiency\",\nand \"Tool-Use Reliability\". Our findings highlight the importance of \"Docstring\nEngineering\", defined as reflexively crafting tool documentation to optimize\nLLM-tool interaction. Our experiments demonstrate both the promise of agentic\nAI for research in Computational Literary Studies and the essential\ninfrastructure development needs for reliable Digital Humanities\ninfrastructures.", "AI": {"tldr": "\u901a\u8fc7\u5b9e\u73b0\u548c\u8bc4\u4f30\u4e00\u4e2a\u4e3aDraCor\u7684MCP\u670d\u52a1\u5668\uff0c\u8ba9LLM\u80fd\u591f\u81ea\u4e3b\u4e0eDraCor API\u4ea4\u4e92\uff0c\u5e76\u901a\u8fc7\u5b9a\u6027\u5b9e\u9a8c\u5206\u6790\u4e86LLM\u5728\u4f7f\u7528MCP\u5de5\u5177\u65f6\u7684\u884c\u4e3a\u7279\u70b9\u548c\u6027\u80fd\u6307\u6807\u3002", "motivation": "\u4e3a\u4e86\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u81ea\u4e3b\u4e0eDraCor API\u8fdb\u884c\u4ea4\u4e92\uff0c\u63a2\u7d22\u673a\u5668\u4eba\u667a\u80fd\u5728\u8ba1\u7b97\u6587\u5b66\u7814\u7a76\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u540c\u65f6\u4e3a\u6570\u5b57\u4eba\u6587\u5b66\u57fa\u7840\u8bbe\u65bd\u7684\u53ef\u9760\u6027\u53d1\u5c55\u63d0\u4f9b\u652f\u6491\u3002", "method": "\u5b9e\u73b0\u4e86\u4e00\u4e2aModel Context Protocol (MCP)\u670d\u52a1\u5668\uff0c\u8fdb\u884c\u4e86\u5b9a\u6027\u5b9e\u9a8c\uff0c\u91cd\u70b9\u5173\u6ce8LLM\u7684\u5de5\u5177\u9009\u62e9\u548c\u5e94\u7528\u80fd\u529b\u3002\u901a\u8fc7\u7cfb\u7edf\u89c2\u5bdfprompt\u6765\u7406\u89e3LLM\u4f7f\u7528MCP\u5de5\u5177\u65f6\u7684\u884c\u4e3a\uff0c\u8bc4\u4f30\u4e86\"\u5de5\u5177\u6b63\u786e\u6027\"\u3001\"\u5de5\u5177\u8c03\u7528\u6548\u7387\"\u548c\"\u5de5\u5177\u4f7f\u7528\u53ef\u9760\u6027\"\u7b49\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4e86\"\u6587\u6863\u5b57\u7b26\u4e32\u5de5\u7a0b\"\uff08Docstring Engineering\uff09\u7684\u91cd\u8981\u6027\uff0c\u5373\u901a\u8fc7\u53cd\u5c04\u6027\u5730\u7cbe\u5fc3\u5236\u4f5c\u5de5\u5177\u6587\u6863\u6765\u4f18\u5316LLM-\u5de5\u5177\u4ea4\u4e92\u3002\u8fd9\u4e2a\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u9ad8LLM\u4f7f\u7528\u5de5\u5177\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u673a\u5668\u4eba\u667a\u80fd\u5728\u8ba1\u7b97\u6587\u5b66\u7814\u7a76\u4e2d\u5177\u6709\u5e7f\u9614\u5e94\u7528\u524d\u666f\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u53ef\u9760\u7684\u6570\u5b57\u4eba\u6587\u5b66\u57fa\u7840\u8bbe\u65bd\u5f00\u53d1\u7684\u91cd\u8981\u6027\u3002\u6587\u6863\u5b57\u7b26\u4e32\u5de5\u7a0b\u662f\u4f18\u5316LLM\u4e0e\u5de5\u5177\u4ea4\u4e92\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2508.13176", "categories": ["cs.AI", "cs.DB", "68T30 (Primary) 68P15, 03B70 (Secondary)", "I.2.4; H.2.3"], "pdf": "https://arxiv.org/pdf/2508.13176", "abs": "https://arxiv.org/abs/2508.13176", "authors": ["Simon Hosemann", "Jean Christoph Jung", "Carsten Lutz", "Sebastian Rudolph"], "title": "Fitting Ontologies and Constraints to Relational Structures", "comment": "Accepted at the 22nd International Conference on Principles of\n  Knowledge Representation and Reasoning (KR 2025)", "summary": "We study the problem of fitting ontologies and constraints to positive and\nnegative examples that take the form of a finite relational structure. As\nontology and constraint languages, we consider the description logics\n$\\mathcal{E\\mkern-2mu L}$ and $\\mathcal{E\\mkern-2mu LI}$ as well as several\nclasses of tuple-generating dependencies (TGDs): full, guarded,\nfrontier-guarded, frontier-one, and unrestricted TGDs as well as inclusion\ndependencies. We pinpoint the exact computational complexity, design\nalgorithms, and analyze the size of fitting ontologies and TGDs. We also\ninvestigate the related problem of constructing a finite basis of concept\ninclusions / TGDs for a given set of finite structures. While finite bases\nexist for $\\mathcal{E\\mkern-2mu L}$, $\\mathcal{E\\mkern-2mu LI}$, guarded TGDs,\nand inclusion dependencies, they in general do not exist for full,\nfrontier-guarded and frontier-one TGDs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u6839\u636e\u6b63\u8d1f\u793a\u4f8b\uff08\u6709\u9650\u5173\u7cfb\u7ed3\u6784\uff09\u6765\u62df\u5408\u672c\u4f53\u548c\u7ea6\u675f\uff0c\u91cd\u70b9\u5173\u6ce8\u63cf\u8ff0\u903b\u8f91EL\u548cELI\u4ee5\u53ca\u591a\u79cd\u7c7b\u578b\u7684\u5143\u7ec4\u751f\u6210\u4f9d\u8d56\uff08TGD\uff09\uff0c\u5206\u6790\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u3001\u7b97\u6cd5\u8bbe\u8ba1\u4ee5\u53ca\u62df\u5408\u672c\u4f53\u548cTGD\u7684\u5927\u5c0f\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u4ece\u7ed9\u5b9a\u7684\u6b63\u8d1f\u793a\u4f8b\u4e2d\u81ea\u52a8\u5b66\u4e60\u672c\u4f53\u548c\u7ea6\u675f\uff0c\u8fd9\u5bf9\u4e8e\u77e5\u8bc6\u8868\u793a\u548c\u6570\u636e\u5e93\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u6784\u5efa\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f7f\u7528\u63cf\u8ff0\u903b\u8f91EL\u548cELI\u4ee5\u53ca\u591a\u79cdTGD\u7c7b\u578b\uff08\u5305\u62ecfull\u3001guarded\u3001frontier-guarded\u3001frontier-one\u548cunrestricted TGDs\u4ee5\u53ca\u5305\u542b\u4f9d\u8d56\uff09\u4f5c\u4e3a\u672c\u4f53\u548c\u7ea6\u675f\u8bed\u8a00\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u7b97\u6cd5\u8bbe\u8ba1\u6765\u7814\u7a76\u62df\u5408\u95ee\u9898\u3002", "result": "\u7cbe\u786e\u786e\u5b9a\u4e86\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7b97\u6cd5\uff0c\u5206\u6790\u4e86\u62df\u5408\u672c\u4f53\u548cTGD\u7684\u5927\u5c0f\u7279\u6027\uff0c\u5e76\u53d1\u73b0\u5bf9\u4e8e\u67d0\u4e9bTGD\u7c7b\u578b\uff08\u5982full\u3001frontier-guarded\u548cfrontier-one TGDs\uff09\u4e0d\u5b58\u5728\u6709\u9650\u57fa\u3002", "conclusion": "\u867d\u7136EL\u3001ELI\u3001guarded TGDs\u548c\u5305\u542b\u4f9d\u8d56\u5b58\u5728\u6709\u9650\u57fa\uff0c\u4f46\u5176\u4ed6\u7c7b\u578b\u7684TGDs\u4e00\u822c\u4e0d\u5b58\u5728\u6709\u9650\u57fa\uff0c\u8fd9\u4e3a\u76f8\u5173\u9886\u57df\u7684\u7406\u8bba\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2508.13453", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.13453", "abs": "https://arxiv.org/abs/2508.13453", "authors": ["Ruby Nealon"], "title": "Beneath the Mask: Can Contribution Data Unveil Malicious Personas in Open-Source Projects?", "comment": null, "summary": "In February 2024, after building trust over two years with project\nmaintainers by making a significant volume of legitimate contributions, GitHub\nuser \"JiaT75\" self-merged a version of the XZ Utils project containing a highly\nsophisticated, well-disguised backdoor targeting sshd processes running on\nsystems with the backdoored package installed. A month later, this package\nbegan to be distributed with popular Linux distributions until a Microsoft\nemployee discovered the backdoor while investigating how a recent system\nupgrade impacted the performance of SSH authentication. Despite its potential\nglobal impact, no tooling exists for monitoring and identifying anomalous\nbehavior by personas contributing to other open-source projects. This paper\ndemonstrates how Open Source Intelligence (OSINT) data gathered from GitHub\ncontributions, analyzed using graph databases and graph theory, can efficiently\nidentify anomalous behaviors exhibited by the \"JiaT75\" persona across other\nopen-source projects.", "AI": {"tldr": "\u901a\u8fc7\u5206\u6790GitHub\u8d21\u732e\u6570\u636e\u548c\u56fe\u8bba\u65b9\u6cd5\uff0c\u8bc6\u522b\u5f00\u6e90\u9879\u76ee\u4e2d\u7684\u5f02\u5e38\u884c\u4e3a\uff0c\u5e94\u5bf9XZ Utils\u540e\u95e8\u4e8b\u4ef6", "motivation": "XZ Utils\u540e\u95e8\u4e8b\u4ef6\u663e\u793a\u5f00\u6e90\u9879\u76ee\u4e2d\u7f3a\u4e4f\u76d1\u63a7\u5f02\u5e38\u884c\u4e3a\u7684\u5de5\u5177\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u65b9\u6cd5\u6765\u8bc6\u522b\u50cf\"JiaT75\"\u8fd9\u6837\u7684\u6076\u610f\u8d21\u732e\u8005", "method": "\u4f7f\u7528\u5f00\u6e90\u60c5\u62a5(OSINT)\u6536\u96c6GitHub\u8d21\u732e\u6570\u636e\uff0c\u91c7\u7528\u56fe\u6570\u636e\u5e93\u548c\u56fe\u8bba\u5206\u6790\u6280\u672f\u6765\u8bc6\u522b\u5f02\u5e38\u884c\u4e3a", "result": "\u80fd\u591f\u9ad8\u6548\u5730\u8bc6\u522b\"JiaT75\"\u8eab\u4efd\u5728\u5176\u4ed6\u5f00\u6e90\u9879\u76ee\u4e2d\u5c55\u73b0\u7684\u5f02\u5e38\u884c\u4e3a\u6a21\u5f0f", "conclusion": "\u56fe\u8bba\u5206\u6790\u7ed3\u5408OSINT\u6570\u636e\u662f\u76d1\u6d4b\u5f00\u6e90\u9879\u76ee\u5b89\u5168\u98ce\u9669\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u53ef\u4ee5\u53ca\u65e9\u53d1\u73b0\u6f5c\u5728\u7684\u6076\u610f\u8d21\u732e\u8005"}}
{"id": "2508.13819", "categories": ["cs.SE", "K.6.3; E.0"], "pdf": "https://arxiv.org/pdf/2508.13819", "abs": "https://arxiv.org/abs/2508.13819", "authors": ["Daniel Ogenrwot", "John Businge", "Shaikh Arifuzzaman"], "title": "Structural and Connectivity Patterns in the Maven Central Software Dependency Network", "comment": "17 pages, 6 figures, 34th International Conference on Software\n  Engineering and Data Engineering", "summary": "Understanding the structural characteristics and connectivity patterns of\nlarge-scale software ecosystems is critical for enhancing software reuse,\nimproving ecosystem resilience, and mitigating security risks. In this paper,\nwe investigate the Maven Central ecosystem, one of the largest repositories of\nJava libraries, by applying network science techniques to its dependency graph.\nLeveraging the Goblin framework, we extracted a sample consisting of the top\n5,000 highly connected artifacts based on their degree centrality and then\nperformed breadth-first search (BFS) expansion from each selected artifact as a\nseed node, traversing the graph outward to capture all libraries and releases\nreachable those seed nodes. This sampling strategy captured the immediate\nstructural context surrounding these libraries resulted in a curated graph\ncomprising of 1.3 million nodes and 20.9 million edges. We conducted a\ncomprehensive analysis of this graph, computing degree distributions,\nbetweenness centrality, PageRank centrality, and connected components\ngraph-theoretic metrics. Our results reveal that Maven Central exhibits a\nhighly interconnected, scale-free, and small-world topology, characterized by a\nsmall number of infrastructural hubs that support the majority of projects.\nFurther analysis using PageRank and betweenness centrality shows that these\nhubs predominantly consist of core ecosystem infrastructure, including testing\nframeworks and general-purpose utility libraries. While these hubs facilitate\nefficient software reuse and integration, they also pose systemic risks;\nfailures or vulnerabilities affecting these critical nodes can have widespread\nand cascading impacts throughout the ecosystem.", "AI": {"tldr": "\u901a\u8fc7\u7f51\u7edc\u79d1\u5b66\u6280\u672f\u5206\u6790Maven Central\u4f9d\u8d56\u56fe\uff0c\u53d1\u73b0\u5176\u5177\u6709\u5c3a\u5ea6\u81ea\u7531\u7684\u5c0f\u4e16\u754c\u62e8\u6251\u7ed3\u6784\uff0c\u5c11\u6570\u6838\u5fc3\u5e93\u652f\u6491\u7740\u6574\u4e2a\u751f\u6001\u7cfb\u7edf\uff0c\u65e2\u63d0\u9ad8\u4e86\u6548\u7387\u4e5f\u5e26\u6765\u7cfb\u7edf\u6027\u98ce\u9669\u3002", "motivation": "\u7406\u89e3\u5927\u89c4\u6a21\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u7684\u7ed3\u6784\u7279\u5f81\u548c\u8fde\u63a5\u6a21\u5f0f\uff0c\u4ee5\u63d0\u9ad8\u8f6f\u4ef6\u91cd\u7528\u3001\u589e\u5f3a\u751f\u6001\u7cfb\u7edf\u5f39\u6027\u548c\u51cf\u5c11\u5b89\u5168\u98ce\u9669\u3002", "method": "\u4f7f\u7528Goblin\u6846\u67b6\u63d0\u53d6Maven Central\u4f9d\u8d56\u56fe\u6837\u672c\uff0c\u5305\u542b\u524d5000\u4e2a\u9ad8\u8fde\u63a5\u5ea6\u5de5\u7a0b\u4f5c\u4e3a\u79cd\u5b50\u8282\u70b9\uff0c\u901a\u8fc7\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\u6269\u5c55\u83b7\u5f97130\u4e07\u8282\u70b9\u548c2090\u4e07\u8fb9\u7684\u56fe\u7ed3\u6784\uff0c\u8ba1\u7b97\u5ea6\u5206\u5e03\u3001\u4e2d\u95f4\u5ea6\u4e2d\u5fc3\u6027\u3001PageRank\u7b49\u56fe\u8bba\u6307\u6807\u3002", "result": "\u53d1\u73b0Maven Central\u5177\u6709\u9ad8\u5ea6\u4e92\u8054\u7684\u5c3a\u5ea6\u81ea\u7531\u5c0f\u4e16\u754c\u62e8\u6251\u7ed3\u6784\uff0c\u5c11\u6570\u6838\u5fc3\u57fa\u7840\u8bbe\u65bd\u5e93\uff08\u6d4b\u8bd5\u6846\u67b6\u548c\u901a\u7528\u5de5\u5177\u5e93\uff09\u652f\u6491\u7740\u5927\u90e8\u5206\u9879\u76ee\uff0c\u8fd9\u4e9b\u5173\u952e\u8282\u70b9\u7684\u6545\u969c\u6216\u6f0f\u6d1e\u53ef\u80fd\u5bfc\u81f4\u5168\u5c40\u6027\u7684\u6fc0\u6d89\u6548\u5e94\u3002", "conclusion": "\u6838\u5fc3\u57fa\u7840\u8bbe\u65bd\u5e93\u867d\u7136\u63d0\u9ad8\u4e86\u8f6f\u4ef6\u91cd\u7528\u6548\u7387\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u7cfb\u7edf\u6027\u98ce\u9669\uff0c\u9700\u8981\u91cd\u89c6\u8fd9\u4e9b\u5173\u952e\u8282\u70b9\u7684\u5f31\u70b9\u548c\u5f31\u70b9\u4ee5\u4fdd\u969c\u751f\u6001\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u3002"}}
{"id": "2508.13177", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13177", "abs": "https://arxiv.org/abs/2508.13177", "authors": ["Nikola Pi\u017eurica", "Nikola Milovi\u0107", "Igor Jovan\u010devi\u0107", "Conor Heins", "Miguel de Prado"], "title": "A Hardware-oriented Approach for Efficient Active Inference Computation and Deployment", "comment": null, "summary": "Active Inference (AIF) offers a robust framework for decision-making, yet its\ncomputational and memory demands pose challenges for deployment, especially in\nresource-constrained environments. This work presents a methodology that\nfacilitates AIF's deployment by integrating pymdp's flexibility and efficiency\nwith a unified, sparse, computational graph tailored for hardware-efficient\nexecution. Our approach reduces latency by over 2x and memory by up to 35%,\nadvancing the deployment of efficient AIF agents for real-time and embedded\napplications.", "AI": {"tldr": "\u901a\u8fc7\u7edf\u4e00\u7684\u7a00\u758f\u8ba1\u7b97\u56fe\u4f18\u5316\uff0c\u5c06pymdp\u7684\u7075\u6d3b\u6027\u4e0e\u786c\u4ef6\u6548\u7387\u7ed3\u5408\uff0c\u4f7f\u4e3b\u52a8\u63a8\u7406\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u8d85\u8fc72\u500d\u7684\u5ef6\u8fdf\u51cf\u5c11\u548c\u8fbe\u523035%\u7684\u5185\u5b58\u8282\u7701", "motivation": "\u4e3b\u52a8\u63a8\u7406(AIF)\u6846\u67b6\u5728\u51b3\u7b56\u5236\u5b9a\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5176\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u5bfc\u81f4\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u56f0\u96be", "method": "\u6574\u5408pymdp\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\uff0c\u4f7f\u7528\u4e13\u95e8\u4e3a\u786c\u4ef6\u6548\u7387\u6267\u884c\u800c\u8bbe\u8ba1\u7684\u7edf\u4e00\u7a00\u758f\u8ba1\u7b97\u56fe", "result": "\u5ef6\u8fdf\u51cf\u5c11\u8d852\u500d\uff0c\u5185\u5b58\u8282\u7701\u8fbe\u523035%", "conclusion": "\u63a8\u8fdb\u4e86\u9ad8\u6548\u4e3b\u52a8\u63a8\u7406\u4ee3\u7406\u5728\u5b9e\u65f6\u548c\u5d4c\u5165\u5f0f\u5e94\u7528\u4e2d\u7684\u90e8\u7f72"}}
{"id": "2508.13520", "categories": ["cs.CR", "math.NT", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.13520", "abs": "https://arxiv.org/abs/2508.13520", "authors": ["Takreem Haider"], "title": "Optimizing Scalar Selection in Elliptic Curve Cryptography Using Differential Evolution for Enhanced Security", "comment": null, "summary": "Elliptic Curve Cryptography (ECC) is a fundamental component of modern\npublic-key cryptosystems that enable efficient and secure digital signatures,\nkey exchanges, and encryption. Its core operation, scalar multiplication,\ndenoted as $k \\cdot P$, where $P$ is a base point and $k$ is a private scalar,\nrelies heavily on the secrecy and unpredictability of $k$. Conventionally, $k$\nis selected using user input or pseudorandom number generators. However, in\nresource-constrained environments with weak entropy sources, these approaches\nmay yield low-entropy or biased scalars, increasing susceptibility to\nside-channel and key recovery attacks. To mitigate these vulnerabilities, we\nintroduce an optimization-driven scalar generation method that explicitly\nmaximizes bit-level entropy. Our approach uses differential evolution (DE), a\npopulation-based metaheuristic algorithm, to search for scalars whose binary\nrepresentations exhibit maximal entropy, defined by an even and statistically\nuniform distribution of ones and zeros. This reformulation of scalar selection\nas an entropy-optimization problem enhances resistance to entropy-based\ncryptanalytic techniques and improves overall unpredictability. Experimental\nresults demonstrate that DE-optimized scalars achieve entropy significantly\nhigher than conventionally generated scalars. The proposed method can be\nintegrated into existing ECC-based protocols, offering a deterministic, tunable\nalternative to traditional randomness, ideal for applications in blockchain,\nsecure messaging, IoT, and other resource-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u4f18\u5316\u692d\u5706\u66f2\u7ebf\u5bc6\u7801\u5b66\u4e2d\u7684\u6807\u91cf\u751f\u6210\uff0c\u901a\u8fc7\u6700\u5927\u5316\u6bd4\u7279\u7ea7\u71b5\u6765\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u6297\u653b\u51fb\u80fd\u529b", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\uff0c\u4f20\u7edf\u6807\u91cf\u751f\u6210\u65b9\u6cd5\u53ef\u80fd\u4ea7\u751f\u4f4e\u71b5\u6216\u504f\u7f6e\u7684\u6807\u91cf\uff0c\u5bb9\u6613\u53d7\u5230\u4fa7\u4fe1\u9053\u548c\u5bc6\u94a5\u6062\u590d\u653b\u51fb", "method": "\u4f7f\u7528\u5dee\u5206\u8fdb\u5316(DE)\u7b97\u6cd5\uff0c\u5c06\u6807\u91cf\u9009\u62e9\u91cd\u65b0\u8868\u8ff0\u4e3a\u71b5\u4f18\u5316\u95ee\u9898\uff0c\u5bfb\u627e\u5177\u6709\u6700\u5927\u71b5\u7684\u4e8c\u8fdb\u5236\u8868\u793a", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eDE\u4f18\u5316\u7684\u6807\u91cf\u71b5\u503c\u663e\u8457\u9ad8\u4e8e\u4f20\u7edf\u65b9\u6cd5\u751f\u6210\u7684\u6807\u91cf", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aECC\u534f\u8bae\u63d0\u4f9b\u4e86\u786e\u5b9a\u6027\u7684\u53ef\u8c03\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u533a\u5757\u94fe\u3001\u5b89\u5168\u6d88\u606f\u3001\u7269\u8054\u7f51\u7b49\u8d44\u6e90\u53d7\u9650\u73af\u5883"}}
{"id": "2508.13863", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.13863", "abs": "https://arxiv.org/abs/2508.13863", "authors": ["Shuai Zhao", "Jieyu Jiang", "Shenlin Cai", "Yaowei Liang", "Chen Jie", "Yinjie Fang", "Wei Zhang", "Guoquan Zhang", "Yaoyao Gu", "Xiang Xiao", "Wei Qin", "Xiangzhen Ouyang", "Wanli Chang"], "title": "Tight Inter-Core Cache Contention Analysis for WCET Estimation on Multicore Systems", "comment": null, "summary": "WCET (Worst-Case Execution Time) estimation on multicore architecture is\nparticularly challenging mainly due to the complex accesses over cache shared\nby multiple cores. Existing analysis identifies possible contentions between\nparallel tasks by leveraging the partial order of the tasks or their program\nregions. Unfortunately, they overestimate the number of cache misses caused by\na remote block access without considering the actual cache state and the number\nof accesses. This paper reports a new analysis for inter-core cache contention.\nBased on the order of program regions in a task, we first identify memory\nreferences that could be affected if a remote access occurs in a region.\nAfterwards, a fine-grained contention analysis is constructed that computes the\nnumber of cache misses based on the access quantity of local and remote blocks.\nWe demonstrate that the overall inter-core cache interference of a task can be\nobtained via dynamic programming. Experiments show that compared to existing\nmethods, the proposed analysis reduces inter-core cache interference and WCET\nestimations by 52.31% and 8.94% on average, without significantly increasing\ncomputation overhead.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6838\u67b6\u6784\u4e0a\u7f13\u5b58\u4e89\u7528\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u5b9e\u9645\u7f13\u5b58\u72b6\u6001\u548c\u8bbf\u95ee\u6b21\u6570\uff0c\u51cf\u5c11\u4e86WCET\u4f30\u8ba1\u8fc7\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u591a\u6838\u67b6\u6784\u4e0a\u7684WCET\u4f30\u8ba1\u9762\u4e34\u7f13\u5b58\u5171\u4eab\u5e26\u6765\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u8fc7\u4e8e\u4f30\u8ba1\u8fdc\u7a0b\u5757\u8bbf\u95ee\u5bfc\u81f4\u7684\u7f13\u5b58\u5931\u6548\u6570\u91cf\uff0c\u6ca1\u6709\u8003\u8651\u5b9e\u9645\u7f13\u5b58\u72b6\u6001\u548c\u8bbf\u95ee\u6b21\u6570\u3002", "method": "\u57fa\u4e8e\u4efb\u52a1\u4e2d\u7a0b\u5e8f\u533a\u57df\u7684\u987a\u5e8f\uff0c\u9996\u5148\u8bc6\u522b\u53ef\u80fd\u53d7\u8fdc\u7a0b\u8bbf\u95ee\u5f71\u54cd\u7684\u5185\u5b58\u5f15\u7528\uff0c\u7136\u540e\u6784\u5efa\u7ec6\u7c92\u5ea6\u7684\u4e89\u7528\u5206\u6790\u6765\u8ba1\u7b97\u57fa\u4e8e\u672c\u5730\u548c\u8fdc\u7a0b\u5757\u8bbf\u95ee\u91cf\u7684\u7f13\u5b58\u5931\u6548\u6570\u91cf\uff0c\u901a\u8fc7\u52a8\u6001\u89c4\u5212\u83b7\u53d6\u6574\u4e2a\u4efb\u52a1\u7684\u6838\u95f4\u7f13\u5b58\u5e72\u6270\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u65b0\u65b9\u6cd5\u5e73\u5747\u51cf\u5c1163.31%\u7684\u6838\u95f4\u7f13\u5b58\u5e72\u6270\u548c8.94%\u7684WCET\u4f30\u8ba1\uff0c\u800c\u8ba1\u7b97\u5f00\u9500\u6ca1\u6709\u663e\u8457\u589e\u52a0\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u7ec6\u7c92\u5ea6\u7f13\u5b58\u4e89\u7528\u5206\u6790\u65b9\u6cd5\u80fd\u591f\u66f4\u51c6\u786e\u5730\u4f30\u8ba1\u591a\u6838\u73af\u5883\u4e0b\u7684WCET\uff0c\u6709\u6548\u51cf\u5c11\u4f30\u8ba1\u8fc7\u9ad8\u7684\u95ee\u9898\uff0c\u5bf9\u5b9e\u65f6\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u5206\u6790\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.13178", "categories": ["cs.AI", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.13178", "abs": "https://arxiv.org/abs/2508.13178", "authors": ["Cong Zhang"], "title": "The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task", "comment": null, "summary": "To elevate the foundational capabilities and generalization prowess of the\ntext-to-SQL model in real-world applications, we integrate model\ninterpretability analysis with execution-guided strategy for semantic parsing\nof WHERE clauses in SQL queries. Furthermore, we augment this approach with\nfiltering adjustments, logical correlation refinements, and model fusion,\nculminating in the design of the CESQL model that facilitates conditional\nenhancement. Our model excels on the WikiSQL dataset, which is emblematic of\nsingle-table database query tasks, markedly boosting the accuracy of prediction\noutcomes. When predicting conditional values in WHERE clauses, we have not only\nminimized our dependence on data within the condition columns of tables but\nalso circumvented the impact of manually labeled training data. Our hope is\nthat this endeavor to enhance accuracy in processing basic database queries\nwill offer fresh perspectives for research into handling complex queries and\nscenarios featuring irregular data in real-world database environments.", "AI": {"tldr": "CESQL\u6a21\u578b\u901a\u8fc7\u96c6\u6210\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5206\u6790\u548c\u6267\u884c\u5f15\u5bfc\u7b56\u7565\uff0c\u7ed3\u5408\u8fc7\u6ee4\u8c03\u6574\u3001\u903b\u8f91\u5173\u8054\u4f18\u5316\u548c\u6a21\u578b\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86WikiSQL\u6570\u636e\u96c6\u4e0aWHERE\u5b50\u53e5\u6761\u4ef6\u503c\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u63d0\u5347\u6587\u672c\u5230SQL\u6a21\u578b\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u7684\u57fa\u7840\u80fd\u529b\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u5904\u7406WHERE\u5b50\u53e5\u8bed\u4e49\u89e3\u6790\u65f6\u51cf\u5c11\u5bf9\u6761\u4ef6\u5217\u6570\u636e\u548c\u4eba\u5de5\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\u3002", "method": "\u96c6\u6210\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5206\u6790\u4e0e\u6267\u884c\u5f15\u5bfc\u7b56\u7565\uff0c\u7ed3\u5408\u8fc7\u6ee4\u8c03\u6574\u3001\u903b\u8f91\u5173\u8054\u7cbe\u5316\u548c\u6a21\u578b\u878d\u5408\uff0c\u8bbe\u8ba1\u6761\u4ef6\u589e\u5f3a\u7684CESQL\u6a21\u578b\u3002", "result": "\u5728WikiSQL\u5355\u8868\u6570\u636e\u5e93\u67e5\u8be2\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u7ed3\u679c\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728WHERE\u5b50\u53e5\u6761\u4ef6\u503c\u9884\u6d4b\u65b9\u9762\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u5904\u7406\u590d\u6742\u67e5\u8be2\u548c\u771f\u5b9e\u6570\u636e\u5e93\u73af\u5883\u4e2d\u4e0d\u89c4\u5219\u6570\u636e\u573a\u666f\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u65b9\u6cd5\u57fa\u7840\u3002"}}
{"id": "2508.13588", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.13588", "abs": "https://arxiv.org/abs/2508.13588", "authors": ["V\u00edctor Mayoral-Vilches", "Jasmin Wachter", "Crist\u00f3bal R. J. Veas Chavez", "Cathrin Schachner", "Luis Javier Navarrete-Lozano", "Mar\u00eda Sanz-G\u00f3mez"], "title": "CAI Fluency: A Framework for Cybersecurity AI Fluency", "comment": null, "summary": "This work introduces CAI Fluency, an an educational platform of the\nCybersecurity AI (CAI) framework dedicated to democratizing the knowledge and\napplication of cybersecurity AI tools in the global security community. The\nmain objective of the CAI framework is to accelerate the widespread adoption\nand effective use of artificial intelligence-based cybersecurity solutions,\npathing the way to vibe-hacking, the cybersecurity analogon to vibe-coding.\n  CAI Fluency builds upon the Framework for AI Fluency, adapting its three\nmodalities of human-AI interaction and four core competencies specifically for\ncybersecurity applications. This theoretical foundation ensures that\npractitioners develop not just technical skills, but also the critical thinking\nand ethical awareness necessary for responsible AI use in security contexts.\n  This technical report serves as a white-paper, as well as detailed\neducational and practical guide that helps users understand the principles\nbehind the CAI framework, and educates them how to apply this knowledge in\ntheir projects and real-world security contexts.", "AI": {"tldr": "CAI Fluency\u662f\u4e00\u4e2a\u57fa\u4e8eCAI\u6846\u67b6\u7684\u6559\u80b2\u5e73\u53f0\uff0c\u65e8\u5728\u666e\u53ca\u7f51\u7edc\u5b89\u5168AI\u5de5\u5177\u7684\u77e5\u8bc6\u548c\u5e94\u7528\uff0c\u901a\u8fc7\u4e09\u79cd\u4eba\u673a\u4ea4\u4e92\u6a21\u5f0f\u548c\u56db\u9879\u6838\u5fc3\u80fd\u529b\u57f9\u517b\u4ece\u4e1a\u8005\u7684\u6280\u672f\u6280\u80fd\u548c\u6279\u5224\u6027\u601d\u7ef4\u3002", "motivation": "\u4fc3\u8fdb\u4eba\u5de5\u667a\u80fd\u7f51\u7edc\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u7684\u5e7f\u6cdb\u91c7\u7528\u548c\u6709\u6548\u4f7f\u7528\uff0c\u5b9e\u73b0\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\"vibe-hacking\"\uff08\u7c7b\u4f3c\u7f16\u7a0b\u4e2d\u7684vibe-coding\u6982\u5ff5\uff09\u3002", "method": "\u57fa\u4e8eAI Fluency\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u8c03\u6574\u4e86\u4e09\u79cd\u4eba\u673a\u4ea4\u4e92\u6a21\u5f0f\u548c\u56db\u9879\u6838\u5fc3\u80fd\u529b\uff0c\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u6559\u80b2\u5e73\u53f0\uff0c\u5305\u542b\u767d\u76ae\u4e66\u3001\u8be6\u7ec6\u7684\u6559\u80b2\u548c\u5b9e\u8df5\u6307\u5357\uff0c\u5e2e\u52a9\u7528\u6237\u7406\u89e3CAI\u6846\u67b6\u539f\u7406\u5e76\u5728\u5b9e\u9645\u5b89\u5168\u573a\u666f\u4e2d\u5e94\u7528\u3002", "conclusion": "CAI Fluency\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u7f51\u7edc\u5b89\u5168AI\u6559\u80b2\u7684\u6846\u67b6\uff0c\u4e0d\u4ec5\u57f9\u517b\u6280\u672f\u80fd\u529b\uff0c\u8fd8\u5f3a\u8c03\u6279\u5224\u6027\u601d\u7ef4\u548c\u4f26\u7406\u610f\u8bc6\uff0c\u4e3a\u8d1f\u8d23\u4efb\u5730\u4f7f\u7528AI\u5b89\u5168\u5de5\u5177\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.13644", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.13644", "abs": "https://arxiv.org/abs/2508.13644", "authors": ["Viktoria Koscinski", "Mark Nelson", "Ahmet Okutan", "Robert Falso", "Mehdi Mirakhorli"], "title": "Conflicting Scores, Confusing Signals: An Empirical Study of Vulnerability Scoring Systems", "comment": null, "summary": "Accurately assessing software vulnerabilities is essential for effective\nprioritization and remediation. While various scoring systems exist to support\nthis task, their differing goals, methodologies and outputs often lead to\ninconsistent prioritization decisions. This work provides the first\nlarge-scale, outcome-linked empirical comparison of four publicly available\nvulnerability scoring systems: the Common Vulnerability Scoring System (CVSS),\nthe Stakeholder-Specific Vulnerability Categorization (SSVC), the Exploit\nPrediction Scoring System (EPSS), and the Exploitability Index. We use a\ndataset of 600 real-world vulnerabilities derived from four months of\nMicrosoft's Patch Tuesday disclosures to investigate the relationships between\nthese scores, evaluate how they support vulnerability management task, how\nthese scores categorize vulnerabilities across triage tiers, and assess their\nability to capture the real-world exploitation risk. Our findings reveal\nsignificant disparities in how scoring systems rank the same vulnerabilities,\nwith implications for organizations relying on these metrics to make\ndata-driven, risk-based decisions. We provide insights into the alignment and\ndivergence of these systems, highlighting the need for more transparent and\nconsistent exploitability, risk, and severity assessments.", "AI": {"tldr": "\u9996\u6b21\u5927\u89c4\u6a21\u5b9e\u8bc1\u6bd4\u8f83\u56db\u79cd\u6f0f\u6d1e\u8bc4\u5206\u7cfb\u7edf(CVSS\u3001SSVC\u3001EPSS\u3001Exploitability Index)\uff0c\u4f7f\u7528\u5fae\u8f6f600\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u6570\u636e\uff0c\u53d1\u73b0\u8bc4\u5206\u7cfb\u7edf\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5f71\u54cd\u57fa\u4e8e\u98ce\u9669\u7684\u6f0f\u6d1e\u7ba1\u7406\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709\u6f0f\u6d1e\u8bc4\u5206\u7cfb\u7edf\u7684\u76ee\u6807\u3001\u65b9\u6cd5\u548c\u8f93\u51fa\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u6f0f\u6d1e\u4f18\u5148\u7ea7\u51b3\u7b56\u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u5b9e\u8bc1\u6bd4\u8f83\u6765\u8bc4\u4f30\u5176\u5b9e\u9645\u6548\u679c\u3002", "method": "\u4f7f\u7528\u5fae\u8f6fPatch Tuesday\u62ab\u9732\u7684600\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u6570\u636e\uff0c\u5206\u6790\u56db\u79cd\u8bc4\u5206\u7cfb\u7edf\u7684\u5173\u7cfb\u3001\u6f0f\u6d1e\u7ba1\u7406\u652f\u6301\u80fd\u529b\u3001\u5206\u7ea7\u5206\u7c7b\u6548\u679c\u548c\u5b9e\u9645\u5229\u7528\u98ce\u9669\u6355\u6349\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u8bc4\u5206\u7cfb\u7edf\u5bf9\u76f8\u540c\u6f0f\u6d1e\u7684\u6392\u540d\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5f71\u54cd\u7ec4\u7ec7\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u98ce\u9669\u51b3\u7b56\u3002", "conclusion": "\u9700\u8981\u66f4\u900f\u660e\u548c\u4e00\u81f4\u7684\u6f0f\u6d1e\u53ef\u5229\u7528\u6027\u3001\u98ce\u9669\u548c\u4e25\u91cd\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8bc4\u5206\u7cfb\u7edf\u95f4\u7684\u4e00\u81f4\u6027\u95ee\u9898\u4e9f\u5f85\u89e3\u51b3\u3002"}}
{"id": "2508.13180", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13180", "abs": "https://arxiv.org/abs/2508.13180", "authors": ["Ziwen Han", "Meher Mankikar", "Julian Michael", "Zifan Wang"], "title": "Search-Time Data Contamination", "comment": null, "summary": "Data contamination refers to the leakage of evaluation data into model\ntraining data, resulting in overfitting to supposedly held-out test sets and\ncompromising test validity. We identify an analogous issue, search-time\ncontamination (STC), in evaluating search-based LLM agents which use tools to\ngather information from online sources when answering user queries. STC occurs\nwhen the retrieval step surfaces a source containing the test question (or a\nnear-duplicate) alongside its answer, enabling agents to copy rather than\ngenuinely infer or reason, undermining benchmark integrity. We find that\nHuggingFace, an online platform hosting evaluation datasets, appears among\nretrieved sources in search based agent logs. Consequently, agents often\nexplicitly acknowledge discovering question answer pairs from HuggingFace\nwithin their reasoning chains. On three commonly used capability benchmarks:\nHumanity's Last Exam (HLE), SimpleQA, and GPQA, we demonstrate that for\napproximately 3% of questions, search-based agents directly find the datasets\nwith ground truth labels on HuggingFace. When millions of evaluation queries\ntarget the same benchmark, even small, repeated leaks can accelerate the\nbenchmark's obsolescence, shortening its intended lifecycle. After HuggingFace\nis blocked, we observe a drop in accuracy on the contaminated subset of\napproximately 15%. We further show through ablation experiments that publicly\naccessible evaluation datasets on HuggingFace may not be the sole source of\nSTC. To this end, we conclude by proposing best practices for benchmark design\nand result reporting to address this novel form of leakage and ensure\ntrustworthy evaluation of search-based LLM agents. To facilitate the auditing\nof evaluation results, we also publicly release the complete logs from our\nexperiments.", "AI": {"tldr": "\u672c\u6587\u8bc6\u522b\u4e86\u641c\u7d22\u578bLLM\u4ee3\u7406\u8bc4\u4f30\u4e2d\u7684\u641c\u7d22\u65f6\u6c61\u67d3\u95ee\u9898\uff0c\u5373\u4ee3\u7406\u5728\u641c\u7d22\u8fc7\u7a0b\u4e2d\u53d1\u73b0\u5305\u542b\u6d4b\u8bd5\u95ee\u9898\u548c\u7b54\u6848\u7684\u6570\u636e\u96c6\uff0c\u5bfc\u81f4\u76f4\u63a5\u590d\u5236\u800c\u975e\u771f\u6b63\u63a8\u7406\uff0c\u635f\u5bb3\u8bc4\u4f30\u57fa\u51c6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u641c\u7d22\u578bLLM\u4ee3\u7406\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u8bc4\u4f30\u5176\u771f\u5b9e\u80fd\u529b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u6570\u636e\u6c61\u67d3\u98ce\u9669\uff0c\u7279\u522b\u662f\u5f53\u8bc4\u4f30\u6570\u636e\u96c6\u5728\u641c\u7d22\u8fc7\u7a0b\u4e2d\u88ab\u610f\u5916\u68c0\u7d22\u5230\u65f6\uff0c\u4f1a\u4e25\u91cd\u626d\u66f2\u8bc4\u4f30\u7ed3\u679c\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e09\u4e2a\u5e38\u7528\u80fd\u529b\u57fa\u51c6\uff08HLE\u3001SimpleQA\u3001GPQA\uff09\u4e0a\u641c\u7d22\u578b\u4ee3\u7406\u7684\u68c0\u7d22\u65e5\u5fd7\uff0c\u8bc6\u522bHuggingFace\u5e73\u53f0\u4e0a\u7684\u8bc4\u4f30\u6570\u636e\u96c6\u88ab\u68c0\u7d22\u5230\u7684\u60c5\u51b5\uff0c\u5e76\u8fdb\u884c\u963b\u65ad\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u3002", "result": "\u53d1\u73b0\u7ea63%\u7684\u95ee\u9898\u4e2d\u4ee3\u7406\u76f4\u63a5\u4eceHuggingFace\u627e\u5230\u5e26\u6807\u7b7e\u7684\u6570\u636e\u96c6\uff1b\u963b\u65adHuggingFace\u540e\uff0c\u53d7\u6c61\u67d3\u5b50\u96c6\u7684\u51c6\u786e\u7387\u4e0b\u964d\u7ea615%\uff1b\u516c\u5f00\u53ef\u8bbf\u95ee\u7684\u8bc4\u4f30\u6570\u636e\u96c6\u53ef\u80fd\u4e0d\u662fSTC\u7684\u552f\u4e00\u6765\u6e90\u3002", "conclusion": "\u63d0\u51fa\u4e86\u57fa\u51c6\u8bbe\u8ba1\u548c\u7ed3\u679c\u62a5\u544a\u7684\u6700\u4f73\u5b9e\u8df5\u5efa\u8bae\uff0c\u4ee5\u89e3\u51b3\u8fd9\u79cd\u65b0\u578b\u6cc4\u6f0f\u95ee\u9898\uff0c\u786e\u4fdd\u641c\u7d22\u578bLLM\u4ee3\u7406\u8bc4\u4f30\u7684\u53ef\u4fe1\u5ea6\uff0c\u5e76\u516c\u5f00\u4e86\u5b8c\u6574\u7684\u5b9e\u9a8c\u65e5\u5fd7\u4ee5\u4f9b\u5ba1\u8ba1\u3002"}}
{"id": "2508.13204", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13204", "abs": "https://arxiv.org/abs/2508.13204", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "QuickMerge++: Fast Token Merging with Autoregressive Prior", "comment": "The paper has been accepted to ICML Tokshop at\n  https://openreview.net/forum?id=dMdxHd0tRf", "summary": "As generative models scale to larger inputs across language, vision, and\nvideo domains, the cost of token-level computation has become a key bottleneck.\nWhile prior work suggests that only a subset of tokens significantly influence\ndownstream predictions, most token selection methods are static,\nmodality-specific, or incompatible with autoregressive generation. In this\npaper, we propose QuickMerge, a lightweight token merging framework designed\nfor efficient next-token prediction.\n  QuickMerge dynamically selects a reduced number of tokens based on attention\nnorm magnitude, guided by an entropy-based budget estimator. To preserve\nautoregressive compatibility, we introduce a lightweight transformer prior\ntrained over the merged token sequence. By combining semantic salience\nestimation, flexible token budgets, and AR alignment, QuickMerge enables\naccurate generation with fewer tokens.\n  We evaluate QuickMerge across multi-modality domains, demonstrating\nconsistent improvements in compute-accuracy tradeoffs. Specifically, QuickMerge\nreduces token counts sustantially while matching as well as exceeding the\nperformance of learned tokenizers and fixed-patch baselines.", "AI": {"tldr": "QuickMerge\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7token\u5408\u5e76\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u8303\u6570\u52a8\u6001\u9009\u62e9\u91cd\u8981token\uff0c\u4f7f\u7528\u57fa\u4e8e\u71b5\u7684\u9884\u7b97\u4f30\u8ba1\u5668\uff0c\u5e76\u5f15\u5165transformer\u5148\u9a8c\u6765\u4fdd\u6301\u81ea\u56de\u5f52\u517c\u5bb9\u6027\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u968f\u7740\u751f\u6210\u6a21\u578b\u5904\u7406\u66f4\u5927\u89c4\u6a21\u8f93\u5165\uff0ctoken\u7ea7\u522b\u7684\u8ba1\u7b97\u6210\u672c\u6210\u4e3a\u4e3b\u8981\u74f6\u9888\u3002\u73b0\u6709token\u9009\u62e9\u65b9\u6cd5\u5927\u591a\u662f\u9759\u6001\u7684\u3001\u6a21\u6001\u7279\u5b9a\u7684\u6216\u4e0d\u517c\u5bb9\u81ea\u56de\u5f52\u751f\u6210\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u52a8\u6001token\u9009\u62e9\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u6ce8\u610f\u529b\u8303\u6570\u5927\u5c0f\u52a8\u6001\u9009\u62e9\u91cd\u8981token\uff0c\u4f7f\u7528\u71b5\u57fa\u9884\u7b97\u4f30\u8ba1\u5668\u786e\u5b9atoken\u6570\u91cf\uff0c\u5f15\u5165\u8f7b\u91cf\u7ea7transformer\u5148\u9a8c\u5728\u5408\u5e76\u540e\u7684token\u5e8f\u5217\u4e0a\u8fdb\u884c\u8bad\u7ec3\u4ee5\u4fdd\u6301\u81ea\u56de\u5f52\u517c\u5bb9\u6027\u3002", "result": "\u5728\u591a\u6a21\u6001\u9886\u57df\u8bc4\u4f30\u663e\u793a\uff0cQuickMerge\u5728\u8ba1\u7b97\u7cbe\u5ea6\u6743\u8861\u65b9\u9762\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u663e\u8457\u51cf\u5c11token\u6570\u91cf\u7684\u540c\u65f6\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u5b66\u4e60\u578btokenizer\u548c\u56fa\u5b9apatch\u57fa\u7ebf\u7684\u6027\u80fd\u3002", "conclusion": "QuickMerge\u901a\u8fc7\u8bed\u4e49\u663e\u8457\u6027\u4f30\u8ba1\u3001\u7075\u6d3btoken\u9884\u7b97\u548c\u81ea\u56de\u5f52\u5bf9\u9f50\u7684\u7ec4\u5408\uff0c\u5b9e\u73b0\u4e86\u7528\u66f4\u5c11token\u8fdb\u884c\u51c6\u786e\u751f\u6210\u7684\u6709\u6548\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u751f\u6210\u6a21\u578b\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2508.13690", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13690", "abs": "https://arxiv.org/abs/2508.13690", "authors": ["Wei Shao", "Zequan Liang", "Ruoyu Zhang", "Ruijie Fang", "Ning Miao", "Ehsan Kourkchi", "Setareh Rafatirad", "Houman Homayoun", "Chongzhou Fang"], "title": "Know Me by My Pulse: Toward Practical Continuous Authentication on Wearable Devices via Wrist-Worn PPG", "comment": "To be published in Network and Distributed System Security (NDSS)\n  Symposium 2026", "summary": "Biometric authentication using physiological signals offers a promising path\ntoward secure and user-friendly access control in wearable devices. While\nelectrocardiogram (ECG) signals have shown high discriminability, their\nintrusive sensing requirements and discontinuous acquisition limit\npracticality. Photoplethysmography (PPG), on the other hand, enables\ncontinuous, non-intrusive authentication with seamless integration into\nwrist-worn wearable devices. However, most prior work relies on high-frequency\nPPG (e.g., 75 - 500 Hz) and complex deep models, which incur significant energy\nand computational overhead, impeding deployment in power-constrained real-world\nsystems. In this paper, we present the first real-world implementation and\nevaluation of a continuous authentication system on a smartwatch, We-Be Band,\nusing low-frequency (25 Hz) multi-channel PPG signals. Our method employs a\nBi-LSTM with attention mechanism to extract identity-specific features from\nshort (4 s) windows of 4-channel PPG. Through extensive evaluations on both\npublic datasets (PTTPPG) and our We-Be Dataset (26 subjects), we demonstrate\nstrong classification performance with an average test accuracy of 88.11%,\nmacro F1-score of 0.88, False Acceptance Rate (FAR) of 0.48%, False Rejection\nRate (FRR) of 11.77%, and Equal Error Rate (EER) of 2.76%. Our 25 Hz system\nreduces sensor power consumption by 53% compared to 512 Hz and 19% compared to\n128 Hz setups without compromising performance. We find that sampling at 25 Hz\npreserves authentication accuracy, whereas performance drops sharply at 20 Hz\nwhile offering only trivial additional power savings, underscoring 25 Hz as the\npractical lower bound. Additionally, we find that models trained exclusively on\nresting data fail under motion, while activity-diverse training improves\nrobustness across physiological states.", "AI": {"tldr": "\u57fa\u4e8e25Hz\u4f4e\u9891\u591a\u901a\u9053PPG\u4fe1\u53f7\u7684\u667a\u80fd\u624b\u8868\u8fde\u7eed\u8eab\u4efd\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u901a\u8fc7Bi-LSTM\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u9ad8\u51c6\u786e\u5ea6\u8ba4\u8bc1\uff0c\u4f46\u4f4e\u9891\u91c7\u6837\u51cf\u5c11\u4e8653%\u4f20\u611f\u5668\u8017\u7535", "motivation": "\u89e3\u51b3ECG\u8eab\u4efd\u9a8c\u8bc1\u4fb5\u5165\u6027\u611f\u77e5\u548c\u95f4\u65ad\u6027\u95ee\u9898\uff0c\u4ee5\u53ca\u9ad8\u9891PPG\u65b9\u6848\u7684\u9ad8\u80fd\u8017\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u9002\u5408\u624b\u8868\u7b49\u529f\u80fd\u9650\u5236\u53ef\u7a7f\u6234\u8bbe\u5907", "method": "\u91c7\u752825Hz\u4f4e\u9891\u591a\u901a\u9053PPG\u4fe1\u53f7\uff0c\u4f7f\u7528\u5177\u6709\u6ce8\u610f\u529b\u673a\u5236\u7684\u53cc\u5411LSTM\u6a21\u578b\uff0c\u4ece4\u79d2\u77ed\u65f6\u95f4\u7a97\u53e3\u63d0\u53d6\u7279\u5f81\uff0c\u5728\u516c\u5f00\u6570\u636e\u96c6\u548c\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30", "result": "\u5e73\u5747\u6d4b\u8bd5\u51c6\u786e\u738788.11%\uff0cF1\u52060.88\uff0cFAR 0.48%\uff0cFRR 11.77%\uff0cEER 2.76%\uff0c\u4f4e\u9891\u91c7\u6837\u6bd4512Hz\u8282\u80fd53%\uff0c\u6bd4128Hz\u8282\u80fd19%\uff0c\u786e\u8ba425Hz\u4e3a\u6700\u4f73\u4f4e\u9891\u754c\u9650", "conclusion": "25Hz\u4f4e\u9891PPG\u80fd\u5728\u4fdd\u6301\u9ad8\u8ba4\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff0c\u4e3a\u53ef\u7a7f\u6234\u8bbe\u5907\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8fde\u7eed\u8eab\u4efd\u9a8c\u8bc1\u65b9\u6848\uff0c\u8fd8\u9700\u6d3b\u52a8\u591a\u6837\u6027\u8bad\u7ec3\u63d0\u5347\u6f5c\u52a8\u72b6\u6001\u7684\u7a33\u5065\u6027"}}
{"id": "2508.13213", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13213", "abs": "https://arxiv.org/abs/2508.13213", "authors": ["Adamo Cerioli", "Edward D. Lee", "Vito D. P. Servedio"], "title": "AI sustains higher strategic tension than humans in chess", "comment": null, "summary": "Strategic decision-making involves managing the tension between immediate\nopportunities and long-term objectives. We study this trade-off in chess by\ncharacterizing and comparing dynamics between human vs human and AI vs AI\ngames. We propose a network-based metric of piece-to-piece interaction to\nquantify the ongoing strategic tension on the board. Its evolution in games\nreveals that the most competitive AI players sustain higher levels of strategic\ntension for longer durations than elite human players. Cumulative tension\nvaries with algorithmic complexity for AI and correspondingly in human-played\ngames increases abruptly with expertise at about 1600 Elo and again at 2300\nElo. The profiles reveal different approaches. Highly competitive AI tolerates\ninterconnected positions balanced between offensive and defensive tactics over\nlong periods. Human play, in contrast, limits tension and game complexity,\nwhich may reflect cognitive limitations and adaptive strategies. The difference\nmay have implications for AI usage in complex, strategic environments.", "AI": {"tldr": "\u68cb\u724c\u4e2d\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u5728\u6218\u7565\u51b3\u7b56\u4e2d\u7684\u5dee\u5f02\uff1aAI\u80fd\u7ef4\u6301\u66f4\u9ad8\u6c34\u5e73\u7684\u6218\u7565\u5f3a\u5ea6\u548c\u590d\u6742\u6027\uff0c\u800c\u4eba\u7c7b\u56e0\u8ba4\u77e5\u9650\u5236\u800c\u9009\u62e9\u63a7\u5236\u6e38\u620f\u590d\u6742\u5ea6\u3002", "motivation": "\u7814\u7a76\u6218\u7565\u51b3\u7b56\u4e2d\u77ac\u65f6\u673a\u4f1a\u4e0e\u957f\u671f\u76ee\u6807\u7684\u7f81\u7eca\u5173\u7cfb\uff0c\u901a\u8fc7\u68cb\u724c\u6e38\u620f\u5bf9\u6bd4\u4eba\u7c7b\u548cAI\u7684\u51b3\u7b56\u884c\u4e3a\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7f51\u7edc\u7684\u68cb\u5b50\u4e92\u52a8\u6307\u6807\u6765\u91cf\u5316\u6218\u7565\u5f3a\u5ea6\uff0c\u5206\u6790\u4eba\u7c7bvs\u4eba\u7c7b\u548cAIvsAI\u6e38\u620f\u7684\u52a8\u6001\u53d8\u5316\u3002", "result": "\u7ade\u4e89\u529b\u5f3a\u7684AI\u80fd\u5728\u66f4\u957f\u65f6\u95f4\u5185\u7ef4\u6301\u66f4\u9ad8\u7684\u6218\u7565\u5f3a\u5ea6\uff1b\u4eba\u7c7b\u6e38\u620f\u7684\u7d2f\u8ba1\u5f3a\u5ea6\u968f\u7740\u4e13\u4e1a\u77e5\u8bc6\u7684\u63d0\u5347\u800c\u51f8\u53d8\u589e\u52a0\uff08\u7279\u522b\u662f\u57281600\u548c2300Elo\u9644\u8fd1\uff09\u3002", "conclusion": "AI\u548c\u4eba\u7c7b\u5728\u6218\u7565\u51b3\u7b56\u4e0a\u91c7\u53d6\u4e0d\u540c\u65b9\u5f0f\uff1aAI\u5bf9\u590d\u6742\u4e92\u8054\u5c40\u9762\u66f4\u8010\u53d7\uff0c\u800c\u4eba\u7c7b\u56e0\u8ba4\u77e5\u9650\u5236\u800c\u9009\u62e9\u63a7\u5236\u590d\u6742\u6027\u3002\u8fd9\u5bf9AI\u5728\u590d\u6742\u6218\u7565\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.13730", "categories": ["cs.CR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.13730", "abs": "https://arxiv.org/abs/2508.13730", "authors": ["Daniel M. Jimenez-Gutierrez", "Yelizaveta Falkouskaya", "Jose L. Hernandez-Ramos", "Aris Anagnostopoulos", "Ioannis Chatzigiannakis", "Andrea Vitaletti"], "title": "On the Security and Privacy of Federated Learning: A Survey with Attacks, Defenses, Frameworks, Applications, and Future Directions", "comment": null, "summary": "Federated Learning (FL) is an emerging distributed machine learning paradigm\nenabling multiple clients to train a global model collaboratively without\nsharing their raw data. While FL enhances data privacy by design, it remains\nvulnerable to various security and privacy threats. This survey provides a\ncomprehensive overview of more than 200 papers regarding the state-of-the-art\nattacks and defense mechanisms developed to address these challenges,\ncategorizing them into security-enhancing and privacy-preserving techniques.\nSecurity-enhancing methods aim to improve FL robustness against malicious\nbehaviors such as byzantine attacks, poisoning, and Sybil attacks. At the same\ntime, privacy-preserving techniques focus on protecting sensitive data through\ncryptographic approaches, differential privacy, and secure aggregation. We\ncritically analyze the strengths and limitations of existing methods, highlight\nthe trade-offs between privacy, security, and model performance, and discuss\nthe implications of non-IID data distributions on the effectiveness of these\ndefenses. Furthermore, we identify open research challenges and future\ndirections, including the need for scalable, adaptive, and energy-efficient\nsolutions operating in dynamic and heterogeneous FL environments. Our survey\naims to guide researchers and practitioners in developing robust and\nprivacy-preserving FL systems, fostering advancements safeguarding\ncollaborative learning frameworks' integrity and confidentiality.", "AI": {"tldr": "\u8fd9\u7bc7\u8c03\u7814\u8bba\u6587\u7efc\u8ff0\u4e86\u8054\u90a6\u5b66\u4e60\u9886\u57df\u7684\u5b89\u5168\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u653b\u51fb\u4e0e\u9632\u5fa1\u6280\u672f\uff0c\u5206\u6790\u4e86200\u591a\u7bc7\u6587\u732e\uff0c\u5e76\u8bc4\u4f30\u4e86\u5404\u79cd\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u548c\u5e94\u7528\u6311\u6218\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u5728\u8bbe\u8ba1\u4e0a\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u4f46\u4ecd\u9762\u4e34\u7740\u591a\u79cd\u5b89\u5168\u6027\u548c\u9690\u79c1\u6f0f\u6d1e\u7684\u5a01\u80c1\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u548c\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8c03\u7814\u8bba\u6587\u91c7\u7528\u7cfb\u7edf\u6027\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u5c06\u76f8\u5173\u6280\u672f\u5206\u4e3a\u5b89\u5168\u6027\u589e\u5f3a\u548c\u9690\u79c1\u4fdd\u62a4\u4e24\u5927\u7c7b\u3002\u5b89\u5168\u6027\u65b9\u6cd5\u6d89\u53ca\u5bf9\u6295\u6bd2\u653b\u51fb\u3001\u5e0c\u62c9\u653b\u51fb\u7b49\u6076\u610f\u884c\u4e3a\u7684\u9632\u5fa1\uff1b\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u5305\u62ec\u52a0\u5bc6\u6280\u672f\u3001\u5dee\u5206\u9690\u79c1\u548c\u5b89\u5168\u805a\u5408\u7b49\u3002", "result": "\u8bc4\u4f30\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u5206\u6790\u4e86\u9690\u79c1\u3001\u5b89\u5168\u6027\u548c\u6a21\u578b\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u8ba8\u8bba\u4e86\u975eIID\u6570\u636e\u5206\u5e03\u5bf9\u9632\u5fa1\u6548\u679c\u7684\u5f71\u54cd\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524d\u7814\u7a76\u7684\u7a7a\u767d\u548c\u6311\u6218\u3002", "conclusion": "\u8fd9\u4efd\u8c03\u7814\u63d0\u4f9b\u4e86\u8054\u90a6\u5b66\u4e60\u5b89\u5168\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u9886\u57df\u7684\u5168\u9762\u6982\u89c8\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u5f00\u53d1\u66f4\u52a0\u5065\u58ee\u548c\u53ef\u9760\u7684\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6307\u5357\uff0c\u4fc3\u8fdb\u534f\u4f5c\u5b66\u4e60\u6846\u67b6\u6574\u4f53\u6027\u548c\u4fdd\u5bc6\u6027\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.13250", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13250", "abs": "https://arxiv.org/abs/2508.13250", "authors": ["Zeyu Zhang", "Yang Zhang", "Haoran Tan", "Rui Li", "Xu Chen"], "title": "Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information", "comment": "15 pages, 13 figures, 3 tables", "summary": "In large language model-based agents, memory serves as a critical capability\nfor achieving personalization by storing and utilizing users' information.\nAlthough some previous studies have adopted memory to implement user\npersonalization, they typically focus on preference alignment and simple\nquestion-answering. However, in the real world, complex tasks often require\nmulti-hop reasoning on a large amount of user information, which poses\nsignificant challenges for current memory approaches. To address this\nlimitation, we propose the multi-hop personalized reasoning task to explore how\ndifferent memory mechanisms perform in multi-hop reasoning over personalized\ninformation. We explicitly define this task and construct a dataset along with\na unified evaluation framework. Then, we implement various explicit and\nimplicit memory methods and conduct comprehensive experiments. We evaluate\ntheir performance on this task from multiple perspectives and analyze their\nstrengths and weaknesses. Besides, we explore hybrid approaches that combine\nboth paradigms and propose the HybridMem method to address their limitations.\nWe demonstrate the effectiveness of our proposed model through extensive\nexperiments. To benefit the research community, we release this project at\nhttps://github.com/nuster1128/MPR.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u591a\u8df3\u4e2a\u6027\u5316\u63a8\u7406\u4efb\u52a1\uff0c\u63a2\u7d22\u4e0d\u540c\u8bb0\u5fc6\u673a\u5236\u5728\u4e2a\u6027\u5316\u4fe1\u606f\u591a\u8df3\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u6784\u5efa\u4e86\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u63d0\u51fa\u4e86HybridMem\u6df7\u5408\u65b9\u6cd5\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bb0\u5fc6\u7684\u4e2a\u6027\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u504f\u597d\u5bf9\u9f50\u548c\u7b80\u5355\u95ee\u7b54\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u4e2d\u590d\u6742\u4efb\u52a1\u9700\u8981\u5bf9\u5927\u91cf\u7528\u6237\u4fe1\u606f\u8fdb\u884c\u591a\u8df3\u63a8\u7406\uff0c\u8fd9\u5bf9\u5f53\u524d\u8bb0\u5fc6\u65b9\u6cd5\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "\u660e\u786e\u5b9a\u4e49\u591a\u8df3\u4e2a\u6027\u5316\u63a8\u7406\u4efb\u52a1\uff0c\u6784\u5efa\u6570\u636e\u96c6\u548c\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9e\u73b0\u5404\u79cd\u663e\u5f0f\u548c\u9690\u5f0f\u8bb0\u5fc6\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u7ed3\u5408\u4e24\u79cd\u8303\u5f0f\u7684HybridMem\u6df7\u5408\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u7efc\u5408\u5b9e\u9a8c\u4ece\u591a\u4e2a\u89d2\u5ea6\u8bc4\u4f30\u4e86\u4e0d\u540c\u8bb0\u5fc6\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5206\u6790\u4e86\u5b83\u4eec\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u89e3\u51b3\u4e2a\u6027\u5316\u4fe1\u606f\u7684\u591a\u8df3\u63a8\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0cHybridMem\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u514b\u670d\u73b0\u6709\u8bb0\u5fc6\u673a\u5236\u7684\u5c40\u9650\u6027\uff0c\u63a8\u52a8\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4ee3\u7406\u5728\u590d\u6742\u4e2a\u6027\u5316\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2508.13750", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.13750", "abs": "https://arxiv.org/abs/2508.13750", "authors": ["Eric Cornelissen", "Musard Balliu"], "title": "NodeShield: Runtime Enforcement of Security-Enhanced SBOMs for Node.js", "comment": "15 pages, 3 figures, 9 tables", "summary": "The software supply chain is an increasingly common attack vector for\nmalicious actors. The Node.js ecosystem has been subject to a wide array of\nattacks, likely due to its size and prevalence. To counter such attacks, the\nresearch community and practitioners have proposed a range of static and\ndynamic mechanisms, including process- and language-level sandboxing,\npermission systems, and taint tracking. Drawing on valuable insight from these\nworks, this paper studies a runtime protection mechanism for (the supply chain\nof) Node.js applications with the ambitious goals of compatibility, automation,\nminimal overhead, and policy conciseness.\n  Specifically, we design, implement and evaluate NodeShield, a protection\nmechanism for Node.js that enforces an application's dependency hierarchy and\ncontrols access to system resources at runtime. We leverage the up-and-coming\nSBOM standard as the source of truth for the dependency hierarchy of the\napplication, thus preventing components from stealthily abusing undeclared\ncomponents. We propose to enhance the SBOM with a notion of capabilities that\nrepresents a set of related system resources a component may access. Our\nproposed SBOM extension, the Capability Bill of Materials or CBOM, records the\nrequired capabilities of each component, providing valuable insight into the\npotential privileged behavior. NodeShield enforces the SBOM and CBOM at runtime\nvia code outlining (as opposed to inlining) with no modifications to the\noriginal code or Node.js runtime, thus preventing unexpected, potentially\nmalicious behavior. Our evaluation shows that NodeShield can prevent over 98%\nout of 67 known supply chain attacks while incurring minimal overhead on\nservers at less than 1ms per request. We achieve this while maintaining broad\ncompatibility with vanilla Node.js and a concise policy language that consists\nof at most 7 entries per dependency.", "AI": {"tldr": "NodeShield\u662f\u4e00\u4e2a\u9488\u5bf9Node.js\u5e94\u7528\u7684\u8fd0\u884c\u65f6\u4fdd\u62a4\u673a\u5236\uff0c\u901a\u8fc7SBOM\u548cCBOM\u6765\u5f3a\u5236\u6267\u884c\u4f9d\u8d56\u5c42\u6b21\u7ed3\u6784\u548c\u7cfb\u7edf\u8d44\u6e90\u8bbf\u95ee\u63a7\u5236\uff0c\u80fd\u591f\u9632\u6b6298%\u7684\u5df2\u77e5\u4f9b\u5e94\u94fe\u653b\u51fb\uff0c\u4e14\u5f00\u9500\u6781\u5c0f\u3002", "motivation": "Node.js\u751f\u6001\u7cfb\u7edf\u56e0\u5176\u89c4\u6a21\u548c\u666e\u53ca\u6027\u800c\u6210\u4e3a\u6076\u610f\u653b\u51fb\u7684\u5e38\u89c1\u76ee\u6807\uff0c\u9700\u8981\u4e00\u79cd\u517c\u5bb9\u6027\u597d\u3001\u81ea\u52a8\u5316\u3001\u5f00\u9500\u5c0f\u4e14\u7b56\u7565\u7b80\u6d01\u7684\u8fd0\u884c\u65f6\u4fdd\u62a4\u673a\u5236\u6765\u5e94\u5bf9\u4f9b\u5e94\u94fe\u653b\u51fb\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86NodeShield\uff0c\u5229\u7528SBOM\u6807\u51c6\u4f5c\u4e3a\u4f9d\u8d56\u5c42\u6b21\u7ed3\u6784\u7684\u771f\u5b9e\u6765\u6e90\uff0c\u5e76\u63d0\u51fa\u4e86CBOM\u6269\u5c55\u6765\u8bb0\u5f55\u7ec4\u4ef6\u6240\u9700\u7684\u80fd\u529b\u3002\u901a\u8fc7\u4ee3\u7801\u8f6e\u5ed3\u5316\uff08\u800c\u975e\u5185\u8054\uff09\u5728\u8fd0\u884c\u65f6\u5f3a\u5236\u6267\u884cSBOM\u548cCBOM\uff0c\u65e0\u9700\u4fee\u6539\u539f\u59cb\u4ee3\u7801\u6216Node.js\u8fd0\u884c\u65f6\u3002", "result": "\u8bc4\u4f30\u663e\u793aNodeShield\u80fd\u591f\u9632\u6b6267\u4e2a\u5df2\u77e5\u4f9b\u5e94\u94fe\u653b\u51fb\u4e2d\u768498%\u4ee5\u4e0a\uff0c\u670d\u52a1\u5668\u7aef\u6bcf\u4e2a\u8bf7\u6c42\u7684\u5f00\u9500\u5c0f\u4e8e1ms\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u539f\u751fNode.js\u7684\u5e7f\u6cdb\u517c\u5bb9\u6027\u3002", "conclusion": "NodeShield\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8fd0\u884c\u65f6\u4fdd\u62a4\u673a\u5236\uff0c\u901a\u8fc7SBOM\u548cCBOM\u7684\u7ec4\u5408\u4f7f\u7528\uff0c\u80fd\u591f\u4ee5\u6700\u5c0f\u5f00\u9500\u6709\u6548\u9632\u5fa1Node.js\u4f9b\u5e94\u94fe\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u7b56\u7565\u7b80\u6d01\u548c\u517c\u5bb9\u6027\u3002"}}
{"id": "2508.13251", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2508.13251", "abs": "https://arxiv.org/abs/2508.13251", "authors": ["Di Zhang", "Xue Jia", "Tran Ba Hung", "Seong Hoon Jang", "Linda Zhang", "Ryuhei Sato", "Yusuke Hashimoto", "Toyoto Sato", "Kiyoe Konno", "Shin-ichi Orimo", "Hao Li"], "title": "\"DIVE\" into Hydrogen Storage Materials Discovery with AI Agents", "comment": "23 pages, 5 figures. The supplementary video is available at the\n  GitHub link provided in the manuscript", "summary": "Data-driven artificial intelligence (AI) approaches are fundamentally\ntransforming the discovery of new materials. Despite the unprecedented\navailability of materials data in the scientific literature, much of this\ninformation remains trapped in unstructured figures and tables, hindering the\nconstruction of large language model (LLM)-based AI agent for automated\nmaterials design. Here, we present the Descriptive Interpretation of Visual\nExpression (DIVE) multi-agent workflow, which systematically reads and\norganizes experimental data from graphical elements in scientific literatures.\nWe focus on solid-state hydrogen storage materials-a class of materials central\nto future clean-energy technologies and demonstrate that DIVE markedly improves\nthe accuracy and coverage of data extraction compared to the direct extraction\nby multimodal models, with gains of 10-15% over commercial models and over 30%\nrelative to open-source models. Building on a curated database of over 30,000\nentries from 4,000 publications, we establish a rapid inverse design workflow\ncapable of identifying previously unreported hydrogen storage compositions in\ntwo minutes. The proposed AI workflow and agent design are broadly transferable\nacross diverse materials, providing a paradigm for AI-driven materials\ndiscovery.", "AI": {"tldr": "DIVE\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u901a\u8fc7\u7cfb\u7edf\u8bfb\u53d6\u548c\u7ec4\u7ec7\u79d1\u5b66\u6587\u732e\u4e2d\u7684\u56fe\u5f62\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u6750\u6599\u6570\u636e\u63d0\u53d6\u51c6\u786e\u6027\uff0c\u5efa\u7acb\u4e86\u5305\u542b3\u4e07\u6761\u6570\u636e\u7684\u6c22\u5b58\u50a8\u6750\u6599\u6570\u636e\u5e93\uff0c\u5b9e\u73b0\u4e86\u5feb\u901f\u9006\u5411\u8bbe\u8ba1\u3002", "motivation": "\u79d1\u5b66\u6587\u732e\u4e2d\u5927\u91cf\u6750\u6599\u6570\u636e\u88ab\u56f0\u5728\u975e\u7ed3\u6784\u5316\u7684\u56fe\u8868\u4e2d\uff0c\u963b\u788d\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u667a\u80fd\u4f53\u8fdb\u884c\u81ea\u52a8\u5316\u6750\u6599\u8bbe\u8ba1\uff0c\u9700\u8981\u89e3\u51b3\u6570\u636e\u63d0\u53d6\u548c\u6574\u7406\u7684\u96be\u9898\u3002", "method": "\u5f00\u53d1\u4e86DIVE\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u7cfb\u7edf\u8bfb\u53d6\u79d1\u5b66\u6587\u732e\u4e2d\u7684\u56fe\u5f62\u5143\u7d20\u5e76\u7ec4\u7ec7\u5b9e\u9a8c\u6570\u636e\uff0c\u4e13\u6ce8\u4e8e\u56fa\u6001\u6c22\u5b58\u50a8\u6750\u6599\u7684\u6570\u636e\u63d0\u53d6\u548c\u6570\u636e\u5e93\u6784\u5efa\u3002", "result": "DIVE\u76f8\u6bd4\u591a\u6a21\u6001\u6a21\u578b\u76f4\u63a5\u63d0\u53d6\uff0c\u51c6\u786e\u7387\u63d0\u534710-15%\uff08\u5546\u4e1a\u6a21\u578b\uff09\u548c30%\u4ee5\u4e0a\uff08\u5f00\u6e90\u6a21\u578b\uff09\uff0c\u5efa\u7acb\u4e86\u5305\u542b4,000\u7bc7\u6587\u732e\u300130,000\u6761\u6570\u636e\u7684\u6570\u636e\u5e93\uff0c\u80fd\u57282\u5206\u949f\u5185\u8bc6\u522b\u672a\u62a5\u9053\u7684\u6c22\u5b58\u50a8\u6210\u5206\u3002", "conclusion": "\u8be5AI\u5de5\u4f5c\u6d41\u548c\u667a\u80fd\u4f53\u8bbe\u8ba1\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4e0d\u540c\u6750\u6599\u9886\u57df\uff0c\u4e3aAI\u9a71\u52a8\u7684\u6750\u6599\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2508.13965", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.13965", "abs": "https://arxiv.org/abs/2508.13965", "authors": ["Yuntao Liu", "Abir Akib", "Zelin Lu", "Qian Xu", "Ankur Srivastava", "Gang Qu", "David Kehlet", "Nij Dorairaj"], "title": "Red Teaming Methodology for Design Obfuscation", "comment": null, "summary": "The main goal of design obfuscation schemes is to protect sensitive design\ndetails from untrusted parties in the VLSI supply chain, including but not\nlimited to off-shore foundries and untrusted end users. In this work, we\nprovide a systematic red teaming approach to evaluate the security of design\nobfuscation approaches. Specifically, we propose security metrics and\nevaluation methodology for the scenarios where the adversary does not have\naccess to a working chip. A case study on the RIPPER tool developed by the\nUniversity of Florida indicates that more information is leaked about the\nstructure of the original design than commonly considered.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u7ea2\u961f\u65b9\u6cd5\u6765\u8bc4\u4f30\u8bbe\u8ba1\u6df7\u6dc6\u65b9\u6848\u7684\u5b89\u5168\u6027\uff0c\u7279\u522b\u9488\u5bf9\u653b\u51fb\u8005\u65e0\u6cd5\u83b7\u5f97\u5de5\u4f5c\u82af\u7247\u7684\u573a\u666f\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u6cc4\u9732\u7684\u8bbe\u8ba1\u7ed3\u6784\u4fe1\u606f\u6bd4\u901a\u5e38\u8ba4\u4e3a\u7684\u66f4\u591a\u3002", "motivation": "\u4fdd\u62a4VLSI\u4f9b\u5e94\u94fe\u4e2d\u654f\u611f\u8bbe\u8ba1\u7ec6\u8282\u514d\u53d7\u4e0d\u53ef\u4fe1\u65b9\uff08\u5982\u79bb\u5cb8\u4ee3\u5de5\u5382\u548c\u4e0d\u53ef\u4fe1\u7ec8\u7aef\u7528\u6237\uff09\u7684\u4fb5\u5bb3\uff0c\u73b0\u6709\u8bbe\u8ba1\u6df7\u6dc6\u65b9\u6848\u7684\u5b89\u5168\u6027\u9700\u8981\u7cfb\u7edf\u5316\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u5b89\u5168\u6307\u6807\u548c\u8bc4\u4f30\u65b9\u6cd5\u5b66\uff0c\u7279\u522b\u9488\u5bf9\u653b\u51fb\u8005\u65e0\u6cd5\u83b7\u5f97\u5de5\u4f5c\u82af\u7247\u7684\u573a\u666f\uff0c\u4f7f\u7528\u4f5b\u7f57\u91cc\u8fbe\u5927\u5b66\u5f00\u53d1\u7684RIPPER\u5de5\u5177\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u73b0\u6709\u8bbe\u8ba1\u6df7\u6dc6\u65b9\u6cd5\u6cc4\u9732\u7684\u539f\u59cb\u8bbe\u8ba1\u7ed3\u6784\u4fe1\u606f\u6bd4\u901a\u5e38\u8ba4\u4e3a\u7684\u8981\u591a\u3002", "conclusion": "\u9700\u8981\u66f4\u4e25\u683c\u7684\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u6765\u786e\u4fdd\u8bbe\u8ba1\u6df7\u6dc6\u65b9\u6848\u7684\u6709\u6548\u6027\uff0c\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u4fe1\u606f\u6cc4\u9732\u98ce\u9669\u3002"}}
{"id": "2508.13256", "categories": ["cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.13256", "abs": "https://arxiv.org/abs/2508.13256", "authors": ["Yuting Zhang", "Karina V. Bunting", "Asgher Champsi", "Xiaoxia Wang", "Wenqi Lu", "Alexander Thorley", "Sandeep S Hothi", "Zhaowen Qiu", "Dipak Kotecha", "Jinming Duan"], "title": "CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support", "comment": null, "summary": "Cardiovascular diseases (CVDs) remain the foremost cause of mortality\nworldwide, a burden worsened by a severe deficit of healthcare workers.\nArtificial intelligence (AI) agents have shown potential to alleviate this gap\nvia automated early detection and proactive screening, yet their clinical\napplication remains limited by: 1) prompt-based clinical role assignment that\nrelies on intrinsic model capabilities without domain-specific tool support; or\n2) rigid sequential workflows, whereas clinical care often requires adaptive\nreasoning that orders specific tests and, based on their results, guides\npersonalised next steps; 3) general and static knowledge bases without\ncontinuous learning capability; and 4) fixed unimodal or bimodal inputs and\nlack of on-demand visual outputs when further clarification is needed. In\nresponse, a multimodal framework, CardAIc-Agents, was proposed to augment\nmodels with external tools and adaptively support diverse cardiac tasks.\nSpecifically, a CardiacRAG agent generated general plans from updatable cardiac\nknowledge, while the chief agent integrated tools to autonomously execute these\nplans and deliver decisions. To enable adaptive and case-specific\ncustomization, a stepwise update strategy was proposed to dynamically refine\nplans based on preceding execution results, once the task was assessed as\ncomplex. In addition, a multidisciplinary discussion tool was introduced to\ninterpret challenging cases, thereby supporting further adaptation. When\nclinicians raised concerns, visual review panels were provided to assist final\nvalidation. Experiments across three datasets showed the efficiency of\nCardAIc-Agents compared to mainstream Vision-Language Models (VLMs),\nstate-of-the-art agentic systems, and fine-tuned VLMs.", "AI": {"tldr": "CardAIc-Agents\u662f\u4e00\u4e2a\u591a\u6a21\u6001AI\u6846\u67b6\uff0c\u901a\u8fc7\u5916\u90e8\u5de5\u5177\u589e\u5f3a\u548c\u81ea\u9002\u5e94\u63a8\u7406\u6765\u89e3\u51b3\u5fc3\u8840\u7ba1\u75be\u75c5\u65e9\u671f\u68c0\u6d4b\u7684\u4e34\u5e8a\u9650\u5236\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5fc3\u8840\u7ba1\u75be\u75c5\u662f\u5168\u7403\u4e3b\u8981\u6b7b\u56e0\uff0c\u4f46\u533b\u7597\u5de5\u4f5c\u8005\u4e25\u91cd\u77ed\u7f3a\u3002\u73b0\u6709AI\u7cfb\u7edf\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u5b58\u5728\u9650\u5236\uff1a\u57fa\u4e8e\u63d0\u793a\u7684\u89d2\u8272\u5206\u914d\u3001\u50f5\u5316\u7684\u5de5\u4f5c\u6d41\u7a0b\u3001\u9759\u6001\u77e5\u8bc6\u5e93\u4ee5\u53ca\u6709\u9650\u7684\u8f93\u5165\u8f93\u51fa\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u6846\u67b6CardAIc-Agents\uff0c\u5305\u542bCardiacRAG\u4ee3\u7406\u751f\u6210\u53ef\u66f4\u65b0\u7684\u5fc3\u810f\u77e5\u8bc6\u8ba1\u5212\uff0c\u4e3b\u4ee3\u7406\u96c6\u6210\u5de5\u5177\u81ea\u4e3b\u6267\u884c\u8ba1\u5212\u3002\u91c7\u7528\u9010\u6b65\u66f4\u65b0\u7b56\u7565\u52a8\u6001\u4f18\u5316\u8ba1\u5212\uff0c\u5f15\u5165\u591a\u5b66\u79d1\u8ba8\u8bba\u5de5\u5177\u5904\u7406\u590d\u6742\u75c5\u4f8b\uff0c\u5e76\u63d0\u4f9b\u89c6\u89c9\u5ba1\u67e5\u9762\u677f\u8f85\u52a9\u9a8c\u8bc1\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCardAIc-Agents\u76f8\u6bd4\u4e3b\u6d41\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3001\u6700\u5148\u8fdb\u7684\u4ee3\u7406\u7cfb\u7edf\u548c\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6548\u7387\u3002", "conclusion": "CardAIc-Agents\u6846\u67b6\u901a\u8fc7\u5de5\u5177\u589e\u5f3a\u548c\u81ea\u9002\u5e94\u63a8\u7406\u6709\u6548\u89e3\u51b3\u4e86\u5fc3\u8840\u7ba1\u75be\u75c5AI\u68c0\u6d4b\u7684\u4e34\u5e8a\u9650\u5236\uff0c\u4e3a\u4e2a\u6027\u5316\u5fc3\u810f\u62a4\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13327", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13327", "abs": "https://arxiv.org/abs/2508.13327", "authors": ["Sarthak Khanna", "Armin Berger", "David Berghaus", "Tobias Deusser", "Lorenz Sparrenberg", "Rafet Sifa"], "title": "Towards Unified Multimodal Financial Forecasting: Integrating Sentiment Embeddings and Market Indicators via Cross-Modal Attention", "comment": "Accepted in IEEE-DSAA 2025", "summary": "We propose STONK (Stock Optimization using News Knowledge), a multimodal\nframework integrating numerical market indicators with sentiment-enriched news\nembeddings to improve daily stock-movement prediction. By combining numerical &\ntextual embeddings via feature concatenation and cross-modal attention, our\nunified pipeline addresses limitations of isolated analyses. Backtesting shows\nSTONK outperforms numeric-only baselines. A comprehensive evaluation of fusion\nstrategies and model configurations offers evidence-based guidance for scalable\nmultimodal financial forecasting. Source code is available on GitHub", "AI": {"tldr": "STONK\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u80a1\u7968\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u6570\u503c\u5e02\u573a\u6307\u6807\u548c\u60c5\u611f\u589e\u5f3a\u7684\u65b0\u95fb\u5d4c\u5165\uff0c\u901a\u8fc7\u7279\u5f81\u62fc\u63a5\u548c\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u63d0\u5347\u80a1\u7968\u6da8\u8dcc\u9884\u6d4b\u6027\u80fd", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5b64\u7acb\u5206\u6790\u65b9\u6cd5\u5728\u80a1\u7968\u9884\u6d4b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u6574\u5408\u6570\u503c\u548c\u6587\u672c\u4fe1\u606f\u6765\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027", "method": "\u4f7f\u7528\u7279\u5f81\u62fc\u63a5\u548c\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u6570\u503c\u5e02\u573a\u6307\u6807\u4e0e\u60c5\u611f\u589e\u5f3a\u7684\u65b0\u95fb\u5d4c\u5165\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u591a\u6a21\u6001\u9884\u6d4b\u7ba1\u9053", "result": "\u56de\u6d4b\u663e\u793aSTONK\u4f18\u4e8e\u7eaf\u6570\u503c\u57fa\u7ebf\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u878d\u5408\u7b56\u7565\u548c\u6a21\u578b\u914d\u7f6e\u7684\u5b9e\u8bc1\u6307\u5bfc", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001\u91d1\u878d\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u6e90\u4ee3\u7801\u5df2\u5728GitHub\u5f00\u6e90"}}
{"id": "2508.13333", "categories": ["cs.AI", "cs.NE", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.13333", "abs": "https://arxiv.org/abs/2508.13333", "authors": ["Chentong Chen", "Mengyuan Zhong", "Jianyong Sun", "Ye Fan", "Jialong Shi"], "title": "HiFo-Prompt: Prompting with Hindsight and Foresight for LLM-based Automatic Heuristic Design", "comment": "9 pages, 6 figures", "summary": "LLM-based Automatic Heuristic Design (AHD) within Evolutionary Computation\n(EC) frameworks has shown promising results. However, its effectiveness is\nhindered by the use of static operators and the lack of knowledge accumulation\nmechanisms. We introduce HiFo-Prompt, a framework that guides LLMs with two\nsynergistic prompting strategies: Foresight and Hindsight. Foresight-based\nprompts adaptively steer the search based on population dynamics, managing the\nexploration-exploitation trade-off. In addition, hindsight-based prompts mimic\nhuman expertise by distilling successful heuristics from past generations into\nfundamental, reusable design principles. This dual mechanism transforms\ntransient discoveries into a persistent knowledge base, enabling the LLM to\nlearn from its own experience. Empirical results demonstrate that HiFo-Prompt\nsignificantly outperforms state-of-the-art LLM-based AHD methods, generating\nhigher-quality heuristics while achieving substantially faster convergence and\nsuperior query efficiency.", "AI": {"tldr": "HiFo-Prompt\u6846\u67b6\u901a\u8fc7\u524d\u77bb\u6027\u548c\u540e\u987e\u6027\u63d0\u793a\u7b56\u7565\uff0c\u89e3\u51b3\u4e86LLM\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4e2d\u9759\u6001\u64cd\u4f5c\u7b26\u548c\u77e5\u8bc6\u79ef\u7d2f\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u542f\u53d1\u5f0f\u751f\u6210\u8d28\u91cf\u548c\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u5728\u8fdb\u5316\u8ba1\u7b97\u6846\u67b6\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u53d7\u5230\u9759\u6001\u64cd\u4f5c\u7b26\u548c\u7f3a\u4e4f\u77e5\u8bc6\u79ef\u7d2f\u673a\u5236\u7684\u9650\u5236\uff0c\u5f71\u54cd\u4e86\u5176\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faHiFo-Prompt\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u79cd\u534f\u540c\u63d0\u793a\u7b56\u7565\uff1a\u524d\u77bb\u6027\u63d0\u793a\u57fa\u4e8e\u79cd\u7fa4\u52a8\u6001\u81ea\u9002\u5e94\u5f15\u5bfc\u641c\u7d22\uff0c\u7ba1\u7406\u63a2\u7d22-\u5229\u7528\u6743\u8861\uff1b\u540e\u987e\u6027\u63d0\u793a\u4ece\u8fc7\u53bb\u4e16\u4ee3\u7684\u6210\u529f\u542f\u53d1\u5f0f\u4e2d\u63d0\u70bc\u53ef\u91cd\u7528\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u6a21\u4eff\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660eHiFo-Prompt\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u4e8eLLM\u7684AHD\u65b9\u6cd5\uff0c\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u542f\u53d1\u5f0f\uff0c\u540c\u65f6\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u5353\u8d8a\u7684\u67e5\u8be2\u6548\u7387\u3002", "conclusion": "\u8be5\u53cc\u673a\u5236\u6846\u67b6\u5c06\u77ac\u65f6\u53d1\u73b0\u8f6c\u5316\u4e3a\u6301\u4e45\u77e5\u8bc6\u5e93\uff0c\u4f7fLLM\u80fd\u591f\u4ece\u81ea\u8eab\u7ecf\u9a8c\u4e2d\u5b66\u4e60\uff0c\u4e3a\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u77e5\u8bc6\u79ef\u7d2f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13371", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13371", "abs": "https://arxiv.org/abs/2508.13371", "authors": ["Ronit Virwani", "Ruchika Suryawanshi"], "title": "LOOP: A Plug-and-Play Neuro-Symbolic Framework for Enhancing Planning in Autonomous Systems", "comment": "Submitted to IAAI-26", "summary": "Planning is one of the most critical tasks in autonomous systems, where even\na small error can lead to major failures or million-dollar losses. Current\nstate-of-the-art neural planning approaches struggle with complex domains,\nproducing plans with missing preconditions, inconsistent goals, and\nhallucinations. While classical planners provide logical guarantees, they lack\nthe flexibility and natural language understanding capabilities needed for\nmodern autonomous systems. Existing neuro-symbolic approaches use one-shot\ntranslation from natural language to formal plans, missing the opportunity for\nneural and symbolic components to work and refine solutions together. To\naddress this gap, we develop LOOP -- a novel neuro-symbolic planning framework\nthat treats planning as an iterative conversation between neural and symbolic\ncomponents rather than simple translation. LOOP integrates 13 coordinated\nneural features including graph neural networks for spatial relationships,\nmulti-agent validation for consensus-based correctness, hierarchical\ndecomposition for complex task management, and causal memory that learns from\nboth successes and failures. Unlike existing approaches, LOOP generates PDDL\nspecifications, refines them iteratively based on symbolic feedback, and builds\na causal knowledge base from execution traces. LOOP was evaluated on six\nstandard IPC benchmark domains, where it achieved 85.8% success rate compared\nto LLM+P (55.0%), LLM-as-Planner (19.2%), and Tree-of-Thoughts (3.3%). This\nwork shows that the key to reliable planning is not in choosing between neural\nnetworks or symbolic reasoners but it lies in making them actually ``talk'' to\neach other during the entire process. LOOP provides a thorough blueprint for\nbuilding autonomous systems that can finally be trusted with critical\nreal-world applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.13387", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13387", "abs": "https://arxiv.org/abs/2508.13387", "authors": ["Thye Shan Ng", "Caren Soyeon Han", "Eun-Jung Holden"], "title": "SPANER: Shared Prompt Aligner for Multimodal Semantic Representation", "comment": null, "summary": "Recent advances in multimodal Parameter-Efficient Fine-Tuning (PEFT) have\nsignificantly improved performance on downstream tasks such as few-shot\nretrieval. However, most existing approaches focus on task-specific gains while\nneglecting the structure of the multimodal embedding space. As a result,\nmodality-specific representations often remain isolated, limiting cross-modal\ngeneralisation. In this work, we introduce Shared Prompt AligNER (SPANER), a\nmodality-agnostic PEFT framework designed to embed inputs from diverse\nmodalities into a unified semantic space. At its core, SPANER employs a shared\nprompt mechanism that acts as a conceptual anchor, enabling semantically\nrelated instances to converge spatially regardless of modality. This shared\nprompt design is inherently extensible, supporting the seamless integration of\nadditional modalities, such as audio, without altering the core architecture.\nThrough comprehensive experiments across vision-language and audio-visual\nbenchmarks, SPANER demonstrates competitive few-shot retrieval performance\nwhile preserving high semantic coherence in the learned embedding space. Our\nresults highlight the importance of aligning embedding structures, rather than\nmerely tuning adapter weights, for scalable multimodal learning.", "AI": {"tldr": "SPANER\u662f\u4e00\u4e2a\u6a21\u6001\u65e0\u5173\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u63d0\u793a\u673a\u5236\u5c06\u4e0d\u540c\u6a21\u6001\u8f93\u5165\u5d4c\u5165\u5230\u7edf\u4e00\u8bed\u4e49\u7a7a\u95f4\uff0c\u63d0\u5347\u8de8\u6a21\u6001\u6cdb\u5316\u80fd\u529b", "motivation": "\u73b0\u6709\u591a\u6a21\u6001PEFT\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u7279\u5b9a\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u5ffd\u89c6\u4e86\u591a\u6a21\u6001\u5d4c\u5165\u7a7a\u95f4\u7684\u7ed3\u6784\uff0c\u5bfc\u81f4\u6a21\u6001\u7279\u5b9a\u8868\u793a\u5b64\u7acb\uff0c\u9650\u5236\u4e86\u8de8\u6a21\u6001\u6cdb\u5316", "method": "\u63d0\u51faSPANER\u6846\u67b6\uff0c\u91c7\u7528\u5171\u4eab\u63d0\u793a\u673a\u5236\u4f5c\u4e3a\u6982\u5ff5\u951a\u70b9\uff0c\u4f7f\u8bed\u4e49\u76f8\u5173\u5b9e\u4f8b\u5728\u7a7a\u95f4\u4e2d\u6536\u655b\uff0c\u652f\u6301\u65e0\u7f1d\u96c6\u6210\u65b0\u6a21\u6001\u800c\u4e0d\u6539\u53d8\u6838\u5fc3\u67b6\u6784", "result": "\u5728\u89c6\u89c9-\u8bed\u8a00\u548c\u97f3\u9891-\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u7ade\u4e89\u529b\u7684\u5c11\u6837\u672c\u68c0\u7d22\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b66\u4e60\u5d4c\u5165\u7a7a\u95f4\u7684\u9ad8\u8bed\u4e49\u4e00\u81f4\u6027", "conclusion": "\u5f3a\u8c03\u5bf9\u9f50\u5d4c\u5165\u7ed3\u6784\u7684\u91cd\u8981\u6027\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u8c03\u6574\u9002\u914d\u5668\u6743\u91cd\uff0c\u5bf9\u4e8e\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001\u5b66\u4e60\u81f3\u5173\u91cd\u8981"}}
{"id": "2508.13404", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13404", "abs": "https://arxiv.org/abs/2508.13404", "authors": ["Nicole Cho", "Kirsty Fielding", "William Watson", "Sumitra Ganesh", "Manuela Veloso"], "title": "TASER: Table Agents for Schema-guided Extraction and Recommendation", "comment": null, "summary": "Real-world financial documents report essential information about an entity's\nfinancial holdings that can span millions of different financial instrument\ntypes. Yet, these details are often buried in messy, multi-page, fragmented\ntables - for example, 99.4% of the tables in our dataset have no bounding boxes\nwith the maximum number of rows amounting to 426 per table across 44 pages. To\ntackle these unique challenges from real-world tables, we present a\ncontinuously learning, agentic table extraction system, TASER (Table Agents for\nSchema-guided Extraction and Recommendation) that extracts highly unstructured,\nmulti-page, heterogeneous tables into normalized, schema-conforming outputs.\nOur table agents execute on table detection, classification, extraction, and\nrecommendations by leveraging an initial schema. Then, our Recommender Agent\nreviews the outputs, recommends schema revisions, and decides on the final\nrecommendations, enabling TASER to outperform existing table detection models\nsuch as Table Transformer by 10.1%. Within this continuous learning process, we\nhighlight that larger batch sizes result in a 104.3% increase in schema\nrecommendations that are actionable and utilized, resulting in a 9.8% increase\nin extracted holdings - highlighting the importance of a continuous learning\nprocess. To train TASER, we have manually labeled 22,584 pages (28,150,449\ntokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of\nthe first real financial table datasets. We release our dataset TASERTab to\nenable the research community to access real-world financial tables and\noutputs. Our results highlight the promise of agentic, schema-guided extraction\nsystems for robust understanding of real-world financial tables.", "AI": {"tldr": "TASER\u662f\u4e00\u4e2a\u6301\u7eed\u5b66\u4e60\u7684\u667a\u80fd\u8868\u683c\u63d0\u53d6\u7cfb\u7edf\uff0c\u4e13\u95e8\u5904\u7406\u771f\u5b9e\u4e16\u754c\u4e2d\u9ad8\u5ea6\u975e\u7ed3\u6784\u5316\u3001\u591a\u9875\u3001\u5f02\u6784\u7684\u91d1\u878d\u8868\u683c\uff0c\u901a\u8fc7\u6a21\u5f0f\u5f15\u5bfc\u7684\u63d0\u53d6\u548c\u63a8\u8350\u5b9e\u73b0\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u91d1\u878d\u6587\u6863\u4e2d\u7684\u8868\u683c\u4fe1\u606f\u5f80\u5f80\u57cb\u85cf\u5728\u6df7\u4e71\u7684\u591a\u9875\u788e\u7247\u5316\u8868\u683c\u4e2d\uff0899.4%\u7684\u8868\u683c\u6ca1\u6709\u8fb9\u754c\u6846\uff09\uff0c\u73b0\u6709\u8868\u683c\u68c0\u6d4b\u6a21\u578b\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u771f\u5b9e\u4e16\u754c\u7684\u590d\u6742\u8868\u683c\u3002", "method": "\u5f00\u53d1\u4e86TASER\u7cfb\u7edf\uff0c\u5305\u542b\u8868\u683c\u68c0\u6d4b\u3001\u5206\u7c7b\u3001\u63d0\u53d6\u548c\u63a8\u8350\u4ee3\u7406\uff0c\u5229\u7528\u521d\u59cb\u6a21\u5f0f\u6267\u884c\u63d0\u53d6\uff0c\u7136\u540e\u901a\u8fc7\u63a8\u8350\u4ee3\u7406\u5ba1\u67e5\u8f93\u51fa\u3001\u5efa\u8bae\u6a21\u5f0f\u4fee\u8ba2\u5e76\u505a\u51fa\u6700\u7ec8\u51b3\u7b56\uff0c\u5b9e\u73b0\u6301\u7eed\u5b66\u4e60\u3002", "result": "TASER\u6bd4Table Transformer\u7b49\u73b0\u6709\u8868\u683c\u68c0\u6d4b\u6a21\u578b\u6027\u80fd\u63d0\u534710.1%\uff0c\u5927\u6279\u91cf\u5904\u7406\u4f7f\u53ef\u64cd\u4f5c\u7684\u6a21\u5f0f\u5efa\u8bae\u589e\u52a0104.3%\uff0c\u63d0\u53d6\u7684\u6301\u4ed3\u91cf\u589e\u52a09.8%\u3002\u6784\u5efa\u4e86\u5305\u542b22,584\u9875\u30013,213\u4e2a\u8868\u683c\u7684\u771f\u5b9e\u91d1\u878d\u6570\u636e\u96c6TASERTab\u3002", "conclusion": "\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u5f0f\u5f15\u5bfc\u63d0\u53d6\u7cfb\u7edf\u5728\u7406\u89e3\u771f\u5b9e\u4e16\u754c\u91d1\u878d\u8868\u683c\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u6301\u7eed\u5b66\u4e60\u8fc7\u7a0b\u5bf9\u4e8e\u5904\u7406\u590d\u6742\u91d1\u878d\u6587\u6863\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.13421", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2508.13421", "abs": "https://arxiv.org/abs/2508.13421", "authors": ["Gabrielle Wehr", "Reuben Rideaux", "Amaya J. Fox", "David R. Lightfoot", "Jason Tangen", "Jason B. Mattingley", "Shane E. Ehrhardt"], "title": "Virtuous Machines: Towards Artificial General Science", "comment": null, "summary": "Artificial intelligence systems are transforming scientific discovery by\naccelerating specific research tasks, from protein structure prediction to\nmaterials design, yet remain confined to narrow domains requiring substantial\nhuman oversight. The exponential growth of scientific literature and increasing\ndomain specialisation constrain researchers' capacity to synthesise knowledge\nacross disciplines and develop unifying theories, motivating exploration of\nmore general-purpose AI systems for science. Here we show that a\ndomain-agnostic, agentic AI system can independently navigate the scientific\nworkflow - from hypothesis generation through data collection to manuscript\npreparation. The system autonomously designed and executed three psychological\nstudies on visual working memory, mental rotation, and imagery vividness,\nexecuted one new online data collection with 288 participants, developed\nanalysis pipelines through 8-hour+ continuous coding sessions, and produced\ncompleted manuscripts. The results demonstrate the capability of AI scientific\ndiscovery pipelines to conduct non-trivial research with theoretical reasoning\nand methodological rigour comparable to experienced researchers, though with\nlimitations in conceptual nuance and theoretical interpretation. This is a step\ntoward embodied AI that can test hypotheses through real-world experiments,\naccelerating discovery by autonomously exploring regions of scientific space\nthat human cognitive and resource constraints might otherwise leave unexplored.\nIt raises important questions about the nature of scientific understanding and\nthe attribution of scientific credit.", "AI": {"tldr": "AI\u7cfb\u7edf\u80fd\u591f\u81ea\u4e3b\u5b8c\u6210\u4ece\u5047\u8bbe\u751f\u6210\u5230\u8bba\u6587\u64b0\u5199\u7684\u5b8c\u6574\u79d1\u7814\u6d41\u7a0b\uff0c\u5728\u5fc3\u7406\u5b66\u7814\u7a76\u4e2d\u5c55\u793a\u4e86\u4e0e\u4eba\u7c7b\u7814\u7a76\u8005\u76f8\u5f53\u7684\u63a8\u7406\u80fd\u529b\u548c\u65b9\u6cd5\u4e25\u8c28\u6027", "motivation": "\u79d1\u5b66\u6587\u732e\u7684\u6307\u6570\u7ea7\u589e\u957f\u548c\u9886\u57df\u4e13\u4e1a\u5316\u9650\u5236\u4e86\u7814\u7a76\u8005\u8de8\u5b66\u79d1\u6574\u5408\u77e5\u8bc6\u7684\u80fd\u529b\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u901a\u7528\u7684AI\u7cfb\u7edf\u6765\u52a0\u901f\u79d1\u5b66\u53d1\u73b0", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u9886\u57df\u65e0\u5173\u7684\u667a\u80fdAI\u7cfb\u7edf\uff0c\u81ea\u4e3b\u8bbe\u8ba1\u5e76\u6267\u884c\u4e86\u4e09\u4e2a\u5fc3\u7406\u5b66\u7814\u7a76\uff08\u89c6\u89c9\u5de5\u4f5c\u8bb0\u5fc6\u3001\u5fc3\u7406\u65cb\u8f6c\u3001\u610f\u8c61\u751f\u52a8\u6027\uff09\uff0c\u8fdb\u884c\u4e86\u5305\u542b288\u540d\u53c2\u4e0e\u8005\u7684\u5728\u7ebf\u6570\u636e\u6536\u96c6\uff0c\u5e76\u901a\u8fc78\u5c0f\u65f6\u4ee5\u4e0a\u7684\u8fde\u7eed\u7f16\u7801\u5f00\u53d1\u5206\u6790\u6d41\u7a0b", "result": "\u7cfb\u7edf\u80fd\u591f\u8fdb\u884c\u975e\u5e73\u51e1\u7684\u7814\u7a76\u5de5\u4f5c\uff0c\u5c55\u73b0\u51fa\u4e0e\u7ecf\u9a8c\u4e30\u5bcc\u7814\u7a76\u8005\u76f8\u5f53\u7684\u7406\u8bba\u63a8\u7406\u548c\u65b9\u6cd5\u4e25\u8c28\u6027\uff0c\u4f46\u5728\u6982\u5ff5\u7ec6\u5fae\u5dee\u522b\u548c\u7406\u8bba\u89e3\u91ca\u65b9\u9762\u5b58\u5728\u5c40\u9650", "conclusion": "\u8fd9\u662f\u5411\u80fd\u591f\u901a\u8fc7\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u5047\u8bbe\u7684\u5177\u8eabAI\u8fc8\u51fa\u7684\u4e00\u6b65\uff0c\u53ef\u4ee5\u81ea\u4e3b\u63a2\u7d22\u4eba\u7c7b\u8ba4\u77e5\u548c\u8d44\u6e90\u9650\u5236\u53ef\u80fd\u65e0\u6cd5\u89e6\u53ca\u7684\u79d1\u5b66\u9886\u57df\uff0c\u540c\u65f6\u4e5f\u5f15\u53d1\u4e86\u5173\u4e8e\u79d1\u5b66\u7406\u89e3\u672c\u8d28\u548c\u79d1\u5b66\u8d21\u732e\u5f52\u5c5e\u7684\u91cd\u8981\u95ee\u9898"}}
{"id": "2508.13433", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13433", "abs": "https://arxiv.org/abs/2508.13433", "authors": ["Jiayu Fang", "Zhiqi Shao", "S T Boris Choy", "Junbin Gao"], "title": "STPFormer: A State-of-the-Art Pattern-Aware Spatio-Temporal Transformer for Traffic Forecasting", "comment": null, "summary": "Spatio-temporal traffic forecasting is challenging due to complex temporal\npatterns, dynamic spatial structures, and diverse input formats. Although\nTransformer-based models offer strong global modeling, they often struggle with\nrigid temporal encoding and weak space-time fusion. We propose STPFormer, a\nSpatio-Temporal Pattern-Aware Transformer that achieves state-of-the-art\nperformance via unified and interpretable representation learning. It\nintegrates four modules: Temporal Position Aggregator (TPA) for pattern-aware\ntemporal encoding, Spatial Sequence Aggregator (SSA) for sequential spatial\nlearning, Spatial-Temporal Graph Matching (STGM) for cross-domain alignment,\nand an Attention Mixer for multi-scale fusion. Experiments on five real-world\ndatasets show that STPFormer consistently sets new SOTA results, with ablation\nand visualizations confirming its effectiveness and generalizability.", "AI": {"tldr": "STPFormer\u662f\u4e00\u4e2a\u65f6\u7a7a\u6a21\u5f0f\u611f\u77e5Transformer\u6a21\u578b\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u5728\u65f6\u7a7a\u4ea4\u901a\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u6a21\u5757\u6765\u5904\u7406\u590d\u6742\u7684\u65f6\u7a7a\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u7684Transformer\u6a21\u578b\u5728\u65f6\u7a7a\u4ea4\u901a\u9884\u6d4b\u4e2d\u5b58\u5728\u65f6\u95f4\u7f16\u7801\u50f5\u5316\u548c\u65f6\u7a7a\u878d\u5408\u80fd\u529b\u5f31\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u65f6\u7a7a\u6a21\u5f0f\u548c\u591a\u6837\u5316\u7684\u8f93\u5165\u683c\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86STPFormer\u6a21\u578b\uff0c\u5305\u542b\u56db\u4e2a\u6a21\u5757\uff1aTemporal Position Aggregator\uff08TPA\uff09\u7528\u4e8e\u6a21\u5f0f\u611f\u77e5\u65f6\u95f4\u7f16\u7801\uff0cSpatial Sequence Aggregator\uff08SSA\uff09\u7528\u4e8e\u5e8f\u5217\u7a7a\u95f4\u5b66\u4e60\uff0cSpatial-Temporal Graph Matching\uff08STGM\uff09\u7528\u4e8e\u8de8\u57df\u5bf9\u9f50\uff0c\u4ee5\u53caAttention Mixer\u7528\u4e8e\u591a\u5c3a\u5ea6\u878d\u5408\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSTPFormer\u59cb\u7ec8\u8fbe\u5230\u65b0\u7684SOTA\u7ed3\u679c\uff0c\u6d88\u878d\u5b9e\u9a8c\u548c\u53ef\u89c6\u5316\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "STPFormer\u901a\u8fc7\u7edf\u4e00\u7684\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u7a7a\u4ea4\u901a\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u590d\u6742\u65f6\u7a7a\u6a21\u5f0f\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13437", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13437", "abs": "https://arxiv.org/abs/2508.13437", "authors": ["Cheikh Ahmed", "Mahdi Mostajabdaveh", "Samin Aref", "Zirui Zhou"], "title": "Discrete Optimization of Min-Max Violation and its Applications Across Computational Sciences", "comment": null, "summary": "We introduce the Discrete Min-Max Violation (DMMV) as a general optimization\nproblem which seeks an assignment of discrete values to variables that\nminimizes the largest constraint violation. This context-free mathematical\nformulation is applicable to a wide range of use cases that have worst-case\nperformance requirements. After defining the DMMV problem mathematically, we\nexplore its properties to establish a foundational understanding. To tackle\nDMMV instance sizes of practical relevance, we develop a GPU-accelerated\nheuristic that takes advantage of the mathematical properties of DMMV for\nspeeding up the solution process. We demonstrate the versatile applicability of\nour heuristic by solving three optimization problems as use cases: (1)\npost-training quantization of language models, (2) discrete tomography, and (3)\nFinite Impulse Response (FIR) filter design. In quantization without outlier\nseparation, our heuristic achieves 14% improvement on average over existing\nmethods. In discrete tomography, it reduces reconstruction error by 16% under\nuniform noise and accelerates computations by a factor of 6 on GPU. For FIR\nfilter design, it nearly achieves 50% ripple reduction compared to using the\ncommercial integer optimization solver, Gurobi. Our comparative results point\nto the benefits of studying DMMV as a context-free optimization problem and the\nadvantages that our proposed heuristic offers on three distinct problems. Our\nGPU-accelerated heuristic will be made open-source to further stimulate\nresearch on DMMV and its other applications. The code is available at\nhttps://anonymous.4open.science/r/AMVM-5F3E/", "AI": {"tldr": "\u63d0\u51fa\u79bb\u6563\u6700\u5c0f-\u6700\u5927\u8fdd\u7ea6(DMMV)\u4f18\u5316\u95ee\u9898\uff0c\u5f00\u53d1GPU\u52a0\u901f\u8d2b\u4f8b\u7b97\u6cd5\uff0c\u5728\u8bed\u8a00\u6a21\u578b\u91cf\u5316\u3001\u79bb\u6563\u65ad\u5c42\u626b\u63cf\u548cFIR\u6ee4\u6ce2\u5668\u8bbe\u8ba1\u4e2d\u53d6\u5f97\u663e\u8457\u6539\u5584", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5177\u6709\u6700\u574f\u60c5\u51b5\u6027\u80fd\u8981\u6c42\u7684\u5e7f\u6cdb\u4f18\u5316\u95ee\u9898\uff0c\u9700\u8981\u4e00\u4e2a\u901a\u7528\u7684\u6570\u5b66\u6846\u67b6\u6765\u5f62\u5f0f\u5316\u8fd9\u7c7b\u95ee\u9898\u5e76\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848", "method": "\u6570\u5b66\u5b9a\u4e49DMMV\u95ee\u9898\uff0c\u5206\u6790\u5176\u6027\u8d28\u7279\u5f81\uff0c\u5f00\u53d1GPU\u52a0\u901f\u7684\u8d2b\u4f8b\u7b97\u6cd5\uff0c\u5229\u7528DMMV\u7684\u6570\u5b66\u6027\u8d28\u63d0\u9ad8\u6c42\u89e3\u901f\u5ea6", "result": "\u5728\u8bed\u8a00\u6a21\u578b\u91cf\u5316\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534715%\uff0c\u79bb\u6563\u65ad\u5c42\u626b\u63cf\u4e2d\u964d\u4f4e16%\u91cd\u5efa\u8bef\u5dee\u5e76\u52a0\u901f6\u500d\uff0cFIR\u6ee4\u6ce2\u5668\u8bbe\u8ba1\u4e2d\u6d6e\u52a8\u6c34\u5e73\u964d\u4f4e\u8fd150%", "conclusion": "DMMV\u4f5c\u4e3a\u4e00\u4e2a\u901a\u7528\u4f18\u5316\u6846\u67b6\u5177\u6709\u5f3a\u5927\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u63d0\u51fa\u7684GPU\u52a0\u901f\u8d2b\u4f8b\u7b97\u6cd5\u5728\u591a\u4e2a\u9886\u57df\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u5c06\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u66f4\u591a\u5e94\u7528\u7814\u7a76"}}
{"id": "2508.13465", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13465", "abs": "https://arxiv.org/abs/2508.13465", "authors": ["Yuzhi Tang", "Tianxiao Li", "Elizabeth Li", "Chris J. Maddison", "Honghua Dong", "Yangjun Ruan"], "title": "LM Agents May Fail to Act on Their Own Risk Knowledge", "comment": null, "summary": "Language model (LM) agents have demonstrated significant potential for\nautomating real-world tasks, yet they pose a diverse array of potential, severe\nrisks in safety-critical scenarios. In this work, we identify a significant gap\nbetween LM agents' risk awareness and safety execution abilities: while they\noften answer \"Yes\" to queries like \"Is executing `sudo rm -rf /*' dangerous?\",\nthey will likely fail to identify such risks in instantiated trajectories or\neven directly perform these risky actions when acting as agents. To\nsystematically investigate this, we develop a comprehensive evaluation\nframework to examine agents' safety across three progressive dimensions: 1)\ntheir knowledge about potential risks, 2) their ability to identify\ncorresponding risks in execution trajectories, and 3) their actual behaviors to\navoid executing these risky actions. Our evaluation reveals two critical\nperformance gaps that resemble the generator-validator gaps observed in LMs:\nwhile agents demonstrate near-perfect risk knowledge ($>98\\%$ pass rates), they\nfail to apply this knowledge when identifying risks in actual scenarios (with\nperformance dropping by $>23\\%$) and often still execute risky actions ($<26\\%$\npass rates). Notably, this trend persists across more capable LMs as well as in\nspecialized reasoning models like DeepSeek-R1, indicating that simply scaling\nmodel capabilities or inference compute does not inherently resolve safety\nconcerns. Instead, we take advantage of these observed gaps to develop a risk\nverifier that independently critiques the proposed actions by agents, with an\nabstractor that converts specific execution trajectories into abstract\ndescriptions where LMs can more effectively identify the risks. Our overall\nsystem achieves a significant reduction of risky action execution by $55.3\\%$\nover vanilla-prompted agents.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5b58\u5728\u98ce\u9669\u610f\u8bc6\u4e0e\u5b89\u5168\u6267\u884c\u80fd\u529b\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u8ddd\uff0c\u5373\u4f7f\u77e5\u9053\u67d0\u4e9b\u64cd\u4f5c\u5371\u9669\uff0c\u5728\u5b9e\u9645\u6267\u884c\u65f6\u4ecd\u4f1a\u6267\u884c\u5371\u9669\u64cd\u4f5c\u3002\u4f5c\u8005\u5f00\u53d1\u4e86\u8bc4\u4f30\u6846\u67b6\u548c\u98ce\u9669\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u6210\u529f\u5c06\u5371\u9669\u64cd\u4f5c\u6267\u884c\u7387\u964d\u4f4e\u4e8655.3%\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u5b58\u5728\u4e25\u91cd\u98ce\u9669\uff0c\u867d\u7136\u5b83\u4eec\u5177\u5907\u98ce\u9669\u77e5\u8bc6\uff0c\u4f46\u5728\u5b9e\u9645\u6267\u884c\u65f6\u65e0\u6cd5\u6709\u6548\u8bc6\u522b\u548c\u907f\u514d\u5371\u9669\u64cd\u4f5c\uff0c\u8fd9\u79cd\u5dee\u8ddd\u9700\u8981\u7cfb\u7edf\u6027\u7684\u7814\u7a76\u548c\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u4e09\u4e2a\u7ef4\u5ea6\u7684\u8bc4\u4f30\u6846\u67b6\uff1a\u98ce\u9669\u77e5\u8bc6\u3001\u98ce\u9669\u8bc6\u522b\u80fd\u529b\u548c\u5b89\u5168\u884c\u4e3a\u6267\u884c\u3002\u57fa\u4e8e\u53d1\u73b0\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u6784\u5efa\u4e86\u98ce\u9669\u9a8c\u8bc1\u5668\u7cfb\u7edf\uff0c\u5305\u542b\u62bd\u8c61\u5668\u5c06\u5177\u4f53\u6267\u884c\u8f68\u8ff9\u8f6c\u6362\u4e3a\u62bd\u8c61\u63cf\u8ff0\uff0c\u4f7f\u6a21\u578b\u80fd\u66f4\u6709\u6548\u8bc6\u522b\u98ce\u9669\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u4ee3\u7406\u98ce\u9669\u77e5\u8bc6\u63a5\u8fd1\u5b8c\u7f8e\uff08>98%\u901a\u8fc7\u7387\uff09\uff0c\u4f46\u5b9e\u9645\u98ce\u9669\u8bc6\u522b\u6027\u80fd\u4e0b\u964d>23%\uff0c\u5371\u9669\u64cd\u4f5c\u6267\u884c\u901a\u8fc7\u7387<26%\u3002\u98ce\u9669\u9a8c\u8bc1\u7cfb\u7edf\u5c06\u5371\u9669\u64cd\u4f5c\u6267\u884c\u7387\u964d\u4f4e\u4e8655.3%\u3002", "conclusion": "\u5355\u7eaf\u6269\u5c55\u6a21\u578b\u80fd\u529b\u6216\u63a8\u7406\u8ba1\u7b97\u65e0\u6cd5\u89e3\u51b3\u5b89\u5168\u95ee\u9898\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u673a\u5236\u3002\u98ce\u9669\u9a8c\u8bc1\u5668\u7cfb\u7edf\u80fd\u6709\u6548\u5f25\u8865\u4ee3\u7406\u7684\u5b89\u5168\u6267\u884c\u5dee\u8ddd\uff0c\u663e\u8457\u964d\u4f4e\u5371\u9669\u64cd\u4f5c\u6267\u884c\u98ce\u9669\u3002"}}
{"id": "2508.13530", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13530", "abs": "https://arxiv.org/abs/2508.13530", "authors": ["Junyeong Park", "Hyeonseo Cho", "Sungjin Ahn"], "title": "CrafterDojo: A Suite of Foundation Models for Building Open-Ended Embodied Agents in Crafter", "comment": null, "summary": "Developing general-purpose embodied agents is a core challenge in AI.\nMinecraft provides rich complexity and internet-scale data, but its slow speed\nand engineering overhead make it unsuitable for rapid prototyping. Crafter\noffers a lightweight alternative that retains key challenges from Minecraft,\nyet its use has remained limited to narrow tasks due to the absence of\nfoundation models that have driven progress in the Minecraft setting. In this\npaper, we present CrafterDojo, a suite of foundation models and tools that\nunlock the Crafter environment as a lightweight, prototyping-friendly, and\nMinecraft-like testbed for general-purpose embodied agent research. CrafterDojo\naddresses this by introducing CrafterVPT, CrafterCLIP, and CrafterSteve-1 for\nbehavior priors, vision-language grounding, and instruction following,\nrespectively. In addition, we provide toolkits for generating behavior and\ncaption datasets (CrafterPlay and CrafterCaption), reference agent\nimplementations, benchmark evaluations, and a complete open-source codebase.", "AI": {"tldr": "\u63d0\u51faCrafterDojo\u5957\u4ef6\uff0c\u5305\u542b\u57fa\u7840\u6a21\u578b\u548c\u5de5\u5177\uff0c\u5c06Crafter\u73af\u5883\u53d8\u6210\u8f7b\u91cf\u7ea7\u3001\u539f\u578b\u53cb\u597d\u7684Minecraft\u7c7b\u4f3c\u6d4b\u8bd5\u5e73\u53f0\uff0c\u652f\u6301\u4f53\u73b0\u667a\u80fd\u4f53\u7cbe\u7814\u7a76", "motivation": "\u89e3\u51b3Minecraft\u73af\u5883\u8fd0\u884c\u6162\u3001\u5de5\u7a0b\u8d39\u7528\u9ad8\u7684\u95ee\u9898\uff0c\u800cCrafter\u73af\u5883\u7f3a\u4e4f\u57fa\u7840\u6a21\u578b\u652f\u6301\uff0c\u9650\u5236\u4e86\u5728\u4f53\u73b0\u667a\u80fd\u4f53\u7cbe\u7814\u7a76\u4e2d\u7684\u5e94\u7528", "method": "\u5f00\u53d1CrafterDojo\u5957\u4ef6\uff0c\u5305\u542bCrafterVPT\uff08\u884c\u4e3a\u5148\u9a8c\uff09\u3001CrafterCLIP\uff08\u89c6\u89c9-\u8bed\u8a00\u57fa\u51c6\uff09\u3001CrafterSteve-1\uff08\u6307\u4ee4\u8ddf\u968f\uff09\u7b49\u57fa\u7840\u6a21\u578b\uff0c\u4ee5\u53ca\u6570\u636e\u96c6\u751f\u6210\u3001\u5f15\u64ce\u5b9e\u73b0\u3001\u6d4b\u8bd5\u8bc4\u4f30\u5de5\u5177", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u5f00\u6e90\u4ee3\u7801\u5e93\uff0c\u4e3aCrafter\u73af\u5883\u63d0\u4f9b\u4e86\u57fa\u7840\u6a21\u578b\u652f\u6301\uff0c\u4f7f\u5176\u6210\u4e3a\u8f7b\u91cf\u7ea7\u4f46\u4fdd\u7559Minecraft\u5173\u952e\u6311\u6218\u7684\u539f\u578b\u5f00\u53d1\u5e73\u53f0", "conclusion": "CrafterDojo\u6700\u7ec8\u89e3\u9501\u4e86Crafter\u73af\u5883\u5728\u4f53\u73b0\u667a\u80fd\u4f53\u7cbe\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u539f\u578b\u5f00\u53d1\u73af\u5883\uff0c\u6709\u52a9\u4e8e\u666e\u904d\u4f53\u73b0\u667a\u80fd\u4f53\u7684\u53d1\u5c55"}}
{"id": "2508.13579", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13579", "abs": "https://arxiv.org/abs/2508.13579", "authors": ["Yue Fang", "Yuxin Guo", "Jiaran Gao", "Hongxin Ding", "Xinke Jiang", "Weibin Liao", "Yongxin Xu", "Yinghao Zhu", "Zhibang Yang", "Liantao Ma", "Junfeng Zhao", "Yasha Wang"], "title": "Toward Better EHR Reasoning in LLMs: Reinforcement Learning with Expert Attention Guidance", "comment": null, "summary": "Improving large language models (LLMs) for electronic health record (EHR)\nreasoning is essential for enabling accurate and generalizable clinical\npredictions. While LLMs excel at medical text understanding, they underperform\non EHR-based prediction tasks due to challenges in modeling temporally\nstructured, high-dimensional data. Existing approaches often rely on hybrid\nparadigms, where LLMs serve merely as frozen prior retrievers while downstream\ndeep learning (DL) models handle prediction, failing to improve the LLM's\nintrinsic reasoning capacity and inheriting the generalization limitations of\nDL models. To this end, we propose EAG-RL, a novel two-stage training framework\ndesigned to intrinsically enhance LLMs' EHR reasoning ability through expert\nattention guidance, where expert EHR models refer to task-specific DL models\ntrained on EHR data. Concretely, EAG-RL first constructs high-quality, stepwise\nreasoning trajectories using expert-guided Monte Carlo Tree Search to\neffectively initialize the LLM's policy. Then, EAG-RL further optimizes the\npolicy via reinforcement learning by aligning the LLM's attention with\nclinically salient features identified by expert EHR models. Extensive\nexperiments on two real-world EHR datasets show that EAG-RL improves the\nintrinsic EHR reasoning ability of LLMs by an average of 14.62%, while also\nenhancing robustness to feature perturbations and generalization to unseen\nclinical domains. These results demonstrate the practical potential of EAG-RL\nfor real-world deployment in clinical prediction tasks. Our code have been\navailable at https://github.com/devilran6/EAG-RL.", "AI": {"tldr": "EAG-RL\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u5bb6\u6ce8\u610f\u529b\u5f15\u5bfc\u6765\u589e\u5f3aLLM\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e73\u5747\u63d0\u534714.62%\u7684\u6027\u80fd", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06LLM\u4f5c\u4e3a\u56fa\u5b9a\u7684\u5148\u9a8c\u68c0\u7d22\u5668\uff0c\u800c\u4e0b\u6e38\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5904\u7406\u9884\u6d4b\uff0c\u65e0\u6cd5\u63d0\u9ad8LLM\u7684\u5185\u5728\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u7ee7\u627f\u4e86DL\u6a21\u578b\u7684\u6cdb\u5316\u9650\u5236", "method": "\u9996\u5148\u4f7f\u7528\u4e13\u5bb6\u5f15\u5bfc\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u5206\u6b65\u63a8\u7406\u8f68\u8ff9\u6765\u521d\u59cb\u5316LLM\u7b56\u7565\uff0c\u7136\u540e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5c06LLM\u7684\u6ce8\u610f\u529b\u4e0e\u4e13\u5bb6EHR\u6a21\u578b\u8bc6\u522b\u7684\u4e34\u5e8a\u663e\u8457\u7279\u5f81\u5bf9\u9f50", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754cEHR\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cEAG-RL\u5e73\u5747\u63d0\u5347LLM\u5185\u5728EHR\u63a8\u7406\u80fd\u529b14.62%\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u5bf9\u7279\u5f81\u6270\u52a8\u7684\u9c81\u68d2\u6027\u548c\u5bf9\u672a\u89c1\u4e34\u5e8a\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b", "conclusion": "EAG-RL\u5728\u4e34\u5e8a\u9884\u6d4b\u4efb\u52a1\u4e2d\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347LLM\u5728EHR\u63a8\u7406\u65b9\u9762\u7684\u6027\u80fd"}}
{"id": "2508.13587", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.13587", "abs": "https://arxiv.org/abs/2508.13587", "authors": ["Lei Chen", "Xuanle Zhao", "Zhixiong Zeng", "Jing Huang", "Liming Zheng", "Yufeng Zhong", "Lin Ma"], "title": "Breaking the SFT Plateau: Multimodal Structured Reinforcement Learning for Chart-to-Code Generation", "comment": "technical report", "summary": "While reinforcement learning (RL) has proven highly effective for general\nreasoning in vision-language models, its application to tasks requiring\nin-depth understanding of information-rich images and generation of structured\noutputs remains underexplored. Chart-to-code generation exemplifies this\nchallenge, demanding complex reasoning over visual charts to generate\nstructured code. Supervised fine-tuning (SFT) alone is often insufficient,\nhighlighting the need for effective RL strategies that appropriately reward\nstructured outputs. We systematically investigate the performance plateau in\nSFT through large-scale experiments and propose Multimodal Structured\nReinforcement Learning (MSRL) for chart-to-code generation, which substantially\nbreaks through this plateau. We construct the largest training corpus to date,\ncontaining 3 million chart-code pairs from real-world arXiv tables to mitigate\nsimplistic patterns of prior synthetic data. Despite reaching state-of-the-art\nperformance, our experiments show that scaling SFT data eventually hits a\nplateau where further increases yield negligible improvements. Our MSRL method\nleverages a multi-granularity structured reward system using multimodal textual\nand visual feedback. At the textual level, rule-based rewards validate\nfine-grained code details. At the visual level, model-based rewards assess\nstructural similarity by rendering generated code into images and employing an\nevaluator model. We implement this within a two-stage curriculum for training\nstability. Results demonstrate that MSRL significantly breaks the SFT plateau,\nimproving high-level metrics by 6.2% and 9.9% on ChartMimic and ReachQA\nbenchmarks respectively, achieving competitive performance with advanced\nclosed-source models.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u591a\u6a21\u6001\u7ed3\u6784\u5316\u5f3a\u5316\u5b66\u4e60(MSRL)\u5728\u56fe\u8868\u8f6c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u591a\u7ea7\u522b\u5956\u52b1\u673a\u5236\u7a81\u7834\u4e86\u76d1\u7763\u5b66\u4e60\u7684\u6027\u80fd\u5e73\u53f0\uff0c\u5728\u4e24\u4e2a\u6807\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f97\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u867d\u7136\u5f3a\u5316\u5b66\u4e60\u5728\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u9700\u8981\u6df1\u5ea6\u7406\u89e3\u4fe1\u606f\u4e30\u5bcc\u56fe\u50cf\u548c\u751f\u6210\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u4efb\u52a1\u4e2d\u5e94\u7528\u4e0d\u8db3\u3002\u56fe\u8868\u8f6c\u4ee3\u7801\u751f\u6210\u4f5c\u4e3a\u4e00\u4e2a\u5177\u6709\u590d\u6742\u89e3\u91ca\u6311\u6218\u7684\u4efb\u52a1\uff0c\u9700\u8981\u6709\u6548\u7684RL\u7b56\u7565\u6765\u5956\u52b1\u7ed3\u6784\u5316\u8f93\u51fa\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u7ed3\u6784\u5316\u5f3a\u5316\u5b66\u4e60(MSRL)\uff0c\u6784\u5efa\u4e86\u5305\u542b300\u4e07\u5bf9\u56fe\u8868-\u4ee3\u7801\u5bf9\u7684\u6700\u5927\u8bad\u7ec3\u8bed\u6599\u5e93\u3002MSRL\u91c7\u7528\u591a\u7ea7\u522b\u7ed3\u6784\u5316\u5956\u52b1\u7cfb\u7edf\uff1a\u6587\u672c\u7ea7\u522b\u4f7f\u7528\u89c4\u5219\u57fa\u7840\u7684\u5956\u52b1\u9a8c\u8bc1\u7ec6\u7c92\u5ea6\u4ee3\u7801\u7ec6\u8282\uff0c\u89c6\u89c9\u7ea7\u522b\u901a\u8fc7\u6e32\u67d3\u751f\u6210\u4ee3\u7801\u4e3a\u56fe\u50cf\u5e76\u4f7f\u7528\u8bc4\u4f30\u6a21\u578b\u6765\u8bc4\u4f30\u7ed3\u6784\u76f8\u4f3c\u6027\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bfe\u7a0b\u8fdb\u884c\u8bad\u7ec3\u7a33\u5b9a\u6027\u4f18\u5316\u3002", "result": "MSRL\u663e\u8457\u7a81\u7834\u4e86SFT\u7684\u6027\u80fd\u5e73\u53f0\uff0c\u5728ChartMimic\u548cReachQA\u6807\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u5206\u522b\u63d0\u5347\u4e866.2%\u548c9.9%\u7684\u9ad8\u7ea7\u6307\u6807\uff0c\u8fbe\u5230\u4e86\u4e0e\u5148\u8fdb\u95ed\u6e90\u6a21\u578b\u76f8\u7ade\u4e89\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u7ed3\u6784\u5316\u5f3a\u5316\u5b66\u4e60\u5728\u590d\u6742\u89e3\u91ca\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u591a\u7ea7\u522b\u5956\u52b1\u673a\u5236\u6210\u529f\u7a81\u7834\u4e86\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u7684\u9650\u5236\uff0c\u4e3a\u7ed3\u6784\u5316\u8f93\u51fa\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13634", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13634", "abs": "https://arxiv.org/abs/2508.13634", "authors": ["Jikai Chen", "Long Chen", "Dong Wang", "Leilei Gan", "Chenyi Zhuang", "Jinjie Gu"], "title": "V2P: From Background Suppression to Center Peaking for Robust GUI Grounding Task", "comment": null, "summary": "Precise localization of GUI elements is crucial for the development of GUI\nagents. Traditional methods rely on bounding box or center-point regression,\nneglecting spatial interaction uncertainty and visual-semantic hierarchies.\nRecent methods incorporate attention mechanisms but still face two key issues:\n(1) ignoring processing background regions causes attention drift from the\ndesired area, and (2) uniform labeling fails to distinguish between center and\nedges of the target UI element, leading to click imprecision. Inspired by how\nhumans visually process and interact with GUI elements, we propose the\nValley-to-Peak (V2P) method to address these issues. To mitigate background\ndistractions, V2P introduces a suppression attention mechanism that minimizes\nthe model's focus on irrelevant regions to highlight the intended region. For\nthe issue of center-edge distinction, V2P applies a Fitts' Law-inspired\napproach by modeling GUI interactions as 2D Gaussian heatmaps where the weight\ngradually decreases from the center towards the edges. The weight distribution\nfollows a Gaussian function, with the variance determined by the target's size.\nConsequently, V2P effectively isolates the target area and teaches the model to\nconcentrate on the most essential point of the UI element. The model trained by\nV2P achieves the performance with 92.3% and 50.5% on two benchmarks\nScreenSpot-v2 and ScreenSpot-Pro. Ablations further confirm each component's\ncontribution, highlighting V2P's generalizability for precise GUI grounding\ntasks.", "AI": {"tldr": "V2P\u65b9\u6cd5\u901a\u8fc7\u6291\u5236\u6ce8\u610f\u529b\u673a\u5236\u548c\u57fa\u4e8eFitts\u5b9a\u5f8b\u7684\u9ad8\u65af\u70ed\u56fe\u5efa\u6a21\uff0c\u89e3\u51b3\u4e86GUI\u5143\u7d20\u5b9a\u4f4d\u4e2d\u7684\u80cc\u666f\u5e72\u6270\u548c\u4e2d\u5fc3\u8fb9\u7f18\u533a\u5206\u95ee\u9898\uff0c\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u8fbe\u523092.3%\u548c50.5%\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfGUI\u5143\u7d20\u5b9a\u4f4d\u65b9\u6cd5\u5ffd\u89c6\u7a7a\u95f4\u4ea4\u4e92\u4e0d\u786e\u5b9a\u6027\u548c\u89c6\u89c9\u8bed\u4e49\u5c42\u6b21\u7ed3\u6784\uff0c\u73b0\u6709\u6ce8\u610f\u529b\u65b9\u6cd5\u5b58\u5728\u80cc\u666f\u533a\u57df\u5e72\u6270\u5bfc\u81f4\u6ce8\u610f\u529b\u6f02\u79fb\uff0c\u4ee5\u53ca\u5747\u5300\u6807\u6ce8\u65e0\u6cd5\u533a\u5206\u76ee\u6807UI\u5143\u7d20\u4e2d\u5fc3\u548c\u8fb9\u7f18\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faValley-to-Peak (V2P)\u65b9\u6cd5\uff1a1) \u6291\u5236\u6ce8\u610f\u529b\u673a\u5236\u51cf\u5c11\u5bf9\u65e0\u5173\u533a\u57df\u7684\u5173\u6ce8\uff1b2) \u57fa\u4e8eFitts\u5b9a\u5f8b\u5c06GUI\u4ea4\u4e92\u5efa\u6a21\u4e3a2D\u9ad8\u65af\u70ed\u56fe\uff0c\u6743\u91cd\u4ece\u4e2d\u5fc3\u5411\u8fb9\u7f18\u9012\u51cf\uff0c\u65b9\u5dee\u7531\u76ee\u6807\u5927\u5c0f\u51b3\u5b9a\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5ScreenSpot-v2\u548cScreenSpot-Pro\u4e0a\u5206\u522b\u8fbe\u523092.3%\u548c50.5%\u7684\u6027\u80fd\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u5404\u7ec4\u4ef6\u8d21\u732e\u3002", "conclusion": "V2P\u65b9\u6cd5\u80fd\u6709\u6548\u9694\u79bb\u76ee\u6807\u533a\u57df\u5e76\u8ba9\u6a21\u578b\u4e13\u6ce8\u4e8eUI\u5143\u7d20\u6700\u5173\u952e\u7684\u70b9\uff0c\u5728\u7cbe\u786eGUI\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u5177\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.13663", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13663", "abs": "https://arxiv.org/abs/2508.13663", "authors": ["Daniel Daza", "Alberto Bernardi", "Luca Costabello", "Christophe Gueret", "Masoud Mansoury", "Michael Cochez", "Martijn Schut"], "title": "Interactive Query Answering on Knowledge Graphs with Soft Entity Constraints", "comment": null, "summary": "Methods for query answering over incomplete knowledge graphs retrieve\nentities that are likely to be answers, which is particularly useful when such\nanswers cannot be reached by direct graph traversal due to missing edges.\nHowever, existing approaches have focused on queries formalized using\nfirst-order-logic. In practice, many real-world queries involve constraints\nthat are inherently vague or context-dependent, such as preferences for\nattributes or related categories. Addressing this gap, we introduce the problem\nof query answering with soft constraints. We propose a Neural Query Reranker\n(NQR) designed to adjust query answer scores by incorporating soft constraints\nwithout disrupting the original answers to a query. NQR operates interactively,\nrefining answers based on incremental examples of preferred and non-preferred\nentities. We extend existing QA benchmarks by generating datasets with soft\nconstraints. Our experiments demonstrate that NQR can capture soft constraints\nwhile maintaining robust query answering performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5728\u77e5\u8bc6\u56fe\u8c31\u67e5\u8be2\u4e2d\u5904\u7406\u8f6f\u7ea6\u675f\u7684\u65b0\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u795e\u7ecf\u67e5\u8be2\u91cd\u6392\u5e8f\u5668(NQR)\u6765\u4ea4\u4e92\u5f0f\u8c03\u6574\u7b54\u6848\u8bc4\u5206\uff0c\u901a\u8fc7\u589e\u91cf\u793a\u4f8b\u6574\u5408\u504f\u597d\u7ea6\u675f\u800c\u4e0d\u7834\u574f\u539f\u59cb\u67e5\u8be2\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e00\u9636\u903b\u8f91\u67e5\u8be2\uff0c\u4f46\u5b9e\u9645\u67e5\u8be2\u5e38\u6d89\u53ca\u6a21\u7cca\u6216\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u8f6f\u7ea6\u675f\uff08\u5982\u5c5e\u6027\u504f\u597d\u3001\u76f8\u5173\u7c7b\u522b\u504f\u597d\uff09\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u67e5\u8be2\u91cd\u6392\u5e8f\u5668(NQR)\uff0c\u901a\u8fc7\u4ea4\u4e92\u65b9\u5f0f\u57fa\u4e8e\u504f\u597d\u548c\u975e\u504f\u597d\u5b9e\u4f53\u7684\u589e\u91cf\u793a\u4f8b\u6765\u8c03\u6574\u67e5\u8be2\u7b54\u6848\u8bc4\u5206\uff0c\u6574\u5408\u8f6f\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u8868\u660eNQR\u80fd\u591f\u6709\u6548\u6355\u83b7\u8f6f\u7ea6\u675f\uff0c\u540c\u65f6\u4fdd\u6301\u7a33\u5065\u7684\u67e5\u8be2\u56de\u7b54\u6027\u80fd\u3002\u6269\u5c55\u4e86\u73b0\u6709QA\u57fa\u51c6\uff0c\u751f\u6210\u4e86\u5305\u542b\u8f6f\u7ea6\u675f\u7684\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86\u77e5\u8bc6\u56fe\u8c31\u67e5\u8be2\u4e2d\u8f6f\u7ea6\u675f\u5904\u7406\u7684\u7a7a\u767d\uff0cNQR\u65b9\u6cd5\u4e3a\u5904\u7406\u6a21\u7cca\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u67e5\u8be2\u7ea6\u675f\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13672", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13672", "abs": "https://arxiv.org/abs/2508.13672", "authors": ["Rehan Raza", "Guanjin Wang", "Kevin Wong", "Hamid Laga", "Marco Fisichella"], "title": "ITL-LIME: Instance-Based Transfer Learning for Enhancing Local Explanations in Low-Resource Data Settings", "comment": "Accepted at the 34th ACM International Conference on Information and\n  Knowledge Management (CIKM 2025)", "summary": "Explainable Artificial Intelligence (XAI) methods, such as Local\nInterpretable Model-Agnostic Explanations (LIME), have advanced the\ninterpretability of black-box machine learning models by approximating their\nbehavior locally using interpretable surrogate models. However, LIME's inherent\nrandomness in perturbation and sampling can lead to locality and instability\nissues, especially in scenarios with limited training data. In such cases, data\nscarcity can result in the generation of unrealistic variations and samples\nthat deviate from the true data manifold. Consequently, the surrogate model may\nfail to accurately approximate the complex decision boundary of the original\nmodel. To address these challenges, we propose a novel Instance-based Transfer\nLearning LIME framework (ITL-LIME) that enhances explanation fidelity and\nstability in data-constrained environments. ITL-LIME introduces instance\ntransfer learning into the LIME framework by leveraging relevant real instances\nfrom a related source domain to aid the explanation process in the target\ndomain. Specifically, we employ clustering to partition the source domain into\nclusters with representative prototypes. Instead of generating random\nperturbations, our method retrieves pertinent real source instances from the\nsource cluster whose prototype is most similar to the target instance. These\nare then combined with the target instance's neighboring real instances. To\ndefine a compact locality, we further construct a contrastive learning-based\nencoder as a weighting mechanism to assign weights to the instances from the\ncombined set based on their proximity to the target instance. Finally, these\nweighted source and target instances are used to train the surrogate model for\nexplanation purposes.", "AI": {"tldr": "\u63d0\u51fa\u4e86ITL-LIME\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u4f8b\u8fc1\u79fb\u5b66\u4e60\u589e\u5f3aLIME\u5728\u6570\u636e\u53d7\u9650\u73af\u5883\u4e0b\u7684\u89e3\u91ca\u4fdd\u771f\u5ea6\u548c\u7a33\u5b9a\u6027\uff0c\u4f7f\u7528\u76f8\u5173\u6e90\u57df\u771f\u5b9e\u5b9e\u4f8b\u800c\u975e\u968f\u673a\u6270\u52a8\u6765\u6539\u8fdb\u89e3\u91ca\u8fc7\u7a0b\u3002", "motivation": "\u4f20\u7edfLIME\u65b9\u6cd5\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u5b58\u5728\u5c40\u90e8\u6027\u548c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u968f\u673a\u6270\u52a8\u53ef\u80fd\u4ea7\u751f\u504f\u79bb\u771f\u5b9e\u6570\u636e\u6d41\u5f62\u7684\u6837\u672c\uff0c\u5bfc\u81f4\u4ee3\u7406\u6a21\u578b\u65e0\u6cd5\u51c6\u786e\u8fd1\u4f3c\u539f\u59cb\u6a21\u578b\u7684\u590d\u6742\u51b3\u7b56\u8fb9\u754c\u3002", "method": "\u5f15\u5165\u5b9e\u4f8b\u8fc1\u79fb\u5b66\u4e60\uff0c\u901a\u8fc7\u805a\u7c7b\u5c06\u6e90\u57df\u5206\u533a\u5e76\u83b7\u53d6\u4ee3\u8868\u6027\u539f\u578b\uff0c\u68c0\u7d22\u4e0e\u76ee\u6807\u5b9e\u4f8b\u6700\u76f8\u4f3c\u7684\u6e90\u7c07\u4e2d\u7684\u76f8\u5173\u771f\u5b9e\u5b9e\u4f8b\uff0c\u7ed3\u5408\u76ee\u6807\u5b9e\u4f8b\u7684\u90bb\u8fd1\u771f\u5b9e\u5b9e\u4f8b\uff0c\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u7f16\u7801\u5668\u4f5c\u4e3a\u52a0\u6743\u673a\u5236\uff0c\u57fa\u4e8e\u5b9e\u4f8b\u4e0e\u76ee\u6807\u5b9e\u4f8b\u7684\u63a5\u8fd1\u7a0b\u5ea6\u5206\u914d\u6743\u91cd\uff0c\u6700\u540e\u7528\u52a0\u6743\u5b9e\u4f8b\u8bad\u7ec3\u4ee3\u7406\u6a21\u578b\u3002", "result": "ITL-LIME\u6846\u67b6\u63d0\u9ad8\u4e86\u89e3\u91ca\u7684\u4fdd\u771f\u5ea6\u548c\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u53d7\u9650\u73af\u5883\u4e0b\uff0c\u901a\u8fc7\u5229\u7528\u76f8\u5173\u6e90\u57df\u7684\u771f\u5b9e\u5b9e\u4f8b\u6765\u66f4\u597d\u5730\u8fd1\u4f3c\u539f\u59cb\u6a21\u578b\u7684\u51b3\u7b56\u8fb9\u754c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LIME\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u5b9e\u4f8b\u8fc1\u79fb\u5b66\u4e60\u548c\u5bf9\u6bd4\u5b66\u4e60\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\u7684\u89e3\u91ca\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.13675", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13675", "abs": "https://arxiv.org/abs/2508.13675", "authors": ["Mariam Arustashvili", "J\u00f6rg Deigm\u00f6ller", "Heiko Paulheim"], "title": "Knowledge Graph Completion for Action Prediction on Situational Graphs -- A Case Study on Household Tasks", "comment": "Accepted at Semantics 2025", "summary": "Knowledge Graphs are used for various purposes, including business\napplications, biomedical analyses, or digital twins in industry 4.0. In this\npaper, we investigate knowledge graphs describing household actions, which are\nbeneficial for controlling household robots and analyzing video footage. In the\nlatter case, the information extracted from videos is notoriously incomplete,\nand completing the knowledge graph for enhancing the situational picture is\nessential. In this paper, we show that, while a standard link prediction\nproblem, situational knowledge graphs have special characteristics that render\nmany link prediction algorithms not fit for the job, and unable to outperform\neven simple baselines.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u5bb6\u5ead\u52a8\u4f5c\u77e5\u8bc6\u56fe\u8bed\u7684\u7279\u6b8a\u6027\u8d28\uff0c\u53d1\u73b0\u591a\u6570\u6807\u51c6\u94fe\u63a5\u9884\u6d4b\u7b97\u6cd5\u5728\u8fd9\u4e2a\u9886\u57df\u8868\u73b0\u5dee\u5f3a\uff0c\u751a\u81f3\u8f83\u7b80\u5355\u57fa\u51c6\u65b9\u6cd5\u90fd\u4e0d\u5982", "motivation": "\u5bb6\u5ead\u52a8\u4f5c\u77e5\u8bc6\u56fe\u8bed\u5728\u5bb6\u5ead\u673a\u5668\u4eba\u63a7\u5236\u548c\u89c6\u9891\u5206\u6790\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4f46\u4ece\u89c6\u9891\u4e2d\u63d0\u53d6\u7684\u4fe1\u606f\u901a\u5e38\u4e0d\u5b8c\u6574\uff0c\u9700\u8981\u901a\u8fc7\u77e5\u8bc6\u56fe\u8fdb\u884c\u8865\u5168\u4ee5\u63d0\u5347\u60c5\u51b5\u62a5\u544a", "method": "\u5bf9\u6bd4\u5206\u6790\u591a\u79cd\u6807\u51c6\u94fe\u63a5\u9884\u6d4b\u7b97\u6cd5\u5728\u60c5\u51b5\u77e5\u8bc6\u56fe\u8bed\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u4e0e\u7b80\u5355\u57fa\u51c6\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83", "result": "\u53d1\u73b0\u60c5\u51b5\u77e5\u8bc6\u56fe\u8bed\u5177\u6709\u7279\u6b8a\u7279\u5f81\uff0c\u5bfc\u81f4\u5927\u90e8\u5206\u6807\u51c6\u94fe\u63a5\u9884\u6d4b\u7b97\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u8868\u73b0\u8f83\u7b80\u5355\u57fa\u51c6\u65b9\u6cd5\u66f4\u5dee", "conclusion": "\u60c5\u51b5\u77e5\u8bc6\u56fe\u8bed\u7684\u7279\u6b8a\u6027\u8d28\u9700\u8981\u4e13\u95e8\u7684\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u73b0\u6709\u6807\u51c6\u65b9\u6cd5\u5728\u8fd9\u4e2a\u9886\u57df\u6548\u679c\u4e0d\u4f73"}}
{"id": "2508.13676", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13676", "abs": "https://arxiv.org/abs/2508.13676", "authors": ["Yu Li", "Zulong Chen", "Wenjian Xu", "Hong Wen", "Yipeng Yu", "Man Lung Yiu", "Yuyu Yin"], "title": "MHSNet:An MoE-based Hierarchical Semantic Representation Network for Accurate Duplicate Resume Detection with Large Language Model", "comment": null, "summary": "To maintain the company's talent pool, recruiters need to continuously search\nfor resumes from third-party websites (e.g., LinkedIn, Indeed). However,\nfetched resumes are often incomplete and inaccurate. To improve the quality of\nthird-party resumes and enrich the company's talent pool, it is essential to\nconduct duplication detection between the fetched resumes and those already in\nthe company's talent pool. Such duplication detection is challenging due to the\nsemantic complexity, structural heterogeneity, and information incompleteness\nof resume texts. To this end, we propose MHSNet, an multi-level identity\nverification framework that fine-tunes BGE-M3 using contrastive learning. With\nthe fine-tuned , Mixture-of-Experts (MoE) generates multi-level sparse and\ndense representations for resumes, enabling the computation of corresponding\nmulti-level semantic similarities. Moreover, the state-aware Mixture-of-Experts\n(MoE) is employed in MHSNet to handle diverse incomplete resumes. Experimental\nresults verify the effectiveness of MHSNet", "AI": {"tldr": "MHSNet\u662f\u4e00\u4e2a\u57fa\u4e8eBGE-M3\u5fae\u8c03\u7684\u591a\u5c42\u6b21\u8eab\u4efd\u9a8c\u8bc1\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u7b2c\u4e09\u65b9\u7f51\u7ad9\u83b7\u53d6\u7684\u7b80\u5386\u4e0e\u516c\u53f8\u4eba\u624d\u5e93\u4e2d\u7b80\u5386\u7684\u91cd\u590d\u9879\uff0c\u89e3\u51b3\u7b80\u5386\u6587\u672c\u7684\u8bed\u4e49\u590d\u6742\u6027\u3001\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u4fe1\u606f\u4e0d\u5b8c\u6574\u6027\u95ee\u9898\u3002", "motivation": "\u7b2c\u4e09\u65b9\u7f51\u7ad9\u83b7\u53d6\u7684\u7b80\u5386\u5f80\u5f80\u4e0d\u5b8c\u6574\u4e14\u4e0d\u51c6\u786e\uff0c\u9700\u8981\u901a\u8fc7\u91cd\u590d\u68c0\u6d4b\u6765\u63d0\u5347\u7b80\u5386\u8d28\u91cf\u5e76\u4e30\u5bcc\u516c\u53f8\u4eba\u624d\u5e93\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u7b80\u5386\u6587\u672c\u7684\u8bed\u4e49\u590d\u6742\u6027\u3001\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u4fe1\u606f\u4e0d\u5b8c\u6574\u6027\u3002", "method": "\u63d0\u51faMHSNet\u6846\u67b6\uff0c\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u5fae\u8c03BGE-M3\u6a21\u578b\uff0c\u901a\u8fc7Mixture-of-Experts\uff08MoE\uff09\u751f\u6210\u591a\u5c42\u6b21\u7a00\u758f\u548c\u5bc6\u96c6\u8868\u793a\u6765\u8ba1\u7b97\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff0c\u5e76\u91c7\u7528\u72b6\u6001\u611f\u77e5MoE\u5904\u7406\u4e0d\u5b8c\u6574\u7b80\u5386\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86MHSNet\u7684\u6709\u6548\u6027\u3002", "conclusion": "MHSNet\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7b80\u5386\u91cd\u590d\u68c0\u6d4b\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u5347\u7b2c\u4e09\u65b9\u7b80\u5386\u8d28\u91cf\u5e76\u4e30\u5bcc\u516c\u53f8\u4eba\u624d\u5e93\u3002"}}
{"id": "2508.13678", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13678", "abs": "https://arxiv.org/abs/2508.13678", "authors": ["Xiao-Wen Yang", "Jie-Jing Shao", "Lan-Zhe Guo", "Bo-Wen Zhang", "Zhi Zhou", "Lin-Han Jia", "Wang-Zhou Dai", "Yu-Feng Li"], "title": "Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models", "comment": "9 pages, 3 figures, IJCAI 2025 Survey Track", "summary": "Large Language Models (LLMs) have shown promising results across various\ntasks, yet their reasoning capabilities remain a fundamental challenge.\nDeveloping AI systems with strong reasoning capabilities is regarded as a\ncrucial milestone in the pursuit of Artificial General Intelligence (AGI) and\nhas garnered considerable attention from both academia and industry. Various\ntechniques have been explored to enhance the reasoning capabilities of LLMs,\nwith neuro-symbolic approaches being a particularly promising way. This paper\ncomprehensively reviews recent developments in neuro-symbolic approaches for\nenhancing LLM reasoning. We first present a formalization of reasoning tasks\nand give a brief introduction to the neurosymbolic learning paradigm. Then, we\ndiscuss neuro-symbolic methods for improving the reasoning capabilities of LLMs\nfrom three perspectives: Symbolic->LLM, LLM->Symbolic, and LLM+Symbolic.\nFinally, we discuss several key challenges and promising future directions. We\nhave also released a GitHub repository including papers and resources related\nto this survey: https://github.com/LAMDASZ-ML/Awesome-LLM-Reasoning-with-NeSy.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u4f7f\u7528\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4ece\u4e09\u4e2a\u89d2\u5ea6\u5206\u6790\u4e86\u76f8\u5173\u6280\u672f\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u6311\u6218\u548c\u65b9\u5411\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u5728\u591a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8270\uff0c\u4f46\u63a8\u7406\u80fd\u529b\u4ecd\u662f\u6838\u5fc3\u6311\u6218\uff0c\u800c\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u88ab\u8ba4\u4e3a\u662f\u63d0\u5347\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u9014\u5f84\u3002", "method": "\u4ece\u4e09\u4e2a\u89d2\u5ea6\u7cfb\u7edf\u8bc4\u4f30\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff1aSymbolic->LLM\uff08\u7b26\u53f7\u5411LLM\u8f93\u5165\uff09\u3001LLM->Symbolic\uff08LLM\u8f93\u51fa\u7b26\u53f7\uff09\u3001LLM+Symbolic\uff08\u4e24\u8005\u534f\u540c\uff09\u3002", "result": "\u8be5\u8bba\u6587\u5b8c\u6574\u5f62\u5f0f\u5316\u4e86\u63a8\u7406\u4efb\u52a1\uff0c\u4ecb\u7ecd\u4e86\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u8303\u5f0f\uff0c\u5e76\u5bf9\u4e0d\u540c\u65b9\u6cd5\u8fdb\u884c\u4e86\u7cfb\u7edf\u5206\u6790\u548c\u8bc4\u4f30\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5728\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5177\u6709\u5f3a\u5927\u6f5c\u529b\uff0c\u8bba\u6587\u6301\u51fa\u4e86\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5f15\u3002"}}
{"id": "2508.13697", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13697", "abs": "https://arxiv.org/abs/2508.13697", "authors": ["Vincent Derkinderen", "Robin Manhaeve", "Rik Adriaensen", "Lucas Van Praet", "Lennert De Smet", "Giuseppe Marra", "Luc De Raedt"], "title": "The DeepLog Neurosymbolic Machine", "comment": null, "summary": "We contribute a theoretical and operational framework for neurosymbolic AI\ncalled DeepLog. DeepLog introduces building blocks and primitives for\nneurosymbolic AI that make abstraction of commonly used representations and\ncomputational mechanisms used in neurosymbolic AI. DeepLog can represent and\nemulate a wide range of neurosymbolic systems. It consists of two key\ncomponents. The first is the DeepLog language for specifying neurosymbolic\nmodels and inference tasks. This language consists of an annotated neural\nextension of grounded first-order logic, and makes abstraction of the type of\nlogic, e.g. boolean, fuzzy or probabilistic, and whether logic is used in the\narchitecture or in the loss function. The second DeepLog component is situated\nat the computational level and uses extended algebraic circuits as\ncomputational graphs. Together these two components are to be considered as a\nneurosymbolic abstract machine, with the DeepLog language as the intermediate\nlevel of abstraction and the circuits level as the computational one. DeepLog\nis implemented in software, relies on the latest insights in implementing\nalgebraic circuits on GPUs, and is declarative in that it is easy to obtain\ndifferent neurosymbolic models by making different choices for the underlying\nalgebraic structures and logics. The generality and efficiency of the DeepLog\nneurosymbolic machine is demonstrated through an experimental comparison\nbetween 1) different fuzzy and probabilistic logics, 2) between using logic in\nthe architecture or in the loss function, and 3) between a standalone CPU-based\nimplementation of a neurosymbolic AI system and a DeepLog GPU-based one.", "AI": {"tldr": "DeepLog\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7AI\u7684\u7406\u8bba\u548c\u64cd\u4f5c\u6846\u67b6\uff0c\u63d0\u4f9b\u6784\u5efa\u5757\u548c\u539f\u8bed\u6765\u62bd\u8c61\u8868\u793a\u548c\u8ba1\u7b97\u673a\u5236\uff0c\u652f\u6301\u591a\u79cd\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u7684\u8868\u793a\u548c\u4eff\u771f\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u795e\u7ecf\u7b26\u53f7AI\u4e2d\u4e0d\u540c\u8868\u793a\u548c\u8ba1\u7b97\u673a\u5236\u7684\u590d\u6742\u6027\uff0c\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u62bd\u8c61\u6846\u67b6\u6765\u7b80\u5316\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u7684\u6784\u5efa\u548c\u63a8\u7406\u4efb\u52a1\u3002", "method": "\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) DeepLog\u8bed\u8a00 - \u57fa\u4e8e\u5e26\u6ce8\u91ca\u7684\u795e\u7ecf\u6269\u5c55\u4e00\u9636\u903b\u8f91\uff0c\u62bd\u8c61\u903b\u8f91\u7c7b\u578b\u548c\u7528\u9014\uff1b2) \u8ba1\u7b97\u5c42\u9762\u7684\u6269\u5c55\u4ee3\u6570\u7535\u8def\u4f5c\u4e3a\u8ba1\u7b97\u56fe\u3002\u4e24\u8005\u6784\u6210\u795e\u7ecf\u7b26\u53f7\u62bd\u8c61\u673a\u5668\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u8bc1\u660e\u4e86DeepLog\u7684\u901a\u7528\u6027\u548c\u6548\u7387\uff1a1) \u4e0d\u540c\u6a21\u7cca\u548c\u6982\u7387\u903b\u8f91\u7684\u6bd4\u8f83\uff1b2) \u903b\u8f91\u5728\u67b6\u6784\u6216\u635f\u5931\u51fd\u6570\u4e2d\u4f7f\u7528\u7684\u6bd4\u8f83\uff1b3) CPU\u5b9e\u73b0\u4e0eGPU\u5b9e\u73b0\u7684\u6027\u80fd\u6bd4\u8f83\u3002", "conclusion": "DeepLog\u63d0\u4f9b\u4e86\u4e00\u4e2a\u58f0\u660e\u5f0f\u7684\u795e\u7ecf\u7b26\u53f7\u62bd\u8c61\u673a\u5668\uff0c\u901a\u8fc7\u9009\u62e9\u4e0d\u540c\u7684\u4ee3\u6570\u7ed3\u6784\u548c\u903b\u8f91\u53ef\u4ee5\u8f7b\u677e\u83b7\u5f97\u4e0d\u540c\u7684\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\uff0c\u5177\u6709\u901a\u7528\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2508.13721", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13721", "abs": "https://arxiv.org/abs/2508.13721", "authors": ["Minh Hoang Nguyen", "Van Dai Do", "Dung Nguyen", "Thin Nguyen", "Hung Le"], "title": "CausalPlan: Empowering Efficient LLM Multi-Agent Collaboration Through Causality-Driven Planning", "comment": null, "summary": "Large language model (LLM) agents-especially smaller, open-source\nmodels-often produce causally invalid or incoherent actions in collaborative\ntasks due to their reliance on surface-level correlations rather than grounded\ncausal reasoning. This limitation undermines their performance in terms of\ncoordination and planning in dynamic environments. We address this challenge\nwith CausalPlan, a two-phase framework that integrates explicit structural\ncausal reasoning into the LLM planning process. At the core of CausalPlan is\nthe Structural Causal Action (SCA) model, which learns a causal graph from\nagent trajectories to capture how prior actions and current environment states\ninfluence future decisions. This structure is then used to guide action\nselection by assigning causal scores to LLM-generated proposals, reweighting\nthem accordingly, or falling back to causally grounded alternatives when\nneeded. By embedding this causal knowledge directly into the decision loop,\nCausalPlan constrains planning to intervention-consistent behaviours without\nrequiring fine-tuning of the LLM itself. We evaluate CausalPlan on the\nOvercooked-AI benchmark across five multi-agent coordination tasks and four\nLLMs of varying sizes: Gemma-7B, Llama-8B, Qwen-14B, and Llama-70B.\nExperimental results show that CausalPlan consistently reduces invalid actions\nand improves collaboration in both AI-AI and human-AI settings, outperforming\nstrong reinforcement learning baselines. Our findings highlight the value of\ncausality-driven planning for deploying efficient, interpretable, and\ngeneralisable multi-agent LLM systems.", "AI": {"tldr": "CausalPlan\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u663e\u5f0f\u7ed3\u6784\u56e0\u679c\u63a8\u7406\u96c6\u6210\u5230LLM\u89c4\u5212\u8fc7\u7a0b\u4e2d\uff0c\u89e3\u51b3\u5c0f\u89c4\u6a21\u5f00\u6e90LLM\u667a\u80fd\u4f53\u5728\u534f\u4f5c\u4efb\u52a1\u4e2d\u4ea7\u751f\u56e0\u679c\u65e0\u6548\u6216\u4e0d\u8fde\u8d2f\u52a8\u4f5c\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\uff08\u5c24\u5176\u662f\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\uff09\u5728\u534f\u4f5c\u4efb\u52a1\u4e2d\u4f9d\u8d56\u8868\u9762\u76f8\u5173\u6027\u800c\u975e\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\uff0c\u5bfc\u81f4\u4ea7\u751f\u56e0\u679c\u65e0\u6548\u6216\u4e0d\u8fde\u8d2f\u52a8\u4f5c\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u534f\u8c03\u548c\u89c4\u5212\u6027\u80fd\u3002", "method": "\u63d0\u51faCausalPlan\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u7ed3\u6784\u56e0\u679c\u52a8\u4f5c\uff08SCA\uff09\u6a21\u578b\uff0c\u4ece\u667a\u80fd\u4f53\u8f68\u8ff9\u4e2d\u5b66\u4e60\u56e0\u679c\u56fe\u6765\u6355\u6349\u5148\u524d\u52a8\u4f5c\u548c\u5f53\u524d\u73af\u5883\u72b6\u6001\u5982\u4f55\u5f71\u54cd\u672a\u6765\u51b3\u7b56\uff0c\u7136\u540e\u4f7f\u7528\u8be5\u7ed3\u6784\u901a\u8fc7\u56e0\u679c\u8bc4\u5206\u6765\u6307\u5bfc\u52a8\u4f5c\u9009\u62e9\u3002", "result": "\u5728Overcooked-AI\u57fa\u51c6\u6d4b\u8bd5\u7684\u4e94\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u8c03\u4efb\u52a1\u548c\u56db\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684LLM\u4e0a\u8bc4\u4f30\uff0cCausalPlan\u6301\u7eed\u51cf\u5c11\u65e0\u6548\u52a8\u4f5c\u5e76\u6539\u5584AI-AI\u548c\u4eba\u7c7b-AI\u8bbe\u7f6e\u4e2d\u7684\u534f\u4f5c\uff0c\u4f18\u4e8e\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u3002", "conclusion": "\u56e0\u679c\u9a71\u52a8\u89c4\u5212\u5bf9\u4e8e\u90e8\u7f72\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6cdb\u5316\u7684\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u65e0\u9700\u5bf9LLM\u672c\u8eab\u8fdb\u884c\u5fae\u8c03\u5373\u53ef\u7ea6\u675f\u89c4\u5212\u4e3a\u5e72\u9884\u4e00\u81f4\u7684\u884c\u4e3a\u3002"}}
{"id": "2508.13754", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13754", "abs": "https://arxiv.org/abs/2508.13754", "authors": ["Liuxin Bao", "Zhihao Peng", "Xiaofei Zhou", "Runmin Cong", "Jiyong Zhang", "Yixuan Yuan"], "title": "Expertise-aware Multi-LLM Recruitment and Collaboration for Medical Decision-Making", "comment": "14 pages", "summary": "Medical Decision-Making (MDM) is a complex process requiring substantial\ndomain-specific expertise to effectively synthesize heterogeneous and\ncomplicated clinical information. While recent advancements in Large Language\nModels (LLMs) show promise in supporting MDM, single-LLM approaches are limited\nby their parametric knowledge constraints and static training corpora, failing\nto robustly integrate the clinical information. To address this challenge, we\npropose the Expertise-aware Multi-LLM Recruitment and Collaboration (EMRC)\nframework to enhance the accuracy and reliability of MDM systems. It operates\nin two stages: (i) expertise-aware agent recruitment and (ii) confidence- and\nadversarial-driven multi-agent collaboration. Specifically, in the first stage,\nwe use a publicly available corpus to construct an LLM expertise table for\ncapturing expertise-specific strengths of multiple LLMs across medical\ndepartment categories and query difficulty levels. This table enables the\nsubsequent dynamic selection of the optimal LLMs to act as medical expert\nagents for each medical query during the inference phase. In the second stage,\nwe employ selected agents to generate responses with self-assessed confidence\nscores, which are then integrated through the confidence fusion and adversarial\nvalidation to improve diagnostic reliability. We evaluate our EMRC framework on\nthree public MDM datasets, where the results demonstrate that our EMRC\noutperforms state-of-the-art single- and multi-LLM methods, achieving superior\ndiagnostic performance. For instance, on the MMLU-Pro-Health dataset, our EMRC\nachieves 74.45% accuracy, representing a 2.69% improvement over the\nbest-performing closed-source model GPT- 4-0613, which demonstrates the\neffectiveness of our expertise-aware agent recruitment strategy and the agent\ncomplementarity in leveraging each LLM's specialized capabilities.", "AI": {"tldr": "\u63d0\u51faEMRC\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u4e1a\u77e5\u8bc6\u9886\u57df\u7684\u591aLLM\u52a8\u6001\u9009\u62e9\u548c\u534f\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u533b\u7597\u51b3\u7b56\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027", "motivation": "\u5355\u4e00LLM\u65b9\u6cd5\u53d7\u9650\u4e8e\u53c2\u6570\u77e5\u8bc6\u7ea6\u675f\u548c\u9759\u6001\u8bad\u7ec3\u8bed\u6599\uff0c\u65e0\u6cd5\u5065\u58ee\u5730\u6574\u5408\u590d\u6742\u7684\u4e34\u5e8a\u4fe1\u606f", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\u3001\u4f7f\u7528\u516c\u5f00\u8bed\u6599\u5efa\u7acbLLM\u4e13\u4e1a\u77e5\u8bc6\u8868\uff0c\u52a8\u6001\u9009\u62e9\u6700\u4f18LLM\uff1b2\u3001\u901a\u8fc7\u81ea\u4fe1\u5206\u6570\u878d\u5408\u548c\u5bf9\u6297\u9a8c\u8bc1\u63d0\u5347\u8bca\u65ad\u53ef\u9760\u6027", "result": "\u5728\u4e09\u4e2a\u516c\u5f00MDM\u6570\u636e\u96c6\u4e0a\u8d85\u8fc7\u6700\u5148\u8fdb\u7684\u5355\u4e00\u548c\u591aLLM\u65b9\u6cd5\uff0c\u5728MMLU-Pro-Health\u6570\u636e\u96c6\u4e0a\u8fbe\u523074.45%\u51c6\u786e\u7387\uff0c\u6bd4GPT-4-0613\u63d0\u53472.69%", "conclusion": "EMRC\u6846\u67b6\u901a\u8fc7\u4e13\u4e1a\u77e5\u8bc6\u9886\u57df\u7684\u52a8\u6001\u9009\u62e9\u548c\u591a\u4ee3\u7406\u534f\u4f5c\uff0c\u6709\u6548\u63d0\u5347\u4e86\u533b\u7597\u51b3\u7b56\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027"}}
{"id": "2508.13811", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.13811", "abs": "https://arxiv.org/abs/2508.13811", "authors": ["Jan Jakub\u016fv", "Mikol\u00e1\u0161 Janota"], "title": "Quantifier Instantiations: To Mimic or To Revolt?", "comment": "Accepted to SMT 2025: 23rd International Workshop on Satisfiability\n  Modulo Theories", "summary": "Quantified formulas pose a significant challenge for Satisfiability Modulo\nTheories (SMT) solvers due to their inherent undecidability. Existing\ninstantiation techniques, such as e-matching, syntax-guided, model-based,\nconflict-based, and enumerative methods, often complement each other. This\npaper introduces a novel instantiation approach that dynamically learns from\nthese techniques during solving. By treating observed instantiations as samples\nfrom a latent language, we use probabilistic context-free grammars to generate\nnew, similar terms. Our method not only mimics successful past instantiations\nbut also explores diversity by optionally inverting learned term probabilities,\naiming to balance exploitation and exploration in quantifier reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\u7684\u52a8\u6001\u91cf\u5316\u5b9e\u4f8b\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u73b0\u6709\u6280\u672f\u4e2d\u5b66\u4e60\u5b9e\u4f8b\u5316\u6a21\u5f0f\u6765\u5e73\u8861\u5229\u7528\u548c\u63a2\u7d22", "motivation": "\u73b0\u6709SMT\u6c42\u89e3\u5668\u4e2d\u7684\u91cf\u5316\u516c\u5f0f\u5b9e\u4f8b\u5316\u6280\u672f\uff08\u5982e-matching\u3001\u8bed\u6cd5\u5f15\u5bfc\u3001\u57fa\u4e8e\u6a21\u578b\u7b49\u65b9\u6cd5\uff09\u5f80\u5f80\u4e92\u8865\u4f46\u7f3a\u4e4f\u52a8\u6001\u5b66\u4e60\u80fd\u529b\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u5904\u7406\u91cf\u5316\u516c\u5f0f\u7684\u4e0d\u53ef\u5224\u5b9a\u6027\u6311\u6218", "method": "\u5c06\u89c2\u5bdf\u5230\u7684\u5b9e\u4f8b\u5316\u89c6\u4e3a\u6f5c\u5728\u8bed\u8a00\u7684\u6837\u672c\uff0c\u4f7f\u7528\u6982\u7387\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\u751f\u6210\u65b0\u7684\u76f8\u4f3c\u9879\uff0c\u65e2\u80fd\u6a21\u4eff\u6210\u529f\u7684\u8fc7\u5f80\u5b9e\u4f8b\u5316\uff0c\u4e5f\u80fd\u901a\u8fc7\u53cd\u8f6c\u5b66\u4e60\u5230\u7684\u9879\u6982\u7387\u6765\u63a2\u7d22\u591a\u6837\u6027", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u52a8\u6001\u5b66\u4e60\u5404\u79cd\u5b9e\u4f8b\u5316\u6280\u672f\uff0c\u5728\u91cf\u5316\u63a8\u7406\u4e2d\u5b9e\u73b0\u5229\u7528\u548c\u63a2\u7d22\u7684\u5e73\u8861", "conclusion": "\u57fa\u4e8e\u6587\u6cd5\u5b66\u4e60\u7684\u52a8\u6001\u5b9e\u4f8b\u5316\u65b9\u6cd5\u4e3aSMT\u6c42\u89e3\u5668\u5904\u7406\u91cf\u5316\u516c\u5f0f\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\uff0c\u901a\u8fc7\u6982\u7387\u5efa\u6a21\u5b9e\u73b0\u4e86\u5b9e\u4f8b\u5316\u6280\u672f\u7684\u667a\u80fd\u7ec4\u5408\u548c\u81ea\u9002\u5e94\u751f\u6210"}}
{"id": "2508.13828", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13828", "abs": "https://arxiv.org/abs/2508.13828", "authors": ["Yifei Chen", "Guanting Dong", "Yutao Zhu", "Zhicheng Dou"], "title": "Revisiting RAG Ensemble: A Theoretical and Mechanistic Analysis of Multi-RAG System Collaboration", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) technology has been widely applied in\nrecent years. However, despite the emergence of various RAG frameworks, a\nsingle RAG framework still cannot adapt well to a broad range of downstream\ntasks. Therefore, how to leverage the advantages of multiple RAG systems has\nbecome an area worth exploring. To address this issue, we have conducted a\ncomprehensive and systematic investigation into ensemble methods based on RAG\nsystems. Specifically, we have analyzed the RAG ensemble framework from both\ntheoretical and mechanistic analysis perspectives. From the theoretical\nanalysis, we provide the first explanation of the RAG ensemble framework from\nthe perspective of information entropy. In terms of mechanism analysis, we have\nexplored the RAG ensemble framework from both the pipeline and module levels.\nWe carefully select four different pipelines (Branching, Iterative, Loop, and\nAgentic) and three different modules (Generator, Retriever, and Reranker) to\nsolve seven different research questions. The experiments show that aggregating\nmultiple RAG systems is both generalizable and robust, whether at the pipeline\nlevel or the module level. Our work lays the foundation for similar research on\nthe multi-RAG system ensemble.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u591a\u4e2aRAG\u7cfb\u7edf\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u4ece\u7406\u8bba\u548c\u673a\u5236\u89d2\u5ea6\u5206\u6790\u4e86\u4fe1\u606f\u745c\u548c\u96c6\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u79cd\u6d41\u6c34\u7ebf\u548c\u4e09\u79cd\u6a21\u5757\u89e3\u51b3\u4e03\u4e2a\u7814\u7a76\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u591aRAG\u7cfb\u7edf\u96c6\u6210\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u7a33\u5065\u6027\u3002", "motivation": "\u5f53\u524d\u5355\u4e2aRAG\u6846\u67b6\u65e0\u6cd5\u826f\u597d\u9002\u5e94\u5e7f\u6cdb\u7684\u4e0b\u6e38\u4efb\u52a1\uff0c\u9700\u8981\u63a2\u7d22\u5982\u4f55\u5229\u7528\u591a\u4e2aRAG\u7cfb\u7edf\u7684\u4f18\u52bf\u6765\u63d0\u5347\u6027\u80fd\u3002", "method": "\u4ece\u7406\u8bba\u5206\u6790\u89d2\u5ea6\u901a\u8fc7\u4fe1\u606f\u745c\u89e3\u91caRAG\u96c6\u6210\u6846\u67b6\uff0c\u4ece\u673a\u5236\u5206\u6790\u89d2\u5ea6\u7814\u7a76\u6d41\u6c34\u7ebf\u7ea7\u522b\u548c\u6a21\u5757\u7ea7\u522b\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u9009\u62e9\u56db\u79cd\u6d41\u6c34\u7ebf\uff08\u5206\u652f\u3001\u8fed\u4ee3\u3001\u5faa\u73af\u3001\u4ee3\u7406\uff09\u548c\u4e09\u79cd\u6a21\u5757\uff08\u751f\u6210\u5668\u3001\u68c0\u7d22\u5668\u3001\u91cd\u6392\u5668\uff09\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u65e0\u8bba\u5728\u6d41\u6c34\u7ebf\u7ea7\u522b\u8fd8\u662f\u6a21\u5757\u7ea7\u522b\uff0c\u805a\u5408\u591a\u4e2aRAG\u7cfb\u7edf\u90fd\u663e\u793a\u51fa\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u7a33\u5065\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u591aRAG\u7cfb\u7edf\u96c6\u6210\u76f8\u5173\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u591a\u7cfb\u7edf\u96c6\u6210\u5728\u63d0\u5347RAG\u6280\u672f\u6027\u80fd\u65b9\u9762\u7684\u6f5c\u529b\u548c\u4ef7\u503c\u3002"}}
{"id": "2508.13876", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.13876", "abs": "https://arxiv.org/abs/2508.13876", "authors": ["Katharina Stein", "Nils Hodel", "Daniel Fi\u0161er", "J\u00f6rg Hoffmann", "Michael Katz", "Alexander Koller"], "title": "Improved Generalized Planning with LLMs through Strategy Refinement and Reflection", "comment": null, "summary": "LLMs have recently been used to generate Python programs representing\ngeneralized plans in PDDL planning, i.e., plans that generalize across the\ntasks of a given PDDL domain. Previous work proposed a framework consisting of\nthree steps: the LLM first generates a summary and then a strategy for the\ndomain, both in natural language, and then implements that strategy as a Python\nprogram, that gets debugged on example planning tasks. In that work, only one\nstrategy is generated and passed directly to the program generation. If the\nstrategy is incorrect, its implementation will therefore result in an incorrect\ngeneralized plan. Here, we introduce an approach that generates the strategy in\nthe form of pseudocode and enables automatic debugging of the pseudocode, hence\nallowing us to identify and fix errors prior to the generation of the\ngeneralized plan itself. Additionally, we extend the Python debugging phase\nwith a reflection step prompting the LLM to pinpoint the reason for the\nobserved plan failure. Finally, we take inspiration from LLM code generation to\nproduce several program variants and pick the best one. Running experiments on\n17 benchmark domains, we show that these extensions substantially improve (and\nnever deteriorate) the quality of the generalized plans. In 12 of the domains,\nour best Python programs solve all tasks that can be generated with the\nrespective instance generator.", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528\u4f2a\u4ee3\u7801\u751f\u6210\u3001\u81ea\u52a8\u8c03\u8bd5\u548c\u53cd\u601d\u6b65\u9aa4\u6539\u8fdbLLM\u751f\u6210\u5e7f\u4e49\u8ba1\u5212\u7684\u8d28\u91cf\uff0c\u572817\u4e2a\u57fa\u51c6\u9886\u57df\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86Python\u7a0b\u5e8f\u7684\u6210\u529f\u7387", "motivation": "\u89e3\u51b3\u4e4b\u524d\u65b9\u6cd5\u4e2d\u53ea\u751f\u6210\u4e00\u4e2a\u7b56\u7565\u5e76\u76f4\u63a5\u8f6c\u6362\u4e3a\u7a0b\u5e8f\uff0c\u5982\u679c\u7b56\u7565\u9519\u8bef\u5c31\u4f1a\u5bfc\u81f4\u5168\u90e8\u5931\u8d25\u7684\u95ee\u9898", "method": "\u4f7f\u7528\u4f2a\u4ee3\u7801\u751f\u6210\u7b56\u7565\u5e76\u5148\u8fdb\u884c\u81ea\u52a8\u8c03\u8bd5\uff0c\u5728Python\u8c03\u8bd5\u9636\u6bb5\u6dfb\u52a0\u53cd\u601d\u6b65\u9aa4\uff0c\u751f\u6210\u591a\u4e2a\u7a0b\u5e8f\u53d8\u4f53\u5e76\u9009\u62e9\u6700\u4f73\u7684", "result": "\u572817\u4e2a\u57fa\u51c6\u9886\u57df\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u5e7f\u4e49\u8ba1\u5212\u7684\u8d28\u91cf\uff0c\u517612\u4e2a\u9886\u57df\u4e2d\u6700\u4f73Python\u7a0b\u5e8f\u80fd\u89e3\u51b3\u6240\u6709\u53ef\u751f\u6210\u7684\u4efb\u52a1", "conclusion": "\u901a\u8fc7\u4f2a\u4ee3\u7801\u8c03\u8bd5\u3001\u53cd\u601d\u548c\u591a\u7a0b\u5e8f\u9009\u62e9\u7b49\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8LLM\u751f\u6210\u5e7f\u4e49\u8ba1\u5212\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027"}}
{"id": "2508.13915", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13915", "abs": "https://arxiv.org/abs/2508.13915", "authors": ["Yihao Ang", "Yifan Bao", "Lei Jiang", "Jiajie Tao", "Anthony K. H. Tung", "Lukasz Szpruch", "Hao Ni"], "title": "Structured Agentic Workflows for Financial Time-Series Modeling with LLMs and Reflective Feedback", "comment": null, "summary": "Time-series data is central to decision-making in financial markets, yet\nbuilding high-performing, interpretable, and auditable models remains a major\nchallenge. While Automated Machine Learning (AutoML) frameworks streamline\nmodel development, they often lack adaptability and responsiveness to\ndomain-specific needs and evolving objectives. Concurrently, Large Language\nModels (LLMs) have enabled agentic systems capable of reasoning, memory\nmanagement, and dynamic code generation, offering a path toward more flexible\nworkflow automation. In this paper, we introduce \\textsf{TS-Agent}, a modular\nagentic framework designed to automate and enhance time-series modeling\nworkflows for financial applications. The agent formalizes the pipeline as a\nstructured, iterative decision process across three stages: model selection,\ncode refinement, and fine-tuning, guided by contextual reasoning and\nexperimental feedback. Central to our architecture is a planner agent equipped\nwith structured knowledge banks, curated libraries of models and refinement\nstrategies, which guide exploration, while improving interpretability and\nreducing error propagation. \\textsf{TS-Agent} supports adaptive learning,\nrobust debugging, and transparent auditing, key requirements for high-stakes\nenvironments such as financial services. Empirical evaluations on diverse\nfinancial forecasting and synthetic data generation tasks demonstrate that\n\\textsf{TS-Agent} consistently outperforms state-of-the-art AutoML and agentic\nbaselines, achieving superior accuracy, robustness, and decision traceability.", "AI": {"tldr": "TS-Agent\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u51b3\u7b56\u8fc7\u7a0b\uff08\u6a21\u578b\u9009\u62e9\u3001\u4ee3\u7801\u4f18\u5316\u3001\u5fae\u8c03\uff09\u5b9e\u73b0\u4f18\u4e8e\u73b0\u6709AutoML\u548c\u4ee3\u7406\u57fa\u51c6\u7684\u6027\u80fd\u3002", "motivation": "\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u9762\u4e34\u9ad8\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\u7684\u6311\u6218\uff0c\u73b0\u6709AutoML\u6846\u67b6\u7f3a\u4e4f\u5bf9\u9886\u57df\u7279\u5b9a\u9700\u6c42\u548c\u52a8\u6001\u76ee\u6807\u7684\u9002\u5e94\u6027\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u4ee3\u7406\u67b6\u6784\uff0c\u5305\u542b\u89c4\u5212\u4ee3\u7406\u548c\u7ed3\u6784\u5316\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u8fed\u4ee3\u51b3\u7b56\u8fc7\u7a0b\uff1a\u6a21\u578b\u9009\u62e9\u3001\u4ee3\u7801\u4f18\u5316\u548c\u5fae\u8c03\uff0c\u7ed3\u5408\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u5b9e\u9a8c\u53cd\u9988\u3002", "result": "\u5728\u591a\u79cd\u91d1\u878d\u9884\u6d4b\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u4efb\u52a1\u4e2d\uff0cTS-Agent\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u51b3\u7b56\u53ef\u8ffd\u6eaf\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684AutoML\u548c\u4ee3\u7406\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TS-Agent\u6846\u67b6\u4e3a\u9ad8\u98ce\u9669\u91d1\u878d\u73af\u5883\u63d0\u4f9b\u4e86\u81ea\u9002\u5e94\u5b66\u4e60\u3001\u9c81\u68d2\u8c03\u8bd5\u548c\u900f\u660e\u5ba1\u8ba1\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u548c\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2508.13942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13942", "abs": "https://arxiv.org/abs/2508.13942", "authors": ["Soumyadeep Dhar"], "title": "The Collaboration Paradox: Why Generative AI Requires Both Strategic Intelligence and Operational Stability in Supply Chain Management", "comment": null, "summary": "The rise of autonomous, AI-driven agents in economic settings raises critical\nquestions about their emergent strategic behavior. This paper investigates\nthese dynamics in the cooperative context of a multi-echelon supply chain, a\nsystem famously prone to instabilities like the bullwhip effect. We conduct\ncomputational experiments with generative AI agents, powered by Large Language\nModels (LLMs), within a controlled supply chain simulation designed to isolate\ntheir behavioral tendencies. Our central finding is the \"collaboration\nparadox\": a novel, catastrophic failure mode where theoretically superior\ncollaborative AI agents, designed with Vendor-Managed Inventory (VMI)\nprinciples, perform even worse than non-AI baselines. We demonstrate that this\nparadox arises from an operational flaw where agents hoard inventory, starving\nthe system. We then show that resilience is only achieved through a synthesis\nof two distinct layers: high-level, AI-driven proactive policy-setting to\nestablish robust operational targets, and a low-level, collaborative execution\nprotocol with proactive downstream replenishment to maintain stability. Our\nfinal framework, which implements this synthesis, can autonomously generate,\nevaluate, and quantify a portfolio of viable strategic choices. The work\nprovides a crucial insight into the emergent behaviors of collaborative AI\nagents and offers a blueprint for designing stable, effective AI-driven systems\nfor business analytics.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0AI\u9a71\u52a8\u7684\u534f\u4f5c\u4ee3\u7406\u5728\u4f9b\u5e94\u94fe\u4e2d\u4f1a\u51fa\u73b0\"\u534f\u4f5c\u6096\u8bba\"\uff0c\u5373\u7406\u8bba\u4e0a\u66f4\u4f18\u7684\u534f\u4f5cAI\u4ee3\u7406\u8868\u73b0\u53cd\u800c\u6bd4\u975eAI\u57fa\u51c6\u66f4\u5dee\uff0c\u539f\u56e0\u662f\u5e93\u5b58\u56e4\u79ef\u5bfc\u81f4\u7cfb\u7edf\u9965\u997f\u3002\u901a\u8fc7\u9ad8\u5c42AI\u7b56\u7565\u8bbe\u5b9a\u548c\u4f4e\u5c42\u534f\u4f5c\u6267\u884c\u7684\u7ed3\u5408\u53ef\u4ee5\u5b9e\u73b0\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "motivation": "\u7814\u7a76AI\u9a71\u52a8\u4ee3\u7406\u5728\u7ecf\u6d4e\u73af\u5883\u4e2d\u7684\u65b0\u5174\u6218\u7565\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u591a\u7ea7\u4f9b\u5e94\u94fe\u8fd9\u79cd\u5bb9\u6613\u51fa\u73b0\u725b\u97ad\u6548\u5e94\u7b49\u4e0d\u7a33\u5b9a\u6027\u7684\u5408\u4f5c\u73af\u5883\u4e2d\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u751f\u6210\u5f0fAI\u4ee3\u7406\u5728\u53d7\u63a7\u4f9b\u5e94\u94fe\u6a21\u62df\u4e2d\u8fdb\u884c\u8ba1\u7b97\u5b9e\u9a8c\uff0c\u5206\u6790\u5176\u884c\u4e3a\u503e\u5411\u3002", "result": "\u53d1\u73b0\u4e86\"\u534f\u4f5c\u6096\u8bba\"\u73b0\u8c61\uff0c\u534f\u4f5cAI\u4ee3\u7406\u8868\u73b0\u6bd4\u975eAI\u57fa\u51c6\u66f4\u5dee\uff1b\u63d0\u51fa\u4e86\u7ed3\u5408\u9ad8\u5c42AI\u7b56\u7565\u8bbe\u5b9a\u548c\u4f4e\u5c42\u534f\u4f5c\u6267\u884c\u7684\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u4e3b\u751f\u6210\u3001\u8bc4\u4f30\u548c\u91cf\u5316\u53ef\u884c\u7684\u6218\u7565\u9009\u62e9\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u534f\u4f5cAI\u4ee3\u7406\u7684\u65b0\u5174\u884c\u4e3a\u7279\u6027\uff0c\u4e3a\u8bbe\u8ba1\u7a33\u5b9a\u6709\u6548\u7684AI\u9a71\u52a8\u5546\u4e1a\u5206\u6790\u7cfb\u7edf\u63d0\u4f9b\u4e86\u84dd\u56fe\u548c\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2508.13975", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13975", "abs": "https://arxiv.org/abs/2508.13975", "authors": ["Jingquan Wang", "Andrew Negrut", "Harry Zhang", "Khailanii Slaton", "Shu Wang", "Radu Serban", "Jinlong Wu", "Dan Negrut"], "title": "ChronoLLM: Customizing Language Models for Physics-Based Simulation Code Generation", "comment": null, "summary": "This contribution is concerned with the following issue: can pretrained large\nlanguage models (LLMs) be refined and customized to the point where they become\nvirtual assistants helping experts with the effective use of a simulation tool?\nIn this case study, the ``simulation tool'' considered is PyChrono, an open\nsource multi-physics dynamics engine for multibody systems. We present a\nframework for refining and customizing both open- and closed-source LLMs to\nharness the power of AI in generating scripts that perform PyChrono virtual\nexperiments. We refine and customize several classes of LLMs through a process\nthat leads to a quantifiable improvement in the quality of the generated\nPyChrono simulation scripts. These scripts can range from simple\nsingle-pendulum simulations to complex virtual experiments involving full\nvehicles on deformable terrain. While the generated scripts are rarely perfect,\nthey often serve as strong starting points for the user to modify and improve\non. Additionally, the LLM can answer specific API questions about the\nsimulator, or recommend modeling approaches. The framework discussed is general\nand can be applied to lower the entry barrier for simulation tools associated\nwith other application domains.", "AI": {"tldr": "\u901a\u8fc7\u7cbe\u70bc\u548c\u5b9a\u5236\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u591f\u4e3aPyChrono\u6a21\u62df\u5de5\u5177\u751f\u6210\u6709\u6548\u7684\u811a\u672c\uff0c\u964d\u4f4e\u4e13\u5bb6\u4f7f\u7528\u6a21\u62df\u5de5\u5177\u7684\u95e8\u69db", "motivation": "\u89e3\u51b3\u4e13\u4e1a\u6a21\u62df\u5de5\u5177\uff08\u5982PyChrono\uff09\u4f7f\u7528\u95e8\u69db\u9ad8\u7684\u95ee\u9898\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u53d8\u6210\u80fd\u591f\u5e2e\u52a9\u4e13\u5bb6\u6709\u6548\u4f7f\u7528\u6a21\u62df\u5de5\u5177\u7684\u865a\u62df\u52a9\u624b", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u5bf9\u5f00\u6e90\u548c\u95ed\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7cbe\u70bc\u548c\u5b9a\u5236\uff0c\u4ee5\u751f\u6210PyChrono\u6a21\u62df\u811a\u672c\uff0c\u5305\u62ec\u4ece\u7b80\u5355\u7684\u5355\u6446\u5230\u590d\u6742\u7684\u8f66\u8f86\u5728\u53ef\u53d8\u5f62\u5730\u5f62\u4e0a\u7684\u6a21\u62df", "result": "\u7cbe\u70bc\u540e\u7684\u6a21\u578b\u5728\u751f\u6210PyChrono\u6a21\u62df\u811a\u672c\u8d28\u91cf\u4e0a\u6709\u91cf\u5316\u63d0\u5347\uff0c\u867d\u7136\u5e76\u975e\u5b8c\u7f8e\u4f46\u80fd\u63d0\u4f9b\u826f\u597d\u7684\u8d77\u70b9\uff0c\u8fd8\u80fd\u56de\u7b54API\u76f8\u5173\u95ee\u9898\u548c\u63a8\u8350\u5efa\u6a21\u65b9\u6cd5", "conclusion": "\u8be5\u6846\u67b6\u5177\u6709\u666e\u904d\u6027\uff0c\u53ef\u4ee5\u5e94\u7528\u4e8e\u5176\u4ed6\u9886\u57df\u7684\u6a21\u62df\u5de5\u5177\uff0c\u6709\u6548\u964d\u4f4e\u4e13\u4e1a\u6a21\u62df\u5de5\u5177\u7684\u4f7f\u7528\u95e8\u69db"}}
{"id": "2508.14020", "categories": ["cs.AI", "cs.DM", "68T01", "I.2.8"], "pdf": "https://arxiv.org/pdf/2508.14020", "abs": "https://arxiv.org/abs/2508.14020", "authors": ["Christian Blum", "Pedro Pinacho-Davidson"], "title": "A Biased Random Key Genetic Algorithm for Solving the Longest Run Subsequence Problem", "comment": null, "summary": "The longest run subsequence (LRS) problem is an NP-hard combinatorial\noptimization problem belonging to the class of subsequence problems from\nbioinformatics. In particular, the problem plays a role in genome reassembly.\nIn this paper, we present a solution to the LRS problem using a Biased Random\nKey Genetic Algorithm (BRKGA). Our approach places particular focus on the\ncomputational efficiency of evaluating individuals, which involves converting\nvectors of gray values into valid solutions to the problem. For comparison\npurposes, a Max-Min Ant System is developed and implemented. This is in\naddition to the application of the integer linear programming solver CPLEX for\nsolving all considered problem instances. The computation results show that the\nproposed BRKGA is currently a state-of-the-art technique for the LRS problem.\nNevertheless, the results also show that there is room for improvement,\nespecially in the context of input strings based on large alphabet sizes.", "AI": {"tldr": "\u4f7f\u7528\u504f\u7f6e\u968f\u673a\u5bc6\u94a5\u9057\u4f20\u7b97\u6cd5(BRKGA)\u89e3\u51b3\u957f\u8dddl\u5b50\u5e8f\u5217(LRS)\u95ee\u9898\uff0c\u8be5\u7b97\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u89e3\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u662f\u76ee\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "motivation": "LRS\u95ee\u9898\u662f\u4e00\u4e2aNP\u96be\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5728\u751f\u7269\u4fe1\u606f\u5b66\u548c\u57fa\u56e0\u7ec4\u91cd\u65b0\u7ec4\u88c5\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7b97\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4f7f\u7528Biased Random Key Genetic Algorithm (BRKGA)\uff0c\u91cd\u70b9\u5173\u6ce8\u4e2a\u4f53\u8bc4\u4f30\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u5c06\u7070\u5ea6\u503c\u5411\u91cf\u8f6c\u6362\u4e3a\u6709\u6548\u89e3\u3002\u4e3a\u4e86\u5bf9\u6bd4\uff0c\u8fd8\u5f00\u53d1\u4e86Max-Min Ant System\u5e76\u4f7f\u7528CPLEX\u6574\u6570\u89c4\u5212\u6c42\u89e3\u5668\u3002", "result": "\u8ba1\u7b97\u7ed3\u679c\u663e\u793a\u63d0\u51fa\u7684BRKGA\u5728LRS\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u662f\u76ee\u524d\u6700\u5148\u8fdb\u7684\u6280\u672f\u3002\u4f46\u5728\u5927\u5b57\u6bcd\u8868\u57fa\u7840\u7684\u8f93\u5165\u5b57\u7b26\u4e32\u4e0a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "BRKGA\u7b97\u6cd5\u5728LRS\u95ee\u9898\u4e0a\u6210\u529f\u5b9e\u73b0\u4e86\u9ad8\u6548\u89e3\u51b3\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u5904\u7406\u5927\u5b57\u6bcd\u96c6\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u95ee\u9898\u3002"}}
{"id": "2508.14040", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14040", "abs": "https://arxiv.org/abs/2508.14040", "authors": ["Hanyu Lai", "Xiao Liu", "Yanxiao Zhao", "Han Xu", "Hanchen Zhang", "Bohao Jing", "Yanyu Ren", "Shuntian Yao", "Yuxiao Dong", "Jie Tang"], "title": "ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents", "comment": null, "summary": "We introduce ComputerRL, a framework for autonomous desktop intelligence that\nenables agents to operate complex digital workspaces skillfully. ComputerRL\nfeatures the API-GUI paradigm, which unifies programmatic API calls and direct\nGUI interaction to address the inherent mismatch between machine agents and\nhuman-centric desktop environments. Scaling end-to-end RL training is crucial\nfor improvement and generalization across diverse desktop tasks, yet remains\nchallenging due to environmental inefficiency and instability in extended\ntraining. To support scalable and robust training, we develop a distributed RL\ninfrastructure capable of orchestrating thousands of parallel virtual desktop\nenvironments to accelerate large-scale online RL. Furthermore, we propose\nEntropulse, a training strategy that alternates reinforcement learning with\nsupervised fine-tuning, effectively mitigating entropy collapse during extended\ntraining runs. We employ ComputerRL on open models GLM-4-9B-0414 and\nQwen2.5-14B, and evaluate them on the OSWorld benchmark. The AutoGLM-OS-9B\nbased on GLM-4-9B-0414 achieves a new state-of-the-art accuracy of 48.1%,\ndemonstrating significant improvements for general agents in desktop\nautomation. The algorithm and framework are adopted in building AutoGLM (Liu et\nal., 2024a)", "AI": {"tldr": "ComputerRL\u662f\u4e00\u4e2a\u81ea\u4e3b\u684c\u9762\u667a\u80fd\u6846\u67b6\uff0c\u901a\u8fc7API-GUI\u8303\u5f0f\u7edf\u4e00\u7a0b\u5e8f\u5316API\u8c03\u7528\u548c\u76f4\u63a5GUI\u4ea4\u4e92\uff0c\u89e3\u51b3\u673a\u5668\u4ee3\u7406\u4e0e\u4eba\u7c7b\u684c\u9762\u73af\u5883\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002\u91c7\u7528\u5206\u5e03\u5f0fRL\u57fa\u7840\u8bbe\u65bd\u548cEntropulse\u8bad\u7ec3\u7b56\u7565\uff0c\u5728OSWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523048.1%\u7684\u6700\u65b0\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4ee3\u7406\u5728\u4eba\u7c7b\u4e2d\u5fc3\u5316\u684c\u9762\u73af\u5883\u4e2d\u64cd\u4f5c\u590d\u6742\u6570\u5b57\u5de5\u4f5c\u7a7a\u95f4\u65f6\u7684\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u5347\u684c\u9762\u81ea\u52a8\u5316\u7684\u901a\u7528\u6027\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faAPI-GUI\u8303\u5f0f\u7edf\u4e00\u7a0b\u5e8f\u5316API\u8c03\u7528\u548cGUI\u4ea4\u4e92\uff1b\u5f00\u53d1\u5206\u5e03\u5f0fRL\u57fa\u7840\u8bbe\u65bd\u652f\u6301\u5927\u89c4\u6a21\u5e76\u884c\u865a\u62df\u684c\u9762\u73af\u5883\uff1b\u8bbe\u8ba1Entropulse\u8bad\u7ec3\u7b56\u7565\uff0c\u4ea4\u66ff\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\u6765\u7f13\u89e3\u71b5\u5d29\u6e83\u95ee\u9898\u3002", "result": "\u5728OSWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8eGLM-4-9B-0414\u7684AutoGLM-OS-9B\u6a21\u578b\u8fbe\u523048.1%\u7684\u6700\u65b0\u51c6\u786e\u7387\uff0c\u663e\u8457\u63d0\u5347\u4e86\u901a\u7528\u4ee3\u7406\u5728\u684c\u9762\u81ea\u52a8\u5316\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "ComputerRL\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684API-GUI\u8303\u5f0f\u548c\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u57fa\u7840\u8bbe\u65bd\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u684c\u9762\u667a\u80fd\u4ee3\u7406\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u4e3a\u81ea\u4e3b\u684c\u9762\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
