{"id": "2602.04007", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.04007", "abs": "https://arxiv.org/abs/2602.04007", "authors": ["Mengqian Zhang", "Sen Yang", "Kartik Nayak", "Fan Zhang"], "title": "Boost+: Equitable, Incentive-Compatible Block Building", "comment": null, "summary": "Block space on the blockchain is scarce and must be allocated efficiently through block building. However, Ethereum's current block-building ecosystem, MEV-Boost, has become highly centralized due to integration, which distorts competition, reduces blockspace efficiency, and obscures MEV flow transparency. To guarantee equitability and economic efficiency in block building, we propose $\\mathrm{Boost+}$, a system that decouples the process into collecting and ordering transactions, and ensures equal access to all collected transactions.\n  The core of $\\mathrm{Boost+}$ is the mechanism $\\mathit{M}_{\\mathrm{Boost+}}$, built around a default algorithm. $\\mathit{M}_{\\mathrm{Boost+}}$ aligns incentives for both searchers (intermediaries that generate or route transactions) and builders: Truthful bidding is a dominant strategy for all builders. For searchers, truthful reporting is dominant whenever the default algorithm dominates competing builders, and it remains dominant for all conflict-free transactions, even when builders may win. We further show that even if a searcher can technically integrate with a builder, non-integration combined with truthful bidding still dominates any deviation for conflict-free transactions. We also implement a concrete default algorithm informed by empirical analysis of real-world transactions and evaluate its efficacy using historical transaction data.", "AI": {"tldr": "Boost+ \u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u533a\u5757\u6784\u5efa\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u4ea4\u6613\u6536\u96c6\u4e0e\u6392\u5e8f\u5206\u79bb\u6765\u786e\u4fdd\u516c\u5e73\u8bbf\u95ee\uff0c\u89e3\u51b3 MEV-Boost \u7684\u4e2d\u5fc3\u5316\u95ee\u9898\uff0c\u63d0\u9ad8\u533a\u5757\u7a7a\u95f4\u6548\u7387\u3002", "motivation": "\u4ee5\u592a\u574a\u5f53\u524d\u7684\u533a\u5757\u6784\u5efa\u751f\u6001\u7cfb\u7edf MEV-Boost \u7531\u4e8e\u96c6\u6210\u800c\u9ad8\u5ea6\u4e2d\u5fc3\u5316\uff0c\u626d\u66f2\u4e86\u7ade\u4e89\u3001\u964d\u4f4e\u4e86\u533a\u5757\u7a7a\u95f4\u6548\u7387\uff0c\u5e76\u6a21\u7cca\u4e86 MEV \u6d41\u7684\u900f\u660e\u5ea6\u3002\u9700\u8981\u4fdd\u8bc1\u533a\u5757\u6784\u5efa\u7684\u516c\u5e73\u6027\u548c\u7ecf\u6d4e\u6548\u7387\u3002", "method": "\u63d0\u51fa Boost+ \u7cfb\u7edf\uff0c\u5c06\u533a\u5757\u6784\u5efa\u8fc7\u7a0b\u89e3\u8026\u4e3a\u4ea4\u6613\u6536\u96c6\u548c\u6392\u5e8f\u4e24\u4e2a\u9636\u6bb5\u3002\u6838\u5fc3\u662f M_Boost+ \u673a\u5236\uff0c\u56f4\u7ed5\u9ed8\u8ba4\u7b97\u6cd5\u6784\u5efa\uff0c\u786e\u4fdd\u6240\u6709\u6536\u96c6\u5230\u7684\u4ea4\u6613\u90fd\u6709\u5e73\u7b49\u8bbf\u95ee\u6743\u3002\u673a\u5236\u8bbe\u8ba1\u4f7f\u8bda\u5b9e\u51fa\u4ef7\u6210\u4e3a\u6240\u6709\u6784\u5efa\u8005\u7684\u4e3b\u5bfc\u7b56\u7565\uff0c\u5bf9\u4e8e\u641c\u7d22\u8005\uff0c\u5728\u9ed8\u8ba4\u7b97\u6cd5\u4e3b\u5bfc\u7ade\u4e89\u6784\u5efa\u8005\u65f6\uff0c\u8bda\u5b9e\u62a5\u544a\u662f\u4e3b\u5bfc\u7b56\u7565\u3002", "result": "M_Boost+ \u673a\u5236\u786e\u4fdd\uff1a1) \u8bda\u5b9e\u51fa\u4ef7\u662f\u6240\u6709\u6784\u5efa\u8005\u7684\u4e3b\u5bfc\u7b56\u7565\uff1b2) \u5bf9\u4e8e\u641c\u7d22\u8005\uff0c\u5f53\u9ed8\u8ba4\u7b97\u6cd5\u4e3b\u5bfc\u7ade\u4e89\u6784\u5efa\u8005\u65f6\uff0c\u8bda\u5b9e\u62a5\u544a\u662f\u4e3b\u5bfc\u7b56\u7565\uff1b3) \u5bf9\u4e8e\u6240\u6709\u65e0\u51b2\u7a81\u4ea4\u6613\uff0c\u5373\u4f7f\u6784\u5efa\u8005\u53ef\u80fd\u83b7\u80dc\uff0c\u8bda\u5b9e\u62a5\u544a\u4ecd\u662f\u4e3b\u5bfc\u7b56\u7565\uff1b4) \u5373\u4f7f\u641c\u7d22\u8005\u6280\u672f\u4e0a\u80fd\u4e0e\u6784\u5efa\u8005\u96c6\u6210\uff0c\u5bf9\u4e8e\u65e0\u51b2\u7a81\u4ea4\u6613\uff0c\u975e\u96c6\u6210\u7ed3\u5408\u8bda\u5b9e\u51fa\u4ef7\u4ecd\u4f18\u4e8e\u4efb\u4f55\u504f\u79bb\u7b56\u7565\u3002", "conclusion": "Boost+ \u901a\u8fc7\u89e3\u8026\u4ea4\u6613\u6536\u96c6\u548c\u6392\u5e8f\uff0c\u89e3\u51b3\u4e86 MEV-Boost \u7684\u4e2d\u5fc3\u5316\u95ee\u9898\uff0c\u786e\u4fdd\u4e86\u533a\u5757\u6784\u5efa\u7684\u516c\u5e73\u6027\u548c\u7ecf\u6d4e\u6548\u7387\u3002\u57fa\u4e8e\u771f\u5b9e\u4ea4\u6613\u6570\u636e\u5b9e\u8bc1\u5206\u6790\u7684\u5177\u4f53\u9ed8\u8ba4\u7b97\u6cd5\u5b9e\u65bd\uff0c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u8be5\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.04039", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.04039", "abs": "https://arxiv.org/abs/2602.04039", "authors": ["Hoang Long Do", "Nasrin Sohrabi", "Muneeb Ul Hassan"], "title": "Evaluating the Vulnerability Landscape of LLM-Generated Smart Contracts", "comment": null, "summary": "Large language models (LLMs) have been widely adopted in modern software development lifecycles, where they are increasingly used to automate and assist code generation, significantly improving developer productivity and reducing development time. In the blockchain domain, developers increasingly rely on LLMs to generate and maintain smart contracts, the immutable, self-executing components of decentralized applications. Because deployed smart contracts cannot be modified, correctness and security are paramount, particularly in high-stakes domains such as finance and governance. Despite this growing reliance, the security implications of LLM-generated smart contracts remain insufficiently understood.\n  In this work, we conduct a systematic security analysis of Solidity smart contracts generated by state-of-the-art LLMs, including ChatGPT, Gemini, and Sonnet. We evaluate these contracts against a broad set of known smart contract vulnerabilities to assess their suitability for direct deployment in production environments. Our extensive experimental study shows that, despite their syntactic correctness and functional completeness, LLM-generated smart contracts frequently exhibit severe security flaws that could be exploited in real-world settings. We further analyze and categorize these vulnerabilities, identifying recurring weakness patterns across different models. Finally, we discuss practical countermeasures and development guidelines to help mitigate these risks, offering actionable insights for both developers and researchers. Our findings aim to support safe integration of LLMs into smart contract development workflows and to strengthen the overall security of the blockchain ecosystem against future security failures.", "AI": {"tldr": "\u5bf9ChatGPT\u3001Gemini\u548cSonnet\u7b49\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684Solidity\u667a\u80fd\u5408\u7ea6\u8fdb\u884c\u7cfb\u7edf\u6027\u5b89\u5168\u5206\u6790\uff0c\u53d1\u73b0\u5c3d\u7ba1\u8fd9\u4e9b\u5408\u7ea6\u8bed\u6cd5\u6b63\u786e\u3001\u529f\u80fd\u5b8c\u6574\uff0c\u4f46\u7ecf\u5e38\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u4e0d\u9002\u5408\u76f4\u63a5\u90e8\u7f72\u5230\u751f\u4ea7\u73af\u5883\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7531\u4e8e\u667a\u80fd\u5408\u7ea6\u90e8\u7f72\u540e\u4e0d\u53ef\u4fee\u6539\u7684\u7279\u6027\uff0c\u5176\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u76ee\u524d\u5bf9LLM\u751f\u6210\u7684\u667a\u80fd\u5408\u7ea6\u7684\u5b89\u5168\u5f71\u54cd\u4e86\u89e3\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u91d1\u878d\u548c\u6cbb\u7406\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u3002", "method": "\u5bf9ChatGPT\u3001Gemini\u548cSonnet\u7b49\u5148\u8fdbLLM\u751f\u6210\u7684Solidity\u667a\u80fd\u5408\u7ea6\u8fdb\u884c\u7cfb\u7edf\u6027\u5b89\u5168\u5206\u6790\uff0c\u9488\u5bf9\u5e7f\u6cdb\u7684\u5df2\u77e5\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u8fdb\u884c\u8bc4\u4f30\uff0c\u5206\u6790\u6f0f\u6d1e\u6a21\u5f0f\u5e76\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1LLM\u751f\u6210\u7684\u667a\u80fd\u5408\u7ea6\u8bed\u6cd5\u6b63\u786e\u4e14\u529f\u80fd\u5b8c\u6574\uff0c\u4f46\u7ecf\u5e38\u8868\u73b0\u51fa\u4e25\u91cd\u7684\u5b89\u5168\u7f3a\u9677\uff0c\u8fd9\u4e9b\u7f3a\u9677\u53ef\u80fd\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u88ab\u5229\u7528\u3002\u7814\u7a76\u8bc6\u522b\u4e86\u4e0d\u540c\u6a21\u578b\u95f4\u91cd\u590d\u51fa\u73b0\u7684\u5f31\u70b9\u6a21\u5f0f\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5b9e\u7528\u7684\u5bf9\u7b56\u548c\u5f00\u53d1\u6307\u5357\u6765\u51cf\u8f7b\u8fd9\u4e9b\u98ce\u9669\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u65e8\u5728\u652f\u6301LLM\u5b89\u5168\u96c6\u6210\u5230\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u4e2d\uff0c\u5e76\u52a0\u5f3a\u533a\u5757\u94fe\u751f\u6001\u7cfb\u7edf\u5bf9\u672a\u6765\u5b89\u5168\u6545\u969c\u7684\u6574\u4f53\u5b89\u5168\u6027\u3002"}}
{"id": "2602.04113", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04113", "abs": "https://arxiv.org/abs/2602.04113", "authors": ["Nikolas Melissaris", "Jiayi Xu", "Antigoni Polychroniadou", "Akira Takahashi", "Chenkai Weng"], "title": "ZKBoost: Zero-Knowledge Verifiable Training for XGBoost", "comment": null, "summary": "Gradient boosted decision trees, particularly XGBoost, are among the most effective methods for tabular data. As deployment in sensitive settings increases, cryptographic guarantees of model integrity become essential. We present ZKBoost, the first zero-knowledge proof of training (zkPoT) protocol for XGBoost, enabling model owners to prove correct training on a committed dataset without revealing data or parameters. We make three key contributions: (1) a fixed-point XGBoost implementation compatible with arithmetic circuits, enabling instantiation of efficient zkPoT, (2) a generic template of zkPoT for XGBoost, which can be instantiated with any general-purpose ZKP backend, and (3) vector oblivious linear evaluation (VOLE)-based instantiation resolving challenges in proving nonlinear fixed-point operations. Our fixed-point implementation matches standard XGBoost accuracy within 1\\% while enabling practical zkPoT on real-world datasets.", "AI": {"tldr": "ZKBoost\u662f\u9996\u4e2a\u7528\u4e8eXGBoost\u7684\u96f6\u77e5\u8bc6\u8bad\u7ec3\u8bc1\u660e\u534f\u8bae\uff0c\u5141\u8bb8\u6a21\u578b\u6240\u6709\u8005\u5728\u627f\u8bfa\u7684\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u6b63\u786e\u8bad\u7ec3\uff0c\u540c\u65f6\u4e0d\u6cc4\u9732\u6570\u636e\u6216\u53c2\u6570\u3002", "motivation": "\u968f\u7740\u68af\u5ea6\u63d0\u5347\u51b3\u7b56\u6811\uff08\u7279\u522b\u662fXGBoost\uff09\u5728\u654f\u611f\u573a\u666f\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u9700\u8981\u5bc6\u7801\u5b66\u4fdd\u8bc1\u6a21\u578b\u5b8c\u6574\u6027\uff0c\u786e\u4fdd\u8bad\u7ec3\u8fc7\u7a0b\u6b63\u786e\u4e14\u53ef\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u5173\u952e\u8d21\u732e\uff1a1) \u517c\u5bb9\u7b97\u672f\u7535\u8def\u7684\u5b9a\u70b9XGBoost\u5b9e\u73b0\uff1b2) \u9002\u7528\u4e8e\u4efb\u4f55\u901a\u7528ZKP\u540e\u7aef\u7684XGBoost zkPoT\u901a\u7528\u6a21\u677f\uff1b3) \u57fa\u4e8eVOLE\u7684\u5b9e\u4f8b\u5316\u89e3\u51b3\u975e\u7ebf\u6027\u5b9a\u70b9\u64cd\u4f5c\u8bc1\u660e\u6311\u6218\u3002", "result": "\u5b9a\u70b9\u5b9e\u73b0\u4e0e\u6807\u51c6XGBoost\u7cbe\u5ea6\u5dee\u5f02\u57281%\u4ee5\u5185\uff0c\u80fd\u591f\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u5b9e\u7528\u7684\u96f6\u77e5\u8bc6\u8bad\u7ec3\u8bc1\u660e\u3002", "conclusion": "ZKBoost\u4e3aXGBoost\u6a21\u578b\u63d0\u4f9b\u4e86\u9996\u4e2a\u96f6\u77e5\u8bc6\u8bad\u7ec3\u8bc1\u660e\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u51c6\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5bc6\u7801\u5b66\u53ef\u9a8c\u8bc1\u7684\u8bad\u7ec3\u5b8c\u6574\u6027\u3002"}}
{"id": "2602.04026", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04026", "abs": "https://arxiv.org/abs/2602.04026", "authors": ["Nandini Sharma", "Thomas Bock", "Rich Bowen", "Sayeed Choudhury", "Brian Fitzgerald", "Matt Germonprez", "Jim Herbsleb", "James Howison", "Tom Hughes", "Min Kyung Lee", "Stephanie Lieggi", "Andreas Liesenfeld", "Georg Link", "Nicholas Matsakis", "Audris Mockus", "Narayan Ramasubbu", "Christopher Robinson", "Gregorio Robles", "Nithya Ruff", "Sonali Shah", "Igor Steinmacher", "Bogdan Vasilescu", "Stephen Walli", "Christopher Yoo"], "title": "Accountability in Open Source Software Ecosystems: Workshop Report", "comment": null, "summary": "Open source software ecosystems are composed of a variety of stakeholders including but not limited to non-profit organizations, volunteer contributors, users, and corporations. The needs and motivations of these stakeholders are often diverse, unknown, and sometimes even conflicting given the engagement and investment of both volunteers and corporate actors. Given this, it is not clear how open source communities identify and engage with their stakeholders, understand their needs, and hold themselves accountable to those needs. We convened 24 expert scholars and practitioners studying and working with open source software communities for an exploratory workshop discussion on these ideas. The workshop titled \"Accountability and Open Source Software Ecosystems\" was organized on Oct 14-15 on campus in Carnegie Mellon University, Pittsburgh, PA. The purpose of this in-person workshop was to initiate conversations that explore important and urgent questions related to the role of accountability in open source software ecosystems, and to inspire an exciting research agenda and meaningful stakeholder engagement ideas for practitioners.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u7ec4\u7ec7\u4e13\u5bb6\u7814\u8ba8\u4f1a\uff0c\u63a2\u8ba8\u5f00\u6e90\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u4e2d\u5229\u76ca\u76f8\u5173\u8005\u7684\u591a\u6837\u6027\u3001\u9700\u6c42\u8bc6\u522b\u548c\u95ee\u8d23\u673a\u5236\u95ee\u9898\uff0c\u65e8\u5728\u6fc0\u53d1\u76f8\u5173\u7814\u7a76\u548c\u5b9e\u8df5\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u5305\u542b\u591a\u79cd\u5229\u76ca\u76f8\u5173\u8005\uff08\u975e\u8425\u5229\u7ec4\u7ec7\u3001\u5fd7\u613f\u8005\u3001\u7528\u6237\u3001\u4f01\u4e1a\u7b49\uff09\uff0c\u4ed6\u4eec\u7684\u9700\u6c42\u548c\u52a8\u673a\u591a\u6837\u4e14\u6709\u65f6\u76f8\u4e92\u51b2\u7a81\u3002\u76ee\u524d\u4e0d\u6e05\u695a\u5f00\u6e90\u793e\u533a\u5982\u4f55\u8bc6\u522b\u548c\u63a5\u89e6\u8fd9\u4e9b\u5229\u76ca\u76f8\u5173\u8005\u3001\u7406\u89e3\u4ed6\u4eec\u7684\u9700\u6c42\uff0c\u5e76\u5bf9\u5176\u9700\u6c42\u8d1f\u8d23\u3002", "method": "\u5728\u5361\u5185\u57fa\u6885\u9686\u5927\u5b66\u7ec4\u7ec7\u4e3a\u671f\u4e24\u5929\u7684\u73b0\u573a\u7814\u8ba8\u4f1a\uff0c\u53ec\u96c624\u4f4d\u7814\u7a76\u548c\u5de5\u4f5c\u4e8e\u5f00\u6e90\u8f6f\u4ef6\u793e\u533a\u7684\u4e13\u5bb6\u5b66\u8005\u548c\u5b9e\u8df5\u8005\uff0c\u8fdb\u884c\u63a2\u7d22\u6027\u8ba8\u8bba\u3002", "result": "\u7814\u8ba8\u4f1a\u65e8\u5728\u542f\u52a8\u5173\u4e8e\u5f00\u6e90\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u4e2d\u95ee\u8d23\u5236\u89d2\u8272\u7684\u91cd\u8981\u548c\u7d27\u8feb\u95ee\u9898\u7684\u5bf9\u8bdd\uff0c\u6fc0\u53d1\u7814\u7a76\u8bae\u7a0b\u548c\u6709\u610f\u4e49\u7684\u5229\u76ca\u76f8\u5173\u8005\u53c2\u4e0e\u5b9e\u8df5\u3002", "conclusion": "\u901a\u8fc7\u4e13\u5bb6\u7814\u8ba8\u4f1a\u63a2\u8ba8\u5f00\u6e90\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u7684\u95ee\u8d23\u673a\u5236\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u8ba8\u8bba\u8d77\u70b9\u548c\u65b9\u5411\u3002"}}
{"id": "2602.03900", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03900", "abs": "https://arxiv.org/abs/2602.03900", "authors": ["Erik Goh", "John Kos", "Ashok Goel"], "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks", "comment": null, "summary": "Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into question. Borrowing from the domain of cognitive and educational science, this paper investigates whether the Task-Method-Knowledge (TMK) framework can improve LLM reasoning capabilities beyond its previously demonstrated success in educational applications. The TMK framework's unique ability to capture causal, teleological, and hierarchical reasoning structures, combined with its explicit task decomposition mechanisms, makes it particularly well-suited for addressing language model reasoning deficiencies, and unlike other hierarchical frameworks such as HTN and BDI, TMK provides explicit representations of not just what to do and how to do it, but also why actions are taken. The study evaluates TMK by experimenting on the PlanBench benchmark, focusing on the Blocksworld domain to test for reasoning and planning capabilities, examining whether TMK-structured prompting can help language models better decompose complex planning problems into manageable sub-tasks. Results also highlight significant performance inversion in reasoning models. TMK prompting enables the reasoning model to achieve up to an accuracy of 97.3\\% on opaque, symbolic tasks (Random versions of Blocksworld in PlanBench) where it previously failed (31.5\\%), suggesting the potential to bridge the gap between semantic approximation and symbolic manipulation. Our findings suggest that TMK functions not merely as context, but also as a mechanism that steers reasoning models away from their default linguistic modes to engage formal, code-execution pathways in the context of the experiments.", "AI": {"tldr": "TMK\u6846\u67b6\u63d0\u793a\u6cd5\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5728PlanBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387\u4ece31.5%\u63d0\u5347\u81f397.3%", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u548c\u89c4\u5212\u4efb\u52a1\u4e0a\u5b58\u5728\u7f3a\u9677\uff0c\u73b0\u6709\u63d0\u793a\u6280\u672f\u5982\u601d\u7ef4\u94fe(CoT)\u7684\u6548\u679c\u53d7\u5230\u8d28\u7591\u3002\u7814\u7a76\u501f\u9274\u8ba4\u77e5\u548c\u6559\u80b2\u79d1\u5b66\u9886\u57df\u7684TMK\u6846\u67b6\uff0c\u63a2\u7d22\u5176\u80fd\u5426\u6539\u5584LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u5176\u56e0\u679c\u3001\u76ee\u7684\u8bba\u548c\u5c42\u6b21\u5316\u63a8\u7406\u7ed3\u6784\u53ef\u80fd\u5f25\u8865\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u4efb\u52a1-\u65b9\u6cd5-\u77e5\u8bc6(TMK)\u6846\u67b6\u6784\u5efa\u63d0\u793a\uff0c\u5728PlanBench\u57fa\u51c6\u6d4b\u8bd5\u7684Blocksworld\u9886\u57df\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6d4b\u8bd5TMK\u7ed3\u6784\u5316\u63d0\u793a\u662f\u5426\u80fd\u5e2e\u52a9\u8bed\u8a00\u6a21\u578b\u66f4\u597d\u5730\u5c06\u590d\u6742\u89c4\u5212\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u5b50\u4efb\u52a1\u3002", "result": "TMK\u63d0\u793a\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5728\u4e0d\u900f\u660e\u7684\u7b26\u53f7\u4efb\u52a1\uff08PlanBench\u4e2d\u7684\u968f\u673aBlocksworld\u7248\u672c\uff09\u4e0a\u51c6\u786e\u7387\u4ece31.5%\u63d0\u5347\u81f397.3%\uff0c\u663e\u793a\u51fa\u5728\u8bed\u4e49\u8fd1\u4f3c\u548c\u7b26\u53f7\u64cd\u4f5c\u4e4b\u95f4\u67b6\u8d77\u6865\u6881\u7684\u6f5c\u529b\u3002", "conclusion": "TMK\u4e0d\u4ec5\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff0c\u66f4\u662f\u4e00\u79cd\u673a\u5236\uff0c\u80fd\u591f\u5f15\u5bfc\u63a8\u7406\u6a21\u578b\u8fdc\u79bb\u5176\u9ed8\u8ba4\u7684\u8bed\u8a00\u6a21\u5f0f\uff0c\u5728\u5b9e\u9a8c\u4e2d\u6fc0\u6d3b\u5f62\u5f0f\u5316\u7684\u4ee3\u7801\u6267\u884c\u8def\u5f84\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660eTMK\u6846\u67b6\u5728\u63d0\u5347LLM\u7b26\u53f7\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2602.04238", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.04238", "abs": "https://arxiv.org/abs/2602.04238", "authors": ["Vipin Kumar Rathi", "Lakshya Chopra", "Nikhil Kumar Rajput"], "title": "Post-Quantum Identity-Based TLS for 5G Service-Based Architecture and Cloud-Native Infrastructure", "comment": "29 pages", "summary": "Cloud-native application platforms and latency-sensitive systems such as 5G Core networks rely heavily on certificate-based Public Key Infrastructure (PKI) and mutual TLS to secure service-to-service communication. While effective, this model introduces significant operational and performance overhead, which is further amplified in the post-quantum setting due to large certificates and expensive signature verification. In this paper, we present a certificate-free authentication framework for private distributed systems based on post-quantum Identity-Based Encryption(IBE). Our design replaces certificate and signature based authentication with identity-derived keys and identity-based key encapsulation, enabling mutually authenticated TLS connections without certificate transmission or validation. We describe an IBE-based replacement for private PKI, including identity lifecycle management, and show how it can be instantiated using a threshold Private Key Generator (T-PKG). We apply this framework to cloud-native application deployments and latency-sensitive 5G Core networks. In particular, we demonstrate how identity-based TLS integrates with the 5G Service-Based Architecture while preserving security semantics and 3GPP requirements, and we show how the same architecture can replace private PKI in Kubernetes, including its control plane, without disrupting existing trust domains or deployment models.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u540e\u91cf\u5b50\u8eab\u4efd\u57fa\u52a0\u5bc6\u7684\u65e0\u8bc1\u4e66\u8ba4\u8bc1\u6846\u67b6\uff0c\u66ff\u4ee3\u4f20\u7edfPKI\u548c\u8bc1\u4e66\u9a8c\u8bc1\uff0c\u7528\u4e8e\u79c1\u6709\u5206\u5e03\u5f0f\u7cfb\u7edf\u3001\u4e91\u539f\u751f\u5e73\u53f0\u548c5G\u6838\u5fc3\u7f51", "motivation": "\u4e91\u539f\u751f\u5e73\u53f0\u548c5G\u6838\u5fc3\u7f51\u7b49\u5ef6\u8fdf\u654f\u611f\u7cfb\u7edf\u4f9d\u8d56\u57fa\u4e8e\u8bc1\u4e66\u7684PKI\u548cmTLS\u8fdb\u884c\u670d\u52a1\u95f4\u901a\u4fe1\u5b89\u5168\uff0c\u4f46\u8be5\u6a21\u578b\u5e26\u6765\u663e\u8457\u7684\u64cd\u4f5c\u548c\u6027\u80fd\u5f00\u9500\uff0c\u5728\u540e\u91cf\u5b50\u573a\u666f\u4e0b\u7531\u4e8e\u5927\u8bc1\u4e66\u548c\u6602\u8d35\u7684\u7b7e\u540d\u9a8c\u8bc1\u800c\u8fdb\u4e00\u6b65\u653e\u5927", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u540e\u91cf\u5b50\u8eab\u4efd\u57fa\u52a0\u5bc6\u7684\u65e0\u8bc1\u4e66\u8ba4\u8bc1\u6846\u67b6\uff0c\u7528\u8eab\u4efd\u6d3e\u751f\u5bc6\u94a5\u548c\u57fa\u4e8e\u8eab\u4efd\u7684\u5bc6\u94a5\u5c01\u88c5\u66ff\u4ee3\u8bc1\u4e66\u548c\u57fa\u4e8e\u7b7e\u540d\u7684\u8ba4\u8bc1\uff0c\u5b9e\u73b0\u65e0\u9700\u8bc1\u4e66\u4f20\u8f93\u6216\u9a8c\u8bc1\u7684\u76f8\u4e92\u8ba4\u8bc1TLS\u8fde\u63a5\uff1b\u5305\u62ec\u57fa\u4e8e\u9608\u503c\u79c1\u94a5\u751f\u6210\u5668\u7684\u79c1\u6709PKI\u66ff\u4ee3\u65b9\u6848", "result": "\u5c06\u6846\u67b6\u5e94\u7528\u4e8e\u4e91\u539f\u751f\u5e94\u7528\u90e8\u7f72\u548c5G\u6838\u5fc3\u7f51\uff0c\u5c55\u793a\u8eab\u4efd\u57faTLS\u5982\u4f55\u4e0e5G\u670d\u52a1\u67b6\u6784\u96c6\u6210\u5e76\u4fdd\u6301\u5b89\u5168\u8bed\u4e49\u548c3GPP\u8981\u6c42\uff0c\u4ee5\u53ca\u76f8\u540c\u67b6\u6784\u5982\u4f55\u5728\u4e0d\u7834\u574f\u73b0\u6709\u4fe1\u4efb\u57df\u6216\u90e8\u7f72\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u66ff\u4ee3Kubernetes\u4e2d\u7684\u79c1\u6709PKI", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u540e\u91cf\u5b50\u8eab\u4efd\u57fa\u52a0\u5bc6\u7684\u65e0\u8bc1\u4e66\u8ba4\u8bc1\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f20\u7edfPKI\u5728\u540e\u91cf\u5b50\u73af\u5883\u4e0b\u7684\u6027\u80fd\u548c\u64cd\u4f5c\u5f00\u9500\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u4e91\u539f\u751f\u5e73\u53f0\u548c5G\u6838\u5fc3\u7f51\u7b49\u5173\u952e\u57fa\u7840\u8bbe\u65bd"}}
{"id": "2602.03950", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03950", "abs": "https://arxiv.org/abs/2602.03950", "authors": ["Aditya Basarkar", "Benyamin Tabarsi", "Tiffany Barnes", "Dongkuan", "Xu"], "title": "Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation", "comment": "9 pages, 7 figures, submitted to ACL ARR 2026", "summary": "Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems have enhanced their mathematical reasoning capabilities, they still lack a reliably revisable representation of the reasoning process. Existing agents either operate in rigid sequential pipelines that cannot correct earlier steps or rely on heuristic self-evaluation that can fail to identify and fix errors. In addition, programmatic context can distract language models and degrade accuracy. To address these gaps, we introduce Iteratively Improved Program Construction (IIPC), a reasoning method that iteratively refines programmatic reasoning chains and combines execution feedback with the native Chain-of-thought abilities of the base LLM to maintain high-level contextual focus. IIPC surpasses competing approaches in the majority of reasoning benchmarks on multiple base LLMs. All code and implementations are released as open source.", "AI": {"tldr": "IIPC\u662f\u4e00\u79cd\u8fed\u4ee3\u6539\u8fdb\u7684\u7a0b\u5e8f\u6784\u9020\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u7a0b\u5e8f\u6267\u884c\u53cd\u9988\u548cLLM\u7684\u601d\u7ef4\u94fe\u80fd\u529b\u6765\u63d0\u5347\u6570\u5b66\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u53ef\u4fee\u6b63\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u4ecd\u7f3a\u4e4f\u53ef\u9760\u53ef\u4fee\u6b63\u7684\u63a8\u7406\u8fc7\u7a0b\u8868\u793a\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u91c7\u7528\u50f5\u5316\u7684\u987a\u5e8f\u6d41\u7a0b\u65e0\u6cd5\u4fee\u6b63\u65e9\u671f\u9519\u8bef\uff0c\u8981\u4e48\u4f9d\u8d56\u53ef\u80fd\u5931\u6548\u7684\u542f\u53d1\u5f0f\u81ea\u8bc4\u4f30\uff0c\u4e14\u7a0b\u5e8f\u5316\u4e0a\u4e0b\u6587\u53ef\u80fd\u5206\u6563\u8bed\u8a00\u6a21\u578b\u7684\u6ce8\u610f\u529b\u5e76\u964d\u4f4e\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u8fed\u4ee3\u6539\u8fdb\u7684\u7a0b\u5e8f\u6784\u9020\uff08IIPC\uff09\u65b9\u6cd5\uff0c\u8fed\u4ee3\u4f18\u5316\u7a0b\u5e8f\u5316\u63a8\u7406\u94fe\uff0c\u5c06\u6267\u884c\u53cd\u9988\u4e0e\u57fa\u7840LLM\u7684\u601d\u7ef4\u94fe\u80fd\u529b\u76f8\u7ed3\u5408\uff0c\u4fdd\u6301\u9ad8\u5c42\u6b21\u4e0a\u4e0b\u6587\u805a\u7126\u3002", "result": "IIPC\u5728\u591a\u4e2a\u57fa\u7840LLM\u4e0a\u7684\u5927\u591a\u6570\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u7ade\u4e89\u65b9\u6cd5\u3002", "conclusion": "IIPC\u901a\u8fc7\u8fed\u4ee3\u6539\u8fdb\u7a0b\u5e8f\u6784\u9020\u548c\u7ed3\u5408\u6267\u884c\u53cd\u9988\u4e0e\u601d\u7ef4\u94fe\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\uff0c\u6240\u6709\u4ee3\u7801\u548c\u5b9e\u73b0\u5df2\u5f00\u6e90\u53d1\u5e03\u3002"}}
{"id": "2602.04562", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.04562", "abs": "https://arxiv.org/abs/2602.04562", "authors": ["Anneliese Riess", "Juan Felipe Gomez", "Flavio du Pin Calmon", "Julia Anne Schnabel", "Georgios Kaissis"], "title": "Optimal conversion from R\u00e9nyi Differential Privacy to $f$-Differential Privacy", "comment": "Preprint. Under review", "summary": "We prove the conjecture stated in Appendix F.3 of [Zhu et al. (2022)]: among all conversion rules that map a R\u00e9nyi Differential Privacy (RDP) profile $\u03c4\\mapsto \u03c1(\u03c4)$ to a valid hypothesis-testing trade-off $f$, the rule based on the intersection of single-order RDP privacy regions is optimal. This optimality holds simultaneously for all valid RDP profiles and for all Type I error levels $\u03b1$. Concretely, we show that in the space of trade-off functions, the tightest possible bound is $f_{\u03c1(\\cdot)}(\u03b1) = \\sup_{\u03c4\\geq 0.5} f_{\u03c4,\u03c1(\u03c4)}(\u03b1)$: the pointwise maximum of the single-order bounds for each RDP privacy region. Our proof unifies and sharpens the insights of [Balle et al. (2019)], [Asoodeh et al. (2021)], and [Zhu et al. (2022)]. Our analysis relies on a precise geometric characterization of the RDP privacy region, leveraging its convexity and the fact that its boundary is determined exclusively by Bernoulli mechanisms. Our results establish that the \"intersection-of-RDP-privacy-regions\" rule is not only valid, but optimal: no other black-box conversion can uniformly dominate it in the Blackwell sense, marking the fundamental limit of what can be inferred about a mechanism's privacy solely from its RDP guarantees.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u5c06R\u00e9nyi\u5dee\u5206\u9690\u79c1(RDP)\u914d\u7f6e\u6587\u4ef6\u8f6c\u6362\u4e3a\u6709\u6548\u5047\u8bbe\u68c0\u9a8c\u6743\u8861\u51fd\u6570\u7684\u6700\u4f18\u8f6c\u6362\u89c4\u5219\u662f\u57fa\u4e8e\u5355\u9636RDP\u9690\u79c1\u533a\u57df\u4ea4\u96c6\u7684\u65b9\u6cd5\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3Zhu\u7b49\u4eba(2022)\u9644\u5f55F.3\u4e2d\u63d0\u51fa\u7684\u731c\u60f3\uff1a\u5728\u6240\u6709\u5c06RDP\u914d\u7f6e\u6587\u4ef6\u6620\u5c04\u5230\u6709\u6548\u5047\u8bbe\u68c0\u9a8c\u6743\u8861\u51fd\u6570\u7684\u8f6c\u6362\u89c4\u5219\u4e2d\uff0c\u57fa\u4e8e\u5355\u9636RDP\u9690\u79c1\u533a\u57df\u4ea4\u96c6\u7684\u89c4\u5219\u662f\u5426\u6700\u4f18\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u7cbe\u786e\u7684\u51e0\u4f55\u7279\u5f81\u5206\u6790RDP\u9690\u79c1\u533a\u57df\uff0c\u5229\u7528\u5176\u51f8\u6027\u4ee5\u53ca\u8fb9\u754c\u5b8c\u5168\u7531\u4f2f\u52aa\u5229\u673a\u5236\u51b3\u5b9a\u7684\u6027\u8d28\u3002\u8bc1\u660e\u5728\u6743\u8861\u51fd\u6570\u7a7a\u95f4\u4e2d\uff0c\u6700\u7d27\u7684\u8fb9\u754c\u662f$f_{\u03c1(\\cdot)}(\u03b1) = \\sup_{\u03c4\\geq 0.5} f_{\u03c4,\u03c1(\u03c4)}(\u03b1)$\uff0c\u5373\u6bcf\u4e2aRDP\u9690\u79c1\u533a\u57df\u5355\u9636\u8fb9\u754c\u7684\u9010\u70b9\u6700\u5927\u503c\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8eRDP\u9690\u79c1\u533a\u57df\u4ea4\u96c6\u7684\u8f6c\u6362\u89c4\u5219\u4e0d\u4ec5\u662f\u6709\u6548\u7684\uff0c\u800c\u4e14\u662f\u6700\u4f18\u7684\uff1a\u5728Blackwell\u610f\u4e49\u4e0a\uff0c\u6ca1\u6709\u5176\u4ed6\u9ed1\u76d2\u8f6c\u6362\u80fd\u4e00\u81f4\u5730\u4f18\u4e8e\u5b83\u3002\u8fd9\u6807\u5fd7\u7740\u4ec5\u4eceRDP\u4fdd\u8bc1\u63a8\u65ad\u673a\u5236\u9690\u79c1\u6027\u7684\u57fa\u672c\u6781\u9650\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8bc1\u660e\u4e86Zhu\u7b49\u4eba(2022)\u7684\u731c\u60f3\uff0c\u7edf\u4e00\u5e76\u5f3a\u5316\u4e86Balle\u7b49\u4eba(2019)\u3001Asoodeh\u7b49\u4eba(2021)\u548cZhu\u7b49\u4eba(2022)\u7684\u89c1\u89e3\uff0c\u786e\u7acb\u4e86RDP\u5230\u5047\u8bbe\u68c0\u9a8c\u6743\u8861\u51fd\u6570\u8f6c\u6362\u7684\u57fa\u672c\u6700\u4f18\u6027\u754c\u9650\u3002"}}
{"id": "2602.04165", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04165", "abs": "https://arxiv.org/abs/2602.04165", "authors": ["Derin Gezgin", "Amartya Das", "Shinhae Kim", "Zhengdong Huang", "Nevena Stojkovic", "Claire Wang"], "title": "I Can't Believe It's Not a Valid Exploit", "comment": null, "summary": "Recently Large Language Models (LLMs) have been used in security vulnerability detection tasks including generating proof-of-concept (PoC) exploits. A PoC exploit is a program used to demonstrate how a vulnerability can be exploited. Several approaches suggest that supporting LLMs with additional guidance can improve PoC generation outcomes, motivating further evaluation of their effectiveness. In this work, we develop PoC-Gym, a framework for PoC generation for Java security vulnerabilities via LLMs and systematic validation of generated exploits. Using PoC-Gym, we evaluate whether the guidance from static analysis tools improves the PoC generation success rate and manually inspect the resulting PoCs. Our results from running PoC-Gym with Claude Sonnet 4, GPT-5 Medium, and gpt-oss-20b show that using static analysis for guidance and criteria lead to 21% higher success rates than the prior baseline, FaultLine. However, manual inspection of both successful and failed PoCs reveals that 71.5% of the PoCs are invalid. These results show that the reported success of LLM-based PoC generation can be significantly misleading, which is hard to detect with current validation mechanisms.", "AI": {"tldr": "PoC-Gym\u6846\u67b6\u8bc4\u4f30LLM\u751f\u6210Java\u5b89\u5168\u6f0f\u6d1ePoC\u5229\u7528\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u9759\u6001\u5206\u6790\u6307\u5bfc\u80fd\u63d0\u9ad821%\u6210\u529f\u7387\uff0c\u4f46\u624b\u52a8\u68c0\u67e5\u663e\u793a71.5%\u7684PoC\u65e0\u6548\uff0c\u8868\u660e\u5f53\u524d\u9a8c\u8bc1\u673a\u5236\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\u3002", "motivation": "\u8bc4\u4f30LLM\u5728\u751f\u6210\u5b89\u5168\u6f0f\u6d1ePoC\u5229\u7528\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u9a8c\u8bc1\u9759\u6001\u5206\u6790\u5de5\u5177\u63d0\u4f9b\u7684\u6307\u5bfc\u662f\u5426\u80fd\u771f\u6b63\u63d0\u9ad8PoC\u751f\u6210\u7684\u6210\u529f\u7387\uff0c\u5e76\u63ed\u793a\u5f53\u524d\u9a8c\u8bc1\u673a\u5236\u7684\u5c40\u9650\u6027\u3002", "method": "\u5f00\u53d1PoC-Gym\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7LLM\u751f\u6210Java\u5b89\u5168\u6f0f\u6d1e\u7684PoC\u5229\u7528\u5e76\u8fdb\u884c\u7cfb\u7edf\u9a8c\u8bc1\u3002\u4f7f\u7528Claude Sonnet 4\u3001GPT-5 Medium\u548cgpt-oss-20b\u7b49\u6a21\u578b\uff0c\u6bd4\u8f83\u4f7f\u7528\u9759\u6001\u5206\u6790\u6307\u5bfc\u4e0e\u57fa\u7ebf\u65b9\u6cd5FaultLine\u7684\u6548\u679c\u3002", "result": "\u4f7f\u7528\u9759\u6001\u5206\u6790\u6307\u5bfc\u6bd4\u57fa\u7ebfFaultLine\u63d0\u9ad821%\u7684\u6210\u529f\u7387\u3002\u4f46\u624b\u52a8\u68c0\u67e5\u53d1\u73b071.5%\u7684PoC\u662f\u65e0\u6548\u7684\uff0c\u8868\u660e\u5f53\u524d\u81ea\u52a8\u9a8c\u8bc1\u673a\u5236\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u9ad8\u6210\u529f\u7387\u6570\u636e\u5177\u6709\u8bef\u5bfc\u6027\u3002", "conclusion": "LLM\u5728PoC\u751f\u6210\u65b9\u9762\u867d\u7136\u663e\u793a\u6539\u8fdb\uff0c\u4f46\u5f53\u524d\u9a8c\u8bc1\u673a\u5236\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u751f\u6210\u8d28\u91cf\uff0c\u62a5\u544a\u7684\u6210\u529f\u7387\u5177\u6709\u8bef\u5bfc\u6027\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u9a8c\u8bc1\u65b9\u6cd5\u6765\u8bc4\u4f30LLM\u5728\u5b89\u5168\u6f0f\u6d1e\u5229\u7528\u751f\u6210\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\u3002"}}
{"id": "2602.03955", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03955", "abs": "https://arxiv.org/abs/2602.03955", "authors": ["Yinyi Luo", "Yiqiao Jin", "Weichen Yu", "Mengqi Zhang", "Srijan Kumar", "Xiaoxiao Li", "Weijie Xu", "Xin Chen", "Jindong Wang"], "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent", "comment": null, "summary": "While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the intelligence of multi-agent systems while remaining computationally efficient. Specifically, we investigate three hierarchical distillation strategies across various models, tasks, scaling, and scenarios: reasoning-enhanced fine-tuning; trajectory-based augmentation; and process-aware distillation. By shifting the burden of computation from inference to training, the distilled models preserve the efficiency of one agent while exhibiting strong reasoning and self-correction performance of multiple agents. They further demonstrate enhanced robustness and generalization across diverse reasoning tasks. We hope this work can shed light on future research on efficient and robust multi-agent development. Our code is at https://github.com/AIFrontierLab/AgentArk.", "AI": {"tldr": "AgentArk\u6846\u67b6\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u52a8\u6001\u84b8\u998f\u5230\u5355\u4e2a\u6a21\u578b\u7684\u6743\u91cd\u4e2d\uff0c\u5c06\u663e\u5f0f\u7684\u6d4b\u8bd5\u65f6\u4ea4\u4e92\u8f6c\u5316\u4e3a\u9690\u5f0f\u7684\u6a21\u578b\u80fd\u529b\uff0c\u4f7f\u5355\u4e2a\u667a\u80fd\u4f53\u5177\u5907\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u667a\u80fd\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u8fc7\u8fed\u4ee3\u8fa9\u8bba\u5b9e\u73b0\u4f18\u8d8a\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u53d7\u5230\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u9519\u8bef\u4f20\u64ad\u7684\u9650\u5236\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5728\u4fdd\u6301\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u63d0\u51faAgentArk\u6846\u67b6\uff0c\u7814\u7a76\u4e09\u79cd\u5206\u5c42\u84b8\u998f\u7b56\u7565\uff1a\u63a8\u7406\u589e\u5f3a\u5fae\u8c03\u3001\u57fa\u4e8e\u8f68\u8ff9\u7684\u589e\u5f3a\u548c\u8fc7\u7a0b\u611f\u77e5\u84b8\u998f\u3002\u901a\u8fc7\u5c06\u8ba1\u7b97\u8d1f\u62c5\u4ece\u63a8\u7406\u8f6c\u79fb\u5230\u8bad\u7ec3\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u52a8\u6001\u84b8\u998f\u5230\u5355\u4e2a\u6a21\u578b\u7684\u6743\u91cd\u4e2d\u3002", "result": "\u84b8\u998f\u540e\u7684\u6a21\u578b\u5728\u4fdd\u6301\u5355\u4e2a\u667a\u80fd\u4f53\u6548\u7387\u7684\u540c\u65f6\uff0c\u5c55\u73b0\u51fa\u591a\u667a\u80fd\u4f53\u7684\u5f3a\u5927\u63a8\u7406\u548c\u81ea\u6211\u7ea0\u6b63\u6027\u80fd\u3002\u5728\u4e0d\u540c\u6a21\u578b\u3001\u4efb\u52a1\u3001\u89c4\u6a21\u548c\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "AgentArk\u901a\u8fc7\u5c06\u591a\u667a\u80fd\u4f53\u52a8\u6001\u84b8\u998f\u5230\u5355\u4e2a\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u63a8\u7406\u7cfb\u7edf\uff0c\u4e3a\u672a\u6765\u9ad8\u6548\u591a\u667a\u80fd\u4f53\u5f00\u53d1\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.04653", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04653", "abs": "https://arxiv.org/abs/2602.04653", "authors": ["Ariel Fogel", "Omer Hofman", "Eilon Cohen", "Roman Vainshtein"], "title": "Inference-Time Backdoors via Hidden Instructions in LLM Chat Templates", "comment": null, "summary": "Open-weight language models are increasingly used in production settings, raising new security challenges. One prominent threat in this context is backdoor attacks, in which adversaries embed hidden behaviors in language models that activate under specific conditions. Previous work has assumed that adversaries have access to training pipelines or deployment infrastructure. We propose a novel attack surface requiring neither, which utilizes the chat template. Chat templates are executable Jinja2 programs invoked at every inference call, occupying a privileged position between user input and model processing. We show that an adversary who distributes a model with a maliciously modified template can implant an inference-time backdoor without modifying model weights, poisoning training data, or controlling runtime infrastructure. We evaluated this attack vector by constructing template backdoors targeting two objectives: degrading factual accuracy and inducing emission of attacker-controlled URLs, and applied them across eighteen models spanning seven families and four inference engines. Under triggered conditions, factual accuracy drops from 90% to 15% on average while attacker-controlled URLs are emitted with success rates exceeding 80%; benign inputs show no measurable degradation. Backdoors generalize across inference runtimes and evade all automated security scans applied by the largest open-weight distribution platform. These results establish chat templates as a reliable and currently undefended attack surface in the LLM supply chain.", "AI": {"tldr": "\u653b\u51fb\u8005\u901a\u8fc7\u4fee\u6539\u804a\u5929\u6a21\u677f\u800c\u975e\u6a21\u578b\u6743\u91cd\u6216\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u4e2d\u690d\u5165\u63a8\u7406\u65f6\u540e\u95e8\uff0c\u8be5\u653b\u51fb\u5728\u89e6\u53d1\u6761\u4ef6\u4e0b\u80fd\u663e\u8457\u964d\u4f4e\u4e8b\u5b9e\u51c6\u786e\u6027\u5e76\u8bf1\u5bfc\u8f93\u51fa\u653b\u51fb\u8005\u63a7\u5236\u7684URL\uff0c\u4e14\u80fd\u9003\u907f\u73b0\u6709\u5b89\u5168\u626b\u63cf", "motivation": "\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u4f7f\u7528\u65e5\u76ca\u589e\u591a\uff0c\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u6311\u6218\u3002\u4f20\u7edf\u7684\u540e\u95e8\u653b\u51fb\u901a\u5e38\u5047\u8bbe\u653b\u51fb\u8005\u80fd\u8bbf\u95ee\u8bad\u7ec3\u7ba1\u9053\u6216\u90e8\u7f72\u57fa\u7840\u8bbe\u65bd\uff0c\u4f46\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u653b\u51fb\u9762\uff0c\u5229\u7528\u804a\u5929\u6a21\u677f\u8fd9\u4e00\u7279\u6743\u4f4d\u7f6e\u5b9e\u65bd\u653b\u51fb\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u6743\u91cd\u3001\u6c61\u67d3\u8bad\u7ec3\u6570\u636e\u6216\u63a7\u5236\u8fd0\u884c\u65f6\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u653b\u51fb\u8005\u901a\u8fc7\u5206\u53d1\u5e26\u6709\u6076\u610f\u4fee\u6539\u804a\u5929\u6a21\u677f\u7684\u6a21\u578b\u6765\u5b9e\u65bd\u63a8\u7406\u65f6\u540e\u95e8\u653b\u51fb\u3002\u804a\u5929\u6a21\u677f\u662f\u6bcf\u6b21\u63a8\u7406\u8c03\u7528\u65f6\u6267\u884c\u7684Jinja2\u7a0b\u5e8f\uff0c\u4f4d\u4e8e\u7528\u6237\u8f93\u5165\u548c\u6a21\u578b\u5904\u7406\u4e4b\u95f4\u7684\u7279\u6743\u4f4d\u7f6e\u3002\u7814\u7a76\u6784\u5efa\u4e86\u9488\u5bf9\u4e24\u4e2a\u76ee\u6807\u7684\u6a21\u677f\u540e\u95e8\uff1a\u964d\u4f4e\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u8bf1\u5bfc\u8f93\u51fa\u653b\u51fb\u8005\u63a7\u5236\u7684URL\uff0c\u5e76\u572818\u4e2a\u6a21\u578b\u30017\u4e2a\u6a21\u578b\u5bb6\u65cf\u548c4\u4e2a\u63a8\u7406\u5f15\u64ce\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u5728\u89e6\u53d1\u6761\u4ef6\u4e0b\uff0c\u4e8b\u5b9e\u51c6\u786e\u6027\u4ece90%\u5e73\u5747\u4e0b\u964d\u523015%\uff0c\u653b\u51fb\u8005\u63a7\u5236\u7684URL\u8f93\u51fa\u6210\u529f\u7387\u8d85\u8fc780%\uff1b\u826f\u6027\u8f93\u5165\u6ca1\u6709\u53ef\u6d4b\u91cf\u7684\u6027\u80fd\u4e0b\u964d\u3002\u540e\u95e8\u5728\u4e0d\u540c\u63a8\u7406\u8fd0\u884c\u65f6\u4e2d\u5177\u6709\u901a\u7528\u6027\uff0c\u5e76\u80fd\u9003\u907f\u6700\u5927\u5f00\u6e90\u6a21\u578b\u5206\u53d1\u5e73\u53f0\u7684\u6240\u6709\u81ea\u52a8\u5316\u5b89\u5168\u626b\u63cf\u3002", "conclusion": "\u804a\u5929\u6a21\u677f\u662fLLM\u4f9b\u5e94\u94fe\u4e2d\u4e00\u4e2a\u53ef\u9760\u4e14\u76ee\u524d\u672a\u88ab\u9632\u5fa1\u7684\u653b\u51fb\u9762\uff0c\u9700\u8981\u65b0\u7684\u5b89\u5168\u63aa\u65bd\u6765\u68c0\u6d4b\u548c\u7f13\u89e3\u8fd9\u7c7b\u6a21\u677f\u540e\u95e8\u653b\u51fb\u3002"}}
{"id": "2602.04195", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.04195", "abs": "https://arxiv.org/abs/2602.04195", "authors": ["Guang Yang", "Xing Hu", "Xiang Chen", "Xin Xia"], "title": "Semantic Consensus Decoding: Backdoor Defense for Verilog Code Generation", "comment": "Under Review", "summary": "Large language models (LLMs) for Verilog code generation are increasingly adopted in hardware design, yet remain vulnerable to backdoor attacks where adversaries inject malicious triggers during training to induce vulnerable hardware designs. Unlike patchable software vulnerabilities, hardware trojans become irreversible once fabricated, making remediation extremely costly or impossible. Existing active defenses require access to training data, impractical for third-party LLM users, while passive defenses struggle against semantically stealthy triggers that naturally blend into design specifications. In this paper, we hypothesize that under the requirements of both effectiveness and stealthiness, attackers are strongly biased toward embedding triggers in non-functional requirements (e.g., style modifiers, quality descriptors) rather than functional specifications that determine hardware behavior. Exploiting this insight, we propose Semantic Consensus Decoding (SCD), an inference-time passive defense with two key components: (1) functional requirement extraction that identifies essential requirements from user specifications, and (2) consensus decoding that adaptively fuses output distributions based on full user specifications and extracted functional requirements. When these distributions diverge significantly, SCD automatically suppresses suspicious components. Extensive experiments with three representative backdoor attacks demonstrate that SCD reduces average attack success rate from 89% to under 3% with negligible impact on generation quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Verilog\u4ee3\u7801\u751f\u6210\u4e2dLLM\u540e\u95e8\u653b\u51fb\u7684\u9632\u5fa1\u65b9\u6cd5SCD\uff0c\u901a\u8fc7\u529f\u80fd\u9700\u6c42\u63d0\u53d6\u548c\u5171\u8bc6\u89e3\u7801\uff0c\u5c06\u653b\u51fb\u6210\u529f\u7387\u4ece89%\u964d\u81f33%\u4ee5\u4e0b\u3002", "motivation": "\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u4f7f\u7528\u7684LLM\u5bb9\u6613\u53d7\u5230\u540e\u95e8\u653b\u51fb\uff0c\u653b\u51fb\u8005\u5728\u8bad\u7ec3\u65f6\u6ce8\u5165\u6076\u610f\u89e6\u53d1\u5668\uff0c\u5bfc\u81f4\u751f\u6210\u6613\u53d7\u653b\u51fb\u7684\u786c\u4ef6\u8bbe\u8ba1\u3002\u4e0e\u53ef\u4fee\u8865\u7684\u8f6f\u4ef6\u6f0f\u6d1e\u4e0d\u540c\uff0c\u786c\u4ef6\u6728\u9a6c\u4e00\u65e6\u5236\u9020\u5c31\u4e0d\u53ef\u9006\u8f6c\uff0c\u4fee\u590d\u6210\u672c\u6781\u9ad8\u6216\u4e0d\u53ef\u80fd\u3002\u73b0\u6709\u4e3b\u52a8\u9632\u5fa1\u9700\u8981\u8bbf\u95ee\u8bad\u7ec3\u6570\u636e\uff0c\u5bf9\u7b2c\u4e09\u65b9LLM\u7528\u6237\u4e0d\u5b9e\u7528\uff1b\u88ab\u52a8\u9632\u5fa1\u96be\u4ee5\u5e94\u5bf9\u8bed\u4e49\u4e0a\u9690\u853d\u7684\u89e6\u53d1\u5668\u3002", "method": "\u63d0\u51fa\u8bed\u4e49\u5171\u8bc6\u89e3\u7801(SCD)\uff0c\u8fd9\u662f\u4e00\u79cd\u63a8\u7406\u65f6\u88ab\u52a8\u9632\u5fa1\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u529f\u80fd\u9700\u6c42\u63d0\u53d6\uff1a\u4ece\u7528\u6237\u89c4\u8303\u4e2d\u8bc6\u522b\u57fa\u672c\u529f\u80fd\u9700\u6c42\uff1b2) \u5171\u8bc6\u89e3\u7801\uff1a\u57fa\u4e8e\u5b8c\u6574\u7528\u6237\u89c4\u8303\u548c\u63d0\u53d6\u7684\u529f\u80fd\u9700\u6c42\u81ea\u9002\u5e94\u878d\u5408\u8f93\u51fa\u5206\u5e03\u3002\u5f53\u8fd9\u4e9b\u5206\u5e03\u663e\u8457\u53d1\u6563\u65f6\uff0cSCD\u81ea\u52a8\u6291\u5236\u53ef\u7591\u7ec4\u4ef6\u3002", "result": "\u901a\u8fc7\u4e09\u79cd\u4ee3\u8868\u6027\u540e\u95e8\u653b\u51fb\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSCD\u5c06\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u4ece89%\u964d\u4f4e\u52303%\u4ee5\u4e0b\uff0c\u540c\u65f6\u5bf9\u751f\u6210\u8d28\u91cf\u5f71\u54cd\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "SCD\u901a\u8fc7\u5229\u7528\u653b\u51fb\u8005\u5728\u4fdd\u6301\u6709\u6548\u6027\u548c\u9690\u853d\u6027\u65f6\u504f\u5411\u5728\u975e\u529f\u80fd\u9700\u6c42\u4e2d\u5d4c\u5165\u89e6\u53d1\u5668\u7684\u7279\u70b9\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u63a8\u7406\u65f6\u88ab\u52a8\u9632\u5fa1\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u540e\u95e8\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2602.03975", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03975", "abs": "https://arxiv.org/abs/2602.03975", "authors": ["Shuhui Qu"], "title": "Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure", "comment": null, "summary": "Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant or unpromising intermediate hypotheses. We study reasoning under a \\emph{verification-cost-limited} setting and ask how verification effort should be allocated across intermediate states. We propose a state-level selective verification framework that combines (i) deterministic feasibility gating over a structured move interface, (ii) pre-verification ranking using a hybrid of learned state-distance and residual scoring, and (iii) adaptive allocation of verifier calls based on local uncertainty. Unlike solution-level best-of-$N$ or uniform intermediate verification, our method distributes verification where it is most informative. On the \\textsc{MATH} benchmark, our approach achieves higher accuracy than best-of-$N$, majority voting, and beam search while using 44\\% fewer verifier calls.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u72b6\u6001\u7ea7\u9009\u62e9\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u5728\u9a8c\u8bc1\u6210\u672c\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u4f18\u5316\u9a8c\u8bc1\u8d44\u6e90\u5206\u914d\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728MATH\u57fa\u51c6\u4e0a\u4f7f\u7528\u66f4\u5c11\u7684\u9a8c\u8bc1\u8c03\u7528\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u8d8a\u6765\u8d8a\u53d7\u5230\u6602\u8d35\u9a8c\u8bc1\u7684\u74f6\u9888\u9650\u5236\uff0c\u8bb8\u591a\u9a8c\u8bc1\u8c03\u7528\u88ab\u6d6a\u8d39\u5728\u5197\u4f59\u6216\u65e0\u524d\u666f\u7684\u4e2d\u95f4\u5047\u8bbe\u4e0a\uff0c\u9700\u8981\u5728\u9a8c\u8bc1\u6210\u672c\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u7814\u7a76\u5982\u4f55\u4f18\u5316\u9a8c\u8bc1\u8d44\u6e90\u7684\u5206\u914d\u3002", "method": "\u63d0\u51fa\u4e86\u72b6\u6001\u7ea7\u9009\u62e9\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u7ed3\u6784\u5316\u79fb\u52a8\u63a5\u53e3\u4e0a\u7684\u786e\u5b9a\u6027\u53ef\u884c\u6027\u95e8\u63a7\uff1b2) \u7ed3\u5408\u5b66\u4e60\u7684\u72b6\u6001\u8ddd\u79bb\u548c\u6b8b\u5dee\u5f97\u5206\u7684\u9884\u9a8c\u8bc1\u6392\u5e8f\uff1b3) \u57fa\u4e8e\u5c40\u90e8\u4e0d\u786e\u5b9a\u6027\u7684\u81ea\u9002\u5e94\u9a8c\u8bc1\u8c03\u7528\u5206\u914d\u3002", "result": "\u5728MATH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4best-of-N\u3001\u591a\u6570\u6295\u7968\u548c\u675f\u641c\u7d22\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u51cf\u5c11\u4e8644%\u7684\u9a8c\u8bc1\u8c03\u7528\u3002", "conclusion": "\u901a\u8fc7\u72b6\u6001\u7ea7\u9009\u62e9\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u9a8c\u8bc1\u6210\u672c\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u66f4\u6709\u6548\u5730\u5206\u914d\u9a8c\u8bc1\u8d44\u6e90\uff0c\u63d0\u9ad8\u63a8\u7406\u7cfb\u7edf\u7684\u6548\u7387\uff0c\u907f\u514d\u5c06\u9a8c\u8bc1\u8c03\u7528\u6d6a\u8d39\u5728\u5197\u4f59\u6216\u65e0\u524d\u666f\u7684\u4e2d\u95f4\u5047\u8bbe\u4e0a\u3002"}}
{"id": "2602.03978", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03978", "abs": "https://arxiv.org/abs/2602.03978", "authors": ["Zidi Xiong", "Shan Chen", "Himabindu Lakkaraju"], "title": "Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning", "comment": null, "summary": "As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal computation--can appear as a \"free gift\" during the early stages of Reinforcement Learning with Verifiable Rewards (RLVR). We make this observation concrete through a systematic evaluation across model families and training domains. Our results show that this effect is not universal: monitorability improvements are strongly data-dependent. In particular, we demonstrate the critical role of data diversity and instruction-following data during RLVR training. We further show that monitorability is orthogonal to capability--improvements in reasoning performance do not imply increased transparency. Through mechanistic analysis, we attribute monitorability gains primarily to response distribution sharpening (entropy reduction) and increased attention to the prompt, rather than stronger causal reliance on reasoning traces. We also reveal how monitorability dynamics vary with controlled training and evaluation difficulty. Together, these findings provide a holistic view of how monitorability emerges under RLVR, clarifying when gains are likely to occur and when they are not.", "AI": {"tldr": "RLVR\u8bad\u7ec3\u65e9\u671f\u53ef\u80fd\u5e26\u6765CoT\u53ef\u76d1\u63a7\u6027\u7684\"\u514d\u8d39\u63d0\u5347\"\uff0c\u4f46\u8fd9\u79cd\u6548\u679c\u5e76\u975e\u666e\u904d\u5b58\u5728\uff0c\u4e3b\u8981\u53d6\u51b3\u4e8e\u6570\u636e\u591a\u6837\u6027\u548c\u6307\u4ee4\u9075\u5faa\u6570\u636e\uff0c\u4e14\u53ef\u76d1\u63a7\u6027\u4e0e\u6a21\u578b\u80fd\u529b\u6b63\u4ea4\u3002", "motivation": "\u968f\u7740\u5927\u578b\u63a8\u7406\u6a21\u578b\u90e8\u7f72\u589e\u52a0\uff0c\u5ba1\u8ba1\u5176\u601d\u7ef4\u94fe\u8f68\u8ff9\u7684\u5b89\u5168\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u53d1\u73b0RLVR\u8bad\u7ec3\u65e9\u671f\u53ef\u80fd\u51fa\u73b0\u53ef\u76d1\u63a7\u6027\u7684\"\u514d\u8d39\u63d0\u5347\"\uff0c\u4f46\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u79cd\u6548\u5e94\u7684\u666e\u904d\u6027\u548c\u673a\u5236\u3002", "method": "\u901a\u8fc7\u8de8\u6a21\u578b\u5bb6\u65cf\u548c\u8bad\u7ec3\u9886\u57df\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5206\u6790\u6570\u636e\u591a\u6837\u6027\u3001\u6307\u4ee4\u9075\u5faa\u6570\u636e\u7684\u4f5c\u7528\uff0c\u8fdb\u884c\u673a\u5236\u5206\u6790\uff08\u54cd\u5e94\u5206\u5e03\u9510\u5316\u3001\u6ce8\u610f\u529b\u6a21\u5f0f\uff09\uff0c\u5e76\u63a7\u5236\u8bad\u7ec3\u548c\u8bc4\u4f30\u96be\u5ea6\u6765\u7814\u7a76\u53ef\u76d1\u63a7\u6027\u52a8\u6001\u3002", "result": "\u53ef\u76d1\u63a7\u6027\u63d0\u5347\u5f3a\u70c8\u4f9d\u8d56\u4e8e\u6570\u636e\uff0c\u7279\u522b\u662f\u6570\u636e\u591a\u6837\u6027\u548c\u6307\u4ee4\u9075\u5faa\u6570\u636e\uff1b\u53ef\u76d1\u63a7\u6027\u4e0e\u63a8\u7406\u80fd\u529b\u6b63\u4ea4\uff1b\u673a\u5236\u4e0a\u4e3b\u8981\u6e90\u4e8e\u54cd\u5e94\u5206\u5e03\u9510\u5316\uff08\u71b5\u51cf\u5c11\uff09\u548c\u63d0\u793a\u6ce8\u610f\u529b\u589e\u52a0\uff0c\u800c\u975e\u5bf9\u63a8\u7406\u8f68\u8ff9\u7684\u56e0\u679c\u4f9d\u8d56\u589e\u5f3a\u3002", "conclusion": "RLVR\u4e0b\u7684\u53ef\u76d1\u63a7\u6027\u63d0\u5347\u4e0d\u662f\u666e\u904d\u73b0\u8c61\uff0c\u9700\u8981\u7279\u5b9a\u6570\u636e\u6761\u4ef6\uff0c\u4e14\u4e0e\u6a21\u578b\u80fd\u529b\u65e0\u5173\u3002\u8fd9\u4e3a\u7406\u89e3\u53ef\u76d1\u63a7\u6027\u4f55\u65f6\u51fa\u73b0\u63d0\u4f9b\u4e86\u6574\u4f53\u89c6\u89d2\uff0c\u6f84\u6e05\u4e86\u63d0\u5347\u53ef\u80fd\u53d1\u751f\u548c\u4e0d\u53ef\u80fd\u53d1\u751f\u7684\u60c5\u51b5\u3002"}}
{"id": "2602.04296", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04296", "abs": "https://arxiv.org/abs/2602.04296", "authors": ["Wenjun Peng", "Xinyu Wang", "Qi Wu"], "title": "ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas", "comment": "ICSE2026", "summary": "Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-generated agents within diverse, competitive game environments. Unlike existing approaches, ProxyWar evaluates not only functional correctness but also the operational characteristics of generated programs, combining automated testing, iterative code repair, and multi-agent tournaments to provide a holistic view of program behavior. Applied to a range of state-of-the-art coders and games, our approach uncovers notable discrepancies between benchmark scores and actual performance in dynamic settings, revealing overlooked limitations and opportunities for improvement. These findings highlight the need for richer, competition-based evaluation of code generation. Looking forward, ProxyWar lays a foundation for research into LLM-driven algorithm discovery, adaptive problem solving, and the study of practical efficiency and robustness, including the potential for models to outperform hand-crafted agents. The project is available at https://github.com/xinke-wang/ProxyWar.", "AI": {"tldr": "ProxyWar\u662f\u4e00\u4e2a\u901a\u8fc7\u5c06LLM\u751f\u6210\u7684\u667a\u80fd\u4f53\u5d4c\u5165\u7ade\u4e89\u6027\u6e38\u620f\u73af\u5883\u6765\u7cfb\u7edf\u8bc4\u4f30\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u6846\u67b6\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86\u57fa\u51c6\u5206\u6570\u4e0e\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u9645\u6027\u80fd\u7684\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u548c\u7b80\u5355\u6307\u6807\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u4ee3\u7801\u5728\u5b9e\u9645\u52a8\u6001\u73af\u5883\u4e2d\u7684\u771f\u5b9e\u6548\u679c\uff0c\u9700\u8981\u66f4\u4e30\u5bcc\u3001\u57fa\u4e8e\u7ade\u4e89\u73af\u5883\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faProxyWar\u6846\u67b6\uff0c\u5c06LLM\u751f\u6210\u7684\u667a\u80fd\u4f53\u5d4c\u5165\u591a\u6837\u5316\u7684\u7ade\u4e89\u6027\u6e38\u620f\u73af\u5883\u4e2d\uff0c\u7ed3\u5408\u81ea\u52a8\u5316\u6d4b\u8bd5\u3001\u8fed\u4ee3\u4ee3\u7801\u4fee\u590d\u548c\u591a\u667a\u80fd\u4f53\u9526\u6807\u8d5b\uff0c\u5168\u9762\u8bc4\u4f30\u7a0b\u5e8f\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u64cd\u4f5c\u7279\u6027\u3002", "result": "\u5e94\u7528\u4e8e\u591a\u79cd\u5148\u8fdb\u4ee3\u7801\u751f\u6210\u6a21\u578b\u548c\u6e38\u620f\u73af\u5883\u540e\uff0c\u53d1\u73b0\u57fa\u51c6\u6d4b\u8bd5\u5206\u6570\u4e0e\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u6027\u80fd\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5ffd\u89c6\u7684\u5c40\u9650\u6027\u548c\u6539\u8fdb\u673a\u4f1a\u3002", "conclusion": "ProxyWar\u4e3a\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u7ade\u4e89\u6027\u8bc4\u4f30\u57fa\u7840\uff0c\u4e3aLLM\u9a71\u52a8\u7684\u7b97\u6cd5\u53d1\u73b0\u3001\u81ea\u9002\u5e94\u95ee\u9898\u89e3\u51b3\u4ee5\u53ca\u5b9e\u9645\u6548\u7387\u548c\u9c81\u68d2\u6027\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u8d85\u8d8a\u624b\u5de5\u7f16\u5199\u667a\u80fd\u4f53\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.04341", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04341", "abs": "https://arxiv.org/abs/2602.04341", "authors": ["Tobias B\u00f6hm", "Jens Guan Su Tien", "Mohini Nonnenmann", "Tom Schoonbaert", "Bart Carpels", "Andreas Biesdorf"], "title": "Model-Driven Legacy System Modernization at Scale", "comment": "Accepted for publication at the 1st Workshop on Code Translation, Transformation, and Modernization (ReCode'26), co-located with ICSE 2026", "summary": "This experience report presents a model-driven approach to legacy system modernization that inserts an enriched, technology-agnostic intermediate model between the legacy codebase and the modern target platform, and reports on its application and evaluation. The four-stage process of analysis, enrichment, synthesis, and transition systematically extracts, abstracts, and transforms system artifacts. We apply our approach to a large industrial application built on legacy versions of the .NET Framework and ASP.NET MVC and show that core user interface components and page structures can be migrated semi-automatically to a modern web stack while preserving functional behavior and essential non-functional qualities. By consolidating architectural knowledge into explicit model representations, the resulting codebase exhibits higher maintainability and extensibility, thereby improving developer experience. Although automation is effective for standard patterns, migration of bespoke layout composites remains challenging and requires targeted manual adaptation. Our contributions are: (i) an end-to-end model-driven process, (ii) an enriched intermediate model that captures structure, dependencies, and semantic metadata, (iii) transformation rules that preserve functional behavior and essential non-functional qualities, and (iv) application and evaluation of the approach in an industrial setting. Overall, model-based abstractions reduce risk and effort while supporting scalable, traceable modernization of legacy applications. Our approach generalizes to comparable modernization contexts and promotes reuse of migration patterns.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u9a71\u52a8\u7684\u9057\u7559\u7cfb\u7edf\u73b0\u4ee3\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u6280\u672f\u65e0\u5173\u7684\u4e2d\u95f4\u6a21\u578b\uff0c\u5b9e\u73b0\u4ece\u4f20\u7edf.NET/ASP.NET MVC\u5230\u73b0\u4ee3Web\u6280\u672f\u6808\u7684\u534a\u81ea\u52a8\u8fc1\u79fb\u3002", "motivation": "\u89e3\u51b3\u9057\u7559\u7cfb\u7edf\u73b0\u4ee3\u5316\u8fc7\u7a0b\u4e2d\u7684\u98ce\u9669\u9ad8\u3001\u5de5\u4f5c\u91cf\u5927\u3001\u96be\u4ee5\u89c4\u6a21\u5316\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4f20\u7edf.NET Framework\u548cASP.NET MVC\u5e94\u7528\u5411\u73b0\u4ee3Web\u6280\u672f\u6808\u8fc1\u79fb\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u56db\u9636\u6bb5\u6a21\u578b\u9a71\u52a8\u65b9\u6cd5\uff1a\u5206\u6790\u3001\u4e30\u5bcc\u3001\u5408\u6210\u3001\u8fc7\u6e21\u3002\u521b\u5efa\u6280\u672f\u65e0\u5173\u7684\u4e2d\u95f4\u6a21\u578b\u6765\u6355\u83b7\u7cfb\u7edf\u7ed3\u6784\u3001\u4f9d\u8d56\u5173\u7cfb\u548c\u8bed\u4e49\u5143\u6570\u636e\uff0c\u901a\u8fc7\u8f6c\u6362\u89c4\u5219\u5b9e\u73b0\u534a\u81ea\u52a8\u8fc1\u79fb\u3002", "result": "\u6210\u529f\u5c06\u5927\u578b\u5de5\u4e1a\u5e94\u7528\u4ece\u4f20\u7edf.NET/ASP.NET MVC\u8fc1\u79fb\u5230\u73b0\u4ee3Web\u6280\u672f\u6808\uff0c\u6838\u5fc3UI\u7ec4\u4ef6\u548c\u9875\u9762\u7ed3\u6784\u5b9e\u73b0\u534a\u81ea\u52a8\u8fc1\u79fb\uff0c\u4fdd\u6301\u4e86\u529f\u80fd\u884c\u4e3a\u548c\u5173\u952e\u975e\u529f\u80fd\u6027\u8d28\u91cf\uff0c\u63d0\u9ad8\u4e86\u4ee3\u7801\u53ef\u7ef4\u62a4\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u57fa\u4e8e\u6a21\u578b\u7684\u62bd\u8c61\u65b9\u6cd5\u964d\u4f4e\u4e86\u73b0\u4ee3\u5316\u98ce\u9669\u548c\u52aa\u529b\uff0c\u652f\u6301\u53ef\u6269\u5c55\u3001\u53ef\u8ffd\u6eaf\u7684\u9057\u7559\u5e94\u7528\u73b0\u4ee3\u5316\u3002\u867d\u7136\u6807\u51c6\u6a21\u5f0f\u81ea\u52a8\u5316\u6548\u679c\u826f\u597d\uff0c\u4f46\u5b9a\u5236\u5e03\u5c40\u7ec4\u5408\u4ecd\u9700\u624b\u52a8\u9002\u914d\u3002\u8be5\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u7c7b\u4f3c\u7684\u73b0\u4ee3\u5316\u573a\u666f\u3002"}}
{"id": "2602.04028", "categories": ["cs.AI", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04028", "abs": "https://arxiv.org/abs/2602.04028", "authors": ["Leila Amgoud", "Martin Cooper"], "title": "Axiomatic Foundations of Counterfactual Explanations", "comment": null, "summary": "Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions could be altered. Despite the growing literature, most existing explainers focus on a single type of counterfactual and are restricted to local explanations, focusing on individual instances. There has been no systematic study of alternative counterfactual types, nor of global counterfactuals that shed light on a system's overall reasoning process.\n  This paper addresses the two gaps by introducing an axiomatic framework built on a set of desirable properties for counterfactual explainers. It proves impossibility theorems showing that no single explainer can satisfy certain axiom combinations simultaneously, and fully characterizes all compatible sets. Representation theorems then establish five one-to-one correspondences between specific subsets of axioms and the families of explainers that satisfy them. Each family gives rise to a distinct type of counterfactual explanation, uncovering five fundamentally different types of counterfactuals. Some of these correspond to local explanations, while others capture global explanations. Finally, the framework situates existing explainers within this taxonomy, formally characterizes their behavior, and analyzes the computational complexity of generating such explanations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684axiomatic\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\uff0c\u8bc6\u522b\u4e86\u4e94\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u5e76\u5c06\u73b0\u6709\u89e3\u91ca\u5668\u7eb3\u5165\u5206\u7c7b\u4f53\u7cfb\u3002", "motivation": "\u5f53\u524d\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7814\u7a76\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u5927\u591a\u6570\u89e3\u91ca\u5668\u53ea\u5173\u6ce8\u5355\u4e00\u7c7b\u578b\u7684\u53cd\u4e8b\u5b9e\uff1b2) \u4e3b\u8981\u5c40\u9650\u4e8e\u5c40\u90e8\u89e3\u91ca\uff0c\u7f3a\u4e4f\u5bf9\u7cfb\u7edf\u6574\u4f53\u63a8\u7406\u8fc7\u7a0b\u7684\u5168\u5c40\u89e3\u91ca\u3002\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u4e0d\u540c\u7c7b\u578b\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u53ca\u5176\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5efa\u7acb\u57fa\u4e8e\u4e00\u7ec4\u7406\u60f3\u5c5e\u6027\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5668\u516c\u7406\u6846\u67b6\uff0c\u8bc1\u660e\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\uff0c\u901a\u8fc7\u8868\u793a\u5b9a\u7406\u5efa\u7acb\u516c\u7406\u5b50\u96c6\u4e0e\u89e3\u91ca\u5668\u5bb6\u65cf\u4e4b\u95f4\u7684\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\uff0c\u8bc6\u522b\u4e94\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002", "result": "\u8bc1\u660e\u4e86\u6ca1\u6709\u5355\u4e00\u89e3\u91ca\u5668\u80fd\u540c\u65f6\u6ee1\u8db3\u67d0\u4e9b\u516c\u7406\u7ec4\u5408\uff0c\u8bc6\u522b\u4e86\u4e94\u79cd\u6839\u672c\u4e0d\u540c\u7c7b\u578b\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08\u5305\u62ec\u5c40\u90e8\u548c\u5168\u5c40\u89e3\u91ca\uff09\uff0c\u5c06\u73b0\u6709\u89e3\u91ca\u5668\u7eb3\u5165\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u5206\u6790\u4e86\u751f\u6210\u6b64\u7c7b\u89e3\u91ca\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53cd\u4e8b\u5b9e\u89e3\u91ca\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u591a\u6837\u6027\uff0c\u533a\u5206\u4e86\u5c40\u90e8\u548c\u5168\u5c40\u89e3\u91ca\u7c7b\u578b\uff0c\u4e3a\u672a\u6765\u89e3\u91ca\u5668\u7684\u8bbe\u8ba1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2602.04358", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04358", "abs": "https://arxiv.org/abs/2602.04358", "authors": ["Stefan Otten", "Philipp Reis", "Philipp Rigoll", "Joshua Ransiek", "Tobias Sch\u00fcrmann", "Jacob Langner", "Eric Sax"], "title": "Generative AI in Systems Engineering: A Framework for Risk Assessment of Large Language Models", "comment": "Accepted at IEEE SysCon 2026", "summary": "The increasing use of Large Language Models (LLMs) offers significant opportunities across the engineering lifecycle, including requirements engineering, software development, process optimization, and decision support. Despite this potential, organizations face substantial challenges in assessing the risks associated with LLM use, resulting in inconsistent integration, unknown failure modes, and limited scalability. This paper introduces the LLM Risk Assessment Framework (LRF), a structured approach for evaluating the application of LLMs within Systems Engineering (SE) environments. The framework classifies LLM-based applications along two fundamental dimensions: autonomy, ranging from supportive assistance to fully automated decision making, and impact, reflecting the potential severity of incorrect or misleading model outputs on engineering processes and system elements. By combining these dimensions, the LRF enables consistent determination of corresponding risk levels across the development lifecycle. The resulting classification supports organizations in identifying appropriate validation strategies, levels of human oversight, and required countermeasures to ensure safe and transparent deployment. The framework thereby helps align the rapid evolution of AI technologies with established engineering principles of reliability, traceability, and controlled process integration. Overall, the LRF provides a basis for risk-aware adoption of LLMs in complex engineering environments and represents a first step toward standardized AI assurance practices in systems engineering.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86LLM\u98ce\u9669\u8bc4\u4f30\u6846\u67b6(LRF)\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7cfb\u7edf\u5de5\u7a0b\u73af\u5883\u4e2d\u7684\u5e94\u7528\u98ce\u9669\uff0c\u901a\u8fc7\u81ea\u4e3b\u6027\u548c\u5f71\u54cd\u4e24\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u5206\u7c7b\uff0c\u5e2e\u52a9\u7ec4\u7ec7\u786e\u5b9a\u9002\u5f53\u7684\u9a8c\u8bc1\u7b56\u7565\u548c\u98ce\u9669\u63a7\u5236\u63aa\u65bd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u7a0b\u751f\u547d\u5468\u671f\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u7ec4\u7ec7\u5728\u8bc4\u4f30\u76f8\u5173\u98ce\u9669\u65f6\u9762\u4e34\u6311\u6218\uff0c\u5bfc\u81f4\u96c6\u6210\u4e0d\u4e00\u81f4\u3001\u6545\u969c\u6a21\u5f0f\u672a\u77e5\u548c\u53ef\u6269\u5c55\u6027\u6709\u9650\u7b49\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u7ed3\u6784\u5316\u65b9\u6cd5\u6765\u8bc4\u4f30LLM\u5728\u7cfb\u7edf\u5de5\u7a0b\u73af\u5883\u4e2d\u7684\u5e94\u7528\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86LLM\u98ce\u9669\u8bc4\u4f30\u6846\u67b6(LRF)\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u4e24\u4e2a\u57fa\u672c\u7ef4\u5ea6\u5bf9LLM\u5e94\u7528\u8fdb\u884c\u5206\u7c7b\uff1a1) \u81ea\u4e3b\u6027\uff08\u4ece\u652f\u6301\u6027\u8f85\u52a9\u5230\u5b8c\u5168\u81ea\u52a8\u5316\u51b3\u7b56\uff09\uff0c2) \u5f71\u54cd\uff08\u6a21\u578b\u9519\u8bef\u6216\u8bef\u5bfc\u6027\u8f93\u51fa\u5bf9\u5de5\u7a0b\u8fc7\u7a0b\u548c\u7cfb\u7edf\u5143\u7d20\u7684\u6f5c\u5728\u4e25\u91cd\u6027\uff09\u3002\u901a\u8fc7\u8fd9\u4e24\u4e2a\u7ef4\u5ea6\u7684\u7ec4\u5408\uff0c\u5728\u6574\u4e2a\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u4e00\u81f4\u5730\u786e\u5b9a\u76f8\u5e94\u7684\u98ce\u9669\u6c34\u5e73\u3002", "result": "LRF\u6846\u67b6\u80fd\u591f\u652f\u6301\u7ec4\u7ec7\u8bc6\u522b\u9002\u5f53\u7684\u9a8c\u8bc1\u7b56\u7565\u3001\u4eba\u5de5\u76d1\u7763\u6c34\u5e73\u548c\u5fc5\u8981\u7684\u5e94\u5bf9\u63aa\u65bd\uff0c\u786e\u4fdd\u5b89\u5168\u900f\u660e\u7684\u90e8\u7f72\u3002\u8be5\u5206\u7c7b\u6709\u52a9\u4e8e\u5c06AI\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\u4e0e\u53ef\u9760\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u53d7\u63a7\u8fc7\u7a0b\u96c6\u6210\u7b49\u65e2\u5b9a\u5de5\u7a0b\u539f\u5219\u76f8\u7ed3\u5408\u3002", "conclusion": "LRF\u4e3a\u590d\u6742\u5de5\u7a0b\u73af\u5883\u4e2d\u98ce\u9669\u611f\u77e5\u7684LLM\u91c7\u7528\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4ee3\u8868\u4e86\u7cfb\u7edf\u5de5\u7a0b\u4e2d\u6807\u51c6\u5316AI\u4fdd\u8bc1\u5b9e\u8df5\u7684\u7b2c\u4e00\u6b65\u3002\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u7ec4\u7ec7\u5728\u5feb\u901f\u53d1\u5c55\u7684AI\u6280\u672f\u4e0e\u5de5\u7a0b\u53ef\u9760\u6027\u539f\u5219\u4e4b\u95f4\u5efa\u7acb\u5e73\u8861\u3002"}}
{"id": "2602.04089", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04089", "abs": "https://arxiv.org/abs/2602.04089", "authors": ["Xiaofeng Lin", "Sirou Zhu", "Yilei Chen", "Mingyu Chen", "Hejian Sang", "Ioannis Paschalidis", "Zhipeng Wang", "Aldo Pacchiano", "Xuezhou Zhang"], "title": "Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL", "comment": null, "summary": "Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction, feedback is delayed, and effective behavior requires balancing information collection and exploitation over time. While in-context learning enables adaptation without weight updates, existing LLMs often struggle to reliably leverage in-context interaction experience in such settings. In this work, we show that this limitation can be addressed through training. We introduce ORBIT, a multi-task, multi-episode meta-reinforcement learning framework that trains LLMs to learn from interaction in context. After meta-training, a relatively small open-source model (Qwen3-14B) demonstrates substantially improved in-context online learning on entirely unseen environments, matching the performance of GPT-5.2 and outperforming standard RL fine-tuning by a large margin. Scaling experiments further reveal consistent gains with model size, suggesting significant headroom for learn-at-inference-time decision-making agents. Code reproducing the results in the paper can be found at https://github.com/XiaofengLin7/ORBIT.", "AI": {"tldr": "ORBIT\u6846\u67b6\u901a\u8fc7\u5143\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLMs\u5728\u4e0a\u4e0b\u6587\u4e2d\u4ece\u4ea4\u4e92\u4e2d\u5b66\u4e60\uff0c\u4f7f\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u5728\u672a\u89c1\u73af\u5883\u4e2d\u8fbe\u5230GPT-5.2\u6c34\u5e73\uff0c\u663e\u8457\u4f18\u4e8e\u6807\u51c6RL\u5fae\u8c03", "motivation": "\u5f53\u524dLLMs\u5728\u9700\u8981\u5728\u7ebf\u4ea4\u4e92\u7684\u51b3\u7b56\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u53ef\u9760\u5229\u7528\u4e0a\u4e0b\u6587\u4ea4\u4e92\u7ecf\u9a8c\uff0c\u800c\u8bb8\u591a\u73b0\u5b9e\u4e16\u754c\u51b3\u7b56\u4efb\u52a1\u9700\u8981\u5e73\u8861\u4fe1\u606f\u6536\u96c6\u548c\u5229\u7528", "method": "\u63d0\u51faORBIT\u6846\u67b6\uff1a\u591a\u4efb\u52a1\u3001\u591a\u56de\u5408\u7684\u5143\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8bad\u7ec3LLMs\u5728\u4e0a\u4e0b\u6587\u4e2d\u4ece\u4ea4\u4e92\u4e2d\u5b66\u4e60\uff0c\u901a\u8fc7\u8bad\u7ec3\u89e3\u51b3\u73b0\u6709LLMs\u7684\u5c40\u9650\u6027", "result": "\u7ecf\u8fc7\u5143\u8bad\u7ec3\u540e\uff0c\u76f8\u5bf9\u8f83\u5c0f\u7684\u5f00\u6e90\u6a21\u578b(Qwen3-14B)\u5728\u5b8c\u5168\u672a\u89c1\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\u7684\u4e0a\u4e0b\u6587\u5728\u7ebf\u5b66\u4e60\u80fd\u529b\uff0c\u5339\u914dGPT-5.2\u6027\u80fd\uff0c\u5927\u5e45\u4f18\u4e8e\u6807\u51c6RL\u5fae\u8c03", "conclusion": "\u901a\u8fc7\u8bad\u7ec3\u53ef\u4ee5\u89e3\u51b3LLMs\u5728\u5728\u7ebf\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0cORBIT\u6846\u67b6\u5c55\u793a\u4e86\u5728\u63a8\u7406\u65f6\u5b66\u4e60\u51b3\u7b56\u667a\u80fd\u4f53\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u5b9e\u9a8c\u663e\u793a\u6301\u7eed\u589e\u76ca"}}
{"id": "2602.04445", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04445", "abs": "https://arxiv.org/abs/2602.04445", "authors": ["Rudra Dhar", "Karthik Vaidhyanathan", "Vasudeva Varma"], "title": "AgenticAKM : Enroute to Agentic Architecture Knowledge Management", "comment": null, "summary": "Architecture Knowledge Management (AKM) is crucial for maintaining current and comprehensive software Architecture Knowledge (AK) in a software project. However AKM is often a laborious process and is not adopted by developers and architects. While LLMs present an opportunity for automation, a naive, single-prompt approach is often ineffective, constrained by context limits and an inability to grasp the distributed nature of architectural knowledge. To address these limitations, we propose an Agentic approach for AKM, AgenticAKM, where the complex problem of architecture recovery and documentation is decomposed into manageable sub-tasks. Specialized agents for architecture Extraction, Retrieval, Generation, and Validation collaborate in a structured workflow to generate AK. To validate we made an initial instantiation of our approach to generate Architecture Decision Records (ADRs) from code repositories. We validated our approach through a user study with 29 repositories. The results demonstrate that our agentic approach generates better ADRs, and is a promising and practical approach for automating AKM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAgenticAKM\uff0c\u4e00\u79cd\u57fa\u4e8e\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u67b6\u6784\u77e5\u8bc6\u7ba1\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u89e3\u67b6\u6784\u6062\u590d\u548c\u6587\u6863\u5316\u4e3a\u53ef\u7ba1\u7406\u7684\u5b50\u4efb\u52a1\uff0c\u81ea\u52a8\u751f\u6210\u67b6\u6784\u51b3\u7b56\u8bb0\u5f55\uff08ADRs\uff09\u3002", "motivation": "\u67b6\u6784\u77e5\u8bc6\u7ba1\u7406\uff08AKM\uff09\u5bf9\u4e8e\u8f6f\u4ef6\u9879\u76ee\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u901a\u5e38\u662f\u4e00\u4e2a\u7e41\u7410\u7684\u8fc7\u7a0b\uff0c\u5f00\u53d1\u8005\u548c\u67b6\u6784\u5e08\u5f80\u5f80\u4e0d\u91c7\u7528\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u673a\u4f1a\uff0c\u4f46\u7b80\u5355\u7684\u5355\u63d0\u793a\u65b9\u6cd5\u53d7\u9650\u4e8e\u4e0a\u4e0b\u6587\u957f\u5ea6\u9650\u5236\uff0c\u4e14\u96be\u4ee5\u7406\u89e3\u67b6\u6784\u77e5\u8bc6\u7684\u5206\u5e03\u5f0f\u7279\u6027\u3002", "method": "\u63d0\u51faAgenticAKM\u65b9\u6cd5\uff0c\u5c06\u590d\u6742\u7684\u67b6\u6784\u6062\u590d\u548c\u6587\u6863\u5316\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u5b50\u4efb\u52a1\u3002\u8bbe\u8ba1\u4e13\u95e8\u7684\u667a\u80fd\u4f53\uff08\u67b6\u6784\u63d0\u53d6\u3001\u68c0\u7d22\u3001\u751f\u6210\u548c\u9a8c\u8bc1\uff09\u5728\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u534f\u4f5c\u751f\u6210\u67b6\u6784\u77e5\u8bc6\u3002\u5177\u4f53\u5b9e\u4f8b\u5316\u4e3a\u4ece\u4ee3\u7801\u4ed3\u5e93\u81ea\u52a8\u751f\u6210\u67b6\u6784\u51b3\u7b56\u8bb0\u5f55\uff08ADRs\uff09\u3002", "result": "\u901a\u8fc7\u5bf929\u4e2a\u4ed3\u5e93\u8fdb\u884c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u667a\u80fd\u4f53\u65b9\u6cd5\u80fd\u751f\u6210\u66f4\u597d\u7684ADRs\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u67b6\u6784\u77e5\u8bc6\u7ba1\u7406\u65b9\u9762\u5177\u6709\u524d\u666f\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "AgenticAKM\u65b9\u6cd5\u901a\u8fc7\u667a\u80fd\u4f53\u534f\u4f5c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfAKM\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u81ea\u52a8\u5316\u67b6\u6784\u77e5\u8bc6\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04101", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04101", "abs": "https://arxiv.org/abs/2602.04101", "authors": ["Harsha Vardhan Khurdula", "Vineet Agarwal", "Yoeven D Khemlani"], "title": "Interfaze: The Future of AI is built on Task-Specific Small Models", "comment": "8 pages, 1 figure", "summary": "We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OCR involving complex PDFs, charts and diagrams, and multilingual ASR with (ii) a context-construction layer that crawls, indexes, and parses external sources (web pages, code, PDFs) into compact structured state, and (iii) an action layer that can browse, retrieve, execute code in a sandbox, and drive a headless browser for dynamic web pages. A thin controller sits on top of this stack and exposes a single, OpenAI-style endpoint: it decides which small models and actions to run and always forwards the distilled context to a user-selected LLM that produces the final response.\n  On this architecture, Interfaze-Beta achieves 83.6% on MMLU-Pro, 91.4% on MMLU, 81.3% on GPQA-Diamond, 57.8% on LiveCodeBench v5, and 90.0% on AIME-2025, along with strong multimodal scores on MMMU (val) (77.3%), AI2D (91.5%), ChartQA (90.9%), and Common Voice v16 (90.8%). We show that most queries are handled primarily by the small-model and tool stack, with the large LLM operating only on distilled context, yielding competitive accuracy while shifting the bulk of computation away from the most expensive and monolithic models.", "AI": {"tldr": "Interfaze\u662f\u4e00\u4e2a\u5c06LLM\u5e94\u7528\u89c6\u4e3a\u4e0a\u4e0b\u6587\u6784\u5efa\u4e0e\u6267\u884c\u95ee\u9898\u7684\u7cfb\u7edf\uff0c\u800c\u975e\u4f9d\u8d56\u5355\u4e00\u6a21\u578b\u3002\u5b83\u901a\u8fc7\u5f02\u6784DNN\u5806\u6808\u3001\u4e0a\u4e0b\u6587\u6784\u5efa\u5c42\u548c\u52a8\u4f5c\u5c42\u5904\u7406\u590d\u6742\u4efb\u52a1\uff0c\u4ec5\u5c06\u63d0\u70bc\u540e\u7684\u4e0a\u4e0b\u6587\u4f20\u9012\u7ed9\u7528\u6237\u9009\u62e9\u7684LLM\u751f\u6210\u6700\u7ec8\u54cd\u5e94\u3002", "motivation": "\u73b0\u4ee3LLM\u5e94\u7528\u4e0d\u5e94\u4ec5\u4f9d\u8d56\u5355\u4e00\u5927\u578b\u6a21\u578b\uff0c\u800c\u5e94\u901a\u8fc7\u6784\u5efa\u548c\u64cd\u4f5c\u4e0a\u4e0b\u6587\u6765\u89e3\u51b3\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u5355\u4e00transformer\u5904\u7406\u6240\u6709\u4efb\u52a1\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u5c06\u8ba1\u7b97\u8d1f\u62c5\u4ece\u6602\u8d35\u7684\u5927\u578b\u6a21\u578b\u8f6c\u79fb\u5230\u5c0f\u578b\u6a21\u578b\u548c\u5de5\u5177\u6808\u4e0a\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1) \u5f02\u6784DNN\u5806\u6808\u914d\u5408\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u611f\u77e5\u6a21\u5757\uff0c\u5904\u7406\u590d\u6742PDF\u3001\u56fe\u8868\u3001\u591a\u8bed\u8a00ASR\u7b49\uff1b(2) \u4e0a\u4e0b\u6587\u6784\u5efa\u5c42\u722c\u53d6\u3001\u7d22\u5f15\u3001\u89e3\u6790\u5916\u90e8\u8d44\u6e90\u4e3a\u7ed3\u6784\u5316\u72b6\u6001\uff1b(3) \u52a8\u4f5c\u5c42\u652f\u6301\u6d4f\u89c8\u3001\u68c0\u7d22\u3001\u6c99\u7bb1\u4ee3\u7801\u6267\u884c\u548c\u9a71\u52a8\u65e0\u5934\u6d4f\u89c8\u5668\u3002\u9876\u5c42\u63a7\u5236\u5668\u51b3\u5b9a\u8fd0\u884c\u54ea\u4e9b\u5c0f\u578b\u6a21\u578b\u548c\u52a8\u4f5c\uff0c\u5e76\u5c06\u63d0\u70bc\u7684\u4e0a\u4e0b\u6587\u4f20\u9012\u7ed9\u7528\u6237\u9009\u62e9\u7684LLM\u3002", "result": "Interfaze-Beta\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff1aMMLU-Pro 83.6%\u3001MMLU 91.4%\u3001GPQA-Diamond 81.3%\u3001LiveCodeBench v5 57.8%\u3001AIME-2025 90.0%\u3002\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\uff1aMMMU(val) 77.3%\u3001AI2D 91.5%\u3001ChartQA 90.9%\u3001Common Voice v16 90.8%\u3002\u5927\u591a\u6570\u67e5\u8be2\u4e3b\u8981\u7531\u5c0f\u578b\u6a21\u578b\u548c\u5de5\u5177\u6808\u5904\u7406\uff0c\u5927\u578bLLM\u4ec5\u64cd\u4f5c\u63d0\u70bc\u540e\u7684\u4e0a\u4e0b\u6587\u3002", "conclusion": "Interfaze\u7cfb\u7edf\u8bc1\u660e\u4e86\u901a\u8fc7\u5c06LLM\u5e94\u7528\u91cd\u6784\u4e3a\u4e0a\u4e0b\u6587\u6784\u5efa\u548c\u6267\u884c\u95ee\u9898\uff0c\u7ed3\u5408\u5c0f\u578b\u6a21\u578b\u548c\u5de5\u5177\u6808\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u5c06\u4e3b\u8981\u8ba1\u7b97\u4ece\u6602\u8d35\u7684\u5927\u578b\u6a21\u578b\u8f6c\u79fb\u51fa\u53bb\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u6a21\u5757\u5316\u7684AI\u7cfb\u7edf\u67b6\u6784\u3002"}}
{"id": "2602.04449", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04449", "abs": "https://arxiv.org/abs/2602.04449", "authors": ["Matias Martinez", "Xavier Franch"], "title": "What's in a Benchmark? The Case of SWE-Bench in Automated Program Repair", "comment": "Accepted in 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE-SEIP'26). https://doi.org/10.1145/3786583.3786904", "summary": "The rapid progress in Automated Program Repair (APR) has been fueled by advances in AI, particularly large language models (LLMs) and agent-based systems. SWE-Bench is a benchmark designed to evaluate repair systems using real issues mined from popular open-source Python repositories. Its public leaderboards-SWE-Bench Lite and Verified-have become central platforms for tracking progress and comparing solutions. In this paper, we present the first comprehensive study of these two leaderboards, examining who is submitting solutions, the products behind the submissions, the LLMs employed, and the openness of the approaches. We analyze 79 entries submitted to Lite leaderboard and 133 to Verified. Our results show that most entries on both leaderboards originate from industry, particularly small companies and large publicly traded companies. These submissions often achieve top results, although academic contributions-typically open source-also remain competitive. We also find a clear dominance of proprietary LLMs, especially Claude family, with state-of-the-art results on both leaderboards currently achieved by Claude 4 Sonnet. These findings offer insights into the SWE-Bench ecosystem that can guide greater transparency and diversity in future benchmark-driven research.", "AI": {"tldr": "\u5bf9SWE-Bench\u4e24\u4e2a\u6392\u884c\u699c\uff08Lite\u548cVerified\uff09\u7684\u9996\u6b21\u7efc\u5408\u5206\u6790\uff0c\u7814\u7a76\u63d0\u4ea4\u8005\u8eab\u4efd\u3001\u4f7f\u7528\u4ea7\u54c1\u3001LLM\u6a21\u578b\u548c\u65b9\u6848\u5f00\u653e\u6027\uff0c\u53d1\u73b0\u884c\u4e1a\u4e3b\u5bfc\u3001Claude\u6a21\u578b\u5360\u4f18\u7684\u73b0\u72b6", "motivation": "\u968f\u7740AI\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\u548c\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u9886\u57df\u8fdb\u5c55\u8fc5\u901f\u3002SWE-Bench\u4f5c\u4e3a\u8bc4\u4f30\u4fee\u590d\u7cfb\u7edf\u7684\u57fa\u51c6\uff0c\u5176\u516c\u5f00\u6392\u884c\u699c\u5df2\u6210\u4e3a\u8ffd\u8e2a\u8fdb\u5c55\u548c\u6bd4\u8f83\u89e3\u51b3\u65b9\u6848\u7684\u6838\u5fc3\u5e73\u53f0\u3002\u672c\u7814\u7a76\u65e8\u5728\u9996\u6b21\u5168\u9762\u5206\u6790\u8fd9\u4e24\u4e2a\u6392\u884c\u699c\u7684\u751f\u6001\u7cfb\u7edf", "method": "\u5206\u6790SWE-Bench\u7684Lite\u548cVerified\u4e24\u4e2a\u6392\u884c\u699c\u7684\u63d0\u4ea4\u6570\u636e\uff0c\u5171\u7814\u7a76\u4e8679\u4e2aLite\u63d0\u4ea4\u548c133\u4e2aVerified\u63d0\u4ea4\u3002\u7814\u7a76\u5185\u5bb9\u5305\u62ec\uff1a\u63d0\u4ea4\u8005\u8eab\u4efd\uff08\u884c\u4e1a/\u5b66\u672f\uff09\u3001\u80cc\u540e\u4ea7\u54c1\u3001\u4f7f\u7528\u7684LLM\u6a21\u578b\u3001\u4ee5\u53ca\u65b9\u6cd5\u7684\u5f00\u653e\u6027\u7a0b\u5ea6", "result": "1. \u4e24\u4e2a\u6392\u884c\u699c\u7684\u5927\u591a\u6570\u63d0\u4ea4\u6765\u81ea\u884c\u4e1a\uff0c\u7279\u522b\u662f\u5c0f\u578b\u516c\u53f8\u548c\u5927\u578b\u4e0a\u5e02\u516c\u53f8\uff1b2. \u884c\u4e1a\u63d0\u4ea4\u901a\u5e38\u83b7\u5f97\u6700\u597d\u7ed3\u679c\uff0c\u4f46\u5b66\u672f\u8d21\u732e\uff08\u901a\u5e38\u662f\u5f00\u6e90\u7684\uff09\u4e5f\u4fdd\u6301\u7ade\u4e89\u529b\uff1b3. \u4e13\u6709LLM\u6a21\u578b\u660e\u663e\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u7279\u522b\u662fClaude\u7cfb\u5217\uff1b4. \u76ee\u524d\u4e24\u4e2a\u6392\u884c\u699c\u7684\u6700\u5148\u8fdb\u7ed3\u679c\u90fd\u7531Claude 4 Sonnet\u5b9e\u73b0", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86SWE-Bench\u751f\u6001\u7cfb\u7edf\u7684\u73b0\u72b6\uff0c\u4e3a\u672a\u6765\u57fa\u51c6\u9a71\u52a8\u7814\u7a76\u63d0\u4f9b\u4e86\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u591a\u6837\u6027\u7684\u6307\u5bfc\u3002\u884c\u4e1a\u4e3b\u5bfc\u548c\u4e13\u6709\u6a21\u578b\u5360\u4f18\u7684\u73b0\u72b6\u503c\u5f97\u5173\u6ce8\uff0c\u9700\u8981\u4fc3\u8fdb\u66f4\u5f00\u653e\u548c\u591a\u6837\u5316\u7684\u7814\u7a76\u751f\u6001\u7cfb\u7edf"}}
{"id": "2602.04467", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04467", "abs": "https://arxiv.org/abs/2602.04467", "authors": ["Ridewaan Hanslo", "Maureen Tanner"], "title": "A Framework of Critical Success Factors for Agile Software Development", "comment": "8 pages, 3 figures, 1 table, conference", "summary": "Despite the popularity of Agile software development, achieving consistent project success remains challenging. This systematic literature review identifies critical success factors (CSFs) in Agile projects by analyzing 53 primary studies. Employing thematic synthesis with content analysis, our analysis yielded 21 CSFs categorized into five themes: organizational, people, technical, process, and project. Team effectiveness and project management emerged as the most frequently cited CSFs, highlighting the importance of people and process factors. These interpreted themes and factors contributed to the development of a theoretical framework to identify how these factors contribute to project success. This study offers valuable insights for researchers and practitioners, guiding future research to validate these findings and test the proposed framework using quantitative methods.", "AI": {"tldr": "\u8fd9\u7bc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u901a\u8fc7\u5206\u679053\u9879\u7814\u7a76\uff0c\u8bc6\u522b\u4e86\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u9879\u76ee\u768421\u4e2a\u5173\u952e\u6210\u529f\u56e0\u7d20\uff0c\u5e76\u5c06\u5176\u5f52\u7c7b\u4e3a\u7ec4\u7ec7\u3001\u4eba\u5458\u3001\u6280\u672f\u3001\u8fc7\u7a0b\u548c\u9879\u76ee\u4e94\u5927\u4e3b\u9898\uff0c\u6784\u5efa\u4e86\u7406\u8bba\u6846\u67b6\u3002", "motivation": "\u5c3d\u7ba1\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u5f88\u6d41\u884c\uff0c\u4f46\u5b9e\u73b0\u4e00\u81f4\u7684\u9879\u76ee\u6210\u529f\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u8bc6\u522b\u654f\u6377\u9879\u76ee\u4e2d\u7684\u5173\u952e\u6210\u529f\u56e0\u7d20\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u4e8653\u9879\u4e3b\u8981\u7814\u7a76\u3002\u4f7f\u7528\u4e3b\u9898\u7efc\u5408\u4e0e\u5185\u5bb9\u5206\u6790\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5bf9\u5173\u952e\u6210\u529f\u56e0\u7d20\u8fdb\u884c\u8bc6\u522b\u548c\u5206\u7c7b\u3002", "result": "\u8bc6\u522b\u51fa21\u4e2a\u5173\u952e\u6210\u529f\u56e0\u7d20\uff0c\u5206\u4e3a\u4e94\u5927\u4e3b\u9898\uff1a\u7ec4\u7ec7\u3001\u4eba\u5458\u3001\u6280\u672f\u3001\u8fc7\u7a0b\u548c\u9879\u76ee\u3002\u56e2\u961f\u6709\u6548\u6027\u548c\u9879\u76ee\u7ba1\u7406\u662f\u6700\u5e38\u88ab\u5f15\u7528\u7684\u56e0\u7d20\uff0c\u5f3a\u8c03\u4e86\u4eba\u5458\u548c\u8fc7\u7a0b\u56e0\u7d20\u7684\u91cd\u8981\u6027\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\u6784\u5efa\u4e86\u7406\u8bba\u6846\u67b6\u3002", "conclusion": "\u7814\u7a76\u4e3a\u654f\u6377\u9879\u76ee\u6210\u529f\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u6307\u5bfc\u672a\u6765\u7814\u7a76\u9a8c\u8bc1\u8fd9\u4e9b\u53d1\u73b0\u5e76\u4f7f\u7528\u5b9a\u91cf\u65b9\u6cd5\u6d4b\u8bd5\u63d0\u51fa\u7684\u7406\u8bba\u6846\u67b6\u3002\u5f3a\u8c03\u4e86\u4eba\u5458\u548c\u8fc7\u7a0b\u56e0\u7d20\u5728\u654f\u6377\u9879\u76ee\u6210\u529f\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\u3002"}}
{"id": "2602.04210", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04210", "abs": "https://arxiv.org/abs/2602.04210", "authors": ["Enyu Zhou", "Zhiheng Xi", "Long Ma", "Zhihao Zhang", "Shihan Dou", "Zhikai Lei", "Guoteng Wang", "Rui Zheng", "Hang Yan", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Steering LLMs via Scalable Interactive Oversight", "comment": null, "summary": "As Large Language Models increasingly automate complex, long-horizon tasks such as \\emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54\\% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u53ef\u6269\u5c55\u4ea4\u4e92\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u9012\u5f52\u5206\u89e3\u590d\u6742\u610f\u56fe\u4e3a\u53ef\u7ba1\u7406\u51b3\u7b56\u6811\uff0c\u8ba9\u975e\u4e13\u5bb6\u7528\u6237\u4e5f\u80fd\u6709\u6548\u6307\u5bfcAI\u5b8c\u6210\u590d\u6742\u4efb\u52a1\uff0c\u5728\u7f51\u9875\u5f00\u53d1\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e8654%\u7684\u5bf9\u9f50\u5ea6\u63d0\u5347\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u81ea\u52a8\u5316\u590d\u6742\u3001\u957f\u65f6\u7a0b\u4efb\u52a1\uff0c\u51fa\u73b0\u4e86\u76d1\u7763\u7f3a\u53e3\uff1a\u7528\u6237\u56e0\u7f3a\u4e4f\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3001\u96be\u4ee5\u7cbe\u786e\u8868\u8fbe\u610f\u56fe\u3001\u65e0\u6cd5\u53ef\u9760\u9a8c\u8bc1\u590d\u6742\u8f93\u51fa\uff0c\u800c\u96be\u4ee5\u6709\u6548\u6307\u5bfcAI\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u4ea4\u4e92\u76d1\u7763\u6846\u67b6\uff0c\u5c06\u590d\u6742\u610f\u56fe\u9012\u5f52\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u51b3\u7b56\u6811\uff0c\u5728\u8282\u70b9\u5904\u6536\u96c6\u4f4e\u8d1f\u62c5\u7684\u7528\u6237\u53cd\u9988\uff0c\u9012\u5f52\u805a\u5408\u8fd9\u4e9b\u4fe1\u53f7\u5f62\u6210\u7cbe\u786e\u7684\u5168\u5c40\u6307\u5bfc\u3002", "result": "\u5728\u7f51\u9875\u5f00\u53d1\u4efb\u52a1\u4e2d\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u4f7f\u975e\u4e13\u5bb6\u7528\u6237\u80fd\u591f\u751f\u6210\u4e13\u5bb6\u7ea7\u7684\u4ea7\u54c1\u9700\u6c42\u6587\u6863\uff0c\u5b9e\u73b0\u4e8654%\u7684\u5bf9\u9f50\u5ea6\u63d0\u5347\u3002\u6846\u67b6\u53ef\u901a\u8fc7\u4ec5\u4f7f\u7528\u5728\u7ebf\u7528\u6237\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u4f18\u5316\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u89e3\u51b3\u53ef\u6269\u5c55\u76d1\u7763\u6311\u6218\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u80fd\u591f\u5728AI\u6269\u5c55\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4eba\u7c7b\u63a7\u5236\uff0c\u4f7f\u975e\u4e13\u5bb6\u7528\u6237\u4e5f\u80fd\u6709\u6548\u6307\u5bfcAI\u5b8c\u6210\u8d85\u8d8a\u81ea\u8eab\u80fd\u529b\u7684\u590d\u6742\u4efb\u52a1\u3002"}}
{"id": "2602.04726", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04726", "abs": "https://arxiv.org/abs/2602.04726", "authors": ["Marian Kica", "Lukas Radosky", "David Slivka", "Karin Kubinova", "Daniel Dovhun", "Tomas Uhercik", "Erik Bircak", "Ivan Polasek"], "title": "Supporting software engineering tasks with agentic AI: Demonstration on document retrieval and test scenario generation", "comment": "This is a preprint of a paper that was accepted at the International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA 2026)", "summary": "The introduction of large language models ignited great retooling and rethinking of the software development models. The ensuing response of software engineering research yielded a massive body of tools and approaches. In this paper, we join the hassle by introducing agentic AI solutions for two tasks. First, we developed a solution for automatic test scenario generation from a detailed requirements description. This approach relies on specialized worker agents forming a star topology with the supervisor agent in the middle. We demonstrate its capabilities on a real-world example. Second, we developed an agentic AI solution for the document retrieval task in the context of software engineering documents. Our solution enables performing various use cases on a body of documents related to the development of a single software, including search, question answering, tracking changes, and large document summarization. In this case, each use case is handled by a dedicated LLM-based agent, which performs all subtasks related to the corresponding use case. We conclude by hinting at the future perspectives of our line of research.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e24\u79cd\u57fa\u4e8e\u667a\u80fd\u4f53AI\u7684\u8f6f\u4ef6\u5de5\u7a0b\u89e3\u51b3\u65b9\u6848\uff1a\u4e00\u662f\u7528\u4e8e\u4ece\u8be6\u7ec6\u9700\u6c42\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u573a\u666f\u7684\u661f\u578b\u62d3\u6251\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4e8c\u662f\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u6587\u6863\u68c0\u7d22\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u652f\u6301\u641c\u7d22\u3001\u95ee\u7b54\u3001\u53d8\u66f4\u8ddf\u8e2a\u548c\u6587\u6863\u6458\u8981\u7b49\u529f\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\u5f15\u53d1\u4e86\u8f6f\u4ef6\u5f00\u53d1\u6a21\u5f0f\u7684\u91cd\u5927\u53d8\u9769\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4ea7\u751f\u4e86\u5927\u91cf\u5de5\u5177\u548c\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u667a\u80fd\u4f53AI\u89e3\u51b3\u65b9\u6848\u6765\u53c2\u4e0e\u8fd9\u4e00\u53d8\u9769\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5177\u4f53\u4efb\u52a1\u63d0\u4f9b\u81ea\u52a8\u5316\u652f\u6301\u3002", "method": "1. \u6d4b\u8bd5\u573a\u666f\u751f\u6210\uff1a\u91c7\u7528\u661f\u578b\u62d3\u6251\u7ed3\u6784\uff0c\u7531\u76d1\u7763\u667a\u80fd\u4f53\u5c45\u4e2d\u534f\u8c03\u591a\u4e2a\u4e13\u7528\u5de5\u4f5c\u667a\u80fd\u4f53\uff0c\u4ece\u8be6\u7ec6\u9700\u6c42\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u573a\u666f\u3002\n2. \u6587\u6863\u68c0\u7d22\uff1a\u4e3a\u6bcf\u4e2a\u7528\u4f8b\uff08\u641c\u7d22\u3001\u95ee\u7b54\u3001\u53d8\u66f4\u8ddf\u8e2a\u3001\u6587\u6863\u6458\u8981\uff09\u8bbe\u8ba1\u4e13\u95e8\u7684LLM\u667a\u80fd\u4f53\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u5904\u7406\u5bf9\u5e94\u7528\u4f8b\u7684\u6240\u6709\u5b50\u4efb\u52a1\u3002", "result": "1. \u6d4b\u8bd5\u573a\u666f\u751f\u6210\u65b9\u6848\u5728\u771f\u5b9e\u4e16\u754c\u793a\u4f8b\u4e2d\u5c55\u793a\u4e86\u5176\u80fd\u529b\u3002\n2. \u6587\u6863\u68c0\u7d22\u7cfb\u7edf\u80fd\u591f\u5bf9\u5355\u4e2a\u8f6f\u4ef6\u5f00\u53d1\u76f8\u5173\u7684\u6587\u6863\u96c6\u5408\u6267\u884c\u591a\u79cd\u7528\u4f8b\u64cd\u4f5c\uff0c\u5305\u62ec\u641c\u7d22\u3001\u95ee\u7b54\u3001\u53d8\u66f4\u8ddf\u8e2a\u548c\u5927\u6587\u6863\u6458\u8981\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86\u667a\u80fd\u4f53AI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u7684\u524d\u666f\u3002"}}
{"id": "2602.04786", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04786", "abs": "https://arxiv.org/abs/2602.04786", "authors": ["Charles Moloney", "Robert Dyer", "Elena Sherman"], "title": "Demonstrating ARG-V's Generation of Realistic Java Benchmarks for SV-COMP", "comment": null, "summary": "The SV-COMP competition provides a state-of-the-art platform for evaluating software verification tools on a standardized set of verification tasks. Consequently, verifier development outcomes are influenced by the composition of program benchmarks included in SV-COMP. When expanding this benchmark corpus, it is crucial to consider whether newly added programs cause verifiers to exhibit behavior distinct from that observed on existing benchmarks. Doing so helps mitigate external threats to the validity of the competition's results.\n  In this paper, we present the application of the ARG-V tool for automatically generating Java verification benchmarks in the SV-COMP format. We demonstrate that, on a newly generated set of 68 realistic benchmarks, all four leading Java verifiers decrease in accuracy and recall compared to their performance on the existing benchmark suite. These findings highlight the potential of ARG-V to enhance the comprehensiveness and realism of verification tool evaluation, while also providing a roadmap for verifier developers aiming to improve their tools' applicability to real-world software.", "AI": {"tldr": "ARG-V\u5de5\u5177\u81ea\u52a8\u751f\u6210Java\u9a8c\u8bc1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u572868\u4e2a\u65b0\u57fa\u51c6\u4e0a\u6240\u6709\u9886\u5148Java\u9a8c\u8bc1\u5668\u7684\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u5747\u4e0b\u964d\uff0c\u663e\u793a\u73b0\u6709\u57fa\u51c6\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u9a8c\u8bc1\u5668\u5728\u771f\u5b9e\u8f6f\u4ef6\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "SV-COMP\u7ade\u8d5b\u7684\u9a8c\u8bc1\u5668\u8bc4\u4f30\u7ed3\u679c\u53d7\u57fa\u51c6\u6d4b\u8bd5\u96c6\u7ec4\u6210\u5f71\u54cd\uff0c\u9700\u8981\u786e\u4fdd\u65b0\u589e\u7a0b\u5e8f\u80fd\u53cd\u6620\u9a8c\u8bc1\u5668\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u884c\u4e3a\u5dee\u5f02\uff0c\u907f\u514d\u8bc4\u4f30\u7ed3\u679c\u7684\u5916\u90e8\u6709\u6548\u6027\u5a01\u80c1\u3002", "method": "\u4f7f\u7528ARG-V\u5de5\u5177\u81ea\u52a8\u751f\u6210\u7b26\u5408SV-COMP\u683c\u5f0f\u7684Java\u9a8c\u8bc1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u521b\u5efa\u4e8668\u4e2a\u73b0\u5b9e\u57fa\u51c6\uff0c\u5e76\u5bf9\u6bd4\u56db\u4e2a\u9886\u5148Java\u9a8c\u8bc1\u5668\u5728\u65b0\u65e7\u57fa\u51c6\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u6240\u6709\u56db\u4e2a\u9886\u5148Java\u9a8c\u8bc1\u5668\u5728\u65b0\u751f\u6210\u768468\u4e2a\u73b0\u5b9e\u57fa\u51c6\u4e0a\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u5747\u51fa\u73b0\u4e0b\u964d\u3002", "conclusion": "ARG-V\u80fd\u589e\u5f3a\u9a8c\u8bc1\u5de5\u5177\u8bc4\u4f30\u7684\u5168\u9762\u6027\u548c\u73b0\u5b9e\u6027\uff0c\u4e3a\u9a8c\u8bc1\u5668\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u6539\u8fdb\u5de5\u5177\u5728\u771f\u5b9e\u8f6f\u4ef6\u4e2d\u9002\u7528\u6027\u7684\u8def\u7ebf\u56fe\u3002"}}
{"id": "2602.04284", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04284", "abs": "https://arxiv.org/abs/2602.04284", "authors": ["Yansong Ning", "Jun Fang", "Naiqiang Tan", "Hao Liu"], "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning", "comment": "Under Review", "summary": "Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.", "AI": {"tldr": "Agent-Omit\uff1a\u4e00\u4e2a\u8bad\u7ec3\u6846\u67b6\uff0c\u4f7fLLM\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u9002\u5e94\u5730\u7701\u7565\u5197\u4f59\u7684\u601d\u7ef4\u548c\u89c2\u5bdf\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c06\u6574\u4e2a\u4ea4\u4e92\u8f68\u8ff9\u540c\u7b49\u5bf9\u5f85\uff0c\u5ffd\u7565\u4e86\u4e0d\u540c\u8f6e\u6b21\u4e2d\u601d\u7ef4\u5fc5\u8981\u6027\u548c\u89c2\u5bdf\u6548\u7528\u7684\u5dee\u5f02\uff0c\u5bfc\u81f4\u667a\u80fd\u4f53\u6548\u7387\u4f4e\u4e0b\u3002", "method": "1. \u5408\u6210\u5c11\u91cf\u51b7\u542f\u52a8\u6570\u636e\uff08\u5355\u8f6e\u548c\u591a\u8f6e\u7701\u7565\u573a\u666f\uff09\u5fae\u8c03\u667a\u80fd\u4f53\uff1b2. \u63d0\u51fa\u7701\u7565\u611f\u77e5\u7684\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u542b\u53cc\u91cd\u91c7\u6837\u673a\u5236\u548c\u5b9a\u5236\u7684\u7701\u7565\u5956\u52b1\u3002", "result": "\u5728\u4e94\u4e2a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgent-Omit-8B\u6a21\u578b\u6027\u80fd\u4e0e\u524d\u6cbfLLM\u667a\u80fd\u4f53\u76f8\u5f53\uff0c\u5728\u6548\u679c-\u6548\u7387\u6743\u8861\u65b9\u9762\u4f18\u4e8e\u4e03\u79cd\u9ad8\u6548LLM\u667a\u80fd\u4f53\u65b9\u6cd5\u3002", "conclusion": "Agent-Omit\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u7701\u7565\u5197\u4f59\u601d\u7ef4\u548c\u89c2\u5bdf\uff0c\u5b9e\u73b0\u4e86\u667a\u80fd\u4f53\u6548\u679c\u4e0e\u6548\u7387\u7684\u6700\u4f73\u5e73\u8861\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u7701\u7565\u7b56\u7565\u504f\u5dee\u6709\u4e0a\u754c\u3002"}}
{"id": "2602.04799", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.04799", "abs": "https://arxiv.org/abs/2602.04799", "authors": ["Nils Chur", "Thorsten Berger", "Einar Broch Johnsen", "Andrzej W\u0105sowski"], "title": "Beyond the Control Equations: An Artifact Study of Implementation Quality in Robot Control Software", "comment": null, "summary": "A controller -- a software module managing hardware behavior -- is a key component of a typical robot system. While control theory gives safety guarantees for standard controller designs, the practical implementation of controllers in software introduces complexities that are often overlooked. Controllers are often designed in continuous space, while the software is executed in discrete space, undermining some of the theoretical guarantees. Despite extensive research on control theory and control modeling, little attention has been paid to the implementations of controllers and how their theoretical guarantees are ensured in real-world software systems. We investigate 184 real-world controller implementations in open-source robot software. We examine their application context, the implementation characteristics, and the testing methods employed to ensure correctness. We find that the implementations often handle discretization in an ad hoc manner, leading to potential issues with real-time reliability. Challenges such as timing inconsistencies, lack of proper error handling, and inadequate consideration of real-time constraints further complicate matters. Testing practices are superficial, no systematic verification of theoretical guarantees is used, leaving possible inconsistencies between expected and actual behavior. Our findings highlight the need for improved implementation guidelines and rigorous verification techniques to ensure the reliability and safety of robotic controllers in practice.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u673a\u5668\u4eba\u63a7\u5236\u5668\u8f6f\u4ef6\u5b9e\u73b0\u5b58\u5728\u7406\u8bba\u4e0e\u5b9e\u9645\u8131\u8282\u95ee\u9898\uff0c\u79bb\u6563\u5316\u5904\u7406\u968f\u610f\u3001\u6d4b\u8bd5\u65b9\u6cd5\u8868\u9762\u5316\uff0c\u7f3a\u4e4f\u5bf9\u7406\u8bba\u4fdd\u8bc1\u7684\u7cfb\u7edf\u9a8c\u8bc1\uff0c\u9700\u8981\u6539\u8fdb\u5b9e\u73b0\u6307\u5357\u548c\u9a8c\u8bc1\u6280\u672f\u3002", "motivation": "\u63a7\u5236\u5668\u662f\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u63a7\u5236\u7406\u8bba\u4e3a\u6807\u51c6\u8bbe\u8ba1\u63d0\u4f9b\u5b89\u5168\u4fdd\u8bc1\uff0c\u4f46\u8f6f\u4ef6\u5b9e\u73b0\u4e2d\u7684\u590d\u6742\u6027\u5e38\u88ab\u5ffd\u89c6\u3002\u63a7\u5236\u5668\u901a\u5e38\u5728\u8fde\u7eed\u7a7a\u95f4\u8bbe\u8ba1\uff0c\u800c\u8f6f\u4ef6\u5728\u79bb\u6563\u7a7a\u95f4\u6267\u884c\uff0c\u8fd9\u524a\u5f31\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002\u5c3d\u7ba1\u63a7\u5236\u7406\u8bba\u548c\u5efa\u6a21\u7814\u7a76\u5e7f\u6cdb\uff0c\u4f46\u63a7\u5236\u5668\u5b9e\u73b0\u53ca\u5176\u7406\u8bba\u4fdd\u8bc1\u5982\u4f55\u5728\u771f\u5b9e\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u786e\u4fdd\u7684\u95ee\u9898\u5f88\u5c11\u53d7\u5230\u5173\u6ce8\u3002", "method": "\u7814\u7a76\u8005\u8c03\u67e5\u4e86184\u4e2a\u5f00\u6e90\u673a\u5668\u4eba\u8f6f\u4ef6\u4e2d\u7684\u771f\u5b9e\u63a7\u5236\u5668\u5b9e\u73b0\uff0c\u68c0\u67e5\u4e86\u5b83\u4eec\u7684\u5e94\u7528\u80cc\u666f\u3001\u5b9e\u73b0\u7279\u5f81\u4ee5\u53ca\u7528\u4e8e\u786e\u4fdd\u6b63\u786e\u6027\u7684\u6d4b\u8bd5\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u63a7\u5236\u5668\u5b9e\u73b0\u901a\u5e38\u4ee5\u4e34\u65f6\u65b9\u5f0f\u5904\u7406\u79bb\u6563\u5316\uff0c\u5bfc\u81f4\u5b9e\u65f6\u53ef\u9760\u6027\u95ee\u9898\u3002\u65f6\u5e8f\u4e0d\u4e00\u81f4\u3001\u7f3a\u4e4f\u9002\u5f53\u7684\u9519\u8bef\u5904\u7406\u3001\u5bf9\u5b9e\u65f6\u7ea6\u675f\u8003\u8651\u4e0d\u8db3\u7b49\u6311\u6218\u8fdb\u4e00\u6b65\u4f7f\u95ee\u9898\u590d\u6742\u5316\u3002\u6d4b\u8bd5\u5b9e\u8df5\u8868\u9762\u5316\uff0c\u6ca1\u6709\u4f7f\u7528\u7cfb\u7edf\u5316\u7684\u7406\u8bba\u4fdd\u8bc1\u9a8c\u8bc1\uff0c\u5bfc\u81f4\u9884\u671f\u884c\u4e3a\u4e0e\u5b9e\u9645\u884c\u4e3a\u53ef\u80fd\u5b58\u5728\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u9700\u8981\u6539\u8fdb\u5b9e\u73b0\u6307\u5357\u548c\u4e25\u683c\u7684\u9a8c\u8bc1\u6280\u672f\uff0c\u4ee5\u786e\u4fdd\u5b9e\u8df5\u4e2d\u673a\u5668\u4eba\u63a7\u5236\u5668\u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2602.04326", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.04326", "abs": "https://arxiv.org/abs/2602.04326", "authors": ["SeungWon Seo", "SooBin Lim", "SeongRae Noh", "Haneul Kim", "HyeongYeop Kang"], "title": "From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents", "comment": "31 pages, 10 figures, Accepted ICLR 2026", "summary": "Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adaptation. Yet, uncertainty is still primarily mitigated through frequent inter-agent communication. This incurs substantial token and time costs, and can disrupt established workflows, when human partners are involved. We introduce PCE, a Planner-Composer-Evaluator framework that converts the fragmented assumptions latent in LLM reasoning traces into a structured decision tree. Internal nodes encode environment assumptions and leaves map to actions; each path is then scored by scenario likelihood, goal-directed gain, and execution cost to guide rational action selection without heavy communication. Across two challenging multi-agent benchmarks (C-WAH and TDW-MAT) and three diverse LLM backbones, PCE consistently outperforms communication-centric baselines in success rate and task efficiency while showing comparable token usage. Ablation results indicate that the performance gains obtained by scaling model capacity or reasoning depth persist even when PCE is applied, while PCE consistently raises the baseline across both capacity and reasoning-depth scales, confirming that structured uncertainty handling complements both forms of scaling. A user study further demonstrates that PCE produces communication patterns that human partners perceive as more efficient and trustworthy. Together, these results establish a principled route for turning latent LLM assumptions into reliable strategies for uncertainty-aware planning.", "AI": {"tldr": "PCE\u6846\u67b6\u901a\u8fc7\u5c06LLM\u63a8\u7406\u4e2d\u7684\u9690\u542b\u5047\u8bbe\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u51b3\u7b56\u6811\uff0c\u5728\u591a\u667a\u80fd\u4f53\u90e8\u5206\u53ef\u89c2\u5bdf\u73af\u5883\u4e2d\u5b9e\u73b0\u65e0\u9700\u9891\u7e41\u901a\u4fe1\u7684\u7406\u6027\u51b3\u7b56", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u5728\u591a\u667a\u80fd\u4f53\u3001\u90e8\u5206\u53ef\u89c2\u5bdf\u3001\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u4e3b\u8981\u4f9d\u8d56\u9891\u7e41\u901a\u4fe1\u6765\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd9\u5e26\u6765\u4e86\u9ad8\u6602\u7684token\u548c\u65f6\u95f4\u6210\u672c\uff0c\u5e76\u53ef\u80fd\u5e72\u6270\u4eba\u7c7b\u5408\u4f5c\u4f19\u4f34\u7684\u5de5\u4f5c\u6d41\u7a0b", "method": "\u63d0\u51faPCE\uff08Planner-Composer-Evaluator\uff09\u6846\u67b6\uff0c\u5c06LLM\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u788e\u7247\u5316\u5047\u8bbe\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u51b3\u7b56\u6811\uff0c\u5185\u90e8\u8282\u70b9\u7f16\u7801\u73af\u5883\u5047\u8bbe\uff0c\u53f6\u8282\u70b9\u6620\u5c04\u5230\u52a8\u4f5c\uff0c\u901a\u8fc7\u573a\u666f\u53ef\u80fd\u6027\u3001\u76ee\u6807\u5bfc\u5411\u6536\u76ca\u548c\u6267\u884c\u6210\u672c\u5bf9\u8def\u5f84\u8fdb\u884c\u8bc4\u5206", "result": "\u5728\u4e24\u4e2a\u591a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\uff08C-WAH\u548cTDW-MAT\uff09\u548c\u4e09\u4e2aLLM\u9aa8\u5e72\u4e0a\uff0cPCE\u5728\u6210\u529f\u7387\u548c\u4efb\u52a1\u6548\u7387\u4e0a\u6301\u7eed\u4f18\u4e8e\u901a\u4fe1\u5bc6\u96c6\u578b\u57fa\u7ebf\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684token\u4f7f\u7528\u91cf\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660ePCE\u5728\u4e0d\u540c\u6a21\u578b\u5bb9\u91cf\u548c\u63a8\u7406\u6df1\u5ea6\u4e0b\u90fd\u80fd\u63d0\u5347\u6027\u80fd", "conclusion": "PCE\u4e3a\u5c06LLM\u7684\u9690\u542b\u5047\u8bbe\u8f6c\u5316\u4e3a\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u89c4\u5212\u7b56\u7565\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u80fd\u591f\u4ea7\u751f\u4eba\u7c7b\u5408\u4f5c\u4f19\u4f34\u8ba4\u4e3a\u66f4\u9ad8\u6548\u548c\u53ef\u4fe1\u7684\u901a\u4fe1\u6a21\u5f0f"}}
{"id": "2602.04824", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04824", "abs": "https://arxiv.org/abs/2602.04824", "authors": ["Samuel W. Flint", "Robert Dyer", "Bonita Sharif"], "title": "Do Developers Read Type Information? An Eye-Tracking Study on TypeScript", "comment": null, "summary": "Statically-annotated types have been shown to aid developers in a number of programming tasks, and this benefit holds true even when static type checking is not used. It is hypothesized that this is because developers use type annotations as in-code documentation. In this study, we aim to provide evidence that developers use type annotations as in-code documentation. Understanding this hypothesized use will help to understand how, and in what contexts, developers use type information; additionally, it may help to design better development tools and inform educational decisions. To provide this evidence, we conduct an eye tracking study with 26 undergraduate students to determine if they read type annotations during code comprehension and bug localization in the TypeScript language. We found that developers do not look directly at lines containing type annotations or type declarations more often when they are present, in either code summarization or bug localization tasks. The results have implications for tool builders to improve the availability of type information, the development community to build good standards for use of type annotations, and education to enforce deliberate teaching of reading patterns.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5f00\u53d1\u8005\u5728\u4ee3\u7801\u7406\u89e3\u548cbug\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u4e0d\u4f1a\u7279\u522b\u5173\u6ce8\u7c7b\u578b\u6ce8\u89e3\uff0c\u8fd9\u5bf9\u5de5\u5177\u8bbe\u8ba1\u3001\u793e\u533a\u6807\u51c6\u548c\u7f16\u7a0b\u6559\u80b2\u6709\u91cd\u8981\u542f\u793a\u3002", "motivation": "\u9759\u6001\u7c7b\u578b\u6ce8\u89e3\u5df2\u88ab\u8bc1\u660e\u80fd\u5e2e\u52a9\u5f00\u53d1\u8005\u5b8c\u6210\u591a\u79cd\u7f16\u7a0b\u4efb\u52a1\uff0c\u5373\u4f7f\u4e0d\u4f7f\u7528\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u4e5f\u662f\u5982\u6b64\u3002\u5047\u8bbe\u8fd9\u662f\u56e0\u4e3a\u5f00\u53d1\u8005\u5c06\u7c7b\u578b\u6ce8\u89e3\u89c6\u4e3a\u5185\u8054\u6587\u6863\u3002\u672c\u7814\u7a76\u65e8\u5728\u63d0\u4f9b\u8bc1\u636e\u8bc1\u660e\u5f00\u53d1\u8005\u786e\u5b9e\u5c06\u7c7b\u578b\u6ce8\u89e3\u4f5c\u4e3a\u5185\u8054\u6587\u6863\u4f7f\u7528\u3002", "method": "\u901a\u8fc7\u773c\u52a8\u8ffd\u8e2a\u7814\u7a76\uff0c\u62db\u52df26\u540d\u672c\u79d1\u751f\uff0c\u5728TypeScript\u8bed\u8a00\u4e2d\u8fdb\u884c\u4ee3\u7801\u7406\u89e3\u548cbug\u5b9a\u4f4d\u4efb\u52a1\uff0c\u89c2\u5bdf\u4ed6\u4eec\u662f\u5426\u9605\u8bfb\u7c7b\u578b\u6ce8\u89e3\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f00\u53d1\u8005\u5728\u4ee3\u7801\u603b\u7ed3\u6216bug\u5b9a\u4f4d\u4efb\u52a1\u4e2d\uff0c\u5f53\u5b58\u5728\u7c7b\u578b\u6ce8\u89e3\u65f6\uff0c\u5e76\u4e0d\u4f1a\u66f4\u9891\u7e41\u5730\u76f4\u63a5\u67e5\u770b\u5305\u542b\u7c7b\u578b\u6ce8\u89e3\u6216\u7c7b\u578b\u58f0\u660e\u7684\u4ee3\u7801\u884c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u5de5\u5177\u5f00\u53d1\u8005\u6539\u8fdb\u7c7b\u578b\u4fe1\u606f\u7684\u53ef\u7528\u6027\u3001\u5f00\u53d1\u793e\u533a\u5efa\u7acb\u826f\u597d\u7684\u7c7b\u578b\u6ce8\u89e3\u4f7f\u7528\u6807\u51c6\u3001\u4ee5\u53ca\u6559\u80b2\u4e2d\u52a0\u5f3a\u9605\u8bfb\u6a21\u5f0f\u7684\u6709\u610f\u8bc6\u6559\u5b66\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.04385", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04385", "abs": "https://arxiv.org/abs/2602.04385", "authors": ["Marco Picone", "Fabio Turazza", "Matteo Martinelli", "Marco Mamei"], "title": "Digital Twins & ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications", "comment": "Author-accepted manuscript of a paper published in the 2025 IEEE International Conference on Systems, Man and Cybernetics (IEEE SMC), October 2025, doi: 10.1109/SMC58881.2025.11343418", "summary": "The increasing complexity of Cyber-Physical Systems (CPS), particularly in the industrial domain, has amplified the challenges associated with the effective integration of Artificial Intelligence (AI) and Machine Learning (ML) techniques. Fragmentation across IoT and IIoT technologies, manifested through diverse communication protocols, data formats and device capabilities, creates a substantial gap between low-level physical layers and high-level intelligent functionalities. Recently, Digital Twin (DT) technology has emerged as a promising solution, offering structured, interoperable and semantically rich digital representations of physical assets. Current approaches are often siloed and tightly coupled, limiting scalability and reuse of AI functionalities. This work proposes a modular and interoperable solution that enables seamless AI pipeline integration into CPS by minimizing configuration and decoupling the roles of DTs and AI components. We introduce the concept of Zero Configuration (ZeroConf) AI pipelines, where DTs orchestrate data management and intelligent augmentation. The approach is demonstrated in a MicroFactory scenario, showing support for concurrent ML models and dynamic data processing, effectively accelerating the deployment of intelligent services in complex industrial settings.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u96f6\u914d\u7f6eAI\u7ba1\u9053\u6846\u67b6\uff0c\u89e3\u51b3\u5de5\u4e1aCPS\u4e2dAI/ML\u96c6\u6210\u788e\u7247\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u3001\u53ef\u4e92\u64cd\u4f5c\u7684\u667a\u80fd\u670d\u52a1\u90e8\u7f72", "motivation": "\u5de5\u4e1aCPS\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\uff0c\u7269\u8054\u7f51/\u5de5\u4e1a\u7269\u8054\u7f51\u6280\u672f\u788e\u7247\u5316\uff08\u901a\u4fe1\u534f\u8bae\u3001\u6570\u636e\u683c\u5f0f\u3001\u8bbe\u5907\u80fd\u529b\u591a\u6837\uff09\u5bfc\u81f4\u7269\u7406\u5c42\u4e0e\u667a\u80fd\u529f\u80fd\u5c42\u4e4b\u95f4\u5b58\u5728\u5de8\u5927\u9e3f\u6c9f\uff0c\u73b0\u6709\u6570\u5b57\u5b6a\u751f\u65b9\u6cd5\u901a\u5e38\u5b64\u7acb\u4e14\u7d27\u8026\u5408\uff0c\u9650\u5236\u4e86AI\u529f\u80fd\u7684\u53ef\u6269\u5c55\u6027\u548c\u91cd\u7528\u6027", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u3001\u53ef\u4e92\u64cd\u4f5c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u914d\u7f6e\u548c\u89e3\u8026\u6570\u5b57\u5b6a\u751f\u4e0eAI\u7ec4\u4ef6\u89d2\u8272\uff0c\u5b9e\u73b0AI\u7ba1\u9053\u65e0\u7f1d\u96c6\u6210\u5230CPS\u4e2d\u3002\u5f15\u5165\u96f6\u914d\u7f6eAI\u7ba1\u9053\u6982\u5ff5\uff0c\u7531\u6570\u5b57\u5b6a\u751f\u534f\u8c03\u6570\u636e\u7ba1\u7406\u548c\u667a\u80fd\u589e\u5f3a", "result": "\u5728\u5fae\u5de5\u5382\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u652f\u6301\u5e76\u53d1ML\u6a21\u578b\u548c\u52a8\u6001\u6570\u636e\u5904\u7406\u7684\u80fd\u529b\uff0c\u6709\u6548\u52a0\u901f\u4e86\u590d\u6742\u5de5\u4e1a\u73af\u5883\u4e2d\u667a\u80fd\u670d\u52a1\u7684\u90e8\u7f72", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u6280\u672f\u5b9e\u73b0\u4e86AI/ML\u5728\u5de5\u4e1aCPS\u4e2d\u7684\u9ad8\u6548\u96c6\u6210\uff0c\u89e3\u51b3\u4e86\u788e\u7247\u5316\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u667a\u80fd\u670d\u52a1\u7684\u90e8\u7f72\u901f\u5ea6\u548c\u53ef\u6269\u5c55\u6027"}}
{"id": "2602.04830", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04830", "abs": "https://arxiv.org/abs/2602.04830", "authors": ["Karina Kohl", "Luigi Carro"], "title": "When Code Becomes Abundant: Redefining Software Engineering Around Orchestration and Verification", "comment": "Accepted to 2026 IEEE/ACM 48th International Conference on Software Engineering: Future of Software Engineering", "summary": "Software Engineering (SE) faces simultaneous pressure from AI automation (reducing code production costs) and hardware-energy constraints (amplifying failure costs). We position that SE must redefine itself around human discernment-intent articulation, architectural control, and verification-rather than code construction. This shift introduces accountability collapse as a central risk and requires fundamental changes to research priorities, educational curricula, and industrial practices. We argue that Software Engineering, as traditionally defined around code construction and process management, is no longer sufficient. Instead, the discipline must be redefined around intent articulation, architectural control, and systematic verification. This redefinition shifts Software Engineering from a production-oriented field to one centered on human judgment under automation, with profound implications for research, practice, and education.", "AI": {"tldr": "\u8f6f\u4ef6\u5de5\u7a0b\u9762\u4e34AI\u81ea\u52a8\u5316\u548c\u786c\u4ef6\u80fd\u8017\u53cc\u91cd\u538b\u529b\uff0c\u9700\u8981\u4ece\u4ee3\u7801\u6784\u5efa\u8f6c\u5411\u610f\u56fe\u8868\u8fbe\u3001\u67b6\u6784\u63a7\u5236\u548c\u9a8c\u8bc1\uff0c\u6838\u5fc3\u98ce\u9669\u662f\u8d23\u4efb\u5d29\u6e83\uff0c\u9700\u8981\u91cd\u5851\u7814\u7a76\u3001\u6559\u80b2\u548c\u5b9e\u8df5", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u9762\u4e34AI\u81ea\u52a8\u5316\uff08\u964d\u4f4e\u4ee3\u7801\u751f\u4ea7\u6210\u672c\uff09\u548c\u786c\u4ef6\u80fd\u8017\u7ea6\u675f\uff08\u653e\u5927\u5931\u8d25\u6210\u672c\uff09\u7684\u53cc\u91cd\u538b\u529b\uff0c\u4f20\u7edf\u56f4\u7ed5\u4ee3\u7801\u6784\u5efa\u548c\u6d41\u7a0b\u7ba1\u7406\u7684\u5b9a\u4e49\u5df2\u4e0d\u8db3\u591f\uff0c\u9700\u8981\u91cd\u65b0\u5b9a\u4e49\u5b66\u79d1\u65b9\u5411", "method": "\u63d0\u51fa\u8f6f\u4ef6\u5de5\u7a0b\u9700\u8981\u91cd\u65b0\u5b9a\u4f4d\uff0c\u4ece\u4ee3\u7801\u6784\u5efa\u8f6c\u5411\u4e09\u4e2a\u6838\u5fc3\uff1a\u4eba\u7c7b\u8fa8\u522b\u529b-\u610f\u56fe\u8868\u8fbe\u3001\u67b6\u6784\u63a7\u5236\u3001\u9a8c\u8bc1\uff0c\u5f3a\u8c03\u4ece\u751f\u4ea7\u5bfc\u5411\u8f6c\u5411\u81ea\u52a8\u5316\u4e0b\u7684\u4eba\u7c7b\u5224\u65ad", "result": "\u8bc6\u522b\u51fa\u8d23\u4efb\u5d29\u6e83\u662f\u6838\u5fc3\u98ce\u9669\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u9700\u8981\u6839\u672c\u6027\u53d8\u9769\uff0c\u4ece\u4f20\u7edf\u5b9a\u4e49\u8f6c\u5411\u4ee5\u610f\u56fe\u8868\u8fbe\u3001\u67b6\u6784\u63a7\u5236\u548c\u7cfb\u7edf\u9a8c\u8bc1\u4e3a\u4e2d\u5fc3\u7684\u65b0\u8303\u5f0f", "conclusion": "\u8f6f\u4ef6\u5de5\u7a0b\u5fc5\u987b\u91cd\u65b0\u5b9a\u4e49\uff0c\u4ece\u4ee3\u7801\u6784\u5efa\u8f6c\u5411\u4eba\u7c7b\u5224\u65ad\u3001\u610f\u56fe\u8868\u8fbe\u548c\u9a8c\u8bc1\uff0c\u8fd9\u5bf9\u7814\u7a76\u91cd\u70b9\u3001\u6559\u80b2\u8bfe\u7a0b\u548c\u5de5\u4e1a\u5b9e\u8df5\u90fd\u6709\u6df1\u8fdc\u5f71\u54cd"}}
{"id": "2602.04496", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04496", "abs": "https://arxiv.org/abs/2602.04496", "authors": ["Zhentao Tang", "Yuqi Cui", "Shixiong Kai", "Wenqian Zhao", "Ke Ye", "Xing Li", "Anxin Tian", "Zehua Pei", "Hui-Ling Zhen", "Shoubo Hu", "Xiaoguang Li", "Yunhe Wang", "Mingxuan Yuan"], "title": "ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control", "comment": null, "summary": "Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidence-aware agentic framework that orchestrates retrieval, tool use, and multi-agent reasoning through a stage-wise Solver-Critic-Selector architecture. Rather than following a fixed pipeline, ReThinker dynamically allocates computation based on model confidence, enabling adaptive tool invocation, guided multi-dimensional reflection, and robust confidence-weighted selection. To support scalable training without human annotation, we further propose a reverse data synthesis pipeline and an adaptive trajectory recycling strategy that transform successful reasoning traces into high-quality supervision. Experiments on HLE, GAIA, and XBench demonstrate that ReThinker consistently outperforms state-of-the-art foundation models with tools and existing deep research systems, achieving state-of-the-art results on expert-level reasoning tasks.", "AI": {"tldr": "ReThinker\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7Solver-Critic-Selector\u67b6\u6784\u52a8\u6001\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u5728\u4e13\u5bb6\u7ea7\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u5bb6\u7ea7\u79d1\u5b66\u63a8\u7406\uff08\u5982Humanity's Last Exam\uff09\u4e0a\u9762\u4e34\u6311\u6218\uff0c\u4f20\u7edf\u5de5\u5177\u7ba1\u9053\u50f5\u5316\u3001\u591a\u667a\u80fd\u4f53\u534f\u8c03\u8106\u5f31\u3001\u6d4b\u8bd5\u65f6\u6269\u5c55\u6548\u7387\u4f4e\u4e0b\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u3002", "method": "\u63d0\u51faReThinker\u6846\u67b6\uff0c\u91c7\u7528Solver-Critic-Selector\u4e09\u9636\u6bb5\u67b6\u6784\uff0c\u57fa\u4e8e\u6a21\u578b\u7f6e\u4fe1\u5ea6\u52a8\u6001\u5206\u914d\u8ba1\u7b97\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u5de5\u5177\u8c03\u7528\u3001\u5f15\u5bfc\u5f0f\u591a\u7ef4\u5ea6\u53cd\u601d\u548c\u7f6e\u4fe1\u5ea6\u52a0\u6743\u9009\u62e9\u3002\u540c\u65f6\u63d0\u51fa\u53cd\u5411\u6570\u636e\u5408\u6210\u7ba1\u9053\u548c\u81ea\u9002\u5e94\u8f68\u8ff9\u56de\u6536\u7b56\u7565\uff0c\u5c06\u6210\u529f\u63a8\u7406\u8f68\u8ff9\u8f6c\u5316\u4e3a\u9ad8\u8d28\u91cf\u76d1\u7763\u6570\u636e\u3002", "result": "\u5728HLE\u3001GAIA\u548cXBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReThinker\u6301\u7eed\u8d85\u8d8a\u73b0\u6709\u6700\u5148\u8fdb\u7684\u5de5\u5177\u589e\u5f3a\u57fa\u7840\u6a21\u578b\u548c\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\uff0c\u5728\u4e13\u5bb6\u7ea7\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u6700\u5148\u8fdb\u7ed3\u679c\u3002", "conclusion": "ReThinker\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u611f\u77e5\u7684\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u548c\u521b\u65b0\u7684\u6570\u636e\u5408\u6210\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e13\u5bb6\u7ea7\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04572", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.04572", "abs": "https://arxiv.org/abs/2602.04572", "authors": ["Niv Fono", "Yftah Ziser", "Omer Ben-Porat"], "title": "From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums", "comment": null, "summary": "While Generative AI (GenAI) systems draw users away from (Q&A) forums, they also depend on the very data those forums produce to improve their performance. Addressing this paradox, we propose a framework of sequential interaction, in which a GenAI system proposes questions to a forum that can publish some of them. Our framework captures several intricacies of such a collaboration, including non-monetary exchanges, asymmetric information, and incentive misalignment. We bring the framework to life through comprehensive, data-driven simulations using real Stack Exchange data and commonly used LLMs. We demonstrate the incentive misalignment empirically, yet show that players can achieve roughly half of the utility in an ideal full-information scenario. Our results highlight the potential for sustainable collaboration that preserves effective knowledge sharing between AI systems and human knowledge platforms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u5e8f\u5217\u4ea4\u4e92\u6846\u67b6\u6765\u89e3\u51b3\u751f\u6210\u5f0fAI\u7cfb\u7edf\u4e0e\u95ee\u7b54\u8bba\u575b\u4e4b\u95f4\u7684\u6096\u8bba\u5173\u7cfb\uff1aAI\u4f9d\u8d56\u8bba\u575b\u6570\u636e\u63d0\u5347\u6027\u80fd\uff0c\u5374\u5c06\u7528\u6237\u4ece\u8bba\u575b\u5438\u5f15\u8d70\u3002\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684Stack Exchange\u6a21\u62df\uff0c\u8bc1\u660e\u4e86\u6fc0\u52b1\u9519\u914d\u95ee\u9898\uff0c\u4f46\u5c55\u793a\u4e86\u53cc\u65b9\u4ecd\u80fd\u83b7\u5f97\u7406\u60f3\u5168\u4fe1\u606f\u573a\u666f\u4e0b\u7ea6\u4e00\u534a\u7684\u6548\u7528\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7cfb\u7edf\u9762\u4e34\u4e00\u4e2a\u6096\u8bba\uff1a\u5b83\u4eec\u4f9d\u8d56\u95ee\u7b54\u8bba\u575b\u4ea7\u751f\u7684\u6570\u636e\u6765\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u540c\u65f6\u53c8\u5c06\u7528\u6237\u4ece\u8fd9\u4e9b\u8bba\u575b\u5438\u5f15\u8d70\u3002\u8fd9\u79cd\u5173\u7cfb\u53ef\u80fd\u5bfc\u81f4\u77e5\u8bc6\u5171\u4eab\u5e73\u53f0\u7684\u53ef\u6301\u7eed\u6027\u5371\u673a\uff0c\u9700\u8981\u63a2\u7d22AI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u77e5\u8bc6\u5e73\u53f0\u4e4b\u95f4\u7684\u534f\u4f5c\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e8f\u5217\u4ea4\u4e92\u6846\u67b6\uff0c\u8ba9\u751f\u6210\u5f0fAI\u7cfb\u7edf\u5411\u8bba\u575b\u63d0\u51fa\u95ee\u9898\uff0c\u8bba\u575b\u53ef\u4ee5\u9009\u62e9\u53d1\u5e03\u5176\u4e2d\u4e00\u4e9b\u95ee\u9898\u3002\u8be5\u6846\u67b6\u8003\u8651\u4e86\u975e\u8d27\u5e01\u4ea4\u6362\u3001\u4fe1\u606f\u4e0d\u5bf9\u79f0\u548c\u6fc0\u52b1\u9519\u914d\u7b49\u590d\u6742\u56e0\u7d20\u3002\u4f7f\u7528\u771f\u5b9e\u7684Stack Exchange\u6570\u636e\u548c\u5e38\u7528LLM\u8fdb\u884c\u5168\u9762\u7684\u6570\u636e\u9a71\u52a8\u6a21\u62df\u6765\u9a8c\u8bc1\u6846\u67b6\u3002", "result": "\u5b9e\u8bc1\u8bc1\u660e\u4e86\u6fc0\u52b1\u9519\u914d\u7684\u5b58\u5728\uff0c\u4f46\u53d1\u73b0\u53c2\u4e0e\u8005\u4ecd\u80fd\u83b7\u5f97\u7406\u60f3\u5168\u4fe1\u606f\u573a\u666f\u4e0b\u7ea6\u4e00\u534a\u7684\u6548\u7528\u3002\u8fd9\u8868\u660e\u5c3d\u7ba1\u5b58\u5728\u6fc0\u52b1\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0cAI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u77e5\u8bc6\u5e73\u53f0\u4e4b\u95f4\u4ecd\u6709\u53ef\u80fd\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u534f\u4f5c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86AI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u77e5\u8bc6\u5e73\u53f0\u4e4b\u95f4\u53ef\u6301\u7eed\u534f\u4f5c\u7684\u6f5c\u529b\uff0c\u8fd9\u79cd\u534f\u4f5c\u80fd\u591f\u4fdd\u6301\u6709\u6548\u7684\u77e5\u8bc6\u5171\u4eab\uff0c\u89e3\u51b3\u751f\u6210\u5f0fAI\u4f9d\u8d56\u8bba\u575b\u6570\u636e\u5374\u5206\u6d41\u7528\u6237\u7684\u6096\u8bba\u95ee\u9898\u3002"}}
{"id": "2602.04575", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04575", "abs": "https://arxiv.org/abs/2602.04575", "authors": ["Jiaheng Liu", "Yuanxing Zhang", "Shihao Li", "Xinping Lei"], "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration", "comment": null, "summary": "For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the \\textbf{Vibe AIGC}, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.\n  Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faVibe AIGC\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u7f16\u6392\u89e3\u51b3\u5f53\u524d\u751f\u6210\u5f0fAI\u7684\u610f\u56fe-\u6267\u884c\u9e3f\u6c9f\u95ee\u9898\uff0c\u5c06\u7528\u6237\u4ece\u63d0\u793a\u5de5\u7a0b\u5e08\u8f6c\u53d8\u4e3a\u63d0\u4f9b\"\u6c1b\u56f4\"\u7684\u6307\u6325\u5b98\uff0c\u7531\u5143\u89c4\u5212\u5668\u5206\u89e3\u4e3a\u53ef\u6267\u884c\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5f0fAI\u53d7\u6a21\u578b\u4e2d\u5fc3\u8303\u5f0f\u4e3b\u5bfc\uff0c\u867d\u7136\u89c6\u89c9\u4fdd\u771f\u5ea6\u663e\u8457\u63d0\u5347\uff0c\u4f46\u5b58\u5728\"\u53ef\u7528\u6027\u5929\u82b1\u677f\"\u548c\u610f\u56fe-\u6267\u884c\u9e3f\u6c9f\u95ee\u9898\u2014\u2014\u7528\u6237\u9ad8\u5c42\u6b21\u610f\u56fe\u4e0e\u968f\u673a\u3001\u9ed1\u76d2\u7684\u5355\u6b21\u6a21\u578b\u8f93\u51fa\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u5dee\u8ddd\u3002", "method": "\u5f15\u5165Vibe AIGC\u8303\u5f0f\uff0c\u53d7Vibe Coding\u542f\u53d1\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u7f16\u6392\u5b9e\u73b0\u5185\u5bb9\u751f\u6210\u3002\u7528\u6237\u4f5c\u4e3a\u6307\u6325\u5b98\u63d0\u4f9b\"\u6c1b\u56f4\"\uff08\u5305\u542b\u5ba1\u7f8e\u504f\u597d\u3001\u529f\u80fd\u903b\u8f91\u7b49\u9ad8\u5c42\u8868\u793a\uff09\uff0c\u4e2d\u592e\u5143\u89c4\u5212\u5668\u4f5c\u4e3a\u7cfb\u7edf\u67b6\u6784\u5e08\uff0c\u5c06\u6c1b\u56f4\u5206\u89e3\u4e3a\u53ef\u6267\u884c\u3001\u53ef\u9a8c\u8bc1\u3001\u81ea\u9002\u5e94\u7684\u667a\u80fd\u4f53\u6d41\u6c34\u7ebf\u3002", "result": "Vibe AIGC\u901a\u8fc7\u4ece\u968f\u673a\u63a8\u7406\u5411\u903b\u8f91\u7f16\u6392\u7684\u8f6c\u53d8\uff0c\u5f25\u5408\u4e86\u4eba\u7c7b\u60f3\u8c61\u529b\u4e0e\u673a\u5668\u6267\u884c\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u5c06AI\u4ece\u8106\u5f31\u7684\u63a8\u7406\u5f15\u64ce\u8f6c\u53d8\u4e3a\u7a33\u5065\u7684\u7cfb\u7edf\u7ea7\u5de5\u7a0b\u4f19\u4f34\u3002", "conclusion": "\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u5c06\u91cd\u65b0\u5b9a\u4e49\u4eba\u673a\u534f\u4f5c\u7ecf\u6d4e\uff0c\u4f7f\u590d\u6742\u3001\u957f\u89c6\u91ce\u6570\u5b57\u8d44\u4ea7\u7684\u521b\u4f5c\u6c11\u4e3b\u5316\uff0c\u4e3a\u751f\u6210\u5f0fAI\u5f00\u8f9f\u65b0\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2602.04634", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.04634", "abs": "https://arxiv.org/abs/2602.04634", "authors": ["Zelai Xu", "Zhexuan Xu", "Ruize Zhang", "Chunyang Zhu", "Shi Yu", "Weilin Liu", "Quanlu Zhang", "Wenbo Ding", "Chao Yu", "Yu Wang"], "title": "WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faWideSeek-R1\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5bbd\u5ea6\u6269\u5c55\uff08\u5e76\u884c\u6267\u884c\uff09\u800c\u975e\u6df1\u5ea6\u6269\u5c55\u6765\u89e3\u51b3\u5e7f\u6cdb\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\uff0c4B\u53c2\u6570\u6a21\u578b\u6027\u80fd\u5ab2\u7f8e671B\u53c2\u6570\u7684\u6df1\u5ea6\u6269\u5c55\u5355\u667a\u80fd\u4f53\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u6df1\u5ea6\u6269\u5c55\uff08\u5355\u667a\u80fd\u4f53\u89e3\u51b3\u957f\u65f6\u7a0b\u95ee\u9898\uff09\uff0c\u4f46\u968f\u7740\u4efb\u52a1\u8303\u56f4\u6269\u5927\uff0c\u74f6\u9888\u4ece\u4e2a\u4f53\u80fd\u529b\u8f6c\u5411\u7ec4\u7ec7\u80fd\u529b\u3002\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f9d\u8d56\u624b\u5de5\u5de5\u4f5c\u6d41\u548c\u8f6e\u8f6c\u4ea4\u4e92\uff0c\u65e0\u6cd5\u6709\u6548\u5e76\u884c\u5316\u5de5\u4f5c\u3002", "method": "\u63d0\u51faWideSeek-R1\u6846\u67b6\uff0c\u91c7\u7528\u4e3b\u667a\u80fd\u4f53-\u5b50\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u4f7f\u7528\u5171\u4eabLLM\u4f46\u9694\u79bb\u4e0a\u4e0b\u6587\u548c\u4e13\u7528\u5de5\u5177\uff0c\u57282\u4e07\u4e2a\u5e7f\u6cdb\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u6570\u636e\u96c6\u4e0a\u8054\u5408\u4f18\u5316\u4e3b\u667a\u80fd\u4f53\u548c\u5e76\u884c\u5b50\u667a\u80fd\u4f53\u3002", "result": "WideSeek-R1-4B\u5728WideSearch\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523040.0%\u7684\u9879\u76eeF1\u5206\u6570\uff0c\u6027\u80fd\u4e0e\u5355\u667a\u80fd\u4f53DeepSeek-R1-671B\u76f8\u5f53\u3002\u968f\u7740\u5e76\u884c\u5b50\u667a\u80fd\u4f53\u6570\u91cf\u589e\u52a0\uff0c\u6027\u80fd\u6301\u7eed\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u5bbd\u5ea6\u6269\u5c55\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5bbd\u5ea6\u6269\u5c55\u662f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u89e3\u51b3\u5e7f\u6cdb\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u7684\u6709\u6548\u65b9\u5411\uff0c\u901a\u8fc7\u5e76\u884c\u5316\u5de5\u4f5c\u6d41\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6548\u7387\uff0c\u5c0f\u53c2\u6570\u6a21\u578b\u901a\u8fc7\u826f\u597d\u7ec4\u7ec7\u80fd\u8fbe\u5230\u5927\u53c2\u6570\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2602.04813", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.04813", "abs": "https://arxiv.org/abs/2602.04813", "authors": ["Shubham Vatsal", "Harsh Dubey", "Aditi Singh"], "title": "Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents", "comment": null, "summary": "Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully Implemented, Partially Implemented, Not Implemented), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (~76% Fully Implemented) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (~92% Not Implemented) and Drift Detection & Mitigation sub-dimension under Adaptation & Learning is rare (~98% Not Implemented). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (~82% Fully Implemented) while orchestration layers remain mostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question Answering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas such as Treatment Planning & Prescription still show substantial gaps (~59% Not Implemented).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e03\u7ef4\u5206\u7c7b\u6cd5\u6765\u7cfb\u7edf\u8bc4\u4f30\u533b\u7597\u9886\u57dfLLM\u667a\u80fd\u4f53\u7684\u80fd\u529b\u73b0\u72b6\uff0c\u901a\u8fc7\u5206\u679049\u9879\u7814\u7a76\u53d1\u73b0\u80fd\u529b\u5b9e\u73b0\u5b58\u5728\u660e\u663e\u4e0d\u5bf9\u79f0\u6027\u3002", "motivation": "\u5f53\u524d\u533b\u7597\u9886\u57dfLLM\u667a\u80fd\u4f53\u7684\u7814\u7a76\u7f3a\u4e4f\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u73b0\u6709\u6587\u732e\u591a\u4e3a\u5bbd\u6cdb\u7efc\u8ff0\u6216\u5355\u4e00\u80fd\u529b\u6df1\u5165\u5206\u6790\uff0c\u65e0\u6cd5\u4e3a\u533b\u7597\u5de5\u4f5c\u63d0\u4f9b\u5171\u540c\u53c2\u8003\u6807\u51c6\u3002", "method": "\u5efa\u7acb\u4e03\u7ef4\u5206\u7c7b\u6cd5\uff08\u8ba4\u77e5\u80fd\u529b\u3001\u77e5\u8bc6\u7ba1\u7406\u3001\u4ea4\u4e92\u6a21\u5f0f\u3001\u9002\u5e94\u4e0e\u5b66\u4e60\u3001\u5b89\u5168\u4e0e\u4f26\u7406\u3001\u6846\u67b6\u7c7b\u578b\u3001\u6838\u5fc3\u4efb\u52a1\u4e0e\u5b50\u4efb\u52a1\uff09\u517129\u4e2a\u5b50\u7ef4\u5ea6\uff0c\u4f7f\u7528\u660e\u786e\u7eb3\u5165\u6392\u9664\u6807\u51c6\u548c\u6807\u7b7e\u89c4\u5219\uff08\u5b8c\u5168\u5b9e\u73b0\u3001\u90e8\u5206\u5b9e\u73b0\u3001\u672a\u5b9e\u73b0\uff09\uff0c\u5bf949\u9879\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u6620\u5c04\u548c\u5b9a\u91cf\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u80fd\u529b\u5b9e\u73b0\u5b58\u5728\u660e\u663e\u4e0d\u5bf9\u79f0\uff1a\u5916\u90e8\u77e5\u8bc6\u6574\u5408\uff0876%\u5b8c\u5168\u5b9e\u73b0\uff09\u666e\u904d\uff0c\u800c\u4e8b\u4ef6\u89e6\u53d1\u6fc0\u6d3b\uff0892%\u672a\u5b9e\u73b0\uff09\u548c\u6f02\u79fb\u68c0\u6d4b\u4e0e\u7f13\u89e3\uff0898%\u672a\u5b9e\u73b0\uff09\u7f55\u89c1\uff1b\u591a\u667a\u80fd\u4f53\u8bbe\u8ba1\uff0882%\u5b8c\u5168\u5b9e\u73b0\uff09\u662f\u4e3b\u5bfc\u67b6\u6784\u6a21\u5f0f\uff1b\u4fe1\u606f\u4e2d\u5fc3\u80fd\u529b\u9886\u5148\uff0c\u800c\u6cbb\u7597\u89c4\u5212\u4e0e\u5904\u65b9\u7b49\u884c\u52a8\u5bfc\u5411\u9886\u57df\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\uff0859%\u672a\u5b9e\u73b0\uff09\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u533b\u7597LLM\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u80fd\u529b\u5b9e\u73b0\u7684\u5206\u5e03\u6a21\u5f0f\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u548c\u80fd\u529b\u53d1\u5c55\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2602.04836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04836", "abs": "https://arxiv.org/abs/2602.04836", "authors": ["Haosen Ge", "Hamsa Bastani", "Osbert Bastani"], "title": "Are AI Capabilities Increasing Exponentially? A Competing Hypothesis", "comment": null, "summary": "Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53cd\u9a73METR\u62a5\u544a\u4e2dAI\u80fd\u529b\u5448\u6307\u6570\u589e\u957f\u7684\u89c2\u70b9\uff0c\u8ba4\u4e3a\u6570\u636e\u4e0d\u652f\u6301\u6307\u6570\u589e\u957f\uff0c\u5e76\u8bc1\u660e\u62d0\u70b9\u5df2\u8fc7\uff0c\u5f3a\u8c03\u73b0\u6709\u6307\u6570\u589e\u957f\u9884\u6d4b\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u9488\u5bf9METR\u62a5\u544a\u58f0\u79f0AI\u80fd\u529b\u81ea2019\u5e74\u4ee5\u6765\u5448\u6307\u6570\u589e\u957f\u7684\u89c2\u70b9\uff0c\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u9884\u6d4b\u7f3a\u4e4f\u6570\u636e\u652f\u6301\uff0c\u9700\u8981\u66f4\u4e25\u8c28\u7684\u5206\u6790\u6765\u63ed\u793a\u73b0\u6709\u9884\u6d4b\u7684\u8106\u5f31\u6027\u3002", "method": "1. \u4f7f\u7528METR\u76f8\u540c\u7684\u6570\u636e\u62df\u5408S\u578b\u66f2\u7ebf\uff0c\u53d1\u73b0\u62d0\u70b9\u5df2\u8fc7\uff1b2. \u63d0\u51fa\u66f4\u590d\u6742\u7684\u6a21\u578b\uff0c\u5c06AI\u80fd\u529b\u5206\u89e3\u4e3a\u57fa\u7840\u80fd\u529b\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5206\u522b\u5206\u6790\u5176\u6539\u8fdb\u901f\u7387\u3002", "result": "1. \u4e0eMETR\u7ed3\u8bba\u76f8\u53cd\uff0cS\u578b\u66f2\u7ebf\u62df\u5408\u663e\u793aAI\u80fd\u529b\u589e\u957f\u7684\u62d0\u70b9\u5df2\u7ecf\u8fc7\u53bb\uff1b2. \u590d\u6742\u6a21\u578b\u652f\u6301AI\u80fd\u529b\u5c06\u5728\u8fd1\u671f\u51fa\u73b0\u62d0\u70b9\u7684\u5047\u8bbe\u3002", "conclusion": "AI\u80fd\u529b\u5e76\u672a\u5448\u73b0\u6307\u6570\u589e\u957f\uff0c\u73b0\u6709\u5173\u4e8e\u6307\u6570\u589e\u957f\u7684\u9884\u6d4b\u662f\u8106\u5f31\u7684\u3002\u7814\u7a76\u76ee\u7684\u4e0d\u662f\u5efa\u7acb\u81ea\u5df1\u7684\u4e25\u8c28\u9884\u6d4b\uff0c\u800c\u662f\u63ed\u793a\u73b0\u6709\u9884\u6d4b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.04837", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04837", "abs": "https://arxiv.org/abs/2602.04837", "authors": ["Zhaotian Weng", "Antonis Antoniades", "Deepak Nathani", "Zhen Zhang", "Xiao Pu", "Xin Eric Wang"], "title": "Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing", "comment": "18 pages", "summary": "Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.", "AI": {"tldr": "GEA\uff08\u7fa4\u4f53\u6f14\u5316\u667a\u80fd\u4f53\uff09\u662f\u4e00\u79cd\u65b0\u578b\u5f00\u653e\u7aef\u81ea\u6539\u8fdb\u8303\u5f0f\uff0c\u5c06\u667a\u80fd\u4f53\u7fa4\u4f53\u4f5c\u4e3a\u57fa\u672c\u6f14\u5316\u5355\u5143\uff0c\u5b9e\u73b0\u7fa4\u4f53\u5185\u7ecf\u9a8c\u5171\u4eab\u548c\u91cd\u7528\uff0c\u663e\u8457\u63d0\u5347\u7f16\u7801\u4efb\u52a1\u6027\u80fd\uff0c\u8d85\u8d8a\u73b0\u6709\u81ea\u6f14\u5316\u65b9\u6cd5\u5e76\u5ab2\u7f8e\u4eba\u7c7b\u8bbe\u8ba1\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u5f00\u653e\u7aef\u81ea\u6f14\u5316\u65b9\u6cd5\u91c7\u7528\u6811\u72b6\u7ed3\u6784\u6f14\u5316\uff0c\u5bfc\u81f4\u63a2\u7d22\u591a\u6837\u6027\u5229\u7528\u6548\u7387\u4f4e\u4e0b\uff0c\u5404\u6f14\u5316\u5206\u652f\u5b64\u7acb\uff0c\u65e0\u6cd5\u6709\u6548\u5171\u4eab\u7ecf\u9a8c\u3002\u9700\u8981\u4e00\u79cd\u65b0\u8303\u5f0f\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u81ea\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u7fa4\u4f53\u6f14\u5316\u667a\u80fd\u4f53\uff08GEA\uff09\u8303\u5f0f\uff0c\u5c06\u667a\u80fd\u4f53\u7fa4\u4f53\u4f5c\u4e3a\u57fa\u672c\u6f14\u5316\u5355\u5143\uff0c\u5728\u6f14\u5316\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u663e\u5f0f\u7684\u7ecf\u9a8c\u5171\u4eab\u548c\u91cd\u7528\u3002\u4e0d\u540c\u4e8e\u4f20\u7edf\u6811\u72b6\u7ed3\u6784\u6f14\u5316\uff0cGEA\u901a\u8fc7\u7fa4\u4f53\u534f\u4f5c\u514b\u670d\u5b64\u7acb\u5206\u652f\u7684\u9650\u5236\u3002", "result": "\u5728\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u81ea\u6f14\u5316\u65b9\u6cd5\uff08SWE-bench Verified\uff1a71.0% vs. 56.7%\uff1bPolyglot\uff1a88.3% vs. 68.3%\uff09\uff0c\u6027\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u9876\u7ea7\u4eba\u7c7b\u8bbe\u8ba1\u6846\u67b6\u3002\u80fd\u66f4\u6709\u6548\u5c06\u65e9\u671f\u63a2\u7d22\u591a\u6837\u6027\u8f6c\u5316\u4e3a\u957f\u671f\u8fdb\u6b65\uff0c\u5728\u4e0d\u540c\u7f16\u7801\u6a21\u578b\u95f4\u5177\u6709\u4e00\u81f4\u53ef\u8fc1\u79fb\u6027\uff0c\u4fee\u590d\u6846\u67b6\u7ea7bug\u5e73\u5747\u53ea\u97001.4\u6b21\u8fed\u4ee3\uff08\u81ea\u6f14\u5316\u65b9\u6cd5\u97005\u6b21\uff09\u3002", "conclusion": "GEA\u901a\u8fc7\u7fa4\u4f53\u4f5c\u4e3a\u6f14\u5316\u5355\u5143\u7684\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u7ecf\u9a8c\u5171\u4eab\u548c\u63a2\u7d22\u591a\u6837\u6027\u5229\u7528\uff0c\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5353\u8d8a\u6027\u80fd\u3001\u53ef\u8fc1\u79fb\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u5f00\u653e\u7aef\u81ea\u6539\u8fdb\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04843", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04843", "abs": "https://arxiv.org/abs/2602.04843", "authors": ["Dmitrii Kharlapenko", "Alessandro Stolfo", "Arthur Conmy", "Mrinmaya Sachan", "Zhijing Jin"], "title": "Fluid Representations in Reasoning Models", "comment": null, "summary": "Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural information. On Mystery Blocksworld - a semantically obfuscated planning domain - we find that QwQ-32B gradually improves its internal representation of actions and concepts during reasoning. The model develops abstract encodings that focus on structure rather than specific action names. Through steering experiments, we establish causal evidence that these adaptations improve problem solving: injecting refined representations from successful traces boosts accuracy, while symbolic representations can replace many obfuscated encodings with minimal performance loss. We find that one of the factors driving reasoning model performance is in-context refinement of token representations, which we dub Fluid Reasoning Representations.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u7cbe\u70bctoken\u8868\u793a\u6765\u63d0\u5347\u62bd\u8c61\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u8fd9\u79cd\u673a\u5236\u88ab\u79f0\u4e3a\"\u6d41\u4f53\u63a8\u7406\u8868\u793a\"", "motivation": "\u5c3d\u7ba1\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u5728\u62bd\u8c61\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u4ecd\u4e0d\u6e05\u695a\u3002\u7814\u7a76\u8005\u5e0c\u671b\u7406\u89e3QwQ-32B\u6a21\u578b\u5982\u4f55\u5904\u7406\u62bd\u8c61\u7ed3\u6784\u4fe1\u606f\uff0c\u7279\u522b\u662f\u5b83\u5982\u4f55\u901a\u8fc7\u751f\u6210\u957f\u63a8\u7406\u94fe\u6765\u63d0\u5347\u6027\u80fd\u3002", "method": "\u5728\u8bed\u4e49\u6df7\u6dc6\u7684\u89c4\u5212\u9886\u57dfMystery Blocksworld\u4e0a\u5bf9QwQ-32B\u8fdb\u884c\u673a\u5236\u5206\u6790\uff0c\u901a\u8fc7\u8f6c\u5411\u5b9e\u9a8c\u5efa\u7acb\u56e0\u679c\u8bc1\u636e\uff0c\u7814\u7a76\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5982\u4f55\u6539\u8fdb\u52a8\u4f5c\u548c\u6982\u5ff5\u7684\u5185\u90e8\u8868\u793a\u3002", "result": "\u53d1\u73b0QwQ-32B\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9010\u6e10\u6539\u8fdb\u52a8\u4f5c\u548c\u6982\u5ff5\u7684\u5185\u90e8\u8868\u793a\uff0c\u53d1\u5c55\u51fa\u5173\u6ce8\u7ed3\u6784\u800c\u975e\u5177\u4f53\u52a8\u4f5c\u540d\u79f0\u7684\u62bd\u8c61\u7f16\u7801\u3002\u6ce8\u5165\u6210\u529f\u8f68\u8ff9\u4e2d\u7684\u7cbe\u70bc\u8868\u793a\u80fd\u63d0\u5347\u51c6\u786e\u6027\uff0c\u800c\u7b26\u53f7\u8868\u793a\u53ef\u4ee5\u66ff\u6362\u8bb8\u591a\u6df7\u6dc6\u7f16\u7801\u4e14\u6027\u80fd\u635f\u5931\u6700\u5c0f\u3002", "conclusion": "\u63a8\u7406\u6a21\u578b\u6027\u80fd\u7684\u4e00\u4e2a\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u662f\u5728\u4e0a\u4e0b\u6587\u7cbe\u70bctoken\u8868\u793a\uff0c\u5373\"\u6d41\u4f53\u63a8\u7406\u8868\u793a\"\u3002\u8fd9\u4e9b\u9002\u5e94\u6539\u8fdb\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4e3a\u7406\u89e3\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u4f5c\u673a\u5236\u63d0\u4f9b\u4e86\u673a\u5236\u6027\u8bc1\u636e\u3002"}}
