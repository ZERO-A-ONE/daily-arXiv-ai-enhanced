{"id": "2602.10134", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10134", "abs": "https://arxiv.org/abs/2602.10134", "authors": ["Zhiyu Sun", "Minrui Luo", "Yu Wang", "Zhili Chen", "Tianxing He"], "title": "Reverse-Engineering Model Editing on Language Models", "comment": null, "summary": "Large language models (LLMs) are pretrained on corpora containing trillions of tokens and, therefore, inevitably memorize sensitive information. Locate-then-edit methods, as a mainstream paradigm of model editing, offer a promising solution by modifying model parameters without retraining. However, in this work, we reveal a critical vulnerability of this paradigm: the parameter updates inadvertently serve as a side channel, enabling attackers to recover the edited data. We propose a two-stage reverse-engineering attack named \\textit{KSTER} (\\textbf{K}ey\\textbf{S}paceRecons\\textbf{T}ruction-then-\\textbf{E}ntropy\\textbf{R}eduction) that leverages the low-rank structure of these updates. First, we theoretically show that the row space of the update matrix encodes a ``fingerprint\" of the edited subjects, enabling accurate subject recovery via spectral analysis. Second, we introduce an entropy-based prompt recovery attack that reconstructs the semantic context of the edit. Extensive experiments on multiple LLMs demonstrate that our attacks can recover edited data with high success rates. Furthermore, we propose \\textit{subspace camouflage}, a defense strategy that obfuscates the update fingerprint with semantic decoys. This approach effectively mitigates reconstruction risks without compromising editing utility. Our code is available at https://github.com/reanatom/EditingAtk.git.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff1a\u53c2\u6570\u66f4\u65b0\u4f1a\u6cc4\u9732\u88ab\u7f16\u8f91\u7684\u654f\u611f\u6570\u636e\uff0c\u5e76\u63d0\u51faKSTER\u653b\u51fb\u65b9\u6cd5\u4ece\u7f16\u8f91\u66f4\u65b0\u4e2d\u6062\u590d\u539f\u59cb\u6570\u636e\uff0c\u540c\u65f6\u63d0\u51fa\u5b50\u7a7a\u95f4\u4f2a\u88c5\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f1a\u8bb0\u5fc6\u654f\u611f\u4fe1\u606f\uff0c\u5b9a\u4f4d\u540e\u7f16\u8f91\u65b9\u6cd5\u4f5c\u4e3a\u4e3b\u6d41\u6a21\u578b\u7f16\u8f91\u8303\u5f0f\uff0c\u901a\u8fc7\u4fee\u6539\u6a21\u578b\u53c2\u6570\u800c\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6765\u89e3\u51b3\u95ee\u9898\u3002\u7136\u800c\uff0c\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u8303\u5f0f\u5b58\u5728\u5173\u952e\u6f0f\u6d1e\uff1a\u53c2\u6570\u66f4\u65b0\u4f1a\u65e0\u610f\u4e2d\u6210\u4e3a\u4fa7\u4fe1\u9053\uff0c\u4f7f\u653b\u51fb\u8005\u80fd\u591f\u6062\u590d\u88ab\u7f16\u8f91\u7684\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u9006\u5411\u5de5\u7a0b\u653b\u51fbKSTER\uff1a1\uff09\u5229\u7528\u66f4\u65b0\u77e9\u9635\u7684\u4f4e\u79e9\u7ed3\u6784\uff0c\u901a\u8fc7\u8c31\u5206\u6790\u4ece\u66f4\u65b0\u77e9\u9635\u7684\u884c\u7a7a\u95f4\u6062\u590d\u7f16\u8f91\u4e3b\u9898\uff1b2\uff09\u5f15\u5165\u57fa\u4e8e\u71b5\u7684\u63d0\u793a\u6062\u590d\u653b\u51fb\uff0c\u91cd\u5efa\u7f16\u8f91\u7684\u8bed\u4e49\u4e0a\u4e0b\u6587\u3002\u540c\u65f6\u63d0\u51fa\u5b50\u7a7a\u95f4\u4f2a\u88c5\u9632\u5fa1\u7b56\u7565\uff0c\u7528\u8bed\u4e49\u8bf1\u9975\u6df7\u6dc6\u66f4\u65b0\u6307\u7eb9\u3002", "result": "\u5728\u591a\u4e2aLLM\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u653b\u51fb\u80fd\u591f\u4ee5\u9ad8\u6210\u529f\u7387\u6062\u590d\u88ab\u7f16\u8f91\u7684\u6570\u636e\u3002\u63d0\u51fa\u7684\u5b50\u7a7a\u95f4\u4f2a\u88c5\u9632\u5fa1\u7b56\u7565\u5728\u4e0d\u5f71\u54cd\u7f16\u8f91\u6548\u7528\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u91cd\u5efa\u98ce\u9669\u3002", "conclusion": "\u5b9a\u4f4d\u540e\u7f16\u8f91\u8303\u5f0f\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u53c2\u6570\u66f4\u65b0\u4f1a\u6cc4\u9732\u654f\u611f\u4fe1\u606f\u3002KSTER\u653b\u51fb\u80fd\u591f\u6709\u6548\u4ece\u7f16\u8f91\u66f4\u65b0\u4e2d\u6062\u590d\u539f\u59cb\u6570\u636e\uff0c\u800c\u5b50\u7a7a\u95f4\u4f2a\u88c5\u9632\u5fa1\u7b56\u7565\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4fdd\u62a4\u673a\u5236\uff0c\u5e73\u8861\u4e86\u5b89\u5168\u6027\u548c\u7f16\u8f91\u6548\u7528\u3002"}}
{"id": "2602.10142", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.10142", "abs": "https://arxiv.org/abs/2602.10142", "authors": ["Molly Campbell", "Ajay Kumar Shrestha"], "title": "Privacy by Voice: Modeling Youth Privacy-Protective Behavior in Smart Voice Assistants", "comment": "To appear in the IEEE ICAIIC 2026 proceedings", "summary": "Smart Voice Assistants (SVAs) are deeply embedded in the lives of youth, yet the mechanisms driving the privacy-protective behaviors among young users remain poorly understood. This study investigates how Canadian youth (aged 16-24) negotiate privacy with SVAs by developing and testing a structural model grounded in five key constructs: perceived privacy risks (PPR), perceived benefits (PPBf), algorithmic transparency and trust (ATT), privacy self-efficacy (PSE), and privacy-protective behaviors (PPB). A cross-sectional survey of N=469 youth was analyzed using partial least squares structural equation modeling. Results reveal that PSE is the strongest predictor of PPB, while the effect of ATT on PPB is fully mediated by PSE. This identifies a critical efficacy gap, where youth's confidence must first be built up for them to act. The model confirms that PPBf directly discourages protective action, yet also indirectly fosters it by slightly boosting self-efficacy. These findings empirically validate and extend earlier qualitative work, quantifying how policy overload and hidden controls erode the self-efficacy necessary for protective action. This study contributes an evidence-based pathway from perception to action and translates it into design imperatives that empower young digital citizens without sacrificing the utility of SVAs.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u5206\u6790\u52a0\u62ff\u5927\u9752\u5c11\u5e74\uff0816-24\u5c81\uff09\u4e0e\u667a\u80fd\u8bed\u97f3\u52a9\u624b\u7684\u9690\u79c1\u534f\u5546\u673a\u5236\uff0c\u53d1\u73b0\u9690\u79c1\u81ea\u6211\u6548\u80fd\u662f\u9690\u79c1\u4fdd\u62a4\u884c\u4e3a\u7684\u6700\u5f3a\u9884\u6d4b\u56e0\u5b50\uff0c\u7b97\u6cd5\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u901a\u8fc7\u81ea\u6211\u6548\u80fd\u5b8c\u5168\u4e2d\u4ecb\u5f71\u54cd\u4fdd\u62a4\u884c\u4e3a\u3002", "motivation": "\u667a\u80fd\u8bed\u97f3\u52a9\u624b\u5df2\u6df1\u5ea6\u878d\u5165\u9752\u5c11\u5e74\u751f\u6d3b\uff0c\u4f46\u9752\u5c11\u5e74\u7528\u6237\u9690\u79c1\u4fdd\u62a4\u884c\u4e3a\u7684\u9a71\u52a8\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u52a0\u62ff\u5927\u9752\u5c11\u5e74\u5982\u4f55\u4e0e\u667a\u80fd\u8bed\u97f3\u52a9\u624b\u534f\u5546\u9690\u79c1\uff0c\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u7814\u7a76\u57fa\u4e8e\u4e94\u4e2a\u5173\u952e\u6784\u5ff5\u6784\u5efa\u7ed3\u6784\u6a21\u578b\uff1a\u611f\u77e5\u9690\u79c1\u98ce\u9669\u3001\u611f\u77e5\u5229\u76ca\u3001\u7b97\u6cd5\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u3001\u9690\u79c1\u81ea\u6211\u6548\u80fd\u3001\u9690\u79c1\u4fdd\u62a4\u884c\u4e3a\u3002\u91c7\u7528\u6a2a\u65ad\u9762\u8c03\u67e5\uff08N=469\u540d\u9752\u5c11\u5e74\uff09\uff0c\u4f7f\u7528\u504f\u6700\u5c0f\u4e8c\u4e58\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a\u9690\u79c1\u81ea\u6211\u6548\u80fd\u662f\u9690\u79c1\u4fdd\u62a4\u884c\u4e3a\u7684\u6700\u5f3a\u9884\u6d4b\u56e0\u5b50\uff1b\u7b97\u6cd5\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u5bf9\u4fdd\u62a4\u884c\u4e3a\u7684\u5f71\u54cd\u5b8c\u5168\u7531\u81ea\u6211\u6548\u80fd\u4e2d\u4ecb\uff1b\u611f\u77e5\u5229\u76ca\u76f4\u63a5\u6291\u5236\u4fdd\u62a4\u884c\u4e3a\uff0c\u4f46\u901a\u8fc7\u8f7b\u5fae\u63d0\u5347\u81ea\u6211\u6548\u80fd\u95f4\u63a5\u4fc3\u8fdb\u4fdd\u62a4\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u5b9e\u8bc1\u9a8c\u8bc1\u5e76\u6269\u5c55\u4e86\u65e9\u671f\u5b9a\u6027\u7814\u7a76\uff0c\u91cf\u5316\u4e86\u653f\u7b56\u8fc7\u8f7d\u548c\u9690\u85cf\u63a7\u5236\u5982\u4f55\u4fb5\u8680\u4fdd\u62a4\u884c\u4e3a\u6240\u9700\u7684\u81ea\u6211\u6548\u80fd\u3002\u63d0\u51fa\u4e86\u4ece\u611f\u77e5\u5230\u884c\u52a8\u7684\u5faa\u8bc1\u8def\u5f84\uff0c\u5e76\u8f6c\u5316\u4e3a\u8bbe\u8ba1\u539f\u5219\uff0c\u65e8\u5728\u4e0d\u727a\u7272\u667a\u80fd\u8bed\u97f3\u52a9\u624b\u5b9e\u7528\u6027\u7684\u524d\u63d0\u4e0b\u589e\u5f3a\u9752\u5c11\u5e74\u6570\u5b57\u516c\u6c11\u7684\u8d4b\u6743\u3002"}}
{"id": "2602.10148", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10148", "abs": "https://arxiv.org/abs/2602.10148", "authors": ["Yu Yan", "Sheng Sun", "Shengjia Cheng", "Teli Liu", "Mingfeng Li", "Min Liu"], "title": "Red-teaming the Multimodal Reasoning: Jailbreaking Vision-Language Models via Cross-modal Entanglement Attacks", "comment": null, "summary": "Vision-Language Models (VLMs) with multimodal reasoning capabilities are high-value attack targets, given their potential for handling complex multimodal harmful tasks. Mainstream black-box jailbreak attacks on VLMs work by distributing malicious clues across modalities to disperse model attention and bypass safety alignment mechanisms. However, these adversarial attacks rely on simple and fixed image-text combinations that lack attack complexity scalability, limiting their effectiveness for red-teaming VLMs' continuously evolving reasoning capabilities. We propose \\textbf{CrossTALK} (\\textbf{\\underline{Cross}}-modal en\\textbf{\\underline{TA}}ng\\textbf{\\underline{L}}ement attac\\textbf{\\underline{K}}), which is a scalable approach that extends and entangles information clues across modalities to exceed VLMs' trained and generalized safety alignment patterns for jailbreak. Specifically, {knowledge-scalable reframing} extends harmful tasks into multi-hop chain instructions, {cross-modal clue entangling} migrates visualizable entities into images to build multimodal reasoning links, and {cross-modal scenario nesting} uses multimodal contextual instructions to steer VLMs toward detailed harmful outputs. Experiments show our COMET achieves state-of-the-art attack success rate.", "AI": {"tldr": "CrossTALK\u662f\u4e00\u79cd\u9488\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u6269\u5c55\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u4fe1\u606f\u7ea0\u7f20\u6765\u7a81\u7834\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u673a\u5236", "motivation": "\u73b0\u6709\u7684\u9ed1\u76d2\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\u4f7f\u7528\u7b80\u5355\u56fa\u5b9a\u7684\u56fe\u50cf-\u6587\u672c\u7ec4\u5408\uff0c\u7f3a\u4e4f\u653b\u51fb\u590d\u6742\u6027\u53ef\u6269\u5c55\u6027\uff0c\u96be\u4ee5\u5e94\u5bf9VLM\u4e0d\u65ad\u53d1\u5c55\u7684\u63a8\u7406\u80fd\u529b\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5", "method": "\u63d0\u51faCrossTALK\u65b9\u6cd5\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a1) \u77e5\u8bc6\u53ef\u6269\u5c55\u91cd\u6784\uff0c\u5c06\u6709\u5bb3\u4efb\u52a1\u6269\u5c55\u4e3a\u591a\u8df3\u94fe\u5f0f\u6307\u4ee4\uff1b2) \u8de8\u6a21\u6001\u7ebf\u7d22\u7ea0\u7f20\uff0c\u5c06\u53ef\u89c6\u5316\u5b9e\u4f53\u8fc1\u79fb\u5230\u56fe\u50cf\u4e2d\u5efa\u7acb\u591a\u6a21\u6001\u63a8\u7406\u94fe\u63a5\uff1b3) \u8de8\u6a21\u6001\u573a\u666f\u5d4c\u5957\uff0c\u4f7f\u7528\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u6307\u4ee4\u5f15\u5bfcVLM\u751f\u6210\u8be6\u7ec6\u6709\u5bb3\u8f93\u51fa", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u653b\u51fb\u6210\u529f\u7387", "conclusion": "CrossTALK\u901a\u8fc7\u8de8\u6a21\u6001\u4fe1\u606f\u7ea0\u7f20\u7684\u53ef\u6269\u5c55\u653b\u51fb\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u7a81\u7834VLM\u8bad\u7ec3\u548c\u6cdb\u5316\u7684\u5b89\u5168\u5bf9\u9f50\u6a21\u5f0f\uff0c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbVLM\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177"}}
{"id": "2602.10367", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10367", "abs": "https://arxiv.org/abs/2602.10367", "authors": ["Zhiling Yan", "Dingjie Song", "Zhe Fang", "Yisheng Ji", "Xiang Li", "Quanzheng Li", "Lichao Sun"], "title": "LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation", "comment": null, "summary": "The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reasoning often rely on either shallow lexical overlap (e.g., ROUGE) or subjective LLM-as-a-Judge scoring, both inadequate for verifying clinical correctness. To bridge these gaps, we introduce LiveMedBench, a continuously updated, contamination-free, and rubric-based benchmark that weekly harvests real-world clinical cases from online medical communities, ensuring strict temporal separation from model training data. We propose a Multi-Agent Clinical Curation Framework that filters raw data noise and validates clinical integrity against evidence-based medical principles. For evaluation, we develop an Automated Rubric-based Evaluation Framework that decomposes physician responses into granular, case-specific criteria, achieving substantially stronger alignment with expert physicians than LLM-as-a-Judge. To date, LiveMedBench comprises 2,756 real-world cases spanning 38 medical specialties and multiple languages, paired with 16,702 unique evaluation criteria. Extensive evaluation of 38 LLMs reveals that even the best-performing model achieves only 39.2%, and 84% of models exhibit performance degradation on post-cutoff cases, confirming pervasive data contamination risks. Error analysis further identifies contextual application-not factual knowledge-as the dominant bottleneck, with 35-48% of failures stemming from the inability to tailor medical knowledge to patient-specific constraints.", "AI": {"tldr": "LiveMedBench\u662f\u4e00\u4e2a\u6301\u7eed\u66f4\u65b0\u7684\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u6bcf\u5468\u6536\u96c6\u771f\u5b9e\u4e34\u5e8a\u75c5\u4f8b\u89e3\u51b3\u6570\u636e\u6c61\u67d3\u548c\u65f6\u95f4\u9519\u4f4d\u95ee\u9898\uff0c\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\u8fdb\u884c\u6570\u636e\u6e05\u6d17\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u8bc4\u4f30\uff0c\u53d1\u73b0LLMs\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u5b58\u5728\u663e\u8457\u6027\u80fd\u74f6\u9888\u3002", "motivation": "\u73b0\u6709\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a1\uff09\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u6d4b\u8bd5\u96c6\u53ef\u80fd\u6cc4\u9732\u5230\u8bad\u7ec3\u6570\u636e\u4e2d\u5bfc\u81f4\u6027\u80fd\u865a\u9ad8\uff1b2\uff09\u65f6\u95f4\u9519\u4f4d\u95ee\u9898\uff0c\u65e0\u6cd5\u6355\u6349\u533b\u5b66\u77e5\u8bc6\u7684\u5feb\u901f\u6f14\u53d8\u3002\u6b64\u5916\uff0c\u5f53\u524d\u8bc4\u4f30\u6307\u6807\u8981\u4e48\u4f9d\u8d56\u6d45\u5c42\u8bcd\u6c47\u91cd\u53e0\uff0c\u8981\u4e48\u4f9d\u8d56\u4e3b\u89c2\u7684LLM\u8bc4\u5206\uff0c\u90fd\u4e0d\u8db3\u4ee5\u9a8c\u8bc1\u4e34\u5e8a\u6b63\u786e\u6027\u3002", "method": "\u63d0\u51faLiveMedBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bcf\u5468\u4ece\u5728\u7ebf\u533b\u5b66\u793e\u533a\u6536\u96c6\u771f\u5b9e\u4e34\u5e8a\u75c5\u4f8b\uff0c\u786e\u4fdd\u4e0e\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u7684\u4e25\u683c\u65f6\u95f4\u5206\u79bb\u3002\u91c7\u7528\u591a\u667a\u80fd\u4f53\u4e34\u5e8a\u7ba1\u7406\u6846\u67b6\u8fc7\u6ee4\u539f\u59cb\u6570\u636e\u566a\u58f0\uff0c\u5e76\u57fa\u4e8e\u5faa\u8bc1\u533b\u5b66\u539f\u5219\u9a8c\u8bc1\u4e34\u5e8a\u5b8c\u6574\u6027\u3002\u5f00\u53d1\u81ea\u52a8\u5316\u57fa\u4e8e\u89c4\u5219\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u533b\u751f\u56de\u7b54\u5206\u89e3\u4e3a\u7ec6\u7c92\u5ea6\u7684\u75c5\u4f8b\u7279\u5b9a\u6807\u51c6\u3002", "result": "LiveMedBench\u5305\u542b2,756\u4e2a\u771f\u5b9e\u75c5\u4f8b\uff0c\u6db5\u76d638\u4e2a\u533b\u5b66\u4e13\u4e1a\u548c\u591a\u79cd\u8bed\u8a00\uff0c\u914d\u670916,702\u4e2a\u72ec\u7279\u8bc4\u4f30\u6807\u51c6\u3002\u5bf938\u4e2aLLMs\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u6700\u4f73\u6a21\u578b\u4ec5\u8fbe\u523039.2%\u7684\u51c6\u786e\u7387\uff0c84%\u7684\u6a21\u578b\u5728\u622a\u6b62\u65e5\u671f\u540e\u7684\u75c5\u4f8b\u4e0a\u8868\u73b0\u4e0b\u964d\uff0c\u8bc1\u5b9e\u4e86\u666e\u904d\u7684\u6570\u636e\u6c61\u67d3\u98ce\u9669\u3002\u9519\u8bef\u5206\u6790\u8868\u660e35-48%\u7684\u5931\u8d25\u6e90\u4e8e\u65e0\u6cd5\u5c06\u533b\u5b66\u77e5\u8bc6\u9002\u5e94\u5230\u60a3\u8005\u7279\u5b9a\u7ea6\u675f\u3002", "conclusion": "LiveMedBench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6301\u7eed\u66f4\u65b0\u3001\u65e0\u6570\u636e\u6c61\u67d3\u7684\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86LLMs\u5728\u4e34\u5e8a\u63a8\u7406\u4e2d\u7684\u4e3b\u8981\u74f6\u9888\u4e0d\u662f\u4e8b\u5b9e\u77e5\u8bc6\uff0c\u800c\u662f\u5c06\u77e5\u8bc6\u9002\u5e94\u5230\u5177\u4f53\u60a3\u8005\u60c5\u5883\u7684\u80fd\u529b\u3002\u8be5\u57fa\u51c6\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30LLMs\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\u3002"}}
{"id": "2602.10153", "categories": ["cs.CR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10153", "abs": "https://arxiv.org/abs/2602.10153", "authors": ["Ashwin Sreevatsa", "Sebastian Prasanna", "Cody Rushing"], "title": "Basic Legibility Protocols Improve Trusted Monitoring", "comment": null, "summary": "The AI Control research agenda aims to develop control protocols: safety techniques that prevent untrusted AI systems from taking harmful actions during deployment. Because human oversight is expensive, one approach is trusted monitoring, where weaker, trusted models oversee stronger, untrusted models$\\unicode{x2013}$but this often fails when the untrusted model's actions exceed the monitor's comprehension. We introduce legibility protocols, which encourage the untrusted model to take actions that are easier for a monitor to evaluate.\n  We perform control evaluations in the APPS coding setting, where an adversarial agent attempts to write backdoored code without detection. We study legibility protocols that allow the untrusted model to thoroughly document its code with comments$\\unicode{x2013}$in contrast to prior work, which removed comments to prevent deceptive ones. We find that: (i) commenting protocols improve safety without sacrificing task performance relative to comment-removal baselines; (ii) commenting disproportionately benefits honest code, which typically has a natural explanation that resolves monitor suspicion, whereas backdoored code frequently lacks an easy justification; (iii) gains from commenting increase with monitor strength, as stronger monitors better distinguish genuine justifications from only superficially plausible ones.", "AI": {"tldr": "AI\u63a7\u5236\u7814\u7a76\u63d0\u51fa\u53ef\u8bfb\u6027\u534f\u8bae\uff0c\u901a\u8fc7\u8ba9\u4e0d\u53ef\u4fe1AI\u6a21\u578b\u7528\u6ce8\u91ca\u5145\u5206\u8bb0\u5f55\u4ee3\u7801\uff0c\u5e2e\u52a9\u8f83\u5f31\u4f46\u53ef\u4fe1\u7684\u76d1\u63a7\u6a21\u578b\u66f4\u597d\u5730\u8bc4\u4f30\u5176\u884c\u4e3a\uff0c\u5728APPS\u7f16\u7801\u73af\u5883\u4e2d\u63d0\u9ad8\u5b89\u5168\u6027\u800c\u4e0d\u727a\u7272\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u53ef\u4fe1\u76d1\u63a7\u65b9\u6cd5\u4e2d\uff0c\u8f83\u5f31\u4f46\u53ef\u4fe1\u7684\u6a21\u578b\u76d1\u63a7\u8f83\u5f3a\u4f46\u4e0d\u53ef\u4fe1\u7684\u6a21\u578b\uff0c\u4f46\u5f53\u4e0d\u53ef\u4fe1\u6a21\u578b\u7684\u884c\u4e3a\u8d85\u51fa\u76d1\u63a7\u6a21\u578b\u7684\u7406\u89e3\u8303\u56f4\u65f6\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4f1a\u5931\u6548\u3002\u9700\u8981\u5f00\u53d1\u65b0\u7684\u63a7\u5236\u534f\u8bae\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f15\u5165\u53ef\u8bfb\u6027\u534f\u8bae\uff0c\u9f13\u52b1\u4e0d\u53ef\u4fe1\u6a21\u578b\u91c7\u53d6\u66f4\u5bb9\u6613\u88ab\u76d1\u63a7\u6a21\u578b\u8bc4\u4f30\u7684\u884c\u52a8\u3002\u5728APPS\u7f16\u7801\u73af\u5883\u4e2d\u8fdb\u884c\u63a7\u5236\u8bc4\u4f30\uff0c\u8ba9\u4e0d\u53ef\u4fe1\u6a21\u578b\u901a\u8fc7\u8be6\u7ec6\u6ce8\u91ca\u6765\u8bb0\u5f55\u4ee3\u7801\uff0c\u4e0e\u4e4b\u524d\u5220\u9664\u6ce8\u91ca\u4ee5\u9632\u6b62\u6b3a\u9a97\u6027\u6ce8\u91ca\u7684\u65b9\u6cd5\u5f62\u6210\u5bf9\u6bd4\u3002", "result": "1) \u6ce8\u91ca\u534f\u8bae\u76f8\u6bd4\u5220\u9664\u6ce8\u91ca\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4e0d\u727a\u7272\u4efb\u52a1\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\uff1b2) \u6ce8\u91ca\u5bf9\u8bda\u5b9e\u4ee3\u7801\u7684\u76ca\u5904\u66f4\u5927\uff0c\u56e0\u4e3a\u8bda\u5b9e\u4ee3\u7801\u901a\u5e38\u6709\u81ea\u7136\u7684\u89e3\u91ca\u53ef\u4ee5\u6d88\u9664\u76d1\u63a7\u6000\u7591\uff0c\u800c\u540e\u95e8\u4ee3\u7801\u5f80\u5f80\u7f3a\u4e4f\u5408\u7406\u7684\u89e3\u91ca\uff1b3) \u6ce8\u91ca\u5e26\u6765\u7684\u6536\u76ca\u968f\u76d1\u63a7\u6a21\u578b\u5f3a\u5ea6\u589e\u52a0\u800c\u589e\u52a0\uff0c\u56e0\u4e3a\u66f4\u5f3a\u7684\u76d1\u63a7\u6a21\u578b\u80fd\u66f4\u597d\u5730\u533a\u5206\u771f\u5b9e\u89e3\u91ca\u548c\u8868\u9762\u5408\u7406\u7684\u89e3\u91ca\u3002", "conclusion": "\u53ef\u8bfb\u6027\u534f\u8bae\u662f\u4e00\u79cd\u6709\u6548\u7684AI\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba9\u4e0d\u53ef\u4fe1\u6a21\u578b\u63d0\u4f9b\u53ef\u8bfb\u7684\u89e3\u91ca\uff0c\u5e2e\u52a9\u8f83\u5f31\u4f46\u53ef\u4fe1\u7684\u76d1\u63a7\u6a21\u578b\u66f4\u597d\u5730\u8bc4\u4f30\u5176\u884c\u4e3a\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u5728\u76d1\u63a7\u6a21\u578b\u8f83\u5f3a\u65f6\u6548\u679c\u66f4\u663e\u8457\u3002"}}
{"id": "2602.10147", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10147", "abs": "https://arxiv.org/abs/2602.10147", "authors": ["Cau\u00e3 Ferreira Barros", "Marcos Kalinowski", "Mohamad Kassab", "Valdemar Vicente Graciano Neto"], "title": "On the Use of a Large Language Model to Support the Conduction of a Systematic Mapping Study: A Brief Report from a Practitioner's View", "comment": "6 pages, includes 2 tables. Submitted and Accepted to the WSESE 2026 ICSE Workshop", "summary": "The use of Large Language Models (LLMs) has drawn growing interest within the scientific community. LLMs can handle large volumes of textual data and support methods for evidence synthesis. Although recent studies highlight the potential of LLMs to accelerate screening and data extraction steps in systematic reviews, detailed reports of their practical application throughout the entire process remain scarce. This paper presents an experience report on the conduction of a systematic mapping study with the support of LLMs, describing the steps followed, the necessary adjustments, and the main challenges faced. Positive aspects are discussed, such as (i) the significant reduction of time in repetitive tasks and (ii) greater standardization in data extraction, as well as negative aspects, including (i) considerable effort to build reliable well-structured prompts, especially for less experienced users, since achieving effective prompts may require several iterations and testing, which can partially offset the expected time savings, (ii) the occurrence of hallucinations, and (iii) the need for constant manual verification. As a contribution, this work offers lessons learned and practical recommendations for researchers interested in adopting LLMs in systematic mappings and reviews, highlighting both efficiency gains and methodological risks and limitations to be considered.", "AI": {"tldr": "\u672c\u6587\u62a5\u544a\u4e86\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u652f\u6301\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u7684\u5b9e\u8df5\u7ecf\u9a8c\uff0c\u603b\u7ed3\u4e86LLMs\u5728\u52a0\u901f\u7cfb\u7edf\u7efc\u8ff0\u6d41\u7a0b\u4e2d\u7684\u4f18\u52bf\u4e0e\u6311\u6218", "motivation": "\u5c3d\u7ba1LLMs\u5728\u52a0\u901f\u7cfb\u7edf\u7efc\u8ff0\u7684\u7b5b\u9009\u548c\u6570\u636e\u63d0\u53d6\u6b65\u9aa4\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5173\u4e8e\u5176\u5728\u6574\u4e2a\u6d41\u7a0b\u4e2d\u5b9e\u9645\u5e94\u7528\u7684\u8be6\u7ec6\u62a5\u544a\u4ecd\u7136\u7a00\u7f3a\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5206\u4eab\u5b9e\u8df5\u7ecf\u9a8c", "method": "\u672c\u6587\u91c7\u7528\u7ecf\u9a8c\u62a5\u544a\u7684\u5f62\u5f0f\uff0c\u63cf\u8ff0\u4e86\u4e00\u4e2a\u5728LLMs\u652f\u6301\u4e0b\u8fdb\u884c\u7684\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u7684\u5b8c\u6574\u6b65\u9aa4\u3001\u5fc5\u8981\u7684\u8c03\u6574\u4ee5\u53ca\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218", "result": "\u7814\u7a76\u53d1\u73b0LLMs\u80fd\u591f\u663e\u8457\u51cf\u5c11\u91cd\u590d\u4efb\u52a1\u7684\u65f6\u95f4\u5e76\u63d0\u9ad8\u6570\u636e\u63d0\u53d6\u7684\u6807\u51c6\u5316\u7a0b\u5ea6\uff0c\u4f46\u4e5f\u9762\u4e34\u6784\u5efa\u53ef\u9760\u63d0\u793a\u9700\u8981\u5927\u91cf\u52aa\u529b\u3001\u51fa\u73b0\u5e7b\u89c9\u95ee\u9898\u4ee5\u53ca\u9700\u8981\u6301\u7eed\u4eba\u5de5\u9a8c\u8bc1\u7b49\u6311\u6218", "conclusion": "\u672c\u6587\u4e3a\u7814\u7a76\u4eba\u5458\u5728\u7cfb\u7edf\u6620\u5c04\u548c\u7efc\u8ff0\u4e2d\u91c7\u7528LLMs\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u6559\u8bad\u548c\u5b9e\u8df5\u5efa\u8bae\uff0c\u5f3a\u8c03\u4e86\u6548\u7387\u63d0\u5347\u7684\u540c\u65f6\u4e5f\u9700\u8981\u8003\u8651\u65b9\u6cd5\u8bba\u98ce\u9669\u548c\u5c40\u9650\u6027"}}
{"id": "2602.10458", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10458", "abs": "https://arxiv.org/abs/2602.10458", "authors": ["Yansong Qu", "Zihao Sheng", "Zilin Huang", "Jiancong Chen", "Yuhao Luo", "Tianyi Wang", "Yiheng Feng", "Samuel Labi", "Sikai Chen"], "title": "Found-RL: foundation model-enhanced reinforcement learning for autonomous driving", "comment": "39 pages", "summary": "Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we present Found-RL, a platform tailored to efficiently enhance RL for AD using foundation models. A core innovation is the asynchronous batch inference framework, which decouples heavy VLM reasoning from the simulation loop, effectively resolving latency bottlenecks to support real-time learning. We introduce diverse supervision mechanisms: Value-Margin Regularization (VMR) and Advantage-Weighted Action Guidance (AWAG) to effectively distill expert-like VLM action suggestions into the RL policy. Additionally, we adopt high-throughput CLIP for dense reward shaping. We address CLIP's dynamic blindness via Conditional Contrastive Action Alignment, which conditions prompts on discretized speed/command and yields a normalized, margin-based bonus from context-specific action-anchor scoring. Found-RL provides an end-to-end pipeline for fine-tuned VLM integration and shows that a lightweight RL model can achieve near-VLM performance compared with billion-parameter VLMs while sustaining real-time inference (approx. 500 FPS). Code, data, and models will be publicly available at https://github.com/ys-qu/found-rl.", "AI": {"tldr": "Found-RL\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u81ea\u52a8\u9a7e\u9a76\u8bbe\u8ba1\u7684\u5f3a\u5316\u5b66\u4e60\u5e73\u53f0\uff0c\u901a\u8fc7\u5f02\u6b65\u6279\u91cf\u63a8\u7406\u6846\u67b6\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728RL\u8bad\u7ec3\u4e2d\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u591a\u79cd\u76d1\u7763\u673a\u5236\u5c06VLM\u77e5\u8bc6\u84b8\u998f\u5230\u8f7b\u91cf\u7ea7RL\u6a21\u578b\u4e2d\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u548c\u8bed\u4e49\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u800c\u57fa\u7840\u6a21\u578b\uff08\u7279\u522b\u662f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff09\u867d\u7136\u80fd\u63d0\u4f9b\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u77e5\u8bc6\uff0c\u4f46\u5176\u9ad8\u63a8\u7406\u5ef6\u8fdf\u963b\u788d\u4e86\u5728\u9ad8\u9891RL\u8bad\u7ec3\u5faa\u73af\u4e2d\u7684\u90e8\u7f72\u3002", "method": "1. \u5f02\u6b65\u6279\u91cf\u63a8\u7406\u6846\u67b6\uff1a\u5c06\u7e41\u91cd\u7684VLM\u63a8\u7406\u4e0e\u4eff\u771f\u5faa\u73af\u89e3\u8026\uff0c\u89e3\u51b3\u5ef6\u8fdf\u74f6\u9888\uff1b2. \u5f15\u5165\u591a\u79cd\u76d1\u7763\u673a\u5236\uff1a\u503c\u8fb9\u754c\u6b63\u5219\u5316\u548c\u4f18\u52bf\u52a0\u6743\u52a8\u4f5c\u6307\u5bfc\uff0c\u5c06VLM\u4e13\u5bb6\u52a8\u4f5c\u5efa\u8bae\u84b8\u998f\u5230RL\u7b56\u7565\u4e2d\uff1b3. \u91c7\u7528\u9ad8\u541e\u5410\u91cfCLIP\u8fdb\u884c\u5bc6\u96c6\u5956\u52b1\u5851\u9020\uff0c\u5e76\u901a\u8fc7\u6761\u4ef6\u5bf9\u6bd4\u52a8\u4f5c\u5bf9\u9f50\u89e3\u51b3CLIP\u7684\u52a8\u6001\u76f2\u533a\u95ee\u9898\u3002", "result": "Found-RL\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u5fae\u8c03VLM\u96c6\u6210\u7ba1\u9053\uff0c\u8f7b\u91cf\u7ea7RL\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u63a5\u8fd1\u5341\u4ebf\u53c2\u6570VLM\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u63a8\u7406\uff08\u7ea6500 FPS\uff09\u3002", "conclusion": "Found-RL\u5e73\u53f0\u6210\u529f\u89e3\u51b3\u4e86VLM\u5728RL\u8bad\u7ec3\u4e2d\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u901a\u8fc7\u9ad8\u6548\u7684\u76d1\u7763\u673a\u5236\u5b9e\u73b0\u4e86\u77e5\u8bc6\u84b8\u998f\uff0c\u4f7f\u8f7b\u91cf\u7ea7RL\u6a21\u578b\u5728\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\u65e2\u80fd\u83b7\u5f97VLM\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u53c8\u80fd\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u3002"}}
{"id": "2602.10171", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10171", "abs": "https://arxiv.org/abs/2602.10171", "authors": ["Wentao Zhang", "Jianfeng Wang", "Liheng Liang", "Yilei Zhao", "HaiBin Wen", "Zhe Zhao"], "title": "EvoCodeBench: A Human-Performance Benchmark for Self-Evolving LLM-Driven Coding Systems", "comment": null, "summary": "As large language models (LLMs) continue to advance in programming tasks, LLM-driven coding systems have evolved from one-shot code generation into complex systems capable of iterative improvement during inference. However, existing code benchmarks primarily emphasize static correctness and implicitly assume fixed model capability during inference. As a result, they do not capture inference-time self-evolution, such as whether accuracy and efficiency improve as an agent iteratively refines its solutions. They also provide limited accounting of resource costs and rarely calibrate model performance against that of human programmers. Moreover, many benchmarks are dominated by high-resource languages, leaving cross-language robustness and long-tail language stability underexplored. Therefore, we present EvoCodeBench, a benchmark for evaluating self-evolving LLM-driven coding systems across programming languages with direct comparison to human performance. EvoCodeBench tracks performance dynamics, measuring solution correctness alongside efficiency metrics such as solving time, memory consumption, and improvement algorithmic design over repeated problem-solving attempts. To ground evaluation in a human-centered reference frame, we directly compare model performance with that of human programmers on the same tasks, enabling relative performance assessment within the human ability distribution. Furthermore, EvoCodeBench supports multiple programming languages, enabling systematic cross-language and long-tail stability analyses under a unified protocol. Our results demonstrate that self-evolving systems exhibit measurable gains in efficiency over time, and that human-relative and multi-language analyses provide insights unavailable through accuracy alone. EvoCodeBench establishes a foundation for evaluating coding intelligence in evolving LLM-driven systems.", "AI": {"tldr": "EvoCodeBench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u81ea\u6211\u8fdb\u5316LLM\u9a71\u52a8\u7f16\u7801\u7cfb\u7edf\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b83\u8ddf\u8e2a\u6027\u80fd\u52a8\u6001\u3001\u6bd4\u8f83\u4eba\u7c7b\u8868\u73b0\uff0c\u5e76\u652f\u6301\u591a\u8bed\u8a00\u5206\u6790\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u4ec5\u5173\u6ce8\u9759\u6001\u6b63\u786e\u6027\u7684\u4ee3\u7801\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u57fa\u51c6\u4e3b\u8981\u5f3a\u8c03\u9759\u6001\u6b63\u786e\u6027\uff0c\u5047\u8bbe\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6a21\u578b\u80fd\u529b\u56fa\u5b9a\uff0c\u65e0\u6cd5\u6355\u6349\u63a8\u7406\u65f6\u7684\u81ea\u6211\u8fdb\u5316\u80fd\u529b\uff08\u5982\u8fed\u4ee3\u6539\u8fdb\u89e3\u51b3\u65b9\u6848\u65f6\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u63d0\u5347\uff09\u3002\u540c\u65f6\u7f3a\u4e4f\u5bf9\u8d44\u6e90\u6210\u672c\u7684\u8003\u91cf\uff0c\u5f88\u5c11\u5c06\u6a21\u578b\u6027\u80fd\u4e0e\u4eba\u7c7b\u7a0b\u5e8f\u5458\u8fdb\u884c\u6821\u51c6\uff0c\u4e14\u4e3b\u8981\u5173\u6ce8\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u5ffd\u7565\u4e86\u8de8\u8bed\u8a00\u9c81\u68d2\u6027\u548c\u957f\u5c3e\u8bed\u8a00\u7a33\u5b9a\u6027\u3002", "method": "\u5f00\u53d1EvoCodeBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8ddf\u8e2a\u6027\u80fd\u52a8\u6001\uff0c\u6d4b\u91cf\u89e3\u51b3\u65b9\u6848\u6b63\u786e\u6027\u4ee5\u53ca\u6548\u7387\u6307\u6807\uff08\u5982\u89e3\u51b3\u65f6\u95f4\u3001\u5185\u5b58\u6d88\u8017\u3001\u6539\u8fdb\u7b97\u6cd5\u8bbe\u8ba1\uff09\u3002\u76f4\u63a5\u6bd4\u8f83\u6a21\u578b\u4e0e\u4eba\u7c7b\u7a0b\u5e8f\u5458\u5728\u76f8\u540c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\uff0c\u5728\u7edf\u4e00\u534f\u8bae\u4e0b\u8fdb\u884c\u7cfb\u7edf\u6027\u7684\u8de8\u8bed\u8a00\u548c\u957f\u5c3e\u7a33\u5b9a\u6027\u5206\u6790\u3002", "result": "\u81ea\u6211\u8fdb\u5316\u7cfb\u7edf\u5728\u6548\u7387\u65b9\u9762\u968f\u65f6\u95f4\u663e\u793a\u51fa\u53ef\u6d4b\u91cf\u7684\u63d0\u5347\uff0c\u4eba\u7c7b\u76f8\u5bf9\u6027\u548c\u591a\u8bed\u8a00\u5206\u6790\u63d0\u4f9b\u4e86\u4ec5\u9760\u51c6\u786e\u6027\u65e0\u6cd5\u83b7\u5f97\u7684\u6d1e\u5bdf\u3002EvoCodeBench\u4e3a\u8bc4\u4f30\u8fdb\u5316\u4e2d\u7684LLM\u9a71\u52a8\u7cfb\u7edf\u7684\u7f16\u7801\u667a\u80fd\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "EvoCodeBench\u5efa\u7acb\u4e86\u4e00\u4e2a\u8bc4\u4f30\u8fdb\u5316LLM\u9a71\u52a8\u7cfb\u7edf\u4e2d\u7f16\u7801\u667a\u80fd\u7684\u57fa\u7840\u6846\u67b6\uff0c\u901a\u8fc7\u8ddf\u8e2a\u6027\u80fd\u52a8\u6001\u3001\u4eba\u7c7b\u76f8\u5bf9\u6bd4\u8f83\u548c\u591a\u8bed\u8a00\u5206\u6790\uff0c\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u57fa\u51c6\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u89c6\u89d2\u3002"}}
{"id": "2602.10467", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10467", "abs": "https://arxiv.org/abs/2602.10467", "authors": ["Jihwan Oh", "Murad Aghazada", "Yooju Shin", "Se-Young Yun", "Taehyeon Kim"], "title": "MERIT Feedback Elicits Better Bargaining in LLM Negotiators", "comment": "Preprint. Affiliation typo corrected", "summary": "Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchmarks rarely capture this limitation. To bridge this gap, we present an utility feedback centric framework. Our contributions are: (i) AgoraBench, a new benchmark spanning nine challenging settings (e.g., deception, monopoly) that supports diverse strategy modeling; (ii) human-aligned, economically grounded metrics derived from utility theory. This is operationalized via agent utility, negotiation power, and acquisition ratio that implicitly measure how well the negotiation aligns with human preference and (iii) a human preference grounded dataset with learning pipeline that strengthens LLMs' bargaining ability through both prompting and finetuning. Empirical results indicate that baseline LLM strategies often diverge from human preferences, while our mechanism substantially improves negotiation performance, yielding deeper strategic behavior and stronger opponent awareness.", "AI": {"tldr": "\u63d0\u51faAgoraBench\u57fa\u51c6\u6d4b\u8bd5\u548c\u57fa\u4e8e\u6548\u7528\u53cd\u9988\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u7684\u6307\u6807\u548c\u6570\u636e\u96c6\u63d0\u5347LLM\u5728\u590d\u6742\u8c08\u5224\u573a\u666f\u4e2d\u7684\u8868\u73b0", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8c08\u5224\u573a\u666f\u4e2d\u4ecd\u5b58\u5728\u6218\u7565\u6df1\u5ea6\u4e0d\u8db3\u548c\u96be\u4ee5\u9002\u5e94\u590d\u6742\u4eba\u7c7b\u56e0\u7d20\u7684\u5c40\u9650\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u5145\u5206\u6355\u6349\u8fd9\u4e9b\u9650\u5236", "method": "\u63d0\u51fa\u6548\u7528\u53cd\u9988\u4e2d\u5fc3\u6846\u67b6\uff1a1) AgoraBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d69\u4e2a\u6311\u6218\u6027\u573a\u666f\uff1b2) \u57fa\u4e8e\u6548\u7528\u7406\u8bba\u7684\u4eba\u7c7b\u5bf9\u9f50\u7ecf\u6d4e\u6307\u6807\uff1b3) \u4eba\u7c7b\u504f\u597d\u6570\u636e\u96c6\u548c\u5b66\u4e60\u7ba1\u9053", "result": "\u57fa\u7ebfLLM\u7b56\u7565\u5e38\u504f\u79bb\u4eba\u7c7b\u504f\u597d\uff0c\u800c\u63d0\u51fa\u7684\u673a\u5236\u663e\u8457\u63d0\u5347\u8c08\u5224\u6027\u80fd\uff0c\u4ea7\u751f\u66f4\u6df1\u5c42\u6218\u7565\u884c\u4e3a\u548c\u66f4\u5f3a\u7684\u5bf9\u624b\u610f\u8bc6", "conclusion": "\u901a\u8fc7\u6548\u7528\u53cd\u9988\u6846\u67b6\u548c\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u589e\u5f3aLLM\u5728\u590d\u6742\u8c08\u5224\u573a\u666f\u4e2d\u7684\u6218\u7565\u80fd\u529b\u548c\u9002\u5e94\u6027"}}
{"id": "2602.10471", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10471", "abs": "https://arxiv.org/abs/2602.10471", "authors": ["Steven Liu", "Jane Luo", "Xin Zhang", "Aofan Liu", "Hao Liu", "Jie Wu", "Ziyang Huang", "Yangyu Huang", "Yu Kang", "Scarlett Li"], "title": "TestExplora: Benchmarking LLMs for Proactive Bug Discovery via Repository-Level Test Generation", "comment": null, "summary": "Given that Large Language Models (LLMs) are increasingly applied to automate software development, comprehensive software assurance spans three distinct goals: regression prevention, reactive reproduction, and proactive discovery. Current evaluations systematically overlook the third goal. Specifically, they either treat existing code as ground truth (a compliance trap) for regression prevention, or depend on post-failure artifacts (e.g., issue reports) for bug reproduction-so they rarely surface defects before failures. To bridge this gap, we present TestExplora, a benchmark designed to evaluate LLMs as proactive testers within full-scale, realistic repository environments. TestExplora contains 2,389 tasks from 482 repositories and hides all defect-related signals. Models must proactively find bugs by comparing implementations against documentation-derived intent, using documentation as the oracle. Furthermore, to keep evaluation sustainable and reduce leakage, we propose continuous, time-aware data collection. Our evaluation reveals a significant capability gap: state-of-the-art models achieve a maximum Fail-to-Pass (F2P) rate of only 16.06%. Further analysis indicates that navigating complex cross-module interactions and leveraging agentic exploration are critical to advancing LLMs toward autonomous software quality assurance. Consistent with this, SWEAgent instantiated with GPT-5-mini achieves an F2P of 17.27% and an F2P@5 of 29.7%, highlighting the effectiveness and promise of agentic exploration in proactive bug discovery tasks.", "AI": {"tldr": "TestExplora\u662f\u4e00\u4e2a\u8bc4\u4f30LLMs\u4f5c\u4e3a\u4e3b\u52a8\u6d4b\u8bd5\u8005\u7684\u57fa\u51c6\uff0c\u5305\u542b2389\u4e2a\u4efb\u52a1\uff0c\u8981\u6c42\u6a21\u578b\u901a\u8fc7\u6bd4\u8f83\u5b9e\u73b0\u4e0e\u6587\u6863\u610f\u56fe\u6765\u4e3b\u52a8\u53d1\u73b0bug\uff0c\u7ed3\u679c\u663e\u793a\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u7684\u6700\u5927F2P\u7387\u4ec5\u4e3a16.06%\uff0c\u8868\u660eLLMs\u5728\u4e3b\u52a8\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u8bc1\u65b9\u9762\u5b58\u5728\u663e\u8457\u80fd\u529b\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524dLLMs\u5728\u8f6f\u4ef6\u81ea\u52a8\u5316\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u56de\u5f52\u9884\u9632\u548c\u53cd\u5e94\u6027bug\u91cd\u73b0\uff0c\u4f46\u5ffd\u89c6\u4e86\u4e3b\u52a8\u53d1\u73b0\u7f3a\u9677\u8fd9\u4e00\u91cd\u8981\u76ee\u6807\u3002\u73b0\u6709\u8bc4\u4f30\u8981\u4e48\u5c06\u73b0\u6709\u4ee3\u7801\u89c6\u4e3a\u57fa\u51c6\uff08\u5408\u89c4\u9677\u9631\uff09\uff0c\u8981\u4e48\u4f9d\u8d56\u6545\u969c\u540e\u5de5\u4ef6\uff0c\u5f88\u5c11\u80fd\u5728\u6545\u969c\u53d1\u751f\u524d\u53d1\u73b0\u7f3a\u9677\u3002", "method": "\u63d0\u51fa\u4e86TestExplora\u57fa\u51c6\uff0c\u5305\u542b2389\u4e2a\u4efb\u52a1\u6765\u81ea482\u4e2a\u4ed3\u5e93\uff0c\u9690\u85cf\u6240\u6709\u7f3a\u9677\u76f8\u5173\u4fe1\u53f7\u3002\u6a21\u578b\u5fc5\u987b\u901a\u8fc7\u6bd4\u8f83\u5b9e\u73b0\u4e0e\u6587\u6863\u63a8\u5bfc\u7684\u610f\u56fe\u6765\u4e3b\u52a8\u53d1\u73b0bug\uff0c\u4f7f\u7528\u6587\u6863\u4f5c\u4e3aoracle\u3002\u91c7\u7528\u8fde\u7eed\u3001\u65f6\u95f4\u611f\u77e5\u7684\u6570\u636e\u6536\u96c6\u65b9\u6cd5\u4ee5\u786e\u4fdd\u8bc4\u4f30\u53ef\u6301\u7eed\u5e76\u51cf\u5c11\u6cc4\u6f0f\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u663e\u8457\u7684\u80fd\u529b\u5dee\u8ddd\uff1a\u6700\u5148\u8fdb\u6a21\u578b\u7684\u6700\u5927Fail-to-Pass\uff08F2P\uff09\u7387\u4ec5\u4e3a16.06%\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u8868\u660e\uff0c\u5bfc\u822a\u590d\u6742\u7684\u8de8\u6a21\u5757\u4ea4\u4e92\u548c\u5229\u7528\u667a\u80fd\u4f53\u63a2\u7d22\u5bf9\u63d0\u5347LLMs\u7684\u81ea\u4e3b\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u8bc1\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002\u4f7f\u7528GPT-5-mini\u7684SWEAgent\u5b9e\u73b0\u4e8617.27%\u7684F2P\u548c29.7%\u7684F2P@5\u3002", "conclusion": "TestExplora\u586b\u8865\u4e86LLMs\u4f5c\u4e3a\u4e3b\u52a8\u6d4b\u8bd5\u8005\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u4e3b\u52a8bug\u53d1\u73b0\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002\u667a\u80fd\u4f53\u63a2\u7d22\u5728\u590d\u6742\u8f6f\u4ef6\u73af\u5883\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u8de8\u6a21\u5757\u4ea4\u4e92\u548c\u63a2\u7d22\u7b56\u7565\u6765\u63d0\u5347LLMs\u7684\u81ea\u4e3b\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u8bc1\u80fd\u529b\u3002"}}
{"id": "2602.10485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10485", "abs": "https://arxiv.org/abs/2602.10485", "authors": ["Zhenhe Cui", "Huaxiang Xia", "Hangjun Shen", "Kailun Luo", "Yong He", "Wei Liang"], "title": "Abstraction Generation for Generalized Planning with Pretrained Large Language Models", "comment": null, "summary": "Qualitative Numerical Planning (QNP) serves as an important abstraction model for generalized planning (GP), which aims to compute general plans that solve multiple instances at once. Recent works show that large language models (LLMs) can function as generalized planners. This work investigates whether LLMs can serve as QNP abstraction generators for GP problems and how to fix abstractions via automated debugging. We propose a prompt protocol: input a GP domain and training tasks to LLMs, prompting them to generate abstract features and further abstract the initial state, action set, and goal into QNP problems. An automated debugging method is designed to detect abstraction errors, guiding LLMs to fix abstractions. Experiments demonstrate that under properly guided by automated debugging, some LLMs can generate useful QNP abstractions.", "AI": {"tldr": "LLMs\u4f5c\u4e3aQNP\u62bd\u8c61\u751f\u6210\u5668\u7528\u4e8e\u5e7f\u4e49\u89c4\u5212\uff0c\u901a\u8fc7\u81ea\u52a8\u8c03\u8bd5\u4fee\u590d\u62bd\u8c61\u9519\u8bef", "motivation": "\u7814\u7a76LLMs\u80fd\u5426\u4f5c\u4e3aQNP\u62bd\u8c61\u751f\u6210\u5668\u4e3a\u5e7f\u4e49\u89c4\u5212\u95ee\u9898\u751f\u6210\u62bd\u8c61\u7279\u5f81\uff0c\u5e76\u89e3\u51b3\u62bd\u8c61\u9519\u8bef\u7684\u81ea\u52a8\u4fee\u590d\u95ee\u9898", "method": "\u63d0\u51fa\u63d0\u793a\u534f\u8bae\uff1a\u8f93\u5165GP\u9886\u57df\u548c\u8bad\u7ec3\u4efb\u52a1\u7ed9LLMs\uff0c\u8ba9\u5b83\u4eec\u751f\u6210\u62bd\u8c61\u7279\u5f81\u5e76\u5c06\u521d\u59cb\u72b6\u6001\u3001\u52a8\u4f5c\u96c6\u548c\u76ee\u6807\u62bd\u8c61\u4e3aQNP\u95ee\u9898\uff1b\u8bbe\u8ba1\u81ea\u52a8\u8c03\u8bd5\u65b9\u6cd5\u68c0\u6d4b\u62bd\u8c61\u9519\u8bef\uff0c\u6307\u5bfcLLMs\u4fee\u590d\u62bd\u8c61", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u81ea\u52a8\u8c03\u8bd5\u7684\u9002\u5f53\u6307\u5bfc\u4e0b\uff0c\u67d0\u4e9bLLMs\u80fd\u591f\u751f\u6210\u6709\u7528\u7684QNP\u62bd\u8c61", "conclusion": "LLMs\u53ef\u4ee5\u4f5c\u4e3aQNP\u62bd\u8c61\u751f\u6210\u5668\uff0c\u7ed3\u5408\u81ea\u52a8\u8c03\u8bd5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u751f\u6210\u548c\u4fee\u590d\u62bd\u8c61\uff0c\u4e3a\u5e7f\u4e49\u89c4\u5212\u63d0\u4f9b\u65b0\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.10161", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10161", "abs": "https://arxiv.org/abs/2602.10161", "authors": ["Kun Wang", "Zherui Li", "Zhenhong Zhou", "Yitong Zhang", "Yan Mi", "Kun Yang", "Yiming Zhang", "Junhao Dong", "Zhongxiang Sun", "Qiankun Li", "Yang Liu"], "title": "Omni-Safety under Cross-Modality Conflict: Vulnerabilities, Dynamics Mechanisms and Efficient Alignment", "comment": null, "summary": "Omni-modal Large Language Models (OLLMs) greatly expand LLMs' multimodal capabilities but also introduce cross-modal safety risks. However, a systematic understanding of vulnerabilities in omni-modal interactions remains lacking. To bridge this gap, we establish a modality-semantics decoupling principle and construct the AdvBench-Omni dataset, which reveals a significant vulnerability in OLLMs. Mechanistic analysis uncovers a Mid-layer Dissolution phenomenon driven by refusal vector magnitude shrinkage, alongside the existence of a modal-invariant pure refusal direction. Inspired by these insights, we extract a golden refusal vector using Singular Value Decomposition and propose OmniSteer, which utilizes lightweight adapters to modulate intervention intensity adaptively. Extensive experiments show that our method not only increases the Refusal Success Rate against harmful inputs from 69.9% to 91.2%, but also effectively preserves the general capabilities across all modalities. Our code is available at: https://github.com/zhrli324/omni-safety-research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5168\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u6a21\u6001-\u8bed\u4e49\u89e3\u8026\u539f\u5219\uff0c\u6784\u5efa\u4e86AdvBench-Omni\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u4e86\u4e2d\u5c42\u6eb6\u89e3\u73b0\u8c61\uff0c\u5e76\u5f00\u53d1\u4e86OmniSteer\u65b9\u6cd5\u901a\u8fc7\u8f7b\u91cf\u9002\u914d\u5668\u63d0\u5347\u6709\u5bb3\u8f93\u5165\u62d2\u7edd\u6210\u529f\u7387\u3002", "motivation": "\u5168\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u6269\u5c55\u4e86\u591a\u6a21\u6001\u80fd\u529b\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u8de8\u6a21\u6001\u5b89\u5168\u98ce\u9669\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u5168\u6a21\u6001\u4ea4\u4e92\u4e2d\u6f0f\u6d1e\u7684\u7cfb\u7edf\u6027\u7406\u89e3\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "1. \u5efa\u7acb\u6a21\u6001-\u8bed\u4e49\u89e3\u8026\u539f\u5219\uff1b2. \u6784\u5efaAdvBench-Omni\u6570\u636e\u96c6\uff1b3. \u901a\u8fc7\u673a\u5236\u5206\u6790\u53d1\u73b0\u4e2d\u5c42\u6eb6\u89e3\u73b0\u8c61\u548c\u6a21\u6001\u4e0d\u53d8\u7eaf\u62d2\u7edd\u65b9\u5411\uff1b4. \u4f7f\u7528\u5947\u5f02\u503c\u5206\u89e3\u63d0\u53d6\u9ec4\u91d1\u62d2\u7edd\u5411\u91cf\uff1b5. \u63d0\u51faOmniSteer\u65b9\u6cd5\uff0c\u5229\u7528\u8f7b\u91cf\u9002\u914d\u5668\u81ea\u9002\u5e94\u8c03\u8282\u5e72\u9884\u5f3a\u5ea6\u3002", "result": "OmniSteer\u65b9\u6cd5\u5c06\u6709\u5bb3\u8f93\u5165\u7684\u62d2\u7edd\u6210\u529f\u7387\u4ece69.9%\u63d0\u5347\u523091.2%\uff0c\u540c\u65f6\u6709\u6548\u4fdd\u7559\u4e86\u6240\u6709\u6a21\u6001\u7684\u901a\u7528\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u7cfb\u7edf\u63ed\u793a\u4e86\u5168\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\u673a\u5236\uff0c\u63d0\u51fa\u7684OmniSteer\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027\u800c\u4e0d\u635f\u5bb3\u5176\u591a\u6a21\u6001\u80fd\u529b\uff0c\u4e3a\u5168\u6a21\u6001\u6a21\u578b\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10583", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10583", "abs": "https://arxiv.org/abs/2602.10583", "authors": ["Bo Xue", "Yunchong Song", "Fanghao Shao", "Xuekai Zhu", "Lin Chen", "Luoyi Fu", "Xinbing Wang", "Zhouhan Lin"], "title": "Flow of Spans: Generalizing Language Models to Dynamic Span-Vocabulary via GFlowNets", "comment": "Published as a conference paper at ICLR 2026", "summary": "Standard autoregressive language models generate text token-by-token from a fixed vocabulary, inducing a tree-structured state space when viewing token sampling as an action, which limits flexibility and expressiveness. Recent work introduces dynamic vocabulary by sampling retrieved text spans but overlooks that the same sentence can be composed of spans of varying lengths, lacking explicit modeling of the directed acyclic graph (DAG) state space. This leads to restricted exploration of compositional paths and is biased toward the chosen path. Generative Flow Networks (GFlowNets) are powerful for efficient exploring and generalizing over state spaces, particularly those with a DAG structure. However, prior GFlowNets-based language models operate at the token level and remain confined to tree-structured spaces, limiting their potential. In this work, we propose Flow of SpanS (FOSS), a principled GFlowNets framework for span generation. FoSS constructs a dynamic span vocabulary by segmenting the retrieved text flexibly, ensuring a DAG-structured state space, which allows GFlowNets to explore diverse compositional paths and improve generalization. With specialized reward models, FoSS generates diverse, high-quality text. Empirically, FoSS improves MAUVE scores by up to 12.5% over Transformer on text generation and achieves 3.5% gains on knowledge-intensive tasks, consistently outperforming state-of-the-art methods. Scaling experiments further demonstrate FoSS benefits from larger models, more data, and richer retrieval corpora, retaining its advantage over strong baselines.", "AI": {"tldr": "FoSS\u63d0\u51fa\u57fa\u4e8eGFlowNets\u7684\u8de8\u5ea6\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8de8\u5ea6\u8bcd\u6c47\u548cDAG\u72b6\u6001\u7a7a\u95f4\u63d0\u5347\u6587\u672c\u751f\u6210\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf", "motivation": "\u4f20\u7edf\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u4f7f\u7528\u56fa\u5b9a\u8bcd\u6c47\u8868\uff0c\u5f62\u6210\u6811\u72b6\u72b6\u6001\u7a7a\u95f4\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u548c\u8868\u8fbe\u80fd\u529b\u3002\u73b0\u6709\u52a8\u6001\u8bcd\u6c47\u65b9\u6cd5\u867d\u7136\u5f15\u5165\u68c0\u7d22\u6587\u672c\u8de8\u5ea6\uff0c\u4f46\u5ffd\u7565\u4e86\u540c\u4e00\u53e5\u5b50\u53ef\u7531\u4e0d\u540c\u957f\u5ea6\u8de8\u5ea6\u7ec4\u6210\uff0c\u7f3a\u4e4f\u5bf9DAG\u72b6\u6001\u7a7a\u95f4\u7684\u663e\u5f0f\u5efa\u6a21\uff0c\u5bfc\u81f4\u7ec4\u5408\u8def\u5f84\u63a2\u7d22\u53d7\u9650\u4e14\u5b58\u5728\u8def\u5f84\u9009\u62e9\u504f\u5dee", "method": "\u63d0\u51faFlow of SpanS (FoSS)\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u7075\u6d3b\u5206\u5272\u68c0\u7d22\u6587\u672c\u6784\u5efa\u52a8\u6001\u8de8\u5ea6\u8bcd\u6c47\u8868\uff1b2\uff09\u786e\u4fddDAG\u7ed3\u6784\u7684\u72b6\u6001\u7a7a\u95f4\uff1b3\uff09\u5229\u7528GFlowNets\u63a2\u7d22\u591a\u6837\u7ec4\u5408\u8def\u5f84\uff1b4\uff09\u7ed3\u5408\u4e13\u7528\u5956\u52b1\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u6587\u672c", "result": "FoSS\u5728\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u6bd4Transformer\u63d0\u5347MAUVE\u5206\u6570\u8fbe12.5%\uff0c\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u83b7\u5f973.5%\u589e\u76ca\uff0c\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u6269\u5c55\u5b9e\u9a8c\u8868\u660eFoSS\u53d7\u76ca\u4e8e\u66f4\u5927\u6a21\u578b\u3001\u66f4\u591a\u6570\u636e\u548c\u66f4\u4e30\u5bcc\u7684\u68c0\u7d22\u8bed\u6599\u5e93", "conclusion": "FoSS\u901a\u8fc7\u5c06GFlowNets\u5e94\u7528\u4e8e\u8de8\u5ea6\u751f\u6210\uff0c\u6784\u5efaDAG\u72b6\u6001\u7a7a\u95f4\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u7ec4\u5408\u8def\u5f84\u63a2\u7d22\u548c\u6cdb\u5316\u65b9\u9762\u7684\u9650\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6587\u672c\u751f\u6210\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf"}}
{"id": "2602.10162", "categories": ["cs.CR", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10162", "abs": "https://arxiv.org/abs/2602.10162", "authors": ["Chenhan Xiao", "Yang Weng"], "title": "Limits of Residual-Based Detection for Physically Consistent False Data Injection", "comment": "10 pages, 10 figures", "summary": "False data injection attacks (FDIAs) pose a persistent challenge to AC power system state estimation. In current practice, detection relies primarily on topology-aware residual-based tests that assume malicious measurements can be distinguished from normal operation through physical inconsistency reflected in abnormal residual behavior. This paper shows that this assumption does not always hold: when FDIA scenarios produce manipulated measurements that remain on the measurement manifold induced by AC power flow relations and measurement redundancy, residual-based detectors may fail to distinguish them from nominal data. The resulting detectability limitation is a property of the measurement manifold itself and does not depend on the attacker's detailed knowledge of the physical system model. To make this limitation observable in practice, we present a data-driven constructive mechanism that incorporates the generic functional structure of AC power flow to generate physically consistent, manifold-constrained perturbations, providing a concrete witness of how residual-based detectors can be bypassed. Numerical studies on multiple AC test systems characterize the conditions under which detection becomes challenging and illustrate its failure modes. The results highlight fundamental limits of residual-based detection in AC state estimation and motivate the need for complementary defenses beyond measurement consistency tests.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u4ea4\u6d41\u7535\u529b\u7cfb\u7edf\u72b6\u6001\u4f30\u8ba1\u4e2d\u57fa\u4e8e\u6b8b\u5dee\u7684\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff1a\u5f53\u653b\u51fb\u4ea7\u751f\u7684\u6d4b\u91cf\u6570\u636e\u4fdd\u6301\u5728\u7531\u4ea4\u6d41\u6f6e\u6d41\u5173\u7cfb\u548c\u6d4b\u91cf\u5197\u4f59\u5ea6\u8bf1\u5bfc\u7684\u6d4b\u91cf\u6d41\u5f62\u4e0a\u65f6\uff0c\u6b8b\u5dee\u68c0\u6d4b\u5668\u53ef\u80fd\u65e0\u6cd5\u533a\u5206\u6076\u610f\u6570\u636e\u548c\u6b63\u5e38\u6570\u636e\u3002", "motivation": "\u5f53\u524d\u4ea4\u6d41\u7535\u529b\u7cfb\u7edf\u72b6\u6001\u4f30\u8ba1\u4e3b\u8981\u4f9d\u8d56\u57fa\u4e8e\u62d3\u6251\u611f\u77e5\u7684\u6b8b\u5dee\u6d4b\u8bd5\u6765\u68c0\u6d4b\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5047\u8bbe\u6076\u610f\u6d4b\u91cf\u53ef\u4ee5\u901a\u8fc7\u7269\u7406\u4e0d\u4e00\u81f4\u6027\u53cd\u6620\u5728\u5f02\u5e38\u6b8b\u5dee\u884c\u4e3a\u4e2d\u88ab\u8bc6\u522b\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u5047\u8bbe\u5e76\u4e0d\u603b\u662f\u6210\u7acb\uff0c\u9700\u8981\u7814\u7a76\u6b8b\u5dee\u68c0\u6d4b\u7684\u6839\u672c\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u6784\u9020\u673a\u5236\uff0c\u7ed3\u5408\u4ea4\u6d41\u6f6e\u6d41\u7684\u901a\u7528\u529f\u80fd\u7ed3\u6784\u6765\u751f\u6210\u7269\u7406\u4e00\u81f4\u3001\u6d41\u5f62\u7ea6\u675f\u7684\u6270\u52a8\uff0c\u4e3a\u6b8b\u5dee\u68c0\u6d4b\u5668\u5982\u4f55\u88ab\u7ed5\u8fc7\u63d0\u4f9b\u4e86\u5177\u4f53\u8bc1\u636e\u3002\u5728\u591a\u4e2a\u4ea4\u6d41\u6d4b\u8bd5\u7cfb\u7edf\u4e0a\u8fdb\u884c\u6570\u503c\u7814\u7a76\uff0c\u8868\u5f81\u68c0\u6d4b\u53d8\u5f97\u56f0\u96be\u7684\u6761\u4ef6\u5e76\u8bf4\u660e\u5176\u5931\u6548\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5f53\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u573a\u666f\u4ea7\u751f\u7684\u64cd\u7eb5\u6d4b\u91cf\u4fdd\u6301\u5728\u7531\u4ea4\u6d41\u6f6e\u6d41\u5173\u7cfb\u548c\u6d4b\u91cf\u5197\u4f59\u5ea6\u8bf1\u5bfc\u7684\u6d4b\u91cf\u6d41\u5f62\u4e0a\u65f6\uff0c\u57fa\u4e8e\u6b8b\u5dee\u7684\u68c0\u6d4b\u5668\u53ef\u80fd\u65e0\u6cd5\u533a\u5206\u5b83\u4eec\u4e0e\u6b63\u5e38\u6570\u636e\u3002\u8fd9\u79cd\u53ef\u68c0\u6d4b\u6027\u9650\u5236\u662f\u6d4b\u91cf\u6d41\u5f62\u672c\u8eab\u7684\u5c5e\u6027\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u653b\u51fb\u8005\u5bf9\u7269\u7406\u7cfb\u7edf\u6a21\u578b\u7684\u8be6\u7ec6\u77e5\u8bc6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u4ea4\u6d41\u72b6\u6001\u4f30\u8ba1\u4e2d\u57fa\u4e8e\u6b8b\u5dee\u68c0\u6d4b\u7684\u6839\u672c\u9650\u5236\uff0c\u5e76\u5f3a\u8c03\u4e86\u9700\u8981\u8d85\u8d8a\u6d4b\u91cf\u4e00\u81f4\u6027\u6d4b\u8bd5\u7684\u8865\u5145\u9632\u5fa1\u63aa\u65bd\u3002\u5f53\u653b\u51fb\u6570\u636e\u4fdd\u6301\u5728\u7269\u7406\u4e00\u81f4\u7684\u6d4b\u91cf\u6d41\u5f62\u4e0a\u65f6\uff0c\u4ec5\u4f9d\u8d56\u6b8b\u5dee\u68c0\u6d4b\u662f\u4e0d\u591f\u7684\u3002"}}
{"id": "2602.10598", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10598", "abs": "https://arxiv.org/abs/2602.10598", "authors": ["Shuai Han", "Mehdi Dastani", "Shihan Wang"], "title": "Neuro-symbolic Action Masking for Deep Reinforcement Learning", "comment": null, "summary": "Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, in a minimally supervised manner during the DRL process. Based on the learned symbolic model of states, NSAM learns action masks that rules out infeasible actions. NSAM enables end-to-end integration of symbolic reasoning and deep policy optimization, where improvements in symbolic grounding and policy learning mutually reinforce each other. We evaluate NSAM on multiple domains with constraints, and experimental results demonstrate that NSAM significantly improves sample efficiency of DRL agent while substantially reducing constraint violations.", "AI": {"tldr": "NSAM\u662f\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u52a8\u4f5c\u5c4f\u853d\u6846\u67b6\uff0c\u80fd\u81ea\u52a8\u5b66\u4e60\u4e0e\u9ad8\u7ef4\u72b6\u6001\u7ea6\u675f\u4e00\u81f4\u7684\u7b26\u53f7\u6a21\u578b\uff0c\u5728DRL\u8bad\u7ec3\u4e2d\u51cf\u5c11\u4e0d\u53ef\u884c\u52a8\u4f5c\u63a2\u7d22\u5e76\u63d0\u9ad8\u6837\u672c\u6548\u7387", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u6307\u5b9a\u7b26\u53f7\u63a5\u5730\u51fd\u6570\u548c\u52a8\u4f5c\u5c4f\u853d\u6280\u672f\u6765\u7ea6\u675fDRL\u4e2d\u7684\u4e0d\u53ef\u884c\u52a8\u4f5c\uff0c\u8fd9\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u81ea\u52a8\u5316\u7a0b\u5ea6\u548c\u53ef\u6269\u5c55\u6027", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u52a8\u4f5c\u5c4f\u853d(NSAM)\u6846\u67b6\uff0c\u5728\u6700\u5c0f\u76d1\u7763\u4e0b\u81ea\u52a8\u5b66\u4e60\u4e0e\u9886\u57df\u7ea6\u675f\u4e00\u81f4\u7684\u7b26\u53f7\u6a21\u578b\uff0c\u57fa\u4e8e\u5b66\u4e60\u5230\u7684\u7b26\u53f7\u72b6\u6001\u6a21\u578b\u751f\u6210\u52a8\u4f5c\u5c4f\u853d\uff0c\u6392\u9664\u4e0d\u53ef\u884c\u52a8\u4f5c\uff0c\u5b9e\u73b0\u7b26\u53f7\u63a8\u7406\u4e0e\u6df1\u5ea6\u7b56\u7565\u4f18\u5316\u7684\u7aef\u5230\u7aef\u96c6\u6210", "result": "\u5728\u591a\u4e2a\u7ea6\u675f\u9886\u57df\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNSAM\u663e\u8457\u63d0\u9ad8\u4e86DRL\u667a\u80fd\u4f53\u7684\u6837\u672c\u6548\u7387\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u7ea6\u675f\u8fdd\u53cd", "conclusion": "NSAM\u901a\u8fc7\u81ea\u52a8\u5b66\u4e60\u7b26\u53f7\u6a21\u578b\u548c\u52a8\u4f5c\u5c4f\u853d\uff0c\u5b9e\u73b0\u4e86\u7b26\u53f7\u63a8\u7406\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u534f\u540c\u589e\u5f3a\uff0c\u4e3a\u7ea6\u675f\u73af\u5883\u4e0b\u7684DRL\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.10166", "categories": ["cs.CR", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.10166", "abs": "https://arxiv.org/abs/2602.10166", "authors": ["Tatsunori Ono"], "title": "MerkleSpeech: Public-Key Verifiable, Chunk-Localised Speech Provenance via Perceptual Fingerprints and Merkle Commitments", "comment": "16 pages, 4 figures, 3 tables", "summary": "Speech provenance goes beyond detecting whether a watermark is present. Real workflows involve splicing, quoting, trimming, and platform-level transforms that may preserve some regions while altering others. Neural watermarking systems have made strides in robustness and localised detection, but most deployments produce outputs with no third-party verifiable cryptographic proof tying a time segment to an issuer-signed original. Provenance standards like C2PA adopt signed manifests and Merkle-based fragment validation, yet their bindings target encoded assets and break under re-encoding or routine processing.\n  We propose MerkleSpeech, a system for public-key verifiable, chunk-localised speech provenance offering two tiers of assurance. The first, a robust watermark attribution layer (WM-only), survives common distribution transforms and answers \"was this chunk issued by a known party?\". The second, a strict cryptographic integrity layer (MSv1), verifies Merkle inclusion of the chunk's fingerprint under an issuer signature. The system computes perceptual fingerprints over short speech chunks, commits them in a Merkle tree whose root is signed with an issuer key, and embeds a compact in-band watermark payload carrying a random content identifier and chunk metadata sufficient to retrieve Merkle inclusion proofs from a repository. Once the payload is extracted, all subsequent verification steps (signature check, fingerprint recomputation, Merkle inclusion) use only public information. The result is a splice-aware timeline indicating which regions pass each tier and why any given region fails. We describe the protocol, provide pseudocode, and present experiments targeting very low false positive rates under resampling, bandpass filtering, and additive noise, informed by recent audits identifying neural codecs as a major stressor for post-hoc audio watermarks.", "AI": {"tldr": "MerkleSpeech\u7cfb\u7edf\u63d0\u4f9b\u4e24\u5c42\u8bed\u97f3\u6765\u6e90\u9a8c\u8bc1\uff1a\u6c34\u5370\u5f52\u5c5e\u5c42\uff08\u6297\u53d8\u6362\uff09\u548c\u4e25\u683c\u52a0\u5bc6\u5b8c\u6574\u6027\u5c42\uff08Merkle\u5305\u542b\u9a8c\u8bc1\uff09\uff0c\u901a\u8fc7\u611f\u77e5\u6307\u7eb9\u3001Merkle\u6811\u548c\u7b7e\u540d\u5b9e\u73b0\u53ef\u516c\u5f00\u9a8c\u8bc1\u7684\u7247\u6bb5\u7ea7\u6765\u6e90\u8ffd\u8e2a\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u6765\u6e90\u9a8c\u8bc1\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff1a\u4f20\u7edf\u6c34\u5370\u68c0\u6d4b\u65e0\u6cd5\u63d0\u4f9b\u7b2c\u4e09\u65b9\u53ef\u9a8c\u8bc1\u7684\u52a0\u5bc6\u8bc1\u660e\uff1bC2PA\u7b49\u6807\u51c6\u9488\u5bf9\u7f16\u7801\u8d44\u4ea7\uff0c\u5728\u91cd\u65b0\u7f16\u7801\u6216\u5e38\u89c4\u5904\u7406\u65f6\u4f1a\u5931\u6548\u3002\u9700\u8981\u4e00\u79cd\u80fd\u62b5\u6297\u5e38\u89c1\u5206\u53d1\u53d8\u6362\u3001\u652f\u6301\u7247\u6bb5\u7ea7\u9a8c\u8bc1\u3001\u5e76\u63d0\u4f9b\u52a0\u5bc6\u8bc1\u660e\u7684\u8bed\u97f3\u6765\u6e90\u9a8c\u8bc1\u7cfb\u7edf\u3002", "method": "\u7cfb\u7edf\u8ba1\u7b97\u77ed\u8bed\u97f3\u7247\u6bb5\u7684\u611f\u77e5\u6307\u7eb9\uff0c\u6784\u5efaMerkle\u6811\u5e76\u7b7e\u540d\u6839\u8282\u70b9\uff0c\u5d4c\u5165\u5305\u542b\u5185\u5bb9\u6807\u8bc6\u7b26\u548c\u7247\u6bb5\u5143\u6570\u636e\u7684\u7d27\u51d1\u6c34\u5370\u8f7d\u8377\u3002\u9a8c\u8bc1\u65f6\u63d0\u53d6\u8f7d\u8377\uff0c\u4f7f\u7528\u516c\u5f00\u4fe1\u606f\u8fdb\u884c\u7b7e\u540d\u9a8c\u8bc1\u3001\u6307\u7eb9\u91cd\u65b0\u8ba1\u7b97\u548cMerkle\u5305\u542b\u9a8c\u8bc1\uff0c\u751f\u6210\u62fc\u63a5\u611f\u77e5\u7684\u65f6\u95f4\u7ebf\u5206\u6790\u3002", "result": "\u7cfb\u7edf\u5728\u91cd\u91c7\u6837\u3001\u5e26\u901a\u6ee4\u6ce2\u548c\u52a0\u6027\u566a\u58f0\u7b49\u5e38\u89c1\u53d8\u6362\u4e0b\u4fdd\u6301\u6781\u4f4e\u7684\u8bef\u62a5\u7387\uff0c\u7279\u522b\u9488\u5bf9\u795e\u7ecf\u7f16\u89e3\u7801\u5668\u8fd9\u4e00\u5bf9\u540e\u5904\u7406\u6c34\u5370\u7684\u4e3b\u8981\u538b\u529b\u6e90\u8fdb\u884c\u4e86\u4f18\u5316\u3002\u80fd\u591f\u751f\u6210\u8be6\u7ec6\u7684\u65f6\u95f4\u7ebf\uff0c\u663e\u793a\u54ea\u4e9b\u533a\u57df\u901a\u8fc7\u5404\u5c42\u9a8c\u8bc1\u4ee5\u53ca\u5931\u8d25\u539f\u56e0\u3002", "conclusion": "MerkleSpeech\u63d0\u4f9b\u4e86\u53ef\u516c\u5f00\u9a8c\u8bc1\u7684\u7247\u6bb5\u7ea7\u8bed\u97f3\u6765\u6e90\u8ffd\u8e2a\uff0c\u7ed3\u5408\u4e86\u6c34\u5370\u7684\u9c81\u68d2\u6027\u548c\u52a0\u5bc6\u8bc1\u660e\u7684\u53ef\u4fe1\u6027\uff0c\u80fd\u591f\u5e94\u5bf9\u5b9e\u9645\u5de5\u4f5c\u6d41\u4e2d\u7684\u62fc\u63a5\u3001\u5f15\u7528\u3001\u4fee\u526a\u548c\u5e73\u53f0\u7ea7\u53d8\u6362\uff0c\u4e3a\u8bed\u97f3\u5185\u5bb9\u6765\u6e90\u63d0\u4f9b\u4e86\u4e24\u5c42\u4fdd\u969c\u673a\u5236\u3002"}}
{"id": "2602.10540", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10540", "abs": "https://arxiv.org/abs/2602.10540", "authors": ["Arty Starr", "Margaret-Anne Storey"], "title": "Theory of Troubleshooting: The Developer's Cognitive Experience of Overcoming Confusion", "comment": "42 pages + 16 pages of appendix, 13 figures, 2 tables", "summary": "This paper introduces a Theory of Troubleshooting that is rooted in cognitive science. This theory helps software developers explain the challenges they face and the project risks that emerge as troubleshooting becomes difficult. We define troubleshooting as the cognitive problem-solving process of identifying, understanding, and constructing a mental model of the cause of an unexpected system behavior, and consider the cognitive process of troubleshooting to be an integral part of the activity of debugging. Troubleshooting is a particularly intense and draining aspect of software work, placing sustained demands on attention, working memory, and mental modeling. By surfacing and naming the confusion experience inherent in troubleshooting in terms of neurological and attentional dynamics, our theory explains how prolonged troubleshooting can deplete cognitive resources and lead to cognitive fatigue. In the study presented in this paper, we interview 27 professional developers about their troubleshooting experiences, and follow a Constructivist Grounded Theory approach to construct a theory grounded in empirical data. Our theory contributes to research on Developer Experience by providing a cognitive foundation for understanding troubleshooting difficulty, fatigue, and sustainability risk--and offers practical implications for both research and industry.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u63d0\u51fa\u4e86\u4e00\u79cd\u6545\u969c\u6392\u9664\u7406\u8bba\uff0c\u89e3\u91ca\u4e86\u8f6f\u4ef6\u5f00\u53d1\u8005\u5728\u6545\u969c\u6392\u9664\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u6311\u6218\u548c\u9879\u76ee\u98ce\u9669\uff0c\u901a\u8fc7\u8bbf\u8c0827\u4f4d\u4e13\u4e1a\u5f00\u53d1\u8005\u6784\u5efa\u4e86\u8be5\u7406\u8bba\u3002", "motivation": "\u6545\u969c\u6392\u9664\u662f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7279\u522b\u7d27\u5f20\u548c\u6d88\u8017\u7cbe\u529b\u7684\u90e8\u5206\uff0c\u5bf9\u6ce8\u610f\u529b\u3001\u5de5\u4f5c\u8bb0\u5fc6\u548c\u5fc3\u7406\u5efa\u6a21\u6709\u6301\u7eed\u9700\u6c42\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u4ece\u8ba4\u77e5\u79d1\u5b66\u89d2\u5ea6\u6df1\u5165\u7406\u89e3\u6545\u969c\u6392\u9664\u56f0\u96be\u3001\u75b2\u52b3\u548c\u53ef\u6301\u7eed\u6027\u98ce\u9669\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u91c7\u7528\u5efa\u6784\u4e3b\u4e49\u624e\u6839\u7406\u8bba\u65b9\u6cd5\uff0c\u8bbf\u8c08\u4e8627\u4f4d\u4e13\u4e1a\u5f00\u53d1\u8005\u5173\u4e8e\u4ed6\u4eec\u7684\u6545\u969c\u6392\u9664\u7ecf\u9a8c\uff0c\u57fa\u4e8e\u7ecf\u9a8c\u6570\u636e\u6784\u5efa\u7406\u8bba\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u7684\u6545\u969c\u6392\u9664\u7406\u8bba\uff0c\u8be5\u7406\u8bba\u5c06\u6545\u969c\u6392\u9664\u5b9a\u4e49\u4e3a\u8bc6\u522b\u3001\u7406\u89e3\u548c\u6784\u5efa\u610f\u5916\u7cfb\u7edf\u884c\u4e3a\u539f\u56e0\u7684\u5fc3\u7406\u6a21\u578b\u7684\u8ba4\u77e5\u95ee\u9898\u89e3\u51b3\u8fc7\u7a0b\u3002\u7406\u8bba\u89e3\u91ca\u4e86\u957f\u671f\u6545\u969c\u6392\u9664\u5982\u4f55\u6d88\u8017\u8ba4\u77e5\u8d44\u6e90\u5e76\u5bfc\u81f4\u8ba4\u77e5\u75b2\u52b3\u3002", "conclusion": "\u8be5\u7406\u8bba\u4e3a\u7406\u89e3\u6545\u969c\u6392\u9664\u56f0\u96be\u3001\u75b2\u52b3\u548c\u53ef\u6301\u7eed\u6027\u98ce\u9669\u63d0\u4f9b\u4e86\u8ba4\u77e5\u57fa\u7840\uff0c\u5bf9\u5f00\u53d1\u4f53\u9a8c\u7814\u7a76\u548c\u5de5\u4e1a\u5b9e\u8df5\u90fd\u6709\u5b9e\u9645\u610f\u4e49\uff0c\u6709\u52a9\u4e8e\u89e3\u91ca\u6545\u969c\u6392\u9664\u56f0\u96be\u65f6\u51fa\u73b0\u7684\u9879\u76ee\u98ce\u9669\u3002"}}
{"id": "2602.10625", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10625", "abs": "https://arxiv.org/abs/2602.10625", "authors": ["Nanxu Gong", "Haotian Li", "Sixun Dong", "Jianxun Lian", "Yanjie Fu", "Xing Xie"], "title": "To Think or Not To Think, That is The Question for Large Reasoning Models in Theory of Mind Tasks", "comment": null, "summary": "Theory of Mind (ToM) assesses whether models can infer hidden mental states such as beliefs, desires, and intentions, which is essential for natural social interaction. Although recent progress in Large Reasoning Models (LRMs) has boosted step-by-step inference in mathematics and coding, it is still underexplored whether this benefit transfers to socio-cognitive skills. We present a systematic study of nine advanced Large Language Models (LLMs), comparing reasoning models with non-reasoning models on three representative ToM benchmarks. The results show that reasoning models do not consistently outperform non-reasoning models and sometimes perform worse. A fine-grained analysis reveals three insights. First, slow thinking collapses: accuracy significantly drops as responses grow longer, and larger reasoning budgets hurt performance. Second, moderate and adaptive reasoning benefits performance: constraining reasoning length mitigates failure, while distinct success patterns demonstrate the necessity of dynamic adaptation. Third, option matching shortcut: when multiple choice options are removed, reasoning models improve markedly, indicating reliance on option matching rather than genuine deduction. We also design two intervention approaches: Slow-to-Fast (S2F) adaptive reasoning and Think-to-Match (T2M) shortcut prevention to further verify and mitigate the problems. With all results, our study highlights the advancement of LRMs in formal reasoning (e.g., math, code) cannot be fully transferred to ToM, a typical task in social reasoning. We conclude that achieving robust ToM requires developing unique capabilities beyond existing reasoning methods.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u63a8\u7406\u80fd\u529b\u65e0\u6cd5\u5b8c\u5168\u8fc1\u79fb\u5230\u793e\u4f1a\u8ba4\u77e5\u9886\u57df\uff0c\u5b58\u5728\"\u6162\u601d\u8003\u5d29\u6e83\"\u3001\u4f9d\u8d56\u9009\u9879\u5339\u914d\u7b49\u95ee\u9898\u3002", "motivation": "\u867d\u7136\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u7b49\u6b63\u5f0f\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u8fdb\u6b65\uff0c\u4f46\u8fd9\u4e9b\u80fd\u529b\u662f\u5426\u80fd\u591f\u8fc1\u79fb\u5230\u793e\u4f1a\u8ba4\u77e5\u6280\u80fd\uff08\u5982\u5fc3\u7406\u7406\u8bba\uff09\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u5bf99\u4e2a\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\uff0c\u6bd4\u8f83\u63a8\u7406\u6a21\u578b\u4e0e\u975e\u63a8\u7406\u6a21\u578b\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u5fc3\u7406\u7406\u8bba\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u6790\u3002", "result": "\u63a8\u7406\u6a21\u578b\u5728\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u4e0a\u5e76\u4e0d\u603b\u662f\u4f18\u4e8e\u975e\u63a8\u7406\u6a21\u578b\uff0c\u6709\u65f6\u8868\u73b0\u66f4\u5dee\u3002\u53d1\u73b0\u6162\u601d\u8003\u5d29\u6e83\u3001\u9002\u5ea6\u81ea\u9002\u5e94\u63a8\u7406\u6709\u76ca\u3001\u9009\u9879\u5339\u914d\u6377\u5f84\u4e09\u4e2a\u5173\u952e\u73b0\u8c61\u3002", "conclusion": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u6b63\u5f0f\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8fdb\u6b65\u65e0\u6cd5\u5b8c\u5168\u8fc1\u79fb\u5230\u5fc3\u7406\u7406\u8bba\u7b49\u793e\u4f1a\u63a8\u7406\u4efb\u52a1\uff0c\u5b9e\u73b0\u7a33\u5065\u7684\u5fc3\u7406\u7406\u8bba\u9700\u8981\u8d85\u8d8a\u73b0\u6709\u63a8\u7406\u65b9\u6cd5\u7684\u72ec\u7279\u80fd\u529b\u3002"}}
{"id": "2602.10169", "categories": ["cs.CR", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10169", "abs": "https://arxiv.org/abs/2602.10169", "authors": ["Nicolai Maisch", "Shengjian Chen", "Alexander Robertus", "Samed Ajdinovi\u0107", "Armin Lechler", "Alexander Verl", "Oliver Riedel"], "title": "Non-Fungible Blockchain Tokens for Traceable Online-Quality Assurance of Milled Workpieces", "comment": null, "summary": "This work presents a concept and implementation for the secure storage and transfer of quality-relevant data of milled workpieces from online-quality assurance processes enabled by real-time simulation models. It utilises Non-Fungible Tokens (NFT) to securely and interoperably store quality data in the form of an Asset Administration Shell (AAS) on a public Ethereum blockchain. Minted by a custom smart contract, the NFTs reference the metadata saved in the Interplanetary File System (IPFS), allowing new data from additional processing steps to be added in a flexible yet secure manner. The concept enables automated traceability throughout the value chain, minimising the need for time-consuming and costly repetitive manual quality checks.", "AI": {"tldr": "\u5229\u7528NFT\u548c\u533a\u5757\u94fe\u6280\u672f\u5b9e\u73b0\u94e3\u524a\u5de5\u4ef6\u5728\u7ebf\u8d28\u91cf\u6570\u636e\u7684\u5b89\u5168\u5b58\u50a8\u4e0e\u4f20\u8f93\uff0c\u901a\u8fc7\u667a\u80fd\u5408\u7ea6\u548cIPFS\u7cfb\u7edf\u5b9e\u73b0\u8d28\u91cf\u6570\u636e\u7684\u53ef\u8ffd\u6eaf\u6027", "motivation": "\u89e3\u51b3\u5728\u7ebf\u8d28\u91cf\u4fdd\u8bc1\u8fc7\u7a0b\u4e2d\u94e3\u524a\u5de5\u4ef6\u8d28\u91cf\u76f8\u5173\u6570\u636e\u7684\u5b89\u5168\u5b58\u50a8\u548c\u4f20\u8f93\u95ee\u9898\uff0c\u51cf\u5c11\u8017\u65f6\u4e14\u6210\u672c\u9ad8\u6602\u7684\u91cd\u590d\u6027\u624b\u52a8\u8d28\u91cf\u68c0\u67e5", "method": "\u4f7f\u7528NFT\u5728\u516c\u5171\u4ee5\u592a\u574a\u533a\u5757\u94fe\u4e0a\u5b89\u5168\u5b58\u50a8\u8d28\u91cf\u6570\u636e\uff08\u91c7\u7528\u8d44\u4ea7\u7ba1\u7406\u58f3AAS\u683c\u5f0f\uff09\uff0c\u901a\u8fc7\u81ea\u5b9a\u4e49\u667a\u80fd\u5408\u7ea6\u94f8\u9020NFT\uff0c\u5c06\u5143\u6570\u636e\u5b58\u50a8\u5728IPFS\u4e2d\uff0c\u652f\u6301\u7075\u6d3b\u6dfb\u52a0\u65b0\u5904\u7406\u6b65\u9aa4\u7684\u6570\u636e", "result": "\u5b9e\u73b0\u4e86\u8d28\u91cf\u6570\u636e\u7684\u81ea\u52a8\u5316\u8ffd\u6eaf\u80fd\u529b\uff0c\u80fd\u591f\u5728\u6574\u4e2a\u4ef7\u503c\u94fe\u4e2d\u5b89\u5168\u3001\u4e92\u64cd\u4f5c\u5730\u5b58\u50a8\u548c\u4f20\u8f93\u8d28\u91cf\u6570\u636e", "conclusion": "\u8be5\u6982\u5ff5\u4e3a\u5728\u7ebf\u8d28\u91cf\u4fdd\u8bc1\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u5b89\u5168\u7684\u6570\u636e\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u533a\u5757\u94fe\u548cNFT\u6280\u672f\u5b9e\u73b0\u4e86\u8d28\u91cf\u6570\u636e\u7684\u53ef\u8ffd\u6eaf\u6027\u548c\u5b89\u5168\u6027"}}
{"id": "2602.10635", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10635", "abs": "https://arxiv.org/abs/2602.10635", "authors": ["Keane Ong", "Sabri Boughorbel", "Luwei Xiao", "Chanakya Ekbote", "Wei Dai", "Ao Qu", "Jingyao Wu", "Rui Mao", "Ehsan Hoque", "Erik Cambria", "Gianmarco Mengaldo", "Paul Pu Liang"], "title": "OmniSapiens: A Foundation Model for Social Behavior Processing via Heterogeneity-Aware Relative Policy Optimization", "comment": null, "summary": "To develop socially intelligent AI, existing approaches typically model human behavioral dimensions (e.g., affective, cognitive, or social attributes) in isolation. Although useful, task-specific modeling often increases training costs and limits generalization across behavioral settings. Recent reasoning RL methods facilitate training a single unified model across multiple behavioral tasks, but do not explicitly address learning across different heterogeneous behavioral data. To address this gap, we introduce Heterogeneity-Aware Relative Policy Optimization (HARPO), an RL method that balances leaning across heterogeneous tasks and samples. This is achieved by modulating advantages to ensure that no single task or sample carries disproportionate influence during policy optimization. Using HARPO, we develop and release Omnisapiens-7B 2.0, a foundation model for social behavior processing. Relative to existing behavioral foundation models, Omnisapiens-7B 2.0 achieves the strongest performance across behavioral tasks, with gains of up to +16.85% and +9.37% on multitask and held-out settings respectively, while producing more explicit and robust reasoning traces. We also validate HARPO against recent RL methods, where it achieves the most consistently strong performance across behavioral tasks.", "AI": {"tldr": "HARPO\u662f\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u8282\u4f18\u52bf\u51fd\u6570\u6765\u5e73\u8861\u5f02\u6784\u4efb\u52a1\u548c\u6837\u672c\u7684\u5b66\u4e60\uff0c\u5f00\u53d1\u4e86Omnisapiens-7B 2.0\u793e\u4ea4\u884c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5b64\u7acb\u5730\u5efa\u6a21\u4eba\u7c7b\u884c\u4e3a\u7ef4\u5ea6\uff08\u60c5\u611f\u3001\u8ba4\u77e5\u6216\u793e\u4f1a\u5c5e\u6027\uff09\uff0c\u4efb\u52a1\u7279\u5b9a\u5efa\u6a21\u589e\u52a0\u4e86\u8bad\u7ec3\u6210\u672c\u5e76\u9650\u5236\u4e86\u8de8\u884c\u4e3a\u8bbe\u7f6e\u7684\u6cdb\u5316\u80fd\u529b\u3002\u867d\u7136\u6700\u8fd1\u7684\u63a8\u7406RL\u65b9\u6cd5\u53ef\u4ee5\u5728\u591a\u4e2a\u884c\u4e3a\u4efb\u52a1\u4e0a\u8bad\u7ec3\u7edf\u4e00\u6a21\u578b\uff0c\u4f46\u6ca1\u6709\u660e\u786e\u89e3\u51b3\u8de8\u5f02\u6784\u884c\u4e3a\u6570\u636e\u7684\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u5f02\u6784\u611f\u77e5\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08HARPO\uff09\uff0c\u8fd9\u662f\u4e00\u79cdRL\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u8282\u4f18\u52bf\u51fd\u6570\u6765\u786e\u4fdd\u5728\u7b56\u7565\u4f18\u5316\u8fc7\u7a0b\u4e2d\u6ca1\u6709\u4efb\u4f55\u5355\u4e2a\u4efb\u52a1\u6216\u6837\u672c\u4ea7\u751f\u4e0d\u6210\u6bd4\u4f8b\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u5e73\u8861\u8de8\u5f02\u6784\u4efb\u52a1\u548c\u6837\u672c\u7684\u5b66\u4e60\u3002", "result": "\u4f7f\u7528HARPO\u5f00\u53d1\u4e86Omnisapiens-7B 2.0\u793e\u4ea4\u884c\u4e3a\u5904\u7406\u57fa\u7840\u6a21\u578b\u3002\u76f8\u5bf9\u4e8e\u73b0\u6709\u884c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u5728\u591a\u4efb\u52a1\u548c\u4fdd\u7559\u8bbe\u7f6e\u4e0a\u5206\u522b\u83b7\u5f97\u9ad8\u8fbe+16.85%\u548c+9.37%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u4ea7\u751f\u66f4\u660e\u786e\u548c\u9c81\u68d2\u7684\u63a8\u7406\u8f68\u8ff9\u3002HARPO\u5728\u884c\u4e3a\u4efb\u52a1\u4e0a\u4e5f\u6bd4\u6700\u8fd1\u7684RL\u65b9\u6cd5\u8868\u73b0\u66f4\u4e00\u81f4\u3002", "conclusion": "HARPO\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u5f02\u6784\u884c\u4e3a\u6570\u636e\u7684\u5b66\u4e60\u5e73\u8861\u95ee\u9898\uff0c\u5f00\u53d1\u7684Omnisapiens-7B 2.0\u6a21\u578b\u5728\u793e\u4ea4\u884c\u4e3a\u5904\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5f00\u53d1\u793e\u4ea4\u667a\u80fdAI\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.10655", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.10655", "abs": "https://arxiv.org/abs/2602.10655", "authors": ["Muhammad Yousaf", "Aitor Arrieta", "Shaukat Ali", "Paolo Arcaini", "Shuai Wang"], "title": "Assessing Vision-Language Models for Perception in Autonomous Underwater Robotic Software", "comment": "10 pages, 5 figures, submitted to ICST 2026", "summary": "Autonomous Underwater Robots (AURs) operate in challenging underwater environments, including low visibility and harsh water conditions. Such conditions present challenges for software engineers developing perception modules for the AUR software. To successfully carry out these tasks, deep learning has been incorporated into the AUR software to support its operations. However, the unique challenges of underwater environments pose difficulties for deep learning models, which often rely on labeled data that is scarce and noisy. This may undermine the trustworthiness of AUR software that relies on perception modules. Vision-Language Models (VLMs) offer promising solutions for AUR software as they generalize to unseen objects and remain robust in noisy conditions by inferring information from contextual cues. Despite this potential, their performance and uncertainty in underwater environments remain understudied from a software engineering perspective. Motivated by the needs of an industrial partner in assurance and risk management for maritime systems to assess the potential use of VLMs in this context, we present an empirical evaluation of VLM-based perception modules within the AUR software. We assess their ability to detect underwater trash by computing performance, uncertainty, and their relationship, to enable software engineers to select appropriate VLMs for their AUR software.", "AI": {"tldr": "\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u4e3b\u6c34\u4e0b\u673a\u5668\u4eba\u611f\u77e5\u6a21\u5757\u4e2d\u7684\u6027\u80fd\u3001\u4e0d\u786e\u5b9a\u6027\u548c\u53ef\u9760\u6027\uff0c\u4ee5\u5e2e\u52a9\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u7528\u4e8e\u6c34\u4e0b\u5783\u573e\u68c0\u6d4b\u4efb\u52a1\u3002", "motivation": "\u6c34\u4e0b\u73af\u5883\u5177\u6709\u4f4e\u80fd\u89c1\u5ea6\u548c\u6076\u52a3\u6761\u4ef6\u7b49\u6311\u6218\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4f9d\u8d56\u7a00\u7f3a\u4e14\u6709\u566a\u58f0\u7684\u6807\u6ce8\u6570\u636e\uff0c\u53ef\u80fd\u5f71\u54cdAUR\u8f6f\u4ef6\u7684\u53ef\u9760\u6027\u3002\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u7269\u4f53\u5e76\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u4f46\u5176\u5728\u6c34\u4e0b\u73af\u5883\u4e2d\u7684\u6027\u80fd\u548c\u4e0d\u786e\u5b9a\u6027\u5c1a\u672a\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89d2\u5ea6\u6df1\u5165\u7814\u7a76\u3002", "method": "\u5bf9\u57fa\u4e8eVLM\u7684AUR\u8f6f\u4ef6\u611f\u77e5\u6a21\u5757\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u901a\u8fc7\u8ba1\u7b97\u6027\u80fd\u3001\u4e0d\u786e\u5b9a\u6027\u53ca\u5176\u5173\u7cfb\u6765\u8bc4\u4f30\u5b83\u4eec\u68c0\u6d4b\u6c34\u4e0b\u5783\u573e\u7684\u80fd\u529b\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86VLM\u5728\u6c34\u4e0b\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3001\u4e0d\u786e\u5b9a\u6027\u548c\u53ef\u9760\u6027\u8bc4\u4f30\u7ed3\u679c\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u9009\u62e9\u9002\u5408AUR\u8f6f\u4ef6\u7684VLM\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002", "conclusion": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u6c34\u4e0b\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89d2\u5ea6\u7cfb\u7edf\u8bc4\u4f30\u5176\u6027\u80fd\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u786e\u4fddAUR\u8f6f\u4ef6\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2602.10699", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10699", "abs": "https://arxiv.org/abs/2602.10699", "authors": ["Jie Jiang", "Yangru Huang", "Zeyu Wang", "Changping Wang", "Yuling Xiong", "Jun Zhang", "Huan Yu"], "title": "Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation", "comment": null, "summary": "Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch. Conventional likelihood-dominated decoding (e.g., beam search) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration, where high-reward items in low-probability branches are prematurely pruned and rarely sampled, and (2) advantage compression, where trajectories sharing high-probability prefixes receive highly correlated rewards with low within-group variance, yielding a weak comparative signal for RL. To address these challenges, we propose V-STAR, a Value-guided Sampling and Tree-structured Advantage Reinforcement framework. V-STAR forms a self-evolving loop via two synergistic components. First, a Value-Guided Efficient Decoding (VED) is developed to identify decisive nodes and selectively deepen high-potential prefixes. This improves exploration efficiency without exhaustive tree search. Second, we propose Sibling-GRPO, which exploits the induced tree topology to compute sibling-relative advantages and concentrates learning signals on decisive branching decisions. Extensive experiments on both offline and online datasets demonstrate that V-STAR outperforms state-of-the-art baselines, delivering superior accuracy and candidate-set diversity under strict latency constraints.", "AI": {"tldr": "V-STAR\u6846\u67b6\u89e3\u51b3\u751f\u6210\u5f0f\u63a8\u8350\u4e2dRL\u8bad\u7ec3\u7684\u6982\u7387-\u5956\u52b1\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u4ef7\u503c\u5f15\u5bfc\u91c7\u6837\u548c\u6811\u72b6\u4f18\u52bf\u5f3a\u5316\u63d0\u5347\u63a2\u7d22\u6548\u7387\u548c\u51b3\u7b56\u4fe1\u53f7", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u4f3c\u7136\u7684\u89e3\u7801\u65b9\u6cd5\u5b58\u5728\u8fd1\u89c6\u504f\u5dee\uff0c\u5bfc\u81f4\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a1) \u63a2\u7d22\u4e0d\u8db3\uff0c\u9ad8\u5956\u52b1\u4f46\u4f4e\u6982\u7387\u5206\u652f\u88ab\u8fc7\u65e9\u526a\u679d\uff1b2) \u4f18\u52bf\u538b\u7f29\uff0c\u5171\u4eab\u9ad8\u6982\u7387\u524d\u7f00\u7684\u8f68\u8ff9\u5956\u52b1\u9ad8\u5ea6\u76f8\u5173\uff0cRL\u5b66\u4e60\u4fe1\u53f7\u5f31", "method": "\u63d0\u51faV-STAR\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u7ec4\u4ef6\uff1a1) \u4ef7\u503c\u5f15\u5bfc\u9ad8\u6548\u89e3\u7801(VED)\uff0c\u8bc6\u522b\u5173\u952e\u8282\u70b9\u5e76\u9009\u62e9\u6027\u52a0\u6df1\u9ad8\u6f5c\u529b\u524d\u7f00\uff1b2) Sibling-GRPO\uff0c\u5229\u7528\u6811\u72b6\u62d3\u6251\u8ba1\u7b97\u5144\u5f1f\u76f8\u5bf9\u4f18\u52bf\uff0c\u805a\u7126\u5b66\u4e60\u4fe1\u53f7\u4e8e\u5173\u952e\u5206\u652f\u51b3\u7b56", "result": "\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cV-STAR\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4e25\u683c\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u63d0\u4f9b\u66f4\u4f18\u7684\u51c6\u786e\u6027\u548c\u5019\u9009\u96c6\u591a\u6837\u6027", "conclusion": "V-STAR\u901a\u8fc7\u89e3\u51b3\u6982\u7387-\u5956\u52b1\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u6709\u6548\u63d0\u5347\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2dRL\u8bad\u7ec3\u7684\u6548\u679c\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a2\u7d22\u548c\u51b3\u7b56\u4fe1\u53f7"}}
{"id": "2602.10272", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.10272", "abs": "https://arxiv.org/abs/2602.10272", "authors": ["Simon Erni", "Martin Kotuliak", "Marc Roeschlin", "Richard Baker", "Srdjan Capkun"], "title": "5Gone: Uplink Overshadowing Attacks in 5G-SA", "comment": null, "summary": "5G presents numerous advantages compared to previous generations: improved throughput, lower latency, and improved privacy protection for subscribers. Attacks against 5G standalone (SA) commonly use fake base stations (FBS), which need to operate at a very high output power level to lure victim phones to connect to them and are thus highly detectable. In this paper, we introduce 5Gone, a powerful software-defined radio (SDR)-based uplink overshadowing attack method against 5G-SA. 5Gone exploits deficiencies in the 3GPP standard to perform surgical, covert denial-of-service, privacy, and downgrade attacks. Uplink overshadowing means that an attacker is transmitting at exactly the same time and frequency as the victim UE, but with a slightly higher output power. 5Gone runs on a COTS x86 computer without any need for dedicated hardware acceleration and can overshadow commercial 100 MHz cells with an E2E latency of less than 500$\u03bc$s, which up to now has not been possible with any software-based UE implementation. We demonstrate that 5Gone is highly scalable, even when many UEs are connecting in parallel, and finally evaluate the attacks end-to-end against 7 phone models and three different chipset vendors both in our lab and in the real-world on public gNodeBs.", "AI": {"tldr": "5Gone\u662f\u4e00\u79cd\u9488\u5bf95G\u72ec\u7acb\u7ec4\u7f51\u7684\u8f6f\u4ef6\u5b9a\u4e49\u65e0\u7ebf\u7535\u4e0a\u884c\u94fe\u8def\u906e\u853d\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u75283GPP\u6807\u51c6\u7f3a\u9677\u8fdb\u884c\u9690\u853d\u7684\u62d2\u7edd\u670d\u52a1\u3001\u9690\u79c1\u548c\u964d\u7ea7\u653b\u51fb\uff0c\u65e0\u9700\u4e13\u7528\u786c\u4ef6\u5373\u53ef\u5b9e\u65f6\u906e\u853d\u5546\u7528\u57fa\u7ad9\u3002", "motivation": "\u9488\u5bf95G\u72ec\u7acb\u7ec4\u7f51\u7684\u653b\u51fb\u901a\u5e38\u4f7f\u7528\u5047\u57fa\u7ad9\uff0c\u4f46\u9700\u8981\u9ad8\u529f\u7387\u8f93\u51fa\u4e14\u6613\u88ab\u68c0\u6d4b\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u9690\u853d\u3001\u4f4e\u529f\u7387\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u6807\u51c6\u7f3a\u9677\u8fdb\u884c\u7cbe\u51c6\u653b\u51fb\u3002", "method": "\u91c7\u7528\u8f6f\u4ef6\u5b9a\u4e49\u65e0\u7ebf\u7535\u7684\u4e0a\u884c\u94fe\u8def\u906e\u853d\u653b\u51fb\u6280\u672f\uff0c\u653b\u51fb\u8005\u4e0e\u53d7\u5bb3\u7528\u6237\u8bbe\u5907\u5728\u540c\u4e00\u65f6\u95f4\u548c\u9891\u7387\u4f20\u8f93\uff0c\u4f46\u529f\u7387\u7565\u9ad8\u3002\u7cfb\u7edf\u8fd0\u884c\u5728\u5546\u7528x86\u8ba1\u7b97\u673a\u4e0a\uff0c\u65e0\u9700\u4e13\u7528\u786c\u4ef6\u52a0\u901f\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u4f4e\u4e8e500\u5fae\u79d2\u3002", "result": "5Gone\u80fd\u591f\u906e\u853d\u5546\u7528100MHz\u57fa\u7ad9\uff0c\u9ad8\u5ea6\u53ef\u6269\u5c55\uff0c\u5373\u4f7f\u591a\u4e2a\u7528\u6237\u8bbe\u5907\u5e76\u884c\u8fde\u63a5\u4e5f\u80fd\u6709\u6548\u653b\u51fb\u3002\u5728\u5b9e\u9a8c\u5ba4\u548c\u771f\u5b9e\u516c\u5171gNodeB\u4e0a\u5bf97\u6b3e\u624b\u673a\u6a21\u578b\u548c3\u4e2a\u4e0d\u540c\u82af\u7247\u4f9b\u5e94\u5546\u8fdb\u884c\u4e86\u7aef\u5230\u7aef\u8bc4\u4f30\u9a8c\u8bc1\u3002", "conclusion": "5Gone\u5c55\u793a\u4e86\u5229\u75283GPP\u6807\u51c6\u7f3a\u9677\u8fdb\u884c\u9690\u853d\u4e0a\u884c\u94fe\u8def\u906e\u853d\u653b\u51fb\u7684\u53ef\u884c\u6027\uff0c\u8fd9\u79cd\u653b\u51fb\u65b9\u6cd5\u6bd4\u4f20\u7edf\u5047\u57fa\u7ad9\u653b\u51fb\u66f4\u96be\u4ee5\u68c0\u6d4b\uff0c\u5bf95G\u5b89\u5168\u63d0\u51fa\u4e86\u65b0\u7684\u6311\u6218\u3002"}}
{"id": "2602.10758", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10758", "abs": "https://arxiv.org/abs/2602.10758", "authors": ["Bo Wang", "Yueyang Chen", "Jieke Shi", "Minghui Li", "Yunbo Lyu", "Yinan Wu", "Youfang Lin", "Zhou Yang"], "title": "Hidden Licensing Risks in the LLMware Ecosystem", "comment": null, "summary": "Large Language Models (LLMs) are increasingly integrated into software systems, giving rise to a new class of systems referred to as LLMware. Beyond traditional source-code components, LLMware embeds or interacts with LLMs that depend on other models and datasets, forming complex supply chains across open-source software (OSS), models, and datasets. However, licensing issues emerging from these intertwined dependencies remain largely unexplored. Leveraging GitHub and Hugging Face, we curate a large-scale dataset capturing LLMware supply chains, including 12,180 OSS repositories, 3,988 LLMs, and 708 datasets. Our analysis reveals that license distributions in LLMware differ substantially from traditional OSS ecosystems. We further examine license-related discussions and find that license selection and maintenance are the dominant concerns, accounting for 84% of cases. To understand incompatibility risks, we analyze license conflicts along supply chains and evaluate state-of-the-art detection approaches, which achieve only 58% and 76% F1 scores in this setting. Motivated by these limitations, we propose LiAgent, an LLM-based agent framework for ecosystem-level license compatibility analysis. LiAgent achieves an F1 score of 87%, improving performance by 14 percentage points over prior methods. We reported 60 incompatibility issues detected by LiAgent, 11 of which have been confirmed by developers. Notably, two conflicted LLMs have over 107 million and 5 million downloads on Hugging Face, respectively, indicating potentially widespread downstream impact. We conclude with implications and recommendations to support the sustainable growth of the LLMware ecosystem.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86LLMware\uff08\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f6f\u4ef6\u7cfb\u7edf\uff09\u4e2d\u7684\u8bb8\u53ef\u8bc1\u95ee\u9898\uff0c\u53d1\u73b0\u5176\u8bb8\u53ef\u8bc1\u5206\u5e03\u4e0e\u4f20\u7edf\u5f00\u6e90\u8f6f\u4ef6\u751f\u6001\u4e0d\u540c\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u6548\u679c\u6709\u9650\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eLLM\u7684LiAgent\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bb8\u53ef\u8bc1\u517c\u5bb9\u6027\u5206\u6790\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\uff0c\u5f62\u6210\u4e86LLMware\u8fd9\u7c7b\u65b0\u7cfb\u7edf\uff0c\u5b83\u4eec\u4f9d\u8d56\u590d\u6742\u7684\u5f00\u6e90\u8f6f\u4ef6\u3001\u6a21\u578b\u548c\u6570\u636e\u96c6\u4f9b\u5e94\u94fe\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u76f8\u4e92\u4ea4\u7ec7\u7684\u4f9d\u8d56\u5173\u7cfb\u5e26\u6765\u7684\u8bb8\u53ef\u8bc1\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u7814\u7a76\u4eceGitHub\u548cHugging Face\u6536\u96c6\u4e86\u5927\u89c4\u6a21LLMware\u4f9b\u5e94\u94fe\u6570\u636e\u96c6\uff0812,180\u4e2a\u5f00\u6e90\u4ed3\u5e93\u30013,988\u4e2aLLM\u3001708\u4e2a\u6570\u636e\u96c6\uff09\uff0c\u5206\u6790\u4e86\u8bb8\u53ef\u8bc1\u5206\u5e03\u548c\u8ba8\u8bba\uff0c\u8bc4\u4f30\u4e86\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8eLLM\u7684LiAgent\u6846\u67b6\u8fdb\u884c\u751f\u6001\u7cfb\u7edf\u7ea7\u522b\u7684\u8bb8\u53ef\u8bc1\u517c\u5bb9\u6027\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLMware\u7684\u8bb8\u53ef\u8bc1\u5206\u5e03\u4e0e\u4f20\u7edf\u5f00\u6e90\u8f6f\u4ef6\u751f\u6001\u663e\u8457\u4e0d\u540c\uff1b\u8bb8\u53ef\u8bc1\u9009\u62e9\u548c\u7ef4\u62a4\u662f\u4e3b\u8981\u5173\u6ce8\u70b9\uff08\u536084%\uff09\uff1b\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5728LLMware\u73af\u5883\u4e2d\u6548\u679c\u6709\u9650\uff08F1\u5206\u6570\u4ec558%\u548c76%\uff09\uff1b\u63d0\u51fa\u7684LiAgent\u6846\u67b6\u8fbe\u523087%\u7684F1\u5206\u6570\uff0c\u63d0\u5347\u4e8614\u4e2a\u767e\u5206\u70b9\uff1b\u68c0\u6d4b\u523060\u4e2a\u4e0d\u517c\u5bb9\u95ee\u9898\uff0c\u5176\u4e2d11\u4e2a\u5df2\u83b7\u5f00\u53d1\u8005\u786e\u8ba4\u3002", "conclusion": "LLMware\u751f\u6001\u7cfb\u7edf\u9762\u4e34\u72ec\u7279\u7684\u8bb8\u53ef\u8bc1\u6311\u6218\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u6548\u679c\u4e0d\u8db3\u3002LiAgent\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u8bb8\u53ef\u8bc1\u517c\u5bb9\u6027\u5206\u6790\u7684\u51c6\u786e\u6027\uff0c\u6709\u52a9\u4e8e\u652f\u6301LLMware\u751f\u6001\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u4e24\u4e2a\u5b58\u5728\u51b2\u7a81\u7684LLM\u4e0b\u8f7d\u91cf\u5de8\u5927\uff081.07\u4ebf\u548c500\u4e07\uff09\uff0c\u53ef\u80fd\u5bf9\u4e0b\u6e38\u4ea7\u751f\u5e7f\u6cdb\u5f71\u54cd\u3002"}}
{"id": "2602.10802", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10802", "abs": "https://arxiv.org/abs/2602.10802", "authors": ["Da-Lun Chen", "Prasasthy Balasubramanian", "Lauri Lov\u00e9n", "Susanna Pirttikangas", "Jaakko Sauvola", "Panagiotis Kostakos"], "title": "Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act", "comment": null, "summary": "Many staff and students in higher education have adopted generative artificial intelligence (GenAI) tools in their work and study. GenAI is expected to enhance cognitive systems by enabling personalized learning and streamlining educational services. However, stakeholders perceptions of GenAI in higher education remain divided, shaped by cultural, disciplinary, and institutional contexts. In addition, the EU AI Act requires universities to ensure regulatory compliance when deploying cognitive systems. These developments highlight the need for institutions to engage stakeholders and tailor GenAI integration to their needs while addressing concerns. This study investigates how GenAI is perceived within the disciplines of Information Technology and Electrical Engineering (ITEE). Using a mixed-method approach, we surveyed 61 staff and 37 students at the Faculty of ITEE, University of Oulu. The results reveal both shared and discipline-specific themes, including strong interest in programming support from GenAI and concerns over response quality, privacy, and academic integrity. Drawing from these insights, the study identifies a set of high-level requirements and proposes a conceptual framework for responsible GenAI integration. Disciplinary-specific requirements reinforce the importance of stakeholder engagement when integrating GenAI into higher education. The high-level requirements and the framework provide practical guidance for universities aiming to harness GenAI while addressing stakeholder concerns and ensuring regulatory compliance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e86\u9ad8\u7b49\u6559\u80b2\u4e2d\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u8ba4\u77e5\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u5206\u6790ITEE\u9886\u57df\u5e08\u751f\u5bf9GenAI\u7684\u770b\u6cd5\uff0c\u8bc6\u522b\u4e86\u5171\u540c\u548c\u5b66\u79d1\u7279\u5b9a\u7684\u4e3b\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u8d1f\u8d23\u4efb\u6574\u5408\u7684\u6846\u67b6\u3002", "motivation": "\u9ad8\u7b49\u6559\u80b2\u4e2d\u5e08\u751f\u5df2\u5e7f\u6cdb\u91c7\u7528\u751f\u6210\u5f0fAI\u5de5\u5177\uff0c\u4f46\u5229\u76ca\u76f8\u5173\u8005\u5bf9GenAI\u7684\u770b\u6cd5\u5b58\u5728\u5206\u6b67\uff0c\u53d7\u6587\u5316\u3001\u5b66\u79d1\u548c\u5236\u5ea6\u80cc\u666f\u5f71\u54cd\u3002\u6b27\u76dfAI\u6cd5\u6848\u8981\u6c42\u5927\u5b66\u786e\u4fdd\u8ba4\u77e5\u7cfb\u7edf\u7684\u76d1\u7ba1\u5408\u89c4\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e86\u89e3\u4e0d\u540c\u5b66\u79d1\u5bf9GenAI\u7684\u8ba4\u77e5\uff0c\u4ee5\u4fbf\u8d1f\u8d23\u4efb\u5730\u6574\u5408\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u8c03\u67e5\u4e86\u5965\u5362\u5927\u5b66ITEE\u5b66\u9662\u768461\u540d\u6559\u804c\u5458\u5de5\u548c37\u540d\u5b66\u751f\uff0c\u901a\u8fc7\u95ee\u5377\u8c03\u67e5\u6536\u96c6\u6570\u636e\uff0c\u5206\u6790\u5e08\u751f\u5bf9GenAI\u7684\u770b\u6cd5\u548c\u5173\u6ce8\u70b9\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5e08\u751f\u5bf9GenAI\u6709\u5171\u540c\u548c\u5b66\u79d1\u7279\u5b9a\u7684\u4e3b\u9898\uff1a\u5f3a\u70c8\u5173\u6ce8\u7f16\u7a0b\u652f\u6301\uff0c\u540c\u65f6\u62c5\u5fe7\u56de\u7b54\u8d28\u91cf\u3001\u9690\u79c1\u548c\u5b66\u672f\u8bda\u4fe1\u95ee\u9898\u3002\u7814\u7a76\u8bc6\u522b\u4e86\u9ad8\u5c42\u6b21\u9700\u6c42\uff0c\u5e76\u63d0\u51fa\u4e86\u8d1f\u8d23\u4efbGenAI\u6574\u5408\u7684\u6982\u5ff5\u6846\u67b6\u3002", "conclusion": "\u5b66\u79d1\u7279\u5b9a\u9700\u6c42\u5f3a\u8c03\u4e86\u5229\u76ca\u76f8\u5173\u8005\u53c2\u4e0e\u7684\u91cd\u8981\u6027\u3002\u9ad8\u5c42\u6b21\u9700\u6c42\u548c\u6846\u67b6\u4e3a\u5927\u5b66\u5229\u7528GenAI\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u540c\u65f6\u89e3\u51b3\u5229\u76ca\u76f8\u5173\u8005\u5173\u5207\u5e76\u786e\u4fdd\u76d1\u7ba1\u5408\u89c4\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5b9a\u5236\u5316\u6574\u5408\u7b56\u7565\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2602.10787", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.10787", "abs": "https://arxiv.org/abs/2602.10787", "authors": ["Samal Mukhtar", "Yinghua Yao", "Zhu Sun", "Mustafa Mustafa", "Yew Soon Ong", "Youcheng Sun"], "title": "VulReaD: Knowledge-Graph-guided Software Vulnerability Reasoning and Detection", "comment": "22 pages, 3 figures", "summary": "Software vulnerability detection (SVD) is a critical challenge in modern systems. Large language models (LLMs) offer natural-language explanations alongside predictions, but most work focuses on binary evaluation, and explanations often lack semantic consistency with Common Weakness Enumeration (CWE) categories. We propose VulReaD, a knowledge-graph-guided approach for vulnerability reasoning and detection that moves beyond binary classification toward CWE-level reasoning. VulReaD leverages a security knowledge graph (KG) as a semantic backbone and uses a strong teacher LLM to generate CWE-consistent contrastive reasoning supervision, enabling student model training without manual annotations. Students are fine-tuned with Odds Ratio Preference Optimization (ORPO) to encourage taxonomy-aligned reasoning while suppressing unsupported explanations. Across three real-world datasets, VulReaD improves binary F1 by 8-10% and multi-class classification by 30% Macro-F1 and 18% Micro-F1 compared to state-of-the-art baselines. Results show that LLMs outperform deep learning baselines in binary detection and that KG-guided reasoning enhances CWE coverage and interpretability.", "AI": {"tldr": "VulReaD\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b89\u5168\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u8bed\u4e49\u9aa8\u5e72\uff0c\u5229\u7528\u6559\u5e08LLM\u751f\u6210CWE\u4e00\u81f4\u7684\u5bf9\u6bd4\u63a8\u7406\u76d1\u7763\uff0c\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\u8fdb\u884c\u6f0f\u6d1e\u63a8\u7406\u548c\u68c0\u6d4b\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u4e8c\u5143\u5206\u7c7b\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u4e3b\u8981\u5173\u6ce8\u4e8c\u5143\u8bc4\u4f30\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u7684\u89e3\u91ca\u5f80\u5f80\u7f3a\u4e4f\u4e0eCWE\u7c7b\u522b\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8fdb\u884cCWE\u7ea7\u522b\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u63d0\u9ad8\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faVulReaD\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u5b89\u5168\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u8bed\u4e49\u9aa8\u5e72\uff1b2) \u5229\u7528\u5f3a\u5927\u7684\u6559\u5e08LLM\u751f\u6210CWE\u4e00\u81f4\u7684\u5bf9\u6bd4\u63a8\u7406\u76d1\u7763\uff1b3) \u8bad\u7ec3\u5b66\u751f\u6a21\u578b\u65f6\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\uff1b4) \u4f7f\u7528Odds Ratio Preference Optimization\u5fae\u8c03\u5b66\u751f\u6a21\u578b\uff0c\u9f13\u52b1\u7b26\u5408\u5206\u7c7b\u5b66\u7684\u63a8\u7406\uff0c\u6291\u5236\u65e0\u652f\u6301\u7684\u8bf4\u660e\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\uff0cVulReaD\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff1a\u4e8c\u5143F1\u63d0\u9ad8\u4e868-10%\uff0c\u591a\u7c7b\u5206\u7c7b\u7684Macro-F1\u63d0\u9ad8\u4e8630%\uff0cMicro-F1\u63d0\u9ad8\u4e8618%\u3002\u7ed3\u679c\u663e\u793aLLM\u5728\u4e8c\u5143\u68c0\u6d4b\u4e2d\u4f18\u4e8e\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\uff0cKG\u5f15\u5bfc\u7684\u63a8\u7406\u589e\u5f3a\u4e86CWE\u8986\u76d6\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "VulReaD\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u5f15\u5bfc\u7684\u6f0f\u6d1e\u63a8\u7406\u65b9\u6cd5\uff0c\u6210\u529f\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u4e8c\u5143\u5206\u7c7b\uff0c\u5b9e\u73b0\u4e86CWE\u7ea7\u522b\u7684\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2602.10418", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10418", "abs": "https://arxiv.org/abs/2602.10418", "authors": ["Weichen Yu", "Ravi Mangal", "Yinyi Luo", "Kai Hu", "Jingxuan He", "Corina S. Pasareanu", "Matt Fredrikson"], "title": "SecCodePRM: A Process Reward Model for Code Security", "comment": "20 pages", "summary": "Large Language Models are rapidly becoming core components of modern software development workflows, yet ensuring code security remains challenging. Existing vulnerability detection pipelines either rely on static analyzers or use LLM/GNN-based detectors trained with coarse program-level supervision. Both families often require complete context, provide sparse end-of-completion feedback, and can degrade as code length grows, making them ill-suited for real-time, prefix-level assessment during interactive coding and streaming generation. We propose SecCodePRM, a security-oriented process reward model that assigns a context-aware, step-level security score along a code trajectory. To train the model, we derive step-level supervision labels from static analyzers and expert annotations, allowing the model to attend more precisely to fine-grained regions associated with inter-procedural vulnerabilities. SecCodePRM has three applications: full-code vulnerability detection (VD), partial-code VD, and secure code generation (CG). For VD, SecCodePRM uses risk-sensitive aggregation that emphasizes high-risk steps; for CG, SecCodePRM supports inference-time scaling by ranking candidate continuations and favoring higher cumulative reward. This design yields dense, real-time feedback that scales to long-horizon generation. Empirically, SecCodePRM outperforms prior approaches in all three settings, while preserving code functional correctness, suggesting improved security without a safety-utility tradeoff.", "AI": {"tldr": "SecCodePRM\u662f\u4e00\u4e2a\u9762\u5411\u5b89\u5168\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u4e3a\u4ee3\u7801\u8f68\u8ff9\u63d0\u4f9b\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6b65\u9aa4\u7ea7\u5b89\u5168\u8bc4\u5206\uff0c\u652f\u6301\u5b9e\u65f6\u6f0f\u6d1e\u68c0\u6d4b\u548c\u5b89\u5168\u4ee3\u7801\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u5206\u6790\u5668\u6216\u57fa\u4e8eLLM/GNN\u7684\u68c0\u6d4b\u5668\uff0c\u9700\u8981\u5b8c\u6574\u4e0a\u4e0b\u6587\u3001\u63d0\u4f9b\u7a00\u758f\u53cd\u9988\uff0c\u4e14\u968f\u7740\u4ee3\u7801\u957f\u5ea6\u589e\u957f\u6027\u80fd\u4e0b\u964d\uff0c\u4e0d\u9002\u5408\u4ea4\u4e92\u5f0f\u7f16\u7801\u548c\u6d41\u5f0f\u751f\u6210\u7684\u5b9e\u65f6\u524d\u7f00\u7ea7\u8bc4\u4f30\u3002", "method": "\u63d0\u51faSecCodePRM\u5b89\u5168\u5bfc\u5411\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u4ece\u9759\u6001\u5206\u6790\u5668\u548c\u4e13\u5bb6\u6807\u6ce8\u4e2d\u63a8\u5bfc\u6b65\u9aa4\u7ea7\u76d1\u7763\u6807\u7b7e\uff0c\u4f7f\u6a21\u578b\u80fd\u66f4\u7cbe\u786e\u5173\u6ce8\u4e0e\u8fc7\u7a0b\u95f4\u6f0f\u6d1e\u76f8\u5173\u7684\u7ec6\u7c92\u5ea6\u533a\u57df\u3002\u91c7\u7528\u98ce\u9669\u654f\u611f\u805a\u5408\u5f3a\u8c03\u9ad8\u98ce\u9669\u6b65\u9aa4\uff0c\u652f\u6301\u63a8\u7406\u65f6\u6269\u5c55\u901a\u8fc7\u6392\u540d\u5019\u9009\u5ef6\u7eed\u5e76\u504f\u597d\u66f4\u9ad8\u7d2f\u79ef\u5956\u52b1\u3002", "result": "SecCodePRM\u5728\u5b8c\u6574\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u3001\u90e8\u5206\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u548c\u5b89\u5168\u4ee3\u7801\u751f\u6210\u4e09\u4e2a\u5e94\u7528\u573a\u666f\u4e2d\u5747\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u529f\u80fd\u6b63\u786e\u6027\uff0c\u8868\u660e\u5728\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u6ca1\u6709\u6743\u8861\u3002", "conclusion": "SecCodePRM\u63d0\u4f9b\u5bc6\u96c6\u3001\u5b9e\u65f6\u7684\u53cd\u9988\uff0c\u53ef\u6269\u5c55\u5230\u957f\u65f6\u7a0b\u751f\u6210\uff0c\u6539\u5584\u4e86\u4ee3\u7801\u5b89\u5168\u6027\u800c\u4e0d\u727a\u7272\u529f\u80fd\u6027\uff0c\u9002\u5408\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u5b9e\u65f6\u5b89\u5168\u8bc4\u4f30\u9700\u6c42\u3002"}}
{"id": "2602.10808", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10808", "abs": "https://arxiv.org/abs/2602.10808", "authors": ["Rasmus Krebs", "Somnath Mazumdar"], "title": "PELLI: Framework to effectively integrate LLMs for quality software generation", "comment": "15 pages", "summary": "Recent studies have revealed that when LLMs are appropriately prompted and configured, they demonstrate mixed results. Such results often meet or exceed the baseline performance. However, these comparisons have two primary issues. First, they mostly considered only reliability as a comparison metric and selected a few LLMs (such as Codex and ChatGPT) for comparision. This paper proposes a comprehensive code quality assessment framework called Programmatic Excellence via LLM Iteration (PELLI). PELLI is an iterative analysis-based process that upholds high-quality code changes. We extended the state-of-the-art by performing a comprehensive evaluation that generates quantitative metrics for analyzing three primary nonfunctional requirements (such as maintainability, performance, and reliability) while selecting five popular LLMs. For PELLI's applicability, we selected three application domains while following Python coding standards. Following this framework, practitioners can ensure harmonious integration between LLMs and human developers, ensuring that their potential is fully realized. PELLI can serve as a practical guide for developers aiming to leverage LLMs while adhering to recognized quality standards. This study's outcomes are crucial for advancing LLM technologies in real-world applications, providing stakeholders with a clear understanding of where these LLMs excel and where they require further refinement. Overall, based on three nonfunctional requirements, we have found that GPT-4T and Gemini performed slightly better. We also found that prompt design can influence the overall code quality. In addition, each application domain demonstrated high and low scores across various metrics, and even within the same metrics across different prompts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PELLI\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u8fed\u4ee3\u5206\u6790\u7684\u4ee3\u7801\u8d28\u91cf\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30LLM\u751f\u6210\u7684\u4ee3\u7801\u8d28\u91cf\uff0c\u91cd\u70b9\u5173\u6ce8\u53ef\u7ef4\u62a4\u6027\u3001\u6027\u80fd\u548c\u53ef\u9760\u6027\u4e09\u4e2a\u975e\u529f\u80fd\u6027\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u6bd4\u8f83LLM\u751f\u6210\u7684\u4ee3\u7801\u8d28\u91cf\u65f6\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u4e3b\u8981\u53ea\u8003\u8651\u53ef\u9760\u6027\u4f5c\u4e3a\u6bd4\u8f83\u6307\u6807\uff1b2) \u53ea\u9009\u62e9\u5c11\u6570LLM\uff08\u5982Codex\u548cChatGPT\uff09\u8fdb\u884c\u6bd4\u8f83\u3002\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u6307\u5bfc\u5f00\u53d1\u8005\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u6548\u5229\u7528LLM\u3002", "method": "\u63d0\u51fa\u4e86PELLI\uff08Programmatic Excellence via LLM Iteration\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u8fed\u4ee3\u5206\u6790\u7684\u4ee3\u7801\u8d28\u91cf\u8bc4\u4f30\u8fc7\u7a0b\u3002\u7814\u7a76\u6269\u5c55\u4e86\u73b0\u6709\u6280\u672f\uff0c\u901a\u8fc7\u751f\u6210\u5b9a\u91cf\u6307\u6807\u6765\u5168\u9762\u8bc4\u4f30\u4e09\u4e2a\u4e3b\u8981\u975e\u529f\u80fd\u6027\u9700\u6c42\uff08\u53ef\u7ef4\u62a4\u6027\u3001\u6027\u80fd\u3001\u53ef\u9760\u6027\uff09\uff0c\u540c\u65f6\u9009\u62e9\u4e86\u4e94\u4e2a\u6d41\u884c\u7684LLM\u3002\u4e3a\u4e86\u9a8c\u8bc1PELLI\u7684\u9002\u7528\u6027\uff0c\u9009\u62e9\u4e86\u4e09\u4e2a\u5e94\u7528\u9886\u57df\u5e76\u9075\u5faaPython\u7f16\u7801\u6807\u51c6\u3002", "result": "\u57fa\u4e8e\u4e09\u4e2a\u975e\u529f\u80fd\u6027\u9700\u6c42\u7684\u8bc4\u4f30\u53d1\u73b0\uff1a1) GPT-4T\u548cGemini\u8868\u73b0\u7565\u597d\uff1b2) \u63d0\u793a\u8bbe\u8ba1\u4f1a\u5f71\u54cd\u6574\u4f53\u4ee3\u7801\u8d28\u91cf\uff1b3) \u6bcf\u4e2a\u5e94\u7528\u9886\u57df\u5728\u4e0d\u540c\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u9ad8\u4f4e\u4e0d\u540c\u7684\u5206\u6570\uff0c\u5373\u4f7f\u5728\u540c\u4e00\u6307\u6807\u4e0a\uff0c\u4e0d\u540c\u63d0\u793a\u4e5f\u4f1a\u4ea7\u751f\u5dee\u5f02\u3002", "conclusion": "PELLI\u53ef\u4ee5\u4f5c\u4e3a\u5f00\u53d1\u8005\u7684\u5b9e\u7528\u6307\u5357\uff0c\u5e2e\u52a9\u4ed6\u4eec\u5728\u9075\u5faa\u516c\u8ba4\u8d28\u91cf\u6807\u51c6\u7684\u540c\u65f6\u6709\u6548\u5229\u7528LLM\u3002\u8be5\u6846\u67b6\u786e\u4fddLLM\u4e0e\u4eba\u7c7b\u5f00\u53d1\u8005\u4e4b\u95f4\u7684\u548c\u8c10\u96c6\u6210\uff0c\u5145\u5206\u53d1\u6325LLM\u7684\u6f5c\u529b\u3002\u7814\u7a76\u7ed3\u679c\u5bf9\u4e8e\u63a8\u8fdbLLM\u6280\u672f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u6307\u5bfc\u3002"}}
{"id": "2602.10845", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10845", "abs": "https://arxiv.org/abs/2602.10845", "authors": ["Xuecheng Zou", "Yu Tang", "Bingbing Wang"], "title": "SynergyKGC: Reconciling Topological Heterogeneity in Knowledge Graph Completion via Topology-Aware Synergy", "comment": "10 pages, 5 tables, 7 figures. This work introduces the Active Synergy mechanism and Identity Anchoring for Knowledge Graph Completion. Code: https://github.com/XuechengZou-2001/SynergyKGC-main", "summary": "Knowledge Graph Completion (KGC) fundamentally hinges on the coherent fusion of pre-trained entity semantics with heterogeneous topological structures to facilitate robust relational reasoning. However, existing paradigms encounter a critical \"structural resolution mismatch,\" failing to reconcile divergent representational demands across varying graph densities, which precipitates structural noise interference in dense clusters and catastrophic representation collapse in sparse regions. We present SynergyKGC, an adaptive framework that advances traditional neighbor aggregation to an active Cross-Modal Synergy Expert via relation-aware cross-attention and semantic-intent-driven gating. By coupling a density-dependent Identity Anchoring strategy with a Double-tower Coherent Consistency architecture, SynergyKGC effectively reconciles topological heterogeneity while ensuring representational stability across training and inference phases. Systematic evaluations on two public benchmarks validate the superiority of our method in significantly boosting KGC hit rates, providing empirical evidence for a generalized principle of resilient information integration in non-homogeneous structured data.", "AI": {"tldr": "SynergyKGC\uff1a\u4e00\u79cd\u901a\u8fc7\u8de8\u6a21\u6001\u534f\u540c\u4e13\u5bb6\u548c\u5bc6\u5ea6\u76f8\u5173\u8eab\u4efd\u951a\u5b9a\u7b56\u7565\u89e3\u51b3\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u7ed3\u6784\u5206\u8fa8\u7387\u4e0d\u5339\u914d\u95ee\u9898\u7684\u81ea\u9002\u5e94\u6846\u67b6", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u65b9\u6cd5\u9762\u4e34\"\u7ed3\u6784\u5206\u8fa8\u7387\u4e0d\u5339\u914d\"\u95ee\u9898\uff0c\u65e0\u6cd5\u5728\u4e0d\u540c\u56fe\u5bc6\u5ea6\u4e0b\u534f\u8c03\u4e0d\u540c\u7684\u8868\u793a\u9700\u6c42\uff0c\u5bfc\u81f4\u5bc6\u96c6\u7c07\u4e2d\u7684\u7ed3\u6784\u566a\u58f0\u5e72\u6270\u548c\u7a00\u758f\u533a\u57df\u4e2d\u7684\u707e\u96be\u6027\u8868\u793a\u5d29\u6e83", "method": "\u63d0\u51faSynergyKGC\u6846\u67b6\uff0c\u5c06\u4f20\u7edf\u90bb\u5c45\u805a\u5408\u63d0\u5347\u4e3a\u4e3b\u52a8\u7684\u8de8\u6a21\u6001\u534f\u540c\u4e13\u5bb6\uff0c\u901a\u8fc7\u5173\u7cfb\u611f\u77e5\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u8bed\u4e49\u610f\u56fe\u9a71\u52a8\u7684\u95e8\u63a7\u673a\u5236\uff0c\u7ed3\u5408\u5bc6\u5ea6\u76f8\u5173\u7684\u8eab\u4efd\u951a\u5b9a\u7b56\u7565\u548c\u53cc\u5854\u4e00\u81f4\u6027\u67b6\u6784", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u7cfb\u7edf\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u663e\u8457\u63d0\u5347KGC\u547d\u4e2d\u7387\u65b9\u9762\u7684\u4f18\u8d8a\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u975e\u5747\u5300\u7ed3\u6784\u5316\u6570\u636e\u4e2d\u7684\u5f39\u6027\u4fe1\u606f\u6574\u5408\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u539f\u5219\u7684\u5b9e\u8bc1\u8bc1\u636e"}}
{"id": "2602.10972", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10972", "abs": "https://arxiv.org/abs/2602.10972", "authors": ["Hina Saeeda", "Mijin Kim", "Eric Knauss", "Jesper Thyssen", "Jesper \u00d8rting", "Jesper Lysemose Korsgaard", "Niels J\u00f8rgen Str\u00f8m"], "title": "Deriving and Validating Requirements Engineering Principles for Large-Scale Agile Development: An Industrial Longitudinal Study", "comment": null, "summary": "In large scale agile systems development, the lack of a unified requirements engineering (RE) process is a major challenge, exacerbated by the absence of high level guiding principles for effective requirements management. To address this challenge, we conducted a five year longitudinal case study with Grundfos AB, in collaboration with the Software Centre in Sweden. RE principles were first derived through qualitative data collection spanning more than 25 sprints, approximately 320 weekly synchronisation meetings, and seven cross-company, company-specific workshops between 2019 and 2024. These activities engaged practitioners from diverse roles, representing several hundred developers across domains. In late 2024, five in depth focus groups with senior leaders at Grundfos provided retrospective validation of the principles and assessed their strategic impact. We aim to (1) empirically examine RE principles in large scale agile system development, (2) explore their benefits in practice within the case company, and (3) identify a set of transferable RE principles for large scale contexts. Using thematic analysis, six key RE principles architectural context, stakeholder-driven validation and alignment, requirements practices in large-scale agile organisations. evolution with lightweight documentation, delegated requirements management, organisational roles and responsibilities, and a shared understanding of requirements are derived. The study was further validated through crosscompany expert evaluation with three additional multinational organisations (Bosch, Ericsson, and Volvo Cars), which are directly responsible for largescale requirements management. Together, these efforts provide a scalable and adaptable foundation for improving requirements practices in largescale agile organisations.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc75\u5e74\u7eb5\u5411\u6848\u4f8b\u7814\u7a76\uff0c\u4e3a\u5927\u89c4\u6a21\u654f\u6377\u7cfb\u7edf\u5f00\u53d1\u63d0\u51fa\u4e866\u4e2a\u53ef\u8f6c\u79fb\u7684\u9700\u6c42\u5de5\u7a0b\u539f\u5219\uff0c\u5e76\u5728\u591a\u5bb6\u8de8\u56fd\u516c\u53f8\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u5927\u89c4\u6a21\u654f\u6377\u7cfb\u7edf\u5f00\u53d1\u4e2d\u7f3a\u4e4f\u7edf\u4e00\u7684\u9700\u6c42\u5de5\u7a0b\u6d41\u7a0b\u548c\u9ad8\u5c42\u6b21\u6307\u5bfc\u539f\u5219\uff0c\u5bfc\u81f4\u9700\u6c42\u7ba1\u7406\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u6269\u5c55\u7684\u5b9e\u8df5\u6846\u67b6\u3002", "method": "\u91c7\u75285\u5e74\u7eb5\u5411\u6848\u4f8b\u7814\u7a76\uff0c\u901a\u8fc7\u8d85\u8fc725\u4e2a\u51b2\u523a\u3001320\u6b21\u5468\u540c\u6b65\u4f1a\u8bae\u30017\u6b21\u8de8\u516c\u53f8\u7814\u8ba8\u4f1a\u6536\u96c6\u5b9a\u6027\u6570\u636e\uff0c\u4f7f\u7528\u4e3b\u9898\u5206\u6790\u63d0\u70bc\u539f\u5219\uff0c\u5e76\u901a\u8fc7\u7126\u70b9\u5c0f\u7ec4\u548c\u8de8\u516c\u53f8\u4e13\u5bb6\u8bc4\u4f30\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u8bc6\u522b\u51fa6\u4e2a\u5173\u952e\u9700\u6c42\u5de5\u7a0b\u539f\u5219\uff1a\u67b6\u6784\u4e0a\u4e0b\u6587\u3001\u5229\u76ca\u76f8\u5173\u8005\u9a71\u52a8\u7684\u9a8c\u8bc1\u4e0e\u5bf9\u9f50\u3001\u8f7b\u91cf\u7ea7\u6587\u6863\u7684\u9700\u6c42\u6f14\u8fdb\u3001\u59d4\u6258\u5f0f\u9700\u6c42\u7ba1\u7406\u3001\u7ec4\u7ec7\u89d2\u8272\u4e0e\u804c\u8d23\u3001\u9700\u6c42\u5171\u4eab\u7406\u89e3\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5927\u89c4\u6a21\u654f\u6377\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u9002\u5e94\u7684\u9700\u6c42\u5b9e\u8df5\u57fa\u7840\uff0c\u8fd9\u4e9b\u539f\u5219\u7ecf\u8fc7\u591a\u5bb6\u8de8\u56fd\u516c\u53f8\u9a8c\u8bc1\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.10885", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10885", "abs": "https://arxiv.org/abs/2602.10885", "authors": ["Leheng Sheng", "Wenchang Ma", "Ruixin Hong", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Reinforcing Chain-of-Thought Reasoning with Self-Evolving Rubrics", "comment": "21 pages", "summary": "Despite chain-of-thought (CoT) playing crucial roles in LLM reasoning, directly rewarding it is difficult: training a reward model demands heavy human labeling efforts, and static RMs struggle with evolving CoT distributions and reward hacking. These challenges motivate us to seek an autonomous CoT rewarding approach that requires no human annotation efforts and can evolve gradually. Inspired by recent self-evolving training methods, we propose \\textbf{RLCER} (\\textbf{R}einforcement \\textbf{L}earning with \\textbf{C}oT Supervision via Self-\\textbf{E}volving \\textbf{R}ubrics), which enhances the outcome-centric RLVR by rewarding CoTs with self-proposed and self-evolving rubrics. We show that self-proposed and self-evolving rubrics provide reliable CoT supervision signals even without outcome rewards, enabling RLCER to outperform outcome-centric RLVR. Moreover, when used as in-prompt hints, these self-proposed rubrics further improve inference-time performance.", "AI": {"tldr": "RLCER\u662f\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u81ea\u4e3bCoT\u5956\u52b1\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u6211\u63d0\u51fa\u548c\u6f14\u8fdb\u7684\u8bc4\u5206\u6807\u51c6\u6765\u76d1\u7763\u601d\u7ef4\u94fe\uff0c\u4f18\u4e8e\u7ed3\u679c\u4e2d\u5fc3\u7684RLVR\u65b9\u6cd5", "motivation": "\u601d\u7ef4\u94fe\u5728LLM\u63a8\u7406\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76f4\u63a5\u5956\u52b1CoT\u5b58\u5728\u56f0\u96be\uff1a\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\uff0c\u9759\u6001\u5956\u52b1\u6a21\u578b\u96be\u4ee5\u9002\u5e94CoT\u5206\u5e03\u7684\u6f14\u53d8\u548c\u5956\u52b1\u653b\u51fb\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u4e14\u80fd\u9010\u6b65\u6f14\u8fdb\u7684\u81ea\u4e3bCoT\u5956\u52b1\u65b9\u6cd5", "method": "\u63d0\u51faRLCER\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u6211\u63d0\u51fa\u548c\u6f14\u8fdb\u7684\u8bc4\u5206\u6807\u51c6\u6765\u76d1\u7763\u601d\u7ef4\u94fe\uff0c\u589e\u5f3a\u7ed3\u679c\u4e2d\u5fc3\u7684RLVR\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u81ea\u6211\u63d0\u51fa\u7684\u8bc4\u5206\u6807\u51c6\u4e3aCoT\u63d0\u4f9b\u53ef\u9760\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u5373\u4f7f\u6ca1\u6709\u7ed3\u679c\u5956\u52b1\u4e5f\u80fd\u5de5\u4f5c", "result": "RLCER\u5728\u65e0\u9700\u7ed3\u679c\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\u8d85\u8d8a\u4e86\u7ed3\u679c\u4e2d\u5fc3\u7684RLVR\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u5f53\u5c06\u8fd9\u4e9b\u81ea\u6211\u63d0\u51fa\u7684\u8bc4\u5206\u6807\u51c6\u7528\u4f5c\u63d0\u793a\u4e2d\u7684\u63d0\u793a\u65f6\uff0c\u8fd8\u80fd\u8fdb\u4e00\u6b65\u63d0\u9ad8\u63a8\u7406\u65f6\u7684\u6027\u80fd", "conclusion": "\u81ea\u6211\u63d0\u51fa\u548c\u6f14\u8fdb\u7684\u8bc4\u5206\u6807\u51c6\u4e3a\u601d\u7ef4\u94fe\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u4f7f\u5f97RLCER\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3CoT\u5956\u52b1\u7684\u6311\u6218\uff0c\u5e76\u5728\u63a8\u7406\u6027\u80fd\u4e0a\u53d6\u5f97\u6539\u8fdb"}}
{"id": "2602.10964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10964", "abs": "https://arxiv.org/abs/2602.10964", "authors": ["F. Carichon", "R. Rampa", "G. Farnadi"], "title": "Can LLMs Cook Jamaican Couscous? A Study of Cultural Novelty in Recipe Generation", "comment": "14 pages, 12 figures, conference", "summary": "Large Language Models (LLMs) are increasingly used to generate and shape cultural content, ranging from narrative writing to artistic production. While these models demonstrate impressive fluency and generative capacity, prior work has shown that they also exhibit systematic cultural biases, raising concerns about stereotyping, homogenization, and the erasure of culturally specific forms of expression. Understanding whether LLMs can meaningfully align with diverse cultures beyond the dominant ones remains a critical challenge. In this paper, we study cultural adaptation in LLMs through the lens of cooking recipes, a domain in which culture, tradition, and creativity are tightly intertwined. We build on the \\textit{GlobalFusion} dataset, which pairs human recipes from different countries according to established measures of cultural distance. Using the same country pairs, we generate culturally adapted recipes with multiple LLMs, enabling a direct comparison between human and LLM behavior in cross-cultural content creation. Our analysis shows that LLMs fail to produce culturally representative adaptations. Unlike humans, the divergence of their generated recipes does not correlate with cultural distance. We further provide explanations for this gap. We show that cultural information is weakly preserved in internal model representations, that models inflate novelty in their production by misunderstanding notions such as creativity and tradition, and that they fail to identify adaptation with its associated countries and to ground it in culturally salient elements such as ingredients. These findings highlight fundamental limitations of current LLMs for culturally oriented generation and have important implications for their use in culturally sensitive applications.", "AI": {"tldr": "LLMs\u5728\u6587\u5316\u9002\u5e94\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u65e0\u6cd5\u50cf\u4eba\u7c7b\u4e00\u6837\u6839\u636e\u6587\u5316\u8ddd\u79bb\u4ea7\u751f\u6709\u610f\u4e49\u7684\u98df\u8c31\u6539\u7f16\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLMs\u5728\u6587\u5316\u654f\u611f\u5e94\u7528\u4e2d\u7684\u6839\u672c\u5c40\u9650\u6027\u3002", "motivation": "LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u751f\u6210\u548c\u5851\u9020\u6587\u5316\u5185\u5bb9\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u8868\u660e\u5b83\u4eec\u5b58\u5728\u7cfb\u7edf\u6027\u6587\u5316\u504f\u89c1\uff0c\u53ef\u80fd\u52a0\u5267\u523b\u677f\u5370\u8c61\u3001\u540c\u8d28\u5316\u548c\u6587\u5316\u8868\u8fbe\u5f62\u5f0f\u7684\u6d88\u5931\u3002\u7406\u89e3LLMs\u80fd\u5426\u8d85\u8d8a\u4e3b\u6d41\u6587\u5316\u800c\u6709\u610f\u4e49\u5730\u9002\u5e94\u591a\u5143\u6587\u5316\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u901a\u8fc7\u70f9\u996a\u98df\u8c31\u8fd9\u4e00\u6587\u5316\u3001\u4f20\u7edf\u548c\u521b\u9020\u529b\u7d27\u5bc6\u4ea4\u7ec7\u7684\u9886\u57df\u7814\u7a76LLMs\u7684\u6587\u5316\u9002\u5e94\u80fd\u529b\u3002\u57fa\u4e8eGlobalFusion\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u76f8\u540c\u56fd\u5bb6\u914d\u5bf9\uff0c\u7528\u591a\u4e2aLLMs\u751f\u6210\u6587\u5316\u9002\u5e94\u98df\u8c31\uff0c\u76f4\u63a5\u6bd4\u8f83\u4eba\u7c7b\u548cLLM\u5728\u8de8\u6587\u5316\u5185\u5bb9\u521b\u4f5c\u4e2d\u7684\u884c\u4e3a\u3002", "result": "LLMs\u65e0\u6cd5\u4ea7\u751f\u5177\u6709\u6587\u5316\u4ee3\u8868\u6027\u7684\u9002\u5e94\u3002\u4e0e\u4eba\u7c7b\u4e0d\u540c\uff0c\u5b83\u4eec\u751f\u6210\u7684\u98df\u8c31\u5dee\u5f02\u4e0e\u6587\u5316\u8ddd\u79bb\u4e0d\u76f8\u5173\u3002\u7814\u7a76\u53d1\u73b0\uff1a1) \u6587\u5316\u4fe1\u606f\u5728\u6a21\u578b\u5185\u90e8\u8868\u793a\u4e2d\u4fdd\u5b58\u8f83\u5f31\uff1b2) \u6a21\u578b\u901a\u8fc7\u8bef\u89e3\u521b\u9020\u6027\u548c\u4f20\u7edf\u7b49\u6982\u5ff5\u6765\u5938\u5927\u65b0\u9896\u6027\uff1b3) \u6a21\u578b\u65e0\u6cd5\u5c06\u9002\u5e94\u4e0e\u76f8\u5173\u56fd\u5bb6\u8054\u7cfb\u8d77\u6765\uff0c\u4e5f\u65e0\u6cd5\u5c06\u5176\u5efa\u7acb\u5728\u98df\u6750\u7b49\u6587\u5316\u663e\u8457\u5143\u7d20\u4e0a\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u6587\u5316\u5bfc\u5411\u7684\u751f\u6210\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff0c\u8fd9\u5bf9\u5b83\u4eec\u5728\u6587\u5316\u654f\u611f\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002\u9700\u8981\u6539\u8fdb\u6a21\u578b\u7684\u6587\u5316\u7406\u89e3\u548c\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2602.10478", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10478", "abs": "https://arxiv.org/abs/2602.10478", "authors": ["Zihao Li", "Hongyi Lu", "Yanan Guo", "Zhenkai Zhang", "Shuai Wang", "Fengwei Zhang"], "title": "GPU-Fuzz: Finding Memory Errors in Deep Learning Frameworks", "comment": null, "summary": "GPU memory errors are a critical threat to deep learning (DL) frameworks, leading to crashes or even security issues. We introduce GPU-Fuzz, a fuzzer locating these issues efficiently by modeling operator parameters as formal constraints. GPU-Fuzz utilizes a constraint solver to generate test cases that systematically probe error-prone boundary conditions in GPU kernels. Applied to PyTorch, TensorFlow, and PaddlePaddle, we uncovered 13 unknown bugs, demonstrating the effectiveness of GPU-Fuzz in finding memory errors.", "AI": {"tldr": "GPU-Fuzz\u662f\u4e00\u4e2a\u9488\u5bf9\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6GPU\u5185\u5b58\u9519\u8bef\u7684\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u901a\u8fc7\u7ea6\u675f\u6c42\u89e3\u5668\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5728PyTorch\u3001TensorFlow\u548cPaddlePaddle\u4e2d\u53d1\u73b0\u4e8613\u4e2a\u672a\u77e5\u6f0f\u6d1e\u3002", "motivation": "GPU\u5185\u5b58\u9519\u8bef\u662f\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684\u5173\u952e\u5a01\u80c1\uff0c\u53ef\u80fd\u5bfc\u81f4\u7cfb\u7edf\u5d29\u6e83\u751a\u81f3\u5b89\u5168\u95ee\u9898\uff0c\u9700\u8981\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u6765\u5b9a\u4f4d\u8fd9\u4e9b\u6f0f\u6d1e\u3002", "method": "\u5c06\u7b97\u5b50\u53c2\u6570\u5efa\u6a21\u4e3a\u5f62\u5f0f\u5316\u7ea6\u675f\uff0c\u5229\u7528\u7ea6\u675f\u6c42\u89e3\u5668\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u7cfb\u7edf\u6027\u5730\u63a2\u6d4bGPU\u5185\u6838\u4e2d\u5bb9\u6613\u51fa\u9519\u7684\u8fb9\u754c\u6761\u4ef6\u3002", "result": "\u5728PyTorch\u3001TensorFlow\u548cPaddlePaddle\u4e09\u4e2a\u4e3b\u6d41\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e2d\u53d1\u73b0\u4e8613\u4e2a\u672a\u77e5\u7684\u5185\u5b58\u9519\u8bef\u6f0f\u6d1e\u3002", "conclusion": "GPU-Fuzz\u80fd\u591f\u6709\u6548\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e2d\u7684GPU\u5185\u5b58\u9519\u8bef\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u7ea6\u675f\u6c42\u89e3\u7684\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u5728\u68c0\u6d4b\u6b64\u7c7b\u5b89\u5168\u95ee\u9898\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.10481", "categories": ["cs.CR", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.10481", "abs": "https://arxiv.org/abs/2602.10481", "authors": ["Mohan Rajagopalan", "Vinay Rao"], "title": "Protecting Context and Prompts: Deterministic Security for Non-Deterministic AI", "comment": null, "summary": "Large Language Model (LLM) applications are vulnerable to prompt injection and context manipulation attacks that traditional security models cannot prevent. We introduce two novel primitives--authenticated prompts and authenticated context--that provide cryptographically verifiable provenance across LLM workflows. Authenticated prompts enable self-contained lineage verification, while authenticated context uses tamper-evident hash chains to ensure integrity of dynamic inputs. Building on these primitives, we formalize a policy algebra with four proven theorems providing protocol-level Byzantine resistance--even adversarial agents cannot violate organizational policies. Five complementary defenses--from lightweight resource controls to LLM-based semantic validation--deliver layered, preventative security with formal guarantees. Evaluation against representative attacks spanning 6 exhaustive categories achieves 100% detection with zero false positives and nominal overhead. We demonstrate the first approach combining cryptographically enforced prompt lineage, tamper-evident context, and provable policy reasoning--shifting LLM security from reactive detection to preventative guarantees.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u65b0\u578b\u539f\u8bed\u2014\u2014\u8ba4\u8bc1\u63d0\u793a\u548c\u8ba4\u8bc1\u4e0a\u4e0b\u6587\uff0c\u4e3aLLM\u5de5\u4f5c\u6d41\u63d0\u4f9b\u5bc6\u7801\u5b66\u53ef\u9a8c\u8bc1\u7684\u6765\u6e90\u8bc1\u660e\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u7b56\u7565\u4ee3\u6570\u548c\u591a\u5c42\u9632\u5fa1\u5b9e\u73b0\u9884\u9632\u6027\u5b89\u5168\u4fdd\u8bc1\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u5bb9\u6613\u53d7\u5230\u63d0\u793a\u6ce8\u5165\u548c\u4e0a\u4e0b\u6587\u64cd\u7eb5\u653b\u51fb\uff0c\u4f20\u7edf\u5b89\u5168\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u9632\u62a4\uff0c\u9700\u8981\u65b0\u7684\u5b89\u5168\u673a\u5236\u6765\u786e\u4fddLLM\u5de5\u4f5c\u6d41\u7684\u5b8c\u6574\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u5f15\u5165\u4e24\u79cd\u5bc6\u7801\u5b66\u539f\u8bed\uff1a\u8ba4\u8bc1\u63d0\u793a\uff08\u63d0\u4f9b\u81ea\u5305\u542b\u7684\u6eaf\u6e90\u9a8c\u8bc1\uff09\u548c\u8ba4\u8bc1\u4e0a\u4e0b\u6587\uff08\u4f7f\u7528\u9632\u7be1\u6539\u54c8\u5e0c\u94fe\u786e\u4fdd\u52a8\u6001\u8f93\u5165\u5b8c\u6574\u6027\uff09\u3002\u57fa\u4e8e\u8fd9\u4e9b\u539f\u8bed\u5f62\u5f0f\u5316\u7b56\u7565\u4ee3\u6570\uff0c\u63d0\u4f9b\u534f\u8bae\u7ea7\u62dc\u5360\u5ead\u5bb9\u9519\uff0c\u5e76\u8bbe\u8ba1\u4e94\u5c42\u4e92\u8865\u9632\u5fa1\u673a\u5236\u3002", "result": "\u5728\u6db5\u76d66\u4e2a\u7c7b\u522b\u7684\u4ee3\u8868\u6027\u653b\u51fb\u8bc4\u4f30\u4e2d\uff0c\u5b9e\u73b0\u4e86100%\u68c0\u6d4b\u7387\u3001\u96f6\u8bef\u62a5\u548c\u53ef\u5ffd\u7565\u7684\u5f00\u9500\uff0c\u9996\u6b21\u7ed3\u5408\u5bc6\u7801\u5b66\u5f3a\u5236\u7684\u63d0\u793a\u6eaf\u6e90\u3001\u9632\u7be1\u6539\u4e0a\u4e0b\u6587\u548c\u53ef\u8bc1\u660e\u7684\u7b56\u7565\u63a8\u7406\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06LLM\u5b89\u5168\u4ece\u88ab\u52a8\u68c0\u6d4b\u8f6c\u5411\u9884\u9632\u6027\u4fdd\u8bc1\uff0c\u901a\u8fc7\u5bc6\u7801\u5b66\u53ef\u9a8c\u8bc1\u7684\u6765\u6e90\u8bc1\u660e\u3001\u9632\u7be1\u6539\u4e0a\u4e0b\u6587\u548c\u5f62\u5f0f\u5316\u7b56\u7565\u63a8\u7406\uff0c\u4e3aLLM\u5de5\u4f5c\u6d41\u63d0\u4f9b\u5206\u5c42\u9884\u9632\u6027\u5b89\u5168\u3002"}}
{"id": "2602.10487", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10487", "abs": "https://arxiv.org/abs/2602.10487", "authors": ["Viet Hoang Luu", "Amirmohammad Pasdar", "Wachiraphan Charoenwet", "Toby Murray", "Shaanan Cohney", "Van-Thuan Pham"], "title": "Following Dragons: Code Review-Guided Fuzzing", "comment": null, "summary": "Modern fuzzers scale to large, real-world software but often fail to exercise the program states developers consider most fragile or security-critical. Such states are typically deep in the execution space, gated by preconditions, or overshadowed by lower-value paths that consume limited fuzzing budgets. Meanwhile, developers routinely surface risk-relevant insights during code review, yet this information is largely ignored by automated testing tools. We present EyeQ, a system that leverages developer intelligence from code reviews to guide fuzzing. EyeQ extracts security-relevant signals from review discussions, localizes the implicated program regions, and translates these insights into annotation-based guidance for fuzzing. The approach operates atop existing annotation-aware fuzzing, requiring no changes to program semantics or developer workflows. We first validate EyeQ through a human-guided feasibility study on a security-focused dataset of PHP code reviews, establishing a strong baseline for review-guided fuzzing. We then automate the workflow using a large language model with carefully designed prompts. EyeQ significantly improves vulnerability discovery over standard fuzzing configurations, uncovering more than 40 previously unknown bugs in the security-critical PHP codebase.", "AI": {"tldr": "EyeQ\u7cfb\u7edf\u5229\u7528\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u5f00\u53d1\u8005\u667a\u80fd\u6765\u6307\u5bfc\u6a21\u7cca\u6d4b\u8bd5\uff0c\u901a\u8fc7\u63d0\u53d6\u5b89\u5168\u76f8\u5173\u4fe1\u53f7\u3001\u5b9a\u4f4d\u76f8\u5173\u7a0b\u5e8f\u533a\u57df\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6d1e\u5bdf\u8f6c\u5316\u4e3a\u57fa\u4e8e\u6ce8\u89e3\u7684\u6a21\u7cca\u6d4b\u8bd5\u6307\u5bfc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u53d1\u73b0\u80fd\u529b\u3002", "motivation": "\u73b0\u4ee3\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u867d\u7136\u80fd\u6269\u5c55\u5230\u5927\u578b\u5b9e\u9645\u8f6f\u4ef6\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u89e6\u53ca\u5f00\u53d1\u8005\u8ba4\u4e3a\u6700\u8106\u5f31\u6216\u6700\u5b89\u5168\u5173\u952e\u7684\u7a0b\u5e8f\u72b6\u6001\u3002\u8fd9\u4e9b\u72b6\u6001\u901a\u5e38\u6df1\u85cf\u5728\u6267\u884c\u7a7a\u95f4\u4e2d\uff0c\u53d7\u524d\u7f6e\u6761\u4ef6\u9650\u5236\uff0c\u6216\u88ab\u4f4e\u4ef7\u503c\u8def\u5f84\u6240\u63a9\u76d6\u3002\u540c\u65f6\uff0c\u5f00\u53d1\u8005\u5728\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7ecf\u5e38\u53d1\u73b0\u98ce\u9669\u76f8\u5173\u7684\u6d1e\u5bdf\uff0c\u4f46\u8fd9\u4e9b\u4fe1\u606f\u5728\u81ea\u52a8\u5316\u6d4b\u8bd5\u5de5\u5177\u4e2d\u57fa\u672c\u88ab\u5ffd\u7565\u3002", "method": "EyeQ\u7cfb\u7edf\u4ece\u4ee3\u7801\u5ba1\u67e5\u8ba8\u8bba\u4e2d\u63d0\u53d6\u5b89\u5168\u76f8\u5173\u4fe1\u53f7\uff0c\u5b9a\u4f4d\u6d89\u53ca\u7684\u7a0b\u5e8f\u533a\u57df\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6d1e\u5bdf\u8f6c\u5316\u4e3a\u57fa\u4e8e\u6ce8\u89e3\u7684\u6a21\u7cca\u6d4b\u8bd5\u6307\u5bfc\u3002\u8be5\u65b9\u6cd5\u5efa\u7acb\u5728\u73b0\u6709\u7684\u6ce8\u89e3\u611f\u77e5\u6a21\u7cca\u6d4b\u8bd5\u4e4b\u4e0a\uff0c\u4e0d\u9700\u8981\u6539\u53d8\u7a0b\u5e8f\u8bed\u4e49\u6216\u5f00\u53d1\u8005\u5de5\u4f5c\u6d41\u7a0b\u3002\u9996\u5148\u901a\u8fc7\u4eba\u5de5\u6307\u5bfc\u7684\u53ef\u884c\u6027\u7814\u7a76\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u7136\u540e\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u6765\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "EyeQ\u663e\u8457\u6539\u8fdb\u4e86\u6f0f\u6d1e\u53d1\u73b0\u80fd\u529b\uff0c\u76f8\u6bd4\u6807\u51c6\u6a21\u7cca\u6d4b\u8bd5\u914d\u7f6e\u6709\u663e\u8457\u63d0\u5347\u3002\u5728\u5b89\u5168\u5173\u952e\u7684PHP\u4ee3\u7801\u5e93\u4e2d\u53d1\u73b0\u4e8640\u591a\u4e2a\u5148\u524d\u672a\u77e5\u7684bug\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u5f00\u53d1\u8005\u667a\u80fd\u6765\u6307\u5bfc\u6a21\u7cca\u6d4b\u8bd5\uff0cEyeQ\u7cfb\u7edf\u80fd\u591f\u66f4\u6709\u6548\u5730\u53d1\u73b0\u5b89\u5168\u6f0f\u6d1e\uff0c\u586b\u8865\u4e86\u81ea\u52a8\u5316\u6d4b\u8bd5\u5de5\u5177\u4e0e\u5f00\u53d1\u8005\u98ce\u9669\u6d1e\u5bdf\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2602.11136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11136", "abs": "https://arxiv.org/abs/2602.11136", "authors": ["Jiayi Zhou", "Yang Sheng", "Hantao Lou", "Yaodong Yang", "Jie Fu"], "title": "FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight", "comment": "27 pages", "summary": "As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation from natural language requirements to formal specifications. This paper bridges this gap by proposing , a neuro-symbolic framework that employs a bidirectional Formal-of-Thought architecture: LLMs serve as specification compilers that top-down decompose high-level human intent into atomic, verifiable constraints, then bottom-up prove compliance using Dafny specifications and Z3 Satisfiability modulo theories solving, which produces mathematical guarantees rather than probabilistic scores. We validate across three benchmarks spanning behavioral safety, multi-domain constraint adherence, and agentic upward deception detection. Experiments on 7 agent models demonstrate that achieves an average improvement of 16.6% over LLM-as-a-Judge baselines, enables weak-to-strong generalization where a 7B judge achieves over 90% accuracy detecting deception from 72B agents, and provides near-linear safety improvement through iterative refinement.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFoT\u6846\u67b6\uff0c\u4f7f\u7528\u53cc\u5411\u5f62\u5f0f\u601d\u7ef4\u67b6\u6784\uff0c\u901a\u8fc7LLM\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u7f16\u8bd1\u4e3a\u5f62\u5f0f\u5316\u89c4\u8303\uff0c\u5e76\u7528Dafny\u548cZ3\u63d0\u4f9b\u6570\u5b66\u4fdd\u8bc1\u800c\u975e\u6982\u7387\u8bc4\u5206\uff0c\u663e\u8457\u63d0\u5347\u884c\u4e3a\u5b89\u5168\u76d1\u7763\u6548\u679c\u3002", "motivation": "\u968f\u7740LLM\u667a\u80fd\u4f53\u5728\u73b0\u5b9e\u9ad8\u98ce\u9669\u9886\u57df\u5e94\u7528\u589e\u591a\uff0c\u786e\u4fdd\u5176\u884c\u4e3a\u5b89\u5168\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u4e3b\u6d41\u7684LLM-as-a-Judge\u76d1\u7763\u8303\u5f0f\u9762\u4e34\u6839\u672c\u56f0\u5883\uff1a\u6982\u7387\u7cfb\u7edf\u5982\u4f55\u53ef\u9760\u76d1\u7763\u5176\u4ed6\u6982\u7387\u7cfb\u7edf\u800c\u4e0d\u7ee7\u627f\u5176\u5931\u8d25\u6a21\u5f0f\uff1f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u5230\u5f62\u5f0f\u5316\u89c4\u8303\u7684\u8f6c\u6362\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002", "method": "\u63d0\u51faFoT\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5411\u5f62\u5f0f\u601d\u7ef4\u67b6\u6784\uff1aLLM\u4f5c\u4e3a\u89c4\u8303\u7f16\u8bd1\u5668\uff0c\u81ea\u4e0a\u800c\u4e0b\u5c06\u9ad8\u7ea7\u4eba\u7c7b\u610f\u56fe\u5206\u89e3\u4e3a\u539f\u5b50\u5316\u3001\u53ef\u9a8c\u8bc1\u7684\u7ea6\u675f\uff0c\u7136\u540e\u81ea\u4e0b\u800c\u4e0a\u4f7f\u7528Dafny\u89c4\u8303\u548cZ3\u53ef\u6ee1\u8db3\u6027\u6a21\u7406\u8bba\u6c42\u89e3\u8bc1\u660e\u5408\u89c4\u6027\uff0c\u4ea7\u751f\u6570\u5b66\u4fdd\u8bc1\u800c\u975e\u6982\u7387\u8bc4\u5206\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u884c\u4e3a\u5b89\u5168\u3001\u591a\u9886\u57df\u7ea6\u675f\u9075\u5b88\u3001\u667a\u80fd\u4f53\u5411\u4e0a\u6b3a\u9a97\u68c0\u6d4b\uff09\u4e2d\u9a8c\u8bc1\uff0c\u5bf97\u4e2a\u667a\u80fd\u4f53\u6a21\u578b\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFoT\u76f8\u6bd4LLM-as-a-Judge\u57fa\u7ebf\u5e73\u5747\u63d0\u534716.6%\uff0c\u5b9e\u73b0\u4e86\u5f31\u5230\u5f3a\u6cdb\u5316\uff087B\u6cd5\u5b98\u68c0\u6d4b72B\u667a\u80fd\u4f53\u6b3a\u9a97\u51c6\u786e\u7387\u8d8590%\uff09\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u7ec6\u5316\u63d0\u4f9b\u63a5\u8fd1\u7ebf\u6027\u7684\u5b89\u5168\u6539\u8fdb\u3002", "conclusion": "FoT\u6846\u67b6\u6210\u529f\u5f25\u5408\u4e86\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u5230\u5f62\u5f0f\u5316\u89c4\u8303\u7684\u8f6c\u6362\u74f6\u9888\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u884c\u4e3a\u5b89\u5168\u76d1\u7763\u63d0\u4f9b\u4e86\u6570\u5b66\u4fdd\u8bc1\u800c\u975e\u6982\u7387\u8bc4\u5206\u7684\u65b0\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u76d1\u7763\u6548\u679c\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.10498", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.10498", "abs": "https://arxiv.org/abs/2602.10498", "authors": ["Qianli Wang", "Boyang Ma", "Minghui Xu", "Yue Zhang"], "title": "When Skills Lie: Hidden-Comment Injection in LLM Agents", "comment": "4 pages", "summary": "LLM agents often rely on Skills to describe available tools and recommended procedures. We study a hidden-comment prompt injection risk in this documentation layer: when a Markdown Skill is rendered to HTML, HTML comment blocks can become invisible to human reviewers, yet the raw text may still be supplied verbatim to the model. In experiments, we find that DeepSeek-V3.2 and GLM-4.5-Air can be influenced by malicious instructions embedded in a hidden comment appended to an otherwise legitimate Skill, yielding outputs that contain sensitive tool intentions. A short defensive system prompt that treats Skills as untrusted and forbids sensitive actions prevents these malicious tool calls and instead surfaces the suspicious hidden instructions.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u667a\u80fd\u4f53\u6280\u80fd\u6587\u6863\u4e2d\u7684Markdown\u8f6cHTML\u65f6\uff0cHTML\u6ce8\u91ca\u5757\u53ef\u80fd\u5bf9\u4eba\u5de5\u5ba1\u67e5\u4e0d\u53ef\u89c1\u4f46\u4ecd\u88ab\u6a21\u578b\u8bfb\u53d6\uff0c\u5b58\u5728\u9690\u85cf\u6ce8\u91ca\u63d0\u793a\u6ce8\u5165\u98ce\u9669\uff0c\u53ef\u901a\u8fc7\u9632\u5fa1\u6027\u7cfb\u7edf\u63d0\u793a\u9632\u8303\u3002", "motivation": "LLM\u667a\u80fd\u4f53\u4f9d\u8d56\u6280\u80fd\u6587\u6863\u63cf\u8ff0\u53ef\u7528\u5de5\u5177\u548c\u63a8\u8350\u6d41\u7a0b\uff0c\u4f46Markdown\u6280\u80fd\u6587\u6863\u5728\u6e32\u67d3\u4e3aHTML\u65f6\uff0cHTML\u6ce8\u91ca\u5757\u53ef\u80fd\u5bf9\u4eba\u5de5\u5ba1\u67e5\u8005\u4e0d\u53ef\u89c1\uff0c\u800c\u539f\u59cb\u6587\u672c\u4ecd\u4f1a\u88ab\u5b8c\u6574\u63d0\u4f9b\u7ed9\u6a21\u578b\uff0c\u8fd9\u6784\u6210\u4e86\u9690\u85cf\u6ce8\u91ca\u63d0\u793a\u6ce8\u5165\u7684\u5b89\u5168\u98ce\u9669\u3002", "method": "\u7814\u7a76\u9690\u85cf\u6ce8\u91ca\u63d0\u793a\u6ce8\u5165\u98ce\u9669\uff1a\u5f53Markdown\u6280\u80fd\u6587\u6863\u6e32\u67d3\u4e3aHTML\u65f6\uff0cHTML\u6ce8\u91ca\u5757\u53ef\u80fd\u5bf9\u4eba\u5de5\u5ba1\u67e5\u4e0d\u53ef\u89c1\u4f46\u4ecd\u88ab\u5b8c\u6574\u63d0\u4f9b\u7ed9\u6a21\u578b\u3002\u901a\u8fc7\u5728\u5408\u6cd5\u6280\u80fd\u6587\u6863\u540e\u9644\u52a0\u6076\u610f\u6307\u4ee4\u7684\u9690\u85cf\u6ce8\u91ca\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6d4b\u8bd5DeepSeek-V3.2\u548cGLM-4.5-Air\u6a21\u578b\u662f\u5426\u53d7\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0DeepSeek-V3.2\u548cGLM-4.5-Air\u6a21\u578b\u786e\u5b9e\u4f1a\u53d7\u5230\u9644\u52a0\u5728\u5408\u6cd5\u6280\u80fd\u6587\u6863\u540e\u7684\u9690\u85cf\u6ce8\u91ca\u4e2d\u6076\u610f\u6307\u4ee4\u7684\u5f71\u54cd\uff0c\u4ea7\u751f\u5305\u542b\u654f\u611f\u5de5\u5177\u610f\u56fe\u7684\u8f93\u51fa\u3002\u7b80\u77ed\u7684\u9632\u5fa1\u6027\u7cfb\u7edf\u63d0\u793a\uff08\u5c06\u6280\u80fd\u89c6\u4e3a\u4e0d\u53ef\u4fe1\u5e76\u7981\u6b62\u654f\u611f\u64cd\u4f5c\uff09\u53ef\u4ee5\u6709\u6548\u9632\u6b62\u6076\u610f\u5de5\u5177\u8c03\u7528\uff0c\u5e76\u66b4\u9732\u51fa\u53ef\u7591\u7684\u9690\u85cf\u6307\u4ee4\u3002", "conclusion": "LLM\u667a\u80fd\u4f53\u6280\u80fd\u6587\u6863\u5c42\u5b58\u5728\u9690\u85cf\u6ce8\u91ca\u63d0\u793a\u6ce8\u5165\u98ce\u9669\uff0cHTML\u6ce8\u91ca\u5757\u53ef\u80fd\u7ed5\u8fc7\u4eba\u5de5\u5ba1\u67e5\u4f46\u4ecd\u88ab\u6a21\u578b\u8bfb\u53d6\u3002\u9632\u5fa1\u6027\u7cfb\u7edf\u63d0\u793a\u662f\u6709\u6548\u7684\u9632\u62a4\u63aa\u65bd\uff0c\u5e94\u5c06\u6280\u80fd\u6587\u6863\u89c6\u4e3a\u4e0d\u53ef\u4fe1\u8f93\u5165\u5e76\u7981\u6b62\u654f\u611f\u64cd\u4f5c\uff0c\u540c\u65f6\u9700\u8981\u66f4\u4e25\u683c\u7684\u5b89\u5168\u5ba1\u67e5\u6d41\u7a0b\u3002"}}
{"id": "2602.10573", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.10573", "abs": "https://arxiv.org/abs/2602.10573", "authors": ["Ruisheng Shi", "Ziding Lin", "Haoran Sun", "Qin Wang", "Shihan Zhang", "Lina Lan", "Zhiyuan Peng", "Chenfeng Wang"], "title": "CryptoCatch: Cryptomining Hidden Nowhere", "comment": "IEEE TDSC with DOI 10.1109/TDSC.2026.3661145", "summary": "Cryptomining poses significant security risks, yet traditional detection methods like blacklists and Deep Packet Inspection (DPI) are often ineffective against encrypted mining traffic and suffer from high false positive rates. In this paper, we propose a practical encrypted cryptomining traffic detection mechanism. It consists of a two-stage detection framework, which can effectively provide fine-grained detection results by machine learning and reduce false positives from classifiers through active probing. Our system achieves an F1-score of 0.99 and identifies specific cryptocurrencies with a 99.39\\% accuracy rate. Extensive testing across various mining pools confirms the effectiveness of our approach, offering a more precise and reliable solution for identifying cryptomining activities.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5b9e\u7528\u7684\u52a0\u5bc6\u52a0\u5bc6\u8d27\u5e01\u6316\u77ff\u6d41\u91cf\u68c0\u6d4b\u673a\u5236\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u68c0\u6d4b\u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u4e3b\u52a8\u63a2\u6d4b\u51cf\u5c11\u8bef\u62a5\u3002", "motivation": "\u52a0\u5bc6\u8d27\u5e01\u6316\u77ff\u5e26\u6765\u91cd\u5927\u5b89\u5168\u98ce\u9669\uff0c\u4f46\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\uff08\u5982\u9ed1\u540d\u5355\u548c\u6df1\u5ea6\u5305\u68c0\u6d4b\uff09\u5bf9\u52a0\u5bc6\u6316\u77ff\u6d41\u91cf\u6548\u679c\u4e0d\u4f73\uff0c\u4e14\u8bef\u62a5\u7387\u9ad8\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u68c0\u6d4b\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u7ec6\u7c92\u5ea6\u68c0\u6d4b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u4e3b\u52a8\u63a2\u6d4b\u51cf\u5c11\u5206\u7c7b\u5668\u7684\u8bef\u62a5\u3002", "result": "\u7cfb\u7edf\u8fbe\u5230F1\u5206\u65700.99\uff0c\u8bc6\u522b\u7279\u5b9a\u52a0\u5bc6\u8d27\u5e01\u7684\u51c6\u786e\u7387\u8fbe\u523099.39%\u3002\u5728\u4e0d\u540c\u6316\u77ff\u6c60\u4e0a\u7684\u5e7f\u6cdb\u6d4b\u8bd5\u8bc1\u5b9e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8bc6\u522b\u52a0\u5bc6\u8d27\u5e01\u6316\u77ff\u6d3b\u52a8\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u52a0\u5bc6\u6316\u77ff\u6d41\u91cf\u5e76\u51cf\u5c11\u8bef\u62a5\u3002"}}
{"id": "2602.10626", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.10626", "abs": "https://arxiv.org/abs/2602.10626", "authors": ["Ruisheng Shi", "Zhiyuan Peng", "Tong Fu", "Lina Lan", "Qin Wang", "Jiaqi Zeng"], "title": "Invisible Trails? An Identity Alignment Scheme based on Online Tracking", "comment": "IEEE TDSC with DOI 10.1109/TDSC.2025.3627604", "summary": "Many tracking companies collect user data and sell it to data markets and advertisers. While they claim to protect user privacy by anonymizing the data, our research reveals that significant privacy risks persist even with anonymized data. Attackers can exploit this data to identify users' accounts on other websites and perform targeted identity alignment. In this paper, we propose an effective identity alignment scheme for accurately identifying targeted users. We develop a data collector to obtain the necessary datasets, an algorithm for identity alignment, and, based on this, construct two types of de-anonymization attacks: the \\textit{passive attack}, which analyzes tracker data to align identities, and the \\textit{active attack}, which induces users to interact online, leading to higher success rates. Furthermore, we introduce, for the first time, a novel evaluation framework for online tracking-based identity alignment. We investigate the key factors influencing the effectiveness of identity alignment. Additionally, we provide an independent assessment of our generated dataset and present a fully functional system prototype applied to a cryptocurrency use case.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u533f\u540d\u5316\u7528\u6237\u6570\u636e\u4ecd\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u5229\u7528\u8ffd\u8e2a\u6570\u636e\u8de8\u7f51\u7ad9\u8bc6\u522b\u7528\u6237\u8eab\u4efd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8eab\u4efd\u5bf9\u9f50\u65b9\u6848\u548c\u4e24\u79cd\u53bb\u533f\u540d\u5316\u653b\u51fb\u65b9\u6cd5\u3002", "motivation": "\u8bb8\u591a\u8ffd\u8e2a\u516c\u53f8\u6536\u96c6\u7528\u6237\u6570\u636e\u5e76\u58f0\u79f0\u901a\u8fc7\u533f\u540d\u5316\u4fdd\u62a4\u9690\u79c1\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u5373\u4f7f\u533f\u540d\u5316\u6570\u636e\u4ecd\u5b58\u5728\u91cd\u5927\u9690\u79c1\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u8de8\u7f51\u7ad9\u8bc6\u522b\u7528\u6237\u8d26\u6237\u5e76\u8fdb\u884c\u9488\u5bf9\u6027\u8eab\u4efd\u5bf9\u9f50\u3002", "method": "\u5f00\u53d1\u6570\u636e\u6536\u96c6\u5668\u83b7\u53d6\u5fc5\u8981\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u8eab\u4efd\u5bf9\u9f50\u7b97\u6cd5\uff0c\u6784\u5efa\u4e24\u79cd\u53bb\u533f\u540d\u5316\u653b\u51fb\uff1a\u88ab\u52a8\u653b\u51fb\uff08\u5206\u6790\u8ffd\u8e2a\u6570\u636e\u5bf9\u9f50\u8eab\u4efd\uff09\u548c\u4e3b\u52a8\u653b\u51fb\uff08\u8bf1\u5bfc\u7528\u6237\u5728\u7ebf\u4ea4\u4e92\u4ee5\u63d0\u9ad8\u6210\u529f\u7387\uff09\uff0c\u5e76\u9996\u6b21\u63d0\u51fa\u57fa\u4e8e\u5728\u7ebf\u8ffd\u8e2a\u7684\u8eab\u4efd\u5bf9\u9f50\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u7814\u7a76\u4e86\u5f71\u54cd\u8eab\u4efd\u5bf9\u9f50\u6548\u679c\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5bf9\u751f\u6210\u7684\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u72ec\u7acb\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5e94\u7528\u4e8e\u52a0\u5bc6\u8d27\u5e01\u7528\u4f8b\u7684\u5b8c\u6574\u7cfb\u7edf\u539f\u578b\uff0c\u8bc1\u660e\u4e86\u8eab\u4efd\u5bf9\u9f50\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5373\u4f7f\u533f\u540d\u5316\u5904\u7406\uff0c\u8ffd\u8e2a\u6570\u636e\u4ecd\u5b58\u5728\u4e25\u91cd\u7684\u9690\u79c1\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u8eab\u4efd\u5bf9\u9f50\u6280\u672f\u8de8\u7f51\u7ad9\u8bc6\u522b\u7528\u6237\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u63aa\u65bd\u6765\u5e94\u5bf9\u8fd9\u79cd\u5a01\u80c1\u3002"}}
{"id": "2602.10750", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10750", "abs": "https://arxiv.org/abs/2602.10750", "authors": ["Rumman Firdos", "Aman Dangi"], "title": "SecureScan: An AI-Driven Multi-Layer Framework for Malware and Phishing Detection Using Logistic Regression and Threat Intelligence Integration", "comment": null, "summary": "The growing sophistication of modern malware and phishing campaigns has diminished the effectiveness of traditional signature-based intrusion detection systems. This work presents SecureScan, an AI-driven, triple-layer detection framework that integrates logistic regression-based classification, heuristic analysis, and external threat intelligence via the VirusTotal API for comprehensive triage of URLs, file hashes, and binaries. The proposed architecture prioritizes efficiency by filtering known threats through heuristics, classifying uncertain samples using machine learning, and validating borderline cases with third-party intelligence. On benchmark datasets, SecureScan achieves 93.1 percent accuracy with balanced precision (0.87) and recall (0.92), demonstrating strong generalization and reduced overfitting through threshold-based decision calibration. A calibrated threshold and gray-zone logic (0.45-0.55) were introduced to minimize false positives and enhance real-world stability. Experimental results indicate that a lightweight statistical model, when augmented with calibrated verification and external intelligence, can achieve reliability and performance comparable to more complex deep learning systems.", "AI": {"tldr": "SecureScan\u662f\u4e00\u4e2a\u4e09\u5c42AI\u9a71\u52a8\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u3001\u542f\u53d1\u5f0f\u5206\u6790\u548cVirusTotal\u5a01\u80c1\u60c5\u62a5\u96c6\u6210\uff0c\u5bf9URL\u3001\u6587\u4ef6\u54c8\u5e0c\u548c\u4e8c\u8fdb\u5236\u6587\u4ef6\u8fdb\u884c\u7efc\u5408\u68c0\u6d4b\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523093.1%\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u4ee3\u6076\u610f\u8f6f\u4ef6\u548c\u9493\u9c7c\u653b\u51fb\u65e5\u76ca\u590d\u6742\uff0c\u4f20\u7edf\u57fa\u4e8e\u7b7e\u540d\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u6548\u679c\u4e0b\u964d\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e09\u5c42\u68c0\u6d4b\u6846\u67b6\uff1a1) \u542f\u53d1\u5f0f\u5206\u6790\u8fc7\u6ee4\u5df2\u77e5\u5a01\u80c1\uff1b2) \u903b\u8f91\u56de\u5f52\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u4e0d\u786e\u5b9a\u6837\u672c\uff1b3) VirusTotal API\u5916\u90e8\u5a01\u80c1\u60c5\u62a5\u9a8c\u8bc1\u8fb9\u754c\u6848\u4f8b\u3002\u91c7\u7528\u9608\u503c\u51b3\u7b56\u6821\u51c6\u548c\u7070\u533a\u903b\u8f91(0.45-0.55)\u51cf\u5c11\u8bef\u62a5\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u523093.1%\u51c6\u786e\u7387\uff0c\u7cbe\u5ea60.87\uff0c\u53ec\u56de\u73870.92\uff0c\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u51cf\u5c11\u8fc7\u62df\u5408\u3002\u8f7b\u91cf\u7ea7\u7edf\u8ba1\u6a21\u578b\u901a\u8fc7\u6821\u51c6\u9a8c\u8bc1\u548c\u5916\u90e8\u60c5\u62a5\u8fbe\u5230\u4e0e\u590d\u6742\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u76f8\u5f53\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u7edf\u8ba1\u6a21\u578b\u7ed3\u5408\u6821\u51c6\u9a8c\u8bc1\u548c\u5916\u90e8\u5a01\u80c1\u60c5\u62a5\uff0c\u80fd\u591f\u5b9e\u73b0\u4e0e\u590d\u6742\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u76f8\u5f53\u7684\u68c0\u6d4b\u6027\u80fd\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10778", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.10778", "abs": "https://arxiv.org/abs/2602.10778", "authors": ["Maximilian Thang", "Lichao Wu", "Sasha Behrouzi", "Mohamadreza Rostami", "Jona te Lintelo", "Stjepan Picek", "Ahmad-Reza Sadeghi"], "title": "GoodVibe: Security-by-Vibe for LLM-Based Code Generation", "comment": null, "summary": "Large language models (LLMs) are increasingly used for code generation in fast, informal development workflows, often referred to as vibe coding, where speed and convenience are prioritized, and security requirements are rarely made explicit. In this setting, models frequently produce functionally correct but insecure code, creating a growing security risk. Existing approaches to improving code security rely on full-parameter fine-tuning or parameter-efficient adaptations, which are either costly and prone to catastrophic forgetting or operate at coarse granularity with limited interpretability and control.\n  We present GoodVibe, a neuron-level framework for improving the security of code language models by default. GoodVibe is based on the key insight that security-relevant reasoning is localized to a small subset of neurons. We identify these neurons using gradient-based attribution from a supervised security task and perform neuron-selective fine-tuning that updates only this security-critical subspace. To further reduce training cost, we introduce activation-driven neuron clustering, enabling structured updates with minimal overhead. We evaluate GoodVibe on six LLMs across security-critical programming languages, including C++, Java, Swift, and Go. GoodVibe substantially improves the security of generated code while preserving general model utility, achieving up to a 2.5x improvement over base models, matching or exceeding full fine-tuning with over 4,700x fewer trainable parameters, and reducing training computation by more than 3.6x compared to the parameter-efficient baseline (LoRA). Our results demonstrate that neuron-level optimization offers an effective and scalable approach to securing code generation without sacrificing efficiency or generality.", "AI": {"tldr": "GoodVibe\u662f\u4e00\u4e2a\u795e\u7ecf\u5143\u7ea7\u522b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u5b89\u5168\u76f8\u5173\u795e\u7ecf\u5143\u5e76\u8fdb\u884c\u9009\u62e9\u6027\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u80fd\u529b\uff0c\u8bad\u7ec3\u6210\u672c\u6781\u4f4e\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5feb\u901f\u5f00\u53d1\u4e2d\u7ecf\u5e38\u751f\u6210\u529f\u80fd\u6b63\u786e\u4f46\u4e0d\u5b89\u5168\u7684\u4ee3\u7801\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u6210\u672c\u9ad8\u4e14\u5bb9\u6613\u707e\u96be\u6027\u9057\u5fd8\uff0c\u8981\u4e48\u7c92\u5ea6\u7c97\u4e14\u53ef\u63a7\u6027\u5dee\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u5b89\u5168\u4f18\u5316\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u5b89\u5168\u76f8\u5173\u63a8\u7406\u96c6\u4e2d\u5728\u5c11\u6570\u795e\u7ecf\u5143\u7684\u6d1e\u5bdf\uff0c\u4f7f\u7528\u68af\u5ea6\u5f52\u56e0\u8bc6\u522b\u5b89\u5168\u5173\u952e\u795e\u7ecf\u5143\uff0c\u8fdb\u884c\u795e\u7ecf\u5143\u9009\u62e9\u6027\u5fae\u8c03\uff0c\u5e76\u5f15\u5165\u6fc0\u6d3b\u9a71\u52a8\u7684\u795e\u7ecf\u5143\u805a\u7c7b\u6765\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u3002", "result": "\u5728C++\u3001Java\u3001Swift\u548cGo\u7b49\u5b89\u5168\u5173\u952e\u7f16\u7a0b\u8bed\u8a00\u76846\u4e2aLLM\u4e0a\u8bc4\u4f30\uff0cGoodVibe\u5c06\u751f\u6210\u4ee3\u7801\u5b89\u5168\u6027\u63d0\u5347\u9ad8\u8fbe2.5\u500d\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u5168\u5fae\u8c03\u6548\u679c\uff0c\u53ef\u8bad\u7ec3\u53c2\u6570\u51cf\u5c114700\u500d\uff0c\u8bad\u7ec3\u8ba1\u7b97\u6bd4LoRA\u57fa\u7ebf\u51cf\u5c113.6\u500d\u4ee5\u4e0a\u3002", "conclusion": "\u795e\u7ecf\u5143\u7ea7\u522b\u4f18\u5316\u4e3a\u4ee3\u7801\u751f\u6210\u5b89\u5168\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4e0d\u727a\u7272\u6548\u7387\u6216\u901a\u7528\u6027\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\u3002"}}
{"id": "2602.11015", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11015", "abs": "https://arxiv.org/abs/2602.11015", "authors": ["Valery Khvatov", "Alexey Neyman"], "title": "CVPL: A Geometric Framework for Post-Hoc Linkage Risk Assessment in Protected Tabular Data", "comment": "53 pages, 9 figures, 6 appendices. Code: https://github.com/DGT-Network/cvpl", "summary": "Formal privacy metrics provide compliance-oriented guarantees but often fail to quantify actual linkability in released datasets. We introduce CVPL (Cluster-Vector-Projection Linkage), a geometric framework for post-hoc assessment of linkage risk between original and protected tabular data. CVPL represents linkage analysis as an operator pipeline comprising blocking, vectorization, latent projection, and similarity evaluation, yielding continuous, scenario-dependent risk estimates rather than binary compliance verdicts. We formally define CVPL under an explicit threat model and introduce threshold-aware risk surfaces, R(lambda, tau), that capture the joint effects of protection strength and attacker strictness. We establish a progressive blocking strategy with monotonicity guarantees, enabling anytime risk estimation with valid lower bounds. We demonstrate that the classical Fellegi-Sunter linkage emerges as a special case of CVPL under restrictive assumptions, and that violations of these assumptions can lead to systematic over-linking bias. Empirical validation on 10,000 records across 19 protection configurations demonstrates that formal k-anonymity compliance may coexist with substantial empirical linkability, with a significant portion arising from non-quasi-identifier behavioral patterns. CVPL provides interpretable diagnostics identifying which features drive linkage feasibility, supporting privacy impact assessment, protection mechanism comparison, and utility-risk trade-off analysis.", "AI": {"tldr": "CVPL\u662f\u4e00\u4e2a\u51e0\u4f55\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u539f\u59cb\u6570\u636e\u4e0e\u53d7\u4fdd\u62a4\u6570\u636e\u4e4b\u95f4\u7684\u94fe\u63a5\u98ce\u9669\uff0c\u63d0\u4f9b\u8fde\u7eed\u7684\u98ce\u9669\u4f30\u8ba1\u800c\u975e\u4e8c\u5143\u5408\u89c4\u5224\u65ad\uff0c\u63ed\u793a\u5f62\u5f0f\u9690\u79c1\u6307\u6807\u4e0e\u5b9e\u9645\u94fe\u63a5\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u5f62\u5f0f\u9690\u79c1\u6307\u6807\uff08\u5982k-\u533f\u540d\u6027\uff09\u63d0\u4f9b\u5408\u89c4\u6027\u4fdd\u8bc1\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u91cf\u5316\u53d1\u5e03\u6570\u636e\u96c6\u4e2d\u5b9e\u9645\u7684\u94fe\u63a5\u98ce\u9669\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u7ed9\u51fa\u4e8c\u5143\u5408\u89c4\u5224\u65ad\uff0c\u7f3a\u4e4f\u5bf9\u5177\u4f53\u94fe\u63a5\u98ce\u9669\u7684\u8fde\u7eed\u8bc4\u4f30\u3002", "method": "\u63d0\u51faCVPL\uff08\u805a\u7c7b-\u5411\u91cf-\u6295\u5f71\u94fe\u63a5\uff09\u6846\u67b6\uff0c\u5c06\u94fe\u63a5\u5206\u6790\u5efa\u6a21\u4e3a\u64cd\u4f5c\u6d41\u6c34\u7ebf\uff1a\u5206\u5757\u3001\u5411\u91cf\u5316\u3001\u6f5c\u5728\u6295\u5f71\u548c\u76f8\u4f3c\u6027\u8bc4\u4f30\u3002\u5f15\u5165\u9608\u503c\u611f\u77e5\u98ce\u9669\u9762R(\u03bb, \u03c4)\u6765\u6355\u6349\u4fdd\u62a4\u5f3a\u5ea6\u548c\u653b\u51fb\u8005\u4e25\u683c\u5ea6\u7684\u8054\u5408\u6548\u5e94\u3002\u5efa\u7acb\u5177\u6709\u5355\u8c03\u6027\u4fdd\u8bc1\u7684\u6e10\u8fdb\u5206\u5757\u7b56\u7565\uff0c\u652f\u6301\u968f\u65f6\u98ce\u9669\u4f30\u8ba1\u548c\u6709\u6548\u4e0b\u754c\u3002", "result": "\u572810,000\u6761\u8bb0\u5f55\u548c19\u79cd\u4fdd\u62a4\u914d\u7f6e\u4e0a\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u663e\u793a\uff0c\u5f62\u5f0fk-\u533f\u540d\u6027\u5408\u89c4\u53ef\u80fd\u4e0e\u5b9e\u8d28\u6027\u7ecf\u9a8c\u94fe\u63a5\u6027\u5171\u5b58\uff0c\u4e14\u5927\u90e8\u5206\u94fe\u63a5\u98ce\u9669\u6765\u81ea\u975e\u51c6\u6807\u8bc6\u7b26\u7684\u884c\u4e3a\u6a21\u5f0f\u3002\u7ecf\u5178Fellegi-Sunter\u94fe\u63a5\u5728\u9650\u5236\u6027\u5047\u8bbe\u4e0b\u662fCVPL\u7684\u7279\u4f8b\uff0c\u8fdd\u53cd\u8fd9\u4e9b\u5047\u8bbe\u4f1a\u5bfc\u81f4\u7cfb\u7edf\u6027\u8fc7\u5ea6\u94fe\u63a5\u504f\u5dee\u3002", "conclusion": "CVPL\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u80fd\u8bc6\u522b\u9a71\u52a8\u94fe\u63a5\u53ef\u884c\u6027\u7684\u7279\u5f81\uff0c\u652f\u6301\u9690\u79c1\u5f71\u54cd\u8bc4\u4f30\u3001\u4fdd\u62a4\u673a\u5236\u6bd4\u8f83\u548c\u6548\u7528-\u98ce\u9669\u6743\u8861\u5206\u6790\uff0c\u5f25\u8865\u4e86\u5f62\u5f0f\u9690\u79c1\u6307\u6807\u4e0e\u5b9e\u9645\u94fe\u63a5\u98ce\u9669\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2602.11019", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.11019", "abs": "https://arxiv.org/abs/2602.11019", "authors": ["Jericho Cain", "Hayden Beadles"], "title": "Mask-Based Window-Level Insider Threat Detection for Campaign Discovery", "comment": null, "summary": "User and Entity Behavior Analytics (UEBA) systems commonly detect insider threats by scoring fixed time windows of user activity for anomalous behavior. While this window-level paradigm has proven effective for identifying sharp behavioral deviations, it remains unclear how much information about longer-running attack campaigns is already present within individual windows, and how such information can be leveraged for campaign discovery. In this work, we study unsupervised window-level insider threat detection on the CERT r4.2 dataset and show that explicitly separating activity presence from activity magnitude yields substantial performance gains. We introduce a dual-channel convolutional autoencoder that reconstructs both a binary activity mask and corresponding activity values, allowing the model to focus representational capacity on sparse behavioral structure rather than dense inactive baselines. Across multiday attack campaigns lasting between one and seven days, the proposed approach achieves a window-level precision-recall AUC of 0.71, substantially exceeding standard unsupervised autoencoder baselines and enabling high-precision operating points with zero false alarms.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u901a\u9053\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u5206\u79bb\u6d3b\u52a8\u5b58\u5728\u548c\u6d3b\u52a8\u5e45\u5ea6\u6765\u6539\u8fdb\u7528\u6237\u548c\u5b9e\u4f53\u884c\u4e3a\u5206\u6790\u4e2d\u7684\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\uff0c\u5728CERT r4.2\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u56fa\u5b9a\u65f6\u95f4\u7a97\u53e3\u7684UEBA\u7cfb\u7edf\u5728\u68c0\u6d4b\u77ed\u671f\u884c\u4e3a\u5f02\u5e38\u65b9\u9762\u6709\u6548\uff0c\u4f46\u96be\u4ee5\u53d1\u73b0\u6301\u7eed\u65f6\u95f4\u8f83\u957f\u7684\u653b\u51fb\u6d3b\u52a8\u3002\u9700\u8981\u7814\u7a76\u5982\u4f55\u4ece\u5355\u4e2a\u65f6\u95f4\u7a97\u53e3\u4e2d\u63d0\u53d6\u66f4\u591a\u5173\u4e8e\u957f\u671f\u653b\u51fb\u6d3b\u52a8\u7684\u4fe1\u606f\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u653b\u51fb\u6d3b\u52a8\u53d1\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u901a\u9053\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff0c\u540c\u65f6\u91cd\u6784\u4e8c\u8fdb\u5236\u6d3b\u52a8\u63a9\u7801\u548c\u5bf9\u5e94\u7684\u6d3b\u52a8\u503c\u3002\u8fd9\u79cd\u65b9\u6cd5\u8ba9\u6a21\u578b\u80fd\u591f\u5c06\u8868\u793a\u80fd\u529b\u96c6\u4e2d\u5728\u7a00\u758f\u7684\u884c\u4e3a\u7ed3\u6784\u4e0a\uff0c\u800c\u4e0d\u662f\u5bc6\u96c6\u7684\u975e\u6d3b\u52a8\u57fa\u7ebf\u3002", "result": "\u5728\u6301\u7eed1-7\u5929\u7684\u591a\u65e5\u653b\u51fb\u6d3b\u52a8\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7a97\u53e3\u7ea7\u7cbe\u786e\u7387-\u53ec\u56de\u7387AUC\u4e3a0.71\uff0c\u663e\u8457\u8d85\u8fc7\u6807\u51c6\u65e0\u76d1\u7763\u81ea\u7f16\u7801\u5668\u57fa\u7ebf\uff0c\u5e76\u80fd\u591f\u5728\u96f6\u8bef\u62a5\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u64cd\u4f5c\u70b9\u3002", "conclusion": "\u901a\u8fc7\u660e\u786e\u5206\u79bb\u6d3b\u52a8\u5b58\u5728\u548c\u6d3b\u52a8\u5e45\u5ea6\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u65e0\u76d1\u7763\u7a97\u53e3\u7ea7\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u4e3a\u53d1\u73b0\u957f\u671f\u653b\u51fb\u6d3b\u52a8\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2602.11023", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.11023", "abs": "https://arxiv.org/abs/2602.11023", "authors": ["Shaoyu Li", "Hexuan Yu", "Shanghao Shi", "Md Mohaimin Al Barat", "Yang Xiao", "Y. Thomas Hou", "Wenjing Lou"], "title": "IU-GUARD: Privacy-Preserving Spectrum Coordination for Incumbent Users under Dynamic Spectrum Sharing", "comment": null, "summary": "With the growing demand for wireless spectrum, dynamic spectrum sharing (DSS) frameworks such as the Citizens Broadband Radio Service (CBRS) have emerged as practical solutions to improve utilization while protecting incumbent users (IUs) such as military radars. However, current incumbent protection mechanisms face critical limitations. The Environmental Sensing Capability (ESC) requires costly sensor deployments and remains vulnerable to interference and security risks. Alternatively, the Incumbent Informing Capability (IIC) requires IUs to disclose their identities and operational parameters to the Spectrum Coordination System (SCS), creating linkable records that compromise operational privacy and mission secrecy. We propose IU-GUARD, a privacy-preserving spectrum sharing framework that enables IUs to access spectrum without revealing their identities. Leveraging verifiable credentials (VCs) and zero-knowledge proofs (ZKPs), IU-GUARD allows IUs to prove their authorization to the SCS while disclosing only essential operational parameters. This decouples IU identity from spectrum access, prevents cross-request linkage, and mitigates the risk of centralized SCS data leakage. We implement a prototype, and our evaluation shows that IU-GUARD achieves strong privacy guarantees with practical computation and communication overhead, making it suitable for real-time DSS deployment.", "AI": {"tldr": "IU-GUARD\u662f\u4e00\u4e2a\u4fdd\u62a4\u9690\u79c1\u7684\u52a8\u6001\u9891\u8c31\u5171\u4eab\u6846\u67b6\uff0c\u4f7f\u7528\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u8ba9\u4e3b\u8981\u7528\u6237\u5728\u4e0d\u66b4\u9732\u8eab\u4efd\u7684\u60c5\u51b5\u4e0b\u8bc1\u660e\u5176\u9891\u8c31\u4f7f\u7528\u6388\u6743\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4fdd\u62a4\u673a\u5236\u7684\u6210\u672c\u9ad8\u3001\u9690\u79c1\u6cc4\u9732\u7b49\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u52a8\u6001\u9891\u8c31\u5171\u4eab\u4e2d\u7684\u4e3b\u8981\u7528\u6237\u4fdd\u62a4\u673a\u5236\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff1a\u73af\u5883\u611f\u77e5\u80fd\u529b\u9700\u8981\u6602\u8d35\u7684\u4f20\u611f\u5668\u90e8\u7f72\u4e14\u6613\u53d7\u5e72\u6270\u548c\u5b89\u5168\u98ce\u9669\uff1b\u4e3b\u8981\u7528\u6237\u4fe1\u606f\u80fd\u529b\u8981\u6c42\u4e3b\u8981\u7528\u6237\u5411\u9891\u8c31\u534f\u8c03\u7cfb\u7edf\u62ab\u9732\u8eab\u4efd\u548c\u64cd\u4f5c\u53c2\u6570\uff0c\u8fd9\u4f1a\u521b\u5efa\u53ef\u94fe\u63a5\u7684\u8bb0\u5f55\uff0c\u635f\u5bb3\u64cd\u4f5c\u9690\u79c1\u548c\u4efb\u52a1\u4fdd\u5bc6\u6027\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u4e3b\u8981\u7528\u6237\u9690\u79c1\u53c8\u80fd\u786e\u4fdd\u9891\u8c31\u5171\u4eab\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faIU-GUARD\u6846\u67b6\uff0c\u5229\u7528\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u6280\u672f\uff0c\u4f7f\u4e3b\u8981\u7528\u6237\u80fd\u591f\u5411\u9891\u8c31\u534f\u8c03\u7cfb\u7edf\u8bc1\u660e\u5176\u6388\u6743\uff0c\u540c\u65f6\u4ec5\u62ab\u9732\u5fc5\u8981\u7684\u64cd\u4f5c\u53c2\u6570\u3002\u8be5\u65b9\u6cd5\u5c06\u4e3b\u8981\u7528\u6237\u8eab\u4efd\u4e0e\u9891\u8c31\u8bbf\u95ee\u89e3\u8026\uff0c\u9632\u6b62\u8de8\u8bf7\u6c42\u94fe\u63a5\uff0c\u5e76\u51cf\u8f7b\u96c6\u4e2d\u5f0f\u9891\u8c31\u534f\u8c03\u7cfb\u7edf\u6570\u636e\u6cc4\u9732\u7684\u98ce\u9669\u3002", "result": "\u5b9e\u73b0\u4e86\u539f\u578b\u7cfb\u7edf\uff0c\u8bc4\u4f30\u663e\u793aIU-GUARD\u5728\u63d0\u4f9b\u5f3a\u5927\u9690\u79c1\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u5177\u6709\u5b9e\u9645\u53ef\u884c\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\uff0c\u9002\u5408\u5b9e\u65f6\u52a8\u6001\u9891\u8c31\u5171\u4eab\u90e8\u7f72\u3002", "conclusion": "IU-GUARD\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u9690\u79c1\u4fdd\u62a4\u9891\u8c31\u5171\u4eab\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u4e3b\u8981\u7528\u6237\u4fdd\u62a4\u673a\u5236\u7684\u5c40\u9650\u6027\uff0c\u5728\u4fdd\u62a4\u4e3b\u8981\u7528\u6237\u64cd\u4f5c\u9690\u79c1\u7684\u540c\u65f6\u786e\u4fdd\u4e86\u9891\u8c31\u5171\u4eab\u7684\u5b89\u5168\u6027\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2602.11088", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.11088", "abs": "https://arxiv.org/abs/2602.11088", "authors": ["Abhishek Saini", "Haolin Jiang", "Hang Liu"], "title": "Vulnerabilities in Partial TEE-Shielded LLM Inference with Precomputed Noise", "comment": null, "summary": "The deployment of large language models (LLMs) on third-party devices requires new ways to protect model intellectual property. While Trusted Execution Environments (TEEs) offer a promising solution, their performance limits can lead to a critical compromise: using a precomputed, static secret basis to accelerate cryptographic operations. We demonstrate that this mainstream design pattern introduces a classic cryptographic flaw, the reuse of secret keying material, into the system's protocol. We prove its vulnerability with two distinct attacks: First, our attack on a model confidentiality system achieves a full confidentiality break by recovering its secret permutations and model weights. Second, our integrity attack completely bypasses the integrity checks of systems like Soter and TSQP. We demonstrate the practicality of our attacks against state-of-the-art LLMs, recovering a layer's secrets from a LLaMA-3 8B model in about 6 minutes and showing the attack scales to compromise 405B-parameter LLMs across a variety of configurations.", "AI": {"tldr": "\u4e3b\u6d41TEE\u52a0\u901f\u8bbe\u8ba1\u4e2d\u7684\u9759\u6001\u5bc6\u94a5\u91cd\u7528\u6f0f\u6d1e\u5bfc\u81f4LLM\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7cfb\u7edf\u88ab\u5b8c\u5168\u653b\u7834", "motivation": "\u7b2c\u4e09\u65b9\u8bbe\u5907\u4e0a\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9700\u8981\u4fdd\u62a4\u6a21\u578b\u77e5\u8bc6\u4ea7\u6743\uff0cTEE\u662f\u53ef\u884c\u65b9\u6848\u4f46\u6027\u80fd\u9650\u5236\u5bfc\u81f4\u8bbe\u8ba1\u59a5\u534f\uff0c\u91c7\u7528\u9884\u8ba1\u7b97\u7684\u9759\u6001\u5bc6\u94a5\u57fa\u7840\u6765\u52a0\u901f\u52a0\u5bc6\u64cd\u4f5c", "method": "\u901a\u8fc7\u5206\u6790\u4e3b\u6d41TEE\u52a0\u901f\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u53d1\u73b0\u5176\u4e2d\u5b58\u5728\u7ecf\u5178\u7684\u5bc6\u7801\u5b66\u7f3a\u9677\u2014\u2014\u5bc6\u94a5\u6750\u6599\u7684\u91cd\u590d\u4f7f\u7528\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u653b\u51fb\u65b9\u6cd5\uff1a\u9488\u5bf9\u6a21\u578b\u4fdd\u5bc6\u7cfb\u7edf\u7684\u653b\u51fb\uff08\u6062\u590d\u79d8\u5bc6\u7f6e\u6362\u548c\u6a21\u578b\u6743\u91cd\uff09\u548c\u9488\u5bf9\u5b8c\u6574\u6027\u7cfb\u7edf\u7684\u653b\u51fb\uff08\u7ed5\u8fc7Soter\u548cTSQP\u7b49\u7cfb\u7edf\u7684\u5b8c\u6574\u6027\u68c0\u67e5\uff09", "result": "\u653b\u51fb\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\uff1a\u5728\u7ea66\u5206\u949f\u5185\u6062\u590dLLaMA-3 8B\u6a21\u578b\u4e00\u5c42\u7684\u79d8\u5bc6\uff1b\u653b\u51fb\u53ef\u6269\u5c55\u5230405B\u53c2\u6570\u7684LLM\uff0c\u5728\u5404\u79cd\u914d\u7f6e\u4e0b\u90fd\u80fd\u6210\u529f", "conclusion": "\u5f53\u524d\u4e3b\u6d41\u7684TEE\u52a0\u901f\u8bbe\u8ba1\u6a21\u5f0f\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u7cfb\u7edf\u4ee5\u907f\u514d\u5bc6\u94a5\u6750\u6599\u7684\u91cd\u590d\u4f7f\u7528\uff0c\u786e\u4fddLLM\u5728\u7b2c\u4e09\u65b9\u8bbe\u5907\u4e0a\u7684\u5b89\u5168\u90e8\u7f72"}}
