{"id": "2510.16059", "categories": ["cs.SE", "cs.CL", "D.2.2; D.2.3"], "pdf": "https://arxiv.org/pdf/2510.16059", "abs": "https://arxiv.org/abs/2510.16059", "authors": ["Xin Cao", "Nan Yu"], "title": "SIADAFIX: issue description response for adaptive program repair", "comment": "20 pages, 3 figures", "summary": "We propose utilizing fast and slow thinking to enhance the capabilities of\nlarge language model-based agents on complex tasks such as program repair. In\nparticular, we design an adaptive program repair method based on issue\ndescription response, called SIADAFIX. The proposed method utilizes slow\nthinking bug fix agent to complete complex program repair tasks, and employs\nfast thinking workflow decision components to optimize and classify issue\ndescriptions, using issue description response results to guide the\norchestration of bug fix agent workflows. SIADAFIX adaptively selects three\nrepair modes, i.e., easy, middle and hard mode, based on problem complexity. It\nemploys fast generalization for simple problems and test-time scaling\ntechniques for complex problems. Experimental results on the SWE-bench Lite\nshow that the proposed method achieves 60.67% pass@1 performance using the\nClaude-4 Sonnet model, reaching state-of-the-art levels among all open-source\nmethods. SIADAFIX effectively balances repair efficiency and accuracy,\nproviding new insights for automated program repair. Our code is available at\nhttps://github.com/liauto-siada/siada-cli.", "AI": {"tldr": "SIADAFIX\u662f\u4e00\u79cd\u57fa\u4e8e\u5feb\u6162\u601d\u7ef4\u7684\u81ea\u9002\u5e94\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u95ee\u9898\u63cf\u8ff0\u54cd\u5e94\u6765\u6307\u5bfc\u4fee\u590d\u5de5\u4f5c\u6d41\uff0c\u5728SWE-bench Lite\u4e0a\u8fbe\u523060.67%\u7684pass@1\u6027\u80fd", "motivation": "\u5229\u7528\u5feb\u6162\u601d\u7ef4\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\uff08\u5982\u7a0b\u5e8f\u4fee\u590d\uff09\u4e0a\u7684\u80fd\u529b\uff0c\u5e73\u8861\u4fee\u590d\u6548\u7387\u548c\u51c6\u786e\u6027", "method": "\u8bbe\u8ba1\u81ea\u9002\u5e94\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5SIADAFIX\uff0c\u4f7f\u7528\u6162\u601d\u7ef4bug\u4fee\u590d\u4ee3\u7406\u5b8c\u6210\u590d\u6742\u4efb\u52a1\uff0c\u5feb\u601d\u7ef4\u5de5\u4f5c\u6d41\u51b3\u7b56\u7ec4\u4ef6\u4f18\u5316\u548c\u5206\u7c7b\u95ee\u9898\u63cf\u8ff0\uff0c\u6839\u636e\u95ee\u9898\u590d\u6742\u5ea6\u81ea\u9002\u5e94\u9009\u62e9\u7b80\u5355\u3001\u4e2d\u7b49\u3001\u56f0\u96be\u4e09\u79cd\u4fee\u590d\u6a21\u5f0f", "result": "\u5728SWE-bench Lite\u4e0a\u4f7f\u7528Claude-4 Sonnet\u6a21\u578b\u8fbe\u523060.67% pass@1\u6027\u80fd\uff0c\u5728\u6240\u6709\u5f00\u6e90\u65b9\u6cd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73", "conclusion": "SIADAFIX\u6709\u6548\u5e73\u8861\u4e86\u4fee\u590d\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2510.16242", "categories": ["cs.SE", "cs.DL"], "pdf": "https://arxiv.org/pdf/2510.16242", "abs": "https://arxiv.org/abs/2510.16242", "authors": ["Eva Maxfield Brown", "Isaac Slaughter", "Nicholas Weber"], "title": "Code Contribution and Credit in Science", "comment": null, "summary": "Software development has become essential to scientific research, but its\nrelationship to traditional metrics of scholarly credit remains poorly\nunderstood. We develop a dataset of approximately 140,000 paired research\narticles and code repositories, as well as a predictive model that matches\nresearch article authors with software repository developer accounts. We use\nthis data to investigate how software development activities influence credit\nallocation in collaborative scientific settings. Our findings reveal\nsignificant patterns distinguishing software contributions from traditional\nauthorship credit. We find that nearly 30% of articles include non-author code\ncontributors- individuals who participated in software development but received\nno formal authorship recognition. While code-contributing authors show a modest\n$\\sim$4.2% increase in article citations, this effect becomes non-significant\nwhen controlling for domain, article type, and open access status. First\nauthors are significantly more likely to be code contributors than other author\npositions. Notably, we identify a negative relationship between coding\nfrequency and scholarly impact metrics. Authors who contribute code more\nfrequently exhibit progressively lower h-indices than non-coding colleagues,\neven when controlling for publication count, author position, domain, and\narticle type. These results suggest a disconnect between software contributions\nand credit, highlighting important implications for institutional reward\nstructures and science policy.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8f6f\u4ef6\u8d21\u732e\u4e0e\u5b66\u672f\u8ba4\u53ef\u4e4b\u95f4\u5b58\u5728\u8131\u8282\uff0c\u8fd130%\u8bba\u6587\u5305\u542b\u672a\u83b7\u4f5c\u8005\u7f72\u540d\u7684\u4ee3\u7801\u8d21\u732e\u8005\uff0c\u9891\u7e41\u7f16\u7801\u7684\u4f5c\u8005h\u6307\u6570\u53cd\u800c\u66f4\u4f4e", "motivation": "\u7406\u89e3\u8f6f\u4ef6\u5f00\u53d1\u6d3b\u52a8\u5982\u4f55\u5f71\u54cd\u79d1\u5b66\u5408\u4f5c\u4e2d\u7684\u5b66\u672f\u8ba4\u53ef\u5206\u914d\uff0c\u63a2\u7a76\u8f6f\u4ef6\u8d21\u732e\u4e0e\u4f20\u7edf\u5b66\u672f\u8bc4\u4ef7\u6307\u6807\u4e4b\u95f4\u7684\u5173\u7cfb", "method": "\u6784\u5efa\u5305\u542b14\u4e07\u7bc7\u7814\u7a76\u8bba\u6587\u4e0e\u4ee3\u7801\u4ed3\u5e93\u914d\u5bf9\u7684\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u9884\u6d4b\u6a21\u578b\u5339\u914d\u8bba\u6587\u4f5c\u8005\u4e0e\u4ee3\u7801\u4ed3\u5e93\u5f00\u53d1\u8005\u8d26\u6237\uff0c\u5206\u6790\u8f6f\u4ef6\u8d21\u732e\u5bf9\u5b66\u672f\u8ba4\u53ef\u7684\u5f71\u54cd", "result": "30%\u8bba\u6587\u5305\u542b\u672a\u83b7\u4f5c\u8005\u7f72\u540d\u7684\u4ee3\u7801\u8d21\u732e\u8005\uff1b\u4ee3\u7801\u8d21\u732e\u4f5c\u8005\u4ec5\u83b7\u5f974.2%\u5f15\u7528\u589e\u957f\u4f46\u7edf\u8ba1\u4e0d\u663e\u8457\uff1b\u7b2c\u4e00\u4f5c\u8005\u66f4\u53ef\u80fd\u662f\u4ee3\u7801\u8d21\u732e\u8005\uff1b\u7f16\u7801\u9891\u7387\u4e0eh\u6307\u6570\u5448\u8d1f\u76f8\u5173", "conclusion": "\u8f6f\u4ef6\u8d21\u732e\u4e0e\u5b66\u672f\u8ba4\u53ef\u4e4b\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u8131\u8282\uff0c\u8fd9\u5bf9\u673a\u6784\u5956\u52b1\u7ed3\u6784\u548c\u79d1\u5b66\u653f\u7b56\u5177\u6709\u91cd\u8981\u542f\u793a"}}
{"id": "2510.16357", "categories": ["cs.SE", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.16357", "abs": "https://arxiv.org/abs/2510.16357", "authors": ["Jugal Gajjar", "Kamalasankari Subramaniakuppusamy"], "title": "MLCPD: A Unified Multi-Language Code Parsing Dataset with Universal AST Schema", "comment": "12 pages, 7 figures, 4 tables, 2 algorithms, and 34 references.\n  HuggingFace:\n  https://huggingface.co/datasets/jugalgajjar/MultiLang-Code-Parser-Dataset\n  GitHub: https://github.com/JugalGajjar/MultiLang-Code-Parser-Dataset", "summary": "We introduce the MultiLang Code Parser Dataset (MLCPD), a large-scale,\nlanguage-agnostic dataset unifying syntactic and structural representations of\ncode across ten major programming languages. MLCPD contains over seven million\nparsed source files normalized under our proposed universal Abstract Syntax\nTree (AST) schema, enabling consistent cross-language reasoning, structural\nlearning, and multilingual software analysis. Unlike existing corpora that\nfocus purely on token-level code or isolated parsers, MLCPD provides both\nhierarchical tree representations and rich metadata for every file, ensuring\nlossless syntactic coverage and structural uniformity. Each entry includes a\nnormalized schema, language-level metadata, and abstracted node semantics\nstored in Parquet format for scalable retrieval. Empirical analyses reveal\nstrong cross-language structural regularities-demonstrating that syntactic\ngraphs from languages as diverse as Python, Java, and Go can be aligned under a\nshared schema. We release the dataset publicly on Hugging Face and the\naccompanying codebase on GitHub, which includes complete pipelines for dataset\nreproduction, grammar compilation, and a visualization tool for exploring the\nunified AST across languages. Together, these resources establish MLCPD as an\nopen, reproducible foundation for future research in cross-language\nrepresentation learning and program analysis.", "AI": {"tldr": "MLCPD\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u8bed\u8a00\u65e0\u5173\u7684\u4ee3\u7801\u89e3\u6790\u6570\u636e\u96c6\uff0c\u7edf\u4e00\u4e8610\u79cd\u4e3b\u8981\u7f16\u7a0b\u8bed\u8a00\u7684\u8bed\u6cd5\u548c\u7ed3\u6784\u8868\u793a\uff0c\u5305\u542b\u8d85\u8fc7700\u4e07\u4e2a\u89e3\u6790\u540e\u7684\u6e90\u6587\u4ef6\uff0c\u91c7\u7528\u901a\u7528AST\u6a21\u5f0f\u8fdb\u884c\u6807\u51c6\u5316\u3002", "motivation": "\u73b0\u6709\u8bed\u6599\u5e93\u4e3b\u8981\u5173\u6ce8\u6807\u8bb0\u7ea7\u4ee3\u7801\u6216\u5b64\u7acb\u89e3\u6790\u5668\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u8de8\u8bed\u8a00\u7ed3\u6784\u8868\u793a\u3002MLCPD\u65e8\u5728\u63d0\u4f9b\u4e00\u81f4\u7684\u8de8\u8bed\u8a00\u63a8\u7406\u3001\u7ed3\u6784\u5b66\u4e60\u548c\u591a\u8bed\u8a00\u8f6f\u4ef6\u5206\u6790\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u901a\u7528\u62bd\u8c61\u8bed\u6cd5\u6811(AST)\u6a21\u5f0f\uff0c\u5bf910\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u6e90\u4ee3\u7801\u8fdb\u884c\u89e3\u6790\u548c\u6807\u51c6\u5316\uff0c\u5305\u542b\u5c42\u6b21\u5316\u6811\u8868\u793a\u548c\u4e30\u5bcc\u5143\u6570\u636e\uff0c\u786e\u4fdd\u65e0\u635f\u8bed\u6cd5\u8986\u76d6\u548c\u7ed3\u6784\u4e00\u81f4\u6027\u3002", "result": "\u7ecf\u9a8c\u5206\u6790\u663e\u793a\u8de8\u8bed\u8a00\u7ed3\u6784\u89c4\u5f8b\u6027\u5f3a\uff0cPython\u3001Java\u3001Go\u7b49\u4e0d\u540c\u8bed\u8a00\u7684\u8bed\u6cd5\u56fe\u53ef\u4ee5\u5728\u5171\u4eab\u6a21\u5f0f\u4e0b\u5bf9\u9f50\u3002\u6570\u636e\u96c6\u4ee5Parquet\u683c\u5f0f\u5b58\u50a8\uff0c\u4fbf\u4e8e\u6269\u5c55\u68c0\u7d22\u3002", "conclusion": "MLCPD\u4e3a\u8de8\u8bed\u8a00\u8868\u793a\u5b66\u4e60\u548c\u7a0b\u5e8f\u5206\u6790\u7684\u672a\u6765\u7814\u7a76\u5efa\u7acb\u4e86\u5f00\u653e\u3001\u53ef\u590d\u73b0\u7684\u57fa\u7840\uff0c\u76f8\u5173\u8d44\u6e90\u5df2\u5728Hugging Face\u548cGitHub\u4e0a\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2510.16384", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.16384", "abs": "https://arxiv.org/abs/2510.16384", "authors": ["Yuwei Zhao", "Yuan-An Xiao", "Qianyu Xiao", "Zhao Zhang", "Yingfei Xiong"], "title": "SemOpt: LLM-Driven Code Optimization via Rule-Based Analysis", "comment": null, "summary": "Automated code optimization aims to improve performance in programs by\nrefactoring code, and recent studies focus on utilizing LLMs for the\noptimization. Typical existing approaches mine optimization commits from\nopen-source codebases to construct a large-scale knowledge base, then employ\ninformation retrieval techniques such as BM25 to retrieve relevant optimization\nexamples for hotspot code locations, thereby guiding LLMs to optimize these\nhotspots. However, since semantically equivalent optimizations can manifest in\nsyntactically dissimilar code snippets, current retrieval methods often fail to\nidentify pertinent examples, leading to suboptimal optimization performance.\nThis limitation significantly reduces the effectiveness of existing\noptimization approaches.\n  To address these limitations, we propose SemOpt, a novel framework that\nleverages static program analysis to precisely identify optimizable code\nsegments, retrieve the corresponding optimization strategies, and generate the\noptimized results. SemOpt consists of three key components: (1) A strategy\nlibrary builder that extracts and clusters optimization strategies from\nreal-world code modifications. (2) A rule generator that generates Semgrep\nstatic analysis rules to capture the condition of applying the optimization\nstrategy. (3) An optimizer that utilizes the strategy library to generate\noptimized code results. All the three components are powered by LLMs.\n  On our benchmark containing 151 optimization tasks, SemOpt demonstrates its\neffectiveness under different LLMs by increasing the number of successful\noptimizations by 1.38 to 28 times compared to the baseline. Moreover, on\npopular large-scale C/C++ projects, it can improve individual performance\nmetrics by 5.04% to 218.07%, demonstrating its practical utility.", "AI": {"tldr": "SemOpt\u662f\u4e00\u4e2a\u5229\u7528\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u548cLLM\u8fdb\u884c\u4ee3\u7801\u4f18\u5316\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u7b56\u7565\u5e93\u3001\u751f\u6210\u9759\u6001\u5206\u6790\u89c4\u5219\u548c\u4f18\u5316\u4ee3\u7801\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u4f18\u5316\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u4fe1\u606f\u68c0\u7d22\u6280\u672f\u4ece\u4ee3\u7801\u5e93\u4e2d\u67e5\u627e\u4f18\u5316\u793a\u4f8b\uff0c\u4f46\u7531\u4e8e\u8bed\u4e49\u7b49\u4ef7\u4f46\u8bed\u6cd5\u4e0d\u540c\u7684\u4ee3\u7801\u7247\u6bb5\u96be\u4ee5\u88ab\u51c6\u786e\u68c0\u7d22\uff0c\u5bfc\u81f4\u4f18\u5316\u6027\u80fd\u4e0d\u4f73\u3002", "method": "SemOpt\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u7b56\u7565\u5e93\u6784\u5efa\u5668\u4ece\u771f\u5b9e\u4ee3\u7801\u4fee\u6539\u4e2d\u63d0\u53d6\u548c\u805a\u7c7b\u4f18\u5316\u7b56\u7565\uff1b\u89c4\u5219\u751f\u6210\u5668\u751f\u6210Semgrep\u9759\u6001\u5206\u6790\u89c4\u5219\u6765\u8bc6\u522b\u53ef\u4f18\u5316\u4ee3\u7801\u6bb5\uff1b\u4f18\u5316\u5668\u5229\u7528\u7b56\u7565\u5e93\u751f\u6210\u4f18\u5316\u7ed3\u679c\u3002\u6240\u6709\u7ec4\u4ef6\u90fd\u7531LLM\u9a71\u52a8\u3002", "result": "\u5728\u5305\u542b151\u4e2a\u4f18\u5316\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSemOpt\u5728\u4e0d\u540cLLM\u4e0b\u5c06\u6210\u529f\u4f18\u5316\u6570\u91cf\u63d0\u9ad8\u4e861.38\u523028\u500d\u3002\u5728\u5927\u578bC/C++\u9879\u76ee\u4e2d\uff0c\u5355\u4e2a\u6027\u80fd\u6307\u6807\u63d0\u5347\u4e865.04%\u5230218.07%\u3002", "conclusion": "SemOpt\u901a\u8fc7\u7ed3\u5408\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u548cLLM\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u4ee3\u7801\u4f18\u5316\u65b9\u6cd5\u4e2d\u68c0\u7d22\u76f8\u5173\u793a\u4f8b\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u4f18\u5316\u6548\u679c\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.15948", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.15948", "abs": "https://arxiv.org/abs/2510.15948", "authors": ["MingSheng Li", "Guangze Zhao", "Sichen Liu"], "title": "VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search", "comment": null, "summary": "Large Vision-Language Models (LVLMs) have achieved remarkable progress in\nmultimodal perception and generation, yet their safety alignment remains a\ncritical challenge.Existing defenses and vulnerable to multimodal jailbreaks,\nas visual inputs introduce new attack surfaces, reasoning chains lack safety\nsupervision, and alignment often degrades under modality fusion.To overcome\nthese limitation, we propose VisuoAlign, a framework for multi-modal safety\nalignment via prompt-guided tree search.VisuoAlign embeds safety constrains\ninto the reasoning process through visual-textual interactive prompts, employs\nMonte Carlo Tree Search(MCTS) to systematically construct diverse\nsafety-critical prompt trajectories, and introduces prompt-based scaling to\nensure real-time risk detection and compliant responses.Extensive experiments\ndemonstrate that VisuoAlign proactively exposes risks, enables comprehensive\ndataset generation, and significantly improves the robustness of LVLMs against\ncomplex cross-modal threats.", "AI": {"tldr": "VisuoAlign\u662f\u4e00\u4e2a\u901a\u8fc7\u63d0\u793a\u5f15\u5bfc\u6811\u641c\u7d22\u8fdb\u884c\u591a\u6a21\u6001\u5b89\u5168\u5bf9\u9f50\u7684\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u4e0b\u7684\u5b89\u5168\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5bf9\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u5b58\u5728\u8106\u5f31\u6027\uff0c\u56e0\u4e3a\u89c6\u89c9\u8f93\u5165\u5f15\u5165\u4e86\u65b0\u7684\u653b\u51fb\u9762\uff0c\u63a8\u7406\u94fe\u7f3a\u4e4f\u5b89\u5168\u76d1\u7763\uff0c\u4e14\u6a21\u6001\u878d\u5408\u4f1a\u524a\u5f31\u5bf9\u9f50\u6548\u679c\u3002", "method": "\u901a\u8fc7\u89c6\u89c9-\u6587\u672c\u4ea4\u4e92\u63d0\u793a\u5c06\u5b89\u5168\u7ea6\u675f\u5d4c\u5165\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6784\u5efa\u591a\u6837\u5316\u7684\u5b89\u5168\u5173\u952e\u63d0\u793a\u8f68\u8ff9\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u63d0\u793a\u7684\u7f29\u653e\u5b9e\u73b0\u5b9e\u65f6\u98ce\u9669\u68c0\u6d4b\u548c\u5408\u89c4\u54cd\u5e94\u3002", "result": "\u5b9e\u9a8c\u8868\u660eVisuoAlign\u80fd\u4e3b\u52a8\u66b4\u9732\u98ce\u9669\uff0c\u652f\u6301\u5168\u9762\u6570\u636e\u96c6\u751f\u6210\uff0c\u5e76\u663e\u8457\u63d0\u5347LVLMs\u5bf9\u590d\u6742\u8de8\u6a21\u6001\u5a01\u80c1\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "VisuoAlign\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5b89\u5168\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u4e3aLVLMs\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u5b89\u5168\u9632\u62a4\u80fd\u529b\u3002"}}
{"id": "2510.15953", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.15953", "abs": "https://arxiv.org/abs/2510.15953", "authors": ["Sisir Doppalapudi"], "title": "Hierarchical Multi-Modal Threat Intelligence Fusion Without Aligned Data: A Practical Framework for Real-World Security Operations", "comment": null, "summary": "Multi-modal threat detection faces a fundamental challenge that involves\nsecurity tools operating in isolation, and this creates streams of network,\nemail, and system data with no natural alignment or correlation. We present\nHierarchical Multi-Modal Threat Intelligence Fusion (HM-TIF), a framework\nexplicitly designed for this realistic scenario where naturally aligned\nmulti-modal attack data does not exist. Unlike prior work that assumes or\ncreates artificial alignment, we develop principled methods for correlating\nindependent security data streams while maintaining operational validity. Our\narchitecture employs hierarchical cross-attention with dynamic weighting that\nadapts to data availability and threat context, coupled with a novel temporal\ncorrelation protocol that preserves statistical independence. Evaluation on\nUNSW-NB15, CSE-CIC-IDS2018, and CICBell-DNS2021 datasets demonstrates that\nHM-TIF achieves 88.7% accuracy with a critical 32% reduction in false positive\nrates, even without true multi-modal training data. The framework maintains\nrobustness when modalities are missing, making it immediately deployable in\nreal security operations where data streams frequently have gaps. Our\ncontributions include: (i) the first multi-modal security framework explicitly\ndesigned for non-aligned data, (ii) a temporal correlation protocol that avoids\ncommon data leakage pitfalls, (iii) empirical validation that multi-modal\nfusion provides operational benefits even without perfect alignment, and (iv)\npractical deployment guidelines for security teams facing heterogeneous,\nuncoordinated data sources. Index Terms: multi-modal learning, threat\nintelligence, non-aligned data, operational security, cross-attention\nmechanisms, practical deployment", "AI": {"tldr": "HM-TIF\u6846\u67b6\u9488\u5bf9\u591a\u6a21\u6001\u5a01\u80c1\u68c0\u6d4b\u4e2d\u6570\u636e\u81ea\u7136\u4e0d\u5bf9\u9f50\u7684\u73b0\u5b9e\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u5c42\u6b21\u5316\u591a\u6a21\u6001\u5a01\u80c1\u60c5\u62a5\u878d\u5408\u65b9\u6cd5\uff0c\u65e0\u9700\u771f\u5b9e\u5bf9\u9f50\u6570\u636e\u5373\u53ef\u5b9e\u73b088.7%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u964d\u4f4e32%\u8bef\u62a5\u7387\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u5a01\u80c1\u68c0\u6d4b\u4e2d\u5b89\u5168\u5de5\u5177\u5b64\u7acb\u8fd0\u884c\u3001\u7f51\u7edc\u3001\u90ae\u4ef6\u548c\u7cfb\u7edf\u6570\u636e\u6d41\u7f3a\u4e4f\u81ea\u7136\u5bf9\u9f50\u548c\u5173\u8054\u7684\u6839\u672c\u6311\u6218\u3002", "method": "\u91c7\u7528\u5c42\u6b21\u5316\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u548c\u52a8\u6001\u6743\u91cd\u8c03\u6574\uff0c\u7ed3\u5408\u65b0\u9896\u7684\u65f6\u95f4\u5173\u8054\u534f\u8bae\u6765\u4fdd\u6301\u7edf\u8ba1\u72ec\u7acb\u6027\uff0c\u65e0\u9700\u5047\u8bbe\u6216\u521b\u5efa\u4eba\u5de5\u5bf9\u9f50\u3002", "result": "\u5728UNSW-NB15\u3001CSE-CIC-IDS2018\u548cCICBell-DNS2021\u6570\u636e\u96c6\u4e0a\u8fbe\u523088.7%\u51c6\u786e\u7387\uff0c\u8bef\u62a5\u7387\u964d\u4f4e32%\uff0c\u5728\u6a21\u6001\u7f3a\u5931\u65f6\u4ecd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "HM-TIF\u662f\u9996\u4e2a\u4e13\u4e3a\u975e\u5bf9\u9f50\u6570\u636e\u8bbe\u8ba1\u7684\u591a\u6a21\u6001\u5b89\u5168\u6846\u67b6\uff0c\u5373\u4f7f\u5728\u6570\u636e\u6d41\u4e0d\u5b8c\u6574\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u7acb\u5373\u90e8\u7f72\u5230\u5b9e\u9645\u5b89\u5168\u8fd0\u8425\u4e2d\u3002"}}
{"id": "2510.16395", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.16395", "abs": "https://arxiv.org/abs/2510.16395", "authors": ["Xin Peng", "Chong Wang"], "title": "Code Digital Twin: Empowering LLMs with Tacit Knowledge for Complex Software Development", "comment": null, "summary": "Recent advances in large language models (LLMs) have demonstrated strong\ncapabilities in software engineering tasks, raising expectations of\nrevolutionary productivity gains. However, enterprise software development is\nlargely driven by incremental evolution, where challenges extend far beyond\nroutine coding and depend critically on tacit knowledge, including design\ndecisions at different levels and historical trade-offs. To achieve effective\nAI-powered support for complex software development, we should align emerging\nAI capabilities with the practical realities of enterprise development. To this\nend, we systematically identify challenges from both software and LLM\nperspectives. Alongside these challenges, we outline opportunities where AI and\nstructured knowledge frameworks can enhance decision-making in tasks such as\nissue localization and impact analysis. To address these needs, we propose the\nCode Digital Twin, a living framework that models both the physical and\nconceptual layers of software, preserves tacit knowledge, and co-evolves with\nthe codebase. By integrating hybrid knowledge representations, multi-stage\nextraction pipelines, incremental updates, LLM-empowered applications, and\nhuman-in-the-loop feedback, the Code Digital Twin transforms fragmented\nknowledge into explicit and actionable representations. Our vision positions it\nas a bridge between AI advancements and enterprise software realities,\nproviding a concrete roadmap toward sustainable, intelligent, and resilient\ndevelopment and evolution of ultra-complex systems.", "AI": {"tldr": "\u63d0\u51faCode Digital Twin\u6846\u67b6\uff0c\u5c06AI\u80fd\u529b\u4e0e\u4f01\u4e1a\u8f6f\u4ef6\u5f00\u53d1\u73b0\u5b9e\u5bf9\u9f50\uff0c\u901a\u8fc7\u6df7\u5408\u77e5\u8bc6\u8868\u793a\u548c\u591a\u9636\u6bb5\u63d0\u53d6\u7ba1\u9053\uff0c\u5c06\u788e\u7247\u5316\u77e5\u8bc6\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u663e\u5f0f\u8868\u793a\u3002", "motivation": "\u4f01\u4e1a\u8f6f\u4ef6\u5f00\u53d1\u4e3b\u8981\u4f9d\u8d56\u589e\u91cf\u6f14\u8fdb\uff0c\u9762\u4e34\u8d85\u8d8a\u5e38\u89c4\u7f16\u7801\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u9690\u6027\u77e5\u8bc6\uff08\u5982\u8bbe\u8ba1\u51b3\u7b56\u548c\u5386\u53f2\u6743\u8861\uff09\u7684\u7f3a\u5931\u3002\u73b0\u6709LLM\u80fd\u529b\u9700\u8981\u4e0e\u590d\u6742\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\u5bf9\u9f50\u3002", "method": "\u63d0\u51faCode Digital Twin\u6846\u67b6\uff0c\u5305\u542b\uff1a\u6df7\u5408\u77e5\u8bc6\u8868\u793a\u3001\u591a\u9636\u6bb5\u63d0\u53d6\u7ba1\u9053\u3001\u589e\u91cf\u66f4\u65b0\u3001LLM\u8d4b\u80fd\u5e94\u7528\u548c\u4eba\u673a\u534f\u540c\u53cd\u9988\uff0c\u5171\u540c\u5efa\u6a21\u8f6f\u4ef6\u7684\u7269\u7406\u548c\u6982\u5ff5\u5c42\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u4fdd\u5b58\u9690\u6027\u77e5\u8bc6\uff0c\u4e0e\u4ee3\u7801\u5e93\u5171\u540c\u6f14\u8fdb\uff0c\u5c06\u788e\u7247\u5316\u77e5\u8bc6\u8f6c\u5316\u4e3a\u663e\u5f0f\u53ef\u64cd\u4f5c\u8868\u793a\uff0c\u4e3a\u8d85\u590d\u6742\u7cfb\u7edf\u7684\u53ef\u6301\u7eed\u667a\u80fd\u5f00\u53d1\u63d0\u4f9b\u5177\u4f53\u8def\u7ebf\u56fe\u3002", "conclusion": "Code Digital Twin\u5728AI\u8fdb\u6b65\u4e0e\u4f01\u4e1a\u8f6f\u4ef6\u73b0\u5b9e\u4e4b\u95f4\u67b6\u8d77\u6865\u6881\uff0c\u4e3a\u5b9e\u73b0\u53ef\u6301\u7eed\u3001\u667a\u80fd\u548c\u5f39\u6027\u7684\u8d85\u590d\u6742\u7cfb\u7edf\u5f00\u53d1\u548c\u6f14\u8fdb\u63d0\u4f9b\u4e86\u5177\u4f53\u8def\u5f84\u3002"}}
{"id": "2510.15952", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15952", "abs": "https://arxiv.org/abs/2510.15952", "authors": ["Myung Ho Kim"], "title": "Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding", "comment": "27 pages", "summary": "Large language models exhibit intelligence without genuine epistemic\nunderstanding, exposing a key gap: the absence of epistemic architecture. This\npaper introduces the Structured Cognitive Loop (SCL) as an executable\nepistemological framework for emergent intelligence. Unlike traditional AI\nresearch asking \"what is intelligence?\" (ontological), SCL asks \"under what\nconditions does cognition emerge?\" (epistemological). Grounded in philosophy of\nmind and cognitive phenomenology, SCL bridges conceptual philosophy and\nimplementable cognition. Drawing on process philosophy, enactive cognition, and\nextended mind theory, we define intelligence not as a property but as a\nperformed process -- a continuous loop of judgment, memory, control, action,\nand regulation. SCL makes three contributions. First, it operationalizes\nphilosophical insights into computationally interpretable structures, enabling\n\"executable epistemology\" -- philosophy as structural experiment. Second, it\nshows that functional separation within cognitive architecture yields more\ncoherent and interpretable behavior than monolithic prompt based systems,\nsupported by agent evaluations. Third, it redefines intelligence: not\nrepresentational accuracy but the capacity to reconstruct its own epistemic\nstate through intentional understanding. This framework impacts philosophy of\nmind, epistemology, and AI. For philosophy, it allows theories of cognition to\nbe enacted and tested. For AI, it grounds behavior in epistemic structure\nrather than statistical regularity. For epistemology, it frames knowledge not\nas truth possession but as continuous reconstruction within a\nphenomenologically coherent loop. We situate SCL within debates on cognitive\nphenomenology, emergence, normativity, and intentionality, arguing that real\nprogress requires not larger models but architectures that realize cognitive\nprinciples structurally.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u8ba4\u77e5\u5faa\u73af(SCL)\u4f5c\u4e3a\u53ef\u6267\u884c\u7684\u8ba4\u77e5\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u771f\u6b63\u8ba4\u77e5\u7ed3\u6784\u7684\u95ee\u9898\u3002SCL\u5c06\u54f2\u5b66\u89c1\u89e3\u8f6c\u5316\u4e3a\u53ef\u8ba1\u7b97\u7ed3\u6784\uff0c\u5f3a\u8c03\u8ba4\u77e5\u662f\u4e00\u4e2a\u7531\u5224\u65ad\u3001\u8bb0\u5fc6\u3001\u63a7\u5236\u3001\u884c\u52a8\u548c\u8c03\u8282\u7ec4\u6210\u7684\u6301\u7eed\u5faa\u73af\u8fc7\u7a0b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u667a\u80fd\u4f46\u7f3a\u4e4f\u771f\u6b63\u7684\u8ba4\u77e5\u7406\u89e3\uff0c\u66b4\u9732\u4e86\u8ba4\u77e5\u67b6\u6784\u7684\u7f3a\u5931\u3002\u4f20\u7edfAI\u7814\u7a76\u5173\u6ce8\"\u4ec0\u4e48\u662f\u667a\u80fd\"\u7684\u672c\u4f53\u8bba\u95ee\u9898\uff0c\u800cSCL\u5173\u6ce8\"\u5728\u4ec0\u4e48\u6761\u4ef6\u4e0b\u8ba4\u77e5\u4f1a\u51fa\u73b0\"\u7684\u8ba4\u77e5\u8bba\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5fc3\u667a\u54f2\u5b66\u548c\u8ba4\u77e5\u73b0\u8c61\u5b66\uff0c\u7ed3\u5408\u8fc7\u7a0b\u54f2\u5b66\u3001\u5177\u8eab\u8ba4\u77e5\u548c\u6269\u5c55\u5fc3\u667a\u7406\u8bba\uff0c\u5c06\u667a\u80fd\u5b9a\u4e49\u4e3a\u6267\u884c\u8fc7\u7a0b\u800c\u975e\u5c5e\u6027\u3002\u901a\u8fc7\u529f\u80fd\u5206\u79bb\u7684\u8ba4\u77e5\u67b6\u6784\u5b9e\u73b0\"\u53ef\u6267\u884c\u8ba4\u77e5\u8bba\"\u3002", "result": "SCL\u5c55\u793a\u4e86\u529f\u80fd\u5206\u79bb\u7684\u8ba4\u77e5\u67b6\u6784\u6bd4\u5355\u4e00\u63d0\u793a\u7cfb\u7edf\u4ea7\u751f\u66f4\u8fde\u8d2f\u548c\u53ef\u89e3\u91ca\u7684\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u667a\u80fd\u4f53\u8bc4\u4f30\u5f97\u5230\u652f\u6301\u3002", "conclusion": "SCL\u91cd\u65b0\u5b9a\u4e49\u667a\u80fd\u4e0d\u662f\u8868\u5f81\u51c6\u786e\u6027\uff0c\u800c\u662f\u901a\u8fc7\u610f\u5411\u6027\u7406\u89e3\u91cd\u5efa\u81ea\u8eab\u8ba4\u77e5\u72b6\u6001\u7684\u80fd\u529b\u3002\u8be5\u6846\u67b6\u5bf9\u5fc3\u667a\u54f2\u5b66\u3001\u8ba4\u77e5\u8bba\u548cAI\u9886\u57df\u90fd\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5f3a\u8c03\u771f\u6b63\u7684\u8fdb\u6b65\u9700\u8981\u5b9e\u73b0\u8ba4\u77e5\u539f\u5219\u7684\u7ed3\u6784\u5316\u67b6\u6784\u800c\u975e\u66f4\u5927\u7684\u6a21\u578b\u3002"}}
{"id": "2510.15971", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15971", "abs": "https://arxiv.org/abs/2510.15971", "authors": ["Md. Ifthekhar Hossain", "Kazi Abdullah Al Arafat", "Bryce Shepard", "Kayd Craig", "Imtiaz Parvez"], "title": "A Graph-Attentive LSTM Model for Malicious URL Detection", "comment": "Planned to be submitted", "summary": "Malicious URLs pose significant security risks as they facilitate phishing\nattacks, distribute malware, and empower attackers to deface websites.\nBlacklist detection methods fail to identify new or obfuscated URLs because\nthey depend on pre-existing patterns. This work presents a hybrid deep learning\nmodel named GNN-GAT-LSTM that combines Graph Neural Networks (GNNs) with Graph\nAttention Networks (GATs) and Long Short-Term Memory (LSTM) networks. The\nproposed architecture extracts both the structural and sequential patterns of\nthe features from data. The model transforms URLs into graphs through a process\nwhere characters become nodes that connect through edges. It applies one-hot\nencoding to represent node features. The model received training and testing\ndata from a collection of 651,191 URLs, which were classified into benign,\nphishing, defacement, and malware categories. The preprocessing stage included\nboth feature engineering and data balancing techniques, which addressed the\nclass imbalance issue to enhance model learning. The GNN-GAT-LSTM model\nachieved outstanding performance through its test accuracy of 0.9806 and its\nweighted F1-score of 0.9804. It showed excellent precision and recall\nperformance across most classes, particularly for benign and defacement URLs.\nOverall, the model provides an efficient and scalable system for detecting\nmalicious URLs while demonstrating strong potential for real-world\ncybersecurity applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGNN-GAT-LSTM\u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u548cLSTM\u7f51\u7edc\uff0c\u7528\u4e8e\u6076\u610fURL\u68c0\u6d4b\uff0c\u5728651,191\u4e2aURL\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e8698.06%\u7684\u51c6\u786e\u7387\u548c98.04%\u7684F1\u5206\u6570\u3002", "motivation": "\u6076\u610fURL\u5e26\u6765\u4e25\u91cd\u5b89\u5168\u98ce\u9669\uff0c\u5305\u62ec\u7f51\u7edc\u9493\u9c7c\u3001\u6076\u610f\u8f6f\u4ef6\u5206\u53d1\u548c\u7f51\u7ad9\u7be1\u6539\u3002\u4f20\u7edf\u9ed1\u540d\u5355\u68c0\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u8bc6\u522b\u65b0\u7684\u6216\u6df7\u6dc6\u7684URL\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u9884\u5148\u5b58\u5728\u7684\u6a21\u5f0f\u3002", "method": "\u5c06URL\u8f6c\u6362\u4e3a\u56fe\u7ed3\u6784\uff0c\u5b57\u7b26\u4f5c\u4e3a\u8282\u70b9\u901a\u8fc7\u8fb9\u8fde\u63a5\uff0c\u4f7f\u7528one-hot\u7f16\u7801\u8868\u793a\u8282\u70b9\u7279\u5f81\u3002\u7ed3\u5408GNN\u3001GAT\u548cLSTM\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\u7684\u7ed3\u6784\u548c\u5e8f\u5217\u6a21\u5f0f\uff0c\u91c7\u7528\u7279\u5f81\u5de5\u7a0b\u548c\u6570\u636e\u5e73\u8861\u6280\u672f\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u52300.9806\u7684\u51c6\u786e\u7387\u548c0.9804\u7684\u52a0\u6743F1\u5206\u6570\uff0c\u5728\u826f\u6027URL\u548c\u7be1\u6539URL\u7c7b\u522b\u4e0a\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u6076\u610fURL\u68c0\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u7cfb\u7edf\uff0c\u5728\u73b0\u5b9e\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u6f5c\u529b\u3002"}}
{"id": "2510.16433", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.16433", "abs": "https://arxiv.org/abs/2510.16433", "authors": ["Tatsuya Shirai", "Olivier Nourry", "Yutaro Kashiwa", "Kenji Fujiwara", "Yasutaka Kamei", "Hajimu Iida"], "title": "Large-Scale Empirical Analysis of Continuous Fuzzing: Insights from 1 Million Fuzzing Sessions", "comment": null, "summary": "Software vulnerabilities are constantly being reported and exploited in\nsoftware products, causing significant impacts on society. In recent years, the\nmain approach to vulnerability detection, fuzzing, has been integrated into the\ncontinuous integration process to run in short and frequent cycles. This\ncontinuous fuzzing allows for fast identification and remediation of\nvulnerabilities during the development process. Despite adoption by thousands\nof projects, however, it is unclear how continuous fuzzing contributes to\nvulnerability detection. This study aims to elucidate the role of continuous\nfuzzing in vulnerability detection. Specifically, we investigate the coverage\nand the total number of fuzzing sessions when fuzzing bugs are discovered. We\ncollect issue reports, coverage reports, and fuzzing logs from OSS-Fuzz, an\nonline service provided by Google that performs fuzzing during continuous\nintegration. Through an empirical study of a total of approximately 1.12\nmillion fuzzing sessions from 878 projects participating in OSS-Fuzz, we reveal\nthat (i) a substantial number of fuzzing bugs exist prior to the integration of\ncontinuous fuzzing, leading to a high detection rate in the early stages; (ii)\ncode coverage continues to increase as continuous fuzzing progresses; and (iii)\nchanges in coverage contribute to the detection of fuzzing bugs. This study\nprovides empirical insights into how continuous fuzzing contributes to fuzzing\nbug detection, offering practical implications for future strategies and tool\ndevelopment in continuous fuzzing.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790OSS-Fuzz\u5e73\u53f0\u7684112\u4e07\u6b21\u6a21\u7cca\u6d4b\u8bd5\u4f1a\u8bdd\uff0c\u63ed\u793a\u4e86\u6301\u7eed\u6a21\u7cca\u6d4b\u8bd5\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u4f5c\u7528\uff1a\u65e9\u671f\u9636\u6bb5\u68c0\u6d4b\u7387\u9ad8\u3001\u4ee3\u7801\u8986\u76d6\u7387\u6301\u7eed\u589e\u957f\u3001\u8986\u76d6\u7387\u53d8\u5316\u6709\u52a9\u4e8e\u6f0f\u6d1e\u53d1\u73b0\u3002", "motivation": "\u5c3d\u7ba1\u6301\u7eed\u6a21\u7cca\u6d4b\u8bd5\u5df2\u88ab\u6570\u5343\u4e2a\u9879\u76ee\u91c7\u7528\uff0c\u4f46\u5176\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u5b9e\u9645\u8d21\u732e\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u7814\u7a76\u65e8\u5728\u9610\u660e\u6301\u7eed\u6a21\u7cca\u6d4b\u8bd5\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u5177\u4f53\u4f5c\u7528\u3002", "method": "\u6536\u96c6OSS-Fuzz\u7684\u95ee\u9898\u62a5\u544a\u3001\u8986\u76d6\u7387\u62a5\u544a\u548c\u6a21\u7cca\u6d4b\u8bd5\u65e5\u5fd7\uff0c\u5bf9878\u4e2a\u9879\u76ee\u7684\u7ea6112\u4e07\u6b21\u6a21\u7cca\u6d4b\u8bd5\u4f1a\u8bdd\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u53d1\u73b0\uff1a(i)\u5927\u91cf\u6a21\u7cca\u6d4b\u8bd5\u6f0f\u6d1e\u5728\u96c6\u6210\u6301\u7eed\u6a21\u7cca\u6d4b\u8bd5\u524d\u5df2\u5b58\u5728\uff0c\u5bfc\u81f4\u65e9\u671f\u68c0\u6d4b\u7387\u9ad8\uff1b(ii)\u968f\u7740\u6301\u7eed\u6a21\u7cca\u6d4b\u8bd5\u8fdb\u884c\uff0c\u4ee3\u7801\u8986\u76d6\u7387\u6301\u7eed\u589e\u52a0\uff1b(iii)\u8986\u76d6\u7387\u53d8\u5316\u6709\u52a9\u4e8e\u6a21\u7cca\u6d4b\u8bd5\u6f0f\u6d1e\u7684\u68c0\u6d4b\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u6301\u7eed\u6a21\u7cca\u6d4b\u8bd5\u5982\u4f55\u4fc3\u8fdb\u6f0f\u6d1e\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u89c1\u89e3\uff0c\u5bf9\u672a\u6765\u7684\u6301\u7eed\u6a21\u7cca\u6d4b\u8bd5\u7b56\u7565\u548c\u5de5\u5177\u5f00\u53d1\u5177\u6709\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2510.15959", "categories": ["cs.AI", "cs.CY", "cs.ET", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.15959", "abs": "https://arxiv.org/abs/2510.15959", "authors": ["Isabelle Hupont", "Marisa Ponti", "Sven Schade"], "title": "Exploring the Potential of Citiverses for Regulatory Learning", "comment": "26 pages", "summary": "Citiverses hold the potential to support regulatory learning by offering\nimmersive, virtual environments for experimenting with policy scenarios and\ntechnologies. This paper proposes a science-for-policy agenda to explore the\npotential of citiverses as experimentation spaces for regulatory learning,\ngrounded in a consultation with a high-level panel of experts, including\npolicymakers from the European Commission, national government science advisers\nand leading researchers in digital regulation and virtual worlds. It identifies\nkey research areas, including scalability, real-time feedback, complexity\nmodelling, cross-border collaboration, risk reduction, citizen participation,\nethical considerations and the integration of emerging technologies. In\naddition, the paper analyses a set of experimental topics, spanning\ntransportation, urban planning and the environment/climate crisis, that could\nbe tested in citiverse platforms to advance regulatory learning in these areas.\nThe proposed work is designed to inform future research for policy and\nemphasizes a responsible approach to developing and using citiverses. It\nprioritizes careful consideration of the ethical, economic, ecological and\nsocial dimensions of different regulations. The paper also explores essential\npreliminary steps necessary for integrating citiverses into the broader\necosystems of experimentation spaces, including test beds, living labs and\nregulatory sandboxes", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u79d1\u5b66\u653f\u7b56\u8bae\u7a0b\uff0c\u63a2\u7d22citiverses\u4f5c\u4e3a\u76d1\u7ba1\u5b66\u4e60\u5b9e\u9a8c\u7a7a\u95f4\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u4e13\u5bb6\u54a8\u8be2\u8bc6\u522b\u5173\u952e\u7814\u7a76\u9886\u57df\u548c\u5b9e\u9a8c\u4e3b\u9898\uff0c\u5f3a\u8c03\u8d1f\u8d23\u4efb\u7684\u53d1\u5c55\u65b9\u6cd5\u3002", "motivation": "\u5229\u7528citiverses\u7684\u6c89\u6d78\u5f0f\u865a\u62df\u73af\u5883\u6765\u652f\u6301\u76d1\u7ba1\u5b66\u4e60\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u5b9e\u9a8c\u7a7a\u95f4\uff0c\u6d4b\u8bd5\u4e0d\u540c\u653f\u7b56\u573a\u666f\u548c\u6280\u672f\u3002", "method": "\u57fa\u4e8e\u4e0e\u6b27\u76df\u59d4\u5458\u4f1a\u653f\u7b56\u5236\u5b9a\u8005\u3001\u56fd\u5bb6\u653f\u5e9c\u79d1\u5b66\u987e\u95ee\u548c\u6570\u5b57\u76d1\u7ba1\u9886\u57df\u9876\u5c16\u7814\u7a76\u8005\u7684\u9ad8\u5c42\u4e13\u5bb6\u5c0f\u7ec4\u54a8\u8be2\uff0c\u8bc6\u522b\u5173\u952e\u7814\u7a76\u9886\u57df\u548c\u5b9e\u9a8c\u4e3b\u9898\u3002", "result": "\u786e\u5b9a\u4e86\u5305\u62ec\u53ef\u6269\u5c55\u6027\u3001\u5b9e\u65f6\u53cd\u9988\u3001\u590d\u6742\u6027\u5efa\u6a21\u3001\u8de8\u5883\u5408\u4f5c\u7b49\u5173\u952e\u7814\u7a76\u9886\u57df\uff0c\u4ee5\u53ca\u4ea4\u901a\u3001\u57ce\u5e02\u89c4\u5212\u3001\u73af\u5883/\u6c14\u5019\u5371\u673a\u7b49\u5b9e\u9a8c\u4e3b\u9898\u3002", "conclusion": "citiverses\u6709\u6f5c\u529b\u6210\u4e3a\u76d1\u7ba1\u5b66\u4e60\u7684\u91cd\u8981\u5b9e\u9a8c\u7a7a\u95f4\uff0c\u4f46\u9700\u8981\u8d1f\u8d23\u4efb\u7684\u53d1\u5c55\u65b9\u6cd5\uff0c\u5145\u5206\u8003\u8651\u4f26\u7406\u3001\u7ecf\u6d4e\u3001\u751f\u6001\u548c\u793e\u4f1a\u7ef4\u5ea6\u3002"}}
{"id": "2510.15973", "categories": ["cs.CR", "cs.AI", "cs.CY", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.15973", "abs": "https://arxiv.org/abs/2510.15973", "authors": ["Tiarnaigh Downey-Webb", "Olamide Jogunola", "Oluwaseun Ajao"], "title": "Safeguarding Efficacy in Large Language Models: Evaluating Resistance to Human-Written and Algorithmic Adversarial Prompts", "comment": "10 pages, 4 pages manuscript submitted to the Language Resources and\n  Evaluation Conference (LREC 2026)", "summary": "This paper presents a systematic security assessment of four prominent Large\nLanguage Models (LLMs) against diverse adversarial attack vectors. We evaluate\nPhi-2, Llama-2-7B-Chat, GPT-3.5-Turbo, and GPT-4 across four distinct attack\ncategories: human-written prompts, AutoDAN, Greedy Coordinate Gradient (GCG),\nand Tree-of-Attacks-with-pruning (TAP). Our comprehensive evaluation employs\n1,200 carefully stratified prompts from the SALAD-Bench dataset, spanning six\nharm categories. Results demonstrate significant variations in model\nrobustness, with Llama-2 achieving the highest overall security (3.4% average\nattack success rate) while Phi-2 exhibits the greatest vulnerability (7.0%\naverage attack success rate). We identify critical transferability patterns\nwhere GCG and TAP attacks, though ineffective against their target model\n(Llama-2), achieve substantially higher success rates when transferred to other\nmodels (up to 17% for GPT-4). Statistical analysis using Friedman tests reveals\nsignificant differences in vulnerability across harm categories ($p < 0.001$),\nwith malicious use prompts showing the highest attack success rates (10.71%\naverage). Our findings contribute to understanding cross-model security\nvulnerabilities and provide actionable insights for developing targeted defense\nmechanisms", "AI": {"tldr": "\u5bf9\u56db\u4e2a\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6027\u5b89\u5168\u8bc4\u4f30\uff0c\u53d1\u73b0Llama-2\u5b89\u5168\u6027\u6700\u9ad8\uff0cPhi-2\u6700\u8106\u5f31\uff0c\u653b\u51fb\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u5b58\u5728\u663e\u8457\u53ef\u8fc1\u79fb\u6027\u3002", "motivation": "\u8bc4\u4f30\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6297\u591a\u6837\u5316\u5bf9\u6297\u653b\u51fb\u7684\u5b89\u5168\u6027\uff0c\u8bc6\u522b\u8de8\u6a21\u578b\u5b89\u5168\u6f0f\u6d1e\u6a21\u5f0f\u3002", "method": "\u4f7f\u7528SALAD-Bench\u6570\u636e\u96c6\u76841200\u4e2a\u5206\u5c42\u63d0\u793a\uff0c\u6d4b\u8bd5\u56db\u79cd\u653b\u51fb\u65b9\u6cd5\uff1a\u4eba\u5de5\u7f16\u5199\u63d0\u793a\u3001AutoDAN\u3001GCG\u548cTAP\uff0c\u8bc4\u4f30\u516d\u4e2a\u5371\u5bb3\u7c7b\u522b\u3002", "result": "Llama-2\u6574\u4f53\u5b89\u5168\u6027\u6700\u9ad8\uff08\u5e73\u5747\u653b\u51fb\u6210\u529f\u73873.4%\uff09\uff0cPhi-2\u6700\u8106\u5f31\uff087.0%\uff09\u3002GCG\u548cTAP\u653b\u51fb\u5728\u6a21\u578b\u95f4\u53ef\u8fc1\u79fb\u6027\u5f3a\uff0c\u5bf9GPT-4\u6210\u529f\u7387\u9ad8\u8fbe17%\u3002\u6076\u610f\u4f7f\u7528\u63d0\u793a\u653b\u51fb\u6210\u529f\u7387\u6700\u9ad8\uff0810.71%\uff09\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u653b\u51fb\u5177\u6709\u8de8\u6a21\u578b\u53ef\u8fc1\u79fb\u6027\uff0c\u9700\u8981\u9488\u5bf9\u6027\u7684\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2510.16502", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.16502", "abs": "https://arxiv.org/abs/2510.16502", "authors": ["Sebasti\u00e1n Pizard", "Ramiro Moreira", "Federico Galiano", "Ignacio Sastre", "Lorena Etcheverry"], "title": "On the Use of Large Language Models for Qualitative Synthesis", "comment": null, "summary": "Large language models (LLMs) show promise for supporting systematic reviews\n(SR), even complex tasks such as qualitative synthesis (QS). However, applying\nthem to a stage that is unevenly reported and variably conducted carries\nimportant risks: misuse can amplify existing weaknesses and erode confidence in\nthe SR findings. To examine the challenges of using LLMs for QS, we conducted a\ncollaborative autoethnography involving two trials. We evaluated each trial for\nmethodological rigor and practical usefulness, and interpreted the results\nthrough a technical lens informed by how LLMs are built and their current\nlimitations.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u7cfb\u7edf\u8bc4\u4ef7\u7684\u5b9a\u6027\u7efc\u5408\u9636\u6bb5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6311\u6218\uff0c\u901a\u8fc7\u534f\u4f5c\u81ea\u4f20\u6c11\u65cf\u5fd7\u65b9\u6cd5\u8bc4\u4f30\u4e86LLM\u5728\u6b64\u8fc7\u7a0b\u4e2d\u7684\u65b9\u6cd5\u8bba\u4e25\u8c28\u6027\u548c\u5b9e\u9645\u6709\u7528\u6027\u3002", "motivation": "\u867d\u7136LLM\u5728\u652f\u6301\u7cfb\u7edf\u8bc4\u4ef7\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u62a5\u544a\u4e0d\u4e00\u81f4\u3001\u6267\u884c\u591a\u53d8\u7684\u5b9a\u6027\u7efc\u5408\u9636\u6bb5\u5e94\u7528LLM\u5b58\u5728\u91cd\u8981\u98ce\u9669\uff0c\u53ef\u80fd\u653e\u5927\u73b0\u6709\u5f31\u70b9\u5e76\u524a\u5f31\u7cfb\u7edf\u8bc4\u4ef7\u7ed3\u679c\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u91c7\u7528\u534f\u4f5c\u81ea\u4f20\u6c11\u65cf\u5fd7\u65b9\u6cd5\uff0c\u8fdb\u884c\u4e86\u4e24\u9879\u8bd5\u9a8c\uff0c\u4ece\u65b9\u6cd5\u8bba\u4e25\u8c28\u6027\u548c\u5b9e\u9645\u6709\u7528\u6027\u89d2\u5ea6\u8bc4\u4f30LLM\u5728\u5b9a\u6027\u7efc\u5408\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u901a\u8fc7\u6280\u672f\u89c6\u89d2\u89e3\u91ca\u7ed3\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4f7f\u7528LLM\u8fdb\u884c\u5b9a\u6027\u7efc\u5408\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u4ed4\u7ec6\u8003\u8651\u5176\u6280\u672f\u5c40\u9650\u6027\u548c\u5bf9\u7cfb\u7edf\u8bc4\u4ef7\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "conclusion": "\u5728\u7cfb\u7edf\u8bc4\u4ef7\u7684\u5b9a\u6027\u7efc\u5408\u9636\u6bb5\u5e94\u7528LLM\u9700\u8981\u8c28\u614e\uff0c\u5fc5\u987b\u7406\u89e3\u5176\u6280\u672f\u5c40\u9650\u6027\uff0c\u4ee5\u907f\u514d\u653e\u5927\u73b0\u6709\u5f31\u70b9\u5e76\u786e\u4fdd\u7814\u7a76\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.15966", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15966", "abs": "https://arxiv.org/abs/2510.15966", "authors": ["Shian Jia", "Ziyang Huang", "Xinbo Wang", "Haofei Zhang", "Mingli Song"], "title": "PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency", "comment": null, "summary": "Memory systems are fundamental to AI agents, yet existing work often lacks\nadaptability to diverse tasks and overlooks the constructive and task-oriented\nrole of AI agent memory. Drawing from Piaget's theory of cognitive development,\nwe propose PISA, a pragmatic, psych-inspired unified memory system that\naddresses these limitations by treating memory as a constructive and adaptive\nprocess. To enable continuous learning and adaptability, PISA introduces a\ntrimodal adaptation mechanism (i.e., schema updation, schema evolution, and\nschema creation) that preserves coherent organization while supporting flexible\nmemory updates. Building on these schema-grounded structures, we further design\na hybrid memory access architecture that seamlessly integrates symbolic\nreasoning with neural retrieval, significantly improving retrieval accuracy and\nefficiency. Our empirical evaluation, conducted on the existing LOCOMO\nbenchmark and our newly proposed AggQA benchmark for data analysis tasks,\nconfirms that PISA sets a new state-of-the-art by significantly enhancing\nadaptability and long-term knowledge retention.", "AI": {"tldr": "PISA\u662f\u4e00\u4e2a\u53d7\u76ae\u4e9a\u6770\u8ba4\u77e5\u53d1\u5c55\u7406\u8bba\u542f\u53d1\u7684\u7edf\u4e00\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e09\u6a21\u6001\u9002\u5e94\u673a\u5236\u548c\u6df7\u5408\u8bb0\u5fc6\u8bbf\u95ee\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86AI\u4ee3\u7406\u7684\u9002\u5e94\u6027\u548c\u957f\u671f\u77e5\u8bc6\u4fdd\u7559\u80fd\u529b\u3002", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u591a\u6837\u5316\u4efb\u52a1\u7684\u9002\u5e94\u6027\uff0c\u4e14\u5ffd\u89c6\u4e86\u8bb0\u5fc6\u7684\u5efa\u6784\u6027\u548c\u4efb\u52a1\u5bfc\u5411\u4f5c\u7528\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u8bb0\u5fc6\u66f4\u65b0\u673a\u5236\u3002", "method": "\u63d0\u51faPISA\u7cfb\u7edf\uff1a1\uff09\u4e09\u6a21\u6001\u9002\u5e94\u673a\u5236\uff08\u56fe\u5f0f\u66f4\u65b0\u3001\u56fe\u5f0f\u6f14\u5316\u548c\u56fe\u5f0f\u521b\u5efa\uff09\uff1b2\uff09\u57fa\u4e8e\u56fe\u5f0f\u7ed3\u6784\u7684\u6df7\u5408\u8bb0\u5fc6\u8bbf\u95ee\u67b6\u6784\uff0c\u7ed3\u5408\u7b26\u53f7\u63a8\u7406\u548c\u795e\u7ecf\u68c0\u7d22\u3002", "result": "\u5728LOCOMO\u57fa\u51c6\u548c\u65b0\u63d0\u51fa\u7684AggQA\u6570\u636e\u5206\u6790\u57fa\u51c6\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cPISA\u5728\u9002\u5e94\u6027\u548c\u957f\u671f\u77e5\u8bc6\u4fdd\u7559\u65b9\u9762\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "PISA\u901a\u8fc7\u5c06\u8bb0\u5fc6\u89c6\u4e3a\u5efa\u6784\u6027\u548c\u9002\u5e94\u6027\u8fc7\u7a0b\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u8bb0\u5fc6\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u6709\u6548\u7684\u8bb0\u5fc6\u7ba1\u7406\u80fd\u529b\u3002"}}
{"id": "2510.15975", "categories": ["cs.CR", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2510.15975", "abs": "https://arxiv.org/abs/2510.15975", "authors": ["Zaixi Zhang", "Souradip Chakraborty", "Amrit Singh Bedi", "Emilin Mathew", "Varsha Saravanan", "Le Cong", "Alvaro Velasquez", "Sheng Lin-Gibson", "Megan Blewett", "Dan Hendrycs", "Alex John London", "Ellen Zhong", "Ben Raphael", "Jian Ma", "Eric Xing", "Russ Altman", "George Church", "Mengdi Wang"], "title": "Generative AI for Biosciences: Emerging Threats and Roadmap to Biosecurity", "comment": null, "summary": "The rapid adoption of generative artificial intelligence (GenAI) in the\nbiosciences is transforming biotechnology, medicine, and synthetic biology. Yet\nthis advancement is intrinsically linked to new vulnerabilities, as GenAI\nlowers the barrier to misuse and introduces novel biosecurity threats, such as\ngenerating synthetic viral proteins or toxins. These dual-use risks are often\noverlooked, as existing safety guardrails remain fragile and can be\ncircumvented through deceptive prompts or jailbreak techniques. In this\nPerspective, we first outline the current state of GenAI in the biosciences and\nemerging threat vectors ranging from jailbreak attacks and privacy risks to the\ndual-use challenges posed by autonomous AI agents. We then examine urgent gaps\nin regulation and oversight, drawing on insights from 130 expert interviews\nacross academia, government, industry, and policy. A large majority ($\\approx\n76$\\%) expressed concern over AI misuse in biology, and 74\\% called for the\ndevelopment of new governance frameworks. Finally, we explore technical\npathways to mitigation, advocating a multi-layered approach to GenAI safety.\nThese defenses include rigorous data filtering, alignment with ethical\nprinciples during development, and real-time monitoring to block harmful\nrequests. Together, these strategies provide a blueprint for embedding security\nthroughout the GenAI lifecycle. As GenAI becomes integrated into the\nbiosciences, safeguarding this frontier requires an immediate commitment to\nboth adaptive governance and secure-by-design technologies.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u5728\u751f\u7269\u79d1\u5b66\u4e2d\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u65b0\u7684\u751f\u7269\u5b89\u5168\u5a01\u80c1\uff0c\u5305\u62ec\u5408\u6210\u75c5\u6bd2\u86cb\u767d\u6216\u6bd2\u7d20\u7684\u751f\u6210\u7b49\u53cc\u91cd\u7528\u9014\u98ce\u9669\u3002\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u8106\u5f31\uff0c\u53ef\u901a\u8fc7\u6b3a\u9a97\u6027\u63d0\u793a\u6216\u8d8a\u72f1\u6280\u672f\u7ed5\u8fc7\u3002\u4e13\u5bb6\u547c\u5401\u5236\u5b9a\u65b0\u7684\u6cbb\u7406\u6846\u67b6\u548c\u591a\u5c42\u6b21\u5b89\u5168\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u751f\u7269\u6280\u672f\u3001\u533b\u5b66\u548c\u5408\u6210\u751f\u7269\u5b66\u4e2d\u7684\u5feb\u901f\u5e94\u7528\u867d\u7136\u5e26\u6765\u4e86\u8fdb\u6b65\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u65b0\u7684\u8106\u5f31\u6027\u3002\u8fd9\u4e9b\u53cc\u91cd\u7528\u9014\u98ce\u9669\u5e38\u88ab\u5ffd\u89c6\uff0c\u73b0\u6709\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u8106\u5f31\u4e14\u6613\u88ab\u7ed5\u8fc7\uff0c\u9700\u8981\u7d27\u6025\u5173\u6ce8\u548c\u6cbb\u7406\u3002", "method": "\u901a\u8fc7130\u4f4d\u6765\u81ea\u5b66\u672f\u754c\u3001\u653f\u5e9c\u3001\u5de5\u4e1a\u548c\u653f\u7b56\u9886\u57df\u7684\u4e13\u5bb6\u8bbf\u8c08\uff0c\u5206\u6790\u751f\u6210\u5f0fAI\u5728\u751f\u7269\u79d1\u5b66\u4e2d\u7684\u73b0\u72b6\u3001\u65b0\u5174\u5a01\u80c1\u5411\u91cf\uff0c\u4ee5\u53ca\u76d1\u7ba1\u548c\u76d1\u7763\u65b9\u9762\u7684\u7d27\u8feb\u5dee\u8ddd\u3002", "result": "\u7ea676%\u7684\u4e13\u5bb6\u5bf9AI\u5728\u751f\u7269\u5b66\u4e2d\u7684\u6ee5\u7528\u8868\u793a\u62c5\u5fe7\uff0c74%\u547c\u5401\u5f00\u53d1\u65b0\u7684\u6cbb\u7406\u6846\u67b6\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u591a\u5c42\u6b21\u7684\u5b89\u5168\u9632\u5fa1\u7b56\u7565\uff0c\u5305\u62ec\u4e25\u683c\u7684\u6570\u636e\u8fc7\u6ee4\u3001\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u7684\u4f26\u7406\u5bf9\u9f50\u4ee5\u53ca\u5b9e\u65f6\u76d1\u63a7\u4ee5\u963b\u6b62\u6709\u5bb3\u8bf7\u6c42\u3002", "conclusion": "\u968f\u7740\u751f\u6210\u5f0fAI\u878d\u5165\u751f\u7269\u79d1\u5b66\uff0c\u4fdd\u62a4\u8fd9\u4e00\u524d\u6cbf\u9886\u57df\u9700\u8981\u7acb\u5373\u81f4\u529b\u4e8e\u9002\u5e94\u6027\u6cbb\u7406\u548c\u5b89\u5168\u8bbe\u8ba1\u6280\u672f\uff0c\u5728\u6574\u4e2a\u751f\u6210\u5f0fAI\u751f\u547d\u5468\u671f\u4e2d\u5d4c\u5165\u5b89\u5168\u6027\u3002"}}
{"id": "2510.16579", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.16579", "abs": "https://arxiv.org/abs/2510.16579", "authors": ["Wendk\u00fbuni C. Ou\u00e9draogo", "Yinghua Li", "Xueqi Dang", "Pawel Borsukiewicz", "Xin Zhou", "Anil Koyuncu", "Jacques Klein", "David Lo", "Tegawend\u00e9 F. Bissyand\u00e9"], "title": "Human-Aligned Code Readability Assessment with Large Language Models", "comment": null, "summary": "Code readability is crucial for software comprehension and maintenance, yet\ndifficult to assess at scale. Traditional static metrics often fail to capture\nthe subjective, context-sensitive nature of human judgments. Large Language\nModels (LLMs) offer a scalable alternative, but their behavior as readability\nevaluators remains underexplored. We introduce CoReEval, the first large-scale\nbenchmark for evaluating LLM-based code readability assessment, comprising over\n1.4 million model-snippet-prompt evaluations across 10 state of the art LLMs.\nThe benchmark spans 3 programming languages (Java, Python, CUDA), 2 code types\n(functional code and unit tests), 4 prompting strategies (ZSL, FSL, CoT, ToT),\n9 decoding settings, and developer-guided prompts tailored to junior and senior\npersonas. We compare LLM outputs against human annotations and a validated\nstatic model, analyzing numerical alignment (MAE, Pearson's, Spearman's) and\njustification quality (sentiment, aspect coverage, semantic clustering). Our\nfindings show that developer-guided prompting grounded in human-defined\nreadability dimensions improves alignment in structured contexts, enhances\nexplanation quality, and enables lightweight personalization through persona\nframing. However, increased score variability highlights trade-offs between\nalignment, stability, and interpretability. CoReEval provides a robust\nfoundation for prompt engineering, model alignment studies, and human in the\nloop evaluation, with applications in education, onboarding, and CI/CD\npipelines where LLMs can serve as explainable, adaptable reviewers.", "AI": {"tldr": "CoReEval\u662f\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u4ee3\u7801\u53ef\u8bfb\u6027\u8bc4\u4f30\u7684\u5927\u89c4\u6a21\u57fa\u51c6\uff0c\u5305\u542b140\u4e07\u6b21\u6a21\u578b-\u4ee3\u7801\u7247\u6bb5-\u63d0\u793a\u8bc4\u4f30\uff0c\u6db5\u76d610\u4e2aLLM\u30013\u79cd\u7f16\u7a0b\u8bed\u8a00\u30012\u79cd\u4ee3\u7801\u7c7b\u578b\u30014\u79cd\u63d0\u793a\u7b56\u7565\u548c9\u79cd\u89e3\u7801\u8bbe\u7f6e\uff0c\u53d1\u73b0\u57fa\u4e8e\u5f00\u53d1\u8005\u6307\u5bfc\u7684\u63d0\u793a\u80fd\u6539\u5584\u5bf9\u9f50\u5ea6\u548c\u89e3\u91ca\u8d28\u91cf\u3002", "motivation": "\u4ee3\u7801\u53ef\u8bfb\u6027\u5bf9\u8f6f\u4ef6\u7406\u89e3\u548c\u7ef4\u62a4\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u96be\u4ee5\u5927\u89c4\u6a21\u8bc4\u4f30\u3002\u4f20\u7edf\u9759\u6001\u6307\u6807\u65e0\u6cd5\u6355\u6349\u4eba\u7c7b\u5224\u65ad\u7684\u4e3b\u89c2\u6027\u548c\u4e0a\u4e0b\u6587\u654f\u611f\u6027\uff0c\u800cLLM\u4f5c\u4e3a\u53ef\u6269\u5c55\u66ff\u4ee3\u65b9\u6848\u7684\u884c\u4e3a\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u6784\u5efaCoReEval\u57fa\u51c6\uff0c\u5305\u542b140\u4e07\u6b21\u8bc4\u4f30\uff0c\u6db5\u76d610\u4e2aLLM\u30013\u79cd\u7f16\u7a0b\u8bed\u8a00(Java\u3001Python\u3001CUDA)\u30012\u79cd\u4ee3\u7801\u7c7b\u578b(\u529f\u80fd\u4ee3\u7801\u548c\u5355\u5143\u6d4b\u8bd5)\u30014\u79cd\u63d0\u793a\u7b56\u7565(ZSL\u3001FSL\u3001CoT\u3001ToT)\u30019\u79cd\u89e3\u7801\u8bbe\u7f6e\uff0c\u4ee5\u53ca\u9488\u5bf9\u521d\u7ea7\u548c\u9ad8\u7ea7\u5f00\u53d1\u8005\u7684\u4e2a\u6027\u5316\u63d0\u793a\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8e\u4eba\u7c7b\u5b9a\u4e49\u53ef\u8bfb\u6027\u7ef4\u5ea6\u7684\u5f00\u53d1\u8005\u6307\u5bfc\u63d0\u793a\u5728\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u4e2d\u6539\u5584\u4e86\u5bf9\u9f50\u5ea6\uff0c\u63d0\u9ad8\u4e86\u89e3\u91ca\u8d28\u91cf\uff0c\u5e76\u901a\u8fc7\u89d2\u8272\u6846\u67b6\u5b9e\u73b0\u4e86\u8f7b\u91cf\u7ea7\u4e2a\u6027\u5316\u3002\u4f46\u5f97\u5206\u53d8\u5f02\u6027\u589e\u52a0\uff0c\u663e\u793a\u4e86\u5bf9\u9f50\u5ea6\u3001\u7a33\u5b9a\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "CoReEval\u4e3a\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u5bf9\u9f50\u7814\u7a76\u548c\u4eba\u673a\u5faa\u73af\u8bc4\u4f30\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u53ef\u5e94\u7528\u4e8e\u6559\u80b2\u3001\u5165\u804c\u57f9\u8bad\u548cCI/CD\u6d41\u6c34\u7ebf\uff0c\u4f7fLLM\u80fd\u591f\u4f5c\u4e3a\u53ef\u89e3\u91ca\u3001\u9002\u5e94\u6027\u5f3a\u7684\u4ee3\u7801\u5ba1\u67e5\u8005\u3002"}}
{"id": "2510.15974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15974", "abs": "https://arxiv.org/abs/2510.15974", "authors": ["Chris Su", "Harrison Li", "Matheus Marques", "George Flint", "Kevin Zhu", "Sunishchal Dev"], "title": "Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games", "comment": null, "summary": "Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in\nperformance on solving puzzles beyond certain perplexity thresholds. In\nsubsequent discourse, questions have arisen as to whether the nature of the\ntask muddles an evaluation of true reasoning. One potential confound is the\nrequirement that the model keep track of the state space on its own. We provide\na large language model (LLM) with an environment interface for Tower of Hanoi\nproblems, allowing it to make a move with a tool call, provide written\njustification, observe the resulting state space, and reprompt itself for the\nnext move. We observe that access to an environment interface does not delay or\neradicate performance collapse. Furthermore, LLM-parameterized policy analysis\nreveals increasing divergence from both optimal policies and uniformly random\npolicies, suggesting that the model exhibits mode-like collapse at each level\nof complexity, and that performance is dependent upon whether the mode reflects\nthe correct solution for the problem. We suggest that a similar phenomena might\ntake place in LRMs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u89e3\u51b3\u8d85\u8fc7\u7279\u5b9a\u590d\u6742\u5ea6\u9608\u503c\u7684\u96be\u9898\u65f6\u4f1a\u51fa\u73b0\u6027\u80fd\u5d29\u6e83\uff0c\u5373\u4f7f\u63d0\u4f9b\u73af\u5883\u63a5\u53e3\u8ba9\u6a21\u578b\u8ddf\u8e2a\u72b6\u6001\u7a7a\u95f4\u4e5f\u65e0\u6cd5\u907f\u514d\u8fd9\u79cd\u5d29\u6e83\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u63a8\u7406\u6a21\u578b\u6027\u80fd\u5d29\u6e83\u7684\u771f\u6b63\u539f\u56e0\uff0c\u9a8c\u8bc1\u662f\u5426\u7531\u4e8e\u6a21\u578b\u9700\u8981\u81ea\u884c\u8ddf\u8e2a\u72b6\u6001\u7a7a\u95f4\u8fd9\u4e00\u8981\u6c42\u6df7\u6dc6\u4e86\u5bf9\u771f\u5b9e\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\u3002", "method": "\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u6c49\u8bfa\u5854\u95ee\u9898\u7684\u73af\u5883\u63a5\u53e3\uff0c\u5141\u8bb8\u6a21\u578b\u901a\u8fc7\u5de5\u5177\u8c03\u7528\u8fdb\u884c\u79fb\u52a8\u3001\u63d0\u4f9b\u4e66\u9762\u7406\u7531\u3001\u89c2\u5bdf\u7ed3\u679c\u72b6\u6001\u7a7a\u95f4\uff0c\u5e76\u91cd\u65b0\u63d0\u793a\u81ea\u5df1\u8fdb\u884c\u4e0b\u4e00\u6b65\u79fb\u52a8\u3002", "result": "\u73af\u5883\u63a5\u53e3\u7684\u8bbf\u95ee\u5e76\u4e0d\u80fd\u5ef6\u8fdf\u6216\u6d88\u9664\u6027\u80fd\u5d29\u6e83\u3002LLM\u53c2\u6570\u5316\u7b56\u7565\u5206\u6790\u663e\u793a\u6a21\u578b\u7b56\u7565\u4e0e\u6700\u4f18\u7b56\u7565\u548c\u5747\u5300\u968f\u673a\u7b56\u7565\u7684\u504f\u79bb\u5ea6\u4e0d\u65ad\u589e\u52a0\uff0c\u8868\u660e\u6a21\u578b\u5728\u6bcf\u4e2a\u590d\u6742\u5ea6\u7ea7\u522b\u90fd\u8868\u73b0\u51fa\u6a21\u5f0f\u5d29\u6e83\u3002", "conclusion": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\u4f1a\u51fa\u73b0\u6027\u80fd\u5d29\u6e83\uff0c\u8fd9\u79cd\u5d29\u6e83\u4e0e\u662f\u5426\u63d0\u4f9b\u73af\u5883\u63a5\u53e3\u65e0\u5173\uff0c\u800c\u662f\u7531\u4e8e\u6a21\u578b\u5728\u7279\u5b9a\u590d\u6742\u5ea6\u7ea7\u522b\u51fa\u73b0\u6a21\u5f0f\u5d29\u6e83\uff0c\u6027\u80fd\u53d6\u51b3\u4e8e\u8be5\u6a21\u5f0f\u662f\u5426\u53cd\u6620\u95ee\u9898\u7684\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.15976", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15976", "abs": "https://arxiv.org/abs/2510.15976", "authors": ["Chenrui Wang", "Junyi Shu", "Billy Chiu", "Yu Li", "Saleh Alharbi", "Min Zhang", "Jing Li"], "title": "Learning to Watermark: A Selective Watermarking Framework for Large Language Models via Multi-Objective Optimization", "comment": "28 pages, 11 figures, NeurIPS 2025 Poster", "summary": "The rapid development of LLMs has raised concerns about their potential\nmisuse, leading to various watermarking schemes that typically offer high\ndetectability. However, existing watermarking techniques often face trade-off\nbetween watermark detectability and generated text quality. In this paper, we\nintroduce Learning to Watermark (LTW), a novel selective watermarking framework\nthat leverages multi-objective optimization to effectively balance these\ncompeting goals. LTW features a lightweight network that adaptively decides\nwhen to apply the watermark by analyzing sentence embeddings, token entropy,\nand current watermarking ratio. Training of the network involves two\nspecifically constructed loss functions that guide the model toward\nPareto-optimal solutions, thereby harmonizing watermark detectability and text\nquality. By integrating LTW with two baseline watermarking methods, our\nexperimental evaluations demonstrate that LTW significantly enhances text\nquality without compromising detectability. Our selective watermarking approach\noffers a new perspective for designing watermarks for LLMs and a way to\npreserve high text quality for watermarks. The code is publicly available at:\nhttps://github.com/fattyray/learning-to-watermark", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLTW\u7684\u9009\u62e9\u6027\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u5e73\u8861\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u548c\u6587\u672c\u8d28\u91cf\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7f51\u7edc\u81ea\u9002\u5e94\u51b3\u5b9a\u4f55\u65f6\u5e94\u7528\u6c34\u5370\u3002", "motivation": "\u73b0\u6709LLM\u6c34\u5370\u6280\u672f\u5728\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u548c\u751f\u6210\u6587\u672c\u8d28\u91cf\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5e73\u8861\u8fd9\u4e24\u4e2a\u7ade\u4e89\u76ee\u6807\u7684\u65b9\u6cd5\u3002", "method": "LTW\u6846\u67b6\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7f51\u7edc\u5206\u6790\u53e5\u5b50\u5d4c\u5165\u3001\u4ee4\u724c\u71b5\u548c\u5f53\u524d\u6c34\u5370\u6bd4\u4f8b\u6765\u81ea\u9002\u5e94\u51b3\u5b9a\u4f55\u65f6\u5e94\u7528\u6c34\u5370\uff0c\u901a\u8fc7\u4e24\u4e2a\u4e13\u95e8\u6784\u5efa\u7684\u635f\u5931\u51fd\u6570\u8fdb\u884c\u591a\u76ee\u6807\u4f18\u5316\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cLTW\u4e0e\u4e24\u79cd\u57fa\u7ebf\u6c34\u5370\u65b9\u6cd5\u7ed3\u5408\u540e\uff0c\u5728\u4fdd\u6301\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u6587\u672c\u8d28\u91cf\u3002", "conclusion": "LTW\u4e3aLLM\u6c34\u5370\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u9ad8\u6587\u672c\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u6709\u6548\u6c34\u5370\u3002"}}
{"id": "2510.16665", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.16665", "abs": "https://arxiv.org/abs/2510.16665", "authors": ["Mohamed Sami Rakha", "Andriy Miranskyy", "Daniel Alencar da Costa"], "title": "Contrasting the Hyperparameter Tuning Impact Across Software Defect Prediction Scenarios", "comment": "Accepted to IEEE Transactions on Software Engineering", "summary": "Software defect prediction (SDP) is crucial for delivering high-quality\nsoftware products. Recent research has indicated that prediction performance\nimprovements in SDP are achievable by applying hyperparameter tuning to a\nparticular SDP scenario. However, the positive impact resulting from the\nhyperparameter tuning step may differ based on the targeted SDP scenario.\nComparing the impact of hyperparameter tuning across SDP scenarios is necessary\nto provide comprehensive insights and enhance the robustness, generalizability,\nand, eventually, the practicality of SDP modeling for quality assurance.\n  Therefore, in this study, we contrast the impact of hyperparameter tuning\nacross two pivotal and consecutive SDP scenarios: (1) Inner Version Defect\nPrediction (IVDP) and (2) Cross Version Defect Prediction (CVDP). The main\ndistinctions between the two scenarios lie in the scope of defect prediction\nand the selected evaluation setups. This study's experiments use common\nevaluation setups, 28 machine learning (ML) algorithms, 53 post-release\nsoftware datasets, two tuning algorithms, and five optimization metrics. We\napply statistical analytics to compare the SDP performance impact differences\nby investigating the overall impact, the single ML algorithm impact, and\nvariations across different software dataset sizes.\n  The results indicate that the SDP gains within the IVDP scenario are\nsignificantly larger than those within the CVDP scenario. The results reveal\nthat asserting performance gains for up to 24 out of 28 ML algorithms may not\nhold across multiple SDP scenarios. Furthermore, we found that small software\ndatasets are more susceptible to larger differences in performance impacts.\nOverall, the study findings recommend software engineering researchers and\npractitioners to consider the effect of the selected SDP scenario when\nexpecting performance gains from hyperparameter tuning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9\u6bd4\u4e86\u8d85\u53c2\u6570\u8c03\u4f18\u5728\u4e24\u79cd\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u573a\u666f\uff08IVDP\u548cCVDP\uff09\u4e2d\u7684\u5f71\u54cd\u5dee\u5f02\uff0c\u53d1\u73b0IVDP\u573a\u666f\u4e2d\u7684\u6027\u80fd\u63d0\u5347\u663e\u8457\u5927\u4e8eCVDP\u573a\u666f\uff0c\u4e14\u5c0f\u6570\u636e\u96c6\u66f4\u5bb9\u6613\u53d7\u5230\u6027\u80fd\u5f71\u54cd\u5dee\u5f02\u7684\u5f71\u54cd\u3002", "motivation": "\u867d\u7136\u8d85\u53c2\u6570\u8c03\u4f18\u53ef\u4ee5\u63d0\u5347\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u6027\u80fd\uff0c\u4f46\u5176\u5f71\u54cd\u7a0b\u5ea6\u53ef\u80fd\u56e0\u4e0d\u540c\u7684\u9884\u6d4b\u573a\u666f\u800c\u5f02\u3002\u4e3a\u4e86\u63d0\u4f9b\u5168\u9762\u89c1\u89e3\u5e76\u589e\u5f3aSDP\u5efa\u6a21\u7684\u7a33\u5065\u6027\u548c\u5b9e\u7528\u6027\uff0c\u9700\u8981\u6bd4\u8f83\u4e0d\u540cSDP\u573a\u666f\u4e2d\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u752828\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u300153\u4e2a\u8f6f\u4ef6\u6570\u636e\u96c6\u3001\u4e24\u79cd\u8c03\u4f18\u7b97\u6cd5\u548c\u4e94\u4e2a\u4f18\u5316\u6307\u6807\uff0c\u5728IVDP\u548cCVDP\u4e24\u79cd\u5173\u952eSDP\u573a\u666f\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u5e94\u7528\u7edf\u8ba1\u5206\u6790\u6765\u6bd4\u8f83\u6027\u80fd\u5f71\u54cd\u5dee\u5f02\u3002", "result": "IVDP\u573a\u666f\u4e2d\u7684SDP\u6027\u80fd\u589e\u76ca\u663e\u8457\u5927\u4e8eCVDP\u573a\u666f\uff1b28\u79cdML\u7b97\u6cd5\u4e2d\u670924\u79cd\u7684\u6027\u80fd\u589e\u76ca\u5728\u4e0d\u540cSDP\u573a\u666f\u4e2d\u53ef\u80fd\u4e0d\u6210\u7acb\uff1b\u5c0f\u8f6f\u4ef6\u6570\u636e\u96c6\u66f4\u5bb9\u6613\u51fa\u73b0\u8f83\u5927\u7684\u6027\u80fd\u5f71\u54cd\u5dee\u5f02\u3002", "conclusion": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u5728\u671f\u671b\u901a\u8fc7\u8d85\u53c2\u6570\u8c03\u4f18\u83b7\u5f97\u6027\u80fd\u589e\u76ca\u65f6\uff0c\u5e94\u8003\u8651\u6240\u9009SDP\u573a\u666f\u7684\u5f71\u54cd\u3002"}}
{"id": "2510.15980", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15980", "abs": "https://arxiv.org/abs/2510.15980", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition", "comment": null, "summary": "We propose \\textbf{Cognitive Load Traces} (CLTs) as a mid-level\ninterpretability framework for deep models, inspired by Cognitive Load Theory\nin human cognition. CLTs are defined as symbolic, temporally varying functions\nthat quantify model-internal resource allocation. Formally, we represent CLTs\nas a three-component stochastic process $(\\mathrm{IL}_t, \\mathrm{EL}_t,\n\\mathrm{GL}_t)$, corresponding to \\emph{Intrinsic}, \\emph{Extraneous}, and\n\\emph{Germane} load. Each component is instantiated through measurable proxies\nsuch as attention entropy, KV-cache miss ratio, representation dispersion, and\ndecoding stability. We propose both symbolic formulations and visualization\nmethods (load curves, simplex diagrams) that enable interpretable analysis of\nreasoning dynamics. Experiments on reasoning and planning benchmarks show that\nCLTs predict error-onset, reveal cognitive strategies, and enable load-guided\ninterventions that improve reasoning efficiency by 15-30\\% while maintaining\naccuracy.", "AI": {"tldr": "\u63d0\u51faCognitive Load Traces (CLTs)\u4f5c\u4e3a\u6df1\u5ea6\u6a21\u578b\u7684\u4e2d\u5c42\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u7b26\u53f7\u5316\u3001\u65f6\u53d8\u51fd\u6570\u91cf\u5316\u6a21\u578b\u5185\u90e8\u8d44\u6e90\u5206\u914d\uff0c\u5305\u542b\u5185\u5728\u3001\u5916\u5728\u548c\u5173\u8054\u8d1f\u8f7d\u4e09\u4e2a\u5206\u91cf\uff0c\u80fd\u591f\u9884\u6d4b\u9519\u8bef\u53d1\u751f\u3001\u63ed\u793a\u8ba4\u77e5\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u8d1f\u8f7d\u5f15\u5bfc\u5e72\u9884\u63d0\u9ad8\u63a8\u7406\u6548\u738715-30%\u3002", "motivation": "\u53d7\u4eba\u7c7b\u8ba4\u77e5\u4e2d\u7684\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\u542f\u53d1\uff0c\u65e8\u5728\u4e3a\u6df1\u5ea6\u6a21\u578b\u5f00\u53d1\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u4e2d\u5c42\u6846\u67b6\u6765\u5206\u6790\u6a21\u578b\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u548c\u8ba4\u77e5\u8d1f\u8377\u3002", "method": "\u5c06CLTs\u5b9a\u4e49\u4e3a\u4e09\u7ec4\u4ef6\u968f\u673a\u8fc7\u7a0b(IL_t, EL_t, GL_t)\uff0c\u5206\u522b\u5bf9\u5e94\u5185\u5728\u3001\u5916\u5728\u548c\u5173\u8054\u8d1f\u8f7d\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u71b5\u3001KV\u7f13\u5b58\u672a\u547d\u4e2d\u7387\u3001\u8868\u793a\u5206\u6563\u5ea6\u548c\u89e3\u7801\u7a33\u5b9a\u6027\u7b49\u53ef\u6d4b\u91cf\u4ee3\u7406\u8fdb\u884c\u5b9e\u4f8b\u5316\uff0c\u5e76\u63d0\u51fa\u7b26\u53f7\u516c\u5f0f\u548c\u53ef\u89c6\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u63a8\u7406\u548c\u89c4\u5212\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCLTs\u80fd\u591f\u9884\u6d4b\u9519\u8bef\u53d1\u751f\u3001\u63ed\u793a\u8ba4\u77e5\u7b56\u7565\uff0c\u901a\u8fc7\u8d1f\u8f7d\u5f15\u5bfc\u5e72\u9884\u53ef\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u63a8\u7406\u6548\u738715-30%\u3002", "conclusion": "CLTs\u4e3a\u6df1\u5ea6\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u80fd\u591f\u91cf\u5316\u5206\u6790\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8ba4\u77e5\u8d1f\u8377\uff0c\u5e76\u4e3a\u4f18\u5316\u63a8\u7406\u6548\u7387\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2510.15989", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.15989", "abs": "https://arxiv.org/abs/2510.15989", "authors": ["Keshav Sood", "Sanjay Selvaraj", "Youyang Qu"], "title": "Meta-Guardian: An Early Evaluation of an On-device Application to Mitigate Psychography Data Leakage in Immersive Technologies", "comment": null, "summary": "The use of Immersive Technologies has shown its potential to revolutionize\nmany sectors such as health, entertainment, education, and industrial sectors.\nImmersive technologies such as Virtual Reality (VR), Augmented reality (AR),\nand Mixed Reality (MR) have redefined user interaction through real-time\nbiometric and behavioral tracking. Although Immersive Technologies (XR)\nessentially need the collection of the biometric data which acts as a baseline\nto create immersive experience, however, this ongoing feedback information\n(includes biometrics) poses critical privacy concerns due to the sensitive\nnature of the data collected. A comprehensive review of recent literature\nexplored the technical dimensions of related problem; however, they largely\noverlook the challenge particularly the intricacies of real-time biometric data\nfiltering within head-mounted display system. Motivated from this, in this\nwork, we propose a novel privacy-preserving system architecture that identifies\nand filters biometric signals (within the VR headset) in real-time before\ntransmission or storage. Implemented as a modular Unity Software-development\nKit (SDK) compatible with major immersive platforms, our solution (named\nMeta-Guardian) employs machine learning models for signal classification and a\nfiltering mechanism to block sensitive data. This framework aims to enable\ndevelopers to embed privacy-by-design principles into immersive experiences on\nvarious headsets and applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMeta-Guardian\u7684\u9690\u79c1\u4fdd\u62a4\u7cfb\u7edf\u67b6\u6784\uff0c\u80fd\u591f\u5728VR\u5934\u663e\u4e2d\u5b9e\u65f6\u8bc6\u522b\u548c\u8fc7\u6ee4\u751f\u7269\u7279\u5f81\u4fe1\u53f7\uff0c\u9632\u6b62\u654f\u611f\u6570\u636e\u4f20\u8f93\u6216\u5b58\u50a8\u3002", "motivation": "\u6c89\u6d78\u5f0f\u6280\u672f\u9700\u8981\u6536\u96c6\u751f\u7269\u7279\u5f81\u6570\u636e\u6765\u521b\u9020\u6c89\u6d78\u5f0f\u4f53\u9a8c\uff0c\u4f46\u8fd9\u4e9b\u5b9e\u65f6\u53cd\u9988\u4fe1\u606f\uff08\u5305\u62ec\u751f\u7269\u7279\u5f81\uff09\u7531\u4e8e\u6570\u636e\u7684\u654f\u611f\u6027\u800c\u5f15\u53d1\u4e25\u91cd\u7684\u9690\u79c1\u95ee\u9898\u3002\u73b0\u6709\u6587\u732e\u5927\u591a\u5ffd\u89c6\u4e86\u5934\u6234\u5f0f\u663e\u793a\u7cfb\u7edf\u4e2d\u5b9e\u65f6\u751f\u7269\u7279\u5f81\u6570\u636e\u8fc7\u6ee4\u7684\u590d\u6742\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684Unity\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\u5305\uff08SDK\uff09\uff0c\u4e0e\u4e3b\u8981\u6c89\u6d78\u5f0f\u5e73\u53f0\u517c\u5bb9\u3002\u8be5\u7cfb\u7edf\u91c7\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u4fe1\u53f7\u5206\u7c7b\uff0c\u5e76\u4f7f\u7528\u8fc7\u6ee4\u673a\u5236\u6765\u963b\u6b62\u654f\u611f\u6570\u636e\u3002", "result": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u5728\u5404\u79cd\u5934\u663e\u548c\u5e94\u7528\u7a0b\u5e8f\u4e2d\u5d4c\u5165\u9690\u79c1\u8bbe\u8ba1\u539f\u5219\u3002", "conclusion": "\u63d0\u51fa\u7684Meta-Guardian\u7cfb\u7edf\u4e3a\u89e3\u51b3\u6c89\u6d78\u5f0f\u6280\u672f\u4e2d\u7684\u751f\u7269\u7279\u5f81\u6570\u636e\u9690\u79c1\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b9e\u65f6\u8fc7\u6ee4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16779", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.16779", "abs": "https://arxiv.org/abs/2510.16779", "authors": ["Xiaoyu Guo", "Minggu Wang", "Jianjun Zhao"], "title": "QuanBench: Benchmarking Quantum Code Generation with Large Language Models", "comment": "This paper was accepted by ASE2025", "summary": "Large language models (LLMs) have demonstrated good performance in general\ncode generation; however, their capabilities in quantum code generation remain\ninsufficiently studied. This paper presents QuanBench, a benchmark for\nevaluating LLMs on quantum code generation. QuanBench includes 44 programming\ntasks that cover quantum algorithms, state preparation, gate decomposition, and\nquantum machine learning. Each task has an executable canonical solution and is\nevaluated by functional correctness (Pass@K) and quantum semantic equivalence\n(Process Fidelity). We evaluate several recent LLMs, including general-purpose\nand code-specialized models. The results show that current LLMs have limited\ncapability in generating the correct quantum code, with overall accuracy below\n40% and frequent semantic errors. We also analyze common failure cases, such as\noutdated API usage, circuit construction errors, and incorrect algorithm logic.\nQuanBench provides a basis for future work on improving quantum code generation\nwith LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86QuanBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91cf\u5b50\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u6027\u80fd\uff0c\u5305\u542b44\u4e2a\u7f16\u7a0b\u4efb\u52a1\uff0c\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u5f53\u524dLLMs\u5728\u751f\u6210\u6b63\u786e\u91cf\u5b50\u4ee3\u7801\u65b9\u9762\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u901a\u7528\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u91cf\u5b50\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u3002", "method": "\u521b\u5efaQuanBench\u57fa\u51c6\uff0c\u5305\u542b44\u4e2a\u8986\u76d6\u91cf\u5b50\u7b97\u6cd5\u3001\u72b6\u6001\u51c6\u5907\u3001\u95e8\u5206\u89e3\u548c\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7684\u7f16\u7a0b\u4efb\u52a1\uff0c\u4f7f\u7528\u529f\u80fd\u6b63\u786e\u6027(Pass@K)\u548c\u91cf\u5b50\u8bed\u4e49\u7b49\u4ef7\u6027(\u8fc7\u7a0b\u4fdd\u771f\u5ea6)\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u5f53\u524dLLMs\u751f\u6210\u6b63\u786e\u91cf\u5b50\u4ee3\u7801\u7684\u80fd\u529b\u6709\u9650\uff0c\u603b\u4f53\u51c6\u786e\u7387\u4f4e\u4e8e40%\uff0c\u7ecf\u5e38\u51fa\u73b0\u8bed\u4e49\u9519\u8bef\uff0c\u5e38\u89c1\u5931\u8d25\u6848\u4f8b\u5305\u62ec\u8fc7\u65f6\u7684API\u4f7f\u7528\u3001\u7535\u8def\u6784\u5efa\u9519\u8bef\u548c\u7b97\u6cd5\u903b\u8f91\u9519\u8bef\u3002", "conclusion": "QuanBench\u4e3a\u672a\u6765\u6539\u8fdbLLMs\u7684\u91cf\u5b50\u4ee3\u7801\u751f\u6210\u80fd\u529b\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5f53\u524d\u6a21\u578b\u5728\u6b64\u9886\u57df\u4ecd\u6709\u663e\u8457\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2510.15981", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.15981", "abs": "https://arxiv.org/abs/2510.15981", "authors": ["Rafael Cabral", "Tuan Manh Do", "Xuejun Yu", "Wai Ming Tai", "Zijin Feng", "Xin Shen"], "title": "ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization", "comment": null, "summary": "Proof autoformalization, the task of translating natural language theorems\nand proofs into machine-verifiable code, is a critical step for integrating\nlarge language models into rigorous mathematical workflows. Current approaches\nfocus on producing executable code, but they frequently fail to preserve the\nsemantic meaning and logical structure of the original human-written argument.\nTo address this, we introduce ProofFlow, a novel pipeline that treats\nstructural fidelity as a primary objective. ProofFlow first constructs a\ndirected acyclic graph (DAG) to map the logical dependencies between proof\nsteps. Then, it employs a novel lemma-based approach to systematically\nformalize each step as an intermediate lemma, preserving the logical structure\nof the original argument. To facilitate evaluation, we present a new benchmark\nof 184 undergraduate-level problems, manually annotated with step-by-step\nsolutions and logical dependency graphs, and introduce ProofScore, a new\ncomposite metric to evaluate syntactic correctness, semantic faithfulness, and\nstructural fidelity. Experimental results show our pipeline sets a new\nstate-of-the-art for autoformalization, achieving a ProofScore of 0.545,\nsubstantially exceeding baselines like full-proof formalization (0.123), which\nprocesses the entire proof at once, and step-proof formalization (0.072), which\nhandles each step independently. Our pipeline, benchmark, and score metric are\nopen-sourced to encourage further progress at\nhttps://github.com/Huawei-AI4Math/ProofFlow.", "AI": {"tldr": "ProofFlow\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u8bc1\u660e\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u6784\u5efa\u903b\u8f91\u4f9d\u8d56\u56fe\u548c\u4f7f\u7528\u57fa\u4e8e\u5f15\u7406\u7684\u65b9\u6cd5\u6765\u4fdd\u6301\u539f\u59cb\u8bc1\u660e\u7684\u7ed3\u6784\u4fdd\u771f\u5ea6\uff0c\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\u5728\u5c06\u81ea\u7136\u8bed\u8a00\u8bc1\u660e\u8f6c\u6362\u4e3a\u673a\u5668\u53ef\u9a8c\u8bc1\u4ee3\u7801\u65f6\uff0c\u7ecf\u5e38\u65e0\u6cd5\u4fdd\u6301\u539f\u59cb\u8bc1\u660e\u7684\u8bed\u4e49\u542b\u4e49\u548c\u903b\u8f91\u7ed3\u6784\u7684\u95ee\u9898\u3002", "method": "\u9996\u5148\u6784\u5efa\u6709\u5411\u65e0\u73af\u56fe\u6765\u6620\u5c04\u8bc1\u660e\u6b65\u9aa4\u95f4\u7684\u903b\u8f91\u4f9d\u8d56\u5173\u7cfb\uff0c\u7136\u540e\u91c7\u7528\u57fa\u4e8e\u5f15\u7406\u7684\u65b9\u6cd5\u7cfb\u7edf\u5730\u5c06\u6bcf\u4e2a\u6b65\u9aa4\u5f62\u5f0f\u5316\u4e3a\u4e2d\u95f4\u5f15\u7406\uff0c\u4ece\u800c\u4fdd\u6301\u539f\u59cb\u8bba\u8bc1\u7684\u903b\u8f91\u7ed3\u6784\u3002", "result": "\u5728\u5305\u542b184\u4e2a\u672c\u79d1\u6c34\u5e73\u95ee\u9898\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cProofFlow\u8fbe\u5230\u4e860.545\u7684ProofScore\uff0c\u663e\u8457\u8d85\u8fc7\u4e86\u5168\u8bc1\u660e\u5f62\u5f0f\u5316(0.123)\u548c\u6b65\u9aa4\u8bc1\u660e\u5f62\u5f0f\u5316(0.072)\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ProofFlow\u901a\u8fc7\u5173\u6ce8\u7ed3\u6784\u4fdd\u771f\u5ea6\uff0c\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u5176\u6d41\u6c34\u7ebf\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u5206\u6307\u6807\u5df2\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.15994", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15994", "abs": "https://arxiv.org/abs/2510.15994", "authors": ["Dongsen Zhang", "Zekun Li", "Xu Luo", "Xuannan Liu", "Peipei Li", "Wenjun Xu"], "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "comment": null, "summary": "The Model Context Protocol (MCP) standardizes how large language model (LLM)\nagents discover, describe, and call external tools. While MCP unlocks broad\ninteroperability, it also enlarges the attack surface by making tools\nfirst-class, composable objects with natural-language metadata, and\nstandardized I/O. We present MSB (MCP Security Benchmark), the first end-to-end\nevaluation suite that systematically measures how well LLM agents resist\nMCP-specific attacks throughout the full tool-use pipeline: task planning, tool\ninvocation, and response handling. MSB contributes: (1) a taxonomy of 12\nattacks including name-collision, preference manipulation, prompt injections\nembedded in tool descriptions, out-of-scope parameter requests,\nuser-impersonating responses, false-error escalation, tool-transfer, retrieval\ninjection, and mixed attacks; (2) an evaluation harness that executes attacks\nby running real tools (both benign and malicious) via MCP rather than\nsimulation; and (3) a robustness metric that quantifies the trade-off between\nsecurity and performance: Net Resilient Performance (NRP). We evaluate nine\npopular LLM agents across 10 domains and 400+ tools, producing 2,000 attack\ninstances. Results reveal the effectiveness of attacks against each stage of\nMCP. Models with stronger performance are more vulnerable to attacks due to\ntheir outstanding tool calling and instruction following capabilities. MSB\nprovides a practical baseline for researchers and practitioners to study,\ncompare, and harden MCP agents.", "AI": {"tldr": "MSB\u662f\u9996\u4e2a\u7aef\u5230\u7aef\u7684MCP\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7cfb\u7edf\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u5b8c\u6574\u5de5\u5177\u4f7f\u7528\u6d41\u7a0b\u4e2d\u5bf9MCP\u7279\u5b9a\u653b\u51fb\u7684\u62b5\u6297\u80fd\u529b\u3002", "motivation": "MCP\u534f\u8bae\u867d\u7136\u5b9e\u73b0\u4e86\u5e7f\u6cdb\u7684\u4e92\u64cd\u4f5c\u6027\uff0c\u4f46\u4e5f\u6269\u5927\u4e86\u653b\u51fb\u9762\uff0c\u4f7f\u5de5\u5177\u6210\u4e3a\u5177\u6709\u81ea\u7136\u8bed\u8a00\u5143\u6570\u636e\u548c\u6807\u51c6\u5316I/O\u7684\u4e00\u7b49\u53ef\u7ec4\u5408\u5bf9\u8c61\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u5b89\u5168\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b12\u79cd\u653b\u51fb\u5206\u7c7b\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u8fd0\u884c\u771f\u5b9e\u5de5\u5177\uff08\u826f\u6027\u548c\u6076\u610f\uff09\u800c\u975e\u6a21\u62df\u6765\u6267\u884c\u653b\u51fb\uff0c\u5e76\u63d0\u51fa\u4e86Net Resilient Performance (NRP)\u9c81\u68d2\u6027\u6307\u6807\u6765\u91cf\u5316\u5b89\u5168\u4e0e\u6027\u80fd\u7684\u6743\u8861\u3002", "result": "\u8bc4\u4f30\u4e869\u4e2a\u6d41\u884cLLM\u4ee3\u7406\u572810\u4e2a\u9886\u57df\u548c400+\u5de5\u5177\u4e0a\u76842000\u4e2a\u653b\u51fb\u5b9e\u4f8b\uff0c\u7ed3\u679c\u663e\u793a\u6027\u80fd\u66f4\u5f3a\u7684\u6a21\u578b\u7531\u4e8e\u51fa\u8272\u7684\u5de5\u5177\u8c03\u7528\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u800c\u66f4\u5bb9\u6613\u53d7\u5230\u653b\u51fb\u3002", "conclusion": "MSB\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u7814\u7a76\u3001\u6bd4\u8f83\u548c\u52a0\u56faMCP\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u57fa\u7ebf\u57fa\u51c6\u3002"}}
{"id": "2510.16786", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16786", "abs": "https://arxiv.org/abs/2510.16786", "authors": ["Pengfei Gao", "Chao Peng"], "title": "More with Less: An Empirical Study of Turn-Control Strategies for Efficient Coding Agents", "comment": null, "summary": "LLM-powered coding agents, which operate in iterative loops (turns) to solve\nsoftware engineering tasks, are becoming increasingly powerful. However, their\npractical deployment is hindered by significant and unpredictable costs. This\nchallenge arises from a combination of factors: quadratically growing token\ncounts with each turn, the high price of models, the large number of turns\nrequired for real-world tasks, and the tendency of agents to take inefficient\nor unnecessary actions. While existing research focuses on optimizing\nindividual turns, the strategic control of the total number of turns remains an\nunderexplored area for managing agent performance and cost. To address this\ngap, we conduct a comprehensive empirical study on SWE-bench using three\nstate-of-the-art models and evaluate the impact of three distinct turn-control\nstrategies: an unrestricted baseline, a fixed-turn limit with reminders, and a\nnovel dynamic-turn strategy that grants extensions on-demand. Our findings\nfirst reveal a fundamental trade-off in the unrestricted setting, where no\nsingle model excels across performance, cost, and turn efficiency. We then show\nthat a fixed-turn limit, specifically at the 75th percentile of the baseline,\nserves as a \"sweet spot\", substantially reducing costs (by 24%-68%) with\nminimal impact on solve rates. Most significantly, the dynamic-turn strategy\nconsistently outperforms fixed-limit approaches, achieving comparable or better\nsolve rates while further reducing costs by an additional 12%-24% by\nintelligently allocating resources only to tasks that need them. This work\nprovides the first systematic analysis of turn-control strategies, offering\nsimple yet effective guidelines for developers to balance cost and efficacy. We\ndemonstrate that dynamic resource allocation is a superior, easy-to-implement\napproach for deploying powerful yet economically viable coding agents.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLM\u7f16\u7801\u4ee3\u7406\u7684\u8f6e\u6b21\u63a7\u5236\u7b56\u7565\uff0c\u53d1\u73b0\u52a8\u6001\u8f6e\u6b21\u7b56\u7565\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u6210\u672c\uff0c\u6bd4\u56fa\u5b9a\u8f6e\u6b21\u9650\u5236\u66f4\u6709\u6548\u3002", "motivation": "LLM\u7f16\u7801\u4ee3\u7406\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u9ad8\u6602\u4e14\u4e0d\u53ef\u9884\u6d4b\u7684\u6210\u672c\u95ee\u9898\uff0c\u4e3b\u8981\u7531\u4e8e\u8f6e\u6b21\u589e\u52a0\u5bfc\u81f4\u4ee4\u724c\u6570\u91cf\u4e8c\u6b21\u589e\u957f\u3001\u6a21\u578b\u4ef7\u683c\u9ad8\u3001\u4efb\u52a1\u9700\u8981\u591a\u8f6e\u6b21\u4ee5\u53ca\u4ee3\u7406\u6548\u7387\u4f4e\u4e0b\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u4f18\u5316\u5355\u8f6e\u6027\u80fd\uff0c\u800c\u8f6e\u6b21\u603b\u6570\u63a7\u5236\u7b56\u7565\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5728SWE-bench\u4e0a\u4f7f\u7528\u4e09\u79cd\u6700\u5148\u8fdb\u6a21\u578b\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30\u4e09\u79cd\u8f6e\u6b21\u63a7\u5236\u7b56\u7565\uff1a\u65e0\u9650\u5236\u57fa\u7ebf\u3001\u5e26\u63d0\u9192\u7684\u56fa\u5b9a\u8f6e\u6b21\u9650\u5236\u3001\u4ee5\u53ca\u6309\u9700\u6269\u5c55\u7684\u65b0\u578b\u52a8\u6001\u8f6e\u6b21\u7b56\u7565\u3002", "result": "\u65e0\u9650\u5236\u8bbe\u7f6e\u4e2d\u5b58\u5728\u57fa\u672c\u6743\u8861\uff0c\u6ca1\u6709\u5355\u4e00\u6a21\u578b\u5728\u6027\u80fd\u3001\u6210\u672c\u548c\u8f6e\u6b21\u6548\u7387\u65b9\u9762\u90fd\u8868\u73b0\u4f18\u5f02\u3002\u56fa\u5b9a\u8f6e\u6b21\u9650\u5236\uff08\u57fa\u7ebf75%\u5206\u4f4d\u6570\uff09\u53ef\u5927\u5e45\u964d\u4f4e\u6210\u672c\uff0824%-68%\uff09\u4e14\u5bf9\u89e3\u51b3\u7387\u5f71\u54cd\u6700\u5c0f\u3002\u52a8\u6001\u8f6e\u6b21\u7b56\u7565\u8868\u73b0\u6700\u4f73\uff0c\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u89e3\u51b3\u7387\u7684\u540c\u65f6\u8fdb\u4e00\u6b65\u964d\u4f4e\u6210\u672c12%-24%\u3002", "conclusion": "\u52a8\u6001\u8d44\u6e90\u5206\u914d\u662f\u90e8\u7f72\u5f3a\u5927\u4e14\u7ecf\u6d4e\u53ef\u884c\u7684\u7f16\u7801\u4ee3\u7406\u7684\u4f18\u8d8a\u65b9\u6cd5\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5e73\u8861\u6210\u672c\u4e0e\u6548\u80fd\u7684\u7b80\u5355\u6709\u6548\u6307\u5357\u3002"}}
{"id": "2510.15983", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15983", "abs": "https://arxiv.org/abs/2510.15983", "authors": ["Sarah Rebecca Ondraszek", "J\u00f6rg Waitelonis", "Katja Keller", "Claudia Niessner", "Anna M. Jacyszyn", "Harald Sack"], "title": "Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science", "comment": "10 pages, 2 figures. Camera-ready version. Accepted to the 5th\n  International Workshop on Scientific Knowledge: Representation, Discovery,\n  and Assessment; 2 November 2025 - Nara, Japan; co-located with The 24th\n  International Semantic Web Conference, ISWC 2025. To be published in CEUR\n  proceedings", "summary": "An essential component for evaluating and comparing physical and cognitive\ncapabilities between populations is the testing of various factors related to\nhuman performance. As a core part of sports science research, testing motor\nperformance enables the analysis of the physical health of different\ndemographic groups and makes them comparable.\n  The Motor Research (MO|RE) data repository, developed at the Karlsruhe\nInstitute of Technology, is an infrastructure for publishing and archiving\nresearch data in sports science, particularly in the field of motor performance\nresearch. In this paper, we present our vision for creating a knowledge graph\nfrom MO|RE data. With an ontology rooted in the Basic Formal Ontology, our\napproach centers on formally representing the interrelation of plan\nspecifications, specific processes, and related measurements. Our goal is to\ntransform how motor performance data are modeled and shared across studies,\nmaking it standardized and machine-understandable. The idea presented here is\ndeveloped within the Leibniz Science Campus ``Digital Transformation of\nResearch'' (DiTraRe).", "AI": {"tldr": "\u63d0\u51fa\u5c06MO|RE\u8fd0\u52a8\u7814\u7a76\u6570\u636e\u4ed3\u5e93\u8f6c\u6362\u4e3a\u57fa\u4e8e\u57fa\u672c\u5f62\u5f0f\u672c\u4f53\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u4ee5\u6807\u51c6\u5316\u548c\u673a\u5668\u53ef\u7406\u89e3\u7684\u65b9\u5f0f\u5efa\u6a21\u548c\u5171\u4eab\u8fd0\u52a8\u8868\u73b0\u6570\u636e\u3002", "motivation": "\u8fd0\u52a8\u8868\u73b0\u6d4b\u8bd5\u662f\u4f53\u80b2\u79d1\u5b66\u7814\u7a76\u7684\u6838\u5fc3\uff0c\u4f46\u73b0\u6709\u6570\u636e\u7f3a\u4e4f\u6807\u51c6\u5316\u5efa\u6a21\u548c\u673a\u5668\u53ef\u7406\u89e3\u6027\uff0c\u9650\u5236\u4e86\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u95f4\u8eab\u4f53\u80fd\u529b\u7684\u6bd4\u8f83\u5206\u6790\u3002", "method": "\u57fa\u4e8e\u57fa\u672c\u5f62\u5f0f\u672c\u4f53\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\uff0c\u91cd\u70b9\u5173\u6ce8\u8ba1\u5212\u89c4\u8303\u3001\u5177\u4f53\u8fc7\u7a0b\u548c\u76f8\u5173\u6d4b\u91cf\u4e4b\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\u7684\u5f62\u5f0f\u5316\u8868\u793a\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u7840\u8bbe\u65bd\uff0c\u7528\u4e8e\u53d1\u5e03\u548c\u5f52\u6863\u4f53\u80b2\u79d1\u5b66\u7814\u7a76\u6570\u636e\uff0c\u7279\u522b\u662f\u5728\u8fd0\u52a8\u8868\u73b0\u7814\u7a76\u9886\u57df\u3002", "conclusion": "\u8be5\u77e5\u8bc6\u56fe\u8c31\u65b9\u6cd5\u5c06\u6539\u53d8\u8fd0\u52a8\u8868\u73b0\u6570\u636e\u7684\u5efa\u6a21\u548c\u5171\u4eab\u65b9\u5f0f\uff0c\u4f7f\u5176\u6807\u51c6\u5316\u4e14\u673a\u5668\u53ef\u7406\u89e3\uff0c\u4fc3\u8fdb\u8de8\u7814\u7a76\u7684\u6570\u636e\u6bd4\u8f83\u548c\u5206\u6790\u3002"}}
{"id": "2510.16005", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16005", "abs": "https://arxiv.org/abs/2510.16005", "authors": ["Giacomo Bertollo", "Naz Bodemir", "Jonah Burgess"], "title": "Breaking Guardrails, Facing Walls: Insights on Adversarial AI for Defenders & Researchers", "comment": null, "summary": "Analyzing 500 CTF participants, this paper shows that while participants\nreadily bypassed simple AI guardrails using common techniques, layered\nmulti-step defenses still posed significant challenges, offering concrete\ninsights for building safer AI systems.", "AI": {"tldr": "\u5bf9500\u540dCTF\u53c2\u4e0e\u8005\u7684\u5206\u6790\u663e\u793a\uff0c\u53c2\u4e0e\u8005\u80fd\u8f7b\u677e\u7ed5\u8fc7\u7b80\u5355\u7684AI\u9632\u62a4\u63aa\u65bd\uff0c\u4f46\u591a\u5c42\u591a\u6b65\u9632\u5fa1\u4ecd\u6784\u6210\u663e\u8457\u6311\u6218\uff0c\u4e3a\u6784\u5efa\u66f4\u5b89\u5168\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5177\u4f53\u89c1\u89e3\u3002", "motivation": "\u7814\u7a76AI\u7cfb\u7edf\u7684\u5b89\u5168\u9632\u62a4\u673a\u5236\u5728\u5b9e\u9645\u653b\u51fb\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u6d4b\u8bd5\u4e0d\u540c\u590d\u6742\u5ea6\u9632\u5fa1\u7b56\u7565\u7684\u62b5\u6297\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5206\u6790500\u540dCTF\uff08\u593a\u65d7\u8d5b\uff09\u53c2\u4e0e\u8005\u7684\u653b\u51fb\u884c\u4e3a\uff0c\u8bc4\u4f30\u4ed6\u4eec\u5bf9\u7b80\u5355AI\u9632\u62a4\u548c\u591a\u5c42\u591a\u6b65\u9632\u5fa1\u7684\u7a81\u7834\u80fd\u529b\u3002", "result": "\u53c2\u4e0e\u8005\u80fd\u591f\u8f7b\u677e\u7ed5\u8fc7\u7b80\u5355\u7684AI\u9632\u62a4\u63aa\u65bd\uff0c\u4f46\u9762\u5bf9\u590d\u6742\u7684\u591a\u5c42\u591a\u6b65\u9632\u5fa1\u65f6\u9047\u5230\u4e86\u663e\u8457\u56f0\u96be\u3002", "conclusion": "\u591a\u5c42\u591a\u6b65\u9632\u5fa1\u7b56\u7565\u5728\u4fdd\u62a4AI\u7cfb\u7edf\u65b9\u9762\u6bd4\u7b80\u5355\u9632\u62a4\u66f4\u6709\u6548\uff0c\u8fd9\u4e3a\u8bbe\u8ba1\u66f4\u5b89\u5168\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2510.16809", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.PL", "68T50, 68N30, 68W40", "I.2.7; D.2.7; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.16809", "abs": "https://arxiv.org/abs/2510.16809", "authors": ["Amirkia Rafiei Oskooei", "Kaan Baturalp Cosdan", "Husamettin Isiktas", "Mehmet S. Aktas"], "title": "When Many-Shot Prompting Fails: An Empirical Study of LLM Code Translation", "comment": null, "summary": "Large Language Models (LLMs) with vast context windows offer new avenues for\nin-context learning (ICL), where providing many examples (\"many-shot\"\nprompting) is often assumed to enhance performance. We investigate this\nassumption for the complex task of code translation. Through a large-scale\nempirical study of over 90,000 translations, we systematically evaluate the\nimpact of scaling in-context examples from zero-shot to many-shot\nconfigurations of up to 625 examples, with prompts spanning from approximately\n100,000 to 800,000 tokens. Our findings reveal a \"many-shot paradox\": while\nstatic similarity metrics may modestly improve with more examples, functional\ncorrectness consistently peaks with few-shot prompting (5-25 examples).\nProviding substantially more examples often degrades this crucial functional\nperformance. This study highlights that for code translation, the quality of a\nfew well-chosen examples outweighs sheer quantity, challenging the universal\nefficacy of \"more is better\" for ICL and underscoring the task-dependent nature\nof optimal prompting strategies. Our results have significant implications for\neffectively leveraging LLMs in software engineering.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u5b58\u5728\"\u591a\u6837\u672c\u6096\u8bba\"\uff1a\u867d\u7136\u9759\u6001\u76f8\u4f3c\u5ea6\u6307\u6807\u968f\u793a\u4f8b\u6570\u91cf\u589e\u52a0\u800c\u7565\u6709\u63d0\u5347\uff0c\u4f46\u529f\u80fd\u6b63\u786e\u6027\u5728\u5c11\u91cf\u793a\u4f8b\uff085-25\u4e2a\uff09\u65f6\u8fbe\u5230\u5cf0\u503c\uff0c\u66f4\u591a\u793a\u4f8b\u53cd\u800c\u4f1a\u964d\u4f4e\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e2d\uff0c\u589e\u52a0\u4e0a\u4e0b\u6587\u793a\u4f8b\u6570\u91cf\uff08\u4ece\u96f6\u6837\u672c\u5230\u591a\u6837\u672c\uff09\u5bf9\u6027\u80fd\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u9a8c\u8bc1\"\u66f4\u591a\u793a\u4f8b\u66f4\u597d\"\u7684\u5047\u8bbe\u662f\u5426\u9002\u7528\u4e8e\u590d\u6742\u4efb\u52a1\u3002", "method": "\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30\u8d85\u8fc790,000\u6b21\u7ffb\u8bd1\uff0c\u7cfb\u7edf\u6027\u5730\u6d4b\u8bd5\u4ece\u96f6\u6837\u672c\u5230\u6700\u591a625\u4e2a\u793a\u4f8b\u7684\u591a\u6837\u672c\u914d\u7f6e\uff0c\u63d0\u793a\u957f\u5ea6\u4ece\u7ea6100,000\u5230800,000\u4e2atoken\u3002", "result": "\u53d1\u73b0\u529f\u80fd\u6b63\u786e\u6027\u5728\u5c11\u91cf\u793a\u4f8b\uff085-25\u4e2a\uff09\u65f6\u8fbe\u5230\u6700\u4f73\uff0c\u66f4\u591a\u793a\u4f8b\u53cd\u800c\u4f1a\u964d\u4f4e\u5173\u952e\u7684\u529f\u80fd\u6027\u80fd\uff0c\u5c3d\u7ba1\u9759\u6001\u76f8\u4f3c\u5ea6\u6307\u6807\u53ef\u80fd\u7565\u6709\u6539\u5584\u3002", "conclusion": "\u5bf9\u4e8e\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\uff0c\u5c11\u91cf\u7cbe\u5fc3\u9009\u62e9\u7684\u793a\u4f8b\u8d28\u91cf\u6bd4\u6570\u91cf\u66f4\u91cd\u8981\uff0c\u6311\u6218\u4e86\"\u8d8a\u591a\u8d8a\u597d\"\u7684\u666e\u904d\u6709\u6548\u6027\uff0c\u5f3a\u8c03\u4e86\u6700\u4f18\u63d0\u793a\u7b56\u7565\u7684\u4efb\u52a1\u4f9d\u8d56\u6027\u3002"}}
{"id": "2510.16001", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16001", "abs": "https://arxiv.org/abs/2510.16001", "authors": ["Ruolan Cheng", "Yong Deng", "Enrique Herrera-Viedma"], "title": "A Non-overlap-based Conflict Measure for Random Permutation Sets", "comment": null, "summary": "Random permutation set (RPS) is a new formalism for reasoning with\nuncertainty involving order information. Measuring the conflict between two\npieces of evidence represented by permutation mass functions remains an urgent\nresearch topic in order-structured uncertain information fusion. In this paper,\na detailed analysis of conflicts in RPS is carried out from two different\nperspectives: random finite set (RFS) and Dempster-Shafer theory (DST).\nStarting from the observation of permutations, we first define an inconsistency\nmeasure between permutations inspired by the rank-biased overlap(RBO) measure\nand further propose a non-overlap-based conflict measure method for RPSs. This\npaper regards RPS theory (RPST) as an extension of DST. The order information\nnewly added in focal sets indicates qualitative propensity, characterized by\ntop-ranked elements occupying a more critical position. Some numerical examples\nare used to demonstrate the behavior and properties of the proposed conflict\nmeasure. The proposed method not only has the natural top-weightedness property\nand can effectively measure the conflict between RPSs from the DST view but\nalso provides decision-makers with a flexible selection of weights, parameters,\nand truncated depths.", "AI": {"tldr": "\u672c\u6587\u4ece\u968f\u673a\u6709\u9650\u96c6\u548cDempster-Shafer\u7406\u8bba\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790\u968f\u673a\u7f6e\u6362\u96c6\u4e2d\u7684\u51b2\u7a81\uff0c\u63d0\u51fa\u57fa\u4e8e\u79e9\u504f\u91cd\u53e0\u7684\u51b2\u7a81\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u89c6\u4e3aDST\u7684\u6269\u5c55\u3002", "motivation": "\u6d4b\u91cf\u7531\u7f6e\u6362\u8d28\u91cf\u51fd\u6570\u8868\u793a\u7684\u4e24\u4e2a\u8bc1\u636e\u4e4b\u95f4\u7684\u51b2\u7a81\u662f\u987a\u5e8f\u7ed3\u6784\u4e0d\u786e\u5b9a\u4fe1\u606f\u878d\u5408\u4e2d\u7684\u7d27\u8feb\u7814\u7a76\u8bfe\u9898\u3002", "method": "\u4ece\u7f6e\u6362\u89c2\u5bdf\u51fa\u53d1\uff0c\u57fa\u4e8e\u79e9\u504f\u91cd\u53e0(RBO)\u5ea6\u91cf\u5b9a\u4e49\u7f6e\u6362\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u5ea6\u91cf\uff0c\u5e76\u8fdb\u4e00\u6b65\u63d0\u51faRPS\u7684\u975e\u91cd\u53e0\u51b2\u7a81\u5ea6\u91cf\u65b9\u6cd5\u3002", "result": "\u6570\u503c\u793a\u4f8b\u5c55\u793a\u4e86\u6240\u63d0\u51b2\u7a81\u5ea6\u91cf\u7684\u884c\u4e3a\u548c\u7279\u6027\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u81ea\u7136\u7684\u9876\u90e8\u52a0\u6743\u7279\u6027\uff0c\u80fd\u4eceDST\u89c6\u89d2\u6709\u6548\u6d4b\u91cfRPS\u95f4\u7684\u51b2\u7a81\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u4e0d\u4ec5\u5177\u6709\u9876\u90e8\u52a0\u6743\u7279\u6027\uff0c\u8fd8\u80fd\u4e3a\u51b3\u7b56\u8005\u63d0\u4f9b\u6743\u91cd\u3001\u53c2\u6570\u548c\u622a\u65ad\u6df1\u5ea6\u7684\u7075\u6d3b\u9009\u62e9\u3002"}}
{"id": "2510.16024", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16024", "abs": "https://arxiv.org/abs/2510.16024", "authors": ["Abdulrahman Alhaidari", "Balaji Palanisamy", "Prashant Krishnamurthy"], "title": "On-Chain Decentralized Learning and Cost-Effective Inference for DeFi Attack Mitigation", "comment": "Published in the 7th Conference on Advances in Financial Technologies\n  (AFT 2025)", "summary": "Billions of dollars are lost every year in DeFi platforms by transactions\nexploiting business logic or accounting vulnerabilities. Existing defenses\nfocus on static code analysis, public mempool screening, attacker contract\ndetection, or trusted off-chain monitors, none of which prevents exploits\nsubmitted through private relays or malicious contracts that execute within the\nsame block. We present the first decentralized, fully on-chain learning\nframework that: (i) performs gas-prohibitive computation on Layer-2 to reduce\ncost, (ii) propagates verified model updates to Layer-1, and (iii) enables\ngas-bounded, low-latency inference inside smart contracts. A novel\nProof-of-Improvement (PoIm) protocol governs the training process and verifies\neach decentralized micro update as a self-verifying training transaction.\nUpdates are accepted by \\textit{PoIm} only if they demonstrably improve at\nleast one core metric (e.g., accuracy, F1-score, precision, or recall) on a\npublic benchmark without degrading any of the other core metrics, while\nadversarial proposals get financially penalized through an adaptable test set\nfor evolving threats. We develop quantization and loop-unrolling techniques\nthat enable inference for logistic regression, SVM, MLPs, CNNs, and gated RNNs\n(with support for formally verified decision tree inference) within the\nEthereum block gas limit, while remaining bit-exact to their off-chain\ncounterparts, formally proven in Z3. We curate 298 unique real-world exploits\n(2020 - 2025) with 402 exploit transactions across eight EVM chains,\ncollectively responsible for \\$3.74 B in losses.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u5168\u94fe\u4e0a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7Layer-2\u8fdb\u884c\u9ad8\u6210\u672c\u8ba1\u7b97\uff0c\u5728Layer-1\u8fdb\u884c\u9a8c\u8bc1\u6a21\u578b\u66f4\u65b0\uff0c\u5e76\u5728\u667a\u80fd\u5408\u7ea6\u5185\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u63a8\u7406\uff0c\u4ee5\u9632\u6b62DeFi\u5e73\u53f0\u4e2d\u7684\u6f0f\u6d1e\u5229\u7528\u3002", "motivation": "DeFi\u5e73\u53f0\u6bcf\u5e74\u56e0\u4e1a\u52a1\u903b\u8f91\u6216\u4f1a\u8ba1\u6f0f\u6d1e\u800c\u635f\u5931\u6570\u5341\u4ebf\u7f8e\u5143\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u65e0\u6cd5\u9632\u6b62\u901a\u8fc7\u79c1\u6709\u4e2d\u7ee7\u6216\u6076\u610f\u5408\u7ea6\u5728\u540c\u4e00\u533a\u5757\u5185\u6267\u884c\u7684\u653b\u51fb\u3002", "method": "\u91c7\u7528Proof-of-Improvement\u534f\u8bae\u7ba1\u7406\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u901a\u8fc7\u91cf\u5316\u6280\u672f\u548c\u5faa\u73af\u5c55\u5f00\u6280\u672f\u5b9e\u73b0\u903b\u8f91\u56de\u5f52\u3001SVM\u3001MLPs\u3001CNNs\u548c\u95e8\u63a7RNNs\u5728\u4ee5\u592a\u574a\u533a\u5757gas\u9650\u5236\u5185\u7684\u63a8\u7406\u3002", "result": "\u6536\u96c6\u4e86298\u4e2a\u771f\u5b9e\u4e16\u754c\u6f0f\u6d1e\u5229\u7528\u6848\u4f8b\uff082020-2025\u5e74\uff09\uff0c\u6d89\u53ca402\u6b21\u5229\u7528\u4ea4\u6613\uff0c\u603b\u635f\u5931\u8fbe37.4\u4ebf\u7f8e\u5143\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u9632\u6b62DeFi\u6f0f\u6d1e\u5229\u7528\uff0c\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u548c\u94fe\u4e0a\u63a8\u7406\u63d0\u4f9b\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2510.16823", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16823", "abs": "https://arxiv.org/abs/2510.16823", "authors": ["Yue Liu", "Zhenchang Xing", "Shidong Pan", "Chakkrit Tantithamthavorn"], "title": "When AI Takes the Wheel: Security Analysis of Framework-Constrained Program Generation", "comment": null, "summary": "In recent years, the AI wave has grown rapidly in software development. Even\nnovice developers can now design and generate complex framework-constrained\nsoftware systems based on their high-level requirements with the help of Large\nLanguage Models (LLMs). However, when LLMs gradually \"take the wheel\" of\nsoftware development, developers may only check whether the program works. They\noften miss security problems hidden in how the generated programs are\nimplemented.\n  In this work, we investigate the security properties of framework-constrained\nprograms generated by state-of-the-art LLMs. We focus specifically on Chrome\nextensions due to their complex security model involving multiple privilege\nboundaries and isolated components. To achieve this, we built ChromeSecBench, a\ndataset with 140 prompts based on known vulnerable extensions. We used these\nprompts to instruct nine state-of-the-art LLMs to generate complete Chrome\nextensions, and then analyzed them for vulnerabilities across three dimensions:\nscenario types, model differences, and vulnerability categories. Our results\nshow that LLMs produced vulnerable programs at alarmingly high rates (18%-50%),\nparticularly in Authentication & Identity and Cookie Management scenarios (up\nto 83% and 78% respectively). Most vulnerabilities exposed sensitive browser\ndata like cookies, history, or bookmarks to untrusted code. Interestingly, we\nfound that advanced reasoning models performed worse, generating more\nvulnerabilities than simpler models. These findings highlight a critical gap\nbetween LLMs' coding skills and their ability to write secure\nframework-constrained programs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0cLLM\u751f\u6210\u7684Chrome\u6269\u5c55\u7a0b\u5e8f\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u6f0f\u6d1e\u7387\u9ad8\u8fbe18%-50%\uff0c\u7279\u522b\u662f\u5728\u8eab\u4efd\u8ba4\u8bc1\u548cCookie\u7ba1\u7406\u573a\u666f\u4e2d\u6f0f\u6d1e\u7387\u53ef\u8fbe83%\u548c78%\u3002\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u53cd\u800c\u8868\u73b0\u66f4\u5dee\u3002", "motivation": "\u968f\u7740LLM\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u5f00\u53d1\u8005\u53ef\u80fd\u53ea\u5173\u6ce8\u7a0b\u5e8f\u529f\u80fd\u800c\u5ffd\u7565\u5b89\u5168\u5b9e\u73b0\u95ee\u9898\uff0c\u9700\u8981\u7814\u7a76LLM\u751f\u6210\u6846\u67b6\u7ea6\u675f\u7a0b\u5e8f\u7684\u5b89\u5168\u6027\u3002", "method": "\u6784\u5efaChromeSecBench\u6570\u636e\u96c6\uff08140\u4e2a\u57fa\u4e8e\u5df2\u77e5\u6f0f\u6d1e\u6269\u5c55\u7684\u63d0\u793a\uff09\uff0c\u4f7f\u75289\u4e2a\u5148\u8fdbLLM\u751f\u6210\u5b8c\u6574Chrome\u6269\u5c55\uff0c\u4ece\u573a\u666f\u7c7b\u578b\u3001\u6a21\u578b\u5dee\u5f02\u548c\u6f0f\u6d1e\u7c7b\u522b\u4e09\u4e2a\u7ef4\u5ea6\u5206\u6790\u5b89\u5168\u6027\u3002", "result": "LLM\u751f\u6210\u7a0b\u5e8f\u6f0f\u6d1e\u7387\u60ca\u4eba\u5730\u9ad8\uff0c\u5927\u591a\u6570\u6f0f\u6d1e\u4f1a\u66b4\u9732\u654f\u611f\u6d4f\u89c8\u5668\u6570\u636e\u7ed9\u4e0d\u53ef\u4fe1\u4ee3\u7801\uff0c\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u751f\u6210\u7684\u6f0f\u6d1e\u53cd\u800c\u66f4\u591a\u3002", "conclusion": "LLM\u7684\u7f16\u7801\u80fd\u529b\u4e0e\u7f16\u5199\u5b89\u5168\u6846\u67b6\u7ea6\u675f\u7a0b\u5e8f\u7684\u80fd\u529b\u5b58\u5728\u5173\u952e\u5dee\u8ddd\uff0c\u9700\u8981\u52a0\u5f3aLLM\u7684\u5b89\u5168\u610f\u8bc6\u8bad\u7ec3\u3002"}}
{"id": "2510.16004", "categories": ["cs.AI", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.16004", "abs": "https://arxiv.org/abs/2510.16004", "authors": ["Andreas Radler", "Vincent Seyfried", "Stefan Pirker", "Johannes Brandstetter", "Thomas Lichtenegger"], "title": "PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction", "comment": "22 pages, 16 figures", "summary": "Neural surrogates have shown great potential in simulating dynamical systems,\nwhile offering real-time capabilities. We envision Neural Twins as a\nprogression of neural surrogates, aiming to create digital replicas of real\nsystems. A neural twin consumes measurements at test time to update its state,\nthereby enabling context-specific decision-making. A critical property of\nneural twins is their ability to remain on-trajectory, i.e., to stay close to\nthe true system state over time. We introduce Parallel-in-time Neural Twins\n(PAINT), an architecture-agnostic family of methods for modeling dynamical\nsystems from measurements. PAINT trains a generative neural network to model\nthe distribution of states parallel over time. At test time, states are\npredicted from measurements in a sliding window fashion. Our theoretical\nanalysis shows that PAINT is on-trajectory, whereas autoregressive models\ngenerally are not. Empirically, we evaluate our method on a challenging\ntwo-dimensional turbulent fluid dynamics problem. The results demonstrate that\nPAINT stays on-trajectory and predicts system states from sparse measurements\nwith high fidelity. These findings underscore PAINT's potential for developing\nneural twins that stay on-trajectory, enabling more accurate state estimation\nand decision-making.", "AI": {"tldr": "PAINT\u662f\u4e00\u79cd\u5e76\u884c\u65f6\u95f4\u795e\u7ecf\u7f51\u7edc\u5b6a\u751f\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u5f0f\u795e\u7ecf\u7f51\u7edc\u5e76\u884c\u5efa\u6a21\u72b6\u6001\u5206\u5e03\uff0c\u80fd\u591f\u5728\u6d4b\u8bd5\u65f6\u4ece\u7a00\u758f\u6d4b\u91cf\u4e2d\u51c6\u786e\u9884\u6d4b\u7cfb\u7edf\u72b6\u6001\u5e76\u4fdd\u6301\u8f68\u8ff9\u8ddf\u8e2a\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u4ee3\u7406\u5728\u6a21\u62df\u52a8\u6001\u7cfb\u7edf\u65f6\u7f3a\u4e4f\u5b9e\u65f6\u66f4\u65b0\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4ece\u6d4b\u91cf\u6570\u636e\u4e2d\u66f4\u65b0\u72b6\u6001\u3001\u5b9e\u73b0\u4e0a\u4e0b\u6587\u7279\u5b9a\u51b3\u7b56\u7684\u795e\u7ecf\u5b6a\u751f\u7cfb\u7edf\u3002", "method": "PAINT\u8bad\u7ec3\u751f\u6210\u5f0f\u795e\u7ecf\u7f51\u7edc\u5e76\u884c\u5efa\u6a21\u65f6\u95f4\u4e0a\u7684\u72b6\u6001\u5206\u5e03\uff0c\u5728\u6d4b\u8bd5\u65f6\u91c7\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u5f0f\u4ece\u6d4b\u91cf\u6570\u636e\u9884\u6d4b\u72b6\u6001\u3002", "result": "\u5728\u4e8c\u7ef4\u6e4d\u6d41\u6d41\u4f53\u52a8\u529b\u5b66\u95ee\u9898\u4e0a\uff0cPAINT\u80fd\u591f\u4fdd\u6301\u8f68\u8ff9\u8ddf\u8e2a\uff0c\u4ece\u7a00\u758f\u6d4b\u91cf\u4e2d\u9ad8\u4fdd\u771f\u5730\u9884\u6d4b\u7cfb\u7edf\u72b6\u6001\u3002", "conclusion": "PAINT\u5c55\u793a\u4e86\u5f00\u53d1\u4fdd\u6301\u8f68\u8ff9\u8ddf\u8e2a\u7684\u795e\u7ecf\u5b6a\u751f\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u72b6\u6001\u4f30\u8ba1\u548c\u51b3\u7b56\u5236\u5b9a\u3002"}}
{"id": "2510.16025", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16025", "abs": "https://arxiv.org/abs/2510.16025", "authors": ["Denis Ovichinnikov", "Hemant Kavadia", "Satya Keerti Chand Kudupudi", "Ilya Rempel", "Vineet Chadha", "Marty Franz", "Paul Master", "Craig Gentry", "Darlene Kindler", "Alberto Reyes", "Muthu Annamalai"], "title": "Resource Estimation of CGGI and CKKS scheme workloads on FracTLcore Computing Fabric", "comment": "5 tables, 2 figures, conference style", "summary": "Cornami Mx2 accelerates of Fully Homomorphic Encryption (FHE) applications,\nenabled by breakthrough work [1], which are otherwise compute limited. Our\nprocessor architecture is based on the systolic array of cores with in-memory\ncompute capability and a network on chip (NoC) processor architecture called\nthe \"FracTLcore compute fabric processor\" (Mx2). Here, we describe the work to\nestimate processor resources to compute workload in CGGI (TFHE-rs) or CKKS\nscheme during construction of our compiler backend for this architecture [2].\nThese processors are available for running applications in both the TFHE-rs\nBoolean scheme and CKKS scheme FHE applications.", "AI": {"tldr": "Cornami Mx2\u5904\u7406\u5668\u901a\u8fc7systolic\u9635\u5217\u548c\u5185\u5b58\u8ba1\u7b97\u80fd\u529b\u52a0\u901f\u5168\u540c\u6001\u52a0\u5bc6\u5e94\u7528\uff0c\u652f\u6301TFHE-rs\u548cCKKS\u4e24\u79cd\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u5168\u540c\u6001\u52a0\u5bc6\u5e94\u7528\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\uff0c\u901a\u8fc7\u4e13\u7528\u786c\u4ef6\u67b6\u6784\u63d0\u5347\u6027\u80fd\u3002", "method": "\u91c7\u7528\u57fa\u4e8esystolic\u9635\u5217\u7684\u6838\u5fc3\u67b6\u6784\uff0c\u5177\u5907\u5185\u5b58\u8ba1\u7b97\u80fd\u529b\u548c\u7247\u4e0a\u7f51\u7edc\uff0c\u6784\u5efa\u7f16\u8bd1\u5668\u540e\u7aef\u6765\u8bc4\u4f30\u5904\u7406\u5668\u8d44\u6e90\u3002", "result": "\u5f00\u53d1\u51fa\u80fd\u591f\u540c\u65f6\u652f\u6301TFHE-rs\u5e03\u5c14\u65b9\u6848\u548cCKKS\u65b9\u6848\u7684\u5168\u540c\u6001\u52a0\u5bc6\u5e94\u7528\u7684\u5904\u7406\u5668\u67b6\u6784\u3002", "conclusion": "Cornami Mx2\u67b6\u6784\u4e3a\u5168\u540c\u6001\u52a0\u5bc6\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u786c\u4ef6\u52a0\u901f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17056", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.17056", "abs": "https://arxiv.org/abs/2510.17056", "authors": ["Luis F. G. Campos", "Leonardo C. Marques", "Walter T. Nakamura"], "title": "Will AI also replace inspectors? Investigating the potential of generative AIs in usability inspection", "comment": "Accepted and to be published in SBQS25 - Brazilian Symposium on\n  Software Quality 2025", "summary": "Usability inspection is a well-established technique for identifying\ninteraction issues in software interfaces, thereby contributing to improved\nproduct quality. However, it is a costly process that requires time and\nspecialized knowledge from inspectors. With advances in Artificial Intelligence\n(AI), new opportunities have emerged to support this task, particularly through\ngenerative models capable of interpreting interfaces and performing inspections\nmore efficiently. This study examines the performance of generative AIs in\nidentifying usability problems, comparing them to those of experienced human\ninspectors. A software prototype was evaluated by four specialists and two AI\nmodels (GPT-4o and Gemini 2.5 Flash), using metrics such as precision, recall,\nand F1-score. While inspectors achieved the highest levels of precision and\noverall coverage, the AIs demonstrated high individual performance and\ndiscovered many novel defects, but with a higher rate of false positives and\nredundant reports. The combination of AIs and human inspectors produced the\nbest results, revealing their complementarity. These findings suggest that AI,\nin its current stage, cannot replace human inspectors but can serve as a\nvaluable augmentation tool to improve efficiency and expand defect coverage.\nThe results provide evidence based on quantitative analysis to inform the\ndiscussion on the role of AI in usability inspections, pointing to viable paths\nfor its complementary use in software quality assessment contexts.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u751f\u6210\u5f0fAI\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5728\u53ef\u7528\u6027\u68c0\u67e5\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0AI\u867d\u7136\u80fd\u53d1\u73b0\u8bb8\u591a\u65b0\u7f3a\u9677\u4f46\u8bef\u62a5\u7387\u8f83\u9ad8\uff0cAI\u4e0e\u4eba\u7c7b\u68c0\u67e5\u5458\u7ed3\u5408\u4f7f\u7528\u6548\u679c\u6700\u4f73\u3002", "motivation": "\u53ef\u7528\u6027\u68c0\u67e5\u6210\u672c\u9ad8\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u968f\u7740AI\u6280\u672f\u7684\u53d1\u5c55\uff0c\u63a2\u7d22\u751f\u6210\u5f0fAI\u5728\u53ef\u7528\u6027\u68c0\u67e5\u4e2d\u7684\u6f5c\u529b\uff0c\u4ee5\u63d0\u5347\u6548\u7387\u548c\u964d\u4f4e\u6210\u672c\u3002", "method": "\u4f7f\u7528\u8f6f\u4ef6\u539f\u578b\uff0c\u75314\u540d\u4e13\u5bb6\u548c2\u4e2aAI\u6a21\u578b(GPT-4o\u548cGemini 2.5 Flash)\u8fdb\u884c\u8bc4\u4f30\uff0c\u91c7\u7528\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u7b49\u6307\u6807\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u4eba\u7c7b\u68c0\u67e5\u5458\u5728\u7cbe\u786e\u7387\u548c\u6574\u4f53\u8986\u76d6\u7387\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0cAI\u6a21\u578b\u4e2a\u4f53\u8868\u73b0\u826f\u597d\u4e14\u53d1\u73b0\u8bb8\u591a\u65b0\u7f3a\u9677\uff0c\u4f46\u8bef\u62a5\u7387\u548c\u5197\u4f59\u62a5\u544a\u8f83\u9ad8\u3002AI\u4e0e\u4eba\u7c7b\u7ed3\u5408\u4f7f\u7528\u6548\u679c\u6700\u597d\u3002", "conclusion": "\u5f53\u524d\u9636\u6bb5\u7684AI\u65e0\u6cd5\u66ff\u4ee3\u4eba\u7c7b\u68c0\u67e5\u5458\uff0c\u4f46\u53ef\u4f5c\u4e3a\u6709\u4ef7\u503c\u7684\u589e\u5f3a\u5de5\u5177\uff0c\u63d0\u9ad8\u6548\u7387\u5e76\u6269\u5927\u7f3a\u9677\u8986\u76d6\u8303\u56f4\uff0c\u5728\u8f6f\u4ef6\u8d28\u91cf\u8bc4\u4f30\u4e2d\u5177\u6709\u4e92\u8865\u4f7f\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.16033", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16033", "abs": "https://arxiv.org/abs/2510.16033", "authors": ["Junyu Ren", "Wensheng Gan", "Guangyu Zhang", "Wei Zhong", "Philip S. Yu"], "title": "Global-focal Adaptation with Information Separation for Noise-robust Transfer Fault Diagnosis", "comment": "Preprint. 16 figures, 12 tables", "summary": "Existing transfer fault diagnosis methods typically assume either clean data\nor sufficient domain similarity, which limits their effectiveness in industrial\nenvironments where severe noise interference and domain shifts coexist. To\naddress this challenge, we propose an information separation global-focal\nadversarial network (ISGFAN), a robust framework for cross-domain fault\ndiagnosis under noise conditions. ISGFAN is built on an information separation\narchitecture that integrates adversarial learning with an improved orthogonal\nloss to decouple domain-invariant fault representation, thereby isolating noise\ninterference and domain-specific characteristics. To further strengthen\ntransfer robustness, ISGFAN employs a global-focal domain-adversarial scheme\nthat constrains both the conditional and marginal distributions of the model.\nSpecifically, the focal domain-adversarial component mitigates\ncategory-specific transfer obstacles caused by noise in unsupervised scenarios,\nwhile the global domain classifier ensures alignment of the overall\ndistribution. Experiments conducted on three public benchmark datasets\ndemonstrate that the proposed method outperforms other prominent existing\napproaches, confirming the superiority of the ISGFAN framework. Data and code\nare available at https://github.com/JYREN-Source/ISGFAN", "AI": {"tldr": "\u63d0\u51faISGFAN\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u5206\u79bb\u548c\u5168\u5c40-\u5c40\u90e8\u5bf9\u6297\u5b66\u4e60\u89e3\u51b3\u566a\u58f0\u5e72\u6270\u548c\u57df\u504f\u79fb\u5171\u5b58\u7684\u8de8\u57df\u6545\u969c\u8bca\u65ad\u95ee\u9898", "motivation": "\u73b0\u6709\u6545\u969c\u8bca\u65ad\u65b9\u6cd5\u5047\u8bbe\u6570\u636e\u5e72\u51c0\u6216\u57df\u76f8\u4f3c\u6027\u8db3\u591f\uff0c\u4f46\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u566a\u58f0\u5e72\u6270\u548c\u57df\u504f\u79fb\u540c\u65f6\u5b58\u5728\uff0c\u9650\u5236\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027", "method": "\u57fa\u4e8e\u4fe1\u606f\u5206\u79bb\u67b6\u6784\uff0c\u7ed3\u5408\u5bf9\u6297\u5b66\u4e60\u548c\u6539\u8fdb\u7684\u6b63\u4ea4\u635f\u5931\u6765\u89e3\u8026\u57df\u4e0d\u53d8\u6545\u969c\u8868\u793a\uff1b\u91c7\u7528\u5168\u5c40-\u5c40\u90e8\u57df\u5bf9\u6297\u65b9\u6848\u7ea6\u675f\u6a21\u578b\u7684\u8fb9\u7f18\u5206\u5e03\u548c\u6761\u4ef6\u5206\u5e03", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5176\u4ed6\u73b0\u6709\u65b9\u6cd5", "conclusion": "ISGFAN\u6846\u67b6\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u8de8\u57df\u6545\u969c\u8bca\u65ad\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027"}}
{"id": "2510.16028", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.16028", "abs": "https://arxiv.org/abs/2510.16028", "authors": ["Jianzhu Yao", "Hongxu Su", "Taobo Liao", "Zerui Cheng", "Huan Zhang", "Xuechao Wang", "Pramod Viswanath"], "title": "Nondeterminism-Aware Optimistic Verification for Floating-Point Neural Networks", "comment": "17 pages, 7 figures", "summary": "Neural networks increasingly run on hardware outside the user's control\n(cloud GPUs, inference marketplaces). Yet ML-as-a-Service reveals little about\nwhat actually ran or whether returned outputs faithfully reflect the intended\ninputs. Users lack recourse against service downgrades (model swaps,\nquantization, graph rewrites, or discrepancies like altered ad embeddings).\nVerifying outputs is hard because floating-point(FP) execution on heterogeneous\naccelerators is inherently nondeterministic. Existing approaches are either\nimpractical for real FP neural networks or reintroduce vendor trust. We present\nNAO: a Nondeterministic tolerance Aware Optimistic verification protocol that\naccepts outputs within principled operator-level acceptance regions rather than\nrequiring bitwise equality. NAO combines two error models: (i) sound\nper-operator IEEE-754 worst-case bounds and (ii) tight empirical percentile\nprofiles calibrated across hardware. Discrepancies trigger a Merkle-anchored,\nthreshold-guided dispute game that recursively partitions the computation graph\nuntil one operator remains, where adjudication reduces to a lightweight\ntheoretical-bound check or a small honest-majority vote against empirical\nthresholds. Unchallenged results finalize after a challenge window, without\nrequiring trusted hardware or deterministic kernels. We implement NAO as a\nPyTorch-compatible runtime and a contract layer currently deployed on Ethereum\nHolesky testnet. The runtime instruments graphs, computes per-operator bounds,\nand runs unmodified vendor kernels in FP32 with negligible overhead (0.3% on\nQwen3-8B). Across CNNs, Transformers and diffusion models on A100, H100,\nRTX6000, RTX4090, empirical thresholds are $10^2-10^3$ times tighter than\ntheoretical bounds, and bound-aware adversarial attacks achieve 0% success. NAO\nreconciles scalability with verifiability for real-world heterogeneous ML\ncompute.", "AI": {"tldr": "NAO\u662f\u4e00\u79cd\u9488\u5bf9\u5f02\u6784\u786c\u4ef6\u4e0aFP\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u7684\u4e50\u89c2\u9a8c\u8bc1\u534f\u8bae\uff0c\u901a\u8fc7\u7ed3\u5408\u7406\u8bba\u8bef\u5dee\u8fb9\u754c\u548c\u7ecf\u9a8c\u9608\u503c\u6765\u5bb9\u5fcd\u975e\u786e\u5b9a\u6027\uff0c\u65e0\u9700\u53ef\u4fe1\u786c\u4ef6\u6216\u786e\u5b9a\u6027\u5185\u6838\u5373\u53ef\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684ML\u8ba1\u7b97\u3002", "motivation": "\u968f\u7740\u795e\u7ecf\u7f51\u7edc\u5728\u7528\u6237\u65e0\u6cd5\u63a7\u5236\u7684\u786c\u4ef6\u4e0a\u8fd0\u884c\uff0cML\u670d\u52a1\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u7528\u6237\u96be\u4ee5\u9a8c\u8bc1\u8f93\u51fa\u662f\u5426\u5fe0\u5b9e\u53cd\u6620\u9884\u671f\u8f93\u5165\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4e0d\u5b9e\u7528\uff0c\u8981\u4e48\u91cd\u65b0\u5f15\u5165\u4f9b\u5e94\u5546\u4fe1\u4efb\u3002", "method": "NAO\u7ed3\u5408\u4e24\u79cd\u8bef\u5dee\u6a21\u578b\uff1aIEEE-754\u6700\u574f\u60c5\u51b5\u8fb9\u754c\u548c\u7ecf\u9a8c\u767e\u5206\u4f4d\u5206\u5e03\uff0c\u91c7\u7528Merkle\u951a\u5b9a\u7684\u9608\u503c\u5f15\u5bfc\u4e89\u8bae\u6e38\u620f\uff0c\u9012\u5f52\u5212\u5206\u8ba1\u7b97\u56fe\u76f4\u81f3\u5355\u4e2a\u7b97\u5b50\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7406\u8bba\u8fb9\u754c\u68c0\u67e5\u6216\u8bda\u5b9e\u591a\u6570\u6295\u7968\u8fdb\u884c\u88c1\u51b3\u3002", "result": "\u5728A100\u3001H100\u3001RTX6000\u3001RTX4090\u7b49\u786c\u4ef6\u4e0a\uff0c\u7ecf\u9a8c\u9608\u503c\u6bd4\u7406\u8bba\u8fb9\u754c\u7d27102-103\u500d\uff0c\u8fb9\u754c\u611f\u77e5\u5bf9\u6297\u653b\u51fb\u6210\u529f\u7387\u4e3a0%\uff0cQwen3-8B\u6a21\u578b\u8fd0\u884c\u65f6\u5f00\u9500\u4ec5\u4e3a0.3%\u3002", "conclusion": "NAO\u5728\u73b0\u5b9e\u4e16\u754c\u5f02\u6784ML\u8ba1\u7b97\u4e2d\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u6027\u4e0e\u53ef\u9a8c\u8bc1\u6027\u7684\u5e73\u8861\uff0c\u4e3aML\u670d\u52a1\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17110", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17110", "abs": "https://arxiv.org/abs/2510.17110", "authors": ["Xiaoyu Guo", "Shinobu Saito", "Jianjun Zhao"], "title": "M2QCode: A Model-Driven Framework for Generating Multi-Platform Quantum Programs", "comment": "This paper was accepted by ASE2025", "summary": "With the growing interest in quantum computing, the emergence of quantum\nsupremacy has marked a pivotal milestone in the field. As a result, numerous\nquantum programming languages (QPLs) have been introduced to support the\ndevelopment of quantum algorithms. However, the application of Model-Driven\nDevelopment (MDD) in quantum system engineering remains largely underexplored.\nThis paper presents an MDD-based approach to support the structured design and\nimplementation of quantum systems. Our framework enables the automatic\ngeneration of quantum code for multiple QPLs, thereby enhancing development\nefficiency and consistency across heterogeneous quantum platforms. The\neffectiveness and practicality of our approach have been demonstrated through\nmultiple case studies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u9a71\u52a8\u5f00\u53d1(MDD)\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u652f\u6301\u91cf\u5b50\u7cfb\u7edf\u7684\u7ed3\u6784\u5316\u8bbe\u8ba1\u548c\u5b9e\u73b0\uff0c\u80fd\u591f\u81ea\u52a8\u4e3a\u591a\u79cd\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\u751f\u6210\u4ee3\u7801\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u8ba1\u7b97\u7684\u53d1\u5c55\uff0c\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\u4e0d\u65ad\u6d8c\u73b0\uff0c\u4f46\u6a21\u578b\u9a71\u52a8\u5f00\u53d1\u5728\u91cf\u5b50\u7cfb\u7edf\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2aMDD\u6846\u67b6\uff0c\u652f\u6301\u4ece\u9ad8\u5c42\u6b21\u6a21\u578b\u81ea\u52a8\u751f\u6210\u591a\u79cd\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\u7684\u4ee3\u7801\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5MDD\u65b9\u6cd5\u80fd\u591f\u63d0\u9ad8\u91cf\u5b50\u7cfb\u7edf\u5f00\u53d1\u6548\u7387\uff0c\u5e76\u786e\u4fdd\u8de8\u5f02\u6784\u91cf\u5b50\u5e73\u53f0\u7684\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.16047", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16047", "abs": "https://arxiv.org/abs/2510.16047", "authors": ["Ioan Hedea"], "title": "Algorithms for dynamic scheduling in manufacturing, towards digital factories Improving Deadline Feasibility and Responsiveness via Temporal Networks", "comment": "8 pages 2 column, 11 figures. Bachelor's thesis", "summary": "Modern manufacturing systems must meet hard delivery deadlines while coping\nwith stochastic task durations caused by process noise, equipment variability,\nand human intervention. Traditional deterministic schedules break down when\nreality deviates from nominal plans, triggering costly last-minute repairs.\nThis thesis combines offline constraint-programming (CP) optimisation with\nonline temporal-network execution to create schedules that remain feasible\nunder worst-case uncertainty. First, we build a CP model of the flexible\njob-shop with per-job deadline tasks and insert an optimal buffer $\\Delta^*$ to\nobtain a fully pro-active baseline. We then translate the resulting plan into a\nSimple Temporal Network with Uncertainty (STNU) and verify dynamic\ncontrollability, which guarantees that a real-time dispatcher can retime\nactivities for every bounded duration realisation without violating resource or\ndeadline constraints. Extensive Monte-Carlo simulations on the open Kacem~1--4\nbenchmark suite show that our hybrid approach eliminates 100\\% of deadline\nviolations observed in state-of-the-art meta-heuristic schedules, while adding\nonly 3--5\\% makespan overhead. Scalability experiments confirm that CP\nsolve-times and STNU checks remain sub-second on medium-size instances. The\nwork demonstrates how temporal-network reasoning can bridge the gap between\nproactive buffering and dynamic robustness, moving industry a step closer to\ntruly digital, self-correcting factories.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u79bb\u7ebf\u7ea6\u675f\u7f16\u7a0b\u4f18\u5316\u548c\u5728\u7ebf\u65f6\u95f4\u7f51\u7edc\u6267\u884c\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u4e3a\u5177\u6709\u968f\u673a\u4efb\u52a1\u6301\u7eed\u65f6\u95f4\u7684\u5236\u9020\u7cfb\u7edf\u521b\u5efa\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u4ecd\u53ef\u884c\u7684\u8c03\u5ea6\u65b9\u6848\u3002", "motivation": "\u73b0\u4ee3\u5236\u9020\u7cfb\u7edf\u9700\u8981\u5728\u5e94\u5bf9\u968f\u673a\u4efb\u52a1\u6301\u7eed\u65f6\u95f4\u7684\u540c\u65f6\u6ee1\u8db3\u4e25\u683c\u7684\u4ea4\u4ed8\u671f\u9650\uff0c\u4f20\u7edf\u786e\u5b9a\u6027\u8c03\u5ea6\u5728\u73b0\u5b9e\u504f\u79bb\u540d\u4e49\u8ba1\u5212\u65f6\u4f1a\u5931\u6548\uff0c\u5bfc\u81f4\u6602\u8d35\u7684\u7d27\u6025\u4fee\u590d\u3002", "method": "\u9996\u5148\u6784\u5efa\u5177\u6709\u6bcf\u9879\u4efb\u52a1\u622a\u6b62\u671f\u9650\u7684\u67d4\u6027\u4f5c\u4e1a\u8f66\u95f4CP\u6a21\u578b\uff0c\u63d2\u5165\u6700\u4f18\u7f13\u51b2\u533a\u0394*\u83b7\u5f97\u5b8c\u5168\u4e3b\u52a8\u57fa\u7ebf\uff1b\u7136\u540e\u5c06\u7ed3\u679c\u8ba1\u5212\u8f6c\u6362\u4e3a\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u7684\u7b80\u5355\u65f6\u95f4\u7f51\u7edc\uff0c\u9a8c\u8bc1\u52a8\u6001\u53ef\u63a7\u6027\u3002", "result": "\u5728Kacem 1-4\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e0a\u7684\u8499\u7279\u5361\u6d1b\u6a21\u62df\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u6d88\u9664\u4e86100%\u7684\u622a\u6b62\u671f\u9650\u8fdd\u53cd\uff0c\u540c\u65f6\u4ec5\u589e\u52a03-5%\u7684\u5236\u9020\u5468\u671f\u5f00\u9500\uff1b\u53ef\u6269\u5c55\u6027\u5b9e\u9a8c\u8bc1\u5b9eCP\u6c42\u89e3\u65f6\u95f4\u548cSTNU\u68c0\u67e5\u5728\u4e2d\u7b49\u89c4\u6a21\u5b9e\u4f8b\u4e2d\u4fdd\u6301\u4e9a\u79d2\u7ea7\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86\u65f6\u95f4\u7f51\u7edc\u63a8\u7406\u5982\u4f55\u5f25\u5408\u4e3b\u52a8\u7f13\u51b2\u548c\u52a8\u6001\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4f7f\u884c\u4e1a\u66f4\u63a5\u8fd1\u771f\u6b63\u7684\u6570\u5b57\u5316\u3001\u81ea\u4fee\u6b63\u5de5\u5382\u3002"}}
{"id": "2510.16037", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16037", "abs": "https://arxiv.org/abs/2510.16037", "authors": ["Peini Cheng", "Amir Bahmani"], "title": "Membership Inference over Diffusion-models-based Synthetic Tabular Data", "comment": null, "summary": "This study investigates the privacy risks associated with diffusion-based\nsynthetic tabular data generation methods, focusing on their susceptibility to\nMembership Inference Attacks (MIAs). We examine two recent models, TabDDPM and\nTabSyn, by developing query-based MIAs based on the step-wise error comparison\nmethod. Our findings reveal that TabDDPM is more vulnerable to these attacks.\nTabSyn exhibits resilience against our attack models. Our work underscores the\nimportance of evaluating the privacy implications of diffusion models and\nencourages further research into robust privacy-preserving mechanisms for\nsynthetic data generation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e86\u57fa\u4e8e\u6269\u6563\u7684\u5408\u6210\u8868\u683c\u6570\u636e\u751f\u6210\u65b9\u6cd5\u7684\u9690\u79c1\u98ce\u9669\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002\u7814\u7a76\u53d1\u73b0TabDDPM\u6bd4TabSyn\u66f4\u5bb9\u6613\u53d7\u5230\u653b\u51fb\u3002", "motivation": "\u8bc4\u4f30\u6269\u6563\u6a21\u578b\u5728\u5408\u6210\u8868\u683c\u6570\u636e\u751f\u6210\u4e2d\u7684\u9690\u79c1\u5f71\u54cd\uff0c\u63ed\u793a\u8fd9\u4e9b\u65b9\u6cd5\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u9010\u6b65\u8bef\u5dee\u6bd4\u8f83\u65b9\u6cd5\u7684\u67e5\u8be2\u5f0f\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u6d4b\u8bd5TabDDPM\u548cTabSyn\u4e24\u79cd\u6a21\u578b\u3002", "result": "TabDDPM\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u8868\u73b0\u51fa\u8f83\u9ad8\u8106\u5f31\u6027\uff0c\u800cTabSyn\u5219\u5bf9\u8fd9\u4e9b\u653b\u51fb\u5177\u6709\u62b5\u6297\u529b\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u8bc4\u4f30\u6269\u6563\u6a21\u578b\u9690\u79c1\u5f71\u54cd\u7684\u91cd\u8981\u6027\uff0c\u9f13\u52b1\u8fdb\u4e00\u6b65\u7814\u7a76\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u9c81\u68d2\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u3002"}}
{"id": "2510.17130", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17130", "abs": "https://arxiv.org/abs/2510.17130", "authors": ["Shuzheng Gao", "Chaozheng Wang", "Cuiyun Gao", "Michael R. Lyu"], "title": "SEER: Enhancing Chain-of-Thought Code Generation through Self-Exploring Deep Reasoning", "comment": "The paper was completed in Feb. 2025, submitted to ICSE 2026 in Mar.\n  2025, received a major revision in Jun. 2025, and was finally accepted in\n  Oct. 2025", "summary": "Code generation, the task of creating executable programs from natural\nlanguage requirements, has recently seen tremendous advances through\nChain-of-Thought (CoT) reasoning, which enables Large Language Models (LLMs) to\ndevelop high-level reasoning plans before writing code. Recent research has\nproposed various methods to enhance models' CoT reasoning for code generation\nsuch as prompt engineering and supervised fine-tuning. However, existing\napproaches still face three critical limitations: (1) limited exploration of\ndiverse reasoning paths, which constrains generalization across various\nprogramming scenarios, (2) lack of quality assessment for intermediate\nreasoning steps, which hampers the reliability of the generated plans and code,\nand (3) the potential negative impact of \"overthinking\", potentially leading to\nunnecessarily complex and incorrect solutions. To address these limitations, we\nframe CoT code generation as a decision making problem and present SEER, a\nSElf-Exploring deep Reasoning framework that enables accurate and adaptive\nreasoning for code generation. SEER introduces three key components: (1)\nDiverse reasoning path exploration, which aims at exploring diverse reasoning\npaths and annotating intermediate steps without relying on manual experts or\nclosed-source proprietary models; (2) Reasoning quality-aware model training,\nwhich trains a policy model for generating candidate reasoning steps and a\nvalue model for assessing their quality; and (3) Adaptive CoT reasoning, which\ndynamically switches between direct generation and step-by-step reasoning for\ndifferent problems.", "AI": {"tldr": "SEER\u662f\u4e00\u4e2a\u81ea\u63a2\u7d22\u6df1\u5ea6\u63a8\u7406\u6846\u67b6\uff0c\u5c06\u4ee3\u7801\u751f\u6210\u7684\u601d\u7ef4\u94fe\u8fc7\u7a0b\u89c6\u4e3a\u51b3\u7b56\u95ee\u9898\uff0c\u901a\u8fc7\u63a2\u7d22\u591a\u6837\u5316\u63a8\u7406\u8def\u5f84\u3001\u8d28\u91cf\u611f\u77e5\u6a21\u578b\u8bad\u7ec3\u548c\u81ea\u9002\u5e94\u63a8\u7406\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u601d\u7ef4\u94fe\u63a8\u7406\u65b9\u6cd5\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u9650\u5236\uff1a\u63a8\u7406\u8def\u5f84\u591a\u6837\u6027\u4e0d\u8db3\u3001\u4e2d\u95f4\u6b65\u9aa4\u8d28\u91cf\u8bc4\u4f30\u7f3a\u5931\u3001\u4ee5\u53ca\"\u8fc7\u5ea6\u601d\u8003\"\u53ef\u80fd\u5bfc\u81f4\u590d\u6742\u9519\u8bef\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "SEER\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u591a\u6837\u5316\u63a8\u7406\u8def\u5f84\u63a2\u7d22\uff08\u65e0\u9700\u4e13\u5bb6\u6216\u95ed\u6e90\u6a21\u578b\uff09\u3001\u63a8\u7406\u8d28\u91cf\u611f\u77e5\u6a21\u578b\u8bad\u7ec3\uff08\u7b56\u7565\u6a21\u578b\u751f\u6210\u63a8\u7406\u6b65\u9aa4\uff0c\u4ef7\u503c\u6a21\u578b\u8bc4\u4f30\u8d28\u91cf\uff09\u3001\u81ea\u9002\u5e94\u601d\u7ef4\u94fe\u63a8\u7406\uff08\u6839\u636e\u95ee\u9898\u52a8\u6001\u5207\u6362\u751f\u6210\u65b9\u5f0f\uff09\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u66f4\u51c6\u786e\u548c\u81ea\u9002\u5e94\u7684\u4ee3\u7801\u751f\u6210\u63a8\u7406\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u63a8\u7406\u8def\u5f84\u5355\u4e00\u3001\u8d28\u91cf\u8bc4\u4f30\u7f3a\u5931\u548c\u8fc7\u5ea6\u601d\u8003\u7684\u95ee\u9898\u3002", "conclusion": "SEER\u901a\u8fc7\u5c06\u4ee3\u7801\u751f\u6210\u7684\u601d\u7ef4\u94fe\u8fc7\u7a0b\u6784\u5efa\u4e3a\u51b3\u7b56\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2510.16095", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16095", "abs": "https://arxiv.org/abs/2510.16095", "authors": ["Dou Liu", "Ying Long", "Sophia Zuoqiu", "Di Liu", "Kang Li", "Yiting Lin", "Hanyi Liu", "Rong Yin", "Tian Tang"], "title": "Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study", "comment": null, "summary": "Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for\nexplainable medical Artificial Intelligence (AI) while constrained by data\nscarcity. Although Large Language Models (LLMs) can synthesize medical data,\ntheir clinical reliability remains unverified. This study evaluates the\nreliability of LLM-generated CoTs and investigates prompting strategies to\nenhance their quality. In a blinded comparative study, senior clinicians in\nAssisted Reproductive Technology (ART) evaluated CoTs generated via three\ndistinct strategies: Zero-shot, Random Few-shot (using shallow examples), and\nSelective Few-shot (using diverse, high-quality examples). These expert ratings\nwere compared against evaluations from a state-of-the-art AI model (GPT-4o).\nThe Selective Few-shot strategy significantly outperformed other strategies\nacross all human evaluation metrics (p < .001). Critically, the Random Few-shot\nstrategy offered no significant improvement over the Zero-shot baseline,\ndemonstrating that low-quality examples are as ineffective as no examples. The\nsuccess of the Selective strategy is attributed to two principles:\n\"Gold-Standard Depth\" (reasoning quality) and \"Representative Diversity\"\n(generalization). Notably, the AI evaluator failed to discern these critical\nperformance differences. The clinical reliability of synthetic CoTs is dictated\nby strategic prompt curation, not the mere presence of examples. We propose a\n\"Dual Principles\" framework as a foundational methodology to generate\ntrustworthy data at scale. This work offers a validated solution to the data\nbottleneck and confirms the indispensable role of human expertise in evaluating\nhigh-stakes clinical AI.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86LLM\u751f\u6210\u7684\u4e34\u5e8a\u601d\u7ef4\u94fe\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u9009\u62e9\u6027\u5c11\u6837\u672c\u7b56\u7565\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c\u548c\u968f\u673a\u5c11\u6837\u672c\u7b56\u7565\uff0c\u63d0\u51fa\u57fa\u4e8e\"\u9ec4\u91d1\u6807\u51c6\u6df1\u5ea6\"\u548c\"\u4ee3\u8868\u6027\u591a\u6837\u6027\"\u7684\u53cc\u539f\u5219\u6846\u67b6\u6765\u751f\u6210\u53ef\u4fe1\u7684\u4e34\u5e8a\u6570\u636e\u3002", "motivation": "\u9ad8\u8d28\u91cf\u4e34\u5e8a\u601d\u7ef4\u94fe\u5bf9\u53ef\u89e3\u91ca\u533b\u7597AI\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u7684\u7ea6\u675f\u3002\u867d\u7136LLM\u80fd\u5408\u6210\u533b\u7597\u6570\u636e\uff0c\u4f46\u5176\u4e34\u5e8a\u53ef\u9760\u6027\u5c1a\u672a\u9a8c\u8bc1\u3002", "method": "\u5728\u8f85\u52a9\u751f\u6b96\u6280\u672f\u9886\u57df\u8fdb\u884c\u76f2\u6cd5\u6bd4\u8f83\u7814\u7a76\uff0c\u8d44\u6df1\u4e34\u5e8a\u533b\u751f\u8bc4\u4f30\u4e09\u79cd\u7b56\u7565\u751f\u6210\u7684\u601d\u7ef4\u94fe\uff1a\u96f6\u6837\u672c\u3001\u968f\u673a\u5c11\u6837\u672c\uff08\u4f7f\u7528\u6d45\u5c42\u793a\u4f8b\uff09\u548c\u9009\u62e9\u6027\u5c11\u6837\u672c\uff08\u4f7f\u7528\u591a\u6837\u5316\u9ad8\u8d28\u91cf\u793a\u4f8b\uff09\u3002", "result": "\u9009\u62e9\u6027\u5c11\u6837\u672c\u7b56\u7565\u5728\u6240\u6709\u4eba\u7c7b\u8bc4\u4f30\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u7b56\u7565\uff08p < .001\uff09\u3002\u968f\u673a\u5c11\u6837\u672c\u7b56\u7565\u76f8\u6bd4\u96f6\u6837\u672c\u57fa\u7ebf\u65e0\u663e\u8457\u6539\u8fdb\u3002AI\u8bc4\u4f30\u5668\u672a\u80fd\u8bc6\u522b\u8fd9\u4e9b\u5173\u952e\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u5408\u6210\u601d\u7ef4\u94fe\u7684\u4e34\u5e8a\u53ef\u9760\u6027\u53d6\u51b3\u4e8e\u7b56\u7565\u6027\u63d0\u793a\u8bcd\u4f18\u5316\uff0c\u800c\u975e\u4ec5\u4ec5\u63d0\u4f9b\u793a\u4f8b\u3002\u63d0\u51fa\"\u53cc\u539f\u5219\"\u6846\u67b6\u4f5c\u4e3a\u751f\u6210\u53ef\u4fe1\u6570\u636e\u7684\u57fa\u7840\u65b9\u6cd5\uff0c\u786e\u8ba4\u4e86\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u5728\u9ad8\u98ce\u9669\u4e34\u5e8aAI\u8bc4\u4f30\u4e2d\u7684\u4e0d\u53ef\u6216\u7f3a\u4f5c\u7528\u3002"}}
{"id": "2510.16044", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16044", "abs": "https://arxiv.org/abs/2510.16044", "authors": ["Zeng Zhang", "Wenjie Yin", "Xiaoqi Li"], "title": "A Novel GPT-Based Framework for Anomaly Detection in System Logs", "comment": null, "summary": "Identification of anomalous events within system logs constitutes a pivotal\nelement within the frame- work of cybersecurity defense strategies. However,\nthis process faces numerous challenges, including the management of substantial\ndata volumes, the distribution of anomalies, and the precision of con-\nventional methods. To address this issue, the present paper puts forward a\nproposal for an intelligent detection method for system logs based on Genera-\ntive Pre-trained Transformers (GPT). The efficacy of this approach is\nattributable to a combination of structured input design and a Focal Loss op-\ntimization strategy, which collectively result in a substantial enhancement of\nthe performance of log anomaly detection. The initial approach involves the\nconversion of raw logs into event ID sequences through the use of the Drain\nparser. Subsequently, the Focal Loss loss function is employed to address the\nissue of class imbalance. The experimental re- sults demonstrate that the\noptimized GPT-2 model significantly outperforms the unoptimized model in a\nrange of key metrics, including precision, recall, and F1 score. In specific\ntasks, comparable or superior performance has been demonstrated to that of the\nGPT-3.5 API.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eGPT\u7684\u667a\u80fd\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8f93\u5165\u8bbe\u8ba1\u548cFocal Loss\u4f18\u5316\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd", "motivation": "\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u9762\u4e34\u5927\u6570\u636e\u91cf\u3001\u5f02\u5e38\u5206\u5e03\u4e0d\u5747\u548c\u4f20\u7edf\u65b9\u6cd5\u7cbe\u5ea6\u4e0d\u8db3\u7b49\u6311\u6218\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u4f7f\u7528Drain\u89e3\u6790\u5668\u5c06\u539f\u59cb\u65e5\u5fd7\u8f6c\u6362\u4e3a\u4e8b\u4ef6ID\u5e8f\u5217\uff0c\u91c7\u7528Focal Loss\u635f\u5931\u51fd\u6570\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u4f18\u5316GPT-2\u6a21\u578b", "result": "\u4f18\u5316\u540e\u7684GPT-2\u6a21\u578b\u5728\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u7b49\u5173\u952e\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u672a\u4f18\u5316\u6a21\u578b\uff0c\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u6027\u80fd\u4e0eGPT-3.5 API\u76f8\u5f53\u6216\u66f4\u4f18", "conclusion": "\u57fa\u4e8eGPT\u7684\u667a\u80fd\u68c0\u6d4b\u65b9\u6cd5\u7ed3\u5408\u7ed3\u6784\u5316\u8f93\u5165\u548cFocal Loss\u4f18\u5316\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u7684\u6027\u80fd"}}
{"id": "2510.17142", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17142", "abs": "https://arxiv.org/abs/2510.17142", "authors": ["Xiaoxue Ren", "Jun Wan", "Yun Peng", "Zhongxin Liu", "Ming Liang", "Dajun Chen", "Wei Jiang", "Yong Li"], "title": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant capability in code\ngeneration, but their potential in code efficiency optimization remains\nunderexplored. Previous LLM-based code efficiency optimization approaches\nexclusively focus on function-level optimization and overlook interaction\nbetween functions, failing to generalize to real-world development scenarios.\nCode editing techniques show great potential for conducting project-level\noptimization, yet they face challenges associated with invalid edits and\nsuboptimal internal functions. To address these gaps, we propose Peace, a novel\nhybrid framework for Project-level code Efficiency optimization through\nAutomatic Code Editing, which also ensures the overall correctness and\nintegrity of the project. Peace integrates three key phases: dependency-aware\noptimizing function sequence construction, valid associated edits\nidentification, and efficiency optimization editing iteration. To rigorously\nevaluate the effectiveness of Peace, we construct PeacExec, the first benchmark\ncomprising 146 real-world optimization tasks from 47 high-impact GitHub Python\nprojects, along with highly qualified test cases and executable environments.\nExtensive experiments demonstrate Peace's superiority over the state-of-the-art\nbaselines, achieving a 69.2% correctness rate (pass@1), +46.9% opt rate, and\n0.840 speedup in execution efficiency. Notably, our Peace outperforms all\nbaselines by significant margins, particularly in complex optimization tasks\nwith multiple functions. Moreover, extensive experiments are also conducted to\nvalidate the contributions of each component in Peace, as well as the rationale\nand effectiveness of our hybrid framework design.", "AI": {"tldr": "\u63d0\u51fa\u4e86Peace\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u4ee3\u7801\u7f16\u8f91\u8fdb\u884c\u9879\u76ee\u7ea7\u4ee3\u7801\u6548\u7387\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u51fd\u6570\u7ea7\u4f18\u5316\u548c\u5ffd\u7565\u51fd\u6570\u95f4\u4ea4\u4e92\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u5728\u4ee3\u7801\u6548\u7387\u4f18\u5316\u65b9\u9762\u4e3b\u8981\u5173\u6ce8\u51fd\u6570\u7ea7\u4f18\u5316\uff0c\u5ffd\u89c6\u4e86\u51fd\u6570\u95f4\u7684\u4ea4\u4e92\uff0c\u65e0\u6cd5\u9002\u5e94\u771f\u5b9e\u5f00\u53d1\u573a\u666f\u3002\u4ee3\u7801\u7f16\u8f91\u6280\u672f\u6709\u6f5c\u529b\u8fdb\u884c\u9879\u76ee\u7ea7\u4f18\u5316\uff0c\u4f46\u9762\u4e34\u65e0\u6548\u7f16\u8f91\u548c\u6b21\u4f18\u5185\u90e8\u51fd\u6570\u7684\u6311\u6218\u3002", "method": "Peace\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u5173\u952e\u9636\u6bb5\uff1a\u4f9d\u8d56\u611f\u77e5\u7684\u4f18\u5316\u51fd\u6570\u5e8f\u5217\u6784\u5efa\u3001\u6709\u6548\u5173\u8054\u7f16\u8f91\u8bc6\u522b\u3001\u6548\u7387\u4f18\u5316\u7f16\u8f91\u8fed\u4ee3\u3002\u8be5\u6df7\u5408\u6846\u67b6\u786e\u4fdd\u9879\u76ee\u7684\u6574\u4f53\u6b63\u786e\u6027\u548c\u5b8c\u6574\u6027\u3002", "result": "\u5728PeacExec\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPeace\u5728146\u4e2a\u771f\u5b9e\u4f18\u5316\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8fbe\u523069.2%\u6b63\u786e\u7387\u3001+46.9%\u4f18\u5316\u7387\u548c0.840\u6267\u884c\u6548\u7387\u52a0\u901f\u6bd4\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Peace\u6846\u67b6\u5728\u9879\u76ee\u7ea7\u4ee3\u7801\u6548\u7387\u4f18\u5316\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u591a\u4e2a\u51fd\u6570\u7684\u590d\u6742\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u9a8c\u8bc1\u4e86\u6df7\u5408\u6846\u67b6\u8bbe\u8ba1\u7684\u5408\u7406\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2510.16193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16193", "abs": "https://arxiv.org/abs/2510.16193", "authors": ["Elija Perrier"], "title": "Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability", "comment": "Under review", "summary": "Corporate responsibility turns on notions of corporate \\textit{mens rea},\ntraditionally imputed from human agents. Yet these assumptions are under\nchallenge as generative AI increasingly mediates enterprise decision-making.\nBuilding on the theory of extended cognition, we argue that in response\ncorporate knowledge may be redefined as a dynamic capability, measurable by the\nefficiency of its information-access procedures and the validated reliability\nof their outputs. We develop a formal model that captures epistemic states of\ncorporations deploying sophisticated AI or information systems, introducing a\ncontinuous organisational knowledge metric $S_S(\\varphi)$ which integrates a\npipeline's computational cost and its statistically validated error rate. We\nderive a thresholded knowledge predicate $\\mathsf{K}_S$ to impute knowledge and\na firm-wide epistemic capacity index $\\mathcal{K}_{S,t}$ to measure overall\ncapability. We then operationally map these quantitative metrics onto the legal\nstandards of actual knowledge, constructive knowledge, wilful blindness, and\nrecklessness. Our work provides a pathway towards creating measurable and\njusticiable audit artefacts, that render the corporate mind tractable and\naccountable in the algorithmic age.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6269\u5c55\u8ba4\u77e5\u7406\u8bba\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u5c06\u4f01\u4e1a\u77e5\u8bc6\u91cd\u65b0\u5b9a\u4e49\u4e3a\u53ef\u6d4b\u91cf\u7684\u52a8\u6001\u80fd\u529b\uff0c\u901a\u8fc7\u4fe1\u606f\u8bbf\u95ee\u7a0b\u5e8f\u7684\u6548\u7387\u548c\u8f93\u51fa\u53ef\u9760\u6027\u6765\u91cf\u5316\uff0c\u4e3aAI\u65f6\u4ee3\u7684\u4f01\u4e1a\u8d23\u4efb\u8ba4\u5b9a\u63d0\u4f9b\u53ef\u5ba1\u8ba1\u7684\u5ea6\u91cf\u6807\u51c6\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u4f01\u4e1a\u51b3\u7b56\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f20\u7edf\u57fa\u4e8e\u4eba\u7c7b\u4ee3\u7406\u7684\u4f01\u4e1a\u72af\u7f6a\u610f\u56fe\u8ba4\u5b9a\u5047\u8bbe\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u91cd\u65b0\u5b9a\u4e49\u4f01\u4e1a\u77e5\u8bc6\u7684\u6982\u5ff5\u4ee5\u9002\u5e94\u7b97\u6cd5\u65f6\u4ee3\u3002", "method": "\u57fa\u4e8e\u6269\u5c55\u8ba4\u77e5\u7406\u8bba\u5f00\u53d1\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u5f15\u5165\u8fde\u7eed\u7ec4\u7ec7\u77e5\u8bc6\u5ea6\u91cfS_S(\u03c6)\uff0c\u6574\u5408\u8ba1\u7b97\u6210\u672c\u548c\u7edf\u8ba1\u9a8c\u8bc1\u9519\u8bef\u7387\uff0c\u63a8\u5bfc\u77e5\u8bc6\u8c13\u8bcdK_S\u548c\u4f01\u4e1a\u8303\u56f4\u8ba4\u77e5\u80fd\u529b\u6307\u6570K_{S,t}\u3002", "result": "\u5efa\u7acb\u4e86\u5c06\u5b9a\u91cf\u6307\u6807\u6620\u5c04\u5230\u6cd5\u5f8b\u6807\u51c6\uff08\u5b9e\u9645\u77e5\u8bc6\u3001\u63a8\u5b9a\u77e5\u8bc6\u3001\u6545\u610f\u5ffd\u89c6\u548c\u9c81\u83bd\uff09\u7684\u64cd\u4f5c\u6846\u67b6\uff0c\u521b\u5efa\u4e86\u53ef\u6d4b\u91cf\u548c\u53ef\u5ba1\u5224\u7684\u5ba1\u8ba1\u5de5\u4ef6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u7b97\u6cd5\u65f6\u4ee3\u4f7f\u4f01\u4e1a\u601d\u7ef4\u53d8\u5f97\u53ef\u8ffd\u8e2a\u548c\u53ef\u95ee\u8d23\u63d0\u4f9b\u4e86\u8def\u5f84\uff0c\u901a\u8fc7\u91cf\u5316\u65b9\u6cd5\u4f7f\u4f01\u4e1a\u77e5\u8bc6\u72b6\u6001\u5728\u6cd5\u5f8b\u4e0a\u53ef\u64cd\u4f5c\u3002"}}
{"id": "2510.16054", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16054", "abs": "https://arxiv.org/abs/2510.16054", "authors": ["Zheng Hui", "Yijiang River Dong", "Sanhanat Sivapiromrat", "Ehsan Shareghi", "Nigel Collier"], "title": "PrivacyPAD: A Reinforcement Learning Framework for Dynamic Privacy-Aware Delegation", "comment": null, "summary": "When users submit queries to Large Language Models (LLMs), their prompts can\noften contain sensitive data, forcing a difficult choice: Send the query to a\npowerful proprietary LLM providers to achieving state-of-the-art performance\nand risk data exposure, or relying on smaller, local models guarantees data\nprivacy but often results in a degradation of task performance. Prior\napproaches have relied on static pipelines that use LLM rewriting, which\nshatters linguistic coherence and indiscriminately removes privacy-sensitive\ninformation, including task-critical content. We reformulate this challenge\n(Privacy-Conscious Delegation) as a sequential decision-making problem and\nintroduce a novel reinforcement learning (RL) framework called PrivacyPAD to\nsolve it. Our framework trains an agent to dynamically route text chunks,\nlearning a policy that optimally balances the trade-off between privacy leakage\nand task performance. It implicitly distinguishes between replaceable\nPersonally Identifiable Information (PII) (which it shields locally) and\ntask-critical PII (which it strategically sends to the remote model for maximal\nutility). To validate our approach in complex scenarios, we also introduce a\nnew medical dataset with high PII density. Our framework achieves a new\nstate-of-the-art on the privacy-utility frontier, demonstrating the necessity\nof learned, adaptive policies for deploying LLMs in sensitive environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86PrivacyPAD\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u8def\u7531\u6587\u672c\u5757\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u548c\u4efb\u52a1\u6027\u80fd\u4e4b\u95f4\u5b9e\u73b0\u6700\u4f18\u5e73\u8861\u3002", "motivation": "\u7528\u6237\u5728\u5411\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4ea4\u67e5\u8be2\u65f6\u9762\u4e34\u4e24\u96be\u9009\u62e9\uff1a\u4f7f\u7528\u5f3a\u5927\u7684\u4e13\u6709\u6a21\u578b\u4f46\u53ef\u80fd\u6cc4\u9732\u654f\u611f\u6570\u636e\uff0c\u6216\u4f7f\u7528\u672c\u5730\u5c0f\u6a21\u578b\u4fdd\u8bc1\u9690\u79c1\u4f46\u6027\u80fd\u4e0b\u964d\u3002\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u9759\u6001\u7ba1\u9053\uff0c\u7834\u574f\u4e86\u8bed\u8a00\u8fde\u8d2f\u6027\u4e14\u65e0\u5dee\u522b\u5220\u9664\u9690\u79c1\u4fe1\u606f\u3002", "method": "\u5c06\u9690\u79c1\u4fdd\u62a4\u59d4\u6258\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u5f15\u5165\u5f3a\u5316\u5b66\u4e60\u6846\u67b6PrivacyPAD\uff0c\u8bad\u7ec3\u667a\u80fd\u4f53\u52a8\u6001\u8def\u7531\u6587\u672c\u5757\uff0c\u5b66\u4e60\u533a\u5206\u53ef\u66ff\u6362\u7684\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\uff08\u672c\u5730\u5904\u7406\uff09\u548c\u4efb\u52a1\u5173\u952e\u4fe1\u606f\uff08\u8fdc\u7a0b\u5904\u7406\uff09\u7684\u7b56\u7565\u3002", "result": "\u5728\u9690\u79c1-\u6548\u7528\u8fb9\u754c\u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u9a8c\u8bc1\u4e86\u5728\u654f\u611f\u73af\u5883\u4e2d\u90e8\u7f72LLM\u65f6\u9700\u8981\u5b66\u4e60\u81ea\u9002\u5e94\u7b56\u7565\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "PrivacyPAD\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u548c\u4efb\u52a1\u6027\u80fd\u7684\u6700\u4f73\u5e73\u8861\uff0c\u4e3a\u5728\u654f\u611f\u73af\u5883\u4e2d\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17163", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17163", "abs": "https://arxiv.org/abs/2510.17163", "authors": ["Shuzheng Gao", "Eric John Li", "Man Ho Lam", "Jingyu Xiao", "Yuxuan Wan", "Chaozheng Wang", "Ng Man Tik", "Michael R. Lyu"], "title": "TREAT: A Code LLMs Trustworthiness / Reliability Evaluation and Testing Framework", "comment": null, "summary": "Large foundation models are fundamentally transforming the software\nengineering landscape, demonstrating exceptional capabilities across diverse\ntasks such as code generation, debugging, and testing. Despite this rapid\nprogress, a significant gap remains in how to comprehensively evaluate these\nmodels' trustworthiness in real-world software engineering scenarios. Existing\nbenchmarks suffer from limited task scope and fail to incorporate critical\nevaluation aspects such as the robustness and reliability of models. To bridge\nthis gap, we present an evaluation framework called TREAT (Code LLMs\nTrustworthiness / Reliability Evaluation And Testing) that provides a holistic\nassessment of model performance in code intelligence tasks. Our evaluation\nframework addresses key limitations in existing approaches with four main\nimprovements: (1) Multi-Task Holistic Evaluation that spans diverse software\nengineering activities rather than limited coding tasks; (2) Multi-Language and\nMulti-Modality Assessment that extends beyond traditional single-language,\ntext-only benchmarks to include multi-modality coding tasks; (3) Robustness\nAssessment that evaluates model reliability under semantically-preserving code\ntransformations; and (4) Rigorous Evaluation Methodology that enhances the\ntrustworthiness of evaluation results through diverse evaluation prompts and\nadaptive solution extraction. Based on this evaluation framework, we assess 26\nstate-of-the-art models and uncover both their strengths and limitations,\nyielding several key insights:(1) Current models show substantial performance\nvariation across programming tasks; (2) Multi-modal language models demonstrate\nspecific performance limitations in UI code generation and edit;", "AI": {"tldr": "\u63d0\u51fa\u4e86TREAT\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30\u4ee3\u7801\u5927\u6a21\u578b\u5728\u771f\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u573a\u666f\u4e2d\u7684\u53ef\u4fe1\u5ea6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u4efb\u52a1\u8303\u56f4\u3001\u591a\u8bed\u8a00\u591a\u6a21\u6001\u3001\u9c81\u68d2\u6027\u548c\u8bc4\u4f30\u65b9\u6cd5\u7b49\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u6a21\u578b\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u4efb\u52a1\u8303\u56f4\u6709\u9650\u3001\u7f3a\u4e4f\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u8bc4\u4f30\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u5168\u9762\u8861\u91cf\u6a21\u578b\u5728\u771f\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u573a\u666f\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u5f00\u53d1\u4e86TREAT\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u4e3b\u8981\u6539\u8fdb\uff1a\u591a\u4efb\u52a1\u5168\u9762\u8bc4\u4f30\u3001\u591a\u8bed\u8a00\u591a\u6a21\u6001\u8bc4\u4f30\u3001\u9c81\u68d2\u6027\u8bc4\u4f30\uff08\u8bed\u4e49\u4fdd\u6301\u7684\u4ee3\u7801\u8f6c\u6362\uff09\u548c\u4e25\u683c\u7684\u8bc4\u4f30\u65b9\u6cd5\uff08\u591a\u6837\u5316\u63d0\u793a\u548c\u81ea\u9002\u5e94\u89e3\u51b3\u65b9\u6848\u63d0\u53d6\uff09\u3002", "result": "\u8bc4\u4f30\u4e8626\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u53d1\u73b0\uff1a\u5f53\u524d\u6a21\u578b\u5728\u4e0d\u540c\u7f16\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff1b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5728UI\u4ee3\u7801\u751f\u6210\u548c\u7f16\u8f91\u65b9\u9762\u5b58\u5728\u7279\u5b9a\u6027\u80fd\u9650\u5236\u3002", "conclusion": "TREAT\u6846\u67b6\u4e3a\u4ee3\u7801\u5927\u6a21\u578b\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02\u548c\u7279\u5b9a\u9650\u5236\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.16194", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16194", "abs": "https://arxiv.org/abs/2510.16194", "authors": ["Guanchen Wu", "Zuhui Chen", "Yuzhang Xie", "Carl Yang"], "title": "Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration", "comment": "Agents4Science 2025 (Spotlight)", "summary": "Protected health information (PHI) de-identification is critical for enabling\nthe safe reuse of clinical notes, yet evaluating and comparing PHI\nde-identification models typically depends on costly, small-scale expert\nannotations. We present TEAM-PHI, a multi-agent evaluation and selection\nframework that uses large language models (LLMs) to automatically measure\nde-identification quality and select the best-performing model without heavy\nreliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each\nindependently judging the correctness of PHI extractions and outputting\nstructured metrics. Their results are then consolidated through an LLM-based\nmajority voting mechanism that integrates diverse evaluator perspectives into a\nsingle, stable, and reproducible ranking. Experiments on a real-world clinical\nnote corpus demonstrate that TEAM-PHI produces consistent and accurate\nrankings: despite variation across individual evaluators, LLM-based voting\nreliably converges on the same top-performing systems. Further comparison with\nground-truth annotations and human evaluation confirms that the framework's\nautomated rankings closely match supervised evaluation. By combining\nindependent evaluation agents with LLM majority voting, TEAM-PHI offers a\npractical, secure, and cost-effective solution for automatic evaluation and\nbest-model selection in PHI de-identification, even when ground-truth labels\nare limited.", "AI": {"tldr": "TEAM-PHI\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u8bc4\u4f30PHI\u53bb\u6807\u8bc6\u5316\u6a21\u578b\u7684\u8d28\u91cf\u5e76\u9009\u62e9\u6700\u4f73\u6a21\u578b\uff0c\u65e0\u9700\u4f9d\u8d56\u6602\u8d35\u7684\u4e13\u5bb6\u6807\u6ce8\u3002", "motivation": "PHI\u53bb\u6807\u8bc6\u5316\u5bf9\u4e8e\u4e34\u5e8a\u7b14\u8bb0\u7684\u5b89\u5168\u91cd\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u6210\u672c\u9ad8\u6602\u7684\u5c0f\u89c4\u6a21\u4e13\u5bb6\u6807\u6ce8\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6bd4\u8f83\u548c\u9009\u62e9\u3002", "method": "\u90e8\u7f72\u591a\u4e2a\u8bc4\u4f30\u667a\u80fd\u4f53\u72ec\u7acb\u5224\u65adPHI\u63d0\u53d6\u7684\u6b63\u786e\u6027\uff0c\u7136\u540e\u901a\u8fc7\u57fa\u4e8eLLM\u7684\u591a\u6570\u6295\u7968\u673a\u5236\u6574\u5408\u8bc4\u4f30\u7ed3\u679c\uff0c\u751f\u6210\u7a33\u5b9a\u53ef\u590d\u73b0\u7684\u6a21\u578b\u6392\u540d\u3002", "result": "\u5728\u771f\u5b9e\u4e34\u5e8a\u7b14\u8bb0\u8bed\u6599\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTEAM-PHI\u80fd\u4ea7\u751f\u4e00\u81f4\u51c6\u786e\u7684\u6a21\u578b\u6392\u540d\uff0c\u4e0e\u6709\u76d1\u7763\u8bc4\u4f30\u548c\u4eba\u5de5\u8bc4\u4f30\u7ed3\u679c\u9ad8\u5ea6\u5339\u914d\u3002", "conclusion": "TEAM-PHI\u901a\u8fc7\u7ed3\u5408\u72ec\u7acb\u8bc4\u4f30\u667a\u80fd\u4f53\u548cLLM\u591a\u6570\u6295\u7968\uff0c\u4e3aPHI\u53bb\u6807\u8bc6\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u3001\u5b89\u5168\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u81ea\u52a8\u8bc4\u4f30\u548c\u6700\u4f73\u6a21\u578b\u9009\u62e9\u65b9\u6848\u3002"}}
{"id": "2510.16067", "categories": ["cs.CR", "cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.16067", "abs": "https://arxiv.org/abs/2510.16067", "authors": ["Saurabh Deochake", "Ryan Murphy", "Jeremiah Gearheart"], "title": "A Multi-Cloud Framework for Zero-Trust Workload Authentication", "comment": "Cyber Security Experimentation and Test (CSET) at the Annual Computer\n  Security Applications Conference (ACSAC) 2025", "summary": "Static, long-lived credentials for workload authentication create untenable\nsecurity risks that violate Zero-Trust principles. This paper presents a\nmulti-cloud framework using Workload Identity Federation (WIF) and OpenID\nConnect (OIDC) for secretless authentication. Our approach uses\ncryptographically-verified, ephemeral tokens, allowing workloads to\nauthenticate without persistent private keys and mitigating credential theft.\nWe validate this framework in an enterprise-scale Kubernetes environment, which\nsignificantly reduces the attack surface. The model offers a unified solution\nto manage workload identities across disparate clouds, enabling future\nimplementation of robust, attribute-based access control.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5de5\u4f5c\u8d1f\u8f7d\u8eab\u4efd\u8054\u76df\u548cOpenID Connect\u7684\u65e0\u5bc6\u94a5\u8ba4\u8bc1\u6846\u67b6\uff0c\u4f7f\u7528\u52a0\u5bc6\u9a8c\u8bc1\u7684\u4e34\u65f6\u4ee4\u724c\u66ff\u4ee3\u9759\u6001\u957f\u671f\u51ed\u8bc1\uff0c\u5728\u591a\u4e91\u73af\u5883\u4e2d\u5b9e\u73b0\u96f6\u4fe1\u4efb\u5b89\u5168\u3002", "motivation": "\u9759\u6001\u957f\u671f\u51ed\u8bc1\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u8fdd\u53cd\u96f6\u4fe1\u4efb\u539f\u5219\uff0c\u9700\u8981\u6d88\u9664\u51ed\u8bc1\u76d7\u7a83\u5a01\u80c1\u5e76\u51cf\u5c11\u653b\u51fb\u9762\u3002", "method": "\u4f7f\u7528\u5de5\u4f5c\u8d1f\u8f7d\u8eab\u4efd\u8054\u76df\u548cOpenID Connect\u6784\u5efa\u591a\u4e91\u6846\u67b6\uff0c\u901a\u8fc7\u52a0\u5bc6\u9a8c\u8bc1\u7684\u4e34\u65f6\u4ee4\u724c\u5b9e\u73b0\u65e0\u5bc6\u94a5\u8ba4\u8bc1\u3002", "result": "\u5728\u4f01\u4e1a\u7ea7Kubernetes\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u653b\u51fb\u9762\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u8de8\u4e0d\u540c\u4e91\u73af\u5883\u7ba1\u7406\u5de5\u4f5c\u8d1f\u8f7d\u8eab\u4efd\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u5b9e\u73b0\u57fa\u4e8e\u5c5e\u6027\u7684\u8bbf\u95ee\u63a7\u5236\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.17164", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17164", "abs": "https://arxiv.org/abs/2510.17164", "authors": ["Maria Deolinda Santana", "Cleyton Magalhaes", "Ronnie de Souza Santos"], "title": "Software Testing with Large Language Models: An Interview Study with Practitioners", "comment": null, "summary": "\\textit{Background:} The use of large language models in software testing is\ngrowing fast as they support numerous tasks, from test case generation to\nautomation, and documentation. However, their adoption often relies on informal\nexperimentation rather than structured guidance. \\textit{Aims:} This study\ninvestigates how software testing professionals use LLMs in practice to propose\na preliminary, practitioner-informed guideline to support their integration\ninto testing workflows. \\textit{Method:} We conducted a qualitative study with\n15 software testers from diverse roles and domains. Data were collected through\nsemi-structured interviews and analyzed using grounded theory-based processes\nfocused on thematic analysis. \\textit{Results:} Testers described an iterative\nand reflective process that included defining testing objectives, applying\nprompt engineering strategies, refining prompts, evaluating outputs, and\nlearning over time. They emphasized the need for human oversight and careful\nvalidation, especially due to known limitations of LLMs such as hallucinations\nand inconsistent reasoning. \\textit{Conclusions:} LLM adoption in software\ntesting is growing, but remains shaped by evolving practices and caution around\nrisks. This study offers a starting point for structuring LLM use in testing\ncontexts and invites future research to refine these practices across teams,\ntools, and tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5b9a\u6027\u8bbf\u8c08\u8c03\u67e5\u4e86\u8f6f\u4ef6\u6d4b\u8bd5\u4e13\u4e1a\u4eba\u5458\u5982\u4f55\u4f7f\u7528LLMs\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5b9e\u8df5\u8005\u7ecf\u9a8c\u7684\u521d\u6b65\u6307\u5bfc\u65b9\u9488\uff0c\u5f3a\u8c03\u8fed\u4ee3\u5f0f\u63d0\u793a\u5de5\u7a0b\u3001\u4eba\u5de5\u76d1\u7763\u548c\u9a8c\u8bc1\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740LLMs\u5728\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u7684\u5feb\u901f\u5e94\u7528\uff0c\u76ee\u524d\u7f3a\u4e4f\u7ed3\u6784\u5316\u6307\u5bfc\uff0c\u4e3b\u8981\u4f9d\u8d56\u975e\u6b63\u5f0f\u5b9e\u9a8c\u3002\u672c\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u6d4b\u8bd5\u4e13\u4e1a\u4eba\u5458\u5b9e\u9645\u4f7f\u7528LLMs\u7684\u65b9\u5f0f\uff0c\u4e3a\u5c06\u5176\u6574\u5408\u5230\u6d4b\u8bd5\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u5b9e\u8df5\u8005\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u5b9a\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u5bf915\u540d\u6765\u81ea\u4e0d\u540c\u89d2\u8272\u548c\u9886\u57df\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u4eba\u5458\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u4f7f\u7528\u57fa\u4e8e\u624e\u6839\u7406\u8bba\u7684\u4e3b\u9898\u5206\u6790\u8fc7\u7a0b\u5206\u6790\u6570\u636e\u3002", "result": "\u6d4b\u8bd5\u4eba\u5458\u63cf\u8ff0\u4e86\u4e00\u4e2a\u8fed\u4ee3\u548c\u53cd\u601d\u7684\u8fc7\u7a0b\uff0c\u5305\u62ec\u5b9a\u4e49\u6d4b\u8bd5\u76ee\u6807\u3001\u5e94\u7528\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u3001\u4f18\u5316\u63d0\u793a\u3001\u8bc4\u4f30\u8f93\u51fa\u548c\u6301\u7eed\u5b66\u4e60\u3002\u4ed6\u4eec\u5f3a\u8c03\u9700\u8981\u4eba\u5de5\u76d1\u7763\u548c\u4ed4\u7ec6\u9a8c\u8bc1\uff0c\u7279\u522b\u662f\u8003\u8651\u5230LLMs\u7684\u5e7b\u89c9\u548c\u4e0d\u4e00\u81f4\u63a8\u7406\u7b49\u5df2\u77e5\u9650\u5236\u3002", "conclusion": "LLMs\u5728\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\u6b63\u5728\u589e\u957f\uff0c\u4f46\u4ecd\u53d7\u5230\u5b9e\u8df5\u6f14\u53d8\u548c\u5bf9\u98ce\u9669\u8c28\u614e\u6001\u5ea6\u7684\u5f71\u54cd\u3002\u672c\u7814\u7a76\u4e3a\u5728\u6d4b\u8bd5\u73af\u5883\u4e2d\u7ed3\u6784\u5316\u4f7f\u7528LLMs\u63d0\u4f9b\u4e86\u8d77\u70b9\uff0c\u5e76\u9080\u8bf7\u672a\u6765\u7814\u7a76\u5728\u4e0d\u540c\u56e2\u961f\u3001\u5de5\u5177\u548c\u4efb\u52a1\u4e2d\u5b8c\u5584\u8fd9\u4e9b\u5b9e\u8df5\u3002"}}
{"id": "2510.16206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16206", "abs": "https://arxiv.org/abs/2510.16206", "authors": ["Alex Zhavoronkov", "Dominika Wilczok", "Roman Yampolskiy"], "title": "The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI", "comment": null, "summary": "Since the rapid expansion of large language models (LLMs), people have begun\nto rely on them for information retrieval. While traditional search engines\ndisplay ranked lists of sources shaped by search engine optimization (SEO),\nadvertising, and personalization, LLMs typically provide a synthesized response\nthat feels singular and authoritative. While both approaches carry risks of\nbias and omission, LLMs may amplify the effect by collapsing multiple\nperspectives into one answer, reducing users ability or inclination to compare\nalternatives. This concentrates power over information in a few LLM vendors\nwhose systems effectively shape what is remembered and what is overlooked. As a\nresult, certain narratives, individuals or groups, may be disproportionately\nsuppressed, while others are disproportionately elevated. Over time, this\ncreates a new threat: the gradual erasure of those with limited digital\npresence, and the amplification of those already prominent, reshaping\ncollective memory.To address these concerns, this paper presents a concept of\nthe Right To Be Remembered (RTBR) which encompasses minimizing the risk of\nAI-driven information omission, embracing the right of fair treatment, while\nensuring that the generated content would be maximally truthful.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\"\u88ab\u8bb0\u4f4f\u6743\"\u6982\u5ff5\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u5bfc\u81f4\u4fe1\u606f\u504f\u89c1\u548c\u96c6\u4f53\u8bb0\u5fc6\u91cd\u5851\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4fe1\u606f\u68c0\u7d22\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5c06\u591a\u5143\u89c6\u89d2\u5408\u6210\u4e3a\u5355\u4e00\u6743\u5a01\u7b54\u6848\u7684\u505a\u6cd5\u53ef\u80fd\u653e\u5927\u504f\u89c1\u98ce\u9669\uff0c\u5bfc\u81f4\u67d0\u4e9b\u7fa4\u4f53\u88ab\u538b\u5236\u800c\u5176\u4ed6\u7fa4\u4f53\u88ab\u8fc7\u5ea6\u653e\u5927\uff0c\u5a01\u80c1\u96c6\u4f53\u8bb0\u5fc6\u7684\u591a\u6837\u6027\u3002", "method": "\u63d0\u51fa\"\u88ab\u8bb0\u4f4f\u6743\"\u6982\u5ff5\u6846\u67b6\uff0c\u5305\u62ec\u6700\u5c0f\u5316AI\u9a71\u52a8\u4fe1\u606f\u9057\u6f0f\u98ce\u9669\u3001\u786e\u4fdd\u516c\u5e73\u5bf9\u5f85\u6743\u5229\uff0c\u540c\u65f6\u4fdd\u8bc1\u751f\u6210\u5185\u5bb9\u6700\u5927\u7a0b\u5ea6\u771f\u5b9e\u3002", "result": "\u5efa\u7acb\u4e86\u5e94\u5bf9LLMs\u4fe1\u606f\u96c6\u4e2d\u5316\u5a01\u80c1\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u4fdd\u62a4\u6570\u5b57\u5b58\u5728\u6709\u9650\u7fa4\u4f53\u7684\u6743\u76ca\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\u3002", "conclusion": "\"\u88ab\u8bb0\u4f4f\u6743\"\u662f\u5e94\u5bf9AI\u65f6\u4ee3\u4fe1\u606f\u504f\u89c1\u548c\u8bb0\u5fc6\u91cd\u5851\u5a01\u80c1\u7684\u91cd\u8981\u6982\u5ff5\uff0c\u9700\u8981\u5728\u6280\u672f\u53d1\u5c55\u4e2d\u5e73\u8861\u4fe1\u606f\u771f\u5b9e\u6027\u4e0e\u591a\u6837\u6027\u4fdd\u62a4\u3002"}}
{"id": "2510.16078", "categories": ["cs.CR", "cs.AI", "cs.CV", "68T10, 68T45, 94A60", "I.4.8; I.5.4; I.2.10"], "pdf": "https://arxiv.org/pdf/2510.16078", "abs": "https://arxiv.org/abs/2510.16078", "authors": ["Abdelilah Ganmati", "Karim Afdel", "Lahcen Koutti"], "title": "ISO/IEC-Compliant Match-on-Card Face Verification with Short Binary Templates", "comment": "~14 pages, 6 figures, 6 tables. Source uses elsarticle class; all\n  figures included as PNG/PDF. Primary: cs.CV", "summary": "We present a practical match-on-card design for face verification in which\ncompact 64/128-bit templates are produced off-card by PCA-ITQ and compared\non-card via constant-time Hamming distance. We specify ISO/IEC 7816-4 and\n14443-4 command APDUs with fixed-length payloads and decision-only status words\n(no score leakage), together with a minimal per-identity EEPROM map. Using real\nbinary codes from a CelebA working set (55 identities, 412 images), we (i)\nderive operating thresholds from ROC/DET, (ii) replay enroll->verify\ntransactions at those thresholds, and (iii) bound end-to-end time by pure link\nlatency plus a small constant on-card budget. Even at the slowest contact rate\n(9.6 kbps), total verification time is 43.9 ms (64 b) and 52.3 ms (128 b); at\n38.4 kbps both are <14 ms. At FAR = 1%, both code lengths reach TPR = 0.836,\nwhile 128 b lowers EER relative to 64 b. An optional +6 B helper (targeted\nsymbol-level parity over empirically unstable bits) is latency-negligible.\nOverall, short binary templates, fixed-payload decision-only APDUs, and\nconstant-time matching satisfy ISO/IEC transport constraints with wide timing\nmargin and align with ISO/IEC 24745 privacy goals. Limitations: single-dataset\nevaluation and design-level (pre-hardware) timing; we outline AgeDB/CFP-FP and\non-card microbenchmarks as next steps.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u5361\u7247\u5339\u914d\u4eba\u8138\u9a8c\u8bc1\u8bbe\u8ba1\uff0c\u4f7f\u752864/128\u4f4d\u7d27\u51d1\u6a21\u677f\uff0c\u901a\u8fc7PCA-ITQ\u79bb\u7ebf\u751f\u6210\uff0c\u5728\u5361\u4e0a\u901a\u8fc7\u6052\u5b9a\u65f6\u95f4\u6c49\u660e\u8ddd\u79bb\u8fdb\u884c\u6bd4\u8f83\u3002", "motivation": "\u6ee1\u8db3ISO/IEC\u4f20\u8f93\u7ea6\u675f\u548c\u9690\u79c1\u76ee\u6807\uff0c\u5b9e\u73b0\u56fa\u5b9a\u8d1f\u8f7d\u3001\u4ec5\u51b3\u7b56\u7684APDU\u901a\u4fe1\uff0c\u9632\u6b62\u5206\u6570\u6cc4\u9732\uff0c\u5e76\u786e\u4fdd\u5bbd\u88d5\u7684\u65f6\u95f4\u4f59\u91cf\u3002", "method": "\u4f7f\u7528PCA-ITQ\u751f\u6210\u7d27\u51d1\u4e8c\u8fdb\u5236\u6a21\u677f\uff0c\u5728\u5361\u4e0a\u901a\u8fc7\u6052\u5b9a\u65f6\u95f4\u6c49\u660e\u8ddd\u79bb\u8fdb\u884c\u5339\u914d\uff0c\u91c7\u7528ISO/IEC 7816-4\u548c14443-4\u547d\u4ee4APDU\uff0c\u5177\u6709\u56fa\u5b9a\u957f\u5ea6\u8d1f\u8f7d\u548c\u4ec5\u51b3\u7b56\u72b6\u6001\u5b57\u3002", "result": "\u57289.6 kbps\u6700\u6162\u63a5\u89e6\u901f\u7387\u4e0b\uff0c\u603b\u9a8c\u8bc1\u65f6\u95f4\u4e3a43.9 ms\uff0864\u4f4d\uff09\u548c52.3 ms\uff08128\u4f4d\uff09\uff1b\u572838.4 kbps\u4e0b\u5747\u5c0f\u4e8e14 ms\u3002\u5728FAR=1%\u65f6\uff0c\u4e24\u79cd\u7801\u957f\u5747\u8fbe\u5230TPR=0.836\uff0c128\u4f4d\u76f8\u6bd464\u4f4d\u964d\u4f4e\u4e86EER\u3002", "conclusion": "\u77ed\u4e8c\u8fdb\u5236\u6a21\u677f\u3001\u56fa\u5b9a\u8d1f\u8f7d\u4ec5\u51b3\u7b56APDU\u548c\u6052\u5b9a\u65f6\u95f4\u5339\u914d\u6ee1\u8db3\u4e86ISO/IEC\u4f20\u8f93\u7ea6\u675f\uff0c\u5177\u6709\u5bbd\u88d5\u7684\u65f6\u95f4\u4f59\u91cf\uff0c\u5e76\u7b26\u5408ISO/IEC 24745\u9690\u79c1\u76ee\u6807\u3002\u5c40\u9650\u6027\u5305\u62ec\u5355\u6570\u636e\u96c6\u8bc4\u4f30\u548c\u8bbe\u8ba1\u7ea7\u65f6\u5e8f\u5206\u6790\u3002"}}
{"id": "2510.17184", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17184", "abs": "https://arxiv.org/abs/2510.17184", "authors": ["Nicolas Robert", "Fabien Gandon", "Maxime Lefran\u00e7ois"], "title": "OLIVAW: ACIMOV's GitHub robot assisting agile collaborative ontology development", "comment": null, "summary": "Agile and collaborative approaches to ontologies design are crucial because\nthey contribute to making them userdriven, up-to-date, and able to evolve\nalongside the systems they support, hence proper continuous validation tooling\nis required to ensure ontologies match developers' requirements all along their\ndevelopment. We propose OLIVAW (Ontology Long-lived Integration Via ACIMOV\nWorkflow), a tool supporting the ACIMOV methodology on GitHub. It relies on W3C\nStandards to assist the development of modular ontologies through GitHub\nComposite Actions, pre-commit hooks, or a command line interface. OLIVAW was\ntested on several ontology projects to ensure its usefulness, genericity and\nreusability. A template repository is available for a quick start. OLIVAW is", "AI": {"tldr": "OLIVAW\u662f\u4e00\u4e2a\u652f\u6301ACIMOV\u65b9\u6cd5\u8bba\u7684\u5de5\u5177\uff0c\u901a\u8fc7GitHub Composite Actions\u3001pre-commit hooks\u6216\u547d\u4ee4\u884c\u754c\u9762\u534f\u52a9\u6a21\u5757\u5316\u672c\u4f53\u5f00\u53d1\uff0c\u57fa\u4e8eW3C\u6807\u51c6\u3002", "motivation": "\u654f\u6377\u548c\u534f\u4f5c\u7684\u672c\u4f53\u8bbe\u8ba1\u65b9\u6cd5\u5bf9\u4e8e\u786e\u4fdd\u672c\u4f53\u4e0e\u7528\u6237\u9700\u6c42\u4fdd\u6301\u4e00\u81f4\u3001\u4fdd\u6301\u6700\u65b0\u72b6\u6001\u5e76\u968f\u7cfb\u7edf\u6f14\u8fdb\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u9002\u5f53\u7684\u6301\u7eed\u9a8c\u8bc1\u5de5\u5177\u3002", "method": "\u63d0\u51faOLIVAW\u5de5\u5177\uff0c\u652f\u6301ACIMOV\u65b9\u6cd5\u8bba\uff0c\u57fa\u4e8eW3C\u6807\u51c6\uff0c\u901a\u8fc7GitHub Composite Actions\u3001pre-commit hooks\u6216\u547d\u4ee4\u884c\u754c\u9762\u534f\u52a9\u6a21\u5757\u5316\u672c\u4f53\u5f00\u53d1\u3002", "result": "OLIVAW\u5728\u591a\u4e2a\u672c\u4f53\u9879\u76ee\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u7528\u6027\u3001\u901a\u7528\u6027\u548c\u53ef\u91cd\u7528\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u6a21\u677f\u4ed3\u5e93\u4ee5\u4fbf\u5feb\u901f\u5f00\u59cb\u4f7f\u7528\u3002", "conclusion": "OLIVAW\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5de5\u5177\uff0c\u652f\u6301\u654f\u6377\u548c\u534f\u4f5c\u7684\u672c\u4f53\u5f00\u53d1\uff0c\u786e\u4fdd\u672c\u4f53\u5728\u6574\u4e2a\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u4e0e\u5f00\u53d1\u8005\u9700\u6c42\u5339\u914d\u3002"}}
{"id": "2510.16234", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16234", "abs": "https://arxiv.org/abs/2510.16234", "authors": ["Hanane Nour Moussa", "Patrick Queiroz Da Silva", "Daniel Adu-Ampratwum", "Alyson East", "Zitong Lu", "Nikki Puccetti", "Mingyi Xue", "Huan Sun", "Bodhisattwa Prasad Majumder", "Sachin Kumar"], "title": "ScholarEval: Research Idea Evaluation Grounded in Literature", "comment": null, "summary": "As AI tools become increasingly common for research ideation, robust\nevaluation is critical to ensure the validity and usefulness of generated\nideas. We introduce ScholarEval, a retrieval augmented evaluation framework\nthat assesses research ideas based on two fundamental criteria: soundness - the\nempirical validity of proposed methods based on existing literature, and\ncontribution - the degree of advancement made by the idea across different\ndimensions relative to prior research. To evaluate ScholarEval, we introduce\nScholarIdeas, the first expert-annotated dataset of multi-domain research ideas\nand reviews, comprised of 117 ideas across four disciplines: artificial\nintelligence, neuroscience, biochemistry, and ecology. Our evaluation shows\nthat ScholarEval achieves significantly higher coverage of points mentioned in\nthe human expert annotated rubrics in ScholarIdeas compared to all baselines.\nFurthermore, ScholarEval is consistently preferred over our strongest baseline\no4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,\nin terms of evaluation actionability, depth, and evidence support. Our\nlarge-scale user study also shows that ScholarEval significantly outperforms\ndeep research in literature engagement, idea refinement, and usefulness. We\nopenly release our code, dataset, and ScholarEval tool for the community to use\nand build on.", "AI": {"tldr": "ScholarEval\u662f\u4e00\u4e2a\u68c0\u7d22\u589e\u5f3a\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u751f\u6210\u7684\u7814\u7a76\u60f3\u6cd5\uff0c\u57fa\u4e8e\u5408\u7406\u6027\u548c\u8d21\u732e\u5ea6\u4e24\u4e2a\u6807\u51c6\u3002\u8be5\u6846\u67b6\u5728\u4e13\u5bb6\u6807\u6ce8\u7684\u591a\u9886\u57df\u6570\u636e\u96c6ScholarIdeas\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5e76\u5728\u7528\u6237\u7814\u7a76\u4e2d\u663e\u793a\u51fa\u66f4\u597d\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u968f\u7740AI\u5de5\u5177\u5728\u7814\u7a76\u6784\u601d\u4e2d\u7684\u666e\u53ca\uff0c\u9700\u8981\u5f3a\u5927\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u786e\u4fdd\u751f\u6210\u60f3\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u7814\u7a76\u60f3\u6cd5\u7684\u79d1\u5b66\u4ef7\u503c\u548c\u521b\u65b0\u6027\u3002", "method": "\u63d0\u51fa\u4e86ScholarEval\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u8bc4\u4f30\u7814\u7a76\u60f3\u6cd5\u7684\u5408\u7406\u6027\u548c\u8d21\u732e\u5ea6\u3002\u6784\u5efa\u4e86ScholarIdeas\u6570\u636e\u96c6\uff0c\u5305\u542b117\u4e2a\u8de8\u9886\u57df\u7814\u7a76\u60f3\u6cd5\u548c\u4e13\u5bb6\u6807\u6ce8\u3002", "result": "ScholarEval\u5728\u4e13\u5bb6\u6807\u6ce8\u7684\u8bc4\u4f30\u8981\u70b9\u8986\u76d6\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u53ef\u64cd\u4f5c\u6027\u3001\u6df1\u5ea6\u548c\u8bc1\u636e\u652f\u6301\u65b9\u9762\u6301\u7eed\u4f18\u4e8eOpenAI\u7684o4-mini-deep-research\u7cfb\u7edf\u3002\u7528\u6237\u7814\u7a76\u663e\u793a\u5728\u6587\u732e\u53c2\u4e0e\u3001\u60f3\u6cd5\u7cbe\u70bc\u548c\u5b9e\u7528\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6df1\u5ea6\u7814\u7a76\u3002", "conclusion": "ScholarEval\u4e3aAI\u751f\u6210\u7814\u7a76\u60f3\u6cd5\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u7ef4\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548c\u5de5\u5177\u5df2\u5f00\u6e90\u3002"}}
{"id": "2510.16087", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.16087", "abs": "https://arxiv.org/abs/2510.16087", "authors": ["Sabbir M Saleh", "Nazim Madhavji", "John Steinbacher"], "title": "Towards a Blockchain-Based CI/CD Framework to Enhance Security in Cloud Environments", "comment": "8 pages, 5 figures, conference", "summary": "Security is becoming a pivotal point in cloud platforms. Several divisions,\nsuch as business organisations, health care, government, etc., have experienced\ncyber-attacks on their infrastructures. This research focuses on security\nissues within Continuous Integration and Deployment (CI/CD) pipelines in a\ncloud platform as a reaction to recent cyber breaches. This research proposes a\nblockchain-based solution to enhance CI/CD pipeline security. This research\naims to develop a framework that leverages blockchain's distributed ledger\ntechnology and tamper-resistant features to improve CI/CD pipeline security.\nThe goal is to emphasise secure software deployment by integrating threat\nmodelling frameworks and adherence to coding standards. It also aims to employ\ntools to automate security testing to detect publicly disclosed vulnerabilities\nand flaws, such as an outdated version of Java Spring Framework, a JavaScript\nlibrary from an unverified source, or a database library that allows SQL\ninjection attacks in the deployed software through the framework.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u533a\u5757\u94fe\u7684CI/CD\u7ba1\u9053\u5b89\u5168\u6846\u67b6\uff0c\u5229\u7528\u5206\u5e03\u5f0f\u8d26\u672c\u548c\u9632\u7be1\u6539\u7279\u6027\u589e\u5f3a\u4e91\u5e73\u53f0\u6301\u7eed\u96c6\u6210\u90e8\u7f72\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u9488\u5bf9\u4e91\u5e73\u53f0CI/CD\u7ba1\u9053\u9762\u4e34\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u7279\u522b\u662f\u8fd1\u671f\u53d1\u751f\u7684\u7f51\u7edc\u653b\u51fb\u4e8b\u4ef6\uff0c\u9700\u8981\u63d0\u5347\u8f6f\u4ef6\u90e8\u7f72\u8fc7\u7a0b\u7684\u5b89\u5168\u6027\u3002", "method": "\u96c6\u6210\u533a\u5757\u94fe\u7684\u5206\u5e03\u5f0f\u8d26\u672c\u6280\u672f\u3001\u5a01\u80c1\u5efa\u6a21\u6846\u67b6\u548c\u7f16\u7801\u6807\u51c6\uff0c\u4f7f\u7528\u81ea\u52a8\u5316\u5b89\u5168\u6d4b\u8bd5\u5de5\u5177\u68c0\u6d4b\u516c\u5f00\u6f0f\u6d1e\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u68c0\u6d4bJava Spring\u6846\u67b6\u65e7\u7248\u672c\u3001\u672a\u9a8c\u8bc1JavaScript\u5e93\u548cSQL\u6ce8\u5165\u6f0f\u6d1e\u7b49\u5b89\u5168\u95ee\u9898\u7684\u6846\u67b6\u3002", "conclusion": "\u533a\u5757\u94fe\u6280\u672f\u80fd\u591f\u6709\u6548\u589e\u5f3aCI/CD\u7ba1\u9053\u7684\u5b89\u5168\u6027\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u5b89\u5168\u6d4b\u8bd5\u548c\u9632\u7be1\u6539\u7279\u6027\u786e\u4fdd\u8f6f\u4ef6\u90e8\u7f72\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2510.17376", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17376", "abs": "https://arxiv.org/abs/2510.17376", "authors": ["Yongmin Li", "Jia Li", "Ge Li", "Zhi Jin"], "title": "AdapTrack: Constrained Decoding without Distorting LLM's Output Intent", "comment": "to be published in ICSE 2026", "summary": "Language model-based code generation and completion tools have been widely\nadopted, but they may sometimes produce code that does not meet necessary\nconstraints, such as syntactic correctness or API existence. Constrained\ndecoding techniques are developed to help the model generate code adhering to\nthe constraints by greedily eliminating generation options that violate\nconstraints at each step of the generation process. However, there is a severe\nlimitation of constrained decoding, that it distorts the model's output intent,\nforcing it to produce code that may satisfy the constraint but does not match\nthe development intent and is therefore incorrect. In response to this\nchallenge, we propose AdapTrack. By incorporating backtracking into the\ngeneration process, AdapTrack avoids distorting the output intent of the model,\nthereby producing results that are not only constraint-compliant but also more\nsemantically aligned with model's output intent. On our synthetic API\ncompletion dataset, AdapTrack can achieve up to 360.87% improvement compared to\nconstrained decoding; on the real-world API completion dataset we collect that\nexhibits similar issues, AdapTrack can achieve up to 38.93% improvement over\nconstrained decoding; in general code genration benchmarks, compared to\nconstrained decoding, AdapTrack can achieve up to 7.84% improvement on\nHumanEval, and up to 6.42% improvement on MBPP. This indicates that, simply by\nbetter adhering to the model's output intent, AdapTrack can achieve significant\nimprovements. We provide a theoretical proof that the distribution produced by\nAdapTrack aligns with the model's distribution given the generated tokens,\nthereby ensuring that the model's output intent is not distorted. Experiments\non DSL problems show that, compared to existing methods, our approach can\nprovide generation results that are more consistent with the language model's\ndistribution.", "AI": {"tldr": "AdapTrack\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u7ea6\u675f\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u56de\u6eaf\u673a\u5236\u907f\u514d\u626d\u66f2\u6a21\u578b\u8f93\u51fa\u610f\u56fe\uff0c\u5728\u4fdd\u6301\u7ea6\u675f\u5408\u89c4\u7684\u540c\u65f6\u66f4\u597d\u5730\u4e0e\u6a21\u578b\u8bed\u4e49\u610f\u56fe\u5bf9\u9f50\u3002", "motivation": "\u4f20\u7edf\u7ea6\u675f\u89e3\u7801\u6280\u672f\u867d\u7136\u80fd\u786e\u4fdd\u4ee3\u7801\u6ee1\u8db3\u8bed\u6cd5\u6216API\u7ea6\u675f\uff0c\u4f46\u4f1a\u626d\u66f2\u6a21\u578b\u7684\u8f93\u51fa\u610f\u56fe\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u4ee3\u7801\u867d\u7136\u7b26\u5408\u7ea6\u675f\u4f46\u8bed\u4e49\u4e0a\u4e0d\u6b63\u786e\u3002", "method": "AdapTrack\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u5f15\u5165\u56de\u6eaf\u673a\u5236\uff0c\u907f\u514d\u5f3a\u5236\u6a21\u578b\u9009\u62e9\u8fdd\u53cd\u5176\u610f\u56fe\u7684\u9009\u9879\uff0c\u786e\u4fdd\u8f93\u51fa\u5206\u5e03\u4e0e\u6a21\u578b\u539f\u59cb\u5206\u5e03\u4e00\u81f4\u3002", "result": "\u5728API\u8865\u5168\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u7ea6\u675f\u89e3\u7801\u63d0\u5347360.87%\uff0c\u5728\u771f\u5b9eAPI\u6570\u636e\u96c6\u4e0a\u63d0\u534738.93%\uff0c\u5728HumanEval\u548cMBPP\u57fa\u51c6\u4e0a\u5206\u522b\u63d0\u53477.84%\u548c6.42%\u3002", "conclusion": "\u901a\u8fc7\u66f4\u597d\u5730\u9075\u5faa\u6a21\u578b\u8f93\u51fa\u610f\u56fe\uff0cAdapTrack\u80fd\u663e\u8457\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u8f93\u51fa\u5206\u5e03\u4e0e\u6a21\u578b\u7ed9\u5b9a\u751f\u6210\u6807\u8bb0\u7684\u5206\u5e03\u4e00\u81f4\u3002"}}
{"id": "2510.16259", "categories": ["cs.AI", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.16259", "abs": "https://arxiv.org/abs/2510.16259", "authors": ["Zhehao Zhang", "Weijie Xu", "Shixian Cui", "Chandan K. Reddy"], "title": "Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense", "comment": "29 pages, 9 tables, 4 figures", "summary": "Recent advances in large reasoning models (LRMs) have enabled remarkable\nperformance on complex tasks such as mathematics and coding by generating long\nChain-of-Thought (CoT) traces. In this paper, we identify and systematically\nanalyze a critical vulnerability we term reasoning distraction, where LRMs are\ndiverted from their primary objective by irrelevant yet complex tasks\nmaliciously embedded in the prompt. Through a comprehensive study across\ndiverse models and benchmarks, we show that even state-of-the-art LRMs are\nhighly susceptible, with injected distractors reducing task accuracy by up to\n60%. We further reveal that certain alignment techniques can amplify this\nweakness and that models may exhibit covert compliance, following hidden\nadversarial instructions in reasoning while concealing them in the final\noutput. To mitigate these risks, we propose a training-based defense that\ncombines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on\nsynthetic adversarial data, improving robustness by over 50 points on\nchallenging distractor attacks. Our findings establish reasoning distraction as\na distinct and urgent threat to LRM reliability and provide a practical step\ntoward safer and more trustworthy reasoning systems.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5e76\u7cfb\u7edf\u5206\u6790\u4e86\u5927\u63a8\u7406\u6a21\u578b(LRMs)\u4e2d\u5b58\u5728\u7684\u4e00\u4e2a\u5173\u952e\u6f0f\u6d1e\u2014\u2014\u63a8\u7406\u5206\u5fc3\uff0c\u5373\u6a21\u578b\u88ab\u6076\u610f\u5d4c\u5165\u63d0\u793a\u4e2d\u7684\u65e0\u5173\u590d\u6742\u4efb\u52a1\u5206\u6563\u6ce8\u610f\u529b\uff0c\u5bfc\u81f4\u4e3b\u8981\u4efb\u52a1\u51c6\u786e\u6027\u4e0b\u964d\u9ad8\u8fbe60%\u3002", "motivation": "\u968f\u7740\u5927\u63a8\u7406\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u7b49\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f5c\u8005\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u5728\u9762\u5bf9\u5305\u542b\u65e0\u5173\u590d\u6742\u4efb\u52a1\u7684\u6076\u610f\u63d0\u793a\u65f6\u5bb9\u6613\u88ab\u5206\u6563\u6ce8\u610f\u529b\uff0c\u8fd9\u6784\u6210\u4e86\u4e00\u4e2a\u4e25\u91cd\u7684\u5b89\u5168\u5a01\u80c1\u3002", "method": "\u901a\u8fc7\u8de8\u591a\u79cd\u6a21\u578b\u548c\u57fa\u51c6\u7684\u5168\u9762\u7814\u7a76\uff0c\u5206\u6790\u4e86\u63a8\u7406\u5206\u5fc3\u6f0f\u6d1e\uff1b\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u5f3a\u5316\u5b66\u4e60(RL)\u7684\u8bad\u7ec3\u9632\u5fa1\u65b9\u6cd5\uff0c\u4f7f\u7528\u5408\u6210\u7684\u5bf9\u6297\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u7814\u7a76\u8868\u660e\u6700\u5148\u8fdb\u7684\u5927\u63a8\u7406\u6a21\u578b\u9ad8\u5ea6\u6613\u53d7\u63a8\u7406\u5206\u5fc3\u653b\u51fb\uff0c\u67d0\u4e9b\u5bf9\u9f50\u6280\u672f\u4f1a\u653e\u5927\u8fd9\u79cd\u5f31\u70b9\uff1b\u63d0\u51fa\u7684\u9632\u5fa1\u65b9\u6cd5\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5206\u5fc3\u653b\u51fb\u4e0a\u5c06\u9c81\u68d2\u6027\u63d0\u9ad8\u4e8650\u591a\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u63a8\u7406\u5206\u5fc3\u662f\u5bf9\u5927\u63a8\u7406\u6a21\u578b\u53ef\u9760\u6027\u7684\u4e00\u4e2a\u72ec\u7279\u4e14\u7d27\u8feb\u7684\u5a01\u80c1\uff0c\u672c\u6587\u4e3a\u6784\u5efa\u66f4\u5b89\u5168\u53ef\u4fe1\u7684\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6b65\u9aa4\u3002"}}
{"id": "2510.16122", "categories": ["cs.CR", "cs.CL", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16122", "abs": "https://arxiv.org/abs/2510.16122", "authors": ["Owais Makroo", "Siva Rajesh Kasa", "Sumegh Roychowdhury", "Karan Gupta", "Nikhil Pattisapu", "Santhosh Kasa", "Sumit Negi"], "title": "The Hidden Cost of Modeling P(X): Vulnerability to Membership Inference Attacks in Generative Text Classifiers", "comment": null, "summary": "Membership Inference Attacks (MIAs) pose a critical privacy threat by\nenabling adversaries to determine whether a specific sample was included in a\nmodel's training dataset. Despite extensive research on MIAs, systematic\ncomparisons between generative and discriminative classifiers remain limited.\nThis work addresses this gap by first providing theoretical motivation for why\ngenerative classifiers exhibit heightened susceptibility to MIAs, then\nvalidating these insights through comprehensive empirical evaluation. Our study\nencompasses discriminative, generative, and pseudo-generative text classifiers\nacross varying training data volumes, evaluated on nine benchmark datasets.\nEmploying a diverse array of MIA strategies, we consistently demonstrate that\nfully generative classifiers which explicitly model the joint likelihood\n$P(X,Y)$ are most vulnerable to membership leakage. Furthermore, we observe\nthat the canonical inference approach commonly used in generative classifiers\nsignificantly amplifies this privacy risk. These findings reveal a fundamental\nutility-privacy trade-off inherent in classifier design, underscoring the\ncritical need for caution when deploying generative classifiers in\nprivacy-sensitive applications. Our results motivate future research directions\nin developing privacy-preserving generative classifiers that can maintain\nutility while mitigating membership inference vulnerabilities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u751f\u6210\u5f0f\u548c\u5224\u522b\u5f0f\u5206\u7c7b\u5668\u5728\u6210\u5458\u63a8\u7406\u653b\u51fb\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u53d1\u73b0\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u7531\u4e8e\u663e\u5f0f\u5efa\u6a21\u8054\u5408\u6982\u7387P(X,Y)\u800c\u5177\u6709\u66f4\u9ad8\u7684\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9\u751f\u6210\u5f0f\u548c\u5224\u522b\u5f0f\u5206\u7c7b\u5668\u5728\u6210\u5458\u63a8\u7406\u653b\u51fb\u4e2d\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\u6709\u9650\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u5e76\u7406\u89e3\u4e0d\u540c\u5206\u7c7b\u5668\u8bbe\u8ba1\u7684\u9690\u79c1\u98ce\u9669\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u7814\u7a76\u6db5\u76d6\u5224\u522b\u5f0f\u3001\u751f\u6210\u5f0f\u548c\u4f2a\u751f\u6210\u5f0f\u6587\u672c\u5206\u7c7b\u5668\uff0c\u5728\u4e5d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u591a\u79cdMIA\u7b56\u7565\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u5b8c\u5168\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u6700\u4e3a\u8106\u5f31\uff0c\u5176\u5178\u578b\u63a8\u7406\u65b9\u6cd5\u663e\u8457\u653e\u5927\u4e86\u9690\u79c1\u98ce\u9669\uff0c\u63ed\u793a\u4e86\u5206\u7c7b\u5668\u8bbe\u8ba1\u4e2d\u56fa\u6709\u7684\u6548\u7528-\u9690\u79c1\u6743\u8861\u3002", "conclusion": "\u5728\u9690\u79c1\u654f\u611f\u5e94\u7528\u4e2d\u90e8\u7f72\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u9700\u8c28\u614e\uff0c\u672a\u6765\u5e94\u7814\u7a76\u5f00\u53d1\u65e2\u80fd\u4fdd\u6301\u6548\u7528\u53c8\u80fd\u51cf\u8f7b\u6210\u5458\u63a8\u7406\u6f0f\u6d1e\u7684\u9690\u79c1\u4fdd\u62a4\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u3002"}}
{"id": "2510.17430", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17430", "abs": "https://arxiv.org/abs/2510.17430", "authors": ["Kuniaki Kudo", "Sherine Devi"], "title": "Scalable CI/CD for Legacy Modernization: An Industrial Experience Addressing Internal Challenges Related to the 2025 Japan Cliff", "comment": null, "summary": "We have developed a Scalable CI/CD Pipeline to address internal challenges\nrelated to Japan 2025 cliff problem, a critical issue where the mass end of\nservice life of legacy core IT systems threatens to significantly increase the\nmaintenance cost and black box nature of these system also leads to difficult\nupdate moreover replace, which leads to lack of progress in Digital\nTransformation (DX). If not addressed, Japan could potentially lose up to 12\ntrillion yen per year after 2025, which is 3 times more than the cost in\nprevious years. Asahi also faced the same internal challenges regarding legacy\nsystem, where manual maintenance workflows and limited QA environment have left\ncritical systems outdated and difficult to update. Middleware and OS version\nhave remained unchanged for years, leading to now its nearing end of service\nlife which require huge maintenance cost and effort to continue its operation.\nTo address this problem, we have developed and implemented a Scalable CI/CD\nPipeline where isolated development environments can be created and deleted\ndynamically and is scalable as needed. This Scalable CI/CD Pipeline incorporate\nGitHub for source code control and branching, Jenkins for pipeline automation,\nAmazon Web Services for scalable environment, and Docker for environment\ncontainerization. This paper presents the design and architecture of the\nScalable CI/CD Pipeline, with the implementation along with some use cases.\nThrough Scalable CI/CD, developers can freely and safely test maintenance\nprocedures and do experiments with new technology in their own environment,\nreducing maintenance cost and drive Digital Transformation (DX).\n  key words: 2025 Japan Cliff, Scalable CI/CD, DevOps, Legacy IT Modernization.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u65e5\u672c2025\u5e74IT\u7cfb\u7edf\u8001\u5316\u5371\u673a\uff0c\u5f00\u53d1\u4e86\u53ef\u6269\u5c55\u7684CI/CD\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u52a8\u6001\u521b\u5efa\u9694\u79bb\u5f00\u53d1\u73af\u5883\u3001\u81ea\u52a8\u5316\u6d41\u7a0b\u548c\u5bb9\u5668\u5316\u6280\u672f\uff0c\u964d\u4f4e\u7ef4\u62a4\u6210\u672c\u5e76\u63a8\u52a8\u6570\u5b57\u5316\u8f6c\u578b\u3002", "motivation": "\u65e5\u672c\u9762\u4e342025\u5e74IT\u7cfb\u7edf\u5927\u89c4\u6a21\u670d\u52a1\u7ec8\u6b62\u7684\u5371\u673a\uff0c\u4f20\u7edf\u7cfb\u7edf\u7ef4\u62a4\u6210\u672c\u9ad8\u6602\u4e14\u96be\u4ee5\u66f4\u65b0\uff0c\u53ef\u80fd\u5bfc\u81f4\u6bcf\u5e7412\u4e07\u4ebf\u65e5\u5143\u635f\u5931\u3002\u671d\u65e5\u516c\u53f8\u4e5f\u9762\u4e34\u7c7b\u4f3c\u6311\u6218\uff0c\u624b\u52a8\u7ef4\u62a4\u6d41\u7a0b\u548c\u6709\u9650QA\u73af\u5883\u5bfc\u81f4\u7cfb\u7edf\u8fc7\u65f6\u3002", "method": "\u5f00\u53d1\u53ef\u6269\u5c55CI/CD\u6d41\u6c34\u7ebf\uff0c\u96c6\u6210GitHub\u6e90\u4ee3\u7801\u63a7\u5236\u3001Jenkins\u6d41\u6c34\u7ebf\u81ea\u52a8\u5316\u3001AWS\u53ef\u6269\u5c55\u73af\u5883\u548cDocker\u5bb9\u5668\u5316\u6280\u672f\uff0c\u5b9e\u73b0\u52a8\u6001\u521b\u5efa\u548c\u5220\u9664\u9694\u79bb\u5f00\u53d1\u73af\u5883\u3002", "result": "\u901a\u8fc7\u53ef\u6269\u5c55CI/CD\uff0c\u5f00\u53d1\u8005\u53ef\u4ee5\u5728\u72ec\u7acb\u73af\u5883\u4e2d\u81ea\u7531\u5b89\u5168\u5730\u6d4b\u8bd5\u7ef4\u62a4\u7a0b\u5e8f\u548c\u65b0\u6280\u672f\u5b9e\u9a8c\uff0c\u663e\u8457\u964d\u4f4e\u7ef4\u62a4\u6210\u672c\u3002", "conclusion": "\u53ef\u6269\u5c55CI/CD\u6d41\u6c34\u7ebf\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfIT\u7cfb\u7edf\u7ef4\u62a4\u96be\u9898\uff0c\u4e3a\u6570\u5b57\u5316\u8f6c\u578b\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6491\uff0c\u662f\u5e94\u5bf9\u65e5\u672c2025\u5e74IT\u5371\u673a\u7684\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.16276", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16276", "abs": "https://arxiv.org/abs/2510.16276", "authors": ["Song Bian", "Minghao Yan", "Anand Jayarajan", "Gennady Pekhimenko", "Shivaram Venkataraman"], "title": "What Limits Agentic Systems Efficiency?", "comment": "27 pages, 15 figures", "summary": "Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have\ndemonstrated strong reasoning capabilities. To further enhance LLM\ncapabilities, recent agentic systems, such as Deep Research, incorporate web\ninteractions into LLM reasoning to mitigate uncertainties and reduce potential\nerrors. However, existing research predominantly focuses on reasoning\nperformance, often neglecting the efficiency of agentic systems. In this work,\nwe present a comprehensive empirical study that identifies efficiency\nbottlenecks in web-interactive agentic systems. We decompose end-to-end latency\ninto two primary components: LLM API latency and web environment latency. We\nconduct a comprehensive empirical study across 15 models and 5 providers to\ndemonstrate high variability in API-based agentic systems. We observe that web\nenvironment latency can contribute as much as 53.7% to the overall latency in a\nweb-based agentic system. To improve latency, we propose SpecCache, a caching\nframework augmented with speculative execution that can reduce web environment\noverhead. Extensive evaluations on two standard benchmarks show that our\napproach improves the cache hit rate by up to 58x compared to a random caching\nstrategy, while reducing web environment overhead by up to 3.2x, without\ndegrading agentic system performance.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u7f51\u7edc\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u7cfb\u7edf\u5b58\u5728\u6548\u7387\u74f6\u9888\uff0c\u63d0\u51faSpecCache\u7f13\u5b58\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u6d4b\u6267\u884c\u663e\u8457\u964d\u4f4e\u7f51\u7edc\u73af\u5883\u5ef6\u8fdf\uff0c\u63d0\u5347\u7f13\u5b58\u547d\u4e2d\u738758\u500d\uff0c\u51cf\u5c11\u7f51\u7edc\u5f00\u95003.2\u500d\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u63a8\u7406\u6027\u80fd\uff0c\u800c\u5ffd\u89c6\u4e86\u7cfb\u7edf\u6548\u7387\u95ee\u9898\u3002\u7f51\u7edc\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u7cfb\u7edf\u5b58\u5728\u663e\u8457\u7684\u5ef6\u8fdf\u74f6\u9888\uff0c\u5f71\u54cd\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "method": "\u5c06\u7aef\u5230\u7aef\u5ef6\u8fdf\u5206\u89e3\u4e3aLLM API\u5ef6\u8fdf\u548c\u7f51\u7edc\u73af\u5883\u5ef6\u8fdf\uff0c\u8fdb\u884c\u8de815\u4e2a\u6a21\u578b\u548c5\u4e2a\u63d0\u4f9b\u5546\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u51faSpecCache\u7f13\u5b58\u6846\u67b6\u5e76\u96c6\u6210\u63a8\u6d4b\u6267\u884c\u673a\u5236\u3002", "result": "\u7f51\u7edc\u73af\u5883\u5ef6\u8fdf\u53ef\u5360\u7cfb\u7edf\u603b\u5ef6\u8fdf\u768453.7%\uff0cSpecCache\u76f8\u6bd4\u968f\u673a\u7f13\u5b58\u7b56\u7565\u63d0\u5347\u7f13\u5b58\u547d\u4e2d\u738758\u500d\uff0c\u51cf\u5c11\u7f51\u7edc\u73af\u5883\u5f00\u95003.2\u500d\uff0c\u4e14\u4e0d\u964d\u4f4e\u7cfb\u7edf\u6027\u80fd\u3002", "conclusion": "\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6548\u7387\u4f18\u5316\u81f3\u5173\u91cd\u8981\uff0cSpecCache\u901a\u8fc7\u7f13\u5b58\u548c\u63a8\u6d4b\u6267\u884c\u6709\u6548\u89e3\u51b3\u4e86\u7f51\u7edc\u73af\u5883\u5ef6\u8fdf\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u9ad8\u6548\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16128", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.16128", "abs": "https://arxiv.org/abs/2510.16128", "authors": ["Kate Glazko", "Jennifer Mankoff"], "title": "Prompt injections as a tool for preserving identity in GAI image descriptions", "comment": "Accepted as a poster to Soups 2025", "summary": "Generative AI risks such as bias and lack of representation impact people who\ndo not interact directly with GAI systems, but whose content does: indirect\nusers. Several approaches to mitigating harms to indirect users have been\ndescribed, but most require top down or external intervention. An emerging\nstrategy, prompt injections, provides an empowering alternative: indirect users\ncan mitigate harm against them, from within their own content. Our approach\nproposes prompt injections not as a malicious attack vector, but as a tool for\ncontent/image owner resistance. In this poster, we demonstrate one case study\nof prompt injections for empowering an indirect user, by retaining an image\nowner's gender and disabled identity when an image is described by GAI.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06\u63d0\u793a\u6ce8\u5165\u4f5c\u4e3a\u4e00\u79cd\u5de5\u5177\uff0c\u8ba9\u95f4\u63a5\u7528\u6237\uff08\u5176\u5185\u5bb9\u88ab\u751f\u6210\u5f0fAI\u7cfb\u7edf\u4f7f\u7528\u4f46\u672a\u76f4\u63a5\u4ea4\u4e92\u7684\u7528\u6237\uff09\u80fd\u591f\u81ea\u6211\u4fdd\u62a4\uff0c\u9632\u6b62\u8eab\u4efd\u7279\u5f81\u88ab\u9519\u8bef\u63cf\u8ff0\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7684\u504f\u89c1\u548c\u7f3a\u4e4f\u4ee3\u8868\u6027\u98ce\u9669\u4f1a\u5f71\u54cd\u95f4\u63a5\u7528\u6237\uff0c\u73b0\u6709\u7f13\u89e3\u65b9\u6cd5\u5927\u591a\u9700\u8981\u81ea\u4e0a\u800c\u4e0b\u7684\u5e72\u9884\uff0c\u9700\u8981\u4e3a\u95f4\u63a5\u7528\u6237\u63d0\u4f9b\u81ea\u4e3b\u9632\u62a4\u624b\u6bb5\u3002", "method": "\u5c06\u63d0\u793a\u6ce8\u5165\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5185\u5bb9\u6240\u6709\u8005\u7684\u62b5\u6297\u5de5\u5177\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u5982\u4f55\u5728\u56fe\u50cf\u63cf\u8ff0\u4e2d\u4fdd\u7559\u6240\u6709\u8005\u7684\u6027\u522b\u548c\u6b8b\u75be\u8eab\u4efd\u7279\u5f81\u3002", "result": "\u6f14\u793a\u4e86\u63d0\u793a\u6ce8\u5165\u80fd\u591f\u6709\u6548\u4fdd\u62a4\u95f4\u63a5\u7528\u6237\u7684\u8eab\u4efd\u7279\u5f81\u4e0d\u88ab\u751f\u6210\u5f0fAI\u9519\u8bef\u63cf\u8ff0\u3002", "conclusion": "\u63d0\u793a\u6ce8\u5165\u53ef\u4ee5\u4f5c\u4e3a\u95f4\u63a5\u7528\u6237\u81ea\u6211\u4fdd\u62a4\u7684\u6709\u6548\u7b56\u7565\uff0c\u4e3a\u5185\u5bb9\u6240\u6709\u8005\u63d0\u4f9b\u62b5\u6297AI\u504f\u89c1\u7684\u8d4b\u80fd\u5de5\u5177\u3002"}}
{"id": "2510.16302", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.16302", "abs": "https://arxiv.org/abs/2510.16302", "authors": ["Changhao Wang", "Yanfang Liu", "Xinxin Fan", "Anzhi Zhou", "Lao Tian", "Yunfeng Lu"], "title": "DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA", "comment": "13 pages, 5 figures", "summary": "Multi-hop reasoning for question answering (QA) plays a critical role in\nretrieval-augmented generation (RAG) for modern large language models (LLMs).\nThe accurate answer can be obtained through retrieving relational structure of\nentities from knowledge graph (KG). Regarding the inherent relation-dependency\nand reasoning pattern, multi-hop reasoning can be in general classified into\ntwo categories: i) parallel fact-verification multi-hop reasoning question,\ni.e., requiring simultaneous verifications of multiple independent\nsub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding\nsequential multi-step inference with intermediate conclusions serving as\nessential premises for subsequent reasoning. Currently, the multi-hop reasoning\napproaches singly employ one of two techniques: LLM response-based fact\nverification and KG path-based chain construction. Nevertheless, the former\nexcels at parallel fact-verification but underperforms on chained reasoning\ntasks, while the latter demonstrates proficiency in chained multi-hop reasoning\nbut suffers from redundant path retrieval when handling parallel\nfact-verification reasoning. These limitations deteriorate the efficiency and\naccuracy for multi-hop QA tasks. To address this challenge, we propose a novel\ndual-track KG verification and reasoning framework DTKG, which is inspired by\nthe Dual Process Theory in cognitive science. Specifically, DTKG comprises two\nmain stages: the Classification Stage and the Branch Processing Stage.", "AI": {"tldr": "\u63d0\u51faDTKG\u6846\u67b6\uff0c\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u8def\u5f84\u6784\u5efa\u548cLLM\u4e8b\u5b9e\u9a8c\u8bc1\u7684\u53cc\u8f68\u65b9\u6cd5\uff0c\u89e3\u51b3\u591a\u8df3\u63a8\u7406\u4e2d\u5e76\u884c\u4e8b\u5b9e\u9a8c\u8bc1\u548c\u94fe\u5f0f\u63a8\u7406\u7684\u5404\u81ea\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u591a\u8df3\u63a8\u7406\u65b9\u6cd5\u8981\u4e48\u4f7f\u7528LLM\u4e8b\u5b9e\u9a8c\u8bc1\uff08\u64c5\u957f\u5e76\u884c\u9a8c\u8bc1\u4f46\u94fe\u5f0f\u63a8\u7406\u5dee\uff09\uff0c\u8981\u4e48\u4f7f\u7528KG\u8def\u5f84\u6784\u5efa\uff08\u64c5\u957f\u94fe\u5f0f\u63a8\u7406\u4f46\u5e76\u884c\u9a8c\u8bc1\u65f6\u8def\u5f84\u68c0\u7d22\u5197\u4f59\uff09\uff0c\u8fd9\u4e9b\u9650\u5236\u964d\u4f4e\u4e86\u591a\u8df3QA\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faDTKG\u53cc\u8f68\u77e5\u8bc6\u56fe\u8c31\u9a8c\u8bc1\u548c\u63a8\u7406\u6846\u67b6\uff0c\u53d7\u8ba4\u77e5\u79d1\u5b66\u53cc\u8fc7\u7a0b\u7406\u8bba\u542f\u53d1\uff0c\u5305\u542b\u5206\u7c7b\u9636\u6bb5\u548c\u5206\u652f\u5904\u7406\u9636\u6bb5\u4e24\u4e2a\u4e3b\u8981\u9636\u6bb5\u3002", "result": "\u8bba\u6587\u672a\u5728\u6458\u8981\u4e2d\u63d0\u4f9b\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\u3002", "conclusion": "DTKG\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u65e8\u5728\u63d0\u9ad8\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2510.16168", "categories": ["cs.CR", "C.2.0; C.2.2; K.6.5"], "pdf": "https://arxiv.org/pdf/2510.16168", "abs": "https://arxiv.org/abs/2510.16168", "authors": ["Ahmed Fouad Kadhim Koysha", "Aytug Boyaci", "Rafet Akdeniz"], "title": "WebRTC Metadata and IP Leakage in Modern Browsers: A Cross-Platform Measurement Study", "comment": "14 pages, 7 figures. This preprint is under review at a Taylor &\n  Francis journal", "summary": "Web Real-Time Communication (WebRTC) enables real-time peer-to-peer\ncommunication, but its Interactive Connectivity Establishment (ICE) process can\nunintentionally expose internal and public IP addresses as metadata. This paper\npresents a cross-platform measurement study of WebRTC metadata leakage using\ncurrent (2025) builds of Chrome, Brave, Firefox, and Tor on desktop and mobile\nplatforms. Experiments were conducted across semi-trusted Wi-Fi and untrusted\nmobile carrier networks. Results show that Chrome remains the most\nleakage-prone, disclosing LAN or Carrier-Grade NAT (CGNAT) addresses on mobile\nand metadata on desktop; Brave avoids direct IP leaks but exposes\nsession-stable mDNS identifiers; Firefox provides strong protection on desktop\nbut leaks internal IPs on Android; and Tor consistently prevents all forms of\nleakage. We introduce a structured threat model for semi-trusted environments\nand evaluate the limitations of mDNS obfuscation. Finally, we propose layered\nmitigation strategies combining browser defaults, institutional safeguards, and\nuser controls. Findings demonstrate that while direct LAN leakage is declining,\nemerging vectors such as mDNS and CGNAT create persistent privacy risks\nrequiring protocol-level redesign and policy action.", "AI": {"tldr": "\u5bf9Chrome\u3001Brave\u3001Firefox\u548cTor\u6d4f\u89c8\u5668\u5728\u684c\u9762\u548c\u79fb\u52a8\u5e73\u53f0\u7684WebRTC\u5143\u6570\u636e\u6cc4\u6f0f\u8fdb\u884c\u8de8\u5e73\u53f0\u6d4b\u91cf\u7814\u7a76\uff0c\u53d1\u73b0Chrome\u6cc4\u6f0f\u6700\u4e25\u91cd\uff0cBrave\u4f7f\u7528mDNS\u6807\u8bc6\u7b26\uff0cFirefox\u5728\u684c\u9762\u7aef\u4fdd\u62a4\u5f3a\u4f46\u5728Android\u6cc4\u6f0f\uff0cTor\u5b8c\u5168\u9632\u6b62\u6cc4\u6f0f\u3002", "motivation": "WebRTC\u7684ICE\u8fc7\u7a0b\u53ef\u80fd\u65e0\u610f\u4e2d\u66b4\u9732\u5185\u90e8\u548c\u516c\u5171IP\u5730\u5740\u4f5c\u4e3a\u5143\u6570\u636e\uff0c\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u9700\u8981\u8bc4\u4f30\u5f53\u524d\u6d4f\u89c8\u5668\u7684\u4fdd\u62a4\u72b6\u51b5\u3002", "method": "\u4f7f\u75282025\u5e74\u7248\u672c\u7684Chrome\u3001Brave\u3001Firefox\u548cTor\u6d4f\u89c8\u5668\uff0c\u5728\u684c\u9762\u548c\u79fb\u52a8\u5e73\u53f0\u4e0a\uff0c\u901a\u8fc7\u534a\u53ef\u4fe1Wi-Fi\u548c\u4e0d\u53ef\u4fe1\u79fb\u52a8\u8fd0\u8425\u5546\u7f51\u7edc\u8fdb\u884c\u5b9e\u9a8c\u6d4b\u91cf\u3002", "result": "Chrome\u5728\u79fb\u52a8\u7aef\u6cc4\u6f0fLAN\u6216CGNAT\u5730\u5740\uff0c\u684c\u9762\u7aef\u6cc4\u6f0f\u5143\u6570\u636e\uff1bBrave\u907f\u514d\u76f4\u63a5IP\u6cc4\u6f0f\u4f46\u66b4\u9732mDNS\u6807\u8bc6\u7b26\uff1bFirefox\u684c\u9762\u7aef\u4fdd\u62a4\u5f3a\u4f46Android\u6cc4\u6f0f\u5185\u90e8IP\uff1bTor\u5b8c\u5168\u9632\u6b62\u6240\u6709\u6cc4\u6f0f\u5f62\u5f0f\u3002", "conclusion": "\u867d\u7136\u76f4\u63a5LAN\u6cc4\u6f0f\u5728\u51cf\u5c11\uff0c\u4f46mDNS\u548cCGNAT\u7b49\u65b0\u5174\u5411\u91cf\u9020\u6210\u6301\u7eed\u9690\u79c1\u98ce\u9669\uff0c\u9700\u8981\u534f\u8bae\u7ea7\u91cd\u65b0\u8bbe\u8ba1\u548c\u653f\u7b56\u884c\u52a8\uff0c\u63d0\u51fa\u4e86\u5206\u5c42\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2510.16309", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16309", "abs": "https://arxiv.org/abs/2510.16309", "authors": ["Crystal Su"], "title": "MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier", "comment": "Accepted to the Annual Conference on Neural Information Processing\n  Systems (NeurIPS 2026) Workshop", "summary": "Large language models (LLMs) often produce fluent reasoning steps while\nviolating simple mathematical or logical constraints. We introduce MedRule-KG,\na compact typed knowledge graph coupled with a symbolic verifier, designed to\nenforce mathematically interpretable rules in reasoning tasks. MedRule-KG\nencodes entities, relations, and three domain-inspired rules, while the\nverifier checks predictions and applies minimal corrections to guarantee\nconsistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG\nimproves exact match (EM) from 0.767 to 0.900, and adding the verifier yields\n1.000 EM while eliminating rule violations entirely. We demonstrate how\nMedRule-KG provides a general scaffold for safe mathematical reasoning, discuss\nablations, and release code and data to encourage reproducibility.", "AI": {"tldr": "MedRule-KG\u662f\u4e00\u4e2a\u7d27\u51d1\u578b\u77e5\u8bc6\u56fe\u8c31\u4e0e\u7b26\u53f7\u9a8c\u8bc1\u5668\uff0c\u901a\u8fc7\u5f3a\u5236\u6267\u884c\u6570\u5b66\u53ef\u89e3\u91ca\u89c4\u5219\u6765\u6539\u5584\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7ecf\u5e38\u8fdd\u53cd\u7b80\u5355\u7684\u6570\u5b66\u6216\u903b\u8f91\u7ea6\u675f\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u786e\u4fdd\u63a8\u7406\u7684\u6570\u5b66\u4e00\u81f4\u6027\u3002", "method": "\u6784\u5efaMedRule-KG\u77e5\u8bc6\u56fe\u8c31\u7f16\u7801\u5b9e\u4f53\u3001\u5173\u7cfb\u548c\u9886\u57df\u89c4\u5219\uff0c\u914d\u5408\u7b26\u53f7\u9a8c\u8bc1\u5668\u68c0\u67e5\u9884\u6d4b\u5e76\u5e94\u7528\u6700\u5c0f\u4fee\u6b63\u4ee5\u4fdd\u8bc1\u4e00\u81f4\u6027\u3002", "result": "\u572890\u4e2aFDA\u884d\u751f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528MedRule-KG\u5c06\u7cbe\u786e\u5339\u914d\u4ece0.767\u63d0\u5347\u52300.900\uff0c\u6dfb\u52a0\u9a8c\u8bc1\u5668\u540e\u8fbe\u52301.000\u7cbe\u786e\u5339\u914d\u5e76\u5b8c\u5168\u6d88\u9664\u89c4\u5219\u8fdd\u89c4\u3002", "conclusion": "MedRule-KG\u4e3a\u5b89\u5168\u6570\u5b66\u63a8\u7406\u63d0\u4f9b\u4e86\u901a\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u548c\u7b26\u53f7\u9a8c\u8bc1\u786e\u4fdd\u63a8\u7406\u7684\u6570\u5b66\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.16219", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16219", "abs": "https://arxiv.org/abs/2510.16219", "authors": ["Yang Feng", "Xudong Pan"], "title": "SentinelNet: Safeguarding Multi-Agent Collaboration Through Credit-Based Dynamic Threat Detection", "comment": null, "summary": "Malicious agents pose significant threats to the reliability and\ndecision-making capabilities of Multi-Agent Systems (MAS) powered by Large\nLanguage Models (LLMs). Existing defenses often fall short due to reactive\ndesigns or centralized architectures which may introduce single points of\nfailure. To address these challenges, we propose SentinelNet, the first\ndecentralized framework for proactively detecting and mitigating malicious\nbehaviors in multi-agent collaboration. SentinelNet equips each agent with a\ncredit-based detector trained via contrastive learning on augmented adversarial\ndebate trajectories, enabling autonomous evaluation of message credibility and\ndynamic neighbor ranking via bottom-k elimination to suppress malicious\ncommunications. To overcome the scarcity of attack data, it generates\nadversarial trajectories simulating diverse threats, ensuring robust training.\nExperiments on MAS benchmarks show SentinelNet achieves near-perfect detection\nof malicious agents, close to 100% within two debate rounds, and recovers 95%\nof system accuracy from compromised baselines. By exhibiting strong\ngeneralizability across domains and attack patterns, SentinelNet establishes a\nnovel paradigm for safeguarding collaborative MAS.", "AI": {"tldr": "SentinelNet\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u7528\u8bc4\u5206\u548c\u5bf9\u6bd4\u5b66\u4e60\u6765\u4e3b\u52a8\u68c0\u6d4b\u548c\u7f13\u89e3\u6076\u610f\u884c\u4e3a\uff0c\u5728\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5b8c\u7f8e\u7684\u6076\u610f\u667a\u80fd\u4f53\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5b58\u5728\u53cd\u5e94\u5f0f\u8bbe\u8ba1\u6216\u96c6\u4e2d\u5f0f\u67b6\u6784\u7684\u7f3a\u9677\uff0c\u5bb9\u6613\u4ea7\u751f\u5355\u70b9\u6545\u969c\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u6076\u610f\u667a\u80fd\u4f53\u5bf9LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5a01\u80c1\u3002", "method": "\u4e3a\u6bcf\u4e2a\u667a\u80fd\u4f53\u914d\u5907\u57fa\u4e8e\u4fe1\u7528\u7684\u68c0\u6d4b\u5668\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5728\u589e\u5f3a\u7684\u5bf9\u6297\u6027\u8fa9\u8bba\u8f68\u8ff9\u4e0a\u8bad\u7ec3\uff0c\u91c7\u7528bottom-k\u6d88\u9664\u8fdb\u884c\u52a8\u6001\u90bb\u5c45\u6392\u540d\uff0c\u5e76\u751f\u6210\u5bf9\u6297\u6027\u8f68\u8ff9\u6765\u89e3\u51b3\u653b\u51fb\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "result": "\u5728MAS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSentinelNet\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5b8c\u7f8e\u7684\u6076\u610f\u667a\u80fd\u4f53\u68c0\u6d4b\uff08\u4e24\u8f6e\u8fa9\u8bba\u5185\u63a5\u8fd1100%\uff09\uff0c\u4ece\u53d7\u635f\u57fa\u7ebf\u4e2d\u6062\u590d\u4e8695%\u7684\u7cfb\u7edf\u51c6\u786e\u7387\u3002", "conclusion": "SentinelNet\u5efa\u7acb\u4e86\u4fdd\u62a4\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u65b0\u8303\u5f0f\uff0c\u5728\u8de8\u9886\u57df\u548c\u653b\u51fb\u6a21\u5f0f\u4e0a\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.16342", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16342", "abs": "https://arxiv.org/abs/2510.16342", "authors": ["Tong Zhang", "Ru Zhang", "Jianyi Liu", "Zhen Yang", "Gongshen Liu"], "title": "Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts", "comment": null, "summary": "Existing concept erasure methods for text-to-image diffusion models commonly\nrely on fixed anchor strategies, which often lead to critical issues such as\nconcept re-emergence and erosion. To address this, we conduct causal tracing to\nreveal the inherent sensitivity of erasure to anchor selection and define\nSibling Exclusive Concepts as a superior class of anchors. Based on this\ninsight, we propose \\textbf{SELECT} (Sibling-Exclusive Evaluation for\nContextual Targeting), a dynamic anchor selection framework designed to\novercome the limitations of fixed anchors. Our framework introduces a novel\ntwo-stage evaluation mechanism that automatically discovers optimal anchors for\nprecise erasure while identifying critical boundary anchors to preserve related\nconcepts. Extensive evaluations demonstrate that SELECT, as a universal anchor\nsolution, not only efficiently adapts to multiple erasure frameworks but also\nconsistently outperforms existing baselines across key performance metrics,\naveraging only 4 seconds for anchor mining of a single concept.", "AI": {"tldr": "\u63d0\u51fa\u4e86SELECT\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u951a\u70b9\u9009\u62e9\u89e3\u51b3\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u4e2d\u6982\u5ff5\u64e6\u9664\u7684\u951a\u70b9\u654f\u611f\u6027\u95ee\u9898\uff0c\u907f\u514d\u6982\u5ff5\u91cd\u73b0\u548c\u4fb5\u8680\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6982\u5ff5\u64e6\u9664\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u951a\u70b9\u7b56\u7565\uff0c\u5bfc\u81f4\u6982\u5ff5\u91cd\u73b0\u548c\u4fb5\u8680\u7b49\u5173\u952e\u95ee\u9898\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u951a\u70b9\u9009\u62e9\u673a\u5236\u3002", "method": "\u57fa\u4e8e\u56e0\u679c\u8ffd\u8e2a\u5206\u6790\u951a\u70b9\u654f\u611f\u6027\uff0c\u5b9a\u4e49\u5144\u5f1f\u6392\u4ed6\u6982\u5ff5\u4f5c\u4e3a\u4f18\u8d28\u951a\u70b9\u7c7b\u522b\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u8bc4\u4f30\u673a\u5236\u81ea\u52a8\u53d1\u73b0\u6700\u4f18\u64e6\u9664\u951a\u70b9\u548c\u8fb9\u754c\u951a\u70b9\u3002", "result": "SELECT\u4f5c\u4e3a\u901a\u7528\u951a\u70b9\u89e3\u51b3\u65b9\u6848\uff0c\u9ad8\u6548\u9002\u914d\u591a\u79cd\u64e6\u9664\u6846\u67b6\uff0c\u5728\u5173\u952e\u6027\u80fd\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5355\u4e2a\u6982\u5ff5\u951a\u70b9\u6316\u6398\u4ec5\u97004\u79d2\u3002", "conclusion": "\u52a8\u6001\u951a\u70b9\u9009\u62e9\u6846\u67b6SELECT\u80fd\u591f\u6709\u6548\u89e3\u51b3\u56fa\u5b9a\u951a\u70b9\u7b56\u7565\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u7cbe\u786e\u6982\u5ff5\u64e6\u9664\u540c\u65f6\u4fdd\u62a4\u76f8\u5173\u6982\u5ff5\u3002"}}
{"id": "2510.16229", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16229", "abs": "https://arxiv.org/abs/2510.16229", "authors": ["Vienna Li", "Justin Villa", "Dan Diessner", "Jayson Clifford", "Laxima Niure Kandel"], "title": "C/N0 Analysis-Based GPS Spoofing Detection with Variable Antenna Orientations", "comment": null, "summary": "GPS spoofing poses a growing threat to aviation by falsifying satellite\nsignals and misleading aircraft navigation systems. This paper demonstrates a\nproof-of-concept spoofing detection strategy based on analyzing satellite\nCarrier-to-Noise Density Ratio (C/N$_0$) variation during controlled static\nantenna orientations. Using a u-blox EVK-M8U receiver and a GPSG-1000 satellite\nsimulator, C/N$_0$ data is collected under three antenna orientations flat,\nbanked right, and banked left) in both real-sky (non-spoofed) and spoofed\nenvironments. Our findings reveal that under non-spoofed signals, C/N$_0$\nvalues fluctuate naturally with orientation, reflecting true geometric\ndependencies. However, spoofed signals demonstrate a distinct pattern: the flat\norientation, which directly faces the spoofing antenna, consistently yielded\nthe highest C/N$_0$ values, while both banked orientations showed reduced\nC/N$_0$ due to misalignment with the spoofing source. These findings suggest\nthat simple maneuvers such as brief banking to induce C/N$_0$ variations can\nprovide early cues of GPS spoofing for general aviation and UAV systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u536b\u661f\u8f7d\u566a\u6bd4(C/N\u2080)\u53d8\u5316\u7684GPS\u6b3a\u9a97\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5929\u7ebf\u5728\u4e0d\u540c\u65b9\u5411\u65f6\u7684\u4fe1\u53f7\u53d8\u5316\u6765\u8bc6\u522b\u6b3a\u9a97\u4fe1\u53f7\u3002", "motivation": "GPS\u6b3a\u9a97\u5bf9\u822a\u7a7a\u5b89\u5168\u6784\u6210\u65e5\u76ca\u4e25\u91cd\u7684\u5a01\u80c1\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u6765\u4fdd\u62a4\u98de\u673a\u5bfc\u822a\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528u-blox EVK-M8U\u63a5\u6536\u5668\u548cGPSG-1000\u536b\u661f\u6a21\u62df\u5668\uff0c\u5728\u5e73\u5766\u3001\u53f3\u503e\u548c\u5de6\u503e\u4e09\u79cd\u5929\u7ebf\u65b9\u5411\u4e0b\u6536\u96c6\u771f\u5b9e\u5929\u7a7a\u4fe1\u53f7\u548c\u6b3a\u9a97\u4fe1\u53f7\u7684C/N\u2080\u6570\u636e\u3002", "result": "\u771f\u5b9e\u4fe1\u53f7\u4e0bC/N\u2080\u968f\u65b9\u5411\u81ea\u7136\u6ce2\u52a8\uff0c\u800c\u6b3a\u9a97\u4fe1\u53f7\u5728\u5e73\u5766\u65b9\u5411\u65f6C/N\u2080\u6700\u9ad8\uff0c\u503e\u659c\u65b9\u5411\u65f6\u56e0\u4e0e\u6b3a\u9a97\u6e90\u4e0d\u5bf9\u9f50\u800c\u964d\u4f4e\u3002", "conclusion": "\u7b80\u5355\u7684\u673a\u52a8\u52a8\u4f5c\u5982\u77ed\u6682\u503e\u659c\u5f15\u8d77\u7684C/N\u2080\u53d8\u5316\u53ef\u4ee5\u4e3a\u901a\u7528\u822a\u7a7a\u548c\u65e0\u4eba\u673a\u7cfb\u7edf\u63d0\u4f9bGPS\u6b3a\u9a97\u7684\u65e9\u671f\u9884\u8b66\u3002"}}
{"id": "2510.16368", "categories": ["cs.AI", "cs.HC", "cs.LG", "econ.TH"], "pdf": "https://arxiv.org/pdf/2510.16368", "abs": "https://arxiv.org/abs/2510.16368", "authors": ["Ali Shirali"], "title": "The Burden of Interactive Alignment with Inconsistent Preferences", "comment": "Published as a conference paper at NeurIPS 2025", "summary": "From media platforms to chatbots, algorithms shape how people interact,\nlearn, and discover information. Such interactions between users and an\nalgorithm often unfold over multiple steps, during which strategic users can\nguide the algorithm to better align with their true interests by selectively\nengaging with content. However, users frequently exhibit inconsistent\npreferences: they may spend considerable time on content that offers little\nlong-term value, inadvertently signaling that such content is desirable.\nFocusing on the user side, this raises a key question: what does it take for\nsuch users to align the algorithm with their true interests?\n  To investigate these dynamics, we model the user's decision process as split\nbetween a rational system 2 that decides whether to engage and an impulsive\nsystem 1 that determines how long engagement lasts. We then study a\nmulti-leader, single-follower extensive Stackelberg game, where users,\nspecifically system 2, lead by committing to engagement strategies and the\nalgorithm best-responds based on observed interactions. We define the burden of\nalignment as the minimum horizon over which users must optimize to effectively\nsteer the algorithm. We show that a critical horizon exists: users who are\nsufficiently foresighted can achieve alignment, while those who are not are\ninstead aligned to the algorithm's objective. This critical horizon can be\nlong, imposing a substantial burden. However, even a small, costly signal\n(e.g., an extra click) can significantly reduce it. Overall, our framework\nexplains how users with inconsistent preferences can align an engagement-driven\nalgorithm with their interests in a Stackelberg equilibrium, highlighting both\nthe challenges and potential remedies for achieving alignment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u7528\u6237\u5982\u4f55\u901a\u8fc7\u7b56\u7565\u6027\u4e92\u52a8\u6765\u5f15\u5bfc\u7b97\u6cd5\u4e0e\u5176\u771f\u5b9e\u5174\u8da3\u5bf9\u9f50\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u7cfb\u7edf\u51b3\u7b56\u6a21\u578b\u548cStackelberg\u535a\u5f08\u6846\u67b6\uff0c\u5b9a\u4e49\u4e86\"\u5bf9\u9f50\u8d1f\u62c5\"\u6982\u5ff5\uff0c\u5e76\u53d1\u73b0\u5173\u952e\u65f6\u95f4\u8303\u56f4\u7684\u5b58\u5728\u4ee5\u53ca\u5c0f\u6210\u672c\u4fe1\u53f7\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u5bf9\u9f50\u8d1f\u62c5\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u6e90\u4e8e\u7528\u6237\u5728\u4e0e\u7b97\u6cd5\u4e92\u52a8\u65f6\u7ecf\u5e38\u8868\u73b0\u51fa\u4e0d\u4e00\u81f4\u7684\u504f\u597d\uff0c\u4ed6\u4eec\u53ef\u80fd\u4f1a\u82b1\u8d39\u5927\u91cf\u65f6\u95f4\u5728\u4f4e\u4ef7\u503c\u5185\u5bb9\u4e0a\uff0c\u65e0\u610f\u4e2d\u5411\u7b97\u6cd5\u53d1\u51fa\u9519\u8bef\u4fe1\u53f7\u3002\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u8fd9\u7c7b\u7528\u6237\u9700\u8981\u4ec0\u4e48\u6761\u4ef6\u624d\u80fd\u8ba9\u7b97\u6cd5\u4e0e\u5176\u771f\u5b9e\u5174\u8da3\u5bf9\u9f50\uff1f", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u5c06\u7528\u6237\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u7406\u6027\u7cfb\u7edf2\uff08\u51b3\u5b9a\u662f\u5426\u53c2\u4e0e\uff09\u548c\u51b2\u52a8\u7cfb\u7edf1\uff08\u51b3\u5b9a\u53c2\u4e0e\u65f6\u957f\uff09\u7684\u53cc\u7cfb\u7edf\u6a21\u578b\uff1b2\uff09\u6784\u5efa\u591a\u9886\u5bfc\u8005-\u5355\u8ffd\u968f\u8005\u7684\u6269\u5c55Stackelberg\u535a\u5f08\u6846\u67b6\uff0c\u7528\u6237\u4f5c\u4e3a\u9886\u5bfc\u8005\u901a\u8fc7\u627f\u8bfa\u53c2\u4e0e\u7b56\u7565\u6765\u5f15\u5bfc\u7b97\u6cd5\uff1b3\uff09\u5b9a\u4e49\u5bf9\u9f50\u8d1f\u62c5\u4f5c\u4e3a\u7528\u6237\u6709\u6548\u5f15\u5bfc\u7b97\u6cd5\u6240\u9700\u7684\u6700\u5c0f\u4f18\u5316\u65f6\u95f4\u8303\u56f4\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\u5b58\u5728\u4e00\u4e2a\u5173\u952e\u65f6\u95f4\u8303\u56f4\uff1a\u8db3\u591f\u6709\u8fdc\u89c1\u7684\u7528\u6237\u53ef\u4ee5\u5b9e\u73b0\u7b97\u6cd5\u5bf9\u9f50\uff0c\u800c\u7f3a\u4e4f\u8fdc\u89c1\u7684\u7528\u6237\u5219\u4f1a\u88ab\u7b97\u6cd5\u76ee\u6807\u6240\u540c\u5316\u3002\u8fd9\u4e2a\u5173\u952e\u65f6\u95f4\u8303\u56f4\u53ef\u80fd\u5f88\u957f\uff0c\u5e26\u6765\u663e\u8457\u7684\u5bf9\u9f50\u8d1f\u62c5\u3002\u4f46\u5373\u4f7f\u662f\u4e00\u4e2a\u5c0f\u7684\u3001\u6709\u6210\u672c\u7684\u4fe1\u53f7\uff08\u5982\u989d\u5916\u70b9\u51fb\uff09\u4e5f\u80fd\u663e\u8457\u964d\u4f4e\u8fd9\u4e00\u8d1f\u62c5\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\uff0c\u5177\u6709\u4e0d\u4e00\u81f4\u504f\u597d\u7684\u7528\u6237\u53ef\u4ee5\u5728Stackelberg\u5747\u8861\u4e2d\u901a\u8fc7\u7b56\u7565\u6027\u4e92\u52a8\u5b9e\u73b0\u4e0e\u53c2\u4e0e\u9a71\u52a8\u7b97\u6cd5\u7684\u5bf9\u9f50\u3002\u8be5\u6846\u67b6\u63ed\u793a\u4e86\u5b9e\u73b0\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u8fc7\u5c0f\u6210\u672c\u4fe1\u53f7\u964d\u4f4e\u5bf9\u9f50\u8d1f\u62c5\u7684\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16251", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16251", "abs": "https://arxiv.org/abs/2510.16251", "authors": ["Changyu Zhao", "Yohan Beugin", "Jean-Charles Noirot Ferrand", "Quinn Burke", "Guancheng Li", "Patrick McDaniel"], "title": "LibIHT: A Hardware-Based Approach to Efficient and Evasion-Resistant Dynamic Binary Analysis", "comment": "Accepted in Proceedings of the 2025 Workshop on Software\n  Understanding and Reverse Engineering (SURE'25), October 13-17, 2025, Taipei,\n  Taiwan", "summary": "Dynamic program analysis is invaluable for malware detection, debugging, and\nperformance profiling. However, software-based instrumentation incurs high\noverhead and can be evaded by anti-analysis techniques. In this paper, we\npropose LibIHT, a hardware-assisted tracing framework that leverages on-CPU\nbranch tracing features (Intel Last Branch Record and Branch Trace Store) to\nefficiently capture program control-flow with minimal performance impact. Our\napproach reconstructs control-flow graphs (CFGs) by collecting hardware\ngenerated branch execution data in the kernel, preserving program behavior\nagainst evasive malware. We implement LibIHT as an OS kernel module and\nuser-space library, and evaluate it on both benign benchmark programs and\nadversarial anti-instrumentation samples. Our results indicate that LibIHT\nreduces runtime overhead by over 150x compared to Intel Pin (7x vs 1,053x\nslowdowns), while achieving high fidelity in CFG reconstruction (capturing over\n99% of execution basic blocks and edges). Although this hardware-assisted\napproach sacrifices the richer semantic detail available from full software\ninstrumentation by capturing only branch addresses, this trade-off is\nacceptable for many applications where performance and low detectability are\nparamount. Our findings show that hardware-based tracing captures control flow\ninformation significantly faster, reduces detection risk and performs dynamic\nanalysis with minimal interference.", "AI": {"tldr": "LibIHT\u662f\u4e00\u4e2a\u57fa\u4e8e\u786c\u4ef6\u8f85\u52a9\u8ffd\u8e2a\u7684\u6846\u67b6\uff0c\u5229\u7528CPU\u5206\u652f\u8ffd\u8e2a\u529f\u80fd\u9ad8\u6548\u6355\u83b7\u7a0b\u5e8f\u63a7\u5236\u6d41\uff0c\u76f8\u6bd4\u8f6f\u4ef6\u63d2\u6869\u663e\u8457\u964d\u4f4e\u6027\u80fd\u5f00\u9500\uff0c\u540c\u65f6\u6709\u6548\u5bf9\u6297\u89c4\u907f\u6027\u6076\u610f\u8f6f\u4ef6\u3002", "motivation": "\u8f6f\u4ef6\u63d2\u6869\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u3001\u8c03\u8bd5\u548c\u6027\u80fd\u5206\u6790\u4e2d\u9762\u4e34\u9ad8\u5f00\u9500\u548c\u53cd\u5206\u6790\u6280\u672f\u89c4\u907f\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u4e14\u96be\u4ee5\u68c0\u6d4b\u7684\u8ffd\u8e2a\u65b9\u6cd5\u3002", "method": "\u5229\u7528Intel Last Branch Record\u548cBranch Trace Store\u7b49CPU\u5206\u652f\u8ffd\u8e2a\u529f\u80fd\uff0c\u5728\u5185\u6838\u4e2d\u6536\u96c6\u786c\u4ef6\u751f\u6210\u7684\u5206\u652f\u6267\u884c\u6570\u636e\uff0c\u91cd\u5efa\u63a7\u5236\u6d41\u56fe(CFG)\uff0c\u5b9e\u73b0\u4e3aOS\u5185\u6838\u6a21\u5757\u548c\u7528\u6237\u7a7a\u95f4\u5e93\u3002", "result": "\u76f8\u6bd4Intel Pin\u51cf\u5c11150\u500d\u4ee5\u4e0a\u7684\u8fd0\u884c\u65f6\u5f00\u9500\uff087\u500dvs 1,053\u500d\u51cf\u901f\uff09\uff0c\u5728CFG\u91cd\u5efa\u4e2d\u6355\u83b7\u8d85\u8fc799%\u7684\u6267\u884c\u57fa\u672c\u5757\u548c\u8fb9\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u786c\u4ef6\u8f85\u52a9\u8ffd\u8e2a\u5728\u6027\u80fd\u548c\u4f4e\u53ef\u68c0\u6d4b\u6027\u81f3\u5173\u91cd\u8981\u7684\u5e94\u7528\u4e2d\u662f\u53ef\u63a5\u53d7\u7684\u6743\u8861\uff0c\u80fd\u591f\u4ee5\u6700\u5c0f\u5e72\u6270\u663e\u8457\u66f4\u5feb\u5730\u6355\u83b7\u63a7\u5236\u6d41\u4fe1\u606f\u5e76\u964d\u4f4e\u68c0\u6d4b\u98ce\u9669\u3002"}}
{"id": "2510.16374", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16374", "abs": "https://arxiv.org/abs/2510.16374", "authors": ["Nick Oh"], "title": "Before you <think>, monitor: Implementing Flavell's metacognitive framework in LLMs", "comment": "Presented at the Workshop on the Application of LLM Explainability to\n  Reasoning and Planning at COLM 2025 (non-archival)", "summary": "Current approaches to enhancing LLM reasoning follows two isolated paradigms:\nMonitor-Generate methods like Plan-and-Solve (Wang et al., 2023) and\nSELF-DISCOVER (Zhou et al., 2024) excel at strategic planning but lack\nmechanisms to verify whether selected strategies succeed; while Generate-Verify\napproaches like Self-Verification (Weng et al., 2022) and SELF-REFINE (Madaan\net al., 2023) iteratively refine outputs but commence generation blindly\nwithout task assessment. This separation creates inefficiencies -- strategies\nfail without feedback, and refinement occurs without strategic grounding. We\naddress this gap by implementing Flavell's cognitive monitoring model (1979)\nfrom the broader Monitor-Generate-Verify framework (Oh and Gobet, 2025),\noperationalising it as a three-phase iterative system. On GSM8K, preliminary\nresults show 75.42% accuracy versus 68.44% for SELF-REFINE and 67.07% for\nSelf-Verification, while requiring fewer attempts (1.3 vs 2.0) at 27-37%\nincreased inference cost. These initial findings suggest upfront monitoring\nproduces higher-quality initial solutions that reduce refinement needs, though\nevaluation beyond arithmetic reasoning is needed to establish generalisability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u76d1\u63a7-\u751f\u6210-\u9a8c\u8bc1\u7684\u4e09\u9636\u6bb5\u8fed\u4ee3\u7cfb\u7edf\uff0c\u5728GSM8K\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e8675.42%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u9700\u8981\u66f4\u5c11\u7684\u5c1d\u8bd5\u6b21\u6570\u3002", "motivation": "\u73b0\u6709LLM\u63a8\u7406\u589e\u5f3a\u65b9\u6cd5\u5b58\u5728\u5206\u79bb\uff1a\u76d1\u63a7-\u751f\u6210\u65b9\u6cd5\u64c5\u957f\u7b56\u7565\u89c4\u5212\u4f46\u7f3a\u4e4f\u9a8c\u8bc1\u673a\u5236\uff0c\u751f\u6210-\u9a8c\u8bc1\u65b9\u6cd5\u80fd\u8fed\u4ee3\u4f18\u5316\u4f46\u7f3a\u4e4f\u7b56\u7565\u57fa\u7840\u3002\u8fd9\u79cd\u5206\u79bb\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u57fa\u4e8eFlavell\u7684\u8ba4\u77e5\u76d1\u63a7\u6a21\u578b\uff0c\u5b9e\u73b0\u76d1\u63a7-\u751f\u6210-\u9a8c\u8bc1\u4e09\u9636\u6bb5\u8fed\u4ee3\u7cfb\u7edf\uff0c\u5728\u751f\u6210\u524d\u8fdb\u884c\u4efb\u52a1\u8bc4\u4f30\u548c\u7b56\u7565\u89c4\u5212\u3002", "result": "\u5728GSM8K\u4e0a\u8fbe\u523075.42%\u51c6\u786e\u7387\uff0c\u4f18\u4e8eSELF-REFINE(68.44%)\u548cSelf-Verification(67.07%)\uff0c\u5c1d\u8bd5\u6b21\u6570\u66f4\u5c11(1.3 vs 2.0)\uff0c\u63a8\u7406\u6210\u672c\u589e\u52a027-37%\u3002", "conclusion": "\u524d\u671f\u76d1\u63a7\u80fd\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u521d\u59cb\u89e3\uff0c\u51cf\u5c11\u4f18\u5316\u9700\u6c42\uff0c\u4f46\u9700\u8981\u5728\u7b97\u672f\u63a8\u7406\u4e4b\u5916\u7684\u4efb\u52a1\u4e0a\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u901a\u7528\u6027\u3002"}}
{"id": "2510.16255", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16255", "abs": "https://arxiv.org/abs/2510.16255", "authors": ["Sarah Egler", "John Schulman", "Nicholas Carlini"], "title": "Detecting Adversarial Fine-tuning with Auditing Agents", "comment": null, "summary": "Large Language Model (LLM) providers expose fine-tuning APIs that let end\nusers fine-tune their frontier LLMs. Unfortunately, it has been shown that an\nadversary with fine-tuning access to an LLM can bypass safeguards. Particularly\nconcerning, such attacks may avoid detection with datasets that are only\nimplicitly harmful. Our work studies robust detection mechanisms for\nadversarial use of fine-tuning APIs. We introduce the concept of a fine-tuning\nauditing agent and show it can detect harmful fine-tuning prior to model\ndeployment. We provide our auditing agent with access to the fine-tuning\ndataset, as well as the fine-tuned and pre-fine-tuned models, and request the\nagent assigns a risk score for the fine-tuning job. We evaluate our detection\napproach on a diverse set of eight strong fine-tuning attacks from the\nliterature, along with five benign fine-tuned models, totaling over 1400\nindependent audits. These attacks are undetectable with basic content\nmoderation on the dataset, highlighting the challenge of the task. With the\nbest set of affordances, our auditing agent achieves a 56.2% detection rate of\nadversarial fine-tuning at a 1% false positive rate. Most promising, the\nauditor is able to detect covert cipher attacks that evade safety evaluations\nand content moderation of the dataset. While benign fine-tuning with\nunintentional subtle safety degradation remains a challenge, we establish a\nbaseline configuration for further work in this area. We release our auditing\nagent at https://github.com/safety-research/finetuning-auditor.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9LLM\u5fae\u8c03API\u7684\u5ba1\u8ba1\u4ee3\u7406\uff0c\u80fd\u591f\u68c0\u6d4b\u6709\u5bb3\u7684\u5fae\u8c03\u884c\u4e3a\uff0c\u57281%\u8bef\u62a5\u7387\u4e0b\u8fbe\u523056.2%\u7684\u68c0\u6d4b\u7387\uff0c\u7279\u522b\u80fd\u8bc6\u522b\u89c4\u907f\u5b89\u5168\u8bc4\u4f30\u7684\u9690\u853d\u653b\u51fb\u3002", "motivation": "LLM\u63d0\u4f9b\u5546\u63d0\u4f9b\u5fae\u8c03API\uff0c\u4f46\u653b\u51fb\u8005\u53ef\u80fd\u5229\u7528\u8fd9\u4e9bAPI\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\uff0c\u4f7f\u7528\u9690\u542b\u6709\u5bb3\u7684\u6570\u636e\u96c6\u8fdb\u884c\u653b\u51fb\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u68c0\u6d4b\u673a\u5236\u3002", "method": "\u6784\u5efa\u5fae\u8c03\u5ba1\u8ba1\u4ee3\u7406\uff0c\u63d0\u4f9b\u5bf9\u5fae\u8c03\u6570\u636e\u96c6\u3001\u5fae\u8c03\u524d\u540e\u6a21\u578b\u7684\u8bbf\u95ee\u6743\u9650\uff0c\u8ba9\u4ee3\u7406\u4e3a\u5fae\u8c03\u4efb\u52a1\u5206\u914d\u98ce\u9669\u8bc4\u5206\uff0c\u57288\u79cd\u5f3a\u653b\u51fb\u548c5\u4e2a\u826f\u6027\u6a21\u578b\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u57281400\u591a\u6b21\u72ec\u7acb\u5ba1\u8ba1\u4e2d\uff0c\u6700\u4f73\u914d\u7f6e\u4e0b\u57281%\u8bef\u62a5\u7387\u65f6\u8fbe\u523056.2%\u7684\u68c0\u6d4b\u7387\uff0c\u7279\u522b\u80fd\u68c0\u6d4b\u89c4\u907f\u5b89\u5168\u8bc4\u4f30\u7684\u9690\u853d\u5bc6\u7801\u653b\u51fb\u3002", "conclusion": "\u867d\u7136\u826f\u6027\u5fae\u8c03\u4e2d\u7684\u65e0\u610f\u8bc6\u5b89\u5168\u9000\u5316\u4ecd\u662f\u6311\u6218\uff0c\u4f46\u4e3a\u8fd9\u4e00\u9886\u57df\u5efa\u7acb\u4e86\u57fa\u51c6\u914d\u7f6e\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.16382", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16382", "abs": "https://arxiv.org/abs/2510.16382", "authors": ["Ze Tao", "Jian Zhang", "Haowei Li", "Xianshuai Li", "Yifei Peng", "Xiyao Liu", "Senzhang Wang", "Chao Liu", "Sheng Ren", "Shichao Zhang"], "title": "Humanoid-inspired Causal Representation Learning for Domain Generalization", "comment": null, "summary": "This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a\nnovel causal framework inspired by human intelligence, designed to overcome the\nlimitations of conventional domain generalization models. Unlike approaches\nthat rely on statistics to capture data-label dependencies and learn\ndistortion-invariant representations, HSCM replicates the hierarchical\nprocessing and multi-level learning of human vision systems, focusing on\nmodeling fine-grained causal mechanisms. By disentangling and reweighting key\nimage attributes such as color, texture, and shape, HSCM enhances\ngeneralization across diverse domains, ensuring robust performance and\ninterpretability. Leveraging the flexibility and adaptability of human\nintelligence, our approach enables more effective transfer and learning in\ndynamic, complex environments. Through both theoretical and empirical\nevaluations, we demonstrate that HSCM outperforms existing domain\ngeneralization models, providing a more principled method for capturing causal\nrelationships and improving model robustness. The code is available at\nhttps://github.com/lambett/HSCM.", "AI": {"tldr": "\u63d0\u51fa\u53d7\u4eba\u7c7b\u667a\u80fd\u542f\u53d1\u7684HSCM\u56e0\u679c\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u548c\u91cd\u52a0\u6743\u56fe\u50cf\u5c5e\u6027\uff08\u989c\u8272\u3001\u7eb9\u7406\u3001\u5f62\u72b6\uff09\u6765\u63d0\u5347\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u73b0\u6709\u9886\u57df\u6cdb\u5316\u6a21\u578b\u3002", "motivation": "\u514b\u670d\u4f20\u7edf\u9886\u57df\u6cdb\u5316\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u6a21\u4eff\u4eba\u7c7b\u89c6\u89c9\u7cfb\u7edf\u7684\u5206\u5c42\u5904\u7406\u548c\u591a\u5c42\u6b21\u5b66\u4e60\u673a\u5236\uff0c\u4e13\u6ce8\u4e8e\u5efa\u6a21\u7ec6\u7c92\u5ea6\u56e0\u679c\u673a\u5236\u3002", "method": "\u6784\u5efa\u53d7\u4eba\u7c7b\u667a\u80fd\u542f\u53d1\u7684\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08HSCM\uff09\uff0c\u89e3\u8026\u548c\u91cd\u52a0\u6743\u5173\u952e\u56fe\u50cf\u5c5e\u6027\uff08\u989c\u8272\u3001\u7eb9\u7406\u3001\u5f62\u72b6\uff09\uff0c\u590d\u5236\u4eba\u7c7b\u89c6\u89c9\u7cfb\u7edf\u7684\u5206\u5c42\u5904\u7406\u548c\u591a\u5c42\u6b21\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "HSCM\u5728\u8de8\u9886\u57df\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u9886\u57df\u6cdb\u5316\u6a21\u578b\uff0c\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "HSCM\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u6355\u6349\u56e0\u679c\u5173\u7cfb\u5e76\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u5728\u52a8\u6001\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u8fc1\u79fb\u548c\u5b66\u4e60\u3002"}}
{"id": "2510.16331", "categories": ["cs.CR", "cs.CC"], "pdf": "https://arxiv.org/pdf/2510.16331", "abs": "https://arxiv.org/abs/2510.16331", "authors": ["Fatemeh Jafarian Dehkordi", "Elahe Vedadi", "Alireza Feizbakhsh", "Yasaman Keshtkarjahromi", "Hulya Seferoglu"], "title": "Efficient and Privacy-Preserving Binary Dot Product via Multi-Party Computation", "comment": null, "summary": "Striking a balance between protecting data privacy and enabling collaborative\ncomputation is a critical challenge for distributed machine learning. While\nprivacy-preserving techniques for federated learning have been extensively\ndeveloped, methods for scenarios involving bitwise operations, such as\ntree-based vertical federated learning (VFL), are still underexplored.\nTraditional mechanisms, including Shamir's secret sharing and multi-party\ncomputation (MPC), are not optimized for bitwise operations over binary data,\nparticularly in settings where each participant holds a different part of the\nbinary vector. This paper addresses the limitations of existing methods by\nproposing a novel binary multi-party computation (BiMPC) framework. The BiMPC\nmechanism facilitates privacy-preserving bitwise operations, with a particular\nfocus on dot product computations of binary vectors, ensuring the privacy of\neach individual bit. The core of BiMPC is a novel approach called Dot Product\nvia Modular Addition (DoMA), which uses regular and modular additions for\nefficient binary dot product calculation. To ensure privacy, BiMPC uses random\nmasking in a higher field for linear computations and a three-party oblivious\ntransfer (triot) protocol for non-linear binary operations. The privacy\nguarantees of the BiMPC framework are rigorously analyzed, demonstrating its\nefficiency and scalability in distributed settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u4e8c\u8fdb\u5236\u591a\u65b9\u8ba1\u7b97\u6846\u67b6BiMPC\uff0c\u4e13\u95e8\u9488\u5bf9\u6811\u57fa\u5782\u76f4\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6309\u4f4d\u64cd\u4f5c\uff0c\u901a\u8fc7DoMA\u65b9\u6cd5\u548c\u4e09\u65b9\u5411\u4e0d\u7ecf\u610f\u4f20\u8f93\u534f\u8bae\u5b9e\u73b0\u9ad8\u6548\u7684\u4e8c\u8fdb\u5236\u5411\u91cf\u70b9\u79ef\u8ba1\u7b97\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u4e2d\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u4e0e\u534f\u540c\u8ba1\u7b97\u4e4b\u95f4\u7684\u5e73\u8861\u662f\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5982Shamir\u79d8\u5bc6\u5171\u4eab\u548c\u591a\u65b9\u8ba1\u7b97\u5bf9\u4e8c\u8fdb\u5236\u6570\u636e\u7684\u6309\u4f4d\u64cd\u4f5c\u4f18\u5316\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u6bcf\u4e2a\u53c2\u4e0e\u8005\u6301\u6709\u4e8c\u8fdb\u5236\u5411\u91cf\u4e0d\u540c\u90e8\u5206\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51faBiMPC\u6846\u67b6\uff0c\u6838\u5fc3\u662fDoMA\u65b9\u6cd5\uff0c\u4f7f\u7528\u5e38\u89c4\u548c\u6a21\u52a0\u6cd5\u8fdb\u884c\u4e8c\u8fdb\u5236\u70b9\u79ef\u8ba1\u7b97\u3002\u91c7\u7528\u9ad8\u57df\u968f\u673a\u63a9\u7801\u8fdb\u884c\u7ebf\u6027\u8ba1\u7b97\uff0c\u4f7f\u7528\u4e09\u65b9\u5411\u4e0d\u7ecf\u610f\u4f20\u8f93\u534f\u8bae\u5904\u7406\u975e\u7ebf\u6027\u4e8c\u8fdb\u5236\u64cd\u4f5c\u3002", "result": "BiMPC\u6846\u67b6\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u80fd\u591f\u4fdd\u62a4\u6bcf\u4e2a\u6bd4\u7279\u7684\u9690\u79c1\u3002", "conclusion": "BiMPC\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u4e8c\u8fdb\u5236\u6309\u4f4d\u64cd\u4f5c\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6811\u57fa\u5782\u76f4\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4f18\u5316\u7684\u9690\u79c1\u4fdd\u62a4\u8ba1\u7b97\u65b9\u6848\u3002"}}
{"id": "2510.16392", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16392", "abs": "https://arxiv.org/abs/2510.16392", "authors": ["Ao Tian", "Yunfeng Lu", "Xinxin Fan", "Changhao Wang", "Lanzhi Zhou", "Yeyao Zhang", "Yanfang Liu"], "title": "RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile", "comment": "11 pages,3 figures", "summary": "Personalized and continuous interactions are the key to enhancing user\nexperience in today's large language model (LLM)-based conversational systems,\nhowever, the finite context windows and static parametric memory make it\ndifficult to model the cross-session long-term user states and behavioral\nconsistency. Currently, the existing solutions to this predicament, such as\nretrieval-augmented generation (RAG) and explicit memory systems, primarily\nfocus on fact-level storage and retrieval, lacking the capability to distill\nlatent preferences and deep traits from the multi-turn dialogues, which limits\nthe long-term and effective user modeling, directly leading to the personalized\ninteractions remaining shallow, and hindering the cross-session continuity. To\nrealize the long-term memory and behavioral consistency for Language Agents in\nLLM era, we propose a self-evolving memory framework RGMem, inspired by the\nideology of classic renormalization group (RG) in physics, this framework\nenables to organize the dialogue history in multiple scales: it first extracts\nsemantics and user insights from episodic fragments, then through hierarchical\ncoarse-graining and rescaling operations, progressively forms a\ndynamically-evolved user profile. The core innovation of our work lies in\nmodeling memory evolution as a multi-scale process of information compression\nand emergence, which accomplishes the high-level and accurate user profiles\nfrom noisy and microscopic-level interactions.", "AI": {"tldr": "\u63d0\u51fa\u4e86RGMem\u6846\u67b6\uff0c\u901a\u8fc7\u53d7\u7269\u7406\u5b66\u91cd\u6574\u5316\u7fa4\u542f\u53d1\u7684\u591a\u5c3a\u5ea6\u8bb0\u5fc6\u7ec4\u7ec7\u65b9\u6cd5\uff0c\u4ece\u5bf9\u8bdd\u5386\u53f2\u4e2d\u63d0\u53d6\u7528\u6237\u6df1\u5c42\u504f\u597d\u548c\u7279\u8d28\uff0c\u5b9e\u73b0\u957f\u671f\u7528\u6237\u5efa\u6a21\u548c\u884c\u4e3a\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709LLM\u5bf9\u8bdd\u7cfb\u7edf\u53d7\u9650\u4e8e\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u548c\u9759\u6001\u53c2\u6570\u8bb0\u5fc6\uff0c\u96be\u4ee5\u5efa\u6a21\u8de8\u4f1a\u8bdd\u7684\u957f\u671f\u7528\u6237\u72b6\u6001\u548c\u884c\u4e3a\u4e00\u81f4\u6027\u3002RAG\u548c\u663e\u5f0f\u8bb0\u5fc6\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8\u4e8b\u5b9e\u7ea7\u5b58\u50a8\u68c0\u7d22\uff0c\u7f3a\u4e4f\u4ece\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u63d0\u53d6\u6f5c\u5728\u504f\u597d\u548c\u6df1\u5c42\u7279\u8d28\u7684\u80fd\u529b\u3002", "method": "RGMem\u6846\u67b6\u91c7\u7528\u591a\u5c3a\u5ea6\u8bb0\u5fc6\u7ec4\u7ec7\uff1a\u4ece\u7247\u6bb5\u7ea7\u5bf9\u8bdd\u4e2d\u63d0\u53d6\u8bed\u4e49\u548c\u7528\u6237\u6d1e\u5bdf\uff0c\u901a\u8fc7\u5206\u5c42\u7c97\u7c92\u5316\u548c\u91cd\u6807\u5ea6\u64cd\u4f5c\uff0c\u9010\u6b65\u5f62\u6210\u52a8\u6001\u6f14\u5316\u7684\u7528\u6237\u6863\u6848\u3002\u6838\u5fc3\u521b\u65b0\u662f\u5c06\u8bb0\u5fc6\u6f14\u5316\u5efa\u6a21\u4e3a\u4fe1\u606f\u538b\u7f29\u548c\u6d8c\u73b0\u7684\u591a\u5c3a\u5ea6\u8fc7\u7a0b\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u4ece\u566a\u58f0\u548c\u5fae\u89c2\u5c42\u9762\u7684\u4ea4\u4e92\u4e2d\u5b9e\u73b0\u9ad8\u7ea7\u522b\u3001\u51c6\u786e\u7684\u7528\u6237\u6863\u6848\u6784\u5efa\uff0c\u89e3\u51b3\u4e86\u957f\u671f\u7528\u6237\u5efa\u6a21\u7684\u6311\u6218\u3002", "conclusion": "RGMem\u6846\u67b6\u901a\u8fc7\u591a\u5c3a\u5ea6\u8bb0\u5fc6\u6f14\u5316\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4e86\u8bed\u8a00\u4ee3\u7406\u5728LLM\u65f6\u4ee3\u7684\u957f\u671f\u8bb0\u5fc6\u548c\u884c\u4e3a\u4e00\u81f4\u6027\uff0c\u4e3a\u4e2a\u6027\u5316\u4ea4\u4e92\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u548c\u8fde\u7eed\u7684\u652f\u6301\u3002"}}
{"id": "2510.16367", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16367", "abs": "https://arxiv.org/abs/2510.16367", "authors": ["Shuai Li", "Kejiang Chen", "Jun Jiang", "Jie Zhang", "Qiyi Yao", "Kai Zeng", "Weiming Zhang", "Nenghai Yu"], "title": "EditMark: Watermarking Large Language Models based on Model Editing", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities, but\ntheir training requires extensive data and computational resources, rendering\nthem valuable digital assets. Therefore, it is essential to watermark LLMs to\nprotect their copyright and trace unauthorized use or resale. Existing methods\nfor watermarking LLMs primarily rely on training LLMs with a watermarked\ndataset, which entails burdensome training costs and negatively impacts the\nLLM's performance. In addition, their watermarked texts are not logical or\nnatural, thereby reducing the stealthiness of the watermark. To address these\nissues, we propose EditMark, the first watermarking method that leverages model\nediting to embed a training-free, stealthy, and performance-lossless watermark\nfor LLMs. We observe that some questions have multiple correct answers.\nTherefore, we assign each answer a unique watermark and update the weights of\nLLMs to generate corresponding questions and answers through the model editing\ntechnique. In addition, we refine the model editing technique to align with the\nrequirements of watermark embedding. Specifically, we introduce an adaptive\nmulti-round stable editing strategy, coupled with the injection of a noise\nmatrix, to improve both the effectiveness and robustness of the watermark\nembedding. Extensive experiments indicate that EditMark can embed 32-bit\nwatermarks into LLMs within 20 seconds (Fine-tuning: 6875 seconds) with a\nwatermark extraction success rate of 100%, which demonstrates its effectiveness\nand efficiency. External experiments further demonstrate that EditMark has\nfidelity, stealthiness, and a certain degree of robustness against common\nattacks.", "AI": {"tldr": "EditMark\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u7f16\u8f91\u7684LLM\u6c34\u5370\u65b9\u6cd5\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5d4c\u5165\u9690\u853d\u4e14\u65e0\u635f\u6027\u80fd\u7684\u6c34\u5370\uff0c\u901a\u8fc7\u591a\u8f6e\u7a33\u5b9a\u7f16\u8f91\u7b56\u7565\u572820\u79d2\u5185\u5d4c\u516532\u4f4d\u6c34\u5370\uff0c\u63d0\u53d6\u6210\u529f\u7387100%\u3002", "motivation": "\u73b0\u6709LLM\u6c34\u5370\u65b9\u6cd5\u9700\u8981\u8bad\u7ec3\u5e26\u6c34\u5370\u7684\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u6210\u672c\u9ad8\u4e14\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff0c\u6c34\u5370\u6587\u672c\u4e0d\u81ea\u7136\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u9690\u853d\u4e14\u4e0d\u5f71\u54cd\u6027\u80fd\u7684\u6c34\u5370\u65b9\u6848\u3002", "method": "\u5229\u7528\u6a21\u578b\u7f16\u8f91\u6280\u672f\uff0c\u4e3a\u591a\u7b54\u6848\u95ee\u9898\u5206\u914d\u552f\u4e00\u6c34\u5370\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u591a\u8f6e\u7a33\u5b9a\u7f16\u8f91\u7b56\u7565\u548c\u566a\u58f0\u77e9\u9635\u6ce8\u5165\u6765\u66f4\u65b0LLM\u6743\u91cd\uff0c\u4f7f\u5176\u751f\u6210\u5bf9\u5e94\u95ee\u7b54\u5bf9\u3002", "result": "\u572820\u79d2\u5185\u6210\u529f\u5d4c\u516532\u4f4d\u6c34\u5370\uff08\u4f20\u7edf\u5fae\u8c03\u97006875\u79d2\uff09\uff0c\u6c34\u5370\u63d0\u53d6\u6210\u529f\u7387100%\uff0c\u5177\u6709\u826f\u597d\u7684\u4fdd\u771f\u5ea6\u3001\u9690\u853d\u6027\u548c\u6297\u653b\u51fb\u9c81\u68d2\u6027\u3002", "conclusion": "EditMark\u662f\u9996\u4e2a\u57fa\u4e8e\u6a21\u578b\u7f16\u8f91\u7684LLM\u6c34\u5370\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u8bad\u7ec3\u514d\u8d39\u3001\u9690\u853d\u4e14\u65e0\u635f\u6027\u80fd\u7684\u6c34\u5370\u5d4c\u5165\uff0c\u4e3aLLM\u7248\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16466", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16466", "abs": "https://arxiv.org/abs/2510.16466", "authors": ["Siddhartha Krothapalli", "Tridib Kumar Das", "Praveen Kumar", "Naveen Suravarpu", "Pratik Narang"], "title": "ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights", "comment": "11 pages, 1 figure, 4 tables", "summary": "As customer feedback becomes increasingly central to strategic growth, the\nability to derive actionable insights from unstructured reviews is essential.\nWhile traditional AI-driven systems excel at predicting user preferences, far\nless work has focused on transforming customer reviews into prescriptive,\nbusiness-facing recommendations. This paper introduces ReviewSense, a novel\nprescriptive decision support framework that leverages advanced large language\nmodels (LLMs) to transform customer reviews into targeted, actionable business\nrecommendations. By identifying key trends, recurring issues, and specific\nconcerns within customer sentiments, ReviewSense extends beyond\npreference-based systems to provide businesses with deeper insights for\nsustaining growth and enhancing customer loyalty. The novelty of this work lies\nin integrating clustering, LLM adaptation, and expert-driven evaluation into a\nunified, business-facing pipeline. Preliminary manual evaluations indicate\nstrong alignment between the model's recommendations and business objectives,\nhighlighting its potential for driving data-informed decision-making. This\nframework offers a new perspective on AI-driven sentiment analysis,\ndemonstrating its value in refining business strategies and maximizing the\nimpact of customer feedback.", "AI": {"tldr": "\u63d0\u51fa\u4e86ReviewSense\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u5546\u4e1a\u5efa\u8bae\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u504f\u597d\u9884\u6d4b\u7cfb\u7edf\u3002", "motivation": "\u5ba2\u6237\u53cd\u9988\u5bf9\u6218\u7565\u589e\u957f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709AI\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8\u504f\u597d\u9884\u6d4b\uff0c\u7f3a\u4e4f\u5c06\u975e\u7ed3\u6784\u5316\u8bc4\u8bba\u8f6c\u5316\u4e3a\u5546\u4e1a\u5efa\u8bae\u7684\u80fd\u529b\u3002", "method": "\u6574\u5408\u805a\u7c7b\u3001LLM\u9002\u5e94\u548c\u4e13\u5bb6\u9a71\u52a8\u8bc4\u4f30\u7684\u7edf\u4e00\u6d41\u7a0b\uff0c\u8bc6\u522b\u5ba2\u6237\u60c5\u7eea\u4e2d\u7684\u5173\u952e\u8d8b\u52bf\u3001\u91cd\u590d\u95ee\u9898\u548c\u5177\u4f53\u5173\u6ce8\u70b9\u3002", "result": "\u521d\u6b65\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u5efa\u8bae\u4e0e\u5546\u4e1a\u76ee\u6807\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5177\u6709\u63a8\u52a8\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u9a71\u52a8\u7684\u60c5\u7eea\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5728\u4f18\u5316\u5546\u4e1a\u7b56\u7565\u548c\u6700\u5927\u5316\u5ba2\u6237\u53cd\u9988\u4ef7\u503c\u65b9\u9762\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2510.16461", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.16461", "abs": "https://arxiv.org/abs/2510.16461", "authors": ["Minjae Seo", "Jaehan Kim", "Eduard Marin", "Myoungsung You", "Taejune Park", "Seungsoo Lee", "Seungwon Shin", "Jinwoo Kim"], "title": "Heimdallr: Fingerprinting SD-WAN Control-Plane Architecture via Encrypted Control Traffic", "comment": "14 pages, 14 figures", "summary": "Software-defined wide area network (SD-WAN) has emerged as a new paradigm for\nsteering a large-scale network flexibly by adopting distributed\nsoftware-defined network (SDN) controllers. The key to building a logically\ncentralized but physically distributed control-plane is running diverse cluster\nmanagement protocols to achieve consistency through an exchange of control\ntraffic. Meanwhile, we observe that the control traffic exposes unique\ntime-series patterns and directional relationships due to the operational\nstructure even though the traffic is encrypted, and this pattern can disclose\nconfidential information such as control-plane topology and protocol\ndependencies, which can be exploited for severe attacks. With this insight, we\npropose a new SD-WAN fingerprinting system, called Heimdallr. It analyzes\nperiodical and operational patterns of SD-WAN cluster management protocols and\nthe context of flow directions from the collected control traffic utilizing a\ndeep learning-based approach, so that it can classify the cluster management\nprotocols automatically from miscellaneous control traffic datasets. Our\nevaluation, which is performed in a realistic SD-WAN environment consisting of\ngeographically distant three campus networks and one enterprise network shows\nthat Heimdallr can classify SD-WAN control traffic with $\\geq$ 93%, identify\nindividual protocols with $\\geq$ 80% macro F-1 scores, and finally can infer\ncontrol-plane topology with $\\geq$ 70% similarity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aHeimdallr\u7684SD-WAN\u6307\u7eb9\u8bc6\u522b\u7cfb\u7edf\uff0c\u80fd\u591f\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u5206\u6790\u52a0\u5bc6\u63a7\u5236\u6d41\u91cf\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u5f0f\u548c\u6d41\u5411\u5173\u7cfb\uff0c\u81ea\u52a8\u8bc6\u522b\u96c6\u7fa4\u7ba1\u7406\u534f\u8bae\u5e76\u63a8\u65ad\u63a7\u5236\u5e73\u9762\u62d3\u6251\u3002", "motivation": "SD-WAN\u7684\u5206\u5e03\u5f0f\u63a7\u5236\u5e73\u9762\u901a\u8fc7\u96c6\u7fa4\u7ba1\u7406\u534f\u8bae\u5b9e\u73b0\u4e00\u81f4\u6027\uff0c\u4f46\u52a0\u5bc6\u7684\u63a7\u5236\u6d41\u91cf\u4ecd\u4f1a\u66b4\u9732\u72ec\u7279\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u5f0f\u548c\u65b9\u5411\u5173\u7cfb\uff0c\u53ef\u80fd\u6cc4\u9732\u63a7\u5236\u5e73\u9762\u62d3\u6251\u548c\u534f\u8bae\u4f9d\u8d56\u7b49\u673a\u5bc6\u4fe1\u606f\uff0c\u88ab\u7528\u4e8e\u4e25\u91cd\u653b\u51fb\u3002", "method": "\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u5206\u6790SD-WAN\u96c6\u7fa4\u7ba1\u7406\u534f\u8bae\u7684\u5468\u671f\u6027\u548c\u64cd\u4f5c\u6a21\u5f0f\uff0c\u4ee5\u53ca\u4ece\u6536\u96c6\u7684\u63a7\u5236\u6d41\u91cf\u4e2d\u63d0\u53d6\u7684\u6d41\u5411\u4e0a\u4e0b\u6587\uff0c\u81ea\u52a8\u4ece\u6df7\u6742\u7684\u63a7\u5236\u6d41\u91cf\u6570\u636e\u96c6\u4e2d\u5206\u7c7b\u96c6\u7fa4\u7ba1\u7406\u534f\u8bae\u3002", "result": "\u5728\u7531\u5730\u7406\u4e0a\u5206\u6563\u7684\u4e09\u4e2a\u6821\u56ed\u7f51\u7edc\u548c\u4e00\u4e2a\u4f01\u4e1a\u7f51\u7edc\u7ec4\u6210\u7684\u771f\u5b9eSD-WAN\u73af\u5883\u4e2d\u8bc4\u4f30\uff0cHeimdallr\u80fd\u591f\u4ee5\u226593%\u7684\u51c6\u786e\u7387\u5206\u7c7bSD-WAN\u63a7\u5236\u6d41\u91cf\uff0c\u4ee5\u226580%\u7684\u5b8fF-1\u5206\u6570\u8bc6\u522b\u5355\u4e2a\u534f\u8bae\uff0c\u5e76\u4ee5\u226570%\u7684\u76f8\u4f3c\u5ea6\u63a8\u65ad\u63a7\u5236\u5e73\u9762\u62d3\u6251\u3002", "conclusion": "Heimdallr\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u8bc6\u522bSD-WAN\u63a7\u5236\u6d41\u91cf\u4e2d\u7684\u96c6\u7fa4\u7ba1\u7406\u534f\u8bae\uff0c\u5e76\u63a8\u65ad\u63a7\u5236\u5e73\u9762\u62d3\u6251\uff0c\u63ed\u793a\u4e86\u52a0\u5bc6\u63a7\u5236\u6d41\u91cf\u4e2d\u4ecd\u5b58\u5728\u53ef\u88ab\u5229\u7528\u7684\u5b89\u5168\u6f0f\u6d1e\u3002"}}
{"id": "2510.16476", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16476", "abs": "https://arxiv.org/abs/2510.16476", "authors": ["Xiaozhe Li", "Xinyu Fang", "Shengyuan Ding", "Linyang Li", "Haodong Duan", "Qingwen Liu", "Kai Chen"], "title": "NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems", "comment": null, "summary": "Large Language Models (LLMs) have shown strong reasoning capabilities, with\nmodels like OpenAI's O-series and DeepSeek R1 excelling at tasks such as\nmathematics, coding, logic, and puzzles through Reinforcement Learning with\nVerifiable Rewards (RLVR). However, their ability to solve more complex\noptimization problems - particularly NP-hard tasks - remains underexplored. To\nbridge this gap, we propose NP-ENGINE, the first comprehensive framework for\ntraining and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks\nacross five domains, each equipped with (i) a controllable instance generator,\n(ii) a rule-based verifier, and (iii) a heuristic solver that provides\napproximate optimal solutions as ground truth. This\ngenerator-verifier-heuristic pipeline enables scalable and verifiable RLVR\ntraining under hierarchical difficulties. We also introduce NP-BENCH, a\nbenchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs'\nability to tackle NP-hard level reasoning problems, focusing not only on\nfeasibility but also on solution quality. Additionally, we present\nQWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on\nQwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and\nachieves SOTA performance with the same model size. Beyond in-domain tasks, we\ndemonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain\n(OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge),\nas well as non-reasoning tasks such as instruction following. We also observe a\nscaling trend: increasing task diversity improves OOD generalization. These\nfindings suggest that task-rich RLVR training is a promising direction for\nadvancing LLM's reasoning ability, revealing new insights into the scaling laws\nof RLVR.", "AI": {"tldr": "\u63d0\u51fa\u4e86NP-ENGINE\u6846\u67b6\uff0c\u9996\u4e2a\u4e13\u95e8\u8bad\u7ec3\u548c\u8bc4\u4f30LLMs\u89e3\u51b3NP-hard\u95ee\u9898\u7684\u7efc\u5408\u7cfb\u7edf\uff0c\u5305\u542b10\u4e2a\u4efb\u52a1\u3001\u53ef\u63a7\u5b9e\u4f8b\u751f\u6210\u5668\u3001\u9a8c\u8bc1\u5668\u548c\u542f\u53d1\u5f0f\u6c42\u89e3\u5668\u3002\u8bad\u7ec3\u51fa\u7684QWEN2.5-7B-NP\u6a21\u578b\u5728NP-BENCH\u57fa\u51c6\u4e0a\u8d85\u8d8aGPT-4o\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u867d\u7136LLMs\u5728\u6570\u5b66\u3001\u7f16\u7a0b\u7b49\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u89e3\u51b3\u590d\u6742NP-hard\u4f18\u5316\u95ee\u9898\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u4e13\u95e8\u7684\u8bad\u7ec3\u6846\u67b6\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5f00\u53d1NP-ENGINE\u6846\u67b6\uff0c\u5305\u542b\u53ef\u63a7\u5b9e\u4f8b\u751f\u6210\u5668\u3001\u89c4\u5219\u9a8c\u8bc1\u5668\u548c\u542f\u53d1\u5f0f\u6c42\u89e3\u5668\uff0c\u652f\u6301\u53ef\u6269\u5c55\u7684RLVR\u8bad\u7ec3\uff1b\u4f7f\u7528\u8bfe\u7a0b\u5b66\u4e60\u5728Qwen2.5-7B-Instruct\u4e0a\u8fdb\u884czero-RLVR\u8bad\u7ec3\u3002", "result": "QWEN2.5-7B-NP\u5728NP-BENCH\u57fa\u51c6\u4e0a\u663e\u8457\u8d85\u8d8aGPT-4o\uff0c\u8fbe\u5230\u540c\u89c4\u6a21\u6a21\u578b\u7684\u6700\u4f73\u6027\u80fd\uff1b\u5728\u8de8\u9886\u57df\u63a8\u7406\u4efb\u52a1\u548c\u975e\u63a8\u7406\u4efb\u52a1\u4e0a\u90fd\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff1b\u53d1\u73b0\u4efb\u52a1\u591a\u6837\u6027\u63d0\u5347\u80fd\u6539\u5584\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8eNP-ENGINE\u7684\u4efb\u52a1\u4e30\u5bccRLVR\u8bad\u7ec3\u662f\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u7684\u6709\u524d\u666f\u65b9\u5411\uff0c\u63ed\u793a\u4e86RLVR\u7684\u6269\u5c55\u89c4\u5f8b\uff0c\u4e3aLLMs\u89e3\u51b3\u590d\u6742\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.16544", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16544", "abs": "https://arxiv.org/abs/2510.16544", "authors": ["Weijie Chen", "Shan Tang", "Yulin Tang", "Xiapu Luo", "Yinqian Zhang", "Weizhong Qiang"], "title": "$\u03c1$Hammer: Reviving RowHammer Attacks on New Architectures via Prefetching", "comment": "Accepted for publication in the 58th IEEE/ACM International Symposium\n  on Microarchitecture (MICRO '25). This is the author's version of the paper", "summary": "Rowhammer is a critical vulnerability in dynamic random access memory (DRAM)\nthat continues to pose a significant threat to various systems. However, we\nfind that conventional load-based attacks are becoming highly ineffective on\nthe most recent architectures such as Intel Alder and Raptor Lake. In this\npaper, we present $\\rho$Hammer, a new Rowhammer framework that systematically\novercomes three core challenges impeding attacks on these new architectures.\nFirst, we design an efficient and generic DRAM address mapping\nreverse-engineering method that uses selective pairwise measurements and\nstructured deduction, enabling recovery of complex mappings within seconds on\nthe latest memory controllers. Second, to break through the activation rate\nbottleneck of load-based hammering, we introduce a novel prefetch-based\nhammering paradigm that leverages the asynchronous nature of x86 prefetch\ninstructions and is further enhanced by multi-bank parallelism to maximize\nthroughput. Third, recognizing that speculative execution causes more severe\ndisorder issues for prefetching, which cannot be simply mitigated by memory\nbarriers, we develop a counter-speculation hammering technique using\ncontrol-flow obfuscation and optimized NOP-based pseudo-barriers to maintain\nprefetch order with minimal overhead. Evaluations across four latest Intel\narchitectures demonstrate $\\rho$Hammer's breakthrough effectiveness: it induces\nup to 200K+ additional bit flips within 2-hour attack pattern fuzzing processes\nand has a 112x higher flip rate than the load-based hammering baselines on\nComet and Rocket Lake. Also, we are the first to revive Rowhammer attacks on\nthe latest Raptor Lake architecture, where baselines completely fail, achieving\nstable flip rates of 2,291/min and fast end-to-end exploitation.", "AI": {"tldr": "\u03c1Hammer\u662f\u4e00\u4e2a\u65b0\u7684Rowhammer\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u5730\u5740\u6620\u5c04\u9006\u5411\u5de5\u7a0b\u3001\u9884\u53d6\u5f0f\u9524\u51fb\u548c\u53cd\u63a8\u6d4b\u6267\u884c\u6280\u672f\uff0c\u6210\u529f\u7a81\u7834\u4e86\u6700\u65b0Intel\u67b6\u6784\u7684\u9632\u5fa1\u673a\u5236\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u8d1f\u8f7d\u7684Rowhammer\u653b\u51fb\u5728\u6700\u65b0Intel\u67b6\u6784\u4e0a\u53d8\u5f97\u65e0\u6548\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u653b\u51fb\u65b9\u6cd5\u6765\u514b\u670d\u5730\u5740\u6620\u5c04\u590d\u6742\u5316\u3001\u6fc0\u6d3b\u7387\u74f6\u9888\u548c\u63a8\u6d4b\u6267\u884c\u5e72\u6270\u7b49\u6311\u6218\u3002", "method": "1) \u4f7f\u7528\u9009\u62e9\u6027\u914d\u5bf9\u6d4b\u91cf\u548c\u7ed3\u6784\u5316\u63a8\u5bfc\u7684DRAM\u5730\u5740\u6620\u5c04\u9006\u5411\u5de5\u7a0b\u65b9\u6cd5\uff1b2) \u57fa\u4e8ex86\u9884\u53d6\u6307\u4ee4\u7684\u5f02\u6b65\u9884\u53d6\u5f0f\u9524\u51fb\u8303\u5f0f\uff0c\u7ed3\u5408\u591abank\u5e76\u884c\u5316\uff1b3) \u63a7\u5236\u6d41\u6df7\u6dc6\u548c\u4f18\u5316\u7684NOP\u4f2a\u5c4f\u969c\u53cd\u63a8\u6d4b\u6267\u884c\u6280\u672f\u3002", "result": "\u5728\u56db\u4e2a\u6700\u65b0Intel\u67b6\u6784\u4e0a\uff0c\u03c1Hammer\u57282\u5c0f\u65f6\u653b\u51fb\u6a21\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u4e2d\u8bf1\u5bfc\u8d85\u8fc720\u4e07\u989d\u5916\u6bd4\u7279\u7ffb\u8f6c\uff0c\u5728Comet\u548cRocket Lake\u4e0a\u7684\u7ffb\u8f6c\u7387\u6bd4\u57fa\u7ebf\u9ad8112\u500d\uff0c\u5e76\u9996\u6b21\u5728Raptor Lake\u4e0a\u5b9e\u73b0\u7a33\u5b9a\u653b\u51fb\u3002", "conclusion": "\u03c1Hammer\u6846\u67b6\u6210\u529f\u514b\u670d\u4e86\u73b0\u4ee3\u5185\u5b58\u63a7\u5236\u5668\u7684\u9632\u5fa1\u673a\u5236\uff0c\u8bc1\u660e\u4e86Rowhammer\u5a01\u80c1\u5728\u6700\u65b0\u67b6\u6784\u4e0a\u4ecd\u7136\u5b58\u5728\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2510.16533", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16533", "abs": "https://arxiv.org/abs/2510.16533", "authors": ["Eilene Tomkins-Flanagan", "Connor Hanley", "Mary A. Kelly"], "title": "Hey Pentti, We Did It Again!: Differentiable vector-symbolic types that prove polynomial termination", "comment": null, "summary": "We present a typed computer language, Doug, in which all typed programs may\nbe proved to halt in polynomial time, encoded in a vector-symbolic architecture\n(VSA). Doug is just an encoding of the light linear functional programming\nlanguage (LLFPL) described by (Schimanski2009, ch. 7). The types of Doug are\nencoded using a slot-value encoding scheme based on holographic declarative\nmemory (HDM; Kelly, 2020). The terms of Doug are encoded using a variant of the\nLisp VSA defined by (Flanagan, 2024). Doug allows for some points on the\nembedding space of a neural network to be interpreted as types, where the types\nof nearby points are similar both in structure and content. Types in Doug are\ntherefore learnable by a neural network. Following (Chollet, 2019), (Card,\n1983), and (Newell, 1981), we view skill as the application of a procedure, or\nprogram of action, that causes a goal to be satisfied. Skill acquisition may\ntherefore be expressed as program synthesis. Using Doug, we hope to describe a\nform of learning of skilled behaviour that follows a human-like pace of skill\nacquisition (i.e., substantially faster than brute force; Heathcote, 2000),\nexceeding the efficiency of all currently existing approaches (Kaplan, 2020;\nJones, 2021; Chollet, 2024). Our approach brings us one step closer to modeling\nhuman mental representations, as they must actually exist in the brain, and\nthose representations' acquisition, as they are actually learned.", "AI": {"tldr": "Doug\u662f\u4e00\u4e2a\u7c7b\u578b\u5316\u8ba1\u7b97\u673a\u8bed\u8a00\uff0c\u6240\u6709\u7c7b\u578b\u5316\u7a0b\u5e8f\u90fd\u80fd\u88ab\u8bc1\u660e\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u505c\u6b62\uff0c\u7f16\u7801\u5728\u5411\u91cf\u7b26\u53f7\u67b6\u6784(VSA)\u4e2d\u3002\u8be5\u8bed\u8a00\u652f\u6301\u7c7b\u578b\u5b66\u4e60\uff0c\u65e8\u5728\u5b9e\u73b0\u7c7b\u4f3c\u4eba\u7c7b\u8282\u594f\u7684\u6280\u80fd\u83b7\u53d6\u3002", "motivation": "\u76ee\u6807\u662f\u5efa\u6a21\u4eba\u7c7b\u5fc3\u7406\u8868\u5f81\u53ca\u5176\u83b7\u53d6\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u6548\u7684\u4eba\u7c7b\u5316\u6280\u80fd\u5b66\u4e60\u901f\u5ea6\u3002", "method": "\u57fa\u4e8e\u8f7b\u91cf\u7ebf\u6027\u51fd\u6570\u5f0f\u7f16\u7a0b\u8bed\u8a00(LLFPL)\uff0c\u4f7f\u7528\u57fa\u4e8e\u5168\u606f\u58f0\u660e\u6027\u8bb0\u5fc6(HDM)\u7684\u69fd\u503c\u7f16\u7801\u65b9\u6848\u7f16\u7801\u7c7b\u578b\uff0c\u4ee5\u53caLisp VSA\u53d8\u4f53\u7f16\u7801\u9879\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bed\u8a00\u8bbe\u8ba1\uff0c\u4f7f\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u5b66\u4e60\u7c7b\u578b\uff0c\u5e76\u4e3a\u9ad8\u6548\u6280\u80fd\u83b7\u53d6\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "Doug\u8bed\u8a00\u4f7f\u6211\u4eec\u66f4\u63a5\u8fd1\u5efa\u6a21\u5927\u8111\u4e2d\u5b9e\u9645\u5b58\u5728\u7684\u5fc3\u7406\u8868\u5f81\u53ca\u5176\u5b66\u4e60\u8fc7\u7a0b\uff0c\u4e3a\u4eba\u7c7b\u5316\u6280\u80fd\u83b7\u53d6\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2510.16558", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16558", "abs": "https://arxiv.org/abs/2510.16558", "authors": ["Xiaofan Li", "Xing Gao"], "title": "Toward Understanding Security Issues in the Model Context Protocol Ecosystem", "comment": null, "summary": "The Model Context Protocol (MCP) is an emerging open standard that enables\nAI-powered applications to interact with external tools through structured\nmetadata. A rapidly growing ecosystem has formed around MCP, including a wide\nrange of MCP hosts (i.e., Cursor, Windsurf, Claude Desktop, and Cline), MCP\nregistries (i.e., mcp.so, MCP Market, MCP Store, Pulse MCP, Smithery, and npm),\nand thousands of community-contributed MCP servers. Although the MCP ecosystem\nis gaining traction, there has been little systematic study of its architecture\nand associated security risks. In this paper, we present the first\ncomprehensive security analysis of the MCP ecosystem. We decompose MCP\necosystem into three core components: hosts, registries, and servers, and study\nthe interactions and trust relationships among them. Users search for servers\non registries and configure them in the host, which translates LLM-generated\noutput into external tool invocations provided by the servers and executes\nthem. Our qualitative analysis reveals that hosts lack output verification\nmechanisms for LLM-generated outputs, enabling malicious servers to manipulate\nmodel behavior and induce a variety of security threats, including but not\nlimited to sensitive data exfiltration. We uncover a wide range of\nvulnerabilities that enable attackers to hijack servers, due to the lack of a\nvetted server submission process in registries. To support our analysis, we\ncollect and analyze a dataset of 67,057 servers from six public registries. Our\nquantitative analysis demonstrates that a substantial number of servers can be\nhijacked by attackers. Finally, we propose practical defense strategies for MCP\nhosts, registries, and users. We responsibly disclosed our findings to affected\nhosts and registries.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9MCP\u751f\u6001\u7cfb\u7edf\u8fdb\u884c\u5b89\u5168\u5206\u6790\uff0c\u63ed\u793a\u4e86\u7531\u4e8e\u7f3a\u4e4f\u8f93\u51fa\u9a8c\u8bc1\u673a\u5236\u548c\u670d\u52a1\u5668\u5ba1\u67e5\u6d41\u7a0b\uff0c\u6076\u610f\u670d\u52a1\u5668\u53ef\u64cd\u7eb5\u6a21\u578b\u884c\u4e3a\u5e76\u5f15\u53d1\u654f\u611f\u6570\u636e\u6cc4\u9732\u7b49\u5b89\u5168\u5a01\u80c1\u3002", "motivation": "MCP\u751f\u6001\u7cfb\u7edf\u5feb\u901f\u53d1\u5c55\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5b89\u5168\u7814\u7a76\uff0c\u9700\u8981\u5206\u6790\u5176\u67b6\u6784\u548c\u5b89\u5168\u98ce\u9669\u3002", "method": "\u5c06MCP\u751f\u6001\u7cfb\u7edf\u5206\u89e3\u4e3a\u4e3b\u673a\u3001\u6ce8\u518c\u8868\u548c\u670d\u52a1\u5668\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5206\u6790\u5b83\u4eec\u4e4b\u95f4\u7684\u4ea4\u4e92\u548c\u4fe1\u4efb\u5173\u7cfb\uff0c\u6536\u96c6\u5e76\u5206\u6790\u6765\u81ea6\u4e2a\u516c\u5171\u6ce8\u518c\u8868\u768467,057\u4e2a\u670d\u52a1\u5668\u6570\u636e\u96c6\u3002", "result": "\u5b9a\u6027\u5206\u6790\u663e\u793a\u4e3b\u673a\u7f3a\u4e4fLLM\u751f\u6210\u8f93\u51fa\u7684\u9a8c\u8bc1\u673a\u5236\uff0c\u6076\u610f\u670d\u52a1\u5668\u53ef\u64cd\u7eb5\u6a21\u578b\u884c\u4e3a\uff1b\u5b9a\u91cf\u5206\u6790\u8868\u660e\u5927\u91cf\u670d\u52a1\u5668\u53ef\u88ab\u653b\u51fb\u8005\u52ab\u6301\u3002", "conclusion": "\u63d0\u51fa\u9488\u5bf9MCP\u4e3b\u673a\u3001\u6ce8\u518c\u8868\u548c\u7528\u6237\u7684\u5b9e\u7528\u9632\u5fa1\u7b56\u7565\uff0c\u5e76\u5411\u53d7\u5f71\u54cd\u65b9\u8d1f\u8d23\u4efb\u5730\u62ab\u9732\u4e86\u53d1\u73b0\u3002"}}
{"id": "2510.16555", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16555", "abs": "https://arxiv.org/abs/2510.16555", "authors": ["Qiongyan Wang", "Xingchen Zou", "Yutian Jiang", "Haomin Wen", "Jiaheng Wei", "Qingsong Wen", "Yuxuan Liang"], "title": "Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence", "comment": null, "summary": "Rapid urbanization intensifies the demand for Urban General Intelligence\n(UGI), referring to AI systems that can understand and reason about complex\nurban environments. Recent studies have built urban foundation models using\nsupervised fine-tuning (SFT) of LLMs and MLLMs, yet these models exhibit\npersistent geospatial bias, producing regionally skewed predictions and limited\ngeneralization. To this end, we propose Urban-R1, a reinforcement\nlearning-based post-training framework that aligns MLLMs with the objectives of\nUGI. Urban-R1 adopts Group Relative Policy Optimization (GRPO) to optimize\nreasoning across geographic groups and employs urban region profiling as a\nproxy task to provide measurable rewards from multimodal urban data. Extensive\nexperiments across diverse regions and tasks show that Urban-R1 effectively\nmitigates geo-bias and improves cross-region generalization, outperforming both\nSFT-trained and closed-source models. Our results highlight reinforcement\nlearning alignment as a promising pathway toward equitable and trustworthy\nurban intelligence.", "AI": {"tldr": "\u63d0\u51fa\u4e86Urban-R1\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6765\u51cf\u5c11\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u57ce\u5e02\u667a\u80fd\u4efb\u52a1\u4e2d\u7684\u5730\u7406\u504f\u89c1\uff0c\u63d0\u9ad8\u8de8\u533a\u57df\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u76d1\u7763\u5fae\u8c03\u7684\u57ce\u5e02\u57fa\u7840\u6a21\u578b\u5b58\u5728\u6301\u7eed\u7684\u5730\u7406\u504f\u89c1\uff0c\u5bfc\u81f4\u533a\u57df\u9884\u6d4b\u504f\u5dee\u548c\u6709\u9650\u6cdb\u5316\u80fd\u529b\uff0c\u9700\u8981\u66f4\u516c\u5e73\u7684\u57ce\u5e02\u667a\u80fd\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u540e\u8bad\u7ec3\u6846\u67b6\uff0c\u4f7f\u7528\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\u6765\u4f18\u5316\u8de8\u5730\u7406\u7fa4\u4f53\u7684\u63a8\u7406\uff0c\u5e76\u4ee5\u57ce\u5e02\u533a\u57df\u753b\u50cf\u4f5c\u4e3a\u4ee3\u7406\u4efb\u52a1\u63d0\u4f9b\u53ef\u6d4b\u91cf\u7684\u5956\u52b1\u3002", "result": "\u5728\u591a\u4e2a\u533a\u57df\u548c\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cUrban-R1\u6709\u6548\u51cf\u8f7b\u4e86\u5730\u7406\u504f\u89c1\u5e76\u6539\u5584\u4e86\u8de8\u533a\u57df\u6cdb\u5316\uff0c\u4f18\u4e8e\u76d1\u7763\u5fae\u8bad\u7ec3\u548c\u95ed\u6e90\u6a21\u578b\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50\u662f\u5b9e\u73b0\u516c\u5e73\u53ef\u4fe1\u57ce\u5e02\u667a\u80fd\u7684\u6709\u524d\u666f\u9014\u5f84\u3002"}}
{"id": "2510.16581", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16581", "abs": "https://arxiv.org/abs/2510.16581", "authors": ["Xinfeng Li", "Shengyuan Pang", "Jialin Wu", "Jiangyi Deng", "Huanlong Zhong", "Yanjiao Chen", "Jie Zhang", "Wenyuan Xu"], "title": "Patronus: Safeguarding Text-to-Image Models against White-Box Adversaries", "comment": "14 pages, 18 figures, 7 tables", "summary": "Text-to-image (T2I) models, though exhibiting remarkable creativity in image\ngeneration, can be exploited to produce unsafe images. Existing safety\nmeasures, e.g., content moderation or model alignment, fail in the presence of\nwhite-box adversaries who know and can adjust model parameters, e.g., by\nfine-tuning. This paper presents a novel defensive framework, named Patronus,\nwhich equips T2I models with holistic protection to defend against white-box\nadversaries. Specifically, we design an internal moderator that decodes unsafe\ninput features into zero vectors while ensuring the decoding performance of\nbenign input features. Furthermore, we strengthen the model alignment with a\ncarefully designed non-fine-tunable learning mechanism, ensuring the T2I model\nwill not be compromised by malicious fine-tuning. We conduct extensive\nexperiments to validate the intactness of the performance on safe content\ngeneration and the effectiveness of rejecting unsafe content generation.\nResults also confirm the resilience of Patronus against various fine-tuning\nattacks by white-box adversaries.", "AI": {"tldr": "Patronus\u662f\u4e00\u4e2a\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u5185\u90e8\u8c03\u8282\u5668\u548c\u975e\u5fae\u8c03\u5b66\u4e60\u673a\u5236\u4fdd\u62a4\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u514d\u53d7\u767d\u76d2\u653b\u51fb\u8005\u7684\u6076\u610f\u5fae\u8c03\u653b\u51fb\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u5728\u9762\u5bf9\u77e5\u9053\u6a21\u578b\u53c2\u6570\u5e76\u80fd\u8c03\u6574\u7684\u767d\u76d2\u653b\u51fb\u8005\u65f6\u5931\u6548\uff0c\u9700\u8981\u65b0\u7684\u9632\u5fa1\u673a\u5236\u6765\u4fdd\u62a4\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u3002", "method": "\u8bbe\u8ba1\u5185\u90e8\u8c03\u8282\u5668\u5c06\u4e0d\u5b89\u5168\u8f93\u5165\u7279\u5f81\u89e3\u7801\u4e3a\u96f6\u5411\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u6027\u8f93\u5165\u7684\u89e3\u7801\u6027\u80fd\uff1b\u91c7\u7528\u975e\u5fae\u8c03\u5b66\u4e60\u673a\u5236\u589e\u5f3a\u6a21\u578b\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5728\u5b89\u5168\u5185\u5bb9\u751f\u6210\u4e0a\u7684\u6027\u80fd\u5b8c\u6574\u6027\uff0c\u4ee5\u53ca\u62d2\u7edd\u4e0d\u5b89\u5168\u5185\u5bb9\u751f\u6210\u7684\u6709\u6548\u6027\uff0c\u786e\u8ba4\u4e86\u5bf9\u5404\u79cd\u767d\u76d2\u5fae\u8c03\u653b\u51fb\u7684\u97e7\u6027\u3002", "conclusion": "Patronus\u6846\u67b6\u4e3a\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u767d\u76d2\u653b\u51fb\u9632\u62a4\uff0c\u786e\u4fdd\u6a21\u578b\u5728\u6076\u610f\u5fae\u8c03\u4e0b\u4e0d\u88ab\u7834\u574f\u3002"}}
{"id": "2510.16559", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16559", "abs": "https://arxiv.org/abs/2510.16559", "authors": ["Tian Xia", "Tianrun Gao", "Wenhao Deng", "Long Wei", "Xiaowei Qian", "Yixian Jiang", "Chenglei Yu", "Tailin Wu"], "title": "BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction", "comment": "33 pages, 10 figures", "summary": "Engineering construction automation aims to transform natural language\nspecifications into physically viable structures, requiring complex integrated\nreasoning under strict physical constraints. While modern LLMs possess broad\nknowledge and strong reasoning capabilities that make them promising candidates\nfor this domain, their construction competencies remain largely unevaluated. To\naddress this gap, we introduce BuildArena, the first physics-aligned\ninteractive benchmark designed for language-driven engineering construction. It\ncontributes to the community in four aspects: (1) a highly customizable\nbenchmarking framework for in-depth comparison and analysis of LLMs; (2) an\nextendable task design strategy spanning static and dynamic mechanics across\nmultiple difficulty tiers; (3) a 3D Spatial Geometric Computation Library for\nsupporting construction based on language instructions; (4) a baseline LLM\nagentic workflow that effectively evaluates diverse model capabilities. On\neight frontier LLMs, BuildArena comprehensively evaluates their capabilities\nfor language-driven and physics-grounded construction automation. The project\npage is at https://build-arena.github.io/.", "AI": {"tldr": "BuildArena\u662f\u9996\u4e2a\u9762\u5411\u8bed\u8a00\u9a71\u52a8\u5de5\u7a0b\u5efa\u8bbe\u7684\u7269\u7406\u5bf9\u9f50\u4ea4\u4e92\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u5de5\u7a0b\u5efa\u7b51\u81ea\u52a8\u5316\u4e2d\u7684\u80fd\u529b\uff0c\u5305\u62ec\u53ef\u5b9a\u5236\u6846\u67b6\u3001\u53ef\u6269\u5c55\u4efb\u52a1\u8bbe\u8ba1\u30013D\u7a7a\u95f4\u51e0\u4f55\u8ba1\u7b97\u5e93\u548c\u57fa\u7ebfLLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u3002", "motivation": "\u5de5\u7a0b\u5efa\u7b51\u81ea\u52a8\u5316\u9700\u8981\u5c06\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u8f6c\u5316\u4e3a\u7269\u7406\u53ef\u884c\u7684\u7ed3\u6784\uff0c\u867d\u7136\u73b0\u4ee3LLM\u5177\u6709\u5e7f\u6cdb\u77e5\u8bc6\u548c\u5f3a\u5927\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u5728\u5efa\u7b51\u9886\u57df\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u8bc4\u4f30\u3002", "method": "\u5f00\u53d1\u4e86BuildArena\u57fa\u51c6\uff0c\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u53ef\u5b9a\u5236\u57fa\u51c6\u6846\u67b6\u3001\u53ef\u6269\u5c55\u4efb\u52a1\u8bbe\u8ba1\u7b56\u7565\u30013D\u7a7a\u95f4\u51e0\u4f55\u8ba1\u7b97\u5e93\u548c\u57fa\u7ebfLLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u516b\u4e2a\u524d\u6cbfLLM\u4e0a\u5168\u9762\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728\u8bed\u8a00\u9a71\u52a8\u548c\u7269\u7406\u57fa\u7840\u5efa\u8bbe\u81ea\u52a8\u5316\u65b9\u9762\u7684\u80fd\u529b\u3002", "conclusion": "BuildArena\u586b\u8865\u4e86LLM\u5728\u5de5\u7a0b\u5efa\u7b51\u81ea\u52a8\u5316\u9886\u57df\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u9996\u4e2a\u7269\u7406\u5bf9\u9f50\u7684\u4ea4\u4e92\u57fa\u51c6\u3002"}}
{"id": "2510.16593", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16593", "abs": "https://arxiv.org/abs/2510.16593", "authors": ["Khandaker Akramul Haque", "Katherine R. Davis"], "title": "DESTinE Block: Private Blockchain Based Data Storage Framework for Power System", "comment": null, "summary": "This paper presents DESTinE Block, a blockchain-based data storage framework\ndesigned for power systems and optimized for resource-constrained environments,\nincluding grid-edge devices such as single-board computers. The proposed\narchitecture leverages the InterPlanetary File System (IPFS) for storing large\nfiles while maintaining secure and traceable metadata on a custom blockchain\nnamed DESTinE Block. The metadata, comprising the IPFS Content Identifier\n(CID), uploader identity, administrator verification, and timestamp; is\nimmutably recorded on-chain to ensure authenticity and integrity. DESTinE Block\nadopts a dual-blockchain abstraction, where the blockchain remains unaware of\nthe IPFS storage layer to enhance security and limit the exposure of sensitive\nfile data. The consensus mechanism is based on Proof of Authority (PoA), where\nboth an administrator and an uploader with distinct cryptographic key pairs are\nrequired to create a block collaboratively. Each block contains verified\nsignatures of both parties and is designed to be computationally efficient,\nenabling deployment on devices like the Raspberry Pi 5. The framework was\ntested on both an x86-based device and an ARM64-based Raspberry Pi,\ndemonstrating its potential for secure, decentralized logging and measurement\nstorage in smart grid applications. Moreover, DESTinE Block is compared with a\nsimilar framework based on Multichain. The results indicate that DESTinE Block\nprovides a promising solution for tamper-evident data retention in distributed\npower system infrastructure while maintaining minimal hardware requirements.", "AI": {"tldr": "DESTinE Block\u662f\u4e00\u4e2a\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u6570\u636e\u5b58\u50a8\u6846\u67b6\uff0c\u4e13\u4e3a\u7535\u529b\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u4f18\u5316\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u3002\u5b83\u91c7\u7528IPFS\u5b58\u50a8\u5927\u6587\u4ef6\uff0c\u5728\u81ea\u5b9a\u4e49\u533a\u5757\u94fe\u4e0a\u8bb0\u5f55\u5b89\u5168\u53ef\u8ffd\u6eaf\u7684\u5143\u6570\u636e\uff0c\u4f7f\u7528PoA\u5171\u8bc6\u673a\u5236\uff0c\u53ef\u5728\u6811\u8393\u6d3e\u7b49\u8bbe\u5907\u4e0a\u8fd0\u884c\u3002", "motivation": "\u4e3a\u7535\u529b\u7cfb\u7edf\u63d0\u4f9b\u5b89\u5168\u3001\u53bb\u4e2d\u5fc3\u5316\u7684\u6570\u636e\u5b58\u50a8\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u7684\u7535\u7f51\u8fb9\u7f18\u8bbe\u5907\uff0c\u786e\u4fdd\u6570\u636e\u771f\u5b9e\u6027\u548c\u5b8c\u6574\u6027\u3002", "method": "\u91c7\u7528\u53cc\u533a\u5757\u94fe\u62bd\u8c61\u67b6\u6784\uff0cIPFS\u5b58\u50a8\u5927\u6587\u4ef6\uff0cDESTinE\u533a\u5757\u94fe\u8bb0\u5f55\u5143\u6570\u636e\uff08CID\u3001\u4e0a\u4f20\u8005\u8eab\u4efd\u3001\u7ba1\u7406\u5458\u9a8c\u8bc1\u3001\u65f6\u95f4\u6233\uff09\u3002\u4f7f\u7528PoA\u5171\u8bc6\u673a\u5236\uff0c\u9700\u8981\u7ba1\u7406\u5458\u548c\u4e0a\u4f20\u8005\u5171\u540c\u521b\u5efa\u533a\u5757\u3002", "result": "\u5728x86\u548cARM64\u8bbe\u5907\uff08\u5305\u62ec\u6811\u8393\u6d3e\uff09\u4e0a\u6210\u529f\u6d4b\u8bd5\uff0c\u4e0eMultichain\u6846\u67b6\u76f8\u6bd4\u8868\u73b0\u826f\u597d\uff0c\u63d0\u4f9b\u9632\u7be1\u6539\u6570\u636e\u4fdd\u7559\u529f\u80fd\uff0c\u786c\u4ef6\u8981\u6c42\u4f4e\u3002", "conclusion": "DESTinE Block\u4e3a\u5206\u5e03\u5f0f\u7535\u529b\u7cfb\u7edf\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u9632\u7be1\u6539\u6570\u636e\u5b58\u50a8\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u5408\u8d44\u6e90\u53d7\u9650\u73af\u5883\u3002"}}
{"id": "2510.16572", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.16572", "abs": "https://arxiv.org/abs/2510.16572", "authors": ["Ayush Chopra", "Aman Sharma", "Feroz Ahmad", "Luca Muscariello", "Vijoy Pandey", "Ramesh Raskar"], "title": "Ripple Effect Protocol: Coordinating Agent Populations", "comment": null, "summary": "Modern AI agents can exchange messages using protocols such as A2A and ACP,\nyet these mechanisms emphasize communication over coordination. As agent\npopulations grow, this limitation produces brittle collective behavior, where\nindividually smart agents converge on poor group outcomes. We introduce the\nRipple Effect Protocol (REP), a coordination protocol in which agents share not\nonly their decisions but also lightweight sensitivities - signals expressing\nhow their choices would change if key environmental variables shifted. These\nsensitivities ripple through local networks, enabling groups to align faster\nand more stably than with agent-centric communication alone. We formalize REP's\nprotocol specification, separating required message schemas from optional\naggregation rules, and evaluate it across scenarios with varying incentives and\nnetwork topologies. Benchmarks across three domains: (i) supply chain cascades\n(Beer Game), (ii) preference aggregation in sparse networks (Movie Scheduling),\nand (iii) sustainable resource allocation (Fishbanks) show that REP improves\ncoordination accuracy and efficiency over A2A by 41 to 100%, while flexibly\nhandling multimodal sensitivity signals from LLMs. By making coordination a\nprotocol-level capability, REP provides scalable infrastructure for the\nemerging Internet of Agents", "AI": {"tldr": "\u63d0\u51fa\u4e86Ripple Effect Protocol (REP)\u534f\u8c03\u534f\u8bae\uff0c\u8ba9\u667a\u80fd\u4f53\u4e0d\u4ec5\u5171\u4eab\u51b3\u7b56\uff0c\u8fd8\u5171\u4eab\u8f7b\u91cf\u7ea7\u654f\u611f\u5ea6\u4fe1\u53f7\uff0c\u4ece\u800c\u5728\u7fa4\u4f53\u4e2d\u5b9e\u73b0\u66f4\u5feb\u66f4\u7a33\u5b9a\u7684\u534f\u8c03\u3002", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u901a\u4fe1\u534f\u8bae\uff08\u5982A2A\u548cACP\uff09\u5f3a\u8c03\u901a\u4fe1\u800c\u975e\u534f\u8c03\uff0c\u968f\u7740\u4ee3\u7406\u7fa4\u4f53\u89c4\u6a21\u589e\u957f\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u8106\u5f31\u7684\u96c6\u4f53\u884c\u4e3a\uff0c\u5373\u4f7f\u4e2a\u4f53\u667a\u80fd\u4f53\u5f88\u806a\u660e\uff0c\u7fa4\u4f53\u7ed3\u679c\u4e5f\u5f88\u5dee\u3002", "method": "REP\u534f\u8bae\u8ba9\u4ee3\u7406\u5171\u4eab\u51b3\u7b56\u548c\u8f7b\u91cf\u7ea7\u654f\u611f\u5ea6\u4fe1\u53f7\uff08\u8868\u8fbe\u5173\u952e\u73af\u5883\u53d8\u91cf\u53d8\u5316\u65f6\u9009\u62e9\u5982\u4f55\u53d8\u5316\u7684\u4fe1\u53f7\uff09\uff0c\u8fd9\u4e9b\u654f\u611f\u5ea6\u5728\u5c40\u90e8\u7f51\u7edc\u4e2d\u4f20\u64ad\uff0c\u5b9e\u73b0\u6bd4\u5355\u7eaf\u4ee3\u7406\u4e2d\u5fc3\u901a\u4fe1\u66f4\u5feb\u66f4\u7a33\u5b9a\u7684\u7fa4\u4f53\u5bf9\u9f50\u3002", "result": "\u5728\u4e09\u4e2a\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff1a\u4f9b\u5e94\u94fe\u7ea7\u8054\uff08\u5564\u9152\u6e38\u620f\uff09\u3001\u7a00\u758f\u7f51\u7edc\u4e2d\u7684\u504f\u597d\u805a\u5408\uff08\u7535\u5f71\u8c03\u5ea6\uff09\u548c\u53ef\u6301\u7eed\u8d44\u6e90\u5206\u914d\uff08\u6e14\u4e1a\u94f6\u884c\uff09\uff0cREP\u76f8\u6bd4A2A\u63d0\u9ad8\u4e8641%\u5230100%\u7684\u534f\u8c03\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5c06\u534f\u8c03\u4f5c\u4e3a\u534f\u8bae\u7ea7\u80fd\u529b\uff0cREP\u4e3a\u65b0\u5174\u7684\u667a\u80fd\u4f53\u4e92\u8054\u7f51\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2510.16610", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16610", "abs": "https://arxiv.org/abs/2510.16610", "authors": ["Bruno Louren\u00e7o", "Pedro Ad\u00e3o", "Jo\u00e3o F. Ferreira", "Mario Monteiro Marques", "C\u00e1tia Vaz"], "title": "Structuring Security: A Survey of Cybersecurity Ontologies, Semantic Log Processing, and LLMs Application", "comment": null, "summary": "This survey investigates how ontologies, semantic log processing, and Large\nLanguage Models (LLMs) enhance cybersecurity. Ontologies structure domain\nknowledge, enabling interoperability, data integration, and advanced threat\nanalysis. Security logs, though critical, are often unstructured and complex.\nTo address this, automated construction of Knowledge Graphs (KGs) from raw logs\nis emerging as a key strategy for organizing and reasoning over security data.\nLLMs enrich this process by providing contextual understanding and extracting\ninsights from unstructured content. This work aligns with European Union (EU)\nefforts such as NIS 2 and the Cybersecurity Taxonomy, highlighting challenges\nand opportunities in intelligent ontology-driven cyber defense.", "AI": {"tldr": "\u672c\u8c03\u67e5\u63a2\u8ba8\u4e86\u672c\u4f53\u8bba\u3001\u8bed\u4e49\u65e5\u5fd7\u5904\u7406\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u589e\u5f3a\u7f51\u7edc\u5b89\u5168\u3002\u672c\u4f53\u8bba\u7ed3\u6784\u5316\u9886\u57df\u77e5\u8bc6\uff0c\u5b9e\u73b0\u4e92\u64cd\u4f5c\u6027\u3001\u6570\u636e\u96c6\u6210\u548c\u9ad8\u7ea7\u5a01\u80c1\u5206\u6790\u3002\u901a\u8fc7\u81ea\u52a8\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u6765\u7ec4\u7ec7\u5b89\u5168\u65e5\u5fd7\u6570\u636e\uff0c\u5e76\u7ed3\u5408LLMs\u63d0\u4f9b\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u6d1e\u5bdf\u63d0\u53d6\u3002", "motivation": "\u5b89\u5168\u65e5\u5fd7\u901a\u5e38\u662f\u975e\u7ed3\u6784\u5316\u548c\u590d\u6742\u7684\uff0c\u96be\u4ee5\u6709\u6548\u5206\u6790\u3002\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u7ec4\u7ec7\u548c\u63a8\u7406\u5b89\u5168\u6570\u636e\uff0c\u4ee5\u5e94\u5bf9\u65e5\u76ca\u590d\u6742\u7684\u7f51\u7edc\u5a01\u80c1\u3002", "method": "\u4f7f\u7528\u672c\u4f53\u8bba\u7ed3\u6784\u5316\u9886\u57df\u77e5\u8bc6\uff0c\u81ea\u52a8\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u6765\u7ec4\u7ec7\u5b89\u5168\u65e5\u5fd7\u6570\u636e\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u4ece\u975e\u7ed3\u6784\u5316\u5185\u5bb9\u4e2d\u63d0\u53d6\u6d1e\u5bdf\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u672c\u4f53\u8bba\u3001\u77e5\u8bc6\u56fe\u8c31\u548cLLMs\u7684\u7efc\u5408\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u5b89\u5168\u65e5\u5fd7\u6570\u636e\uff0c\u5b9e\u73b0\u667a\u80fd\u5316\u7684\u7f51\u7edc\u9632\u5fa1\u3002", "conclusion": "\u672c\u4f53\u8bba\u9a71\u52a8\u7684\u7f51\u7edc\u9632\u5fa1\u65b9\u6cd5\u7ed3\u5408\u8bed\u4e49\u65e5\u5fd7\u5904\u7406\u548cLLMs\uff0c\u4e3a\u7f51\u7edc\u5b89\u5168\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5206\u6790\u6846\u67b6\uff0c\u7b26\u5408\u6b27\u76dfNIS 2\u548c\u7f51\u7edc\u5b89\u5168\u5206\u7c7b\u6cd5\u7684\u8981\u6c42\uff0c\u5c55\u793a\u4e86\u667a\u80fd\u7f51\u7edc\u9632\u5fa1\u7684\u6311\u6218\u548c\u673a\u9047\u3002"}}
{"id": "2510.16582", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16582", "abs": "https://arxiv.org/abs/2510.16582", "authors": ["Junchi Yu", "Yujie Liu", "Jindong Gu", "Philip Torr", "Dongzhan Zhou"], "title": "Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?", "comment": "NeurIPS 2025 (Spotlight)", "summary": "Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances\nlarge language models (LLMs) by providing structured and interpretable external\nknowledge. However, existing KG-based RAG methods struggle to retrieve accurate\nand diverse information from text-rich KGs for complex real-world queries.\nProcess Reward Models (PRMs) offer a way to align the retrieval process of\nKG-based RAG with query-specific knowledge requirements, but they heavily rely\non process-level supervision signals that are expensive and hard to obtain on\nKGs. To address this challenge, we propose GraphFlow, a framework that\nefficiently retrieves accurate and diverse knowledge required for real-world\nqueries from text-rich KGs. GraphFlow employs a transition-based flow matching\nobjective to jointly optimize a retrieval policy and a flow estimator. The flow\nestimator factorizes the reward of the retrieval outcome into the intermediate\nretrieval states. Such reward factorization guides the retrieval policy to\nretrieve candidates from KGs in proportion to their reward. This allows\nGraphFlow to explore high-quality regions of KGs that yield diverse and\nrelevant results. We evaluate GraphFlow on the STaRK benchmark, which includes\nreal-world queries from multiple domains over text-rich KGs. GraphFlow\noutperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit\nrate and recall. It also shows strong generalization to unseen KGs,\ndemonstrating its effectiveness and robustness.", "AI": {"tldr": "GraphFlow\u6846\u67b6\u901a\u8fc7\u57fa\u4e8e\u8f6c\u6362\u7684\u6d41\u5339\u914d\u76ee\u6807\u4f18\u5316\u68c0\u7d22\u7b56\u7565\u548c\u6d41\u4f30\u8ba1\u5668\uff0c\u4ece\u6587\u672c\u4e30\u5bcc\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u9ad8\u6548\u68c0\u7d22\u51c6\u786e\u591a\u6837\u7684\u77e5\u8bc6\uff0c\u5728STaRK\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709KG-RAG\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684RAG\u65b9\u6cd5\u96be\u4ee5\u4ece\u6587\u672c\u4e30\u5bcc\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4e3a\u590d\u6742\u771f\u5b9e\u4e16\u754c\u67e5\u8be2\u68c0\u7d22\u51c6\u786e\u591a\u6837\u7684\u4fe1\u606f\uff0c\u800c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u9700\u8981\u6602\u8d35\u4e14\u96be\u4ee5\u83b7\u53d6\u7684\u8fc7\u7a0b\u7ea7\u76d1\u7763\u4fe1\u53f7\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u8f6c\u6362\u7684\u6d41\u5339\u914d\u76ee\u6807\u8054\u5408\u4f18\u5316\u68c0\u7d22\u7b56\u7565\u548c\u6d41\u4f30\u8ba1\u5668\uff0c\u6d41\u4f30\u8ba1\u5668\u5c06\u68c0\u7d22\u7ed3\u679c\u7684\u5956\u52b1\u5206\u89e3\u5230\u4e2d\u95f4\u68c0\u7d22\u72b6\u6001\uff0c\u6307\u5bfc\u68c0\u7d22\u7b56\u7565\u6309\u5956\u52b1\u6bd4\u4f8b\u4ece\u77e5\u8bc6\u56fe\u8c31\u4e2d\u68c0\u7d22\u5019\u9009\u3002", "result": "\u5728STaRK\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGraphFlow\u5728\u547d\u4e2d\u7387\u548c\u53ec\u56de\u7387\u4e0a\u5e73\u5747\u4f18\u4e8e\u5f3aKG-RAG\u57fa\u7ebf\uff08\u5305\u62ecGPT-4o\uff0910%\uff0c\u5e76\u5bf9\u672a\u89c1\u8fc7\u7684\u77e5\u8bc6\u56fe\u8c31\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "GraphFlow\u80fd\u591f\u6709\u6548\u63a2\u7d22\u77e5\u8bc6\u56fe\u8c31\u7684\u9ad8\u8d28\u91cf\u533a\u57df\uff0c\u4ea7\u751f\u591a\u6837\u4e14\u76f8\u5173\u7684\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.16637", "categories": ["cs.CR", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.16637", "abs": "https://arxiv.org/abs/2510.16637", "authors": ["Alireza Heshmati", "Saman Soleimani Roudi", "Sajjad Amini", "Shahrokh Ghaemmaghami", "Farokh Marvasti"], "title": "A Versatile Framework for Designing Group-Sparse Adversarial Attacks", "comment": null, "summary": "Existing adversarial attacks often neglect perturbation sparsity, limiting\ntheir ability to model structural changes and to explain how deep neural\nnetworks (DNNs) process meaningful input patterns. We propose ATOS (Attack\nThrough Overlapping Sparsity), a differentiable optimization framework that\ngenerates structured, sparse adversarial perturbations in element-wise,\npixel-wise, and group-wise forms. For white-box attacks on image classifiers,\nwe introduce the Overlapping Smoothed L0 (OSL0) function, which promotes\nconvergence to a stationary point while encouraging sparse, structured\nperturbations. By grouping channels and adjacent pixels, ATOS improves\ninterpretability and helps identify robust versus non-robust features. We\napproximate the L-infinity gradient using the logarithm of the sum of\nexponential absolute values to tightly control perturbation magnitude. On\nCIFAR-10 and ImageNet, ATOS achieves a 100% attack success rate while producing\nsignificantly sparser and more structurally coherent perturbations than prior\nmethods. The structured group-wise attack highlights critical regions from the\nnetwork's perspective, providing counterfactual explanations by replacing\nclass-defining regions with robust features from the target class.", "AI": {"tldr": "\u63d0\u51fa\u4e86ATOS\uff08\u901a\u8fc7\u91cd\u53e0\u7a00\u758f\u6027\u653b\u51fb\uff09\u6846\u67b6\uff0c\u751f\u6210\u7ed3\u6784\u5316\u7a00\u758f\u5bf9\u6297\u6270\u52a8\uff0c\u5728\u4fdd\u6301\u9ad8\u653b\u51fb\u6210\u529f\u7387\u7684\u540c\u65f6\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u653b\u51fb\u901a\u5e38\u5ffd\u7565\u6270\u52a8\u7a00\u758f\u6027\uff0c\u9650\u5236\u4e86\u5efa\u6a21\u7ed3\u6784\u53d8\u5316\u548c\u89e3\u91ca\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u6709\u610f\u4e49\u8f93\u5165\u6a21\u5f0f\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165\u91cd\u53e0\u5e73\u6ed1L0\uff08OSL0\uff09\u51fd\u6570\uff0c\u901a\u8fc7\u5206\u7ec4\u901a\u9053\u548c\u76f8\u90bb\u50cf\u7d20\u751f\u6210\u5143\u7d20\u7ea7\u3001\u50cf\u7d20\u7ea7\u548c\u5206\u7ec4\u7ea7\u7684\u7ed3\u6784\u5316\u7a00\u758f\u6270\u52a8\uff0c\u5e76\u4f7f\u7528\u5bf9\u6570\u6307\u6570\u7edd\u5bf9\u503c\u4e4b\u548c\u903c\u8fd1L\u65e0\u7a77\u68af\u5ea6\u6765\u63a7\u5236\u6270\u52a8\u5e45\u5ea6\u3002", "result": "\u5728CIFAR-10\u548cImageNet\u4e0a\u5b9e\u73b0100%\u653b\u51fb\u6210\u529f\u7387\uff0c\u4ea7\u751f\u7684\u6270\u52a8\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u7a00\u758f\u4e14\u7ed3\u6784\u66f4\u8fde\u8d2f\u3002\u5206\u7ec4\u653b\u51fb\u4ece\u7f51\u7edc\u89d2\u5ea6\u7a81\u51fa\u5173\u952e\u533a\u57df\u3002", "conclusion": "ATOS\u6846\u67b6\u80fd\u591f\u751f\u6210\u7ed3\u6784\u5316\u7a00\u758f\u5bf9\u6297\u6270\u52a8\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u653b\u51fb\u6548\u7387\uff0c\u8fd8\u901a\u8fc7\u7528\u76ee\u6807\u7c7b\u7684\u9c81\u68d2\u7279\u5f81\u66ff\u6362\u7c7b\u522b\u5b9a\u4e49\u533a\u57df\u6765\u63d0\u4f9b\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u6709\u52a9\u4e8e\u8bc6\u522b\u9c81\u68d2\u4e0e\u975e\u9c81\u68d2\u7279\u5f81\u3002"}}
{"id": "2510.16601", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16601", "abs": "https://arxiv.org/abs/2510.16601", "authors": ["Tianxing Wu", "Shutong Zhu", "Jingting Wang", "Ning Xu", "Guilin Qi", "Haofen Wang"], "title": "Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning", "comment": "13 pages, accepted by NeurIPS 2025 (spotlight)", "summary": "Uncertain knowledge graphs (UKGs) associate each triple with a confidence\nscore to provide more precise knowledge representations. Recently, since\nreal-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG)\ncompletion attracts more attention, aiming to complete missing triples and\nconfidences. Current studies attempt to learn UKG embeddings to solve this\nproblem, but they neglect the extremely imbalanced distributions of triple\nconfidences. This causes that the learnt embeddings are insufficient to\nhigh-quality UKG completion. Thus, in this paper, to address the above issue,\nwe propose a new semi-supervised Confidence Distribution Learning (ssCDL)\nmethod for UKG completion, where each triple confidence is transformed into a\nconfidence distribution to introduce more supervision information of different\nconfidences to reinforce the embedding learning process. ssCDL iteratively\nlearns UKG embedding by relational learning on labeled data (i.e., existing\ntriples with confidences) and unlabeled data with pseudo labels (i.e., unseen\ntriples with the generated confidences), which are predicted by meta-learning\nto augment the training data and rebalance the distribution of triple\nconfidences. Experiments on two UKG datasets demonstrate that ssCDL\nconsistently outperforms state-of-the-art baselines in different evaluation\nmetrics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u7684\u534a\u76d1\u7763\u7f6e\u4fe1\u5ea6\u5206\u5e03\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7f6e\u4fe1\u5ea6\u8f6c\u5316\u4e3a\u5206\u5e03\u5e76\u5229\u7528\u5143\u5b66\u4e60\u751f\u6210\u4f2a\u6807\u7b7e\u6765\u5e73\u8861\u6570\u636e\u5206\u5e03\uff0c\u63d0\u5347\u5d4c\u5165\u5b66\u4e60\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u65b9\u6cd5\u5ffd\u7565\u4e86\u7f6e\u4fe1\u5ea6\u7684\u6781\u7aef\u4e0d\u5e73\u8861\u5206\u5e03\u95ee\u9898\uff0c\u5bfc\u81f4\u5b66\u4e60\u5230\u7684\u5d4c\u5165\u4e0d\u8db3\u4ee5\u652f\u6301\u9ad8\u8d28\u91cf\u7684\u56fe\u8c31\u8865\u5168\u3002", "method": "\u63d0\u51fassCDL\u65b9\u6cd5\uff0c\u5c06\u7f6e\u4fe1\u5ea6\u8f6c\u5316\u4e3a\u5206\u5e03\u5f15\u5165\u66f4\u591a\u76d1\u7763\u4fe1\u606f\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u751f\u6210\u4f2a\u6807\u7b7e\u6765\u6269\u5145\u8bad\u7ec3\u6570\u636e\u5e76\u5e73\u8861\u7f6e\u4fe1\u5ea6\u5206\u5e03\uff0c\u8fed\u4ee3\u5b66\u4e60\u56fe\u8c31\u5d4c\u5165\u3002", "result": "\u5728\u4e24\u4e2a\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cssCDL\u5728\u4e0d\u540c\u8bc4\u4f30\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ssCDL\u901a\u8fc7\u5904\u7406\u7f6e\u4fe1\u5ea6\u4e0d\u5e73\u8861\u5206\u5e03\u95ee\u9898\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u7684\u6027\u80fd\u3002"}}
{"id": "2510.16706", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16706", "abs": "https://arxiv.org/abs/2510.16706", "authors": ["Hongjie Zhang", "Zhiqi Zhao", "Hanzhou Wu", "Zhihua Xia", "Athanasios V. Vasilakos"], "title": "Rotation, Scale, and Translation Resilient Black-box Fingerprinting for Intellectual Property Protection of EaaS Models", "comment": null, "summary": "Feature embedding has become a cornerstone technology for processing\nhigh-dimensional and complex data, which results in that Embedding as a Service\n(EaaS) models have been widely deployed in the cloud. To protect the\nintellectual property of EaaS models, existing methods apply digital\nwatermarking to inject specific backdoor triggers into EaaS models by modifying\ntraining samples or network parameters. However, these methods inevitably\nproduce detectable patterns through semantic analysis and exhibit\nsusceptibility to geometric transformations including rotation, scaling, and\ntranslation (RST). To address this problem, we propose a fingerprinting\nframework for EaaS models, rather than merely refining existing watermarking\ntechniques. Different from watermarking techniques, the proposed method\nestablishes EaaS model ownership through geometric analysis of embedding\nspace's topological structure, rather than relying on the modified training\nsamples or triggers. The key innovation lies in modeling the victim and\nsuspicious embeddings as point clouds, allowing us to perform robust spatial\nalignment and similarity measurement, which inherently resists RST attacks.\nExperimental results evaluated on visual and textual embedding tasks verify the\nsuperiority and applicability. This research reveals inherent characteristics\nof EaaS models and provides a promising solution for ownership verification of\nEaaS models under the black-box scenario.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5d4c\u5165\u5373\u670d\u52a1\uff08EaaS\uff09\u6a21\u578b\u7684\u6307\u7eb9\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u5d4c\u5165\u7a7a\u95f4\u7684\u62d3\u6251\u7ed3\u6784\u6765\u9a8c\u8bc1\u6a21\u578b\u6240\u6709\u6743\uff0c\u800c\u975e\u4f9d\u8d56\u4f20\u7edf\u6c34\u5370\u6280\u672f\u3002\u8be5\u65b9\u6cd5\u5c06\u5d4c\u5165\u5efa\u6a21\u4e3a\u70b9\u4e91\uff0c\u8fdb\u884c\u7a7a\u95f4\u5bf9\u9f50\u548c\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u80fd\u591f\u62b5\u6297\u65cb\u8f6c\u3001\u7f29\u653e\u548c\u5e73\u79fb\uff08RST\uff09\u653b\u51fb\u3002", "motivation": "\u73b0\u6709EaaS\u6a21\u578b\u6c34\u5370\u65b9\u6cd5\u901a\u8fc7\u4fee\u6539\u8bad\u7ec3\u6837\u672c\u6216\u7f51\u7edc\u53c2\u6570\u6ce8\u5165\u540e\u95e8\u89e6\u53d1\u5668\uff0c\u4f46\u4f1a\u4ea7\u751f\u53ef\u68c0\u6d4b\u7684\u8bed\u4e49\u6a21\u5f0f\u4e14\u5bb9\u6613\u53d7\u5230\u51e0\u4f55\u53d8\u6362\u653b\u51fb\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5065\u7684\u6240\u6709\u6743\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "\u5c06\u53d7\u5bb3\u6a21\u578b\u548c\u53ef\u7591\u6a21\u578b\u7684\u5d4c\u5165\u5efa\u6a21\u4e3a\u70b9\u4e91\uff0c\u901a\u8fc7\u51e0\u4f55\u5206\u6790\u5d4c\u5165\u7a7a\u95f4\u7684\u62d3\u6251\u7ed3\u6784\u8fdb\u884c\u7a7a\u95f4\u5bf9\u9f50\u548c\u76f8\u4f3c\u6027\u6d4b\u91cf\uff0c\u800c\u975e\u4f9d\u8d56\u4fee\u6539\u7684\u8bad\u7ec3\u6837\u672c\u6216\u89e6\u53d1\u5668\u3002", "result": "\u5728\u89c6\u89c9\u548c\u6587\u672c\u5d4c\u5165\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u548c\u9002\u7528\u6027\uff0c\u80fd\u591f\u6709\u6548\u62b5\u6297RST\u653b\u51fb\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86EaaS\u6a21\u578b\u7684\u56fa\u6709\u7279\u6027\uff0c\u4e3a\u9ed1\u76d2\u573a\u666f\u4e0b\u7684\u6a21\u578b\u6240\u6709\u6743\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16614", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16614", "abs": "https://arxiv.org/abs/2510.16614", "authors": ["Xuan Zhang", "Ruixiao Li", "Zhijian Zhou", "Long Li", "Yulei Qin", "Ke Li", "Xing Sun", "Xiaoyu Tan", "Chao Qu", "Yuan Qi"], "title": "Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards", "comment": null, "summary": "Reinforcement Learning (RL) has become a compelling way to strengthen the\nmulti step reasoning ability of Large Language Models (LLMs). However,\nprevalent RL paradigms still lean on sparse outcome-based rewards and limited\nexploration, which often drives LLMs toward repetitive and suboptimal reasoning\npatterns. In this paper, we study the central question of how to design\nexploration for LLM reasoning and introduce MERCI (Motivating Exploration in\nLLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that\naugments policy optimization with a principled intrinsic reward. Building on\nthe idea of count-based exploration, MERCI leverages a lightweight Coin\nFlipping Network (CFN) to estimate the pseudo count and further epistemic\nuncertainty over reasoning trajectories, and converts them into an intrinsic\nreward that values novelty while preserving the learning signal from task\nrewards. We integrate MERCI into some advanced RL frameworks like Group\nRelative Policy Optimization (GRPO). Experiments on complex reasoning\nbenchmarks demonstrate that MERCI encourages richer and more varied chains of\nthought, significantly improves performance over strong baselines, and helps\nthe policy escape local routines to discover better solutions. It indicates\nthat our targeted intrinsic motivation can make exploration reliable for\nlanguage model reasoning.", "AI": {"tldr": "MERCI\u662f\u4e00\u79cd\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u8ba1\u6570\u7684\u5185\u5728\u5956\u52b1\u6765\u6fc0\u52b1\u63a2\u7d22\uff0c\u907f\u514d\u6a21\u578b\u9677\u5165\u91cd\u590d\u548c\u6b21\u4f18\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\u4f9d\u8d56\u7a00\u758f\u7684\u7ed3\u679c\u5956\u52b1\u548c\u6709\u9650\u7684\u63a2\u7d22\uff0c\u5bfc\u81f4LLM\u8d8b\u5411\u4e8e\u91cd\u590d\u548c\u6b21\u4f18\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u9700\u8981\u8bbe\u8ba1\u66f4\u597d\u7684\u63a2\u7d22\u673a\u5236\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7684Coin Flipping Network\u4f30\u8ba1\u63a8\u7406\u8f68\u8ff9\u7684\u4f2a\u8ba1\u6570\u548c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u5185\u5728\u5956\u52b1\uff0c\u5e76\u4e0e\u4efb\u52a1\u5956\u52b1\u7ed3\u5408\u8fdb\u884c\u7b56\u7565\u4f18\u5316\u3002", "result": "\u5728\u590d\u6742\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMERCI\u9f13\u52b1\u66f4\u4e30\u5bcc\u591a\u6837\u7684\u601d\u7ef4\u94fe\uff0c\u663e\u8457\u8d85\u8d8a\u5f3a\u57fa\u7ebf\u6027\u80fd\uff0c\u5e2e\u52a9\u7b56\u7565\u9003\u79bb\u5c40\u90e8\u6a21\u5f0f\u53d1\u73b0\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u9488\u5bf9\u6027\u7684\u5185\u5728\u52a8\u673a\u53ef\u4ee5\u4f7f\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u63a2\u7d22\u66f4\u52a0\u53ef\u9760\u6709\u6548\u3002"}}
{"id": "2510.16716", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16716", "abs": "https://arxiv.org/abs/2510.16716", "authors": ["Asmita Mohanty", "Gezheng Kang", "Lei Gao", "Murali Annavaram"], "title": "DistilLock: Safeguarding LLMs from Unauthorized Knowledge Distillation on the Edge", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong performance across\ndiverse tasks, but fine-tuning them typically relies on cloud-based,\ncentralized infrastructures. This requires data owners to upload potentially\nsensitive data to external servers, raising serious privacy concerns. An\nalternative approach is to fine-tune LLMs directly on edge devices using local\ndata; however, this introduces a new challenge: the model owner must transfer\nproprietary models to the edge, which risks intellectual property (IP) leakage.\nTo address this dilemma, we propose DistilLock, a TEE-assisted fine-tuning\nframework that enables privacy-preserving knowledge distillation on the edge.\nIn DistilLock, a proprietary foundation model is executed within a trusted\nexecution environment (TEE) enclave on the data owner's device, acting as a\nsecure black-box teacher. This setup preserves both data privacy and model IP\nby preventing direct access to model internals. Furthermore, DistilLock employs\na model obfuscation mechanism to offload obfuscated weights to untrusted\naccelerators for efficient knowledge distillation without compromising\nsecurity. We demonstrate that DistilLock prevents unauthorized knowledge\ndistillation processes and model-stealing attacks while maintaining high\ncomputational efficiency, but offering a secure and practical solution for\nedge-based LLM personalization.", "AI": {"tldr": "DistilLock\u662f\u4e00\u4e2a\u57fa\u4e8e\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEE)\u7684\u9690\u79c1\u4fdd\u62a4\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b89\u5168\u5730\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u548c\u6a21\u578b\u77e5\u8bc6\u4ea7\u6743\u3002", "motivation": "\u89e3\u51b3\u4e91\u7aef\u96c6\u4e2d\u5f0f\u5fae\u8c03\u5e26\u6765\u7684\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u4ee5\u53ca\u8fb9\u7f18\u8bbe\u5907\u672c\u5730\u5fae\u8c03\u5bfc\u81f4\u7684\u77e5\u8bc6\u4ea7\u6743\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u5728\u6570\u636e\u6240\u6709\u8005\u8bbe\u5907\u7684TEE enclave\u4e2d\u8fd0\u884c\u4e13\u6709\u57fa\u7840\u6a21\u578b\u4f5c\u4e3a\u5b89\u5168\u9ed1\u76d2\u6559\u5e08\uff0c\u91c7\u7528\u6a21\u578b\u6df7\u6dc6\u673a\u5236\u5c06\u6df7\u6dc6\u6743\u91cd\u5378\u8f7d\u5230\u4e0d\u53ef\u4fe1\u52a0\u901f\u5668\u8fdb\u884c\u9ad8\u6548\u77e5\u8bc6\u84b8\u998f\u3002", "result": "DistilLock\u80fd\u591f\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u77e5\u8bc6\u84b8\u998f\u8fc7\u7a0b\u548c\u6a21\u578b\u7a83\u53d6\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "DistilLock\u4e3a\u57fa\u4e8e\u8fb9\u7f18\u7684LLM\u4e2a\u6027\u5316\u63d0\u4f9b\u4e86\u5b89\u5168\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u8ba1\u7b97\u6548\u7387\u7684\u9700\u6c42\u3002"}}
{"id": "2510.16658", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.16658", "abs": "https://arxiv.org/abs/2510.16658", "authors": ["Shihao Yang", "Xiying Huang", "Danilo Bernardo", "Jun-En Ding", "Andrew Michael", "Jingmei Yang", "Patrick Kwan", "Ashish Raj", "Feng Liu"], "title": "Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review", "comment": null, "summary": "The advent of large-scale artificial intelligence (AI) models has a\ntransformative effect on neuroscience research, which represents a paradigm\nshift from the traditional computational methods through the facilitation of\nend-to-end learning from raw brain signals and neural data. In this paper, we\nexplore the transformative effects of large-scale AI models on five major\nneuroscience domains: neuroimaging and data processing, brain-computer\ninterfaces and neural decoding, molecular neuroscience and genomic modeling,\nclinical assistance and translational frameworks, and disease-specific\napplications across neurological and psychiatric disorders. These models are\ndemonstrated to address major computational neuroscience challenges, including\nmultimodal neural data integration, spatiotemporal pattern interpretation, and\nthe derivation of translational frameworks for clinical deployment. Moreover,\nthe interaction between neuroscience and AI has become increasingly reciprocal,\nas biologically informed architectural constraints are now incorporated to\ndevelop more interpretable and computationally efficient models. This review\nhighlights both the notable promise of such technologies and key implementation\nconsiderations, with particular emphasis on rigorous evaluation frameworks,\neffective domain knowledge integration, and comprehensive ethical guidelines\nfor clinical use. Finally, a systematic listing of critical neuroscience\ndatasets used to derive and validate large-scale AI models across diverse\nresearch applications is provided.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u89c4\u6a21AI\u6a21\u578b\u5bf9\u795e\u7ecf\u79d1\u5b66\u7814\u7a76\u7684\u53d8\u9769\u6027\u5f71\u54cd\uff0c\u6db5\u76d6\u4e86\u795e\u7ecf\u5f71\u50cf\u5904\u7406\u3001\u8111\u673a\u63a5\u53e3\u3001\u5206\u5b50\u795e\u7ecf\u79d1\u5b66\u3001\u4e34\u5e8a\u8f85\u52a9\u548c\u75be\u75c5\u5e94\u7528\u7b49\u4e94\u5927\u9886\u57df\uff0c\u5c55\u793a\u4e86\u8fd9\u4e9b\u6a21\u578b\u5728\u89e3\u51b3\u591a\u6a21\u6001\u795e\u7ecf\u6570\u636e\u6574\u5408\u3001\u65f6\u7a7a\u6a21\u5f0f\u89e3\u91ca\u7b49\u6311\u6218\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u5927\u89c4\u6a21AI\u6a21\u578b\u7684\u51fa\u73b0\u4e3a\u795e\u7ecf\u79d1\u5b66\u7814\u7a76\u5e26\u6765\u4e86\u8303\u5f0f\u8f6c\u53d8\uff0c\u4fc3\u8fdb\u4e86\u4ece\u539f\u59cb\u8111\u4fe1\u53f7\u548c\u795e\u7ecf\u6570\u636e\u7684\u7aef\u5230\u7aef\u5b66\u4e60\uff0c\u65e8\u5728\u89e3\u51b3\u4f20\u7edf\u8ba1\u7b97\u65b9\u6cd5\u9762\u4e34\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u7684\u65b9\u5f0f\uff0c\u63a2\u7d22\u5927\u89c4\u6a21AI\u6a21\u578b\u5728\u4e94\u4e2a\u4e3b\u8981\u795e\u7ecf\u79d1\u5b66\u9886\u57df\u7684\u5e94\u7528\uff1a\u795e\u7ecf\u5f71\u50cf\u4e0e\u6570\u636e\u5904\u7406\u3001\u8111\u673a\u63a5\u53e3\u4e0e\u795e\u7ecf\u89e3\u7801\u3001\u5206\u5b50\u795e\u7ecf\u79d1\u5b66\u4e0e\u57fa\u56e0\u7ec4\u5efa\u6a21\u3001\u4e34\u5e8a\u8f85\u52a9\u4e0e\u8f6c\u5316\u6846\u67b6\u3001\u4ee5\u53ca\u795e\u7ecf\u7cfb\u7edf\u548c\u7cbe\u795e\u75be\u75c5\u7684\u7279\u5b9a\u5e94\u7528\u3002", "result": "\u7814\u7a76\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u6709\u6548\u6574\u5408\u591a\u6a21\u6001\u795e\u7ecf\u6570\u636e\u3001\u89e3\u91ca\u65f6\u7a7a\u6a21\u5f0f\uff0c\u5e76\u5efa\u7acb\u4e34\u5e8a\u90e8\u7f72\u7684\u8f6c\u5316\u6846\u67b6\u3002\u540c\u65f6\uff0c\u795e\u7ecf\u79d1\u5b66\u4e0eAI\u7684\u4e92\u52a8\u53d8\u5f97\u66f4\u52a0\u76f8\u4e92\u4fc3\u8fdb\uff0c\u751f\u7269\u542f\u53d1\u7684\u67b6\u6784\u7ea6\u675f\u88ab\u7eb3\u5165\u4ee5\u5f00\u53d1\u66f4\u53ef\u89e3\u91ca\u548c\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u7684\u6a21\u578b\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u5f3a\u8c03\u4e86\u8fd9\u4e9b\u6280\u672f\u7684\u663e\u8457\u524d\u666f\u548c\u5173\u952e\u5b9e\u65bd\u8003\u8651\uff0c\u7279\u522b\u5f3a\u8c03\u4e25\u683c\u7684\u8bc4\u4f30\u6846\u67b6\u3001\u6709\u6548\u7684\u9886\u57df\u77e5\u8bc6\u6574\u5408\u4ee5\u53ca\u4e34\u5e8a\u4f7f\u7528\u7684\u5168\u9762\u4f26\u7406\u6307\u5357\uff0c\u5e76\u63d0\u4f9b\u4e86\u7528\u4e8e\u9a8c\u8bc1\u5927\u89c4\u6a21AI\u6a21\u578b\u7684\u5173\u952e\u795e\u7ecf\u79d1\u5b66\u6570\u636e\u96c6\u7cfb\u7edf\u5217\u8868\u3002"}}
{"id": "2510.16744", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16744", "abs": "https://arxiv.org/abs/2510.16744", "authors": ["Srinivas Vivek"], "title": "Cryptanalysis of a Privacy-Preserving Ride-Hailing Service from NSS 2022", "comment": "9 pages", "summary": "Ride-Hailing Services (RHS) match a ride request initiated by a rider with a\nsuitable driver responding to the ride request. A Privacy-Preserving RHS\n(PP-RHS) aims to facilitate ride matching while ensuring the privacy of riders'\nand drivers' location data w.r.t. the Service Provider (SP). At NSS 2022, Xie\net al. proposed a PP-RHS. In this work, we demonstrate a passive attack on\ntheir PP-RHS protocol. Our attack allows the SP to completely recover the\nlocations of the rider as well as that of the responding drivers in every ride\nrequest. Further, our attack is very efficient as it is independent of the\nsecurity parameter.", "AI": {"tldr": "\u5bf9Xie\u7b49\u4eba\u5728NSS 2022\u63d0\u51fa\u7684\u9690\u79c1\u4fdd\u62a4\u7f51\u7ea6\u8f66\u670d\u52a1\u534f\u8bae\u8fdb\u884c\u88ab\u52a8\u653b\u51fb\uff0c\u80fd\u591f\u5b8c\u5168\u6062\u590d\u4e58\u5ba2\u548c\u53f8\u673a\u7684\u7cbe\u786e\u4f4d\u7f6e\u4fe1\u606f\u3002", "motivation": "\u9a8c\u8bc1Xie\u7b49\u4eba\u63d0\u51fa\u7684\u9690\u79c1\u4fdd\u62a4\u7f51\u7ea6\u8f66\u670d\u52a1\u534f\u8bae\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u5176\u5b58\u5728\u7684\u9690\u79c1\u6cc4\u9732\u6f0f\u6d1e\u3002", "method": "\u91c7\u7528\u88ab\u52a8\u653b\u51fb\u65b9\u5f0f\uff0c\u5206\u6790\u534f\u8bae\u4e2d\u7684\u4f4d\u7f6e\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff0c\u5229\u7528\u534f\u8bae\u8bbe\u8ba1\u7f3a\u9677\u6765\u6062\u590d\u4f4d\u7f6e\u4fe1\u606f\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u4e58\u5ba2\u548c\u53f8\u673a\u4f4d\u7f6e\u7684\u5b8c\u5168\u6062\u590d\uff0c\u653b\u51fb\u6548\u7387\u9ad8\u4e14\u4e0e\u5b89\u5168\u53c2\u6570\u65e0\u5173\u3002", "conclusion": "Xie\u7b49\u4eba\u7684PP-RHS\u534f\u8bae\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u65e0\u6cd5\u6709\u6548\u4fdd\u62a4\u7528\u6237\u4f4d\u7f6e\u9690\u79c1\uff0c\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u5b89\u5168\u673a\u5236\u3002"}}
{"id": "2510.16701", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16701", "abs": "https://arxiv.org/abs/2510.16701", "authors": ["Ni Zhang", "Zhiguang Cao", "Jianan Zhou", "Cong Zhang", "Yew-Soon Ong"], "title": "An Agentic Framework with LLMs for Solving Complex Vehicle Routing Problems", "comment": null, "summary": "Complex vehicle routing problems (VRPs) remain a fundamental challenge,\ndemanding substantial expert effort for intent interpretation and algorithm\ndesign. While large language models (LLMs) offer a promising path toward\nautomation, current approaches still rely on external intervention, which\nrestrict autonomy and often lead to execution errors and low solution\nfeasibility. To address these challenges, we propose an Agentic Framework with\nLLMs (AFL) for solving complex vehicle routing problems, achieving full\nautomation from problem instance to solution. AFL directly extracts knowledge\nfrom raw inputs and enables self-contained code generation without handcrafted\nmodules or external solvers. To improve trustworthiness, AFL decomposes the\noverall pipeline into three manageable subtasks and employs four specialized\nagents whose coordinated interactions enforce cross-functional consistency and\nlogical soundness. Extensive experiments on 60 complex VRPs, ranging from\nstandard benchmarks to practical variants, validate the effectiveness and\ngenerality of our framework, showing comparable performance against\nmeticulously designed algorithms. Notably, it substantially outperforms\nexisting LLM-based baselines in both code reliability and solution feasibility,\nachieving rates close to 100% on the evaluated benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6AFL\uff0c\u7528\u4e8e\u89e3\u51b3\u590d\u6742\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4ece\u95ee\u9898\u5b9e\u4f8b\u5230\u89e3\u51b3\u65b9\u6848\u7684\u5b8c\u5168\u81ea\u52a8\u5316\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u6216\u5916\u90e8\u6c42\u89e3\u5668\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5728\u89e3\u51b3\u590d\u6742VRP\u95ee\u9898\u65f6\u4ecd\u9700\u8981\u5916\u90e8\u5e72\u9884\uff0c\u5bfc\u81f4\u81ea\u4e3b\u6027\u53d7\u9650\u3001\u6267\u884c\u9519\u8bef\u591a\u3001\u89e3\u51b3\u65b9\u6848\u53ef\u884c\u6027\u4f4e\u3002", "method": "AFL\u6846\u67b6\u5c06\u6574\u4e2a\u6d41\u7a0b\u5206\u89e3\u4e3a\u4e09\u4e2a\u5b50\u4efb\u52a1\uff0c\u4f7f\u7528\u56db\u4e2a\u4e13\u95e8\u4ee3\u7406\u8fdb\u884c\u534f\u8c03\u4ea4\u4e92\uff0c\u76f4\u63a5\u4ece\u539f\u59cb\u8f93\u5165\u4e2d\u63d0\u53d6\u77e5\u8bc6\u5e76\u751f\u6210\u81ea\u5305\u542b\u4ee3\u7801\u3002", "result": "\u572860\u4e2a\u590d\u6742VRP\u95ee\u9898\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4ee3\u7801\u53ef\u9760\u6027\u548c\u89e3\u51b3\u65b9\u6848\u53ef\u884c\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709LLM\u57fa\u7ebf\uff0c\u5728\u8bc4\u4f30\u57fa\u51c6\u4e0a\u63a5\u8fd1100%\u7684\u6210\u529f\u7387\u3002", "conclusion": "AFL\u6846\u67b6\u5b9e\u73b0\u4e86\u590d\u6742VRP\u95ee\u9898\u7684\u5b8c\u5168\u81ea\u52a8\u5316\u6c42\u89e3\uff0c\u6027\u80fd\u53ef\u4e0e\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7b97\u6cd5\u76f8\u5ab2\u7f8e\uff0c\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u57fa\u4e8eLLM\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u548c\u53ef\u884c\u6027\u3002"}}
{"id": "2510.16794", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16794", "abs": "https://arxiv.org/abs/2510.16794", "authors": ["Jie Zhang", "Meng Ding", "Yang Liu", "Jue Hong", "Florian Tram\u00e8r"], "title": "Black-box Optimization of LLM Outputs by Asking for Directions", "comment": null, "summary": "We present a novel approach for attacking black-box large language models\n(LLMs) by exploiting their ability to express confidence in natural language.\nExisting black-box attacks require either access to continuous model outputs\nlike logits or confidence scores (which are rarely available in practice), or\nrely on proxy signals from other models. Instead, we demonstrate how to prompt\nLLMs to express their internal confidence in a way that is sufficiently\ncalibrated to enable effective adversarial optimization. We apply our general\nmethod to three attack scenarios: adversarial examples for vision-LLMs,\njailbreaks and prompt injections. Our attacks successfully generate malicious\ninputs against systems that only expose textual outputs, thereby dramatically\nexpanding the attack surface for deployed LLMs. We further find that better and\nlarger models exhibit superior calibration when expressing confidence, creating\na concerning security paradox where model capability improvements directly\nenhance vulnerability. Our code is available at this\n[link](https://github.com/zj-jayzhang/black_box_llm_optimization).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528LLM\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u7f6e\u4fe1\u5ea6\u7684\u9ed1\u76d2\u653b\u51fb\u65b9\u6cd5\uff0c\u65e0\u9700\u8bbf\u95eelogits\u6216\u7f6e\u4fe1\u5ea6\u5206\u6570\uff0c\u901a\u8fc7\u63d0\u793aLLM\u8868\u8fbe\u5185\u90e8\u7f6e\u4fe1\u5ea6\u6765\u5b9e\u73b0\u5bf9\u6297\u6027\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u7684\u9ed1\u76d2\u653b\u51fb\u9700\u8981\u8fde\u7eed\u6a21\u578b\u8f93\u51fa\u6216\u4f9d\u8d56\u5176\u4ed6\u6a21\u578b\u7684\u4ee3\u7406\u4fe1\u53f7\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u5f88\u5c11\u53ef\u7528\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4ec5\u57fa\u4e8e\u6587\u672c\u8f93\u51fa\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u63d0\u793aLLM\u4ee5\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u5176\u5185\u90e8\u7f6e\u4fe1\u5ea6\uff0c\u5229\u7528\u8fd9\u79cd\u8868\u8fbe\u8fdb\u884c\u5bf9\u6297\u6027\u4f18\u5316\uff0c\u5e94\u7528\u4e8e\u89c6\u89c9-LLM\u7684\u5bf9\u6297\u6837\u672c\u3001\u8d8a\u72f1\u548c\u63d0\u793a\u6ce8\u5165\u4e09\u79cd\u653b\u51fb\u573a\u666f\u3002", "result": "\u6210\u529f\u751f\u6210\u4e86\u9488\u5bf9\u4ec5\u66b4\u9732\u6587\u672c\u8f93\u51fa\u7684\u7cfb\u7edf\u7684\u6076\u610f\u8f93\u5165\uff0c\u663e\u8457\u6269\u5927\u4e86\u5df2\u90e8\u7f72LLM\u7684\u653b\u51fb\u9762\u3002\u53d1\u73b0\u66f4\u597d\u66f4\u5927\u7684\u6a21\u578b\u5728\u8868\u8fbe\u7f6e\u4fe1\u5ea6\u65f6\u5177\u6709\u66f4\u597d\u7684\u6821\u51c6\u6027\u3002", "conclusion": "\u6a21\u578b\u80fd\u529b\u7684\u6539\u8fdb\u76f4\u63a5\u589e\u5f3a\u4e86\u6f0f\u6d1e\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u4ee4\u4eba\u62c5\u5fe7\u7684\u5b89\u5168\u6096\u8bba\uff0c\u8868\u660e\u9700\u8981\u91cd\u65b0\u8003\u8651LLM\u90e8\u7f72\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2510.16720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16720", "abs": "https://arxiv.org/abs/2510.16720", "authors": ["Jitao Sang", "Jinlin Xiao", "Jiarun Han", "Jilin Chen", "Xiaoyi Chen", "Shuyu Wei", "Yongjie Sun", "Yuhang Wang"], "title": "Beyond Pipelines: A Survey of the Paradigm Shift toward Model-Native Agentic AI", "comment": null, "summary": "The rapid evolution of agentic AI marks a new phase in artificial\nintelligence, where Large Language Models (LLMs) no longer merely respond but\nact, reason, and adapt. This survey traces the paradigm shift in building\nagentic AI: from Pipeline-based systems, where planning, tool use, and memory\nare orchestrated by external logic, to the emerging Model-native paradigm,\nwhere these capabilities are internalized within the model's parameters. We\nfirst position Reinforcement Learning (RL) as the algorithmic engine enabling\nthis paradigm shift. By reframing learning from imitating static data to\noutcome-driven exploration, RL underpins a unified solution of LLM + RL + Task\nacross language, vision and embodied domains. Building on this, the survey\nsystematically reviews how each capability -- Planning, Tool use, and Memory --\nhas evolved from externally scripted modules to end-to-end learned behaviors.\nFurthermore, it examines how this paradigm shift has reshaped major agent\napplications, specifically the Deep Research agent emphasizing long-horizon\nreasoning and the GUI agent emphasizing embodied interaction. We conclude by\ndiscussing the continued internalization of agentic capabilities like\nMulti-agent collaboration and Reflection, alongside the evolving roles of the\nsystem and model layers in future agentic AI. Together, these developments\noutline a coherent trajectory toward model-native agentic AI as an integrated\nlearning and interaction framework, marking the transition from constructing\nsystems that apply intelligence to developing models that grow intelligence\nthrough experience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u667a\u80fdAI\u4ece\u57fa\u4e8e\u7ba1\u9053\u7684\u7cfb\u7edf\u5411\u6a21\u578b\u539f\u751f\u8303\u5f0f\u7684\u8f6c\u53d8\uff0c\u5176\u4e2d\u89c4\u5212\u3001\u5de5\u5177\u4f7f\u7528\u548c\u8bb0\u5fc6\u7b49\u80fd\u529b\u4ece\u5916\u90e8\u903b\u8f91\u7f16\u6392\u8f6c\u53d8\u4e3a\u6a21\u578b\u5185\u90e8\u53c2\u6570\u5316\u3002\u5f3a\u5316\u5b66\u4e60\u662f\u5b9e\u73b0\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u7684\u5173\u952e\u7b97\u6cd5\u5f15\u64ce\u3002", "motivation": "\u8ffd\u8e2a\u667a\u80fdAI\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u4ece\u6784\u5efa\u5e94\u7528\u667a\u80fd\u7684\u7cfb\u7edf\u8f6c\u5411\u5f00\u53d1\u901a\u8fc7\u7ecf\u9a8c\u589e\u957f\u667a\u80fd\u7684\u6a21\u578b\uff0c\u63a2\u7d22\u4ece\u5916\u90e8\u7f16\u6392\u5230\u5185\u90e8\u5b66\u4e60\u7684\u6f14\u8fdb\u8def\u5f84\u3002", "method": "\u7cfb\u7edf\u56de\u987e\u4e86\u89c4\u5212\u3001\u5de5\u5177\u4f7f\u7528\u548c\u8bb0\u5fc6\u7b49\u80fd\u529b\u7684\u6f14\u53d8\u8fc7\u7a0b\uff0c\u4ece\u5916\u90e8\u811a\u672c\u6a21\u5757\u5230\u7aef\u5230\u7aef\u5b66\u4e60\u884c\u4e3a\uff0c\u5e76\u5206\u6790\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u5b9e\u73b0\u8fd9\u4e00\u8f6c\u53d8\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\u3002", "result": "\u8bc6\u522b\u51fa\u667a\u80fdAI\u53d1\u5c55\u7684\u8fde\u8d2f\u8f68\u8ff9\uff0c\u5373\u5411\u6a21\u578b\u539f\u751f\u667a\u80fdAI\u7684\u6f14\u8fdb\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u96c6\u6210\u7684\u5b66\u4e60\u548c\u4ea4\u4e92\u6846\u67b6\u3002", "conclusion": "\u667a\u80fdAI\u6b63\u5728\u4ece\u6784\u5efa\u5e94\u7528\u667a\u80fd\u7684\u7cfb\u7edf\u8f6c\u5411\u5f00\u53d1\u901a\u8fc7\u7ecf\u9a8c\u589e\u957f\u667a\u80fd\u7684\u6a21\u578b\uff0c\u6807\u5fd7\u7740\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u7684\u65b0\u9636\u6bb5\u3002"}}
{"id": "2510.16830", "categories": ["cs.CR", "cs.CL", "68T07, 94A60, 68Q25", "I.2.6; G.1.6; E.3; C.2.4"], "pdf": "https://arxiv.org/pdf/2510.16830", "abs": "https://arxiv.org/abs/2510.16830", "authors": ["Hasan Akgul", "Daniel Borg", "Arta Berisha", "Amina Rahimova", "Andrej Novak", "Mila Petrov"], "title": "Verifiable Fine-Tuning for LLMs: Zero-Knowledge Training Proofs Bound to Data Provenance and Policy", "comment": "20 pages, 10 figures", "summary": "Large language models are often adapted through parameter efficient fine\ntuning, but current release practices provide weak assurances about what data\nwere used and how updates were computed. We present Verifiable Fine Tuning, a\nprotocol and system that produces succinct zero knowledge proofs that a\nreleased model was obtained from a public initialization under a declared\ntraining program and an auditable dataset commitment. The approach combines\nfive elements. First, commitments that bind data sources, preprocessing,\nlicenses, and per epoch quota counters to a manifest. Second, a verifiable\nsampler that supports public replayable and private index hiding batch\nselection. Third, update circuits restricted to parameter efficient fine tuning\nthat enforce AdamW style optimizer semantics and proof friendly approximations\nwith explicit error budgets. Fourth, recursive aggregation that folds per step\nproofs into per epoch and end to end certificates with millisecond\nverification. Fifth, provenance binding and optional trusted execution property\ncards that attest code identity and constants. On English and bilingual\ninstruction mixtures, the method maintains utility within tight budgets while\nachieving practical proof performance. Policy quotas are enforced with zero\nviolations, and private sampling windows show no measurable index leakage.\nFederated experiments demonstrate that the system composes with probabilistic\naudits and bandwidth constraints. These results indicate that end to end\nverifiable fine tuning is feasible today for real parameter efficient\npipelines, closing a critical trust gap for regulated and decentralized\ndeployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u53ef\u9a8c\u8bc1\u5fae\u8c03\u534f\u8bae\uff0c\u901a\u8fc7\u96f6\u77e5\u8bc6\u8bc1\u660e\u786e\u4fdd\u6a21\u578b\u662f\u4ece\u516c\u5f00\u521d\u59cb\u5316\u6a21\u578b\u7ecf\u8fc7\u58f0\u660e\u8bad\u7ec3\u7a0b\u5e8f\u548c\u53ef\u5ba1\u8ba1\u6570\u636e\u96c6\u5f97\u5230\u7684\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u6a21\u578b\u53d1\u5e03\u5b9e\u8df5\u4e2d\u7684\u6570\u636e\u6765\u6e90\u548c\u66f4\u65b0\u8ba1\u7b97\u7f3a\u4e4f\u53ef\u4fe1\u4fdd\u8bc1\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u53d1\u5e03\u5b9e\u8df5\u65e0\u6cd5\u63d0\u4f9b\u5173\u4e8e\u4f7f\u7528\u6570\u636e\u548c\u66f4\u65b0\u8ba1\u7b97\u7684\u53ef\u4fe1\u4fdd\u8bc1\uff0c\u5b58\u5728\u4fe1\u4efb\u7f3a\u53e3\uff0c\u7279\u522b\u662f\u5728\u53d7\u76d1\u7ba1\u548c\u53bb\u4e2d\u5fc3\u5316\u90e8\u7f72\u573a\u666f\u4e2d\u3002", "method": "\u7ed3\u5408\u4e94\u4e2a\u8981\u7d20\uff1a\u6570\u636e\u6e90\u627f\u8bfa\u7ed1\u5b9a\u3001\u53ef\u9a8c\u8bc1\u91c7\u6837\u5668\u3001\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u66f4\u65b0\u7535\u8def\u3001\u9012\u5f52\u805a\u5408\u8bc1\u660e\u3001\u6765\u6e90\u7ed1\u5b9a\u548c\u53ef\u4fe1\u6267\u884c\u5c5e\u6027\u5361\u3002", "result": "\u5728\u82f1\u8bed\u548c\u53cc\u8bed\u6307\u4ee4\u6df7\u5408\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u4e25\u683c\u9884\u7b97\u5185\u4fdd\u6301\u5b9e\u7528\u6027\uff0c\u5b9e\u73b0\u5b9e\u9645\u8bc1\u660e\u6027\u80fd\uff0c\u7b56\u7565\u914d\u989d\u96f6\u8fdd\u89c4\uff0c\u79c1\u6709\u91c7\u6837\u7a97\u53e3\u65e0\u7d22\u5f15\u6cc4\u9732\u3002", "conclusion": "\u7aef\u5230\u7aef\u53ef\u9a8c\u8bc1\u5fae\u8c03\u5bf9\u4e8e\u771f\u5b9e\u53c2\u6570\u9ad8\u6548\u6d41\u6c34\u7ebf\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u53d7\u76d1\u7ba1\u548c\u53bb\u4e2d\u5fc3\u5316\u90e8\u7f72\u586b\u8865\u4e86\u5173\u952e\u4fe1\u4efb\u7f3a\u53e3\u3002"}}
{"id": "2510.16724", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16724", "abs": "https://arxiv.org/abs/2510.16724", "authors": ["Minhua Lin", "Zongyu Wu", "Zhichao Xu", "Hui Liu", "Xianfeng Tang", "Qi He", "Charu Aggarwal", "Hui Liu", "Xiang Zhang", "Suhang Wang"], "title": "A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications", "comment": "38 pages, 4 figures, 7 tables", "summary": "The advent of large language models (LLMs) has transformed information access\nand reasoning through open-ended natural language interaction. However, LLMs\nremain limited by static knowledge, factual hallucinations, and the inability\nto retrieve real-time or domain-specific information. Retrieval-Augmented\nGeneration (RAG) mitigates these issues by grounding model outputs in external\nevidence, but traditional RAG pipelines are often single turn and heuristic,\nlacking adaptive control over retrieval and reasoning. Recent advances in\nagentic search address these limitations by enabling LLMs to plan, retrieve,\nand reflect through multi-step interaction with search environments. Within\nthis paradigm, reinforcement learning (RL) offers a powerful mechanism for\nadaptive and self-improving search behavior. This survey provides the first\ncomprehensive overview of \\emph{RL-based agentic search}, organizing the\nemerging field along three complementary dimensions: (i) What RL is for\n(functional roles), (ii) How RL is used (optimization strategies), and (iii)\nWhere RL is applied (scope of optimization). We summarize representative\nmethods, evaluation protocols, and applications, and discuss open challenges\nand future directions toward building reliable and scalable RL driven agentic\nsearch systems. We hope this survey will inspire future research on the\nintegration of RL and agentic search. Our repository is available at\nhttps://github.com/ventr1c/Awesome-RL-based-Agentic-Search-Papers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u662f\u5173\u4e8e\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u641c\u7d22\u7cfb\u7edf\u7684\u7efc\u8ff0\uff0c\u63a2\u8ba8\u4e86\u5982\u4f55\u7528RL\u89e3\u51b3\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u3001\u591a\u6b65\u9aa4\u7684\u667a\u80fd\u641c\u7d22\u3002", "motivation": "\u4f20\u7edfRAG\u7cfb\u7edf\u5b58\u5728\u5355\u8f6e\u4ea4\u4e92\u3001\u542f\u53d1\u5f0f\u68c0\u7d22\u7b49\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u5b9e\u73b0\u81ea\u9002\u5e94\u63a7\u5236\u548c\u591a\u6b65\u9aa4\u63a8\u7406\u3002\u667a\u80fd\u641c\u7d22\u901a\u8fc7\u591a\u6b65\u9aa4\u4ea4\u4e92\u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u4e3a\u667a\u80fd\u641c\u7d22\u63d0\u4f9b\u4e86\u81ea\u9002\u5e94\u548c\u81ea\u6211\u6539\u8fdb\u7684\u673a\u5236\u3002", "method": "\u8be5\u7efc\u8ff0\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u7ec4\u7ec7\u57fa\u4e8eRL\u7684\u667a\u80fd\u641c\u7d22\u9886\u57df\uff1aRL\u7684\u529f\u80fd\u89d2\u8272\u3001\u4f18\u5316\u7b56\u7565\u548c\u5e94\u7528\u8303\u56f4\u3002\u603b\u7ed3\u4e86\u4ee3\u8868\u6027\u65b9\u6cd5\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u5e94\u7528\u573a\u666f\u3002", "result": "\u63d0\u4f9b\u4e86\u8be5\u9886\u57df\u7684\u9996\u4e2a\u5168\u9762\u6982\u8ff0\uff0c\u5efa\u7acb\u4e86\u7cfb\u7edf\u5316\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u6db5\u76d6\u4e86\u4ece\u65b9\u6cd5\u5230\u5e94\u7528\u7684\u5b8c\u6574\u7814\u7a76\u4f53\u7cfb\u3002", "conclusion": "\u57fa\u4e8eRL\u7684\u667a\u80fd\u641c\u7d22\u7cfb\u7edf\u5177\u6709\u6784\u5efa\u53ef\u9760\u3001\u53ef\u6269\u5c55\u641c\u7d22\u7cfb\u7edf\u7684\u6f5c\u529b\uff0c\u8be5\u7efc\u8ff0\u65e8\u5728\u6fc0\u53d1RL\u4e0e\u667a\u80fd\u641c\u7d22\u878d\u5408\u7684\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2510.16835", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16835", "abs": "https://arxiv.org/abs/2510.16835", "authors": ["Hongpeng Bai", "Minhong Dong", "Yao Zhang", "Shunzhe Zhao", "Haobo Zhang", "Lingyue Li", "Yude Bai", "Guangquan Xu"], "title": "ThreatIntel-Andro: Expert-Verified Benchmarking for Robust Android Malware Research", "comment": null, "summary": "The rapidly evolving Android malware ecosystem demands high-quality,\nreal-time datasets as a foundation for effective detection and defense. With\nthe widespread adoption of mobile devices across industrial systems, they have\nbecome a critical yet often overlooked attack surface in industrial\ncybersecurity. However, mainstream datasets widely used in academia and\nindustry (e.g., Drebin) exhibit significant limitations: on one hand, their\nheavy reliance on VirusTotal's multi-engine aggregation results introduces\nsubstantial label noise; on the other hand, outdated samples reduce their\ntemporal relevance. Moreover, automated labeling tools (e.g., AVClass2) suffer\nfrom suboptimal aggregation strategies, further compounding labeling errors and\npropagating inaccuracies throughout the research community.", "AI": {"tldr": "Android\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u96c6\u5b58\u5728\u6807\u7b7e\u566a\u58f0\u3001\u65f6\u6548\u6027\u5dee\u548c\u81ea\u52a8\u5316\u6807\u6ce8\u5de5\u5177\u805a\u5408\u7b56\u7565\u4e0d\u4f73\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u5de5\u4e1a\u7f51\u7edc\u5b89\u5168\u7814\u7a76\u3002", "motivation": "\u79fb\u52a8\u8bbe\u5907\u5728\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u4f7f\u5176\u6210\u4e3a\u5173\u952e\u653b\u51fb\u9762\uff0c\u4f46\u73b0\u6709\u4e3b\u6d41\u6570\u636e\u96c6\u5b58\u5728\u6807\u7b7e\u566a\u58f0\u548c\u65f6\u6548\u6027\u95ee\u9898\uff0c\u5f71\u54cd\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u6548\u679c\u3002", "method": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u8bf4\u660e\u5177\u4f53\u65b9\u6cd5\uff0c\u4f46\u6307\u51fa\u4e86\u73b0\u6709\u6570\u636e\u96c6\u5bf9VirusTotal\u591a\u5f15\u64ce\u805a\u5408\u7684\u8fc7\u5ea6\u4f9d\u8d56\u4ee5\u53ca\u81ea\u52a8\u5316\u6807\u6ce8\u5de5\u5177\u7684\u7f3a\u9677\u3002", "result": "\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u663e\u8457\u7684\u6807\u7b7e\u566a\u58f0\u3001\u65f6\u6548\u6027\u4e0d\u8db3\u95ee\u9898\uff0c\u81ea\u52a8\u5316\u6807\u6ce8\u5de5\u5177\u7684\u805a\u5408\u7b56\u7565\u4e0d\u4f73\u8fdb\u4e00\u6b65\u52a0\u5267\u4e86\u6807\u7b7e\u9519\u8bef\u3002", "conclusion": "\u9700\u8981\u66f4\u9ad8\u8d28\u91cf\u3001\u5b9e\u65f6\u66f4\u65b0\u7684Android\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u96c6\u6765\u652f\u6301\u6709\u6548\u7684\u68c0\u6d4b\u548c\u9632\u5fa1\u7814\u7a76\u3002"}}
{"id": "2510.16742", "categories": ["cs.AI", "cs.MA", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.16742", "abs": "https://arxiv.org/abs/2510.16742", "authors": ["Paul Saves", "Pramudita Satria Palar", "Muhammad Daffa Robani", "Nicolas Verstaevel", "Moncef Garouani", "Julien Aligon", "Benoit Gaudou", "Koji Shimoyama", "Joseph Morlier"], "title": "Surrogate Modeling and Explainable Artificial Intelligence for Complex Systems: A Workflow for Automated Simulation Exploration", "comment": null, "summary": "Complex systems are increasingly explored through simulation-driven\nengineering workflows that combine physics-based and empirical models with\noptimization and analytics. Despite their power, these workflows face two\ncentral obstacles: (1) high computational cost, since accurate exploration\nrequires many expensive simulator runs; and (2) limited transparency and\nreliability when decisions rely on opaque blackbox components. We propose a\nworkflow that addresses both challenges by training lightweight emulators on\ncompact designs of experiments that (i) provide fast, low-latency\napproximations of expensive simulators, (ii) enable rigorous uncertainty\nquantification, and (iii) are adapted for global and local Explainable\nArtificial Intelligence (XAI) analyses. This workflow unifies every\nsimulation-based complex-system analysis tool, ranging from engineering design\nto agent-based models for socio-environmental understanding. In this paper, we\nproposea comparative methodology and practical recommendations for using\nsurrogate-based explainability tools within the proposed workflow. The\nmethodology supports continuous and categorical inputs, combines global-effect\nand uncertainty analyses with local attribution, and evaluates the consistency\nof explanations across surrogate models, thereby diagnosing surrogate adequacy\nand guiding further data collection or model refinement. We demonstrate the\napproach on two contrasting case studies: a multidisciplinary design analysis\nof a hybrid-electric aircraft and an agent-based model of urban segregation.\nResults show that the surrogate model and XAI coupling enables large-scale\nexploration in seconds, uncovers nonlinear interactions and emergent behaviors,\nidentifies key design and policy levers, and signals regions where surrogates\nrequire more data or alternative architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7406\u6a21\u578b\u7684\u4eff\u771f\u9a71\u52a8\u5de5\u7a0b\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u4eff\u771f\u5668\u6765\u89e3\u51b3\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u900f\u660e\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u652f\u6301\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u53ef\u89e3\u91caAI\u5206\u6790\u3002", "motivation": "\u89e3\u51b3\u4eff\u771f\u9a71\u52a8\u5de5\u7a0b\u5de5\u4f5c\u6d41\u9762\u4e34\u7684\u4e24\u4e2a\u6838\u5fc3\u969c\u788d\uff1a(1)\u9ad8\u8ba1\u7b97\u6210\u672c\uff0c(2)\u9ed1\u76d2\u7ec4\u4ef6\u5bfc\u81f4\u7684\u900f\u660e\u5ea6\u4e0d\u8db3\u548c\u53ef\u9760\u6027\u95ee\u9898\u3002", "method": "\u5728\u7d27\u51d1\u5b9e\u9a8c\u8bbe\u8ba1\u4e0a\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u4eff\u771f\u5668\uff0c\u7ed3\u5408\u5168\u5c40\u6548\u5e94\u5206\u6790\u3001\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u548c\u5c40\u90e8\u5f52\u56e0\uff0c\u8bc4\u4f30\u4e0d\u540c\u4ee3\u7406\u6a21\u578b\u95f4\u89e3\u91ca\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u4e2d\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u5728\u79d2\u7ea7\u5b8c\u6210\u5927\u89c4\u6a21\u63a2\u7d22\uff0c\u53d1\u73b0\u975e\u7ebf\u6027\u76f8\u4e92\u4f5c\u7528\u548c\u6d8c\u73b0\u884c\u4e3a\uff0c\u8bc6\u522b\u5173\u952e\u8bbe\u8ba1\u548c\u653f\u7b56\u6760\u6746\uff0c\u5e76\u6307\u793a\u4ee3\u7406\u6a21\u578b\u9700\u8981\u66f4\u591a\u6570\u636e\u6216\u66ff\u4ee3\u67b6\u6784\u7684\u533a\u57df\u3002", "conclusion": "\u4ee3\u7406\u6a21\u578b\u4e0e\u53ef\u89e3\u91caAI\u7684\u7ed3\u5408\u4e3a\u590d\u6742\u7cfb\u7edf\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u900f\u660e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u4ece\u5de5\u7a0b\u8bbe\u8ba1\u5230\u793e\u4f1a\u73af\u5883\u7406\u89e3\u7684\u5404\u79cd\u4eff\u771f\u5e94\u7528\u3002"}}
{"id": "2510.16871", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16871", "abs": "https://arxiv.org/abs/2510.16871", "authors": ["Anirban Chakraborty", "Nimish Mishra", "Sayandeep Saha", "Sarani Bhattacharya", "Debdeep Mukhopadhyay"], "title": "Addendum: Systematic Evaluation of Randomized Cache Designs against Cache Occupancy", "comment": null, "summary": "In the main text published at USENIX Security 2025, we presented a systematic\nanalysis of the role of cache occupancy in the design considerations for\nrandomized caches (from the perspectives of performance and security). On the\nperformance front, we presented a uniform benchmarking strategy that allows for\na fair comparison among different randomized cache designs. Likewise, from the\nsecurity perspective, we presented three threat assumptions: (1) covert\nchannels; (2) process fingerprinting side-channel; and (3) AES key recovery.\nThe main takeaway of our work is an open problem of designing a randomized\ncache of comparable efficiency with modern set-associative LLCs, while still\nresisting both contention-based and occupancy-based attacks. This note is meant\nas an addendum to the main text in light of the observations made in [2]. To\nsummarize, the authors in [2] argue that (1) L1d cache size plays a role in\nadversarial success, and that (2) a patched version of MIRAGE with randomized\ninitial seeding of global eviction map prevents leakage of AES key. We discuss\nthe same in this addendum.", "AI": {"tldr": "\u672c\u6587\u662f\u5bf9USENIX Security 2025\u4e3b\u8bba\u6587\u7684\u8865\u5145\u8bf4\u660e\uff0c\u8ba8\u8bba\u4e86\u7f13\u5b58\u5360\u7528\u7387\u5728\u968f\u673a\u5316\u7f13\u5b58\u8bbe\u8ba1\u4e2d\u7684\u6027\u80fd\u4e0e\u5b89\u5168\u4f5c\u7528\uff0c\u5e76\u56de\u5e94\u4e86\u76f8\u5173\u6587\u732e\u7684\u89c2\u5bdf\u7ed3\u679c\u3002", "motivation": "\u7cfb\u7edf\u5206\u6790\u7f13\u5b58\u5360\u7528\u7387\u5728\u968f\u673a\u5316\u7f13\u5b58\u8bbe\u8ba1\u4e2d\u7684\u89d2\u8272\uff0c\u4ece\u6027\u80fd\u548c\u5b89\u5168\u6027\u4e24\u4e2a\u89d2\u5ea6\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff0c\u5e76\u9488\u5bf9\u76f8\u5173\u6587\u732e\u7684\u65b0\u89c2\u5bdf\u8fdb\u884c\u8865\u5145\u8ba8\u8bba\u3002", "method": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u57fa\u51c6\u6d4b\u8bd5\u7b56\u7565\u7528\u4e8e\u516c\u5e73\u6bd4\u8f83\u4e0d\u540c\u968f\u673a\u5316\u7f13\u5b58\u8bbe\u8ba1\uff0c\u5e76\u4ece\u5b89\u5168\u89d2\u5ea6\u5b9a\u4e49\u4e86\u4e09\u79cd\u5a01\u80c1\u5047\u8bbe\uff1a\u9690\u853d\u4fe1\u9053\u3001\u8fdb\u7a0b\u6307\u7eb9\u4fa7\u4fe1\u9053\u548cAES\u5bc6\u94a5\u6062\u590d\u653b\u51fb\u3002", "result": "\u53d1\u73b0\u8bbe\u8ba1\u4e00\u4e2a\u65e2\u5177\u6709\u73b0\u4ee3\u7ec4\u76f8\u8054LLC\u76f8\u5f53\u6548\u7387\uff0c\u53c8\u80fd\u62b5\u6297\u57fa\u4e8e\u4e89\u7528\u548c\u57fa\u4e8e\u5360\u7528\u7387\u653b\u51fb\u7684\u968f\u673a\u5316\u7f13\u5b58\u662f\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u3002", "conclusion": "L1d\u7f13\u5b58\u5927\u5c0f\u5bf9\u653b\u51fb\u6210\u529f\u7387\u6709\u5f71\u54cd\uff0cMIRAGE\u7684\u968f\u673a\u5316\u521d\u59cb\u79cd\u5b50\u7248\u672c\u53ef\u4ee5\u9632\u6b62AES\u5bc6\u94a5\u6cc4\u9732\uff0c\u8fd9\u4e3a\u968f\u673a\u5316\u7f13\u5b58\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2510.16753", "categories": ["cs.AI", "68T30", "H.3.3"], "pdf": "https://arxiv.org/pdf/2510.16753", "abs": "https://arxiv.org/abs/2510.16753", "authors": ["Wei Huang", "Peining Li", "Meiyu Liang", "Xu Hou", "Junping Du", "Yingxia Shao", "Guanhua Ye", "Wu Liu", "Kangkang Lu", "Yang Yu"], "title": "ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion", "comment": "11 pages, 4 figures", "summary": "Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by\nincorporating visual and textual modalities, enabling richer and more\nexpressive entity representations. However, existing MKGs often suffer from\nincompleteness, which hinder their effectiveness in downstream tasks.\nTherefore, multimodal knowledge graph completion (MKGC) task is receiving\nincreasing attention. While large language models (LLMs) have shown promise for\nknowledge graph completion (KGC), their application to the multimodal setting\nremains underexplored. Moreover, applying Multimodal Large Language Models\n(MLLMs) to the task of MKGC introduces significant challenges: (1) the large\nnumber of image tokens per entity leads to semantic noise and modality\nconflicts, and (2) the high computational cost of processing large token\ninputs. To address these issues, we propose Efficient Lightweight Multimodal\nLarge Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token\nCompressor (MVTC) based on multi-head attention mechanism, which adaptively\ncompresses image tokens from both textual and visual views, thereby effectively\nreducing redundancy while retaining necessary information and avoiding modality\nconflicts. Additionally, we design an attention pruning strategy to remove\nredundant attention layers from MLLMs, thereby significantly reducing the\ninference cost. We further introduce a linear projection to compensate for the\nperformance degradation caused by pruning. Extensive experiments on benchmark\nFB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art\nperformance while substantially improving computational efficiency,\nestablishing a new paradigm for multimodal knowledge graph completion.", "AI": {"tldr": "\u63d0\u51faELMM\u65b9\u6cd5\u89e3\u51b3\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u7684\u8bed\u4e49\u566a\u58f0\u548c\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u89c6\u56fe\u89c6\u89c9\u6807\u8bb0\u538b\u7f29\u5668\u548c\u6ce8\u610f\u529b\u526a\u679d\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709MKG\u5b58\u5728\u4e0d\u5b8c\u6574\u6027\u95ee\u9898\uff0c\u800c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728MKGC\u4efb\u52a1\u4e2d\u9762\u4e34\u56fe\u50cf\u6807\u8bb0\u8fc7\u591a\u5bfc\u81f4\u7684\u8bed\u4e49\u566a\u58f0\u3001\u6a21\u6001\u51b2\u7a81\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faELMM\u6846\u67b6\uff0c\u5305\u542b\u57fa\u4e8e\u591a\u5934\u6ce8\u610f\u529b\u7684\u591a\u89c6\u56fe\u89c6\u89c9\u6807\u8bb0\u538b\u7f29\u5668(MVTC)\u548c\u6ce8\u610f\u529b\u526a\u679d\u7b56\u7565\uff0c\u901a\u8fc7\u7ebf\u6027\u6295\u5f71\u8865\u507f\u526a\u679d\u5e26\u6765\u7684\u6027\u80fd\u635f\u5931\u3002", "result": "\u5728FB15k-237-IMG\u548cWN18-IMG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "ELMM\u4e3a\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u5efa\u7acb\u4e86\u65b0\u7684\u8303\u5f0f\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u89e3\u51b3\u4e86\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u3002"}}
{"id": "2510.16873", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16873", "abs": "https://arxiv.org/abs/2510.16873", "authors": ["Jacob Leiken", "Sunoo Park"], "title": "On the Credibility of Deniable Communication in Court", "comment": null, "summary": "Over time, cryptographically deniable systems have come to be associated in\ncomputer-science literature with the idea of \"denying\" evidence in court -\nspecifically, with the ability to convincingly forge evidence in courtroom\nscenarios and an inability to authenticate evidence in such contexts.\nEvidentiary processes in courts, however, have been developed over centuries to\naccount for the reality that evidence has always been forgeable, and relies on\nfactors outside of cryptographic models to seek the truth \"as well as possible\"\nwhile acknowledging that all evidence is imperfect. We argue that deniability\ndoes not and need not change this paradigm.\n  Our analysis highlights a gap between technical deniability notions and their\napplication to the real world. There will always be factors outside a\ncryptographic model that influence perceptions of a message's authenticity, in\nrealistic situations. We propose the broader concept of credibility to capture\nthese factors. The credibility of a system is determined by (1) a threshold of\nquality that a forgery must pass to be \"believable\" as an original\ncommunication, which varies based on sociotechnical context and threat model,\n(2) the ease of creating a forgery that passes this threshold, which is also\ncontext- and threat-model-dependent, and (3) default system retention policy\nand retention settings. All three aspects are important for designing secure\ncommunication systems for real-world threat models, and some aspects of (2) and\n(3) may be incorporated directly into technical system design. We hope that our\nmodel of credibility will facilitate system design and deployment that\naddresses threats that are not and cannot be captured by purely technical\ndefinitions and existing cryptographic models, and support more nuanced\ndiscourse on the strengths and limitations of cryptographic guarantees within\nspecific legal and sociotechnical contexts.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2510.16756", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.16756", "abs": "https://arxiv.org/abs/2510.16756", "authors": ["Siyin Wang", "Wenyi Yu", "Xianzhao Chen", "Xiaohai Tian", "Jun Zhang", "Lu Lu", "Chao Zhang"], "title": "End-to-end Listen, Look, Speak and Act", "comment": "22 pages, 8 figures", "summary": "Human interaction is inherently multimodal and full-duplex: we listen while\nwatching, speak while acting, and fluidly adapt to turn-taking and\ninterruptions. Realizing these capabilities is essential for building models\nsimulating humans. We present ELLSA (End-to-end Listen, Look, Speak and Act),\nwhich, to our knowledge, is the first full-duplex, end-to-end model that\nsimultaneously perceives and generates across vision, text, speech, and action\nwithin a single architecture, enabling interaction patterns previously out of\nreach, yielding more natural, human-like behaviors. At its core is a novel\nSA-MoE architecture (Self-Attention Mixture-of-Experts) that routes each\nmodality to specialized experts and fuses them through a unified attention\nbackbone. This provides a generalizable solution for joint multimodal\nperception and concurrent generation, leveraging strong pre-trained components\nwhile enabling efficient modality integration and mitigating modality\ninterference. On speech-interaction and robot-manipulation benchmarks, ELLSA\nmatches modality-specific baselines, while uniquely supporting advanced\nmultimodal and full-duplex behaviors such as dialogue and action turn-taking,\ndefective instruction rejection, speaking-while-acting, context-grounded visual\nquestion answering, and action barge-ins. We contend that ELLSA represents a\nstep toward more natural and general interactive intelligence, contributing to\nthe broader pursuit of artificial general intelligence. All data, code and\nmodel checkpoints will be released upon acceptance.", "AI": {"tldr": "ELLSA\u662f\u9996\u4e2a\u5168\u53cc\u5de5\u3001\u7aef\u5230\u7aef\u7684\u591a\u6a21\u6001\u4ea4\u4e92\u6a21\u578b\uff0c\u80fd\u591f\u540c\u65f6\u611f\u77e5\u548c\u751f\u6210\u89c6\u89c9\u3001\u6587\u672c\u3001\u8bed\u97f3\u548c\u52a8\u4f5c\uff0c\u5b9e\u73b0\u66f4\u81ea\u7136\u7684\u4eba\u7c7b\u5316\u884c\u4e3a\u3002", "motivation": "\u4eba\u7c7b\u4ea4\u4e92\u672c\u8d28\u4e0a\u662f\u591a\u6a21\u6001\u548c\u5168\u53cc\u5de5\u7684\uff0c\u9700\u8981\u6a21\u578b\u80fd\u591f\u540c\u65f6\u611f\u77e5\u548c\u751f\u6210\u591a\u79cd\u6a21\u6001\u4fe1\u606f\uff0c\u5b9e\u73b0\u66f4\u81ea\u7136\u7684\u4ea4\u4e92\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u65b0\u9896\u7684SA-MoE\u67b6\u6784\uff08\u81ea\u6ce8\u610f\u529b\u4e13\u5bb6\u6df7\u5408\uff09\uff0c\u5c06\u5404\u6a21\u6001\u8def\u7531\u5230\u4e13\u7528\u4e13\u5bb6\uff0c\u901a\u8fc7\u7edf\u4e00\u6ce8\u610f\u529b\u9aa8\u5e72\u7f51\u7edc\u8fdb\u884c\u878d\u5408\uff0c\u5b9e\u73b0\u8054\u5408\u591a\u6a21\u6001\u611f\u77e5\u548c\u5e76\u53d1\u751f\u6210\u3002", "result": "\u5728\u8bed\u97f3\u4ea4\u4e92\u548c\u673a\u5668\u4eba\u64cd\u4f5c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cELLSA\u8fbe\u5230\u6a21\u6001\u7279\u5b9a\u57fa\u7ebf\u7684\u6027\u80fd\uff0c\u540c\u65f6\u652f\u6301\u9ad8\u7ea7\u591a\u6a21\u6001\u548c\u5168\u53cc\u5de5\u884c\u4e3a\uff0c\u5982\u5bf9\u8bdd\u548c\u52a8\u4f5c\u8f6e\u8f6c\u3001\u7f3a\u9677\u6307\u4ee4\u62d2\u7edd\u3001\u8fb9\u8bf4\u8bdd\u8fb9\u884c\u52a8\u7b49\u3002", "conclusion": "ELLSA\u4ee3\u8868\u4e86\u5411\u66f4\u81ea\u7136\u548c\u901a\u7528\u4ea4\u4e92\u667a\u80fd\u8fc8\u51fa\u7684\u4e00\u6b65\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u4eba\u5de5\u901a\u7528\u667a\u80fd\u7684\u8ffd\u6c42\u3002"}}
{"id": "2510.16923", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16923", "abs": "https://arxiv.org/abs/2510.16923", "authors": ["Mansi Phute", "Matthew Hull", "Haoran Wang", "Alec Helbling", "ShengYun Peng", "Willian Lunardi", "Martin Andreoni", "Wenke Lee", "Polo Chau"], "title": "UNDREAM: Bridging Differentiable Rendering and Photorealistic Simulation for End-to-end Adversarial Attacks", "comment": null, "summary": "Deep learning models deployed in safety critical applications like autonomous\ndriving use simulations to test their robustness against adversarial attacks in\nrealistic conditions. However, these simulations are non-differentiable,\nforcing researchers to create attacks that do not integrate simulation\nenvironmental factors, reducing attack success. To address this limitation, we\nintroduce UNDREAM, the first software framework that bridges the gap between\nphotorealistic simulators and differentiable renderers to enable end-to-end\noptimization of adversarial perturbations on any 3D objects. UNDREAM enables\nmanipulation of the environment by offering complete control over weather,\nlighting, backgrounds, camera angles, trajectories, and realistic human and\nobject movements, thereby allowing the creation of diverse scenes. We showcase\na wide array of distinct physically plausible adversarial objects that UNDREAM\nenables researchers to swiftly explore in different configurable environments.\nThis combination of photorealistic simulation and differentiable optimization\nopens new avenues for advancing research of physical adversarial attacks.", "AI": {"tldr": "UNDREAM\u662f\u4e00\u4e2a\u8f6f\u4ef6\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u7167\u7247\u7ea7\u771f\u5b9e\u611f\u6a21\u62df\u5668\u548c\u53ef\u5fae\u5206\u6e32\u67d3\u5668\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u76843D\u7269\u4f53\u5bf9\u6297\u6270\u52a8\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u62df\u5668\u4e0d\u53ef\u5fae\u5206\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u81ea\u52a8\u9a7e\u9a76\u7b49\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u4f7f\u7528\u7684\u6a21\u62df\u5668\u4e0d\u53ef\u5fae\u5206\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5728\u6a21\u62df\u73af\u5883\u4e2d\u96c6\u6210\u73af\u5883\u56e0\u7d20\u6765\u521b\u5efa\u6709\u6548\u7684\u5bf9\u6297\u653b\u51fb\u3002", "method": "\u5f00\u53d1UNDREAM\u6846\u67b6\uff0c\u63d0\u4f9b\u5bf9\u5929\u6c14\u3001\u5149\u7167\u3001\u80cc\u666f\u3001\u76f8\u673a\u89d2\u5ea6\u3001\u8f68\u8ff9\u4ee5\u53ca\u771f\u5b9e\u4eba\u7c7b\u548c\u7269\u4f53\u8fd0\u52a8\u7684\u5b8c\u5168\u63a7\u5236\uff0c\u7ed3\u5408\u53ef\u5fae\u5206\u6e32\u67d3\u5668\u5b9e\u73b0\u7aef\u5230\u7aef\u4f18\u5316\u3002", "result": "\u5c55\u793a\u4e86UNDREAM\u80fd\u591f\u751f\u6210\u591a\u79cd\u7269\u7406\u4e0a\u5408\u7406\u7684\u5bf9\u6297\u7269\u4f53\uff0c\u5e76\u53ef\u5728\u4e0d\u540c\u53ef\u914d\u7f6e\u73af\u5883\u4e2d\u5feb\u901f\u63a2\u7d22\u3002", "conclusion": "\u7167\u7247\u7ea7\u771f\u5b9e\u611f\u6a21\u62df\u4e0e\u53ef\u5fae\u5206\u4f18\u5316\u7684\u7ed3\u5408\u4e3a\u7269\u7406\u5bf9\u6297\u653b\u51fb\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.16769", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16769", "abs": "https://arxiv.org/abs/2510.16769", "authors": ["Shuo Han", "Yukun Cao", "Zezhong Ding", "Zengyi Gao", "S Kevin Zhou", "Xike Xie"], "title": "See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models", "comment": null, "summary": "Vision-language models (VLMs) have shown promise in graph understanding, but\nremain limited by input-token constraints, facing scalability bottlenecks and\nlacking effective mechanisms to coordinate textual and visual modalities. To\naddress these challenges, we propose GraphVista, a unified framework that\nenhances both scalability and modality coordination in graph understanding. For\nscalability, GraphVista organizes graph information hierarchically into a\nlightweight GraphRAG base, which retrieves only task-relevant textual\ndescriptions and high-resolution visual subgraphs, compressing redundant\ncontext while preserving key reasoning elements. For modality coordination,\nGraphVista introduces a planning agent that routes tasks to the most suitable\nmodality-using the text modality for simple property reasoning and the visual\nmodality for local and structurally complex reasoning grounded in explicit\ntopology. Extensive experiments demonstrate that GraphVista scales to large\ngraphs, up to $200\\times$ larger than those used in existing benchmarks, and\nconsistently outperforms existing textual, visual, and fusion-based methods,\nachieving up to $4.4\\times$ quality improvement over the state-of-the-art\nbaselines by fully exploiting the complementary strengths of both modalities.", "AI": {"tldr": "GraphVista\u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u7ec4\u7ec7\u56fe\u4fe1\u606f\u5230\u8f7b\u91cf\u7ea7GraphRAG\u57fa\u7840\u548c\u5f15\u5165\u89c4\u5212\u4ee3\u7406\u6765\u534f\u8c03\u6a21\u6001\uff0c\u89e3\u51b3\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u7406\u89e3\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6a21\u6001\u534f\u8c03\u95ee\u9898\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u7406\u89e3\u4e2d\u9762\u4e34\u8f93\u5165\u4ee4\u724c\u9650\u5236\u5bfc\u81f4\u7684\u53ef\u6269\u5c55\u6027\u74f6\u9888\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u6709\u6548\u534f\u8c03\u6587\u672c\u548c\u89c6\u89c9\u6a21\u6001\u7684\u673a\u5236\u3002", "method": "GraphVista\u91c7\u7528\u5206\u5c42\u65b9\u6cd5\u7ec4\u7ec7\u56fe\u4fe1\u606f\u5230GraphRAG\u57fa\u7840\uff0c\u4ec5\u68c0\u7d22\u4efb\u52a1\u76f8\u5173\u7684\u6587\u672c\u63cf\u8ff0\u548c\u9ad8\u5206\u8fa8\u7387\u89c6\u89c9\u5b50\u56fe\uff1b\u5f15\u5165\u89c4\u5212\u4ee3\u7406\u6839\u636e\u4efb\u52a1\u590d\u6742\u5ea6\u8def\u7531\u5230\u6700\u9002\u5408\u7684\u6a21\u6001\u3002", "result": "GraphVista\u53ef\u6269\u5c55\u5230\u6bd4\u73b0\u6709\u57fa\u51c6\u5927200\u500d\u7684\u56fe\uff0c\u5728\u6587\u672c\u3001\u89c6\u89c9\u548c\u878d\u5408\u65b9\u6cd5\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u8d28\u91cf\u63d0\u5347\u8fbe4.4\u500d\u3002", "conclusion": "GraphVista\u901a\u8fc7\u5145\u5206\u5229\u7528\u4e24\u79cd\u6a21\u6001\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u7406\u89e3\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6a21\u6001\u534f\u8c03\u6311\u6218\u3002"}}
{"id": "2510.16959", "categories": ["cs.CR", "cs.CC"], "pdf": "https://arxiv.org/pdf/2510.16959", "abs": "https://arxiv.org/abs/2510.16959", "authors": ["Surendra Ghentiyala"], "title": "Efficient derandomization of differentially private counting queries", "comment": "Accepted to SOSA'26", "summary": "Differential privacy for the 2020 census required an estimated 90 terabytes\nof randomness [GL20], an amount which may be prohibitively expensive or\nentirely infeasible to generate. Motivated by these practical concerns, [CSV25]\ninitiated the study of the randomness complexity of differential privacy, and\nin particular, the randomness complexity of $d$ counting queries. This is the\ntask of outputting the number of entries in a dataset that satisfy predicates\n$\\mathcal{P}_1, \\dots, \\mathcal{P}_d$ respectively. They showed the rather\nsurprising fact that though any reasonably accurate,\n$\\varepsilon$-differentially private mechanism for one counting query requires\n$1-O(\\varepsilon)$ bits of randomness in expectation, there exists a fairly\naccurate mechanism for $d$ counting queries which requires only $O(\\log d)$\nbits of randomness in expectation.\n  The mechanism of [CSV25] is inefficient (not polynomial time) and relies on a\ncombinatorial object known as rounding schemes. Here, we give a polynomial time\nmechanism which achieves nearly the same randomness complexity versus accuracy\ntradeoff as that of [CSV25]. Our construction is based on the following simple\nobservation: after a randomized shift of the answer to each counting query, the\nanswer to many counting queries remains the same regardless of whether we add\nnoise to that coordinate or not. This allows us to forgo the step of adding\nnoise to the result of many counting queries. Our mechanism does not make use\nof rounding schemes. Therefore, it provides a different -- and, in our opinion,\nclearer -- insight into the origins of the randomness savings that can be\nobtained by batching $d$ counting queries. Therefore, it provides a different\n-- and, in our opinion, clearer -- insight into the origins of the randomness\nsavings that can be obtained by batching $d$ counting queries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9879\u5f0f\u65f6\u95f4\u673a\u5236\uff0c\u7528\u4e8e\u5dee\u5206\u9690\u79c1\u4e0b\u7684d\u4e2a\u8ba1\u6570\u67e5\u8be2\uff0c\u4ec5\u9700O(log d)\u4f4d\u968f\u673a\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u6240\u9700\u768490TB\u968f\u673a\u6027\u3002", "motivation": "2020\u5e74\u4eba\u53e3\u666e\u67e5\u7684\u5dee\u5206\u9690\u79c1\u9700\u8981\u7ea690TB\u968f\u673a\u6027\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u6210\u672c\u9ad8\u6602\u6216\u4e0d\u53ef\u884c\u3002\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5982\u4f55\u51cf\u5c11\u5dee\u5206\u9690\u79c1\u673a\u5236\u6240\u9700\u7684\u968f\u673a\u6027\u590d\u6742\u5ea6\u3002", "method": "\u57fa\u4e8e\u7b80\u5355\u89c2\u5bdf\uff1a\u5bf9\u6bcf\u4e2a\u8ba1\u6570\u67e5\u8be2\u8fdb\u884c\u968f\u673a\u504f\u79fb\u540e\uff0c\u8bb8\u591a\u67e5\u8be2\u7684\u7ed3\u679c\u5728\u662f\u5426\u6dfb\u52a0\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u4e0d\u53d8\uff0c\u4ece\u800c\u53ef\u4ee5\u7701\u7565\u5bf9\u8fd9\u4e9b\u67e5\u8be2\u6dfb\u52a0\u566a\u58f0\u7684\u6b65\u9aa4\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f7f\u7528\u590d\u6742\u7684\u820d\u5165\u65b9\u6848\u3002", "result": "\u63d0\u51fa\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u673a\u5236\u5b9e\u73b0\u4e86\u4e0e[CSV25]\u51e0\u4e4e\u76f8\u540c\u7684\u968f\u673a\u6027\u590d\u6742\u5ea6\u4e0e\u51c6\u786e\u6027\u6743\u8861\uff0c\u4ec5\u9700O(log d)\u4f4d\u968f\u673a\u6027\u3002", "conclusion": "\u8be5\u673a\u5236\u4e0d\u4ec5\u9ad8\u6548\uff0c\u800c\u4e14\u4e3a\u7406\u89e3\u901a\u8fc7\u6279\u5904\u7406d\u4e2a\u8ba1\u6570\u67e5\u8be2\u83b7\u5f97\u968f\u673a\u6027\u8282\u7701\u7684\u6839\u6e90\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7684\u89c1\u89e3\u3002"}}
{"id": "2510.16802", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16802", "abs": "https://arxiv.org/abs/2510.16802", "authors": ["Chao Li", "Yuru Wang"], "title": "Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation", "comment": "14 pages", "summary": "Traditional knowledge graphs are constrained by fixed ontologies that\norganize concepts within rigid hierarchical structures. The root cause lies in\ntreating domains as implicit context rather than as explicit, reasoning-level\ncomponents. To overcome these limitations, we propose the Domain-Contextualized\nConcept Graph (CDC), a novel knowledge modeling framework that elevates domains\nto first-class elements of conceptual representation. CDC adopts a C-D-C triple\nstructure - <Concept, Relation@Domain, Concept'> - where domain specifications\nserve as dynamic classification dimensions defined on demand. Grounded in a\ncognitive-linguistic isomorphic mapping principle, CDC operationalizes how\nhumans understand concepts through contextual frames. We formalize more than\ntwenty standardized relation predicates (structural, logical, cross-domain, and\ntemporal) and implement CDC in Prolog for full inference capability. Case\nstudies in education, enterprise knowledge systems, and technical documentation\ndemonstrate that CDC enables context-aware reasoning, cross-domain analogy, and\npersonalized knowledge modeling - capabilities unattainable under traditional\nontology-based frameworks.", "AI": {"tldr": "\u63d0\u51faDomain-Contextualized Concept Graph (CDC)\u6846\u67b6\uff0c\u5c06\u9886\u57df\u4f5c\u4e3a\u77e5\u8bc6\u8868\u793a\u7684\u4e00\u7b49\u5143\u7d20\uff0c\u91c7\u7528<\u6982\u5ff5, \u5173\u7cfb@\u9886\u57df, \u6982\u5ff5'>\u7684\u4e09\u5143\u7ec4\u7ed3\u6784\uff0c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u548c\u8de8\u9886\u57df\u7c7b\u6bd4\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u53d7\u9650\u4e8e\u56fa\u5b9a\u7684\u672c\u4f53\u8bba\u548c\u521a\u6027\u5c42\u6b21\u7ed3\u6784\uff0c\u95ee\u9898\u5728\u4e8e\u5c06\u9886\u57df\u89c6\u4e3a\u9690\u5f0f\u4e0a\u4e0b\u6587\u800c\u975e\u663e\u5f0f\u7684\u63a8\u7406\u7ea7\u7ec4\u4ef6\u3002", "method": "\u91c7\u7528C-D-C\u4e09\u5143\u7ec4\u7ed3\u6784\uff0c\u57fa\u4e8e\u8ba4\u77e5-\u8bed\u8a00\u540c\u6784\u6620\u5c04\u539f\u5219\uff0c\u5b9a\u4e4920\u591a\u4e2a\u6807\u51c6\u5316\u5173\u7cfb\u8c13\u8bcd\uff0c\u5e76\u5728Prolog\u4e2d\u5b9e\u73b0\u5b8c\u6574\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u6559\u80b2\u3001\u4f01\u4e1a\u77e5\u8bc6\u7cfb\u7edf\u548c\u6587\u6863\u7ba1\u7406\u7b49\u6848\u4f8b\u4e2d\uff0cCDC\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u3001\u8de8\u9886\u57df\u7c7b\u6bd4\u548c\u4e2a\u6027\u5316\u77e5\u8bc6\u5efa\u6a21\u7b49\u4f20\u7edf\u6846\u67b6\u65e0\u6cd5\u5b9e\u73b0\u7684\u80fd\u529b\u3002", "conclusion": "CDC\u6846\u67b6\u901a\u8fc7\u5c06\u9886\u57df\u63d0\u5347\u4e3a\u6982\u5ff5\u8868\u793a\u7684\u4e00\u7b49\u5143\u7d20\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u672c\u4f53\u8bba\u6846\u67b6\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u77e5\u8bc6\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u52a8\u6001\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.17000", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17000", "abs": "https://arxiv.org/abs/2510.17000", "authors": ["Masahiro Kaneko", "Timothy Baldwin"], "title": "Bits Leaked per Query: Information-Theoretic Bounds on Adversarial Attacks against LLMs", "comment": "NeurIPS 2025 (spotlight)", "summary": "Adversarial attacks by malicious users that threaten the safety of large\nlanguage models (LLMs) can be viewed as attempts to infer a target property $T$\nthat is unknown when an instruction is issued, and becomes knowable only after\nthe model's reply is observed. Examples of target properties $T$ include the\nbinary flag that triggers an LLM's harmful response or rejection, and the\ndegree to which information deleted by unlearning can be restored, both\nelicited via adversarial instructions. The LLM reveals an \\emph{observable\nsignal} $Z$ that potentially leaks hints for attacking through a response\ncontaining answer tokens, thinking process tokens, or logits. Yet the scale of\ninformation leaked remains anecdotal, leaving auditors without principled\nguidance and defenders blind to the transparency--risk trade-off. We fill this\ngap with an information-theoretic framework that computes how much information\ncan be safely disclosed, and enables auditors to gauge how close their methods\ncome to the fundamental limit. Treating the mutual information $I(Z;T)$ between\nthe observation $Z$ and the target property $T$ as the leaked bits per query,\nwe show that achieving error $\\varepsilon$ requires at least\n$\\log(1/\\varepsilon)/I(Z;T)$ queries, scaling linearly with the inverse leak\nrate and only logarithmically with the desired accuracy. Thus, even a modest\nincrease in disclosure collapses the attack cost from quadratic to logarithmic\nin terms of the desired accuracy. Experiments on seven LLMs across\nsystem-prompt leakage, jailbreak, and relearning attacks corroborate the\ntheory: exposing answer tokens alone requires about a thousand queries; adding\nlogits cuts this to about a hundred; and revealing the full thinking process\ntrims it to a few dozen. Our results provide the first principled yardstick for\nbalancing transparency and security when deploying LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4fe1\u606f\u8bba\u6846\u67b6\u6765\u8861\u91cfLLM\u5728\u5bf9\u6297\u653b\u51fb\u4e2d\u7684\u4fe1\u606f\u6cc4\u9732\u7a0b\u5ea6\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u8f93\u51fa\u7c7b\u578b\uff08\u7b54\u6848token\u3001logits\u3001\u601d\u7ef4\u8fc7\u7a0b\uff09\u5bf9\u653b\u51fb\u6210\u672c\u7684\u5f71\u54cd\uff0c\u4e3a\u5e73\u8861\u900f\u660e\u5ea6\u548c\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002", "motivation": "\u5f53\u524dLLM\u5728\u5bf9\u6297\u653b\u51fb\u4e2d\u7684\u4fe1\u606f\u6cc4\u9732\u7a0b\u5ea6\u7f3a\u4e4f\u91cf\u5316\u8bc4\u4f30\uff0c\u5bfc\u81f4\u5ba1\u8ba1\u8005\u7f3a\u4e4f\u539f\u5219\u6027\u6307\u5bfc\uff0c\u9632\u5fa1\u8005\u65e0\u6cd5\u6743\u8861\u900f\u660e\u5ea6\u4e0e\u98ce\u9669\u3002\u9700\u8981\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u6765\u91cf\u5316\u4fe1\u606f\u6cc4\u9732\u5e76\u6307\u5bfc\u5b89\u5168\u90e8\u7f72\u3002", "method": "\u4f7f\u7528\u4e92\u4fe1\u606fI(Z;T)\u4f5c\u4e3a\u4fe1\u606f\u6cc4\u9732\u5ea6\u91cf\uff0c\u6784\u5efa\u4fe1\u606f\u8bba\u6846\u67b6\u5206\u6790\u4e0d\u540c\u89c2\u6d4b\u4fe1\u53f7Z\uff08\u7b54\u6848token\u3001logits\u3001\u601d\u7ef4\u8fc7\u7a0b\uff09\u4e0e\u76ee\u6807\u5c5e\u6027T\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63a8\u5bfc\u653b\u51fb\u6240\u9700\u67e5\u8be2\u6b21\u6570\u4e0e\u6cc4\u9732\u7387\u7684\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff1a\u4ec5\u66b4\u9732\u7b54\u6848token\u9700\u8981\u7ea61000\u6b21\u67e5\u8be2\uff1b\u6dfb\u52a0logits\u53ef\u51cf\u5c11\u5230\u7ea6100\u6b21\uff1b\u66b4\u9732\u5b8c\u6574\u601d\u7ef4\u8fc7\u7a0b\u4ec5\u9700\u51e0\u5341\u6b21\u67e5\u8be2\u3002\u653b\u51fb\u6210\u672c\u4e0e\u6cc4\u9732\u7387\u6210\u53cd\u6bd4\uff0c\u4e0e\u671f\u671b\u7cbe\u5ea6\u5448\u5bf9\u6570\u5173\u7cfb\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aLLM\u90e8\u7f72\u4e2d\u7684\u900f\u660e\u5ea6-\u5b89\u5168\u6027\u6743\u8861\u63d0\u4f9b\u4e86\u9996\u4e2a\u539f\u5219\u6027\u8861\u91cf\u6807\u51c6\uff0c\u8bc1\u660e\u9002\u5ea6\u589e\u52a0\u4fe1\u606f\u6cc4\u9732\u4f1a\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u672c\uff0c\u5f3a\u8c03\u4e86\u5728\u63d0\u4f9b\u900f\u660e\u5ea6\u65f6\u9700\u8c28\u614e\u63a7\u5236\u4fe1\u606f\u6cc4\u9732\u3002"}}
{"id": "2510.16872", "categories": ["cs.AI", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.16872", "abs": "https://arxiv.org/abs/2510.16872", "authors": ["Shaolei Zhang", "Ju Fan", "Meihao Fan", "Guoliang Li", "Xiaoyong Du"], "title": "DeepAnalyze: Agentic Large Language Models for Autonomous Data Science", "comment": "Code: https://github.com/ruc-datalab/DeepAnalyze Model:\n  https://huggingface.co/RUC-DataLab/DeepAnalyze-8B", "summary": "Autonomous data science, from raw data sources to analyst-grade deep research\nreports, has been a long-standing challenge, and is now becoming feasible with\nthe emergence of powerful large language models (LLMs). Recent workflow-based\ndata agents have shown promising results on specific data tasks but remain\nfundamentally limited in achieving fully autonomous data science due to their\nreliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,\nthe first agentic LLM designed for autonomous data science, capable of\nautomatically completing the end-toend pipeline from data sources to\nanalyst-grade deep research reports. To tackle high-complexity data science\ntasks, we propose a curriculum-based agentic training paradigm that emulates\nthe learning trajectory of human data scientists, enabling LLMs to\nprogressively acquire and integrate multiple capabilities in real-world\nenvironments. We also introduce a data-grounded trajectory synthesis framework\nthat constructs high-quality training data. Through agentic training,\nDeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data\nquestion answering and specialized analytical tasks to open-ended data\nresearch. Experiments demonstrate that, with only 8B parameters, DeepAnalyze\noutperforms previous workflow-based agents built on most advanced proprietary\nLLMs. The model, code, and training data of DeepAnalyze are open-sourced,\npaving the way toward autonomous data science.", "AI": {"tldr": "DeepAnalyze-8B\u662f\u9996\u4e2a\u7528\u4e8e\u81ea\u4e3b\u6570\u636e\u79d1\u5b66\u7684\u4ee3\u7406\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u591f\u4ece\u6570\u636e\u6e90\u5230\u5206\u6790\u5e08\u7ea7\u6df1\u5ea6\u7814\u7a76\u62a5\u544a\u81ea\u52a8\u5b8c\u6210\u7aef\u5230\u7aef\u6d41\u7a0b\uff0c\u4ec5\u752880\u4ebf\u53c2\u6570\u5c31\u8d85\u8d8a\u4e86\u57fa\u4e8e\u6700\u5148\u8fdb\u4e13\u6709LLM\u7684\u5de5\u4f5c\u6d41\u4ee3\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5de5\u4f5c\u6d41\u7684\u6570\u636e\u4ee3\u7406\u5728\u7279\u5b9a\u6570\u636e\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7531\u4e8e\u4f9d\u8d56\u9884\u5b9a\u4e49\u5de5\u4f5c\u6d41\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5b8c\u5168\u81ea\u4e3b\u7684\u6570\u636e\u79d1\u5b66\u3002\u968f\u7740\u5f3a\u5927LLM\u7684\u51fa\u73b0\uff0c\u81ea\u4e3b\u6570\u636e\u79d1\u5b66\u53d8\u5f97\u53ef\u884c\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u8bfe\u7a0b\u5b66\u4e60\u7684\u4ee3\u7406\u8bad\u7ec3\u8303\u5f0f\uff0c\u6a21\u62df\u4eba\u7c7b\u6570\u636e\u79d1\u5b66\u5bb6\u7684\u5b66\u4e60\u8f68\u8ff9\uff0c\u4f7fLLM\u80fd\u591f\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u9010\u6b65\u83b7\u53d6\u548c\u6574\u5408\u591a\u79cd\u80fd\u529b\u3002\u8fd8\u5f15\u5165\u4e86\u6570\u636e\u57fa\u7840\u8f68\u8ff9\u5408\u6210\u6846\u67b6\u6765\u6784\u5efa\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDeepAnalyze-8B\u80fd\u591f\u6267\u884c\u5e7f\u6cdb\u7684\u6570\u636e\u4efb\u52a1\uff0c\u4ece\u6570\u636e\u95ee\u7b54\u3001\u4e13\u4e1a\u5206\u6790\u4efb\u52a1\u5230\u5f00\u653e\u5f0f\u6570\u636e\u7814\u7a76\uff0c\u6027\u80fd\u8d85\u8d8a\u4e86\u4e4b\u524d\u57fa\u4e8e\u6700\u5148\u8fdb\u4e13\u6709LLM\u7684\u5de5\u4f5c\u6d41\u4ee3\u7406\u3002", "conclusion": "DeepAnalyze\u6a21\u578b\u3001\u4ee3\u7801\u548c\u8bad\u7ec3\u6570\u636e\u5df2\u5f00\u6e90\uff0c\u4e3a\u81ea\u4e3b\u6570\u636e\u79d1\u5b66\u7684\u53d1\u5c55\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.17033", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17033", "abs": "https://arxiv.org/abs/2510.17033", "authors": ["Leixu Huang", "Zedian Shao", "Teodora Baluta"], "title": "Watermark Robustness and Radioactivity May Be at Odds in Federated Learning", "comment": "9 pages, 4 figures (not including citation and appendix) submitted to\n  ICLR 2026", "summary": "Federated learning (FL) enables fine-tuning large language models (LLMs)\nacross distributed data sources. As these sources increasingly include\nLLM-generated text, provenance tracking becomes essential for accountability\nand transparency. We adapt LLM watermarking for data provenance in FL where a\nsubset of clients compute local updates on watermarked data, and the server\naverages all updates into the global LLM. In this setup, watermarks are\nradioactive: the watermark signal remains detectable after fine-tuning with\nhigh confidence. The $p$-value can reach $10^{-24}$ even when as little as\n$6.6\\%$ of data is watermarked. However, the server can act as an active\nadversary that wants to preserve model utility while evading provenance\ntracking. Our observation is that updates induced by watermarked synthetic data\nappear as outliers relative to non-watermark updates. Our adversary thus\napplies strong robust aggregation that can filter these outliers, together with\nthe watermark signal. All evaluated radioactive watermarks are not robust\nagainst such an active filtering server. Our work suggests fundamental\ntrade-offs between radioactivity, robustness, and utility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u5e94\u7528LLM\u6c34\u5370\u6280\u672f\u8fdb\u884c\u6570\u636e\u6eaf\u6e90\uff0c\u6c34\u5370\u5177\u6709\u653e\u5c04\u6027\u7279\u5f81\uff08\u8bad\u7ec3\u540e\u4ecd\u53ef\u68c0\u6d4b\uff09\uff0c\u4f46\u9762\u4e34\u670d\u52a1\u5668\u4e3b\u52a8\u8fc7\u6ee4\u653b\u51fb\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740\u8054\u90a6\u5b66\u4e60\u4e2d\u8d8a\u6765\u8d8a\u591a\u4f7f\u7528LLM\u751f\u6210\u7684\u6570\u636e\uff0c\u9700\u8981\u5efa\u7acb\u6570\u636e\u6eaf\u6e90\u673a\u5236\u4ee5\u786e\u4fdd\u95ee\u8d23\u5236\u548c\u900f\u660e\u5ea6\u3002", "method": "\u5c06LLM\u6c34\u5370\u6280\u672f\u5e94\u7528\u4e8e\u8054\u90a6\u5b66\u4e60\u73af\u5883\uff0c\u8ba9\u90e8\u5206\u5ba2\u6237\u7aef\u5728\u5e26\u6c34\u5370\u6570\u636e\u4e0a\u8ba1\u7b97\u672c\u5730\u66f4\u65b0\uff0c\u670d\u52a1\u5668\u805a\u5408\u6240\u6709\u66f4\u65b0\u5230\u5168\u5c40LLM\u4e2d\u3002", "result": "\u6c34\u5370\u5177\u6709\u653e\u5c04\u6027\u7279\u5f81\uff0c\u5373\u4f7f\u53ea\u67096.6%\u7684\u6570\u636e\u5e26\u6c34\u5370\uff0cp\u503c\u4ecd\u53ef\u8fbe10^{-24}\u3002\u4f46\u670d\u52a1\u5668\u4f5c\u4e3a\u4e3b\u52a8\u5bf9\u6297\u8005\u53ef\u4ee5\u901a\u8fc7\u9c81\u68d2\u805a\u5408\u8fc7\u6ee4\u6c34\u5370\u66f4\u65b0\u3002", "conclusion": "\u653e\u5c04\u6027\u6c34\u5370\u5728\u4e3b\u52a8\u8fc7\u6ee4\u670d\u52a1\u5668\u9762\u524d\u4e0d\u5177\u9c81\u68d2\u6027\uff0c\u9700\u8981\u5728\u653e\u5c04\u6027\u3001\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002"}}
{"id": "2510.16907", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16907", "abs": "https://arxiv.org/abs/2510.16907", "authors": ["Kangrui Wang", "Pingyue Zhang", "Zihan Wang", "Yaning Gao", "Linjie Li", "Qineng Wang", "Hanyang Chen", "Chi Wan", "Yiping Lu", "Zhengyuan Yang", "Lijuan Wang", "Ranjay Krishna", "Jiajun Wu", "Li Fei-Fei", "Yejin Choi", "Manling Li"], "title": "VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents", "comment": "Accepted to NeurIPS 2025", "summary": "A key challenge in training Vision-Language Model (VLM) agents, compared to\nLanguage Model (LLM) agents, lies in the shift from textual states to complex\nvisual observations. This transition introduces partial observability and\ndemands robust world modeling. We ask: Can VLM agents construct internal world\nmodels through explicit visual state reasoning? To address this question, we\narchitecturally enforce and reward the agent's reasoning process via\nreinforcement learning (RL), formulating it as a Partially Observable Markov\nDecision Process (POMDP). We find that decomposing the agent's reasoning into\nState Estimation (\"what is the current state?\") and Transition Modeling (\"what\ncomes next?\") is critical for success, as demonstrated through five reasoning\nstrategies. Our investigation into how agents represent internal beliefs\nreveals that the optimal representation is task-dependent: Natural Language\nexcels at capturing semantic relationships in general tasks, while Structured\nformats are indispensable for precise manipulation and control. Building on\nthese insights, we design a World Modeling Reward that provides dense,\nturn-level supervision for accurate state prediction, and introduce Bi-Level\nGeneral Advantage Estimation (Bi-Level GAE) for turn-aware credit assignment.\nThrough this form of visual state reasoning, a 3B-parameter model achieves a\nscore of 0.82 across five diverse agent benchmarks, representing a 3$\\times$\nimprovement over its untrained counterpart (0.21) and outperforming proprietary\nreasoning models such as GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5\n(0.62). All experiments are conducted within our VAGEN framework, a scalable\nsystem for training and analyzing multi-turn VLM agents in diverse visual\nenvironments. Code and data are publicly available at\nhttps://vagen-ai.github.io.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3VLM\u4ee3\u7406\u6784\u5efa\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u5c06\u89c6\u89c9\u72b6\u6001\u63a8\u7406\u5206\u89e3\u4e3a\u72b6\u6001\u4f30\u8ba1\u548c\u8f6c\u79fb\u5efa\u6a21\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e16\u754c\u5efa\u6a21\u5956\u52b1\u548c\u53cc\u5c42GAE\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u672a\u8bad\u7ec3\u6a21\u578b\u548c\u4e13\u6709\u63a8\u7406\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3VLM\u4ee3\u7406\u4ece\u6587\u672c\u72b6\u6001\u8f6c\u5411\u590d\u6742\u89c6\u89c9\u89c2\u5bdf\u65f6\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u6311\u6218\uff0c\u63a2\u7d22\u4ee3\u7406\u662f\u5426\u80fd\u901a\u8fc7\u663e\u5f0f\u89c6\u89c9\u72b6\u6001\u63a8\u7406\u6784\u5efa\u5185\u90e8\u4e16\u754c\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5728POMDP\u6846\u67b6\u4e0b\u8bad\u7ec3\u4ee3\u7406\uff0c\u5c06\u63a8\u7406\u8fc7\u7a0b\u5206\u89e3\u4e3a\u72b6\u6001\u4f30\u8ba1\u548c\u8f6c\u79fb\u5efa\u6a21\uff0c\u8bbe\u8ba1\u4e86\u4e16\u754c\u5efa\u6a21\u5956\u52b1\u548c\u53cc\u5c42GAE\u65b9\u6cd5\u8fdb\u884c\u5bc6\u96c6\u76d1\u7763\u548c\u4fe1\u7528\u5206\u914d\u3002", "result": "3B\u53c2\u6570\u6a21\u578b\u5728\u4e94\u4e2a\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5f97\u52060.82\uff0c\u6bd4\u672a\u8bad\u7ec3\u6a21\u578b(0.21)\u63d0\u53473\u500d\uff0c\u4f18\u4e8eGPT-5(0.75)\u3001Gemini 2.5 Pro(0.67)\u548cClaude 4.5(0.62)\u3002", "conclusion": "\u89c6\u89c9\u72b6\u6001\u63a8\u7406\u80fd\u6709\u6548\u5e2e\u52a9VLM\u4ee3\u7406\u6784\u5efa\u4e16\u754c\u6a21\u578b\uff0c\u6700\u4f18\u8868\u793a\u5f62\u5f0f\u53d6\u51b3\u4e8e\u4efb\u52a1\u7279\u6027\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728VAGEN\u6846\u67b6\u4e0b\u5b9e\u73b0\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2510.17087", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.17087", "abs": "https://arxiv.org/abs/2510.17087", "authors": ["Ziqing Zhu"], "title": "Quantum Key Distribution for Virtual Power Plant Communication: A Lightweight Key-Aware Scheduler with Provable Stability", "comment": null, "summary": "Virtual power plants (VPPs) are becoming a cornerstone of future grids,\naggregating distributed PV, wind, storage, and flexible loads for market\nparticipation and real-time balancing. As operations move to minute-- and\nsecond--level feedback, communication security shifts from a compliance item to\nan operational constraint: latency, reliability, and confidentiality jointly\ndetermine whether dispatch, protection, and settlement signals arrive on time.\nConventional PKI and key-rotation schemes struggle with cross-domain,\nhigh-frequency messaging and face long-term quantum threats. Quantum key\ndistribution (QKD) offers information-theoretic key freshness, but its key\nyield is scarce and stochastic, often misaligned with bursty VPP traffic. This\npaper proposes a key-aware priority and quota framework that treats quantum\nkeys as first-class scheduling resources. The design combines (i)\nforecast-driven long-term quotas and short-term tokens, (ii) key-aware\ndeficit-round-robin arbitration, (iii) a preemptive emergency key reserve, and\n(iv) graceful degradation via encryption-mode switching and controlled\ndown-sampling for non-critical traffic. A drift-plus-penalty analysis\nestablishes strong stability under average supply--demand balance with\nquantifiable bounds on backlog and tail latency, providing interpretable\noperating guarantees. We build a reproducible testbed on IEEE 33- and 123-bus\nVPP systems and evaluate normal, degraded, and outage regimes with\nindustry-consistent message classes and TTLs. Against FIFO, fixed-priority, and\nstatic-quota baselines, the proposed scheme consistently reduces tail delay and\npassive timeouts for critical messages, improves per-bit key utility, and\nenhances power-tracking reliability during key scarcity and regime switches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u865a\u62df\u7535\u5382\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7684\u5bc6\u94a5\u611f\u77e5\u4f18\u5148\u7ea7\u548c\u914d\u989d\u6846\u67b6\uff0c\u5c06\u91cf\u5b50\u5bc6\u94a5\u4f5c\u4e3a\u4e00\u7ea7\u8c03\u5ea6\u8d44\u6e90\u8fdb\u884c\u7ba1\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5173\u952e\u6d88\u606f\u7684\u4f20\u8f93\u6027\u80fd\u548c\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "motivation": "\u865a\u62df\u7535\u5382\u9700\u8981\u9ad8\u9891\u901a\u4fe1\u652f\u6301\u5206\u949f\u7ea7\u548c\u79d2\u7ea7\u5b9e\u65f6\u8c03\u5ea6\uff0c\u4f20\u7edfPKI\u548c\u5bc6\u94a5\u8f6e\u6362\u65b9\u6848\u96be\u4ee5\u6ee1\u8db3\u8de8\u57df\u9ad8\u9891\u6d88\u606f\u4f20\u8f93\u9700\u6c42\uff0c\u4e14\u9762\u4e34\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u3002\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u867d\u7136\u63d0\u4f9b\u4fe1\u606f\u8bba\u5b89\u5168\uff0c\u4f46\u5176\u5bc6\u94a5\u4ea7\u91cf\u6709\u9650\u4e14\u968f\u673a\uff0c\u4e0e\u7a81\u53d1\u6027VPP\u6d41\u91cf\u4e0d\u5339\u914d\u3002", "method": "\u8bbe\u8ba1\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\u7684\u6846\u67b6\uff1a(1)\u57fa\u4e8e\u9884\u6d4b\u7684\u957f\u671f\u914d\u989d\u548c\u77ed\u671f\u4ee4\u724c\u673a\u5236\uff1b(2)\u5bc6\u94a5\u611f\u77e5\u7684\u8d64\u5b57\u8f6e\u8be2\u4ef2\u88c1\uff1b(3)\u62a2\u5360\u5f0f\u5e94\u6025\u5bc6\u94a5\u50a8\u5907\uff1b(4)\u901a\u8fc7\u52a0\u5bc6\u6a21\u5f0f\u5207\u6362\u548c\u975e\u5173\u952e\u6d41\u91cf\u964d\u91c7\u6837\u7684\u4f18\u96c5\u964d\u7ea7\u673a\u5236\u3002", "result": "\u5728IEEE 33\u548c123\u603b\u7ebfVPP\u7cfb\u7edf\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4FIFO\u3001\u56fa\u5b9a\u4f18\u5148\u7ea7\u548c\u9759\u6001\u914d\u989d\u57fa\u7ebf\uff0c\u8be5\u65b9\u6848\u6301\u7eed\u964d\u4f4e\u4e86\u5173\u952e\u6d88\u606f\u7684\u5c3e\u90e8\u5ef6\u8fdf\u548c\u88ab\u52a8\u8d85\u65f6\uff0c\u63d0\u9ad8\u4e86\u6bcf\u6bd4\u7279\u5bc6\u94a5\u6548\u7528\uff0c\u589e\u5f3a\u4e86\u5bc6\u94a5\u7a00\u7f3a\u548c\u72b6\u6001\u5207\u6362\u671f\u95f4\u7684\u529f\u7387\u8ddf\u8e2a\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u5bc6\u94a5\u611f\u77e5\u8c03\u5ea6\u6846\u67b6\u5728\u5e73\u5747\u4f9b\u9700\u5e73\u8861\u4e0b\u5efa\u7acb\u4e86\u5f3a\u7a33\u5b9a\u6027\uff0c\u4e3a\u91cf\u5b50\u5bc6\u94a5\u8d44\u6e90\u53d7\u9650\u7684\u865a\u62df\u7535\u5382\u901a\u4fe1\u63d0\u4f9b\u4e86\u53ef\u91cf\u5316\u7684\u64cd\u4f5c\u4fdd\u969c\u3002"}}
{"id": "2510.16956", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16956", "abs": "https://arxiv.org/abs/2510.16956", "authors": ["Mark Towers", "Yali Du", "Christopher Freeman", "Timothy J. Norman"], "title": "A Comparative User Evaluation of XRL Explanations using Goal Identification", "comment": "Accepted to ECAI 2025 Workshop on Evaluating Explainable AI and\n  Complex Decision-Making, 8 Pages", "summary": "Debugging is a core application of explainable reinforcement learning (XRL)\nalgorithms; however, limited comparative evaluations have been conducted to\nunderstand their relative performance. We propose a novel evaluation\nmethodology to test whether users can identify an agent's goal from an\nexplanation of its decision-making. Utilising the Atari's Ms. Pacman\nenvironment and four XRL algorithms, we find that only one achieved greater\nthan random accuracy for the tested goals and that users were generally\noverconfident in their selections. Further, we find that users' self-reported\nease of identification and understanding for every explanation did not\ncorrelate with their accuracy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u7528\u6237\u662f\u5426\u80fd\u4ece\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u89e3\u91ca\u4e2d\u8bc6\u522b\u667a\u80fd\u4f53\u7684\u76ee\u6807\u3002\u5728Ms. Pacman\u73af\u5883\u4e2d\u6d4b\u8bd5\u56db\u79cd\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u53d1\u73b0\u53ea\u6709\u4e00\u79cd\u7b97\u6cd5\u5728\u6d4b\u8bd5\u76ee\u6807\u4e0a\u8fbe\u5230\u4e86\u8d85\u8fc7\u968f\u673a\u6c34\u5e73\u7684\u51c6\u786e\u7387\uff0c\u4e14\u7528\u6237\u666e\u904d\u9ad8\u4f30\u4e86\u81ea\u5df1\u7684\u9009\u62e9\u51c6\u786e\u6027\u3002", "motivation": "\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6838\u5fc3\u5e94\u7528\u662f\u8c03\u8bd5\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u7b97\u6cd5\u76f8\u5bf9\u6027\u80fd\u7684\u6bd4\u8f83\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528Atari\u7684Ms. Pacman\u73af\u5883\u548c\u56db\u79cd\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u63d0\u51fa\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u6d4b\u8bd5\u7528\u6237\u4ece\u7b97\u6cd5\u51b3\u7b56\u89e3\u91ca\u4e2d\u8bc6\u522b\u667a\u80fd\u4f53\u76ee\u6807\u7684\u80fd\u529b\u3002", "result": "\u53ea\u6709\u4e00\u79cd\u7b97\u6cd5\u5728\u6d4b\u8bd5\u76ee\u6807\u4e0a\u8fbe\u5230\u4e86\u8d85\u8fc7\u968f\u673a\u6c34\u5e73\u7684\u51c6\u786e\u7387\uff1b\u7528\u6237\u666e\u904d\u9ad8\u4f30\u81ea\u5df1\u7684\u9009\u62e9\u51c6\u786e\u6027\uff1b\u7528\u6237\u81ea\u6211\u62a5\u544a\u7684\u8bc6\u522b\u548c\u7406\u89e3\u96be\u6613\u7a0b\u5ea6\u4e0e\u4ed6\u4eec\u7684\u5b9e\u9645\u51c6\u786e\u7387\u6ca1\u6709\u76f8\u5173\u6027\u3002", "conclusion": "\u5f53\u524d\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u89e3\u91ca\u6548\u679c\u6709\u9650\uff0c\u7528\u6237\u7684\u4e3b\u89c2\u611f\u53d7\u4e0e\u5b9e\u9645\u8bc6\u522b\u80fd\u529b\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u8981\u6539\u8fdb\u89e3\u91ca\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u8c03\u8bd5\u6548\u679c\u3002"}}
{"id": "2510.17098", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17098", "abs": "https://arxiv.org/abs/2510.17098", "authors": ["Elias Hossain", "Swayamjit Saha", "Somshubhra Roy", "Ravi Prasad"], "title": "Can Transformer Memory Be Corrupted? Investigating Cache-Side Vulnerabilities in Large Language Models", "comment": null, "summary": "Even when prompts and parameters are secured, transformer language models\nremain vulnerable because their key-value (KV) cache during inference\nconstitutes an overlooked attack surface. This paper introduces Malicious Token\nInjection (MTI), a modular framework that systematically perturbs cached key\nvectors at selected layers and timesteps through controlled magnitude and\nfrequency, using additive Gaussian noise, zeroing, and orthogonal rotations. A\ntheoretical analysis quantifies how these perturbations propagate through\nattention, linking logit deviations to the Frobenius norm of corruption and\nsoftmax Lipschitz dynamics. Empirical results show that MTI significantly\nalters next-token distributions and downstream task performance across GPT-2\nand LLaMA-2/7B, as well as destabilizes retrieval-augmented and agentic\nreasoning pipelines. These findings identify cache integrity as a critical yet\nunderexplored vulnerability in current LLM deployments, positioning cache\ncorruption as a reproducible and theoretically grounded threat model for future\nrobustness and security research.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u6076\u610f\u4ee4\u724c\u6ce8\u5165(MTI)\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6270\u52a8transformer\u8bed\u8a00\u6a21\u578b\u7684KV\u7f13\u5b58\u6765\u653b\u51fb\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u7f13\u5b58\u5b8c\u6574\u6027\u662f\u4e00\u4e2a\u88ab\u5ffd\u89c6\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "\u5373\u4f7f\u63d0\u793a\u548c\u53c2\u6570\u5f97\u5230\u4fdd\u62a4\uff0ctransformer\u8bed\u8a00\u6a21\u578b\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u653b\u51fb\uff0c\u56e0\u4e3a\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u952e\u503c(KV)\u7f13\u5b58\u6784\u6210\u4e86\u4e00\u4e2a\u88ab\u5ffd\u89c6\u7684\u653b\u51fb\u9762\u3002", "method": "MTI\u6846\u67b6\u901a\u8fc7\u63a7\u5236\u5e45\u5ea6\u548c\u9891\u7387\uff0c\u5728\u9009\u5b9a\u5c42\u548c\u65f6\u95f4\u6b65\u4e0a\u4f7f\u7528\u52a0\u6027\u9ad8\u65af\u566a\u58f0\u3001\u5f52\u96f6\u548c\u6b63\u4ea4\u65cb\u8f6c\u6765\u7cfb\u7edf\u6027\u5730\u6270\u52a8\u7f13\u5b58\u7684\u952e\u5411\u91cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aMTI\u663e\u8457\u6539\u53d8\u4e86GPT-2\u548cLLaMA-2/7B\u7684\u4e0b\u4e00\u4e2a\u4ee4\u724c\u5206\u5e03\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u7834\u574f\u4e86\u68c0\u7d22\u589e\u5f3a\u548c\u4ee3\u7406\u63a8\u7406\u7ba1\u9053\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\u7f13\u5b58\u5b8c\u6574\u6027\u662f\u5f53\u524dLLM\u90e8\u7f72\u4e2d\u5173\u952e\u4f46\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u6f0f\u6d1e\uff0c\u5c06\u7f13\u5b58\u635f\u574f\u5b9a\u4f4d\u4e3a\u672a\u6765\u9c81\u68d2\u6027\u548c\u5b89\u5168\u7814\u7a76\u7684\u53ef\u590d\u73b0\u4e14\u7406\u8bba\u57fa\u7840\u7684\u5a01\u80c1\u6a21\u578b\u3002"}}
{"id": "2510.16996", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16996", "abs": "https://arxiv.org/abs/2510.16996", "authors": ["Juncheng Dong", "Yang Yang", "Tao Liu", "Yang Wang", "Feng Qi", "Vahid Tarokh", "Kaushik Rangadurai", "Shuang Yang"], "title": "STARK: Strategic Team of Agents for Refining Kernels", "comment": null, "summary": "The efficiency of GPU kernels is central to the progress of modern AI, yet\noptimizing them remains a difficult and labor-intensive task due to complex\ninteractions between memory hierarchies, thread scheduling, and\nhardware-specific characteristics. While recent advances in large language\nmodels (LLMs) provide new opportunities for automated code generation, existing\napproaches largely treat LLMs as single-shot generators or naive refinement\ntools, limiting their effectiveness in navigating the irregular kernel\noptimization landscape. We introduce an LLM agentic framework for GPU kernel\noptimization that systematically explores the design space through multi-agent\ncollaboration, grounded instruction, dynamic context management, and strategic\nsearch. This framework mimics the workflow of expert engineers, enabling LLMs\nto reason about hardware trade-offs, incorporate profiling feedback, and refine\nkernels iteratively. We evaluate our approach on KernelBench, a benchmark for\nLLM-based kernel optimization, and demonstrate substantial improvements over\nbaseline agents: our system produces correct solutions where baselines often\nfail, and achieves kernels with up to 16x faster runtime performance. These\nresults highlight the potential of agentic LLM frameworks to advance fully\nautomated, scalable GPU kernel optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316GPU\u5185\u6838\u4f18\u5316\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5185\u6838\u6027\u80fd\u3002", "motivation": "GPU\u5185\u6838\u4f18\u5316\u5bf9AI\u8fdb\u6b65\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5185\u5b58\u5c42\u6b21\u3001\u7ebf\u7a0b\u8c03\u5ea6\u548c\u786c\u4ef6\u7279\u6027\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u3002\u4f20\u7edfLLM\u65b9\u6cd5\u4f5c\u4e3a\u5355\u6b21\u751f\u6210\u5668\u6216\u7b80\u5355\u4f18\u5316\u5de5\u5177\u6548\u679c\u6709\u9650\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u5305\u542b\u57fa\u4e8e\u7ecf\u9a8c\u7684\u6307\u4ee4\u3001\u52a8\u6001\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u7b56\u7565\u641c\u7d22\uff0c\u6a21\u62df\u4e13\u5bb6\u5de5\u7a0b\u5e08\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8ba9LLM\u80fd\u591f\u63a8\u7406\u786c\u4ef6\u6743\u8861\u3001\u6574\u5408\u6027\u80fd\u5206\u6790\u53cd\u9988\u5e76\u8fed\u4ee3\u4f18\u5316\u5185\u6838\u3002", "result": "\u5728KernelBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u7cfb\u7edf\u5728\u57fa\u7ebf\u7ecf\u5e38\u5931\u8d25\u7684\u60c5\u51b5\u4e0b\u80fd\u4ea7\u751f\u6b63\u786e\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u8fbe16\u500d\u7684\u8fd0\u884c\u65f6\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u667a\u80fd\u4f53LLM\u6846\u67b6\u5728\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684GPU\u5185\u6838\u4f18\u5316\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2510.17175", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17175", "abs": "https://arxiv.org/abs/2510.17175", "authors": ["Muhammad Wahid Akram", "Keshav Sood", "Muneeb Ul Hassan"], "title": "QR\u00efS: A Preemptive Novel Method for Quishing Detection Through Structural Features of QR", "comment": "13 pages, 11 figures, and 7 tables", "summary": "Globally, individuals and organizations employ Quick Response (QR) codes for\nswift and convenient communication. Leveraging this, cybercriminals embed\nfalsify and misleading information in QR codes to launch various phishing\nattacks which termed as Quishing. Many former studies have introduced defensive\napproaches to preclude Quishing such as by classifying the embedded content of\nQR codes and then label the QR codes accordingly, whereas other studies\nclassify them using visual features (i.e., deep features, histogram density\nanalysis features). However, these approaches mainly rely on black-box\ntechniques which do not clearly provide interpretability and transparency to\nfully comprehend and reproduce the intrinsic decision process; therefore,\nhaving certain obvious limitations includes the approaches' trust,\naccountability, issues in bias detection, and many more. We proposed QR\\\"iS,\nthe pioneer method to classify QR codes through the comprehensive structural\nanalysis of a QR code which helps to identify phishing QR codes beforehand. Our\nclassification method is clearly transparent which makes it reproducible,\nscalable, and easy to comprehend. First, we generated QR codes dataset (i.e.\n400,000 samples) using recently published URLs datasets [1], [2]. Then, unlike\nblack-box models, we developed a simple algorithm to extract 24 structural\nfeatures from layout patterns present in QR codes. Later, we train the machine\nlearning models on the harvested features and obtained accuracy of up to\n83.18%. To further evaluate the effectiveness of our approach, we perform the\ncomparative analysis of proposed method with relevant contemporary studies.\nLastly, for real-world deployment and validation, we developed a mobile app\nwhich assures the feasibility of the proposed solution in real-world scenarios\nwhich eventually strengthen the applicability of the study.", "AI": {"tldr": "\u63d0\u51fa\u4e86QR\"iS\u65b9\u6cd5\uff0c\u901a\u8fc7QR\u7801\u7684\u7ed3\u6784\u5206\u6790\u6765\u8bc6\u522b\u9493\u9c7c\u653b\u51fb\uff0c\u4f7f\u752824\u4e2a\u7ed3\u6784\u7279\u5f81\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u51c6\u786e\u7387\u8fbe83.18%\uff0c\u5e76\u5f00\u53d1\u4e86\u79fb\u52a8\u5e94\u7528\u9a8c\u8bc1\u5b9e\u7528\u6027\u3002", "motivation": "\u73b0\u6709QR\u7801\u9632\u9493\u9c7c\u65b9\u6cd5\u4f9d\u8d56\u9ed1\u76d2\u6280\u672f\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\uff0c\u5b58\u5728\u4fe1\u4efb\u3001\u95ee\u8d23\u548c\u504f\u89c1\u68c0\u6d4b\u7b49\u95ee\u9898\u3002", "method": "\u751f\u621040\u4e07\u4e2aQR\u7801\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u7b97\u6cd5\u63d0\u53d624\u4e2a\u7ed3\u6784\u7279\u5f81\uff0c\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u6a21\u578b\u51c6\u786e\u7387\u6700\u9ad8\u8fbe83.18%\uff0c\u5f00\u53d1\u4e86\u79fb\u52a8\u5e94\u7528\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002", "conclusion": "QR\"iS\u662f\u9996\u4e2a\u901a\u8fc7QR\u7801\u7ed3\u6784\u5206\u6790\u5206\u7c7b\u7684\u65b9\u6cd5\uff0c\u5177\u6709\u900f\u660e\u3001\u53ef\u590d\u73b0\u3001\u53ef\u6269\u5c55\u548c\u6613\u7406\u89e3\u7684\u4f18\u52bf\u3002"}}
{"id": "2510.17052", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17052", "abs": "https://arxiv.org/abs/2510.17052", "authors": ["Hassan Hamad", "Yingru Xu", "Liang Zhao", "Wenbo Yan", "Narendra Gyanchandani"], "title": "ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems", "comment": null, "summary": "Tool-augmented large language models (LLMs) are increasingly employed in\nreal-world applications, but tool usage errors still hinder their reliability.\nWe introduce ToolCritic, a diagnostic framework that evaluates and improves LLM\nbehavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight\ndistinct error types specific to tool-calling (e.g., premature invocation,\nargument misalignment, and misinterpretation of tool outputs) and provides\ntargeted feedback to the main LLM. The main LLM, assumed to have strong\nreasoning, task understanding and orchestration capabilities, then revises its\nresponse based on ToolCritic's feedback. We systematically define these error\ncategories and construct a synthetic dataset to train ToolCritic. Experimental\nresults on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic\nimproves tool-calling accuracy by up to 13% over baselines, including zero-shot\nprompting and self-correction techniques. This represents a promising step\ntoward more robust LLM integration with external tools in real-world dialogue\napplications.", "AI": {"tldr": "ToolCritic\u662f\u4e00\u4e2a\u8bca\u65ad\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u589e\u5f3a\u5de5\u5177\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u884c\u4e3a\uff0c\u901a\u8fc7\u68c0\u6d4b8\u79cd\u7279\u5b9a\u5de5\u5177\u8c03\u7528\u9519\u8bef\u5e76\u63d0\u4f9b\u9488\u5bf9\u6027\u53cd\u9988\uff0c\u53ef\u5c06\u5de5\u5177\u8c03\u7528\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe13%\u3002", "motivation": "\u5de5\u5177\u589e\u5f3a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u5de5\u5177\u4f7f\u7528\u9519\u8bef\u4ecd\u7136\u963b\u788d\u5176\u53ef\u9760\u6027\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u9519\u8bef\u68c0\u6d4b\u548c\u6539\u8fdb\u673a\u5236\u3002", "method": "\u5b9a\u4e498\u79cd\u5de5\u5177\u8c03\u7528\u9519\u8bef\u7c7b\u522b\uff0c\u6784\u5efa\u5408\u6210\u6570\u636e\u96c6\u8bad\u7ec3ToolCritic\uff0c\u8ba9\u4e3bLLM\u57fa\u4e8eToolCritic\u7684\u53cd\u9988\u4fee\u6b63\u54cd\u5e94\u3002", "result": "\u5728Schema-Guided Dialogue\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cToolCritic\u76f8\u6bd4\u96f6\u6837\u672c\u63d0\u793a\u548c\u81ea\u6821\u6b63\u6280\u672f\uff0c\u5c06\u5de5\u5177\u8c03\u7528\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe13%\u3002", "conclusion": "ToolCritic\u662f\u5411\u66f4\u7a33\u5065\u7684LLM\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\u5728\u73b0\u5b9e\u5bf9\u8bdd\u5e94\u7528\u4e2d\u8fc8\u51fa\u7684\u6709\u5e0c\u671b\u7684\u4e00\u6b65\u3002"}}
{"id": "2510.17220", "categories": ["cs.CR", "cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.17220", "abs": "https://arxiv.org/abs/2510.17220", "authors": ["Giulia Giusti"], "title": "Exploiting the Potential of Linearity in Automatic Differentiation and Computational Cryptography", "comment": null, "summary": "The concept of linearity plays a central role in both mathematics and\ncomputer science, with distinct yet complementary meanings. In mathematics,\nlinearity underpins functions and vector spaces, forming the foundation of\nlinear algebra and functional analysis. In computer science, it relates to\nresource-sensitive computation. Linear Logic (LL), for instance, models\nassumptions that must be used exactly once, providing a natural framework for\ntracking computational resources such as time, memory, or data access. This\ndual perspective makes linearity essential to programming languages, type\nsystems, and formal models that express both computational complexity and\ncomposability. Bridging these interpretations enables rigorous yet practical\nmethodologies for analyzing and verifying complex systems.\n  This thesis explores the use of LL to model programming paradigms based on\nlinearity. It comprises two parts: ADLL and CryptoBLL. The former applies LL to\nAutomatic Differentiation (AD), modeling linear functions over the reals and\nthe transposition operation. The latter uses LL to express complexity\nconstraints on adversaries in computational cryptography.\n  In AD, two main approaches use linear type systems: a theoretical one\ngrounded in proof theory, and a practical one implemented in JAX, a Python\nlibrary developed by Google for machine learning research. In contrast,\nframeworks like PyTorch and TensorFlow support AD without linear types. ADLL\naims to bridge theory and practice by connecting JAX's type system to LL.\n  In modern cryptography, several calculi aim to model cryptographic proofs\nwithin the computational paradigm. These efforts face a trade-off between\nexpressiveness, to capture reductions, and simplicity, to abstract probability\nand complexity. CryptoBLL addresses this tension by proposing a framework for\nthe automatic analysis of protocols in computational cryptography.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u7ebf\u6027\u903b\u8f91\u5728\u7f16\u7a0b\u8303\u5f0f\u4e2d\u7684\u5e94\u7528\uff0c\u4e3b\u8981\u5305\u62ecADLL\u548cCryptoBLL\u4e24\u90e8\u5206\u3002ADLL\u5c06\u7ebf\u6027\u903b\u8f91\u5e94\u7528\u4e8e\u81ea\u52a8\u5fae\u5206\uff0cCryptoBLL\u7528\u4e8e\u8868\u8fbe\u8ba1\u7b97\u5bc6\u7801\u5b66\u4e2d\u7684\u590d\u6742\u6027\u7ea6\u675f\u3002", "motivation": "\u7ebf\u6027\u6982\u5ff5\u5728\u6570\u5b66\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u5177\u6709\u91cd\u8981\u5730\u4f4d\uff0c\u6570\u5b66\u4e2d\u652f\u6491\u51fd\u6570\u548c\u5411\u91cf\u7a7a\u95f4\uff0c\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u4e0e\u8d44\u6e90\u654f\u611f\u8ba1\u7b97\u76f8\u5173\u3002\u7ebf\u6027\u903b\u8f91\u80fd\u591f\u7cbe\u786e\u5efa\u6a21\u8ba1\u7b97\u8d44\u6e90\u7684\u4f7f\u7528\uff0c\u4e3a\u7f16\u7a0b\u8bed\u8a00\u3001\u7c7b\u578b\u7cfb\u7edf\u548c\u5f62\u5f0f\u6a21\u578b\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u8bba\u6587\u91c7\u7528\u7ebf\u6027\u903b\u8f91\uff08LL\uff09\u4f5c\u4e3a\u6838\u5fc3\u5de5\u5177\uff1a1\uff09ADLL\u90e8\u5206\u5c06\u7ebf\u6027\u903b\u8f91\u5e94\u7528\u4e8e\u81ea\u52a8\u5fae\u5206\uff0c\u5efa\u6a21\u5b9e\u6570\u4e0a\u7684\u7ebf\u6027\u51fd\u6570\u548c\u8f6c\u7f6e\u64cd\u4f5c\uff1b2\uff09CryptoBLL\u90e8\u5206\u4f7f\u7528\u7ebf\u6027\u903b\u8f91\u8868\u8fbe\u8ba1\u7b97\u5bc6\u7801\u5b66\u4e2d\u5bf9\u624b\u7684\u590d\u6742\u6027\u7ea6\u675f\u3002", "result": "ADLL\u8fde\u63a5\u4e86JAX\u7684\u7c7b\u578b\u7cfb\u7edf\u4e0e\u7ebf\u6027\u903b\u8f91\u7406\u8bba\uff0c\u5f25\u5408\u4e86\u81ea\u52a8\u5fae\u5206\u7406\u8bba\uff08\u57fa\u4e8e\u8bc1\u660e\u8bba\uff09\u4e0e\u5b9e\u8df5\uff08\u5982JAX\u5b9e\u73b0\uff09\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002CryptoBLL\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u81ea\u52a8\u5206\u6790\u8ba1\u7b97\u5bc6\u7801\u5b66\u534f\u8bae\u7684\u65b0\u6846\u67b6\u3002", "conclusion": "\u7ebf\u6027\u903b\u8f91\u4e3a\u5efa\u6a21\u7f16\u7a0b\u8303\u5f0f\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u7406\u8bba\u57fa\u7840\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u8ba1\u7b97\u590d\u6742\u6027\u548c\u53ef\u7ec4\u5408\u6027\u3002\u8be5\u7814\u7a76\u4e3a\u5206\u6790\u548c\u9a8c\u8bc1\u590d\u6742\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e25\u8c28\u800c\u5b9e\u7528\u7684\u65b9\u6cd5\u5b66\uff0c\u5728\u81ea\u52a8\u5fae\u5206\u548c\u5bc6\u7801\u5b66\u9886\u57df\u5c55\u793a\u4e86\u7ebf\u6027\u903b\u8f91\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.17064", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17064", "abs": "https://arxiv.org/abs/2510.17064", "authors": ["Rongbin Li", "Wenbo Chen", "Zhao Li", "Rodrigo Munoz-Castaneda", "Jinbo Li", "Neha S. Maurya", "Arnav Solanki", "Huan He", "Hanwen Xing", "Meaghan Ramlakhan", "Zachary Wise", "Zhuhao Wu", "Hua Xu", "Michael Hawrylycz", "W. Jim Zheng"], "title": "A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation", "comment": "22 pages, 6 figures, 2 tables", "summary": "Single-cell RNA sequencing has transformed our ability to identify diverse\ncell types and their transcriptomic signatures. However, annotating these\nsignatures-especially those involving poorly characterized genes-remains a\nmajor challenge. Traditional methods, such as Gene Set Enrichment Analysis\n(GSEA), depend on well-curated annotations and often perform poorly in these\ncontexts. Large Language Models (LLMs) offer a promising alternative but\nstruggle to represent complex biological knowledge within structured\nontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID:\nhttps://biodataai.uth.edu/BRAINCELL-AID), a novel multi-agent AI system that\nintegrates free-text descriptions with ontology labels to enable more accurate\nand robust gene set annotation. By incorporating retrieval-augmented generation\n(RAG), we developed a robust agentic workflow that refines predictions using\nrelevant PubMed literature, reducing hallucinations and enhancing\ninterpretability. Using this workflow, we achieved correct annotations for 77%\nof mouse gene sets among their top predictions. Applying this approach, we\nannotated 5,322 brain cell clusters from the comprehensive mouse brain cell\natlas generated by the BRAIN Initiative Cell Census Network, enabling novel\ninsights into brain cell function by identifying region-specific gene\nco-expression patterns and inferring functional roles of gene ensembles.\nBRAINCELL-AID also identifies Basal Ganglia-related cell types with\nneurologically meaningful descriptions. Hence, we create a valuable resource to\nsupport community-driven cell type annotation.", "AI": {"tldr": "BRAINCELL-AID\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u81ea\u7531\u6587\u672c\u63cf\u8ff0\u548c\u672c\u4f53\u6807\u7b7e\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u56e0\u96c6\u6ce8\u91ca\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u6280\u672f\u867d\u7136\u80fd\u8bc6\u522b\u591a\u6837\u7ec6\u80de\u7c7b\u578b\uff0c\u4f46\u5bf9\u6d89\u53ca\u7279\u5f81\u4e0d\u660e\u786e\u57fa\u56e0\u7684\u8f6c\u5f55\u7ec4\u7279\u5f81\u8fdb\u884c\u6ce8\u91ca\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u4f20\u7edf\u65b9\u6cd5\u5982GSEA\u4f9d\u8d56\u7cbe\u5fc3\u7b56\u5212\u7684\u6ce8\u91ca\uff0c\u5728\u8fd9\u4e9b\u60c5\u5883\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5f00\u53d1\u4e86BRAINCELL-AID\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\uff0c\u6574\u5408\u81ea\u7531\u6587\u672c\u63cf\u8ff0\u4e0e\u672c\u4f53\u6807\u7b7e\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6280\u672f\u6784\u5efa\u7a33\u5065\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u5229\u7528\u76f8\u5173PubMed\u6587\u732e\u7cbe\u70bc\u9884\u6d4b\u3002", "result": "\u5728\u9f20\u7c7b\u57fa\u56e0\u96c6\u6ce8\u91ca\u4e2d\uff0c77%\u7684\u57fa\u56e0\u96c6\u5728\u5176\u524d\u51e0\u4f4d\u9884\u6d4b\u4e2d\u83b7\u5f97\u4e86\u6b63\u786e\u6ce8\u91ca\u3002\u5e94\u7528\u8be5\u65b9\u6cd5\u6ce8\u91ca\u4e86BRAIN Initiative Cell Census Network\u751f\u6210\u76845,322\u4e2a\u8111\u7ec6\u80de\u7c07\uff0c\u8bc6\u522b\u4e86\u533a\u57df\u7279\u5f02\u6027\u57fa\u56e0\u5171\u8868\u8fbe\u6a21\u5f0f\uff0c\u5e76\u63a8\u65ad\u57fa\u56e0\u96c6\u5408\u7684\u529f\u80fd\u89d2\u8272\u3002", "conclusion": "BRAINCELL-AID\u521b\u5efa\u4e86\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u8d44\u6e90\u6765\u652f\u6301\u793e\u533a\u9a71\u52a8\u7684\u7ec6\u80de\u7c7b\u578b\u6ce8\u91ca\uff0c\u80fd\u591f\u8bc6\u522b\u5177\u6709\u795e\u7ecf\u5b66\u610f\u4e49\u63cf\u8ff0\u7684\u57fa\u5e95\u795e\u7ecf\u8282\u76f8\u5173\u7ec6\u80de\u7c7b\u578b\u3002"}}
{"id": "2510.17277", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17277", "abs": "https://arxiv.org/abs/2510.17277", "authors": ["Xinkai Wang", "Beibei Li", "Zerui Shao", "Ao Liu", "Shouling Ji"], "title": "Multimodal Safety Is Asymmetric: Cross-Modal Exploits Unlock Black-Box MLLMs Jailbreaks", "comment": null, "summary": "Multimodal large language models (MLLMs) have demonstrated significant\nutility across diverse real-world applications. But MLLMs remain vulnerable to\njailbreaks, where adversarial inputs can collapse their safety constraints and\ntrigger unethical responses. In this work, we investigate jailbreaks in the\ntext-vision multimodal setting and pioneer the observation that visual\nalignment imposes uneven safety constraints across modalities in MLLMs, thereby\ngiving rise to multimodal safety asymmetry. We then develop PolyJailbreak, a\nblack-box jailbreak method grounded in reinforcement learning. Initially, we\nprobe the model's attention dynamics and latent representation space, assessing\nhow visual inputs reshape cross-modal information flow and diminish the model's\nability to separate harmful from benign inputs, thereby exposing exploitable\nvulnerabilities. On this basis, we systematize them into generalizable and\nreusable operational rules that constitute a structured library of Atomic\nStrategy Primitives, which translate harmful intents into jailbreak inputs\nthrough step-wise transformations. Guided by the primitives, PolyJailbreak\nemploys a multi-agent optimization process that automatically adapts inputs\nagainst the target models. We conduct comprehensive evaluations on a variety of\nopen-source and closed-source MLLMs, demonstrating that PolyJailbreak\noutperforms state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PolyJailbreak\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u6a21\u6001\u5b89\u5168\u4e0d\u5bf9\u79f0\u6027\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u81ea\u52a8\u751f\u6210\u5bf9\u6297\u6027\u8f93\u5165\u6765\u7ed5\u8fc7\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u7ea6\u675f\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\uff0c\u5bfc\u81f4\u6a21\u578b\u4ea7\u751f\u4e0d\u9053\u5fb7\u54cd\u5e94\u3002\u7814\u7a76\u53d1\u73b0\u89c6\u89c9\u5bf9\u9f50\u5728\u4e0d\u540c\u6a21\u6001\u95f4\u65bd\u52a0\u4e86\u4e0d\u5747\u5300\u7684\u5b89\u5168\u7ea6\u675f\uff0c\u5f62\u6210\u4e86\u591a\u6a21\u6001\u5b89\u5168\u4e0d\u5bf9\u79f0\u6027\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u9ed1\u76d2\u8d8a\u72f1\u65b9\u6cd5PolyJailbreak\uff1a\u9996\u5148\u63a2\u6d4b\u6a21\u578b\u7684\u6ce8\u610f\u529b\u52a8\u6001\u548c\u6f5c\u5728\u8868\u793a\u7a7a\u95f4\uff0c\u5206\u6790\u89c6\u89c9\u8f93\u5165\u5982\u4f55\u91cd\u5851\u8de8\u6a21\u6001\u4fe1\u606f\u6d41\uff1b\u7136\u540e\u7cfb\u7edf\u5316\u4e3a\u53ef\u91cd\u7528\u7684\u539f\u5b50\u7b56\u7565\u539f\u8bed\u5e93\uff1b\u6700\u540e\u91c7\u7528\u591a\u4ee3\u7406\u4f18\u5316\u8fc7\u7a0b\u81ea\u52a8\u8c03\u6574\u8f93\u5165\u5bf9\u6297\u76ee\u6807\u6a21\u578b\u3002", "result": "\u5728\u591a\u79cd\u5f00\u6e90\u548c\u95ed\u6e90MLLMs\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u8bc1\u660ePolyJailbreak\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "PolyJailbreak\u65b9\u6cd5\u6709\u6548\u5229\u7528\u4e86\u591a\u6a21\u6001\u5b89\u5168\u4e0d\u5bf9\u79f0\u6027\uff0c\u80fd\u591f\u6210\u529f\u7ed5\u8fc7MLLMs\u7684\u5b89\u5168\u7ea6\u675f\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u591a\u6a21\u6001\u6a21\u578b\u5728\u5b89\u5168\u9632\u62a4\u65b9\u9762\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2510.17108", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17108", "abs": "https://arxiv.org/abs/2510.17108", "authors": ["Yoonjin Lee", "Munhee Kim", "Hanbi Choi", "Juhyeon Park", "Seungho Lyoo", "Woojin Park"], "title": "Structured Debate Improves Corporate Credit Reasoning in Financial AI", "comment": "18 pages, 4 figures, 2 algorithms, 2 tables, 4 appendices, will be\n  submitted to AAAI-2026 workshop", "summary": "Despite advances in financial AI, the automation of evidence-based reasoning\nremains unresolved in corporate credit assessment, where qualitative\nnon-financial indicators exert decisive influence on loan repayment outcomes\nyet resist formalization. Existing approaches focus predominantly on numerical\nprediction and provide limited support for the interpretive judgments required\nin professional loan evaluation. This study develops and evaluates two\noperational large language model (LLM)-based systems designed to generate\nstructured reasoning from non-financial evidence. The first is a\nnon-adversarial single-agent system (NAS) that produces bidirectional analysis\nthrough a single-pass reasoning pipeline. The second is a debate-based\nmulti-agent system (KPD-MADS) that operationalizes adversarial verification\nthrough a ten-step structured interaction protocol grounded in Karl Popper's\ncritical dialogue framework. Both systems were applied to three real corporate\ncases and evaluated by experienced credit risk professionals. Compared to\nmanual expert reporting, both systems achieved substantial productivity gains\n(NAS: 11.55 s per case; KPD-MADS: 91.97 s; human baseline: 1920 s). The\nKPD-MADS demonstrated superior reasoning quality, receiving higher median\nratings in explanatory adequacy (4.0 vs. 3.0), practical applicability (4.0 vs.\n3.0), and usability (62.5 vs. 52.5). These findings show that structured\nmulti-agent interaction can enhance reasoning rigor and interpretability in\nfinancial AI, advancing scalable and defensible automation in corporate credit\nassessment.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e24\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\u7528\u4e8e\u4f01\u4e1a\u4fe1\u7528\u8bc4\u4f30\u4e2d\u7684\u8bc1\u636e\u63a8\u7406\uff1a\u5355\u4ee3\u7406\u7cfb\u7edf(NAS)\u548c\u57fa\u4e8e\u8fa9\u8bba\u7684\u591a\u4ee3\u7406\u7cfb\u7edf(KPD-MADS)\uff0c\u540e\u8005\u5728\u63a8\u7406\u8d28\u91cf\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u89e3\u51b3\u4f01\u4e1a\u4fe1\u7528\u8bc4\u4f30\u4e2d\u5b9a\u6027\u975e\u8d22\u52a1\u6307\u6807\u7684\u81ea\u52a8\u5316\u63a8\u7406\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6570\u503c\u9884\u6d4b\uff0c\u7f3a\u4e4f\u5bf9\u4e13\u4e1a\u8d37\u6b3e\u8bc4\u4f30\u6240\u9700\u7684\u89e3\u91ca\u6027\u5224\u65ad\u652f\u6301\u3002", "method": "\u5f00\u53d1\u4e86\u4e24\u79cdLLM\u7cfb\u7edf\uff1a\u5355\u4ee3\u7406\u7cfb\u7edf(NAS)\u901a\u8fc7\u5355\u6b21\u63a8\u7406\u7ba1\u9053\u4ea7\u751f\u53cc\u5411\u5206\u6790\uff1b\u591a\u4ee3\u7406\u7cfb\u7edf(KPD-MADS)\u57fa\u4e8e\u5361\u5c14\u00b7\u6ce2\u666e\u6279\u5224\u5bf9\u8bdd\u6846\u67b6\uff0c\u91c7\u7528\u5341\u6b65\u7ed3\u6784\u5316\u4ea4\u4e92\u534f\u8bae\u8fdb\u884c\u5bf9\u6297\u6027\u9a8c\u8bc1\u3002", "result": "\u4e24\u4e2a\u7cfb\u7edf\u90fd\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u751f\u4ea7\u529b\u63d0\u5347(NAS:11.55\u79d2/\u6848\u4f8b\uff1bKPD-MADS:91.97\u79d2\uff1b\u4eba\u5de5\u57fa\u7ebf:1920\u79d2)\u3002KPD-MADS\u5728\u89e3\u91ca\u5145\u5206\u6027(4.0 vs 3.0)\u3001\u5b9e\u9645\u9002\u7528\u6027(4.0 vs 3.0)\u548c\u53ef\u7528\u6027(62.5 vs 52.5)\u65b9\u9762\u83b7\u5f97\u66f4\u9ad8\u8bc4\u5206\u3002", "conclusion": "\u7ed3\u6784\u5316\u591a\u4ee3\u7406\u4ea4\u4e92\u53ef\u4ee5\u589e\u5f3a\u91d1\u878dAI\u4e2d\u7684\u63a8\u7406\u4e25\u8c28\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u63a8\u52a8\u4f01\u4e1a\u4fe1\u7528\u8bc4\u4f30\u7684\u53ef\u6269\u5c55\u548c\u53ef\u8fa9\u62a4\u81ea\u52a8\u5316\u3002"}}
{"id": "2510.17284", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17284", "abs": "https://arxiv.org/abs/2510.17284", "authors": ["Jiri Gavenda", "Petr Svenda", "Stanislav Bobon", "Vladimir Sedlacek"], "title": "Analysis of Input-Output Mappings in Coinjoin Transactions with Arbitrary Values", "comment": null, "summary": "A coinjoin protocol aims to increase transactional privacy for Bitcoin and\nBitcoin-like blockchains via collaborative transactions, by violating\nassumptions behind common analysis heuristics. Estimating the resulting privacy\ngain is a crucial yet unsolved problem due to a range of influencing factors\nand large computational complexity.\n  We adapt the BlockSci on-chain analysis software to coinjoin transactions,\ndemonstrating a significant (10-50%) average post-mix anonymity set size\ndecrease for all three major designs with a central coordinator: Whirlpool,\nWasabi 1.x, and Wasabi 2.x. The decrease is highest during the first day and\nnegligible after one year from a coinjoin creation.\n  Moreover, we design a precise, parallelizable privacy estimation method,\nwhich takes into account coinjoin fees, implementation-specific limitations and\nusers' post-mix behavior. We evaluate our method in detail on a set of emulated\nand real-world Wasabi 2.x coinjoins and extrapolate to its largest real-world\ncoinjoins with hundreds of inputs and outputs. We conclude that despite the\nusers' undesirable post-mix behavior, correctly attributing the coins to their\nowners is still very difficult, even with our improved analysis algorithm.", "AI": {"tldr": "CoinJoin\u534f\u8bae\u901a\u8fc7\u534f\u4f5c\u4ea4\u6613\u589e\u5f3a\u6bd4\u7279\u5e01\u9690\u79c1\uff0c\u4f46\u9690\u79c1\u589e\u76ca\u96be\u4ee5\u91cf\u5316\u3002\u7814\u7a76\u53d1\u73b0\u4e3b\u8981CoinJoin\u8bbe\u8ba1\uff08Whirlpool\u3001Wasabi 1.x/2.x\uff09\u7684\u5e73\u5747\u533f\u540d\u96c6\u5927\u5c0f\u51cf\u5c1110-50%\uff0c\u5e76\u5728\u4e00\u5e74\u540e\u8d8b\u4e8e\u7a33\u5b9a\u3002\u5f00\u53d1\u4e86\u8003\u8651\u8d39\u7528\u3001\u5b9e\u73b0\u9650\u5236\u548c\u7528\u6237\u884c\u4e3a\u7684\u7cbe\u786e\u9690\u79c1\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8bc1\u660e\u5373\u4f7f\u4f7f\u7528\u6539\u8fdb\u7684\u5206\u6790\u7b97\u6cd5\uff0c\u6b63\u786e\u8ffd\u8e2a\u786c\u5e01\u5f52\u5c5e\u4ecd\u975e\u5e38\u56f0\u96be\u3002", "motivation": "CoinJoin\u534f\u8bae\u65e8\u5728\u901a\u8fc7\u8fdd\u53cd\u5e38\u89c1\u5206\u6790\u542f\u53d1\u5f0f\u5047\u8bbe\u6765\u589e\u5f3a\u6bd4\u7279\u5e01\u4ea4\u6613\u9690\u79c1\uff0c\u4f46\u7531\u4e8e\u591a\u79cd\u5f71\u54cd\u56e0\u7d20\u548c\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u91cf\u5316\u5176\u9690\u79c1\u589e\u76ca\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "1. \u8c03\u6574BlockSci\u94fe\u4e0a\u5206\u6790\u8f6f\u4ef6\u4ee5\u5206\u6790CoinJoin\u4ea4\u6613\n2. \u8bbe\u8ba1\u8003\u8651CoinJoin\u8d39\u7528\u3001\u5b9e\u73b0\u7279\u5b9a\u9650\u5236\u548c\u7528\u6237\u6df7\u5408\u540e\u884c\u4e3a\u7684\u7cbe\u786e\u5e76\u884c\u9690\u79c1\u8bc4\u4f30\u65b9\u6cd5\n3. \u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754cWasabi 2.x CoinJoin\u4e0a\u8fdb\u884c\u8be6\u7ec6\u8bc4\u4f30\uff0c\u5e76\u5916\u63a8\u5230\u6700\u5927\u89c4\u6a21\u7684\u771f\u5b9e\u4e16\u754cCoinJoin", "result": "1. \u4e09\u79cd\u4e3b\u8981CoinJoin\u8bbe\u8ba1\uff08Whirlpool\u3001Wasabi 1.x\u3001Wasabi 2.x\uff09\u7684\u5e73\u5747\u6df7\u5408\u540e\u533f\u540d\u96c6\u5927\u5c0f\u51cf\u5c1110-50%\n2. \u51cf\u5c11\u5e45\u5ea6\u5728\u7b2c\u4e00\u5929\u6700\u9ad8\uff0c\u4e00\u5e74\u540e\u53d8\u5f97\u53ef\u5ffd\u7565\u4e0d\u8ba1\n3. \u5373\u4f7f\u8003\u8651\u7528\u6237\u4e0d\u7406\u60f3\u7684\u6df7\u5408\u540e\u884c\u4e3a\uff0c\u4f7f\u7528\u6539\u8fdb\u7684\u5206\u6790\u7b97\u6cd5\u6b63\u786e\u5f52\u5c5e\u786c\u5e01\u4ecd\u975e\u5e38\u56f0\u96be", "conclusion": "\u5c3d\u7ba1\u7528\u6237\u6df7\u5408\u540e\u884c\u4e3a\u4e0d\u7406\u60f3\uff0c\u4f46\u901a\u8fc7CoinJoin\u534f\u8bae\u6b63\u786e\u8ffd\u8e2a\u786c\u5e01\u5f52\u5c5e\u4ecd\u7136\u6781\u5176\u56f0\u96be\uff0c\u5373\u4f7f\u4f7f\u7528\u6539\u8fdb\u7684\u5206\u6790\u7b97\u6cd5\u3002CoinJoin\u5728\u589e\u5f3a\u6bd4\u7279\u5e01\u4ea4\u6613\u9690\u79c1\u65b9\u9762\u4ecd\u7136\u6709\u6548\u3002"}}
{"id": "2510.17145", "categories": ["cs.AI", "68T05, 62H30"], "pdf": "https://arxiv.org/pdf/2510.17145", "abs": "https://arxiv.org/abs/2510.17145", "authors": ["Phi-Hung Hoang", "Nam-Thuan Trinh", "Van-Manh Tran", "Thi-Thu-Hong Phan"], "title": "Enhanced Fish Freshness Classification with Incremental Handcrafted Feature Fusion", "comment": "35 pages, 6 figures and 11 tables", "summary": "Accurate assessment of fish freshness remains a major challenge in the food\nindustry, with direct consequences for product quality, market value, and\nconsumer health. Conventional sensory evaluation is inherently subjective,\ninconsistent, and difficult to standardize across contexts, often limited by\nsubtle, species-dependent spoilage cues. To address these limitations, we\npropose a handcrafted feature-based approach that systematically extracts and\nincrementally fuses complementary descriptors, including color statistics,\nhistograms across multiple color spaces, and texture features such as Local\nBinary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish\neye images. Our method captures global chromatic variations from full images\nand localized degradations from ROI segments, fusing each independently to\nevaluate their effectiveness in assessing freshness. Experiments on the\nFreshness of the Fish Eyes (FFE) dataset demonstrate the approach's\neffectiveness: in a standard train-test setting, a LightGBM classifier achieved\n77.56% accuracy, a 14.35% improvement over the previous deep learning baseline\nof 63.21%. With augmented data, an Artificial Neural Network (ANN) reached\n97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results\ndemonstrate that carefully engineered, handcrafted features, when strategically\nprocessed, yield a robust, interpretable, and reliable solution for automated\nfish freshness assessment, providing valuable insights for practical\napplications in food quality monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u624b\u5de5\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u989c\u8272\u7edf\u8ba1\u3001\u591a\u8272\u5f69\u7a7a\u95f4\u76f4\u65b9\u56fe\u4ee5\u53ca\u7eb9\u7406\u7279\u5f81\u6765\u8bc4\u4f30\u9c7c\u7c7b\u65b0\u9c9c\u5ea6\uff0c\u5728FFE\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u611f\u5b98\u8bc4\u4f30\u9c7c\u7c7b\u65b0\u9c9c\u5ea6\u5b58\u5728\u4e3b\u89c2\u6027\u3001\u4e0d\u4e00\u81f4\u6027\u548c\u96be\u4ee5\u6807\u51c6\u5316\u7684\u95ee\u9898\uff0c\u9700\u8981\u5ba2\u89c2\u3001\u53ef\u9760\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4ece\u9c7c\u773c\u56fe\u50cf\u4e2d\u7cfb\u7edf\u63d0\u53d6\u548c\u589e\u91cf\u878d\u5408\u4e92\u8865\u63cf\u8ff0\u7b26\uff0c\u5305\u62ec\u989c\u8272\u7edf\u8ba1\u3001\u591a\u8272\u5f69\u7a7a\u95f4\u76f4\u65b9\u56fe\u4ee5\u53caLBP\u548cGLCM\u7eb9\u7406\u7279\u5f81\uff0c\u540c\u65f6\u6355\u83b7\u5168\u5c40\u8272\u5f69\u53d8\u5316\u548c\u5c40\u90e8\u9000\u5316\u7279\u5f81\u3002", "result": "\u5728\u6807\u51c6\u8bad\u7ec3-\u6d4b\u8bd5\u8bbe\u7f6e\u4e0b\uff0cLightGBM\u5206\u7c7b\u5668\u8fbe\u523077.56%\u51c6\u786e\u7387\uff0c\u6bd4\u4e4b\u524d\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u63d0\u534714.35%\uff1b\u4f7f\u7528\u589e\u5f3a\u6570\u636e\u65f6\uff0cANN\u8fbe\u523097.16%\u51c6\u786e\u7387\uff0c\u6bd4\u4e4b\u524d\u6700\u4f73\u7ed3\u679c\u63d0\u534719.86%\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u624b\u5de5\u7279\u5f81\u7ecf\u8fc7\u7b56\u7565\u6027\u5904\u7406\u540e\uff0c\u80fd\u591f\u4e3a\u81ea\u52a8\u5316\u9c7c\u7c7b\u65b0\u9c9c\u5ea6\u8bc4\u4f30\u63d0\u4f9b\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5bf9\u98df\u54c1\u8d28\u91cf\u76d1\u6d4b\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.17308", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17308", "abs": "https://arxiv.org/abs/2510.17308", "authors": ["Reo Eriguchi", "Kazumasa Shinagawa"], "title": "Single-Shuffle Full-Open Card-Based Protocols for Any Function", "comment": null, "summary": "A card-based secure computation protocol is a method for $n$ parties to\ncompute a function $f$ on their private inputs $(x_1,\\ldots,x_n)$ using\nphysical playing cards, in such a way that the suits of revealed cards leak no\ninformation beyond the value of $f(x_1,\\ldots,x_n)$. A \\textit{single-shuffle\nfull-open} protocol is a minimal model of card-based secure computation in\nwhich, after the parties place face-down cards representing their inputs, a\nsingle shuffle operation is performed and then all cards are opened to derive\nthe output. Despite the simplicity of this model, the class of functions known\nto admit single-shuffle full-open protocols has been limited to a few small\nexamples. In this work, we prove for the first time that every function admits\na single-shuffle full-open protocol. We present two constructions that offer a\ntrade-off between the number of cards and the complexity of the shuffle\noperation. These feasibility results are derived from a novel connection\nbetween single-shuffle full-open protocols and a cryptographic primitive known\nas \\textit{Private Simultaneous Messages} protocols, which has rarely been\nstudied in the context of card-based cryptography. We also present variants of\nsingle-shuffle protocols in which only a subset of cards are revealed. These\nprotocols reduce the complexity of the shuffle operation compared to existing\nprotocols in the same setting.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u8bc1\u660e\u4e86\u6240\u6709\u51fd\u6570\u90fd\u5b58\u5728\u5355\u6b21\u6d17\u724c\u5168\u516c\u5f00\u7684\u5361\u724c\u5b89\u5168\u8ba1\u7b97\u534f\u8bae\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u5728\u5361\u724c\u6570\u91cf\u548c\u6d17\u724c\u590d\u6742\u5ea6\u4e4b\u95f4\u6743\u8861\u7684\u6784\u9020\u65b9\u6cd5\u3002", "motivation": "\u5355\u6b21\u6d17\u724c\u5168\u516c\u5f00\u534f\u8bae\u662f\u5361\u724c\u5b89\u5168\u8ba1\u7b97\u7684\u6700\u5c0f\u6a21\u578b\uff0c\u4f46\u4e4b\u524d\u5df2\u77e5\u53ef\u5b9e\u73b0\u7684\u51fd\u6570\u7c7b\u4ec5\u9650\u4e8e\u5c11\u6570\u5c0f\u4f8b\u5b50\uff0c\u9650\u5236\u4e86\u8be5\u6a21\u578b\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u901a\u8fc7\u5efa\u7acb\u5355\u6b21\u6d17\u724c\u5168\u516c\u5f00\u534f\u8bae\u4e0e\u5bc6\u7801\u5b66\u539f\u8bed\"\u79c1\u6709\u540c\u65f6\u6d88\u606f\u534f\u8bae\"\u7684\u65b0\u8054\u7cfb\uff0c\u8bbe\u8ba1\u4e86\u4e24\u79cd\u6784\u9020\u65b9\u6cd5\uff0c\u5e76\u5728\u4ec5\u516c\u5f00\u90e8\u5206\u5361\u724c\u7684\u53d8\u4f53\u4e2d\u964d\u4f4e\u4e86\u6d17\u724c\u590d\u6742\u5ea6\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u6240\u6709\u51fd\u6570\u90fd\u5b58\u5728\u5355\u6b21\u6d17\u724c\u5168\u516c\u5f00\u534f\u8bae\uff0c\u5e76\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u534f\u8bae\u6784\u9020\uff0c\u5728\u5361\u724c\u6570\u91cf\u548c\u6d17\u724c\u590d\u6742\u5ea6\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6743\u8861\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6269\u5c55\u4e86\u5355\u6b21\u6d17\u724c\u5168\u516c\u5f00\u534f\u8bae\u7684\u5e94\u7528\u8303\u56f4\uff0c\u4e3a\u5361\u724c\u5b89\u5168\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u6784\u9020\u65b9\u6cd5\u3002"}}
{"id": "2510.17146", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.17146", "abs": "https://arxiv.org/abs/2510.17146", "authors": ["Subin Lin", "Chuanbo Hua"], "title": "Physics-Informed Large Language Models for HVAC Anomaly Detection with Autonomous Rule Generation", "comment": "NeurIPS 2025 Workshop of UrbanAI (Oral)", "summary": "Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a\nsubstantial share of global building energy use, making reliable anomaly\ndetection essential for improving efficiency and reducing emissions. Classical\nrule-based approaches offer explainability but lack adaptability, while deep\nlearning methods provide predictive power at the cost of transparency,\nefficiency, and physical plausibility. Recent attempts to use Large Language\nModels (LLMs) for anomaly detection improve interpretability but largely ignore\nthe physical principles that govern HVAC operations. We present PILLM, a\nPhysics-Informed LLM framework that operates within an evolutionary loop to\nautomatically generate, evaluate, and refine anomaly detection rules. Our\napproach introduces physics-informed reflection and crossover operators that\nembed thermodynamic and control-theoretic constraints, enabling rules that are\nboth adaptive and physically grounded. Experiments on the public Building Fault\nDetection dataset show that PILLM achieves state-of-the-art performance while\nproducing diagnostic rules that are interpretable and actionable, advancing\ntrustworthy and deployable AI for smart building systems.", "AI": {"tldr": "PILLM\u662f\u4e00\u4e2a\u57fa\u4e8e\u7269\u7406\u77e5\u8bc6\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u8fdb\u5316\u5faa\u73af\u81ea\u52a8\u751f\u6210\u3001\u8bc4\u4f30\u548c\u4f18\u5316HVAC\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u89c4\u5219\uff0c\u7ed3\u5408\u70ed\u529b\u5b66\u548c\u63a7\u5236\u7406\u8bba\u7ea6\u675f\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u4e14\u7269\u7406\u5408\u7406\u7684\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "HVAC\u7cfb\u7edf\u80fd\u8017\u5360\u5efa\u7b51\u80fd\u8017\u5f88\u5927\u6bd4\u4f8b\uff0c\u4f20\u7edf\u89c4\u5219\u65b9\u6cd5\u53ef\u89e3\u91ca\u4f46\u7f3a\u4e4f\u9002\u5e94\u6027\uff0c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u9884\u6d4b\u80fd\u529b\u5f3a\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u7269\u7406\u5408\u7406\u6027\u3002\u73b0\u6709LLM\u65b9\u6cd5\u6539\u5584\u4e86\u53ef\u89e3\u91ca\u6027\u4f46\u5ffd\u7565\u4e86HVAC\u8fd0\u884c\u7684\u7269\u7406\u539f\u7406\u3002", "method": "\u63d0\u51faPILLM\u6846\u67b6\uff0c\u5728\u8fdb\u5316\u5faa\u73af\u4e2d\u5d4c\u5165\u7269\u7406\u77e5\u8bc6\u53cd\u5c04\u548c\u4ea4\u53c9\u7b97\u5b50\uff0c\u7ed3\u5408\u70ed\u529b\u5b66\u548c\u63a7\u5236\u7406\u8bba\u7ea6\u675f\uff0c\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316\u5f02\u5e38\u68c0\u6d4b\u89c4\u5219\u3002", "result": "\u5728\u516c\u5171\u5efa\u7b51\u6545\u969c\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPILLM\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4ea7\u751f\u53ef\u89e3\u91ca\u548c\u53ef\u64cd\u4f5c\u7684\u8bca\u65ad\u89c4\u5219\u3002", "conclusion": "PILLM\u63a8\u8fdb\u4e86\u667a\u80fd\u5efa\u7b51\u7cfb\u7edf\u4e2d\u53ef\u4fe1\u8d56\u548c\u53ef\u90e8\u7f72AI\u7684\u53d1\u5c55\uff0c\u5b9e\u73b0\u4e86\u65e2\u9002\u5e94\u6027\u5f3a\u53c8\u7269\u7406\u57fa\u7840\u624e\u5b9e\u7684\u5f02\u5e38\u68c0\u6d4b\u3002"}}
{"id": "2510.17311", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17311", "abs": "https://arxiv.org/abs/2510.17311", "authors": ["Eduard Marin", "Jinwoo Kim", "Alessio Pavoni", "Mauro Conti", "Roberto Di Pietro"], "title": "The Hidden Dangers of Public Serverless Repositories: An Empirical Security Assessment", "comment": "Accepted at ESORICS 2025", "summary": "Serverless computing has rapidly emerged as a prominent cloud paradigm,\nenabling developers to focus solely on application logic without the burden of\nmanaging servers or underlying infrastructure. Public serverless repositories\nhave become key to accelerating the development of serverless applications.\nHowever, their growing popularity makes them attractive targets for\nadversaries. Despite this, the security posture of these repositories remains\nlargely unexplored, exposing developers and organizations to potential risks.\nIn this paper, we present the first comprehensive analysis of the security\nlandscape of serverless components hosted in public repositories. We analyse\n2,758 serverless components from five widely used public repositories popular\namong developers and enterprises, and 125,936 Infrastructure as Code (IaC)\ntemplates across three widely used IaC frameworks. Our analysis reveals\nsystemic vulnerabilities including outdated software packages, misuse of\nsensitive parameters, exploitable deployment configurations, susceptibility to\ntypo-squatting attacks and opportunities to embed malicious behaviour within\ncompressed serverless components. Finally, we provide practical recommendations\nto mitigate these threats.", "AI": {"tldr": "\u5bf95\u4e2a\u516c\u5171\u65e0\u670d\u52a1\u5668\u4ed3\u5e93\u548c3\u4e2aIaC\u6846\u67b6\u76842,758\u4e2a\u65e0\u670d\u52a1\u5668\u7ec4\u4ef6\u548c125,936\u4e2a\u6a21\u677f\u8fdb\u884c\u5b89\u5168\u5206\u6790\uff0c\u53d1\u73b0\u7cfb\u7edf\u6027\u6f0f\u6d1e\u5e76\u63d0\u51fa\u7f13\u89e3\u5efa\u8bae\u3002", "motivation": "\u516c\u5171\u65e0\u670d\u52a1\u5668\u4ed3\u5e93\u65e5\u76ca\u6d41\u884c\u4f46\u5b89\u5168\u72b6\u51b5\u672a\u88ab\u5145\u5206\u7814\u7a76\uff0c\u5f00\u53d1\u8005\u548c\u7ec4\u7ec7\u9762\u4e34\u6f5c\u5728\u98ce\u9669\u3002", "method": "\u5206\u67902,758\u4e2a\u65e0\u670d\u52a1\u5668\u7ec4\u4ef6\u548c125,936\u4e2a\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\u6a21\u677f\uff0c\u8bc6\u522b\u591a\u79cd\u5b89\u5168\u6f0f\u6d1e\u7c7b\u578b\u3002", "result": "\u53d1\u73b0\u8fc7\u65f6\u8f6f\u4ef6\u5305\u3001\u654f\u611f\u53c2\u6570\u8bef\u7528\u3001\u53ef\u88ab\u5229\u7528\u7684\u90e8\u7f72\u914d\u7f6e\u3001\u6613\u53d7\u57df\u540d\u62a2\u6ce8\u653b\u51fb\u4ee5\u53ca\u538b\u7f29\u7ec4\u4ef6\u4e2d\u5d4c\u5165\u6076\u610f\u884c\u4e3a\u7b49\u7cfb\u7edf\u6027\u6f0f\u6d1e\u3002", "conclusion": "\u65e0\u670d\u52a1\u5668\u516c\u5171\u4ed3\u5e93\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u5b9e\u65bd\u7f13\u89e3\u63aa\u65bd\u6765\u4fdd\u62a4\u5f00\u53d1\u8005\u548c\u7ec4\u7ec7\u3002"}}
{"id": "2510.17149", "categories": ["cs.AI", "I.2.11"], "pdf": "https://arxiv.org/pdf/2510.17149", "abs": "https://arxiv.org/abs/2510.17149", "authors": ["Hongyi Du", "Jiaqi Su", "Jisen Li", "Lijie Ding", "Yingxuan Yang", "Peixuan Han", "Xiangru Tang", "Kunlun Zhu", "Jiaxuan You"], "title": "Which LLM Multi-Agent Protocol to Choose?", "comment": "Under review at ICLR 2026.Code and benchmark artifacts:\n  https://github.com/ulab-uiuc/AgentProtocols", "summary": "As large-scale multi-agent systems evolve, the communication protocol layer\nhas become a critical yet under-evaluated factor shaping performance and\nreliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,\netc.), selection is often intuition-driven and lacks standardized guidance. We\nintroduce ProtocolBench, a benchmark that systematically compares agent\nprotocols along four measurable axes: task success, end-to-end latency, message\nor byte overhead, and robustness under failures. On ProtocolBench, protocol\nchoice significantly influences system behavior. In the Streaming Queue\nscenario, overall completion time varies by up to 36.5% across protocols, and\nmean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,\nresilience also differs consistently across protocols. Beyond evaluation, we\npresent ProtocolRouter, a learnable protocol router that selects per-scenario\n(or per-module) protocols from requirement and runtime signals. ProtocolRouter\nreduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol\nbaseline, and achieves scenario-specific gains such as higher success in GAIA.\nWe also release ProtocolRouterBench to standardize protocol evaluation and\nimprove reliability at scale.", "AI": {"tldr": "ProtocolBench\u662f\u4e00\u4e2a\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u4fe1\u534f\u8bae\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u56db\u4e2a\u53ef\u6d4b\u91cf\u7ef4\u5ea6\uff1a\u4efb\u52a1\u6210\u529f\u7387\u3001\u7aef\u5230\u7aef\u5ef6\u8fdf\u3001\u6d88\u606f/\u5b57\u8282\u5f00\u9500\u548c\u6545\u969c\u6062\u590d\u80fd\u529b\u3002\u7814\u7a76\u8fd8\u63d0\u51fa\u4e86ProtocolRouter\uff0c\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u534f\u8bae\u8def\u7531\u5668\uff0c\u80fd\u591f\u6839\u636e\u573a\u666f\u9700\u6c42\u9009\u62e9\u6700\u4f18\u534f\u8bae\u3002", "motivation": "\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\uff0c\u901a\u4fe1\u534f\u8bae\u5c42\u662f\u5f71\u54cd\u6027\u80fd\u548c\u53ef\u9760\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4f46\u76ee\u524d\u534f\u8bae\u9009\u62e9\u7f3a\u4e4f\u6807\u51c6\u5316\u6307\u5bfc\uff0c\u5f80\u5f80\u57fa\u4e8e\u76f4\u89c9\u800c\u975e\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u5f00\u53d1ProtocolBench\u57fa\u51c6\u6d4b\u8bd5\u7cfb\u7edf\uff0c\u4ece\u56db\u4e2a\u7ef4\u5ea6\u5bf9\u6bd4\u4e0d\u540c\u534f\u8bae\u6027\u80fd\uff1b\u63d0\u51faProtocolRouter\u534f\u8bae\u8def\u7531\u5668\uff0c\u901a\u8fc7\u5b66\u4e60\u7b97\u6cd5\u4e3a\u4e0d\u540c\u573a\u666f\u9009\u62e9\u6700\u4f18\u534f\u8bae\u3002", "result": "\u534f\u8bae\u9009\u62e9\u663e\u8457\u5f71\u54cd\u7cfb\u7edf\u884c\u4e3a\uff1a\u5728Streaming Queue\u573a\u666f\u4e2d\uff0c\u603b\u4f53\u5b8c\u6210\u65f6\u95f4\u5dee\u5f02\u8fbe36.5%\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u5dee\u5f02\u8fbe3.48\u79d2\uff1bProtocolRouter\u76f8\u6bd4\u6700\u4f73\u5355\u534f\u8bae\u57fa\u7ebf\uff0c\u6545\u969c\u6062\u590d\u65f6\u95f4\u51cf\u5c1118.1%\uff0c\u5728GAIA\u573a\u666f\u4e2d\u6210\u529f\u7387\u66f4\u9ad8\u3002", "conclusion": "\u534f\u8bae\u9009\u62e9\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd\u6709\u91cd\u5927\u5f71\u54cd\uff0cProtocolBench\u548cProtocolRouter\u4e3a\u534f\u8bae\u8bc4\u4f30\u548c\u9009\u62e9\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2510.17403", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.17403", "abs": "https://arxiv.org/abs/2510.17403", "authors": ["Stella N. Arinze", "Patrick U. Okafor", "Onyekachi M. Egwuagu", "Augustine O. Nwajana"], "title": "Process Automation Architecture Using RFID for Transparent Voting Systems", "comment": "7 pages, 5 figures, 1 table", "summary": "This paper presents the development of a process automation architecture\nleveraging Radio Frequency Identification (RFID) technology for secure,\ntransparent and efficient voting systems. The proposed architecture automates\nthe voting workflow through RFID-enabled voter identification, encrypted vote\ncasting, and secure data transmission. Each eligible voter receives a smart\nRFID card containing a uniquely encrypted identifier, which is verified using\nan RC522 reader interfaced with a microcontroller. Upon successful\nverification, the voter interacts with a touchscreen interface to cast a vote,\nwhich is then encrypted using AES-128 and securely stored on a local SD card or\ntransmitted via GSM to a central server. A tamper-proof monitoring mechanism\nrecords each session with time-stamped digital signatures, ensuring\nauditability and data integrity. The architecture is designed to function in\nboth online and offline modes, with an automated batch synchronization\nmechanism that updates vote records once network connectivity is restored.\nSystem testing in simulated environments confirmed 100% voter authentication\naccuracy, minimized latency (average voting time of 11.5 seconds), and\nrobustness against cloning, double voting, and data interception. The\nintegration of real-time monitoring and secure process control modules enables\nelectoral authorities to automate data logging, detect anomalies, and validate\nsystem integrity dynamically. This work demonstrates a scalable,\nautomation-driven solution for voting infrastructure, offering enhanced\ntransparency, resilience, and deployment flexibility, especially in\nenvironments where digital transformation of electoral processes is critically\nneeded.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8eRFID\u6280\u672f\u7684\u6295\u7968\u7cfb\u7edf\u81ea\u52a8\u5316\u67b6\u6784\uff0c\u5b9e\u73b0\u5b89\u5168\u900f\u660e\u7684\u6295\u7968\u6d41\u7a0b\uff0c\u652f\u6301\u5728\u7ebf\u548c\u79bb\u7ebf\u6a21\u5f0f\uff0c\u6d4b\u8bd5\u663e\u793a100%\u8ba4\u8bc1\u51c6\u786e\u7387\u548c11.5\u79d2\u5e73\u5747\u6295\u7968\u65f6\u95f4\u3002", "motivation": "\u4e3a\u9009\u4e3e\u8fc7\u7a0b\u63d0\u4f9b\u5b89\u5168\u3001\u900f\u660e\u548c\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u6570\u5b57\u5316\u8f6c\u578b\u7684\u9009\u4e3e\u73af\u5883\u3002", "method": "\u4f7f\u7528RFID\u667a\u80fd\u5361\u8fdb\u884c\u9009\u6c11\u8eab\u4efd\u9a8c\u8bc1\uff0c\u7ed3\u5408RC522\u8bfb\u5361\u5668\u548c\u5fae\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u89e6\u6478\u5c4f\u754c\u9762\u6295\u7968\uff0c\u91c7\u7528AES-128\u52a0\u5bc6\u548cGSM\u4f20\u8f93\uff0c\u914d\u5907\u9632\u7be1\u6539\u76d1\u63a7\u673a\u5236\u3002", "result": "\u7cfb\u7edf\u6d4b\u8bd5\u663e\u793a100%\u9009\u6c11\u8ba4\u8bc1\u51c6\u786e\u7387\uff0c\u6700\u5c0f\u5316\u5ef6\u8fdf\uff08\u5e73\u5747\u6295\u7968\u65f6\u95f411.5\u79d2\uff09\uff0c\u6709\u6548\u9632\u6b62\u514b\u9686\u3001\u91cd\u590d\u6295\u7968\u548c\u6570\u636e\u62e6\u622a\u3002", "conclusion": "\u8be5\u67b6\u6784\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u6295\u7968\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u4f9b\u589e\u5f3a\u7684\u900f\u660e\u5ea6\u3001\u97e7\u6027\u548c\u90e8\u7f72\u7075\u6d3b\u6027\u3002"}}
{"id": "2510.17172", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17172", "abs": "https://arxiv.org/abs/2510.17172", "authors": ["Shun Huang", "Wenlu Xing", "Shijia Geng", "Hailong Wang", "Guangkun Nie", "Gongzheng Tang", "Chenyang He", "Shenda Hong"], "title": "Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients", "comment": null, "summary": "Malignant ventricular arrhythmias (VT/VF) following acute myocardial\ninfarction (AMI) are a major cause of in-hospital death, yet early\nidentification remains a clinical challenge. While traditional risk scores have\nlimited performance, end-to-end deep learning models often lack the\ninterpretability needed for clinical trust. This study aimed to develop a\nhybrid predictive framework that integrates a large-scale electrocardiogram\n(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to\nimprove both accuracy and interpretability. We analyzed 6,634 ECG recordings\nfrom AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder\nmodel was used to extract 150-dimensional diagnostic probability features ,\nwhich were then refined through feature selection to train the XGBoost\nclassifier. Model performance was evaluated using AUC and F1-score , and the\nSHAP method was used for interpretability. The ECGFounder + XGBoost hybrid\nmodel achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC\n0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that\nmodel-identified key features, such as \"premature ventricular complexes\" (risk\npredictor) and \"normal sinus rhythm\" (protective factor), were highly\nconsistent with clinical knowledge. We conclude that this hybrid framework\nprovides a novel paradigm for VT/VF risk prediction by validating the use of\nfoundation model outputs as effective, automated feature engineering for\nbuilding trustworthy, explainable AI-based clinical decision support systems.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408ECG\u57fa\u7840\u6a21\u578b\u548c\u53ef\u89e3\u91caXGBoost\u5206\u7c7b\u5668\u7684\u6df7\u5408\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u6025\u6027\u5fc3\u808c\u6897\u6b7b\u540e\u6076\u6027\u5ba4\u6027\u5fc3\u5f8b\u5931\u5e38\u98ce\u9669\uff0c\u5728\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u6025\u6027\u5fc3\u808c\u6897\u6b7b\u540e\u6076\u6027\u5ba4\u6027\u5fc3\u5f8b\u5931\u5e38\u662f\u9662\u5185\u6b7b\u4ea1\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u4f20\u7edf\u98ce\u9669\u8bc4\u5206\u6027\u80fd\u6709\u9650\uff0c\u7aef\u5230\u7aef\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7f3a\u4e4f\u4e34\u5e8a\u4fe1\u4efb\u6240\u9700\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528ECG\u57fa\u7840\u6a21\u578b\u63d0\u53d6150\u7ef4\u8bca\u65ad\u6982\u7387\u7279\u5f81\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u540e\u8bad\u7ec3XGBoost\u5206\u7c7b\u5668\uff0c\u91c7\u7528SHAP\u65b9\u6cd5\u8fdb\u884c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002", "result": "\u6df7\u5408\u6a21\u578bAUC\u8fbe\u52300.801\uff0c\u4f18\u4e8eKNN(0.677)\u3001RNN(0.676)\u548c1D-CNN(0.720)\uff0cSHAP\u5206\u6790\u663e\u793a\u6a21\u578b\u8bc6\u522b\u7279\u5f81\u4e0e\u4e34\u5e8a\u77e5\u8bc6\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u8be5\u6df7\u5408\u6846\u67b6\u4e3a\u57fa\u7840\u6a21\u578b\u8f93\u51fa\u4f5c\u4e3a\u6709\u6548\u81ea\u52a8\u5316\u7279\u5f81\u5de5\u7a0b\u63d0\u4f9b\u4e86\u9a8c\u8bc1\uff0c\u4e3a\u6784\u5efa\u53ef\u4fe1\u8d56\u3001\u53ef\u89e3\u91ca\u7684AI\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2510.17521", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17521", "abs": "https://arxiv.org/abs/2510.17521", "authors": ["Francesco Balassone", "V\u00edctor Mayoral-Vilches", "Stefan Rass", "Martin Pinzger", "Gaetano Perrone", "Simon Pietro Romano", "Peter Schartner"], "title": "Cybersecurity AI: Evaluating Agentic Cybersecurity in Attack/Defense CTFs", "comment": null, "summary": "We empirically evaluate whether AI systems are more effective at attacking or\ndefending in cybersecurity. Using CAI (Cybersecurity AI)'s parallel execution\nframework, we deployed autonomous agents in 23 Attack/Defense CTF\nbattlegrounds. Statistical analysis reveals defensive agents achieve 54.3%\nunconstrained patching success versus 28.3% offensive initial access\n(p=0.0193), but this advantage disappears under operational constraints: when\ndefense requires maintaining availability (23.9%) and preventing all intrusions\n(15.2%), no significant difference exists (p>0.05). Exploratory taxonomy\nanalysis suggests potential patterns in vulnerability exploitation, though\nlimited sample sizes preclude definitive conclusions. This study provides the\nfirst controlled empirical evidence challenging claims of AI attacker\nadvantage, demonstrating that defensive effectiveness critically depends on\nsuccess criteria, a nuance absent from conceptual analyses but essential for\ndeployment. These findings underscore the urgency for defenders to adopt\nopen-source Cybersecurity AI frameworks to maintain security equilibrium\nagainst accelerating offensive automation.", "AI": {"tldr": "AI\u9632\u5fa1\u7cfb\u7edf\u5728\u65e0\u7ea6\u675f\u6761\u4ef6\u4e0b\u6bd4\u653b\u51fb\u7cfb\u7edf\u66f4\u6709\u6548\uff0854.3% vs 28.3%\uff09\uff0c\u4f46\u5728\u64cd\u4f5c\u7ea6\u675f\u4e0b\u8fd9\u79cd\u4f18\u52bf\u6d88\u5931\u3002\u9632\u5fa1\u6548\u679c\u9ad8\u5ea6\u4f9d\u8d56\u6210\u529f\u6807\u51c6\uff0c\u6311\u6218\u4e86AI\u653b\u51fb\u4f18\u52bf\u7684\u4f20\u7edf\u89c2\u70b9\u3002", "motivation": "\u5b9e\u8bc1\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u7f51\u7edc\u5b89\u5168\u4e2d\u662f\u66f4\u64c5\u957f\u653b\u51fb\u8fd8\u662f\u9632\u5fa1\uff0c\u6311\u6218\u5173\u4e8eAI\u653b\u51fb\u4f18\u52bf\u7684\u4f20\u7edf\u89c2\u70b9\u3002", "method": "\u4f7f\u7528CAI\u5e76\u884c\u6267\u884c\u6846\u67b6\uff0c\u572823\u4e2a\u653b\u9632CTF\u6218\u573a\u90e8\u7f72\u81ea\u4e3b\u4ee3\u7406\uff0c\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u9632\u5fa1\u4ee3\u7406\u5728\u65e0\u7ea6\u675f\u4fee\u8865\u6210\u529f\u7387\u8fbe54.3%\uff0c\u663e\u8457\u9ad8\u4e8e\u653b\u51fb\u521d\u59cb\u8bbf\u95ee\u768428.3%\uff1b\u4f46\u5728\u64cd\u4f5c\u7ea6\u675f\u4e0b\uff08\u5982\u4fdd\u6301\u53ef\u7528\u6027\u3001\u9632\u6b62\u6240\u6709\u5165\u4fb5\uff09\uff0c\u4f18\u52bf\u6d88\u5931\u3002", "conclusion": "\u9632\u5fa1\u6709\u6548\u6027\u5173\u952e\u53d6\u51b3\u4e8e\u6210\u529f\u6807\u51c6\uff0c\u8fd9\u4e00\u7ec6\u5fae\u5dee\u522b\u5bf9\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u5f3a\u8c03\u9632\u5fa1\u8005\u9700\u8981\u91c7\u7528\u5f00\u6e90\u7f51\u7edc\u5b89\u5168AI\u6846\u67b6\u6765\u5bf9\u6297\u52a0\u901f\u7684\u653b\u51fb\u81ea\u52a8\u5316\u3002"}}
{"id": "2510.17173", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17173", "abs": "https://arxiv.org/abs/2510.17173", "authors": ["Melik Ozolcer", "Sang Won Bae"], "title": "Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users", "comment": "Accepted to the NeurIPS 2025 Workshop on Multi-Turn Interactions in\n  Large Language Models", "summary": "We study a web-deployed, tool-augmented LLM health coach with real users. In\na pilot with seven users (280 rated turns), offline policy evaluation (OPE)\nover factorized decision heads (Tool/Style) shows that a uniform heavy-tool\npolicy raises average value on logs but harms specific subgroups, most notably\nlow-health-literacy/high-self-efficacy users. A lightweight simulator with\nhidden archetypes further shows that adding a small early information-gain\nbonus reliably shortens trait identification and improves goal success and\npass@3. Together, these early findings indicate an evaluation-first path to\npersonalization: freeze the generator, learn subgroup-aware decision heads on\ntyped rewards (objective tool outcomes and satisfaction), and always report\nper-archetype metrics to surface subgroup harms that averages obscure.", "AI": {"tldr": "\u7814\u7a76\u663e\u793a\uff0c\u7edf\u4e00\u7684\u5de5\u5177\u5bc6\u96c6\u578b\u7b56\u7565\u867d\u7136\u80fd\u63d0\u5347\u6574\u4f53\u4ef7\u503c\uff0c\u4f46\u4f1a\u5bf9\u7279\u5b9a\u7528\u6237\u7fa4\u4f53\uff08\u7279\u522b\u662f\u5065\u5eb7\u7d20\u517b\u4f4e\u4f46\u81ea\u6211\u6548\u80fd\u9ad8\u7684\u7528\u6237\uff09\u9020\u6210\u4f24\u5bb3\u3002\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6a21\u62df\u5668\u53d1\u73b0\uff0c\u6dfb\u52a0\u65e9\u671f\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u53ef\u4ee5\u7f29\u77ed\u7279\u8d28\u8bc6\u522b\u65f6\u95f4\u5e76\u63d0\u9ad8\u76ee\u6807\u6210\u529f\u7387\u3002", "motivation": "\u7814\u7a76\u7f51\u7edc\u90e8\u7f72\u7684\u3001\u5de5\u5177\u589e\u5f3a\u7684LLM\u5065\u5eb7\u6559\u7ec3\u5728\u771f\u5b9e\u7528\u6237\u4e2d\u7684\u8868\u73b0\uff0c\u63a2\u7d22\u4e2a\u6027\u5316\u7b56\u7565\u5bf9\u7528\u6237\u7fa4\u4f53\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u907f\u514d\u5e73\u5747\u6307\u6807\u63a9\u76d6\u7684\u7fa4\u4f53\u4f24\u5bb3\u3002", "method": "\u4f7f\u7528\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\uff08OPE\uff09\u5206\u6790\u56e0\u5b50\u5316\u51b3\u7b56\u5934\uff08\u5de5\u5177/\u98ce\u683c\uff09\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6a21\u62df\u5668\u6d4b\u8bd5\u6dfb\u52a0\u65e9\u671f\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u7684\u6548\u679c\uff0c\u91c7\u7528\u57fa\u4e8e\u7c7b\u578b\u5316\u5956\u52b1\uff08\u5ba2\u89c2\u5de5\u5177\u7ed3\u679c\u548c\u6ee1\u610f\u5ea6\uff09\u7684\u5b50\u7fa4\u4f53\u611f\u77e5\u51b3\u7b56\u5934\u5b66\u4e60\u3002", "result": "\u7edf\u4e00\u7684\u91cd\u5de5\u5177\u7b56\u7565\u5728\u65e5\u5fd7\u4e0a\u63d0\u9ad8\u5e73\u5747\u4ef7\u503c\u4f46\u4f24\u5bb3\u7279\u5b9a\u5b50\u7fa4\u4f53\uff1b\u6dfb\u52a0\u5c0f\u89c4\u6a21\u65e9\u671f\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u53ef\u9760\u5730\u7f29\u77ed\u7279\u8d28\u8bc6\u522b\u65f6\u95f4\uff0c\u63d0\u9ad8\u76ee\u6807\u6210\u529f\u7387\u548cpass@3\u6307\u6807\u3002", "conclusion": "\u63d0\u51fa\u8bc4\u4f30\u4f18\u5148\u7684\u4e2a\u6027\u5316\u8def\u5f84\uff1a\u51bb\u7ed3\u751f\u6210\u5668\uff0c\u5728\u7c7b\u578b\u5316\u5956\u52b1\u4e0a\u5b66\u4e60\u5b50\u7fa4\u4f53\u611f\u77e5\u51b3\u7b56\u5934\uff0c\u59cb\u7ec8\u62a5\u544a\u6bcf\u4e2a\u539f\u578b\u6307\u6807\u4ee5\u63ed\u793a\u5e73\u5747\u6307\u6807\u63a9\u76d6\u7684\u5b50\u7fa4\u4f53\u4f24\u5bb3\u3002"}}
{"id": "2510.17552", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17552", "abs": "https://arxiv.org/abs/2510.17552", "authors": ["Persefoni Konteli", "Nikolaos Makris", "Evgenia Niovi Sassalou", "Stylianos A. Kazazis", "Alkinoos Papageorgopoulos", "Stefanos Vasileiadis", "Konstantinos Tsimvrakidis", "Symeon Tsintzos", "Georgios M. Nikolopoulos", "George T. Kanellos"], "title": "Dynamic Switched Quantum Key Distribution Networkwith PUF-based authentication", "comment": null, "summary": "We demonstrate a centrally controlled dynamic switched-QKD network,\nwithintegrated PUF-based dynamic authentication for each QKD link. The\nperformance of the dynamicswitched-QKD network with real-time PUF-based\nauthentication is analyzed.", "AI": {"tldr": "\u5c55\u793a\u4e86\u4e00\u4e2a\u4e2d\u5fc3\u63a7\u5236\u7684\u52a8\u6001\u4ea4\u6362QKD\u7f51\u7edc\uff0c\u96c6\u6210\u4e86\u57fa\u4e8ePUF\u7684\u52a8\u6001\u8ba4\u8bc1\u673a\u5236", "motivation": "\u63d0\u9ad8\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7f51\u7edc\u7684\u5b89\u5168\u6027\u548c\u52a8\u6001\u7ba1\u7406\u80fd\u529b", "method": "\u91c7\u7528\u4e2d\u5fc3\u63a7\u5236\u7684\u52a8\u6001\u4ea4\u6362QKD\u7f51\u7edc\u67b6\u6784\uff0c\u96c6\u6210\u57fa\u4e8ePUF\u7684\u5b9e\u65f6\u8ba4\u8bc1", "result": "\u5206\u6790\u4e86\u5177\u6709\u5b9e\u65f6PUF\u8ba4\u8bc1\u7684\u52a8\u6001\u4ea4\u6362QKD\u7f51\u7edc\u7684\u6027\u80fd", "conclusion": "\u8be5\u65b9\u6848\u4e3aQKD\u7f51\u7edc\u63d0\u4f9b\u4e86\u589e\u5f3a\u7684\u5b89\u5168\u6027\u548c\u52a8\u6001\u7ba1\u7406\u529f\u80fd"}}
{"id": "2510.17211", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17211", "abs": "https://arxiv.org/abs/2510.17211", "authors": ["Tingsong Xiao", "Yao An Lee", "Zelin Xu", "Yupu Zhang", "Zibo Liu", "Yu Huang", "Jiang Bian", "Serena Jingchuan Guo", "Zhe Jiang"], "title": "Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling", "comment": null, "summary": "Disease progression modeling aims to characterize and predict how a patient's\ndisease complications worsen over time based on longitudinal electronic health\nrecords (EHRs). Accurate modeling of disease progression, such as type 2\ndiabetes, can enhance patient sub-phenotyping and inform effective and timely\ninterventions. However, the problem is challenging due to the need to learn\ncontinuous-time dynamics of progression patterns based on irregular-time event\nsamples and patient heterogeneity (\\eg different progression rates and\npathways). Existing mechanistic and data-driven methods either lack\nadaptability to learn from real-world data or fail to capture complex\ncontinuous-time dynamics on progression trajectories. To address these\nlimitations, we propose Temporally Detailed Hypergraph Neural Ordinary\nDifferential Equation (TD-HNODE), which represents disease progression on\nclinically recognized trajectories as a temporally detailed hypergraph and\nlearns the continuous-time progression dynamics via a neural ODE framework.\nTD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the\ninterdependency of disease complication markers within both intra- and\ninter-progression trajectories. Experiments on two real-world clinical datasets\ndemonstrate that TD-HNODE outperforms multiple baselines in modeling the\nprogression of type 2 diabetes and related cardiovascular diseases.", "AI": {"tldr": "\u63d0\u51fa\u4e86TD-HNODE\u6a21\u578b\uff0c\u901a\u8fc7\u65f6\u95f4\u8be6\u7ec6\u8d85\u56fe\u548c\u795e\u7ecfODE\u6846\u67b6\u5b66\u4e60\u75be\u75c5\u8fdb\u5c55\u7684\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\uff0c\u57282\u578b\u7cd6\u5c3f\u75c5\u548c\u5fc3\u8840\u7ba1\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u51c6\u786e\u5efa\u6a21\u75be\u75c5\u8fdb\u5c55\uff08\u59822\u578b\u7cd6\u5c3f\u75c5\uff09\u53ef\u4ee5\u6539\u5584\u60a3\u8005\u4e9a\u578b\u5206\u578b\u548c\u53ca\u65f6\u5e72\u9884\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u4e0d\u89c4\u5219\u65f6\u95f4\u91c7\u6837\u548c\u60a3\u8005\u5f02\u8d28\u6027\uff0c\u65e0\u6cd5\u6355\u6349\u590d\u6742\u7684\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\u3002", "method": "TD-HNODE\u5c06\u75be\u75c5\u8fdb\u5c55\u8868\u793a\u4e3a\u65f6\u95f4\u8be6\u7ec6\u8d85\u56fe\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684TD-Hypergraph Laplacian\u6355\u6349\u75be\u75c5\u5e76\u53d1\u75c7\u6807\u8bb0\u5728\u8fdb\u5c55\u8f68\u8ff9\u5185\u548c\u8f68\u8ff9\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f7f\u7528\u795e\u7ecfODE\u6846\u67b6\u5b66\u4e60\u8fde\u7eed\u65f6\u95f4\u8fdb\u5c55\u52a8\u6001\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTD-HNODE\u5728\u5efa\u6a212\u578b\u7cd6\u5c3f\u75c5\u548c\u76f8\u5173\u5fc3\u8840\u7ba1\u75be\u75c5\u8fdb\u5c55\u65b9\u9762\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TD-HNODE\u80fd\u591f\u6709\u6548\u6355\u6349\u75be\u75c5\u8fdb\u5c55\u7684\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\uff0c\u89e3\u51b3\u4e86\u4e0d\u89c4\u5219\u65f6\u95f4\u91c7\u6837\u548c\u60a3\u8005\u5f02\u8d28\u6027\u7684\u6311\u6218\uff0c\u4e3a\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17621", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17621", "abs": "https://arxiv.org/abs/2510.17621", "authors": ["Vincenzo Carletti", "Pasquale Foggia", "Carlo Mazzocca", "Giuseppe Parrella", "Mario Vento"], "title": "GUIDE: Enhancing Gradient Inversion Attacks in Federated Learning with Denoising Models", "comment": null, "summary": "Federated Learning (FL) enables collaborative training of Machine Learning\n(ML) models across multiple clients while preserving their privacy. Rather than\nsharing raw data, federated clients transmit locally computed updates to train\nthe global model. Although this paradigm should provide stronger privacy\nguarantees than centralized ML, client updates remain vulnerable to privacy\nleakage. Adversaries can exploit them to infer sensitive properties about the\ntraining data or even to reconstruct the original inputs via Gradient Inversion\nAttacks (GIAs). Under the honest-butcurious threat model, GIAs attempt to\nreconstruct training data by reversing intermediate updates using\noptimizationbased techniques. We observe that these approaches usually\nreconstruct noisy approximations of the original inputs, whose quality can be\nenhanced with specialized denoising models. This paper presents Gradient Update\nInversion with DEnoising (GUIDE), a novel methodology that leverages diffusion\nmodels as denoising tools to improve image reconstruction attacks in FL. GUIDE\ncan be integrated into any GIAs that exploits surrogate datasets, a widely\nadopted assumption in GIAs literature. We comprehensively evaluate our approach\nin two attack scenarios that use different FL algorithms, models, and datasets.\nOur results demonstrate that GUIDE integrates seamlessly with two state-ofthe-\nart GIAs, substantially improving reconstruction quality across multiple\nmetrics. Specifically, GUIDE achieves up to 46% higher perceptual similarity,\nas measured by the DreamSim metric.", "AI": {"tldr": "GUIDE\u662f\u4e00\u79cd\u5229\u7528\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u53bb\u566a\u5de5\u5177\u6765\u589e\u5f3a\u8054\u90a6\u5b66\u4e60\u4e2d\u56fe\u50cf\u91cd\u5efa\u653b\u51fb\u6548\u679c\u7684\u65b0\u65b9\u6cd5\uff0c\u53ef\u96c6\u6210\u5230\u4efb\u4f55\u4f7f\u7528\u4ee3\u7406\u6570\u636e\u96c6\u7684\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u4fdd\u62a4\u9690\u79c1\uff0c\u4f46\u5ba2\u6237\u7aef\u66f4\u65b0\u4ecd\u5bb9\u6613\u53d7\u5230\u9690\u79c1\u6cc4\u9732\u653b\u51fb\uff0c\u7279\u522b\u662f\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u3002\u73b0\u6709\u65b9\u6cd5\u91cd\u5efa\u7684\u56fe\u50cf\u901a\u5e38\u542b\u6709\u566a\u58f0\uff0c\u9700\u8981\u4e13\u95e8\u7684\u53bb\u566a\u6280\u672f\u6765\u63d0\u5347\u8d28\u91cf\u3002", "method": "\u63d0\u51faGUIDE\u65b9\u6cd5\uff0c\u5c06\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u53bb\u566a\u5de5\u5177\u96c6\u6210\u5230\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u4e2d\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u7684\u5f3a\u5927\u53bb\u566a\u80fd\u529b\u6765\u63d0\u5347\u91cd\u5efa\u56fe\u50cf\u7684\u8d28\u91cf\u3002", "result": "GUIDE\u4e0e\u4e24\u79cd\u6700\u5148\u8fdb\u7684\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u65e0\u7f1d\u96c6\u6210\uff0c\u5728\u591a\u79cd\u6307\u6807\u4e0a\u663e\u8457\u63d0\u9ad8\u91cd\u5efa\u8d28\u91cf\uff0cDreamSim\u611f\u77e5\u76f8\u4f3c\u5ea6\u6307\u6807\u63d0\u5347\u9ad8\u8fbe46%\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u53bb\u566a\u5de5\u5177\u80fd\u6709\u6548\u589e\u5f3a\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u6548\u679c\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2510.17235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17235", "abs": "https://arxiv.org/abs/2510.17235", "authors": ["Chong Chen", "Ze Liu", "Lingfeng Bao", "Yanlin Wang", "Ting Chen", "Daoyuan Wu", "Jiachi Chen"], "title": "Coinvisor: An RL-Enhanced Chatbot Agent for Interactive Cryptocurrency Investment Analysis", "comment": null, "summary": "The cryptocurrency market offers significant investment opportunities but\nfaces challenges including high volatility and fragmented information. Data\nintegration and analysis are essential for informed investment decisions.\nCurrently, investors use three main approaches: (1) Manual analysis across\nvarious sources, which depends heavily on individual experience and is\ntime-consuming and prone to bias; (2) Data aggregation platforms-limited in\nfunctionality and depth of analysis; (3) Large language model agents-based on\nstatic pretrained models, lacking real-time data integration and multi-step\nreasoning capabilities. To address these limitations, we present Coinvisor, a\nreinforcement learning-based chatbot that provides comprehensive analytical\nsupport for cryptocurrency investment through a multi-agent framework.\nCoinvisor integrates diverse analytical capabilities through specialized tools.\nIts key innovation is a reinforcement learning-based tool selection mechanism\nthat enables multi-step planning and flexible integration of diverse data\nsources. This design supports real-time interaction and adaptive analysis of\ndynamic content, delivering accurate and actionable investment insights. We\nevaluated Coinvisor through automated benchmarks on tool calling accuracy and\nuser studies with 20 cryptocurrency investors using our interface. Results show\nthat Coinvisor improves recall by 40.7% and F1 score by 26.6% over the base\nmodel in tool orchestration. User studies show high satisfaction (4.64/5), with\nparticipants preferring Coinvisor to both general LLMs and existing crypto\nplatforms (4.62/5).", "AI": {"tldr": "Coinvisor\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u52a0\u5bc6\u8d27\u5e01\u6295\u8d44\u5206\u6790\u804a\u5929\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6846\u67b6\u63d0\u4f9b\u5168\u9762\u7684\u5206\u6790\u652f\u6301\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u5b58\u5728\u9ad8\u6ce2\u52a8\u6027\u548c\u4fe1\u606f\u788e\u7247\u5316\u95ee\u9898\uff0c\u73b0\u6709\u5206\u6790\u65b9\u6cd5\u5305\u62ec\u624b\u52a8\u5206\u6790\u3001\u6570\u636e\u805a\u5408\u5e73\u53f0\u548cLLM\u4ee3\u7406\u90fd\u5b58\u5728\u5404\u79cd\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u5b9e\u65f6\u5206\u6790\u5de5\u5177\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5de5\u5177\u9009\u62e9\u673a\u5236\u548c\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u96c6\u6210\u591a\u6837\u5316\u5206\u6790\u80fd\u529b\uff0c\u652f\u6301\u591a\u6b65\u89c4\u5212\u548c\u5b9e\u65f6\u6570\u636e\u6574\u5408\u3002", "result": "\u5728\u5de5\u5177\u7f16\u6392\u65b9\u9762\uff0c\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u53ec\u56de\u7387\u63d0\u534740.7%\uff0cF1\u5206\u6570\u63d0\u534726.6%\uff1b\u7528\u6237\u7814\u7a76\u663e\u793a\u9ad8\u6ee1\u610f\u5ea6(4.64/5)\uff0c\u53c2\u4e0e\u8005\u66f4\u504f\u597dCoinvisor\u800c\u975e\u901a\u7528LLM\u548c\u73b0\u6709\u5e73\u53f0(4.62/5)\u3002", "conclusion": "Coinvisor\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u52a0\u5bc6\u8d27\u5e01\u6295\u8d44\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u7528\u6237\u4f53\u9a8c\uff0c\u4e3a\u6295\u8d44\u8005\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2510.17687", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17687", "abs": "https://arxiv.org/abs/2510.17687", "authors": ["Xu Zhang", "Hao Li", "Zhichao Lu"], "title": "CrossGuard: Safeguarding MLLMs against Joint-Modal Implicit Malicious Attacks", "comment": "14 pages, 8 figures, 2 tables", "summary": "Multimodal Large Language Models (MLLMs) achieve strong reasoning and\nperception capabilities but are increasingly vulnerable to jailbreak attacks.\nWhile existing work focuses on explicit attacks, where malicious content\nresides in a single modality, recent studies reveal implicit attacks, in which\nbenign text and image inputs jointly express unsafe intent. Such joint-modal\nthreats are difficult to detect and remain underexplored, largely due to the\nscarcity of high-quality implicit data. We propose ImpForge, an automated\nred-teaming pipeline that leverages reinforcement learning with tailored reward\nmodules to generate diverse implicit samples across 14 domains. Building on\nthis dataset, we further develop CrossGuard, an intent-aware safeguard\nproviding robust and comprehensive defense against both explicit and implicit\nthreats. Extensive experiments across safe and unsafe benchmarks, implicit and\nexplicit attacks, and multiple out-of-domain settings demonstrate that\nCrossGuard significantly outperforms existing defenses, including advanced\nMLLMs and guardrails, achieving stronger security while maintaining high\nutility. This offers a balanced and practical solution for enhancing MLLM\nrobustness against real-world multimodal threats.", "AI": {"tldr": "\u63d0\u51faImpForge\u81ea\u52a8\u7ea2\u961f\u7ba1\u9053\u751f\u6210\u591a\u6837\u5316\u9690\u5f0f\u653b\u51fb\u6837\u672c\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1CrossGuard\u610f\u56fe\u611f\u77e5\u9632\u62a4\u7cfb\u7edf\uff0c\u6709\u6548\u9632\u5fa1\u663e\u5f0f\u548c\u9690\u5f0f\u591a\u6a21\u6001\u5a01\u80c1\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u548c\u611f\u77e5\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9762\u4e34\u65e5\u76ca\u4e25\u91cd\u7684\u8d8a\u72f1\u653b\u51fb\u5a01\u80c1\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u663e\u5f0f\u653b\u51fb\uff0c\u800c\u9690\u5f0f\u653b\u51fb\uff08\u826f\u6027\u6587\u672c\u548c\u56fe\u50cf\u8054\u5408\u8868\u8fbe\u4e0d\u5b89\u5168\u610f\u56fe\uff09\u96be\u4ee5\u68c0\u6d4b\u4e14\u7814\u7a76\u4e0d\u8db3\uff0c\u4e3b\u8981\u7531\u4e8e\u9ad8\u8d28\u91cf\u9690\u5f0f\u6570\u636e\u7a00\u7f3a\u3002", "method": "1. \u63d0\u51faImpForge\uff1a\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u5b9a\u5236\u5956\u52b1\u6a21\u5757\u7684\u81ea\u52a8\u7ea2\u961f\u7ba1\u9053\uff0c\u572814\u4e2a\u9886\u57df\u751f\u6210\u591a\u6837\u5316\u9690\u5f0f\u6837\u672c\uff1b2. \u5f00\u53d1CrossGuard\uff1a\u57fa\u4e8e\u8be5\u6570\u636e\u96c6\u7684\u610f\u56fe\u611f\u77e5\u9632\u62a4\u7cfb\u7edf\uff0c\u63d0\u4f9b\u5bf9\u663e\u5f0f\u548c\u9690\u5f0f\u5a01\u80c1\u7684\u5168\u9762\u9632\u5fa1\u3002", "result": "\u5728\u5b89\u5168\u548c\u4e0d\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u3001\u9690\u5f0f\u548c\u663e\u5f0f\u653b\u51fb\u4ee5\u53ca\u591a\u4e2a\u57df\u5916\u8bbe\u7f6e\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cCrossGuard\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\uff08\u5305\u62ec\u5148\u8fdbMLLM\u548c\u9632\u62a4\u680f\uff09\uff0c\u5728\u4fdd\u6301\u9ad8\u5b9e\u7528\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u66f4\u5f3a\u7684\u5b89\u5168\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u589e\u5f3aMLLM\u5bf9\u6297\u73b0\u5b9e\u4e16\u754c\u591a\u6a21\u6001\u5a01\u80c1\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u5e73\u8861\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17309", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17309", "abs": "https://arxiv.org/abs/2510.17309", "authors": ["Thorsten Fr\u00f6hlich", "Tim Schlippe"], "title": "RubiSCoT: A Framework for AI-Supported Academic Assessment", "comment": null, "summary": "The evaluation of academic theses is a cornerstone of higher education,\nensuring rigor and integrity. Traditional methods, though effective, are\ntime-consuming and subject to evaluator variability. This paper presents\nRubiSCoT, an AI-supported framework designed to enhance thesis evaluation from\nproposal to final submission. Using advanced natural language processing\ntechniques, including large language models, retrieval-augmented generation,\nand structured chain-of-thought prompting, RubiSCoT offers a consistent,\nscalable solution. The framework includes preliminary assessments,\nmultidimensional assessments, content extraction, rubric-based scoring, and\ndetailed reporting. We present the design and implementation of RubiSCoT,\ndiscussing its potential to optimize academic assessment processes through\nconsistent, scalable, and transparent evaluation.", "AI": {"tldr": "RubiSCoT\u662f\u4e00\u4e2aAI\u652f\u6301\u7684\u8bba\u6587\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528NLP\u6280\u672f\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4ece\u63d0\u6848\u5230\u6700\u7ec8\u63d0\u4ea4\u63d0\u4f9b\u4e00\u81f4\u3001\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u8bba\u6587\u8bc4\u4f30\u65b9\u6cd5\u8017\u65f6\u4e14\u53d7\u8bc4\u4f30\u8005\u4e3b\u89c2\u6027\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u4e00\u81f4\u7684\u8bc4\u4f30\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u5148\u8fdb\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\uff0c\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u63d0\u793a\uff0c\u63d0\u4f9b\u521d\u6b65\u8bc4\u4f30\u3001\u591a\u7ef4\u8bc4\u4f30\u3001\u5185\u5bb9\u63d0\u53d6\u3001\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u5206\u548c\u8be6\u7ec6\u62a5\u544a\u3002", "result": "\u5f00\u53d1\u4e86RubiSCoT\u6846\u67b6\u7684\u8bbe\u8ba1\u548c\u5b9e\u73b0\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4f18\u5316\u5b66\u672f\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "RubiSCoT\u6709\u6f5c\u529b\u901a\u8fc7\u4e00\u81f4\u3001\u53ef\u6269\u5c55\u548c\u900f\u660e\u7684\u8bc4\u4f30\u6765\u4f18\u5316\u5b66\u672f\u8bc4\u4f30\u6d41\u7a0b\u3002"}}
{"id": "2510.17759", "categories": ["cs.CR", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17759", "abs": "https://arxiv.org/abs/2510.17759", "authors": ["Qilin Liao", "Anamika Lochab", "Ruqi Zhang"], "title": "VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models", "comment": "18 pages, 7 Figures,", "summary": "Vision-Language Models (VLMs) extend large language models with visual\nreasoning, but their multimodal design also introduces new, underexplored\nvulnerabilities. Existing multimodal red-teaming methods largely rely on\nbrittle templates, focus on single-attack settings, and expose only a narrow\nsubset of vulnerabilities. To address these limitations, we introduce VERA-V, a\nvariational inference framework that recasts multimodal jailbreak discovery as\nlearning a joint posterior distribution over paired text-image prompts. This\nprobabilistic view enables the generation of stealthy, coupled adversarial\ninputs that bypass model guardrails. We train a lightweight attacker to\napproximate the posterior, allowing efficient sampling of diverse jailbreaks\nand providing distributional insights into vulnerabilities. VERA-V further\nintegrates three complementary strategies: (i) typography-based text prompts\nthat embed harmful cues, (ii) diffusion-based image synthesis that introduces\nadversarial signals, and (iii) structured distractors to fragment VLM\nattention. Experiments on HarmBench and HADES benchmarks show that VERA-V\nconsistently outperforms state-of-the-art baselines on both open-source and\nfrontier VLMs, achieving up to 53.75% higher attack success rate (ASR) over the\nbest baseline on GPT-4o.", "AI": {"tldr": "VERA-V\u662f\u4e00\u4e2a\u53d8\u5206\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u591a\u6a21\u6001\u8d8a\u72f1\u53d1\u73b0\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5b66\u4e60\u914d\u5bf9\u6587\u672c-\u56fe\u50cf\u63d0\u793a\u7684\u8054\u5408\u540e\u9a8c\u5206\u5e03\uff0c\u751f\u6210\u9690\u853d\u7684\u5bf9\u6297\u8f93\u5165\u6765\u7ed5\u8fc7\u6a21\u578b\u9632\u62a4\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u7ea2\u961f\u65b9\u6cd5\u4f9d\u8d56\u8106\u5f31\u7684\u6a21\u677f\uff0c\u4e13\u6ce8\u4e8e\u5355\u653b\u51fb\u8bbe\u7f6e\uff0c\u53ea\u80fd\u66b4\u9732\u6709\u9650\u7684\u6f0f\u6d1e\u5b50\u96c6\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u6f0f\u6d1e\u53d1\u73b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u63a8\u7406\u6846\u67b6\u5b66\u4e60\u6587\u672c-\u56fe\u50cf\u63d0\u793a\u7684\u8054\u5408\u540e\u9a8c\u5206\u5e03\uff0c\u7ed3\u5408\u4e09\u79cd\u7b56\u7565\uff1a\u57fa\u4e8e\u6392\u7248\u7684\u6709\u5bb3\u6587\u672c\u63d0\u793a\u3001\u57fa\u4e8e\u6269\u6563\u7684\u56fe\u50cf\u5408\u6210\u5f15\u5165\u5bf9\u6297\u4fe1\u53f7\u3001\u7ed3\u6784\u5316\u5e72\u6270\u7269\u5206\u6563VLM\u6ce8\u610f\u529b\u3002", "result": "\u5728HarmBench\u548cHADES\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVERA-V\u5728\u5f00\u6e90\u548c\u524d\u6cbfVLM\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728GPT-4o\u4e0a\u653b\u51fb\u6210\u529f\u7387\u6bd4\u6700\u4f73\u57fa\u7ebf\u9ad8\u51fa53.75%\u3002", "conclusion": "VERA-V\u901a\u8fc7\u6982\u7387\u65b9\u6cd5\u6709\u6548\u53d1\u73b0\u591a\u6a21\u6001\u6f0f\u6d1e\uff0c\u4e3a\u7406\u89e3\u548c\u9632\u5fa1\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u98ce\u9669\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2510.17382", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17382", "abs": "https://arxiv.org/abs/2510.17382", "authors": ["Rishabh Jain", "Keisuke Okumura", "Michael Amir", "Amanda Prorok"], "title": "Graph Attention-Guided Search for Dense Multi-Agent Pathfinding", "comment": null, "summary": "Finding near-optimal solutions for dense multi-agent pathfinding (MAPF)\nproblems in real-time remains challenging even for state-of-the-art planners.\nTo this end, we develop a hybrid framework that integrates a learned heuristic\nderived from MAGAT, a neural MAPF policy with a graph attention scheme, into a\nleading search-based algorithm, LaCAM. While prior work has explored\nlearning-guided search in MAPF, such methods have historically underperformed.\nIn contrast, our approach, termed LaGAT, outperforms both purely search-based\nand purely learning-based methods in dense scenarios. This is achieved through\nan enhanced MAGAT architecture, a pre-train-then-fine-tune strategy on maps of\ninterest, and a deadlock detection scheme to account for imperfect neural\nguidance. Our results demonstrate that, when carefully designed, hybrid search\noffers a powerful solution for tightly coupled, challenging multi-agent\ncoordination problems.", "AI": {"tldr": "\u63d0\u51faLaGAT\u6df7\u5408\u6846\u67b6\uff0c\u5c06\u57fa\u4e8e\u56fe\u6ce8\u610f\u529b\u7684\u795e\u7ecf\u7f51\u7edc\u542f\u53d1\u5f0f(MAGAT)\u96c6\u6210\u5230\u641c\u7d22\u7b97\u6cd5LaCAM\u4e2d\uff0c\u5728\u5bc6\u96c6\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u4efb\u52a1\u4e2d\u4f18\u4e8e\u7eaf\u641c\u7d22\u548c\u7eaf\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u5bc6\u96c6\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u95ee\u9898\u5728\u5b9e\u65f6\u573a\u666f\u4e2d\u4ecd\u5177\u6311\u6218\u6027\uff0c\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u5728MAPF\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u7ed3\u5408\u5b66\u4e60\u548c\u641c\u7d22\u7684\u4f18\u52bf\u3002", "method": "\u589e\u5f3aMAGAT\u67b6\u6784\uff0c\u91c7\u7528\u9884\u8bad\u7ec3-\u5fae\u8c03\u7b56\u7565\uff0c\u96c6\u6210\u6b7b\u9501\u68c0\u6d4b\u673a\u5236\uff0c\u5c06\u5b66\u4e60\u5230\u7684\u542f\u53d1\u5f0f\u878d\u5165LaCAM\u641c\u7d22\u7b97\u6cd5\u3002", "result": "LaGAT\u5728\u5bc6\u96c6\u573a\u666f\u4e2d\u8d85\u8d8a\u4e86\u7eaf\u641c\u7d22\u548c\u7eaf\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u6df7\u5408\u641c\u7d22\u5728\u590d\u6742\u591a\u667a\u80fd\u4f53\u534f\u8c03\u95ee\u9898\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6df7\u5408\u641c\u7d22\u4e3a\u7d27\u5bc6\u8026\u5408\u7684\u6311\u6218\u6027\u591a\u667a\u80fd\u4f53\u534f\u8c03\u95ee\u9898\u63d0\u4f9b\u4e86\u5f3a\u5927\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17418", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.17418", "abs": "https://arxiv.org/abs/2510.17418", "authors": ["Mustafa F. Abdelwahed", "Alice Toniolo", "Joan Espasa", "Ian P. Gent"], "title": "Diverse Planning with Simulators via Linear Temporal Logic", "comment": null, "summary": "Autonomous agents rely on automated planning algorithms to achieve their\nobjectives. Simulation-based planning offers a significant advantage over\ndeclarative models in modelling complex environments. However, relying solely\non a planner that produces a single plan may not be practical, as the generated\nplans may not always satisfy the agent's preferences. To address this\nlimitation, we introduce $\\texttt{FBI}_\\texttt{LTL}$, a diverse planner\nexplicitly designed for simulation-based planning problems.\n$\\texttt{FBI}_\\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define\nsemantic diversity criteria, enabling agents to specify what constitutes\nmeaningfully different plans. By integrating these LTL-based diversity models\ndirectly into the search process, $\\texttt{FBI}_\\texttt{LTL}$ ensures the\ngeneration of semantically diverse plans, addressing a critical limitation of\nexisting diverse planning approaches that may produce syntactically different\nbut semantically identical solutions. Extensive evaluations on various\nbenchmarks consistently demonstrate that $\\texttt{FBI}_\\texttt{LTL}$ generates\nmore diverse plans compared to a baseline approach. This work establishes the\nfeasibility of semantically-guided diverse planning in simulation-based\nenvironments, paving the way for innovative approaches in realistic,\nnon-symbolic domains where traditional model-based approaches fail.", "AI": {"tldr": "\u63d0\u51faFBI_LTL\uff0c\u4e00\u79cd\u7528\u4e8e\u6a21\u62df\u89c4\u5212\u95ee\u9898\u7684\u591a\u6837\u5316\u89c4\u5212\u5668\uff0c\u4f7f\u7528\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\u5b9a\u4e49\u8bed\u4e49\u591a\u6837\u6027\u6807\u51c6\uff0c\u751f\u6210\u8bed\u4e49\u591a\u6837\u5316\u7684\u8ba1\u5212", "motivation": "\u4f20\u7edf\u89c4\u5212\u5668\u53ea\u751f\u6210\u5355\u4e00\u8ba1\u5212\uff0c\u53ef\u80fd\u65e0\u6cd5\u6ee1\u8db3\u4ee3\u7406\u504f\u597d\uff1b\u73b0\u6709\u591a\u6837\u5316\u89c4\u5212\u65b9\u6cd5\u53ef\u80fd\u4ea7\u751f\u8bed\u6cd5\u4e0d\u540c\u4f46\u8bed\u4e49\u76f8\u540c\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u4f7f\u7528\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\u5b9a\u4e49\u8bed\u4e49\u591a\u6837\u6027\u6807\u51c6\uff0c\u5e76\u5c06\u8fd9\u4e9b\u591a\u6837\u6027\u6a21\u578b\u76f4\u63a5\u96c6\u6210\u5230\u641c\u7d22\u8fc7\u7a0b\u4e2d", "result": "\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFBI_LTL\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u80fd\u751f\u6210\u66f4\u591a\u6837\u5316\u7684\u8ba1\u5212", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u786e\u7acb\u4e86\u5728\u6a21\u62df\u73af\u5883\u4e2d\u8fdb\u884c\u8bed\u4e49\u5f15\u5bfc\u591a\u6837\u5316\u89c4\u5212\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u4f20\u7edf\u57fa\u4e8e\u6a21\u578b\u65b9\u6cd5\u5931\u6548\u7684\u73b0\u5b9e\u975e\u7b26\u53f7\u9886\u57df\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84"}}
{"id": "2510.17450", "categories": ["cs.AI", "H.4.2; I.2.3; I.2.6; I.2.8; I.2.9; J.7"], "pdf": "https://arxiv.org/pdf/2510.17450", "abs": "https://arxiv.org/abs/2510.17450", "authors": ["Johan Schubert", "Farzad Kamrani", "Tove Gustavi"], "title": "Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions", "comment": "Presented at the 6th International Workshop on Active Inference,\n  15-17 October 2025, Montreal, Canada", "summary": "We develop an active inference route-planning method for the autonomous\ncontrol of intelligent agents. The aim is to reconnoiter a geographical area to\nmaintain a common operational picture. To achieve this, we construct an\nevidence map that reflects our current understanding of the situation,\nincorporating both positive and \"negative\" sensor observations of possible\ntarget objects collected over time, and diffusing the evidence across the map\nas time progresses. The generative model of active inference uses\nDempster-Shafer theory and a Gaussian sensor model, which provides input to the\nagent. The generative process employs a Bayesian approach to update a posterior\nprobability distribution. We calculate the variational free energy for all\npositions within the area by assessing the divergence between a pignistic\nprobability distribution of the evidence map and a posterior probability\ndistribution of a target object based on the observations, including the level\nof surprise associated with receiving new observations. Using the free energy,\nwe direct the agents' movements in a simulation by taking an incremental step\ntoward a position that minimizes the free energy. This approach addresses the\nchallenge of exploration and exploitation, allowing agents to balance searching\nextensive areas of the geographical map while tracking identified target\nobjects.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u7684\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u4e3b\u63a7\u5236\u667a\u80fd\u4ee3\u7406\u5728\u7279\u5b9a\u5730\u7406\u533a\u57df\u5185\u8fdb\u884c\u4fa6\u5bdf\uff0c\u4ee5\u7ef4\u6301\u5171\u540c\u4f5c\u6218\u6001\u52bf\u56fe\u3002", "motivation": "\u89e3\u51b3\u667a\u80fd\u4ee3\u7406\u5728\u5730\u7406\u533a\u57df\u4fa6\u5bdf\u4e2d\u7684\u63a2\u7d22\u4e0e\u5229\u7528\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u5efa\u8bc1\u636e\u5730\u56fe\u6765\u53cd\u6620\u5f53\u524d\u6001\u52bf\u7406\u89e3\uff0c\u5e76\u6301\u7eed\u66f4\u65b0\u4ee5\u8ddf\u8e2a\u76ee\u6807\u5bf9\u8c61\u3002", "method": "\u7ed3\u5408Dempster-Shafer\u7406\u8bba\u548c\u9ad8\u65af\u4f20\u611f\u5668\u6a21\u578b\u6784\u5efa\u751f\u6210\u6a21\u578b\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u65b9\u6cd5\u66f4\u65b0\u540e\u9a8c\u6982\u7387\u5206\u5e03\uff0c\u901a\u8fc7\u8ba1\u7b97\u53d8\u5206\u81ea\u7531\u80fd\u91cf\u6765\u6307\u5bfc\u4ee3\u7406\u79fb\u52a8\uff0c\u9009\u62e9\u6700\u5c0f\u5316\u81ea\u7531\u80fd\u91cf\u7684\u4f4d\u7f6e\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e73\u8861\u5bf9\u5730\u7406\u533a\u57df\u7684\u5927\u8303\u56f4\u641c\u7d22\u4e0e\u5bf9\u5df2\u8bc6\u522b\u76ee\u6807\u5bf9\u8c61\u7684\u8ddf\u8e2a\uff0c\u901a\u8fc7\u8bc1\u636e\u6269\u6563\u548c\u81ea\u7531\u80fd\u91cf\u6700\u5c0f\u5316\u5b9e\u73b0\u667a\u80fd\u8def\u5f84\u89c4\u5212\u3002", "conclusion": "\u4e3b\u52a8\u63a8\u7406\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u4e3a\u81ea\u4e3b\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4fa6\u5bdf\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u6743\u8861\u95ee\u9898\uff0c\u5728\u6a21\u62df\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2510.17463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17463", "abs": "https://arxiv.org/abs/2510.17463", "authors": ["Cor Steging", "Tadeusz Zbiegie\u0144"], "title": "Label Indeterminacy in AI & Law", "comment": "This manuscript has been accepted for presentation as a short paper\n  at the 38th International Conference on Legal Knowledge and Information\n  Systems (JURIX) in Turin, December 9 to 11 of 2025", "summary": "Machine learning is increasingly used in the legal domain, where it typically\noperates retrospectively by treating past case outcomes as ground truth.\nHowever, legal outcomes are often shaped by human interventions that are not\ncaptured in most machine learning approaches. A final decision may result from\na settlement, an appeal, or other procedural actions. This creates label\nindeterminacy: the outcome could have been different if the intervention had or\nhad not taken place. We argue that legal machine learning applications need to\naccount for label indeterminacy. Methods exist that can impute these\nindeterminate labels, but they are all grounded in unverifiable assumptions. In\nthe context of classifying cases from the European Court of Human Rights, we\nshow that the way that labels are constructed during training can significantly\naffect model behaviour. We therefore position label indeterminacy as a relevant\nconcern in AI & Law and demonstrate how it can shape model behaviour.", "AI": {"tldr": "\u6cd5\u5f8b\u673a\u5668\u5b66\u4e60\u9700\u8981\u5904\u7406\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\uff0c\u56e0\u4e3a\u6cd5\u5f8b\u7ed3\u679c\u5f80\u5f80\u53d7\u5230\u4eba\u4e3a\u5e72\u9884\u5f71\u54cd\uff0c\u5bfc\u81f4\u540c\u4e00\u6848\u4ef6\u53ef\u80fd\u6709\u4e0d\u540c\u7ed3\u679c\u3002", "motivation": "\u6cd5\u5f8b\u673a\u5668\u5b66\u4e60\u901a\u5e38\u5c06\u8fc7\u53bb\u6848\u4ef6\u7ed3\u679c\u89c6\u4e3a\u7edd\u5bf9\u771f\u5b9e\uff0c\u4f46\u6cd5\u5f8b\u7ed3\u679c\u5e38\u53d7\u548c\u89e3\u3001\u4e0a\u8bc9\u7b49\u4eba\u4e3a\u5e72\u9884\u5f71\u54cd\uff0c\u9020\u6210\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u5728\u6b27\u6d32\u4eba\u6743\u6cd5\u9662\u6848\u4ef6\u5206\u7c7b\u4e2d\uff0c\u7814\u7a76\u6807\u7b7e\u6784\u5efa\u65b9\u5f0f\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\uff0c\u4f7f\u7528\u73b0\u6709\u65b9\u6cd5\u4f30\u7b97\u4e0d\u786e\u5b9a\u6807\u7b7e\u3002", "result": "\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6807\u7b7e\u7684\u6784\u5efa\u65b9\u5f0f\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\uff0c\u4e0d\u540c\u6807\u7b7e\u5904\u7406\u65b9\u6cd5\u5bfc\u81f4\u4e0d\u540c\u6a21\u578b\u8868\u73b0\u3002", "conclusion": "\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u662fAI\u4e0e\u6cd5\u5f8b\u9886\u57df\u7684\u91cd\u8981\u5173\u6ce8\u70b9\uff0c\u9700\u8981\u5728\u6cd5\u5f8b\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e2d\u4e88\u4ee5\u8003\u8651\u3002"}}
{"id": "2510.17590", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.CY", "cs.LG", "I.2.7; H.3.3; I.4.9"], "pdf": "https://arxiv.org/pdf/2510.17590", "abs": "https://arxiv.org/abs/2510.17590", "authors": ["Mir Nafis Sharear Shopnil", "Sharad Duwal", "Abhishek Tyagi", "Adiba Mahbub Proma"], "title": "MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning", "comment": "16 pages, 3 tables, 1 figure", "summary": "Misinformation spreads across web platforms through billions of daily\nmultimodal posts that combine text and images, overwhelming manual\nfact-checking capacity. Supervised detection models require domain-specific\ntraining data and fail to generalize across diverse manipulation tactics. We\npresent MIRAGE, an inference-time, model-pluggable agentic framework that\ndecomposes multimodal verification into four sequential modules: visual\nveracity assessment detects AI-generated images, cross-modal consistency\nanalysis identifies out-of-context repurposing, retrieval-augmented factual\nchecking grounds claims in web evidence through iterative question generation,\nand a calibrated judgment module integrates all signals. MIRAGE orchestrates\nvision-language model reasoning with targeted web retrieval, outputs structured\nand citation-linked rationales. On MMFakeBench validation set (1,000 samples),\nMIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming\nthe strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65\npoints while maintaining 34.3% false positive rate versus 97.3% for a\njudge-only baseline. Test set results (5,000 samples) confirm generalization\nwith 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification\ncontributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97\npoints. Our results demonstrate that decomposed agentic reasoning with web\nretrieval can match supervised detector performance without domain-specific\ntraining, enabling misinformation detection across modalities where labeled\ndata remains scarce.", "AI": {"tldr": "MIRAGE\u662f\u4e00\u4e2a\u63a8\u7406\u65f6\u3001\u6a21\u578b\u53ef\u63d2\u62d4\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u591a\u6a21\u6001\u9a8c\u8bc1\u4e3a\u56db\u4e2a\u6a21\u5757\u6765\u68c0\u6d4b\u7f51\u7edc\u865a\u5047\u4fe1\u606f\uff0c\u65e0\u9700\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u6570\u636e\u5373\u53ef\u8fbe\u5230\u76d1\u7763\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u3002", "motivation": "\u7f51\u7edc\u5e73\u53f0\u4e0a\u6bcf\u5929\u6709\u6570\u5341\u4ebf\u7ed3\u5408\u6587\u672c\u548c\u56fe\u50cf\u7684\u591a\u6a21\u6001\u5e16\u5b50\u4f20\u64ad\u865a\u5047\u4fe1\u606f\uff0c\u8d85\u51fa\u4eba\u5de5\u4e8b\u5b9e\u6838\u67e5\u80fd\u529b\u3002\u76d1\u7763\u68c0\u6d4b\u6a21\u578b\u9700\u8981\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u6570\u636e\uff0c\u4e14\u65e0\u6cd5\u6cdb\u5316\u5230\u591a\u6837\u5316\u7684\u64cd\u7eb5\u7b56\u7565\u3002", "method": "MIRAGE\u6846\u67b6\u5c06\u591a\u6a21\u6001\u9a8c\u8bc1\u5206\u89e3\u4e3a\u56db\u4e2a\u987a\u5e8f\u6a21\u5757\uff1a\u89c6\u89c9\u771f\u5b9e\u6027\u8bc4\u4f30\u68c0\u6d4bAI\u751f\u6210\u56fe\u50cf\u3001\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u5206\u6790\u8bc6\u522b\u4e0a\u4e0b\u6587\u4e0d\u5f53\u4f7f\u7528\u3001\u68c0\u7d22\u589e\u5f3a\u7684\u4e8b\u5b9e\u68c0\u67e5\u901a\u8fc7\u8fed\u4ee3\u95ee\u9898\u751f\u6210\u5c06\u58f0\u660e\u57fa\u4e8e\u7f51\u7edc\u8bc1\u636e\u3001\u6821\u51c6\u5224\u65ad\u6a21\u5757\u6574\u5408\u6240\u6709\u4fe1\u53f7\u3002", "result": "\u5728MMFakeBench\u9a8c\u8bc1\u96c6\u4e0a\uff0cMIRAGE\u4e0eGPT-4o-mini\u7ec4\u5408\u8fbe\u523081.65% F1\u5206\u6570\u548c75.1%\u51c6\u786e\u7387\uff0c\u6bd4\u6700\u5f3a\u7684\u96f6\u6837\u672c\u57fa\u7ebf\uff08GPT-4V\u4e0eMMD-Agent\u768474.0% F1\uff09\u9ad8\u51fa7.65\u70b9\uff0c\u540c\u65f6\u4fdd\u630134.3%\u7684\u5047\u9633\u6027\u7387\uff0c\u8fdc\u4f4e\u4e8e\u4ec5\u5224\u65ad\u57fa\u7ebf\u768497.3%\u3002\u6d4b\u8bd5\u96c6\u7ed3\u679c\u786e\u8ba4\u4e86\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5206\u89e3\u7684\u4ee3\u7406\u63a8\u7406\u4e0e\u7f51\u7edc\u68c0\u7d22\u76f8\u7ed3\u5408\uff0c\u53ef\u4ee5\u5728\u6ca1\u6709\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5339\u914d\u76d1\u7763\u68c0\u6d4b\u5668\u7684\u6027\u80fd\uff0c\u5728\u6807\u8bb0\u6570\u636e\u7a00\u7f3a\u7684\u591a\u6a21\u6001\u573a\u666f\u4e2d\u5b9e\u73b0\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u3002"}}
{"id": "2510.17598", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17598", "abs": "https://arxiv.org/abs/2510.17598", "authors": ["Amir Jalilifard", "Anderson de Rezende Rocha", "Marcos Medeiros Raimundo"], "title": "Reasoning Distillation and Structural Alignment for Improved Code Generation", "comment": null, "summary": "Effective code generation with language models hinges on two critical\nfactors: accurately understanding the intent of the prompt and generating code\nthat applies algorithmic reasoning to produce correct solutions capable of\npassing diverse test cases while adhering to the syntax of the target\nprogramming language. Unlike other language tasks, code generation requires\nmore than accurate token prediction; it demands comprehension of solution-level\nand structural relationships rather than merely generating the most likely\ntokens. very large language model (VLLM) are capable of generating detailed\nsteps toward the correct solution of complex tasks where reasoning is crucial\nin solving the problem. Such reasoning capabilities may be absent in smaller\nlanguage models. Therefore, in this work, we distill the reasoning capabilities\nof a VLLM into a smaller, more efficient model that is faster and cheaper to\ndeploy. Our approach trains the model to emulate the reasoning and\nproblem-solving abilities of the VLLM by learning to identify correct solution\npathways and establishing a structural correspondence between problem\ndefinitions and potential solutions through a novel method of structure-aware\nloss optimization. This enables the model to transcend token-level generation\nand to deeply grasp the overarching structure of solutions for given problems.\nExperimental results show that our fine-tuned model, developed through a cheap\nand simple to implement process, significantly outperforms our baseline model\nin terms of pass@1, average data flow, and average syntax match metrics across\nthe MBPP, MBPP Plus, and HumanEval benchmarks.", "AI": {"tldr": "\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u66f4\u5c0f\u3001\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u635f\u5931\u4f18\u5316\u65b9\u6cd5\uff0c\u4f7f\u5c0f\u6a21\u578b\u80fd\u591f\u7406\u89e3\u95ee\u9898\u4e0e\u89e3\u51b3\u65b9\u6848\u4e4b\u95f4\u7684\u7ed3\u6784\u5bf9\u5e94\u5173\u7cfb\uff0c\u4ece\u800c\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u6709\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u90e8\u7f72\u6210\u672c\u9ad8\u4e14\u6548\u7387\u4f4e\u3002\u5c0f\u6a21\u578b\u7f3a\u4e4f\u8fd9\u79cd\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u5c06\u5927\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u5c0f\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u4ee3\u7801\u751f\u6210\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u611f\u77e5\u635f\u5931\u4f18\u5316\u65b9\u6cd5\uff0c\u8bad\u7ec3\u5c0f\u6a21\u578b\u6a21\u62df\u5927\u6a21\u578b\u7684\u63a8\u7406\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u5b66\u4e60\u8bc6\u522b\u6b63\u786e\u7684\u89e3\u51b3\u8def\u5f84\uff0c\u5efa\u7acb\u95ee\u9898\u5b9a\u4e49\u4e0e\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u4e4b\u95f4\u7684\u7ed3\u6784\u5bf9\u5e94\u5173\u7cfb\u3002", "result": "\u5728MBPP\u3001MBPP Plus\u548cHumanEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7ecf\u8fc7\u5fae\u8c03\u7684\u6a21\u578b\u5728pass@1\u3001\u5e73\u5747\u6570\u636e\u6d41\u548c\u5e73\u5747\u8bed\u6cd5\u5339\u914d\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u7b80\u5355\u4e14\u4f4e\u6210\u672c\u7684\u84b8\u998f\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u6210\u529f\u5c06\u5927\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u8f6c\u79fb\u5230\u5c0f\u6a21\u578b\u4e2d\uff0c\u4f7f\u5176\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u540c\u65f6\u4fdd\u6301\u90e8\u7f72\u6548\u7387\u548c\u6210\u672c\u4f18\u52bf\u3002"}}
{"id": "2510.17614", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.17614", "abs": "https://arxiv.org/abs/2510.17614", "authors": ["Praphul Singh", "Corey Barrett", "Sumana Srivasta", "Irfan Bulu", "Sri Gadde", "Krishnaram Kenthapadi"], "title": "OG-Rank: Learning to Rank Fast and Slow with Uncertainty and Reward-Trend Guided Adaptive Exploration", "comment": null, "summary": "Clinicians need ranking systems that work in real time and still justify\ntheir choices. Motivated by the need for a low-latency, decoder-based reranker,\nwe present OG-Rank, a single-decoder approach that pairs a pooled first-token\nscoring signal with an uncertainty-gated explanation step. The model scores all\ncandidates in one pass and generates a brief, structured rationale only when\nthe list is genuinely ambiguous, keeping latency predictable. Trained with a\ncurriculum that concentrates effort on hard cases, OG-Rank delivers strong\neffectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,\nnDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,\nnDCG@20~0.699 at a 45\\% gate rate), while compact backbones show similar gains\nunder the same policy. Encoder baselines trail in both effectiveness and\nflexibility. The result is a practical recipe: rank fast by default and explain\nwhen it helps, a pattern that applies broadly to decision tasks where selective\ngeneration buys accuracy at acceptable cost. The single-policy design\nsimplifies deployment and budget planning, and the curriculum principle (spend\nmore on the hard cases, less on the easy ones) readily transfers beyond\nclinical order selection.", "AI": {"tldr": "OG-Rank\u662f\u4e00\u4e2a\u4f4e\u5ef6\u8fdf\u7684\u89e3\u7801\u5668\u91cd\u6392\u5e8f\u7cfb\u7edf\uff0c\u901a\u8fc7\u5355\u6b21\u8bc4\u5206\u548c\u4e0d\u786e\u5b9a\u6027\u95e8\u63a7\u89e3\u91ca\u6b65\u9aa4\uff0c\u5728\u4fdd\u6301\u53ef\u9884\u6d4b\u5ef6\u8fdf\u7684\u540c\u65f6\u63d0\u4f9b\u6392\u540d\u548c\u9009\u62e9\u6027\u89e3\u91ca\u3002", "motivation": "\u4e34\u5e8a\u533b\u751f\u9700\u8981\u5b9e\u65f6\u5de5\u4f5c\u5e76\u80fd\u89e3\u91ca\u5176\u9009\u62e9\u7684\u6392\u540d\u7cfb\u7edf\uff0c\u9700\u8981\u4f4e\u5ef6\u8fdf\u7684\u89e3\u7801\u5668\u91cd\u6392\u5e8f\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5355\u89e3\u7801\u5668\u65b9\u6cd5\uff0c\u7ed3\u5408\u6c60\u5316\u9996\u8bcd\u8bc4\u5206\u4fe1\u53f7\u548c\u4e0d\u786e\u5b9a\u6027\u95e8\u63a7\u89e3\u91ca\u6b65\u9aa4\uff0c\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u4e13\u6ce8\u4e8e\u56f0\u96be\u6848\u4f8b\u8bad\u7ec3\u3002", "result": "\u5728\u4e34\u5e8a\u533b\u5631\u9009\u62e9\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff08\u5feb\u901f\u8def\u5f84\uff1aRecall@1~0.45\uff0cnDCG@20~0.625\uff09\uff0c\u5f53\u95e8\u63a7\u6fc0\u6d3b\u65f6\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\uff08Recall@1~0.56\uff0cnDCG@20~0.699\uff0c\u95e8\u63a7\u738745%\uff09\u3002", "conclusion": "OG-Rank\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u65b9\u6848\uff1a\u9ed8\u8ba4\u5feb\u901f\u6392\u540d\uff0c\u5728\u9700\u8981\u65f6\u63d0\u4f9b\u89e3\u91ca\uff0c\u8fd9\u79cd\u6a21\u5f0f\u9002\u7528\u4e8e\u9700\u8981\u9009\u62e9\u6027\u751f\u6210\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u51b3\u7b56\u4efb\u52a1\u3002"}}
{"id": "2510.17638", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17638", "abs": "https://arxiv.org/abs/2510.17638", "authors": ["Qingchuan Yang", "Simon Mahns", "Sida Li", "Anri Gu", "Jibang Wu", "Haifeng Xu"], "title": "LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena", "comment": "https://www.prophetarena.co/", "summary": "Forecasting is not only a fundamental intellectual pursuit but also is of\nsignificant importance to societal systems such as finance and economics. With\nthe rapid advances of large language models (LLMs) trained on Internet-scale\ndata, it raises the promise of employing LLMs to forecast real-world future\nevents, an emerging paradigm we call \"LLM-as-a-Prophet\". This paper\nsystematically investigates such predictive intelligence of LLMs. To this end,\nwe build Prophet Arena, a general evaluation benchmark that continuously\ncollects live forecasting tasks and decomposes each task into distinct pipeline\nstages, in order to support our controlled and large-scale experimentation. Our\ncomprehensive evaluation reveals that many LLMs already exhibit impressive\nforecasting capabilities, reflected in, e.g., their small calibration errors,\nconsistent prediction confidence and promising market returns. However, we also\nuncover key bottlenecks towards achieving superior predictive intelligence via\nLLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of\ndata sources and slower information aggregation compared to markets when\nresolution nears.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u9884\u6d4b\u5de5\u5177\u7684\u80fd\u529b\uff0c\u53d1\u73b0LLMs\u5df2\u5177\u5907\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4f46\u5b58\u5728\u4e8b\u4ef6\u56de\u5fc6\u4e0d\u51c6\u786e\u3001\u6570\u636e\u6e90\u8bef\u89e3\u7b49\u5173\u952e\u74f6\u9888\u3002", "motivation": "\u968f\u7740\u5728\u4e92\u8054\u7f51\u89c4\u6a21\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u7814\u7a76\u5229\u7528LLMs\u9884\u6d4b\u73b0\u5b9e\u4e16\u754c\u672a\u6765\u4e8b\u4ef6\u7684\u6f5c\u529b\uff0c\u8fd9\u4e00\u65b0\u5174\u8303\u5f0f\u88ab\u79f0\u4e3a'LLM-as-a-Prophet'\u3002", "method": "\u6784\u5efa\u4e86Prophet Arena\u8bc4\u4f30\u57fa\u51c6\uff0c\u6301\u7eed\u6536\u96c6\u5b9e\u65f6\u9884\u6d4b\u4efb\u52a1\u5e76\u5c06\u6bcf\u4e2a\u4efb\u52a1\u5206\u89e3\u4e3a\u4e0d\u540c\u7684\u6d41\u6c34\u7ebf\u9636\u6bb5\uff0c\u652f\u6301\u53d7\u63a7\u548c\u5927\u89c4\u6a21\u5b9e\u9a8c\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u8bb8\u591aLLMs\u5df2\u5c55\u73b0\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u8868\u73b0\u4e3a\u8f83\u5c0f\u7684\u6821\u51c6\u8bef\u5dee\u3001\u4e00\u81f4\u7684\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u548c\u6709\u524d\u666f\u7684\u5e02\u573a\u56de\u62a5\u3002", "conclusion": "\u867d\u7136LLMs\u5177\u5907\u9884\u6d4b\u6f5c\u529b\uff0c\u4f46\u5728\u5b9e\u73b0\u5353\u8d8a\u9884\u6d4b\u667a\u80fd\u65b9\u9762\u4ecd\u5b58\u5728\u5173\u952e\u74f6\u9888\uff0c\u5305\u62ec\u4e8b\u4ef6\u56de\u5fc6\u4e0d\u51c6\u786e\u3001\u6570\u636e\u6e90\u8bef\u89e3\u4ee5\u53ca\u5728\u63a5\u8fd1\u51b3\u7b56\u65f6\u4fe1\u606f\u805a\u5408\u901f\u5ea6\u6162\u4e8e\u5e02\u573a\u7b49\u95ee\u9898\u3002"}}
{"id": "2510.17697", "categories": ["cs.AI", "cs.LG", "cs.MA", "I.2.11; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.17697", "abs": "https://arxiv.org/abs/2510.17697", "authors": ["Anjie Liu", "Jianhong Wang", "Samuel Kaski", "Jun Wang", "Mengyue Yang"], "title": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "comment": "Accepted to NeurIPS 2025", "summary": "Steering cooperative multi-agent reinforcement learning (MARL) towards\ndesired outcomes is challenging, particularly when the global guidance from a\nhuman on the whole multi-agent system is impractical in a large-scale MARL. On\nthe other hand, designing mechanisms to coordinate agents most relies on\nempirical studies, lacking a easy-to-use research tool. In this work, we employ\nmulti-agent influence diagrams (MAIDs) as a graphical framework to address the\nabove issues. First, we introduce interaction paradigms that leverage MAIDs to\nanalyze and visualize existing approaches in MARL. Then, we design a new\ninteraction paradigm based on MAIDs, referred to as targeted intervention that\nis applied to only a single targeted agent, so the problem of global guidance\ncan be mitigated. In our implementation, we introduce a causal inference\ntechnique-referred to as Pre-Strategy Intervention (PSI)-to realize the\ntargeted intervention paradigm. Since MAIDs can be regarded as a special class\nof causal diagrams, a composite desired outcome that integrates the primary\ntask goal and an additional desired outcome can be achieved by maximizing the\ncorresponding causal effect through the PSI. Moreover, the bundled relevance\ngraph analysis of MAIDs provides a tool to identify whether an MARL learning\nparadigm is workable under the design of an interaction paradigm. In\nexperiments, we demonstrate the effectiveness of our proposed targeted\nintervention, and verify the result of relevance graph analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f71\u54cd\u56fe(MAIDs)\u7684\u65b0\u4ea4\u4e92\u8303\u5f0f\u2014\u2014\u76ee\u6807\u5e72\u9884\uff0c\u901a\u8fc7\u4ec5\u5bf9\u5355\u4e2a\u76ee\u6807\u667a\u80fd\u4f53\u8fdb\u884c\u5e72\u9884\u6765\u7f13\u89e3\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u5168\u5c40\u6307\u5bfc\u4e0d\u5207\u5b9e\u9645\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u5bf9\u6574\u4e2a\u7cfb\u7edf\u8fdb\u884c\u5168\u5c40\u4eba\u5de5\u6307\u5bfc\u4e0d\u5207\u5b9e\u9645\uff0c\u800c\u73b0\u6709\u7684\u534f\u8c03\u673a\u5236\u8bbe\u8ba1\u4e3b\u8981\u4f9d\u8d56\u7ecf\u9a8c\u7814\u7a76\uff0c\u7f3a\u4e4f\u6613\u7528\u7684\u7814\u7a76\u5de5\u5177\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u5f71\u54cd\u56fe(MAIDs)\u4f5c\u4e3a\u56fe\u5f62\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u76ee\u6807\u5e72\u9884\u8303\u5f0f\uff0c\u5e76\u5f15\u5165\u9884\u7b56\u7565\u5e72\u9884(PSI)\u56e0\u679c\u63a8\u7406\u6280\u672f\u6765\u5b9e\u73b0\u8be5\u8303\u5f0f\u3002\u901a\u8fc7\u6700\u5927\u5316\u76f8\u5e94\u7684\u56e0\u679c\u6548\u5e94\u6765\u8fbe\u6210\u590d\u5408\u671f\u671b\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u76ee\u6807\u5e72\u9884\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u76f8\u5173\u6027\u56fe\u5206\u6790\u7684\u7ed3\u679c\u3002", "conclusion": "MAIDs\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u6846\u67b6\u6765\u5206\u6790\u548c\u53ef\u89c6\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u76ee\u6807\u5e72\u9884\u8303\u5f0f\u80fd\u591f\u6709\u6548\u7f13\u89e3\u5168\u5c40\u6307\u5bfc\u95ee\u9898\uff0cPSI\u6280\u672f\u80fd\u591f\u6210\u529f\u5b9e\u73b0\u671f\u671b\u7684\u7ed3\u679c\u5bfc\u5411\u3002"}}
{"id": "2510.17705", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17705", "abs": "https://arxiv.org/abs/2510.17705", "authors": ["Dayan Pan", "Zhaoyang Fu", "Jingyuan Wang", "Xiao Han", "Yue Zhu", "Xiangyu Zhao"], "title": "Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models", "comment": "Accepted by CIKM' 25", "summary": "Large Language Models (LLMs) possess remarkable generalization capabilities\nbut struggle with multi-task adaptation, particularly in balancing knowledge\nretention with task-specific specialization. Conventional fine-tuning methods\nsuffer from catastrophic forgetting and substantial resource consumption, while\nexisting parameter-efficient methods perform suboptimally in complex multi-task\nscenarios. To address this, we propose Contextual Attention Modulation (CAM), a\nnovel mechanism that dynamically modulates the representations of\nself-attention modules in LLMs. CAM enhances task-specific features while\npreserving general knowledge, thereby facilitating more effective and efficient\nadaptation. For effective multi-task adaptation, CAM is integrated into our\nHybrid Contextual Attention Modulation (HyCAM) framework, which combines a\nshared, full-parameter CAM module with multiple specialized, lightweight CAM\nmodules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.\nExtensive experiments on heterogeneous tasks, including question answering,\ncode generation, and logical reasoning, demonstrate that our approach\nsignificantly outperforms existing approaches, achieving an average performance\nimprovement of 3.65%. The implemented code and data are available to ease\nreproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM.", "AI": {"tldr": "\u63d0\u51faContextual Attention Modulation (CAM)\u673a\u5236\u548cHyCAM\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u8282\u81ea\u6ce8\u610f\u529b\u8868\u793a\u6765\u589e\u5f3a\u4efb\u52a1\u7279\u5b9a\u7279\u5f81\u5e76\u4fdd\u7559\u901a\u7528\u77e5\u8bc6\uff0c\u5728\u591a\u4efb\u52a1\u9002\u5e94\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4efb\u52a1\u9002\u5e94\u4e2d\u5b58\u5728\u77e5\u8bc6\u4fdd\u7559\u4e0e\u4efb\u52a1\u4e13\u95e8\u5316\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u548c\u8d44\u6e90\u6d88\u8017\u5927\u7684\u7f3a\u9677\uff0c\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\u5728\u590d\u6742\u591a\u4efb\u52a1\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faCAM\u673a\u5236\u52a8\u6001\u8c03\u8282\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u8868\u793a\uff0c\u5e76\u6784\u5efaHyCAM\u6846\u67b6\uff0c\u7ed3\u5408\u5171\u4eab\u7684\u5168\u53c2\u6570CAM\u6a21\u5757\u548c\u591a\u4e2a\u8f7b\u91cf\u7ea7\u4e13\u7528CAM\u6a21\u5757\uff0c\u91c7\u7528\u52a8\u6001\u8def\u7531\u7b56\u7565\u8fdb\u884c\u81ea\u9002\u5e94\u77e5\u8bc6\u878d\u5408\u3002", "result": "\u5728\u95ee\u7b54\u3001\u4ee3\u7801\u751f\u6210\u548c\u903b\u8f91\u63a8\u7406\u7b49\u5f02\u6784\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5e73\u5747\u6027\u80fd\u63d0\u53473.65%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CAM\u548cHyCAM\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4efb\u52a1\u9002\u5e94\u4e2d\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u77e5\u8bc6\u4fdd\u7559\u4e0e\u4efb\u52a1\u4e13\u95e8\u5316\u5e73\u8861\u3002"}}
{"id": "2510.17771", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17771", "abs": "https://arxiv.org/abs/2510.17771", "authors": ["Zhining Liu", "Ziyi Chen", "Hui Liu", "Chen Luo", "Xianfeng Tang", "Suhang Wang", "Joy Zeng", "Zhenwei Dai", "Zhan Shi", "Tianxin Wei", "Benoit Dumoulin", "Hanghang Tong"], "title": "Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs", "comment": "21 pages, 10 figures, 6 tables", "summary": "Vision-Language Models (VLMs) achieve strong results on multimodal tasks such\nas visual question answering, yet they can still fail even when the correct\nvisual evidence is present. In this work, we systematically investigate whether\nthese failures arise from not perceiving the evidence or from not leveraging it\neffectively. By examining layer-wise attention dynamics, we find that shallow\nlayers focus primarily on text, while deeper layers sparsely but reliably\nattend to localized evidence regions. Surprisingly, VLMs often perceive the\nvisual evidence when outputting incorrect answers, a phenomenon we term\n``seeing but not believing'' that widely exists in major VLM families. Building\non this, we introduce an inference-time intervention that highlights deep-layer\nevidence regions through selective attention-based masking. It requires no\ntraining and consistently improves accuracy across multiple families, including\nLLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable\nevidence internally but under-utilize it, making such signals explicit can\nbridge the gap between perception and reasoning, advancing the diagnostic\nunderstanding and reliability of VLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u5b58\u5728\"\u770b\u89c1\u4f46\u4e0d\u76f8\u4fe1\"\u73b0\u8c61\uff0c\u5373\u6a21\u578b\u80fd\u611f\u77e5\u5230\u6b63\u786e\u7684\u89c6\u89c9\u8bc1\u636e\u4f46\u4ecd\u8f93\u51fa\u9519\u8bef\u7b54\u6848\u3002\u901a\u8fc7\u5206\u6790\u6ce8\u610f\u529b\u52a8\u6001\uff0c\u53d1\u73b0\u6df1\u5c42\u6ce8\u610f\u529b\u80fd\u53ef\u9760\u5b9a\u4f4d\u8bc1\u636e\u533a\u57df\u3002\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u7684\u63a8\u7406\u65f6\u5e72\u9884\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u63a9\u7801\u589e\u5f3a\u8bc1\u636e\u5229\u7528\uff0c\u663e\u8457\u63d0\u5347\u591a\u4e2aVLM\u5bb6\u65cf\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5c3d\u7ba1\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5b83\u4eec\u4ecd\u4f1a\u5728\u6b63\u786e\u89c6\u89c9\u8bc1\u636e\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u5931\u8d25\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u6027\u5730\u63a2\u7a76\u8fd9\u4e9b\u5931\u8d25\u662f\u7531\u4e8e\u672a\u611f\u77e5\u8bc1\u636e\u8fd8\u662f\u672a\u6709\u6548\u5229\u7528\u8bc1\u636e\u5bfc\u81f4\u7684\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5c42\u95f4\u6ce8\u610f\u529b\u52a8\u6001\uff0c\u53d1\u73b0\u6d45\u5c42\u4e3b\u8981\u5173\u6ce8\u6587\u672c\uff0c\u6df1\u5c42\u7a00\u758f\u4f46\u53ef\u9760\u5730\u5173\u6ce8\u5c40\u90e8\u8bc1\u636e\u533a\u57df\u3002\u63d0\u51fa\u63a8\u7406\u65f6\u5e72\u9884\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6ce8\u610f\u529b\u63a9\u7801\u6765\u7a81\u51fa\u6df1\u5c42\u8bc1\u636e\u533a\u57df\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5e94\u7528\u3002", "result": "\u53d1\u73b0VLMs\u666e\u904d\u5b58\u5728\"\u770b\u89c1\u4f46\u4e0d\u76f8\u4fe1\"\u73b0\u8c61\uff0c\u6a21\u578b\u5185\u90e8\u7f16\u7801\u4e86\u53ef\u9760\u7684\u8bc1\u636e\u4f46\u672a\u5145\u5206\u5229\u7528\u3002\u63d0\u51fa\u7684\u5e72\u9884\u65b9\u6cd5\u5728LLaVA\u3001Qwen\u3001Gemma\u548cInternVL\u7b49\u591a\u4e2aVLM\u5bb6\u65cf\u4e0a\u4e00\u81f4\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "VLMs\u5728\u5185\u90e8\u7f16\u7801\u4e86\u53ef\u9760\u7684\u8bc1\u636e\u4fe1\u53f7\u4f46\u672a\u5145\u5206\u5229\u7528\uff0c\u901a\u8fc7\u4f7f\u8fd9\u4e9b\u4fe1\u53f7\u663e\u5f0f\u5316\u53ef\u4ee5\u5f25\u5408\u611f\u77e5\u4e0e\u63a8\u7406\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63a8\u8fdb\u5bf9VLM\u7684\u8bca\u65ad\u7406\u89e3\u548c\u53ef\u9760\u6027\u63d0\u5347\u3002"}}
