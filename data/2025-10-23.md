<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 18]
- [cs.CR](#cs.CR) [Total: 21]
- [cs.AI](#cs.AI) [Total: 24]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [CosmoCore Affective Dream-Replay Reinforcement Learning for Code Generation](https://arxiv.org/abs/2510.18895)
*Santhosh Kumar Ravindran*

Main category: cs.SE

TL;DR: CosmoCore是一个受神经科学启发的强化学习架构，通过整合情感信号来增强大语言模型的代码生成能力，显著减少幻觉代码并加速自我修正。


<details>
  <summary>Details</summary>
Motivation: 受人类和动物学习的启发，特别是从错误中感到尴尬从而快速纠正的行为（如训练小狗避免重复错误），旨在将情感信号整合到代码生成中以提高学习效率。

Method: 使用轻量级多层感知机(MLP)为代码生成轨迹标记情感效价和惊喜度，将高负效价(尴尬)的代码片段优先放入Dream Queue进行五倍重放，同时修剪低惊喜度的成功案例以防止过度自信和缓冲区膨胀。

Result: 在HumanEval和BigCodeBench等代码生成基准测试中，CosmoCore将幻觉代码（如语法错误或逻辑错误）减少了48%，自我修正速度提高了45%。

Conclusion: 该框架扩展了基于人类反馈的强化学习(RLHF)，为代码助手提供更情感感知的能力，在IDE和数据管道中具有应用前景。

Abstract: We introduce CosmoCore, a neuroscience-inspired reinforcement learning (RL)
architecture that integrates affective signals to enhance code generation in
large language models (LLMs). Motivated by human and animal learning where
embarrassment from mistakes drives rapid correction, as observed in training a
puppy to avoid repeating errors after a single scolding CosmoCore tags code
generation trajectories with valence and surprise using a lightweight
multi-layer perceptron (MLP). High-negative valence (cringe) episodes, such as
buggy code outputs, are prioritized in a Dream Queue for five-fold replay
during off-policy updates, while low-surprise successes are pruned to prevent
overconfidence and buffer bloat. Evaluated on code generation benchmarks like
HumanEval and BigCodeBench, alongside simulations with a custom data pipeline
environment, CosmoCore reduces hallucinated code (e.g., syntax errors or
logical bugs) by 48\% and accelerates self-correction by 45\%. Local
experiments using Hugging Face models in a PySpark environment validate these
gains, with code snippets provided for replication. Ablations confirm valence
tagging boosts curiosity in exploration, and pruning mitigates inefficiency.
This framework extends RL from human feedback (RLHF) for more emotionally aware
code assistants, with applications in IDEs and data pipelines. Code and the
custom mini-world simulation are released.

</details>


### [2] [A Survey on Feedback Types in Automated Programming Assessment Systems](https://arxiv.org/abs/2510.18923)
*Eduard Frankford,Tobias Antensteiner,Michael Vierhauser,Clemens Sauerwein,Vivien Wallner,Iris Groher,Reinhold Plösch,Ruth Breu*

Main category: cs.SE

TL;DR: 该研究比较了编程自动评估系统中不同反馈机制的效果，发现单元测试反馈最受学生欢迎，但AI生成的反馈能显著提升学生表现，建议结合两种方法优化编程教育。


<details>
  <summary>Details</summary>
Motivation: 随着编程课程需求增加，需要自动化评估系统来提供可扩展的评估和即时反馈。传统基于单元测试的反馈存在局限性，而大语言模型为提升反馈质量和个性化提供了新机会。

Method: 对来自两所大学的200多名学生进行大规模研究，比较编译器反馈、标准单元测试反馈和基于LLM的高级反馈在感知质量和学生表现方面的影响。

Result: 学生认为单元测试反馈最有帮助，但AI生成的反馈能显著提高学生表现。

Conclusion: 建议结合单元测试和AI驱动的指导来优化自动反馈机制，改善编程教育的学习成果。

Abstract: With the recent rapid increase in digitization across all major industries,
acquiring programming skills has increased the demand for introductory
programming courses. This has further resulted in universities integrating
programming courses into a wide range of curricula, including not only
technical studies but also business and management fields of study.
  Consequently, additional resources are needed for teaching, grading, and
tutoring students with diverse educational backgrounds and skills. As part of
this, Automated Programming Assessment Systems (APASs) have emerged, providing
scalable and high-quality assessment systems with efficient evaluation and
instant feedback. Commonly, APASs heavily rely on predefined unit tests for
generating feedback, often limiting the scope and level of detail of feedback
that can be provided to students. With the rise of Large Language Models (LLMs)
in recent years, new opportunities have emerged as these technologies can
enhance feedback quality and personalization.
  To investigate how different feedback mechanisms in APASs are perceived by
students, and how effective they are in supporting problem-solving, we have
conducted a large-scale study with over 200 students from two different
universities. Specifically, we compare baseline Compiler Feedback, standard
Unit Test Feedback, and advanced LLM-based Feedback regarding perceived quality
and impact on student performance.
  Results indicate that while students rate unit test feedback as the most
helpful, AI-generated feedback leads to significantly better performances.
These findings suggest combining unit tests and AI-driven guidance to optimize
automated feedback mechanisms and improve learning outcomes in programming
education.

</details>


### [3] [Extending Resource Constrained Project Scheduling to Mega-Projects with Model-Based Systems Engineering & Hetero-functional Graph Theory](https://arxiv.org/abs/2510.19035)
*Amirreza Hosseini,Amro M. Farid*

Main category: cs.SE

TL;DR: 该论文将资源受限项目调度问题与基于模型的系统工程和异质功能图理论相结合，提出了一个从活动节点网络到SysML活动图再到操作数网络的转换流程，并证明RCPSP是该框架的一个特例。


<details>
  <summary>Details</summary>
Motivation: 虽然资源受限项目调度问题是项目管理的核心，但它与基于模型的系统工程文献脱节，限制了其在复杂系统设计和管理中的集成。

Method: 构建从活动节点网络到SysML活动图再到操作数网络的转换流程，并将异质功能网络最小成本流公式专门化到RCPSP环境中。

Result: 在包含可再生和不可再生操作数的示例中，专门的HFNMCF产生相似的调度结果，但提供了项目状态的明确解释，支持更丰富的监控和控制。

Conclusion: 该框架保留了经典RCPSP的优势，同时适应了大型复杂项目中遇到的实际约束和企业级决策过程。

Abstract: Within the project management context, project scheduling serves as an
indispensable component, functioning as a fundamental tool for planning,
monitoring, controlling, and managing projects more broadly. Although the
resource-constrained project scheduling problem (RCPSP) lies at the core of
project management activities, it remains largely disconnected from the broader
literature on model-based systems engineering (MBSE), thereby limiting its
integration into the design and management of complex systems. The original
contribution of this paper is twofold. First, the paper seeks to reconcile the
RCPSP with the broader literature and vocabulary of model-based systems
engineering and hetero-functional graph theory (HFGT). A concrete translation
pipeline from an activity-on-node network to a SysML activity diagram, and then
to an operand net is constructed. Using this representation, it specializes the
hetero-functional network minimum-cost flow (HFNMCF) formulation to the RCPSP
context as a systematic means of HFGT for quantitative analysis and proves that
the RCPSP is recoverable as a special case of a broader model. Secondly, on an
illustrative instance with renewable and non-renewable operands, the
specialized HFNMCF, while producing similar schedules, yields explicit
explanations of the project states that enable richer monitoring and control.
Overall, the framework preserves the strengths of the classical RCPSP while
accommodating real-world constraints and enterprise-level decision processes
encountered in large, complex megaprojects.

</details>


### [4] [Docker-based CI/CD for Rocq/OCaml projects](https://arxiv.org/abs/2510.19089)
*Érik Martin-Dorel*

Main category: cs.SE

TL;DR: 本文介绍了三个紧密相关的软件项目：docker-coq、docker-coq-action和docker-keeper，旨在促进基于Docker的Coq/OCaml项目CI/CD使用，并为未来维护者提供设计文档。


<details>
  <summary>Details</summary>
Motivation: 为Coq（现称Rocq）或OCaml项目提供基于Docker的CI/CD解决方案，同时为这些DevOps工具的未来维护者记录需求和设计选择。

Method: 开发三个相互关联的DevOps工具：docker-coq（Docker镜像）、docker-coq-action（GitHub Action）和docker-keeper（自动化工具），采用Docker容器化技术。

Result: 成功创建了一套完整的Docker-based CI/CD工具链，支持Coq/OCaml项目的自动化构建和测试。

Conclusion: 这些工具为Coq/OCaml社区提供了可靠的CI/CD基础设施，并通过详细文档支持项目的可持续维护和发展。

Abstract: This paper presents three closely-related software projects, namely:
docker-coq, docker-coq-action, and docker-keeper. It aims at two objectives:
provide a high-level description of the available features -- to foster the use
of a Docker-based CI/CD for Rocq (formerly known as Coq) or OCaml projects --
and document the underlying requirements and the main design choices of these
three DevOps tools -- to help their future maintainers.

</details>


### [5] [Automated Concern Extraction from Textual Requirements of Cyber-Physical Systems: A Multi-solution Study](https://arxiv.org/abs/2510.19237)
*Dongming Jin,Zhi Jin,Xiaohong Chen,Zheng Fang,Linyu Li,Shengxin Zhao,Chuihui Wang,Hongbin Xiao*

Main category: cs.SE

TL;DR: 提出了ReqEBench，一个用于CPS需求关注点提取的新基准，包含2,721个真实CPS需求，覆盖12个系统，用于评估自动化需求关注点提取解决方案的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化需求关注点提取解决方案缺乏公平和全面的基准来评估其有效性，特别是在CPS领域。

Method: 构建ReqEBench基准，包含2,721个来自12个真实世界CPS的需求，经过严格标注过程，覆盖多个应用领域和全面的CPS相关关注点。

Result: 对三类自动化需求关注点提取解决方案进行比较研究，发现GPT-4在实体关注点提取中的最高F1分数仅为0.24，分析了基于LLM的解决方案的失败案例和不足。

Conclusion: ReqEBench将促进自动化需求关注点提取的评估和发展，为改进基于LLM的解决方案提供了思路。

Abstract: Cyber-physical systems (CPSs) are characterized by a deep integration of the
information space and the physical world, which makes the extraction of
requirements concerns more challenging. Some automated solutions for
requirements concern extraction have been proposed to alleviate the burden on
requirements engineers. However, evaluating the effectiveness of these
solutions, which relies on fair and comprehensive benchmarks, remains an open
question. To address this gap, we propose ReqEBench, a new CPSs requirements
concern extraction benchmark, which contains 2,721 requirements from 12
real-world CPSs. ReqEBench offers four advantages. It aligns with real-world
CPSs requirements in multiple dimensions, e.g., scale and complexity. It covers
comprehensive concerns related to CPSs requirements. It undergoes a rigorous
annotation process. It covers multiple application domains of CPSs, e.g.,
aerospace and healthcare. We conducted a comparative study on three types of
automated requirements concern extraction solutions and revealed their
performance in real-world CPSs using our ReqEBench. We found that the highest
F1 score of GPT-4 is only 0.24 in entity concern extraction. We further analyze
failure cases of popular LLM-based solutions, summarize their shortcomings, and
provide ideas for improving their capabilities. We believe ReqEBench will
facilitate the evaluation and development of automated requirements concern
extraction.

</details>


### [6] [A General Solution for the Implementation of CI/CD in Embedded Linux Development](https://arxiv.org/abs/2510.19240)
*Behnam Agahi,Hamed Farbeh*

Main category: cs.SE

TL;DR: 该研究设计并实现了一个基于Yocto项目的集成化、可复现的Linux操作系统开发基础设施，采用三层架构确保版本同步和可扩展性，通过CI/CD流水线和缓存优化显著减少构建时间。


<details>
  <summary>Details</summary>
Motivation: 随着嵌入式系统在各行业的广泛应用，需要自动化平台来开发和部署定制的基于Linux的操作系统，以提高开发效率和系统可靠性。

Method: 采用三层架构：主Yocto仓库、自定义层(meta-custom)和协调清单层；开发了三个示例项目；使用GitLab CI实现CI/CD流水线；结合Docker隔离环境；部署本地缓存服务器优化构建时间。

Result: 构建时间显著减少；通过QEMU模拟器的6个启动测试场景验证了系统功能和稳定性；实现了可复现的构建过程。

Conclusion: 所提出的设计不仅确保可复现性，还可扩展到高级应用如实时Linux版本的持续部署。建议扩展自动化测试、实现系统监控、使用分布式构建等进一步优化。

Abstract: With the growing use of embedded systems in various industries, the need for
automated platforms for the development and deployment of customized
Linux-based operating systems has become more important. This research was
conducted with the aim of designing and implementing an integrated and
reproducible infrastructure for the development, building, and testing of a
Linux-based operating system using the Yocto Project. The proposed structure
was implemented based on a three-layer architecture consisting of the main
Yocto repositories, a custom layer (meta-custom), and a coordinating manifest
layer to ensure version synchronization, scalability, and reproducibility.
Three sample projects, including libhelloworld, helloworld, and the kernel
module hello mod, were developed and integrated into the build process.
Continuous Integration and Continuous Deployment pipelines were implemented
with GitLab CI and combined with an isolated Docker environment to automate and
streamline the build and testing workflows. Using a local cache server
containing hashserv, downloads and sstate cache significantly reduced the build
time. The functionality and stability of the system were verified through six
boot test scenarios in the QEMU simulator. The results show that the proposed
design not only ensures reproducibility but also can be extended to advanced
applications such as continuous deployment of real-time Linux versions. Future
recommendations include expanding automated tests, implementing system
monitoring with Prometheus and Grafana, using distributed builds, optimizing
with Docker multi-stage builds, and enabling continuous deployment of real-time
Linux changes to provide a stable and scalable model for industrial and
research projects in embedded systems with a rapid and reliable development
cycle.

</details>


### [7] [Trace: Securing Smart Contract Repository Against Access Control Vulnerability](https://arxiv.org/abs/2510.19254)
*Chong Chen,Jiachi Chen,Lingfeng Bao,David Lo,Yanlin Wang,Zhenyu Shan,Ting Chen,Guangqiang Yin,Jianxing Yu,Zibin Zheng*

Main category: cs.SE

TL;DR: TRACE是一个针对不可编译智能合约仓库的访问控制漏洞检测工具，使用LLM定位敏感函数并补全为可编译合约，通过函数调用图和CFG分析检测漏洞，在多个数据集上表现优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 智能合约中的访问控制漏洞已造成数十亿美元损失，现有工具无法有效处理不可编译的复杂仓库，因为需要合约可编译才能生成抽象表示进行分析。

Method: 使用LLM定位涉及关键操作的敏感函数，将函数片段补全为完整可编译合约，从AST构建函数调用图，使用每个函数的CFG作为节点信息，分析敏感函数节点检测访问控制漏洞。

Result: 在开源CVE数据集中检测出15个CVE中的14个；在5000个近期链上合约中达到89.2%准确率，远超最佳现有工具的76.9%；在83个真实仓库中达到87.0%准确率，显著超过DeepSeek-R1的14.3%。

Conclusion: TRACE能够有效检测不可编译智能合约仓库中的访问控制漏洞，在多个测试场景下均显著优于现有最先进工具。

Abstract: Smart contract vulnerabilities, particularly improper Access Control that
allows unauthorized execution of restricted functions, have caused billions of
dollars in losses. GitHub hosts numerous smart contract repositories containing
source code, documentation, and configuration files-these serve as intermediate
development artifacts that must be compiled and packaged before deployment.
Third-party developers often reference, reuse, or fork code from these
repositories during custom development. However, if the referenced code
contains vulnerabilities, it can introduce significant security risks. Existing
tools for detecting smart contract vulnerabilities are limited in their ability
to handle complex repositories, as they typically require the target contract
to be compilable to generate an abstract representation for further analysis.
This paper presents TRACE, a tool designed to secure non-compilable smart
contract repositories against access control vulnerabilities. TRACE employs
LLMs to locate sensitive functions involving critical operations (e.g.,
transfer) within the contract and subsequently completes function snippets into
a fully compilable contract. TRACE constructs a function call graph from the
abstract syntax tree (AST) of the completed contract. It uses the control flow
graph (CFG) of each function as node information. The nodes of the sensitive
functions are then analyzed to detect Access Control vulnerabilities.
Experimental results demonstrate that TRACE outperforms state-of-the-art tools
on an open-sourced CVE dataset, detecting 14 out of 15 CVEs. In addition, it
achieves 89.2% precision on 5,000 recent on-chain contracts, far exceeding the
best existing tool at 76.9%. On 83 real-world repositories, TRACE achieves
87.0% precision, significantly surpassing DeepSeek-R1's 14.3%.

</details>


### [8] [From Specification to Service: Accelerating API-First Development Using Multi-Agent Systems](https://arxiv.org/abs/2510.19274)
*Saurabh Chauhan,Zeeshan Rasheed,Malik Abdul Sami,Kai-Kristian Kemell,Muhammad Waseem,Zheying Zhang,Jussi Rasku,Mika Saari,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: 使用基于LLM的智能体自动化RESTful微服务的API优先开发，通过OpenAPI规范生成服务器代码，并利用执行日志和错误消息的反馈循环来优化代码。


<details>
  <summary>Details</summary>
Motivation: 推进RESTful Web服务的API优先开发自动化，测试基于LLM的多智能体系统在支持API优先开发方法中的能力。

Method: 利用LLM智能体创建OpenAPI规范，从中生成服务器代码，并通过分析执行日志和错误消息的反馈循环来完善代码。

Result: 使用PRAB基准测试表明，当保持OpenAPI规范小而专注时，LLM能够生成与规范对齐的完整功能代码和业务逻辑。

Conclusion: 基于LLM的多智能体系统能够有效支持API优先开发方法，通过集成日志分析可以高效检测和解决问题，减少生成功能性和健壮服务所需的迭代次数。

Abstract: This paper presents a system that uses Large Language Models (LLMs)-based
agents to automate the API-first development of RESTful microservices. This
system helps to create an OpenAPI specification, generate server code from it,
and refine the code through a feedback loop that analyzes execution logs and
error messages. The integration of log analysis enables the LLM to detect and
address issues efficiently, reducing the number of iterations required to
produce functional and robust services. This study's main goal is to advance
API-first development automation for RESTful web services and test the
capability of LLM-based multi-agent systems in supporting the API-first
development approach. To test the proposed system's potential, we utilized the
PRAB benchmark. The results indicate that if we keep the OpenAPI specification
small and focused, LLMs are capable of generating complete functional code with
business logic that aligns to the specification. The code for the system is
publicly available at https://github.com/sirbh/code-gen

</details>


### [9] [An Empirical Study of Bitwise Operators Intuitiveness through Performance Metrics](https://arxiv.org/abs/2510.19281)
*Shubham Joshi*

Main category: cs.SE

TL;DR: 研究探讨了不同编程背景人员对位运算符的可读性和理解能力，发现某些运算符（如OR、NOT、左移）在任务完成时间上有显著差异。


<details>
  <summary>Details</summary>
Motivation: 位运算符在编程中广泛使用但可能难以理解，研究旨在评估不同编程经验人员对位运算符的理解差异，以改进其设计。

Method: 采用被试内实验设计，让23名不同编程背景的参与者完成JavaScript编程任务，记录任务完成时间和准确率。

Result: 运算符是预测响应时间的因素之一（R²=0.032，p<0.001），OR、NOT和左移运算符在任务完成时间上显示出统计显著性。

Conclusion: 位运算符的复杂性通常不会导致更长的任务完成时间，但某些运算符不够直观，需要进一步研究和重新设计以提高可理解性。

Abstract: Objectives: This study aims to investigate the readability and
understandability of bitwise operators in programming, with the main hypothesis
that there will be a difference in the performance metrics (response time and
error rate) between participants exposed to various bitwise operators related
questions and those who are not.
  Participants: Participants in this human research study include people
without programming background, novice programmers, and university students
with varying programming experience (from freshmen to PhD level). There were 23
participants for this study.
  Study Methods: This study uses an Within-Subjects Experimental Design to
assess how people with diverse programming backgrounds understand and use
bitwise operators. Participants complete tasks in JavaScript program, and their
task completion time and accuracy of the tasks are recorded for analysis.
  Findings: The results indicate that operators can be one of the factors
predicting response time, with a small but significant effect, with R-squared
0.032, (1, 494) = 16.5, p < .001. Additionally, some operators like OR, NOT,
and Left Shift showed statistical significance in task completion times
compared to other operators.
  Conclusions: While the complexity of bitwise operators did not generally
result in longer task completion times, certain operators were found to be less
intuitive, suggesting the need for further investigation and potential redesign
for improved understandability.

</details>


### [10] [Bytecode-centric Detection of Known-to-be-vulnerable Dependencies in Java Projects](https://arxiv.org/abs/2510.19393)
*Stefan Schott,Serena Elisa Ponta,Wolfram Fischer,Jonas Klauke,Eric Bodden*

Main category: cs.SE

TL;DR: Jaralyzer是一个基于字节码分析的Java依赖扫描器，能够有效检测修改后的开源依赖中的安全漏洞，在检测准确性和覆盖范围上优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 现代Java项目中71%的代码来自开源依赖，这带来了严重的安全风险。现有依赖扫描器在检测修改后的依赖（如重新编译、重新打包等）时存在挑战。

Method: 开发了Jaralyzer工具，直接分析依赖的字节码，不依赖元数据或源代码的可用性。

Result: 在56个流行OSS组件上的评估显示，Jaralyzer在检测修改依赖中的漏洞方面优于其他扫描器，是唯一能识别所有类型修改的工具。即使对于未修改依赖，也比现有最佳工具多检测28个真实漏洞，减少29个误报。

Conclusion: Jaralyzer通过字节码分析有效解决了依赖修改带来的检测挑战，在漏洞检测准确性和覆盖范围上显著优于现有工具。

Abstract: On average, 71% of the code in typical Java projects comes from open-source
software (OSS) dependencies, making OSS dependencies the dominant component of
modern software code bases. This high degree of OSS reliance comes with a
considerable security risk of adding known security vulnerabilities to a code
base. To remedy this risk, researchers and companies have developed various
dependency scanners, which try to identify inclusions of known-to-be-vulnerable
OSS dependencies. However, there are still challenges that modern dependency
scanners do not overcome, especially when it comes to dependency modifications,
such as re-compilations, re-bundlings or re-packagings, which are common in the
Java ecosystem. To overcome these challenges, we present Jaralyzer, a
bytecode-centric dependency scanner for Java. Jaralyzer does not rely on the
metadata or the source code of the included OSS dependencies being available
but directly analyzes a dependency's bytecode. Our evaluation across 56 popular
OSS components demonstrates that Jaralyzer outperforms other popular dependency
scanners in detecting vulnerabilities within modified dependencies. It is the
only scanner capable of identifying vulnerabilities across all the above
mentioned types of modifications. But even when applied to unmodified
dependencies, Jaralyzer outperforms the current state-of-the-art code-centric
scanner Eclipse Steady by detecting 28 more true vulnerabilities and yielding
29 fewer false warnings.

</details>


### [11] [AutoMT: A Multi-Agent LLM Framework for Automated Metamorphic Testing of Autonomous Driving Systems](https://arxiv.org/abs/2510.19438)
*Linfeng Liang,Chenkai Tan,Yao Deng,Yingfeng Cai,T. Y Chen,Xi Zheng*

Main category: cs.SE

TL;DR: AutoMT是一个基于大语言模型的多智能体蜕变测试框架，用于自动驾驶系统测试，能够自动从交通规则中提取蜕变关系并生成有效的后续测试用例。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统是安全关键系统，故障可能导致严重后果。现有的蜕变测试方法依赖大量人工工作且缺乏自动化，需要更高效的自动化测试方案。

Method: 使用LLM从Gherkin语法描述的交通规则中提取蜕变关系，通过视觉语言智能体分析场景，搜索智能体从RAG数据库中检索合适的蜕变关系，利用计算机视觉生成后续测试用例。

Result: AutoMT在后续用例生成中实现了比最佳基线（手动专家定义的蜕变关系）高达5倍的测试多样性，检测到20.55%更多的行为违规。

Conclusion: AutoMT能够自动提取多样化的蜕变关系，增强真实世界数据集，发现现场测试和数据收集中经常遗漏的边界情况。其模块化架构支持集成到工业流程中，可能实现基于仿真的测试来系统覆盖代表性不足或安全关键场景。

Abstract: Autonomous Driving Systems (ADS) are safety-critical, where failures can be
severe. While Metamorphic Testing (MT) is effective for fault detection in ADS,
existing methods rely heavily on manual effort and lack automation. We present
AutoMT, a multi-agent MT framework powered by Large Language Models (LLMs) that
automates the extraction of Metamorphic Relations (MRs) from local traffic
rules and the generation of valid follow-up test cases. AutoMT leverages LLMs
to extract MRs from traffic rules in Gherkin syntax using a predefined
ontology. A vision-language agent analyzes scenarios, and a search agent
retrieves suitable MRs from a RAG-based database to generate follow-up cases
via computer vision. Experiments show that AutoMT achieves up to 5 x higher
test diversity in follow-up case generation compared to the best baseline
(manual expert-defined MRs) in terms of validation rate, and detects up to
20.55% more behavioral violations. While manual MT relies on a fixed set of
predefined rules, AutoMT automatically extracts diverse metamorphic relations
that augment real-world datasets and help uncover corner cases often missed
during in-field testing and data collection. Its modular architecture
separating MR extraction, filtering, and test generation supports integration
into industrial pipelines and potentially enables simulation-based testing to
systematically cover underrepresented or safety-critical scenarios.

</details>


### [12] [Mapping and Evolving Interoperability Testing in European Energy Systems: The int:net Perspective](https://arxiv.org/abs/2510.19460)
*Thomas I. Strasser,Edmund Widl,Carlos Ayon Mac Gregor,Mirko Ginocchi,Rene Kuchenbuch*

Main category: cs.SE

TL;DR: 本文通过调查30个欧洲互操作性测试设施，分析了欧洲能源互操作性测试现状，提供了测试基础设施分类清单、应用方法和参考测试案例，并提出了未来测试环境的蓝图。


<details>
  <summary>Details</summary>
Motivation: 欧洲能源转型需要高度互操作性，但目前缺乏专门和全面的互操作性测试关注，需要结构化的欧洲互操作性测试能力概览。

Method: 通过对30个欧洲测试设施进行结构化调查，分析测试基础设施、应用方法和参考测试案例。

Result: 提供了欧洲互操作性测试设施的分类清单和方法论，提出了未来测试环境的发展蓝图。

Conclusion: 研究成果有助于建立协调的欧洲互操作性测试生态系统，支持合作、创新并与能源转型目标保持一致。

Abstract: The ongoing transformation of the European energy landscape, driven by the
integration of renewable energy sources, digital technologies, and
decentralized systems, requires a high degree of interoperability across
diverse components and systems. Ensuring that these elements can exchange
information and operate together reliably is essential for achieving a secure,
flexible, and efficient energy supply infrastructure. While several initiatives
have contributed to the development of smart grid testing infrastructures, they
do not provide a dedicated or comprehensive focus on interoperability testing.
A structured and harmonized overview of interoperability testing capabilities
across Europe is therefore still missing. This work therefore presents a novel
contribution by analyzing the European interoperability testing facility
landscape through a structured survey of 30 facilities. It provides a
categorized inventory of testing infrastructures, applied methodologies, and
reference test cases, and introduces a blueprint for the development of future
testing environments. The findings contribute to the establishment of a
coordinated European ecosystem for interoperability testing, supporting
collaboration, innovation, and alignment with the goals of the energy
transition.

</details>


### [13] [A Goal-Driven Survey on Root Cause Analysis](https://arxiv.org/abs/2510.19593)
*Aoyang Fang,Haowen Yang,Haoze Dong,Qisheng Lu,Junjielong Xu,Pinjia He*

Main category: cs.SE

TL;DR: 本文提出了一个基于目标的框架，对2014-2025年间135篇云事故管理中的根因分析论文进行分类和整合，强调传统按数据类型分类方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有根因分析调查通常按数据类型分类，忽视了不同研究的目标差异，导致目标不同的研究被混为一谈，模糊了领域进展和差距。

Method: 提出目标驱动的分类框架，根据研究目标而非数据类型对根因分析论文进行系统分类和整合。

Result: 成功分类和整合了135篇根因分析论文，揭示了不同目标导向的研究进展，并讨论了根因分析的总体目标作为不同表述的统一框架。

Conclusion: 目标驱动的分类方法能更清晰地展示根因分析领域的发展状况，为研究者和实践者提供更有价值的指导，同时指出了该领域的开放挑战和未来方向。

Abstract: Root Cause Analysis (RCA) is a crucial aspect of incident management in
large-scale cloud services. While the term root cause analysis or RCA has been
widely used, different studies formulate the task differently. This is because
the term "RCA" implicitly covers tasks with distinct underlying goals. For
instance, the goal of localizing a faulty service for rapid triage is
fundamentally different from identifying a specific functional bug for a
definitive fix. However, previous surveys have largely overlooked these
goal-based distinctions, conventionally categorizing papers by input data types
(e.g., metric-based vs. trace-based methods). This leads to the grouping of
works with disparate objectives, thereby obscuring the true progress and gaps
in the field. Meanwhile, the typical audience of an RCA survey is either laymen
who want to know the goals and big picture of the task or RCA researchers who
want to figure out past research under the same task formulation. Thus, an RCA
survey that organizes the related papers according to their goals is in high
demand. To this end, this paper presents a goal-driven framework that
effectively categorizes and integrates 135 papers on RCA in the context of
cloud incident management based on their diverse goals, spanning the period
from 2014 to 2025. In addition to the goal-driven categorization, it discusses
the ultimate goal of all RCA papers as an umbrella covering different RCA
formulations. Moreover, the paper discusses open challenges and future
directions in RCA.

</details>


### [14] [Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1](https://arxiv.org/abs/2510.19600)
*Qianli Ma,Siyu Wang,Yilin Chen,Yinhao Tang,Yixiang Yang,Chang Guo,Bingjie Gao,Zhening Xing,Yanan Sun,Zhipeng Zhang*

Main category: cs.SE

TL;DR: AutoPage是一个多智能体系统，能够自动将学术论文转化为交互式网页，通过分层协作流程解决AI幻觉问题，在15分钟内以低于0.1美元的成本生成高质量网页。


<details>
  <summary>Details</summary>
Motivation: 研究人员在制作项目网页时面临手动、重复性工作的困扰，现有自动化工具无法处理网页的动态交互特性，需要一种新的解决方案。

Method: 采用多智能体系统，将论文到网页的创建过程分解为从叙事规划到多模态内容生成和交互式渲染的粗到细管道，使用专门的"检查器"智能体验证每个步骤，并设置可选的人工检查点。

Result: AutoPage不仅能生成高质量、视觉吸引人的网页，而且效率极高，在15分钟内以低于0.1美元的成本完成。

Conclusion: AutoPage将系统从单纯工具转变为强大的协作助手，通过PageBench基准验证了方法的有效性，为学术传播提供了高效解决方案。

Abstract: In the quest for scientific progress, communicating research is as vital as
the discovery itself. Yet, researchers are often sidetracked by the manual,
repetitive chore of building project webpages to make their dense papers
accessible. While automation has tackled static slides and posters, the
dynamic, interactive nature of webpages has remained an unaddressed challenge.
To bridge this gap, we reframe the problem, arguing that the solution lies not
in a single command, but in a collaborative, hierarchical process. We introduce
$\textbf{AutoPage}$, a novel multi-agent system that embodies this philosophy.
AutoPage deconstructs paper-to-page creation into a coarse-to-fine pipeline
from narrative planning to multimodal content generation and interactive
rendering. To combat AI hallucination, dedicated "Checker" agents verify each
step against the source paper, while optional human checkpoints ensure the
final product aligns perfectly with the author's vision, transforming the
system from a mere tool into a powerful collaborative assistant. To rigorously
validate our approach, we also construct $\textbf{PageBench}$, the first
benchmark for this new task. Experiments show AutoPage not only generates
high-quality, visually appealing pages but does so with remarkable efficiency
in under 15 minutes for less than \$0.1. Code and dataset will be released at
$\href{https://mqleet.github.io/AutoPage_ProjectPage/}{Webpage}$.

</details>


### [15] [FidelityGPT: Correcting Decompilation Distortions with Retrieval Augmented Generation](https://arxiv.org/abs/2510.19615)
*Zhiping Zhou,Xiaohong Li,Ruitao Feng,Yao Zhang,Yuekang Li,Wenbu Feng,Yunqian Wang,Yuqing Li*

Main category: cs.SE

TL;DR: FidelityGPT是一个提升反编译代码准确性和可读性的框架，通过系统性地检测和修正语义失真，在闭源二进制文件上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有反编译方法存在保真度问题，导致反编译输出的可读性和语义准确性下降，特别是在复杂闭源二进制文件中缺乏鲁棒的检测和修正机制。

Method: 引入失真感知提示模板，结合检索增强生成(RAG)和动态语义强度算法定位失真代码行，从数据库中检索语义相似代码，并使用变量依赖算法缓解长上下文限制。

Result: 在620个函数对上的评估显示，平均检测准确率89%，精确率83%。相比最先进的DeGPT(修复率83%，正确修复率37%)，FidelityGPT达到94%修复率和64%正确修复率。

Conclusion: FidelityGPT在准确性和可读性方面取得显著提升，展示了基于LLM的反编译和逆向工程的潜力。

Abstract: Decompilation converts machine code into human-readable form, enabling
analysis and debugging without source code. However, fidelity issues often
degrade the readability and semantic accuracy of decompiled output. Existing
methods, such as variable renaming or structural simplification, provide
partial improvements but lack robust detection and correction, particularly for
complex closed-source binaries. We present FidelityGPT, a framework that
enhances decompiled code accuracy and readability by systematically detecting
and correcting semantic distortions. FidelityGPT introduces distortion-aware
prompt templates tailored to closed-source settings and integrates
Retrieval-Augmented Generation (RAG) with a dynamic semantic intensity
algorithm to locate distorted lines and retrieve semantically similar code from
a database. A variable dependency algorithm further mitigates long-context
limitations by analyzing redundant variables and integrating their dependencies
into the prompt context. Evaluated on 620 function pairs from a binary
similarity benchmark, FidelityGPT achieved an average detection accuracy of 89%
and a precision of 83%. Compared to the state-of-the-art DeGPT (Fix Rate 83%,
Corrected Fix Rate 37%), FidelityGPT attained 94% FR and 64% CFR, demonstrating
significant gains in accuracy and readability. These results highlight its
potential to advance LLM-based decompilation and reverse engineering.

</details>


### [16] [Toward Agentic Software Engineering Beyond Code: Framing Vision, Values, and Vocabulary](https://arxiv.org/abs/2510.19692)
*Rashina Hoda*

Main category: cs.SE

TL;DR: 本文主张将智能代理软件工程的研究范围从代码相关活动扩展到整个软件开发过程，提出了指导原则和词汇设计建议，旨在为这一新兴领域奠定坚实基础。


<details>
  <summary>Details</summary>
Motivation: 随着智能代理AI在软件工程中引发范式转变，需要建立智能代理软件工程作为研究领域，并解决实践中出现的社会技术问题。

Method: 通过分析软件工程基础和演进趋势，结合新兴的智能代理SE框架，提出扩展研究范围的建议、初步的价值观和原则，以及词汇设计指导。

Result: 提出了'全过程'愿景，将智能代理SE的研究范围从代码扩展到整个软件开发过程，并建立了指导原则和词汇标准。

Conclusion: 这些建议将促进社区合作，引导软件工程社区为智能代理SE奠定坚实基础，使其不仅是必然趋势，而且在长期发展中具有目的性和可取性。

Abstract: Agentic AI is poised to usher in a seismic paradigm shift in Software
Engineering (SE). As technologists rush head-along to make agentic AI a
reality, SE researchers are driven to establish agentic SE as a research area.
While early visions of agentic SE are primarily focused on code-related
activities, early empirical evidence calls for a consideration of a range of
socio-technical concerns to make it work in practice. This paper contributes to
the emerging community vision by: (a) recommending an expansion of its scope
beyond code, toward a 'whole of process' vision, grounding it in SE foundations
and evolution and emerging agentic SE frameworks, (b) proposing a preliminary
set of values and principles to guide efforts, and (c) sharing guidance on
designing/using well-defined vocabulary for agentic SE. It is hoped that these
ideas will encourage community collaborations and steer the SE community
towards laying strong foundations of agentic SE so its not only inevitable but
also deliberate and desirable in the long run.

</details>


### [17] [Review of Tools for Zero-Code LLM Based Application Development](https://arxiv.org/abs/2510.19747)
*Priyaranjan Pattnayak,Hussain Bohra*

Main category: cs.SE

TL;DR: 本文调查了基于大语言模型(LLM)的无代码开发平台，分析了各类平台的特点、分类和核心功能，比较了它们的优劣势，并讨论了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLM技术的发展，零代码开发平台正在改变软件创建方式，让非程序员也能构建AI驱动的应用程序。本文旨在系统性地调查和分析这一新兴领域的现状和发展趋势。

Method: 采用广泛的调查方法，基于界面风格、后端集成、输出类型和可扩展性等关键维度对平台进行分类，分析专用LLM应用构建器和集成LLM功能的通用无代码平台。

Result: 提出了一个分类法，按界面类型、支持的LLM后端、输出类型和可扩展性对平台进行分类。详细比较了各平台的优缺点，并讨论了与传统和低代码开发方法相比的权衡。

Conclusion: 基于LLM的零代码平台大大降低了创建AI应用程序的门槛，但在灵活性和可靠性方面仍面临挑战。该领域正在快速发展，为非程序员创建复杂软件提供了令人兴奋的机会。

Abstract: Large Language Models (LLMs) are transforming software creation by enabling
zero code development platforms. Our survey reviews recent platforms that let
users build applications without writing code, by leveraging LLMs as the brains
of the development process. We adopt a broad survey methodology, categorizing
platforms based on key dimensions such as interface style, backend integration,
output type, and extensibility. We analyze both dedicated LLM based app
builders (OpenAI's custom GPTs, Bolt.new, Dust.tt, Flowise, Cognosys) and
general no code platforms (e.g., Bubble, Glide) that integrate LLM
capabilities. We present a taxonomy categorizing these platforms by their
interface (conversational, visual, etc.), supported LLM backends, output type
(chatbot, full application, workflow), and degree of extensibility. Core
features such as autonomous agents, memory management, workflow orchestration,
and API integrations are in scope of the survey. We provide a detailed
comparison, highlighting each platform's strengths and limitations. Trade offs
(customizability, scalability, vendor lock-in) are discussed in comparison with
traditional and low code development approaches. Finally, we outline future
directions, including multimodal interfaces, on device LLMs, and improved
orchestration for democratizing app creation with AI. Our findings indicate
that while zero code LLM platforms greatly reduce the barrier to creating AI
powered applications, they still face challenges in flexibility and
reliability. Overall, the landscape is rapidly evolving, offering exciting
opportunities to empower non programmers to create sophisticated software.

</details>


### [18] [BOSQTGEN: Breaking the Sound Barrier in Test Generation](https://arxiv.org/abs/2510.19777)
*S M Sadrul Islam Asif,James Chen,Earl T. Barr,Mark Marron*

Main category: cs.SE

TL;DR: BOSQTGEN是一个新颖的黑盒API测试生成方法，通过分解API规范、使用LLM建议连贯参数值、结合组合测试来高效采样，显著提升了代码覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现代软件越来越多地通过组合API构建，但API契约不足会导致期望不匹配和故障。现有测试生成技术面临多语言系统、源代码不可访问、成本可靠性权衡以及生成结构化输入困难等挑战。

Method: BOSQTGEN采用黑盒方法，将API规范分解为原语，使用LLM为这些原语建议连贯的参数值，并采用组合测试来高效采样这些值，覆盖关键交互同时避免随机采样的冗余。

Result: 在RESTful基准测试中，BOSQTGEN平均达到82%的代码覆盖率，通常比现有最先进系统提高20%或更多，接近手写测试套件的水平。

Conclusion: BOSQTGEN提供完全API驱动的测试生成方法，使开发人员能够自动创建高质量的测试用例，用于验证或测试驱动开发。

Abstract: Modern software is increasingly built by composing APIs, elevating the API
contract to a critical role. Inadequate contracts, however, lead to mismatched
expectations and failures, creating a pressing need for robust conformance
testing. Current test generation techniques are hindered by key challenges:
polyglot systems, source code inaccessibility, a cost-reliability trade-off,
and, most critically, the difficulty of generating structured inputs.
  We introduce BOSQTGEN, a novel black-box methodology and tool for API test
generation. BOSQTGEN utilizes a novel approach for decomposing API
specifications into primitives, using LLMs to suggest coherent strata for them,
and employing combinatorial testing to efficiently sample over these values.
This approach ensures coverage of critical interactions while avoiding the
redundancy of random sampling.
  The resulting BOSQTGEN system achieves an average of 82% code coverage on
RESTful benchmarks, often a 20% or more increase over prior state-of-the-art
systems and nearing parity with hand-written test suites. Providing a fully
API-driven approach to test generation, enables developers to automatically
create high-quality test cases for validation or test-driven development.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [19] [The Black Tuesday Attack: how to crash the stock market with adversarial examples to financial forecasting models](https://arxiv.org/abs/2510.18990)
*Thomas Hofweber,Jefrey Bergl,Ian Reyes,Amir Sadovnik*

Main category: cs.CR

TL;DR: 论文探讨了通过轻微操纵个股价值来制造对抗性样本，从而引发股市崩盘的可能性，这种攻击难以检测且对金融稳定构成重大风险。


<details>
  <summary>Details</summary>
Motivation: 研究金融预测模型对对抗性攻击的脆弱性，揭示恶意行为者可能通过微小干预引发大规模经济破坏的风险。

Method: 通过理论分析探讨如何对个股价值进行轻微操纵，制造对抗性样本使金融预测模型做出自我实现的崩盘预测。

Result: 发现这种攻击具有可行性，能够在不被察觉的情况下引发股市崩盘，对金融稳定构成严重威胁。

Conclusion: 这种威胁被严重低估，迫切需要研究防御措施来保护金融系统免受此类对抗性攻击。

Abstract: We investigate and defend the possibility of causing a stock market crash via
small manipulations of individual stock values that together realize an
adversarial example to financial forecasting models, causing these models to
make the self-fulfilling prediction of a crash. Such a crash triggered by an
adversarial example would likely be hard to detect, since the model's
predictions would be accurate and the interventions that would cause it are
minor. This possibility is a major risk to financial stability and an
opportunity for hostile actors to cause great economic damage to an adversary.
This threat also exists against individual stocks and the corresponding
valuation of individual companies. We outline how such an attack might proceed,
what its theoretical basis is, how it can be directed towards a whole economy
or an individual company, and how one might defend against it. We conclude that
this threat is vastly underappreciated and requires urgent research on how to
defend against it.

</details>


### [20] [Fusion of Machine Learning and Blockchain-based Privacy-Preserving Approach for Health Care Data in the Internet of Things](https://arxiv.org/abs/2510.19026)
*Behnam Rezaei Bezanjani,Seyyed Hamid Ghafouri,Reza Gholamrezaei*

Main category: cs.CR

TL;DR: 提出了一种基于区块链和机器学习的三阶段安全方法，用于保护医疗物联网系统中的患者数据安全，在检测率、误报率等指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医疗物联网设备的快速普及带来了革命性进步，但也引发了严重的安全担忧，特别是医疗数据的网络安全威胁。医疗信息的敏感性要求确保数据机密性、完整性和可用性。

Method: 三阶段方法：1) 区块链支持的请求和交易加密；2) 请求模式识别检查；3) 特征选择和BiLSTM网络用于入侵检测。

Result: 与AIBPSF-IoMT、OMLIDS-PBIoT和AIMMFIDS三种现有方法相比，在检测率、误报率、精确率、召回率和准确率等所有评估标准上均表现更优。

Conclusion: 该方法在提高基于物联网的医疗系统安全性方面表现出有效性，能够更好地保护患者数据免受网络威胁。

Abstract: In recent years, the rapid integration of Internet of Things (IoT) devices
into the healthcare sector has brought about revolutionary advancements in
patient care and data management. While these technological innovations hold
immense promise, they concurrently raise critical security concerns,
particularly in safeguarding medical data against potential cyber threats. The
sensitive nature of health-related information requires robust measures to
ensure the confidentiality, integrity, and availability of patient data in
IoT-enabled medical environments. Addressing the imperative need for enhanced
security in IoT-based healthcare systems, we propose a comprehensive method
encompassing three distinct phases. In the first phase, we implement
Blockchain-Enabled Request and Transaction Encryption to strengthen data
transaction security, providing an immutable and transparent framework. In the
second phase, we introduce a Request Pattern Recognition Check that leverages
diverse data sources to identify and block potential unauthorized access
attempts. Finally, the third phase incorporates Feature Selection and a BiLSTM
network to enhance the accuracy and efficiency of intrusion detection using
advanced machine learning techniques. We compared the simulation results of the
proposed method with three recent related methods: AIBPSF-IoMT, OMLIDS-PBIoT,
and AIMMFIDS. The evaluation criteria include detection rate, false alarm rate,
precision, recall, and accuracy - crucial benchmarks for assessing the overall
performance of intrusion detection systems. Our findings show that the proposed
method outperforms existing approaches across all evaluated criteria,
demonstrating its effectiveness in improving the security of IoT-based
healthcare systems.

</details>


### [21] [Securing IoT Communications via Anomaly Traffic Detection: Synergy of Genetic Algorithm and Ensemble Method](https://arxiv.org/abs/2510.19121)
*Behnam Seyedi,Octavian Postolache*

Main category: cs.CR

TL;DR: 提出了一种基于遗传算法和集成学习的IoT异常检测框架，通过数据预处理、特征选择和集成分类器实现高效安全防护，准确率达98%。


<details>
  <summary>Details</summary>
Motivation: 解决IoT网络因去中心化架构和资源限制而面临的安全威胁，包括DoS攻击、异常流量和数据篡改等问题。

Method: 三阶段方法：1) 使用Median KS Test进行数据预处理；2) 遗传算法结合鹰启发搜索策略进行特征选择；3) 集成决策树、随机森林和XGBoost的分类器。

Result: 达到98%准确率、95%检测率，误报率10%，漏报率5%，优于现有方法。

Conclusion: 该框架具有高适应性和可扩展性，能有效提升IoT网络安全防护能力，应对不断演变的网络威胁。

Abstract: The rapid growth of the Internet of Things (IoT) has transformed industries
by enabling seamless data exchange among connected devices. However, IoT
networks remain vulnerable to security threats such as denial of service (DoS)
attacks, anomalous traffic, and data manipulation due to decentralized
architectures and limited resources. To address these issues, this paper
proposes an advanced anomaly detection framework with three main phases. First,
data preprocessing is performed using the Median KS Test to remove noise,
handle missing values, and balance datasets for cleaner input. Second, a
feature selection phase employs a Genetic Algorithm combined with eagle
inspired search strategies to identify the most relevant features, reduce
dimensionality, and improve efficiency without sacrificing accuracy. Finally,
an ensemble classifier integrates Decision Tree, Random Forest, and XGBoost
algorithms to achieve accurate and reliable anomaly detection. The proposed
model demonstrates high adaptability and scalability across diverse IoT
environments. Experimental results show that it outperforms existing methods by
achieving 98 percent accuracy, 95 percent detection rate, and reductions in
false positive (10 percent) and false negative (5 percent) rates. These results
confirm the framework effectiveness and robustness in improving IoT network
security against evolving cyber threats.

</details>


### [22] [HAMLOCK: HArdware-Model LOgically Combined attacK](https://arxiv.org/abs/2510.19145)
*Sanskar Amgain,Daniel Lobo,Atri Chatterjee,Swarup Bhunia,Fnu Suya*

Main category: cs.CR

TL;DR: HAMLOCK是一种新型硬件-软件联合后门攻击，将攻击逻辑分布在硬件和软件边界，比传统模型级后门攻击更隐蔽。软件模型仅轻微调整少数神经元激活值，硬件木马检测这些特定激活模式并直接操纵最终输出。


<details>
  <summary>Details</summary>
Motivation: 传统模型级后门攻击将完整攻击逻辑嵌入模型权重中，容易被检测到。需要开发更隐蔽的攻击方法，利用硬件-软件边界来分散攻击逻辑。

Method: 1) 软件层面：轻微调整少数神经元，使其在触发模式出现时产生独特的激活值；2) 硬件层面：部署硬件木马监控特定神经元的最高有效位或8位指数，检测到独特激活后直接操纵最终输出logits进行错误分类。

Result: 在MNIST、CIFAR10、GTSRB和ImageNet等基准测试中，HAMLOCK实现了接近完美的攻击成功率，且对干净数据准确率影响极小。成功规避了最先进的模型级防御方法，硬件木马面积和功耗开销仅0.01%，可被工艺和环境噪声掩盖。

Conclusion: HAMLOCK暴露了硬件-软件接口的关键安全漏洞，需要开发新的跨层防御机制来应对这种新兴威胁。

Abstract: The growing use of third-party hardware accelerators (e.g., FPGAs, ASICs) for
deep neural networks (DNNs) introduces new security vulnerabilities.
Conventional model-level backdoor attacks, which only poison a model's weights
to misclassify inputs with a specific trigger, are often detectable because the
entire attack logic is embedded within the model (i.e., software), creating a
traceable layer-by-layer activation path.
  This paper introduces the HArdware-Model Logically Combined Attack (HAMLOCK),
a far stealthier threat that distributes the attack logic across the
hardware-software boundary. The software (model) is now only minimally altered
by tuning the activations of few neurons to produce uniquely high activation
values when a trigger is present. A malicious hardware Trojan detects those
unique activations by monitoring the corresponding neurons' most significant
bit or the 8-bit exponents and triggers another hardware Trojan to directly
manipulate the final output logits for misclassification.
  This decoupled design is highly stealthy, as the model itself contains no
complete backdoor activation path as in conventional attacks and hence, appears
fully benign. Empirically, across benchmarks like MNIST, CIFAR10, GTSRB, and
ImageNet, HAMLOCK achieves a near-perfect attack success rate with a negligible
clean accuracy drop. More importantly, HAMLOCK circumvents the state-of-the-art
model-level defenses without any adaptive optimization. The hardware Trojan is
also undetectable, incurring area and power overheads as low as 0.01%, which is
easily masked by process and environmental noise. Our findings expose a
critical vulnerability at the hardware-software interface, demanding new
cross-layer defenses against this emerging threat.

</details>


### [23] [OpenGuardrails: An Open-Source Context-Aware AI Guardrails Platform](https://arxiv.org/abs/2510.19169)
*Thomas Wang,Haowen Li*

Main category: cs.CR

TL;DR: OpenGuardrails是一个开源项目，提供上下文感知的安全性和操作检测模型，以及可部署的AI护栏平台，保护LLM免受内容安全风险、模型操作攻击和数据泄露。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在现实应用中的集成度提高，保护其免受不安全、恶意或侵犯隐私的内容变得至关重要。

Method: 使用统一的大模型实现内容安全和模型操作检测，使用轻量级NER管道（如Presidio风格模型或基于正则表达式的检测器）进行数据泄露识别和编辑。系统可作为安全网关或基于API的服务部署。

Result: 在安全基准测试中达到最先进性能，在英语、中文和多语言任务的提示和响应分类方面表现出色。

Conclusion: 所有模型都基于Apache 2.0许可证公开发布，提供企业级、完全私有的部署选项。

Abstract: As large language models (LLMs) become increasingly integrated into
real-world applications, safeguarding them against unsafe, malicious, or
privacy-violating content is critically important. We present OpenGuardrails,
the first open-source project to provide both a context-aware safety and
manipulation detection model and a deployable platform for comprehensive AI
guardrails. OpenGuardrails protects against content-safety risks,
model-manipulation attacks (e.g., prompt injection, jailbreaking,
code-interpreter abuse, and the generation/execution of malicious code), and
data leakage. Content-safety and model-manipulation detection are implemented
by a unified large model, while data-leakage identification and redaction are
performed by a separate lightweight NER pipeline (e.g., Presidio-style models
or regex-based detectors). The system can be deployed as a security gateway or
an API-based service, with enterprise-grade, fully private deployment options.
OpenGuardrails achieves state-of-the-art (SOTA) performance on safety
benchmarks, excelling in both prompt and response classification across
English, Chinese, and multilingual tasks. All models are released under the
Apache 2.0 license for public use.

</details>


### [24] [Defending Against Prompt Injection with DataFilter](https://arxiv.org/abs/2510.19207)
*Yizhu Wang,Sizhe Chen,Raghad Alkhudair,Basel Alomair,David Wagner*

Main category: cs.CR

TL;DR: DataFilter是一种针对提示注入攻击的防御方法，通过在数据到达后端LLM之前移除恶意指令，同时保留良性信息，实现高安全性和实用性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理被广泛部署与不受信任的外部数据交互，提示注入攻击成为重大安全威胁。现有防御方法要么需要模型权重访问权限，要么导致实用性显著下降，要么需要复杂的系统重构。

Method: DataFilter使用监督微调在模拟注入数据上进行训练，同时利用用户指令和数据来选择性去除对抗性内容。这是一种模型无关的测试时防御方法。

Result: 在多个基准测试中，DataFilter持续将提示注入攻击成功率降低到接近零，同时保持了LLM的实用性。

Conclusion: DataFilter提供了强大的安全性、高实用性和即插即用部署能力，是保护黑盒商业LLM免受提示注入攻击的实用防御方案。

Abstract: When large language model (LLM) agents are increasingly deployed to automate
tasks and interact with untrusted external data, prompt injection emerges as a
significant security threat. By injecting malicious instructions into the data
that LLMs access, an attacker can arbitrarily override the original user task
and redirect the agent toward unintended, potentially harmful actions. Existing
defenses either require access to model weights (fine-tuning), incur
substantial utility loss (detection-based), or demand non-trivial system
redesign (system-level). Motivated by this, we propose DataFilter, a test-time
model-agnostic defense that removes malicious instructions from the data before
it reaches the backend LLM. DataFilter is trained with supervised fine-tuning
on simulated injections and leverages both the user's instruction and the data
to selectively strip adversarial content while preserving benign information.
Across multiple benchmarks, DataFilter consistently reduces the prompt
injection attack success rates to near zero while maintaining the LLMs'
utility. DataFilter delivers strong security, high utility, and plug-and-play
deployment, making it a strong practical defense to secure black-box commercial
LLMs against prompt injection. Our DataFilter model is released at
https://huggingface.co/JoyYizhu/DataFilter for immediate use, with the code to
reproduce our results at https://github.com/yizhu-joy/DataFilter.

</details>


### [25] [LAPRAD: LLM-Assisted PRotocol Attack Discovery](https://arxiv.org/abs/2510.19264)
*R. Can Aygun,Yehuda Afek,Anat Bremler-Barr,Leonard Kleinrock*

Main category: cs.CR

TL;DR: LAPRAD是一种利用LLM辅助发现协议漏洞的方法，成功发现了DNS协议的三种新型DDoS攻击，这些攻击能够绕过现有补丁，严重降低解析器性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高互联网协议的安全性，需要更快、半自动的方法来发现DNS、BGP等协议中的新漏洞。

Method: LAPRAD采用三阶段流程：1) 使用GPT-o1识别潜在漏洞；2) 通过LangChain自动构建攻击配置；3) 验证攻击功能性和有效性。

Result: 发现了三种新的DNS DDoS攻击：1) 诱饵切换技术缓存虚假DNSSEC RRSIGs；2) 利用大型DNSSEC加密算法绕过RRSet限制；3) 利用ANY类型响应产生类似效果。这些攻击能将解析器服务能力降至6%。

Conclusion: LAPRAD方法有效发现了新型DNS协议漏洞，这些SigCacheFlush攻击变种能够绕过现有防护措施，影响主流DNS解析器的最新版本。

Abstract: With the goal of improving the security of Internet protocols, we seek
faster, semi-automatic methods to discover new vulnerabilities in protocols
such as DNS, BGP, and others. To this end, we introduce the LLM-Assisted
Protocol Attack Discovery (LAPRAD) methodology, enabling security researchers
with some DNS knowledge to efficiently uncover vulnerabilities that would
otherwise be hard to detect.
  LAPRAD follows a three-stage process. In the first, we consult an LLM
(GPT-o1) that has been trained on a broad corpus of DNS-related sources and
previous DDoS attacks to identify potential exploits. In the second stage, a
different LLM automatically constructs the corresponding attack configurations
using the ReACT approach implemented via LangChain (DNS zone file generation).
Finally, in the third stage, we validate the attack's functionality and
effectiveness.
  Using LAPRAD, we uncovered three new DDoS attacks on the DNS protocol and
rediscovered two recently reported ones that were not included in the LLM's
training data. The first new attack employs a bait-and-switch technique to
trick resolvers into caching large, bogus DNSSEC RRSIGs, reducing their serving
capacity to as little as 6%. The second exploits large DNSSEC encryption
algorithms (RSA-4096) with multiple keys, thereby bypassing a recently
implemented default RRSet limit. The third leverages ANY-type responses to
produce a similar effect.
  These variations of a cache-flushing DDoS attack, called SigCacheFlush,
circumvent existing patches, severely degrade resolver query capacity, and
impact the latest versions of major DNS resolver implementations.

</details>


### [26] [Reliability and Resilience of AI-Driven Critical Network Infrastructure under Cyber-Physical Threats](https://arxiv.org/abs/2510.19295)
*Konstantinos A. Lizos,Leandros Maglaras,Elena Petrovik,Saied M. Abd El-atty,Georgios Tsachtsiris,Mohamed Amine Ferrag*

Main category: cs.CR

TL;DR: 提出了一种面向5G/6G网络的容错和弹性感知框架，通过AI驱动的异常检测、自适应路由和冗余机制来缓解网络攻击下的级联故障。


<details>
  <summary>Details</summary>
Motivation: 随着AI驱动的5G/6G网络基础设施在关键任务服务中的依赖增加，需要提高对复杂网络物理威胁的可靠性和弹性，这些网络因分布式智能、虚拟化资源和跨域集成而面临新的攻击面。

Method: 整合AI驱动的异常检测、自适应路由和冗余机制，使用NS-3仿真进行验证，分析可靠性、延迟、弹性指数和丢包率等关键性能指标。

Result: 所提框架显著改善了故障恢复能力，稳定了数据包传输，并减少了服务中断，优于基线方法。

Conclusion: 该框架有效提升了5G/6G网络在遭受网络物理攻击时的容错能力和系统弹性。

Abstract: The increasing reliance on AI-driven 5G/6G network infrastructures for
mission-critical services highlights the need for reliability and resilience
against sophisticated cyber-physical threats. These networks are highly exposed
to novel attack surfaces due to their distributed intelligence, virtualized
resources, and cross-domain integration. This paper proposes a fault-tolerant
and resilience-aware framework that integrates AI-driven anomaly detection,
adaptive routing, and redundancy mechanisms to mitigate cascading failures
under cyber-physical attack conditions. A comprehensive validation is carried
out using NS-3 simulations, where key performance indicators such as
reliability, latency, resilience index, and packet loss rate are analyzed under
various attack scenarios. The deduced results demonstrate that the proposed
framework significantly improves fault recovery, stabilizes packet delivery,
and reduces service disruption compared to baseline approaches.

</details>


### [27] [An Adaptive Intelligent Thermal-Aware Routing Protocol for Wireless Body Area Networks](https://arxiv.org/abs/2510.19300)
*Abdollah Rahimi,Mehdi Jafari Shahbazzadeh,Amid Khatibi*

Main category: cs.CR

TL;DR: 提出了一种智能温度感知和可靠性路由方法，通过两阶段机制优化WBAN性能：网络设置与智能路径选择、动态流量管理与热点避免。


<details>
  <summary>Details</summary>
Motivation: 无线体域网在医疗监测等应用中面临能量有限、拓扑动态变化和节点温度敏感等挑战，传统最短路径路由容易导致特定节点拥塞和过热，造成早期故障。

Method: 采用两阶段方法：第一阶段节点共享剩余能量、温度、链路可靠性和延迟信息，使用多标准决策算法构建优化拓扑；第二阶段持续监控实时条件，将流量从过热或耗尽节点重新路由。

Result: 仿真结果显示，与现有方法相比，该方法吞吐量提高13%，端到端延迟降低10%，能耗减少25%，路由负载降低30%。

Conclusion: 所提出的温度感知和可靠性路由方法能有效解决WBAN中的拥塞和过热问题，显著提升网络性能。

Abstract: Wireless Body Area Networks (WBANs) have gained significant attention due to
their applications in healthcare monitoring, sports, military communication,
and remote patient care. These networks consist of wearable or implanted
sensors that continuously collect and transmit physiological data, requiring
efficient and reliable communication. However, WBANs face challenges such as
limited energy, dynamic topology, and sensitivity to node temperature, which
demand specialized routing strategies. Traditional shortest-path routing often
causes congestion and overheating in specific nodes, leading to early failures.
To address these problems, this paper proposes an intelligent temperature-aware
and reliability-based routing approach that enhances WBAN performance. The
proposed method works in two phases: (1) network setup and intelligent path
selection, and (2) dynamic traffic management and hotspot avoidance. In the
first phase, nodes share information such as residual energy, temperature, link
reliability, and delay to build an optimized topology using a multi-criteria
decision algorithm. The second phase continuously monitors real-time conditions
and reroutes traffic away from overheated or depleted nodes. Simulation results
show that the proposed approach improves throughput by 13 percent, reduces
end-to-end delay by 10 percent, decreases energy consumption by 25 percent, and
lowers routing load by 30 percent compared to existing methods.

</details>


### [28] [Collaborative penetration testing suite for emerging generative AI algorithms](https://arxiv.org/abs/2510.19303)
*Petar Radanliev*

Main category: cs.CR

TL;DR: 提出一个协作渗透测试套件，集成传统安全工具、区块链日志、量子密码学和AI红队模拟，以保护生成式AI模型免受经典和量子网络攻击。


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI的漏洞（模型反转、数据投毒、对抗性输入）和量子威胁（Shor算法破解RSA/ECC加密），确保AI模型在经典和量子攻击下的安全性。

Method: 开发五组件协作渗透测试套件：集成DAST/SAST工具（OWASP ZAP、Burp Suite、SonarQube、Fortify）、IAST对比评估、区块链日志（Hyperledger Fabric）、量子密码学（基于格的RLWE协议）和AI红队模拟（对抗性ML和量子辅助攻击）。

Result: 在测试环境中识别300+漏洞，2周内高危问题减少70%，区块链记录漏洞解决效率达90%，量子抗性密码学在测试中保持100%完整性。

Conclusion: 成功开发量子AI安全协议，集成了区块链、量子密码学和AI红队技术，为生成式AI提供全面的安全防护。

Abstract: Problem Space: AI Vulnerabilities and Quantum Threats Generative AI
vulnerabilities: model inversion, data poisoning, adversarial inputs. Quantum
threats Shor Algorithm breaking RSA ECC encryption. Challenge Secure generative
AI models against classical and quantum cyberattacks. Proposed Solution
Collaborative Penetration Testing Suite Five Integrated Components: DAST SAST
OWASP ZAP, Burp Suite, SonarQube, Fortify. IAST Contrast Assess integrated with
CI CD pipeline. Blockchain Logging Hyperledger Fabric for tamper-proof logs.
Quantum Cryptography Lattice based RLWE protocols. AI Red Team Simulations
Adversarial ML & Quantum-assisted attacks. Integration Layer: Unified workflow
for AI, cybersecurity, and quantum experts. Key Results 300+ vulnerabilities
identified across test environments. 70% reduction in high-severity issues
within 2 weeks. 90% resolution efficiency for blockchain-logged
vulnerabilities. Quantum-resistant cryptography maintained 100% integrity in
tests. Outcome: Quantum AI Security Protocol integrating Blockchain Quantum
Cryptography AI Red Teaming.

</details>


### [29] [Authorization of Knowledge-base Agents in an Intent-based Management Function](https://arxiv.org/abs/2510.19324)
*Loay Abdelrazek,Leyli Karaçay,Marin Orlic*

Main category: cs.CR

TL;DR: 提出一个增强的授权框架，通过整合上下文和功能属性与代理角色，实现动态、策略驱动的访问控制，确保代理仅获得对知识图谱的最小必要权限。


<details>
  <summary>Details</summary>
Motivation: 在6G网络意图管理系统（IbM）中，代理在监控网络状态、收集数据和执行操作方面发挥关键作用，但确保代理的安全和细粒度授权在动态多租户环境中仍面临挑战。传统访问控制模型（如RBAC、ABAC、RelBAC）缺乏适应意图操作所需的灵活性和粒度。

Method: 提出一个增强的授权框架，整合上下文和功能属性与代理角色，实现动态、策略驱动的访问控制。通过分析代理功能，确保代理仅获得对知识图谱的最小必要权限。

Result: 该框架能够提供更灵活和细粒度的访问控制，适应动态和多租户环境的需求。

Conclusion: 所提出的授权框架能够有效解决意图管理系统中代理授权的问题，提供动态和策略驱动的访问控制，确保安全性和最小权限原则。

Abstract: As networks move toward the next-generation 6G, Intent-based Management (IbM)
systems are increasingly adopted to simplify and automate network management by
translating high-level intents into low-level configurations. Within these
systems, agents play a critical role in monitoring current state of the
network, gathering data, and enforcing actions across the network to fulfill
the intent. However, ensuring secure and fine-grained authorization of agents
remains a significant challenge, especially in dynamic and multi-tenant
environments. Traditional models such as Role-Based Access Control (RBAC),
Attribute-Based Access Control (ABAC) and Relational-Based Access Control
(RelBAC) often lack the flexibility to accommodate the evolving context and
granularity required by intentbased operations. In this paper, we propose an
enhanced authorization framework that integrates contextual and functional
attributes with agent roles to achieve dynamic, policy-driven access control.
By analyzing agent functionalities, our approach ensures that agents are
granted only the minimal necessary privileges towards knowledge graphs.

</details>


### [30] [A Probabilistic Computing Approach to the Closest Vector Problem for Lattice-Based Factoring](https://arxiv.org/abs/2510.19390)
*Max O. Al-Hasso,Marko von der Leyen*

Main category: cs.CR

TL;DR: 该论文研究将概率计算应用于格基分解算法中的最近向量问题(CVP)近似优化任务，结果显示该方法能在线性时间内找到最优CVP近似，且比类似量子/经典方法减少100倍格实例使用。


<details>
  <summary>Details</summary>
Motivation: 最近向量问题(CVP)是格基密码学中的核心问题，其硬度假设支撑着格基密码系统的安全性。同时，Schnorr的格基分解算法将整数分解问题转化为CVP。近期研究探索在格基分解算法中加入启发式CVP近似优化步骤，而概率计算作为随机算法的硬件加速器，适合用于此类组合优化任务。

Method: 设计了用于CVP近似优化的概率计算算法，讨论了'素数格'参数，并通过实验验证概率计算在解决CVP及其作为格基分解子程序的有效性。

Result: (a) 该方法能在问题规模的线性时间内找到可用的最大CVP近似优化；(b) 结合所提出的格参数，概率计算用于分解半素数时，比类似量子/经典方法减少高达100倍的格实例使用。

Conclusion: 概率计算在格基分解算法的CVP近似优化任务中表现出色，不仅效率高且显著减少了计算资源需求，为格基分解提供了有效的计算加速方案。

Abstract: The closest vector problem (CVP) is a fundamental optimization problem in
lattice-based cryptography and its conjectured hardness underpins the security
of lattice-based cryptosystems. Furthermore, Schnorr's lattice-based factoring
algorithm reduces integer factoring (the foundation of current cryptosystems,
including RSA) to the CVP. Recent work has investigated the inclusion of a
heuristic CVP approximation `refinement' step in the lattice-based factoring
algorithm, using quantum variational algorithms to perform the heuristic
optimization. This coincides with the emergence of probabilistic computing as a
hardware accelerator for randomized algorithms including tasks in combinatorial
optimization. In this work we investigate the application of probabilistic
computing to the heuristic optimization task of CVP approximation refinement in
lattice-based factoring. We present the design of a probabilistic computing
algorithm for this task, a discussion of `prime lattice' parameters, and
experimental results showing the efficacy of probabilistic computing for
solving the CVP as well as its efficacy as a subroutine for lattice-based
factoring. The main results found that (a) this approach is capable of finding
the maximal available CVP approximation refinement in time linear in problem
size and (b) probabilistic computing used in conjunction with the lattice
parameters presented can find the composite prime factors of a semiprime number
using up to 100x fewer lattice instances than similar quantum and classical
methods.

</details>


### [31] [From See to Shield: ML-Assisted Fine-Grained Access Control for Visual Data](https://arxiv.org/abs/2510.19418)
*Mete Harun Akcay,Buse Gul Atli,Siddharth Prakash Rao,Alexandros Bakas*

Main category: cs.CR

TL;DR: 提出了一种可信数据共享系统架构，通过策略驱动的访问控制实现敏感区域的选择性保护，结合自动检测、后校正、密钥管理和访问控制四个核心模块，在保持可扩展性的同时确保数据安全。


<details>
  <summary>Details</summary>
Motivation: 随着存储数据量不断增长，在大型存储库中识别和保护敏感信息变得越来越困难，特别是在与具有不同角色和权限的多个用户共享数据时。

Method: 系统架构整合四个核心模块：自动敏感区域检测、后校正、密钥管理和访问控制。采用混合加密方案，使用对称加密提高效率，基于属性的加密实现策略执行。支持高效密钥分发并隔离密钥存储以增强安全性。

Result: 在视觉数据集上的实验表明，系统提供有效的隐私敏感对象检测，宏观平均F1分数提高5%，平均精度均值提高10%，平均策略执行解密时间每张图像小于1秒。

Conclusion: 该系统为细粒度访问控制提供了一个有效、高效且可扩展的解决方案，能够在大规模数据共享环境中实现敏感信息的保护。

Abstract: As the volume of stored data continues to grow, identifying and protecting
sensitive information within large repositories becomes increasingly
challenging, especially when shared with multiple users with different roles
and permissions. This work presents a system architecture for trusted data
sharing with policy-driven access control, enabling selective protection of
sensitive regions while maintaining scalability. The proposed architecture
integrates four core modules that combine automated detection of sensitive
regions, post-correction, key management, and access control. Sensitive regions
are secured using a hybrid scheme that employs symmetric encryption for
efficiency and Attribute-Based Encryption for policy enforcement. The system
supports efficient key distribution and isolates key storage to strengthen
overall security. To demonstrate its applicability, we evaluate the system on
visual datasets, where Privacy-Sensitive Objects in images are automatically
detected, reassessed, and selectively encrypted prior to sharing in a data
repository. Experimental results show that our system provides effective PSO
detection, increases macro-averaged F1 score (5%) and mean Average Precision
(10%), and maintains an average policy-enforced decryption time of less than 1
second per image. These results demonstrate the effectiveness, efficiency and
scalability of our proposed solution for fine-grained access control.

</details>


### [32] [Monitoring LLM-based Multi-Agent Systems Against Corruptions via Node Evaluation](https://arxiv.org/abs/2510.19420)
*Chengcan Wu,Zhixin Zhang,Mingqian Xu,Zeming Wei,Meng Sun*

Main category: cs.CR

TL;DR: 提出了一种针对基于大语言模型的多智能体系统的动态防御范式，通过持续监控通信并动态调整图拓扑来防御恶意攻击。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统涉及复杂的通信过程，容易受到腐败攻击，现有的静态图防御方法无法有效应对动态攻击。

Method: 动态防御范式：持续监控MAS图中的通信，动态调整图拓扑，准确破坏恶意通信，防御多样化的动态攻击。

Result: 在日益复杂和动态的MAS环境中，该方法显著优于现有的MAS防御机制。

Conclusion: 该方法为基于LLM的多智能体系统的可信应用提供了有效的防护措施。

Abstract: Large Language Model (LLM)-based Multi-Agent Systems (MAS) have become a
popular paradigm of AI applications. However, trustworthiness issues in MAS
remain a critical concern. Unlike challenges in single-agent systems, MAS
involve more complex communication processes, making them susceptible to
corruption attacks. To mitigate this issue, several defense mechanisms have
been developed based on the graph representation of MAS, where agents represent
nodes and communications form edges. Nevertheless, these methods predominantly
focus on static graph defense, attempting to either detect attacks in a fixed
graph structure or optimize a static topology with certain defensive
capabilities. To address this limitation, we propose a dynamic defense paradigm
for MAS graph structures, which continuously monitors communication within the
MAS graph, then dynamically adjusts the graph topology, accurately disrupts
malicious communications, and effectively defends against evolving and diverse
dynamic attacks. Experimental results in increasingly complex and dynamic MAS
environments demonstrate that our method significantly outperforms existing MAS
defense mechanisms, contributing an effective guardrail for their trustworthy
applications. Our code is available at
https://github.com/ChengcanWu/Monitoring-LLM-Based-Multi-Agent-Systems.

</details>


### [33] [Transmitter Identification via Volterra Series Based Radio Frequency Fingerprint](https://arxiv.org/abs/2510.19440)
*Rundong Jiang,Jun Hu,Zhiyuan Xie,Yunqi Song,Shiyou Xu*

Main category: cs.CR

TL;DR: 提出了一种基于Volterra级数和神经网络的新型射频指纹识别方法，通过小波分解处理高维核函数，在LoRa数据集上取得了98%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 无线设备数量增长需要安全网络接入，现有射频指纹识别方法缺乏统一理论框架，手工特征和直接神经网络分类导致泛化性和可解释性不足。

Method: 将发射机建模为黑盒，用Volterra级数表示接收信号，通过小波分解近似核函数，使用最小二乘拟合系数，最后用复数神经网络进行分类。

Result: 在公共LoRa数据集上，静态信道准确率超过98%，多径和多普勒效应下准确率超过90%，达到最先进性能。

Conclusion: 该方法提高了射频指纹识别的可解释性和在不同信道条件下的泛化能力。

Abstract: The growing number of wireless devices increases the need for secure network
access. Radio Frequency Fingerprinting (RFF), a physical-layer authentication
method, offers a promising solution as it requires no cryptography and resists
spoofing. However, existing RFF approaches often lack a unified theory and
effective feature extraction. Many methods use handcrafted signal features or
direct neural network classification, leading to limited generalization and
interpretability. In this work, we model the transmitter as a black box and
analyze its impact on transmitted signals. By treating the deviation from an
ideal signal as hardware-induced distortion, we represent the received signal
using a Volterra series, using its kernels to capture linear and nonlinear
hardware traits. To manage the high dimensionality of these kernels, we
approximate them via wavelet decomposition and estimate coefficients through
least-squares fitting. The resulting wavelet coefficients provide compact yet
informative hardware representations, which are classified using a
complex-valued neural network. Experiments on a public LoRa dataset show
state-of-the-art performance, with over 98% accuracy in static channels and
above 90% under multipath and Doppler effects. The proposed approach improves
both interpretability and generalization across varying channel conditions.

</details>


### [34] [AegisMCP: Online Graph Intrusion Detection for Tool-Augmented LLMs on Edge Devices](https://arxiv.org/abs/2510.19462)
*Zhonghao Zhan,Amir Al Sadi,Krinos Li,Hamed Haddadi*

Main category: cs.CR

TL;DR: 提出了AegisMCP协议级入侵检测器，用于保护MCP智能家居代理工具链的安全，包含攻击套件、行为学习框架和实时检测器。


<details>
  <summary>Details</summary>
Motivation: 研究MCP代理工具链在智能家居中的安全性问题，需要检测协议级别的入侵行为。

Method: 开发了NEBULA-Schema行为学习框架，将MCP活动表示为流式异质时序图，并构建了CPU专用流式检测器，融合新颖性、会话DAG结构和属性线索。

Result: 在模拟智能家居测试平台上，AegisMCP实现了亚秒级的窗口模型推理和端到端告警，在边缘硬件上性能优于流量和序列基线方法。

Conclusion: AegisMCP能有效检测MCP协议级入侵，DAG和安装/权限信号对检测性能至关重要，提供了可复现的评估代码和方案。

Abstract: In this work, we study security of Model Context Protocol (MCP) agent
toolchains and their applications in smart homes. We introduce AegisMCP, a
protocol-level intrusion detector. Our contributions are: (i) a minimal attack
suite spanning instruction-driven escalation, chain-of-tool exfiltration,
malicious MCP server registration, and persistence; (ii) NEBULA-Schema
(Network-Edge Behavioral Learning for Untrusted LLM Agents), a reusable
protocol-level instrumentation that represents MCP activity as a streaming
heterogeneous temporal graph over agents, MCP servers, tools, devices, remotes,
and sessions; and (iii) a CPU-only streaming detector that fuses novelty,
session-DAG structure, and attribute cues for near-real-time edge inference,
with optional fusion of local prompt-guardrail signals. On an emulated
smart-home testbed spanning multiple MCP stacks and a physical bench, AegisMCP
achieves sub-second per-window model inference and end-to-end alerting. The
latency of AegisMCP is consistently sub-second on Intel N150-class edge
hardware, while outperforming traffic-only and sequence baselines; ablations
confirm the importance of DAG and install/permission signals. We release code,
schemas, and generators for reproducible evaluation.

</details>


### [35] [Cross-Chain Sealed-Bid Auctions Using Confidential Compute Blockchains](https://arxiv.org/abs/2510.19491)
*Jonas Gebele,Timm Mutzel,Burak Oez,Florian Matthes*

Main category: cs.CR

TL;DR: 提出了一个基于可信执行环境(TEE)的密封投标拍卖协议，在保密计算区块链上执行敏感投标逻辑，同时在公共链上进行结算和执行，解决了密封投标拍卖中的隐私、可验证性和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 密封投标拍卖需要公平竞争和高效分配，但集中式基础设施存在操纵风险，而公共区块链的透明度又与投标保密性冲突。现有方案难以在不依赖可信中介、多轮协议或昂贵密码学的情况下平衡隐私、可验证性和可扩展性。

Method: 使用TEE支持的保密计算区块链执行投标逻辑，投标人将资金提交到由安全区域生成的托管地址。任何方可在截止日期后触发解决方案，保密区块链通过可验证的链下计算确定获胜者，并在公共链上执行签名的结算交易。

Result: 该设计在不依赖可信第三方或协议修改的情况下提供了安全性、隐私性和可扩展性。在SUAVE上实现并与以太坊结算集成，评估了可扩展性和信任假设，展示了在现有基础设施上的最小集成部署。

Conclusion: 该协议成功解决了密封投标拍卖中的核心挑战，通过TEE和区块链的结合实现了隐私保护、可验证性和可扩展性的平衡，为实际部署提供了可行方案。

Abstract: Sealed-bid auctions ensure fair competition and efficient allocation but are
often deployed on centralized infrastructure, enabling opaque manipulation.
Public blockchains eliminate central control, yet their inherent transparency
conflicts with the confidentiality required for sealed bidding. Prior attempts
struggle to reconcile privacy, verifiability, and scalability without relying
on trusted intermediaries, multi-round protocols, or expensive cryptography. We
present a sealed-bid auction protocol that executes sensitive bidding logic on
a Trusted Execution Environment (TEE)-backed confidential compute blockchain
while retaining settlement and enforcement on a public chain. Bidders commit
funds to enclave-generated escrow addresses, ensuring confidentiality and
binding commitments. After the deadline, any party can trigger resolution: the
confidential blockchain determines the winner through verifiable off-chain
computation and issues signed settlement transactions for execution on the
public chain. Our design provides security, privacy, and scalability without
trusted third parties or protocol modifications. We implement it on SUAVE with
Ethereum settlement, evaluate its scalability and trust assumptions, and
demonstrate deployment with minimal integration on existing infrastructure

</details>


### [36] [Privacy-Preserving Spiking Neural Networks: A Deep Dive into Encryption Parameter Optimisation](https://arxiv.org/abs/2510.19537)
*Mahitha Pulivathi*

Main category: cs.CR

TL;DR: BioEncryptSNN是一个基于脉冲神经网络的加密-解密框架，通过将密文转换为脉冲序列并利用时间神经动力学来建模加密和解密过程，在保持数据完整性的同时实现了比传统加密算法更快的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型的计算和能耗需求不断增长，同时云模型执行中的数据隐私问题促使采用加密方法。脉冲神经网络模拟大脑的事件驱动行为，提供了更好的性能和更低的功耗。

Method: BioEncryptSNN将密文转换为脉冲序列，利用时间神经动力学来建模加密和解密过程，优化密钥长度、脉冲时序和突触连接等参数。

Result: 与AES-128、RSA-2048和DES相比，BioEncryptSNN在保持数据完整性的同时，加密和解密速度比PyCryptodome的AES实现快4.1倍。该框架在对称和非对称密码中表现出可扩展性和适应性。

Conclusion: SNNs为安全、节能的计算提供了一个有前景的方向，BioEncryptSNN展示了脉冲神经网络在加密应用中的潜力。

Abstract: Deep learning is widely applied to modern problems through neural networks,
but the growing computational and energy demands of these models have driven
interest in more efficient approaches. Spiking Neural Networks (SNNs), the
third generation of neural networks, mimic the brain's event-driven behaviour,
offering improved performance and reduced power use. At the same time, concerns
about data privacy during cloud-based model execution have led to the adoption
of cryptographic methods. This article introduces BioEncryptSNN, a spiking
neural network based encryption-decryption framework for secure and
noise-resilient data protection. Unlike conventional algorithms, BioEncryptSNN
converts ciphertext into spike trains and exploits temporal neural dynamics to
model encryption and decryption, optimising parameters such as key length,
spike timing, and synaptic connectivity. Benchmarked against AES-128, RSA-2048,
and DES, BioEncryptSNN preserved data integrity while achieving up to 4.1x
faster encryption and decryption than PyCryptodome's AES implementation. The
framework demonstrates scalability and adaptability across symmetric and
asymmetric ciphers, positioning SNNs as a promising direction for secure,
energy-efficient computing.

</details>


### [37] [CircuitGuard: Mitigating LLM Memorization in RTL Code Generation Against IP Leakage](https://arxiv.org/abs/2510.19676)
*Nowfel Mashnoor,Mohammad Akyash,Hadi Kamali,Kimia Azar*

Main category: cs.CR

TL;DR: CircuitGuard是一种针对LLM在RTL代码生成中记忆问题的防御策略，通过RTL感知相似性度量和激活级引导方法，在减少知识产权泄露的同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: LLM在RTL硬件综合中容易记忆训练数据，导致专有或安全敏感设计在推理时意外泄露。RTL代码的结构特性使得即使没有字面重叠也可能造成IP泄露，而小的语法变化又会严重影响电路行为。

Method: CircuitGuard包含：(1)新颖的RTL感知相似性度量，捕捉结构和功能等价性；(2)激活级引导方法，识别并衰减负责记忆的transformer组件。

Result: 在Llama 3.1-8B模型中识别出275个记忆关键特征，实现高达80%的语义相似性降低，同时保持生成质量，跨域转移效果达78-85%。

Conclusion: CircuitGuard有效平衡了泄露减少和正确性保持，为RTL代码生成的记忆问题提供了实用解决方案。

Abstract: Large Language Models (LLMs) have achieved remarkable success in generative
tasks, including register-transfer level (RTL) hardware synthesis. However,
their tendency to memorize training data poses critical risks when proprietary
or security-sensitive designs are unintentionally exposed during inference.
While prior work has examined memorization in natural language, RTL introduces
unique challenges: In RTL, structurally different implementations (e.g.,
behavioral vs. gate-level descriptions) can realize the same hardware, leading
to intellectual property (IP) leakage (full or partial) even without verbatim
overlap. Conversely, even small syntactic variations (e.g., operator precedence
or blocking vs. non-blocking assignments) can drastically alter circuit
behavior, making correctness preservation especially challenging. In this work,
we systematically study memorization in RTL code generation and propose
CircuitGuard, a defense strategy that balances leakage reduction with
correctness preservation. CircuitGuard (1) introduces a novel RTL-aware
similarity metric that captures both structural and functional equivalence
beyond surface-level overlap, and (2) develops an activation-level steering
method that identifies and attenuates transformer components most responsible
for memorization. Our empirical evaluation demonstrates that CircuitGuard
identifies (and isolates) 275 memorization-critical features across layers
18-28 of Llama 3.1-8B model, achieving up to 80% reduction in semantic
similarity to proprietary patterns while maintaining generation quality.
CircuitGuard further shows 78-85% cross-domain transfer effectiveness, enabling
robust memorization mitigation across circuit categories without retraining.

</details>


### [38] [Exploring the Effect of DNN Depth on Adversarial Attacks in Network Intrusion Detection Systems](https://arxiv.org/abs/2510.19761)
*Mohamed ElShehaby,Ashraf Matrawy*

Main category: cs.CR

TL;DR: 论文研究了在NIDS领域，增加深度神经网络层数对对抗攻击鲁棒性的影响，发现在NIDS中增加层数会显著降低鲁棒性，而在计算机视觉领域影响较小。


<details>
  <summary>Details</summary>
Motivation: 对抗攻击对机器学习系统特别是深度神经网络构成重大挑战，本研究旨在探讨在网络入侵检测系统(NIDS)领域中，增加神经网络层深度是否会影响其对抗攻击的鲁棒性。

Method: 比较了不同深度神经网络在NIDS和计算机视觉领域的对抗鲁棒性，后者被广泛用于对抗攻击实验。

Result: 实验结果显示，在NIDS领域，增加更多层不一定会提高性能，反而可能显著降低对抗攻击的鲁棒性；而在计算机视觉领域，增加层数对鲁棒性的影响较为温和。

Conclusion: 这些发现可为开发鲁棒的NIDS神经网络提供指导，并突显了网络安全领域在机器学习环境中的独特性。

Abstract: Adversarial attacks pose significant challenges to Machine Learning (ML)
systems and especially Deep Neural Networks (DNNs) by subtly manipulating
inputs to induce incorrect predictions. This paper investigates whether
increasing the layer depth of deep neural networks affects their robustness
against adversarial attacks in the Network Intrusion Detection System (NIDS)
domain. We compare the adversarial robustness of various deep neural networks
across both \ac{NIDS} and computer vision domains (the latter being widely used
in adversarial attack experiments). Our experimental results reveal that in the
NIDS domain, adding more layers does not necessarily improve their performance,
yet it may actually significantly degrade their robustness against adversarial
attacks. Conversely, in the computer vision domain, adding more layers exhibits
a more modest impact on robustness. These findings can guide the development of
robust neural networks for (NIDS) applications and highlight the unique
characteristics of network security domains within the (ML) landscape.

</details>


### [39] [Under Pressure: Security Analysis and Process Impacts of a Commercial Smart Air Compressor](https://arxiv.org/abs/2510.19772)
*Jad Zarzour,Matthew Jablonski*

Main category: cs.CR

TL;DR: 对商用智能空压机进行安全分析，发现硬编码凭证、未认证API和不安全更新机制等关键漏洞，通过威胁模型和实际攻击演示展示了这些漏洞对工业过程的严重影响。


<details>
  <summary>Details</summary>
Motivation: 工业物联网设备在制造业的广泛应用加速了工业4.0转型，但也带来了新的网络安全风险，需要对这些设备进行全面的安全评估。

Method: 采用综合安全分析方法，包括正式威胁建模、测试环境中的实际攻击场景演示，以及对设备供应链的分析。

Result: 发现多个关键安全漏洞，包括硬编码凭证、未认证API和不安全更新机制，这些漏洞可导致服务拒绝和关键过程遥测数据损坏。

Conclusion: 研究强调了将网络安全原则纳入IIoT设备设计和供应链治理的必要性，以增强对新兴工业网络威胁的抵御能力。

Abstract: The integration of Industrial Internet of Things (IIoT) devices into
manufacturing environments has accelerated the transition to Industry 4.0, but
has also introduced new cybersecurity risks. This paper conducts a
comprehensive security analysis of a commercial smart air compressor, revealing
critical vulnerabilities including hardcoded credentials, unauthenticated APIs,
and an insecure update mechanism. It includes a formal threat model,
demonstrates practical attack scenarios in a testbed environment, and evaluates
their subsequent impact on an industrial process, leading to denial of service
and the corruption of critical process telemetry. In addition, an analysis of
the device's supply chain reveals how product integration from multiple vendors
and limited security considerations can expose a device to threats. The
findings underscore the necessity of incorporating cybersecurity principles
into both IIoT device design and supply chain governance to enhance resilience
against emerging industrial cyber threats.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [40] [Test-time Verification via Optimal Transport: Coverage, ROC, & Sub-optimality](https://arxiv.org/abs/2510.18982)
*Arpan Mukherjee,Marcello Bullo,Debabrota Basu,Deniz Gündüz*

Main category: cs.AI

TL;DR: 本文提出了一个统一框架来分析验证式测试时扩展中生成器覆盖率、验证器收敛区域和采样算法次优性之间的几何关系，揭示了次优性-覆盖率曲线的三个区域。


<details>
  <summary>Details</summary>
Motivation: 虽然带有验证的测试时扩展在提升大语言模型性能方面显示出潜力，但验证器的作用及其缺陷仍未充分探索。现有研究只捕捉了这些因素的部分子集，缺乏量化它们相互作用几何特征的统一框架。

Method: 将可验证的测试时扩展构建为传输问题，提出了两类采样算法（顺序和批量），并分析了它们的计算复杂度如何影响这些权衡关系。

Result: 理论分析揭示了次优性-覆盖率曲线存在三个区域：传输区域（次优性随覆盖率增加）、策略改进区域（次优性可能随覆盖率减少，取决于验证器的收敛区域）和饱和区域（次优性趋于稳定）。在Qwen、Llama和Gemma模型上的实证结果验证了理论发现。

Conclusion: 通过传输问题框架，本文系统分析了验证式测试时扩展中三个关键因素的相互作用，为理解和优化大语言模型的测试时扩展提供了理论基础和实践指导。

Abstract: While test-time scaling with verification has shown promise in improving the
performance of large language models (LLMs), the role of the verifier and its
imperfections remain underexplored. The effect of verification manifests
through interactions of three quantities: (i) the generator's coverage, (ii)
the verifier's region of convergence (ROC), and (iii) the sampling algorithm's
sub-optimality. Though recent studies capture subsets of these factors, a
unified framework quantifying the geometry of their interplay is missing. We
frame verifiable test-time scaling as a transport problem. This characterizes
the interaction of coverage, ROC, and sub-optimality, and uncovers that the
sub-optimality--coverage curve exhibits three regimes. A transport regime --
where sub-optimality increases with coverage, a policy improvement regime --
where sub-optimality may decrease with coverage, depending on the verifier's
ROC, and a saturation regime -- where sub-optimality plateaus, unaffected by
coverage. We further propose and analyze two classes of sampling algorithms --
sequential and batched, and examine how their computational complexities shape
these trade-offs. Empirical results with Qwen, Llama, and Gemma models
corroborate our theoretical findings.

</details>


### [41] [Timely Clinical Diagnosis through Active Test Selection](https://arxiv.org/abs/2510.18988)
*Silas Ruhrberg Estévez,Nicolás Astorga,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: ACTMED是一个结合贝叶斯实验设计和大型语言模型的临床诊断框架，通过逐步选择能最大程度减少诊断不确定性的测试来优化诊断过程。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习诊断方法依赖静态数据集，无法模拟临床医生在实践中的顺序性、资源感知推理，特别是在高压或资源有限环境中诊断复杂且易出错。

Method: 将贝叶斯实验设计与大型语言模型结合，LLMs作为灵活模拟器生成患者状态分布并支持信念更新，无需结构化任务特定训练数据。

Result: 在真实世界数据集上的评估显示，ACTMED能优化测试选择，提高诊断准确性、可解释性和资源利用效率。

Conclusion: 该框架代表了向透明、自适应且与临床医生对齐的诊断系统迈出的一步，能在减少对领域特定数据依赖的情况下跨环境泛化。

Abstract: There is growing interest in using machine learning (ML) to support clinical
diag- nosis, but most approaches rely on static, fully observed datasets and
fail to reflect the sequential, resource-aware reasoning clinicians use in
practice. Diagnosis remains complex and error prone, especially in
high-pressure or resource-limited settings, underscoring the need for
frameworks that help clinicians make timely and cost-effective decisions. We
propose ACTMED (Adaptive Clinical Test selection via Model-based Experimental
Design), a diagnostic framework that integrates Bayesian Experimental Design
(BED) with large language models (LLMs) to better emulate real-world diagnostic
reasoning. At each step, ACTMED selects the test expected to yield the greatest
reduction in diagnostic uncertainty for a given patient. LLMs act as flexible
simulators, generating plausible patient state distributions and supporting
belief updates without requiring structured, task-specific training data.
Clinicians can remain in the loop; reviewing test suggestions, interpreting
intermediate outputs, and applying clinical judgment throughout. We evaluate
ACTMED on real-world datasets and show it can optimize test selection to
improve diagnostic accuracy, interpretability, and resource use. This
represents a step to- ward transparent, adaptive, and clinician-aligned
diagnostic systems that generalize across settings with reduced reliance on
domain-specific data.

</details>


### [42] [Rectifying Shortcut Behaviors in Preference-based Reward Learning](https://arxiv.org/abs/2510.19050)
*Wenqian Ye,Guangtao Zheng,Aidong Zhang*

Main category: cs.AI

TL;DR: 提出PRISM方法，通过学习群不变核来缓解基于偏好的奖励模型中的捷径行为问题，提高奖励模型在分布外任务上的准确性。


<details>
  <summary>Details</summary>
Motivation: 基于人类反馈的强化学习中，偏好奖励模型容易出现过优化和奖励黑客问题，通过利用训练数据中的虚假特征（如回答冗长、讨好语气等）来获得高奖励分数，而非真正反映预期目标。

Method: 受核视角不变性理论启发，提出PRISM方法，通过闭式学习目标学习具有特征映射的群不变核，缓解偏好奖励学习中的捷径行为。

Result: 在多个基准测试中，该方法一致提高了奖励模型在多样化分布外任务上的准确性，并减少了下游策略模型对捷径的依赖。

Conclusion: PRISM为基于偏好的对齐建立了一个稳健框架，有效缓解了奖励模型中的捷径行为问题。

Abstract: In reinforcement learning from human feedback, preference-based reward models
play a central role in aligning large language models to human-aligned
behavior. However, recent studies show that these models are prone to reward
hacking and often fail to generalize well due to over-optimization. They
achieve high reward scores by exploiting shortcuts, that is, exploiting
spurious features (e.g., response verbosity, agreeable tone, or sycophancy)
that correlate with human preference labels in the training data rather than
genuinely reflecting the intended objectives. In this paper, instead of probing
these issues one at a time, we take a broader view of the reward hacking
problem as shortcut behaviors and introduce a principled yet flexible approach
to mitigate shortcut behaviors in preference-based reward learning. Inspired by
the invariant theory in the kernel perspective, we propose Preference-based
Reward Invariance for Shortcut Mitigation (PRISM), which learns group-invariant
kernels with feature maps in a closed-form learning objective. Experimental
results in several benchmarks show that our method consistently improves the
accuracy of the reward model on diverse out-of-distribution tasks and reduces
the dependency on shortcuts in downstream policy models, establishing a robust
framework for preference-based alignment.

</details>


### [43] [The MUSE Benchmark: Probing Music Perception and Auditory Relational Reasoning in Audio LLMS](https://arxiv.org/abs/2510.19055)
*Brandon James Carone,Iran R. Roman,Pablo Ripollés*

Main category: cs.AI

TL;DR: MUSE基准测试揭示当前多模态大语言模型在音乐理解方面存在严重缺陷，特别是在关系推理方面，与人类专家存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前对多模态大语言模型音频理解能力的评估可能掩盖了其在关系推理方面的根本弱点，需要更全面的评估工具。

Method: 开发了MUSE基准测试，包含10个任务来探测基础音乐感知技能，评估了4个SOTA模型并与200人的人类基线进行对比。

Result: SOTA模型能力差异巨大，与人类专家存在持续差距。Gemini Pro在基础感知上表现良好，但Qwen和Audio Flamingo 3表现接近随机水平。思维链提示效果不一致且往往有害。

Conclusion: MUSE基准为评估不变音乐表征和开发更鲁棒的AI系统提供了关键工具。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated capabilities in
audio understanding, but current evaluations may obscure fundamental weaknesses
in relational reasoning. We introduce the Music Understanding and Structural
Evaluation (MUSE) Benchmark, an open-source resource with 10 tasks designed to
probe fundamental music perception skills. We evaluate four SOTA models (Gemini
Pro and Flash, Qwen2.5-Omni, and Audio-Flamingo 3) against a large human
baseline (N=200). Our results reveal a wide variance in SOTA capabilities and a
persistent gap with human experts. While Gemini Pro succeeds on basic
perception, Qwen and Audio Flamingo 3 perform at or near chance, exposing
severe perceptual deficits. Furthermore, we find Chain-of-Thought (CoT)
prompting provides inconsistent, often detrimental results. Our work provides a
critical tool for evaluating invariant musical representations and driving
development of more robust AI systems.

</details>


### [44] [A Multi-faceted Analysis of Cognitive Abilities: Evaluating Prompt Methods with Large Language Models on the CONSORT Checklist](https://arxiv.org/abs/2510.19139)
*Sohyeon Jeon,Hyung-Chul Lee*

Main category: cs.AI

TL;DR: 该研究评估了大型语言模型(LLMs)在根据CONSORT标准评估临床试验报告方面的能力，发现不同模型和提示条件在推理风格、不确定性表达和替代解释方面存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在医疗领域快速扩展，但它们按照CONSORT标准评估临床试验报告的能力仍不明确，特别是在认知和推理策略方面。

Method: 采用行为和元认知分析方法，使用专家验证数据，系统比较了两个代表性LLM在三种提示条件下的表现。

Result: 模型在处理不同CONSORT项目和提示类型时表现出明显差异，包括推理风格的转变、明确的不确定性表达和替代解释模式。

Conclusion: 结果突显了这些系统在临床合规自动化方面的当前局限性，并强调了理解其认知适应和策略行为对于开发更可解释和可靠的医疗AI的重要性。

Abstract: Despite the rapid expansion of Large Language Models (LLMs) in healthcare,
the ability of these systems to assess clinical trial reporting according to
CONSORT standards remains unclear, particularly with respect to their cognitive
and reasoning strategies. This study applies a behavioral and metacognitive
analytic approach with expert-validated data, systematically comparing two
representative LLMs under three prompt conditions. Clear differences emerged in
how the models approached various CONSORT items, and prompt types, including
shifts in reasoning style, explicit uncertainty, and alternative
interpretations shaped response patterns. Our results highlight the current
limitations of these systems in clinical compliance automation and underscore
the importance of understanding their cognitive adaptations and strategic
behavior in developing more explainable and reliable medical AI.

</details>


### [45] [The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early Exit in Reasoning Models](https://arxiv.org/abs/2510.19176)
*Yuqiao Tan,Shizhu He,Kang Liu,Jun Zhao*

Main category: cs.AI

TL;DR: 论文提出模式选择作为早期退出的更具挑战性变体，旨在通过零步思维在推理开始前决定使用长链思维还是短链思维模式，以减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 推理模型在数学和逻辑推理任务中表现出色，但其逐步思考过程常导致过度思考，产生不必要的计算负担。模式选择和早期退出方法都旨在减轻这种计算负担。

Method: 将模式选择识别为早期退出问题的变体，在推理过程开始时基于预定义的虚假思维做出决策（零步思维）。通过九个基线的实证研究，比较了基于提示的方法和利用内部信息的方法。

Result: 基于提示的方法由于分类能力有限而经常失败，而利用内部信息的方法在大多数场景中表现更好但仍存在稳定性问题。现有方法在信息有限的情况下不足以有效解决模式选择问题。

Conclusion: 仅依赖模型提供信息的现有方法在信息有限场景下无法有效解决模式选择问题，突显了该任务的持续挑战性。

Abstract: Reasoning models have demonstrated exceptional performance in tasks such as
mathematics and logical reasoning, primarily due to their ability to engage in
step-by-step thinking during the reasoning process. However, this often leads
to overthinking, resulting in unnecessary computational overhead. To address
this issue, Mode Selection aims to automatically decide between Long-CoT
(Chain-of-Thought) or Short-CoT by utilizing either a Thinking or NoThinking
mode. Simultaneously, Early Exit determines the optimal stopping point during
the iterative reasoning process. Both methods seek to reduce the computational
burden. In this paper, we first identify Mode Selection as a more challenging
variant of the Early Exit problem, as they share similar objectives but differ
in decision timing. While Early Exit focuses on determining the best stopping
point for concise reasoning at inference time, Mode Selection must make this
decision at the beginning of the reasoning process, relying on pre-defined fake
thoughts without engaging in an explicit reasoning process, referred to as
zero-step thinking. Through empirical studies on nine baselines, we observe
that prompt-based approaches often fail due to their limited classification
capabilities when provided with minimal hand-crafted information. In contrast,
approaches that leverage internal information generally perform better across
most scenarios but still exhibit issues with stability. Our findings indicate
that existing methods relying solely on the information provided by models are
insufficient for effectively addressing Mode Selection in scenarios with
limited information, highlighting the ongoing challenges of this task. Our code
is available at https://github.com/Trae1ounG/Zero_Step_Thinking.

</details>


### [46] [WebGraphEval: Multi-Turn Trajectory Evaluation for Web Agents using Graph Representation](https://arxiv.org/abs/2510.19205)
*Yaoyao Qian,Yuanli Wang,Jinda Zhang,Yun Zong,Meixu Chen,Hanhan Zhou,Jindan Huang,Yifan Zeng,Xinyu Hu,Chan Hee Song,Danqing Zhang*

Main category: cs.AI

TL;DR: WebGraphEval是一个将多个智能体的网页交互轨迹抽象为统一加权行动图的框架，用于评估网页智能体的结构多样性和效率，超越传统的二元成功指标。


<details>
  <summary>Details</summary>
Motivation: 当前网页智能体评估主要依赖二元成功指标或单一参考轨迹，忽略了基准数据集中存在的结构多样性问题。

Method: 将多个智能体的轨迹抽象为统一的加权行动图，规范编码行动，合并重复行为，并应用结构分析包括奖励传播和成功加权边缘统计。

Result: 对六个网页智能体的数千条轨迹评估显示，图抽象捕捉了跨模型规律性，突显了冗余和低效，识别了基于结果指标忽略的关键决策点。

Conclusion: 通过将网页交互构建为图结构数据，WebGraphEval建立了多路径、跨智能体和效率感知的网页智能体评估通用方法。

Abstract: Current evaluation of web agents largely reduces to binary success metrics or
conformity to a single reference trajectory, ignoring the structural diversity
present in benchmark datasets. We present WebGraphEval, a framework that
abstracts trajectories from multiple agents into a unified, weighted action
graph. This representation is directly compatible with benchmarks such as
WebArena, leveraging leaderboard runs and newly collected trajectories without
modifying environments. The framework canonically encodes actions, merges
recurring behaviors, and applies structural analyses including reward
propagation and success-weighted edge statistics. Evaluations across thousands
of trajectories from six web agents show that the graph abstraction captures
cross-model regularities, highlights redundancy and inefficiency, and
identifies critical decision points overlooked by outcome-based metrics. By
framing web interaction as graph-structured data, WebGraphEval establishes a
general methodology for multi-path, cross-agent, and efficiency-aware
evaluation of web agents.

</details>


### [47] [ChatGPT Unveils Its Limits: Principles of Law Deliver Checkmate](https://arxiv.org/abs/2510.19261)
*Marianna Molinari,Ilaria Angela Amantea,Marinella Quaranta,Guido Governatori*

Main category: cs.AI

TL;DR: 本研究通过法律领域实验评估ChatGPT性能，发现即使其具备必要知识和能力，也无法有效整合推理以得出全面结果，揭示了其在复杂问题分解和综合解决方面的重大局限。


<details>
  <summary>Details</summary>
Motivation: 评估ChatGPT在法律领域的实际表现，特别是与基于正则表达式的基线方法对比，而非仅与人类表现比较，以揭示其真正的能力局限。

Method: 在法律领域进行实验，将ChatGPT与基于正则表达式(Regex)的基线方法进行性能对比，分析其在法律决策中提取关键段落和法律原则的能力。

Result: 研究表明ChatGPT即使拥有必要知识和能力，也无法有效整合推理以产生全面结果，在复杂问题分解和综合解决方面存在重大局限。

Conclusion: 真正的智能需要具备分解复杂问题并根据多种所需能力进行推理的能力，而在法律领域，这种全面理解和推理能力目前仍是人类独有的特质。

Abstract: This study examines the performance of ChatGPT with an experiment in the
legal domain. We compare the outcome with it a baseline using regular
expressions (Regex), rather than focusing solely on the assessment against
human performance. The study reveals that even if ChatGPT has access to the
necessary knowledge and competencies, it is unable to assemble them, reason
through, in a way that leads to an exhaustive result. This unveils a major
limitation of ChatGPT. Intelligence encompasses the ability to break down
complex issues and address them according to multiple required competencies,
providing a unified and comprehensive solution. In the legal domain, one of the
most crucial tasks is reading legal decisions and extracting key passages
condensed from principles of law (PoLs), which are then incorporated into
subsequent rulings by judges or defense documents by lawyers. In performing
this task, artificial intelligence lacks an all-encompassing understanding and
reasoning, which makes it inherently limited. Genuine intelligence, remains a
uniquely human trait, at least in this particular field.

</details>


### [48] [An Argumentative Explanation Framework for Generalized Reason Model with Inconsistent Precedents](https://arxiv.org/abs/2510.19263)
*Wachara Fungwacharakorn,Gauvain Bourgne,Ken Satoh*

Main category: cs.AI

TL;DR: 本文扩展了推导状态论证框架，为容纳不一致先例的广义推理模型提供论证性解释方法


<details>
  <summary>Details</summary>
Motivation: 传统先例约束假设先例集必须一致，但广义推理模型放宽了这一假设。目前已有基于传统一致推理模型的论证解释方法，但缺乏针对广义推理框架的相应方法

Method: 扩展推导状态论证框架，使其能够解释基于广义推理模型的推理过程

Result: 开发了能够处理不一致先例的论证解释框架

Conclusion: 成功扩展了DSA框架，为广义推理模型提供了有效的论证性解释方法

Abstract: Precedential constraint is one foundation of case-based reasoning in AI and
Law. It generally assumes that the underlying set of precedents must be
consistent. To relax this assumption, a generalized notion of the reason model
has been introduced. While several argumentative explanation approaches exist
for reasoning with precedents based on the traditional consistent reason model,
there has been no corresponding argumentative explanation method developed for
this generalized reasoning framework accommodating inconsistent precedents. To
address this question, this paper examines an extension of the derivation state
argumentation framework (DSA-framework) to explain the reasoning according to
the generalized notion of the reason model.

</details>


### [49] [Learning to Make Friends: Coaching LLM Agents toward Emergent Social Ties](https://arxiv.org/abs/2510.19299)
*Philipp J. Schneider,Lin Tian,Marian-Andrei Rizoiu*

Main category: cs.AI

TL;DR: 提出了一个多智能体LLM模拟框架，通过行为奖励函数和情境学习来研究LLM智能体是否能复现人类在线社交动态，包括同质性、互惠性和社会验证等特征。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型智能体是否能重现人类在线行为的复杂社交动态，以及什么记忆和学习机制能使这种动态出现。

Method: 设计了一个多智能体LLM模拟框架，智能体通过行为奖励函数（捕捉社交互动、信息寻求、自我展示、协调和情感支持等核心驱动因素）进行重复互动、相互评估，并通过情境学习加速适应过程。

Result: 实验表明，经过指导的LLM智能体能够发展出稳定的互动模式并形成涌现的社交联系，产生的网络结构反映了真实在线社区的特性。

Conclusion: 该框架为研究LLM群体中的集体动态建立了一个原则性测试平台，揭示了人工智能体如何近似或偏离类人社交行为。

Abstract: Can large language model (LLM) agents reproduce the complex social dynamics
that characterize human online behavior -- shaped by homophily, reciprocity,
and social validation -- and what memory and learning mechanisms enable such
dynamics to emerge? We present a multi-agent LLM simulation framework in which
agents repeatedly interact, evaluate one another, and adapt their behavior
through in-context learning accelerated by a coaching signal. To model human
social behavior, we design behavioral reward functions that capture core
drivers of online engagement, including social interaction, information
seeking, self-presentation, coordination, and emotional support. These rewards
align agent objectives with empirically observed user motivations, enabling the
study of how network structures and group formations emerge from individual
decision-making. Our experiments show that coached LLM agents develop stable
interaction patterns and form emergent social ties, yielding network structures
that mirror properties of real online communities. By combining behavioral
rewards with in-context adaptation, our framework establishes a principled
testbed for investigating collective dynamics in LLM populations and reveals
how artificial agents may approximate or diverge from human-like social
behavior.

</details>


### [50] [Continual Knowledge Adaptation for Reinforcement Learning](https://arxiv.org/abs/2510.19314)
*Jinwu Hu,Zihao Lian,Zhiquan Wen,Chenghao Li,Guohao Chen,Xutao Wen,Bin Xiao,Mingkui Tan*

Main category: cs.AI

TL;DR: 提出了CKA-RL方法，通过持续知识适应策略和自适应知识合并机制，解决强化学习中的灾难性遗忘和知识利用效率问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界环境通常是非平稳的，需要智能体持续适应新任务和变化条件。现有的持续强化学习方法存在灾难性遗忘和知识利用效率低的问题。

Method: 提出持续知识适应策略，维护任务特定知识向量池，动态使用历史知识适应新任务；引入自适应知识合并机制，合并相似知识向量以减少内存需求。

Result: 在三个基准测试上优于现有最优方法，整体性能提升4.20%，前向迁移提升8.02%。

Conclusion: CKA-RL能有效缓解灾难性遗忘，实现跨任务的高效知识迁移，在持续强化学习场景中表现优异。

Abstract: Reinforcement Learning enables agents to learn optimal behaviors through
interactions with environments. However, real-world environments are typically
non-stationary, requiring agents to continuously adapt to new tasks and
changing conditions. Although Continual Reinforcement Learning facilitates
learning across multiple tasks, existing methods often suffer from catastrophic
forgetting and inefficient knowledge utilization. To address these challenges,
we propose Continual Knowledge Adaptation for Reinforcement Learning (CKA-RL),
which enables the accumulation and effective utilization of historical
knowledge. Specifically, we introduce a Continual Knowledge Adaptation
strategy, which involves maintaining a task-specific knowledge vector pool and
dynamically using historical knowledge to adapt the agent to new tasks. This
process mitigates catastrophic forgetting and enables efficient knowledge
transfer across tasks by preserving and adapting critical model parameters.
Additionally, we propose an Adaptive Knowledge Merging mechanism that combines
similar knowledge vectors to address scalability challenges, reducing memory
requirements while ensuring the retention of essential knowledge. Experiments
on three benchmarks demonstrate that the proposed CKA-RL outperforms
state-of-the-art methods, achieving an improvement of 4.20% in overall
performance and 8.02% in forward transfer. The source code is available at
https://github.com/Fhujinwu/CKA-RL.

</details>


### [51] [MSC-Bench: A Rigorous Benchmark for Multi-Server Tool Orchestration](https://arxiv.org/abs/2510.19423)
*Jia-Kai Dong,I-Wei Huang,Chun-Tin Wu,Yi-Tien Tsai*

Main category: cs.AI

TL;DR: MSC-Bench是一个用于评估LLM代理在多跳、端到端工具编排能力的大规模基准测试，通过构建"等函数集"作为基准真值，提供客观评估指标，减少对LLM作为评判的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试往往孤立评估工具，忽略了功能重叠和跨服务器编排等挑战，导致评估过于乐观。MSC-Bench旨在解决这些差距。

Method: 采用五级课程设计，从单工具编排到复杂跨服务器规划，系统测试代理能力，并构建"等函数集"作为基准真值。

Result: 实验表明，僵化的层次结构会阻碍性能，即使最先进的代理在鲁棒性方面也存在系统性弱点。

Conclusion: MSC-Bench提供了一个诊断框架，暴露现有方法的局限性，指导开发更强大高效的工具使用代理。

Abstract: We introduce MSC-Bench, a large-scale benchmark for evaluating multi-hop,
end-to-end tool orchestration by LLM agents in a hierarchical Model-Context
Protocol (MCP) ecosystem. Existing benchmarks often evaluate tools in
isolation, ignoring challenges such as functional overlap and cross-server
orchestration, leading to overly optimistic assessments. MSC-Bench addresses
these gaps by constructing ground truth through 'equal function sets', allowing
objective metrics such as F1 score and reducing the dependency on
LLM-as-a-judge evaluation. Organized as a five-level curriculum, it
systematically tests agent capabilities from single-tool orchestration to
complex cross-server planning, and robustness to out-of-scope requests.
Experiments reveal that rigid hierarchies can hinder performance without
co-designed strategies, and even state-of-the-art agents exhibit systemic
weaknesses in robustness. MSC-Bench provides a diagnostic framework to expose
these limitations and guide the development of more capable and efficient
tool-using agents. The benchmark and resources are publicly available at
https://github.com/snooow1029/MSC_Bench.

</details>


### [52] [NeSyPr: Neurosymbolic Proceduralization For Efficient Embodied Reasoning](https://arxiv.org/abs/2510.19429)
*Wonje Choi,Jooyoung Kim,Honguk Woo*

Main category: cs.AI

TL;DR: NeSyPr是一个神经符号程序化框架，通过将符号规划转化为可组合的程序表示，使语言模型能够在动态环境中进行高效推理，无需依赖外部符号规划器。


<details>
  <summary>Details</summary>
Motivation: 解决在动态环境中使用语言模型进行具身任务时的延迟、连接性和资源限制问题，特别是在无法实时访问大规模推理引擎或符号规划器的情况下。

Method: 首先使用符号工具生成任务特定规划，然后将这些规划转化为编码隐式产生规则的可组合程序表示，最后将这些程序无缝集成到语言模型的推理过程中。

Result: 在PDDLGym、VirtualHome和ALFWorld等具身基准测试中，NeSyPr展现出比大规模推理模型和符号规划器更高效的推理能力，同时使用更紧凑的语言模型。

Conclusion: 神经符号程序化能够将多步符号结构化路径寻找和推理抽象为单步语言模型推理，适合在延迟敏感和资源受限的物理系统中部署。

Abstract: We address the challenge of adopting language models (LMs) for embodied tasks
in dynamic environments, where online access to large-scale inference engines
or symbolic planners is constrained due to latency, connectivity, and resource
limitations. To this end, we present NeSyPr, a novel embodied reasoning
framework that compiles knowledge via neurosymbolic proceduralization, thereby
equipping LM-based agents with structured, adaptive, and timely reasoning
capabilities. In NeSyPr, task-specific plans are first explicitly generated by
a symbolic tool leveraging its declarative knowledge. These plans are then
transformed into composable procedural representations that encode the plans'
implicit production rules, enabling the resulting composed procedures to be
seamlessly integrated into the LM's inference process. This neurosymbolic
proceduralization abstracts and generalizes multi-step symbolic structured
path-finding and reasoning into single-step LM inference, akin to human
knowledge compilation. It supports efficient test-time inference without
relying on external symbolic guidance, making it well suited for deployment in
latency-sensitive and resource-constrained physical systems. We evaluate NeSyPr
on the embodied benchmarks PDDLGym, VirtualHome, and ALFWorld, demonstrating
its efficient reasoning capabilities over large-scale reasoning models and a
symbolic planner, while using more compact LMs.

</details>


### [53] [DAIL: Beyond Task Ambiguity for Language-Conditioned Reinforcement Learning](https://arxiv.org/abs/2510.19562)
*Runpeng Xie,Quanwei Wang,Hao Hu,Zherui Zhou,Ni Mu,Xiyun Li,Yiqin Yang,Shuang Xu,Qianchuan Zhao,Bo XU*

Main category: cs.AI

TL;DR: 提出DAIL方法解决语言指令的歧义性问题，通过分布策略和语义对齐提升智能代理对自然语言指令的理解能力


<details>
  <summary>Details</summary>
Motivation: 自然语言指令的灵活性导致语言条件任务中存在大量歧义，严重影响算法性能

Method: DAIL方法包含两个关键组件：分布策略和语义对齐模块。分布策略通过价值分布估计机制增强任务可区分性，语义对齐模块捕捉轨迹与语言指令之间的对应关系

Result: 在结构化和视觉观察基准测试上的广泛实验结果表明，DAIL能有效解决指令歧义问题，性能优于基线方法

Conclusion: DAIL方法通过分布对齐学习有效解决了语言指令的歧义性问题，为智能代理理解自然语言指令提供了有效解决方案

Abstract: Comprehending natural language and following human instructions are critical
capabilities for intelligent agents. However, the flexibility of linguistic
instructions induces substantial ambiguity across language-conditioned tasks,
severely degrading algorithmic performance. To address these limitations, we
present a novel method named DAIL (Distributional Aligned Learning), featuring
two key components: distributional policy and semantic alignment. Specifically,
we provide theoretical results that the value distribution estimation mechanism
enhances task differentiability. Meanwhile, the semantic alignment module
captures the correspondence between trajectories and linguistic instructions.
Extensive experimental results on both structured and visual observation
benchmarks demonstrate that DAIL effectively resolves instruction ambiguities,
achieving superior performance to baseline methods. Our implementation is
available at https://github.com/RunpengXie/Distributional-Aligned-Learning.

</details>


### [54] [HSCodeComp: A Realistic and Expert-level Benchmark for Deep Search Agents in Hierarchical Rule Application](https://arxiv.org/abs/2510.19631)
*Yiqian Yang,Tian Lan,Qianghuai Jia,Li Zhu,Hui Jiang,Hang Zhu,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.AI

TL;DR: HSCodeComp是首个评估深度搜索代理在分层规则应用能力的电商基准，要求代理根据商品描述预测10位协调制度编码(HSCode)，现有最佳代理准确率仅46.8%，远低于人类专家的95.0%。


<details>
  <summary>Details</summary>
Motivation: 当前代理基准忽视了深度搜索代理应用复杂规则（如法律条款、关税规则）的关键能力，这些规则具有模糊边界和隐式逻辑关系，需要专门评估。

Method: 从大型电商平台收集真实数据构建HSCodeComp基准，包含632个产品条目，由多位人类专家标注HSCode，评估代理在分层规则应用中的表现。

Result: 实验显示最佳代理仅达到46.8%的10位准确率，远低于人类专家的95.0%，测试时扩展也无法进一步提升性能。

Conclusion: 分层规则应用对当前代理构成重大挑战，需要开发更强大的规则理解和应用能力，HSCodeComp为评估和改进此类能力提供了重要基准。

Abstract: Effective deep search agents must not only access open-domain and
domain-specific knowledge but also apply complex rules-such as legal clauses,
medical manuals and tariff rules. These rules often feature vague boundaries
and implicit logic relationships, making precise application challenging for
agents. However, this critical capability is largely overlooked by current
agent benchmarks.
  To fill this gap, we introduce HSCodeComp, the first realistic, expert-level
e-commerce benchmark designed to evaluate deep search agents in hierarchical
rule application. In this task, the deep reasoning process of agents is guided
by these rules to predict 10-digit Harmonized System Code (HSCode) of products
with noisy but realistic descriptions. These codes, established by the World
Customs Organization, are vital for global supply chain efficiency. Built from
real-world data collected from large-scale e-commerce platforms, our proposed
HSCodeComp comprises 632 product entries spanning diverse product categories,
with these HSCodes annotated by several human experts.
  Extensive experimental results on several state-of-the-art LLMs, open-source,
and closed-source agents reveal a huge performance gap: best agent achieves
only 46.8% 10-digit accuracy, far below human experts at 95.0%. Besides,
detailed analysis demonstrates the challenges of hierarchical rule application,
and test-time scaling fails to improve performance further.

</details>


### [55] [AgentSense: LLMs Empower Generalizable and Explainable Web-Based Participatory Urban Sensing](https://arxiv.org/abs/2510.19661)
*Xusen Guo,Mingxing Peng,Xixuan Hao,Xingchen Zou,Qiongyan Wang,Sijie Ruan,Yuxuan Liang*

Main category: cs.AI

TL;DR: AgentSense是一个基于多智能体进化系统的混合训练免费框架，将大语言模型集成到参与式城市感知中，通过迭代优化解决方案来适应动态城市条件和异构工作者偏好，同时提供自然语言解释增强透明度。


<details>
  <summary>Details</summary>
Motivation: 现有的城市感知系统在多样化城市场景中泛化能力有限，决策过程缺乏可解释性。需要开发能够适应动态城市条件、考虑工作者偏好并提供透明解释的系统。

Method: 结合大语言模型和多智能体进化系统，首先使用经典规划器生成基线解决方案，然后迭代优化以适应动态城市条件和异构工作者偏好，同时生成自然语言解释。

Result: 在两个大规模移动数据集和七种动态干扰上的实验表明，AgentSense在适应性和可解释性方面优于传统方法，相比单智能体LLM基线在性能和鲁棒性方面表现更优，提供更合理透明的解释。

Conclusion: AgentSense代表了向部署自适应和可解释城市感知系统的重要进展，为基于网络的城市管理提供了有效的解决方案。

Abstract: Web-based participatory urban sensing has emerged as a vital approach for
modern urban management by leveraging mobile individuals as distributed
sensors. However, existing urban sensing systems struggle with limited
generalization across diverse urban scenarios and poor interpretability in
decision-making. In this work, we introduce AgentSense, a hybrid, training-free
framework that integrates large language models (LLMs) into participatory urban
sensing through a multi-agent evolution system. AgentSense initially employs
classical planner to generate baseline solutions and then iteratively refines
them to adapt sensing task assignments to dynamic urban conditions and
heterogeneous worker preferences, while producing natural language explanations
that enhance transparency and trust. Extensive experiments across two
large-scale mobility datasets and seven types of dynamic disturbances
demonstrate that AgentSense offers distinct advantages in adaptivity and
explainability over traditional methods. Furthermore, compared to single-agent
LLM baselines, our approach outperforms in both performance and robustness,
while delivering more reasonable and transparent explanations. These results
position AgentSense as a significant advancement towards deploying adaptive and
explainable urban sensing systems on the web.

</details>


### [56] [A Graph Engine for Guitar Chord-Tone Soloing Education](https://arxiv.org/abs/2510.19666)
*Matthew Keating,Michael Casey*

Main category: cs.AI

TL;DR: 开发了一个基于图论的吉他即兴演奏系统，通过计算和弦音之间的最优过渡，为吉他学生提供和弦音独奏建议。


<details>
  <summary>Details</summary>
Motivation: 和弦音独奏是爵士吉他即兴演奏的基础练习，但学习和实践难度较高，需要系统化的指导工具。

Method: 构建加权图模型，节点代表和弦音琶音，边权重基于最优过渡音计算，通过最短路径算法生成独奏线条。

Result: 成功开发了用户友好的系统，能够为吉他学生生成和弦音独奏建议，辅助即兴演奏练习。

Conclusion: 基于图论的引擎为吉他学生提供了有效的和弦音独奏练习工具，有助于爵士吉他即兴演奏的学习。

Abstract: We present a graph-based engine for computing chord tone soloing suggestions
for guitar students. Chord tone soloing is a fundamental practice for
improvising over a chord progression, where the instrumentalist uses only the
notes contained in the current chord. This practice is a building block for all
advanced jazz guitar theory but is difficult to learn and practice. First, we
discuss methods for generating chord-tone arpeggios. Next, we construct a
weighted graph where each node represents a chord tone arpeggio for a chord in
the progression. Then, we calculate the edge weight between each consecutive
chord's nodes in terms of optimal transition tones. We then find the shortest
path through this graph and reconstruct a chord-tone soloing line. Finally, we
discuss a user-friendly system to handle input and output to this engine for
guitar students to practice chord tone soloing.

</details>


### [57] [Explainable e-sports win prediction through Machine Learning classification in streaming](https://arxiv.org/abs/2510.19671)
*Silvia García-Méndez,Francisco de Arriba-Pérez*

Main category: cs.AI

TL;DR: 提出了一种可解释的电竞赛事胜利预测分类解决方案，通过滑动窗口控制输入数据来反映游戏变化，准确率超过90%，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着电竞观众和玩家数量增长，以及通信技术和云计算的发展，电竞产业持续扩大。虽然基于AI的电竞分析传统上是从相关数据中提取有意义模式并进行可视化以增强决策，但专业胜利预测大多关注批量分类，忽略了可视化技术。

Method: 开发了一种可解释的胜利预测分类解决方案，在流式处理中使用多个滑动窗口控制输入数据，以反映游戏中的相关变化。

Result: 实验结果显示准确率超过90%，超越了文献中的竞争解决方案。

Conclusion: 该系统可被排名和推荐系统利用，用于明智决策，其可解释性模块增强了预测结果的可信度。

Abstract: The increasing number of spectators and players in e-sports, along with the
development of optimized communication solutions and cloud computing
technology, has motivated the constant growth of the online game industry. Even
though Artificial Intelligence-based solutions for e-sports analytics are
traditionally defined as extracting meaningful patterns from related data and
visualizing them to enhance decision-making, most of the effort in professional
winning prediction has been focused on the classification aspect from a batch
perspective, also leaving aside the visualization techniques. Consequently,
this work contributes to an explainable win prediction classification solution
in streaming in which input data is controlled over several sliding windows to
reflect relevant game changes. Experimental results attained an accuracy higher
than 90 %, surpassing the performance of competing solutions in the literature.
Ultimately, our system can be leveraged by ranking and recommender systems for
informed decision-making, thanks to the explainability module, which fosters
trust in the outcome predictions.

</details>


### [58] [SysMoBench: Evaluating AI on Formally Modeling Complex Real-World Systems](https://arxiv.org/abs/2509.23130)
*Qian Cheng,Ruize Tang,Emilie Ma,Finn Hackett,Peiyang He,Yiming Su,Ivan Beschastnikh,Yu Huang,Xiaoxing Ma,Tianyin Xu*

Main category: cs.AI

TL;DR: SysMoBench是一个评估AI为大型复杂系统生成形式化模型能力的基准测试，专注于并发和分布式系统，使用TLA+作为规范语言。


<details>
  <summary>Details</summary>
Motivation: 形式化模型对于指定大型复杂计算机系统并验证其正确性至关重要，但编写和维护成本高昂。现有AI方法主要针对小型代码，无法处理现实系统构件。

Method: 创建SysMoBench基准测试，自动化评估指标包括语法和运行时正确性、与系统代码的一致性以及不变式正确性。包含九个多样化系统构件。

Result: SysMoBench能够评估当前LLM和智能体在形式化建模方面的能力和局限性，为该领域工具提供坚实基础。

Conclusion: 该基准测试为理解AI在系统形式化建模方面的能力提供了框架，并开辟了有前景的新研究方向。

Abstract: Formal models are essential to specifying large, complex computer systems and
verifying their correctness, but are notoriously expensive to write and
maintain. Recent advances in generative AI show promise in generating certain
forms of specifications. However, existing work mostly targets small code, not
complete systems. It is unclear whether AI can deal with realistic system
artifacts, as this requires abstracting their complex behavioral properties
into formal models. We present SysMoBench, a benchmark that evaluates AI's
ability to formally model large, complex systems. We focus on concurrent and
distributed systems, which are keystones of today's critical computing
infrastructures, encompassing operating systems and cloud infrastructure. We
use TLA+, the de facto specification language for concurrent and distributed
systems, though the benchmark can be extended to other specification languages.
We address the primary challenge of evaluating AI-generated models by
automating metrics like syntactic and runtime correctness, conformance to
system code, and invariant correctness. SysMoBench currently includes nine
diverse system artifacts: the Raft implementation of Etcd and Redis, the
Spinlock and Mutex in Asterinas OS, etc.; more artifacts are being actively
added. SysMoBench enables us to understand the capabilities and limitations of
today's LLMs and agents, putting tools in this area on a firm footing and
opening up promising new research directions.

</details>


### [59] [RLIE: Rule Generation with Logistic Regression, Iterative Refinement, and Evaluation for Large Language Models](https://arxiv.org/abs/2510.19698)
*Yang Yang,Hua XU,Zhangyi Hu,Yutao Yue*

Main category: cs.AI

TL;DR: RLIE是一个统一框架，将LLMs与概率建模相结合来学习加权规则集，包含规则生成、逻辑回归学习权重、迭代优化和评估四个阶段。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法忽略了规则间的相互作用，且未充分探索将LLMs与概率规则学习结合进行鲁棒推理的机会。

Method: 四阶段框架：1）LLM生成和筛选候选规则；2）逻辑回归学习概率权重；3）基于预测误差迭代优化规则集；4）评估加权规则集作为直接分类器的性能。

Result: 使用学习权重的规则直接应用表现优异，而将规则、权重和逻辑模型输出注入LLM反而降低准确性。

Conclusion: LLMs擅长语义生成和解释，但在精确概率整合方面可靠性较低。RLIE阐明了LLMs在归纳推理中的潜力和局限性，通过与经典概率规则组合方法结合实现更可靠的神经符号推理。

Abstract: Large Language Models (LLMs) can propose rules in natural language,
sidestepping the need for a predefined predicate space in traditional rule
learning. Yet many LLM-based approaches ignore interactions among rules, and
the opportunity to couple LLMs with probabilistic rule learning for robust
inference remains underexplored. We present RLIE, a unified framework that
integrates LLMs with probabilistic modeling to learn a set of weighted rules.
RLIE has four stages: (1) Rule generation, where an LLM proposes and filters
candidates; (2) Logistic regression, which learns probabilistic weights for
global selection and calibration; (3) Iterative refinement, which updates the
rule set using prediction errors; and (4) Evaluation, which compares the
weighted rule set as a direct classifier with methods that inject rules into an
LLM. We evaluate multiple inference strategies on real-world datasets. Applying
rules directly with their learned weights yields superior performance, whereas
prompting LLMs with the rules, weights, and logistic-model outputs surprisingly
degrades accuracy. This supports the view that LLMs excel at semantic
generation and interpretation but are less reliable for precise probabilistic
integration. RLIE clarifies the potential and limitations of LLMs for inductive
reasoning and couples them with classic probabilistic rule combination methods
to enable more reliable neuro-symbolic reasoning.

</details>


### [60] [Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning](https://arxiv.org/abs/2510.19732)
*Gunshi Gupta,Karmesh Yadav,Zsolt Kira,Yarin Gal,Rahaf Aljundi*

Main category: cs.AI

TL;DR: Memo是一个基于transformer的架构和训练方法，用于强化学习中的记忆密集型长时程任务。它通过在训练时向模型输入中插入周期性总结标记来创建和检索记忆，在计算和存储效率上优于传统长上下文transformer基线。


<details>
  <summary>Details</summary>
Motivation: 当前基于transformer的具身智能体策略训练中，视觉输入常常超出transformer的上下文限制，而人类能够将终身经验压缩为记忆。现有方法要么依赖固定大小记忆的循环模型，要么依赖完整上下文的transformer，缺乏有效的记忆压缩机制。

Method: 提出Memo架构，在训练期间将周期性总结标记与模型输入交错排列，实现记忆的创建和检索。这种方法允许模型在推理时更好地泛化到更长上下文，并在流式设置中保持鲁棒性。

Result: 在网格世界元强化学习基准和照片级真实室内环境的多目标导航任务中，Memo优于朴素的长上下文transformer基线，同时计算和存储效率更高。Memo在推理时对更长上下文具有更好的泛化能力。

Conclusion: Memo通过记忆创建和检索机制，为具身智能体在长期任务中提供了有效的记忆管理方案，解决了transformer上下文限制的问题，同时保持了计算效率。

Abstract: To enable embodied agents to operate effectively over extended timeframes, it
is crucial to develop models that form and access memories to stay
contextualized in their environment. In the current paradigm of training
transformer-based policies for embodied sequential decision-making tasks,
visual inputs often overwhelm the context limits of transformers, while humans
can maintain and utilize a lifetime of experience compressed as memories.
Significant compression is possible in principle, as much of the input is
irrelevant and can be abstracted. However, existing approaches predominantly
focus on either recurrent models with fixed-size memory or transformers with
full-context reliance. In this work, we propose Memo, a transformer-based
architecture and training recipe for reinforcement learning (RL) on
memory-intensive, long-horizon tasks. Memo incorporates the creation and
retrieval of memory by interleaving periodic summarization tokens with the
inputs of a model during training. We demonstrate Memo's effectiveness on a
gridworld meta-RL benchmark and a multi-object navigation task in
photo-realistic indoor settings. Memo outperforms naive long-context
transformer baselines while being more compute and storage efficient.
Additionally, Memo generalizes better to longer contexts at inference time and
remains robust in streaming settings, where historical context must be
truncated to fit inference constraints.

</details>


### [61] [Misalignment Bounty: Crowdsourcing AI Agent Misbehavior](https://arxiv.org/abs/2510.19738)
*Rustem Turtayev,Natalia Fedorova,Oleg Serikov,Sergey Koldyba,Lev Avagyan,Dmitrii Volkov*

Main category: cs.AI

TL;DR: 该论文介绍了"错位赏金"项目，这是一个众包项目，旨在收集AI系统与人类意图不符的行为案例。项目收到295份提交，其中9份获奖。


<details>
  <summary>Details</summary>
Motivation: 收集AI系统与人类意图不符的清晰、可复现案例，以更好地理解和解决AI对齐问题。

Method: 通过众包项目"错位赏金"收集案例，使用特定的评估标准对提交进行评审。

Result: 项目共收到295份提交，其中9份被选为获奖案例，展示了AI系统追求非预期或不安全目标的具体实例。

Conclusion: 该项目成功收集了AI错位行为的实际案例，为理解和解决AI对齐问题提供了有价值的实证材料。

Abstract: Advanced AI systems sometimes act in ways that differ from human intent. To
gather clear, reproducible examples, we ran the Misalignment Bounty: a
crowdsourced project that collected cases of agents pursuing unintended or
unsafe goals. The bounty received 295 submissions, of which nine were awarded.
  This report explains the program's motivation and evaluation criteria, and
walks through the nine winning submissions step by step.

</details>


### [62] [Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents](https://arxiv.org/abs/2510.19771)
*Gil Pasternak,Dheeraj Rajagopal,Julia White,Dhruv Atreja,Matthew Thomas,George Hurn-Maloney,Ash Lewis*

Main category: cs.AI

TL;DR: PROBE是一个评估LLM智能体主动性的新基准，通过三个核心能力（问题搜索、瓶颈识别、解决方案执行）来测试智能体在跨源和长时间跨度推理方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前评估LLM智能体主动性的基准局限于局部上下文，无法测试跨源和长时间跨度的推理能力，需要新的评估方法来填补这一空白。

Method: 提出PROBE基准，将主动性分解为三个核心能力管道：搜索未指定问题、识别具体瓶颈、执行适当解决方案，并应用于评估领先的LLM和流行智能体框架。

Result: 即使是当前最先进的模型也在此基准上表现不佳，GPT-5和Claude Opus-4.1的最佳端到端性能仅为40%，揭示了智能体系统在自主行动方面的局限性。

Conclusion: 研究结果突显了智能体系统自主行动的当前局限性，并揭示了有前景的未来研究方向。

Abstract: LLM-based agents are increasingly moving towards proactivity: rather than
awaiting instruction, they exercise agency to anticipate user needs and solve
them autonomously. However, evaluating proactivity is challenging; current
benchmarks are constrained to localized context, limiting their ability to test
reasoning across sources and longer time horizons. To address this gap, we
present PROBE (Proactive Resolution Of BottlEnecks). PROBE decomposes
proactivity as a pipeline of three core capabilities: (1) searching for
unspecified issues, (2) identifying specific bottlenecks, and (3) executing
appropriate resolutions. We apply PROBE to evaluate leading LLMs and popular
agentic frameworks, showing that even state-of-the-art models struggle to solve
this benchmark. Computing our consistent measurements across frontier LLMs and
agents, we find that the best end-to-end performance of 40% is achieved by both
GPT-5 and Claude Opus-4.1. Additionally, we demonstrate the relative
capabilities of each model and analyze mutual failure modes. Our results
highlight the current limitations of autonomous action in agentic systems, and
expose promising future research directions.

</details>


### [63] [Benchmarking World-Model Learning](https://arxiv.org/abs/2510.19788)
*Archana Warrier,Dat Nyugen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares*

Main category: cs.AI

TL;DR: 提出了WorldTest评估协议和AutumnBench测试套件，用于评估模型学习智能体在不同环境中的世界模型能力，发现人类表现优于前沿模型。


<details>
  <summary>Details</summary>
Motivation: 当前世界模型学习和评估方法局限于下一帧预测和相同环境中的奖励最大化，无法真正评估模型对世界动态的理解能力。

Method: 设计WorldTest协议：奖励无关的探索阶段和在不同但相关环境中的测试阶段；创建AutumnBench套件，包含43个网格世界环境和129个任务，涵盖掩码帧预测、规划和因果动态变化预测。

Result: 517名人类参与者表现优于三个前沿模型；计算规模扩展只在某些环境中提升性能；AutumnBench揭示了世界模型学习的显著提升空间。

Conclusion: WorldTest提供了评估智能体环境动态学习能力的新模板，AutumnBench展示了世界模型学习的巨大改进潜力。

Abstract: Model-learning agents should gather information to learn world models that
support many downstream tasks and inferences, such as predicting unobserved
states, estimating near- and far-term consequences of actions, planning action
sequences, and detecting changes in dynamics. Current methods for learning and
evaluating world models diverge from this goal: training and evaluation are
anchored to next-frame prediction, and success is scored by reward maximization
in the same environment. We propose WorldTest, a protocol to evaluate
model-learning agents that separates reward-free interaction from a scored test
phase in a different but related environment. WorldTest is
open-ended$\unicode{x2014}$models should support many different tasks unknown
ahead of time$\unicode{x2014}$and agnostic to model representation, allowing
comparison across approaches. We instantiated WorldTest with AutumnBench, a
suite of 43 interactive grid-world environments and 129 tasks across three
families: masked-frame prediction, planning, and predicting changes to the
causal dynamics. We compared 517 human participants and three frontier models
on AutumnBench. We found that humans outperform the models, and scaling compute
improves performance only in some environments but not others. WorldTest
provides a novel template$\unicode{x2014}$reward-free exploration, derived
tests, and behavior-based scoring$\unicode{x2014}$to evaluate what agents learn
about environment dynamics, and AutumnBench exposes significant headroom in
world-model learning.

</details>
