{"id": "2511.08607", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.08607", "abs": "https://arxiv.org/abs/2511.08607", "authors": ["Yongxin Zhao", "Shenglin Zhang", "Yujia Wu", "Yuxin Sun", "Yongqian Sun", "Dan Pei", "Chetan Bansal", "Minghua Ma"], "title": "Triage in Software Engineering: A Systematic Review of Research and Practice", "comment": null, "summary": "As modern software systems continue to grow in complexity, triage has become a fundamental process in system operations and maintenance. Triage aims to efficiently prioritize, assign, and assess issues to ensure the reliability of complex environments. The vast amount of heterogeneous data generated by software systems has made effective triage indispensable for maintaining reliability, facilitating maintainability, and enabling rapid issue response. Motivated by these challenges, researchers have devoted extensive effort to advancing triage automation and have achieved significant progress over the past two decades. This survey provides a comprehensive review of 234 papers from 2004 to the present, offering an in-depth examination of the fundamental concepts, system architecture, and problem statement. By comparing the distinct goals of academic and industrial research and by analyzing empirical studies of industrial practices, we identify the major obstacles that limit the practical deployment of triage systems. To assist practitioners in method selection and performance evaluation, we summarize widely adopted open-source datasets and evaluation metrics, providing a unified perspective on the measurement of triage effectiveness. Finally, we outline potential future directions and emerging opportunities to foster a closer integration between academic innovation and industrial application. All reviewed papers and projects are available at https://github.com/AIOps-Lab-NKU/TriageSurvey.", "AI": {"tldr": "\u672c\u6587\u5bf92004\u5e74\u81f3\u4eca\u7684234\u7bc7\u8bba\u6587\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u6df1\u5165\u63a2\u8ba8\u4e86\u8f6f\u4ef6\u7cfb\u7edf\u6545\u969c\u5206\u8bca\u7684\u57fa\u672c\u6982\u5ff5\u3001\u7cfb\u7edf\u67b6\u6784\u548c\u95ee\u9898\u9648\u8ff0\uff0c\u603b\u7ed3\u4e86\u5f00\u6e90\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u6545\u969c\u5206\u8bca\u5df2\u6210\u4e3a\u7cfb\u7edf\u8fd0\u7ef4\u7684\u57fa\u672c\u8fc7\u7a0b\u3002\u6d77\u91cf\u5f02\u6784\u6570\u636e\u4f7f\u5f97\u6709\u6548\u5206\u8bca\u5bf9\u4e8e\u7ef4\u62a4\u53ef\u9760\u6027\u3001\u4fc3\u8fdb\u53ef\u7ef4\u62a4\u6027\u548c\u5b9e\u73b0\u5feb\u901f\u95ee\u9898\u54cd\u5e94\u53d8\u5f97\u4e0d\u53ef\u6216\u7f3a\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u5b66\u672f\u548c\u5de5\u4e1a\u7814\u7a76\u7684\u4e0d\u540c\u76ee\u6807\uff0c\u5206\u6790\u5de5\u4e1a\u5b9e\u8df5\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc6\u522b\u9650\u5236\u5206\u8bca\u7cfb\u7edf\u5b9e\u9645\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\uff0c\u5e76\u603b\u7ed3\u5e7f\u6cdb\u91c7\u7528\u7684\u5f00\u6e90\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u63d0\u4f9b\u4e86\u6545\u969c\u5206\u8bca\u7684\u7edf\u4e00\u89c6\u89d2\uff0c\u8bc6\u522b\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u4e3b\u8981\u969c\u788d\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u65b9\u6cd5\u9009\u62e9\u548c\u6027\u80fd\u8bc4\u4f30\u7684\u6307\u5bfc\u3002", "conclusion": "\u6982\u8ff0\u4e86\u672a\u6765\u6f5c\u5728\u65b9\u5411\u548c\u65b0\u5174\u673a\u9047\uff0c\u4ee5\u4fc3\u8fdb\u5b66\u672f\u521b\u65b0\u4e0e\u5de5\u4e1a\u5e94\u7528\u66f4\u7d27\u5bc6\u7684\u6574\u5408\uff0c\u6240\u6709\u7efc\u8ff0\u8bba\u6587\u548c\u9879\u76ee\u53ef\u5728\u6307\u5b9aGitHub\u4ed3\u5e93\u83b7\u53d6\u3002"}}
{"id": "2511.08644", "categories": ["cs.SE", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.08644", "abs": "https://arxiv.org/abs/2511.08644", "authors": ["Punit Kumar", "Asif Imran", "Tevfik Kosar"], "title": "Energy Consumption of Dataframe Libraries for End-to-End Deep Learning Pipelines:A Comparative Analysis", "comment": null, "summary": "This paper presents a detailed comparative analysis of the performance of three major Python data manipulation libraries - Pandas, Polars, and Dask - specifically when embedded within complete deep learning (DL) training and inference pipelines. The research bridges a gap in existing literature by studying how these libraries interact with substantial GPU workloads during critical phases like data loading, preprocessing, and batch feeding. The authors measured key performance indicators including runtime, memory usage, disk usage, and energy consumption (both CPU and GPU) across various machine learning models and datasets.", "AI": {"tldr": "\u5bf9Pandas\u3001Polars\u548cDask\u4e09\u4e2aPython\u6570\u636e\u64cd\u4f5c\u5e93\u5728\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u548c\u63a8\u7406\u7ba1\u9053\u4e2d\u7684\u6027\u80fd\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c\u91cd\u70b9\u5173\u6ce8\u5b83\u4eec\u4e0eGPU\u5de5\u4f5c\u8d1f\u8f7d\u7684\u4ea4\u4e92\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u6570\u636e\u64cd\u4f5c\u5e93\u5728\u6df1\u5ea6\u5b66\u4e60\u5b8c\u6574\u7ba1\u9053\u4e2d\u4e0eGPU\u5de5\u4f5c\u8d1f\u8f7d\u4ea4\u4e92\u7684\u7814\u7a76\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u52a0\u8f7d\u3001\u9884\u5904\u7406\u548c\u6279\u6b21\u8f93\u5165\u7b49\u5173\u952e\u9636\u6bb5\u3002", "method": "\u6d4b\u91cf\u4e86\u5305\u62ec\u8fd0\u884c\u65f6\u95f4\u3001\u5185\u5b58\u4f7f\u7528\u3001\u78c1\u76d8\u4f7f\u7528\u548c\u80fd\u8017\uff08CPU\u548cGPU\uff09\u5728\u5185\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u6570\u636e\u96c6\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e09\u4e2a\u5e93\u5728\u6df1\u5ea6\u5b66\u4e60\u7ba1\u9053\u4e2d\u7684\u8be6\u7ec6\u6027\u80fd\u5bf9\u6bd4\u6570\u636e\uff0c\u6db5\u76d6\u4e86\u591a\u4e2a\u7ef4\u5ea6\u7684\u6027\u80fd\u6307\u6807\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u6570\u636e\u64cd\u4f5c\u5e93\u5728\u6df1\u5ea6\u5b66\u4e60\u5b8c\u6574\u5de5\u4f5c\u6d41\u4e2d\u6027\u80fd\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u9009\u62e9\u5408\u9002\u7684\u6570\u636e\u5904\u7406\u5de5\u5177\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u3002"}}
{"id": "2511.09000", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09000", "abs": "https://arxiv.org/abs/2511.09000", "authors": ["Jarin Tasnim", "Debasish Chakroborti", "Chanchal K. Roy", "Kevin A. Schneider"], "title": "An insight into the technical debt-fix trade off in software backporting", "comment": "10 Pages", "summary": "Maintaining software is an ongoing process that stretches beyond the initial release. Stable software versions continuously evolve to fix bugs, add improvements, address security issues, and ensure compatibility. This ongoing support involves Backporting, which means taking a fix or update from a newer version and applying it to an older version of the same software. As software versions evolve, new technical debt can arise during backport maintenance activities. This study examines the technical debt involved in fixing 105,396 commits from 31,076 backport sources across 87 repositories in three software ecosystems (Apache, Eclipse, and Python). The goal is to identify when and why new technical debt arises during backporting in stable source code. Our results indicate that approximately 4.3% of backports introduce new technical debt. Apache contributes the most absolute instances, while Python and Eclipse exhibit nearly three times higher debt-to-commit ratios than Apache. Feature migrations make older Apache releases debt-prone in the early phase, whereas Python and Eclipse releases tend to accumulate technical debt mostly during the middle phase of their release cycles. Additionally, developers who are inexperienced, under high workloads, or non-owners are more likely to introduce technical debt during backporting.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e8687\u4e2a\u4ed3\u5e93\u4e2d31,076\u4e2a\u56de\u4f20\u6e90\u7684105,396\u6b21\u63d0\u4ea4\uff0c\u53d1\u73b0\u7ea64.3%\u7684\u56de\u4f20\u4f1a\u5f15\u5165\u65b0\u7684\u6280\u672f\u503a\u52a1\uff0c\u4e0d\u540c\u751f\u6001\u7cfb\u7edf\u548c\u5f00\u53d1\u9636\u6bb5\u7684\u6280\u672f\u503a\u52a1\u6a21\u5f0f\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u56de\u4f20\u7ef4\u62a4\u6d3b\u52a8\u4e2d\u6280\u672f\u503a\u52a1\u7684\u4ea7\u751f\u60c5\u51b5\uff0c\u8bc6\u522b\u5728\u7a33\u5b9a\u6e90\u4ee3\u7801\u56de\u4f20\u8fc7\u7a0b\u4e2d\u4f55\u65f6\u4ee5\u53ca\u4e3a\u4f55\u4f1a\u4ea7\u751f\u65b0\u7684\u6280\u672f\u503a\u52a1\u3002", "method": "\u5206\u6790\u4e86\u4e09\u4e2a\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\uff08Apache\u3001Eclipse\u548cPython\uff09\u4e2d87\u4e2a\u4ed3\u5e93\u768431,076\u4e2a\u56de\u4f20\u6e90\u7684105,396\u6b21\u63d0\u4ea4\uff0c\u901a\u8fc7\u91cf\u5316\u5206\u6790\u8bc6\u522b\u6280\u672f\u503a\u52a1\u5f15\u5165\u6a21\u5f0f\u3002", "result": "\u7ea64.3%\u7684\u56de\u4f20\u5f15\u5165\u4e86\u65b0\u7684\u6280\u672f\u503a\u52a1\uff1bApache\u8d21\u732e\u4e86\u6700\u591a\u7684\u7edd\u5bf9\u5b9e\u4f8b\uff0c\u800cPython\u548cEclipse\u7684\u503a\u52a1\u63d0\u4ea4\u6bd4\u51e0\u4e4e\u662fApache\u7684\u4e09\u500d\uff1b\u4e0d\u540c\u751f\u6001\u7cfb\u7edf\u5728\u4e0d\u540c\u53d1\u5e03\u5468\u671f\u9636\u6bb5\u7684\u6280\u672f\u503a\u52a1\u79ef\u7d2f\u6a21\u5f0f\u4e0d\u540c\uff1b\u7ecf\u9a8c\u4e0d\u8db3\u3001\u5de5\u4f5c\u8d1f\u8377\u9ad8\u6216\u975e\u6240\u6709\u8005\u7684\u5f00\u53d1\u8005\u66f4\u53ef\u80fd\u5728\u56de\u4f20\u4e2d\u5f15\u5165\u6280\u672f\u503a\u52a1\u3002", "conclusion": "\u56de\u4f20\u7ef4\u62a4\u6d3b\u52a8\u786e\u5b9e\u4f1a\u5f15\u5165\u6280\u672f\u503a\u52a1\uff0c\u5176\u6a21\u5f0f\u548c\u7a0b\u5ea6\u56e0\u751f\u6001\u7cfb\u7edf\u3001\u53d1\u5e03\u5468\u671f\u9636\u6bb5\u548c\u5f00\u53d1\u8005\u7279\u5f81\u800c\u5f02\uff0c\u9700\u8981\u9488\u5bf9\u6027\u5730\u7ba1\u7406\u56de\u4f20\u8fc7\u7a0b\u4ee5\u51cf\u5c11\u6280\u672f\u503a\u52a1\u7684\u5f15\u5165\u3002"}}
{"id": "2511.09038", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09038", "abs": "https://arxiv.org/abs/2511.09038", "authors": ["Oussama Jebbar", "Ferhat Khendek", "Maria Toeroe"], "title": "Test Plan Generation for Live Testing of Cloud Services", "comment": null, "summary": "Live testing is performed in the production environment ideally without causing unacceptable disturbance to the production traffic. Thus, test activities have to be orchestrated properly to avoid interferences with the production traffic. A test plan is the road map that specifies how the test activities need to be orchestrated. Developing a test plan includes tasks such as test configuration selection/generation, test configuration deployment planning, creating the test runs schedule, choosing strategies to mitigate the risk of interferences, etc. The manual design of a test plan is tedious and error prone. This task becomes harder especially when the systems are large and complex. In this paper we propose an approach for automating test plans generation. With this approach we aim at reducing service disruption that may be induced by the testing activities in production. We illustrate our approach with a case study and discuss its different aspects.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u5316\u6d4b\u8bd5\u8ba1\u5212\u751f\u6210\u65b9\u6cd5\uff0c\u65e8\u5728\u51cf\u5c11\u751f\u4ea7\u73af\u5883\u4e2d\u6d4b\u8bd5\u6d3b\u52a8\u53ef\u80fd\u5f15\u8d77\u7684\u670d\u52a1\u4e2d\u65ad", "motivation": "\u624b\u52a8\u8bbe\u8ba1\u6d4b\u8bd5\u8ba1\u5212\u7e41\u7410\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u7279\u522b\u662f\u5728\u5927\u578b\u590d\u6742\u7cfb\u7edf\u4e2d\u66f4\u4e3a\u56f0\u96be\uff0c\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u907f\u514d\u6d4b\u8bd5\u6d3b\u52a8\u5bf9\u751f\u4ea7\u6d41\u91cf\u7684\u5e72\u6270", "method": "\u63d0\u51fa\u81ea\u52a8\u5316\u6d4b\u8bd5\u8ba1\u5212\u751f\u6210\u65b9\u6cd5\uff0c\u5305\u62ec\u6d4b\u8bd5\u914d\u7f6e\u9009\u62e9/\u751f\u6210\u3001\u90e8\u7f72\u89c4\u5212\u3001\u6d4b\u8bd5\u8fd0\u884c\u8c03\u5ea6\u4ee5\u53ca\u5e72\u6270\u98ce\u9669\u7f13\u89e3\u7b56\u7565\u9009\u62e9\u7b49\u4efb\u52a1", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bf4\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u4e0d\u540c\u65b9\u9762\uff0c\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u6d4b\u8bd5\u8ba1\u5212\u751f\u6210\u7684\u5b9e\u9645\u5e94\u7528", "conclusion": "\u81ea\u52a8\u5316\u6d4b\u8bd5\u8ba1\u5212\u751f\u6210\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u5c11\u751f\u4ea7\u73af\u5883\u4e2d\u6d4b\u8bd5\u6d3b\u52a8\u5f15\u8d77\u7684\u670d\u52a1\u4e2d\u65ad\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u5e76\u964d\u4f4e\u4eba\u4e3a\u9519\u8bef"}}
{"id": "2511.08715", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08715", "abs": "https://arxiv.org/abs/2511.08715", "authors": ["Connar Hite", "Sean Saud", "Raef Taha", "Nayim Rahman", "Tanvir Atahary", "Scott Douglass", "Tarek Taha"], "title": "Bridging Natural Language and ASP: A Hybrid Approach Using LLMs and AMR Parsing", "comment": null, "summary": "Answer Set Programming (ASP) is a declarative programming paradigm based on logic programming and non-monotonic reasoning. It is a tremendously powerful tool for describing and solving combinatorial problems. Like any other language, ASP requires users to learn how it works and the syntax involved. It is becoming increasingly required for those unfamiliar with programming languages to interact with code. This paper proposes a novel method of translating unconstrained English into ASP programs for logic puzzles using an LLM and Abstract Meaning Representation (AMR) graphs. Everything from ASP rules, facts, and constraints is generated to fully represent and solve the desired problem. Example logic puzzles are used to demonstrate the capabilities of the system. While most current methods rely entirely on an LLM, our system minimizes the role of the LLM only to complete straightforward tasks. The LLM is used to simplify natural language sentences, identify keywords, and generate simple facts. The AMR graphs are then parsed from simplified language and used to generate ASP constraints systematically. The system successfully creates an entire ASP program that solves a combinatorial logic problem. This approach is a significant first step in creating a lighter-weight, explainable system that converts natural language to solve complex logic problems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528LLM\u548cAMR\u56fe\u5c06\u65e0\u7ea6\u675f\u82f1\u8bed\u7ffb\u8bd1\u6210ASP\u7a0b\u5e8f\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u903b\u8f91\u8c1c\u9898\uff0c\u751f\u6210\u5b8c\u6574\u7684ASP\u7a0b\u5e8f\u6765\u6c42\u89e3\u7ec4\u5408\u903b\u8f91\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u8d8a\u6765\u8d8a\u591a\u4e0d\u719f\u6089\u7f16\u7a0b\u8bed\u8a00\u7684\u4eba\u9700\u8981\u4e0e\u4ee3\u7801\u4ea4\u4e92\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u8ba9\u975e\u4e13\u4e1a\u4eba\u58eb\u4e5f\u80fd\u4f7f\u7528ASP\u89e3\u51b3\u7ec4\u5408\u95ee\u9898\u3002\u5f53\u524d\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56LLM\uff0c\u9700\u8981\u66f4\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528LLM\u7b80\u5316\u81ea\u7136\u8bed\u8a00\u53e5\u5b50\u3001\u8bc6\u522b\u5173\u952e\u8bcd\u548c\u751f\u6210\u7b80\u5355\u4e8b\u5b9e\uff0c\u7136\u540e\u4ece\u7b80\u5316\u8bed\u8a00\u89e3\u6790AMR\u56fe\uff0c\u7cfb\u7edf\u6027\u5730\u751f\u6210ASP\u7ea6\u675f\uff0c\u6700\u5c0f\u5316LLM\u7684\u4f5c\u7528\u3002", "result": "\u7cfb\u7edf\u6210\u529f\u521b\u5efa\u4e86\u5b8c\u6574\u7684ASP\u7a0b\u5e8f\u6765\u89e3\u51b3\u7ec4\u5408\u903b\u8f91\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5728\u903b\u8f91\u8c1c\u9898\u793a\u4f8b\u4e2d\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u5728\u521b\u5efa\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u81ea\u7136\u8bed\u8a00\u5230\u590d\u6742\u903b\u8f91\u95ee\u9898\u6c42\u89e3\u7cfb\u7edf\u65b9\u9762\u7684\u91cd\u8981\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2511.09122", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09122", "abs": "https://arxiv.org/abs/2511.09122", "authors": ["Joschka Kersting", "Michael Rummel", "Gesa Benndorf"], "title": "Vendor-Aware Industrial Agents: RAG-Enhanced LLMs for Secure On-Premise PLC Code Generation", "comment": null, "summary": "Programmable Logic Controllers are operated by proprietary code dialects; this makes it challenging to train coding assistants. Current LLMs are trained on large code datasets and are capable of writing IEC 61131-3 compatible code out of the box, but they neither know specific function blocks, nor related project code. Moreover, companies like Mitsubishi Electric and their customers do not trust cloud providers. Hence, an own coding agent is the desired solution to cope with this. In this study, we present our work on a low-data domain coding assistant solution for industrial use. We show how we achieved high quality code generation without fine-tuning large models and by fine-tuning small local models for edge device usage. Our tool lets several AI models compete with each other, uses reasoning, corrects bugs automatically and checks code validity by compiling it directly in the chat interface. We support our approach with an extensive evaluation that comes with code compilation statistics and user ratings. We found that a Retrieval-Augmented Generation (RAG) supported coding assistant can work in low-data domains by using extensive prompt engineering and directed retrieval.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u5de5\u4e1a\u9886\u57df\u7684\u4f4e\u6570\u636e\u9886\u57df\u7f16\u7a0b\u52a9\u624b\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6280\u672f\uff0c\u5728\u4e0d\u5fae\u8c03\u5927\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u8d28\u91cf\u4ee3\u7801\u751f\u6210\uff0c\u652f\u6301\u8fb9\u7f18\u8bbe\u5907\u4f7f\u7528\u7684\u5c0f\u6a21\u578b\u5fae\u8c03\u3002", "motivation": "\u53ef\u7f16\u7a0b\u903b\u8f91\u63a7\u5236\u5668\u4f7f\u7528\u4e13\u6709\u4ee3\u7801\u65b9\u8a00\uff0c\u96be\u4ee5\u8bad\u7ec3\u7f16\u7801\u52a9\u624b\uff1b\u73b0\u6709LLM\u4e0d\u4e86\u89e3\u7279\u5b9a\u529f\u80fd\u5757\u548c\u76f8\u5173\u9879\u76ee\u4ee3\u7801\uff1b\u4f01\u4e1a\u4e0d\u4fe1\u4efb\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\uff0c\u9700\u8981\u672c\u5730\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6280\u672f\uff0c\u7ed3\u5408\u5e7f\u6cdb\u63d0\u793a\u5de5\u7a0b\u548c\u5b9a\u5411\u68c0\u7d22\uff0c\u8ba9\u591a\u4e2aAI\u6a21\u578b\u76f8\u4e92\u7ade\u4e89\uff0c\u4f7f\u7528\u63a8\u7406\u80fd\u529b\uff0c\u81ea\u52a8\u4fee\u6b63\u9519\u8bef\uff0c\u5e76\u5728\u804a\u5929\u754c\u9762\u4e2d\u76f4\u63a5\u7f16\u8bd1\u4ee3\u7801\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u5de5\u5177\u80fd\u591f\u63d0\u4f9b\u4ee3\u7801\u7f16\u8bd1\u7edf\u8ba1\u548c\u7528\u6237\u8bc4\u5206\uff0c\u8bc1\u660eRAG\u652f\u6301\u7684\u7f16\u7801\u52a9\u624b\u53ef\u4ee5\u5728\u4f4e\u6570\u636e\u9886\u57df\u6709\u6548\u5de5\u4f5c\u3002", "conclusion": "\u5728\u4f4e\u6570\u636e\u9886\u57df\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u548c\u5b9a\u5411\u68c0\u7d22\uff0c\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u4ee3\u7801\u751f\u6210\uff0c\u6ee1\u8db3\u5de5\u4e1a\u5e94\u7528\u9700\u6c42\u3002"}}
{"id": "2511.08747", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08747", "abs": "https://arxiv.org/abs/2511.08747", "authors": ["Isaac Joffe", "Chris Eliasmith"], "title": "Vector Symbolic Algebras for the Abstraction and Reasoning Corpus", "comment": null, "summary": "The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) is a generative, few-shot fluid intelligence benchmark. Although humans effortlessly solve ARC-AGI, it remains extremely difficult for even the most advanced artificial intelligence systems. Inspired by methods for modelling human intelligence spanning neuroscience to psychology, we propose a cognitively plausible ARC-AGI solver. Our solver integrates System 1 intuitions with System 2 reasoning in an efficient and interpretable process using neurosymbolic methods based on Vector Symbolic Algebras (VSAs). Our solver works by object-centric program synthesis, leveraging VSAs to represent abstract objects, guide solution search, and enable sample-efficient neural learning. Preliminary results indicate success, with our solver scoring 10.8% on ARC-AGI-1-Train and 3.0% on ARC-AGI-1-Eval. Additionally, our solver performs well on simpler benchmarks, scoring 94.5% on Sort-of-ARC and 83.1% on 1D-ARC -- the latter outperforming GPT-4 at a tiny fraction of the computational cost. Importantly, our approach is unique; we believe we are the first to apply VSAs to ARC-AGI and have developed the most cognitively plausible ARC-AGI solver yet. Our code is available at: https://github.com/ijoffe/ARC-VSA-2025.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5411\u91cf\u7b26\u53f7\u4ee3\u6570\u7684\u8ba4\u77e5\u5408\u7406ARC-AGI\u6c42\u89e3\u5668\uff0c\u7ed3\u5408\u7cfb\u7edf1\u76f4\u89c9\u548c\u7cfb\u7edf2\u63a8\u7406\uff0c\u901a\u8fc7\u9762\u5411\u5bf9\u8c61\u7684\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\u89e3\u51b3ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "ARC-AGI\u662f\u4eba\u7c7b\u8f7b\u677e\u89e3\u51b3\u4f46\u5bf9AI\u7cfb\u7edf\u6781\u5176\u56f0\u96be\u7684\u6d41\u4f53\u667a\u529b\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d7\u795e\u7ecf\u79d1\u5b66\u548c\u5fc3\u7406\u5b66\u7684\u4eba\u7c7b\u667a\u80fd\u5efa\u6a21\u65b9\u6cd5\u542f\u53d1\uff0c\u65e8\u5728\u5f00\u53d1\u8ba4\u77e5\u5408\u7406\u7684\u6c42\u89e3\u5668\u3002", "method": "\u4f7f\u7528\u5411\u91cf\u7b26\u53f7\u4ee3\u6570(VSA)\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u96c6\u6210\u7cfb\u7edf1\u76f4\u89c9\u548c\u7cfb\u7edf2\u63a8\u7406\uff0c\u901a\u8fc7\u9762\u5411\u5bf9\u8c61\u7684\u7a0b\u5e8f\u5408\u6210\uff0c\u5229\u7528VSA\u8868\u793a\u62bd\u8c61\u5bf9\u8c61\u3001\u6307\u5bfc\u89e3\u51b3\u65b9\u6848\u641c\u7d22\u5e76\u5b9e\u73b0\u6837\u672c\u9ad8\u6548\u7684\u795e\u7ecf\u5b66\u4e60\u3002", "result": "\u5728ARC-AGI-1-Train\u4e0a\u5f97\u520610.8%\uff0c\u5728ARC-AGI-1-Eval\u4e0a\u5f97\u52063.0%\uff1b\u5728Sort-of-ARC\u4e0a\u5f97\u520694.5%\uff0c\u57281D-ARC\u4e0a\u5f97\u520683.1%\u4e14\u4ee5\u6781\u4f4e\u8ba1\u7b97\u6210\u672c\u8d85\u8d8aGPT-4\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5c06VSA\u5e94\u7528\u4e8eARC-AGI\u7684\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u8ba4\u77e5\u5408\u7406\u7684ARC-AGI\u6c42\u89e3\u5668\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2511.09212", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09212", "abs": "https://arxiv.org/abs/2511.09212", "authors": ["Zeru Cheng", "Yanjing Yang", "He Zhang", "Lanxin Yang", "Jinghao Hu", "Jinwei Xu", "Bohan Liu", "Haifeng Shen"], "title": "Leveraging Self-Paced Learning for Software Vulnerability Detection", "comment": null, "summary": "Software vulnerabilities are major risks to software systems. Recently, researchers have proposed many deep learning approaches to detect software vulnerabilities. However, their accuracy is limited in practice. One of the main causes is low-quality training data (i.e., source code). To this end, we propose a new approach: SPLVD (Self-Paced Learning for Software Vulnerability Detection). SPLVD dynamically selects source code for model training based on the stage of training, which simulates the human learning process progressing from easy to hard. SPLVD has a data selector that is specifically designed for the vulnerability detection task, which enables it to prioritize the learning of easy source code. Before each training epoch, SPLVD uses the data selector to recalculate the difficulty of the source code, select new training source code, and update the data selector. When evaluating SPLVD, we first use three benchmark datasets with over 239K source code in which 25K are vulnerable for standard evaluations. Experimental results demonstrate that SPLVD achieves the highest F1 of 89.2%, 68.7%, and 43.5%, respectively, outperforming the state-of-the-art approaches. Then we collect projects from OpenHarmony, a new ecosystem that has not been learned by general LLMs, to evaluate SPLVD further. SPLVD achieves the highest precision of 90.9%, demonstrating its practical effectiveness.", "AI": {"tldr": "SPLVD\u662f\u4e00\u79cd\u57fa\u4e8e\u81ea\u6b65\u5b66\u4e60\u7684\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u8bad\u7ec3\u6570\u636e\u6a21\u62df\u4eba\u7c7b\u4ece\u6613\u5230\u96be\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u51c6\u786e\u7387\u6709\u9650\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u4f4e\u3002\u9700\u8981\u6539\u8fdb\u8bad\u7ec3\u6570\u636e\u9009\u62e9\u7b56\u7565\u6765\u63d0\u9ad8\u68c0\u6d4b\u6027\u80fd\u3002", "method": "\u63d0\u51faSPLVD\u65b9\u6cd5\uff0c\u5305\u542b\u4e13\u95e8\u8bbe\u8ba1\u7684\u6570\u636e\u9009\u62e9\u5668\uff0c\u5728\u6bcf\u8f6e\u8bad\u7ec3\u524d\u91cd\u65b0\u8ba1\u7b97\u6e90\u4ee3\u7801\u96be\u5ea6\uff0c\u9009\u62e9\u65b0\u7684\u8bad\u7ec3\u6570\u636e\u5e76\u66f4\u65b0\u9009\u62e9\u5668\uff0c\u6a21\u62df\u4eba\u7c7b\u4ece\u6613\u5230\u96be\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08\u8d85\u8fc7239K\u6e90\u4ee3\u7801\uff0c\u5176\u4e2d25K\u6709\u6f0f\u6d1e\uff09\u4e0a\uff0cSPLVD\u5206\u522b\u8fbe\u523089.2%\u300168.7%\u548c43.5%\u7684\u6700\u9ad8F1\u5206\u6570\u3002\u5728OpenHarmony\u9879\u76ee\u4e0a\u8fbe\u523090.9%\u7684\u6700\u9ad8\u7cbe\u786e\u7387\u3002", "conclusion": "SPLVD\u901a\u8fc7\u81ea\u6b65\u5b66\u4e60\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\uff0c\u5728\u6807\u51c6\u8bc4\u4f30\u548c\u5b9e\u9645\u65b0\u751f\u6001\u7cfb\u7edf\u4e0a\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.08703", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08703", "abs": "https://arxiv.org/abs/2511.08703", "authors": ["Yaroslav Popryho", "Debjit Pal", "Inna Partin-Vaisband"], "title": "Automated Hardware Trojan Insertion in Industrial-Scale Designs", "comment": "Accepted in DATE 2026", "summary": "Industrial Systems-on-Chips (SoCs) often comprise hundreds of thousands to millions of nets and millions to tens of millions of connectivity edges, making empirical evaluation of hardware-Trojan (HT) detectors on realistic designs both necessary and difficult. Public benchmarks remain significantly smaller and hand-crafted, while releasing truly malicious RTL raises ethical and operational risks. This work presents an automated and scalable methodology for generating HT-like patterns in industry-scale netlists whose purpose is to stress-test detection tools without altering user-visible functionality. The pipeline (i) parses large gate-level designs into connectivity graphs, (ii) explores rare regions using SCOAP testability metrics, and (iii) applies parameterized, function-preserving graph transformations to synthesize trigger-payload pairs that mimic the statistical footprint of stealthy HTs. When evaluated on the benchmarks generated in this work, representative state-of-the-art graph-learning models fail to detect Trojans. The framework closes the evaluation gap between academic circuits and modern SoCs by providing reproducible challenge instances that advance security research without sharing step-by-step attack instructions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5de5\u4e1a\u89c4\u6a21\u7f51\u8868\u4e2d\u751f\u6210\u786c\u4ef6\u6728\u9a6c(HT)\u7c7b\u6a21\u5f0f\uff0c\u4ee5\u5728\u4e0d\u6539\u53d8\u7528\u6237\u53ef\u89c1\u529f\u80fd\u7684\u60c5\u51b5\u4e0b\u5bf9\u68c0\u6d4b\u5de5\u5177\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u89e3\u6790\u95e8\u7ea7\u8bbe\u8ba1\u3001\u63a2\u7d22\u7f55\u89c1\u533a\u57df\u548c\u5e94\u7528\u529f\u80fd\u4fdd\u6301\u7684\u56fe\u53d8\u6362\u6765\u5408\u6210\u89e6\u53d1-\u8d1f\u8f7d\u5bf9\uff0c\u6a21\u62df\u9690\u853dHT\u7684\u7edf\u8ba1\u7279\u5f81\u3002", "motivation": "\u5de5\u4e1aSoC\u901a\u5e38\u5305\u542b\u6570\u5341\u4e07\u5230\u6570\u767e\u4e07\u4e2a\u7f51\u8868\u548c\u6570\u767e\u4e07\u5230\u6570\u5343\u4e07\u4e2a\u8fde\u63a5\u8fb9\uff0c\u4f7f\u5f97\u5728\u73b0\u5b9e\u8bbe\u8ba1\u4e0a\u5bf9\u786c\u4ef6\u6728\u9a6c\u68c0\u6d4b\u5668\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u65e2\u5fc5\u8981\u53c8\u56f0\u96be\u3002\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4ecd\u7136\u663e\u8457\u8f83\u5c0f\u4e14\u662f\u624b\u5de5\u5236\u4f5c\u7684\uff0c\u800c\u53d1\u5e03\u771f\u6b63\u7684\u6076\u610fRTL\u4f1a\u5e26\u6765\u4f26\u7406\u548c\u64cd\u4f5c\u98ce\u9669\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u62ec\u4e09\u4e2a\u6b65\u9aa4\uff1a(i)\u5c06\u5927\u578b\u95e8\u7ea7\u8bbe\u8ba1\u89e3\u6790\u4e3a\u8fde\u63a5\u56fe\uff0c(ii)\u4f7f\u7528SCOAP\u53ef\u6d4b\u8bd5\u6027\u6307\u6807\u63a2\u7d22\u7f55\u89c1\u533a\u57df\uff0c(iii)\u5e94\u7528\u53c2\u6570\u5316\u3001\u529f\u80fd\u4fdd\u6301\u7684\u56fe\u53d8\u6362\u6765\u5408\u6210\u6a21\u62df\u9690\u853dHT\u7edf\u8ba1\u7279\u5f81\u7684\u89e6\u53d1-\u8d1f\u8f7d\u5bf9\u3002", "result": "\u5728\u672c\u6587\u751f\u6210\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\u65f6\uff0c\u4ee3\u8868\u6027\u7684\u6700\u5148\u8fdb\u56fe\u5b66\u4e60\u6a21\u578b\u672a\u80fd\u68c0\u6d4b\u5230\u6728\u9a6c\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u63d0\u4f9b\u53ef\u91cd\u590d\u7684\u6311\u6218\u5b9e\u4f8b\uff0c\u5728\u4e0d\u5171\u4eab\u9010\u6b65\u653b\u51fb\u6307\u4ee4\u7684\u60c5\u51b5\u4e0b\u63a8\u8fdb\u5b89\u5168\u7814\u7a76\uff0c\u4ece\u800c\u7f29\u5c0f\u4e86\u5b66\u672f\u7535\u8def\u4e0e\u73b0\u4ee3SoC\u4e4b\u95f4\u7684\u8bc4\u4f30\u5dee\u8ddd\u3002"}}
{"id": "2511.09223", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09223", "abs": "https://arxiv.org/abs/2511.09223", "authors": ["Panya Trakoolgerntong", "Tao Xiao", "Masanari Kondo", "Chaiyong Ragkhitwetsagul", "Morakot Choetkiertikul", "Pattaraporn Sangaroonsilp", "Yasutaka Kamei"], "title": "AILINKPREVIEWER: Enhancing Code Reviews with LLM-Powered Link Previews", "comment": null, "summary": "Code review is a key practice in software engineering, where developers evaluate code changes to ensure quality and maintainability. Links to issues and external resources are often included in Pull Requests (PRs) to provide additional context, yet they are typically discarded in automated tasks such as PR summarization and code review comment generation. This limits the richness of information available to reviewers and increases cognitive load by forcing context-switching. To address this gap, we present AILINKPREVIEWER, a tool that leverages Large Language Models (LLMs) to generate previews of links in PRs using PR metadata, including titles, descriptions, comments, and link body content. We analyzed 50 engineered GitHub repositories and compared three approaches: Contextual LLM summaries, Non-Contextual LLM summaries, and Metadata-based previews. The results in metrics such as BLEU, BERTScore, and compression ratio show that contextual summaries consistently outperform other methods. However, in a user study with seven participants, most preferred non-contextual summaries, suggesting a trade-off between metric performance and perceived usability. These findings demonstrate the potential of LLM-powered link previews to enhance code review efficiency and to provide richer context for developers and automation in software engineering.\n  The video demo is available at https://www.youtube.com/watch?v=h2qH4RtrB3E, and the tool and its source code can be found at https://github.com/c4rtune/AILinkPreviewer.", "AI": {"tldr": "AILINKPREVIEWER\u5de5\u5177\u5229\u7528LLM\u751f\u6210PR\u4e2d\u94fe\u63a5\u7684\u9884\u89c8\uff0c\u901a\u8fc7\u7ed3\u5408PR\u5143\u6570\u636e\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u63d0\u5347\u4ee3\u7801\u5ba1\u67e5\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u5ba1\u67e5\u4e2d\uff0cPR\u4e2d\u7684\u94fe\u63a5\u4fe1\u606f\u5728\u81ea\u52a8\u5316\u4efb\u52a1\u4e2d\u88ab\u4e22\u5f03\uff0c\u5bfc\u81f4\u4fe1\u606f\u4e0d\u5b8c\u6574\uff0c\u589e\u52a0\u8bc4\u5ba1\u8005\u7684\u8ba4\u77e5\u8d1f\u62c5\u548c\u4e0a\u4e0b\u6587\u5207\u6362\u6210\u672c\u3002", "method": "\u5206\u679050\u4e2aGitHub\u4ed3\u5e93\uff0c\u6bd4\u8f83\u4e09\u79cd\u65b9\u6cd5\uff1a\u4e0a\u4e0b\u6587LLM\u6458\u8981\u3001\u975e\u4e0a\u4e0b\u6587LLM\u6458\u8981\u548c\u57fa\u4e8e\u5143\u6570\u636e\u7684\u9884\u89c8\uff0c\u4f7f\u7528BLEU\u3001BERTScore\u548c\u538b\u7f29\u7387\u7b49\u6307\u6807\u8bc4\u4f30\u3002", "result": "\u4e0a\u4e0b\u6587\u6458\u8981\u5728\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u7528\u6237\u7814\u7a76\u663e\u793a\u5927\u591a\u6570\u53c2\u4e0e\u8005\u66f4\u559c\u6b22\u975e\u4e0a\u4e0b\u6587\u6458\u8981\uff0c\u8868\u660e\u6307\u6807\u6027\u80fd\u4e0e\u7528\u6237\u4f53\u9a8c\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u94fe\u63a5\u9884\u89c8\u6709\u6f5c\u529b\u63d0\u5347\u4ee3\u7801\u5ba1\u67e5\u6548\u7387\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002"}}
{"id": "2511.08902", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.08902", "abs": "https://arxiv.org/abs/2511.08902", "authors": ["Yingjie Sun", "Guyue Li", "Hongfu Chou", "Aiqun Hu"], "title": "Channel-Robust RFF for Low-Latency 5G Device Identification in SIMO Scenarios", "comment": null, "summary": "Ultra-low latency, the hallmark of fifth-generation mobile communications (5G), imposes exacting timing demands on identification as well. Current cryptographic solutions introduce additional computational overhead, which results in heightened identification delays. Radio frequency fingerprint (RFF) identifies devices at the physical layer, blocking impersonation attacks while significantly reducing latency. Unfortunately, multipath channels compromise RFF accuracy, and existing channel-resilient methods demand feedback or processing across multiple time points, incurring extra signaling latency. To address this problem, the paper introduces a new RFF extraction technique that employs signals from multiple receiving antennas to address multipath issues without adding latency. Unlike single-domain methods, the Log-Linear Delta Ratio (LLDR) of co-temporal channel frequency responses (CFRs) from multiple antennas is employed to preserve discriminative RFF features, eliminating multi-time sampling and reducing acquisition time. To overcome the challenge of the reliance on minimal channel variation, the frequency band is segmented into sub-bands, and the LLDR is computed within each sub-band individually. Simulation results indicate that the proposed scheme attains a 96.13% identification accuracy for 30 user equipments (UEs) within a 20-path channel under a signal-to-noise ratio (SNR) of 20 dB. Furthermore, we evaluate the theoretical latency using the Roofline model, resulting in the air interface latency of 0.491 ms, which satisfies ultra-reliable and low-latency communications (URLLC) latency requirements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u5929\u7ebf\u4fe1\u53f7\u7684\u65b0\u578b\u5c04\u9891\u6307\u7eb9\u63d0\u53d6\u6280\u672f\uff0c\u901a\u8fc7\u8ba1\u7b97\u5171\u65f6\u4fe1\u9053\u9891\u7387\u54cd\u5e94\u7684\u5bf9\u6570\u7ebf\u6027\u589e\u91cf\u6bd4\u6765\u89e3\u51b3\u591a\u5f84\u95ee\u9898\uff0c\u65e0\u9700\u589e\u52a0\u5ef6\u8fdf\u5373\u53ef\u5b9e\u73b096.13%\u7684\u8bbe\u5907\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "5G\u8d85\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u5bf9\u8bbe\u5907\u8bc6\u522b\u63d0\u51fa\u4e86\u4e25\u683c\u7684\u65f6\u5e8f\u8981\u6c42\uff0c\u73b0\u6709\u52a0\u5bc6\u65b9\u6848\u4f1a\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u548c\u8bc6\u522b\u5ef6\u8fdf\u3002\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u867d\u7136\u80fd\u964d\u4f4e\u5ef6\u8fdf\uff0c\u4f46\u591a\u5f84\u4fe1\u9053\u4f1a\u5f71\u54cd\u5176\u51c6\u786e\u6027\uff0c\u800c\u73b0\u6709\u7684\u6297\u591a\u5f84\u65b9\u6cd5\u9700\u8981\u53cd\u9988\u6216\u591a\u65f6\u95f4\u70b9\u5904\u7406\uff0c\u4f1a\u5e26\u6765\u989d\u5916\u7684\u4fe1\u4ee4\u5ef6\u8fdf\u3002", "method": "\u63d0\u51faLog-Linear Delta Ratio (LLDR)\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u63a5\u6536\u5929\u7ebf\u7684\u5171\u65f6\u4fe1\u9053\u9891\u7387\u54cd\u5e94\u6765\u63d0\u53d6\u5c04\u9891\u6307\u7eb9\u7279\u5f81\u3002\u5c06\u9891\u5e26\u5212\u5206\u4e3a\u5b50\u5e26\uff0c\u5728\u6bcf\u4e2a\u5b50\u5e26\u5185\u5355\u72ec\u8ba1\u7b97LLDR\uff0c\u4ee5\u514b\u670d\u5bf9\u6700\u5c0f\u4fe1\u9053\u53d8\u5316\u7684\u4f9d\u8d56\u3002\u8be5\u65b9\u6cd5\u907f\u514d\u4e86\u591a\u65f6\u95f4\u91c7\u6837\uff0c\u51cf\u5c11\u4e86\u91c7\u96c6\u65f6\u95f4\u3002", "result": "\u572820\u8def\u5f84\u4fe1\u9053\u548c20dB\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\uff0c\u5bf930\u4e2a\u7528\u6237\u8bbe\u5907\u7684\u8bc6\u522b\u51c6\u786e\u7387\u8fbe\u523096.13%\u3002\u4f7f\u7528Roofline\u6a21\u578b\u8bc4\u4f30\u7406\u8bba\u5ef6\u8fdf\uff0c\u7a7a\u4e2d\u63a5\u53e3\u5ef6\u8fdf\u4e3a0.491ms\uff0c\u6ee1\u8db3\u8d85\u53ef\u9760\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u7684\u5ef6\u8fdf\u8981\u6c42\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6848\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u5f84\u4fe1\u9053\u5bf9\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u7684\u5f71\u54cd\uff0c\u5728\u4fdd\u6301\u9ad8\u8bc6\u522b\u51c6\u786e\u7387\u7684\u540c\u65f6\u6ee1\u8db35G\u8d85\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u7684\u65f6\u5e8f\u8981\u6c42\uff0c\u4e3a\u7269\u7406\u5c42\u8bbe\u5907\u8bc6\u522b\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09231", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09231", "abs": "https://arxiv.org/abs/2511.09231", "authors": ["Tobias Eisenreich", "Nicholas Friedlaender", "Stefan Wagner"], "title": "Leveraging Large Language Models for Use Case Model Generation from Software Requirements", "comment": "Accepted at the Intelligent Software Engineering Workshop (ISE 2025) at ASE 2025", "summary": "Use case modeling employs user-centered scenarios to outline system requirements. These help to achieve consensus among relevant stakeholders. Because the manual creation of use case models is demanding and time-consuming, it is often skipped in practice. This study explores the potential of Large Language Models (LLMs) to assist in this tedious process. The proposed method integrates an open-weight LLM to systematically extract actors and use cases from software requirements with advanced prompt engineering techniques. The method is evaluated using an exploratory study conducted with five professional software engineers, which compares traditional manual modeling to the proposed LLM-based approach. The results show a substantial acceleration, reducing the modeling time by 60\\%. At the same time, the model quality remains on par. Besides improving the modeling efficiency, the participants indicated that the method provided valuable guidance in the process.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7528\u4f8b\u5efa\u6a21\uff0c\u901a\u8fc7\u96c6\u6210\u5f00\u6e90LLM\u548c\u9ad8\u7ea7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u4ece\u8f6f\u4ef6\u9700\u6c42\u4e2d\u63d0\u53d6\u53c2\u4e0e\u8005\u548c\u7528\u4f8b\uff0c\u76f8\u6bd4\u4f20\u7edf\u624b\u52a8\u65b9\u6cd5\u5efa\u6a21\u65f6\u95f4\u51cf\u5c1160%\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u3002", "motivation": "\u7528\u4f8b\u5efa\u6a21\u91c7\u7528\u7528\u6237\u4e2d\u5fc3\u573a\u666f\u6765\u6982\u8ff0\u7cfb\u7edf\u9700\u6c42\uff0c\u6709\u52a9\u4e8e\u76f8\u5173\u5229\u76ca\u76f8\u5173\u8005\u8fbe\u6210\u5171\u8bc6\u3002\u4f46\u7531\u4e8e\u624b\u52a8\u521b\u5efa\u7528\u4f8b\u6a21\u578b\u8017\u65f6\u8d39\u529b\uff0c\u5b9e\u8df5\u4e2d\u5e38\u88ab\u8df3\u8fc7\u3002\u672c\u7814\u7a76\u63a2\u7d22LLM\u5728\u8f85\u52a9\u8fd9\u4e00\u7e41\u7410\u8fc7\u7a0b\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5\u96c6\u6210\u5f00\u6e90\u6743\u91cdLLM\uff0c\u901a\u8fc7\u9ad8\u7ea7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u4ece\u8f6f\u4ef6\u9700\u6c42\u4e2d\u7cfb\u7edf\u63d0\u53d6\u53c2\u4e0e\u8005\u548c\u7528\u4f8b\u3002\u91c7\u7528\u63a2\u7d22\u6027\u7814\u7a76\uff0c\u7531\u4e94\u540d\u4e13\u4e1a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u6bd4\u8f83\u4f20\u7edf\u624b\u52a8\u5efa\u6a21\u4e0eLLM\u65b9\u6cd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5efa\u6a21\u65f6\u95f4\u5927\u5e45\u52a0\u901f\uff0c\u51cf\u5c1160%\u3002\u540c\u65f6\u6a21\u578b\u8d28\u91cf\u4fdd\u6301\u540c\u7b49\u6c34\u5e73\u3002\u53c2\u4e0e\u8005\u8868\u793a\u8be5\u65b9\u6cd5\u5728\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6307\u5bfc\u3002", "conclusion": "LLM\u8f85\u52a9\u7684\u7528\u4f8b\u5efa\u6a21\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5efa\u6a21\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u8d28\u91cf\uff0c\u4e3a\u8f6f\u4ef6\u9700\u6c42\u5de5\u7a0b\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u81ea\u52a8\u5316\u652f\u6301\u3002"}}
{"id": "2511.08905", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08905", "abs": "https://arxiv.org/abs/2511.08905", "authors": ["Zixun Xiong", "Gaoyi Wu", "Qingyang Yu", "Mingyu Derek Ma", "Lingfeng Yao", "Miao Pan", "Xiaojiang Du", "Hao Wang"], "title": "iSeal: Encrypted Fingerprinting for Reliable LLM Ownership Verification", "comment": "Accepted by AAAI 2026", "summary": "Given the high cost of large language model (LLM) training from scratch, safeguarding LLM intellectual property (IP) has become increasingly crucial. As the standard paradigm for IP ownership verification, LLM fingerprinting thus plays a vital role in addressing this challenge. Existing LLM fingerprinting methods verify ownership by extracting or injecting model-specific features. However, they overlook potential attacks during the verification process, leaving them ineffective when the model thief fully controls the LLM's inference process. In such settings, attackers may share prompt-response pairs to enable fingerprint unlearning or manipulate outputs to evade exact-match verification. We propose iSeal, the first fingerprinting method designed for reliable verification when the model thief controls the suspected LLM in an end-to-end manner. It injects unique features into both the model and an external module, reinforced by an error-correction mechanism and a similarity-based verification strategy. These components are resistant to verification-time attacks, including collusion-based fingerprint unlearning and response manipulation, backed by both theoretical analysis and empirical results. iSeal achieves 100 percent Fingerprint Success Rate (FSR) on 12 LLMs against more than 10 attacks, while baselines fail under unlearning and response manipulations.", "AI": {"tldr": "iSeal\u662f\u4e00\u79cd\u9488\u5bf9LLM\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7684\u6307\u7eb9\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u653b\u51fb\u8005\u5b8c\u5168\u63a7\u5236\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u53ef\u9760\u9a8c\u8bc1\uff0c\u901a\u8fc7\u6a21\u578b\u548c\u5916\u90e8\u6a21\u5757\u7684\u7279\u5f81\u6ce8\u5165\u3001\u7ea0\u9519\u673a\u5236\u548c\u76f8\u4f3c\u6027\u9a8c\u8bc1\u7b56\u7565\u6765\u62b5\u5fa1\u9a8c\u8bc1\u65f6\u653b\u51fb\u3002", "motivation": "\u7531\u4e8eLLM\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\uff0c\u4fdd\u62a4\u5176\u77e5\u8bc6\u4ea7\u6743\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u6307\u7eb9\u65b9\u6cd5\u5728\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u53d7\u5230\u653b\u51fb\uff0c\u5f53\u6a21\u578b\u7a83\u8d3c\u5b8c\u5168\u63a7\u5236LLM\u63a8\u7406\u8fc7\u7a0b\u65f6\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4f1a\u5931\u6548\u3002", "method": "iSeal\u901a\u8fc7\u5728\u6a21\u578b\u548c\u5916\u90e8\u6a21\u5757\u4e2d\u6ce8\u5165\u72ec\u7279\u7279\u5f81\uff0c\u7ed3\u5408\u7ea0\u9519\u673a\u5236\u548c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u9a8c\u8bc1\u7b56\u7565\uff0c\u8bbe\u8ba1\u51fa\u80fd\u591f\u62b5\u6297\u9a8c\u8bc1\u65f6\u653b\u51fb\u7684\u6307\u7eb9\u7cfb\u7edf\u3002", "result": "\u572812\u4e2aLLM\u4e0a\u5bf9\u629710\u591a\u79cd\u653b\u51fb\u65f6\uff0ciSeal\u5b9e\u73b0\u4e86100%\u7684\u6307\u7eb9\u6210\u529f\u7387\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u5728\u6307\u7eb9\u9057\u5fd8\u548c\u54cd\u5e94\u64cd\u7eb5\u653b\u51fb\u4e0b\u5931\u6548\u3002", "conclusion": "iSeal\u662f\u9996\u4e2a\u80fd\u591f\u5728\u6a21\u578b\u7a83\u8d3c\u7aef\u5230\u7aef\u63a7\u5236\u53ef\u7591LLM\u65f6\u8fdb\u884c\u53ef\u9760\u9a8c\u8bc1\u7684\u6307\u7eb9\u65b9\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7ed3\u679c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2511.08873", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08873", "abs": "https://arxiv.org/abs/2511.08873", "authors": ["Shouang Wei", "Min Zhang", "Xin Lin", "Bo Jiang", "Kun Kuang", "Zhongxiang Dai"], "title": "UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models", "comment": null, "summary": "Large language models (LLMs) are shifting from answer providers to intelligent tutors in educational settings, yet current supervised fine-tuning methods only learn surface teaching patterns without dynamic adaptation capabilities. Recent reinforcement learning approaches address this limitation but face two critical challenges. First, they evaluate teaching effectiveness solely based on whether students produce correct outputs, unable to distinguish whether students genuinely understand or echo teacher-provided answers during interaction. Second, they cannot perceive students' evolving cognitive states in real time through interactive dialogue, thus failing to adapt teaching strategies to match students' cognitive levels dynamically. We propose the Unidirectional Cognitive Optimization (UCO) method to address these challenges. UCO uses a multi-turn interactive reinforcement learning paradigm where the innovation lies in two synergistic reward functions: the Progress Reward captures students' cognitive advancement, evaluating whether students truly transition from confusion to comprehension, while the Scaffold Reward dynamically identifies each student's Zone of Proximal Development (ZPD), encouraging teachers to maintain productive teaching within this zone. We evaluate UCO by comparing it against 11 baseline models on BigMath and MathTutorBench benchmarks. Experimental results demonstrate that our UCO model outperforms all models of equivalent scale and achieves performance comparable to advanced closed-source models. The code and data are available at https://github.com/Mind-Lab-ECNU/UCO.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5355\u5411\u8ba4\u77e5\u4f18\u5316\uff08UCO\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3LLM\u4f5c\u4e3a\u667a\u80fd\u5bfc\u5e08\u65f6\u7684\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u65e0\u6cd5\u533a\u5206\u5b66\u751f\u662f\u5426\u771f\u6b63\u7406\u89e3\uff0c\u4ee5\u53ca\u65e0\u6cd5\u611f\u77e5\u5b66\u751f\u8ba4\u77e5\u72b6\u6001\u53d8\u5316\u3002", "motivation": "\u5f53\u524dLLM\u4f5c\u4e3a\u667a\u80fd\u5bfc\u5e08\u7684\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u53ea\u80fd\u5b66\u4e60\u8868\u9762\u6559\u5b66\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u52a8\u6001\u9002\u5e94\u80fd\u529b\uff1b\u800c\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u65e0\u6cd5\u533a\u5206\u5b66\u751f\u662f\u5426\u771f\u6b63\u7406\u89e3\uff0c\u4ee5\u53ca\u65e0\u6cd5\u5b9e\u65f6\u611f\u77e5\u5b66\u751f\u8ba4\u77e5\u72b6\u6001\u53d8\u5316\u3002", "method": "UCO\u91c7\u7528\u591a\u8f6e\u4ea4\u4e92\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u5956\u52b1\u51fd\u6570\uff1a\u8fdb\u5c55\u5956\u52b1\u6355\u6349\u5b66\u751f\u8ba4\u77e5\u8fdb\u6b65\uff0c\u8bc4\u4f30\u5b66\u751f\u662f\u5426\u771f\u6b63\u4ece\u56f0\u60d1\u8f6c\u5411\u7406\u89e3\uff1b\u652f\u67b6\u5956\u52b1\u52a8\u6001\u8bc6\u522b\u6bcf\u4e2a\u5b66\u751f\u7684\u6700\u8fdc\u53d1\u5c55\u533a\uff0c\u9f13\u52b1\u6559\u5e08\u5728\u8be5\u533a\u57df\u5185\u4fdd\u6301\u9ad8\u6548\u6559\u5b66\u3002", "result": "\u5728BigMath\u548cMathTutorBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cUCO\u6a21\u578b\u4f18\u4e8e\u6240\u6709\u540c\u7b49\u89c4\u6a21\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u8fbe\u5230\u4e0e\u5148\u8fdb\u95ed\u6e90\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "UCO\u65b9\u6cd5\u901a\u8fc7\u8fdb\u5c55\u5956\u52b1\u548c\u652f\u67b6\u5956\u52b1\u7684\u534f\u540c\u4f5c\u7528\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u4f5c\u4e3a\u667a\u80fd\u5bfc\u5e08\u65f6\u7684\u8ba4\u77e5\u72b6\u6001\u611f\u77e5\u548c\u6559\u5b66\u7b56\u7565\u52a8\u6001\u9002\u5e94\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6559\u5b66\u6548\u679c\u3002"}}
{"id": "2511.09268", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09268", "abs": "https://arxiv.org/abs/2511.09268", "authors": ["Helio Victor F. Santos", "Vitor Costa", "Joao Eduardo Montandon", "Marco Tulio Valente"], "title": "Decoding the Configuration of AI Coding Agents: Insights from Claude Code Projects", "comment": null, "summary": "Agentic code assistants are a new generation of AI systems capable of performing end-to-end software engineering tasks. While these systems promise unprecedented productivity gains, their behavior and effectiveness depend heavily on configuration files that define architectural constraints, coding practices, and tool usage policies. However, little is known about the structure and content of these configuration artifacts. This paper presents an empirical study of the configuration ecosystem of Claude Code, one of the most widely used agentic coding systems. We collected and analyzed 328 configuration files from public Claude Code projects to identify (i) the software engineering concerns and practices they specify and (ii) how these concerns co-occur within individual files. The results highlight the importance of defining a wide range of concerns and practices in agent configuration files, with particular emphasis on specifying the architecture the agent should follow.", "AI": {"tldr": "\u672c\u6587\u5bf9Claude Code\u667a\u80fd\u4ee3\u7801\u52a9\u624b\u7684\u914d\u7f6e\u751f\u6001\u7cfb\u7edf\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u4e86328\u4e2a\u516c\u5f00\u914d\u7f6e\u6587\u4ef6\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5173\u6ce8\u70b9\u548c\u5b9e\u8df5\uff0c\u7279\u522b\u5f3a\u8c03\u4e86\u67b6\u6784\u89c4\u8303\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u667a\u80fd\u4ee3\u7801\u52a9\u624b\u7684\u884c\u4e3a\u548c\u6548\u679c\u4e25\u91cd\u4f9d\u8d56\u4e8e\u5b9a\u4e49\u67b6\u6784\u7ea6\u675f\u3001\u7f16\u7801\u5b9e\u8df5\u548c\u5de5\u5177\u4f7f\u7528\u7b56\u7565\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u4f46\u76ee\u524d\u5bf9\u8fd9\u4e9b\u914d\u7f6e\u5de5\u4ef6\u7684\u7ed3\u6784\u548c\u5185\u5bb9\u4e86\u89e3\u751a\u5c11\u3002", "method": "\u6536\u96c6\u5e76\u5206\u6790\u4e86\u6765\u81ea\u516c\u5171Claude Code\u9879\u76ee\u7684328\u4e2a\u914d\u7f6e\u6587\u4ef6\uff0c\u8bc6\u522b\u4e86(i)\u5b83\u4eec\u6307\u5b9a\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5173\u6ce8\u70b9\u548c\u5b9e\u8df5\uff0c\u4ee5\u53ca(ii)\u8fd9\u4e9b\u5173\u6ce8\u70b9\u5728\u5355\u4e2a\u6587\u4ef6\u4e2d\u7684\u5171\u73b0\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u667a\u80fd\u4f53\u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u5e7f\u6cdb\u5173\u6ce8\u70b9\u548c\u5b9e\u8df5\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\u6307\u5b9a\u667a\u80fd\u4f53\u5e94\u9075\u5faa\u7684\u67b6\u6784\u3002", "conclusion": "\u914d\u7f6e\u6587\u4ef6\u4e2d\u9700\u8981\u660e\u786e\u5b9a\u4e49\u5404\u79cd\u8f6f\u4ef6\u5de5\u7a0b\u5173\u6ce8\u70b9\u548c\u5b9e\u8df5\uff0c\u5176\u4e2d\u67b6\u6784\u89c4\u8303\u5c24\u4e3a\u5173\u952e\uff0c\u8fd9\u5bf9\u667a\u80fd\u4ee3\u7801\u52a9\u624b\u7684\u6709\u6548\u8fd0\u884c\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.08985", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08985", "abs": "https://arxiv.org/abs/2511.08985", "authors": ["Yunfei Yang", "Xiaojun Chen", "Yuexin Xuan", "Zhendong Zhao", "Xin Zhao", "He Li"], "title": "DeepTracer: Tracing Stolen Model via Deep Coupled Watermarks", "comment": "Extended version of the paper accepted by AAAI 2026", "summary": "Model watermarking techniques can embed watermark information into the protected model for ownership declaration by constructing specific input-output pairs. However, existing watermarks are easily removed when facing model stealing attacks, and make it difficult for model owners to effectively verify the copyright of stolen models. In this paper, we analyze the root cause of the failure of current watermarking methods under model stealing scenarios and then explore potential solutions. Specifically, we introduce a robust watermarking framework, DeepTracer, which leverages a novel watermark samples construction method and a same-class coupling loss constraint. DeepTracer can incur a high-coupling model between watermark task and primary task that makes adversaries inevitably learn the hidden watermark task when stealing the primary task functionality. Furthermore, we propose an effective watermark samples filtering mechanism that elaborately select watermark key samples used in model ownership verification to enhance the reliability of watermarks. Extensive experiments across multiple datasets and models demonstrate that our method surpasses existing approaches in defending against various model stealing attacks, as well as watermark attacks, and achieves new state-of-the-art effectiveness and robustness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DeepTracer\u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u6c34\u5370\u6837\u672c\u6784\u5efa\u65b9\u6cd5\u548c\u540c\u7c7b\u8026\u5408\u635f\u5931\u7ea6\u675f\uff0c\u5728\u6a21\u578b\u7a83\u53d6\u653b\u51fb\u4e0b\u5b9e\u73b0\u9c81\u68d2\u7684\u6c34\u5370\u4fdd\u62a4\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u6c34\u5370\u6280\u672f\u5728\u9762\u5bf9\u6a21\u578b\u7a83\u53d6\u653b\u51fb\u65f6\u5bb9\u6613\u88ab\u79fb\u9664\uff0c\u5bfc\u81f4\u6a21\u578b\u6240\u6709\u8005\u96be\u4ee5\u6709\u6548\u9a8c\u8bc1\u88ab\u76d7\u6a21\u578b\u7684\u7248\u6743\u3002", "method": "\u91c7\u7528\u6c34\u5370\u6837\u672c\u6784\u5efa\u65b9\u6cd5\u548c\u540c\u7c7b\u8026\u5408\u635f\u5931\u7ea6\u675f\uff0c\u4f7f\u6c34\u5370\u4efb\u52a1\u4e0e\u4e3b\u8981\u4efb\u52a1\u9ad8\u5ea6\u8026\u5408\uff0c\u8feb\u4f7f\u653b\u51fb\u8005\u5728\u7a83\u53d6\u4e3b\u8981\u529f\u80fd\u65f6\u4e0d\u53ef\u907f\u514d\u5730\u5b66\u4e60\u9690\u85cf\u7684\u6c34\u5370\u4efb\u52a1\u3002\u540c\u65f6\u63d0\u51fa\u6c34\u5370\u6837\u672c\u8fc7\u6ee4\u673a\u5236\uff0c\u7cbe\u5fc3\u9009\u62e9\u7528\u4e8e\u6a21\u578b\u6240\u6709\u6743\u9a8c\u8bc1\u7684\u6c34\u5370\u5173\u952e\u6837\u672c\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9632\u5fa1\u5404\u79cd\u6a21\u578b\u7a83\u53d6\u653b\u51fb\u548c\u6c34\u5370\u653b\u51fb\u65b9\u9762\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "DeepTracer\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u6a21\u578b\u7a83\u53d6\u653b\u51fb\uff0c\u4e3a\u6a21\u578b\u7248\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.08892", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08892", "abs": "https://arxiv.org/abs/2511.08892", "authors": ["Weihao Tan", "Xiangyang Li", "Yunhao Fang", "Heyuan Yao", "Shi Yan", "Hao Luo", "Tenglong Ao", "Huihui Li", "Hongbin Ren", "Bairen Yi", "Yujia Qin", "Bo An", "Libin Liu", "Guang Shi"], "title": "Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds", "comment": null, "summary": "We introduce Lumine, the first open recipe for developing generalist agents capable of completing hours-long complex missions in real time within challenging 3D open-world environments. Lumine adopts a human-like interaction paradigm that unifies perception, reasoning, and action in an end-to-end manner, powered by a vision-language model. It processes raw pixels at 5 Hz to produce precise 30 Hz keyboard-mouse actions and adaptively invokes reasoning only when necessary. Trained in Genshin Impact, Lumine successfully completes the entire five-hour Mondstadt main storyline on par with human-level efficiency and follows natural language instructions to perform a broad spectrum of tasks in both 3D open-world exploration and 2D GUI manipulation across collection, combat, puzzle-solving, and NPC interaction. In addition to its in-domain performance, Lumine demonstrates strong zero-shot cross-game generalization. Without any fine-tuning, it accomplishes 100-minute missions in Wuthering Waves and the full five-hour first chapter of Honkai: Star Rail. These promising results highlight Lumine's effectiveness across distinct worlds and interaction dynamics, marking a concrete step toward generalist agents in open-ended environments.", "AI": {"tldr": "Lumine\u662f\u9996\u4e2a\u80fd\u591f\u57283D\u5f00\u653e\u4e16\u754c\u4e2d\u5b9e\u65f6\u5b8c\u6210\u6570\u5c0f\u65f6\u590d\u6742\u4efb\u52a1\u7684\u901a\u7528\u667a\u80fd\u4f53\uff0c\u91c7\u7528\u7aef\u5230\u7aef\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7edf\u4e00\u611f\u77e5\u3001\u63a8\u7406\u548c\u884c\u52a8\uff0c\u5728Genshin Impact\u4e2d\u8bad\u7ec3\u540e\u80fd\u5b8c\u62105\u5c0f\u65f6\u4e3b\u7ebf\u5267\u60c5\uff0c\u5e76\u5177\u5907\u96f6\u6837\u672c\u8de8\u6e38\u620f\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f00\u53d1\u80fd\u591f\u5728\u590d\u67423D\u5f00\u653e\u4e16\u754c\u4e2d\u5b8c\u6210\u957f\u65f6\u95f4\u4efb\u52a1\u7684\u901a\u7528\u667a\u80fd\u4f53\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5b9e\u65f6\u3001\u957f\u65f6\u95f4\u4efb\u52a1\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u4eba\u673a\u4ea4\u4e92\u8303\u5f0f\uff0c\u901a\u8fc7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ee55Hz\u5904\u7406\u539f\u59cb\u50cf\u7d20\uff0c\u751f\u621030Hz\u7684\u952e\u76d8\u9f20\u6807\u52a8\u4f5c\uff0c\u4ec5\u5728\u5fc5\u8981\u65f6\u8fdb\u884c\u63a8\u7406\u3002\u5728Genshin Impact\u4e2d\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u6210\u529f\u5b8c\u6210Genshin Impact\u4e2d5\u5c0f\u65f6Mondstadt\u4e3b\u7ebf\u5267\u60c5\uff0c\u6548\u7387\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\uff1b\u5728Wuthering Waves\u4e2d\u5b8c\u6210100\u5206\u949f\u4efb\u52a1\uff0c\u5728Honkai: Star Rail\u4e2d\u5b8c\u62105\u5c0f\u65f6\u7b2c\u4e00\u7ae0\uff0c\u5747\u65e0\u9700\u5fae\u8c03\u3002", "conclusion": "Lumine\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u8de8\u4e0d\u540c\u4e16\u754c\u548c\u4ea4\u4e92\u52a8\u6001\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u662f\u8fc8\u5411\u901a\u7528\u667a\u80fd\u4f53\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2511.09373", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09373", "abs": "https://arxiv.org/abs/2511.09373", "authors": ["Adam \u0160torek", "Vikas Upadhyay", "Marianne Menglin Liu", "Daniel W. Peterson", "Anshul Mittal", "Sujeeth Bharadwaj", "Fahad Shah", "Dan Roth"], "title": "Routesplain: Towards Faithful and Intervenable Routing for Software-related Tasks", "comment": null, "summary": "LLMs now tackle a wide range of software-related tasks, yet we show that their performance varies markedly both across and within these tasks. Routing user queries to the appropriate LLMs can therefore help improve response quality while reducing cost. Prior work, however, has focused mainly on general-purpose LLM routing via black-box models. We introduce Routesplain, the first LLM router for software-related tasks, including multilingual code generation and repair, input/output prediction, and computer science QA. Unlike existing routing approaches, Routesplain first extracts human-interpretable concepts from each query (e.g., task, domain, reasoning complexity) and only routes based on these concepts, thereby providing intelligible, faithful rationales. We evaluate Routesplain on 16 state-of-the-art LLMs across eight software-related tasks; Routesplain outperforms individual models both in terms of accuracy and cost, and equals or surpasses all black-box baselines, with concept-level intervention highlighting avenues for further router improvements.", "AI": {"tldr": "Routesplain\u662f\u4e00\u4e2a\u4e13\u4e3a\u8f6f\u4ef6\u76f8\u5173\u4efb\u52a1\u8bbe\u8ba1\u7684LLM\u8def\u7531\u7cfb\u7edf\uff0c\u901a\u8fc7\u63d0\u53d6\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\u6765\u667a\u80fd\u9009\u62e9\u6700\u9002\u5408\u7684LLM\uff0c\u5728\u51c6\u786e\u6027\u548c\u6210\u672c\u65b9\u9762\u90fd\u4f18\u4e8e\u5355\u4e2a\u6a21\u578b\uff0c\u5e76\u8fbe\u5230\u6216\u8d85\u8fc7\u6240\u6709\u9ed1\u76d2\u57fa\u7ebf\u3002", "motivation": "\u5f53\u524dLLM\u5728\u8f6f\u4ef6\u76f8\u5173\u4efb\u52a1\u4e2d\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff0c\u901a\u8fc7\u8def\u7531\u7528\u6237\u67e5\u8be2\u5230\u5408\u9002\u7684LLM\u53ef\u4ee5\u63d0\u9ad8\u54cd\u5e94\u8d28\u91cf\u5e76\u964d\u4f4e\u6210\u672c\uff0c\u4f46\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u901a\u7528LLM\u8def\u7531\u3002", "method": "Routesplain\u9996\u5148\u4ece\u6bcf\u4e2a\u67e5\u8be2\u4e2d\u63d0\u53d6\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\uff08\u5982\u4efb\u52a1\u7c7b\u578b\u3001\u9886\u57df\u3001\u63a8\u7406\u590d\u6742\u5ea6\uff09\uff0c\u7136\u540e\u4ec5\u57fa\u4e8e\u8fd9\u4e9b\u6982\u5ff5\u8fdb\u884c\u8def\u7531\uff0c\u63d0\u4f9b\u53ef\u7406\u89e3\u7684\u3001\u53ef\u4fe1\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u572816\u4e2a\u6700\u5148\u8fdb\u7684LLM\u548c8\u4e2a\u8f6f\u4ef6\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cRoutesplain\u5728\u51c6\u786e\u6027\u548c\u6210\u672c\u65b9\u9762\u90fd\u4f18\u4e8e\u5355\u4e2a\u6a21\u578b\uff0c\u5e76\u7b49\u4e8e\u6216\u8d85\u8fc7\u6240\u6709\u9ed1\u76d2\u57fa\u7ebf\u3002", "conclusion": "Routesplain\u662f\u7b2c\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u8f6f\u4ef6\u76f8\u5173\u4efb\u52a1\u7684LLM\u8def\u7531\u5668\uff0c\u901a\u8fc7\u6982\u5ff5\u7ea7\u5e72\u9884\u4e3a\u8def\u7531\u5668\u8fdb\u4e00\u6b65\u6539\u8fdb\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2511.09043", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09043", "abs": "https://arxiv.org/abs/2511.09043", "authors": ["Farjana Yesmin"], "title": "MedHE: Communication-Efficient Privacy-Preserving Federated Learning with Adaptive Gradient Sparsification for Healthcare", "comment": "8 pages, 4 Figures, 5 Tables", "summary": "Healthcare federated learning requires strong privacy guarantees while maintaining computational efficiency across resource-constrained medical institutions. This paper presents MedHE, a novel framework combining adaptive gradient sparsification with CKKS homomorphic encryption to enable privacy-preserving collaborative learning on sensitive medical data. Our approach introduces a dynamic threshold mechanism with error compensation for top-k gradient selection, achieving 97.5 percent communication reduction while preserving model utility. We provide formal security analysis under Ring Learning with Errors assumptions and demonstrate differential privacy guarantees with epsilon less than or equal to 1.0. Statistical testing across 5 independent trials shows MedHE achieves 89.5 percent plus or minus 0.8 percent accuracy, maintaining comparable performance to standard federated learning (p=0.32) while reducing communication from 1277 MB to 32 MB per training round. Comprehensive evaluation demonstrates practical feasibility for real-world medical deployments with HIPAA compliance and scalability to 100 plus institutions.", "AI": {"tldr": "MedHE\u6846\u67b6\u7ed3\u5408\u81ea\u9002\u5e94\u68af\u5ea6\u7a00\u758f\u5316\u548cCKKS\u540c\u6001\u52a0\u5bc6\uff0c\u5728\u533b\u7597\u8054\u90a6\u5b66\u4e60\u4e2d\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\uff0c\u901a\u4fe1\u91cf\u51cf\u5c1197.5%\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u533b\u7597\u8054\u90a6\u5b66\u4e60\u9700\u8981\u5728\u8d44\u6e90\u53d7\u9650\u7684\u533b\u7597\u673a\u6784\u95f4\u63d0\u4f9b\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u91c7\u7528\u81ea\u9002\u5e94\u68af\u5ea6\u7a00\u758f\u5316\u4e0eCKKS\u540c\u6001\u52a0\u5bc6\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5f15\u5165\u5e26\u8bef\u5dee\u8865\u507f\u7684\u52a8\u6001\u9608\u503c\u673a\u5236\u8fdb\u884ctop-k\u68af\u5ea6\u9009\u62e9\u3002", "result": "\u57285\u6b21\u72ec\u7acb\u8bd5\u9a8c\u4e2d\u8fbe\u523089.5\u00b10.8%\u51c6\u786e\u7387\uff0c\u901a\u4fe1\u91cf\u4ece1277MB\u964d\u81f332MB/\u8f6e\uff0c\u4e0e\u6807\u51c6\u8054\u90a6\u5b66\u4e60\u6027\u80fd\u76f8\u5f53(p=0.32)\uff0c\u6ee1\u8db3\u03b5\u22641.0\u7684\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u3002", "conclusion": "MedHE\u6846\u67b6\u5177\u6709HIPAA\u5408\u89c4\u6027\uff0c\u53ef\u6269\u5c55\u81f3100+\u673a\u6784\uff0c\u4e3a\u73b0\u5b9e\u533b\u7597\u90e8\u7f72\u63d0\u4f9b\u5b9e\u7528\u53ef\u884c\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09032", "categories": ["cs.AI", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09032", "abs": "https://arxiv.org/abs/2511.09032", "authors": ["Dingji Wang", "You Lu", "Bihuan Chen", "Shuo Hao", "Haowen Jiang", "Yifan Tian", "Xin Peng"], "title": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs", "comment": "The paper has been accepted by the 40th IEEE/ACM International Conference on Automated Software Engineering, ASE 2025", "summary": "End-to-end autonomous driving systems (ADSs), with their strong capabilities in environmental perception and generalizable driving decisions, are attracting growing attention from both academia and industry. However, once deployed on public roads, ADSs are inevitably exposed to diverse driving hazards that may compromise safety and degrade system performance. This raises a strong demand for resilience of ADSs, particularly the capability to continuously monitor driving hazards and adaptively respond to potential safety violations, which is crucial for maintaining robust driving behaviors in complex driving scenarios.\n  To bridge this gap, we propose a runtime resilience-oriented framework, Argus, to mitigate the driving hazards, thus preventing potential safety violations and improving the driving performance of an ADS. Argus continuously monitors the trajectories generated by the ADS for potential hazards and, whenever the EGO vehicle is deemed unsafe, seamlessly takes control through a hazard mitigator. We integrate Argus with three state-of-the-art end-to-end ADSs, i.e., TCP, UniAD and VAD. Our evaluation has demonstrated that Argus effectively and efficiently enhances the resilience of ADSs, improving the driving score of the ADS by up to 150.30% on average, and preventing up to 64.38% of the violations, with little additional time overhead.", "AI": {"tldr": "\u63d0\u51faArgus\u6846\u67b6\uff0c\u901a\u8fc7\u6301\u7eed\u76d1\u63a7\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u8f68\u8ff9\u5e76\u9002\u65f6\u63a5\u7ba1\u63a7\u5236\u6765\u7f13\u89e3\u9a7e\u9a76\u5371\u9669\uff0c\u63d0\u5347\u7cfb\u7edf\u97e7\u6027\u3002", "motivation": "\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u90e8\u7f72\u65f6\u9762\u4e34\u5404\u79cd\u9a7e\u9a76\u5371\u9669\uff0c\u9700\u8981\u5177\u5907\u6301\u7eed\u76d1\u63a7\u548c\u81ea\u9002\u5e94\u54cd\u5e94\u7684\u97e7\u6027\u80fd\u529b\u6765\u786e\u4fdd\u5b89\u5168\u3002", "method": "\u8bbe\u8ba1\u8fd0\u884c\u65f6\u97e7\u6027\u5bfc\u5411\u6846\u67b6Argus\uff0c\u5305\u542b\u8f68\u8ff9\u76d1\u63a7\u548c\u5371\u9669\u7f13\u89e3\u5668\uff0c\u5f53\u68c0\u6d4b\u5230\u4e0d\u5b89\u5168\u72b6\u6001\u65f6\u65e0\u7f1d\u63a5\u7ba1\u63a7\u5236\u3002", "result": "\u4e0eTCP\u3001UniAD\u548cVAD\u4e09\u4e2a\u5148\u8fdb\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u96c6\u6210\u6d4b\u8bd5\uff0c\u9a7e\u9a76\u8bc4\u5206\u5e73\u5747\u63d0\u5347150.30%\uff0c\u8fdd\u89c4\u9884\u9632\u7387\u8fbe64.38%\uff0c\u65f6\u95f4\u5f00\u9500\u5c0f\u3002", "conclusion": "Argus\u80fd\u6709\u6548\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u97e7\u6027\uff0c\u663e\u8457\u6539\u5584\u9a7e\u9a76\u6027\u80fd\u5e76\u9884\u9632\u5b89\u5168\u8fdd\u89c4\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.09051", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.09051", "abs": "https://arxiv.org/abs/2511.09051", "authors": ["Parsa Hedayatnia", "Tina Tavakkoli", "Hadi Amini", "Mohammad Allahbakhsh", "Haleh Amintoosi"], "title": "Attack-Centric by Design: A Program-Structure Taxonomy of Smart Contract Vulnerabilities", "comment": "42 pages, 1 figure, 8 root-cause families", "summary": "Smart contracts concentrate high value assets and complex logic in small, immutable programs, where even minor bugs can cause major losses. Existing taxonomies and tools remain fragmented, organized around symptoms such as reentrancy rather than structural causes. This paper introduces an attack-centric, program-structure taxonomy that unifies Solidity vulnerabilities into eight root-cause families covering control flow, external calls, state integrity, arithmetic safety, environmental dependencies, access control, input validation, and cross-domain protocol assumptions. Each family is illustrated through concise Solidity examples, exploit mechanics, and mitigations, and linked to the detection signals observable by static, dynamic, and learning-based tools. We further cross-map legacy datasets (SmartBugs, SolidiFI) to this taxonomy to reveal label drift and coverage gaps. The taxonomy provides a consistent vocabulary and practical checklist that enable more interpretable detection, reproducible audits, and structured security education for both researchers and practitioners.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u653b\u51fb\u7684Solidity\u6f0f\u6d1e\u5206\u7c7b\u6cd5\uff0c\u5c06\u6f0f\u6d1e\u7edf\u4e00\u4e3a8\u4e2a\u6839\u672c\u539f\u56e0\u5bb6\u65cf\uff0c\u5305\u62ec\u63a7\u5236\u6d41\u3001\u5916\u90e8\u8c03\u7528\u3001\u72b6\u6001\u5b8c\u6574\u6027\u7b49\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e00\u81f4\u7684\u8bcd\u6c47\u8868\u548c\u5b9e\u7528\u68c0\u67e5\u6e05\u5355\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u5c06\u9ad8\u4ef7\u503c\u8d44\u4ea7\u548c\u590d\u6742\u903b\u8f91\u96c6\u4e2d\u5728\u5c0f\u578b\u4e0d\u53ef\u53d8\u7a0b\u5e8f\u4e2d\uff0c\u5373\u4f7f\u662f\u5c0f\u9519\u8bef\u4e5f\u53ef\u80fd\u5bfc\u81f4\u91cd\u5927\u635f\u5931\u3002\u73b0\u6709\u7684\u5206\u7c7b\u6cd5\u548c\u5de5\u5177\u4ecd\u7136\u5206\u6563\uff0c\u56f4\u7ed5\u75c7\u72b6\u800c\u975e\u7ed3\u6784\u539f\u56e0\u7ec4\u7ec7\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u653b\u51fb\u7684\u7a0b\u5e8f\u7ed3\u6784\u5206\u7c7b\u6cd5\uff0c\u5c06Solidity\u6f0f\u6d1e\u7edf\u4e00\u4e3a8\u4e2a\u6839\u672c\u539f\u56e0\u5bb6\u65cf\uff0c\u6bcf\u4e2a\u5bb6\u65cf\u901a\u8fc7\u7b80\u6d01\u7684Solidity\u793a\u4f8b\u3001\u5229\u7528\u673a\u5236\u548c\u7f13\u89e3\u63aa\u65bd\u8fdb\u884c\u8bf4\u660e\uff0c\u5e76\u4e0e\u9759\u6001\u3001\u52a8\u6001\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u5de5\u5177\u7684\u68c0\u6d4b\u4fe1\u53f7\u76f8\u5173\u8054\u3002", "result": "\u5206\u7c7b\u6cd5\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u8bcd\u6c47\u8868\u548c\u5b9e\u7528\u68c0\u67e5\u6e05\u5355\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u53ef\u89e3\u91ca\u7684\u68c0\u6d4b\u3001\u53ef\u91cd\u73b0\u7684\u5ba1\u8ba1\u548c\u7ed3\u6784\u5316\u7684\u5b89\u5168\u6559\u80b2\u3002\u8fdb\u4e00\u6b65\u5c06\u4f20\u7edf\u6570\u636e\u96c6\u6620\u5c04\u5230\u8be5\u5206\u7c7b\u6cd5\uff0c\u63ed\u793a\u4e86\u6807\u7b7e\u6f02\u79fb\u548c\u8986\u76d6\u8303\u56f4\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u4e00\u81f4\u7684\u8bcd\u6c47\u8868\u548c\u5b9e\u7528\u68c0\u67e5\u6e05\u5355\uff0c\u5b9e\u73b0\u4e86\u66f4\u53ef\u89e3\u91ca\u7684\u68c0\u6d4b\u3001\u53ef\u91cd\u73b0\u7684\u5ba1\u8ba1\u548c\u7ed3\u6784\u5316\u7684\u5b89\u5168\u6559\u80b2\u3002"}}
{"id": "2511.08934", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08934", "abs": "https://arxiv.org/abs/2511.08934", "authors": ["Di Liao", "Ruijia Liang", "Ziyi Ye"], "title": "A Research on Business Process Optimisation Model Integrating AI and Big Data Analytics", "comment": null, "summary": "With the deepening of digital transformation, business process optimisation has become the key to improve the competitiveness of enterprises. This study constructs a business process optimisation model integrating artificial intelligence and big data to achieve intelligent management of the whole life cycle of processes. The model adopts a three-layer architecture incorporating data processing, AI algorithms, and business logic to enable real-time process monitoring and optimization. Through distributed computing and deep learning techniques, the system can handle complex business scenarios while maintaining high performance and reliability. Experimental validation across multiple enterprise scenarios shows that the model shortens process processing time by 42%, improves resource utilisation by 28%, and reduces operating costs by 35%. The system maintained 99.9% availability under high concurrent loads. The research results have important theoretical and practical value for promoting the digital transformation of enterprises, and provide new ideas for improving the operational efficiency of enterprises.", "AI": {"tldr": "\u672c\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u878d\u5408\u4eba\u5de5\u667a\u80fd\u4e0e\u5927\u6570\u636e\u7684\u4e1a\u52a1\u6d41\u7a0b\u4f18\u5316\u6a21\u578b\uff0c\u91c7\u7528\u4e09\u5c42\u67b6\u6784\u5b9e\u73b0\u6d41\u7a0b\u5168\u751f\u547d\u5468\u671f\u7684\u667a\u80fd\u5316\u7ba1\u7406\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u8457\u63d0\u5347\u4e86\u4f01\u4e1a\u8fd0\u8425\u6548\u7387\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u5316\u8f6c\u578b\u7684\u6df1\u5165\uff0c\u4e1a\u52a1\u6d41\u7a0b\u4f18\u5316\u6210\u4e3a\u63d0\u5347\u4f01\u4e1a\u7ade\u4e89\u529b\u7684\u5173\u952e\uff0c\u9700\u8981\u6784\u5efa\u667a\u80fd\u5316\u7684\u6d41\u7a0b\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5305\u542b\u6570\u636e\u5904\u7406\u3001AI\u7b97\u6cd5\u548c\u4e1a\u52a1\u903b\u8f91\u7684\u4e09\u5c42\u67b6\u6784\u6a21\u578b\uff0c\u7ed3\u5408\u5206\u5e03\u5f0f\u8ba1\u7b97\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u5b9e\u73b0\u5b9e\u65f6\u6d41\u7a0b\u76d1\u63a7\u548c\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0c\u6a21\u578b\u7f29\u77ed\u6d41\u7a0b\u5904\u7406\u65f6\u95f442%\uff0c\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u738728%\uff0c\u964d\u4f4e\u8fd0\u8425\u6210\u672c35%\uff0c\u5728\u9ad8\u5e76\u53d1\u8d1f\u8f7d\u4e0b\u4fdd\u630199.9%\u7684\u53ef\u7528\u6027\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u5bf9\u4f01\u4e1a\u6570\u5b57\u5316\u8f6c\u578b\u5177\u6709\u91cd\u8981\u7406\u8bba\u4ef7\u503c\u548c\u5b9e\u8df5\u610f\u4e49\uff0c\u4e3a\u63d0\u5347\u4f01\u4e1a\u8fd0\u8425\u6548\u7387\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.09134", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09134", "abs": "https://arxiv.org/abs/2511.09134", "authors": ["Zexu Wang", "Jiachi Chen", "Zewei Lin", "Wenqing Chen", "Kaiwen Ning", "Jianxing Yu", "Yuming Feng", "Yu Zhang", "Weizhe Zhang", "Zibin Zheng"], "title": "One Signature, Multiple Payments: Demystifying and Detecting Signature Replay Vulnerabilities in Smart Contracts", "comment": "Accepted at ICSE2026", "summary": "Smart contracts have significantly advanced blockchain technology, and digital signatures are crucial for reliable verification of contract authority. Through signature verification, smart contracts can ensure that signers possess the required permissions, thus enhancing security and scalability. However, lacking checks on signature usage conditions can lead to repeated verifications, increasing the risk of permission abuse and threatening contract assets. We define this issue as the Signature Replay Vulnerability (SRV). In this paper, we conducted the first empirical study to investigate the causes and characteristics of the SRVs. From 1,419 audit reports across 37 blockchain security companies, we identified 108 with detailed SRV descriptions and classified five types of SRVs. To detect these vulnerabilities automatically, we designed LASiR, which utilizes the general semantic understanding ability of Large Language Models (LLMs) to assist in the static taint analysis of the signature state and identify the signature reuse behavior. It also employs path reachability verification via symbolic execution to ensure effective and reliable detection. To evaluate the performance of LASiR, we conducted large-scale experiments on 15,383 contracts involving signature verification, selected from the initial dataset of 918,964 contracts across four blockchains: Ethereum, Binance Smart Chain, Polygon, and Arbitrum. The results indicate that SRVs are widespread, with affected contracts holding $4.76 million in active assets. Among these, 19.63% of contracts that use signatures on Ethereum contain SRVs. Furthermore, manual verification demonstrates that LASiR achieves an F1-score of 87.90% for detection. Ablation studies and comparative experiments reveal that the semantic information provided by LLMs aids static taint analysis, significantly enhancing LASiR's detection performance.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u667a\u80fd\u5408\u7ea6\u4e2d\u7684\u7b7e\u540d\u91cd\u653e\u6f0f\u6d1e(SRV)\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u68c0\u6d4b\u5de5\u5177LASiR\uff0c\u572815,383\u4e2a\u5408\u7ea6\u4e2d\u53d1\u73b0SRV\u666e\u904d\u5b58\u5728\uff0c\u6d89\u53ca476\u4e07\u7f8e\u5143\u6d3b\u8dc3\u8d44\u4ea7\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u4e2d\u6570\u5b57\u7b7e\u540d\u9a8c\u8bc1\u7f3a\u4e4f\u4f7f\u7528\u6761\u4ef6\u68c0\u67e5\u4f1a\u5bfc\u81f4\u91cd\u590d\u9a8c\u8bc1\uff0c\u589e\u52a0\u6743\u9650\u6ee5\u7528\u98ce\u9669\uff0c\u5a01\u80c1\u5408\u7ea6\u8d44\u4ea7\u5b89\u5168\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u7b7e\u540d\u91cd\u653e\u6f0f\u6d1e\u7684\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u8bbe\u8ba1LASiR\u5de5\u5177\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u8f85\u52a9\u9759\u6001\u6c61\u70b9\u5206\u6790\uff0c\u8bc6\u522b\u7b7e\u540d\u91cd\u7528\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u7b26\u53f7\u6267\u884c\u8fdb\u884c\u8def\u5f84\u53ef\u8fbe\u6027\u9a8c\u8bc1\u3002", "result": "\u4ece37\u5bb6\u533a\u5757\u94fe\u5b89\u5168\u516c\u53f8\u76841,419\u4efd\u5ba1\u8ba1\u62a5\u544a\u4e2d\u8bc6\u522b\u51fa108\u4e2aSRV\u6848\u4f8b\uff0c\u5206\u7c7b\u4e3a5\u79cd\u7c7b\u578b\u3002\u572815,383\u4e2a\u5408\u7ea6\u4e2d\u53d1\u73b0SRV\u666e\u904d\u5b58\u5728\uff0c\u4ee5\u592a\u574a\u4e0a19.63%\u4f7f\u7528\u7b7e\u540d\u7684\u5408\u7ea6\u5b58\u5728SRV\uff0c\u6d89\u53ca476\u4e07\u7f8e\u5143\u8d44\u4ea7\u3002LASiR\u68c0\u6d4bF1\u5206\u6570\u8fbe87.90%\u3002", "conclusion": "\u7b7e\u540d\u91cd\u653e\u6f0f\u6d1e\u5728\u667a\u80fd\u5408\u7ea6\u4e2d\u666e\u904d\u5b58\u5728\u4e14\u5371\u5bb3\u4e25\u91cd\uff0cLASiR\u7ed3\u5408LLM\u8bed\u4e49\u7406\u89e3\u80fd\u6709\u6548\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u667a\u80fd\u5408\u7ea6\u5b89\u5168\u63d0\u4f9b\u91cd\u8981\u4fdd\u969c\u3002"}}
{"id": "2511.08947", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08947", "abs": "https://arxiv.org/abs/2511.08947", "authors": ["Xiaohan Zhang", "Tian Gao", "Mingyue Cheng", "Bokai Pan", "Ze Guo", "Yaguo Liu", "Xiaoyu Tao"], "title": "AlphaCast: A Human Wisdom-LLM Intelligence Co-Reasoning Framework for Interactive Time Series Forecasting", "comment": null, "summary": "Time series forecasting plays a critical role in high-stakes domains such as energy, healthcare, and climate. Although recent advances have improved accuracy, most approaches still treat forecasting as a static one-time mapping task, lacking the interaction, reasoning, and adaptability of human experts. This gap limits their usefulness in complex real-world environments. To address this, we propose AlphaCast, a human wisdom-large language model (LLM) intelligence co-reasoning framework that redefines forecasting as an interactive process. The key idea is to enable step-by-step collaboration between human wisdom and LLM intelligence to jointly prepare, generate, and verify forecasts. The framework consists of two stages: (1) automated prediction preparation, where AlphaCast builds a multi-source cognitive foundation comprising a feature set that captures key statistics and time patterns, a domain knowledge base distilled from corpora and historical series, a contextual repository that stores rich information for each time window, and a case base that retrieves optimal strategies via pattern clustering and matching; and (2) generative reasoning and reflective optimization, where AlphaCast integrates statistical temporal features, prior knowledge, contextual information, and forecasting strategies, triggering a meta-reasoning loop for continuous self-correction and strategy refinement. Extensive experiments on short- and long-term datasets show that AlphaCast consistently outperforms state-of-the-art baselines in predictive accuracy. Code is available at this repository: https://github.com/SkyeGT/AlphaCast_Official .", "AI": {"tldr": "AlphaCast\u662f\u4e00\u4e2a\u4eba\u7c7b\u667a\u6167\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u534f\u540c\u63a8\u7406\u7684\u65f6\u5e8f\u9884\u6d4b\u6846\u67b6\uff0c\u5c06\u9884\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4ea4\u4e92\u8fc7\u7a0b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u534f\u4f5c\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u9884\u6d4b\u3002", "motivation": "\u5f53\u524d\u65f6\u5e8f\u9884\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u4eba\u7c7b\u4e13\u5bb6\u7684\u4ea4\u4e92\u3001\u63a8\u7406\u548c\u9002\u5e94\u6027\uff0c\u9650\u5236\u4e86\u5728\u590d\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u81ea\u52a8\u9884\u6d4b\u51c6\u5907\uff0c\u6784\u5efa\u591a\u6e90\u8ba4\u77e5\u57fa\u7840\uff1b2\uff09\u751f\u6210\u63a8\u7406\u548c\u53cd\u601d\u4f18\u5316\uff0c\u89e6\u53d1\u5143\u63a8\u7406\u5faa\u73af\u8fdb\u884c\u6301\u7eed\u81ea\u6821\u6b63\u3002", "result": "\u5728\u77ed\u671f\u548c\u957f\u671f\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAlphaCast\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "AlphaCast\u901a\u8fc7\u4eba\u7c7b\u667a\u6167\u4e0eLLM\u667a\u80fd\u7684\u534f\u540c\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u5e8f\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.09088", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09088", "abs": "https://arxiv.org/abs/2511.09088", "authors": ["Taifeng Liu", "Xinjing Liu", "Liangqiu Dong", "Yang Liu", "Yilong Yang", "Zhuo Ma"], "title": "Improving Sustainability of Adversarial Examples in Class-Incremental Learning", "comment": "This paper is accepted to AAAI 2026", "summary": "Current adversarial examples (AEs) are typically designed for static models. However, with the wide application of Class-Incremental Learning (CIL), models are no longer static and need to be updated with new data distributed and labeled differently from the old ones. As a result, existing AEs often fail after CIL updates due to significant domain drift. In this paper, we propose SAE to enhance the sustainability of AEs against CIL. The core idea of SAE is to enhance the robustness of AE semantics against domain drift by making them more similar to the target class while distinguishing them from all other classes. Achieving this is challenging, as relying solely on the initial CIL model to optimize AE semantics often leads to overfitting. To resolve the problem, we propose a Semantic Correction Module. This module encourages the AE semantics to be generalized, based on a visual-language model capable of producing universal semantics. Additionally, it incorporates the CIL model to correct the optimization direction of the AE semantics, guiding them closer to the target class. To further reduce fluctuations in AE semantics, we propose a Filtering-and-Augmentation Module, which first identifies non-target examples with target-class semantics in the latent space and then augments them to foster more stable semantics. Comprehensive experiments demonstrate that SAE outperforms baselines by an average of 31.28% when updated with a 9-fold increase in the number of classes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSAE\u65b9\u6cd5\uff0c\u65e8\u5728\u589e\u5f3a\u5bf9\u6297\u6837\u672c\u5728\u7c7b\u589e\u91cf\u5b66\u4e60(CIL)\u66f4\u65b0\u540e\u7684\u53ef\u6301\u7eed\u6027\uff0c\u901a\u8fc7\u8bed\u4e49\u4fee\u6b63\u548c\u8fc7\u6ee4\u589e\u5f3a\u6a21\u5757\u6765\u5e94\u5bf9\u9886\u57df\u6f02\u79fb\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5bf9\u6297\u6837\u672c\u901a\u5e38\u9488\u5bf9\u9759\u6001\u6a21\u578b\u8bbe\u8ba1\uff0c\u4f46\u5728\u7c7b\u589e\u91cf\u5b66\u4e60\u573a\u666f\u4e0b\uff0c\u6a21\u578b\u4f1a\u4e0d\u65ad\u66f4\u65b0\uff0c\u5bfc\u81f4\u73b0\u6709\u5bf9\u6297\u6837\u672c\u56e0\u663e\u8457\u7684\u9886\u57df\u6f02\u79fb\u800c\u5931\u6548\u3002", "method": "\u63d0\u51faSAE\u65b9\u6cd5\uff0c\u5305\u542b\u8bed\u4e49\u4fee\u6b63\u6a21\u5757\u548c\u8fc7\u6ee4\u589e\u5f3a\u6a21\u5757\u3002\u8bed\u4e49\u4fee\u6b63\u6a21\u5757\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u901a\u7528\u8bed\u4e49\uff0c\u5e76\u7ed3\u5408CIL\u6a21\u578b\u4fee\u6b63\u5bf9\u6297\u6837\u672c\u8bed\u4e49\u4f18\u5316\u65b9\u5411\uff1b\u8fc7\u6ee4\u589e\u5f3a\u6a21\u5757\u8bc6\u522b\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5177\u6709\u76ee\u6807\u7c7b\u8bed\u4e49\u7684\u975e\u76ee\u6807\u6837\u672c\u5e76\u8fdb\u884c\u589e\u5f3a\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cSAE\u5728\u7c7b\u522b\u6570\u91cf\u589e\u52a09\u500d\u7684\u60c5\u51b5\u4e0b\uff0c\u5e73\u5747\u6027\u80fd\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa31.28%\u3002", "conclusion": "SAE\u80fd\u591f\u6709\u6548\u589e\u5f3a\u5bf9\u6297\u6837\u672c\u5728\u7c7b\u589e\u91cf\u5b66\u4e60\u66f4\u65b0\u540e\u7684\u53ef\u6301\u7eed\u6027\uff0c\u901a\u8fc7\u8bed\u4e49\u6cdb\u5316\u548c\u7a33\u5b9a\u6027\u63d0\u5347\u6765\u5e94\u5bf9\u9886\u57df\u6f02\u79fb\u6311\u6218\u3002"}}
{"id": "2511.09005", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.09005", "abs": "https://arxiv.org/abs/2511.09005", "authors": ["Alvin Chauhan"], "title": "AI Founding Fathers: A Case Study of GIS Search in Multi-Agent Pipelines", "comment": "9 pages, 3 figures. Code and data available at https://github.com/alvco/Founding_Fathers_AI", "summary": "Although Large Language Models (LLMs) show exceptional fluency, efforts persist to extract stronger reasoning capabilities from them. Drawing on search-based interpretations of LLM computation, this paper advances a systematic framework for understanding LLM reasoning and optimization. Namely, that enhancing reasoning is best achieved by structuring a multi-agent pipeline to ensure a traversal of the search space in a gradual, incremental, and sequential (GIS) manner. Stated succinctly, high-quality reasoning is a controlled, incremental search. To test this framework, we investigate the efficacy of recursive refinement (RR)--an iterative process of self-criticism, adversarial stress-testing, and integrating critical feedback--as a practical method for implementing GIS search. We designed an experiment comparing a simple, linear pipeline against a complex, explicitly structured pipeline leveraging a recursive refinement layer. The multi-agent models were constructed to reflect the historical personas of three US Founding Fathers (Hamilton, Jefferson, and Madison) using RAG-powered corpora and were prompted to generate responses to three contemporary political issues. Model performance was evaluated using a two-tiered approach: a quantitative score from an LLM arbiter agent and qualitative human judgment. Our results revealed that the complex model consistently outperformed the simple model across all nine test cases with an average arbiter-outputted score of 88.3 versus 71.7. The complex model's arguments were superior in analytical depth, structural nuance, and strategic framing. We conclude that recursive refinement is a robust architectural feature for enhancing LLM reasoning via GIS search.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u6765\u5b9e\u73b0\u6e10\u8fdb\u5f0f\u3001\u589e\u91cf\u5f0f\u548c\u987a\u5e8f\u5f0f\u7684\u641c\u7d22\u7a7a\u95f4\u904d\u5386\uff0c\u4ece\u800c\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u9012\u5f52\u7cbe\u70bc\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6d41\u7545\u6027\uff0c\u4f46\u7814\u7a76\u8005\u4ecd\u5728\u52aa\u529b\u63d0\u5347\u5176\u63a8\u7406\u80fd\u529b\u3002\u672c\u6587\u57fa\u4e8e\u641c\u7d22\u5bfc\u5411\u7684LLM\u8ba1\u7b97\u89e3\u91ca\uff0c\u65e8\u5728\u7cfb\u7edf\u5316\u7406\u89e3LLM\u63a8\u7406\u548c\u4f18\u5316\u3002", "method": "\u91c7\u7528\u9012\u5f52\u7cbe\u70bc\u65b9\u6cd5\uff0c\u5305\u62ec\u81ea\u6211\u6279\u8bc4\u3001\u5bf9\u6297\u6027\u538b\u529b\u6d4b\u8bd5\u548c\u5173\u952e\u53cd\u9988\u6574\u5408\u7684\u8fed\u4ee3\u8fc7\u7a0b\u3002\u8bbe\u8ba1\u4e86\u7b80\u5355\u7ebf\u6027\u7ba1\u9053\u4e0e\u590d\u6742\u7ed3\u6784\u5316\u7ba1\u9053\u7684\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u4f7f\u7528\u4e09\u4f4d\u7f8e\u56fd\u5f00\u56fd\u5143\u52cb\u7684\u5386\u53f2\u4eba\u7269\u89d2\u8272\uff0c\u901a\u8fc7RAG\u589e\u5f3a\u8bed\u6599\u5e93\u751f\u6210\u5bf9\u5f53\u4ee3\u653f\u6cbb\u8bae\u9898\u7684\u56de\u5e94\u3002", "result": "\u590d\u6742\u6a21\u578b\u5728\u6240\u6709\u4e5d\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u5747\u4f18\u4e8e\u7b80\u5355\u6a21\u578b\uff0c\u5e73\u5747\u4ef2\u88c1\u5206\u6570\u4e3a88.3\u5bf971.7\u3002\u590d\u6742\u6a21\u578b\u7684\u8bba\u8bc1\u5728\u5206\u6790\u6df1\u5ea6\u3001\u7ed3\u6784\u7ec6\u5fae\u5dee\u522b\u548c\u6218\u7565\u6846\u67b6\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u9012\u5f52\u7cbe\u70bc\u662f\u901a\u8fc7GIS\u641c\u7d22\u589e\u5f3aLLM\u63a8\u7406\u7684\u5f3a\u5927\u67b6\u6784\u7279\u5f81\uff0c\u9ad8\u8d28\u91cf\u63a8\u7406\u662f\u53d7\u63a7\u7684\u589e\u91cf\u641c\u7d22\u8fc7\u7a0b\u3002"}}
{"id": "2511.09252", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09252", "abs": "https://arxiv.org/abs/2511.09252", "authors": ["Jian Wang", "Hong Shen", "Chan-Tong Lam"], "title": "Unveiling Hidden Threats: Using Fractal Triggers to Boost Stealthiness of Distributed Backdoor Attacks in Federated Learning", "comment": "10 pages, 1 figures, conference", "summary": "Traditional distributed backdoor attacks (DBA) in federated learning improve stealthiness by decomposing global triggers into sub-triggers, which however requires more poisoned data to maintian the attck strength and hence increases the exposure risk. To overcome this defect, This paper proposes a novel method, namely Fractal-Triggerred Distributed Backdoor Attack (FTDBA), which leverages the self-similarity of fractals to enhance the feature strength of sub-triggers and hence significantly reduce the required poisoning volume for the same attack strength. To address the detectability of fractal structures in the frequency and gradient domains, we introduce a dynamic angular perturbation mechanism that adaptively adjusts perturbation intensity across the training phases to balance efficiency and stealthiness. Experiments show that FTDBA achieves a 92.3\\% attack success rate with only 62.4\\% of the poisoning volume required by traditional DBA methods, while reducing the detection rate by 22.8\\% and KL divergence by 41.2\\%. This study presents a low-exposure, high-efficiency paradigm for federated backdoor attacks and expands the application of fractal features in adversarial sample generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5f62\u7279\u5f81\u7684\u5206\u5e03\u5f0f\u540e\u95e8\u653b\u51fb\u65b9\u6cd5FTDBA\uff0c\u5229\u7528\u5206\u5f62\u81ea\u76f8\u4f3c\u6027\u589e\u5f3a\u5b50\u89e6\u53d1\u5668\u7684\u7279\u5f81\u5f3a\u5ea6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8fbe\u5230\u76f8\u540c\u653b\u51fb\u5f3a\u5ea6\u6240\u9700\u7684\u6295\u6bd2\u6570\u636e\u91cf\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u89d2\u5ea6\u6270\u52a8\u673a\u5236\u5e73\u8861\u653b\u51fb\u6548\u7387\u548c\u9690\u853d\u6027\u3002", "motivation": "\u4f20\u7edf\u5206\u5e03\u5f0f\u540e\u95e8\u653b\u51fb\u901a\u8fc7\u5c06\u5168\u5c40\u89e6\u53d1\u5668\u5206\u89e3\u4e3a\u5b50\u89e6\u53d1\u5668\u6765\u63d0\u9ad8\u9690\u853d\u6027\uff0c\u4f46\u8fd9\u9700\u8981\u66f4\u591a\u6295\u6bd2\u6570\u636e\u6765\u7ef4\u6301\u653b\u51fb\u5f3a\u5ea6\uff0c\u589e\u52a0\u4e86\u66b4\u9732\u98ce\u9669\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u7f3a\u9677\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u4f4e\u66b4\u9732\u3001\u9ad8\u6548\u7387\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u63d0\u51faFTDBA\u65b9\u6cd5\uff0c\u5229\u7528\u5206\u5f62\u7684\u81ea\u76f8\u4f3c\u6027\u589e\u5f3a\u5b50\u89e6\u53d1\u5668\u7684\u7279\u5f81\u5f3a\u5ea6\uff1b\u5f15\u5165\u52a8\u6001\u89d2\u5ea6\u6270\u52a8\u673a\u5236\uff0c\u5728\u8bad\u7ec3\u9636\u6bb5\u81ea\u9002\u5e94\u8c03\u6574\u6270\u52a8\u5f3a\u5ea6\u4ee5\u5e73\u8861\u6548\u7387\u548c\u9690\u853d\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFTDBA\u4ec5\u9700\u4f20\u7edfDBA\u65b9\u6cd562.4%\u7684\u6295\u6bd2\u6570\u636e\u91cf\u5c31\u80fd\u8fbe\u523092.3%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u68c0\u6d4b\u7387\u964d\u4f4e22.8%\uff0cKL\u6563\u5ea6\u964d\u4f4e41.2%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8054\u90a6\u540e\u95e8\u653b\u51fb\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u66b4\u9732\u3001\u9ad8\u6548\u7387\u7684\u8303\u5f0f\uff0c\u5e76\u6269\u5c55\u4e86\u5206\u5f62\u7279\u5f81\u5728\u5bf9\u6297\u6837\u672c\u751f\u6210\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2511.09044", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09044", "abs": "https://arxiv.org/abs/2511.09044", "authors": ["Yousef Emami", "Radha Reddy", "Azadeh Pourkabirian", "Miguel Gutierrez Gaitan"], "title": "Advancing Autonomous Emergency Response Systems: A Generative AI Perspective", "comment": "8 pages, 3 figures, 2 tables", "summary": "Autonomous Vehicles (AVs) are poised to revolutionize emergency services by enabling faster, safer, and more efficient responses. This transformation is driven by advances in Artificial Intelligence (AI), particularly Reinforcement Learning (RL), which allows AVs to navigate complex environments and make critical decisions in real time. However, conventional RL paradigms often suffer from poor sample efficiency and lack adaptability in dynamic emergency scenarios. This paper reviews next-generation AV optimization strategies to address these limitations. We analyze the shift from conventional RL to Diffusion Model (DM)-augmented RL, which enhances policy robustness through synthetic data generation, albeit with increased computational cost. Additionally, we explore the emerging paradigm of Large Language Model (LLM)-assisted In-Context Learning (ICL), which offers a lightweight and interpretable alternative by enabling rapid, on-the-fly adaptation without retraining. By reviewing the state of the art in AV intelligence, DM-augmented RL, and LLM-assisted ICL, this paper provides a critical framework for understanding the next generation of autonomous emergency response systems from a Generative AI perspective.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u4e0b\u4e00\u4ee3\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u5e94\u6025\u670d\u52a1\u4e2d\u7684\u4f18\u5316\u7b56\u7565\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u4ece\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5411\u6269\u6563\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u8f6c\u53d8\uff0c\u4e3a\u7406\u89e3\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u81ea\u4e3b\u5e94\u6025\u54cd\u5e94\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6846\u67b6\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6709\u671b\u901a\u8fc7\u66f4\u5feb\u3001\u66f4\u5b89\u5168\u3001\u66f4\u9ad8\u6548\u7684\u54cd\u5e94\u6765\u9769\u65b0\u5e94\u6025\u670d\u52a1\uff0c\u4f46\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u52a8\u6001\u5e94\u6025\u573a\u666f\u4e2d\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u548c\u9002\u5e94\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u4f18\u5316\u7b56\u7565\u6765\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\u3002", "method": "\u5206\u6790\u4e86\u4ece\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5230\u6269\u6563\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u7684\u8f6c\u53d8\uff0c\u6269\u6563\u6a21\u578b\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u589e\u5f3a\u7b56\u7565\u9c81\u68d2\u6027\uff1b\u540c\u65f6\u63a2\u7d22\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u65b0\u8303\u5f0f\uff0c\u652f\u6301\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u5feb\u901f\u73b0\u573a\u9002\u5e94\u3002", "result": "\u6269\u6563\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u63d0\u9ad8\u4e86\u7b56\u7565\u9c81\u68d2\u6027\u4f46\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\uff1b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u4e14\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u5b9e\u73b0\u5feb\u901f\u9002\u5e94\u3002", "conclusion": "\u901a\u8fc7\u7efc\u8ff0\u81ea\u52a8\u9a7e\u9a76\u667a\u80fd\u3001\u6269\u6563\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u6700\u65b0\u6280\u672f\uff0c\u4e3a\u7406\u89e3\u4e0b\u4e00\u4ee3\u81ea\u4e3b\u5e94\u6025\u54cd\u5e94\u7cfb\u7edf\u4ece\u751f\u6210\u5f0fAI\u89d2\u5ea6\u63d0\u4f9b\u4e86\u5173\u952e\u6846\u67b6\u3002"}}
{"id": "2511.09351", "categories": ["cs.CR", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.09351", "abs": "https://arxiv.org/abs/2511.09351", "authors": ["Min Liang", "Ruihao Gao", "Jiali Wu"], "title": "Quantum Meet-in-the-Middle Attacks on Key-Length Extension Constructions", "comment": "23 pages, 4 figures", "summary": "Key-length extension (KLE) techniques provide a general approach to enhancing the security of block ciphers by using longer keys. There are mainly two classes of KLE techniques, cascade encryption and XOR-cascade encryption. This paper presents several quantum meet-in-the-middle (MITM) attacks against two specific KLE constructions.\n  For the two-key triple encryption (2kTE), we propose two quantum MITM attacks under the Q2 model. The first attack, leveraging the quantum claw-finding (QCF) algorithm, achieves a time complexity of $O(2^{2\u03ba/3})$ with $O(2^{2\u03ba/3})$ quantum random access memory (QRAM). The second attack, based on Grover's algorithm, achieves a time complexity of $O(2^{\u03ba/2})$ with $O(2^\u03ba)$ QRAM. The latter complexity is nearly identical to Grover-based brute-force attack on the underlying block cipher, indicating that 2kTE does not enhance security under the Q2 model when sufficient QRAM resources are available.\n  For the 3XOR-cascade encryption (3XCE), we propose a quantum MITM attack applicable to the Q1 model. This attack requires no QRAM and has a time complexity of $O(2^{(\u03ba+n)/2})$ ($\u03ba$ and $n$ are the key length and block length of the underlying block cipher, respectively.), achieving a quadratic speedup over classical MITM attack.\n  Furthermore, we extend the quantum MITM attack to quantum sieve-in-the-middle (SITM) attack, which is applicable for more constructions. We present a general quantum SITM framework for the construction $ELE=E^2\\circ L\\circ E^1$ and provide specific attack schemes for three different forms of the middle layer $L$. The quantum SITM attack technique can be further applied to a broader range of quantum cryptanalysis scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u4e24\u79cd\u5bc6\u94a5\u957f\u5ea6\u6269\u5c55\u6784\u9020\u7684\u91cf\u5b50\u4e2d\u95f4\u76f8\u9047\u653b\u51fb\uff1a\u5bf92kTE\u7684\u4e24\u79cdQ2\u6a21\u578b\u653b\u51fb\uff08\u57fa\u4e8e\u91cf\u5b50\u722a\u67e5\u627e\u548cGrover\u7b97\u6cd5\uff09\uff0c\u4ee5\u53ca\u5bf93XCE\u7684Q1\u6a21\u578b\u653b\u51fb\u3002\u8fd8\u6269\u5c55\u4e86\u91cf\u5b50\u7b5b\u9009\u4e2d\u76f8\u9047\u653b\u51fb\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u6784\u9020\u3002", "motivation": "\u7814\u7a76\u5bc6\u94a5\u957f\u5ea6\u6269\u5c55\u6280\u672f\u5728\u91cf\u5b50\u8ba1\u7b97\u6a21\u578b\u4e0b\u7684\u5b89\u5168\u6027\uff0c\u8bc4\u4f30\u73b0\u6709KLE\u6784\u9020\u5728\u91cf\u5b50\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u4e3a\u91cf\u5b50\u5b89\u5168\u5bc6\u7801\u8bbe\u8ba1\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u91c7\u7528\u91cf\u5b50\u4e2d\u95f4\u76f8\u9047\u653b\u51fb\u65b9\u6cd5\uff0c\u7ed3\u5408\u91cf\u5b50\u722a\u67e5\u627e\u7b97\u6cd5\u3001Grover\u7b97\u6cd5\u548c\u91cf\u5b50\u7b5b\u9009\u4e2d\u76f8\u9047\u653b\u51fb\u6280\u672f\uff0c\u9488\u5bf92kTE\u548c3XCE\u6784\u9020\u8bbe\u8ba1\u5177\u4f53\u653b\u51fb\u65b9\u6848\u3002", "result": "\u5bf92kTE\u7684\u653b\u51fb\u5728Q2\u6a21\u578b\u4e0b\u5206\u522b\u8fbe\u5230O(2^{2\u03ba/3})\u548cO(2^{\u03ba/2})\u65f6\u95f4\u590d\u6742\u5ea6\uff1b\u5bf93XCE\u7684Q1\u6a21\u578b\u653b\u51fb\u8fbe\u5230O(2^{(\u03ba+n)/2})\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u76f8\u6bd4\u7ecf\u5178\u653b\u51fb\u5b9e\u73b0\u4e8c\u6b21\u52a0\u901f\u3002", "conclusion": "2kTE\u5728Q2\u6a21\u578b\u4e0b\u65e0\u6cd5\u63d0\u4f9b\u5b89\u5168\u589e\u5f3a\uff0c3XCE\u5728Q1\u6a21\u578b\u4e0b\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u91cf\u5b50SITM\u653b\u51fb\u6846\u67b6\u53ef\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u5bc6\u7801\u5206\u6790\u573a\u666f\u3002"}}
{"id": "2511.09092", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.09092", "abs": "https://arxiv.org/abs/2511.09092", "authors": ["Zezhen Ding", "Zhen Tan", "Jiheng Zhang", "Tianlong Chen"], "title": "OR-R1: Automating Modeling and Solving of Operations Research Optimization Problem via Test-Time Reinforcement Learning", "comment": "9 pages, 5 figures, AAAI 2026", "summary": "Optimization modeling and solving are fundamental to the application of Operations Research (OR) in real-world decision making, yet the process of translating natural language problem descriptions into formal models and solver code remains highly expertise intensive. While recent advances in large language models (LLMs) have opened new opportunities for automation, the generalization ability and data efficiency of existing LLM-based methods are still limited, asmost require vast amounts of annotated or synthetic data, resulting in high costs and scalability barriers. In this work, we present OR-R1, a data-efficient training framework for automated optimization modeling and solving. OR-R1 first employs supervised fine-tuning (SFT) to help the model acquire the essential reasoning patterns for problem formulation and code generation from limited labeled data. In addition, it improves the capability and consistency through Test-Time Group Relative Policy Optimization (TGRPO). This two-stage design enables OR-R1 to leverage both scarce labeled and abundant unlabeled data for effective learning. Experiments show that OR-R1 achieves state-of-the-art performance with an average solving accuracy of $67.7\\%$, using only $1/10$ the synthetic data required by prior methods such as ORLM, exceeding ORLM's solving accuracy by up to $4.2\\%$. Remarkably, OR-R1 outperforms ORLM by over $2.4\\%$ with just $100$ synthetic samples. Furthermore, TGRPO contributes an additional $3.1\\%-6.4\\%$ improvement in accuracy, significantly narrowing the gap between single-attempt (Pass@1) and multi-attempt (Pass@8) performance from $13\\%$ to $7\\%$. Extensive evaluations across diverse real-world benchmarks demonstrate that OR-R1 provides a robust, scalable, and cost-effective solution for automated OR optimization problem modeling and solving, lowering the expertise and data barriers for industrial OR applications.", "AI": {"tldr": "OR-R1\u662f\u4e00\u4e2a\u6570\u636e\u9ad8\u6548\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u4f18\u5316\u5efa\u6a21\u548c\u6c42\u89e3\u3002\u5b83\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u6d4b\u8bd5\u65f6\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7684\u4e24\u9636\u6bb5\u8bbe\u8ba1\uff0c\u4ec5\u97001/10\u7684\u6570\u636e\u91cf\u5c31\u80fd\u8fbe\u523067.7%\u7684\u5e73\u5747\u6c42\u89e3\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u5316\u5efa\u6a21\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6216\u5408\u6210\u6570\u636e\uff0c\u5bfc\u81f4\u6210\u672c\u9ad8\u4e14\u53ef\u6269\u5c55\u6027\u5dee\u3002OR-R1\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u6570\u636e\u6548\u7387\u9ad8\u3001\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u81ea\u52a8\u5316\u4f18\u5316\u5efa\u6a21\u548c\u6c42\u89e3\u6846\u67b6\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a1\uff09\u76d1\u7763\u5fae\u8c03\u4ece\u6709\u9650\u6807\u6ce8\u6570\u636e\u4e2d\u5b66\u4e60\u95ee\u9898\u5efa\u6a21\u548c\u4ee3\u7801\u751f\u6210\u7684\u63a8\u7406\u6a21\u5f0f\uff1b2\uff09\u6d4b\u8bd5\u65f6\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u5229\u7528\u5927\u91cf\u672a\u6807\u6ce8\u6570\u636e\u63d0\u5347\u80fd\u529b\u548c\u4e00\u81f4\u6027\u3002", "result": "OR-R1\u4ec5\u97001/10\u7684\u5408\u6210\u6570\u636e\u5c31\u8fbe\u523067.7%\u7684\u5e73\u5747\u6c42\u89e3\u51c6\u786e\u7387\uff0c\u6bd4ORLM\u9ad8\u51fa4.2%\u3002\u5728\u4ec5100\u4e2a\u5408\u6210\u6837\u672c\u4e0b\u4ecd\u4f18\u4e8eORLM 2.4%\u3002TGRPO\u5e26\u67653.1%-6.4%\u7684\u989d\u5916\u63d0\u5347\uff0c\u5c06\u5355\u6b21\u5c1d\u8bd5\u4e0e\u591a\u6b21\u5c1d\u8bd5\u7684\u6027\u80fd\u5dee\u8ddd\u4ece13%\u7f29\u5c0f\u52307%\u3002", "conclusion": "OR-R1\u4e3a\u81ea\u52a8\u5316\u8fd0\u7b79\u5b66\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u548c\u6c42\u89e3\u63d0\u4f9b\u4e86\u7a33\u5065\u3001\u53ef\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5de5\u4e1a\u5e94\u7528\u7684\u4e13\u4e1a\u77e5\u8bc6\u548c\u6570\u636e\u95e8\u69db\u3002"}}
{"id": "2511.09552", "categories": ["cs.CR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.09552", "abs": "https://arxiv.org/abs/2511.09552", "authors": ["Abhirup Das", "Pranav Dudani", "Shruti Sharma", "Ravi Kumar C."], "title": "Intelligent Carrier Allocation: A Cross-Modal Reasoning Framework for Adaptive Multimodal Steganography", "comment": "8 pages, 10 figures", "summary": "In today's digital world, which has many different types of media, steganography, the art of secret communication, has a lot of problems to deal with. Traditional methods are often fixed and only work with one type of carrier media. This means they don't work well with all the different types of media that are out there. This system doesn't send data to \"weak\" or easily detectable carriers because it can't adapt. This makes the system less safe and less secret in general. This paper proposes a novel Intelligent Carrier Allocation framework founded on a Cross-Modal Reasoning (CMR) Engine. This engine looks at a wide range of carriers, such as images, audio, and text, to see if they are good for steganography. It uses important measurements like entropy, signal complexity, and vocabulary richness to come up with a single reliability score for each modality. The framework uses these scores to fairly and intelligently share the secret bitstream, giving more data to carriers that are thought to be stronger and more complex. This adaptive allocation strategy makes the system as hard to find as possible and as strong as possible against steganalysis. We demonstrate that this reasoning-based approach is more secure and superior in data protection compared to static, non-adaptive multimodal techniques. This makes it possible to build stronger and smarter secret communication systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8de8\u6a21\u6001\u63a8\u7406\u5f15\u64ce\u7684\u667a\u80fd\u8f7d\u4f53\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u56fe\u50cf\u3001\u97f3\u9891\u548c\u6587\u672c\u7b49\u591a\u79cd\u8f7d\u4f53\u7684\u71b5\u503c\u3001\u4fe1\u53f7\u590d\u6742\u5ea6\u548c\u8bcd\u6c47\u4e30\u5bcc\u5ea6\u7b49\u6307\u6807\uff0c\u4e3a\u6bcf\u79cd\u6a21\u6001\u751f\u6210\u53ef\u9760\u6027\u8bc4\u5206\uff0c\u5e76\u636e\u6b64\u81ea\u9002\u5e94\u5730\u5206\u914d\u79d8\u5bc6\u6bd4\u7279\u6d41\uff0c\u63d0\u9ad8\u9690\u5199\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u6297\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u9690\u5199\u65b9\u6cd5\u901a\u5e38\u56fa\u5b9a\u4e14\u4ec5\u9002\u7528\u4e8e\u5355\u4e00\u8f7d\u4f53\u7c7b\u578b\uff0c\u65e0\u6cd5\u9002\u5e94\u591a\u79cd\u5a92\u4f53\u7c7b\u578b\uff0c\u5bfc\u81f4\u7cfb\u7edf\u5b89\u5168\u6027\u4e0d\u8db3\u4e14\u5bb9\u6613\u88ab\u68c0\u6d4b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u667a\u80fd\u8bc4\u4f30\u4e0d\u540c\u8f7d\u4f53\u5e76\u81ea\u9002\u5e94\u5206\u914d\u79d8\u5bc6\u6570\u636e\u7684\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u8de8\u6a21\u6001\u63a8\u7406\u5f15\u64ce\uff0c\u5206\u6790\u56fe\u50cf\u3001\u97f3\u9891\u548c\u6587\u672c\u7b49\u591a\u79cd\u8f7d\u4f53\u7684\u71b5\u503c\u3001\u4fe1\u53f7\u590d\u6742\u5ea6\u548c\u8bcd\u6c47\u4e30\u5bcc\u5ea6\u7b49\u6307\u6807\uff0c\u751f\u6210\u53ef\u9760\u6027\u8bc4\u5206\uff0c\u5e76\u57fa\u4e8e\u8bc4\u5206\u667a\u80fd\u5206\u914d\u79d8\u5bc6\u6bd4\u7279\u6d41\uff0c\u4f18\u5148\u5206\u914d\u7ed9\u66f4\u5f3a\u66f4\u590d\u6742\u7684\u8f7d\u4f53\u3002", "result": "\u8be5\u63a8\u7406\u65b9\u6cd5\u76f8\u6bd4\u9759\u6001\u975e\u81ea\u9002\u5e94\u591a\u6a21\u6001\u6280\u672f\u5177\u6709\u66f4\u9ad8\u7684\u5b89\u5168\u6027\u548c\u6570\u636e\u4fdd\u62a4\u80fd\u529b\uff0c\u80fd\u591f\u6784\u5efa\u66f4\u5f3a\u5927\u3001\u66f4\u667a\u80fd\u7684\u79d8\u5bc6\u901a\u4fe1\u7cfb\u7edf\u3002", "conclusion": "\u57fa\u4e8e\u8de8\u6a21\u6001\u63a8\u7406\u7684\u667a\u80fd\u8f7d\u4f53\u5206\u914d\u6846\u67b6\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u9690\u5199\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u6297\u68c0\u6d4b\u80fd\u529b\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u7684\u79d8\u5bc6\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09158", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09158", "abs": "https://arxiv.org/abs/2511.09158", "authors": ["Yuhao Wang", "Xiaopeng Li", "Cheng Gong", "Ziru Liu", "Suiyun Zhang", "Rui Liu", "Xiangyu Zhao"], "title": "Efficient Reasoning via Reward Model", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has been shown to enhance the reasoning capabilities of large language models (LLMs), enabling the development of large reasoning models (LRMs). However, LRMs such as DeepSeek-R1 and OpenAI o1 often generate verbose responses containing redundant or irrelevant reasoning step-a phenomenon known as overthinking-which substantially increases computational costs. Prior efforts to mitigate this issue commonly incorporate length penalties into the reward function, but we find they frequently suffer from two critical issues: length collapse and training collapse, resulting in sub-optimal performance. To address them, we propose a pipeline for training a Conciseness Reward Model (CRM) that scores the conciseness of reasoning path. Additionally, we introduce a novel reward formulation named Conciseness Reward Function (CRF) with explicit dependency between the outcome reward and conciseness score, thereby fostering both more effective and more efficient reasoning. From a theoretical standpoint, we demonstrate the superiority of the new reward from the perspective of variance reduction and improved convergence properties. Besides, on the practical side, extensive experiments on five mathematical benchmark datasets demonstrate the method's effectiveness and token efficiency, which achieves an 8.1% accuracy improvement and a 19.9% reduction in response token length on Qwen2.5-7B. Furthermore, the method generalizes well to other LLMs including Llama and Mistral. The implementation code and datasets are publicly available for reproduction: https://anonymous.4open.science/r/CRM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u7b80\u6d01\u6027\u5956\u52b1\u6a21\u578b\uff08CRM\uff09\u7684\u7ba1\u9053\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u7b80\u6d01\u6027\u5956\u52b1\u51fd\u6570\uff08CRF\uff09\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5728\u51cf\u5c11\u54cd\u5e94\u957f\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08\u5982DeepSeek-R1\u548cOpenAI o1\uff09\u7ecf\u5e38\u751f\u6210\u5305\u542b\u5197\u4f59\u63a8\u7406\u6b65\u9aa4\u7684\u5197\u957f\u54cd\u5e94\uff08\u8fc7\u5ea6\u601d\u8003\u73b0\u8c61\uff09\uff0c\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u957f\u5ea6\u60e9\u7f5a\u5b58\u5728\u957f\u5ea6\u5d29\u6e83\u548c\u8bad\u7ec3\u5d29\u6e83\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u8bad\u7ec3\u7b80\u6d01\u6027\u5956\u52b1\u6a21\u578b\uff08CRM\uff09\u7684\u7ba1\u9053\u6765\u8bc4\u4f30\u63a8\u7406\u8def\u5f84\u7684\u7b80\u6d01\u6027\uff0c\u5e76\u5f15\u5165\u5177\u6709\u7ed3\u679c\u5956\u52b1\u4e0e\u7b80\u6d01\u6027\u5f97\u5206\u660e\u786e\u4f9d\u8d56\u5173\u7cfb\u7684\u7b80\u6d01\u6027\u5956\u52b1\u51fd\u6570\uff08CRF\uff09\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u5b66\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728Qwen2.5-7B\u4e0a\u5b9e\u73b0\u4e868.1%\u7684\u51c6\u786e\u7387\u63d0\u5347\u548c19.9%\u7684\u54cd\u5e94\u957f\u5ea6\u51cf\u5c11\uff0c\u4e14\u5728Llama\u548cMistral\u7b49\u5176\u4ed6LLMs\u4e0a\u6cdb\u5316\u826f\u597d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u65b0\u5956\u52b1\u5728\u65b9\u5dee\u51cf\u5c11\u548c\u6536\u655b\u6027\u6539\u8fdb\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u5b9e\u8df5\u4e0a\u6709\u6548\u89e3\u51b3\u4e86\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u548c\u66f4\u6709\u6548\u7684\u63a8\u7406\u3002"}}
{"id": "2511.09178", "categories": ["cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09178", "abs": "https://arxiv.org/abs/2511.09178", "authors": ["Niclas Flehmig", "Mary Ann Lundteigen", "Shen Yin"], "title": "Perspectives on a Reliability Monitoring Framework for Agentic AI Systems", "comment": null, "summary": "The implementation of agentic AI systems has the potential of providing more helpful AI systems in a variety of applications. These systems work autonomously towards a defined goal with reduced external control. Despite their potential, one of their flaws is the insufficient reliability which makes them especially unsuitable for high-risk domains such as healthcare or process industry. Unreliable systems pose a risk in terms of unexpected behavior during operation and mitigation techniques are needed. In this work, we derive the main reliability challenges of agentic AI systems during operation based on their characteristics. We draw the connection to traditional AI systems and formulate a fundamental reliability challenge during operation which is inherent to traditional and agentic AI systems. As our main contribution, we propose a two-layered reliability monitoring framework for agentic AI systems which consists of a out-of-distribution detection layer for novel inputs and AI transparency layer to reveal internal operations. This two-layered monitoring approach gives a human operator the decision support which is needed to decide whether an output is potential unreliable or not and intervene. This framework provides a foundation for developing mitigation techniques to reduce risk stemming from uncertain reliability during operation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u5c42\u53ef\u9760\u6027\u76d1\u63a7\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u667a\u80fdAI\u7cfb\u7edf\u5728\u8fd0\u884c\u671f\u95f4\u7684\u53ef\u9760\u6027\u4e0d\u8db3\u95ee\u9898\uff0c\u901a\u8fc7\u5f02\u5e38\u68c0\u6d4b\u548c\u900f\u660e\u5ea6\u5c42\u4e3a\u64cd\u4f5c\u5458\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u3002", "motivation": "\u667a\u80fdAI\u7cfb\u7edf\u867d\u7136\u80fd\u5728\u5404\u79cd\u5e94\u7528\u4e2d\u63d0\u4f9b\u66f4\u6709\u5e2e\u52a9\u7684AI\u7cfb\u7edf\uff0c\u4f46\u7531\u4e8e\u53ef\u9760\u6027\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5982\u533b\u7597\u4fdd\u5065\u6216\u6d41\u7a0b\u5de5\u4e1a\u4e2d\uff0c\u5176\u4e0d\u53ef\u9760\u6027\u5e26\u6765\u4e86\u610f\u5916\u884c\u4e3a\u7684\u98ce\u9669\uff0c\u9700\u8981\u7f13\u89e3\u6280\u672f\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u53cc\u5c42\u53ef\u9760\u6027\u76d1\u63a7\u6846\u67b6\uff0c\u5305\u62ec\u7528\u4e8e\u68c0\u6d4b\u65b0\u8f93\u5165\u7684\u5206\u5e03\u5916\u68c0\u6d4b\u5c42\u548c\u63ed\u793a\u5185\u90e8\u64cd\u4f5c\u7684AI\u900f\u660e\u5ea6\u5c42\uff0c\u4e3a\u4eba\u7c7b\u64cd\u4f5c\u5458\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u4ee5\u5224\u65ad\u8f93\u51fa\u662f\u5426\u53ef\u80fd\u4e0d\u53ef\u9760\u5e76\u8fdb\u884c\u5e72\u9884\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u7f13\u89e3\u6280\u672f\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4ee5\u51cf\u5c11\u8fd0\u884c\u671f\u95f4\u4e0d\u786e\u5b9a\u6027\u53ef\u9760\u6027\u5e26\u6765\u7684\u98ce\u9669\u3002", "conclusion": "\u53cc\u5c42\u76d1\u63a7\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u652f\u6301\u4eba\u7c7b\u64cd\u4f5c\u5458\u5224\u65adAI\u7cfb\u7edf\u8f93\u51fa\u7684\u53ef\u9760\u6027\uff0c\u5e76\u4e3a\u964d\u4f4e\u8fd0\u884c\u98ce\u9669\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2511.09247", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09247", "abs": "https://arxiv.org/abs/2511.09247", "authors": ["Yi-Hsien Hsieh", "Ta-Jung Chien", "Chun-Kai Huang", "Shao-Hua Sun", "Che Lin"], "title": "MedFuse: Multiplicative Embedding Fusion For Irregular Clinical Time Series", "comment": null, "summary": "Clinical time series derived from electronic health records (EHRs) are inherently irregular, with asynchronous sampling, missing values, and heterogeneous feature dynamics. While numerical laboratory measurements are highly informative, existing embedding strategies usually combine feature identity and value embeddings through additive operations, which constrains their ability to capture value-dependent feature interactions. We propose MedFuse, a framework for irregular clinical time series centered on the MuFuse (Multiplicative Embedding Fusion) module. MuFuse fuses value and feature embeddings through multiplicative modulation, preserving feature-specific information while modeling higher-order dependencies across features. Experiments on three real-world datasets covering both intensive and chronic care show that MedFuse consistently outperforms state-of-the-art baselines on key predictive tasks. Analysis of the learned representations further demonstrates that multiplicative fusion enhances expressiveness and supports cross-dataset pretraining. These results establish MedFuse as a generalizable approach for modeling irregular clinical time series.", "AI": {"tldr": "MedFuse\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u4e0d\u89c4\u5219\u4e34\u5e8a\u65f6\u95f4\u5e8f\u5217\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e58\u6cd5\u5d4c\u5165\u878d\u5408\u6a21\u5757\u5c06\u7279\u5f81\u503c\u548c\u7279\u5f81\u8eab\u4efd\u5d4c\u5165\u8fdb\u884c\u4e58\u6cd5\u8c03\u5236\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u7279\u5f81\u95f4\u7684\u9ad8\u9636\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u7684\u4e34\u5e8a\u65f6\u95f4\u5e8f\u5217\u5177\u6709\u4e0d\u89c4\u5219\u6027\u3001\u5f02\u6b65\u91c7\u6837\u3001\u7f3a\u5931\u503c\u548c\u5f02\u8d28\u7279\u5f81\u52a8\u6001\u7b49\u95ee\u9898\u3002\u73b0\u6709\u7684\u5d4c\u5165\u7b56\u7565\u901a\u5e38\u901a\u8fc7\u52a0\u6cd5\u64cd\u4f5c\u7ed3\u5408\u7279\u5f81\u8eab\u4efd\u548c\u503c\u5d4c\u5165\uff0c\u9650\u5236\u4e86\u6355\u6349\u503c\u4f9d\u8d56\u7279\u5f81\u4ea4\u4e92\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86MedFuse\u6846\u67b6\uff0c\u6838\u5fc3\u662fMuFuse\uff08\u4e58\u6cd5\u5d4c\u5165\u878d\u5408\uff09\u6a21\u5757\uff0c\u901a\u8fc7\u4e58\u6cd5\u8c03\u5236\u878d\u5408\u503c\u548c\u7279\u5f81\u5d4c\u5165\uff0c\u5728\u4fdd\u7559\u7279\u5f81\u7279\u5b9a\u4fe1\u606f\u7684\u540c\u65f6\u5efa\u6a21\u8de8\u7279\u5f81\u7684\u9ad8\u9636\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u6db5\u76d6\u91cd\u75c7\u548c\u6162\u6027\u62a4\u7406\u7684\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMedFuse\u5728\u5173\u952e\u9884\u6d4b\u4efb\u52a1\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u5b66\u4e60\u8868\u793a\u7684\u5206\u6790\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e58\u6cd5\u878d\u5408\u589e\u5f3a\u4e86\u8868\u8fbe\u80fd\u529b\u5e76\u652f\u6301\u8de8\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u3002", "conclusion": "MedFuse\u4e3a\u5efa\u6a21\u4e0d\u89c4\u5219\u4e34\u5e8a\u65f6\u95f4\u5e8f\u5217\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6cdb\u5316\u7684\u65b9\u6cd5\uff0c\u4e58\u6cd5\u878d\u5408\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2511.09275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09275", "abs": "https://arxiv.org/abs/2511.09275", "authors": ["Minlan Shao", "Zijian Zhang", "Yili Wang", "Yiwei Dai", "Xu Shen", "Xin Wang"], "title": "HyperD: Hybrid Periodicity Decoupling Framework for Traffic Forecasting", "comment": null, "summary": "Accurate traffic forecasting plays a vital role in intelligent transportation systems, enabling applications such as congestion control, route planning, and urban mobility optimization.However, traffic forecasting remains challenging due to two key factors: (1) complex spatial dependencies arising from dynamic interactions between road segments and traffic sensors across the network, and (2) the coexistence of multi-scale periodic patterns (e.g., daily and weekly periodic patterns driven by human routines) with irregular fluctuations caused by unpredictable events (e.g., accidents, weather, or construction). To tackle these challenges, we propose HyperD (Hybrid Periodic Decoupling), a novel framework that decouples traffic data into periodic and residual components. The periodic component is handled by the Hybrid Periodic Representation Module, which extracts fine-grained daily and weekly patterns using learnable periodic embeddings and spatial-temporal attention. The residual component, which captures non-periodic, high-frequency fluctuations, is modeled by the Frequency-Aware Residual Representation Module, leveraging complex-valued MLP in frequency domain. To enforce semantic separation between the two components, we further introduce a Dual-View Alignment Loss, which aligns low-frequency information with the periodic branch and high-frequency information with the residual branch. Extensive experiments on four real-world traffic datasets demonstrate that HyperD achieves state-of-the-art prediction accuracy, while offering superior robustness under disturbances and improved computational efficiency compared to existing methods.", "AI": {"tldr": "HyperD\u662f\u4e00\u4e2a\u7528\u4e8e\u4ea4\u901a\u9884\u6d4b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4ea4\u901a\u6570\u636e\u89e3\u8026\u4e3a\u5468\u671f\u6027\u548c\u6b8b\u5dee\u5206\u91cf\u6765\u5904\u7406\u590d\u6742\u7684\u65f6\u7a7a\u4f9d\u8d56\u6027\u548c\u591a\u5c3a\u5ea6\u5468\u671f\u6027\u6a21\u5f0f\u3002", "motivation": "\u4ea4\u901a\u9884\u6d4b\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u590d\u6742\u7684\u7a7a\u95f4\u4f9d\u8d56\u6027\u548c\u591a\u5c3a\u5ea6\u5468\u671f\u6027\u6a21\u5f0f\u4e0e\u4e0d\u89c4\u5219\u6ce2\u52a8\u7684\u5171\u5b58\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u56e0\u7d20\u3002", "method": "\u63d0\u51faHyperD\u6846\u67b6\uff0c\u5305\u542b\u6df7\u5408\u5468\u671f\u6027\u8868\u793a\u6a21\u5757\uff08\u5904\u7406\u5468\u671f\u6027\u5206\u91cf\uff09\u548c\u9891\u7387\u611f\u77e5\u6b8b\u5dee\u8868\u793a\u6a21\u5757\uff08\u5904\u7406\u975e\u5468\u671f\u6027\u6ce2\u52a8\uff09\uff0c\u5e76\u5f15\u5165\u53cc\u89c6\u56fe\u5bf9\u9f50\u635f\u5931\u6765\u5f3a\u5236\u8bed\u4e49\u5206\u79bb\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHyperD\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5728\u5e72\u6270\u4e0b\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff0c\u8ba1\u7b97\u6548\u7387\u4e5f\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "HyperD\u901a\u8fc7\u89e3\u8026\u5468\u671f\u6027\u548c\u975e\u5468\u671f\u6027\u5206\u91cf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ea4\u901a\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u548c\u9c81\u68d2\u7684\u9884\u6d4b\u65b9\u6848\u3002"}}
{"id": "2511.09287", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09287", "abs": "https://arxiv.org/abs/2511.09287", "authors": ["Roland Aydin", "Christian Cyron", "Steve Bachelor", "Ashton Anderson", "Robert West"], "title": "From Model Training to Model Raising -- A call to reform AI model training paradigms from post-hoc alignment to intrinsic, identity-based development", "comment": "Accepted for publication in Communications of the ACM (CACM), Opinion section", "summary": "Current AI training methods align models with human values only after their core capabilities have been established, resulting in models that are easily misaligned and lack deep-rooted value systems. We propose a paradigm shift from \"model training\" to \"model raising\", in which alignment is woven into a model's development from the start. We identify several key components for this paradigm, all centered around redesigning the training corpus: reframing training data from a first-person perspective, recontextualizing information as lived experience, simulating social interactions, and scaffolding the ordering of training data. We expect that this redesign of the training corpus will lead to an early commitment to values from the first training token onward, such that knowledge, skills, and values are intrinsically much harder to separate. In an ecosystem in which large language model capabilities start overtaking human capabilities in many tasks, this seems to us like a critical need.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ece\"\u6a21\u578b\u8bad\u7ec3\"\u8f6c\u5411\"\u6a21\u578b\u57f9\u517b\"\u7684\u65b0\u8303\u5f0f\uff0c\u5c06\u4ef7\u503c\u89c2\u5bf9\u9f50\u878d\u5165\u6a21\u578b\u5f00\u53d1\u5168\u8fc7\u7a0b\uff0c\u901a\u8fc7\u91cd\u6784\u8bad\u7ec3\u8bed\u6599\u5e93\u5b9e\u73b0\u77e5\u8bc6\u4e0e\u4ef7\u503c\u89c2\u7684\u5185\u5728\u878d\u5408\u3002", "motivation": "\u5f53\u524dAI\u8bad\u7ec3\u65b9\u6cd5\u5728\u6a21\u578b\u6838\u5fc3\u80fd\u529b\u5efa\u7acb\u540e\u624d\u8fdb\u884c\u4ef7\u503c\u89c2\u5bf9\u9f50\uff0c\u5bfc\u81f4\u6a21\u578b\u6613\u9519\u4f4d\u4e14\u7f3a\u4e4f\u6df1\u5c42\u6b21\u4ef7\u503c\u4f53\u7cfb\u3002\u5728\u5927\u6a21\u578b\u80fd\u529b\u8d85\u8d8a\u4eba\u7c7b\u7684\u80cc\u666f\u4e0b\uff0c\u9700\u8981\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u8bad\u7ec3\u8303\u5f0f\u3002", "method": "\u91cd\u65b0\u8bbe\u8ba1\u8bad\u7ec3\u8bed\u6599\u5e93\uff1a\u91c7\u7528\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u91cd\u6784\u8bad\u7ec3\u6570\u636e\u3001\u5c06\u4fe1\u606f\u91cd\u65b0\u60c5\u5883\u5316\u4e3a\u751f\u6d3b\u4f53\u9a8c\u3001\u6a21\u62df\u793e\u4f1a\u4e92\u52a8\u3001\u642d\u5efa\u8bad\u7ec3\u6570\u636e\u6392\u5e8f\u7684\u811a\u624b\u67b6\u3002", "result": "\u9884\u671f\u8fd9\u79cd\u8bad\u7ec3\u8bed\u6599\u5e93\u7684\u91cd\u65b0\u8bbe\u8ba1\u5c06\u5b9e\u73b0\u4ece\u7b2c\u4e00\u4e2a\u8bad\u7ec3\u6807\u8bb0\u5f00\u59cb\u7684\u65e9\u671f\u4ef7\u503c\u89c2\u627f\u8bfa\uff0c\u4f7f\u77e5\u8bc6\u3001\u6280\u80fd\u548c\u4ef7\u503c\u89c2\u5185\u5728\u96be\u4ee5\u5206\u79bb\u3002", "conclusion": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u5f00\u59cb\u8d85\u8d8a\u4eba\u7c7b\u7684\u751f\u6001\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u79cd\u4ece\u8bad\u7ec3\u5230\u57f9\u517b\u7684\u8303\u5f0f\u8f6c\u53d8\u662f\u81f3\u5173\u91cd\u8981\u7684\u9700\u6c42\u3002"}}
{"id": "2511.09325", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09325", "abs": "https://arxiv.org/abs/2511.09325", "authors": ["Stine Beltoft", "Lukas Galke"], "title": "Not Everything That Counts Can Be Counted: A Case for Safe Qualitative AI", "comment": "Accepted at 3rd International Conference on Frontiers of Artificial Intelligence, Ethics, and Multidisciplinary Applications (FAIEMA 2025)", "summary": "Artificial intelligence (AI) and large language models (LLM) are reshaping science, with most recent advances culminating in fully-automated scientific discovery pipelines. But qualitative research has been left behind. Researchers in qualitative methods are hesitant about AI adoption. Yet when they are willing to use AI at all, they have little choice but to rely on general-purpose tools like ChatGPT to assist with interview interpretation, data annotation, and topic modeling - while simultaneously acknowledging these system's well-known limitations of being biased, opaque, irreproducible, and privacy-compromising. This creates a critical gap: while AI has substantially advanced quantitative methods, the qualitative dimensions essential for meaning-making and comprehensive scientific understanding remain poorly integrated. We argue for developing dedicated qualitative AI systems built from the ground up for interpretive research. Such systems must be transparent, reproducible, and privacy-friendly. We review recent literature to show how existing automated discovery pipelines could be enhanced by robust qualitative capabilities, and identify key opportunities where safe qualitative AI could advance multidisciplinary and mixed-methods research.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u5b9a\u6027\u7814\u7a76\u7684AI\u7cfb\u7edf\uff0c\u4ee5\u89e3\u51b3\u5f53\u524d\u5b9a\u6027\u7814\u7a76\u8005\u5728AI\u5e94\u7528\u4e2d\u7684\u56f0\u5883\u3002\u73b0\u6709\u901a\u7528AI\u5de5\u5177\u5b58\u5728\u504f\u89c1\u3001\u4e0d\u900f\u660e\u3001\u4e0d\u53ef\u590d\u73b0\u548c\u9690\u79c1\u95ee\u9898\uff0c\u800c\u5b9a\u6027\u65b9\u6cd5\u5bf9\u4e8e\u79d1\u5b66\u7406\u89e3\u81f3\u5173\u91cd\u8981\u3002", "motivation": "AI\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6b63\u5728\u91cd\u5851\u79d1\u5b66\uff0c\u4f46\u5b9a\u6027\u7814\u7a76\u88ab\u5ffd\u89c6\u3002\u7814\u7a76\u8005\u5bf9AI\u6301\u4fdd\u7559\u6001\u5ea6\uff0c\u53ea\u80fd\u4f9d\u8d56\u6709\u7f3a\u9677\u7684\u901a\u7528\u5de5\u5177\u5982ChatGPT\uff0c\u8fd9\u9020\u6210\u4e86\u5173\u952e\u5dee\u8ddd\u3002", "method": "\u4e3b\u5f20\u4ece\u96f6\u5f00\u59cb\u6784\u5efa\u4e13\u95e8\u7528\u4e8e\u89e3\u91ca\u6027\u7814\u7a76\u7684\u5b9a\u6027AI\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5fc5\u987b\u900f\u660e\u3001\u53ef\u590d\u73b0\u4e14\u4fdd\u62a4\u9690\u79c1\u3002\u56de\u987e\u6587\u732e\u5c55\u793a\u5982\u4f55\u901a\u8fc7\u5f3a\u5927\u7684\u5b9a\u6027\u80fd\u529b\u589e\u5f3a\u73b0\u6709\u81ea\u52a8\u5316\u53d1\u73b0\u6d41\u7a0b\u3002", "result": "\u8bc6\u522b\u4e86\u5b89\u5168\u5b9a\u6027AI\u53ef\u4ee5\u63a8\u52a8\u591a\u5b66\u79d1\u548c\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u7684\u5173\u952e\u673a\u4f1a\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u5b9a\u6027AI\u7cfb\u7edf\u6765\u5f25\u5408\u5b9a\u91cf\u65b9\u6cd5\u4e0e\u5b9a\u6027\u7ef4\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u786e\u4fdd\u79d1\u5b66\u53d1\u73b0\u7684\u5168\u9762\u6027\u3002"}}
{"id": "2511.09378", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09378", "abs": "https://arxiv.org/abs/2511.09378", "authors": ["Augusto B. Corr\u00eaa", "Andr\u00e9 G. Pereira", "Jendrik Seipp"], "title": "The 2025 Planning Performance of Frontier Large Language Models", "comment": null, "summary": "The capacity of Large Language Models (LLMs) for reasoning remains an active area of research, with the capabilities of frontier models continually advancing. We provide an updated evaluation of the end-to-end planning performance of three frontier LLMs as of 2025, where models are prompted to generate a plan from PDDL domain and task descriptions. We evaluate DeepSeek R1, Gemini 2.5 Pro, GPT-5 and as reference the planner LAMA on a subset of domains from the most recent Learning Track of the International Planning Competition. Our results show that on standard PDDL domains, the performance of GPT-5 in terms of solved tasks is competitive with LAMA. When the PDDL domains and tasks are obfuscated to test for pure reasoning, the performance of all LLMs degrades, though less severely than previously reported for other models. These results show substantial improvements over prior generations of LLMs, reducing the performance gap to planners on a challenging benchmark.", "AI": {"tldr": "\u8bc4\u4f302025\u5e74\u4e09\u4e2a\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u5728PDDL\u89c4\u5212\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0cGPT-5\u5728\u6807\u51c6PDDL\u9886\u57df\u8868\u73b0\u4e0eLAMA\u89c4\u5212\u5668\u76f8\u5f53\uff0c\u4f46\u5728\u6df7\u6dc6\u6d4b\u8bd5\u4e2d\u6240\u6709\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u8bc4\u4f30\u524d\u6cbfLLM\u5728\u7aef\u5230\u7aef\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u4e0e\u4e13\u4e1a\u89c4\u5212\u5668\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "method": "\u4f7f\u7528\u56fd\u9645\u89c4\u5212\u7ade\u8d5b\u5b66\u4e60\u8d5b\u9053\u4e2d\u7684PDDL\u9886\u57df\u548c\u4efb\u52a1\u5b50\u96c6\uff0c\u6d4b\u8bd5DeepSeek R1\u3001Gemini 2.5 Pro\u3001GPT-5\u548cLAMA\u89c4\u5212\u5668\uff0c\u5305\u62ec\u6807\u51c6PDDL\u548c\u6df7\u6dc6PDDL\u4e24\u79cd\u60c5\u51b5\u3002", "result": "GPT-5\u5728\u6807\u51c6PDDL\u9886\u57df\u89e3\u51b3\u4efb\u52a1\u6570\u91cf\u4e0eLAMA\u76f8\u5f53\uff1b\u6240\u6709LLM\u5728\u6df7\u6dc6PDDL\u6d4b\u8bd5\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u4f46\u4e0b\u964d\u7a0b\u5ea6\u6bd4\u4e4b\u524d\u6a21\u578b\u62a5\u544a\u7684\u8981\u5c0f\u3002", "conclusion": "\u524d\u6cbfLLM\u5728\u89c4\u5212\u4efb\u52a1\u4e0a\u76f8\u6bd4\u524d\u4ee3\u6a21\u578b\u6709\u663e\u8457\u6539\u8fdb\uff0c\u4e0e\u89c4\u5212\u5668\u5728\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u6027\u80fd\u5dee\u8ddd\u6b63\u5728\u7f29\u5c0f\u3002"}}
{"id": "2511.09433", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09433", "abs": "https://arxiv.org/abs/2511.09433", "authors": ["Brian Rogers", "Micah Bowles", "Chris J. Lintott", "Steve Croft"], "title": "What We Don't C: Representations for scientific discovery beyond VAEs", "comment": "Accepted to the Machine Learning and the Physical Sciences workshop at NeurIPS 2025", "summary": "Accessing information in learned representations is critical for scientific discovery in high-dimensional domains. We introduce a novel method based on latent flow matching with classifier-free guidance that disentangles latent subspaces by explicitly separating information included in conditioning from information that remains in the residual representation. Across three experiments -- a synthetic 2D Gaussian toy problem, colored MNIST, and the Galaxy10 astronomy dataset -- we show that our method enables access to meaningful features of high dimensional data. Our results highlight a simple yet powerful mechanism for analyzing, controlling, and repurposing latent representations, providing a pathway toward using generative models for scientific exploration of what we don't capture, consider, or catalog.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6f5c\u5728\u6d41\u5339\u914d\u548c\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u5206\u79bb\u6761\u4ef6\u4fe1\u606f\u548c\u6b8b\u5dee\u8868\u793a\u6765\u89e3\u8026\u6f5c\u5728\u5b50\u7a7a\u95f4\uff0c\u5b9e\u73b0\u4e86\u5bf9\u9ad8\u7ef4\u6570\u636e\u6709\u610f\u4e49\u7279\u5f81\u7684\u8bbf\u95ee\u3002", "motivation": "\u5728\u9ad8\u7ef4\u9886\u57df\u4e2d\u8bbf\u95ee\u5b66\u4e60\u8868\u793a\u4e2d\u7684\u4fe1\u606f\u5bf9\u4e8e\u79d1\u5b66\u53d1\u73b0\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u5206\u6790\u3001\u63a7\u5236\u548c\u91cd\u65b0\u5229\u7528\u6f5c\u5728\u8868\u793a\u3002", "method": "\u4f7f\u7528\u6f5c\u5728\u6d41\u5339\u914d\u7ed3\u5408\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\uff0c\u663e\u5f0f\u5206\u79bb\u6761\u4ef6\u4fe1\u606f\u548c\u6b8b\u5dee\u8868\u793a\uff0c\u4ece\u800c\u89e3\u8026\u6f5c\u5728\u5b50\u7a7a\u95f4\u3002", "result": "\u5728\u4e09\u4e2a\u5b9e\u9a8c\u4e2d\uff08\u5408\u62102D\u9ad8\u65af\u95ee\u9898\u3001\u5f69\u8272MNIST\u548cGalaxy10\u5929\u6587\u6570\u636e\u96c6\uff09\u5747\u6210\u529f\u8bbf\u95ee\u5230\u9ad8\u7ef4\u6570\u636e\u7684\u6709\u610f\u4e49\u7279\u5f81\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4f7f\u7528\u751f\u6210\u6a21\u578b\u8fdb\u884c\u79d1\u5b66\u63a2\u7d22\u63d0\u4f9b\u4e86\u4e00\u6761\u7b80\u5355\u800c\u5f3a\u5927\u7684\u9014\u5f84\uff0c\u80fd\u591f\u5206\u6790\u6211\u4eec\u672a\u6355\u83b7\u3001\u8003\u8651\u6216\u7f16\u76ee\u7684\u4fe1\u606f\u3002"}}
{"id": "2511.09483", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09483", "abs": "https://arxiv.org/abs/2511.09483", "authors": ["Peiyu Li", "Xiaobao Huang", "Nitesh V. Chawla"], "title": "CrochetBench: Can Vision-Language Models Move from Describing to Doing in Crochet Domain?", "comment": "code available at https://github.com/Peiyu-Georgia-Li/crochetBench", "summary": "We present CrochetBench, a benchmark for evaluating the ability of multimodal large language models to perform fine-grained, low-level procedural reasoning in the domain of crochet. Unlike prior benchmarks that focus on high-level description or visual question answering, CrochetBench shifts the emphasis from describing to doing: models are required to recognize stitches, select structurally appropriate instructions, and generate compilable crochet procedures. We adopt the CrochetPARADE DSL as our intermediate representation, enabling structural validation and functional evaluation via execution. The benchmark covers tasks including stitch classification, instruction grounding, and both natural language and image-to-DSL translation. Across all tasks, performance sharply declines as the evaluation shifts from surface-level similarity to executable correctness, exposing limitations in long-range symbolic reasoning and 3D-aware procedural synthesis. CrochetBench offers a new lens for assessing procedural competence in multimodal models and highlights the gap between surface-level understanding and executable precision in real-world creative domains. Code is available at https://github.com/Peiyu-Georgia-Li/crochetBench.", "AI": {"tldr": "CrochetBench\u662f\u4e00\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u94a9\u9488\u7f16\u7ec7\u9886\u57df\u8fdb\u884c\u7ec6\u7c92\u5ea6\u3001\u4f4e\u5c42\u6b21\u7a0b\u5e8f\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u3002\u5b83\u8981\u6c42\u6a21\u578b\u8bc6\u522b\u9488\u6cd5\u3001\u9009\u62e9\u7ed3\u6784\u5408\u9002\u7684\u6307\u4ee4\u5e76\u751f\u6210\u53ef\u7f16\u8bd1\u7684\u94a9\u9488\u7a0b\u5e8f\uff0c\u901a\u8fc7\u6267\u884c\u9a8c\u8bc1\u529f\u80fd\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u9ad8\u5c42\u6b21\u63cf\u8ff0\u6216\u89c6\u89c9\u95ee\u7b54\uff0c\u800cCrochetBench\u5c06\u91cd\u70b9\u4ece\u63cf\u8ff0\u8f6c\u5411\u5b9e\u9645\u64cd\u4f5c\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u521b\u610f\u9886\u57df\u4e2d\u7684\u7a0b\u5e8f\u80fd\u529b\u3002", "method": "\u91c7\u7528CrochetPARADE DSL\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u652f\u6301\u7ed3\u6784\u9a8c\u8bc1\u548c\u901a\u8fc7\u6267\u884c\u7684\u529f\u80fd\u8bc4\u4f30\u3002\u57fa\u51c6\u6db5\u76d6\u9488\u6cd5\u5206\u7c7b\u3001\u6307\u4ee4\u63a5\u5730\u3001\u81ea\u7136\u8bed\u8a00\u5230DSL\u7ffb\u8bd1\u548c\u56fe\u50cf\u5230DSL\u7ffb\u8bd1\u7b49\u4efb\u52a1\u3002", "result": "\u5728\u6240\u6709\u4efb\u52a1\u4e2d\uff0c\u5f53\u8bc4\u4f30\u4ece\u8868\u9762\u76f8\u4f3c\u6027\u8f6c\u5411\u53ef\u6267\u884c\u6b63\u786e\u6027\u65f6\uff0c\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u66b4\u9732\u4e86\u6a21\u578b\u5728\u957f\u8ddd\u79bb\u7b26\u53f7\u63a8\u7406\u548c3D\u611f\u77e5\u7a0b\u5e8f\u5408\u6210\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "conclusion": "CrochetBench\u4e3a\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u7684\u7a0b\u5e8f\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u7a81\u663e\u4e86\u8868\u9762\u7406\u89e3\u4e0e\u771f\u5b9e\u4e16\u754c\u521b\u610f\u9886\u57df\u4e2d\u53ef\u6267\u884c\u7cbe\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.09493", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09493", "abs": "https://arxiv.org/abs/2511.09493", "authors": ["Adam Tauman Kalai", "Yael Tauman Kalai", "Or Zamir"], "title": "Consensus Sampling for Safer Generative AI", "comment": null, "summary": "Many approaches to AI safety rely on inspecting model outputs or activations, yet certain risks are inherently undetectable by inspection alone. We propose a complementary, architecture-agnostic approach that enhances safety through the aggregation of multiple generative models, with the aggregated model inheriting its safety from the safest subset of a given size among them. Specifically, we present a consensus sampling algorithm that, given $k$ models and a prompt, achieves risk competitive with the average risk of the safest $s$ of the $k$ models, where $s$ is a chosen parameter, while abstaining when there is insufficient agreement between them. The approach leverages the models' ability to compute output probabilities, and we bound the probability of abstention when sufficiently many models are safe and exhibit adequate agreement. The algorithm is inspired by the provable copyright protection algorithm of Vyas et al. (2023). It requires some overlap among safe models, offers no protection when all models are unsafe, and may accumulate risk over repeated use. Nonetheless, our results provide a new, model-agnostic approach for AI safety by amplifying safety guarantees from an unknown subset of models within a collection to that of a single reliable model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u805a\u5408\u591a\u4e2a\u751f\u6210\u6a21\u578b\u6765\u589e\u5f3aAI\u5b89\u5168\u6027\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u5171\u8bc6\u91c7\u6837\u7b97\u6cd5\u4ecek\u4e2a\u6a21\u578b\u4e2d\u9009\u62e9\u6700\u5b89\u5168\u7684s\u4e2a\u6a21\u578b\uff0c\u5728\u6a21\u578b\u95f4\u8fbe\u6210\u8db3\u591f\u5171\u8bc6\u65f6\u8f93\u51fa\u7ed3\u679c\uff0c\u5426\u5219\u5f03\u6743\u3002", "motivation": "\u73b0\u6709\u7684AI\u5b89\u5168\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u68c0\u67e5\u6a21\u578b\u8f93\u51fa\u6216\u6fc0\u6d3b\uff0c\u4f46\u67d0\u4e9b\u98ce\u9669\u4ec5\u901a\u8fc7\u68c0\u67e5\u65e0\u6cd5\u68c0\u6d4b\u3002\u9700\u8981\u4e00\u79cd\u67b6\u6784\u65e0\u5173\u7684\u8865\u5145\u65b9\u6cd5\u6765\u589e\u5f3a\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51fa\u5171\u8bc6\u91c7\u6837\u7b97\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u8ba1\u7b97\u8f93\u51fa\u6982\u7387\u7684\u80fd\u529b\uff0c\u4ecek\u4e2a\u6a21\u578b\u4e2d\u9009\u62e9\u6700\u5b89\u5168\u7684s\u4e2a\u6a21\u578b\uff0c\u5f53\u8fd9\u4e9b\u6a21\u578b\u95f4\u8fbe\u6210\u8db3\u591f\u5171\u8bc6\u65f6\u8f93\u51fa\u7ed3\u679c\uff0c\u5426\u5219\u5f03\u6743\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u4e0e\u6700\u5b89\u5168\u7684s\u4e2a\u6a21\u578b\u5e73\u5747\u98ce\u9669\u76f8\u5f53\u7684\u5b89\u5168\u6027\uff0c\u5e76\u5728\u8db3\u591f\u591a\u6a21\u578b\u5b89\u5168\u4e14\u8fbe\u6210\u5145\u5206\u5171\u8bc6\u65f6\u9650\u5236\u5f03\u6743\u6982\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u65e0\u5173\u7684AI\u5b89\u5168\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u6a21\u578b\u96c6\u5408\u4e2d\u7684\u672a\u77e5\u5b89\u5168\u5b50\u96c6\u653e\u5927\u5b89\u5168\u4fdd\u8bc1\u5230\u5355\u4e2a\u53ef\u9760\u6a21\u578b\u3002"}}
{"id": "2511.09497", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09497", "abs": "https://arxiv.org/abs/2511.09497", "authors": ["Vahid Salehi"], "title": "Fundamentals of Physical AI", "comment": "This paper is already published in Journal of Intelligent System of Systems Lifecycle Management", "summary": "This work will elaborate the fundamental principles of physical artificial intelligence (Physical AI) from a scientific and systemic perspective. The aim is to create a theoretical foundation that describes the physical embodiment, sensory perception, ability to act, learning processes, and context sensitivity of intelligent systems within a coherent framework. While classical AI approaches rely on symbolic processing and data driven models, Physical AI understands intelligence as an emergent phenomenon of real interaction between body, environment, and experience. The six fundamentals presented here are embodiment, sensory perception, motor action, learning, autonomy, and context sensitivity, and form the conceptual basis for designing and evaluating physically intelligent systems. Theoretically, it is shown that these six principles do not represent loose functional modules but rather act as a closed control loop in which energy, information, control, and context are in constant interaction. This circular interaction enables a system to generate meaning not from databases, but from physical experience, a paradigm shift that understands intelligence as an physical embodied process. Physical AI understands learning not as parameter adjustment, but as a change in the structural coupling between agents and the environment. To illustrate this, the theoretical model is explained using a practical scenario: An adaptive assistant robot supports patients in a rehabilitation clinic. This example illustrates that physical intelligence does not arise from abstract calculation, but from immediate, embodied experience. It shows how the six fundamentals interact in a real system: embodiment as a prerequisite, perception as input, movement as expression, learning as adaptation, autonomy as regulation, and context as orientation.", "AI": {"tldr": "\u672c\u6587\u4ece\u79d1\u5b66\u548c\u7cfb\u7edf\u89d2\u5ea6\u9610\u8ff0\u4e86\u7269\u7406\u4eba\u5de5\u667a\u80fd\u7684\u57fa\u672c\u539f\u7406\uff0c\u65e8\u5728\u4e3a\u667a\u80fd\u7cfb\u7edf\u7684\u7269\u7406\u4f53\u73b0\u3001\u611f\u5b98\u611f\u77e5\u3001\u884c\u52a8\u80fd\u529b\u3001\u5b66\u4e60\u8fc7\u7a0b\u548c\u60c5\u5883\u654f\u611f\u6027\u5efa\u7acb\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002", "motivation": "\u521b\u5efa\u63cf\u8ff0\u667a\u80fd\u7cfb\u7edf\u7269\u7406\u4f53\u73b0\u3001\u611f\u5b98\u611f\u77e5\u3001\u884c\u52a8\u80fd\u529b\u3001\u5b66\u4e60\u8fc7\u7a0b\u548c\u60c5\u5883\u654f\u611f\u6027\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5c06\u667a\u80fd\u7406\u89e3\u4e3a\u8eab\u4f53\u3001\u73af\u5883\u548c\u7ecf\u9a8c\u4e4b\u95f4\u771f\u5b9e\u4ea4\u4e92\u7684\u6d8c\u73b0\u73b0\u8c61\u3002", "method": "\u63d0\u51fa\u516d\u4e2a\u57fa\u672c\u539f\u7406\uff1a\u4f53\u73b0\u3001\u611f\u5b98\u611f\u77e5\u3001\u8fd0\u52a8\u884c\u4e3a\u3001\u5b66\u4e60\u3001\u81ea\u4e3b\u6027\u548c\u60c5\u5883\u654f\u611f\u6027\uff0c\u8fd9\u4e9b\u539f\u7406\u6784\u6210\u5c01\u95ed\u63a7\u5236\u5faa\u73af\uff0c\u80fd\u91cf\u3001\u4fe1\u606f\u3001\u63a7\u5236\u548c\u60c5\u5883\u5728\u5176\u4e2d\u6301\u7eed\u4ea4\u4e92\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7406\u8bba\u6a21\u578b\uff0c\u5c06\u667a\u80fd\u7406\u89e3\u4e3a\u7269\u7406\u4f53\u73b0\u8fc7\u7a0b\uff0c\u5b66\u4e60\u88ab\u89c6\u4e3a\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4e4b\u95f4\u7ed3\u6784\u8026\u5408\u7684\u53d8\u5316\uff0c\u800c\u975e\u53c2\u6570\u8c03\u6574\u3002", "conclusion": "\u7269\u7406\u4eba\u5de5\u667a\u80fd\u5c06\u667a\u80fd\u7406\u89e3\u4e3a\u7269\u7406\u4f53\u73b0\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5eb7\u590d\u8bca\u6240\u4e2d\u81ea\u9002\u5e94\u8f85\u52a9\u673a\u5668\u4eba\u7684\u5b9e\u4f8b\u5c55\u793a\u4e86\u516d\u4e2a\u57fa\u672c\u539f\u7406\u5728\u771f\u5b9e\u7cfb\u7edf\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\u3002"}}
{"id": "2511.09535", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09535", "abs": "https://arxiv.org/abs/2511.09535", "authors": ["Niklas Lauffer", "Ameesh Shah", "Micah Carroll", "Sanjit A. Seshia", "Stuart Russell", "Michael Dennis"], "title": "Robust and Diverse Multi-Agent Learning via Rational Policy Gradient", "comment": "Published at NeurIPS 2025", "summary": "Adversarial optimization algorithms that explicitly search for flaws in agents' policies have been successfully applied to finding robust and diverse policies in multi-agent settings. However, the success of adversarial optimization has been largely limited to zero-sum settings because its naive application in cooperative settings leads to a critical failure mode: agents are irrationally incentivized to self-sabotage, blocking the completion of tasks and halting further learning. To address this, we introduce Rationality-preserving Policy Optimization (RPO), a formalism for adversarial optimization that avoids self-sabotage by ensuring agents remain rational--that is, their policies are optimal with respect to some possible partner policy. To solve RPO, we develop Rational Policy Gradient (RPG), which trains agents to maximize their own reward in a modified version of the original game in which we use opponent shaping techniques to optimize the adversarial objective. RPG enables us to extend a variety of existing adversarial optimization algorithms that, no longer subject to the limitations of self-sabotage, can find adversarial examples, improve robustness and adaptability, and learn diverse policies. We empirically validate that our approach achieves strong performance in several popular cooperative and general-sum environments. Our project page can be found at https://rational-policy-gradient.github.io.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Rationality-preserving Policy Optimization (RPO)\u6846\u67b6\u548cRational Policy Gradient (RPG)\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5408\u4f5c\u548c\u4e00\u822c\u548c\u73af\u5883\u4e2d\u907f\u514d\u5bf9\u6297\u4f18\u5316\u4e2d\u7684\u81ea\u7834\u574f\u95ee\u9898\uff0c\u786e\u4fdd\u667a\u80fd\u4f53\u4fdd\u6301\u7406\u6027\u3002", "motivation": "\u5bf9\u6297\u4f18\u5316\u7b97\u6cd5\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u80fd\u6709\u6548\u53d1\u73b0\u9c81\u68d2\u548c\u591a\u6837\u5316\u7684\u7b56\u7565\uff0c\u4f46\u5728\u5408\u4f5c\u73af\u5883\u4e2d\u4f1a\u5bfc\u81f4\u667a\u80fd\u4f53\u975e\u7406\u6027\u5730\u81ea\u7834\u574f\uff0c\u963b\u788d\u4efb\u52a1\u5b8c\u6210\u548c\u5b66\u4e60\u8fdb\u7a0b\u3002", "method": "\u5f00\u53d1\u4e86RPG\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u624b\u5851\u9020\u6280\u672f\u5728\u4fee\u6539\u540e\u7684\u6e38\u620f\u7248\u672c\u4e2d\u8bad\u7ec3\u667a\u80fd\u4f53\u6700\u5927\u5316\u81ea\u8eab\u5956\u52b1\uff0c\u540c\u65f6\u4fdd\u6301\u7406\u6027\uff08\u5373\u5176\u7b56\u7565\u76f8\u5bf9\u4e8e\u67d0\u4e9b\u53ef\u80fd\u7684\u4f19\u4f34\u7b56\u7565\u662f\u6700\u4f18\u7684\uff09\u3002", "result": "RPG\u65b9\u6cd5\u5728\u591a\u4e2a\u6d41\u884c\u7684\u5408\u4f5c\u548c\u4e00\u822c\u548c\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u5f3a\u52b2\u6027\u80fd\uff0c\u80fd\u591f\u53d1\u73b0\u5bf9\u6297\u6837\u672c\u3001\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u5e76\u5b66\u4e60\u591a\u6837\u5316\u7b56\u7565\u3002", "conclusion": "RPO\u6846\u67b6\u548cRPG\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u5bf9\u6297\u4f18\u5316\u5728\u5408\u4f5c\u73af\u5883\u4e2d\u7684\u81ea\u7834\u574f\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u5bf9\u6297\u4f18\u5316\u7b97\u6cd5\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2511.09549", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09549", "abs": "https://arxiv.org/abs/2511.09549", "authors": ["Daniel Platnick", "Dawson Tomasz", "Eamon Earl", "Sourena Khanzadeh", "Richard Valenzano"], "title": "Breadth-First Search vs. Restarting Random Walks for Escaping Uninformed Heuristic Regions", "comment": null, "summary": "Greedy search methods like Greedy Best-First Search (GBFS) and Enforced Hill-Climbing (EHC) often struggle when faced with Uninformed Heuristic Regions (UHRs) like heuristic local minima or plateaus. In this work, we theoretically and empirically compare two popular methods for escaping UHRs in breadth-first search (BrFS) and restarting random walks (RRWs). We first derive the expected runtime of escaping a UHR using BrFS and RRWs, based on properties of the UHR and the random walk procedure, and then use these results to identify when RRWs will be faster in expectation than BrFS. We then evaluate these methods for escaping UHRs by comparing standard EHC, which uses BrFS to escape UHRs, to variants of EHC called EHC-RRW, which use RRWs for that purpose. EHC-RRW is shown to have strong expected runtime guarantees in cases where EHC has previously been shown to be effective. We also run experiments with these approaches on PDDL planning benchmarks to better understand their relative effectiveness for escaping UHRs.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22(BrFS)\u548c\u91cd\u542f\u968f\u673a\u6e38\u8d70(RRWs)\u4e24\u79cd\u65b9\u6cd5\u5728\u9003\u79bb\u65e0\u4fe1\u606f\u542f\u53d1\u5f0f\u533a\u57df(UHRs)\u65f6\u7684\u8868\u73b0\uff0c\u63a8\u5bfc\u4e86\u5b83\u4eec\u7684\u671f\u671b\u8fd0\u884c\u65f6\u95f4\uff0c\u5e76\u5f00\u53d1\u4e86\u4f7f\u7528RRWs\u7684EHC-RRW\u53d8\u4f53\uff0c\u5728PDDL\u89c4\u5212\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8d2a\u5a6a\u641c\u7d22\u65b9\u6cd5\u5982GBFS\u548cEHC\u5728\u9047\u5230\u542f\u53d1\u5f0f\u5c40\u90e8\u6700\u5c0f\u503c\u6216\u5e73\u53f0\u7b49\u65e0\u4fe1\u606f\u542f\u53d1\u5f0f\u533a\u57df(UHRs)\u65f6\u5e38\u5e38\u9677\u5165\u56f0\u5883\uff0c\u9700\u8981\u6709\u6548\u7684\u9003\u79bb\u673a\u5236\u3002", "method": "\u7406\u8bba\u63a8\u5bfcBrFS\u548cRRWs\u9003\u79bbUHRs\u7684\u671f\u671b\u8fd0\u884c\u65f6\u95f4\uff0c\u5f00\u53d1EHC-RRW\u53d8\u4f53\u4f7f\u7528\u968f\u673a\u6e38\u8d70\u66ff\u4ee3\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\u6765\u9003\u79bbUHRs\uff0c\u5e76\u5728PDDL\u89c4\u5212\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u786e\u5b9a\u4e86RRWs\u6bd4BrFS\u66f4\u5feb\u7684\u6761\u4ef6\uff0cEHC-RRW\u5728EHC\u6709\u6548\u7684\u573a\u666f\u4e0b\u5177\u6709\u5f3a\u5927\u7684\u671f\u671b\u8fd0\u884c\u65f6\u95f4\u4fdd\u8bc1\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728\u9003\u79bbUHRs\u65b9\u9762\u7684\u76f8\u5bf9\u6709\u6548\u6027\u3002", "conclusion": "\u91cd\u542f\u968f\u673a\u6e38\u8d70(RRWs)\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u6bd4\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22(BrFS)\u80fd\u66f4\u6709\u6548\u5730\u9003\u79bb\u65e0\u4fe1\u606f\u542f\u53d1\u5f0f\u533a\u57df\uff0cEHC-RRW\u53d8\u4f53\u5728\u89c4\u5212\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2511.09120", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09120", "abs": "https://arxiv.org/abs/2511.09120", "authors": ["Luis Del Vasto-Terrientes"], "title": "Differentially Private Rankings via Outranking Methods and Performance Data Aggregation", "comment": "Accepted and published in the USB Proceedings of the 22th International Conference on Modeling Decisions for Artificial Intelligence (MDAI 2025), Valencia, Spain, September 15--18, 2025, ISBN 978-91-531-0240-3, pp. 21--32", "summary": "Multiple-Criteria Decision Making (MCDM) is a sub-discipline of Operations Research that helps decision-makers in choosing, ranking, or sorting alternatives based on conflicting criteria. Over time, its application has been expanded into dynamic and data-driven domains, such as recommender systems. In these contexts, the availability and handling of personal and sensitive data can play a critical role in the decision-making process. Despite this increased reliance on sensitive data, the integration of privacy mechanisms with MCDM methods is underdeveloped. This paper introduces an integrated approach that combines MCDM outranking methods with Differential Privacy (DP), safeguarding individual contributions' privacy in ranking problems. This approach relies on a pre-processing step to aggregate multiple user evaluations into a comprehensive performance matrix. The evaluation results show a strong to very strong statistical correlation between the true rankings and their anonymized counterparts, ensuring robust privacy parameter guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u591a\u51c6\u5219\u51b3\u7b56(MCDM)\u6392\u5e8f\u65b9\u6cd5\u4e0e\u5dee\u5206\u9690\u79c1(DP)\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5728\u4fdd\u62a4\u4e2a\u4eba\u8d21\u732e\u9690\u79c1\u7684\u540c\u65f6\u8fdb\u884c\u6392\u540d\u51b3\u7b56\u3002", "motivation": "\u968f\u7740MCDM\u65b9\u6cd5\u5728\u52a8\u6001\u548c\u6570\u636e\u9a71\u52a8\u9886\u57df(\u5982\u63a8\u8350\u7cfb\u7edf)\u7684\u5e94\u7528\u6269\u5c55\uff0c\u654f\u611f\u6570\u636e\u7684\u5904\u7406\u548c\u9690\u79c1\u4fdd\u62a4\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u9690\u79c1\u673a\u5236\u4e0eMCDM\u65b9\u6cd5\u7684\u96c6\u6210\u8fd8\u4e0d\u591f\u6210\u719f\u3002", "method": "\u91c7\u7528\u9884\u5904\u7406\u6b65\u9aa4\u5c06\u591a\u4e2a\u7528\u6237\u8bc4\u4f30\u805a\u5408\u4e3a\u7efc\u5408\u6027\u80fd\u77e9\u9635\uff0c\u5e76\u5c06MCDM\u6392\u5e8f\u65b9\u6cd5\u4e0e\u5dee\u5206\u9690\u79c1\u76f8\u7ed3\u5408\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u771f\u5b9e\u6392\u540d\u4e0e\u5176\u533f\u540d\u5bf9\u5e94\u7269\u4e4b\u95f4\u5b58\u5728\u5f3a\u5230\u975e\u5e38\u5f3a\u7684\u7edf\u8ba1\u76f8\u5173\u6027\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u5f3a\u5927\u7684\u9690\u79c1\u53c2\u6570\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u4fdd\u62a4\u4e2a\u4eba\u9690\u79c1\u7684\u540c\u65f6\u8fdb\u884c\u6709\u6548\u7684\u591a\u51c6\u5219\u51b3\u7b56\u6392\u540d\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
