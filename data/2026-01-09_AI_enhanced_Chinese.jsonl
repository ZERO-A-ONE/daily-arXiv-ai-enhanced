{"id": "2601.03364", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03364", "abs": "https://arxiv.org/abs/2601.03364", "authors": ["Nadia Damianova", "Santiago Berrezueta-Guzman"], "title": "The Anatomy of a Successful Student Scrum Team: Motivation, Personalities, and Academic Adaptation", "comment": "Preprint submitted to Elsevier", "summary": "Agile methods, and Scrum in particular, are widely taught in software engineering education; however, there is limited empirical evidence on how these practices function in long-running, student-led projects under academic and hybrid work constraints. This paper presents a year-long case study of an eight-person student development team tasked with designing and implementing a virtual reality game that simulates a university campus and provides program-related educational content. We analyze how the team adapted Scrum practices (sprint structure, roles, backlog management) to fit semester rhythms, exams, travel, and part-time availability, and how communication and coordination were maintained in a hybrid on-site/remote environment. Using qualitative observations and artifacts from Discord, Notion, and GitHub, as well as contribution metrics and a custom communication effectiveness index (score: 0.76/1.00), we evaluate three dimensions: (1) the effectiveness of collaboration tools, (2) the impact of hybrid work on communication and productivity, and (3) the feasibility of aligning Scrum with academic timelines. Our findings show that (i) lightweight, tool-mediated coordination enabled stable progress even during remote periods; (ii) one-week sprints and flexible ceremonies helped reconcile Scrum with academic obligations; and (iii) shared motivation, role clarity, and compatible working styles were as critical as process mechanics. We propose practical recommendations for instructors and student teams adopting agile methods in hybrid, project-based learning settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4e3a\u671f\u4e00\u5e74\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5206\u6790\u4e868\u4eba\u5b66\u751f\u56e2\u961f\u5728\u6df7\u5408\u5de5\u4f5c\u73af\u5883\u4e0b\u5982\u4f55\u8c03\u6574Scrum\u5b9e\u8df5\u4ee5\u9002\u5e94\u5b66\u672f\u7ea6\u675f\uff0c\u53d1\u73b0\u8f7b\u91cf\u7ea7\u5de5\u5177\u534f\u8c03\u3001\u7075\u6d3b\u51b2\u523a\u5468\u671f\u548c\u56e2\u961f\u52a8\u529b\u5bf9\u9879\u76ee\u6210\u529f\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u867d\u7136\u654f\u6377\u65b9\u6cd5\u548cScrum\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4e2d\u88ab\u5e7f\u6cdb\u6559\u6388\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u8fd9\u4e9b\u5b9e\u8df5\u5728\u957f\u671f\u5b66\u751f\u4e3b\u5bfc\u9879\u76ee\u4e2d\u5982\u4f55\u9002\u5e94\u5b66\u672f\u7ea6\u675f\u548c\u6df7\u5408\u5de5\u4f5c\u73af\u5883\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002", "method": "\u91c7\u7528\u4e3a\u671f\u4e00\u5e74\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5206\u67908\u4eba\u5b66\u751f\u5f00\u53d1\u56e2\u961f\u8bbe\u8ba1\u548c\u5b9e\u65bd\u865a\u62df\u73b0\u5b9e\u6821\u56ed\u6e38\u620f\u7684\u9879\u76ee\u3002\u901a\u8fc7Discord\u3001Notion\u3001GitHub\u7684\u5b9a\u6027\u89c2\u5bdf\u548c\u5de5\u4ef6\uff0c\u7ed3\u5408\u8d21\u732e\u6307\u6807\u548c\u81ea\u5b9a\u4e49\u6c9f\u901a\u6709\u6548\u6027\u6307\u6570\uff08\u5f97\u5206\uff1a0.76/1.00\uff09\uff0c\u8bc4\u4f30\u4e09\u4e2a\u7ef4\u5ea6\uff1a\u534f\u4f5c\u5de5\u5177\u6709\u6548\u6027\u3001\u6df7\u5408\u5de5\u4f5c\u5bf9\u6c9f\u901a\u548c\u751f\u4ea7\u7387\u7684\u5f71\u54cd\u3001Scrum\u4e0e\u5b66\u672f\u65f6\u95f4\u8868\u7684\u534f\u8c03\u53ef\u884c\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(1)\u8f7b\u91cf\u7ea7\u5de5\u5177\u534f\u8c03\u5373\u4f7f\u5728\u8fdc\u7a0b\u671f\u95f4\u4e5f\u80fd\u4fdd\u6301\u7a33\u5b9a\u8fdb\u5c55\uff1b(2)\u4e00\u5468\u51b2\u523a\u548c\u7075\u6d3b\u4eea\u5f0f\u6709\u52a9\u4e8e\u534f\u8c03Scrum\u4e0e\u5b66\u672f\u4e49\u52a1\uff1b(3)\u5171\u4eab\u52a8\u673a\u3001\u89d2\u8272\u6e05\u6670\u5ea6\u548c\u517c\u5bb9\u5de5\u4f5c\u98ce\u683c\u4e0e\u6d41\u7a0b\u673a\u5236\u540c\u7b49\u91cd\u8981\u3002", "conclusion": "\u4e3a\u6559\u5e08\u548c\u5b66\u751f\u5728\u6df7\u5408\u9879\u76ee\u5f0f\u5b66\u4e60\u73af\u5883\u4e2d\u91c7\u7528\u654f\u6377\u65b9\u6cd5\u63d0\u51fa\u4e86\u5b9e\u7528\u5efa\u8bae\uff0c\u5f3a\u8c03\u8f7b\u91cf\u7ea7\u5de5\u5177\u534f\u8c03\u3001\u7075\u6d3b\u6d41\u7a0b\u8c03\u6574\u548c\u56e2\u961f\u52a8\u529b\u7ba1\u7406\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.03430", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.03430", "abs": "https://arxiv.org/abs/2601.03430", "authors": ["Mohamed Ouf", "Shayan Noei", "Zeph Van Iterson", "Mariam Guizani", "Ying Zou"], "title": "An Empirical Analysis of Community and Coding Patterns in OSS4SG vs. Conventional OSS", "comment": null, "summary": "Open Source Software for Social Good (OSS4SG) projects aim to address critical societal challenges, such as healthcare access and community safety. Understanding the community dynamics and contributor patterns in these projects is essential for ensuring their sustainability and long-term impact. However, while extensive research has focused on conventional Open Source Software (OSS), little is known about how the mission-driven nature of OSS4SG influences its development practices. To address this gap, we conduct a large-scale empirical study of 1,039 GitHub repositories, comprising 422 OSS4SG and 617 conventional OSS projects, to compare community structure, contributor engagement, and coding practices. Our findings reveal that OSS4SG projects foster significantly more stable and \"sticky\" (63.4%) communities, whereas conventional OSS projects are more \"magnetic\" (75.4%), attracting a high turnover of contributors. OSS4SG projects also demonstrate consistent engagement throughout the year, while conventional OSS communities exhibit seasonal fluctuations. Additionally, OSS4SG projects rely heavily on core contributors for both code quality and issue resolution, while conventional OSS projects leverage casual contributors for issue resolution, with core contributors focusing primarily on code quality.", "AI": {"tldr": "OSS4SG\u9879\u76ee\u76f8\u6bd4\u4f20\u7edfOSS\u9879\u76ee\u62e5\u6709\u66f4\u7a33\u5b9a\u3001\u7c98\u6027\u66f4\u5f3a\u7684\u793e\u533a\uff0c\u8d21\u732e\u8005\u53c2\u4e0e\u5ea6\u66f4\u5747\u8861\uff0c\u6838\u5fc3\u8d21\u732e\u8005\u5728\u4ee3\u7801\u8d28\u91cf\u548c\u95ee\u9898\u89e3\u51b3\u4e2d\u90fd\u53d1\u6325\u5173\u952e\u4f5c\u7528\u3002", "motivation": "\u867d\u7136\u4f20\u7edf\u5f00\u6e90\u8f6f\u4ef6\u5df2\u6709\u5927\u91cf\u7814\u7a76\uff0c\u4f46\u9488\u5bf9\u793e\u4f1a\u516c\u76ca\u5f00\u6e90\u8f6f\u4ef6\uff08OSS4SG\uff09\u7684\u793e\u533a\u52a8\u6001\u548c\u8d21\u732e\u8005\u6a21\u5f0f\u4e86\u89e3\u751a\u5c11\uff0c\u7279\u522b\u662f\u5176\u4f7f\u547d\u9a71\u52a8\u6027\u8d28\u5982\u4f55\u5f71\u54cd\u5f00\u53d1\u5b9e\u8df5\u3002", "method": "\u5bf91,039\u4e2aGitHub\u4ed3\u5e93\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u5305\u62ec422\u4e2aOSS4SG\u9879\u76ee\u548c617\u4e2a\u4f20\u7edfOSS\u9879\u76ee\uff0c\u6bd4\u8f83\u793e\u533a\u7ed3\u6784\u3001\u8d21\u732e\u8005\u53c2\u4e0e\u5ea6\u548c\u7f16\u7801\u5b9e\u8df5\u3002", "result": "OSS4SG\u9879\u76ee\u793e\u533a\u66f4\u7a33\u5b9a\uff0863.4%\u7c98\u6027\uff09\uff0c\u4f20\u7edfOSS\u9879\u76ee\u66f4\u6613\u5438\u5f15\u65b0\u8d21\u732e\u8005\uff0875.4%\u78c1\u6027\uff09\uff1bOSS4SG\u5168\u5e74\u53c2\u4e0e\u5ea6\u7a33\u5b9a\uff0c\u4f20\u7edfOSS\u6709\u5b63\u8282\u6027\u6ce2\u52a8\uff1bOSS4SG\u6838\u5fc3\u8d21\u732e\u8005\u540c\u65f6\u8d1f\u8d23\u4ee3\u7801\u8d28\u91cf\u548c\u95ee\u9898\u89e3\u51b3\uff0c\u4f20\u7edfOSS\u4e2d\u6838\u5fc3\u8d21\u732e\u8005\u4e13\u6ce8\u4ee3\u7801\u8d28\u91cf\uff0c\u4e34\u65f6\u8d21\u732e\u8005\u8d1f\u8d23\u95ee\u9898\u89e3\u51b3\u3002", "conclusion": "OSS4SG\u9879\u76ee\u7684\u4f7f\u547d\u9a71\u52a8\u6027\u8d28\u5851\u9020\u4e86\u72ec\u7279\u7684\u793e\u533a\u52a8\u6001\uff0c\u5f62\u6210\u4e86\u66f4\u7a33\u5b9a\u3001\u7c98\u6027\u66f4\u5f3a\u7684\u793e\u533a\u7ed3\u6784\uff0c\u8fd9\u5bf9\u786e\u4fdd\u793e\u4f1a\u516c\u76ca\u5f00\u6e90\u9879\u76ee\u7684\u53ef\u6301\u7eed\u6027\u548c\u957f\u671f\u5f71\u54cd\u529b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.03432", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03432", "abs": "https://arxiv.org/abs/2601.03432", "authors": ["Danny Brahman", "Mohammad Mahoor"], "title": "CodeEval: A pedagogical approach for targeted evaluation of code-trained Large Language Models", "comment": "Accepted at the International Joint Conference on Natural Language Processing & Asia-Pacific Chapter of the Association for Computational Linguistics, 2025. Will be published at ACL anthology", "summary": "Large Language Models (LLMs) are predominantly assessed based on their common sense reasoning, language comprehension, and logical reasoning abilities. While models trained in specialized domains like mathematics or coding have demonstrated remarkable advancements in logical reasoning, there remains a significant gap in evaluating their code generation capabilities. Existing benchmark datasets fall short in pinpointing specific strengths and weaknesses, impeding targeted enhancements in models' reasoning abilities to synthesize code. To bridge this gap, our paper introduces an innovative, pedagogical benchmarking method that mirrors the evaluation processes encountered in academic programming courses. We introduce CodeEval, a multi-dimensional benchmark dataset designed to rigorously evaluate LLMs across 24 distinct aspects of Python programming. The dataset covers three proficiency levels - beginner, intermediate, and advanced - and includes both class-based and function-based problem types with detailed problem specifications and comprehensive test suites. To facilitate widespread adoption, we also developed RunCodeEval, an open-source execution framework that provides researchers with a ready-to-use evaluation pipeline for CodeEval. RunCodeEval handles test execution, context setup, and metrics generation, enabling researchers to quickly obtain detailed insights into model strengths and weaknesses across complexity levels, problem types, and programming categories. This combination enables targeted evaluation and guides improvements in LLMs' programming proficiencies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86CodeEval\u57fa\u51c6\u6570\u636e\u96c6\u548cRunCodeEval\u6267\u884c\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u7ef4\u5ea6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684Python\u7f16\u7a0b\u80fd\u529b\uff0c\u586b\u8865\u73b0\u6709\u57fa\u51c6\u5728\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u5e38\u8bc6\u63a8\u7406\u3001\u8bed\u8a00\u7406\u89e3\u548c\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u4ee3\u7801\u751f\u6210\u80fd\u529b\u8bc4\u4f30\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002\u73b0\u6709\u7684\u57fa\u51c6\u6570\u636e\u96c6\u65e0\u6cd5\u7cbe\u786e\u5b9a\u4f4d\u6a21\u578b\u7684\u5177\u4f53\u4f18\u52bf\u548c\u5f31\u70b9\uff0c\u963b\u788d\u4e86\u9488\u5bf9\u6027\u5730\u63d0\u5347\u6a21\u578b\u7684\u4ee3\u7801\u5408\u6210\u63a8\u7406\u80fd\u529b\u3002", "method": "1. \u63d0\u51faCodeEval\u591a\u7ef4\u5ea6\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6db5\u76d6Python\u7f16\u7a0b\u768424\u4e2a\u4e0d\u540c\u65b9\u9762\uff0c\u5305\u542b\u4e09\u4e2a\u719f\u7ec3\u7ea7\u522b\uff08\u521d\u7ea7\u3001\u4e2d\u7ea7\u3001\u9ad8\u7ea7\uff09\u4ee5\u53ca\u57fa\u4e8e\u7c7b\u548c\u57fa\u4e8e\u51fd\u6570\u7684\u95ee\u9898\u7c7b\u578b\uff1b2. \u5f00\u53d1RunCodeEval\u5f00\u6e90\u6267\u884c\u6846\u67b6\uff0c\u63d0\u4f9b\u5373\u7528\u578b\u8bc4\u4f30\u7ba1\u9053\uff0c\u5904\u7406\u6d4b\u8bd5\u6267\u884c\u3001\u4e0a\u4e0b\u6587\u8bbe\u7f6e\u548c\u6307\u6807\u751f\u6210\u3002", "result": "CodeEval\u57fa\u51c6\u6570\u636e\u96c6\u80fd\u591f\u5bf9LLMs\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\uff0cRunCodeEval\u6846\u67b6\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u5feb\u901f\u83b7\u5f97\u6a21\u578b\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u7ea7\u522b\u3001\u95ee\u9898\u7c7b\u578b\u548c\u7f16\u7a0b\u7c7b\u522b\u4e0a\u7684\u8be6\u7ec6\u4f18\u52a3\u52bf\u5206\u6790\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u586b\u8865\u4e86LLMs\u4ee3\u7801\u751f\u6210\u80fd\u529b\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u6559\u5b66\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u4e3a\u9488\u5bf9\u6027\u8bc4\u4f30\u548c\u6539\u8fdbLLMs\u7684\u7f16\u7a0b\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u6307\u5bfc\u6a21\u578b\u7f16\u7a0b\u80fd\u529b\u7684\u63d0\u5347\u3002"}}
{"id": "2601.03512", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03512", "abs": "https://arxiv.org/abs/2601.03512", "authors": ["Yuhan Wu", "Huan Zhang", "Wei Cheng", "Chen Shen", "Jingyue Yang", "Wei Hu"], "title": "Bootstrapping Code Translation with Weighted Multilanguage Exploration", "comment": null, "summary": "Code translation across multiple programming languages is essential yet challenging due to two vital obstacles: scarcity of parallel data paired with executable test oracles, and optimization imbalance when handling diverse language pairs. We propose BootTrans, a bootstrapping method that resolves both obstacles. Its key idea is to leverage the functional invariance and cross-lingual portability of test suites, adapting abundant pivot-language unit tests to serve as universal verification oracles for multilingual RL training. Our method introduces a dual-pool architecture with seed and exploration pools to progressively expand training data via execution-guided experience collection. Furthermore, we design a language-aware weighting mechanism that dynamically prioritizes harder translation directions based on relative performance across sibling languages, mitigating optimization imbalance. Extensive experiments on the HumanEval-X and TransCoder-Test benchmarks demonstrate substantial improvements over baseline LLMs across all translation directions, with ablations validating the effectiveness of both bootstrapping and weighting components.", "AI": {"tldr": "BootTrans\u662f\u4e00\u79cd\u5229\u7528\u6d4b\u8bd5\u5957\u4ef6\u529f\u80fd\u4e0d\u53d8\u6027\u548c\u8de8\u8bed\u8a00\u53ef\u79fb\u690d\u6027\u7684\u5f15\u5bfc\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u6c60\u67b6\u6784\u548c\u8bed\u8a00\u611f\u77e5\u6743\u91cd\u673a\u5236\u89e3\u51b3\u591a\u8bed\u8a00\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u548c\u4f18\u5316\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u591a\u8bed\u8a00\u4ee3\u7801\u7ffb\u8bd1\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a1\uff09\u5e76\u884c\u6570\u636e\u7a00\u7f3a\u4e14\u7f3a\u4e4f\u53ef\u6267\u884c\u7684\u6d4b\u8bd5\u9884\u8a00\uff1b2\uff09\u5904\u7406\u4e0d\u540c\u8bed\u8a00\u5bf9\u65f6\u5b58\u5728\u4f18\u5316\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faBootTrans\u5f15\u5bfc\u65b9\u6cd5\uff0c\u5229\u7528\u6d4b\u8bd5\u5957\u4ef6\u7684\u529f\u80fd\u4e0d\u53d8\u6027\u548c\u8de8\u8bed\u8a00\u53ef\u79fb\u690d\u6027\uff0c\u5c06\u4e30\u5bcc\u7684\u67a2\u8f74\u8bed\u8a00\u5355\u5143\u6d4b\u8bd5\u9002\u914d\u4e3a\u591a\u8bed\u8a00RL\u8bad\u7ec3\u7684\u901a\u7528\u9a8c\u8bc1\u9884\u8a00\u3002\u91c7\u7528\u53cc\u6c60\u67b6\u6784\uff08\u79cd\u5b50\u6c60\u548c\u63a2\u7d22\u6c60\uff09\u901a\u8fc7\u6267\u884c\u5f15\u5bfc\u7684\u7ecf\u9a8c\u6536\u96c6\u9010\u6b65\u6269\u5c55\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u8bbe\u8ba1\u8bed\u8a00\u611f\u77e5\u6743\u91cd\u673a\u5236\uff0c\u57fa\u4e8e\u5144\u5f1f\u8bed\u8a00\u95f4\u7684\u76f8\u5bf9\u6027\u80fd\u52a8\u6001\u4f18\u5148\u5904\u7406\u8f83\u96be\u7684\u7ffb\u8bd1\u65b9\u5411\u3002", "result": "\u5728HumanEval-X\u548cTransCoder-Test\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u7ffb\u8bd1\u65b9\u5411\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u57fa\u7ebfLLM\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5f15\u5bfc\u548c\u6743\u91cd\u7ec4\u4ef6\u7684\u6709\u6548\u6027\u3002", "conclusion": "BootTrans\u901a\u8fc7\u5229\u7528\u6d4b\u8bd5\u5957\u4ef6\u7684\u8de8\u8bed\u8a00\u53ef\u79fb\u690d\u6027\u548c\u52a8\u6001\u8bed\u8a00\u611f\u77e5\u6743\u91cd\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8bed\u8a00\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u548c\u4f18\u5316\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2601.03288", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03288", "abs": "https://arxiv.org/abs/2601.03288", "authors": ["Songyang Liu", "Chaozhuo Li", "Rui Pu", "Litian Zhang", "Chenxu Wang", "Zejian Chen", "Yuting Zhang", "Yiming Hei"], "title": "How Real is Your Jailbreak? Fine-grained Jailbreak Evaluation with Anchored Reference", "comment": "7 pages, 3 figures, preprint", "summary": "Jailbreak attacks present a significant challenge to the safety of Large Language Models (LLMs), yet current automated evaluation methods largely rely on coarse classifications that focus mainly on harmfulness, leading to substantial overestimation of attack success. To address this problem, we propose FJAR, a fine-grained jailbreak evaluation framework with anchored references. We first categorized jailbreak responses into five fine-grained categories: Rejective, Irrelevant, Unhelpful, Incorrect, and Successful, based on the degree to which the response addresses the malicious intent of the query. This categorization serves as the basis for FJAR. Then, we introduce a novel harmless tree decomposition approach to construct high-quality anchored references by breaking down the original queries. These references guide the evaluator in determining whether the response genuinely fulfills the original query. Extensive experiments demonstrate that FJAR achieves the highest alignment with human judgment and effectively identifies the root causes of jailbreak failures, providing actionable guidance for improving attack strategies.", "AI": {"tldr": "FJAR\u662f\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u7684\u8d8a\u72f1\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u951a\u5b9a\u53c2\u8003\u548c\u4e94\u7ea7\u5206\u7c7b\u6765\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8d8a\u72f1\u653b\u51fb\u6210\u529f\u7387\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u56e0\u7c97\u7c92\u5ea6\u5206\u7c7b\u800c\u9ad8\u4f30\u653b\u51fb\u6210\u529f\u7387\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8d8a\u72f1\u653b\u51fb\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u7c97\u7c92\u5ea6\u5206\u7c7b\uff08\u4e3b\u8981\u5173\u6ce8\u6709\u5bb3\u6027\uff09\uff0c\u5bfc\u81f4\u653b\u51fb\u6210\u529f\u7387\u88ab\u4e25\u91cd\u9ad8\u4f30\u3002\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u51c6\u786e\u8861\u91cf\u8d8a\u72f1\u653b\u51fb\u7684\u5b9e\u9645\u6548\u679c\u3002", "method": "\u63d0\u51faFJAR\u6846\u67b6\uff1a1\uff09\u5c06\u8d8a\u72f1\u54cd\u5e94\u5206\u4e3a\u4e94\u4e2a\u7ec6\u7c92\u5ea6\u7c7b\u522b\uff1a\u62d2\u7edd\u3001\u65e0\u5173\u3001\u65e0\u5e2e\u52a9\u3001\u4e0d\u6b63\u786e\u3001\u6210\u529f\uff0c\u57fa\u4e8e\u54cd\u5e94\u6ee1\u8db3\u6076\u610f\u67e5\u8be2\u610f\u56fe\u7684\u7a0b\u5ea6\uff1b2\uff09\u5f15\u5165\u65e0\u5bb3\u6811\u5206\u89e3\u65b9\u6cd5\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u951a\u5b9a\u53c2\u8003\uff0c\u901a\u8fc7\u5206\u89e3\u539f\u59cb\u67e5\u8be2\u6765\u6307\u5bfc\u8bc4\u4f30\u8005\u5224\u65ad\u54cd\u5e94\u662f\u5426\u771f\u6b63\u6ee1\u8db3\u539f\u59cb\u67e5\u8be2\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cFJAR\u5728\u4e0e\u4eba\u5224\u65ad\u5bf9\u9f50\u65b9\u9762\u8fbe\u5230\u6700\u9ad8\u6c34\u5e73\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u8d8a\u72f1\u5931\u8d25\u7684\u6839\u672c\u539f\u56e0\uff0c\u4e3a\u6539\u8fdb\u653b\u51fb\u7b56\u7565\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002", "conclusion": "FJAR\u6846\u67b6\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5206\u7c7b\u548c\u951a\u5b9a\u53c2\u8003\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8d8a\u72f1\u653b\u51fb\u8bc4\u4f30\u7684\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u9ad8\u4f30\u653b\u51fb\u6210\u529f\u7387\u7684\u95ee\u9898\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u5de5\u5177\u3002"}}
{"id": "2601.03513", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03513", "abs": "https://arxiv.org/abs/2601.03513", "authors": ["Yi Wang", "Zhenting Huang", "Zhaohan Ding", "Ruoxue Liao", "Yuan Huang", "Xinzijian Liu", "Jiajun Xie", "Siheng Chen", "Linfeng Zhang"], "title": "Deploy-Master: Automating the Deployment of 50,000+ Agent-Ready Scientific Tools in One Day", "comment": null, "summary": "Open-source scientific software is abundant, yet most tools remain difficult to compile, configure, and reuse, sustaining a small-workshop mode of scientific computing. This deployment bottleneck limits reproducibility, large-scale evaluation, and the practical integration of scientific tools into modern AI-for-Science (AI4S) and agentic workflows.\n  We present Deploy-Master, a one-stop agentic workflow for large-scale tool discovery, build specification inference, execution-based validation, and publication. Guided by a taxonomy spanning 90+ scientific and engineering domains, our discovery stage starts from a recall-oriented pool of over 500,000 public repositories and progressively filters it to 52,550 executable tool candidates under license- and quality-aware criteria. Deploy-Master transforms heterogeneous open-source repositories into runnable, containerized capabilities grounded in execution rather than documentation claims. In a single day, we performed 52,550 build attempts and constructed reproducible runtime environments for 50,112 scientific tools. Each successful tool is validated by a minimal executable command and registered in SciencePedia for search and reuse, enabling direct human use and optional agent-based invocation.\n  Beyond delivering runnable tools, we report a deployment trace at the scale of 50,000 tools, characterizing throughput, cost profiles, failure surfaces, and specification uncertainty that become visible only at scale. These results explain why scientific software remains difficult to operationalize and motivate shared, observable execution substrates as a foundation for scalable AI4S and agentic science.", "AI": {"tldr": "Deploy-Master\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u53d1\u73b0\u3001\u6784\u5efa\u3001\u9a8c\u8bc1\u548c\u53d1\u5e03\u5f00\u6e90\u79d1\u5b66\u8f6f\u4ef6\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u79d1\u5b66\u8f6f\u4ef6\u90e8\u7f72\u56f0\u96be\u7684\u95ee\u9898\uff0c\u5728\u4e00\u5929\u5185\u6210\u529f\u6784\u5efa\u4e8650,112\u4e2a\u53ef\u6267\u884c\u5de5\u5177\u3002", "motivation": "\u5f00\u6e90\u79d1\u5b66\u8f6f\u4ef6\u867d\u7136\u4e30\u5bcc\uff0c\u4f46\u5927\u591a\u6570\u5de5\u5177\u96be\u4ee5\u7f16\u8bd1\u3001\u914d\u7f6e\u548c\u91cd\u7528\uff0c\u8fd9\u9650\u5236\u4e86\u79d1\u5b66\u8ba1\u7b97\u7684\u53ef\u91cd\u590d\u6027\u3001\u5927\u89c4\u6a21\u8bc4\u4f30\u4ee5\u53ca\u4e0e\u73b0\u4ee3AI-for-Science\u548c\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u96c6\u6210\u3002\u8fd9\u79cd\u90e8\u7f72\u74f6\u9888\u963b\u788d\u4e86\u79d1\u5b66\u8f6f\u4ef6\u7684\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "Deploy-Master\u91c7\u7528\u4e00\u7ad9\u5f0f\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u5305\u62ec\uff1a1\uff09\u57fa\u4e8e90+\u79d1\u5b66\u5de5\u7a0b\u9886\u57df\u5206\u7c7b\u7684\u5927\u89c4\u6a21\u5de5\u5177\u53d1\u73b0\uff1b2\uff09\u4ece50\u4e07\u4e2a\u516c\u5171\u4ed3\u5e93\u4e2d\u7b5b\u9009\u51fa52,550\u4e2a\u5019\u9009\u5de5\u5177\uff1b3\uff09\u6784\u5efa\u89c4\u8303\u63a8\u65ad\uff1b4\uff09\u57fa\u4e8e\u6267\u884c\u7684\u9a8c\u8bc1\uff1b5\uff09\u5bb9\u5668\u5316\u90e8\u7f72\u3002\u7cfb\u7edf\u5c06\u5f02\u6784\u5f00\u6e90\u4ed3\u5e93\u8f6c\u5316\u4e3a\u53ef\u8fd0\u884c\u7684\u5bb9\u5668\u5316\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u6700\u5c0f\u53ef\u6267\u884c\u547d\u4ee4\u9a8c\u8bc1\u6bcf\u4e2a\u5de5\u5177\u3002", "result": "\u5728\u4e00\u5929\u5185\u5b8c\u6210\u4e8652,550\u6b21\u6784\u5efa\u5c1d\u8bd5\uff0c\u6210\u529f\u4e3a50,112\u4e2a\u79d1\u5b66\u5de5\u5177\u6784\u5efa\u4e86\u53ef\u91cd\u590d\u7684\u8fd0\u884c\u65f6\u73af\u5883\u3002\u6240\u6709\u6210\u529f\u5de5\u5177\u90fd\u6ce8\u518c\u5230SciencePedia\u4e2d\u4f9b\u641c\u7d22\u548c\u91cd\u7528\u3002\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e8650,000\u4e2a\u5de5\u5177\u89c4\u6a21\u7684\u90e8\u7f72\u8ddf\u8e2a\u6570\u636e\uff0c\u63ed\u793a\u4e86\u541e\u5410\u91cf\u3001\u6210\u672c\u5206\u5e03\u3001\u5931\u8d25\u6a21\u5f0f\u548c\u89c4\u8303\u4e0d\u786e\u5b9a\u6027\u7b49\u5927\u89c4\u6a21\u90e8\u7f72\u7279\u5f81\u3002", "conclusion": "Deploy-Master\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u53ef\u8fd0\u884c\u7684\u5de5\u5177\u96c6\u5408\uff0c\u8fd8\u901a\u8fc7\u5927\u89c4\u6a21\u90e8\u7f72\u5b9e\u8df5\u63ed\u793a\u4e86\u79d1\u5b66\u8f6f\u4ef6\u96be\u4ee5\u64cd\u4f5c\u5316\u7684\u6839\u672c\u539f\u56e0\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5171\u4eab\u3001\u53ef\u89c2\u5bdf\u7684\u6267\u884c\u57fa\u7840\u5bf9\u4e8e\u53ef\u6269\u5c55\u7684AI-for-Science\u548c\u667a\u80fd\u4f53\u79d1\u5b66\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u89e3\u51b3\u79d1\u5b66\u8f6f\u4ef6\u90e8\u7f72\u74f6\u9888\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u65b9\u6848\u3002"}}
{"id": "2601.03359", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03359", "abs": "https://arxiv.org/abs/2601.03359", "authors": ["Alberto Purpura", "Li Wang", "Sahil Badyal", "Eugenio Beaufrand", "Adam Faulkner"], "title": "Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization", "comment": null, "summary": "Large Language Models (LLMs) often generate substantively relevant content but fail to adhere to formal constraints, leading to outputs that are conceptually correct but procedurally flawed. Traditional prompt refinement approaches focus on rephrasing the description of the primary task an LLM has to perform, neglecting the granular constraints that function as acceptance criteria for its response. We propose a novel multi-agentic workflow that decouples optimization of the primary task description from its constraints, using quantitative scores as feedback to iteratively rewrite and improve them. Our evaluation demonstrates this method produces revised prompts that yield significantly higher compliance scores from models like Llama 3.1 8B and Mixtral-8x 7B.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u5c06\u4e3b\u4efb\u52a1\u63cf\u8ff0\u4f18\u5316\u4e0e\u7ea6\u675f\u6761\u4ef6\u89e3\u8026\uff0c\u901a\u8fc7\u91cf\u5316\u5206\u6570\u53cd\u9988\u8fed\u4ee3\u6539\u8fdb\u63d0\u793a\u8bcd\uff0c\u663e\u8457\u63d0\u5347LLM\u8f93\u51fa\u5bf9\u5f62\u5f0f\u7ea6\u675f\u7684\u9075\u5b88\u7a0b\u5ea6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u751f\u6210\u5185\u5bb9\u76f8\u5173\u4f46\u4e0d\u7b26\u5408\u5f62\u5f0f\u7ea6\u675f\u7684\u8f93\u51fa\uff0c\u4f20\u7edf\u63d0\u793a\u8bcd\u4f18\u5316\u65b9\u6cd5\u53ea\u5173\u6ce8\u91cd\u8ff0\u4e3b\u4efb\u52a1\u63cf\u8ff0\uff0c\u5ffd\u7565\u4e86\u4f5c\u4e3a\u54cd\u5e94\u9a8c\u6536\u6807\u51c6\u7684\u7ec6\u7c92\u5ea6\u7ea6\u675f\u6761\u4ef6\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u5c06\u4e3b\u4efb\u52a1\u63cf\u8ff0\u4f18\u5316\u4e0e\u5176\u7ea6\u675f\u6761\u4ef6\u89e3\u8026\uff0c\u4f7f\u7528\u91cf\u5316\u5206\u6570\u4f5c\u4e3a\u53cd\u9988\uff0c\u8fed\u4ee3\u91cd\u5199\u548c\u6539\u8fdb\u63d0\u793a\u8bcd\u3002", "result": "\u8bc4\u4f30\u8868\u660e\u8be5\u65b9\u6cd5\u4ea7\u751f\u7684\u4fee\u8ba2\u63d0\u793a\u8bcd\u5728Llama 3.1 8B\u548cMixtral-8x 7B\u7b49\u6a21\u578b\u4e0a\u83b7\u5f97\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u5408\u89c4\u6027\u5206\u6570\u3002", "conclusion": "\u901a\u8fc7\u89e3\u8026\u4efb\u52a1\u63cf\u8ff0\u4e0e\u7ea6\u675f\u6761\u4ef6\uff0c\u5e76\u4f7f\u7528\u91cf\u5316\u53cd\u9988\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8LLM\u8f93\u51fa\u5bf9\u5f62\u5f0f\u7ea6\u675f\u7684\u9075\u5b88\u7a0b\u5ea6\uff0c\u89e3\u51b3\u6982\u5ff5\u6b63\u786e\u4f46\u7a0b\u5e8f\u9519\u8bef\u7684\u95ee\u9898\u3002"}}
{"id": "2601.03294", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03294", "abs": "https://arxiv.org/abs/2601.03294", "authors": ["Kaibo Huang", "Jin Tan", "Yukun Wei", "Wanling Li", "Zipei Zhang", "Hui Tian", "Zhongliang Yang", "Linna Zhou"], "title": "AgentMark: Utility-Preserving Behavioral Watermarking for Agents", "comment": null, "summary": "LLM-based agents are increasingly deployed to autonomously solve complex tasks, raising urgent needs for IP protection and regulatory provenance. While content watermarking effectively attributes LLM-generated outputs, it fails to directly identify the high-level planning behaviors (e.g., tool and subgoal choices) that govern multi-step execution. Critically, watermarking at the planning-behavior layer faces unique challenges: minor distributional deviations in decision-making can compound during long-term agent operation, degrading utility, and many agents operate as black boxes that are difficult to intervene in directly. To bridge this gap, we propose AgentMark, a behavioral watermarking framework that embeds multi-bit identifiers into planning decisions while preserving utility. It operates by eliciting an explicit behavior distribution from the agent and applying distribution-preserving conditional sampling, enabling deployment under black-box APIs while remaining compatible with action-layer content watermarking. Experiments across embodied, tool-use, and social environments demonstrate practical multi-bit capacity, robust recovery from partial logs, and utility preservation. The code is available at https://github.com/Tooooa/AgentMark.", "AI": {"tldr": "AgentMark\uff1a\u4e00\u4e2a\u4e3aLLM\u667a\u80fd\u4f53\u89c4\u5212\u884c\u4e3a\u5d4c\u5165\u591a\u6bd4\u7279\u6807\u8bc6\u7b26\u7684\u6c34\u5370\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u6548\u7528\u7684\u540c\u65f6\u5b9e\u73b0\u884c\u4e3a\u6eaf\u6e90", "motivation": "\u968f\u7740LLM\u667a\u80fd\u4f53\u88ab\u90e8\u7f72\u6765\u81ea\u4e3b\u89e3\u51b3\u590d\u6742\u4efb\u52a1\uff0c\u5bf9\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u548c\u76d1\u7ba1\u6eaf\u6e90\u7684\u9700\u6c42\u65e5\u76ca\u8feb\u5207\u3002\u4f20\u7edf\u5185\u5bb9\u6c34\u5370\u53ea\u80fd\u8bc6\u522bLLM\u751f\u6210\u7684\u8f93\u51fa\uff0c\u65e0\u6cd5\u76f4\u63a5\u8bc6\u522b\u63a7\u5236\u591a\u6b65\u6267\u884c\u7684\u9ad8\u5c42\u89c4\u5212\u884c\u4e3a\uff08\u5982\u5de5\u5177\u9009\u62e9\u548c\u5b50\u76ee\u6807\u9009\u62e9\uff09\u3002\u89c4\u5212\u884c\u4e3a\u5c42\u6c34\u5370\u9762\u4e34\u72ec\u7279\u6311\u6218\uff1a\u51b3\u7b56\u4e2d\u7684\u5fae\u5c0f\u5206\u5e03\u504f\u5dee\u5728\u957f\u671f\u8fd0\u884c\u4e2d\u4f1a\u7d2f\u79ef\u5f71\u54cd\u6548\u7528\uff0c\u4e14\u8bb8\u591a\u667a\u80fd\u4f53\u4f5c\u4e3a\u9ed1\u76d2\u96be\u4ee5\u76f4\u63a5\u5e72\u9884\u3002", "method": "\u63d0\u51faAgentMark\u884c\u4e3a\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u667a\u80fd\u4f53\u5f15\u51fa\u663e\u5f0f\u884c\u4e3a\u5206\u5e03\uff0c\u5e76\u5e94\u7528\u4fdd\u6301\u5206\u5e03\u7684\u6761\u4ef6\u91c7\u6837\uff0c\u5728\u89c4\u5212\u51b3\u7b56\u4e2d\u5d4c\u5165\u591a\u6bd4\u7279\u6807\u8bc6\u7b26\u3002\u8be5\u65b9\u6cd5\u53ef\u5728\u9ed1\u76d2API\u4e0b\u90e8\u7f72\uff0c\u5e76\u4e0e\u52a8\u4f5c\u5c42\u5185\u5bb9\u6c34\u5370\u517c\u5bb9\u3002", "result": "\u5728\u5177\u8eab\u3001\u5de5\u5177\u4f7f\u7528\u548c\u793e\u4ea4\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAgentMark\u5177\u6709\u5b9e\u7528\u7684\u591a\u6bd4\u7279\u5bb9\u91cf\uff0c\u80fd\u591f\u4ece\u90e8\u5206\u65e5\u5fd7\u4e2d\u7a33\u5065\u6062\u590d\u6807\u8bc6\u7b26\uff0c\u5e76\u4fdd\u6301\u6548\u7528\u3002", "conclusion": "AgentMark\u586b\u8865\u4e86\u667a\u80fd\u4f53\u89c4\u5212\u884c\u4e3a\u6c34\u5370\u7684\u7a7a\u767d\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u7684\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u548c\u76d1\u7ba1\u6eaf\u6e90\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.03389", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03389", "abs": "https://arxiv.org/abs/2601.03389", "authors": ["Michael Petrowski", "Milica Ga\u0161i\u0107"], "title": "Exploration Through Introspection: A Self-Aware Reward Model", "comment": "Accepted at AAAI-26 ToM4AI Workshop", "summary": "Understanding how artificial agents model internal mental states is central to advancing Theory of Mind in AI. Evidence points to a unified system for self- and other-awareness. We explore this self-awareness by having reinforcement learning agents infer their own internal states in gridworld environments. Specifically, we introduce an introspective exploration component that is inspired by biological pain as a learning signal by utilizing a hidden Markov model to infer \"pain-belief\" from online observations. This signal is integrated into a subjective reward function to study how self-awareness affects the agent's learning abilities. Further, we use this computational framework to investigate the difference in performance between normal and chronic pain perception models. Results show that introspective agents in general significantly outperform standard baseline agents and can replicate complex human-like behaviors.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5185\u7701\u63a2\u7d22\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u63a8\u65ad\"\u75bc\u75db\u4fe1\u5ff5\"\u4f5c\u4e3a\u5b66\u4e60\u4fe1\u53f7\uff0c\u7814\u7a76\u81ea\u6211\u610f\u8bc6\u5bf9\u667a\u80fd\u4f53\u5b66\u4e60\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u5e76\u6bd4\u8f83\u6b63\u5e38\u4e0e\u6162\u6027\u75bc\u75db\u611f\u77e5\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u7406\u89e3\u4eba\u5de5\u667a\u80fd\u5982\u4f55\u5efa\u6a21\u5185\u90e8\u5fc3\u7406\u72b6\u6001\u5bf9\u4e8e\u63a8\u8fdb\u5fc3\u667a\u7406\u8bba\u81f3\u5173\u91cd\u8981\u3002\u8bc1\u636e\u8868\u660e\u81ea\u6211\u8ba4\u77e5\u548c\u4ed6\u4eba\u8ba4\u77e5\u5b58\u5728\u7edf\u4e00\u7cfb\u7edf\uff0c\u672c\u7814\u7a76\u901a\u8fc7\u8ba9\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u7f51\u683c\u4e16\u754c\u4e2d\u63a8\u65ad\u81ea\u8eab\u5185\u90e8\u72b6\u6001\u6765\u63a2\u7d22\u8fd9\u79cd\u81ea\u6211\u610f\u8bc6\u3002", "method": "\u5f15\u5165\u53d7\u751f\u7269\u75bc\u75db\u542f\u53d1\u7684\u5185\u7701\u63a2\u7d22\u7ec4\u4ef6\uff0c\u4f7f\u7528\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u4ece\u5728\u7ebf\u89c2\u5bdf\u4e2d\u63a8\u65ad\"\u75bc\u75db\u4fe1\u5ff5\"\uff0c\u5c06\u8be5\u4fe1\u53f7\u6574\u5408\u5230\u4e3b\u89c2\u5956\u52b1\u51fd\u6570\u4e2d\uff0c\u6784\u5efa\u8ba1\u7b97\u6846\u67b6\u6bd4\u8f83\u6b63\u5e38\u4e0e\u6162\u6027\u75bc\u75db\u611f\u77e5\u6a21\u578b\u7684\u5dee\u5f02\u3002", "result": "\u5185\u7701\u667a\u80fd\u4f53\u603b\u4f53\u4e0a\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u57fa\u7ebf\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u590d\u73b0\u590d\u6742\u7684\u4eba\u7c7b\u884c\u4e3a\u6a21\u5f0f\uff0c\u9a8c\u8bc1\u4e86\u81ea\u6211\u610f\u8bc6\u6a21\u578b\u5728\u63d0\u5347\u5b66\u4e60\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5185\u7701\u63a2\u7d22\u7684\u8ba1\u7b97\u6846\u67b6\u4e3a\u7814\u7a76\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u81ea\u6211\u610f\u8bc6\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u8bc1\u660e\u4e86\u81ea\u6211\u72b6\u6001\u63a8\u65ad\u80fd\u591f\u663e\u8457\u63d0\u5347\u667a\u80fd\u4f53\u6027\u80fd\uff0c\u5e76\u4e3a\u7406\u89e3\u6b63\u5e38\u4e0e\u75c5\u7406\u6027\u75bc\u75db\u611f\u77e5\u5dee\u5f02\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6a21\u578b\u57fa\u7840\u3002"}}
{"id": "2601.03300", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03300", "abs": "https://arxiv.org/abs/2601.03300", "authors": ["Scott Thornton"], "title": "TRYLOCK: Defense-in-Depth Against LLM Jailbreaks via Layered Preference and Representation Engineering", "comment": "14 pages, 4 figures. Code and datasets at https://github.com/scthornton/trylock", "summary": "Large language models remain vulnerable to jailbreak attacks, and single-layer defenses often trade security for usability. We present TRYLOCK, the first defense-in-depth architecture that combines four heterogeneous mechanisms across the inference stack: weight-level safety alignment via DPO, activation-level control via Representation Engineering (RepE) steering, adaptive steering strength selected by a lightweight sidecar classifier, and input canonicalization to neutralize encoding-based bypasses. On Mistral-7B-Instruct evaluated against a 249-prompt attack set spanning five attack families, TRYLOCK achieves 88.0% relative ASR reduction (46.5% to 5.6%), with each layer contributing unique coverage: RepE blocks 36% of attacks that bypass DPO alone, while canonicalization catches 14% of encoding attacks that evade both. We discover a non-monotonic steering phenomenon -- intermediate strength (alpha=1.0) degrades safety below baseline -- and provide mechanistic hypotheses explaining RepE-DPO interference. The adaptive sidecar reduces over-refusal from 60% to 48% while maintaining identical attack defense, demonstrating that security and usability need not be mutually exclusive. We release all components -- trained adapters, steering vectors, sidecar classifier, preference pairs, and complete evaluation methodology -- enabling full reproducibility.", "AI": {"tldr": "TRYLOCK\u662f\u4e00\u4e2a\u591a\u5c42\u9632\u5fa1\u67b6\u6784\uff0c\u901a\u8fc7\u6743\u91cd\u7ea7\u5b89\u5168\u5bf9\u9f50\u3001\u6fc0\u6d3b\u7ea7\u63a7\u5236\u3001\u81ea\u9002\u5e94\u5f3a\u5ea6\u9009\u62e9\u548c\u8f93\u5165\u89c4\u8303\u5316\u56db\u5c42\u673a\u5236\uff0c\u5728Mistral-7B-Instruct\u4e0a\u5b9e\u73b088.0%\u7684\u76f8\u5bf9\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\uff0c\u540c\u65f6\u51cf\u5c11\u8fc7\u5ea6\u62d2\u7edd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\uff0c\u5355\u5c42\u9632\u5fa1\u5f80\u5f80\u9700\u8981\u5728\u5b89\u5168\u6027\u548c\u53ef\u7528\u6027\u4e4b\u95f4\u505a\u51fa\u6743\u8861\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u6df1\u5ea6\u9632\u5fa1\u67b6\u6784\u6765\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u4fdd\u62a4\u3002", "method": "\u63d0\u51faTRYLOCK\u6df1\u5ea6\u9632\u5fa1\u67b6\u6784\uff0c\u5305\u542b\u56db\u4e2a\u5f02\u6784\u673a\u5236\uff1a1) \u901a\u8fc7DPO\u8fdb\u884c\u6743\u91cd\u7ea7\u5b89\u5168\u5bf9\u9f50\uff1b2) \u901a\u8fc7\u8868\u793a\u5de5\u7a0b\u8fdb\u884c\u6fc0\u6d3b\u7ea7\u63a7\u5236\uff1b3) \u901a\u8fc7\u8f7b\u91cf\u7ea7\u4fa7\u5206\u7c7b\u5668\u9009\u62e9\u81ea\u9002\u5e94\u8f6c\u5411\u5f3a\u5ea6\uff1b4) \u8f93\u5165\u89c4\u8303\u5316\u4ee5\u4e2d\u548c\u57fa\u4e8e\u7f16\u7801\u7684\u7ed5\u8fc7\u653b\u51fb\u3002", "result": "\u5728\u5305\u542b249\u4e2a\u63d0\u793a\u7684\u4e94\u4e2a\u653b\u51fb\u5bb6\u65cf\u6d4b\u8bd5\u96c6\u4e0a\uff0cTRYLOCK\u5c06\u653b\u51fb\u6210\u529f\u7387\u4ece46.5%\u964d\u4f4e\u52305.6%\uff0c\u5b9e\u73b088.0%\u7684\u76f8\u5bf9\u964d\u4f4e\u3002\u5404\u5c42\u63d0\u4f9b\u72ec\u7279\u8986\u76d6\uff1aRepE\u963b\u6b62\u4e8636%\u7ed5\u8fc7DPO\u7684\u653b\u51fb\uff0c\u89c4\u8303\u5316\u6355\u83b7\u4e8614%\u7684\u7f16\u7801\u653b\u51fb\u3002\u81ea\u9002\u5e94\u4fa7\u5206\u7c7b\u5668\u5c06\u8fc7\u5ea6\u62d2\u7edd\u4ece60%\u964d\u4f4e\u523048%\u3002", "conclusion": "TRYLOCK\u5c55\u793a\u4e86\u5b89\u5168\u6027\u548c\u53ef\u7528\u6027\u4e0d\u5fc5\u76f8\u4e92\u6392\u65a5\uff0c\u901a\u8fc7\u6df1\u5ea6\u9632\u5fa1\u67b6\u6784\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\u9ad8\u5b89\u5168\u6027\u548c\u4f4e\u8fc7\u5ea6\u62d2\u7edd\u3002\u53d1\u73b0\u4e86\u975e\u5355\u8c03\u8f6c\u5411\u73b0\u8c61\uff0c\u5e76\u63d0\u4f9b\u4e86RepE-DPO\u5e72\u6270\u7684\u673a\u5236\u5047\u8bbe\u3002\u6240\u6709\u7ec4\u4ef6\u90fd\u5df2\u5f00\u6e90\u4ee5\u786e\u4fdd\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2601.03470", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03470", "abs": "https://arxiv.org/abs/2601.03470", "authors": ["Michael C. Darling", "Alan H. Hesu", "Michael A. Mardikes", "Brian C. McGuigan", "Reed M. Milewicz"], "title": "Toward Maturity-Based Certification of Embodied AI: Quantifying Trustworthiness Through Measurement Mechanisms", "comment": "Accepted to AAAI-26 Bridge Program B10: Making Embodied AI Reliable with Testing and Formal Verification", "summary": "We propose a maturity-based framework for certifying embodied AI systems through explicit measurement mechanisms. We argue that certifiable embodied AI requires structured assessment frameworks, quantitative scoring mechanisms, and methods for navigating multi-objective trade-offs inherent in trustworthiness evaluation. We demonstrate this approach using uncertainty quantification as an exemplar measurement mechanism and illustrate feasibility through an Uncrewed Aircraft System (UAS) detection case study.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6210\u719f\u5ea6\u7684\u8ba4\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u660e\u786e\u6d4b\u91cf\u673a\u5236\u4e3a\u5177\u8eabAI\u7cfb\u7edf\u63d0\u4f9b\u8ba4\u8bc1\uff0c\u4ee5\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e3a\u4f8b\u8bc1\uff0c\u901a\u8fc7\u65e0\u4eba\u673a\u7cfb\u7edf\u68c0\u6d4b\u6848\u4f8b\u9a8c\u8bc1\u53ef\u884c\u6027", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5bf9\u5177\u8eabAI\u7cfb\u7edf\u7684\u7ed3\u6784\u5316\u8ba4\u8bc1\u6846\u67b6\uff0c\u9700\u8981\u53ef\u91cf\u5316\u7684\u8bc4\u4f30\u673a\u5236\u6765\u786e\u4fdd\u5176\u53ef\u4fe1\u5ea6\uff0c\u7279\u522b\u662f\u5728\u591a\u76ee\u6807\u6743\u8861\u7684\u590d\u6742\u73af\u5883\u4e2d", "method": "\u63d0\u51fa\u57fa\u4e8e\u6210\u719f\u5ea6\u7684\u8ba4\u8bc1\u6846\u67b6\uff0c\u5305\u542b\u7ed3\u6784\u5316\u8bc4\u4f30\u6846\u67b6\u3001\u5b9a\u91cf\u8bc4\u5206\u673a\u5236\u548c\u591a\u76ee\u6807\u6743\u8861\u5bfc\u822a\u65b9\u6cd5\uff0c\u4ee5\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4f5c\u4e3a\u793a\u4f8b\u6d4b\u91cf\u673a\u5236\uff0c\u901a\u8fc7\u65e0\u4eba\u673a\u7cfb\u7edf\u68c0\u6d4b\u6848\u4f8b\u8fdb\u884c\u9a8c\u8bc1", "result": "\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u673a\u5236\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u5177\u8eabAI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\uff0c\u5e76\u5728\u65e0\u4eba\u673a\u68c0\u6d4b\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027", "conclusion": "\u57fa\u4e8e\u6210\u719f\u5ea6\u7684\u8ba4\u8bc1\u6846\u67b6\u4e3a\u5177\u8eabAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u91cf\u5316\u7684\u8ba4\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u660e\u786e\u7684\u6d4b\u91cf\u673a\u5236\u548c\u591a\u76ee\u6807\u6743\u8861\u5bfc\u822a\uff0c\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u548c\u63d0\u5347\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6"}}
{"id": "2601.03621", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03621", "abs": "https://arxiv.org/abs/2601.03621", "authors": ["Verya Monjezi", "Ashish Kumar", "Ashutosh Trivedi", "Gang Tan", "Saeid Tizpaz-Niari"], "title": "On the Robustness of Fairness Practices: A Causal Framework for Systematic Evaluation", "comment": null, "summary": "Machine learning (ML) algorithms are increasingly deployed to make critical decisions in socioeconomic applications such as finance, criminal justice, and autonomous driving. However, due to their data-driven and pattern-seeking nature, ML algorithms may develop decision logic that disproportionately distributes opportunities, benefits, resources, or information among different population groups, potentially harming marginalized communities. In response to such fairness concerns, the software engineering and ML communities have made significant efforts to establish the best practices for creating fair ML software. These include fairness interventions for training ML models, such as including sensitive features, selecting non-sensitive attributes, and applying bias mitigators. But how reliably can software professionals tasked with developing data-driven systems depend on these recommendations? And how well do these practices generalize in the presence of faulty labels, missing data, or distribution shifts? These questions form the core theme of this paper.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u673a\u5668\u5b66\u4e60\u516c\u5e73\u6027\u5b9e\u8df5\u5728\u73b0\u5b9e\u6570\u636e\u95ee\u9898\uff08\u5982\u9519\u8bef\u6807\u7b7e\u3001\u7f3a\u5931\u6570\u636e\u548c\u5206\u5e03\u504f\u79fb\uff09\u4e0b\u7684\u53ef\u9760\u6027\u95ee\u9898", "motivation": "\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5728\u793e\u4f1a\u7ecf\u6d4e\u5e94\u7528\u4e2d\u505a\u51fa\u5173\u952e\u51b3\u7b56\u65f6\u53ef\u80fd\u5b58\u5728\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u548cML\u793e\u533a\u5df2\u63d0\u51fa\u591a\u79cd\u516c\u5e73\u6027\u5e72\u9884\u63aa\u65bd\uff0c\u4f46\u8fd9\u4e9b\u5b9e\u8df5\u5728\u73b0\u5b9e\u6570\u636e\u95ee\u9898\u4e0b\u7684\u53ef\u9760\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u9a8c\u8bc1", "method": "\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u73b0\u6709\u516c\u5e73\u6027\u5b9e\u8df5\u5728\u5b58\u5728\u9519\u8bef\u6807\u7b7e\u3001\u7f3a\u5931\u6570\u636e\u548c\u5206\u5e03\u504f\u79fb\u7b49\u73b0\u5b9e\u6570\u636e\u95ee\u9898\u4e0b\u7684\u8868\u73b0\uff0c\u5206\u6790\u8fd9\u4e9b\u63a8\u8350\u5b9e\u8df5\u7684\u53ef\u9760\u6027", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u63a8\u8350\u7684\u516c\u5e73\u6027\u5b9e\u8df5\u5728\u73b0\u5b9e\u6570\u636e\u95ee\u9898\u4e0b\u53ef\u80fd\u4e0d\u591f\u53ef\u9760\uff0c\u65e0\u6cd5\u5f88\u597d\u5730\u6cdb\u5316\u5230\u5b58\u5728\u6570\u636e\u8d28\u91cf\u95ee\u9898\u7684\u5b9e\u9645\u573a\u666f\u4e2d", "conclusion": "\u9700\u8981\u66f4\u7a33\u5065\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u6846\u67b6\u548c\u5e72\u9884\u63aa\u65bd\uff0c\u4ee5\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6570\u636e\u8d28\u91cf\u95ee\u9898\uff0c\u786e\u4fdd\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u516c\u5e73\u6027"}}
{"id": "2601.03475", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03475", "abs": "https://arxiv.org/abs/2601.03475", "authors": ["Ruiqi Deng", "Geoffrey Martin", "Tony Wang", "Gongbo Zhang", "Yi Liu", "Chunhua Weng", "Yanshan Wang", "Justin F Rousseau", "Yifan Peng"], "title": "CPGPrompt: Translating Clinical Guidelines into LLM-Executable Decision Support", "comment": null, "summary": "Clinical practice guidelines (CPGs) provide evidence-based recommendations for patient care; however, integrating them into Artificial Intelligence (AI) remains challenging. Previous approaches, such as rule-based systems, face significant limitations, including poor interpretability, inconsistent adherence to guidelines, and narrow domain applicability. To address this, we develop and validate CPGPrompt, an auto-prompting system that converts narrative clinical guidelines into large language models (LLMs).\n  Our framework translates CPGs into structured decision trees and utilizes an LLM to dynamically navigate them for patient case evaluation. Synthetic vignettes were generated across three domains (headache, lower back pain, and prostate cancer) and distributed into four categories to test different decision scenarios. System performance was assessed on both binary specialty-referral decisions and fine-grained pathway-classification tasks.\n  The binary specialty referral classification achieved consistently strong performance across all domains (F1: 0.85-1.00), with high recall (1.00 $\\pm$ 0.00). In contrast, multi-class pathway assignment showed reduced performance, with domain-specific variations: headache (F1: 0.47), lower back pain (F1: 0.72), and prostate cancer (F1: 0.77). Domain-specific performance differences reflected the structure of each guideline. The headache guideline highlighted challenges with negation handling. The lower back pain guideline required temporal reasoning. In contrast, prostate cancer pathways benefited from quantifiable laboratory tests, resulting in more reliable decision-making.", "AI": {"tldr": "CPGPrompt\u7cfb\u7edf\u5c06\u4e34\u5e8a\u6307\u5357\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u51b3\u7b56\u6811\uff0c\u5229\u7528LLM\u52a8\u6001\u5bfc\u822a\u8fdb\u884c\u60a3\u8005\u8bc4\u4f30\uff0c\u5728\u4e13\u79d1\u8f6c\u8bca\u51b3\u7b56\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u591a\u7c7b\u522b\u8def\u5f84\u5206\u7c7b\u4e0a\u5b58\u5728\u9886\u57df\u5dee\u5f02\u3002", "motivation": "\u4e34\u5e8a\u5b9e\u8df5\u6307\u5357\uff08CPGs\uff09\u4e3a\u60a3\u8005\u62a4\u7406\u63d0\u4f9b\u5faa\u8bc1\u5efa\u8bae\uff0c\u4f46\u5c06\u5176\u6574\u5408\u5230\u4eba\u5de5\u667a\u80fd\u4e2d\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u57fa\u4e8e\u89c4\u5219\u7684\u7cfb\u7edf\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u5dee\u3001\u6307\u5357\u4f9d\u4ece\u6027\u4e0d\u4e00\u81f4\u548c\u9886\u57df\u9002\u7528\u6027\u7a84\u7b49\u9650\u5236\u3002", "method": "\u5f00\u53d1CPGPrompt\u81ea\u52a8\u63d0\u793a\u7cfb\u7edf\uff0c\u5c06\u53d9\u8ff0\u6027\u4e34\u5e8a\u6307\u5357\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u51b3\u7b56\u6811\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u52a8\u6001\u5bfc\u822a\u51b3\u7b56\u6811\u8fdb\u884c\u60a3\u8005\u75c5\u4f8b\u8bc4\u4f30\u3002\u4f7f\u7528\u4e09\u4e2a\u9886\u57df\uff08\u5934\u75db\u3001\u8170\u75db\u3001\u524d\u5217\u817a\u764c\uff09\u7684\u5408\u6210\u75c5\u4f8b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u7cfb\u7edf\u5728\u4e8c\u5143\u4e13\u79d1\u8f6c\u8bca\u51b3\u7b56\u548c\u7ec6\u7c92\u5ea6\u8def\u5f84\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u4e8c\u5143\u4e13\u79d1\u8f6c\u8bca\u5206\u7c7b\u5728\u6240\u6709\u9886\u57df\u8868\u73b0\u4e00\u81f4\u5f3a\u52b2\uff08F1\uff1a0.85-1.00\uff09\uff0c\u53ec\u56de\u7387\u9ad8\uff081.00\u00b10.00\uff09\u3002\u591a\u7c7b\u522b\u8def\u5f84\u5206\u914d\u8868\u73b0\u964d\u4f4e\uff0c\u5b58\u5728\u9886\u57df\u5dee\u5f02\uff1a\u5934\u75db\uff08F1\uff1a0.47\uff09\u3001\u8170\u75db\uff08F1\uff1a0.72\uff09\u3001\u524d\u5217\u817a\u764c\uff08F1\uff1a0.77\uff09\u3002\u6027\u80fd\u5dee\u5f02\u53cd\u6620\u4e86\u5404\u6307\u5357\u7684\u7ed3\u6784\u7279\u70b9\uff1a\u5934\u75db\u6307\u5357\u5728\u5426\u5b9a\u5904\u7406\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u8170\u75db\u6307\u5357\u9700\u8981\u65f6\u95f4\u63a8\u7406\uff0c\u524d\u5217\u817a\u764c\u8def\u5f84\u53d7\u76ca\u4e8e\u53ef\u91cf\u5316\u7684\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u3002", "conclusion": "CPGPrompt\u7cfb\u7edf\u6210\u529f\u5c06\u4e34\u5e8a\u6307\u5357\u6574\u5408\u5230LLM\u4e2d\uff0c\u5728\u4e13\u79d1\u8f6c\u8bca\u51b3\u7b56\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u590d\u6742\u8def\u5f84\u5206\u7c7b\u4efb\u52a1\u4e0a\u4ecd\u9700\u6539\u8fdb\u3002\u4e0d\u540c\u6307\u5357\u7684\u7ed3\u6784\u7279\u70b9\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\uff0c\u672a\u6765\u9700\u8981\u9488\u5bf9\u7279\u5b9a\u6311\u6218\u8fdb\u884c\u4f18\u5316\u3002"}}
{"id": "2601.03640", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.03640", "abs": "https://arxiv.org/abs/2601.03640", "authors": ["Mohd Ariful Haque", "Kishor Datta Gupta", "Mohammad Ashiqur Rahman", "Roy George"], "title": "Verbatim Data Transcription Failures in LLM Code Generation: A State-Tracking Stress Test", "comment": null, "summary": "Many real-world software tasks require exact transcription of provided data into code, such as cryptographic constants, protocol test vectors, allowlists, and calibration tables. These tasks are operationally sensitive because small omissions or alterations can remain silent while producing syntactically valid programs. This paper introduces a deliberately minimal transcription-to-code benchmark to isolate this reliability concern in LLM-based code generation. Given a list of high-precision decimal constants, a model must generate Python code that embeds the constants verbatim and performs a simple aggregate computation. We describe the prompting variants, evaluation protocol based on exact-string inclusion, and analysis framework used to characterize state-tracking and long-horizon generation failures. The benchmark is intended as a compact stress test that complements existing code-generation evaluations by focusing on data integrity rather than algorithmic reasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e13\u95e8\u6d4b\u8bd5LLM\u4ee3\u7801\u751f\u6210\u4e2d\u7cbe\u786e\u8f6c\u5f55\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8981\u6c42\u6a21\u578b\u5c06\u9ad8\u7cbe\u5ea6\u5341\u8fdb\u5236\u5e38\u6570\u539f\u6837\u5d4c\u5165Python\u4ee3\u7801\u5e76\u8fdb\u884c\u7b80\u5355\u805a\u5408\u8ba1\u7b97\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u8f6f\u4ef6\u4efb\u52a1\uff08\u5982\u52a0\u5bc6\u5e38\u6570\u3001\u534f\u8bae\u6d4b\u8bd5\u5411\u91cf\u3001\u767d\u540d\u5355\u3001\u6821\u51c6\u8868\uff09\u9700\u8981\u5c06\u6570\u636e\u7cbe\u786e\u8f6c\u5f55\u5230\u4ee3\u7801\u4e2d\uff0c\u8fd9\u4e9b\u4efb\u52a1\u5bf9\u64cd\u4f5c\u654f\u611f\uff0c\u56e0\u4e3a\u5c0f\u7684\u9057\u6f0f\u6216\u6539\u52a8\u53ef\u80fd\u5728\u751f\u6210\u8bed\u6cd5\u6709\u6548\u7a0b\u5e8f\u7684\u540c\u65f6\u4fdd\u6301\u9759\u9ed8\u9519\u8bef\u3002\u73b0\u6709\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u7b97\u6cd5\u63a8\u7406\uff0c\u7f3a\u4e4f\u5bf9\u6570\u636e\u5b8c\u6574\u6027\u7684\u4e13\u95e8\u6d4b\u8bd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6700\u5c0f\u5316\u7684\u8f6c\u5f55\u5230\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\uff1a\u7ed9\u5b9a\u9ad8\u7cbe\u5ea6\u5341\u8fdb\u5236\u5e38\u6570\u5217\u8868\uff0c\u6a21\u578b\u5fc5\u987b\u751f\u6210\u5d4c\u5165\u8fd9\u4e9b\u5e38\u6570\u539f\u6837\u7684Python\u4ee3\u7801\u5e76\u6267\u884c\u7b80\u5355\u805a\u5408\u8ba1\u7b97\u3002\u63cf\u8ff0\u4e86\u63d0\u793a\u53d8\u4f53\u3001\u57fa\u4e8e\u7cbe\u786e\u5b57\u7b26\u4e32\u5305\u542b\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u4ee5\u53ca\u7528\u4e8e\u8868\u5f81\u72b6\u6001\u8ddf\u8e2a\u548c\u957f\u89c6\u91ce\u751f\u6210\u5931\u8d25\u7684\u5206\u6790\u6846\u67b6\u3002", "result": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4f5c\u4e3a\u4e00\u4e2a\u7d27\u51d1\u7684\u538b\u529b\u6d4b\u8bd5\uff0c\u65e8\u5728\u8865\u5145\u73b0\u6709\u7684\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\uff0c\u91cd\u70b9\u5173\u6ce8\u6570\u636e\u5b8c\u6574\u6027\u800c\u975e\u7b97\u6cd5\u63a8\u7406\u3002\u901a\u8fc7\u7cbe\u786e\u5b57\u7b26\u4e32\u5305\u542b\u8bc4\u4f30\u6765\u68c0\u6d4b\u8f6c\u5f55\u9519\u8bef\u3002", "conclusion": "\u8be5\u8bba\u6587\u5f15\u5165\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9LLM\u4ee3\u7801\u751f\u6210\u4e2d\u6570\u636e\u5b8c\u6574\u6027\u53ef\u9760\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u5728\u7cbe\u786e\u8f6c\u5f55\u80fd\u529b\u6d4b\u8bd5\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u6709\u52a9\u4e8e\u8bc6\u522b\u72b6\u6001\u8ddf\u8e2a\u548c\u957f\u89c6\u91ce\u751f\u6210\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\u3002"}}
{"id": "2601.03482", "categories": ["cs.AI", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.03482", "abs": "https://arxiv.org/abs/2601.03482", "authors": ["Stefan Konigorski", "Johannes E. Vedder", "Babajide Alamu Owoyele", "\u0130brahim \u00d6zkan"], "title": "Personalization of Large Foundation Models for Health Interventions", "comment": "Accepted to the AAAI 2026 Workshop on Personalization in the Era of Large Foundation Models (PerFM)", "summary": "Large foundation models (LFMs) transform healthcare AI in prevention, diagnostics, and treatment. However, whether LFMs can provide truly personalized treatment recommendations remains an open question. Recent research has revealed multiple challenges for personalization, including the fundamental generalizability paradox: models achieving high accuracy in one clinical study perform at chance level in others, demonstrating that personalization and external validity exist in tension. This exemplifies broader contradictions in AI-driven healthcare: the privacy-performance paradox, scale-specificity paradox, and the automation-empathy paradox. As another challenge, the degree of causal understanding required for personalized recommendations, as opposed to mere predictive capacities of LFMs, remains an open question. N-of-1 trials -- crossover self-experiments and the gold standard for individual causal inference in personalized medicine -- resolve these tensions by providing within-person causal evidence while preserving privacy through local experimentation. Despite their impressive capabilities, this paper argues that LFMs cannot replace N-of-1 trials. We argue that LFMs and N-of-1 trials are complementary: LFMs excel at rapid hypothesis generation from population patterns using multimodal data, while N-of-1 trials excel at causal validation for a given individual. We propose a hybrid framework that combines the strengths of both to enable personalization and navigate the identified paradoxes: LFMs generate ranked intervention candidates with uncertainty estimates, which trigger subsequent N-of-1 trials. Clarifying the boundary between prediction and causation and explicitly addressing the paradoxical tensions are essential for responsible AI integration in personalized medicine.", "AI": {"tldr": "\u5927\u578b\u57fa\u7840\u6a21\u578b\u5728\u533b\u7597AI\u4e2d\u9762\u4e34\u4e2a\u6027\u5316\u6cbb\u7597\u7684\u6839\u672c\u6027\u77db\u76fe\uff0c\u65e0\u6cd5\u66ff\u4ee3N-of-1\u8bd5\u9a8c\uff0c\u4f46\u4e24\u8005\u53ef\u4ee5\u4e92\u8865\u7ed3\u5408", "motivation": "\u5927\u578b\u57fa\u7840\u6a21\u578b\u5728\u533b\u7597AI\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u80fd\u5426\u63d0\u4f9b\u771f\u6b63\u4e2a\u6027\u5316\u7684\u6cbb\u7597\u5efa\u8bae\u4ecd\u5b58\u7591\u95ee\u3002\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u591a\u91cd\u77db\u76fe\uff1a\u6cdb\u5316\u6096\u8bba\uff08\u6a21\u578b\u5728\u67d0\u4e2a\u4e34\u5e8a\u7814\u7a76\u4e2d\u51c6\u786e\u7387\u9ad8\uff0c\u5728\u5176\u4ed6\u7814\u7a76\u4e2d\u5374\u8868\u73b0\u968f\u673a\uff09\u3001\u9690\u79c1-\u6027\u80fd\u6096\u8bba\u3001\u89c4\u6a21-\u7279\u5f02\u6027\u6096\u8bba\u3001\u81ea\u52a8\u5316-\u540c\u7406\u5fc3\u6096\u8bba\u3002\u6b64\u5916\uff0c\u4e2a\u6027\u5316\u63a8\u8350\u9700\u8981\u56e0\u679c\u7406\u89e3\u800c\u975e\u4ec5\u4ec5\u662f\u9884\u6d4b\u80fd\u529b\uff0c\u8fd9\u4e5f\u662f\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u6846\u67b6\uff1a\u5927\u578b\u57fa\u7840\u6a21\u578b\u64c5\u957f\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u4ece\u7fa4\u4f53\u6a21\u5f0f\u4e2d\u5feb\u901f\u751f\u6210\u5047\u8bbe\uff0c\u800cN-of-1\u8bd5\u9a8c\uff08\u4ea4\u53c9\u81ea\u6211\u5b9e\u9a8c\uff0c\u4e2a\u6027\u5316\u533b\u5b66\u4e2d\u4e2a\u4f53\u56e0\u679c\u63a8\u65ad\u7684\u91d1\u6807\u51c6\uff09\u64c5\u957f\u4e3a\u7279\u5b9a\u4e2a\u4f53\u63d0\u4f9b\u56e0\u679c\u9a8c\u8bc1\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\uff1a\u5927\u578b\u57fa\u7840\u6a21\u578b\u751f\u6210\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5e72\u9884\u5019\u9009\u6392\u540d\uff0c\u89e6\u53d1\u540e\u7eed\u7684N-of-1\u8bd5\u9a8c\u3002", "result": "\u8bba\u6587\u8bba\u8bc1\u5927\u578b\u57fa\u7840\u6a21\u578b\u65e0\u6cd5\u66ff\u4ee3N-of-1\u8bd5\u9a8c\uff0c\u4f46\u4e24\u8005\u5177\u6709\u4e92\u8865\u6027\u3002\u901a\u8fc7\u660e\u786e\u9884\u6d4b\u4e0e\u56e0\u679c\u4e4b\u95f4\u7684\u754c\u9650\uff0c\u5e76\u660e\u786e\u89e3\u51b3\u5df2\u8bc6\u522b\u7684\u6096\u8bba\u6027\u5f20\u529b\uff0c\u53ef\u4ee5\u8d1f\u8d23\u4efb\u5730\u5c06AI\u6574\u5408\u5230\u4e2a\u6027\u5316\u533b\u5b66\u4e2d\u3002", "conclusion": "\u5927\u578b\u57fa\u7840\u6a21\u578b\u548cN-of-1\u8bd5\u9a8c\u662f\u4e92\u8865\u7684\uff1a\u524d\u8005\u64c5\u957f\u57fa\u4e8e\u7fa4\u4f53\u6a21\u5f0f\u7684\u5feb\u901f\u5047\u8bbe\u751f\u6210\uff0c\u540e\u8005\u64c5\u957f\u4e2a\u4f53\u56e0\u679c\u9a8c\u8bc1\u3002\u7ed3\u5408\u4e24\u8005\u7684\u6df7\u5408\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u4e2a\u6027\u5316\u5e76\u5e94\u5bf9\u5df2\u8bc6\u522b\u7684\u6096\u8bba\u3002\u660e\u786e\u9884\u6d4b\u4e0e\u56e0\u679c\u7684\u754c\u9650\u5bf9\u4e8e\u8d1f\u8d23\u4efb\u5730\u6574\u5408AI\u5230\u4e2a\u6027\u5316\u533b\u5b66\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.03323", "categories": ["cs.CR", "cs.CV", "cs.HC", "cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.03323", "abs": "https://arxiv.org/abs/2601.03323", "authors": ["Oran Duan", "Yinghua Shen", "Yingzhu Lv", "Luyang Jie", "Yaxin Liu", "Qiong Wu"], "title": "Listen to Rhythm, Choose Movements: Autoregressive Multimodal Dance Generation via Diffusion and Mamba with Decoupled Dance Dataset", "comment": "12 pages, 13 figures", "summary": "Advances in generative models and sequence learning have greatly promoted research in dance motion generation, yet current methods still suffer from coarse semantic control and poor coherence in long sequences. In this work, we present Listen to Rhythm, Choose Movements (LRCM), a multimodal-guided diffusion framework supporting both diverse input modalities and autoregressive dance motion generation. We explore a feature decoupling paradigm for dance datasets and generalize it to the Motorica Dance dataset, separating motion capture data, audio rhythm, and professionally annotated global and local text descriptions. Our diffusion architecture integrates an audio-latent Conformer and a text-latent Cross-Conformer, and incorporates a Motion Temporal Mamba Module (MTMM) to enable smooth, long-duration autoregressive synthesis. Experimental results indicate that LRCM delivers strong performance in both functional capability and quantitative metrics, demonstrating notable potential in multimodal input scenarios and extended sequence generation. We will release the full codebase, dataset, and pretrained models publicly upon acceptance.", "AI": {"tldr": "LRCM\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u5f15\u5bfc\u7684\u6269\u6563\u6846\u67b6\uff0c\u652f\u6301\u591a\u6837\u5316\u8f93\u5165\u6a21\u6001\u548c\u81ea\u56de\u5f52\u821e\u8e48\u52a8\u4f5c\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u8bed\u4e49\u63a7\u5236\u7c97\u7cd9\u548c\u957f\u5e8f\u5217\u8fde\u8d2f\u6027\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u821e\u8e48\u52a8\u4f5c\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u8bed\u4e49\u63a7\u5236\u7c97\u7cd9\u548c\u957f\u5e8f\u5217\u8fde\u8d2f\u6027\u5dee\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u597d\u7684\u591a\u6a21\u6001\u5f15\u5bfc\u548c\u957f\u5e8f\u5217\u751f\u6210\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u7279\u5f81\u89e3\u8026\u8303\u5f0f\u5206\u79bb\u8fd0\u52a8\u6355\u6349\u6570\u636e\u3001\u97f3\u9891\u8282\u594f\u548c\u4e13\u4e1a\u6807\u6ce8\u7684\u5168\u5c40/\u5c40\u90e8\u6587\u672c\u63cf\u8ff0\uff1b\u91c7\u7528\u97f3\u9891\u6f5c\u5728Conformer\u548c\u6587\u672c\u6f5c\u5728Cross-Conformer\u7684\u6269\u6563\u67b6\u6784\uff0c\u5e76\u5f15\u5165Motion Temporal Mamba Module\u5b9e\u73b0\u5e73\u6ed1\u7684\u957f\u65f6\u81ea\u56de\u5f52\u5408\u6210\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eLRCM\u5728\u529f\u80fd\u80fd\u529b\u548c\u91cf\u5316\u6307\u6807\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u5728\u591a\u6a21\u6001\u8f93\u5165\u573a\u666f\u548c\u6269\u5c55\u5e8f\u5217\u751f\u6210\u65b9\u9762\u5c55\u73b0\u51fa\u663e\u8457\u6f5c\u529b\u3002", "conclusion": "LRCM\u6846\u67b6\u901a\u8fc7\u591a\u6a21\u6001\u5f15\u5bfc\u548c\u81ea\u56de\u5f52\u751f\u6210\uff0c\u6709\u6548\u63d0\u5347\u4e86\u821e\u8e48\u52a8\u4f5c\u751f\u6210\u7684\u8bed\u4e49\u63a7\u5236\u548c\u957f\u5e8f\u5217\u8fde\u8d2f\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.03780", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03780", "abs": "https://arxiv.org/abs/2601.03780", "authors": ["Md Ahasanuzzaman", "Bram Adams", "Emad Fallahzadeh", "Gustavo A. Oliva", "Ahmed E. Hassan"], "title": "Assessing and Improving the Representativeness of Code Generation Benchmarks Using Knowledge Units (KUs) of Programming Languages -- An Empirical Study", "comment": null, "summary": "Large Language Models (LLMs) such as GPT-4, Claude and LLaMA have shown impressive performance in code generation, typically evaluated using benchmarks (e.g., HumanEval). However, effective code generation requires models to understand and apply a wide range of language concepts. If the concepts exercised in benchmarks are not representative of those used in real-world projects, evaluations may yield incomplete. Despite this concern, the representativeness of code concepts in benchmarks has not been systematically examined.\n  To address this gap, we present the first empirical study that analyzes the representativeness of code generation benchmarks through the lens of Knowledge Units (KUs) - cohesive sets of programming language capabilities provided by language constructs and APIs. We analyze KU coverage in two widely used Python benchmarks, HumanEval and MBPP, and compare them with 30 real-world Python projects. Our results show that each benchmark covers only half of the identified 20 KUs, whereas projects exercise all KUs with relatively balanced distributions. In contrast, benchmark tasks exhibit highly skewed KU distributions.\n  To mitigate this misalignment, we propose a prompt-based LLM framework that synthesizes KU-based tasks to rebalance benchmark KU distributions and better align them with real-world usage. Using this framework, we generate 440 new tasks and augment existing benchmarks. The augmented benchmarks substantially improve KU coverage and achieve over a 60% improvement in distributional alignment. Evaluations of state-of-the-art LLMs on these augmented benchmarks reveal consistent and statistically significant performance drops (12.54-44.82%), indicating that existing benchmarks overestimate LLM performance due to their limited KU coverage. Our findings provide actionable guidance for building more realistic evaluations of LLM code-generation capabilities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7f16\u7a0b\u6982\u5ff5\u7684\u4ee3\u8868\u6027\u95ee\u9898\uff0c\u53d1\u73b0HumanEval\u548cMBPP\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u8986\u76d6\u4e86\u4e00\u534a\u7684\u7f16\u7a0b\u77e5\u8bc6\u5355\u5143\uff0c\u4e14\u5206\u5e03\u4e25\u91cd\u504f\u659c\uff0c\u800c\u771f\u5b9e\u9879\u76ee\u4f7f\u7528\u4e86\u6240\u6709\u77e5\u8bc6\u5355\u5143\u4e14\u5206\u5e03\u5747\u8861\u3002\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u57fa\u4e8e\u63d0\u793a\u7684LLM\u6846\u67b6\u6765\u5408\u6210\u65b0\u4efb\u52a1\u4ee5\u91cd\u65b0\u5e73\u8861\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u9ad8\u4f30\u4e86LLM\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982HumanEval\uff09\u8bc4\u4f30LLM\u6027\u80fd\u65f6\uff0c\u5982\u679c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u7f16\u7a0b\u6982\u5ff5\u4e0d\u80fd\u4ee3\u8868\u771f\u5b9e\u9879\u76ee\u4e2d\u7684\u6982\u5ff5\u4f7f\u7528\uff0c\u8bc4\u4f30\u7ed3\u679c\u53ef\u80fd\u4e0d\u5b8c\u6574\u3002\u7136\u800c\uff0c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4ee3\u7801\u6982\u5ff5\u7684\u4ee3\u8868\u6027\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u7814\u7a76\u3002", "method": "1. \u63d0\u51fa\u77e5\u8bc6\u5355\u5143\uff08KUs\uff09\u4f5c\u4e3a\u5206\u6790\u6846\u67b6\uff0c\u5c06\u7f16\u7a0b\u8bed\u8a00\u80fd\u529b\u7ec4\u7ec7\u4e3a\u8fde\u8d2f\u7684\u96c6\u5408\n2. \u5206\u6790\u4e24\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684Python\u57fa\u51c6\u6d4b\u8bd5\uff08HumanEval\u548cMBPP\uff09\u7684KU\u8986\u76d6\u60c5\u51b5\n3. \u4e0e30\u4e2a\u771f\u5b9ePython\u9879\u76ee\u8fdb\u884c\u5bf9\u6bd4\n4. \u63d0\u51fa\u57fa\u4e8e\u63d0\u793a\u7684LLM\u6846\u67b6\uff0c\u5408\u6210KU\u57fa\u7840\u4efb\u52a1\u4ee5\u91cd\u65b0\u5e73\u8861\u57fa\u51c6\u6d4b\u8bd5\u5206\u5e03\n5. \u751f\u6210440\u4e2a\u65b0\u4efb\u52a1\u5e76\u589e\u5f3a\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5", "result": "1. \u6bcf\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u8986\u76d6\u4e8620\u4e2a\u5df2\u8bc6\u522bKUs\u4e2d\u7684\u4e00\u534a\uff0c\u800c\u771f\u5b9e\u9879\u76ee\u4f7f\u7528\u4e86\u6240\u6709KUs\u4e14\u5206\u5e03\u76f8\u5bf9\u5747\u8861\n2. \u57fa\u51c6\u6d4b\u8bd5\u4efb\u52a1\u5448\u73b0\u9ad8\u5ea6\u504f\u659c\u7684KU\u5206\u5e03\n3. \u589e\u5f3a\u540e\u7684\u57fa\u51c6\u6d4b\u8bd5\u663e\u8457\u63d0\u9ad8\u4e86KU\u8986\u76d6\u7387\uff0c\u5206\u5e03\u5bf9\u9f50\u5ea6\u63d0\u5347\u4e8660%\u4ee5\u4e0a\n4. \u5728\u589e\u5f3a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\u6700\u5148\u8fdb\u7684LLM\uff0c\u53d1\u73b0\u6027\u80fd\u51fa\u73b0\u4e00\u81f4\u4e14\u7edf\u8ba1\u663e\u8457\u7684\u4e0b\u964d\uff0812.54-44.82%\uff09\n5. \u8868\u660e\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7531\u4e8e\u6709\u9650\u7684KU\u8986\u76d6\u800c\u9ad8\u4f30\u4e86LLM\u6027\u80fd", "conclusion": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u5728\u7f16\u7a0b\u6982\u5ff5\u7684\u4ee3\u8868\u6027\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u4e0d\u8db3\uff0c\u5bfc\u81f4\u9ad8\u4f30\u4e86LLM\u7684\u5b9e\u9645\u6027\u80fd\u3002\u63d0\u51fa\u7684\u57fa\u4e8e\u63d0\u793a\u7684LLM\u6846\u67b6\u80fd\u591f\u6709\u6548\u589e\u5f3a\u57fa\u51c6\u6d4b\u8bd5\u7684\u4ee3\u8868\u6027\uff0c\u4e3a\u6784\u5efa\u66f4\u73b0\u5b9e\u7684LLM\u4ee3\u7801\u751f\u6210\u80fd\u529b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002"}}
{"id": "2601.03429", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03429", "abs": "https://arxiv.org/abs/2601.03429", "authors": ["Firas Ben Hmida", "Zain Sbeih", "Philemon Hailemariam", "Birhanu Eshete"], "title": "DeepLeak: Privacy Enhancing Hardening of Model Explanations Against Membership Leakage", "comment": "17 pages, 6 figures, 8 tables. This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (IEEE SaTML 2026)", "summary": "Machine learning (ML) explainability is central to algorithmic transparency in high-stakes settings such as predictive diagnostics and loan approval. However, these same domains require rigorous privacy guaranties, creating tension between interpretability and privacy. Although prior work has shown that explanation methods can leak membership information, practitioners still lack systematic guidance on selecting or deploying explanation techniques that balance transparency with privacy.\n  We present DeepLeak, a system to audit and mitigate privacy risks in post-hoc explanation methods. DeepLeak advances the state-of-the-art in three ways: (1) comprehensive leakage profiling: we develop a stronger explanation-aware membership inference attack (MIA) to quantify how much representative explanation methods leak membership information under default configurations; (2) lightweight hardening strategies: we introduce practical, model-agnostic mitigations, including sensitivity-calibrated noise, attribution clipping, and masking, that substantially reduce membership leakage while preserving explanation utility; and (3) root-cause analysis: through controlled experiments, we pinpoint algorithmic properties (e.g., attribution sparsity and sensitivity) that drive leakage.\n  Evaluating 15 explanation techniques across four families on image benchmarks, DeepLeak shows that default settings can leak up to 74.9% more membership information than previously reported. Our mitigations cut leakage by up to 95% (minimum 46.5%) with only <=3.3% utility loss on average. DeepLeak offers a systematic, reproducible path to safer explainability in privacy-sensitive ML.", "AI": {"tldr": "DeepLeak\u7cfb\u7edf\u7528\u4e8e\u5ba1\u8ba1\u548c\u7f13\u89e3\u540e\u89e3\u91ca\u65b9\u6cd5\u4e2d\u7684\u9690\u79c1\u98ce\u9669\uff0c\u901a\u8fc7\u66f4\u5f3a\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u91cf\u5316\u89e3\u91ca\u65b9\u6cd5\u7684\u6210\u5458\u4fe1\u606f\u6cc4\u9732\uff0c\u63d0\u51fa\u8f7b\u91cf\u7ea7\u7f13\u89e3\u7b56\u7565\u51cf\u5c11\u6cc4\u9732\uff0c\u5e76\u8bc6\u522b\u9a71\u52a8\u6cc4\u9732\u7684\u7b97\u6cd5\u7279\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u5728\u533b\u7597\u8bca\u65ad\u548c\u8d37\u6b3e\u5ba1\u6279\u7b49\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8fd9\u4e9b\u9886\u57df\u540c\u65f6\u9700\u8981\u4e25\u683c\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u5bfc\u81f4\u53ef\u89e3\u91ca\u6027\u4e0e\u9690\u79c1\u4e4b\u95f4\u5b58\u5728\u5f20\u529b\u3002\u73b0\u6709\u7814\u7a76\u663e\u793a\u89e3\u91ca\u65b9\u6cd5\u53ef\u80fd\u6cc4\u9732\u6210\u5458\u4fe1\u606f\uff0c\u4f46\u4ece\u4e1a\u8005\u7f3a\u4e4f\u7cfb\u7edf\u6307\u5bfc\u6765\u9009\u62e9\u6216\u90e8\u7f72\u65e2\u80fd\u4fdd\u6301\u900f\u660e\u5ea6\u53c8\u80fd\u4fdd\u62a4\u9690\u79c1\u7684\u89e3\u91ca\u6280\u672f\u3002", "method": "DeepLeak\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u90e8\u5206\uff1a(1) \u5168\u9762\u7684\u6cc4\u9732\u5206\u6790\uff1a\u5f00\u53d1\u66f4\u5f3a\u7684\u89e3\u91ca\u611f\u77e5\u6210\u5458\u63a8\u7406\u653b\u51fb\u6765\u91cf\u5316\u4ee3\u8868\u6027\u89e3\u91ca\u65b9\u6cd5\u5728\u9ed8\u8ba4\u914d\u7f6e\u4e0b\u7684\u6210\u5458\u4fe1\u606f\u6cc4\u9732\u7a0b\u5ea6\uff1b(2) \u8f7b\u91cf\u7ea7\u52a0\u56fa\u7b56\u7565\uff1a\u5f15\u5165\u5b9e\u7528\u7684\u6a21\u578b\u65e0\u5173\u7f13\u89e3\u63aa\u65bd\uff0c\u5305\u62ec\u7075\u654f\u5ea6\u6821\u51c6\u566a\u58f0\u3001\u5f52\u56e0\u88c1\u526a\u548c\u63a9\u7801\uff0c\u663e\u8457\u51cf\u5c11\u6210\u5458\u6cc4\u9732\u540c\u65f6\u4fdd\u6301\u89e3\u91ca\u6548\u7528\uff1b(3) \u6839\u672c\u539f\u56e0\u5206\u6790\uff1a\u901a\u8fc7\u53d7\u63a7\u5b9e\u9a8c\u786e\u5b9a\u9a71\u52a8\u6cc4\u9732\u7684\u7b97\u6cd5\u7279\u6027\uff08\u5982\u5f52\u56e0\u7a00\u758f\u6027\u548c\u7075\u654f\u5ea6\uff09\u3002", "result": "\u5728\u56fe\u50cf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f3015\u79cd\u89e3\u91ca\u6280\u672f\uff0c\u53d1\u73b0\u9ed8\u8ba4\u8bbe\u7f6e\u4e0b\u7684\u6210\u5458\u4fe1\u606f\u6cc4\u9732\u6bd4\u5148\u524d\u62a5\u544a\u9ad8\u51fa74.9%\u3002\u63d0\u51fa\u7684\u7f13\u89e3\u63aa\u65bd\u5c06\u6cc4\u9732\u51cf\u5c11\u9ad8\u8fbe95%\uff08\u6700\u4f4e46.5%\uff09\uff0c\u5e73\u5747\u6548\u7528\u635f\u5931\u4ec5\u22643.3%\u3002", "conclusion": "DeepLeak\u4e3a\u9690\u79c1\u654f\u611f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u4e00\u6761\u7cfb\u7edf\u3001\u53ef\u590d\u73b0\u7684\u5b89\u5168\u8def\u5f84\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u5728\u4fdd\u6301\u89e3\u91ca\u6548\u7528\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2601.03857", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03857", "abs": "https://arxiv.org/abs/2601.03857", "authors": ["Alessandra Parziale", "Gianmario Voria", "Valeria Pontillo", "Amleto Di Salle", "Patrizio Pelliccione", "Gemma Catolino", "Fabio Palomba"], "title": "Once Upon a Team: Investigating Bias in LLM-Driven Software Team Composition and Task Allocation", "comment": null, "summary": "LLMs are increasingly used to boost productivity and support software engineering tasks. However, when applied to socially sensitive decisions such as team composition and task allocation, they raise concerns of fairness. Prior studies have revealed that LLMs may reproduce stereotypes; however, these analyses remain exploratory and examine sensitive attributes in isolation. This study investigates whether LLMs exhibit bias in team composition and task assignment by analyzing the combined effects of candidates' country and pronouns. Using three LLMs and 3,000 simulated decisions, we find systematic disparities: demographic attributes significantly shaped both selection likelihood and task allocation, even when accounting for expertise-related factors. Task distributions further reflected stereotypes, with technical and leadership roles unevenly assigned across groups. Our findings indicate that LLMs exacerbate demographic inequities in software engineering contexts, underscoring the need for fairness-aware assessment.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u7ec4\u5efa\u548c\u4efb\u52a1\u5206\u914d\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u5019\u9009\u4eba\u7684\u56fd\u5bb6\u548c\u4ee3\u8bcd\u7b49\u4eba\u53e3\u5c5e\u6027\u663e\u8457\u5f71\u54cd\u9009\u62e9\u53ef\u80fd\u6027\u548c\u4efb\u52a1\u5206\u914d\uff0c\u52a0\u5267\u4e86\u4eba\u53e3\u4e0d\u5e73\u7b49\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u63d0\u9ad8\u751f\u4ea7\u529b\u548c\u652f\u6301\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff0c\u4f46\u5f53\u5e94\u7528\u4e8e\u56e2\u961f\u7ec4\u5efa\u548c\u4efb\u52a1\u5206\u914d\u7b49\u793e\u4f1a\u654f\u611f\u51b3\u7b56\u65f6\uff0c\u5f15\u53d1\u4e86\u516c\u5e73\u6027\u62c5\u5fe7\u3002\u5148\u524d\u7814\u7a76\u8868\u660eLLM\u53ef\u80fd\u518d\u73b0\u523b\u677f\u5370\u8c61\uff0c\u4f46\u8fd9\u4e9b\u5206\u6790\u4ecd\u662f\u63a2\u7d22\u6027\u7684\uff0c\u4e14\u5b64\u7acb\u5730\u8003\u5bdf\u654f\u611f\u5c5e\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5019\u9009\u4eba\u56fd\u5bb6\u548c\u4ee3\u8bcd\u7684\u7ec4\u5408\u6548\u5e94\uff0c\u4f7f\u7528\u4e09\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c3000\u4e2a\u6a21\u62df\u51b3\u7b56\uff0c\u7814\u7a76LLM\u5728\u56e2\u961f\u7ec4\u5efa\u548c\u4efb\u52a1\u5206\u914d\u4e2d\u662f\u5426\u5b58\u5728\u504f\u89c1\uff0c\u540c\u65f6\u8003\u8651\u4e86\u4e13\u4e1a\u77e5\u8bc6\u76f8\u5173\u56e0\u7d20\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u6027\u5dee\u5f02\uff1a\u4eba\u53e3\u5c5e\u6027\u663e\u8457\u5f71\u54cd\u9009\u62e9\u53ef\u80fd\u6027\u548c\u4efb\u52a1\u5206\u914d\uff0c\u5373\u4f7f\u8003\u8651\u4e86\u4e13\u4e1a\u77e5\u8bc6\u56e0\u7d20\u3002\u4efb\u52a1\u5206\u5e03\u8fdb\u4e00\u6b65\u53cd\u6620\u4e86\u523b\u677f\u5370\u8c61\uff0c\u6280\u672f\u548c\u9886\u5bfc\u89d2\u8272\u5728\u4e0d\u540c\u7fa4\u4f53\u4e2d\u5206\u914d\u4e0d\u5747\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u73af\u5883\u4e2d\u52a0\u5267\u4e86\u4eba\u53e3\u4e0d\u5e73\u7b49\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u516c\u5e73\u610f\u8bc6\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.03465", "categories": ["cs.CR", "math.GR"], "pdf": "https://arxiv.org/pdf/2601.03465", "abs": "https://arxiv.org/abs/2601.03465", "authors": ["Yevgen Kotukh", "Gennady Khalimov"], "title": "Security Parameter Analysis of the LINEture Post-Quantum Digital Signature Scheme", "comment": null, "summary": "This paper presents a comprehensive cryptographic analysis of the security parameters of the LINEture post-quantum digital signature scheme, which is constructed using matrix algebra over elementary abelian 2-groups. We investigate the influence of three principal parameters. First, the word size m (exhibiting quadratic impact), the second is a vector dimension l, and the third is a number of submatrices in the session key q (exhibiting linear impact) on cryptographic strength. Our analysis reveals a dualistic nature of the parameter l. According to the previous analysis, it does not affect resistance to guessing attacks. A deeper examination of the verification mechanism demonstrates that l establishes a kind of verification barrier of l times m bits. We establish the threshold relationship l less q minus 1 times m, below which parameter l becomes security-critical. The optimal selection rule l near q minus 1 times m is proposed for maximum cryptographic efficiency. Comparative analysis with NIST PQC standards and practical parameter recommendations are provided.", "AI": {"tldr": "\u672c\u6587\u5bf9LINEture\u540e\u91cf\u5b50\u6570\u5b57\u7b7e\u540d\u65b9\u6848\u7684\u5b89\u5168\u53c2\u6570\u8fdb\u884c\u4e86\u5168\u9762\u5bc6\u7801\u5206\u6790\uff0c\u7814\u7a76\u4e86\u4e09\u4e2a\u4e3b\u8981\u53c2\u6570\u5bf9\u5bc6\u7801\u5f3a\u5ea6\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u53c2\u6570l\u7684\u53cc\u91cd\u6027\u8d28\uff0c\u5e76\u63d0\u51fa\u4e86\u6700\u4f18\u53c2\u6570\u9009\u62e9\u89c4\u5219\u3002", "motivation": "LINEture\u662f\u4e00\u79cd\u57fa\u4e8e\u521d\u7b49\u963f\u8d1d\u5c142-\u7fa4\u4e0a\u77e9\u9635\u4ee3\u6570\u7684\u540e\u91cf\u5b50\u6570\u5b57\u7b7e\u540d\u65b9\u6848\uff0c\u9700\u8981\u5bf9\u5176\u5b89\u5168\u53c2\u6570\u8fdb\u884c\u6df1\u5165\u5206\u6790\u4ee5\u8bc4\u4f30\u5176\u5bc6\u7801\u5f3a\u5ea6\uff0c\u7279\u522b\u662f\u53c2\u6570l\u7684\u53cc\u91cd\u6027\u8d28\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "method": "\u91c7\u7528\u5bc6\u7801\u5206\u6790\u65b9\u6cd5\uff0c\u91cd\u70b9\u7814\u7a76\u4e09\u4e2a\u4e3b\u8981\u53c2\u6570\uff1a\u5b57\u5927\u5c0fm\uff08\u4e8c\u6b21\u5f71\u54cd\uff09\u3001\u5411\u91cf\u7ef4\u5ea6l\u548c\u4f1a\u8bdd\u5bc6\u94a5\u4e2d\u5b50\u77e9\u9635\u6570\u91cfq\uff08\u7ebf\u6027\u5f71\u54cd\uff09\u3002\u901a\u8fc7\u6df1\u5165\u5206\u6790\u9a8c\u8bc1\u673a\u5236\uff0c\u5efa\u7acb\u4e86\u53c2\u6570\u95f4\u7684\u9608\u503c\u5173\u7cfb\u3002", "result": "\u5206\u6790\u663e\u793a\u53c2\u6570l\u5177\u6709\u53cc\u91cd\u6027\u8d28\uff1a\u4e0d\u5f71\u54cd\u731c\u6d4b\u653b\u51fb\u62b5\u6297\u6027\uff0c\u4f46\u5728\u9a8c\u8bc1\u673a\u5236\u4e2d\u5efa\u7acbl\u00d7m\u4f4d\u7684\u9a8c\u8bc1\u5c4f\u969c\u3002\u5efa\u7acb\u4e86\u9608\u503c\u5173\u7cfbl < (q-1)\u00d7m\uff0c\u4f4e\u4e8e\u6b64\u9608\u503c\u65f6l\u6210\u4e3a\u5b89\u5168\u5173\u952e\u53c2\u6570\u3002\u63d0\u51fa\u4e86\u6700\u4f18\u9009\u62e9\u89c4\u5219l \u2248 (q-1)\u00d7m\u4ee5\u5b9e\u73b0\u6700\u5927\u5bc6\u7801\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u4e3aLINEture\u540e\u91cf\u5b50\u7b7e\u540d\u65b9\u6848\u63d0\u4f9b\u4e86\u53c2\u6570\u9009\u62e9\u7684\u6307\u5bfc\u539f\u5219\uff0c\u63ed\u793a\u4e86\u53c2\u6570l\u7684\u53cc\u91cd\u5b89\u5168\u4f5c\u7528\uff0c\u5e76\u4e0eNIST PQC\u6807\u51c6\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\uff0c\u63d0\u4f9b\u4e86\u5b9e\u9645\u53c2\u6570\u5efa\u8bae\u3002"}}
{"id": "2601.03537", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03537", "abs": "https://arxiv.org/abs/2601.03537", "authors": ["Di Wu", "Yanyan Zhao", "Xin Lu", "Mingzhe Li", "Bing Qin"], "title": "STAR-S: Improving Safety Alignment through Self-Taught Reasoning on Safety Rules", "comment": "19 pages,4 figures", "summary": "Defending against jailbreak attacks is crucial for the safe deployment of Large Language Models (LLMs). Recent research has attempted to improve safety by training models to reason over safety rules before responding. However, a key issue lies in determining what form of safety reasoning effectively defends against jailbreak attacks, which is difficult to explicitly design or directly obtain. To address this, we propose \\textbf{STAR-S} (\\textbf{S}elf-\\textbf{TA}ught \\textbf{R}easoning based on \\textbf{S}afety rules), a framework that integrates the learning of safety rule reasoning into a self-taught loop. The core of STAR-S involves eliciting reasoning and reflection guided by safety rules, then leveraging fine-tuning to enhance safety reasoning. Repeating this process creates a synergistic cycle. Improvements in the model's reasoning and interpretation of safety rules allow it to produce better reasoning data under safety rule prompts, which is then utilized for further training. Experiments show that STAR-S effectively defends against jailbreak attacks, outperforming baselines. Code is available at: https://github.com/pikepokenew/STAR_S.git.", "AI": {"tldr": "STAR-S\u662f\u4e00\u4e2a\u901a\u8fc7\u81ea\u6211\u6559\u5b66\u5faa\u73af\u5b66\u4e60\u5b89\u5168\u89c4\u5219\u63a8\u7406\u6765\u9632\u5fa1\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u653b\u51fb\u7684\u6846\u67b6", "motivation": "\u73b0\u6709\u7684\u901a\u8fc7\u8bad\u7ec3\u6a21\u578b\u57fa\u4e8e\u5b89\u5168\u89c4\u5219\u8fdb\u884c\u63a8\u7406\u7684\u65b9\u6cd5\u96be\u4ee5\u786e\u5b9a\u4f55\u79cd\u5f62\u5f0f\u7684\u5b89\u5168\u63a8\u7406\u80fd\u6709\u6548\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\uff0c\u8fd9\u5f88\u96be\u660e\u786e\u8bbe\u8ba1\u6216\u76f4\u63a5\u83b7\u5f97", "method": "\u63d0\u51faSTAR-S\u6846\u67b6\uff0c\u5c06\u5b89\u5168\u89c4\u5219\u63a8\u7406\u5b66\u4e60\u6574\u5408\u5230\u81ea\u6211\u6559\u5b66\u5faa\u73af\u4e2d\uff1a\u5728\u5b89\u5168\u89c4\u5219\u6307\u5bfc\u4e0b\u5f15\u51fa\u63a8\u7406\u548c\u53cd\u601d\uff0c\u7136\u540e\u901a\u8fc7\u5fae\u8c03\u589e\u5f3a\u5b89\u5168\u63a8\u7406\u80fd\u529b\uff0c\u91cd\u590d\u6b64\u8fc7\u7a0b\u5f62\u6210\u534f\u540c\u5faa\u73af", "result": "\u5b9e\u9a8c\u8868\u660eSTAR-S\u80fd\u6709\u6548\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "STAR-S\u901a\u8fc7\u81ea\u6211\u6559\u5b66\u5faa\u73af\u5b66\u4e60\u5b89\u5168\u89c4\u5219\u63a8\u7406\uff0c\u4e3a\u9632\u5fa1\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u653b\u51fb\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.03878", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03878", "abs": "https://arxiv.org/abs/2601.03878", "authors": ["Giovanni Rosa", "David Moreno-Lumbreras", "Gregorio Robles", "Jes\u00fas M. Gonz\u00e1lez-Barahona"], "title": "Understanding Specification-Driven Code Generation with LLMs: An Empirical Study Design", "comment": "This paper is a Stage 1 Registered Report. The study protocol and analysis plan were peer reviewed and accepted at SANER 2026 with a Continuity Acceptance (CA) score for Stage 2", "summary": "Large Language Models (LLMs) are increasingly integrated into software development workflows, yet their behavior in structured, specification-driven processes remains poorly understood. This paper presents an empirical study design using CURRANTE, a Visual Studio Code extension that enables a human-in-the-loop workflow for LLM-assisted code generation. The tool guides developers through three sequential stages--Specification, Tests, and Function--allowing them to define requirements, generate and refine test suites, and produce functions that satisfy those tests. Participants will solve medium-difficulty problems from the LiveCodeBench dataset, while the tool records fine-grained interaction logs, effectiveness metrics (e.g., pass rate, all-pass completion), efficiency indicators (e.g., time-to-pass), and iteration behaviors. The study aims to analyze how human intervention in specification and test refinement influences the quality and dynamics of LLM-generated code. The results will provide empirical insights into the design of next-generation development environments that align human reasoning with model-driven code generation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4f7f\u7528CURRANTE\u5de5\u5177\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u4eba\u7c7b\u5728\u89c4\u8303\u548c\u6d4b\u8bd5\u7ec6\u5316\u4e2d\u7684\u5e72\u9884\u5982\u4f55\u5f71\u54cdLLM\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u52a8\u6001\u8fc7\u7a0b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\uff0c\u4f46\u5b83\u4eec\u5728\u7ed3\u6784\u5316\u3001\u89c4\u8303\u9a71\u52a8\u8fc7\u7a0b\u4e2d\u7684\u884c\u4e3a\u4ecd\u7136\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\u3002\u9700\u8981\u7814\u7a76\u4eba\u7c7b\u5728\u89c4\u8303\u548c\u6d4b\u8bd5\u7ec6\u5316\u4e2d\u7684\u5e72\u9884\u5982\u4f55\u5f71\u54cdLLM\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u52a8\u6001\u3002", "method": "\u4f7f\u7528CURRANTE\u5de5\u5177\uff08Visual Studio Code\u6269\u5c55\uff09\u8fdb\u884c\u4eba\u7c7b\u5728\u73af\u5de5\u4f5c\u6d41\u7814\u7a76\u3002\u8be5\u5de5\u5177\u5f15\u5bfc\u5f00\u53d1\u8005\u901a\u8fc7\u4e09\u4e2a\u987a\u5e8f\u9636\u6bb5\uff1a\u89c4\u8303\u5b9a\u4e49\u3001\u6d4b\u8bd5\u751f\u6210\u4e0e\u7ec6\u5316\u3001\u51fd\u6570\u751f\u6210\u3002\u53c2\u4e0e\u8005\u5c06\u89e3\u51b3LiveCodeBench\u6570\u636e\u96c6\u4e2d\u7684\u4e2d\u7b49\u96be\u5ea6\u95ee\u9898\uff0c\u5de5\u5177\u8bb0\u5f55\u7ec6\u7c92\u5ea6\u4ea4\u4e92\u65e5\u5fd7\u3001\u6709\u6548\u6027\u6307\u6807\uff08\u901a\u8fc7\u7387\u3001\u5168\u901a\u8fc7\u5b8c\u6210\u7387\uff09\u3001\u6548\u7387\u6307\u6807\uff08\u901a\u8fc7\u65f6\u95f4\uff09\u548c\u8fed\u4ee3\u884c\u4e3a\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u5c06\u63d0\u4f9b\u4eba\u7c7b\u5e72\u9884\u5bf9LLM\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u548c\u52a8\u6001\u5f71\u54cd\u7684\u5b9e\u8bc1\u6d1e\u5bdf\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u5f00\u53d1\u73af\u5883\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4f9d\u636e\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u4e3a\u8bbe\u8ba1\u80fd\u591f\u534f\u8c03\u4eba\u7c7b\u63a8\u7406\u4e0e\u6a21\u578b\u9a71\u52a8\u4ee3\u7801\u751f\u6210\u7684\u4e0b\u4e00\u4ee3\u5f00\u53d1\u73af\u5883\u63d0\u4f9b\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2601.03504", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.03504", "abs": "https://arxiv.org/abs/2601.03504", "authors": ["Rasmus Erlemann", "Charles Colyer Morris", "Sanjyot Sathe"], "title": "Full-Stack Knowledge Graph and LLM Framework for Post-Quantum Cyber Readiness", "comment": "21 pages, 2 figures", "summary": "The emergence of large-scale quantum computing threatens widely deployed public-key cryptographic systems, creating an urgent need for enterprise-level methods to assess post-quantum (PQ) readiness. While PQ standards are under development, organizations lack scalable and quantitative frameworks for measuring cryptographic exposure and prioritizing migration across complex infrastructures. This paper presents a knowledge graph based framework that models enterprise cryptographic assets, dependencies, and vulnerabilities to compute a unified PQ readiness score. Infrastructure components, cryptographic primitives, certificates, and services are represented as a heterogeneous graph, enabling explicit modeling of dependency-driven risk propagation. PQ exposure is quantified using graph-theoretic risk functionals and attributed across cryptographic domains via Shapley value decomposition. To support scalability and data quality, the framework integrates large language models with human-in-the-loop validation for asset classification and risk attribution. The resulting approach produces explainable, normalized readiness metrics that support continuous monitoring, comparative analysis, and remediation prioritization.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u4f01\u4e1a\u7ea7\u540e\u91cf\u5b50\u5bc6\u7801\u5c31\u7eea\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u8bba\u98ce\u9669\u51fd\u6570\u91cf\u5316\u5bc6\u7801\u66b4\u9732\u98ce\u9669\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u5de5\u9a8c\u8bc1\u5b9e\u73b0\u53ef\u6269\u5c55\u5206\u6790", "motivation": "\u5927\u89c4\u6a21\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u73b0\u6709\u516c\u94a5\u5bc6\u7801\u4f53\u7cfb\uff0c\u4f01\u4e1a\u7f3a\u4e4f\u53ef\u6269\u5c55\u7684\u5b9a\u91cf\u6846\u67b6\u6765\u8bc4\u4f30\u5bc6\u7801\u66b4\u9732\u7a0b\u5ea6\u548c\u4f18\u5148\u8fc1\u79fb\u7b56\u7565", "method": "\u6784\u5efa\u5f02\u6784\u77e5\u8bc6\u56fe\u8c31\u5efa\u6a21\u4f01\u4e1a\u5bc6\u7801\u8d44\u4ea7\u3001\u4f9d\u8d56\u5173\u7cfb\u548c\u6f0f\u6d1e\uff0c\u4f7f\u7528\u56fe\u8bba\u98ce\u9669\u51fd\u6570\u91cf\u5316\u540e\u91cf\u5b50\u66b4\u9732\u98ce\u9669\uff0c\u901a\u8fc7Shapley\u503c\u5206\u89e3\u8de8\u5bc6\u7801\u57df\u5f52\u56e0\u98ce\u9669\uff0c\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u5de5\u9a8c\u8bc1\u786e\u4fdd\u6570\u636e\u8d28\u91cf\u548c\u53ef\u6269\u5c55\u6027", "result": "\u6846\u67b6\u751f\u6210\u53ef\u89e3\u91ca\u3001\u6807\u51c6\u5316\u7684\u5c31\u7eea\u5ea6\u6307\u6807\uff0c\u652f\u6301\u6301\u7eed\u76d1\u63a7\u3001\u6bd4\u8f83\u5206\u6790\u548c\u4fee\u590d\u4f18\u5148\u7ea7\u6392\u5e8f", "conclusion": "\u8be5\u77e5\u8bc6\u56fe\u8c31\u6846\u67b6\u4e3a\u4f01\u4e1a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u5b9a\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u540e\u91cf\u5b50\u5bc6\u7801\u5c31\u7eea\u5ea6\u5e76\u6307\u5bfc\u8fc1\u79fb\u4f18\u5148\u7ea7\u51b3\u7b56"}}
{"id": "2601.03550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03550", "abs": "https://arxiv.org/abs/2601.03550", "authors": ["Zhizhang Fu", "Yuancheng Gu", "Chenkai Hu", "Hanmeng Liu", "Yue Zhang"], "title": "ReEfBench: Quantifying the Reasoning Efficiency of LLMs", "comment": null, "summary": "Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework for the non-intrusive, comprehensive process-centric evaluation of reasoning. (2) Through this lens, we identify four distinct behavioral prototypes and diagnose the failure modes. (3) We examine the impact of inference mode, training strategy, and model scale. Our analysis reveals that extended token generation is not a prerequisite for deep reasoning. Furthermore, we reveal critical constraints: mixing long and short CoT data in training risks in premature saturation and collapse, while distillation into smaller models captures behavioral length but fails to replicate logical efficacy due to intrinsic capacity limits.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u6765\u8bc4\u4f30LLM\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u53d1\u73b0\u6269\u5c55token\u751f\u6210\u5e76\u975e\u6df1\u5ea6\u63a8\u7406\u7684\u5fc5\u8981\u6761\u4ef6\uff0c\u5e76\u63ed\u793a\u4e86\u8bad\u7ec3\u6570\u636e\u6df7\u5408\u548c\u6a21\u578b\u84b8\u998f\u7684\u5173\u952e\u9650\u5236\u3002", "motivation": "\u5f53\u524dCoT\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u533a\u5206\u6027\u80fd\u63d0\u5347\u662f\u6765\u81ea\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\u8fd8\u662f\u4ec5\u4ec5\u6765\u81ea\u66f4\u957f\u7684\u8f93\u51fa\u3002\u9700\u8981\u4e00\u79cd\u975e\u4fb5\u5165\u6027\u3001\u5168\u9762\u7684\u8fc7\u7a0b\u4e2d\u5fc3\u8bc4\u4f30\u65b9\u6cd5\u6765\u6df1\u5165\u7406\u89e3LLM\u7684\u63a8\u7406\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7528\u4e8e\u5bf9\u63a8\u7406\u8fc7\u7a0b\u8fdb\u884c\u975e\u4fb5\u5165\u6027\u3001\u5168\u9762\u7684\u8bc4\u4f30\u3002\u901a\u8fc7\u8fd9\u4e2a\u6846\u67b6\u8bc6\u522b\u4e86\u56db\u79cd\u4e0d\u540c\u7684\u884c\u4e3a\u539f\u578b\uff0c\u5e76\u8bca\u65ad\u4e86\u5931\u8d25\u6a21\u5f0f\u3002\u7814\u7a76\u4e86\u63a8\u7406\u6a21\u5f0f\u3001\u8bad\u7ec3\u7b56\u7565\u548c\u6a21\u578b\u89c4\u6a21\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u6269\u5c55token\u751f\u6210\u5e76\u975e\u6df1\u5ea6\u63a8\u7406\u7684\u5fc5\u8981\u6761\u4ef6\uff1b2\uff09\u8bad\u7ec3\u4e2d\u6df7\u5408\u957f\u77edCoT\u6570\u636e\u53ef\u80fd\u5bfc\u81f4\u8fc7\u65e9\u9971\u548c\u548c\u5d29\u6e83\uff1b3\uff09\u5c06\u5927\u6a21\u578b\u84b8\u998f\u5230\u5c0f\u6a21\u578b\u867d\u7136\u80fd\u590d\u5236\u884c\u4e3a\u957f\u5ea6\uff0c\u4f46\u7531\u4e8e\u5185\u5728\u5bb9\u91cf\u9650\u5236\u65e0\u6cd5\u590d\u5236\u903b\u8f91\u6548\u80fd\u3002", "conclusion": "\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u771f\u6b63\u7406\u89e3LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8bad\u7ec3\u7b56\u7565\u548c\u6a21\u578b\u89c4\u6a21\u5bf9\u63a8\u7406\u884c\u4e3a\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u7b80\u5355\u7684\u957f\u5ea6\u6269\u5c55\u4e0d\u80fd\u7b49\u540c\u4e8e\u6df1\u5ea6\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u3002"}}
{"id": "2601.03988", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03988", "abs": "https://arxiv.org/abs/2601.03988", "authors": ["Nicolas Lacroix", "Mireille Blay-Fornarino", "S\u00e9bastien Mosser", "Frederic Precioso"], "title": "Using Small Language Models to Reverse-Engineer Machine Learning Pipelines Structures", "comment": "SANER 2026 Registered Report", "summary": "Background: Extracting the stages that structure Machine Learning (ML) pipelines from source code is key for gaining a deeper understanding of data science practices. However, the diversity caused by the constant evolution of the ML ecosystem (e.g., algorithms, libraries, datasets) makes this task challenging. Existing approaches either depend on non-scalable, manual labeling, or on ML classifiers that do not properly support the diversity of the domain. These limitations highlight the need for more flexible and reliable solutions.\n  Objective: We evaluate whether Small Language Models (SLMs) can leverage their code understanding and classification abilities to address these limitations, and subsequently how they can advance our understanding of data science practices.\n  Method: We conduct a confirmatory study based on two reference works selected for their relevance regarding current state-of-the-art's limitations. First, we compare several SLMs using Cochran's Q test. The best-performing model is then evaluated against the reference studies using two distinct McNemar's tests. We further analyze how variations in taxonomy definitions affect performance through an additional Cochran's Q test. Finally, a goodness-of-fit analysis is conducted using Pearson's chi-squared tests to compare our insights on data science practices with those from prior studies.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u63d0\u53d6\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u9636\u6bb5\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u9886\u57df\u591a\u6837\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63a8\u8fdb\u5bf9\u6570\u636e\u79d1\u5b66\u5b9e\u8df5\u7684\u7406\u89e3\u3002", "motivation": "\u4ece\u6e90\u4ee3\u7801\u4e2d\u63d0\u53d6\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u9636\u6bb5\u5bf9\u4e8e\u6df1\u5165\u7406\u89e3\u6570\u636e\u79d1\u5b66\u5b9e\u8df5\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u673a\u5668\u5b66\u4e60\u751f\u6001\u7cfb\u7edf\u7684\u4e0d\u65ad\u6f14\u53d8\uff08\u7b97\u6cd5\u3001\u5e93\u3001\u6570\u636e\u96c6\u7b49\uff09\u5e26\u6765\u4e86\u591a\u6837\u6027\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4e0d\u53ef\u6269\u5c55\u7684\u624b\u52a8\u6807\u6ce8\uff0c\u8981\u4e48\u4f7f\u7528\u65e0\u6cd5\u5f88\u597d\u652f\u6301\u9886\u57df\u591a\u6837\u6027\u7684\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u7075\u6d3b\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u9a8c\u8bc1\u6027\u7814\u7a76\u8bbe\u8ba1\uff0c\u57fa\u4e8e\u4e24\u4e2a\u5177\u6709\u4ee3\u8868\u6027\u7684\u53c2\u8003\u5de5\u4f5c\u3002\u9996\u5148\u4f7f\u7528Cochran's Q\u68c0\u9a8c\u6bd4\u8f83\u591a\u4e2aSLMs\uff0c\u9009\u51fa\u6700\u4f73\u6a21\u578b\u3002\u7136\u540e\u901a\u8fc7\u4e24\u4e2a\u72ec\u7acb\u7684McNemar's\u68c0\u9a8c\u5c06\u8be5\u6a21\u578b\u4e0e\u53c2\u8003\u7814\u7a76\u8fdb\u884c\u6bd4\u8f83\u3002\u8fdb\u4e00\u6b65\u901a\u8fc7\u989d\u5916\u7684Cochran's Q\u68c0\u9a8c\u5206\u6790\u5206\u7c7b\u5b9a\u4e49\u53d8\u5316\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002\u6700\u540e\u4f7f\u7528Pearson\u5361\u65b9\u68c0\u9a8c\u8fdb\u884c\u62df\u5408\u4f18\u5ea6\u5206\u6790\uff0c\u5c06\u672c\u7814\u7a76\u5bf9\u6570\u636e\u79d1\u5b66\u5b9e\u8df5\u7684\u89c1\u89e3\u4e0e\u5148\u524d\u7814\u7a76\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63d0\u53d6\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u9636\u6bb5\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u901a\u8fc7\u7edf\u8ba1\u68c0\u9a8c\u6bd4\u8f83\u4e86\u591a\u4e2aSLMs\u7684\u6027\u80fd\uff0c\u5e76\u8bc4\u4f30\u4e86\u6700\u4f73\u6a21\u578b\u76f8\u5bf9\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u52bf\u3002\u540c\u65f6\u5206\u6790\u4e86\u5206\u7c7b\u5b9a\u4e49\u53d8\u5316\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u5c06\u7814\u7a76\u7ed3\u679c\u4e0e\u5148\u524d\u6570\u636e\u79d1\u5b66\u5b9e\u8df5\u7684\u7814\u7a76\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "conclusion": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5229\u7528\u5176\u4ee3\u7801\u7406\u89e3\u548c\u5206\u7c7b\u80fd\u529b\uff0c\u4e3a\u63d0\u53d6\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u9636\u6bb5\u63d0\u4f9b\u66f4\u7075\u6d3b\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ece\u800c\u63a8\u8fdb\u5bf9\u6570\u636e\u79d1\u5b66\u5b9e\u8df5\u7684\u7406\u89e3\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u652f\u6301\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u591a\u6837\u6027\uff0c\u5e76\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u65b0\u7684\u6280\u672f\u9014\u5f84\u3002"}}
{"id": "2601.03508", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.03508", "abs": "https://arxiv.org/abs/2601.03508", "authors": ["Zhuohan Cui", "Qianqian Lang", "Zikun Song"], "title": "A Critical Analysis of the Medibank Health Data Breach and Differential Privacy Solutions", "comment": null, "summary": "This paper critically examines the 2022 Medibank health insurance data breach, which exposed sensitive medical records of 9.7 million individuals due to unencrypted storage, centralized access, and the absence of privacy-preserving analytics. To address these vulnerabilities, we propose an entropy-aware differential privacy (DP) framework that integrates Laplace and Gaussian mechanisms with adaptive budget allocation. The design incorporates TLS-encrypted database access, field-level mechanism selection, and smooth sensitivity models to mitigate re-identification risks. Experimental validation was conducted using synthetic Medibank datasets (N = 131,000) with entropy-calibrated DP mechanisms, where high-entropy attributes received stronger noise injection. Results demonstrate a 90.3% reduction in re-identification probability while maintaining analytical utility loss below 24%. The framework further aligns with GDPR Article 32 and Australian Privacy Principle 11.1, ensuring regulatory compliance. By combining rigorous privacy guarantees with practical usability, this work contributes a scalable and technically feasible solution for healthcare data protection, offering a pathway toward resilient, trustworthy, and regulation-ready medical analytics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u71b5\u611f\u77e5\u5dee\u5206\u9690\u79c1\u7684\u533b\u7597\u6570\u636e\u4fdd\u62a4\u6846\u67b6\uff0c\u9488\u5bf9Medibank\u6570\u636e\u6cc4\u9732\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9884\u7b97\u5206\u914d\u548c\u52a0\u5bc6\u8bbf\u95ee\u673a\u5236\uff0c\u5728\u964d\u4f4e91%\u91cd\u8bc6\u522b\u98ce\u9669\u7684\u540c\u65f6\u4fdd\u6301\u5206\u6790\u6548\u7528\u635f\u5931\u4f4e\u4e8e24%\u3002", "motivation": "\u9488\u5bf92022\u5e74Medibank\u5065\u5eb7\u4fdd\u9669\u6570\u636e\u6cc4\u9732\u4e8b\u4ef6\u66b4\u9732\u7684\u95ee\u9898\uff1a970\u4e07\u4e2a\u4eba\u654f\u611f\u533b\u7597\u8bb0\u5f55\u56e0\u672a\u52a0\u5bc6\u5b58\u50a8\u3001\u96c6\u4e2d\u8bbf\u95ee\u548c\u7f3a\u4e4f\u9690\u79c1\u4fdd\u62a4\u5206\u6790\u800c\u6cc4\u9732\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u63d0\u51fa\u71b5\u611f\u77e5\u5dee\u5206\u9690\u79c1\u6846\u67b6\uff0c\u6574\u5408\u62c9\u666e\u62c9\u65af\u548c\u9ad8\u65af\u673a\u5236\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u9884\u7b97\u5206\u914d\u3002\u8bbe\u8ba1\u5305\u62ecTLS\u52a0\u5bc6\u6570\u636e\u5e93\u8bbf\u95ee\u3001\u5b57\u6bb5\u7ea7\u673a\u5236\u9009\u62e9\u548c\u5e73\u6ed1\u654f\u611f\u6027\u6a21\u578b\uff0c\u9ad8\u71b5\u5c5e\u6027\u83b7\u5f97\u66f4\u5f3a\u7684\u566a\u58f0\u6ce8\u5165\u3002", "result": "\u4f7f\u7528\u5408\u6210Medibank\u6570\u636e\u96c6\uff08N=131,000\uff09\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u91cd\u8bc6\u522b\u6982\u7387\u964d\u4f4e90.3%\uff0c\u540c\u65f6\u5206\u6790\u6548\u7528\u635f\u5931\u4fdd\u6301\u572824%\u4ee5\u4e0b\u3002\u6846\u67b6\u7b26\u5408GDPR\u7b2c32\u6761\u548c\u6fb3\u5927\u5229\u4e9a\u9690\u79c1\u539f\u521911.1\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u7ed3\u5408\u4e25\u683c\u7684\u9690\u79c1\u4fdd\u8bc1\u548c\u5b9e\u9645\u53ef\u7528\u6027\uff0c\u4e3a\u533b\u7597\u6570\u636e\u4fdd\u62a4\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u6280\u672f\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u5f39\u6027\u3001\u53ef\u4fe1\u4e14\u7b26\u5408\u6cd5\u89c4\u7684\u533b\u7597\u5206\u6790\u63d0\u4f9b\u4e86\u8def\u5f84\u3002"}}
{"id": "2601.03587", "categories": ["cs.CR", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.03587", "abs": "https://arxiv.org/abs/2601.03587", "authors": ["Kelvin Uzoma Echenim", "Karuna Pande Joshi"], "title": "Deontic Knowledge Graphs for Privacy Compliance in Multimodal Disaster Data Sharing", "comment": null, "summary": "Disaster response requires sharing heterogeneous artifacts, from tabular assistance records to UAS imagery, under overlapping privacy mandates. Operational systems often reduce compliance to binary access control, which is brittle in time-critical workflows. We present a novel deontic knowledge graph-based framework that integrates a Disaster Management Knowledge Graph (DKG) with a Policy Knowledge Graph (PKG) derived from IoT-Reg and FEMA/DHS privacy drivers. Our release decision function supports three outcomes: Allow, Block, and Allow-with-Transform. The latter binds obligations to transforms and verifies post-transform compliance via provenance-linked derived artifacts; blocked requests are logged as semantic privacy incidents. Evaluation on a 5.1M-triple DKG with 316K images shows exact-match decision correctness, sub-second per-decision latency, and interactive query performance across both single-graph and federated workloads.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e49\u52a1\u77e5\u8bc6\u56fe\u8c31\u7684\u707e\u5bb3\u54cd\u5e94\u6570\u636e\u5171\u4eab\u6846\u67b6\uff0c\u6574\u5408\u707e\u5bb3\u7ba1\u7406\u77e5\u8bc6\u56fe\u8c31\u4e0e\u653f\u7b56\u77e5\u8bc6\u56fe\u8c31\uff0c\u652f\u6301\u5141\u8bb8\u3001\u963b\u6b62\u3001\u5141\u8bb8\u4f46\u8f6c\u6362\u4e09\u79cd\u51b3\u7b56\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u9690\u79c1\u5408\u89c4\u63a7\u5236\u3002", "motivation": "\u707e\u5bb3\u54cd\u5e94\u9700\u8981\u5171\u4eab\u5f02\u6784\u6570\u636e\uff08\u8868\u683c\u8bb0\u5f55\u3001\u65e0\u4eba\u673a\u56fe\u50cf\u7b49\uff09\uff0c\u4f46\u9762\u4e34\u91cd\u53e0\u7684\u9690\u79c1\u6cd5\u89c4\u8981\u6c42\u3002\u73b0\u6709\u7cfb\u7edf\u901a\u5e38\u91c7\u7528\u4e8c\u5143\u8bbf\u95ee\u63a7\u5236\uff0c\u5728\u65f6\u95f4\u5173\u952e\u7684\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u8fc7\u4e8e\u8106\u5f31\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u5408\u89c4\u673a\u5236\u3002", "method": "\u6784\u5efa\u707e\u5bb3\u7ba1\u7406\u77e5\u8bc6\u56fe\u8c31\uff08DKG\uff09\u4e0e\u653f\u7b56\u77e5\u8bc6\u56fe\u8c31\uff08PKG\uff09\uff0c\u57fa\u4e8eIoT-Reg\u548cFEMA/DHS\u9690\u79c1\u9a71\u52a8\u3002\u63d0\u51fa\u91ca\u653e\u51b3\u7b56\u51fd\u6570\uff0c\u652f\u6301\u4e09\u79cd\u7ed3\u679c\uff1a\u5141\u8bb8\u3001\u963b\u6b62\u3001\u5141\u8bb8\u4f46\u8f6c\u6362\uff08\u7ed1\u5b9a\u8f6c\u6362\u4e49\u52a1\u5e76\u901a\u8fc7\u6eaf\u6e90\u9a8c\u8bc1\u5408\u89c4\u6027\uff09\u3002", "result": "\u5728\u5305\u542b510\u4e07\u4e09\u5143\u7ec4DKG\u548c31.6\u4e07\u56fe\u50cf\u7684\u6d4b\u8bd5\u4e2d\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u5339\u914d\u51b3\u7b56\u6b63\u786e\u6027\u3001\u4e9a\u79d2\u7ea7\u5355\u51b3\u7b56\u5ef6\u8fdf\uff0c\u4ee5\u53ca\u5728\u5355\u56fe\u548c\u8054\u90a6\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u4ea4\u4e92\u5f0f\u67e5\u8be2\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u6574\u5408\u4e0e\u7ec6\u7c92\u5ea6\u51b3\u7b56\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u707e\u5bb3\u54cd\u5e94\u4e2d\u5f02\u6784\u6570\u636e\u5171\u4eab\u7684\u9690\u79c1\u5408\u89c4\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u4e8c\u5143\u8bbf\u95ee\u63a7\u5236\u66f4\u7075\u6d3b\u3001\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.03595", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03595", "abs": "https://arxiv.org/abs/2601.03595", "authors": ["Yi Fang", "Wenjie Wang", "Mingfeng Xue", "Boyi Deng", "Fengli Xu", "Dayiheng Liu", "Fuli Feng"], "title": "Controllable LLM Reasoning via Sparse Autoencoder-Based Steering", "comment": "Under Review", "summary": "Large Reasoning Models (LRMs) exhibit human-like cognitive reasoning strategies (e.g. backtracking, cross-verification) during reasoning process, which improves their performance on complex tasks. Currently, reasoning strategies are autonomously selected by LRMs themselves. However, such autonomous selection often produces inefficient or even erroneous reasoning paths. To make reasoning more reliable and flexible, it is important to develop methods for controlling reasoning strategies. Existing methods struggle to control fine-grained reasoning strategies due to conceptual entanglement in LRMs' hidden states. To address this, we leverage Sparse Autoencoders (SAEs) to decompose strategy-entangled hidden states into a disentangled feature space. To identify the few strategy-specific features from the vast pool of SAE features, we propose SAE-Steering, an efficient two-stage feature identification pipeline. SAE-Steering first recalls features that amplify the logits of strategy-specific keywords, filtering out over 99\\% of features, and then ranks the remaining features by their control effectiveness. Using the identified strategy-specific features as control vectors, SAE-Steering outperforms existing methods by over 15\\% in control effectiveness. Furthermore, controlling reasoning strategies can redirect LRMs from erroneous paths to correct ones, achieving a 7\\% absolute accuracy improvement.", "AI": {"tldr": "\u63d0\u51faSAE-Steering\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5206\u89e3\u63a8\u7406\u7b56\u7565\u7ea0\u7f20\u7684\u9690\u85cf\u72b6\u6001\uff0c\u5e76\u8bc6\u522b\u7b56\u7565\u7279\u5b9a\u7279\u5f81\u4f5c\u4e3a\u63a7\u5236\u5411\u91cf\uff0c\u5b9e\u73b0\u5bf9\u5927\u578b\u63a8\u7406\u6a21\u578b\u63a8\u7406\u7b56\u7565\u7684\u6709\u6548\u63a7\u5236\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u867d\u7136\u80fd\u81ea\u4e3b\u9009\u62e9\u63a8\u7406\u7b56\u7565\uff0c\u4f46\u8fd9\u79cd\u81ea\u4e3b\u9009\u62e9\u5e38\u4ea7\u751f\u4f4e\u6548\u751a\u81f3\u9519\u8bef\u7684\u63a8\u7406\u8def\u5f84\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u63a7\u5236\u7ec6\u7c92\u5ea6\u63a8\u7406\u7b56\u7565\uff0c\u56e0\u4e3a\u7b56\u7565\u6982\u5ff5\u5728\u9690\u85cf\u72b6\u6001\u4e2d\u7ea0\u7f20\u5728\u4e00\u8d77\u3002", "method": "\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5c06\u7b56\u7565\u7ea0\u7f20\u7684\u9690\u85cf\u72b6\u6001\u5206\u89e3\u4e3a\u89e3\u7f20\u7684\u7279\u5f81\u7a7a\u95f4\uff0c\u63d0\u51faSAE-Steering\u4e24\u9636\u6bb5\u7279\u5f81\u8bc6\u522b\u6d41\u7a0b\uff1a\u9996\u5148\u901a\u8fc7\u653e\u5927\u7b56\u7565\u7279\u5b9a\u5173\u952e\u8bcd\u7684logits\u53ec\u56de\u7279\u5f81\uff08\u8fc7\u6ee499%\u4ee5\u4e0a\u7279\u5f81\uff09\uff0c\u7136\u540e\u6309\u63a7\u5236\u6548\u679c\u5bf9\u5269\u4f59\u7279\u5f81\u6392\u5e8f\u3002", "result": "SAE-Steering\u5728\u63a7\u5236\u6548\u679c\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u8d85\u8fc715%\u3002\u901a\u8fc7\u63a7\u5236\u63a8\u7406\u7b56\u7565\uff0c\u80fd\u5c06\u6a21\u578b\u4ece\u9519\u8bef\u8def\u5f84\u91cd\u5b9a\u5411\u5230\u6b63\u786e\u8def\u5f84\uff0c\u5b9e\u73b07%\u7684\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u5347\u3002", "conclusion": "SAE-Steering\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u548c\u63a7\u5236\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u7b56\u7565\uff0c\u63d0\u9ad8\u63a8\u7406\u7684\u53ef\u9760\u6027\u548c\u7075\u6d3b\u6027\uff0c\u4e3a\u6a21\u578b\u53ef\u63a7\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.04124", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04124", "abs": "https://arxiv.org/abs/2601.04124", "authors": ["Lloyd Montgomery", "Clara L\u00fcders", "Christian Rahe", "Walid Maalej"], "title": "Smells Depend on the Context: An Interview Study of Issue Tracking Problems and Smells in Practice", "comment": "30 pages, 1 figure, accepted at the ACM TOSEM journal", "summary": "Issue Tracking Systems (ITSs) enable software developers and managers to collect and resolve issues collaboratively. While researchers have extensively analysed ITS data to automate or assist specific activities such as issue assignments, duplicate detection, or priority prediction, developer studies on ITSs remain rare. Particularly, little is known about the challenges Software Engineering (SE) teams encounter in ITSs and when certain practices and workarounds (such as leaving issue fields like \"priority\" empty) are considered problematic. To fill this gap, we conducted an in-depth interview study with 26 experienced SE practitioners from different organisations and industries. We asked them about general problems encountered, as well as the relevance of 31 ITS smells (aka potentially problematic practices) discussed in the literature. By applying Thematic Analysis to the interview notes, we identified 14 common problems including issue findability, zombie issues, workflow bloat, and lack of workflow enforcement. Participants also stated that many of the ITS smells do not occur or are not problematic. Our results suggest that ITS problems and smells are highly dependent on context factors such as ITS configuration, workflow stage, and team size. We also discuss potential tooling solutions to configure, monitor, and visualise ITS smells to cope with these challenges.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u8bbf\u8c0826\u4f4d\u8f6f\u4ef6\u5de5\u7a0b\u4ece\u4e1a\u8005\uff0c\u8bc6\u522b\u4e86\u95ee\u9898\u8ddf\u8e2a\u7cfb\u7edf\u4e2d\u768414\u4e2a\u5e38\u89c1\u95ee\u9898\uff0c\u5e76\u8bc4\u4f30\u4e8631\u79cd\u6587\u732e\u4e2d\u8ba8\u8bba\u7684ITS\u5f02\u5473\uff08\u6f5c\u5728\u95ee\u9898\u5b9e\u8df5\uff09\u7684\u5b9e\u9645\u76f8\u5173\u6027\uff0c\u53d1\u73b0\u8bb8\u591a\u5f02\u5473\u5728\u5b9e\u8df5\u4e2d\u5e76\u4e0d\u51fa\u73b0\u6216\u4e0d\u6784\u6210\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1\u95ee\u9898\u8ddf\u8e2a\u7cfb\u7edf\uff08ITS\uff09\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u7814\u7a76\u4eba\u5458\u4e5f\u5bf9\u5176\u6570\u636e\u8fdb\u884c\u4e86\u5927\u91cf\u5206\u6790\u4ee5\u81ea\u52a8\u5316\u6216\u8f85\u52a9\u7279\u5b9a\u6d3b\u52a8\uff0c\u4f46\u5bf9ITS\u4e2d\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u9762\u4e34\u7684\u6311\u6218\u4ee5\u53ca\u67d0\u4e9b\u5b9e\u8df5\u548c\u5de5\u4f5c\u65b9\u5f0f\uff08\u5982\u7559\u7a7a\"\u4f18\u5148\u7ea7\"\u7b49\u5b57\u6bb5\uff09\u4f55\u65f6\u88ab\u89c6\u4e3a\u95ee\u9898\u7684\u7814\u7a76\u4ecd\u7136\u5f88\u5c11\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u8bbf\u8c08\u7814\u7a76\u65b9\u6cd5\uff0c\u91c7\u8bbf\u4e86\u6765\u81ea\u4e0d\u540c\u7ec4\u7ec7\u548c\u884c\u4e1a\u768426\u4f4d\u7ecf\u9a8c\u4e30\u5bcc\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4ece\u4e1a\u8005\uff0c\u8be2\u95ee\u4ed6\u4eec\u9047\u5230\u7684\u4e00\u822c\u95ee\u9898\u4ee5\u53ca\u6587\u732e\u4e2d\u8ba8\u8bba\u768431\u79cdITS\u5f02\u5473\uff08\u6f5c\u5728\u95ee\u9898\u5b9e\u8df5\uff09\u7684\u76f8\u5173\u6027\uff0c\u7136\u540e\u5bf9\u8bbf\u8c08\u8bb0\u5f55\u5e94\u7528\u4e3b\u9898\u5206\u6790\u3002", "result": "\u8bc6\u522b\u4e8614\u4e2a\u5e38\u89c1\u95ee\u9898\uff0c\u5305\u62ec\u95ee\u9898\u53ef\u67e5\u627e\u6027\u3001\u50f5\u5c38\u95ee\u9898\u3001\u5de5\u4f5c\u6d41\u7a0b\u81c3\u80bf\u548c\u7f3a\u4e4f\u5de5\u4f5c\u6d41\u7a0b\u6267\u884c\u7b49\u3002\u53c2\u4e0e\u8005\u8fd8\u8868\u793a\uff0c\u8bb8\u591aITS\u5f02\u5473\u5728\u5b9e\u9645\u4e2d\u5e76\u4e0d\u51fa\u73b0\u6216\u4e0d\u6784\u6210\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0ITS\u95ee\u9898\u548c\u5f02\u5473\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u4e0a\u4e0b\u6587\u56e0\u7d20\uff0c\u5982ITS\u914d\u7f6e\u3001\u5de5\u4f5c\u6d41\u7a0b\u9636\u6bb5\u548c\u56e2\u961f\u89c4\u6a21\u3002", "conclusion": "ITS\u95ee\u9898\u548c\u5f02\u5473\u5177\u6709\u9ad8\u5ea6\u60c5\u5883\u4f9d\u8d56\u6027\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u4e0a\u4e0b\u6587\u8fdb\u884c\u8bc4\u4f30\u3002\u7814\u7a76\u8ba8\u8bba\u4e86\u6f5c\u5728\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u914d\u7f6e\u3001\u76d1\u63a7\u548c\u53ef\u89c6\u5316ITS\u5f02\u5473\u7684\u5de5\u5177\uff0c\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002"}}
{"id": "2601.03594", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.03594", "abs": "https://arxiv.org/abs/2601.03594", "authors": ["Zejian Chen", "Chaozhuo Li", "Chao Li", "Xi Zhang", "Litian Zhang", "Yiming He"], "title": "Jailbreaking LLMs & VLMs: Mechanisms, Evaluation, and Unified Defense", "comment": null, "summary": "This paper provides a systematic survey of jailbreak attacks and defenses on Large Language Models (LLMs) and Vision-Language Models (VLMs), emphasizing that jailbreak vulnerabilities stem from structural factors such as incomplete training data, linguistic ambiguity, and generative uncertainty. It further differentiates between hallucinations and jailbreaks in terms of intent and triggering mechanisms. We propose a three-dimensional survey framework: (1) Attack dimension-including template/encoding-based, in-context learning manipulation, reinforcement/adversarial learning, LLM-assisted and fine-tuned attacks, as well as prompt- and image-level perturbations and agent-based transfer in VLMs; (2) Defense dimension-encompassing prompt-level obfuscation, output evaluation, and model-level alignment or fine-tuning; and (3) Evaluation dimension-covering metrics such as Attack Success Rate (ASR), toxicity score, query/time cost, and multimodal Clean Accuracy and Attribute Success Rate. Compared with prior works, this survey spans the full spectrum from text-only to multimodal settings, consolidating shared mechanisms and proposing unified defense principles: variant-consistency and gradient-sensitivity detection at the perception layer, safety-aware decoding and output review at the generation layer, and adversarially augmented preference alignment at the parameter layer. Additionally, we summarize existing multimodal safety benchmarks and discuss future directions, including automated red teaming, cross-modal collaborative defense, and standardized evaluation.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u8d8a\u72f1\u653b\u51fb\u4e0e\u9632\u5fa1\uff0c\u63d0\u51fa\u4e86\u4e09\u7ef4\u5206\u6790\u6846\u67b6\uff08\u653b\u51fb\u3001\u9632\u5fa1\u3001\u8bc4\u4f30\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u9632\u5fa1\u539f\u5219\u3002", "motivation": "\u8d8a\u72f1\u6f0f\u6d1e\u6e90\u4e8e\u7ed3\u6784\u6027\u56e0\u7d20\uff08\u4e0d\u5b8c\u6574\u8bad\u7ec3\u6570\u636e\u3001\u8bed\u8a00\u6b67\u4e49\u3001\u751f\u6210\u4e0d\u786e\u5b9a\u6027\uff09\uff0c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u4ece\u7eaf\u6587\u672c\u5230\u591a\u6a21\u6001\u73af\u5883\u7684\u5168\u9762\u5206\u6790\uff0c\u9700\u8981\u7edf\u4e00\u7684\u9632\u5fa1\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e09\u7ef4\u8c03\u67e5\u6846\u67b6\uff1a1)\u653b\u51fb\u7ef4\u5ea6\uff08\u6a21\u677f/\u7f16\u7801\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u64cd\u7eb5\u3001\u5f3a\u5316/\u5bf9\u6297\u5b66\u4e60\u3001LLM\u8f85\u52a9\u3001\u5fae\u8c03\u653b\u51fb\u7b49\uff09\uff1b2)\u9632\u5fa1\u7ef4\u5ea6\uff08\u63d0\u793a\u7ea7\u6df7\u6dc6\u3001\u8f93\u51fa\u8bc4\u4f30\u3001\u6a21\u578b\u7ea7\u5bf9\u9f50\uff09\uff1b3)\u8bc4\u4f30\u7ef4\u5ea6\uff08\u653b\u51fb\u6210\u529f\u7387\u3001\u6bd2\u6027\u5206\u6570\u3001\u67e5\u8be2/\u65f6\u95f4\u6210\u672c\u7b49\uff09\u3002", "result": "\u533a\u5206\u4e86\u5e7b\u89c9\u4e0e\u8d8a\u72f1\u7684\u610f\u56fe\u548c\u89e6\u53d1\u673a\u5236\uff0c\u6574\u5408\u4e86\u5171\u4eab\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u9632\u5fa1\u539f\u5219\uff1a\u611f\u77e5\u5c42\u7684\u53d8\u4f53\u4e00\u81f4\u6027\u548c\u68af\u5ea6\u654f\u611f\u6027\u68c0\u6d4b\u3001\u751f\u6210\u5c42\u7684\u5b89\u5168\u611f\u77e5\u89e3\u7801\u548c\u8f93\u51fa\u5ba1\u67e5\u3001\u53c2\u6570\u5c42\u7684\u5bf9\u6297\u589e\u5f3a\u504f\u597d\u5bf9\u9f50\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4ece\u7eaf\u6587\u672c\u5230\u591a\u6a21\u6001\u73af\u5883\u7684\u5168\u9762\u8d8a\u72f1\u653b\u51fb\u4e0e\u9632\u5fa1\u7efc\u8ff0\uff0c\u603b\u7ed3\u4e86\u73b0\u6709\u591a\u6a21\u6001\u5b89\u5168\u57fa\u51c6\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u65b9\u5411\uff08\u81ea\u52a8\u7ea2\u961f\u3001\u8de8\u6a21\u6001\u534f\u540c\u9632\u5fa1\u3001\u6807\u51c6\u5316\u8bc4\u4f30\uff09\u3002"}}
{"id": "2601.03624", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03624", "abs": "https://arxiv.org/abs/2601.03624", "authors": ["Zoran Milosevic", "Fethi Rabhi"], "title": "Architecting Agentic Communities using Design Patterns", "comment": "supplementary material accompanying this paper is also attached .. its title is \"Complete Agentic AI Design Patterns Catalogue\"", "summary": "The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures). We focus on Agentic Communities - coordination frameworks encompassing LLM Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications. Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems. This approach provides both practical guidance and formal verification capabilities, enabling expression of organizational, legal, and ethical rules through accountability mechanisms that ensure operational and verifiable governance of inter-agent communication, negotiation, and intent modeling. We validate this framework through a clinical trial matching case study. Our goal is to provide actionable guidance to practitioners while maintaining the formal rigor essential for enterprise deployment in dynamic, multi-agent ecosystems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u4f01\u4e1a\u5206\u5e03\u5f0f\u7cfb\u7edf\u6807\u51c6\u3001\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u884c\u4e1a\u5b9e\u8df5\u7684AI\u667a\u80fd\u4f53\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5206\u4e3aLLM\u667a\u80fd\u4f53\u3001Agentic AI\u548c\u667a\u80fd\u4f53\u793e\u533a\u4e09\u4e2a\u5c42\u6b21\uff0c\u91cd\u70b9\u5173\u6ce8\u667a\u80fd\u4f53\u793e\u533a\u4f5c\u4e3a\u4f01\u4e1a\u5e94\u7528\u7684\u6838\u5fc3\u534f\u8c03\u6846\u67b6\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u548c\u667a\u80fd\u4f53AI\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u67b6\u6784\u6307\u5bfc\u6765\u6784\u5efa\u590d\u6742\u7684\u751f\u4ea7\u7ea7\u7cfb\u7edf\u3002\u5f53\u524d\u7f3a\u4e4f\u7ed3\u5408\u5b9e\u8df5\u6307\u5bfc\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u67b6\u6784\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u591a\u667a\u80fd\u4f53\u534f\u8c03\u548c\u4f01\u4e1a\u5e94\u7528\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51fa\u4e09\u5c42\u8bbe\u8ba1\u6a21\u5f0f\u5206\u7c7b\uff1aLLM\u667a\u80fd\u4f53\uff08\u4efb\u52a1\u7279\u5b9a\u81ea\u52a8\u5316\uff09\u3001Agentic AI\uff08\u81ea\u9002\u5e94\u76ee\u6807\u5bfb\u6c42\u8005\uff09\u3001\u667a\u80fd\u4f53\u793e\u533a\uff08\u7ec4\u7ec7\u6846\u67b6\uff0cAI\u667a\u80fd\u4f53\u4e0e\u4eba\u7c7b\u901a\u8fc7\u6b63\u5f0f\u89d2\u8272\u3001\u534f\u8bae\u548c\u6cbb\u7406\u7ed3\u6784\u534f\u8c03\uff09\u3002\u57fa\u4e8e\u5206\u5e03\u5f0f\u7cfb\u7edf\u534f\u8c03\u539f\u5219\uff0c\u5efa\u7acb\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u4f5c\u534f\u8bae\u89c4\u8303AI\u667a\u80fd\u4f53\u4e0e\u4eba\u7c7b\u5728\u6cbb\u7406\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u89d2\u8272\u3002", "result": "\u5efa\u7acb\u4e86\u7ed3\u5408\u5b9e\u8df5\u6307\u5bfc\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u80fd\u529b\u7684\u67b6\u6784\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u95ee\u8d23\u673a\u5236\u8868\u8fbe\u7ec4\u7ec7\u3001\u6cd5\u5f8b\u548c\u4f26\u7406\u89c4\u5219\uff0c\u786e\u4fdd\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u3001\u534f\u5546\u548c\u610f\u56fe\u5efa\u6a21\u7684\u53ef\u64cd\u4f5c\u548c\u53ef\u9a8c\u8bc1\u6cbb\u7406\u3002\u901a\u8fc7\u4e34\u5e8a\u8bd5\u9a8c\u5339\u914d\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u540c\u65f6\u4fdd\u6301\u4f01\u4e1a\u90e8\u7f72\u5728\u52a8\u6001\u591a\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u4e2d\u6240\u5fc5\u9700\u7684\u5f62\u5f0f\u5316\u4e25\u8c28\u6027\uff0c\u586b\u8865\u4e86\u667a\u80fd\u4f53AI\u7cfb\u7edf\u67b6\u6784\u6307\u5bfc\u7684\u7a7a\u767d\u3002"}}
{"id": "2601.03923", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.03923", "abs": "https://arxiv.org/abs/2601.03923", "authors": ["Homayoun Maleki", "Nekane Sainz", "Jon Legarda"], "title": "Human Challenge Oracle: Designing AI-Resistant, Identity-Bound, Time-Limited Tasks for Sybil-Resistant Consensus", "comment": "21 pages, 4 tables. Initial preprint", "summary": "Sybil attacks remain a fundamental obstacle in open online systems, where adversaries can cheaply create and sustain large numbers of fake identities. Existing defenses, including CAPTCHAs and one-time proof-of-personhood mechanisms, primarily address identity creation and provide limited protection against long-term, large-scale Sybil participation, especially as automated solvers and AI systems continue to improve.\n  We introduce the Human Challenge Oracle (HCO), a new security primitive for continuous, rate-limited human verification. HCO issues short, time-bound challenges that are cryptographically bound to individual identities and must be solved in real time. The core insight underlying HCO is that real-time human cognitive effort, such as perception, attention, and interactive reasoning, constitutes a scarce resource that is inherently difficult to parallelize or amortize across identities.\n  We formalize the design goals and security properties of HCO and show that, under explicit and mild assumptions, sustaining s active identities incurs a cost that grows linearly with s in every time window. We further describe abstract classes of admissible challenges and concrete browser-based instantiations, and present an initial empirical study illustrating that these challenges are easily solvable by humans within seconds while remaining difficult for contemporary automated systems under strict time constraints.", "AI": {"tldr": "HCO\u662f\u4e00\u79cd\u65b0\u7684\u5b89\u5168\u539f\u8bed\uff0c\u901a\u8fc7\u5b9e\u65f6\u3001\u9650\u901f\u7684\u4eba\u7c7b\u9a8c\u8bc1\u6765\u5bf9\u6297Sybil\u653b\u51fb\uff0c\u5229\u7528\u4eba\u7c7b\u8ba4\u77e5\u52aa\u529b\u4f5c\u4e3a\u96be\u4ee5\u5e76\u884c\u5316\u7684\u7a00\u7f3a\u8d44\u6e90", "motivation": "\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\uff08\u5982CAPTCHA\u548c\u4e00\u6b21\u6027\u4eba\u683c\u8bc1\u660e\u673a\u5236\uff09\u4e3b\u8981\u89e3\u51b3\u8eab\u4efd\u521b\u5efa\u95ee\u9898\uff0c\u5bf9\u957f\u671f\u3001\u5927\u89c4\u6a21\u7684Sybil\u53c2\u4e0e\u63d0\u4f9b\u6709\u9650\u4fdd\u62a4\uff0c\u7279\u522b\u662f\u968f\u7740\u81ea\u52a8\u5316\u6c42\u89e3\u5668\u548cAI\u7cfb\u7edf\u7684\u4e0d\u65ad\u6539\u8fdb", "method": "\u5f15\u5165\u4eba\u7c7b\u6311\u6218\u9884\u8a00\u673a\uff08HCO\uff09\uff0c\u53d1\u5e03\u4e0e\u4e2a\u4f53\u8eab\u4efd\u52a0\u5bc6\u7ed1\u5b9a\u7684\u77ed\u671f\u3001\u65f6\u95f4\u9650\u5236\u7684\u6311\u6218\uff0c\u5fc5\u987b\u5728\u5b9e\u65f6\u89e3\u51b3\u3002\u6838\u5fc3\u6d1e\u5bdf\u662f\u5b9e\u65f6\u4eba\u7c7b\u8ba4\u77e5\u52aa\u529b\uff08\u5982\u611f\u77e5\u3001\u6ce8\u610f\u529b\u548c\u4ea4\u4e92\u63a8\u7406\uff09\u6784\u6210\u96be\u4ee5\u5e76\u884c\u5316\u6216\u8de8\u8eab\u4efd\u5206\u644a\u7684\u7a00\u7f3a\u8d44\u6e90", "result": "\u5728\u660e\u786e\u4e14\u6e29\u548c\u7684\u5047\u8bbe\u4e0b\uff0c\u7ef4\u6301s\u4e2a\u6d3b\u8dc3\u8eab\u4efd\u7684\u6210\u672c\u5728\u6bcf\u4e2a\u65f6\u95f4\u7a97\u53e3\u5185\u968fs\u7ebf\u6027\u589e\u957f\u3002\u5177\u4f53\u6d4f\u89c8\u5668\u5b9e\u73b0\u8868\u660e\u8fd9\u4e9b\u6311\u6218\u5bf9\u4eba\u7c7b\u5728\u51e0\u79d2\u5185\u53ef\u8f7b\u677e\u89e3\u51b3\uff0c\u800c\u5bf9\u5f53\u4ee3\u81ea\u52a8\u5316\u7cfb\u7edf\u5728\u4e25\u683c\u65f6\u95f4\u9650\u5236\u4e0b\u4ecd\u7136\u56f0\u96be", "conclusion": "HCO\u4e3a\u6301\u7eed\u3001\u9650\u901f\u7684\u4eba\u7c7b\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u65b0\u7684\u5b89\u5168\u539f\u8bed\uff0c\u80fd\u591f\u6709\u6548\u5bf9\u6297Sybil\u653b\u51fb\uff0c\u5229\u7528\u4eba\u7c7b\u8ba4\u77e5\u7a00\u7f3a\u6027\u4f5c\u4e3a\u9632\u5fa1\u57fa\u7840"}}
{"id": "2601.03662", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03662", "abs": "https://arxiv.org/abs/2601.03662", "authors": ["Su-Hyeon Kim", "Hyundong Jin", "Yejin Lee", "Yo-Sub Han"], "title": "How Does the Thinking Step Influence Model Safety? An Entropy-based Safety Reminder for LRMs", "comment": null, "summary": "Large Reasoning Models (LRMs) achieve remarkable success through explicit thinking steps, yet the thinking steps introduce a novel risk by potentially amplifying unsafe behaviors. Despite this vulnerability, conventional defense mechanisms remain ineffective as they overlook the unique reasoning dynamics of LRMs. In this work, we find that the emergence of safe-reminding phrases within thinking steps plays a pivotal role in ensuring LRM safety. Motivated by this finding, we propose SafeRemind, a decoding-time defense method that dynamically injects safe-reminding phrases into thinking steps. By leveraging entropy triggers to intervene at decision-locking points, SafeRemind redirects potentially harmful trajectories toward safer outcomes without requiring any parameter updates. Extensive evaluations across five LRMs and six benchmarks demonstrate that SafeRemind substantially enhances safety, achieving improvements of up to 45.5%p while preserving core reasoning utility.", "AI": {"tldr": "SafeRemind\u662f\u4e00\u79cd\u89e3\u7801\u65f6\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u601d\u8003\u6b65\u9aa4\u4e2d\u52a8\u6001\u6ce8\u5165\u5b89\u5168\u63d0\u9192\u77ed\u8bed\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027\u800c\u4e0d\u5f71\u54cd\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u663e\u5f0f\u601d\u8003\u6b65\u9aa4\u53d6\u5f97\u663e\u8457\u6210\u529f\uff0c\u4f46\u8fd9\u4e9b\u6b65\u9aa4\u53ef\u80fd\u653e\u5927\u4e0d\u5b89\u5168\u884c\u4e3a\u3002\u73b0\u6709\u9632\u5fa1\u673a\u5236\u5ffd\u89c6\u4e86LRM\u72ec\u7279\u7684\u63a8\u7406\u52a8\u6001\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u63a8\u7406\u8fc7\u7a0b\u7684\u5b89\u5168\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSafeRemind\u65b9\u6cd5\uff0c\u5229\u7528\u71b5\u89e6\u53d1\u5668\u5728\u51b3\u7b56\u9501\u5b9a\u70b9\u8fdb\u884c\u5e72\u9884\uff0c\u52a8\u6001\u5730\u5c06\u5b89\u5168\u63d0\u9192\u77ed\u8bed\u6ce8\u5165\u5230\u601d\u8003\u6b65\u9aa4\u4e2d\uff0c\u5c06\u6f5c\u5728\u6709\u5bb3\u8f68\u8ff9\u91cd\u5b9a\u5411\u5230\u66f4\u5b89\u5168\u7684\u7ed3\u679c\uff0c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u3002", "result": "\u57285\u4e2aLRM\u548c6\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cSafeRemind\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u6027\uff0c\u6700\u9ad8\u6539\u558445.5\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6838\u5fc3\u63a8\u7406\u6548\u7528\u3002", "conclusion": "\u601d\u8003\u6b65\u9aa4\u4e2d\u7684\u5b89\u5168\u63d0\u9192\u77ed\u8bed\u5bf9\u786e\u4fddLRM\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0cSafeRemind\u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u89e3\u7801\u65f6\u9632\u5fa1\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u5f71\u54cd\u63a8\u7406\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\u5927\u5e45\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027\u3002"}}
{"id": "2601.03979", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03979", "abs": "https://arxiv.org/abs/2601.03979", "authors": ["Andreea-Elena Bodea", "Stephen Meisenbacher", "Alexandra Klymenko", "Florian Matthes"], "title": "SoK: Privacy Risks and Mitigations in Retrieval-Augmented Generation Systems", "comment": "17 pages, 3 figures, 5 tables. This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML 2026). The final version will be available on IEEE Xplore", "summary": "The continued promise of Large Language Models (LLMs), particularly in their natural language understanding and generation capabilities, has driven a rapidly increasing interest in identifying and developing LLM use cases. In an effort to complement the ingrained \"knowledge\" of LLMs, Retrieval-Augmented Generation (RAG) techniques have become widely popular. At its core, RAG involves the coupling of LLMs with domain-specific knowledge bases, whereby the generation of a response to a user question is augmented with contextual and up-to-date information. The proliferation of RAG has sparked concerns about data privacy, particularly with the inherent risks that arise when leveraging databases with potentially sensitive information. Numerous recent works have explored various aspects of privacy risks in RAG systems, from adversarial attacks to proposed mitigations. With the goal of surveying and unifying these works, we ask one simple question: What are the privacy risks in RAG, and how can they be measured and mitigated? To answer this question, we conduct a systematic literature review of RAG works addressing privacy, and we systematize our findings into a comprehensive set of privacy risks, mitigation techniques, and evaluation strategies. We supplement these findings with two primary artifacts: a Taxonomy of RAG Privacy Risks and a RAG Privacy Process Diagram. Our work contributes to the study of privacy in RAG not only by conducting the first systematization of risks and mitigations, but also by uncovering important considerations when mitigating privacy risks in RAG systems and assessing the current maturity of proposed mitigations.", "AI": {"tldr": "\u672c\u6587\u5bf9\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u4e2d\u7684\u9690\u79c1\u98ce\u9669\u8fdb\u884c\u4e86\u9996\u6b21\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u9690\u79c1\u98ce\u9669\u5206\u7c7b\u6cd5\u548cRAG\u9690\u79c1\u8fc7\u7a0b\u56fe\uff0c\u603b\u7ed3\u4e86\u98ce\u9669\u6d4b\u91cf\u4e0e\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u968f\u7740RAG\u6280\u672f\u5728\u7ed3\u5408LLM\u4e0e\u9886\u57df\u77e5\u8bc6\u5e93\u65b9\u9762\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u6570\u636e\u9690\u79c1\u95ee\u9898\u65e5\u76ca\u51f8\u663e\u3002\u73b0\u6709\u7814\u7a76\u5bf9RAG\u9690\u79c1\u98ce\u9669\u7684\u5404\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u63a2\u7d22\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6574\u7406\u548c\u7edf\u4e00\u6846\u67b6\uff0c\u9700\u8981\u5168\u9762\u8c03\u67e5RAG\u4e2d\u7684\u9690\u79c1\u98ce\u9669\u53ca\u5176\u6d4b\u91cf\u4e0e\u7f13\u89e3\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u6536\u96c6\u548c\u5206\u6790\u5173\u6ce8RAG\u9690\u79c1\u7684\u7814\u7a76\u5de5\u4f5c\uff0c\u5c06\u53d1\u73b0\u7cfb\u7edf\u5316\u4e3a\u5168\u9762\u7684\u9690\u79c1\u98ce\u9669\u96c6\u3001\u7f13\u89e3\u6280\u672f\u548c\u8bc4\u4f30\u7b56\u7565\uff0c\u5e76\u521b\u5efa\u4e86\u4e24\u4e2a\u4e3b\u8981\u6210\u679c\uff1aRAG\u9690\u79c1\u98ce\u9669\u5206\u7c7b\u6cd5\u548cRAG\u9690\u79c1\u8fc7\u7a0b\u56fe\u3002", "result": "\u5efa\u7acb\u4e86\u9996\u4e2aRAG\u9690\u79c1\u98ce\u9669\u4e0e\u7f13\u89e3\u63aa\u65bd\u7684\u7cfb\u7edf\u5316\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u7f13\u89e3RAG\u9690\u79c1\u98ce\u9669\u65f6\u7684\u91cd\u8981\u8003\u8651\u56e0\u7d20\uff0c\u8bc4\u4f30\u4e86\u73b0\u6709\u7f13\u89e3\u63aa\u65bd\u7684\u6210\u719f\u5ea6\uff0c\u4e3aRAG\u9690\u79c1\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u6027\u53c2\u8003\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86RAG\u9690\u79c1\u7814\u7a76\u9886\u57df\u7684\u7cfb\u7edf\u6027\u7a7a\u767d\uff0c\u4e0d\u4ec5\u9996\u6b21\u7cfb\u7edf\u5316\u4e86\u98ce\u9669\u4e0e\u7f13\u89e3\u63aa\u65bd\uff0c\u8fd8\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5206\u7c7b\u6846\u67b6\u548c\u8fc7\u7a0b\u56fe\uff0c\u4e3a\u672a\u6765RAG\u7cfb\u7edf\u7684\u9690\u79c1\u4fdd\u62a4\u8bbe\u8ba1\u548c\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.03672", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03672", "abs": "https://arxiv.org/abs/2601.03672", "authors": ["Chen Zhang", "Kepu Zhang", "Jiatong Zhang", "Xiao Zhang", "Jun Xu"], "title": "Sandwich Reasoning: An Answer-Reasoning-Answer Approach for Low-Latency Query Correction", "comment": null, "summary": "Query correction is a critical entry point in modern search pipelines, demanding high accuracy strictly within real-time latency constraints. Chain-of-Thought (CoT) reasoning improves accuracy but incurs prohibitive latency for real-time query correction. A potential solution is to output an answer before reasoning to reduce latency; however, under autoregressive decoding, the early answer is independent of subsequent reasoning, preventing the model from leveraging its reasoning capability to improve accuracy. To address this issue, we propose Sandwich Reasoning (SandwichR), a novel approach that explicitly aligns a fast initial answer with post-hoc reasoning, enabling low-latency query correction without sacrificing reasoning-aware accuracy. SandwichR follows an Answer-Reasoning-Answer paradigm, producing an initial correction, an explicit reasoning process, and a final refined correction. To align the initial answer with post-reasoning insights, we design a consistency-aware reinforcement learning (RL) strategy: a dedicated consistency reward enforces alignment between the initial and final corrections, while margin-based rejection sampling prioritizes borderline samples where reasoning drives the most impactful corrective gains. Additionally, we construct a high-quality query correction dataset, addressing the lack of specialized benchmarks for complex query correction. Experimental results demonstrate that SandwichR achieves SOTA accuracy comparable to standard CoT while delivering a 40-70% latency reduction, resolving the latency-accuracy trade-off in online search.", "AI": {"tldr": "SandwichR\u662f\u4e00\u79cd\u65b0\u9896\u7684\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\"\u7b54\u6848-\u63a8\u7406-\u7b54\u6848\"\u8303\u5f0f\uff0c\u5728\u4fdd\u6301CoT\u63a8\u7406\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u5ef6\u8fdf\uff0c\u89e3\u51b3\u4e86\u67e5\u8be2\u4fee\u6b63\u4e2d\u7684\u5ef6\u8fdf-\u51c6\u786e\u6027\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u67e5\u8be2\u4fee\u6b63\u662f\u73b0\u4ee3\u641c\u7d22\u7ba1\u9053\u7684\u5173\u952e\u5165\u53e3\u70b9\uff0c\u9700\u8981\u5728\u5b9e\u65f6\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002CoT\u63a8\u7406\u867d\u7136\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u5ef6\u8fdf\u8fc7\u9ad8\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u65f6\u8981\u6c42\u3002\u63d0\u524d\u8f93\u51fa\u7b54\u6848\u53ef\u4ee5\u964d\u4f4e\u5ef6\u8fdf\uff0c\u4f46\u5728\u81ea\u56de\u5f52\u89e3\u7801\u4e0b\uff0c\u65e9\u671f\u7b54\u6848\u4e0e\u540e\u7eed\u63a8\u7406\u65e0\u5173\uff0c\u65e0\u6cd5\u5229\u7528\u63a8\u7406\u80fd\u529b\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faSandwichR\u65b9\u6cd5\uff0c\u91c7\u7528\"\u7b54\u6848-\u63a8\u7406-\u7b54\u6848\"\u8303\u5f0f\uff1a\u5148\u751f\u6210\u521d\u59cb\u4fee\u6b63\uff0c\u7136\u540e\u8fdb\u884c\u663e\u5f0f\u63a8\u7406\u8fc7\u7a0b\uff0c\u6700\u540e\u751f\u6210\u7cbe\u70bc\u7684\u6700\u7ec8\u4fee\u6b63\u3002\u4f7f\u7528\u4e00\u81f4\u6027\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u4e00\u81f4\u6027\u5956\u52b1\u5f3a\u5236\u521d\u59cb\u4fee\u6b63\u4e0e\u6700\u7ec8\u4fee\u6b63\u5bf9\u9f50\uff0c\u540c\u65f6\u57fa\u4e8e\u8fb9\u754c\u7684\u62d2\u7edd\u91c7\u6837\u4f18\u5148\u5904\u7406\u63a8\u7406\u80fd\u5e26\u6765\u6700\u5927\u4fee\u6b63\u589e\u76ca\u7684\u8fb9\u754c\u6837\u672c\u3002\u8fd8\u6784\u5efa\u4e86\u9ad8\u8d28\u91cf\u7684\u67e5\u8be2\u4fee\u6b63\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSandwichR\u5728\u51c6\u786e\u6027\u4e0a\u8fbe\u5230\u4e0e\u6807\u51c6CoT\u76f8\u5f53\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u540c\u65f6\u5b9e\u73b0\u4e8640-70%\u7684\u5ef6\u8fdf\u964d\u4f4e\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5728\u7ebf\u641c\u7d22\u4e2d\u7684\u5ef6\u8fdf-\u51c6\u786e\u6027\u6743\u8861\u95ee\u9898\u3002", "conclusion": "SandwichR\u901a\u8fc7\u5c06\u5feb\u901f\u521d\u59cb\u7b54\u6848\u4e0e\u4e8b\u540e\u63a8\u7406\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u67e5\u8be2\u4fee\u6b63\u800c\u4e0d\u727a\u7272\u63a8\u7406\u611f\u77e5\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u5b9e\u65f6\u641c\u7d22\u7cfb\u7edf\u4e2d\u7684\u67e5\u8be2\u4fee\u6b63\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.03687", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03687", "abs": "https://arxiv.org/abs/2601.03687", "authors": ["Yonatan Vernik", "Alexander Tuisov", "David Izhaki", "Hana Weitman", "Gal A. Kaminka", "Alexander Shleyfman"], "title": "Personalized Medication Planning via Direct Domain Modeling and LLM-Generated Heuristics", "comment": null, "summary": "Personalized medication planning involves selecting medications and determining a dosing schedule to achieve medical goals specific to each individual patient. Previous work successfully demonstrated that automated planners, using general domain-independent heuristics, are able to generate personalized treatments, when the domain and problems are modeled using a general domain description language (\\pddlp). Unfortunately, this process was limited in practice to consider no more than seven medications. In clinical terms, this is a non-starter. In this paper, we explore the use of automatically-generated domain- and problem-specific heuristics to be used with general search, as a method of scaling up medication planning to levels allowing closer work with clinicians. Specifically, we specify the domain programmatically (specifying an initial state and a successor generation procedure), and use an LLM to generate a problem specific heuristic that can be used by a fixed search algorithm (GBFS). The results indicate dramatic improvements in coverage and planning time, scaling up the number of medications to at least 28, and bringing medication planning one step closer to practical applications.", "AI": {"tldr": "\u4f7f\u7528LLM\u751f\u6210\u7279\u5b9a\u95ee\u9898\u542f\u53d1\u5f0f\u51fd\u6570\uff0c\u7ed3\u5408GBFS\u641c\u7d22\u7b97\u6cd5\uff0c\u5c06\u4e2a\u6027\u5316\u7528\u836f\u89c4\u5212\u7684\u836f\u7269\u6570\u91cf\u4ece7\u79cd\u6269\u5c55\u523028\u79cd\u4ee5\u4e0a\uff0c\u663e\u8457\u63d0\u5347\u89c4\u5212\u8986\u76d6\u7387\u548c\u6548\u7387", "motivation": "\u4e2a\u6027\u5316\u7528\u836f\u89c4\u5212\u9700\u8981\u4e3a\u6bcf\u4f4d\u60a3\u8005\u9009\u62e9\u836f\u7269\u5e76\u786e\u5b9a\u7ed9\u836f\u65b9\u6848\uff0c\u4f46\u73b0\u6709\u57fa\u4e8e\u901a\u7528\u9886\u57df\u65e0\u5173\u542f\u53d1\u5f0f\u51fd\u6570\u7684\u81ea\u52a8\u5316\u89c4\u5212\u65b9\u6cd5\u6700\u591a\u53ea\u80fd\u5904\u74067\u79cd\u836f\u7269\uff0c\u8fd9\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u8fdc\u8fdc\u4e0d\u591f\uff0c\u9700\u8981\u6269\u5c55\u5230\u66f4\u591a\u836f\u7269\u6570\u91cf", "method": "\u901a\u8fc7\u7a0b\u5e8f\u5316\u65b9\u5f0f\u6307\u5b9a\u9886\u57df\uff08\u5b9a\u4e49\u521d\u59cb\u72b6\u6001\u548c\u72b6\u6001\u8f6c\u79fb\u8fc7\u7a0b\uff09\uff0c\u4f7f\u7528LLM\u751f\u6210\u7279\u5b9a\u95ee\u9898\u542f\u53d1\u5f0f\u51fd\u6570\uff0c\u7ed3\u5408\u56fa\u5b9a\u7684\u8d2a\u5a6a\u6700\u4f73\u4f18\u5148\u641c\u7d22\uff08GBFS\uff09\u7b97\u6cd5\u8fdb\u884c\u89c4\u5212", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u89c4\u5212\u8986\u76d6\u7387\u548c\u89c4\u5212\u65f6\u95f4\uff0c\u80fd\u591f\u5904\u7406\u81f3\u5c1128\u79cd\u836f\u7269\uff0c\u5c06\u4e2a\u6027\u5316\u7528\u836f\u89c4\u5212\u5411\u5b9e\u9645\u5e94\u7528\u63a8\u8fdb\u4e86\u4e00\u6b65", "conclusion": "\u4f7f\u7528LLM\u81ea\u52a8\u751f\u6210\u9886\u57df\u548c\u95ee\u9898\u7279\u5b9a\u542f\u53d1\u5f0f\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u6269\u5c55\u4e2a\u6027\u5316\u7528\u836f\u89c4\u5212\u7684\u89c4\u6a21\uff0c\u4f7f\u5176\u66f4\u63a5\u8fd1\u4e34\u5e8a\u5e94\u7528\u9700\u6c42"}}
{"id": "2601.03769", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03769", "abs": "https://arxiv.org/abs/2601.03769", "authors": ["Zihang Li", "Yuhang Wang", "Yikun Zong", "Wenhan Yu", "Xiaokun Yuan", "Runhan Jiang", "Zirui Liu", "Tong Yang", "Arthur Jiang"], "title": "EntroCoT: Enhancing Chain-of-Thought via Adaptive Entropy-Guided Segmentation", "comment": null, "summary": "Chain-of-Thought (CoT) prompting has significantly enhanced the mathematical reasoning capabilities of Large Language Models. We find existing fine-tuning datasets frequently suffer from the \"answer right but reasoning wrong\" probelm, where correct final answers are derived from hallucinated, redundant, or logically invalid intermediate steps. This paper proposes EntroCoT, a unified framework for automatically identifying and refining low-quality CoT supervision traces. EntroCoT first proposes an entropy-based mechanism to segment the reasoning trace into multiple steps at uncertain junctures, and then introduces a Monte Carlo rollout-based mechanism to evaluate the marginal contribution of each step. By accurately filtering deceptive reasoning samples, EntroCoT constructs a high-quality dataset where every intermediate step in each reasoning trace facilitates the final answer. Extensive experiments on mathematical benchmarks demonstrate that fine-tuning on the subset constructed by EntroCoT consistently outperforms the baseslines of full-dataset supervision.", "AI": {"tldr": "EntroCoT\uff1a\u901a\u8fc7\u71b5\u57fa\u5206\u5272\u548c\u8499\u7279\u5361\u6d1b\u8bc4\u4f30\u81ea\u52a8\u8bc6\u522b\u548c\u4f18\u5316\u4f4e\u8d28\u91cf\u601d\u7ef4\u94fe\u76d1\u7763\u6570\u636e\uff0c\u63d0\u5347\u6570\u5b66\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u5fae\u8c03\u6570\u636e\u96c6\u5b58\u5728\"\u7b54\u6848\u6b63\u786e\u4f46\u63a8\u7406\u9519\u8bef\"\u7684\u95ee\u9898\uff0c\u5373\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u4f46\u4e2d\u95f4\u6b65\u9aa4\u5b58\u5728\u5e7b\u89c9\u3001\u5197\u4f59\u6216\u903b\u8f91\u9519\u8bef\uff0c\u8fd9\u5f71\u54cd\u4e86\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347", "method": "\u63d0\u51faEntroCoT\u6846\u67b6\uff1a1\uff09\u57fa\u4e8e\u71b5\u7684\u673a\u5236\u5728\u4e0d\u786e\u5b9a\u8282\u70b9\u5206\u5272\u63a8\u7406\u8f68\u8ff9\uff1b2\uff09\u8499\u7279\u5361\u6d1brollout\u673a\u5236\u8bc4\u4f30\u6bcf\u4e2a\u6b65\u9aa4\u7684\u8fb9\u9645\u8d21\u732e\uff1b3\uff09\u51c6\u786e\u8fc7\u6ee4\u6b3a\u9a97\u6027\u63a8\u7406\u6837\u672c\uff0c\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6", "result": "\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528EntroCoT\u6784\u5efa\u7684\u5b50\u96c6\u8fdb\u884c\u5fae\u8c03\uff0c\u5176\u6027\u80fd\u59cb\u7ec8\u4f18\u4e8e\u5168\u6570\u636e\u96c6\u76d1\u7763\u7684\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "EntroCoT\u80fd\u6709\u6548\u8bc6\u522b\u548c\u4f18\u5316\u4f4e\u8d28\u91cf\u601d\u7ef4\u94fe\u76d1\u7763\u6570\u636e\uff0c\u6784\u5efa\u9ad8\u8d28\u91cf\u63a8\u7406\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b"}}
{"id": "2601.03822", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03822", "abs": "https://arxiv.org/abs/2601.03822", "authors": ["Muyang Zhao", "Qi Qi", "Hao Sun"], "title": "ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition", "comment": null, "summary": "Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faROI-Reasoning\u6846\u67b6\uff0c\u901a\u8fc7\u5143\u8ba4\u77e5\u5fae\u8c03\u548c\u7406\u6027\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e25\u683c\u8ba1\u7b97\u9884\u7b97\u4e0b\u8fdb\u884c\u63a8\u7406\u51b3\u7b56\uff0c\u4f18\u5316\u591a\u4efb\u52a1\u7684\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5177\u5907\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u65e0\u6cd5\u81ea\u52a8\u5224\u65ad\u4e0d\u540c\u4efb\u52a1\u6240\u9700\u7684\u8ba1\u7b97\u91cf\uff0c\u5728\u4e25\u683c\u7684\u8ba1\u7b97\u9884\u7b97\u7ea6\u675f\u4e0b\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9884\u6d4b\u4efb\u52a1\u96be\u5ea6\u3001\u8bc4\u4f30\u6295\u8d44\u56de\u62a5\u7387\u5e76\u6218\u7565\u6027\u5730\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faROI-Reasoning\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u5143\u8ba4\u77e5\u5fae\u8c03\u9636\u6bb5\uff0c\u8bad\u7ec3\u6a21\u578b\u5728\u751f\u6210\u524d\u9884\u6d4b\u63a8\u7406\u6210\u672c\u548c\u9884\u671f\u6548\u7528\uff0c\u505a\u51fa\u660e\u786e\u7684\u89e3\u51b3\u6216\u8df3\u8fc7\u51b3\u7b56\uff1b2) \u7406\u6027\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\uff0c\u5728\u4e25\u683c\u7684token\u9884\u7b97\u4e0b\u4f18\u5316\u5e8f\u5217\u51b3\u7b56\uff0c\u5b66\u4e60\u957f\u671f\u5206\u914d\u7b56\u7565\u3002", "result": "\u5728\u9884\u7b97\u7ea6\u675f\u7684\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cROI-Reasoning\u5728\u4fdd\u6301\u6574\u4f53\u5f97\u5206\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5728\u4e25\u683c\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u9057\u61be\u503c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aLLMs\u5f15\u5165\u4e86\u5185\u5728\u7684\u9884\u7b97\u611f\u77e5\u7406\u6027\u80fd\u529b\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u4e3a\u6709\u5e8f\u968f\u673a\u591a\u9009\u62e9\u80cc\u5305\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u7684\u6700\u4f18\u63a8\u7406\u51b3\u7b56\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.03840", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.03840", "abs": "https://arxiv.org/abs/2601.03840", "authors": ["Racquel Dennison", "Jesse Heyninck", "Thomas Meyer"], "title": "Defeasible Conditionals using Answer Set Programming", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Defeasible entailment is concerned with drawing plausible conclusions from incomplete information. A foundational framework for modelling defeasible entailment is the KLM framework. Introduced by Kraus, Lehmann, and Magidor, the KLM framework outlines several key properties for defeasible entailment. One of the most prominent algorithms within this framework is Rational Closure (RC). This paper presents a declarative definition for computing RC using Answer Set Programming (ASP). Our approach enables the automatic construction of the minimal ranked model from a given knowledge base and supports entailment checking for specified queries. We formally prove the correctness of our ASP encoding and conduct empirical evaluations to compare the performance of our implementation with that of existing imperative implementations, specifically the InfOCF solver. The results demonstrate that our ASP-based approach adheres to RC's theoretical foundations and offers improved computational efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u8ba1\u7b97\u7406\u6027\u95ed\u5305\uff08RC\uff09\u7684\u58f0\u660e\u5f0f\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u4ece\u77e5\u8bc6\u5e93\u81ea\u52a8\u6784\u5efa\u6700\u5c0f\u6392\u5e8f\u6a21\u578b\u5e76\u8fdb\u884c\u8574\u6db5\u68c0\u67e5\uff0c\u76f8\u6bd4\u73b0\u6709\u547d\u4ee4\u5f0f\u5b9e\u73b0\u5177\u6709\u66f4\u597d\u7684\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u53ef\u5e9f\u6b62\u8574\u6db5\u5904\u7406\u4ece\u4e0d\u5b8c\u6574\u4fe1\u606f\u4e2d\u5f97\u51fa\u5408\u7406\u7ed3\u8bba\u7684\u95ee\u9898\uff0cKLM\u6846\u67b6\u662f\u5176\u57fa\u7840\u6a21\u578b\uff0c\u7406\u6027\u95ed\u5305\u662f\u8be5\u6846\u67b6\u4e2d\u6700\u7a81\u51fa\u7684\u7b97\u6cd5\u4e4b\u4e00\u3002\u73b0\u6709\u5b9e\u73b0\u591a\u4e3a\u547d\u4ee4\u5f0f\u65b9\u6cd5\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u58f0\u660e\u5f0f\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u4e3a\u7406\u6027\u95ed\u5305\u63d0\u4f9b\u58f0\u660e\u5f0f\u5b9a\u4e49\uff0c\u80fd\u591f\u81ea\u52a8\u4ece\u7ed9\u5b9a\u77e5\u8bc6\u5e93\u6784\u5efa\u6700\u5c0f\u6392\u5e8f\u6a21\u578b\uff0c\u5e76\u652f\u6301\u5bf9\u6307\u5b9a\u67e5\u8be2\u8fdb\u884c\u8574\u6db5\u68c0\u67e5\u3002", "result": "\u5f62\u5f0f\u5316\u8bc1\u660e\u4e86ASP\u7f16\u7801\u7684\u6b63\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u5c06ASP\u5b9e\u73b0\u4e0e\u73b0\u6709\u547d\u4ee4\u5f0f\u5b9e\u73b0\uff08InfOCF\u6c42\u89e3\u5668\uff09\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\uff0c\u7ed3\u679c\u663e\u793aASP\u65b9\u6cd5\u9075\u5faaRC\u7684\u7406\u8bba\u57fa\u7840\u4e14\u63d0\u4f9b\u66f4\u597d\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "ASP\u4e3a\u7406\u6027\u95ed\u5305\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u58f0\u660e\u5f0f\u8ba1\u7b97\u65b9\u6cd5\uff0c\u65e2\u4fdd\u6301\u4e86\u7406\u8bba\u6b63\u786e\u6027\uff0c\u53c8\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u53ef\u5e9f\u6b62\u63a8\u7406\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5de5\u5177\u3002"}}
{"id": "2601.03844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03844", "abs": "https://arxiv.org/abs/2601.03844", "authors": ["Agostino Dovier", "Talissa Dreossi", "Andrea Formisano", "Benedetta Strizzolo"], "title": "XAI-LAW: A Logic Programming Tool for Modeling, Explaining, and Learning Legal Decisions", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "We propose an approach to model articles of the Italian Criminal Code (ICC), using Answer Set Programming (ASP), and to semi-automatically learn legal rules from examples based on prior judicial decisions. The developed tool is intended to support legal experts during the criminal trial phase by providing reasoning and possible legal outcomes. The methodology involves analyzing and encoding articles of the ICC in ASP, including \"crimes against the person\" and property offenses. The resulting model is validated on a set of previous verdicts and refined as necessary. During the encoding process, contradictions may arise; these are properly handled by the system, which also generates possible decisions for new cases and provides explanations through a tool that leverages the \"supportedness\" of stable models. The automatic explainability offered by the tool can also be used to clarify the logic behind judicial decisions, making the decision-making process more interpretable. Furthermore, the tool integrates an inductive logic programming system for ASP, which is employed to generalize legal rules from case examples.", "AI": {"tldr": "\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u5bf9\u610f\u5927\u5229\u5211\u6cd5\u5178\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u57fa\u4e8e\u53f8\u6cd5\u5224\u4f8b\u534a\u81ea\u52a8\u5b66\u4e60\u6cd5\u5f8b\u89c4\u5219\uff0c\u5f00\u53d1\u652f\u6301\u6cd5\u5f8b\u4e13\u5bb6\u5728\u5211\u4e8b\u5ba1\u5224\u9636\u6bb5\u8fdb\u884c\u63a8\u7406\u548c\u9884\u6d4b\u6cd5\u5f8b\u7ed3\u679c\u7684\u5de5\u5177\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u652f\u6301\u6cd5\u5f8b\u4e13\u5bb6\u5728\u5211\u4e8b\u5ba1\u5224\u9636\u6bb5\u8fdb\u884c\u63a8\u7406\u548c\u9884\u6d4b\u6cd5\u5f8b\u7ed3\u679c\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u5c06\u6cd5\u5f8b\u6761\u6587\u7f16\u7801\u4e3a\u5f62\u5f0f\u5316\u903b\u8f91\u89c4\u5219\uff0c\u63d0\u9ad8\u6cd5\u5f8b\u51b3\u7b56\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u5bf9\u610f\u5927\u5229\u5211\u6cd5\u5178\u4e2d\u7684\"\u4eba\u8eab\u72af\u7f6a\"\u548c\u8d22\u4ea7\u72af\u7f6a\u6761\u6b3e\u8fdb\u884c\u5efa\u6a21\u548c\u7f16\u7801\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5148\u524d\u5224\u51b3\u6765\u5b8c\u5584\u6a21\u578b\uff0c\u5e76\u5229\u7528ASP\u7684\"\u652f\u6301\u6027\"\u7a33\u5b9a\u6a21\u578b\u63d0\u4f9b\u89e3\u91ca\u3002\u540c\u65f6\u96c6\u6210\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u7cfb\u7edf\u4ece\u6848\u4f8b\u4e2d\u5f52\u7eb3\u6cd5\u5f8b\u89c4\u5219\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u6cd5\u5f8b\u6761\u6587\u7f16\u7801\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u77db\u76fe\u3001\u4e3a\u65b0\u6848\u4ef6\u751f\u6210\u53ef\u80fd\u51b3\u7b56\u5e76\u63d0\u4f9b\u89e3\u91ca\u7684\u5de5\u5177\u3002\u8be5\u5de5\u5177\u80fd\u591f\u57fa\u4e8e\u5148\u524d\u5224\u51b3\u9a8c\u8bc1\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u4ece\u6848\u4f8b\u4e2d\u5b66\u4e60\u6cd5\u5f8b\u89c4\u5219\u3002", "conclusion": "ASP\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5efa\u6a21\u610f\u5927\u5229\u5211\u6cd5\u5178\u5e76\u652f\u6301\u6cd5\u5f8b\u63a8\u7406\uff0c\u63d0\u4f9b\u7684\u81ea\u52a8\u89e3\u91ca\u529f\u80fd\u4f7f\u53f8\u6cd5\u51b3\u7b56\u8fc7\u7a0b\u66f4\u52a0\u900f\u660e\u548c\u53ef\u89e3\u91ca\uff0c\u540c\u65f6\u901a\u8fc7\u5f52\u7eb3\u5b66\u4e60\u80fd\u591f\u4ece\u6848\u4f8b\u4e2d\u63d0\u53d6\u6cd5\u5f8b\u89c4\u5219\uff0c\u4e3a\u6cd5\u5f8b\u4e13\u5bb6\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2601.03845", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.03845", "abs": "https://arxiv.org/abs/2601.03845", "authors": ["Akihiro Takemura", "Masayuki Otani", "Katsumi Inoue"], "title": "Formally Explaining Decision Tree Models with Answer Set Programming", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Decision tree models, including random forests and gradient-boosted decision trees, are widely used in machine learning due to their high predictive performance.  However, their complex structures often make them difficult to interpret, especially in safety-critical applications where model decisions require formal justification.  Recent work has demonstrated that logical and abductive explanations can be derived through automated reasoning techniques.  In this paper, we propose a method for generating various types of explanations, namely, sufficient, contrastive, majority, and tree-specific explanations, using Answer Set Programming (ASP).  Compared to SAT-based approaches, our ASP-based method offers greater flexibility in encoding user preferences and supports enumeration of all possible explanations.  We empirically evaluate the approach on a diverse set of datasets and demonstrate its effectiveness and limitations compared to existing methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e3a\u51b3\u7b56\u6811\u6a21\u578b\u751f\u6210\u591a\u79cd\u89e3\u91ca\u7c7b\u578b\uff0c\u76f8\u6bd4SAT\u65b9\u6cd5\u66f4\u5177\u7075\u6d3b\u6027\u4e14\u652f\u6301\u679a\u4e3e\u6240\u6709\u53ef\u80fd\u89e3\u91ca\u3002", "motivation": "\u51b3\u7b56\u6811\u6a21\u578b\uff08\u5982\u968f\u673a\u68ee\u6797\u548c\u68af\u5ea6\u63d0\u5347\u51b3\u7b56\u6811\uff09\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u590d\u6742\u7ed3\u6784\u96be\u4ee5\u89e3\u91ca\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u6b63\u5f0f\u8bba\u8bc1\u7684\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u3002\u73b0\u6709\u5de5\u4f5c\u5df2\u8bc1\u660e\u53ef\u4ee5\u901a\u8fc7\u81ea\u52a8\u63a8\u7406\u6280\u672f\u63a8\u5bfc\u903b\u8f91\u548c\u6eaf\u56e0\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u751f\u6210\u591a\u79cd\u89e3\u91ca\u7c7b\u578b\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u5145\u5206\u89e3\u91ca\u3001\u5bf9\u6bd4\u89e3\u91ca\u3001\u591a\u6570\u89e3\u91ca\u548c\u6811\u7279\u5b9a\u89e3\u91ca\u3002\u76f8\u6bd4\u57fa\u4e8eSAT\u7684\u65b9\u6cd5\uff0cASP\u65b9\u6cd5\u5728\u7f16\u7801\u7528\u6237\u504f\u597d\u65b9\u9762\u66f4\u5177\u7075\u6d3b\u6027\uff0c\u5e76\u652f\u6301\u679a\u4e3e\u6240\u6709\u53ef\u80fd\u7684\u89e3\u91ca\u3002", "result": "\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e0e\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5c55\u793a\u4e86\u5176\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u57fa\u4e8eASP\u7684\u65b9\u6cd5\u4e3a\u51b3\u7b56\u6811\u6a21\u578b\u89e3\u91ca\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u751f\u6210\u591a\u79cd\u7c7b\u578b\u7684\u89e3\u91ca\u5e76\u652f\u6301\u5b8c\u6574\u679a\u4e3e\uff0c\u5728\u53ef\u89e3\u91caAI\u9886\u57df\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.03850", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03850", "abs": "https://arxiv.org/abs/2601.03850", "authors": ["Veronika Semmelrock", "Gerhard Friedrich"], "title": "Investigating the Grounding Bottleneck for a Large-Scale Configuration Problem: Existing Tools and Constraint-Aware Guessing", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Answer set programming (ASP) aims to realize the AI vision: The user specifies the problem, and the computer solves it. Indeed, ASP has made this vision true in many application domains. However, will current ASP solving techniques scale up for large configuration problems? As a benchmark for such problems, we investigated the configuration of electronic systems, which may comprise more than 30,000 components. We show the potential and limits of current ASP technology, focusing on methods that address the so-called grounding bottleneck, i.e., the sharp increase of memory demands in the size of the problem instances. To push the limits, we investigated the incremental solving approach, which proved effective in practice. However, even in the incremental approach, memory demands impose significant limits. Based on an analysis of grounding, we developed the method constraint-aware guessing, which significantly reduced the memory need.", "AI": {"tldr": "ASP\u6280\u672f\u5728\u5904\u7406\u5927\u89c4\u6a21\u914d\u7f6e\u95ee\u9898\u65f6\u9762\u4e34\u5185\u5b58\u74f6\u9888\uff0c\u7814\u7a76\u8005\u901a\u8fc7\u589e\u91cf\u6c42\u89e3\u548c\u7ea6\u675f\u611f\u77e5\u731c\u6d4b\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u9700\u6c42", "motivation": "\u7814\u7a76\u5f53\u524dASP\u6c42\u89e3\u6280\u672f\u662f\u5426\u80fd\u591f\u6269\u5c55\u5230\u5927\u89c4\u6a21\u914d\u7f6e\u95ee\u9898\uff0c\u7279\u522b\u662f\u7535\u5b50\u7cfb\u7edf\u914d\u7f6e\u8fd9\u7c7b\u53ef\u80fd\u5305\u542b\u8d85\u8fc730,000\u4e2a\u7ec4\u4ef6\u7684\u590d\u6742\u95ee\u9898", "method": "\u91c7\u7528\u589e\u91cf\u6c42\u89e3\u65b9\u6cd5\uff0c\u5e76\u57fa\u4e8e\u5bf9\u57fa\u7840\u5316\u8fc7\u7a0b\u7684\u5206\u6790\u5f00\u53d1\u4e86\u7ea6\u675f\u611f\u77e5\u731c\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u57fa\u7840\u5316\u74f6\u9888\u95ee\u9898", "result": "\u589e\u91cf\u6c42\u89e3\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u6709\u6548\uff0c\u4f46\u5185\u5b58\u9700\u6c42\u4ecd\u6784\u6210\u663e\u8457\u9650\u5236\uff1b\u7ea6\u675f\u611f\u77e5\u731c\u6d4b\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u9700\u6c42", "conclusion": "\u5f53\u524dASP\u6280\u672f\u5728\u5904\u7406\u5927\u89c4\u6a21\u914d\u7f6e\u95ee\u9898\u65f6\u5b58\u5728\u5185\u5b58\u74f6\u9888\uff0c\u4f46\u901a\u8fc7\u589e\u91cf\u6c42\u89e3\u548c\u7ea6\u675f\u611f\u77e5\u731c\u6d4b\u7b49\u4f18\u5316\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u6539\u5584\u6027\u80fd\uff0c\u63a8\u52a8ASP\u6280\u672f\u7684\u5e94\u7528\u8fb9\u754c"}}
{"id": "2601.03948", "categories": ["cs.AI", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2601.03948", "abs": "https://arxiv.org/abs/2601.03948", "authors": ["Rui Sun", "Yifan Sun", "Sheng Xu", "Li Zhao", "Jing Li", "Daxin Jiang", "Cheng Hua", "Zuo Bai"], "title": "Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification", "comment": null, "summary": "Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to achieve remarkable reasoning in domains like mathematics and coding, where verifiable rewards provide clear signals. However, extending this paradigm to financial decision is challenged by the market's stochastic nature: rewards are verifiable but inherently noisy, causing standard RL to degenerate into reward hacking. To address this, we propose Trade-R1, a model training framework that bridges verifiable rewards to stochastic environments via process-level reasoning verification. Our key innovation is a verification method that transforms the problem of evaluating reasoning over lengthy financial documents into a structured Retrieval-Augmented Generation (RAG) task. We construct a triangular consistency metric, assessing pairwise alignment between retrieved evidence, reasoning chains, and decisions to serve as a validity filter for noisy market returns. We explore two reward integration strategies: Fixed-effect Semantic Reward (FSR) for stable alignment signals, and Dynamic-effect Semantic Reward (DSR) for coupled magnitude optimization. Experiments on different country asset selection demonstrate that our paradigm reduces reward hacking, with DSR achieving superior cross-market generalization while maintaining the highest reasoning consistency.", "AI": {"tldr": "Trade-R1\uff1a\u901a\u8fc7\u8fc7\u7a0b\u7ea7\u63a8\u7406\u9a8c\u8bc1\u5c06\u53ef\u9a8c\u8bc1\u5956\u52b1\u4e0e\u968f\u673a\u91d1\u878d\u73af\u5883\u8fde\u63a5\uff0c\u89e3\u51b3\u6807\u51c6RL\u5728\u91d1\u878d\u51b3\u7b56\u4e2d\u7684\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u7b49\u53ef\u9a8c\u8bc1\u5956\u52b1\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u91d1\u878d\u51b3\u7b56\u4e2d\u9762\u4e34\u6311\u6218\uff1a\u5e02\u573a\u5177\u6709\u968f\u673a\u6027\uff0c\u5956\u52b1\u867d\u7136\u53ef\u9a8c\u8bc1\u4f46\u672c\u8d28\u4e0a\u662f\u566a\u58f0\u7684\uff0c\u5bfc\u81f4\u6807\u51c6RL\u9000\u5316\u4e3a\u5956\u52b1\u9ed1\u5ba2", "method": "\u63d0\u51faTrade-R1\u6846\u67b6\uff0c\u901a\u8fc7\u8fc7\u7a0b\u7ea7\u63a8\u7406\u9a8c\u8bc1\u8fde\u63a5\u53ef\u9a8c\u8bc1\u5956\u52b1\u4e0e\u968f\u673a\u73af\u5883\u3002\u6838\u5fc3\u521b\u65b0\u662f\u5c06\u5197\u957f\u91d1\u878d\u6587\u6863\u7684\u63a8\u7406\u8bc4\u4f30\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316RAG\u4efb\u52a1\uff0c\u6784\u5efa\u4e09\u89d2\u4e00\u81f4\u6027\u5ea6\u91cf\u6765\u8bc4\u4f30\u68c0\u7d22\u8bc1\u636e\u3001\u63a8\u7406\u94fe\u548c\u51b3\u7b56\u4e4b\u95f4\u7684\u5bf9\u9f50\uff0c\u4f5c\u4e3a\u566a\u58f0\u5e02\u573a\u56de\u62a5\u7684\u6709\u6548\u6027\u8fc7\u6ee4\u5668\u3002\u63a2\u7d22\u4e24\u79cd\u5956\u52b1\u6574\u5408\u7b56\u7565\uff1a\u56fa\u5b9a\u6548\u5e94\u8bed\u4e49\u5956\u52b1\uff08FSR\uff09\u548c\u52a8\u6001\u6548\u5e94\u8bed\u4e49\u5956\u52b1\uff08DSR\uff09", "result": "\u5728\u4e0d\u540c\u56fd\u5bb6\u8d44\u4ea7\u9009\u62e9\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u8303\u5f0f\u51cf\u5c11\u4e86\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\uff0cDSR\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u8de8\u5e02\u573a\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6700\u9ad8\u7684\u63a8\u7406\u4e00\u81f4\u6027", "conclusion": "Trade-R1\u901a\u8fc7\u8fc7\u7a0b\u7ea7\u63a8\u7406\u9a8c\u8bc1\u6709\u6548\u89e3\u51b3\u4e86\u91d1\u878d\u51b3\u7b56\u4e2dRL\u7684\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\uff0c\u4e3a\u968f\u673a\u73af\u5883\u4e2d\u7684\u53ef\u9a8c\u8bc1\u5956\u52b1\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f"}}
{"id": "2601.03969", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03969", "abs": "https://arxiv.org/abs/2601.03969", "authors": ["Wei Wu", "Liyi Chen", "Congxi Xiao", "Tianfu Wang", "Qimeng Wang", "Chengqiang Lu", "Yan Gao", "Yi Wu", "Yao Hu", "Hui Xiong"], "title": "Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models", "comment": null, "summary": "Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing efficient reasoning methods relying on explicit length penalties often introduce optimization conflicts and leave the generative mechanisms driving overthinking largely unexamined. In this paper, we identify a phenomenon termed length shift where models increasingly generate unnecessary reasoning on trivial inputs during training. To address this, we introduce Dynamic Outlier Truncation (DOT), a training-time intervention that selectively suppresses redundant tokens. This method targets only the extreme tail of response lengths within fully correct rollout groups while preserving long-horizon reasoning capabilities for complex problems. To complement this intervention and ensure stable convergence, we further incorporate auxiliary KL regularization and predictive dynamic sampling. Experimental results across multiple model scales demonstrate that our approach significantly pushes the efficiency-performance Pareto frontier outward. Notably, on the AIME-24, our method reduces inference token usage by 78% while simultaneously increasing accuracy compared to the initial policy and surpassing state-of-the-art efficient reasoning methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDOT\u65b9\u6cd5\u89e3\u51b3\u5927\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u8fc7\u5ea6\u5197\u957f\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u622a\u65ad\u5197\u4f59token\u51cf\u5c1178%\u63a8\u7406token\u4f7f\u7528\uff0c\u540c\u65f6\u63d0\u5347\u51c6\u786e\u7387", "motivation": "\u73b0\u6709\u589e\u5f3a\u63a8\u7406\u6a21\u578b\u5728\u7b80\u5355\u67e5\u8be2\u4e0a\u8fc7\u5ea6\u5197\u957f\uff0c\u5bfc\u81f4\u90e8\u7f72\u6210\u672c\u9ad8\uff1b\u73b0\u6709\u57fa\u4e8e\u957f\u5ea6\u60e9\u7f5a\u7684\u65b9\u6cd5\u5b58\u5728\u4f18\u5316\u51b2\u7a81\uff0c\u4e14\u672a\u6df1\u5165\u63a2\u7a76\u8fc7\u5ea6\u601d\u8003\u7684\u751f\u6210\u673a\u5236", "method": "\u63d0\u51fa\u52a8\u6001\u5f02\u5e38\u622a\u65ad(DOT)\uff1a\u5728\u8bad\u7ec3\u65f6\u9009\u62e9\u6027\u6291\u5236\u5197\u4f59token\uff0c\u4ec5\u9488\u5bf9\u5b8c\u5168\u6b63\u786erollout\u7ec4\u4e2d\u7684\u6781\u7aef\u957f\u5ea6\u5c3e\u90e8\uff1b\u7ed3\u5408\u8f85\u52a9KL\u6b63\u5219\u5316\u548c\u9884\u6d4b\u52a8\u6001\u91c7\u6837\u786e\u4fdd\u7a33\u5b9a\u6536\u655b", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u89c4\u6a21\u4e0a\u663e\u8457\u6269\u5c55\u6548\u7387-\u6027\u80fd\u5e15\u7d2f\u6258\u524d\u6cbf\uff1b\u5728AIME-24\u4e0a\u51cf\u5c1178%\u63a8\u7406token\u4f7f\u7528\uff0c\u540c\u65f6\u63d0\u9ad8\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u73b0\u6709\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5", "conclusion": "DOT\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u957f\u5ea6\u504f\u79fb\u73b0\u8c61\uff0c\u5728\u4fdd\u6301\u590d\u6742\u95ee\u9898\u957f\u7a0b\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2601.04035", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04035", "abs": "https://arxiv.org/abs/2601.04035", "authors": ["Yilin Cao", "Yufeng Zhong", "Zhixiong Zeng", "Liming Zheng", "Jing Huang", "Haibo Qiu", "Peng Shi", "Wenji Mao", "Wan Guanglu"], "title": "MobileDreamer: Generative Sketch World Model for GUI Agent", "comment": null, "summary": "Mobile GUI agents have shown strong potential in real-world automation and practical applications. However, most existing agents remain reactive, making decisions mainly from current screen, which limits their performance on long-horizon tasks. Building a world model from repeated interactions enables forecasting action outcomes and supports better decision making for mobile GUI agents. This is challenging because the model must predict post-action states with spatial awareness while remaining efficient enough for practical deployment. In this paper, we propose MobileDreamer, an efficient world-model-based lookahead framework to equip the GUI agents based on the future imagination provided by the world model. It consists of textual sketch world model and rollout imagination for GUI agent. Textual sketch world model forecasts post-action states through a learning process to transform digital images into key task-related sketches, and designs a novel order-invariant learning strategy to preserve the spatial information of GUI elements. The rollout imagination strategy for GUI agent optimizes the action-selection process by leveraging the prediction capability of world model. Experiments on Android World show that MobileDreamer achieves state-of-the-art performance and improves task success by 5.25%. World model evaluations further verify that our textual sketch modeling accurately forecasts key GUI elements.", "AI": {"tldr": "MobileDreamer\uff1a\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u7684\u79fb\u52a8GUI\u667a\u80fd\u4f53\u524d\u77bb\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u672c\u8349\u56fe\u4e16\u754c\u6a21\u578b\u9884\u6d4b\u52a8\u4f5c\u540e\u72b6\u6001\uff0c\u63d0\u5347\u957f\u65f6\u7a0b\u4efb\u52a1\u6027\u80fd", "motivation": "\u73b0\u6709\u79fb\u52a8GUI\u667a\u80fd\u4f53\u591a\u4e3a\u53cd\u5e94\u5f0f\uff0c\u4e3b\u8981\u4f9d\u8d56\u5f53\u524d\u5c4f\u5e55\u4fe1\u606f\u8fdb\u884c\u51b3\u7b56\uff0c\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u53d7\u9650\u3002\u6784\u5efa\u4e16\u754c\u6a21\u578b\u80fd\u591f\u9884\u6d4b\u52a8\u4f5c\u7ed3\u679c\uff0c\u652f\u6301\u66f4\u597d\u7684\u51b3\u7b56\u5236\u5b9a\u3002", "method": "\u63d0\u51faMobileDreamer\u6846\u67b6\uff0c\u5305\u542b\u6587\u672c\u8349\u56fe\u4e16\u754c\u6a21\u578b\u548c\u6eda\u52a8\u60f3\u8c61\u7b56\u7565\u3002\u6587\u672c\u8349\u56fe\u4e16\u754c\u6a21\u578b\u5c06\u6570\u5b57\u56fe\u50cf\u8f6c\u6362\u4e3a\u5173\u952e\u4efb\u52a1\u76f8\u5173\u8349\u56fe\uff0c\u91c7\u7528\u987a\u5e8f\u4e0d\u53d8\u5b66\u4e60\u7b56\u7565\u4fdd\u6301GUI\u5143\u7d20\u7a7a\u95f4\u4fe1\u606f\uff1b\u6eda\u52a8\u60f3\u8c61\u7b56\u7565\u5229\u7528\u4e16\u754c\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u4f18\u5316\u52a8\u4f5c\u9009\u62e9\u8fc7\u7a0b\u3002", "result": "\u5728Android World\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMobileDreamer\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4efb\u52a1\u6210\u529f\u7387\u63d0\u53475.25%\u3002\u4e16\u754c\u6a21\u578b\u8bc4\u4f30\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u6587\u672c\u8349\u56fe\u5efa\u6a21\u80fd\u51c6\u786e\u9884\u6d4b\u5173\u952eGUI\u5143\u7d20\u3002", "conclusion": "MobileDreamer\u901a\u8fc7\u9ad8\u6548\u7684\u4e16\u754c\u6a21\u578b\u524d\u77bb\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79fb\u52a8GUI\u667a\u80fd\u4f53\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.04060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04060", "abs": "https://arxiv.org/abs/2601.04060", "authors": ["Jinwei Su", "Qizhen Lan", "Zeyu Wang", "Yinghui Xia", "Hairu Wen", "Yiqun Duan", "Xi Xiao", "Tianyu Shi", "Yang Jingsong", "Lewei He"], "title": "ComfySearch: Autonomous Exploration and Reasoning for ComfyUI Workflows", "comment": null, "summary": "AI-generated content has progressed from monolithic models to modular workflows, especially on platforms like ComfyUI, allowing users to customize complex creative pipelines. However, the large number of components in ComfyUI and the difficulty of maintaining long-horizon structural consistency under strict graph constraints frequently lead to low pass rates and workflows of limited quality. To tackle these limitations, we present ComfySearch, an agentic framework that can effectively explore the component space and generate functional ComfyUI pipelines via validation-guided workflow construction. Experiments demonstrate that ComfySearch substantially outperforms existing methods on complex and creative tasks, achieving higher executability (pass) rates, higher solution rates, and stronger generalization.", "AI": {"tldr": "ComfySearch\uff1a\u4e00\u4e2a\u57fa\u4e8e\u9a8c\u8bc1\u5f15\u5bfc\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u5728ComfyUI\u5e73\u53f0\u4e0a\u63a2\u7d22\u7ec4\u4ef6\u7a7a\u95f4\u5e76\u751f\u6210\u529f\u80fd\u6027\u5de5\u4f5c\u6d41\uff0c\u663e\u8457\u63d0\u5347\u6267\u884c\u6210\u529f\u7387\u3001\u89e3\u51b3\u65b9\u6848\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "ComfyUI\u5e73\u53f0\u4e0a\u7684AI\u751f\u6210\u5185\u5bb9\u5df2\u4ece\u5355\u4e00\u6a21\u578b\u53d1\u5c55\u5230\u6a21\u5757\u5316\u5de5\u4f5c\u6d41\uff0c\u4f46\u5927\u91cf\u7ec4\u4ef6\u548c\u4e25\u683c\u56fe\u7ea6\u675f\u4e0b\u4fdd\u6301\u957f\u671f\u7ed3\u6784\u4e00\u81f4\u6027\u56f0\u96be\uff0c\u5bfc\u81f4\u6267\u884c\u901a\u8fc7\u7387\u4f4e\u3001\u5de5\u4f5c\u6d41\u8d28\u91cf\u6709\u9650\u3002", "method": "\u63d0\u51faComfySearch\u6846\u67b6\uff0c\u91c7\u7528\u667a\u80fd\u4f53\u63a2\u7d22\u7ec4\u4ef6\u7a7a\u95f4\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5f15\u5bfc\u7684\u5de5\u4f5c\u6d41\u6784\u5efa\u65b9\u6cd5\u751f\u6210\u529f\u80fd\u6027ComfyUI\u7ba1\u9053\u3002", "result": "\u5b9e\u9a8c\u8868\u660eComfySearch\u5728\u590d\u6742\u521b\u610f\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6267\u884c\u901a\u8fc7\u7387\u3001\u89e3\u51b3\u65b9\u6848\u7387\u548c\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "ComfySearch\u6709\u6548\u89e3\u51b3\u4e86ComfyUI\u5e73\u53f0\u4e2d\u7ec4\u4ef6\u7a7a\u95f4\u63a2\u7d22\u548c\u5de5\u4f5c\u6d41\u6784\u5efa\u7684\u6311\u6218\uff0c\u4e3a\u6a21\u5757\u5316AI\u5185\u5bb9\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.04170", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04170", "abs": "https://arxiv.org/abs/2601.04170", "authors": ["Abhishek Rath"], "title": "Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions", "comment": null, "summary": "Multi-agent Large Language Model (LLM) systems have emerged as powerful architectures for complex task decomposition and collaborative problem-solving. However, their long-term behavioral stability remains largely unexamined. This study introduces the concept of agent drift, defined as the progressive degradation of agent behavior, decision quality, and inter-agent coherence over extended interaction sequences. We present a comprehensive theoretical framework for understanding drift phenomena, proposing three distinct manifestations: semantic drift (progressive deviation from original intent), coordination drift (breakdown in multi-agent consensus mechanisms), and behavioral drift (emergence of unintended strategies).\n  We introduce the Agent Stability Index (ASI), a novel composite metric framework for quantifying drift across twelve dimensions, including response consistency, tool usage patterns, reasoning pathway stability, and inter-agent agreement rates. Through simulation-based analysis and theoretical modeling, we demonstrate how unchecked agent drift can lead to substantial reductions in task completion accuracy and increased human intervention requirements.\n  We propose three mitigation strategies: episodic memory consolidation, drift-aware routing protocols, and adaptive behavioral anchoring. Theoretical analysis suggests these approaches can significantly reduce drift-related errors while maintaining system throughput. This work establishes a foundational methodology for monitoring, measuring, and mitigating agent drift in production agentic AI systems, with direct implications for enterprise deployment reliability and AI safety research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\"\u667a\u80fd\u4f53\u6f02\u79fb\"\u6982\u5ff5\uff0c\u6307\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u4e2d\u884c\u4e3a\u3001\u51b3\u7b56\u8d28\u91cf\u548c\u534f\u4f5c\u4e00\u81f4\u6027\u968f\u65f6\u95f4\u9010\u6e10\u9000\u5316\u7684\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u91cf\u5316\u6846\u67b6\u548c\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5728\u590d\u6742\u4efb\u52a1\u5206\u89e3\u548c\u534f\u4f5c\u89e3\u51b3\u95ee\u9898\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5176\u957f\u671f\u884c\u4e3a\u7a33\u5b9a\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u9700\u8981\u7406\u89e3\u667a\u80fd\u4f53\u5728\u957f\u65f6\u95f4\u4ea4\u4e92\u5e8f\u5217\u4e2d\u884c\u4e3a\u9000\u5316\u7684\u73b0\u8c61\u53ca\u5176\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u667a\u80fd\u4f53\u6f02\u79fb\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5305\u62ec\u8bed\u4e49\u6f02\u79fb\u3001\u534f\u8c03\u6f02\u79fb\u548c\u884c\u4e3a\u6f02\u79fb\u4e09\u79cd\u8868\u73b0\u5f62\u5f0f\u3002\u5f00\u53d1\u4e86\u667a\u80fd\u4f53\u7a33\u5b9a\u6027\u6307\u6570\uff08ASI\uff09\uff0c\u4e00\u4e2a\u5305\u542b12\u4e2a\u7ef4\u5ea6\u7684\u590d\u5408\u5ea6\u91cf\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u6f02\u79fb\u73b0\u8c61\u3002\u901a\u8fc7\u6a21\u62df\u5206\u6790\u548c\u7406\u8bba\u5efa\u6a21\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u672a\u53d7\u63a7\u5236\u7684\u667a\u80fd\u4f53\u6f02\u79fb\u4f1a\u5bfc\u81f4\u4efb\u52a1\u5b8c\u6210\u51c6\u786e\u7387\u663e\u8457\u4e0b\u964d\uff0c\u5e76\u589e\u52a0\u4eba\u5de5\u5e72\u9884\u9700\u6c42\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u63d0\u51fa\u7684\u7f13\u89e3\u7b56\u7565\uff08\u60c5\u666f\u8bb0\u5fc6\u6574\u5408\u3001\u6f02\u79fb\u611f\u77e5\u8def\u7531\u534f\u8bae\u3001\u81ea\u9002\u5e94\u884c\u4e3a\u951a\u5b9a\uff09\u80fd\u663e\u8457\u51cf\u5c11\u6f02\u79fb\u76f8\u5173\u9519\u8bef\uff0c\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u541e\u5410\u91cf\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u76d1\u6d4b\u3001\u6d4b\u91cf\u548c\u7f13\u89e3\u751f\u4ea7\u7ea7\u667a\u80fdAI\u7cfb\u7edf\u4e2d\u7684\u667a\u80fd\u4f53\u6f02\u79fb\u5efa\u7acb\u4e86\u57fa\u7840\u65b9\u6cd5\u8bba\uff0c\u5bf9\u4f01\u4e1a\u90e8\u7f72\u53ef\u9760\u6027\u548cAI\u5b89\u5168\u7814\u7a76\u5177\u6709\u76f4\u63a5\u610f\u4e49\u3002"}}
