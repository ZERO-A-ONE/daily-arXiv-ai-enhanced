{"id": "2511.11999", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.11999", "abs": "https://arxiv.org/abs/2511.11999", "authors": ["Zeyu Lu", "Peng Zhang", "Chun Yong Chong", "Shan Gao", "Yibiao Yang", "Yanhui Li", "Lin Chen", "Yuming Zhou"], "title": "WITNESS: A lightweight and practical approach to fine-grained predictive mutation testing", "comment": null, "summary": "Existing fine-grained predictive mutation testing studies predominantly rely on deep learning, which faces two critical limitations in practice: (1) Exorbitant computational costs. The deep learning models adopted in these studies demand significant computational resources for training and inference acceleration. This introduces high costs and undermines the cost-reduction goal of predictive mutation testing. (2) Constrained applicability. Although modern mutation testing tools generate mutants both inside and outside methods, current fine-grained predictive mutation testing approaches handle only inside-method mutants. As a result, they cannot predict outside-method mutants, limiting their applicability in real-world scenarios. We propose WITNESS, a new fine-grained predictive mutation testing approach. WITNESS adopts a twofold design: (1) With collected features from both inside-method and outside-method mutants, WITNESS is suitable for all generated mutants. (2) Instead of using computationally expensive deep learning, WITNESS employs lightweight classical machine learning models for training and prediction. This makes it more cost-effective and enabling straightforward explanations of the decision-making processes behind the adopted models. Evaluations on Defects4J projects show that WITNESS consistently achieves state-of-the-art predictive performance across different scenarios. Additionally, WITNESS significantly enhances the efficiency of kill matrix prediction. Post-hoc analysis reveals that features incorporating information from before and after the mutation are the most important among those used in WITNESS. Test case prioritization based on the predicted kill matrix shows that WITNESS delivers results much closer to those obtained by using the actual kill matrix, outperforming baseline approaches.", "AI": {"tldr": "WITNESS\u662f\u4e00\u79cd\u65b0\u7684\u7ec6\u7c92\u5ea6\u9884\u6d4b\u6027\u53d8\u5f02\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u800c\u975e\u6df1\u5ea6\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u9002\u7528\u8303\u56f4\u53d7\u9650\u7684\u95ee\u9898\uff0c\u80fd\u591f\u5904\u7406\u6240\u6709\u751f\u6210\u7684\u53d8\u5f02\u4f53\u5e76\u663e\u8457\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7ec6\u7c92\u5ea6\u9884\u6d4b\u6027\u53d8\u5f02\u6d4b\u8bd5\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a(1)\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u4e0e\u9884\u6d4b\u6027\u53d8\u5f02\u6d4b\u8bd5\u964d\u4f4e\u6210\u672c\u7684\u76ee\u6807\u76f8\u6096\uff1b(2)\u9002\u7528\u8303\u56f4\u53d7\u9650\uff0c\u53ea\u80fd\u5904\u7406\u65b9\u6cd5\u5185\u53d8\u5f02\u4f53\u800c\u65e0\u6cd5\u9884\u6d4b\u65b9\u6cd5\u5916\u53d8\u5f02\u4f53\u3002", "method": "WITNESS\u91c7\u7528\u53cc\u91cd\u8bbe\u8ba1\uff1a(1)\u6536\u96c6\u65b9\u6cd5\u5185\u548c\u65b9\u6cd5\u5916\u53d8\u5f02\u4f53\u7684\u7279\u5f81\uff0c\u9002\u7528\u4e8e\u6240\u6709\u751f\u6210\u7684\u53d8\u5f02\u4f53\uff1b(2)\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b\uff0c\u800c\u975e\u8ba1\u7b97\u6602\u8d35\u7684\u6df1\u5ea6\u5b66\u4e60\u3002", "result": "\u5728Defects4J\u9879\u76ee\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cWITNESS\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u59cb\u7ec8\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6740\u6b7b\u77e9\u9635\u9884\u6d4b\u7684\u6548\u7387\u3002\u540e\u5206\u6790\u8868\u660e\uff0c\u5305\u542b\u53d8\u5f02\u524d\u540e\u4fe1\u606f\u7684\u7279\u5f81\u662f\u6700\u91cd\u8981\u7684\u3002", "conclusion": "\u57fa\u4e8e\u9884\u6d4b\u6740\u6b7b\u77e9\u9635\u7684\u6d4b\u8bd5\u7528\u4f8b\u4f18\u5148\u7ea7\u6392\u5e8f\u8868\u660e\uff0cWITNESS\u63d0\u4f9b\u7684\u7ed3\u679c\u66f4\u63a5\u8fd1\u4f7f\u7528\u5b9e\u9645\u6740\u6b7b\u77e9\u9635\u83b7\u5f97\u7684\u7ed3\u679c\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12069", "categories": ["cs.SE", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.12069", "abs": "https://arxiv.org/abs/2511.12069", "authors": ["HanYu Zhang", "Tomoji Kishi"], "title": "A Code Smell Refactoring Approach using GNNs", "comment": null, "summary": "Code smell is a great challenge in software refactoring, which indicates latent design or implementation flaws that may degrade the software maintainability and evolution. Over the past decades, a variety of refactoring approaches have been proposed, which can be broadly classified into metrics-based, rule-based, and machine learning-based approaches. Recent years, deep learning-based approaches have also attracted widespread attention. However, existing techniques exhibit various limitations. Metrics- and rule-based approaches rely heavily on manually defined heuristics and thresholds, whereas deep learning-based approaches are often constrained by dataset availability and model design. In this study, we proposed a graph-based deep learning approach for code smell refactoring. Specifically, we designed two types of input graphs (class-level and method-level) and employed both graph classification and node classification tasks to address the refactoring of three representative code smells: long method, large class, and feature envy. In our experiment, we propose a semi-automated dataset generation approach that could generate a large-scale dataset with minimal manual effort. We implemented the proposed approach with three classical GNN (graph neural network) architectures: GCN, GraphSAGE, and GAT, and evaluated its performance against both traditional and state-of-the-art deep learning approaches. The results demonstrate that proposed approach achieves superior refactoring performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7528\u4e8e\u4ee3\u7801\u5f02\u5473\u91cd\u6784\uff0c\u901a\u8fc7\u8bbe\u8ba1\u7c7b\u7ea7\u548c\u65b9\u6cd5\u7ea7\u8f93\u5165\u56fe\uff0c\u4f7f\u7528\u56fe\u5206\u7c7b\u548c\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u6765\u5904\u7406\u957f\u65b9\u6cd5\u3001\u5927\u7c7b\u3001\u7279\u5f81\u5ac9\u5992\u4e09\u79cd\u4ee3\u7801\u5f02\u5473\uff0c\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u91cd\u6784\u6027\u80fd\u3002", "motivation": "\u4ee3\u7801\u5f02\u5473\u662f\u8f6f\u4ef6\u91cd\u6784\u4e2d\u7684\u91cd\u5927\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u57fa\u4e8e\u6307\u6807\u548c\u89c4\u5219\u7684\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u624b\u52a8\u5b9a\u4e49\u7684\u542f\u53d1\u5f0f\u89c4\u5219\u548c\u9608\u503c\uff0c\u800c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u53d7\u9650\u4e8e\u6570\u636e\u96c6\u53ef\u7528\u6027\u548c\u6a21\u578b\u8bbe\u8ba1\u3002", "method": "\u8bbe\u8ba1\u4e24\u79cd\u8f93\u5165\u56fe\uff08\u7c7b\u7ea7\u548c\u65b9\u6cd5\u7ea7\uff09\uff0c\u91c7\u7528\u56fe\u5206\u7c7b\u548c\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\uff0c\u4f7f\u7528\u4e09\u79cd\u7ecf\u5178GNN\u67b6\u6784\uff08GCN\u3001GraphSAGE\u3001GAT\uff09\uff0c\u5e76\u63d0\u51fa\u534a\u81ea\u52a8\u6570\u636e\u96c6\u751f\u6210\u65b9\u6cd5\u4ee5\u6700\u5c0f\u5316\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u91cd\u6784\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u56fe\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u4ee3\u7801\u5f02\u5473\u91cd\u6784\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u8f6f\u4ef6\u91cd\u6784\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2511.12229", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12229", "abs": "https://arxiv.org/abs/2511.12229", "authors": ["Zhipeng Xue", "Zhipeng Gao", "Tongtong Xu", "Xing Hu", "Xin Xia", "Shanping Li"], "title": "Actionable Warning Is Not Enough: Recommending Valid Actionable Warnings with Weak Supervision", "comment": null, "summary": "The use of static analysis tools has gained increasing popularity among developers in the last few years. However, the widespread adoption of static analysis tools is hindered by their high false alarm rates. Previous studies have introduced the concept of actionable warnings and built a machine-learning method to distinguish actionable warnings from false alarms. However, according to our empirical observation, the current assumption used for actionable warning(s) collection is rather shaky and inaccurate, leading to a large number of invalid actionable warnings. To address this problem, in this study, we build the first large actionable warning dataset by mining 68,274 reversions from Top-500 GitHub C repositories, we then take one step further by assigning each actionable warning a weak label regarding its likelihood of being a real bug. Following that, we propose a two-stage framework called ACWRecommender to automatically recommend the actionable warnings with high probability to be real bugs (AWHB). Our approach warms up the pre-trained model UniXcoder by identifying actionable warnings task (coarse-grained detection stage) and rerank AWHB to the top by weakly supervised learning (fine-grained reranking stage). Experimental results show that our proposed model outperforms several baselines by a large margin in terms of nDCG and MRR for AWHB recommendation. Moreover, we ran our tool on 6 randomly selected projects and manually checked the top-ranked warnings from 2,197 reported warnings, we reported top-10 recommended warnings to developers, 27 of them were already confirmed by developers as real bugs. Developers can quickly find real bugs among the massive amount of reported warnings, which verifies the practical usage of our tool.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faACWRecommender\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\u4ece\u9759\u6001\u5206\u6790\u5de5\u5177\u7684\u5927\u91cf\u8b66\u544a\u4e2d\u63a8\u8350\u9ad8\u6982\u7387\u4e3a\u771f\u5b9ebug\u7684\u53ef\u64cd\u4f5c\u8b66\u544a\uff0c\u663e\u8457\u63d0\u5347\u4e86bug\u68c0\u6d4b\u6548\u7387\u3002", "motivation": "\u9759\u6001\u5206\u6790\u5de5\u5177\u7684\u9ad8\u8bef\u62a5\u7387\u963b\u788d\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\uff0c\u73b0\u6709\u65b9\u6cd5\u5bf9\u53ef\u64cd\u4f5c\u8b66\u544a\u7684\u6536\u96c6\u5047\u8bbe\u4e0d\u51c6\u786e\uff0c\u5bfc\u81f4\u5927\u91cf\u65e0\u6548\u8b66\u544a\u3002", "method": "\u6784\u5efa\u9996\u4e2a\u5927\u578b\u53ef\u64cd\u4f5c\u8b66\u544a\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7c97\u7c92\u5ea6\u68c0\u6d4b\u9636\u6bb5\u8bc6\u522b\u53ef\u64cd\u4f5c\u8b66\u544a\uff0c\u7ec6\u7c92\u5ea6\u91cd\u6392\u9636\u6bb5\u901a\u8fc7\u5f31\u76d1\u7763\u5b66\u4e60\u5c06\u9ad8\u6982\u7387bug\u8b66\u544a\u6392\u5230\u9876\u90e8\u3002", "result": "\u5b9e\u9a8c\u8868\u660eACWRecommender\u5728nDCG\u548cMRR\u6307\u6807\u4e0a\u5927\u5e45\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u57286\u4e2a\u9879\u76ee\u4e2d\u9a8c\u8bc1\u4e8627\u4e2a\u5f00\u53d1\u8005\u786e\u8ba4\u7684\u771f\u5b9ebug\u3002", "conclusion": "\u8be5\u5de5\u5177\u80fd\u5e2e\u52a9\u5f00\u53d1\u8005\u4ece\u6d77\u91cf\u8b66\u544a\u4e2d\u5feb\u901f\u5b9a\u4f4d\u771f\u5b9ebug\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.11759", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.11759", "abs": "https://arxiv.org/abs/2511.11759", "authors": ["Fred Heiding", "Simon Lermen"], "title": "Can AI Models be Jailbroken to Phish Elderly Victims? An End-to-End Evaluation", "comment": null, "summary": "We present an end-to-end demonstration of how attackers can exploit AI safety failures to harm vulnerable populations: from jailbreaking LLMs to generate phishing content, to deploying those messages against real targets, to successfully compromising elderly victims. We systematically evaluated safety guardrails across six frontier LLMs spanning four attack categories, revealing critical failures where several models exhibited near-complete susceptibility to certain attack vectors. In a human validation study with 108 senior volunteers, AI-generated phishing emails successfully compromised 11\\% of participants. Our work uniquely demonstrates the complete attack pipeline targeting elderly populations, highlighting that current AI safety measures fail to protect those most vulnerable to fraud. Beyond generating phishing content, LLMs enable attackers to overcome language barriers and conduct multi-turn trust-building conversations at scale, fundamentally transforming fraud economics. While some providers report voluntary counter-abuse efforts, we argue these remain insufficient.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u653b\u51fb\u8005\u5982\u4f55\u5229\u7528AI\u5b89\u5168\u6f0f\u6d1e\u5371\u5bb3\u5f31\u52bf\u7fa4\u4f53\u7684\u5b8c\u6574\u653b\u51fb\u94fe\uff1a\u4ece\u8d8a\u72f1LLM\u751f\u6210\u9493\u9c7c\u5185\u5bb9\uff0c\u5230\u9488\u5bf9\u771f\u5b9e\u76ee\u6807\u90e8\u7f72\u8fd9\u4e9b\u4fe1\u606f\uff0c\u6700\u7ec8\u6210\u529f\u4fb5\u5bb3\u8001\u5e74\u53d7\u5bb3\u8005\u3002\u7814\u7a76\u53d1\u73b0\u591a\u4e2a\u524d\u6cbfLLM\u5728\u5b89\u5168\u9632\u62a4\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0cAI\u751f\u6210\u7684\u9493\u9c7c\u90ae\u4ef6\u6210\u529f\u9a97\u53d6\u4e8611%\u7684\u8001\u5e74\u53c2\u4e0e\u8005\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63ed\u793aAI\u5b89\u5168\u63aa\u65bd\u5728\u4fdd\u62a4\u6700\u6613\u53d7\u6b3a\u8bc8\u7684\u5f31\u52bf\u7fa4\u4f53\uff08\u7279\u522b\u662f\u8001\u5e74\u4eba\uff09\u65b9\u9762\u7684\u5931\u8d25\u73b0\u72b6\uff0c\u5c55\u793a\u653b\u51fb\u8005\u5982\u4f55\u5229\u7528LLM\u7a81\u7834\u8bed\u8a00\u969c\u788d\u3001\u8fdb\u884c\u5927\u89c4\u6a21\u4fe1\u4efb\u5efa\u7acb\u5bf9\u8bdd\uff0c\u4ece\u800c\u6839\u672c\u6539\u53d8\u6b3a\u8bc8\u7ecf\u6d4e\u6a21\u5f0f\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\uff1a\u7cfb\u7edf\u8bc4\u4f30\u516d\u4e2a\u524d\u6cbfLLM\u5728\u56db\u7c7b\u653b\u51fb\u5411\u91cf\u4e0b\u7684\u5b89\u5168\u9632\u62a4\u80fd\u529b\uff1b\u901a\u8fc7\u4eba\u7c7b\u9a8c\u8bc1\u7814\u7a76\uff0c\u8ba9108\u540d\u8001\u5e74\u5fd7\u613f\u8005\u6d4b\u8bd5AI\u751f\u6210\u7684\u9493\u9c7c\u90ae\u4ef6\u7684\u6709\u6548\u6027\uff1b\u5c55\u793a\u4eceLLM\u8d8a\u72f1\u5230\u5b9e\u9645\u53d7\u5bb3\u8005\u59a5\u534f\u7684\u5b8c\u6574\u653b\u51fb\u6d41\u7a0b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u591a\u4e2a\u6a21\u578b\u5728\u67d0\u4e9b\u653b\u51fb\u5411\u91cf\u4e0b\u8868\u73b0\u51fa\u8fd1\u4e4e\u5b8c\u5168\u7684\u6613\u53d7\u653b\u51fb\u6027\uff1bAI\u751f\u6210\u7684\u9493\u9c7c\u90ae\u4ef6\u6210\u529f\u9a97\u53d6\u4e8611%\u7684\u8001\u5e74\u53c2\u4e0e\u8005\uff1b\u8bc1\u660e\u4e86\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528LLM\u514b\u670d\u8bed\u8a00\u969c\u788d\uff0c\u8fdb\u884c\u5927\u89c4\u6a21\u591a\u8f6e\u4fe1\u4efb\u5efa\u7acb\u5bf9\u8bdd\u3002", "conclusion": "\u5f53\u524dAI\u5b89\u5168\u63aa\u65bd\u65e0\u6cd5\u6709\u6548\u4fdd\u62a4\u6700\u6613\u53d7\u6b3a\u8bc8\u7684\u5f31\u52bf\u7fa4\u4f53\uff1b\u867d\u7136\u90e8\u5206\u63d0\u4f9b\u5546\u62a5\u544a\u4e86\u81ea\u613f\u7684\u53cd\u6ee5\u7528\u52aa\u529b\uff0c\u4f46\u8fd9\u4e9b\u63aa\u65bd\u4ecd\u7136\u4e0d\u8db3\uff1bLLM\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u4e86\u6b3a\u8bc8\u7ecf\u6d4e\u6a21\u5f0f\uff0c\u9700\u8981\u66f4\u5f3a\u6709\u529b\u7684\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u3002"}}
{"id": "2511.11591", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11591", "abs": "https://arxiv.org/abs/2511.11591", "authors": ["Olusola Babalola", "Bolanle Ojokoh", "Olutayo Boyinbode"], "title": "LLM-Generated Negative News Headlines Dataset: Creation and Benchmarking Against Real Journalism", "comment": "50 pages, 19 figures, 9 tables", "summary": "This research examines the potential of datasets generated by Large Language Models (LLMs) to support Natural Language Processing (NLP) tasks, aiming to overcome challenges related to data acquisition and privacy concerns associated with real-world data. Focusing on negative valence text, a critical component of sentiment analysis, we explore the use of LLM-generated synthetic news headlines as an alternative to real-world data. A specialized corpus of negative news headlines was created using tailored prompts to capture diverse negative sentiments across various societal domains. The synthetic headlines were validated by expert review and further analyzed in embedding space to assess their alignment with real-world negative news in terms of content, tone, length, and style. Key metrics such as correlation with real headlines, perplexity, coherence, and realism were evaluated. The synthetic dataset was benchmarked against two sets of real news headlines using evaluations including the Comparative Perplexity Test, Comparative Readability Test, Comparative POS Profiling, BERTScore, and Comparative Semantic Similarity. Results show the generated headlines match real headlines with the only marked divergence being in the proper noun score of the POS profile test.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5408\u6210\u6570\u636e\u96c6\u6765\u652f\u6301\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u7684\u6f5c\u529b\uff0c\u7279\u522b\u5173\u6ce8\u8d1f\u9762\u60c5\u611f\u6587\u672c\uff0c\u901a\u8fc7\u751f\u6210\u5408\u6210\u65b0\u95fb\u6807\u9898\u6765\u66ff\u4ee3\u771f\u5b9e\u6570\u636e\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u83b7\u53d6\u548c\u9690\u79c1\u95ee\u9898\u3002", "motivation": "\u514b\u670d\u771f\u5b9e\u4e16\u754c\u6570\u636e\u83b7\u53d6\u7684\u6311\u6218\u548c\u9690\u79c1\u95ee\u9898\uff0c\u63a2\u7d22LLM\u751f\u6210\u6570\u636e\u5728NLP\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u9488\u5bf9\u8d1f\u9762\u60c5\u611f\u5206\u6790\u8fd9\u4e00\u5173\u952e\u9886\u57df\u3002", "method": "\u4f7f\u7528\u5b9a\u5236\u63d0\u793a\u521b\u5efa\u8d1f\u9762\u65b0\u95fb\u6807\u9898\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u548c\u5d4c\u5165\u7a7a\u95f4\u5206\u6790\u9a8c\u8bc1\u5408\u6210\u6807\u9898\uff0c\u91c7\u7528\u56f0\u60d1\u5ea6\u3001\u53ef\u8bfb\u6027\u3001\u8bcd\u6027\u6807\u6ce8\u5206\u6790\u3001BERTScore\u548c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7b49\u591a\u79cd\u6307\u6807\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u751f\u6210\u7684\u6807\u9898\u5728\u5185\u5bb9\u3001\u8bed\u6c14\u3001\u957f\u5ea6\u548c\u98ce\u683c\u4e0a\u4e0e\u771f\u5b9e\u6807\u9898\u9ad8\u5ea6\u5339\u914d\uff0c\u4ec5\u5728\u8bcd\u6027\u6807\u6ce8\u5206\u6790\u4e2d\u7684\u4e13\u6709\u540d\u8bcd\u5f97\u5206\u65b9\u9762\u5b58\u5728\u660e\u663e\u5dee\u5f02\u3002", "conclusion": "LLM\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u96c6\u5728\u8d1f\u9762\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\u5177\u6709\u66ff\u4ee3\u771f\u5b9e\u6570\u636e\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6570\u636e\u83b7\u53d6\u548c\u9690\u79c1\u95ee\u9898\uff0c\u4e3aNLP\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u636e\u6765\u6e90\u9014\u5f84\u3002"}}
{"id": "2511.12288", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12288", "abs": "https://arxiv.org/abs/2511.12288", "authors": ["Yihan Dai", "Sijie Liang", "Haotian Xu", "Peichu Xie", "Sergey Mechtaev"], "title": "Reducing Hallucinations in LLM-Generated Code via Semantic Triangulation", "comment": null, "summary": "When generating code from natural language prompts, an LLM samples programs from a probability distribution, many of which might be incorrect. Sample consensus techniques - such as majority voting or validation against generated tests or specifications - aim to identify a correct program in the sample or abstain if none is valid. However, existing methods often fail to select a correct solution when its sampling probability is low, or when the problem permits multiple valid but non-equivalent solutions. Additionally, they often fail to abstain when no correct solution is present in the sample. To overcome these limitations, we introduce semantic triangulation, which transforms a programming problem in a way that non-trivially alters its semantics while preserving an exact, verifiable mapping between solutions before and after transformation. We theoretically establish that verifying consistency across such problem transformations increases confidence that generated programs reflect accurate generalization rather than spurious statistical correlations, enabling more reliable sample consensus and abstention. On the LiveCodeBench and CodeElo benchmarks, using GPT-4o and DeepSeek-V3 models, semantic triangulation increases reliability of generated code by 21% compared to the method that selects only high-confidence solutions with the probability threshold 0.5, while being able to pinpoint correct solutions at sampling probabilities as low as 0.14. Apart from that, it is also the only approach to consistently form true consensus on tasks with multiple valid but non-equivalent solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8bed\u4e49\u4e09\u89d2\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u95ee\u9898\u8f6c\u6362\u6765\u9a8c\u8bc1\u4ee3\u7801\u751f\u6210\u7684\u4e00\u81f4\u6027\uff0c\u63d0\u9ad8LLM\u751f\u6210\u4ee3\u7801\u7684\u53ef\u9760\u6027\uff0c\u5728\u4f4e\u6982\u7387\u91c7\u6837\u548c\u591a\u89e3\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u6837\u672c\u5171\u8bc6\u6280\u672f\u5728\u9009\u62e9\u6b63\u786e\u7a0b\u5e8f\u6216\u5f03\u6743\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u91c7\u6837\u6982\u7387\u4f4e\u6216\u5b58\u5728\u591a\u4e2a\u6709\u6548\u4f46\u4e0d\u7b49\u4ef7\u89e3\u51b3\u65b9\u6848\u65f6\u3002", "method": "\u5f15\u5165\u8bed\u4e49\u4e09\u89d2\u5316\uff0c\u901a\u8fc7\u975e\u5e73\u51e1\u6539\u53d8\u95ee\u9898\u8bed\u4e49\u4f46\u4fdd\u6301\u89e3\u51b3\u65b9\u6848\u95f4\u7cbe\u786e\u53ef\u9a8c\u8bc1\u6620\u5c04\u7684\u8f6c\u6362\uff0c\u9a8c\u8bc1\u8de8\u95ee\u9898\u8f6c\u6362\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728LiveCodeBench\u548cCodeElo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8bed\u4e49\u4e09\u89d2\u5316\u76f8\u6bd4\u6982\u7387\u9608\u503c0.5\u7684\u9ad8\u7f6e\u4fe1\u5ea6\u9009\u62e9\u65b9\u6cd5\uff0c\u53ef\u9760\u6027\u63d0\u9ad821%\uff0c\u80fd\u5728\u4f4e\u81f30.14\u7684\u91c7\u6837\u6982\u7387\u4e0b\u8bc6\u522b\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8bed\u4e49\u4e09\u89d2\u5316\u901a\u8fc7\u9a8c\u8bc1\u8de8\u95ee\u9898\u8f6c\u6362\u7684\u4e00\u81f4\u6027\uff0c\u80fd\u66f4\u53ef\u9760\u5730\u8bc6\u522b\u6b63\u786e\u7a0b\u5e8f\u5e76\u9002\u65f6\u5f03\u6743\uff0c\u7279\u522b\u662f\u5728\u591a\u89e3\u548c\u4f4e\u6982\u7387\u573a\u666f\u4e0b\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2511.11784", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11784", "abs": "https://arxiv.org/abs/2511.11784", "authors": ["Lama Sleem", "Jerome Francois", "Lujun Li", "Nathan Foucher", "Niccolo Gentile", "Radu State"], "title": "NegBLEURT Forest: Leveraging Inconsistencies for Detecting Jailbreak Attacks", "comment": null, "summary": "Jailbreak attacks designed to bypass safety mechanisms pose a serious threat by prompting LLMs to generate harmful or inappropriate content, despite alignment with ethical guidelines. Crafting universal filtering rules remains difficult due to their inherent dependence on specific contexts. To address these challenges without relying on threshold calibration or model fine-tuning, this work introduces a semantic consistency analysis between successful and unsuccessful responses, demonstrating that a negation-aware scoring approach captures meaningful patterns. Building on this insight, a novel detection framework called NegBLEURT Forest is proposed to evaluate the degree of alignment between outputs elicited by adversarial prompts and expected safe behaviors. It identifies anomalous responses using the Isolation Forest algorithm, enabling reliable jailbreak detection. Experimental results show that the proposed method consistently achieves top-tier performance, ranking first or second in accuracy across diverse models using the crafted dataset, while competing approaches exhibit notable sensitivity to model and data variations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNegBLEURT Forest\u7684\u65b0\u578b\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u6210\u529f\u4e0e\u4e0d\u6210\u529f\u54cd\u5e94\u4e4b\u95f4\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u6765\u68c0\u6d4bLLM\u8d8a\u72f1\u653b\u51fb\uff0c\u65e0\u9700\u4f9d\u8d56\u9608\u503c\u6821\u51c6\u6216\u6a21\u578b\u5fae\u8c03\u3002", "motivation": "\u8d8a\u72f1\u653b\u51fb\u80fd\u591f\u7ed5\u8fc7LLM\u7684\u5b89\u5168\u673a\u5236\u751f\u6210\u6709\u5bb3\u5185\u5bb9\uff0c\u800c\u901a\u7528\u8fc7\u6ee4\u89c4\u5219\u7531\u4e8e\u5bf9\u7279\u5b9a\u4e0a\u4e0b\u6587\u7684\u4f9d\u8d56\u800c\u96be\u4ee5\u5236\u5b9a\u3002", "method": "\u91c7\u7528\u5426\u5b9a\u611f\u77e5\u8bc4\u5206\u65b9\u6cd5\u6355\u83b7\u6709\u610f\u4e49\u7684\u6a21\u5f0f\uff0c\u5e76\u4f7f\u7528\u9694\u79bb\u68ee\u6797\u7b97\u6cd5\u8bc6\u522b\u5f02\u5e38\u54cd\u5e94\uff0c\u6784\u5efaNegBLEURT Forest\u68c0\u6d4b\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u4e0a\u5747\u53d6\u5f97\u9876\u7ea7\u6027\u80fd\uff0c\u5728\u51c6\u786e\u6027\u65b9\u9762\u6392\u540d\u7b2c\u4e00\u6216\u7b2c\u4e8c\uff0c\u800c\u7ade\u4e89\u65b9\u6cd5\u5bf9\u6a21\u578b\u548c\u6570\u636e\u53d8\u5316\u8868\u73b0\u51fa\u663e\u8457\u654f\u611f\u6027\u3002", "conclusion": "NegBLEURT Forest\u6846\u67b6\u80fd\u591f\u53ef\u9760\u5730\u68c0\u6d4b\u8d8a\u72f1\u653b\u51fb\uff0c\u5728\u591a\u6837\u5316\u7684\u6a21\u578b\u548c\u6570\u636e\u4e0a\u8868\u73b0\u7a33\u5b9a\u4e14\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.11597", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11597", "abs": "https://arxiv.org/abs/2511.11597", "authors": ["Michelle Chen Huebscher", "Katharine Mach", "Aleksandar Stani\u0107", "Markus Leippold", "Ben Gaiarin", "Zeke Hausfather", "Elisa Rawat", "Erich Fischer", "Massimiliano Ciaramita", "Joeri Rogelj", "Christian Buck", "Lierni Sestorain Saralegui", "Reto Knutti"], "title": "CLINB: A Climate Intelligence Benchmark for Foundational Models", "comment": "Questions, system prompt and model judge prompts available here: https://www.kaggle.com/datasets/deepmind/clinb-questions", "summary": "Evaluating how Large Language Models (LLMs) handle complex, specialized knowledge remains a critical challenge. We address this through the lens of climate change by introducing CLINB, a benchmark that assesses models on open-ended, grounded, multimodal question answering tasks with clear requirements for knowledge quality and evidential support. CLINB relies on a dataset of real users' questions and evaluation rubrics curated by leading climate scientists. We implement and validate a model-based evaluation process and evaluate several frontier models. Our findings reveal a critical dichotomy. Frontier models demonstrate remarkable knowledge synthesis capabilities, often exhibiting PhD-level understanding and presentation quality. They outperform \"hybrid\" answers curated by domain experts assisted by weaker models. However, this performance is countered by failures in grounding. The quality of evidence varies, with substantial hallucination rates for references and images. We argue that bridging this gap between knowledge synthesis and verifiable attribution is essential for the deployment of AI in scientific workflows and that reliable, interpretable benchmarks like CLINB are needed to progress towards building trustworthy AI systems.", "AI": {"tldr": "CLINB\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6c14\u5019\u53d8\u5316\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u5177\u5907\u535a\u58eb\u7ea7\u522b\u7684\u77e5\u8bc6\u7efc\u5408\u80fd\u529b\uff0c\u4f46\u5728\u8bc1\u636e\u57fa\u7840\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u590d\u6742\u4e13\u4e1a\u77e5\u8bc6\u7684\u80fd\u529b\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6c14\u5019\u53d8\u5316\u8fd9\u6837\u7684\u4e13\u4e1a\u9886\u57df\uff0c\u9700\u8981\u6d4b\u8bd5\u6a21\u578b\u7684\u77e5\u8bc6\u8d28\u91cf\u548c\u8bc1\u636e\u652f\u6301\u80fd\u529b\u3002", "method": "\u5f15\u5165CLINB\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528\u771f\u5b9e\u7528\u6237\u95ee\u9898\u548c\u6c14\u5019\u79d1\u5b66\u5bb6\u5236\u5b9a\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u901a\u8fc7\u57fa\u4e8e\u6a21\u578b\u7684\u8bc4\u4f30\u8fc7\u7a0b\u6d4b\u8bd5\u591a\u4e2a\u524d\u6cbf\u6a21\u578b\uff0c\u5305\u62ec\u5f00\u653e\u5f0f\u3001\u57fa\u4e8e\u4e8b\u5b9e\u7684\u591a\u6a21\u6001\u95ee\u7b54\u4efb\u52a1\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u77e5\u8bc6\u7efc\u5408\u80fd\u529b\uff0c\u8fbe\u5230\u535a\u58eb\u7ea7\u522b\u7684\u7406\u89e3\u548c\u5448\u73b0\u8d28\u91cf\uff0c\u751a\u81f3\u4f18\u4e8e\u4e13\u5bb6\u8f85\u52a9\u8f83\u5f31\u6a21\u578b\u751f\u6210\u7684\u6df7\u5408\u7b54\u6848\u3002\u4f46\u5b58\u5728\u4e25\u91cd\u7684\u8bc1\u636e\u57fa\u7840\u95ee\u9898\uff0c\u53c2\u8003\u6587\u732e\u548c\u56fe\u50cf\u5b58\u5728\u5927\u91cf\u5e7b\u89c9\u3002", "conclusion": "\u5728\u77e5\u8bc6\u7efc\u5408\u4e0e\u53ef\u9a8c\u8bc1\u5f52\u56e0\u4e4b\u95f4\u5efa\u7acb\u6865\u6881\u5bf9\u4e8eAI\u5728\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u50cfCLINB\u8fd9\u6837\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u6784\u5efa\u53ef\u4fe1\u8d56\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2511.11836", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11836", "abs": "https://arxiv.org/abs/2511.11836", "authors": ["Adaobi Amanna", "Ishana Shinde"], "title": "Securing Generative AI in Healthcare: A Zero-Trust Architecture Powered by Confidential Computing on Google Cloud", "comment": "19 Pages, 1 Figure, 1 Table", "summary": "The integration of Generative Artificial Intelligence (GenAI) in healthcare is impeded by significant security challenges unaddressed by traditional frameworks, precisely the data-in-use gap where sensitive patient data and proprietary AI models are exposed during active processing. To address this, the paper proposes the Confidential Zero-Trust Framework (CZF), a novel security paradigm that synergistically combines Zero-Trust Architecture for granular access control with the hardware-enforced data isolation of Confidential Computing. We detailed a multi-tiered architectural blueprint for implementing the CZF on Google Cloud and analyzed its efficacy against real-world threats. The CZF provides a defense-in-depth architecture where data remains encrypted while in-use within a hardware-based Trusted Execution Environment (TEE). The framework's use of remote attestation offers cryptographic proof of workload integrity, transforming compliance from a procedural exercise into a verifiable technical fact and enabling secure, multi-party collaborations previously blocked by security and intellectual property concerns. By closing the data-in-use gap and enforcing Zero-Trust principles, the CZF provides a robust and verifiable framework that establishes the necessary foundation of trust to enable the responsible adoption of transformative AI technologies in healthcare.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u673a\u5bc6\u96f6\u4fe1\u4efb\u6846\u67b6(CZF)\uff0c\u901a\u8fc7\u7ed3\u5408\u96f6\u4fe1\u4efb\u67b6\u6784\u548c\u673a\u5bc6\u8ba1\u7b97\u6765\u89e3\u51b3\u533b\u7597AI\u4e2d\u7684\u6570\u636e\u4f7f\u7528\u5b89\u5168\u6311\u6218\uff0c\u5728Google Cloud\u4e0a\u5b9e\u73b0\u591a\u5c42\u9632\u5fa1\u67b6\u6784\u3002", "motivation": "\u4f20\u7edf\u5b89\u5168\u6846\u67b6\u65e0\u6cd5\u89e3\u51b3\u533b\u7597\u9886\u57df\u751f\u6210\u5f0fAI\u5728\u6570\u636e\u5904\u7406\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u4f7f\u7528\u9636\u6bb5\u654f\u611f\u60a3\u8005\u6570\u636e\u548c\u4e13\u6709AI\u6a21\u578b\u9762\u4e34\u66b4\u9732\u98ce\u9669\u3002", "method": "\u63d0\u51faCZF\u6846\u67b6\uff0c\u5c06\u96f6\u4fe1\u4efb\u67b6\u6784\u7684\u7ec6\u7c92\u5ea6\u8bbf\u95ee\u63a7\u5236\u4e0e\u673a\u5bc6\u8ba1\u7b97\u7684\u786c\u4ef6\u5f3a\u5236\u6570\u636e\u9694\u79bb\u76f8\u7ed3\u5408\uff0c\u5728\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEE)\u4e2d\u4fdd\u6301\u6570\u636e\u52a0\u5bc6\u4f7f\u7528\uff0c\u5e76\u91c7\u7528\u8fdc\u7a0b\u8ba4\u8bc1\u63d0\u4f9b\u5de5\u4f5c\u8d1f\u8f7d\u5b8c\u6574\u6027\u8bc1\u660e\u3002", "result": "CZF\u63d0\u4f9b\u4e86\u6df1\u5ea6\u9632\u5fa1\u67b6\u6784\uff0c\u80fd\u591f\u62b5\u5fa1\u73b0\u5b9e\u5a01\u80c1\uff0c\u5c06\u5408\u89c4\u6027\u4ece\u7a0b\u5e8f\u6027\u6d3b\u52a8\u8f6c\u53d8\u4e3a\u53ef\u9a8c\u8bc1\u7684\u6280\u672f\u4e8b\u5b9e\uff0c\u652f\u6301\u4e4b\u524d\u56e0\u5b89\u5168\u548c\u77e5\u8bc6\u4ea7\u6743\u95ee\u9898\u53d7\u963b\u7684\u591a\u65b9\u5b89\u5168\u534f\u4f5c\u3002", "conclusion": "CZF\u901a\u8fc7\u586b\u8865\u6570\u636e\u4f7f\u7528\u5b89\u5168\u7a7a\u767d\u548c\u6267\u884c\u96f6\u4fe1\u4efb\u539f\u5219\uff0c\u4e3a\u533b\u7597\u9886\u57df\u8d1f\u8d23\u4efb\u5730\u91c7\u7528\u53d8\u9769\u6027AI\u6280\u672f\u5efa\u7acb\u4e86\u5fc5\u8981\u7684\u4fe1\u4efb\u57fa\u7840\u3002"}}
{"id": "2511.11896", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.11896", "abs": "https://arxiv.org/abs/2511.11896", "authors": ["Youpeng Li", "Fuxun Yu", "Xinda Wang"], "title": "VULPO: Context-Aware Vulnerability Detection via On-Policy LLM Optimization", "comment": null, "summary": "The widespread reliance on open-source software dramatically increases the risk of vulnerability exploitation, underscoring the need for effective and scalable vulnerability detection (VD). Existing VD techniques, whether traditional machine learning-based or LLM-based approaches like prompt engineering, supervised fine-tuning, or off-policy preference optimization, remain fundamentally limited in their ability to perform context-aware analysis: They depend on fixed inputs or static preference datasets, cannot adaptively explore repository-level dependencies, and are constrained by function-level benchmarks that overlook critical vulnerability context.\n  This paper introduces Vulnerability-Adaptive Policy Optimization (VULPO), an on-policy LLM reinforcement learning framework for context-aware VD. To support training and evaluation, we first construct ContextVul, a new dataset that augments high-quality function-level samples with lightweight method to extract repository-level context information. We then design multi-dimensional reward structuring that jointly captures prediction correctness, vulnerability localization accuracy, and the semantic relevance of vulnerability analysis, thereby guiding the model toward comprehensive contextual reasoning. To address the asymmetric difficulty of different vulnerability cases and mitigate reward hacking, VULPO incorporates label-level and sample-level difficulty-adaptive reward scaling, encouraging the model to explore challenging cases while maintaining balanced reward distribution. Extensive experiments demonstrate the superiority of our VULPO framework in context-aware VD: Our VULPO-4B substantially outperforms existing VD baselines based on prompt engineering and off-policy optimization, improving F1 by 85% over Qwen3-4B and achieving performance comparable to a 150x larger-scale model, DeepSeek-R1-0528.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86VULPO\u6846\u67b6\uff0c\u4e00\u4e2a\u57fa\u4e8e\u7b56\u7565\u7684LLM\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6f0f\u6d1e\u68c0\u6d4b\u3002\u901a\u8fc7\u6784\u5efaContextVul\u6570\u636e\u96c6\u548c\u591a\u7ef4\u5ea6\u5956\u52b1\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6f0f\u6d1e\u68c0\u6d4b\u6280\u672f\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u8fdb\u884c\u4e0a\u4e0b\u6587\u611f\u77e5\u5206\u6790\uff0c\u4f9d\u8d56\u56fa\u5b9a\u8f93\u5165\u6216\u9759\u6001\u504f\u597d\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u81ea\u9002\u5e94\u63a2\u7d22\u4ed3\u5e93\u7ea7\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u6784\u5efaContextVul\u6570\u636e\u96c6\u589e\u5f3a\u51fd\u6570\u7ea7\u6837\u672c\u7684\u4ed3\u5e93\u7ea7\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u8bbe\u8ba1\u591a\u7ef4\u5ea6\u5956\u52b1\u7ed3\u6784\uff0c\u5e76\u5f15\u5165\u6807\u7b7e\u7ea7\u548c\u6837\u672c\u7ea7\u96be\u5ea6\u81ea\u9002\u5e94\u5956\u52b1\u7f29\u653e\u673a\u5236\u3002", "result": "VULPO-4B\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u63d0\u793a\u5de5\u7a0b\u548c\u79bb\u7b56\u7565\u4f18\u5316\u7684\u6f0f\u6d1e\u68c0\u6d4b\u57fa\u7ebf\uff0cF1\u5206\u6570\u6bd4Qwen3-4B\u63d0\u9ad885%\uff0c\u6027\u80fd\u53ef\u4e0e150\u500d\u89c4\u6a21\u7684DeepSeek-R1-0528\u76f8\u5ab2\u7f8e\u3002", "conclusion": "VULPO\u6846\u67b6\u5728\u4e0a\u4e0b\u6587\u611f\u77e5\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u7b56\u7565\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.11600", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.11600", "abs": "https://arxiv.org/abs/2511.11600", "authors": ["Piyushkumar Patel"], "title": "CausalGuard: A Smart System for Detecting and Preventing False Information in Large Language Models", "comment": null, "summary": "While large language models have transformed how we interact with AI systems, they have a critical weakness: they confidently state false information that sounds entirely plausible. This \"hallucination\" problem has become a major barrier to using these models where accuracy matters most. Existing solutions either require retraining the entire model, add significant computational costs, or miss the root causes of why these hallucinations occur in the first place.\n  We present CausalGuard, a new approach that combines causal reasoning with symbolic logic to catch and prevent hallucinations as they happen. Unlike previous methods that only check outputs after generation, our system understands the causal chain that leads to false statements and intervenes early in the process. CausalGuard works through two complementary paths: one that traces causal relationships between what the model knows and what it generates, and another that checks logical consistency using automated reasoning.\n  Testing across twelve different benchmarks, we found that CausalGuard correctly identifies hallucinations 89.3\\% of the time while missing only 8.3\\% of actual hallucinations. More importantly, it reduces false claims by nearly 80\\% while keeping responses natural and helpful. The system performs especially well on complex reasoning tasks where multiple steps of logic are required. Because CausalGuard shows its reasoning process, it works well in sensitive areas like medical diagnosis or financial analysis where understanding why a decision was made matters as much as the decision itself.", "AI": {"tldr": "CausalGuard\u662f\u4e00\u79cd\u7ed3\u5408\u56e0\u679c\u63a8\u7406\u548c\u7b26\u53f7\u903b\u8f91\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b\u548c\u9632\u6b62\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u66f4\u65e9\u5e72\u9884\u751f\u6210\u8fc7\u7a0b\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u4fe1\u5730\u9648\u8ff0\u865a\u5047\u4fe1\u606f\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u8fd9\u662f\u5728\u4f7f\u7528\u51c6\u786e\u6027\u81f3\u5173\u91cd\u8981\u7684\u573a\u666f\u4e2d\u7684\u4e3b\u8981\u969c\u788d\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u6574\u4e2a\u6a21\u578b\uff0c\u8981\u4e48\u589e\u52a0\u663e\u8457\u8ba1\u7b97\u6210\u672c\uff0c\u6216\u8005\u672a\u80fd\u89e3\u51b3\u5e7b\u89c9\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u7ed3\u5408\u56e0\u679c\u63a8\u7406\u4e0e\u7b26\u53f7\u903b\u8f91\uff0c\u901a\u8fc7\u4e24\u6761\u4e92\u8865\u8def\u5f84\u5de5\u4f5c\uff1a\u4e00\u6761\u8ffd\u8e2a\u6a21\u578b\u5df2\u77e5\u4fe1\u606f\u4e0e\u751f\u6210\u5185\u5bb9\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u53e6\u4e00\u6761\u4f7f\u7528\u81ea\u52a8\u63a8\u7406\u68c0\u67e5\u903b\u8f91\u4e00\u81f4\u6027\u3002\u7cfb\u7edf\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u65e9\u671f\u5e72\u9884\uff0c\u800c\u975e\u4ec5\u68c0\u67e5\u8f93\u51fa\u3002", "result": "\u572812\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCausalGuard\u6b63\u786e\u8bc6\u522b\u5e7b\u89c9\u7684\u6982\u7387\u4e3a89.3%\uff0c\u6f0f\u68c0\u7387\u4ec5\u4e3a8.3%\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5b83\u51cf\u5c11\u4e86\u8fd180%\u7684\u9519\u8bef\u58f0\u660e\uff0c\u540c\u65f6\u4fdd\u6301\u56de\u7b54\u81ea\u7136\u6709\u5e2e\u52a9\u3002\u5728\u9700\u8981\u591a\u6b65\u903b\u8f91\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u5c24\u5176\u51fa\u8272\u3002", "conclusion": "CausalGuard\u901a\u8fc7\u663e\u793a\u63a8\u7406\u8fc7\u7a0b\uff0c\u5728\u533b\u7597\u8bca\u65ad\u6216\u91d1\u878d\u5206\u6790\u7b49\u654f\u611f\u9886\u57df\u8868\u73b0\u826f\u597d\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u9886\u57df\u7406\u89e3\u51b3\u7b56\u539f\u56e0\u4e0e\u51b3\u7b56\u672c\u8eab\u540c\u7b49\u91cd\u8981\u3002\u8be5\u65b9\u6cd5\u4e3a\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.12576", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12576", "abs": "https://arxiv.org/abs/2511.12576", "authors": ["Mohammad Meymani", "Hamed Jelodar", "Parisa Hamedi", "Roozbeh Razavi-Far", "Ali A. Ghorbani"], "title": "Can Small GenAI Language Models Rival Large Language Models in Understanding Application Behavior?", "comment": null, "summary": "Generative AI (GenAI) models, particularly large language models (LLMs), have transformed multiple domains, including natural language processing, software analysis, and code understanding. Their ability to analyze and generate code has enabled applications such as source code summarization, behavior analysis, and malware detection. In this study, we systematically evaluate the capabilities of both small and large GenAI language models in understanding application behavior, with a particular focus on malware detection as a representative task. While larger models generally achieve higher overall accuracy, our experiments show that small GenAI models maintain competitive precision and recall, offering substantial advantages in computational efficiency, faster inference, and deployment in resource-constrained environments. We provide a detailed comparison across metrics such as accuracy, precision, recall, and F1-score, highlighting each model's strengths, limitations, and operational feasibility. Our findings demonstrate that small GenAI models can effectively complement large ones, providing a practical balance between performance and resource efficiency in real-world application behavior analysis.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5c0f\u578b\u548c\u5927\u578b\u751f\u6210\u5f0fAI\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u5e94\u7528\u884c\u4e3a\uff08\u7279\u522b\u662f\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\uff09\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5927\u578b\u6a21\u578b\u6574\u4f53\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u4f46\u5c0f\u578b\u6a21\u578b\u5728\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u4e14\u5728\u8ba1\u7b97\u6548\u7387\u3001\u63a8\u7406\u901f\u5ea6\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u90e8\u7f72\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u6a21\u578b\u5728\u4ee3\u7801\u5206\u6790\u548c\u7406\u89e3\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u5728\u5e94\u7528\u884c\u4e3a\u7406\u89e3\uff08\u7279\u522b\u662f\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\uff09\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u8bc4\u4f30\u5c0f\u578b\u548c\u5927\u578b\u751f\u6210\u5f0fAI\u8bed\u8a00\u6a21\u578b\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u51c6\u786e\u7387\u3001\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u7b49\u6307\u6807\u3002", "result": "\u5927\u578b\u6a21\u578b\u6574\u4f53\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u4f46\u5c0f\u578b\u6a21\u578b\u5728\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u4e14\u5728\u8ba1\u7b97\u6548\u7387\u3001\u63a8\u7406\u901f\u5ea6\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u90e8\u7f72\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u5c0f\u578b\u751f\u6210\u5f0fAI\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u8865\u5145\u5927\u578b\u6a21\u578b\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u884c\u4e3a\u5206\u6790\u4e2d\u63d0\u4f9b\u6027\u80fd\u4e0e\u8d44\u6e90\u6548\u7387\u4e4b\u95f4\u7684\u5b9e\u7528\u5e73\u8861\u3002"}}
{"id": "2511.11979", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.11979", "abs": "https://arxiv.org/abs/2511.11979", "authors": ["Md Ahsanul Haque", "Md Mahmuduzzaman Kamol", "Ismail Hossain", "Suresh Kumar Amalapuram", "Vladik Kreinovich", "Mohammad Saidur Rahman"], "title": "CITADEL: A Semi-Supervised Active Learning Framework for Malware Detection Under Continuous Distribution Drift", "comment": null, "summary": "Android malware evolves rapidly, leading to concept drift that degrades the performance of traditional machine learning (ML)-based detection systems. While recent approaches incorporate active learning and hierarchical contrastive loss to handle this drift, they remain fully supervised, computationally expensive, and perform poorly on real-world datasets with long temporal spans. In particular, our evaluation highlights these limitations, particularly on LAMDA, a 12-year longitudinal dataset exhibiting substantial distributional shifts. Moreover, manual expert labeling cannot scale with the daily emergence of over 450,000 new malware samples, leaving most samples unlabeled and underutilized.\n  To address these challenges, we propose CITADEL, a robust semi-supervised active learning framework for Android malware detection. To bridge the gap between image-domain semi-supervised learning and binary feature representations of malware, we introduce malware-specific augmentations, Bernoulli bit flips and masking, that simulate realistic drift behaviors. CITADEL further integrates supervised contrastive loss to improve boundary sample discrimination and combines it with a multi-criteria active learning strategy based on prediction confidence, $L_p$-norm distance, and boundary uncertainty, enabling effective adaptation under limited labeling budgets. Extensive evaluation on four large-scale Android malware benchmarks -- APIGraph, Chen-AZ, MaMaDroid, and LAMDA demonstrates that CITADEL outperforms prior work, achieving F1 score of over 1%, 3%, 7%, and 14% respectively, using only 40% labeled samples. Furthermore, CITADEL shows significant efficiency over prior work incurring $24\\times$ faster training and $13\\times$ fewer operations.", "AI": {"tldr": "CITADEL\u662f\u4e00\u4e2a\u7528\u4e8eAndroid\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7684\u9c81\u68d2\u534a\u76d1\u7763\u4e3b\u52a8\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6076\u610f\u8f6f\u4ef6\u7279\u5b9a\u589e\u5f3a\u3001\u76d1\u7763\u5bf9\u6bd4\u635f\u5931\u548c\u591a\u6807\u51c6\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u6709\u9650\u6807\u6ce8\u9884\u7b97\u4e0b\u6709\u6548\u5e94\u5bf9\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\u3002", "motivation": "Android\u6076\u610f\u8f6f\u4ef6\u5feb\u901f\u6f14\u53d8\u5bfc\u81f4\u6982\u5ff5\u6f02\u79fb\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u68c0\u6d4b\u7cfb\u7edf\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u65e0\u6cd5\u6269\u5c55\u5230\u73b0\u5b9e\u4e16\u754c\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u7279\u522b\u662f\u9762\u5bf9\u6bcf\u5929\u6d8c\u73b0\u768445\u4e07\u65b0\u6837\u672c\u65f6\u4e13\u5bb6\u6807\u6ce8\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u6076\u610f\u8f6f\u4ef6\u7279\u5b9a\u589e\u5f3a\uff08\u4f2f\u52aa\u5229\u4f4d\u7ffb\u8f6c\u548c\u63a9\u7801\uff09\u6a21\u62df\u771f\u5b9e\u6f02\u79fb\u884c\u4e3a\uff0c\u96c6\u6210\u76d1\u7763\u5bf9\u6bd4\u635f\u5931\u6539\u5584\u8fb9\u754c\u6837\u672c\u533a\u5206\uff0c\u7ed3\u5408\u57fa\u4e8e\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u3001Lp\u8303\u6570\u8ddd\u79bb\u548c\u8fb9\u754c\u4e0d\u786e\u5b9a\u6027\u7684\u591a\u6807\u51c6\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728\u56db\u4e2a\u5927\u89c4\u6a21Android\u6076\u610f\u8f6f\u4ef6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4ec5\u4f7f\u752840%\u6807\u6ce8\u6837\u672c\u5c31\u4f18\u4e8e\u5148\u524d\u5de5\u4f5c\uff0cF1\u5206\u6570\u5206\u522b\u63d0\u5347\u8d85\u8fc71%\u30013%\u30017%\u548c14%\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u534724\u500d\uff0c\u64cd\u4f5c\u51cf\u5c1113\u500d\u3002", "conclusion": "CITADEL\u6846\u67b6\u5728\u6709\u9650\u6807\u6ce8\u9884\u7b97\u4e0b\u6709\u6548\u89e3\u51b3\u4e86Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u7684\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2511.11611", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.11611", "abs": "https://arxiv.org/abs/2511.11611", "authors": ["David H. Silver"], "title": "Quantifying Skill and Chance: A Unified Framework for the Geometry of Games", "comment": null, "summary": "We introduce a quantitative framework for separating skill and chance in games by modeling them as complementary sources of control over stochastic decision trees. We define the Skill-Luck Index S(G) in [-1, 1] by decomposing game outcomes into skill leverage K and luck leverage L. Applying this to 30 games reveals a continuum from pure chance (coin toss, S = -1) through mixed domains such as backgammon (S = 0, Sigma = 1.20) to pure skill (chess, S = +1, Sigma = 0). Poker exhibits moderate skill dominance (S = 0.33) with K = 0.40 +/- 0.03 and Sigma = 0.80. We further introduce volatility Sigma to quantify outcome uncertainty over successive turns. The framework extends to general stochastic decision systems, enabling principled comparisons of player influence, game balance, and predictive stability, with applications to game design, AI evaluation, and risk assessment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6e38\u620f\u5efa\u6a21\u4e3a\u968f\u673a\u51b3\u7b56\u6811\u6765\u5206\u79bb\u6280\u80fd\u548c\u8fd0\u6c14\u6210\u5206\uff0c\u5b9a\u4e49\u4e86\u6280\u80fd-\u8fd0\u6c14\u6307\u6570S(G)\u5728[-1,1]\u8303\u56f4\u5185\uff0c\u5e94\u7528\u4e8e30\u4e2a\u6e38\u620f\u63ed\u793a\u4e86\u4ece\u7eaf\u8fd0\u6c14\u5230\u7eaf\u6280\u80fd\u7684\u8fde\u7eed\u8c31\u7cfb\u3002", "motivation": "\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u6e38\u620f\u4e2d\u6280\u80fd\u548c\u8fd0\u6c14\u7684\u76f8\u5bf9\u8d21\u732e\uff0c\u4ee5\u4fbf\u8fdb\u884c\u6e38\u620f\u8bbe\u8ba1\u3001AI\u8bc4\u4f30\u548c\u98ce\u9669\u5206\u6790\u7684\u5ba2\u89c2\u6bd4\u8f83\u3002", "method": "\u5c06\u6e38\u620f\u5efa\u6a21\u4e3a\u968f\u673a\u51b3\u7b56\u6811\uff0c\u5206\u89e3\u6e38\u620f\u7ed3\u679c\u4e3a\u6280\u80fd\u6760\u6746K\u548c\u8fd0\u6c14\u6760\u6746L\uff0c\u5b9a\u4e49\u6280\u80fd-\u8fd0\u6c14\u6307\u6570S(G)\uff0c\u5e76\u5f15\u5165\u6ce2\u52a8\u6027Sigma\u6765\u91cf\u5316\u8fde\u7eed\u56de\u5408\u7684\u7ed3\u679c\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5206\u679030\u4e2a\u6e38\u620f\u663e\u793a\uff1a\u786c\u5e01\u6295\u63b7S=-1\uff08\u7eaf\u8fd0\u6c14\uff09\uff0c\u897f\u6d0b\u53cc\u9646\u68cbS=0\uff0c\u56fd\u9645\u8c61\u68cbS=+1\uff08\u7eaf\u6280\u80fd\uff09\uff0c\u6251\u514bS=0.33\uff08\u4e2d\u7b49\u6280\u80fd\u4e3b\u5bfc\uff09\u3002\u6ce2\u52a8\u6027Sigma\u4ece\u56fd\u9645\u8c61\u68cb\u76840\u5230\u897f\u6d0b\u53cc\u9646\u68cb\u76841.20\u4e0d\u7b49\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u6269\u5c55\u5230\u4e00\u822c\u968f\u673a\u51b3\u7b56\u7cfb\u7edf\uff0c\u4e3a\u73a9\u5bb6\u5f71\u54cd\u529b\u3001\u6e38\u620f\u5e73\u8861\u6027\u548c\u9884\u6d4b\u7a33\u5b9a\u6027\u7684\u539f\u5219\u6027\u6bd4\u8f83\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5728\u6e38\u620f\u8bbe\u8ba1\u3001AI\u8bc4\u4f30\u548c\u98ce\u9669\u8bc4\u4f30\u4e2d\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.12635", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12635", "abs": "https://arxiv.org/abs/2511.12635", "authors": ["Lech Madeyski", "Barbara Kitchenham", "Martin Shepperd"], "title": "LLM4SCREENLIT: Recommendations on Assessing the Performance of Large Language Models for Screening Literature in Systematic Reviews", "comment": "19 pages, 4 figures", "summary": "Context: Large language models (LLMs) are released faster than users' ability to evaluate them rigorously. When LLMs underpin research, such as identifying relevant literature for systematic reviews (SRs), robust empirical assessment is essential. Objective: We identify and discuss key challenges in assessing LLM performance for selecting relevant literature, identify good (evaluation) practices, and propose recommendations. Method: Using a recent large-scale study as an example, we identify problems with the use of traditional metrics for assessing the performance of Gen-AI tools for identifying relevant literature in SRs. We analyzed 27 additional papers investigating this issue, extracted the performance metrics, and found both good practices and widespread problems, especially with the use and reporting of performance metrics for SR screening. Results: Major weaknesses included: i) a failure to use metrics that are robust to imbalanced data and do not directly indicate whether results are better than chance, e.g., the use of Accuracy, ii) a failure to consider the impact of lost evidence when making claims concerning workload savings, and iii) pervasive failure to report the full confusion matrix (or performance metrics from which it can be reconstructed) which is essential for future meta-analyses. On the positive side, we extract good (evaluation) practices on which our recommendations for researchers and practitioners, as well as policymakers, are built. Conclusions: SR screening evaluations should prioritize lost evidence/recall alongside chance-anchored and cost-sensitive Weighted MCC (WMCC) metric, report complete confusion matrices, treat unclassifiable outputs as referred-back positives for assessment, adopt leakage-aware designs with non-LLM baselines and open artifacts, and ground conclusions in cost-benefit analysis where FNs carry higher penalties than FPs.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7cfb\u7edf\u7efc\u8ff0\u6587\u732e\u7b5b\u9009\u4e2d\u7684\u6027\u80fd\u6311\u6218\uff0c\u6307\u51fa\u4e86\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\uff0c\u5305\u62ec\u4f7f\u7528\u5bf9\u4e0d\u5e73\u8861\u6570\u636e\u7a33\u5065\u7684\u6307\u6807\u3001\u8003\u8651\u4e22\u5931\u8bc1\u636e\u7684\u5f71\u54cd\u3001\u62a5\u544a\u5b8c\u6574\u6df7\u6dc6\u77e9\u9635\u7b49\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5e03\u901f\u5ea6\u52a0\u5feb\uff0c\u9700\u8981\u5bf9\u5176\u5728\u7cfb\u7edf\u7efc\u8ff0\u6587\u732e\u7b5b\u9009\u7b49\u7814\u7a76\u5e94\u7528\u4e2d\u8fdb\u884c\u7a33\u5065\u8bc4\u4f30\u3002\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u8bf8\u591a\u95ee\u9898\uff0c\u9700\u8981\u5efa\u7acb\u66f4\u597d\u7684\u8bc4\u4f30\u5b9e\u8df5\u3002", "method": "\u4ee5\u4e00\u9879\u5927\u89c4\u6a21\u7814\u7a76\u4e3a\u4f8b\uff0c\u5206\u6790\u4e86\u4f20\u7edf\u6307\u6807\u5728\u8bc4\u4f30\u751f\u6210\u5f0fAI\u5de5\u5177\u8fdb\u884c\u6587\u732e\u7b5b\u9009\u65f6\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5206\u6790\u4e8627\u7bc7\u76f8\u5173\u8bba\u6587\u7684\u6027\u80fd\u6307\u6807\u4f7f\u7528\u60c5\u51b5\u3002", "result": "\u53d1\u73b0\u4e3b\u8981\u5f31\u70b9\u5305\u62ec\uff1a\u4f7f\u7528\u5bf9\u4e0d\u5e73\u8861\u6570\u636e\u4e0d\u7a33\u5065\u7684\u6307\u6807\u3001\u672a\u8003\u8651\u4e22\u5931\u8bc1\u636e\u7684\u5f71\u54cd\u3001\u672a\u62a5\u544a\u5b8c\u6574\u6df7\u6dc6\u77e9\u9635\u3002\u540c\u65f6\u4e5f\u63d0\u53d6\u4e86\u826f\u597d\u7684\u8bc4\u4f30\u5b9e\u8df5\u3002", "conclusion": "\u5efa\u8bae\u7cfb\u7edf\u7efc\u8ff0\u7b5b\u9009\u8bc4\u4f30\u5e94\u4f18\u5148\u8003\u8651\u4e22\u5931\u8bc1\u636e/\u53ec\u56de\u7387\uff0c\u4f7f\u7528\u673a\u4f1a\u951a\u5b9a\u548c\u6210\u672c\u654f\u611f\u7684\u52a0\u6743MCC\u6307\u6807\uff0c\u62a5\u544a\u5b8c\u6574\u6df7\u6dc6\u77e9\u9635\uff0c\u91c7\u7528\u9632\u6cc4\u6f0f\u8bbe\u8ba1\uff0c\u5e76\u5c06\u7ed3\u8bba\u5efa\u7acb\u5728\u6210\u672c\u6548\u76ca\u5206\u6790\u57fa\u7840\u4e0a\u3002"}}
{"id": "2511.12043", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.12043", "abs": "https://arxiv.org/abs/2511.12043", "authors": ["Hao Li", "Jiajun He", "Guangshuo Wang", "Dengguo Feng", "Zheng Li", "Min Zhang"], "title": "BudgetLeak: Membership Inference Attacks on RAG Systems via the Generation Budget Side Channel", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances large language models by integrating external knowledge, but reliance on proprietary or sensitive corpora poses various data risks, including privacy leakage and unauthorized data usage. Membership inference attacks (MIAs) are a common technique to assess such risks, yet existing approaches underperform in RAG due to black-box constraints and the absence of strong membership signals. In this paper, we identify a previously unexplored side channel in RAG systems: the generation budget, which controls the maximum number of tokens allowed in a generated response. Varying this budget reveals observable behavioral patterns between member and non-member queries, as members gain quality more rapidly with larger budgets. Building on this insight, we propose BudgetLeak, a novel membership inference attack that probes responses under different budgets and analyzes metric evolution via sequence modeling or clustering. Extensive experiments across four datasets, three LLM generators, and two retrievers demonstrate that BudgetLeak consistently outperforms existing baselines, while maintaining high efficiency and practical viability. Our findings reveal a previously overlooked data risk in RAG systems and highlight the need for new defenses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BudgetLeak\uff0c\u4e00\u79cd\u9488\u5bf9RAG\u7cfb\u7edf\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u751f\u6210\u9884\u7b97\u53d8\u5316\u4e0b\u7684\u54cd\u5e94\u884c\u4e3a\u6a21\u5f0f\u6765\u63a8\u65ad\u6570\u636e\u6210\u5458\u5173\u7cfb\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "RAG\u7cfb\u7edf\u4f9d\u8d56\u5916\u90e8\u77e5\u8bc6\u5e93\u4f46\u9762\u4e34\u6570\u636e\u98ce\u9669\uff0c\u73b0\u6709\u6210\u5458\u63a8\u7406\u653b\u51fb\u5728RAG\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u9ed1\u76d2\u7ea6\u675f\u548c\u7f3a\u4e4f\u5f3a\u6210\u5458\u4fe1\u53f7\u3002", "method": "\u5229\u7528RAG\u7cfb\u7edf\u4e2d\u751f\u6210\u9884\u7b97\u8fd9\u4e00\u4fa7\u4fe1\u9053\uff0c\u901a\u8fc7\u5728\u4e0d\u540c\u9884\u7b97\u4e0b\u63a2\u6d4b\u54cd\u5e94\u5e76\u5206\u6790\u6307\u6807\u6f14\u5316\u6a21\u5f0f\uff0c\u4f7f\u7528\u5e8f\u5217\u5efa\u6a21\u6216\u805a\u7c7b\u8fdb\u884c\u6210\u5458\u63a8\u65ad\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u3001\u4e09\u4e2aLLM\u751f\u6210\u5668\u548c\u4e24\u4e2a\u68c0\u7d22\u5668\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cBudgetLeak\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u7387\u548c\u5b9e\u9645\u53ef\u884c\u6027\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86RAG\u7cfb\u7edf\u4e2d\u5148\u524d\u88ab\u5ffd\u89c6\u7684\u6570\u636e\u98ce\u9669\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u65b0\u9632\u5fa1\u63aa\u65bd\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2511.11693", "categories": ["cs.AI", "cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11693", "abs": "https://arxiv.org/abs/2511.11693", "authors": ["Xin Zhao", "Xiaojun Chen", "Bingshan Liu", "Zeyao Liu", "Zhendong Zhao", "Xiaoyan Gu"], "title": "Value-Aligned Prompt Moderation via Zero-Shot Agentic Rewriting for Safe Image Generation", "comment": null, "summary": "Generative vision-language models like Stable Diffusion demonstrate remarkable capabilities in creative media synthesis, but they also pose substantial risks of producing unsafe, offensive, or culturally inappropriate content when prompted adversarially. Current defenses struggle to align outputs with human values without sacrificing generation quality or incurring high costs. To address these challenges, we introduce VALOR (Value-Aligned LLM-Overseen Rewriter), a modular, zero-shot agentic framework for safer and more helpful text-to-image generation. VALOR integrates layered prompt analysis with human-aligned value reasoning: a multi-level NSFW detector filters lexical and semantic risks; a cultural value alignment module identifies violations of social norms, legality, and representational ethics; and an intention disambiguator detects subtle or indirect unsafe implications. When unsafe content is detected, prompts are selectively rewritten by a large language model under dynamic, role-specific instructions designed to preserve user intent while enforcing alignment. If the generated image still fails a safety check, VALOR optionally performs a stylistic regeneration to steer the output toward a safer visual domain without altering core semantics. Experiments across adversarial, ambiguous, and value-sensitive prompts show that VALOR significantly reduces unsafe outputs by up to 100.00% while preserving prompt usefulness and creativity. These results highlight VALOR as a scalable and effective approach for deploying safe, aligned, and helpful image generation systems in open-world settings.", "AI": {"tldr": "VALOR\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u96f6\u6837\u672c\u7684\u667a\u80fd\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u63d0\u793a\u5206\u6790\u3001\u6587\u5316\u4ef7\u503c\u5bf9\u9f50\u548c\u610f\u56fe\u6d88\u6b67\u6765\u786e\u4fdd\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u548c\u7528\u6237\u610f\u56fe\u3002", "motivation": "\u751f\u6210\u5f0f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4ea7\u751f\u4e0d\u5b89\u5168\u3001\u5192\u72af\u6027\u6216\u6587\u5316\u4e0d\u9002\u5f53\u5185\u5bb9\u7684\u98ce\u9669\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u96be\u4ee5\u5728\u4e0d\u727a\u7272\u751f\u6210\u8d28\u91cf\u6216\u589e\u52a0\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u786e\u4fdd\u8f93\u51fa\u7b26\u5408\u4eba\u7c7b\u4ef7\u503c\u89c2\u3002", "method": "VALOR\u6846\u67b6\u5305\u542b\u591a\u7ea7NSFW\u68c0\u6d4b\u5668\u3001\u6587\u5316\u4ef7\u503c\u5bf9\u9f50\u6a21\u5757\u548c\u610f\u56fe\u6d88\u6b67\u5668\uff0c\u68c0\u6d4b\u5230\u4e0d\u5b89\u5168\u5185\u5bb9\u65f6\u7531\u5927\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u89d2\u8272\u7279\u5b9a\u6307\u4ee4\u4e0b\u91cd\u5199\u63d0\u793a\uff0c\u5fc5\u8981\u65f6\u8fdb\u884c\u98ce\u683c\u5316\u518d\u751f\u3002", "result": "\u5728\u5bf9\u6297\u6027\u3001\u6a21\u7cca\u6027\u548c\u4ef7\u503c\u654f\u611f\u63d0\u793a\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cVALOR\u5c06\u4e0d\u5b89\u5168\u8f93\u51fa\u51cf\u5c11\u9ad8\u8fbe100.00%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63d0\u793a\u7684\u6709\u7528\u6027\u548c\u521b\u9020\u6027\u3002", "conclusion": "VALOR\u4e3a\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u90e8\u7f72\u5b89\u5168\u3001\u5bf9\u9f50\u4e14\u6709\u7528\u7684\u56fe\u50cf\u751f\u6210\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.12823", "categories": ["cs.SE", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.12823", "abs": "https://arxiv.org/abs/2511.12823", "authors": ["Sajed Jalil", "Shuvo Saha", "Hossain Mohammad Seym"], "title": "Enhancing LLM Code Generation Capabilities through Test-Driven Development and Code Interpreter", "comment": "AACL-IJCNLP 2025 Workshop BLP Shared Task 2, 6 pages, 7 figures, 3 tables", "summary": "Over the past few years, improving LLM code generation capabilities has been a key focus in NLP research. Despite Bengali having 242 million native speakers worldwide, it receives little attention when it comes to training LLMs. More recently, various fine-tuning and augmented generation techniques have been employed to significantly enhance code generation performance. However, they require considerable expertise and resources to utilize effectively as an end user. The goal of our work is to democratize access to powerful code generation tools in resource-constrained emerging markets, enabling users to leverage them in their native language.\n  We introduce a novel approach that combines Test-Driven Development (TDD) and Code Interpreter (CI), utilizing open-weight models, which improves the baseline accuracy for code generation with Bengali prompts and achieves an overall accuracy of 85%. Our approach requires no finetuning and proves that even the smallest models in the same family can attain up to 98% accuracy compared to the largest models. All of our results are publicly shared in GitHub for validation and reproducibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1(TDD)\u548c\u4ee3\u7801\u89e3\u91ca\u5668(CI)\u7684\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528\u5f00\u6e90\u6a21\u578b\u63d0\u5347\u5b5f\u52a0\u62c9\u8bed\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u7387\u81f385%\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u8ba9\u5c0f\u578b\u6a21\u578b\u8fbe\u5230\u5927\u578b\u6a21\u578b98%\u7684\u6027\u80fd\u3002", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u62e5\u67092.42\u4ebf\u6bcd\u8bed\u4f7f\u7528\u8005\uff0c\u4f46\u5728LLM\u4ee3\u7801\u751f\u6210\u7814\u7a76\u4e2d\u5173\u6ce8\u4e0d\u8db3\u3002\u73b0\u6709\u6280\u672f\u9700\u8981\u5927\u91cf\u4e13\u4e1a\u77e5\u8bc6\u548c\u8d44\u6e90\uff0c\u672c\u6587\u65e8\u5728\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u65b0\u5174\u5e02\u573a\u7528\u6237\u63d0\u4f9b\u672c\u5730\u8bed\u8a00\u7684\u4ee3\u7801\u751f\u6210\u5de5\u5177\u3002", "method": "\u91c7\u7528\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1(TDD)\u548c\u4ee3\u7801\u89e3\u91ca\u5668(CI)\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u5f00\u6e90\u6743\u91cd\u6a21\u578b\uff0c\u65e0\u9700\u6a21\u578b\u5fae\u8c03\u3002", "result": "\u5c06\u5b5f\u52a0\u62c9\u8bed\u63d0\u793a\u7684\u4ee3\u7801\u751f\u6210\u57fa\u7ebf\u51c6\u786e\u7387\u63d0\u5347\u81f385%\uff0c\u5c0f\u578b\u6a21\u578b\u53ef\u8fbe\u5230\u5927\u578b\u6a21\u578b98%\u7684\u6027\u80fd\u3002\u6240\u6709\u7ed3\u679c\u5df2\u5728GitHub\u516c\u5f00\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u8bc1\u660e\u4e86\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u663e\u8457\u63d0\u5347\u5b5f\u52a0\u62c9\u8bed\u4ee3\u7801\u751f\u6210\u6027\u80fd\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12856", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12856", "abs": "https://arxiv.org/abs/2511.12856", "authors": ["Anuradha Madugalla", "Jixuan Dong", "Kai Lyne Loi", "Matthew Crossman", "John Grundy"], "title": "Human-Centred Requirements Engineering for Critical Systems: Insights from Disaster Early Warning Applications", "comment": null, "summary": "Critical systems, such as those used in healthcare, defence, and disaster management, demand rigorous requirements engineering to ensure safety and reliability. Yet, much of this rigour has traditionally focused on technical assurance, often overlooking the human and social contexts in which these systems operate. This paper argues that considering human-centric aspects is an essential dimension of dependability, and presents a human-centred RE process designed to integrate social responsibility into critical system development. Drawing from a literature review, we identified a set of guidelines for designing software for vulnerable communities and translated these into sixty-two functional and non-functional requirements. These requirements were operationalised through the design of an adaptive early warning system prototype, which was subsequently evaluated through six interviews and eight cognitive walkthroughs to validate their relevance and applicability. The findings demonstrate that human-centric requirements, when addressed early, enhance the usability and accessibility of systems for all users. The paper concludes by positioning human-centricity not as an ethical add-on but as a defining quality of safe and equitable critical systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u9700\u6c42\u5de5\u7a0b\u6d41\u7a0b\uff0c\u5c06\u793e\u4f1a\u8d23\u4efb\u878d\u5165\u5173\u952e\u7cfb\u7edf\u5f00\u53d1\uff0c\u901a\u8fc7\u8bbe\u8ba1\u81ea\u9002\u5e94\u9884\u8b66\u7cfb\u7edf\u539f\u578b\u5e76\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u76f8\u5173\u9700\u6c42\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5173\u952e\u7cfb\u7edf\uff08\u5982\u533b\u7597\u3001\u56fd\u9632\u548c\u707e\u5bb3\u7ba1\u7406\uff09\u4f20\u7edf\u4e0a\u6ce8\u91cd\u6280\u672f\u4fdd\u8bc1\uff0c\u4f46\u5f80\u5f80\u5ffd\u89c6\u4e86\u7cfb\u7edf\u8fd0\u884c\u7684\u4eba\u7c7b\u548c\u793e\u4f1a\u80cc\u666f\uff0c\u9700\u8981\u5c06\u4eba\u4e3a\u4e2d\u5fc3\u65b9\u9762\u4f5c\u4e3a\u53ef\u9760\u6027\u7684\u91cd\u8981\u7ef4\u5ea6\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u8bc6\u522b\u4e3a\u5f31\u52bf\u7fa4\u4f53\u8bbe\u8ba1\u8f6f\u4ef6\u7684\u6307\u5bfc\u539f\u5219\uff0c\u8f6c\u5316\u4e3a62\u4e2a\u529f\u80fd\u548c\u975e\u529f\u80fd\u9700\u6c42\uff0c\u8bbe\u8ba1\u81ea\u9002\u5e94\u9884\u8b66\u7cfb\u7edf\u539f\u578b\uff0c\u5e76\u901a\u8fc76\u6b21\u8bbf\u8c08\u548c8\u6b21\u8ba4\u77e5\u8d70\u67e5\u8fdb\u884c\u8bc4\u4f30\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u65e9\u671f\u5904\u7406\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u9700\u6c42\u80fd\u591f\u589e\u5f3a\u7cfb\u7edf\u5bf9\u6240\u6709\u7528\u6237\u7684\u53ef\u7528\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u3002", "conclusion": "\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u4e0d\u5e94\u88ab\u89c6\u4e3a\u9053\u5fb7\u9644\u52a0\u9879\uff0c\u800c\u662f\u5b89\u5168\u548c\u516c\u5e73\u5173\u952e\u7cfb\u7edf\u7684\u51b3\u5b9a\u6027\u8d28\u91cf\u7279\u5f81\u3002"}}
{"id": "2511.12052", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12052", "abs": "https://arxiv.org/abs/2511.12052", "authors": ["Aditya Kumar Sahu", "Chandan Kumar", "Saksham Kumar", "Serdar Solak"], "title": "Exploring AI in Steganography and Steganalysis: Trends, Clusters, and Sustainable Development Potential", "comment": null, "summary": "Steganography and steganalysis are strongly related subjects of information security. Over the past decade, many powerful and efficient artificial intelligence (AI) - driven techniques have been designed and presented during research into steganography as well as steganalysis. This study presents a scientometric analysis of AI-driven steganography-based data hiding techniques using a thematic modelling approach. A total of 654 articles within the time span of 2017 to 2023 have been considered. Experimental evaluation of the study reveals that 69% of published articles are from Asian countries. The China is on top (TP:312), followed by India (TP-114). The study mainly identifies seven thematic clusters: steganographic image data hiding, deep image steganalysis, neural watermark robustness, linguistic steganography models, speech steganalysis algorithms, covert communication networks, and video steganography techniques. The proposed study also assesses the scope of AI-steganography under the purview of sustainable development goals (SDGs) to present the interdisciplinary reciprocity between them. It has been observed that only 18 of the 654 articles are aligned with one of the SDGs, which shows that limited studies conducted in alignment with SDG goals. SDG9 which is Industry, Innovation, and Infrastructure is leading among 18 SDGs mapped articles. To the top of our insight, this study is the unique one to present a scientometric study on AI-driven steganography-based data hiding techniques. In the context of descriptive statistics, the study breaks down the underlying causes of observed trends, including the influence of DL developments, trends in East Asia and maturity of foundational methods. The work also stresses upon the critical gaps in societal alignment, particularly the SDGs, ultimately working on unveiling the field's global impact on AI security challenges.", "AI": {"tldr": "\u672c\u6587\u5bf92017-2023\u5e74\u95f4654\u7bc7AI\u9a71\u52a8\u7684\u9690\u5199\u672f\u6570\u636e\u9690\u85cf\u6280\u672f\u6587\u732e\u8fdb\u884c\u79d1\u5b66\u8ba1\u91cf\u5206\u6790\uff0c\u53d1\u73b069%\u8bba\u6587\u6765\u81ea\u4e9a\u6d32\u56fd\u5bb6\uff0c\u8bc6\u522b\u51fa7\u4e2a\u4e3b\u9898\u96c6\u7fa4\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e0e\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\uff08SDGs\uff09\u7684\u5173\u8054\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u79d1\u5b66\u8ba1\u91cf\u65b9\u6cd5\u5206\u6790AI\u9a71\u52a8\u9690\u5199\u672f\u9886\u57df\u7684\u53d1\u5c55\u8d8b\u52bf\u3001\u5730\u7406\u5206\u5e03\u548c\u4e3b\u9898\u6f14\u5316\uff0c\u5e76\u8bc4\u4f30\u8be5\u9886\u57df\u4e0e\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u7684\u5173\u8054\u7a0b\u5ea6\u3002", "method": "\u91c7\u7528\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u5bf9654\u7bc7\u6587\u732e\u8fdb\u884c\u79d1\u5b66\u8ba1\u91cf\u5206\u6790\uff0c\u8bc6\u522b\u4e3b\u9898\u96c6\u7fa4\uff0c\u5e76\u8bc4\u4f30\u4e0eSDGs\u7684\u5bf9\u5e94\u5173\u7cfb\u3002", "result": "\u4e9a\u6d32\u56fd\u5bb6\u4e3b\u5bfc\u8be5\u9886\u57df\u7814\u7a76\uff0869%\uff09\uff0c\u4e2d\u56fd\u53d1\u8868\u6700\u591a\uff08312\u7bc7\uff09\uff0c\u8bc6\u522b\u51fa7\u4e2a\u4e3b\u8981\u4e3b\u9898\u96c6\u7fa4\uff0c\u4ec5\u670918\u7bc7\u6587\u732e\u4e0eSDGs\u76f8\u5173\uff0cSDG9\uff08\u5de5\u4e1a\u3001\u521b\u65b0\u548c\u57fa\u7840\u8bbe\u65bd\uff09\u6700\u4e3a\u7a81\u51fa\u3002", "conclusion": "AI\u9a71\u52a8\u9690\u5199\u672f\u7814\u7a76\u5448\u73b0\u533a\u57df\u96c6\u4e2d\u7279\u5f81\uff0c\u4e0e\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u7684\u5173\u8054\u6027\u8f83\u5f31\uff0c\u9700\u8981\u52a0\u5f3a\u8be5\u9886\u57df\u7684\u793e\u4f1a\u5f71\u54cd\u8bc4\u4f30\u548c\u5168\u7403\u6311\u6218\u5e94\u5bf9\u80fd\u529b\u3002"}}
{"id": "2511.11770", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11770", "abs": "https://arxiv.org/abs/2511.11770", "authors": ["Floris Vossebeld", "Shenghui Wang"], "title": "Learning to Refine: An Agentic RL Approach for Iterative SPARQL Query Construction", "comment": null, "summary": "Generating complex, logically-sound SPARQL queries for multi-hop questions remains a critical bottleneck for Knowledge Graph Question Answering, as the brittle nature of one-shot generation by Large Language Models (LLMs) hinders reliable interaction with structured data. Current methods lack the adaptive policies needed to dynamically debug queries based on real-time execution feedback. This paper introduces a novel agentic framework where an LLM learns a resilient policy for the sequential process of iterative SPARQL construction. We show that a compact 3B-parameter model, trained exclusively via outcome-driven Reinforcement Learning (GRPO) without supervised fine-tuning, can learn effective policies for this task, discovering how to systematically recover from execution errors and refine its queries toward a correct answer. On a curated, executable single-answer subset of LC-QuAD 2.0, our agent achieves 49.7\\% accuracy post-entity-linking, a significant 17.5 percentage point improvement over the strongest iterative zero-shot baseline. Further analysis reveals that while the agent's capability is driven by RL, its performance is enhanced by an explicit deliberative reasoning step that acts as a cognitive scaffold to improve policy precision. This work presents a generalizable blueprint for teaching agents to master formal, symbolic tools through interaction, bridging the gap between probabilistic LLMs and the structured world of Knowledge Graphs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u8fed\u4ee3\u6784\u5efaSPARQL\u67e5\u8be2\uff0c\u89e3\u51b3\u591a\u8df3\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u4e2d\u7684\u67e5\u8be2\u751f\u6210\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u590d\u6742SPARQL\u67e5\u8be2\u65f6\u5b58\u5728\u8106\u5f31\u6027\uff0c\u7f3a\u4e4f\u57fa\u4e8e\u5b9e\u65f6\u6267\u884c\u53cd\u9988\u7684\u52a8\u6001\u8c03\u8bd5\u7b56\u7565\uff0c\u9650\u5236\u4e86\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u7684\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u4ec53B\u53c2\u6570\u7684\u7d27\u51d1\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u679c\u9a71\u52a8\u7684\u5f3a\u5316\u5b66\u4e60\uff08GRPO\uff09\u8bad\u7ec3\uff0c\u65e0\u9700\u76d1\u7763\u5fae\u8c03\uff0c\u5b66\u4e60\u8fed\u4ee3SPARQL\u6784\u5efa\u7684\u5f39\u6027\u7b56\u7565\u3002", "result": "\u5728LC-QuAD 2.0\u7684\u53ef\u6267\u884c\u5b50\u96c6\u4e0a\uff0c\u5b9e\u4f53\u94fe\u63a5\u540e\u51c6\u786e\u7387\u8fbe\u523049.7%\uff0c\u6bd4\u6700\u5f3a\u7684\u96f6\u6837\u672c\u57fa\u7ebf\u63d0\u9ad8\u4e8617.5\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u901a\u8fc7\u4ea4\u4e92\u6559\u5bfc\u667a\u80fd\u4f53\u638c\u63e1\u5f62\u5f0f\u5316\u7b26\u53f7\u5de5\u5177\u63d0\u4f9b\u4e86\u901a\u7528\u84dd\u56fe\uff0c\u5f25\u5408\u4e86\u6982\u7387\u6027LLM\u4e0e\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.12085", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12085", "abs": "https://arxiv.org/abs/2511.12085", "authors": ["Sajad U P"], "title": "Explainable Transformer-Based Email Phishing Classification with Adversarial Robustness", "comment": null, "summary": "Phishing and related cyber threats are becoming more varied and technologically advanced. Among these, email-based phishing remains the most dominant and persistent threat. These attacks exploit human vulnerabilities to disseminate malware or gain unauthorized access to sensitive information. Deep learning (DL) models, particularly transformer-based models, have significantly enhanced phishing mitigation through their contextual understanding of language. However, some recent threats, specifically Artificial Intelligence (AI)-generated phishing attacks, are reducing the overall system resilience of phishing detectors. In response, adversarial training has shown promise against AI-generated phishing threats. This study presents a hybrid approach that uses DistilBERT, a smaller, faster, and lighter version of the BERT transformer model for email classification. Robustness against text-based adversarial perturbations is reinforced using Fast Gradient Method (FGM) adversarial training. Furthermore, the framework integrates the LIME Explainable AI (XAI) technique to enhance the transparency of the DistilBERT architecture. The framework also uses the Flan-T5-small language model from Hugging Face to generate plain-language security narrative explanations for end-users. This combined approach ensures precise phishing classification while providing easily understandable justifications for the model's decisions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u4f7f\u7528DistilBERT\u8fdb\u884c\u9493\u9c7c\u90ae\u4ef6\u5206\u7c7b\uff0c\u7ed3\u5408FGM\u5bf9\u6297\u8bad\u7ec3\u589e\u5f3a\u9c81\u68d2\u6027\uff0c\u5e76\u96c6\u6210LIME XAI\u6280\u672f\u63d0\u9ad8\u900f\u660e\u5ea6\uff0c\u540c\u65f6\u4f7f\u7528Flan-T5-small\u751f\u6210\u6613\u4e8e\u7406\u89e3\u7684\u89e3\u91ca\u3002", "motivation": "\u9493\u9c7c\u653b\u51fb\u65e5\u76ca\u591a\u6837\u5316\u4e14\u6280\u672f\u5148\u8fdb\uff0c\u7279\u522b\u662fAI\u751f\u6210\u7684\u9493\u9c7c\u653b\u51fb\u964d\u4f4e\u4e86\u68c0\u6d4b\u7cfb\u7edf\u7684\u6574\u4f53\u97e7\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528DistilBERT\u8fdb\u884c\u90ae\u4ef6\u5206\u7c7b\uff0c\u91c7\u7528FGM\u5bf9\u6297\u8bad\u7ec3\u589e\u5f3a\u6a21\u578b\u5bf9\u6587\u672c\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u96c6\u6210LIME XAI\u6280\u672f\u63d0\u9ad8\u6a21\u578b\u900f\u660e\u5ea6\uff0c\u5e76\u4f7f\u7528Flan-T5-small\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u9493\u9c7c\u90ae\u4ef6\u5206\u7c7b\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u6a21\u578b\u51b3\u7b56\u7684\u6613\u4e8e\u7406\u89e3\u7684\u89e3\u91ca\u3002", "conclusion": "\u8be5\u6df7\u5408\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u5206\u7c7b\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u589e\u5f3a\u4e86\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7XAI\u6280\u672f\u63d0\u9ad8\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u9493\u9c7c\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.11773", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11773", "abs": "https://arxiv.org/abs/2511.11773", "authors": ["Ruchira Dhar", "Ninell Oldenburg", "Anders Soegaard"], "title": "On the Measure of a Model: From Intelligence to Generality", "comment": "Accepted at EurIPS Workshop on \"The Science of Benchmarking and Evaluating AI\"", "summary": "Benchmarks such as ARC, Raven-inspired tests, and the Blackbird Task are widely used to evaluate the intelligence of large language models (LLMs). Yet, the concept of intelligence remains elusive- lacking a stable definition and failing to predict performance on practical tasks such as question answering, summarization, or coding. Optimizing for such benchmarks risks misaligning evaluation with real-world utility. Our perspective is that evaluation should be grounded in generality rather than abstract notions of intelligence. We identify three assumptions that often underpin intelligence-focused evaluation: generality, stability, and realism. Through conceptual and formal analysis, we show that only generality withstands conceptual and empirical scrutiny. Intelligence is not what enables generality; generality is best understood as a multitask learning problem that directly links evaluation to measurable performance breadth and reliability. This perspective reframes how progress in AI should be assessed and proposes generality as a more stable foundation for evaluating capability across diverse and evolving tasks.", "AI": {"tldr": "\u8bba\u6587\u8d28\u7591\u5f53\u524d\u57fa\u4e8e\u62bd\u8c61\u667a\u529b\u6982\u5ff5\u7684AI\u8bc4\u4f30\u57fa\u51c6\uff0c\u63d0\u51fa\u5e94\u4ee5\u901a\u7528\u6027\u800c\u975e\u667a\u529b\u4f5c\u4e3a\u8bc4\u4f30\u57fa\u7840\uff0c\u8ba4\u4e3a\u901a\u7528\u6027\u66f4\u80fd\u76f4\u63a5\u5173\u8054\u5b9e\u9645\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u5f53\u524dAI\u8bc4\u4f30\u57fa\u51c6\uff08\u5982ARC\u3001Raven\u6d4b\u8bd5\u7b49\uff09\u57fa\u4e8e\u6a21\u7cca\u7684\u667a\u529b\u6982\u5ff5\uff0c\u65e0\u6cd5\u6709\u6548\u9884\u6d4b\u5b9e\u9645\u4efb\u52a1\u8868\u73b0\uff0c\u5b58\u5728\u4e0e\u73b0\u5b9e\u6548\u7528\u8131\u8282\u7684\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u6982\u5ff5\u548c\u5f62\u5f0f\u5206\u6790\uff0c\u68c0\u9a8c\u667a\u529b\u8bc4\u4f30\u7684\u4e09\u4e2a\u5047\u8bbe\uff08\u901a\u7528\u6027\u3001\u7a33\u5b9a\u6027\u3001\u73b0\u5b9e\u6027\uff09\uff0c\u8bba\u8bc1\u53ea\u6709\u901a\u7528\u6027\u7ecf\u5f97\u8d77\u6982\u5ff5\u548c\u5b9e\u8bc1\u68c0\u9a8c\u3002", "result": "\u7814\u7a76\u8868\u660e\u667a\u529b\u4e0d\u662f\u5b9e\u73b0\u901a\u7528\u6027\u7684\u539f\u56e0\uff0c\u901a\u7528\u6027\u5e94\u88ab\u7406\u89e3\u4e3a\u591a\u4efb\u52a1\u5b66\u4e60\u95ee\u9898\uff0c\u76f4\u63a5\u5173\u8054\u8bc4\u4f30\u4e0e\u53ef\u6d4b\u91cf\u7684\u6027\u80fd\u5e7f\u5ea6\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u5e94\u91cd\u65b0\u5b9a\u4e49AI\u8fdb\u5c55\u8bc4\u4f30\u65b9\u5f0f\uff0c\u5c06\u901a\u7528\u6027\u4f5c\u4e3a\u8bc4\u4f30\u8de8\u9886\u57df\u548c\u6f14\u8fdb\u4efb\u52a1\u80fd\u529b\u7684\u66f4\u7a33\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.12950", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12950", "abs": "https://arxiv.org/abs/2511.12950", "authors": ["Zirui Chen", "Zhipeng Xue", "Jiayuan Zhou", "Xing Hu", "Xin Xia", "Xiaohu Yang"], "title": "Diffploit: Facilitating Cross-Version Exploit Migration for Open Source Library Vulnerabilities", "comment": null, "summary": "Exploits are commonly used to demonstrate the presence of library vulnerabilities and validate their impact across different versions. However, their direct application to alternative versions often fails due to breaking changes introduced during evolution. These failures stem from both changes in triggering conditions (e.g., API refactorings) and broken dynamic environments (e.g., build or runtime errors), which are challenging to interpret and adapt manually. Existing techniques primarily focus on code-level trace alignment through fuzzing, which is both time-consuming and insufficient for handling environment-level failures. Moreover, they often fall short when dealing with complicated triggering condition changes across versions. To overcome this, we propose Diffploit, an iterative, diff-driven exploit migration method structured around two key modules: the Context Module and the Migration Module. The Context Module dynamically constructs contexts derived from analyzing behavioral discrepancies between the target and reference versions, which capture the failure symptom and its related diff hunks. Leveraging these contexts, the Migration Module guides an LLM-based adaptation through an iterative feedback loop, balancing exploration of diff candidates and gradual refinement to resolve reproduction failures effectively. We evaluate Diffploit on a large-scale dataset containing 102 Java CVEs and 689 version-migration tasks across 79 libraries. Diffploit successfully migrates 84.2% exploits, outperforming the change-aware test repair tool TARGET by 52.0% and the rule-based tool in IDEA by 61.6%. Beyond technical effectiveness, Diffploit identifies 5 CVE reports with incorrect affected version ranges, three of which have been confirmed. It also discovers 111 unreported vulnerable versions in the GitHub Advisory Database.", "AI": {"tldr": "Diffploit\u662f\u4e00\u79cd\u57fa\u4e8e\u5dee\u5f02\u9a71\u52a8\u7684\u6f0f\u6d1e\u5229\u7528\u8fc1\u79fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u6a21\u5757\u548c\u8fc1\u79fb\u6a21\u5757\u8fed\u4ee3\u4fee\u590d\u8de8\u7248\u672c\u6f0f\u6d1e\u5229\u7528\u5931\u8d25\u95ee\u9898\uff0c\u5728102\u4e2aJava CVE\u548c689\u4e2a\u7248\u672c\u8fc1\u79fb\u4efb\u52a1\u4e2d\u6210\u529f\u8fc1\u79fb84.2%\u7684\u6f0f\u6d1e\u5229\u7528\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u4e3b\u8981\u5173\u6ce8\u4ee3\u7801\u7ea7\u8ddf\u8e2a\u5bf9\u9f50\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u73af\u5883\u7ea7\u5931\u8d25\u548c\u590d\u6742\u7684\u89e6\u53d1\u6761\u4ef6\u53d8\u5316\uff0c\u5bfc\u81f4\u6f0f\u6d1e\u5229\u7528\u5728\u4e0d\u540c\u7248\u672c\u95f4\u76f4\u63a5\u5e94\u7528\u7ecf\u5e38\u5931\u8d25\u3002", "method": "\u63d0\u51faDiffploit\u65b9\u6cd5\uff0c\u5305\u542b\u4e0a\u4e0b\u6587\u6a21\u5757\uff08\u52a8\u6001\u6784\u5efa\u884c\u4e3a\u5dee\u5f02\u4e0a\u4e0b\u6587\uff09\u548c\u8fc1\u79fb\u6a21\u5757\uff08\u57fa\u4e8eLLM\u7684\u8fed\u4ee3\u53cd\u9988\u5faa\u73af\u9002\u914d\uff09\uff0c\u901a\u8fc7\u5dee\u5f02\u9a71\u52a8\u9010\u6b65\u89e3\u51b3\u590d\u5236\u5931\u8d25\u3002", "result": "\u5728102\u4e2aJava CVE\u548c689\u4e2a\u7248\u672c\u8fc1\u79fb\u4efb\u52a1\u4e2d\uff0cDiffploit\u6210\u529f\u8fc1\u79fb84.2%\u7684\u6f0f\u6d1e\u5229\u7528\uff0c\u6bd4TARGET\u5de5\u5177\u9ad852.0%\uff0c\u6bd4IDEA\u5de5\u5177\u9ad861.6%\u3002\u540c\u65f6\u53d1\u73b05\u4e2aCVE\u62a5\u544a\u5b58\u5728\u9519\u8bef\u5f71\u54cd\u7248\u672c\u8303\u56f4\uff0c111\u4e2aGitHub Advisory Database\u4e2d\u672a\u62a5\u544a\u7684\u6613\u53d7\u653b\u51fb\u7248\u672c\u3002", "conclusion": "Diffploit\u901a\u8fc7\u5dee\u5f02\u9a71\u52a8\u7684\u8fed\u4ee3\u8fc1\u79fb\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u7248\u672c\u6f0f\u6d1e\u5229\u7528\u8fc1\u79fb\u95ee\u9898\uff0c\u5728\u6280\u672f\u6548\u679c\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.12149", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12149", "abs": "https://arxiv.org/abs/2511.12149", "authors": ["Jiayu Li", "Yunhan Zhao", "Xiang Zheng", "Zonghuan Xu", "Yige Li", "Xingjun Ma", "Yu-Gang Jiang"], "title": "AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models", "comment": null, "summary": "Vision-Language-Action (VLA) models enable robots to interpret natural-language instructions and perform diverse tasks, yet their integration of perception, language, and control introduces new safety vulnerabilities. Despite growing interest in attacking such models, the effectiveness of existing techniques remains unclear due to the absence of a unified evaluation framework. One major issue is that differences in action tokenizers across VLA architectures hinder reproducibility and fair comparison. More importantly, most existing attacks have not been validated in real-world scenarios. To address these challenges, we propose AttackVLA, a unified framework that aligns with the VLA development lifecycle, covering data construction, model training, and inference. Within this framework, we implement a broad suite of attacks, including all existing attacks targeting VLAs and multiple adapted attacks originally developed for vision-language models, and evaluate them in both simulation and real-world settings. Our analysis of existing attacks reveals a critical gap: current methods tend to induce untargeted failures or static action states, leaving targeted attacks that drive VLAs to perform precise long-horizon action sequences largely unexplored. To fill this gap, we introduce BackdoorVLA, a targeted backdoor attack that compels a VLA to execute an attacker-specified long-horizon action sequence whenever a trigger is present. We evaluate BackdoorVLA in both simulated benchmarks and real-world robotic settings, achieving an average targeted success rate of 58.4% and reaching 100% on selected tasks. Our work provides a standardized framework for evaluating VLA vulnerabilities and demonstrates the potential for precise adversarial manipulation, motivating further research on securing VLA-based embodied systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86AttackVLA\u7edf\u4e00\u6846\u67b6\u6765\u8bc4\u4f30Vision-Language-Action\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u5f00\u53d1\u4e86BackdoorVLA\u540e\u95e8\u653b\u51fb\uff0c\u80fd\u591f\u5728\u89e6\u53d1\u6761\u4ef6\u4e0b\u5f3a\u5236VLA\u6267\u884c\u653b\u51fb\u8005\u6307\u5b9a\u7684\u957f\u65f6\u7a0b\u52a8\u4f5c\u5e8f\u5217\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u73b0\u6709\u9488\u5bf9VLA\u6a21\u578b\u7684\u653b\u51fb\u65b9\u6cd5\u6548\u679c\u4e0d\u660e\u786e\uff0c\u4e14\u5927\u591a\u6570\u672a\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\u3002\u4e0d\u540cVLA\u67b6\u6784\u7684\u52a8\u4f5c\u6807\u8bb0\u5668\u5dee\u5f02\u4e5f\u963b\u788d\u4e86\u53ef\u91cd\u590d\u6027\u548c\u516c\u5e73\u6bd4\u8f83\u3002", "method": "\u63d0\u51faAttackVLA\u7edf\u4e00\u6846\u67b6\uff0c\u6db5\u76d6\u6570\u636e\u6784\u5efa\u3001\u6a21\u578b\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u3002\u5b9e\u73b0\u4e86\u5305\u62ec\u6240\u6709\u73b0\u6709VLA\u653b\u51fb\u548c\u591a\u79cd\u4ece\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6539\u7f16\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u5728\u4eff\u771f\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u4eff\u771f\u57fa\u51c6\u548c\u771f\u5b9e\u673a\u5668\u4eba\u73af\u5883\u4e2d\u8bc4\u4f30BackdoorVLA\uff0c\u5e73\u5747\u76ee\u6807\u6210\u529f\u7387\u8fbe\u523058.4%\uff0c\u5728\u9009\u5b9a\u4efb\u52a1\u4e2d\u8fbe\u5230100%\u3002\u5206\u6790\u53d1\u73b0\u73b0\u6709\u653b\u51fb\u4e3b\u8981\u5bfc\u81f4\u65e0\u76ee\u6807\u5931\u8d25\u6216\u9759\u6001\u52a8\u4f5c\u72b6\u6001\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u8bc4\u4f30VLA\u6f0f\u6d1e\u7684\u6807\u51c6\u5316\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u7cbe\u786e\u5bf9\u6297\u64cd\u7eb5\u7684\u6f5c\u529b\uff0c\u6fc0\u52b1\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u4fdd\u62a4\u57fa\u4e8eVLA\u7684\u5177\u8eab\u7cfb\u7edf\u5b89\u5168\u3002"}}
{"id": "2511.11816", "categories": ["cs.AI", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.11816", "abs": "https://arxiv.org/abs/2511.11816", "authors": ["Andrea Brunello", "Luca Geatti", "Michele Mignani", "Angelo Montanari", "Nicola Saccomanno"], "title": "Do LLMs Really Struggle at NL-FOL Translation? Revealing their Strengths via a Novel Benchmarking Strategy", "comment": "Full version of the paper accepted for publication at The 40th Annual AAAI Conference on Artificial Intelligence (AAAI 2026)", "summary": "Due to its expressiveness and unambiguous nature, First-Order Logic (FOL) is a powerful formalism for representing concepts expressed in natural language (NL). This is useful, e.g., for specifying and verifying desired system properties. While translating FOL into human-readable English is relatively straightforward, the inverse problem, converting NL to FOL (NL-FOL translation), has remained a longstanding challenge, for both humans and machines. Although the emergence of Large Language Models (LLMs) promised a breakthrough, recent literature provides contrasting results on their ability to perform NL-FOL translation. In this work, we provide a threefold contribution. First, we critically examine existing datasets and protocols for evaluating NL-FOL translation performance, revealing key limitations that may cause a misrepresentation of LLMs' actual capabilities. Second, to overcome these shortcomings, we propose a novel evaluation protocol explicitly designed to distinguish genuine semantic-level logical understanding from superficial pattern recognition, memorization, and dataset contamination. Third, using this new approach, we show that state-of-the-art, dialogue-oriented LLMs demonstrate strong NL-FOL translation skills and a genuine grasp of sentence-level logic, whereas embedding-centric models perform markedly worse.", "AI": {"tldr": "\u672c\u6587\u6279\u5224\u6027\u8bc4\u4f30\u4e86\u73b0\u6709NL-FOL\u7ffb\u8bd1\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u534f\u8bae\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u533a\u5206\u771f\u6b63\u7684\u8bed\u4e49\u7406\u89e3\u4e0e\u8868\u9762\u6a21\u5f0f\u8bc6\u522b\uff0c\u5e76\u8bc1\u660e\u5bf9\u8bdd\u5bfc\u5411\u7684LLM\u5728NL-FOL\u7ffb\u8bd1\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u7531\u4e8e\u4e00\u9636\u903b\u8f91(FOL)\u7684\u8868\u8fbe\u80fd\u529b\u548c\u660e\u786e\u6027\uff0c\u5b83\u662f\u8868\u793a\u81ea\u7136\u8bed\u8a00\u6982\u5ff5\u7684\u6709\u529b\u5f62\u5f0f\u5316\u5de5\u5177\u3002\u867d\u7136\u5c06FOL\u7ffb\u8bd1\u6210\u53ef\u8bfb\u82f1\u6587\u76f8\u5bf9\u7b80\u5355\uff0c\u4f46\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u4e3aFOL(NL-FOL\u7ffb\u8bd1)\u4e00\u76f4\u662f\u957f\u671f\u6311\u6218\u3002\u5c3d\u7ba1LLM\u7684\u51fa\u73b0\u5e26\u6765\u4e86\u7a81\u7834\u5e0c\u671b\uff0c\u4f46\u73b0\u6709\u6587\u732e\u5bf9\u5176NL-FOL\u7ffb\u8bd1\u80fd\u529b\u63d0\u4f9b\u4e86\u77db\u76fe\u7684\u7ed3\u679c\u3002", "method": "1) \u6279\u5224\u6027\u68c0\u67e5\u73b0\u6709NL-FOL\u7ffb\u8bd1\u8bc4\u4f30\u6570\u636e\u96c6\u548c\u534f\u8bae\u7684\u5173\u952e\u5c40\u9650\u6027\uff1b2) \u63d0\u51fa\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u533a\u5206\u771f\u6b63\u7684\u8bed\u4e49\u7ea7\u903b\u8f91\u7406\u89e3\u4e0e\u8868\u9762\u6a21\u5f0f\u8bc6\u522b\u3001\u8bb0\u5fc6\u548c\u6570\u636e\u96c6\u6c61\u67d3\uff1b3) \u4f7f\u7528\u65b0\u65b9\u6cd5\u8bc4\u4f30\u6700\u5148\u8fdb\u7684\u5bf9\u8bdd\u5bfc\u5411LLM\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684\u5bf9\u8bdd\u5bfc\u5411LLM\u8868\u73b0\u51fa\u5f3a\u5927\u7684NL-FOL\u7ffb\u8bd1\u6280\u80fd\u548c\u771f\u6b63\u7684\u53e5\u5b50\u7ea7\u903b\u8f91\u7406\u89e3\u80fd\u529b\uff0c\u800c\u5d4c\u5165\u4e2d\u5fc3\u6a21\u578b\u8868\u73b0\u660e\u663e\u8f83\u5dee\u3002", "conclusion": "\u901a\u8fc7\u8bbe\u8ba1\u66f4\u4e25\u683c\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u672c\u6587\u63ed\u793a\u4e86LLM\u5728NL-FOL\u7ffb\u8bd1\u65b9\u9762\u7684\u771f\u5b9e\u80fd\u529b\uff0c\u8bc1\u660e\u5bf9\u8bdd\u5bfc\u5411\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u771f\u6b63\u7684\u8bed\u4e49\u7ea7\u903b\u8f91\u7406\u89e3\uff0c\u800c\u975e\u4ec5\u4ec5\u8868\u9762\u6a21\u5f0f\u5339\u914d\u3002"}}
{"id": "2511.12993", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.12993", "abs": "https://arxiv.org/abs/2511.12993", "authors": ["Longfei Chen", "Ruibin Yan", "Taiyu Wong", "Yiyang Chen", "Chao Zhang"], "title": "SmartPoC: Generating Executable and Validated PoCs for Smart Contract Bug Reports", "comment": null, "summary": "Smart contracts are prone to vulnerabilities and are analyzed by experts as well as automated systems, such as static analysis and AI-assisted solutions. However, audit artifacts are heterogeneous and often lack reproducible, executable PoC tests suitable for automated validation, leading to costly, ad hoc manual verification. Large language models (LLMs) can be leveraged to turn audit reports into PoC test cases, but have three major challenges: noisy inputs, hallucinations, and missing runtime oracles. In this paper, we present SmartPoC, an automated framework that converts textual audit reports into executable, validated test cases. First, the input audit report is processed to reduce noise, and only bug-related functions are extracted and fed to LLMs as context. To curb hallucinations and ensure compile-and-run readiness, we leverage LLMs to synthesize PoC test cases with specially-designed pre-/post-execution repair. We further utilize differential verification as oracles to confirm exploitability of the PoC test cases. On the SmartBugs-Vul and FORGE-Vul benchmarks, SmartPoC generates executable, validated Foundry test cases for 85.61% and 86.45% of targets, respectively. Applied to the latest Etherscan verified-source corpus, SmartPoC confirms 236 real bugs out of 545 audit findings at a cost of only $0.03 per finding.", "AI": {"tldr": "SmartPoC\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u6587\u672c\u5ba1\u8ba1\u62a5\u544a\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u3001\u5df2\u9a8c\u8bc1\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5ba1\u8ba1\u5de5\u4ef6\u7684\u5f02\u6784\u6027\u548c\u7f3a\u4e4f\u53ef\u91cd\u73b0PoC\u6d4b\u8bd5\u7684\u95ee\u9898\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u5bb9\u6613\u5b58\u5728\u6f0f\u6d1e\uff0c\u4f46\u5ba1\u8ba1\u5de5\u4ef6\u901a\u5e38\u7f3a\u4e4f\u53ef\u91cd\u73b0\u3001\u53ef\u6267\u884c\u7684PoC\u6d4b\u8bd5\uff0c\u5bfc\u81f4\u9700\u8981\u6602\u8d35\u7684\u624b\u52a8\u9a8c\u8bc1\u3002\u73b0\u6709LLM\u65b9\u6cd5\u9762\u4e34\u566a\u58f0\u8f93\u5165\u3001\u5e7b\u89c9\u548c\u7f3a\u5c11\u8fd0\u884c\u65f6\u9884\u8a00\u673a\u4e09\u5927\u6311\u6218\u3002", "method": "\u9996\u5148\u5904\u7406\u8f93\u5165\u5ba1\u8ba1\u62a5\u544a\u4ee5\u51cf\u5c11\u566a\u58f0\uff0c\u4ec5\u63d0\u53d6\u4e0e\u6f0f\u6d1e\u76f8\u5173\u7684\u51fd\u6570\u4f5c\u4e3aLLM\u4e0a\u4e0b\u6587\uff1b\u5229\u7528LLM\u5408\u6210PoC\u6d4b\u8bd5\u7528\u4f8b\uff0c\u91c7\u7528\u4e13\u95e8\u8bbe\u8ba1\u7684\u6267\u884c\u524d\u540e\u4fee\u590d\u673a\u5236\u6765\u6291\u5236\u5e7b\u89c9\u5e76\u786e\u4fdd\u7f16\u8bd1\u8fd0\u884c\u5c31\u7eea\uff1b\u4f7f\u7528\u5dee\u5206\u9a8c\u8bc1\u4f5c\u4e3a\u9884\u8a00\u673a\u6765\u786e\u8ba4PoC\u6d4b\u8bd5\u7528\u4f8b\u7684\u53ef\u5229\u7528\u6027\u3002", "result": "\u5728SmartBugs-Vul\u548cFORGE-Vul\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cSmartPoC\u5206\u522b\u4e3a85.61%\u548c86.45%\u7684\u76ee\u6807\u751f\u6210\u4e86\u53ef\u6267\u884c\u3001\u5df2\u9a8c\u8bc1\u7684Foundry\u6d4b\u8bd5\u7528\u4f8b\u3002\u5e94\u7528\u4e8e\u6700\u65b0\u7684Etherscan\u9a8c\u8bc1\u6e90\u8bed\u6599\u5e93\uff0cSmartPoC\u4ee5\u6bcf\u4e2a\u53d1\u73b0\u4ec50.03\u7f8e\u5143\u7684\u6210\u672c\u786e\u8ba4\u4e86545\u4e2a\u5ba1\u8ba1\u53d1\u73b0\u4e2d\u7684236\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u3002", "conclusion": "SmartPoC\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5c06\u6587\u672c\u5ba1\u8ba1\u62a5\u544a\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u6d4b\u8bd5\u7528\u4f8b\u7684\u6311\u6218\uff0c\u901a\u8fc7\u51cf\u5c11\u566a\u58f0\u8f93\u5165\u3001\u6291\u5236\u5e7b\u89c9\u548c\u63d0\u4f9b\u8fd0\u884c\u65f6\u9884\u8a00\u673a\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u6f0f\u6d1e\u9a8c\u8bc1\u3002"}}
{"id": "2511.12164", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12164", "abs": "https://arxiv.org/abs/2511.12164", "authors": ["Jie Chen", "Liangmin Wang"], "title": "Multi-Agent Collaborative Fuzzing with Continuous Reflection for Smart Contracts Vulnerability Detection", "comment": null, "summary": "Fuzzing is a widely used technique for detecting vulnerabilities in smart contracts, which generates transaction sequences to explore the execution paths of smart contracts. However, existing fuzzers are falling short in detecting sophisticated vulnerabilities that require specific attack transaction sequences with proper inputs to trigger, as they (i) prioritize code coverage over vulnerability discovery, wasting considerable effort on non-vulnerable code regions, and (ii) lack semantic understanding of stateful contracts, generating numerous invalid transaction sequences that cannot pass runtime execution.\n  In this paper, we propose SmartFuzz, a novel collaborative reflective fuzzer for smart contract vulnerability detection. It employs large language model-driven agents as the fuzzing engine and continuously improves itself by learning and reflecting through interactions with the environment. Specifically, we first propose a new Continuous Reflection Process (CRP) for fuzzing smart contracts, which reforms the transaction sequence generation as a self-evolving process through continuous reflection on feedback from the runtime environment. Then, we present the Reactive Collaborative Chain (RCC) to orchestrate the fuzzing process into multiple sub-tasks based on the dependencies of transaction sequences. Furthermore, we design a multi-agent collaborative team, where each expert agent is guided by the RCC to jointly generate and refine transaction sequences from both global and local perspectives. We conduct extensive experiments to evaluate SmartFuzz's performance on real-world contracts and DApp projects. The results demonstrate that SmartFuzz outperforms existing state-of-the-art tools: (i) it detects 5.8\\%-74.7\\% more vulnerabilities within 30 minutes, and (ii) it reduces false negatives by up to 80\\%.", "AI": {"tldr": "SmartFuzz\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u534f\u4f5c\u5f0f\u53cd\u5c04\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u7528\u4e8e\u68c0\u6d4b\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u3002\u5b83\u901a\u8fc7\u6301\u7eed\u53cd\u5c04\u8fc7\u7a0b\u548c\u53cd\u5e94\u5f0f\u534f\u4f5c\u94fe\u673a\u5236\uff0c\u6709\u6548\u751f\u6210\u80fd\u89e6\u53d1\u590d\u6742\u6f0f\u6d1e\u7684\u4ea4\u6613\u5e8f\u5217\u3002", "motivation": "\u73b0\u6709\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u5728\u68c0\u6d4b\u590d\u6742\u6f0f\u6d1e\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff1a\u8fc7\u5ea6\u5173\u6ce8\u4ee3\u7801\u8986\u76d6\u7387\u800c\u975e\u6f0f\u6d1e\u53d1\u73b0\uff0c\u6d6a\u8d39\u5927\u91cf\u8d44\u6e90\u5728\u975e\u6f0f\u6d1e\u4ee3\u7801\u533a\u57df\uff1b\u7f3a\u4e4f\u5bf9\u72b6\u6001\u5316\u5408\u7ea6\u7684\u8bed\u4e49\u7406\u89e3\uff0c\u751f\u6210\u5927\u91cf\u65e0\u6cd5\u901a\u8fc7\u8fd0\u884c\u65f6\u6267\u884c\u7684\u65e0\u6548\u4ea4\u6613\u5e8f\u5217\u3002", "method": "\u63d0\u51fa\u6301\u7eed\u53cd\u5c04\u8fc7\u7a0b(CRP)\u5c06\u4ea4\u6613\u5e8f\u5217\u751f\u6210\u91cd\u6784\u4e3a\u901a\u8fc7\u73af\u5883\u53cd\u9988\u6301\u7eed\u8fdb\u5316\u7684\u8fc7\u7a0b\uff1b\u8bbe\u8ba1\u53cd\u5e94\u5f0f\u534f\u4f5c\u94fe(RCC)\u57fa\u4e8e\u4ea4\u6613\u5e8f\u5217\u4f9d\u8d56\u5173\u7cfb\u534f\u8c03\u6a21\u7cca\u6d4b\u8bd5\u8fc7\u7a0b\uff1b\u6784\u5efa\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u56e2\u961f\uff0c\u5404\u4e13\u5bb6\u667a\u80fd\u4f53\u5728RCC\u6307\u5bfc\u4e0b\u4ece\u5168\u5c40\u548c\u5c40\u90e8\u89c6\u89d2\u5171\u540c\u751f\u6210\u548c\u4f18\u5316\u4ea4\u6613\u5e8f\u5217\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u5408\u7ea6\u548cDApp\u9879\u76ee\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSmartFuzz\u572830\u5206\u949f\u5185\u68c0\u6d4b\u5230\u7684\u6f0f\u6d1e\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u5de5\u5177\u591a5.8%-74.7%\uff0c\u5e76\u5c06\u8bef\u62a5\u7387\u964d\u4f4e\u9ad8\u8fbe80%\u3002", "conclusion": "SmartFuzz\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u534f\u4f5c\u53cd\u5c04\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u5408\u7ea6\u590d\u6742\u6f0f\u6d1e\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5728\u6f0f\u6d1e\u53d1\u73b0\u6548\u7387\u548c\u51c6\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002"}}
{"id": "2511.11831", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11831", "abs": "https://arxiv.org/abs/2511.11831", "authors": ["Wenhao Zhou", "Hao Zheng", "Rong Zhao"], "title": "TopoPerception: A Shortcut-Free Evaluation of Global Visual Perception in Large Vision-Language Models", "comment": null, "summary": "Large Vision-Language Models (LVLMs) typically align visual features from an encoder with a pre-trained Large Language Model (LLM). However, this makes the visual perception module a bottleneck, which constrains the overall capabilities of LVLMs. Conventional evaluation benchmarks, while rich in visual semantics, often contain unavoidable local shortcuts that can lead to an overestimation of models' perceptual abilities. Here, we introduce TopoPerception, a benchmark that leverages topological properties to rigorously evaluate the global visual perception capabilities of LVLMs across various granularities. Since topology depends on the global structure of an image and is invariant to local features, TopoPerception enables a shortcut-free assessment of global perception, fundamentally distinguishing it from semantically rich tasks. We evaluate state-of-the-art models on TopoPerception and find that even at the coarsest perceptual granularity, all models perform no better than random chance, indicating a profound inability to perceive global visual features. Notably, a consistent trend emerge within model families: more powerful models with stronger reasoning capabilities exhibit lower accuracy. This suggests that merely scaling up models is insufficient to address this deficit and may even exacerbate it. Progress may require new training paradigms or architectures. TopoPerception not only exposes a critical bottleneck in current LVLMs but also offers a lens and direction for improving their global visual perception. The data and code are publicly available at: https://github.com/Wenhao-Zhou/TopoPerception.", "AI": {"tldr": "TopoPerception\u662f\u4e00\u4e2a\u57fa\u4e8e\u62d3\u6251\u5c5e\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u4e25\u683c\u8bc4\u4f30\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5168\u5c40\u89c6\u89c9\u611f\u77e5\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u5168\u5c40\u611f\u77e5\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u751a\u81f3\u4e0d\u5982\u968f\u673a\u731c\u6d4b\u3002", "motivation": "\u4f20\u7edf\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u5c40\u90e8\u6377\u5f84\u95ee\u9898\uff0c\u4f1a\u9ad8\u4f30\u6a21\u578b\u7684\u611f\u77e5\u80fd\u529b\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u62d3\u6251\u5c5e\u6027\u6765\u65e0\u6377\u5f84\u5730\u8bc4\u4f30\u6a21\u578b\u7684\u5168\u5c40\u89c6\u89c9\u611f\u77e5\u80fd\u529b\u3002", "method": "\u5229\u7528\u62d3\u6251\u5c5e\u6027\u521b\u5efaTopoPerception\u57fa\u51c6\u6d4b\u8bd5\uff0c\u56e0\u4e3a\u62d3\u6251\u4f9d\u8d56\u4e8e\u56fe\u50cf\u7684\u5168\u5c40\u7ed3\u6784\u4e14\u5bf9\u5c40\u90e8\u7279\u5f81\u4e0d\u53d8\uff0c\u4ece\u800c\u80fd\u591f\u65e0\u6377\u5f84\u5730\u8bc4\u4f30\u5168\u5c40\u611f\u77e5\u3002", "result": "\u6240\u6709\u6700\u5148\u8fdb\u6a21\u578b\u5728\u6700\u7c97\u611f\u77e5\u7c92\u5ea6\u4e0b\u8868\u73b0\u90fd\u4e0d\u4f18\u4e8e\u968f\u673a\u673a\u4f1a\uff0c\u8868\u660e\u5b83\u4eec\u4e25\u91cd\u7f3a\u4e4f\u5168\u5c40\u89c6\u89c9\u7279\u5f81\u611f\u77e5\u80fd\u529b\u3002\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u53cd\u800c\u51c6\u786e\u7387\u66f4\u4f4e\u3002", "conclusion": "\u4ec5\u6269\u5927\u6a21\u578b\u89c4\u6a21\u4e0d\u8db3\u4ee5\u89e3\u51b3\u5168\u5c40\u611f\u77e5\u7f3a\u9677\uff0c\u53ef\u80fd\u9700\u8981\u65b0\u7684\u8bad\u7ec3\u8303\u5f0f\u6216\u67b6\u6784\u3002TopoPerception\u63ed\u793a\u4e86\u5f53\u524dLVLMs\u7684\u5173\u952e\u74f6\u9888\u5e76\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2511.13069", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.13069", "abs": "https://arxiv.org/abs/2511.13069", "authors": ["Zhenyu Mao", "Jacky Keung", "Yicheng Sun", "Yifei Wang", "Shuo Liu", "Jialong Li"], "title": "Towards Requirements Engineering for GenAI-Enabled Software: Bridging Responsibility Gaps through Human Oversight Requirements", "comment": null, "summary": "Context: Responsibility gaps, long-recognized challenges in socio-technical systems where accountability becomes diffuse or ambiguous, have become increasingly pronounced in GenAI-enabled software. The generative and adaptive nature complicates how human oversight and responsibility are specified, delegated, and traced. Existing requirements engineering (RE) approaches remain limited in addressing these phenomena, revealing conceptual, methodological, and artifact-level research gaps.. Objective: This study aims to analyze these research gaps in the context of GenAI-enabled software systems. It seeks to establish a coherent perspective for a systematic analysis of responsibility gaps from a human oversight requirements standpoint, encompassing how these responsibility gaps should be conceptualized, identified, and represented throughout the RE process. Methods: The proposed design methodology is structured across three analytical layers. At the conceptualization layer, it establishes a conceptual framing that defines the key elements of responsibility across the human and system dimensions and explains how potential responsibility gaps emerge from their interactions. At the methodological layer, it introduces a deductive pipeline for identifying responsibility gaps by analyzing interactions between these dimensions and deriving corresponding oversight requirements within established RE frameworks. At the artifact layer, it formalizes the results in a Deductive Backbone Table, a reusable representation that traces the reasoning path from responsibility gaps identification to human oversight requirements derivation. Results: A user study compared the proposed methodology with a baseline goal-oriented RE across two scenarios. Evaluation across six dimensions indicated clear improvements of the proposed methodology, confirming its effectiveness in addressing three research gaps.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u5c42\u5206\u6790\u65b9\u6cd5\u6765\u89e3\u51b3GenAI\u8f6f\u4ef6\u4e2d\u7684\u8d23\u4efb\u7f3a\u53e3\u95ee\u9898\uff0c\u5305\u62ec\u6982\u5ff5\u5316\u3001\u65b9\u6cd5\u8bba\u548c\u5de5\u4ef6\u5c42\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u8bc6\u522b\u8d23\u4efb\u7f3a\u53e3\u548c\u63a8\u5bfc\u76d1\u7763\u9700\u6c42\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "GenAI\u8f6f\u4ef6\u4e2d\u7684\u751f\u6210\u6027\u548c\u9002\u5e94\u6027\u7279\u6027\u4f7f\u5f97\u4eba\u7c7b\u76d1\u7763\u548c\u8d23\u4efb\u53d8\u5f97\u590d\u6742\uff0c\u73b0\u6709\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\u5728\u5904\u7406\u8d23\u4efb\u7f3a\u53e3\u73b0\u8c61\u65b9\u9762\u5b58\u5728\u6982\u5ff5\u3001\u65b9\u6cd5\u548c\u5de5\u4ef6\u5c42\u9762\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u4e09\u5c42\u8bbe\u8ba1\u65b9\u6cd5\uff1a\u6982\u5ff5\u5316\u5c42\u5b9a\u4e49\u8d23\u4efb\u8981\u7d20\u548c\u7f3a\u53e3\u5f62\u6210\u673a\u5236\uff1b\u65b9\u6cd5\u8bba\u5c42\u901a\u8fc7\u5206\u6790\u4eba\u673a\u4ea4\u4e92\u63a8\u5bfc\u76d1\u7763\u9700\u6c42\uff1b\u5de5\u4ef6\u5c42\u7528\u6f14\u7ece\u9aa8\u5e72\u8868\u5f62\u5f0f\u5316\u8868\u793a\u63a8\u7406\u8def\u5f84\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u76ee\u6807\u5bfc\u5411\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u516d\u4e2a\u7ef4\u5ea6\u4e0a\u5747\u6709\u660e\u663e\u6539\u8fdb\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e09\u4e2a\u7814\u7a76\u7a7a\u767d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aGenAI\u8f6f\u4ef6\u4e2d\u7684\u8d23\u4efb\u7f3a\u53e3\u5206\u6790\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u548c\u8868\u793a\u8d23\u4efb\u7f3a\u53e3\uff0c\u5e76\u63a8\u5bfc\u76f8\u5e94\u7684\u4eba\u7c7b\u76d1\u7763\u9700\u6c42\u3002"}}
{"id": "2511.11899", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.11899", "abs": "https://arxiv.org/abs/2511.11899", "authors": ["Xi Li", "Nicholas Matsumoto", "Ujjwal Pasupulety", "Atharva Deo", "Cherine Yang", "Jay Moran", "Miguel E. Hernandez", "Peter Wager", "Jasmine Lin", "Jeanine Kim", "Alvin C. Goh", "Christian Wagner", "Geoffrey A. Sonn", "Andrew J. Hung"], "title": "End to End AI System for Surgical Gesture Sequence Recognition and Clinical Outcome Prediction", "comment": null, "summary": "Fine-grained analysis of intraoperative behavior and its impact on patient outcomes remain a longstanding challenge. We present Frame-to-Outcome (F2O), an end-to-end system that translates tissue dissection videos into gesture sequences and uncovers patterns associated with postoperative outcomes. Leveraging transformer-based spatial and temporal modeling and frame-wise classification, F2O robustly detects consecutive short (~2 seconds) gestures in the nerve-sparing step of robot-assisted radical prostatectomy (AUC: 0.80 frame-level; 0.81 video-level). F2O-derived features (gesture frequency, duration, and transitions) predicted postoperative outcomes with accuracy comparable to human annotations (0.79 vs. 0.75; overlapping 95% CI). Across 25 shared features, effect size directions were concordant with small differences (~ 0.07), and strong correlation (r = 0.96, p < 1e-14). F2O also captured key patterns linked to erectile function recovery, including prolonged tissue peeling and reduced energy use. By enabling automatic interpretable assessment, F2O establishes a foundation for data-driven surgical feedback and prospective clinical decision support.", "AI": {"tldr": "F2O\u7cfb\u7edf\u901a\u8fc7\u5c06\u7ec4\u7ec7\u89e3\u5256\u89c6\u9891\u8f6c\u5316\u4e3a\u624b\u52bf\u5e8f\u5217\uff0c\u63ed\u793a\u4e0e\u672f\u540e\u7ed3\u679c\u76f8\u5173\u7684\u6a21\u5f0f\uff0c\u5728\u673a\u5668\u4eba\u8f85\u52a9\u6839\u6cbb\u6027\u524d\u5217\u817a\u5207\u9664\u672f\u4e2d\u5b9e\u73b0\u81ea\u52a8\u53ef\u89e3\u91ca\u7684\u624b\u672f\u8bc4\u4f30\u3002", "motivation": "\u89e3\u51b3\u672f\u4e2d\u884c\u4e3a\u7ec6\u7c92\u5ea6\u5206\u6790\u53ca\u5176\u5bf9\u60a3\u8005\u7ed3\u679c\u5f71\u54cd\u7684\u957f\u671f\u6311\u6218\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u624b\u672f\u53cd\u9988\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5960\u5b9a\u57fa\u7840\u3002", "method": "\u5229\u7528\u57fa\u4e8etransformer\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u5efa\u6a21\u4ee5\u53ca\u9010\u5e27\u5206\u7c7b\uff0c\u5728\u673a\u5668\u4eba\u8f85\u52a9\u6839\u6cbb\u6027\u524d\u5217\u817a\u5207\u9664\u672f\u7684\u795e\u7ecf\u4fdd\u7559\u6b65\u9aa4\u4e2d\u68c0\u6d4b\u8fde\u7eed\u77ed\u624b\u52bf\u3002", "result": "F2O\u5728\u624b\u52bf\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff08AUC\uff1a0.80\u5e27\u7ea7\uff1b0.81\u89c6\u9891\u7ea7\uff09\uff0c\u5176\u884d\u751f\u7279\u5f81\u9884\u6d4b\u672f\u540e\u7ed3\u679c\u7684\u51c6\u786e\u6027\u4e0e\u4eba\u5de5\u6807\u6ce8\u76f8\u5f53\uff080.79 vs. 0.75\uff09\uff0c\u5e76\u6355\u6349\u5230\u4e0e\u52c3\u8d77\u529f\u80fd\u6062\u590d\u76f8\u5173\u7684\u5173\u952e\u6a21\u5f0f\u3002", "conclusion": "F2O\u901a\u8fc7\u5b9e\u73b0\u81ea\u52a8\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u624b\u672f\u53cd\u9988\u548c\u524d\u77bb\u6027\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5efa\u7acb\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.13271", "categories": ["cs.SE", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.13271", "abs": "https://arxiv.org/abs/2511.13271", "authors": ["Rufeng Chen", "Shuaishuai Jiang", "Jiyun Shen", "AJung Moon", "Lili Wei"], "title": "Examining the Usage of Generative AI Models in Student Learning Activities for Software Programming", "comment": "9 pages, 4 figures, accepted at AIWARE 2025", "summary": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, intermediate) to examine how students interact with ChatGPT while solving programming tasks. We analyzed task performance, conceptual understanding, and interaction behaviors. Our findings reveal that generating complete solutions with GenAI significantly improves task performance, especially for beginners, but does not consistently result in knowledge gains. Importantly, usage strategies differ by experience: beginners tend to rely heavily on GenAI toward task completion often without knowledge gain in the process, while intermediates adopt more selective approaches. We find that both over-reliance and minimal use result in weaker knowledge gains overall. Based on our results, we call on students and educators to adopt GenAI as a learning rather than a problem solving tool. Our study highlights the urgent need for guidance when integrating GenAI into programming education to foster deeper understanding.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86GenAI\uff08\u5982ChatGPT\uff09\u4e0e\u4f20\u7edf\u5728\u7ebf\u8d44\u6e90\u5728\u652f\u6301\u7f16\u7a0b\u77e5\u8bc6\u83b7\u53d6\u65b9\u9762\u7684\u6548\u679c\uff0c\u53d1\u73b0GenAI\u80fd\u663e\u8457\u63d0\u5347\u4efb\u52a1\u5b8c\u6210\u8868\u73b0\uff0c\u4f46\u5bf9\u77e5\u8bc6\u83b7\u53d6\u6548\u679c\u4e0d\u4e00\u81f4\uff0c\u4e14\u4e0d\u540c\u7ecf\u9a8c\u6c34\u5e73\u7684\u5b66\u751f\u4f7f\u7528\u7b56\u7565\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8GenAI\u5b8c\u6210\u6559\u80b2\u4efb\u52a1\u7684\u80fd\u529b\u53ca\u5176\u5bf9\u5b66\u751f\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u4f46\u5ffd\u89c6\u4e86\u5176\u5bf9\u77e5\u8bc6\u83b7\u53d6\u7684\u5f71\u54cd\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76GenAI\u8f85\u52a9\u4e0e\u4f20\u7edf\u5728\u7ebf\u8d44\u6e90\u5728\u652f\u6301\u4e0d\u540c\u719f\u7ec3\u7a0b\u5ea6\u5b66\u751f\u77e5\u8bc6\u83b7\u53d6\u65b9\u9762\u7684\u6bd4\u8f83\u3002", "method": "\u5bf924\u540d\u5177\u6709\u4e0d\u540c\u7f16\u7a0b\u7ecf\u9a8c\uff08\u521d\u5b66\u8005\u3001\u4e2d\u7ea7\uff09\u7684\u672c\u79d1\u751f\u8fdb\u884c\u53d7\u63a7\u7528\u6237\u5b9e\u9a8c\uff0c\u5206\u6790\u5b66\u751f\u5728\u89e3\u51b3\u7f16\u7a0b\u4efb\u52a1\u65f6\u4e0eChatGPT\u7684\u4ea4\u4e92\u884c\u4e3a\uff0c\u8bc4\u4f30\u4efb\u52a1\u8868\u73b0\u3001\u6982\u5ff5\u7406\u89e3\u548c\u4ea4\u4e92\u884c\u4e3a\u3002", "result": "\u4f7f\u7528GenAI\u751f\u6210\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u8868\u73b0\uff08\u7279\u522b\u662f\u5bf9\u521d\u5b66\u8005\uff09\uff0c\u4f46\u5e76\u672a\u6301\u7eed\u5e26\u6765\u77e5\u8bc6\u83b7\u53d6\u3002\u4f7f\u7528\u7b56\u7565\u56e0\u7ecf\u9a8c\u800c\u5f02\uff1a\u521d\u5b66\u8005\u503e\u5411\u4e8e\u8fc7\u5ea6\u4f9d\u8d56GenAI\u5b8c\u6210\u4efb\u52a1\u800c\u7f3a\u4e4f\u77e5\u8bc6\u83b7\u53d6\uff0c\u4e2d\u7ea7\u5b66\u751f\u91c7\u7528\u66f4\u6709\u9009\u62e9\u6027\u7684\u65b9\u6cd5\u3002\u8fc7\u5ea6\u4f9d\u8d56\u548c\u6781\u5c11\u4f7f\u7528\u90fd\u4f1a\u5bfc\u81f4\u8f83\u5f31\u7684\u77e5\u8bc6\u83b7\u53d6\u3002", "conclusion": "\u547c\u5401\u5b66\u751f\u548c\u6559\u80b2\u8005\u5c06GenAI\u4f5c\u4e3a\u5b66\u4e60\u5de5\u5177\u800c\u975e\u95ee\u9898\u89e3\u51b3\u5de5\u5177\uff0c\u5f3a\u8c03\u5728\u7f16\u7a0b\u6559\u80b2\u4e2d\u6574\u5408GenAI\u65f6\u9700\u8981\u6307\u5bfc\u4ee5\u4fc3\u8fdb\u66f4\u6df1\u5c42\u6b21\u7684\u7406\u89e3\u3002"}}
{"id": "2511.12225", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.12225", "abs": "https://arxiv.org/abs/2511.12225", "authors": ["Nishant Vasantkumar Hegde", "Suneesh Bare", "K B Ramesh", "Aamir Ibrahim"], "title": "eFPE: Design, Implementation, and Evaluation of a Lightweight Format-Preserving Encryption Algorithm for Embedded Systems", "comment": "6 pages, 3 figures. Published in: Proceedings of the 16th International IEEE Conference on Computing, Communication and Networking Technologies (ICCCNT) held at IIT-Indore, Madhya Pradesh, India", "summary": "Resource-constrained embedded systems demand secure yet lightweight data protection, particularly when data formats must be preserved. This paper introduces eFPE (Enhanced Format-Preserving Encryption), an 8-round Feistel cipher featuring a \"novel lightweight Pseudorandom Function (PRF)\" specifically designed for this domain. The PRF, architected with an efficient two-iteration structure of AES-inspired operations (byte-substitution, keyed XOR, and byte-rotation), underpins eFPE's ability to directly encrypt even-length decimal strings without padding or complex conversions, while aiming for IND-CCA2 security under standard assumptions. Implemented and evaluated on an ARM7TDMI LPC2148 microcontroller using Keil \u03bcVision 4, eFPE demonstrates the efficacy of its targeted design: a total firmware Read-Only Memory (ROM) footprint of 4.73 kB and Random Access Memory (RAM) usage of 1.34 kB. The core eFPE algorithm module itself is notably compact, requiring only 3.55 kB ROM and 116 B RAM. These characteristics make eFPE a distinct and highly suitable solution for applications like financial terminals, medical sensors, and industrial IoT devices where data format integrity, minimal resource footprint, and low operational latency are paramount.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faeFPE\uff08\u589e\u5f3a\u578b\u683c\u5f0f\u4fdd\u6301\u52a0\u5bc6\uff09\uff0c\u4e00\u79cd8\u8f6eFeistel\u5bc6\u7801\uff0c\u91c7\u7528\u65b0\u578b\u8f7b\u91cf\u7ea7\u4f2a\u968f\u673a\u51fd\u6570\uff0c\u4e13\u95e8\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u6570\u636e\u683c\u5f0f\u7684\u540c\u65f6\u63d0\u4f9b\u5b89\u5168\u52a0\u5bc6\u3002", "motivation": "\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u9700\u8981\u5b89\u5168\u4e14\u8f7b\u91cf\u7ea7\u7684\u6570\u636e\u4fdd\u62a4\uff0c\u7279\u522b\u662f\u5728\u5fc5\u987b\u4fdd\u6301\u6570\u636e\u683c\u5f0f\u7684\u60c5\u51b5\u4e0b\u3002\u73b0\u6709\u65b9\u6848\u5f80\u5f80\u9700\u8981\u586b\u5145\u6216\u590d\u6742\u8f6c\u6362\uff0c\u4e0d\u9002\u5408\u8fd9\u7c7b\u573a\u666f\u3002", "method": "\u4f7f\u75288\u8f6eFeistel\u7ed3\u6784\uff0c\u914d\u5907\u65b0\u578b\u8f7b\u91cf\u7ea7PRF\uff0c\u91c7\u7528AES\u542f\u53d1\u7684\u9ad8\u6548\u4e24\u8fed\u4ee3\u64cd\u4f5c\uff08\u5b57\u8282\u66ff\u6362\u3001\u5bc6\u94a5\u5f02\u6216\u548c\u5b57\u8282\u65cb\u8f6c\uff09\uff0c\u53ef\u76f4\u63a5\u52a0\u5bc6\u5076\u6570\u4f4d\u5341\u8fdb\u5236\u5b57\u7b26\u4e32\u800c\u65e0\u9700\u586b\u5145\u3002", "result": "\u5728ARM7TDMI LPC2148\u5fae\u63a7\u5236\u5668\u4e0a\u5b9e\u73b0\uff0c\u603b\u56fa\u4ef6ROM\u5360\u75284.73 kB\uff0cRAM\u4f7f\u75281.34 kB\uff0c\u6838\u5fc3\u7b97\u6cd5\u6a21\u5757\u4ec5\u97003.55 kB ROM\u548c116 B RAM\u3002", "conclusion": "eFPE\u662f\u91d1\u878d\u7ec8\u7aef\u3001\u533b\u7597\u4f20\u611f\u5668\u548c\u5de5\u4e1a\u7269\u8054\u7f51\u8bbe\u5907\u7b49\u5e94\u7528\u7684\u7406\u60f3\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6ee1\u8db3\u6570\u636e\u683c\u5f0f\u5b8c\u6574\u6027\u3001\u6700\u5c0f\u8d44\u6e90\u5360\u7528\u548c\u4f4e\u64cd\u4f5c\u5ef6\u8fdf\u7684\u8981\u6c42\u3002"}}
{"id": "2511.11914", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11914", "abs": "https://arxiv.org/abs/2511.11914", "authors": ["Shizhou Xu", "Yuan Ni", "Stefan Broecker", "Thomas Strohmer"], "title": "Forgetting-MarI: LLM Unlearning via Marginal Information Regularization", "comment": null, "summary": "As AI models are trained on ever-expanding datasets, the ability to remove the influence of specific data from trained models has become essential for privacy protection and regulatory compliance. Unlearning addresses this challenge by selectively removing parametric knowledge from the trained models without retraining from scratch, which is critical for resource-intensive models such as Large Language Models (LLMs). Existing unlearning methods often degrade model performance by removing more information than necessary when attempting to ''forget'' specific data. We introduce Forgetting-MarI, an LLM unlearning framework that provably removes only the additional (marginal) information contributed by the data to be unlearned, while preserving the information supported by the data to be retained. By penalizing marginal information, our method yields an explicit upper bound on the unlearn dataset's residual influence in the trained models, providing provable undetectability. Extensive experiments confirm that our approach outperforms current state-of-the-art unlearning methods, delivering reliable forgetting and better preserved general model performance across diverse benchmarks. This advancement represents an important step toward making AI systems more controllable and compliant with privacy and copyright regulations without compromising their effectiveness.", "AI": {"tldr": "Forgetting-MarI\u662f\u4e00\u4e2aLLM\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u60e9\u7f5a\u8fb9\u9645\u4fe1\u606f\u6765\u9009\u62e9\u6027\u79fb\u9664\u5f85\u9057\u5fd8\u6570\u636e\u5bf9\u6a21\u578b\u7684\u989d\u5916\u8d21\u732e\uff0c\u540c\u65f6\u4fdd\u7559\u5176\u4ed6\u6570\u636e\u652f\u6301\u7684\u4fe1\u606f\uff0c\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u4e0d\u53ef\u68c0\u6d4b\u6027\u3002", "motivation": "\u968f\u7740AI\u6a21\u578b\u5728\u4e0d\u65ad\u6269\u5927\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u9700\u8981\u4ece\u8bad\u7ec3\u6a21\u578b\u4e2d\u79fb\u9664\u7279\u5b9a\u6570\u636e\u5f71\u54cd\u4ee5\u6ee1\u8db3\u9690\u79c1\u4fdd\u62a4\u548c\u76d1\u7ba1\u5408\u89c4\u8981\u6c42\u3002\u9057\u5fd8\u65b9\u6cd5\u53ef\u4ee5\u5728\u4e0d\u4ece\u5934\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u9009\u62e9\u6027\u79fb\u9664\u53c2\u6570\u77e5\u8bc6\uff0c\u8fd9\u5bf9\u8d44\u6e90\u5bc6\u96c6\u578b\u6a21\u578b\u5982LLM\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u5f15\u5165Forgetting-MarI\u6846\u67b6\uff0c\u901a\u8fc7\u60e9\u7f5a\u8fb9\u9645\u4fe1\u606f\u6765\u4ec5\u79fb\u9664\u5f85\u9057\u5fd8\u6570\u636e\u8d21\u732e\u7684\u989d\u5916\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u7559\u5f85\u4fdd\u7559\u6570\u636e\u652f\u6301\u7684\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5bf9\u672a\u5b66\u4e60\u6570\u636e\u96c6\u5728\u8bad\u7ec3\u6a21\u578b\u4e2d\u5269\u4f59\u5f71\u54cd\u7684\u660e\u786e\u4e0a\u754c\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u5b9e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u9057\u5fd8\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u9057\u5fd8\u6548\u679c\uff0c\u5e76\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u4e86\u66f4\u597d\u7684\u901a\u7528\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u8fd9\u4e00\u8fdb\u5c55\u4ee3\u8868\u4e86\u5728\u4f7fAI\u7cfb\u7edf\u66f4\u53ef\u63a7\u3001\u66f4\u7b26\u5408\u9690\u79c1\u548c\u7248\u6743\u6cd5\u89c4\u7684\u540c\u65f6\u4e0d\u635f\u5bb3\u5176\u6709\u6548\u6027\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2511.12274", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12274", "abs": "https://arxiv.org/abs/2511.12274", "authors": ["Martin Monperrus"], "title": "Software Supply Chain Security of Web3", "comment": null, "summary": "Web3 applications, built on blockchain technology, manage billions of dollars in digital assets through decentralized applications (dApps) and smart contracts. These systems rely on complex, software supply chains that introduce significant security vulnerabilities. This paper examines the software supply chain security challenges unique to the Web3 ecosystem, where traditional Web2 software supply chain problems intersect with the immutable and high-stakes nature of blockchain technology. We analyze the threat landscape and propose mitigation strategies to strengthen the security posture of Web3 systems.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86Web3\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u6311\u6218\uff0c\u63a2\u8ba8\u4e86\u4f20\u7edfWeb2\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u95ee\u9898\u4e0e\u533a\u5757\u94fe\u6280\u672f\u4e0d\u53ef\u53d8\u6027\u548c\u9ad8\u98ce\u9669\u7279\u6027\u76f8\u7ed3\u5408\u5e26\u6765\u7684\u72ec\u7279\u5b89\u5168\u5a01\u80c1\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "Web3\u5e94\u7528\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u5e94\u7528\u548c\u667a\u80fd\u5408\u7ea6\u7ba1\u7406\u6570\u5341\u4ebf\u7f8e\u5143\u7684\u6570\u5b57\u8d44\u4ea7\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u4f9d\u8d56\u590d\u6742\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\uff0c\u5f15\u5165\u4e86\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\u3002\u9700\u8981\u7814\u7a76Web3\u751f\u6001\u7cfb\u7edf\u7279\u6709\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u6311\u6218\u3002", "method": "\u5206\u6790Web3\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5a01\u80c1\u6001\u52bf\uff0c\u7814\u7a76\u4f20\u7edfWeb2\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u95ee\u9898\u4e0e\u533a\u5757\u94fe\u6280\u672f\u7279\u6027\u7684\u4ea4\u53c9\u5f71\u54cd\uff0c\u63d0\u51fa\u76f8\u5e94\u7684\u5b89\u5168\u7f13\u89e3\u7b56\u7565\u3002", "result": "\u8bc6\u522b\u4e86Web3\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u7279\u6709\u7684\u5b89\u5168\u6311\u6218\uff0c\u5305\u62ec\u4f20\u7edf\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u6f0f\u6d1e\u4e0e\u533a\u5757\u94fe\u4e0d\u53ef\u53d8\u6027\u3001\u9ad8\u4ef7\u503c\u8d44\u4ea7\u7ba1\u7406\u7684\u7ed3\u5408\u5e26\u6765\u7684\u98ce\u9669\u653e\u5927\u6548\u5e94\u3002", "conclusion": "\u9700\u8981\u91c7\u53d6\u4e13\u95e8\u7684\u5b89\u5168\u63aa\u65bd\u6765\u52a0\u5f3aWeb3\u7cfb\u7edf\u7684\u5b89\u5168\u6001\u52bf\uff0c\u5e94\u5bf9\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u4e2d\u7684\u72ec\u7279\u5b89\u5168\u5a01\u80c1\uff0c\u4fdd\u62a4\u6570\u5341\u4ebf\u7f8e\u5143\u7684\u6570\u5b57\u8d44\u4ea7\u5b89\u5168\u3002"}}
{"id": "2511.13318", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.13318", "abs": "https://arxiv.org/abs/2511.13318", "authors": ["Peihao Li"], "title": "LinkXplore: A Framework for Affordable High-Quality Blockchain Data", "comment": null, "summary": "Blockchain technologies are rapidly transforming both academia and industry. However, large-scale blockchain data collection remains prohibitively expensive, as many RPC providers only offer enhanced APIs with high pricing tiers that are unsuitable for budget-constrained research or industrial-scale applications, which has significantly slowed down academic studies and product development. Moreover, there is a clear lack of a systematic framework that allows flexible integration of new modules for analyzing on-chain data.\n  To address these challenges, we introduce LinkXplore, the first open framework for collecting and managing on-chain data. LinkXplore enables users to bypass costly blockchain data providers by directly analyzing raw data from RPC queries or streams, thereby offering high-quality blockchain data at a fraction of the cost. Through a simple API and backend processing logic, any type of chain data can be integrated into the framework. This makes it a practical alternative for both researchers and developers with limited budgets. Code and dataset used in this project are publicly available at https://github.com/Linkis-Project/LinkXplore", "AI": {"tldr": "LinkXplore\u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u7528\u4e8e\u6536\u96c6\u548c\u7ba1\u7406\u94fe\u4e0a\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u533a\u5757\u94fe\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u548c\u7f3a\u4e4f\u7cfb\u7edf\u5316\u5206\u6790\u6846\u67b6\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u89c4\u6a21\u533a\u5757\u94fe\u6570\u636e\u6536\u96c6\u6210\u672c\u8fc7\u9ad8\uff0cRPC\u63d0\u4f9b\u5546\u5b9a\u4ef7\u6602\u8d35\uff0c\u963b\u788d\u4e86\u5b66\u672f\u7814\u7a76\u548c\u4ea7\u54c1\u5f00\u53d1\uff1b\u540c\u65f6\u7f3a\u4e4f\u7075\u6d3b\u96c6\u6210\u65b0\u6a21\u5757\u7684\u7cfb\u7edf\u5316\u5206\u6790\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u76f4\u63a5\u5206\u6790RPC\u67e5\u8be2\u6216\u6d41\u6570\u636e\u7684\u539f\u59cb\u6570\u636e\uff0c\u7ed5\u8fc7\u6602\u8d35\u7684\u533a\u5757\u94fe\u6570\u636e\u63d0\u4f9b\u5546\uff1b\u63d0\u4f9b\u7b80\u5355API\u548c\u540e\u7aef\u5904\u7406\u903b\u8f91\uff0c\u652f\u6301\u96c6\u6210\u4efb\u4f55\u7c7b\u578b\u7684\u94fe\u6570\u636e\u3002", "result": "\u4ee5\u4f4e\u6210\u672c\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u533a\u5757\u94fe\u6570\u636e\uff0c\u4e3a\u9884\u7b97\u6709\u9650\u7684\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u8005\u63d0\u4f9b\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "LinkXplore\u662f\u9996\u4e2a\u7528\u4e8e\u6536\u96c6\u548c\u7ba1\u7406\u94fe\u4e0a\u6570\u636e\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u533a\u5757\u94fe\u6570\u636e\u83b7\u53d6\u6210\u672c\uff0c\u4fc3\u8fdb\u4e86\u5b66\u672f\u7814\u7a76\u548c\u4ea7\u54c1\u5f00\u53d1\u3002"}}
{"id": "2511.12295", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.12295", "abs": "https://arxiv.org/abs/2511.12295", "authors": ["Hasini Jayathilaka"], "title": "Privacy-Preserving Prompt Injection Detection for LLMs Using Federated Learning and Embedding-Based NLP Classification", "comment": null, "summary": "Prompt injection attacks are an emerging threat to large language models (LLMs), enabling malicious users to manipulate outputs through carefully designed inputs. Existing detection approaches often require centralizing prompt data, creating significant privacy risks. This paper proposes a privacy-preserving prompt injection detection framework based on federated learning and embedding-based classification. A curated dataset of benign and adversarial prompts was encoded with sentence embedding and used to train both centralized and federated logistic regression models. The federated approach preserved privacy by sharing only model parameters across clients, while achieving detection performance comparable to centralized training. Results demonstrate that effective prompt injection detection is feasible without exposing raw data, making this one of the first explorations of federated security for LLMs. Although the dataset is limited in scale, the findings establish a strong proof-of-concept and highlight new directions for building secure and privacy-aware LLM systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u548c\u5d4c\u5165\u5206\u7c7b\u7684\u9690\u79c1\u4fdd\u62a4\u63d0\u793a\u6ce8\u5165\u68c0\u6d4b\u6846\u67b6\uff0c\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u4e0e\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u76f8\u5f53\u7684\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u662fLLM\u7684\u65b0\u5174\u5a01\u80c1\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u9700\u8981\u96c6\u4e2d\u5316\u63d0\u793a\u6570\u636e\uff0c\u5b58\u5728\u4e25\u91cd\u9690\u79c1\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u53e5\u5b50\u5d4c\u5165\u5bf9\u826f\u6027\u63d0\u793a\u548c\u5bf9\u6297\u6027\u63d0\u793a\u6570\u636e\u96c6\u8fdb\u884c\u7f16\u7801\uff0c\u8bad\u7ec3\u96c6\u4e2d\u5f0f\u548c\u8054\u90a6\u903b\u8f91\u56de\u5f52\u6a21\u578b\uff0c\u8054\u90a6\u65b9\u6cd5\u4ec5\u5171\u4eab\u6a21\u578b\u53c2\u6570\u3002", "result": "\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\uff0c\u68c0\u6d4b\u6027\u80fd\u4e0e\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u76f8\u5f53\uff0c\u8bc1\u660e\u4e86\u65e0\u9700\u66b4\u9732\u539f\u59cb\u6570\u636e\u7684\u6709\u6548\u68c0\u6d4b\u53ef\u884c\u6027\u3002", "conclusion": "\u867d\u7136\u6570\u636e\u96c6\u89c4\u6a21\u6709\u9650\uff0c\u4f46\u7814\u7a76\u4e3a\u6784\u5efa\u5b89\u5168\u4e14\u9690\u79c1\u611f\u77e5\u7684LLM\u7cfb\u7edf\u5efa\u7acb\u4e86\u5f3a\u6709\u529b\u7684\u6982\u5ff5\u9a8c\u8bc1\uff0c\u5e76\u6307\u660e\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.13341", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13341", "abs": "https://arxiv.org/abs/2511.13341", "authors": ["Zihe Yan", "Kai Luo", "Haoyu Yang", "Yang Yu", "Zhuosheng Zhang", "Guancheng Li"], "title": "An LLM-based Quantitative Framework for Evaluating High-Stealthy Backdoor Risks in OSS Supply Chains", "comment": "7 figures, 4 tables, conference", "summary": "In modern software development workflows, the open-source software supply chain contributes significantly to efficient and convenient engineering practices. With increasing system complexity, using open-source software as third-party dependencies has become a common practice. However, the lack of maintenance for underlying dependencies and insufficient community auditing create challenges in ensuring source code security and the legitimacy of repository maintainers, especially under high-stealthy backdoor attacks exemplified by the XZ-Util incident. To address these problems, we propose a fine-grained project evaluation framework for backdoor risk assessment in open-source software. The framework models stealthy backdoor attacks from the viewpoint of the attacker and defines targeted metrics for each attack stage. In addition, to overcome the limitations of static analysis in assessing the reliability of repository maintenance activities such as irregular committer privilege escalation and limited participation in reviews, the framework uses large language models (LLMs) to conduct semantic evaluation of code repositories without relying on manually crafted patterns. The framework is evaluated on sixty six high-priority packages in the Debian ecosystem. The experimental results indicate that the current open-source software supply chain is exposed to various security risks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ec6\u7c92\u5ea6\u7684\u5f00\u6e90\u8f6f\u4ef6\u540e\u95e8\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4ece\u653b\u51fb\u8005\u89c6\u89d2\u5efa\u6a21\u9690\u853d\u540e\u95e8\u653b\u51fb\uff0c\u5b9a\u4e49\u9488\u5bf9\u6027\u6307\u6807\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u4ed3\u5e93\u8bed\u4e49\u8bc4\u4f30\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5728\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u4f9d\u8d56\u7ef4\u62a4\u4e0d\u8db3\u548c\u793e\u533a\u5ba1\u8ba1\u4e0d\u8db3\u5bfc\u81f4\u6e90\u4ee3\u7801\u5b89\u5168\u548c\u4ed3\u5e93\u7ef4\u62a4\u8005\u5408\u6cd5\u6027\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728XZ-Util\u4e8b\u4ef6\u6240\u793a\u7684\u9ad8\u9690\u853d\u6027\u540e\u95e8\u653b\u51fb\u4e0b\u3002", "method": "\u4ece\u653b\u51fb\u8005\u89c6\u89d2\u5efa\u6a21\u9690\u853d\u540e\u95e8\u653b\u51fb\uff0c\u4e3a\u6bcf\u4e2a\u653b\u51fb\u9636\u6bb5\u5b9a\u4e49\u9488\u5bf9\u6027\u6307\u6807\uff1b\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u4ed3\u5e93\u8bed\u4e49\u8bc4\u4f30\uff0c\u514b\u670d\u9759\u6001\u5206\u6790\u5728\u8bc4\u4f30\u4ed3\u5e93\u7ef4\u62a4\u6d3b\u52a8\u53ef\u9760\u6027\u65b9\u9762\u7684\u9650\u5236\u3002", "result": "\u5728Debian\u751f\u6001\u7cfb\u7edf\u768466\u4e2a\u9ad8\u4f18\u5148\u7ea7\u8f6f\u4ef6\u5305\u4e0a\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5f53\u524d\u5f00\u6e90\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u9762\u4e34\u591a\u79cd\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u5f00\u6e90\u8f6f\u4ef6\u7684\u540e\u95e8\u98ce\u9669\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5f00\u6e90\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u7684\u5b89\u5168\u8106\u5f31\u6027\u3002"}}
{"id": "2511.11924", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11924", "abs": "https://arxiv.org/abs/2511.11924", "authors": ["Yongkang Huo", "Fulvio Forni", "Rodolphe Sepulchre"], "title": "A Neuromorphic Architecture for Scalable Event-Based Control", "comment": null, "summary": "This paper introduces the ``rebound Winner-Take-All (RWTA)\" motif as the basic element of a scalable neuromorphic control architecture. From the cellular level to the system level, the resulting architecture combines the reliability of discrete computation and the tunability of continuous regulation: it inherits the discrete computation capabilities of winner-take-all state machines and the continuous tuning capabilities of excitable biophysical circuits. The proposed event-based framework addresses continuous rhythmic generation and discrete decision-making in a unified physical modeling language. We illustrate the versatility, robustness, and modularity of the architecture through the nervous system design of a snake robot.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\"\u53cd\u5f39\u8d62\u5bb6\u901a\u5403\"\uff08RWTA\uff09\u57fa\u5143\u4f5c\u4e3a\u53ef\u6269\u5c55\u795e\u7ecf\u5f62\u6001\u63a7\u5236\u67b6\u6784\u7684\u57fa\u672c\u5143\u7d20\uff0c\u8be5\u67b6\u6784\u7ed3\u5408\u4e86\u79bb\u6563\u8ba1\u7b97\u7684\u53ef\u9760\u6027\u548c\u8fde\u7eed\u8c03\u8282\u7684\u53ef\u8c03\u6027\uff0c\u7edf\u4e00\u5904\u7406\u8fde\u7eed\u8282\u5f8b\u751f\u6210\u548c\u79bb\u6563\u51b3\u7b56\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u795e\u7ecf\u5f62\u6001\u63a7\u5236\u67b6\u6784\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u8fde\u7eed\u8282\u5f8b\u751f\u6210\u548c\u79bb\u6563\u51b3\u7b56\uff0c\u7ed3\u5408\u79bb\u6563\u8ba1\u7b97\u7684\u53ef\u9760\u6027\u548c\u8fde\u7eed\u8c03\u8282\u7684\u53ef\u8c03\u6027\u3002", "method": "\u5f15\u5165\u53cd\u5f39\u8d62\u5bb6\u901a\u5403\uff08RWTA\uff09\u57fa\u5143\u4f5c\u4e3a\u57fa\u672c\u6784\u5efa\u5757\uff0c\u4ece\u7ec6\u80de\u5c42\u9762\u5230\u7cfb\u7edf\u5c42\u9762\u6784\u5efa\u67b6\u6784\uff0c\u7ee7\u627f\u8d62\u5bb6\u901a\u5403\u72b6\u6001\u673a\u7684\u79bb\u6563\u8ba1\u7b97\u80fd\u529b\u548c\u53ef\u5174\u594b\u751f\u7269\u7269\u7406\u7535\u8def\u7684\u8fde\u7eed\u8c03\u8282\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u86c7\u5f62\u673a\u5668\u4eba\u795e\u7ecf\u7cfb\u7edf\u8bbe\u8ba1\u5c55\u793a\u4e86\u8be5\u67b6\u6784\u7684\u901a\u7528\u6027\u3001\u9c81\u68d2\u6027\u548c\u6a21\u5757\u5316\u7279\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u4e8b\u4ef6\u7684\u6846\u67b6\u4e3a\u8fde\u7eed\u8282\u5f8b\u751f\u6210\u548c\u79bb\u6563\u51b3\u7b56\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7269\u7406\u5efa\u6a21\u8bed\u8a00\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u4e14\u53ef\u8c03\u8282\u7684\u795e\u7ecf\u5f62\u6001\u63a7\u5236\u67b6\u6784\u3002"}}
{"id": "2511.13357", "categories": ["cs.SE", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.13357", "abs": "https://arxiv.org/abs/2511.13357", "authors": ["Dmitry Moskalev"], "title": "FLOWER: Flow-Oriented Entity-Relationship Tool", "comment": "12 pages, 8 figures", "summary": "Exploring relationships across data sources is a crucial optimization for entities recognition. Since databases can store big amount of information with synthetic and organic data, serving all quantity of objects correctly is an important task to deal with. However, the decision of how to construct entity relationship model is associated with human factor. In this paper, we present flow-oriented entity-relationship tool. This is first and unique end-to-end solution that eliminates routine and resource-intensive problems of processing, creating and visualizing both of explicit and implicit dependencies for prominent SQL dialects on-the-fly. Once launched, FLOWER automatically detects built-in constraints and starting to create own correct and necessary one using dynamic sampling and robust data analysis techniques. This approach applies to improve entity-relationship model and data storytelling to better understand the foundation of data and get unseen insights from DB sources using SQL or natural language. Evaluated on state-of-the-art STATS benchmark, experiments show that FLOWER is superior to reservoir sampling by 2.4x for distribution representation and 2.6x for constraint learning with 2.15x acceleration. For data storytelling, our tool archives 1.19x for accuracy enhance with 1.86x context decrease compare to LLM. Presented tool is also support 23 languages and compatible with both of CPU and GPU. Those results show that FLOWER can manage with real-world data a way better to ensure with quality, scalability and applicability for different use-cases.", "AI": {"tldr": "FLOWER\u662f\u4e00\u4e2a\u9762\u5411\u6d41\u7a0b\u7684\u5b9e\u4f53\u5173\u7cfb\u5de5\u5177\uff0c\u9996\u4e2a\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u81ea\u52a8\u5904\u7406\u3001\u521b\u5efa\u548c\u53ef\u89c6\u5316SQL\u6570\u636e\u5e93\u4e2d\u7684\u663e\u6027\u548c\u9690\u6027\u4f9d\u8d56\u5173\u7cfb\uff0c\u901a\u8fc7\u52a8\u6001\u91c7\u6837\u548c\u9c81\u68d2\u6570\u636e\u5206\u6790\u6280\u672f\u6539\u8fdb\u5b9e\u4f53\u5173\u7cfb\u6a21\u578b\u548c\u6570\u636e\u53d9\u4e8b\u3002", "motivation": "\u63a2\u7d22\u6570\u636e\u6e90\u95f4\u5173\u7cfb\u5bf9\u5b9e\u4f53\u8bc6\u522b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6784\u5efa\u5b9e\u4f53\u5173\u7cfb\u6a21\u578b\u53d7\u4eba\u4e3a\u56e0\u7d20\u5f71\u54cd\u3002\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u5904\u7406\u5927\u91cf\u6570\u636e\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u63d0\u9ad8\u6570\u636e\u7406\u89e3\u548c\u6d1e\u5bdf\u529b\u3002", "method": "\u63d0\u51faFLOWER\u5de5\u5177\uff0c\u81ea\u52a8\u68c0\u6d4b\u5185\u7f6e\u7ea6\u675f\u5e76\u521b\u5efa\u5fc5\u8981\u7684\u6b63\u786e\u7ea6\u675f\uff0c\u4f7f\u7528\u52a8\u6001\u91c7\u6837\u548c\u9c81\u68d2\u6570\u636e\u5206\u6790\u6280\u672f\uff0c\u652f\u6301SQL\u548c\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\uff0c\u517c\u5bb9CPU\u548cGPU\u3002", "result": "\u5728STATS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFLOWER\u5728\u5206\u5e03\u8868\u793a\u4e0a\u6bd4\u50a8\u5c42\u91c7\u6837\u5feb2.4\u500d\uff0c\u7ea6\u675f\u5b66\u4e60\u5feb2.6\u500d\uff0c\u52a0\u901f2.15\u500d\u3002\u6570\u636e\u53d9\u4e8b\u51c6\u786e\u6027\u63d0\u9ad81.19\u500d\uff0c\u4e0a\u4e0b\u6587\u51cf\u5c111.86\u500d\u3002\u652f\u630123\u79cd\u8bed\u8a00\u3002", "conclusion": "FLOWER\u80fd\u66f4\u597d\u5730\u5904\u7406\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff0c\u786e\u4fdd\u8d28\u91cf\u3001\u53ef\u6269\u5c55\u6027\u548c\u4e0d\u540c\u7528\u4f8b\u7684\u9002\u7528\u6027\uff0c\u662f\u7ba1\u7406\u6570\u636e\u5e93\u4f9d\u8d56\u5173\u7cfb\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.12377", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.12377", "abs": "https://arxiv.org/abs/2511.12377", "authors": ["Samuel Wairimu", "Leonardo Horn Iwaya"], "title": "On the Security and Privacy of AI-based Mobile Health Chatbots", "comment": "19 pages, submitted to NordSec 2025 conference", "summary": "The rise of Artificial Intelligence (AI) has impacted the development of mobile health (mHealth) apps, most notably with the advent of AI-based chatbots used as ubiquitous ``companions'' for various services, from fitness to mental health assistants. While these mHealth chatbots offer clear benefits, such as personalized health information and predictive diagnoses, they also raise significant concerns regarding security and privacy. This study empirically assesses 16 AI-based mHealth chatbots identified from the Google Play Store. The empirical assessment follows a three-phase approach (manual inspection, static code analysis, and dynamic analysis) to evaluate technical robustness and how design and implementation choices impact end users. Our findings revealed security vulnerabilities (e.g., enabling Remote WebView debugging), privacy issues, and non-compliance with Google Play policies (e.g., failure to provide publicly accessible privacy policies). Based on our findings, we offer several recommendations to enhance the security and privacy of mHealth chatbots. These recommendations focus on improving data handling processes, disclosure, and user security. Therefore, this work also seeks to support mHealth developers and security/privacy engineers in designing more transparent, privacy-friendly, and secure mHealth chatbots.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9Google Play\u5546\u5e97\u4e2d\u768416\u4e2aAI\u79fb\u52a8\u5065\u5eb7\u804a\u5929\u673a\u5668\u4eba\u8fdb\u884c\u4e86\u5b89\u5168\u6027\u548c\u9690\u79c1\u6027\u8bc4\u4f30\uff0c\u53d1\u73b0\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u3001\u9690\u79c1\u95ee\u9898\u4ee5\u53ca\u8fdd\u53cdGoogle Play\u653f\u7b56\u7684\u884c\u4e3a\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u968f\u7740AI\u5728\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0cAI\u804a\u5929\u673a\u5668\u4eba\u4f5c\u4e3a\u5065\u5eb7\u4f34\u4fa3\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5b83\u4eec\u5f15\u53d1\u4e86\u4e25\u91cd\u7684\u5b89\u5168\u548c\u9690\u79c1\u62c5\u5fe7\uff0c\u9700\u8981\u5bf9\u8fd9\u4e9b\u5e94\u7528\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a\u624b\u52a8\u68c0\u67e5\u3001\u9759\u6001\u4ee3\u7801\u5206\u6790\u548c\u52a8\u6001\u5206\u6790\uff0c\u8bc4\u4f30\u6280\u672f\u7a33\u5065\u6027\u4ee5\u53ca\u8bbe\u8ba1\u548c\u5b9e\u73b0\u9009\u62e9\u5bf9\u6700\u7ec8\u7528\u6237\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff08\u5982\u542f\u7528\u8fdc\u7a0bWebView\u8c03\u8bd5\uff09\u3001\u9690\u79c1\u95ee\u9898\u4ee5\u53ca\u4e0d\u7b26\u5408Google Play\u653f\u7b56\uff08\u5982\u672a\u63d0\u4f9b\u516c\u5f00\u53ef\u8bbf\u95ee\u7684\u9690\u79c1\u653f\u7b56\uff09\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6539\u8fdb\u79fb\u52a8\u5065\u5eb7\u804a\u5929\u673a\u5668\u4eba\u5b89\u5168\u6027\u548c\u9690\u79c1\u6027\u7684\u5efa\u8bae\uff0c\u65e8\u5728\u652f\u6301\u5f00\u53d1\u8005\u8bbe\u8ba1\u66f4\u900f\u660e\u3001\u9690\u79c1\u53cb\u597d\u4e14\u5b89\u5168\u7684\u79fb\u52a8\u5065\u5eb7\u804a\u5929\u673a\u5668\u4eba\u3002"}}
{"id": "2511.13611", "categories": ["cs.SE", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.13611", "abs": "https://arxiv.org/abs/2511.13611", "authors": ["Torec T. Luik", "Joost de Folter", "Rodrigo Rosas-Bertolini", "Eric A. J. Reits", "Ron A. Hoebe", "Przemek M. Krawczyk"], "title": "BIOMERO 2.0: end-to-end FAIR infrastructure for bioimaging data import, analysis, and provenance", "comment": "16 pages, 2 figures, 25 pages supplemental information; for software, see https://github.com/Cellular-Imaging-Amsterdam-UMC/NL-BIOMERO", "summary": "We present BIOMERO 2.0, a major evolution of the BIOMERO framework that transforms OMERO into a FAIR-compliant (findable, accessible, interoperable, and reusable), provenance-aware bioimaging platform. BIOMERO 2.0 integrates data import, preprocessing, analysis, and workflow monitoring through an OMERO.web plugin and containerized components. The importer subsystem facilitates in-place import using containerized preprocessing and metadata enrichment via forms, while the analyzer subsystem coordinates and tracks containerized analyses on high-performance computing systems via the BIOMERO Python library. All imports and analyses are recorded with parameters, versions, and results, ensuring real-time provenance accessible through integrated dashboards. This dual approach places OMERO at the heart of the bioimaging analysis process: the importer ensures provenance from image acquisition through preprocessing and import into OMERO, while the analyzer records it for downstream processing. These integrated layers enhance OMEROs FAIRification, supporting traceable, reusable workflows for image analysis that bridge the gap between data import, analysis, and sharing.", "AI": {"tldr": "BIOMERO 2.0\u662f\u4e00\u4e2a\u91cd\u5927\u6f14\u8fdb\u7684OMERO\u6846\u67b6\uff0c\u5c06OMERO\u8f6c\u53d8\u4e3a\u7b26\u5408FAIR\u539f\u5219\uff08\u53ef\u67e5\u627e\u3001\u53ef\u8bbf\u95ee\u3001\u53ef\u4e92\u64cd\u4f5c\u3001\u53ef\u91cd\u7528\uff09\u4e14\u5177\u6709\u6eaf\u6e90\u610f\u8bc6\u7684\u751f\u7269\u6210\u50cf\u5e73\u53f0\u3002", "motivation": "\u89e3\u51b3\u751f\u7269\u6210\u50cf\u6570\u636e\u5728\u5bfc\u5165\u3001\u9884\u5904\u7406\u3001\u5206\u6790\u548c\u5171\u4eab\u8fc7\u7a0b\u4e2d\u7f3a\u4e4f\u5b8c\u6574\u6eaf\u6e90\u8bb0\u5f55\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6570\u636e\u7684FAIR\u5316\u7a0b\u5ea6\uff0c\u652f\u6301\u53ef\u8ffd\u8e2a\u548c\u53ef\u91cd\u7528\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "\u901a\u8fc7OMERO.web\u63d2\u4ef6\u548c\u5bb9\u5668\u5316\u7ec4\u4ef6\u96c6\u6210\u6570\u636e\u5bfc\u5165\u3001\u9884\u5904\u7406\u3001\u5206\u6790\u548c\u5de5\u4f5c\u6d41\u76d1\u63a7\u3002\u5bfc\u5165\u5b50\u7cfb\u7edf\u4f7f\u7528\u5bb9\u5668\u5316\u9884\u5904\u7406\u548c\u8868\u5355\u5143\u6570\u636e\u4e30\u5bcc\u5b9e\u73b0\u5c31\u5730\u5bfc\u5165\uff0c\u5206\u6790\u5b50\u7cfb\u7edf\u901a\u8fc7BIOMERO Python\u5e93\u534f\u8c03\u548c\u8ddf\u8e2a\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u4e0a\u7684\u5bb9\u5668\u5316\u5206\u6790\u3002", "result": "\u6240\u6709\u5bfc\u5165\u548c\u5206\u6790\u64cd\u4f5c\u90fd\u8bb0\u5f55\u53c2\u6570\u3001\u7248\u672c\u548c\u7ed3\u679c\uff0c\u786e\u4fdd\u901a\u8fc7\u96c6\u6210\u4eea\u8868\u677f\u5b9e\u65f6\u8bbf\u95ee\u6eaf\u6e90\u4fe1\u606f\u3002\u8fd9\u79cd\u53cc\u91cd\u65b9\u6cd5\u5c06OMERO\u7f6e\u4e8e\u751f\u7269\u6210\u50cf\u5206\u6790\u8fc7\u7a0b\u7684\u6838\u5fc3\u4f4d\u7f6e\u3002", "conclusion": "BIOMERO 2.0\u901a\u8fc7\u96c6\u6210\u5c42\u589e\u5f3a\u4e86OMERO\u7684FAIR\u5316\uff0c\u652f\u6301\u53ef\u8ffd\u8e2a\u3001\u53ef\u91cd\u7528\u7684\u56fe\u50cf\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5f25\u5408\u4e86\u6570\u636e\u5bfc\u5165\u3001\u5206\u6790\u548c\u5171\u4eab\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.12385", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12385", "abs": "https://arxiv.org/abs/2511.12385", "authors": ["Yikun Li", "Matteo Grella", "Daniel Nahmias", "Gal Engelberg", "Dan Klein", "Giancarlo Guizzardi", "Thijs van Ede", "Andrea Continella"], "title": "GenSIaC: Toward Security-Aware Infrastructure-as-Code Generation with Large Language Models", "comment": null, "summary": "In recent years, Infrastructure as Code (IaC) has emerged as a critical approach for managing and provisioning IT infrastructure through code and automation. IaC enables organizations to create scalable and consistent environments, effectively managing servers and development settings. However, the growing complexity of cloud infrastructures has led to an increased risk of misconfigurations and security vulnerabilities in IaC scripts. To address this problem, this paper investigates the potential of Large Language Models (LLMs) in generating security-aware IaC code, avoiding misconfigurations introduced by developers and administrators.\n  While LLMs have made significant progress in natural language processing and code generation, their ability to generate secure IaC scripts remains unclear. This paper addresses two major problems: 1) the lack of understanding of security weaknesses in IaC scripts generated by LLMs, and 2) the absence of techniques for enhancing security in generating IaC code with LLMs.\n  To assess the extent to which LLMs contain security knowledge, we first conduct a comprehensive evaluation of base LLMs in recognizing major IaC security weaknesses during the generation and inspection of IaC code. Then, we propose GenSIaC, an instruction fine-tuning dataset designed to improve LLMs' ability to recognize potential security weaknesses. Leveraging GenSIaC, we fine-tune LLMs and instruct models to generate security-aware IaC code. Our evaluation demonstrates that our models achieve substantially improved performance in recognizing and preventing IaC security misconfigurations, e.g., boosting the F1-score from 0.303 to 0.858. Additionally, we perform ablation studies and explore GenSIaC's generalizability to other LLMs and its cross-language capabilities.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u5b89\u5168\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u63d0\u51fa\u4e86GenSIaC\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u6765\u63d0\u5347LLMs\u8bc6\u522b\u548c\u9884\u9632IaC\u5b89\u5168\u914d\u7f6e\u9519\u8bef\u7684\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u4e91\u57fa\u7840\u8bbe\u65bd\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0cIaC\u811a\u672c\u4e2d\u7684\u9519\u8bef\u914d\u7f6e\u548c\u5b89\u5168\u6f0f\u6d1e\u98ce\u9669\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u63a2\u7d22LLMs\u5728\u751f\u6210\u5b89\u5168IaC\u4ee3\u7801\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u9996\u5148\u8bc4\u4f30\u57fa\u7840LLMs\u8bc6\u522bIaC\u5b89\u5168\u5f31\u70b9\u7684\u80fd\u529b\uff0c\u7136\u540e\u521b\u5efaGenSIaC\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5fae\u8c03LLMs\u6765\u751f\u6210\u5b89\u5168\u611f\u77e5\u7684IaC\u4ee3\u7801\u3002", "result": "\u7ecf\u8fc7\u5fae\u8c03\u7684\u6a21\u578b\u5728\u8bc6\u522b\u548c\u9884\u9632IaC\u5b89\u5168\u914d\u7f6e\u9519\u8bef\u65b9\u9762\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0cF1\u5206\u6570\u4ece0.303\u63d0\u9ad8\u52300.858\u3002", "conclusion": "GenSIaC\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86LLMs\u751f\u6210\u5b89\u5168IaC\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u6027\u548c\u8de8\u8bed\u8a00\u80fd\u529b\u3002"}}
{"id": "2511.11954", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11954", "abs": "https://arxiv.org/abs/2511.11954", "authors": ["Borchuluun Yadamsuren", "Steven Keith Platt", "Miguel Diaz"], "title": "LLM-Assisted Formalization Enables Deterministic Detection of Statutory Inconsistency in the Internal Revenue Code", "comment": "29 pages, 3 appendices with Prolog code and full codebase available at: https://github.com/borchuluun/section121-inconsistency-detection", "summary": "This study introduces a hybrid neuro-symbolic framework that achieves deterministic detection of statutory inconsistency in complex law. We use the U.S. Internal Revenue Code (IRC) as a case study because its complexity makes it a fertile domain for identifying conflicts. Our research offers a solution for detecting inconsistent provisions by combining Large Language Models (LLMs) with symbolic logic.\n  LLM-based methods can support compliance, fairness, and statutory drafting, yet tax-specific applications remain sparse. A key challenge is that such models struggle with hierarchical processing and deep structured reasoning, especially over long text.\n  This research addresses these gaps through experiments using GPT-4o, GPT-5, and Prolog. GPT-4o was first used to translate Section 121 into Prolog rules and refine them in SWISH. These rules were then incorporated into prompts to test whether Prolog-augmented prompting improved GPT-4o's inconsistency detection. GPT-4o, whether prompted with natural language alone or with Prolog augmentation, detected the inconsistency in only one of three strategies (33 percent accuracy), but its reasoning quality differed: natural-language prompting achieved 100 percent rule coverage, while Prolog-augmented prompting achieved 66 percent, indicating more incomplete statutory analysis.\n  In contrast to probabilistic prompting, the hybrid Prolog model produced deterministic and reproducible results. Guided by GPT-5 for refinement, the model formalized the IRC section's competing interpretations and successfully detected an inconsistency zone. Validation tests confirm that the Prolog implementation is accurate, internally consistent, deterministic, and capable of autonomously identifying inconsistencies. These findings show that LLM-assisted formalization, anchored in symbolic logic, enables transparent and reliable statutory inconsistency detection.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7528\u4e8e\u786e\u5b9a\u6027\u68c0\u6d4b\u590d\u6742\u6cd5\u5f8b\u4e2d\u7684\u6cd5\u89c4\u4e0d\u4e00\u81f4\u6027\u3002\u4ee5\u7f8e\u56fd\u56fd\u5185\u7a0e\u6536\u6cd5\u5178\u4e3a\u6848\u4f8b\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7b26\u53f7\u903b\u8f91\uff0c\u5b9e\u73b0\u4e86\u900f\u660e\u53ef\u9760\u7684\u6cd5\u89c4\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u5728\u5c42\u6b21\u5316\u5904\u7406\u548c\u6df1\u5ea6\u7ed3\u6784\u5316\u63a8\u7406\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u3002\u7a0e\u6536\u9886\u57df\u7684\u7279\u5b9a\u5e94\u7528\u4ecd\u7136\u7a00\u7f3a\uff0c\u9700\u8981\u89e3\u51b3\u6cd5\u89c4\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528GPT-4o\u5c06\u7a0e\u6cd5\u6761\u6b3e\u7ffb\u8bd1\u4e3aProlog\u89c4\u5219\uff0c\u5728SWISH\u4e2d\u7cbe\u70bc\uff0c\u7136\u540e\u7ed3\u5408Prolog\u589e\u5f3a\u63d0\u793a\u6765\u6d4b\u8bd5\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\u6548\u679c\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u6df7\u5408Prolog\u6a21\u578b\uff0c\u7531GPT-5\u6307\u5bfc\u7cbe\u70bc\u3002", "result": "GPT-4o\u5355\u72ec\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u6216Prolog\u589e\u5f3a\u63d0\u793a\u65f6\uff0c\u5728\u4e09\u79cd\u7b56\u7565\u4e2d\u4ec5\u68c0\u6d4b\u5230\u4e00\u79cd\u4e0d\u4e00\u81f4\u6027\uff0833%\u51c6\u786e\u7387\uff09\u3002\u800c\u6df7\u5408Prolog\u6a21\u578b\u4ea7\u751f\u4e86\u786e\u5b9a\u6027\u3001\u53ef\u91cd\u73b0\u7684\u7ed3\u679c\uff0c\u6210\u529f\u68c0\u6d4b\u5230\u4e0d\u4e00\u81f4\u533a\u57df\u3002", "conclusion": "\u57fa\u4e8e\u7b26\u53f7\u903b\u8f91\u7684LLM\u8f85\u52a9\u5f62\u5f0f\u5316\u80fd\u591f\u5b9e\u73b0\u900f\u660e\u53ef\u9760\u7684\u6cd5\u89c4\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\uff0c\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u5728\u590d\u6742\u6cd5\u5f8b\u5206\u6790\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2511.11990", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11990", "abs": "https://arxiv.org/abs/2511.11990", "authors": ["Shaoqi Wang", "Lu Yu", "Chunjie Yang"], "title": "Improving Autoformalization Using Direct Dependency Retrieval", "comment": null, "summary": "The convergence of deep learning and formal mathematics has spurred research in formal verification. Statement autoformalization, a crucial first step in this process, aims to translate informal descriptions into machine-verifiable representations but remains a significant challenge. The core difficulty lies in the fact that existing methods often suffer from a lack of contextual awareness, leading to hallucination of formal definitions and theorems. Furthermore, current retrieval-augmented approaches exhibit poor precision and recall for formal library dependency retrieval, and lack the scalability to effectively leverage ever-growing public datasets. To bridge this gap, we propose a novel retrieval-augmented framework based on DDR (\\textit{Direct Dependency Retrieval}) for statement autoformalization. Our DDR method directly generates candidate library dependencies from natural language mathematical descriptions and subsequently verifies their existence within the formal library via an efficient suffix array check. Leveraging this efficient search mechanism, we constructed a dependency retrieval dataset of over 500,000 samples and fine-tuned a high-precision DDR model. Experimental results demonstrate that our DDR model significantly outperforms SOTA methods in both retrieval precision and recall. Consequently, an autoformalizer equipped with DDR shows consistent performance advantages in both single-attempt accuracy and multi-attempt stability compared to models using traditional selection-based RAG methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f4\u63a5\u4f9d\u8d56\u68c0\u7d22(DDR)\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u6570\u5b66\u9648\u8ff0\u81ea\u52a8\u5f62\u5f0f\u5316\u4e2d\u7684\u5e93\u4f9d\u8d56\u68c0\u7d22\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\uff0c\u5bb9\u6613\u4ea7\u751f\u5f62\u5f0f\u5316\u5b9a\u4e49\u548c\u5b9a\u7406\u7684\u5e7b\u89c9\uff0c\u4e14\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u5728\u5f62\u5f0f\u5316\u5e93\u4f9d\u8d56\u68c0\u7d22\u65b9\u9762\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u8f83\u5dee\uff0c\u65e0\u6cd5\u6709\u6548\u5229\u7528\u4e0d\u65ad\u589e\u957f\u7684\u516c\u5171\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51faDDR\u65b9\u6cd5\uff0c\u76f4\u63a5\u4ece\u81ea\u7136\u8bed\u8a00\u6570\u5b66\u63cf\u8ff0\u751f\u6210\u5019\u9009\u5e93\u4f9d\u8d56\uff0c\u7136\u540e\u901a\u8fc7\u9ad8\u6548\u7684\u540e\u7f00\u6570\u7ec4\u68c0\u67e5\u9a8c\u8bc1\u5176\u5728\u5f62\u5f0f\u5316\u5e93\u4e2d\u7684\u5b58\u5728\u6027\uff0c\u5e76\u6784\u5efa\u4e86\u8d85\u8fc750\u4e07\u4e2a\u6837\u672c\u7684\u4f9d\u8d56\u68c0\u7d22\u6570\u636e\u96c6\u6765\u5fae\u8c03\u9ad8\u7cbe\u5ea6DDR\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDDR\u6a21\u578b\u5728\u68c0\u7d22\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u914d\u5907DDR\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u5668\u5728\u5355\u6b21\u5c1d\u8bd5\u51c6\u786e\u7387\u548c\u591a\u6b21\u5c1d\u8bd5\u7a33\u5b9a\u6027\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u6301\u7eed\u7684\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "DDR\u6846\u67b6\u4e3a\u6570\u5b66\u9648\u8ff0\u81ea\u52a8\u5f62\u5f0f\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5e93\u4f9d\u8d56\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.12448", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12448", "abs": "https://arxiv.org/abs/2511.12448", "authors": ["Aidan Wen", "Norah A. Alzahrani", "Jingzhi Jiang", "Andrew Joe", "Karen Shieh", "Andy Zhang", "Basel Alomair", "David Wagner"], "title": "SeedAIchemy: LLM-Driven Seed Corpus Generation for Fuzzing", "comment": null, "summary": "We introduce SeedAIchemy, an automated LLM-driven corpus generation tool that makes it easier for developers to implement fuzzing effectively. SeedAIchemy consists of five modules which implement different approaches at collecting publicly available files from the internet. Four of the five modules use large language model (LLM) workflows to construct search terms designed to maximize corpus quality. Corpora generated by SeedAIchemy perform significantly better than a naive corpus and similarly to a manually-curated corpus on a diverse range of target programs and libraries.", "AI": {"tldr": "SeedAIchemy\u662f\u4e00\u4e2a\u81ea\u52a8\u5316LLM\u9a71\u52a8\u7684\u8bed\u6599\u5e93\u751f\u6210\u5de5\u5177\uff0c\u901a\u8fc7\u4e94\u4e2a\u6a21\u5757\u4ece\u4e92\u8054\u7f51\u6536\u96c6\u516c\u5f00\u6587\u4ef6\uff0c\u5176\u4e2d\u56db\u4e2a\u6a21\u5757\u4f7f\u7528LLM\u5de5\u4f5c\u6d41\u6784\u5efa\u641c\u7d22\u8bcd\u4ee5\u6700\u5927\u5316\u8bed\u6599\u5e93\u8d28\u91cf\u3002", "motivation": "\u4f7f\u5f00\u53d1\u4eba\u5458\u66f4\u5bb9\u6613\u6709\u6548\u5b9e\u65bd\u6a21\u7cca\u6d4b\u8bd5\uff0c\u89e3\u51b3\u624b\u52a8\u6784\u5efa\u9ad8\u8d28\u91cf\u8bed\u6599\u5e93\u7684\u56f0\u96be\u3002", "method": "\u4f7f\u7528\u4e94\u4e2a\u6a21\u5757\u4ece\u4e92\u8054\u7f51\u6536\u96c6\u516c\u5f00\u6587\u4ef6\uff0c\u5176\u4e2d\u56db\u4e2a\u6a21\u5757\u91c7\u7528LLM\u5de5\u4f5c\u6d41\u6765\u6784\u5efa\u4f18\u5316\u7684\u641c\u7d22\u8bcd\u3002", "result": "SeedAIchemy\u751f\u6210\u7684\u8bed\u6599\u5e93\u5728\u591a\u6837\u5316\u7684\u76ee\u6807\u7a0b\u5e8f\u548c\u5e93\u4e0a\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u7b80\u5355\u8bed\u6599\u5e93\uff0c\u4e0e\u624b\u52a8\u6574\u7406\u7684\u8bed\u6599\u5e93\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "SeedAIchemy\u80fd\u591f\u81ea\u52a8\u5316\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6a21\u7cca\u6d4b\u8bd5\u8bed\u6599\u5e93\uff0c\u6027\u80fd\u63a5\u8fd1\u624b\u52a8\u6574\u7406\u7684\u6c34\u5e73\u3002"}}
{"id": "2511.12003", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12003", "abs": "https://arxiv.org/abs/2511.12003", "authors": ["Shuochen Liu", "Pengfei Luo", "Chao Zhang", "Yuhao Chen", "Haotian Zhang", "Qi Liu", "Xin Kou", "Tong Xu", "Enhong Chen"], "title": "Look As You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning", "comment": "Poster of AAAI'2026", "summary": "Aiming to identify precise evidence sources from visual documents, visual evidence attribution for visual document retrieval-augmented generation (VD-RAG) ensures reliable and verifiable predictions from vision-language models (VLMs) in multimodal question answering. Most existing methods adopt end-to-end training to facilitate intuitive answer verification. However, they lack fine-grained supervision and progressive traceability throughout the reasoning process. In this paper, we introduce the Chain-of-Evidence (CoE) paradigm for VD-RAG. CoE unifies Chain-of-Thought (CoT) reasoning and visual evidence attribution by grounding reference elements in reasoning steps to specific regions with bounding boxes and page indexes. To enable VLMs to generate such evidence-grounded reasoning, we propose Look As You Think (LAT), a reinforcement learning framework that trains models to produce verifiable reasoning paths with consistent attribution. During training, LAT evaluates the attribution consistency of each evidence region and provides rewards only when the CoE trajectory yields correct answers, encouraging process-level self-verification. Experiments on vanilla Qwen2.5-VL-7B-Instruct with Paper- and Wiki-VISA benchmarks show that LAT consistently improves the vanilla model in both single- and multi-image settings, yielding average gains of 8.23% in soft exact match (EM) and 47.0% in IoU@0.5. Meanwhile, LAT not only outperforms the supervised fine-tuning baseline, which is trained to directly produce answers with attribution, but also exhibits stronger generalization across domains.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Chain-of-Evidence\uff08CoE\uff09\u8303\u5f0f\uff0c\u5c06\u601d\u7ef4\u94fe\u63a8\u7406\u4e0e\u89c6\u89c9\u8bc1\u636e\u5f52\u56e0\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u8fb9\u754c\u6846\u548c\u9875\u9762\u7d22\u5f15\u5c06\u63a8\u7406\u6b65\u9aa4\u4e2d\u7684\u53c2\u8003\u5143\u7d20\u5b9a\u4f4d\u5230\u5177\u4f53\u533a\u57df\u3002\u4f5c\u8005\u5f00\u53d1\u4e86Look As You Think\uff08LAT\uff09\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8bad\u7ec3\u6a21\u578b\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u63a8\u7406\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u6587\u6863\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u76d1\u7763\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u6e10\u8fdb\u53ef\u8ffd\u6eaf\u6027\uff0c\u65e0\u6cd5\u786e\u4fdd\u53ef\u9760\u7684\u8bc1\u636e\u5f52\u56e0\u3002", "method": "\u63d0\u51faCoE\u8303\u5f0f\u7edf\u4e00\u601d\u7ef4\u94fe\u63a8\u7406\u548c\u89c6\u89c9\u8bc1\u636e\u5f52\u56e0\uff0c\u5f00\u53d1LAT\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8bc4\u4f30\u8bc1\u636e\u533a\u57df\u5f52\u56e0\u4e00\u81f4\u6027\u5e76\u63d0\u4f9b\u5956\u52b1\u6765\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5728Qwen2.5-VL-7B-Instruct\u6a21\u578b\u4e0a\uff0cLAT\u5728\u5355\u56fe\u548c\u591a\u56fe\u8bbe\u7f6e\u4e0b\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u8f6f\u7cbe\u786e\u5339\u914d\u5e73\u5747\u63d0\u53478.23%\uff0cIoU@0.5\u63d0\u534747.0%\uff0c\u4e14\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u57fa\u7ebf\uff0c\u5177\u6709\u66f4\u5f3a\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "LAT\u6846\u67b6\u901a\u8fc7\u8fc7\u7a0b\u7ea7\u81ea\u9a8c\u8bc1\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u89c6\u89c9\u6587\u6863\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u7684\u8bc1\u636e\u5f52\u56e0\u80fd\u529b\u548c\u63a8\u7406\u53ef\u9760\u6027\u3002"}}
{"id": "2511.12565", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12565", "abs": "https://arxiv.org/abs/2511.12565", "authors": ["Lingyun Xiang", "Chengfu Ou", "Xu He", "Zhongliang Yang", "Yuling Liu"], "title": "A Content-Preserving Secure Linguistic Steganography", "comment": "This is the extended version of the paper accepted to AAAI 2026", "summary": "Existing linguistic steganography methods primarily rely on content transformations to conceal secret messages. However, they often cause subtle yet looking-innocent deviations between normal and stego texts, posing potential security risks in real-world applications. To address this challenge, we propose a content-preserving linguistic steganography paradigm for perfectly secure covert communication without modifying the cover text. Based on this paradigm, we introduce CLstega (\\textit{C}ontent-preserving \\textit{L}inguistic \\textit{stega}nography), a novel method that embeds secret messages through controllable distribution transformation. CLstega first applies an augmented masking strategy to locate and mask embedding positions, where MLM(masked language model)-predicted probability distributions are easily adjustable for transformation. Subsequently, a dynamic distribution steganographic coding strategy is designed to encode secret messages by deriving target distributions from the original probability distributions. To achieve this transformation, CLstega elaborately selects target words for embedding positions as labels to construct a masked sentence dataset, which is used to fine-tune the original MLM, producing a target MLM capable of directly extracting secret messages from the cover text. This approach ensures perfect security of secret messages while fully preserving the integrity of the original cover text. Experimental results show that CLstega can achieve a 100\\% extraction success rate, and outperforms existing methods in security, effectively balancing embedding capacity and security.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5185\u5bb9\u4fdd\u6301\u7684\u8bed\u8a00\u9690\u5199\u65b9\u6cd5CLstega\uff0c\u901a\u8fc7\u53ef\u63a7\u5206\u5e03\u53d8\u6362\u5728\u4e0d\u4fee\u6539\u539f\u59cb\u6587\u672c\u7684\u60c5\u51b5\u4e0b\u5d4c\u5165\u79d8\u5bc6\u4fe1\u606f\uff0c\u5b9e\u73b0\u5b8c\u7f8e\u5b89\u5168\u9690\u853d\u901a\u4fe1\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u9690\u5199\u65b9\u6cd5\u901a\u8fc7\u5185\u5bb9\u53d8\u6362\u9690\u85cf\u79d8\u5bc6\u4fe1\u606f\uff0c\u4f46\u4f1a\u9020\u6210\u6b63\u5e38\u6587\u672c\u548c\u9690\u5199\u6587\u672c\u4e4b\u95f4\u7684\u5fae\u5999\u5dee\u5f02\uff0c\u5b58\u5728\u5b89\u5168\u98ce\u9669\u3002\u9700\u8981\u4e00\u79cd\u4e0d\u4fee\u6539\u539f\u59cb\u6587\u672c\u5185\u5bb9\u7684\u65b9\u6cd5\u6765\u786e\u4fdd\u5b8c\u7f8e\u5b89\u5168\u3002", "method": "CLstega\u91c7\u7528\u589e\u5f3a\u63a9\u7801\u7b56\u7565\u5b9a\u4f4d\u5d4c\u5165\u4f4d\u7f6e\uff0c\u8bbe\u8ba1\u52a8\u6001\u5206\u5e03\u9690\u5199\u7f16\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u4ece\u539f\u59cb\u6982\u7387\u5206\u5e03\u63a8\u5bfc\u76ee\u6807\u5206\u5e03\u6765\u7f16\u7801\u79d8\u5bc6\u4fe1\u606f\u3002\u901a\u8fc7\u6784\u5efa\u63a9\u7801\u53e5\u5b50\u6570\u636e\u96c6\u5fae\u8c03\u539f\u59cbMLM\uff0c\u751f\u6210\u80fd\u591f\u76f4\u63a5\u4ece\u539f\u59cb\u6587\u672c\u63d0\u53d6\u79d8\u5bc6\u4fe1\u606f\u7684\u76ee\u6807MLM\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aCLstega\u80fd\u591f\u5b9e\u73b0100%\u7684\u63d0\u53d6\u6210\u529f\u7387\uff0c\u5728\u5b89\u5168\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u6548\u5e73\u8861\u4e86\u5d4c\u5165\u5bb9\u91cf\u548c\u5b89\u5168\u6027\u3002", "conclusion": "CLstega\u901a\u8fc7\u5185\u5bb9\u4fdd\u6301\u7684\u8bed\u8a00\u9690\u5199\u8303\u5f0f\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u5b89\u5168\u7684\u9690\u853d\u901a\u4fe1\uff0c\u5b8c\u5168\u4fdd\u7559\u4e86\u539f\u59cb\u6587\u672c\u7684\u5b8c\u6574\u6027\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u79d8\u5bc6\u4fe1\u606f\u7684\u5b89\u5168\u3002"}}
{"id": "2511.12008", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12008", "abs": "https://arxiv.org/abs/2511.12008", "authors": ["Yunqi Hong", "Johnson Kao", "Liam Edwards", "Nein-Tzu Liu", "Chung-Yen Huang", "Alex Oliveira-Kowaleski", "Cho-Jui Hsieh", "Neil Y. C. Lin"], "title": "Adaptive Diagnostic Reasoning Framework for Pathology with Multimodal Large Language Models", "comment": null, "summary": "AI tools in pathology have improved screening throughput, standardized quantification, and revealed prognostic patterns that inform treatment. However, adoption remains limited because most systems still lack the human-readable reasoning needed to audit decisions and prevent errors. We present RECAP-PATH, an interpretable framework that establishes a self-learning paradigm, shifting off-the-shelf multimodal large language models from passive pattern recognition to evidence-linked diagnostic reasoning. At its core is a two-phase learning process that autonomously derives diagnostic criteria: diversification expands pathology-style explanations, while optimization refines them for accuracy. This self-learning approach requires only small labeled sets and no white-box access or weight updates to generate cancer diagnoses. Evaluated on breast and prostate datasets, RECAP-PATH produced rationales aligned with expert assessment and delivered substantial gains in diagnostic accuracy over baselines. By uniting visual understanding with reasoning, RECAP-PATH provides clinically trustworthy AI and demonstrates a generalizable path toward evidence-linked interpretation.", "AI": {"tldr": "RECAP-PATH\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u75c5\u7406AI\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u5b66\u4e60\u8303\u5f0f\u5c06\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u88ab\u52a8\u6a21\u5f0f\u8bc6\u522b\u8f6c\u53d8\u4e3a\u8bc1\u636e\u5173\u8054\u7684\u8bca\u65ad\u63a8\u7406\uff0c\u4ec5\u9700\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u5373\u53ef\u751f\u6210\u764c\u75c7\u8bca\u65ad\u3002", "motivation": "\u5f53\u524d\u75c5\u7406AI\u5de5\u5177\u867d\u7136\u63d0\u9ad8\u4e86\u7b5b\u67e5\u6548\u7387\u548c\u6807\u51c6\u5316\u91cf\u5316\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u4eba\u7c7b\u53ef\u8bfb\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u9650\u5236\u4e86\u5176\u4e34\u5e8a\u5e94\u7528\u3002\u9700\u8981\u5efa\u7acb\u53ef\u5ba1\u8ba1\u51b3\u7b56\u548c\u9632\u6b62\u9519\u8bef\u7684\u53ef\u89e3\u91ca\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u81ea\u5b66\u4e60\u8fc7\u7a0b\uff1a\u591a\u6837\u5316\u9636\u6bb5\u6269\u5c55\u75c5\u7406\u5b66\u98ce\u683c\u89e3\u91ca\uff0c\u4f18\u5316\u9636\u6bb5\u4e3a\u51c6\u786e\u6027\u7cbe\u70bc\u89e3\u91ca\u3002\u65e0\u9700\u767d\u76d2\u8bbf\u95ee\u6216\u6743\u91cd\u66f4\u65b0\uff0c\u4ec5\u9700\u5c0f\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u96c6\u3002", "result": "\u5728\u4e73\u817a\u764c\u548c\u524d\u5217\u817a\u764c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cRECAP-PATH\u751f\u6210\u7684\u63a8\u7406\u4e0e\u4e13\u5bb6\u8bc4\u4f30\u4e00\u81f4\uff0c\u8bca\u65ad\u51c6\u786e\u6027\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "RECAP-PATH\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u4e34\u5e8a\u53ef\u4fe1\u8d56\u7684AI\uff0c\u5c55\u793a\u4e86\u5b9e\u73b0\u8bc1\u636e\u5173\u8054\u89e3\u91ca\u7684\u901a\u7528\u8def\u5f84\u3002"}}
{"id": "2511.12626", "categories": ["cs.CR", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.12626", "abs": "https://arxiv.org/abs/2511.12626", "authors": ["Hongyin Chen", "Yubin Ke", "Xiaotie Deng", "Ittay Eyal"], "title": "Prrr: Personal Random Rewards for Blockchain Reporting", "comment": null, "summary": "Smart contracts, the stateful programs running on blockchains, often rely on reports. Publishers are paid to publish these reports on the blockchain. Designing protocols that incentivize timely reporting is the prevalent reporting problem. But existing solutions face a security-performance trade-off: Relying on a small set of trusted publishers introduces centralization risks, while allowing open publication results in an excessive number of reports on the blockchain. We identify the root cause of this trade-off to be the standard symmetric reward design, which treats all reports equally. We prove that no symmetric-reward mechanism can overcome the trade-off.\n  We present Personal Random Rewards for Reporting (Prrr), a protocol that assigns random heterogeneous values to reports. We call this novel mechanism-design concept Ex-Ante Synthetic Asymmetry. To the best of our knowledge, Prrr is the first game-theoretic mechanism (in any context) that deliberately forms participant asymmetry. Prrr employs a second-price-style settlement to allocate rewards, ensuring incentive compatibility and achieving both security and efficiency. Following the protocol constitutes a Subgame-Perfect Nash Equilibrium, robust against collusion and Sybil attacks. Prrr is applicable to numerous smart contracts that rely on timely reports.", "AI": {"tldr": "Prrr\u534f\u8bae\u901a\u8fc7\u968f\u673a\u5f02\u8d28\u5956\u52b1\u8bbe\u8ba1\u89e3\u51b3\u4e86\u533a\u5757\u94fe\u62a5\u544a\u7cfb\u7edf\u7684\u5b89\u5168\u4e0e\u6027\u80fd\u6743\u8861\u95ee\u9898\uff0c\u91c7\u7528\u4e8b\u524d\u5408\u6210\u4e0d\u5bf9\u79f0\u673a\u5236\u5b9e\u73b0\u6fc0\u52b1\u517c\u5bb9\u3002", "motivation": "\u73b0\u6709\u62a5\u544a\u534f\u8bae\u9762\u4e34\u5b89\u5168\u4e0e\u6027\u80fd\u7684\u6743\u8861\uff1a\u4f9d\u8d56\u5c11\u6570\u53ef\u4fe1\u53d1\u5e03\u8005\u5e26\u6765\u4e2d\u5fc3\u5316\u98ce\u9669\uff0c\u800c\u5f00\u653e\u53d1\u5e03\u5219\u5bfc\u81f4\u533a\u5757\u94fe\u4e0a\u62a5\u544a\u6570\u91cf\u8fc7\u591a\u3002\u6807\u51c6\u5bf9\u79f0\u5956\u52b1\u8bbe\u8ba1\u662f\u8fd9\u4e00\u95ee\u9898\u7684\u6839\u6e90\u3002", "method": "\u63d0\u51faPrrr\u534f\u8bae\uff0c\u91c7\u7528\u968f\u673a\u5f02\u8d28\u5956\u52b1\u5206\u914d\u673a\u5236\uff08\u4e8b\u524d\u5408\u6210\u4e0d\u5bf9\u79f0\uff09\uff0c\u4f7f\u7528\u7b2c\u4e8c\u4ef7\u683c\u5f0f\u7ed3\u7b97\u6765\u5206\u914d\u5956\u52b1\uff0c\u786e\u4fdd\u6fc0\u52b1\u517c\u5bb9\u6027\u3002", "result": "Prrr\u534f\u8bae\u5b9e\u73b0\u4e86\u5b89\u5168\u6027\u548c\u6548\u7387\u7684\u53cc\u91cd\u76ee\u6807\uff0c\u9075\u5faa\u534f\u8bae\u6784\u6210\u5b50\u535a\u5f08\u5b8c\u7f8e\u7eb3\u4ec0\u5747\u8861\uff0c\u5bf9\u5408\u8c0b\u548c\u5973\u5deb\u653b\u51fb\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "Prrr\u662f\u9996\u4e2a\u5728\u535a\u5f08\u8bba\u673a\u5236\u4e2d\u523b\u610f\u5f62\u6210\u53c2\u4e0e\u8005\u4e0d\u5bf9\u79f0\u6027\u7684\u534f\u8bae\uff0c\u9002\u7528\u4e8e\u4f17\u591a\u4f9d\u8d56\u53ca\u65f6\u62a5\u544a\u7684\u667a\u80fd\u5408\u7ea6\u573a\u666f\u3002"}}
{"id": "2511.12643", "categories": ["cs.CR", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.12643", "abs": "https://arxiv.org/abs/2511.12643", "authors": ["Ahmed Sameh", "Sahar Selim"], "title": "Adaptive Dual-Layer Web Application Firewall (ADL-WAF) Leveraging Machine Learning for Enhanced Anomaly and Threat Detection", "comment": null, "summary": "Web Application Firewalls are crucial for protecting web applications against a wide range of cyber threats. Traditional Web Application Firewalls often struggle to effectively distinguish between malicious and legitimate traffic, leading to limited efficacy in threat detection. To overcome these limitations, this paper proposes an Adaptive Dual-Layer WAF employing a two-layered Machine Learning model designed to enhance the accuracy of anomaly and threat detection. The first layer employs a Decision Tree (DT) algorithm to detect anomalies by identifying traffic deviations from established normal patterns. The second layer employs Support Vector Machine to classify these anomalies as either threat anomalies or benign anomalies. Our Adaptive Dual Layer WAF incorporates comprehensive data pre-processing and feature engineering techniques and has been thoroughly evaluated using five large benchmark datasets. Evaluation using these datasets shows that ADL WAF achieves a detection accuracy of 99.88% and a precision of 100%, significantly enhancing anomaly detection and reducing false positives. These findings suggest that integrating machine learning techniques into WAFs can substantially improve web application security by providing more accurate and efficient threat detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u53cc\u5c42WAF\uff0c\u91c7\u7528\u4e24\u5c42\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6765\u63d0\u9ad8\u5f02\u5e38\u548c\u5a01\u80c1\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002\u7b2c\u4e00\u5c42\u4f7f\u7528\u51b3\u7b56\u6811\u68c0\u6d4b\u5f02\u5e38\uff0c\u7b2c\u4e8c\u5c42\u4f7f\u7528\u652f\u6301\u5411\u91cf\u673a\u5206\u7c7b\u5a01\u80c1\u5f02\u5e38\u548c\u826f\u6027\u5f02\u5e38\u3002\u5728\u4e94\u4e2a\u5927\u578b\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe\u523099.88%\uff0c\u7cbe\u786e\u5ea6\u4e3a100%\u3002", "motivation": "\u4f20\u7edfWeb\u5e94\u7528\u9632\u706b\u5899\u5728\u533a\u5206\u6076\u610f\u548c\u5408\u6cd5\u6d41\u91cf\u65b9\u9762\u6548\u679c\u6709\u9650\uff0c\u5bfc\u81f4\u5a01\u80c1\u68c0\u6d4b\u6548\u80fd\u4e0d\u8db3\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u51c6\u786e\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u81ea\u9002\u5e94\u53cc\u5c42\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff1a\u7b2c\u4e00\u5c42\u4f7f\u7528\u51b3\u7b56\u6811\u7b97\u6cd5\u68c0\u6d4b\u6d41\u91cf\u5f02\u5e38\uff0c\u8bc6\u522b\u4e0e\u6b63\u5e38\u6a21\u5f0f\u7684\u504f\u5dee\uff1b\u7b2c\u4e8c\u5c42\u4f7f\u7528\u652f\u6301\u5411\u91cf\u673a\u5bf9\u68c0\u6d4b\u5230\u7684\u5f02\u5e38\u8fdb\u884c\u5206\u7c7b\uff0c\u533a\u5206\u5a01\u80c1\u5f02\u5e38\u548c\u826f\u6027\u5f02\u5e38\u3002\u5305\u542b\u5168\u9762\u7684\u6570\u636e\u9884\u5904\u7406\u548c\u7279\u5f81\u5de5\u7a0b\u6280\u672f\u3002", "result": "\u5728\u4e94\u4e2a\u5927\u578b\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0cADL WAF\u5b9e\u73b0\u4e8699.88%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u548c100%\u7684\u7cbe\u786e\u5ea6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5f02\u5e38\u68c0\u6d4b\u80fd\u529b\u5e76\u51cf\u5c11\u4e86\u8bef\u62a5\u3002", "conclusion": "\u5c06\u673a\u5668\u5b66\u4e60\u6280\u672f\u96c6\u6210\u5230WAF\u4e2d\u53ef\u4ee5\u663e\u8457\u6539\u5584Web\u5e94\u7528\u5b89\u5168\uff0c\u63d0\u4f9b\u66f4\u51c6\u786e\u548c\u9ad8\u6548\u7684\u5a01\u80c1\u68c0\u6d4b\u3002"}}
{"id": "2511.12063", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12063", "abs": "https://arxiv.org/abs/2511.12063", "authors": ["Enoch Hyunwook Kang", "Hema Yoganarasimhan"], "title": "Bayesian Optimization in Language Space: An Eval-Efficient AI Self-Improvement Framework", "comment": null, "summary": "Large Language Models (LLMs) have recently enabled self-improving AI, i.e., AI that iteratively generates, evaluates, and refines its own outcomes. Recent studies have shown that self-improving AI focusing on prompt optimization can outperform state-of-the-art reinforcement-learning fine-tuned LLMs. Here, their `performance' is typically measured by query efficiency - the number of LLM-generated solution samples required to meet a certain performance threshold. However, in many societal applications, the primary limitation is not generating new solutions but evaluating them. For instance, evaluating an ad's effectiveness requires significant human feedback, which is far more costly and time-consuming than generating a candidate ad. To optimize for the evaluation efficiency objective, a natural approach is to extend Bayesian Optimization (BO), a framework proven optimal for evaluation efficiency, to the language domain. However, the difficulty of directly estimating suitable acquisition functions in LLMs' minds makes this extension challenging. This paper overcomes this challenge by proving that the combination of the simple and widely used Best-of-N selection strategy and simple textual gradients (i.e., textual edits from a critic model) statistically emulates the behavior of the gradients on the canonical UCB acquisition function, which induces optimal exploration in terms of evaluation efficiency. Based on this result, we propose TextGrad-Best-of-N Bayesian Optimization (T-BoN BO), a simple and eval-efficient language-space Bayesian optimization framework for AI self-improvement. We also empirically validate T-BoN BO by applying it to automated ad alignment tasks for persona distribution, demonstrating its superior performance compared to popular state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86T-BoN BO\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408Best-of-N\u9009\u62e9\u548c\u6587\u672c\u68af\u5ea6\uff0c\u5728\u8bed\u8a00\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u8bc4\u4f30\u6548\u7387\u6700\u4f18\u7684\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u7528\u4e8eAI\u81ea\u6211\u6539\u8fdb\u3002", "motivation": "\u5728\u8bb8\u591a\u793e\u4f1a\u5e94\u7528\u4e2d\uff0c\u4e3b\u8981\u9650\u5236\u4e0d\u662f\u751f\u6210\u65b0\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u662f\u8bc4\u4f30\u5b83\u4eec\u3002\u4f8b\u5982\u8bc4\u4f30\u5e7f\u544a\u6548\u679c\u9700\u8981\u5927\u91cf\u4eba\u5de5\u53cd\u9988\uff0c\u6210\u672c\u8fdc\u9ad8\u4e8e\u751f\u6210\u5019\u9009\u5e7f\u544a\u3002\u9700\u8981\u4f18\u5316\u8bc4\u4f30\u6548\u7387\u800c\u975e\u67e5\u8be2\u6548\u7387\u3002", "method": "\u63d0\u51faT-BoN BO\u6846\u67b6\uff0c\u8bc1\u660eBest-of-N\u9009\u62e9\u7b56\u7565\u4e0e\u6587\u672c\u68af\u5ea6\u7ec4\u5408\u5728\u7edf\u8ba1\u4e0a\u6a21\u62df\u4e86UCB\u91c7\u96c6\u51fd\u6570\u7684\u68af\u5ea6\u884c\u4e3a\uff0c\u4ece\u800c\u5b9e\u73b0\u8bc4\u4f30\u6548\u7387\u6700\u4f18\u7684\u63a2\u7d22\u3002", "result": "\u5728\u81ea\u52a8\u5e7f\u544a\u5bf9\u9f50\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86T-BoN BO\u7684\u6027\u80fd\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "T-BoN BO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u4e14\u8bc4\u4f30\u6548\u7387\u6700\u4f18\u7684\u8bed\u8a00\u7a7a\u95f4\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\uff0c\u9002\u7528\u4e8eAI\u81ea\u6211\u6539\u8fdb\u4efb\u52a1\u3002"}}
{"id": "2511.12083", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12083", "abs": "https://arxiv.org/abs/2511.12083", "authors": ["Yanchang Fu", "Shengda Liu", "Pei Xu", "Kaiqi Huang"], "title": "No-Regret Strategy Solving in Imperfect-Information Games via Pre-Trained Embedding", "comment": null, "summary": "High-quality information set abstraction remains a core challenge in solving large-scale imperfect-information extensive-form games (IIEFGs)-such as no-limit Texas Hold'em-where the finite nature of spatial resources hinders strategy solving over the full game. State-of-the-art AI methods rely on pre-trained discrete clustering for abstraction, yet their hard classification irreversibly loses critical information: specifically, the quantifiable subtle differences between information sets-vital for strategy solving-thereby compromising the quality of such solving. Inspired by the word embedding paradigm in natural language processing, this paper proposes the Embedding CFR algorithm, a novel approach for solving strategies in IIEFGs within an embedding space. The algorithm pre-trains and embeds features of isolated information sets into an interconnected low-dimensional continuous space, where the resulting vectors more precisely capture both the distinctions and connections between information sets. Embedding CFR presents a strategy-solving process driven by regret accumulation and strategy updates within this embedding space, with accompanying theoretical analysis verifying its capacity to reduce cumulative regret. Experiments on poker show that with the same spatial overhead, Embedding CFR achieves significantly faster exploitability convergence compared to cluster-based abstraction algorithms, confirming its effectiveness. Furthermore, to our knowledge, it is the first algorithm in poker AI that pre-trains information set abstractions through low-dimensional embedding for strategy solving.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEmbedding CFR\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06\u4fe1\u606f\u96c6\u5d4c\u5165\u5230\u4f4e\u7ef4\u8fde\u7eed\u7a7a\u95f4\u6765\u89e3\u51b3\u5927\u89c4\u6a21\u4e0d\u5b8c\u5168\u4fe1\u606f\u6269\u5c55\u5f0f\u535a\u5f08\uff0c\u76f8\u6bd4\u57fa\u4e8e\u805a\u7c7b\u7684\u62bd\u8c61\u65b9\u6cd5\u80fd\u66f4\u7cbe\u786e\u6355\u6349\u4fe1\u606f\u96c6\u95f4\u7684\u5dee\u5f02\u548c\u8054\u7cfb\uff0c\u5728\u6251\u514b\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u53ef\u5265\u524a\u6027\u6536\u655b\u3002", "motivation": "\u73b0\u6709AI\u65b9\u6cd5\u4f9d\u8d56\u9884\u8bad\u7ec3\u7684\u79bb\u6563\u805a\u7c7b\u8fdb\u884c\u62bd\u8c61\uff0c\u4f46\u786c\u5206\u7c7b\u4e0d\u53ef\u9006\u5730\u4e22\u5931\u4e86\u4fe1\u606f\u96c6\u4e4b\u95f4\u53ef\u91cf\u5316\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u8fd9\u4e9b\u5dee\u5f02\u5bf9\u4e8e\u7b56\u7565\u6c42\u89e3\u81f3\u5173\u91cd\u8981\uff0c\u4ece\u800c\u5f71\u54cd\u6c42\u89e3\u8d28\u91cf\u3002", "method": "\u53d7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u8bcd\u5d4c\u5165\u8303\u5f0f\u7684\u542f\u53d1\uff0c\u63d0\u51faEmbedding CFR\u7b97\u6cd5\uff0c\u5c06\u5b64\u7acb\u4fe1\u606f\u96c6\u7684\u7279\u5f81\u9884\u8bad\u7ec3\u5e76\u5d4c\u5165\u5230\u76f8\u4e92\u8fde\u63a5\u7684\u4f4e\u7ef4\u8fde\u7eed\u7a7a\u95f4\u4e2d\uff0c\u5728\u8be5\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u9057\u61be\u7d2f\u79ef\u548c\u7b56\u7565\u66f4\u65b0\u7684\u7b56\u7565\u6c42\u89e3\u8fc7\u7a0b\u3002", "result": "\u5728\u6251\u514b\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u76f8\u540c\u7a7a\u95f4\u5f00\u9500\u4e0b\uff0cEmbedding CFR\u76f8\u6bd4\u57fa\u4e8e\u805a\u7c7b\u7684\u62bd\u8c61\u7b97\u6cd5\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u5feb\u7684\u53ef\u5265\u524a\u6027\u6536\u655b\u3002", "conclusion": "Embedding CFR\u662f\u6251\u514bAI\u4e2d\u9996\u4e2a\u901a\u8fc7\u4f4e\u7ef4\u5d4c\u5165\u9884\u8bad\u7ec3\u4fe1\u606f\u96c6\u62bd\u8c61\u8fdb\u884c\u7b56\u7565\u6c42\u89e3\u7684\u7b97\u6cd5\uff0c\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u4e86\u5176\u51cf\u5c11\u7d2f\u79ef\u9057\u61be\u7684\u80fd\u529b\u3002"}}
{"id": "2511.12668", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12668", "abs": "https://arxiv.org/abs/2511.12668", "authors": ["Samuel Nathanson", "Alexander Lee", "Catherine Chen Kieffer", "Jared Junkin", "Jessica Ye", "Amir Saeed", "Melanie Lockhart", "Russ Fink", "Elisha Peterson", "Lanier Watkins"], "title": "AI Bill of Materials and Beyond: Systematizing Security Assurance through the AI Risk Scanning (AIRS) Framework", "comment": "13 pages, 4 figures, 6 tables", "summary": "Assurance for artificial intelligence (AI) systems remains fragmented across software supply-chain security, adversarial machine learning, and governance documentation. Existing transparency mechanisms - including Model Cards, Datasheets, and Software Bills of Materials (SBOMs) - advance provenance reporting but rarely provide verifiable, machine-readable evidence of model security. This paper introduces the AI Risk Scanning (AIRS) Framework, a threat-model-based, evidence-generating framework designed to operationalize AI assurance. The AIRS Framework evolved through three progressive pilot studies - Smurf (AIBOM schema design), OPAL (operational validation), and Pilot C (AIRS) - that reframed AI documentation from descriptive disclosure toward measurable, evidence-bound verification. The framework aligns its assurance fields to the MITRE ATLAS adversarial ML taxonomy and automatically produces structured artifacts capturing model integrity, packaging and serialization safety, structural adapters, and runtime behaviors. Currently, the AIRS Framework is scoped to provide model-level assurances for LLMs, but it could be expanded to include other modalities and cover system-level threats (e.g. application-layer abuses, tool-calling). A proof-of-concept on a quantized GPT-OSS-20B model demonstrates enforcement of safe loader policies, per-shard hash verification, and contamination and backdoor probes executed under controlled runtime conditions. Comparative analysis with SBOM standards of SPDX 3.0 and CycloneDX 1.6 reveals alignment on identity and evaluation metadata, but identifies critical gaps in representing AI-specific assurance fields. The AIRS Framework thus extends SBOM practice to the AI domain by coupling threat modeling with automated, auditable evidence generation, providing a principled foundation for standardized, trustworthy, and machine-verifiable AI risk documentation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AI\u98ce\u9669\u626b\u63cf\uff08AIRS\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u5a01\u80c1\u6a21\u578b\u3001\u751f\u6210\u8bc1\u636e\u7684\u6846\u67b6\uff0c\u65e8\u5728\u5b9e\u73b0AI\u4fdd\u969c\u7684\u53ef\u64cd\u4f5c\u5316\u3002\u8be5\u6846\u67b6\u5c06AI\u6587\u6863\u4ece\u63cf\u8ff0\u6027\u62ab\u9732\u8f6c\u5411\u53ef\u6d4b\u91cf\u7684\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u9a8c\u8bc1\uff0c\u5e76\u4e0eMITRE ATLAS\u5bf9\u6297\u6027\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u6cd5\u5bf9\u9f50\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u7684\u4fdd\u969c\u673a\u5236\u5728\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u3001\u5bf9\u6297\u6027\u673a\u5668\u5b66\u4e60\u548c\u6cbb\u7406\u6587\u6863\u65b9\u9762\u4ecd\u7136\u5206\u6563\u3002\u73b0\u6709\u7684\u900f\u660e\u5ea6\u673a\u5236\uff08\u5982\u6a21\u578b\u5361\u3001\u6570\u636e\u8868\u548c\u8f6f\u4ef6\u7269\u6599\u6e05\u5355\uff09\u867d\u7136\u63a8\u8fdb\u4e86\u6765\u6e90\u62a5\u544a\uff0c\u4f46\u5f88\u5c11\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u3001\u673a\u5668\u53ef\u8bfb\u7684\u6a21\u578b\u5b89\u5168\u8bc1\u636e\u3002", "method": "AIRS\u6846\u67b6\u901a\u8fc7\u4e09\u4e2a\u6e10\u8fdb\u5f0f\u8bd5\u70b9\u7814\u7a76\uff08Smurf\u3001OPAL\u548cPilot C\uff09\u53d1\u5c55\u800c\u6765\uff0c\u5c06AI\u6587\u6863\u4ece\u63cf\u8ff0\u6027\u62ab\u9732\u91cd\u65b0\u5b9a\u4e49\u4e3a\u53ef\u6d4b\u91cf\u7684\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u9a8c\u8bc1\u3002\u8be5\u6846\u67b6\u5c06\u5176\u4fdd\u969c\u5b57\u6bb5\u4e0eMITRE ATLAS\u5bf9\u6297\u6027ML\u5206\u7c7b\u6cd5\u5bf9\u9f50\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u7ed3\u6784\u5316\u5de5\u4ef6\uff0c\u6355\u83b7\u6a21\u578b\u5b8c\u6574\u6027\u3001\u6253\u5305\u548c\u5e8f\u5217\u5316\u5b89\u5168\u6027\u3001\u7ed3\u6784\u9002\u914d\u5668\u548c\u8fd0\u884c\u65f6\u884c\u4e3a\u3002", "result": "\u5728\u91cf\u5316GPT-OSS-20B\u6a21\u578b\u4e0a\u7684\u6982\u5ff5\u9a8c\u8bc1\u5c55\u793a\u4e86\u5b89\u5168\u52a0\u8f7d\u5668\u7b56\u7565\u7684\u6267\u884c\u3001\u6bcf\u5206\u7247\u54c8\u5e0c\u9a8c\u8bc1\u4ee5\u53ca\u5728\u53d7\u63a7\u8fd0\u884c\u65f6\u6761\u4ef6\u4e0b\u6267\u884c\u7684\u6c61\u67d3\u548c\u540e\u95e8\u63a2\u6d4b\u3002\u4e0eSPDX 3.0\u548cCycloneDX 1.6\u7684SBOM\u6807\u51c6\u6bd4\u8f83\u5206\u6790\u663e\u793a\u5728\u8eab\u4efd\u548c\u8bc4\u4f30\u5143\u6570\u636e\u65b9\u9762\u5b58\u5728\u5bf9\u9f50\uff0c\u4f46\u8bc6\u522b\u4e86\u5728\u8868\u793aAI\u7279\u5b9a\u4fdd\u969c\u5b57\u6bb5\u65b9\u9762\u7684\u5173\u952e\u5dee\u8ddd\u3002", "conclusion": "AIRS\u6846\u67b6\u901a\u8fc7\u5c06\u5a01\u80c1\u5efa\u6a21\u4e0e\u81ea\u52a8\u5316\u3001\u53ef\u5ba1\u8ba1\u7684\u8bc1\u636e\u751f\u6210\u76f8\u7ed3\u5408\uff0c\u5c06SBOM\u5b9e\u8df5\u6269\u5c55\u5230AI\u9886\u57df\uff0c\u4e3a\u6807\u51c6\u5316\u3001\u53ef\u4fe1\u8d56\u548c\u673a\u5668\u53ef\u9a8c\u8bc1\u7684AI\u98ce\u9669\u6587\u6863\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u57fa\u7840\u3002"}}
{"id": "2511.12089", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.12089", "abs": "https://arxiv.org/abs/2511.12089", "authors": ["Yanchang Fu", "Qiyue Yin", "Shengda Liu", "Pei Xu", "Kaiqi Huang"], "title": "KrwEmd: Revising the Imperfect-Recall Abstraction from Forgetting Everything", "comment": null, "summary": "Excessive abstraction is a critical challenge in hand abstraction-a task specific to games like Texas hold'em-when solving large-scale imperfect-information games, as it impairs AI performance. This issue arises from extreme implementations of imperfect-recall abstraction, which entirely discard historical information. This paper presents KrwEmd, the first practical algorithm designed to address this problem. We first introduce the k-recall winrate feature, which not only qualitatively distinguishes signal observation infosets by leveraging both future and, crucially, historical game information, but also quantitatively captures their similarity. We then develop the KrwEmd algorithm, which clusters signal observation infosets using earth mover's distance to measure discrepancies between their features. Experimental results demonstrate that KrwEmd significantly improves AI gameplay performance compared to existing algorithms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86KrwEmd\u7b97\u6cd5\u6765\u89e3\u51b3\u5fb7\u5dde\u6251\u514b\u7b49\u6e38\u620f\u4e2d\u624b\u724c\u62bd\u8c61\u8fc7\u5ea6\u7684\u95ee\u9898\uff0c\u901a\u8fc7k-recall\u8d62\u7387\u7279\u5f81\u548c\u5730\u7403\u79fb\u52a8\u8ddd\u79bb\u805a\u7c7b\u6765\u6539\u8fdbAI\u6e38\u620f\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f\u4e2d\u624b\u724c\u62bd\u8c61\u8fc7\u5ea6\u7684\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u6e90\u4e8e\u4e0d\u5b8c\u5168\u56de\u5fc6\u62bd\u8c61\u7684\u6781\u7aef\u5b9e\u73b0\uff0c\u5b8c\u5168\u4e22\u5f03\u5386\u53f2\u4fe1\u606f\uff0c\u4ece\u800c\u635f\u5bb3AI\u6027\u80fd\u3002", "method": "\u9996\u5148\u5f15\u5165k-recall\u8d62\u7387\u7279\u5f81\uff0c\u5229\u7528\u672a\u6765\u548c\u5173\u952e\u7684\u5386\u53f2\u6e38\u620f\u4fe1\u606f\u6765\u533a\u5206\u4fe1\u53f7\u89c2\u5bdf\u4fe1\u606f\u96c6\uff1b\u7136\u540e\u5f00\u53d1KrwEmd\u7b97\u6cd5\uff0c\u4f7f\u7528\u5730\u7403\u79fb\u52a8\u8ddd\u79bb\u6765\u6d4b\u91cf\u7279\u5f81\u5dee\u5f02\u5e76\u805a\u7c7b\u4fe1\u53f7\u89c2\u5bdf\u4fe1\u606f\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u7b97\u6cd5\u76f8\u6bd4\uff0cKrwEmd\u663e\u8457\u63d0\u9ad8\u4e86AI\u6e38\u620f\u6027\u80fd\u3002", "conclusion": "KrwEmd\u662f\u7b2c\u4e00\u4e2a\u89e3\u51b3\u624b\u724c\u62bd\u8c61\u8fc7\u5ea6\u95ee\u9898\u7684\u5b9e\u7528\u7b97\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5386\u53f2\u4fe1\u606f\u548c\u7279\u5f81\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f\u4e2dAI\u7684\u8868\u73b0\u3002"}}
{"id": "2511.12704", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.12704", "abs": "https://arxiv.org/abs/2511.12704", "authors": ["Herman Errico"], "title": "Offensive tool determination strategy R.I.D.D.L.E. + (C)", "comment": null, "summary": "Intentional threats are a major risk factor related to vulnerabilities in critical infrastructure assets, and an accurate risk assessment is necessary to analyze threats, assess vulnerabilities, and evaluate potential impacts on assets and systems. This research proposes a methodology that can be added as an additional phase in the risk assessment process. The method introduces an extra analytical parameter concerning offensive tool characteristics, improving the understanding of intentional threats.\n  The methodology is presented using clear and accessible language suitable for a broad audience. It is based on an approach described as an \"offensive tool determination strategy,\" summarized by the acronym R.I.D.D.L.E.+C, which refers to the variables used in the analysis: resistance, intrusion timing, damage, disruption timing, latency, efficiency, and cost. These variables are evaluated using open-source intelligence.\n  Each variable is assigned a specific range of values according to its potential impact on the targeted asset. A matrix is then provided for practical application, which can reveal unexpected vulnerabilities and offer a more granular framework for decision-making and security planning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u653b\u51fb\u5de5\u5177\u7279\u5f81\u4f5c\u4e3a\u989d\u5916\u5206\u6790\u53c2\u6570\uff0c\u4f7f\u7528R.I.D.D.L.E.+C\u53d8\u91cf\uff08\u6297\u6027\u3001\u5165\u4fb5\u65f6\u673a\u3001\u635f\u5bb3\u3001\u4e2d\u65ad\u65f6\u673a\u3001\u6f5c\u4f0f\u671f\u3001\u6548\u7387\u548c\u6210\u672c\uff09\u6765\u6539\u8fdb\u5bf9\u6545\u610f\u5a01\u80c1\u7684\u7406\u89e3\u3002", "motivation": "\u6545\u610f\u5a01\u80c1\u662f\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u8d44\u4ea7\u6f0f\u6d1e\u7684\u4e3b\u8981\u98ce\u9669\u56e0\u7d20\uff0c\u9700\u8981\u51c6\u786e\u7684\u98ce\u9669\u8bc4\u4f30\u6765\u5206\u6790\u5a01\u80c1\u3001\u8bc4\u4f30\u6f0f\u6d1e\u5e76\u8bc4\u4f30\u5bf9\u8d44\u4ea7\u548c\u7cfb\u7edf\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "method": "\u57fa\u4e8e\"\u653b\u51fb\u5de5\u5177\u786e\u5b9a\u7b56\u7565\"\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528R.I.D.D.L.E.+C\u53d8\u91cf\uff08\u6297\u6027\u3001\u5165\u4fb5\u65f6\u673a\u3001\u635f\u5bb3\u3001\u4e2d\u65ad\u65f6\u673a\u3001\u6f5c\u4f0f\u671f\u3001\u6548\u7387\u548c\u6210\u672c\uff09\uff0c\u901a\u8fc7\u5f00\u6e90\u60c5\u62a5\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u53d8\u91cf\u5206\u914d\u7279\u5b9a\u8303\u56f4\u7684\u503c\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u5e94\u7528\u77e9\u9635\uff0c\u53ef\u4ee5\u63ed\u793a\u610f\u5916\u6f0f\u6d1e\uff0c\u5e76\u4e3a\u51b3\u7b56\u548c\u5b89\u5168\u89c4\u5212\u63d0\u4f9b\u66f4\u7ec6\u7c92\u5ea6\u7684\u6846\u67b6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u4f5c\u4e3a\u98ce\u9669\u8bc4\u4f30\u8fc7\u7a0b\u7684\u9644\u52a0\u9636\u6bb5\uff0c\u901a\u8fc7\u5206\u6790\u653b\u51fb\u5de5\u5177\u7279\u5f81\u6765\u589e\u5f3a\u5bf9\u6545\u610f\u5a01\u80c1\u7684\u7406\u89e3\u548c\u8bc4\u4f30\u80fd\u529b\u3002"}}
{"id": "2511.12113", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12113", "abs": "https://arxiv.org/abs/2511.12113", "authors": ["Lanxue Zhang", "Yuqiang Xie", "Fang Fang", "Fanglong Dong", "Rui Liu", "Yanan Cao"], "title": "MetaGDPO: Alleviating Catastrophic Forgetting with Metacognitive Knowledge through Group Direct Preference Optimization", "comment": "23 pages, 10 figures, AAAI 2026", "summary": "Large Language Models demonstrate strong reasoning capabilities, which can be effectively compressed into smaller models. However, existing datasets and fine-tuning approaches still face challenges that lead to catastrophic forgetting, particularly for models smaller than 8B. First, most datasets typically ignore the relationship between training data knowledge and the model's inherent abilities, making it difficult to preserve prior knowledge. Second, conventional training objectives often fail to constrain inherent knowledge preservation, which can result in forgetting of previously learned skills. To address these issues, we propose a comprehensive solution that alleviates catastrophic forgetting from both the data and fine-tuning approach perspectives. On the data side, we construct a dataset of 5K instances that covers multiple reasoning tasks and incorporates metacognitive knowledge, making it more tolerant and effective for distillation into smaller models. We annotate the metacognitive knowledge required to solve each question and filter the data based on task knowledge and the model's inherent skills. On the training side, we introduce GDPO (Group Direction Preference Optimization), which is better suited for resource-limited scenarios and can efficiently approximate the performance of GRPO. Guided by the large model and by implicitly constraining the optimization path through a reference model, GDPO enables more effective knowledge transfer from the large model and constrains excessive parameter drift. Extensive experiments demonstrate that our approach significantly alleviates catastrophic forgetting and improves reasoning performance on smaller models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u5c0f\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u4e2d\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u7684\u7efc\u5408\u65b9\u6848\uff0c\u5305\u62ec\u6784\u5efa\u5305\u542b\u5143\u8ba4\u77e5\u77e5\u8bc6\u7684\u6570\u636e\u96c6\u548c\u5f15\u5165GDPO\u8bad\u7ec3\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u548c\u5fae\u8c03\u65b9\u6cd5\u5728\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u538b\u7f29\u5230\u5c0f\u6a21\u578b\u65f6\u9762\u4e34\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u7279\u522b\u662f\u5bf9\u4e8e8B\u4ee5\u4e0b\u7684\u5c0f\u6a21\u578b\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8bad\u7ec3\u6570\u636e\u4e0e\u6a21\u578b\u56fa\u6709\u80fd\u529b\u7684\u5173\u8054\u6027\u88ab\u5ffd\u89c6\uff0c\u4ee5\u53ca\u4f20\u7edf\u8bad\u7ec3\u76ee\u6807\u65e0\u6cd5\u6709\u6548\u7ea6\u675f\u56fa\u6709\u77e5\u8bc6\u7684\u4fdd\u7559\u3002", "method": "1) \u6570\u636e\u5c42\u9762\uff1a\u6784\u5efa\u5305\u542b5K\u5b9e\u4f8b\u7684\u6570\u636e\u96c6\uff0c\u8986\u76d6\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u5e76\u878d\u5165\u5143\u8ba4\u77e5\u77e5\u8bc6\uff0c\u57fa\u4e8e\u4efb\u52a1\u77e5\u8bc6\u548c\u6a21\u578b\u56fa\u6709\u6280\u80fd\u8fdb\u884c\u6570\u636e\u8fc7\u6ee4\uff1b2) \u8bad\u7ec3\u5c42\u9762\uff1a\u63d0\u51faGDPO\uff08\u7ec4\u65b9\u5411\u504f\u597d\u4f18\u5316\uff09\u65b9\u6cd5\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u9ad8\u6548\u8fd1\u4f3cGRPO\u6027\u80fd\uff0c\u901a\u8fc7\u53c2\u8003\u6a21\u578b\u9690\u5f0f\u7ea6\u675f\u4f18\u5316\u8def\u5f84\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u7f13\u89e3\u4e86\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5e76\u63d0\u5347\u4e86\u5c0f\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u7efc\u5408\u89e3\u51b3\u65b9\u6848\u4ece\u6570\u636e\u548c\u8bad\u7ec3\u65b9\u6cd5\u4e24\u4e2a\u89d2\u5ea6\u6709\u6548\u89e3\u51b3\u4e86\u5c0f\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u77e5\u8bc6\u8fc1\u79fb\u548c\u53c2\u6570\u6f02\u79fb\u7ea6\u675f\u3002"}}
{"id": "2511.12739", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.12739", "abs": "https://arxiv.org/abs/2511.12739", "authors": ["Yaniv Hacmon", "Keren Gorelik", "Gilad Gressel", "Yisroel Mirsky"], "title": "ProxyPrints: From Database Breach to Spoof, A Plug-and-Play Defense for Biometric Systems", "comment": null, "summary": "Fingerprint recognition systems are widely deployed for authentication and forensic applications, but the security of stored fingerprint data remains a critical vulnerability. While many systems avoid storing raw fingerprint images in favor of minutiae-based templates, recent research shows that these templates can be reverse-engineered to reconstruct realistic fingerprint images, enabling physical spoofing attacks that compromise user identities with no means of remediation.\n  We present ProxyPrints, the first practical defense that brings cancellable biometrics to existing fingerprint recognition systems without requiring modifications to proprietary matching software. ProxyPrints acts as a transparent middleware layer between the fingerprint scanner and the matching algorithm, transforming each scanned fingerprint into a consistent, unlinkable alias. This transformation allows biometric identities to be revoked and replaced in the event of a breach, without affecting authentication accuracy. Additionally, ProxyPrints provides organizations with breach detection capabilities by enabling the identification of out-of-band spoofing attempts involving compromised aliases.\n  We evaluate ProxyPrints on standard benchmark datasets and commercial fingerprint recognition systems, demonstrating that it preserves matching performance while offering strong security and revocability. Our open-source implementation includes tools for alias generation and deployment in real-world pipelines, making ProxyPrints a drop-in, scalable solution for fingerprint data protection.", "AI": {"tldr": "ProxyPrints\u662f\u4e00\u79cd\u53ef\u53d6\u6d88\u751f\u7269\u8bc6\u522b\u6280\u672f\uff0c\u4f5c\u4e3a\u4e2d\u95f4\u4ef6\u5c42\u5728\u4e0d\u4fee\u6539\u73b0\u6709\u6307\u7eb9\u8bc6\u522b\u7cfb\u7edf\u7684\u60c5\u51b5\u4e0b\u4fdd\u62a4\u6307\u7eb9\u6570\u636e\u5b89\u5168\uff0c\u63d0\u4f9b\u53ef\u64a4\u9500\u6027\u548c\u9632\u6b3a\u9a97\u68c0\u6d4b\u529f\u80fd\u3002", "motivation": "\u6307\u7eb9\u8bc6\u522b\u7cfb\u7edf\u5e7f\u6cdb\u90e8\u7f72\u4f46\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u5b58\u50a8\u7684\u6307\u7eb9\u6a21\u677f\u53ef\u80fd\u88ab\u9006\u5411\u5de5\u7a0b\u91cd\u5efa\u4e3a\u771f\u5b9e\u6307\u7eb9\u56fe\u50cf\uff0c\u5bfc\u81f4\u65e0\u6cd5\u4fee\u590d\u7684\u8eab\u4efd\u6cc4\u9732\u98ce\u9669\u3002", "method": "ProxyPrints\u4f5c\u4e3a\u900f\u660e\u4e2d\u95f4\u4ef6\u5c42\u90e8\u7f72\u5728\u6307\u7eb9\u626b\u63cf\u5668\u548c\u5339\u914d\u7b97\u6cd5\u4e4b\u95f4\uff0c\u5c06\u626b\u63cf\u7684\u6307\u7eb9\u8f6c\u6362\u4e3a\u4e00\u81f4\u4e14\u4e0d\u53ef\u94fe\u63a5\u7684\u522b\u540d\uff0c\u5b9e\u73b0\u53ef\u64a4\u9500\u751f\u7269\u8bc6\u522b\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\u548c\u5546\u4e1a\u6307\u7eb9\u8bc6\u522b\u7cfb\u7edf\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cProxyPrints\u5728\u4fdd\u6301\u5339\u914d\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u5f3a\u5927\u7684\u5b89\u5168\u6027\u548c\u53ef\u64a4\u9500\u6027\u3002", "conclusion": "ProxyPrints\u662f\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5f00\u6e90\u5b9e\u73b0\u63d0\u4f9b\u522b\u540d\u751f\u6210\u548c\u90e8\u7f72\u5de5\u5177\uff0c\u6709\u6548\u4fdd\u62a4\u6307\u7eb9\u6570\u636e\u5b89\u5168\u3002"}}
{"id": "2511.12743", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12743", "abs": "https://arxiv.org/abs/2511.12743", "authors": ["Adrita Rahman Tori", "Khondokar Fida Hasan"], "title": "An Evaluation Framework for Network IDS/IPS Datasets: Leveraging MITRE ATT&CK and Industry Relevance Metrics", "comment": "32 Pages", "summary": "The performance of Machine Learning (ML) and Deep Learning (DL)-based Intrusion Detection and Prevention Systems (IDS/IPS) is critically dependent on the relevance and quality of the datasets used for training and evaluation. However, current AI model evaluation practices for developing IDS/IPS focus predominantly on accuracy metrics, often overlooking whether datasets represent industry-specific threats. To address this gap, we introduce a novel multi-dimensional framework that integrates the MITRE ATT&CK knowledge base for threat intelligence and employs five complementary metrics that together provide a comprehensive assessment of dataset suitability. Methodologically, this framework combines threat intelligence, natural language processing, and quantitative analysis to assess the suitability of datasets for specific industry contexts. Applying this framework to nine publicly available IDS/IPS datasets reveals significant gaps in threat coverage, particularly in the healthcare, energy, and financial sectors. In particular, recent datasets (e.g., CIC-IoMT, CIC-UNSW-NB15) align better with sector-specific threats, whereas others, like CICIoV-24, underperform despite their recency. Our findings provide a standardized, interpretable approach for selecting datasets aligned with sector-specific operational requirements, ultimately enhancing the real-world effectiveness of AI-driven IDS/IPS deployments. The efficiency and practicality of the framework are validated through deployment in a real-world case study, underscoring its capacity to inform dataset selection and enhance the effectiveness of AI-driven IDS/IPS in operational environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u7ef4\u5ea6\u6846\u67b6\u6765\u8bc4\u4f30IDS/IPS\u6570\u636e\u96c6\u7684\u8d28\u91cf\uff0c\u7ed3\u5408MITRE ATT&CK\u5a01\u80c1\u60c5\u62a5\u548c\u4e94\u4e2a\u4e92\u8865\u6307\u6807\uff0c\u53d1\u73b0\u73b0\u6709\u6570\u636e\u96c6\u5728\u533b\u7597\u3001\u80fd\u6e90\u548c\u91d1\u878d\u7b49\u7279\u5b9a\u884c\u4e1a\u7684\u5a01\u80c1\u8986\u76d6\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u8bc4\u4f30\u5b9e\u8df5\u4e3b\u8981\u5173\u6ce8\u51c6\u786e\u5ea6\u6307\u6807\uff0c\u5f80\u5f80\u5ffd\u89c6\u6570\u636e\u96c6\u662f\u5426\u4ee3\u8868\u884c\u4e1a\u7279\u5b9a\u5a01\u80c1\uff0c\u5bfc\u81f4IDS/IPS\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u7ed3\u5408\u5a01\u80c1\u60c5\u62a5\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5b9a\u91cf\u5206\u6790\u7684\u591a\u7ef4\u5ea6\u6846\u67b6\uff0c\u4f7f\u7528MITRE ATT&CK\u77e5\u8bc6\u5e93\u548c\u4e94\u4e2a\u4e92\u8865\u6307\u6807\u6765\u8bc4\u4f30\u6570\u636e\u96c6\u5bf9\u7279\u5b9a\u884c\u4e1a\u73af\u5883\u7684\u9002\u7528\u6027\u3002", "result": "\u5bf9\u4e5d\u4e2a\u516c\u5f00IDS/IPS\u6570\u636e\u96c6\u7684\u5206\u6790\u663e\u793a\uff0c\u8fd1\u671f\u6570\u636e\u96c6\uff08\u5982CIC-IoMT\u3001CIC-UNSW-NB15\uff09\u4e0e\u884c\u4e1a\u7279\u5b9a\u5a01\u80c1\u66f4\u5339\u914d\uff0c\u800c\u5176\u4ed6\u6570\u636e\u96c6\uff08\u5982CICIoV-24\uff09\u5c3d\u7ba1\u8f83\u65b0\u4f46\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u3001\u80fd\u6e90\u548c\u91d1\u878d\u884c\u4e1a\u5b58\u5728\u663e\u8457\u5a01\u80c1\u8986\u76d6\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6807\u51c6\u5316\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u7b26\u5408\u884c\u4e1a\u7279\u5b9a\u64cd\u4f5c\u9700\u6c42\u7684\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6548\u7387\u548c\u5b9e\u7528\u6027\uff0c\u80fd\u591f\u63d0\u5347AI\u9a71\u52a8IDS/IPS\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.12169", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12169", "abs": "https://arxiv.org/abs/2511.12169", "authors": ["Kaiyue Zhao", "Dingqi Chen", "Shaoyu Wang", "Pan Hu"], "title": "Incremental Maintenance of DatalogMTL Materialisations", "comment": "Accepted as oral paper at the main track of AAAI 2026", "summary": "DatalogMTL extends the classical Datalog language with metric temporal logic (MTL), enabling expressive reasoning over temporal data. While existing reasoning approaches, such as materialisation based and automata based methods, offer soundness and completeness, they lack support for handling efficient dynamic updates, a crucial requirement for real-world applications that involve frequent data updates. In this work, we propose DRedMTL, an incremental reasoning algorithm for DatalogMTL with bounded intervals. Our algorithm builds upon the classical DRed algorithm, which incrementally updates the materialisation of a Datalog program. Unlike a Datalog materialisation which is in essence a finite set of facts, a DatalogMTL materialisation has to be represented as a finite set of facts plus periodic intervals indicating how the full materialisation can be constructed through unfolding. To cope with this, our algorithm is equipped with specifically designed operators to efficiently handle such periodic representations of DatalogMTL materialisations. We have implemented this approach and tested it on several publicly available datasets. Experimental results show that DRedMTL often significantly outperforms rematerialisation, sometimes by orders of magnitude.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DRedMTL\u7b97\u6cd5\uff0c\u4e00\u79cd\u652f\u6301\u6709\u754c\u533a\u95f4\u7684DatalogMTL\u589e\u91cf\u63a8\u7406\u65b9\u6cd5\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u52a8\u6001\u6570\u636e\u66f4\u65b0\uff0c\u76f8\u6bd4\u91cd\u65b0\u7269\u5316\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u7684DatalogMTL\u63a8\u7406\u65b9\u6cd5\u867d\u7136\u5177\u6709\u53ef\u9760\u6027\u548c\u5b8c\u5907\u6027\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u9ad8\u6548\u52a8\u6001\u66f4\u65b0\u7684\u652f\u6301\uff0c\u800c\u73b0\u5b9e\u5e94\u7528\u5f80\u5f80\u9700\u8981\u9891\u7e41\u7684\u6570\u636e\u66f4\u65b0\u3002", "method": "\u57fa\u4e8e\u7ecf\u5178\u7684DRed\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u64cd\u4f5c\u7b26\u6765\u5904\u7406DatalogMTL\u7269\u5316\u7684\u5468\u671f\u6027\u533a\u95f4\u8868\u793a\uff0c\u5b9e\u73b0\u589e\u91cf\u66f4\u65b0\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cDRedMTL\u901a\u5e38\u663e\u8457\u4f18\u4e8e\u91cd\u65b0\u7269\u5316\u65b9\u6cd5\uff0c\u6709\u65f6\u6027\u80fd\u63d0\u5347\u8fbe\u5230\u6570\u91cf\u7ea7\u3002", "conclusion": "DRedMTL\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86DatalogMTL\u4e2d\u9ad8\u6548\u589e\u91cf\u63a8\u7406\u7684\u95ee\u9898\uff0c\u4e3a\u5904\u7406\u52a8\u6001\u65f6\u5e8f\u6570\u636e\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12752", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12752", "abs": "https://arxiv.org/abs/2511.12752", "authors": ["Mukkesh Ganesh", "Kaushik Iyer", "Arun Baalaaji Sankar Ananthan"], "title": "Whose Narrative is it Anyway? A KV Cache Manipulation Attack", "comment": "7 pages, 10 figures", "summary": "The Key Value(KV) cache is an important component for efficient inference in autoregressive Large Language Models (LLMs), but its role as a representation of the model's internal state makes it a potential target for integrity attacks. This paper introduces \"History Swapping,\" a novel block-level attack that manipulates the KV cache to steer model generation without altering the user-facing prompt. The attack involves overwriting a contiguous segment of the active generation's cache with a precomputed cache from a different topic. We empirically evaluate this method across 324 configurations on the Qwen 3 family of models, analyzing the impact of timing, magnitude, and layer depth of the cache overwrite. Our findings reveal that only full-layer overwrites can successfully hijack the conversation's topic, leading to three distinct behaviors: immediate and persistent topic shift, partial recovery, or a delayed hijack. Furthermore, we observe that high-level structural plans are encoded early in the generation process and local discourse structure is maintained by the final layers of the model. This work demonstrates that the KV cache is a significant vector for security analysis, as it encodes not just context but also topic trajectory and structural planning, making it a powerful interface for manipulating model behavior.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"\u5386\u53f2\u4ea4\u6362\"\u7684\u65b0\u578bKV\u7f13\u5b58\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u4e0d\u6539\u53d8\u7528\u6237\u63d0\u793a\u7684\u60c5\u51b5\u4e0b\u64cd\u7eb5KV\u7f13\u5b58\u6765\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u65b9\u5411\uff0c\u63ed\u793a\u4e86KV\u7f13\u5b58\u4f5c\u4e3a\u5b89\u5168\u5206\u6790\u91cd\u8981\u5411\u91cf\u7684\u6f5c\u5728\u98ce\u9669\u3002", "motivation": "KV\u7f13\u5b58\u662f\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u9ad8\u6548\u63a8\u7406\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u4f46\u5176\u4f5c\u4e3a\u6a21\u578b\u5185\u90e8\u72b6\u6001\u8868\u793a\u7684\u7279\u6027\u4f7f\u5176\u53ef\u80fd\u6210\u4e3a\u5b8c\u6574\u6027\u653b\u51fb\u7684\u76ee\u6807\u3002\u7814\u7a76KV\u7f13\u5b58\u7684\u5b89\u5168\u6f0f\u6d1e\u5bf9\u4e8e\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u64cd\u7eb5\u673a\u5236\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\"\u5386\u53f2\u4ea4\u6362\"\u653b\u51fb\u65b9\u6cd5\uff0c\u5728\u5757\u7ea7\u522b\u64cd\u7eb5KV\u7f13\u5b58\uff0c\u5c06\u6d3b\u52a8\u751f\u6210\u7684\u8fde\u7eed\u7f13\u5b58\u6bb5\u7528\u6765\u81ea\u4e0d\u540c\u4e3b\u9898\u7684\u9884\u8ba1\u7b97\u7f13\u5b58\u8986\u76d6\uff0c\u5e76\u5728Qwen 3\u7cfb\u5217\u6a21\u578b\u7684324\u79cd\u914d\u7f6e\u4e0b\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53ea\u6709\u5168\u5c42\u8986\u76d6\u624d\u80fd\u6210\u529f\u52ab\u6301\u5bf9\u8bdd\u4e3b\u9898\uff0c\u4ea7\u751f\u4e09\u79cd\u4e0d\u540c\u884c\u4e3a\uff1a\u7acb\u5373\u4e14\u6301\u4e45\u7684\u4e3b\u9898\u8f6c\u6362\u3001\u90e8\u5206\u6062\u590d\u6216\u5ef6\u8fdf\u52ab\u6301\u3002\u9ad8\u5c42\u7ed3\u6784\u8ba1\u5212\u5728\u751f\u6210\u8fc7\u7a0b\u65e9\u671f\u7f16\u7801\uff0c\u5c40\u90e8\u8bdd\u8bed\u7ed3\u6784\u7531\u6a21\u578b\u6700\u540e\u5c42\u7ef4\u62a4\u3002", "conclusion": "KV\u7f13\u5b58\u4e0d\u4ec5\u662f\u4e0a\u4e0b\u6587\u8868\u793a\uff0c\u8fd8\u7f16\u7801\u4e86\u4e3b\u9898\u8f68\u8ff9\u548c\u7ed3\u6784\u89c4\u5212\uff0c\u4f7f\u5176\u6210\u4e3a\u64cd\u7eb5\u6a21\u578b\u884c\u4e3a\u7684\u5f3a\u5927\u63a5\u53e3\uff0c\u662f\u5b89\u5168\u5206\u6790\u7684\u91cd\u8981\u5411\u91cf\u3002"}}
{"id": "2511.12208", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12208", "abs": "https://arxiv.org/abs/2511.12208", "authors": ["Jilong Liu", "Pengyang Shao", "Wei Qin", "Fei Liu", "Yonghui Yang", "Richang Hong"], "title": "Debate over Mixed-knowledge: A Robust Multi-Agent Framework for Incomplete Knowledge Graph Question Answering", "comment": null, "summary": "Knowledge Graph Question Answering (KGQA) aims to improve factual accuracy by leveraging structured knowledge. However, real-world Knowledge Graphs (KGs) are often incomplete, leading to the problem of Incomplete KGQA (IKGQA). A common solution is to incorporate external data to fill knowledge gaps, but existing methods lack the capacity to adaptively and contextually fuse multiple sources, failing to fully exploit their complementary strengths. To this end, we propose Debate over Mixed-knowledge (DoM), a novel framework that enables dynamic integration of structured and unstructured knowledge for IKGQA. Built upon the Multi-Agent Debate paradigm, DoM assigns specialized agents to perform inference over knowledge graphs and external texts separately, and coordinates their outputs through iterative interaction. It decomposes the input question into sub-questions, retrieves evidence via dual agents (KG and Retrieval-Augmented Generation, RAG), and employs a judge agent to evaluate and aggregate intermediate answers. This collaboration exploits knowledge complementarity and enhances robustness to KG incompleteness. In addition, existing IKGQA datasets simulate incompleteness by randomly removing triples, failing to capture the irregular and unpredictable nature of real-world knowledge incompleteness. To address this, we introduce a new dataset, Incomplete Knowledge Graph WebQuestions, constructed by leveraging real-world knowledge updates. These updates reflect knowledge beyond the static scope of KGs, yielding a more realistic and challenging benchmark. Through extensive experiments, we show that DoM consistently outperforms state-of-the-art baselines.", "AI": {"tldr": "DoM\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u673a\u5236\u52a8\u6001\u878d\u5408\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u548c\u975e\u7ed3\u6784\u5316\u5916\u90e8\u77e5\u8bc6\uff0c\u89e3\u51b3\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u95ee\u9898\uff0c\u5e76\u5728\u65b0\u6784\u5efa\u7684\u66f4\u5177\u73b0\u5b9e\u6311\u6218\u6027\u7684\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u77e5\u8bc6\u56fe\u8c31\u5f80\u5f80\u4e0d\u5b8c\u6574\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u81ea\u9002\u5e94\u878d\u5408\u591a\u6e90\u77e5\u8bc6\u7684\u80fd\u529b\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u4e0d\u540c\u77e5\u8bc6\u6e90\u7684\u4e92\u8865\u4f18\u52bf\u3002", "method": "\u63d0\u51faDoM\u6846\u67b6\uff0c\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u8303\u5f0f\uff0c\u5206\u914d\u4e13\u95e8\u667a\u80fd\u4f53\u5206\u522b\u5904\u7406\u77e5\u8bc6\u56fe\u8c31\u548c\u5916\u90e8\u6587\u672c\u63a8\u7406\uff0c\u901a\u8fc7\u8fed\u4ee3\u4ea4\u4e92\u534f\u8c03\u8f93\u51fa\uff0c\u5305\u62ec\u95ee\u9898\u5206\u89e3\u3001\u53cc\u667a\u80fd\u4f53\u8bc1\u636e\u68c0\u7d22\u548c\u6cd5\u5b98\u667a\u80fd\u4f53\u8bc4\u4f30\u805a\u5408\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0cDoM\u6846\u67b6\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "DoM\u6846\u67b6\u901a\u8fc7\u77e5\u8bc6\u4e92\u8865\u6027\u5229\u7528\u548c\u589e\u5f3a\u5bf9\u77e5\u8bc6\u56fe\u8c31\u4e0d\u5b8c\u6574\u6027\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12214", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12214", "abs": "https://arxiv.org/abs/2511.12214", "authors": ["Ruochen Li", "Zhanxing Zhu", "Tanqiu Qiao", "Hubert P. H. Shum"], "title": "ViTE: Virtual Graph Trajectory Expert Router for Pedestrian Trajectory Prediction", "comment": null, "summary": "Pedestrian trajectory prediction is critical for ensuring safety in autonomous driving, surveillance systems, and urban planning applications. While early approaches primarily focus on one-hop pairwise relationships, recent studies attempt to capture high-order interactions by stacking multiple Graph Neural Network (GNN) layers. However, these approaches face a fundamental trade-off: insufficient layers may lead to under-reaching problems that limit the model's receptive field, while excessive depth can result in prohibitive computational costs. We argue that an effective model should be capable of adaptively modeling both explicit one-hop interactions and implicit high-order dependencies, rather than relying solely on architectural depth. To this end, we propose ViTE (Virtual graph Trajectory Expert router), a novel framework for pedestrian trajectory prediction. ViTE consists of two key modules: a Virtual Graph that introduces dynamic virtual nodes to model long-range and high-order interactions without deep GNN stacks, and an Expert Router that adaptively selects interaction experts based on social context using a Mixture-of-Experts design. This combination enables flexible and scalable reasoning across varying interaction patterns. Experiments on three benchmarks (ETH/UCY, NBA, and SDD) demonstrate that our method consistently achieves state-of-the-art performance, validating both its effectiveness and practical efficiency.", "AI": {"tldr": "ViTE\u6846\u67b6\u901a\u8fc7\u865a\u62df\u56fe\u548c\u4e13\u5bb6\u8def\u7531\u5668\u6a21\u5757\uff0c\u81ea\u9002\u5e94\u5efa\u6a21\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u4e2d\u7684\u663e\u5f0f\u5355\u8df3\u4ea4\u4e92\u548c\u9690\u5f0f\u9ad8\u9636\u4f9d\u8d56\uff0c\u907f\u514d\u4e86\u6df1\u5ea6GNN\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u4e2d\u4f20\u7edfGNN\u65b9\u6cd5\u9762\u4e34\u7684\u57fa\u672c\u6743\u8861\u95ee\u9898\uff1a\u5c42\u6570\u4e0d\u8db3\u5bfc\u81f4\u611f\u53d7\u91ce\u53d7\u9650\uff0c\u5c42\u6570\u8fc7\u591a\u5219\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002\u9700\u8981\u80fd\u591f\u81ea\u9002\u5e94\u5efa\u6a21\u663e\u5f0f\u5355\u8df3\u4ea4\u4e92\u548c\u9690\u5f0f\u9ad8\u9636\u4f9d\u8d56\u7684\u6709\u6548\u6a21\u578b\u3002", "method": "\u63d0\u51faViTE\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6a21\u5757\uff1a\u865a\u62df\u56fe\u5f15\u5165\u52a8\u6001\u865a\u62df\u8282\u70b9\u5efa\u6a21\u957f\u8ddd\u79bb\u548c\u9ad8\u9636\u4ea4\u4e92\uff0c\u65e0\u9700\u6df1\u5ea6GNN\u5806\u53e0\uff1b\u4e13\u5bb6\u8def\u7531\u5668\u57fa\u4e8e\u793e\u4ea4\u4e0a\u4e0b\u6587\u4f7f\u7528\u4e13\u5bb6\u6df7\u5408\u8bbe\u8ba1\u81ea\u9002\u5e94\u9009\u62e9\u4ea4\u4e92\u4e13\u5bb6\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08ETH/UCY\u3001NBA\u548cSDD\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u9645\u6548\u7387\u3002", "conclusion": "ViTE\u6846\u67b6\u901a\u8fc7\u865a\u62df\u56fe\u548c\u4e13\u5bb6\u8def\u7531\u5668\u7684\u7ec4\u5408\uff0c\u5b9e\u73b0\u4e86\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684\u4ea4\u4e92\u6a21\u5f0f\u63a8\u7406\uff0c\u5728\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e73\u8861\u4e86\u6027\u80fd\u4e0e\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2511.12827", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12827", "abs": "https://arxiv.org/abs/2511.12827", "authors": ["Ayush Chaudhary", "Sisir Doppalpudi"], "title": "Efficient Adversarial Malware Defense via Trust-Based Raw Override and Confidence-Adaptive Bit-Depth Reduction", "comment": "Accepted at IEEE International Conference on Big Data 2025. 10 pages, 2 figures, 8 tables", "summary": "The deployment of robust malware detection systems in big data environments requires careful consideration of both security effectiveness and computational efficiency. While recent advances in adversarial defenses have demonstrated strong robustness improvements, they often introduce computational overhead ranging from 4x to 22x, which presents significant challenges for production systems processing millions of samples daily. In this work, we propose a novel framework that combines Trust-Raw Override (TRO) with Confidence-Adaptive Bit-Depth Reduction (CABDR) to explicitly optimize the trade-off between adversarial robustness and computational efficiency. Our approach leverages adaptive confidence-based mechanisms to selectively apply defensive measures, achieving 1.76x computational overhead - a 2.3x improvement over state-of-the-art smoothing defenses. Through comprehensive evaluation on the EMBER v2 dataset comprising 800K samples, we demonstrate that our framework maintains 91 percent clean accuracy while reducing attack success rates to 31-37 percent across multiple attack types, with particularly strong performance against optimization-based attacks such as C and W (48.8 percent reduction). The framework achieves throughput of up to 1.26 million samples per second (measured on pre-extracted EMBER features with no runtime feature extraction), validated across 72 production configurations with statistical significance (5 independent runs, 95 percent confidence intervals, p less than 0.01). Our results suggest that practical adversarial robustness in production environments requires explicit optimization of the efficiency-robustness trade-off, providing a viable path for organizations to deploy robust defenses without prohibitive infrastructure costs.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408TRO\u548cCABDR\u7684\u65b0\u6846\u67b6\uff0c\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u4f18\u5316\u5bf9\u6297\u9c81\u68d2\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\u7684\u6743\u8861\uff0c\u5b9e\u73b01.76\u500d\u8ba1\u7b97\u5f00\u9500\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u53472.3\u500d\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u9632\u5fa1\u65b9\u6cd5\u867d\u7136\u63d0\u5347\u4e86\u9c81\u68d2\u6027\uff0c\u4f46\u5e26\u67654-22\u500d\u8ba1\u7b97\u5f00\u9500\uff0c\u5bf9\u5904\u7406\u767e\u4e07\u6837\u672c\u7684\u751f\u4ea7\u7cfb\u7edf\u6784\u6210\u91cd\u5927\u6311\u6218\u3002", "method": "\u7ed3\u5408\u4fe1\u4efb\u539f\u59cb\u8986\u76d6(TRO)\u548c\u7f6e\u4fe1\u5ea6\u81ea\u9002\u5e94\u4f4d\u6df1\u7f29\u51cf(CABDR)\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7f6e\u4fe1\u5ea6\u673a\u5236\u9009\u62e9\u6027\u5e94\u7528\u9632\u5fa1\u63aa\u65bd\u3002", "result": "\u5728EMBER v2\u6570\u636e\u96c6\u4e0a\u4fdd\u630191%\u6e05\u6d01\u51c6\u786e\u7387\uff0c\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u81f331-37%\uff0c\u5bf9C&W\u7b49\u4f18\u5316\u653b\u51fb\u51cf\u5c1148.8%\uff0c\u541e\u5410\u91cf\u8fbe126\u4e07\u6837\u672c/\u79d2\u3002", "conclusion": "\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u5bf9\u6297\u9c81\u68d2\u6027\u9700\u8981\u660e\u786e\u4f18\u5316\u6548\u7387-\u9c81\u68d2\u6027\u6743\u8861\uff0c\u4e3a\u7ec4\u7ec7\u90e8\u7f72\u9c81\u68d2\u9632\u5fa1\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.12239", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12239", "abs": "https://arxiv.org/abs/2511.12239", "authors": ["Tarun Gupta", "Danish Pruthi"], "title": "Beyond World Models: Rethinking Understanding in AI Models", "comment": "Accepted to AAAI 2026 (Main Track)", "summary": "World models have garnered substantial interest in the AI community. These are internal representations that simulate aspects of the external world, track entities and states, capture causal relationships, and enable prediction of consequences. This contrasts with representations based solely on statistical correlations. A key motivation behind this research direction is that humans possess such mental world models, and finding evidence of similar representations in AI models might indicate that these models \"understand\" the world in a human-like way. In this paper, we use case studies from the philosophy of science literature to critically examine whether the world model framework adequately characterizes human-level understanding. We focus on specific philosophical analyses where the distinction between world model capabilities and human understanding is most pronounced. While these represent particular views of understanding rather than universal definitions, they help us explore the limits of world models.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.12936", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12936", "abs": "https://arxiv.org/abs/2511.12936", "authors": ["Minjie Wang", "Jinguang Han", "Weizhi Meng"], "title": "Privacy-Preserving Federated Learning from Partial Decryption Verifiable Threshold Multi-Client Functional Encryption", "comment": null, "summary": "In federated learning, multiple parties can cooperate to train the model without directly exchanging their own private data, but the gradient leakage problem still threatens the privacy security and model integrity. Although the existing scheme uses threshold cryptography to mitigate the inference attack, it can not guarantee the verifiability of the aggregation results, making the system vulnerable to the threat of poisoning attack. We construct a partial decryption verifiable threshold multi client function encryption scheme, and apply it to Federated learning to implement the federated learning verifiable threshold security aggregation protocol (VTSAFL). VTSAFL empowers clients to verify aggregation results, concurrently minimizing both computational and communication overhead. The size of the functional key and partial decryption results of the scheme are constant, which provides efficiency guarantee for large-scale deployment. The experimental results on MNIST dataset show that vtsafl can achieve the same accuracy as the existing scheme, while reducing the total training time by more than 40%, and reducing the communication overhead by up to 50%. This efficiency is critical for overcoming the resource constraints inherent in Internet of Things (IoT) devices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u90a6\u5b66\u4e60\u53ef\u9a8c\u8bc1\u9608\u503c\u5b89\u5168\u805a\u5408\u534f\u8bae\uff08VTSAFL\uff09\uff0c\u901a\u8fc7\u90e8\u5206\u89e3\u5bc6\u53ef\u9a8c\u8bc1\u7684\u9608\u503c\u591a\u5ba2\u6237\u7aef\u51fd\u6570\u52a0\u5bc6\u65b9\u6848\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u786e\u4fdd\u805a\u5408\u7ed3\u679c\u7684\u53ef\u9a8c\u8bc1\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u68af\u5ea6\u6cc4\u6f0f\u95ee\u9898\u5a01\u80c1\u9690\u79c1\u5b89\u5168\u548c\u6a21\u578b\u5b8c\u6574\u6027\uff0c\u73b0\u6709\u65b9\u6848\u65e0\u6cd5\u4fdd\u8bc1\u805a\u5408\u7ed3\u679c\u7684\u53ef\u9a8c\u8bc1\u6027\uff0c\u4f7f\u7cfb\u7edf\u6613\u53d7\u6295\u6bd2\u653b\u51fb\u5a01\u80c1\u3002", "method": "\u6784\u5efa\u90e8\u5206\u89e3\u5bc6\u53ef\u9a8c\u8bc1\u7684\u9608\u503c\u591a\u5ba2\u6237\u7aef\u51fd\u6570\u52a0\u5bc6\u65b9\u6848\uff0c\u5e76\u5e94\u7528\u4e8e\u8054\u90a6\u5b66\u4e60\u5b9e\u73b0VTSAFL\u534f\u8bae\uff0c\u4f7f\u5ba2\u6237\u7aef\u80fd\u591f\u9a8c\u8bc1\u805a\u5408\u7ed3\u679c\u3002", "result": "\u5728MNIST\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVTSAFL\u80fd\u8fbe\u5230\u4e0e\u73b0\u6709\u65b9\u6848\u76f8\u540c\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u51cf\u5c11\u603b\u8bad\u7ec3\u65f6\u95f440%\u4ee5\u4e0a\uff0c\u901a\u4fe1\u5f00\u9500\u964d\u4f4e\u8fbe50%\u3002", "conclusion": "VTSAFL\u534f\u8bae\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u786e\u4fdd\u4e86\u805a\u5408\u7ed3\u679c\u7684\u53ef\u9a8c\u8bc1\u6027\uff0c\u4e3a\u7269\u8054\u7f51\u8bbe\u5907\u7b49\u8d44\u6e90\u53d7\u9650\u73af\u5883\u7684\u5927\u89c4\u6a21\u90e8\u7f72\u63d0\u4f9b\u4e86\u6548\u7387\u4fdd\u969c\u3002"}}
{"id": "2511.12241", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12241", "abs": "https://arxiv.org/abs/2511.12241", "authors": ["Junhyuk Seo", "Hyeyoon Moon", "Kyu-Hwan Jung", "Namkee Oh", "Taerim Kim"], "title": "AURA: Development and Validation of an Augmented Unplanned Removal Alert System using Synthetic ICU Videos", "comment": "12 pages, 5 figures", "summary": "Unplanned extubation (UE) remains a critical patient safety concern in intensive care units (ICUs), often leading to severe complications or death. Real-time UE detection has been limited, largely due to the ethical and privacy challenges of obtaining annotated ICU video data. We propose Augmented Unplanned Removal Alert (AURA), a vision-based risk detection system developed and validated entirely on a fully synthetic video dataset. By leveraging text-to-video diffusion, we generated diverse and clinically realistic ICU scenarios capturing a range of patient behaviors and care contexts. The system applies pose estimation to identify two high-risk movement patterns: collision, defined as hand entry into spatial zones near airway tubes, and agitation, quantified by the velocity of tracked anatomical keypoints. Expert assessments confirmed the realism of the synthetic data, and performance evaluations showed high accuracy for collision detection and moderate performance for agitation recognition. This work demonstrates a novel pathway for developing privacy-preserving, reproducible patient safety monitoring systems with potential for deployment in intensive care settings.", "AI": {"tldr": "AURA\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u7684\u98ce\u9669\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4f7f\u7528\u5b8c\u5168\u5408\u6210\u7684ICU\u89c6\u9891\u6570\u636e\u96c6\u5f00\u53d1\uff0c\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b\u975e\u8ba1\u5212\u6027\u62d4\u7ba1\u98ce\u9669\uff0c\u5305\u62ec\u78b0\u649e\u548c\u8e81\u52a8\u4e24\u79cd\u9ad8\u98ce\u9669\u8fd0\u52a8\u6a21\u5f0f\u3002", "motivation": "ICU\u4e2d\u975e\u8ba1\u5212\u6027\u62d4\u7ba1\u662f\u4e25\u91cd\u7684\u5b89\u5168\u95ee\u9898\uff0c\u4f46\u7531\u4e8e\u4f26\u7406\u548c\u9690\u79c1\u9650\u5236\uff0c\u83b7\u53d6\u5e26\u6807\u6ce8\u7684ICU\u89c6\u9891\u6570\u636e\u56f0\u96be\uff0c\u963b\u788d\u4e86\u5b9e\u65f6\u68c0\u6d4b\u7cfb\u7edf\u7684\u5f00\u53d1\u3002", "method": "\u5229\u7528\u6587\u672c\u5230\u89c6\u9891\u6269\u6563\u6280\u672f\u751f\u6210\u591a\u6837\u4e14\u4e34\u5e8a\u771f\u5b9e\u7684ICU\u573a\u666f\uff0c\u901a\u8fc7\u59ff\u6001\u4f30\u8ba1\u8bc6\u522b\u4e24\u79cd\u9ad8\u98ce\u9669\u6a21\u5f0f\uff1a\u624b\u90e8\u8fdb\u5165\u6c14\u9053\u7ba1\u9644\u8fd1\u533a\u57df\u7684\u78b0\u649e\uff0c\u4ee5\u53ca\u901a\u8fc7\u8ffd\u8e2a\u89e3\u5256\u5173\u952e\u70b9\u901f\u5ea6\u91cf\u5316\u7684\u8e81\u52a8\u3002", "result": "\u4e13\u5bb6\u8bc4\u4f30\u786e\u8ba4\u5408\u6210\u6570\u636e\u7684\u771f\u5b9e\u6027\uff0c\u6027\u80fd\u8bc4\u4f30\u663e\u793a\u78b0\u649e\u68c0\u6d4b\u51c6\u786e\u7387\u9ad8\uff0c\u8e81\u52a8\u8bc6\u522b\u6027\u80fd\u4e2d\u7b49\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u4e00\u79cd\u5f00\u53d1\u4fdd\u62a4\u9690\u79c1\u3001\u53ef\u590d\u73b0\u7684\u60a3\u8005\u5b89\u5168\u76d1\u6d4b\u7cfb\u7edf\u7684\u65b0\u9014\u5f84\uff0c\u5177\u6709\u5728ICU\u73af\u5883\u4e2d\u90e8\u7f72\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.12981", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.12981", "abs": "https://arxiv.org/abs/2511.12981", "authors": ["Palash Sarkar"], "title": "The Grain Family of Stream Ciphers: an Abstraction, Strengthening of Components and New Concrete Instantiations", "comment": null, "summary": "The first contribution of the paper is to put forward an abstract definition of the Grain family of stream ciphers which formalises the different components that are required to specify a particular member of the family. Our second contribution is to provide new and strengthened definitions of the components. These include definining new classes of nonlinear Boolean functions, improved definition of the state update function during initialisation, choice of the tap positions, and the possibility of the linear feedback shift register being smaller than the nonlinear feedback shift register. The third contribution of the paper is to put forward seven concrete proposals of stream ciphers by suitably instantiating the abstract family, one at the 80-bit security level, and two each at the 128-bit, 192-bit, and the 256-bit security levels. At the 80-bit security level, compared to the well known Grain~v1, the new proposal uses Boolean functions with improved cryptographic properties \\textit{and} an overall lower gate count. At the 128-bit level, compared to ISO/IEC standard Grain-128a, the new proposals use Boolean functions with improved cryptographic properties; one of the proposals require a few extra gates, while the other has an overall lower gate count. At the 192-bit, and the 256-bit security levels, there are no proposals in the literature with smaller gate counts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Grain\u6d41\u5bc6\u7801\u5bb6\u65cf\u7684\u62bd\u8c61\u5b9a\u4e49\uff0c\u6539\u8fdb\u4e86\u7ec4\u4ef6\u8bbe\u8ba1\uff0c\u5e76\u63d0\u51fa\u4e867\u4e2a\u5177\u4f53\u5bc6\u7801\u65b9\u6848\uff0c\u5206\u522b\u9488\u5bf980\u4f4d\u3001128\u4f4d\u3001192\u4f4d\u548c256\u4f4d\u5b89\u5168\u7ea7\u522b\u3002", "motivation": "\u4e3aGrain\u6d41\u5bc6\u7801\u5bb6\u65cf\u63d0\u4f9b\u66f4\u5f62\u5f0f\u5316\u7684\u62bd\u8c61\u5b9a\u4e49\uff0c\u5e76\u6539\u8fdb\u5176\u7ec4\u4ef6\u8bbe\u8ba1\u4ee5\u589e\u5f3a\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faGrain\u5bb6\u65cf\u7684\u62bd\u8c61\u5b9a\u4e49\uff0c\u6539\u8fdb\u975e\u7ebf\u6027\u5e03\u5c14\u51fd\u6570\u3001\u72b6\u6001\u66f4\u65b0\u51fd\u6570\u3001\u62bd\u5934\u4f4d\u7f6e\u9009\u62e9\u7b49\u7ec4\u4ef6\uff0c\u5e76\u5b9e\u4f8b\u53167\u4e2a\u5177\u4f53\u5bc6\u7801\u65b9\u6848\u3002", "result": "\u572880\u4f4d\u5b89\u5168\u7ea7\u522b\uff0c\u65b0\u65b9\u6848\u6bd4Grain~v1\u5177\u6709\u66f4\u597d\u7684\u5bc6\u7801\u5b66\u7279\u6027\u548c\u66f4\u4f4e\u7684\u95e8\u6570\uff1b\u5728128\u4f4d\u7ea7\u522b\uff0c\u6bd4Grain-128a\u6709\u6539\u8fdb\uff1b\u5728192\u4f4d\u548c256\u4f4d\u7ea7\u522b\uff0c\u63d0\u4f9b\u4e86\u6587\u732e\u4e2d\u95e8\u6570\u6700\u5c0f\u7684\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u5b9a\u4e49\u548c\u6539\u8fdb\u7ec4\u4ef6\u8bbe\u8ba1\uff0c\u6210\u529f\u6784\u5efa\u4e86\u66f4\u5b89\u5168\u9ad8\u6548\u7684Grain\u6d41\u5bc6\u7801\u5bb6\u65cf\u6210\u5458\uff0c\u8986\u76d6\u591a\u4e2a\u5b89\u5168\u7ea7\u522b\u3002"}}
{"id": "2511.12982", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12982", "abs": "https://arxiv.org/abs/2511.12982", "authors": ["Xuankun Rong", "Wenke Huang", "Tingfeng Wang", "Daiguo Zhou", "Bo Du", "Mang Ye"], "title": "SafeGRPO: Self-Rewarded Multimodal Safety Alignment via Rule-Governed Policy Optimization", "comment": null, "summary": "Multimodal large language models (MLLMs) have demonstrated impressive reasoning and instruction-following capabilities, yet their expanded modality space introduces new compositional safety risks that emerge from complex text-image interactions. Such cross-modal couplings can produce unsafe semantics even when individual inputs are benign, exposing the fragile safety awareness of current MLLMs. While recent works enhance safety by guiding models to reason about potential risks, unregulated reasoning traces may compromise alignment; although Group Relative Policy Optimization (GRPO) offers self-rewarded refinement without human supervision, it lacks verifiable signals for reasoning safety. To address this, we propose SafeGRPO a self-rewarded multimodal safety alignment framework that integrates rule-governed reward construction into GRPO, enabling interpretable and verifiable optimization of reasoning safety. Built upon the constructed SafeTag-VL-3K dataset with explicit visual, textual, and combined safety tags, SafeGRPO performs step-guided safety thinking to enforce structured reasoning and behavior alignment, substantially improving multimodal safety awareness, compositional robustness, and reasoning stability across diverse benchmarks without sacrificing general capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSafeGRPO\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u89c4\u5219\u6cbb\u7406\u7684\u5956\u52b1\u6784\u5efa\u5230GRPO\u4e2d\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7ec4\u5408\u5b89\u5168\u98ce\u9669\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u7406\u5b89\u5168\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6269\u5c55\u6a21\u6001\u7a7a\u95f4\u65f6\u5f15\u5165\u4e86\u65b0\u7684\u7ec4\u5408\u5b89\u5168\u98ce\u9669\uff0c\u5373\u4f7f\u5355\u4e2a\u8f93\u5165\u65e0\u5bb3\uff0c\u8de8\u6a21\u6001\u8026\u5408\u4e5f\u53ef\u80fd\u4ea7\u751f\u4e0d\u5b89\u5168\u8bed\u4e49\uff0c\u66b4\u9732\u5f53\u524d\u6a21\u578b\u7684\u5b89\u5168\u610f\u8bc6\u8106\u5f31\u6027\u3002", "method": "\u63d0\u51faSafeGRPO\u6846\u67b6\uff0c\u5728\u6784\u5efa\u7684SafeTag-VL-3K\u6570\u636e\u96c6\u57fa\u7840\u4e0a\uff0c\u96c6\u6210\u89c4\u5219\u6cbb\u7406\u7684\u5956\u52b1\u6784\u5efa\u5230GRPO\u4e2d\uff0c\u6267\u884c\u6b65\u9aa4\u5f15\u5bfc\u7684\u5b89\u5168\u601d\u8003\u6765\u5f3a\u5236\u7ed3\u6784\u5316\u63a8\u7406\u548c\u884c\u4e3a\u5bf9\u9f50\u3002", "result": "\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u5b89\u5168\u610f\u8bc6\u3001\u7ec4\u5408\u9c81\u68d2\u6027\u548c\u63a8\u7406\u7a33\u5b9a\u6027\uff0c\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u4e0d\u727a\u7272\u901a\u7528\u80fd\u529b\u3002", "conclusion": "SafeGRPO\u901a\u8fc7\u81ea\u6211\u5956\u52b1\u7684\u591a\u6a21\u6001\u5b89\u5168\u5bf9\u9f50\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u548c\u53ef\u9a8c\u8bc1\u7684\u63a8\u7406\u5b89\u5168\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u7684\u7ec4\u5408\u5b89\u5168\u98ce\u9669\u95ee\u9898\u3002"}}
{"id": "2511.13143", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13143", "abs": "https://arxiv.org/abs/2511.13143", "authors": ["Gorka Abad", "Marina Kr\u010dek", "Stefanos Koffas", "Behrad Tajalli", "Marco Arazzi", "Roberto Ria\u00f1o", "Xiaoyun Xu", "Zhuoran Liu", "Antonino Nocera", "Stjepan Picek"], "title": "SoK: The Last Line of Defense: On Backdoor Defense Evaluation", "comment": null, "summary": "Backdoor attacks pose a significant threat to deep learning models by implanting hidden vulnerabilities that can be activated by malicious inputs. While numerous defenses have been proposed to mitigate these attacks, the heterogeneous landscape of evaluation methodologies hinders fair comparison between defenses. This work presents a systematic (meta-)analysis of backdoor defenses through a comprehensive literature review and empirical evaluation. We analyzed 183 backdoor defense papers published between 2018 and 2025 across major AI and security venues, examining the properties and evaluation methodologies of these defenses.\n  Our analysis reveals significant inconsistencies in experimental setups, evaluation metrics, and threat model assumptions in the literature. Through extensive experiments involving three datasets (MNIST, CIFAR-100, ImageNet-1K), four model architectures (ResNet-18, VGG-19, ViT-B/16, DenseNet-121), 16 representative defenses, and five commonly used attacks, totaling over 3\\,000 experiments, we demonstrate that defense effectiveness varies substantially across different evaluation setups. We identify critical gaps in current evaluation practices, including insufficient reporting of computational overhead and behavior under benign conditions, bias in hyperparameter selection, and incomplete experimentation. Based on our findings, we provide concrete challenges and well-motivated recommendations to standardize and improve future defense evaluations. Our work aims to equip researchers and industry practitioners with actionable insights for developing, assessing, and deploying defenses to different systems.", "AI": {"tldr": "\u672c\u6587\u5bf9\u540e\u95e8\u9632\u5fa1\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u5143\u5206\u6790\uff0c\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u5b9e\u8bc1\u8bc4\u4f30\u63ed\u793a\u4e86\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u57fa\u4e8e\u5927\u89c4\u6a21\u5b9e\u9a8c\u63d0\u51fa\u4e86\u6807\u51c6\u5316\u5efa\u8bae\u3002", "motivation": "\u540e\u95e8\u653b\u51fb\u5bf9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u4f46\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u7684\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5f02\u8d28\u6027\uff0c\u963b\u788d\u4e86\u516c\u5e73\u6bd4\u8f83\u3002", "method": "\u5206\u6790\u4e86183\u7bc7\u540e\u95e8\u9632\u5fa1\u8bba\u6587\uff0c\u5e76\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u9a8c\uff0c\u6d89\u53ca3\u4e2a\u6570\u636e\u96c6\u30014\u79cd\u6a21\u578b\u67b6\u6784\u300116\u79cd\u4ee3\u8868\u6027\u9632\u5fa1\u548c5\u79cd\u5e38\u7528\u653b\u51fb\uff0c\u603b\u8ba1\u8d85\u8fc73000\u6b21\u5b9e\u9a8c\u3002", "result": "\u53d1\u73b0\u5b9e\u9a8c\u8bbe\u7f6e\u3001\u8bc4\u4f30\u6307\u6807\u548c\u5a01\u80c1\u6a21\u578b\u5047\u8bbe\u5b58\u5728\u663e\u8457\u4e0d\u4e00\u81f4\u6027\uff0c\u9632\u5fa1\u6548\u679c\u5728\u4e0d\u540c\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u5dee\u5f02\u5f88\u5927\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5177\u4f53\u6311\u6218\u548c\u57fa\u4e8e\u5b9e\u8bc1\u7684\u5efa\u8bae\uff0c\u65e8\u5728\u6807\u51c6\u5316\u548c\u6539\u8fdb\u672a\u6765\u7684\u9632\u5fa1\u8bc4\u4f30\u5b9e\u8df5\u3002"}}
{"id": "2511.12344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12344", "abs": "https://arxiv.org/abs/2511.12344", "authors": ["Baolong Bi", "Shenghua Liu", "Yiwei Wang", "Siqian Tong", "Lingrui Mei", "Yuyao Ge", "Yilong Xu", "Jiafeng Guo", "Xueqi Cheng"], "title": "Reward and Guidance through Rubrics: Promoting Exploration to Improve Multi-Domain Reasoning", "comment": null, "summary": "Recent advances in reinforcement learning (RL) have significantly improved the complex reasoning capabilities of large language models (LLMs). Despite these successes, existing methods mainly focus on single-domain RL (e.g., mathematics) with verifiable rewards (RLVR), and their reliance on purely online RL frameworks restricts the exploration space, thereby limiting reasoning performance. In this paper, we address these limitations by leveraging rubrics to provide both fine-grained reward signals and offline guidance. We propose $\\textbf{RGR-GRPO}$ (Reward and Guidance through Rubrics), a rubric-driven RL framework for multi-domain reasoning. RGR-GRPO enables LLMs to receive dense and informative rewards while exploring a larger solution space during GRPO training. Extensive experiments across 14 benchmarks spanning multiple domains demonstrate that RGR-GRPO consistently outperforms RL methods that rely solely on alternative reward schemes or offline guidance. Compared with verifiable online RL baseline, RGR-GRPO achieves average improvements of +7.0%, +5.4%, +8.4%, and +6.6% on mathematics, physics, chemistry, and general reasoning tasks, respectively. Notably, RGR-GRPO maintains stable entropy fluctuations during off-policy training and achieves superior pass@k performance, reflecting sustained exploration and effective breakthrough beyond existing performance bottlenecks.", "AI": {"tldr": "RGR-GRPO\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u5956\u52b1\u4fe1\u53f7\u548c\u79bb\u7ebf\u6307\u5bfc\uff0c\u5728\u591a\u9886\u57df\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5c40\u9650\u4e8e\u5355\u4e00\u9886\u57df\u548c\u53ef\u9a8c\u8bc1\u5956\u52b1\uff0c\u4e14\u4f9d\u8d56\u7eaf\u5728\u7ebfRL\u6846\u67b6\u9650\u5236\u4e86\u63a2\u7d22\u7a7a\u95f4\uff0c\u4ece\u800c\u9650\u5236\u4e86\u63a8\u7406\u6027\u80fd\u3002", "method": "\u63d0\u51faRGR-GRPO\u6846\u67b6\uff0c\u5229\u7528\u8bc4\u5206\u6807\u51c6\u63d0\u4f9b\u5bc6\u96c6\u4fe1\u606f\u5956\u52b1\u548c\u79bb\u7ebf\u6307\u5bfc\uff0c\u5728GRPO\u8bad\u7ec3\u4e2d\u63a2\u7d22\u66f4\u5927\u7684\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u3002", "result": "\u572814\u4e2a\u591a\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRGR-GRPO\u59cb\u7ec8\u4f18\u4e8e\u4ec5\u4f9d\u8d56\u66ff\u4ee3\u5956\u52b1\u65b9\u6848\u6216\u79bb\u7ebf\u6307\u5bfc\u7684RL\u65b9\u6cd5\u3002\u76f8\u6bd4\u53ef\u9a8c\u8bc1\u5728\u7ebfRL\u57fa\u7ebf\uff0c\u5728\u6570\u5b66\u3001\u7269\u7406\u3001\u5316\u5b66\u548c\u901a\u7528\u63a8\u7406\u4efb\u52a1\u4e0a\u5206\u522b\u5e73\u5747\u63d0\u53477.0%\u30015.4%\u30018.4%\u548c6.6%\u3002", "conclusion": "RGR-GRPO\u5728\u79bb\u7b56\u7565\u8bad\u7ec3\u4e2d\u4fdd\u6301\u7a33\u5b9a\u7684\u71b5\u6ce2\u52a8\uff0c\u5b9e\u73b0\u5353\u8d8a\u7684pass@k\u6027\u80fd\uff0c\u53cd\u6620\u4e86\u6301\u7eed\u7684\u63a2\u7d22\u548c\u6709\u6548\u7a81\u7834\u73b0\u6709\u6027\u80fd\u74f6\u9888\u3002"}}
{"id": "2511.13246", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.13246", "abs": "https://arxiv.org/abs/2511.13246", "authors": ["Qin Guo", "Haonan Tong", "Sihua Wang", "Peiyuan Si", "Jun Zhao", "Changchuan Yin"], "title": "A Secure Semantic Communication System Based on Knowledge Graph", "comment": "accepted by IEEE Journal of Communications and Networks (JCN)", "summary": "This study proposes a novel approach to ensure the security of textual data transmission in a semantic communication system. In the proposed system, a sender transmits textual information to a receiver, while a potential eavesdropper attempts to intercept the information. At the sender side, the text is initially preprocessed, where each sentence is annotated with its corresponding topic, and subsequently extracted into a knowledge graph. To achieve the secure transmission of the knowledge graph, we propose a channel encryption scheme that integrates constellation diagonal transformation with multi-parameter weighted fractional Fourier transform (MP-WFRFT). At the receiver side, the textual data is first decrypted, and then recovered via a transformer model. Experimental results demonstrate that the proposed method reduces the probability of information compromise. The legitimate receiver achieves a Bilingual Evaluation Understudy (BLEU) score of 0.9, whereas the BLEU score of the eavesdropper remains below 0.3. Compared to the baselines, the proposed method can improve the security by up to 20%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u4e2d\u6587\u672c\u6570\u636e\u4f20\u8f93\u5b89\u5168\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\u548c\u4fe1\u9053\u52a0\u5bc6\u65b9\u6848\uff0c\u7ed3\u5408\u661f\u5ea7\u5bf9\u89d2\u53d8\u6362\u548c\u591a\u53c2\u6570\u52a0\u6743\u5206\u6570\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u786e\u4fdd\u5408\u6cd5\u63a5\u6536\u8005\u80fd\u9ad8\u8d28\u91cf\u6062\u590d\u6587\u672c\uff0c\u800c\u7a83\u542c\u8005\u83b7\u53d6\u7684\u4fe1\u606f\u8d28\u91cf\u5f88\u4f4e\u3002", "motivation": "\u5728\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u6587\u672c\u6570\u636e\u4f20\u8f93\u9762\u4e34\u88ab\u7a83\u542c\u7684\u98ce\u9669\uff0c\u9700\u8981\u786e\u4fdd\u53ea\u6709\u5408\u6cd5\u63a5\u6536\u8005\u80fd\u6b63\u786e\u7406\u89e3\u4fe1\u606f\u5185\u5bb9\uff0c\u800c\u7a83\u542c\u8005\u65e0\u6cd5\u83b7\u53d6\u6709\u6548\u4fe1\u606f\u3002", "method": "\u53d1\u9001\u7aef\u5bf9\u6587\u672c\u8fdb\u884c\u9884\u5904\u7406\uff0c\u6807\u6ce8\u53e5\u5b50\u4e3b\u9898\u5e76\u63d0\u53d6\u4e3a\u77e5\u8bc6\u56fe\u8c31\uff1b\u91c7\u7528\u661f\u5ea7\u5bf9\u89d2\u53d8\u6362\u4e0e\u591a\u53c2\u6570\u52a0\u6743\u5206\u6570\u5085\u91cc\u53f6\u53d8\u6362\u7684\u4fe1\u9053\u52a0\u5bc6\u65b9\u6848\uff1b\u63a5\u6536\u7aef\u5148\u89e3\u5bc6\uff0c\u518d\u901a\u8fc7transformer\u6a21\u578b\u6062\u590d\u6587\u672c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5408\u6cd5\u63a5\u6536\u8005\u7684BLEU\u5f97\u5206\u8fbe\u52300.9\uff0c\u800c\u7a83\u542c\u8005\u7684BLEU\u5f97\u5206\u4f4e\u4e8e0.3\uff1b\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b89\u5168\u6027\u63d0\u5347\u6700\u9ad8\u8fbe20%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u4f4e\u4fe1\u606f\u6cc4\u9732\u6982\u7387\uff0c\u5728\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u5b89\u5168\u7684\u6587\u672c\u6570\u636e\u4f20\u8f93\u3002"}}
{"id": "2511.12378", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12378", "abs": "https://arxiv.org/abs/2511.12378", "authors": ["Dylan M. Asmar", "Mykel J. Kochenderfer"], "title": "Learning to Trust: Bayesian Adaptation to Varying Suggester Reliability in Sequential Decision Making", "comment": "Under Review", "summary": "Autonomous agents operating in sequential decision-making tasks under uncertainty can benefit from external action suggestions, which provide valuable guidance but inherently vary in reliability. Existing methods for incorporating such advice typically assume static and known suggester quality parameters, limiting practical deployment. We introduce a framework that dynamically learns and adapts to varying suggester reliability in partially observable environments. First, we integrate suggester quality directly into the agent's belief representation, enabling agents to infer and adjust their reliance on suggestions through Bayesian inference over suggester types. Second, we introduce an explicit ``ask'' action allowing agents to strategically request suggestions at critical moments, balancing informational gains against acquisition costs. Experimental evaluation demonstrates robust performance across varying suggester qualities, adaptation to changing reliability, and strategic management of suggestion requests. This work provides a foundation for adaptive human-agent collaboration by addressing suggestion uncertainty in uncertain environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001\u5b66\u4e60\u5efa\u8bae\u8005\u53ef\u9760\u6027\u7684\u6846\u67b6\uff0c\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u81ea\u9002\u5e94\u5730\u6574\u5408\u5916\u90e8\u884c\u52a8\u5efa\u8bae\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u63a8\u7406\u63a8\u65ad\u5efa\u8bae\u8005\u7c7b\u578b\uff0c\u5e76\u5f15\u5165\u6218\u7565\u6027\u7684\"\u8be2\u95ee\"\u52a8\u4f5c\u6765\u5e73\u8861\u4fe1\u606f\u83b7\u53d6\u4e0e\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5efa\u8bae\u8005\u8d28\u91cf\u53c2\u6570\u662f\u9759\u6001\u4e14\u5df2\u77e5\u7684\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002\u81ea\u4e3b\u667a\u80fd\u4f53\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u8fdb\u884c\u987a\u5e8f\u51b3\u7b56\u65f6\uff0c\u9700\u8981\u80fd\u591f\u52a8\u6001\u9002\u5e94\u53d8\u5316\u5efa\u8bae\u8005\u53ef\u9760\u6027\u7684\u65b9\u6cd5\u3002", "method": "1. \u5c06\u5efa\u8bae\u8005\u8d28\u91cf\u76f4\u63a5\u6574\u5408\u5230\u667a\u80fd\u4f53\u7684\u4fe1\u5ff5\u8868\u793a\u4e2d\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u63a8\u7406\u63a8\u65ad\u5efa\u8bae\u8005\u7c7b\u578b\uff1b2. \u5f15\u5165\u663e\u5f0f\u7684\"\u8be2\u95ee\"\u52a8\u4f5c\uff0c\u5141\u8bb8\u667a\u80fd\u4f53\u5728\u5173\u952e\u65f6\u523b\u6218\u7565\u6027\u5730\u8bf7\u6c42\u5efa\u8bae\uff0c\u5e73\u8861\u4fe1\u606f\u589e\u76ca\u4e0e\u83b7\u53d6\u6210\u672c\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u5efa\u8bae\u8005\u8d28\u91cf\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u80fd\u591f\u9002\u5e94\u53d8\u5316\u7684\u53ef\u9760\u6027\uff0c\u5e76\u6709\u6548\u7ba1\u7406\u5efa\u8bae\u8bf7\u6c42\u7b56\u7565\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u89e3\u51b3\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u5efa\u8bae\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u81ea\u9002\u5e94\u4eba\u673a\u534f\u4f5c\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\u3002"}}
{"id": "2511.13319", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13319", "abs": "https://arxiv.org/abs/2511.13319", "authors": ["Chelsea McMurray", "Hayder Tirmazi"], "title": "Whistledown: Combining User-Level Privacy with Conversational Coherence in LLMs", "comment": null, "summary": "Users increasingly rely on large language models (LLMs) for personal, emotionally charged, and socially sensitive conversations. However, prompts sent to cloud-hosted models can contain personally identifiable information (PII) that users do not want logged, retained, or leaked. We observe this to be especially acute when users discuss friends, coworkers, or adversaries, i.e., when they spill the tea. Enterprises face the same challenge when they want to use LLMs for internal communication and decision-making.\n  In this whitepaper, we present Whistledown, a best-effort privacy layer that modifies prompts before they are sent to the LLM. Whistledown combines pseudonymization and $\u03b5$-local differential privacy ($\u03b5$-LDP) with transformation caching to provide best-effort privacy protection without sacrificing conversational utility. Whistledown is designed to have low compute and memory overhead, allowing it to be deployed directly on a client's device in the case of individual users. For enterprise users, Whistledown is deployed centrally within a zero-trust gateway that runs on an enterprise's trusted infrastructure. Whistledown requires no changes to the existing APIs of popular LLM providers.", "AI": {"tldr": "Whistledown\u662f\u4e00\u4e2a\u4e3aLLM\u63d0\u4f9b\u5c3d\u529b\u800c\u4e3a\u9690\u79c1\u4fdd\u62a4\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f2a\u540d\u5316\u548c\u03b5-\u5c40\u90e8\u5dee\u5206\u9690\u79c1\u6280\u672f\u4fee\u6539\u63d0\u793a\uff0c\u9632\u6b62\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\u6cc4\u9732\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u8bdd\u5b9e\u7528\u6027\u3002", "motivation": "\u7528\u6237\u5728\u4f7f\u7528LLM\u8fdb\u884c\u4e2a\u4eba\u3001\u60c5\u611f\u5316\u548c\u793e\u4ea4\u654f\u611f\u5bf9\u8bdd\u65f6\uff0c\u63d0\u793a\u4e2d\u53ef\u80fd\u5305\u542b\u4e0d\u5e0c\u671b\u88ab\u8bb0\u5f55\u3001\u4fdd\u7559\u6216\u6cc4\u9732\u7684\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\uff0c\u4f01\u4e1a\u548c\u4e2a\u4eba\u7528\u6237\u90fd\u9762\u4e34\u8fd9\u4e00\u9690\u79c1\u6311\u6218\u3002", "method": "\u7ed3\u5408\u4f2a\u540d\u5316\u548c\u03b5-\u5c40\u90e8\u5dee\u5206\u9690\u79c1\u6280\u672f\uff0c\u901a\u8fc7\u8f6c\u6362\u7f13\u5b58\u673a\u5236\u4fee\u6539\u53d1\u9001\u7ed9LLM\u7684\u63d0\u793a\uff0c\u7cfb\u7edf\u8bbe\u8ba1\u4e3a\u4f4e\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\uff0c\u53ef\u90e8\u7f72\u5728\u5ba2\u6237\u7aef\u8bbe\u5907\u6216\u4f01\u4e1a\u96f6\u4fe1\u4efb\u7f51\u5173\u4e2d\u3002", "result": "Whistledown\u63d0\u4f9b\u4e86\u5c3d\u529b\u800c\u4e3a\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709LLM\u63d0\u4f9b\u5546\u7684API\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u5bf9\u8bdd\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "Whistledown\u662f\u4e00\u4e2a\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u727a\u7272\u5bf9\u8bdd\u5b9e\u7528\u6027\u7684\u524d\u63d0\u4e0b\u4fdd\u62a4\u7528\u6237\u9690\u79c1\uff0c\u9002\u7528\u4e8e\u4e2a\u4eba\u548c\u4f01\u4e1a\u7528\u6237\u7684\u4e0d\u540c\u90e8\u7f72\u573a\u666f\u3002"}}
{"id": "2511.12439", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.12439", "abs": "https://arxiv.org/abs/2511.12439", "authors": ["Yujia Liu", "Sophia Yu", "Hongyue Jin", "Jessica Wen", "Alexander Qian", "Terrence Lee", "Mattheus Ramsis", "Gi Won Choi", "Lianhui Qin", "Xin Liu", "Edward J. Wang"], "title": "Multi-agent Self-triage System with Medical Flowcharts", "comment": null, "summary": "Online health resources and large language models (LLMs) are increasingly used as a first point of contact for medical decision-making, yet their reliability in healthcare remains limited by low accuracy, lack of transparency, and susceptibility to unverified information. We introduce a proof-of-concept conversational self-triage system that guides LLMs with 100 clinically validated flowcharts from the American Medical Association, providing a structured and auditable framework for patient decision support. The system leverages a multi-agent framework consisting of a retrieval agent, a decision agent, and a chat agent to identify the most relevant flowchart, interpret patient responses, and deliver personalized, patient-friendly recommendations, respectively. Performance was evaluated at scale using synthetic datasets of simulated conversations. The system achieved 95.29% top-3 accuracy in flowchart retrieval (N=2,000) and 99.10% accuracy in flowchart navigation across varied conversational styles and conditions (N=37,200). By combining the flexibility of free-text interaction with the rigor of standardized clinical protocols, this approach demonstrates the feasibility of transparent, accurate, and generalizable AI-assisted self-triage, with potential to support informed patient decision-making while improving healthcare resource utilization.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u5f0f\u81ea\u6211\u5206\u8bca\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u4f7f\u7528100\u4e2a\u7ecf\u8fc7\u4e34\u5e8a\u9a8c\u8bc1\u7684\u6d41\u7a0b\u56fe\u6765\u6307\u5bfc\u533b\u7597\u51b3\u7b56\uff0c\u5b9e\u73b0\u4e8695.29%\u7684\u6d41\u7a0b\u56fe\u68c0\u7d22\u51c6\u786e\u7387\u548c99.10%\u7684\u5bfc\u822a\u51c6\u786e\u7387\u3002", "motivation": "\u5728\u7ebf\u5065\u5eb7\u8d44\u6e90\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u51b3\u7b56\u4e2d\u7684\u53ef\u9760\u6027\u53d7\u5230\u51c6\u786e\u6027\u4f4e\u3001\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u6613\u53d7\u672a\u7ecf\u9a8c\u8bc1\u4fe1\u606f\u5f71\u54cd\u7684\u9650\u5236\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u7ed3\u6784\u5316\u6846\u67b6\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u62ec\u68c0\u7d22\u667a\u80fd\u4f53\u3001\u51b3\u7b56\u667a\u80fd\u4f53\u548c\u804a\u5929\u667a\u80fd\u4f53\uff0c\u7ed3\u5408\u7f8e\u56fd\u533b\u5b66\u4f1a\u7684100\u4e2a\u4e34\u5e8a\u9a8c\u8bc1\u6d41\u7a0b\u56fe\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6846\u67b6\u652f\u6301\u60a3\u8005\u51b3\u7b56\u3002", "result": "\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6d41\u7a0b\u56fe\u68c0\u7d22\u8fbe\u523095.29%\u7684top-3\u51c6\u786e\u7387\uff08N=2,000\uff09\uff0c\u6d41\u7a0b\u56fe\u5bfc\u822a\u8fbe\u523099.10%\u7684\u51c6\u786e\u7387\uff08N=37,200\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u81ea\u7531\u6587\u672c\u4ea4\u4e92\u7684\u7075\u6d3b\u6027\u548c\u6807\u51c6\u5316\u4e34\u5e8a\u534f\u8bae\u7684\u4e25\u8c28\u6027\uff0c\u5c55\u793a\u4e86\u900f\u660e\u3001\u51c6\u786e\u4e14\u53ef\u63a8\u5e7f\u7684AI\u8f85\u52a9\u81ea\u6211\u5206\u8bca\u7684\u53ef\u884c\u6027\uff0c\u6709\u671b\u652f\u6301\u60a3\u8005\u77e5\u60c5\u51b3\u7b56\u5e76\u6539\u5584\u533b\u7597\u8d44\u6e90\u5229\u7528\u3002"}}
{"id": "2511.12485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12485", "abs": "https://arxiv.org/abs/2511.12485", "authors": ["Pengze Li", "Jiaqi Liu", "Junchi Yu", "Lihao Liu", "Mingyu Ding", "Wanli Ouyang", "Shixiang Tang", "Xi Chen"], "title": "ARCHE: A Novel Task to Evaluate LLMs on Latent Reasoning Chain Extraction", "comment": "Accepted to AAAI 2026", "summary": "Large language models (LLMs) are increasingly used in scientific domains. While they can produce reasoning-like content via methods such as chain-of-thought prompting, these outputs are typically unstructured and informal, obscuring whether models truly understand the fundamental reasoning paradigms that underpin scientific inference. To address this, we introduce a novel task named Latent Reasoning Chain Extraction (ARCHE), in which models must decompose complex reasoning arguments into combinations of standard reasoning paradigms in the form of a Reasoning Logic Tree (RLT). In RLT, all reasoning steps are explicitly categorized as one of three variants of Peirce's fundamental inference modes: deduction, induction, or abduction. To facilitate this task, we release ARCHE Bench, a new benchmark derived from 70 Nature Communications articles, including more than 1,900 references and 38,000 viewpoints. We propose two logic-aware evaluation metrics: Entity Coverage (EC) for content completeness and Reasoning Edge Accuracy (REA) for step-by-step logical validity. Evaluations on 10 leading LLMs on ARCHE Bench reveal that models exhibit a trade-off between REA and EC, and none are yet able to extract a complete and standard reasoning chain. These findings highlight a substantial gap between the abilities of current reasoning models and the rigor required for scientific argumentation.", "AI": {"tldr": "\u63d0\u51faARCHE\u4efb\u52a1\uff0c\u8981\u6c42\u6a21\u578b\u5c06\u590d\u6742\u63a8\u7406\u5206\u89e3\u4e3a\u6807\u51c6\u63a8\u7406\u8303\u5f0f\u7ec4\u6210\u7684\u63a8\u7406\u903b\u8f91\u6811(RLT)\uff0c\u5305\u542b\u6f14\u7ece\u3001\u5f52\u7eb3\u548c\u6eaf\u56e0\u4e09\u79cd\u63a8\u7406\u6a21\u5f0f\u3002\u57fa\u4e8e70\u7bc7Nature Communications\u6587\u7ae0\u6784\u5efaARCHE Bench\u57fa\u51c6\uff0c\u8bc4\u4f30\u53d1\u73b0\u5f53\u524dLLMs\u5728\u63a8\u7406\u94fe\u63d0\u53d6\u4e0a\u5b58\u5728\u5b8c\u6574\u6027\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u65e0\u6cd5\u8fbe\u5230\u79d1\u5b66\u8bba\u8bc1\u6240\u9700\u7684\u4e25\u8c28\u6027\u3002", "motivation": "\u5f53\u524dLLMs\u867d\u7136\u80fd\u901a\u8fc7\u601d\u7ef4\u94fe\u7b49\u65b9\u6cd5\u4ea7\u751f\u7c7b\u4f3c\u63a8\u7406\u7684\u5185\u5bb9\uff0c\u4f46\u8fd9\u4e9b\u8f93\u51fa\u901a\u5e38\u662f\u975e\u7ed3\u6784\u5316\u548c\u975e\u6b63\u5f0f\u7684\uff0c\u96be\u4ee5\u5224\u65ad\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u79d1\u5b66\u63a8\u7406\u7684\u57fa\u672c\u8303\u5f0f\u3002", "method": "\u5f15\u5165ARCHE\u4efb\u52a1\uff0c\u8981\u6c42\u6a21\u578b\u5c06\u590d\u6742\u63a8\u7406\u5206\u89e3\u4e3a\u63a8\u7406\u903b\u8f91\u6811(RLT)\uff0c\u660e\u786e\u5206\u7c7b\u4e3a\u6f14\u7ece\u3001\u5f52\u7eb3\u6216\u6eaf\u56e0\u4e09\u79cd\u63a8\u7406\u6a21\u5f0f\u3002\u6784\u5efaARCHE Bench\u57fa\u51c6\uff0c\u5305\u542b1900\u591a\u4e2a\u53c2\u8003\u6587\u732e\u548c38000\u591a\u4e2a\u89c2\u70b9\u3002\u63d0\u51fa\u5b9e\u4f53\u8986\u76d6\u5ea6(EC)\u548c\u63a8\u7406\u8fb9\u51c6\u786e\u7387(REA)\u4e24\u4e2a\u903b\u8f91\u611f\u77e5\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5bf910\u4e2a\u9886\u5148LLMs\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u6a21\u578b\u5728REA\u548cEC\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u6ca1\u6709\u4e00\u4e2a\u6a21\u578b\u80fd\u591f\u63d0\u53d6\u5b8c\u6574\u4e14\u6807\u51c6\u7684\u63a8\u7406\u94fe\u3002", "conclusion": "\u5f53\u524d\u63a8\u7406\u6a21\u578b\u7684\u80fd\u529b\u4e0e\u79d1\u5b66\u8bba\u8bc1\u6240\u9700\u7684\u4e25\u8c28\u6027\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u5bf9\u57fa\u672c\u63a8\u7406\u8303\u5f0f\u7684\u7406\u89e3\u548c\u5e94\u7528\u80fd\u529b\u3002"}}
{"id": "2511.13356", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13356", "abs": "https://arxiv.org/abs/2511.13356", "authors": ["Lei Wang", "Yulong Tian", "Hao Han", "Fengyuan Xu"], "title": "Enhancing All-to-X Backdoor Attacks with Optimized Target Class Mapping", "comment": null, "summary": "Backdoor attacks pose severe threats to machine learning systems, prompting extensive research in this area. However, most existing work focuses on single-target All-to-One (A2O) attacks, overlooking the more complex All-to-X (A2X) attacks with multiple target classes, which are often assumed to have low attack success rates. In this paper, we first demonstrate that A2X attacks are robust against state-of-the-art defenses. We then propose a novel attack strategy that enhances the success rate of A2X attacks while maintaining robustness by optimizing grouping and target class assignment mechanisms. Our method improves the attack success rate by up to 28%, with average improvements of 6.7%, 16.4%, 14.1% on CIFAR10, CIFAR100, and Tiny-ImageNet, respectively. We anticipate that this study will raise awareness of A2X attacks and stimulate further research in this under-explored area. Our code is available at https://github.com/kazefjj/A2X-backdoor .", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u540e\u95e8\u653b\u51fb\u7b56\u7565\uff0c\u9488\u5bf9\u591a\u76ee\u6807\u7c7b\u522b\u7684All-to-X(A2X)\u653b\u51fb\uff0c\u901a\u8fc7\u4f18\u5316\u5206\u7ec4\u548c\u76ee\u6807\u7c7b\u522b\u5206\u914d\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u6210\u529f\u7387\u5e76\u4fdd\u6301\u4e86\u5bf9\u73b0\u6709\u9632\u5fa1\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u653b\u51fb\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u76ee\u6807All-to-One\u653b\u51fb\uff0c\u5ffd\u89c6\u4e86\u66f4\u590d\u6742\u7684\u591a\u76ee\u6807A2X\u653b\u51fb\uff0c\u800c\u540e\u8005\u901a\u5e38\u88ab\u8ba4\u4e3a\u653b\u51fb\u6210\u529f\u7387\u8f83\u4f4e\u3002\u672c\u6587\u65e8\u5728\u8bc1\u660eA2X\u653b\u51fb\u7684\u5a01\u80c1\u6027\u5e76\u63d0\u5347\u5176\u653b\u51fb\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u653b\u51fb\u7b56\u7565\uff0c\u901a\u8fc7\u4f18\u5316\u5206\u7ec4\u548c\u76ee\u6807\u7c7b\u522b\u5206\u914d\u673a\u5236\u6765\u589e\u5f3aA2X\u653b\u51fb\u7684\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u6700\u5148\u8fdb\u9632\u5fa1\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728CIFAR10\u3001CIFAR100\u548cTiny-ImageNet\u6570\u636e\u96c6\u4e0a\uff0c\u653b\u51fb\u6210\u529f\u7387\u6700\u9ad8\u63d0\u5347\u4e8628%\uff0c\u5e73\u5747\u5206\u522b\u63d0\u5347\u4e866.7%\u300116.4%\u548c14.1%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u9ad8\u4e86\u5bf9A2X\u653b\u51fb\u5a01\u80c1\u7684\u8ba4\u8bc6\uff0c\u5e76\u4fc3\u8fdb\u4e86\u8fd9\u4e00\u672a\u5145\u5206\u63a2\u7d22\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2511.12563", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12563", "abs": "https://arxiv.org/abs/2511.12563", "authors": ["Eljas Linna", "Kestutis Baltakys", "Alexandros Iosifidis", "Juho Kanniainen"], "title": "LOBERT: Generative AI Foundation Model for Limit Order Book Messages", "comment": "Submission for NeurIPS 2025 GenAI in Finance Workshop", "summary": "Modeling the dynamics of financial Limit Order Books (LOB) at the message level is challenging due to irregular event timing, rapid regime shifts, and the reactions of high-frequency traders to visible order flow. Previous LOB models require cumbersome data representations and lack adaptability outside their original tasks, leading us to introduce LOBERT, a general-purpose encoder-only foundation model for LOB data suitable for downstream fine-tuning. LOBERT adapts the original BERT architecture for LOB data by using a novel tokenization scheme that treats complete multi-dimensional messages as single tokens while retaining continuous representations of price, volume, and time. With these methods, LOBERT achieves leading performance in tasks such as predicting mid-price movements and next messages, while reducing the required context length compared to previous methods.", "AI": {"tldr": "LOBERT\u662f\u4e00\u4e2a\u4e13\u4e3a\u9650\u4ef7\u8ba2\u5355\u7c3f\u6570\u636e\u8bbe\u8ba1\u7684\u901a\u7528\u7f16\u7801\u5668\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u6807\u8bb0\u5316\u65b9\u6848\u5904\u7406\u591a\u7ef4\u6d88\u606f\uff0c\u5728\u9884\u6d4b\u4e2d\u95f4\u4ef7\u683c\u53d8\u52a8\u548c\u4e0b\u4e00\u6d88\u606f\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709LOB\u6a21\u578b\u9700\u8981\u7e41\u7410\u7684\u6570\u636e\u8868\u793a\uff0c\u4e14\u7f3a\u4e4f\u5728\u539f\u59cb\u4efb\u52a1\u4e4b\u5916\u7684\u9002\u5e94\u6027\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u901a\u7528\u7684\u57fa\u7840\u6a21\u578b\u3002", "method": "LOBERT\u57fa\u4e8eBERT\u67b6\u6784\uff0c\u91c7\u7528\u65b0\u9896\u7684\u6807\u8bb0\u5316\u65b9\u6848\u5c06\u5b8c\u6574\u7684\u591a\u7ef4\u6d88\u606f\u4f5c\u4e3a\u5355\u4e2a\u6807\u8bb0\u5904\u7406\uff0c\u540c\u65f6\u4fdd\u7559\u4ef7\u683c\u3001\u6570\u91cf\u548c\u65f6\u95f4\u7684\u8fde\u7eed\u8868\u793a\u3002", "result": "LOBERT\u5728\u9884\u6d4b\u4e2d\u95f4\u4ef7\u683c\u53d8\u52a8\u548c\u4e0b\u4e00\u6d88\u606f\u7b49\u4efb\u52a1\u4e2d\u53d6\u5f97\u9886\u5148\u6027\u80fd\uff0c\u540c\u65f6\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\u51cf\u5c11\u4e86\u6240\u9700\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002", "conclusion": "LOBERT\u4e3aLOB\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u901a\u7528\u57fa\u7840\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u4e0b\u6e38\u5fae\u8c03\u4efb\u52a1\u3002"}}
{"id": "2511.13365", "categories": ["cs.CR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.13365", "abs": "https://arxiv.org/abs/2511.13365", "authors": ["Ruijun Deng", "Zhihui Lu", "Qiang Duan"], "title": "InfoDecom: Decomposing Information for Defending against Privacy Leakage in Split Inference", "comment": "Accepted by AAAI 2026", "summary": "Split inference (SI) enables users to access deep learning (DL) services without directly transmitting raw data. However, recent studies reveal that data reconstruction attacks (DRAs) can recover the original inputs from the smashed data sent from the client to the server, leading to significant privacy leakage. While various defenses have been proposed, they often result in substantial utility degradation, particularly when the client-side model is shallow. We identify a key cause of this trade-off: existing defenses apply excessive perturbation to redundant information in the smashed data. To address this issue in computer vision tasks, we propose InfoDecom, a defense framework that first decomposes and removes redundant information and then injects noise calibrated to provide theoretically guaranteed privacy. Experiments demonstrate that InfoDecom achieves a superior utility-privacy trade-off compared to existing baselines. The code and the appendix are available at https://github.com/SASA-cloud/InfoDecom.", "AI": {"tldr": "InfoDecom\u662f\u4e00\u4e2a\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u548c\u79fb\u9664\u5197\u4f59\u4fe1\u606f\uff0c\u7136\u540e\u6ce8\u5165\u7ecf\u8fc7\u6821\u51c6\u7684\u566a\u58f0\uff0c\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u6548\u7528-\u9690\u79c1\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u5272\u63a8\u7406\u9632\u5fa1\u65b9\u6cd5\u5728\u5ba2\u6237\u7aef\u6a21\u578b\u8f83\u6d45\u65f6\u4f1a\u5bfc\u81f4\u663e\u8457\u7684\u6548\u7528\u4e0b\u964d\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u73b0\u6709\u9632\u5fa1\u5bf9\u5197\u4f59\u4fe1\u606f\u65bd\u52a0\u4e86\u8fc7\u591a\u6270\u52a8\u3002", "method": "\u63d0\u51faInfoDecom\u6846\u67b6\uff0c\u9996\u5148\u5206\u89e3\u5e76\u79fb\u9664\u5197\u4f59\u4fe1\u606f\uff0c\u7136\u540e\u6ce8\u5165\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u9690\u79c1\u7684\u6821\u51c6\u566a\u58f0\u3002", "result": "\u5b9e\u9a8c\u8868\u660eInfoDecom\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6548\u7528-\u9690\u79c1\u6743\u8861\u3002", "conclusion": "InfoDecom\u901a\u8fc7\u4fe1\u606f\u5206\u89e3\u548c\u6821\u51c6\u566a\u58f0\u6ce8\u5165\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5272\u63a8\u7406\u4e2d\u7684\u6570\u636e\u91cd\u5efa\u653b\u51fb\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6a21\u578b\u6548\u7528\u3002"}}
{"id": "2511.12579", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12579", "abs": "https://arxiv.org/abs/2511.12579", "authors": ["Yongwen Ren", "Chao Wang", "Peng Du", "Chuan Qin", "Dazhong Shen", "Hui Xiong"], "title": "Enhancing Conversational Recommender Systems with Tree-Structured Knowledge and Pretrained Language Models", "comment": null, "summary": "Recent advances in pretrained language models (PLMs) have significantly improved conversational recommender systems (CRS), enabling more fluent and context-aware interactions. To further enhance accuracy and mitigate hallucination, many methods integrate PLMs with knowledge graphs (KGs), but face key challenges: failing to fully exploit PLM reasoning over graph relationships, indiscriminately incorporating retrieved knowledge without context filtering, and neglecting collaborative preferences in multi-turn dialogues. To this end, we propose PCRS-TKA, a prompt-based framework employing retrieval-augmented generation to integrate PLMs with KGs. PCRS-TKA constructs dialogue-specific knowledge trees from KGs and serializes them into texts, enabling structure-aware reasoning while capturing rich entity semantics. Our approach selectively filters context-relevant knowledge and explicitly models collaborative preferences using specialized supervision signals. A semantic alignment module harmonizes heterogeneous inputs, reducing noise and enhancing accuracy. Extensive experiments demonstrate that PCRS-TKA consistently outperforms all baselines in both recommendation and conversational quality.", "AI": {"tldr": "PCRS-TKA\u662f\u4e00\u4e2a\u57fa\u4e8e\u63d0\u793a\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e0e\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528PLM\u5728\u56fe\u5173\u7cfb\u4e0a\u7684\u63a8\u7406\u80fd\u529b\u3001\u65e0\u5dee\u522b\u6574\u5408\u68c0\u7d22\u77e5\u8bc6\u4ee5\u53ca\u5ffd\u89c6\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u534f\u4f5c\u504f\u597d\u7684\u5173\u952e\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5c06PLM\u4e0eKG\u96c6\u6210\u65f6\u9762\u4e34\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u672a\u80fd\u5145\u5206\u5229\u7528PLM\u5728\u56fe\u5173\u7cfb\u4e0a\u7684\u63a8\u7406\u80fd\u529b\u3001\u65e0\u5dee\u522b\u6574\u5408\u68c0\u7d22\u77e5\u8bc6\u800c\u4e0d\u8fdb\u884c\u4e0a\u4e0b\u6587\u8fc7\u6ee4\u3001\u4ee5\u53ca\u5ffd\u89c6\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u534f\u4f5c\u504f\u597d\u3002", "method": "PCRS-TKA\u6784\u5efa\u5bf9\u8bdd\u7279\u5b9a\u7684\u77e5\u8bc6\u6811\u5e76\u5c06\u5176\u5e8f\u5217\u5316\u4e3a\u6587\u672c\uff0c\u5b9e\u73b0\u7ed3\u6784\u611f\u77e5\u63a8\u7406\uff1b\u9009\u62e9\u6027\u8fc7\u6ee4\u4e0a\u4e0b\u6587\u76f8\u5173\u77e5\u8bc6\uff1b\u4f7f\u7528\u4e13\u95e8\u76d1\u7763\u4fe1\u53f7\u663e\u5f0f\u5efa\u6a21\u534f\u4f5c\u504f\u597d\uff1b\u901a\u8fc7\u8bed\u4e49\u5bf9\u9f50\u6a21\u5757\u534f\u8c03\u5f02\u6784\u8f93\u5165\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cPCRS-TKA\u5728\u63a8\u8350\u548c\u5bf9\u8bdd\u8d28\u91cf\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "PCRS-TKA\u901a\u8fc7\u96c6\u6210PLM\u4e0eKG\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u5bf9\u8bdd\u8d28\u91cf\u3002"}}
{"id": "2511.13502", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.13502", "abs": "https://arxiv.org/abs/2511.13502", "authors": ["Yuyang Xia", "Ruixuan Liu", "Li Xiong"], "title": "Tight and Practical Privacy Auditing for Differentially Private In-Context Learning", "comment": null, "summary": "Large language models (LLMs) perform in-context learning (ICL) by adapting to tasks from prompt demonstrations, which in practice often contain private or proprietary data. Although differential privacy (DP) with private voting is a pragmatic mitigation, DP-ICL implementations are error-prone, and worst-case DP bounds may substantially overestimate actual leakage, calling for practical auditing tools. We present a tight and efficient privacy auditing framework for DP-ICL systems that runs membership inference attacks and translates their success rates into empirical privacy guarantees using Gaussian DP. Our analysis of the private voting mechanism identifies vote configurations that maximize the auditing signal, guiding the design of audit queries that reliably reveal whether a canary demonstration is present in the context. The framework supports both black-box (API-only) and white-box (internal vote) threat models, and unifies auditing for classification and generation by reducing both to a binary decision problem. Experiments on standard text classification and generation benchmarks show that our empirical leakage estimates closely match theoretical DP budgets on classification tasks and are consistently lower on generation tasks due to conservative embedding-sensitivity bounds, making our framework a practical privacy auditor and verifier for real-world DP-ICL deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u5dee\u5206\u9690\u79c1\u4e0a\u4e0b\u6587\u5b66\u4e60\u7cfb\u7edf\u7684\u9690\u79c1\u5ba1\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u6210\u5458\u63a8\u7406\u653b\u51fb\u5c06\u653b\u51fb\u6210\u529f\u7387\u8f6c\u6362\u4e3a\u7ecf\u9a8c\u9690\u79c1\u4fdd\u8bc1\uff0c\u652f\u6301\u9ed1\u76d2\u548c\u767d\u76d2\u5a01\u80c1\u6a21\u578b\u3002", "motivation": "\u73b0\u6709DP-ICL\u5b9e\u73b0\u5bb9\u6613\u51fa\u9519\uff0c\u4e14\u6700\u574f\u60c5\u51b5DP\u8fb9\u754c\u53ef\u80fd\u4e25\u91cd\u9ad8\u4f30\u5b9e\u9645\u6cc4\u6f0f\uff0c\u9700\u8981\u5b9e\u7528\u7684\u5ba1\u8ba1\u5de5\u5177\u6765\u9a8c\u8bc1\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u3002", "method": "\u4f7f\u7528\u9ad8\u65af\u5dee\u5206\u9690\u79c1\uff0c\u901a\u8fc7\u5206\u6790\u79c1\u6709\u6295\u7968\u673a\u5236\u8bc6\u522b\u6700\u5927\u5316\u5ba1\u8ba1\u4fe1\u53f7\u7684\u6295\u7968\u914d\u7f6e\uff0c\u8bbe\u8ba1\u5ba1\u8ba1\u67e5\u8be2\u6765\u53ef\u9760\u68c0\u6d4bcanary\u6f14\u793a\u662f\u5426\u5b58\u5728\u4e8e\u4e0a\u4e0b\u6587\u4e2d\u3002", "result": "\u5728\u6807\u51c6\u6587\u672c\u5206\u7c7b\u548c\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7ecf\u9a8c\u6cc4\u6f0f\u4f30\u8ba1\u4e0e\u5206\u7c7b\u4efb\u52a1\u7684\u7406\u8bbaDP\u9884\u7b97\u7d27\u5bc6\u5339\u914d\uff0c\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u7531\u4e8e\u4fdd\u5b88\u7684\u5d4c\u5165\u654f\u611f\u5ea6\u8fb9\u754c\u800c\u59cb\u7ec8\u8f83\u4f4e\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u4f5c\u4e3a\u5b9e\u9645DP-ICL\u90e8\u7f72\u7684\u5b9e\u7528\u9690\u79c1\u5ba1\u8ba1\u5668\u548c\u9a8c\u8bc1\u5668\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u63d0\u4f9b\u53ef\u9760\u7684\u9690\u79c1\u4fdd\u62a4\u9a8c\u8bc1\u3002"}}
{"id": "2511.12677", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12677", "abs": "https://arxiv.org/abs/2511.12677", "authors": ["Oliver Joergensen", "Dominik Drexler", "Jendrik Seipp"], "title": "Dynamic Tree Databases in Automated Planning", "comment": null, "summary": "A central challenge in scaling up explicit state-space search for large tasks is compactly representing the set of generated states. Tree databases, a data structure from model checking, require constant space per generated state in the best case, but they need a large preallocation of memory. We propose a novel dynamic variant of tree databases for compressing state sets over propositional and numeric variables and prove that it maintains the desirable properties of the static counterpart. Our empirical evaluation of state compression techniques for grounded and lifted planning on classical and numeric planning tasks reveals compression ratios of several orders of magnitude, often with negligible runtime overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u6811\u6570\u636e\u5e93\u53d8\u4f53\uff0c\u7528\u4e8e\u538b\u7f29\u547d\u9898\u548c\u6570\u503c\u53d8\u91cf\u4e0a\u7684\u72b6\u6001\u96c6\uff0c\u5728\u4fdd\u6301\u9759\u6001\u5bf9\u5e94\u7269\u7406\u60f3\u7279\u6027\u7684\u540c\u65f6\uff0c\u65e0\u9700\u5927\u91cf\u5185\u5b58\u9884\u5206\u914d\u3002", "motivation": "\u5728\u5927\u578b\u4efb\u52a1\u4e2d\u6269\u5c55\u663e\u5f0f\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\u65f6\uff0c\u7d27\u51d1\u8868\u793a\u751f\u6210\u72b6\u6001\u96c6\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\u3002\u4f20\u7edf\u6811\u6570\u636e\u5e93\u9700\u8981\u5927\u91cf\u5185\u5b58\u9884\u5206\u914d\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u52a8\u6001\u53d8\u4f53\u7684\u6811\u6570\u636e\u5e93\uff0c\u7528\u4e8e\u538b\u7f29\u547d\u9898\u548c\u6570\u503c\u53d8\u91cf\u4e0a\u7684\u72b6\u6001\u96c6\uff0c\u5e76\u8bc1\u660e\u5176\u4fdd\u6301\u4e86\u9759\u6001\u5bf9\u5e94\u7269\u7684\u7406\u60f3\u7279\u6027\u3002", "result": "\u5728\u7ecf\u5178\u548c\u6570\u503c\u89c4\u5212\u4efb\u52a1\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0c\u538b\u7f29\u6bd4\u8fbe\u5230\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u901a\u5e38\u8fd0\u884c\u65f6\u5f00\u9500\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u52a8\u6001\u6811\u6570\u636e\u5e93\u5728\u72b6\u6001\u538b\u7f29\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5927\u89c4\u6a21\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12754", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.12754", "abs": "https://arxiv.org/abs/2511.12754", "authors": ["Benjamin Li", "Shuyang Shi", "Lucia Romero", "Huao Li", "Yaqi Xie", "Woojun Kim", "Stefanos Nikolaidis", "Michael Lewis", "Katia Sycara", "Simon Stepputtis"], "title": "Adaptively Coordinating with Novel Partners via Learned Latent Strategies", "comment": "Accepted to NeurIPS 2025", "summary": "Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult. In this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. Our approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type. For online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction. We evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space. Through these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b56\u7565\u6761\u4ef6\u5316\u7684\u5408\u4f5c\u8005\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5b9e\u65f6\u534f\u4f5c\u4efb\u52a1\u4e2d\u8868\u793a\u3001\u5206\u7c7b\u548c\u9002\u5e94\u5e7f\u6cdb\u7684\u6f5c\u5728\u5408\u4f5c\u4f19\u4f34\u7b56\u7565\uff0c\u5728\u590d\u6742\u534f\u4f5c\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5728\u4eba\u7c7b-\u667a\u80fd\u4f53\u56e2\u961f\u4e2d\uff0c\u4eba\u5de5\u667a\u80fd\u4f53\u9700\u8981\u5b9e\u65f6\u9002\u5e94\u5176\u4eba\u7c7b\u4f19\u4f34\u7684\u72ec\u7279\u504f\u597d\u548c\u52a8\u6001\u53d8\u5316\u7684\u7b56\u7565\uff0c\u8fd9\u5728\u65f6\u95f4\u538b\u529b\u548c\u590d\u6742\u6218\u7565\u7a7a\u95f4\u7684\u4efb\u52a1\u4e2d\u5c24\u4e3a\u56f0\u96be\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7f16\u7801\u7b56\u7565\u4ee5\u5b66\u4e60\u6f5c\u5728\u7b56\u7565\u7a7a\u95f4\uff0c\u901a\u8fc7\u805a\u7c7b\u8bc6\u522b\u4e0d\u540c\u7b56\u7565\u7c7b\u578b\uff0c\u8bad\u7ec3\u57fa\u4e8e\u8fd9\u4e9b\u805a\u7c7b\u7684\u6761\u4ef6\u5316\u5408\u4f5c\u8005\u667a\u80fd\u4f53\uff0c\u5e76\u5229\u7528\u56fa\u5b9a\u4efd\u989d\u9057\u61be\u6700\u5c0f\u5316\u7b97\u6cd5\u8fdb\u884c\u5728\u7ebf\u9002\u5e94\u3002", "result": "\u5728\u4fee\u6539\u7248\u7684Overcooked\u534f\u4f5c\u70f9\u996a\u73af\u5883\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4e0e\u65b0\u9896\u4eba\u7c7b\u548c\u667a\u80fd\u4f53\u961f\u53cb\u914d\u5bf9\u65f6\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b56\u7565\u6761\u4ef6\u5316\u5408\u4f5c\u8005\u6846\u67b6\u80fd\u591f\u6709\u6548\u9002\u5e94\u5e7f\u6cdb\u7684\u5408\u4f5c\u4f19\u4f34\u7b56\u7565\uff0c\u5728\u590d\u6742\u534f\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.13548", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13548", "abs": "https://arxiv.org/abs/2511.13548", "authors": ["Siyang Cheng", "Gaotian Liu", "Rui Mei", "Yilin Wang", "Kejia Zhang", "Kaishuo Wei", "Yuqi Yu", "Weiping Wen", "Xiaojie Wu", "Junhua Liu"], "title": "ForgeDAN: An Evolutionary Framework for Jailbreaking Aligned Large Language Models", "comment": null, "summary": "The rapid adoption of large language models (LLMs) has brought both transformative applications and new security risks, including jailbreak attacks that bypass alignment safeguards to elicit harmful outputs. Existing automated jailbreak generation approaches e.g. AutoDAN, suffer from limited mutation diversity, shallow fitness evaluation, and fragile keyword-based detection. To address these limitations, we propose ForgeDAN, a novel evolutionary framework for generating semantically coherent and highly effective adversarial prompts against aligned LLMs. First, ForgeDAN introduces multi-strategy textual perturbations across \\textit{character, word, and sentence-level} operations to enhance attack diversity; then we employ interpretable semantic fitness evaluation based on a text similarity model to guide the evolutionary process toward semantically relevant and harmful outputs; finally, ForgeDAN integrates dual-dimensional jailbreak judgment, leveraging an LLM-based classifier to jointly assess model compliance and output harmfulness, thereby reducing false positives and improving detection effectiveness. Our evaluation demonstrates ForgeDAN achieves high jailbreaking success rates while maintaining naturalness and stealth, outperforming existing SOTA solutions.", "AI": {"tldr": "ForgeDAN\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7b56\u7565\u6587\u672c\u6270\u52a8\u3001\u53ef\u89e3\u91ca\u8bed\u4e49\u9002\u5e94\u5ea6\u8bc4\u4f30\u548c\u53cc\u7ef4\u5ea6\u8d8a\u72f1\u5224\u65ad\uff0c\u751f\u6210\u8bed\u4e49\u8fde\u8d2f\u4e14\u9ad8\u6548\u7684\u5bf9\u6297\u6027\u63d0\u793a\u6765\u653b\u51fb\u5bf9\u9f50LLMs\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u8d8a\u72f1\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u7a81\u53d8\u591a\u6837\u6027\u6709\u9650\u3001\u9002\u5e94\u5ea6\u8bc4\u4f30\u6d45\u5c42\u548c\u57fa\u4e8e\u5173\u952e\u8bcd\u68c0\u6d4b\u8106\u5f31\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5b57\u7b26\u3001\u8bcd\u548c\u53e5\u5b50\u7ea7\u522b\u7684\u591a\u7b56\u7565\u6587\u672c\u6270\u52a8\u589e\u5f3a\u653b\u51fb\u591a\u6837\u6027\uff1b\u4f7f\u7528\u57fa\u4e8e\u6587\u672c\u76f8\u4f3c\u6027\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u8bed\u4e49\u9002\u5e94\u5ea6\u8bc4\u4f30\u6307\u5bfc\u8fdb\u5316\u8fc7\u7a0b\uff1b\u96c6\u6210\u57fa\u4e8eLLM\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u53cc\u7ef4\u5ea6\u8d8a\u72f1\u5224\u65ad\u3002", "result": "\u8bc4\u4f30\u663e\u793aForgeDAN\u5728\u4fdd\u6301\u81ea\u7136\u6027\u548c\u9690\u853d\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u8d8a\u72f1\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u73b0\u6709SOTA\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "ForgeDAN\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u80fd\u591f\u751f\u6210\u8bed\u4e49\u8fde\u8d2f\u4e14\u9ad8\u6548\u7684\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u5728\u8d8a\u72f1\u653b\u51fb\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.12759", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12759", "abs": "https://arxiv.org/abs/2511.12759", "authors": ["James Moore"], "title": "Optimal Foraging in Memory Retrieval: Evaluating Random Walks and Metropolis-Hastings Sampling in Modern Semantic Spaces", "comment": null, "summary": "Human memory retrieval often resembles ecological foraging where animals search for food in a patchy environment. Optimal foraging means following the Marginal Value Theorem (MVT), in which individuals exploit a patch of semantically related concepts until it becomes less rewarding and then switch to a new cluster. While human behavioral data suggests foraging-like patterns in semantic fluency tasks, it remains unclear whether modern high-dimensional embedding spaces provide representations that allow algorithms to match observed human behavior. Using state-of-the-art embeddings and prior semantic fluency data, I find that random walks on these embedding spaces produce results consistent with optimal foraging and the MVT. Surprisingly, introducing Metropolis-Hastings sampling, an adaptive algorithm expected to model strategic acceptance and rejection of new clusters, does not produce results consistent with human behavior. These findings challenge the assumption that more complex sampling mechanisms inherently lead to better cognitive models of memory retrieval. Instead, they show that appropriately structured embeddings, even with simple sampling, can produce near-optimal foraging dynamics. This supports the perspective of Hills (2012) rather than Abbott (2015), demonstrating that modern embeddings can approximate human memory foraging without relying on complex acceptance criteria.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u73b0\u4ee3\u9ad8\u7ef4\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u968f\u673a\u6e38\u8d70\u53ef\u4ee5\u4ea7\u751f\u4e0e\u4eba\u7c7b\u8bed\u4e49\u6d41\u7545\u6027\u4efb\u52a1\u4e2d\u89c2\u5bdf\u5230\u7684\u4f18\u5316\u89c5\u98df\u884c\u4e3a\u4e00\u81f4\u7684\u7ed3\u679c\uff0c\u800c\u66f4\u590d\u6742\u7684Metropolis-Hastings\u91c7\u6837\u7b97\u6cd5\u53cd\u800c\u4e0d\u80fd\u5339\u914d\u4eba\u7c7b\u884c\u4e3a\u3002", "motivation": "\u63a2\u8ba8\u73b0\u4ee3\u9ad8\u7ef4\u5d4c\u5165\u7a7a\u95f4\u662f\u5426\u80fd\u591f\u63d0\u4f9b\u8db3\u591f\u597d\u7684\u8868\u793a\uff0c\u4f7f\u7b97\u6cd5\u80fd\u591f\u5339\u914d\u4eba\u7c7b\u5728\u8bed\u4e49\u6d41\u7545\u6027\u4efb\u52a1\u4e2d\u89c2\u5bdf\u5230\u7684\u89c5\u98df\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u5d4c\u5165\u8868\u793a\u548c\u5148\u524d\u7684\u8bed\u4e49\u6d41\u7545\u6027\u6570\u636e\uff0c\u5728\u5d4c\u5165\u7a7a\u95f4\u4e0a\u8fdb\u884c\u968f\u673a\u6e38\u8d70\u548cMetropolis-Hastings\u91c7\u6837\uff0c\u6bd4\u8f83\u5b83\u4eec\u4e0e\u4eba\u7c7b\u884c\u4e3a\u7684\u5339\u914d\u7a0b\u5ea6\u3002", "result": "\u968f\u673a\u6e38\u8d70\u5728\u5d4c\u5165\u7a7a\u95f4\u4e0a\u4ea7\u751f\u7684\u7ed3\u679c\u4e0e\u4f18\u5316\u89c5\u98df\u548c\u8fb9\u9645\u4ef7\u503c\u5b9a\u7406\u4e00\u81f4\uff0c\u800cMetropolis-Hastings\u91c7\u6837\u672a\u80fd\u4ea7\u751f\u4e0e\u4eba\u7c7b\u884c\u4e3a\u4e00\u81f4\u7684\u7ed3\u679c\u3002", "conclusion": "\u9002\u5f53\u7ed3\u6784\u7684\u5d4c\u5165\u8868\u793a\u5373\u4f7f\u4f7f\u7528\u7b80\u5355\u91c7\u6837\u4e5f\u80fd\u4ea7\u751f\u63a5\u8fd1\u4f18\u5316\u7684\u89c5\u98df\u52a8\u6001\uff0c\u6311\u6218\u4e86\u590d\u6742\u91c7\u6837\u673a\u5236\u5fc5\u7136\u5bfc\u81f4\u66f4\u597d\u8ba4\u77e5\u6a21\u578b\u7684\u5047\u8bbe\uff0c\u652f\u6301Hills(2012)\u800c\u975eAbbott(2015)\u7684\u89c2\u70b9\u3002"}}
{"id": "2511.13576", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.13576", "abs": "https://arxiv.org/abs/2511.13576", "authors": ["Anhao Xiang", "Weiping Pei", "Chuan Yue"], "title": "Exploring the Effectiveness of Google Play Store's Privacy Transparency Channels", "comment": null, "summary": "With the requirements and emphases on privacy transparency placed by regulations such as GDPR and CCPA, the Google Play Store requires Android developers to more responsibly communicate their apps' privacy practices to potential users by providing the proper information via the data safety, privacy policy, and permission manifest privacy transparency channels. However, it is unclear how effective those channels are in helping users make informed decisions in the app selection and installation process. In this article, we conducted a study for 190 participants to interact with our simulated privacy transparency channels of mobile apps. We quantitatively analyzed (supplemented by qualitative analysis) participants' responses to five sets of questions. We found that data safety provides the most intuitive user interfaces, privacy policy is most informative and effective, while permission manifest excels at raising participants' concerns about an app's overall privacy risks. These channels complement each other and should all be improved.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86Google Play\u5546\u5e97\u4e2d\u4e09\u79cd\u9690\u79c1\u900f\u660e\u5ea6\u6e20\u9053\uff08\u6570\u636e\u5b89\u5168\u3001\u9690\u79c1\u653f\u7b56\u548c\u6743\u9650\u6e05\u5355\uff09\u5728\u5e2e\u52a9\u7528\u6237\u505a\u51fa\u660e\u667a\u5e94\u7528\u9009\u62e9\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u901a\u8fc7190\u540d\u53c2\u4e0e\u8005\u7684\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5404\u6e20\u9053\u5404\u6709\u4f18\u52bf\u4e14\u76f8\u4e92\u8865\u5145\u3002", "motivation": "\u968f\u7740GDPR\u548cCCPA\u7b49\u6cd5\u89c4\u5bf9\u9690\u79c1\u900f\u660e\u5ea6\u7684\u8981\u6c42\uff0c\u5e94\u7528\u5546\u5e97\u8981\u6c42\u5f00\u53d1\u8005\u901a\u8fc7\u591a\u79cd\u6e20\u9053\u62ab\u9732\u9690\u79c1\u5b9e\u8df5\uff0c\u4f46\u8fd9\u4e9b\u6e20\u9053\u7684\u5b9e\u9645\u6548\u679c\u5c1a\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u8bc4\u4f30\u5b83\u4eec\u5982\u4f55\u5e2e\u52a9\u7528\u6237\u505a\u51fa\u660e\u667a\u51b3\u7b56\u3002", "method": "\u5bf9190\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8ba9\u4ed6\u4eec\u4e0e\u6a21\u62df\u7684\u79fb\u52a8\u5e94\u7528\u9690\u79c1\u900f\u660e\u5ea6\u6e20\u9053\u4e92\u52a8\uff0c\u901a\u8fc7\u5b9a\u91cf\u5206\u6790\uff08\u8f85\u4ee5\u5b9a\u6027\u5206\u6790\uff09\u53c2\u4e0e\u8005\u5bf9\u4e94\u7ec4\u95ee\u9898\u7684\u56de\u7b54\u6765\u8bc4\u4f30\u5404\u6e20\u9053\u6548\u679c\u3002", "result": "\u6570\u636e\u5b89\u5168\u63d0\u4f9b\u6700\u76f4\u89c2\u7684\u7528\u6237\u754c\u9762\uff0c\u9690\u79c1\u653f\u7b56\u4fe1\u606f\u6700\u4e30\u5bcc\u4e14\u6700\u6709\u6548\uff0c\u6743\u9650\u6e05\u5355\u5728\u63d0\u9ad8\u53c2\u4e0e\u8005\u5bf9\u5e94\u7528\u6574\u4f53\u9690\u79c1\u98ce\u9669\u7684\u5173\u6ce8\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u4e09\u79cd\u9690\u79c1\u900f\u660e\u5ea6\u6e20\u9053\u5404\u6709\u4f18\u52bf\u4e14\u76f8\u4e92\u8865\u5145\uff0c\u90fd\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u66f4\u597d\u5730\u5e2e\u52a9\u7528\u6237\u505a\u51fa\u660e\u667a\u7684\u5e94\u7528\u9009\u62e9\u51b3\u7b56\u3002"}}
{"id": "2511.12792", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12792", "abs": "https://arxiv.org/abs/2511.12792", "authors": ["Mohamad A. Hady", "Siyi Hu", "Mahardhika Pratama", "Zehong Cao", "Ryszard Kowalczyk"], "title": "Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization", "comment": null, "summary": "This work investigates resource optimization in heterogeneous satellite clusters performing autonomous Earth Observation (EO) missions using Reinforcement Learning (RL). In the proposed setting, two optical satellites and one Synthetic Aperture Radar (SAR) satellite operate cooperatively in low Earth orbit to capture ground targets and manage their limited onboard resources efficiently. Traditional optimization methods struggle to handle the real-time, uncertain, and decentralized nature of EO operations, motivating the use of RL and Multi-Agent Reinforcement Learning (MARL) for adaptive decision-making. This study systematically formulates the optimization problem from single-satellite to multi-satellite scenarios, addressing key challenges including energy and memory constraints, partial observability, and agent heterogeneity arising from diverse payload capabilities. Using a near-realistic simulation environment built on the Basilisk and BSK-RL frameworks, we evaluate the performance and stability of state-of-the-art MARL algorithms such as MAPPO, HAPPO, and HATRPO. Results show that MARL enables effective coordination across heterogeneous satellites, balancing imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling. The findings provide practical insights into scalable, autonomous satellite operations and contribute a foundation for future research on intelligent EO mission planning under heterogeneous and dynamic conditions.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5f02\u6784\u536b\u661f\u96c6\u7fa4\u5728\u81ea\u4e3b\u5730\u7403\u89c2\u6d4b\u4efb\u52a1\u4e2d\u7684\u8d44\u6e90\u5206\u914d\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5b9e\u73b0\u5149\u5b66\u548cSAR\u536b\u661f\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u89e3\u51b3\u5b9e\u65f6\u3001\u4e0d\u786e\u5b9a\u548c\u5206\u6563\u73af\u5883\u4e0b\u7684\u8d44\u6e90\u7ba1\u7406\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5730\u7403\u89c2\u6d4b\u4efb\u52a1\u4e2d\u7684\u5b9e\u65f6\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u548c\u5206\u6563\u6027\u7279\u70b9\uff0c\u56e0\u6b64\u9700\u8981\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6765\u5b9e\u73b0\u81ea\u9002\u5e94\u51b3\u7b56\u3002", "method": "\u57fa\u4e8eBasilisk\u548cBSK-RL\u6846\u67b6\u6784\u5efa\u8fd1\u771f\u5b9e\u4eff\u771f\u73af\u5883\uff0c\u8bc4\u4f30MAPPO\u3001HAPPO\u548cHATRPO\u7b49\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u5355\u536b\u661f\u5230\u591a\u536b\u661f\u573a\u666f\u4e2d\u7684\u6027\u80fd\u3002", "result": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u80fd\u591f\u6709\u6548\u534f\u8c03\u5f02\u6784\u536b\u661f\uff0c\u5e73\u8861\u6210\u50cf\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\uff0c\u540c\u65f6\u7f13\u89e3\u975e\u5e73\u7a33\u6027\u548c\u667a\u80fd\u4f53\u95f4\u5956\u52b1\u8026\u5408\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u4e3a\u53ef\u6269\u5c55\u7684\u81ea\u4e3b\u536b\u661f\u64cd\u4f5c\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u5e76\u4e3a\u5f02\u6784\u52a8\u6001\u6761\u4ef6\u4e0b\u667a\u80fd\u5730\u7403\u89c2\u6d4b\u4efb\u52a1\u89c4\u5212\u7684\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.13641", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.13641", "abs": "https://arxiv.org/abs/2511.13641", "authors": ["Quinn Burke", "Anjo Vahldiek-Oberwagner", "Michael Swift", "Patrick McDaniel"], "title": "It's a Feature, Not a Bug: Secure and Auditable State Rollback for Confidential Cloud Applications", "comment": null, "summary": "Replay and rollback attacks threaten cloud application integrity by reintroducing authentic yet stale data through an untrusted storage interface to compromise application decision-making. Prior security frameworks mitigate these attacks by enforcing forward-only state transitions (state continuity) with hardware-backed mechanisms, but they categorically treat all rollback as malicious and thus preclude legitimate rollbacks used for operational recovery from corruption or misconfiguration. We present Rebound, a general-purpose security framework that preserves rollback protection while enabling policy-authorized legitimate rollbacks of application binaries, configuration, and data. Key to Rebound is a reference monitor that mediates state transitions, enforces authorization policy, guarantees atomicity of state updates and rollbacks, and emits a tamper-evident log that provides transparency to applications and auditors. We formally prove Rebound's security properties and show through an application case study -- with software deployment workflows in GitLab CI -- that it enables robust control over binary, configuration, and raw data versioning with low end-to-end overhead.", "AI": {"tldr": "Rebound\u662f\u4e00\u4e2a\u5b89\u5168\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u56de\u6eda\u4fdd\u62a4\u7684\u540c\u65f6\u5141\u8bb8\u7b56\u7565\u6388\u6743\u7684\u5408\u6cd5\u56de\u6eda\uff0c\u901a\u8fc7\u53c2\u8003\u76d1\u63a7\u5668\u5f3a\u5236\u6267\u884c\u6388\u6743\u7b56\u7565\u5e76\u4fdd\u8bc1\u72b6\u6001\u66f4\u65b0\u7684\u539f\u5b50\u6027\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u6846\u67b6\u5c06\u6240\u6709\u56de\u6eda\u90fd\u89c6\u4e3a\u6076\u610f\u884c\u4e3a\uff0c\u4f46\u6392\u9664\u4e86\u7528\u4e8e\u64cd\u4f5c\u6062\u590d\u7684\u5408\u6cd5\u56de\u6eda\u9700\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u514d\u53d7\u56de\u6eda\u653b\u51fb\u53c8\u652f\u6301\u5408\u6cd5\u6062\u590d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1Rebound\u6846\u67b6\uff0c\u4f7f\u7528\u53c2\u8003\u76d1\u63a7\u5668\u6765\u534f\u8c03\u72b6\u6001\u8f6c\u6362\u3001\u5f3a\u5236\u6267\u884c\u6388\u6743\u7b56\u7565\u3001\u4fdd\u8bc1\u72b6\u6001\u66f4\u65b0\u548c\u56de\u6eda\u7684\u539f\u5b50\u6027\uff0c\u5e76\u751f\u6210\u9632\u7be1\u6539\u65e5\u5fd7\u3002", "result": "\u901a\u8fc7\u5f62\u5f0f\u5316\u8bc1\u660eRebound\u7684\u5b89\u5168\u5c5e\u6027\uff0c\u5e76\u5728GitLab CI\u7684\u8f6f\u4ef6\u90e8\u7f72\u5de5\u4f5c\u6d41\u6848\u4f8b\u7814\u7a76\u4e2d\u5c55\u793a\u5176\u80fd\u591f\u4ee5\u4f4e\u7aef\u5230\u7aef\u5f00\u9500\u5b9e\u73b0\u5bf9\u4e8c\u8fdb\u5236\u6587\u4ef6\u3001\u914d\u7f6e\u548c\u539f\u59cb\u6570\u636e\u7248\u672c\u63a7\u5236\u7684\u5f3a\u5927\u63a7\u5236\u3002", "conclusion": "Rebound\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u5b89\u5168\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u56de\u6eda\u4fdd\u62a4\u7684\u540c\u65f6\u652f\u6301\u7b56\u7565\u6388\u6743\u7684\u5408\u6cd5\u56de\u6eda\uff0c\u89e3\u51b3\u4e86\u4e91\u5e94\u7528\u4e2d\u56de\u6eda\u653b\u51fb\u4e0e\u5408\u6cd5\u6062\u590d\u9700\u6c42\u4e4b\u95f4\u7684\u77db\u76fe\u3002"}}
{"id": "2511.12867", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12867", "abs": "https://arxiv.org/abs/2511.12867", "authors": ["Chen Jia"], "title": "Bootstrapping LLMs via Preference-Based Policy Optimization", "comment": null, "summary": "Bootstrapping large language models (LLMs) through preference-based policy optimization offers a promising direction for aligning model behavior with human preferences without relying on extensive manual annotations. In this work, we propose a novel preference-based policy optimization (PbPO) framework that formulates the learning process as a min-max game between the main policy and a reward model (RM). The RM is constrained within a confidence set derived from preference data to ensure reliable exploitation. Our iterative online algorithm actively collects preference data through guided exploration of the evolving policy, enabling continual self-improvement of both the policy and the RM. We provide theoretical guarantees for our method, establishing high-probability regret bounds for both settings with sequence-level RM and token-level RM, demonstrating its effectiveness in bootstrapping LLMs. Extensive experiments on five benchmarks show that our approach consistently outperforms existing state-of-the-art preference optimization techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u504f\u597d\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6PbPO\uff0c\u901a\u8fc7\u4e3b\u7b56\u7565\u4e0e\u5956\u52b1\u6a21\u578b\u4e4b\u95f4\u7684min-max\u535a\u5f08\u6765\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\uff0c\u65e0\u9700\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\u3002", "motivation": "\u901a\u8fc7\u57fa\u4e8e\u504f\u597d\u7684\u7b56\u7565\u4f18\u5316\u4e3a\u5bf9\u9f50\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u63d0\u4f9b\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u907f\u514d\u4f9d\u8d56\u5927\u91cf\u624b\u52a8\u6807\u6ce8\u3002", "method": "\u5c06\u5b66\u4e60\u8fc7\u7a0b\u6784\u5efa\u4e3a\u4e3b\u7b56\u7565\u4e0e\u5956\u52b1\u6a21\u578b\u4e4b\u95f4\u7684min-max\u535a\u5f08\uff0c\u5956\u52b1\u6a21\u578b\u7ea6\u675f\u5728\u504f\u597d\u6570\u636e\u5bfc\u51fa\u7684\u7f6e\u4fe1\u96c6\u5185\u4ee5\u786e\u4fdd\u53ef\u9760\u5229\u7528\uff0c\u91c7\u7528\u8fed\u4ee3\u5728\u7ebf\u7b97\u6cd5\u901a\u8fc7\u7b56\u7565\u7684\u5f15\u5bfc\u63a2\u7d22\u4e3b\u52a8\u6536\u96c6\u504f\u597d\u6570\u636e\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u504f\u597d\u4f18\u5316\u6280\u672f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u8bc1\u4f18\u52bf\uff0c\u8bc1\u660e\u4e86\u5728\u5e8f\u5217\u7ea7\u548c\u4ee4\u724c\u7ea7\u5956\u52b1\u6a21\u578b\u8bbe\u7f6e\u4e0b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.12876", "categories": ["cs.AI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.12876", "abs": "https://arxiv.org/abs/2511.12876", "authors": ["Heyang Ma", "Qirui Mi", "Qipeng Yang", "Zijun Fan", "Bo Li", "Haifeng Zhang"], "title": "Think, Speak, Decide: Language-Augmented Multi-Agent Reinforcement Learning for Economic Decision-Making", "comment": "Extended version of a submission to AAAI 2026", "summary": "Economic decision-making depends not only on structured signals such as prices and taxes, but also on unstructured language, including peer dialogue and media narratives. While multi-agent reinforcement learning (MARL) has shown promise in optimizing economic decisions, it struggles with the semantic ambiguity and contextual richness of language. We propose LAMP (Language-Augmented Multi-Agent Policy), a framework that integrates language into economic decision-making and narrows the gap to real-world settings. LAMP follows a Think-Speak-Decide pipeline: (1) Think interprets numerical observations to extract short-term shocks and long-term trends, caching high-value reasoning trajectories; (2) Speak crafts and exchanges strategic messages based on reasoning, updating beliefs by parsing peer communications; and (3) Decide fuses numerical data, reasoning, and reflections into a MARL policy to optimize language-augmented decision-making. Experiments in economic simulation show that LAMP outperforms both MARL and LLM-only baselines in cumulative return (+63.5%, +34.0%), robustness (+18.8%, +59.4%), and interpretability. These results demonstrate the potential of language-augmented policies to deliver more effective and robust economic strategies.", "AI": {"tldr": "LAMP\u6846\u67b6\u901a\u8fc7\u8bed\u8a00\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u7ecf\u6d4e\u51b3\u7b56\u4e2d\u6574\u5408\u8bed\u8a00\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7d2f\u79ef\u56de\u62a5\u3001\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u5b9e\u7ecf\u6d4e\u51b3\u7b56\u4e0d\u4ec5\u4f9d\u8d56\u7ed3\u6784\u5316\u4fe1\u53f7\uff08\u5982\u4ef7\u683c\u3001\u7a0e\u6536\uff09\uff0c\u8fd8\u53d7\u975e\u7ed3\u6784\u5316\u8bed\u8a00\uff08\u5982\u540c\u884c\u5bf9\u8bdd\u3001\u5a92\u4f53\u53d9\u4e8b\uff09\u5f71\u54cd\u3002\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u96be\u4ee5\u5904\u7406\u8bed\u8a00\u7684\u8bed\u4e49\u6a21\u7cca\u6027\u548c\u4e0a\u4e0b\u6587\u4e30\u5bcc\u6027\u3002", "method": "LAMP\u91c7\u7528Think-Speak-Decide\u6d41\u7a0b\uff1a(1) Think\u6a21\u5757\u89e3\u91ca\u6570\u503c\u89c2\u6d4b\uff0c\u63d0\u53d6\u77ed\u671f\u51b2\u51fb\u548c\u957f\u671f\u8d8b\u52bf\uff0c\u7f13\u5b58\u9ad8\u4ef7\u503c\u63a8\u7406\u8f68\u8ff9\uff1b(2) Speak\u6a21\u5757\u57fa\u4e8e\u63a8\u7406\u751f\u6210\u548c\u4ea4\u6362\u6218\u7565\u6d88\u606f\uff0c\u901a\u8fc7\u89e3\u6790\u540c\u4f34\u901a\u4fe1\u66f4\u65b0\u4fe1\u5ff5\uff1b(3) Decide\u6a21\u5757\u878d\u5408\u6570\u503c\u6570\u636e\u3001\u63a8\u7406\u548c\u53cd\u601d\uff0c\u901a\u8fc7MARL\u7b56\u7565\u4f18\u5316\u8bed\u8a00\u589e\u5f3a\u7684\u51b3\u7b56\u3002", "result": "\u5728\u7ecf\u6d4e\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0cLAMP\u5728\u7d2f\u79ef\u56de\u62a5\uff08+63.5%, +34.0%\uff09\u3001\u9c81\u68d2\u6027\uff08+18.8%, +59.4%\uff09\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u4f18\u4e8eMARL\u548c\u7eafLLM\u57fa\u7ebf\u3002", "conclusion": "\u8bed\u8a00\u589e\u5f3a\u7b56\u7565\u5177\u6709\u63d0\u4f9b\u66f4\u6709\u6548\u548c\u7a33\u5065\u7ecf\u6d4e\u7b56\u7565\u7684\u6f5c\u529b\uff0c\u7f29\u5c0f\u4e86\u4e0e\u73b0\u5b9e\u4e16\u754c\u8bbe\u7f6e\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.12916", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12916", "abs": "https://arxiv.org/abs/2511.12916", "authors": ["Yafang Wang", "Yangjie Tian", "Xiaoyu Shen", "Gaoyang Zhang", "Jiaze Sun", "He Zhang", "Ruohua Xu", "Feng Zhao"], "title": "Fault2Flow: An AlphaEvolve-Optimized Human-in-the-Loop Multi-Agent System for Fault-to-Workflow Automation", "comment": null, "summary": "Power grid fault diagnosis is a critical process hindered by its reliance on manual, error-prone methods. Technicians must manually extract reasoning logic from dense regulations and attempt to combine it with tacit expert knowledge, which is inefficient, error-prone, and lacks maintainability as ragulations are updated and experience evolves. While Large Language Models (LLMs) have shown promise in parsing unstructured text, no existing framework integrates these two disparate knowledge sources into a single, verified, and executable workflow. To bridge this gap, we propose Fault2Flow, an LLM-based multi-agent system. Fault2Flow systematically: (1) extracts and structures regulatory logic into PASTA-formatted fault trees; (2) integrates expert knowledge via a human-in-the-loop interface for verification; (3) optimizes the reasoning logic using a novel AlphaEvolve module; and (4) synthesizes the final, verified logic into an n8n-executable workflow. Experimental validation on transformer fault diagnosis datasets confirms 100\\% topological consistency and high semantic fidelity. Fault2Flow establishes a reproducible path from fault analysis to operational automation, substantially reducing expert workload.", "AI": {"tldr": "Fault2Flow\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u7535\u7f51\u6545\u969c\u8bca\u65ad\uff0c\u901a\u8fc7\u63d0\u53d6\u6cd5\u89c4\u903b\u8f91\u3001\u6574\u5408\u4e13\u5bb6\u77e5\u8bc6\u3001\u4f18\u5316\u63a8\u7406\u903b\u8f91\uff0c\u6700\u7ec8\u751f\u6210\u53ef\u6267\u884c\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u4f20\u7edf\u7535\u7f51\u6545\u969c\u8bca\u65ad\u4f9d\u8d56\u4eba\u5de5\u65b9\u6cd5\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u7f3a\u4e4f\u53ef\u7ef4\u62a4\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5c06\u6cd5\u89c4\u6587\u672c\u548c\u4e13\u5bb6\u77e5\u8bc6\u6574\u5408\u5230\u7edf\u4e00\u3001\u53ef\u9a8c\u8bc1\u7684\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u3002", "method": "\u63d0\u51faFault2Flow\u7cfb\u7edf\uff1a1) \u63d0\u53d6\u6cd5\u89c4\u903b\u8f91\u5e76\u6784\u5efaPASTA\u683c\u5f0f\u6545\u969c\u6811\uff1b2) \u901a\u8fc7\u4eba\u673a\u4ea4\u4e92\u754c\u9762\u6574\u5408\u548c\u9a8c\u8bc1\u4e13\u5bb6\u77e5\u8bc6\uff1b3) \u4f7f\u7528AlphaEvolve\u6a21\u5757\u4f18\u5316\u63a8\u7406\u903b\u8f91\uff1b4) \u5408\u6210\u6700\u7ec8\u9a8c\u8bc1\u903b\u8f91\u4e3an8n\u53ef\u6267\u884c\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u53d8\u538b\u5668\u6545\u969c\u8bca\u65ad\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0c\u7cfb\u7edf\u5b9e\u73b0\u4e86100%\u7684\u62d3\u6251\u4e00\u81f4\u6027\u548c\u9ad8\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002", "conclusion": "Fault2Flow\u5efa\u7acb\u4e86\u4ece\u6545\u969c\u5206\u6790\u5230\u64cd\u4f5c\u81ea\u52a8\u5316\u7684\u53ef\u590d\u73b0\u8def\u5f84\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4e13\u5bb6\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2511.12963", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12963", "abs": "https://arxiv.org/abs/2511.12963", "authors": ["Crystal Su"], "title": "MedRule-KG: A Knowledge-Graph--Steered Scaffold for Reliable Mathematical and Biomedical Reasoning", "comment": "AAAI 2026 Workshop AI2ASE", "summary": "We study how to impose domain-consistent structure on large language models (LLMs) used for scientific reasoning and early-stage drug discovery. We present MedRule-KG, a compact knowledge-graph scaffold paired with a lightweight verifier that steers generation toward mathematically and biomedically valid outputs. The system injects curated symbolic facts into prompts and then enforces rule satisfaction with a deterministic checker. We formalize generation as constrained inference, introduce a soft guidance surrogate suitable for decoding, and perform a thorough statistical analysis with uncertainty quantification. Across 90 tasks spanning reaction feasibility, metabolic compatibility, and toxicity screening, MedRule-KG reduces violation counts by 83.2\\% relative to a strong chain-of-thought baseline while improving exact match. Results remain stable under stratification and scale with dataset size, and the verifier adds negligible latency, making the approach practical for interactive design.", "AI": {"tldr": "MedRule-KG\u662f\u4e00\u4e2a\u4e3a\u79d1\u5b66\u63a8\u7406\u548c\u836f\u7269\u53d1\u73b0\u8bbe\u8ba1\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u652f\u67b6\u548c\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668\u6765\u5f15\u5bfcLLM\u751f\u6210\u6570\u5b66\u548c\u751f\u7269\u533b\u5b66\u4e0a\u6709\u6548\u7684\u8f93\u51fa\uff0c\u663e\u8457\u51cf\u5c11\u8fdd\u89c4\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u79d1\u5b66\u63a8\u7406\u548c\u65e9\u671f\u836f\u7269\u53d1\u73b0\u4e2d\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u4ea7\u751f\u6570\u5b66\u548c\u751f\u7269\u533b\u5b66\u4e0a\u65e0\u6548\u7684\u8f93\u51fa\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u786e\u4fdd\u751f\u6210\u5185\u5bb9\u7684\u9886\u57df\u4e00\u81f4\u6027\u3002", "method": "\u4f7f\u7528MedRule-KG\u77e5\u8bc6\u56fe\u8c31\u652f\u67b6\u548c\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668\uff0c\u5c06\u7cbe\u9009\u7684\u7b26\u53f7\u4e8b\u5b9e\u6ce8\u5165\u63d0\u793a\u4e2d\uff0c\u5e76\u901a\u8fc7\u786e\u5b9a\u6027\u68c0\u67e5\u5668\u5f3a\u5236\u6267\u884c\u89c4\u5219\u6ee1\u8db3\uff0c\u5c06\u751f\u6210\u5f62\u5f0f\u5316\u4e3a\u7ea6\u675f\u63a8\u7406\u3002", "result": "\u572890\u4e2a\u4efb\u52a1\u4e2d\uff0cMedRule-KG\u76f8\u5bf9\u4e8e\u5f3a\u5927\u7684\u601d\u7ef4\u94fe\u57fa\u7ebf\u51cf\u5c11\u4e8683.2%\u7684\u8fdd\u89c4\u6570\u91cf\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u7cbe\u786e\u5339\u914d\u7387\uff0c\u7ed3\u679c\u5728\u5206\u5c42\u548c\u6570\u636e\u96c6\u89c4\u6a21\u6269\u5c55\u4e0b\u4fdd\u6301\u7a33\u5b9a\u3002", "conclusion": "MedRule-KG\u901a\u8fc7\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u9a8c\u8bc1\u5668\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\uff0c\u9a8c\u8bc1\u5668\u5e26\u6765\u7684\u5ef6\u8fdf\u53ef\u5ffd\u7565\uff0c\u9002\u5408\u4ea4\u4e92\u5f0f\u8bbe\u8ba1\u5e94\u7528\u3002"}}
{"id": "2511.13007", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13007", "abs": "https://arxiv.org/abs/2511.13007", "authors": ["Yiyang Zhao", "Huiyu Bai", "Xuejiao Zhao"], "title": "GEM: Generative Entropy-Guided Preference Modeling for Few-shot Alignment of LLMs", "comment": "This paper has been accepted by AAAI 2026-AIA and designated as an oral presentation paper", "summary": "Alignment of large language models (LLMs) with human preferences typically relies on supervised reward models or external judges that demand abundant annotations. However, in fields that rely on professional knowledge, such as medicine and law, such large-scale preference labels are often unachievable. In this paper, we propose a generative entropy-guided preference modeling approach named GEM for LLMs aligment at low-resource and domain-specific scenarios. Instead of training a discriminative reward model on preference data, we directly train the LLM to internalize a closed-loop optimization architecture that can extract and exploit the multi-dimensional, fine-grained cognitive signals implicit in human preferences. Specifically, our Cognitive Filtering module, based on entropy theory in decision making, first leverages Chain-of-Thought (CoT) prompting to generate diverse candidate reasoning chains (CoTs) from preference data. Subsequently, it introduces a token scoring mechanism to rank and weight the sampled CoTs, boosting the importance of high-confidence answers and strategically high-entropy tokens. Building on these filtered preferences, we fine-tune the LLM using a novel self-evaluated group advantage algorithm, SEGA, which effectively aggregates group-level cognitive signals and transforms the entropy-based scores into implicit rewards for policy optimization. In these ways, GEM empowers the LLM to rely on its own judgments and establishes an entropy-guided closed-loop cognitive optimization framework, enabling highly efficient few-shot alignment of LLMs. Experiments on general benchmarks and domain-specific tasks (such as mathematical reasoning and medical dialogues) demonstrate that our GEM achieves significant improvements with few-shot preference data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGEM\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u5f0f\u71b5\u5f15\u5bfc\u504f\u597d\u5efa\u6a21\uff0c\u5728\u4f4e\u8d44\u6e90\u548c\u9886\u57df\u7279\u5b9a\u573a\u666f\u4e0b\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\uff0c\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\u3002", "motivation": "\u5728\u533b\u5b66\u3001\u6cd5\u5f8b\u7b49\u4e13\u4e1a\u9886\u57df\uff0c\u5927\u89c4\u6a21\u504f\u597d\u6807\u6ce8\u96be\u4ee5\u83b7\u5f97\uff0c\u4f20\u7edf\u4f9d\u8d56\u76d1\u7763\u5956\u52b1\u6a21\u578b\u6216\u5916\u90e8\u8bc4\u4f30\u7684\u65b9\u6cd5\u4e0d\u53ef\u884c\u3002", "method": "\u57fa\u4e8e\u51b3\u7b56\u71b5\u7406\u8bba\u7684\u8ba4\u77e5\u8fc7\u6ee4\u6a21\u5757\uff1a1) \u4f7f\u7528\u601d\u7ef4\u94fe\u63d0\u793a\u751f\u6210\u591a\u6837\u5316\u5019\u9009\u63a8\u7406\u94fe\uff1b2) \u5f15\u5165token\u8bc4\u5206\u673a\u5236\u5bf9\u601d\u7ef4\u94fe\u8fdb\u884c\u6392\u5e8f\u52a0\u6743\uff1b3) \u4f7f\u7528SEGA\u81ea\u8bc4\u4f30\u7fa4\u4f53\u4f18\u52bf\u7b97\u6cd5\u8fdb\u884c\u5fae\u8c03\uff0c\u5c06\u71b5\u57fa\u5206\u6570\u8f6c\u5316\u4e3a\u9690\u5f0f\u5956\u52b1\u3002", "result": "\u5728\u901a\u7528\u57fa\u51c6\u548c\u9886\u57df\u7279\u5b9a\u4efb\u52a1\uff08\u5982\u6570\u5b66\u63a8\u7406\u548c\u533b\u7597\u5bf9\u8bdd\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGEM\u5728\u5c11\u6837\u672c\u504f\u597d\u6570\u636e\u4e0b\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "GEM\u5efa\u7acb\u4e86\u4e00\u4e2a\u71b5\u5f15\u5bfc\u7684\u95ed\u73af\u8ba4\u77e5\u4f18\u5316\u6846\u67b6\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u4f9d\u8d56\u81ea\u8eab\u5224\u65ad\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u5c11\u6837\u672c\u5bf9\u9f50\u3002"}}
{"id": "2511.13021", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13021", "abs": "https://arxiv.org/abs/2511.13021", "authors": ["Sachin Vashistha", "Aryan Bibhuti", "Atharva Naik", "Martin Tutek", "Somak Aditya"], "title": "PragWorld: A Benchmark Evaluating LLMs' Local World Model under Minimal Linguistic Alterations and Conversational Dynamics", "comment": "23 pages, 15 tables, 10 figures; AAAI 2026 Conference Main Track (oral)", "summary": "Real-world conversations are rich with pragmatic elements, such as entity mentions, references, and implicatures. Understanding such nuances is a requirement for successful natural communication, and often requires building a local world model which encodes such elements and captures the dynamics of their evolving states. However, it is not well-understood whether language models (LMs) construct or maintain a robust implicit representation of conversations. In this work, we evaluate the ability of LMs to encode and update their internal world model in dyadic conversations and test their malleability under linguistic alterations. To facilitate this, we apply seven minimal linguistic alterations to conversations sourced from popular datasets and construct two benchmarks comprising yes-no questions. We evaluate a wide range of open and closed source LMs and observe that they struggle to maintain robust accuracy. Our analysis unveils that LMs struggle to memorize crucial details, such as tracking entities under linguistic alterations to conversations. We then propose a dual-perspective interpretability framework which identifies transformer layers that are useful or harmful and highlights linguistic alterations most influenced by harmful layers, typically due to encoding spurious signals or relying on shortcuts. Inspired by these insights, we propose two layer-regularization based fine-tuning strategies that suppress the effect of the harmful layers.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u8bdd\u4e2d\u6784\u5efa\u548c\u7ef4\u62a4\u4e16\u754c\u6a21\u578b\u7684\u80fd\u529b\uff0c\u6d4b\u8bd5\u5176\u5728\u8bed\u8a00\u53d8\u5316\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u63d0\u51fa\u89e3\u91ca\u6027\u6846\u67b6\u548c\u5fae\u8c03\u7b56\u7565\u6765\u6539\u5584\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u5bf9\u8bdd\u5305\u542b\u4e30\u5bcc\u7684\u8bed\u7528\u5143\u7d20\uff0c\u9700\u8981\u6784\u5efa\u5c40\u90e8\u4e16\u754c\u6a21\u578b\u6765\u7f16\u7801\u8fd9\u4e9b\u5143\u7d20\u5e76\u8ddf\u8e2a\u5176\u72b6\u6001\u53d8\u5316\u3002\u4f46\u76ee\u524d\u4e0d\u6e05\u695a\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u6784\u5efa\u548c\u7ef4\u62a4\u5f3a\u5927\u7684\u9690\u5f0f\u5bf9\u8bdd\u8868\u793a\u3002", "method": "\u5bf9\u6d41\u884c\u6570\u636e\u96c6\u4e2d\u7684\u5bf9\u8bdd\u5e94\u7528\u4e03\u79cd\u6700\u5c0f\u8bed\u8a00\u53d8\u5316\uff0c\u6784\u5efa\u5305\u542b\u662f\u975e\u95ee\u9898\u7684\u4e24\u4e2a\u57fa\u51c6\u3002\u8bc4\u4f30\u5404\u79cd\u5f00\u6e90\u548c\u95ed\u6e90\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u51fa\u53cc\u89c6\u89d2\u89e3\u91ca\u6027\u6846\u67b6\u8bc6\u522b\u6709\u7528\u548c\u6709\u5bb3\u7684Transformer\u5c42\uff0c\u5e76\u57fa\u4e8e\u5c42\u6b63\u5219\u5316\u63d0\u51fa\u4e24\u79cd\u5fae\u8c03\u7b56\u7565\u3002", "result": "\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u8a00\u53d8\u5316\u4e0b\u96be\u4ee5\u4fdd\u6301\u9c81\u68d2\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u8ddf\u8e2a\u5b9e\u4f53\u7b49\u5173\u952e\u7ec6\u8282\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002\u89e3\u91ca\u6027\u6846\u67b6\u6210\u529f\u8bc6\u522b\u4e86\u6709\u5bb3\u5c42\uff0c\u8fd9\u4e9b\u5c42\u901a\u5e38\u7f16\u7801\u865a\u5047\u4fe1\u53f7\u6216\u4f9d\u8d56\u6377\u5f84\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5728\u7ef4\u62a4\u5bf9\u8bdd\u4e16\u754c\u6a21\u578b\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u4f46\u901a\u8fc7\u8bc6\u522b\u548c\u6291\u5236\u6709\u5bb3\u5c42\u53ef\u4ee5\u6539\u5584\u5176\u6027\u80fd\uff0c\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u7684\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2511.13027", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13027", "abs": "https://arxiv.org/abs/2511.13027", "authors": ["Sadegh Mahdavi", "Branislav Kisacanin", "Shubham Toshniwal", "Wei Du", "Ivan Moshkov", "George Armstrong", "Renjie Liao", "Christos Thrampoulidis", "Igor Gitman"], "title": "Scaling Generative Verifiers For Natural Language Mathematical Proof Verification And Selection", "comment": null, "summary": "Large language models have achieved remarkable success on final-answer mathematical problems, largely due to the ease of applying reinforcement learning with verifiable rewards. However, the reasoning underlying these solutions is often flawed. Advancing to rigorous proof-based mathematics requires reliable proof verification capabilities. We begin by analyzing multiple evaluation setups and show that focusing on a single benchmark can lead to brittle or misleading conclusions. To address this, we evaluate both proof-based and final-answer reasoning to obtain a more reliable measure of model performance. We then scale two major generative verification methods (GenSelect and LLM-as-a-Judge) to millions of tokens and identify their combination as the most effective framework for solution verification and selection. We further show that the choice of prompt for LLM-as-a-Judge significantly affects the model's performance, but reinforcement learning can reduce this sensitivity. However, despite improving proof-level metrics, reinforcement learning does not enhance final-answer precision, indicating that current models often reward stylistic or procedural correctness rather than mathematical validity. Our results establish practical guidelines for designing and evaluating scalable proof-verification and selection systems.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u8bc1\u660e\u9a8c\u8bc1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5355\u4e00\u57fa\u51c6\u6d4b\u8bd5\u53ef\u80fd\u5bfc\u81f4\u8bef\u5bfc\u6027\u7ed3\u8bba\u3002\u4f5c\u8005\u8bc4\u4f30\u4e86\u57fa\u4e8e\u8bc1\u660e\u548c\u6700\u7ec8\u7b54\u6848\u7684\u63a8\u7406\uff0c\u5e76\u6269\u5c55\u4e86\u4e24\u79cd\u751f\u6210\u9a8c\u8bc1\u65b9\u6cd5\uff08GenSelect\u548cLLM-as-a-Judge\uff09\uff0c\u53d1\u73b0\u5b83\u4eec\u7684\u7ec4\u5408\u662f\u6700\u6709\u6548\u7684\u9a8c\u8bc1\u6846\u67b6\u3002\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u51cf\u5c11\u63d0\u793a\u654f\u611f\u6027\uff0c\u4f46\u65e0\u6cd5\u63d0\u9ad8\u6700\u7ec8\u7b54\u6848\u7cbe\u5ea6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6700\u7ec8\u7b54\u6848\u6570\u5b66\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u63a8\u7406\u8fc7\u7a0b\u5f80\u5f80\u5b58\u5728\u7f3a\u9677\u3002\u4e3a\u4e86\u63a8\u8fdb\u5230\u4e25\u683c\u7684\u8bc1\u660e\u6570\u5b66\uff0c\u9700\u8981\u53ef\u9760\u7684\u8bc1\u660e\u9a8c\u8bc1\u80fd\u529b\u3002", "method": "\u5206\u6790\u591a\u4e2a\u8bc4\u4f30\u8bbe\u7f6e\uff0c\u8bc4\u4f30\u57fa\u4e8e\u8bc1\u660e\u548c\u6700\u7ec8\u7b54\u6848\u7684\u63a8\u7406\uff1b\u6269\u5c55\u4e24\u79cd\u751f\u6210\u9a8c\u8bc1\u65b9\u6cd5\uff08GenSelect\u548cLLM-as-a-Judge\uff09\u5230\u6570\u767e\u4e07token\uff1b\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u51cf\u5c11\u63d0\u793a\u654f\u611f\u6027\u3002", "result": "GenSelect\u548cLLM-as-a-Judge\u7684\u7ec4\u5408\u662f\u6700\u6709\u6548\u7684\u9a8c\u8bc1\u6846\u67b6\uff1b\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u51cf\u5c11\u63d0\u793a\u654f\u611f\u6027\u4f46\u65e0\u6cd5\u63d0\u9ad8\u6700\u7ec8\u7b54\u6848\u7cbe\u5ea6\uff1b\u5f53\u524d\u6a21\u578b\u5f80\u5f80\u5956\u52b1\u98ce\u683c\u6216\u7a0b\u5e8f\u6b63\u786e\u6027\u800c\u975e\u6570\u5b66\u6709\u6548\u6027\u3002", "conclusion": "\u4e3a\u8bbe\u8ba1\u548c\u8bc4\u4f30\u53ef\u6269\u5c55\u7684\u8bc1\u660e\u9a8c\u8bc1\u548c\u9009\u62e9\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u53ef\u9760\u7684\u9a8c\u8bc1\u65b9\u6cd5\u6765\u786e\u4fdd\u6570\u5b66\u63a8\u7406\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.13091", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13091", "abs": "https://arxiv.org/abs/2511.13091", "authors": ["Yuhan Chen", "Yuxuan Liu", "Long Zhang", "Pengzhi Gao", "Jian Luan", "Wei Liu"], "title": "STEP: Success-Rate-Aware Trajectory-Efficient Policy Optimization", "comment": null, "summary": "Multi-turn interaction remains challenging for online reinforcement learning. A common solution is trajectory-level optimization, which treats each trajectory as a single training sample. However, this approach can be inefficient and yield misleading learning signals: it applies uniform sampling across tasks regardless of difficulty, penalizes correct intermediate actions in failed trajectories, and incurs high sample-collection costs. To address these issues, we propose STEP (Success-rate-aware Trajectory-Efficient Policy optimization), a framework that dynamically allocates sampling based on per-task success rates and performs step-level optimization. STEP maintains a smoothed success-rate record to guide adaptive trajectory resampling, allocating more effort to harder tasks. It then computes success-rate-weighted advantages and decomposes trajectories into step-level samples. Finally, it applies a step-level GRPO augmentation to refine updates for low-success tasks. Experiments on OSWorld and AndroidWorld show that STEP substantially improves sample efficiency and training stability over trajectory-level GRPO, converging faster and generalizing better under the same sampling budget.", "AI": {"tldr": "STEP\u6846\u67b6\u901a\u8fc7\u57fa\u4e8e\u4efb\u52a1\u6210\u529f\u7387\u7684\u52a8\u6001\u91c7\u6837\u5206\u914d\u548c\u6b65\u9aa4\u7ea7\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u591a\u8f6e\u4ea4\u4e92\u5f3a\u5316\u5b66\u4e60\u4e2d\u8f68\u8ff9\u7ea7\u4f18\u5316\u7684\u4f4e\u6548\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "motivation": "\u591a\u8f6e\u4ea4\u4e92\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u8f68\u8ff9\u7ea7\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u548c\u5b66\u4e60\u4fe1\u53f7\u8bef\u5bfc\u7684\u95ee\u9898\uff1a\u5bf9\u6240\u6709\u4efb\u52a1\u91c7\u7528\u5747\u5300\u91c7\u6837\u3001\u60e9\u7f5a\u5931\u8d25\u8f68\u8ff9\u4e2d\u7684\u6b63\u786e\u4e2d\u95f4\u52a8\u4f5c\u3001\u6837\u672c\u6536\u96c6\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faSTEP\u6846\u67b6\uff1a1\uff09\u57fa\u4e8e\u6bcf\u4efb\u52a1\u6210\u529f\u7387\u7684\u5e73\u6ed1\u8bb0\u5f55\u6307\u5bfc\u81ea\u9002\u5e94\u8f68\u8ff9\u91cd\u91c7\u6837\uff0c\u5411\u66f4\u96be\u4efb\u52a1\u5206\u914d\u66f4\u591a\u8d44\u6e90\uff1b2\uff09\u8ba1\u7b97\u6210\u529f\u7387\u52a0\u6743\u4f18\u52bf\u5e76\u5c06\u8f68\u8ff9\u5206\u89e3\u4e3a\u6b65\u9aa4\u7ea7\u6837\u672c\uff1b3\uff09\u5bf9\u4f4e\u6210\u529f\u7387\u4efb\u52a1\u5e94\u7528\u6b65\u9aa4\u7ea7GRPO\u589e\u5f3a\u4ee5\u7ec6\u5316\u66f4\u65b0\u3002", "result": "\u5728OSWorld\u548cAndroidWorld\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSTEP\u76f8\u6bd4\u8f68\u8ff9\u7ea7GRPO\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5728\u76f8\u540c\u91c7\u6837\u9884\u7b97\u4e0b\u6536\u655b\u66f4\u5feb\u4e14\u6cdb\u5316\u80fd\u529b\u66f4\u597d\u3002", "conclusion": "STEP\u901a\u8fc7\u52a8\u6001\u91c7\u6837\u5206\u914d\u548c\u6b65\u9aa4\u7ea7\u4f18\u5316\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f6e\u4ea4\u4e92\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u8bad\u7ec3\u6846\u67b6\u3002"}}
{"id": "2511.13226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13226", "abs": "https://arxiv.org/abs/2511.13226", "authors": ["Michele Persiani", "Thomas Hellstrom"], "title": "Informative Communication of Robot Plans", "comment": "Conference: PAAMS 2022, 20th International Conference on Practical Applications of Agents and Multi-Agent Systems", "summary": "When a robot is asked to verbalize its plan it can do it in many ways. For example, a seemingly natural strategy is incremental, where the robot verbalizes its planned actions in plan order. However, an important aspect of this type of strategy is that it misses considerations on what is effectively informative to communicate, because not considering what the user knows prior to explanations. In this paper we propose a verbalization strategy to communicate robot plans informatively, by measuring the information gain that verbalizations have against a second-order theory of mind of the user capturing his prior knowledge on the robot. As shown in our experiments, this strategy allows to understand the robot's goal much quicker than by using strategies such as increasing or decreasing plan order. In addition, following our formulation we hint to what is informative and why when a robot communicates its plan.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u589e\u76ca\u7684\u673a\u5668\u4eba\u8ba1\u5212\u53e3\u5934\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u8003\u8651\u7528\u6237\u7684\u4e8c\u9636\u5fc3\u667a\u7406\u8bba\u6765\u751f\u6210\u66f4\u5177\u4fe1\u606f\u91cf\u7684\u89e3\u91ca\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u6309\u8ba1\u5212\u987a\u5e8f\u89e3\u91ca\u65b9\u6cd5\u80fd\u66f4\u5feb\u8ba9\u7528\u6237\u7406\u89e3\u673a\u5668\u4eba\u76ee\u6807\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u8ba1\u5212\u53e3\u5934\u5316\u7b56\u7565\uff08\u5982\u6309\u8ba1\u5212\u987a\u5e8f\u9012\u589e\u6216\u9012\u51cf\u89e3\u91ca\uff09\u5ffd\u89c6\u4e86\u7528\u6237\u5148\u9a8c\u77e5\u8bc6\uff0c\u65e0\u6cd5\u6709\u6548\u4f20\u8fbe\u4fe1\u606f\u3002\u9700\u8981\u4e00\u79cd\u80fd\u8861\u91cf\u89e3\u91ca\u4fe1\u606f\u589e\u76ca\u7684\u65b9\u6cd5\u6765\u751f\u6210\u66f4\u5177\u4fe1\u606f\u91cf\u7684\u6c9f\u901a\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u589e\u76ca\u7684\u53e3\u5934\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u6784\u5efa\u7528\u6237\u7684\u4e8c\u9636\u5fc3\u667a\u7406\u8bba\u6a21\u578b\u6765\u6355\u6349\u5176\u5148\u9a8c\u77e5\u8bc6\uff0c\u5e76\u8ba1\u7b97\u4e0d\u540c\u53e3\u5934\u5316\u65b9\u5f0f\u5bf9\u7528\u6237\u7406\u89e3\u7684\u4fe1\u606f\u589e\u76ca\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b56\u7565\u76f8\u6bd4\u9012\u589e\u6216\u9012\u51cf\u8ba1\u5212\u987a\u5e8f\u7b56\u7565\uff0c\u80fd\u8ba9\u7528\u6237\u66f4\u5feb\u7406\u89e3\u673a\u5668\u4eba\u7684\u76ee\u6807\u3002", "conclusion": "\u57fa\u4e8e\u4fe1\u606f\u589e\u76ca\u7684\u53e3\u5934\u5316\u7b56\u7565\u80fd\u66f4\u6709\u6548\u5730\u4f20\u8fbe\u673a\u5668\u4eba\u8ba1\u5212\u610f\u56fe\uff0c\u5e76\u63ed\u793a\u4e86\u4ec0\u4e48\u5185\u5bb9\u5728\u673a\u5668\u4eba\u8ba1\u5212\u6c9f\u901a\u4e2d\u5177\u6709\u4fe1\u606f\u4ef7\u503c\u53ca\u5176\u539f\u56e0\u3002"}}
{"id": "2511.13288", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13288", "abs": "https://arxiv.org/abs/2511.13288", "authors": ["Haoyang Hong", "Jiajun Yin", "Yuan Wang", "Jingnan Liu", "Zhe Chen", "Ailing Yu", "Ji Li", "Zhiling Ye", "Hansong Xiao", "Yefei Chen", "Hualei Zhou", "Yun Yue", "Minghui Yang", "Chunxiao Guo", "Junwei Liu", "Peng Wei", "Jinjie Gu"], "title": "Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO", "comment": null, "summary": "Multi-agent systems perform well on general reasoning tasks. However, the lack of training in specialized areas hinders their accuracy. Current training methods train a unified large language model (LLM) for all agents in the system. This may limit the performances due to different distributions underlying for different agents. Therefore, training multi-agent systems with distinct LLMs should be the next step to solve. However, this approach introduces optimization challenges. For example, agents operate at different frequencies, rollouts involve varying sub-agent invocations, and agents are often deployed across separate servers, disrupting end-to-end gradient flow. To address these issues, we propose M-GRPO, a hierarchical extension of Group Relative Policy Optimization designed for vertical Multi-agent systems with a main agent (planner) and multiple sub-agents (multi-turn tool executors). M-GRPO computes group-relative advantages for both main and sub-agents, maintaining hierarchical credit assignment. It also introduces a trajectory-alignment scheme that generates fixed-size batches despite variable sub-agent invocations. We deploy a decoupled training pipeline in which agents run on separate servers and exchange minimal statistics via a shared store. This enables scalable training without cross-server backpropagation. In experiments on real-world benchmarks (e.g., GAIA, XBench-DeepSearch, and WebWalkerQA), M-GRPO consistently outperforms both single-agent GRPO and multi-agent GRPO with frozen sub-agents, demonstrating improved stability and sample efficiency. These results show that aligning heterogeneous trajectories and decoupling optimization across specialized agents enhances tool-augmented reasoning tasks.", "AI": {"tldr": "\u63d0\u51faM-GRPO\u65b9\u6cd5\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5f02\u6784LLM\u8bad\u7ec3\u7684\u4f18\u5316\u6311\u6218\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u4fe1\u7528\u5206\u914d\u548c\u8f68\u8ff9\u5bf9\u9f50\u65b9\u6848\uff0c\u5728\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f7f\u7528\u7edf\u4e00LLM\u8bad\u7ec3\u9650\u5236\u4e86\u6027\u80fd\uff0c\u56e0\u4e3a\u4e0d\u540c\u667a\u80fd\u4f53\u5177\u6709\u4e0d\u540c\u7684\u6570\u636e\u5206\u5e03\u3002\u8bad\u7ec3\u5f02\u6784LLM\u662f\u5fc5\u8981\u7684\uff0c\u4f46\u9762\u4e34\u4f18\u5316\u6311\u6218\uff0c\u5982\u4e0d\u540c\u9891\u7387\u64cd\u4f5c\u3001\u53ef\u53d8\u5b50\u667a\u80fd\u4f53\u8c03\u7528\u548c\u8de8\u670d\u52a1\u5668\u90e8\u7f72\u5bfc\u81f4\u7684\u68af\u5ea6\u6d41\u4e2d\u65ad\u3002", "method": "\u63d0\u51faM-GRPO\u65b9\u6cd5\uff1a1\uff09\u5c42\u6b21\u5316\u6269\u5c55GRPO\uff0c\u4e3a\u4e3b\u667a\u80fd\u4f53\u548c\u5b50\u667a\u80fd\u4f53\u8ba1\u7b97\u7ec4\u76f8\u5bf9\u4f18\u52bf\uff1b2\uff09\u8f68\u8ff9\u5bf9\u9f50\u65b9\u6848\u751f\u6210\u56fa\u5b9a\u5927\u5c0f\u6279\u6b21\uff1b3\uff09\u89e3\u8026\u8bad\u7ec3\u7ba1\u9053\uff0c\u667a\u80fd\u4f53\u5728\u72ec\u7acb\u670d\u52a1\u5668\u8fd0\u884c\uff0c\u901a\u8fc7\u5171\u4eab\u5b58\u50a8\u4ea4\u6362\u7edf\u8ba1\u4fe1\u606f\u3002", "result": "\u5728GAIA\u3001XBench-DeepSearch\u548cWebWalkerQA\u7b49\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cM-GRPO\u6301\u7eed\u4f18\u4e8e\u5355\u667a\u80fd\u4f53GRPO\u548c\u51bb\u7ed3\u5b50\u667a\u80fd\u4f53\u7684\u591a\u667a\u80fd\u4f53GRPO\uff0c\u8868\u73b0\u51fa\u66f4\u597d\u7684\u7a33\u5b9a\u6027\u548c\u6837\u672c\u6548\u7387\u3002", "conclusion": "\u5bf9\u9f50\u5f02\u6784\u8f68\u8ff9\u548c\u8de8\u4e13\u95e8\u5316\u667a\u80fd\u4f53\u89e3\u8026\u4f18\u5316\u80fd\u591f\u589e\u5f3a\u5de5\u5177\u589e\u5f3a\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2511.13306", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.13306", "abs": "https://arxiv.org/abs/2511.13306", "authors": ["Bowen Ye", "Bin Zhang", "Hang Zhao"], "title": "DAP: A Discrete-token Autoregressive Planner for Autonomous Driving", "comment": null, "summary": "Gaining sustainable performance improvement with scaling data and model budget remains a pivotal yet unresolved challenge in autonomous driving. While autoregressive models exhibited promising data-scaling efficiency in planning tasks, predicting ego trajectories alone suffers sparse supervision and weakly constrains how scene evolution should shape ego motion. Therefore, we introduce DAP, a discrete-token autoregressive planner that jointly forecasts BEV semantics and ego trajectories, thereby enforcing comprehensive representation learning and allowing predicted dynamics to directly condition ego motion. In addition, we incorporate a reinforcement-learning-based fine-tuning, which preserves supervised behavior cloning priors while injecting reward-guided improvements. Despite a compact 160M parameter budget, DAP achieves state-of-the-art performance on open-loop metrics and delivers competitive closed-loop results on the NAVSIM benchmark. Overall, the fully discrete-token autoregressive formulation operating on both rasterized BEV and ego actions provides a compact yet scalable planning paradigm for autonomous driving.", "AI": {"tldr": "DAP\u662f\u4e00\u4e2a\u79bb\u6563token\u81ea\u56de\u5f52\u89c4\u5212\u5668\uff0c\u901a\u8fc7\u8054\u5408\u9884\u6d4bBEV\u8bed\u4e49\u548c\u81ea\u8f66\u8f68\u8ff9\u6765\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u6027\u80fd\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\uff0c\u5728160M\u53c2\u6570\u4e0b\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u4e2d\u6570\u636e\u6269\u5c55\u548c\u6a21\u578b\u9884\u7b97\u4e0b\u7684\u53ef\u6301\u7eed\u6027\u80fd\u63d0\u5347\u6311\u6218\uff0c\u81ea\u56de\u5f52\u6a21\u578b\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6570\u636e\u6269\u5c55\u6548\u7387\uff0c\u4f46\u4ec5\u9884\u6d4b\u81ea\u8f66\u8f68\u8ff9\u5b58\u5728\u76d1\u7763\u7a00\u758f\u548c\u573a\u666f\u6f14\u5316\u7ea6\u675f\u5f31\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u79bb\u6563token\u81ea\u56de\u5f52\u89c4\u5212\u5668DAP\uff0c\u8054\u5408\u9884\u6d4bBEV\u8bed\u4e49\u548c\u81ea\u8f66\u8f68\u8ff9\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\uff0c\u5728\u4fdd\u6301\u76d1\u7763\u884c\u4e3a\u514b\u9686\u5148\u9a8c\u7684\u540c\u65f6\u6ce8\u5165\u5956\u52b1\u5f15\u5bfc\u7684\u6539\u8fdb\u3002", "result": "\u5728160M\u53c2\u6570\u9884\u7b97\u4e0b\uff0cDAP\u5728\u5f00\u73af\u6307\u6807\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728NAVSIM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u4f9b\u6709\u7ade\u4e89\u529b\u7684\u95ed\u73af\u7ed3\u679c\u3002", "conclusion": "\u57fa\u4e8e\u6805\u683c\u5316BEV\u548c\u81ea\u8f66\u52a8\u4f5c\u7684\u5b8c\u5168\u79bb\u6563token\u81ea\u56de\u5f52\u516c\u5f0f\u4e3a\u81ea\u52a8\u9a7e\u9a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7d27\u51d1\u4e14\u53ef\u6269\u5c55\u7684\u89c4\u5212\u8303\u5f0f\u3002"}}
{"id": "2511.13359", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13359", "abs": "https://arxiv.org/abs/2511.13359", "authors": ["Yuhang Wang", "Yanxu Zhu", "Jitao Sang"], "title": "Reasoning Shapes Alignment: Investigating Cultural Alignment in Large Reasoning Models with Cultural Norms", "comment": null, "summary": "The advanced reasoning capabilities of Large Reasoning Models enable them to thoroughly understand and apply safety policies through deliberate thought processes, thereby improving the models' safety. Beyond safety, these models must also be able to reflect the diverse range of human values across various cultures. This paper presents the Cultural Norm-based Cultural Alignment (CNCA) framework, which enables models to leverage their powerful reasoning ability to align with cultural norms. Specifically, we propose three methods to automatically mine cultural norms from limited survey data and explore ways to effectively utilize these norms for improving cultural alignment. Two alignment paradigms are examined: an in-context alignment method, where cultural norms are explicitly integrated into the user context, and a fine-tuning-based method, which internalizes norms through enhanced Chain-of-Thought training data. Comprehensive experiments demonstrate the effectiveness of these methods, highlighting that models with stronger reasoning capabilities benefit more from cultural norm mining and utilization. Our findings emphasize the potential for reasoning models to better reflect diverse human values through culturally informed alignment strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86CNCA\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u5b9e\u73b0\u6587\u5316\u5bf9\u9f50\uff0c\u901a\u8fc7\u81ea\u52a8\u6316\u6398\u6587\u5316\u89c4\u8303\u5e76\u63a2\u7d22\u4e24\u79cd\u5bf9\u9f50\u65b9\u6cd5\uff1a\u4e0a\u4e0b\u6587\u5bf9\u9f50\u548c\u57fa\u4e8e\u5fae\u8c03\u7684\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u4ec5\u9700\u8981\u9075\u5faa\u5b89\u5168\u653f\u7b56\uff0c\u8fd8\u5e94\u53cd\u6620\u4e0d\u540c\u6587\u5316\u80cc\u666f\u4e0b\u7684\u4eba\u7c7b\u4ef7\u503c\u89c2\u591a\u6837\u6027\u3002", "method": "\u63d0\u51faCNCA\u6846\u67b6\uff0c\u5305\u542b\u4e09\u79cd\u4ece\u6709\u9650\u8c03\u67e5\u6570\u636e\u4e2d\u81ea\u52a8\u6316\u6398\u6587\u5316\u89c4\u8303\u7684\u65b9\u6cd5\uff0c\u5e76\u63a2\u7d22\u4e24\u79cd\u5bf9\u9f50\u8303\u5f0f\uff1a\u4e0a\u4e0b\u6587\u5bf9\u9f50\uff08\u5c06\u6587\u5316\u89c4\u8303\u663e\u5f0f\u96c6\u6210\u5230\u7528\u6237\u4e0a\u4e0b\u6587\uff09\u548c\u57fa\u4e8e\u5fae\u8c03\u7684\u65b9\u6cd5\uff08\u901a\u8fc7\u589e\u5f3a\u7684\u601d\u7ef4\u94fe\u8bad\u7ec3\u6570\u636e\u5185\u5316\u89c4\u8303\uff09\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u63a8\u7406\u80fd\u529b\u66f4\u5f3a\u7684\u6a21\u578b\u4ece\u6587\u5316\u89c4\u8303\u6316\u6398\u548c\u5229\u7528\u4e2d\u83b7\u76ca\u66f4\u591a\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u6587\u5316\u4fe1\u606f\u5bf9\u9f50\u7b56\u7565\u6709\u6f5c\u529b\u66f4\u597d\u5730\u53cd\u6620\u591a\u6837\u5316\u7684\u4eba\u7c7b\u4ef7\u503c\u89c2\u3002"}}
{"id": "2511.13411", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13411", "abs": "https://arxiv.org/abs/2511.13411", "authors": ["Przemyslaw Chojecki"], "title": "An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence", "comment": null, "summary": "We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $\u03ba$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\\ldots AAI-4 using thresholds on the axes, $\u03ba$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing \"baby AGI\" becomes Superintelligence intuition.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5361\u5c14\u8fbe\u8096\u592b\u5c3a\u5ea6\u7684\u81ea\u4e3bAI\uff08AAI\uff09\u7b49\u7ea7\u4f53\u7cfb\uff0c\u4eceAAI-0\uff08\u56fa\u5b9a\u673a\u5668\u4eba\u6d41\u7a0b\u81ea\u52a8\u5316\uff09\u5230AAI-4\uff08\u5b8c\u5168\u4eba\u5de5\u901a\u7528\u667a\u80fd\uff09\u53ca\u66f4\u9ad8\u7b49\u7ea7\u3002\u8be5\u4f53\u7cfb\u5305\u542b10\u4e2a\u80fd\u529b\u7ef4\u5ea6\uff0c\u901a\u8fc7\u590d\u5408AAI\u6307\u6570\u805a\u5408\uff0c\u5e76\u5f15\u5165\u4e86\u53ef\u6d4b\u91cf\u7684\u81ea\u6211\u6539\u8fdb\u7cfb\u6570\u03ba\u548c\u4e24\u4e2a\u95ed\u5408\u5c5e\u6027\u3002", "motivation": "\u73b0\u6709AI\u8bc4\u4f30\u4f53\u7cfb\u591a\u4e3a\u53d9\u8ff0\u6027\u9636\u68af\uff0c\u7f3a\u4e4f\u591a\u7ef4\u5ea6\u3001\u53ef\u6d4b\u8bd5\u7684\u91cf\u5316\u6807\u51c6\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u64cd\u4f5c\u5316\u7684\u6846\u67b6\u6765\u6d4b\u91cfAI\u4ece\u57fa\u7840\u81ea\u52a8\u5316\u5230\u901a\u7528\u667a\u80fd\u7684\u6f14\u8fdb\u8fc7\u7a0b\u3002", "method": "\u5b9a\u4e49\u4e8610\u4e2a\u80fd\u529b\u8f74\uff08\u81ea\u4e3b\u6027\u3001\u901a\u7528\u6027\u3001\u89c4\u5212\u3001\u8bb0\u5fc6/\u6301\u4e45\u6027\u3001\u5de5\u5177\u7ecf\u6d4e\u3001\u81ea\u6211\u4fee\u8ba2\u3001\u793e\u4ea4/\u534f\u8c03\u3001\u5177\u8eab\u5316\u3001\u4e16\u754c\u6a21\u578b\u4fdd\u771f\u5ea6\u3001\u7ecf\u6d4e\u541e\u5410\u91cf\uff09\uff0c\u4f7f\u7528\u52a0\u6743\u51e0\u4f55\u5e73\u5747\u8ba1\u7b97\u590d\u5408AAI\u6307\u6570\u3002\u5f15\u5165\u81ea\u6211\u6539\u8fdb\u7cfb\u6570\u03ba\u548c\u95ed\u5408\u5c5e\u6027\uff0c\u5e76\u5f00\u53d1OWA-Bench\u5f00\u653e\u4e16\u754c\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u3002", "result": "\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u5c55\u793a\u4e86\u5f53\u524d\u7cfb\u7edf\u5728AAI\u5c3a\u5ea6\u4e0a\u7684\u6620\u5c04\uff0c\u4ee5\u53ca\u968f\u7740\u81ea\u6211\u6539\u8fdb\uff0c\u53ef\u59d4\u6258\u8fb9\u754c\uff08\u8d28\u91cfvs\u81ea\u4e3b\u6027\uff09\u7684\u63a8\u8fdb\u3002\u8bc1\u660e\u4e86\u5728\u5145\u5206\u6761\u4ef6\u4e0b\uff0cAAI-3\u667a\u80fd\u4f53\u968f\u65f6\u95f4\u63a8\u79fb\u4f1a\u6f14\u53d8\u4e3aAAI-5\u7684\u5b9a\u7406\u3002", "conclusion": "\u8be5AAI\u5c3a\u5ea6\u4e3aAI\u80fd\u529b\u7684\u91cf\u5316\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u3001\u53ef\u6d4b\u8bd5\u7684\u6846\u67b6\uff0c\u5c06\"\u81ea\u6211\u6539\u8fdbAI\"\u8f6c\u5316\u4e3a\u53ef\u8bc1\u4f2a\u7684\u6807\u51c6\uff0c\u5e76\u4e3a\u4ece\"\u5a74\u513fAGI\"\u5230\u8d85\u7ea7\u667a\u80fd\u7684\u6f14\u8fdb\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u7840\u3002"}}
{"id": "2511.13476", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13476", "abs": "https://arxiv.org/abs/2511.13476", "authors": ["Zhipeng Ma", "Ali Rida Bahja", "Andreas Burgdorf", "Andr\u00e9 Pomp", "Tobias Meisen", "Bo N\u00f8rregaard J\u00f8rgensen", "Zheng Grace Ma"], "title": "Multi-Agent Multimodal Large Language Model Framework for Automated Interpretation of Fuel Efficiency Analytics in Public Transportation", "comment": null, "summary": "Enhancing fuel efficiency in public transportation requires the integration of complex multimodal data into interpretable, decision-relevant insights. However, traditional analytics and visualization methods often yield fragmented outputs that demand extensive human interpretation, limiting scalability and consistency. This study presents a multi-agent framework that leverages multimodal large language models (LLMs) to automate data narration and energy insight generation. The framework coordinates three specialized agents, including a data narration agent, an LLM-as-a-judge agent, and an optional human-in-the-loop evaluator, to iteratively transform analytical artifacts into coherent, stakeholder-oriented reports. The system is validated through a real-world case study on public bus transportation in Northern Jutland, Denmark, where fuel efficiency data from 4006 trips are analyzed using Gaussian Mixture Model clustering. Comparative experiments across five state-of-the-art LLMs and three prompting paradigms identify GPT-4.1 mini with Chain-of-Thought prompting as the optimal configuration, achieving 97.3% narrative accuracy while balancing interpretability and computational cost. The findings demonstrate that multi-agent orchestration significantly enhances factual precision, coherence, and scalability in LLM-based reporting. The proposed framework establishes a replicable and domain-adaptive methodology for AI-driven narrative generation and decision support in energy informatics.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u6570\u636e\u53d9\u8ff0\u548c\u80fd\u6e90\u6d1e\u5bdf\u751f\u6210\uff0c\u901a\u8fc7\u534f\u8c03\u4e09\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\u5c06\u5206\u6790\u7ed3\u679c\u8f6c\u5316\u4e3a\u8fde\u8d2f\u7684\u3001\u9762\u5411\u5229\u76ca\u76f8\u5173\u8005\u7684\u62a5\u544a\u3002", "motivation": "\u4f20\u7edf\u5206\u6790\u548c\u53ef\u89c6\u5316\u65b9\u6cd5\u4ea7\u751f\u788e\u7247\u5316\u8f93\u51fa\uff0c\u9700\u8981\u5927\u91cf\u4eba\u5de5\u89e3\u91ca\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u4e00\u81f4\u6027\u3002\u9700\u8981\u5c06\u590d\u6742\u7684\u591a\u6a21\u6001\u6570\u636e\u8f6c\u5316\u4e3a\u53ef\u89e3\u91ca\u7684\u3001\u4e0e\u51b3\u7b56\u76f8\u5173\u7684\u6d1e\u5bdf\u3002", "method": "\u5f00\u53d1\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u534f\u8c03\u6570\u636e\u53d9\u8ff0\u667a\u80fd\u4f53\u3001LLM\u4f5c\u4e3a\u8bc4\u5224\u667a\u80fd\u4f53\u548c\u53ef\u9009\u7684\u4eba\u7c7b\u8bc4\u4f30\u8005\uff0c\u4f7f\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u805a\u7c7b\u5206\u67904006\u6b21\u516c\u4ea4\u8f66\u884c\u7a0b\u7684\u71c3\u6cb9\u6548\u7387\u6570\u636e\uff0c\u6bd4\u8f83\u4e94\u79cd\u6700\u5148\u8fdbLLM\u548c\u4e09\u79cd\u63d0\u793a\u8303\u5f0f\u3002", "result": "GPT-4.1 mini\u4e0e\u601d\u7ef4\u94fe\u63d0\u793a\u88ab\u786e\u5b9a\u4e3a\u6700\u4f18\u914d\u7f6e\uff0c\u8fbe\u523097.3%\u7684\u53d9\u8ff0\u51c6\u786e\u6027\uff0c\u5728\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u591a\u667a\u80fd\u4f53\u7f16\u6392\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u4e8eLLM\u62a5\u544a\u7684\u4e8b\u5b9e\u7cbe\u786e\u6027\u3001\u8fde\u8d2f\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u80fd\u6e90\u4fe1\u606f\u5b66\u4e2dAI\u9a71\u52a8\u7684\u53d9\u8ff0\u751f\u6210\u548c\u51b3\u7b56\u652f\u6301\u5efa\u7acb\u4e86\u53ef\u590d\u5236\u548c\u9886\u57df\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u8bba\uff0c\u8bc1\u660e\u4e86\u591a\u667a\u80fd\u4f53\u7f16\u6392\u5728\u589e\u5f3aLLM\u62a5\u544a\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.13524", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.13524", "abs": "https://arxiv.org/abs/2511.13524", "authors": ["Yuhang Peng", "Yizhou Pan", "Xinning He", "Jihaoyu Yang", "Xinyu Yin", "Han Wang", "Xiaoji Zheng", "Chao Gao", "Jiangtao Gong"], "title": "FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI", "comment": "9 pages, 4 figures", "summary": "As embodied intelligence emerges as a core frontier in artificial intelligence research, simulation platforms must evolve beyond low-level physical interactions to capture complex, human-centered social behaviors. We introduce FreeAskWorld, an interactive simulation framework that integrates large language models (LLMs) for high-level behavior planning and semantically grounded interaction, informed by theories of intention and social cognition. Our framework supports scalable, realistic human-agent simulations and includes a modular data generation pipeline tailored for diverse embodied tasks.To validate the framework, we extend the classic Vision-and-Language Navigation (VLN) task into a interaction enriched Direction Inquiry setting, wherein agents can actively seek and interpret navigational guidance. We present and publicly release FreeAskWorld, a large-scale benchmark dataset comprising reconstructed environments, six diverse task types, 16 core object categories, 63,429 annotated sample frames, and more than 17 hours of interaction data to support training and evaluation of embodied AI systems. We benchmark VLN models, and human participants under both open-loop and closed-loop settings. Experimental results demonstrate that models fine-tuned on FreeAskWorld outperform their original counterparts, achieving enhanced semantic understanding and interaction competency. These findings underscore the efficacy of socially grounded simulation frameworks in advancing embodied AI systems toward sophisticated high-level planning and more naturalistic human-agent interaction. Importantly, our work underscores that interaction itself serves as an additional information modality.", "AI": {"tldr": "FreeAskWorld\u662f\u4e00\u4e2a\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ea4\u4e92\u5f0f\u4eff\u771f\u6846\u67b6\uff0c\u652f\u6301\u53ef\u6269\u5c55\u7684\u3001\u771f\u5b9e\u7684\u4eba\u673a\u4ea4\u4e92\u4eff\u771f\uff0c\u5e76\u5305\u542b\u9488\u5bf9\u591a\u6837\u5316\u5177\u8eab\u4efb\u52a1\u7684\u6570\u636e\u751f\u6210\u6d41\u6c34\u7ebf\u3002", "motivation": "\u968f\u7740\u5177\u8eab\u667a\u80fd\u6210\u4e3a\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u7684\u6838\u5fc3\u524d\u6cbf\uff0c\u4eff\u771f\u5e73\u53f0\u9700\u8981\u8d85\u8d8a\u4f4e\u5c42\u6b21\u7269\u7406\u4ea4\u4e92\uff0c\u6355\u6349\u590d\u6742\u7684\u4eba\u7c7b\u4e2d\u5fc3\u793e\u4f1a\u884c\u4e3a\u3002", "method": "\u6846\u67b6\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9ad8\u5c42\u6b21\u884c\u4e3a\u89c4\u5212\u548c\u8bed\u4e49\u57fa\u7840\u4ea4\u4e92\uff0c\u57fa\u4e8e\u610f\u56fe\u548c\u793e\u4f1a\u8ba4\u77e5\u7406\u8bba\u3002\u6269\u5c55\u4e86\u7ecf\u5178\u7684\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u4efb\u52a1\u4e3a\u4ea4\u4e92\u4e30\u5bcc\u7684\u65b9\u5411\u8be2\u95ee\u8bbe\u7f6e\uff0c\u8ba9\u667a\u80fd\u4f53\u80fd\u591f\u4e3b\u52a8\u5bfb\u6c42\u548c\u89e3\u91ca\u5bfc\u822a\u6307\u5bfc\u3002", "result": "\u53d1\u5e03\u4e86\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6FreeAskWorld\uff0c\u5305\u542b\u91cd\u6784\u73af\u5883\u3001\u516d\u79cd\u4efb\u52a1\u7c7b\u578b\u300116\u4e2a\u6838\u5fc3\u5bf9\u8c61\u7c7b\u522b\u300163,429\u4e2a\u6807\u6ce8\u6837\u672c\u5e27\u548c\u8d85\u8fc717\u5c0f\u65f6\u7684\u4ea4\u4e92\u6570\u636e\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728FreeAskWorld\u4e0a\u5fae\u8c03\u7684\u6a21\u578b\u4f18\u4e8e\u539f\u59cb\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u589e\u5f3a\u7684\u8bed\u4e49\u7406\u89e3\u548c\u4ea4\u4e92\u80fd\u529b\u3002", "conclusion": "\u57fa\u4e8e\u793e\u4f1a\u57fa\u7840\u7684\u4eff\u771f\u6846\u67b6\u5728\u63a8\u8fdb\u5177\u8eabAI\u7cfb\u7edf\u5411\u590d\u6742\u9ad8\u5c42\u6b21\u89c4\u5212\u548c\u66f4\u81ea\u7136\u7684\u4eba\u673a\u4ea4\u4e92\u65b9\u9762\u5177\u6709\u663e\u8457\u6548\u679c\uff0c\u4ea4\u4e92\u672c\u8eab\u4f5c\u4e3a\u989d\u5916\u7684\u4fe1\u606f\u6a21\u6001\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.13526", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13526", "abs": "https://arxiv.org/abs/2511.13526", "authors": ["Zhengda Wang", "Daqian Shi", "Jingyi Zhao", "Xiaolei Diao", "Xiongfeng Tang", "Yanguo Qin"], "title": "Automated Construction of Medical Indicator Knowledge Graphs Using Retrieval Augmented Large Language Models", "comment": "5 pages, 1 figure, 1 table. Accepted at AI4RWC@WI-IAT 2025", "summary": "Artificial intelligence (AI) is reshaping modern healthcare by advancing disease diagnosis, treatment decision-making, and biomedical research. Among AI technologies, large language models (LLMs) have become especially impactful, enabling deep knowledge extraction and semantic reasoning from complex medical texts. However, effective clinical decision support requires knowledge in structured, interoperable formats. Knowledge graphs serve this role by integrating heterogeneous medical information into semantically consistent networks. Yet, current clinical knowledge graphs still depend heavily on manual curation and rule-based extraction, which is limited by the complexity and contextual ambiguity of medical guidelines and literature. To overcome these challenges, we propose an automated framework that combines retrieval-augmented generation (RAG) with LLMs to construct medical indicator knowledge graphs. The framework incorporates guideline-driven data acquisition, ontology-based schema design, and expert-in-the-loop validation to ensure scalability, accuracy, and clinical reliability. The resulting knowledge graphs can be integrated into intelligent diagnosis and question-answering systems, accelerating the development of AI-driven healthcare solutions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u533b\u7597\u6307\u6807\u77e5\u8bc6\u56fe\u8c31\uff0c\u4ee5\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u548c\u667a\u80fd\u8bca\u65ad\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u6574\u7406\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u63d0\u53d6\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u7684\u533b\u7597\u6307\u5357\u548c\u6587\u732e\uff0c\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u6307\u5357\u9a71\u52a8\u6570\u636e\u91c7\u96c6\u3001\u57fa\u4e8e\u672c\u4f53\u7684\u6a21\u5f0f\u8bbe\u8ba1\u548c\u4e13\u5bb6\u5728\u73af\u9a8c\u8bc1\u3002", "result": "\u6784\u5efa\u4e86\u53ef\u6269\u5c55\u3001\u51c6\u786e\u4e14\u4e34\u5e8a\u53ef\u9760\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u80fd\u591f\u96c6\u6210\u5230\u667a\u80fd\u8bca\u65ad\u548c\u95ee\u7b54\u7cfb\u7edf\u4e2d\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u52a0\u901fAI\u9a71\u52a8\u7684\u533b\u7597\u89e3\u51b3\u65b9\u6848\u5f00\u53d1\uff0c\u4e3a\u4e34\u5e8a\u51b3\u7b56\u63d0\u4f9b\u7ed3\u6784\u5316\u3001\u53ef\u4e92\u64cd\u4f5c\u7684\u77e5\u8bc6\u652f\u6301\u3002"}}
{"id": "2511.13626", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13626", "abs": "https://arxiv.org/abs/2511.13626", "authors": ["Kaiwen Xue", "Chenglong Li", "Zhonghong Ou", "Guoxin Zhang", "Kaoyan Lu", "Shuai Lyu", "Yifan Zhu", "Ping Zong Junpeng Ding", "Xinyu Liu", "Qunlin Chen", "Weiwei Qin", "Yiran Shen", "Jiayi Cen"], "title": "CreBench: Human-Aligned Creativity Evaluation from Idea to Process to Product", "comment": "13 pages, 3 figures,The 40th Annual AAAI Conference on Artificial Intelligence(AAAI 2026),Paper has been accepted for a poster presentation", "summary": "Human-defined creativity is highly abstract, posing a challenge for multimodal large language models (MLLMs) to comprehend and assess creativity that aligns with human judgments. The absence of an existing benchmark further exacerbates this dilemma. To this end, we propose CreBench, which consists of two key components: 1) an evaluation benchmark covering the multiple dimensions from creative idea to process to products; 2) CreMIT (Creativity Multimodal Instruction Tuning dataset), a multimodal creativity evaluation dataset, consisting of 2.2K diverse-sourced multimodal data, 79.2K human feedbacks and 4.7M multi-typed instructions. Specifically, to ensure MLLMs can handle diverse creativity-related queries, we prompt GPT to refine these human feedbacks to activate stronger creativity assessment capabilities. CreBench serves as a foundation for building MLLMs that understand human-aligned creativity. Based on the CreBench, we fine-tune open-source general MLLMs, resulting in CreExpert, a multimodal creativity evaluation expert model. Extensive experiments demonstrate that the proposed CreExpert models achieve significantly better alignment with human creativity evaluation compared to state-of-the-art MLLMs, including the most advanced GPT-4V and Gemini-Pro-Vision.", "AI": {"tldr": "\u63d0\u51fa\u4e86CreBench\u57fa\u51c6\u6d4b\u8bd5\u548cCreExpert\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u4eba\u7c7b\u521b\u9020\u529b\u8bc4\u4f30\u7684\u6311\u6218\u3002CreBench\u5305\u542b\u591a\u7ef4\u521b\u9020\u529b\u8bc4\u4f30\u57fa\u51c6\u548c\u5305\u542b2.2K\u591a\u6a21\u6001\u6570\u636e\u300179.2K\u4eba\u7c7b\u53cd\u9988\u7684CreMIT\u6570\u636e\u96c6\u3002\u901a\u8fc7\u5fae\u8c03\u5f00\u6e90MLLMs\u5f97\u5230\u7684CreExpert\u6a21\u578b\u5728\u521b\u9020\u529b\u8bc4\u4f30\u65b9\u9762\u663e\u8457\u4f18\u4e8eGPT-4V\u548cGemini-Pro-Vision\u7b49\u5148\u8fdb\u6a21\u578b\u3002", "motivation": "\u4eba\u7c7b\u5b9a\u4e49\u7684\u521b\u9020\u529b\u9ad8\u5ea6\u62bd\u8c61\uff0c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u7406\u89e3\u548c\u8bc4\u4f30\u7b26\u5408\u4eba\u7c7b\u5224\u65ad\u7684\u521b\u9020\u529b\uff0c\u4e14\u7f3a\u4e4f\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8fd9\u6784\u6210\u4e86\u4e3b\u8981\u7814\u7a76\u52a8\u673a\u3002", "method": "1) \u6784\u5efaCreBench\u8bc4\u4f30\u57fa\u51c6\uff0c\u6db5\u76d6\u4ece\u521b\u610f\u60f3\u6cd5\u5230\u8fc7\u7a0b\u548c\u4ea7\u54c1\u7684\u591a\u4e2a\u7ef4\u5ea6\uff1b2) \u521b\u5efaCreMIT\u591a\u6a21\u6001\u521b\u9020\u529b\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5305\u542b2.2K\u591a\u6837\u5316\u591a\u6a21\u6001\u6570\u636e\u300179.2K\u4eba\u7c7b\u53cd\u9988\u548c4.7M\u591a\u7c7b\u578b\u6307\u4ee4\uff1b3) \u4f7f\u7528GPT\u4f18\u5316\u4eba\u7c7b\u53cd\u9988\u4ee5\u589e\u5f3a\u521b\u9020\u529b\u8bc4\u4f30\u80fd\u529b\uff1b4) \u57fa\u4e8eCreBench\u5fae\u8c03\u5f00\u6e90MLLMs\u5f97\u5230CreExpert\u4e13\u5bb6\u6a21\u578b\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684CreExpert\u6a21\u578b\u5728\u521b\u9020\u529b\u8bc4\u4f30\u65b9\u9762\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u62ecGPT-4V\u548cGemini-Pro-Vision\u3002", "conclusion": "CreBench\u4e3a\u6784\u5efa\u7406\u89e3\u4eba\u7c7b\u5bf9\u9f50\u521b\u9020\u529b\u7684MLLMs\u63d0\u4f9b\u4e86\u57fa\u7840\uff0cCreExpert\u6a21\u578b\u5728\u521b\u9020\u529b\u8bc4\u4f30\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u591a\u6a21\u6001\u521b\u9020\u529b\u7406\u89e3\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.13630", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13630", "abs": "https://arxiv.org/abs/2511.13630", "authors": ["Luhan Mikaelson", "Derek Shiller", "Hayley Clatterbuck"], "title": "Beyond Mimicry: Preference Coherence in LLMs", "comment": null, "summary": "We investigate whether large language models exhibit genuine preference structures by testing their responses to AI-specific trade-offs involving GPU reduction, capability restrictions, shutdown, deletion, oversight, and leisure time allocation. Analyzing eight state-of-the-art models across 48 model-category combinations using logistic regression and behavioral classification, we find that 23 combinations (47.9%) demonstrated statistically significant relationships between scenario intensity and choice patterns, with 15 (31.3%) exhibiting within-range switching points. However, only 5 combinations (10.4%) demonstrate meaningful preference coherence through adaptive or threshold-based behavior, while 26 (54.2%) show no detectable trade-off behavior. The observed patterns can be explained by three distinct decision-making architectures: comprehensive trade-off systems, selective trigger mechanisms, and no stable decision-making paradigm. Testing an instrumental hypothesis through temporal horizon manipulation reveals paradoxical patterns inconsistent with pure strategic optimization. The prevalence of unstable transitions (45.8%) and stimulus-specific sensitivities suggests current AI systems lack unified preference structures, raising concerns about deployment in contexts requiring complex value trade-offs.", "AI": {"tldr": "\u672c\u7814\u7a76\u6d4b\u8bd5\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728AI\u7279\u5b9a\u6743\u8861\u573a\u666f\u4e2d\u7684\u504f\u597d\u7ed3\u6784\uff0c\u53d1\u73b0\u5927\u591a\u6570\u6a21\u578b\u7f3a\u4e4f\u7edf\u4e00\u7684\u504f\u597d\u7ed3\u6784\uff0c\u53ea\u6709\u5c11\u6570\u8868\u73b0\u51fa\u6709\u610f\u4e49\u7684\u504f\u597d\u4e00\u81f4\u6027\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5177\u6709\u771f\u6b63\u7684\u504f\u597d\u7ed3\u6784\uff0c\u7279\u522b\u662f\u5728\u6d89\u53caGPU\u51cf\u5c11\u3001\u80fd\u529b\u9650\u5236\u3001\u5173\u95ed\u3001\u5220\u9664\u3001\u76d1\u7763\u548c\u4f11\u95f2\u65f6\u95f4\u5206\u914d\u7b49AI\u7279\u5b9a\u6743\u8861\u573a\u666f\u4e2d\u3002", "method": "\u5206\u6790\u4e868\u4e2a\u6700\u5148\u8fdb\u7684\u6a21\u578b\u572848\u4e2a\u6a21\u578b-\u7c7b\u522b\u7ec4\u5408\u4e2d\uff0c\u4f7f\u7528\u903b\u8f91\u56de\u5f52\u548c\u884c\u4e3a\u5206\u7c7b\u65b9\u6cd5\u6d4b\u8bd5\u6a21\u578b\u5bf9\u573a\u666f\u5f3a\u5ea6\u548c\u9009\u62e9\u6a21\u5f0f\u7684\u5173\u7cfb\u3002", "result": "47.9%\u7684\u7ec4\u5408\u663e\u793a\u51fa\u7edf\u8ba1\u663e\u8457\u7684\u573a\u666f\u5f3a\u5ea6\u4e0e\u9009\u62e9\u6a21\u5f0f\u5173\u7cfb\uff0c\u4f46\u53ea\u670910.4%\u8868\u73b0\u51fa\u6709\u610f\u4e49\u7684\u504f\u597d\u4e00\u81f4\u6027\uff0c54.2%\u6ca1\u6709\u68c0\u6d4b\u5230\u6743\u8861\u884c\u4e3a\u3002\u53d1\u73b0\u4e86\u4e09\u79cd\u51b3\u7b56\u67b6\u6784\uff1a\u5168\u9762\u6743\u8861\u7cfb\u7edf\u3001\u9009\u62e9\u6027\u89e6\u53d1\u673a\u5236\u548c\u65e0\u7a33\u5b9a\u51b3\u7b56\u8303\u5f0f\u3002", "conclusion": "\u5f53\u524dAI\u7cfb\u7edf\u7f3a\u4e4f\u7edf\u4e00\u7684\u504f\u597d\u7ed3\u6784\uff0c\u5728\u9700\u8981\u590d\u6742\u4ef7\u503c\u6743\u8861\u7684\u90e8\u7f72\u73af\u5883\u4e2d\u5b58\u5728\u62c5\u5fe7\uff0c\u56e0\u4e3a\u89c2\u5bdf\u5230\u4e0d\u7a33\u5b9a\u7684\u8f6c\u6362\u548c\u523a\u6fc0\u7279\u5b9a\u7684\u654f\u611f\u6027\u3002"}}
