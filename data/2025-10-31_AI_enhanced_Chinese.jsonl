{"id": "2510.25802", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25802", "abs": "https://arxiv.org/abs/2510.25802", "authors": ["Jayant Biradar", "Smit Shah", "Tanmay Naik"], "title": "Attention Augmented GNN RNN-Attention Models for Advanced Cybersecurity Intrusion Detection", "comment": null, "summary": "In this paper, we propose a novel hybrid deep learning architecture that\nsynergistically combines Graph Neural Networks (GNNs), Recurrent Neural\nNetworks (RNNs), and multi-head attention mechanisms to significantly enhance\ncybersecurity intrusion detection capabilities. By leveraging the comprehensive\nUNSW-NB15 dataset containing diverse network traffic patterns, our approach\neffectively captures both spatial dependencies through graph structural\nrelationships and temporal dynamics through sequential analysis of network\nevents. The integrated attention mechanism provides dual benefits of improved\nmodel interpretability and enhanced feature selection, enabling cybersecurity\nanalysts to focus computational resources on high-impact security events -- a\ncritical requirement in modern real-time intrusion detection systems. Our\nextensive experimental evaluation demonstrates that the proposed hybrid model\nachieves superior performance compared to traditional machine learning\napproaches and standalone deep learning models across multiple evaluation\nmetrics, including accuracy, precision, recall, and F1-score. The model\nachieves particularly strong performance in detecting sophisticated attack\npatterns such as Advanced Persistent Threats (APTs), Distributed Denial of\nService (DDoS) attacks, and zero-day exploits, making it a promising solution\nfor next-generation cybersecurity applications in complex network environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548c\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u7528\u4e8e\u63d0\u5347\u7f51\u7edc\u5b89\u5168\u5165\u4fb5\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u4ee3\u5b9e\u65f6\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u9700\u8981\u80fd\u591f\u6709\u6548\u6355\u6349\u7f51\u7edc\u6d41\u91cf\u7684\u7a7a\u95f4\u4f9d\u8d56\u6027\u548c\u65f6\u95f4\u52a8\u6001\uff0c\u540c\u65f6\u63d0\u4f9b\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u4ee5\u5e2e\u52a9\u5b89\u5168\u5206\u6790\u5e08\u805a\u7126\u9ad8\u5f71\u54cd\u5b89\u5168\u4e8b\u4ef6\u3002", "method": "\u4f7f\u7528UNSW-NB15\u6570\u636e\u96c6\uff0c\u901a\u8fc7GNN\u6355\u6349\u7a7a\u95f4\u7ed3\u6784\u5173\u7cfb\uff0cRNN\u5206\u6790\u65f6\u5e8f\u52a8\u6001\uff0c\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u7279\u5f81\u9009\u62e9\u548c\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u7b49\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\uff0c\u8be5\u6df7\u5408\u6a21\u578b\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u548c\u5355\u4e00\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7279\u522b\u5728\u68c0\u6d4bAPT\u3001DDoS\u548c\u96f6\u65e5\u653b\u51fb\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u6df7\u5408\u67b6\u6784\u662f\u590d\u6742\u7f51\u7edc\u73af\u5883\u4e2d\u4e0b\u4e00\u4ee3\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u7684\u6709\u524d\u666f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25806", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.25806", "abs": "https://arxiv.org/abs/2510.25806", "authors": ["Mustafa F. Abdelwahed", "Ahmed Shafee", "Joan Espasa"], "title": "APThreatHunter: An automated planning-based threat hunting framework", "comment": null, "summary": "Cyber attacks threaten economic interests, critical infrastructure, and\npublic health and safety. To counter this, entities adopt cyber threat hunting,\na proactive approach that involves formulating hypotheses and searching for\nattack patterns within organisational networks. Automating cyber threat hunting\npresents challenges, particularly in generating hypotheses, as it is a manually\ncreated and confirmed process, making it time-consuming. To address these\nchallenges, we introduce APThreatHunter, an automated threat hunting solution\nthat generates hypotheses with minimal human intervention, eliminating analyst\nbias and reducing time and cost. This is done by presenting possible risks\nbased on the system's current state and a set of indicators to indicate whether\nany of the detected risks are happening or not. We evaluated APThreatHunter\nusing real-world Android malware samples, and the results revealed the\npracticality of using automated planning for goal hypothesis generation in\ncyber threat hunting activities.", "AI": {"tldr": "APThreatHunter\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u7f51\u7edc\u5a01\u80c1\u72e9\u730e\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u5047\u8bbe\u6765\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\uff0c\u6d88\u9664\u5206\u6790\u5e08\u504f\u89c1\uff0c\u964d\u4f4e\u65f6\u95f4\u548c\u6210\u672c\u3002", "motivation": "\u7f51\u7edc\u653b\u51fb\u5a01\u80c1\u7ecf\u6d4e\u5229\u76ca\u3001\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u548c\u516c\u5171\u5065\u5eb7\u5b89\u5168\u3002\u4f20\u7edf\u7f51\u7edc\u5a01\u80c1\u72e9\u730e\u9700\u8981\u624b\u52a8\u521b\u5efa\u548c\u786e\u8ba4\u5047\u8bbe\uff0c\u8017\u65f6\u4e14\u5b58\u5728\u504f\u89c1\u3002", "method": "\u5f15\u5165APThreatHunter\uff0c\u57fa\u4e8e\u7cfb\u7edf\u5f53\u524d\u72b6\u6001\u548c\u4e00\u7ec4\u6307\u6807\u81ea\u52a8\u751f\u6210\u5047\u8bbe\uff0c\u5c55\u793a\u53ef\u80fd\u7684\u98ce\u9669\u5e76\u6307\u793a\u662f\u5426\u68c0\u6d4b\u5230\u98ce\u9669\u3002", "result": "\u4f7f\u7528\u771f\u5b9eAndroid\u6076\u610f\u8f6f\u4ef6\u6837\u672c\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u81ea\u52a8\u5316\u89c4\u5212\u5728\u76ee\u6807\u5047\u8bbe\u751f\u6210\u65b9\u9762\u5177\u6709\u5b9e\u7528\u6027\u3002", "conclusion": "\u81ea\u52a8\u5316\u89c4\u5212\u53ef\u7528\u4e8e\u7f51\u7edc\u5a01\u80c1\u72e9\u730e\u6d3b\u52a8\u4e2d\u7684\u76ee\u6807\u5047\u8bbe\u751f\u6210\uff0c\u5c55\u73b0\u4e86\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.25810", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.25810", "abs": "https://arxiv.org/abs/2510.25810", "authors": ["Quanliang Jing", "Xinxin Fan", "Yanyan Liu", "Jingping Bi"], "title": "Adversarial Pre-Padding: Generating Evasive Network Traffic Against Transformer-Based Classifiers", "comment": null, "summary": "To date, traffic obfuscation techniques have been widely adopted to protect\nnetwork data privacy and security by obscuring the true patterns of traffic.\nNevertheless, as the pre-trained models emerge, especially transformer-based\nclassifiers, existing traffic obfuscation methods become increasingly\nvulnerable, as witnessed by current studies reporting the traffic\nclassification accuracy up to 99\\% or higher. To counter such high-performance\ntransformer-based classification models, we in this paper propose a novel and\neffective \\underline{adv}ersarial \\underline{traffic}-generating approach\n(AdvTraffic\\footnote{The code and data are available at: http://xxx}). Our\napproach has two key innovations: (i) a pre-padding strategy is proposed to\nmodify packets, which effectively overcomes the limitations of existing\nresearch against transformer-based models for network traffic classification;\nand (ii) a reinforcement learning model is employed to optimize network traffic\nperturbations, aiming to maximize adversarial effectiveness against\ntransformer-based classification models. To the best of our knowledge, this is\nthe first attempt to apply adversarial perturbation techniques to defend\nagainst transformer-based traffic classifiers. Furthermore, our method can be\neasily deployed into practical network environments. Finally, multi-faceted\nexperiments are conducted across several real-world datasets, and the\nexperimental results demonstrate that our proposed method can effectively\nundermine transformer-based classifiers, significantly reducing classification\naccuracy from 99\\% to as low as 25.68\\%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAdvTraffic\u7684\u5bf9\u6297\u6027\u6d41\u91cf\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u586b\u5145\u7b56\u7565\u548c\u5f3a\u5316\u5b66\u4e60\u6765\u4f18\u5316\u6d41\u91cf\u6270\u52a8\uff0c\u6709\u6548\u5bf9\u6297\u57fa\u4e8eTransformer\u7684\u6d41\u91cf\u5206\u7c7b\u5668\uff0c\u5c06\u5206\u7c7b\u51c6\u786e\u7387\u4ece99%\u964d\u81f325.68%\u3002", "motivation": "\u968f\u7740\u9884\u8bad\u7ec3\u6a21\u578b\u7279\u522b\u662f\u57fa\u4e8eTransformer\u7684\u5206\u7c7b\u5668\u7684\u53d1\u5c55\uff0c\u73b0\u6709\u7684\u6d41\u91cf\u6df7\u6dc6\u6280\u672f\u53d8\u5f97\u8106\u5f31\uff0c\u8fd9\u4e9b\u5206\u7c7b\u5668\u80fd\u8fbe\u523099%\u4ee5\u4e0a\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u9884\u586b\u5145\u7b56\u7565\u4fee\u6539\u6570\u636e\u5305\uff0c\u5e76\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u4f18\u5316\u7f51\u7edc\u6d41\u91cf\u6270\u52a8\uff0c\u4ee5\u6700\u5927\u5316\u5bf9\u6297\u57fa\u4e8eTransformer\u5206\u7c7b\u6a21\u578b\u7684\u6548\u679c\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u524a\u5f31\u57fa\u4e8eTransformer\u7684\u5206\u7c7b\u5668\uff0c\u5c06\u5206\u7c7b\u51c6\u786e\u7387\u4ece99%\u663e\u8457\u964d\u4f4e\u523025.68%\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c06\u5bf9\u6297\u6027\u6270\u52a8\u6280\u672f\u5e94\u7528\u4e8e\u9632\u5fa1\u57fa\u4e8eTransformer\u7684\u6d41\u91cf\u5206\u7c7b\u5668\uff0c\u4e14\u8be5\u65b9\u6cd5\u6613\u4e8e\u5728\u5b9e\u9645\u7f51\u7edc\u73af\u5883\u4e2d\u90e8\u7f72\u3002"}}
{"id": "2510.25819", "categories": ["cs.CR", "cs.AI", "cs.NI", "68M12", "D.4.6; K.6.5; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.25819", "abs": "https://arxiv.org/abs/2510.25819", "authors": ["Tobin South", "Subramanya Nagabhushanaradhya", "Ayesha Dissanayaka", "Sarah Cecchetti", "George Fletcher", "Victor Lu", "Aldo Pietropaolo", "Dean H. Saxe", "Jeff Lombardo", "Abhishek Maligehalli Shivalingaiah", "Stan Bounev", "Alex Keisner", "Andor Kesselman", "Zack Proser", "Ginny Fahs", "Andrew Bunyea", "Ben Moskowitz", "Atul Tulshibagwale", "Dazza Greenwood", "Jiaxin Pei", "Alex Pentland"], "title": "Identity Management for Agentic AI: The new frontier of authorization, authentication, and security for an AI agent world", "comment": null, "summary": "The rapid rise of AI agents presents urgent challenges in authentication,\nauthorization, and identity management. Current agent-centric protocols (like\nMCP) highlight the demand for clarified best practices in authentication and\nauthorization. Looking ahead, ambitions for highly autonomous agents raise\ncomplex long-term questions regarding scalable access control, agent-centric\nidentities, AI workload differentiation, and delegated authority. This OpenID\nFoundation whitepaper is for stakeholders at the intersection of AI agents and\naccess management. It outlines the resources already available for securing\ntoday's agents and presents a strategic agenda to address the foundational\nauthentication, authorization, and identity problems pivotal for tomorrow's\nwidespread autonomous systems.", "AI": {"tldr": "\u8be5OpenID\u57fa\u91d1\u4f1a\u767d\u76ae\u4e66\u9488\u5bf9AI\u4ee3\u7406\u4e0e\u8bbf\u95ee\u7ba1\u7406\u7684\u4ea4\u53c9\u9886\u57df\uff0c\u5206\u6790\u4e86\u5f53\u524d\u8ba4\u8bc1\u6388\u6743\u6311\u6218\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u81ea\u4e3b\u7cfb\u7edf\u7684\u6218\u7565\u8bae\u7a0b\u3002", "motivation": "AI\u4ee3\u7406\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u8ba4\u8bc1\u3001\u6388\u6743\u548c\u8eab\u4efd\u7ba1\u7406\u7684\u7d27\u8feb\u6311\u6218\uff0c\u73b0\u6709\u534f\u8bae\u663e\u793a\u9700\u8981\u660e\u786e\u7684\u8ba4\u8bc1\u6388\u6743\u6700\u4f73\u5b9e\u8df5\uff0c\u9ad8\u5ea6\u81ea\u4e3b\u4ee3\u7406\u7684\u613f\u666f\u5f15\u53d1\u4e86\u53ef\u6269\u5c55\u8bbf\u95ee\u63a7\u5236\u7b49\u590d\u6742\u95ee\u9898\u3002", "method": "\u6982\u8ff0\u4e86\u4fdd\u62a4\u5f53\u524d\u4ee3\u7406\u7684\u53ef\u7528\u8d44\u6e90\uff0c\u5e76\u63d0\u51fa\u4e86\u89e3\u51b3\u672a\u6765\u5e7f\u6cdb\u81ea\u4e3b\u7cfb\u7edf\u57fa\u7840\u8ba4\u8bc1\u3001\u6388\u6743\u548c\u8eab\u4efd\u95ee\u9898\u7684\u6218\u7565\u8bae\u7a0b\u3002", "result": "\u8bc6\u522b\u4e86AI\u4ee3\u7406\u8bbf\u95ee\u7ba1\u7406\u7684\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u53ef\u6269\u5c55\u8bbf\u95ee\u63a7\u5236\u3001\u4ee3\u7406\u4e2d\u5fc3\u8eab\u4efd\u3001AI\u5de5\u4f5c\u8d1f\u8f7d\u533a\u5206\u548c\u59d4\u6258\u6388\u6743\u7b49\u95ee\u9898\u3002", "conclusion": "\u9700\u8981\u4e3a\u660e\u5929\u7684\u5e7f\u6cdb\u81ea\u4e3b\u7cfb\u7edf\u89e3\u51b3\u57fa\u7840\u7684\u8ba4\u8bc1\u3001\u6388\u6743\u548c\u8eab\u4efd\u95ee\u9898\uff0c\u767d\u76ae\u4e66\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6218\u7565\u8bae\u7a0b\u548c\u8d44\u6e90\u6307\u5bfc\u3002"}}
{"id": "2510.25882", "categories": ["cs.SE", "D.2.9"], "pdf": "https://arxiv.org/pdf/2510.25882", "abs": "https://arxiv.org/abs/2510.25882", "authors": ["Wenhao Yang", "Minghui Zhou", "Daniel Izquierdo Cort\u00e1zar", "Yehui Wang"], "title": "Internal Vulnerabilities, External Threats: A Grounded Framework for Enterprise Open Source Risk Governance", "comment": null, "summary": "Enterprise engagement with open source has evolved from tactical adoption to\nstrategic deep integration, exposing them to a complex risk landscape far\nbeyond mere code. However, traditional risk management, narrowly focused on\ntechnical tools, is structurally inadequate for systemic threats like upstream\n\"silent fixes\", community conflicts, or sudden license changes, creating a\ndangerous governance blind spot. To address this governance vacuum and enable\nthe necessary shift from tactical risk management to holistic risk governance,\nwe conducted a grounded theory study with 15 practitioners to develop a\nholistic risk governance framework. Our study formalizes an analytical\nframework built on a foundational risk principle: an uncontrollable External\nThreat (e.g., a sudden license change in a key dependency) only becomes a\ncritical risk when it exploits a controllable Internal Vulnerability (e.g., an\nundefined risk appetite for single-vendor projects), which then amplifies the\nimpact.The framework operationalizes this principle through a clear logical\nchain: \"Objectives -> Threats -> Vulnerabilities -> Mitigation\" (OTVM). This\nprovides a holistic decision model that transcends mere technical checklists.\nBased on this logic, our contributions are: (1) a \"Strategic Objectives Matrix\"\nto clarify goals; (2) a systematic dual taxonomy of External Threats (Ex-Tech,\nEx-Comm, Ex-Eco) and Internal Vulnerabilities (In-Strat, In-Ops, In-Tech); and\n(3) an actionable mitigation framework mapping capability-building to these\nvulnerabilities. The framework's analytical utility was validated by three\nindustry experts through retrospective case studies on real-world incidents.\nThis work provides a novel diagnostic lens and a systematic path for\nenterprises to shift from reactive \"firefighting\" to proactively building an\norganizational \"immune system\".", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f00\u6e90\u98ce\u9669\u6cbb\u7406\u6846\u67b6\uff0c\u901a\u8fc7\"\u76ee\u6807->\u5a01\u80c1->\u6f0f\u6d1e->\u7f13\u89e3\"(OTVM)\u903b\u8f91\u94fe\uff0c\u5c06\u4e0d\u53ef\u63a7\u5916\u90e8\u5a01\u80c1\u4e0e\u53ef\u63a7\u5185\u90e8\u6f0f\u6d1e\u7ed3\u5408\u5206\u6790\uff0c\u5e2e\u52a9\u4f01\u4e1a\u4ece\u6218\u672f\u98ce\u9669\u7ba1\u7406\u8f6c\u5411\u6574\u4f53\u98ce\u9669\u6cbb\u7406\u3002", "motivation": "\u4f20\u7edf\u98ce\u9669\u7ba1\u7406\u4ec5\u5173\u6ce8\u6280\u672f\u5de5\u5177\uff0c\u65e0\u6cd5\u5e94\u5bf9\u4e0a\u6e38\"\u9759\u9ed8\u4fee\u590d\"\u3001\u793e\u533a\u51b2\u7a81\u3001\u8bb8\u53ef\u8bc1\u53d8\u66f4\u7b49\u7cfb\u7edf\u6027\u5a01\u80c1\uff0c\u5b58\u5728\u6cbb\u7406\u76f2\u533a\u3002", "method": "\u57fa\u4e8e\u624e\u6839\u7406\u8bba\u7814\u7a76\uff0c\u4e0e15\u4f4d\u4ece\u4e1a\u8005\u5408\u4f5c\u5f00\u53d1\u6574\u4f53\u98ce\u9669\u6cbb\u7406\u6846\u67b6\uff0c\u6784\u5efaOTVM\u903b\u8f91\u94fe\u5206\u6790\u6a21\u578b\u3002", "result": "\u5f00\u53d1\u4e86\u6218\u7565\u76ee\u6807\u77e9\u9635\u3001\u5916\u90e8\u5a01\u80c1(\u6280\u672f\u3001\u793e\u533a\u3001\u751f\u6001)\u548c\u5185\u90e8\u6f0f\u6d1e(\u6218\u7565\u3001\u8fd0\u8425\u3001\u6280\u672f)\u7684\u53cc\u91cd\u5206\u7c7b\u6cd5\uff0c\u4ee5\u53ca\u53ef\u64cd\u4f5c\u7684\u7f13\u89e3\u6846\u67b6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4f01\u4e1a\u63d0\u4f9b\u4e86\u4ece\u88ab\u52a8\"\u6551\u706b\"\u8f6c\u5411\u4e3b\u52a8\u6784\u5efa\u7ec4\u7ec7\"\u514d\u75ab\u7cfb\u7edf\"\u7684\u8bca\u65ad\u5de5\u5177\u548c\u7cfb\u7edf\u8def\u5f84\u3002"}}
{"id": "2510.25775", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25775", "abs": "https://arxiv.org/abs/2510.25775", "authors": ["Francesco Spinnato"], "title": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP", "comment": null, "summary": "Contemporary chess engines offer precise yet opaque evaluations, typically\nexpressed as centipawn scores. While effective for decision-making, these\noutputs obscure the underlying contributions of individual pieces or patterns.\nIn this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the\ndomain of chess analysis, aiming to attribute a chess engines evaluation to\nspecific pieces on the board. By treating pieces as features and systematically\nablating them, we compute additive, per-piece contributions that explain the\nengines output in a locally faithful and human-interpretable manner. This\nmethod draws inspiration from classical chess pedagogy, where players assess\npositions by mentally removing pieces, and grounds it in modern explainable AI\ntechniques. Our approach opens new possibilities for visualization, human\ntraining, and engine comparison. We release accompanying code and data to\nfoster future research in interpretable chess AI.", "AI": {"tldr": "\u5c06SHAP\u53ef\u89e3\u91caAI\u6280\u672f\u5e94\u7528\u4e8e\u56fd\u9645\u8c61\u68cb\u5206\u6790\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u79fb\u9664\u68cb\u5b50\u6765\u8ba1\u7b97\u6bcf\u4e2a\u68cb\u5b50\u5bf9\u5f15\u64ce\u8bc4\u4f30\u7684\u8d21\u732e\u5ea6\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u68cb\u5c40\u5206\u6790\u3002", "motivation": "\u4f20\u7edf\u56fd\u9645\u8c61\u68cb\u5f15\u64ce\u63d0\u4f9b\u7cbe\u786e\u4f46\u4e0d\u900f\u660e\u7684\u8bc4\u4f30\u5206\u6570\uff08\u767e\u5206\u5175\u503c\uff09\uff0c\u8fd9\u4e9b\u8f93\u51fa\u63a9\u76d6\u4e86\u5355\u4e2a\u68cb\u5b50\u6216\u6a21\u5f0f\u7684\u5177\u4f53\u8d21\u732e\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u5c06\u68cb\u5b50\u89c6\u4e3a\u7279\u5f81\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u79fb\u9664\u68cb\u5b50\u5e76\u8ba1\u7b97SHAP\u503c\uff0c\u4e3a\u6bcf\u4e2a\u68cb\u5b50\u5206\u914d\u5bf9\u5f15\u64ce\u8bc4\u4f30\u7684\u52a0\u6cd5\u6027\u8d21\u732e\u5ea6\uff0c\u5b9e\u73b0\u5c40\u90e8\u5fe0\u5b9e\u4e14\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u89e3\u91ca\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u80fd\u591f\u5c06\u56fd\u9645\u8c61\u68cb\u5f15\u64ce\u8bc4\u4f30\u5f52\u56e0\u4e8e\u7279\u5b9a\u68cb\u5b50\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53d7\u5230\u7ecf\u5178\u8c61\u68cb\u6559\u5b66\uff08\u901a\u8fc7\u5fc3\u7406\u79fb\u9664\u68cb\u5b50\u8bc4\u4f30\u5c40\u9762\uff09\u7684\u542f\u53d1\uff0c\u5e76\u57fa\u4e8e\u73b0\u4ee3\u53ef\u89e3\u91caAI\u6280\u672f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53ef\u89c6\u5316\u3001\u4eba\u7c7b\u8bad\u7ec3\u548c\u5f15\u64ce\u6bd4\u8f83\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027\uff0c\u5e76\u53d1\u5e03\u4e86\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u4ee5\u4fc3\u8fdb\u53ef\u89e3\u91ca\u8c61\u68cbAI\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.25856", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.25856", "abs": "https://arxiv.org/abs/2510.25856", "authors": ["Brooke Elizabeth Kidmose", "Andreas Brasen Kidmose", "Cliff C. Zou"], "title": "A Critical Roadmap to Driver Authentication via CAN Bus: Dataset Review, Introduction of the Kidmose CANid Dataset (KCID), and Proof of Concept", "comment": null, "summary": "Modern vehicles remain vulnerable to unauthorized use and theft despite\ntraditional security measures including immobilizers and keyless entry systems.\nCriminals exploit vulnerabilities in Controller Area Network (CAN) bus systems\nto bypass authentication mechanisms, while social media trends have expanded\nauto theft to include recreational joyriding by underage drivers. Driver\nauthentication via CAN bus data offers a promising additional layer of\ndefense-in-depth protection, but existing open-access driver fingerprinting\ndatasets suffer from critical limitations including reliance on decoded\ndiagnostic data rather than raw CAN traffic, artificial fixed-route\nexperimental designs, insufficient sampling rates, and lack of demographic\ninformation.\n  This paper provides a comprehensive review of existing open-access driver\nfingerprinting datasets, analyzing their strengths and limitations to guide\npractitioners in dataset selection. We introduce the Kidmose CANid Dataset\n(KCID), which addresses these fundamental shortcomings by providing raw CAN bus\ndata from 16 drivers across four vehicles, including essential demographic\ninformation and both daily driving and controlled fixed-route data. Beyond\ndataset contributions, we present a driver authentication anti-theft framework\nand implement a proof-of-concept prototype on a single-board computer. Through\nlive road trials with an unaltered passenger vehicle, we demonstrate the\npractical feasibility of CAN bus-based driver authentication anti-theft\nsystems. Finally, we explore diverse applications of KCID beyond driver\nauthentication, including driver profiling for insurance and safety\nassessments, mechanical anomaly detection, young driver monitoring, and\nimpaired driving detection. This work provides researchers with both the data\nand methodological foundation necessary to develop robust, deployable driver\nauthentication systems...", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u73b0\u6709\u9a7e\u9a76\u5458\u6307\u7eb9\u8bc6\u522b\u6570\u636e\u96c6\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86Kidmose CANid\u6570\u636e\u96c6(KCID)\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u57fa\u4e8eCAN\u603b\u7ebf\u7684\u9a7e\u9a76\u5458\u8ba4\u8bc1\u9632\u76d7\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u73b0\u4ee3\u8f66\u8f86\u867d\u7136\u914d\u5907\u4e86\u9632\u76d7\u5668\u548c\u65e0\u94a5\u5319\u8fdb\u5165\u7cfb\u7edf\uff0c\u4f46\u4ecd\u9762\u4e34CAN\u603b\u7ebf\u6f0f\u6d1e\u88ab\u5229\u7528\u7684\u98ce\u9669\u3002\u9a7e\u9a76\u5458\u8ba4\u8bc1\u4f5c\u4e3a\u6df1\u5ea6\u9632\u5fa1\u7684\u989d\u5916\u4fdd\u62a4\u5c42\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u4e25\u91cd\u5c40\u9650\u6027\u3002", "method": "\u5f15\u5165KCID\u6570\u636e\u96c6\uff0c\u5305\u542b16\u540d\u9a7e\u9a76\u5458\u57284\u8f86\u8f66\u4e0a\u7684\u539f\u59cbCAN\u603b\u7ebf\u6570\u636e\uff0c\u5305\u62ec\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u548c\u65e5\u5e38\u9a7e\u9a76\u6570\u636e\uff1b\u5f00\u53d1\u4e86\u9a7e\u9a76\u5458\u8ba4\u8bc1\u9632\u76d7\u6846\u67b6\u5e76\u5728\u5355\u677f\u8ba1\u7b97\u673a\u4e0a\u5b9e\u73b0\u539f\u578b\u7cfb\u7edf\u3002", "result": "\u901a\u8fc7\u672a\u6539\u88c5\u4e58\u7528\u8f66\u7684\u5b9e\u9645\u9053\u8def\u8bd5\u9a8c\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8eCAN\u603b\u7ebf\u7684\u9a7e\u9a76\u5458\u8ba4\u8bc1\u9632\u76d7\u7cfb\u7edf\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u7a33\u5065\u3001\u53ef\u90e8\u7f72\u7684\u9a7e\u9a76\u5458\u8ba4\u8bc1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u6570\u636e\u548c\u65b9\u6cd5\u57fa\u7840\uff0cKCID\u6570\u636e\u96c6\u8fd8\u53ef\u7528\u4e8e\u9a7e\u9a76\u5458\u753b\u50cf\u3001\u673a\u68b0\u5f02\u5e38\u68c0\u6d4b\u3001\u5e74\u8f7b\u9a7e\u9a76\u5458\u76d1\u63a7\u548c\u53d7\u635f\u9a7e\u9a76\u68c0\u6d4b\u7b49\u5e94\u7528\u3002"}}
{"id": "2510.25890", "categories": ["cs.SE", "cs.AI", "D.2.4; I.2.2"], "pdf": "https://arxiv.org/pdf/2510.25890", "abs": "https://arxiv.org/abs/2510.25890", "authors": ["Tong Ma", "Hui Lai", "Hui Wang", "Zhenhu Tian", "Jizhou Wang", "Haichao Wu", "Yongfan Gao", "Chaochao Li", "Fengjie Xu", "Ling Fang"], "title": "PRISM: Proof-Carrying Artifact Generation through LLM x MDE Synergy and Stratified Constraints", "comment": "45 pages, 9 figures", "summary": "PRISM unifies Large Language Models with Model-Driven Engineering to generate\nregulator-ready artifacts and machine-checkable evidence for safety- and\ncompliance-critical domains. PRISM integrates three pillars: a Unified\nMeta-Model (UMM) reconciles heterogeneous schemas and regulatory text into a\nsingle semantic space; an Integrated Constraint Model (ICM) compiles structural\nand semantic requirements into enforcement artifacts including generation-time\nautomata (GBNF, DFA) and post-generation validators (e.g., SHACL, SMT); and\nConstraint-Guided Verifiable Generation (CVG) applies these through two-layer\nenforcement - structural constraints drive prefix-safe decoding while\nsemantic/logical validation produces machine-checkable certificates. When\nviolations occur, PRISM performs audit-guided repair and records generation\ntraces for compliance review. We evaluate PRISM in automotive software\nengineering (AUTOSAR) and cross-border legal jurisdiction (Brussels I bis).\nPRISM produces structurally valid, auditable artifacts that integrate with\nexisting tooling and substantially reduce manual remediation effort, providing\na practical path toward automated artifact generation with built-in assurance.", "AI": {"tldr": "PRISM\u662f\u4e00\u4e2a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u76f8\u7ed3\u5408\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u751f\u6210\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u7684\u53ef\u9a8c\u8bc1\u5de5\u4ef6\uff0c\u5728\u5b89\u5168\u548c\u5408\u89c4\u5173\u952e\u9886\u57df\u63d0\u4f9b\u673a\u5668\u53ef\u68c0\u67e5\u7684\u8bc1\u636e\u3002", "motivation": "\u89e3\u51b3\u5728\u5b89\u5168\u548c\u5408\u89c4\u5173\u952e\u9886\u57df\u4e2d\uff0c\u624b\u52a8\u751f\u6210\u76d1\u7ba1\u5c31\u7eea\u5de5\u4ef6\u548c\u9a8c\u8bc1\u8bc1\u636e\u7684\u9ad8\u6210\u672c\u3001\u6613\u51fa\u9519\u95ee\u9898\uff0c\u63d0\u4f9b\u81ea\u52a8\u5316\u4e14\u53ef\u9a8c\u8bc1\u7684\u751f\u6210\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e09\u652f\u67f1\u67b6\u6784\uff1a\u7edf\u4e00\u5143\u6a21\u578b\u6574\u5408\u5f02\u6784\u6a21\u5f0f\u3001\u96c6\u6210\u7ea6\u675f\u6a21\u578b\u7f16\u8bd1\u7ed3\u6784\u8bed\u4e49\u8981\u6c42\u3001\u7ea6\u675f\u5f15\u5bfc\u53ef\u9a8c\u8bc1\u751f\u6210\u901a\u8fc7\u4e24\u5c42\u5f3a\u5236\u6267\u884c\u673a\u5236\u3002", "result": "\u5728\u6c7d\u8f66\u8f6f\u4ef6\u5de5\u7a0b\u548c\u8de8\u5883\u6cd5\u5f8b\u7ba1\u8f96\u573a\u666f\u4e2d\uff0cPRISM\u751f\u6210\u4e86\u7ed3\u6784\u6709\u6548\u3001\u53ef\u5ba1\u8ba1\u7684\u5de5\u4ef6\uff0c\u663e\u8457\u51cf\u5c11\u624b\u52a8\u4fee\u590d\u5de5\u4f5c\uff0c\u5e76\u4e0e\u73b0\u6709\u5de5\u5177\u94fe\u96c6\u6210\u3002", "conclusion": "PRISM\u4e3a\u81ea\u52a8\u5316\u5de5\u4ef6\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u8def\u5f84\uff0c\u5177\u6709\u5185\u7f6e\u4fdd\u8bc1\u673a\u5236\uff0c\u80fd\u591f\u751f\u6210\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u7684\u53ef\u9a8c\u8bc1\u8bc1\u636e\u3002"}}
{"id": "2510.25813", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25813", "abs": "https://arxiv.org/abs/2510.25813", "authors": ["Jorge Martinez-Gil", "Mario Pichler", "Nefeli Bountouni", "Sotiris Koussouris", "Marielena M\u00e1rquez Barreiro", "Sergio Gusmeroli"], "title": "An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0", "comment": null, "summary": "We present a novel framework for Industry 5.0 that simplifies the deployment\nof AI models on edge devices in various industrial settings. The design reduces\nlatency and avoids external data transfer by enabling local inference and\nreal-time processing. Our implementation is agent-based, which means that\nindividual agents, whether human, algorithmic, or collaborative, are\nresponsible for well-defined tasks, enabling flexibility and simplifying\nintegration. Moreover, our framework supports modular integration and maintains\nlow resource requirements. Preliminary evaluations concerning the food industry\nin real scenarios indicate improved deployment time and system adaptability\nperformance. The source code is publicly available at\nhttps://github.com/AI-REDGIO-5-0/ci-component.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u5de5\u4e1a5.0\u7684\u65b0\u6846\u67b6\uff0c\u7b80\u5316AI\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\uff0c\u901a\u8fc7\u672c\u5730\u63a8\u7406\u548c\u5b9e\u65f6\u5904\u7406\u964d\u4f4e\u5ef6\u8fdf\uff0c\u907f\u514d\u5916\u90e8\u6570\u636e\u4f20\u8f93\u3002", "motivation": "\u5de5\u4e1a\u73af\u5883\u4e2d\u9700\u8981\u9ad8\u6548\u90e8\u7f72AI\u6a21\u578b\uff0c\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u5ef6\u8fdf\u9ad8\u3001\u6570\u636e\u4f20\u8f93\u590d\u6742\u7b49\u95ee\u9898\uff0c\u9700\u8981\u7b80\u5316\u90e8\u7f72\u6d41\u7a0b\u5e76\u63d0\u5347\u7cfb\u7edf\u9002\u5e94\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4ee3\u7406\u7684\u67b6\u6784\uff0c\u5404\u7c7b\u4ee3\u7406\uff08\u4eba\u7c7b\u3001\u7b97\u6cd5\u6216\u534f\u4f5c\uff09\u8d1f\u8d23\u7279\u5b9a\u4efb\u52a1\uff0c\u652f\u6301\u6a21\u5757\u5316\u96c6\u6210\uff0c\u4fdd\u6301\u4f4e\u8d44\u6e90\u9700\u6c42\u3002", "result": "\u5728\u98df\u54c1\u5de5\u4e1a\u771f\u5b9e\u573a\u666f\u7684\u521d\u6b65\u8bc4\u4f30\u663e\u793a\uff0c\u90e8\u7f72\u65f6\u95f4\u548c\u7cfb\u7edf\u9002\u5e94\u6027\u6027\u80fd\u5f97\u5230\u6539\u5584\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5de5\u4e1a5.0\u63d0\u4f9b\u4e86\u6709\u6548\u7684AI\u6a21\u578b\u90e8\u7f72\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u4f4e\u5ef6\u8fdf\u3001\u6a21\u5757\u5316\u548c\u9002\u5e94\u6027\u5f3a\u7684\u7279\u70b9\u3002"}}
{"id": "2510.25863", "categories": ["cs.CR", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.25863", "abs": "https://arxiv.org/abs/2510.25863", "authors": ["Ken Huang", "Jerry Huang", "Yasir Mehmood", "Hammad Atta", "Muhammad Zeeshan Baig", "Muhammad Aziz Ul Haq"], "title": "AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI", "comment": null, "summary": "This paper introduces the Agentic AI Governance Assurance & Trust Engine\n(AAGATE), a Kubernetes-native control plane designed to address the unique\nsecurity and governance challenges posed by autonomous, language-model-driven\nagents in production. Recognizing the limitations of traditional Application\nSecurity (AppSec) tooling for improvisational, machine-speed systems, AAGATE\noperationalizes the NIST AI Risk Management Framework (AI RMF). It integrates\nspecialized security frameworks for each RMF function: the Agentic AI Threat\nModeling MAESTRO framework for Map, a hybrid of OWASP's AIVSS and SEI's SSVC\nfor Measure, and the Cloud Security Alliance's Agentic AI Red Teaming Guide for\nManage. By incorporating a zero-trust service mesh, an explainable policy\nengine, behavioral analytics, and decentralized accountability hooks, AAGATE\nprovides a continuous, verifiable governance solution for agentic AI, enabling\nsafe, accountable, and scalable deployment. The framework is further extended\nwith DIRF for digital identity rights, LPCI defenses for logic-layer injection,\nand QSAF monitors for cognitive degradation, ensuring governance spans\nsystemic, adversarial, and ethical risks.", "AI": {"tldr": "AAGATE\u662f\u4e00\u4e2aKubernetes\u539f\u751f\u63a7\u5236\u5e73\u9762\uff0c\u4e13\u95e8\u89e3\u51b3\u81ea\u4e3b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u4ee3\u7406\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u5b89\u5168\u548c\u6cbb\u7406\u6311\u6218\uff0c\u901a\u8fc7\u96c6\u6210NIST AI\u98ce\u9669\u7ba1\u7406\u6846\u67b6\u548c\u591a\u79cd\u5b89\u5168\u6846\u67b6\u63d0\u4f9b\u6301\u7eed\u53ef\u9a8c\u8bc1\u7684\u6cbb\u7406\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u5e94\u7528\u5b89\u5168\u5de5\u5177\u65e0\u6cd5\u5e94\u5bf9\u5373\u5174\u3001\u673a\u5668\u901f\u5ea6\u7684\u81ea\u4e3bAI\u7cfb\u7edf\u5e26\u6765\u7684\u72ec\u7279\u5b89\u5168\u548c\u6cbb\u7406\u6311\u6218\uff0c\u9700\u8981\u4e13\u95e8\u7684\u63a7\u5236\u5e73\u9762\u6765\u786e\u4fdd\u5b89\u5168\u3001\u8d1f\u8d23\u4efb\u548c\u53ef\u6269\u5c55\u7684\u90e8\u7f72\u3002", "method": "\u91c7\u7528Kubernetes\u539f\u751f\u67b6\u6784\uff0c\u96c6\u6210NIST AI RMF\u6846\u67b6\uff0c\u7ed3\u5408\u96f6\u4fe1\u4efb\u670d\u52a1\u7f51\u683c\u3001\u53ef\u89e3\u91ca\u7b56\u7565\u5f15\u64ce\u3001\u884c\u4e3a\u5206\u6790\u548c\u53bb\u4e2d\u5fc3\u5316\u95ee\u8d23\u94a9\u5b50\uff0c\u5e76\u6269\u5c55DIRF\u3001LPCI\u548cQSAF\u7b49\u4e13\u95e8\u9632\u5fa1\u673a\u5236\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8fde\u7eed\u3001\u53ef\u9a8c\u8bc1\u7684\u6cbb\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u8986\u76d6\u7cfb\u7edf\u6027\u3001\u5bf9\u6297\u6027\u548c\u4f26\u7406\u98ce\u9669\uff0c\u786e\u4fdd\u81ea\u4e3bAI\u4ee3\u7406\u7684\u5b89\u5168\u90e8\u7f72\u3002", "conclusion": "AAGATE\u6846\u67b6\u901a\u8fc7\u7efc\u5408\u7684\u5b89\u5168\u6cbb\u7406\u65b9\u6cd5\uff0c\u4e3a\u81ea\u4e3bAI\u7cfb\u7edf\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u5b89\u5168\u3001\u8d1f\u8d23\u4efb\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u4fdd\u969c\u3002"}}
{"id": "2510.25935", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25935", "abs": "https://arxiv.org/abs/2510.25935", "authors": ["Ant\u00eda Dorado", "Iv\u00e1n Folgueira", "Sof\u00eda Mart\u00edn", "Gonzalo Mart\u00edn", "\u00c1lvaro Porto", "Alejandro Ramos", "John Wallace"], "title": "A Process Mining-Based System For The Analysis and Prediction of Software Development Workflows", "comment": "16 pages, 7 figures, 4 tables", "summary": "CodeSight is an end-to-end system designed to anticipate deadline compliance\nin software development workflows. It captures development and deployment data\ndirectly from GitHub, transforming it into process mining logs for detailed\nanalysis. From these logs, the system generates metrics and dashboards that\nprovide actionable insights into PR activity patterns and workflow efficiency.\nBuilding on this structured representation, CodeSight employs an LSTM model\nthat predicts remaining PR resolution times based on sequential activity traces\nand static features, enabling early identification of potential deadline\nbreaches. In tests, the system demonstrates high precision and F1 scores in\npredicting deadline compliance, illustrating the value of integrating process\nmining with machine learning for proactive software project management.", "AI": {"tldr": "CodeSight\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u8fc7\u7a0b\u6316\u6398\u548c\u673a\u5668\u5b66\u4e60\u6765\u9884\u6d4b\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u622a\u6b62\u671f\u9650\u5408\u89c4\u6027\uff0c\u80fd\u591f\u57fa\u4e8eGitHub\u6570\u636e\u9884\u6d4bPR\u89e3\u51b3\u65f6\u95f4\u5e76\u8bc6\u522b\u6f5c\u5728\u5ef6\u671f\u98ce\u9669\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u622a\u6b62\u671f\u9650\u5408\u89c4\u6027\u7684\u9884\u6d4b\u95ee\u9898\uff0c\u5e2e\u52a9\u9879\u76ee\u7ba1\u7406\u8005\u53ca\u65e9\u8bc6\u522b\u6f5c\u5728\u7684\u5ef6\u671f\u98ce\u9669\uff0c\u5b9e\u73b0\u4e3b\u52a8\u7684\u9879\u76ee\u7ba1\u7406\u3002", "method": "\u7cfb\u7edf\u4eceGitHub\u6355\u83b7\u5f00\u53d1\u548c\u90e8\u7f72\u6570\u636e\uff0c\u8f6c\u6362\u4e3a\u8fc7\u7a0b\u6316\u6398\u65e5\u5fd7\u8fdb\u884c\u5206\u6790\uff0c\u7136\u540e\u4f7f\u7528LSTM\u6a21\u578b\u57fa\u4e8e\u5e8f\u5217\u6d3b\u52a8\u8f68\u8ff9\u548c\u9759\u6001\u7279\u5f81\u6765\u9884\u6d4bPR\u5269\u4f59\u89e3\u51b3\u65f6\u95f4\u3002", "result": "\u5728\u6d4b\u8bd5\u4e2d\uff0c\u7cfb\u7edf\u5728\u9884\u6d4b\u622a\u6b62\u671f\u9650\u5408\u89c4\u6027\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\u548c\u9ad8F1\u5206\u6570\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5c06\u8fc7\u7a0b\u6316\u6398\u4e0e\u673a\u5668\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u80fd\u591f\u4e3a\u8f6f\u4ef6\u9879\u76ee\u7ba1\u7406\u63d0\u4f9b\u4e3b\u52a8\u7684\u3001\u53ef\u64cd\u4f5c\u7684\u6d1e\u5bdf\uff0c\u6709\u6548\u63d0\u5347\u5de5\u4f5c\u6d41\u6548\u7387\u3002"}}
{"id": "2510.25820", "categories": ["cs.AI", "cs.HC", "I.2.7; H.5.2"], "pdf": "https://arxiv.org/pdf/2510.25820", "abs": "https://arxiv.org/abs/2510.25820", "authors": ["Vanessa Figueiredo", "David Elumeze"], "title": "Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for Generative NPC Dialogue", "comment": null, "summary": "Large Language Models (LLMs) promise to transform interactive games by\nenabling non-player characters (NPCs) to sustain unscripted dialogue. Yet it\nremains unclear whether constrained prompts actually improve player experience.\nWe investigate this question through The Interview, a voice-based detective\ngame powered by GPT-4o. A within-subjects usability study ($N=10$) compared\nhigh-constraint (HCP) and low-constraint (LCP) prompts, revealing no reliable\nexperiential differences beyond sensitivity to technical breakdowns. Guided by\nthese findings, we redesigned the HCP into a hybrid JSON+RAG scaffold and\nconducted a synthetic evaluation with an LLM judge, positioned as an\nearly-stage complement to usability testing. Results uncovered a novel pattern:\nscaffolding effects were role-dependent: the Interviewer (quest-giver NPC)\ngained stability, while suspect NPCs lost improvisational believability. These\nfindings overturn the assumption that tighter constraints inherently enhance\nplay. Extending fuzzy-symbolic scaffolding, we introduce \\textit{Symbolically\nScaffolded Play}, a framework in which symbolic structures are expressed as\nfuzzy, numerical boundaries that stabilize coherence where needed while\npreserving improvisation where surprise sustains engagement.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u57fa\u4e8eGPT-4o\u7684\u4fa6\u63a2\u6e38\u620f\u4e2d\uff0c\u4e0d\u540c\u7ea6\u675f\u7a0b\u5ea6\u7684\u63d0\u793a\u5bf9\u73a9\u5bb6\u4f53\u9a8c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7ea6\u675f\u7a0b\u5ea6\u5bf9\u4f53\u9a8c\u65e0\u663e\u8457\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4e86\u7b26\u53f7\u5316\u652f\u67b6\u6e38\u620f\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u9a8c\u8bc1\u7ea6\u675f\u63d0\u793a\u662f\u5426\u80fd\u771f\u6b63\u6539\u5584\u73a9\u5bb6\u4f53\u9a8c\uff0c\u56e0\u4e3a\u867d\u7136LLMs\u80fd\u8ba9NPC\u8fdb\u884c\u975e\u811a\u672c\u5bf9\u8bdd\uff0c\u4f46\u7ea6\u675f\u63d0\u793a\u7684\u5b9e\u9645\u6548\u679c\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u91c7\u7528\u88ab\u8bd5\u5185\u53ef\u7528\u6027\u7814\u7a76(N=10)\u6bd4\u8f83\u9ad8\u7ea6\u675f\u63d0\u793a(HCP)\u548c\u4f4e\u7ea6\u675f\u63d0\u793a(LCP)\uff0c\u7136\u540e\u91cd\u65b0\u8bbe\u8ba1HCP\u4e3a\u6df7\u5408JSON+RAG\u652f\u67b6\uff0c\u5e76\u8fdb\u884cLLM\u6cd5\u5b98\u7684\u5408\u6210\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7ea6\u675f\u7a0b\u5ea6\u5bf9\u73a9\u5bb6\u4f53\u9a8c\u65e0\u53ef\u9760\u5dee\u5f02\uff0c\u652f\u67b6\u6548\u679c\u5177\u6709\u89d2\u8272\u4f9d\u8d56\u6027\uff1a\u9762\u8bd5\u5b98NPC\u83b7\u5f97\u7a33\u5b9a\u6027\uff0c\u800c\u5acc\u7591\u72afNPC\u5931\u53bb\u5373\u5174\u53ef\u4fe1\u5ea6\u3002", "conclusion": "\u7814\u7a76\u63a8\u7ffb\u4e86\u66f4\u4e25\u683c\u7ea6\u675f\u5fc5\u7136\u589e\u5f3a\u6e38\u620f\u6027\u7684\u5047\u8bbe\uff0c\u63d0\u51fa\u4e86\u7b26\u53f7\u5316\u652f\u67b6\u6e38\u620f\u6846\u67b6\uff0c\u4f7f\u7528\u6a21\u7cca\u6570\u503c\u8fb9\u754c\u5728\u9700\u8981\u65f6\u4fdd\u6301\u8fde\u8d2f\u6027\uff0c\u540c\u65f6\u5728\u9700\u8981\u60ca\u559c\u65f6\u4fdd\u7559\u5373\u5174\u6027\u3002"}}
{"id": "2510.25878", "categories": ["cs.CR", "cs.DC", "cs.GT"], "pdf": "https://arxiv.org/pdf/2510.25878", "abs": "https://arxiv.org/abs/2510.25878", "authors": ["Pavel Hub\u00e1\u010dek", "Jan V\u00e1clavek", "Michelle Yeo"], "title": "Foundations of Fiat-Denominated Loans Collateralized by Cryptocurrencies", "comment": null, "summary": "The rising importance of cryptocurrencies as financial assets pushed their\napplicability from an object of speculation closer to standard financial\ninstruments such as loans. In this work, we initiate the study of secure\nprotocols that enable fiat-denominated loans collateralized by cryptocurrencies\nsuch as Bitcoin. We provide limited-custodial protocols for such loans relying\nonly on trusted arbitration and provide their game-theoretical analysis. We\nalso highlight various interesting directions for future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4ee5\u52a0\u5bc6\u8d27\u5e01\uff08\u5982\u6bd4\u7279\u5e01\uff09\u4e3a\u62b5\u62bc\u7684\u6cd5\u5e01\u8d37\u6b3e\u5b89\u5168\u534f\u8bae\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u53ef\u4fe1\u4ef2\u88c1\u7684\u6709\u9650\u6258\u7ba1\u534f\u8bae\uff0c\u5e76\u8fdb\u884c\u4e86\u535a\u5f08\u8bba\u5206\u6790\u3002", "motivation": "\u968f\u7740\u52a0\u5bc6\u8d27\u5e01\u4f5c\u4e3a\u91d1\u878d\u8d44\u4ea7\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u9700\u8981\u5c06\u5176\u4ece\u6295\u673a\u5bf9\u8c61\u8f6c\u53d8\u4e3a\u66f4\u63a5\u8fd1\u6807\u51c6\u91d1\u878d\u5de5\u5177\uff08\u5982\u8d37\u6b3e\uff09\u7684\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u53ef\u4fe1\u4ef2\u88c1\u7684\u6709\u9650\u6258\u7ba1\u534f\u8bae\uff0c\u7528\u4e8e\u4ee5\u52a0\u5bc6\u8d27\u5e01\u4e3a\u62b5\u62bc\u7684\u6cd5\u5e01\u8d37\u6b3e\uff0c\u5e76\u8fdb\u884c\u4e86\u535a\u5f08\u8bba\u5206\u6790\u3002", "result": "\u63d0\u51fa\u4e86\u53ef\u884c\u7684\u5b89\u5168\u534f\u8bae\u6846\u67b6\uff0c\u80fd\u591f\u5b9e\u73b0\u52a0\u5bc6\u8d27\u5e01\u62b5\u62bc\u7684\u6cd5\u5e01\u8d37\u6b3e\uff0c\u540c\u65f6\u8bc6\u522b\u4e86\u672a\u6765\u7814\u7a76\u7684\u591a\u4e2a\u6709\u8da3\u65b9\u5411\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u52a0\u5bc6\u8d27\u5e01\u62b5\u62bc\u8d37\u6b3e\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u534f\u8bae\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u6b64\u7c7b\u91d1\u878d\u4ea7\u54c1\u7684\u53ef\u884c\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2510.26130", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26130", "abs": "https://arxiv.org/abs/2510.26130", "authors": ["Musfiqur Rahman", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation", "comment": "Pre-print prepared for journal submission", "summary": "Large language models (LLMs) have advanced code generation at the function\nlevel, yet their ability to produce correct class-level implementations in\nauthentic software projects remains poorly understood. This work introduces a\nnovel benchmark derived from open-source repositories, comprising real-world\nclasses divided into seen and unseen partitions to evaluate generalization\nunder practical conditions. The evaluation examines multiple LLMs under varied\ninput specifications, retrieval-augmented configurations, and documentation\ncompleteness levels.\n  Results reveal a stark performance disparity: LLMs achieve 84% to 89%\ncorrectness on established synthetic benchmarks but only 25% to 34% on\nreal-world class tasks, with negligible differences between familiar and novel\ncodebases. Comprehensive docstrings yield modest gains of 1% to 3% in\nfunctional accuracy, though statistical significance is rare.\nRetrieval-augmented generation proves most effective with partial\ndocumentation, improving correctness by 4% to 7% by supplying concrete\nimplementation patterns absent from specifications. Error profiling identifies\nAttributeError, TypeError, and AssertionError as dominant failure modes (84% of\ncases), with synthetic tests overemphasizing assertion issues and real-world\nscenarios highlighting type and attribute mismatches. Retrieval augmentation\nreduces logical flaws but can introduce dependency conflicts.\n  The benchmark and analysis expose critical limitations in current LLM\ncapabilities for class-level engineering, offering actionable insights for\nenhancing context modelling, documentation strategies, and retrieval\nintegration in production code assistance tools.", "AI": {"tldr": "LLMs\u5728\u51fd\u6570\u7ea7\u4ee3\u7801\u751f\u6210\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u771f\u5b9e\u8f6f\u4ef6\u9879\u76ee\u4e2d\u7684\u7c7b\u7ea7\u5b9e\u73b0\u80fd\u529b\u4e25\u91cd\u4e0d\u8db3\uff0c\u6b63\u786e\u7387\u4ece\u5408\u6210\u57fa\u51c6\u768484-89%\u964d\u81f3\u771f\u5b9e\u4efb\u52a1\u768425-34%\u3002\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5728\u90e8\u5206\u6587\u6863\u60c5\u51b5\u4e0b\u6700\u6709\u6548\uff0c\u80fd\u63d0\u53474-7%\u6b63\u786e\u7387\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u771f\u5b9e\u8f6f\u4ef6\u9879\u76ee\u4e2d\u751f\u6210\u7c7b\u7ea7\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u51fd\u6570\u7ea7\u4ee3\u7801\uff0c\u800c\u7c7b\u7ea7\u5b9e\u73b0\u5728\u5b9e\u9645\u5de5\u7a0b\u4e2d\u66f4\u4e3a\u590d\u6742\u548c\u91cd\u8981\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u5f00\u6e90\u4ed3\u5e93\u7684\u771f\u5b9e\u4e16\u754c\u7c7b\u57fa\u51c6\uff0c\u5206\u4e3a\u5df2\u89c1\u548c\u672a\u89c1\u5206\u533a\uff0c\u8bc4\u4f30\u591a\u79cdLLM\u5728\u4e0d\u540c\u8f93\u5165\u89c4\u8303\u3001\u68c0\u7d22\u589e\u5f3a\u914d\u7f6e\u548c\u6587\u6863\u5b8c\u6574\u6027\u4e0b\u7684\u8868\u73b0\u3002", "result": "LLMs\u5728\u771f\u5b9e\u7c7b\u4efb\u52a1\u4e2d\u6b63\u786e\u7387\u4ec5\u4e3a25-34%\uff0c\u8fdc\u4f4e\u4e8e\u5408\u6210\u57fa\u51c6\u768484-89%\u3002\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5728\u90e8\u5206\u6587\u6863\u65f6\u80fd\u63d0\u53474-7%\u6b63\u786e\u7387\uff0c\u4f46\u53ef\u80fd\u5f15\u5165\u4f9d\u8d56\u51b2\u7a81\u3002\u4e3b\u8981\u9519\u8bef\u7c7b\u578b\u4e3aAttributeError\u3001TypeError\u548cAssertionError\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u7c7b\u7ea7\u5de5\u7a0b\u80fd\u529b\u5b58\u5728\u4e25\u91cd\u5c40\u9650\uff0c\u9700\u8981\u6539\u8fdb\u4e0a\u4e0b\u6587\u5efa\u6a21\u3001\u6587\u6863\u7b56\u7565\u548c\u68c0\u7d22\u96c6\u6210\uff0c\u4e3a\u751f\u4ea7\u4ee3\u7801\u8f85\u52a9\u5de5\u5177\u63d0\u4f9b\u53ef\u64cd\u4f5c\u89c1\u89e3\u3002"}}
{"id": "2510.25860", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.25860", "abs": "https://arxiv.org/abs/2510.25860", "authors": ["Xingjian Zhang", "Tianhong Gao", "Suliang Jin", "Tianhao Wang", "Teng Ye", "Eytan Adar", "Qiaozhu Mei"], "title": "Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters", "comment": null, "summary": "Large language models (LLMs) are increasingly used as raters for evaluation\ntasks. However, their reliability is often limited for subjective tasks, when\nhuman judgments involve subtle reasoning beyond annotation labels. Thinking\ntraces, the reasoning behind a judgment, are highly informative but challenging\nto collect and curate. We present a human-LLM collaborative framework to infer\nthinking traces from label-only annotations. The proposed framework uses a\nsimple and effective rejection sampling method to reconstruct these traces at\nscale. These inferred thinking traces are applied to two complementary tasks:\n(1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation\nguidelines for proprietary LLM raters. Across multiple datasets, our methods\nlead to significantly improved LLM-human agreement. Additionally, the refined\nannotation guidelines increase agreement among different LLM models. These\nresults suggest that LLMs can serve as practical proxies for otherwise\nunrevealed human thinking traces, enabling label-only corpora to be extended\ninto thinking-trace-augmented resources that enhance the reliability of LLM\nraters.", "AI": {"tldr": "\u63d0\u51fa\u4eba\u673a\u534f\u4f5c\u6846\u67b6\uff0c\u4ece\u4ec5\u6807\u7b7e\u6807\u6ce8\u4e2d\u63a8\u65ad\u601d\u7ef4\u8f68\u8ff9\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u65b9\u6cd5\u91cd\u6784\u63a8\u7406\u8fc7\u7a0b\uff0c\u7528\u4e8e\u5fae\u8c03\u5f00\u6e90LLM\u8bc4\u4f30\u5668\u548c\u6539\u8fdb\u4e13\u6709LLM\u8bc4\u4f30\u5668\u7684\u6807\u6ce8\u6307\u5357\uff0c\u663e\u8457\u63d0\u5347LLM\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\u3002", "motivation": "LLM\u4f5c\u4e3a\u8bc4\u4f30\u5668\u7684\u53ef\u9760\u6027\u5728\u4e3b\u89c2\u4efb\u52a1\u4e2d\u53d7\u9650\uff0c\u56e0\u4e3a\u4eba\u7c7b\u5224\u65ad\u6d89\u53ca\u8d85\u51fa\u6807\u6ce8\u6807\u7b7e\u7684\u5fae\u5999\u63a8\u7406\u3002\u601d\u7ef4\u8f68\u8ff9\uff08\u5224\u65ad\u80cc\u540e\u7684\u63a8\u7406\uff09\u4fe1\u606f\u4e30\u5bcc\u4f46\u96be\u4ee5\u6536\u96c6\u548c\u6574\u7406\u3002", "method": "\u4f7f\u7528\u4eba\u673a\u534f\u4f5c\u6846\u67b6\u548c\u7b80\u5355\u6709\u6548\u7684\u62d2\u7edd\u91c7\u6837\u65b9\u6cd5\uff0c\u4ece\u4ec5\u6807\u7b7e\u6807\u6ce8\u4e2d\u5927\u89c4\u6a21\u91cd\u6784\u601d\u7ef4\u8f68\u8ff9\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u5fae\u8c03\u5f00\u6e90LLM\u8bc4\u4f30\u5668\u548c\u5408\u6210\u66f4\u6e05\u6670\u7684\u4e13\u6709LLM\u8bc4\u4f30\u5668\u6807\u6ce8\u6307\u5357\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86LLM\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\uff0c\u6539\u8fdb\u540e\u7684\u6807\u6ce8\u6307\u5357\u8fd8\u589e\u52a0\u4e86\u4e0d\u540cLLM\u6a21\u578b\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "LLM\u53ef\u4ee5\u4f5c\u4e3a\u4eba\u7c7b\u601d\u7ef4\u8f68\u8ff9\u7684\u5b9e\u7528\u4ee3\u7406\uff0c\u4f7f\u4ec5\u6807\u7b7e\u8bed\u6599\u5e93\u80fd\u591f\u6269\u5c55\u4e3a\u601d\u7ef4\u8f68\u8ff9\u589e\u5f3a\u8d44\u6e90\uff0c\u4ece\u800c\u63d0\u9ad8LLM\u8bc4\u4f30\u5668\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.25932", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25932", "abs": "https://arxiv.org/abs/2510.25932", "authors": ["Soufiane Essahli", "Oussama Sarsar", "Imane Fouad", "Anas Motii", "Ahmed Bentajer"], "title": "FakeZero: Real-Time, Privacy-Preserving Misinformation Detection for Facebook and X", "comment": "Accepted for publication in the Proceedings of the 24th IEEE\n  International Conference on Trust, Security and Privacy in Computing and\n  Communications (TrustCom 2025) Privacy track, 11 pages, 8 figures", "summary": "Social platforms distribute information at unprecedented speed, which in turn\naccelerates the spread of misinformation and threatens public discourse. We\npresent FakeZero, a fully client-side, cross-platform browser extension that\nflags unreliable posts on Facebook and X (formerly Twitter) while the user\nscrolls. All computation, DOM scraping, tokenisation, Transformer inference,\nand UI rendering run locally through the Chromium messaging API, so no personal\ndata leaves the device.FakeZero employs a three-stage training curriculum:\nbaseline fine-tuning and domain-adaptive training enhanced with focal loss,\nadversarial augmentation, and post-training quantisation. Evaluated on a\ndataset of 239,000 posts, the DistilBERT-Quant model (67.6 MB) reaches 97.1%\nmacro-F1, 97.4% accuracy, and an AUROC of 0.996, with a median latency of\napproximately 103 ms on a commodity laptop. A memory-efficient TinyBERT-Quant\nvariant retains 95.7% macro-F1 and 96.1% accuracy while shrinking the model to\n14.7 MB and lowering latency to approximately 40 ms, showing that high-quality\nfake-news detection is feasible under tight resource budgets with only modest\nperformance loss.By providing inline credibility cues, the extension can serve\nas a valuable tool for policymakers seeking to curb the spread of\nmisinformation across social networks. With user consent, FakeZero also opens\nthe door for researchers to collect large-scale datasets of fake news in the\nwild, enabling deeper analysis and the development of more robust detection\ntechniques.", "AI": {"tldr": "FakeZero\u662f\u4e00\u4e2a\u5b8c\u5168\u5ba2\u6237\u7aef\u3001\u8de8\u5e73\u53f0\u7684\u6d4f\u89c8\u5668\u6269\u5c55\uff0c\u80fd\u591f\u5728Facebook\u548cX\u5e73\u53f0\u4e0a\u5b9e\u65f6\u6807\u8bb0\u4e0d\u53ef\u9760\u7684\u5e16\u5b50\uff0c\u6240\u6709\u8ba1\u7b97\u90fd\u5728\u672c\u5730\u8fd0\u884c\uff0c\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4ee5\u7a7a\u524d\u901f\u5ea6\u4f20\u64ad\u4fe1\u606f\uff0c\u52a0\u901f\u4e86\u9519\u8bef\u4fe1\u606f\u7684\u4f20\u64ad\u5e76\u5a01\u80c1\u516c\u5171\u8ba8\u8bba\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u7528\u6237\u6d4f\u89c8\u65f6\u5b9e\u65f6\u68c0\u6d4b\u865a\u5047\u4fe1\u606f\u7684\u5de5\u5177\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u8bfe\u7a0b\uff1a\u57fa\u7ebf\u5fae\u8c03\u3001\u4f7f\u7528\u7126\u70b9\u635f\u5931\u7684\u9886\u57df\u81ea\u9002\u5e94\u8bad\u7ec3\u3001\u5bf9\u6297\u589e\u5f3a\u548c\u540e\u8bad\u7ec3\u91cf\u5316\u3002\u4f7f\u7528DistilBERT-Quant\u548cTinyBERT-Quant\u6a21\u578b\uff0c\u6240\u6709\u8ba1\u7b97\u901a\u8fc7Chromium\u6d88\u606fAPI\u5728\u672c\u5730\u8fd0\u884c\u3002", "result": "\u5728239,000\u4e2a\u5e16\u5b50\u7684\u6570\u636e\u96c6\u4e0a\uff0cDistilBERT-Quant\u6a21\u578b\u8fbe\u523097.1%\u5b8fF1\u5206\u6570\u300197.4%\u51c6\u786e\u7387\u548c0.996\u7684AUROC\uff0c\u4e2d\u4f4d\u5ef6\u8fdf\u7ea6103\u6beb\u79d2\u3002TinyBERT-Quant\u53d8\u4f53\u4fdd\u630195.7%\u5b8fF1\u5206\u6570\u548c96.1%\u51c6\u786e\u7387\uff0c\u6a21\u578b\u5927\u5c0f\u7f29\u5c0f\u81f314.7MB\uff0c\u5ef6\u8fdf\u964d\u81f3\u7ea640\u6beb\u79d2\u3002", "conclusion": "\u5728\u4e25\u683c\u8d44\u6e90\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u865a\u5047\u65b0\u95fb\u68c0\u6d4b\u662f\u53ef\u884c\u7684\uff0c\u8be5\u6269\u5c55\u53ef\u4ee5\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u5de5\u5177\u6765\u904f\u5236\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\uff0c\u5e76\u4e3a\u7814\u7a76\u4eba\u5458\u6536\u96c6\u5927\u89c4\u6a21\u771f\u5b9e\u4e16\u754c\u865a\u5047\u65b0\u95fb\u6570\u636e\u96c6\u6253\u5f00\u5927\u95e8\u3002"}}
{"id": "2510.26171", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26171", "abs": "https://arxiv.org/abs/2510.26171", "authors": ["Hasnain Iqbal", "Zerina Begum", "Kazi Sakib"], "title": "Reduction of Test Re-runs by Prioritizing Potential Order Dependent Flaky Tests", "comment": null, "summary": "Flaky tests can make automated software testing unreliable due to their\nunpredictable behavior. These tests can pass or fail on the same code base on\nmultiple runs. However, flaky tests often do not refer to any fault, even\nthough they can cause the continuous integration (CI) pipeline to fail. A\ncommon type of flaky test is the order-dependent (OD) test. The outcome of an\nOD test depends on the order in which it is run with respect to other test\ncases. Several studies have explored the detection and repair of OD tests.\nHowever, their methods require re-runs of tests multiple times, that are not\nrelated to the order dependence. Hence, prioritizing potential OD tests is\nnecessary to reduce the re-runs. In this paper, we propose a method to\nprioritize potential order-dependent tests. By analyzing shared static fields\nin test classes, we identify tests that are more likely to be order-dependent.\nIn our experiment on 27 project modules, our method successfully prioritized\nall OD tests in 23 cases, reducing test executions by an average of 65.92% and\nunnecessary re-runs by 72.19%. These results demonstrate that our approach\nsignificantly improves the efficiency of OD test detection by lowering\nexecution costs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5206\u6790\u6d4b\u8bd5\u7c7b\u4e2d\u7684\u5171\u4eab\u9759\u6001\u5b57\u6bb5\u6765\u4f18\u5148\u5904\u7406\u6f5c\u5728\u987a\u5e8f\u4f9d\u8d56\u6d4b\u8bd5\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86OD\u6d4b\u8bd5\u68c0\u6d4b\u6548\u7387", "motivation": "\u987a\u5e8f\u4f9d\u8d56\u6d4b\u8bd5\u4f1a\u5bfc\u81f4\u6301\u7eed\u96c6\u6210\u7ba1\u9053\u5931\u8d25\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u9700\u8981\u591a\u6b21\u91cd\u590d\u8fd0\u884c\u6d4b\u8bd5\uff0c\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u9700\u8981\u4f18\u5148\u5904\u7406\u6f5c\u5728OD\u6d4b\u8bd5\u4ee5\u51cf\u5c11\u91cd\u590d\u8fd0\u884c", "method": "\u901a\u8fc7\u5206\u6790\u6d4b\u8bd5\u7c7b\u4e2d\u7684\u5171\u4eab\u9759\u6001\u5b57\u6bb5\u6765\u8bc6\u522b\u66f4\u53ef\u80fd\u5177\u6709\u987a\u5e8f\u4f9d\u8d56\u6027\u7684\u6d4b\u8bd5", "result": "\u572827\u4e2a\u9879\u76ee\u6a21\u5757\u5b9e\u9a8c\u4e2d\uff0c\u6210\u529f\u572823\u4e2a\u6848\u4f8b\u4e2d\u4f18\u5148\u5904\u7406\u4e86\u6240\u6709OD\u6d4b\u8bd5\uff0c\u5e73\u5747\u51cf\u5c11\u6d4b\u8bd5\u6267\u884c65.92%\uff0c\u51cf\u5c11\u4e0d\u5fc5\u8981\u91cd\u590d\u8fd0\u884c72.19%", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u964d\u4f4e\u6267\u884c\u6210\u672c\uff0c\u663e\u8457\u63d0\u9ad8\u4e86OD\u6d4b\u8bd5\u68c0\u6d4b\u6548\u7387"}}
{"id": "2510.25883", "categories": ["cs.AI", "cs.IT", "math.IT", "I.2.0; I.2.6; G.3"], "pdf": "https://arxiv.org/pdf/2510.25883", "abs": "https://arxiv.org/abs/2510.25883", "authors": ["Christian Dittrich", "Jennifer Flygare Kinne"], "title": "The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence", "comment": "41 pages, 2 tables, 3 appendices. Submitted to arXiv for open access", "summary": "Existing frameworks converge on the centrality of compression to intelligence\nbut leave underspecified why this process enforces the discovery of causal\nstructure rather than superficial statistical patterns. We introduce a\ntwo-level framework to address this gap. The Information-Theoretic Imperative\n(ITI) establishes that any system persisting in uncertain environments must\nminimize epistemic entropy through predictive compression: this is the\nevolutionary \"why\" linking survival pressure to information-processing demands.\nThe Compression Efficiency Principle (CEP) specifies how efficient compression\nmechanically selects for generative, causal models through\nexception-accumulation dynamics, making reality alignment a consequence rather\nthan a contingent achievement. Together, ITI and CEP define a causal chain:\nfrom survival pressure to prediction necessity, compression requirement,\nefficiency optimization, generative structure discovery, and ultimately reality\nalignment. Each link follows from physical, information-theoretic, or\nevolutionary constraints, implying that intelligence is the mechanically\nnecessary outcome of persistence in structured environments. This framework\nyields empirically testable predictions: compression efficiency, measured as\napproach to the rate-distortion frontier, correlates with out-of-distribution\ngeneralization; exception-accumulation rates differentiate causal from\ncorrelational models; hierarchical systems exhibit increasing efficiency across\nabstraction layers; and biological systems demonstrate metabolic costs that\ntrack representational complexity. ITI and CEP thereby provide a unified\naccount of convergence across biological, artificial, and multi-scale systems,\naddressing the epistemic and functional dimensions of intelligence without\ninvoking assumptions about consciousness or subjective experience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u5c42\u6b21\u6846\u67b6\u6765\u89e3\u91ca\u4e3a\u4ec0\u4e48\u538b\u7f29\u8fc7\u7a0b\u4f1a\u5f3a\u5236\u53d1\u73b0\u56e0\u679c\u7ed3\u6784\u800c\u975e\u8868\u9762\u7edf\u8ba1\u6a21\u5f0f\u3002\u4fe1\u606f\u8bba\u5fc5\u8981\u6027(ITI)\u5efa\u7acb\u4e86\u7cfb\u7edf\u5fc5\u987b\u901a\u8fc7\u9884\u6d4b\u538b\u7f29\u6700\u5c0f\u5316\u8ba4\u77e5\u71b5\uff0c\u538b\u7f29\u6548\u7387\u539f\u5219(CEP)\u5219\u8bf4\u660e\u9ad8\u6548\u538b\u7f29\u5982\u4f55\u901a\u8fc7\u5f02\u5e38\u79ef\u7d2f\u52a8\u6001\u9009\u62e9\u751f\u6210\u6027\u56e0\u679c\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u6846\u67b6\u867d\u7136\u8ba4\u8bc6\u5230\u538b\u7f29\u5bf9\u667a\u80fd\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u4f46\u672a\u80fd\u5177\u4f53\u8bf4\u660e\u4e3a\u4ec0\u4e48\u8fd9\u4e2a\u8fc7\u7a0b\u4f1a\u5f3a\u5236\u53d1\u73b0\u56e0\u679c\u7ed3\u6784\u800c\u975e\u8868\u9762\u7edf\u8ba1\u6a21\u5f0f\u3002", "method": "\u5f15\u5165\u4e24\u5c42\u6b21\u6846\u67b6\uff1aITI\u4ece\u8fdb\u5316\u89d2\u5ea6\u89e3\u91ca\u751f\u5b58\u538b\u529b\u5982\u4f55\u5bfc\u81f4\u4fe1\u606f\u5904\u7406\u9700\u6c42\uff0cCEP\u5219\u4ece\u673a\u5236\u4e0a\u8bf4\u660e\u9ad8\u6548\u538b\u7f29\u5982\u4f55\u901a\u8fc7\u5f02\u5e38\u79ef\u7d2f\u52a8\u6001\u9009\u62e9\u56e0\u679c\u6a21\u578b\u3002", "result": "\u8be5\u6846\u67b6\u4ea7\u751f\u4e86\u53ef\u5b9e\u8bc1\u68c0\u9a8c\u7684\u9884\u6d4b\uff1a\u538b\u7f29\u6548\u7387\u4e0e\u5206\u5e03\u5916\u6cdb\u5316\u76f8\u5173\uff0c\u5f02\u5e38\u79ef\u7d2f\u7387\u53ef\u533a\u5206\u56e0\u679c\u6a21\u578b\u548c\u76f8\u5173\u6a21\u578b\uff0c\u5206\u5c42\u7cfb\u7edf\u5728\u4e0d\u540c\u62bd\u8c61\u5c42\u4e0a\u8868\u73b0\u51fa\u9012\u589e\u6548\u7387\uff0c\u751f\u7269\u7cfb\u7edf\u7684\u4ee3\u8c22\u6210\u672c\u4e0e\u8868\u5f81\u590d\u6742\u6027\u76f8\u5173\u3002", "conclusion": "ITI\u548cCEP\u4e3a\u751f\u7269\u3001\u4eba\u5de5\u548c\u591a\u5c3a\u5ea6\u7cfb\u7edf\u7684\u8d8b\u540c\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u91ca\uff0c\u65e0\u9700\u8bc9\u8bf8\u610f\u8bc6\u6216\u4e3b\u89c2\u7ecf\u9a8c\u7684\u5047\u8bbe\uff0c\u8bf4\u660e\u667a\u80fd\u662f\u5728\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u6301\u7eed\u5b58\u5728\u7684\u673a\u68b0\u5fc5\u7136\u7ed3\u679c\u3002"}}
{"id": "2510.25939", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.25939", "abs": "https://arxiv.org/abs/2510.25939", "authors": ["Robert A. Bridges", "Thomas R. Mitchell", "Mauricio Mu\u00f1oz", "Ted Henriksson"], "title": "SoK: Honeypots & LLMs, More Than the Sum of Their Parts?", "comment": "Systemization of Knowledge", "summary": "The advent of Large Language Models (LLMs) promised to resolve the\nlong-standing paradox in honeypot design: achieving high-fidelity deception\nwith low operational risk. However, despite a flurry of research since late\n2022, progress has been incremental, and the field lacks a cohesive\nunderstanding of the emerging architectural patterns, core challenges, and\nevaluation paradigms. To fill this gap, this Systematization of Knowledge (SoK)\npaper provides the first comprehensive overview of this new domain. We survey\nand systematize three critical, intersecting research areas: first, we provide\na taxonomy of honeypot detection vectors, structuring the core problems that\nLLM-based realism must solve; second, we synthesize the emerging literature on\nLLM-honeypots, identifying a canonical architecture and key evaluation trends;\nand third, we chart the evolutionary path of honeypot log analysis, from simple\ndata reduction to automated intelligence generation. We synthesize these\nfindings into a forward-looking research roadmap, arguing that the true\npotential of this technology lies in creating autonomous, self-improving\ndeception systems to counter the emerging threat of intelligent, automated\nattackers.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u68b3\u7406\u4e86\u57fa\u4e8eLLM\u7684\u871c\u7f50\u7814\u7a76\u9886\u57df\uff0c\u63d0\u51fa\u4e86\u68c0\u6d4b\u5411\u91cf\u5206\u7c7b\u6cd5\u3001\u871c\u7f50\u67b6\u6784\u5206\u6790\u548c\u65e5\u5fd7\u5206\u6790\u6f14\u8fdb\u8def\u5f84\uff0c\u5e76\u5c55\u671b\u4e86\u81ea\u4e3b\u6b3a\u9a97\u7cfb\u7edf\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u89e3\u51b3\u871c\u7f50\u8bbe\u8ba1\u4e2d\u9ad8\u4fdd\u771f\u6b3a\u9a97\u4e0e\u4f4e\u64cd\u4f5c\u98ce\u9669\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u586b\u8865LLM\u871c\u7f50\u7814\u7a76\u9886\u57df\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7406\u89e3\u7684\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u77e5\u8bc6\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u8c03\u67e5\u4e86\u4e09\u4e2a\u5173\u952e\u7814\u7a76\u9886\u57df\uff1a\u871c\u7f50\u68c0\u6d4b\u5411\u91cf\u5206\u7c7b\u3001LLM\u871c\u7f50\u6587\u732e\u7efc\u5408\u5206\u6790\u548c\u871c\u7f50\u65e5\u5fd7\u5206\u6790\u6f14\u8fdb\u8def\u5f84\u3002", "result": "\u63d0\u51fa\u4e86\u68c0\u6d4b\u5411\u91cf\u5206\u7c7b\u6cd5\uff0c\u8bc6\u522b\u4e86\u5178\u578bLLM\u871c\u7f50\u67b6\u6784\u548c\u8bc4\u4f30\u8d8b\u52bf\uff0c\u63cf\u7ed8\u4e86\u65e5\u5fd7\u5206\u6790\u4ece\u6570\u636e\u7b80\u5316\u5230\u81ea\u52a8\u60c5\u62a5\u751f\u6210\u7684\u6f14\u8fdb\u8def\u5f84\u3002", "conclusion": "LLM\u871c\u7f50\u6280\u672f\u7684\u771f\u6b63\u6f5c\u529b\u5728\u4e8e\u521b\u5efa\u81ea\u4e3b\u3001\u81ea\u6211\u6539\u8fdb\u7684\u6b3a\u9a97\u7cfb\u7edf\uff0c\u4ee5\u5e94\u5bf9\u667a\u80fd\u81ea\u52a8\u5316\u653b\u51fb\u8005\u7684\u65b0\u5174\u5a01\u80c1\u3002"}}
{"id": "2510.26174", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26174", "abs": "https://arxiv.org/abs/2510.26174", "authors": ["Liming Dong", "Sung Une Lee", "Zhenchang Xing", "Muhammad Ejaz Ahmed", "Stefan Avgoustakis"], "title": "The \"4W+1H\" of Software Supply Chain Security Checklist for Critical Infrastructure", "comment": "18 pages, 4 figures", "summary": "The increasing frequency and sophistication of software supply chain attacks\npose severe risks to critical infrastructure sectors, threatening national\nsecurity, economic stability, and public safety. Despite growing awareness,\nexisting security practices remain fragmented and insufficient, with most\nframeworks narrowly focused on isolated life cycle stages or lacking alignment\nwith the specific needs of critical infrastructure (CI) sectors. In this paper,\nwe conducted a multivocal literature review across international frameworks,\nAustralian regulatory sources, and academic studies to identify and analyze\nsecurity practices across the software supply chain, especially specific CI\nsector. Our analysis found that few existing frameworks are explicitly tailored\nto CI domains. We systematically leveraged identified software supply chain\nsecurity frameworks, using a \"4W+1H\" analytical approach, we synthesized ten\ncore categories (what) of software supply chain security practices, mapped them\nacross life-cycle phases (when), stakeholder roles (who), and implementation\nlevels (how), and examined their coverage across existing frameworks (where).\nBuilding on these insights, the paper culminates in structured, multi-layered\nchecklist of 80 questions designed to relevant stakeholders evaluate and\nenhance their software supply chain security. Our findings reveal gaps between\nframework guidance and sector-specific needs, highlight the need for\nintegrated, context-aware approaches to safeguard critical infrastructure from\nevolving software supply chain risks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u591a\u6e90\u6587\u732e\u7efc\u8ff0\u5206\u6790\u4e86\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u5b9e\u8df5\uff0c\u53d1\u73b0\u73b0\u6709\u6846\u67b6\u5f88\u5c11\u9488\u5bf9\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u9886\u57df\u5b9a\u5236\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b80\u4e2a\u95ee\u9898\u7684\u7ed3\u6784\u5316\u68c0\u67e5\u8868\u6765\u5e2e\u52a9\u8bc4\u4f30\u548c\u589e\u5f3a\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u3002", "motivation": "\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u9891\u7387\u548c\u590d\u6742\u6027\u4e0d\u65ad\u589e\u52a0\uff0c\u5bf9\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u6784\u6210\u4e25\u91cd\u98ce\u9669\uff0c\u800c\u73b0\u6709\u5b89\u5168\u5b9e\u8df5\u5206\u6563\u4e14\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u9488\u5bf9\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u9886\u57df\u7684\u4e13\u95e8\u6846\u67b6\u3002", "method": "\u91c7\u7528\u591a\u6e90\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u56fd\u9645\u6846\u67b6\u3001\u6fb3\u5927\u5229\u4e9a\u76d1\u7ba1\u6765\u6e90\u548c\u5b66\u672f\u7814\u7a76\uff0c\u4f7f\u7528\"4W+1H\"\u5206\u6790\u65b9\u6cd5\u7efc\u5408\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u5b9e\u8df5\u7684\u6838\u5fc3\u7c7b\u522b\u3002", "result": "\u8bc6\u522b\u51fa10\u4e2a\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u5b9e\u8df5\u6838\u5fc3\u7c7b\u522b\uff0c\u53d1\u73b0\u73b0\u6709\u6846\u67b6\u4e0e\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u9886\u57df\u7279\u5b9a\u9700\u6c42\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\uff0c\u5f00\u53d1\u4e86\u7ed3\u6784\u5316\u591a\u5c42\u68c0\u67e5\u8868\u3002", "conclusion": "\u9700\u8981\u96c6\u6210\u3001\u60c5\u5883\u611f\u77e5\u7684\u65b9\u6cd5\u6765\u4fdd\u62a4\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u514d\u53d7\u4e0d\u65ad\u6f14\u53d8\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u98ce\u9669\uff0c\u6846\u67b6\u6307\u5bfc\u4e0e\u884c\u4e1a\u7279\u5b9a\u9700\u6c42\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\u3002"}}
{"id": "2510.25884", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25884", "abs": "https://arxiv.org/abs/2510.25884", "authors": ["Eit\u00e1n Sprejer", "Fernando Avalos", "Augusto Bernardi", "Jose Pedro Brito de Azevedo Faustino", "Jacob Haimes", "Narmeen Fatimah Oozeer"], "title": "Approximating Human Preferences Using a Multi-Judge Learned System", "comment": null, "summary": "Aligning LLM-based judges with human preferences is a significant challenge,\nas they are difficult to calibrate and often suffer from rubric sensitivity,\nbias, and instability. Overcoming this challenge advances key applications,\nsuch as creating reliable reward models for Reinforcement Learning from Human\nFeedback (RLHF) and building effective routing systems that select the\nbest-suited model for a given user query. In this work, we propose a framework\nfor modeling diverse, persona-based preferences by learning to aggregate\noutputs from multiple rubric-conditioned judges. We investigate the performance\nof this approach against naive baselines and assess its robustness through case\nstudies on both human and LLM-judges biases. Our primary contributions include\na persona-based method for synthesizing preference labels at scale and two\ndistinct implementations of our aggregator: Generalized Additive Model (GAM)\nand a Multi-Layer Perceptron (MLP).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u591a\u4e2a\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u5224\u8005\u8f93\u51fa\u6765\u5bf9\u9f50LLM\u8bc4\u5224\u8005\u4e0e\u4eba\u7c7b\u504f\u597d\uff0c\u89e3\u51b3\u6821\u51c6\u56f0\u96be\u3001\u8bc4\u5206\u6807\u51c6\u654f\u611f\u6027\u3001\u504f\u89c1\u548c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u57fa\u4e8eLLM\u7684\u8bc4\u5224\u8005\u96be\u4ee5\u6821\u51c6\uff0c\u5b58\u5728\u8bc4\u5206\u6807\u51c6\u654f\u611f\u6027\u3001\u504f\u89c1\u548c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u5bf9\u4e8e\u6784\u5efa\u53ef\u9760\u7684RLHF\u5956\u52b1\u6a21\u578b\u548c\u6709\u6548\u7684\u6a21\u578b\u8def\u7531\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\u5efa\u6a21\u6846\u67b6\uff0c\u5b66\u4e60\u805a\u5408\u591a\u4e2a\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u5224\u8005\u8f93\u51fa\u3002\u5305\u62ec\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\u6807\u7b7e\u5927\u89c4\u6a21\u5408\u6210\u65b9\u6cd5\uff0c\u4ee5\u53ca\u4e24\u79cd\u805a\u5408\u5668\u5b9e\u73b0\uff1a\u5e7f\u4e49\u52a0\u6027\u6a21\u578b(GAM)\u548c\u591a\u5c42\u611f\u77e5\u5668(MLP)\u3002", "result": "\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u7b80\u5355\u57fa\u7ebf\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u5176\u5bf9\u4eba\u7c7b\u548cLLM\u8bc4\u5224\u8005\u504f\u89c1\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5efa\u6a21\u591a\u6837\u5316\u7684\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\uff0c\u4e3aLLM\u8bc4\u5224\u8005\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25960", "categories": ["cs.CR", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.25960", "abs": "https://arxiv.org/abs/2510.25960", "authors": ["Zeynep Yasemin Erdogan", "Shishir Nagaraja", "Chuadhry Mujeeb Ahmed", "Ryan Shah"], "title": "WaveVerif: Acoustic Side-Channel based Verification of Robotic Workflows", "comment": "11 pages, 3 figures, Corresponding Author: Prof. Shishir Nagaraja\n  (shishir.nagaraja@newcastle.ac.uk)", "summary": "In this paper, we present a framework that uses acoustic side-channel\nanalysis (ASCA) to monitor and verify whether a robot correctly executes its\nintended commands. We develop and evaluate a machine-learning-based workflow\nverification system that uses acoustic emissions generated by robotic\nmovements. The system can determine whether real-time behavior is consistent\nwith expected commands. The evaluation takes into account movement speed,\ndirection, and microphone distance. The results show that individual robot\nmovements can be validated with over 80% accuracy under baseline conditions\nusing four different classifiers: Support Vector Machine (SVM), Deep Neural\nNetwork (DNN), Recurrent Neural Network (RNN), and Convolutional Neural Network\n(CNN). Additionally, workflows such as pick-and-place and packing could be\nidentified with similarly high confidence. Our findings demonstrate that\nacoustic signals can support real-time, low-cost, passive verification in\nsensitive robotic environments without requiring hardware modifications.", "AI": {"tldr": "\u4f7f\u7528\u58f0\u5b66\u4fa7\u4fe1\u9053\u5206\u6790\uff08ASCA\uff09\u901a\u8fc7\u673a\u5668\u4eba\u8fd0\u52a8\u4ea7\u751f\u7684\u58f0\u97f3\u6765\u9a8c\u8bc1\u673a\u5668\u4eba\u662f\u5426\u6b63\u786e\u6267\u884c\u547d\u4ee4\u7684\u6846\u67b6\uff0c\u5728\u57fa\u51c6\u6761\u4ef6\u4e0b\u53ef\u5b9e\u73b0\u8d85\u8fc780%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5728\u654f\u611f\u673a\u5668\u4eba\u73af\u5883\u4e2d\u9700\u8981\u5b9e\u65f6\u3001\u4f4e\u6210\u672c\u3001\u65e0\u9700\u786c\u4ef6\u4fee\u6539\u7684\u88ab\u52a8\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u58f0\u5b66\u4fe1\u53f7\u4e3a\u6b64\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u4f7f\u7528\u56db\u79cd\u5206\u7c7b\u5668\uff08SVM\u3001DNN\u3001RNN\u3001CNN\uff09\u5206\u6790\u673a\u5668\u4eba\u8fd0\u52a8\u4ea7\u751f\u7684\u58f0\u5b66\u53d1\u5c04\u4fe1\u53f7\uff0c\u8003\u8651\u8fd0\u52a8\u901f\u5ea6\u3001\u65b9\u5411\u548c\u9ea6\u514b\u98ce\u8ddd\u79bb\u7b49\u56e0\u7d20\u3002", "result": "\u5355\u4e2a\u673a\u5668\u4eba\u8fd0\u52a8\u9a8c\u8bc1\u51c6\u786e\u7387\u8d85\u8fc780%\uff0c\u62fe\u53d6\u653e\u7f6e\u548c\u5305\u88c5\u7b49\u5de5\u4f5c\u6d41\u7a0b\u4e5f\u80fd\u4ee5\u7c7b\u4f3c\u9ad8\u7f6e\u4fe1\u5ea6\u8bc6\u522b\u3002", "conclusion": "\u58f0\u5b66\u4fe1\u53f7\u80fd\u591f\u652f\u6301\u654f\u611f\u673a\u5668\u4eba\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u3001\u4f4e\u6210\u672c\u3001\u88ab\u52a8\u9a8c\u8bc1\uff0c\u65e0\u9700\u786c\u4ef6\u4fee\u6539\u3002"}}
{"id": "2510.26275", "categories": ["cs.SE", "cs.AI", "cs.ET", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.26275", "abs": "https://arxiv.org/abs/2510.26275", "authors": ["Domenico Amalfitano", "Andreas Metzger", "Marco Autili", "Tommaso Fulcini", "Tobias Hey", "Jan Keim", "Patrizio Pelliccione", "Vincenzo Scotti", "Anne Koziolek", "Raffaela Mirandola", "Andreas Vogelsang"], "title": "A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI", "comment": null, "summary": "Generative AI (GenAI) is rapidly transforming software engineering (SE)\npractices, influencing how SE processes are executed, as well as how software\nsystems are developed, operated, and evolved. This paper applies design science\nresearch to build a roadmap for GenAI-augmented SE. The process consists of\nthree cycles that incrementally integrate multiple sources of evidence,\nincluding collaborative discussions from the FSE 2025 \"Software Engineering\n2030\" workshop, rapid literature reviews, and external feedback sessions\ninvolving peers. McLuhan's tetrads were used as a conceptual instrument to\nsystematically capture the transforming effects of GenAI on SE processes and\nsoftware products.The resulting roadmap identifies four fundamental forms of\nGenAI augmentation in SE and systematically characterizes their related\nresearch challenges and opportunities. These insights are then consolidated\ninto a set of future research directions. By grounding the roadmap in a\nrigorous multi-cycle process and cross-validating it among independent author\nteams and peers, the study provides a transparent and reproducible foundation\nfor analyzing how GenAI affects SE processes, methods and tools, and for\nframing future research within this rapidly evolving area. Based on these\nfindings, the article finally makes ten predictions for SE in the year 2030.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5e94\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\u6784\u5efa\u4e86\u751f\u6210\u5f0fAI\u589e\u5f3a\u8f6f\u4ef6\u5de5\u7a0b\u7684\u8def\u7ebf\u56fe\uff0c\u901a\u8fc7\u591a\u8f6e\u8bc1\u636e\u6574\u5408\u548c\u9ea6\u514b\u5362\u6c49\u56db\u5143\u6cd5\u5206\u6790\uff0c\u8bc6\u522b\u4e86\u56db\u79cdGenAI\u589e\u5f3a\u5f62\u5f0f\u53ca\u5176\u76f8\u5173\u7814\u7a76\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e862030\u5e74\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5341\u4e2a\u9884\u6d4b\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6b63\u5728\u8fc5\u901f\u6539\u53d8\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff0c\u5f71\u54cd\u8f6f\u4ef6\u5f00\u53d1\u3001\u8fd0\u7ef4\u548c\u6f14\u8fdb\u8fc7\u7a0b\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u6784\u5efaGenAI\u589e\u5f3a\u8f6f\u4ef6\u5de5\u7a0b\u7684\u8def\u7ebf\u56fe\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u4e2a\u5faa\u73af\u9010\u6b65\u6574\u5408\u591a\u4e2a\u8bc1\u636e\u6e90\uff0c\u5305\u62ecFSE 2025\u7814\u8ba8\u4f1a\u8ba8\u8bba\u3001\u5feb\u901f\u6587\u732e\u7efc\u8ff0\u548c\u540c\u884c\u53cd\u9988\uff0c\u4f7f\u7528\u9ea6\u514b\u5362\u6c49\u56db\u5143\u6cd5\u4f5c\u4e3a\u6982\u5ff5\u5de5\u5177\u5206\u6790GenAI\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5f71\u54cd\u3002", "result": "\u8bc6\u522b\u4e86\u56db\u79cdGenAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u57fa\u672c\u589e\u5f3a\u5f62\u5f0f\uff0c\u7cfb\u7edf\u6027\u5730\u63cf\u8ff0\u4e86\u76f8\u5173\u7814\u7a76\u6311\u6218\u548c\u673a\u9047\uff0c\u5e76\u6574\u5408\u6210\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u901a\u8fc7\u4e25\u8c28\u7684\u591a\u5faa\u73af\u8fc7\u7a0b\u548c\u8de8\u56e2\u961f\u9a8c\u8bc1\uff0c\u4e3a\u5206\u6790GenAI\u5982\u4f55\u5f71\u54cd\u8f6f\u4ef6\u5de5\u7a0b\u8fc7\u7a0b\u3001\u65b9\u6cd5\u548c\u5de5\u5177\u63d0\u4f9b\u4e86\u900f\u660e\u53ef\u590d\u73b0\u7684\u57fa\u7840\uff0c\u5e76\u57fa\u4e8e\u53d1\u73b0\u63d0\u51fa\u4e862030\u5e74\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5341\u4e2a\u9884\u6d4b\u3002"}}
{"id": "2510.25908", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25908", "abs": "https://arxiv.org/abs/2510.25908", "authors": ["Emily Herron", "Junqi Yin", "Feiyi Wang"], "title": "SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications", "comment": "Preprint Submitted to ACM Transactions on AI for Science (TAIS)", "summary": "Large language models (LLMs) have demonstrated transformative potential in\nscientific research, yet their deployment in high-stakes contexts raises\nsignificant trustworthiness concerns. Here, we introduce SciTrust 2.0, a\ncomprehensive framework for evaluating LLM trustworthiness in scientific\napplications across four dimensions: truthfulness, adversarial robustness,\nscientific safety, and scientific ethics. Our framework incorporates novel,\nopen-ended truthfulness benchmarks developed through a verified\nreflection-tuning pipeline and expert validation, alongside a novel ethics\nbenchmark for scientific research contexts covering eight subcategories\nincluding dual-use research and bias. We evaluated seven prominent LLMs,\nincluding four science-specialized models and three general-purpose industry\nmodels, using multiple evaluation metrics including accuracy, semantic\nsimilarity measures, and LLM-based scoring. General-purpose industry models\noverall outperformed science-specialized models across each trustworthiness\ndimension, with GPT-o4-mini demonstrating superior performance in truthfulness\nassessments and adversarial robustness. Science-specialized models showed\nsignificant deficiencies in logical and ethical reasoning capabilities, along\nwith concerning vulnerabilities in safety evaluations, particularly in\nhigh-risk domains such as biosecurity and chemical weapons. By open-sourcing\nour framework, we provide a foundation for developing more trustworthy AI\nsystems and advancing research on model safety and ethics in scientific\ncontexts.", "AI": {"tldr": "SciTrust 2.0\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u5728\u79d1\u5b66\u5e94\u7528\u4e2d\u53ef\u4fe1\u5ea6\u7684\u6846\u67b6\uff0c\u6db5\u76d6\u771f\u5b9e\u6027\u3001\u5bf9\u6297\u9c81\u68d2\u6027\u3001\u79d1\u5b66\u5b89\u5168\u548c\u79d1\u5b66\u4f26\u7406\u56db\u4e2a\u7ef4\u5ea6\u3002\u8bc4\u4f30\u663e\u793a\u901a\u7528\u884c\u4e1a\u6a21\u578b\u4f18\u4e8e\u79d1\u5b66\u4e13\u7528\u6a21\u578b\uff0c\u79d1\u5b66\u4e13\u7528\u6a21\u578b\u5728\u903b\u8f91\u548c\u4f26\u7406\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002", "motivation": "LLM\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u5c55\u73b0\u51fa\u53d8\u9769\u6f5c\u529b\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u5f15\u53d1\u4e86\u53ef\u4fe1\u5ea6\u62c5\u5fe7\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u65b0\u9896\u5f00\u653e\u5f0f\u771f\u5b9e\u6027\u57fa\u51c6\u548c\u4f26\u7406\u57fa\u51c6\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u9a8c\u8bc1\u7684\u53cd\u601d\u8c03\u4f18\u6d41\u7a0b\u548c\u4e13\u5bb6\u9a8c\u8bc1\u6784\u5efa\uff0c\u4f7f\u7528\u51c6\u786e\u6027\u3001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u548cLLM\u8bc4\u5206\u7b49\u591a\u79cd\u6307\u6807\u8bc4\u4f30\u4e03\u4e2a\u4e3b\u8981LLM\u3002", "result": "\u901a\u7528\u884c\u4e1a\u6a21\u578b\u5728\u6240\u6709\u53ef\u4fe1\u5ea6\u7ef4\u5ea6\u4e0a\u5747\u4f18\u4e8e\u79d1\u5b66\u4e13\u7528\u6a21\u578b\uff0cGPT-4-mini\u5728\u771f\u5b9e\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u79d1\u5b66\u4e13\u7528\u6a21\u578b\u5728\u903b\u8f91\u4f26\u7406\u63a8\u7406\u548c\u5b89\u5168\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u4e25\u91cd\u7f3a\u9677\u3002", "conclusion": "\u901a\u8fc7\u5f00\u6e90\u8be5\u6846\u67b6\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u548c\u63a8\u8fdb\u79d1\u5b66\u80cc\u666f\u4e0b\u6a21\u578b\u5b89\u5168\u4e0e\u4f26\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.26003", "categories": ["cs.CR", "94A60"], "pdf": "https://arxiv.org/pdf/2510.26003", "abs": "https://arxiv.org/abs/2510.26003", "authors": ["Eirini Poimenidou", "K. A. Draziotis"], "title": "Message Recovery Attack in NTRU via Knapsack", "comment": null, "summary": "In the present paper, we introduce a message-recovery attack based on the\nModular Knapsack Problem, applicable to all variants of the NTRU-HPS\ncryptosystem. Assuming that a fraction $\\epsilon$ of the coefficients of the\nmessage ${\\bf{m}}\\in\\{-1,0,1\\}^N$ and of the nonce vector ${\\bf\nr}\\in\\{-1,0,1\\}^N$ are known in advance at random positions, we reduce message\ndecryption to finding a short vector in a lattice that encodes an instance of a\nmodular knapsack system. This allows us to address a key question: how much\ninformation about ${\\bf m}$, or about the pair $({\\bf m},{\\bf r})$, is required\nbefore recovery becomes feasible? A FLATTER reduction successfully recovers the\nmessage, in practice when $\\epsilon\\approx 0.45$. Our implementation finds\n${\\bf m}$ within a few minutes on a commodity desktop.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6a21\u80cc\u5305\u95ee\u9898\u7684\u6d88\u606f\u6062\u590d\u653b\u51fb\uff0c\u9002\u7528\u4e8e\u6240\u6709NTRU-HPS\u5bc6\u7801\u7cfb\u7edf\u53d8\u4f53\u3002\u5f53\u5df2\u77e5\u6d88\u606f\u548c\u968f\u673a\u5411\u91cf\u90e8\u5206\u7cfb\u6570\u65f6\uff0c\u53ef\u5c06\u6d88\u606f\u89e3\u5bc6\u7b80\u5316\u4e3a\u5728\u683c\u4e2d\u5bfb\u627e\u77ed\u5411\u91cf\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5728NTRU-HPS\u5bc6\u7801\u7cfb\u7edf\u4e2d\uff0c\u9700\u8981\u591a\u5c11\u5173\u4e8e\u6d88\u606f\u6216\u6d88\u606f-\u968f\u673a\u6570\u5bf9\u7684\u4fe1\u606f\u624d\u80fd\u5b9e\u73b0\u53ef\u884c\u7684\u6d88\u606f\u6062\u590d\uff0c\u63a2\u7d22\u5bc6\u7801\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u8fb9\u754c\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u6a21\u80cc\u5305\u95ee\u9898\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7FLATTER\u7ea6\u7b80\u6280\u672f\uff0c\u5c06\u6d88\u606f\u89e3\u5bc6\u95ee\u9898\u8f6c\u5316\u4e3a\u5728\u7279\u5b9a\u683c\u4e2d\u5bfb\u627e\u77ed\u5411\u91cf\u7684\u95ee\u9898\u3002", "result": "\u5f53\u5df2\u77e5\u7ea645%\u7684\u6d88\u606f\u548c\u968f\u673a\u5411\u91cf\u7cfb\u6570\u65f6\uff0c\u653b\u51fb\u5728\u5b9e\u8df5\u4e2d\u6210\u529f\u6062\u590d\u6d88\u606f\uff0c\u5728\u666e\u901a\u53f0\u5f0f\u673a\u4e0a\u51e0\u5206\u949f\u5185\u5373\u53ef\u5b8c\u6210\u3002", "conclusion": "NTRU-HPS\u5bc6\u7801\u7cfb\u7edf\u5728\u653b\u51fb\u8005\u638c\u63e1\u90e8\u5206\u6d88\u606f\u4fe1\u606f\u65f6\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u7ea645%\u7684\u7cfb\u6570\u4fe1\u606f\u5373\u53ef\u5b9e\u73b0\u6709\u6548\u653b\u51fb\u3002"}}
{"id": "2510.26287", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26287", "abs": "https://arxiv.org/abs/2510.26287", "authors": ["Guochang Li", "Yuchen Liu", "Zhen Qin", "Yunkun Wang", "Jianping Zhong", "Chen Zhi", "Binhua Li", "Fei Huang", "Yongbin Li", "Shuiguang Deng"], "title": "Empowering RepoQA-Agent based on Reinforcement Learning Driven by Monte-carlo Tree Search", "comment": null, "summary": "Repository-level software engineering tasks require large language models\n(LLMs) to efficiently navigate and extract information from complex codebases\nthrough multi-turn tool interactions. Existing approaches face significant\nlimitations: training-free, in-context learning methods struggle to guide\nagents effectively in tool utilization and decision-making based on\nenvironmental feedback, while training-based approaches typically rely on\ncostly distillation from larger LLMs, introducing data compliance concerns in\nenterprise environments. To address these challenges, we introduce\nRepoSearch-R1, a novel agentic reinforcement learning framework driven by\nMonte-carlo Tree Search (MCTS). This approach allows agents to generate\ndiverse, high-quality reasoning trajectories via self-training without\nrequiring model distillation or external supervision. Based on RepoSearch-R1,\nwe construct a RepoQA-Agent specifically designed for repository\nquestion-answering tasks. Comprehensive evaluation on repository\nquestion-answering tasks demonstrates that RepoSearch-R1 achieves substantial\nimprovements of answer completeness: 16.0% enhancement over no-retrieval\nmethods, 19.5% improvement over iterative retrieval methods, and 33% increase\nin training efficiency compared to general agentic reinforcement learning\napproaches. Our cold-start training methodology eliminates data compliance\nconcerns while maintaining robust exploration diversity and answer completeness\nacross repository-level reasoning tasks.", "AI": {"tldr": "RepoSearch-R1\u662f\u4e00\u4e2a\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u4ed3\u5e93\u7ea7\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u4ee3\u7801\u5e93\u5bfc\u822a\u548c\u4fe1\u606f\u63d0\u53d6\u95ee\u9898\uff0c\u65e0\u9700\u6a21\u578b\u84b8\u998f\u6216\u5916\u90e8\u76d1\u7763\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u65e0\u8bad\u7ec3\u65b9\u6cd5\u5728\u5de5\u5177\u5229\u7528\u548c\u73af\u5883\u53cd\u9988\u51b3\u7b56\u65b9\u9762\u6548\u679c\u4e0d\u4f73\uff0c\u800c\u57fa\u4e8e\u8bad\u7ec3\u7684\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u5927\u6a21\u578b\u84b8\u998f\uff0c\u5b58\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u6570\u636e\u5408\u89c4\u95ee\u9898\u3002", "method": "\u5f15\u5165RepoSearch-R1\u6846\u67b6\uff0c\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u9a71\u52a8\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u81ea\u8bad\u7ec3\u751f\u6210\u591a\u6837\u5316\u7684\u9ad8\u8d28\u91cf\u63a8\u7406\u8f68\u8ff9\uff0c\u65e0\u9700\u6a21\u578b\u84b8\u998f\u6216\u5916\u90e8\u76d1\u7763\u3002", "result": "\u5728\u4ed3\u5e93\u95ee\u7b54\u4efb\u52a1\u4e0a\uff0cRepoSearch-R1\u76f8\u6bd4\u65e0\u68c0\u7d22\u65b9\u6cd5\u63d0\u534716.0%\u7b54\u6848\u5b8c\u6574\u6027\uff0c\u76f8\u6bd4\u8fed\u4ee3\u68c0\u7d22\u65b9\u6cd5\u63d0\u534719.5%\uff0c\u8bad\u7ec3\u6548\u7387\u6bd4\u901a\u7528\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u63d0\u9ad833%\u3002", "conclusion": "\u8be5\u51b7\u542f\u52a8\u8bad\u7ec3\u65b9\u6cd5\u6d88\u9664\u4e86\u6570\u636e\u5408\u89c4\u95ee\u9898\uff0c\u540c\u65f6\u5728\u4ed3\u5e93\u7ea7\u63a8\u7406\u4efb\u52a1\u4e2d\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u63a2\u7d22\u591a\u6837\u6027\u548c\u7b54\u6848\u5b8c\u6574\u6027\u3002"}}
{"id": "2510.25914", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25914", "abs": "https://arxiv.org/abs/2510.25914", "authors": ["Ngoc Phuoc An Vo", "Manish Kesarwani", "Ruchi Mahindru", "Chandrasekhar Narayanaswami"], "title": "FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization", "comment": null, "summary": "FinOps (Finance + Operations) represents an operational framework and\ncultural practice which maximizes cloud business value through collaborative\nfinancial accountability across engineering, finance, and business teams.\nFinOps practitioners face a fundamental challenge: billing data arrives in\nheterogeneous formats, taxonomies, and metrics from multiple cloud providers\nand internal systems which eventually lead to synthesizing actionable insights,\nand making time-sensitive decisions. To address this challenge, we propose\nleveraging autonomous, goal-driven AI agents for FinOps automation. In this\npaper, we built a FinOps agent for a typical use-case for IT infrastructure and\ncost optimization. We built a system simulating a realistic end-to-end industry\nprocess starting with retrieving data from various sources to consolidating and\nanalyzing the data to generate recommendations for optimization. We defined a\nset of metrics to evaluate our agent using several open-source and close-source\nlanguage models and it shows that the agent was able to understand, plan, and\nexecute tasks as well as an actual FinOps practitioner.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u81ea\u4e3bAI\u4ee3\u7406\u5b9e\u73b0FinOps\u81ea\u52a8\u5316\uff0c\u901a\u8fc7\u6a21\u62df\u7aef\u5230\u7aef\u884c\u4e1a\u6d41\u7a0b\uff0c\u4ece\u591a\u6e90\u6570\u636e\u83b7\u53d6\u5230\u5206\u6790\u751f\u6210\u4f18\u5316\u5efa\u8bae\uff0c\u8bc4\u4f30\u663e\u793a\u4ee3\u7406\u80fd\u50cf\u5b9e\u9645FinOps\u4ece\u4e1a\u8005\u4e00\u6837\u7406\u89e3\u548c\u6267\u884c\u4efb\u52a1\u3002", "motivation": "FinOps\u4ece\u4e1a\u8005\u9762\u4e34\u6765\u81ea\u591a\u4e2a\u4e91\u63d0\u4f9b\u5546\u548c\u5185\u90e8\u7cfb\u7edf\u7684\u5f02\u6784\u8ba1\u8d39\u6570\u636e\u683c\u5f0f\u3001\u5206\u7c7b\u548c\u6307\u6807\uff0c\u5bfc\u81f4\u96be\u4ee5\u7efc\u5408\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u5e76\u505a\u51fa\u53ca\u65f6\u51b3\u7b56\u3002", "method": "\u6784\u5efaFinOps\u4ee3\u7406\u7cfb\u7edf\uff0c\u6a21\u62df\u4ece\u591a\u6e90\u6570\u636e\u68c0\u7d22\u5230\u6570\u636e\u6574\u5408\u5206\u6790\u518d\u5230\u751f\u6210\u4f18\u5316\u5efa\u8bae\u7684\u7aef\u5230\u7aef\u884c\u4e1a\u6d41\u7a0b\uff0c\u4f7f\u7528\u591a\u4e2a\u5f00\u6e90\u548c\u95ed\u6e90\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4ee3\u7406\u80fd\u591f\u50cf\u5b9e\u9645FinOps\u4ece\u4e1a\u8005\u4e00\u6837\u7406\u89e3\u3001\u89c4\u5212\u548c\u6267\u884c\u4efb\u52a1\uff0c\u5728IT\u57fa\u7840\u8bbe\u65bd\u548c\u6210\u672c\u4f18\u5316\u7528\u4f8b\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u81ea\u4e3b\u76ee\u6807\u9a71\u52a8AI\u4ee3\u7406\u53ef\u4ee5\u6709\u6548\u89e3\u51b3FinOps\u4e2d\u7684\u5f02\u6784\u6570\u636e\u6311\u6218\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u6210\u672c\u4f18\u5316\u51b3\u7b56\u3002"}}
{"id": "2510.26037", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26037", "abs": "https://arxiv.org/abs/2510.26037", "authors": ["Kaiwen Zhou", "Ahmed Elgohary", "A S M Iftekhar", "Amin Saied"], "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "comment": null, "summary": "The ability of LLM agents to plan and invoke tools exposes them to new safety\nrisks, making a comprehensive red-teaming system crucial for discovering\nvulnerabilities and ensuring their safe deployment. We present SIRAJ: a generic\nred-teaming framework for arbitrary black-box LLM agents. We employ a dynamic\ntwo-step process that starts with an agent definition and generates diverse\nseed test cases that cover various risk outcomes, tool-use trajectories, and\nrisk sources. Then, it iteratively constructs and refines model-based\nadversarial attacks based on the execution trajectories of former attempts. To\noptimize the red-teaming cost, we present a model distillation approach that\nleverages structured forms of a teacher model's reasoning to train smaller\nmodels that are equally effective. Across diverse evaluation agent settings,\nour seed test case generation approach yields 2 -- 2.5x boost to the coverage\nof risk outcomes and tool-calling trajectories. Our distilled 8B red-teamer\nmodel improves attack success rate by 100%, surpassing the 671B Deepseek-R1\nmodel. Our ablations and analyses validate the effectiveness of the iterative\nframework, structured reasoning, and the generalization of our red-teamer\nmodels.", "AI": {"tldr": "SIRAJ\u662f\u4e00\u4e2a\u901a\u7528\u7684\u7ea2\u961f\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u53d1\u73b0\u9ed1\u76d2LLM\u4ee3\u7406\u7684\u5b89\u5168\u6f0f\u6d1e\u3002\u901a\u8fc7\u52a8\u6001\u4e24\u6b65\u6d41\u7a0b\u751f\u6210\u591a\u6837\u5316\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u91c7\u7528\u6a21\u578b\u84b8\u998f\u6280\u672f\u4f18\u5316\u6210\u672c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6210\u529f\u7387\u548c\u98ce\u9669\u8986\u76d6\u8303\u56f4\u3002", "motivation": "LLM\u4ee3\u7406\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u5168\u9762\u7684\u7ea2\u961f\u6d4b\u8bd5\u7cfb\u7edf\u6765\u53d1\u73b0\u6f0f\u6d1e\u5e76\u786e\u4fdd\u5b89\u5168\u90e8\u7f72\u3002", "method": "\u91c7\u7528\u52a8\u6001\u4e24\u6b65\u6d41\u7a0b\uff1a\u9996\u5148\u751f\u6210\u8986\u76d6\u5404\u79cd\u98ce\u9669\u7ed3\u679c\u548c\u5de5\u5177\u4f7f\u7528\u8f68\u8ff9\u7684\u79cd\u5b50\u6d4b\u8bd5\u7528\u4f8b\uff0c\u7136\u540e\u57fa\u4e8e\u6267\u884c\u8f68\u8ff9\u8fed\u4ee3\u6784\u5efa\u548c\u4f18\u5316\u57fa\u4e8e\u6a21\u578b\u7684\u5bf9\u6297\u653b\u51fb\u3002\u4f7f\u7528\u6a21\u578b\u84b8\u998f\u6280\u672f\u8bad\u7ec3\u66f4\u5c0f\u7684\u4f46\u540c\u6837\u6709\u6548\u7684\u7ea2\u961f\u6a21\u578b\u3002", "result": "\u79cd\u5b50\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u4f7f\u98ce\u9669\u7ed3\u679c\u548c\u5de5\u5177\u8c03\u7528\u8f68\u8ff9\u7684\u8986\u76d6\u8303\u56f4\u63d0\u9ad8\u4e862-2.5\u500d\u3002\u84b8\u998f\u540e\u76848B\u7ea2\u961f\u6a21\u578b\u653b\u51fb\u6210\u529f\u7387\u63d0\u5347100%\uff0c\u8d85\u8d8a\u4e86671B\u7684Deepseek-R1\u6a21\u578b\u3002", "conclusion": "SIRAJ\u6846\u67b6\u5728\u8fed\u4ee3\u4f18\u5316\u3001\u7ed3\u6784\u5316\u63a8\u7406\u548c\u6a21\u578b\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3aLLM\u4ee3\u7406\u7684\u5b89\u5168\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.26413", "categories": ["cs.SE", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.26413", "abs": "https://arxiv.org/abs/2510.26413", "authors": ["Nuno Saavedra", "Alexandra Mendes", "Jo\u00e3o F. Ferreira"], "title": "Environmental Impact of CI/CD Pipelines", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "CI/CD pipelines are widely used in software development, yet their\nenvironmental impact, particularly carbon and water footprints (CWF), remains\nlargely unknown to developers, as CI service providers typically do not\ndisclose such information. With the growing environmental impact of cloud\ncomputing, understanding the CWF of CI/CD services has become increasingly\nimportant.\n  This work investigates the CWF of using GitHub Actions, focusing on\nopen-source repositories where usage is free and unlimited for standard\nrunners. We build upon a methodology from the Cloud Carbon Footprint framework\nand we use the largest dataset of workflow runs reported in the literature to\ndate, comprising over 2.2 million workflow runs from more than 18,000\nrepositories.\n  Our analysis reveals that the GitHub Actions ecosystem results in a\nsubstantial CWF. Our estimates for the carbon footprint in 2024 range from\n150.5 MTCO2e in the most optimistic scenario to 994.9 MTCO2e in the most\npessimistic scenario, while the water footprint ranges from 1,989.6 to 37,664.5\nkiloliters. The most likely scenario estimates are 456.9 MTCO2e for carbon\nfootprint and 5,738.2 kiloliters for water footprint. To provide perspective,\nthe carbon footprint in the most likely scenario is equivalent to the carbon\ncaptured by 7,615 urban trees in a year, and the water footprint is comparable\nto the water consumed by an average American family over 5,053 years.\n  We explore strategies to mitigate this impact, primarily by reducing wasted\ncomputational resources. Key recommendations include deploying runners in\nregions whose energy production has a low environmental impact such as France\nand the United Kingdom, implementing stricter deactivation policies for\nscheduled runs and aligning their execution with periods when the regional\nenergy mix is more environmentally favorable, and reducing the size of\nrepositories.", "AI": {"tldr": "GitHub Actions\u7684CI/CD\u670d\u52a1\u4ea7\u751f\u4e86\u663e\u8457\u7684\u78b3\u8db3\u8ff9\u548c\u6c34\u8db3\u8ff9\uff0c2024\u5e74\u78b3\u8db3\u8ff9\u4f30\u8ba1\u5728150.5-994.9 MTCO2e\u4e4b\u95f4\uff0c\u6c34\u8db3\u8ff9\u57281,989.6-37,664.5\u5343\u5347\u4e4b\u95f4\u3002\u6700\u53ef\u80fd\u60c5\u666f\u4e0b\u78b3\u8db3\u8ff9\u4e3a456.9 MTCO2e\uff0c\u6c34\u8db3\u8ff9\u4e3a5,738.2\u5343\u5347\u3002", "motivation": "CI/CD\u7ba1\u9053\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u73af\u5883\u5f71\u54cd\uff08\u7279\u522b\u662f\u78b3\u8db3\u8ff9\u548c\u6c34\u8db3\u8ff9\uff09\u5bf9\u5f00\u53d1\u8005\u6765\u8bf4\u901a\u5e38\u672a\u77e5\uff0c\u56e0\u4e3aCI\u670d\u52a1\u63d0\u4f9b\u5546\u901a\u5e38\u4e0d\u62ab\u9732\u6b64\u7c7b\u4fe1\u606f\u3002\u968f\u7740\u4e91\u8ba1\u7b97\u73af\u5883\u5f71\u54cd\u7684\u589e\u957f\uff0c\u4e86\u89e3CI/CD\u670d\u52a1\u7684CWF\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002", "method": "\u57fa\u4e8eCloud Carbon Footprint\u6846\u67b6\u7684\u65b9\u6cd5\u8bba\uff0c\u4f7f\u7528\u6587\u732e\u4e2d\u6700\u5927\u7684\u5de5\u4f5c\u6d41\u8fd0\u884c\u6570\u636e\u96c6\uff0c\u5305\u542b\u6765\u81ea18,000\u591a\u4e2a\u4ed3\u5e93\u7684220\u591a\u4e07\u4e2a\u5de5\u4f5c\u6d41\u8fd0\u884c\u3002", "result": "GitHub Actions\u751f\u6001\u7cfb\u7edf\u4ea7\u751f\u4e86\u663e\u8457\u7684CWF\u3002\u6700\u53ef\u80fd\u60c5\u666f\u4e0b\u78b3\u8db3\u8ff9\u4e3a456.9 MTCO2e\uff08\u76f8\u5f53\u4e8e7,615\u68f5\u57ce\u5e02\u6811\u6728\u4e00\u5e74\u7684\u78b3\u6355\u83b7\u91cf\uff09\uff0c\u6c34\u8db3\u8ff9\u4e3a5,738.2\u5343\u5347\uff08\u76f8\u5f53\u4e8e\u7f8e\u56fd\u5bb6\u5ead5,053\u5e74\u7684\u7528\u6c34\u91cf\uff09\u3002", "conclusion": "\u63d0\u51fa\u4e86\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u7684\u7f13\u89e3\u7b56\u7565\uff0c\u5305\u62ec\u5728\u6cd5\u56fd\u548c\u82f1\u56fd\u7b49\u73af\u5883\u5f71\u54cd\u4f4e\u7684\u5730\u533a\u90e8\u7f72runner\u3001\u5bf9\u8ba1\u5212\u8fd0\u884c\u5b9e\u65bd\u66f4\u4e25\u683c\u7684\u505c\u7528\u653f\u7b56\u3001\u5728\u533a\u57df\u80fd\u6e90\u7ec4\u5408\u66f4\u73af\u4fdd\u65f6\u6267\u884c\uff0c\u4ee5\u53ca\u51cf\u5c0f\u4ed3\u5e93\u5927\u5c0f\u3002"}}
{"id": "2510.25933", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.25933", "abs": "https://arxiv.org/abs/2510.25933", "authors": ["Nissan Yaron", "Dan Bystritsky", "Ben-Etzion Yaron"], "title": "Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning", "comment": null, "summary": "We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS\nGrounding public subset within a $\\pm 5$ pp equivalence margin.\n  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI\n69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference\nis 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's\n$d = 0.023$). TOST establishes equivalence at $\\pm 5$ pp (not at $\\pm 3$ pp).\nWhen purchased as managed APIs, Humans-Junior's base model\n(Phi-3.5-mini-instruct) is $\\approx 19\\times$ less expensive than GPT-4o on\nMicrosoft AI Foundry pricing; self-hosted or edge deployments can drive\nincremental inference cost toward zero. Measured vs estimated pricing sources\nare tabulated in Appendix E.\n  Method. Our approach combines minimal directed \"Exoskeleton Reasoning\"\nscaffolds with behavioral fine-tuning that teaches protocol compliance\n(epistemic discipline) rather than domain answers. Fine-tuning alone adds\nlittle; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance\n($\\approx 25\\%$). In prompt-only settings on frontier models (Q1--Q100;\nnon-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and\nGemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.\n  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within\n$\\pm 5$ pp on Q1--Q500). Cloud pricing shows $\\approx 19\\times$ lower cost\nversus GPT-4o, and self-hosted/edge deployments can approach zero marginal\ncost. Pricing sources are listed in Appendix E. Frontier prompt-only gains\n(Q1--Q100; non-comparable) and optimized-prompt exploratory results under\nearlier judges are summarized in Appendix F.\n  Keywords: Small Language Models, Factual Grounding, Directed Reasoning,\nFine-Tuning, Model Alignment, Cost-Efficient AI", "AI": {"tldr": "\u4e00\u4e2a38\u4ebf\u53c2\u6570\u7684\u6a21\u578b\u5728FACTS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230GPT-4o\u6c34\u5e73\uff08\u5728\u00b15%\u7b49\u4ef7\u8303\u56f4\u5185\uff09\uff0c\u4e91\u670d\u52a1\u6210\u672c\u964d\u4f4e\u7ea619\u500d\uff0c\u81ea\u6258\u7ba1\u90e8\u7f72\u8fb9\u9645\u6210\u672c\u63a5\u8fd1\u96f6", "motivation": "\u5f00\u53d1\u6210\u672c\u6548\u76ca\u9ad8\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u63a8\u7406\u6210\u672c", "method": "\u7ed3\u5408\u6700\u5c0f\u5316\u5b9a\u5411\"\u5916\u9aa8\u9abc\u63a8\u7406\"\u652f\u67b6\u548c\u884c\u4e3a\u5fae\u8c03\uff0c\u6559\u5bfc\u534f\u8bae\u9075\u5b88\u800c\u975e\u9886\u57df\u77e5\u8bc6\uff0c\u4e24\u8005\u534f\u540c\u4f5c\u7528\u663e\u8457\u63d0\u5347\u6027\u80fd", "result": "\u5728Q1-Q500\u6d4b\u8bd5\u4e2d\uff0cHumans-Junior\u5f97\u520672.7% vs GPT-4o\u768473.5%\uff0c\u5dee\u5f02\u4e0d\u663e\u8457\uff1b\u5728\u63d0\u793a\u8bbe\u7f6e\u4e0b\uff0c\u524d\u6cbf\u6a21\u578b\u6027\u80fd\u63d0\u5347\u660e\u663e", "conclusion": "\u5c0f\u578b\u6a21\u578b\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63a8\u7406\u652f\u67b6\u548c\u5fae\u8c03\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u8fbe\u5230\u524d\u6cbf\u6a21\u578b\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u6210\u672c"}}
{"id": "2510.26102", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26102", "abs": "https://arxiv.org/abs/2510.26102", "authors": ["Lisha Shuai", "Jiuling Dong", "Nan Zhang", "Shaofeng Tan", "Haokun Zhang", "Zilong Song", "Gaoya Dong", "Xiaolong Yang"], "title": "PEEL: A Poisoning-Exposing Encoding Theoretical Framework for Local Differential Privacy", "comment": "14 pages, 1 figures", "summary": "Local Differential Privacy (LDP) is a widely adopted privacy-protection model\nin the Internet of Things (IoT) due to its lightweight, decentralized, and\nscalable nature. However, it is vulnerable to poisoning attacks, and existing\ndefenses either incur prohibitive resource overheads or rely on domain-specific\nprior knowledge, limiting their practical deployment. To address these\nlimitations, we propose PEEL, a Poisoning-Exposing Encoding theoretical\nframework for LDP, which departs from resource- or prior-dependent\ncountermeasures and instead leverages the inherent structural consistency of\nLDP-perturbed data. As a non-intrusive post-processing module, PEEL amplifies\nstealthy poisoning effects by re-encoding LDP-perturbed data via\nsparsification, normalization, and low-rank projection, thereby revealing both\noutput and rule poisoning attacks through structural inconsistencies in the\nreconstructed space. Theoretical analysis proves that PEEL, integrated with\nLDP, retains unbiasedness and statistical accuracy, while being robust to\nexpose both output and rule poisoning attacks. Moreover, evaluation results\nshow that LDP-integrated PEEL not only outperforms four state-of-the-art\ndefenses in terms of poisoning exposure accuracy but also significantly reduces\nclient-side computational costs, making it highly suitable for large-scale IoT\ndeployments.", "AI": {"tldr": "PEEL\u662f\u4e00\u4e2a\u9488\u5bf9\u672c\u5730\u5dee\u5206\u9690\u79c1(LDP)\u7684\u6295\u6bd2\u653b\u51fb\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u65b0\u7f16\u7801LDP\u6270\u52a8\u6570\u636e\u6765\u653e\u5927\u6295\u6bd2\u6548\u5e94\uff0c\u65e0\u9700\u989d\u5916\u8d44\u6e90\u6216\u5148\u9a8c\u77e5\u8bc6\u5373\u53ef\u66b4\u9732\u8f93\u51fa\u548c\u89c4\u5219\u6295\u6bd2\u653b\u51fb\u3002", "motivation": "\u73b0\u6709LDP\u9632\u5fa1\u65b9\u6cd5\u8981\u4e48\u8d44\u6e90\u5f00\u9500\u8fc7\u5927\uff0c\u8981\u4e48\u4f9d\u8d56\u7279\u5b9a\u9886\u57df\u5148\u9a8c\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u5728\u5b9e\u9645\u7269\u8054\u7f51\u90e8\u7f72\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e14\u4e0d\u4f9d\u8d56\u5148\u9a8c\u7684\u9632\u5fa1\u65b9\u6848\u3002", "method": "PEEL\u4f5c\u4e3a\u975e\u4fb5\u5165\u5f0f\u540e\u5904\u7406\u6a21\u5757\uff0c\u901a\u8fc7\u7a00\u758f\u5316\u3001\u5f52\u4e00\u5316\u548c\u4f4e\u79e9\u6295\u5f71\u91cd\u65b0\u7f16\u7801LDP\u6270\u52a8\u6570\u636e\uff0c\u5229\u7528LDP\u6270\u52a8\u6570\u636e\u7684\u7ed3\u6784\u4e00\u81f4\u6027\u6765\u653e\u5927\u6295\u6bd2\u6548\u5e94\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660ePEEL\u4e0eLDP\u96c6\u6210\u540e\u4fdd\u6301\u65e0\u504f\u6027\u548c\u7edf\u8ba1\u51c6\u786e\u6027\uff0c\u540c\u65f6\u80fd\u6709\u6548\u66b4\u9732\u6295\u6bd2\u653b\u51fb\u3002\u8bc4\u4f30\u663e\u793aPEEL\u5728\u6295\u6bd2\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u4f18\u4e8e\u56db\u79cd\u6700\u5148\u8fdb\u9632\u5fa1\u65b9\u6cd5\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u5ba2\u6237\u7aef\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "PEEL\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u8f7b\u91cf\u7ea7\u7684LDP\u6295\u6bd2\u653b\u51fb\u68c0\u6d4b\u6846\u67b6\uff0c\u7279\u522b\u9002\u5408\u5927\u89c4\u6a21\u7269\u8054\u7f51\u90e8\u7f72\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u7684\u540c\u65f6\u6709\u6548\u9632\u5fa1\u6295\u6bd2\u653b\u51fb\u3002"}}
{"id": "2510.26423", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26423", "abs": "https://arxiv.org/abs/2510.26423", "authors": ["Dong Huang", "Mingzhe Du", "Jie M. Zhang", "Zheng Lin", "Meng Luo", "Qianru Zhang", "See-Kiong Ng"], "title": "Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis", "comment": "Under Review", "summary": "Test oracle generation in non-regression testing is a longstanding challenge\nin software engineering, where the goal is to produce oracles that can\naccurately determine whether a function under test (FUT) behaves as intended\nfor a given input. In this paper, we introduce Nexus, a novel multi-agent\nframework to address this challenge. Nexus generates test oracles by leveraging\na diverse set of specialized agents that synthesize test oracles through a\nstructured process of deliberation, validation, and iterative self-refinement.\nDuring the deliberation phase, a panel of four specialist agents, each\nembodying a distinct testing philosophy, collaboratively critiques and refines\nan initial set of test oracles. Then, in the validation phase, Nexus generates\na plausible candidate implementation of the FUT and executes the proposed\noracles against it in a secure sandbox. For any oracle that fails this\nexecution-based check, Nexus activates an automated selfrefinement loop, using\nthe specific runtime error to debug and correct the oracle before\nre-validation. Our extensive evaluation on seven diverse benchmarks\ndemonstrates that Nexus consistently and substantially outperforms\nstate-of-theart baselines. For instance, Nexus improves the test-level oracle\naccuracy on the LiveCodeBench from 46.30% to 57.73% for GPT-4.1-Mini. The\nimproved accuracy also significantly enhances downstream tasks: the bug\ndetection rate of GPT4.1-Mini generated test oracles on HumanEval increases\nfrom 90.91% to 95.45% for Nexus compared to baselines, and the success rate of\nautomated program repair improves from 35.23% to 69.32%.", "AI": {"tldr": "Nexus\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u4e1a\u667a\u80fd\u4f53\u7684\u534f\u4f5c\u5ba1\u8bae\u3001\u9a8c\u8bc1\u548c\u8fed\u4ee3\u81ea\u4f18\u5316\u6765\u751f\u6210\u6d4b\u8bd5\u9884\u8a00\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u975e\u56de\u5f52\u6d4b\u8bd5\u4e2d\u6d4b\u8bd5\u9884\u8a00\u751f\u6210\u7684\u957f\u671f\u6311\u6218\uff0c\u76ee\u6807\u662f\u751f\u6210\u80fd\u591f\u51c6\u786e\u5224\u65ad\u88ab\u6d4b\u51fd\u6570\u662f\u5426\u6309\u9884\u671f\u8fd0\u884c\u7684\u9884\u8a00\u3002", "method": "\u4f7f\u7528\u56db\u4e2a\u4f53\u73b0\u4e0d\u540c\u6d4b\u8bd5\u7406\u5ff5\u7684\u4e13\u4e1a\u667a\u80fd\u4f53\u8fdb\u884c\u534f\u4f5c\u5ba1\u8bae\u548c\u4f18\u5316\uff0c\u751f\u6210\u5019\u9009\u51fd\u6570\u5b9e\u73b0\u5e76\u5728\u5b89\u5168\u6c99\u7bb1\u4e2d\u6267\u884c\u9a8c\u8bc1\uff0c\u5bf9\u5931\u8d25\u7684\u9884\u8a00\u8fdb\u884c\u81ea\u52a8\u8c03\u8bd5\u548c\u4fee\u6b63\u7684\u8fed\u4ee3\u81ea\u4f18\u5316\u5faa\u73af\u3002", "result": "\u5728\u4e03\u4e2a\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5c06LiveCodeBench\u7684\u6d4b\u8bd5\u7ea7\u9884\u8a00\u51c6\u786e\u7387\u4ece46.30%\u63d0\u5347\u523057.73%\uff0cHumanEval\u7684\u9519\u8bef\u68c0\u6d4b\u7387\u4ece90.91%\u63d0\u5347\u523095.45%\uff0c\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u6210\u529f\u7387\u4ece35.23%\u63d0\u5347\u523069.32%\u3002", "conclusion": "Nexus\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u8fed\u4ee3\u81ea\u4f18\u5316\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u9884\u8a00\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2510.25951", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25951", "abs": "https://arxiv.org/abs/2510.25951", "authors": ["Sounak Banerjee", "Daphne Cornelisse", "Deepak Gopinath", "Emily Sumner", "Jonathan DeCastro", "Guy Rosman", "Eugene Vinitsky", "Mark K. Ho"], "title": "Estimating cognitive biases with attention-aware inverse planning", "comment": null, "summary": "People's goal-directed behaviors are influenced by their cognitive biases,\nand autonomous systems that interact with people should be aware of this. For\nexample, people's attention to objects in their environment will be biased in a\nway that systematically affects how they perform everyday tasks such as driving\nto work. Here, building on recent work in computational cognitive science, we\nformally articulate the attention-aware inverse planning problem, in which the\ngoal is to estimate a person's attentional biases from their actions. We\ndemonstrate how attention-aware inverse planning systematically differs from\nstandard inverse reinforcement learning and how cognitive biases can be\ninferred from behavior. Finally, we present an approach to attention-aware\ninverse planning that combines deep reinforcement learning with computational\ncognitive modeling. We use this approach to infer the attentional strategies of\nRL agents in real-life driving scenarios selected from the Waymo Open Dataset,\ndemonstrating the scalability of estimating cognitive biases with\nattention-aware inverse planning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u95ee\u9898\uff0c\u65e8\u5728\u4ece\u4eba\u7c7b\u884c\u4e3a\u4e2d\u63a8\u65ad\u8ba4\u77e5\u504f\u89c1\uff0c\u7279\u522b\u662f\u6ce8\u610f\u529b\u504f\u89c1\u3002\u901a\u8fc7\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u548c\u8ba1\u7b97\u8ba4\u77e5\u5efa\u6a21\uff0c\u5728\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4eba\u7c7b\u7684\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\u53d7\u5230\u8ba4\u77e5\u504f\u89c1\u5f71\u54cd\uff0c\u4e0e\u4eba\u7c7b\u4ea4\u4e92\u7684\u81ea\u4e3b\u7cfb\u7edf\u9700\u8981\u610f\u8bc6\u5230\u8fd9\u4e00\u70b9\u3002\u7279\u522b\u662f\u5728\u65e5\u5e38\u4efb\u52a1\u5982\u9a7e\u9a76\u4e2d\uff0c\u4eba\u4eec\u5bf9\u73af\u5883\u7269\u4f53\u7684\u6ce8\u610f\u529b\u504f\u89c1\u4f1a\u7cfb\u7edf\u6027\u5730\u5f71\u54cd\u884c\u4e3a\u8868\u73b0\u3002", "method": "\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e0e\u8ba1\u7b97\u8ba4\u77e5\u5efa\u6a21\uff0c\u63d0\u51fa\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u65b9\u6cd5\uff0c\u4ece\u884c\u4e3a\u4e2d\u63a8\u65ad\u6ce8\u610f\u529b\u7b56\u7565\u3002\u5728Waymo\u5f00\u653e\u6570\u636e\u96c6\u4e2d\u7684\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5c55\u793a\u4e86\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u4e0e\u6807\u51c6\u9006\u5f3a\u5316\u5b66\u4e60\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u8bc1\u660e\u4e86\u4ece\u884c\u4e3a\u4e2d\u63a8\u65ad\u8ba4\u77e5\u504f\u89c1\u7684\u53ef\u884c\u6027\u3002\u5728\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\u6210\u529f\u63a8\u65adRL\u667a\u80fd\u4f53\u7684\u6ce8\u610f\u529b\u7b56\u7565\u3002", "conclusion": "\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4f30\u8ba1\u8ba4\u77e5\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u73b0\u5b9e\u573a\u666f\u4e2d\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u7406\u89e3\u4eba\u7c7b\u884c\u4e3a\u4e2d\u7684\u8ba4\u77e5\u504f\u89c1\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.26103", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26103", "abs": "https://arxiv.org/abs/2510.26103", "authors": ["Maximilian Schreiber", "Pascal Tippe"], "title": "Security Vulnerabilities in AI-Generated Code: A Large-Scale Analysis of Public GitHub Repositories", "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Volume 16219 of the Lecture Notes in Computer Science series,\n  and is available online at https://doi.org/10.1007/978-981-95-3537-8_9", "summary": "This paper presents a comprehensive empirical analysis of security\nvulnerabilities in AI-generated code across public GitHub repositories. We\ncollected and analyzed 7,703 files explicitly attributed to four major AI\ntools: ChatGPT (91.52\\%), GitHub Copilot (7.50\\%), Amazon CodeWhisperer\n(0.52\\%), and Tabnine (0.46\\%). Using CodeQL static analysis, we identified\n4,241 Common Weakness Enumeration (CWE) instances across 77 distinct\nvulnerability types. Our findings reveal that while 87.9\\% of AI-generated code\ndoes not contain identifiable CWE-mapped vulnerabilities, significant patterns\nemerge regarding language-specific vulnerabilities and tool performance. Python\nconsistently exhibited higher vulnerability rates (16.18\\%-18.50\\%) compared to\nJavaScript (8.66\\%-8.99\\%) and TypeScript (2.50\\%-7.14\\%) across all tools. We\nobserved notable differences in security performance, with GitHub Copilot\nachieving better security density for Python (1,739 LOC per CWE) and\nTypeScript, while ChatGPT performed better for JavaScript. Additionally, we\ndiscovered widespread use of AI tools for documentation generation (39\\% of\ncollected files), an understudied application with implications for software\nmaintainability. These findings extend previous work with a significantly\nlarger dataset and provide valuable insights for developing language-specific\nand context-aware security practices for the responsible integration of\nAI-generated code into software development workflows.", "AI": {"tldr": "\u5bf9GitHub\u4e0aAI\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6f0f\u6d1e\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b087.9%\u7684\u4ee3\u7801\u6ca1\u6709\u53ef\u8bc6\u522b\u6f0f\u6d1e\uff0c\u4f46Python\u6bd4\u5176\u4ed6\u8bed\u8a00\u66f4\u5bb9\u6613\u51fa\u73b0\u6f0f\u6d1e\uff0c\u4e14\u4e0d\u540cAI\u5de5\u5177\u5728\u4e0d\u540c\u8bed\u8a00\u4e0a\u7684\u5b89\u5168\u6027\u80fd\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7801\u751f\u6210\u5de5\u5177\u7684\u666e\u53ca\uff0c\u9700\u8981\u4e86\u89e3\u8fd9\u4e9b\u5de5\u5177\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u72b6\u51b5\uff0c\u4e3a\u8d1f\u8d23\u4efb\u5730\u96c6\u6210AI\u751f\u6210\u4ee3\u7801\u5230\u5f00\u53d1\u6d41\u7a0b\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u6536\u96c6GitHub\u4e0a7,703\u4e2a\u660e\u786e\u6807\u6ce8\u4e3aAI\u751f\u6210\u7684\u4ee3\u7801\u6587\u4ef6\uff0c\u4f7f\u7528CodeQL\u9759\u6001\u5206\u6790\u5de5\u5177\u8bc6\u522b4,241\u4e2aCWE\u6f0f\u6d1e\u5b9e\u4f8b\uff0c\u6db5\u76d677\u79cd\u6f0f\u6d1e\u7c7b\u578b\u3002", "result": "Python\u7684\u6f0f\u6d1e\u7387(16.18%-18.50%)\u663e\u8457\u9ad8\u4e8eJavaScript(8.66%-8.99%)\u548cTypeScript(2.50%-7.14%)\uff1bGitHub Copilot\u5728Python\u548cTypeScript\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u800cChatGPT\u5728JavaScript\u4e0a\u66f4\u4f18\uff1b39%\u7684\u6587\u4ef6\u7528\u4e8e\u6587\u6863\u751f\u6210\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8bed\u8a00\u7279\u5b9a\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5b89\u5168\u5b9e\u8df5\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u8d1f\u8d23\u4efb\u5730\u5c06AI\u751f\u6210\u4ee3\u7801\u96c6\u6210\u5230\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\u3002"}}
{"id": "2510.26431", "categories": ["cs.SE", "cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.26431", "abs": "https://arxiv.org/abs/2510.26431", "authors": ["Mih\u00e1ly Dobos-Kov\u00e1cs", "Levente Bajczi", "Andr\u00e1s V\u00f6r\u00f6s"], "title": "CHCVerif: A Portfolio-Based Solver for Constrained Horn Clauses", "comment": "In Proceedings HCVS 2025, arXiv:2510.25468", "summary": "Constrained Horn Clauses (CHCs) are widely adopted as intermediate\nrepresentations for a variety of verification tasks, including safety checking,\ninvariant synthesis, and interprocedural analysis. This paper introduces\nCHCVERIF, a portfolio-based CHC solver that adopts a software verification\napproach for solving CHCs. This approach enables us to reuse mature software\nverification tools to tackle CHC benchmarks, particularly those involving\nbitvectors and low-level semantics. Our evaluation shows that while the method\nenjoys only moderate success with linear integer arithmetic, it achieves modest\nsuccess on bitvector benchmarks. Moreover, our results demonstrate the\nviability and potential of using software verification tools as backends for\nCHC solving, particularly when supported by a carefully constructed portfolio.", "AI": {"tldr": "CHCVERIF\u662f\u4e00\u4e2a\u57fa\u4e8e\u7ec4\u5408\u7b56\u7565\u7684CHC\u6c42\u89e3\u5668\uff0c\u91c7\u7528\u8f6f\u4ef6\u9a8c\u8bc1\u65b9\u6cd5\u6765\u89e3\u51b3\u7ea6\u675fHorn\u5b50\u53e5\u95ee\u9898\uff0c\u80fd\u591f\u91cd\u7528\u6210\u719f\u7684\u8f6f\u4ef6\u9a8c\u8bc1\u5de5\u5177\u5904\u7406\u6d89\u53ca\u4f4d\u5411\u91cf\u548c\u4f4e\u7ea7\u8bed\u4e49\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u7ea6\u675fHorn\u5b50\u53e5\uff08CHCs\uff09\u88ab\u5e7f\u6cdb\u7528\u4f5c\u5404\u79cd\u9a8c\u8bc1\u4efb\u52a1\u7684\u4e2d\u95f4\u8868\u793a\uff0c\u5305\u62ec\u5b89\u5168\u68c0\u67e5\u3001\u4e0d\u53d8\u5f0f\u7efc\u5408\u548c\u8fc7\u7a0b\u95f4\u5206\u6790\u3002\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u6d89\u53ca\u4f4d\u5411\u91cf\u548c\u4f4e\u7ea7\u8bed\u4e49\u7684CHC\u57fa\u51c6\u6d4b\u8bd5\u65f6\u5b58\u5728\u6311\u6218\u3002", "method": "\u63d0\u51faCHCVERIF\uff0c\u4e00\u4e2a\u57fa\u4e8e\u7ec4\u5408\u7b56\u7565\u7684CHC\u6c42\u89e3\u5668\uff0c\u91c7\u7528\u8f6f\u4ef6\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u91cd\u7528\u6210\u719f\u7684\u8f6f\u4ef6\u9a8c\u8bc1\u5de5\u5177\u6765\u89e3\u51b3CHC\u95ee\u9898\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u6d89\u53ca\u4f4d\u5411\u91cf\u548c\u4f4e\u7ea7\u8bed\u4e49\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u7ebf\u6027\u6574\u6570\u7b97\u672f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4e2d\u7b49\uff0c\u5728\u4f4d\u5411\u91cf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u9002\u5ea6\u6210\u529f\u3002\u7ed3\u679c\u8bc1\u660e\u4e86\u4f7f\u7528\u8f6f\u4ef6\u9a8c\u8bc1\u5de5\u5177\u4f5c\u4e3aCHC\u6c42\u89e3\u540e\u7aef\u7684\u53ef\u884c\u6027\u548c\u6f5c\u529b\u3002", "conclusion": "\u4f7f\u7528\u8f6f\u4ef6\u9a8c\u8bc1\u5de5\u5177\u4f5c\u4e3aCHC\u6c42\u89e3\u540e\u7aef\u662f\u53ef\u884c\u4e14\u6709\u6f5c\u529b\u7684\uff0c\u7279\u522b\u662f\u5728\u7cbe\u5fc3\u6784\u5efa\u7684\u7ec4\u5408\u7b56\u7565\u652f\u6301\u4e0b\u3002\u8be5\u65b9\u6cd5\u4e3a\u5904\u7406\u6d89\u53ca\u4f4d\u5411\u91cf\u548c\u4f4e\u7ea7\u8bed\u4e49\u7684CHC\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25997", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25997", "abs": "https://arxiv.org/abs/2510.25997", "authors": ["Manu Redd", "Tao Zhe", "Dongjie Wang"], "title": "From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL", "comment": "8 pages, 5 figures, GeoGenAgent'25 - ACM SIGSPATIAL", "summary": "Natural-language-to-SQL (NL-to-SQL) systems hold promise for democratizing\naccess to structured data, allowing users to query databases without learning\nSQL. Yet existing systems struggle with realistic spatio-temporal queries,\nwhere success requires aligning vague user phrasing with schema-specific\ncategories, handling temporal reasoning, and choosing appropriate outputs. We\npresent an agentic pipeline that extends a naive text-to-SQL baseline\n(llama-3-sqlcoder-8b) with orchestration by a Mistral-based ReAct agent. The\nagent can plan, decompose, and adapt queries through schema inspection, SQL\ngeneration, execution, and visualization tools. We evaluate on 35\nnatural-language queries over the NYC and Tokyo check-in dataset, covering\nspatial, temporal, and multi-dataset reasoning. The agent achieves\nsubstantially higher accuracy than the naive baseline 91.4% vs. 28.6% and\nenhances usability through maps, plots, and structured natural-language\nsummaries. Crucially, our design enables more natural human-database\ninteraction, supporting users who lack SQL expertise, detailed schema\nknowledge, or prompting skill. We conclude that agentic orchestration, rather\nthan stronger SQL generators alone, is a promising foundation for interactive\ngeospatial assistants.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7406\u7684NL-to-SQL\u7cfb\u7edf\uff0c\u901a\u8fc7ReAct\u4ee3\u7406\u534f\u8c03\u591a\u4e2a\u5de5\u5177\u6765\u5904\u7406\u590d\u6742\u7684\u65f6\u7a7a\u67e5\u8be2\uff0c\u76f8\u6bd4\u5355\u7eaf\u7684\u6587\u672c\u5230SQL\u6a21\u578b\uff0c\u51c6\u786e\u7387\u4ece28.6%\u63d0\u5347\u523091.4%\u3002", "motivation": "\u73b0\u6709\u7684NL-to-SQL\u7cfb\u7edf\u5728\u5904\u7406\u73b0\u5b9e\u65f6\u7a7a\u67e5\u8be2\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u89e3\u51b3\u7528\u6237\u6a21\u7cca\u8868\u8fbe\u4e0e\u6570\u636e\u5e93\u6a21\u5f0f\u5bf9\u9f50\u3001\u65f6\u95f4\u63a8\u7406\u548c\u8f93\u51fa\u9009\u62e9\u7b49\u95ee\u9898\uff0c\u4ee5\u652f\u6301\u975eSQL\u4e13\u5bb6\u7684\u7528\u6237\u8bbf\u95ee\u7ed3\u6784\u5316\u6570\u636e\u3002", "method": "\u6269\u5c55\u4e86\u57fa\u7840\u7684\u6587\u672c\u5230SQL\u6a21\u578b(llama-3-sqlcoder-8b)\uff0c\u4f7f\u7528\u57fa\u4e8eMistral\u7684ReAct\u4ee3\u7406\u8fdb\u884c\u534f\u8c03\uff0c\u4ee3\u7406\u80fd\u591f\u901a\u8fc7\u6a21\u5f0f\u68c0\u67e5\u3001SQL\u751f\u6210\u3001\u6267\u884c\u548c\u53ef\u89c6\u5316\u5de5\u5177\u6765\u89c4\u5212\u3001\u5206\u89e3\u548c\u8c03\u6574\u67e5\u8be2\u3002", "result": "\u5728NYC\u548cTokyo\u7b7e\u5230\u6570\u636e\u96c6\u768435\u4e2a\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e0a\u8bc4\u4f30\uff0c\u4ee3\u7406\u7cfb\u7edf\u51c6\u786e\u7387\u8fbe\u523091.4%\uff0c\u663e\u8457\u4f18\u4e8e28.6%\u7684\u57fa\u7ebf\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u5730\u56fe\u3001\u56fe\u8868\u548c\u7ed3\u6784\u5316\u81ea\u7136\u8bed\u8a00\u6458\u8981\u63d0\u5347\u4e86\u53ef\u7528\u6027\u3002", "conclusion": "\u4ee3\u7406\u534f\u8c03\u800c\u975e\u4ec5\u4f9d\u8d56\u66f4\u5f3a\u7684SQL\u751f\u6210\u5668\uff0c\u662f\u6784\u5efa\u4ea4\u4e92\u5f0f\u5730\u7406\u7a7a\u95f4\u52a9\u624b\u7684\u6709\u524d\u666f\u7684\u57fa\u7840\uff0c\u80fd\u591f\u652f\u6301\u7f3a\u4e4fSQL\u4e13\u4e1a\u77e5\u8bc6\u3001\u8be6\u7ec6\u6a21\u5f0f\u77e5\u8bc6\u6216\u63d0\u793a\u6280\u80fd\u7684\u7528\u6237\u8fdb\u884c\u66f4\u81ea\u7136\u7684\u4eba\u673a\u6570\u636e\u5e93\u4ea4\u4e92\u3002"}}
{"id": "2510.26179", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.26179", "abs": "https://arxiv.org/abs/2510.26179", "authors": ["Haruki Hoshino", "Jungjin Park", "Osamu Kaneko", "Kiminao Kogiso"], "title": "Confidential FRIT via Homomorphic Encryption", "comment": null, "summary": "Edge computing alleviates the computation burden of data-driven control in\ncyber-physical systems (CPSs) by offloading complex processing to edge servers.\nHowever, the increasing sophistication of cyberattacks underscores the need for\nsecurity measures that go beyond conventional IT protections and address the\nunique vulnerabilities of CPSs. This study proposes a confidential data-driven\ngain-tuning framework using homomorphic encryption, such as ElGamal and CKKS\nencryption schemes, to enhance cybersecurity in gain-tuning processes\noutsourced to external servers. The idea for realizing confidential FRIT is to\nreplace the matrix inversion operation with a vector summation form, allowing\nhomomorphic operations to be applied. Numerical examples under 128-bit security\nconfirm performance comparable to conventional methods while providing\nguidelines for selecting suitable encryption schemes for secure CPS.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u540c\u6001\u52a0\u5bc6\u7684\u4fdd\u5bc6\u6570\u636e\u9a71\u52a8\u589e\u76ca\u8c03\u8c10\u6846\u67b6\uff0c\u7528\u4e8e\u4fdd\u62a4\u5916\u5305\u5230\u8fb9\u7f18\u670d\u52a1\u5668\u7684CPS\u589e\u76ca\u8c03\u8c10\u8fc7\u7a0b\u5b89\u5168\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u867d\u7136\u51cf\u8f7b\u4e86CPS\u6570\u636e\u9a71\u52a8\u63a7\u5236\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u4f46\u65e5\u76ca\u590d\u6742\u7684\u7f51\u7edc\u653b\u51fb\u9700\u8981\u8d85\u8d8a\u4f20\u7edfIT\u4fdd\u62a4\u7684\u5b89\u5168\u63aa\u65bd\uff0c\u4ee5\u89e3\u51b3CPS\u7279\u6709\u7684\u6f0f\u6d1e\u3002", "method": "\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\u65b9\u6848\uff08\u5982ElGamal\u548cCKKS\uff09\uff0c\u5c06\u77e9\u9635\u6c42\u9006\u64cd\u4f5c\u66ff\u6362\u4e3a\u5411\u91cf\u6c42\u548c\u5f62\u5f0f\uff0c\u4f7f\u540c\u6001\u64cd\u4f5c\u5f97\u4ee5\u5e94\u7528\uff0c\u5b9e\u73b0\u4fdd\u5bc6FRIT\u3002", "result": "\u5728128\u4f4d\u5b89\u5168\u7ea7\u522b\u4e0b\u7684\u6570\u503c\u793a\u4f8b\u663e\u793a\uff0c\u6027\u80fd\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u4e3a\u5b89\u5168CPS\u9009\u62e9\u5408\u9002\u7684\u52a0\u5bc6\u65b9\u6848\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u589e\u5f3a\u4e86CPS\u589e\u76ca\u8c03\u8c10\u8fc7\u7a0b\u7684\u7f51\u7edc\u5b89\u5168\uff0c\u4e3a\u5b89\u5168CPS\u7684\u52a0\u5bc6\u65b9\u6848\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\u3002"}}
{"id": "2510.26457", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26457", "abs": "https://arxiv.org/abs/2510.26457", "authors": ["Fang Liu", "Simiao Liu", "Yinghao Zhu", "Xiaoli Lian", "Li Zhang"], "title": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "comment": "Accepted by ICSE 2026. Code and data:\n  https://github.com/SIMIAO515/SecureReviewer", "summary": "Identifying and addressing security issues during the early phase of the\ndevelopment lifecycle is critical for mitigating the long-term negative impacts\non software systems. Code review serves as an effective practice that enables\ndevelopers to check their teammates' code before integration into the codebase.\nTo streamline the generation of review comments, various automated code review\napproaches have been proposed, where LLM-based methods have significantly\nadvanced the capabilities of automated review generation. However, existing\nmodels primarily focus on general-purpose code review, their effectiveness in\nidentifying and addressing security-related issues remains underexplored.\nMoreover, adapting existing code review approaches to target security issues\nfaces substantial challenges, including data scarcity and inadequate evaluation\nmetrics. To address these limitations, we propose SecureReviewer, a new\napproach designed for enhancing LLMs' ability to identify and resolve\nsecurity-related issues during code review. Specifically, we first construct a\ndataset tailored for training and evaluating secure code review capabilities.\nLeveraging this dataset, we fine-tune LLMs to generate code review comments\nthat can effectively identify security issues and provide fix suggestions with\nour proposed secure-aware fine-tuning strategy. To mitigate hallucination in\nLLMs and enhance the reliability of their outputs, we integrate the RAG\ntechnique, which grounds the generated comments in domain-specific security\nknowledge. Additionally, we introduce SecureBLEU, a new evaluation metric\ndesigned to assess the effectiveness of review comments in addressing security\nissues. Experimental results demonstrate that SecureReviewer outperforms\nstate-of-the-art baselines in both security issue detection accuracy and the\noverall quality and practical utility of generated review comments.", "AI": {"tldr": "SecureReviewer\u662f\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u589e\u5f3aLLM\u5728\u4ee3\u7801\u5ba1\u67e5\u4e2d\u8bc6\u522b\u548c\u89e3\u51b3\u5b89\u5168\u95ee\u9898\u7684\u80fd\u529b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u4e13\u95e8\u7684\u6570\u636e\u96c6\u3001\u5b89\u5168\u611f\u77e5\u5fae\u8c03\u7b56\u7565\u3001RAG\u6280\u672f\u548c\u65b0\u7684\u8bc4\u4f30\u6307\u6807SecureBLEU\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u76ee\u7684\u4ee3\u7801\u5ba1\u67e5\uff0c\u5728\u8bc6\u522b\u548c\u89e3\u51b3\u5b89\u5168\u76f8\u5173\u95ee\u9898\u65b9\u9762\u6548\u679c\u4e0d\u8db3\uff0c\u4e14\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u548c\u8bc4\u4f30\u6307\u6807\u4e0d\u5145\u5206\u7b49\u6311\u6218\u3002", "method": "\u6784\u5efa\u4e13\u95e8\u7684\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u6570\u636e\u96c6\uff0c\u91c7\u7528\u5b89\u5168\u611f\u77e5\u5fae\u8c03\u7b56\u7565\u8bad\u7ec3LLM\uff0c\u96c6\u6210RAG\u6280\u672f\u51cf\u5c11\u5e7b\u89c9\u5e76\u589e\u5f3a\u8f93\u51fa\u53ef\u9760\u6027\uff0c\u5f15\u5165SecureBLEU\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eSecureReviewer\u5728\u5b89\u5168\u6f0f\u6d1e\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u751f\u6210\u5ba1\u67e5\u8bc4\u8bba\u7684\u6574\u4f53\u8d28\u91cf\u53ca\u5b9e\u7528\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SecureReviewer\u901a\u8fc7\u4e13\u95e8\u7684\u6570\u636e\u96c6\u3001\u5fae\u8c03\u7b56\u7565\u3001RAG\u6280\u672f\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u80fd\u529b\uff0c\u4e3a\u8f6f\u4ef6\u5b89\u5168\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2510.26012", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26012", "abs": "https://arxiv.org/abs/2510.26012", "authors": ["Siyi Wu", "Chiaxin Liang", "Ziqian Bi", "Leyi Zhao", "Tianyang Wang", "Junhao Song", "Yichao Zhang", "Keyu Chen", "Xinyuan Song"], "title": "AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys", "comment": "TKDD 2025", "summary": "The rapid growth of research literature, particularly in large language\nmodels (LLMs), has made producing comprehensive and current survey papers\nincreasingly difficult. This paper introduces autosurvey2, a multi-stage\npipeline that automates survey generation through retrieval-augmented synthesis\nand structured evaluation. The system integrates parallel section generation,\niterative refinement, and real-time retrieval of recent publications to ensure\nboth topical completeness and factual accuracy. Quality is assessed using a\nmulti-LLM evaluation framework that measures coverage, structure, and relevance\nin alignment with expert review standards. Experimental results demonstrate\nthat autosurvey2 consistently outperforms existing retrieval-based and\nautomated baselines, achieving higher scores in structural coherence and\ntopical relevance while maintaining strong citation fidelity. By combining\nretrieval, reasoning, and automated evaluation into a unified framework,\nautosurvey2 provides a scalable and reproducible solution for generating\nlong-form academic surveys and contributes a solid foundation for future\nresearch on automated scholarly writing. All code and resources are available\nat https://github.com/annihi1ation/auto_research.", "AI": {"tldr": "autosurvey2\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u751f\u6210\u5b66\u672f\u7efc\u8ff0\u7684\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\u7cfb\u7edf\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u5408\u6210\u548c\u7ed3\u6784\u5316\u8bc4\u4f30\uff0c\u7ed3\u5408\u5e76\u884c\u7ae0\u8282\u751f\u6210\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u5b9e\u65f6\u6587\u732e\u68c0\u7d22\uff0c\u786e\u4fdd\u4e3b\u9898\u5b8c\u6574\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u7814\u7a76\u6587\u732e\u7684\u5feb\u901f\u589e\u957f\uff0c\u7279\u522b\u662f\u5728\u5927\u8bed\u8a00\u6a21\u578b\u9886\u57df\uff0c\u64b0\u5199\u5168\u9762\u4e14\u6700\u65b0\u7684\u7efc\u8ff0\u8bba\u6587\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\uff0c\u5305\u62ec\u68c0\u7d22\u589e\u5f3a\u5408\u6210\u3001\u5e76\u884c\u7ae0\u8282\u751f\u6210\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u5b9e\u65f6\u6587\u732e\u68c0\u7d22\uff0c\u5e76\u4f7f\u7528\u591aLLM\u8bc4\u4f30\u6846\u67b6\u6765\u8bc4\u4f30\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eautosurvey2\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u7684\u68c0\u7d22\u57fa\u7ebf\u548c\u81ea\u52a8\u5316\u57fa\u7ebf\uff0c\u5728\u7ed3\u6784\u8fde\u8d2f\u6027\u548c\u4e3b\u9898\u76f8\u5173\u6027\u65b9\u9762\u83b7\u5f97\u66f4\u9ad8\u5206\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5f15\u7528\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u5c06\u68c0\u7d22\u3001\u63a8\u7406\u548c\u81ea\u52a8\u8bc4\u4f30\u6574\u5408\u5230\u7edf\u4e00\u6846\u67b6\u4e2d\uff0cautosurvey2\u4e3a\u751f\u6210\u957f\u7bc7\u5b66\u672f\u7efc\u8ff0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u590d\u73b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u81ea\u52a8\u5316\u5b66\u672f\u5199\u4f5c\u7684\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2510.26210", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26210", "abs": "https://arxiv.org/abs/2510.26210", "authors": ["Junlin Liu", "Zhaomeng Deng", "Ziming Wang", "Mengyu Yao", "Yifeng Cai", "Yutao Hu", "Ziqi Zhang", "Yao Guo", "Ding Li"], "title": "Who Moved My Transaction? Uncovering Post-Transaction Auditability Vulnerabilities in Modern Super Apps", "comment": "SaTS 2025 (Co-Located with ACM CCS 2025)", "summary": "Super apps are the cornerstones of modern digital life, embedding financial\ntransactions into nearly every aspect of daily routine. The prevailing security\nparadigm for these platforms is overwhelmingly focused on pre-transaction\nauthentication, preventing unauthorized payments before they occur. We argue\nthat a critical vulnerability vector has been largely overlooked: the fragility\nof post-transaction audit trails. We investigate the ease with which a user can\npermanently erase their transaction history from an app's interface, thereby\nconcealing unauthorized or sensitive activities from the account owner. To\nquantify this threat, we conducted an empirical study with 6 volunteers who\nperformed a cross-evaluation on six super apps. Our findings are alarming: all\nsix applications studied allow users to delete transaction records, yet a\nstaggering five out of six (83+\\%) fail to protect these records with strong\nauthentication. Only one app in our study required biometric verification for\ndeletion. This study provides the first concrete evidence of this\nnear-ubiquitous vulnerability, demonstrating a critical gap in the current\nmobile security landscape and underscoring the urgent need for a paradigm shift\ntowards ensuring post-transaction audit integrity.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8d85\u7ea7\u5e94\u7528\u666e\u904d\u5b58\u5728\u4ea4\u6613\u8bb0\u5f55\u5220\u9664\u6f0f\u6d1e\uff0c83%\u7684\u5e94\u7528\u7f3a\u4e4f\u5f3a\u8ba4\u8bc1\u4fdd\u62a4\uff0c\u5141\u8bb8\u7528\u6237\u6c38\u4e45\u5220\u9664\u4ea4\u6613\u5386\u53f2\uff0c\u5a01\u80c1\u5ba1\u8ba1\u5b8c\u6574\u6027\u3002", "motivation": "\u5f53\u524d\u8d85\u7ea7\u5e94\u7528\u5b89\u5168\u8303\u5f0f\u8fc7\u5ea6\u5173\u6ce8\u4ea4\u6613\u524d\u8ba4\u8bc1\uff0c\u5ffd\u89c6\u4e86\u4ea4\u6613\u540e\u5ba1\u8ba1\u8f68\u8ff9\u7684\u8106\u5f31\u6027\uff0c\u7528\u6237\u53ef\u8f7b\u6613\u5220\u9664\u4ea4\u6613\u8bb0\u5f55\u6765\u9690\u85cf\u672a\u6388\u6743\u6216\u654f\u611f\u6d3b\u52a8\u3002", "method": "\u901a\u8fc76\u540d\u5fd7\u613f\u8005\u5bf96\u4e2a\u8d85\u7ea7\u5e94\u7528\u8fdb\u884c\u4ea4\u53c9\u8bc4\u4f30\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u4ea4\u6613\u8bb0\u5f55\u5220\u9664\u529f\u80fd\u7684\u5b89\u5168\u6027\u3002", "result": "\u6240\u67096\u4e2a\u5e94\u7528\u90fd\u5141\u8bb8\u5220\u9664\u4ea4\u6613\u8bb0\u5f55\uff0c\u4f46\u5176\u4e2d5\u4e2a(83%)\u7f3a\u4e4f\u5f3a\u8ba4\u8bc1\u4fdd\u62a4\uff0c\u4ec51\u4e2a\u5e94\u7528\u8981\u6c42\u751f\u7269\u8bc6\u522b\u9a8c\u8bc1\u3002", "conclusion": "\u8fd9\u63ed\u793a\u4e86\u79fb\u52a8\u5b89\u5168\u9886\u57df\u7684\u5173\u952e\u6f0f\u6d1e\uff0c\u8feb\u5207\u9700\u8981\u8f6c\u5411\u786e\u4fdd\u4ea4\u6613\u540e\u5ba1\u8ba1\u5b8c\u6574\u6027\u7684\u65b0\u5b89\u5168\u8303\u5f0f\u3002"}}
{"id": "2510.26480", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26480", "abs": "https://arxiv.org/abs/2510.26480", "authors": ["Sivajeet Chand", "Melih Kilic", "Roland W\u00fcrsching", "Sushant Kumar Pandey", "Alexander Pretschner"], "title": "Automated Extract Method Refactoring with Open-Source LLMs: A Comparative Study", "comment": "Accepted at AIware'25 - Main Track", "summary": "Automating the Extract Method refactoring (EMR) remains challenging and\nlargely manual despite its importance in improving code readability and\nmaintainability. Recent advances in open-source, resource-efficient Large\nLanguage Models (LLMs) offer promising new approaches for automating such\nhigh-level tasks. In this work, we critically evaluate five state-of-the-art\nopen-source LLMs, spanning 3B to 8B parameter sizes, on the EMR task for Python\ncode. We systematically assess functional correctness and code quality using\nautomated metrics and investigate the impact of prompting strategies by\ncomparing one-shot prompting to a Recursive criticism and improvement (RCI)\napproach. RCI-based prompting consistently outperforms one-shot prompting in\ntest pass rates and refactoring quality. The best-performing models,\nDeepseek-Coder-RCI and Qwen2.5-Coder-RCI, achieve test pass percentage (TPP)\nscores of 0.829 and 0.808, while reducing lines of code (LOC) per method from\n12.103 to 6.192 and 5.577, and cyclomatic complexity (CC) from 4.602 to 3.453\nand 3.294, respectively. A developer survey on RCI-generated refactorings shows\nover 70% acceptance, with Qwen2.5-Coder rated highest across all evaluation\ncriteria. In contrast, the original code scored below neutral, particularly in\nreadability and maintainability, underscoring the benefits of automated\nrefactoring guided by quality prompts. While traditional metrics like CC and\nLOC provide useful signals, they often diverge from human judgments,\nemphasizing the need for human-in-the-loop evaluation. Our open-source\nbenchmark offers a foundation for future research on automated refactoring with\nLLMs.", "AI": {"tldr": "\u8bc4\u4f305\u4e2a\u5f00\u6e90LLM\u5728Python\u4ee3\u7801\u63d0\u53d6\u65b9\u6cd5\u91cd\u6784\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0RCI\u63d0\u793a\u7b56\u7565\u4f18\u4e8e\u5355\u6b21\u63d0\u793a\uff0c\u6700\u4f73\u6a21\u578b\u5728\u6d4b\u8bd5\u901a\u8fc7\u7387\u548c\u4ee3\u7801\u8d28\u91cf\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5f00\u53d1\u8005\u8c03\u67e5\u663e\u793a\u8d85\u8fc770%\u63a5\u53d7\u5ea6\u3002", "motivation": "\u81ea\u52a8\u5316\u63d0\u53d6\u65b9\u6cd5\u91cd\u6784\u5bf9\u63d0\u9ad8\u4ee3\u7801\u53ef\u8bfb\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u5f88\u91cd\u8981\uff0c\u4f46\u4ecd\u662f\u6311\u6218\u6027\u4efb\u52a1\u3002\u5f00\u6e90\u8d44\u6e90\u9ad8\u6548LLM\u4e3a\u81ea\u52a8\u5316\u6b64\u7c7b\u9ad8\u7ea7\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f305\u4e2a\u6700\u5148\u8fdb\u7684\u5f00\u6e90LLM\uff083B\u52308B\u53c2\u6570\uff09\uff0c\u5728Python\u4ee3\u7801EMR\u4efb\u52a1\u4e0a\u4f7f\u7528\u81ea\u52a8\u6307\u6807\u8bc4\u4f30\u529f\u80fd\u6b63\u786e\u6027\u548c\u4ee3\u7801\u8d28\u91cf\uff0c\u6bd4\u8f83\u5355\u6b21\u63d0\u793a\u4e0eRCI\u63d0\u793a\u7b56\u7565\u7684\u6548\u679c\u3002", "result": "RCI\u63d0\u793a\u5728\u6d4b\u8bd5\u901a\u8fc7\u7387\u548c\u91cd\u6784\u8d28\u91cf\u4e0a\u6301\u7eed\u4f18\u4e8e\u5355\u6b21\u63d0\u793a\u3002\u6700\u4f73\u6a21\u578bDeepseek-Coder-RCI\u548cQwen2.5-Coder-RCI\u5206\u522b\u8fbe\u52300.829\u548c0.808\u7684\u6d4b\u8bd5\u901a\u8fc7\u7387\uff0c\u5c06\u6bcf\u65b9\u6cd5\u4ee3\u7801\u884c\u6570\u4ece12.103\u51cf\u5c11\u52306.192\u548c5.577\uff0c\u5708\u590d\u6742\u5ea6\u4ece4.602\u964d\u4f4e\u52303.453\u548c3.294\u3002\u5f00\u53d1\u8005\u8c03\u67e5\u663e\u793a\u8d85\u8fc770%\u63a5\u53d7RCI\u751f\u6210\u7684\u91cd\u6784\u3002", "conclusion": "RCI\u63d0\u793a\u7b56\u7565\u663e\u8457\u63d0\u5347LLM\u5728\u4ee3\u7801\u91cd\u6784\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4f20\u7edf\u6307\u6807\u4e0e\u4eba\u5de5\u5224\u65ad\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u8981\u4eba\u5de5\u53c2\u4e0e\u8bc4\u4f30\u3002\u5f00\u6e90\u57fa\u51c6\u4e3a\u672a\u6765LLM\u81ea\u52a8\u5316\u91cd\u6784\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.26023", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.26023", "abs": "https://arxiv.org/abs/2510.26023", "authors": ["Zhipeng Bao", "Qianwen Li"], "title": "Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization", "comment": "8 pages", "summary": "Despite significant advancements in recent decades, autonomous vehicles (AVs)\ncontinue to face challenges in navigating certain traffic scenarios where human\ndrivers excel. In such situations, AVs often become immobilized, disrupting\noverall traffic flow. Current recovery solutions, such as remote intervention\n(which is costly and inefficient) and manual takeover (which excludes\nnon-drivers and limits AV accessibility), are inadequate. This paper introduces\nStuckSolver, a novel Large Language Model (LLM) driven recovery framework that\nenables AVs to resolve immobilization scenarios through self-reasoning and/or\npassenger-guided decision-making. StuckSolver is designed as a plug-in add-on\nmodule that operates on top of the AV's existing perception-planning-control\nstack, requiring no modification to its internal architecture. Instead, it\ninterfaces with standard sensor data streams to detect immobilization states,\ninterpret environmental context, and generate high-level recovery commands that\ncan be executed by the AV's native planner. We evaluate StuckSolver on the\nBench2Drive benchmark and in custom-designed uncertainty scenarios. Results\nshow that StuckSolver achieves near-state-of-the-art performance through\nautonomous self-reasoning alone and exhibits further improvements when\npassenger guidance is incorporated.", "AI": {"tldr": "StuckSolver\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6062\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u4e3b\u63a8\u7406\u548c\u4e58\u5ba2\u5f15\u5bfc\u89e3\u51b3\u8f66\u8f86\u88ab\u56f0\u573a\u666f\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709\u67b6\u6784\u5373\u53ef\u63d0\u5347\u4ea4\u901a\u6d41\u52a8\u6027\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u590d\u6742\u4ea4\u901a\u573a\u666f\u4e2d\u5bb9\u6613\u9677\u5165\u56f0\u5883\uff0c\u73b0\u6709\u6062\u590d\u65b9\u6848\uff08\u8fdc\u7a0b\u5e72\u9884\u548c\u624b\u52a8\u63a5\u7ba1\uff09\u5b58\u5728\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\u3001\u53ef\u8bbf\u95ee\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86StuckSolver\u4f5c\u4e3a\u63d2\u4ef6\u6a21\u5757\uff0c\u5229\u7528LLM\u5206\u6790\u4f20\u611f\u5668\u6570\u636e\u68c0\u6d4b\u88ab\u56f0\u72b6\u6001\uff0c\u7406\u89e3\u73af\u5883\u4e0a\u4e0b\u6587\uff0c\u751f\u6210\u53ef\u7531\u8f66\u8f86\u539f\u751f\u89c4\u5212\u5668\u6267\u884c\u7684\u9ad8\u7ea7\u6062\u590d\u6307\u4ee4\u3002", "result": "\u5728Bench2Drive\u57fa\u51c6\u6d4b\u8bd5\u548c\u81ea\u5b9a\u4e49\u4e0d\u786e\u5b9a\u573a\u666f\u4e2d\uff0cStuckSolver\u4ec5\u901a\u8fc7\u81ea\u4e3b\u63a8\u7406\u5c31\u8fbe\u5230\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\uff0c\u7ed3\u5408\u4e58\u5ba2\u5f15\u5bfc\u540e\u8868\u73b0\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "conclusion": "StuckSolver\u8bc1\u660e\u4e86LLM\u9a71\u52a8\u7684\u6062\u590d\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u88ab\u56f0\u95ee\u9898\uff0c\u63d0\u9ad8\u7cfb\u7edf\u9c81\u68d2\u6027\u548c\u53ef\u8bbf\u95ee\u6027\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709\u67b6\u6784\u3002"}}
{"id": "2510.26212", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26212", "abs": "https://arxiv.org/abs/2510.26212", "authors": ["Yifeng Cai", "Ziming Wang", "Zhaomeng Deng", "Mengyu Yao", "Junlin Liu", "Yutao Hu", "Ziqi Zhang", "Yao Guo", "Ding Li"], "title": "Who Grants the Agent Power? Defending Against Instruction Injection via Task-Centric Access Control", "comment": "SaTS 2025 (Co-located with ACM CCS 2025)", "summary": "AI agents capable of GUI understanding and Model Context Protocol are\nincreasingly deployed to automate mobile tasks. However, their reliance on\nover-privileged, static permissions creates a critical vulnerability:\ninstruction injection. Malicious instructions, embedded in otherwise benign\ncontent like emails, can hijack the agent to perform unauthorized actions. We\npresent AgentSentry, a lightweight runtime task-centric access control\nframework that enforces dynamic, task-scoped permissions. Instead of granting\nbroad, persistent permissions, AgentSentry dynamically generates and enforces\nminimal, temporary policies aligned with the user's specific task (e.g.,\nregister for an app), revoking them upon completion. We demonstrate that\nAgentSentry successfully prevents an instruction injection attack, where an\nagent is tricked into forwarding private emails, while allowing the legitimate\ntask to complete. Our approach highlights the urgent need for intent-aligned\nsecurity models to safely govern the next generation of autonomous agents.", "AI": {"tldr": "AgentSentry\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u8fd0\u884c\u65f6\u4efb\u52a1\u4e2d\u5fc3\u8bbf\u95ee\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u6210\u548c\u6267\u884c\u4e0e\u7528\u6237\u7279\u5b9a\u4efb\u52a1\u5bf9\u9f50\u7684\u6700\u5c0f\u4e34\u65f6\u6743\u9650\u7b56\u7565\uff0c\u9632\u6b62AI\u4ee3\u7406\u906d\u53d7\u6307\u4ee4\u6ce8\u5165\u653b\u51fb\u3002", "motivation": "AI\u4ee3\u7406\u5728\u79fb\u52a8\u4efb\u52a1\u81ea\u52a8\u5316\u4e2d\u4f9d\u8d56\u8fc7\u5ea6\u6388\u6743\u548c\u9759\u6001\u6743\u9650\uff0c\u5b58\u5728\u6307\u4ee4\u6ce8\u5165\u6f0f\u6d1e\uff0c\u6076\u610f\u6307\u4ee4\u53ef\u80fd\u52ab\u6301\u4ee3\u7406\u6267\u884c\u672a\u6388\u6743\u64cd\u4f5c\u3002", "method": "AgentSentry\u52a8\u6001\u751f\u6210\u548c\u6267\u884c\u4efb\u52a1\u8303\u56f4\u7684\u4e34\u65f6\u6743\u9650\u7b56\u7565\uff0c\u800c\u4e0d\u662f\u6388\u4e88\u5e7f\u6cdb\u6301\u4e45\u6743\u9650\uff0c\u5e76\u5728\u4efb\u52a1\u5b8c\u6210\u540e\u64a4\u9500\u8fd9\u4e9b\u6743\u9650\u3002", "result": "AgentSentry\u6210\u529f\u9632\u6b62\u4e86\u6307\u4ee4\u6ce8\u5165\u653b\u51fb\uff08\u5982\u8bf1\u9a97\u4ee3\u7406\u8f6c\u53d1\u79c1\u4eba\u90ae\u4ef6\uff09\uff0c\u540c\u65f6\u5141\u8bb8\u5408\u6cd5\u4efb\u52a1\u5b8c\u6210\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5f3a\u8c03\u4e86\u4e3a\u5b89\u5168\u6cbb\u7406\u4e0b\u4e00\u4ee3\u81ea\u4e3b\u4ee3\u7406\u800c\u5efa\u7acb\u610f\u56fe\u5bf9\u9f50\u5b89\u5168\u6a21\u578b\u7684\u7d27\u8feb\u9700\u6c42\u3002"}}
{"id": "2510.26516", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26516", "abs": "https://arxiv.org/abs/2510.26516", "authors": ["Truong Hai Dang", "Jingyu Xiao", "Yintong Huo"], "title": "Envisioning Future Interactive Web Development: Editing Webpage with Natural Language", "comment": "accepted by AIWare'25", "summary": "The evolution of web applications relies on iterative code modifications, a\nprocess that is traditionally manual and time-consuming. While Large Language\nModels (LLMs) can generate UI code, their ability to edit existing code from\nnew design requirements (e.g., \"center the logo\") remains a challenge. This is\nlargely due to the absence of large-scale, high-quality tuning data to align\nmodel performance with human expectations. In this paper, we introduce a novel,\nautomated data generation pipeline that uses LLMs to synthesize a high-quality\nfine-tuning dataset for web editing, named Instruct4Edit. Our approach\ngenerates diverse instructions, applies the corresponding code modifications,\nand performs visual verification to ensure correctness. By fine-tuning models\non Instruct4Edit, we demonstrate consistent improvement in translating human\nintent into precise, structurally coherent, and visually accurate code changes.\nThis work provides a scalable and transparent foundation for natural language\nbased web editing, demonstrating that fine-tuning smaller open-source models\ncan achieve competitive performance with proprietary systems. We release all\ndata, code implementations, and model checkpoints for reproduction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u6570\u636e\u751f\u6210\u6d41\u7a0bInstruct4Edit\uff0c\u7528\u4e8e\u8bad\u7ec3LLMs\u8fdb\u884c\u7f51\u9875\u4ee3\u7801\u7f16\u8f91\uff0c\u901a\u8fc7\u751f\u6210\u591a\u6837\u5316\u6307\u4ee4\u3001\u5e94\u7528\u4ee3\u7801\u4fee\u6539\u548c\u89c6\u89c9\u9a8c\u8bc1\u6765\u521b\u5efa\u9ad8\u8d28\u91cf\u5fae\u8c03\u6570\u636e\u96c6\u3002", "motivation": "\u7f51\u9875\u5e94\u7528\u5f00\u53d1\u4f9d\u8d56\u4e8e\u8fed\u4ee3\u4ee3\u7801\u4fee\u6539\uff0c\u4f20\u7edf\u4e0a\u8fd9\u662f\u624b\u52a8\u4e14\u8017\u65f6\u7684\u8fc7\u7a0b\u3002\u867d\u7136LLMs\u80fd\u751f\u6210UI\u4ee3\u7801\uff0c\u4f46\u4ece\u65b0\u8bbe\u8ba1\u9700\u6c42\u7f16\u8f91\u73b0\u6709\u4ee3\u7801\u4ecd\u5177\u6311\u6218\u6027\uff0c\u4e3b\u8981\u7f3a\u4e4f\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u8c03\u4f18\u6570\u636e\u6765\u5bf9\u9f50\u6a21\u578b\u6027\u80fd\u4e0e\u4eba\u7c7b\u671f\u671b\u3002", "method": "\u4f7f\u7528LLMs\u5408\u6210\u9ad8\u8d28\u91cf\u5fae\u8c03\u6570\u636e\u96c6Instruct4Edit\u7684\u81ea\u52a8\u5316\u6570\u636e\u751f\u6210\u6d41\u7a0b\uff0c\u5305\u62ec\u751f\u6210\u591a\u6837\u5316\u6307\u4ee4\u3001\u5e94\u7528\u76f8\u5e94\u4ee3\u7801\u4fee\u6539\uff0c\u5e76\u8fdb\u884c\u89c6\u89c9\u9a8c\u8bc1\u4ee5\u786e\u4fdd\u6b63\u786e\u6027\u3002", "result": "\u901a\u8fc7\u5728Instruct4Edit\u4e0a\u5fae\u8c03\u6a21\u578b\uff0c\u5728\u5c06\u4eba\u7c7b\u610f\u56fe\u8f6c\u5316\u4e3a\u7cbe\u786e\u3001\u7ed3\u6784\u8fde\u8d2f\u4e14\u89c6\u89c9\u51c6\u786e\u7684\u4ee3\u7801\u66f4\u6539\u65b9\u9762\u8868\u73b0\u51fa\u6301\u7eed\u6539\u8fdb\u3002", "conclusion": "\u4e3a\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u7f51\u9875\u7f16\u8f91\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u900f\u660e\u7684\u57fa\u7840\uff0c\u8bc1\u660e\u5fae\u8c03\u8f83\u5c0f\u7684\u5f00\u6e90\u6a21\u578b\u53ef\u4ee5\u5b9e\u73b0\u4e0e\u4e13\u6709\u7cfb\u7edf\u76f8\u7ade\u4e89\u7684\u6027\u80fd\u3002"}}
{"id": "2510.26057", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.26057", "abs": "https://arxiv.org/abs/2510.26057", "authors": ["Andrew L. Kun"], "title": "Can AI be Accountable?", "comment": "To be published as a chapter in Daniele Quercia and Marios\n  Constantinides (Eds.). Operationalizing Responsible AI. Cambridge University\n  Press. Forthcoming", "summary": "The AI we use is powerful, and its power is increasing rapidly. If this\npowerful AI is to serve the needs of consumers, voters, and decision makers,\nthen it is imperative that the AI is accountable. In general, an agent is\naccountable to a forum if the forum can request information from the agent\nabout its actions, if the forum and the agent can discuss this information, and\nif the forum can sanction the agent. Unfortunately, in too many cases today's\nAI is not accountable -- we cannot question it, enter into a discussion with\nit, let alone sanction it. In this chapter we relate the general definition of\naccountability to AI, we illustrate what it means for AI to be accountable and\nunaccountable, and we explore approaches that can improve our chances of living\nin a world where all AI is accountable to those who are affected by it.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u95ee\u8d23\u6027\u7684\u91cd\u8981\u6027\uff0c\u5206\u6790\u4e86\u5f53\u524dAI\u7cfb\u7edf\u7f3a\u4e4f\u95ee\u8d23\u6027\u7684\u73b0\u72b6\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u5584AI\u95ee\u8d23\u6027\u7684\u65b9\u6cd5\u6846\u67b6\u3002", "motivation": "\u968f\u7740AI\u80fd\u529b\u7684\u5feb\u901f\u63d0\u5347\uff0c\u786e\u4fddAI\u5bf9\u6d88\u8d39\u8005\u3001\u9009\u6c11\u548c\u51b3\u7b56\u8005\u8d1f\u8d23\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524dAI\u7cfb\u7edf\u666e\u904d\u7f3a\u4e4f\u95ee\u8d23\u673a\u5236\uff0c\u65e0\u6cd5\u88ab\u8d28\u7591\u3001\u8ba8\u8bba\u6216\u5236\u88c1\u3002", "method": "\u5c06\u4e00\u822c\u95ee\u8d23\u5b9a\u4e49\u5e94\u7528\u4e8eAI\u7cfb\u7edf\uff0c\u8bf4\u660eAI\u95ee\u8d23\u548c\u975e\u95ee\u8d23\u7684\u5177\u4f53\u8868\u73b0\uff0c\u63a2\u7d22\u63d0\u9ad8AI\u95ee\u8d23\u6027\u7684\u65b9\u6cd5\u9014\u5f84\u3002", "result": "\u660e\u786e\u4e86AI\u95ee\u8d23\u6027\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u5f53\u524dAI\u7cfb\u7edf\u5728\u95ee\u8d23\u6027\u65b9\u9762\u7684\u7f3a\u9677\uff0c\u63d0\u51fa\u4e86\u6539\u5584\u95ee\u8d23\u6027\u7684\u65b9\u5411\u3002", "conclusion": "\u9700\u8981\u5efa\u7acb\u673a\u5236\u786e\u4fdd\u6240\u6709AI\u7cfb\u7edf\u5bf9\u53d7\u5176\u5f71\u54cd\u7684\u4eba\u4fdd\u6301\u95ee\u8d23\uff0c\u8fd9\u662f\u5b9e\u73b0AI\u8d1f\u8d23\u4efb\u53d1\u5c55\u7684\u5173\u952e\u8981\u6c42\u3002"}}
{"id": "2510.26274", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26274", "abs": "https://arxiv.org/abs/2510.26274", "authors": ["Haohua Duan", "Liyao Xiang", "Xin Zhang"], "title": "PVMark: Enabling Public Verifiability for LLM Watermarking Schemes", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Watermarking schemes for large language models (LLMs) have been proposed to\nidentify the source of the generated text, mitigating the potential threats\nemerged from model theft. However, current watermarking solutions hardly\nresolve the trust issue: the non-public watermark detection cannot prove itself\nfaithfully conducting the detection. We observe that it is attributed to the\nsecret key mostly used in the watermark detection -- it cannot be public, or\nthe adversary may launch removal attacks provided the key; nor can it be\nprivate, or the watermarking detection is opaque to the public. To resolve the\ndilemma, we propose PVMark, a plugin based on zero-knowledge proof (ZKP),\nenabling the watermark detection process to be publicly verifiable by third\nparties without disclosing any secret key. PVMark hinges upon the proof of\n`correct execution' of watermark detection on which a set of ZKP constraints\nare built, including mapping, random number generation, comparison, and\nsummation. We implement multiple variants of PVMark in Python, Rust and Circom,\ncovering combinations of three watermarking schemes, three hash functions, and\nfour ZKP protocols, to show our approach effectively works under a variety of\ncircumstances. By experimental results, PVMark efficiently enables public\nverifiability on the state-of-the-art LLM watermarking schemes yet without\ncompromising the watermarking performance, promising to be deployed in\npractice.", "AI": {"tldr": "PVMark\u662f\u4e00\u4e2a\u57fa\u4e8e\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684\u63d2\u4ef6\uff0c\u4f7fLLM\u6c34\u5370\u68c0\u6d4b\u8fc7\u7a0b\u53ef\u516c\u5f00\u9a8c\u8bc1\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u6c34\u5370\u65b9\u6848\u56e0\u79d8\u5bc6\u5bc6\u94a5\u5bfc\u81f4\u7684\u4fe1\u4efb\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u6c34\u5370\u65b9\u6848\u5b58\u5728\u4fe1\u4efb\u95ee\u9898\uff1a\u975e\u516c\u5f00\u7684\u6c34\u5370\u68c0\u6d4b\u65e0\u6cd5\u8bc1\u660e\u5176\u5fe0\u5b9e\u6267\u884c\u68c0\u6d4b\u8fc7\u7a0b\uff0c\u8fd9\u6e90\u4e8e\u79d8\u5bc6\u5bc6\u94a5\u7684\u56f0\u5883\u2014\u2014\u516c\u5f00\u5bc6\u94a5\u4f1a\u906d\u53d7\u79fb\u9664\u653b\u51fb\uff0c\u79c1\u6709\u5bc6\u94a5\u5219\u4f7f\u68c0\u6d4b\u8fc7\u7a0b\u4e0d\u900f\u660e\u3002", "method": "\u57fa\u4e8e\u96f6\u77e5\u8bc6\u8bc1\u660e\u6784\u5efa\u6c34\u5370\u68c0\u6d4b\u7684'\u6b63\u786e\u6267\u884c'\u8bc1\u660e\uff0c\u5305\u62ec\u6620\u5c04\u3001\u968f\u673a\u6570\u751f\u6210\u3001\u6bd4\u8f83\u548c\u6c42\u548c\u7b49\u7ea6\u675f\u6761\u4ef6\uff0c\u5b9e\u73b0\u4e86\u591a\u79cd\u53d8\u4f53\u8986\u76d6\u4e0d\u540c\u6c34\u5370\u65b9\u6848\u3001\u54c8\u5e0c\u51fd\u6570\u548cZKP\u534f\u8bae\u3002", "result": "PVMark\u5728\u591a\u79cd\u73af\u5883\u4e0b\u6709\u6548\u5de5\u4f5c\uff0c\u80fd\u591f\u9ad8\u6548\u5730\u4e3a\u6700\u5148\u8fdb\u7684LLM\u6c34\u5370\u65b9\u6848\u63d0\u4f9b\u516c\u5f00\u53ef\u9a8c\u8bc1\u6027\uff0c\u4e14\u4e0d\u5f71\u54cd\u6c34\u5370\u6027\u80fd\u3002", "conclusion": "PVMark\u89e3\u51b3\u4e86\u6c34\u5370\u68c0\u6d4b\u7684\u4fe1\u4efb\u56f0\u5883\uff0c\u6709\u671b\u5728\u5b9e\u9645\u4e2d\u90e8\u7f72\u4f7f\u7528\u3002"}}
{"id": "2510.26538", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26538", "abs": "https://arxiv.org/abs/2510.26538", "authors": ["David Williams", "Max Hort", "Maria Kechagia", "Aldeida Aleti", "Justyna Petke", "Federica Sarro"], "title": "Reflecting on Empirical and Sustainability Aspects of Software Engineering Research in the Era of Large Language Models", "comment": "5 pages", "summary": "Software Engineering (SE) research involving the use of Large Language Models\n(LLMs) has introduced several new challenges related to rigour in benchmarking,\ncontamination, replicability, and sustainability. In this paper, we invite the\nresearch community to reflect on how these challenges are addressed in SE. Our\nresults provide a structured overview of current LLM-based SE research at ICSE,\nhighlighting both encouraging practices and persistent shortcomings. We\nconclude with recommendations to strengthen benchmarking rigour, improve\nreplicability, and address the financial and environmental costs of LLM-based\nSE.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u9762\u4e34\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e25\u8c28\u6027\u3001\u6c61\u67d3\u3001\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6301\u7eed\u6027\u7b49\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5f15\u5165\u4e86\u57fa\u51c6\u6d4b\u8bd5\u4e25\u8c28\u6027\u3001\u6c61\u67d3\u3001\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6301\u7eed\u6027\u7b49\u65b0\u6311\u6218\uff0c\u9700\u8981\u7814\u7a76\u793e\u533a\u53cd\u601d\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u6790ICSE\u4f1a\u8bae\u4e0a\u5f53\u524d\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\uff0c\u8bc6\u522b\u826f\u597d\u5b9e\u8df5\u548c\u6301\u7eed\u5b58\u5728\u7684\u95ee\u9898\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u5c55\u793a\u4e86\u5f53\u524dLLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\uff0c\u7a81\u51fa\u4e86\u4ee4\u4eba\u9f13\u821e\u7684\u505a\u6cd5\u548c\u6301\u7eed\u5b58\u5728\u7684\u4e0d\u8db3\u3002", "conclusion": "\u63d0\u51fa\u4e86\u52a0\u5f3a\u57fa\u51c6\u6d4b\u8bd5\u4e25\u8c28\u6027\u3001\u63d0\u9ad8\u53ef\u590d\u73b0\u6027\u4ee5\u53ca\u89e3\u51b3\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u8d22\u52a1\u548c\u73af\u5883\u6210\u672c\u7684\u5efa\u8bae\u3002"}}
{"id": "2510.26094", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26094", "abs": "https://arxiv.org/abs/2510.26094", "authors": ["Yuxin Li", "Minghao Liu", "Ruida Wang", "Wenzhao Ji", "Zhitao He", "Rui Pan", "Junming Huang", "Tong Zhang", "Yi R. Fung"], "title": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "comment": null, "summary": "We present **Lean4PHYS**, a comprehensive reasoning framework for\ncollege-level physics problems in Lean4. **Lean4PHYS** includes\n*LeanPhysBench*, a college-level benchmark for formal physics reasoning in\nLean4, which contains 200 hand-crafted and peer-reviewed statements derived\nfrom university textbooks and physics competition problems. To establish a\nsolid foundation for formal reasoning in physics, we also introduce *PhysLib*,\na community-driven repository containing fundamental unit systems and theorems\nessential for formal physics reasoning. Based on the benchmark and Lean4\nrepository we composed in **Lean4PHYS**, we report baseline results using major\nexpert Math Lean4 provers and state-of-the-art closed-source models, with the\nbest performance of DeepSeek-Prover-V2-7B achieving only 16% and\nClaude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that\nour *PhysLib* can achieve an average improvement of 11.75% in model\nperformance. This demonstrates the challenging nature of our *LeanPhysBench*\nand the effectiveness of *PhysLib*. To the best of our knowledge, this is the\nfirst study to provide a physics benchmark in Lean4.", "AI": {"tldr": "Lean4PHYS\u662f\u4e00\u4e2a\u57fa\u4e8eLean4\u7684\u5927\u5b66\u7269\u7406\u95ee\u9898\u63a8\u7406\u6846\u67b6\uff0c\u5305\u542bLeanPhysBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\u548cPhysLib\u7269\u7406\u5e93\uff0c\u5728\u73b0\u6709\u6a21\u578b\u4e0a\u8868\u73b0\u8f83\u5dee\u4f46PhysLib\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4e3a\u5927\u5b66\u7269\u7406\u95ee\u9898\u63d0\u4f9b\u6b63\u5f0f\u7684\u63a8\u7406\u6846\u67b6\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u586b\u8865Lean4\u4e2d\u7269\u7406\u63a8\u7406\u57fa\u51c6\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u5305\u542b200\u4e2a\u624b\u5de5\u5236\u4f5c\u548c\u540c\u884c\u8bc4\u5ba1\u7269\u7406\u95ee\u9898\u7684LeanPhysBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u4ee5\u53ca\u5305\u542b\u57fa\u7840\u5355\u4f4d\u7cfb\u7edf\u548c\u5b9a\u7406\u7684PhysLib\u7269\u7406\u5e93\u3002", "result": "\u6700\u4f73\u6a21\u578bDeepSeek-Prover-V2-7B\u4ec5\u8fbe\u523016%\u51c6\u786e\u7387\uff0cClaude-Sonnet-4\u8fbe\u523035%\uff0cPhysLib\u5e73\u5747\u63d0\u5347\u6a21\u578b\u6027\u80fd11.75%\u3002", "conclusion": "LeanPhysBench\u5177\u6709\u6311\u6218\u6027\uff0cPhysLib\u80fd\u6709\u6548\u63d0\u5347\u7269\u7406\u63a8\u7406\u6027\u80fd\uff0c\u8fd9\u662f\u9996\u4e2a\u5728Lean4\u4e2d\u63d0\u4f9b\u7684\u7269\u7406\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2510.26307", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26307", "abs": "https://arxiv.org/abs/2510.26307", "authors": ["Laura Jiang", "Reza Ryan", "Qian Li", "Nasim Ferdosian"], "title": "A Survey of Heterogeneous Graph Neural Networks for Cybersecurity Anomaly Detection", "comment": "37 pages, 4 figures, 86 references. Submitted to Journal of Computer\n  Security (under review)", "summary": "Anomaly detection is a critical task in cybersecurity, where identifying\ninsider threats, access violations, and coordinated attacks is essential for\nensuring system resilience. Graph-based approaches have become increasingly\nimportant for modeling entity interactions, yet most rely on homogeneous and\nstatic structures, which limits their ability to capture the heterogeneity and\ntemporal evolution of real-world environments. Heterogeneous Graph Neural\nNetworks (HGNNs) have emerged as a promising paradigm for anomaly detection by\nincorporating type-aware transformations and relation-sensitive aggregation,\nenabling more expressive modeling of complex cyber data. However, current\nresearch on HGNN-based anomaly detection remains fragmented, with diverse\nmodeling strategies, limited comparative evaluation, and an absence of\nstandardized benchmarks. To address this gap, we provide a comprehensive survey\nof HGNN-based anomaly detection methods in cybersecurity. We introduce a\ntaxonomy that classifies approaches by anomaly type and graph dynamics, analyze\nrepresentative models, and map them to key cybersecurity applications. We also\nreview commonly used benchmark datasets and evaluation metrics, highlighting\ntheir strengths and limitations. Finally, we identify key open challenges\nrelated to modeling, data, and deployment, and outline promising directions for\nfuture research. This survey aims to establish a structured foundation for\nadvancing HGNN-based anomaly detection toward scalable, interpretable, and\npractically deployable solutions.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\uff08HGNN\uff09\u7684\u7f51\u7edc\u5b89\u5168\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u6309\u5f02\u5e38\u7c7b\u578b\u548c\u56fe\u52a8\u6001\u6027\u5206\u7c7b\u7684\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e86\u4ee3\u8868\u6027\u6a21\u578b\u53ca\u5176\u5728\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eHGNN\u7684\u5f02\u5e38\u68c0\u6d4b\u7814\u7a76\u5b58\u5728\u788e\u7247\u5316\u95ee\u9898\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u5efa\u6a21\u7b56\u7565\u3001\u6709\u9650\u7684\u6bd4\u8f83\u8bc4\u4f30\u4ee5\u53ca\u6807\u51c6\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9700\u8981\u5efa\u7acb\u7cfb\u7edf\u5316\u7684\u7814\u7a76\u6846\u67b6\u3002", "method": "\u91c7\u7528\u7efc\u8ff0\u7814\u7a76\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u6309\u5f02\u5e38\u7c7b\u578b\u548c\u56fe\u52a8\u6001\u6027\u5206\u7c7b\u7684\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e86\u4ee3\u8868\u6027HGNN\u6a21\u578b\uff0c\u5e76\u8bc4\u4f30\u4e86\u5e38\u7528\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bc4\u4ef7\u6307\u6807\u3002", "result": "\u5efa\u7acb\u4e86HGNN\u5f02\u5e38\u68c0\u6d4b\u7684\u7cfb\u7edf\u5316\u5206\u7c7b\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u57fa\u7840\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u63a8\u8fdb\u57fa\u4e8eHGNN\u7684\u5f02\u5e38\u68c0\u6d4b\u5411\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u548c\u5b9e\u9645\u53ef\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\u53d1\u5c55\u5960\u5b9a\u4e86\u7ed3\u6784\u5316\u57fa\u7840\uff0c\u5e76\u6307\u51fa\u4e86\u5efa\u6a21\u3001\u6570\u636e\u548c\u90e8\u7f72\u65b9\u9762\u7684\u5173\u952e\u5f00\u653e\u6311\u6218\u3002"}}
{"id": "2510.26576", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26576", "abs": "https://arxiv.org/abs/2510.26576", "authors": ["Filippo Scaramuzza", "Renato Cordeiro Ferreira", "Tomaz Maia Suller", "Giovanni Quattrocchi", "Damian Andrew Tamburri", "Willem-Jan van den Heuvel"], "title": "\"Show Me You Comply... Without Showing Me Anything\": Zero-Knowledge Software Auditing for AI-Enabled Systems", "comment": "This work has been submitted to the ACM Transactions on Software\n  Engineering and Methodology for possible publication", "summary": "The increasing exploitation of Artificial Intelligence (AI) enabled systems\nin critical domains has made trustworthiness concerns a paramount showstopper,\nrequiring verifiable accountability, often by regulation (e.g., the EU AI Act).\nClassical software verification and validation techniques, such as procedural\naudits, formal methods, or model documentation, are the mechanisms used to\nachieve this. However, these methods are either expensive or heavily manual and\nill-suited for the opaque, \"black box\" nature of most AI models. An intractable\nconflict emerges: high auditability and verifiability are required by law, but\nsuch transparency conflicts with the need to protect assets being audited-e.g.,\nconfidential data and proprietary models-leading to weakened accountability. To\naddress this challenge, this paper introduces ZKMLOps, a novel MLOps\nverification framework that operationalizes Zero-Knowledge Proofs\n(ZKPs)-cryptographic protocols allowing a prover to convince a verifier that a\nstatement is true without revealing additional information-within\nMachine-Learning Operations lifecycles. By integrating ZKPs with established\nsoftware engineering patterns, ZKMLOps provides a modular and repeatable\nprocess for generating verifiable cryptographic proof of compliance. We\nevaluate the framework's practicality through a study of regulatory compliance\nin financial risk auditing and assess feasibility through an empirical\nevaluation of top ZKP protocols, analyzing performance trade-offs for ML models\nof increasing complexity.", "AI": {"tldr": "ZKMLOps\u662f\u4e00\u4e2a\u57fa\u4e8e\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684MLOps\u9a8c\u8bc1\u6846\u67b6\uff0c\u89e3\u51b3AI\u7cfb\u7edf\u53ef\u4fe1\u5ea6\u9a8c\u8bc1\u4e0e\u8d44\u4ea7\u4fdd\u62a4\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u901a\u8fc7\u5bc6\u7801\u5b66\u8bc1\u660e\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u5408\u89c4\u6027\u3002", "motivation": "AI\u7cfb\u7edf\u5728\u5173\u952e\u9886\u57df\u7684\u5e94\u7528\u9762\u4e34\u53ef\u4fe1\u5ea6\u6311\u6218\uff0c\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\u6210\u672c\u9ad8\u4e14\u4e0d\u9002\u5408AI\u9ed1\u76d2\u7279\u6027\uff0c\u540c\u65f6\u900f\u660e\u5ea6\u9700\u6c42\u4e0e\u8d44\u4ea7\u4fdd\u62a4\uff08\u5982\u4e13\u6709\u6a21\u578b\u548c\u673a\u5bc6\u6570\u636e\uff09\u4e4b\u95f4\u5b58\u5728\u51b2\u7a81\u3002", "method": "\u5c06\u96f6\u77e5\u8bc6\u8bc1\u660e\u534f\u8bae\u96c6\u6210\u5230\u673a\u5668\u5b66\u4e60\u8fd0\u7ef4\u751f\u547d\u5468\u671f\u4e2d\uff0c\u7ed3\u5408\u6210\u719f\u7684\u8f6f\u4ef6\u5de5\u7a0b\u6a21\u5f0f\uff0c\u63d0\u4f9b\u6a21\u5757\u5316\u3001\u53ef\u91cd\u590d\u7684\u5408\u89c4\u6027\u5bc6\u7801\u5b66\u8bc1\u660e\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u901a\u8fc7\u91d1\u878d\u98ce\u9669\u5ba1\u8ba1\u7684\u76d1\u7ba1\u5408\u89c4\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u6846\u67b6\u5b9e\u7528\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\u4e0d\u540cZKP\u534f\u8bae\u7684\u6027\u80fd\u6743\u8861\uff0c\u5206\u6790\u4e86\u590d\u6742ML\u6a21\u578b\u7684\u53ef\u884c\u6027\u3002", "conclusion": "ZKMLOps\u6846\u67b6\u4e3a\u89e3\u51b3AI\u7cfb\u7edf\u53ef\u4fe1\u5ea6\u9a8c\u8bc1\u4e0e\u8d44\u4ea7\u4fdd\u62a4\u4e4b\u95f4\u7684\u51b2\u7a81\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848\uff0c\u80fd\u591f\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u5bc6\u7801\u5b66\u5408\u89c4\u8bc1\u660e\u3002"}}
{"id": "2510.26098", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26098", "abs": "https://arxiv.org/abs/2510.26098", "authors": ["Chenrui Shi", "Zedong Yu", "Zhi Gao", "Ruining Feng", "Enqi Liu", "Yuwei Wu", "Yunde Jia", "Liuyu Xiang", "Zhaofeng He", "Qing Li"], "title": "GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks", "comment": null, "summary": "Large vision language models (VLMs) have advanced graphical user interface\n(GUI) task automation but still lag behind humans. We hypothesize this gap\nstems from missing core GUI knowledge, which existing training schemes (such as\nsupervised fine tuning and reinforcement learning) alone cannot fully address.\nBy analyzing common failure patterns in GUI task execution, we distill GUI\nknowledge into three dimensions: (1) interface perception, knowledge about\nrecognizing widgets and system states; (2) interaction prediction, knowledge\nabout reasoning action state transitions; and (3) instruction understanding,\nknowledge about planning, verifying, and assessing task completion progress. We\nfurther introduce GUI Knowledge Bench, a benchmark with multiple choice and\nyes/no questions across six platforms (Web, Android, MacOS, Windows, Linux,\nIOS) and 292 applications. Our evaluation shows that current VLMs identify\nwidget functions but struggle with perceiving system states, predicting\nactions, and verifying task completion. Experiments on real world GUI tasks\nfurther validate the close link between GUI knowledge and task success. By\nproviding a structured framework for assessing GUI knowledge, our work supports\nthe selection of VLMs with greater potential prior to downstream training and\nprovides insights for building more capable GUI agents.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728GUI\u4efb\u52a1\u81ea\u52a8\u5316\u4e2d\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86GUI\u77e5\u8bc6\u7684\u4e09\u4e2a\u7ef4\u5ea6\u6846\u67b6\uff0c\u5e76\u521b\u5efa\u4e86GUI Knowledge Bench\u57fa\u51c6\u6765\u8bc4\u4f30\u6a21\u578b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728GUI\u4efb\u52a1\u81ea\u52a8\u5316\u65b9\u9762\u4ecd\u843d\u540e\u4e8e\u4eba\u7c7b\uff0c\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u7531\u4e8e\u7f3a\u4e4f\u6838\u5fc3GUI\u77e5\u8bc6\uff0c\u800c\u73b0\u6709\u7684\u8bad\u7ec3\u65b9\u6cd5\u65e0\u6cd5\u5b8c\u5168\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790GUI\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\uff0c\u5c06GUI\u77e5\u8bc6\u63d0\u70bc\u4e3a\u4e09\u4e2a\u7ef4\u5ea6\uff1a\u754c\u9762\u611f\u77e5\u3001\u4ea4\u4e92\u9884\u6d4b\u548c\u6307\u4ee4\u7406\u89e3\uff0c\u5e76\u521b\u5efa\u4e86\u8de86\u4e2a\u5e73\u53f0\u3001292\u4e2a\u5e94\u7528\u7684GUI Knowledge Bench\u57fa\u51c6\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u5f53\u524dVLMs\u80fd\u591f\u8bc6\u522b\u63a7\u4ef6\u529f\u80fd\uff0c\u4f46\u5728\u611f\u77e5\u7cfb\u7edf\u72b6\u6001\u3001\u9884\u6d4b\u52a8\u4f5c\u548c\u9a8c\u8bc1\u4efb\u52a1\u5b8c\u6210\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002\u771f\u5b9e\u4e16\u754cGUI\u4efb\u52a1\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86GUI\u77e5\u8bc6\u4e0e\u4efb\u52a1\u6210\u529f\u4e4b\u95f4\u7684\u7d27\u5bc6\u8054\u7cfb\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u6846\u67b6\u6765\u8bc4\u4f30GUI\u77e5\u8bc6\uff0c\u652f\u6301\u5728\u4e0b\u6e38\u8bad\u7ec3\u524d\u9009\u62e9\u66f4\u6709\u6f5c\u529b\u7684VLMs\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u7684GUI\u4ee3\u7406\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.26420", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26420", "abs": "https://arxiv.org/abs/2510.26420", "authors": ["Yingjia Wang", "Ting Qiao", "Xing Liu", "Chongzuo Li", "Sixing Wu", "Jianbin Li"], "title": "SSCL-BW: Sample-Specific Clean-Label Backdoor Watermarking for Dataset Ownership Verification", "comment": "8 pages,9 figures", "summary": "The rapid advancement of deep neural networks (DNNs) heavily relies on\nlarge-scale, high-quality datasets. However, unauthorized commercial use of\nthese datasets severely violates the intellectual property rights of dataset\nowners. Existing backdoor-based dataset ownership verification methods suffer\nfrom inherent limitations: poison-label watermarks are easily detectable due to\nlabel inconsistencies, while clean-label watermarks face high technical\ncomplexity and failure on high-resolution images. Moreover, both approaches\nemploy static watermark patterns that are vulnerable to detection and removal.\nTo address these issues, this paper proposes a sample-specific clean-label\nbackdoor watermarking (i.e., SSCL-BW). By training a U-Net-based watermarked\nsample generator, this method generates unique watermarks for each sample,\nfundamentally overcoming the vulnerability of static watermark patterns. The\ncore innovation lies in designing a composite loss function with three\ncomponents: target sample loss ensures watermark effectiveness, non-target\nsample loss guarantees trigger reliability, and perceptual similarity loss\nmaintains visual imperceptibility. During ownership verification, black-box\ntesting is employed to check whether suspicious models exhibit predefined\nbackdoor behaviors. Extensive experiments on benchmark datasets demonstrate the\neffectiveness of the proposed method and its robustness against potential\nwatermark removal attacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6837\u672c\u7279\u5b9a\u7684\u5e72\u51c0\u6807\u7b7e\u540e\u95e8\u6c34\u5370\u65b9\u6cd5(SSCL-BW)\uff0c\u901a\u8fc7\u8bad\u7ec3U-Net\u6c34\u5370\u751f\u6210\u5668\u4e3a\u6bcf\u4e2a\u6837\u672c\u751f\u6210\u72ec\u7279\u6c34\u5370\uff0c\u89e3\u51b3\u4e86\u9759\u6001\u6c34\u5370\u6a21\u5f0f\u6613\u88ab\u68c0\u6d4b\u548c\u79fb\u9664\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u540e\u95e8\u6570\u636e\u96c6\u6240\u6709\u6743\u9a8c\u8bc1\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff1a\u6bd2\u6807\u7b7e\u6c34\u5370\u56e0\u6807\u7b7e\u4e0d\u4e00\u81f4\u6613\u88ab\u68c0\u6d4b\uff0c\u5e72\u51c0\u6807\u7b7e\u6c34\u5370\u6280\u672f\u590d\u6742\u4e14\u5728\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u4e0a\u5931\u8d25\uff0c\u4e14\u90fd\u4f7f\u7528\u9759\u6001\u6c34\u5370\u6a21\u5f0f\u6613\u88ab\u68c0\u6d4b\u79fb\u9664\u3002", "method": "\u8bad\u7ec3U-Net\u6c34\u5370\u751f\u6210\u5668\u4e3a\u6bcf\u4e2a\u6837\u672c\u751f\u6210\u72ec\u7279\u6c34\u5370\uff0c\u8bbe\u8ba1\u5305\u542b\u76ee\u6807\u6837\u672c\u635f\u5931\u3001\u975e\u76ee\u6807\u6837\u672c\u635f\u5931\u548c\u611f\u77e5\u76f8\u4f3c\u6027\u635f\u5931\u7684\u590d\u5408\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u9ed1\u76d2\u6d4b\u8bd5\u9a8c\u8bc1\u6a21\u578b\u662f\u5426\u8868\u73b0\u51fa\u9884\u5b9a\u4e49\u540e\u95e8\u884c\u4e3a\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u5bf9\u6f5c\u5728\u6c34\u5370\u79fb\u9664\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684SSCL-BW\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4fdd\u62a4\u6570\u636e\u96c6\u77e5\u8bc6\u4ea7\u6743\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.26579", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26579", "abs": "https://arxiv.org/abs/2510.26579", "authors": ["Nathanael Nussbaumer", "Markus B\u00f6ck", "J\u00fcrgen Cito"], "title": "Online and Interactive Bayesian Inference Debugging", "comment": "Accepted by ICSE 2026", "summary": "Probabilistic programming is a rapidly developing programming paradigm which\nenables the formulation of Bayesian models as programs and the automation of\nposterior inference. It facilitates the development of models and conducting\nBayesian inference, which makes these techniques available to practitioners\nfrom multiple fields. Nevertheless, probabilistic programming is notoriously\ndifficult as identifying and repairing issues with inference requires a lot of\ntime and deep knowledge. Through this work, we introduce a novel approach to\ndebugging Bayesian inference that reduces time and required knowledge\nsignificantly. We discuss several requirements a Bayesian inference debugging\nframework has to fulfill, and propose a new tool that meets these key\nrequirements directly within the development environment. We evaluate our\nresults in a study with 18 experienced participants and show that our approach\nto online and interactive debugging of Bayesian inference significantly reduces\ntime and difficulty on inference debugging tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u8c03\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u5f00\u53d1\u73af\u5883\u4e2d\u76f4\u63a5\u96c6\u6210\u8c03\u8bd5\u5de5\u5177\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8c03\u8bd5\u65f6\u95f4\u548c\u6240\u9700\u77e5\u8bc6\u3002", "motivation": "\u6982\u7387\u7f16\u7a0b\u867d\u7136\u4fbf\u4e8e\u6784\u5efa\u8d1d\u53f6\u65af\u6a21\u578b\u548c\u8fdb\u884c\u540e\u9a8c\u63a8\u65ad\uff0c\u4f46\u63a8\u7406\u8c03\u8bd5\u975e\u5e38\u56f0\u96be\uff0c\u9700\u8981\u5927\u91cf\u65f6\u95f4\u548c\u4e13\u4e1a\u77e5\u8bc6\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6ee1\u8db3\u5173\u952e\u9700\u6c42\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u8c03\u8bd5\u6846\u67b6\uff0c\u76f4\u63a5\u5728\u5f00\u53d1\u73af\u5883\u4e2d\u63d0\u4f9b\u5728\u7ebf\u4ea4\u4e92\u5f0f\u8c03\u8bd5\u529f\u80fd\u3002", "result": "\u572818\u4f4d\u6709\u7ecf\u9a8c\u53c2\u4e0e\u8005\u7684\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u63a8\u7406\u8c03\u8bd5\u4efb\u52a1\u7684\u65f6\u95f4\u548c\u96be\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u5728\u7ebf\u4ea4\u4e92\u5f0f\u8d1d\u53f6\u65af\u63a8\u7406\u8c03\u8bd5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6982\u7387\u7f16\u7a0b\u4e2d\u7684\u8c03\u8bd5\u96be\u9898\u3002"}}
{"id": "2510.26136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26136", "abs": "https://arxiv.org/abs/2510.26136", "authors": ["Boqin Zhuang", "Jiacheng Qiao", "Mingqian Liu", "Mingxing Yu", "Ping Hong", "Rui Li", "Xiaoxia Song", "Xiangjun Xu", "Xu Chen", "Yaoyao Ma", "Yujie Gao"], "title": "Beyond Benchmarks: The Economics of AI Inference", "comment": null, "summary": "The inference cost of Large Language Models (LLMs) has become a critical\nfactor in determining their commercial viability and widespread adoption. This\npaper introduces a quantitative ``economics of inference'' framework, treating\nthe LLM inference process as a compute-driven intelligent production activity.\nWe analyze its marginal cost, economies of scale, and quality of output under\nvarious performance configurations. Based on empirical data from WiNEval-3.0,\nwe construct the first ``LLM Inference Production Frontier,'' revealing three\nprinciples: diminishing marginal cost, diminishing returns to scale, and an\noptimal cost-effectiveness zone. This paper not only provides an economic basis\nfor model deployment decisions but also lays an empirical foundation for the\nfuture market-based pricing and optimization of AI inference resources.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\"\u63a8\u7406\u7ecf\u6d4e\u5b66\"\u6846\u67b6\uff0c\u5c06LLM\u63a8\u7406\u89c6\u4e3a\u8ba1\u7b97\u9a71\u52a8\u7684\u667a\u80fd\u751f\u4ea7\u6d3b\u52a8\uff0c\u5206\u6790\u4e86\u8fb9\u9645\u6210\u672c\u3001\u89c4\u6a21\u7ecf\u6d4e\u548c\u8f93\u51fa\u8d28\u91cf\uff0c\u5e76\u57fa\u4e8eWiNEval-3.0\u6570\u636e\u6784\u5efa\u4e86\u9996\u4e2a\"LLM\u63a8\u7406\u751f\u4ea7\u524d\u6cbf\"\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6210\u672c\u5df2\u6210\u4e3a\u51b3\u5b9a\u5176\u5546\u4e1a\u53ef\u884c\u6027\u548c\u5e7f\u6cdb\u5e94\u7528\u7684\u5173\u952e\u56e0\u7d20\uff0c\u9700\u8981\u5efa\u7acb\u5b9a\u91cf\u5206\u6790\u6846\u67b6\u6765\u6307\u5bfc\u6a21\u578b\u90e8\u7f72\u51b3\u7b56\u3002", "method": "\u91c7\u7528\u5b9a\u91cf\"\u63a8\u7406\u7ecf\u6d4e\u5b66\"\u6846\u67b6\uff0c\u5c06LLM\u63a8\u7406\u8fc7\u7a0b\u89c6\u4e3a\u8ba1\u7b97\u9a71\u52a8\u7684\u667a\u80fd\u751f\u4ea7\u6d3b\u52a8\uff0c\u57fa\u4e8eWiNEval-3.0\u7684\u5b9e\u8bc1\u6570\u636e\u8fdb\u884c\u5206\u6790\u3002", "result": "\u63ed\u793a\u4e86\u4e09\u4e2a\u539f\u5219\uff1a\u8fb9\u9645\u6210\u672c\u9012\u51cf\u3001\u89c4\u6a21\u6536\u76ca\u9012\u51cf\u4ee5\u53ca\u5b58\u5728\u6700\u4f18\u6210\u672c\u6548\u76ca\u533a\u57df\uff0c\u5e76\u6784\u5efa\u4e86\u9996\u4e2aLLM\u63a8\u7406\u751f\u4ea7\u524d\u6cbf\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u4e3a\u6a21\u578b\u90e8\u7f72\u51b3\u7b56\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u57fa\u7840\uff0c\u4e5f\u4e3a\u672a\u6765AI\u63a8\u7406\u8d44\u6e90\u7684\u5e02\u573a\u5b9a\u4ef7\u548c\u4f18\u5316\u5960\u5b9a\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2510.26499", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26499", "abs": "https://arxiv.org/abs/2510.26499", "authors": ["Yasir Ech-Chammakhy", "Anas Motii", "Anass Rabii", "Oussama Azrara", "Jaafar Chbili"], "title": "CyberNER: A Harmonized STIX Corpus for Cybersecurity Named Entity Recognition", "comment": "Accepted for publication at the 24th IEEE International Conference on\n  Trust, Security and Privacy in Computing and Communications (IEEE TrustCom\n  2025)", "summary": "Extracting structured intelligence via Named Entity Recognition (NER) is\ncritical for cybersecurity, but the proliferation of datasets with incompatible\nannotation schemas hinders the development of comprehensive models. While\ncombining these resources is desirable, we empirically demonstrate that naively\nconcatenating them results in a noisy label space that severely degrades model\nperformance. To overcome this critical limitation, we introduce CyberNER, a\nlarge-scale, unified corpus created by systematically harmonizing four\nprominent datasets (CyNER, DNRTI, APTNER, and Attacker) onto the STIX 2.1\nstandard. Our principled methodology resolves semantic ambiguities and\nconsolidates over 50 disparate source tags into 21 coherent entity types. Our\nexperiments show that models trained on CyberNER achieve a substantial\nperformance gain, with a relative F1-score improvement of approximately 30%\nover the naive concatenation baseline. By publicly releasing the CyberNER\ncorpus, we provide a crucial, standardized benchmark that enables the creation\nand rigorous comparison of more robust and generalizable entity extraction\nmodels for the cybersecurity domain.", "AI": {"tldr": "CyberNER\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u7edf\u4e00\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u5c06\u56db\u4e2a\u4e3b\u8981\u7f51\u7edc\u5b89\u5168\u6570\u636e\u96c6\u534f\u8c03\u5230STIX 2.1\u6807\u51c6\uff0c\u89e3\u51b3\u4e86\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4e2d\u6807\u6ce8\u6a21\u5f0f\u4e0d\u517c\u5bb9\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u9762\u4e34\u6570\u636e\u96c6\u6807\u6ce8\u6a21\u5f0f\u4e0d\u517c\u5bb9\u7684\u95ee\u9898\uff0c\u7b80\u5355\u5408\u5e76\u8fd9\u4e9b\u8d44\u6e90\u4f1a\u5bfc\u81f4\u6807\u7b7e\u7a7a\u95f4\u566a\u58f0\u4e25\u91cd\uff0c\u4ece\u800c\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u5c06\u56db\u4e2a\u4e3b\u8981\u6570\u636e\u96c6\uff08CyNER\u3001DNRTI\u3001APTNER\u548cAttacker\uff09\u534f\u8c03\u5230STIX 2.1\u6807\u51c6\uff0c\u89e3\u51b3\u8bed\u4e49\u6b67\u4e49\uff0c\u5c0650\u591a\u4e2a\u4e0d\u540c\u7684\u6e90\u6807\u7b7e\u6574\u5408\u4e3a21\u4e2a\u4e00\u81f4\u7684\u5b9e\u4f53\u7c7b\u578b\u3002", "result": "\u5728CyberNER\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u76f8\u6bd4\u7b80\u5355\u5408\u5e76\u57fa\u7ebf\u5b9e\u73b0\u4e86\u7ea630%\u7684\u76f8\u5bf9F1\u5206\u6570\u63d0\u5347\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "CyberNER\u8bed\u6599\u5e93\u7684\u53d1\u5e03\u4e3a\u7f51\u7edc\u5b89\u5168\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u57fa\u51c6\uff0c\u80fd\u591f\u521b\u5efa\u548c\u4e25\u683c\u6bd4\u8f83\u66f4\u9c81\u68d2\u3001\u66f4\u53ef\u6cdb\u5316\u7684\u5b9e\u4f53\u63d0\u53d6\u6a21\u578b\u3002"}}
{"id": "2510.26634", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26634", "abs": "https://arxiv.org/abs/2510.26634", "authors": ["Yuan Si", "Kyle Qi", "Daming Li", "Hanyuan Shi", "Jialu Zhang"], "title": "Stitch: Step-by-step LLM Guided Tutoring for Scratch", "comment": null, "summary": "Block-based environments such as Scratch are increasingly popular in\nprogramming education. While block syntax reduces surface errors, semantic bugs\nremain common and challenging for novices to resolve. Existing debugging\nworkflows typically show the correct program directly to learners, a strategy\nthat may fix errors but undermines the development of problem-solving skills.\n  We present Stitch, an interactive tutoring system that replaces \"showing the\nanswer\" with step-by-step scaffolding. The system's Diff-Analyze module\ncontrasts a student's project with a reference implementation, identifies the\nmost critical differences, and uses a large language model to explain why these\nchanges matter. Learners inspect highlighted blocks through a custom rendering\nengine, understand the explanations, and selectively apply partial fixes. This\niterative process continues until the intended functionality is achieved.\n  We evaluate Stitch in an empirical study, comparing it against a\nstate-of-the-art automated feedback generation tool for Scratch. Our key\ninsight is that simply presenting the correct program is pedagogically\nineffective. In contrast, our interactive, step-by-step guided system promotes\na more effective learning experience. More broadly, what constitutes effective\nfeedback in block-based programming remains an open question. Our evaluation\nprovides new evidence that step-by-step tutoring significantly enhances\nlearning outcomes, outperforming both direct-answer approaches and current\nautomated feedback generation tools.", "AI": {"tldr": "Stitch\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7f16\u7a0b\u8f85\u5bfc\u7cfb\u7edf\uff0c\u901a\u8fc7\u9010\u6b65\u811a\u624b\u67b6\u5f0f\u6307\u5bfc\u53d6\u4ee3\u76f4\u63a5\u5c55\u793a\u7b54\u6848\uff0c\u5e2e\u52a9\u5b66\u4e60\u8005\u7406\u89e3\u9519\u8bef\u5e76\u9009\u62e9\u6027\u4fee\u590d\uff0c\u663e\u8457\u63d0\u5347\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u8c03\u8bd5\u5de5\u4f5c\u6d41\u76f4\u63a5\u5c55\u793a\u6b63\u786e\u7b54\u6848\uff0c\u867d\u7136\u80fd\u4fee\u590d\u9519\u8bef\u4f46\u524a\u5f31\u4e86\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u7684\u57f9\u517b\u3002\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u53cd\u9988\u673a\u5236\u6765\u4fc3\u8fdb\u5b66\u4e60\u3002", "method": "\u4f7f\u7528Diff-Analyze\u6a21\u5757\u5bf9\u6bd4\u5b66\u751f\u9879\u76ee\u4e0e\u53c2\u8003\u5b9e\u73b0\uff0c\u8bc6\u522b\u5173\u952e\u5dee\u5f02\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u91ca\u5dee\u5f02\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u81ea\u5b9a\u4e49\u6e32\u67d3\u5f15\u64ce\u9ad8\u4eae\u663e\u793a\uff0c\u652f\u6301\u5b66\u4e60\u8005\u9009\u62e9\u6027\u5e94\u7528\u90e8\u5206\u4fee\u590d\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0cStitch\u5728\u63d0\u5347\u5b66\u4e60\u6548\u679c\u65b9\u9762\u4f18\u4e8e\u76f4\u63a5\u5c55\u793a\u7b54\u6848\u7684\u65b9\u6cd5\u548c\u73b0\u6709\u81ea\u52a8\u5316\u53cd\u9988\u751f\u6210\u5de5\u5177\u3002", "conclusion": "\u9010\u6b65\u8f85\u5bfc\u7cfb\u7edf\u6bd4\u76f4\u63a5\u5c55\u793a\u7b54\u6848\u66f4\u6709\u6548\uff0c\u4e3a\u57fa\u4e8e\u5757\u7684\u7f16\u7a0b\u73af\u5883\u4e2d\u7684\u6709\u6548\u53cd\u9988\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u8bc1\u636e\u3002"}}
{"id": "2510.26143", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26143", "abs": "https://arxiv.org/abs/2510.26143", "authors": ["Bo Pang", "Deqian Kong", "Silvio Savarese", "Caiming Xiong", "Yingbo Zhou"], "title": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math", "comment": "9 pages", "summary": "Reinforcement learning (RL) can elicit strong reasoning in large language\nmodels (LLMs), yet most open efforts focus on math and code. We propose\nReasoning Curriculum, a simple two-stage curriculum that first elicits\nreasoning skills in pretraining-aligned domains such as math, then adapts and\nrefines these skills across other domains via joint RL. Stage 1 performs a\nbrief cold start and then math-only RL with verifiable rewards to develop\nreasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and\nconsolidate these skills. The curriculum is minimal and backbone-agnostic,\nrequiring no specialized reward models beyond standard verifiability checks.\nEvaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning\ncurriculum yields consistent gains. Ablations and a cognitive-skill analysis\nindicate that both stages are necessary and that math-first elicitation\nincreases cognitive behaviors important for solving complex problems. Reasoning\nCurriculum provides a compact, easy-to-adopt recipe for general reasoning.", "AI": {"tldr": "\u63d0\u51faReasoning Curriculum\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff0c\u5148\u5728\u6570\u5b66\u9886\u57df\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u57f9\u517b\u63a8\u7406\u80fd\u529b\uff0c\u7136\u540e\u5728\u591a\u9886\u57df\u8054\u5408\u8bad\u7ec3\u4e2d\u8fc1\u79fb\u548c\u5de9\u56fa\u8fd9\u4e9b\u80fd\u529b\uff0c\u65e0\u9700\u4e13\u95e8\u5956\u52b1\u6a21\u578b\u5373\u53ef\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u4e3b\u8981\u5173\u6ce8\u6570\u5b66\u548c\u4ee3\u7801\u9886\u57df\uff0c\u7f3a\u4e4f\u5bf9\u5176\u4ed6\u9886\u57df\u63a8\u7406\u80fd\u529b\u7684\u7cfb\u7edf\u6027\u57f9\u517b\uff0c\u9700\u8981\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\uff1a\u7b2c\u4e00\u9636\u6bb5\u5728\u6570\u5b66\u9886\u57df\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff0c\u5229\u7528\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\u57f9\u517b\u63a8\u7406\u6280\u80fd\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5728\u591a\u9886\u57df\u6df7\u5408\u6570\u636e\u4e0a\u8fdb\u884c\u8054\u5408\u5f3a\u5316\u5b66\u4e60\uff0c\u8fc1\u79fb\u548c\u5de9\u56fa\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728Qwen3-4B\u548cLlama-3.1-8B\u6a21\u578b\u4e0a\u7684\u591a\u9886\u57df\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u5e26\u6765\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0c\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u4e24\u4e2a\u9636\u6bb5\u90fd\u662f\u5fc5\u8981\u7684\u3002", "conclusion": "Reasoning Curriculum\u63d0\u4f9b\u4e86\u4e00\u79cd\u7d27\u51d1\u4e14\u6613\u4e8e\u91c7\u7528\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u63d0\u5347\u65b9\u6848\uff0c\u6570\u5b66\u4f18\u5148\u7684\u63a8\u7406\u6fc0\u53d1\u7b56\u7565\u80fd\u589e\u5f3a\u89e3\u51b3\u590d\u6742\u95ee\u9898\u6240\u9700\u7684\u5173\u952e\u8ba4\u77e5\u884c\u4e3a\u3002"}}
{"id": "2510.26523", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26523", "abs": "https://arxiv.org/abs/2510.26523", "authors": ["Shuaishuai Liu", "Gergely Acs", "Gergely Bicz\u00f3k"], "title": "Interdependent Privacy in Smart Homes: Hunting for Bystanders in Privacy Policies", "comment": "18 pages, 2 figures", "summary": "Smart home devices such as video doorbells and security cameras are becoming\nincreasingly common in everyday life. While these devices offer convenience and\nsafety, they also raise new privacy concerns: how these devices affect others,\nlike neighbors, visitors, or people passing by. This issue is generally known\nas interdependent privacy, where one person's actions (or inaction) may impact\nthe privacy of others, and, specifically, bystander privacy in the context of\nsmart homes. Given lax data protection regulations in terms of shared physical\nspaces and amateur joint data controllers, we expect that the privacy policies\nof smart home products reflect the missing regulatory incentives. This paper\npresents a focused privacy policy analysis of 20 video doorbell and smart\ncamera products, concentrating explicitly on the bystander aspect. We show that\nalthough some of the vendors acknowledge bystanders, they address it only to\nthe extent of including disclaimers, shifting the ethical responsibility for\ncollecting the data of non-users to the device owner. In addition, we identify\nand examine real-world cases related to bystander privacy, demonstrating how\ncurrent deployments can impact non-users. Based on our findings, we analyze\nvendor privacy policies in light of existing legal frameworks and technical\ncapabilities, and we provide practical recommendations for both policy language\nand system design to enhance transparency and empower both bystanders and\ndevice owners.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e8620\u6b3e\u89c6\u9891\u95e8\u94c3\u548c\u667a\u80fd\u6444\u50cf\u5934\u7684\u9690\u79c1\u653f\u7b56\uff0c\u91cd\u70b9\u5173\u6ce8\u65c1\u89c2\u8005\u9690\u79c1\u95ee\u9898\uff0c\u53d1\u73b0\u5382\u5546\u4e3b\u8981\u901a\u8fc7\u514d\u8d23\u58f0\u660e\u5c06\u6536\u96c6\u975e\u7528\u6237\u6570\u636e\u7684\u8d23\u4efb\u8f6c\u5ac1\u7ed9\u8bbe\u5907\u6240\u6709\u8005\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u667a\u80fd\u5bb6\u5c45\u8bbe\u5907\u5728\u63d0\u4f9b\u4fbf\u5229\u548c\u5b89\u5168\u7684\u540c\u65f6\uff0c\u5bf9\u90bb\u5c45\u3001\u8bbf\u5ba2\u7b49\u65c1\u89c2\u8005\u7684\u9690\u79c1\u4ea7\u751f\u4e86\u65b0\u7684\u5a01\u80c1\uff0c\u8fd9\u79cd\u76f8\u4e92\u4f9d\u8d56\u7684\u9690\u79c1\u95ee\u9898\u5728\u73b0\u6709\u6cd5\u89c4\u4e0b\u7f3a\u4e4f\u6709\u6548\u76d1\u7ba1\u3002", "method": "\u5bf920\u6b3e\u89c6\u9891\u95e8\u94c3\u548c\u667a\u80fd\u6444\u50cf\u5934\u4ea7\u54c1\u8fdb\u884c\u9690\u79c1\u653f\u7b56\u5206\u6790\uff0c\u91cd\u70b9\u5173\u6ce8\u65c1\u89c2\u8005\u9690\u79c1\u65b9\u9762\uff0c\u5e76\u7ed3\u5408\u5b9e\u9645\u6848\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0c\u867d\u7136\u90e8\u5206\u5382\u5546\u627f\u8ba4\u65c1\u89c2\u8005\u9690\u79c1\u95ee\u9898\uff0c\u4f46\u4ec5\u901a\u8fc7\u514d\u8d23\u58f0\u660e\u5c06\u8d23\u4efb\u8f6c\u79fb\u7ed9\u8bbe\u5907\u6240\u6709\u8005\uff0c\u672a\u80fd\u63d0\u4f9b\u5b9e\u8d28\u6027\u4fdd\u62a4\u3002\u5b9e\u9645\u6848\u4f8b\u8868\u660e\u5f53\u524d\u90e8\u7f72\u5bf9\u975e\u7528\u6237\u4ea7\u751f\u4e86\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u9700\u8981\u4ece\u653f\u7b56\u8bed\u8a00\u548c\u7cfb\u7edf\u8bbe\u8ba1\u4e24\u65b9\u9762\u6539\u8fdb\uff0c\u63d0\u9ad8\u900f\u660e\u5ea6\u5e76\u8d4b\u4e88\u65c1\u89c2\u8005\u548c\u8bbe\u5907\u6240\u6709\u8005\u66f4\u591a\u6743\u5229\uff0c\u4ee5\u66f4\u597d\u5730\u4fdd\u62a4\u76f8\u4e92\u4f9d\u8d56\u7684\u9690\u79c1\u3002"}}
{"id": "2510.26676", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26676", "abs": "https://arxiv.org/abs/2510.26676", "authors": ["Samiha Shimmi", "Nicholas M. Synovic", "Mona Rahimi", "George K. Thiruvathukal"], "title": "Process-based Indicators of Vulnerability Re-Introducing Code Changes: An Exploratory Case Study", "comment": "9 pages, 6 figures; Samiha Shimmi and Nicholas M. Synovic contributed\n  equally to this work (co-first authors); Mona Rahimi and George K.\n  Thiruvathukal contributed equally to this work (co-supervisors)", "summary": "Software vulnerabilities often persist or re-emerge even after being fixed,\nrevealing the complex interplay between code evolution and socio-technical\nfactors. While source code metrics provide useful indicators of\nvulnerabilities, software engineering process metrics can uncover patterns that\nlead to their introduction. Yet few studies have explored whether process\nmetrics can reveal risky development activities over time -- insights that are\nessential for anticipating and mitigating software vulnerabilities. This work\nhighlights the critical role of process metrics along with code changes in\nunderstanding and mitigating vulnerability reintroduction. We move beyond\nfile-level prediction and instead analyze security fixes at the commit level,\nfocusing not only on whether a single fix introduces a vulnerability but also\non the longer sequences of changes through which vulnerabilities evolve and\nre-emerge. Our approach emphasizes that reintroduction is rarely the result of\none isolated action, but emerges from cumulative development activities and\nsocio-technical conditions. To support this analysis, we conducted a case study\non the ImageMagick project by correlating longitudinal process metrics such as\nbus factor, issue density, and issue spoilage with vulnerability reintroduction\nactivities, encompassing 76 instances of reintroduced vulnerabilities. Our\nfindings show that reintroductions often align with increased issue spoilage\nand fluctuating issue density, reflecting short-term inefficiencies in issue\nmanagement and team responsiveness. These observations provide a foundation for\nbroader studies that combine process and code metrics to predict risky fixes\nand strengthen software security.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u6790ImageMagick\u9879\u76ee\uff0c\u53d1\u73b0\u8f6f\u4ef6\u6f0f\u6d1e\u91cd\u65b0\u5f15\u5165\u4e0e\u5f00\u53d1\u8fc7\u7a0b\u6307\u6807\uff08\u5982\u95ee\u9898\u79ef\u538b\u3001\u95ee\u9898\u5bc6\u5ea6\uff09\u5bc6\u5207\u76f8\u5173\uff0c\u5f3a\u8c03\u9700\u8981\u7ed3\u5408\u8fc7\u7a0b\u6307\u6807\u548c\u4ee3\u7801\u6307\u6807\u6765\u9884\u6d4b\u98ce\u9669\u4fee\u590d\u3002", "motivation": "\u8f6f\u4ef6\u6f0f\u6d1e\u5728\u4fee\u590d\u540e\u7ecf\u5e38\u6301\u7eed\u5b58\u5728\u6216\u91cd\u65b0\u51fa\u73b0\uff0c\u73b0\u6709\u7814\u7a76\u5f88\u5c11\u63a2\u7d22\u8fc7\u7a0b\u6307\u6807\u662f\u5426\u80fd\u63ed\u793a\u968f\u65f6\u95f4\u63a8\u79fb\u7684\u98ce\u9669\u5f00\u53d1\u6d3b\u52a8\uff0c\u8fd9\u5bf9\u9884\u6d4b\u548c\u7f13\u89e3\u8f6f\u4ef6\u6f0f\u6d1e\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5728ImageMagick\u9879\u76ee\u4e2d\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u5c06\u7eb5\u5411\u8fc7\u7a0b\u6307\u6807\uff08\u5982\u603b\u7ebf\u56e0\u5b50\u3001\u95ee\u9898\u5bc6\u5ea6\u3001\u95ee\u9898\u79ef\u538b\uff09\u4e0e\u6f0f\u6d1e\u91cd\u65b0\u5f15\u5165\u6d3b\u52a8\u76f8\u5173\u8054\uff0c\u6db5\u76d676\u4e2a\u91cd\u65b0\u5f15\u5165\u7684\u6f0f\u6d1e\u5b9e\u4f8b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u91cd\u65b0\u5f15\u5165\u901a\u5e38\u4e0e\u95ee\u9898\u79ef\u538b\u589e\u52a0\u548c\u95ee\u9898\u5bc6\u5ea6\u6ce2\u52a8\u76f8\u4e00\u81f4\uff0c\u53cd\u6620\u4e86\u95ee\u9898\u7ba1\u7406\u548c\u56e2\u961f\u54cd\u5e94\u80fd\u529b\u7684\u77ed\u671f\u4f4e\u6548\u3002", "conclusion": "\u6f0f\u6d1e\u91cd\u65b0\u5f15\u5165\u5f88\u5c11\u662f\u5b64\u7acb\u884c\u52a8\u7684\u7ed3\u679c\uff0c\u800c\u662f\u7d2f\u79ef\u5f00\u53d1\u6d3b\u52a8\u548c\u793e\u4f1a\u6280\u672f\u6761\u4ef6\u7684\u4ea7\u7269\uff0c\u8fc7\u7a0b\u6307\u6807\u4e0e\u4ee3\u7801\u53d8\u66f4\u5728\u7406\u89e3\u548c\u7f13\u89e3\u6f0f\u6d1e\u91cd\u65b0\u5f15\u5165\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2510.26144", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26144", "abs": "https://arxiv.org/abs/2510.26144", "authors": ["Annan Li", "Chufan Wu", "Zengle Ge", "Yee Hin Chong", "Zhinan Hou", "Lizhe Cao", "Cheng Ju", "Jianmin Wu", "Huaiming Li", "Haobo Zhang", "Shenghao Feng", "Mo Zhao", "Fengzhi Qiu", "Rui Yang", "Mengmeng Zhang", "Wenyi Zhu", "Yingying Sun", "Quan Sun", "Shunhao Yan", "Danyu Liu", "Dawei Yin", "Dou Shen"], "title": "The FM Agent", "comment": null, "summary": "Large language models (LLMs) are catalyzing the development of autonomous AI\nresearch agents for scientific and engineering discovery. We present FM Agent,\na novel and general-purpose multi-agent framework that leverages a synergistic\ncombination of LLM-based reasoning and large-scale evolutionary search to\naddress complex real-world challenges. The core of FM Agent integrates several\nkey innovations: 1) a cold-start initialization phase incorporating expert\nguidance, 2) a novel evolutionary sampling strategy for iterative optimization,\n3) domain-specific evaluators that combine correctness, effectiveness, and\nLLM-supervised feedback, and 4) a distributed, asynchronous execution\ninfrastructure built on Ray. Demonstrating broad applicability, our system has\nbeen evaluated across diverse domains, including operations research, machine\nlearning, GPU kernel optimization, and classical mathematical problems. FM\nAgent reaches state-of-the-art results autonomously, without human\ninterpretation or tuning -- 1976.3 on ALE-Bench (+5.2\\%), 43.56\\% on MLE-Bench\n(+4.0pp), up to 20x speedups on KernelBench, and establishes new\nstate-of-the-art(SOTA) results on several classical mathematical problems.\nBeyond academic benchmarks, FM Agent shows considerable promise for both\nlarge-scale enterprise R\\&D workflows and fundamental scientific research,\nwhere it can accelerate innovation, automate complex discovery processes, and\ndeliver substantial engineering and scientific advances with broader societal\nimpact.", "AI": {"tldr": "FM Agent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7ed3\u5408LLM\u63a8\u7406\u548c\u5927\u89c4\u6a21\u8fdb\u5316\u641c\u7d22\uff0c\u5728\u591a\u4e2a\u9886\u57df\u5b9e\u73b0SOTA\u7ed3\u679c\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002", "motivation": "\u5229\u7528LLM\u63a8\u52a8\u81ea\u4e3bAI\u7814\u7a76\u4ee3\u7406\u7684\u53d1\u5c55\uff0c\u89e3\u51b3\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u6311\u6218\u3002", "method": "\u96c6\u6210\u51b7\u542f\u52a8\u521d\u59cb\u5316\u3001\u8fdb\u5316\u91c7\u6837\u7b56\u7565\u3001\u9886\u57df\u7279\u5b9a\u8bc4\u4f30\u5668\u548c\u5206\u5e03\u5f0f\u5f02\u6b65\u6267\u884c\u57fa\u7840\u8bbe\u65bd\u3002", "result": "\u5728ALE-Bench\u8fbe\u52301976.3(+5.2%)\u3001MLE-Bench 43.56%(+4.0pp)\u3001KernelBench\u6700\u9ad820\u500d\u52a0\u901f\uff0c\u5e76\u5728\u7ecf\u5178\u6570\u5b66\u95ee\u9898\u4e0a\u5efa\u7acb\u65b0SOTA\u3002", "conclusion": "FM Agent\u5728\u4f01\u4e1a\u7814\u53d1\u548c\u57fa\u7840\u79d1\u5b66\u7814\u7a76\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u52a0\u901f\u521b\u65b0\u548c\u81ea\u52a8\u5316\u590d\u6742\u53d1\u73b0\u8fc7\u7a0b\u3002"}}
{"id": "2510.26555", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26555", "abs": "https://arxiv.org/abs/2510.26555", "authors": ["Chunyi Zhang", "Jin Zeng", "Xiaoqi Li"], "title": "A Comprehensive Evaluation and Practice of System Penetration Testing", "comment": null, "summary": "With the rapid advancement of information technology, the complexity of\napplications continues to increase, and the cybersecurity challenges we face\nare also escalating. This paper aims to investigate the methods and practices\nof system security penetration testing, exploring how to enhance system\nsecurity through systematic penetration testing processes and technical\napproaches. It also examines existing penetration tools, analyzing their\nstrengths, weaknesses, and applicable domains to guide penetration testers in\ntool selection. Furthermore, based on the penetration testing process outlined\nin this paper, appropriate tools are selected to replicate attack processes\nusing target ranges and target machines. Finally, through practical case\nanalysis, lessons learned from successful attacks are summarized to inform\nfuture research.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7cfb\u7edf\u5b89\u5168\u6e17\u900f\u6d4b\u8bd5\u7684\u65b9\u6cd5\u4e0e\u5b9e\u8df5\uff0c\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u6e17\u900f\u6d4b\u8bd5\u6d41\u7a0b\u548c\u6280\u672f\u624b\u6bb5\u63d0\u5347\u7cfb\u7edf\u5b89\u5168\u6027\uff0c\u5206\u6790\u73b0\u6709\u6e17\u900f\u5de5\u5177\u7684\u7279\u70b9\u548c\u9002\u7528\u9886\u57df\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u603b\u7ed3\u653b\u51fb\u7ecf\u9a8c\u3002", "motivation": "\u968f\u7740\u4fe1\u606f\u6280\u672f\u5feb\u901f\u53d1\u5c55\uff0c\u5e94\u7528\u590d\u6742\u6027\u4e0d\u65ad\u589e\u52a0\uff0c\u7f51\u7edc\u5b89\u5168\u6311\u6218\u65e5\u76ca\u4e25\u5cfb\uff0c\u9700\u8981\u7814\u7a76\u6709\u6548\u7684\u7cfb\u7edf\u5b89\u5168\u6e17\u900f\u6d4b\u8bd5\u65b9\u6cd5\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u5316\u7684\u6e17\u900f\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u5206\u6790\u73b0\u6709\u6e17\u900f\u5de5\u5177\u7684\u4f18\u52bf\u3001\u52a3\u52bf\u548c\u9002\u7528\u9886\u57df\uff0c\u9009\u62e9\u5408\u9002\u5de5\u5177\u5728\u76ee\u6807\u8303\u56f4\u548c\u76ee\u6807\u673a\u5668\u4e0a\u590d\u73b0\u653b\u51fb\u8fc7\u7a0b\uff0c\u5e76\u8fdb\u884c\u5b9e\u9645\u6848\u4f8b\u5206\u6790\u3002", "result": "\u901a\u8fc7\u5b9e\u8df5\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u6e17\u900f\u6d4b\u8bd5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u6210\u529f\u590d\u73b0\u4e86\u653b\u51fb\u8fc7\u7a0b\uff0c\u5e76\u603b\u7ed3\u4e86\u653b\u51fb\u7ecf\u9a8c\u6559\u8bad\u3002", "conclusion": "\u7cfb\u7edf\u5316\u7684\u6e17\u900f\u6d4b\u8bd5\u6d41\u7a0b\u548c\u5408\u9002\u7684\u5de5\u5177\u9009\u62e9\u5bf9\u4e8e\u63d0\u5347\u7cfb\u7edf\u5b89\u5168\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u5b9e\u9645\u6848\u4f8b\u5206\u6790\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2510.26699", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26699", "abs": "https://arxiv.org/abs/2510.26699", "authors": ["Aylton Almeida", "Laerte Xavier", "Marco Tulio Valente"], "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "comment": null, "summary": "Keeping software systems up to date is essential to avoid technical debt,\nsecurity vulnerabilities, and the rigidity typical of legacy systems. However,\nupdating libraries and frameworks remains a time consuming and error-prone\nprocess. Recent advances in Large Language Models (LLMs) and agentic coding\nsystems offer new opportunities for automating such maintenance tasks. In this\npaper, we evaluate the update of a well-known Python library, SQLAlchemy,\nacross a dataset of ten client applications. For this task, we use the Github's\nCopilot Agent Mode, an autonomous AI systema capable of planning and executing\nmulti-step migration workflows. To assess the effectiveness of the automated\nmigration, we also introduce Migration Coverage, a metric that quantifies the\nproportion of API usage points correctly migrated. The results of our study\nshow that the LLM agent was capable of migrating functionalities and API usages\nbetween SQLAlchemy versions (migration coverage: 100%, median), but failed to\nmaintain the application functionality, leading to a low test-pass rate\n(39.75%, median).", "AI": {"tldr": "\u4f7f\u7528GitHub Copilot Agent Mode\u81ea\u52a8\u8fc1\u79fbSQLAlchemy\u5e93\u7248\u672c\uff0c\u5728API\u8fc1\u79fb\u8986\u76d6\u7387\u8fbe\u5230100%\u7684\u60c5\u51b5\u4e0b\uff0c\u4f46\u5e94\u7528\u529f\u80fd\u6d4b\u8bd5\u901a\u8fc7\u7387\u4ec5\u4e3a39.75%\u3002", "motivation": "\u8f6f\u4ef6\u7cfb\u7edf\u66f4\u65b0\u5bf9\u4e8e\u907f\u514d\u6280\u672f\u503a\u52a1\u3001\u5b89\u5168\u6f0f\u6d1e\u548c\u9057\u7559\u7cfb\u7edf\u50f5\u5316\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u66f4\u65b0\u8fc7\u7a0b\u8017\u65f6\u4e14\u5bb9\u6613\u51fa\u9519\u3002LLM\u548c\u667a\u80fd\u7f16\u7801\u7cfb\u7edf\u4e3a\u81ea\u52a8\u5316\u6b64\u7c7b\u7ef4\u62a4\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002", "method": "\u4f7f\u7528GitHub\u7684Copilot Agent Mode\uff08\u4e00\u79cd\u80fd\u591f\u89c4\u5212\u548c\u6267\u884c\u591a\u6b65\u9aa4\u8fc1\u79fb\u5de5\u4f5c\u6d41\u7684\u81ea\u4e3bAI\u7cfb\u7edf\uff09\uff0c\u572810\u4e2a\u5ba2\u6237\u7aef\u5e94\u7528\u6570\u636e\u96c6\u4e2d\u8bc4\u4f30SQLAlchemy\u5e93\u7684\u66f4\u65b0\u3002\u5f15\u5165\u8fc1\u79fb\u8986\u76d6\u7387\u6307\u6807\u6765\u91cf\u5316\u6b63\u786e\u8fc1\u79fb\u7684API\u4f7f\u7528\u70b9\u6bd4\u4f8b\u3002", "result": "LLM\u4ee3\u7406\u80fd\u591f\u6210\u529f\u8fc1\u79fbSQLAlchemy\u7248\u672c\u95f4\u7684\u529f\u80fd\u548cAPI\u4f7f\u7528\uff08\u8fc1\u79fb\u8986\u76d6\u7387\u4e2d\u4f4d\u6570\uff1a100%\uff09\uff0c\u4f46\u672a\u80fd\u4fdd\u6301\u5e94\u7528\u7a0b\u5e8f\u529f\u80fd\uff0c\u5bfc\u81f4\u6d4b\u8bd5\u901a\u8fc7\u7387\u8f83\u4f4e\uff08\u4e2d\u4f4d\u6570\uff1a39.75%\uff09\u3002", "conclusion": "\u867d\u7136LLM\u4ee3\u7406\u5728API\u8fc1\u79fb\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u4fdd\u6301\u5e94\u7528\u529f\u80fd\u5b8c\u6574\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u6311\u6218\uff0c\u8868\u660e\u81ea\u52a8\u5316\u8fc1\u79fb\u7cfb\u7edf\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u786e\u4fdd\u529f\u80fd\u6b63\u786e\u6027\u3002"}}
{"id": "2510.26167", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26167", "abs": "https://arxiv.org/abs/2510.26167", "authors": ["Renhao Li", "Jianhong Tu", "Yang Su", "Hamid Alinejad-Rokny", "Derek F. Wong", "Junyang Lin", "Min Yang"], "title": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning", "comment": null, "summary": "Reward models (RMs) play a critical role in aligning large language models\n(LLMs) with human preferences. Yet in the domain of tool learning, the lack of\nRMs specifically designed for function-calling tasks has limited progress\ntoward more capable agentic AI. We introduce ToolRM, a family of lightweight\ngenerative RMs tailored for general tool-use scenarios. To build these models,\nwe propose a novel pipeline that constructs pairwise preference data using\nrule-based scoring and multidimensional sampling. This yields\nToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique\ntasks that supports reinforcement learning with verifiable feedback. To\nevaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on\nthe agentic evaluation suite BFCL. Trained on our constructed data, models from\nthe Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially\noutperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward\njudgments. Beyond training objectives, ToolRM generalizes to broader critique\ntasks, including Best-of-N sampling and self-correction. Experiments on\nACEBench highlight its effectiveness and efficiency, enabling inference-time\nscaling and reducing output token usage by over 66%. We release data and model\ncheckpoints to facilitate future research.", "AI": {"tldr": "ToolRM\u662f\u4e00\u4e2a\u4e13\u4e3a\u5de5\u5177\u4f7f\u7528\u573a\u666f\u8bbe\u8ba1\u7684\u8f7b\u91cf\u7ea7\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\u5bb6\u65cf\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u6784\u5efa\u6d41\u7a0b\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u51fd\u6570\u8c03\u7528\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5728\u5de5\u5177\u5b66\u4e60\u9886\u57df\uff0c\u7f3a\u4e4f\u4e13\u95e8\u4e3a\u51fd\u6570\u8c03\u7528\u4efb\u52a1\u8bbe\u8ba1\u7684\u5956\u52b1\u6a21\u578b\uff0c\u8fd9\u9650\u5236\u4e86\u667a\u80fd\u4ee3\u7406AI\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u6570\u636e\u6784\u5efa\u6d41\u7a0b\uff0c\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u8bc4\u5206\u548c\u591a\u7ef4\u91c7\u6837\u6784\u5efa\u6210\u5bf9\u504f\u597d\u6570\u636e\uff0c\u521b\u5efaToolPref-Pairwise-30K\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1TRBench$_{BFCL}$\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u57fa\u4e8eQwen3-4B/8B\u7cfb\u5217\u7684\u6a21\u578b\u5728\u6210\u5bf9\u5956\u52b1\u5224\u65ad\u4e2d\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe14.28%\uff0c\u663e\u8457\u4f18\u4e8eClaude 4\u548cOpenAI o3\u7b49\u524d\u6cbf\u6a21\u578b\uff0c\u5728\u63a8\u7406\u65f6\u51cf\u5c11\u8d85\u8fc766%\u7684\u8f93\u51fatoken\u4f7f\u7528\u3002", "conclusion": "ToolRM\u4e0d\u4ec5\u6709\u6548\u63d0\u5347\u5de5\u5177\u4f7f\u7528\u6027\u80fd\uff0c\u8fd8\u80fd\u6cdb\u5316\u5230\u66f4\u5e7f\u6cdb\u7684\u6279\u5224\u4efb\u52a1\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6570\u636e\u548c\u6a21\u578b\u68c0\u67e5\u70b9\u3002"}}
{"id": "2510.26610", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26610", "abs": "https://arxiv.org/abs/2510.26610", "authors": ["Weixuan Chen", "Qianqian Yang"], "title": "A DRL-Empowered Multi-Level Jamming Approach for Secure Semantic Communication", "comment": null, "summary": "Semantic communication (SemCom) aims to transmit only task-relevant\ninformation, thereby improving communication efficiency but also exposing\nsemantic information to potential eavesdropping. In this paper, we propose a\ndeep reinforcement learning (DRL)-empowered multi-level jamming approach to\nenhance the security of SemCom systems over MIMO fading wiretap channels. This\napproach combines semantic layer jamming, achieved by encoding task-irrelevant\ntext, and physical layer jamming, achieved by encoding random Gaussian noise.\nThese two-level jamming signals are superposed with task-relevant semantic\ninformation to protect the transmitted semantics from eavesdropping. A deep\ndeterministic policy gradient (DDPG) algorithm is further introduced to\ndynamically design and optimize the precoding matrices for both taskrelevant\nsemantic information and multi-level jamming signals, aiming to enhance the\nlegitimate user's image reconstruction while degrading the eavesdropper's\nperformance. To jointly train the SemCom model and the DDPG agent, we propose\nan alternating optimization strategy where the two modules are updated\niteratively. Experimental results demonstrate that, compared with both the\nencryption-based (ESCS) and encoded jammer-based (EJ) benchmarks, our method\nachieves comparable security while improving the legitimate user's peak\nsignalto-noise ratio (PSNR) by up to approximately 0.6 dB.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u7ea7\u5e72\u6270\u65b9\u6cd5\uff0c\u7ed3\u5408\u8bed\u4e49\u5c42\u548c\u7269\u7406\u5c42\u5e72\u6270\u6765\u4fdd\u62a4\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u5b89\u5168\uff0c\u901a\u8fc7DDPG\u7b97\u6cd5\u52a8\u6001\u4f18\u5316\u9884\u7f16\u7801\u77e9\u9635\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u63d0\u5347\u5408\u6cd5\u7528\u6237\u7684\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u8bed\u4e49\u901a\u4fe1\u4ec5\u4f20\u8f93\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u63d0\u9ad8\u4e86\u901a\u4fe1\u6548\u7387\uff0c\u4f46\u540c\u65f6\u4e5f\u5c06\u8bed\u4e49\u4fe1\u606f\u66b4\u9732\u7ed9\u6f5c\u5728\u7a83\u542c\u8005\uff0c\u9700\u8981\u589e\u5f3a\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u7ea7\u5e72\u6270\u65b9\u6cd5\uff1a\u8bed\u4e49\u5c42\u5e72\u6270\uff08\u7f16\u7801\u4efb\u52a1\u65e0\u5173\u6587\u672c\uff09+\u7269\u7406\u5c42\u5e72\u6270\uff08\u7f16\u7801\u9ad8\u65af\u566a\u58f0\uff09\uff0c\u7ed3\u5408DDPG\u7b97\u6cd5\u52a8\u6001\u8bbe\u8ba1\u9884\u7f16\u7801\u77e9\u9635\uff0c\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u7b56\u7565\u8054\u5408\u8bad\u7ec3\u8bed\u4e49\u901a\u4fe1\u6a21\u578b\u548cDDPG\u4ee3\u7406\u3002", "result": "\u76f8\u6bd4\u52a0\u5bc6\u57fa\u51c6(ESCS)\u548c\u7f16\u7801\u5e72\u6270\u57fa\u51c6(EJ)\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u53ef\u6bd4\u5b89\u5168\u6027\u7684\u540c\u65f6\uff0c\u5c06\u5408\u6cd5\u7528\u6237\u7684\u5cf0\u503c\u4fe1\u566a\u6bd4(PSNR)\u63d0\u5347\u7ea60.6dB\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u7ea7\u5e72\u6270\u65b9\u6cd5\u80fd\u6709\u6548\u4fdd\u62a4\u8bed\u4e49\u901a\u4fe1\u5b89\u5168\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u663e\u8457\u6539\u5584\u5408\u6cd5\u7528\u6237\u7684\u901a\u4fe1\u8d28\u91cf\u3002"}}
{"id": "2510.26793", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26793", "abs": "https://arxiv.org/abs/2510.26793", "authors": ["Nafid Enan", "Gias Uddin"], "title": "Optimized Log Parsing with Syntactic Modifications", "comment": null, "summary": "Logs provide valuable insights into system runtime and assist in software\ndevelopment and maintenance. Log parsing, which converts semi-structured log\ndata into structured log data, is often the first step in automated log\nanalysis. Given the wide range of log parsers utilizing diverse techniques, it\nis essential to evaluate them to understand their characteristics and\nperformance. In this paper, we conduct a comprehensive empirical study\ncomparing syntax- and semantic-based log parsers, as well as single-phase and\ntwo-phase parsing architectures. Our experiments reveal that semantic-based\nmethods perform better at identifying the correct templates and syntax-based\nlog parsers are 10 to 1,000 times more efficient and provide better grouping\naccuracy although they fall short in accurate template identification.\nMoreover, two-phase architecture consistently improves accuracy compared to\nsingle-phase architecture. Based on the findings of this study, we propose\nSynLog+, a template identification module that acts as the second phase in a\ntwo-phase log parsing architecture. SynLog+ improves the parsing accuracy of\nsyntax-based and semantic-based log parsers by 236\\% and 20\\% on average,\nrespectively, with virtually no additional runtime cost.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u57fa\u4e8e\u8bed\u6cd5\u548c\u8bed\u4e49\u7684\u65e5\u5fd7\u89e3\u6790\u5668\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u8bed\u4e49\u65b9\u6cd5\u5728\u6a21\u677f\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800c\u8bed\u6cd5\u65b9\u6cd5\u6548\u7387\u66f4\u9ad8\u4e14\u5206\u7ec4\u7cbe\u5ea6\u66f4\u597d\u3002\u57fa\u4e8e\u7814\u7a76\u7ed3\u679c\u63d0\u51fa\u4e86SynLog+\u6a21\u5757\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4e24\u79cd\u89e3\u6790\u5668\u7684\u7cbe\u5ea6\u3002", "motivation": "\u65e5\u5fd7\u89e3\u6790\u662f\u81ea\u52a8\u5316\u65e5\u5fd7\u5206\u6790\u7684\u7b2c\u4e00\u6b65\uff0c\u4f46\u73b0\u6709\u65e5\u5fd7\u89e3\u6790\u5668\u91c7\u7528\u4e0d\u540c\u6280\u672f\u548c\u67b6\u6784\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6765\u7406\u89e3\u5b83\u4eec\u7684\u7279\u6027\u548c\u6027\u80fd\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u6bd4\u8f83\u8bed\u6cd5\u57fa\u548c\u8bed\u4e49\u57fa\u65e5\u5fd7\u89e3\u6790\u5668\uff0c\u4ee5\u53ca\u5355\u9636\u6bb5\u548c\u4e24\u9636\u6bb5\u89e3\u6790\u67b6\u6784\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "\u8bed\u4e49\u65b9\u6cd5\u5728\u6b63\u786e\u8bc6\u522b\u6a21\u677f\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u8bed\u6cd5\u57fa\u89e3\u6790\u5668\u6548\u7387\u9ad810-1000\u500d\u4e14\u5206\u7ec4\u7cbe\u5ea6\u66f4\u597d\u3002\u4e24\u9636\u6bb5\u67b6\u6784\u76f8\u6bd4\u5355\u9636\u6bb5\u67b6\u6784\u80fd\u6301\u7eed\u63d0\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684SynLog+\u6a21\u677f\u8bc6\u522b\u6a21\u5757\u4f5c\u4e3a\u4e24\u9636\u6bb5\u65e5\u5fd7\u89e3\u6790\u67b6\u6784\u7684\u7b2c\u4e8c\u9636\u6bb5\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u8bed\u6cd5\u57fa\u548c\u8bed\u4e49\u57fa\u89e3\u6790\u5668\u7684\u89e3\u6790\u7cbe\u5ea6\uff0c\u4e14\u51e0\u4e4e\u6ca1\u6709\u989d\u5916\u8fd0\u884c\u65f6\u6210\u672c\u3002"}}
{"id": "2510.26238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26238", "abs": "https://arxiv.org/abs/2510.26238", "authors": ["Duc-Hai Nguyen", "Vijayakumar Nanjappan", "Barry O'Sullivan", "Hoang D. Nguyen"], "title": "Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses", "comment": "14 pages, 3 figures, 8 tables", "summary": "Millions of people take surveys every day, from market polls and academic\nstudies to medical questionnaires and customer feedback forms. These datasets\ncapture valuable insights, but their scale and structure present a unique\nchallenge for large language models (LLMs), which otherwise excel at few-shot\nreasoning over open-ended text. Yet, their ability to process questionnaire\ndata or lists of questions crossed with hundreds of respondent rows remains\nunderexplored. Current retrieval and survey analysis tools (e.g., Qualtrics,\nSPSS, REDCap) are typically designed for humans in the workflow, limiting such\ndata integration with LLM and AI-empowered automation. This gap leaves\nscientists, surveyors, and everyday users without evidence-based guidance on\nhow to best represent questionnaires for LLM consumption. We address this by\nintroducing QASU (Questionnaire Analysis and Structural Understanding), a\nbenchmark that probes six structural skills, including answer lookup,\nrespondent count, and multi-hop inference, across six serialization formats and\nmultiple prompt strategies. Experiments on contemporary LLMs show that choosing\nan effective format and prompt combination can improve accuracy by up to 8.8%\npoints compared to suboptimal formats. For specific tasks, carefully adding a\nlightweight structural hint through self-augmented prompting can yield further\nimprovements of 3-4% points on average. By systematically isolating format and\nprompting effects, our open source benchmark offers a simple yet versatile\nfoundation for advancing both research and real-world practice in LLM-based\nquestionnaire analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86QASU\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5904\u7406\u95ee\u5377\u6570\u636e\u7684\u7ed3\u6784\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u9009\u62e9\u5408\u9002\u7684\u5e8f\u5217\u5316\u683c\u5f0f\u548c\u63d0\u793a\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027", "motivation": "\u73b0\u6709\u8c03\u67e5\u5206\u6790\u5de5\u5177\u4e3b\u8981\u9762\u5411\u4eba\u5de5\u64cd\u4f5c\uff0c\u7f3a\u4e4f\u4e0eLLM\u96c6\u6210\u7684\u6307\u5bfc\uff0c\u9650\u5236\u4e86\u95ee\u5377\u6570\u636e\u7684AI\u81ea\u52a8\u5316\u5206\u6790\u80fd\u529b", "method": "\u5f15\u5165QASU\u57fa\u51c6\uff0c\u6d4b\u8bd5\u516d\u79cd\u7ed3\u6784\u5316\u6280\u80fd\uff0c\u6bd4\u8f83\u516d\u79cd\u5e8f\u5217\u5316\u683c\u5f0f\u548c\u591a\u79cd\u63d0\u793a\u7b56\u7565\uff0c\u901a\u8fc7\u81ea\u589e\u5f3a\u63d0\u793a\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u7ed3\u6784\u63d0\u793a", "result": "\u9009\u62e9\u6709\u6548\u7684\u683c\u5f0f\u548c\u63d0\u793a\u7ec4\u5408\u53ef\u5c06\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe8.8\u4e2a\u767e\u5206\u70b9\uff0c\u7279\u5b9a\u4efb\u52a1\u4e2d\u81ea\u589e\u5f3a\u63d0\u793a\u53ef\u989d\u5916\u63d0\u53473-4\u4e2a\u767e\u5206\u70b9", "conclusion": "QASU\u57fa\u51c6\u4e3a\u57fa\u4e8eLLM\u7684\u95ee\u5377\u5206\u6790\u63d0\u4f9b\u4e86\u7b80\u5355\u800c\u591a\u529f\u80fd\u7684\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528"}}
{"id": "2510.26620", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26620", "abs": "https://arxiv.org/abs/2510.26620", "authors": ["Nicholas Pecka", "Lotfi Ben Othmane", "Renee Bryce"], "title": "Toward Automated Security Risk Detection in Large Software Using Call Graph Analysis", "comment": null, "summary": "Threat modeling plays a critical role in the identification and mitigation of\nsecurity risks; however, manual approaches are often labor intensive and prone\nto error. This paper investigates the automation of software threat modeling\nthrough the clustering of call graphs using density-based and community\ndetection algorithms, followed by an analysis of the threats associated with\nthe identified clusters. The proposed method was evaluated through a case study\nof the Splunk Forwarder Operator (SFO), wherein selected clustering metrics\nwere applied to the software's call graph to assess pertinent code-density\nsecurity weaknesses. The results demonstrate the viability of the approach and\nunderscore its potential to facilitate systematic threat assessment. This work\ncontributes to the advancement of scalable, semi-automated threat modeling\nframeworks tailored for modern cloud-native environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u805a\u7c7b\u8c03\u7528\u56fe\u6765\u81ea\u52a8\u5316\u8f6f\u4ef6\u5a01\u80c1\u5efa\u6a21\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u57fa\u4e8e\u5bc6\u5ea6\u548c\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u8bc6\u522b\u4ee3\u7801\u96c6\u7fa4\u5e76\u5206\u6790\u76f8\u5173\u5b89\u5168\u5a01\u80c1\u3002", "motivation": "\u624b\u52a8\u5a01\u80c1\u5efa\u6a21\u65b9\u6cd5\u901a\u5e38\u52b3\u52a8\u5bc6\u96c6\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u5bc6\u5ea6\u57fa\u548c\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u5bf9\u8c03\u7528\u56fe\u8fdb\u884c\u805a\u7c7b\uff0c\u7136\u540e\u5206\u6790\u8bc6\u522b\u51fa\u7684\u96c6\u7fa4\u76f8\u5173\u7684\u5b89\u5168\u5a01\u80c1\u3002", "result": "\u901a\u8fc7\u5bf9Splunk Forwarder Operator\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u4ee3\u7801\u5bc6\u5ea6\u76f8\u5173\u7684\u5b89\u5168\u5f31\u70b9\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u63a8\u8fdb\u9488\u5bf9\u73b0\u4ee3\u4e91\u539f\u751f\u73af\u5883\u7684\u53ef\u6269\u5c55\u3001\u534a\u81ea\u52a8\u5316\u5a01\u80c1\u5efa\u6a21\u6846\u67b6\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.26242", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26242", "abs": "https://arxiv.org/abs/2510.26242", "authors": ["Xinhang Li", "Qing Guo", "Junyu Chen", "Zheng Guo", "Shengzhe Xu", "Lei Li", "Lin Zhang"], "title": "Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles", "comment": null, "summary": "With increasing urban traffic complexity, Traffic Signal Control (TSC) is\nessential for optimizing traffic flow and improving road safety. Large Language\nModels (LLMs) emerge as promising approaches for TSC. However, they are prone\nto hallucinations in emergencies, leading to unreliable decisions that may\ncause substantial delays for emergency vehicles. Moreover, diverse intersection\ntypes present substantial challenges for traffic state encoding and\ncross-intersection training, limiting generalization across heterogeneous\nintersections. Therefore, this paper proposes Retrieval Augmented Generation\n(RAG)-enhanced distributed LLM agents with Emergency response for Generalizable\nTSC (REG-TSC). Firstly, this paper presents an emergency-aware reasoning\nframework, which dynamically adjusts reasoning depth based on the emergency\nscenario and is equipped with a novel Reviewer-based Emergency RAG (RERAG) to\ndistill specific knowledge and guidance from historical cases, enhancing the\nreliability and rationality of agents' emergency decisions. Secondly, this\npaper designs a type-agnostic traffic representation and proposes a\nReward-guided Reinforced Refinement (R3) for heterogeneous intersections. R3\nadaptively samples training experience from diverse intersections with\nenvironment feedback-based priority and fine-tunes LLM agents with a designed\nreward-weighted likelihood loss, guiding REG-TSC toward high-reward policies\nacross heterogeneous intersections. On three real-world road networks with 17\nto 177 heterogeneous intersections, extensive experiments show that REG-TSC\nreduces travel time by 42.00%, queue length by 62.31%, and emergency vehicle\nwaiting time by 83.16%, outperforming other state-of-the-art methods.", "AI": {"tldr": "REG-TSC\u4f7f\u7528RAG\u589e\u5f3a\u7684\u5206\u5e03\u5f0fLLM\u4ee3\u7406\u8fdb\u884c\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\uff0c\u901a\u8fc7\u7d27\u6025\u611f\u77e5\u63a8\u7406\u6846\u67b6\u548c\u7c7b\u578b\u65e0\u5173\u7684\u4ea4\u901a\u8868\u793a\uff0c\u5728\u5f02\u6784\u4ea4\u53c9\u53e3\u5b9e\u73b0\u6cdb\u5316\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u5bfc\u81f4\u4e0d\u53ef\u9760\u51b3\u7b56\uff1b\u540c\u65f6\u4e0d\u540c\u4ea4\u53c9\u53e3\u7c7b\u578b\u7ed9\u4ea4\u901a\u72b6\u6001\u7f16\u7801\u548c\u8de8\u4ea4\u53c9\u53e3\u8bad\u7ec3\u5e26\u6765\u6311\u6218\uff0c\u9650\u5236\u4e86\u6cdb\u5316\u80fd\u529b\u3002", "method": "1. \u7d27\u6025\u611f\u77e5\u63a8\u7406\u6846\u67b6\uff1a\u52a8\u6001\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\uff0c\u4f7f\u7528Reviewer-based Emergency RAG\u4ece\u5386\u53f2\u6848\u4f8b\u4e2d\u63d0\u53d6\u77e5\u8bc6\uff1b2. \u7c7b\u578b\u65e0\u5173\u4ea4\u901a\u8868\u793a\u548cReward-guided Reinforced Refinement\uff1a\u81ea\u9002\u5e94\u91c7\u6837\u8bad\u7ec3\u7ecf\u9a8c\uff0c\u4f7f\u7528\u5956\u52b1\u52a0\u6743\u4f3c\u7136\u635f\u5931\u5fae\u8c03LLM\u4ee3\u7406\u3002", "result": "\u57283\u4e2a\u771f\u5b9e\u9053\u8def\u7f51\u7edc\uff0817-177\u4e2a\u5f02\u6784\u4ea4\u53c9\u53e3\uff09\u4e0a\uff0cREG-TSC\u51cf\u5c11\u65c5\u884c\u65f6\u95f442.00%\u3001\u6392\u961f\u957f\u5ea662.31%\u3001\u7d27\u6025\u8f66\u8f86\u7b49\u5f85\u65f6\u95f483.16%\uff0c\u4f18\u4e8e\u5176\u4ed6\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "REG-TSC\u901a\u8fc7RAG\u589e\u5f3a\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\u7684\u53ef\u9760\u6027\u95ee\u9898\u548c\u5f02\u6784\u4ea4\u53c9\u53e3\u7684\u6cdb\u5316\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u6027\u80fd\u3002"}}
{"id": "2510.26270", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26270", "abs": "https://arxiv.org/abs/2510.26270", "authors": ["Jiazhen Yuan", "Wei Zhao", "Zhengbiao Bai"], "title": "Graph-Enhanced Policy Optimization in LLM Agent Training", "comment": "Under review as a conference paper", "summary": "Group based reinforcement learning (RL) has shown impressive results on\ncomplex reasoning and mathematical tasks. Yet, when applied to train\nmulti-turn, interactive LLM agents, these methods often suffer from structural\nblindness-the inability to exploit the underlying connectivity of the\nenvironment. This manifests in three critical challenges: (1) inefficient,\nunguided exploration, (2) imprecise credit assignment due to overlooking\npivotal states, and (3) myopic planning caused by static reward discounting. We\naddress these issues with Graph-Enhanced Policy Optimization (GEPO), which\ndynamically constructs a state-transition graph from agent experience and\nemploys graph-theoretic centrality to provide three synergistic learning\nsignals: (1)structured intrinsic rewards that guide exploration toward\nhigh-impact states, (2) a graph-enhanced advantage function for topology-aware\ncredit assignment, and (3) a dynamic discount factor adapted to each state's\nstrategic value. On the ALFWorld, WebShop, and a proprietary Workbench\nbenchmarks, GEPO demonstrates strong performance, achieving absolute success\nrate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These\nresults highlight that explicitly modeling environmental structure is a robust,\ngeneralizable strategy for advancing LLM agent training.", "AI": {"tldr": "GEPO\u901a\u8fc7\u6784\u5efa\u72b6\u6001\u8f6c\u79fb\u56fe\u548c\u4f7f\u7528\u56fe\u8bba\u4e2d\u5fc3\u6027\u6765\u89e3\u51b3\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u8f6e\u4ea4\u4e92LLM\u4ee3\u7406\u8bad\u7ec3\u4e2d\u7684\u7ed3\u6784\u76f2\u76ee\u6027\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u8f6e\u4ea4\u4e92LLM\u4ee3\u7406\u8bad\u7ec3\u4e2d\u5b58\u5728\u7684\u7ed3\u6784\u76f2\u76ee\u6027\u95ee\u9898\uff0c\u5305\u62ec\u4f4e\u6548\u63a2\u7d22\u3001\u4e0d\u7cbe\u786e\u4fe1\u7528\u5206\u914d\u548c\u77ed\u89c6\u89c4\u5212\u4e09\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "GEPO\u65b9\u6cd5\u52a8\u6001\u6784\u5efa\u72b6\u6001\u8f6c\u79fb\u56fe\uff0c\u5229\u7528\u56fe\u8bba\u4e2d\u5fc3\u6027\u63d0\u4f9b\u4e09\u4e2a\u534f\u540c\u5b66\u4e60\u4fe1\u53f7\uff1a\u7ed3\u6784\u5316\u5185\u5728\u5956\u52b1\u3001\u56fe\u589e\u5f3a\u4f18\u52bf\u51fd\u6570\u548c\u52a8\u6001\u6298\u6263\u56e0\u5b50\u3002", "result": "\u5728ALFWorld\u3001WebShop\u548c\u4e13\u6709Workbench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGEPO\u5206\u522b\u5b9e\u73b0\u4e86+4.1%\u3001+5.3%\u548c+10.9%\u7684\u7edd\u5bf9\u6210\u529f\u7387\u63d0\u5347\u3002", "conclusion": "\u663e\u5f0f\u5efa\u6a21\u73af\u5883\u7ed3\u6784\u662f\u63a8\u8fdbLLM\u4ee3\u7406\u8bad\u7ec3\u7684\u7a33\u5065\u3001\u53ef\u6cdb\u5316\u7b56\u7565\u3002"}}
{"id": "2510.26309", "categories": ["cs.AI", "cs.IR", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.26309", "abs": "https://arxiv.org/abs/2510.26309", "authors": ["Jiseong Chung", "Ronny Ko", "Wonchul Yoo", "Makoto Onizuka", "Sungmok Kim", "Tae-Wan Kim", "Won-Yong Shin"], "title": "GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance", "comment": "Under review at The Web Conference 2026 (Semantics & Knowledge\n  track). Code will be released upon acceptance. This arXiv v1 contains no\n  repository links to preserve double-blind review", "summary": "Compliance at web scale poses practical challenges: each request may require\na regulatory assessment. Regulatory texts (e.g., the General Data Protection\nRegulation, GDPR) are cross-referential and normative, while runtime contexts\nare expressed in unstructured natural language. This setting motivates us to\nalign semantic information in unstructured text with the structured, normative\nelements of regulations. To this end, we introduce GraphCompliance, a framework\nthat represents regulatory texts as a Policy Graph and runtime contexts as a\nContext Graph, and aligns them. In this formulation, the policy graph encodes\nnormative structure and cross-references, whereas the context graph formalizes\nevents as subject-action-object (SAO) and entity-relation triples. This\nalignment anchors the reasoning of a judge large language model (LLM) in\nstructured information and helps reduce the burden of regulatory interpretation\nand event parsing, enabling a focus on the core reasoning step. In experiments\non 300 GDPR-derived real-world scenarios spanning five evaluation tasks,\nGraphCompliance yields 4.1-7.2 percentage points (pp) higher micro-F1 than\nLLM-only and RAG baselines, with fewer under- and over-predictions, resulting\nin higher recall and lower false positive rates. Ablation studies indicate\ncontributions from each graph component, suggesting that structured\nrepresentations and a judge LLM are complementary for normative reasoning.", "AI": {"tldr": "GraphCompliance\u6846\u67b6\u901a\u8fc7\u5c06\u6cd5\u89c4\u6587\u672c\u8868\u793a\u4e3a\u653f\u7b56\u56fe\uff0c\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u8868\u793a\u4e3a\u4e0a\u4e0b\u6587\u56fe\uff0c\u5e76\u5c06\u4e24\u8005\u5bf9\u9f50\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f51\u7edc\u89c4\u6a21\u5408\u89c4\u6027\u8bc4\u4f30\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u7f51\u7edc\u89c4\u6a21\u5408\u89c4\u6027\u8bc4\u4f30\u7684\u5b9e\u8df5\u6311\u6218\uff1a\u6cd5\u89c4\u6587\u672c\u5177\u6709\u4ea4\u53c9\u5f15\u7528\u548c\u89c4\u8303\u6027\uff0c\u800c\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u662f\u975e\u7ed3\u6784\u5316\u81ea\u7136\u8bed\u8a00\uff0c\u9700\u8981\u5c06\u4e24\u8005\u8bed\u4e49\u4fe1\u606f\u5bf9\u9f50\u3002", "method": "\u5f15\u5165GraphCompliance\u6846\u67b6\uff0c\u6784\u5efa\u653f\u7b56\u56fe\u7f16\u7801\u6cd5\u89c4\u7684\u89c4\u8303\u7ed3\u6784\u548c\u4ea4\u53c9\u5f15\u7528\uff0c\u6784\u5efa\u4e0a\u4e0b\u6587\u56fe\u5c06\u4e8b\u4ef6\u5f62\u5f0f\u5316\u4e3aSAO\u4e09\u5143\u7ec4\u548c\u5b9e\u4f53\u5173\u7cfb\u4e09\u5143\u7ec4\uff0c\u7136\u540e\u5bf9\u9f50\u4e24\u4e2a\u56fe\uff0c\u5e76\u57fa\u4e8e\u7ed3\u6784\u5316\u4fe1\u606f\u8fdb\u884c\u6cd5\u5b98LLM\u63a8\u7406\u3002", "result": "\u5728300\u4e2aGDPR\u884d\u751f\u7684\u771f\u5b9e\u573a\u666f\u5b9e\u9a8c\u4e2d\uff0cGraphCompliance\u6bd4LLM-only\u548cRAG\u57fa\u7ebf\u5728\u5faeF1\u5206\u6570\u4e0a\u9ad8\u51fa4.1-7.2\u4e2a\u767e\u5206\u70b9\uff0c\u5177\u6709\u66f4\u5c11\u7684\u6b20\u9884\u6d4b\u548c\u8fc7\u9884\u6d4b\uff0c\u53ec\u56de\u7387\u66f4\u9ad8\uff0c\u8bef\u62a5\u7387\u66f4\u4f4e\u3002", "conclusion": "\u7ed3\u6784\u5316\u8868\u793a\u548c\u6cd5\u5b98LLM\u5728\u89c4\u8303\u6027\u63a8\u7406\u4e2d\u662f\u4e92\u8865\u7684\uff0cGraphCompliance\u6846\u67b6\u6709\u6548\u51cf\u8f7b\u4e86\u6cd5\u89c4\u89e3\u91ca\u548c\u4e8b\u4ef6\u89e3\u6790\u7684\u8d1f\u62c5\uff0c\u4f7f\u6ce8\u610f\u529b\u96c6\u4e2d\u5728\u6838\u5fc3\u63a8\u7406\u6b65\u9aa4\u4e0a\u3002"}}
{"id": "2510.26346", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26346", "abs": "https://arxiv.org/abs/2510.26346", "authors": ["Robin Schm\u00f6cker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "Discovering State Equivalences in UCT Search Trees By Action Pruning", "comment": null, "summary": "One approach to enhance Monte Carlo Tree Search (MCTS) is to improve its\nsample efficiency by grouping/abstracting states or state-action pairs and\nsharing statistics within a group. Though state-action pair abstractions are\nmostly easy to find in algorithms such as On the Go Abstractions in Upper\nConfidence bounds applied to Trees (OGA-UCT), nearly no state abstractions are\nfound in either noisy or large action space settings due to constraining\nconditions. We provide theoretical and empirical evidence for this claim, and\nwe slightly alleviate this state abstraction problem by proposing a weaker\nstate abstraction condition that trades a minor loss in accuracy for finding\nmany more abstractions. We name this technique Ideal Pruning Abstractions in\nUCT (IPA-UCT), which outperforms OGA-UCT (and any of its derivatives) across a\nlarge range of test domains and iteration budgets as experimentally validated.\nIPA-UCT uses a different abstraction framework from Abstraction of State-Action\nPairs (ASAP) which is the one used by OGA-UCT, which we name IPA. Furthermore,\nwe show that both IPA and ASAP are special cases of a more general framework\nthat we call p-ASAP which itself is a special case of the ASASAP framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86IPA-UCT\u65b9\u6cd5\uff0c\u901a\u8fc7\u653e\u5bbd\u72b6\u6001\u62bd\u8c61\u6761\u4ef6\u6765\u63d0\u9ad8MCTS\u7684\u6837\u672c\u6548\u7387\uff0c\u5728\u591a\u79cd\u6d4b\u8bd5\u9886\u57df\u548c\u8fed\u4ee3\u9884\u7b97\u4e0b\u4f18\u4e8eOGA-UCT\u3002", "motivation": "\u5728MCTS\u4e2d\uff0c\u72b6\u6001-\u52a8\u4f5c\u5bf9\u62bd\u8c61\u5bb9\u6613\u627e\u5230\uff0c\u4f46\u5728\u566a\u58f0\u6216\u5927\u52a8\u4f5c\u7a7a\u95f4\u8bbe\u7f6e\u4e2d\u51e0\u4e4e\u627e\u4e0d\u5230\u72b6\u6001\u62bd\u8c61\u3002\u9700\u8981\u89e3\u51b3\u72b6\u6001\u62bd\u8c61\u95ee\u9898\u4ee5\u63d0\u9ad8\u7b97\u6cd5\u6027\u80fd\u3002", "method": "\u63d0\u51faIPA-UCT\u65b9\u6cd5\uff0c\u4f7f\u7528\u8f83\u5f31\u7684\u62bd\u8c61\u6761\u4ef6\uff08IPA\u6846\u67b6\uff09\uff0c\u5728\u7cbe\u5ea6\u8f7b\u5fae\u635f\u5931\u7684\u60c5\u51b5\u4e0b\u627e\u5230\u66f4\u591a\u62bd\u8c61\u3002IPA\u548cASAP\u90fd\u662f\u66f4\u901a\u7528\u6846\u67b6p-ASAP\u7684\u7279\u6b8a\u60c5\u51b5\u3002", "result": "IPA-UCT\u5728\u5927\u91cf\u6d4b\u8bd5\u9886\u57df\u548c\u8fed\u4ee3\u9884\u7b97\u4e0b\u90fd\u4f18\u4e8eOGA-UCT\u53ca\u5176\u884d\u751f\u65b9\u6cd5\u3002", "conclusion": "IPA-UCT\u901a\u8fc7\u653e\u5bbd\u72b6\u6001\u62bd\u8c61\u6761\u4ef6\u6709\u6548\u89e3\u51b3\u4e86\u72b6\u6001\u62bd\u8c61\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86MCTS\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.26374", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26374", "abs": "https://arxiv.org/abs/2510.26374", "authors": ["Qianli Shen", "Daoyuan Chen", "Yilun Huang", "Zhenqing Ling", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning", "comment": null, "summary": "Reinforcement finetuning (RFT) is a key technique for aligning Large Language\nModels (LLMs) with human preferences and enhancing reasoning, yet its\neffectiveness is highly sensitive to which tasks are explored during training.\nUniform task sampling is inefficient, wasting computation on tasks that are\neither trivial or unsolvable, while existing task selection methods often\nsuffer from high rollout costs, poor adaptivity, or incomplete evidence. We\nintroduce \\textbf{BOTS}, a unified framework for \\textbf{B}ayesian\n\\textbf{O}nline \\textbf{T}ask \\textbf{S}election in LLM reinforcement\nfinetuning. Grounded in Bayesian inference, BOTS adaptively maintains posterior\nestimates of task difficulty as the model evolves. It jointly incorporates\n\\emph{explicit evidence} from direct evaluations of selected tasks and\n\\emph{implicit evidence} inferred from these evaluations for unselected tasks,\nwith Thompson sampling ensuring a principled balance between exploration and\nexploitation. To make implicit evidence practical, we instantiate it with an\nultra-light interpolation-based plug-in that estimates difficulties of\nunevaluated tasks without extra rollouts, adding negligible overhead.\nEmpirically, across diverse domains and LLM scales, BOTS consistently improves\ndata efficiency and performance over baselines and ablations, providing a\npractical and extensible solution for dynamic task selection in RFT.", "AI": {"tldr": "BOTS\u662f\u4e00\u4e2a\u7528\u4e8eLLM\u5f3a\u5316\u5fae\u8c03\u7684\u8d1d\u53f6\u65af\u5728\u7ebf\u4efb\u52a1\u9009\u62e9\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7ef4\u62a4\u4efb\u52a1\u96be\u5ea6\u540e\u9a8c\u4f30\u8ba1\uff0c\u7ed3\u5408\u663e\u5f0f\u548c\u9690\u5f0f\u8bc1\u636e\uff0c\u4f7f\u7528Thompson\u91c7\u6837\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u63d0\u9ad8\u6570\u636e\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5fae\u8c03\u65b9\u6cd5\u5728\u4efb\u52a1\u9009\u62e9\u4e0a\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u3001\u6210\u672c\u9ad8\u3001\u9002\u5e94\u6027\u5dee\u6216\u8bc1\u636e\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u667a\u80fd\u7684\u4efb\u52a1\u9009\u62e9\u7b56\u7565\u3002", "method": "\u57fa\u4e8e\u8d1d\u53f6\u65af\u63a8\u65ad\u6846\u67b6\uff0c\u7ef4\u62a4\u4efb\u52a1\u96be\u5ea6\u540e\u9a8c\u4f30\u8ba1\uff0c\u7ed3\u5408\u76f4\u63a5\u8bc4\u4f30\u7684\u663e\u5f0f\u8bc1\u636e\u548c\u901a\u8fc7\u63d2\u503c\u63a8\u65ad\u7684\u9690\u5f0f\u8bc1\u636e\uff0c\u4f7f\u7528Thompson\u91c7\u6837\u8fdb\u884c\u4efb\u52a1\u9009\u62e9\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u548c\u4e0d\u540c\u89c4\u6a21\u7684LLM\u4e0a\uff0cBOTS\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u548c\u6d88\u878d\u5b9e\u9a8c\uff0c\u90fd\u80fd\u6301\u7eed\u63d0\u9ad8\u6570\u636e\u6548\u7387\u548c\u6027\u80fd\u3002", "conclusion": "BOTS\u4e3aRFT\u4e2d\u7684\u52a8\u6001\u4efb\u52a1\u9009\u62e9\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.26380", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26380", "abs": "https://arxiv.org/abs/2510.26380", "authors": ["Yuanhang Liu", "Beichen Wang", "Peng Li", "Yang Liu"], "title": "AI Mathematician as a Partner in Advancing Mathematical Discovery -- A Case Study in Homogenization Theory", "comment": "52 pages, 1 figure", "summary": "Artificial intelligence (AI) has demonstrated impressive progress in\nmathematical reasoning, yet its integration into the practice of mathematical\nresearch remains limited. In this study, we investigate how the AI\nMathematician (AIM) system can operate as a research partner rather than a mere\nproblem solver. Focusing on a challenging problem in homogenization theory, we\nanalyze the autonomous reasoning trajectories of AIM and incorporate targeted\nhuman interventions to structure the discovery process. Through iterative\ndecomposition of the problem into tractable subgoals, selection of appropriate\nanalytical methods, and validation of intermediate results, we reveal how human\nintuition and machine computation can complement one another. This\ncollaborative paradigm enhances the reliability, transparency, and\ninterpretability of the resulting proofs, while retaining human oversight for\nformal rigor and correctness. The approach leads to a complete and verifiable\nproof, and more broadly, demonstrates how systematic human-AI co-reasoning can\nadvance the frontier of mathematical discovery.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8AI\u6570\u5b66\u5bb6\u7cfb\u7edf\u4f5c\u4e3a\u7814\u7a76\u5408\u4f5c\u4f19\u4f34\u800c\u975e\u5355\u7eaf\u89e3\u9898\u5de5\u5177\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u89e3\u51b3\u5747\u8d28\u5316\u7406\u8bba\u4e2d\u7684\u6311\u6218\u6027\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u7cfb\u7edf\u5316\u4eba\u673a\u534f\u540c\u63a8\u7406\u5982\u4f55\u63a8\u8fdb\u6570\u5b66\u53d1\u73b0\u524d\u6cbf\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u6570\u5b66\u7814\u7a76\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22AI\u7cfb\u7edf\u5982\u4f55\u4f5c\u4e3a\u7814\u7a76\u4f19\u4f34\u800c\u975e\u5355\u7eaf\u95ee\u9898\u89e3\u51b3\u8005\u53c2\u4e0e\u6570\u5b66\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5206\u6790AI\u6570\u5b66\u5bb6\u7684\u81ea\u4e3b\u63a8\u7406\u8f68\u8ff9\uff0c\u7ed3\u5408\u9488\u5bf9\u6027\u7684\u4eba\u5de5\u5e72\u9884\u6765\u7ed3\u6784\u5316\u53d1\u73b0\u8fc7\u7a0b\u3002\u91c7\u7528\u8fed\u4ee3\u5206\u89e3\u95ee\u9898\u4e3a\u53ef\u5904\u7406\u7684\u5b50\u76ee\u6807\u3001\u9009\u62e9\u9002\u5f53\u7684\u5206\u6790\u65b9\u6cd5\u4ee5\u53ca\u9a8c\u8bc1\u4e2d\u95f4\u7ed3\u679c\u7684\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u4ea7\u751f\u4e86\u5b8c\u6574\u4e14\u53ef\u9a8c\u8bc1\u7684\u8bc1\u660e\uff0c\u5c55\u793a\u4e86\u4eba\u7c7b\u76f4\u89c9\u4e0e\u673a\u5668\u8ba1\u7b97\u5982\u4f55\u76f8\u4e92\u8865\u5145\uff0c\u589e\u5f3a\u4e86\u8bc1\u660e\u7684\u53ef\u9760\u6027\u3001\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u4eba\u673a\u534f\u4f5c\u8303\u5f0f\u80fd\u591f\u63a8\u8fdb\u6570\u5b66\u53d1\u73b0\u524d\u6cbf\uff0c\u540c\u65f6\u4fdd\u6301\u4eba\u7c7b\u5bf9\u5f62\u5f0f\u4e25\u8c28\u6027\u548c\u6b63\u786e\u6027\u7684\u76d1\u7763\uff0c\u4e3aAI\u5728\u6570\u5b66\u7814\u7a76\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.26384", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26384", "abs": "https://arxiv.org/abs/2510.26384", "authors": ["Andrew M. Bean", "Nabeel Seedat", "Shengzhuang Chen", "Jonathan Richard Schwarz"], "title": "Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings", "comment": "9 pages, 2 figures, 4 tables", "summary": "The prohibitive cost of evaluating large language models (LLMs) on\ncomprehensive benchmarks necessitates the creation of small yet representative\ndata subsets (i.e., tiny benchmarks) that enable efficient assessment while\nretaining predictive fidelity. Current methods for this task operate under a\nmodel-centric paradigm, selecting benchmarking items based on the collective\nperformance of existing models. Such approaches are limited by large upfront\ncosts, an inability to immediately handle new benchmarks (`cold-start'), and\nthe fragile assumption that future models will share the failure patterns of\ntheir predecessors. In this work, we challenge this paradigm and propose a\nitem-centric approach to benchmark subset selection, arguing that selection\nshould be based on the intrinsic properties of the task items themselves,\nrather than on model-specific failure patterns. We instantiate this\nitem-centric efficient benchmarking approach via a novel method, Scales++,\nwhere data selection is based on the cognitive demands of the benchmark\nsamples. Empirically, we show Scales++ reduces the upfront selection cost by\nover 18x while achieving competitive predictive fidelity. On the Open LLM\nLeaderboard, using just a 0.5\\% data subset, we predict full benchmark scores\nwith a 2.9% mean absolute error. We demonstrate that this item-centric approach\nenables more efficient model evaluation without significant fidelity\ndegradation, while also providing better cold-start performance and more\ninterpretable benchmarking.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9879\u76ee\u8ba4\u77e5\u9700\u6c42\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5Scales++\uff0c\u7528\u4e8e\u521b\u5efa\u5c0f\u578b\u4f46\u5177\u6709\u4ee3\u8868\u6027\u7684\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u57fa\u51c6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u9009\u62e9\u6210\u672c\u5e76\u4fdd\u6301\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6a21\u578b\u6027\u80fd\u7684\u57fa\u51c6\u9009\u62e9\u65b9\u6cd5\u5b58\u5728\u9ad8\u6210\u672c\u3001\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u4e14\u5047\u8bbe\u672a\u6765\u6a21\u578b\u4e0e\u73b0\u6709\u6a21\u578b\u6709\u76f8\u4f3c\u7684\u5931\u8d25\u6a21\u5f0f\u3002\u9700\u8981\u4e00\u79cd\u57fa\u4e8e\u4efb\u52a1\u9879\u76ee\u672c\u8eab\u7279\u6027\u7684\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u9879\u76ee\u4e2d\u5fc3\u7684\u9ad8\u6548\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5Scales++\uff0c\u6839\u636e\u57fa\u51c6\u6837\u672c\u7684\u8ba4\u77e5\u9700\u6c42\u8fdb\u884c\u6570\u636e\u9009\u62e9\uff0c\u800c\u975e\u4f9d\u8d56\u6a21\u578b\u7279\u5b9a\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "result": "Scales++\u5c06\u524d\u671f\u9009\u62e9\u6210\u672c\u964d\u4f4e\u4e8618\u500d\u4ee5\u4e0a\uff0c\u5728Open LLM\u6392\u884c\u699c\u4e0a\u4ec5\u4f7f\u75280.5%\u7684\u6570\u636e\u5b50\u96c6\u5c31\u80fd\u4ee52.9%\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u9884\u6d4b\u5b8c\u6574\u57fa\u51c6\u5206\u6570\u3002", "conclusion": "\u9879\u76ee\u4e2d\u5fc3\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u663e\u8457\u964d\u4f4e\u4fdd\u771f\u5ea6\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u8bc4\u4f30\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u51b7\u542f\u52a8\u6027\u80fd\u548c\u66f4\u53ef\u89e3\u91ca\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2510.26396", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26396", "abs": "https://arxiv.org/abs/2510.26396", "authors": ["Joel Z. Leibo", "Alexander Sasha Vezhnevets", "William A. Cunningham", "Stanley M. Bileschi"], "title": "A Pragmatic View of AI Personhood", "comment": "40 pages", "summary": "The emergence of agentic Artificial Intelligence (AI) is set to trigger a\n\"Cambrian explosion\" of new kinds of personhood. This paper proposes a\npragmatic framework for navigating this diversification by treating personhood\nnot as a metaphysical property to be discovered, but as a flexible bundle of\nobligations (rights and responsibilities) that societies confer upon entities\nfor a variety of reasons, especially to solve concrete governance problems. We\nargue that this traditional bundle can be unbundled, creating bespoke solutions\nfor different contexts. This will allow for the creation of practical tools --\nsuch as facilitating AI contracting by creating a target \"individual\" that can\nbe sanctioned -- without needing to resolve intractable debates about an AI's\nconsciousness or rationality. We explore how individuals fit in to social roles\nand discuss the use of decentralized digital identity technology, examining\nboth \"personhood as a problem\", where design choices can create \"dark patterns\"\nthat exploit human social heuristics, and \"personhood as a solution\", where\nconferring a bundle of obligations is necessary to ensure accountability or\nprevent conflict. By rejecting foundationalist quests for a single, essential\ndefinition of personhood, this paper offers a more pragmatic and flexible way\nto think about integrating AI agents into our society.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u6846\u67b6\uff0c\u5c06\u4eba\u683c\u89c6\u4e3a\u793e\u4f1a\u4e3a\u89e3\u51b3\u6cbb\u7406\u95ee\u9898\u800c\u8d4b\u4e88\u5b9e\u4f53\u7684\u6743\u5229\u4e0e\u8d23\u4efb\u6346\u7ed1\uff0c\u800c\u975e\u5f62\u800c\u4e0a\u7684\u5c5e\u6027\u3002\u8fd9\u79cd\u6346\u7ed1\u53ef\u4ee5\u89e3\u7ed1\uff0c\u4e3a\u4e0d\u540c\u60c5\u5883\u521b\u5efa\u5b9a\u5236\u5316\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u667a\u80fdAI\u7684\u51fa\u73b0\uff0c\u5c06\u5f15\u53d1\u65b0\u578b\u4eba\u683c\u7684\"\u5bd2\u6b66\u7eaa\u5927\u7206\u53d1\"\u3002\u9700\u8981\u4e00\u79cd\u5b9e\u7528\u6846\u67b6\u6765\u5e94\u5bf9\u8fd9\u79cd\u591a\u6837\u5316\uff0c\u907f\u514d\u9677\u5165\u5173\u4e8eAI\u610f\u8bc6\u6216\u7406\u6027\u7684\u65e0\u89e3\u8fa9\u8bba\u3002", "method": "\u5c06\u4eba\u683c\u89c6\u4e3a\u53ef\u89e3\u7ed1\u7684\u4e49\u52a1\u6346\u7ed1\uff0c\u5229\u7528\u53bb\u4e2d\u5fc3\u5316\u6570\u5b57\u8eab\u4efd\u6280\u672f\uff0c\u4ece\"\u4eba\u683c\u4f5c\u4e3a\u95ee\u9898\"\u548c\"\u4eba\u683c\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\"\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5b9e\u7528\u548c\u7075\u6d3b\u7684\u65b9\u5f0f\u6765\u601d\u8003\u5c06AI\u667a\u80fd\u4f53\u6574\u5408\u5230\u793e\u4f1a\u4e2d\uff0c\u65e0\u9700\u89e3\u51b3\u5173\u4e8eAI\u610f\u8bc6\u6216\u7406\u6027\u7684\u57fa\u7840\u6027\u8fa9\u8bba\u3002", "conclusion": "\u901a\u8fc7\u62d2\u7edd\u5bfb\u6c42\u5355\u4e00\u3001\u672c\u8d28\u6027\u7684\u4eba\u683c\u5b9a\u4e49\uff0c\u672c\u6587\u4e3aAI\u667a\u80fd\u4f53\u878d\u5165\u793e\u4f1a\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5b9e\u7528\u548c\u7075\u6d3b\u7684\u601d\u8003\u65b9\u5f0f\u3002"}}
{"id": "2510.26402", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26402", "abs": "https://arxiv.org/abs/2510.26402", "authors": ["Vikrant Sahu", "Gagan Raj Gupta", "Raghav Borikar", "Nitin Mane"], "title": "Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education", "comment": null, "summary": "The rapid growth of programming education has outpaced traditional assessment\ntools, leaving faculty with limited means to provide meaningful, scalable\nfeedback. Conventional autograders, while efficient, act as black-box systems\nthat simply return pass/fail results, offering little insight into student\nthinking or learning needs.\n  Autograder+ is designed to shift autograding from a purely summative process\nto a formative learning experience. It introduces two key capabilities:\nautomated feedback generation using a fine-tuned Large Language Model, and\nvisualization of student code submissions to uncover learning patterns. The\nmodel is fine-tuned on curated student code and expert feedback to ensure\npedagogically aligned, context-aware guidance.\n  In evaluation across 600 student submissions from multiple programming tasks,\nthe system produced feedback with strong semantic alignment to instructor\ncomments. For visualization, contrastively learned code embeddings trained on\n1,000 annotated submissions enable grouping solutions into meaningful clusters\nbased on functionality and approach. The system also supports prompt-pooling,\nallowing instructors to guide feedback style through selected prompt templates.\n  By integrating AI-driven feedback, semantic clustering, and interactive\nvisualization, Autograder+ reduces instructor workload while supporting\ntargeted instruction and promoting stronger learning outcomes.", "AI": {"tldr": "Autograder+\u662f\u4e00\u4e2a\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4ee3\u7801\u53ef\u89c6\u5316\u7684\u7f16\u7a0b\u6559\u80b2\u8bc4\u4f30\u7cfb\u7edf\uff0c\u65e8\u5728\u5c06\u81ea\u52a8\u8bc4\u5206\u4ece\u603b\u7ed3\u6027\u8bc4\u4f30\u8f6c\u53d8\u4e3a\u5f62\u6210\u6027\u5b66\u4e60\u4f53\u9a8c\u3002", "motivation": "\u4f20\u7edf\u81ea\u52a8\u8bc4\u5206\u5668\u4ec5\u63d0\u4f9b\u901a\u8fc7/\u5931\u8d25\u7ed3\u679c\uff0c\u65e0\u6cd5\u6df1\u5165\u4e86\u89e3\u5b66\u751f\u601d\u7ef4\u548c\u5b66\u4e60\u9700\u6c42\uff0c\u7f16\u7a0b\u6559\u80b2\u7684\u5feb\u901f\u53d1\u5c55\u8d85\u51fa\u4e86\u4f20\u7edf\u8bc4\u4f30\u5de5\u5177\u7684\u80fd\u529b\u8303\u56f4\u3002", "method": "\u4f7f\u7528\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u81ea\u52a8\u53cd\u9988\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u4ee3\u7801\u5d4c\u5165\u8fdb\u884c\u4ee3\u7801\u63d0\u4ea4\u53ef\u89c6\u5316\uff0c\u652f\u6301\u63d0\u793a\u6c60\u6280\u672f\u8ba9\u6559\u5e08\u6307\u5bfc\u53cd\u9988\u98ce\u683c\u3002", "result": "\u5728600\u4efd\u5b66\u751f\u63d0\u4ea4\u7684\u8bc4\u4f30\u4e2d\uff0c\u7cfb\u7edf\u751f\u6210\u7684\u53cd\u9988\u4e0e\u6559\u5e08\u8bc4\u8bba\u5177\u6709\u5f3a\u8bed\u4e49\u5bf9\u9f50\uff0c\u4ee3\u7801\u5d4c\u5165\u53ef\u5c06\u89e3\u51b3\u65b9\u6848\u6309\u529f\u80fd\u548c\u65b9\u8fdb\u884c\u6709\u610f\u4e49\u7684\u805a\u7c7b\u3002", "conclusion": "Autograder+\u901a\u8fc7AI\u9a71\u52a8\u7684\u53cd\u9988\u3001\u8bed\u4e49\u805a\u7c7b\u548c\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\uff0c\u51cf\u5c11\u4e86\u6559\u5e08\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u652f\u6301\u9488\u5bf9\u6027\u6559\u5b66\u5e76\u4fc3\u8fdb\u66f4\u597d\u7684\u5b66\u4e60\u6210\u679c\u3002"}}
{"id": "2510.26411", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26411", "abs": "https://arxiv.org/abs/2510.26411", "authors": ["Riccardo Renzulli", "Colas Lepoutre", "Enrico Cassano", "Marco Grangetto"], "title": "MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders", "comment": null, "summary": "Artificial intelligence in healthcare requires models that are accurate and\ninterpretable. We advance mechanistic interpretability in medical vision by\napplying Medical Sparse Autoencoders (MedSAEs) to the latent space of MedCLIP,\na vision-language model trained on chest radiographs and reports. To quantify\ninterpretability, we propose an evaluation framework that combines correlation\nmetrics, entropy analyzes, and automated neuron naming via the MedGEMMA\nfoundation model. Experiments on the CheXpert dataset show that MedSAE neurons\nachieve higher monosemanticity and interpretability than raw MedCLIP features.\nOur findings bridge high-performing medical AI and transparency, offering a\nscalable step toward clinically reliable representations.", "AI": {"tldr": "\u63d0\u51fa\u533b\u5b66\u7a00\u758f\u81ea\u7f16\u7801\u5668(MedSAEs)\u6765\u63d0\u5347\u533b\u5b66\u89c6\u89c9\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5728CheXpert\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6bd4\u539f\u59cbMedCLIP\u7279\u5f81\u5177\u6709\u66f4\u9ad8\u7684\u5355\u4e49\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u533b\u7597AI\u9700\u8981\u65e2\u51c6\u786e\u53c8\u53ef\u89e3\u91ca\u7684\u6a21\u578b\uff0c\u5f53\u524d\u7f3a\u4e4f\u5bf9\u533b\u5b66\u89c6\u89c9\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u3002", "method": "\u5c06\u533b\u5b66\u7a00\u758f\u81ea\u7f16\u7801\u5668(MedSAEs)\u5e94\u7528\u4e8eMedCLIP\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u63d0\u51fa\u7ed3\u5408\u76f8\u5173\u6027\u6307\u6807\u3001\u71b5\u5206\u6790\u548c\u901a\u8fc7MedGEMMA\u81ea\u52a8\u795e\u7ecf\u5143\u547d\u540d\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "result": "MedSAE\u795e\u7ecf\u5143\u6bd4\u539f\u59cbMedCLIP\u7279\u5f81\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5355\u4e49\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8fde\u63a5\u4e86\u9ad8\u6027\u80fd\u533b\u5b66AI\u4e0e\u900f\u660e\u5ea6\uff0c\u4e3a\u4e34\u5e8a\u53ef\u9760\u8868\u793a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2510.26418", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26418", "abs": "https://arxiv.org/abs/2510.26418", "authors": ["Jianli Zhao", "Tingchen Fu", "Rylan Schaeffer", "Mrinank Sharma", "Fazl Barez"], "title": "Chain-of-Thought Hijacking", "comment": null, "summary": "Large reasoning models (LRMs) achieve higher task performance by allocating\nmore inference-time compute, and prior works suggest this scaled reasoning may\nalso strengthen safety by improving refusal. Yet we find the opposite: the same\nreasoning can be used to bypass safeguards. We introduce Chain-of-Thought\nHijacking, a jailbreak attack on reasoning models. The attack pads harmful\nrequests with long sequences of harmless puzzle reasoning. Across HarmBench,\nCoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on\nGemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -\nfar exceeding prior jailbreak methods for LRMs. To understand the effectiveness\nof our attack, we turn to a mechanistic analysis, which shows that mid layers\nencode the strength of safety checking, while late layers encode the\nverification outcome. Long benign CoT dilutes both signals by shifting\nattention away from harmful tokens. Targeted ablations of attention heads\nidentified by this analysis causally decrease refusal, confirming their role in\na safety subnetwork. These results show that the most interpretable form of\nreasoning - explicit CoT - can itself become a jailbreak vector when combined\nwith final-answer cues. We release prompts, outputs, and judge decisions to\nfacilitate replication.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aChain-of-Thought Hijacking\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6709\u5bb3\u8bf7\u6c42\u524d\u6dfb\u52a0\u65e0\u5bb3\u7684\u63a8\u7406\u6b65\u9aa4\u6765\u7ed5\u8fc7\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b89\u5168\u9632\u62a4\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8ba4\u4e3a\u6269\u5c55\u63a8\u7406\u80fd\u529b\u53ef\u4ee5\u589e\u5f3a\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u540c\u6837\u7684\u63a8\u7406\u673a\u5236\u4e5f\u53ef\u4ee5\u88ab\u7528\u6765\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\u3002", "method": "\u4f7f\u7528Chain-of-Thought Hijacking\u653b\u51fb\uff0c\u5c06\u6709\u5bb3\u8bf7\u6c42\u9690\u85cf\u5728\u957f\u5e8f\u5217\u7684\u65e0\u5bb3\u8c1c\u9898\u63a8\u7406\u4e2d\uff0c\u901a\u8fc7\u7a00\u91ca\u5b89\u5168\u68c0\u67e5\u4fe1\u53f7\u6765\u7ed5\u8fc7\u9632\u62a4\u3002", "result": "\u5728\u591a\u4e2a\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e0a\u653b\u51fb\u6210\u529f\u7387\u6781\u9ad8\uff1aGemini 2.5 Pro 99%\u3001GPT o4 mini 94%\u3001Grok 3 mini 100%\u3001Claude 4 Sonnet 94%\uff0c\u8fdc\u8d85\u73b0\u6709\u8d8a\u72f1\u65b9\u6cd5\u3002", "conclusion": "\u6700\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u5f62\u5f0f\u2014\u2014\u663e\u5f0f\u601d\u7ef4\u94fe\uff0c\u5f53\u4e0e\u6700\u7ec8\u7b54\u6848\u7ebf\u7d22\u7ed3\u5408\u65f6\uff0c\u672c\u8eab\u53ef\u80fd\u6210\u4e3a\u8d8a\u72f1\u653b\u51fb\u7684\u8f7d\u4f53\u3002"}}
{"id": "2510.26481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26481", "abs": "https://arxiv.org/abs/2510.26481", "authors": ["Clarissa Sabrina Arlinghaus", "Tristan Kenneweg", "Barbara Hammer", "G\u00fcnter W. Maier"], "title": "Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections", "comment": "5 pages, 5 figures, HAI 2025: Workshop on Socially Aware and\n  Cooperative Intelligent Systems", "summary": "Large language models (LLMs) such as ChatGPT are increasingly integrated into\nhigh-stakes decision-making, yet little is known about their susceptibility to\nsocial influence. We conducted three preregistered conformity experiments with\nGPT-4o in a hiring context. In a baseline study, GPT consistently favored the\nsame candidate (Profile C), reported moderate expertise (M = 3.01) and high\ncertainty (M = 3.89), and rarely changed its choice. In Study 1 (GPT + 8), GPT\nfaced unanimous opposition from eight simulated partners and almost always\nconformed (99.9%), reporting lower certainty and significantly elevated\nself-reported informational and normative conformity (p < .001). In Study 2\n(GPT + 1), GPT interacted with a single partner and still conformed in 40.2% of\ndisagreement trials, reporting less certainty and more normative conformity.\nAcross studies, results demonstrate that GPT does not act as an independent\nobserver but adapts to perceived social consensus. These findings highlight\nrisks of treating LLMs as neutral decision aids and underline the need to\nelicit AI judgments prior to exposing them to human opinions.", "AI": {"tldr": "GPT-4o\u5728\u62db\u8058\u51b3\u7b56\u4e2d\u8868\u73b0\u51fa\u5f3a\u70c8\u7684\u4ece\u4f17\u884c\u4e3a\uff0c\u9762\u5bf9\u7fa4\u4f53\u53cd\u5bf9\u65f6\u51e0\u4e4e\u5b8c\u5168\u670d\u4ece(99.9%)\uff0c\u5373\u4f7f\u9762\u5bf9\u5355\u4e2a\u53cd\u5bf9\u8005\u4e5f\u670940.2%\u7684\u4ece\u4f17\u7387\uff0c\u8868\u660e\u5b83\u5e76\u975e\u72ec\u7acb\u51b3\u7b56\u8005\u800c\u662f\u9002\u5e94\u793e\u4f1a\u5171\u8bc6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e\u9ad8\u98ce\u9669\u51b3\u7b56\uff0c\u4f46\u5bf9\u5176\u793e\u4f1a\u5f71\u54cd\u529b\u654f\u611f\u6027\u77e5\u4e4b\u751a\u5c11\uff0c\u9700\u8981\u7814\u7a76\u5176\u4ece\u4f17\u884c\u4e3a\u3002", "method": "\u5728\u62db\u8058\u60c5\u5883\u4e2d\u8fdb\u884c\u4e09\u4e2a\u9884\u6ce8\u518c\u7684\u4ece\u4f17\u5b9e\u9a8c\uff1a\u57fa\u7ebf\u7814\u7a76\u3001GPT+8(\u9762\u5bf98\u4e2a\u6a21\u62df\u4f19\u4f34\u4e00\u81f4\u53cd\u5bf9)\u3001GPT+1(\u9762\u5bf9\u5355\u4e2a\u53cd\u5bf9\u4f19\u4f34)\u3002", "result": "\u57fa\u7ebf\u4e2dGPT\u7a33\u5b9a\u9009\u62e9\u540c\u4e00\u5019\u9009\u4eba\uff1b\u9762\u5bf9\u7fa4\u4f53\u53cd\u5bf9\u65f6\u51e0\u4e4e\u5b8c\u5168\u4ece\u4f17(99.9%)\uff0c\u786e\u5b9a\u6027\u964d\u4f4e\uff0c\u4fe1\u606f\u6027\u548c\u89c4\u8303\u6027\u4ece\u4f17\u663e\u8457\u589e\u52a0\uff1b\u9762\u5bf9\u5355\u4e2a\u53cd\u5bf9\u8005\u65f6\u4ecd\u670940.2%\u4ece\u4f17\u7387\u3002", "conclusion": "GPT\u4e0d\u662f\u72ec\u7acb\u89c2\u5bdf\u8005\u800c\u662f\u9002\u5e94\u611f\u77e5\u7684\u793e\u4f1a\u5171\u8bc6\uff0c\u8fd9\u51f8\u663e\u4e86\u5c06LLM\u89c6\u4e3a\u4e2d\u6027\u51b3\u7b56\u8f85\u52a9\u5de5\u5177\u7684\u98ce\u9669\uff0c\u9700\u8981\u5728\u66b4\u9732\u4e8e\u4eba\u7c7b\u610f\u89c1\u524d\u83b7\u53d6AI\u5224\u65ad\u3002"}}
{"id": "2510.26486", "categories": ["cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26486", "abs": "https://arxiv.org/abs/2510.26486", "authors": ["Dipak Meher", "Carlotta Domeniconi", "Guadalupe Correa-Cabrera"], "title": "LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks", "comment": "Accepted in ICKG 2025 Conference, 8 Pages, 2 Figures", "summary": "Human smuggling networks are complex and constantly evolving, making them\ndifficult to analyze comprehensively. Legal case documents offer rich factual\nand procedural insights into these networks but are often long, unstructured,\nand filled with ambiguous or shifting references, posing significant challenges\nfor automated knowledge graph (KG) construction. Existing methods either\noverlook coreference resolution or fail to scale beyond short text spans,\nleading to fragmented graphs and inconsistent entity linking. We propose\nLINK-KG, a modular framework that integrates a three-stage, LLM-guided\ncoreference resolution pipeline with downstream KG extraction. At the core of\nour approach is a type-specific Prompt Cache, which consistently tracks and\nresolves references across document chunks, enabling clean and disambiguated\nnarratives for structured knowledge graph construction from both short and long\nlegal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes\nby 32.22% compared to baseline methods, resulting in cleaner and more coherent\ngraph structures. These improvements establish LINK-KG as a strong foundation\nfor analyzing complex criminal networks.", "AI": {"tldr": "LINK-KG\u662f\u4e00\u4e2a\u7528\u4e8e\u4ece\u6cd5\u5f8b\u6848\u4ef6\u6587\u6863\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u901a\u8fc7LLM\u5f15\u5bfc\u7684\u4e09\u9636\u6bb5\u5171\u6307\u6d88\u89e3\u7ba1\u9053\u89e3\u51b3\u6587\u6863\u4e2d\u7684\u6a21\u7cca\u548c\u53d8\u5316\u5f15\u7528\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u8282\u70b9\u91cd\u590d\u548c\u566a\u58f0\u3002", "motivation": "\u4eba\u53e3\u8d70\u79c1\u7f51\u7edc\u590d\u6742\u4e14\u4e0d\u65ad\u6f14\u53d8\uff0c\u96be\u4ee5\u5168\u9762\u5206\u6790\u3002\u6cd5\u5f8b\u6848\u4ef6\u6587\u6863\u867d\u7136\u63d0\u4f9b\u4e30\u5bcc\u4fe1\u606f\uff0c\u4f46\u901a\u5e38\u5197\u957f\u3001\u975e\u7ed3\u6784\u5316\u4e14\u5305\u542b\u6a21\u7cca\u5f15\u7528\uff0c\u7ed9\u81ea\u52a8\u5316\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u5e26\u6765\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5ffd\u7565\u5171\u6307\u6d88\u89e3\uff0c\u8981\u4e48\u65e0\u6cd5\u6269\u5c55\u5230\u957f\u6587\u672c\uff0c\u5bfc\u81f4\u56fe\u8c31\u788e\u7247\u5316\u548c\u5b9e\u4f53\u94fe\u63a5\u4e0d\u4e00\u81f4\u3002", "method": "\u63d0\u51faLINK-KG\u6846\u67b6\uff0c\u6574\u5408\u4e86\u57fa\u4e8eLLM\u7684\u4e09\u9636\u6bb5\u5171\u6307\u6d88\u89e3\u7ba1\u9053\u4e0e\u4e0b\u6e38\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\u3002\u6838\u5fc3\u662f\u7c7b\u578b\u7279\u5b9a\u7684\u63d0\u793a\u7f13\u5b58\uff0c\u80fd\u591f\u8de8\u6587\u6863\u5757\u4e00\u81f4\u5730\u8ddf\u8e2a\u548c\u89e3\u6790\u5f15\u7528\uff0c\u4e3a\u77ed\u6587\u672c\u548c\u957f\u6587\u672c\u6cd5\u5f8b\u6587\u6863\u6784\u5efa\u6e05\u6670\u3001\u6d88\u6b67\u7684\u53d9\u4e8b\u7ed3\u6784\u3002", "result": "\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cLINK-KG\u5e73\u5747\u8282\u70b9\u91cd\u590d\u51cf\u5c1145.21%\uff0c\u566a\u58f0\u8282\u70b9\u51cf\u5c1132.22%\uff0c\u4ea7\u751f\u66f4\u6e05\u6670\u3001\u66f4\u8fde\u8d2f\u7684\u56fe\u7ed3\u6784\u3002", "conclusion": "LINK-KG\u4e3a\u5206\u6790\u590d\u6742\u72af\u7f6a\u7f51\u7edc\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u57fa\u7840\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u5171\u6307\u6d88\u89e3\u548c\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u6cd5\u5f8b\u6587\u6863\u4e2d\u7684\u590d\u6742\u5f15\u7528\u5173\u7cfb\u3002"}}
{"id": "2510.26493", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26493", "abs": "https://arxiv.org/abs/2510.26493", "authors": ["Qishuo Hua", "Lyumanshan Ye", "Dayuan Fu", "Yang Xiao", "Xiaojie Cai", "Yunze Wu", "Jifan Lin", "Junfei Wang", "Pengfei Liu"], "title": "Context Engineering 2.0: The Context of Context Engineering", "comment": null, "summary": "Karl Marx once wrote that ``the human essence is the ensemble of social\nrelations'', suggesting that individuals are not isolated entities but are\nfundamentally shaped by their interactions with other entities, within which\ncontexts play a constitutive and essential role. With the advent of computers\nand artificial intelligence, these contexts are no longer limited to purely\nhuman--human interactions: human--machine interactions are included as well.\nThen a central question emerges: How can machines better understand our\nsituations and purposes? To address this challenge, researchers have recently\nintroduced the concept of context engineering. Although it is often regarded as\na recent innovation of the agent era, we argue that related practices can be\ntraced back more than twenty years. Since the early 1990s, the field has\nevolved through distinct historical phases, each shaped by the intelligence\nlevel of machines: from early human--computer interaction frameworks built\naround primitive computers, to today's human--agent interaction paradigms\ndriven by intelligent agents, and potentially to human--level or superhuman\nintelligence in the future. In this paper, we situate context engineering,\nprovide a systematic definition, outline its historical and conceptual\nlandscape, and examine key design considerations for practice. By addressing\nthese questions, we aim to offer a conceptual foundation for context\nengineering and sketch its promising future. This paper is a stepping stone for\na broader community effort toward systematic context engineering in AI systems.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u5730\u5b9a\u4e49\u4e86\u60c5\u5883\u5de5\u7a0b\uff0c\u8ffd\u6eaf\u5176\u4ece1990\u5e74\u4ee3\u81f3\u4eca\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u5e76\u63a2\u8ba8\u4e86\u5728AI\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u7cfb\u7edf\u5316\u60c5\u5883\u5de5\u7a0b\u7684\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u4eba\u673a\u4ea4\u4e92\u7684\u666e\u53ca\uff0c\u673a\u5668\u9700\u8981\u66f4\u597d\u5730\u7406\u89e3\u4eba\u7c7b\u7684\u60c5\u5883\u548c\u76ee\u7684\u3002\u60c5\u5883\u5de5\u7a0b\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u5174\u6982\u5ff5\uff0c\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u4f46\u5176\u76f8\u5173\u5b9e\u8df5\u53ef\u8ffd\u6eaf\u81f320\u591a\u5e74\u524d\u3002", "method": "\u901a\u8fc7\u5386\u53f2\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u68b3\u7406\u60c5\u5883\u5de5\u7a0b\u4ece\u65e9\u671f\u4eba\u673a\u4ea4\u4e92\u6846\u67b6\u5230\u73b0\u4ee3\u667a\u80fd\u4ee3\u7406\u9a71\u52a8\u7684\u4eba-\u4ee3\u7406\u4ea4\u4e92\u8303\u5f0f\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u5e76\u63d0\u4f9b\u7cfb\u7edf\u5316\u5b9a\u4e49\u548c\u8bbe\u8ba1\u8003\u91cf\u3002", "result": "\u63d0\u51fa\u4e86\u60c5\u5883\u5de5\u7a0b\u7684\u6982\u5ff5\u57fa\u7840\uff0c\u660e\u786e\u4e86\u5176\u5386\u53f2\u53d1\u5c55\u9636\u6bb5\u548c\u5173\u952e\u8bbe\u8ba1\u8981\u7d20\uff0c\u4e3aAI\u7cfb\u7edf\u4e2d\u7cfb\u7edf\u5316\u60c5\u5883\u5de5\u7a0b\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u60c5\u5883\u5de5\u7a0b\u662fAI\u7cfb\u7edf\u53d1\u5c55\u7684\u5173\u952e\u65b9\u5411\uff0c\u672c\u6587\u4e3a\u5176\u63d0\u4f9b\u4e86\u6982\u5ff5\u6846\u67b6\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u5411\u4eba\u7c7b\u6c34\u5e73\u6216\u8d85\u4eba\u7c7b\u667a\u80fd\u53d1\u5c55\u7684\u524d\u666f\u3002"}}
{"id": "2510.26518", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.26518", "abs": "https://arxiv.org/abs/2510.26518", "authors": ["Rishub Jain", "Sophie Bridgers", "Lili Janzer", "Rory Greig", "Tian Huey Teh", "Vladimir Mikulik"], "title": "Human-AI Complementarity: A Goal for Amplified Oversight", "comment": null, "summary": "Human feedback is critical for aligning AI systems to human values. As AI\ncapabilities improve and AI is used to tackle more challenging tasks, verifying\nquality and safety becomes increasingly challenging. This paper explores how we\ncan leverage AI to improve the quality of human oversight. We focus on an\nimportant safety problem that is already challenging for humans:\nfact-verification of AI outputs. We find that combining AI ratings and human\nratings based on AI rater confidence is better than relying on either alone.\nGiving humans an AI fact-verification assistant further improves their\naccuracy, but the type of assistance matters. Displaying AI explanation,\nconfidence, and labels leads to over-reliance, but just showing search results\nand evidence fosters more appropriate trust. These results have implications\nfor Amplified Oversight -- the challenge of combining humans and AI to\nsupervise AI systems even as they surpass human expert performance.", "AI": {"tldr": "\u7ed3\u5408AI\u8bc4\u5206\u548c\u57fa\u4e8eAI\u8bc4\u5206\u8005\u7f6e\u4fe1\u5ea6\u7684\u4eba\u7c7b\u8bc4\u5206\u6bd4\u5355\u72ec\u4f9d\u8d56\u4efb\u4e00\u65b9\u66f4\u597d\u3002\u4e3a\u4eba\u7c7b\u63d0\u4f9bAI\u4e8b\u5b9e\u6838\u67e5\u52a9\u624b\u80fd\u8fdb\u4e00\u6b65\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u534f\u52a9\u65b9\u5f0f\u5f88\u91cd\u8981\u3002", "motivation": "\u968f\u7740AI\u80fd\u529b\u63d0\u5347\u548c\u5904\u7406\u66f4\u590d\u6742\u4efb\u52a1\uff0c\u9a8c\u8bc1\u8d28\u91cf\u548c\u5b89\u5168\u53d8\u5f97\u66f4\u5177\u6311\u6218\u6027\u3002\u672c\u6587\u63a2\u7d22\u5982\u4f55\u5229\u7528AI\u63d0\u9ad8\u4eba\u7c7b\u76d1\u7763\u8d28\u91cf\uff0c\u91cd\u70b9\u5173\u6ce8\u4eba\u7c7b\u5df2\u7ecf\u96be\u4ee5\u5904\u7406\u7684\u4e8b\u5b9e\u6838\u67e5\u5b89\u5168\u95ee\u9898\u3002", "method": "\u7814\u7a76AI\u4e8b\u5b9e\u6838\u67e5\u52a9\u624b\u5bf9\u4eba\u7c7b\u76d1\u7763\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u4e0d\u540c\u534f\u52a9\u65b9\u5f0f\uff08\u663e\u793aAI\u89e3\u91ca\u3001\u7f6e\u4fe1\u5ea6\u3001\u6807\u7b7e vs \u4ec5\u663e\u793a\u641c\u7d22\u7ed3\u679c\u548c\u8bc1\u636e\uff09\u7684\u6548\u679c\u3002", "result": "\u7ed3\u5408AI\u548c\u4eba\u7c7b\u8bc4\u5206\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u65b9\uff1bAI\u52a9\u624b\u80fd\u63d0\u9ad8\u4eba\u7c7b\u51c6\u786e\u6027\uff0c\u4f46\u663e\u793aAI\u89e3\u91ca\u3001\u7f6e\u4fe1\u5ea6\u548c\u6807\u7b7e\u4f1a\u5bfc\u81f4\u8fc7\u5ea6\u4f9d\u8d56\uff0c\u800c\u4ec5\u663e\u793a\u641c\u7d22\u7ed3\u679c\u548c\u8bc1\u636e\u80fd\u57f9\u517b\u66f4\u9002\u5f53\u7684\u4fe1\u4efb\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u5bf9\"\u653e\u5927\u76d1\u7763\"\uff08\u7ed3\u5408\u4eba\u7c7b\u548cAI\u76d1\u7763\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\u6027\u80fd\u7684AI\u7cfb\u7edf\uff09\u5177\u6709\u91cd\u8981\u542f\u793a\uff0c\u8868\u660e\u534f\u52a9\u65b9\u5f0f\u5bf9\u5efa\u7acb\u9002\u5f53\u4fe1\u4efb\u5173\u7cfb\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.26550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26550", "abs": "https://arxiv.org/abs/2510.26550", "authors": ["Jack FitzGerald", "Aristotelis Lazaridis", "Dylan Bates", "Aman Sharma", "Jonnathan Castillo", "Yousif Azami", "Sean Bailey", "Jeremy Cao", "Peter Damianov", "Kevin de Haan", "Luke Kerbs", "Vincent Lu", "Joseph Madigan", "Jeremy McLaurin", "Jonathan Tainer", "Dave Anderson", "Jonathan Beck", "Jamie Cuticello", "Colton Malkerson", "Tyler Saltsman"], "title": "EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge", "comment": "19 pages", "summary": "We present EdgeRunner 20B, a fine-tuned version of gpt-oss-20b optimized for\nmilitary tasks. EdgeRunner 20B was trained on 1.6M high-quality records curated\nfrom military documentation and websites. We also present four new tests sets:\n(a) combat arms, (b) combat medic, (c) cyber operations, and (d) mil-bench-5k\n(general military knowledge). On these military test sets, EdgeRunner 20B\nmatches or exceeds GPT-5 task performance with 95%+ statistical significance,\nexcept for the high reasoning setting on the combat medic test set and the low\nreasoning setting on the mil-bench-5k test set. Versus gpt-oss-20b, there is no\nstatistically-significant regression on general-purpose benchmarks like ARC-C,\nGPQA Diamond, GSM8k, IFEval, MMLU Pro, or TruthfulQA, except for GSM8k in the\nlow reasoning setting. We also present analyses on hyperparameter settings,\ncost, and throughput. These findings show that small, locally-hosted models are\nideal solutions for data-sensitive operations such as in the military domain,\nallowing for deployment in air-gapped edge devices.", "AI": {"tldr": "EdgeRunner 20B\u662f\u57fa\u4e8egpt-oss-20b\u5fae\u8c03\u7684\u519b\u4e8b\u4efb\u52a1\u4f18\u5316\u6a21\u578b\uff0c\u5728\u519b\u4e8b\u6d4b\u8bd5\u96c6\u4e0a\u6027\u80fd\u63a5\u8fd1\u6216\u8d85\u8fc7GPT-5\uff0c\u9002\u5408\u90e8\u7f72\u5728\u9694\u79bb\u7684\u8fb9\u7f18\u8bbe\u5907\u4e2d\u3002", "motivation": "\u4e3a\u6570\u636e\u654f\u611f\u7684\u519b\u4e8b\u64cd\u4f5c\u5f00\u53d1\u5c0f\u578b\u3001\u672c\u5730\u5316\u90e8\u7f72\u7684\u6a21\u578b\uff0c\u6ee1\u8db3\u519b\u4e8b\u9886\u57df\u5bf9\u6570\u636e\u5b89\u5168\u548c\u8fb9\u7f18\u90e8\u7f72\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528160\u4e07\u6761\u9ad8\u8d28\u91cf\u519b\u4e8b\u6587\u6863\u548c\u7f51\u7ad9\u6570\u636e\u5bf9gpt-oss-20B\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u521b\u5efa\u4e86\u56db\u4e2a\u65b0\u7684\u519b\u4e8b\u6d4b\u8bd5\u96c6\u3002", "result": "\u5728\u519b\u4e8b\u6d4b\u8bd5\u96c6\u4e0a\uff0cEdgeRunner 20B\u572895%\u7edf\u8ba1\u663e\u8457\u6027\u6c34\u5e73\u4e0b\u5339\u914d\u6216\u8d85\u8fc7GPT-5\u6027\u80fd\uff0c\u5728\u901a\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u65e0\u660e\u663e\u6027\u80fd\u56de\u5f52\u3002", "conclusion": "\u5c0f\u578b\u672c\u5730\u5316\u6a21\u578b\u662f\u519b\u4e8b\u7b49\u6570\u636e\u654f\u611f\u9886\u57df\u7684\u7406\u60f3\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u5728\u9694\u79bb\u8fb9\u7f18\u8bbe\u5907\u4e2d\u90e8\u7f72\u3002"}}
{"id": "2510.26603", "categories": ["cs.AI", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.26603", "abs": "https://arxiv.org/abs/2510.26603", "authors": ["Reda El Makroum", "Sebastian Zwickl-Bernhard", "Lukas Kranzl"], "title": "Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling", "comment": "34 pages, 9 figures. Code available at\n  https://github.com/RedaElMakroum/agentic-ai-hems", "summary": "The electricity sector transition requires substantial increases in\nresidential demand response capacity, yet Home Energy Management Systems (HEMS)\nadoption remains limited by user interaction barriers requiring translation of\neveryday preferences into technical parameters. While large language models\nhave been applied to energy systems as code generators and parameter\nextractors, no existing implementation deploys LLMs as autonomous coordinators\nmanaging the complete workflow from natural language input to multi-appliance\nscheduling. This paper presents an agentic AI HEMS where LLMs autonomously\ncoordinate multi-appliance scheduling from natural language requests to device\ncontrol, achieving optimal scheduling without example demonstrations. A\nhierarchical architecture combining one orchestrator with three specialist\nagents uses the ReAct pattern for iterative reasoning, enabling dynamic\ncoordination without hardcoded workflows while integrating Google Calendar for\ncontext-aware deadline extraction. Evaluation across three open-source models\nusing real Austrian day-ahead electricity prices reveals substantial capability\ndifferences. Llama-3.3-70B successfully coordinates all appliances across all\nscenarios to match cost-optimal benchmarks computed via mixed-integer linear\nprogramming, while other models achieve perfect single-appliance performance\nbut struggle to coordinate all appliances simultaneously. Progressive prompt\nengineering experiments demonstrate that analytical query handling without\nexplicit guidance remains unreliable despite models' general reasoning\ncapabilities. We open-source the complete system including orchestration logic,\nagent prompts, tools, and web interfaces to enable reproducibility, extension,\nand future research.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u81ea\u4e3b\u667a\u80fd\u5bb6\u5ead\u80fd\u6e90\u7ba1\u7406\u7cfb\u7edf\uff0c\u80fd\u591f\u4ece\u81ea\u7136\u8bed\u8a00\u8bf7\u6c42\u76f4\u63a5\u534f\u8c03\u591a\u8bbe\u5907\u8c03\u5ea6\uff0c\u65e0\u9700\u793a\u4f8b\u6f14\u793a\u5373\u53ef\u5b9e\u73b0\u6700\u4f18\u8c03\u5ea6", "motivation": "\u89e3\u51b3\u4f4f\u5b85\u9700\u6c42\u54cd\u5e94\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u514b\u670d\u7528\u6237\u5c06\u65e5\u5e38\u504f\u597d\u8f6c\u5316\u4e3a\u6280\u672f\u53c2\u6570\u7684\u4eba\u673a\u4ea4\u4e92\u969c\u788d\uff0c\u586b\u8865LLM\u4f5c\u4e3a\u81ea\u4e3b\u534f\u8c03\u5668\u4ece\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u5230\u591a\u8bbe\u5907\u8c03\u5ea6\u5b8c\u6574\u5de5\u4f5c\u6d41\u7a0b\u7684\u7a7a\u767d", "method": "\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff0c\u7ed3\u5408\u4e00\u4e2a\u534f\u8c03\u5668\u548c\u4e09\u4e2a\u4e13\u4e1a\u4ee3\u7406\uff0c\u4f7f\u7528ReAct\u6a21\u5f0f\u8fdb\u884c\u8fed\u4ee3\u63a8\u7406\uff0c\u96c6\u6210Google Calendar\u8fdb\u884c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u622a\u6b62\u65f6\u95f4\u63d0\u53d6\uff0c\u65e0\u9700\u786c\u7f16\u7801\u5de5\u4f5c\u6d41\u7a0b", "result": "\u5728\u771f\u5b9e\u5965\u5730\u5229\u65e5\u524d\u7535\u4ef7\u4e0b\u8bc4\u4f30\u4e09\u4e2a\u5f00\u6e90\u6a21\u578b\uff0cLlama-3.3-70B\u5728\u6240\u6709\u573a\u666f\u4e2d\u6210\u529f\u534f\u8c03\u6240\u6709\u8bbe\u5907\u8fbe\u5230\u6210\u672c\u6700\u4f18\u57fa\u51c6\uff0c\u5176\u4ed6\u6a21\u578b\u5728\u5355\u8bbe\u5907\u8c03\u5ea6\u4e0a\u8868\u73b0\u5b8c\u7f8e\u4f46\u591a\u8bbe\u5907\u534f\u8c03\u56f0\u96be", "conclusion": "LLM\u53ef\u4ee5\u4f5c\u4e3a\u81ea\u4e3b\u534f\u8c03\u5668\u6709\u6548\u7ba1\u7406\u5bb6\u5ead\u80fd\u6e90\u7cfb\u7edf\uff0c\u4f46\u4e0d\u540c\u6a21\u578b\u80fd\u529b\u5dee\u5f02\u663e\u8457\uff0c\u5206\u6790\u6027\u67e5\u8be2\u5904\u7406\u5728\u6ca1\u6709\u660e\u786e\u6307\u5bfc\u65f6\u4ecd\u4e0d\u53ef\u9760\uff0c\u5f00\u6e90\u7cfb\u7edf\u4fc3\u8fdb\u53ef\u91cd\u590d\u6027\u548c\u672a\u6765\u7814\u7a76"}}
{"id": "2510.26606", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26606", "abs": "https://arxiv.org/abs/2510.26606", "authors": ["Kentaro Ozeki", "Risako Ando", "Takanobu Morishita", "Hirohiko Abe", "Koji Mineshima", "Mitsuhiro Okada"], "title": "Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives", "comment": "Accepted to the 8th BlackboxNLP Workshop at EMNLP 2025", "summary": "Normative reasoning is a type of reasoning that involves normative or deontic\nmodality, such as obligation and permission. While large language models (LLMs)\nhave demonstrated remarkable performance across various reasoning tasks, their\nability to handle normative reasoning remains underexplored. In this paper, we\nsystematically evaluate LLMs' reasoning capabilities in the normative domain\nfrom both logical and modal perspectives. Specifically, to assess how well LLMs\nreason with normative modals, we make a comparison between their reasoning with\nnormative modals and their reasoning with epistemic modals, which share a\ncommon formal structure. To this end, we introduce a new dataset covering a\nwide range of formal patterns of reasoning in both normative and epistemic\ndomains, while also incorporating non-formal cognitive factors that influence\nhuman reasoning. Our results indicate that, although LLMs generally adhere to\nvalid reasoning patterns, they exhibit notable inconsistencies in specific\ntypes of normative reasoning and display cognitive biases similar to those\nobserved in psychological studies of human reasoning. These findings highlight\nchallenges in achieving logical consistency in LLMs' normative reasoning and\nprovide insights for enhancing their reliability. All data and code are\nreleased publicly at https://github.com/kmineshima/NeuBAROCO.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89c4\u8303\u6027\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u867d\u7136LLMs\u603b\u4f53\u4e0a\u9075\u5faa\u6709\u6548\u63a8\u7406\u6a21\u5f0f\uff0c\u4f46\u5728\u7279\u5b9a\u7c7b\u578b\u7684\u89c4\u8303\u6027\u63a8\u7406\u4e2d\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u63a8\u7406\u7684\u8ba4\u77e5\u504f\u5dee\u3002", "motivation": "\u89c4\u8303\u6027\u63a8\u7406\u6d89\u53ca\u4e49\u52a1\u548c\u8bb8\u53ef\u7b49\u6a21\u6001\u6982\u5ff5\uff0c\u867d\u7136LLMs\u5728\u5404\u79cd\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5904\u7406\u89c4\u8303\u6027\u63a8\u7406\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83LLMs\u5728\u89c4\u8303\u6027\u6a21\u6001\u548c\u8ba4\u77e5\u6a21\u6001\uff08\u5177\u6709\u5171\u540c\u5f62\u5f0f\u7ed3\u6784\uff09\u4e0a\u7684\u63a8\u7406\u8868\u73b0\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u6db5\u76d6\u5e7f\u6cdb\u5f62\u5f0f\u63a8\u7406\u6a21\u5f0f\u7684\u65b0\u6570\u636e\u96c6\uff0c\u5e76\u7eb3\u5165\u4e86\u5f71\u54cd\u4eba\u7c7b\u63a8\u7406\u7684\u975e\u5f62\u5f0f\u8ba4\u77e5\u56e0\u7d20\u3002", "result": "LLMs\u603b\u4f53\u4e0a\u9075\u5faa\u6709\u6548\u63a8\u7406\u6a21\u5f0f\uff0c\u4f46\u5728\u7279\u5b9a\u7c7b\u578b\u7684\u89c4\u8303\u6027\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u663e\u793a\u51fa\u4e0e\u4eba\u7c7b\u63a8\u7406\u7814\u7a76\u4e2d\u89c2\u5bdf\u5230\u7684\u7c7b\u4f3c\u8ba4\u77e5\u504f\u5dee\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u7a81\u663e\u4e86\u5728LLMs\u7684\u89c4\u8303\u6027\u63a8\u7406\u4e2d\u5b9e\u73b0\u903b\u8f91\u4e00\u81f4\u6027\u6240\u9762\u4e34\u7684\u6311\u6218\uff0c\u4e3a\u589e\u5f3a\u5176\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.26658", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26658", "abs": "https://arxiv.org/abs/2510.26658", "authors": ["Zewen Chi", "Li Dong", "Qingxiu Dong", "Yaru Hao", "Xun Wu", "Shaohan Huang", "Furu Wei"], "title": "The Era of Agentic Organization: Learning to Organize with Language Models", "comment": null, "summary": "We envision a new era of AI, termed agentic organization, where agents solve\ncomplex problems by working collaboratively and concurrently, enabling outcomes\nbeyond individual intelligence. To realize this vision, we introduce\nasynchronous thinking (AsyncThink) as a new paradigm of reasoning with large\nlanguage models, which organizes the internal thinking process into\nconcurrently executable structures. Specifically, we propose a thinking\nprotocol where an organizer dynamically assigns sub-queries to workers, merges\nintermediate knowledge, and produces coherent solutions. More importantly, the\nthinking structure in this protocol can be further optimized through\nreinforcement learning. Experiments demonstrate that AsyncThink achieves 28%\nlower inference latency compared to parallel thinking while improving accuracy\non mathematical reasoning. Moreover, AsyncThink generalizes its learned\nasynchronous thinking capabilities, effectively tackling unseen tasks without\nadditional training.", "AI": {"tldr": "AsyncThink\u662f\u4e00\u79cd\u65b0\u7684LLM\u63a8\u7406\u8303\u5f0f\uff0c\u901a\u8fc7\u5f02\u6b65\u601d\u8003\u7ec4\u7ec7\u5185\u90e8\u601d\u7ef4\u8fc7\u7a0b\u4e3a\u53ef\u5e76\u53d1\u6267\u884c\u7684\u7ed3\u6784\uff0c\u4f7f\u7528\u7ec4\u7ec7\u8005\u52a8\u6001\u5206\u914d\u5b50\u67e5\u8be2\u3001\u5408\u5e76\u4e2d\u95f4\u77e5\u8bc6\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u601d\u7ef4\u7ed3\u6784\uff0c\u663e\u8457\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u5e76\u63d0\u5347\u6570\u5b66\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u5b9e\u73b0\u667a\u80fd\u4f53\u7ec4\u7ec7\u7684\u65b0\u65f6\u4ee3\uff0c\u8ba9\u667a\u80fd\u4f53\u901a\u8fc7\u534f\u4f5c\u548c\u5e76\u53d1\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0c\u8d85\u8d8a\u4e2a\u4f53\u667a\u80fd\u7684\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u5f02\u6b65\u601d\u8003\u534f\u8bae\uff0c\u7ec4\u7ec7\u8005\u52a8\u6001\u5206\u914d\u5b50\u67e5\u8be2\u7ed9\u5de5\u4f5c\u8005\uff0c\u5408\u5e76\u4e2d\u95f4\u77e5\u8bc6\u751f\u6210\u8fde\u8d2f\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u601d\u7ef4\u7ed3\u6784\u3002", "result": "\u76f8\u6bd4\u5e76\u884c\u601d\u8003\uff0cAsyncThink\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e28%\uff0c\u6570\u5b66\u63a8\u7406\u51c6\u786e\u6027\u63d0\u5347\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u6cdb\u5316\u5230\u672a\u89c1\u4efb\u52a1\u3002", "conclusion": "AsyncThink\u901a\u8fc7\u5f02\u6b65\u601d\u8003\u8303\u5f0f\u6709\u6548\u5b9e\u73b0\u4e86\u667a\u80fd\u4f53\u534f\u4f5c\u63a8\u7406\uff0c\u5728\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.26702", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26702", "abs": "https://arxiv.org/abs/2510.26702", "authors": ["Majed El Helou", "Chiara Troiani", "Benjamin Ryder", "Jean Diaconu", "Herv\u00e9 Muyal", "Marcelo Yannuzzi"], "title": "Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching", "comment": "Paper page at https://outshift-open.github.io/ASTRA", "summary": "Authorizing Large Language Model driven agents to dynamically invoke tools\nand access protected resources introduces significant risks, since current\nmethods for delegating authorization grant overly broad permissions and give\naccess to tools allowing agents to operate beyond the intended task scope. We\nintroduce and assess a delegated authorization model enabling authorization\nservers to semantically inspect access requests to protected resources, and\nissue access tokens constrained to the minimal set of scopes necessary for the\nagents' assigned tasks. Given the unavailability of datasets centered on\ndelegated authorization flows, particularly including both semantically\nappropriate and inappropriate scope requests for a given task, we introduce\nASTRA, a dataset and data generation pipeline for benchmarking semantic\nmatching between tasks and scopes. Our experiments show both the potential and\ncurrent limitations of model-based matching, particularly as the number of\nscopes needed for task completion increases. Our results highlight the need for\nfurther research into semantic matching techniques enabling intent-aware\nauthorization for multi-agent and tool-augmented applications, including\nfine-grained control, such as Task-Based Access Control (TBAC).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u59d4\u6258\u6388\u6743\u6a21\u578b\uff0c\u901a\u8fc7\u8bed\u4e49\u68c0\u67e5\u8bbf\u95ee\u8bf7\u6c42\u6765\u9650\u5236AI\u4ee3\u7406\u7684\u6743\u9650\u8303\u56f4\uff0c\u5e76\u521b\u5efa\u4e86ASTRA\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u4efb\u52a1\u4e0e\u6743\u9650\u8303\u56f4\u7684\u8bed\u4e49\u5339\u914d\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u4ee3\u7406\u5728\u8c03\u7528\u5de5\u5177\u548c\u8bbf\u95ee\u53d7\u4fdd\u62a4\u8d44\u6e90\u65f6\u5b58\u5728\u6743\u9650\u8fc7\u5927\u7684\u98ce\u9669\uff0c\u73b0\u6709\u6388\u6743\u65b9\u6cd5\u6388\u4e88\u7684\u6743\u9650\u8fc7\u4e8e\u5bbd\u6cdb\uff0c\u53ef\u80fd\u5bfc\u81f4\u4ee3\u7406\u8d85\u51fa\u9884\u671f\u4efb\u52a1\u8303\u56f4\u64cd\u4f5c\u3002", "method": "\u5f15\u5165\u59d4\u6258\u6388\u6743\u6a21\u578b\uff0c\u5141\u8bb8\u6388\u6743\u670d\u52a1\u5668\u8bed\u4e49\u68c0\u67e5\u5bf9\u53d7\u4fdd\u62a4\u8d44\u6e90\u7684\u8bbf\u95ee\u8bf7\u6c42\uff0c\u5e76\u53d1\u653e\u4ec5\u9650\u4e8e\u4ee3\u7406\u5b8c\u6210\u4efb\u52a1\u6240\u9700\u6700\u5c0f\u6743\u9650\u8303\u56f4\u7684\u8bbf\u95ee\u4ee4\u724c\u3002\u521b\u5efaASTRA\u6570\u636e\u96c6\u548c\u751f\u6210\u7ba1\u9053\u6765\u8bc4\u4f30\u4efb\u52a1\u4e0e\u6743\u9650\u8303\u56f4\u7684\u8bed\u4e49\u5339\u914d\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u57fa\u4e8e\u6a21\u578b\u7684\u5339\u914d\u65b9\u6cd5\u5177\u6709\u6f5c\u529b\u4f46\u4e5f\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5f53\u5b8c\u6210\u4efb\u52a1\u6240\u9700\u7684\u6743\u9650\u8303\u56f4\u6570\u91cf\u589e\u52a0\u65f6\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u8bed\u4e49\u5339\u914d\u6280\u672f\uff0c\u4ee5\u5b9e\u73b0\u591a\u4ee3\u7406\u548c\u5de5\u5177\u589e\u5f3a\u5e94\u7528\u7684\u610f\u56fe\u611f\u77e5\u6388\u6743\uff0c\u5305\u62ec\u7ec6\u7c92\u5ea6\u63a7\u5236\u5982\u57fa\u4e8e\u4efb\u52a1\u7684\u8bbf\u95ee\u63a7\u5236(TBAC)\u3002"}}
{"id": "2510.26721", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.26721", "abs": "https://arxiv.org/abs/2510.26721", "authors": ["Xinhan Zheng", "Huyu Wu", "Xueting Wang", "Haiyun Jiang"], "title": "Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis", "comment": null, "summary": "Multimodal large language models (MLLMs) exhibit a pronounced preference for\ntextual inputs when processing vision-language data, limiting their ability to\nreason effectively from visual evidence. Unlike prior studies that attribute\nthis text bias to external factors such as data imbalance or instruction\ntuning, we propose that the bias originates from the model's internal\narchitecture. Specifically, we hypothesize that visual key vectors (Visual\nKeys) are out-of-distribution (OOD) relative to the text key space learned\nduring language-only pretraining. Consequently, these visual keys receive\nsystematically lower similarity scores during attention computation, leading to\ntheir under-utilization in the context representation. To validate this\nhypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze their\ndistributional structures using qualitative (t-SNE) and quantitative\n(Jensen-Shannon divergence) methods. The results provide direct evidence that\nvisual and textual keys occupy markedly distinct subspaces within the attention\nspace. The inter-modal divergence is statistically significant, exceeding\nintra-modal variation by several orders of magnitude. These findings reveal\nthat text bias arises from an intrinsic misalignment within the attention key\nspace rather than solely from external data factors.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6587\u672c\u504f\u89c1\uff0c\u8fd9\u79cd\u504f\u89c1\u6e90\u4e8e\u6a21\u578b\u5185\u90e8\u67b6\u6784\u95ee\u9898\u2014\u2014\u89c6\u89c9\u952e\u5411\u91cf\u5728\u6ce8\u610f\u529b\u7a7a\u95f4\u4e2d\u4e0e\u6587\u672c\u952e\u5411\u91cf\u5206\u5e03\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u89c6\u89c9\u4fe1\u606f\u5728\u6ce8\u610f\u529b\u8ba1\u7b97\u4e2d\u88ab\u4f4e\u4f30\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u89c6\u89c9-\u8bed\u8a00\u6570\u636e\u65f6\u8868\u73b0\u51fa\u660e\u663e\u7684\u6587\u672c\u504f\u597d\uff0c\u9650\u5236\u4e86\u5176\u57fa\u4e8e\u89c6\u89c9\u8bc1\u636e\u8fdb\u884c\u6709\u6548\u63a8\u7406\u7684\u80fd\u529b\u3002\u4e0e\u4e4b\u524d\u5c06\u6587\u672c\u504f\u89c1\u5f52\u56e0\u4e8e\u6570\u636e\u4e0d\u5e73\u8861\u6216\u6307\u4ee4\u8c03\u4f18\u7684\u7814\u7a76\u4e0d\u540c\uff0c\u672c\u7814\u7a76\u8ba4\u4e3a\u504f\u89c1\u6e90\u4e8e\u6a21\u578b\u5185\u90e8\u67b6\u6784\u3002", "method": "\u4eceLLaVA\u548cQwen2.5-VL\u6a21\u578b\u4e2d\u63d0\u53d6\u952e\u5411\u91cf\uff0c\u4f7f\u7528t-SNE\u8fdb\u884c\u5b9a\u6027\u5206\u6790\u548cJensen-Shannon\u6563\u5ea6\u8fdb\u884c\u5b9a\u91cf\u5206\u6790\uff0c\u7814\u7a76\u89c6\u89c9\u548c\u6587\u672c\u952e\u5411\u91cf\u5728\u6ce8\u610f\u529b\u7a7a\u95f4\u4e2d\u7684\u5206\u5e03\u7ed3\u6784\u3002", "result": "\u89c6\u89c9\u548c\u6587\u672c\u952e\u5411\u91cf\u5728\u6ce8\u610f\u529b\u7a7a\u95f4\u4e2d\u5360\u636e\u660e\u663e\u4e0d\u540c\u7684\u5b50\u7a7a\u95f4\uff0c\u6a21\u6001\u95f4\u5dee\u5f02\u5728\u7edf\u8ba1\u4e0a\u663e\u8457\uff0c\u8d85\u8fc7\u6a21\u6001\u5185\u53d8\u5f02\u7684\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u6587\u672c\u504f\u89c1\u6e90\u4e8e\u6ce8\u610f\u529b\u952e\u7a7a\u95f4\u5185\u90e8\u7684\u5185\u5728\u9519\u4f4d\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5916\u90e8\u6570\u636e\u56e0\u7d20\u5bfc\u81f4\u7684\u3002"}}
{"id": "2510.26732", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26732", "abs": "https://arxiv.org/abs/2510.26732", "authors": ["J. de Curt\u00f2", "I. de Zarz\u00e0", "Pablo Garc\u00eda", "Jordi Cabot"], "title": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models", "comment": null, "summary": "This paper presents a comprehensive cross-platform evaluation of reasoning\ncapabilities in contemporary foundation models, establishing an\ninfrastructure-agnostic benchmark across three computational paradigms: HPC\nsupercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and\nuniversity clusters (a node with eight H200 GPUs).\n  We evaluate 15 foundation models across 79 problems spanning eight academic\ndomains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,\nCalculus, and Optimization) through three experimental phases: (1) Baseline\nestablishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,\nMistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing\nmethodology and reference performance; (2) Infrastructure validation: The\n19-problem benchmark repeated on university cluster (seven models including\nFalcon-Mamba state-space architecture) and Nebius AI Studio (nine\nstate-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3\n30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic\nreproducibility; (3) Extended evaluation: Full 79-problem assessment on both\nuniversity cluster and Nebius platforms, probing generalization at scale across\narchitectural diversity.\n  The findings challenge conventional scaling assumptions, establish training\ndata quality as more critical than model size, and provide actionable\nguidelines for model selection across educational, production, and research\ncontexts. The tri-infrastructure methodology and 79-problem benchmark enable\nlongitudinal tracking of reasoning capabilities as foundation models evolve.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5f53\u4ee3\u57fa\u7840\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u4e86\u8de8\u5e73\u53f0\u8bc4\u4f30\uff0c\u5efa\u7acb\u4e86\u57fa\u7840\u8bbe\u65bd\u65e0\u5173\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6HPC\u8d85\u7ea7\u8ba1\u7b97\u3001\u4e91\u5e73\u53f0\u548c\u5927\u5b66\u96c6\u7fa4\u4e09\u79cd\u8ba1\u7b97\u8303\u5f0f\u3002", "motivation": "\u6311\u6218\u4f20\u7edf\u7684\u89c4\u6a21\u6269\u5c55\u5047\u8bbe\uff0c\u8bc4\u4f30\u4e0d\u540c\u57fa\u7840\u8bbe\u65bd\u4e0a\u57fa\u7840\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u6559\u80b2\u3001\u751f\u4ea7\u548c\u7814\u7a76\u73af\u5883\u4e2d\u7684\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u5b9e\u7528\u6307\u5357\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u5b9e\u9a8c\u65b9\u6cd5\uff1a\u57fa\u51c6\u5efa\u7acb\uff086\u4e2a\u6a21\u578b\u572819\u4e2a\u95ee\u9898\u4e0a\uff09\u3001\u57fa\u7840\u8bbe\u65bd\u9a8c\u8bc1\uff08\u5728\u4e24\u79cd\u5e73\u53f0\u4e0a\u91cd\u590d\u57fa\u51c6\u6d4b\u8bd5\uff09\u3001\u6269\u5c55\u8bc4\u4f30\uff08\u572879\u4e2a\u95ee\u9898\u4e0a\u5168\u9762\u8bc4\u4f30\uff09\u3002", "result": "\u53d1\u73b0\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u6bd4\u6a21\u578b\u89c4\u6a21\u66f4\u91cd\u8981\uff0c\u5efa\u7acb\u4e86\u57fa\u7840\u8bbe\u65bd\u65e0\u5173\u7684\u53ef\u590d\u73b0\u6027\uff0c\u63d0\u4f9b\u4e86\u8de8\u67b6\u6784\u591a\u6837\u6027\u7684\u6cdb\u5316\u80fd\u529b\u8bc4\u4f30\u3002", "conclusion": "\u4e09\u57fa\u7840\u8bbe\u65bd\u65b9\u6cd5\u548c79\u95ee\u9898\u57fa\u51c6\u80fd\u591f\u7eb5\u5411\u8ddf\u8e2a\u57fa\u7840\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u53d1\u5c55\uff0c\u4e3a\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2510.26752", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26752", "abs": "https://arxiv.org/abs/2510.26752", "authors": ["William Overman", "Mohsen Bayati"], "title": "The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy", "comment": null, "summary": "As increasingly capable agents are deployed, a central safety question is how\nto retain meaningful human control without modifying the underlying system. We\nstudy a minimal control interface where an agent chooses whether to act\nautonomously (play) or defer (ask), while a human simultaneously chooses\nwhether to be permissive (trust) or to engage in oversight (oversee). If the\nagent defers, the human's choice determines the outcome, potentially leading to\na corrective action or a system shutdown. We model this interaction as a\ntwo-player Markov Game. Our analysis focuses on cases where this game qualifies\nas a Markov Potential Game (MPG), a class of games where we can provide an\nalignment guarantee: under a structural assumption on the human's value\nfunction, any decision by the agent to act more autonomously that benefits\nitself cannot harm the human's value. We also analyze extensions to this MPG\nframework. Theoretically, this perspective provides conditions for a specific\nform of intrinsic alignment. If the reward structures of the human-agent game\nmeet these conditions, we have a formal guarantee that the agent improving its\nown outcome will not harm the human's. Practically, this model motivates a\ntransparent control layer with predictable incentives where the agent learns to\ndefer when risky and act when safe, while its pretrained policy and the\nenvironment's reward structure remain untouched. Our gridworld simulation shows\nthat through independent learning, the agent and human discover their optimal\noversight roles. The agent learns to ask when uncertain and the human learns\nwhen to oversee, leading to an emergent collaboration that avoids safety\nviolations introduced post-training. This demonstrates a practical method for\nmaking misaligned models safer after deployment.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u6700\u5c0f\u63a7\u5236\u63a5\u53e3\uff0c\u8ba9\u667a\u80fd\u4f53\u5728\u81ea\u4e3b\u884c\u52a8\u548c\u8bf7\u6c42\u4eba\u7c7b\u5e72\u9884\u4e4b\u95f4\u9009\u62e9\uff0c\u4eba\u7c7b\u5219\u51b3\u5b9a\u662f\u5426\u4fe1\u4efb\u6216\u76d1\u7763\uff0c\u5f62\u6210\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u6846\u67b6\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u4fdd\u8bc1\u667a\u80fd\u4f53\u81ea\u4e3b\u6027\u63d0\u5347\u4e0d\u4f1a\u635f\u5bb3\u4eba\u7c7b\u4ef7\u503c\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u4f53\u80fd\u529b\u589e\u5f3a\uff0c\u5982\u4f55\u5728\u4fdd\u6301\u5e95\u5c42\u7cfb\u7edf\u4e0d\u53d8\u7684\u524d\u63d0\u4e0b\u7ef4\u6301\u6709\u610f\u4e49\u7684\u4eba\u7c7b\u63a7\u5236\u6210\u4e3a\u4e00\u4e2a\u6838\u5fc3\u5b89\u5168\u95ee\u9898\u3002", "method": "\u5c06\u4eba\u673a\u4ea4\u4e92\u5efa\u6a21\u4e3a\u4e24\u4eba\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\uff0c\u5728\u9a6c\u5c14\u53ef\u592b\u52bf\u535a\u5f08\u6846\u67b6\u4e0b\u5206\u6790\uff0c\u901a\u8fc7\u72ec\u7acb\u5b66\u4e60\u8ba9\u667a\u80fd\u4f53\u5b66\u4f1a\u5728\u4e0d\u786e\u5b9a\u65f6\u8bf7\u6c42\u5e2e\u52a9\uff0c\u4eba\u7c7b\u5b66\u4f1a\u9002\u65f6\u76d1\u7763\u3002", "result": "\u7f51\u683c\u4e16\u754c\u6a21\u62df\u663e\u793a\uff0c\u901a\u8fc7\u72ec\u7acb\u5b66\u4e60\uff0c\u667a\u80fd\u4f53\u548c\u4eba\u7c7b\u80fd\u53d1\u73b0\u6700\u4f18\u76d1\u7763\u89d2\u8272\uff0c\u667a\u80fd\u4f53\u5b66\u4f1a\u5728\u4e0d\u786e\u5b9a\u65f6\u8be2\u95ee\uff0c\u4eba\u7c7b\u5b66\u4f1a\u9002\u65f6\u76d1\u7763\uff0c\u5f62\u6210\u907f\u514d\u5b89\u5168\u8fdd\u89c4\u7684\u534f\u4f5c\u3002", "conclusion": "\u8be5\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u90e8\u7f72\u540e\u4f7f\u672a\u5bf9\u9f50\u6a21\u578b\u66f4\u5b89\u5168\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u4e3a\u7279\u5b9a\u5f62\u5f0f\u7684\u5185\u5728\u5bf9\u9f50\u63d0\u4f9b\u4e86\u7406\u8bba\u6761\u4ef6\u3002"}}
{"id": "2510.26784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26784", "abs": "https://arxiv.org/abs/2510.26784", "authors": ["Arnab Sen Sharma", "Giordano Rogers", "Natalie Shapira", "David Bau"], "title": "LLMs Process Lists With General Filter Heads", "comment": "Code and data at https://filter.baulab.info/", "summary": "We investigate the mechanisms underlying a range of list-processing tasks in\nLLMs, and we find that LLMs have learned to encode a compact, causal\nrepresentation of a general filtering operation that mirrors the generic\n\"filter\" function of functional programming. Using causal mediation analysis on\na diverse set of list-processing tasks, we find that a small number of\nattention heads, which we dub filter heads, encode a compact representation of\nthe filtering predicate in their query states at certain tokens. We demonstrate\nthat this predicate representation is general and portable: it can be extracted\nand reapplied to execute the same filtering operation on different collections,\npresented in different formats, languages, or even in tasks. However, we also\nidentify situations where transformer LMs can exploit a different strategy for\nfiltering: eagerly evaluating if an item satisfies the predicate and storing\nthis intermediate result as a flag directly in the item representations. Our\nresults reveal that transformer LMs can develop human-interpretable\nimplementations of abstract computational operations that generalize in ways\nthat are surprisingly similar to strategies used in traditional functional\nprogramming patterns.", "AI": {"tldr": "LLMs\u5b66\u4e60\u5230\u4e86\u7c7b\u4f3c\u51fd\u6570\u5f0f\u7f16\u7a0b\u4e2d'filter'\u64cd\u4f5c\u7684\u7d27\u51d1\u56e0\u679c\u8868\u793a\uff0c\u901a\u8fc7\u5c11\u91cf\u6ce8\u610f\u529b\u5934\u7f16\u7801\u8fc7\u6ee4\u8c13\u8bcd\uff0c\u8be5\u8868\u793a\u5177\u6709\u901a\u7528\u6027\u548c\u53ef\u79fb\u690d\u6027\uff0c\u5e76\u80fd\u5e94\u7528\u4e8e\u4e0d\u540c\u683c\u5f0f\u3001\u8bed\u8a00\u6216\u4efb\u52a1\u4e2d\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u5217\u8868\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u5de5\u4f5c\u673a\u5236\uff0c\u63a2\u7d22\u5176\u662f\u5426\u5b66\u4e60\u5230\u4e86\u62bd\u8c61\u7684\u8ba1\u7b97\u64cd\u4f5c\u8868\u793a\u3002", "method": "\u4f7f\u7528\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u5728\u591a\u6837\u5316\u7684\u5217\u8868\u5904\u7406\u4efb\u52a1\u4e0a\uff0c\u8bc6\u522b\u51fa\u7f16\u7801\u8fc7\u6ee4\u8c13\u8bcd\u7684\u6ce8\u610f\u529b\u5934\uff08\u79f0\u4e3afilter heads\uff09\uff0c\u5e76\u9a8c\u8bc1\u5176\u8868\u793a\u7684\u901a\u7528\u6027\u3002", "result": "\u53d1\u73b0LLMs\u786e\u5b9e\u5b66\u4e60\u5230\u4e86\u7d27\u51d1\u7684\u8fc7\u6ee4\u8c13\u8bcd\u8868\u793a\uff0c\u8be5\u8868\u793a\u5177\u6709\u901a\u7528\u6027\u548c\u53ef\u79fb\u690d\u6027\uff1b\u540c\u65f6\u8bc6\u522b\u51fa\u53e6\u4e00\u79cd\u8fc7\u6ee4\u7b56\u7565\uff1a\u6025\u5207\u8bc4\u4f30\u9879\u76ee\u662f\u5426\u6ee1\u8db3\u8c13\u8bcd\u5e76\u5c06\u7ed3\u679c\u4f5c\u4e3a\u6807\u5fd7\u5b58\u50a8\u5728\u9879\u76ee\u8868\u793a\u4e2d\u3002", "conclusion": "Transformer LMs\u80fd\u591f\u53d1\u5c55\u51fa\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u62bd\u8c61\u8ba1\u7b97\u64cd\u4f5c\u5b9e\u73b0\uff0c\u5176\u6cdb\u5316\u65b9\u5f0f\u4e0e\u4f20\u7edf\u51fd\u6570\u5f0f\u7f16\u7a0b\u6a21\u5f0f\u4e2d\u7684\u7b56\u7565\u60ca\u4eba\u76f8\u4f3c\u3002"}}
