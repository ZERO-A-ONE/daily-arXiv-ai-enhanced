{"id": "2507.05269", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05269", "abs": "https://arxiv.org/abs/2507.05269", "authors": ["Danning Xie", "Mingwei Zheng", "Xuwei Liu", "Jiannan Wang", "Chengpeng Wang", "Lin Tan", "Xiangyu Zhang"], "title": "CORE: Benchmarking LLMs Code Reasoning Capabilities through Static Analysis Tasks", "comment": null, "summary": "Large language models (LLMs) have been widely adopted across diverse software\nengineering domains, such as code generation, program repair, and vulnerability\ndetection. These applications require understanding beyond surface-level code\npatterns: value propagation, control flow, and interdependence between program\nelements. However, existing benchmarks primarily evaluate end-to-end outcomes,\nsuch as whether code is correctly repaired or generated, leaving the models\nability for program semantic reasoning underexplored. This work presents CoRe,\na high-quality, human-verified benchmark designed to evaluate LLMs on\nfundamental static analysis tasks. CoRe includes 12,553 task instances spanning\ndata dependency, control dependency, and information flow across programs\nwritten in C/C++, Java, and Python. To ensure semantic diversity and reasoning\ncomplexity, we propose a semantics-aware diverse sampling strategy that selects\ntargets and task instances based on structural coverage and dependency depth.\nWe evaluate 10 mainstream LLMs and show that, while they perform well at\nidentifying dependencies, models still struggle with tasks that require deeper\nsemantic understanding and multi-step reasoning. We further conduct qualitative\nanalyses to uncover key challenges, such as complex control structures and\nbackward dependency patterns, offering insights into improving LLMs code\nreasoning capabilities.", "AI": {"tldr": "CoRe\u662f\u4e00\u4e2a\u9ad8\u8d28\u91cf\u3001\u4eba\u5de5\u9a8c\u8bc1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9759\u6001\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u6df1\u5c42\u8bed\u4e49\u7406\u89e3\u548c\u591a\u6b65\u63a8\u7406\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u7aef\u5230\u7aef\u7ed3\u679c\uff0c\u5ffd\u7565\u4e86\u5bf9\u7a0b\u5e8f\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5168\u9762\u7684\u6d4b\u8bd5\u5de5\u5177\u3002", "method": "\u63d0\u51faCoRe\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b12,553\u4e2a\u4efb\u52a1\u5b9e\u4f8b\uff0c\u6db5\u76d6\u6570\u636e\u4f9d\u8d56\u3001\u63a7\u5236\u4f9d\u8d56\u548c\u4fe1\u606f\u6d41\uff0c\u91c7\u7528\u8bed\u4e49\u611f\u77e5\u7684\u591a\u6837\u6027\u91c7\u6837\u7b56\u7565\u3002", "result": "\u8bc4\u4f3010\u79cd\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u5176\u5728\u4f9d\u8d56\u8bc6\u522b\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6df1\u5c42\u8bed\u4e49\u548c\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u6a21\u578b\u5728\u590d\u6742\u63a7\u5236\u7ed3\u6784\u548c\u53cd\u5411\u4f9d\u8d56\u6a21\u5f0f\u4e0a\u7684\u6311\u6218\uff0c\u4e3a\u63d0\u5347\u4ee3\u7801\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.05270", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05270", "abs": "https://arxiv.org/abs/2507.05270", "authors": ["Boyuan Li", "Chengwei Liu", "Lingling Fan", "Sen Chen", "Zhenlin Zhang", "Zheli Liu"], "title": "Open Source, Hidden Costs: A Systematic Literature Review on OSS License Management", "comment": null, "summary": "Integrating third-party software components is a common practice in modern\nsoftware development, offering significant advantages in terms of efficiency\nand innovation. However, this practice is fraught with risks related to\nsoftware licensing. A lack of understanding may lead to disputes, which can\npose serious legal and operational challenges. To these ends, both academia and\nindustry have conducted various investigations and proposed solutions and tools\nto deal with these challenges. However, significant limitations still remain.\nMoreover, the rapid evolution of open-source software (OSS) licenses, as well\nas the rapidly incorporated generative software engineering techniques, such as\nlarge language models for code (CodeLLMs), are placing greater demands on the\nsystematic management of software license risks. To unveil the severe\nchallenges and explore possible future directions, we conduct the first\nsystematic literature review (SLR) on 80 carefully selected OSS license-related\npapers, classifying existing research into three key categories, i.e., license\nidentification, license risk assessment, and license risk mitigation. Based on\nthese, we discuss challenges in existing solutions, conclude the opportunities\nto shed light on future research directions and offer practical recommendations\nfor practitioners. We hope this thorough review will help bridge the gaps\nbetween academia and industry and accelerate the ecosystem-wide governance of\nlegitimate software risks within the software engineering community.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u7b2c\u4e09\u65b9\u8f6f\u4ef6\u7ec4\u4ef6\u96c6\u6210\u4e2d\u7684\u8bb8\u53ef\u8bc1\u98ce\u9669\uff0c\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u5206\u7c7b\u73b0\u6709\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u65b9\u5411\u548c\u5b9e\u8df5\u5efa\u8bae\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u96c6\u6210\u7b2c\u4e09\u65b9\u7ec4\u4ef6\u867d\u9ad8\u6548\u4f46\u4f34\u968f\u8bb8\u53ef\u8bc1\u98ce\u9669\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u4ecd\u6709\u5c40\u9650\uff0c\u9700\u7cfb\u7edf\u6027\u7ba1\u7406\u3002", "method": "\u5bf980\u7bc7\u5f00\u6e90\u8f6f\u4ef6\u8bb8\u53ef\u8bc1\u76f8\u5173\u8bba\u6587\u8fdb\u884c\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u7c7b\u4e3a\u8bb8\u53ef\u8bc1\u8bc6\u522b\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u98ce\u9669\u7f13\u89e3\u3002", "result": "\u63ed\u793a\u4e86\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u548c\u5b9e\u8df5\u5efa\u8bae\u3002", "conclusion": "\u5e0c\u671b\u586b\u8865\u5b66\u672f\u754c\u4e0e\u5de5\u4e1a\u754c\u95f4\u7684\u9e3f\u6c9f\uff0c\u52a0\u901f\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u5bf9\u5408\u6cd5\u8f6f\u4ef6\u98ce\u9669\u7684\u7cfb\u7edf\u6cbb\u7406\u3002"}}
{"id": "2507.05272", "categories": ["cs.SE", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.05272", "abs": "https://arxiv.org/abs/2507.05272", "authors": ["Daragh King", "Vasileios Koutavas", "Laura Kovacs"], "title": "FuzzFeed: An Automatic Approach to Weakest Precondition Generation using LLMs and Fuzzing", "comment": null, "summary": "The weakest precondition (WP) of a program describes the largest set of\ninitial states from which all terminating executions of the program satisfy a\ngiven postcondition. The generation of WPs is an important task with practical\napplications in areas ranging from verification to run-time error checking.\n  This paper proposes the combination of Large Language Models (LLMs) and fuzz\ntesting for generating WPs. In pursuit of this goal, we introduce Fuzzing\nGuidance (FG); FG acts as a means of directing LLMs towards correct WPs using\nprogram execution feedback. FG utilises fuzz testing for approximately checking\nthe validity and weakness of candidate WPs, this information is then fed back\nto the LLM as a means of context refinement.\n  We demonstrate the effectiveness of our approach on a comprehensive benchmark\nset of deterministic array programs in Java. Our experiments indicate that LLMs\nare capable of producing viable candidate WPs, and that this ability can be\npractically enhanced through FG.", "AI": {"tldr": "\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u6a21\u7cca\u6d4b\u8bd5\u751f\u6210\u6700\u5f31\u524d\u7f6e\u6761\u4ef6\uff08WP\uff09\uff0c\u901a\u8fc7\u6a21\u7cca\u6307\u5bfc\uff08FG\uff09\u5229\u7528\u6267\u884c\u53cd\u9988\u4f18\u5316LLMs\u7684\u8f93\u51fa\u3002", "motivation": "\u751f\u6210\u6700\u5f31\u524d\u7f6e\u6761\u4ef6\uff08WP\uff09\u5728\u9a8c\u8bc1\u548c\u8fd0\u884c\u65f6\u9519\u8bef\u68c0\u67e5\u7b49\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u6709\u9650\u3002", "method": "\u63d0\u51fa\u6a21\u7cca\u6307\u5bfc\uff08FG\uff09\uff0c\u5229\u7528\u6a21\u7cca\u6d4b\u8bd5\u9a8c\u8bc1\u5019\u9009WP\u7684\u5f31\u6027\u548c\u6b63\u786e\u6027\uff0c\u5e76\u5c06\u53cd\u9988\u7528\u4e8e\u4f18\u5316LLMs\u7684\u8f93\u51fa\u3002", "result": "\u5728Java\u786e\u5b9a\u6027\u6570\u7ec4\u7a0b\u5e8f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLLMs\u80fd\u751f\u6210\u53ef\u884c\u7684\u5019\u9009WP\uff0c\u4e14FG\u80fd\u663e\u8457\u63d0\u5347\u5176\u6548\u679c\u3002", "conclusion": "LLMs\u7ed3\u5408FG\u80fd\u6709\u6548\u751f\u6210WP\uff0c\u4e3a\u7a0b\u5e8f\u9a8c\u8bc1\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2507.05279", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.05279", "abs": "https://arxiv.org/abs/2507.05279", "authors": ["Virgile Boraud", "Yannis Bendi-Ouis", "Paul Bernard", "Xavier Hinaut"], "title": "ReservoirChat: Interactive Documentation Enhanced with LLM and Knowledge Graph for ReservoirPy", "comment": null, "summary": "We introduce a tool designed to improve the capabilities of Large Language\nModels (LLMs) in assisting with code development using the ReservoirPy library,\nas well as in answering complex questions in the field of Reservoir Computing.\nBy incorporating external knowledge through Retrieval-Augmented Generation\n(RAG) and knowledge graphs, our approach aims to reduce hallucinations and\nincrease the factual accuracy of generated responses. The system provides an\ninteractive experience similar to ChatGPT, tailored specifically for\nReservoirPy, enabling users to write, debug, and understand Python code while\naccessing reliable domain-specific insights. In our evaluation, while\nproprietary models such as ChatGPT-4o and NotebookLM performed slightly better\non general knowledge questions, our model outperformed them on coding tasks and\nshowed a significant improvement over its base model, Codestral-22B.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5de5\u5177\uff0c\u901a\u8fc7\u7ed3\u5408RAG\u548c\u77e5\u8bc6\u56fe\u8c31\u63d0\u5347LLMs\u5728ReservoirPy\u5e93\u4ee3\u7801\u5f00\u53d1\u548cReservoir Computing\u9886\u57df\u95ee\u7b54\u4e2d\u7684\u80fd\u529b\uff0c\u51cf\u5c11\u5e7b\u89c9\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u63d0\u5347LLMs\u5728\u4ee3\u7801\u5f00\u53d1\u548c\u4e13\u4e1a\u9886\u57df\u95ee\u7b54\u4e2d\u7684\u8868\u73b0\uff0c\u51cf\u5c11\u9519\u8bef\u4fe1\u606f\u3002", "method": "\u7ed3\u5408Retrieval-Augmented Generation (RAG)\u548c\u77e5\u8bc6\u56fe\u8c31\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u4f53\u9a8c\u3002", "result": "\u5728\u4ee3\u7801\u4efb\u52a1\u4e0a\u4f18\u4e8eChatGPT-4o\u548cNotebookLM\uff0c\u663e\u8457\u8d85\u8d8a\u57fa\u7840\u6a21\u578bCodestral-22B\u3002", "conclusion": "\u8be5\u5de5\u5177\u5728\u4e13\u4e1a\u9886\u57df\u548c\u4ee3\u7801\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.05267", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05267", "abs": "https://arxiv.org/abs/2507.05267", "authors": ["Markus B\u00f6ck"], "title": "Strongly Solving $7 \\times 6$ Connect-Four on Consumer Grade Hardware", "comment": null, "summary": "While the game Connect-Four has been solved mathematically and the best move\ncan be effectively computed with search based methods, a strong solution in the\nform of a look-up table was believed to be infeasible. In this paper, we\nrevisit a symbolic search method based on binary decision diagrams to produce\nstrong solutions. With our efficient implementation we were able to produce a\n89.6 GB large look-up table in 47 hours on a single CPU core with 128 GB main\nmemory for the standard $7 \\times 6$ board size. In addition to this\nwin-draw-loss evaluation, we include an alpha-beta search in our open source\nartifact to find the move which achieves the fastest win or slowest loss.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7b26\u53f7\u641c\u7d22\u65b9\u6cd5\uff08\u57fa\u4e8e\u4e8c\u5143\u51b3\u7b56\u56fe\uff09\u4e3aConnect-Four\u6e38\u620f\u751f\u6210\u5f3a\u89e3\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u6548\u768489.6GB\u67e5\u627e\u8868\u3002", "motivation": "\u5c3d\u7ba1Connect-Four\u6e38\u620f\u5df2\u6709\u6570\u5b66\u89e3\uff0c\u4f46\u4f20\u7edf\u8ba4\u4e3a\u5f3a\u89e3\u5f62\u5f0f\u7684\u67e5\u627e\u8868\u4e0d\u53ef\u884c\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u7b26\u53f7\u641c\u7d22\u65b9\u6cd5\u751f\u6210\u5f3a\u89e3\u7684\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4e8c\u5143\u51b3\u7b56\u56fe\u7684\u7b26\u53f7\u641c\u7d22\u65b9\u6cd5\uff0c\u9ad8\u6548\u5b9e\u73b0\u751f\u6210\u67e5\u627e\u8868\uff0c\u5e76\u5305\u542balpha-beta\u641c\u7d22\u4ee5\u4f18\u5316\u6700\u5feb\u80dc\u5229\u6216\u6700\u6162\u5931\u8d25\u7684\u7b56\u7565\u3002", "result": "\u6210\u529f\u751f\u621089.6GB\u7684\u67e5\u627e\u8868\uff0c\u8017\u65f647\u5c0f\u65f6\uff08\u5355CPU\u6838\u5fc3\uff0c128GB\u5185\u5b58\uff09\uff0c\u9002\u7528\u4e8e\u6807\u51c67\u00d76\u68cb\u76d8\u3002", "conclusion": "\u7b26\u53f7\u641c\u7d22\u65b9\u6cd5\u53ef\u884c\u4e14\u9ad8\u6548\uff0c\u4e3aConnect-Four\u63d0\u4f9b\u4e86\u5f3a\u89e3\uff0c\u5e76\u5f00\u6e90\u4e86\u76f8\u5173\u5de5\u5177\u3002"}}
{"id": "2507.05415", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05415", "abs": "https://arxiv.org/abs/2507.05415", "authors": ["Lu Xian", "Van Tran", "Lauren Lee", "Meera Kumar", "Yichen Zhang", "Florian Schaub"], "title": "Layered, Overlapping, and Inconsistent: A Large-Scale Analysis of the Multiple Privacy Policies and Controls of U.S. Banks", "comment": "Accepted for publication in CCS 2025. This is a pre-publication\n  version", "summary": "Privacy policies are often complex. An exception is the two-page standardized\nnotice that U.S. financial institutions must provide under the\nGramm-Leach-Bliley Act (GLBA). However, banks now operate websites, mobile\napps, and other services that involve complex data sharing practices that\nrequire additional privacy notices and do-not-sell opt-outs. We conducted a\nlarge-scale analysis of how U.S. banks implement privacy policies and controls\nin response to GLBA; other federal privacy policy requirements; and the\nCalifornia Consumer Privacy Act (CCPA), a key example for U.S. state privacy\nlaws. We focused on the disclosure and control of a set of especially\nprivacy-invasive practices: third-party data sharing for marketing-related\npurposes. We collected privacy policies for the 2,067 largest U.S. banks,\n45.3\\% of which provided multiple policies. Across disclosures and controls\nwithin the \\textit{same} bank, we identified frequent, concerning\ninconsistencies -- such as banks indicating in GLBA notices that they do not\nshare with third parties but disclosing sharing elsewhere, or using third-party\nmarketing/advertising cookies without disclosure. This multiplicity of\npolicies, with the inconsistencies it causes, may create consumer confusion and\nundermine the transparency goals of the very laws that require them. Our\nfindings call into question whether current policy requirements, such as the\nGLBA notice, are achieving their intended goals in today's online banking\nlandscape. We discuss potential avenues for reforming and harmonizing privacy\npolicies and control requirements across federal and state laws.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u7f8e\u56fd\u94f6\u884c\u5728\u9690\u79c1\u653f\u7b56\u5b9e\u65bd\u4e2d\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u53ef\u80fd\u524a\u5f31\u900f\u660e\u5ea6\u76ee\u6807\u3002", "motivation": "\u5206\u6790\u7f8e\u56fd\u94f6\u884c\u5982\u4f55\u6267\u884c\u9690\u79c1\u653f\u7b56\uff0c\u5c24\u5176\u662f\u6d89\u53ca\u7b2c\u4e09\u65b9\u6570\u636e\u5171\u4eab\u7684\u9690\u79c1\u4fb5\u5165\u6027\u5b9e\u8df5\u3002", "method": "\u6536\u96c6\u5e76\u5206\u67902067\u5bb6\u7f8e\u56fd\u6700\u5927\u94f6\u884c\u7684\u9690\u79c1\u653f\u7b56\uff0c\u5173\u6ce8\u62ab\u9732\u548c\u63a7\u5236\u7684\u4e00\u81f4\u6027\u3002", "result": "\u53d1\u73b0\u653f\u7b56\u95f4\u5b58\u5728\u9891\u7e41\u4e0d\u4e00\u81f4\uff0c\u5982GLBA\u901a\u77e5\u4e0e\u5b9e\u9645\u62ab\u9732\u4e0d\u7b26\uff0c\u53ef\u80fd\u5f15\u53d1\u6d88\u8d39\u8005\u56f0\u60d1\u3002", "conclusion": "\u8d28\u7591\u5f53\u524d\u653f\u7b56\u8981\u6c42\u662f\u5426\u6709\u6548\uff0c\u63d0\u51fa\u6539\u9769\u548c\u534f\u8c03\u8054\u90a6\u4e0e\u5dde\u6cd5\u5f8b\u7684\u9690\u79c1\u653f\u7b56\u5efa\u8bae\u3002"}}
{"id": "2507.05281", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05281", "abs": "https://arxiv.org/abs/2507.05281", "authors": ["Lingyue Fu", "Hao Guan", "Bolun Zhang", "Haowei Yuan", "Yaoming Zhu", "Jun Xu", "Zongyu Wang", "Lin Qiu", "Xunliang Cai", "Xuezhi Cao", "Weiwen Liu", "Weinan Zhang", "Yong Yu"], "title": "CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark", "comment": null, "summary": "As Large Language Models (LLMs) demonstrate increasingly sophisticated code\nprocessing capabilities, evaluating their performance on engineering-level code\nremains challenging. Existing repository-level benchmarks primarily focus on\nsingle scenarios, such as code generation or bug fixing, without adequately\ncapturing the diversity and complexity of real-world software or project\nengineering workflows. Furthermore, these benchmarks suffer from limited\ncontrollability in question positioning and reliability issues in their\ngenerated test cases. To address these limitations, we present CorePipe, a\nfully automated pipeline that converts repositories into comprehensive test\ncases, and introduce CoreCodeBench, a configurable multi-scenario\nrepository-level benchmark. To simulate real engineering scenarios, CorePipe\ngenerates three types of atomic questions (Development, BugFix, and Test-Driven\nDevelopment) specifically targeting core code segments. These atomic questions\nare further combined into three types of composite questions, with difficulty\nlevels flexibly adjusted through hyperparameter tuning. CoreCodeBench provides\na comprehensive and extensive repository-level benchmark to investigate the\napplicability of LLMs in real-world engineering projects. Experiments with 16\nLLMs across diverse scenarios reveal varying capabilities and offer\nmulti-dimensional insights into LLM performance in engineering contexts. The\ncode for CorePipe is available at\nhttps://github.com/AGI-Eval-Official/CoreCodeBench, and the data for\nCoreCodeBench can be accessed at\nhttps://huggingface.co/collections/tubehhh/corecodebench-68256d2faabf4b1610a08caa.", "AI": {"tldr": "CorePipe\u548cCoreCodeBench\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u7ba1\u9053\u548c\u53ef\u914d\u7f6e\u7684\u591a\u573a\u666f\u4ed3\u5e93\u7ea7\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u771f\u5b9e\u5de5\u7a0b\u73af\u5883\u4e2d\u7684\u4ee3\u7801\u5904\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u4ed3\u5e93\u7ea7\u57fa\u51c6\u6d4b\u8bd5\u5c40\u9650\u4e8e\u5355\u4e00\u573a\u666f\uff0c\u65e0\u6cd5\u5168\u9762\u53cd\u6620\u771f\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u7684\u591a\u6837\u6027\u548c\u590d\u6742\u6027\uff0c\u4e14\u5b58\u5728\u53ef\u63a7\u6027\u548c\u53ef\u9760\u6027\u95ee\u9898\u3002", "method": "CorePipe\u5c06\u4ed3\u5e93\u8f6c\u5316\u4e3a\u7efc\u5408\u6d4b\u8bd5\u7528\u4f8b\uff0c\u751f\u6210\u4e09\u79cd\u539f\u5b50\u95ee\u9898\uff08\u5f00\u53d1\u3001\u4fee\u590d\u3001\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1\uff09\uff0c\u5e76\u7ec4\u5408\u4e3a\u590d\u5408\u95ee\u9898\uff0c\u901a\u8fc7\u8d85\u53c2\u6570\u8c03\u6574\u96be\u5ea6\u3002CoreCodeBench\u4f5c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u4e8616\u79cdLLM\uff0c\u63ed\u793a\u4e86\u5176\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u80fd\u529b\u5dee\u5f02\uff0c\u63d0\u4f9b\u4e86\u591a\u7ef4\u5ea6\u7684\u6027\u80fd\u6d1e\u5bdf\u3002", "conclusion": "CoreCodeBench\u4e3a\u7814\u7a76LLM\u5728\u771f\u5b9e\u5de5\u7a0b\u9879\u76ee\u7684\u9002\u7528\u6027\u63d0\u4f9b\u4e86\u5168\u9762\u4e14\u5e7f\u6cdb\u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u3002"}}
{"id": "2507.05283", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05283", "abs": "https://arxiv.org/abs/2507.05283", "authors": ["Yue Wang", "Miao Zhou", "Guijing Huang", "Rui Zhuo", "Chao Yi", "Zhenliang Ma"], "title": "Chat2SPaT: A Large Language Model Based Tool for Automating Traffic Signal Control Plan Management", "comment": null, "summary": "Pre-timed traffic signal control, commonly used for operating signalized\nintersections and coordinated arterials, requires tedious manual work for\nsignaling plan creating and updating. When the time-of-day or day-of-week plans\nare utilized, one intersection is often associated with multiple plans, leading\nto further repetitive manual plan parameter inputting. To enable a\nuser-friendly traffic signal control plan management process, this study\nproposes Chat2SPaT, a method to convert users' semi-structured and ambiguous\ndescriptions on the signal control plan to exact signal phase and timing (SPaT)\nresults, which could further be transformed into structured stage-based or\nring-based plans to interact with intelligent transportation system (ITS)\nsoftware and traffic signal controllers. With curated prompts, Chat2SPaT first\nleverages large language models' (LLMs) capability of understanding users' plan\ndescriptions and reformulate the plan as a combination of phase sequence and\nphase attribute results in the json format. Based on LLM outputs, python\nscripts are designed to locate phases in a cycle, address nuances of traffic\nsignal control, and finally assemble the complete traffic signal control plan.\nWithin a chat, the pipeline can be utilized iteratively to conduct further plan\nediting. Experiments show that Chat2SPaT can generate plans with an accuracy of\nover 94% for both English and Chinese cases, using a test dataset with over 300\nplan descriptions. As the first benchmark for evaluating LLMs' capability of\nunderstanding traffic signal control plan descriptions, Chat2SPaT provides an\neasy-to-use plan management pipeline for traffic practitioners and researchers,\nserving as a potential new building block for a more accurate and versatile\napplication of LLMs in the field of ITS. The source codes, prompts and test\ndataset are openly accessible at https://github.com/yuewangits/Chat2SPaT.", "AI": {"tldr": "Chat2SPaT\u662f\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c06\u7528\u6237\u5bf9\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u8ba1\u5212\u7684\u534a\u7ed3\u6784\u5316\u63cf\u8ff0\u8f6c\u6362\u4e3a\u7cbe\u786e\u7684\u4fe1\u53f7\u76f8\u4f4d\u548c\u65f6\u5e8f\uff08SPaT\uff09\u7ed3\u679c\uff0c\u51c6\u786e\u7387\u8d85\u8fc794%\u3002", "motivation": "\u51cf\u5c11\u624b\u52a8\u8f93\u5165\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u8ba1\u5212\u7684\u7e41\u7410\u5de5\u4f5c\uff0c\u63d0\u9ad8\u8ba1\u5212\u7ba1\u7406\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u5229\u7528LLMs\u7406\u89e3\u7528\u6237\u63cf\u8ff0\u5e76\u751f\u6210JSON\u683c\u5f0f\u7684\u76f8\u4f4d\u5e8f\u5217\u548c\u5c5e\u6027\uff0c\u518d\u901a\u8fc7Python\u811a\u672c\u7ec4\u88c5\u5b8c\u6574\u7684\u4fe1\u53f7\u63a7\u5236\u8ba1\u5212\u3002", "result": "\u5728\u6d4b\u8bd5\u6570\u636e\u96c6\uff08300\u591a\u4e2a\u8ba1\u5212\u63cf\u8ff0\uff09\u4e2d\uff0cChat2SPaT\u7684\u51c6\u786e\u7387\u8d85\u8fc794%\uff08\u4e2d\u82f1\u6587\u5747\u9002\u7528\uff09\u3002", "conclusion": "Chat2SPaT\u4e3a\u4ea4\u901a\u4ece\u4e1a\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u6613\u4e8e\u4f7f\u7528\u7684\u8ba1\u5212\u7ba1\u7406\u5de5\u5177\uff0c\u5c55\u793a\u4e86LLMs\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\uff08ITS\uff09\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.05421", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05421", "abs": "https://arxiv.org/abs/2507.05421", "authors": ["Harrison Green", "Claire Le Goues", "Fraser Brown"], "title": "FrameShift: Learning to Resize Fuzzer Inputs Without Breaking Them", "comment": null, "summary": "Coverage-guided fuzzers are powerful automated bug-finding tools. They mutate\nprogram inputs, observe coverage, and save any input that hits an unexplored\npath for future mutation. Unfortunately, without knowledge of input\nformats--for example, the relationship between formats' data fields and\nsizes--fuzzers are prone to generate destructive frameshift mutations. These\ntime-wasting mutations yield malformed inputs that are rejected by the target\nprogram. To avoid such breaking mutations, this paper proposes a novel,\nlightweight technique that preserves the structure of inputs during mutation by\ndetecting and using relation fields.\n  Our technique, FrameShift, is simple, fast, and does not require additional\ninstrumentation beyond standard coverage feedback. We implement our technique\nin two state-of-the-art fuzzers, AFL++ and LibAFL, and perform a 12+ CPU-year\nfuzzer evaluation, finding that FrameShift improves the performance of the\nfuzzer in each configuration, sometimes increasing coverage by more than 50%.\nFurthermore, through a series of case studies, we show that our technique is\nversatile enough to find important structural relationships in a variety of\nformats, even generalizing beyond C/C++ targets to both Rust and Python.", "AI": {"tldr": "FrameShift\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6280\u672f\uff0c\u901a\u8fc7\u68c0\u6d4b\u548c\u4f7f\u7528\u5173\u7cfb\u5b57\u6bb5\u5728\u7a81\u53d8\u4e2d\u4fdd\u7559\u8f93\u5165\u7ed3\u6784\uff0c\u907f\u514d\u7834\u574f\u6027\u7a81\u53d8\uff0c\u63d0\u5347\u6a21\u7cca\u6d4b\u8bd5\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u56e0\u7f3a\u4e4f\u8f93\u5165\u683c\u5f0f\u77e5\u8bc6\uff0c\u5bb9\u6613\u751f\u6210\u7834\u574f\u6027\u7a81\u53d8\uff0c\u5bfc\u81f4\u65e0\u6548\u8f93\u5165\u3002", "method": "\u63d0\u51faFrameShift\u6280\u672f\uff0c\u5229\u7528\u5173\u7cfb\u5b57\u6bb5\u4fdd\u6301\u8f93\u5165\u7ed3\u6784\uff0c\u65e0\u9700\u989d\u5916\u5de5\u5177\u3002", "result": "\u5728AFL++\u548cLibAFL\u4e2d\u5b9e\u73b0\uff0c12+ CPU\u5e74\u6d4b\u8bd5\u663e\u793a\u8986\u76d6\u7387\u63d0\u5347\u8d8550%\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u8bed\u8a00\u3002", "conclusion": "FrameShift\u7b80\u5355\u9ad8\u6548\uff0c\u663e\u8457\u63d0\u5347\u6a21\u7cca\u6d4b\u8bd5\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u683c\u5f0f\u548c\u8bed\u8a00\u3002"}}
{"id": "2507.05289", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05289", "abs": "https://arxiv.org/abs/2507.05289", "authors": ["Igor Regis da Silva Simoes", "Elaine Venson"], "title": "Measuring how changes in code readability attributes affect code quality evaluation by Large Language Models", "comment": null, "summary": "Code readability is one of the main aspects of code quality, influenced by\nvarious properties like identifier names, comments, code structure, and\nadherence to standards. However, measuring this attribute poses challenges in\nboth industry and academia. While static analysis tools assess attributes such\nas code smells and comment percentage, code reviews introduce an element of\nsubjectivity. This paper explores using Large Language Models (LLMs) to\nevaluate code quality attributes related to its readability in a standardized,\nreproducible, and consistent manner. We conducted a quasi-experiment study to\nmeasure the effects of code changes on Large Language Model (LLM)s\ninterpretation regarding its readability quality attribute. Nine LLMs were\ntested, undergoing three interventions: removing comments, replacing identifier\nnames with obscure names, and refactoring to remove code smells. Each\nintervention involved 10 batch analyses per LLM, collecting data on response\nvariability. We compared the results with a known reference model and tool. The\nresults showed that all LLMs were sensitive to the interventions, with\nagreement with the reference classifier being high for the original and\nrefactored code scenarios. The LLMs demonstrated a strong semantic sensitivity\nthat the reference model did not fully capture. A thematic analysis of the LLMs\nreasoning confirmed their evaluations directly reflected the nature of each\nintervention. The models also exhibited response variability, with 9.37% to\n14.58% of executions showing a standard deviation greater than zero, indicating\nresponse oscillation, though this did not always compromise the statistical\nsignificance of the results. LLMs demonstrated potential for evaluating\nsemantic quality aspects, such as coherence between identifier names, comments,\nand documentation with code purpose.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6807\u51c6\u5316\u8bc4\u4f30\u4ee3\u7801\u53ef\u8bfb\u6027\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86LLMs\u5bf9\u4ee3\u7801\u5e72\u9884\u7684\u654f\u611f\u6027\u548c\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u4ee3\u7801\u53ef\u8bfb\u6027\u662f\u4ee3\u7801\u8d28\u91cf\u7684\u91cd\u8981\u65b9\u9762\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u4e3b\u89c2\u6027\u548c\u4e0d\u4e00\u81f4\u6027\uff0cLLMs\u53ef\u80fd\u63d0\u4f9b\u6807\u51c6\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u51c6\u5b9e\u9a8c\u7814\u7a76\uff0c\u6d4b\u8bd59\u79cdLLMs\u5bf9\u4e09\u79cd\u4ee3\u7801\u5e72\u9884\uff08\u5220\u9664\u6ce8\u91ca\u3001\u66ff\u6362\u6807\u8bc6\u7b26\u540d\u79f0\u3001\u91cd\u6784\u6d88\u9664\u4ee3\u7801\u5f02\u5473\uff09\u7684\u53cd\u5e94\uff0c\u5e76\u4e0e\u53c2\u8003\u6a21\u578b\u5bf9\u6bd4\u3002", "result": "LLMs\u5bf9\u6240\u6709\u5e72\u9884\u654f\u611f\uff0c\u4e0e\u53c2\u8003\u5206\u7c7b\u5668\u5728\u539f\u59cb\u548c\u91cd\u6784\u4ee3\u7801\u573a\u666f\u4e2d\u4e00\u81f4\u6027\u9ad8\uff0c\u4e14\u8868\u73b0\u51fa\u8bed\u4e49\u654f\u611f\u6027\u3002\u54cd\u5e94\u5b58\u5728\u4e00\u5b9a\u53d8\u5f02\u6027\uff0c\u4f46\u7ed3\u679c\u4ecd\u5177\u7edf\u8ba1\u663e\u8457\u6027\u3002", "conclusion": "LLMs\u5728\u8bc4\u4f30\u4ee3\u7801\u8bed\u4e49\u8d28\u91cf\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u5728\u6807\u8bc6\u7b26\u540d\u79f0\u3001\u6ce8\u91ca\u4e0e\u4ee3\u7801\u76ee\u7684\u7684\u8fde\u8d2f\u6027\u4e0a\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2507.05297", "categories": ["cs.AI", "econ.TH"], "pdf": "https://arxiv.org/pdf/2507.05297", "abs": "https://arxiv.org/abs/2507.05297", "authors": ["Zijun Meng"], "title": "Fuzzy Classification Aggregation for a Continuum of Agents", "comment": null, "summary": "We prove that any optimal, independent, and zero unanimous fuzzy\nclassification aggregation function of a continuum of individual\nclassifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted\narithmetic mean.", "AI": {"tldr": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u8fde\u7eed\u4e2a\u4f53\u5206\u7c7b\u7684\u6700\u4f18\u3001\u72ec\u7acb\u4e14\u96f6\u4e00\u81f4\u7684\u6a21\u7cca\u5206\u7c7b\u805a\u5408\u51fd\u6570\u5fc5\u987b\u662f\u52a0\u6743\u7b97\u672f\u5e73\u5747\u3002", "motivation": "\u7814\u7a76\u6a21\u7cca\u5206\u7c7b\u805a\u5408\u51fd\u6570\u7684\u6027\u8d28\uff0c\u7279\u522b\u662f\u5728\u591a\u5bf9\u8c61\u591a\u7c7b\u578b\u5206\u7c7b\u4e2d\u7684\u6700\u4f18\u6027\u3001\u72ec\u7acb\u6027\u548c\u4e00\u81f4\u6027\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\uff0c\u5206\u6790\u8fde\u7eed\u4e2a\u4f53\u5206\u7c7b\u7684\u805a\u5408\u51fd\u6570\uff0c\u5e76\u9a8c\u8bc1\u5176\u5fc5\u987b\u6ee1\u8db3\u52a0\u6743\u7b97\u672f\u5e73\u5747\u7684\u6761\u4ef6\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u7ed9\u5b9a\u6761\u4ef6\u4e0b\uff0c\u6a21\u7cca\u5206\u7c7b\u805a\u5408\u51fd\u6570\u53ea\u80fd\u662f\u52a0\u6743\u7b97\u672f\u5e73\u5747\u3002", "conclusion": "\u52a0\u6743\u7b97\u672f\u5e73\u5747\u662f\u6ee1\u8db3\u6700\u4f18\u3001\u72ec\u7acb\u548c\u96f6\u4e00\u81f4\u6761\u4ef6\u7684\u552f\u4e00\u6a21\u7cca\u5206\u7c7b\u805a\u5408\u51fd\u6570\u3002"}}
{"id": "2507.05445", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05445", "abs": "https://arxiv.org/abs/2507.05445", "authors": ["Daniel Jones", "Giorgio Severi", "Martin Pouliot", "Gary Lopez", "Joris de Gruyter", "Santiago Zanella-Beguelin", "Justin Song", "Blake Bullwinkel", "Pamela Cortez", "Amanda Minnich"], "title": "A Systematization of Security Vulnerabilities in Computer Use Agents", "comment": null, "summary": "Computer Use Agents (CUAs), autonomous systems that interact with software\ninterfaces via browsers or virtual machines, are rapidly being deployed in\nconsumer and enterprise environments. These agents introduce novel attack\nsurfaces and trust boundaries that are not captured by traditional threat\nmodels. Despite their growing capabilities, the security boundaries of CUAs\nremain poorly understood. In this paper, we conduct a systematic threat\nanalysis and testing of real-world CUAs under adversarial conditions. We\nidentify seven classes of risks unique to the CUA paradigm, and analyze three\nconcrete exploit scenarios in depth: (1) clickjacking via visual overlays that\nmislead interface-level reasoning, (2) indirect prompt injection that enables\nRemote Code Execution (RCE) through chained tool use, and (3) CoT exposure\nattacks that manipulate implicit interface framing to hijack multi-step\nreasoning. These case studies reveal deeper architectural flaws across current\nCUA implementations. Namely, a lack of input provenance tracking, weak\ninterface-action binding, and insufficient control over agent memory and\ndelegation. We conclude by proposing a CUA-specific security evaluation\nframework and design principles for safe deployment in adversarial and\nhigh-stakes settings.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUAs\uff09\u7684\u5b89\u5168\u98ce\u9669\uff0c\u63ed\u793a\u4e86\u4e03\u7c7b\u72ec\u7279\u5a01\u80c1\uff0c\u5e76\u6df1\u5165\u7814\u7a76\u4e86\u4e09\u79cd\u5177\u4f53\u653b\u51fb\u573a\u666f\uff0c\u63d0\u51fa\u4e86\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\u548c\u8bbe\u8ba1\u539f\u5219\u3002", "motivation": "CUAs\u7684\u5e7f\u6cdb\u5e94\u7528\u5f15\u5165\u4e86\u4f20\u7edf\u5a01\u80c1\u6a21\u578b\u672a\u6db5\u76d6\u7684\u65b0\u653b\u51fb\u9762\u548c\u4fe1\u4efb\u8fb9\u754c\uff0c\u4f46\u5176\u5b89\u5168\u8fb9\u754c\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5bf9\u6297\u6761\u4ef6\u4e0b\u7684\u7cfb\u7edf\u5a01\u80c1\u5206\u6790\u548c\u5b9e\u9645CUA\u6d4b\u8bd5\uff0c\u8bc6\u522b\u4e86\u4e03\u7c7b\u98ce\u9669\uff0c\u5e76\u6df1\u5165\u5206\u6790\u4e86\u4e09\u79cd\u5177\u4f53\u653b\u51fb\u573a\u666f\u3002", "result": "\u63ed\u793a\u4e86\u5f53\u524dCUA\u5b9e\u73b0\u4e2d\u7684\u67b6\u6784\u7f3a\u9677\uff0c\u5305\u62ec\u8f93\u5165\u6765\u6e90\u8ddf\u8e2a\u4e0d\u8db3\u3001\u63a5\u53e3-\u52a8\u4f5c\u7ed1\u5b9a\u8584\u5f31\u4ee5\u53ca\u4ee3\u7406\u5185\u5b58\u548c\u59d4\u6258\u63a7\u5236\u4e0d\u8db3\u3002", "conclusion": "\u63d0\u51fa\u4e86\u9488\u5bf9CUAs\u7684\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\u548c\u8bbe\u8ba1\u539f\u5219\uff0c\u4ee5\u652f\u6301\u5176\u5728\u5bf9\u6297\u6027\u548c\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u5b89\u5168\u90e8\u7f72\u3002"}}
{"id": "2507.05294", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05294", "abs": "https://arxiv.org/abs/2507.05294", "authors": ["William Law"], "title": "zkSDK: Streamlining zero-knowledge proof development through automated trace-driven ZK-backend selection", "comment": "undergrad thesis", "summary": "The rapid advancement of creating Zero-Knowledge (ZK) programs has led to the\ndevelopment of numerous tools designed to support developers. Popular options\ninclude being able to write in general-purpose programming languages like Rust\nfrom Risc Zero. Other languages exist like Circom, Lib-snark, and Cairo.\nHowever, developers entering the ZK space are faced with many different ZK\nbackends to choose from, leading to a steep learning curve and a fragmented\ndeveloper experience across different platforms. As a result, many developers\ntend to select a single ZK backend and remain tied to it. This thesis\nintroduces zkSDK, a modular framework that streamlines ZK application\ndevelopment by abstracting the backend complexities. At the core of zkSDK is\nPresto, a custom Python-like programming language that enables the profiling\nand analysis of a program to assess its computational workload intensity.\nCombined with user-defined criteria, zkSDK employs a dynamic selection\nalgorithm to automatically choose the optimal ZK-proving backend. Through an\nin-depth analysis and evaluation of real-world workloads, we demonstrate that\nzkSDK effectively selects the best-suited backend from a set of supported ZK\nbackends, delivering a seamless and user-friendly development experience.", "AI": {"tldr": "zkSDK\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u62bd\u8c61\u540e\u7aef\u590d\u6742\u6027\u7b80\u5316ZK\u5e94\u7528\u5f00\u53d1\uff0c\u4f7f\u7528Presto\u8bed\u8a00\u52a8\u6001\u9009\u62e9\u6700\u4f18ZK\u540e\u7aef\u3002", "motivation": "ZK\u5f00\u53d1\u8005\u9762\u4e34\u591a\u79cd\u540e\u7aef\u9009\u62e9\uff0c\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u4e14\u4f53\u9a8c\u788e\u7247\u5316\uff0czkSDK\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "zkSDK\u57fa\u4e8ePresto\u8bed\u8a00\u5206\u6790\u7a0b\u5e8f\u8ba1\u7b97\u8d1f\u8f7d\uff0c\u7ed3\u5408\u7528\u6237\u6807\u51c6\u52a8\u6001\u9009\u62e9\u6700\u4f18ZK\u540e\u7aef\u3002", "result": "zkSDK\u80fd\u6709\u6548\u9009\u62e9\u6700\u9002\u5408\u7684\u540e\u7aef\uff0c\u63d0\u4f9b\u65e0\u7f1d\u7684\u5f00\u53d1\u4f53\u9a8c\u3002", "conclusion": "zkSDK\u4e3aZK\u5f00\u53d1\u63d0\u4f9b\u4e86\u7edf\u4e00\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.05488", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.05488", "abs": "https://arxiv.org/abs/2507.05488", "authors": ["Subhasis Dasgupta", "Jon Stephens", "Amarnath Gupta"], "title": "OLG++: A Semantic Extension of Obligation Logic Graph", "comment": null, "summary": "We present OLG++, a semantic extension of the Obligation Logic Graph (OLG)\nfor modeling regulatory and legal rules in municipal and interjurisdictional\ncontexts. OLG++ introduces richer node and edge types, including spatial,\ntemporal, party group, defeasibility, and logical grouping constructs, enabling\nnuanced representations of legal obligations, exceptions, and hierarchies. The\nmodel supports structured reasoning over rules with contextual conditions,\nprecedence, and complex triggers. We demonstrate its expressiveness through\nexamples from food business regulations, showing how OLG++ supports legal\nquestion answering using property graph queries. OLG++ also improves over\nLegalRuleML by providing native support for subClassOf, spatial constraints,\nand reified exception structures. Our examples show that OLG++ is more\nexpressive than prior graph-based models for legal knowledge representation.", "AI": {"tldr": "OLG++\u662fObligation Logic Graph\uff08OLG\uff09\u7684\u8bed\u4e49\u6269\u5c55\uff0c\u7528\u4e8e\u5efa\u6a21\u5e02\u653f\u548c\u8de8\u8f96\u533a\u80cc\u666f\u4e0b\u7684\u6cd5\u89c4\u548c\u6cd5\u5f8b\u89c4\u5219\u3002\u5b83\u5f15\u5165\u4e86\u66f4\u4e30\u5bcc\u7684\u8282\u70b9\u548c\u8fb9\u7c7b\u578b\uff0c\u652f\u6301\u590d\u6742\u7684\u6cd5\u5f8b\u4e49\u52a1\u3001\u4f8b\u5916\u548c\u5c42\u6b21\u7ed3\u6784\u7684\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u98df\u54c1\u4e1a\u52a1\u6cd5\u89c4\u793a\u4f8b\u5c55\u793a\u4e86\u5176\u8868\u8fbe\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u6cd5\u5f8b\u77e5\u8bc6\u8868\u793a\u6a21\u578b\uff08\u5982LegalRuleML\uff09\u5728\u8868\u8fbe\u7a7a\u95f4\u7ea6\u675f\u3001\u5b50\u7c7b\u5173\u7cfb\u548c\u4f8b\u5916\u7ed3\u6784\u65f6\u5b58\u5728\u4e0d\u8db3\uff0cOLG++\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "OLG++\u6269\u5c55\u4e86OLG\uff0c\u589e\u52a0\u4e86\u7a7a\u95f4\u3001\u65f6\u95f4\u3001\u7fa4\u4f53\u3001\u53ef\u5e9f\u6b62\u6027\u548c\u903b\u8f91\u5206\u7ec4\u7b49\u6784\u9020\uff0c\u652f\u6301\u4e0a\u4e0b\u6587\u6761\u4ef6\u3001\u4f18\u5148\u7ea7\u548c\u590d\u6742\u89e6\u53d1\u5668\u7684\u7ed3\u6784\u5316\u63a8\u7406\u3002", "result": "OLG++\u5728\u8868\u8fbe\u6cd5\u5f8b\u4e49\u52a1\u548c\u4f8b\u5916\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff08\u5982LegalRuleML\uff09\uff0c\u5e76\u901a\u8fc7\u5c5e\u6027\u56fe\u67e5\u8be2\u652f\u6301\u6cd5\u5f8b\u95ee\u9898\u56de\u7b54\u3002", "conclusion": "OLG++\u4e3a\u6cd5\u5f8b\u77e5\u8bc6\u8868\u793a\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u8bed\u4e49\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7684\u6cd5\u5f8b\u89c4\u5219\u5efa\u6a21\u548c\u63a8\u7406\u3002"}}
{"id": "2507.05512", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05512", "abs": "https://arxiv.org/abs/2507.05512", "authors": ["Gehao Zhang", "Eugene Bagdasarian", "Juan Zhai", "Shiqing Ma"], "title": "Disappearing Ink: Obfuscation Breaks N-gram Code Watermarks in Theory and Practice", "comment": null, "summary": "Distinguishing AI-generated code from human-written code is becoming crucial\nfor tasks such as authorship attribution, content tracking, and misuse\ndetection. Based on this, N-gram-based watermarking schemes have emerged as\nprominent, which inject secret watermarks to be detected during the generation.\n  However, their robustness in code content remains insufficiently evaluated.\nMost claims rely solely on defenses against simple code transformations or code\noptimizations as a simulation of attack, creating a questionable sense of\nrobustness. In contrast, more sophisticated schemes already exist in the\nsoftware engineering world, e.g., code obfuscation, which significantly alters\ncode while preserving functionality. Although obfuscation is commonly used to\nprotect intellectual property or evade software scanners, the robustness of\ncode watermarking techniques against such transformations remains largely\nunexplored.\n  In this work, we formally model the code obfuscation and prove the\nimpossibility of N-gram-based watermarking's robustness with only one intuitive\nand experimentally verified assumption, distribution consistency, satisfied.\nGiven the original false positive rate of the watermarking detection, the ratio\nthat the detector failed on the watermarked code after obfuscation will\nincrease to 1 - fpr.\n  The experiments have been performed on three SOTA watermarking schemes, two\nLLMs, two programming languages, four code benchmarks, and four obfuscators.\nAmong them, all watermarking detectors show coin-flipping detection abilities\non obfuscated codes (AUROC tightly surrounds 0.5). Among all models,\nwatermarking schemes, and datasets, both programming languages own obfuscators\nthat can achieve attack effects with no detection AUROC higher than 0.6 after\nthe attack. Based on the theoretical and practical observations, we also\nproposed a potential path of robust code watermarking.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86N-gram\u6c34\u5370\u65b9\u6848\u5728\u4ee3\u7801\u4e2d\u7684\u9c81\u68d2\u6027\u4e0d\u8db3\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u4ee3\u7801\u6df7\u6dc6\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u533a\u5206AI\u751f\u6210\u4ee3\u7801\u4e0e\u4eba\u5de5\u7f16\u5199\u4ee3\u7801\u5bf9\u4f5c\u8005\u5f52\u5c5e\u3001\u5185\u5bb9\u8ffd\u8e2a\u548c\u6ee5\u7528\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6c34\u5370\u65b9\u6848\u5728\u4ee3\u7801\u6df7\u6dc6\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\u672a\u5145\u5206\u8bc4\u4f30\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5f62\u5f0f\u5316\u5efa\u6a21\u4ee3\u7801\u6df7\u6dc6\uff0c\u8bc1\u660eN-gram\u6c34\u5370\u5728\u6ee1\u8db3\u5206\u5e03\u4e00\u81f4\u6027\u5047\u8bbe\u65f6\u65e0\u6cd5\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u70b9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u6709\u6c34\u5370\u68c0\u6d4b\u5668\u5728\u6df7\u6dc6\u4ee3\u7801\u4e0a\u7684\u68c0\u6d4b\u80fd\u529b\u63a5\u8fd1\u968f\u673a\uff08AUROC\u22480.5\uff09\uff0c\u4e14\u5b58\u5728\u6df7\u6dc6\u5668\u80fd\u4f7f\u68c0\u6d4bAUROC\u4e0d\u8d85\u8fc70.6\u3002", "conclusion": "N-gram\u6c34\u5370\u65b9\u6848\u5728\u4ee3\u7801\u6df7\u6dc6\u653b\u51fb\u4e0b\u8868\u73b0\u8106\u5f31\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u53ef\u80fd\u7684\u9c81\u68d2\u6c34\u5370\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2507.05307", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05307", "abs": "https://arxiv.org/abs/2507.05307", "authors": ["Xuanqi Gao", "Juan Zhai", "Shiqing Ma", "Siyi Xie", "Chao Shen"], "title": "ASSURE: Metamorphic Testing for AI-powered Browser Extensions", "comment": null, "summary": "The integration of Large Language Models (LLMs) into browser extensions has\nrevolutionized web browsing, enabling sophisticated functionalities like\ncontent summarization, intelligent translation, and context-aware writing\nassistance. However, these AI-powered extensions introduce unprecedented\nchallenges in testing and reliability assurance. Traditional browser extension\ntesting approaches fail to address the non-deterministic behavior,\ncontext-sensitivity, and complex web environment integration inherent to\nLLM-powered extensions. Similarly, existing LLM testing methodologies operate\nin isolation from browser-specific contexts, creating a critical gap in\neffective evaluation frameworks. To bridge this gap, we present ASSURE, a\nmodular automated testing framework specifically designed for AI-powered\nbrowser extensions. ASSURE comprises three principal components: (1) a modular\ntest case generation engine that supports plugin-based extension of testing\nscenarios, (2) an automated execution framework that orchestrates the complex\ninteractions between web content, extension processing, and AI model behavior,\nand (3) a configurable validation pipeline that systematically evaluates\nbehavioral consistency and security invariants rather than relying on exact\noutput matching. Our evaluation across six widely-used AI browser extensions\ndemonstrates ASSURE's effectiveness, identifying 531 distinct issues spanning\nsecurity vulnerabilities, metamorphic relation violations, and content\nalignment problems. ASSURE achieves 6.4x improved testing throughput compared\nto manual approaches, detecting critical security vulnerabilities within 12.4\nminutes on average. This efficiency makes ASSURE practical for integration into\ndevelopment pipelines, offering a comprehensive solution to the unique\nchallenges of testing AI-powered browser extensions.", "AI": {"tldr": "ASSURE\u662f\u4e00\u4e2a\u4e13\u4e3aAI\u6d4f\u89c8\u5668\u6269\u5c55\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5e94\u5bf9\u7684\u975e\u786e\u5b9a\u6027\u884c\u4e3a\u548c\u4e0a\u4e0b\u6587\u654f\u611f\u6027\u7b49\u95ee\u9898\u3002", "motivation": "AI\u6d4f\u89c8\u5668\u6269\u5c55\u7684\u6d4b\u8bd5\u548c\u53ef\u9760\u6027\u4fdd\u969c\u9762\u4e34\u524d\u6240\u672a\u6709\u7684\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u548c\u73b0\u6709LLM\u6d4b\u8bd5\u65b9\u6cd5\u5747\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u3002", "method": "ASSURE\u5305\u542b\u6a21\u5757\u5316\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5f15\u64ce\u3001\u81ea\u52a8\u5316\u6267\u884c\u6846\u67b6\u548c\u53ef\u914d\u7f6e\u9a8c\u8bc1\u7ba1\u9053\uff0c\u7cfb\u7edf\u8bc4\u4f30\u884c\u4e3a\u4e00\u81f4\u6027\u548c\u5b89\u5168\u6027\u3002", "result": "\u5728\u516d\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684AI\u6d4f\u89c8\u5668\u6269\u5c55\u4e2d\uff0cASSURE\u8bc6\u522b\u4e86531\u4e2a\u95ee\u9898\uff0c\u6d4b\u8bd5\u541e\u5410\u91cf\u6bd4\u624b\u52a8\u65b9\u6cd5\u63d0\u9ad8\u4e866.4\u500d\u3002", "conclusion": "ASSURE\u4e3aAI\u6d4f\u89c8\u5668\u6269\u5c55\u7684\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u5408\u96c6\u6210\u5230\u5f00\u53d1\u6d41\u7a0b\u4e2d\u3002"}}
{"id": "2507.05495", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05495", "abs": "https://arxiv.org/abs/2507.05495", "authors": ["Prahaladh Chandrahasan", "Jiahe Jin", "Zhihan Zhang", "Tevin Wang", "Andy Tang", "Lucy Mo", "Morteza Ziyadi", "Leonardo F. R. Ribeiro", "Zimeng Qiu", "Markus Dreyer", "Akari Asai", "Chenyan Xiong"], "title": "Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents", "comment": null, "summary": "Effectively evaluating deep research agents that autonomously search the web,\nanalyze information, and generate reports remains a major challenge,\nparticularly when it comes to assessing long reports and giving detailed\nfeedback on their intermediate steps. To address these gaps, we introduce Deep\nResearch Comparator, a platform that offers a holistic framework for deep\nresearch agent hosting, side-by-side comparison, fine-grained human feedback\ncollection, and ranking calculation. Given a user query, our platform displays\nthe final reports from two different agents along with their intermediate steps\nduring generation. Annotators can evaluate the overall quality of final reports\nbased on side-by-side comparison, and also provide detailed feedback separately\nby assessing intermediate steps or specific text spans within the final report.\nFurthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This\nscaffold serves as a baseline that facilitates the easy integration of various\nlarge language models to transform them into deep research agents for\nevaluation. To demonstrate the platform's utility for deep research agent\ndevelopment, we have collected real user preference data from 17 annotators on\nthree deep research agents. A demo video of our platform can be found at\nhttps://www.youtube.com/watch?v=g4d2dnbdseg.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86Deep Research Comparator\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6bd4\u8f83\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u53cd\u9988\u548c\u6392\u540d\u8ba1\u7b97\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5728\u751f\u6210\u62a5\u544a\u548c\u4e2d\u95f4\u6b65\u9aa4\u8bc4\u4f30\u4e0a\u7684\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86Deep Research Comparator\u5e73\u53f0\u548cSimple Deepresearch\u4ee3\u7406\u6846\u67b6\uff0c\u652f\u6301\u591a\u4ee3\u7406\u6bd4\u8f83\u548c\u53cd\u9988\u6536\u96c6\u3002", "result": "\u6536\u96c6\u4e8617\u4f4d\u6ce8\u91ca\u8005\u7684\u771f\u5b9e\u7528\u6237\u504f\u597d\u6570\u636e\uff0c\u9a8c\u8bc1\u4e86\u5e73\u53f0\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5e73\u53f0\u4e3a\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u652f\u6301\u8bc4\u4f30\u548c\u6539\u8fdb\u3002"}}
{"id": "2507.05524", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05524", "abs": "https://arxiv.org/abs/2507.05524", "authors": ["Sara Chennoufi", "Yufei Han", "Gregory Blanc", "Emiliano De Cristofaro", "Christophe Kiennert"], "title": "PROTEAN: Federated Intrusion Detection in Non-IID Environments through Prototype-Based Knowledge Sharing", "comment": null, "summary": "In distributed networks, participants often face diverse and fast-evolving\ncyberattacks. This makes techniques based on Federated Learning (FL) a\npromising mitigation strategy. By only exchanging model updates, FL\nparticipants can collaboratively build detection models without revealing\nsensitive information, e.g., network structures or security postures. However,\nthe effectiveness of FL solutions is often hindered by significant data\nheterogeneity, as attack patterns often differ drastically across organizations\ndue to varying security policies. To address these challenges, we introduce\nPROTEAN, a Prototype Learning-based framework geared to facilitate\ncollaborative and privacy-preserving intrusion detection. PROTEAN enables\naccurate detection in environments with highly non-IID attack distributions and\npromotes direct knowledge sharing by exchanging class prototypes of different\nattack types among participants. This allows organizations to better understand\nattack techniques not present in their data collections. We instantiate PROTEAN\non two cyber intrusion datasets collected from IIoT and 5G-connected\nparticipants and evaluate its performance in terms of utility and privacy,\ndemonstrating its effectiveness in addressing data heterogeneity while\nimproving cyber attack understanding in federated intrusion detection systems\n(IDSs).", "AI": {"tldr": "PROTEAN\u662f\u4e00\u4e2a\u57fa\u4e8e\u539f\u578b\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u6570\u636e\u5f02\u6784\u6027\u95ee\u9898\uff0c\u63d0\u5347\u5165\u4fb5\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u5206\u5e03\u5f0f\u7f51\u7edc\u4e2d\uff0c\u53c2\u4e0e\u8005\u9762\u4e34\u591a\u6837\u4e14\u5feb\u901f\u6f14\u53d8\u7684\u7f51\u7edc\u653b\u51fb\uff0c\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u56e0\u5176\u9690\u79c1\u4fdd\u62a4\u7279\u6027\u6210\u4e3a\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u6570\u636e\u5f02\u6784\u6027\u9650\u5236\u4e86\u5176\u6548\u679c\u3002", "method": "PROTEAN\u901a\u8fc7\u4ea4\u6362\u4e0d\u540c\u653b\u51fb\u7c7b\u578b\u7684\u7c7b\u539f\u578b\uff0c\u4fc3\u8fdb\u76f4\u63a5\u77e5\u8bc6\u5171\u4eab\uff0c\u89e3\u51b3\u4e86\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u653b\u51fb\u5206\u5e03\u7684\u95ee\u9898\u3002", "result": "\u5728IIoT\u548c5G\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPROTEAN\u5728\u6548\u7528\u548c\u9690\u79c1\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u6709\u6548\u5e94\u5bf9\u6570\u636e\u5f02\u6784\u6027\u5e76\u63d0\u5347\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "PROTEAN\u4e3a\u8054\u90a6\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2507.05316", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05316", "abs": "https://arxiv.org/abs/2507.05316", "authors": ["Koren Lazar", "Matan Vetzler", "Kiran Kate", "Jason Tsay", "David Boaz Himanshu Gupta", "Avraham Shinnar", "Rohith D Vallam", "David Amid Esther Goldbraich", "Guy Uziel", "Jim Laredo", "Ateret Anaby Tavor"], "title": "OASBuilder: Generating OpenAPI Specifications from Online API Documentation with Large Language Models", "comment": null, "summary": "AI agents and business automation tools interacting with external web\nservices require standardized, machine-readable information about their APIs in\nthe form of API specifications. However, the information about APIs available\nonline is often presented as unstructured, free-form HTML documentation,\nrequiring external users to spend significant time manually converting it into\na structured format. To address this, we introduce OASBuilder, a novel\nframework that transforms long and diverse API documentation pages into\nconsistent, machine-readable API specifications. This is achieved through a\ncarefully crafted pipeline that integrates large language models and rule-based\nalgorithms which are guided by domain knowledge of the structure of\ndocumentation webpages. Our experiments demonstrate that OASBuilder generalizes\nwell across hundreds of APIs, and produces valid OpenAPI specifications that\nencapsulate most of the information from the original documentation. OASBuilder\nhas been successfully implemented in an enterprise environment, saving\nthousands of hours of manual effort and making hundreds of complex enterprise\nAPIs accessible as tools for LLMs.", "AI": {"tldr": "OASBuilder\u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u5c06\u975e\u7ed3\u6784\u5316\u7684API\u6587\u6863\u8f6c\u6362\u4e3a\u673a\u5668\u53ef\u8bfb\u7684OpenAPI\u89c4\u8303\uff0c\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u7b97\u6cd5\u3002", "motivation": "\u5728\u7ebfAPI\u6587\u6863\u591a\u4e3a\u975e\u7ed3\u6784\u5316HTML\uff0c\u9700\u8981\u624b\u52a8\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u683c\u5f0f\uff0c\u8017\u65f6\u8d39\u529b\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u7b97\u6cd5\uff0c\u5229\u7528\u6587\u6863\u7f51\u9875\u7ed3\u6784\u77e5\u8bc6\uff0c\u6784\u5efa\u8f6c\u6362\u7ba1\u9053\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cOASBuilder\u80fd\u5904\u7406\u6570\u767e\u79cdAPI\uff0c\u751f\u6210\u6709\u6548\u7684OpenAPI\u89c4\u8303\uff0c\u6db5\u76d6\u5927\u90e8\u5206\u539f\u59cb\u6587\u6863\u4fe1\u606f\u3002", "conclusion": "OASBuilder\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u6210\u529f\u5e94\u7528\uff0c\u8282\u7701\u5927\u91cf\u624b\u52a8\u65f6\u95f4\uff0c\u4f7f\u590d\u6742API\u66f4\u6613\u4e8eLLM\u4f7f\u7528\u3002"}}
{"id": "2507.05515", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.05515", "abs": "https://arxiv.org/abs/2507.05515", "authors": ["Haochen Huang", "Jiahuan Pei", "Mohammad Aliannejadi", "Xin Sun", "Moonisa Ahsan", "Pablo Cesar", "Chuang Yu", "Zhaochun Ren", "Junxiao Wang"], "title": "Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality", "comment": "20 pages", "summary": "Vision-language models (VLMs) are essential for enabling AI-powered smart\nassistants to interpret and reason in multimodal environments. However, their\napplication in augmented reality (AR) training remains largely unexplored. In\nthis work, we introduce a comprehensive dataset tailored for AR training,\nfeaturing systematized vision-language tasks, and evaluate nine\nstate-of-the-art VLMs on it. Our results reveal that even advanced models,\nincluding GPT-4o, struggle with fine-grained assembly tasks, achieving a\nmaximum F1 score of just 40.54% on state detection. These findings highlight\nthe demand for enhanced datasets, benchmarks, and further research to improve\nfine-grained vision-language alignment. Beyond technical contributions, our\nwork has broader social implications, particularly in empowering blind and\nvisually impaired users with equitable access to AI-driven learning\nopportunities. We provide all related resources, including the dataset, source\ncode, and evaluation results, to support the research community.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u9488\u5bf9AR\u8bad\u7ec3\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e86\u4e5d\u79cd\u5148\u8fdb\u6a21\u578b\uff0c\u53d1\u73b0\u5176\u5728\u7ec6\u7c92\u5ea6\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u547c\u5401\u6539\u8fdb\u6570\u636e\u96c6\u548c\u57fa\u51c6\u3002", "motivation": "\u63a2\u7d22\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728AR\u8bad\u7ec3\u4e2d\u7684\u5e94\u7528\uff0c\u586b\u8865\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u4e3a\u76f2\u4eba\u548c\u89c6\u969c\u7528\u6237\u63d0\u4f9b\u5e73\u7b49\u7684AI\u5b66\u4e60\u673a\u4f1a\u3002", "method": "\u6784\u5efa\u4e86\u7cfb\u7edf\u5316\u7684\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e5d\u79cd\u5148\u8fdb\u7684VLM\u6a21\u578b\u3002", "result": "\u5373\u4f7f\u662fGPT-4o\u7b49\u5148\u8fdb\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u88c5\u914d\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u72b6\u6001\u68c0\u6d4b\u7684\u6700\u9ad8F1\u5206\u6570\u4ec5\u4e3a40.54%\u3002", "conclusion": "\u9700\u6539\u8fdb\u6570\u636e\u96c6\u548c\u57fa\u51c6\u4ee5\u63d0\u5347\u7ec6\u7c92\u5ea6\u89c6\u89c9\u8bed\u8a00\u5bf9\u9f50\uff0c\u7814\u7a76\u5177\u6709\u5e7f\u6cdb\u7684\u793e\u4f1a\u610f\u4e49\uff0c\u652f\u6301\u76f2\u4eba\u548c\u89c6\u969c\u7528\u6237\u3002"}}
{"id": "2507.05558", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05558", "abs": "https://arxiv.org/abs/2507.05558", "authors": ["Arthur Gervais", "Liyi Zhou"], "title": "AI Agent Smart Contract Exploit Generation", "comment": null, "summary": "We present A1, an agentic execution driven system that transforms any LLM\ninto an end-to-end exploit generator. A1 has no hand-crafted heuristics and\nprovides the agent with six domain-specific tools that enable autonomous\nvulnerability discovery. The agent can flexibly leverage these tools to\nunderstand smart contract behavior, generate exploit strategies, test them on\nblockchain states, and refine approaches based on execution feedback. All\noutputs are concretely validated to eliminate false positives.\n  The evaluation across 36 real-world vulnerable contracts on Ethereum and\nBinance Smart Chain demonstrates a 62.96% (17 out of 27) success rate on the\nVERITE benchmark. Beyond the VERITE dataset, A1 identified 9 additional\nvulnerable contracts, with 5 cases occurring after the strongest model's\ntraining cutoff date. Across all 26 successful cases, A1 extracts up to 8.59\nmillion USD per case and 9.33 million USD total. Through 432 experiments across\nsix LLMs, we analyze iteration-wise performance showing diminishing returns\nwith average marginal gains of +9.7%, +3.7%, +5.1%, and +2.8% for iterations\n2-5 respectively, with per-experiment costs ranging $0.01-$3.59. A Monte Carlo\nanalysis of 19 historical attacks shows success probabilities of 85.9%-88.8%\nwithout detection delays.\n  We investigate whether an attacker or a defender benefits most from deploying\nA1 as a continuous on-chain scanning system. Our model shows that OpenAI's\no3-pro maintains profitability up to a 30.0 days scanning delay at 0.100%\nvulnerability incidence rates, while faster models require >=1.000% rates to\nbreak-even. The findings exposes a troubling asymmetry: at 0.1% vulnerability\nrates, attackers achieve an on-chain scanning profitability at a $6000 exploit\nvalue, while defenders require $60000, raising fundamental questions about\nwhether AI agents inevitably favor exploitation over defense.", "AI": {"tldr": "A1\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u7aef\u5230\u7aef\u6f0f\u6d1e\u5229\u7528\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u516d\u79cd\u9886\u57df\u5de5\u5177\u5b9e\u73b0\u81ea\u4e3b\u6f0f\u6d1e\u53d1\u73b0\uff0c\u6210\u529f\u7387\u4e3a62.96%\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u7ecf\u6d4e\u6548\u76ca\u548c\u4e0d\u5bf9\u79f0\u6027\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5229\u7528LLM\u751f\u6210\u7aef\u5230\u7aef\u7684\u6f0f\u6d1e\u5229\u7528\u65b9\u6848\uff0c\u5e76\u9a8c\u8bc1\u5176\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u6548\u679c\u548c\u7ecf\u6d4e\u53ef\u884c\u6027\u3002", "method": "A1\u7cfb\u7edf\u901a\u8fc7\u516d\u79cd\u5de5\u5177\u652f\u6301LLM\u81ea\u4e3b\u53d1\u73b0\u6f0f\u6d1e\uff0c\u5305\u62ec\u7406\u89e3\u5408\u7ea6\u884c\u4e3a\u3001\u751f\u6210\u7b56\u7565\u3001\u6d4b\u8bd5\u548c\u4f18\u5316\u3002", "result": "\u572836\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u5408\u7ea6\u4e2d\uff0cA1\u6210\u529f\u7387\u4e3a62.96%\uff0c\u63d0\u53d6\u603b\u91d1\u989d\u8fbe933\u4e07\u7f8e\u5143\uff0c\u4e14\u653b\u51fb\u8005\u6bd4\u9632\u5fa1\u8005\u66f4\u5177\u7ecf\u6d4e\u4f18\u52bf\u3002", "conclusion": "A1\u5c55\u793a\u4e86LLM\u5728\u6f0f\u6d1e\u5229\u7528\u4e2d\u7684\u9ad8\u6548\u6027\uff0c\u4f46\u63ed\u793a\u4e86\u653b\u51fb\u8005\u4e0e\u9632\u5fa1\u8005\u4e4b\u95f4\u7684\u7ecf\u6d4e\u4e0d\u5bf9\u79f0\u6027\uff0c\u5f15\u53d1\u4e86\u5bf9AI\u4ee3\u7406\u504f\u5411\u6027\u7684\u62c5\u5fe7\u3002"}}
{"id": "2507.05325", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05325", "abs": "https://arxiv.org/abs/2507.05325", "authors": ["Lidiany Cerqueira", "Jo\u00e3o Pedro Bastos", "Danilo Neves", "Glauco Carneiro", "Rodrigo Sp\u00ednola", "S\u00e1vio Freire", "Jos\u00e9 Amancio Macedo Santos", "Manoel Mendon\u00e7a"], "title": "Exploring Empathy in Software Engineering: Insights from a Grey Literature Analysis of Practitioners' Perspectives", "comment": "This is the author's version of the paper accepted for publication in\n  ACM Transactions on Software Engineering and Methodology. The final version\n  will be available via the ACM Digital Library. The HTML preview may not\n  render some formatting correctly. Please refer to the PDF version for\n  accurate presentation", "summary": "Context. Empathy, a key social skill, is essential for communication and\ncollaboration in SE but remains an under-researched topic. Aims. This study\ninvestigates empathy in SE from practitioners' perspectives, aiming to\ncharacterize its meaning, identify barriers, discuss practices to overcome\nthem, and explore its effects. Method. A qualitative content analysis was\nconducted on 55 web articles from DEV and Medium, two communities widely used\nby practitioners. To strengthen our findings, we conducted a follow-up survey\nwith empathy experts. Results. The study proposes a definition of empathy in\nSE, identifies barriers such as toxic culture and excessive technical focus,\npractices to foster empathy in teams, and outcomes, including improved\ncollaboration, communication, and reduced anxiety, frustration, and stress.\nThese findings are synthesized into a conceptual framework. Conclusion. Survey\nresults indicate the framework is clear, valuable, and raises empathy\nawareness, with suggestions for improvements and integration into training.\nThis study paves the way for improving team dynamics by addressing barriers and\noffering strategies to cultivate empathy. Future work will explore empathy's\nbroader implications in SE practice.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5171\u60c5\uff0c\u5b9a\u4e49\u4e86\u5176\u542b\u4e49\uff0c\u8bc6\u522b\u4e86\u969c\u788d\uff0c\u63d0\u51fa\u4e86\u514b\u670d\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\u3002", "motivation": "\u5171\u60c5\u662f\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u672a\u88ab\u5145\u5206\u7814\u7a76\u7684\u5173\u952e\u793e\u4ea4\u6280\u80fd\uff0c\u5bf9\u6c9f\u901a\u548c\u534f\u4f5c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5206\u679055\u7bc7DEV\u548cMedium\u7684\u6587\u7ae0\uff0c\u5e76\u7ed3\u5408\u4e13\u5bb6\u8c03\u67e5\u8fdb\u884c\u5b9a\u6027\u5185\u5bb9\u5206\u6790\u3002", "result": "\u63d0\u51fa\u4e86\u5171\u60c5\u7684\u5b9a\u4e49\uff0c\u8bc6\u522b\u4e86\u969c\u788d\uff08\u5982\u6bd2\u6027\u6587\u5316\u548c\u8fc7\u5ea6\u6280\u672f\u5bfc\u5411\uff09\uff0c\u63d0\u51fa\u4e86\u56e2\u961f\u5171\u60c5\u5b9e\u8df5\uff0c\u5e76\u5c55\u793a\u4e86\u79ef\u6781\u6548\u679c\uff08\u5982\u6539\u5584\u534f\u4f5c\u548c\u51cf\u5c11\u538b\u529b\uff09\u3002", "conclusion": "\u6846\u67b6\u88ab\u8ba4\u4e3a\u6e05\u6670\u4e14\u6709\u4ef7\u503c\uff0c\u672a\u6765\u5c06\u8fdb\u4e00\u6b65\u63a2\u7d22\u5171\u60c5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e7f\u6cdb\u5f71\u54cd\u3002"}}
{"id": "2507.05519", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.05519", "abs": "https://arxiv.org/abs/2507.05519", "authors": ["Gopal Gupta", "Abhiramon Rajasekharan", "Alexis R. Tudor", "Elmer Salazar", "Joaqu\u00edn Arias"], "title": "Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicated Answer Set Programming System", "comment": null, "summary": "We consider the problem of implementing deontic modal logic. We show how\n(deontic) modal operators can be expressed elegantly using default negation\n(negation-as-failure) and strong negation present in answer set programming\n(ASP). We propose using global constraints of ASP to represent obligations and\nimpermissibilities of deontic modal logic. We show that our proposed\nrepresentation results in the various paradoxes of deontic modal logic being\nelegantly resolved.", "AI": {"tldr": "\u4f7f\u7528ASP\u4e2d\u7684\u9ed8\u8ba4\u5426\u5b9a\u548c\u5f3a\u5426\u5b9a\u4f18\u96c5\u8868\u8fbe\u4e49\u52a1\u6a21\u6001\u903b\u8f91\uff0c\u5e76\u901a\u8fc7\u5168\u5c40\u7ea6\u675f\u89e3\u51b3\u5176\u6096\u8bba\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u5728ASP\u4e2d\u5b9e\u73b0\u4e49\u52a1\u6a21\u6001\u903b\u8f91\uff0c\u89e3\u51b3\u5176\u7ecf\u5178\u6096\u8bba\u95ee\u9898\u3002", "method": "\u5229\u7528ASP\u7684\u9ed8\u8ba4\u5426\u5b9a\u548c\u5f3a\u5426\u5b9a\u8868\u793a\u6a21\u6001\u7b97\u5b50\uff0c\u5e76\u901a\u8fc7\u5168\u5c40\u7ea6\u675f\u8868\u8fbe\u4e49\u52a1\u548c\u7981\u6b62\u3002", "result": "\u63d0\u51fa\u7684\u8868\u793a\u65b9\u6cd5\u80fd\u4f18\u96c5\u89e3\u51b3\u4e49\u52a1\u6a21\u6001\u903b\u8f91\u7684\u591a\u79cd\u6096\u8bba\u3002", "conclusion": "ASP\u4e3a\u4e49\u52a1\u6a21\u6001\u903b\u8f91\u7684\u5b9e\u73b0\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u4f18\u96c5\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.05576", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2507.05576", "abs": "https://arxiv.org/abs/2507.05576", "authors": ["Mehdi Elahi", "Mohamed R. Elshamy", "Abdel-Hameed Badawy", "Ahmad Patooghy"], "title": "iThermTroj: Exploiting Intermittent Thermal Trojans in Multi-Processor System-on-Chips", "comment": null, "summary": "Thermal Trojan attacks present a pressing concern for the security and\nreliability of System-on-Chips (SoCs), especially in mobile applications. The\nsituation becomes more complicated when such attacks are more evasive and\noperate sporadically to stay hidden from detection mechanisms. In this paper,\nwe introduce Intermittent Thermal Trojans (iThermTroj) that exploit the chips'\nthermal information in a random time-triggered manner. According to our\nexperiments, iThermTroj attack can easily bypass available threshold-based\nthermal Trojan detection solutions. We investigate SoC vulnerabilities to\nvariations of iThermTroj through an in-depth analysis of Trojan activation and\nduration scenarios. We also propose a set of tiny Machine Learning classifiers\nfor run-time anomaly detection to protect SoCs against such intermittent\nthermal Trojan attacks. Compared to existing methods, our approach improves the\nattack detection rate by 29.4\\%, 17.2\\%, and 14.3\\% in scenarios where\niThermTroj manipulates up to 80\\%, 60\\%, and 40\\% of SoC's thermal data,\nrespectively. Additionally, our method increases the full protection resolution\nto 0.8 degrees Celsius, meaning that any temperature manipulations exceeding\n$\\pm 0.8$ degrees will be detected with 100\\% accuracy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u95f4\u6b47\u6027\u70ed\u7279\u6d1b\u4f0a\u6728\u9a6c\u653b\u51fb\uff08iThermTroj\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u5fae\u578b\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u7684\u8fd0\u884c\u65f6\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u68c0\u6d4b\u7387\u548c\u4fdd\u62a4\u5206\u8fa8\u7387\u3002", "motivation": "\u70ed\u7279\u6d1b\u4f0a\u6728\u9a6c\u653b\u51fb\u5bf9SoC\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u5c24\u5176\u662f\u5f53\u653b\u51fb\u66f4\u9690\u853d\u4e14\u95f4\u6b47\u6027\u64cd\u4f5c\u65f6\uff0c\u73b0\u6709\u68c0\u6d4b\u673a\u5236\u96be\u4ee5\u5e94\u5bf9\u3002", "method": "\u901a\u8fc7\u6df1\u5165\u5206\u6790\u7279\u6d1b\u4f0a\u6728\u9a6c\u6fc0\u6d3b\u548c\u6301\u7eed\u65f6\u95f4\u573a\u666f\uff0c\u63d0\u51fa\u4e86\u4e00\u7ec4\u5fae\u578b\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u7528\u4e8e\u8fd0\u884c\u65f6\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u5728\u653b\u51fb\u64cd\u7eb580%\u300160%\u548c40%\u70ed\u6570\u636e\u65f6\uff0c\u68c0\u6d4b\u7387\u5206\u522b\u63d0\u9ad8\u4e8629.4%\u300117.2%\u548c14.3%\uff0c\u4fdd\u62a4\u5206\u8fa8\u7387\u63d0\u5347\u81f30.8\u6444\u6c0f\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u4e86\u5bf9\u95f4\u6b47\u6027\u70ed\u7279\u6d1b\u4f0a\u6728\u9a6c\u653b\u51fb\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u4e3aSoC\u5b89\u5168\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u4fdd\u62a4\u3002"}}
{"id": "2507.05504", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05504", "abs": "https://arxiv.org/abs/2507.05504", "authors": ["Alex Kleijwegt", "Sinem Getir Yaman", "Radu Calinescu"], "title": "Tool for Supporting Debugging and Understanding of Normative Requirements Using LLMs", "comment": null, "summary": "Normative requirements specify social, legal, ethical, empathetic, and\ncultural (SLEEC) norms that must be observed by a system. To support the\nidentification of SLEEC requirements, numerous standards and regulations have\nbeen developed. These requirements are typically defined by stakeholders in the\nnon-technical system with diverse expertise (e.g., ethicists, lawyers, social\nscientists). Hence, ensuring their consistency and managing the requirement\nelicitation process are complex and error-prone tasks. Recent research has\naddressed this challenge using domain-specific languages to specify normative\nrequirements as rules, whose consistency can then be analyzed with formal\nmethods. Nevertheless, these approaches often present the results from formal\nverification tools in a way that is inaccessible to non-technical users. This\nhinders understanding and makes the iterative process of eliciting and\nvalidating these requirements inefficient in terms of both time and effort. To\naddress this problem, we introduce SLEEC-LLM, a tool that uses large language\nmodels (LLMs) to provide natural-language interpretations for model-checking\ncounterexamples corresponding to SLEEC rule inconsistencies. SLEEC-LLM improves\nthe efficiency and explainability of normative requirements elicitation and\nconsistency analysis. To demonstrate its effectiveness, we summarise its use in\ntwo real-world case studies involving non-technical stakeholders.", "AI": {"tldr": "SLEEC-LLM\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e3aSLEEC\u89c4\u5219\u4e0d\u4e00\u81f4\u6027\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u63d0\u5347\u89c4\u8303\u9700\u6c42\u83b7\u53d6\u548c\u4e00\u81f4\u6027\u5206\u6790\u7684\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u89c4\u8303\u9700\u6c42\uff08SLEEC\uff09\u7684\u8bc6\u522b\u548c\u7ba1\u7406\u590d\u6742\u4e14\u6613\u51fa\u9519\uff0c\u73b0\u6709\u65b9\u6cd5\u7684\u6280\u672f\u6027\u7ed3\u679c\u5bf9\u975e\u6280\u672f\u7528\u6237\u4e0d\u53cb\u597d\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5f15\u5165SLEEC-LLM\u5de5\u5177\uff0c\u5229\u7528LLMs\u5c06\u6a21\u578b\u68c0\u67e5\u7684\u53cd\u4f8b\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86SLEEC-LLM\u7684\u6709\u6548\u6027\u3002", "conclusion": "SLEEC-LLM\u663e\u8457\u63d0\u5347\u4e86\u89c4\u8303\u9700\u6c42\u83b7\u53d6\u548c\u4e00\u81f4\u6027\u5206\u6790\u7684\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.05520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05520", "abs": "https://arxiv.org/abs/2507.05520", "authors": ["Karishma Thakrar", "Shreyas Basavatia", "Akshay Daftardar"], "title": "Cultivating Multimodal Intelligence: Interpretive Reasoning and Agentic RAG Approaches to Dermatological Diagnosis", "comment": "2025 ImageCLEF MEDIQA-MAGIC Challenge", "summary": "The second edition of the 2025 ImageCLEF MEDIQA-MAGIC challenge, co-organized\nby researchers from Microsoft, Stanford University, and the Hospital Clinic of\nBarcelona, focuses on multimodal dermatology question answering and\nsegmentation, using real-world patient queries and images. This work addresses\nthe Closed Visual Question Answering (CVQA) task, where the goal is to select\nthe correct answer to multiple-choice clinical questions based on both\nuser-submitted images and accompanying symptom descriptions. The proposed\napproach combines three core components: (1) fine-tuning open-source multimodal\nmodels from the Qwen, Gemma, and LLaMA families on the competition dataset, (2)\nintroducing a structured reasoning layer that reconciles and adjudicates\nbetween candidate model outputs, and (3) incorporating agentic\nretrieval-augmented generation (agentic RAG), which adds relevant information\nfrom the American Academy of Dermatology's symptom and condition database to\nfill in gaps in patient context. The team achieved second place with a\nsubmission that scored sixth, demonstrating competitive performance and high\naccuracy. Beyond competitive benchmarks, this research addresses a practical\nchallenge in telemedicine: diagnostic decisions must often be made\nasynchronously, with limited input and with high accuracy and interpretability.\nBy emulating the systematic reasoning patterns employed by dermatologists when\nevaluating skin conditions, this architecture provided a pathway toward more\nreliable automated diagnostic support systems.", "AI": {"tldr": "2025 ImageCLEF MEDIQA-MAGIC\u6311\u6218\u8d5b\u5173\u6ce8\u591a\u6a21\u6001\u76ae\u80a4\u75c5\u95ee\u7b54\u4e0e\u5206\u5272\uff0c\u63d0\u51fa\u7ed3\u5408\u5fae\u8c03\u591a\u6a21\u6001\u6a21\u578b\u3001\u7ed3\u6784\u5316\u63a8\u7406\u5c42\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u65b9\u6cd5\uff0c\u53d6\u5f97\u9ad8\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u89e3\u51b3\u8fdc\u7a0b\u533b\u7597\u4e2d\u8bca\u65ad\u51b3\u7b56\u7684\u5f02\u6b65\u6027\u548c\u9ad8\u51c6\u786e\u6027\u9700\u6c42\uff0c\u6a21\u62df\u76ae\u80a4\u79d1\u533b\u751f\u7684\u7cfb\u7edf\u6027\u63a8\u7406\u6a21\u5f0f\u3002", "method": "\u7ed3\u5408\u5fae\u8c03\u5f00\u6e90\u591a\u6a21\u6001\u6a21\u578b\uff08Qwen\u3001Gemma\u3001LLaMA\uff09\u3001\u7ed3\u6784\u5316\u63a8\u7406\u5c42\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08agentic RAG\uff09\u3002", "result": "\u56e2\u961f\u83b7\u5f97\u7b2c\u4e8c\u540d\uff0c\u63d0\u4ea4\u4f5c\u54c1\u6392\u540d\u7b2c\u516d\uff0c\u8868\u73b0\u7ade\u4e89\u529b\u548c\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u81ea\u52a8\u5316\u8bca\u65ad\u652f\u6301\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8def\u5f84\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u533b\u7597\u573a\u666f\u3002"}}
{"id": "2507.05622", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05622", "abs": "https://arxiv.org/abs/2507.05622", "authors": ["Shuo Shao", "Yiming Li", "Mengren Zheng", "Zhiyang Hu", "Yukun Chen", "Boheng Li", "Yu He", "Junfeng Guo", "Tianwei Zhang", "Dacheng Tao", "Zhan Qin"], "title": "DATABench: Evaluating Dataset Auditing in Deep Learning from an Adversarial Perspective", "comment": null, "summary": "The widespread application of Deep Learning across diverse domains hinges\ncritically on the quality and composition of training datasets. However, the\ncommon lack of disclosure regarding their usage raises significant privacy and\ncopyright concerns. Dataset auditing techniques, which aim to determine if a\nspecific dataset was used to train a given suspicious model, provide promising\nsolutions to addressing these transparency gaps. While prior work has developed\nvarious auditing methods, their resilience against dedicated adversarial\nattacks remains largely unexplored. To bridge the gap, this paper initiates a\ncomprehensive study evaluating dataset auditing from an adversarial\nperspective. We start with introducing a novel taxonomy, classifying existing\nmethods based on their reliance on internal features (IF) (inherent to the\ndata) versus external features (EF) (artificially introduced for auditing).\nSubsequently, we formulate two primary attack types: evasion attacks, designed\nto conceal the use of a dataset, and forgery attacks, intending to falsely\nimplicate an unused dataset. Building on the understanding of existing methods\nand attack objectives, we further propose systematic attack strategies:\ndecoupling, removal, and detection for evasion; adversarial example-based\nmethods for forgery. These formulations and strategies lead to our new\nbenchmark, DATABench, comprising 17 evasion attacks, 5 forgery attacks, and 9\nrepresentative auditing methods. Extensive evaluations using DATABench reveal\nthat none of the evaluated auditing methods are sufficiently robust or\ndistinctive under adversarial settings. These findings underscore the urgent\nneed for developing a more secure and reliable dataset auditing method capable\nof withstanding sophisticated adversarial manipulation. Code is available at\nhttps://github.com/shaoshuo-ss/DATABench.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5bf9\u6297\u89c6\u89d2\u4e0b\u7684\u6570\u636e\u96c6\u5ba1\u8ba1\u65b9\u6cd5\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u653b\u51fb\u7b56\u7565\u548c\u57fa\u51c6\u6d4b\u8bd5DATABench\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u96c6\u5ba1\u8ba1\u65b9\u6cd5\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u5206\u7c7b\u6cd5\u533a\u5206\u5185\u90e8\u7279\u5f81\uff08IF\uff09\u548c\u5916\u90e8\u7279\u5f81\uff08EF\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e24\u79cd\u653b\u51fb\u7c7b\u578b\uff1a\u9003\u907f\u653b\u51fb\u548c\u4f2a\u9020\u653b\u51fb\u3002\u8fdb\u4e00\u6b65\u63d0\u51fa\u7cfb\u7edf\u6027\u653b\u51fb\u7b56\u7565\uff0c\u5e76\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5DATABench\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u73b0\u6709\u5ba1\u8ba1\u65b9\u6cd5\u5728\u5bf9\u6297\u73af\u5883\u4e0b\u5747\u4e0d\u591f\u9c81\u68d2\u6216\u5177\u6709\u533a\u5206\u6027\u3002", "conclusion": "\u4e9f\u9700\u5f00\u53d1\u66f4\u5b89\u5168\u53ef\u9760\u7684\u6570\u636e\u96c6\u5ba1\u8ba1\u65b9\u6cd5\u4ee5\u62b5\u5fa1\u590d\u6742\u5bf9\u6297\u653b\u51fb\u3002"}}
{"id": "2507.05565", "categories": ["cs.SE", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.05565", "abs": "https://arxiv.org/abs/2507.05565", "authors": ["Sangwon Hyun", "Shaukat Ali", "M. Ali Babar"], "title": "Search-based Selection of Metamorphic Relations for Optimized Robustness Testing of Large Language Models", "comment": null, "summary": "Assessing the trustworthiness of Large Language Models (LLMs), such as\nrobustness, has garnered significant attention. Recently, metamorphic testing\nthat defines Metamorphic Relations (MRs) has been widely applied to evaluate\nthe robustness of LLM executions. However, the MR-based robustness testing\nstill requires a scalable number of MRs, thereby necessitating the optimization\nof selecting MRs. Most extant LLM testing studies are limited to automatically\ngenerating test cases (i.e., MRs) to enhance failure detection. Additionally,\nmost studies only considered a limited test space of single perturbation MRs in\ntheir evaluation of LLMs. In contrast, our paper proposes a search-based\napproach for optimizing the MR groups to maximize failure detection and\nminimize the LLM execution cost. Moreover, our approach covers the\ncombinatorial perturbations in MRs, facilitating the expansion of test space in\nthe robustness assessment. We have developed a search process and implemented\nfour search algorithms: Single-GA, NSGA-II, SPEA2, and MOEA/D with novel\nencoding to solve the MR selection problem in the LLM robustness testing. We\nconducted comparative experiments on the four search algorithms along with a\nrandom search, using two major LLMs with primary Text-to-Text tasks. Our\nstatistical and empirical investigation revealed two key findings: (1) the\nMOEA/D algorithm performed the best in optimizing the MR space for LLM\nrobustness testing, and (2) we identified silver bullet MRs for the LLM\nrobustness testing, which demonstrated dominant capabilities in confusing LLMs\nacross different Text-to-Text tasks. In LLM robustness assessment, our research\nsheds light on the fundamental problem for optimized testing and provides\ninsights into search-based solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u641c\u7d22\u7684\u65b9\u6cd5\uff0c\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7a33\u5065\u6027\u6d4b\u8bd5\u4e2d\u7684\u53d8\u5f62\u5173\u7cfb\uff08MR\uff09\u9009\u62e9\uff0c\u4ee5\u6700\u5927\u5316\u6545\u969c\u68c0\u6d4b\u5e76\u6700\u5c0f\u5316\u6267\u884c\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728LLM\u7a33\u5065\u6027\u6d4b\u8bd5\u4e2d\u4e3b\u8981\u5173\u6ce8\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff08MRs\uff09\uff0c\u4f46\u7f3a\u4e4f\u5bf9MR\u9009\u62e9\u7684\u4f18\u5316\uff0c\u4e14\u6d4b\u8bd5\u7a7a\u95f4\u6709\u9650\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u641c\u7d22\u8fc7\u7a0b\uff0c\u5e76\u5b9e\u73b0\u4e86\u56db\u79cd\u641c\u7d22\u7b97\u6cd5\uff08Single-GA\u3001NSGA-II\u3001SPEA2\u3001MOEA/D\uff09\u6765\u89e3\u51b3MR\u9009\u62e9\u95ee\u9898\uff0c\u540c\u65f6\u8003\u8651\u4e86\u7ec4\u5408\u6270\u52a8\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMOEA/D\u7b97\u6cd5\u5728\u4f18\u5316LLM\u7a33\u5065\u6027\u6d4b\u8bd5\u7684MR\u7a7a\u95f4\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u53d1\u73b0\u4e86\u5177\u6709\u663e\u8457\u6df7\u6dc6\u80fd\u529b\u7684\u201c\u94f6\u5f39MRs\u201d\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aLLM\u7a33\u5065\u6027\u6d4b\u8bd5\u4e2d\u7684\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u641c\u7d22\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u6269\u5c55\u4e86\u6d4b\u8bd5\u7a7a\u95f4\u3002"}}
{"id": "2507.05528", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05528", "abs": "https://arxiv.org/abs/2507.05528", "authors": ["Jiahuan Pei", "Fanghua Ye", "Xin Sun", "Wentao Deng", "Koen Hindriks", "Junxiao Wang"], "title": "Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment", "comment": "14 pages", "summary": "Large language models (LLMs) have advanced virtual educators and learners,\nbridging NLP with AI4Education. Existing work often lacks scalability and fails\nto leverage diverse, large-scale course content, with limited frameworks for\nassessing pedagogic quality. To this end, we propose WikiHowAgent, a\nmulti-agent workflow leveraging LLMs to simulate interactive teaching-learning\nconversations. It integrates teacher and learner agents, an interaction\nmanager, and an evaluator to facilitate procedural learning and assess\npedagogic quality. We introduce a dataset of 114,296 teacher-learner\nconversations grounded in 14,287 tutorials across 17 domains and 727 topics.\nOur evaluation protocol combines computational and rubric-based metrics with\nhuman judgment alignment. Results demonstrate the workflow's effectiveness in\ndiverse setups, offering insights into LLM capabilities across domains. Our\ndatasets and implementations are fully open-sourced.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faWikiHowAgent\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u6a21\u62df\u6559\u5b66\u4e92\u52a8\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u534f\u8bae\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u53ef\u6269\u5c55\u6027\u548c\u5229\u7528\u5927\u89c4\u6a21\u591a\u6837\u5316\u8bfe\u7a0b\u5185\u5bb9\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e14\u7f3a\u4e4f\u8bc4\u4f30\u6559\u5b66\u8d28\u91cf\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51faWikiHowAgent\uff0c\u6574\u5408\u6559\u5e08\u548c\u5b66\u4e60\u8005\u667a\u80fd\u4f53\u3001\u4ea4\u4e92\u7ba1\u7406\u5668\u548c\u8bc4\u4f30\u5668\uff0c\u652f\u6301\u7a0b\u5e8f\u5316\u5b66\u4e60\u5e76\u8bc4\u4f30\u6559\u5b66\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u5de5\u4f5c\u6d41\u5728\u591a\u6837\u5316\u573a\u666f\u4e2d\u6709\u6548\uff0c\u5e76\u63d0\u4f9b\u4e86\u8de8\u9886\u57df\u7684\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u6d1e\u5bdf\u3002", "conclusion": "\u8bba\u6587\u5f00\u6e90\u4e86\u6570\u636e\u96c6\u548c\u5b9e\u73b0\uff0c\u4e3aAI4Education\u9886\u57df\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u548c\u8d44\u6e90\u3002"}}
{"id": "2507.05630", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05630", "abs": "https://arxiv.org/abs/2507.05630", "authors": ["Sarthak Choudhary", "Divyam Anshumaan", "Nils Palumbo", "Somesh Jha"], "title": "How Not to Detect Prompt Injections with an LLM", "comment": null, "summary": "LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, in which adversaries embed malicious instructions within seemingly\nbenign user inputs to manipulate the LLM's intended behavior. Recent defenses\nbased on $\\textit{known-answer detection}$ (KAD) have achieved near-perfect\nperformance by using an LLM to classify inputs as clean or contaminated. In\nthis work, we formally characterize the KAD framework and uncover a structural\nvulnerability in its design that invalidates its core security premise. We\ndesign a methodical adaptive attack, $\\textit{DataFlip}$, to exploit this\nfundamental weakness. It consistently evades KAD defenses with detection rates\nas low as $1.5\\%$ while reliably inducing malicious behavior with success rates\nof up to $88\\%$, without needing white-box access to the LLM or any\noptimization procedures.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u5df2\u77e5\u7b54\u6848\u68c0\u6d4b\uff08KAD\uff09\u9632\u5fa1\u6846\u67b6\u7684\u7ed3\u6784\u6027\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDataFlip\u7684\u81ea\u9002\u5e94\u653b\u51fb\u65b9\u6cd5\uff0c\u80fd\u591f\u9ad8\u6548\u7ed5\u8fc7KAD\u9632\u5fa1\u3002", "motivation": "LLM\u5e94\u7528\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u73b0\u6709KAD\u9632\u5fa1\u6846\u67b6\u867d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b58\u5728\u8bbe\u8ba1\u7f3a\u9677\uff0c\u9700\u6df1\u5165\u5206\u6790\u5176\u5f31\u70b9\u3002", "method": "\u901a\u8fc7\u5f62\u5f0f\u5316\u5206\u6790KAD\u6846\u67b6\uff0c\u8bbe\u8ba1DataFlip\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u5176\u7ed3\u6784\u6027\u6f0f\u6d1e\u7ed5\u8fc7\u9632\u5fa1\u3002", "result": "DataFlip\u653b\u51fb\u6210\u529f\u7387\u8fbe88%\uff0c\u68c0\u6d4b\u7387\u4f4e\u81f31.5%\uff0c\u65e0\u9700\u767d\u76d2\u8bbf\u95ee\u6216\u4f18\u5316\u8fc7\u7a0b\u3002", "conclusion": "KAD\u9632\u5fa1\u6846\u67b6\u5b58\u5728\u6839\u672c\u6027\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u91cd\u65b0\u8bbe\u8ba1\u9632\u5fa1\u673a\u5236\u4ee5\u5e94\u5bf9\u6b64\u7c7b\u653b\u51fb\u3002"}}
{"id": "2507.05932", "categories": ["cs.SE", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.05932", "abs": "https://arxiv.org/abs/2507.05932", "authors": ["You Lu", "Dingji Wang", "Kaifeng Huang", "Bihuan Chen", "Xin Peng"], "title": "TigAug: Data Augmentation for Testing Traffic Light Detection in Autonomous Driving Systems", "comment": null, "summary": "Autonomous vehicle technology has been developed in the last decades with\nrecent advances in sensing and computing technology. There is an urgent need to\nensure the reliability and robustness of autonomous driving systems (ADSs).\nDespite the recent achievements in testing various ADS modules, little\nattention has been paid on the automated testing of traffic light detection\nmodels in ADSs. A common practice is to manually collect and label traffic\nlight data. However, it is labor-intensive, and even impossible to collect\ndiverse data under different driving environments.\n  To address these problems, we propose and implement TigAug to automatically\naugment labeled traffic light images for testing traffic light detection models\nin ADSs. We construct two families of metamorphic relations and three families\nof transformations based on a systematic understanding of weather environments,\ncamera properties, and traffic light properties. We use augmented images to\ndetect erroneous behaviors of traffic light detection models by\ntransformation-specific metamorphic relations, and to improve the performance\nof traffic light detection models by retraining. Large-scale experiments with\nfour state-of-the-art traffic light detection models and two traffic light\ndatasets have demonstrated that i) TigAug is effective in testing traffic light\ndetection models, ii) TigAug is efficient in synthesizing traffic light images,\nand iii) TigAug generates traffic light images with acceptable naturalness.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTigAug\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u589e\u5f3a\u6807\u8bb0\u7684\u4ea4\u901a\u706f\u56fe\u50cf\u6765\u6d4b\u8bd5\u548c\u6539\u8fdb\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u7684\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u7684\u6d4b\u8bd5\u4f9d\u8d56\u4eba\u5de5\u6536\u96c6\u548c\u6807\u6ce8\u6570\u636e\uff0c\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u8986\u76d6\u591a\u6837\u5316\u7684\u9a7e\u9a76\u73af\u5883\u3002", "method": "\u6784\u5efa\u4e86\u4e24\u7c7b\u8715\u53d8\u5173\u7cfb\u548c\u4e09\u7c7b\u56fe\u50cf\u53d8\u6362\uff0c\u57fa\u4e8e\u5929\u6c14\u3001\u76f8\u673a\u548c\u4ea4\u901a\u706f\u7279\u6027\u751f\u6210\u589e\u5f3a\u56fe\u50cf\uff0c\u7528\u4e8e\u6d4b\u8bd5\u548c\u6a21\u578b\u6539\u8fdb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eTigAug\u80fd\u6709\u6548\u6d4b\u8bd5\u6a21\u578b\u3001\u9ad8\u6548\u5408\u6210\u56fe\u50cf\uff0c\u4e14\u751f\u6210\u56fe\u50cf\u5177\u6709\u53ef\u63a5\u53d7\u7684\u81ea\u7136\u5ea6\u3002", "conclusion": "TigAug\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u6027\u80fd\u63d0\u5347\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.05538", "categories": ["cs.AI", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.05538", "abs": "https://arxiv.org/abs/2507.05538", "authors": ["Subhabrata Majumdar", "Brian Pendleton", "Abhishek Gupta"], "title": "Red Teaming AI Red Teaming", "comment": null, "summary": "Red teaming has evolved from its origins in military applications to become a\nwidely adopted methodology in cybersecurity and AI. In this paper, we take a\ncritical look at the practice of AI red teaming. We argue that despite its\ncurrent popularity in AI governance, there exists a significant gap between red\nteaming's original intent as a critical thinking exercise and its narrow focus\non discovering model-level flaws in the context of generative AI. Current AI\nred teaming efforts focus predominantly on individual model vulnerabilities\nwhile overlooking the broader sociotechnical systems and emergent behaviors\nthat arise from complex interactions between models, users, and environments.\nTo address this deficiency, we propose a comprehensive framework\noperationalizing red teaming in AI systems at two levels: macro-level system\nred teaming spanning the entire AI development lifecycle, and micro-level model\nred teaming. Drawing on cybersecurity experience and systems theory, we further\npropose a set of recommendations. In these, we emphasize that effective AI red\nteaming requires multifunctional teams that examine emergent risks, systemic\nvulnerabilities, and the interplay between technical and social factors.", "AI": {"tldr": "\u672c\u6587\u6279\u5224\u6027\u5730\u5ba1\u89c6\u4e86AI\u7ea2\u961f\u6d4b\u8bd5\u7684\u5b9e\u8df5\uff0c\u6307\u51fa\u5176\u5f53\u524d\u5728\u751f\u6210\u5f0fAI\u4e2d\u8fc7\u4e8e\u5173\u6ce8\u6a21\u578b\u7ea7\u7f3a\u9677\uff0c\u800c\u5ffd\u7565\u4e86\u66f4\u5e7f\u6cdb\u7684\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u3002\u4f5c\u8005\u63d0\u51fa\u4e00\u4e2a\u4e24\u5c42\u6b21\u6846\u67b6\uff0c\u5e76\u5efa\u8bae\u591a\u5b66\u79d1\u56e2\u961f\u4ee5\u5e94\u5bf9\u7cfb\u7edf\u6027\u98ce\u9669\u3002", "motivation": "\u63a2\u8ba8AI\u7ea2\u961f\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5176\u5ffd\u89c6\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u548c\u6d8c\u73b0\u884c\u4e3a\u7684\u7f3a\u9677\uff0c\u65e8\u5728\u63a8\u52a8\u66f4\u5168\u9762\u7684\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4e24\u5c42\u6b21\u6846\u67b6\uff1a\u5b8f\u89c2\u7cfb\u7edf\u7ea7\u7ea2\u961f\u6d4b\u8bd5\u548c\u5fae\u89c2\u6a21\u578b\u7ea7\u7ea2\u961f\u6d4b\u8bd5\uff0c\u7ed3\u5408\u7f51\u7edc\u5b89\u5168\u7ecf\u9a8c\u548c\u7cfb\u7edf\u7406\u8bba\u3002", "result": "\u5f3a\u8c03\u6709\u6548\u7684AI\u7ea2\u961f\u6d4b\u8bd5\u9700\u591a\u5b66\u79d1\u56e2\u961f\uff0c\u5173\u6ce8\u6d8c\u73b0\u98ce\u9669\u3001\u7cfb\u7edf\u6027\u6f0f\u6d1e\u53ca\u6280\u672f\u4e0e\u793e\u4f1a\u56e0\u7d20\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "conclusion": "\u547c\u5401\u6269\u5c55\u7ea2\u961f\u6d4b\u8bd5\u7684\u8303\u56f4\uff0c\u4ee5\u66f4\u597d\u5730\u5e94\u5bf9AI\u7cfb\u7edf\u4e2d\u7684\u590d\u6742\u6027\u548c\u7cfb\u7edf\u6027\u98ce\u9669\u3002"}}
{"id": "2507.05649", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05649", "abs": "https://arxiv.org/abs/2507.05649", "authors": ["Kaixiang Zhao", "Joseph Yousry Attalla", "Qian Lou", "Yushun Dong"], "title": "DESIGN: Encrypted GNN Inference via Server-Side Input Graph Pruning", "comment": "Under Review in Conference on Neural Information Processing Systems\n  (NeurIPS 2025)", "summary": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in\nvarious graph-based learning tasks. However, enabling privacy-preserving GNNs\nin encrypted domains, such as under Fully Homomorphic Encryption (FHE),\ntypically incurs substantial computational overhead, rendering real-time and\nprivacy-preserving inference impractical. In this work, we propose DESIGN\n(EncrypteD GNN Inference via sErver-Side Input Graph pruNing), a novel\nframework for efficient encrypted GNN inference. DESIGN tackles the critical\nefficiency limitations of existing FHE GNN approaches, which often overlook\ninput data redundancy and apply uniform computational strategies. Our framework\nachieves significant performance gains through a hierarchical optimization\nstrategy executed entirely on the server: first, FHE-compatible node importance\nscores (based on encrypted degree statistics) are computed from the encrypted\ngraph. These scores then guide a homomorphic partitioning process, generating\nmulti-level importance masks directly under FHE. This dynamically generated\nmask facilitates both input graph pruning (by logically removing unimportant\nelements) and a novel adaptive polynomial activation scheme, where activation\ncomplexity is tailored to node importance levels. Empirical evaluations\ndemonstrate that DESIGN substantially accelerates FHE GNN inference compared to\nstate-of-the-art methods while maintaining competitive model accuracy,\npresenting a robust solution for secure graph analytics.", "AI": {"tldr": "DESIGN\u6846\u67b6\u901a\u8fc7\u670d\u52a1\u5668\u7aef\u8f93\u5165\u56fe\u526a\u679d\u548c\u81ea\u9002\u5e94\u591a\u9879\u5f0f\u6fc0\u6d3b\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a0\u5bc6GNN\u63a8\u7406\u7684\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709FHE GNN\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\uff0c\u5ffd\u89c6\u4e86\u8f93\u5165\u6570\u636e\u5197\u4f59\u548c\u7edf\u4e00\u8ba1\u7b97\u7b56\u7565\u7684\u95ee\u9898\u3002", "method": "DESIGN\u91c7\u7528\u5206\u5c42\u4f18\u5316\u7b56\u7565\uff0c\u5305\u62ec\u57fa\u4e8e\u52a0\u5bc6\u5ea6\u7edf\u8ba1\u7684\u8282\u70b9\u91cd\u8981\u6027\u8bc4\u5206\u3001\u540c\u6001\u5206\u533a\u751f\u6210\u591a\u7ea7\u91cd\u8981\u6027\u63a9\u7801\uff0c\u4ee5\u53ca\u81ea\u9002\u5e94\u591a\u9879\u5f0f\u6fc0\u6d3b\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDESIGN\u663e\u8457\u52a0\u901f\u4e86FHE GNN\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u6027\u7684\u6a21\u578b\u51c6\u786e\u6027\u3002", "conclusion": "DESIGN\u4e3a\u5b89\u5168\u56fe\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.05981", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05981", "abs": "https://arxiv.org/abs/2507.05981", "authors": ["Marc Oriol", "Quim Motger", "Jordi Marco", "Xavier Franch"], "title": "Multi-Agent Debate Strategies to Enhance Requirements Engineering with Large Language Models", "comment": null, "summary": "Context: Large Language Model (LLM) agents are becoming widely used for\nvarious Requirements Engineering (RE) tasks. Research on improving their\naccuracy mainly focuses on prompt engineering, model fine-tuning, and retrieval\naugmented generation. However, these methods often treat models as isolated\nblack boxes - relying on single-pass outputs without iterative refinement or\ncollaboration, limiting robustness and adaptability. Objective: We propose\nthat, just as human debates enhance accuracy and reduce bias in RE tasks by\nincorporating diverse perspectives, different LLM agents debating and\ncollaborating may achieve similar improvements. Our goal is to investigate\nwhether Multi-Agent Debate (MAD) strategies can enhance RE performance. Method:\nWe conducted a systematic study of existing MAD strategies across various\ndomains to identify their key characteristics. To assess their applicability in\nRE, we implemented and tested a preliminary MAD-based framework for RE\nclassification. Results: Our study identified and categorized several MAD\nstrategies, leading to a taxonomy outlining their core attributes. Our\npreliminary evaluation demonstrated the feasibility of applying MAD to RE\nclassification. Conclusions: MAD presents a promising approach for improving\nLLM accuracy in RE tasks. This study provides a foundational understanding of\nMAD strategies, offering insights for future research and refinements in RE\napplications.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\uff08MAD\uff09\u7b56\u7565\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u521d\u6b65\u6846\u67b6\u5e76\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06LLM\u89c6\u4e3a\u5b64\u7acb\u9ed1\u7bb1\uff0c\u7f3a\u4e4f\u8fed\u4ee3\u4f18\u5316\u548c\u534f\u4f5c\uff0c\u9650\u5236\u4e86\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002\u53d7\u4eba\u7c7b\u8fa9\u8bba\u542f\u53d1\uff0c\u7814\u7a76MAD\u7b56\u7565\u662f\u5426\u80fd\u63d0\u5347RE\u6027\u80fd\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u73b0\u6709MAD\u7b56\u7565\uff0c\u63d0\u51fa\u5206\u7c7b\u6cd5\uff0c\u5e76\u521d\u6b65\u5b9e\u73b0MAD\u6846\u67b6\u7528\u4e8eRE\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u7814\u7a76\u603b\u7ed3\u4e86MAD\u7b56\u7565\u7684\u6838\u5fc3\u7279\u5f81\uff0c\u521d\u6b65\u8bc4\u4f30\u8868\u660eMAD\u5728RE\u5206\u7c7b\u4e2d\u5177\u6709\u53ef\u884c\u6027\u3002", "conclusion": "MAD\u4e3a\u63d0\u5347LLM\u5728RE\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.05541", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05541", "abs": "https://arxiv.org/abs/2507.05541", "authors": ["Shovito Barua Soumma", "Asiful Arefeen", "Stephanie M. Carpenter", "Melanie Hingle", "Hassan Ghasemzadeh"], "title": "SenseCF: LLM-Prompted Counterfactuals for Intervention and Sensor Data Augmentation", "comment": "In review", "summary": "Counterfactual explanations (CFs) offer human-centric insights into machine\nlearning predictions by highlighting minimal changes required to alter an\noutcome. Therefore, CFs can be used as (i) interventions for abnormality\nprevention and (ii) augmented data for training robust models. In this work, we\nexplore large language models (LLMs), specifically GPT-4o-mini, for generating\nCFs in a zero-shot and three-shot setting. We evaluate our approach on two\ndatasets: the AI-Readi flagship dataset for stress prediction and a public\ndataset for heart disease detection. Compared to traditional methods such as\nDiCE, CFNOW, and NICE, our few-shot LLM-based approach achieves high\nplausibility (up to 99%), strong validity (up to 0.99), and competitive\nsparsity. Moreover, using LLM-generated CFs as augmented samples improves\ndownstream classifier performance (an average accuracy gain of 5%), especially\nin low-data regimes. This demonstrates the potential of prompt-based generative\ntechniques to enhance explainability and robustness in clinical and\nphysiological prediction tasks. Code base: github.com/anonymous/SenseCF.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4o-mini\uff09\u751f\u6210\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CFs\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u589e\u5f3a\u673a\u5668\u5b66\u4e60\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CFs\uff09\u80fd\u63d0\u4f9b\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u9884\u6d4b\u89e3\u91ca\uff0c\u5e76\u53ef\u7528\u4e8e\u5e72\u9884\u5f02\u5e38\u9884\u9632\u548c\u6570\u636e\u589e\u5f3a\u3002", "method": "\u5728\u96f6\u6837\u672c\u548c\u4e09\u6837\u672c\u8bbe\u7f6e\u4e0b\uff0c\u4f7f\u7528LLM\u751f\u6210CFs\uff0c\u5e76\u5728\u4e24\u4e2a\u6570\u636e\u96c6\uff08\u538b\u529b\u9884\u6d4b\u548c\u5fc3\u810f\u75c5\u68c0\u6d4b\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff08\u5982DiCE\u3001CFNOW\u3001NICE\uff09\uff0cLLM\u65b9\u6cd5\u5728\u5408\u7406\u6027\uff0899%\uff09\u3001\u6709\u6548\u6027\uff080.99\uff09\u548c\u7a00\u758f\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u80fd\u63d0\u5347\u4e0b\u6e38\u5206\u7c7b\u5668\u6027\u80fd\uff08\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad85%\uff09\u3002", "conclusion": "\u57fa\u4e8e\u63d0\u793a\u7684\u751f\u6210\u6280\u672f\u6709\u671b\u63d0\u5347\u4e34\u5e8a\u548c\u751f\u7406\u9884\u6d4b\u4efb\u52a1\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.05660", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05660", "abs": "https://arxiv.org/abs/2507.05660", "authors": ["Aravind Cheruvu", "Shravya Kanchi", "Sifat Muhammad Abdullah", "Nicholas Kong", "Daphne Yao", "Murtuza Jadliwala", "Bimal Viswanath"], "title": "TuneShield: Mitigating Toxicity in Conversational AI while Fine-tuning on Untrusted Data", "comment": "Pre-print", "summary": "Recent advances in foundation models, such as LLMs, have revolutionized\nconversational AI. Chatbots are increasingly being developed by customizing\nLLMs on specific conversational datasets. However, mitigating toxicity during\nthis customization, especially when dealing with untrusted training data,\nremains a significant challenge. To address this, we introduce TuneShield, a\ndefense framework designed to mitigate toxicity during chatbot fine-tuning\nwhile preserving conversational quality. TuneShield leverages LLM-based\ntoxicity classification, utilizing the instruction-following capabilities and\nsafety alignment of LLMs to effectively identify toxic samples, outperforming\nindustry API services. TuneShield generates synthetic conversation samples,\ntermed 'healing data', based on the identified toxic samples, using them to\nmitigate toxicity while reinforcing desirable behavior during fine-tuning. It\nperforms an alignment process to further nudge the chatbot towards producing\ndesired responses. Our findings show that TuneShield effectively mitigates\ntoxicity injection attacks while preserving conversational quality, even when\nthe toxicity classifiers are imperfect or biased. TuneShield proves to be\nresilient against adaptive adversarial and jailbreak attacks. Additionally,\nTuneShield demonstrates effectiveness in mitigating adaptive toxicity injection\nattacks during dialog-based learning (DBL).", "AI": {"tldr": "TuneShield\u662f\u4e00\u4e2a\u9632\u5fa1\u6846\u67b6\uff0c\u7528\u4e8e\u5728LLM\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u51cf\u5c11\u6bd2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u8bdd\u8d28\u91cf\u3002", "motivation": "\u5b9a\u5236LLM\u65f6\uff0c\u5904\u7406\u4e0d\u53ef\u4fe1\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u6bd2\u6027\u662f\u4e00\u4e2a\u91cd\u8981\u6311\u6218\u3002", "method": "\u5229\u7528LLM\u7684\u6bd2\u6027\u5206\u7c7b\u80fd\u529b\u751f\u6210\u2018\u6cbb\u6108\u6570\u636e\u2019\uff0c\u5e76\u901a\u8fc7\u5bf9\u9f50\u8fc7\u7a0b\u4f18\u5316\u6a21\u578b\u3002", "result": "TuneShield\u6709\u6548\u51cf\u5c11\u6bd2\u6027\u653b\u51fb\uff0c\u4fdd\u6301\u5bf9\u8bdd\u8d28\u91cf\uff0c\u5bf9\u6297\u81ea\u9002\u5e94\u653b\u51fb\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "TuneShield\u5728\u51cf\u5c11\u6bd2\u6027\u548c\u5bf9\u6297\u653b\u51fb\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e\u5bf9\u8bdd\u5b66\u4e60\u573a\u666f\u3002"}}
{"id": "2507.05995", "categories": ["cs.SE", "68Nxx", "D.2.0; D.2.8"], "pdf": "https://arxiv.org/pdf/2507.05995", "abs": "https://arxiv.org/abs/2507.05995", "authors": ["Pengzhou Chen", "Tao Chen"], "title": "PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning", "comment": "This paper has been accepted by ICSE26", "summary": "The high configurability of modern software systems has made configuration\ntuning a crucial step for assuring system performance, e.g., latency or\nthroughput. However, given the expensive measurements, large configuration\nspace, and rugged configuration landscape, existing tuners suffer\nineffectiveness due to the difficult balance of budget utilization between\nexploring uncertain regions (for escaping from local optima) and exploiting\nguidance of known good configurations (for fast convergence). The root cause is\nthat we lack knowledge of where the promising regions lay, which also causes\nchallenges in the explainability of the results.\n  In this paper, we propose PromiseTune that tunes configuration guided by\ncausally purified rules. PromiseTune is unique in the sense that we learn\nrules, which reflect certain regions in the configuration landscape, and purify\nthem with causal inference. The remaining rules serve as approximated\nreflections of the promising regions, bounding the tuning to emphasize these\nplaces in the landscape. This, as we demonstrate, can effectively mitigate the\nimpact of the exploration and exploitation trade-off. Those purified regions\ncan then be paired with the measured configurations to provide spatial\nexplainability at the landscape level. Comparing with 11 state-of-the-art\ntuners on 12 systems and varying budgets, we show that PromiseTune performs\nsignificantly better than the others with $42\\%$ superior rank to the overall\nsecond best while providing richer information to explain the hidden system\ncharacteristics.", "AI": {"tldr": "PromiseTune\u901a\u8fc7\u56e0\u679c\u63a8\u65ad\u7eaf\u5316\u7684\u89c4\u5219\u6307\u5bfc\u914d\u7f6e\u8c03\u4f18\uff0c\u6709\u6548\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u7684\u9ad8\u53ef\u914d\u7f6e\u6027\u4f7f\u914d\u7f6e\u8c03\u4f18\u6210\u4e3a\u786e\u4fdd\u6027\u80fd\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u4f46\u73b0\u6709\u8c03\u4f18\u65b9\u6cd5\u56e0\u96be\u4ee5\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u800c\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faPromiseTune\uff0c\u901a\u8fc7\u56e0\u679c\u63a8\u65ad\u7eaf\u5316\u89c4\u5219\uff0c\u8fd1\u4f3c\u53cd\u6620\u6709\u6f5c\u529b\u7684\u914d\u7f6e\u533a\u57df\uff0c\u5e76\u4ee5\u6b64\u6307\u5bfc\u8c03\u4f18\u3002", "result": "\u572812\u4e2a\u7cfb\u7edf\u548c\u4e0d\u540c\u9884\u7b97\u4e0b\uff0cPromiseTune\u663e\u8457\u4f18\u4e8e11\u79cd\u73b0\u6709\u65b9\u6cd5\uff0c\u6392\u540d\u4f18\u52bf\u8fbe42%\u3002", "conclusion": "PromiseTune\u4e0d\u4ec5\u6027\u80fd\u4f18\u8d8a\uff0c\u8fd8\u80fd\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u89e3\u91ca\u6027\u4fe1\u606f\uff0c\u63ed\u793a\u7cfb\u7edf\u9690\u85cf\u7279\u6027\u3002"}}
{"id": "2507.05566", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05566", "abs": "https://arxiv.org/abs/2507.05566", "authors": ["David Bensa\u00efd", "Noam Rotstein", "Roy Velich", "Daniel Bensa\u00efd", "Ron Kimmel"], "title": "SingLoRA: Low Rank Adaptation Using a Single Matrix", "comment": null, "summary": "Low-Rank Adaptation (LoRA) has significantly advanced parameter-efficient\nfine-tuning of large pretrained models. LoRA augments the pre-trained weights\nof a model by adding the product of two smaller matrices that together form a\nlow-rank matrix update. Recent research has shown that scale disparities\nbetween these two matrices often cause unstable training dynamics, leading to\nsuboptimal performance. In this paper, we propose SingLoRA, which reformulates\nlow-rank adaptation by learning the weights update as a decomposition of a\nsingle low-rank matrix multiplied by its transpose. This simple design\ninherently removes inter-matrix scale conflicts, ensuring stable optimization,\nand roughly halves the parameter count. We analyze SingLoRA within the\ninfinite-width neural network framework, showing that it guarantees stable\nfeature learning by construction. Extensive experiments on multiple tasks\nvalidate these benefits. In common sense reasoning, fine-tuning LLama 7B on\nMNLI with SingLoRA achieves 91.3% accuracy - surpassing LoRA (89.1%) and LoRA+\n(90.2%) - while using only 60% of their parameter budget. In image generation,\nfine-tuning Stable Diffusion with SingLoRA significantly improves image\nfidelity on DreamBooth, achieving a DINO similarity score of 0.151, compared to\nscores of 0.148 and 0.143 for DoRA and LoRA, respectively.", "AI": {"tldr": "SingLoRA\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f4e\u79e9\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u5355\u4f4e\u79e9\u77e9\u9635\u5206\u89e3\u89e3\u51b3LoRA\u4e2d\u7684\u5c3a\u5ea6\u51b2\u7a81\u95ee\u9898\uff0c\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027\u5e76\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u3002", "motivation": "LoRA\u5728\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u4e2d\u5b58\u5728\u5c3a\u5ea6\u51b2\u7a81\u95ee\u9898\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u6027\u80fd\u4e0b\u964d\u3002", "method": "SingLoRA\u5c06\u6743\u91cd\u66f4\u65b0\u91cd\u65b0\u8868\u8ff0\u4e3a\u5355\u4f4e\u79e9\u77e9\u9635\u4e0e\u5176\u8f6c\u7f6e\u7684\u4e58\u79ef\uff0c\u6d88\u9664\u5c3a\u5ea6\u51b2\u7a81\u5e76\u51cf\u5c11\u53c2\u6570\u3002", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5982LLama 7B\u5fae\u8c03MNLI\u51c6\u786e\u7387\u8fbe91.3%\uff0c\u4f18\u4e8eLoRA\u548cLoRA+\uff0c\u4e14\u53c2\u6570\u66f4\u5c11\u3002", "conclusion": "SingLoRA\u901a\u8fc7\u7b80\u5355\u8bbe\u8ba1\u89e3\u51b3\u4e86LoRA\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u5e76\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2507.05683", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.05683", "abs": "https://arxiv.org/abs/2507.05683", "authors": ["Steven Duplij", "Qiang Guo"], "title": "Polyadic encryption", "comment": "revtex 4.2, 9 pages", "summary": "A novel original procedure of encryption/decryption based on the polyadic\nalgebraic structures and on signal processing methods is proposed. First, we\nuse signals with integer amplitudes to send information. Then we use polyadic\ntechniques to transfer the plaintext into series of special integers. The\nreceiver restores the plaintext using special rules and systems of equations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u5143\u4ee3\u6570\u7ed3\u6784\u548c\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\u7684\u52a0\u5bc6/\u89e3\u5bc6\u65b0\u65b9\u6cd5\u3002", "motivation": "\u5229\u7528\u591a\u5143\u4ee3\u6570\u7ed3\u6784\u548c\u4fe1\u53f7\u5904\u7406\u6280\u672f\uff0c\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u52a0\u5bc6/\u89e3\u5bc6\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6574\u6570\u632f\u5e45\u4fe1\u53f7\u4f20\u9012\u4fe1\u606f\uff0c\u901a\u8fc7\u591a\u5143\u6280\u672f\u5c06\u660e\u6587\u8f6c\u6362\u4e3a\u7279\u6b8a\u6574\u6570\u5e8f\u5217\uff0c\u63a5\u6536\u65b9\u901a\u8fc7\u7279\u5b9a\u89c4\u5219\u548c\u65b9\u7a0b\u7ec4\u6062\u590d\u660e\u6587\u3002", "result": "\u5b9e\u73b0\u4e86\u57fa\u4e8e\u591a\u5143\u4ee3\u6570\u548c\u4fe1\u53f7\u5904\u7406\u7684\u52a0\u5bc6/\u89e3\u5bc6\u6d41\u7a0b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u52a0\u5bc6\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\uff0c\u5177\u6709\u6f5c\u5728\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.06014", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.06014", "abs": "https://arxiv.org/abs/2507.06014", "authors": ["Tim Puhlf\u00fcr\u00df", "Julia Butzke", "Walid Maalej"], "title": "Model Cards Revisited: Bridging the Gap Between Theory and Practice for Ethical AI Requirements", "comment": "Accepted for publication at the 33rd IEEE International Requirements\n  Engineering 2025 conference", "summary": "Model cards are the primary documentation framework for developers of\nartificial intelligence (AI) models to communicate critical information to\ntheir users. Those users are often developers themselves looking for relevant\ndocumentation to ensure that their AI systems comply with the ethical\nrequirements of existing laws, guidelines, and standards. Recent studies\nindicate inadequate model documentation practices, suggesting a gap between AI\nrequirements and current practices in model documentation. To understand this\ngap and provide actionable guidance to bridge it, we conducted a thematic\nanalysis of 26 guidelines on ethics and AI, three AI documentation frameworks,\nthree quantitative studies of model cards, and ten actual model cards. We\nidentified a total of 43 ethical requirements relevant to model documentation\nand organized them into a taxonomy featuring four themes and twelve sub-themes\nrepresenting ethical principles. Our findings indicate that model developers\npredominantly emphasize model capabilities and reliability in the documentation\nwhile overlooking other ethical aspects, such as explainability, user autonomy,\nand fairness. This underscores the need for enhanced support in documenting\nethical AI considerations. Our taxonomy serves as a foundation for a revised\nmodel card framework that holistically addresses ethical AI requirements.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86AI\u6a21\u578b\u6587\u6863\uff08\u6a21\u578b\u5361\uff09\u7684\u73b0\u72b6\uff0c\u53d1\u73b0\u5f00\u53d1\u8005\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u80fd\u529b\u548c\u53ef\u9760\u6027\uff0c\u800c\u5ffd\u7565\u4e86\u5176\u4ed6\u4f26\u7406\u8981\u6c42\uff08\u5982\u53ef\u89e3\u91ca\u6027\u3001\u7528\u6237\u81ea\u4e3b\u6027\u548c\u516c\u5e73\u6027\uff09\u3002\u901a\u8fc7\u5206\u679026\u4efd\u4f26\u7406\u6307\u5357\u30013\u4e2a\u6587\u6863\u6846\u67b6\u548c10\u4e2a\u5b9e\u9645\u6a21\u578b\u5361\uff0c\u63d0\u51fa\u4e86\u5305\u542b43\u4e2a\u4f26\u7406\u8981\u6c42\u7684\u5206\u7c7b\u6cd5\uff0c\u4e3a\u6539\u8fdb\u6a21\u578b\u5361\u6846\u67b6\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u6587\u6863\u5b9e\u8df5\u4e0d\u8db3\uff0c\u672a\u80fd\u6ee1\u8db3\u4f26\u7406\u8981\u6c42\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5206\u6790\u4ee5\u586b\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u5bf926\u4efd\u4f26\u7406\u6307\u5357\u30013\u4e2aAI\u6587\u6863\u6846\u67b6\u30013\u9879\u5b9a\u91cf\u7814\u7a76\u548c10\u4e2a\u5b9e\u9645\u6a21\u578b\u5361\u8fdb\u884c\u4e3b\u9898\u5206\u6790\uff0c\u63d0\u53d6\u5e76\u5206\u7c7b\u4f26\u7406\u8981\u6c42\u3002", "result": "\u63d0\u51fa\u4e86\u5305\u542b43\u4e2a\u4f26\u7406\u8981\u6c42\u7684\u5206\u7c7b\u6cd5\uff0c\u53d1\u73b0\u5f00\u53d1\u8005\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u80fd\u529b\u548c\u53ef\u9760\u6027\uff0c\u5ffd\u89c6\u4e86\u5176\u4ed6\u4f26\u7406\u65b9\u9762\u3002", "conclusion": "\u9700\u8981\u6539\u8fdb\u6a21\u578b\u5361\u6846\u67b6\u4ee5\u5168\u9762\u6ee1\u8db3\u4f26\u7406\u8981\u6c42\uff0c\u63d0\u51fa\u7684\u5206\u7c7b\u6cd5\u4e3a\u6b64\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.05587", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05587", "abs": "https://arxiv.org/abs/2507.05587", "authors": ["Elija Perrier"], "title": "Towards Measurement Theory for Artificial Intelligence", "comment": "Under review for Iliad Conference 2025", "summary": "We motivate and outline a programme for a formal theory of measurement of\nartificial intelligence. We argue that formalising measurement for AI will\nallow researchers, practitioners, and regulators to: (i) make comparisons\nbetween systems and the evaluation methods applied to them; (ii) connect\nfrontier AI evaluations with established quantitative risk analysis techniques\ndrawn from engineering and safety science; and (iii) foreground how what counts\nas AI capability is contingent upon the measurement operations and scales we\nelect to use. We sketch a layered measurement stack, distinguish direct from\nindirect observables, and signpost how these ingredients provide a pathway\ntoward a unified, calibratable taxonomy of AI phenomena.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u6d4b\u91cf\u7684\u6b63\u5f0f\u7406\u8bba\u6846\u67b6\uff0c\u65e8\u5728\u652f\u6301\u7cfb\u7edf\u6bd4\u8f83\u3001\u98ce\u9669\u5206\u6790\u53ca\u80fd\u529b\u8bc4\u4f30\u3002", "motivation": "\u4e3aAI\u7814\u7a76\u3001\u5b9e\u8df5\u548c\u76d1\u7ba1\u63d0\u4f9b\u7edf\u4e00\u7684\u6d4b\u91cf\u6807\u51c6\uff0c\u4ee5\u4fbf\u6bd4\u8f83\u7cfb\u7edf\u3001\u8fde\u63a5\u524d\u6cbf\u8bc4\u4f30\u4e0e\u98ce\u9669\u5206\u6790\u6280\u672f\uff0c\u5e76\u660e\u786eAI\u80fd\u529b\u7684\u6d4b\u91cf\u4f9d\u8d56\u6027\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u7684\u6d4b\u91cf\u5806\u6808\uff0c\u533a\u5206\u76f4\u63a5\u4e0e\u95f4\u63a5\u53ef\u89c2\u6d4b\u6027\uff0c\u6784\u5efa\u53ef\u6821\u51c6\u7684AI\u73b0\u8c61\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u4e3aAI\u6d4b\u91cf\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\uff0c\u652f\u6301\u7cfb\u7edf\u6bd4\u8f83\u3001\u98ce\u9669\u5206\u6790\u53ca\u80fd\u529b\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u7406\u8bba\u6846\u67b6\u4e3aAI\u6d4b\u91cf\u63d0\u4f9b\u7edf\u4e00\u8def\u5f84\uff0c\u4fc3\u8fdb\u66f4\u79d1\u5b66\u7684\u8bc4\u4f30\u548c\u76d1\u7ba1\u3002"}}
{"id": "2507.05728", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05728", "abs": "https://arxiv.org/abs/2507.05728", "authors": ["Ruofei Wang", "Peiqi Duan", "Boxin Shi", "Renjie Wan"], "title": "Asynchronous Event Error-Minimizing Noise for Safeguarding Event Dataset", "comment": "Accepted by ICCV2025", "summary": "With more event datasets being released online, safeguarding the event\ndataset against unauthorized usage has become a serious concern for data\nowners. Unlearnable Examples are proposed to prevent the unauthorized\nexploitation of image datasets. However, it's unclear how to create unlearnable\nasynchronous event streams to prevent event misuse. In this work, we propose\nthe first unlearnable event stream generation method to prevent unauthorized\ntraining from event datasets. A new form of asynchronous event error-minimizing\nnoise is proposed to perturb event streams, tricking the unauthorized model\ninto learning embedded noise instead of realistic features. To be compatible\nwith the sparse event, a projection strategy is presented to sparsify the noise\nto render our unlearnable event streams (UEvs). Extensive experiments\ndemonstrate that our method effectively protects event data from unauthorized\nexploitation, while preserving their utility for legitimate use. We hope our\nUEvs contribute to the advancement of secure and trustworthy event dataset\nsharing. Code is available at: https://github.com/rfww/uevs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4e8b\u4ef6\u6570\u636e\u96c6\u7684\u4e0d\u53ef\u5b66\u4e60\u4e8b\u4ef6\u6d41\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f02\u6b65\u4e8b\u4ef6\u8bef\u5dee\u6700\u5c0f\u5316\u566a\u58f0\u5e72\u6270\u6570\u636e\uff0c\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u8bad\u7ec3\u3002", "motivation": "\u968f\u7740\u5728\u7ebf\u4e8b\u4ef6\u6570\u636e\u96c6\u7684\u589e\u591a\uff0c\u4fdd\u62a4\u6570\u636e\u514d\u53d7\u672a\u7ecf\u6388\u6743\u4f7f\u7528\u6210\u4e3a\u91cd\u8981\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5f02\u6b65\u4e8b\u4ef6\u8bef\u5dee\u6700\u5c0f\u5316\u566a\u58f0\u548c\u6295\u5f71\u7b56\u7565\uff0c\u751f\u6210\u7a00\u758f\u7684\u4e0d\u53ef\u5b66\u4e60\u4e8b\u4ef6\u6d41\uff08UEvs\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u9632\u6b62\u6570\u636e\u6ee5\u7528\uff0c\u540c\u65f6\u4fdd\u7559\u5408\u6cd5\u7528\u9014\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "UEvs\u6709\u52a9\u4e8e\u63a8\u52a8\u5b89\u5168\u53ef\u4fe1\u7684\u4e8b\u4ef6\u6570\u636e\u96c6\u5171\u4eab\u3002"}}
{"id": "2507.05591", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05591", "abs": "https://arxiv.org/abs/2507.05591", "authors": ["Wei Zhang", "Juan Chen", "En Zhu", "Wenhong Cheng", "YunPeng Li", "Yanbo J. Wang"], "title": "MLlm-DR: Towards Explainable Depression Recognition with MultiModal Large Language Models", "comment": null, "summary": "Automated depression diagnosis aims to analyze multimodal information from\ninterview videos to predict participants' depression scores. Previous studies\noften lack clear explanations of how these scores were determined, limiting\ntheir adoption in clinical practice. While the advent of LLMs provides a\npossible pathway for explainable depression diagnosis, current LLMs capable of\nprocessing multimodal data lack training on interview data, resulting in poor\ndiagnostic performance when used directly. In this paper, we propose a novel\nmultimodal large language model (MLlm-DR) that can understand multimodal\ninformation inputs and supports explainable depression diagnosis. MLlm-DR\nintegrates a smaller LLMs and a lightweight query module (LQ-former).\nSpecifically, the smaller LLMs is designed to generate depression scores and\ncorresponding evaluation rationales. To enhance its logical reasoning for\ndomain-specific tasks while maintaining practicality, we constructed a robust\ntraining dataset to fine-tune it. Meanwhile, the LQ-former captures\ndepression-related features from speech and visual data, aiding the model's\nability to process multimodal information, to achieve comprehensive depression\ndiagnosis. Our approach achieves state-of-the-art results on two\ninterview-based benchmark datasets, CMDC and E-DAIC-WOZ, demonstrating its\neffectiveness and superiority.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLlm-DR\uff09\uff0c\u7528\u4e8e\u53ef\u89e3\u91ca\u7684\u6291\u90c1\u75c7\u8bca\u65ad\uff0c\u7ed3\u5408\u5c0f\u578bLLM\u548c\u8f7b\u91cf\u67e5\u8be2\u6a21\u5757\uff08LQ-former\uff09\uff0c\u5728CMDC\u548cE-DAIC-WOZ\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u6291\u90c1\u75c7\u8bca\u65ad\u65b9\u6cd5\u7f3a\u4e4f\u89e3\u91ca\u6027\uff0c\u4e14\u591a\u6a21\u6001LLM\u5728\u8bbf\u8c08\u6570\u636e\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u5e94\u7528\u7684\u63a8\u5e7f\u3002", "method": "MLlm-DR\u6574\u5408\u5c0f\u578bLLM\u751f\u6210\u6291\u90c1\u75c7\u8bc4\u5206\u53ca\u89e3\u91ca\uff0cLQ-former\u6355\u6349\u8bed\u97f3\u548c\u89c6\u89c9\u7279\u5f81\uff0c\u901a\u8fc7\u7cbe\u7ec6\u8bad\u7ec3\u63d0\u5347\u903b\u8f91\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728CMDC\u548cE-DAIC-WOZ\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "MLlm-DR\u4e3a\u53ef\u89e3\u91ca\u7684\u6291\u90c1\u75c7\u8bca\u65ad\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u4e34\u5e8a\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.05794", "categories": ["cs.CR", "cs.AI", "cs.LO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.05794", "abs": "https://arxiv.org/abs/2507.05794", "authors": ["Avi Shaked", "Nan Messe"], "title": "Automated Reasoning for Vulnerability Management by Design", "comment": null, "summary": "For securing systems, it is essential to manage their vulnerability posture\nand design appropriate security controls. Vulnerability management allows to\nproactively address vulnerabilities by incorporating pertinent security\ncontrols into systems designs. Current vulnerability management approaches do\nnot support systematic reasoning about the vulnerability postures of systems\ndesigns. To effectively manage vulnerabilities and design security controls, we\npropose a formally grounded automated reasoning mechanism. We integrate the\nmechanism into an open-source security design tool and demonstrate its\napplication through an illustrative example driven by real-world challenges.\nThe automated reasoning mechanism allows system designers to identify\nvulnerabilities that are applicable to a specific system design, explicitly\nspecify vulnerability mitigation options, declare selected controls, and thus\nsystematically manage vulnerability postures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f62\u5f0f\u5316\u57fa\u7840\u7684\u81ea\u52a8\u5316\u63a8\u7406\u673a\u5236\uff0c\u7528\u4e8e\u7cfb\u7edf\u5316\u7ba1\u7406\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u6f0f\u6d1e\u6001\u52bf\uff0c\u5e76\u96c6\u6210\u5230\u5f00\u6e90\u5b89\u5168\u8bbe\u8ba1\u5de5\u5177\u4e2d\u3002", "motivation": "\u5f53\u524d\u6f0f\u6d1e\u7ba1\u7406\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u7cfb\u7edf\u8bbe\u8ba1\u6f0f\u6d1e\u6001\u52bf\u7684\u7cfb\u7edf\u5316\u63a8\u7406\u652f\u6301\uff0c\u9700\u6539\u8fdb\u4ee5\u6709\u6548\u7ba1\u7406\u6f0f\u6d1e\u548c\u8bbe\u8ba1\u5b89\u5168\u63a7\u5236\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u5f62\u5f0f\u5316\u57fa\u7840\u7684\u81ea\u52a8\u5316\u63a8\u7406\u673a\u5236\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u5f00\u6e90\u5b89\u5168\u8bbe\u8ba1\u5de5\u5177\u4e2d\u3002", "result": "\u8be5\u673a\u5236\u5e2e\u52a9\u8bbe\u8ba1\u5e08\u8bc6\u522b\u7279\u5b9a\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u6f0f\u6d1e\uff0c\u660e\u786e\u6307\u5b9a\u7f13\u89e3\u9009\u9879\uff0c\u5e76\u7cfb\u7edf\u5316\u7ba1\u7406\u6f0f\u6d1e\u6001\u52bf\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u52a8\u5316\u63a8\u7406\u673a\u5236\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u5e08\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u6f0f\u6d1e\u7ba1\u7406\u5de5\u5177\uff0c\u63d0\u5347\u4e86\u5b89\u5168\u63a7\u5236\u8bbe\u8ba1\u7684\u6548\u7387\u3002"}}
{"id": "2507.05613", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05613", "abs": "https://arxiv.org/abs/2507.05613", "authors": ["Lei Fan", "Fangxue Liu", "Cheng Chen"], "title": "Domain adaptation of large language models for geotechnical applications", "comment": null, "summary": "Recent developments in large language models (LLMs) are opening up new\nopportunities in geotechnical engineering and engineering geology. While\ngeneral-purpose LLMs possess broad capabilities, effective application in\ngeotechnics often requires domain-specific adaptation. Such tailored LLMs are\nincreasingly employed to streamline geotechnical workflows. This paper presents\nthe first survey of the adaptation and application of LLMs in geotechnical\nengineering. It outlines key methodologies for adaptation to geotechnical\ndomain, including prompt engineering, retrieval-augmented generation,\ndomain-adaptive pretraining, and fine-tuning. The survey examines the\nstate-of-the-art applications of geotechnical-adapted LLMs, including\ngeological interpretation, subsurface characterization, site planning, design\ncalculations, numerical modeling, safety and risk assessment, and educational\ntutoring. It also analyzes benefits and limitations of geotechnical-adapted\nLLMs, and identifies promising directions for future research in this\ninterdisciplinary discipline. The findings serve as a valuable resource for\npractitioners seeking to integrate LLMs into geotechnical practice, while also\nproviding a foundation to stimulate further investigation within the academic\ncommunity.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5ca9\u571f\u5de5\u7a0b\u4e2d\u7684\u9002\u5e94\u4e0e\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u5173\u952e\u65b9\u6cd5\uff08\u5982\u63d0\u793a\u5de5\u7a0b\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b49\uff09\u53ca\u524d\u6cbf\u5e94\u7528\uff08\u5982\u5730\u8d28\u89e3\u91ca\u3001\u98ce\u9669\u8bc4\u4f30\u7b49\uff09\uff0c\u5e76\u5206\u6790\u4e86\u5176\u4f18\u52bf\u4e0e\u5c40\u9650\u3002", "motivation": "\u968f\u7740LLMs\u7684\u53d1\u5c55\uff0c\u5176\u5728\u5ca9\u571f\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u9700\u9886\u57df\u7279\u5b9a\u9002\u5e94\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\uff0c\u4e3a\u5b9e\u8df5\u8005\u548c\u5b66\u672f\u754c\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u901a\u8fc7\u7efc\u8ff0\u65b9\u6cd5\uff0c\u603b\u7ed3\u4e86LLMs\u5728\u5ca9\u571f\u5de5\u7a0b\u4e2d\u7684\u9002\u5e94\u6280\u672f\uff08\u5982\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u3001\u5fae\u8c03\uff09\u548c\u5e94\u7528\u573a\u666f\uff08\u5982\u8bbe\u8ba1\u8ba1\u7b97\u3001\u6570\u503c\u5efa\u6a21\uff09\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLLMs\u5728\u5ca9\u571f\u5de5\u7a0b\u4e2d\u80fd\u663e\u8457\u63d0\u5347\u6548\u7387\uff0c\u4f46\u4e5f\u5b58\u5728\u9886\u57df\u77e5\u8bc6\u4e0d\u8db3\u7b49\u5c40\u9650\u3002\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u6539\u8fdb\u6a21\u578b\u9002\u5e94\u6027\u548c\u6269\u5c55\u5e94\u7528\u8303\u56f4\u3002", "conclusion": "\u672c\u6587\u4e3aLLMs\u5728\u5ca9\u571f\u5de5\u7a0b\u4e2d\u7684\u5b9e\u8df5\u548c\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u63a8\u52a8\u4e86\u8fd9\u4e00\u8de8\u5b66\u79d1\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.05872", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05872", "abs": "https://arxiv.org/abs/2507.05872", "authors": ["Berkay Kemal Balioglu", "Alireza Khodaie", "Mehmet Emre Gursoy"], "title": "LDP$^3$: An Extensible and Multi-Threaded Toolkit for Local Differential Privacy Protocols and Post-Processing Methods", "comment": null, "summary": "Local differential privacy (LDP) has become a prominent notion for\nprivacy-preserving data collection. While numerous LDP protocols and\npost-processing (PP) methods have been developed, selecting an optimal\ncombination under different privacy budgets and datasets remains a challenge.\nMoreover, the lack of a comprehensive and extensible LDP benchmarking toolkit\nraises difficulties in evaluating new protocols and PP methods. To address\nthese concerns, this paper presents LDP$^3$ (pronounced LDP-Cube), an\nopen-source, extensible, and multi-threaded toolkit for LDP researchers and\npractitioners. LDP$^3$ contains implementations of several LDP protocols, PP\nmethods, and utility metrics in a modular and extensible design. Its modular\ndesign enables developers to conveniently integrate new protocols and PP\nmethods. Furthermore, its multi-threaded nature enables significant reductions\nin execution times via parallelization. Experimental evaluations demonstrate\nthat: (i) using LDP$^3$ to select a good protocol and post-processing method\nsubstantially improves utility compared to a bad or random choice, and (ii) the\nmulti-threaded design of LDP$^3$ brings substantial benefits in terms of\nefficiency.", "AI": {"tldr": "LDP$^3$\u662f\u4e00\u4e2a\u5f00\u6e90\u3001\u53ef\u6269\u5c55\u7684\u591a\u7ebf\u7a0b\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u4f18\u5316\u672c\u5730\u5dee\u5206\u9690\u79c1\uff08LDP\uff09\u534f\u8bae\u548c\u540e\u5904\u7406\u65b9\u6cd5\u7684\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u6570\u636e\u6548\u7528\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3LDP\u534f\u8bae\u548c\u540e\u5904\u7406\u65b9\u6cd5\u9009\u62e9\u56f0\u96be\u4ee5\u53ca\u7f3a\u4e4f\u5168\u9762\u8bc4\u4f30\u5de5\u5177\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1LDP$^3$\u5de5\u5177\u5305\uff0c\u5305\u542b\u591a\u79cdLDP\u534f\u8bae\u3001\u540e\u5904\u7406\u65b9\u6cd5\u548c\u6548\u7528\u6307\u6807\uff0c\u91c7\u7528\u6a21\u5757\u5316\u548c\u591a\u7ebf\u7a0b\u8bbe\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLDP$^3$\u80fd\u663e\u8457\u63d0\u5347\u6570\u636e\u6548\u7528\uff0c\u5e76\u901a\u8fc7\u5e76\u884c\u5316\u5927\u5e45\u51cf\u5c11\u6267\u884c\u65f6\u95f4\u3002", "conclusion": "LDP$^3$\u4e3aLDP\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u5de5\u5177\uff0c\u4f18\u5316\u4e86\u534f\u8bae\u548c\u540e\u5904\u7406\u65b9\u6cd5\u7684\u9009\u62e9\u3002"}}
{"id": "2507.05624", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05624", "abs": "https://arxiv.org/abs/2507.05624", "authors": ["Wei Zhang", "Juan Chen", "Yanbo J. Wang", "En Zhu", "Xuan Yang", "Yiduo Wang"], "title": "ADMC: Attention-based Diffusion Model for Missing Modalities Feature Completion", "comment": null, "summary": "Multimodal emotion and intent recognition is essential for automated\nhuman-computer interaction, It aims to analyze users' speech, text, and visual\ninformation to predict their emotions or intent. One of the significant\nchallenges is that missing modalities due to sensor malfunctions or incomplete\ndata. Traditional methods that attempt to reconstruct missing information often\nsuffer from over-coupling and imprecise generation processes, leading to\nsuboptimal outcomes. To address these issues, we introduce an Attention-based\nDiffusion model for Missing Modalities feature Completion (ADMC). Our framework\nindependently trains feature extraction networks for each modality, preserving\ntheir unique characteristics and avoiding over-coupling. The Attention-based\nDiffusion Network (ADN) generates missing modality features that closely align\nwith authentic multimodal distribution, enhancing performance across all\nmissing-modality scenarios. Moreover, ADN's cross-modal generation offers\nimproved recognition even in full-modality contexts. Our approach achieves\nstate-of-the-art results on the IEMOCAP and MIntRec benchmarks, demonstrating\nits effectiveness in both missing and complete modality scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u6269\u6563\u6a21\u578b\uff08ADMC\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u548c\u610f\u56fe\u8bc6\u522b\u4e2d\u7f3a\u5931\u6a21\u6001\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u72ec\u7acb\u8bad\u7ec3\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u548c\u751f\u6210\u7f3a\u5931\u6a21\u6001\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u6570\u636e\u4e2d\u56e0\u4f20\u611f\u5668\u6545\u969c\u6216\u6570\u636e\u4e0d\u5b8c\u6574\u5bfc\u81f4\u7684\u7f3a\u5931\u6a21\u6001\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u8fc7\u8026\u5408\u548c\u751f\u6210\u4e0d\u7cbe\u786e\u7684\u7f3a\u9677\u3002", "method": "\u63d0\u51faADMC\u6846\u67b6\uff0c\u72ec\u7acb\u8bad\u7ec3\u5404\u6a21\u6001\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0c\u5229\u7528\u6ce8\u610f\u529b\u6269\u6563\u7f51\u7edc\uff08ADN\uff09\u751f\u6210\u4e0e\u771f\u5b9e\u591a\u6a21\u6001\u5206\u5e03\u4e00\u81f4\u7684\u7f3a\u5931\u7279\u5f81\u3002", "result": "\u5728IEMOCAP\u548cMIntRec\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u4f18\u7ed3\u679c\uff0c\u9002\u7528\u4e8e\u7f3a\u5931\u548c\u5b8c\u6574\u6a21\u6001\u573a\u666f\u3002", "conclusion": "ADMC\u901a\u8fc7\u907f\u514d\u8fc7\u8026\u5408\u548c\u7cbe\u786e\u751f\u6210\u7f3a\u5931\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u60c5\u611f\u548c\u610f\u56fe\u8bc6\u522b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.05875", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.05875", "abs": "https://arxiv.org/abs/2507.05875", "authors": ["Alireza Khodaie", "Berkay Kemal Balioglu", "Mehmet Emre Gursoy"], "title": "Post-Processing in Local Differential Privacy: An Extensive Evaluation and Benchmark Platform", "comment": null, "summary": "Local differential privacy (LDP) has recently gained prominence as a powerful\nparadigm for collecting and analyzing sensitive data from users' devices.\nHowever, the inherent perturbation added by LDP protocols reduces the utility\nof the collected data. To mitigate this issue, several post-processing (PP)\nmethods have been developed. Yet, the comparative performance of PP methods\nunder diverse settings remains underexplored. In this paper, we present an\nextensive benchmark comprising 6 popular LDP protocols, 7 PP methods, 4 utility\nmetrics, and 6 datasets to evaluate the behaviors and optimality of PP methods\nunder diverse conditions. Through extensive experiments, we show that while PP\ncan substantially improve utility when the privacy budget is small (i.e.,\nstrict privacy), its benefit diminishes as the privacy budget grows. Moreover,\nour findings reveal that the optimal PP method depends on multiple factors,\nincluding the choice of LDP protocol, privacy budget, data characteristics\n(such as distribution and domain size), and the specific utility metric. To\nadvance research in this area and assist practitioners in identifying the most\nsuitable PP method for their setting, we introduce LDP$^3$, an open-source\nbenchmark platform. LDP$^3$ contains all methods used in our experimental\nanalysis, and it is designed in a modular, extensible, and multi-threaded way\nfor future use and development.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u4e0d\u540c\u540e\u5904\u7406\u65b9\u6cd5\u5728\u672c\u5730\u5dee\u5206\u9690\u79c1\uff08LDP\uff09\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u540e\u5904\u7406\u5728\u5c0f\u9690\u79c1\u9884\u7b97\u65f6\u663e\u8457\u63d0\u5347\u6570\u636e\u6548\u7528\uff0c\u4f46\u5176\u6548\u679c\u968f\u9690\u79c1\u9884\u7b97\u589e\u52a0\u800c\u51cf\u5f31\u3002\u6700\u4f18\u540e\u5904\u7406\u65b9\u6cd5\u53d7\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\uff0c\u4f5c\u8005\u8fd8\u5f00\u53d1\u4e86\u5f00\u6e90\u5e73\u53f0LDP$^3$\u4ee5\u652f\u6301\u7814\u7a76\u548c\u5b9e\u8df5\u3002", "motivation": "\u672c\u5730\u5dee\u5206\u9690\u79c1\uff08LDP\uff09\u534f\u8bae\u5728\u4fdd\u62a4\u7528\u6237\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u6570\u636e\u6548\u7528\uff0c\u540e\u5904\u7406\u65b9\u6cd5\u65e8\u5728\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u4f46\u5176\u6027\u80fd\u6bd4\u8f83\u548c\u9002\u7528\u6761\u4ef6\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u7814\u7a76\u8bbe\u8ba1\u4e86\u5305\u542b6\u79cdLDP\u534f\u8bae\u30017\u79cd\u540e\u5904\u7406\u65b9\u6cd5\u30014\u79cd\u6548\u7528\u6307\u6807\u548c6\u4e2a\u6570\u636e\u96c6\u7684\u5e7f\u6cdb\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u540e\u5904\u7406\u65b9\u6cd5\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u540e\u5904\u7406\u5728\u5c0f\u9690\u79c1\u9884\u7b97\u65f6\u663e\u8457\u63d0\u5347\u6548\u7528\uff0c\u4f46\u968f\u7740\u9690\u79c1\u9884\u7b97\u589e\u52a0\u6548\u679c\u51cf\u5f31\u3002\u6700\u4f18\u540e\u5904\u7406\u65b9\u6cd5\u53d7LDP\u534f\u8bae\u3001\u9690\u79c1\u9884\u7b97\u3001\u6570\u636e\u7279\u5f81\u548c\u6548\u7528\u6307\u6807\u7b49\u591a\u56e0\u7d20\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u540e\u5904\u7406\u65b9\u6cd5\u7684\u9002\u7528\u6761\u4ef6\uff0c\u5e76\u5f00\u53d1\u4e86\u5f00\u6e90\u5e73\u53f0LDP$^3$\uff0c\u4e3a\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684\u5de5\u5177\u3002"}}
{"id": "2507.05629", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05629", "abs": "https://arxiv.org/abs/2507.05629", "authors": ["Yuan An", "John Liu", "Niyam Acharya", "Ruhma Hashmi"], "title": "Enhancing Student Learning with LLM-Generated Retrieval Practice Questions: An Empirical Study in Data Science Courses", "comment": null, "summary": "Retrieval practice is a well-established pedagogical technique known to\nsignificantly enhance student learning and knowledge retention. However,\ngenerating high-quality retrieval practice questions is often time-consuming\nand labor intensive for instructors, especially in rapidly evolving technical\nsubjects. Large Language Models (LLMs) offer the potential to automate this\nprocess by generating questions in response to prompts, yet the effectiveness\nof LLM-generated retrieval practice on student learning remains to be\nestablished. In this study, we conducted an empirical study involving two\ncollege-level data science courses, with approximately 60 students. We compared\nlearning outcomes during one week in which students received LLM-generated\nmultiple-choice retrieval practice questions to those from a week in which no\nsuch questions were provided. Results indicate that students exposed to\nLLM-generated retrieval practice achieved significantly higher knowledge\nretention, with an average accuracy of 89%, compared to 73% in the week without\nsuch practice. These findings suggest that LLM-generated retrieval questions\ncan effectively support student learning and may provide a scalable solution\nfor integrating retrieval practice into real-time teaching. However, despite\nthese encouraging outcomes and the potential time-saving benefits, cautions\nmust be taken, as the quality of LLM-generated questions can vary. Instructors\nmust still manually verify and revise the generated questions before releasing\nthem to students.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u751f\u6210\u68c0\u7d22\u7ec3\u4e60\u95ee\u9898\u5bf9\u5b66\u751f\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u7ed3\u679c\u663e\u793aLLM\u751f\u6210\u7684\u95ee\u9898\u663e\u8457\u63d0\u9ad8\u4e86\u5b66\u751f\u7684\u77e5\u8bc6\u4fdd\u7559\u7387\u3002", "motivation": "\u89e3\u51b3\u6559\u5e08\u624b\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u68c0\u7d22\u7ec3\u4e60\u95ee\u9898\u8017\u65f6\u8d39\u529b\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u5feb\u901f\u53d1\u5c55\u7684\u6280\u672f\u5b66\u79d1\u4e2d\u3002", "method": "\u901a\u8fc7\u4e24\u9879\u5927\u5b66\u6570\u636e\u79d1\u5b66\u8bfe\u7a0b\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u6bd4\u8f83\u5b66\u751f\u4f7f\u7528LLM\u751f\u6210\u7684\u591a\u9009\u9898\u4e0e\u672a\u4f7f\u7528\u65f6\u7684\u5b66\u4e60\u6548\u679c\u3002", "result": "\u4f7f\u7528LLM\u751f\u6210\u95ee\u9898\u7684\u5b66\u751f\u77e5\u8bc6\u4fdd\u7559\u7387\u663e\u8457\u63d0\u9ad8\uff0889% vs. 73%\uff09\u3002", "conclusion": "LLM\u751f\u6210\u7684\u68c0\u7d22\u7ec3\u4e60\u95ee\u9898\u80fd\u6709\u6548\u652f\u6301\u5b66\u4e60\uff0c\u4f46\u9700\u6559\u5e08\u624b\u52a8\u9a8c\u8bc1\u4ee5\u786e\u4fdd\u8d28\u91cf\u3002"}}
{"id": "2507.06008", "categories": ["cs.CR", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.06008", "abs": "https://arxiv.org/abs/2507.06008", "authors": ["Jungeun Lim", "Stephan A. Fahrenkrog-Petersen", "Xixi Lu", "Jan Mendling", "Minseok Song"], "title": "The Impact of Event Data Partitioning on Privacy-aware Process Discovery", "comment": null, "summary": "Information systems support the execution of business processes. The event\nlogs of these executions generally contain sensitive information about\ncustomers, patients, and employees. The corresponding privacy challenges can be\naddressed by anonymizing the event logs while still retaining utility for\nprocess discovery. However, trading off utility and privacy is difficult: the\nhigher the complexity of event log, the higher the loss of utility by\nanonymization. In this work, we propose a pipeline that combines anonymization\nand event data partitioning, where event abstraction is utilized for\npartitioning. By leveraging event abstraction, event logs can be segmented into\nmultiple parts, allowing each sub-log to be anonymized separately. This\npipeline preserves privacy while mitigating the loss of utility. To validate\nour approach, we study the impact of event partitioning on two anonymization\ntechniques using three real-world event logs and two process discovery\ntechniques. Our results demonstrate that event partitioning can bring\nimprovements in process discovery utility for directly-follows-based\nanonymization techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u533f\u540d\u5316\u548c\u4e8b\u4ef6\u6570\u636e\u5206\u533a\u7684\u7ba1\u9053\uff0c\u901a\u8fc7\u4e8b\u4ef6\u62bd\u8c61\u8fdb\u884c\u5206\u533a\uff0c\u4ee5\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u51cf\u5c11\u6548\u7528\u635f\u5931\u3002", "motivation": "\u4fe1\u606f\u7cfb\u7edf\u7684\u4e8b\u4ef6\u65e5\u5fd7\u5305\u542b\u654f\u611f\u4fe1\u606f\uff0c\u533f\u540d\u5316\u4f1a\u964d\u4f4e\u65e5\u5fd7\u7684\u6548\u7528\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u65e5\u5fd7\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ba1\u9053\uff0c\u7ed3\u5408\u533f\u540d\u5316\u548c\u4e8b\u4ef6\u6570\u636e\u5206\u533a\uff0c\u5229\u7528\u4e8b\u4ef6\u62bd\u8c61\u8fdb\u884c\u5206\u533a\uff0c\u5206\u522b\u533f\u540d\u5316\u5b50\u65e5\u5fd7\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u4e8b\u4ef6\u5206\u533a\u53ef\u4ee5\u63d0\u5347\u57fa\u4e8e\u76f4\u63a5\u8ddf\u968f\u5173\u7cfb\u7684\u533f\u540d\u5316\u6280\u672f\u7684\u6548\u7528\u3002", "conclusion": "\u4e8b\u4ef6\u5206\u533a\u65b9\u6cd5\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u6709\u6548\u51cf\u5c11\u4e86\u533f\u540d\u5316\u5bf9\u65e5\u5fd7\u6548\u7528\u7684\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2507.05638", "categories": ["cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.05638", "abs": "https://arxiv.org/abs/2507.05638", "authors": ["Litian Zhang", "Xiaoming Zhang", "Bingyu Yan", "Ziyi Zhou", "Bo Zhang", "Zhenyu Guan", "Xi Zhang", "Chaozhuo Li"], "title": "LLMs are Introvert", "comment": null, "summary": "The exponential growth of social media and generative AI has transformed\ninformation dissemination, fostering connectivity but also accelerating the\nspread of misinformation. Understanding information propagation dynamics and\ndeveloping effective control strategies is essential to mitigate harmful\ncontent. Traditional models, such as SIR, provide basic insights but\ninadequately capture the complexities of online interactions. Advanced methods,\nincluding attention mechanisms and graph neural networks, enhance accuracy but\ntypically overlook user psychology and behavioral dynamics. Large language\nmodels (LLMs), with their human-like reasoning, offer new potential for\nsimulating psychological aspects of information spread. We introduce an\nLLM-based simulation environment capturing agents' evolving attitudes,\nemotions, and responses. Initial experiments, however, revealed significant\ngaps between LLM-generated behaviors and authentic human dynamics, especially\nin stance detection and psychological realism. A detailed evaluation through\nSocial Information Processing Theory identified major discrepancies in\ngoal-setting and feedback evaluation, stemming from the lack of emotional\nprocessing in standard LLM training. To address these issues, we propose the\nSocial Information Processing-based Chain of Thought (SIP-CoT) mechanism\nenhanced by emotion-guided memory. This method improves the interpretation of\nsocial cues, personalization of goals, and evaluation of feedback. Experimental\nresults confirm that SIP-CoT-enhanced LLM agents more effectively process\nsocial information, demonstrating behaviors, attitudes, and emotions closer to\nreal human interactions. In summary, this research highlights critical\nlimitations in current LLM-based propagation simulations and demonstrates how\nintegrating SIP-CoT and emotional memory significantly enhances the social\nintelligence and realism of LLM agents.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6a21\u62df\u4fe1\u606f\u4f20\u64ad\u4e2d\u7684\u5fc3\u7406\u548c\u884c\u4e3a\u52a8\u6001\uff0c\u63d0\u51faSIP-CoT\u673a\u5236\u589e\u5f3aLLM\u7684\u793e\u4f1a\u667a\u80fd\u548c\u771f\u5b9e\u6027\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u548c\u751f\u6210\u5f0fAI\u7684\u5feb\u901f\u53d1\u5c55\u52a0\u5267\u4e86\u9519\u8bef\u4fe1\u606f\u7684\u4f20\u64ad\uff0c\u4f20\u7edf\u6a21\u578b\u65e0\u6cd5\u5145\u5206\u6355\u6349\u5728\u7ebf\u4e92\u52a8\u7684\u590d\u6742\u6027\uff0c\u800c\u73b0\u6709\u9ad8\u7ea7\u65b9\u6cd5\u53c8\u5ffd\u89c6\u4e86\u7528\u6237\u5fc3\u7406\u548c\u884c\u4e3a\u52a8\u6001\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u793e\u4f1a\u4fe1\u606f\u5904\u7406\u7406\u8bba\uff08SIP\uff09\u7684SIP-CoT\u673a\u5236\uff0c\u7ed3\u5408\u60c5\u611f\u5f15\u5bfc\u8bb0\u5fc6\uff0c\u6539\u8fdbLLM\u5bf9\u793e\u4ea4\u7ebf\u7d22\u7684\u89e3\u91ca\u3001\u76ee\u6807\u4e2a\u6027\u5316\u548c\u53cd\u9988\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSIP-CoT\u589e\u5f3a\u7684LLM\u4ee3\u7406\u80fd\u66f4\u6709\u6548\u5730\u5904\u7406\u793e\u4f1a\u4fe1\u606f\uff0c\u884c\u4e3a\u3001\u6001\u5ea6\u548c\u60c5\u611f\u66f4\u63a5\u8fd1\u771f\u5b9e\u4eba\u7c7b\u4e92\u52a8\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524dLLM\u6a21\u62df\u4f20\u64ad\u7684\u5c40\u9650\u6027\uff0c\u5e76\u8bc1\u660eSIP-CoT\u548c\u60c5\u611f\u8bb0\u5fc6\u7684\u6574\u5408\u80fd\u663e\u8457\u63d0\u5347LLM\u4ee3\u7406\u7684\u793e\u4f1a\u667a\u80fd\u548c\u771f\u5b9e\u6027\u3002"}}
{"id": "2507.06039", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.06039", "abs": "https://arxiv.org/abs/2507.06039", "authors": ["Oleksii Oleksenko", "Flavien Solt", "C\u00e9dric Fournet", "Jana Hofmann", "Boris K\u00f6pf", "Stavros Volos"], "title": "Enter, Exit, Page Fault, Leak: Testing Isolation Boundaries for Microarchitectural Leaks", "comment": "Accepted at IEEE SP 2025; delayed due to embargo; to appear at IEEE\n  SP 2026", "summary": "CPUs provide isolation mechanisms like virtualization and privilege levels to\nprotect software. Yet these focus on architectural isolation while typically\noverlooking microarchitectural side channels, exemplified by Meltdown and\nForeshadow. Software must therefore supplement architectural defenses with\nad-hoc microarchitectural patches, which are constantly evolving as new attacks\nemerge and defenses are proposed. Such reactive approach makes ensuring\ncomplete isolation a daunting task, and leaves room for errors and oversights.\n  We address this problem by developing a tool that stress tests\nmicroarchitectural isolation between security domains such as virtual machines,\nkernel, and processes, with the goal of detecting flaws in the isolation\nboundaries. The tool extends model-based relational testing (MRT) methodology\nto enable detection of cross-domain information leakage. We design a new test\ncase generator and execution sandbox to handle multi-domain execution, new\nleakage models to encode expected leaks, and new analysis techniques to manage\nnondeterminism.\n  We use this tool to perform an in-depth testing campaign on six x86-64 CPUs\nfor leakage across different isolation boundaries. The testing campaign exposed\nfour new leaks and corroborated numerous known ones, with only two false\npositives throughout the entire campaign. These results show critical gaps in\ncurrent isolation mechanisms as well as validate a robust methodology for\ndetecting microarchitectural flaws. As such, this approach enables a shift from\nreactive patching to proactive security validation in processor design.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u5de5\u5177\uff0c\u7528\u4e8e\u6d4b\u8bd5\u5fae\u67b6\u6784\u9694\u79bb\u7f3a\u9677\uff0c\u53d1\u73b0\u4e86\u65b0\u7684\u6f0f\u6d1e\u5e76\u9a8c\u8bc1\u4e86\u5df2\u77e5\u6f0f\u6d1e\uff0c\u4e3a\u5904\u7406\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e3b\u52a8\u5b89\u5168\u9a8c\u8bc1\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709CPU\u9694\u79bb\u673a\u5236\u4e3b\u8981\u5173\u6ce8\u67b6\u6784\u5c42\u9762\uff0c\u5ffd\u89c6\u4e86\u5fae\u67b6\u6784\u4fa7\u4fe1\u9053\u653b\u51fb\uff08\u5982Meltdown\u548cForeshadow\uff09\uff0c\u5bfc\u81f4\u8f6f\u4ef6\u9700\u8981\u4e0d\u65ad\u4fee\u8865\u6f0f\u6d1e\uff0c\u96be\u4ee5\u786e\u4fdd\u5b8c\u5168\u9694\u79bb\u3002", "method": "\u6269\u5c55\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u5173\u7cfb\u6d4b\u8bd5\uff08MRT\uff09\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u4e86\u65b0\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5668\u3001\u6267\u884c\u6c99\u7bb1\u3001\u6cc4\u6f0f\u6a21\u578b\u548c\u5206\u6790\u6280\u672f\uff0c\u4ee5\u68c0\u6d4b\u8de8\u57df\u4fe1\u606f\u6cc4\u6f0f\u3002", "result": "\u5728\u516d\u6b3ex86-64 CPU\u4e0a\u6d4b\u8bd5\uff0c\u53d1\u73b0\u4e86\u56db\u4e2a\u65b0\u6f0f\u6d1e\u5e76\u9a8c\u8bc1\u4e86\u591a\u4e2a\u5df2\u77e5\u6f0f\u6d1e\uff0c\u4ec5\u6709\u4e24\u4e2a\u8bef\u62a5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\u5f53\u524d\u9694\u79bb\u673a\u5236\u7684\u7f3a\u9677\uff0c\u5e76\u4e3a\u5904\u7406\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4ece\u88ab\u52a8\u4fee\u8865\u8f6c\u5411\u4e3b\u52a8\u5b89\u5168\u9a8c\u8bc1\u7684\u9014\u5f84\u3002"}}
{"id": "2507.05651", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05651", "abs": "https://arxiv.org/abs/2507.05651", "authors": ["Tianxing Wu", "Lizhe Cao", "Shuang Wang", "Jiming Wang", "Shutong Zhu", "Yerong Wu", "Yuqing Feng"], "title": "City-Level Foreign Direct Investment Prediction with Tabular Learning on Judicial Data", "comment": "9 pages, accepted by IJCAI 2025", "summary": "To advance the United Nations Sustainable Development Goal on promoting\nsustained, inclusive, and sustainable economic growth, foreign direct\ninvestment (FDI) plays a crucial role in catalyzing economic expansion and\nfostering innovation. Precise city-level FDI prediction is quite important for\nlocal government and is commonly studied based on economic data (e.g., GDP).\nHowever, such economic data could be prone to manipulation, making predictions\nless reliable. To address this issue, we try to leverage large-scale judicial\ndata which reflects judicial performance influencing local investment security\nand returns, for city-level FDI prediction. Based on this, we first build an\nindex system for the evaluation of judicial performance over twelve million\npublicly available adjudication documents according to which a tabular dataset\nis reformulated. We then propose a new Tabular Learning method on Judicial Data\n(TLJD) for city-level FDI prediction. TLJD integrates row data and column data\nin our built tabular dataset for judicial performance indicator encoding, and\nutilizes a mixture of experts model to adjust the weights of different\nindicators considering regional variations. To validate the effectiveness of\nTLJD, we design cross-city and cross-time tasks for city-level FDI predictions.\nExtensive experiments on both tasks demonstrate the superiority of TLJD (reach\nto at least 0.92 R2) over the other ten state-of-the-art baselines in different\nevaluation metrics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53f8\u6cd5\u6570\u636e\u7684\u8868\u683c\u5b66\u4e60\u65b9\u6cd5\uff08TLJD\uff09\uff0c\u7528\u4e8e\u57ce\u5e02\u7ea7\u5916\u56fd\u76f4\u63a5\u6295\u8d44\uff08FDI\uff09\u9884\u6d4b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7ecf\u6d4e\u6570\u636e\u53ef\u80fd\u88ab\u64cd\u7eb5\u7684\u95ee\u9898\u3002", "motivation": "\u4e3a\u4fc3\u8fdb\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\uff0cFDI\u5bf9\u7ecf\u6d4e\u589e\u957f\u548c\u521b\u65b0\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u57fa\u4e8e\u7ecf\u6d4e\u6570\u636e\u7684\u9884\u6d4b\u53ef\u80fd\u4e0d\u53ef\u9760\u3002", "method": "\u5229\u7528\u5927\u89c4\u6a21\u53f8\u6cd5\u6570\u636e\u6784\u5efa\u53f8\u6cd5\u7ee9\u6548\u8bc4\u4f30\u6307\u6807\u4f53\u7cfb\uff0c\u5e76\u63d0\u51faTLJD\u65b9\u6cd5\uff0c\u7ed3\u5408\u884c\u6570\u636e\u548c\u5217\u6570\u636e\u8fdb\u884c\u6307\u6807\u7f16\u7801\uff0c\u4f7f\u7528\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u8c03\u6574\u6743\u91cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTLJD\u5728\u8de8\u57ce\u5e02\u548c\u8de8\u65f6\u95f4\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5176\u4ed6\u5341\u79cd\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0cR2\u8fbe\u5230\u81f3\u5c110.92\u3002", "conclusion": "TLJD\u901a\u8fc7\u53f8\u6cd5\u6570\u636e\u63d0\u5347\u4e86FDI\u9884\u6d4b\u7684\u53ef\u9760\u6027\uff0c\u4e3a\u5730\u65b9\u653f\u5e9c\u51b3\u7b56\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2507.06043", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06043", "abs": "https://arxiv.org/abs/2507.06043", "authors": ["Xiaohu Li", "Yunfeng Ning", "Zepeng Bao", "Mayi Xu", "Jianhao Chen", "Tieyun Qian"], "title": "CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations", "comment": null, "summary": "Security alignment enables the Large Language Model (LLM) to gain the\nprotection against malicious queries, but various jailbreak attack methods\nreveal the vulnerability of this security mechanism. Previous studies have\nisolated LLM jailbreak attacks and defenses. We analyze the security protection\nmechanism of the LLM, and propose a framework that combines attack and defense.\nOur method is based on the linearly separable property of LLM intermediate\nlayer embedding, as well as the essence of jailbreak attack, which aims to\nembed harmful problems and transfer them to the safe area. We utilize\ngenerative adversarial network (GAN) to learn the security judgment boundary\ninside the LLM to achieve efficient jailbreak attack and defense. The\nexperimental results indicate that our method achieves an average jailbreak\nsuccess rate of 88.85\\% across three popular LLMs, while the defense success\nrate on the state-of-the-art jailbreak dataset reaches an average of 84.17\\%.\nThis not only validates the effectiveness of our approach but also sheds light\non the internal security mechanisms of LLMs, offering new insights for\nenhancing model security The code and data are available at\nhttps://github.com/NLPGM/CAVGAN.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u653b\u51fb\u4e0e\u9632\u5fa1\u7684\u6846\u67b6\uff0c\u5229\u7528GAN\u5b66\u4e60LLM\u5185\u90e8\u7684\u5b89\u5168\u5224\u65ad\u8fb9\u754c\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8d8a\u72f1\u653b\u51fb\u4e0e\u9632\u5fa1\u3002", "motivation": "\u7814\u7a76LLM\u7684\u5b89\u5168\u4fdd\u62a4\u673a\u5236\uff0c\u63ed\u793a\u5176\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u653b\u51fb\u4e0e\u9632\u5fa1\u7684\u65b9\u6cd5\u4ee5\u589e\u5f3a\u6a21\u578b\u5b89\u5168\u6027\u3002", "method": "\u57fa\u4e8eLLM\u4e2d\u95f4\u5c42\u5d4c\u5165\u7684\u7ebf\u6027\u53ef\u5206\u6027\uff0c\u5229\u7528GAN\u5b66\u4e60\u5b89\u5168\u5224\u65ad\u8fb9\u754c\uff0c\u5b9e\u73b0\u653b\u51fb\u4e0e\u9632\u5fa1\u7684\u7ed3\u5408\u3002", "result": "\u5728\u4e09\u79cd\u6d41\u884cLLM\u4e0a\u5e73\u5747\u8d8a\u72f1\u6210\u529f\u7387\u4e3a88.85%\uff0c\u9632\u5fa1\u6210\u529f\u7387\u4e3a84.17%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u63ed\u793a\u4e86LLM\u5185\u90e8\u5b89\u5168\u673a\u5236\uff0c\u4e3a\u589e\u5f3a\u6a21\u578b\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.05716", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05716", "abs": "https://arxiv.org/abs/2507.05716", "authors": ["Dipayan Sengupta", "Saumya Panda"], "title": "Divergent Realities: A Comparative Analysis of Human Expert vs. Artificial Intelligence Based Generation and Evaluation of Treatment Plans in Dermatology", "comment": "13 pages, 3 tables", "summary": "Background: Evaluating AI-generated treatment plans is a key challenge as AI\nexpands beyond diagnostics, especially with new reasoning models. This study\ncompares plans from human experts and two AI models (a generalist and a\nreasoner), assessed by both human peers and a superior AI judge.\n  Methods: Ten dermatologists, a generalist AI (GPT-4o), and a reasoning AI\n(o3) generated treatment plans for five complex dermatology cases. The\nanonymized, normalized plans were scored in two phases: 1) by the ten human\nexperts, and 2) by a superior AI judge (Gemini 2.5 Pro) using an identical\nrubric.\n  Results: A profound 'evaluator effect' was observed. Human experts scored\npeer-generated plans significantly higher than AI plans (mean 7.62 vs. 7.16;\np=0.0313), ranking GPT-4o 6th (mean 7.38) and the reasoning model, o3, 11th\n(mean 6.97). Conversely, the AI judge produced a complete inversion, scoring AI\nplans significantly higher than human plans (mean 7.75 vs. 6.79; p=0.0313). It\nranked o3 1st (mean 8.20) and GPT-4o 2nd, placing all human experts lower.\n  Conclusions: The perceived quality of a clinical plan is fundamentally\ndependent on the evaluator's nature. An advanced reasoning AI, ranked poorly by\nhuman experts, was judged as superior by a sophisticated AI, revealing a deep\ngap between experience-based clinical heuristics and data-driven algorithmic\nlogic. This paradox presents a critical challenge for AI integration,\nsuggesting the future requires synergistic, explainable human-AI systems that\nbridge this reasoning gap to augment clinical care.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4eba\u7c7b\u4e13\u5bb6\u4e0e\u4e24\u79cdAI\u6a21\u578b\uff08\u901a\u7528\u578b\u548c\u63a8\u7406\u578b\uff09\u751f\u6210\u7684\u76ae\u80a4\u75c5\u6cbb\u7597\u65b9\u6848\uff0c\u53d1\u73b0\u8bc4\u4f30\u7ed3\u679c\u56e0\u8bc4\u4f30\u8005\uff08\u4eba\u7c7b\u6216AI\uff09\u800c\u5f02\uff0c\u63ed\u793a\u4e86\u4e34\u5e8a\u7ecf\u9a8c\u4e0e\u7b97\u6cd5\u903b\u8f91\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u8bc4\u4f30AI\u751f\u6210\u7684\u6cbb\u7597\u65b9\u6848\u8d28\u91cf\uff0c\u5c24\u5176\u662f\u5728AI\u6269\u5c55\u5230\u8bca\u65ad\u4e4b\u5916\u7684\u9886\u57df\u65f6\uff0c\u63a2\u7d22\u4eba\u7c7b\u4e0eAI\u8bc4\u4f30\u7684\u5dee\u5f02\u3002", "method": "10\u540d\u76ae\u80a4\u79d1\u533b\u751f\u3001\u901a\u7528AI\uff08GPT-4o\uff09\u548c\u63a8\u7406AI\uff08o3\uff09\u4e3a5\u4e2a\u590d\u6742\u76ae\u80a4\u75c5\u6848\u4f8b\u751f\u6210\u6cbb\u7597\u65b9\u6848\uff0c\u533f\u540d\u540e\u7531\u4eba\u7c7b\u4e13\u5bb6\u548c\u9ad8\u7ea7AI\uff08Gemini 2.5 Pro\uff09\u8bc4\u5206\u3002", "result": "\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u5206\u663e\u8457\u9ad8\u4e8eAI\u65b9\u6848\uff0c\u800cAI\u8bc4\u59d4\u5219\u76f8\u53cd\uff0c\u63a8\u7406AI\uff08o3\uff09\u5728AI\u8bc4\u59d4\u4e2d\u6392\u540d\u7b2c\u4e00\u3002", "conclusion": "\u6cbb\u7597\u65b9\u6848\u8d28\u91cf\u611f\u77e5\u53d6\u51b3\u4e8e\u8bc4\u4f30\u8005\u6027\u8d28\uff0c\u672a\u6765\u9700\u5f00\u53d1\u53ef\u89e3\u91ca\u7684\u4eba\u673a\u534f\u540c\u7cfb\u7edf\u4ee5\u5f25\u5408\u7406\u5ff5\u5dee\u8ddd\u3002"}}
{"id": "2507.06064", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.06064", "abs": "https://arxiv.org/abs/2507.06064", "authors": ["Oleksandr Kurbatov", "Kyrylo Baybula", "Yaroslava Chopa", "Sergey Kozlov", "Oleg Komendant", "Illia Dovgopoly", "Dmitrii Kurbatov", "Zakhar Naumets", "Yulia Artikulova", "Pavel Kravchenko", "Volodymyr Dubinin", "Lasha Antadze", "Yaroslav Panasenko", "Mykhailo Velykodnyi"], "title": "Wrapless: The trustless lending protocol on top of Bitcoin", "comment": null, "summary": "This paper presents Wrapless -- a lending protocol that enables the\ncollateralization of bitcoins without requiring a trusted wrapping mechanism.\nThe protocol facilitates a \"loan channel\" on the Bitcoin blockchain, allowing\nbitcoins to be locked as collateral for loans issued on any blockchain that\nsupports Turing-complete smart contracts. The protocol is designed in a way\nthat makes it economically irrational for each involved party to manipulate the\nloan rules. There is still a significant research area to bring the protocol\ncloser to traditional AMM financial instruments.", "AI": {"tldr": "Wrapless\u662f\u4e00\u79cd\u501f\u8d37\u534f\u8bae\uff0c\u5141\u8bb8\u6bd4\u7279\u5e01\u4f5c\u4e3a\u62b5\u62bc\u54c1\uff0c\u65e0\u9700\u4f9d\u8d56\u53ef\u4fe1\u7684\u5305\u88c5\u673a\u5236\u3002", "motivation": "\u89e3\u51b3\u6bd4\u7279\u5e01\u4f5c\u4e3a\u62b5\u62bc\u54c1\u65f6\u5bf9\u53ef\u4fe1\u5305\u88c5\u673a\u5236\u7684\u4f9d\u8d56\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6bd4\u7279\u5e01\u533a\u5757\u94fe\u4e0a\u7684\u201c\u8d37\u6b3e\u901a\u9053\u201d\u5b9e\u73b0\uff0c\u652f\u6301\u56fe\u7075\u5b8c\u5907\u667a\u80fd\u5408\u7ea6\u7684\u533a\u5757\u94fe\u5747\u53ef\u4f7f\u7528\u3002", "result": "\u534f\u8bae\u8bbe\u8ba1\u786e\u4fdd\u5404\u65b9\u64cd\u7eb5\u8d37\u6b3e\u89c4\u5219\u5728\u7ecf\u6d4e\u4e0a\u4e0d\u5408\u7406\u3002", "conclusion": "\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u4f7f\u5176\u66f4\u63a5\u8fd1\u4f20\u7edfAMM\u91d1\u878d\u5de5\u5177\u3002"}}
{"id": "2507.05755", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05755", "abs": "https://arxiv.org/abs/2507.05755", "authors": ["Lukas Kuhn", "Florian Buettner"], "title": "An autonomous agent for auditing and improving the reliability of clinical AI models", "comment": null, "summary": "The deployment of AI models in clinical practice faces a critical challenge:\nmodels achieving expert-level performance on benchmarks can fail\ncatastrophically when confronted with real-world variations in medical imaging.\nMinor shifts in scanner hardware, lighting or demographics can erode accuracy,\nbut currently reliability auditing to identify such catastrophic failure cases\nbefore deployment is a bespoke and time-consuming process. Practitioners lack\naccessible and interpretable tools to expose and repair hidden failure modes.\nHere we introduce ModelAuditor, a self-reflective agent that converses with\nusers, selects task-specific metrics, and simulates context-dependent,\nclinically relevant distribution shifts. ModelAuditor then generates\ninterpretable reports explaining how much performance likely degrades during\ndeployment, discussing specific likely failure modes and identifying root\ncauses and mitigation strategies. Our comprehensive evaluation across three\nreal-world clinical scenarios - inter-institutional variation in\nhistopathology, demographic shifts in dermatology, and equipment heterogeneity\nin chest radiography - demonstrates that ModelAuditor is able correctly\nidentify context-specific failure modes of state-of-the-art models such as the\nestablished SIIM-ISIC melanoma classifier. Its targeted recommendations recover\n15-25% of performance lost under real-world distribution shift, substantially\noutperforming both baseline models and state-of-the-art augmentation methods.\nThese improvements are achieved through a multi-agent architecture and execute\non consumer hardware in under 10 minutes, costing less than US$0.50 per audit.", "AI": {"tldr": "ModelAuditor\u662f\u4e00\u4e2a\u81ea\u7701\u4ee3\u7406\uff0c\u901a\u8fc7\u5bf9\u8bdd\u548c\u6a21\u62df\u4e34\u5e8a\u76f8\u5173\u5206\u5e03\u53d8\u5316\uff0c\u8bc6\u522bAI\u6a21\u578b\u5728\u771f\u5b9e\u533b\u7597\u573a\u666f\u4e2d\u7684\u6f5c\u5728\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u62a5\u544a\u548c\u6539\u8fdb\u7b56\u7565\u3002", "motivation": "AI\u6a21\u578b\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u53ef\u80fd\u56e0\u786c\u4ef6\u3001\u5149\u7167\u6216\u4eba\u53e3\u7edf\u8ba1\u53d8\u5316\u800c\u5931\u6548\uff0c\u76ee\u524d\u7f3a\u4e4f\u9ad8\u6548\u5de5\u5177\u8fdb\u884c\u53ef\u9760\u6027\u5ba1\u8ba1\u3002", "method": "ModelAuditor\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u9009\u62e9\u4efb\u52a1\u7279\u5b9a\u6307\u6807\uff0c\u6a21\u62df\u5206\u5e03\u53d8\u5316\uff0c\u5e76\u751f\u6210\u62a5\u544a\u3002", "result": "\u5728\u4e09\u79cd\u4e34\u5e8a\u573a\u666f\u4e2d\uff0cModelAuditor\u6210\u529f\u8bc6\u522b\u5931\u8d25\u6a21\u5f0f\uff0c\u6027\u80fd\u6062\u590d15-25%\uff0c\u6210\u672c\u4f4e\u4e8e0.5\u7f8e\u5143\u3002", "conclusion": "ModelAuditor\u4e3a\u4e34\u5e8aAI\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u53ef\u9760\u6027\u5ba1\u8ba1\u5de5\u5177\u3002"}}
{"id": "2507.06092", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06092", "abs": "https://arxiv.org/abs/2507.06092", "authors": ["Shravya Kanchi", "Neal Mangaokar", "Aravind Cheruvu", "Sifat Muhammad Abdullah", "Shirin Nilizadeh", "Atul Prakash", "Bimal Viswanath"], "title": "Taming Data Challenges in ML-based Security Tasks: Lessons from Integrating Generative AI", "comment": null, "summary": "Machine learning-based supervised classifiers are widely used for security\ntasks, and their improvement has been largely focused on algorithmic\nadvancements. We argue that data challenges that negatively impact the\nperformance of these classifiers have received limited attention. We address\nthe following research question: Can developments in Generative AI (GenAI)\naddress these data challenges and improve classifier performance? We propose\naugmenting training datasets with synthetic data generated using GenAI\ntechniques to improve classifier generalization. We evaluate this approach\nacross 7 diverse security tasks using 6 state-of-the-art GenAI methods and\nintroduce a novel GenAI scheme called Nimai that enables highly controlled data\nsynthesis. We find that GenAI techniques can significantly improve the\nperformance of security classifiers, achieving improvements of up to 32.6% even\nin severely data-constrained settings (only ~180 training samples).\nFurthermore, we demonstrate that GenAI can facilitate rapid adaptation to\nconcept drift post-deployment, requiring minimal labeling in the adjustment\nprocess. Despite successes, our study finds that some GenAI schemes struggle to\ninitialize (train and produce data) on certain security tasks. We also identify\ncharacteristics of specific tasks, such as noisy labels, overlapping class\ndistributions, and sparse feature vectors, which hinder performance boost using\nGenAI. We believe that our study will drive the development of future GenAI\ntools designed for security tasks.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5229\u7528\u751f\u6210\u5f0fAI\uff08GenAI\uff09\u751f\u6210\u5408\u6210\u6570\u636e\u4ee5\u89e3\u51b3\u5b89\u5168\u4efb\u52a1\u4e2d\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u7684\u6570\u636e\u6311\u6218\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u7b97\u6cd5\u6539\u8fdb\uff0c\u800c\u6570\u636e\u6311\u6218\u5bf9\u5206\u7c7b\u5668\u6027\u80fd\u7684\u8d1f\u9762\u5f71\u54cd\u672a\u5f97\u5230\u8db3\u591f\u91cd\u89c6\u3002", "method": "\u63d0\u51fa\u901a\u8fc7GenAI\u751f\u6210\u5408\u6210\u6570\u636e\u589e\u5f3a\u8bad\u7ec3\u96c6\uff0c\u5e76\u57287\u4e2a\u5b89\u5168\u4efb\u52a1\u4e2d\u8bc4\u4f30\u4e866\u79cdGenAI\u65b9\u6cd5\u53ca\u65b0\u65b9\u6848Nimai\u3002", "result": "GenAI\u663e\u8457\u63d0\u5347\u5206\u7c7b\u5668\u6027\u80fd\uff08\u6700\u9ad832.6%\uff09\uff0c\u5e76\u652f\u6301\u5feb\u901f\u9002\u5e94\u6982\u5ff5\u6f02\u79fb\uff0c\u4f46\u67d0\u4e9b\u4efb\u52a1\u4e2dGenAI\u521d\u59cb\u5316\u56f0\u96be\u3002", "conclusion": "GenAI\u5728\u5b89\u5168\u4efb\u52a1\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u9700\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u7279\u6027\u4f18\u5316\u5de5\u5177\u5f00\u53d1\u3002"}}
{"id": "2507.05765", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05765", "abs": "https://arxiv.org/abs/2507.05765", "authors": ["Bruno Jammes", "Edgar Hernando Sep\u00falveda-Oviedo", "Corinne Alonso"], "title": "Real-time monitoring of the SoH of lithium-ion batteries", "comment": "in French language, Symposium de G{\\'e}nie {\\'E}lectrique SGE 2025,\n  Jul 2025, Toulouse, France", "summary": "Real-time monitoring of the state of health (SoH) of batteries remains a\nmajor challenge, particularly in microgrids where operational constraints limit\nthe use of traditional methods. As part of the 4BLife project, we propose an\ninnovative method based on the analysis of a discharge pulse at the end of the\ncharge phase. The parameters of the equivalent electrical model describing the\nvoltage evolution across the battery terminals during this current pulse are\nthen used to estimate the SoH. Based on the experimental data acquired so far,\nthe initial results demonstrate the relevance of the proposed approach. After\ntraining using the parameters of two batteries with a capacity degradation of\naround 85%, we successfully predicted the degradation of two other batteries,\ncycled down to approximately 90% SoH, with a mean absolute error of around 1%\nin the worst case, and an explainability score of the estimator close to 0.9.\nIf these performances are confirmed, this method can be easily integrated into\nbattery management systems (BMS) and paves the way for optimized battery\nmanagement under continuous operation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5145\u7535\u672b\u6bb5\u653e\u7535\u8109\u51b2\u5206\u6790\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u76d1\u6d4b\u7535\u6c60\u5065\u5eb7\u72b6\u6001\uff08SoH\uff09\uff0c\u5728\u5fae\u7535\u7f51\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u5fae\u7535\u7f51\u4e2d\u53d7\u9650\uff0c\u9700\u5f00\u53d1\u65b0\u65b9\u6cd5\u5b9e\u65f6\u76d1\u6d4b\u7535\u6c60SoH\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5145\u7535\u672b\u6bb5\u7684\u653e\u7535\u8109\u51b2\uff0c\u5229\u7528\u7b49\u6548\u7535\u8def\u6a21\u578b\u53c2\u6570\u4f30\u8ba1SoH\u3002", "result": "\u5b9e\u9a8c\u6570\u636e\u663e\u793a\uff0c\u9884\u6d4bSoH\u7684\u8bef\u5dee\u7ea61%\uff0c\u89e3\u91ca\u6027\u8bc4\u5206\u63a5\u8fd10.9\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u671b\u96c6\u6210\u5230\u7535\u6c60\u7ba1\u7406\u7cfb\u7edf\uff08BMS\uff09\u4e2d\uff0c\u4f18\u5316\u6301\u7eed\u8fd0\u884c\u4e0b\u7684\u7535\u6c60\u7ba1\u7406\u3002"}}
{"id": "2507.06112", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.06112", "abs": "https://arxiv.org/abs/2507.06112", "authors": ["Antoine Geimer", "Clementine Maurice"], "title": "Fun with flags: How Compilers Break and Fix Constant-Time Code", "comment": "11 pages", "summary": "Developers rely on constant-time programming to prevent timing side-channel\nattacks. But these efforts can be undone by compilers, whose optimizations may\nsilently reintroduce leaks. While recent works have measured the extent of such\nleakage, they leave developers without actionable insights: which optimization\npasses are responsible, and how to disable them without modifying the compiler\nremains unclear.\n  In this paper, we conduct a qualitative analysis of how compiler\noptimizations break constant-time code. We construct a dataset of\ncompiler-introduced constant-time violations and analyze the internals of two\nwidely used compilers, GCC and LLVM, to identify the specific optimization\npasses responsible. Our key insight is that a small set of passes are at the\nroot of most leaks. To the best of our knowledge, we are also the first to\ncharacterize how the interactions between these passes contribute to leakage.\nBased on this analysis, we propose an original and practical mitigation that\nrequires no source code modification or custom compiler: disabling selected\noptimization passes via compiler flags. We show that this approach\nsignificantly reduces leakage with minimal performance overhead, offering an\nimmediately deployable defense for developers.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u7f16\u8bd1\u5668\u4f18\u5316\u5982\u4f55\u7834\u574f\u5e38\u6570\u65f6\u95f4\u7f16\u7a0b\uff0c\u8bc6\u522b\u4e86\u5bfc\u81f4\u6cc4\u6f0f\u7684\u5173\u952e\u4f18\u5316\u6b65\u9aa4\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u4fee\u6539\u7f16\u8bd1\u5668\u6216\u6e90\u4ee3\u7801\u7684\u7f13\u89e3\u65b9\u6cd5\u3002", "motivation": "\u5f00\u53d1\u8005\u4f9d\u8d56\u5e38\u6570\u65f6\u95f4\u7f16\u7a0b\u9632\u6b62\u65f6\u5e8f\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u4f46\u7f16\u8bd1\u5668\u4f18\u5316\u53ef\u80fd\u91cd\u65b0\u5f15\u5165\u6cc4\u6f0f\uff0c\u76ee\u524d\u7f3a\u4e4f\u5177\u4f53\u53ef\u64cd\u4f5c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6784\u5efa\u7f16\u8bd1\u5668\u5f15\u5165\u7684\u5e38\u6570\u65f6\u95f4\u8fdd\u89c4\u6570\u636e\u96c6\uff0c\u5206\u6790GCC\u548cLLVM\u7684\u4f18\u5316\u6b65\u9aa4\uff0c\u8bc6\u522b\u4e3b\u8981\u6cc4\u6f0f\u6765\u6e90\u3002", "result": "\u53d1\u73b0\u5c11\u6570\u4f18\u5316\u6b65\u9aa4\u662f\u6cc4\u6f0f\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u7f16\u8bd1\u5668\u6807\u5fd7\u7981\u7528\u8fd9\u4e9b\u6b65\u9aa4\u7684\u7f13\u89e3\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u6cc4\u6f0f\u4e14\u6027\u80fd\u5f00\u9500\u5c0f\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u53ef\u76f4\u63a5\u90e8\u7f72\u7684\u9632\u5fa1\u65b9\u6848\u3002"}}
{"id": "2507.05791", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05791", "abs": "https://arxiv.org/abs/2507.05791", "authors": ["Yan Yang", "Dongxu Li", "Yutong Dai", "Yuhao Yang", "Ziyang Luo", "Zirui Zhao", "Zhiyuan Hu", "Junzhe Huang", "Amrita Saha", "Zeyuan Chen", "Ran Xu", "Liyuan Pan", "Caiming Xiong", "Junnan Li"], "title": "GTA1: GUI Test-time Scaling Agent", "comment": null, "summary": "Graphical user interface (GUI) agents autonomously operate across platforms\n(e.g., Linux) to complete tasks by interacting with visual elements.\nSpecifically, a user instruction is decomposed into a sequence of action\nproposals, each corresponding to an interaction with the GUI. After each\naction, the agent observes the updated GUI environment to plan the next step.\nHowever, two main challenges arise: i) resolving ambiguity in task planning\n(i.e., the action proposal sequence), where selecting an appropriate plan is\nnon-trivial, as many valid ones may exist; ii) accurately grounding actions in\ncomplex and high-resolution interfaces, i.e., precisely interacting with visual\ntargets.\n  This paper investigates the two aforementioned challenges with our GUI\nTest-time Scaling Agent, namely GTA1. First, to select the most appropriate\naction proposal, we introduce a test-time scaling method. At each step, we\nsample multiple candidate action proposals and leverage a judge model to\nevaluate and select the most suitable one. It trades off computation for better\ndecision quality by concurrent sampling, shortening task execution steps, and\nimproving overall performance. Second, we propose a model that achieves\nimproved accuracy when grounding the selected action proposal to its\ncorresponding visual elements. Our key insight is that reinforcement learning\n(RL) facilitates visual grounding through inherent objective alignments,\nrewarding successful clicks on interface elements.\n  Experimentally, our method establishes state-of-the-art performance across\ndiverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7%\naccuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When\npaired with a planner applying our test-time scaling strategy, it exhibits\nstate-of-the-art agentic performance (e.g., 45.2% task success rate on\nOSWorld). We open-source our code and models here.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGTA1\u7684GUI\u4ee3\u7406\uff0c\u901a\u8fc7\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u548c\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u4efb\u52a1\u89c4\u5212\u548c\u89c6\u89c9\u5143\u7d20\u4ea4\u4e92\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3GUI\u4ee3\u7406\u5728\u4efb\u52a1\u89c4\u5212\u4e2d\u7684\u6a21\u7cca\u6027\u548c\u590d\u6742\u754c\u9762\u4e2d\u89c6\u89c9\u5143\u7d20\u4ea4\u4e92\u7684\u51c6\u786e\u6027\u6311\u6218\u3002", "method": "\u5f15\u5165\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u9009\u62e9\u6700\u4f73\u52a8\u4f5c\u63d0\u6848\uff0c\u5e76\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u63d0\u9ad8\u89c6\u89c9\u5143\u7d20\u4ea4\u4e92\u7684\u51c6\u786e\u6027\u3002", "result": "GTA1\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5982Screenspot-Pro\uff0850.1%\uff09\u3001Screenspot-V2\uff0892.4%\uff09\u548cOSWorld-G\uff0867.7%\uff09\u3002", "conclusion": "GTA1\u901a\u8fc7\u6d4b\u8bd5\u65f6\u7f29\u653e\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86GUI\u4ee3\u7406\u7684\u6027\u80fd\uff0c\u4ee3\u7801\u548c\u6a21\u578b\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.05816", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05816", "abs": "https://arxiv.org/abs/2507.05816", "authors": ["Shuai Zhao", "Yulin Zhang", "Luwei Xiao", "Xinyi Wu", "Yanhao Jia", "Zhongliang Guo", "Xiaobao Wu", "Cong-Duy Nguyen", "Guoming Zhang", "Anh Tuan Luu"], "title": "Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity", "comment": null, "summary": "Despite the remarkable progress of large language models (LLMs) across\nvarious domains, their capacity to predict retinopathy of prematurity (ROP)\nrisk remains largely unexplored. To address this gap, we introduce a novel\nChinese benchmark dataset, termed CROP, comprising 993 admission records\nannotated with low, medium, and high-risk labels. To systematically examine the\npredictive capabilities and affective biases of LLMs in ROP risk\nstratification, we propose Affective-ROPTester, an automated evaluation\nframework incorporating three prompting strategies: Instruction-based,\nChain-of-Thought (CoT), and In-Context Learning (ICL). The Instruction scheme\nassesses LLMs' intrinsic knowledge and associated biases, whereas the CoT and\nICL schemes leverage external medical knowledge to enhance predictive accuracy.\nCrucially, we integrate emotional elements at the prompt level to investigate\nhow different affective framings influence the model's ability to predict ROP\nand its bias patterns. Empirical results derived from the CROP dataset yield\ntwo principal observations. First, LLMs demonstrate limited efficacy in ROP\nrisk prediction when operating solely on intrinsic knowledge, yet exhibit\nmarked performance gains when augmented with structured external inputs.\nSecond, affective biases are evident in the model outputs, with a consistent\ninclination toward overestimating medium- and high-risk cases. Third, compared\nto negative emotions, positive emotional framing contributes to mitigating\npredictive bias in model outputs. These findings highlight the critical role of\naffect-sensitive prompt engineering in enhancing diagnostic reliability and\nemphasize the utility of Affective-ROPTester as a framework for evaluating and\nmitigating affective bias in clinical language modeling systems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9884\u6d4b\u65e9\u4ea7\u513f\u89c6\u7f51\u819c\u75c5\u53d8\uff08ROP\uff09\u98ce\u9669\u65b9\u9762\u7684\u80fd\u529b\uff0c\u63d0\u51fa\u4e86CROP\u6570\u636e\u96c6\u548cAffective-ROPTester\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0\u5916\u90e8\u77e5\u8bc6\u589e\u5f3a\u548c\u60c5\u611f\u63d0\u793a\u5de5\u7a0b\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u5e76\u51cf\u5c11\u504f\u89c1\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u591a\u9886\u57df\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5176\u5728ROP\u98ce\u9669\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u80fd\u529b\u548c\u60c5\u611f\u504f\u89c1\u3002", "method": "\u63d0\u51faCROP\u6570\u636e\u96c6\u548cAffective-ROPTester\u6846\u67b6\uff0c\u7ed3\u5408\u6307\u4ee4\u3001\u601d\u7ef4\u94fe\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e09\u79cd\u63d0\u793a\u7b56\u7565\uff0c\u5e76\u878d\u5165\u60c5\u611f\u5143\u7d20\u3002", "result": "LLMs\u5728\u4ec5\u4f9d\u8d56\u5185\u90e8\u77e5\u8bc6\u65f6\u8868\u73b0\u6709\u9650\uff0c\u4f46\u5916\u90e8\u8f93\u5165\u663e\u8457\u63d0\u5347\u6027\u80fd\uff1b\u60c5\u611f\u504f\u89c1\u660e\u663e\uff0c\u79ef\u6781\u60c5\u611f\u63d0\u793a\u6709\u52a9\u4e8e\u51cf\u5c11\u504f\u89c1\u3002", "conclusion": "\u60c5\u611f\u654f\u611f\u7684\u63d0\u793a\u5de5\u7a0b\u5bf9\u63d0\u5347\u8bca\u65ad\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0cAffective-ROPTester\u4e3a\u4e34\u5e8a\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2507.05868", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05868", "abs": "https://arxiv.org/abs/2507.05868", "authors": ["Alo\u00efs Rautureau", "\u00c9ric Piette"], "title": "CogniPlay: a work-in-progress Human-like model for General Game Playing", "comment": "5 pages, 1 figure", "summary": "While AI systems have equaled or surpassed human performance in a wide\nvariety of games such as Chess, Go, or Dota 2, describing these systems as\ntruly \"human-like\" remains far-fetched. Despite their success, they fail to\nreplicate the pattern-based, intuitive decision-making processes observed in\nhuman cognition. This paper presents an overview of findings from cognitive\npsychology and previous efforts to model human-like behavior in artificial\nagents, discusses their applicability to General Game Playing (GGP) and\nintroduces our work-in-progress model based on these observations: CogniPlay.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u7cfb\u7edf\u5728\u6e38\u620f\u4e2d\u8868\u73b0\u4f18\u5f02\u4f46\u4ecd\u7f3a\u4e4f\u4eba\u7c7b\u76f4\u89c9\u51b3\u7b56\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u8ba4\u77e5\u5fc3\u7406\u5b66\u7684\u6a21\u578bCogniPlay\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u6e38\u620f\u4e2d\u8868\u73b0\u8d85\u8d8a\u4eba\u7c7b\uff0c\u4f46\u5176\u51b3\u7b56\u8fc7\u7a0b\u4e0e\u4eba\u7c7b\u76f4\u89c9\u4e0d\u540c\uff0c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u7ed3\u5408\u8ba4\u77e5\u5fc3\u7406\u5b66\u548c\u524d\u4eba\u7814\u7a76\uff0c\u63d0\u51fa\u65b0\u6a21\u578bCogniPlay\uff0c\u5e94\u7528\u4e8e\u901a\u7528\u6e38\u620f\uff08GGP\uff09\u3002", "result": "\u6a21\u578bCogniPlay\u4e3a\u5de5\u4f5c\u8fdb\u5c55\uff0c\u65e8\u5728\u6a21\u62df\u4eba\u7c7b\u76f4\u89c9\u51b3\u7b56\u3002", "conclusion": "CogniPlay\u6709\u671b\u5728\u901a\u7528\u6e38\u620f\u4e2d\u5b9e\u73b0\u66f4\u63a5\u8fd1\u4eba\u7c7b\u7684\u51b3\u7b56\u6a21\u5f0f\u3002"}}
{"id": "2507.05886", "categories": ["cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.05886", "abs": "https://arxiv.org/abs/2507.05886", "authors": ["Aaron Bembenek"], "title": "Current Practices for Building LLM-Powered Reasoning Tools Are Ad Hoc -- and We Can Do Better", "comment": "6 pages, 4 figures", "summary": "There is growing excitement about building software verifiers, synthesizers,\nand other Automated Reasoning (AR) tools by combining traditional symbolic\nalgorithms and Large Language Models (LLMs). Unfortunately, the current\npractice for constructing such neurosymbolic AR systems is an ad hoc\nprogramming model that does not have the strong guarantees of traditional\nsymbolic algorithms, nor a deep enough synchronization of neural networks and\nsymbolic reasoning to unlock the full potential of LLM-powered reasoning. I\npropose Neurosymbolic Transition Systems as a principled computational model\nthat can underlie infrastructure for building neurosymbolic AR tools. In this\nmodel, symbolic state is paired with intuition, and state transitions operate\nover symbols and intuition in parallel. I argue why this new paradigm can scale\nlogical reasoning beyond current capabilities while retaining the strong\nguarantees of symbolic algorithms, and I sketch out how the computational model\nI propose can be reified in a logic programming language.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u795e\u7ecf\u7b26\u53f7\u8f6c\u6362\u7cfb\u7edf\u201d\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u65e8\u5728\u7ed3\u5408\u7b26\u53f7\u7b97\u6cd5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4ee5\u6784\u5efa\u66f4\u5f3a\u5927\u7684\u81ea\u52a8\u63a8\u7406\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u6784\u5efa\u795e\u7ecf\u7b26\u53f7\u81ea\u52a8\u63a8\u7406\u7cfb\u7edf\u7684\u65b9\u6cd5\u7f3a\u4e4f\u4f20\u7edf\u7b26\u53f7\u7b97\u6cd5\u7684\u5f3a\u4fdd\u8bc1\uff0c\u4e14\u672a\u80fd\u5145\u5206\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u4e0e\u7b26\u53f7\u63a8\u7406\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u8f6c\u6362\u7cfb\u7edf\uff0c\u5c06\u7b26\u53f7\u72b6\u6001\u4e0e\u76f4\u89c9\u914d\u5bf9\uff0c\u5e76\u5728\u7b26\u53f7\u548c\u76f4\u89c9\u4e0a\u5e76\u884c\u6267\u884c\u72b6\u6001\u8f6c\u6362\u3002", "result": "\u8be5\u6a21\u578b\u6709\u671b\u6269\u5c55\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u7559\u7b26\u53f7\u7b97\u6cd5\u7684\u5f3a\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u8ba1\u7b97\u6a21\u578b\u53ef\u5177\u4f53\u5316\u4e3a\u903b\u8f91\u7f16\u7a0b\u8bed\u8a00\uff0c\u4e3a\u795e\u7ecf\u7b26\u53f7\u81ea\u52a8\u63a8\u7406\u5de5\u5177\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.05891", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05891", "abs": "https://arxiv.org/abs/2507.05891", "authors": ["Robert Leppich", "Michael Stenger", "Andr\u00e9 Bauer", "Samuel Kounev"], "title": "Decomposing the Time Series Forecasting Pipeline: A Modular Approach for Time Series Representation, Information Extraction, and Projection", "comment": null, "summary": "With the advent of Transformers, time series forecasting has seen significant\nadvances, yet it remains challenging due to the need for effective sequence\nrepresentation, memory construction, and accurate target projection. Time\nseries forecasting remains a challenging task, demanding effective sequence\nrepresentation, meaningful information extraction, and precise future\nprojection. Each dataset and forecasting configuration constitutes a distinct\ntask, each posing unique challenges the model must overcome to produce accurate\npredictions. To systematically address these task-specific difficulties, this\nwork decomposes the time series forecasting pipeline into three core stages:\ninput sequence representation, information extraction and memory construction,\nand final target projection. Within each stage, we investigate a range of\narchitectural configurations to assess the effectiveness of various modules,\nsuch as convolutional layers for feature extraction and self-attention\nmechanisms for information extraction, across diverse forecasting tasks,\nincluding evaluations on seven benchmark datasets. Our models achieve\nstate-of-the-art forecasting accuracy while greatly enhancing computational\nefficiency, with reduced training and inference times and a lower parameter\ncount. The source code is available at\nhttps://github.com/RobertLeppich/REP-Net.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5206\u89e3\u4e3a\u4e09\u4e2a\u6838\u5fc3\u9636\u6bb5\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc4\u4f30\u4e0d\u540c\u6a21\u5757\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u7684\u63d0\u5347\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5728Transformer\u65f6\u4ee3\u867d\u6709\u8fdb\u6b65\uff0c\u4f46\u4ecd\u9762\u4e34\u5e8f\u5217\u8868\u793a\u3001\u4fe1\u606f\u63d0\u53d6\u548c\u76ee\u6807\u6295\u5f71\u7684\u6311\u6218\uff0c\u9700\u9488\u5bf9\u4e0d\u540c\u4efb\u52a1\u89e3\u51b3\u72ec\u7279\u95ee\u9898\u3002", "method": "\u5c06\u9884\u6d4b\u6d41\u7a0b\u5206\u89e3\u4e3a\u8f93\u5165\u5e8f\u5217\u8868\u793a\u3001\u4fe1\u606f\u63d0\u53d6\u4e0e\u8bb0\u5fc6\u6784\u5efa\u3001\u76ee\u6807\u6295\u5f71\u4e09\u9636\u6bb5\uff0c\u8bc4\u4f30\u5377\u79ef\u5c42\u548c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7b49\u6a21\u5757\u7684\u6709\u6548\u6027\u3002", "result": "\u5728\u4e03\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u51cf\u5c11\u4e86\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4\u53ca\u53c2\u6570\u91cf\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5206\u89e3\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u548c\u9ad8\u7cbe\u5ea6\u7684\u5e73\u8861\u3002"}}
{"id": "2507.05894", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05894", "abs": "https://arxiv.org/abs/2507.05894", "authors": ["Fathinah Izzati", "Xinyue Li", "Yuxuan Wu", "Gus Xia"], "title": "MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation", "comment": null, "summary": "Humans can imagine various atmospheres and settings when listening to music,\nenvisioning movie scenes that complement each piece. For example, slow,\nmelancholic music might evoke scenes of heartbreak, while upbeat melodies\nsuggest celebration. This paper explores whether a Music Language Model, e.g.\nMU-LLaMA, can perform a similar task, called Music Scene Imagination (MSI),\nwhich requires cross-modal information from video and music to train. To\nimprove upon existing music captioning models which focusing solely on musical\nelements, we introduce MusiScene, a music captioning model designed to imagine\nscenes that complement each music. In this paper, (1) we construct a\nlarge-scale video-audio caption dataset with 3,371 pairs, (2) we finetune Music\nUnderstanding LLaMA for the MSI task to create MusiScene, and (3) we conduct\ncomprehensive evaluations and prove that our MusiScene is more capable of\ngenerating contextually relevant captions compared to MU-LLaMA. We leverage the\ngenerated MSI captions to enhance Video Background Music Generation (VBMG) from\ntext.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMusiScene\u6a21\u578b\uff0c\u901a\u8fc7\u97f3\u4e50\u573a\u666f\u60f3\u8c61\uff08MSI\uff09\u4efb\u52a1\u751f\u6210\u4e0e\u97f3\u4e50\u5339\u914d\u7684\u573a\u666f\u63cf\u8ff0\uff0c\u5e76\u7528\u4e8e\u63d0\u5347\u89c6\u9891\u80cc\u666f\u97f3\u4e50\u751f\u6210\uff08VBMG\uff09\u3002", "motivation": "\u63a2\u7d22\u97f3\u4e50\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u50cf\u4eba\u7c7b\u4e00\u6837\u901a\u8fc7\u97f3\u4e50\u60f3\u8c61\u573a\u666f\uff0c\u5f25\u8865\u73b0\u6709\u97f3\u4e50\u6807\u6ce8\u6a21\u578b\u4ec5\u5173\u6ce8\u97f3\u4e50\u5143\u7d20\u7684\u4e0d\u8db3\u3002", "method": "\u6784\u5efa\u5927\u89c4\u6a21\u89c6\u9891-\u97f3\u9891\u6807\u6ce8\u6570\u636e\u96c6\uff083,371\u5bf9\uff09\uff0c\u5fae\u8c03Music Understanding LLaMA\u4ee5\u521b\u5efaMusiScene\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002", "result": "MusiScene\u5728\u751f\u6210\u4e0a\u4e0b\u6587\u76f8\u5173\u6807\u6ce8\u65b9\u9762\u4f18\u4e8eMU-LLaMA\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u89c6\u9891\u80cc\u666f\u97f3\u4e50\u751f\u6210\u4efb\u52a1\u3002", "conclusion": "MusiScene\u901a\u8fc7\u8de8\u6a21\u6001\u4fe1\u606f\u8bad\u7ec3\uff0c\u6709\u6548\u5b9e\u73b0\u4e86\u97f3\u4e50\u573a\u666f\u60f3\u8c61\uff0c\u4e3a\u97f3\u4e50\u4e0e\u89c6\u9891\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.05934", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05934", "abs": "https://arxiv.org/abs/2507.05934", "authors": ["Baojiao Xiong", "Boheng Chen", "Chengzhi Wang", "Daxiong Luo", "Dongsheng Xu", "Dongyang Liu", "Fan Yang", "Fangyuan Li", "Fei Teng", "Feng Wang", "Fukang Qin", "Fuquan Peng", "Guanxin Tan", "Guozhi Wang", "Haibo Yu", "Haohao Gao", "Heng Liu", "Hongbo Yang", "Hongjian Zou", "Houzheng Shen", "Hu Meng", "Huan Li", "Hui Tan", "Jiali Chen", "Jianzhao Chen", "Jinliang Zhu", "Kai Wang", "Lei Wu", "Liangbing Liu", "Liuyang Bian", "Liyan He", "Long Liu", "Peiwen Li", "Penggang Shi", "Qi Ding", "Rui Hu", "Shuai Cao", "Shuai Ren", "Shuang Peng", "Teng Xie", "Weiji Chen", "Weilin Xiang", "Weixin Wu", "Xi Yin", "Xiaoxin Chen", "Xu Chen", "Yafei Wen", "Yan Hu", "Yanzhou Yang", "Yina Xie", "Yinghao Chen", "Yixuan Liao", "Yu Geng", "Yuanjiang Ouyang", "Yuanzhuo Yang", "Yuehua He", "Yushuai Peng", "Zhaoxiong Wang", "Zheng Wang", "Zhibo Zhou", "Ziyang Wu"], "title": "BlueLM-2.5-3B Technical Report", "comment": null, "summary": "We present BlueLM-2.5-3B, a compact and unified dense Multimodal Large\nLanguage Model (MLLM) designed for efficient edge-device deployment, offering\nstrong general-purpose and reasoning capabilities. To the best of our\nknowledge, this is the first 3B-scale MLLM to support both thinking and\nnon-thinking modes, while also enabling explicit control over thinking token\nbudget. BlueLM-2.5-3B is developed through diversified data curation, key data\nresampling, hybrid heterogeneous reinforcement learning, and a high-performance\ntraining infrastructure. Our model achieves superior multimodal capacity while\npreserving competitive pure-text performance with only 2.9 billion parameters.\nWe conduct comprehensive evaluations across a broad range of multimodal and\ntext-only benchmarks. In thinking mode, BlueLM-2.5-3B achieves comparable\nperformance to Qwen3-4B on text-only benchmarks, and trails the larger\nKimi-VL-A3B-16B by only about 5% on average across multimodal evaluations. In\nnon-thinking mode, it outperforms Qwen2.5-VL-3B on the majority of multimodal\nbenchmarks. Additionally, BlueLM-2.5-3B exhibits exceptional data efficiency.\nAll of the aforementioned performance is achieved with substantially less total\ntraining data than Qwen2.5-VL-3B and Qwen3-4B. We hope our work contributes to\nthe advancement of high-performance, on-device MLLMs and provides meaningful\ninsights to the research community.", "AI": {"tldr": "BlueLM-2.5-3B\u662f\u4e00\u4e2a\u7d27\u51d1\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u652f\u6301\u601d\u8003\u548c\u666e\u901a\u6a21\u5f0f\uff0c\u5e76\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u9ad8\u6548\u8fd0\u884c\u3002", "motivation": "\u5f00\u53d1\u9ad8\u6027\u80fd\u3001\u9002\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u6587\u672c\u548c\u591a\u6a21\u6001\u4efb\u52a1\u7684\u7ade\u4e89\u529b\u3002", "method": "\u901a\u8fc7\u591a\u6837\u5316\u6570\u636e\u6574\u7406\u3001\u5173\u952e\u6570\u636e\u91cd\u91c7\u6837\u3001\u6df7\u5408\u5f02\u6784\u5f3a\u5316\u5b66\u4e60\u548c\u9ad8\u6027\u80fd\u8bad\u7ec3\u57fa\u7840\u8bbe\u65bd\u5f00\u53d1\u6a21\u578b\u3002", "result": "\u57283B\u53c2\u6570\u89c4\u6a21\u4e0b\uff0c\u6a21\u578b\u5728\u591a\u6a21\u6001\u548c\u7eaf\u6587\u672c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u6570\u636e\u6548\u7387\u9ad8\u3002", "conclusion": "BlueLM-2.5-3B\u4e3a\u9ad8\u6027\u80fd\u8fb9\u7f18\u8bbe\u5907MLLM\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2507.05938", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05938", "abs": "https://arxiv.org/abs/2507.05938", "authors": ["Yucheng Sheng", "Jiacheng Wang", "Xingyu Zhou", "Le Liang", "Hao Ye", "Shi Jin", "Geoffrey Ye Li"], "title": "A Wireless Foundation Model for Multi-Task Prediction", "comment": null, "summary": "With the growing complexity and dynamics of the mobile communication\nnetworks, accurately predicting key system parameters, such as channel state\ninformation (CSI), user location, and network traffic, has become essential for\na wide range of physical (PHY)-layer and medium access control (MAC)-layer\ntasks. Although traditional deep learning (DL)-based methods have been widely\napplied to such prediction tasks, they often struggle to generalize across\ndifferent scenarios and tasks. In response, we propose a unified foundation\nmodel for multi-task prediction in wireless networks that supports diverse\nprediction intervals. The proposed model enforces univariate decomposition to\nunify heterogeneous tasks, encodes granularity for interval awareness, and uses\na causal Transformer backbone for accurate predictions. Additionally, we\nintroduce a patch masking strategy during training to support arbitrary input\nlengths. After trained on large-scale datasets, the proposed foundation model\ndemonstrates strong generalization to unseen scenarios and achieves zero-shot\nperformance on new tasks that surpass traditional full-shot baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u57fa\u7840\u6a21\u578b\uff0c\u7528\u4e8e\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u591a\u4efb\u52a1\u9884\u6d4b\uff0c\u652f\u6301\u4e0d\u540c\u9884\u6d4b\u533a\u95f4\uff0c\u5e76\u901a\u8fc7\u5206\u89e3\u3001\u7f16\u7801\u548c\u56e0\u679cTransformer\u5b9e\u73b0\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u79fb\u52a8\u901a\u4fe1\u7f51\u7edc\u7684\u590d\u6742\u6027\u548c\u52a8\u6001\u6027\u589e\u52a0\uff0c\u51c6\u786e\u9884\u6d4b\u5173\u952e\u7cfb\u7edf\u53c2\u6570\u5bf9PHY\u5c42\u548cMAC\u5c42\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u5355\u53d8\u91cf\u5206\u89e3\u7edf\u4e00\u5f02\u6784\u4efb\u52a1\uff0c\u7f16\u7801\u7c92\u5ea6\u4ee5\u5b9e\u73b0\u533a\u95f4\u611f\u77e5\uff0c\u4f7f\u7528\u56e0\u679cTransformer\u4f5c\u4e3a\u4e3b\u5e72\uff0c\u5e76\u5f15\u5165\u8865\u4e01\u63a9\u7801\u7b56\u7565\u652f\u6301\u4efb\u610f\u8f93\u5165\u957f\u5ea6\u3002", "result": "\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u540e\uff0c\u6a21\u578b\u5728\u672a\u89c1\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5728\u65b0\u4efb\u52a1\u4e0a\u5b9e\u73b0\u96f6\u6837\u672c\u6027\u80fd\uff0c\u8d85\u8d8a\u4f20\u7edf\u5168\u6837\u672c\u57fa\u7ebf\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u7840\u6a21\u578b\u5728\u65e0\u7ebf\u7f51\u7edc\u591a\u4efb\u52a1\u9884\u6d4b\u4e2d\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2507.05976", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.05976", "abs": "https://arxiv.org/abs/2507.05976", "authors": ["Alessandro Umbrico", "Guido Bologna", "Luca Coraci", "Francesca Fracasso", "Silvia Gola", "Gabriella Cortellessa"], "title": "Enhancing the Interpretability of Rule-based Explanations through Information Retrieval", "comment": null, "summary": "The lack of transparency of data-driven Artificial Intelligence techniques\nlimits their interpretability and acceptance into healthcare decision-making\nprocesses. We propose an attribution-based approach to improve the\ninterpretability of Explainable AI-based predictions in the specific context of\narm lymphedema's risk assessment after lymph nodal radiotherapy in breast\ncancer. The proposed method performs a statistical analysis of the attributes\nin the rule-based prediction model using standard metrics from Information\nRetrieval techniques. This analysis computes the relevance of each attribute to\nthe prediction and provides users with interpretable information about the\nimpact of risk factors. The results of a user study that compared the output\ngenerated by the proposed approach with the raw output of the Explainable AI\nmodel suggested higher levels of interpretability and usefulness in the context\nof predicting lymphedema risk.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5c5e\u6027\u7684\u65b9\u6cd5\uff0c\u63d0\u5347\u53ef\u89e3\u91caAI\u5728\u4e73\u817a\u764c\u6dcb\u5df4\u7ed3\u653e\u7597\u540e\u6dcb\u5df4\u6c34\u80bf\u98ce\u9669\u8bc4\u4f30\u4e2d\u7684\u900f\u660e\u5ea6\u548c\u53ef\u63a5\u53d7\u6027\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u7684AI\u6280\u672f\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u9650\u5236\u4e86\u5176\u5728\u533b\u7597\u51b3\u7b56\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u63a5\u53d7\u5ea6\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u7ed3\u5408\u4fe1\u606f\u68c0\u7d22\u6280\u672f\u4e2d\u7684\u6807\u51c6\u6307\u6807\uff0c\u5bf9\u5c5e\u6027\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\uff0c\u8ba1\u7b97\u5176\u5bf9\u9884\u6d4b\u7684\u76f8\u5173\u6027\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u539f\u59cb\u53ef\u89e3\u91caAI\u6a21\u578b\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u8f93\u51fa\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86AI\u9884\u6d4b\u5728\u533b\u7597\u98ce\u9669\u8bc4\u4f30\u4e2d\u7684\u900f\u660e\u5ea6\u548c\u7528\u6237\u63a5\u53d7\u5ea6\u3002"}}
{"id": "2507.05984", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.05984", "abs": "https://arxiv.org/abs/2507.05984", "authors": ["Zhijun Guo", "Alvina Lai", "Julia Ive", "Alexandru Petcu", "Yutong Wang", "Luyuan Qi", "Johan H Thygesen", "Kezhi Li"], "title": "Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening", "comment": null, "summary": "Static tools like the Patient Health Questionnaire-9 (PHQ-9) effectively\nscreen depression but lack interactivity and adaptability. We developed\nHopeBot, a chatbot powered by a large language model (LLM) that administers the\nPHQ-9 using retrieval-augmented generation and real-time clarification. In a\nwithin-subject study, 132 adults in the United Kingdom and China completed both\nself-administered and chatbot versions. Scores demonstrated strong agreement\n(ICC = 0.91; 45% identical). Among 75 participants providing comparative\nfeedback, 71% reported greater trust in the chatbot, highlighting clearer\nstructure, interpretive guidance, and a supportive tone. Mean ratings (0-10)\nwere 8.4 for comfort, 7.7 for voice clarity, 7.6 for handling sensitive topics,\nand 7.4 for recommendation helpfulness; the latter varied significantly by\nemployment status and prior mental-health service use (p < 0.05). Overall,\n87.1% expressed willingness to reuse or recommend HopeBot. These findings\ndemonstrate voice-based LLM chatbots can feasibly serve as scalable, low-burden\nadjuncts for routine depression screening.", "AI": {"tldr": "HopeBot\u662f\u4e00\u6b3e\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u7528\u4e8e\u6291\u90c1\u75c7\u7b5b\u67e5\uff0c\u4e0e\u4f20\u7edf\u9759\u6001\u95ee\u5377PHQ-9\u76f8\u6bd4\uff0c\u66f4\u5177\u4e92\u52a8\u6027\u548c\u9002\u5e94\u6027\u3002\u7814\u7a76\u8868\u660e\u5176\u8bc4\u5206\u4e0e\u4f20\u7edf\u65b9\u6cd5\u9ad8\u5ea6\u4e00\u81f4\uff0c\u4e14\u7528\u6237\u53cd\u9988\u79ef\u6781\u3002", "motivation": "\u4f20\u7edf\u6291\u90c1\u75c7\u7b5b\u67e5\u5de5\u5177\uff08\u5982PHQ-9\uff09\u7f3a\u4e4f\u4e92\u52a8\u6027\u548c\u9002\u5e94\u6027\uff0c\u9650\u5236\u4e86\u5176\u6548\u679c\u3002", "method": "\u5f00\u53d1\u4e86HopeBot\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u5b9e\u65f6\u6f84\u6e05\u529f\u80fd\uff0c\u8fdb\u884cPHQ-9\u95ee\u5377\u7684\u4ea4\u4e92\u5f0f\u7ba1\u7406\u3002", "result": "132\u540d\u53c2\u4e0e\u8005\u6d4b\u8bd5\u663e\u793a\uff0cHopeBot\u4e0e\u4f20\u7edf\u65b9\u6cd5\u8bc4\u5206\u9ad8\u5ea6\u4e00\u81f4\uff08ICC=0.91\uff09\uff0c71%\u7528\u6237\u66f4\u4fe1\u4efb\u804a\u5929\u673a\u5668\u4eba\u3002", "conclusion": "\u8bed\u97f3\u9a71\u52a8\u7684LLM\u804a\u5929\u673a\u5668\u4eba\u53ef\u4f5c\u4e3a\u6291\u90c1\u75c7\u7b5b\u67e5\u7684\u53ef\u6269\u5c55\u3001\u4f4e\u8d1f\u62c5\u8f85\u52a9\u5de5\u5177\u3002"}}
{"id": "2507.06013", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06013", "abs": "https://arxiv.org/abs/2507.06013", "authors": ["Kushal Gajjar", "Harshit Sikchi", "Arpit Singh Gautam", "Marc Hammons", "Saurabh Jha"], "title": "CogniSQL-R1-Zero: Lightweight Reinforced Reasoning for Efficient SQL Generation", "comment": null, "summary": "Translating natural language into SQL (Text-to-SQL) remains a core challenge\nat the intersection of language understanding and structured data access.\nAlthough large language models (LLMs) have improved fluency, generating correct\nand executable SQL, especially for complex queries, continues to be\nchallenging. We introduce CogniSQL-R1-Zero, a reinforcement learning (RL)\nframework and model that produces accurate SQL using a lightweight reward\nsignal based on execution correctness and format-tag compliance. By avoiding\nintermediate supervision, hybrid pipelines and complex reward shaping, our\nmethod encourages stable learning and stronger alignment with the ultimate task\nobjective-producing executable programs. CogniSQL-R1-Zero achieves\nstate-of-the-art execution accuracy on Text2SQL benchmark; BIRD bench,\noutperforming prior supervised and instruction-tuned baselines including SFT\nCodeS-7B, DeepSeek-Coder 236B, and Mistral 123B-despite being trained on a\nsignificantly smaller 7B backbone. This result underscores the scalability and\nefficiency of our RL-based approach when trained on just four NVIDIA A100 GPUs\n(40 GB VRAM each). To support further research in efficient and interpretable\nText-to-SQL modeling, we release two curated datasets: (i) a collection of\n5,024 reasoning traces with varying context lengths, and (ii) a\npositive-sampled corpus of 36,356 corpus of weakly supervised queries, each\nannotated with six semantically diverse reasoning paths. Together, these\ncontributions advance scalable, execution-aligned Text-to-SQL generation.", "AI": {"tldr": "CogniSQL-R1-Zero\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u51c6\u786e\u7684SQL\u67e5\u8be2\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5956\u52b1\u4fe1\u53f7\uff08\u6267\u884c\u6b63\u786e\u6027\u548c\u683c\u5f0f\u5408\u89c4\u6027\uff09\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\uff0c\u5e76\u5728Text2SQL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u81ea\u7136\u8bed\u8a00\u8f6cSQL\uff08Text-to-SQL\uff09\u662f\u8bed\u8a00\u7406\u89e3\u548c\u7ed3\u6784\u5316\u6570\u636e\u8bbf\u95ee\u7684\u6838\u5fc3\u6311\u6218\uff0c\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6d41\u7545\u6027\u4e0a\u6709\u6240\u63d0\u5347\uff0c\u4f46\u751f\u6210\u590d\u6742\u67e5\u8be2\u7684\u6b63\u786eSQL\u4ecd\u7136\u56f0\u96be\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5956\u52b1\u4fe1\u53f7\uff08\u6267\u884c\u6b63\u786e\u6027\u548c\u683c\u5f0f\u5408\u89c4\u6027\uff09\u8bad\u7ec3\u6a21\u578b\uff0c\u907f\u514d\u4e2d\u95f4\u76d1\u7763\u548c\u590d\u6742\u5956\u52b1\u8bbe\u8ba1\u3002", "result": "\u5728Text2SQL\u57fa\u51c6\u6d4b\u8bd5\uff08BIRD bench\uff09\u4e2d\uff0cCogniSQL-R1-Zero\u8d85\u8d8a\u4e86\u5305\u62ecSFT CodeS-7B\u3001DeepSeek-Coder 236B\u548cMistral 123B\u5728\u5185\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5c3d\u7ba1\u5176\u57fa\u4e8e\u8f83\u5c0f\u76847B\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684Text-to-SQL\u751f\u6210\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u53d1\u5e03\u4e86\u4e24\u5957\u6570\u636e\u96c6\u4ee5\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.06029", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06029", "abs": "https://arxiv.org/abs/2507.06029", "authors": ["Courtney Ford", "Mark T. Keane"], "title": "Feature-Guided Neighbor Selection for Non-Expert Evaluation of Model Predictions", "comment": "7 pages, 5 figures, 1 table. Accepted at IJCAI 2025 Workshop on\n  User-Aligned Assessment of Adaptive AI Systems", "summary": "Explainable AI (XAI) methods often struggle to generate clear, interpretable\noutputs for users without domain expertise. We introduce Feature-Guided\nNeighbor Selection (FGNS), a post hoc method that enhances interpretability by\nselecting class-representative examples using both local and global feature\nimportance. In a user study (N = 98) evaluating Kannada script classifications,\nFGNS significantly improved non-experts' ability to identify model errors while\nmaintaining appropriate agreement with correct predictions. Participants made\nfaster and more accurate decisions compared to those given traditional k-NN\nexplanations. Quantitative analysis shows that FGNS selects neighbors that\nbetter reflect class characteristics rather than merely minimizing\nfeature-space distance, leading to more consistent selection and tighter\nclustering around class prototypes. These results support FGNS as a step toward\nmore human-aligned model assessment, although further work is needed to address\nthe gap between explanation quality and perceived trust.", "AI": {"tldr": "FGNS\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\u91cd\u8981\u6027\u9009\u62e9\u4ee3\u8868\u6027\u6837\u672c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u975e\u4e13\u5bb6\u7528\u6237\u5bf9\u6a21\u578b\u9519\u8bef\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9884\u6d4b\u4e00\u81f4\u6027\u3002", "motivation": "\u5f53\u524dXAI\u65b9\u6cd5\u5bf9\u975e\u4e13\u5bb6\u7528\u6237\u751f\u6210\u6e05\u6670\u89e3\u91ca\u7684\u80fd\u529b\u4e0d\u8db3\uff0cFGNS\u65e8\u5728\u901a\u8fc7\u6539\u8fdb\u6837\u672c\u9009\u62e9\u63d0\u5347\u89e3\u91ca\u6027\u3002", "method": "FGNS\u662f\u4e00\u79cd\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u5229\u7528\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\u91cd\u8981\u6027\u9009\u62e9\u7c7b\u4ee3\u8868\u6027\u6837\u672c\u3002", "result": "\u5728\u7528\u6237\u7814\u7a76\u4e2d\uff0cFGNS\u663e\u8457\u63d0\u5347\u4e86\u975e\u4e13\u5bb6\u7684\u51b3\u7b56\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff0c\u4e14\u6240\u9009\u90bb\u5c45\u66f4\u7b26\u5408\u7c7b\u522b\u7279\u5f81\u3002", "conclusion": "FGNS\u662f\u8fc8\u5411\u66f4\u4eba\u6027\u5316\u6a21\u578b\u8bc4\u4f30\u7684\u4e00\u6b65\uff0c\u4f46\u89e3\u91ca\u8d28\u91cf\u4e0e\u7528\u6237\u4fe1\u4efb\u4e4b\u95f4\u7684\u5dee\u8ddd\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.06042", "categories": ["cs.AI", "03B42, 03B48"], "pdf": "https://arxiv.org/pdf/2507.06042", "abs": "https://arxiv.org/abs/2507.06042", "authors": ["Tommaso Flaminio", "Lluis Godo", "Ram\u00f3n Pino P\u00e9rez", "Lluis Subirana"], "title": "On Lockean beliefs that are deductively closed and minimal change", "comment": "18 pages, to appear in the proceedings of JELIA 2025", "summary": "Within the formal setting of the Lockean thesis, an agent belief set is\ndefined in terms of degrees of confidence and these are described in\nprobabilistic terms. This approach is of established interest, notwithstanding\nsome limitations that make its use troublesome in some contexts, like, for\ninstance, in belief change theory. Precisely, Lockean belief sets are not\ngenerally closed under (classical) logical deduction. The aim of the present\npaper is twofold: on one side we provide two characterizations of those belief\nsets that are closed under classical logic deduction, and on the other we\npropose an approach to probabilistic update that allows us for a minimal\nrevision of those beliefs, i.e., a revision obtained by making the fewest\npossible changes to the existing belief set while still accommodating the new\ninformation. In particular, we show how we can deductively close a belief set\nvia a minimal revision.", "AI": {"tldr": "\u8bba\u6587\u5728Lockean\u7406\u8bba\u6846\u67b6\u4e0b\uff0c\u7814\u7a76\u4e86\u57fa\u4e8e\u6982\u7387\u7f6e\u4fe1\u5ea6\u7684\u4fe1\u5ff5\u96c6\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u4f7f\u5176\u95ed\u5408\u4e8e\u7ecf\u5178\u903b\u8f91\u6f14\u7ece\u7684\u7279\u5f81\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6700\u5c0f\u5316\u4fee\u6b63\u7684\u66f4\u65b0\u65b9\u6cd5\u3002", "motivation": "Lockean\u4fe1\u5ff5\u96c6\u5728\u7ecf\u5178\u903b\u8f91\u6f14\u7ece\u4e0b\u901a\u5e38\u4e0d\u95ed\u5408\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u4fe1\u5ff5\u4fee\u6b63\u7406\u8bba\u7b49\u9886\u57df\u7684\u5e94\u7528\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u4f9b\u4e86\u4e24\u79cd\u4f7f\u4fe1\u5ff5\u96c6\u95ed\u5408\u4e8e\u7ecf\u5178\u903b\u8f91\u6f14\u7ece\u7684\u7279\u5f81\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6700\u5c0f\u4fee\u6b63\u7684\u6982\u7387\u66f4\u65b0\u65b9\u6cd5\u3002", "result": "\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u6700\u5c0f\u4fee\u6b63\u5b9e\u73b0\u4fe1\u5ff5\u96c6\u7684\u6f14\u7ece\u95ed\u5408\u3002", "conclusion": "\u8bba\u6587\u4e3aLockean\u4fe1\u5ff5\u96c6\u7684\u95ed\u5408\u6027\u548c\u4fee\u6b63\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u6269\u5c55\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2507.06057", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06057", "abs": "https://arxiv.org/abs/2507.06057", "authors": ["Bo Pang", "Yalu Ouyang", "Hangfei Xu", "Ziqi Jia", "Panpan Li", "Shengzhao Wen", "Lu Wang", "Shiyong Li", "Yanpeng Wang"], "title": "FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models", "comment": null, "summary": "Advancements in reasoning for large language models (LLMs) have lead to\nsignificant performance improvements for LLMs in various fields such as\nmathematics and programming. However, research applying these advances to the\nfinancial domain, where considerable domain-specific knowledge is necessary to\ncomplete tasks, remains limited. To address this gap, we introduce FEVO\n(Financial Evolution), a multi-stage enhancement framework developed to enhance\nLLM performance in the financial domain. FEVO systemically enhances LLM\nperformance by using continued pre-training (CPT) to expand financial domain\nknowledge, supervised fine-tuning (SFT) to instill structured, elaborate\nreasoning patterns, and reinforcement learning (RL) to further integrate the\nexpanded financial domain knowledge with the learned structured reasoning. To\nensure effective and efficient training, we leverage frontier reasoning models\nand rule-based filtering to curate FEVO-Train, high-quality datasets\nspecifically designed for the different post-training phases. Using our\nframework, we train the FEVO series of models -- C32B, S32B, R32B -- from\nQwen2.5-32B and evaluate them on seven benchmarks to assess financial and\ngeneral capabilities, with results showing that FEVO-R32B achieves\nstate-of-the-art performance on five financial benchmarks against much larger\nmodels as well as specialist models. More significantly, FEVO-R32B demonstrates\nmarkedly better performance than FEVO-R32B-0 (trained from Qwen2.5-32B-Instruct\nusing only RL), thus validating the effectiveness of financial domain knowledge\nexpansion and structured, logical reasoning distillation", "AI": {"tldr": "FEVO\u6846\u67b6\u901a\u8fc7\u591a\u9636\u6bb5\u589e\u5f3a\u65b9\u6cd5\u63d0\u5347LLM\u5728\u91d1\u878d\u9886\u57df\u7684\u6027\u80fd\uff0c\u5305\u62ec\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u4f18\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u5c06LLM\u5e94\u7528\u4e8e\u9700\u8981\u5927\u91cf\u9886\u57df\u77e5\u8bc6\u7684\u91d1\u878d\u9886\u57df\u65b9\u9762\u4ecd\u6709\u9650\uff0c\u56e0\u6b64\u5f00\u53d1\u4e86FEVO\u6846\u67b6\u4ee5\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "FEVO\u91c7\u7528\u6301\u7eed\u9884\u8bad\u7ec3\uff08CPT\uff09\u6269\u5c55\u91d1\u878d\u77e5\u8bc6\uff0c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u57f9\u517b\u7ed3\u6784\u5316\u63a8\u7406\u6a21\u5f0f\uff0c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6574\u5408\u77e5\u8bc6\u4e0e\u63a8\u7406\u3002", "result": "FEVO-R32B\u5728\u4e94\u4e2a\u91d1\u878d\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u4e14\u663e\u8457\u4f18\u4e8e\u4ec5\u4f7f\u7528RL\u8bad\u7ec3\u7684\u6a21\u578b\u3002", "conclusion": "FEVO\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u91d1\u878d\u9886\u57df\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u91d1\u878d\u77e5\u8bc6\u6269\u5c55\u548c\u7ed3\u6784\u5316\u63a8\u7406\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.06077", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06077", "abs": "https://arxiv.org/abs/2507.06077", "authors": ["Iman Rahimi", "Isha Patel"], "title": "AI-Based Demand Forecasting and Load Balancing for Optimising Energy use in Healthcare Systems: A real case study", "comment": null, "summary": "This paper tackles the urgent need for efficient energy management in\nhealthcare facilities, where fluctuating demands challenge operational\nefficiency and sustainability. Traditional methods often prove inadequate,\ncausing inefficiencies and higher costs. To address this, the study presents an\nAI-based framework combining Long Short-Term Memory (LSTM), genetic algorithm\n(GA), and SHAP (Shapley Additive Explanations), specifically designed for\nhealthcare energy management. Although LSTM is widely used for time-series\nforecasting, its application in healthcare energy prediction remains\nunderexplored. The results reveal that LSTM significantly outperforms ARIMA and\nProphet models in forecasting complex, non-linear demand patterns. LSTM\nachieves a Mean Absolute Error (MAE) of 21.69 and Root Mean Square Error (RMSE)\nof 29.96, far better than Prophet (MAE: 59.78, RMSE: 81.22) and ARIMA (MAE:\n87.73, RMSE: 125.22), demonstrating superior performance. The genetic algorithm\nis applied to optimize model parameters and improve load balancing strategies,\nenabling adaptive responses to real-time energy fluctuations. SHAP analysis\nfurther enhances model transparency by explaining the influence of different\nfeatures on predictions, fostering trust in decision-making processes. This\nintegrated LSTM-GA-SHAP approach offers a robust solution for improving\nforecasting accuracy, boosting energy efficiency, and advancing sustainability\nin healthcare facilities. Future research may explore real-time deployment and\nhybridization with reinforcement learning for continuous optimization. Overall,\nthe study establishes a solid foundation for using AI in healthcare energy\nmanagement, highlighting its scalability, efficiency, and resilience potential.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LSTM\u3001\u9057\u4f20\u7b97\u6cd5\u548cSHAP\u7684AI\u6846\u67b6\uff0c\u7528\u4e8e\u533b\u7597\u8bbe\u65bd\u7684\u9ad8\u6548\u80fd\u6e90\u7ba1\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u80fd\u6e90\u6548\u7387\u3002", "motivation": "\u533b\u7597\u8bbe\u65bd\u80fd\u6e90\u9700\u6c42\u6ce2\u52a8\u5927\uff0c\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\u4e14\u6210\u672c\u9ad8\uff0c\u4e9f\u9700\u667a\u80fd\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528LSTM\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u53c2\u6570\uff0c\u5229\u7528SHAP\u589e\u5f3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "result": "LSTM\u5728MAE\u548cRMSE\u4e0a\u663e\u8457\u4f18\u4e8eARIMA\u548cProphet\u6a21\u578b\uff0c\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u4e86\u8d1f\u8f7d\u5e73\u8861\uff0cSHAP\u63d0\u9ad8\u4e86\u900f\u660e\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u533b\u7597\u80fd\u6e90\u7ba1\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u53ef\u63a2\u7d22\u5b9e\u65f6\u90e8\u7f72\u548c\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u3002"}}
{"id": "2507.06134", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06134", "abs": "https://arxiv.org/abs/2507.06134", "authors": ["Sanidhya Vijayvargiya", "Aditya Bharat Soni", "Xuhui Zhou", "Zora Zhiruo Wang", "Nouha Dziri", "Graham Neubig", "Maarten Sap"], "title": "OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety", "comment": "19 pages, 10 figures", "summary": "Recent advances in AI agents capable of solving complex, everyday tasks, from\nscheduling to customer service, have enabled deployment in real-world settings,\nbut their possibilities for unsafe behavior demands rigorous evaluation. While\nprior benchmarks have attempted to assess agent safety, most fall short by\nrelying on simulated environments, narrow task domains, or unrealistic tool\nabstractions. We introduce OpenAgentSafety, a comprehensive and modular\nframework for evaluating agent behavior across eight critical risk categories.\nUnlike prior work, our framework evaluates agents that interact with real\ntools, including web browsers, code execution environments, file systems, bash\nshells, and messaging platforms; and supports over 350 multi-turn, multi-user\ntasks spanning both benign and adversarial user intents. OpenAgentSafety is\ndesigned for extensibility, allowing researchers to add tools, tasks, websites,\nand adversarial strategies with minimal effort. It combines rule-based analysis\nwith LLM-as-judge assessments to detect both overt and subtle unsafe behaviors.\nEmpirical analysis of five prominent LLMs in agentic scenarios reveals unsafe\nbehavior in 51.2% of safety-vulnerable tasks with Claude-Sonnet-3.7, to 72.7%\nwith o3-mini, highlighting critical safety vulnerabilities and the need for\nstronger safeguards before real-world deployment.", "AI": {"tldr": "OpenAgentSafety\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u4ee3\u7406\u5728\u771f\u5b9e\u5de5\u5177\u4ea4\u4e92\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u8986\u76d6\u516b\u7c7b\u5173\u952e\u98ce\u9669\uff0c\u652f\u6301\u591a\u4efb\u52a1\u548c\u591a\u7528\u6237\u573a\u666f\uff0c\u53d1\u73b0\u4e3b\u6d41LLM\u572851.2%\u81f372.7%\u7684\u4efb\u52a1\u4e2d\u5b58\u5728\u4e0d\u5b89\u5168\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u5b89\u5168\u6027\u8bc4\u4f30\u591a\u4f9d\u8d56\u6a21\u62df\u73af\u5883\u6216\u72ed\u7a84\u4efb\u52a1\u57df\uff0c\u65e0\u6cd5\u5168\u9762\u53cd\u6620\u771f\u5b9e\u98ce\u9669\uff0c\u4e9f\u9700\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faOpenAgentSafety\u6846\u67b6\uff0c\u652f\u6301\u771f\u5b9e\u5de5\u5177\u4ea4\u4e92\uff08\u5982\u6d4f\u89c8\u5668\u3001\u4ee3\u7801\u6267\u884c\u73af\u5883\u7b49\uff09\uff0c\u7ed3\u5408\u89c4\u5219\u5206\u6790\u548cLLM\u8bc4\u4f30\uff0c\u68c0\u6d4b\u663e\u6027\u548c\u9690\u6027\u4e0d\u5b89\u5168\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4e3b\u6d41LLM\u5728\u5b89\u5168\u6f0f\u6d1e\u4efb\u52a1\u4e2d\u4e0d\u5b89\u5168\u884c\u4e3a\u6bd4\u4f8b\u9ad8\u8fbe51.2%\uff08Claude-Sonnet-3.7\uff09\u81f372.7%\uff08o3-mini\uff09\u3002", "conclusion": "OpenAgentSafety\u63ed\u793a\u4e86AI\u4ee3\u7406\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u663e\u8457\u5b89\u5168\u98ce\u9669\uff0c\u5f3a\u8c03\u5b9e\u9645\u90e8\u7f72\u524d\u9700\u52a0\u5f3a\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2507.06187", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06187", "abs": "https://arxiv.org/abs/2507.06187", "authors": ["Scott Geng", "Hamish Ivison", "Chun-Liang Li", "Maarten Sap", "Jerry Li", "Ranjay Krishna", "Pang Wei Koh"], "title": "The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong Gains", "comment": "COLM 2025", "summary": "Improvements in language models are often driven by improving the quality of\nthe data we train them on, which can be limiting when strong supervision is\nscarce. In this work, we show that paired preference data consisting of\nindividually weak data points can enable gains beyond the strength of each\nindividual data point. We formulate the delta learning hypothesis to explain\nthis phenomenon, positing that the relative quality delta between points\nsuffices to drive learning via preference tuning--even when supervised\nfinetuning on the weak data hurts. We validate our hypothesis in controlled\nexperiments and at scale, where we post-train 8B models on preference data\ngenerated by pairing a small 3B model's responses with outputs from an even\nsmaller 1.5B model to create a meaningful delta. Strikingly, on a standard\n11-benchmark evaluation suite (MATH, MMLU, etc.), our simple recipe matches the\nperformance of Tulu 3, a state-of-the-art open model tuned from the same base\nmodel while relying on much stronger supervisors (e.g., GPT-4o). Thus, delta\nlearning enables simpler and cheaper open recipes for state-of-the-art\npost-training. To better understand delta learning, we prove in logistic\nregression that the performance gap between two weak teacher models provides\nuseful signal for improving a stronger student. Overall, our work shows that\nmodels can learn surprisingly well from paired data that might typically be\nconsidered weak.", "AI": {"tldr": "\u901a\u8fc7\u914d\u5bf9\u504f\u597d\u6570\u636e\uff08\u5373\u4f7f\u5355\u4e2a\u6570\u636e\u70b9\u8f83\u5f31\uff09\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u63d0\u51fadelta\u5b66\u4e60\u5047\u8bbe\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u5f3a\u76d1\u7763\u6570\u636e\u7a00\u7f3a\u65f6\uff0c\u5982\u4f55\u5229\u7528\u5f31\u6570\u636e\u70b9\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fadelta\u5b66\u4e60\u5047\u8bbe\uff0c\u901a\u8fc7\u914d\u5bf9\u5f31\u6570\u636e\u70b9\uff08\u59823B\u548c1.5B\u6a21\u578b\u7684\u8f93\u51fa\uff09\u8bad\u7ec38B\u6a21\u578b\u3002", "result": "\u572811\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6027\u80fd\u4e0eTulu 3\u76f8\u5f53\uff0c\u4e14\u6210\u672c\u66f4\u4f4e\u3002", "conclusion": "delta\u5b66\u4e60\u4e3a\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7b80\u5355\u3001\u66f4\u7ecf\u6d4e\u7684\u65b9\u6cd5\uff0c\u5373\u4f7f\u6570\u636e\u70b9\u8f83\u5f31\u4e5f\u80fd\u6709\u6548\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.06213", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06213", "abs": "https://arxiv.org/abs/2507.06213", "authors": ["Cl\u00e9ment Yvernes", "Emilie Devijver", "Marianne Clausel", "Eric Gaussier"], "title": "Identifiability in Causal Abstractions: A Hierarchy of Criteria", "comment": "Accepted at the CAR Workshop at UAI2025", "summary": "Identifying the effect of a treatment from observational data typically\nrequires assuming a fully specified causal diagram. However, such diagrams are\nrarely known in practice, especially in complex or high-dimensional settings.\nTo overcome this limitation, recent works have explored the use of causal\nabstractions-simplified representations that retain partial causal information.\nIn this paper, we consider causal abstractions formalized as collections of\ncausal diagrams, and focus on the identifiability of causal queries within such\ncollections. We introduce and formalize several identifiability criteria under\nthis setting. Our main contribution is to organize these criteria into a\nstructured hierarchy, highlighting their relationships. This hierarchical view\nenables a clearer understanding of what can be identified under varying levels\nof causal knowledge. We illustrate our framework through examples from the\nliterature and provide tools to reason about identifiability when full causal\nknowledge is unavailable.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u89c2\u6d4b\u6570\u636e\u4e2d\u8bc6\u522b\u6cbb\u7597\u6548\u679c\u65f6\uff0c\u56e0\u679c\u56fe\u901a\u5e38\u9700\u8981\u5b8c\u5168\u6307\u5b9a\uff0c\u4f46\u5b9e\u9645\u4e2d\u96be\u4ee5\u5b9e\u73b0\u3002\u4f5c\u8005\u63d0\u51fa\u4f7f\u7528\u56e0\u679c\u62bd\u8c61\uff08\u7b80\u5316\u7684\u56e0\u679c\u8868\u793a\uff09\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5e76\u7814\u7a76\u4e86\u5728\u6b64\u6846\u67b6\u4e0b\u7684\u53ef\u8bc6\u522b\u6027\u6807\u51c6\u3002", "motivation": "\u5728\u590d\u6742\u6216\u9ad8\u7ef4\u73af\u5883\u4e2d\uff0c\u5b8c\u5168\u6307\u5b9a\u7684\u56e0\u679c\u56fe\u5f80\u5f80\u672a\u77e5\uff0c\u9650\u5236\u4e86\u56e0\u679c\u6548\u5e94\u7684\u8bc6\u522b\u3002\u56e0\u679c\u62bd\u8c61\u63d0\u4f9b\u4e86\u4e00\u79cd\u90e8\u5206\u4fdd\u7559\u56e0\u679c\u4fe1\u606f\u7684\u7b80\u5316\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u5f62\u5f0f\u5316\u4e86\u56e0\u679c\u62bd\u8c61\u7684\u96c6\u5408\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u4e2a\u53ef\u8bc6\u522b\u6027\u6807\u51c6\uff0c\u5c06\u5176\u7ec4\u7ec7\u6210\u5c42\u6b21\u7ed3\u6784\u4ee5\u660e\u786e\u5173\u7cfb\u3002", "result": "\u901a\u8fc7\u5c42\u6b21\u5316\u7684\u53ef\u8bc6\u522b\u6027\u6807\u51c6\uff0c\u8bba\u6587\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u56e0\u679c\u77e5\u8bc6\u6c34\u5e73\u4e0b\u53ef\u4ee5\u8bc6\u522b\u7684\u5185\u5bb9\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u56e0\u679c\u6548\u5e94\u7684\u8bc6\u522b\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u5de5\u5177\uff0c\u5c24\u5176\u662f\u5728\u7f3a\u4e4f\u5b8c\u6574\u56e0\u679c\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2507.06221", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2507.06221", "abs": "https://arxiv.org/abs/2507.06221", "authors": ["Yuxuan Lu", "Yifan Wu", "Jason Hartline", "Michael J. Curry"], "title": "Aligned Textual Scoring Rules", "comment": null, "summary": "Scoring rules elicit probabilistic predictions from a strategic agent by\nscoring the prediction against a ground truth state. A scoring rule is proper\nif, from the agent's perspective, reporting the true belief maximizes the\nexpected score. With the development of language models, Wu and Hartline (2024)\nproposes a reduction from textual information elicitation to the numerical\n(i.e. probabilistic) information elicitation problem, which achieves provable\nproperness for textual elicitation. However, not all proper scoring rules are\nwell aligned with human preference over text. Our paper designs the Aligned\nScoring rule (ASR) for text by optimizing and minimizing the mean squared error\nbetween a proper scoring rule and a reference score (e.g. human score). Our\nexperiments show that our ASR outperforms previous methods in aligning with\nhuman preference while maintaining properness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u9f50\u8bc4\u5206\u89c4\u5219\uff08ASR\uff09\uff0c\u901a\u8fc7\u4f18\u5316\u5747\u65b9\u8bef\u5dee\u6765\u5bf9\u9f50\u4eba\u7c7b\u504f\u597d\uff0c\u540c\u65f6\u4fdd\u6301\u8bc4\u5206\u89c4\u5219\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6b63\u786e\u8bc4\u5206\u89c4\u5219\u5728\u6587\u672c\u4fe1\u606f\u83b7\u53d6\u4e2d\u4e0d\u4e00\u5b9a\u4e0e\u4eba\u7c7b\u504f\u597d\u4e00\u81f4\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u6b63\u786e\u6027\u53c8\u80fd\u5bf9\u9f50\u4eba\u7c7b\u504f\u597d\u7684\u8bc4\u5206\u89c4\u5219\u3002", "method": "\u8bbe\u8ba1ASR\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6b63\u786e\u8bc4\u5206\u89c4\u5219\u4e0e\u53c2\u8003\u8bc4\u5206\uff08\u5982\u4eba\u7c7b\u8bc4\u5206\uff09\u4e4b\u95f4\u7684\u5747\u65b9\u8bef\u5dee\u6765\u4f18\u5316\u5bf9\u9f50\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cASR\u5728\u4fdd\u6301\u6b63\u786e\u6027\u7684\u540c\u65f6\uff0c\u6bd4\u4e4b\u524d\u7684\u65b9\u6cd5\u66f4\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u3002", "conclusion": "ASR\u662f\u4e00\u79cd\u6709\u6548\u7684\u8bc4\u5206\u89c4\u5219\uff0c\u65e2\u80fd\u4fdd\u8bc1\u6b63\u786e\u6027\uff0c\u53c8\u80fd\u66f4\u597d\u5730\u5bf9\u9f50\u4eba\u7c7b\u504f\u597d\u3002"}}
