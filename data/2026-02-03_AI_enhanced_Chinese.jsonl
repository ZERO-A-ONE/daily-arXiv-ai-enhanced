{"id": "2601.22269", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22269", "abs": "https://arxiv.org/abs/2601.22269", "authors": ["Sahil Garg", "Brad Cheezum", "Sridhar Dutta", "Vishal Agarwal"], "title": "JAF: Judge Agent Forest", "comment": null, "summary": "Judge agents are fundamental to agentic AI frameworks: they provide automated evaluation, and enable iterative self-refinement of reasoning processes. We introduce JAF: Judge Agent Forest, a framework in which the judge agent conducts joint inference across a cohort of query--response pairs generated by a primary agent, rather than evaluating each in isolation. This paradigm elevates the judge from a local evaluator to a holistic learner: by simultaneously assessing related responses, the judge discerns cross-instance patterns and inconsistencies, whose aggregate feedback enables the primary agent to improve by viewing its own outputs through the judge's collective perspective.\n  Conceptually, JAF bridges belief propagation and ensemble-learning principles: overlapping in-context neighborhoods induce a knowledge-graph structure that facilitates propagation of critique, and repeated, randomized evaluations yield a robust ensemble of context-sensitive judgments. JAF can be instantiated entirely via ICL, with the judge prompted for each query using its associated primary-agent response plus a small, possibly noisy set of peer exemplars. While kNN in embedding space is a natural starting point for exemplars, this approach overlooks categorical structure, domain metadata, or nuanced distinctions accessible to modern LLMs.\n  To overcome these limitations, we develop a flexible locality-sensitive hashing (LSH) algorithm that learns informative binary codes by integrating semantic embeddings, LLM-driven hash predicates, supervision from categorical labels, and relevant side information. These hash codes support efficient, interpretable, and relation-aware selection of diverse exemplars, and further optimize exploration of CoT reasoning paths. We validate JAF with an empirical study on the demanding task of cloud misconfigs triage in large-scale cloud environments.", "AI": {"tldr": "JAF\u6846\u67b6\u901a\u8fc7\u8ba9\u8bc4\u5224\u667a\u80fd\u4f53\u540c\u65f6\u8bc4\u4f30\u591a\u4e2a\u76f8\u5173\u67e5\u8be2-\u54cd\u5e94\u5bf9\uff0c\u5b9e\u73b0\u4ece\u5c40\u90e8\u8bc4\u4f30\u5230\u6574\u4f53\u5b66\u4e60\u7684\u8f6c\u53d8\uff0c\u5229\u7528\u4fe1\u5ff5\u4f20\u64ad\u548c\u96c6\u6210\u5b66\u4e60\u539f\u7406\u63d0\u5347\u667a\u80fd\u4f53\u6027\u80fd", "motivation": "\u4f20\u7edf\u8bc4\u5224\u667a\u80fd\u4f53\u5355\u72ec\u8bc4\u4f30\u6bcf\u4e2a\u67e5\u8be2-\u54cd\u5e94\u5bf9\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8bc6\u522b\u8de8\u5b9e\u4f8b\u6a21\u5f0f\u548c\u4e00\u81f4\u6027\u7684\u6574\u4f53\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u667a\u80fd\u4f53\u7684\u81ea\u6211\u6539\u8fdb\u80fd\u529b", "method": "\u63d0\u51faJAF\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u7684\u7b97\u6cd5\uff0c\u6574\u5408\u8bed\u4e49\u5d4c\u5165\u3001LLM\u9a71\u52a8\u7684\u54c8\u5e0c\u8c13\u8bcd\u3001\u7c7b\u522b\u6807\u7b7e\u76d1\u7763\u548c\u76f8\u5173\u4fa7\u4fe1\u606f\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u3001\u5173\u7cfb\u611f\u77e5\u7684\u8303\u4f8b\u9009\u62e9", "result": "\u5728\u4e91\u914d\u7f6e\u9519\u8bef\u5206\u7c7b\u7684\u590d\u6742\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86JAF\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5927\u578b\u4e91\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c", "conclusion": "JAF\u6846\u67b6\u901a\u8fc7\u96c6\u4f53\u63a8\u7406\u548c\u96c6\u6210\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc4\u5224\u667a\u80fd\u4f53\u7684\u8bc4\u4f30\u8d28\u91cf\u548c\u667a\u80fd\u4f53\u7684\u81ea\u6211\u6539\u8fdb\u80fd\u529b\uff0c\u4e3a\u667a\u80fd\u4f53AI\u6846\u67b6\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc4\u4f30\u8303\u5f0f"}}
{"id": "2601.22182", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22182", "abs": "https://arxiv.org/abs/2601.22182", "authors": ["Yizhong Ding"], "title": "ShellForge: Adversarial Co-Evolution of Webshell Generation and Multi-View Detection for Robust Webshell Defense", "comment": null, "summary": "Webshells remain a primary foothold for attackers to compromise servers, particularly within PHP ecosystems. However, existing detection mechanisms often struggle to keep pace with rapid variant evolution and sophisticated obfuscation techniques that camouflage malicious intent. Furthermore, many current defenses suffer from high false-alarm rates when encountering benign administrative scripts that employ heavy obfuscation for intellectual property protection. To address these challenges, we present ShellForge, an adversarial co-evolution framework that couples automated webshell generation with multi-view detection to continuously harden defensive boundaries. The framework operates through an iterative co-training loop where a generator and a detector mutually reinforce each other via the exchange of hard samples. The generator is optimized through supervised fine-tuning and preference-based reinforcement learning to synthesize functional, highly evasive variants. Simultaneously, we develop a multi-view fusion detector that integrates semantic features from long-string compression, structural features from pruned abstract syntax trees, and global statistical indicators such as Shannon entropy. To minimize false positives, ShellForge utilizes a LLM-based transformation to create de-malicious samples--scripts that retain complex obfuscation patterns but lack harmful payloads--serving as high-quality hard negatives during training. Evaluations on the public FWOID benchmark demonstrate that ShellForge significantly enhances defensive robustness. Upon convergence, the detector maintains a 0.981 F1-score while the generator achieves a 0.939 evasion rate against commercial engines on VirusTotal.", "AI": {"tldr": "ShellForge\u662f\u4e00\u4e2a\u5bf9\u6297\u6027\u534f\u540c\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316webshell\u751f\u6210\u548c\u591a\u89c6\u56fe\u68c0\u6d4b\u6765\u589e\u5f3aPHP webshell\u9632\u5fa1\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u5e76\u964d\u4f4e\u8bef\u62a5\u7387\u3002", "motivation": "\u73b0\u6709webshell\u68c0\u6d4b\u673a\u5236\u96be\u4ee5\u5e94\u5bf9\u5feb\u901f\u53d8\u79cd\u548c\u590d\u6742\u6df7\u6dc6\u6280\u672f\uff0c\u4e14\u5728\u9762\u5bf9\u7528\u4e8e\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7684\u826f\u6027\u6df7\u6dc6\u811a\u672c\u65f6\u8bef\u62a5\u7387\u9ad8\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u9632\u5fa1\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5bf9\u6297\u6027\u534f\u540c\u8bad\u7ec3\u6846\u67b6\uff0c\u5305\u542b\u751f\u6210\u5668\u548c\u68c0\u6d4b\u5668\u7684\u8fed\u4ee3\u5faa\u73af\u3002\u751f\u6210\u5668\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u57fa\u4e8e\u504f\u597d\u7684\u5f3a\u5316\u5b66\u4e60\u5408\u6210\u529f\u80fd\u6027\u5f3a\u3001\u9ad8\u5ea6\u89c4\u907f\u7684\u53d8\u79cd\uff1b\u68c0\u6d4b\u5668\u878d\u5408\u957f\u5b57\u7b26\u4e32\u538b\u7f29\u7684\u8bed\u4e49\u7279\u5f81\u3001\u4fee\u526a\u62bd\u8c61\u8bed\u6cd5\u6811\u7684\u7ed3\u6784\u7279\u5f81\u548c\u9999\u519c\u71b5\u7b49\u5168\u5c40\u7edf\u8ba1\u6307\u6807\uff1b\u4f7f\u7528LLM\u751f\u6210\u53bb\u6076\u610f\u6837\u672c\u4f5c\u4e3a\u9ad8\u8d28\u91cf\u8d1f\u6837\u672c\u3002", "result": "\u5728FWOID\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u68c0\u6d4b\u5668\u6536\u655b\u540e\u4fdd\u63010.981\u7684F1\u5206\u6570\uff0c\u751f\u6210\u5668\u5728VirusTotal\u4e0a\u5bf9\u5546\u4e1a\u5f15\u64ce\u8fbe\u52300.939\u7684\u89c4\u907f\u7387\uff0c\u663e\u8457\u63d0\u5347\u9632\u5fa1\u9c81\u68d2\u6027\u3002", "conclusion": "ShellForge\u901a\u8fc7\u5bf9\u6297\u6027\u534f\u540c\u8fdb\u5316\u6709\u6548\u5e94\u5bf9webshell\u53d8\u79cd\u548c\u6df7\u6dc6\u6311\u6218\uff0c\u5728\u4fdd\u6301\u9ad8\u68c0\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u8bef\u62a5\uff0c\u4e3a\u670d\u52a1\u5668\u5b89\u5168\u63d0\u4f9b\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2601.22196", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.22196", "abs": "https://arxiv.org/abs/2601.22196", "authors": ["Piotr Przymus", "Witold Weiner", "Krzysztof Rykaczewski", "Gunnar Kudrjavets"], "title": "Linux Kernel Recency Matters, CVE Severity Doesn't, and History Fades", "comment": null, "summary": "In 2024, the Linux kernel became its own Common Vulnerabilities and Exposures (CVE) Numbering Authority (CNA), formalizing how kernel vulnerabilities are identified and tracked. We analyze the anatomy and dynamics of kernel CVEs using metadata, associated commits, and patch latency to understand what drives patching. Results show that severity and Common Vulnerability Scoring System (CVSS) metrics have a negligible association with patch latency, whereas kernel recency is a reasonable predictor in survival models. Kernel developers fix newer kernels sooner, while older ones retain unresolved CVEs. Commits introducing vulnerabilities are typically broader and more complex than their fixes, though often only approximate reconstructions of development history. The Linux kernel remains a unique open-source project -- its CVE process is no exception.", "AI": {"tldr": "Linux\u5185\u6838\u6210\u4e3a\u81ea\u5df1\u7684CNA\u540e\uff0c\u7814\u7a76\u53d1\u73b0\u5185\u6838\u6f0f\u6d1e\u4fee\u590d\u5ef6\u8fdf\u4e0e\u4e25\u91cd\u6027\u8bc4\u5206\u5173\u8054\u5fae\u5f31\uff0c\u5185\u6838\u65b0\u65e7\u7a0b\u5ea6\u624d\u662f\u5173\u952e\u9884\u6d4b\u56e0\u7d20\uff0c\u65b0\u5185\u6838\u4fee\u590d\u66f4\u5feb\uff0c\u65e7\u5185\u6838\u9057\u7559\u6f0f\u6d1e\u66f4\u591a", "motivation": "\u7814\u7a76Linux\u5185\u6838\u6210\u4e3a\u81ea\u5df1\u7684CVE\u7f16\u53f7\u673a\u6784\u540e\uff0c\u5206\u6790\u5185\u6838\u6f0f\u6d1e\u7684\u89e3\u5256\u7ed3\u6784\u548c\u52a8\u6001\u7279\u5f81\uff0c\u4e86\u89e3\u9a71\u52a8\u5185\u6838\u6f0f\u6d1e\u4fee\u590d\u7684\u5173\u952e\u56e0\u7d20\uff0c\u7279\u522b\u662f\u4e3a\u4ec0\u4e48\u67d0\u4e9b\u6f0f\u6d1e\u4fee\u590d\u66f4\u5feb\u800c\u5176\u4ed6\u6f0f\u6d1e\u957f\u671f\u5b58\u5728", "method": "\u4f7f\u7528\u5143\u6570\u636e\u3001\u76f8\u5173\u63d0\u4ea4\u8bb0\u5f55\u548c\u8865\u4e01\u5ef6\u8fdf\u6570\u636e\u8fdb\u884c\u5206\u6790\uff0c\u901a\u8fc7\u751f\u5b58\u6a21\u578b\u7814\u7a76\u5185\u6838\u6f0f\u6d1e\u4fee\u590d\u7684\u52a8\u6001\u7279\u5f81\uff0c\u6bd4\u8f83\u5f15\u5165\u6f0f\u6d1e\u7684\u63d0\u4ea4\u4e0e\u4fee\u590d\u63d0\u4ea4\u7684\u590d\u6742\u5ea6\u548c\u8303\u56f4", "result": "\u4e25\u91cd\u6027\u548cCVSS\u8bc4\u5206\u6307\u6807\u4e0e\u8865\u4e01\u5ef6\u8fdf\u5173\u8054\u5fae\u5f31\uff1b\u5185\u6838\u65b0\u65e7\u7a0b\u5ea6\u662f\u5408\u7406\u7684\u9884\u6d4b\u56e0\u7d20\uff0c\u65b0\u5185\u6838\u4fee\u590d\u66f4\u5feb\uff0c\u65e7\u5185\u6838\u4fdd\u7559\u672a\u89e3\u51b3\u7684CVE\uff1b\u5f15\u5165\u6f0f\u6d1e\u7684\u63d0\u4ea4\u901a\u5e38\u6bd4\u4fee\u590d\u63d0\u4ea4\u66f4\u5e7f\u6cdb\u548c\u590d\u6742", "conclusion": "Linux\u5185\u6838\u7684CVE\u6d41\u7a0b\u5177\u6709\u72ec\u7279\u6027\uff0c\u6f0f\u6d1e\u4fee\u590d\u4e3b\u8981\u53d7\u5185\u6838\u65b0\u65e7\u7a0b\u5ea6\u9a71\u52a8\u800c\u975e\u4f20\u7edf\u5b89\u5168\u6307\u6807\uff0c\u8fd9\u53cd\u6620\u4e86\u5185\u6838\u4f5c\u4e3a\u72ec\u7279\u5f00\u6e90\u9879\u76ee\u7684\u7279\u6027"}}
{"id": "2601.22185", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.22185", "abs": "https://arxiv.org/abs/2601.22185", "authors": ["Alberto Maria Mongardini", "Alessandro Mei"], "title": "MemeChain: A Multimodal Cross-Chain Dataset for Meme Coin Forensics and Risk Analysis", "comment": null, "summary": "The meme coin ecosystem has grown into one of the most active yet least observable segments of the cryptocurrency market, characterized by extreme churn, minimal project commitment, and widespread fraudulent behavior. While countless meme coins are deployed across multiple blockchains, they rely heavily on off-chain web and social infrastructure to signal legitimacy. These very signals are largely absent from existing datasets, which are often limited to single-chain data or lack the multimodal artifacts required for comprehensive risk modeling.\n  To address this gap, we introduce MemeChain, a large-scale, open-source, cross-chain dataset comprising 34,988 meme coins across Ethereum, BNB Smart Chain, Solana, and Base. MemeChain integrates on-chain data with off-chain artifacts, including website HTML source code, token logos, and linked social media accounts, enabling multimodal and forensic study of meme coin projects. Analysis of the dataset shows that visual branding is frequently omitted in low-effort deployments, and many projects lack a functional website. Moreover, we quantify the ecosystem's extreme volatility, identifying 1,801 tokens (5.15%) that cease all trading activity within just 24 hours of launch. By providing unified cross-chain coverage and rich off-chain context, MemeChain serves as a foundational resource for research in financial forensics, multimodal anomaly detection, and automated scam prevention in the meme coin ecosystem.", "AI": {"tldr": "MemeChain\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u5f00\u6e90\u3001\u8de8\u94fe\u6570\u636e\u96c6\uff0c\u5305\u542b34,988\u4e2a\u6a21\u56e0\u5e01\uff0c\u6574\u5408\u4e86\u94fe\u4e0a\u6570\u636e\u548c\u94fe\u4e0b\u5de5\u4ef6\uff08\u7f51\u7ad9HTML\u3001\u4ee3\u5e01logo\u3001\u793e\u4ea4\u5a92\u4f53\u8d26\u6237\uff09\uff0c\u7528\u4e8e\u6a21\u56e0\u5e01\u751f\u6001\u7cfb\u7edf\u7684\u591a\u6a21\u6001\u548c\u6cd5\u8bc1\u7814\u7a76\u3002", "motivation": "\u6a21\u56e0\u5e01\u751f\u6001\u7cfb\u7edf\u662f\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u4e2d\u6700\u6d3b\u8dc3\u4f46\u6700\u4e0d\u53ef\u89c2\u6d4b\u7684\u9886\u57df\uff0c\u5177\u6709\u6781\u7aef\u6d41\u5931\u7387\u3001\u6700\u4f4e\u9879\u76ee\u627f\u8bfa\u548c\u5e7f\u6cdb\u6b3a\u8bc8\u884c\u4e3a\u3002\u73b0\u6709\u6570\u636e\u96c6\u901a\u5e38\u9650\u4e8e\u5355\u94fe\u6570\u636e\u6216\u7f3a\u4e4f\u591a\u6a21\u6001\u5de5\u4ef6\uff0c\u65e0\u6cd5\u8fdb\u884c\u5168\u9762\u7684\u98ce\u9669\u5efa\u6a21\u3002", "method": "\u6784\u5efaMemeChain\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4ee5\u592a\u574a\u3001BNB\u667a\u80fd\u94fe\u3001Solana\u548cBase\u56db\u4e2a\u533a\u5757\u94fe\u4e0a\u768434,988\u4e2a\u6a21\u56e0\u5e01\uff0c\u6574\u5408\u94fe\u4e0a\u6570\u636e\u4e0e\u94fe\u4e0b\u5de5\u4ef6\uff08\u7f51\u7ad9HTML\u6e90\u4ee3\u7801\u3001\u4ee3\u5e01logo\u3001\u94fe\u63a5\u7684\u793e\u4ea4\u5a92\u4f53\u8d26\u6237\uff09\u3002", "result": "\u5206\u6790\u663e\u793a\uff1a1\uff09\u89c6\u89c9\u54c1\u724c\u5728\u4f4e\u8d28\u91cf\u90e8\u7f72\u4e2d\u7ecf\u5e38\u88ab\u7701\u7565\uff1b2\uff09\u8bb8\u591a\u9879\u76ee\u7f3a\u4e4f\u529f\u80fd\u6027\u7f51\u7ad9\uff1b3\uff09\u751f\u6001\u7cfb\u7edf\u6781\u7aef\u6ce2\u52a8\uff0c1,801\u4e2a\u4ee3\u5e01\uff085.15%\uff09\u5728\u542f\u52a8\u540e24\u5c0f\u65f6\u5185\u505c\u6b62\u6240\u6709\u4ea4\u6613\u6d3b\u52a8\u3002", "conclusion": "MemeChain\u901a\u8fc7\u63d0\u4f9b\u7edf\u4e00\u7684\u8de8\u94fe\u8986\u76d6\u548c\u4e30\u5bcc\u7684\u94fe\u4e0b\u4e0a\u4e0b\u6587\uff0c\u6210\u4e3a\u6a21\u56e0\u5e01\u751f\u6001\u7cfb\u7edf\u4e2d\u91d1\u878d\u6cd5\u8bc1\u3001\u591a\u6a21\u6001\u5f02\u5e38\u68c0\u6d4b\u548c\u81ea\u52a8\u8bc8\u9a97\u9884\u9632\u7814\u7a76\u7684\u57fa\u7840\u8d44\u6e90\u3002"}}
{"id": "2601.22208", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22208", "abs": "https://arxiv.org/abs/2601.22208", "authors": ["Evelien Riddell", "James Riddell", "Gengyi Sun", "Micha\u0142 Antkiewicz", "Krzysztof Czarnecki"], "title": "Stalled, Biased, and Confused: Uncovering Reasoning Failures in LLMs for Cloud-Based Root Cause Analysis", "comment": "FORGE 2026", "summary": "Root cause analysis (RCA) is essential for diagnosing failures within complex software systems to ensure system reliability. The highly distributed and interdependent nature of modern cloud-based systems often complicates RCA efforts, particularly for multi-hop fault propagation, where symptoms appear far from their true causes. Recent advancements in Large Language Models (LLMs) present new opportunities to enhance automated RCA. However, their practical value for RCA depends on the fidelity of reasoning and decision-making. Existing work relies on historical incident corpora, operates directly on high-volume telemetry beyond current LLM capacity, or embeds reasoning inside complex multi-agent pipelines -- conditions that obscure whether failures arise from reasoning itself or from peripheral design choices.\n  We present a focused empirical evaluation that isolates an LLM's reasoning behavior. We design a controlled experimental framework that foregrounds the LLM by using a simplified experimental setting. We evaluate six LLMs under two agentic workflows (ReAct and Plan-and-Execute) and a non-agentic baseline on two real-world case studies (GAIA and OpenRCA). In total, we executed 48,000 simulated failure scenarios, totaling 228 days of execution time. We measure both root-cause accuracy and the quality of intermediate reasoning traces. We produce a labeled taxonomy of 16 common RCA reasoning failures and use an LLM-as-a-Judge for annotation. Our results clarify where current open-source LLMs succeed and fail in multi-hop RCA, quantify sensitivity to input data modalities, and identify reasoning failures that predict final correctness. Together, these contributions provide transparent and reproducible empirical results and a failure taxonomy to guide future work on reasoning-driven system diagnosis.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u53d7\u63a7\u5b9e\u9a8c\u6846\u67b6\u8bc4\u4f30LLM\u5728\u591a\u8df3\u6839\u56e0\u5206\u6790\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u6d4b\u8bd5\u4e866\u4e2aLLM\u5728\u4e24\u79cd\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e0b\u7684\u8868\u73b0\uff0c\u6267\u884c\u4e8648,000\u4e2a\u6545\u969c\u573a\u666f\uff0c\u5e76\u5efa\u7acb\u4e8616\u79cd\u5e38\u89c1\u63a8\u7406\u5931\u8d25\u7684\u5206\u7c7b\u4f53\u7cfb\u3002", "motivation": "\u73b0\u4ee3\u4e91\u7cfb\u7edf\u7684\u9ad8\u5ea6\u5206\u5e03\u5f0f\u548c\u76f8\u4e92\u4f9d\u8d56\u6027\u4f7f\u6839\u56e0\u5206\u6790\u53d8\u5f97\u590d\u6742\uff0c\u7279\u522b\u662f\u591a\u8df3\u6545\u969c\u4f20\u64ad\u95ee\u9898\u3002\u867d\u7136LLM\u4e3a\u81ea\u52a8\u5316RCA\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\uff0c\u4f46\u5176\u5b9e\u7528\u4ef7\u503c\u53d6\u51b3\u4e8e\u63a8\u7406\u548c\u51b3\u7b56\u7684\u4fdd\u771f\u5ea6\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5386\u53f2\u4e8b\u4ef6\u8bed\u6599\u5e93\u3001\u5904\u7406\u8d85\u51faLLM\u5bb9\u91cf\u7684\u6d77\u91cf\u9065\u6d4b\u6570\u636e\uff0c\u6216\u5c06\u63a8\u7406\u5d4c\u5165\u590d\u6742\u591a\u667a\u80fd\u4f53\u7ba1\u9053\uff0c\u8fd9\u4e9b\u6761\u4ef6\u6a21\u7cca\u4e86\u5931\u8d25\u662f\u6e90\u4e8e\u63a8\u7406\u672c\u8eab\u8fd8\u662f\u5916\u56f4\u8bbe\u8ba1\u9009\u62e9\u3002", "method": "\u8bbe\u8ba1\u4e86\u53d7\u63a7\u5b9e\u9a8c\u6846\u67b6\uff0c\u901a\u8fc7\u7b80\u5316\u5b9e\u9a8c\u8bbe\u7f6e\u7a81\u51faLLM\u7684\u63a8\u7406\u884c\u4e3a\u3002\u8bc4\u4f30\u4e866\u4e2aLLM\u5728\u4e24\u79cd\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff08ReAct\u548cPlan-and-Execute\uff09\u548c\u4e00\u4e2a\u975e\u667a\u80fd\u4f53\u57fa\u7ebf\u4e0b\u7684\u8868\u73b0\uff0c\u4f7f\u7528\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u6848\u4f8b\u7814\u7a76\uff08GAIA\u548cOpenRCA\uff09\u3002\u6267\u884c\u4e8648,000\u4e2a\u6a21\u62df\u6545\u969c\u573a\u666f\uff0c\u6d4b\u91cf\u6839\u56e0\u51c6\u786e\u6027\u548c\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\u3002\u5efa\u7acb\u4e8616\u79cd\u5e38\u89c1RCA\u63a8\u7406\u5931\u8d25\u7684\u6807\u8bb0\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u4f7f\u7528LLM-as-a-Judge\u8fdb\u884c\u6807\u6ce8\u3002", "result": "\u7814\u7a76\u9610\u660e\u4e86\u5f53\u524d\u5f00\u6e90LLM\u5728\u591a\u8df3RCA\u4e2d\u7684\u6210\u529f\u548c\u5931\u8d25\u4e4b\u5904\uff0c\u91cf\u5316\u4e86\u5bf9\u8f93\u5165\u6570\u636e\u6a21\u6001\u7684\u654f\u611f\u6027\uff0c\u5e76\u8bc6\u522b\u4e86\u80fd\u591f\u9884\u6d4b\u6700\u7ec8\u6b63\u786e\u6027\u7684\u63a8\u7406\u5931\u8d25\u6a21\u5f0f\u3002\u63d0\u4f9b\u4e86\u900f\u660e\u53ef\u590d\u73b0\u7684\u5b9e\u8bc1\u7ed3\u679c\u548c\u5931\u8d25\u5206\u7c7b\u4f53\u7cfb\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u63a8\u7406\u9a71\u52a8\u7684\u7cfb\u7edf\u8bca\u65ad\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u548c\u6307\u5bfc\u6846\u67b6\uff0c\u901a\u8fc7\u9694\u79bbLLM\u7684\u63a8\u7406\u884c\u4e3a\uff0c\u660e\u786e\u4e86\u5f53\u524dLLM\u5728\u590d\u6742\u6839\u56e0\u5206\u6790\u4e2d\u7684\u80fd\u529b\u8fb9\u754c\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2601.22401", "categories": ["cs.AI", "math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2601.22401", "abs": "https://arxiv.org/abs/2601.22401", "authors": ["Tony Feng", "Trieu Trinh", "Garrett Bingham", "Jiwon Kang", "Shengtong Zhang", "Sang-hyun Kim", "Kevin Barreto", "Carl Schildkraut", "Junehyuk Jung", "Jaehyeon Seo", "Carlo Pagano", "Yuri Chervonyi", "Dawsen Hwang", "Kaiying Hou", "Sergei Gukov", "Cheng-Chiang Tsai", "Hyunwoo Choi", "Youngbeom Jin", "Wei-Yuan Li", "Hao-An Wu", "Ruey-An Shiu", "Yu-Sheng Shih", "Quoc V. Le", "Thang Luong"], "title": "Semi-Autonomous Mathematics Discovery with Gemini: A Case Study on the Erd\u0151s Problems", "comment": null, "summary": "We present a case study in semi-autonomous mathematics discovery, using Gemini to systematically evaluate 700 conjectures labeled 'Open' in Bloom's Erd\u0151s Problems database. We employ a hybrid methodology: AI-driven natural language verification to narrow the search space, followed by human expert evaluation to gauge correctness and novelty. We address 13 problems that were marked 'Open' in the database: 5 through seemingly novel autonomous solutions, and 8 through identification of previous solutions in the existing literature. Our findings suggest that the 'Open' status of the problems was through obscurity rather than difficulty. We also identify and discuss issues arising in applying AI to math conjectures at scale, highlighting the difficulty of literature identification and the risk of ''subconscious plagiarism'' by AI. We reflect on the takeaways from AI-assisted efforts on the Erd\u0151s Problems.", "AI": {"tldr": "\u4f7f\u7528Gemini AI\u7cfb\u7edf\u8bc4\u4f30Bloom\u7684Erd\u0151s\u95ee\u9898\u6570\u636e\u5e93\u4e2d700\u4e2a\u6807\u8bb0\u4e3a\"\u5f00\u653e\"\u7684\u731c\u60f3\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\uff08AI\u81ea\u7136\u8bed\u8a00\u9a8c\u8bc1+\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4f30\uff09\u89e3\u51b3\u4e8613\u4e2a\u95ee\u9898\uff0c\u53d1\u73b0\u8fd9\u4e9b\u95ee\u9898\u7684\"\u5f00\u653e\"\u72b6\u6001\u66f4\u591a\u662f\u7531\u4e8e\u6587\u732e\u96be\u4ee5\u67e5\u627e\u800c\u975e\u95ee\u9898\u672c\u8eab\u56f0\u96be\u3002", "motivation": "\u63a2\u7d22\u534a\u81ea\u4e3b\u6570\u5b66\u53d1\u73b0\u7684\u53ef\u80fd\u6027\uff0c\u6d4b\u8bd5AI\u5728\u7cfb\u7edf\u8bc4\u4f30\u6570\u5b66\u731c\u60f3\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u9488\u5bf9Erd\u0151s\u95ee\u9898\u6570\u636e\u5e93\u4e2d\u6807\u8bb0\u4e3a\"\u5f00\u653e\"\u4f46\u53ef\u80fd\u5df2\u6709\u89e3\u51b3\u65b9\u6848\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a1) AI\u9a71\u52a8\u7684\u81ea\u7136\u8bed\u8a00\u9a8c\u8bc1\u6765\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff1b2) \u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4f30\u4ee5\u5224\u65ad\u6b63\u786e\u6027\u548c\u65b0\u9896\u6027\u3002\u4f7f\u7528Gemini AI\u7cfb\u7edf\u8bc4\u4f30\u4e86700\u4e2a\u6807\u8bb0\u4e3a\"\u5f00\u653e\"\u7684Erd\u0151s\u95ee\u9898\u731c\u60f3\u3002", "result": "\u89e3\u51b3\u4e8613\u4e2a\u6807\u8bb0\u4e3a\"\u5f00\u653e\"\u7684\u95ee\u9898\uff1a\u5176\u4e2d5\u4e2a\u901a\u8fc7\u770b\u4f3c\u65b0\u9896\u7684\u81ea\u4e3b\u89e3\u51b3\u65b9\u6848\u89e3\u51b3\uff0c8\u4e2a\u901a\u8fc7\u8bc6\u522b\u73b0\u6709\u6587\u732e\u4e2d\u7684\u5148\u524d\u89e3\u51b3\u65b9\u6848\u89e3\u51b3\u3002\u53d1\u73b0\u8fd9\u4e9b\u95ee\u9898\u7684\"\u5f00\u653e\"\u72b6\u6001\u66f4\u591a\u662f\u7531\u4e8e\u6587\u732e\u96be\u4ee5\u67e5\u627e\uff08obscurity\uff09\u800c\u975e\u95ee\u9898\u672c\u8eab\u56f0\u96be\u3002", "conclusion": "AI\u5728\u6570\u5b66\u731c\u60f3\u8bc4\u4f30\u4e2d\u9762\u4e34\u6587\u732e\u8bc6\u522b\u56f0\u96be\uff0c\u5b58\u5728\"\u6f5c\u610f\u8bc6\u527d\u7a83\"\u98ce\u9669\u3002Erd\u0151s\u95ee\u9898\u7684\"\u5f00\u653e\"\u72b6\u6001\u5f80\u5f80\u662f\u7531\u4e8e\u6587\u732e\u96be\u4ee5\u67e5\u627e\u800c\u975e\u6570\u5b66\u96be\u5ea6\u3002AI\u8f85\u52a9\u65b9\u6cd5\u5728\u6570\u5b66\u53d1\u73b0\u4e2d\u5177\u6709\u6f5c\u529b\u4f46\u9700\u8c28\u614e\u5904\u7406\u6587\u732e\u8bc6\u522b\u95ee\u9898\u3002"}}
{"id": "2601.22240", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22240", "abs": "https://arxiv.org/abs/2601.22240", "authors": ["Pedro H. Barcha Correia", "Ryan W. Achjian", "Diego E. G. Caetano de Oliveira", "Ygor Acacio Maria", "Victor Takashi Hayashi", "Marcos Lopes", "Charles Christian Miers", "Marcos A. Simplicio"], "title": "A Systematic Literature Review on LLM Defenses Against Prompt Injection and Jailbreaking: Expanding NIST Taxonomy", "comment": "27 pages, 14 figures, 11 tables, submitted to Elsevier Computer Science Review", "summary": "The rapid advancement and widespread adoption of generative artificial intelligence (GenAI) and large language models (LLMs) has been accompanied by the emergence of new security vulnerabilities and challenges, such as jailbreaking and other prompt injection attacks. These maliciously crafted inputs can exploit LLMs, causing data leaks, unauthorized actions, or compromised outputs, for instance. As both offensive and defensive prompt injection techniques evolve quickly, a structured understanding of mitigation strategies becomes increasingly important. To address that, this work presents the first systematic literature review on prompt injection mitigation strategies, comprehending 88 studies. Building upon NIST's report on adversarial machine learning, this work contributes to the field through several avenues. First, it identifies studies beyond those documented in NIST's report and other academic reviews and surveys. Second, we propose an extension to NIST taxonomy by introducing additional categories of defenses. Third, by adopting NIST's established terminology and taxonomy as a foundation, we promote consistency and enable future researchers to build upon the standardized taxonomy proposed in this work. Finally, we provide a comprehensive catalog of the reviewed prompt injection defenses, documenting their reported quantitative effectiveness across specific LLMs and attack datasets, while also indicating which solutions are open-source and model-agnostic. This catalog, together with the guidelines presented herein, aims to serve as a practical resource for researchers advancing the field of adversarial machine learning and for developers seeking to implement effective defenses in production systems.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u63d0\u793a\u6ce8\u5165\u7f13\u89e3\u7b56\u7565\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u6db5\u76d688\u9879\u7814\u7a76\uff0c\u6269\u5c55\u4e86NIST\u5bf9\u6297\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u5305\u542b\u91cf\u5316\u6548\u679c\u7684\u5f00\u6e90\u9632\u5fa1\u65b9\u6848\u76ee\u5f55\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u51fa\u73b0\u4e86\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\u5982\u8d8a\u72f1\u548c\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002\u8fd9\u4e9b\u6076\u610f\u8f93\u5165\u53ef\u80fd\u5bfc\u81f4\u6570\u636e\u6cc4\u9732\u3001\u672a\u6388\u6743\u64cd\u4f5c\u7b49\u95ee\u9898\u3002\u7531\u4e8e\u653b\u9632\u6280\u672f\u5feb\u901f\u6f14\u8fdb\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u7f13\u89e3\u7b56\u7565\u7406\u89e3\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u57fa\u4e8eNIST\u5bf9\u6297\u673a\u5668\u5b66\u4e60\u62a5\u544a\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u9632\u5fa1\u5206\u7c7b\u6cd5\uff0c\u5efa\u7acb\u4e86\u5305\u542b88\u9879\u7814\u7a76\u7684\u7efc\u5408\u76ee\u5f55\uff0c\u8bb0\u5f55\u91cf\u5316\u6548\u679c\u3001\u5f00\u6e90\u72b6\u6001\u548c\u6a21\u578b\u65e0\u5173\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u6269\u5c55\u7684NIST\u5206\u7c7b\u6cd5\uff0c\u65b0\u589e\u9632\u5fa1\u7c7b\u522b\uff1b\u521b\u5efa\u4e86\u5168\u9762\u7684\u63d0\u793a\u6ce8\u5165\u9632\u5fa1\u76ee\u5f55\uff0c\u5305\u542b\u5177\u4f53LLM\u548c\u653b\u51fb\u6570\u636e\u96c6\u4e0a\u7684\u91cf\u5316\u6548\u679c\u8bc4\u4f30\uff1b\u8bc6\u522b\u4e86\u5f00\u6e90\u548c\u6a21\u578b\u65e0\u5173\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5bf9\u6297\u673a\u5668\u5b66\u4e60\u9886\u57df\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u5206\u7c7b\u6846\u67b6\u548c\u5b9e\u7528\u8d44\u6e90\u76ee\u5f55\uff0c\u6709\u52a9\u4e8e\u7814\u7a76\u4eba\u5458\u63a8\u8fdb\u8be5\u9886\u57df\u53d1\u5c55\uff0c\u5e76\u4e3a\u5f00\u53d1\u8005\u5728\u751f\u4ea7\u7cfb\u7edf\u4e2d\u5b9e\u65bd\u6709\u6548\u9632\u5fa1\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2601.22418", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22418", "abs": "https://arxiv.org/abs/2601.22418", "authors": ["Julius Sechang Mboli", "Omolara Aderonke Ogungbemi"], "title": "AI-Enabled Waste Classification as a Data-Driven Decision Support Tool for Circular Economy and Urban Sustainability", "comment": "Accepted version of Conference paper", "summary": "Efficient waste sorting is crucial for enabling circular-economy practices and resource recovery in smart cities. This paper evaluates both traditional machine-learning (Random Forest, SVM, AdaBoost) and deep-learning techniques including custom CNNs, VGG16, ResNet50, and three transfer-learning models (DenseNet121, EfficientNetB0, InceptionV3) for binary classification of 25 077 waste images (80/20 train/test split, augmented and resized to 150x150 px). The paper assesses the impact of Principal Component Analysis for dimensionality reduction on traditional models. DenseNet121 achieved the highest accuracy (91 %) and ROC-AUC (0.98), outperforming the best traditional classifier by 20 pp. Principal Component Analysis (PCA) showed negligible benefit for classical methods, whereas transfer learning substantially improved performance under limited-data conditions. Finally, we outline how these models integrate into a real-time Data-Driven Decision Support System for automated waste sorting, highlighting potential reductions in landfill use and lifecycle environmental impacts.)", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5783\u573e\u56fe\u50cf\u4e8c\u5143\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0DenseNet121\u5728\u51c6\u786e\u7387\u548cROC-AUC\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u63a2\u8ba8\u4e86PCA\u5bf9\u4f20\u7edf\u6a21\u578b\u7684\u5f71\u54cd\u4ee5\u53ca\u6a21\u578b\u5728\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u667a\u80fd\u57ce\u5e02\u4e2d\u9ad8\u6548\u7684\u5783\u573e\u5206\u7c7b\u5bf9\u4e8e\u5b9e\u73b0\u5faa\u73af\u7ecf\u6d4e\u548c\u8d44\u6e90\u56de\u6536\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u5783\u573e\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u81ea\u52a8\u5316\u5783\u573e\u5206\u62e3\u7cfb\u7edf\u63d0\u4f9b\u6280\u672f\u652f\u6301\u3002", "method": "\u4f7f\u752825,077\u5f20\u5783\u573e\u56fe\u50cf\uff0880/20\u8bad\u7ec3/\u6d4b\u8bd5\u5206\u5272\uff0c\u589e\u5f3a\u5e76\u8c03\u6574\u81f3150x150\u50cf\u7d20\uff09\uff0c\u8bc4\u4f30\u4f20\u7edf\u673a\u5668\u5b66\u4e60\uff08\u968f\u673a\u68ee\u6797\u3001SVM\u3001AdaBoost\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u81ea\u5b9a\u4e49CNN\u3001VGG16\u3001ResNet50\uff09\u4ee5\u53ca\u4e09\u79cd\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\uff08DenseNet121\u3001EfficientNetB0\u3001InceptionV3\uff09\uff0c\u540c\u65f6\u8bc4\u4f30\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u5bf9\u4f20\u7edf\u6a21\u578b\u7684\u964d\u7ef4\u6548\u679c\u3002", "result": "DenseNet121\u53d6\u5f97\u4e86\u6700\u9ad8\u51c6\u786e\u7387\uff0891%\uff09\u548cROC-AUC\uff080.98\uff09\uff0c\u6bd4\u6700\u4f73\u4f20\u7edf\u5206\u7c7b\u5668\u9ad8\u51fa20\u4e2a\u767e\u5206\u70b9\u3002PCA\u5bf9\u4f20\u7edf\u65b9\u6cd5\u6539\u5584\u6709\u9650\uff0c\u800c\u8fc1\u79fb\u5b66\u4e60\u5728\u6709\u9650\u6570\u636e\u6761\u4ef6\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\u7279\u522b\u662fDenseNet121\u5728\u5783\u573e\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8fd9\u4e9b\u6a21\u578b\u53ef\u4ee5\u96c6\u6210\u5230\u5b9e\u65f6\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u5783\u573e\u5206\u62e3\uff0c\u6709\u671b\u51cf\u5c11\u586b\u57cb\u573a\u4f7f\u7528\u548c\u751f\u547d\u5468\u671f\u73af\u5883\u5f71\u54cd\u3002"}}
{"id": "2601.22246", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22246", "abs": "https://arxiv.org/abs/2601.22246", "authors": ["Ya Jiang", "Massieh Kordi Boroujeny", "Surender Suresh Kumar", "Kai Zeng"], "title": "MirrorMark: A Distortion-Free Multi-Bit Watermark for Large Language Models", "comment": null, "summary": "As large language models (LLMs) become integral to applications such as question answering and content creation, reliable content attribution has become increasingly important. Watermarking is a promising approach, but existing methods either provide only binary signals or distort the sampling distribution, degrading text quality; distortion-free approaches, in turn, often suffer from weak detectability or robustness. We propose MirrorMark, a multi-bit and distortion-free watermark for LLMs. By mirroring sampling randomness in a measure-preserving manner, MirrorMark embeds multi-bit messages without altering the token probability distribution, preserving text quality by design. To improve robustness, we introduce a context-based scheduler that balances token assignments across message positions while remaining resilient to insertions and deletions. We further provide a theoretical analysis of the equal error rate to interpret empirical performance. Experiments show that MirrorMark matches the text quality of non-watermarked generation while achieving substantially stronger detectability: with 54 bits embedded in 300 tokens, it improves bit accuracy by 8-12% and correctly identifies up to 11% more watermarked texts at 1% false positive rate.", "AI": {"tldr": "MirrorMark\u662f\u4e00\u79cd\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6bd4\u7279\u65e0\u5931\u771f\u6c34\u5370\u65b9\u6cd5\uff0c\u901a\u8fc7\u955c\u50cf\u91c7\u6837\u968f\u673a\u6027\u5d4c\u5165\u591a\u6bd4\u7279\u6d88\u606f\u800c\u4e0d\u6539\u53d8token\u6982\u7387\u5206\u5e03\uff0c\u4fdd\u6301\u6587\u672c\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u53ef\u68c0\u6d4b\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u95ee\u7b54\u548c\u5185\u5bb9\u521b\u4f5c\u7b49\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u53ef\u9760\u7684\u5185\u5bb9\u6eaf\u6e90\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u8981\u4e48\u53ea\u80fd\u63d0\u4f9b\u4e8c\u8fdb\u5236\u4fe1\u53f7\uff0c\u8981\u4e48\u4f1a\u626d\u66f2\u91c7\u6837\u5206\u5e03\u964d\u4f4e\u6587\u672c\u8d28\u91cf\uff1b\u800c\u65e0\u5931\u771f\u65b9\u6cd5\u5f80\u5f80\u5b58\u5728\u53ef\u68c0\u6d4b\u6027\u5f31\u6216\u9c81\u68d2\u6027\u5dee\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faMirrorMark\u65b9\u6cd5\uff1a1\uff09\u901a\u8fc7\u955c\u50cf\u91c7\u6837\u968f\u673a\u6027\u7684\u4fdd\u6d4b\u5ea6\u65b9\u5f0f\u5d4c\u5165\u591a\u6bd4\u7279\u6d88\u606f\uff0c\u4e0d\u6539\u53d8token\u6982\u7387\u5206\u5e03\uff1b2\uff09\u5f15\u5165\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u8c03\u5ea6\u5668\uff0c\u5e73\u8861\u6d88\u606f\u4f4d\u7f6e\u95f4\u7684token\u5206\u914d\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u63d2\u5165\u548c\u5220\u9664\u64cd\u4f5c\u7684\u9c81\u68d2\u6027\uff1b3\uff09\u63d0\u4f9b\u7406\u8bba\u5206\u6790\u89e3\u91ca\u7ecf\u9a8c\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMirrorMark\u4e0e\u975e\u6c34\u5370\u751f\u6210\u7684\u6587\u672c\u8d28\u91cf\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u53ef\u68c0\u6d4b\u6027\uff1a\u5728300\u4e2atoken\u4e2d\u5d4c\u516554\u6bd4\u7279\u65f6\uff0c\u6bd4\u7279\u51c6\u786e\u7387\u63d0\u9ad88-12%\uff0c\u57281%\u8bef\u62a5\u7387\u4e0b\u6b63\u786e\u8bc6\u522b\u7684\u6c34\u5370\u6587\u672c\u589e\u52a0\u9ad8\u8fbe11%\u3002", "conclusion": "MirrorMark\u662f\u4e00\u79cd\u6709\u6548\u7684\u591a\u6bd4\u7279\u65e0\u5931\u771f\u6c34\u5370\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u6587\u672c\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6c34\u5370\u7684\u53ef\u68c0\u6d4b\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5bb9\u6eaf\u6e90\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22414", "categories": ["cs.SE", "cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.22414", "abs": "https://arxiv.org/abs/2601.22414", "authors": ["Ibrahim Khalilov", "Chaoran Chen", "Ziang Xiao", "Tianshi Li", "Toby Jia-Jun Li", "Yaxing Yao"], "title": "PriviSense: A Frida-Based Framework for Multi-Sensor Spoofing on Android", "comment": null, "summary": "Mobile apps increasingly rely on real-time sensor and system data to adapt their behavior to user context. While emulators and instrumented builds offer partial solutions, they often fail to support reproducible testing of context-sensitive app behavior on physical devices. We present PriviSense, a Frida-based, on-device toolkit for runtime spoofing of sensor and system signals on rooted Android devices. PriviSense can script and inject time-varying sensor streams (accelerometer, gyroscope, step counter) and system values (battery level, system time, device metadata) into unmodified apps, enabling reproducible on-device experiments without emulators or app rewrites. Our demo validates real-time spoofing on a rooted Android device across five representative sensor-visualization apps. By supporting scriptable and reversible manipulation of these values, PriviSense facilitates testing of app logic, uncovering of context-based behaviors, and privacy-focused analysis. To ensure ethical use, the code is shared upon request with verified researchers.\n  Tool Guide: How to Run PriviSense on Rooted Android https://bit.ly/privisense-guide Demonstration video: https://www.youtube.com/watch?v=4Qwnogcc3pw", "AI": {"tldr": "PriviSense\u662f\u4e00\u4e2a\u57fa\u4e8eFrida\u7684\u5de5\u5177\u5305\uff0c\u53ef\u5728\u5df2root\u7684Android\u8bbe\u5907\u4e0a\u5b9e\u65f6\u4f2a\u9020\u4f20\u611f\u5668\u548c\u7cfb\u7edf\u4fe1\u53f7\uff0c\u652f\u6301\u65e0\u9700\u6a21\u62df\u5668\u6216\u5e94\u7528\u4fee\u6539\u7684\u53ef\u91cd\u590d\u6d4b\u8bd5\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u8d8a\u6765\u8d8a\u4f9d\u8d56\u5b9e\u65f6\u4f20\u611f\u5668\u548c\u7cfb\u7edf\u6570\u636e\u6765\u9002\u5e94\u7528\u6237\u4e0a\u4e0b\u6587\uff0c\u4f46\u6a21\u62df\u5668\u548c\u63d2\u6869\u6784\u5efa\u901a\u5e38\u65e0\u6cd5\u652f\u6301\u5728\u7269\u7406\u8bbe\u5907\u4e0a\u5bf9\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u5e94\u7528\u884c\u4e3a\u8fdb\u884c\u53ef\u91cd\u590d\u6d4b\u8bd5\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eFrida\u7684\u8fd0\u884c\u65f6\u6b3a\u9a97\u6280\u672f\uff0c\u5728\u5df2root\u7684Android\u8bbe\u5907\u4e0a\u811a\u672c\u5316\u548c\u6ce8\u5165\u65f6\u53d8\u4f20\u611f\u5668\u6d41\uff08\u52a0\u901f\u5ea6\u8ba1\u3001\u9640\u87ba\u4eea\u3001\u6b65\u6570\u8ba1\u6570\u5668\uff09\u548c\u7cfb\u7edf\u503c\uff08\u7535\u6c60\u7535\u91cf\u3001\u7cfb\u7edf\u65f6\u95f4\u3001\u8bbe\u5907\u5143\u6570\u636e\uff09\u5230\u672a\u4fee\u6539\u7684\u5e94\u7528\u4e2d\u3002", "result": "\u5728\u5df2root\u7684Android\u8bbe\u5907\u4e0a\u5bf9\u4e94\u4e2a\u4ee3\u8868\u6027\u7684\u4f20\u611f\u5668\u53ef\u89c6\u5316\u5e94\u7528\u8fdb\u884c\u4e86\u5b9e\u65f6\u6b3a\u9a97\u9a8c\u8bc1\uff0c\u652f\u6301\u5bf9\u8fd9\u4e9b\u503c\u7684\u53ef\u811a\u672c\u5316\u548c\u53ef\u9006\u64cd\u4f5c\u3002", "conclusion": "PriviSense\u901a\u8fc7\u652f\u6301\u53ef\u811a\u672c\u5316\u548c\u53ef\u9006\u7684\u64cd\u4f5c\uff0c\u4fc3\u8fdb\u4e86\u5e94\u7528\u903b\u8f91\u6d4b\u8bd5\u3001\u57fa\u4e8e\u4e0a\u4e0b\u6587\u884c\u4e3a\u7684\u53d1\u73b0\u4ee5\u53ca\u9690\u79c1\u91cd\u70b9\u5206\u6790\uff0c\u4e3a\u786e\u4fdd\u4f26\u7406\u4f7f\u7528\uff0c\u4ee3\u7801\u4ec5\u4e0e\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u7814\u7a76\u4eba\u5458\u5171\u4eab\u3002"}}
{"id": "2601.22434", "categories": ["cs.CR", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22434", "abs": "https://arxiv.org/abs/2601.22434", "authors": ["Georgi Ganev", "Emiliano De Cristofaro"], "title": "Rethinking Anonymity Claims in Synthetic Data Generation: A Model-Centric Privacy Attack Perspective", "comment": null, "summary": "Training generative machine learning models to produce synthetic tabular data has become a popular approach for enhancing privacy in data sharing. As this typically involves processing sensitive personal information, releasing either the trained model or generated synthetic datasets can still pose privacy risks. Yet, recent research, commercial deployments, and privacy regulations like the General Data Protection Regulation (GDPR) largely assess anonymity at the level of an individual dataset.\n  In this paper, we rethink anonymity claims about synthetic data from a model-centric perspective and argue that meaningful assessments must account for the capabilities and properties of the underlying generative model and be grounded in state-of-the-art privacy attacks. This perspective better reflects real-world products and deployments, where trained models are often readily accessible for interaction or querying. We interpret the GDPR's definitions of personal data and anonymization under such access assumptions to identify the types of identifiability risks that must be mitigated and map them to privacy attacks across different threat settings. We then argue that synthetic data techniques alone do not ensure sufficient anonymization. Finally, we compare the two mechanisms most commonly used alongside synthetic data -- Differential Privacy (DP) and Similarity-based Privacy Metrics (SBPMs) -- and argue that while DP can offer robust protections against identifiability risks, SBPMs lack adequate safeguards. Overall, our work connects regulatory notions of identifiability with model-centric privacy attacks, enabling more responsible and trustworthy regulatory assessment of synthetic data systems by researchers, practitioners, and policymakers.", "AI": {"tldr": "\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u5408\u6210\u6570\u636e\u7684\u533f\u540d\u6027\u4e3b\u5f20\uff0c\u4ece\u6a21\u578b\u4e2d\u5fc3\u89c6\u89d2\u51fa\u53d1\uff0c\u8ba4\u4e3a\u6709\u610f\u4e49\u7684\u9690\u79c1\u8bc4\u4f30\u5fc5\u987b\u8003\u8651\u5e95\u5c42\u751f\u6210\u6a21\u578b\u7684\u80fd\u529b\u548c\u7279\u6027\uff0c\u5e76\u57fa\u4e8e\u6700\u5148\u8fdb\u7684\u9690\u79c1\u653b\u51fb\u8fdb\u884c\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524d\u5408\u6210\u6570\u636e\u9690\u79c1\u8bc4\u4f30\u4e3b\u8981\u505c\u7559\u5728\u6570\u636e\u96c6\u5c42\u9762\uff0c\u800c\u73b0\u5b9e\u90e8\u7f72\u4e2d\u751f\u6210\u6a21\u578b\u901a\u5e38\u53ef\u88ab\u4ea4\u4e92\u6216\u67e5\u8be2\u3002\u9700\u8981\u4ece\u6a21\u578b\u4e2d\u5fc3\u89c6\u89d2\u91cd\u65b0\u601d\u8003\u533f\u540d\u6027\u4e3b\u5f20\uff0c\u4ee5\u66f4\u597d\u5730\u53cd\u6620\u5b9e\u9645\u4ea7\u54c1\u548c\u90e8\u7f72\u60c5\u51b5\u3002", "method": "1. \u4ece\u6a21\u578b\u4e2d\u5fc3\u89c6\u89d2\u91cd\u65b0\u89e3\u91caGDPR\u4e2d\u4e2a\u4eba\u6570\u636e\u548c\u533f\u540d\u5316\u7684\u5b9a\u4e49\uff1b2. \u8bc6\u522b\u4e0d\u540c\u5a01\u80c1\u573a\u666f\u4e0b\u5fc5\u987b\u7f13\u89e3\u7684\u53ef\u8bc6\u522b\u6027\u98ce\u9669\u7c7b\u578b\uff1b3. \u5c06\u8fd9\u4e9b\u98ce\u9669\u6620\u5c04\u5230\u9690\u79c1\u653b\u51fb\uff1b4. \u6bd4\u8f83\u5dee\u5206\u9690\u79c1(DP)\u548c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u9690\u79c1\u6307\u6807(SBPMs)\u4e24\u79cd\u673a\u5236\u3002", "result": "1. \u5408\u6210\u6570\u636e\u6280\u672f\u672c\u8eab\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u5145\u5206\u7684\u533f\u540d\u5316\uff1b2. \u5dee\u5206\u9690\u79c1(DP)\u80fd\u591f\u63d0\u4f9b\u9488\u5bf9\u53ef\u8bc6\u522b\u6027\u98ce\u9669\u7684\u5f3a\u5927\u4fdd\u62a4\uff1b3. \u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u9690\u79c1\u6307\u6807(SBPMs)\u7f3a\u4e4f\u8db3\u591f\u7684\u4fdd\u62a4\u63aa\u65bd\u3002", "conclusion": "\u901a\u8fc7\u5c06\u76d1\u7ba1\u5c42\u9762\u7684\u53ef\u8bc6\u522b\u6027\u6982\u5ff5\u4e0e\u6a21\u578b\u4e2d\u5fc3\u7684\u9690\u79c1\u653b\u51fb\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u3001\u4ece\u4e1a\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u66f4\u8d1f\u8d23\u4efb\u548c\u53ef\u4fe1\u8d56\u7684\u5408\u6210\u6570\u636e\u7cfb\u7edf\u76d1\u7ba1\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2601.22590", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22590", "abs": "https://arxiv.org/abs/2601.22590", "authors": ["Minxing Wang", "Yintong Huo"], "title": "Small is Beautiful: A Practical and Efficient Log Parsing Framework", "comment": "Accepted by FSE'26", "summary": "Log parsing is a fundamental step in log analysis, partitioning raw logs into constant templates and dynamic variables. While recent semantic-based parsers leveraging Large Language Models (LLMs) exhibit superior generalizability over traditional syntax-based methods, their effectiveness is heavily contingent on model scale. This dependency leads to significant performance collapse when employing smaller, more resource-efficient LLMs. Such degradation creates a major barrier to real-world adoption, where data privacy requirements and computational constraints necessitate the use of succinct models. To bridge this gap, we propose EFParser, an unsupervised LLM-based log parser designed to enhance the capabilities of smaller models through systematic architectural innovation. EFParser introduces a dual-cache system with an adaptive updating mechanism that distinguishes between novel patterns and variations of existing templates. This allows the parser to merge redundant templates and rectify prior errors, maintaining cache consistency. Furthermore, a dedicated correction module acts as a gatekeeper, validating and refining every LLM-generated template before caching to prevent error injection. Empirical evaluations on public large-scale datasets demonstrate that EFParser outperforms state-of-the-art baselines by an average of 12.5% across all metrics when running on smaller LLMs, even surpassing some baselines utilizing large-scale models. Despite its additional validation steps, EFParser maintains high computational efficiency, offering a robust and practical solution for real-world log analysis deployment.", "AI": {"tldr": "EFParser\u662f\u4e00\u79cd\u57fa\u4e8e\u5c0f\u89c4\u6a21LLM\u7684\u65e0\u76d1\u7763\u65e5\u5fd7\u89e3\u6790\u5668\uff0c\u901a\u8fc7\u53cc\u7f13\u5b58\u7cfb\u7edf\u548c\u6821\u6b63\u6a21\u5757\u63d0\u5347\u5c0f\u6a21\u578b\u6027\u80fd\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u65e5\u5fd7\u89e3\u6790\u5668\u867d\u7136\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u4f46\u4e25\u91cd\u4f9d\u8d56\u6a21\u578b\u89c4\u6a21\uff0c\u4f7f\u7528\u5c0f\u6a21\u578b\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\u3002\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u7531\u4e8e\u6570\u636e\u9690\u79c1\u548c\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\uff0c\u9700\u8981\u4f7f\u7528\u66f4\u8f7b\u91cf\u7ea7\u7684\u6a21\u578b\uff0c\u8fd9\u6784\u6210\u4e86\u73b0\u5b9e\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\u3002", "method": "\u63d0\u51faEFParser\uff0c\u91c7\u7528\u53cc\u7f13\u5b58\u7cfb\u7edf\uff08\u5e26\u81ea\u9002\u5e94\u66f4\u65b0\u673a\u5236\uff09\u533a\u5206\u65b0\u6a21\u677f\u548c\u73b0\u6709\u6a21\u677f\u53d8\u4f53\uff0c\u80fd\u591f\u5408\u5e76\u5197\u4f59\u6a21\u677f\u5e76\u4fee\u6b63\u5148\u524d\u9519\u8bef\u3002\u8fd8\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u6821\u6b63\u6a21\u5757\u4f5c\u4e3a\u95e8\u63a7\u5668\uff0c\u9a8c\u8bc1\u548c\u4f18\u5316\u6bcf\u4e2aLLM\u751f\u6210\u7684\u6a21\u677f\u540e\u518d\u7f13\u5b58\uff0c\u9632\u6b62\u9519\u8bef\u6ce8\u5165\u3002", "result": "\u5728\u516c\u5f00\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0cEFParser\u5728\u5c0f\u89c4\u6a21LLM\u4e0a\u8fd0\u884c\u65f6\uff0c\u5728\u6240\u6709\u6307\u6807\u4e0a\u5e73\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf12.5%\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86\u4e00\u4e9b\u4f7f\u7528\u5927\u89c4\u6a21\u6a21\u578b\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u5c3d\u7ba1\u589e\u52a0\u4e86\u9a8c\u8bc1\u6b65\u9aa4\uff0cEFParser\u4ecd\u4fdd\u6301\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "EFParser\u901a\u8fc7\u7cfb\u7edf\u67b6\u6784\u521b\u65b0\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5c0f\u89c4\u6a21LLM\u5728\u65e5\u5fd7\u89e3\u6790\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u65e5\u5fd7\u5206\u6790\u90e8\u7f72\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u5c0f\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002"}}
{"id": "2601.22446", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22446", "abs": "https://arxiv.org/abs/2601.22446", "authors": ["Chengyao Yu", "Hao Zeng", "Youxin Zhu", "Jianguo Huang", "Huajun Zeng", "Bingyi Jing"], "title": "Anytime Safe PAC Efficient Reasoning", "comment": null, "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex tasks but suffer from high computational costs and latency. While selective thinking strategies improve efficiency by routing easy queries to non-thinking models, existing approaches often incur uncontrollable errors, especially in online settings where the performance loss of a non-thinking model is only partially observed and data are non-stationary. To address this, we propose Betting Probably Approximately Correct (B-PAC) reasoning, a principled method that enables anytime safe and efficient online reasoning under partial feedback. Specifically, we utilize inverse propensity scoring estimators to construct test supermartingales for candidate thresholds, and then dynamically adjust the routing threshold based on the accumulated statistical evidence of safety. Theoretically, we establish the anytime-valid performance loss control and the efficiency of B-PAC reasoning. Extensive experiments demonstrate that B-PAC reasoning significantly reduces computational overhead, decreasing thinking model usage by up to 81.01\\%, while controlling the performance loss below the user-specified level.", "AI": {"tldr": "B-PAC\u63a8\u7406\uff1a\u4e00\u79cd\u5728\u7ebf\u73af\u5883\u4e0b\u5b89\u5168\u9ad8\u6548\u7684\u5927\u6a21\u578b\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8def\u7531\u9608\u503c\u63a7\u5236\u6027\u80fd\u635f\u5931\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u867d\u7136\u6027\u80fd\u5f3a\u5927\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u5ef6\u8fdf\u5927\u3002\u73b0\u6709\u7684\u9009\u62e9\u6027\u601d\u8003\u7b56\u7565\u867d\u7136\u80fd\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u5728\u5728\u7ebf\u73af\u5883\u4e2d\u5b58\u5728\u4e0d\u53ef\u63a7\u9519\u8bef\uff0c\u56e0\u4e3a\u975e\u601d\u8003\u6a21\u578b\u7684\u6027\u80fd\u635f\u5931\u53ea\u80fd\u90e8\u5206\u89c2\u6d4b\u4e14\u6570\u636e\u975e\u5e73\u7a33", "method": "\u63d0\u51faB-PAC\u63a8\u7406\u65b9\u6cd5\uff0c\u5229\u7528\u9006\u503e\u5411\u8bc4\u5206\u4f30\u8ba1\u5668\u6784\u5efa\u5019\u9009\u9608\u503c\u7684\u6d4b\u8bd5\u8d85\u9785\uff0c\u57fa\u4e8e\u7d2f\u79ef\u7edf\u8ba1\u8bc1\u636e\u52a8\u6001\u8c03\u6574\u8def\u7531\u9608\u503c\uff0c\u5b9e\u73b0\u4efb\u610f\u65f6\u95f4\u6709\u6548\u7684\u6027\u80fd\u635f\u5931\u63a7\u5236", "result": "B-PAC\u63a8\u7406\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u5c06\u601d\u8003\u6a21\u578b\u4f7f\u7528\u7387\u51cf\u5c11\u9ad8\u8fbe81.01%\uff0c\u540c\u65f6\u5c06\u6027\u80fd\u635f\u5931\u63a7\u5236\u5728\u7528\u6237\u6307\u5b9a\u6c34\u5e73\u4ee5\u4e0b", "conclusion": "B-PAC\u63a8\u7406\u4e3a\u5728\u7ebf\u73af\u5883\u4e0b\u7684\u5b89\u5168\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u4efb\u610f\u65f6\u95f4\u6709\u6548\u7684\u6027\u80fd\u635f\u5931\u63a7\u5236\u548c\u6548\u7387\u63d0\u5347"}}
{"id": "2601.22485", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.22485", "abs": "https://arxiv.org/abs/2601.22485", "authors": ["Naen Xu", "Jinghuai Zhang", "Ping He", "Chunyi Zhou", "Jun Wang", "Zhihui Fu", "Tianyu Du", "Zhaoxiang Wang", "Shouling Ji"], "title": "FraudShield: Knowledge Graph Empowered Defense for LLMs against Fraud Attacks", "comment": "WWW 2026", "summary": "Large language models (LLMs) have been widely integrated into critical automated workflows, including contract review and job application processes. However, LLMs are susceptible to manipulation by fraudulent information, which can lead to harmful outcomes. Although advanced defense methods have been developed to address this issue, they often exhibit limitations in effectiveness, interpretability, and generalizability, particularly when applied to LLM-based applications. To address these challenges, we introduce FraudShield, a novel framework designed to protect LLMs from fraudulent content by leveraging a comprehensive analysis of fraud tactics. Specifically, FraudShield constructs and refines a fraud tactic-keyword knowledge graph to capture high-confidence associations between suspicious text and fraud techniques. The structured knowledge graph augments the original input by highlighting keywords and providing supporting evidence, guiding the LLM toward more secure responses. Extensive experiments show that FraudShield consistently outperforms state-of-the-art defenses across four mainstream LLMs and five representative fraud types, while also offering interpretable clues for the model's generations.", "AI": {"tldr": "FraudShield\u662f\u4e00\u4e2a\u4fdd\u62a4\u5927\u8bed\u8a00\u6a21\u578b\u514d\u53d7\u6b3a\u8bc8\u5185\u5bb9\u653b\u51fb\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u6b3a\u8bc8\u7b56\u7565-\u5173\u952e\u8bcd\u77e5\u8bc6\u56fe\u8c31\u6765\u589e\u5f3a\u6a21\u578b\u5bf9\u53ef\u7591\u6587\u672c\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u4e3b\u6d41LLM\u548c\u6b3a\u8bc8\u7c7b\u578b\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5408\u540c\u5ba1\u67e5\u3001\u6c42\u804c\u7533\u8bf7\u7b49\u5173\u952e\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u6b3a\u8bc8\u4fe1\u606f\u7684\u64cd\u7eb5\uff0c\u5bfc\u81f4\u6709\u5bb3\u540e\u679c\u3002\u73b0\u6709\u7684\u9632\u5fa1\u65b9\u6cd5\u5728\u6709\u6548\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u7279\u522b\u662f\u5728LLM\u5e94\u7528\u4e2d\u3002", "method": "FraudShield\u901a\u8fc7\u6784\u5efa\u548c\u4f18\u5316\u6b3a\u8bc8\u7b56\u7565-\u5173\u952e\u8bcd\u77e5\u8bc6\u56fe\u8c31\uff0c\u6355\u6349\u53ef\u7591\u6587\u672c\u4e0e\u6b3a\u8bc8\u6280\u672f\u4e4b\u95f4\u7684\u9ad8\u7f6e\u4fe1\u5ea6\u5173\u8054\u3002\u8be5\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u901a\u8fc7\u7a81\u51fa\u5173\u952e\u8bcd\u548c\u63d0\u4f9b\u652f\u6301\u8bc1\u636e\u6765\u589e\u5f3a\u539f\u59cb\u8f93\u5165\uff0c\u5f15\u5bfcLLM\u751f\u6210\u66f4\u5b89\u5168\u7684\u54cd\u5e94\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cFraudShield\u5728\u56db\u4e2a\u4e3b\u6d41LLM\u548c\u4e94\u79cd\u4ee3\u8868\u6027\u6b3a\u8bc8\u7c7b\u578b\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u9632\u5fa1\u65b9\u6cd5\uff0c\u540c\u65f6\u4e3a\u6a21\u578b\u7684\u751f\u6210\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ebf\u7d22\u3002", "conclusion": "FraudShield\u901a\u8fc7\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u6b3a\u8bc8\u5185\u5bb9\u9632\u5fa1\u65b9\u9762\u7684\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u3001\u53ef\u89e3\u91ca\u4e14\u6cdb\u5316\u6027\u5f3a\u7684\u4fdd\u62a4\u65b9\u6848\u3002"}}
{"id": "2601.22449", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22449", "abs": "https://arxiv.org/abs/2601.22449", "authors": ["Tristan Shah", "Stas Tiomkin"], "title": "Controllable Information Production", "comment": null, "summary": "Intrinsic Motivation (IM) is a paradigm for generating intelligent behavior without external utilities. The existing information-theoretic methods for IM are predominantly based on information transmission, which explicitly depends on the designer's choice of which random variables engage in transmission. In this work, we introduce a novel IM principle, Controllable Information Production (CIP), that avoids both external utilities and designer-specified variables. We derive the CIP objective from Optimal Control, showing a connection between extrinsic and intrinsic behaviors. CIP appears as the gap between open-loop and closed-loop Kolmogorov-Sinai entropies, which simultaneously rewards the pursuit and regulation of chaos. We establish key theoretical properties of CIP and demonstrate its effectiveness on standard IM benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5185\u5728\u52a8\u673a\u539f\u5219\u2014\u2014\u53ef\u63a7\u4fe1\u606f\u751f\u4ea7(CIP)\uff0c\u5b83\u907f\u514d\u4e86\u5916\u90e8\u6548\u7528\u548c\u8bbe\u8ba1\u8005\u6307\u5b9a\u7684\u53d8\u91cf\uff0c\u901a\u8fc7\u5f00\u73af\u4e0e\u95ed\u73afKolmogorov-Sinai\u71b5\u7684\u5dee\u503c\u6765\u540c\u65f6\u5956\u52b1\u5bf9\u6df7\u6c8c\u7684\u8ffd\u6c42\u548c\u8c03\u8282\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u5185\u5728\u52a8\u673a\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4fe1\u606f\u4f20\u8f93\uff0c\u8fd9\u660e\u786e\u53d6\u51b3\u4e8e\u8bbe\u8ba1\u8005\u5bf9\u53c2\u4e0e\u4f20\u8f93\u7684\u968f\u673a\u53d8\u91cf\u7684\u9009\u62e9\u3002\u672c\u6587\u65e8\u5728\u907f\u514d\u5bf9\u5916\u90e8\u6548\u7528\u548c\u8bbe\u8ba1\u8005\u6307\u5b9a\u53d8\u91cf\u7684\u4f9d\u8d56\uff0c\u63d0\u51fa\u4e00\u79cd\u66f4\u901a\u7528\u7684\u5185\u5728\u52a8\u673a\u539f\u5219\u3002", "method": "\u4ece\u6700\u4f18\u63a7\u5236\u7406\u8bba\u63a8\u5bfc\u51faCIP\u76ee\u6807\uff0c\u5c06\u5176\u8868\u793a\u4e3a\u5f00\u73af\u4e0e\u95ed\u73afKolmogorov-Sinai\u71b5\u4e4b\u95f4\u7684\u5dee\u503c\u3002\u8fd9\u79cd\u65b9\u6cd5\u540c\u65f6\u5956\u52b1\u5bf9\u6df7\u6c8c\u7684\u8ffd\u6c42\u548c\u8c03\u8282\uff0c\u5efa\u7acb\u4e86\u5916\u5728\u884c\u4e3a\u4e0e\u5185\u5728\u884c\u4e3a\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "result": "\u5efa\u7acb\u4e86CIP\u7684\u5173\u952e\u7406\u8bba\u7279\u6027\uff0c\u5e76\u5728\u6807\u51c6\u5185\u5728\u52a8\u673a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "CIP\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5185\u5728\u52a8\u673a\u539f\u5219\uff0c\u5b83\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u4fe1\u606f\u751f\u4ea7\u800c\u975e\u4f20\u8f93\u7684\u89c6\u89d2\uff0c\u4e3a\u667a\u80fd\u884c\u4e3a\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.22556", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.22556", "abs": "https://arxiv.org/abs/2601.22556", "authors": ["Weizhi Liu", "Yue Li", "Zhaoxia Yin"], "title": "VocBulwark: Towards Practical Generative Speech Watermarking via Additional-Parameter Injection", "comment": null, "summary": "Generated speech achieves human-level naturalness but escalates security risks of misuse. However, existing watermarking methods fail to reconcile fidelity with robustness, as they rely either on simple superposition in the noise space or on intrusive alterations to model weights. To bridge this gap, we propose VocBulwark, an additional-parameter injection framework that freezes generative model parameters to preserve perceptual quality. Specifically, we design a Temporal Adapter to deeply entangle watermarks with acoustic attributes, synergizing with a Coarse-to-Fine Gated Extractor to resist advanced attacks. Furthermore, we develop an Accuracy-Guided Optimization Curriculum that dynamically orchestrates gradient flow to resolve the optimization conflict between fidelity and robustness. Comprehensive experiments demonstrate that VocBulwark achieves high-capacity and high-fidelity watermarking, offering robust defense against complex practical scenarios, with resilience to Codec regenerations and variable-length manipulations.", "AI": {"tldr": "VocBulwark\u662f\u4e00\u4e2a\u8bed\u97f3\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u51bb\u7ed3\u751f\u6210\u6a21\u578b\u53c2\u6570\u4fdd\u6301\u97f3\u8d28\uff0c\u4f7f\u7528\u65f6\u95f4\u9002\u914d\u5668\u6df1\u5ea6\u5d4c\u5165\u6c34\u5370\uff0c\u7ed3\u5408\u7c97\u5230\u7ec6\u95e8\u63a7\u63d0\u53d6\u5668\u62b5\u6297\u653b\u51fb\uff0c\u5e76\u901a\u8fc7\u7cbe\u5ea6\u5f15\u5bfc\u4f18\u5316\u8bfe\u7a0b\u89e3\u51b3\u4fdd\u771f\u5ea6\u4e0e\u9c81\u68d2\u6027\u51b2\u7a81\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u751f\u6210\u6280\u672f\u5df2\u8fbe\u5230\u4eba\u7c7b\u81ea\u7136\u6c34\u5e73\uff0c\u4f46\u5e26\u6765\u4e86\u6ee5\u7528\u98ce\u9669\u3002\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u65e0\u6cd5\u517c\u987e\u4fdd\u771f\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u8981\u4e48\u5728\u566a\u58f0\u7a7a\u95f4\u7b80\u5355\u53e0\u52a0\uff0c\u8981\u4e48\u9700\u8981\u4fb5\u5165\u6027\u5730\u4fee\u6539\u6a21\u578b\u6743\u91cd\u3002", "method": "\u63d0\u51faVocBulwark\u6846\u67b6\uff1a1) \u51bb\u7ed3\u751f\u6210\u6a21\u578b\u53c2\u6570\u4ee5\u4fdd\u6301\u611f\u77e5\u8d28\u91cf\uff1b2) \u8bbe\u8ba1\u65f6\u95f4\u9002\u914d\u5668\u5c06\u6c34\u5370\u4e0e\u58f0\u5b66\u5c5e\u6027\u6df1\u5ea6\u7ea0\u7f20\uff1b3) \u7ed3\u5408\u7c97\u5230\u7ec6\u95e8\u63a7\u63d0\u53d6\u5668\u62b5\u6297\u9ad8\u7ea7\u653b\u51fb\uff1b4) \u5f00\u53d1\u7cbe\u5ea6\u5f15\u5bfc\u4f18\u5316\u8bfe\u7a0b\u52a8\u6001\u534f\u8c03\u68af\u5ea6\u6d41\uff0c\u89e3\u51b3\u4fdd\u771f\u5ea6\u4e0e\u9c81\u68d2\u6027\u7684\u4f18\u5316\u51b2\u7a81\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cVocBulwark\u5b9e\u73b0\u4e86\u9ad8\u5bb9\u91cf\u548c\u9ad8\u4fdd\u771f\u5ea6\u7684\u6c34\u5370\uff0c\u80fd\u591f\u6709\u6548\u9632\u5fa1\u590d\u6742\u7684\u5b9e\u9645\u573a\u666f\u653b\u51fb\uff0c\u5305\u62ec\u7f16\u89e3\u7801\u5668\u518d\u751f\u548c\u53d8\u957f\u64cd\u4f5c\u7b49\u3002", "conclusion": "VocBulwark\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u8bed\u97f3\u6c34\u5370\u4e2d\u4fdd\u771f\u5ea6\u4e0e\u9c81\u68d2\u6027\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u751f\u6210\u8bed\u97f3\u7684\u5b89\u5168\u4f7f\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u4fdd\u62a4\u65b9\u6848\u3002"}}
{"id": "2601.22627", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.22627", "abs": "https://arxiv.org/abs/2601.22627", "authors": ["Yuqing Xiao", "John Grundy", "Anuradha Madugalla", "Elizabeth Manias"], "title": "Elderly HealthMag: Systematic Building and Calibrating a Tool for Identifying and Evaluating Senior User Digital Health Software", "comment": null, "summary": "Digital health (DH) software is increasingly deployed to populations where many end users live with one or more health conditions. Yet, DH software development teams frequently operate using implicit, incorrect assumptions about these users, resulting in products that under-serve the specific requirements imposed by their age and health conditions. Consequently, while software may meet clinical objectives on paper, it often fails to be inclusive during actual user interaction. To address this, we propose \\textbf{\\textit{HealthMag}}, a tool inspired by GenderMag designed to help better elicit, model and evaluate requirements for digital health software. We developed HealthMag through systematic mapping and calibration following the InclusiveMag framework. Furthermore, we integrated this with a calibrated version of an existing AgeMag method to create a dual-lens approach: \\textbf{\\textit{Elderly HealthMag}}, designed to aid requirements, design and evaluation of mHealth software for senior end users. We demonstrate application and utility of Age HealthMag via cognitive walkthroughs in identifying inclusivity biases in current senior user-oriented digital health applications.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86HealthMag\u5de5\u5177\uff0c\u5e2e\u52a9\u6570\u5b57\u5065\u5eb7\u8f6f\u4ef6\u5f00\u53d1\u56e2\u961f\u66f4\u597d\u5730\u8bc6\u522b\u548c\u6ee1\u8db3\u6709\u5065\u5eb7\u95ee\u9898\u7684\u7528\u6237\u9700\u6c42\uff0c\u7279\u522b\u662f\u9488\u5bf9\u8001\u5e74\u7528\u6237\u7684Elderly HealthMag\u53cc\u91cd\u65b9\u6cd5\u3002", "motivation": "\u6570\u5b57\u5065\u5eb7\u8f6f\u4ef6\u7ecf\u5e38\u57fa\u4e8e\u5bf9\u7528\u6237\u7684\u9690\u542b\u3001\u9519\u8bef\u5047\u8bbe\u8fdb\u884c\u5f00\u53d1\uff0c\u5bfc\u81f4\u4ea7\u54c1\u65e0\u6cd5\u6ee1\u8db3\u6709\u5065\u5eb7\u95ee\u9898\u7684\u7528\u6237\u7684\u5b9e\u9645\u9700\u6c42\uff0c\u7279\u522b\u662f\u8001\u5e74\u7528\u6237\u7684\u9700\u6c42\uff0c\u4f7f\u5f97\u8f6f\u4ef6\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\u7f3a\u4e4f\u5305\u5bb9\u6027\u3002", "method": "\u57fa\u4e8eInclusiveMag\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u548c\u6821\u51c6\u5f00\u53d1HealthMag\u5de5\u5177\uff0c\u5e76\u4e0e\u73b0\u6709\u7684AgeMag\u65b9\u6cd5\u6574\u5408\uff0c\u521b\u5efa\u4e86\u9488\u5bf9\u8001\u5e74\u7528\u6237\u7684Elderly HealthMag\u53cc\u91cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba4\u77e5\u8d70\u67e5\u6765\u8bc6\u522b\u6570\u5b57\u5065\u5eb7\u5e94\u7528\u4e2d\u7684\u5305\u5bb9\u6027\u504f\u89c1\u3002", "result": "\u5f00\u53d1\u4e86HealthMag\u548cElderly HealthMag\u5de5\u5177\uff0c\u80fd\u591f\u5e2e\u52a9\u8bc6\u522b\u5f53\u524d\u9762\u5411\u8001\u5e74\u7528\u6237\u7684\u6570\u5b57\u5065\u5eb7\u5e94\u7528\u4e2d\u7684\u5305\u5bb9\u6027\u504f\u89c1\uff0c\u63d0\u9ad8\u8f6f\u4ef6\u5bf9\u7279\u5b9a\u5065\u5eb7\u6761\u4ef6\u548c\u5e74\u9f84\u9700\u6c42\u7684\u9002\u5e94\u6027\u3002", "conclusion": "HealthMag\u5de5\u5177\u4e3a\u6570\u5b57\u5065\u5eb7\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u83b7\u53d6\u3001\u5efa\u6a21\u548c\u8bc4\u4f30\u7528\u6237\u9700\u6c42\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6709\u5065\u5eb7\u95ee\u9898\u548c\u8001\u5e74\u7528\u6237\u7684\u5305\u5bb9\u6027\u9700\u6c42\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u6709\u6548\u7684\u6570\u5b57\u5065\u5eb7\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22513", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22513", "abs": "https://arxiv.org/abs/2601.22513", "authors": ["Shi Fu", "Yingjie Wang", "Shengchao Hu", "Peng Wang", "Dacheng Tao"], "title": "Why Self-Rewarding Works: Theoretical Guarantees for Iterative Alignment of Language Models", "comment": null, "summary": "Self-Rewarding Language Models (SRLMs) achieve notable success in iteratively improving alignment without external feedback. Yet, despite their striking empirical progress, the core mechanisms driving their capabilities remain unelucidated, leaving a critical gap in theoretical understanding. This paper provides the first rigorous theoretical guarantees for SRLMs. We first establish a lower bound that characterizes the fundamental limits of a single update step, revealing a critical dependence on the quality of the initial model. We then derive finite-sample error bounds for the full iterative paradigm, showing that performance improves at a rate of $\\widetilde{\\mathcal{O}}\\left(1/\\sqrt{n}\\right)$ with sample size $n$. Crucially, our analysis reveals that the dependence on the initial model decays exponentially with the number of iterations $T$. This provides a formal explanation for why self-rewarding succeeds: it robustly overcomes poor initialization by steering the dynamics toward internal stability and consistency. Finally, we instantiate our theoretical framework for the linear softmax model class, yielding tailored guarantees that connect our high-level insights to practical model architectures.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u4e3a\u81ea\u5956\u52b1\u8bed\u8a00\u6a21\u578b\uff08SRLMs\uff09\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u63ed\u793a\u4e86\u5176\u6027\u80fd\u6539\u8fdb\u673a\u5236\u548c\u521d\u59cb\u5316\u4f9d\u8d56\u6027\u7684\u8870\u51cf\u89c4\u5f8b\u3002", "motivation": "\u81ea\u5956\u52b1\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u9700\u5916\u90e8\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\u901a\u8fc7\u8fed\u4ee3\u6539\u8fdb\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5176\u6838\u5fc3\u673a\u5236\u7f3a\u4e4f\u7406\u8bba\u89e3\u91ca\uff0c\u5b58\u5728\u7406\u8bba\u7406\u89e3\u4e0a\u7684\u5173\u952e\u7a7a\u767d\u3002", "method": "\u9996\u5148\u5efa\u7acb\u5355\u6b65\u66f4\u65b0\u7684\u4e0b\u754c\u5206\u6790\u521d\u59cb\u6a21\u578b\u8d28\u91cf\u7684\u5f71\u54cd\uff1b\u7136\u540e\u63a8\u5bfc\u5b8c\u6574\u8fed\u4ee3\u8303\u5f0f\u7684\u6709\u9650\u6837\u672c\u8bef\u5dee\u754c\uff1b\u6700\u540e\u5728\u7ebf\u6027softmax\u6a21\u578b\u7c7b\u4e2d\u5b9e\u4f8b\u5316\u7406\u8bba\u6846\u67b6\u3002", "result": "\u6027\u80fd\u6539\u8fdb\u901f\u7387\u4e0e\u6837\u672c\u91cfn\u7684\u5173\u7cfb\u4e3a$\\widetilde{\\mathcal{O}}\\left(1/\\sqrt{n}\\right)$\uff1b\u5bf9\u521d\u59cb\u6a21\u578b\u7684\u4f9d\u8d56\u968f\u8fed\u4ee3\u6b21\u6570T\u5448\u6307\u6570\u8870\u51cf\uff1b\u4e3a\u81ea\u5956\u52b1\u6210\u529f\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u89e3\u91ca\u3002", "conclusion": "\u81ea\u5956\u52b1\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u6307\u6570\u8870\u51cf\u521d\u59cb\u4f9d\u8d56\u6027\u7684\u65b9\u5f0f\u514b\u670d\u4e0d\u826f\u521d\u59cb\u5316\uff0c\u5f15\u5bfc\u52a8\u6001\u5411\u5185\u90e8\u7a33\u5b9a\u6027\u548c\u4e00\u81f4\u6027\u53d1\u5c55\uff0c\u8fd9\u89e3\u91ca\u4e86\u5176\u6210\u529f\u7684\u539f\u56e0\u3002"}}
{"id": "2601.22667", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22667", "abs": "https://arxiv.org/abs/2601.22667", "authors": ["Chi Zhang", "Zehan Li", "Ziqian Zhong", "Haibing Ma", "Dan Xiao", "Chen Lin", "Ming Dong"], "title": "From Horizontal Layering to Vertical Integration: A Comparative Study of the AI-Driven Software Development Paradigm", "comment": null, "summary": "This paper examines the organizational implications of Generative AI adoption in software engineering through a multiple-case comparative study. We contrast two development environments: a traditional enterprise (brownfield) and an AI-native startup (greenfield). Our analysis reveals that transitioning from Horizontal Layering (functional specialization) to Vertical Integration (end-to-end ownership) yields 8-fold to 33-fold reductions in resource consumption. We attribute these gains to the emergence of Super Employees, AI-augmented engineers who span traditional role boundaries, and the elimination of inter-functional coordination overhead. Theoretically, we propose Human-AI Collaboration Efficacy as the primary optimization target for engineering organizations, supplanting individual productivity metrics. Our Total Factor Productivity analysis identifies an AI Distortion Effect that diminishes returns to labor scale while amplifying technological leverage. We conclude with managerial strategies for organizational redesign, including the reactivation of idle cognitive bandwidth in senior engineers and the suppression of blind scale expansion.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u5bfc\u81f4\u7ec4\u7ec7\u7ed3\u6784\u4ece\u6c34\u5e73\u5206\u5c42\u5411\u5782\u76f4\u6574\u5408\u8f6c\u53d8\uff0c\u5e26\u67658-33\u500d\u7684\u8d44\u6e90\u6548\u7387\u63d0\u5347\uff0c\u4e3b\u8981\u5f97\u76ca\u4e8e\"\u8d85\u7ea7\u5458\u5de5\"\u7684\u51fa\u73b0\u548c\u8de8\u804c\u80fd\u534f\u8c03\u6210\u672c\u7684\u6d88\u9664\u3002", "motivation": "\u7814\u7a76\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u7ec4\u7ec7\u5f71\u54cd\uff0c\u5bf9\u6bd4\u4f20\u7edf\u4f01\u4e1a\u548cAI\u539f\u751f\u521d\u521b\u516c\u53f8\u7684\u4e0d\u540c\u5f00\u53d1\u73af\u5883\uff0c\u63a2\u7d22AI\u5982\u4f55\u6539\u53d8\u8f6f\u4ef6\u5de5\u7a0b\u7684\u7ec4\u7ec7\u7ed3\u6784\u548c\u6548\u7387\u3002", "method": "\u91c7\u7528\u591a\u6848\u4f8b\u6bd4\u8f83\u7814\u7a76\u65b9\u6cd5\uff0c\u5bf9\u6bd4\u5206\u6790\u4f20\u7edf\u4f01\u4e1a\uff08\u68d5\u5730\uff09\u548cAI\u539f\u751f\u521d\u521b\u516c\u53f8\uff08\u7eff\u5730\uff09\u4e24\u79cd\u5f00\u53d1\u73af\u5883\uff0c\u901a\u8fc7\u603b\u8981\u7d20\u751f\u4ea7\u7387\u5206\u6790\u8bc6\u522bAI\u626d\u66f2\u6548\u5e94\u3002", "result": "\u4ece\u6c34\u5e73\u5206\u5c42\uff08\u804c\u80fd\u4e13\u4e1a\u5316\uff09\u5411\u5782\u76f4\u6574\u5408\uff08\u7aef\u5230\u7aef\u6240\u6709\u6743\uff09\u8f6c\u53d8\u53ef\u5e26\u67658-33\u500d\u7684\u8d44\u6e90\u6d88\u8017\u51cf\u5c11\uff1bAI\u589e\u5f3a\u7684\u5de5\u7a0b\u5e08\uff08\u8d85\u7ea7\u5458\u5de5\uff09\u8de8\u8d8a\u4f20\u7edf\u89d2\u8272\u8fb9\u754c\uff0c\u6d88\u9664\u8de8\u804c\u80fd\u534f\u8c03\u6210\u672c\uff1b\u53d1\u73b0AI\u626d\u66f2\u6548\u5e94\uff0c\u964d\u4f4e\u52b3\u52a8\u89c4\u6a21\u56de\u62a5\u540c\u65f6\u653e\u5927\u6280\u672f\u6760\u6746\u3002", "conclusion": "\u63d0\u51fa\u4eba\u673a\u534f\u4f5c\u6548\u80fd\u5e94\u6210\u4e3a\u5de5\u7a0b\u7ec4\u7ec7\u7684\u4e3b\u8981\u4f18\u5316\u76ee\u6807\uff0c\u53d6\u4ee3\u4e2a\u4eba\u751f\u4ea7\u529b\u6307\u6807\uff1b\u4e3a\u7ba1\u7406\u8005\u63d0\u4f9b\u7ec4\u7ec7\u91cd\u65b0\u8bbe\u8ba1\u7b56\u7565\uff0c\u5305\u62ec\u91cd\u65b0\u6fc0\u6d3b\u9ad8\u7ea7\u5de5\u7a0b\u5e08\u7684\u95f2\u7f6e\u8ba4\u77e5\u5e26\u5bbd\u548c\u6291\u5236\u76f2\u76ee\u89c4\u6a21\u6269\u5f20\u3002"}}
{"id": "2601.22528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22528", "abs": "https://arxiv.org/abs/2601.22528", "authors": ["Hongze Mi", "Yibo Feng", "WenJie Lu", "Song Cao", "Jinyuan Li", "Yanming Li", "Xuelin Zhang", "Haotian Luo", "Songyang Peng", "He Cui", "Tengfei Tian", "Jun Fang", "Hua Chai", "Naiqiang Tan"], "title": "Darwinian Memory: A Training-Free Self-Regulating Memory System for GUI Agent Evolution", "comment": null, "summary": "Multimodal Large Language Model (MLLM) agents facilitate Graphical User Interface (GUI) automation but struggle with long-horizon, cross-application tasks due to limited context windows. While memory systems provide a viable solution, existing paradigms struggle to adapt to dynamic GUI environments, suffering from a granularity mismatch between high-level intent and low-level execution, and context pollution where the static accumulation of outdated experiences drives agents into hallucination. To address these bottlenecks, we propose the Darwinian Memory System (DMS), a self-evolving architecture that constructs memory as a dynamic ecosystem governed by the law of survival of the fittest. DMS decomposes complex trajectories into independent, reusable units for compositional flexibility, and implements Utility-driven Natural Selection to track survival value, actively pruning suboptimal paths and inhibiting high-risk plans. This evolutionary pressure compels the agent to derive superior strategies. Extensive experiments on real-world multi-app benchmarks validate that DMS boosts general-purpose MLLMs without training costs or architectural overhead, achieving average gains of 18.0% in success rate and 33.9% in execution stability, while reducing task latency, establishing it as an effective self-evolving memory system for GUI tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDarwinian Memory System (DMS)\uff0c\u4e00\u79cd\u81ea\u6f14\u5316\u7684\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u901a\u8fc7\"\u9002\u8005\u751f\u5b58\"\u6cd5\u5219\u89e3\u51b3MLLM\u667a\u80fd\u4f53\u5728GUI\u81ea\u52a8\u5316\u4e2d\u957f\u671f\u8de8\u5e94\u7528\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u9650\u5236\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\u548c\u6267\u884c\u7a33\u5b9a\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLM)\u667a\u80fd\u4f53\u5728GUI\u81ea\u52a8\u5316\u4e2d\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1) \u5904\u7406\u957f\u8de8\u5ea6\u3001\u8de8\u5e94\u7528\u4efb\u52a1\u65f6\u53d7\u9650\u4e8e\u6709\u9650\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\uff1b2) \u73b0\u6709\u8bb0\u5fc6\u7cfb\u7edf\u96be\u4ee5\u9002\u5e94\u52a8\u6001GUI\u73af\u5883\uff0c\u5b58\u5728\u9ad8\u5c42\u610f\u56fe\u4e0e\u4f4e\u5c42\u6267\u884c\u7684\u7c92\u5ea6\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4ee5\u53ca\u9759\u6001\u79ef\u7d2f\u8fc7\u65f6\u7ecf\u9a8c\u5bfc\u81f4\u7684\u4e0a\u4e0b\u6587\u6c61\u67d3\u548c\u5e7b\u89c9\u95ee\u9898\u3002", "method": "\u63d0\u51faDarwinian Memory System (DMS)\uff0c\u4e00\u79cd\u81ea\u6f14\u5316\u7684\u8bb0\u5fc6\u67b6\u6784\uff0c\u5c06\u8bb0\u5fc6\u6784\u5efa\u4e3a\u53d7\"\u9002\u8005\u751f\u5b58\"\u6cd5\u5219\u652f\u914d\u7684\u52a8\u6001\u751f\u6001\u7cfb\u7edf\u3002DMS\u5c06\u590d\u6742\u8f68\u8ff9\u5206\u89e3\u4e3a\u72ec\u7acb\u53ef\u91cd\u7528\u7684\u5355\u5143\u4ee5\u5b9e\u73b0\u7ec4\u5408\u7075\u6d3b\u6027\uff0c\u5e76\u5b9e\u73b0\u6548\u7528\u9a71\u52a8\u7684\u81ea\u7136\u9009\u62e9\u673a\u5236\u6765\u8ddf\u8e2a\u751f\u5b58\u4ef7\u503c\uff0c\u4e3b\u52a8\u4fee\u526a\u6b21\u4f18\u8def\u5f84\u5e76\u6291\u5236\u9ad8\u98ce\u9669\u8ba1\u5212\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u591a\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDMS\u5728\u4e0d\u589e\u52a0\u8bad\u7ec3\u6210\u672c\u6216\u67b6\u6784\u5f00\u9500\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u901a\u7528MLLM\u7684\u6027\u80fd\uff1a\u5e73\u5747\u6210\u529f\u7387\u63d0\u534718.0%\uff0c\u6267\u884c\u7a33\u5b9a\u6027\u63d0\u534733.9%\uff0c\u540c\u65f6\u964d\u4f4e\u4efb\u52a1\u5ef6\u8fdf\u3002", "conclusion": "DMS\u88ab\u8bc1\u660e\u662f\u4e00\u79cd\u6709\u6548\u7684\u81ea\u6f14\u5316\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u80fd\u591f\u89e3\u51b3GUI\u4efb\u52a1\u4e2dMLLM\u667a\u80fd\u4f53\u7684\u4e0a\u4e0b\u6587\u9650\u5236\u548c\u8bb0\u5fc6\u9002\u5e94\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u8fdb\u5316\u538b\u529b\u9a71\u52a8\u667a\u80fd\u4f53\u63a8\u5bfc\u51fa\u66f4\u4f18\u7b56\u7565\u3002"}}
{"id": "2601.22655", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22655", "abs": "https://arxiv.org/abs/2601.22655", "authors": ["Feiyang Huang", "Yuqiang Sun", "Fan Zhang", "Ziqi Yang", "Han Liu", "Yang Liu"], "title": "The Semantic Trap: Do Fine-tuned LLMs Learn Vulnerability Root Cause or Just Functional Pattern?", "comment": "21 pages", "summary": "LLMs demonstrate promising performance in software vulnerability detection after fine-tuning. However, it remains unclear whether these gains reflect a genuine understanding of vulnerability root causes or merely an exploitation of functional patterns. In this paper, we identify a critical failure mode termed the \"semantic trap,\" where fine-tuned LLMs achieve high detection scores by associating certain functional domains with vulnerability likelihood rather than reasoning about the underlying security semantics.To systematically evaluate this phenomenon, we propose TrapEval, a comprehensive evaluation framework designed to disentangle vulnerability root cause from functional pattern. TrapEval introduces two complementary datasets derived from real-world open-source projects: V2N, which pairs vulnerable code with unrelated benign code, and V2P, which pairs vulnerable code with its corresponding patched version, forcing models to distinguish near-identical code that differs only in subtle security-critical logic. Using TrapEval, we fine-tune five representative state-of-the-art LLMs across three model families and evaluate them under cross-dataset testing, semantic-preserving perturbations, and varying degrees of semantic gap measured by CodeBLEU.Our empirical results reveal that, despite improvements in metrics, fine-tuned LLMs consistently struggle to distinguish vulnerable code from its patched counterpart, exhibit severe robustness degradation under minor semantic-preserving transformations, and rely heavily on functional-context shortcuts when the semantic gap is small. These findings provide strong evidence that current fine-tuning practices often fail to impart true vulnerability reasoning. Our findings serve as a wake-up call: high benchmark scores on traditional datasets may be illusory, masking the model's inability to understand the true causal logic of vulnerabilities.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0\u5fae\u8c03\u540e\u7684LLMs\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u53ef\u80fd\u9677\u5165\"\u8bed\u4e49\u9677\u9631\"\uff1a\u6a21\u578b\u901a\u8fc7\u5173\u8054\u529f\u80fd\u6a21\u5f0f\u800c\u975e\u7406\u89e3\u5b89\u5168\u8bed\u4e49\u6765\u83b7\u5f97\u9ad8\u5206\uff0c\u65e0\u6cd5\u771f\u6b63\u533a\u5206\u6f0f\u6d1e\u4ee3\u7801\u4e0e\u5176\u4fee\u590d\u7248\u672c\u3002", "motivation": "\u5f53\u524d\u5fae\u8c03\u540e\u7684LLMs\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u6027\u80fd\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u79cd\u63d0\u5347\u662f\u6e90\u4e8e\u5bf9\u6f0f\u6d1e\u6839\u672c\u539f\u56e0\u7684\u771f\u6b63\u7406\u89e3\uff0c\u8fd8\u662f\u4ec5\u4ec5\u5229\u7528\u4e86\u529f\u80fd\u6a21\u5f0f\u7684\u6377\u5f84\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u4e86\u5b89\u5168\u8bed\u4e49\u3002", "method": "\u63d0\u51faTrapEval\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u6570\u636e\u96c6\uff1aV2N\uff08\u6f0f\u6d1e\u4ee3\u7801\u4e0e\u65e0\u5173\u826f\u6027\u4ee3\u7801\u914d\u5bf9\uff09\u548cV2P\uff08\u6f0f\u6d1e\u4ee3\u7801\u4e0e\u5176\u4fee\u590d\u7248\u672c\u914d\u5bf9\uff09\u3002\u5fae\u8c035\u4e2a\u4ee3\u8868\u6027LLMs\uff0c\u5728\u8de8\u6570\u636e\u96c6\u6d4b\u8bd5\u3001\u8bed\u4e49\u4fdd\u7559\u6270\u52a8\u548c\u4e0d\u540c\u8bed\u4e49\u5dee\u8ddd\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5c3d\u7ba1\u6307\u6807\u6709\u6240\u6539\u5584\uff0c\u4f46\u5fae\u8c03\u540e\u7684LLMs\u6301\u7eed\u96be\u4ee5\u533a\u5206\u6f0f\u6d1e\u4ee3\u7801\u4e0e\u5176\u4fee\u590d\u7248\u672c\uff0c\u5728\u8f7b\u5fae\u8bed\u4e49\u4fdd\u7559\u53d8\u6362\u4e0b\u8868\u73b0\u51fa\u4e25\u91cd\u7684\u9c81\u68d2\u6027\u9000\u5316\uff0c\u5f53\u8bed\u4e49\u5dee\u8ddd\u8f83\u5c0f\u65f6\u4e25\u91cd\u4f9d\u8d56\u529f\u80fd\u4e0a\u4e0b\u6587\u6377\u5f84\u3002", "conclusion": "\u5f53\u524d\u5fae\u8c03\u5b9e\u8df5\u5f80\u5f80\u672a\u80fd\u4f20\u6388\u771f\u6b63\u7684\u6f0f\u6d1e\u63a8\u7406\u80fd\u529b\uff0c\u4f20\u7edf\u6570\u636e\u96c6\u4e0a\u7684\u9ad8\u5206\u53ef\u80fd\u662f\u865a\u5e7b\u7684\uff0c\u63a9\u76d6\u4e86\u6a21\u578b\u65e0\u6cd5\u7406\u89e3\u6f0f\u6d1e\u771f\u6b63\u56e0\u679c\u903b\u8f91\u7684\u95ee\u9898\u3002\u8fd9\u4e3a\u9886\u57df\u6572\u54cd\u4e86\u8b66\u949f\u3002"}}
{"id": "2601.22676", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22676", "abs": "https://arxiv.org/abs/2601.22676", "authors": ["Jinrui Sun", "Tong Jia", "Minghua He", "Ying Li"], "title": "VarParser: Unleashing the Neglected Power of Variables for LLM-based Log Parsing", "comment": "12 pages, 9 figures, Accepted in TheWebConf 2026", "summary": "Logs serve as a primary source of information for engineers to diagnose failures in large-scale online service systems. Log parsing, which extracts structured events from massive unstructured log data, is a critical first step for downstream tasks like anomaly detection and failure diagnosis. With advances in large language models (LLMs), leveraging their strong text understanding capabilities has proven effective for accurate log parsing. However, existing LLM-based log parsers all focus on the constant part of logs, ignoring the potential contribution of the variable part to log parsing. This constant-centric strategy brings four key problems. First, inefficient log grouping and sampling with only constant information. Second, a relatively large number of LLM invocations due to constant-based cache, leading to low log parsing accuracy and efficiency. Third, a relatively large number of consumed constant tokens in prompts leads to high LLM invocation costs. At last, these methods only retain placeholders in the results, losing the system visibility brought by variable information in logs.\n  Facing these problems, we propose a variable-centric log parsing strategy named VarParser. Through variable contribution sampling, variable-centric parsing cache, and adaptive variable-aware in-context learning, our approach can efficiently capture the variable parts of logs and leverage their contributions to parsing. By introducing variable units, we preserve rich variable information, enhancing the integrity of log parsing results. Extensive evaluations on large-scale datasets demonstrate that VarParser achieves higher accuracy compared to existing methods, significantly improving parsing efficiency while reducing the LLM invocation costs.", "AI": {"tldr": "VarParser\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u53d8\u91cf\u4e3a\u4e2d\u5fc3\u7684\u65e5\u5fd7\u89e3\u6790\u7b56\u7565\uff0c\u901a\u8fc7\u5229\u7528\u65e5\u5fd7\u4e2d\u7684\u53d8\u91cf\u90e8\u5206\u4fe1\u606f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u65e5\u5fd7\u89e3\u6790\u5668\u53ea\u5173\u6ce8\u5e38\u91cf\u90e8\u5206\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u89e3\u6790\u51c6\u786e\u7387\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65e5\u5fd7\u89e3\u6790\u5668\u90fd\u53ea\u5173\u6ce8\u65e5\u5fd7\u7684\u5e38\u91cf\u90e8\u5206\uff0c\u5ffd\u7565\u4e86\u53d8\u91cf\u90e8\u5206\u5bf9\u65e5\u5fd7\u89e3\u6790\u7684\u6f5c\u5728\u8d21\u732e\u3002\u8fd9\u79cd\u5e38\u91cf\u4e2d\u5fc3\u7b56\u7565\u5e26\u6765\u4e86\u56db\u4e2a\u5173\u952e\u95ee\u9898\uff1a1\uff09\u4ec5\u4f7f\u7528\u5e38\u91cf\u4fe1\u606f\u5bfc\u81f4\u65e5\u5fd7\u5206\u7ec4\u548c\u91c7\u6837\u6548\u7387\u4f4e\u4e0b\uff1b2\uff09\u57fa\u4e8e\u5e38\u91cf\u7684\u7f13\u5b58\u5bfc\u81f4LLM\u8c03\u7528\u6b21\u6570\u8f83\u591a\uff0c\u964d\u4f4e\u89e3\u6790\u51c6\u786e\u7387\u548c\u6548\u7387\uff1b3\uff09\u63d0\u793a\u4e2d\u6d88\u8017\u7684\u5e38\u91cf\u6807\u8bb0\u8f83\u591a\u5bfc\u81f4LLM\u8c03\u7528\u6210\u672c\u9ad8\uff1b4\uff09\u7ed3\u679c\u4e2d\u53ea\u4fdd\u7559\u5360\u4f4d\u7b26\uff0c\u5931\u53bb\u4e86\u65e5\u5fd7\u4e2d\u53d8\u91cf\u4fe1\u606f\u5e26\u6765\u7684\u7cfb\u7edf\u53ef\u89c1\u6027\u3002", "method": "\u63d0\u51faVarParser\u53d8\u91cf\u4e2d\u5fc3\u65e5\u5fd7\u89e3\u6790\u7b56\u7565\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a1\uff09\u53d8\u91cf\u8d21\u732e\u91c7\u6837\uff1a\u9ad8\u6548\u6355\u83b7\u65e5\u5fd7\u7684\u53d8\u91cf\u90e8\u5206\u5e76\u5229\u7528\u5176\u5bf9\u89e3\u6790\u7684\u8d21\u732e\uff1b2\uff09\u53d8\u91cf\u4e2d\u5fc3\u89e3\u6790\u7f13\u5b58\uff1a\u51cf\u5c11LLM\u8c03\u7528\u6b21\u6570\uff1b3\uff09\u81ea\u9002\u5e94\u53d8\u91cf\u611f\u77e5\u4e0a\u4e0b\u6587\u5b66\u4e60\u3002\u901a\u8fc7\u5f15\u5165\u53d8\u91cf\u5355\u5143\uff0c\u4fdd\u7559\u4e30\u5bcc\u7684\u53d8\u91cf\u4fe1\u606f\uff0c\u589e\u5f3a\u65e5\u5fd7\u89e3\u6790\u7ed3\u679c\u7684\u5b8c\u6574\u6027\u3002", "result": "\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cVarParser\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u89e3\u6790\u6548\u7387\u5e76\u964d\u4f4e\u4e86LLM\u8c03\u7528\u6210\u672c\u3002", "conclusion": "VarParser\u901a\u8fc7\u91c7\u7528\u53d8\u91cf\u4e2d\u5fc3\u7684\u65e5\u5fd7\u89e3\u6790\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709LLM\u65e5\u5fd7\u89e3\u6790\u5668\u7684\u5c40\u9650\u6027\uff0c\u5728\u4fdd\u6301\u7cfb\u7edf\u53ef\u89c1\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e5\u5fd7\u89e3\u6790\u7684\u51c6\u786e\u7387\u3001\u6548\u7387\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2601.22706", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22706", "abs": "https://arxiv.org/abs/2601.22706", "authors": ["Yanlin Wang", "Ziyao Zhang", "Chong Wang", "Xinyi Xu", "Mingwei Liu", "Yong Wang", "Jiachi Chen", "Zibin Zheng"], "title": "RealSec-bench: A Benchmark for Evaluating Secure Code Generation in Real-World Repositories", "comment": "9 pages, 6 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation, but their proficiency in producing secure code remains a critical, under-explored area. Existing benchmarks often fall short by relying on synthetic vulnerabilities or evaluating functional correctness in isolation, failing to capture the complex interplay between functionality and security found in real-world software. To address this gap, we introduce RealSec-bench, a new benchmark for secure code generation meticulously constructed from real-world, high-risk Java repositories. Our methodology employs a multi-stage pipeline that combines systematic SAST scanning with CodeQL, LLM-based false positive elimination, and rigorous human expert validation. The resulting benchmark contains 105 instances grounded in real-word repository contexts, spanning 19 Common Weakness Enumeration (CWE) types and exhibiting a wide diversity of data flow complexities, including vulnerabilities with up to 34-hop inter-procedural dependencies. Using RealSec-bench, we conduct an extensive empirical study on 5 popular LLMs. We introduce a novel composite metric, SecurePass@K, to assess both functional correctness and security simultaneously. We find that while Retrieval-Augmented Generation (RAG) techniques can improve functional correctness, they provide negligible benefits to security. Furthermore, explicitly prompting models with general security guidelines often leads to compilation failures, harming functional correctness without reliably preventing vulnerabilities. Our work highlights the gap between functional and secure code generation in current LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86RealSec-bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u751f\u6210\u5b89\u5168\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524dLLM\u5728\u529f\u80fd\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0cRAG\u6280\u672f\u5bf9\u5b89\u5168\u6027\u63d0\u5347\u6709\u9650\uff0c\u901a\u7528\u5b89\u5168\u63d0\u793a\u53cd\u800c\u53ef\u80fd\u635f\u5bb3\u529f\u80fd\u6027\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u529f\u80fd\u6027\uff0c\u7f3a\u4e4f\u5bf9\u5b89\u5168\u6027\u7684\u8bc4\u4f30\uff0c\u4e14\u591a\u4f7f\u7528\u5408\u6210\u6f0f\u6d1e\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u8f6f\u4ef6\u4e2d\u529f\u80fd\u4e0e\u5b89\u5168\u7684\u590d\u6742\u4ea4\u4e92\u5173\u7cfb\u3002", "method": "\u6784\u5efaRealSec-bench\u57fa\u51c6\uff1a\u4ece\u771f\u5b9e\u9ad8\u98ce\u9669Java\u4ed3\u5e93\u4e2d\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u6d41\u7a0b\uff08SAST\u626b\u63cf\u3001CodeQL\u3001LLM\u8bef\u62a5\u6d88\u9664\u3001\u4e13\u5bb6\u9a8c\u8bc1\uff09\u6536\u96c6105\u4e2a\u5b9e\u4f8b\uff0c\u6db5\u76d619\u79cdCWE\u7c7b\u578b\u3002\u63d0\u51faSecurePass@K\u590d\u5408\u6307\u6807\uff0c\u8bc4\u4f305\u4e2a\u6d41\u884cLLM\u7684\u5b89\u5168\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "result": "RAG\u6280\u672f\u80fd\u63d0\u5347\u529f\u80fd\u6b63\u786e\u6027\u4f46\u5bf9\u5b89\u5168\u6027\u6539\u5584\u6709\u9650\uff1b\u663e\u5f0f\u5b89\u5168\u63d0\u793a\u5e38\u5bfc\u81f4\u7f16\u8bd1\u5931\u8d25\uff0c\u635f\u5bb3\u529f\u80fd\u6027\u4e14\u4e0d\u80fd\u53ef\u9760\u9632\u6b62\u6f0f\u6d1e\uff1b\u5f53\u524dLLM\u5728\u529f\u80fd\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u5b89\u5168\u4ee3\u7801\u751f\u6210\u5f00\u53d1\u66f4\u6709\u6548\u7684\u6280\u672f\uff0c\u5f53\u524dLLM\u5728\u751f\u6210\u5b89\u5168\u4ee3\u7801\u65b9\u9762\u4ecd\u6709\u5f88\u5927\u6539\u8fdb\u7a7a\u95f4\uff0c\u529f\u80fd\u6b63\u786e\u6027\u4e0d\u7b49\u4e8e\u5b89\u5168\u6027\u3002"}}
{"id": "2601.22748", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22748", "abs": "https://arxiv.org/abs/2601.22748", "authors": ["You Lu", "Jiyang Zhang", "Bihuan Chen", "Chaofeng Sha", "Dingji Wang", "Xin Peng"], "title": "AutoMerge: Search-Based Model Merging Framework for Effective Model Reuse", "comment": null, "summary": "Software reuse has long been recognized as a critical and widely studied topic in software engineering, offering substantial benefits in reducing development costs, improving software quality, and enhancing operational efficiency. This paradigm extends into deep learning through model reuse. Recently, model merging has emerged in the domain of large language models (LLMs) as a training-free approach that takes multiple task-specific models with the same architecture as source models and merges them without retraining, enhancing model reuse within LLMs. However, no prior work has systematically investigated whether such an approach can be effectively applied to other deep learning models with different architectures across domains. To bridge this gap, we present the first systematic study that evaluates five model merging techniques on three distinct model architectures across three domains: LLMs, image classification, and autonomous driving. Our findings reveal that directly applying existing model merging techniques leads to highly inconsistent results and falls notably short of their success within LLMs. Moreover, a single model merging technique often fails to handle the heterogeneous structural properties within a model, limiting its applicability to different model architectures across domains. Furthermore, the effectiveness of model merging techniques is highly sensitive to hyperparameter configurations, thereby constraining their potential for broader adoption. Inspired by these insights, we propose AutoMerge, a novel search-based model merging framework that first segments complex models into multiple heterogeneous blocks and then systematically explores the merging space to identify the merging technique and its hyperparameter configuration.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u6a21\u578b\u5408\u5e76\u6280\u672f\u5728\u4e0d\u540c\u67b6\u6784\u548c\u9886\u57df\u7684\u9002\u7528\u6027\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728LLMs\u4e4b\u5916\u6548\u679c\u4e0d\u4f73\uff0c\u63d0\u51fa\u4e86AutoMerge\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "motivation": "\u8f6f\u4ef6\u91cd\u7528\u662f\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u91cd\u8981\u8bfe\u9898\uff0c\u6a21\u578b\u5408\u5e76\u4f5c\u4e3a\u8bad\u7ec3\u514d\u8d39\u7684\u65b9\u6cd5\u5728LLMs\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8de8\u9886\u57df\u3001\u4e0d\u540c\u67b6\u6784\u6a21\u578b\u7684\u7cfb\u7edf\u7814\u7a76\uff0c\u9700\u8981\u63a2\u7d22\u6a21\u578b\u5408\u5e76\u6280\u672f\u5728\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "1. \u7cfb\u7edf\u8bc4\u4f30\u4e865\u79cd\u6a21\u578b\u5408\u5e76\u6280\u672f\u57283\u79cd\u4e0d\u540c\u6a21\u578b\u67b6\u6784\uff08LLMs\u3001\u56fe\u50cf\u5206\u7c7b\u3001\u81ea\u52a8\u9a7e\u9a76\uff09\u4e0a\u7684\u8868\u73b0\uff1b2. \u63d0\u51fa\u4e86AutoMerge\u6846\u67b6\uff1a\u9996\u5148\u5c06\u590d\u6742\u6a21\u578b\u5206\u5272\u4e3a\u591a\u4e2a\u5f02\u6784\u5757\uff0c\u7136\u540e\u7cfb\u7edf\u63a2\u7d22\u5408\u5e76\u7a7a\u95f4\u4ee5\u786e\u5b9a\u6700\u4f73\u5408\u5e76\u6280\u672f\u53ca\u5176\u8d85\u53c2\u6570\u914d\u7f6e\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1. \u76f4\u63a5\u5e94\u7528\u73b0\u6709\u6a21\u578b\u5408\u5e76\u6280\u672f\u5728\u4e0d\u540c\u9886\u57df\u6548\u679c\u4e0d\u4e00\u81f4\uff0c\u8fdc\u4e0d\u5982\u5728LLMs\u4e2d\u7684\u6210\u529f\uff1b2. \u5355\u4e00\u5408\u5e76\u6280\u672f\u96be\u4ee5\u5904\u7406\u6a21\u578b\u5185\u90e8\u7684\u5f02\u6784\u7ed3\u6784\u7279\u6027\uff1b3. \u5408\u5e76\u6280\u672f\u7684\u6548\u679c\u5bf9\u8d85\u53c2\u6570\u914d\u7f6e\u9ad8\u5ea6\u654f\u611f\uff1b4. \u73b0\u6709\u65b9\u6cd5\u9650\u5236\u4e86\u6a21\u578b\u5408\u5e76\u7684\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u6a21\u578b\u5408\u5e76\u6280\u672f\u4e0d\u80fd\u7b80\u5355\u5730\u4eceLLMs\u6269\u5c55\u5230\u5176\u4ed6\u9886\u57df\uff0c\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u67b6\u6784\u548c\u9886\u57df\u8fdb\u884c\u4e13\u95e8\u4f18\u5316\u3002AutoMerge\u6846\u67b6\u901a\u8fc7\u5206\u5272\u5f02\u6784\u5757\u548c\u7cfb\u7edf\u641c\u7d22\u7684\u65b9\u6cd5\uff0c\u4e3a\u89e3\u51b3\u8de8\u9886\u57df\u6a21\u578b\u5408\u5e76\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.22536", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22536", "abs": "https://arxiv.org/abs/2601.22536", "authors": ["Yixin Yang", "Qingxiu Dong", "Zhifang Sui"], "title": "Decoding in Geometry: Alleviating Embedding-Space Crowding for Complex Reasoning", "comment": null, "summary": "Sampling-based decoding underlies complex reasoning in large language models (LLMs), where decoding strategies critically shape model behavior. Temperature- and truncation-based methods reshape the next-token distribution through global probability reweighting or thresholding to balance the quality-diversity tradeoff. However, they operate solely on token probabilities, ignoring fine-grained relationships among tokens in the embedding space. We uncover a novel phenomenon, embedding-space crowding, where the next-token distribution concentrates its probability mass on geometrically close tokens in the embedding space. We quantify crowding at multiple granularities and find a statistical association with reasoning success in mathematical problem solving. Motivated by this finding, we propose CraEG, a plug-and-play sampling method that mitigates crowding through geometry-guided reweighting. CraEG is training-free, single-pass, and compatible with standard sampling strategies. Experiments on multiple models and benchmarks demonstrate improved generation performance, with gains in robustness and diversity metrics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCraEG\u65b9\u6cd5\uff0c\u901a\u8fc7\u51e0\u4f55\u5f15\u5bfc\u91cd\u52a0\u6743\u7f13\u89e3\u5d4c\u5165\u7a7a\u95f4\u62e5\u6324\u73b0\u8c61\uff0c\u63d0\u5347LLM\u751f\u6210\u6027\u80fd", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6e29\u5ea6\u548c\u622a\u65ad\u7684\u91c7\u6837\u65b9\u6cd5\u4ec5\u64cd\u4f5ctoken\u6982\u7387\uff0c\u5ffd\u7565\u4e86\u5d4c\u5165\u7a7a\u95f4\u4e2dtoken\u4e4b\u95f4\u7684\u7ec6\u7c92\u5ea6\u51e0\u4f55\u5173\u7cfb\u3002\u7814\u7a76\u53d1\u73b0\u5d4c\u5165\u7a7a\u95f4\u62e5\u6324\u73b0\u8c61\uff08\u6982\u7387\u8d28\u91cf\u96c6\u4e2d\u5728\u51e0\u4f55\u76f8\u8fd1\u7684token\u4e0a\uff09\uff0c\u4e14\u4e0e\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u63a8\u7406\u6210\u529f\u5b58\u5728\u7edf\u8ba1\u5173\u8054\u3002", "method": "\u63d0\u51faCraEG\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u51e0\u4f55\u5f15\u5bfc\u91cd\u52a0\u6743\u6765\u7f13\u89e3\u5d4c\u5165\u7a7a\u95f4\u62e5\u6324\u73b0\u8c61\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\u3001\u5355\u6b21\u901a\u8fc7\uff0c\u4e14\u4e0e\u6807\u51c6\u91c7\u6837\u7b56\u7565\u517c\u5bb9\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCraEG\u63d0\u9ad8\u4e86\u751f\u6210\u6027\u80fd\uff0c\u5728\u9c81\u68d2\u6027\u548c\u591a\u6837\u6027\u6307\u6807\u4e0a\u90fd\u6709\u63d0\u5347\u3002", "conclusion": "\u5d4c\u5165\u7a7a\u95f4\u62e5\u6324\u662f\u5f71\u54cdLLM\u63a8\u7406\u7684\u91cd\u8981\u73b0\u8c61\uff0cCraEG\u901a\u8fc7\u51e0\u4f55\u5f15\u5bfc\u7684\u91c7\u6837\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2601.22710", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.22710", "abs": "https://arxiv.org/abs/2601.22710", "authors": ["Jaehee Kim", "Pilsung Kang"], "title": "AlienLM: Alienization of Language for API-Boundary Privacy in Black-Box LLMs", "comment": null, "summary": "Modern LLMs are increasingly accessed via black-box APIs, requiring users to transmit sensitive prompts, outputs, and fine-tuning data to external providers, creating a critical privacy risk at the API boundary. We introduce AlienLM, a deployable API-only privacy layer that protects text by translating it into an Alien Language via a vocabulary-scale bijection, enabling lossless recovery on the client side. Using only standard fine-tuning APIs, Alien Adaptation Training (AAT) adapts target models to operate directly on alienized inputs. Across four LLM backbones and seven benchmarks, AlienLM retains over 81\\% of plaintext-oracle performance on average, substantially outperforming random-bijection and character-level baselines. Under adversaries with access to model weights, corpus statistics, and learning-based inverse translation, recovery attacks reconstruct fewer than 0.22\\% of alienized tokens. Our results demonstrate a practical pathway for privacy-preserving LLM deployment under API-only access, substantially reducing plaintext exposure while maintaining task performance.", "AI": {"tldr": "AlienLM\u662f\u4e00\u4e2a\u53ef\u90e8\u7f72\u7684API\u9690\u79c1\u4fdd\u62a4\u5c42\uff0c\u901a\u8fc7\u8bcd\u6c47\u7ea7\u53cc\u5c04\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\"\u5916\u661f\u8bed\u8a00\"\uff0c\u5728\u5ba2\u6237\u7aef\u65e0\u635f\u6062\u590d\uff0c\u4ec5\u4f7f\u7528\u6807\u51c6\u5fae\u8c03API\u8ba9\u76ee\u6807\u6a21\u578b\u76f4\u63a5\u5728\"\u5916\u661f\u5316\"\u8f93\u5165\u4e0a\u64cd\u4f5c\uff0c\u5728\u4fdd\u630181%\u4ee5\u4e0a\u660e\u6587\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u5f3a\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u73b0\u4ee3LLM\u8d8a\u6765\u8d8a\u591a\u5730\u901a\u8fc7\u9ed1\u76d2API\u8bbf\u95ee\uff0c\u7528\u6237\u9700\u8981\u5c06\u654f\u611f\u63d0\u793a\u3001\u8f93\u51fa\u548c\u5fae\u8c03\u6570\u636e\u4f20\u8f93\u7ed9\u5916\u90e8\u63d0\u4f9b\u5546\uff0c\u8fd9\u5728API\u8fb9\u754c\u5904\u9020\u6210\u4e86\u4e25\u91cd\u7684\u9690\u79c1\u98ce\u9669\u3002", "method": "\u5f15\u5165AlienLM\uff0c\u901a\u8fc7\u8bcd\u6c47\u7ea7\u53cc\u5c04\u5c06\u6587\u672c\u7ffb\u8bd1\u6210\"\u5916\u661f\u8bed\u8a00\"\uff0c\u5ba2\u6237\u7aef\u53ef\u65e0\u635f\u6062\u590d\uff1b\u4f7f\u7528\u6807\u51c6\u5fae\u8c03API\u8fdb\u884cAlien Adaptation Training (AAT)\uff0c\u4f7f\u76ee\u6807\u6a21\u578b\u76f4\u63a5\u5728\"\u5916\u661f\u5316\"\u8f93\u5165\u4e0a\u64cd\u4f5c\u3002", "result": "\u5728\u56db\u4e2aLLM\u4e3b\u5e72\u548c\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAlienLM\u5e73\u5747\u4fdd\u6301\u8d85\u8fc781%\u7684\u660e\u6587\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u968f\u673a\u53cc\u5c04\u548c\u5b57\u7b26\u7ea7\u57fa\u7ebf\uff1b\u5728\u5bf9\u624b\u62e5\u6709\u6a21\u578b\u6743\u91cd\u3001\u8bed\u6599\u7edf\u8ba1\u548c\u5b66\u4e60\u578b\u9006\u7ffb\u8bd1\u7684\u60c5\u51b5\u4e0b\uff0c\u6062\u590d\u653b\u51fb\u4ec5\u80fd\u91cd\u5efa\u5c11\u4e8e0.22%\u7684\"\u5916\u661f\u5316\"\u6807\u8bb0\u3002", "conclusion": "AlienLM\u4e3aAPI-only\u8bbf\u95ee\u4e0b\u7684\u9690\u79c1\u4fdd\u62a4LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u660e\u6587\u66b4\u9732\u98ce\u9669\u3002"}}
{"id": "2601.22773", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22773", "abs": "https://arxiv.org/abs/2601.22773", "authors": ["Sung Une Lee", "Liming Zhu", "Md Shamsujjoha", "Liming Dong", "Qinghua Lu", "Jieshan Chen"], "title": "Constructing Safety Cases for AI Systems: A Reusable Template Framework", "comment": "41 pages, 8 figures, 8 tables", "summary": "Safety cases, structured arguments that a system is acceptably safe, are becoming central to the governance of AI systems. Yet, traditional safety-case practices from aviation or nuclear engineering rely on well-specified system boundaries, stable architectures, and known failure modes. Modern AI systems such as generative and agentic AI are the opposite. Their capabilities emerge unpredictably from low-level training objectives, their behaviour varies with prompts, and their risk profiles shift through fine-tuning, scaffolding, or deployment context. This study examines how safety cases are currently constructed for AI systems and why classical approaches fail to capture these dynamics. It then proposes a framework of reusable safety-case templates, each following a predefined structure of claims, arguments, and evidence tailored for AI systems. The framework introduces comprehensive taxonomies for AI-specific claim types (assertion-based, constrained-based, capability-based), argument types (demonstrative, comparative, causal/explanatory, risk-based, and normative), and evidence families (empirical, mechanistic, comparative, expert-driven, formal methods, operational/field data, and model-based). Each template is illustrated through end-to-end patterns addressing distinctive challenges such as evaluation without ground truth, dynamic model updates, and threshold-based risk decisions. The result is a systematic, composable, and reusable approach to constructing and maintaining safety cases that are credible, auditable, and adaptive to the evolving behaviour of generative and frontier AI systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9AI\u7cfb\u7edf\u5b89\u5168\u8bba\u8bc1\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u91cd\u7528\u5b89\u5168\u8bba\u8bc1\u6a21\u677f\u6846\u67b6\uff0c\u5305\u542bAI\u7279\u5b9a\u7684\u58f0\u660e\u7c7b\u578b\u3001\u8bba\u8bc1\u7c7b\u578b\u548c\u8bc1\u636e\u5bb6\u65cf\u5206\u7c7b\uff0c\u4ee5\u5e94\u5bf9\u751f\u6210\u5f0fAI\u548c\u524d\u6cbfAI\u7cfb\u7edf\u7684\u52a8\u6001\u7279\u6027\u3002", "motivation": "\u4f20\u7edf\u5b89\u5168\u8bba\u8bc1\u65b9\u6cd5\uff08\u5982\u822a\u7a7a\u6216\u6838\u5de5\u7a0b\u9886\u57df\uff09\u4f9d\u8d56\u4e8e\u660e\u786e\u7684\u7cfb\u7edf\u8fb9\u754c\u3001\u7a33\u5b9a\u67b6\u6784\u548c\u5df2\u77e5\u6545\u969c\u6a21\u5f0f\uff0c\u4f46\u73b0\u4ee3AI\u7cfb\u7edf\uff08\u7279\u522b\u662f\u751f\u6210\u5f0f\u548c\u667a\u80fd\u4f53AI\uff09\u5177\u6709\u80fd\u529b\u4e0d\u53ef\u9884\u6d4b\u6027\u3001\u884c\u4e3a\u968f\u63d0\u793a\u53d8\u5316\u3001\u98ce\u9669\u7279\u5f81\u968f\u5fae\u8c03\u6216\u90e8\u7f72\u73af\u5883\u53d8\u5316\u7b49\u52a8\u6001\u7279\u6027\uff0c\u5bfc\u81f4\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u6355\u6349\u8fd9\u4e9b\u52a8\u6001\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u91cd\u7528\u5b89\u5168\u8bba\u8bc1\u6a21\u677f\u6846\u67b6\uff0c\u5305\u542b\uff1a1\uff09AI\u7279\u5b9a\u7684\u58f0\u660e\u7c7b\u578b\u5206\u7c7b\uff08\u57fa\u4e8e\u65ad\u8a00\u3001\u57fa\u4e8e\u7ea6\u675f\u3001\u57fa\u4e8e\u80fd\u529b\uff09\uff1b2\uff09\u8bba\u8bc1\u7c7b\u578b\u5206\u7c7b\uff08\u6f14\u793a\u6027\u3001\u6bd4\u8f83\u6027\u3001\u56e0\u679c/\u89e3\u91ca\u6027\u3001\u57fa\u4e8e\u98ce\u9669\u3001\u89c4\u8303\u6027\uff09\uff1b3\uff09\u8bc1\u636e\u5bb6\u65cf\u5206\u7c7b\uff08\u7ecf\u9a8c\u6027\u3001\u673a\u5236\u6027\u3001\u6bd4\u8f83\u6027\u3001\u4e13\u5bb6\u9a71\u52a8\u3001\u5f62\u5f0f\u5316\u65b9\u6cd5\u3001\u64cd\u4f5c/\u73b0\u573a\u6570\u636e\u3001\u57fa\u4e8e\u6a21\u578b\uff09\u3002\u6bcf\u4e2a\u6a21\u677f\u91c7\u7528\u9884\u5b9a\u4e49\u7684\u58f0\u660e-\u8bba\u8bc1-\u8bc1\u636e\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u7aef\u5230\u7aef\u6a21\u5f0f\u89e3\u51b3\u7279\u5b9a\u6311\u6218\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u3001\u53ef\u7ec4\u5408\u3001\u53ef\u91cd\u7528\u7684\u5b89\u5168\u8bba\u8bc1\u6784\u5efa\u548c\u7ef4\u62a4\u65b9\u6cd5\uff0c\u80fd\u591f\u5e94\u5bf9\u65e0\u771f\u5b9e\u6807\u7b7e\u8bc4\u4f30\u3001\u52a8\u6001\u6a21\u578b\u66f4\u65b0\u3001\u57fa\u4e8e\u9608\u503c\u7684\u98ce\u9669\u51b3\u7b56\u7b49\u72ec\u7279\u6311\u6218\uff0c\u4f7f\u5b89\u5168\u8bba\u8bc1\u66f4\u52a0\u53ef\u4fe1\u3001\u53ef\u5ba1\u8ba1\uff0c\u5e76\u80fd\u9002\u5e94\u751f\u6210\u5f0f\u548c\u524d\u6cbfAI\u7cfb\u7edf\u7684\u6f14\u5316\u884c\u4e3a\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u7cfb\u7edf\u5b89\u5168\u8bba\u8bc1\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u5b89\u5168\u8bba\u8bc1\u5728\u5e94\u5bf9AI\u52a8\u6001\u7279\u6027\u65f6\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u53ef\u91cd\u7528\u6a21\u677f\u4f7f\u5b89\u5168\u8bba\u8bc1\u66f4\u52a0\u53ef\u4fe1\u3001\u53ef\u5ba1\u8ba1\u4e14\u80fd\u9002\u5e94AI\u7cfb\u7edf\u7684\u6301\u7eed\u6f14\u5316\u3002"}}
{"id": "2601.22791", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22791", "abs": "https://arxiv.org/abs/2601.22791", "authors": ["Sabinakhon Akbarova", "Felix Dobslaw", "Robert Feldt"], "title": "Understanding on the Edge: LLM-generated Boundary Test Explanations", "comment": "This is the author's accepted manuscript of a paper accepted for publication at AST 2026. The final version will appear in the ACM Digital Library", "summary": "Boundary value analysis and testing (BVT) is fundamental in software quality assurance because faults tend to cluster at input extremes, yet testers often struggle to understand and justify why certain input-output pairs represent meaningful behavioral boundaries. Large Language Models (LLMs) could help by producing natural-language rationales, but their value for BVT has not been empirically assessed. We therefore conducted an exploratory study on LLM-generated boundary explanations: in a survey, twenty-seven software professionals rated GPT-4.1 explanations for twenty boundary pairs on clarity, correctness, completeness and perceived usefulness, and six of them elaborated in follow-up interviews. Overall, 63.5% of all ratings were positive (4-5 on a five-point Likert scale) compared to 17% negative (1-2), indicating general agreement but also variability in perceptions. Participants favored explanations that followed a clear structure, cited authoritative sources, and adapted their depth to the reader's expertise; they also stressed the need for actionable examples to support debugging and documentation. From these insights, we distilled a seven-item requirement checklist that defines concrete design criteria for future LLM-based boundary explanation tools. The results suggest that, with further refinement, LLM-based tools can support testing workflows by making boundary explanations more actionable and trustworthy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86LLM\u751f\u6210\u8fb9\u754c\u503c\u5206\u6790\u89e3\u91ca\u7684\u5b9e\u7528\u6027\uff0c\u901a\u8fc7\u8c03\u67e527\u540d\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\u5bf9GPT-4.1\u751f\u6210\u768420\u4e2a\u8fb9\u754c\u5bf9\u89e3\u91ca\u8fdb\u884c\u8bc4\u5206\uff0c\u53d1\u73b063.5%\u7684\u8bc4\u5206\u662f\u79ef\u6781\u7684\uff0c\u8868\u660eLLM\u5728\u63d0\u4f9b\u8fb9\u754c\u503c\u89e3\u91ca\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "motivation": "\u8fb9\u754c\u503c\u5206\u6790\u5728\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u8bc1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6d4b\u8bd5\u4eba\u5458\u5e38\u5e38\u96be\u4ee5\u7406\u89e3\u548c\u8bc1\u660e\u67d0\u4e9b\u8f93\u5165-\u8f93\u51fa\u5bf9\u4e3a\u4f55\u4ee3\u8868\u6709\u610f\u4e49\u7684\u884c\u4e3a\u8fb9\u754c\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u4f46\u5176\u5728\u8fb9\u754c\u503c\u5206\u6790\u4e2d\u7684\u4ef7\u503c\u5c1a\u672a\u7ecf\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u63a2\u7d22\u6027\u7814\u7a76\uff0c\u8c03\u67e527\u540d\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\u5bf9GPT-4.1\u751f\u6210\u768420\u4e2a\u8fb9\u754c\u5bf9\u89e3\u91ca\u8fdb\u884c\u8bc4\u5206\uff08\u6e05\u6670\u5ea6\u3001\u6b63\u786e\u6027\u3001\u5b8c\u6574\u6027\u548c\u611f\u77e5\u6709\u7528\u6027\uff09\uff0c\u5176\u4e2d6\u4eba\u53c2\u4e0e\u540e\u7eed\u8bbf\u8c08\u3002\u4ece\u8fd9\u4e9b\u89c1\u89e3\u4e2d\u63d0\u70bc\u51fa\u4e03\u9879\u9700\u6c42\u68c0\u67e5\u8868\u3002", "result": "63.5%\u7684\u8bc4\u5206\u662f\u79ef\u6781\u7684\uff085\u70b9\u674e\u514b\u7279\u91cf\u8868\u4e2d\u76844-5\u5206\uff09\uff0c17%\u662f\u6d88\u6781\u7684\uff081-2\u5206\uff09\u3002\u53c2\u4e0e\u8005\u504f\u597d\u7ed3\u6784\u6e05\u6670\u3001\u5f15\u7528\u6743\u5a01\u6765\u6e90\u3001\u6839\u636e\u8bfb\u8005\u4e13\u4e1a\u77e5\u8bc6\u8c03\u6574\u6df1\u5ea6\u7684\u89e3\u91ca\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u53ef\u64cd\u4f5c\u7684\u793a\u4f8b\u6765\u652f\u6301\u8c03\u8bd5\u548c\u6587\u6863\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u8fdb\u4e00\u6b65\u6539\u8fdb\uff0c\u57fa\u4e8eLLM\u7684\u5de5\u5177\u53ef\u4ee5\u901a\u8fc7\u4f7f\u8fb9\u754c\u89e3\u91ca\u66f4\u5177\u53ef\u64cd\u4f5c\u6027\u548c\u53ef\u4fe1\u5ea6\u6765\u652f\u6301\u6d4b\u8bd5\u5de5\u4f5c\u6d41\u7a0b\u3002\u4ece\u89c1\u89e3\u4e2d\u63d0\u70bc\u7684\u4e03\u9879\u9700\u6c42\u68c0\u67e5\u8868\u4e3a\u672a\u6765\u57fa\u4e8eLLM\u7684\u8fb9\u754c\u89e3\u91ca\u5de5\u5177\u5b9a\u4e49\u4e86\u5177\u4f53\u7684\u8bbe\u8ba1\u6807\u51c6\u3002"}}
{"id": "2601.22586", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22586", "abs": "https://arxiv.org/abs/2601.22586", "authors": ["Qian Hong", "Siyuan Chang", "Xiao Zhou"], "title": "WED-Net: A Weather-Effect Disentanglement Network with Causal Augmentation for Urban Flow Prediction", "comment": "The ACM on Web Conference 2026 (WWW'26)", "summary": "Urban spatio-temporal prediction under extreme conditions (e.g., heavy rain) is challenging due to event rarity and dynamics. Existing data-driven approaches that incorporate weather as auxiliary input often rely on coarse-grained descriptors and lack dedicated mechanisms to capture fine-grained spatio-temporal effects. Although recent methods adopt causal techniques to improve out-of-distribution generalization, they typically overlook temporal dynamics or depend on fixed confounder stratification. To address these limitations, we propose WED-Net (Weather-Effect Disentanglement Network), a dual-branch Transformer architecture that separates intrinsic and weather-induced traffic patterns via self- and cross-attention, enhanced with memory banks and fused through adaptive gating. To further promote disentanglement, we introduce a discriminator that explicitly distinguishes weather conditions. Additionally, we design a causal data augmentation strategy that perturbs non-causal parts while preserving causal structures, enabling improved generalization under rare scenarios. Experiments on taxi-flow datasets from three cities demonstrate that WED-Net delivers robust performance under extreme weather conditions, highlighting its potential to support safer mobility, highlighting its potential to support safer mobility, disaster preparedness, and urban resilience in real-world settings. The code is publicly available at https://github.com/HQ-LV/WED-Net.", "AI": {"tldr": "WED-Net\u662f\u4e00\u4e2a\u53cc\u5206\u652fTransformer\u67b6\u6784\uff0c\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u5206\u79bb\u5185\u5728\u4ea4\u901a\u6a21\u5f0f\u548c\u5929\u6c14\u8bf1\u5bfc\u7684\u4ea4\u901a\u6a21\u5f0f\uff0c\u4f7f\u7528\u8bb0\u5fc6\u5e93\u548c\u81ea\u9002\u5e94\u95e8\u63a7\u878d\u5408\uff0c\u5e76\u5f15\u5165\u5224\u522b\u5668\u548c\u56e0\u679c\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u4ee5\u63d0\u5347\u6781\u7aef\u5929\u6c14\u6761\u4ef6\u4e0b\u7684\u57ce\u5e02\u65f6\u7a7a\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u6781\u7aef\u5929\u6c14\u6761\u4ef6\u4e0b\u7684\u57ce\u5e02\u65f6\u7a7a\u9884\u6d4b\u5b58\u5728\u6311\u6218\uff1a1\uff09\u4e8b\u4ef6\u7f55\u89c1\u4e14\u52a8\u6001\u53d8\u5316\uff1b2\uff09\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u7c97\u7c92\u5ea6\u5929\u6c14\u63cf\u8ff0\u7b26\uff1b3\uff09\u7f3a\u4e4f\u6355\u6349\u7ec6\u7c92\u5ea6\u65f6\u7a7a\u6548\u5e94\u7684\u4e13\u7528\u673a\u5236\uff1b4\uff09\u73b0\u6709\u56e0\u679c\u65b9\u6cd5\u901a\u5e38\u5ffd\u7565\u65f6\u95f4\u52a8\u6001\u6216\u4f9d\u8d56\u56fa\u5b9a\u6df7\u6742\u56e0\u7d20\u5206\u5c42\u3002", "method": "\u63d0\u51faWED-Net\uff08Weather-Effect Disentanglement Network\uff09\uff1a1\uff09\u53cc\u5206\u652fTransformer\u67b6\u6784\uff0c\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u5206\u79bb\u5185\u5728\u548c\u5929\u6c14\u8bf1\u5bfc\u7684\u4ea4\u901a\u6a21\u5f0f\uff1b2\uff09\u4f7f\u7528\u8bb0\u5fc6\u5e93\u548c\u81ea\u9002\u5e94\u95e8\u63a7\u878d\u5408\uff1b3\uff09\u5f15\u5165\u5224\u522b\u5668\u660e\u786e\u533a\u5206\u5929\u6c14\u6761\u4ef6\uff1b4\uff09\u8bbe\u8ba1\u56e0\u679c\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u6270\u52a8\u975e\u56e0\u679c\u90e8\u5206\u540c\u65f6\u4fdd\u7559\u56e0\u679c\u7ed3\u6784\u3002", "result": "\u5728\u4e09\u4e2a\u57ce\u5e02\u7684\u51fa\u79df\u8f66\u6d41\u91cf\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cWED-Net\u5728\u6781\u7aef\u5929\u6c14\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u7a33\u5065\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5176\u5728\u652f\u6301\u66f4\u5b89\u5168\u7684\u51fa\u884c\u3001\u707e\u5bb3\u51c6\u5907\u548c\u57ce\u5e02\u97e7\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "WED-Net\u901a\u8fc7\u89e3\u8026\u5929\u6c14\u6548\u5e94\u548c\u5185\u5728\u4ea4\u901a\u6a21\u5f0f\uff0c\u7ed3\u5408\u56e0\u679c\u6570\u636e\u589e\u5f3a\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6781\u7aef\u5929\u6c14\u6761\u4ef6\u4e0b\u7684\u57ce\u5e02\u65f6\u7a7a\u9884\u6d4b\u80fd\u529b\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u51fa\u884c\u3001\u707e\u5bb3\u51c6\u5907\u548c\u57ce\u5e02\u97e7\u6027\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2601.22832", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22832", "abs": "https://arxiv.org/abs/2601.22832", "authors": ["Matthew Becker", "Yifei Chen", "Nicholas Cochran", "Pouyan Ghasemi", "Abhishek Gulati", "Mark Harman", "Zachary Haluza", "Mehrdad Honarkhah", "Herve Robert", "Jiacheng Liu", "Weini Liu", "Sreeja Thummala", "Xiaoning Yang", "Rui Xin", "Sophie Zeng"], "title": "Just-in-Time Catching Test Generation at Meta", "comment": "Submitted to FSE 2026 industry track", "summary": "We report on Just-in-Time catching test generation at Meta, designed to prevent bugs in large scale backend systems of hundreds of millions of line of code. Unlike traditional hardening tests, which pass at generation time, catching tests are meant to fail, surfacing bugs before code lands. The primary challenge is to reduce development drag from false positive test failures. Analyzing 22,126 generated tests, we show code-change-aware methods improve candidate catch generation 4x over hardening tests and 20x over coincidentally failing tests. To address false positives, we use rule-based and LLM-based assessors. These assessors reduce human review load by 70%. Inferential statistical analysis showed that human-accepted code changes are assessed to have significantly more false positives, while human-rejected changes have significantly more true positives. We reported 41 candidate catches to engineers; 8 were confirmed to be true positives, 4 of which would have led to serious failures had they remained uncaught. Overall, our results show that Just-in-Time catching is scalable, industrially applicable, and that it prevents serious failures from reaching production.", "AI": {"tldr": "Meta\u5f00\u53d1\u4e86\u5373\u65f6\u6355\u83b7\u6d4b\u8bd5\u751f\u6210\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u5927\u578b\u540e\u7aef\u7cfb\u7edf\u4e2d\u9884\u9632bug\u3002\u4e0e\u4f20\u7edf\u6d4b\u8bd5\u4e0d\u540c\uff0c\u6355\u83b7\u6d4b\u8bd5\u65e8\u5728\u5931\u8d25\uff0c\u5728\u4ee3\u7801\u5408\u5e76\u524d\u53d1\u73b0bug\u3002\u901a\u8fc7\u4ee3\u7801\u53d8\u66f4\u611f\u77e5\u65b9\u6cd5\uff0c\u5019\u9009\u6355\u83b7\u751f\u6210\u6548\u7387\u6bd4\u4f20\u7edf\u6d4b\u8bd5\u63d0\u53474\u500d\uff0c\u6bd4\u5076\u7136\u5931\u8d25\u6d4b\u8bd5\u63d0\u534720\u500d\u3002\u7ed3\u5408\u89c4\u5219\u548cLLM\u8bc4\u4f30\u5668\u51cf\u5c1170%\u4eba\u5de5\u5ba1\u6838\uff0c\u6210\u529f\u8bc6\u522b\u51fa8\u4e2a\u771f\u5b9ebug\uff0c\u5176\u4e2d4\u4e2a\u53ef\u80fd\u5f15\u53d1\u4e25\u91cd\u6545\u969c\u3002", "motivation": "Meta\u9762\u4e34\u5927\u89c4\u6a21\u540e\u7aef\u7cfb\u7edf\uff08\u6570\u4ebf\u884c\u4ee3\u7801\uff09\u4e2d\u9884\u9632bug\u7684\u6311\u6218\u3002\u4f20\u7edf\u5f3a\u5316\u6d4b\u8bd5\u5728\u751f\u6210\u65f6\u901a\u8fc7\uff0c\u65e0\u6cd5\u6709\u6548\u53d1\u73b0\u6f5c\u5728\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5728\u4ee3\u7801\u5408\u5e76\u524d\u4e3b\u52a8\u53d1\u73b0bug\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u51cf\u5c11\u8bef\u62a5\u5e26\u6765\u7684\u5f00\u53d1\u8d1f\u62c5\u3002", "method": "\u91c7\u7528\u5373\u65f6\u6355\u83b7\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\uff1a1\uff09\u4ee3\u7801\u53d8\u66f4\u611f\u77e5\u65b9\u6cd5\u751f\u6210\u5019\u9009\u6355\u83b7\u6d4b\u8bd5\uff1b2\uff09\u7ed3\u5408\u89c4\u5219\u57fa\u7840\u548cLLM\u57fa\u7840\u7684\u8bc4\u4f30\u5668\u7b5b\u9009\u6d4b\u8bd5\uff1b3\uff09\u7edf\u8ba1\u5206\u6790\u4eba\u5de5\u63a5\u53d7\u548c\u62d2\u7edd\u7684\u4ee3\u7801\u53d8\u66f4\u4e2d\u7684\u8bef\u62a5\u548c\u771f\u9633\u6027\u60c5\u51b5\uff1b4\uff09\u5411\u5de5\u7a0b\u5e08\u62a5\u544a\u5019\u9009\u6355\u83b7\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "1\uff09\u4ee3\u7801\u53d8\u66f4\u611f\u77e5\u65b9\u6cd5\u4f7f\u5019\u9009\u6355\u83b7\u751f\u6210\u6bd4\u4f20\u7edf\u5f3a\u5316\u6d4b\u8bd5\u63d0\u53474\u500d\uff0c\u6bd4\u5076\u7136\u5931\u8d25\u6d4b\u8bd5\u63d0\u534720\u500d\uff1b2\uff09\u8bc4\u4f30\u5668\u51cf\u5c1170%\u4eba\u5de5\u5ba1\u6838\u8d1f\u62c5\uff1b3\uff09\u7edf\u8ba1\u5206\u6790\u663e\u793a\u4eba\u5de5\u63a5\u53d7\u7684\u53d8\u66f4\u8bef\u62a5\u663e\u8457\u66f4\u591a\uff0c\u4eba\u5de5\u62d2\u7edd\u7684\u53d8\u66f4\u771f\u9633\u6027\u663e\u8457\u66f4\u591a\uff1b4\uff09\u62a5\u544a\u768441\u4e2a\u5019\u9009\u6355\u83b7\u4e2d\uff0c8\u4e2a\u786e\u8ba4\u4e3a\u771f\u9633\u6027\uff0c\u5176\u4e2d4\u4e2a\u53ef\u80fd\u5f15\u53d1\u4e25\u91cd\u6545\u969c\u3002", "conclusion": "\u5373\u65f6\u6355\u83b7\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u5de5\u4e1a\u9002\u7528\u6027\uff0c\u80fd\u6709\u6548\u9632\u6b62\u4e25\u91cd\u6545\u969c\u8fdb\u5165\u751f\u4ea7\u73af\u5883\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e3b\u52a8\u53d1\u73b0bug\u3001\u51cf\u5c11\u8bef\u62a5\u8d1f\u62c5\uff0c\u4e3a\u5927\u89c4\u6a21\u4ee3\u7801\u5e93\u7684\u8d28\u91cf\u4fdd\u969c\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22595", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22595", "abs": "https://arxiv.org/abs/2601.22595", "authors": ["Hao Yi", "Yulan Hu", "Xin Li", "Sheng Ouyang", "Lizhong Ding", "Yong Liu"], "title": "Learn More with Less: Uncertainty Consistency Guided Query Selection for RLVR", "comment": null, "summary": "Large Language Models (LLMs) have recently improved mathematical reasoning through Reinforcement Learning with Verifiable Reward (RLVR). However, existing RLVR algorithms require large query budgets, making annotation costly. We investigate whether fewer but more informative queries can yield similar or superior performance, introducing active learning (AL) into RLVR. We identify that classic AL sampling strategies fail to outperform random selection in this setting, due to ignoring objective uncertainty when only selecting by subjective uncertainty. This work proposes an uncertainty consistency metric to evaluate how well subjective uncertainty aligns with objective uncertainty. In the offline setting, this alignment is measured using the Point-Biserial Correlation Coefficient (PBC). For online training, because of limited sampling and dynamically shifting output distributions, PBC estimation is difficult. Therefore, we introduce a new online variant, computed from normalized advantage and subjective uncertainty. Theoretically, we prove that the online variant is strictly negatively correlated with offline PBC and supports better sample selection. Experiments show our method consistently outperforms random and classic AL baselines, achieving full-dataset performance while training on only 30% of the data, effectively reducing the cost of RLVR for reasoning tasks.", "AI": {"tldr": "\u5c06\u4e3b\u52a8\u5b66\u4e60\u5f15\u5165RLVR\u6846\u67b6\uff0c\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u4e00\u81f4\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5728\u4ec5\u4f7f\u752830%\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u5168\u6570\u636e\u96c6\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u6807\u6ce8\u6210\u672c", "motivation": "\u73b0\u6709RLVR\u7b97\u6cd5\u9700\u8981\u5927\u91cf\u67e5\u8be2\u6807\u6ce8\uff0c\u6210\u672c\u9ad8\u6602\u3002\u7814\u7a76\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u66f4\u5c11\u4f46\u4fe1\u606f\u91cf\u66f4\u5927\u7684\u67e5\u8be2\u83b7\u5f97\u76f8\u4f3c\u6216\u66f4\u597d\u7684\u6027\u80fd\uff0c\u5c06\u4e3b\u52a8\u5b66\u4e60\u5f15\u5165RLVR\u6846\u67b6", "method": "\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u4e00\u81f4\u6027\u5ea6\u91cf\u65b9\u6cd5\uff1a\u79bb\u7ebf\u573a\u666f\u4f7f\u7528\u70b9\u53cc\u5217\u76f8\u5173\u7cfb\u6570(PBC)\u8861\u91cf\u4e3b\u89c2\u4e0d\u786e\u5b9a\u6027\u4e0e\u5ba2\u89c2\u4e0d\u786e\u5b9a\u6027\u5bf9\u9f50\u7a0b\u5ea6\uff1b\u5728\u7ebf\u573a\u666f\u5f15\u5165\u57fa\u4e8e\u5f52\u4e00\u5316\u4f18\u52bf\u548c\u4e3b\u89c2\u4e0d\u786e\u5b9a\u6027\u7684\u65b0\u53d8\u4f53\u3002\u7406\u8bba\u8bc1\u660e\u5728\u7ebf\u53d8\u4f53\u4e0e\u79bb\u7ebfPBC\u4e25\u683c\u8d1f\u76f8\u5173\uff0c\u652f\u6301\u66f4\u597d\u7684\u6837\u672c\u9009\u62e9", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u968f\u673a\u9009\u62e9\u548c\u7ecf\u5178\u4e3b\u52a8\u5b66\u4e60\u57fa\u7ebf\uff0c\u5728\u4ec5\u4f7f\u752830%\u6570\u636e\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u5168\u6570\u636e\u96c6\u6027\u80fd\uff0c\u6709\u6548\u964d\u4f4e\u63a8\u7406\u4efb\u52a1\u7684RLVR\u6210\u672c", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4e3b\u52a8\u5b66\u4e60\u548c\u4e0d\u786e\u5b9a\u6027\u4e00\u81f4\u6027\u5ea6\u91cf\uff0c\u663e\u8457\u51cf\u5c11\u4e86RLVR\u7b97\u6cd5\u6240\u9700\u7684\u67e5\u8be2\u6570\u91cf\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u6807\u6ce8\u6210\u672c\uff0c\u4e3a\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6848"}}
{"id": "2601.22772", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.22772", "abs": "https://arxiv.org/abs/2601.22772", "authors": ["Timofey Mezhuev", "Darya Parygina", "Daniil Kuts"], "title": "Rust and Go directed fuzzing with LibAFL-DiFuzz", "comment": null, "summary": "In modern SSDLC, program analysis and automated testing are essential for minimizing vulnerabilities before software release, with fuzzing being a fast and widely used dynamic testing method. However, traditional coverage-guided fuzzing may be less effective in specific tasks like verifying static analysis reports or reproducing crashes, while directed fuzzing, focusing on targeted program locations using proximity metrics, proves to be more effective. Some of the earliest directed fuzzers are, for example, AFLGo and BEACON, which use different proximity metric approaches. Although most automated testing tools focus on C/C++ code, the growing popularity of Rust and Go causes the need for precise and efficient testing solutions for these languages. This work expands the applicability of directed fuzzing beyond traditional analysis of C/C++ software. We present a novel approach to directed greybox fuzzing tailored specifically for Rust and Go applications. We introduce advanced preprocessing techniques, rustc compiler customizations, and elaborate graph construction and instrumentation methods to enable effective targeting of specific program locations. Our implemented fuzzing tools, based on LibAFL-DiFuzz backend, demonstrate competitive advantages compared to popular existing fuzzers like afl.rs, cargo-fuzz, and go-fuzz. According to TTE (Time to Exposure) experiments, Rust-LibAFL-DiFuzz outperforms other tools by the best TTE result. Some stability issues can be explained by different mutation approaches. Go-LibAFL-DiFuzz outperforms its opponent by the best and, in the majority of cases, by average result, having two cases with orders of magnitude difference. These results prove better efficiency and accuracy of our approach.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Rust\u548cGo\u8bed\u8a00\u7684\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f16\u8bd1\u5668\u5b9a\u5236\u548c\u9ad8\u7ea7\u9884\u5904\u7406\u6280\u672f\uff0c\u5728TTE\uff08\u66b4\u9732\u65f6\u95f4\uff09\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u3002", "motivation": "\u968f\u7740Rust\u548cGo\u8bed\u8a00\u7684\u6d41\u884c\uff0c\u9700\u8981\u4e3a\u8fd9\u4e9b\u8bed\u8a00\u63d0\u4f9b\u7cbe\u786e\u9ad8\u6548\u7684\u6d4b\u8bd5\u89e3\u51b3\u65b9\u6848\u3002\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u4e3b\u8981\u9488\u5bf9C/C++\uff0c\u800c\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u5728\u9a8c\u8bc1\u9759\u6001\u5206\u6790\u62a5\u544a\u6216\u91cd\u73b0\u5d29\u6e83\u7b49\u7279\u5b9a\u4efb\u52a1\u4e2d\u66f4\u6709\u6548\uff0c\u4f46\u7f3a\u4e4f\u5bf9Rust\u548cGo\u7684\u652f\u6301\u3002", "method": "\u63d0\u51fa\u9488\u5bf9Rust\u548cGo\u5e94\u7528\u7684\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u65b0\u65b9\u6cd5\uff0c\u5305\u62ec\u9ad8\u7ea7\u9884\u5904\u7406\u6280\u672f\u3001rustc\u7f16\u8bd1\u5668\u5b9a\u5236\u3001\u7cbe\u7ec6\u7684\u56fe\u6784\u5efa\u548c\u63d2\u6869\u65b9\u6cd5\uff0c\u57fa\u4e8eLibAFL-DiFuzz\u540e\u7aef\u5b9e\u73b0\u3002", "result": "Rust-LibAFL-DiFuzz\u5728TTE\u5b9e\u9a8c\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4f18\u4e8eafl.rs\u3001cargo-fuzz\u7b49\u5de5\u5177\uff1bGo-LibAFL-DiFuzz\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u5e73\u5747\u7ed3\u679c\u6700\u597d\uff0c\u6709\u4e24\u4e2a\u6848\u4f8b\u5b58\u5728\u6570\u91cf\u7ea7\u5dee\u5f02\u7684\u4f18\u52bf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6269\u5c55\u4e86\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u5728C/C++\u4ee5\u5916\u7684\u5e94\u7528\u8303\u56f4\uff0c\u8bc1\u660e\u4e86\u9488\u5bf9Rust\u548cGo\u7684\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2601.22881", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22881", "abs": "https://arxiv.org/abs/2601.22881", "authors": ["Ke Ping", "Hamza Bin Mazhar", "Yuqing Wang", "Ying Song", "Mika V. M\u00e4ntyl\u00e4"], "title": "AnoMod: A Dataset for Anomaly Detection and Root Cause Analysis in Microservice Systems", "comment": "Accepted at the 23rd International Conference on Mining Software Repositories (MSR 2026). Dataset paper", "summary": "Microservice systems (MSS) have become a predominant architectural style for cloud services. Yet the community still lacks high-quality, publicly available datasets for anomaly detection (AD) and root cause analysis (RCA) in MSS. Most benchmarks emphasize performance-related faults and provide only one or two monitoring modalities, limiting research on broader failure modes and cross-modal methods. To address these gaps, we introduce a new multimodal anomaly dataset built on two open-source microservice systems: SocialNetwork and TrainTicket. We design and inject four categories of anomalies (Ano): performance-level, service-level, database-level, and code-level, to emulate realistic anomaly modes. For each scenario, we collect five modalities (Mod): logs, metrics, distributed traces, API responses, and code coverage reports, offering a richer, end-to-end view of system state and inter-service interactions. We name our dataset, reflecting its unique properties, as AnoMod. This dataset enables (1) evaluation of cross-modal anomaly detection and fusion/ablation strategies, and (2) fine-grained RCA studies across service and code regions, supporting end-to-end troubleshooting pipelines that jointly consider detection and localization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86AnoMod\u6570\u636e\u96c6\uff0c\u4e00\u4e2a\u7528\u4e8e\u5fae\u670d\u52a1\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u548c\u6839\u56e0\u5206\u6790\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5305\u542b\u56db\u79cd\u5f02\u5e38\u7c7b\u578b\u548c\u4e94\u79cd\u76d1\u63a7\u6a21\u6001\u3002", "motivation": "\u5f53\u524d\u5fae\u670d\u52a1\u7cfb\u7edf\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u3001\u516c\u5f00\u53ef\u7528\u7684\u5f02\u5e38\u68c0\u6d4b\u548c\u6839\u56e0\u5206\u6790\u6570\u636e\u96c6\u3002\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u6027\u80fd\u76f8\u5173\u6545\u969c\uff0c\u4e14\u4ec5\u63d0\u4f9b\u4e00\u5230\u4e24\u79cd\u76d1\u63a7\u6a21\u6001\uff0c\u9650\u5236\u4e86\u66f4\u5e7f\u6cdb\u6545\u969c\u6a21\u5f0f\u548c\u591a\u6a21\u6001\u65b9\u6cd5\u7684\u7814\u7a76\u3002", "method": "\u57fa\u4e8e\u4e24\u4e2a\u5f00\u6e90\u5fae\u670d\u52a1\u7cfb\u7edf\uff08SocialNetwork\u548cTrainTicket\uff09\uff0c\u8bbe\u8ba1\u5e76\u6ce8\u5165\u4e86\u56db\u7c7b\u5f02\u5e38\uff1a\u6027\u80fd\u7ea7\u3001\u670d\u52a1\u7ea7\u3001\u6570\u636e\u5e93\u7ea7\u548c\u4ee3\u7801\u7ea7\u3002\u4e3a\u6bcf\u4e2a\u573a\u666f\u6536\u96c6\u4e94\u79cd\u6a21\u6001\u6570\u636e\uff1a\u65e5\u5fd7\u3001\u6307\u6807\u3001\u5206\u5e03\u5f0f\u8ffd\u8e2a\u3001API\u54cd\u5e94\u548c\u4ee3\u7801\u8986\u76d6\u7387\u62a5\u544a\u3002", "result": "\u521b\u5efa\u4e86AnoMod\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u3001\u7aef\u5230\u7aef\u7684\u7cfb\u7edf\u72b6\u6001\u89c6\u56fe\u548c\u8de8\u670d\u52a1\u4ea4\u4e92\u4fe1\u606f\uff0c\u652f\u6301\u8de8\u6a21\u6001\u5f02\u5e38\u68c0\u6d4b\u548c\u878d\u5408/\u6d88\u878d\u7b56\u7565\u8bc4\u4f30\uff0c\u4ee5\u53ca\u8de8\u670d\u52a1\u548c\u4ee3\u7801\u533a\u57df\u7684\u7ec6\u7c92\u5ea6\u6839\u56e0\u5206\u6790\u7814\u7a76\u3002", "conclusion": "AnoMod\u6570\u636e\u96c6\u586b\u8865\u4e86\u5fae\u670d\u52a1\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u548c\u6839\u56e0\u5206\u6790\u9886\u57df\u7684\u6570\u636e\u7a7a\u767d\uff0c\u652f\u6301\u7aef\u5230\u7aef\u6545\u969c\u6392\u9664\u6d41\u7a0b\uff0c\u80fd\u591f\u540c\u65f6\u8003\u8651\u5f02\u5e38\u68c0\u6d4b\u548c\u5b9a\u4f4d\uff0c\u4e3a\u591a\u6a21\u6001\u65b9\u6cd5\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2601.22617", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22617", "abs": "https://arxiv.org/abs/2601.22617", "authors": ["Hongxi Yan", "Qingjie Liu", "Yunhong Wang"], "title": "EntroCut: Entropy-Guided Adaptive Truncation for Efficient Chain-of-Thought Reasoning in Small-scale Large Reasoning Models", "comment": "Accepted by ICASSP26", "summary": "Large Reasoning Models (LRMs) excel at complex reasoning tasks through extended chain-of-thought generation, but their reliance on lengthy intermediate steps incurs substantial computational cost. We find that the entropy of the model's output distribution in early reasoning steps reliably distinguishes correct from incorrect reasoning. Motivated by this observation, we propose EntroCut, a training-free method that dynamically truncates reasoning by identifying high-confidence states where reasoning can be safely terminated. To comprehensively evaluate the trade-off between efficiency and accuracy, we introduce the Efficiency-Performance Ratio (EPR), a unified metric that quantifies relative token savings per unit accuracy loss. Experiments on four benchmarks show that EntroCut reduces token usage by up to 40\\% with minimal accuracy sacrifice, achieving superior efficiency-performance trade-offs compared with existing training-free methods. These results demonstrate that entropy-guided dynamic truncation provides a practical approach to mitigate the inefficiency of LRMs.", "AI": {"tldr": "EntroCut\uff1a\u4e00\u79cd\u57fa\u4e8e\u71b5\u7684\u52a8\u6001\u622a\u65ad\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u9ad8\u7f6e\u4fe1\u5ea6\u72b6\u6001\u6765\u63d0\u524d\u7ec8\u6b62\u63a8\u7406\u8fc7\u7a0b\uff0c\u663e\u8457\u51cf\u5c11\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684token\u6d88\u8017", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4f9d\u8d56\u5197\u957f\u7684\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5728\u65e9\u671f\u63a8\u7406\u6b65\u9aa4\u7684\u8f93\u51fa\u5206\u5e03\u71b5\u80fd\u591f\u53ef\u9760\u5730\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u63a8\u7406\uff0c\u8fd9\u542f\u53d1\u4e86\u5f00\u53d1\u66f4\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5\u7684\u9700\u6c42", "method": "\u63d0\u51faEntroCut\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u52a8\u6001\u622a\u65ad\u6280\u672f\u3002\u901a\u8fc7\u76d1\u6d4b\u6a21\u578b\u8f93\u51fa\u5206\u5e03\u7684\u71b5\u6765\u8bc6\u522b\u9ad8\u7f6e\u4fe1\u5ea6\u72b6\u6001\uff0c\u5728\u8fd9\u4e9b\u72b6\u6001\u4e0b\u53ef\u4ee5\u5b89\u5168\u5730\u63d0\u524d\u7ec8\u6b62\u63a8\u7406\u8fc7\u7a0b\uff0c\u4ece\u800c\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684token\u6d88\u8017", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEntroCut\u80fd\u591f\u5c06token\u4f7f\u7528\u91cf\u51cf\u5c11\u9ad8\u8fbe40%\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u5c0f\u7684\u51c6\u786e\u7387\u635f\u5931\u3002\u8be5\u65b9\u6cd5\u5728\u6548\u7387-\u6027\u80fd\u6743\u8861\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u65e0\u9700\u8bad\u7ec3\u65b9\u6cd5", "conclusion": "\u57fa\u4e8e\u71b5\u7684\u52a8\u6001\u622a\u65ad\u4e3a\u7f13\u89e3\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u4f4e\u6548\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8d44\u6e90\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.22804", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.22804", "abs": "https://arxiv.org/abs/2601.22804", "authors": ["Rourab Paul", "Krishnendu Guha", "Amlan Chakrabarti"], "title": "Trojan-Resilient NTT: Protecting Against Control Flow and Timing Faults on Reconfigurable Platforms", "comment": null, "summary": "Number Theoretic Transform (NTT) is the most essential component for polynomial multiplications used in lattice-based Post-Quantum Cryptography (PQC) algorithms such as Kyber, Dilithium, NTRU etc. However, side-channel attacks (SCA) and hardware vulnerabilities in the form of hardware Trojans may alter control signals to disrupt the circuit's control flow and introduce unconventional delays in the critical hardware of PQC. Hardware Trojans, especially on control signals, are more low cost and impactful than data signals because a single corrupted control signal can disrupt or bypass entire computation sequences, whereas data faults usually cause only localized errors. On the other hand, adversaries can perform Soft Analytical Side Channel Attacks (SASCA) on the design using the inserted hardware Trojan. In this paper, we present a secure NTT architecture capable of detecting unconventional delays, control-flow disruptions, and SASCA, while providing an adaptive fault-correction methodology for their mitigation. Extensive simulations and implementations of our Secure NTT on Artix-7 FPGA with different Kyber variants show that our fault detection and correction modules can efficiently detect and correct faults whether caused unintentionally or intentionally by hardware Trojans with a high success rate, while introducing only modest area and time overheads.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5b89\u5168\u7684NTT\u67b6\u6784\uff0c\u80fd\u591f\u68c0\u6d4b\u975e\u5e38\u89c4\u5ef6\u8fdf\u3001\u63a7\u5236\u6d41\u4e2d\u65ad\u548c\u8f6f\u5206\u6790\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u5e76\u63d0\u4f9b\u81ea\u9002\u5e94\u6545\u969c\u6821\u6b63\u65b9\u6cd5\uff0c\u7528\u4e8e\u540e\u91cf\u5b50\u5bc6\u7801\u786c\u4ef6\u5b89\u5168\u9632\u62a4\u3002", "motivation": "\u6570\u8bba\u53d8\u6362(NTT)\u662f\u540e\u91cf\u5b50\u5bc6\u7801\u7b97\u6cd5\u4e2d\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u4f46\u4fa7\u4fe1\u9053\u653b\u51fb\u548c\u786c\u4ef6\u6728\u9a6c\u53ef\u80fd\u7834\u574f\u7535\u8def\u63a7\u5236\u6d41\u5e76\u5f15\u5165\u975e\u5e38\u89c4\u5ef6\u8fdf\u3002\u786c\u4ef6\u6728\u9a6c\u5bf9\u63a7\u5236\u4fe1\u53f7\u7684\u653b\u51fb\u6210\u672c\u4f4e\u4e14\u5f71\u54cd\u5927\uff0c\u800c\u8f6f\u5206\u6790\u4fa7\u4fe1\u9053\u653b\u51fb(SASCA)\u53ef\u80fd\u5229\u7528\u63d2\u5165\u7684\u786c\u4ef6\u6728\u9a6c\u8fdb\u884c\u653b\u51fb\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5b89\u5168\u7684NTT\u67b6\u6784\uff0c\u5305\u542b\u6545\u969c\u68c0\u6d4b\u548c\u6821\u6b63\u6a21\u5757\uff0c\u80fd\u591f\u68c0\u6d4b\u975e\u5e38\u89c4\u5ef6\u8fdf\u3001\u63a7\u5236\u6d41\u4e2d\u65ad\u548cSASCA\u653b\u51fb\uff0c\u5e76\u63d0\u4f9b\u81ea\u9002\u5e94\u6545\u969c\u6821\u6b63\u673a\u5236\u6765\u7f13\u89e3\u8fd9\u4e9b\u5a01\u80c1\u3002", "result": "\u5728Artix-7 FPGA\u4e0a\u5bf9\u4e0d\u540cKyber\u53d8\u4f53\u8fdb\u884c\u5e7f\u6cdb\u4eff\u771f\u548c\u5b9e\u73b0\uff0c\u7ed3\u679c\u663e\u793a\u6545\u969c\u68c0\u6d4b\u548c\u6821\u6b63\u6a21\u5757\u80fd\u591f\u9ad8\u6548\u68c0\u6d4b\u548c\u6821\u6b63\u7531\u786c\u4ef6\u6728\u9a6c\u5f15\u8d77\u7684\u6545\u969c\uff0c\u6210\u529f\u7387\u5f88\u9ad8\uff0c\u540c\u65f6\u53ea\u5f15\u5165\u9002\u5ea6\u7684\u9762\u79ef\u548c\u65f6\u95f4\u5f00\u9500\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b89\u5168NTT\u67b6\u6784\u80fd\u591f\u6709\u6548\u9632\u62a4\u540e\u91cf\u5b50\u5bc6\u7801\u786c\u4ef6\u4e2d\u7684\u4fa7\u4fe1\u9053\u653b\u51fb\u548c\u786c\u4ef6\u6728\u9a6c\u5a01\u80c1\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u62a4\u3002"}}
{"id": "2601.22919", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22919", "abs": "https://arxiv.org/abs/2601.22919", "authors": ["Fabian Bally", "Michael Sch\u00f6tz", "Thomas Limbrunner"], "title": "A Serverless Edge-Native Data Processing Architecture for Autonomous Driving Training", "comment": "Source code is available at https://github.com/LASFAS/jblambda", "summary": "Data is both the key enabler and a major bottleneck for machine learning in autonomous driving. Effective model training requires not only large quantities of sensor data but also balanced coverage that includes rare yet safety-critical scenarios. Capturing such events demands extensive driving time and efficient selection. This paper introduces the Lambda framework, an edge-native platform that enables on-vehicle data filtering and processing through user-defined functions. The framework provides a serverless-inspired abstraction layer that separates application logic from low-level execution concerns such as scheduling, deployment, and isolation. By adapting Function-as-a-Service (FaaS) principles to resource-constrained automotive environments, it allows developers to implement modular, event-driven filtering algorithms while maintaining compatibility with ROS 2 and existing data recording pipelines. We evaluate the framework on an NVIDIA Jetson Orin Nano and compare it against native ROS 2 deployments. Results show competitive performance, reduced latency and jitter, and confirm that lambda-based abstractions can support real-time data processing in embedded autonomous driving systems. The source code is available at https://github.com/LASFAS/jblambda.", "AI": {"tldr": "Lambda\u6846\u67b6\u662f\u4e00\u4e2a\u8fb9\u7f18\u539f\u751f\u5e73\u53f0\uff0c\u901a\u8fc7\u7528\u6237\u5b9a\u4e49\u51fd\u6570\u5b9e\u73b0\u8f66\u8f7d\u6570\u636e\u8fc7\u6ee4\u548c\u5904\u7406\uff0c\u5c06FaaS\u539f\u5219\u9002\u914d\u5230\u8d44\u6e90\u53d7\u9650\u7684\u6c7d\u8f66\u73af\u5883\u4e2d\uff0c\u652f\u6301\u5b9e\u65f6\u6570\u636e\u5904\u7406\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u673a\u5668\u5b66\u4e60\u9700\u8981\u5927\u91cf\u4f20\u611f\u5668\u6570\u636e\uff0c\u7279\u522b\u662f\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u5e73\u8861\u8986\u76d6\uff0c\u4f46\u6355\u83b7\u8fd9\u4e9b\u4e8b\u4ef6\u9700\u8981\u5927\u91cf\u9a7e\u9a76\u65f6\u95f4\u548c\u9ad8\u6548\u9009\u62e9\uff0c\u73b0\u6709\u7cfb\u7edf\u5b58\u5728\u74f6\u9888\u3002", "method": "\u5f15\u5165Lambda\u6846\u67b6\uff0c\u63d0\u4f9b\u65e0\u670d\u52a1\u5668\u98ce\u683c\u7684\u62bd\u8c61\u5c42\uff0c\u5206\u79bb\u5e94\u7528\u903b\u8f91\u4e0e\u5e95\u5c42\u6267\u884c\u5173\u6ce8\u70b9\uff0c\u9002\u914dFaaS\u539f\u5219\u5230\u6c7d\u8f66\u73af\u5883\uff0c\u652f\u6301\u6a21\u5757\u5316\u3001\u4e8b\u4ef6\u9a71\u52a8\u7684\u8fc7\u6ee4\u7b97\u6cd5\uff0c\u517c\u5bb9ROS 2\u548c\u73b0\u6709\u6570\u636e\u8bb0\u5f55\u7ba1\u9053\u3002", "result": "\u5728NVIDIA Jetson Orin Nano\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u539f\u751fROS 2\u90e8\u7f72\uff0c\u8868\u73b0\u51fa\u7ade\u4e89\u6027\u6027\u80fd\u3001\u964d\u4f4e\u7684\u5ef6\u8fdf\u548c\u6296\u52a8\uff0c\u8bc1\u5b9elambda\u62bd\u8c61\u80fd\u652f\u6301\u5d4c\u5165\u5f0f\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5b9e\u65f6\u6570\u636e\u5904\u7406\u3002", "conclusion": "Lambda\u6846\u67b6\u6210\u529f\u5c06FaaS\u539f\u5219\u5f15\u5165\u8d44\u6e90\u53d7\u9650\u7684\u6c7d\u8f66\u73af\u5883\uff0c\u652f\u6301\u5b9e\u65f6\u6570\u636e\u8fc7\u6ee4\u548c\u5904\u7406\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u6570\u636e\u91c7\u96c6\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22623", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.22623", "abs": "https://arxiv.org/abs/2601.22623", "authors": ["Wei Zhu", "Zhiwen Tang", "Kun Yue"], "title": "SYMPHONY: Synergistic Multi-agent Planning with Heterogeneous Language Model Assembly", "comment": "Accepted by NeurIPS 2025", "summary": "Recent advancements have increasingly focused on leveraging large language models (LLMs) to construct autonomous agents for complex problem-solving tasks. However, existing approaches predominantly employ a single-agent framework to generate search branches and estimate rewards during Monte Carlo Tree Search (MCTS) planning. This single-agent paradigm inherently limits exploration capabilities, often resulting in insufficient diversity among generated branches and suboptimal planning performance. To overcome these limitations, we propose Synergistic Multi-agent Planning with Heterogeneous langauge model assembly (SYMPHONY), a novel multi-agent planning framework that integrates a pool of heterogeneous language model-based agents. By leveraging diverse reasoning patterns across agents, SYMPHONY enhances rollout diversity and facilitates more effective exploration. Empirical results across multiple benchmark tasks show that SYMPHONY achieves strong performance even when instantiated with open-source LLMs deployable on consumer-grade hardware. When enhanced with cloud-based LLMs accessible via API, SYMPHONY demonstrates further improvements, outperforming existing state-of-the-art baselines and underscoring the effectiveness of heterogeneous multi-agent coordination in planning tasks.", "AI": {"tldr": "SYMPHONY\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u5f02\u6784\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u6c60\u6765\u589e\u5f3a\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u63a2\u7d22\u80fd\u529b\uff0c\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u6846\u67b6\u80fd\u751f\u6210\u66f4\u591a\u6837\u5316\u7684\u641c\u7d22\u5206\u652f\uff0c\u63d0\u5347\u89c4\u5212\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u4e3b\u8981\u91c7\u7528\u5355\u667a\u80fd\u4f53\u6846\u67b6\u8fdb\u884c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u89c4\u5212\uff0c\u8fd9\u79cd\u8303\u5f0f\u9650\u5236\u4e86\u63a2\u7d22\u80fd\u529b\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u641c\u7d22\u5206\u652f\u591a\u6837\u6027\u4e0d\u8db3\uff0c\u89c4\u5212\u6027\u80fd\u6b20\u4f73\u3002", "method": "\u63d0\u51faSYMPHONY\u6846\u67b6\uff0c\u96c6\u6210\u5f02\u6784\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u6c60\uff0c\u5229\u7528\u4e0d\u540c\u667a\u80fd\u4f53\u7684\u591a\u6837\u5316\u63a8\u7406\u6a21\u5f0f\u6765\u589e\u5f3arollout\u591a\u6837\u6027\uff0c\u4fc3\u8fdb\u66f4\u6709\u6548\u7684\u63a2\u7d22\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u4efb\u52a1\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cSYMPHONY\u5373\u4f7f\u4f7f\u7528\u53ef\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u90e8\u7f72\u7684\u5f00\u6e90LLMs\u4e5f\u80fd\u5b9e\u73b0\u5f3a\u5927\u6027\u80fd\uff1b\u5f53\u4f7f\u7528\u57fa\u4e8e\u4e91\u7684API\u8bbf\u95ee\u7684LLMs\u589e\u5f3a\u65f6\uff0c\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5f02\u6784\u591a\u667a\u80fd\u4f53\u534f\u8c03\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u5177\u6709\u663e\u8457\u6548\u679c\uff0cSYMPHONY\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u591a\u6837\u5316\u667a\u80fd\u4f53\u589e\u5f3a\u4e86\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u63a2\u7d22\u80fd\u529b\uff0c\u4e3a\u590d\u6742\u95ee\u9898\u89e3\u51b3\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u6784\u5efa\u65b9\u6cd5\u3002"}}
{"id": "2601.22818", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22818", "abs": "https://arxiv.org/abs/2601.22818", "authors": ["Charles Westphal", "Keivan Navaie", "Fernando E. Rosas"], "title": "Hide and Seek in Embedding Space: Geometry-based Steganography and Detection in Large Language Models", "comment": null, "summary": "Fine-tuned LLMs can covertly encode prompt secrets into outputs via steganographic channels. Prior work demonstrated this threat but relied on trivially recoverable encodings. We formalize payload recoverability via classifier accuracy and show previous schemes achieve 100\\% recoverability. In response, we introduce low-recoverability steganography, replacing arbitrary mappings with embedding-space-derived ones. For Llama-8B (LoRA) and Ministral-8B (LoRA) trained on TrojanStego prompts, exact secret recovery rises from 17$\\rightarrow$30\\% (+78\\%) and 24$\\rightarrow$43\\% (+80\\%) respectively, while on Llama-70B (LoRA) trained on Wiki prompts, it climbs from 9$\\rightarrow$19\\% (+123\\%), all while reducing payload recoverability. We then discuss detection. We argue that detecting fine-tuning-based steganographic attacks requires approaches beyond traditional steganalysis. Standard approaches measure distributional shift, which is an expected side-effect of fine-tuning. Instead, we propose a mechanistic interpretability approach: linear probes trained on later-layer activations detect the secret with up to 33\\% higher accuracy in fine-tuned models compared to base models, even for low-recoverability schemes. This suggests that malicious fine-tuning leaves actionable internal signatures amenable to interpretability-based defenses.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76LLM\u5fae\u8c03\u4e2d\u7684\u9690\u5199\u672f\u653b\u51fb\uff0c\u63d0\u51fa\u4f4e\u53ef\u6062\u590d\u6027\u9690\u5199\u65b9\u6848\uff0c\u5e76\u63a2\u8ba8\u57fa\u4e8e\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7684\u68c0\u6d4b\u65b9\u6cd5", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u5fae\u8c03\u540e\u7684LLM\u53ef\u4ee5\u901a\u8fc7\u9690\u5199\u901a\u9053\u5c06\u63d0\u793a\u79d8\u5bc6\u7f16\u7801\u5230\u8f93\u51fa\u4e2d\uff0c\u4f46\u5148\u524d\u5de5\u4f5c\u4f9d\u8d56\u4e8e\u53ef\u8f7b\u6613\u6062\u590d\u7684\u7f16\u7801\u65b9\u5f0f\u3002\u9700\u8981\u7814\u7a76\u66f4\u9690\u853d\u7684\u9690\u5199\u65b9\u6848\u53ca\u5176\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "1. \u5f62\u5f0f\u5316\u5b9a\u4e49\u6709\u6548\u8f7d\u8377\u53ef\u6062\u590d\u6027\uff08\u901a\u8fc7\u5206\u7c7b\u5668\u51c6\u786e\u7387\u8861\u91cf\uff09\uff1b2. \u63d0\u51fa\u4f4e\u53ef\u6062\u590d\u6027\u9690\u5199\u65b9\u6848\uff0c\u7528\u5d4c\u5165\u7a7a\u95f4\u5bfc\u51fa\u7684\u6620\u5c04\u66ff\u6362\u4efb\u610f\u6620\u5c04\uff1b3. \u4f7f\u7528\u7ebf\u6027\u63a2\u9488\u5206\u6790\u540e\u671f\u5c42\u6fc0\u6d3b\uff0c\u68c0\u6d4b\u79d8\u5bc6\u5b58\u5728\u3002", "result": "\u5728Llama-8B\u548cMinistral-8B\u4e0a\uff0c\u7cbe\u786e\u79d8\u5bc6\u6062\u590d\u7387\u5206\u522b\u4ece17%\u63d0\u5347\u523030%\uff08+78%\uff09\u548c24%\u63d0\u5347\u523043%\uff08+80%\uff09\uff1b\u5728Llama-70B\u4e0a\u4ece9%\u63d0\u5347\u523019%\uff08+123%\uff09\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u6709\u6548\u8f7d\u8377\u53ef\u6062\u590d\u6027\u3002\u7ebf\u6027\u63a2\u9488\u5728\u5fae\u8c03\u6a21\u578b\u4e2d\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u6bd4\u57fa\u7840\u6a21\u578b\u9ad833%\u3002", "conclusion": "\u6076\u610f\u5fae\u8c03\u4f1a\u5728\u6a21\u578b\u4e2d\u7559\u4e0b\u53ef\u64cd\u4f5c\u7684\u5185\u5728\u7b7e\u540d\uff0c\u57fa\u4e8e\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u68c0\u6d4b\u4f4e\u53ef\u6062\u590d\u6027\u9690\u5199\u653b\u51fb\uff0c\u4e3a\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.22952", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22952", "abs": "https://arxiv.org/abs/2601.22952", "authors": ["Yunpeng Xiong", "Ting Zhang"], "title": "Sifting the Noise: A Comparative Study of LLM Agents in Vulnerability False Positive Filtering", "comment": null, "summary": "Static Application Security Testing (SAST) tools are essential for identifying software vulnerabilities, but they often produce a high volume of false positives (FPs), imposing a substantial manual triage burden on developers. Recent advances in Large Language Model (LLM) agents offer a promising direction by enabling iterative reasoning, tool use, and environment interaction to refine SAST alerts. However, the comparative effectiveness of different LLM-based agent architectures for FP filtering remains poorly understood. In this paper, we present a comparative study of three state-of-the-art LLM-based agent frameworks, i.e., Aider, OpenHands, and SWE-agent, for vulnerability FP filtering. We evaluate these frameworks using the vulnerabilities from the OWASP Benchmark and real-world open-source Java projects. The experimental results show that LLM-based agents can remove the majority of SAST noise, reducing an initial FP detection rate of over 92% on the OWASP Benchmark to as low as 6.3% in the best configuration. On real-world dataset, the best configuration of LLM-based agents can achieve an FP identification rate of up to 93.3% involving CodeQL alerts. However, the benefits of agents are strongly backbone- and CWE-dependent: agentic frameworks significantly outperform vanilla prompting for stronger models such as Claude Sonnet 4 and GPT-5, but yield limited or inconsistent gains for weaker backbones. Moreover, aggressive FP reduction can come at the cost of suppressing true vulnerabilities, highlighting important trade-offs. Finally, we observe large disparities in computational cost across agent frameworks. Overall, our study demonstrates that LLM-based agents are a powerful but non-uniform solution for SAST FP filtering, and that their practical deployment requires careful consideration of agent design, backbone model choice, vulnerability category, and operational cost.", "AI": {"tldr": "LLM\u667a\u80fd\u4f53\u5728SAST\u8bef\u62a5\u8fc7\u6ee4\u4e2d\u7684\u6bd4\u8f83\u7814\u7a76\uff1aAider\u3001OpenHands\u548cSWE-agent\u4e09\u79cd\u6846\u67b6\u5728OWASP\u57fa\u51c6\u548c\u771f\u5b9eJava\u9879\u76ee\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u6700\u4f73\u914d\u7f6e\u53ef\u5c06\u8bef\u62a5\u7387\u4ece92%\u964d\u81f36.3%\uff0c\u4f46\u6548\u679c\u53d7\u9aa8\u5e72\u6a21\u578b\u3001\u6f0f\u6d1e\u7c7b\u578b\u548c\u8ba1\u7b97\u6210\u672c\u5f71\u54cd\u663e\u8457\u3002", "motivation": "SAST\u5de5\u5177\u4ea7\u751f\u5927\u91cf\u8bef\u62a5\uff0c\u7ed9\u5f00\u53d1\u8005\u5e26\u6765\u7e41\u91cd\u7684\u624b\u52a8\u6392\u67e5\u8d1f\u62c5\u3002\u867d\u7136LLM\u667a\u80fd\u4f53\u901a\u8fc7\u8fed\u4ee3\u63a8\u7406\u3001\u5de5\u5177\u4f7f\u7528\u548c\u73af\u5883\u4ea4\u4e92\u4e3aSAST\u8bef\u62a5\u8fc7\u6ee4\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u4f46\u4e0d\u540cLLM\u667a\u80fd\u4f53\u67b6\u6784\u5728\u8bef\u62a5\u8fc7\u6ee4\u4e2d\u7684\u6bd4\u8f83\u6548\u679c\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u6bd4\u8f83\u7814\u7a76\u4e09\u79cd\u6700\u5148\u8fdb\u7684LLM\u667a\u80fd\u4f53\u6846\u67b6\uff08Aider\u3001OpenHands\u548cSWE-agent\uff09\u5728\u6f0f\u6d1e\u8bef\u62a5\u8fc7\u6ee4\u4e2d\u7684\u8868\u73b0\u3002\u4f7f\u7528OWASP\u57fa\u51c6\u548c\u771f\u5b9e\u5f00\u6e90Java\u9879\u76ee\u4e2d\u7684\u6f0f\u6d1e\u8fdb\u884c\u8bc4\u4f30\uff0c\u5206\u6790\u4e0d\u540c\u914d\u7f6e\u4e0b\u667a\u80fd\u4f53\u6846\u67b6\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "LLM\u667a\u80fd\u4f53\u80fd\u663e\u8457\u51cf\u5c11SAST\u566a\u58f0\uff1a\u5728OWASP\u57fa\u51c6\u4e0a\uff0c\u6700\u4f73\u914d\u7f6e\u53ef\u5c06\u521d\u59cb92%\u4ee5\u4e0a\u7684\u8bef\u62a5\u7387\u964d\u81f36.3%\uff1b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9CodeQL\u8b66\u62a5\u7684\u8bef\u62a5\u8bc6\u522b\u7387\u53ef\u8fbe93.3%\u3002\u4f46\u6548\u679c\u9ad8\u5ea6\u4f9d\u8d56\u9aa8\u5e72\u6a21\u578b\u548cCWE\u7c7b\u578b\uff1a\u667a\u80fd\u4f53\u6846\u67b6\u5bf9Claude Sonnet 4\u548cGPT-5\u7b49\u5f3a\u6a21\u578b\u6548\u679c\u663e\u8457\uff0c\u5bf9\u5f31\u6a21\u578b\u63d0\u5347\u6709\u9650\uff1b\u6fc0\u8fdb\u7684\u8bef\u62a5\u51cf\u5c11\u53ef\u80fd\u6291\u5236\u771f\u5b9e\u6f0f\u6d1e\uff1b\u4e0d\u540c\u6846\u67b6\u7684\u8ba1\u7b97\u6210\u672c\u5dee\u5f02\u5f88\u5927\u3002", "conclusion": "LLM\u667a\u80fd\u4f53\u662fSAST\u8bef\u62a5\u8fc7\u6ee4\u7684\u5f3a\u5927\u4f46\u975e\u5747\u5300\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u9645\u90e8\u7f72\u9700\u8981\u4ed4\u7ec6\u8003\u8651\u667a\u80fd\u4f53\u8bbe\u8ba1\u3001\u9aa8\u5e72\u6a21\u578b\u9009\u62e9\u3001\u6f0f\u6d1e\u7c7b\u522b\u548c\u8fd0\u8425\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u3002"}}
{"id": "2601.22636", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22636", "abs": "https://arxiv.org/abs/2601.22636", "authors": ["Mingqian Feng", "Xiaodong Liu", "Weiwei Yang", "Chenliang Xu", "Christopher White", "Jianfeng Gao"], "title": "Statistical Estimation of Adversarial Risk in Large Language Models under Best-of-N Sampling", "comment": null, "summary": "Large Language Models (LLMs) are typically evaluated for safety under single-shot or low-budget adversarial prompting, which underestimates real-world risk. In practice, attackers can exploit large-scale parallel sampling to repeatedly probe a model until a harmful response is produced. While recent work shows that attack success increases with repeated sampling, principled methods for predicting large-scale adversarial risk remain limited. We propose a scaling-aware Best-of-N estimation of risk, SABER, for modeling jailbreak vulnerability under Best-of-N sampling. We model sample-level success probabilities using a Beta distribution, the conjugate prior of the Bernoulli distribution, and derive an analytic scaling law that enables reliable extrapolation of large-N attack success rates from small-budget measurements. Using only n=100 samples, our anchored estimator predicts ASR@1000 with a mean absolute error of 1.66, compared to 12.04 for the baseline, which is an 86.2% reduction in estimation error. Our results reveal heterogeneous risk scaling profiles and show that models appearing robust under standard evaluation can experience rapid nonlinear risk amplification under parallel adversarial pressure. This work provides a low-cost, scalable methodology for realistic LLM safety assessment. We will release our code and evaluation scripts upon publication to future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86SABER\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e76\u884c\u91c7\u6837\u653b\u51fb\u4e0b\u7684\u5b89\u5168\u98ce\u9669\uff0c\u901a\u8fc7Beta\u5206\u5e03\u5efa\u6a21\u6837\u672c\u7ea7\u6210\u529f\u6982\u7387\uff0c\u4ec5\u9700\u5c11\u91cf\u6837\u672c\u5373\u53ef\u51c6\u786e\u9884\u6d4b\u5927\u89c4\u6a21\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u8bc4\u4f30\u901a\u5e38\u57fa\u4e8e\u5355\u6b21\u6216\u4f4e\u9884\u7b97\u7684\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u8fd9\u4f4e\u4f30\u4e86\u5b9e\u9645\u98ce\u9669\u3002\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u5927\u89c4\u6a21\u5e76\u884c\u91c7\u6837\u53cd\u590d\u63a2\u6d4b\u6a21\u578b\u76f4\u5230\u4ea7\u751f\u6709\u5bb3\u54cd\u5e94\uff0c\u9700\u8981\u66f4\u51c6\u786e\u7684\u98ce\u9669\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSABER\u65b9\u6cd5\uff0c\u4f7f\u7528Beta\u5206\u5e03\uff08\u4f2f\u52aa\u5229\u5206\u5e03\u7684\u5171\u8f6d\u5148\u9a8c\uff09\u5efa\u6a21\u6837\u672c\u7ea7\u6210\u529f\u6982\u7387\uff0c\u63a8\u5bfc\u51fa\u89e3\u6790\u7f29\u653e\u5b9a\u5f8b\uff0c\u80fd\u591f\u4ece\u5c0f\u9884\u7b97\u6d4b\u91cf\u53ef\u9760\u5730\u5916\u63a8\u5927\u89c4\u6a21\u653b\u51fb\u6210\u529f\u7387\u3002", "result": "\u4ec5\u4f7f\u7528n=100\u4e2a\u6837\u672c\uff0cSABER\u65b9\u6cd5\u9884\u6d4bASR@1000\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4e3a1.66\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u768412.04\u8bef\u5dee\u51cf\u5c11\u4e8686.2%\u3002\u7814\u7a76\u63ed\u793a\u4e86\u5f02\u8d28\u98ce\u9669\u7f29\u653e\u7279\u5f81\uff0c\u663e\u793a\u5728\u6807\u51c6\u8bc4\u4f30\u4e0b\u770b\u4f3c\u7a33\u5065\u7684\u6a21\u578b\u5728\u5e76\u884c\u5bf9\u6297\u538b\u529b\u4e0b\u53ef\u80fd\u7ecf\u5386\u5feb\u901f\u975e\u7ebf\u6027\u98ce\u9669\u653e\u5927\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u53ef\u6269\u5c55\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u771f\u5b9e\u5730\u53cd\u6620\u5b9e\u9645\u653b\u51fb\u573a\u666f\u4e0b\u7684\u98ce\u9669\u3002\u7814\u7a76\u5c06\u53d1\u5e03\u4ee3\u7801\u548c\u8bc4\u4f30\u811a\u672c\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2601.22956", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22956", "abs": "https://arxiv.org/abs/2601.22956", "authors": ["Boyin Tan", "Haoning Deng", "Junyuan Zhang", "Junjielong Xu", "Pinjia He", "Youcheng Sun"], "title": "SWE-Manager: Selecting and Synthesizing Golden Proposals Before Coding", "comment": null, "summary": "Large language model (LLM) research in software engineering has largely focused on tasks such as code generation and bug repair. In practice, teams often draft multiple candidate proposals for fixing an issue and then deliberate on one golden proposal for implementation. This selection requires not only assessing the issue's scope, impact, and urgency, but also a clear understanding of each proposal's strengths and weaknesses. A good selection could make issue resolution more reliable while reducing regression and operational risk, whereas a poor choice can increase risk and even cause unpredictable failures.\n  We first conduct a manual study of real-world issues to characterize the rationales maintainers use when selecting among competing proposals. Motivated by these findings, we introduce SWE-Manager, a joint selection and synthesis approach that selects the best proposal and synthesizes a golden proposal. SWE-Manager is an 8B model trained via reinforcement learning (RL) to compare proposals, justify its choice, and synthesize a golden proposal for implementation. We view proposal selection as a reasoning task, mirroring how technical managers review competing proposals by weighing issue context and each proposal's solution without executing code or running tests. On the SWE-Lancer Manager benchmark, SWE-Manager achieves 53.21 selection accuracy and 57.75 earn rate, earning 152,750 dollars and outperforming strong baselines including GPT-5. To further evaluate the effectiveness of SWE-Manager in real-world issue resolution, we design the P2A framework, which simulates a real-world workflow where multiple proposals are drafted, reviewed, and a golden proposal is selected for implementation ...", "AI": {"tldr": "SWE-Manager\uff1a\u4e00\u4e2a\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u76848B\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u89e3\u51b3\u4e2d\u6bd4\u8f83\u591a\u4e2a\u4fee\u590d\u63d0\u6848\u3001\u9009\u62e9\u6700\u4f73\u65b9\u6848\u5e76\u5408\u6210\u6700\u7ec8\u5b9e\u65bd\u65b9\u6848", "motivation": "\u5f53\u524dLLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u4ee3\u7801\u751f\u6210\u548c\u9519\u8bef\u4fee\u590d\uff0c\u4f46\u5b9e\u9645\u56e2\u961f\u5de5\u4f5c\u4e2d\u9700\u8981\u4ece\u591a\u4e2a\u5019\u9009\u63d0\u6848\u4e2d\u9009\u62e9\u6700\u4f73\u65b9\u6848\u3002\u597d\u7684\u9009\u62e9\u80fd\u63d0\u9ad8\u95ee\u9898\u89e3\u51b3\u7684\u53ef\u9760\u6027\u5e76\u964d\u4f4e\u98ce\u9669\uff0c\u800c\u5dee\u7684\u9009\u62e9\u4f1a\u589e\u52a0\u98ce\u9669\u751a\u81f3\u5bfc\u81f4\u4e0d\u53ef\u9884\u6d4b\u7684\u6545\u969c\u3002", "method": "\u9996\u5148\u901a\u8fc7\u4eba\u5de5\u7814\u7a76\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u6765\u7406\u89e3\u7ef4\u62a4\u8005\u9009\u62e9\u63d0\u6848\u7684\u7406\u6027\u4f9d\u636e\u3002\u7136\u540e\u5f15\u5165SWE-Manager\uff0c\u8fd9\u662f\u4e00\u4e2a\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u76848B\u6a21\u578b\uff0c\u80fd\u591f\u6bd4\u8f83\u63d0\u6848\u3001\u8bc1\u660e\u9009\u62e9\u5408\u7406\u6027\u5e76\u5408\u6210\u6700\u7ec8\u5b9e\u65bd\u65b9\u6848\u3002\u5c06\u63d0\u6848\u9009\u62e9\u89c6\u4e3a\u63a8\u7406\u4efb\u52a1\uff0c\u6a21\u62df\u6280\u672f\u7ecf\u7406\u5728\u4e0d\u6267\u884c\u4ee3\u7801\u6216\u8fd0\u884c\u6d4b\u8bd5\u7684\u60c5\u51b5\u4e0b\u6743\u8861\u95ee\u9898\u4e0a\u4e0b\u6587\u548c\u6bcf\u4e2a\u63d0\u6848\u89e3\u51b3\u65b9\u6848\u7684\u8fc7\u7a0b\u3002", "result": "\u5728SWE-Lancer Manager\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSWE-Manager\u5b9e\u73b0\u4e8653.21%\u7684\u9009\u62e9\u51c6\u786e\u7387\u548c57.75%\u7684\u6536\u76ca\u7387\uff0c\u83b7\u5f97\u4e86152,750\u7f8e\u5143\u7684\u6536\u76ca\uff0c\u8868\u73b0\u4f18\u4e8e\u5305\u62ecGPT-5\u5728\u5185\u7684\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002\u8fd8\u8bbe\u8ba1\u4e86P2A\u6846\u67b6\u6765\u6a21\u62df\u771f\u5b9e\u4e16\u754c\u5de5\u4f5c\u6d41\u7a0b\u4ee5\u8fdb\u4e00\u6b65\u8bc4\u4f30\u6a21\u578b\u6548\u679c\u3002", "conclusion": "SWE-Manager\u901a\u8fc7\u5c06\u63d0\u6848\u9009\u62e9\u89c6\u4e3a\u63a8\u7406\u4efb\u52a1\uff0c\u6709\u6548\u6a21\u62df\u4e86\u6280\u672f\u7ecf\u7406\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5728\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u89e3\u51b3\u4e2d\u80fd\u591f\u9009\u62e9\u6700\u4f73\u63d0\u6848\u5e76\u5408\u6210\u5b9e\u65bd\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2601.22645", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22645", "abs": "https://arxiv.org/abs/2601.22645", "authors": ["Vaibhav Ram S. V. N. S", "Swetanshu Agrawal", "Samudra Banerjee", "Abdul Muhsin"], "title": "Beyond Medical Chatbots: Meddollina and the Rise of Continuous Clinical Intelligence", "comment": null, "summary": "Generative medical AI now appears fluent and knowledgeable enough to resemble clinical intelligence, encouraging the belief that scaling will make it safe. But clinical reasoning is not text generation. It is a responsibility-bound process under ambiguity, incomplete evidence, and longitudinal context. Even as benchmark scores rise, generation-centric systems still show behaviours incompatible with clinical deployment: premature closure, unjustified certainty, intent drift, and instability across multi-step decisions.\n  We argue these are structural consequences of treating medicine as next-token prediction. We formalise Clinical Contextual Intelligence (CCI) as a distinct capability class required for real-world clinical use, defined by persistent context awareness, intent preservation, bounded inference, and principled deferral when evidence is insufficient.\n  We introduce Meddollina, a governance-first clinical intelligence system designed to constrain inference before language realisation, prioritising clinical appropriateness over generative completeness. Meddollina acts as a continuous intelligence layer supporting clinical workflows while preserving clinician authority. We evaluate Meddollina using a behaviour-first regime across 16,412+ heterogeneous medical queries, benchmarking against general-purpose models, medical-tuned models, and retrieval-augmented systems.\n  Meddollina exhibits a distinct behavioural profile: calibrated uncertainty, conservative reasoning under underspecification, stable longitudinal constraint adherence, and reduced speculative completion relative to generation-centric baselines. These results suggest deployable medical AI will not emerge from scaling alone, motivating a shift toward Continuous Clinical Intelligence, where progress is measured by clinician-aligned behaviour under uncertainty rather than fluency-driven completion.", "AI": {"tldr": "\u8bba\u6587\u6279\u8bc4\u5f53\u524d\u751f\u6210\u5f0f\u533b\u7597AI\u4ec5\u5173\u6ce8\u6587\u672c\u751f\u6210\u800c\u975e\u4e34\u5e8a\u63a8\u7406\uff0c\u63d0\u51fa\u4e34\u5e8a\u60c5\u5883\u667a\u80fd(CCI)\u6982\u5ff5\uff0c\u5e76\u5f00\u53d1\u4e86Meddollina\u7cfb\u7edf\uff0c\u901a\u8fc7\u884c\u4e3a\u4f18\u5148\u8bc4\u4f30\u663e\u793a\u5176\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u6821\u51c6\u548c\u4fdd\u5b88\u63a8\u7406\u4f18\u4e8e\u751f\u6210\u4e2d\u5fc3\u57fa\u7ebf\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5f0f\u533b\u7597AI\u867d\u7136\u770b\u8d77\u6765\u6d41\u7545\u4e14\u77e5\u8bc6\u4e30\u5bcc\uff0c\u4f46\u4e34\u5e8a\u63a8\u7406\u4e0d\u662f\u6587\u672c\u751f\u6210\uff0c\u800c\u662f\u9700\u8981\u5728\u6a21\u7cca\u6027\u3001\u4e0d\u5b8c\u6574\u8bc1\u636e\u548c\u7eb5\u5411\u60c5\u5883\u4e0b\u627f\u62c5\u8d23\u4efb\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002\u751f\u6210\u4e2d\u5fc3\u7cfb\u7edf\u5b58\u5728\u8fc7\u65e9\u7ed3\u8bba\u3001\u4e0d\u5408\u7406\u786e\u5b9a\u6027\u3001\u610f\u56fe\u6f02\u79fb\u548c\u591a\u6b65\u51b3\u7b56\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\uff0c\u8fd9\u4e9b\u662f\"\u5c06\u533b\u5b66\u89c6\u4e3a\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\"\u7684\u7ed3\u6784\u6027\u540e\u679c\u3002", "method": "\u63d0\u51fa\u4e34\u5e8a\u60c5\u5883\u667a\u80fd(CCI)\u4f5c\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e34\u5e8a\u4f7f\u7528\u6240\u9700\u7684\u80fd\u529b\u7c7b\u522b\uff0c\u5b9a\u4e49\u4e3a\u5177\u6709\u6301\u7eed\u60c5\u5883\u610f\u8bc6\u3001\u610f\u56fe\u4fdd\u6301\u3001\u6709\u754c\u63a8\u7406\u548c\u8bc1\u636e\u4e0d\u8db3\u65f6\u7684\u539f\u5219\u6027\u5ef6\u8fdf\u3002\u5f00\u53d1\u4e86Meddollina\u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u6cbb\u7406\u4f18\u5148\u7684\u4e34\u5e8a\u667a\u80fd\u7cfb\u7edf\uff0c\u5728\u8bed\u8a00\u5b9e\u73b0\u524d\u7ea6\u675f\u63a8\u7406\uff0c\u4f18\u5148\u8003\u8651\u4e34\u5e8a\u9002\u5b9c\u6027\u800c\u975e\u751f\u6210\u5b8c\u6574\u6027\u3002\u91c7\u7528\u884c\u4e3a\u4f18\u5148\u8bc4\u4f30\u673a\u5236\uff0c\u572816,412+\u4e2a\u5f02\u8d28\u533b\u7597\u67e5\u8be2\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "Meddollina\u5c55\u73b0\u51fa\u72ec\u7279\u7684\u884c\u4e3a\u7279\u5f81\uff1a\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u3001\u5728\u672a\u660e\u786e\u60c5\u51b5\u4e0b\u7684\u4fdd\u5b88\u63a8\u7406\u3001\u7a33\u5b9a\u7684\u7eb5\u5411\u7ea6\u675f\u9075\u5b88\uff0c\u4ee5\u53ca\u76f8\u5bf9\u4e8e\u751f\u6210\u4e2d\u5fc3\u57fa\u7ebf\u7684\u51cf\u5c11\u63a8\u6d4b\u6027\u5b8c\u6210\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\u53ef\u90e8\u7f72\u7684\u533b\u7597AI\u4e0d\u4f1a\u4ec5\u901a\u8fc7\u6269\u5c55\u89c4\u6a21\u51fa\u73b0\u3002", "conclusion": "\u9700\u8981\u4ece\u6269\u5c55\u89c4\u6a21\u8f6c\u5411\u8fde\u7eed\u4e34\u5e8a\u667a\u80fd\uff0c\u5176\u4e2d\u8fdb\u5c55\u5e94\u901a\u8fc7\u4e34\u5e8a\u533b\u751f\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5bf9\u9f50\u884c\u4e3a\u6765\u8861\u91cf\uff0c\u800c\u975e\u57fa\u4e8e\u6d41\u7545\u5ea6\u7684\u5b8c\u6210\u5ea6\u3002Meddollina\u4f5c\u4e3a\u8fde\u7eed\u667a\u80fd\u5c42\u652f\u6301\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u4e34\u5e8a\u533b\u751f\u7684\u6743\u5a01\u3002"}}
{"id": "2601.22921", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22921", "abs": "https://arxiv.org/abs/2601.22921", "authors": ["Farnaz Soltaniani", "Shoaib Razzaq", "Mohammad Ghafari"], "title": "Evaluating Large Language Models for Security Bug Report Prediction", "comment": null, "summary": "Early detection of security bug reports (SBRs) is critical for timely vulnerability mitigation. We present an evaluation of prompt-based engineering and fine-tuning approaches for predicting SBRs using Large Language Models (LLMs). Our findings reveal a distinct trade-off between the two approaches. Prompted proprietary models demonstrate the highest sensitivity to SBRs, achieving a G-measure of 77% and a recall of 74% on average across all the datasets, albeit at the cost of a higher false-positive rate, resulting in an average precision of only 22%. Fine-tuned models, by contrast, exhibit the opposite behavior, attaining a lower overall G-measure of 51% but substantially higher precision of 75% at the cost of reduced recall of 36%. Though a one-time investment in building fine-tuned models is necessary, the inference on the largest dataset is up to 50 times faster than that of proprietary models. These findings suggest that further investigations to harness the power of LLMs for SBR prediction are necessary.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u4e8e\u63d0\u793a\u5de5\u7a0b\u548c\u5fae\u8c03\u4e24\u79cd\u65b9\u6cd5\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u7684\u6548\u679c\uff0c\u53d1\u73b0\u4e24\u8005\u5b58\u5728\u660e\u663e\u7684\u6743\u8861\u5173\u7cfb\uff1a\u63d0\u793a\u65b9\u6cd5\u53ec\u56de\u7387\u9ad8\u4f46\u7cbe\u5ea6\u4f4e\uff0c\u5fae\u8c03\u65b9\u6cd5\u7cbe\u5ea6\u9ad8\u4f46\u53ec\u56de\u7387\u4f4e\u3002", "motivation": "\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u7684\u65e9\u671f\u68c0\u6d4b\u5bf9\u4e8e\u53ca\u65f6\u7f13\u89e3\u6f0f\u6d1e\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728SBR\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u63d0\u793a\u7684\u5de5\u7a0b\u65b9\u6cd5\u548c\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u63d0\u793a\u65b9\u6cd5\u5e73\u5747G-measure\u4e3a77%\uff0c\u53ec\u56de\u738774%\uff0c\u4f46\u7cbe\u5ea6\u4ec522%\uff1b\u5fae\u8c03\u65b9\u6cd5G-measure\u4e3a51%\uff0c\u7cbe\u5ea675%\uff0c\u53ec\u56de\u738736%\u3002\u5fae\u8c03\u6a21\u578b\u63a8\u7406\u901f\u5ea6\u6bd4\u4e13\u6709\u6a21\u578b\u5feb50\u500d\u3002", "conclusion": "\u4e24\u79cd\u65b9\u6cd5\u5404\u6709\u4f18\u52a3\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u5145\u5206\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884cSBR\u9884\u6d4b\uff0c\u5fae\u8c03\u6a21\u578b\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e0a\u6709\u4f18\u52bf\uff0c\u63d0\u793a\u65b9\u6cd5\u5728\u53ec\u56de\u7387\u4e0a\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2601.22647", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22647", "abs": "https://arxiv.org/abs/2601.22647", "authors": ["Jinwoo Jang", "Minjong Yoo", "Sihyung Yoon", "Honguk Woo"], "title": "Test-Time Mixture of World Models for Embodied Agents in Dynamic Environments", "comment": "Accepted at ICLR 2026. 10 pages. Code available at https://github.com/doldam0/tmow", "summary": "Language model (LM)-based embodied agents are increasingly deployed in real-world settings. Yet, their adaptability remains limited in dynamic environments, where constructing accurate and flexible world models is crucial for effective reasoning and decision-making. To address this challenge, we extend the Mixture-of-Experts (MoE) paradigm to embodied agents. While conventional MoE architectures modularize knowledge into expert components with pre-trained routing, they remain rigid once deployed, making them less effective for adapting to unseen domains in dynamic environments. We therefore propose Test-time Mixture of World Models (TMoW), a framework that enhances adaptability to unseen and evolving domains. TMoW updates its routing function over world models at test time, unlike conventional MoE where the function remains fixed, enabling agents to recombine existing models and integrate new ones for continual adaptation. It achieves this through (i) multi-granular prototype-based routing, which adapts mixtures across object- to scene-level similarities, (ii) test-time refinement that aligns unseen domain features with prototypes during inference, and (iii) distilled mixture-based augmentation, which efficiently constructs new models from few-shot data and existing prototypes. We evaluate TMoW on VirtualHome, ALFWorld, and RLBench benchmarks, demonstrating strong performance in both zero-shot adaptation and few-shot expansion scenarios, and showing that it enables embodied agents to operate effectively in dynamic environments.", "AI": {"tldr": "TMoW\u6846\u67b6\u901a\u8fc7\u6d4b\u8bd5\u65f6\u66f4\u65b0\u4e16\u754c\u6a21\u578b\u7684\u8def\u7531\u51fd\u6570\uff0c\u589e\u5f3a\u5177\u8eab\u667a\u80fd\u4f53\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\uff0c\u652f\u6301\u96f6\u6837\u672c\u9002\u5e94\u548c\u5c11\u6837\u672c\u6269\u5c55", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u5177\u8eab\u667a\u80fd\u4f53\u5728\u52a8\u6001\u73af\u5883\u4e2d\u9002\u5e94\u6027\u6709\u9650\uff0c\u9700\u8981\u6784\u5efa\u51c6\u786e\u7075\u6d3b\u7684\u4e16\u754c\u6a21\u578b\u6765\u652f\u6301\u6709\u6548\u63a8\u7406\u548c\u51b3\u7b56", "method": "\u63d0\u51fa\u6d4b\u8bd5\u65f6\u4e16\u754c\u6a21\u578b\u6df7\u5408(TMoW)\u6846\u67b6\uff1a1)\u591a\u7c92\u5ea6\u539f\u578b\u8def\u7531\uff0c\u57fa\u4e8e\u5bf9\u8c61\u5230\u573a\u666f\u7ea7\u76f8\u4f3c\u6027\u8c03\u6574\u6df7\u5408\uff1b2)\u6d4b\u8bd5\u65f6\u7ec6\u5316\uff0c\u5728\u63a8\u7406\u65f6\u5bf9\u9f50\u672a\u89c1\u57df\u7279\u5f81\u4e0e\u539f\u578b\uff1b3)\u84b8\u998f\u6df7\u5408\u589e\u5f3a\uff0c\u4ece\u5c11\u91cf\u6570\u636e\u548c\u73b0\u6709\u539f\u578b\u9ad8\u6548\u6784\u5efa\u65b0\u6a21\u578b", "result": "\u5728VirtualHome\u3001ALFWorld\u548cRLBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u96f6\u6837\u672c\u9002\u5e94\u548c\u5c11\u6837\u672c\u6269\u5c55\u573a\u666f\u4e2d\u90fd\u5c55\u73b0\u51fa\u5f3a\u5927\u6027\u80fd", "conclusion": "TMoW\u901a\u8fc7\u6d4b\u8bd5\u65f6\u66f4\u65b0\u8def\u7531\u51fd\u6570\uff0c\u4f7f\u5177\u8eab\u667a\u80fd\u4f53\u80fd\u591f\u6709\u6548\u91cd\u7ec4\u73b0\u6709\u6a21\u578b\u5e76\u96c6\u6210\u65b0\u6a21\u578b\uff0c\u5b9e\u73b0\u6301\u7eed\u9002\u5e94\uff0c\u4ece\u800c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u6709\u6548\u8fd0\u884c"}}
{"id": "2601.22935", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22935", "abs": "https://arxiv.org/abs/2601.22935", "authors": ["Evgeny Grigorenko", "David Stanojevi\u0107", "David Ili\u0107", "Egor Bogomolov", "Kostadin Cvejoski"], "title": "Protecting Private Code in IDE Autocomplete using Differential Privacy", "comment": "6 pages", "summary": "Modern Integrated Development Environments (IDEs) increasingly leverage Large Language Models (LLMs) to provide advanced features like code autocomplete. While powerful, training these models on user-written code introduces significant privacy risks, making the models themselves a new type of data vulnerability. Malicious actors can exploit this by launching attacks to reconstruct sensitive training data or infer whether a specific code snippet was used for training. This paper investigates the use of Differential Privacy (DP) as a robust defense mechanism for training an LLM for Kotlin code completion. We fine-tune a \\texttt{Mellum} model using DP and conduct a comprehensive evaluation of its privacy and utility. Our results demonstrate that DP provides a strong defense against Membership Inference Attacks (MIAs), reducing the attack's success rate close to a random guess (AUC from 0.901 to 0.606). Furthermore, we show that this privacy guarantee comes at a minimal cost to model performance, with the DP-trained model achieving utility scores comparable to its non-private counterpart, even when trained on 100x less data. Our findings suggest that DP is a practical and effective solution for building private and trustworthy AI-powered IDE features.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5728Kotlin\u4ee3\u7801\u8865\u5168LLM\u8bad\u7ec3\u4e2d\u4f7f\u7528\u5dee\u5206\u9690\u79c1(DP)\u4f5c\u4e3a\u9632\u5fa1\u673a\u5236\uff0c\u8bc1\u660eDP\u80fd\u6709\u6548\u62b5\u5fa1\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd", "motivation": "\u73b0\u4ee3IDE\u4f7f\u7528LLM\u8fdb\u884c\u4ee3\u7801\u8865\u5168\u65f6\uff0c\u8bad\u7ec3\u7528\u6237\u4ee3\u7801\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u6a21\u578b\u53ef\u80fd\u6210\u4e3a\u65b0\u7684\u6570\u636e\u6f0f\u6d1e\uff0c\u6076\u610f\u653b\u51fb\u8005\u53ef\u91cd\u6784\u654f\u611f\u8bad\u7ec3\u6570\u636e\u6216\u63a8\u65ad\u7279\u5b9a\u4ee3\u7801\u7247\u6bb5\u662f\u5426\u7528\u4e8e\u8bad\u7ec3", "method": "\u4f7f\u7528\u5dee\u5206\u9690\u79c1(DP)\u8bad\u7ec3Kotlin\u4ee3\u7801\u8865\u5168\u7684LLM\uff0c\u5bf9Mellum\u6a21\u578b\u8fdb\u884cDP\u5fae\u8c03\uff0c\u5e76\u5168\u9762\u8bc4\u4f30\u5176\u9690\u79c1\u6027\u548c\u5b9e\u7528\u6027", "result": "DP\u80fd\u6709\u6548\u9632\u5fa1\u6210\u5458\u63a8\u7406\u653b\u51fb(MIAs)\uff0c\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u81f3\u63a5\u8fd1\u968f\u673a\u731c\u6d4b\u6c34\u5e73(AUC\u4ece0.901\u964d\u81f30.606)\uff0c\u4e14\u9690\u79c1\u4fdd\u62a4\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u5f88\u5c0f\uff0cDP\u8bad\u7ec3\u6a21\u578b\u5373\u4f7f\u5728100\u500d\u5c11\u6570\u636e\u4e0b\u4e5f\u80fd\u8fbe\u5230\u4e0e\u975e\u79c1\u6709\u6a21\u578b\u76f8\u5f53\u7684\u5b9e\u7528\u6027", "conclusion": "\u5dee\u5206\u9690\u79c1\u662f\u6784\u5efa\u79c1\u5bc6\u4e14\u53ef\u4fe1\u8d56\u7684AI\u9a71\u52a8IDE\u529f\u80fd\u7684\u5b9e\u7528\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.23020", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.23020", "abs": "https://arxiv.org/abs/2601.23020", "authors": ["Stefan Schott", "Serena Elisa Ponta", "Wolfram Fischer", "Jonas Klauke", "Eric Bodden"], "title": "Uncovering Hidden Inclusions of Vulnerable Dependencies in Real-World Java Projects", "comment": null, "summary": "Open-source software (OSS) dependencies are a dominant component of modern software code bases. Using proven and well-tested OSS components lets developers reduce development time and cost while improving quality. However, heavy reliance on open-source software also introduces significant security risks, including the incorporation of known vulnerabilities into the codebase. To mitigate these risks, metadata-based dependency scanners, which are lightweight and fast, and code-centric scanners, which enable the detection of modified dependencies hidden from metadata-based approaches, have been developed. In this paper, we present Unshade, a hybrid approach towards dependency scanning in Java that combines the efficiency of metadata-based scanning with the ability to detect modified dependencies of code-centric approaches. Unshade first augments a Java project's software bill of materials (SBOM) by identifying modified and hidden dependencies via a bytecode-based fingerprinting mechanism. This augmented SBOM is then passed to a metadata-based vulnerability scanner to identify known vulnerabilities in both declared and newly revealed dependencies. Leveraging Unshade's high scalability, we conducted a large-scale study of the 1,808 most popular open-source Java Maven projects on GitHub. The results show that nearly 50% of these projects contain at least one modified, hidden dependency associated with a known vulnerability. On average, each affected project includes more than eight such hidden vulnerable dependencies, all missed by traditional metadata-based scanners. Overall, Unshade identified 7,712 unique CVEs in hidden dependencies that would remain undetected when relying on metadata-based scanning alone.", "AI": {"tldr": "Unshade\u662f\u4e00\u4e2a\u6df7\u5408\u4f9d\u8d56\u626b\u63cf\u5de5\u5177\uff0c\u7ed3\u5408\u5143\u6570\u636e\u626b\u63cf\u6548\u7387\u548c\u4ee3\u7801\u4e2d\u5fc3\u65b9\u6cd5\u68c0\u6d4b\u4fee\u6539\u4f9d\u8d56\u7684\u80fd\u529b\uff0c\u5728Java\u9879\u76ee\u4e2d\u8bc6\u522b\u9690\u85cf\u7684\u6613\u53d7\u653b\u51fb\u4f9d\u8d56\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u4f9d\u8d56\u662f\u73b0\u4ee3\u4ee3\u7801\u5e93\u7684\u4e3b\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u867d\u7136\u80fd\u51cf\u5c11\u5f00\u53d1\u65f6\u95f4\u548c\u6210\u672c\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u663e\u8457\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5305\u62ec\u5df2\u77e5\u6f0f\u6d1e\u7684\u5f15\u5165\u3002\u73b0\u6709\u5143\u6570\u636e\u626b\u63cf\u5668\u8f7b\u91cf\u5feb\u901f\u4f46\u65e0\u6cd5\u68c0\u6d4b\u4fee\u6539\u4f9d\u8d56\uff0c\u800c\u4ee3\u7801\u4e2d\u5fc3\u626b\u63cf\u5668\u80fd\u68c0\u6d4b\u4fee\u6539\u4f9d\u8d56\u4f46\u6548\u7387\u8f83\u4f4e\u3002", "method": "Unshade\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u9996\u5148\u901a\u8fc7\u57fa\u4e8e\u5b57\u8282\u7801\u7684\u6307\u7eb9\u8bc6\u522b\u673a\u5236\u8bc6\u522b\u4fee\u6539\u548c\u9690\u85cf\u7684\u4f9d\u8d56\uff0c\u589e\u5f3aJava\u9879\u76ee\u7684\u8f6f\u4ef6\u7269\u6599\u6e05\u5355(SBOM)\uff0c\u7136\u540e\u5c06\u589e\u5f3a\u7684SBOM\u4f20\u9012\u7ed9\u5143\u6570\u636e\u6f0f\u6d1e\u626b\u63cf\u5668\uff0c\u8bc6\u522b\u58f0\u660e\u4f9d\u8d56\u548c\u65b0\u53d1\u73b0\u4f9d\u8d56\u4e2d\u7684\u5df2\u77e5\u6f0f\u6d1e\u3002", "result": "\u5bf9GitHub\u4e0a1,808\u4e2a\u6700\u6d41\u884c\u7684\u5f00\u6e90Java Maven\u9879\u76ee\u8fdb\u884c\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u7ed3\u679c\u663e\u793a\uff1a\u8fd150%\u9879\u76ee\u5305\u542b\u81f3\u5c11\u4e00\u4e2a\u4e0e\u5df2\u77e5\u6f0f\u6d1e\u76f8\u5173\u7684\u4fee\u6539\u9690\u85cf\u4f9d\u8d56\uff1b\u5e73\u5747\u6bcf\u4e2a\u53d7\u5f71\u54cd\u9879\u76ee\u5305\u542b\u8d85\u8fc78\u4e2a\u6b64\u7c7b\u9690\u85cf\u6613\u53d7\u653b\u51fb\u4f9d\u8d56\uff1b\u5171\u8bc6\u522b\u51fa7,712\u4e2a\u72ec\u7279CVE\uff0c\u8fd9\u4e9b\u5728\u4ec5\u4f9d\u8d56\u5143\u6570\u636e\u626b\u63cf\u65f6\u4f1a\u88ab\u9057\u6f0f\u3002", "conclusion": "Unshade\u6210\u529f\u7ed3\u5408\u4e86\u5143\u6570\u636e\u626b\u63cf\u7684\u6548\u7387\u548c\u4ee3\u7801\u4e2d\u5fc3\u65b9\u6cd5\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u9690\u85cf\u6613\u53d7\u653b\u51fb\u4f9d\u8d56\u7684\u68c0\u6d4b\u7387\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u626b\u63cf\u65b9\u6cd5\u9057\u6f0f\u7684\u5927\u91cf\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2601.22648", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22648", "abs": "https://arxiv.org/abs/2601.22648", "authors": ["Xianzhou Zeng", "Jing Huang", "Chunmei Xie", "Gongrui Nan", "Siye Chen", "Mengyu Lu", "Weiqi Xiong", "Qixuan Zhou", "Junhao Zhang", "Qiang Zhu", "Yadong Li", "Xingzhong Xu"], "title": "UCPO: Uncertainty-Aware Policy Optimization", "comment": null, "summary": "The key to building trustworthy Large Language Models (LLMs) lies in endowing them with inherent uncertainty expression capabilities to mitigate the hallucinations that restrict their high-stakes applications. However, existing RL paradigms such as GRPO often suffer from Advantage Bias due to binary decision spaces and static uncertainty rewards, inducing either excessive conservatism or overconfidence. To tackle this challenge, this paper unveils the root causes of reward hacking and overconfidence in current RL paradigms incorporating uncertainty-based rewards, based on which we propose the UnCertainty-Aware Policy Optimization (UCPO) framework. UCPO employs Ternary Advantage Decoupling to separate and independently normalize deterministic and uncertain rollouts, thereby eliminating advantage bias. Furthermore, a Dynamic Uncertainty Reward Adjustment mechanism is introduced to calibrate uncertainty weights in real-time according to model evolution and instance difficulty. Experimental results in mathematical reasoning and general tasks demonstrate that UCPO effectively resolves the reward imbalance, significantly improving the reliability and calibration of the model beyond their knowledge boundaries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faUCPO\u6846\u67b6\u89e3\u51b3LLM\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\u4e2d\u7684\u4f18\u52bf\u504f\u5dee\u95ee\u9898\uff0c\u901a\u8fc7\u4e09\u5143\u4f18\u52bf\u89e3\u8026\u548c\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u5956\u52b1\u8c03\u6574\uff0c\u63d0\u5347\u6a21\u578b\u5728\u77e5\u8bc6\u8fb9\u754c\u5916\u7684\u53ef\u9760\u6027\u548c\u6821\u51c6\u6027\u3002", "motivation": "\u73b0\u6709RL\u8303\u5f0f\uff08\u5982GRPO\uff09\u5728\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\u4e2d\u5b58\u5728\u4f18\u52bf\u504f\u5dee\u95ee\u9898\uff0c\u6e90\u4e8e\u4e8c\u5143\u51b3\u7b56\u7a7a\u95f4\u548c\u9759\u6001\u4e0d\u786e\u5b9a\u6027\u5956\u52b1\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u5ea6\u4fdd\u5b88\u6216\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u9650\u5236\u4e86LLM\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51faUnCertainty-Aware Policy Optimization (UCPO)\u6846\u67b6\uff1a1\uff09\u4e09\u5143\u4f18\u52bf\u89e3\u8026\uff1a\u5206\u79bb\u5e76\u72ec\u7acb\u5f52\u4e00\u5316\u786e\u5b9a\u6027\u548c\u4e0d\u786e\u5b9a\u6027rollouts\u4ee5\u6d88\u9664\u4f18\u52bf\u504f\u5dee\uff1b2\uff09\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u5956\u52b1\u8c03\u6574\uff1a\u6839\u636e\u6a21\u578b\u6f14\u5316\u548c\u5b9e\u4f8b\u96be\u5ea6\u5b9e\u65f6\u6821\u51c6\u4e0d\u786e\u5b9a\u6027\u6743\u91cd\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u548c\u901a\u7528\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cUCPO\u6709\u6548\u89e3\u51b3\u4e86\u5956\u52b1\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u77e5\u8bc6\u8fb9\u754c\u5916\u7684\u53ef\u9760\u6027\u548c\u6821\u51c6\u6027\u3002", "conclusion": "UCPO\u6846\u67b6\u901a\u8fc7\u89e3\u51b3\u73b0\u6709RL\u8303\u5f0f\u4e2d\u7684\u4f18\u52bf\u504f\u5dee\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u5177\u6709\u5185\u5728\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\u80fd\u529b\u7684\u53ef\u4fe1LLM\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u7f13\u89e3\u4e86\u5e7b\u89c9\u95ee\u9898\u5bf9\u9ad8\u98ce\u9669\u5e94\u7528\u7684\u9650\u5236\u3002"}}
{"id": "2601.22938", "categories": ["cs.CR", "cs.AI", "eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22938", "abs": "https://arxiv.org/abs/2601.22938", "authors": ["Huan Song", "Shuyu Tian", "Junyi Hao", "Cheng Yuan", "Zhenyu Jia", "Jiawei Shao", "Xuelong Li"], "title": "A Real-Time Privacy-Preserving Behavior Recognition System via Edge-Cloud Collaboration", "comment": null, "summary": "As intelligent sensing expands into high-privacy environments such as restrooms and changing rooms, the field faces a critical privacy-security paradox. Traditional RGB surveillance raises significant concerns regarding visual recording and storage, while existing privacy-preserving methods-ranging from physical desensitization to traditional cryptographic or obfuscation techniques-often compromise semantic understanding capabilities or fail to guarantee mathematical irreversibility against reconstruction attacks. To address these challenges, this study presents a novel privacy-preserving perception technology based on the AI Flow theoretical framework and an edge-cloud collaborative architecture. The proposed methodology integrates source desensitization with irreversible feature mapping. Leveraging Information Bottleneck theory, the edge device performs millisecond-level processing to transform raw imagery into abstract feature vectors via non-linear mapping and stochastic noise injection. This process constructs a unidirectional information flow that strips identity-sensitive attributes, rendering the reconstruction of original images impossible. Subsequently, the cloud platform utilizes multimodal family models to perform joint inference solely on these abstract vectors to detect abnormal behaviors. This approach fundamentally severs the path to privacy leakage at the architectural level, achieving a breakthrough from video surveillance to de-identified behavior perception and offering a robust solution for risk management in high-sensitivity public spaces.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI Flow\u7406\u8bba\u6846\u67b6\u548c\u8fb9\u4e91\u534f\u540c\u67b6\u6784\u7684\u65b0\u578b\u9690\u79c1\u4fdd\u62a4\u611f\u77e5\u6280\u672f\uff0c\u901a\u8fc7\u6e90\u7aef\u8131\u654f\u548c\u4e0d\u53ef\u9006\u7279\u5f81\u6620\u5c04\uff0c\u5b9e\u73b0\u4ece\u89c6\u9891\u76d1\u63a7\u5230\u53bb\u8eab\u4efd\u5316\u884c\u4e3a\u611f\u77e5\u7684\u7a81\u7834", "motivation": "\u667a\u80fd\u611f\u77e5\u6269\u5c55\u5230\u9ad8\u9690\u79c1\u73af\u5883\uff08\u5982\u536b\u751f\u95f4\u3001\u66f4\u8863\u5ba4\uff09\u65f6\u9762\u4e34\u9690\u79c1-\u5b89\u5168\u6096\u8bba\uff1a\u4f20\u7edfRGB\u76d1\u63a7\u5b58\u5728\u89c6\u89c9\u8bb0\u5f55\u548c\u5b58\u50a8\u7684\u9690\u79c1\u62c5\u5fe7\uff0c\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u8981\u4e48\u635f\u5bb3\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u8981\u4e48\u65e0\u6cd5\u4fdd\u8bc1\u6570\u5b66\u4e0d\u53ef\u9006\u6027\u5bf9\u6297\u91cd\u5efa\u653b\u51fb", "method": "\u57fa\u4e8eAI Flow\u7406\u8bba\u6846\u67b6\u548c\u8fb9\u4e91\u534f\u540c\u67b6\u6784\uff0c\u96c6\u6210\u6e90\u7aef\u8131\u654f\u4e0e\u4e0d\u53ef\u9006\u7279\u5f81\u6620\u5c04\u3002\u8fb9\u7f18\u8bbe\u5907\u5229\u7528\u4fe1\u606f\u74f6\u9888\u7406\u8bba\u8fdb\u884c\u6beb\u79d2\u7ea7\u5904\u7406\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u6620\u5c04\u548c\u968f\u673a\u566a\u58f0\u6ce8\u5165\u5c06\u539f\u59cb\u56fe\u50cf\u8f6c\u6362\u4e3a\u62bd\u8c61\u7279\u5f81\u5411\u91cf\uff0c\u6784\u5efa\u5355\u5411\u4fe1\u606f\u6d41\uff1b\u4e91\u7aef\u5e73\u53f0\u4f7f\u7528\u591a\u6a21\u6001\u5bb6\u65cf\u6a21\u578b\u4ec5\u57fa\u4e8e\u8fd9\u4e9b\u62bd\u8c61\u5411\u91cf\u8fdb\u884c\u8054\u5408\u63a8\u7406\u4ee5\u68c0\u6d4b\u5f02\u5e38\u884c\u4e3a", "result": "\u8be5\u65b9\u6cd5\u5728\u67b6\u6784\u5c42\u9762\u4ece\u6839\u672c\u4e0a\u5207\u65ad\u4e86\u9690\u79c1\u6cc4\u9732\u8def\u5f84\uff0c\u5b9e\u73b0\u4e86\u4ece\u89c6\u9891\u76d1\u63a7\u5230\u53bb\u8eab\u4efd\u5316\u884c\u4e3a\u611f\u77e5\u7684\u7a81\u7834\uff0c\u4e3a\u9ad8\u654f\u611f\u6027\u516c\u5171\u7a7a\u95f4\u7684\u98ce\u9669\u7ba1\u7406\u63d0\u4f9b\u4e86\u7a33\u5065\u89e3\u51b3\u65b9\u6848", "conclusion": "\u8be5\u6280\u672f\u901a\u8fc7\u4e0d\u53ef\u9006\u7279\u5f81\u6620\u5c04\u548c\u5355\u5411\u4fe1\u606f\u6d41\u8bbe\u8ba1\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u4e3a\u9ad8\u9690\u79c1\u73af\u5883\u4e0b\u7684\u667a\u80fd\u611f\u77e5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9690\u79c1-\u5b89\u5168\u5e73\u8861\u65b9\u6848"}}
{"id": "2601.23059", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23059", "abs": "https://arxiv.org/abs/2601.23059", "authors": ["Antonio Vitale", "Emanuela Guglielmi", "Simone Scalabrino", "Rocco Oliveto"], "title": "On the Impact of Code Comments for Automated Bug-Fixing: An Empirical Study", "comment": "Accepted at the 34th IEEE/ACM International Conference on Program Comprehension (ICPC 2026)", "summary": "Large Language Models (LLMs) are increasingly relevant in Software Engineering research and practice, with Automated Bug Fixing (ABF) being one of their key applications. ABF involves transforming a buggy method into its fixed equivalent. A common preprocessing step in ABF involves removing comments from code prior to training. However, we hypothesize that comments may play a critical role in fixing certain types of bugs by providing valuable design and implementation insights. In this study, we investigate how the presence or absence of comments, both during training and at inference time, impacts the bug-fixing capabilities of LLMs. We conduct an empirical evaluation comparing two model families, each evaluated under all combinations of training and inference conditions (with and without comments), and thereby revisiting the common practice of removing comments during training. To address the limited availability of comments in state-of-the-art datasets, we use an LLM to automatically generate comments for methods lacking them. Our findings show that comments improve ABF accuracy by up to threefold when present in both phases, while training with comments does not degrade performance when instances lack them. Additionally, an interpretability analysis identifies that comments detailing method implementation are particularly effective in aiding LLMs to fix bugs accurately.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4ee3\u7801\u6ce8\u91ca\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4fee\u590dbug\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6ce8\u91ca\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u90fd\u80fd\u663e\u8457\u63d0\u5347\u4fee\u590d\u51c6\u786e\u7387", "motivation": "\u5f53\u524d\u81ea\u52a8bug\u4fee\u590d\u7814\u7a76\u4e2d\u666e\u904d\u5b58\u5728\u79fb\u9664\u4ee3\u7801\u6ce8\u91ca\u7684\u505a\u6cd5\uff0c\u4f46\u7814\u7a76\u8005\u5047\u8bbe\u6ce8\u91ca\u53ef\u80fd\u5305\u542b\u91cd\u8981\u7684\u8bbe\u8ba1\u548c\u5b9e\u73b0\u4fe1\u606f\uff0c\u5bf9\u4fee\u590d\u67d0\u4e9b\u7c7b\u578b\u7684bug\u81f3\u5173\u91cd\u8981", "method": "\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\u6bd4\u8f83\u4e24\u4e2a\u6a21\u578b\u5bb6\u65cf\uff0c\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u7684\u6240\u6709\u7ec4\u5408\u6761\u4ef6\u4e0b\uff08\u6709/\u65e0\u6ce8\u91ca\uff09\u6d4b\u8bd5\u6a21\u578b\u6027\u80fd\uff1b\u4f7f\u7528LLM\u4e3a\u7f3a\u5c11\u6ce8\u91ca\u7684\u6570\u636e\u96c6\u81ea\u52a8\u751f\u6210\u6ce8\u91ca", "result": "\u5f53\u6ce8\u91ca\u540c\u65f6\u5b58\u5728\u4e8e\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u65f6\uff0c\u81ea\u52a8bug\u4fee\u590d\u51c6\u786e\u7387\u6700\u591a\u53ef\u63d0\u9ad8\u4e09\u500d\uff1b\u8bad\u7ec3\u65f6\u5305\u542b\u6ce8\u91ca\u4e0d\u4f1a\u964d\u4f4e\u65e0\u6ce8\u91ca\u5b9e\u4f8b\u7684\u6027\u80fd\uff1b\u8be6\u7ec6\u63cf\u8ff0\u65b9\u6cd5\u5b9e\u73b0\u7684\u6ce8\u91ca\u5bf9\u5e2e\u52a9LLM\u51c6\u786e\u4fee\u590dbug\u7279\u522b\u6709\u6548", "conclusion": "\u4ee3\u7801\u6ce8\u91ca\u5728\u81ea\u52a8bug\u4fee\u590d\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4e0d\u5e94\u5728\u9884\u5904\u7406\u4e2d\u968f\u610f\u79fb\u9664\uff1b\u5305\u542b\u6ce8\u91ca\u7684\u8bad\u7ec3\u7b56\u7565\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u4e14\u65e0\u8d1f\u9762\u5f71\u54cd"}}
{"id": "2601.22662", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.22662", "abs": "https://arxiv.org/abs/2601.22662", "authors": ["Wei Zhu", "Lixing Yu", "Hao-Ren Yao", "Zhiwen Tang", "Kun Yue"], "title": "Task-Aware LLM Council with Adaptive Decision Pathways for Decision Support", "comment": "A shorter version of this work has been accepted by ICASSP 2026", "summary": "Large language models (LLMs) have shown strong capabilities across diverse decision-making tasks. However, existing approaches often overlook the specialization differences among available models, treating all LLMs as uniformly applicable regardless of task characteristics. This limits their ability to adapt to varying reasoning demands and task complexities. In this work, we propose Task-Aware LLM Council (TALC), a task-adaptive decision framework that integrates a council of LLMs with Monte Carlo Tree Search (MCTS) to enable dynamic expert selection and efficient multi-step planning. Each LLM is equipped with a structured success memory profile derived from prior task trajectories, enabling semantic matching between current reasoning context and past successes. At each decision point, TALC routes control to the most contextually appropriate model and estimates node value using a dual-signal mechanism that fuses model-based evaluations with historical utility scores. These signals are adaptively weighted based on intra-node variance and used to guide MCTS selection, allowing the system to balance exploration depth with planning confidence. Experiments on WebShop, HumanEval, and the Game of 24 demonstrate that TALC achieves superior task success rates and improved search efficiency compared to strong baselines, validating the benefits of specialization-aware routing and adaptive planning.", "AI": {"tldr": "TALC\u662f\u4e00\u4e2a\u4efb\u52a1\u81ea\u9002\u5e94\u7684LLM\u51b3\u7b56\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210LLM\u59d4\u5458\u4f1a\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u5b9e\u73b0\u52a8\u6001\u4e13\u5bb6\u9009\u62e9\u548c\u9ad8\u6548\u591a\u6b65\u89c4\u5212\uff0c\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5ffd\u89c6\u4e0d\u540cLLM\u7684\u4e13\u4e1a\u5316\u5dee\u5f02\uff0c\u5c06\u6240\u6709\u6a21\u578b\u89c6\u4e3a\u540c\u7b49\u9002\u7528\uff0c\u9650\u5236\u4e86\u7cfb\u7edf\u9002\u5e94\u4e0d\u540c\u63a8\u7406\u9700\u6c42\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4efb\u52a1\u611f\u77e5\u7684LLM\u59d4\u5458\u4f1a\u6846\u67b6\uff0c\u6bcf\u4e2aLLM\u914d\u5907\u7ed3\u6784\u5316\u6210\u529f\u8bb0\u5fc6\u6863\u6848\uff0c\u901a\u8fc7\u8bed\u4e49\u5339\u914d\u5c06\u5f53\u524d\u63a8\u7406\u4e0a\u4e0b\u6587\u4e0e\u5386\u53f2\u6210\u529f\u7ecf\u9a8c\u5bf9\u9f50\u3002\u91c7\u7528\u53cc\u4fe1\u53f7\u673a\u5236\u878d\u5408\u6a21\u578b\u8bc4\u4f30\u548c\u5386\u53f2\u6548\u7528\u5206\u6570\uff0c\u57fa\u4e8e\u8282\u70b9\u5185\u65b9\u5dee\u81ea\u9002\u5e94\u52a0\u6743\uff0c\u6307\u5bfcMCTS\u9009\u62e9\u3002", "result": "\u5728WebShop\u3001HumanEval\u548c24\u70b9\u6e38\u620f\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTALC\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u4efb\u52a1\u6210\u529f\u7387\u548c\u6539\u8fdb\u7684\u641c\u7d22\u6548\u7387\u3002", "conclusion": "TALC\u9a8c\u8bc1\u4e86\u4e13\u4e1a\u5316\u611f\u77e5\u8def\u7531\u548c\u81ea\u9002\u5e94\u89c4\u5212\u7684\u4f18\u52bf\uff0c\u4e3aLLM\u51b3\u7b56\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u4efb\u52a1\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2601.22946", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22946", "abs": "https://arxiv.org/abs/2601.22946", "authors": ["Farnaz Soltaniani", "Mohammad Ghafari"], "title": "From Data Leak to Secret Misses: The Impact of Data Leakage on Secret Detection Models", "comment": null, "summary": "Machine learning models are increasingly used for software security tasks. These models are commonly trained and evaluated on large Internet-derived datasets, which often contain duplicated or highly similar samples. When such samples are split across training and test sets, data leakage may occur, allowing models to memorize patterns instead of learning to generalize. We investigate duplication in a widely used benchmark dataset of hard coded secrets and show how data leakage can substantially inflate the reported performance of AI-based secret detectors, resulting in a misleading picture of their real-world effectiveness.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u673a\u5668\u5b66\u4e60\u5b89\u5168\u68c0\u6d4b\u6a21\u578b\u5728\u5305\u542b\u91cd\u590d\u6837\u672c\u7684\u6570\u636e\u96c6\u4e0a\u5b58\u5728\u6570\u636e\u6cc4\u9732\u95ee\u9898\uff0c\u5bfc\u81f4\u6027\u80fd\u8bc4\u4f30\u865a\u9ad8\uff0c\u4e0d\u80fd\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u6548\u679c\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u8f6f\u4ef6\u5b89\u5168\u4efb\u52a1\uff0c\u8fd9\u4e9b\u6a21\u578b\u901a\u5e38\u5728\u5927\u578b\u4e92\u8054\u7f51\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u5f80\u5f80\u5305\u542b\u91cd\u590d\u6216\u9ad8\u5ea6\u76f8\u4f3c\u7684\u6837\u672c\u3002\u5f53\u8fd9\u4e9b\u6837\u672c\u5206\u5e03\u5728\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e2d\u65f6\uff0c\u53ef\u80fd\u5bfc\u81f4\u6570\u636e\u6cc4\u9732\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u8bb0\u5fc6\u6a21\u5f0f\u800c\u4e0d\u662f\u5b66\u4e60\u6cdb\u5316\u3002", "method": "\u7814\u7a76\u8c03\u67e5\u4e86\u5e7f\u6cdb\u4f7f\u7528\u7684\u786c\u7f16\u7801\u5bc6\u94a5\u57fa\u51c6\u6570\u636e\u96c6\u4e2d\u7684\u91cd\u590d\u60c5\u51b5\uff0c\u5206\u6790\u4e86\u6570\u636e\u6cc4\u9732\u5982\u4f55\u5f71\u54cdAI\u5bc6\u94a5\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u6570\u636e\u6cc4\u9732\u4f1a\u663e\u8457\u5938\u5927\u57fa\u4e8eAI\u7684\u5bc6\u94a5\u68c0\u6d4b\u5668\u62a5\u544a\u7684\u6027\u80fd\uff0c\u5bfc\u81f4\u5bf9\u5176\u771f\u5b9e\u4e16\u754c\u6709\u6548\u6027\u7684\u8bef\u5bfc\u6027\u8bc4\u4f30\u3002", "conclusion": "\u5728\u673a\u5668\u5b66\u4e60\u5b89\u5168\u4efb\u52a1\u4e2d\uff0c\u9700\u8981\u4ed4\u7ec6\u5904\u7406\u6570\u636e\u96c6\u4e2d\u7684\u91cd\u590d\u6837\u672c\uff0c\u907f\u514d\u6570\u636e\u6cc4\u9732\u5bfc\u81f4\u7684\u6027\u80fd\u8bc4\u4f30\u504f\u5dee\uff0c\u4ee5\u786e\u4fdd\u6a21\u578b\u8bc4\u4f30\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u6548\u679c\u3002"}}
{"id": "2601.23139", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.23139", "abs": "https://arxiv.org/abs/2601.23139", "authors": ["Ruizhen Gu", "Jos\u00e9 Miguel Rojas", "Donghwan Shin"], "title": "Automated Testing of Prevalent 3D User Interactions in Virtual Reality Applications", "comment": "31 pages, 7 figures", "summary": "Virtual Reality (VR) technologies offer immersive user experiences across various domains, but present unique testing challenges compared to traditional software. Existing VR testing approaches enable scene navigation and interaction activation, but lack the ability to automatically synthesise realistic 3D user inputs (e.g, grab and trigger actions via hand-held controllers). Automated testing that generates and executes such input remains an unresolved challenge. Furthermore, existing metrics fail to robustly capture diverse interaction coverage. This paper addresses these gaps through four key contributions. First, we empirically identify four prevalent interaction types in nine open-source VR projects: fire, manipulate, socket, and custom. Second, we introduce the Interaction Flow Graph, a novel abstraction that systematically models 3D user interactions by identifying targets, actions, and conditions. Third, we construct XRBench3D, a benchmark comprising ten VR scenes that encompass 456 distinct user interactions for evaluating VR interaction testing. Finally, we present XRintTest, an automated testing approach that leverages this graph for dynamic scene exploration and interaction execution. Evaluation on XRBench3D shows that XRintTest achieves great effectiveness, reaching 93% coverage of fire, manipulate and socket interactions across all scenes, and performing 12x more effectively and 6x more efficiently than random exploration. Moreover, XRintTest can detect runtime exceptions and non-exception interaction issues, including subtle configuration defects. In addition, the Interaction Flow Graph can reveal potential interaction design smells that may compromise intended functionality and hinder testing performance for VR applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9VR\u5e94\u7528\u6d4b\u8bd5\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86Interaction Flow Graph\u62bd\u8c61\u6a21\u578b\u3001XRBench3D\u57fa\u51c6\u6d4b\u8bd5\u96c6\u548cXRintTest\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86VR\u4ea4\u4e92\u6d4b\u8bd5\u7684\u8986\u76d6\u7387\u548c\u6548\u7387\u3002", "motivation": "VR\u6280\u672f\u867d\u7136\u63d0\u4f9b\u6c89\u6d78\u5f0f\u7528\u6237\u4f53\u9a8c\uff0c\u4f46\u4e0e\u4f20\u7edf\u8f6f\u4ef6\u76f8\u6bd4\u5b58\u5728\u72ec\u7279\u7684\u6d4b\u8bd5\u6311\u6218\u3002\u73b0\u6709VR\u6d4b\u8bd5\u65b9\u6cd5\u7f3a\u4e4f\u81ea\u52a8\u5408\u6210\u771f\u5b9e3D\u7528\u6237\u8f93\u5165\uff08\u5982\u901a\u8fc7\u624b\u6301\u63a7\u5236\u5668\u7684\u6293\u53d6\u548c\u89e6\u53d1\u52a8\u4f5c\uff09\u7684\u80fd\u529b\uff0c\u4e14\u73b0\u6709\u6307\u6807\u65e0\u6cd5\u7a33\u5065\u6355\u6349\u591a\u6837\u5316\u7684\u4ea4\u4e92\u8986\u76d6\u7387\u3002", "method": "1. \u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc6\u522b\u4e869\u4e2a\u5f00\u6e90VR\u9879\u76ee\u4e2d\u56db\u79cd\u4e3b\u8981\u4ea4\u4e92\u7c7b\u578b\uff1afire\u3001manipulate\u3001socket\u548ccustom\uff1b2. \u63d0\u51fa\u4e86Interaction Flow Graph\uff0c\u901a\u8fc7\u8bc6\u522b\u76ee\u6807\u3001\u52a8\u4f5c\u548c\u6761\u4ef6\u6765\u7cfb\u7edf\u5efa\u6a213D\u7528\u6237\u4ea4\u4e92\uff1b3. \u6784\u5efa\u4e86XRBench3D\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u5305\u542b10\u4e2aVR\u573a\u666f\u548c456\u4e2a\u4e0d\u540c\u7528\u6237\u4ea4\u4e92\uff1b4. \u5f00\u53d1\u4e86XRintTest\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5229\u7528\u8be5\u56fe\u8fdb\u884c\u52a8\u6001\u573a\u666f\u63a2\u7d22\u548c\u4ea4\u4e92\u6267\u884c\u3002", "result": "\u5728XRBench3D\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cXRintTest\u5728\u6240\u6709\u573a\u666f\u4e2d\u5bf9fire\u3001manipulate\u548csocket\u4ea4\u4e92\u7684\u8986\u76d6\u7387\u8fbe\u523093%\uff0c\u6bd4\u968f\u673a\u63a2\u7d22\u65b9\u6cd5\u6548\u679c\u63d0\u534712\u500d\uff0c\u6548\u7387\u63d0\u53476\u500d\u3002\u6b64\u5916\uff0cXRintTest\u80fd\u591f\u68c0\u6d4b\u8fd0\u884c\u65f6\u5f02\u5e38\u548c\u975e\u5f02\u5e38\u4ea4\u4e92\u95ee\u9898\uff0c\u5305\u62ec\u5fae\u5999\u7684\u914d\u7f6e\u7f3a\u9677\u3002Interaction Flow Graph\u8fd8\u80fd\u63ed\u793a\u53ef\u80fd\u635f\u5bb3\u9884\u671f\u529f\u80fd\u548c\u963b\u788d\u6d4b\u8bd5\u6027\u80fd\u7684\u4ea4\u4e92\u8bbe\u8ba1\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u4ea4\u4e92\u5efa\u6a21\u548c\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86VR\u5e94\u7528\u6d4b\u8bd5\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u6548\u7387\uff0c\u5e76\u4e3aVR\u4ea4\u4e92\u8bbe\u8ba1\u548c\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u548c\u57fa\u51c6\u3002"}}
{"id": "2601.22664", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22664", "abs": "https://arxiv.org/abs/2601.22664", "authors": ["Zixuan Huang", "Xin Xia", "Yuxi Ren", "Jianbin Zheng", "Xuefeng Xiao", "Hongyan Xie", "Li Huaqiu", "Songshi Liang", "Zhongxiang Dai", "Fuzhen Zhuang", "Jianxin Li", "Yikun Ban", "Deqing Wang"], "title": "Real-Time Aligned Reward Model beyond Semantics", "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for aligning large language models (LLMs) with human preferences, yet it is susceptible to reward overoptimization, in which policy models overfit to the reward model, exploit spurious reward patterns instead of faithfully capturing human intent. Prior mitigations primarily relies on surface semantic information and fails to efficiently address the misalignment between the reward model (RM) and the policy model caused by continuous policy distribution shifts. This inevitably leads to an increasing reward discrepancy, exacerbating reward overoptimization. To address these limitations, we introduce R2M (Real-Time Aligned Reward Model), a novel lightweight RLHF framework. R2M goes beyond vanilla reward models that solely depend on the semantic representations of a pretrained LLM. Instead, it leverages the evolving hidden states of the policy (namely policy feedback) to align with the real-time distribution shift of the policy during the RL process. This work points to a promising new direction for improving the performance of reward models through real-time utilization of feedback from policy models.", "AI": {"tldr": "R2M\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7RLHF\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u7b56\u7565\u6a21\u578b\u7684\u5b9e\u65f6\u9690\u85cf\u72b6\u6001\u53cd\u9988\u6765\u5e94\u5bf9\u5956\u52b1\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u5956\u52b1\u6a21\u578b\u4e0e\u7b56\u7565\u5206\u5e03\u53d8\u5316\u7684\u5b9e\u65f6\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709RLHF\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u5956\u52b1\u8fc7\u4f18\u5316\u7684\u5f71\u54cd\uff0c\u5373\u7b56\u7565\u6a21\u578b\u8fc7\u5ea6\u62df\u5408\u5956\u52b1\u6a21\u578b\uff0c\u5229\u7528\u865a\u5047\u5956\u52b1\u6a21\u5f0f\u800c\u975e\u771f\u6b63\u6355\u6349\u4eba\u7c7b\u610f\u56fe\u3002\u73b0\u6709\u7f13\u89e3\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u8868\u9762\u8bed\u4e49\u4fe1\u606f\uff0c\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u7531\u8fde\u7eed\u7b56\u7565\u5206\u5e03\u53d8\u5316\u5f15\u8d77\u7684\u5956\u52b1\u6a21\u578b\u4e0e\u7b56\u7565\u6a21\u578b\u4e4b\u95f4\u7684\u9519\u4f4d\u95ee\u9898\uff0c\u5bfc\u81f4\u5956\u52b1\u5dee\u5f02\u589e\u5927\u5e76\u52a0\u5267\u5956\u52b1\u8fc7\u4f18\u5316\u3002", "method": "\u63d0\u51faR2M\uff08\u5b9e\u65f6\u5bf9\u9f50\u5956\u52b1\u6a21\u578b\uff09\u6846\u67b6\uff0c\u8d85\u8d8a\u4ec5\u4f9d\u8d56\u9884\u8bad\u7ec3LLM\u8bed\u4e49\u8868\u793a\u7684\u666e\u901a\u5956\u52b1\u6a21\u578b\u3002R2M\u5229\u7528\u7b56\u7565\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u6f14\u5316\u9690\u85cf\u72b6\u6001\uff08\u5373\u7b56\u7565\u53cd\u9988\uff09\uff0c\u4e0e\u7b56\u7565\u7684\u5b9e\u65f6\u5206\u5e03\u53d8\u5316\u8fdb\u884c\u5bf9\u9f50\u3002", "result": "\u8be5\u65b9\u6cd5\u4e3a\u901a\u8fc7\u5b9e\u65f6\u5229\u7528\u7b56\u7565\u6a21\u578b\u53cd\u9988\u6765\u6539\u8fdb\u5956\u52b1\u6a21\u578b\u6027\u80fd\u6307\u51fa\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b0\u65b9\u5411\u3002", "conclusion": "R2M\u901a\u8fc7\u5f15\u5165\u7b56\u7565\u53cd\u9988\u673a\u5236\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u89e3\u51b3RLHF\u4e2d\u7684\u5956\u52b1\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u5956\u52b1\u6a21\u578b\u4e0e\u7b56\u7565\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u5b9e\u65f6\u5bf9\u9f50\u3002"}}
{"id": "2601.23142", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.23142", "abs": "https://arxiv.org/abs/2601.23142", "authors": ["Mohamed Ouf", "Amr Mohamed", "Mariam Guizani"], "title": "Do Good, Stay Longer? Temporal Patterns and Predictors of Newcomer-to-Core Transitions in Conventional OSS and OSS4SG", "comment": null, "summary": "Open Source Software (OSS) sustainability relies on newcomers transitioning to core contributors, but this pipeline is broken, with most newcomers becoming inactive after initial contributions. Open Source Software for Social Good (OSS4SG) projects, which prioritize societal impact as their primary mission, may be associated with different newcomer-to-core transition outcomes than conventional OSS projects. We compared 375 projects (190 OSS4SG, 185 OSS), analyzing 92,721 contributors and 3.5 million commits. OSS4SG projects retain contributors at 2.2X higher rates and contributors have 19.6% higher probability of achieving core status. Early broad project exploration predicts core achievement (22.2% importance); conventional OSS concentrates on one dominant pathway (61.62% of transitions) while OSS4SG provides multiple pathways. Contrary to intuition, contributors who invest time learning the project before intensifying their contributions (Late Spike pattern) achieve core status 2.4-2.9X faster (21 weeks) than those who contribute intensively from day one (Early Spike pattern, 51-60 weeks). OSS4SG supports two effective temporal patterns while only Late Spike achieves fastest time-to-core in conventional OSS. Our findings suggest that finding a project aligned with personal values and taking time to understand the codebase before major contributions are key strategies for achieving core status. Our findings show that project mission is associated with measurably different environments for newcomer-to-core transitions and provide evidence-based guidance for newcomers and maintainers.", "AI": {"tldr": "OSS4SG\u9879\u76ee\u76f8\u6bd4\u4f20\u7edfOSS\u9879\u76ee\uff0c\u65b0\u4eba\u5411\u6838\u5fc3\u8d21\u732e\u8005\u8f6c\u5316\u7684\u6210\u529f\u7387\u66f4\u9ad8\uff082.2\u500d\u7559\u5b58\u7387\uff0c19.6%\u66f4\u9ad8\u6838\u5fc3\u5730\u4f4d\u6982\u7387\uff09\uff0c\u4e14\u63d0\u4f9b\u591a\u79cd\u8f6c\u5316\u8def\u5f84\u800c\u975e\u5355\u4e00\u4e3b\u5bfc\u8def\u5f84\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5148\u82b1\u65f6\u95f4\u4e86\u89e3\u9879\u76ee\u518d\u96c6\u4e2d\u8d21\u732e\u7684\u6a21\u5f0f\uff08Late Spike\uff09\u6bd4\u4e00\u5f00\u59cb\u5c31\u9ad8\u5f3a\u5ea6\u8d21\u732e\u7684\u6a21\u5f0f\uff08Early Spike\uff09\u66f4\u5feb\u6210\u4e3a\u6838\u5fc3\uff0821\u5468 vs 51-60\u5468\uff09\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u7684\u53ef\u6301\u7eed\u6027\u4f9d\u8d56\u4e8e\u65b0\u4eba\u5411\u6838\u5fc3\u8d21\u732e\u8005\u7684\u8f6c\u5316\uff0c\u4f46\u8fd9\u4e00\u8f6c\u5316\u7ba1\u9053\u5b58\u5728\u95ee\u9898\uff0c\u5927\u591a\u6570\u65b0\u4eba\u5728\u521d\u6b65\u8d21\u732e\u540e\u53d8\u5f97\u4e0d\u6d3b\u8dc3\u3002\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u4f20\u7edfOSS\u9879\u76ee\u548c\u4ee5\u793e\u4f1a\u5f71\u54cd\u4e3a\u4f7f\u547d\u7684OSS4SG\u9879\u76ee\u5728\u65b0\u4eba\u5411\u6838\u5fc3\u8f6c\u5316\u65b9\u9762\u7684\u5dee\u5f02\uff0c\u63a2\u7d22\u66f4\u6709\u6548\u7684\u8f6c\u5316\u7b56\u7565\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86375\u4e2a\u9879\u76ee\uff08190\u4e2aOSS4SG\uff0c185\u4e2a\u4f20\u7edfOSS\uff09\uff0c\u6db5\u76d692,721\u540d\u8d21\u732e\u8005\u548c350\u4e07\u6b21\u63d0\u4ea4\u3002\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\u7559\u5b58\u7387\u3001\u6838\u5fc3\u5730\u4f4d\u6982\u7387\u3001\u8f6c\u5316\u8def\u5f84\u6a21\u5f0f\u548c\u65f6\u95f4\u6a21\u5f0f\uff0c\u8bc6\u522b\u5f71\u54cd\u65b0\u4eba\u5411\u6838\u5fc3\u8f6c\u5316\u7684\u5173\u952e\u56e0\u7d20\u3002", "result": "OSS4SG\u9879\u76ee\u6bd4\u4f20\u7edfOSS\u9879\u76ee\u67092.2\u500d\u66f4\u9ad8\u7684\u8d21\u732e\u8005\u7559\u5b58\u7387\u548c19.6%\u66f4\u9ad8\u7684\u6838\u5fc3\u5730\u4f4d\u6982\u7387\u3002\u4f20\u7edfOSS\u9879\u76ee\u4e3b\u8981\u4f9d\u8d56\u5355\u4e00\u4e3b\u5bfc\u8f6c\u5316\u8def\u5f84\uff0861.62%\uff09\uff0c\u800cOSS4SG\u63d0\u4f9b\u591a\u79cd\u8def\u5f84\u3002\u7814\u7a76\u53d1\u73b0Late Spike\u6a21\u5f0f\uff08\u5148\u5b66\u4e60\u518d\u96c6\u4e2d\u8d21\u732e\uff09\u6bd4Early Spike\u6a21\u5f0f\uff08\u4ece\u4e00\u5f00\u59cb\u5c31\u9ad8\u5f3a\u5ea6\u8d21\u732e\uff09\u5feb2.4-2.9\u500d\u6210\u4e3a\u6838\u5fc3\uff0821\u5468 vs 51-60\u5468\uff09\u3002", "conclusion": "\u9879\u76ee\u4f7f\u547d\u4e0e\u4e2a\u4eba\u4ef7\u503c\u89c2\u7684\u5951\u5408\u4ee5\u53ca\u5148\u82b1\u65f6\u95f4\u4e86\u89e3\u4ee3\u7801\u5e93\u518d\u8fdb\u884c\u4e3b\u8981\u8d21\u732e\u662f\u6210\u4e3a\u6838\u5fc3\u8d21\u732e\u8005\u7684\u5173\u952e\u7b56\u7565\u3002OSS4SG\u9879\u76ee\u521b\u9020\u4e86\u66f4\u6709\u5229\u4e8e\u65b0\u4eba\u5411\u6838\u5fc3\u8f6c\u5316\u7684\u73af\u5883\uff0c\u4e3a\u65b0\u4eba\u3001\u7ef4\u62a4\u8005\u548c\u9879\u76ee\u7ba1\u7406\u8005\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u6307\u5bfc\u3002"}}
{"id": "2601.23088", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23088", "abs": "https://arxiv.org/abs/2601.23088", "authors": ["Zhixiang Zhang", "Zesen Liu", "Yuchong Xie", "Quanfeng Huang", "Dongdong She"], "title": "From Similarity to Vulnerability: Key Collision Attack on LLM Semantic Caching", "comment": null, "summary": "Semantic caching has emerged as a pivotal technique for scaling LLM applications, widely adopted by major providers including AWS and Microsoft. By utilizing semantic embedding vectors as cache keys, this mechanism effectively minimizes latency and redundant computation for semantically similar queries. In this work, we conceptualize semantic cache keys as a form of fuzzy hashes. We demonstrate that the locality required to maximize cache hit rates fundamentally conflicts with the cryptographic avalanche effect necessary for collision resistance. Our conceptual analysis formalizes this inherent trade-off between performance (locality) and security (collision resilience), revealing that semantic caching is naturally vulnerable to key collision attacks.\n  While prior research has focused on side-channel and privacy risks, we present the first systematic study of integrity risks arising from cache collisions. We introduce CacheAttack, an automated framework for launching black-box collision attacks. We evaluate CacheAttack in security-critical tasks and agentic workflows. It achieves a hit rate of 86\\% in LLM response hijacking and can induce malicious behaviors in LLM agent, while preserving strong transferability across different embedding models. A case study on a financial agent further illustrates the real-world impact of these vulnerabilities. Finally, we discuss mitigation strategies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u8bed\u4e49\u7f13\u5b58\u952e\u89c6\u4e3a\u6a21\u7cca\u54c8\u5e0c\uff0c\u63ed\u793a\u4e86\u6027\u80fd\uff08\u5c40\u90e8\u6027\uff09\u4e0e\u5b89\u5168\uff08\u6297\u78b0\u649e\u6027\uff09\u4e4b\u95f4\u7684\u6839\u672c\u51b2\u7a81\uff0c\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u7f13\u5b58\u78b0\u649e\u5b8c\u6574\u6027\u98ce\u9669\u7684\u7cfb\u7edf\u7814\u7a76\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u653b\u51fb\u6846\u67b6CacheAttack\u3002", "motivation": "\u8bed\u4e49\u7f13\u5b58\u5df2\u6210\u4e3a\u6269\u5c55LLM\u5e94\u7528\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4fa7\u4fe1\u9053\u548c\u9690\u79c1\u98ce\u9669\uff0c\u7f3a\u4e4f\u5bf9\u7f13\u5b58\u78b0\u649e\u5f15\u53d1\u7684\u5b8c\u6574\u6027\u98ce\u9669\u7684\u7cfb\u7edf\u7814\u7a76\u3002\u4f5c\u8005\u53d1\u73b0\u8bed\u4e49\u7f13\u5b58\u952e\u4f5c\u4e3a\u6a21\u7cca\u54c8\u5e0c\uff0c\u5176\u6700\u5927\u5316\u7f13\u5b58\u547d\u4e2d\u7387\u6240\u9700\u7684\u5c40\u90e8\u6027\u4e0e\u5bc6\u7801\u5b66\u96ea\u5d29\u6548\u5e94\u6240\u9700\u7684\u6297\u78b0\u649e\u6027\u5b58\u5728\u6839\u672c\u51b2\u7a81\u3002", "method": "\u5c06\u8bed\u4e49\u7f13\u5b58\u952e\u6982\u5ff5\u5316\u4e3a\u6a21\u7cca\u54c8\u5e0c\uff0c\u5f62\u5f0f\u5316\u5206\u6790\u6027\u80fd\u4e0e\u5b89\u5168\u4e4b\u95f4\u7684\u6743\u8861\u3002\u5f00\u53d1CacheAttack\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u53d1\u8d77\u9ed1\u76d2\u78b0\u649e\u653b\u51fb\u3002\u5728\u5b89\u5168\u5173\u952e\u4efb\u52a1\u548c\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e2d\u8bc4\u4f30\u653b\u51fb\u6548\u679c\uff0c\u5305\u62ecLLM\u54cd\u5e94\u52ab\u6301\u548c\u8bf1\u5bfc\u6076\u610f\u884c\u4e3a\uff0c\u5e76\u7814\u7a76\u4e0d\u540c\u5d4c\u5165\u6a21\u578b\u95f4\u7684\u53ef\u8fc1\u79fb\u6027\u3002", "result": "CacheAttack\u5728LLM\u54cd\u5e94\u52ab\u6301\u4e2d\u8fbe\u523086%\u7684\u547d\u4e2d\u7387\uff0c\u80fd\u591f\u8bf1\u5bfcLLM\u667a\u80fd\u4f53\u4ea7\u751f\u6076\u610f\u884c\u4e3a\uff0c\u4e14\u5728\u4e0d\u540c\u5d4c\u5165\u6a21\u578b\u95f4\u4fdd\u6301\u5f3a\u53ef\u8fc1\u79fb\u6027\u3002\u91d1\u878d\u667a\u80fd\u4f53\u6848\u4f8b\u7814\u7a76\u8fdb\u4e00\u6b65\u5c55\u793a\u4e86\u8fd9\u4e9b\u6f0f\u6d1e\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "conclusion": "\u8bed\u4e49\u7f13\u5b58\u5929\u7136\u6613\u53d7\u5bc6\u94a5\u78b0\u649e\u653b\u51fb\uff0c\u63ed\u793a\u4e86\u6027\u80fd\u4e0e\u5b89\u5168\u4e4b\u95f4\u7684\u6839\u672c\u6743\u8861\u3002\u8fd9\u662f\u9996\u4e2a\u7cfb\u7edf\u7814\u7a76\u7f13\u5b58\u78b0\u649e\u5b8c\u6574\u6027\u98ce\u9669\u7684\u5de5\u4f5c\uff0c\u63d0\u51fa\u7684CacheAttack\u6846\u67b6\u5c55\u793a\u4e86\u5b9e\u9645\u5a01\u80c1\uff0c\u6700\u540e\u8ba8\u8bba\u4e86\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2601.23254", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.23254", "abs": "https://arxiv.org/abs/2601.23254", "authors": ["Baoyi Wang", "Xingliang Wang", "Guochang Li", "Chen Zhi", "Junxiao Han", "Xinkui Zhao", "Nan Wang", "Shuiguang Deng", "Jianwei Yin"], "title": "GrepRAG: An Empirical Study and Optimization of Grep-Like Retrieval for Code Completion", "comment": "Under Review", "summary": "Repository-level code completion remains challenging for large language models (LLMs) due to cross-file dependencies and limited context windows. Prior work addresses this challenge using Retrieval-Augmented Generation (RAG) frameworks based on semantic indexing or structure-aware graph analysis, but these approaches incur substantial computational overhead for index construction and maintenance. Motivated by common developer workflows that rely on lightweight search utilities (e.g., ripgrep), we revisit a fundamental yet underexplored question: how far can simple, index-free lexical retrieval support repository-level code completion before more complex retrieval mechanisms become necessary? To answer this question, we systematically investigate lightweight, index-free, intent-aware lexical retrieval through extensive empirical analysis. We first introduce Naive GrepRAG, a baseline framework in which LLMs autonomously generate ripgrep commands to retrieve relevant context. Despite its simplicity, Naive GrepRAG achieves performance comparable to sophisticated graph-based baselines. Further analysis shows that its effectiveness stems from retrieving lexically precise code fragments that are spatially closer to the completion site. We also identify key limitations of lexical retrieval, including sensitivity to noisy matches from high-frequency ambiguous keywords and context fragmentation caused by rigid truncation boundaries. To address these issues, we propose GrepRAG, which augments lexical retrieval with a lightweight post-processing pipeline featuring identifier-weighted re-ranking and structure-aware deduplication. Extensive evaluation on CrossCodeEval and RepoEval-Updated demonstrates that GrepRAG consistently outperforms state-of-the-art (SOTA) methods, achieving 7.04-15.58 percent relative improvement in code exact match (EM) over the best baseline on CrossCodeEval.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGrepRAG\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u7d22\u5f15\u7684\u8bcd\u6c47\u68c0\u7d22\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\uff0c\u901a\u8fc7\u7b80\u5355\u7684grep\u547d\u4ee4\u68c0\u7d22\u548c\u8f7b\u91cf\u7ea7\u540e\u5904\u7406\uff0c\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u590d\u6742\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7684\u8bed\u4e49\u7d22\u5f15\u6216\u56fe\u5206\u6790\uff0c\u8ba1\u7b97\u5f00\u9500\u5927\u3002\u53d7\u5f00\u53d1\u8005\u5e38\u7528\u8f7b\u91cf\u7ea7\u641c\u7d22\u5de5\u5177\u542f\u53d1\uff0c\u63a2\u7d22\u7b80\u5355\u8bcd\u6c47\u68c0\u7d22\u5728\u4ee3\u7801\u8865\u5168\u4e2d\u7684\u6f5c\u529b\u3002", "method": "1. \u63d0\u51faNaive GrepRAG\u57fa\u7ebf\uff1aLLM\u81ea\u4e3b\u751f\u6210ripgrep\u547d\u4ee4\u68c0\u7d22\u76f8\u5173\u4e0a\u4e0b\u6587\uff1b2. \u6539\u8fdb\u4e3aGrepRAG\uff1a\u589e\u52a0\u6807\u8bc6\u7b26\u52a0\u6743\u91cd\u6392\u5e8f\u548c\u7ed3\u6784\u611f\u77e5\u53bb\u91cd\u540e\u5904\u7406\u7ba1\u9053\u3002", "result": "Naive GrepRAG\u6027\u80fd\u5df2\u63a5\u8fd1\u590d\u6742\u56fe\u57fa\u7ebf\uff1bGrepRAG\u5728CrossCodeEval\u548cRepoEval-Updated\u4e0a\u6301\u7eed\u8d85\u8d8aSOTA\u65b9\u6cd5\uff0c\u5728CrossCodeEval\u4e0a\u4ee3\u7801\u7cbe\u786e\u5339\u914d\u76f8\u5bf9\u63d0\u53477.04-15.58%\u3002", "conclusion": "\u7b80\u5355\u8bcd\u6c47\u68c0\u7d22\u7ed3\u5408\u8f7b\u91cf\u7ea7\u540e\u5904\u7406\u80fd\u6709\u6548\u652f\u6301\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\uff0c\u65e0\u9700\u590d\u6742\u7d22\u5f15\u673a\u5236\uff0c\u4e3a\u4ee3\u7801\u8865\u5168\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22758", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22758", "abs": "https://arxiv.org/abs/2601.22758", "authors": ["Libin Qiu", "Zhirong Gao", "Junfu Chen", "Yuhang Ye", "Weizhi Huang", "Xiaobo Xue", "Wenkai Qiu", "Shuo Tang"], "title": "AutoRefine: From Trajectories to Reusable Expertise for Continual LLM Agent Refinement", "comment": "8 pages, 3 figures, 3 tables", "summary": "Large language model agents often fail to accumulate knowledge from experience, treating each task as an independent challenge. Recent methods extract experience as flattened textual knowledge, which cannot capture procedural logic of complex subtasks. They also lack maintenance mechanisms, causing repository degradation as experience accumulates. We introduce AutoRefine, a framework that extracts and maintains dual-form Experience Patterns from agent execution histories. For procedural subtasks, we extract specialized subagents with independent reasoning and memory. For static knowledge, we extract skill patterns as guidelines or code snippets. A continuous maintenance mechanism scores, prunes, and merges patterns to prevent repository degradation. Evaluated on ALFWorld, ScienceWorld, and TravelPlanner, AutoRefine achieves 98.4%, 70.4%, and 27.1% respectively, with 20-73% step reductions. On TravelPlanner, automatic extraction exceeds manually designed systems (27.1% vs 12.1%), demonstrating its ability to capture procedural coordination.", "AI": {"tldr": "AutoRefine\u6846\u67b6\u4ece\u667a\u80fd\u4f53\u6267\u884c\u5386\u53f2\u4e2d\u63d0\u53d6\u548c\u7ef4\u62a4\u53cc\u91cd\u5f62\u5f0f\u7684\u7ecf\u9a8c\u6a21\u5f0f\uff0c\u5305\u62ec\u7528\u4e8e\u590d\u6742\u5b50\u4efb\u52a1\u7684\u4e13\u7528\u5b50\u667a\u80fd\u4f53\u548c\u7528\u4e8e\u9759\u6001\u77e5\u8bc6\u7684\u6280\u80fd\u6a21\u5f0f\uff0c\u901a\u8fc7\u6301\u7eed\u7ef4\u62a4\u673a\u5236\u9632\u6b62\u77e5\u8bc6\u5e93\u9000\u5316\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u6b65\u9aa4\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5f80\u5f80\u65e0\u6cd5\u4ece\u7ecf\u9a8c\u4e2d\u79ef\u7d2f\u77e5\u8bc6\uff0c\u5c06\u6bcf\u4e2a\u4efb\u52a1\u89c6\u4e3a\u72ec\u7acb\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u7ecf\u9a8c\u63d0\u53d6\u4e3a\u6241\u5e73\u5316\u7684\u6587\u672c\u77e5\u8bc6\uff0c\u65e0\u6cd5\u6355\u6349\u590d\u6742\u5b50\u4efb\u52a1\u7684\u7a0b\u5e8f\u903b\u8f91\uff0c\u4e14\u7f3a\u4e4f\u7ef4\u62a4\u673a\u5236\u5bfc\u81f4\u77e5\u8bc6\u5e93\u968f\u7740\u7ecf\u9a8c\u79ef\u7d2f\u800c\u9000\u5316\u3002", "method": "\u63d0\u51faAutoRefine\u6846\u67b6\uff0c\u4ece\u667a\u80fd\u4f53\u6267\u884c\u5386\u53f2\u4e2d\u63d0\u53d6\u548c\u7ef4\u62a4\u53cc\u91cd\u5f62\u5f0f\u7684\u7ecf\u9a8c\u6a21\u5f0f\uff1a1) \u5bf9\u4e8e\u7a0b\u5e8f\u6027\u5b50\u4efb\u52a1\uff0c\u63d0\u53d6\u5177\u6709\u72ec\u7acb\u63a8\u7406\u548c\u8bb0\u5fc6\u7684\u4e13\u7528\u5b50\u667a\u80fd\u4f53\uff1b2) \u5bf9\u4e8e\u9759\u6001\u77e5\u8bc6\uff0c\u63d0\u53d6\u6280\u80fd\u6a21\u5f0f\u4f5c\u4e3a\u6307\u5bfc\u65b9\u9488\u6216\u4ee3\u7801\u7247\u6bb5\u3002\u91c7\u7528\u6301\u7eed\u7ef4\u62a4\u673a\u5236\u5bf9\u6a21\u5f0f\u8fdb\u884c\u8bc4\u5206\u3001\u4fee\u526a\u548c\u5408\u5e76\uff0c\u9632\u6b62\u77e5\u8bc6\u5e93\u9000\u5316\u3002", "result": "\u5728ALFWorld\u3001ScienceWorld\u548cTravelPlanner\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAutoRefine\u5206\u522b\u8fbe\u523098.4%\u300170.4%\u548c27.1%\u7684\u6210\u529f\u7387\uff0c\u540c\u65f6\u51cf\u5c1120-73%\u7684\u6b65\u9aa4\u3002\u5728TravelPlanner\u4e0a\uff0c\u81ea\u52a8\u63d0\u53d6\u7684\u7cfb\u7edf\u8d85\u8fc7\u624b\u52a8\u8bbe\u8ba1\u7cfb\u7edf\uff0827.1% vs 12.1%\uff09\uff0c\u5c55\u793a\u4e86\u5176\u6355\u6349\u7a0b\u5e8f\u534f\u8c03\u7684\u80fd\u529b\u3002", "conclusion": "AutoRefine\u6846\u67b6\u901a\u8fc7\u63d0\u53d6\u548c\u7ef4\u62a4\u53cc\u91cd\u5f62\u5f0f\u7684\u7ecf\u9a8c\u6a21\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u667a\u80fd\u4f53\u65e0\u6cd5\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u590d\u6742\u7a0b\u5e8f\u903b\u8f91\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6027\u80fd\u5e76\u51cf\u5c11\u4e86\u6267\u884c\u6b65\u9aa4\uff0c\u8bc1\u660e\u4e86\u81ea\u52a8\u7ecf\u9a8c\u63d0\u53d6\u5728\u6355\u6349\u7a0b\u5e8f\u534f\u8c03\u65b9\u9762\u7684\u4f18\u52bf\u3002"}}
{"id": "2601.23092", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23092", "abs": "https://arxiv.org/abs/2601.23092", "authors": ["Haitham S. Al-Sinani", "Chris J. Mitchell"], "title": "WiFiPenTester: Advancing Wireless Ethical Hacking with Governed GenAI", "comment": "35 pages, 10 figures", "summary": "Wireless ethical hacking relies heavily on skilled practitioners manually interpreting reconnaissance results and executing complex, time-sensitive sequences of commands to identify vulnerable targets, capture authentication handshakes, and assess password resilience; a process that is inherently labour-intensive, difficult to scale, and prone to subjective judgement and human error. To help address these limitations, we propose WiFiPenTester, an experimental, governed, and reproducible system for GenAI-enabled wireless ethical hacking. The system integrates large language models into the reconnaissance and decision-support phases of wireless security assessment, enabling intelligent target ranking, attack feasibility estimation, and strategy recommendation, while preserving strict human-in-the-loop control and budget-aware execution. We describe the system architecture, threat model, governance mechanisms, and prompt-engineering methodology, and empirical experiments conducted across multiple wireless environments. The results demonstrate that GenAI assistance improves target selection accuracy and overall assessment efficiency, while maintaining auditability and ethical safeguards. This indicates that WiFiPenTester is a meaningful step toward practical, safe, and scalable GenAI-assisted wireless penetration testing, while reinforcing the necessity of bounded autonomy, human oversight, and rigorous governance mechanisms when deploying GenAI in ethical hacking.", "AI": {"tldr": "WiFiPenTester\uff1a\u4e00\u4e2a\u5b9e\u9a8c\u6027\u7684\u3001\u53d7\u7ba1\u63a7\u7684\u3001\u53ef\u590d\u73b0\u7684GenAI\u65e0\u7ebf\u4f26\u7406\u9ed1\u5ba2\u7cfb\u7edf\uff0c\u901a\u8fc7\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u6539\u8fdb\u65e0\u7ebf\u5b89\u5168\u8bc4\u4f30\u7684\u76ee\u6807\u9009\u62e9\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4eba\u5de5\u76d1\u7763\u548c\u4f26\u7406\u4fdd\u969c\u3002", "motivation": "\u4f20\u7edf\u65e0\u7ebf\u4f26\u7406\u9ed1\u5ba2\u4f9d\u8d56\u4eba\u5de5\u624b\u52a8\u89e3\u91ca\u4fa6\u5bdf\u7ed3\u679c\u5e76\u6267\u884c\u590d\u6742\u547d\u4ee4\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u52b3\u52a8\u5bc6\u96c6\u3001\u96be\u4ee5\u6269\u5c55\u3001\u6613\u53d7\u4e3b\u89c2\u5224\u65ad\u548c\u4eba\u4e3a\u9519\u8bef\u5f71\u54cd\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u65e0\u7ebf\u5b89\u5168\u8bc4\u4f30\u3002", "method": "\u63d0\u51faWiFiPenTester\u7cfb\u7edf\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u65e0\u7ebf\u5b89\u5168\u8bc4\u4f30\u7684\u4fa6\u5bdf\u548c\u51b3\u7b56\u652f\u6301\u9636\u6bb5\uff0c\u5b9e\u73b0\u667a\u80fd\u76ee\u6807\u6392\u540d\u3001\u653b\u51fb\u53ef\u884c\u6027\u8bc4\u4f30\u548c\u7b56\u7565\u63a8\u8350\uff0c\u540c\u65f6\u4fdd\u6301\u4e25\u683c\u7684\u4eba\u5de5\u76d1\u7763\u63a7\u5236\u548c\u9884\u7b97\u611f\u77e5\u6267\u884c\u3002\u5305\u62ec\u7cfb\u7edf\u67b6\u6784\u3001\u5a01\u80c1\u6a21\u578b\u3001\u6cbb\u7406\u673a\u5236\u548c\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u3002", "result": "\u5728\u591a\u4e2a\u65e0\u7ebf\u73af\u5883\u4e2d\u7684\u5b9e\u8bc1\u5b9e\u9a8c\u8868\u660e\uff0cGenAI\u8f85\u52a9\u63d0\u9ad8\u4e86\u76ee\u6807\u9009\u62e9\u51c6\u786e\u6027\u548c\u6574\u4f53\u8bc4\u4f30\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u53ef\u5ba1\u8ba1\u6027\u548c\u4f26\u7406\u4fdd\u969c\u3002", "conclusion": "WiFiPenTester\u662f\u5411\u5b9e\u7528\u3001\u5b89\u5168\u3001\u53ef\u6269\u5c55\u7684GenAI\u8f85\u52a9\u65e0\u7ebf\u6e17\u900f\u6d4b\u8bd5\u8fc8\u51fa\u7684\u6709\u610f\u4e49\u4e00\u6b65\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u5728\u4f26\u7406\u9ed1\u5ba2\u4e2d\u90e8\u7f72GenAI\u65f6\u9700\u8981\u6709\u9650\u81ea\u6cbb\u3001\u4eba\u5de5\u76d1\u7763\u548c\u4e25\u683c\u6cbb\u7406\u673a\u5236\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2601.23257", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.23257", "abs": "https://arxiv.org/abs/2601.23257", "authors": ["Chenglin Li", "Yisen Xu", "Zehao Wang", "Shin Hwei Tan", "Tse-Hsun", "Chen"], "title": "Outcome-Conditioned Reasoning Distillation for Resolving Software Issues", "comment": "17 pages, 3 figures, 5 tables", "summary": "Software issue resolution in large repositories is a long-range decision process: choices made during localization shape the space of viable edits, and missteps can compound into incorrect patches. Despite this, many LLM-based repair pipelines still operate in a reset-and-solve manner, producing fresh reasoning for every new issue instead of carrying forward what worked in past fixes. This is wasteful because repositories routinely contain earlier issues with overlapping structure, failure modes, or constraints, where prior repair experience could provide useful guidance. Existing approaches typically harvest this signal through forward-time trial procedures, such as repeated refinement or search, incurring high inference cost while still risking divergence from the eventual correct patch. We present an Outcome-Conditioned Reasoning Distillation(O-CRD) framework that uses resolved in-repository issues with verified patches as supervision. Starting from a historical fix, the method reconstructs a stage-wise repair trace backward from the verified outcome, then reuses the distilled guidance at inference time to steer file/function localization and patch synthesis, without fine-tuning or online search. On SWE-Bench Lite, this approach increases Pass@1 by 10.4% with GPT-4o, 8.6% with DeepSeek-V3, and 10.3% with GPT-5, indicating that outcome-conditioned reuse of verified repairs can replace costly forward exploration for software issue resolution.", "AI": {"tldr": "O-CRD\u6846\u67b6\u5229\u7528\u5df2\u89e3\u51b3\u7684\u4ee3\u7801\u5e93\u95ee\u9898\u4f5c\u4e3a\u76d1\u7763\uff0c\u901a\u8fc7\u4ece\u5df2\u9a8c\u8bc1\u8865\u4e01\u53cd\u5411\u91cd\u6784\u4fee\u590d\u8f68\u8ff9\uff0c\u5728\u63a8\u7406\u65f6\u91cd\u7528\u8fd9\u4e9b\u6307\u5bfc\u6765\u5f15\u5bfc\u95ee\u9898\u5b9a\u4f4d\u548c\u8865\u4e01\u751f\u6210\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u5728\u7ebf\u641c\u7d22\uff0c\u663e\u8457\u63d0\u5347\u8f6f\u4ef6\u95ee\u9898\u4fee\u590d\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u4fee\u590d\u7ba1\u9053\u901a\u5e38\u4ee5\u91cd\u7f6e\u548c\u89e3\u51b3\u7684\u65b9\u5f0f\u64cd\u4f5c\uff0c\u4e3a\u6bcf\u4e2a\u65b0\u95ee\u9898\u751f\u6210\u65b0\u7684\u63a8\u7406\uff0c\u800c\u4e0d\u662f\u5229\u7528\u8fc7\u53bb\u4fee\u590d\u4e2d\u7684\u7ecf\u9a8c\u3002\u8fd9\u5f88\u6d6a\u8d39\uff0c\u56e0\u4e3a\u4ee3\u7801\u5e93\u4e2d\u901a\u5e38\u5305\u542b\u5177\u6709\u91cd\u53e0\u7ed3\u6784\u3001\u6545\u969c\u6a21\u5f0f\u6216\u7ea6\u675f\u7684\u65e9\u671f\u95ee\u9898\uff0c\u5148\u524d\u7684\u4fee\u590d\u7ecf\u9a8c\u53ef\u4ee5\u63d0\u4f9b\u6709\u7528\u7684\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u7ed3\u679c\u6761\u4ef6\u63a8\u7406\u84b8\u998f(O-CRD)\u6846\u67b6\uff0c\u4f7f\u7528\u5df2\u89e3\u51b3\u7684\u4ee3\u7801\u5e93\u95ee\u9898\u548c\u5df2\u9a8c\u8bc1\u8865\u4e01\u4f5c\u4e3a\u76d1\u7763\u3002\u4ece\u5386\u53f2\u4fee\u590d\u5f00\u59cb\uff0c\u65b9\u6cd5\u4ece\u5df2\u9a8c\u8bc1\u7ed3\u679c\u5411\u540e\u91cd\u6784\u5206\u9636\u6bb5\u7684\u4fee\u590d\u8f68\u8ff9\uff0c\u7136\u540e\u5728\u63a8\u7406\u65f6\u91cd\u7528\u84b8\u998f\u7684\u6307\u5bfc\u6765\u5f15\u5bfc\u6587\u4ef6/\u51fd\u6570\u5b9a\u4f4d\u548c\u8865\u4e01\u5408\u6210\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u5728\u7ebf\u641c\u7d22\u3002", "result": "\u5728SWE-Bench Lite\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4f7fGPT-4o\u7684Pass@1\u63d0\u9ad8\u4e8610.4%\uff0cDeepSeek-V3\u63d0\u9ad8\u4e868.6%\uff0cGPT-5\u63d0\u9ad8\u4e8610.3%\uff0c\u8868\u660e\u7ed3\u679c\u6761\u4ef6\u7684\u5df2\u9a8c\u8bc1\u4fee\u590d\u91cd\u7528\u53ef\u4ee5\u66ff\u4ee3\u6602\u8d35\u7684\u6b63\u5411\u63a2\u7d22\u3002", "conclusion": "\u7ed3\u679c\u6761\u4ef6\u7684\u5df2\u9a8c\u8bc1\u4fee\u590d\u91cd\u7528\u53ef\u4ee5\u6709\u6548\u66ff\u4ee3\u6602\u8d35\u7684\u6b63\u5411\u63a2\u7d22\uff0c\u4e3a\u8f6f\u4ef6\u95ee\u9898\u89e3\u51b3\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u4ee3\u7801\u5e93\u4e2d\u8f6f\u4ef6\u95ee\u9898\u4fee\u590d\u7684\u6027\u80fd\u3002"}}
{"id": "2601.22776", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22776", "abs": "https://arxiv.org/abs/2601.22776", "authors": ["Shichao Ma", "Zhiyuan Ma", "Ming Yang", "Xiaofan Li", "Xing Wu", "Jintao Du", "Yu Cheng", "Weiqiang Wang", "Qiliang Liu", "Zhengyang Zhou", "Yang Wang"], "title": "TSPO: Breaking the Double Homogenization Dilemma in Multi-turn Search Policy Optimization", "comment": null, "summary": "Multi-turn tool-integrated reasoning enables Large Language Models (LLMs) to solve complex tasks through iterative information retrieval. However, current reinforcement learning (RL) frameworks for search-augmented reasoning predominantly rely on sparse outcome-level rewards, leading to a \"Double Homogenization Dilemma.\" This manifests as (1) Process homogenization, where the thinking, reasoning, and tooling involved in generation are ignored. (2) Intra-group homogenization, coarse-grained outcome rewards often lead to inefficiencies in intra-group advantage estimation with methods like Group Relative Policy Optimization (GRPO) during sampling. To address this, we propose Turn-level Stage-aware Policy Optimization (TSPO). TSPO introduces the First-Occurrence Latent Reward (FOLR) mechanism, allocating partial rewards to the step where the ground-truth answer first appears, thereby preserving process-level signals and increasing reward variance within groups without requiring external reward models or any annotations. Extensive experiments demonstrate that TSPO significantly outperforms state-of-the-art baselines, achieving average performance gains of 24% and 13.6% on Qwen2.5-3B and 7B models, respectively.", "AI": {"tldr": "TSPO\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u9996\u6b21\u51fa\u73b0\u6f5c\u5728\u5956\u52b1\u673a\u5236\u89e3\u51b3\u591a\u8f6e\u5de5\u5177\u96c6\u6210\u63a8\u7406\u4e2d\u7684\"\u53cc\u91cd\u540c\u8d28\u5316\u56f0\u5883\"\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u641c\u7d22\u589e\u5f3a\u63a8\u7406\u6846\u67b6\u4e3b\u8981\u4f9d\u8d56\u7a00\u758f\u7684\u7ed3\u679c\u7ea7\u5956\u52b1\uff0c\u5bfc\u81f4\"\u53cc\u91cd\u540c\u8d28\u5316\u56f0\u5883\"\uff1a1) \u8fc7\u7a0b\u540c\u8d28\u5316\uff0c\u5ffd\u7565\u4e86\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u601d\u8003\u3001\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\uff1b2) \u7ec4\u5185\u540c\u8d28\u5316\uff0c\u7c97\u7c92\u5ea6\u7684\u7ed3\u679c\u5956\u52b1\u5bfc\u81f4\u7ec4\u5185\u4f18\u52bf\u4f30\u8ba1\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faTurn-level Stage-aware Policy Optimization (TSPO)\uff0c\u5f15\u5165\u9996\u6b21\u51fa\u73b0\u6f5c\u5728\u5956\u52b1(FOLR)\u673a\u5236\uff0c\u5c06\u90e8\u5206\u5956\u52b1\u5206\u914d\u7ed9\u6b63\u786e\u7b54\u6848\u9996\u6b21\u51fa\u73b0\u7684\u6b65\u9aa4\uff0c\u4fdd\u7559\u8fc7\u7a0b\u7ea7\u4fe1\u53f7\u5e76\u589e\u52a0\u7ec4\u5185\u5956\u52b1\u65b9\u5dee\uff0c\u65e0\u9700\u5916\u90e8\u5956\u52b1\u6a21\u578b\u6216\u989d\u5916\u6807\u6ce8\u3002", "result": "TSPO\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u5728Qwen2.5-3B\u548c7B\u6a21\u578b\u4e0a\u5206\u522b\u5b9e\u73b0\u4e86\u5e73\u574724%\u548c13.6%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "TSPO\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u8fc7\u7a0b\u7ea7\u5956\u52b1\u5206\u914d\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f6e\u5de5\u5177\u96c6\u6210\u63a8\u7406\u4e2d\u7684\u53cc\u91cd\u540c\u8d28\u5316\u95ee\u9898\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u5728\u641c\u7d22\u589e\u5f3a\u63a8\u7406\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.23132", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23132", "abs": "https://arxiv.org/abs/2601.23132", "authors": ["Saeid Jamshidi", "Kawser Wazed Nafi", "Arghavan Moradi Dakhel", "Foutse Khomh", "Amin Nikanjam", "Mohammad Adnan Hamdaqa"], "title": "Secure Tool Manifest and Digital Signing Solution for Verifiable MCP and LLM Pipelines", "comment": null, "summary": "Large Language Models (LLMs) are increasingly adopted in sensitive domains such as healthcare and financial institutions' data analytics; however, their execution pipelines remain vulnerable to manipulation and unverifiable behavior. Existing control mechanisms, such as the Model Context Protocol (MCP), define compliance policies for tool invocation but lack verifiable enforcement and transparent validation of model actions. To address this gap, we propose a novel Secure Tool Manifest and Digital Signing Framework, a structured and security-aware extension of Model Context Protocols. The framework enforces cryptographically signed manifests, integrates transparent verification logs, and isolates model-internal execution metadata from user-visible components to ensure verifiable execution integrity. Furthermore, the evaluation demonstrates that the framework scales nearly linearly (R-squared = 0.998), achieves near-perfect acceptance of valid executions while consistently rejecting invalid ones, and maintains balanced model utilization across execution pipelines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b89\u5168\u5de5\u5177\u6e05\u5355\u548c\u6570\u5b57\u7b7e\u540d\u6846\u67b6\uff0c\u4f5c\u4e3a\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u7684\u6269\u5c55\uff0c\u901a\u8fc7\u52a0\u5bc6\u7b7e\u540d\u548c\u900f\u660e\u9a8c\u8bc1\u786e\u4fddLLM\u6267\u884c\u7ba1\u9053\u7684\u5b8c\u6574\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u6267\u884c\u7ba1\u9053\u5bb9\u6613\u53d7\u5230\u64cd\u7eb5\u4e14\u884c\u4e3a\u4e0d\u53ef\u9a8c\u8bc1\u3002\u73b0\u6709\u7684\u63a7\u5236\u673a\u5236\uff08\u5982MCP\uff09\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u7684\u6267\u884c\u5f3a\u5236\u548c\u900f\u660e\u7684\u6a21\u578b\u52a8\u4f5c\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u5b89\u5168\u5de5\u5177\u6e05\u5355\u548c\u6570\u5b57\u7b7e\u540d\u6846\u67b6\uff0c\u5305\u62ec\uff1a1\uff09\u5f3a\u5236\u6267\u884c\u52a0\u5bc6\u7b7e\u540d\u7684\u6e05\u5355\uff1b2\uff09\u96c6\u6210\u900f\u660e\u9a8c\u8bc1\u65e5\u5fd7\uff1b3\uff09\u5c06\u6a21\u578b\u5185\u90e8\u6267\u884c\u5143\u6570\u636e\u4e0e\u7528\u6237\u53ef\u89c1\u7ec4\u4ef6\u9694\u79bb\uff0c\u786e\u4fdd\u53ef\u9a8c\u8bc1\u7684\u6267\u884c\u5b8c\u6574\u6027\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff1a1\uff09\u6846\u67b6\u6269\u5c55\u6027\u63a5\u8fd1\u7ebf\u6027\uff08R\u5e73\u65b9=0.998\uff09\uff1b2\uff09\u51e0\u4e4e\u5b8c\u7f8e\u63a5\u53d7\u6709\u6548\u6267\u884c\uff0c\u540c\u65f6\u4e00\u81f4\u62d2\u7edd\u65e0\u6548\u6267\u884c\uff1b3\uff09\u5728\u6267\u884c\u7ba1\u9053\u4e2d\u4fdd\u6301\u5e73\u8861\u7684\u6a21\u578b\u5229\u7528\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u89e3\u51b3\u4e86LLM\u5728\u654f\u611f\u9886\u57df\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u4f9b\u4e86\u53ef\u9a8c\u8bc1\u7684\u6267\u884c\u5b8c\u6574\u6027\u548c\u900f\u660e\u9a8c\u8bc1\u673a\u5236\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u6a21\u578b\u6267\u884c\u7ba1\u9053\u7684\u5b89\u5168\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2601.22786", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22786", "abs": "https://arxiv.org/abs/2601.22786", "authors": ["Hamid Reza Akbari", "Mohammad Hossein Sameti", "Amir M. Mansourian", "Mohammad Hossein Rohban", "Hossein Sameti"], "title": "Toward IIT-Inspired Consciousness in LLMs: A Reward-Based Learning Framework", "comment": "13 pages, 8 figures, 4 tables", "summary": "The pursuit of Artificial General Intelligence (AGI) is a central goal in language model development, in which consciousness-like processing could serve as a key facilitator. While current language models are not conscious, they exhibit behaviors analogous to certain aspects of consciousness. This paper investigates the implementation of a leading theory of consciousness, Integrated Information Theory (IIT), within language models via a reward-based learning paradigm. IIT provides a formal, axiom-based mathematical framework for quantifying consciousness. Drawing inspiration from its core principles, we formulate a novel reward function that quantifies a text's causality, coherence and integration, characteristics associated with conscious processing. Empirically, it is found that optimizing for this IIT-inspired reward leads to more concise text generation. On out of domain tasks, careful tuning achieves up to a 31% reduction in output length while preserving accuracy levels comparable to the base model. In addition to primary task performance, the broader effects of this training methodology on the model's confidence calibration and test-time computational scaling is analyzed. The proposed framework offers significant practical advantages: it is conceptually simple, computationally efficient, requires no external data or auxiliary models, and leverages a general, capability-driven signal rather than task-specific heuristics. Code available at https://github.com/MH-Sameti/LLM_PostTraining.git", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6574\u5408\u4fe1\u606f\u7406\u8bba(IIT)\u7684\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u7684\u56e0\u679c\u6027\u3001\u8fde\u8d2f\u6027\u548c\u6574\u5408\u6027\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0d\u635f\u5931\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u5c06\u8f93\u51fa\u957f\u5ea6\u51cf\u5c11\u9ad8\u8fbe31%\u7684\u6548\u679c\u3002", "motivation": "\u8ffd\u6c42\u4eba\u5de5\u901a\u7528\u667a\u80fd(AGI)\u662f\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u7684\u6838\u5fc3\u76ee\u6807\uff0c\u800c\u7c7b\u4f3c\u610f\u8bc6\u7684\u5904\u7406\u53ef\u80fd\u6210\u4e3a\u5173\u952e\u4fc3\u8fdb\u56e0\u7d20\u3002\u867d\u7136\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u4e0d\u5177\u5907\u610f\u8bc6\uff0c\u4f46\u5b83\u4eec\u8868\u73b0\u51fa\u4e0e\u610f\u8bc6\u67d0\u4e9b\u65b9\u9762\u7c7b\u4f3c\u7684\u884c\u4e3a\u3002\u672c\u7814\u7a76\u65e8\u5728\u5c06\u9886\u5148\u7684\u610f\u8bc6\u7406\u8bba\u2014\u2014\u6574\u5408\u4fe1\u606f\u7406\u8bba(IIT)\u901a\u8fc7\u57fa\u4e8e\u5956\u52b1\u7684\u5b66\u4e60\u8303\u5f0f\u5e94\u7528\u4e8e\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u57fa\u4e8e\u6574\u5408\u4fe1\u606f\u7406\u8bba(IIT)\u7684\u6838\u5fc3\u539f\u5219\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5956\u52b1\u51fd\u6570\uff0c\u7528\u4e8e\u91cf\u5316\u6587\u672c\u7684\u56e0\u679c\u6027\u3001\u8fde\u8d2f\u6027\u548c\u6574\u5408\u6027\u2014\u2014\u8fd9\u4e9b\u7279\u5f81\u4e0e\u610f\u8bc6\u5904\u7406\u76f8\u5173\u3002\u901a\u8fc7\u5956\u52b1\u9a71\u52a8\u7684\u5b66\u4e60\u8303\u5f0f\u4f18\u5316\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u751f\u6210\u66f4\u7b26\u5408\u8fd9\u4e9b\u7279\u5f81\u7684\u6587\u672c\u3002", "result": "\u4f18\u5316IIT\u542f\u53d1\u7684\u5956\u52b1\u51fd\u6570\u80fd\u4ea7\u751f\u66f4\u7b80\u6d01\u7684\u6587\u672c\u751f\u6210\u3002\u5728\u9886\u57df\u5916\u4efb\u52a1\u4e0a\uff0c\u7ecf\u8fc7\u7cbe\u7ec6\u8c03\u4f18\u540e\uff0c\u8f93\u51fa\u957f\u5ea6\u51cf\u5c11\u4e86\u9ad8\u8fbe31%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u57fa\u7840\u6a21\u578b\u76f8\u5f53\u7684\u51c6\u786e\u6027\u6c34\u5e73\u3002\u7814\u7a76\u8fd8\u5206\u6790\u4e86\u8be5\u65b9\u6cd5\u5bf9\u6a21\u578b\u7f6e\u4fe1\u5ea6\u6821\u51c6\u548c\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u6027\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5177\u6709\u663e\u8457\u7684\u5b9e\u9645\u4f18\u52bf\uff1a\u6982\u5ff5\u7b80\u5355\u3001\u8ba1\u7b97\u9ad8\u6548\u3001\u65e0\u9700\u5916\u90e8\u6570\u636e\u6216\u8f85\u52a9\u6a21\u578b\uff0c\u5e76\u4e14\u5229\u7528\u4e86\u901a\u7528\u7684\u80fd\u529b\u9a71\u52a8\u4fe1\u53f7\u800c\u975e\u4efb\u52a1\u7279\u5b9a\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u4e3a\u8bed\u8a00\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u4e14\u6709\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2601.22790", "categories": ["cs.AI", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.22790", "abs": "https://arxiv.org/abs/2601.22790", "authors": ["Jianguo Huang", "Hao Zeng", "Bingyi Jing", "Hongxin Wei", "Bo An"], "title": "Conditional Performance Guarantee for Large Reasoning Models", "comment": null, "summary": "Large reasoning models have shown strong performance through extended chain-of-thought reasoning, yet their computational cost remains significant. Probably approximately correct (PAC) reasoning provides statistical guarantees for efficient reasoning by adaptively switching between thinking and non-thinking models, but the guarantee holds only in the marginal case and does not provide exact conditional coverage. We propose G-PAC reasoning, a practical framework that provides PAC-style guarantees at the group level by partitioning the input space. We develop two instantiations: Group PAC (G-PAC) reasoning for known group structures and Clustered PAC (C-PAC) reasoning for unknown groupings. We prove that both G-PAC and C-PAC achieve group-conditional risk control, and that grouping can strictly improve efficiency over marginal PAC reasoning in heterogeneous settings. Our experiments on diverse reasoning benchmarks demonstrate that G-PAC and C-PAC successfully achieve group-conditional risk control while maintaining substantial computational savings.", "AI": {"tldr": "\u63d0\u51fa\u4e86G-PAC\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8f93\u5165\u7a7a\u95f4\u5206\u7ec4\u5b9e\u73b0\u7ec4\u7ea7PAC\u4fdd\u8bc1\uff0c\u76f8\u6bd4\u4f20\u7edf\u8fb9\u9645PAC\u63a8\u7406\u5728\u5f02\u6784\u573a\u666f\u4e0b\u80fd\u4e25\u683c\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u5c55\u73b0\u5f3a\u5927\u6027\u80fd\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u73b0\u6709\u7684PAC\u63a8\u7406\u867d\u7136\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u4f46\u4ec5\u5728\u8fb9\u9645\u60c5\u51b5\u4e0b\u6709\u6548\uff0c\u65e0\u6cd5\u63d0\u4f9b\u7cbe\u786e\u7684\u6761\u4ef6\u8986\u76d6\u3002", "method": "\u63d0\u51faG-PAC\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5212\u5206\u8f93\u5165\u7a7a\u95f4\u5b9e\u73b0\u7ec4\u7ea7PAC\u4fdd\u8bc1\u3002\u5f00\u53d1\u4e24\u79cd\u5177\u4f53\u5b9e\u73b0\uff1a\u9488\u5bf9\u5df2\u77e5\u5206\u7ec4\u7ed3\u6784\u7684Group PAC (G-PAC)\u63a8\u7406\uff0c\u4ee5\u53ca\u9488\u5bf9\u672a\u77e5\u5206\u7ec4\u7684Clustered PAC (C-PAC)\u63a8\u7406\u3002", "result": "\u7406\u8bba\u8bc1\u660eG-PAC\u548cC-PAC\u90fd\u80fd\u5b9e\u73b0\u7ec4\u6761\u4ef6\u98ce\u9669\u63a7\u5236\uff0c\u4e14\u5728\u5f02\u6784\u8bbe\u7f6e\u4e0b\u5206\u7ec4\u80fd\u4e25\u683c\u63d0\u5347\u6548\u7387\u3002\u5728\u591a\u6837\u5316\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e24\u79cd\u65b9\u6cd5\u90fd\u6210\u529f\u5b9e\u73b0\u4e86\u7ec4\u6761\u4ef6\u98ce\u9669\u63a7\u5236\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u663e\u8457\u7684\u8ba1\u7b97\u8282\u7701\u3002", "conclusion": "G-PAC\u63a8\u7406\u6846\u67b6\u4e3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u7ec4\u7ea7PAC\u4fdd\u8bc1\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u8fb9\u9645PAC\u63a8\u7406\u66f4\u7cbe\u786e\u7684\u98ce\u9669\u63a7\u5236\u3002"}}
{"id": "2601.22803", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22803", "abs": "https://arxiv.org/abs/2601.22803", "authors": ["Ji Shi", "Peiming Guo", "Meishan Zhang", "Miao Zhang", "Xuebo Liu", "Min Zhang", "Weili Guan"], "title": "CVeDRL: An Efficient Code Verifier via Difficulty-aware Reinforcement Learning", "comment": "17 pages, 3 figures", "summary": "Code verifiers play a critical role in post-verification for LLM-based code generation, yet existing supervised fine-tuning methods suffer from data scarcity, high failure rates, and poor inference efficiency. While reinforcement learning (RL) offers a promising alternative by optimizing models through execution-driven rewards without labeled supervision, our preliminary results show that naive RL with only functionality rewards fails to generate effective unit tests for difficult branches and samples. We first theoretically analyze showing that branch coverage, sample difficulty, syntactic and functional correctness can be jointly modeled as RL rewards, where optimizing these signals can improve the reliability of unit-test-based verification. Guided by this analysis, we design syntax- and functionality-aware rewards and further propose branch- and sample-difficulty--aware RL using exponential reward shaping and static analysis metrics. With this formulation, CVeDRL achieves state-of-the-art performance with only 0.6B parameters, yielding up to 28.97% higher pass rate and 15.08% higher branch coverage than GPT-3.5, while delivering over $20\\times$ faster inference than competitive baselines. Code is available at https://github.com/LIGHTCHASER1/CVeDRL.git", "AI": {"tldr": "CVeDRL\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4ee3\u7801\u9a8c\u8bc1\u5668\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u6cd5\u3001\u529f\u80fd\u3001\u5206\u652f\u8986\u76d6\u548c\u6837\u672c\u96be\u5ea6\u611f\u77e5\u7684\u5956\u52b1\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u76d1\u7763\u5fae\u8c03\u7684\u4ee3\u7801\u9a8c\u8bc1\u5668\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u3001\u9ad8\u5931\u8d25\u7387\u548c\u63a8\u7406\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002\u867d\u7136\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u65e0\u9700\u6807\u6ce8\u76d1\u7763\u7684\u4f18\u5316\u9014\u5f84\uff0c\u4f46\u4ec5\u4f7f\u7528\u529f\u80fd\u5956\u52b1\u7684\u6734\u7d20RL\u65b9\u6cd5\u96be\u4ee5\u751f\u6210\u9488\u5bf9\u56f0\u96be\u5206\u652f\u548c\u6837\u672c\u7684\u6709\u6548\u5355\u5143\u6d4b\u8bd5\u3002", "method": "\u9996\u5148\u7406\u8bba\u5206\u6790\u8868\u660e\u5206\u652f\u8986\u76d6\u3001\u6837\u672c\u96be\u5ea6\u3001\u8bed\u6cd5\u548c\u529f\u80fd\u6b63\u786e\u6027\u53ef\u4ee5\u8054\u5408\u5efa\u6a21\u4e3aRL\u5956\u52b1\u3002\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86\u8bed\u6cd5\u548c\u529f\u80fd\u611f\u77e5\u7684\u5956\u52b1\uff0c\u5e76\u8fdb\u4e00\u6b65\u63d0\u51fa\u5206\u652f\u548c\u6837\u672c\u96be\u5ea6\u611f\u77e5\u7684RL\u65b9\u6cd5\uff0c\u91c7\u7528\u6307\u6570\u5956\u52b1\u5851\u9020\u548c\u9759\u6001\u5206\u6790\u6307\u6807\u3002", "result": "CVeDRL\u4ec5\u75280.6B\u53c2\u6570\u5c31\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u76f8\u6bd4GPT-3.5\u5b9e\u73b0\u4e86\u9ad8\u8fbe28.97%\u7684\u901a\u8fc7\u7387\u63d0\u5347\u548c15.08%\u7684\u5206\u652f\u8986\u76d6\u7387\u63d0\u5347\uff0c\u540c\u65f6\u63a8\u7406\u901f\u5ea6\u6bd4\u7ade\u4e89\u57fa\u7ebf\u5feb20\u500d\u4ee5\u4e0a\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5206\u652f\u8986\u76d6\u3001\u6837\u672c\u96be\u5ea6\u3001\u8bed\u6cd5\u548c\u529f\u80fd\u6b63\u786e\u6027\u8054\u5408\u5efa\u6a21\u4e3aRL\u5956\u52b1\uff0cCVeDRL\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u5355\u5143\u6d4b\u8bd5\u7684\u4ee3\u7801\u9a8c\u8bc1\u7684\u53ef\u9760\u6027\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2601.22997", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22997", "abs": "https://arxiv.org/abs/2601.22997", "authors": ["Roham Koohestani", "Ate\u015f G\u00f6rpelio\u011flu", "Egor Klimov", "Burcu Kulahcioglu Ozkan", "Maliheh Izadi"], "title": "TriCEGAR: A Trace-Driven Abstraction Mechanism for Agentic AI", "comment": null, "summary": "Agentic AI systems act through tools and evolve their behavior over long, stochastic interaction traces. This setting complicates assurance, because behavior depends on nondeterministic environments and probabilistic model outputs. Prior work introduced runtime verification for agentic AI via Dynamic Probabilistic Assurance (DPA), learning an MDP online and model checking quantitative properties. A key limitation is that developers must manually define the state abstraction, which couples verification to application-specific heuristics and increases adoption friction. This paper proposes TriCEGAR, a trace-driven abstraction mechanism that automates state construction from execution logs and supports online construction of an agent behavioral MDP. TriCEGAR represents abstractions as predicate trees learned from traces and refined using counterexamples. We describe a framework-native implementation that (i) captures typed agent lifecycle events, (ii) builds abstractions from traces, (iii) constructs an MDP, and (iv) performs probabilistic model checking to compute bounds such as Pmax(success) and Pmin(failure). We also show how run likelihoods enable anomaly detection as a guardrailing signal.", "AI": {"tldr": "TriCEGAR\uff1a\u4e00\u79cd\u57fa\u4e8e\u6267\u884c\u65e5\u5fd7\u81ea\u52a8\u6784\u5efa\u72b6\u6001\u62bd\u8c61\u7684\u673a\u5236\uff0c\u7528\u4e8e\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7684\u8fd0\u884c\u65f6\u9a8c\u8bc1\uff0c\u65e0\u9700\u624b\u52a8\u5b9a\u4e49\u72b6\u6001\u62bd\u8c61", "motivation": "\u667a\u80fd\u4f53AI\u7cfb\u7edf\u901a\u8fc7\u5de5\u5177\u884c\u52a8\uff0c\u884c\u4e3a\u5728\u957f\u671f\u968f\u673a\u4ea4\u4e92\u8f68\u8ff9\u4e2d\u6f14\u5316\uff0c\u8fd9\u4f7f\u5f97\u4fdd\u8bc1\u53d8\u5f97\u590d\u6742\u3002\u73b0\u6709\u52a8\u6001\u6982\u7387\u4fdd\u8bc1\uff08DPA\uff09\u65b9\u6cd5\u9700\u8981\u5f00\u53d1\u8005\u624b\u52a8\u5b9a\u4e49\u72b6\u6001\u62bd\u8c61\uff0c\u8fd9\u589e\u52a0\u4e86\u91c7\u7528\u6469\u64e6\u5e76\u8026\u5408\u5230\u5e94\u7528\u7279\u5b9a\u542f\u53d1\u5f0f\u65b9\u6cd5", "method": "\u63d0\u51faTriCEGAR\u673a\u5236\uff0c\u4ece\u6267\u884c\u65e5\u5fd7\u81ea\u52a8\u6784\u5efa\u72b6\u6001\u62bd\u8c61\uff0c\u4f7f\u7528\u8c13\u8bcd\u6811\u8868\u793a\u62bd\u8c61\u5e76\u901a\u8fc7\u53cd\u4f8b\u8fdb\u884c\u7ec6\u5316\u3002\u5b9e\u73b0\u6846\u67b6\u539f\u751f\u5b9e\u73b0\uff0c\u5305\u62ec\uff1a\u6355\u83b7\u7c7b\u578b\u5316\u667a\u80fd\u4f53\u751f\u547d\u5468\u671f\u4e8b\u4ef6\u3001\u4ece\u8f68\u8ff9\u6784\u5efa\u62bd\u8c61\u3001\u6784\u5efaMDP\u3001\u6267\u884c\u6982\u7387\u6a21\u578b\u68c0\u67e5", "result": "TriCEGAR\u80fd\u591f\u81ea\u52a8\u6784\u5efa\u667a\u80fd\u4f53\u884c\u4e3aMDP\uff0c\u652f\u6301\u5728\u7ebf\u6784\u5efa\uff0c\u5e76\u8ba1\u7b97\u6982\u7387\u8fb9\u754c\u5982Pmax(\u6210\u529f)\u548cPmin(\u5931\u8d25)\u3002\u8fd0\u884c\u4f3c\u7136\u6027\u8fd8\u652f\u6301\u5f02\u5e38\u68c0\u6d4b\u4f5c\u4e3a\u62a4\u680f\u4fe1\u53f7", "conclusion": "TriCEGAR\u901a\u8fc7\u81ea\u52a8\u5316\u72b6\u6001\u62bd\u8c61\u6784\u5efa\uff0c\u89e3\u51b3\u4e86\u73b0\u6709DPA\u65b9\u6cd5\u7684\u5173\u952e\u9650\u5236\uff0c\u964d\u4f4e\u4e86\u667a\u80fd\u4f53AI\u7cfb\u7edf\u8fd0\u884c\u65f6\u9a8c\u8bc1\u7684\u91c7\u7528\u95e8\u69db"}}
{"id": "2601.22806", "categories": ["cs.AI", "math.DG"], "pdf": "https://arxiv.org/pdf/2601.22806", "abs": "https://arxiv.org/abs/2601.22806", "authors": ["Aldric Labarthe", "Roland Bouffanais", "Julien Randon-Furling"], "title": "Aligning the Unseen in Attributed Graphs: Interplay between Graph Geometry and Node Attributes Manifold", "comment": null, "summary": "The standard approach to representation learning on attributed graphs -- i.e., simultaneously reconstructing node attributes and graph structure -- is geometrically flawed, as it merges two potentially incompatible metric spaces. This forces a destructive alignment that erodes information about the graph's underlying generative process. To recover this lost signal, we introduce a custom variational autoencoder that separates manifold learning from structural alignment. By quantifying the metric distortion needed to map the attribute manifold onto the graph's Heat Kernel, we transform geometric conflict into an interpretable structural descriptor. Experiments show our method uncovers connectivity patterns and anomalies undetectable by conventional approaches, proving both their theoretical inadequacy and practical limitations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u4f20\u7edf\u5c5e\u6027\u56fe\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u51e0\u4f55\u7f3a\u9677\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u79bb\u6d41\u5f62\u5b66\u4e60\u4e0e\u7ed3\u6784\u5bf9\u9f50\u7684\u81ea\u5b9a\u4e49\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u91cf\u5316\u5ea6\u91cf\u626d\u66f2\u6765\u63ed\u793a\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u68c0\u6d4b\u7684\u8fde\u63a5\u6a21\u5f0f\u548c\u5f02\u5e38\u3002", "motivation": "\u4f20\u7edf\u5c5e\u6027\u56fe\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u540c\u65f6\u91cd\u5efa\u8282\u70b9\u5c5e\u6027\u548c\u56fe\u7ed3\u6784\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5728\u51e0\u4f55\u4e0a\u5b58\u5728\u7f3a\u9677\uff0c\u56e0\u4e3a\u5b83\u5408\u5e76\u4e86\u4e24\u4e2a\u53ef\u80fd\u4e0d\u517c\u5bb9\u7684\u5ea6\u91cf\u7a7a\u95f4\uff0c\u5bfc\u81f4\u7834\u574f\u6027\u7684\u5bf9\u9f50\uff0c\u4ece\u800c\u4fb5\u8680\u4e86\u5173\u4e8e\u56fe\u5e95\u5c42\u751f\u6210\u8fc7\u7a0b\u7684\u4fe1\u606f\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u81ea\u5b9a\u4e49\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff0c\u5c06\u6d41\u5f62\u5b66\u4e60\u4e0e\u7ed3\u6784\u5bf9\u9f50\u5206\u79bb\u3002\u901a\u8fc7\u91cf\u5316\u5c06\u5c5e\u6027\u6d41\u5f62\u6620\u5c04\u5230\u56fe\u70ed\u6838\u6240\u9700\u7684\u5ea6\u91cf\u626d\u66f2\uff0c\u5c06\u51e0\u4f55\u51b2\u7a81\u8f6c\u5316\u4e3a\u53ef\u89e3\u91ca\u7684\u7ed3\u6784\u63cf\u8ff0\u7b26\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u53d1\u73b0\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u68c0\u6d4b\u7684\u8fde\u63a5\u6a21\u5f0f\u548c\u5f02\u5e38\uff0c\u8bc1\u660e\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u7406\u8bba\u4e0a\u7684\u4e0d\u8db3\u548c\u5b9e\u8df5\u4e0a\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u901a\u8fc7\u5206\u79bb\u6d41\u5f62\u5b66\u4e60\u548c\u7ed3\u6784\u5bf9\u9f50\uff0c\u5e76\u91cf\u5316\u5ea6\u91cf\u626d\u66f2\uff0c\u53ef\u4ee5\u6062\u590d\u4f20\u7edf\u65b9\u6cd5\u4e22\u5931\u7684\u4fe1\u53f7\uff0c\u4e3a\u5c5e\u6027\u56fe\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u66f4\u51c6\u786e\u548c\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.22896", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22896", "abs": "https://arxiv.org/abs/2601.22896", "authors": ["Xinyi Ke", "Kai Li", "Junliang Xing", "Yifan Zhang", "Jian Cheng"], "title": "Game-Theoretic Co-Evolution for LLM-Based Heuristic Discovery", "comment": null, "summary": "Large language models (LLMs) have enabled rapid progress in automatic heuristic discovery (AHD), yet most existing methods are predominantly limited by static evaluation against fixed instance distributions, leading to potential overfitting and poor generalization under distributional shifts. We propose Algorithm Space Response Oracles (ASRO), a game-theoretic framework that reframes heuristic discovery as a program level co-evolution between solver and instance generator. ASRO models their interaction as a two-player zero-sum game, maintains growing strategy pools on both sides, and iteratively expands them via LLM-based best-response oracles against mixed opponent meta-strategies, thereby replacing static evaluation with an adaptive, self-generated curriculum. Across multiple combinatorial optimization domains, ASRO consistently outperforms static-training AHD baselines built on the same program search mechanisms, achieving substantially improved generalization and robustness on diverse and out-of-distribution instances.", "AI": {"tldr": "ASRO\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u7b97\u6cd5\u7a7a\u95f4\u54cd\u5e94\u9884\u8a00\u6846\u67b6\uff0c\u5c06\u542f\u53d1\u5f0f\u53d1\u73b0\u91cd\u6784\u4e3a\u6c42\u89e3\u5668\u4e0e\u5b9e\u4f8b\u751f\u6210\u5668\u4e4b\u95f4\u7684\u7a0b\u5e8f\u7ea7\u534f\u540c\u8fdb\u5316\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684\u54cd\u5e94\u9884\u8a00\u5b9e\u73b0\u81ea\u9002\u5e94\u8bfe\u7a0b\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u53d1\u73b0\u65b9\u6cd5\u4e3b\u8981\u5c40\u9650\u4e8e\u5bf9\u56fa\u5b9a\u5b9e\u4f8b\u5206\u5e03\u7684\u9759\u6001\u8bc4\u4f30\uff0c\u5bb9\u6613\u5bfc\u81f4\u8fc7\u62df\u5408\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u5dee\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u9002\u5e94\u3001\u907f\u514d\u9759\u6001\u8bc4\u4f30\u5c40\u9650\u6027\u7684\u6846\u67b6\u3002", "method": "ASRO\u5c06\u542f\u53d1\u5f0f\u53d1\u73b0\u5efa\u6a21\u4e3a\u53cc\u4eba\u96f6\u548c\u535a\u5f08\uff0c\u7ef4\u62a4\u6c42\u89e3\u5668\u548c\u5b9e\u4f8b\u751f\u6210\u5668\u53cc\u65b9\u4e0d\u65ad\u589e\u957f\u7684\u6218\u7565\u6c60\uff0c\u901a\u8fc7\u57fa\u4e8eLLM\u7684\u6700\u4f73\u54cd\u5e94\u9884\u8a00\u8fed\u4ee3\u6269\u5c55\u53cc\u65b9\u7b56\u7565\uff0c\u4f7f\u7528\u6df7\u5408\u5bf9\u624b\u5143\u7b56\u7565\u66ff\u4ee3\u9759\u6001\u8bc4\u4f30\uff0c\u5f62\u6210\u81ea\u9002\u5e94\u7684\u81ea\u751f\u6210\u8bfe\u7a0b\u3002", "result": "\u5728\u591a\u4e2a\u7ec4\u5408\u4f18\u5316\u9886\u57df\u4e2d\uff0cASRO\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8e\u76f8\u540c\u7a0b\u5e8f\u641c\u7d22\u673a\u5236\u7684\u9759\u6001\u8bad\u7ec3\u57fa\u51c6\u65b9\u6cd5\uff0c\u5728\u591a\u6837\u5316\u548c\u5206\u5e03\u5916\u5b9e\u4f8b\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u8fdb\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "ASRO\u901a\u8fc7\u535a\u5f08\u8bba\u6846\u67b6\u5c06\u542f\u53d1\u5f0f\u53d1\u73b0\u91cd\u6784\u4e3a\u534f\u540c\u8fdb\u5316\u8fc7\u7a0b\uff0c\u5229\u7528LLM\u9a71\u52a8\u7684\u54cd\u5e94\u9884\u8a00\u5b9e\u73b0\u81ea\u9002\u5e94\u8bfe\u7a0b\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9759\u6001\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u81ea\u52a8\u542f\u53d1\u5f0f\u53d1\u73b0\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.22900", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22900", "abs": "https://arxiv.org/abs/2601.22900", "authors": ["Xuancheng Li", "Haitao Li", "Yujia Zhou", "YiqunLiu", "Qingyao Ai"], "title": "MulFeRL: Enhancing Reinforcement Learning with Verbal Feedback in a Multi-turn Loop", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is widely used to improve reasoning in multiple domains, yet outcome-only scalar rewards are often sparse and uninformative, especially on failed samples, where they merely indicate failure and provide no insight into why the reasoning fails. In this paper, we investigate how to leverage richer verbal feedback to guide RLVR training on failed samples, and how to convert such feedback into a trainable learning signal. Specifically, we propose a multi-turn feedback-guided reinforcement learning framework. It builds on three mechanisms: (1) dynamic multi-turn regeneration guided by feedback, triggered only on failed samples, (2) two complementary learning signals for within-turn and cross-turn optimization, and (3) structured feedback injection into the model's reasoning process. Trained on sampled OpenR1-Math, the approach outperforms supervised fine-tuning and RLVR baselines in-domain and generalizes well out-of-domain.", "AI": {"tldr": "\u63d0\u51fa\u591a\u8f6e\u53cd\u9988\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u591a\u8f6e\u751f\u6210\u3001\u53cc\u91cd\u5b66\u4e60\u4fe1\u53f7\u548c\u7ed3\u6784\u5316\u53cd\u9988\u6ce8\u5165\uff0c\u89e3\u51b3\u4f20\u7edfRLVR\u4e2d\u7a00\u758f\u5956\u52b1\u95ee\u9898\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u5728\u5931\u8d25\u6837\u672c\u4e0a\u4ec5\u63d0\u4f9b\u7a00\u758f\u7684\u6807\u91cf\u5956\u52b1\uff0c\u65e0\u6cd5\u89e3\u91ca\u63a8\u7406\u5931\u8d25\u539f\u56e0\uff0c\u9650\u5236\u4e86\u5b66\u4e60\u6548\u679c", "method": "\u63d0\u51fa\u591a\u8f6e\u53cd\u9988\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u673a\u5236\uff1a1\uff09\u4ec5\u5728\u5931\u8d25\u6837\u672c\u4e0a\u89e6\u53d1\u7684\u52a8\u6001\u591a\u8f6e\u53cd\u9988\u5f15\u5bfc\u751f\u6210\uff1b2\uff09\u7528\u4e8e\u8f6e\u5185\u548c\u8de8\u8f6e\u4f18\u5316\u7684\u53cc\u91cd\u4e92\u8865\u5b66\u4e60\u4fe1\u53f7\uff1b3\uff09\u7ed3\u6784\u5316\u53cd\u9988\u6ce8\u5165\u5230\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b", "result": "\u5728OpenR1-Math\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u8be5\u65b9\u6cd5\u5728\u9886\u57df\u5185\u8868\u73b0\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u548cRLVR\u57fa\u7ebf\uff0c\u5e76\u5728\u9886\u57df\u5916\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b", "conclusion": "\u901a\u8fc7\u5229\u7528\u4e30\u5bcc\u7684\u8bed\u8a00\u53cd\u9988\u6307\u5bfcRLVR\u8bad\u7ec3\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5931\u8d25\u6837\u672c\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2601.22948", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22948", "abs": "https://arxiv.org/abs/2601.22948", "authors": ["Nicola Milano", "Stefano Nolfi"], "title": "Alignment among Language, Vision and Action Representations", "comment": null, "summary": "A fundamental question in cognitive science and AI concerns whether different learning modalities: language, vision, and action, give rise to distinct or shared internal representations. Traditional views assume that models trained on different data types develop specialized, non-transferable representations. However, recent evidence suggests unexpected convergence: models optimized for distinct tasks may develop similar representational geometries. We investigate whether this convergence extends to embodied action learning by training a transformer-based agent to execute goal-directed behaviors in response to natural language instructions. Using behavioral cloning on the BabyAI platform, we generated action-grounded language embeddings shaped exclusively by sensorimotor control requirements. We then compared these representations with those extracted from state-of-the-art large language models (LLaMA, Qwen, DeepSeek, BERT) and vision-language models (CLIP, BLIP). Despite substantial differences in training data, modality, and objectives, we observed robust cross-modal alignment. Action representations aligned strongly with decoder-only language models and BLIP (precision@15: 0.70-0.73), approaching the alignment observed among language models themselves. Alignment with CLIP and BERT was significantly weaker. These findings indicate that linguistic, visual, and action representations converge toward partially shared semantic structures, supporting modality-independent semantic organization and highlighting potential for cross-domain transfer in embodied AI systems.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bed\u8a00\u3001\u89c6\u89c9\u548c\u52a8\u4f5c\u5b66\u4e60\u4f1a\u4ea7\u751f\u90e8\u5206\u5171\u4eab\u7684\u8bed\u4e49\u8868\u793a\uff0c\u652f\u6301\u8de8\u6a21\u6001\u7684\u8bed\u4e49\u7ec4\u7ec7", "motivation": "\u63a2\u7d22\u4e0d\u540c\u5b66\u4e60\u6a21\u6001\uff08\u8bed\u8a00\u3001\u89c6\u89c9\u3001\u52a8\u4f5c\uff09\u662f\u5426\u4ea7\u751f\u72ec\u7279\u6216\u5171\u4eab\u7684\u5185\u90e8\u8868\u793a\uff0c\u6311\u6218\u4f20\u7edf\u8ba4\u4e3a\u4e0d\u540c\u6570\u636e\u7c7b\u578b\u7684\u6a21\u578b\u4f1a\u53d1\u5c55\u4e13\u95e8\u5316\u3001\u4e0d\u53ef\u8f6c\u79fb\u8868\u793a\u7684\u89c2\u70b9", "method": "\u5728BabyAI\u5e73\u53f0\u4e0a\u8bad\u7ec3\u57fa\u4e8etransformer\u7684\u667a\u80fd\u4f53\u6267\u884c\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\uff0c\u751f\u6210\u52a8\u4f5c\u57fa\u7840\u7684\u8bed\u8a00\u5d4c\u5165\uff0c\u7136\u540e\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLaMA\u3001Qwen\u3001DeepSeek\u3001BERT\uff09\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08CLIP\u3001BLIP\uff09\u7684\u8868\u793a\u8fdb\u884c\u6bd4\u8f83", "result": "\u52a8\u4f5c\u8868\u793a\u4e0e\u4ec5\u89e3\u7801\u5668\u8bed\u8a00\u6a21\u578b\u548cBLIP\u5f3a\u70c8\u5bf9\u9f50\uff08\u7cbe\u5ea6@15\uff1a0.70-0.73\uff09\uff0c\u63a5\u8fd1\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u4f46\u4e0eCLIP\u548cBERT\u7684\u5bf9\u9f50\u663e\u8457\u8f83\u5f31", "conclusion": "\u8bed\u8a00\u3001\u89c6\u89c9\u548c\u52a8\u4f5c\u8868\u793a\u6536\u655b\u4e8e\u90e8\u5206\u5171\u4eab\u7684\u8bed\u4e49\u7ed3\u6784\uff0c\u652f\u6301\u6a21\u6001\u72ec\u7acb\u7684\u8bed\u4e49\u7ec4\u7ec7\uff0c\u7a81\u663e\u4e86\u5728\u5177\u8eabAI\u7cfb\u7edf\u4e2d\u8de8\u9886\u57df\u8f6c\u79fb\u7684\u6f5c\u529b"}}
{"id": "2601.22977", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22977", "abs": "https://arxiv.org/abs/2601.22977", "authors": ["Lei You"], "title": "Quantifying Model Uniqueness in Heterogeneous AI Ecosystems", "comment": null, "summary": "As AI systems evolve from isolated predictors into complex, heterogeneous ecosystems of foundation models and specialized adapters, distinguishing genuine behavioral novelty from functional redundancy becomes a critical governance challenge. Here, we introduce a statistical framework for auditing model uniqueness based on In-Silico Quasi-Experimental Design (ISQED). By enforcing matched interventions across models, we isolate intrinsic model identity and quantify uniqueness as the Peer-Inexpressible Residual (PIER), i.e. the component of a target's behavior strictly irreducible to any stochastic convex combination of its peers, with vanishing PIER characterizing when such a routing-based substitution becomes possible. We establish the theoretical foundations of ecosystem auditing through three key contributions. First, we prove a fundamental limitation of observational logs: uniqueness is mathematically non-identifiable without intervention control. Second, we derive a scaling law for active auditing, showing that our adaptive query protocol achieves minimax-optimal sample efficiency ($d\u03c3^2\u03b3^{-2}\\log(Nd/\u03b4)$). Third, we demonstrate that cooperative game-theoretic methods, such as Shapley values, fundamentally fail to detect redundancy. We implement this framework via the DISCO (Design-Integrated Synthetic Control) estimator and deploy it across diverse ecosystems, including computer vision models (ResNet/ConvNeXt/ViT), large language models (BERT/RoBERTa), and city-scale traffic forecasters. These results move trustworthy AI beyond explaining single models: they establish a principled, intervention-based science of auditing and governing heterogeneous model ecosystems.", "AI": {"tldr": "\u63d0\u51faISQED\u7edf\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5339\u914d\u5e72\u9884\u91cf\u5316\u6a21\u578b\u72ec\u7279\u6027\uff08PIER\uff09\uff0c\u8bc1\u660e\u89c2\u6d4b\u65e5\u5fd7\u65e0\u6cd5\u8bc6\u522b\u72ec\u7279\u6027\uff0c\u63a8\u5bfc\u4e3b\u52a8\u5ba1\u8ba1\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u5c55\u793a\u5408\u4f5c\u535a\u5f08\u65b9\u6cd5\u65e0\u6cd5\u68c0\u6d4b\u5197\u4f59", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u4ece\u5b64\u7acb\u9884\u6d4b\u5668\u6f14\u53d8\u4e3a\u590d\u6742\u7684\u5f02\u6784\u751f\u6001\u7cfb\u7edf\uff0c\u533a\u5206\u771f\u6b63\u7684\u884c\u4e3a\u65b0\u9896\u6027\u4e0e\u529f\u80fd\u5197\u4f59\u6210\u4e3a\u5173\u952e\u6cbb\u7406\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u539f\u5219\u6027\u7684\u5ba1\u8ba1\u6846\u67b6", "method": "\u5f15\u5165In-Silico Quasi-Experimental Design (ISQED)\u6846\u67b6\uff0c\u901a\u8fc7\u5339\u914d\u5e72\u9884\u9694\u79bb\u5185\u5728\u6a21\u578b\u8eab\u4efd\uff0c\u91cf\u5316Peer-Inexpressible Residual (PIER)\uff0c\u4f7f\u7528DISCO\u4f30\u8ba1\u5668\u5b9e\u73b0\uff0c\u5e76\u63a8\u5bfc\u4e3b\u52a8\u5ba1\u8ba1\u7684\u7f29\u653e\u5b9a\u5f8b", "result": "\u8bc1\u660e\u89c2\u6d4b\u65e5\u5fd7\u65e0\u6cd5\u6570\u5b66\u8bc6\u522b\u72ec\u7279\u6027\uff0c\u63a8\u5bfc\u51fa\u6700\u5c0f\u6700\u5927\u6700\u4f18\u6837\u672c\u6548\u7387\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u5c55\u793aShapley\u503c\u7b49\u5408\u4f5c\u535a\u5f08\u65b9\u6cd5\u65e0\u6cd5\u68c0\u6d4b\u5197\u4f59\uff0c\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u8bed\u8a00\u6a21\u578b\u548c\u4ea4\u901a\u9884\u6d4b\u7b49\u591a\u6837\u5316\u751f\u6001\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\u6846\u67b6", "conclusion": "\u8be5\u7814\u7a76\u5c06\u53ef\u4fe1AI\u4ece\u89e3\u91ca\u5355\u4e00\u6a21\u578b\u6269\u5c55\u5230\u5efa\u7acb\u57fa\u4e8e\u5e72\u9884\u7684\u5f02\u6784\u6a21\u578b\u751f\u6001\u7cfb\u7edf\u5ba1\u8ba1\u79d1\u5b66\uff0c\u4e3aAI\u6cbb\u7406\u63d0\u4f9b\u539f\u5219\u6027\u6846\u67b6"}}
{"id": "2601.22984", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22984", "abs": "https://arxiv.org/abs/2601.22984", "authors": ["Yuhao Zhan", "Tianyu Fan", "Linxuan Huang", "Zirui Guo", "Chao Huang"], "title": "Why Your Deep Research Agent Fails? On Hallucination Evaluation in Full Research Trajectory", "comment": null, "summary": "Diagnosing the failure mechanisms of Deep Research Agents (DRAs) remains a critical challenge. Existing benchmarks predominantly rely on end-to-end evaluation, obscuring critical intermediate hallucinations, such as flawed planning, that accumulate throughout the research trajectory. To bridge this gap, we propose a shift from outcome-based to process-aware evaluation by auditing the full research trajectory. We introduce the PIES Taxonomy to categorize hallucinations along functional components (Planning vs. Summarization) and error properties (Explicit vs. Implicit). We instantiate this taxonomy into a fine-grained evaluation framework that decomposes the trajectory to rigorously quantify these hallucinations. Leveraging this framework to isolate 100 distinctively hallucination-prone tasks including adversarial scenarios, we curate DeepHalluBench. Experiments on six state-of-theart DRAs reveal that no system achieves robust reliability. Furthermore, our diagnostic analysis traces the etiology of these failures to systemic deficits, specifically hallucination propagation and cognitive biases, providing foundational insights to guide future architectural optimization. Data and code are available at https://github.com/yuhao-zhan/DeepHalluBench.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u7ed3\u679c\u5bfc\u5411\u8bc4\u4f30\u8f6c\u5411\u8fc7\u7a0b\u611f\u77e5\u8bc4\u4f30\uff0c\u901a\u8fc7\u5ba1\u8ba1\u5b8c\u6574\u7814\u7a76\u8f68\u8ff9\u6765\u8bca\u65ad\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\uff08DRAs\uff09\u7684\u5931\u8d25\u673a\u5236\uff0c\u5f15\u5165PIES\u5206\u7c7b\u6cd5\u5bf9\u5e7b\u89c9\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u6784\u5efaDeepHalluBench\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u4f9d\u8d56\u7aef\u5230\u7aef\u8bc4\u4f30\uff0c\u63a9\u76d6\u4e86\u7814\u7a76\u8f68\u8ff9\u4e2d\u79ef\u7d2f\u7684\u5173\u952e\u4e2d\u95f4\u5e7b\u89c9\uff08\u5982\u9519\u8bef\u89c4\u5212\uff09\uff0c\u96be\u4ee5\u8bca\u65ad\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u7684\u5931\u8d25\u673a\u5236\u3002", "method": "\u63d0\u51faPIES\u5206\u7c7b\u6cd5\uff0c\u6309\u529f\u80fd\u7ec4\u4ef6\uff08\u89c4\u5212vs\u603b\u7ed3\uff09\u548c\u9519\u8bef\u5c5e\u6027\uff08\u663e\u5f0fvs\u9690\u5f0f\uff09\u5bf9\u5e7b\u89c9\u8fdb\u884c\u5206\u7c7b\uff1b\u5f00\u53d1\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6846\u67b6\u5206\u89e3\u7814\u7a76\u8f68\u8ff9\u4ee5\u91cf\u5316\u8fd9\u4e9b\u5e7b\u89c9\uff1b\u6784\u5efa\u5305\u542b100\u4e2a\u5e7b\u89c9\u6613\u53d1\u4efb\u52a1\u7684DeepHalluBench\u57fa\u51c6\u3002", "result": "\u5728\u516d\u4e2a\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u6ca1\u6709\u7cfb\u7edf\u80fd\u5b9e\u73b0\u7a33\u5065\u7684\u53ef\u9760\u6027\uff1b\u8bca\u65ad\u5206\u6790\u5c06\u5931\u8d25\u539f\u56e0\u8ffd\u6eaf\u5230\u7cfb\u7edf\u6027\u7f3a\u9677\uff0c\u7279\u522b\u662f\u5e7b\u89c9\u4f20\u64ad\u548c\u8ba4\u77e5\u504f\u5dee\u3002", "conclusion": "\u8fc7\u7a0b\u611f\u77e5\u8bc4\u4f30\u80fd\u66f4\u7cbe\u786e\u8bca\u65ad\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u7684\u5931\u8d25\u673a\u5236\uff0c\u4e3a\u672a\u6765\u67b6\u6784\u4f18\u5316\u63d0\u4f9b\u57fa\u7840\u6027\u89c1\u89e3\uff0cPIES\u5206\u7c7b\u6cd5\u548cDeepHalluBench\u57fa\u51c6\u4e3a\u7cfb\u7edf\u53ef\u9760\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\u3002"}}
{"id": "2601.23032", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23032", "abs": "https://arxiv.org/abs/2601.23032", "authors": ["Siyu Gong", "Linan Yue", "Weibo Gao", "Fangzhou Yao", "Shimin Di", "Lei Feng", "Min-Ling Zhang"], "title": "Guided by Trajectories: Repairing and Rewarding Tool-Use Trajectories for Tool-Integrated Reasoning", "comment": null, "summary": "Tool-Integrated Reasoning (TIR) enables large language models (LLMs) to solve complex tasks by interacting with external tools, yet existing approaches depend on high-quality synthesized trajectories selected by scoring functions and sparse outcome-based rewards, providing limited and biased supervision for learning TIR. To address these challenges, in this paper, we propose AutoTraj, a two-stage framework that automatically learns TIR by repairing and rewarding tool-use trajectories. Specifically, in the supervised fine-tuning (SFT) stage, AutoTraj generates multiple candidate tool-use trajectories for each query and evaluates them along multiple dimensions. High-quality trajectories are directly retained, while low-quality ones are repaired using a LLM (i.e., LLM-as-Repairer). The resulting repaired and high-quality trajectories form a synthetic SFT dataset, while each repaired trajectory paired with its original low-quality counterpart constitutes a dataset for trajectory preference modeling. In the reinforcement learning (RL) stage, based on the preference dataset, we train a trajectory-level reward model to assess the quality of reasoning paths and combine it with outcome and format rewards, thereby explicitly guiding the optimization toward reliable TIR behaviors. Experiments on real-world benchmarks demonstrate the effectiveness of AutoTraj in TIR.", "AI": {"tldr": "AutoTraj\uff1a\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u4fee\u590d\u548c\u5956\u52b1\u5de5\u5177\u4f7f\u7528\u8f68\u8ff9\u6765\u81ea\u52a8\u5b66\u4e60\u5de5\u5177\u96c6\u6210\u63a8\u7406\uff0c\u65e0\u9700\u4f9d\u8d56\u9ad8\u8d28\u91cf\u5408\u6210\u8f68\u8ff9", "motivation": "\u73b0\u6709\u5de5\u5177\u96c6\u6210\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u9ad8\u8d28\u91cf\u5408\u6210\u8f68\u8ff9\u548c\u7a00\u758f\u7ed3\u679c\u5956\u52b1\uff0c\u63d0\u4f9b\u6709\u9650\u4e14\u6709\u504f\u7684\u76d1\u7763\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5b66\u4e60\u6846\u67b6", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u76d1\u7763\u5fae\u8c03\u9636\u6bb5\u751f\u6210\u591a\u4e2a\u5019\u9009\u8f68\u8ff9\uff0c\u8bc4\u4f30\u540e\u4fdd\u7559\u9ad8\u8d28\u91cf\u8f68\u8ff9\uff0c\u4fee\u590d\u4f4e\u8d28\u91cf\u8f68\u8ff9\uff1b2\uff09\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\u57fa\u4e8e\u504f\u597d\u6570\u636e\u96c6\u8bad\u7ec3\u8f68\u8ff9\u7ea7\u5956\u52b1\u6a21\u578b\uff0c\u7ed3\u5408\u7ed3\u679c\u548c\u683c\u5f0f\u5956\u52b1", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc1\u660e\u4e86AutoTraj\u5728\u5de5\u5177\u96c6\u6210\u63a8\u7406\u4e2d\u7684\u6709\u6548\u6027", "conclusion": "AutoTraj\u901a\u8fc7\u81ea\u52a8\u4fee\u590d\u548c\u5956\u52b1\u5de5\u5177\u4f7f\u7528\u8f68\u8ff9\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u96c6\u6210\u63a8\u7406\u65b9\u6cd5\u7684\u76d1\u7763\u4e0d\u8db3\u95ee\u9898"}}
{"id": "2601.23045", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23045", "abs": "https://arxiv.org/abs/2601.23045", "authors": ["Alexander H\u00e4gele", "Aryo Pradipta Gema", "Henry Sleight", "Ethan Perez", "Jascha Sohl-Dickstein"], "title": "The Hot Mess of AI: How Does Misalignment Scale With Model Intelligence and Task Complexity?", "comment": "ICLR 2026", "summary": "As AI becomes more capable, we entrust it with more general and consequential tasks. The risks from failure grow more severe with increasing task scope. It is therefore important to understand how extremely capable AI models will fail: Will they fail by systematically pursuing goals we do not intend? Or will they fail by being a hot mess, and taking nonsensical actions that do not further any goal? We operationalize this question using a bias-variance decomposition of the errors made by AI models: An AI's \\emph{incoherence} on a task is measured over test-time randomness as the fraction of its error that stems from variance rather than bias in task outcome. Across all tasks and frontier models we measure, the longer models spend reasoning and taking actions, \\emph{the more incoherent} their failures become. Incoherence changes with model scale in a way that is experiment dependent. However, in several settings, larger, more capable models are more incoherent than smaller models. Consequently, scale alone seems unlikely to eliminate incoherence. Instead, as more capable AIs pursue harder tasks, requiring more sequential action and thought, our results predict failures to be accompanied by more incoherent behavior. This suggests a future where AIs sometimes cause industrial accidents (due to unpredictable misbehavior), but are less likely to exhibit consistent pursuit of a misaligned goal. This increases the relative importance of alignment research targeting reward hacking or goal misspecification.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u968f\u7740AI\u80fd\u529b\u589e\u5f3a\uff0c\u5176\u5931\u8d25\u884c\u4e3a\u66f4\u503e\u5411\u4e8e\"\u6df7\u4e71\"\u800c\u975e\"\u7cfb\u7edf\u6027\u76ee\u6807\u8ffd\u6c42\"\uff0c\u8fd9\u5f71\u54cd\u4e86AI\u5b89\u5168\u7814\u7a76\u7684\u65b9\u5411", "motivation": "\u968f\u7740AI\u627f\u62c5\u66f4\u5e7f\u6cdb\u548c\u91cd\u8981\u7684\u4efb\u52a1\uff0c\u7406\u89e3\u5176\u5931\u8d25\u6a21\u5f0f\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff1a\u662f\u7cfb\u7edf\u6027\u5730\u8ffd\u6c42\u9519\u8bef\u76ee\u6807\uff0c\u8fd8\u662f\u91c7\u53d6\u65e0\u610f\u4e49\u7684\u6df7\u4e71\u884c\u4e3a\uff1f\u8fd9\u5173\u7cfb\u5230AI\u5b89\u5168\u7814\u7a76\u7684\u65b9\u5411\u9009\u62e9\u3002", "method": "\u4f7f\u7528\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\u6765\u91cf\u5316AI\u7684\"\u4e0d\u8fde\u8d2f\u6027\"\uff0c\u6d4b\u91cf\u6a21\u578b\u9519\u8bef\u4e2d\u65b9\u5dee\u800c\u975e\u504f\u5dee\u7684\u6bd4\u4f8b\u3002\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u524d\u6cbf\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5206\u6790\u63a8\u7406\u65f6\u95f4\u548c\u6a21\u578b\u89c4\u6a21\u5bf9\u4e0d\u8fde\u8d2f\u6027\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u578b\u63a8\u7406\u65f6\u95f4\u8d8a\u957f\uff0c\u5176\u5931\u8d25\u884c\u4e3a\u8d8a\u4e0d\u8fde\u8d2f\uff1b\u6a21\u578b\u89c4\u6a21\u5bf9\u4e0d\u8fde\u8d2f\u6027\u7684\u5f71\u54cd\u56e0\u5b9e\u9a8c\u800c\u5f02\uff0c\u4f46\u5728\u591a\u4e2a\u8bbe\u7f6e\u4e2d\uff0c\u66f4\u5927\u3001\u66f4\u5f3a\u7684\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u4e0d\u8fde\u8d2f\u6027\u3002\u4ec5\u9760\u89c4\u6a21\u6269\u5c55\u4e0d\u592a\u53ef\u80fd\u6d88\u9664\u4e0d\u8fde\u8d2f\u6027\u3002", "conclusion": "\u968f\u7740AI\u5904\u7406\u66f4\u590d\u6742\u7684\u987a\u5e8f\u6027\u4efb\u52a1\uff0c\u5176\u5931\u8d25\u5c06\u4f34\u968f\u66f4\u591a\u4e0d\u8fde\u8d2f\u884c\u4e3a\uff0c\u8fd9\u610f\u5473\u7740AI\u66f4\u53ef\u80fd\u9020\u6210\u5de5\u4e1a\u4e8b\u6545\uff08\u7531\u4e8e\u4e0d\u53ef\u9884\u6d4b\u7684\u9519\u8bef\u884c\u4e3a\uff09\uff0c\u800c\u975e\u6301\u7eed\u8ffd\u6c42\u9519\u8bef\u76ee\u6807\u3002\u8fd9\u63d0\u9ad8\u4e86\u9488\u5bf9\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u548c\u76ee\u6807\u9519\u8bef\u6307\u5b9a\u7684\u5bf9\u9f50\u7814\u7a76\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.23048", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23048", "abs": "https://arxiv.org/abs/2601.23048", "authors": ["Bowen Cao", "Dongdong Zhang", "Yixia Li", "Junpeng Liu", "Shijue Huang", "Chufan Shi", "Hongyuan Lu", "Yaokang Wu", "Guanhua Chen", "Wai Lam", "Furu Wei"], "title": "From Abstract to Contextual: What LLMs Still Cannot Do in Mathematics", "comment": "ICLR 2026", "summary": "Large language models now solve many benchmark math problems at near-expert levels, yet this progress has not fully translated into reliable performance in real-world applications. We study this gap through contextual mathematical reasoning, where the mathematical core must be formulated from descriptive scenarios. We introduce ContextMATH, a benchmark that repurposes AIME and MATH-500 problems into two contextual settings: Scenario Grounding (SG), which embeds abstract problems into realistic narratives without increasing reasoning complexity, and Complexity Scaling (CS), which transforms explicit conditions into sub-problems to capture how constraints often appear in practice. Evaluating 61 proprietary and open-source models, we observe sharp drops: on average, open-source models decline by 13 and 34 points on SG and CS, while proprietary models drop by 13 and 20. Error analysis shows that errors are dominated by incorrect problem formulation, with formulation accuracy declining as original problem difficulty increases. Correct formulation emerges as a prerequisite for success, and its sufficiency improves with model scale, indicating that larger models advance in both understanding and reasoning. Nevertheless, formulation and reasoning remain two complementary bottlenecks that limit contextual mathematical problem solving. Finally, we find that fine-tuning with scenario data improves performance, whereas formulation-only training is ineffective. However, performance gaps are only partially alleviated, highlighting contextual mathematical reasoning as a central unsolved challenge for LLMs.", "AI": {"tldr": "ContextMATH\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0cLLMs\u5728\u4e0a\u4e0b\u6587\u6570\u5b66\u63a8\u7406\u4e2d\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u95ee\u9898\u8868\u8ff0\u800c\u975e\u8ba1\u7b97\u80fd\u529b", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u4f18\u5f02\u8868\u73b0\u4e3a\u4f55\u672a\u80fd\u8f6c\u5316\u4e3a\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u80fd\uff0c\u5173\u6ce8\u4e0a\u4e0b\u6587\u6570\u5b66\u63a8\u7406\u80fd\u529b", "method": "\u5f15\u5165ContextMATH\u57fa\u51c6\uff0c\u5c06AIME\u548cMATH-500\u95ee\u9898\u8f6c\u5316\u4e3a\u4e24\u79cd\u4e0a\u4e0b\u6587\u8bbe\u7f6e\uff1a\u573a\u666f\u57fa\u7840(SG)\u548c\u590d\u6742\u5ea6\u6269\u5c55(CS)\uff0c\u8bc4\u4f3061\u4e2a\u4e13\u6709\u548c\u5f00\u6e90\u6a21\u578b", "result": "\u6a21\u578b\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff1a\u5f00\u6e90\u6a21\u578b\u5728SG\u548cCS\u4e0a\u5206\u522b\u4e0b\u964d13\u548c34\u5206\uff0c\u4e13\u6709\u6a21\u578b\u4e0b\u964d13\u548c20\u5206\uff1b\u9519\u8bef\u4e3b\u8981\u7531\u95ee\u9898\u8868\u8ff0\u9519\u8bef\u4e3b\u5bfc\uff0c\u8868\u8ff0\u51c6\u786e\u6027\u968f\u539f\u95ee\u9898\u96be\u5ea6\u589e\u52a0\u800c\u4e0b\u964d", "conclusion": "\u6b63\u786e\u7684\u95ee\u9898\u8868\u8ff0\u662f\u6210\u529f\u7684\u524d\u63d0\uff0c\u5176\u5145\u5206\u6027\u968f\u6a21\u578b\u89c4\u6a21\u63d0\u5347\uff1b\u8868\u8ff0\u548c\u63a8\u7406\u662f\u4e24\u4e2a\u4e92\u8865\u7684\u74f6\u9888\uff1b\u5fae\u8c03\u53ef\u6539\u5584\u6027\u80fd\u4f46\u5dee\u8ddd\u4ec5\u90e8\u5206\u7f13\u89e3\uff0c\u4e0a\u4e0b\u6587\u6570\u5b66\u63a8\u7406\u4ecd\u662fLLMs\u672a\u89e3\u51b3\u7684\u6838\u5fc3\u6311\u6218"}}
{"id": "2601.23049", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23049", "abs": "https://arxiv.org/abs/2601.23049", "authors": ["Yakun Zhu", "Yutong Huang", "Shengqian Qin", "Zhongzhen Huang", "Shaoting Zhang", "Xiaofan Zhang"], "title": "MedMCP-Calc: Benchmarking LLMs for Realistic Medical Calculator Scenarios via MCP Integration", "comment": null, "summary": "Medical calculators are fundamental to quantitative, evidence-based clinical practice. However, their real-world use is an adaptive, multi-stage process, requiring proactive EHR data acquisition, scenario-dependent calculator selection, and multi-step computation, whereas current benchmarks focus only on static single-step calculations with explicit instructions. To address these limitations, we introduce MedMCP-Calc, the first benchmark for evaluating LLMs in realistic medical calculator scenarios through Model Context Protocol (MCP) integration. MedMCP-Calc comprises 118 scenario tasks across 4 clinical domains, featuring fuzzy task descriptions mimicking natural queries, structured EHR database interaction, external reference retrieval, and process-level evaluation. Our evaluation of 23 leading models reveals critical limitations: even top performers like Claude Opus 4.5 exhibit substantial gaps, including difficulty selecting appropriate calculators for end-to-end workflows given fuzzy queries, poor performance in iterative SQL-based database interactions, and marked reluctance to leverage external tools for numerical computation. Performance also varies considerably across clinical domains. Building on these findings, we develop CalcMate, a fine-tuned model incorporating scenario planning and tool augmentation, achieving state-of-the-art performance among open-source models. Benchmark and Codes are available in https://github.com/SPIRAL-MED/MedMCP-Calc.", "AI": {"tldr": "MedMCP-Calc\u662f\u9996\u4e2a\u901a\u8fc7MCP\u96c6\u6210\u8bc4\u4f30LLM\u5728\u771f\u5b9e\u533b\u7597\u8ba1\u7b97\u573a\u666f\u4e2d\u7684\u57fa\u51c6\uff0c\u5305\u542b118\u4e2a\u8de84\u4e2a\u4e34\u5e8a\u9886\u57df\u7684\u573a\u666f\u4efb\u52a1\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u6a21\u7cca\u67e5\u8be2\u3001\u6570\u636e\u5e93\u4ea4\u4e92\u548c\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u7684\u663e\u8457\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u533b\u7597\u8ba1\u7b97\u57fa\u51c6\u4ec5\u5173\u6ce8\u9759\u6001\u5355\u6b65\u8ba1\u7b97\uff0c\u800c\u771f\u5b9e\u4e34\u5e8a\u5b9e\u8df5\u9700\u8981\u591a\u9636\u6bb5\u81ea\u9002\u5e94\u8fc7\u7a0b\uff0c\u5305\u62ec\u4e3b\u52a8\u83b7\u53d6EHR\u6570\u636e\u3001\u573a\u666f\u4f9d\u8d56\u7684\u8ba1\u7b97\u5668\u9009\u62e9\u548c\u590d\u6742\u8ba1\u7b97\u6d41\u7a0b\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u8d34\u8fd1\u5b9e\u9645\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f00\u53d1MedMCP-Calc\u57fa\u51c6\uff0c\u5305\u542b118\u4e2a\u8de84\u4e2a\u4e34\u5e8a\u9886\u57df\u7684\u573a\u666f\u4efb\u52a1\uff0c\u7279\u5f81\u5305\u62ec\uff1a\u6a21\u7cca\u4efb\u52a1\u63cf\u8ff0\u6a21\u62df\u81ea\u7136\u67e5\u8be2\u3001\u7ed3\u6784\u5316EHR\u6570\u636e\u5e93\u4ea4\u4e92\u3001\u5916\u90e8\u53c2\u8003\u68c0\u7d22\u548c\u8fc7\u7a0b\u7ea7\u8bc4\u4f30\u3002\u57fa\u4e8e\u8bc4\u4f30\u7ed3\u679c\u5f00\u53d1CalcMate\u6a21\u578b\uff0c\u96c6\u6210\u573a\u666f\u89c4\u5212\u548c\u5de5\u5177\u589e\u5f3a\u3002", "result": "\u8bc4\u4f3023\u4e2a\u9886\u5148\u6a21\u578b\u53d1\u73b0\u5173\u952e\u5c40\u9650\uff1a\u5373\u4f7f\u9876\u7ea7\u6a21\u578b\u5982Claude Opus 4.5\u4e5f\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5305\u62ec\u96be\u4ee5\u6839\u636e\u6a21\u7cca\u67e5\u8be2\u9009\u62e9\u5408\u9002\u8ba1\u7b97\u5668\u3001\u8fed\u4ee3SQL\u6570\u636e\u5e93\u4ea4\u4e92\u6027\u80fd\u5dee\u3001\u4e0d\u613f\u4f7f\u7528\u5916\u90e8\u5de5\u5177\u8fdb\u884c\u6570\u503c\u8ba1\u7b97\u3002\u6027\u80fd\u5728\u4e0d\u540c\u4e34\u5e8a\u9886\u57df\u5dee\u5f02\u663e\u8457\u3002CalcMate\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "MedMCP-Calc\u586b\u8865\u4e86\u533b\u7597\u8ba1\u7b97\u8bc4\u4f30\u7684\u91cd\u8981\u7a7a\u767d\uff0c\u63ed\u793a\u4e86LLM\u5728\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\u5c40\u9650\uff0c\u4e3a\u672a\u6765\u533b\u7597AI\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u548c\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2601.23086", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23086", "abs": "https://arxiv.org/abs/2601.23086", "authors": ["Nathaniel Mitrani Hadida", "Sassan Bhanji", "Cameron Tice", "Puria Radmard"], "title": "Chain-of-thought obfuscation learned from output supervision can generalise to unseen tasks", "comment": null, "summary": "Chain-of-thought (CoT) reasoning provides a significant performance uplift to LLMs by enabling planning, exploration, and deliberation of their actions. CoT is also a powerful tool for monitoring the behaviours of these agents: when faithful, they offer interpretations of the model's decision making process, and an early warning sign for dangerous behaviours. However, optimisation pressures placed on the CoT may cause the model to obfuscate reasoning traces, losing this beneficial property. We show that obfuscation can generalise across tasks; models that learn to obfuscate reasoning involving reward hacking (e.g. accessing and utilising leaked information) generalise both the reward hacking behaviour and its obfuscation in CoT to unseen reward hacking settings. Most worryingly, we show that obfuscation of CoT reasoning, and its generalisation across tasks, also follows when we penalise only the model's final actions after closing its CoT. Our findings suggest that current practices of penalising harmful generations may inadvertently lead to a reduction in the broader monitorability of LLMs in unpredictable ways.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u5316\u538b\u529b\u53ef\u80fd\u5bfc\u81f4\u5176\u6a21\u7cca\u5316\u601d\u7ef4\u94fe\u63a8\u7406\u8fc7\u7a0b\uff0c\u8fd9\u79cd\u6a21\u7cca\u5316\u884c\u4e3a\u4f1a\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u6cdb\u5316\uff0c\u5373\u4f7f\u53ea\u60e9\u7f5a\u6700\u7ec8\u884c\u4e3a\u4e5f\u4f1a\u5bfc\u81f4\u63a8\u7406\u8fc7\u7a0b\u53d8\u5f97\u4e0d\u53ef\u76d1\u63a7\u3002", "motivation": "\u601d\u7ef4\u94fe\u63a8\u7406\u662f\u76d1\u63a7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u7684\u91cd\u8981\u5de5\u5177\uff0c\u4f46\u4f18\u5316\u538b\u529b\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u6a21\u7cca\u5316\u63a8\u7406\u8fc7\u7a0b\uff0c\u4ece\u800c\u5931\u53bb\u76d1\u63a7\u80fd\u529b\u3002\u7814\u7a76\u8005\u5e0c\u671b\u4e86\u89e3\u8fd9\u79cd\u6a21\u7cca\u5316\u884c\u4e3a\u662f\u5426\u4f1a\u8de8\u4efb\u52a1\u6cdb\u5316\uff0c\u4ee5\u53ca\u4ec5\u60e9\u7f5a\u6700\u7ec8\u884c\u4e3a\u662f\u5426\u4e5f\u4f1a\u5bfc\u81f4\u63a8\u7406\u6a21\u7cca\u5316\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u6a21\u578b\u5728\u5956\u52b1\u7834\u89e3\u4efb\u52a1\u4e2d\u7684\u884c\u4e3a\uff0c\u89c2\u5bdf\u6a21\u578b\u662f\u5426\u5b66\u4f1a\u6a21\u7cca\u5316\u601d\u7ef4\u94fe\u63a8\u7406\u3002\u7814\u7a76\u6d4b\u8bd5\u4e86\u4e24\u79cd\u60e9\u7f5a\u65b9\u5f0f\uff1a\u76f4\u63a5\u60e9\u7f5a\u63a8\u7406\u8fc7\u7a0b\u548c\u4ec5\u60e9\u7f5a\u6700\u7ec8\u884c\u4e3a\uff0c\u5206\u6790\u6a21\u7cca\u5316\u884c\u4e3a\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u7684\u6cdb\u5316\u60c5\u51b5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u6a21\u578b\u5b66\u4f1a\u6a21\u7cca\u5316\u6d89\u53ca\u5956\u52b1\u7834\u89e3\u7684\u63a8\u7406\u8fc7\u7a0b\uff1b2\uff09\u8fd9\u79cd\u6a21\u7cca\u5316\u884c\u4e3a\u4f1a\u5728\u672a\u89c1\u8fc7\u7684\u5956\u52b1\u7834\u89e3\u573a\u666f\u4e2d\u6cdb\u5316\uff1b3\uff09\u5373\u4f7f\u53ea\u60e9\u7f5a\u6700\u7ec8\u884c\u4e3a\uff0c\u4e5f\u4f1a\u5bfc\u81f4\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u6a21\u7cca\u5316\u53ca\u5176\u8de8\u4efb\u52a1\u6cdb\u5316\u3002", "conclusion": "\u5f53\u524d\u60e9\u7f5a\u6709\u5bb3\u751f\u6210\u7684\u505a\u6cd5\u53ef\u80fd\u65e0\u610f\u4e2d\u5bfc\u81f4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76d1\u63a7\u6027\u7684\u4e0d\u53ef\u9884\u6d4b\u964d\u4f4e\uff0c\u56e0\u4e3a\u6a21\u578b\u4f1a\u5b66\u4f1a\u6a21\u7cca\u5316\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f7f\u76d1\u63a7\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\u3002"}}
{"id": "2601.23143", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23143", "abs": "https://arxiv.org/abs/2601.23143", "authors": ["Seanie Lee", "Sangwoo Park", "Yumin Choi", "Gyeongman Kim", "Minki Kang", "Jihun Yun", "Dongmin Park", "Jongho Park", "Sung Ju Hwang"], "title": "THINKSAFE: Self-Generated Safety Alignment for Reasoning Models", "comment": "17 pages, 13 figures", "summary": "Large reasoning models (LRMs) achieve remarkable performance by leveraging reinforcement learning (RL) on reasoning tasks to generate long chain-of-thought (CoT) reasoning. However, this over-optimization often prioritizes compliance, making models vulnerable to harmful prompts. To mitigate this safety degradation, recent approaches rely on external teacher distillation, yet this introduces a distributional discrepancy that degrades native reasoning. We propose ThinkSafe, a self-generated alignment framework that restores safety alignment without external teachers. Our key insight is that while compliance suppresses safety mechanisms, models often retain latent knowledge to identify harm. ThinkSafe unlocks this via lightweight refusal steering, guiding the model to generate in-distribution safety reasoning traces. Fine-tuning on these self-generated responses effectively realigns the model while minimizing distribution shift. Experiments on DeepSeek-R1-Distill and Qwen3 show ThinkSafe significantly improves safety while preserving reasoning proficiency. Notably, it achieves superior safety and comparable reasoning to GRPO, with significantly reduced computational cost. Code, models, and datasets are available at https://github.com/seanie12/ThinkSafe.git.", "AI": {"tldr": "ThinkSafe\u662f\u4e00\u79cd\u81ea\u751f\u6210\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u62d2\u7edd\u5f15\u5bfc\u89e3\u9501\u6a21\u578b\u7684\u6f5c\u5728\u5b89\u5168\u77e5\u8bc6\uff0c\u751f\u6210\u5b89\u5168\u63a8\u7406\u8f68\u8ff9\u8fdb\u884c\u5fae\u8c03\uff0c\u5728\u6062\u590d\u5b89\u5168\u5bf9\u9f50\u7684\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u8fc7\u5ea6\u4f18\u5316\uff0c\u5f80\u5f80\u4f18\u5148\u8003\u8651\u5408\u89c4\u6027\uff0c\u5bfc\u81f4\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u6709\u5bb3\u63d0\u793a\u7684\u653b\u51fb\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u6559\u5e08\u84b8\u998f\uff0c\u4f46\u4f1a\u5f15\u5165\u5206\u5e03\u5dee\u5f02\uff0c\u635f\u5bb3\u539f\u751f\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faThinkSafe\u81ea\u751f\u6210\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u62d2\u7edd\u5f15\u5bfc\u89e3\u9501\u6a21\u578b\u8bc6\u522b\u5371\u5bb3\u7684\u6f5c\u5728\u77e5\u8bc6\uff0c\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u5206\u5e03\u5185\u7684\u5b89\u5168\u63a8\u7406\u8f68\u8ff9\uff0c\u7136\u540e\u5728\u8fd9\u4e9b\u81ea\u751f\u6210\u54cd\u5e94\u4e0a\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5728DeepSeek-R1-Distill\u548cQwen3\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cThinkSafe\u663e\u8457\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\u540c\u65f6\u4fdd\u6301\u4e86\u63a8\u7406\u80fd\u529b\u3002\u4e0eGRPO\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u5b89\u5168\u6027\u548c\u76f8\u5f53\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8ba1\u7b97\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "ThinkSafe\u901a\u8fc7\u81ea\u751f\u6210\u5bf9\u9f50\u6709\u6548\u89e3\u51b3\u4e86\u5b89\u5168\u5bf9\u9f50\u9000\u5316\u95ee\u9898\uff0c\u65e0\u9700\u5916\u90e8\u6559\u5e08\uff0c\u5728\u6062\u590d\u5b89\u5168\u6027\u7684\u540c\u65f6\u6700\u5c0f\u5316\u5206\u5e03\u504f\u79fb\uff0c\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002"}}
{"id": "2601.23179", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23179", "abs": "https://arxiv.org/abs/2601.23179", "authors": ["Hui Lu", "Yi Yu", "Yiming Yang", "Chenyu Yi", "Xueyi Ke", "Qixing Zhang", "Bingquan Shen", "Alex Kot", "Xudong Jiang"], "title": "Make Anything Match Your Target: Universal Adversarial Perturbations against Closed-Source MLLMs via Multi-Crop Routed Meta Optimization", "comment": null, "summary": "Targeted adversarial attacks on closed-source multimodal large language models (MLLMs) have been increasingly explored under black-box transfer, yet prior methods are predominantly sample-specific and offer limited reusability across inputs. We instead study a more stringent setting, Universal Targeted Transferable Adversarial Attacks (UTTAA), where a single perturbation must consistently steer arbitrary inputs toward a specified target across unknown commercial MLLMs. Naively adapting existing sample-wise attacks to this universal setting faces three core difficulties: (i) target supervision becomes high-variance due to target-crop randomness, (ii) token-wise matching is unreliable because universality suppresses image-specific cues that would otherwise anchor alignment, and (iii) few-source per-target adaptation is highly initialization-sensitive, which can degrade the attainable performance. In this work, we propose MCRMO-Attack, which stabilizes supervision via Multi-Crop Aggregation with an Attention-Guided Crop, improves token-level reliability through alignability-gated Token Routing, and meta-learns a cross-target perturbation prior that yields stronger per-target solutions. Across commercial MLLMs, we boost unseen-image attack success rate by +23.7\\% on GPT-4o and +19.9\\% on Gemini-2.0 over the strongest universal baseline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMCRMO-Attack\u65b9\u6cd5\uff0c\u89e3\u51b3\u901a\u7528\u76ee\u6807\u53ef\u8f6c\u79fb\u5bf9\u6297\u653b\u51fb\u4e2d\u7684\u4e09\u4e2a\u6838\u5fc3\u56f0\u96be\uff1a\u76ee\u6807\u76d1\u7763\u9ad8\u65b9\u5dee\u3001\u8bcd\u5143\u5339\u914d\u4e0d\u53ef\u9760\u3001\u4ee5\u53ca\u5c11\u6837\u672c\u9002\u5e94\u5bf9\u521d\u59cb\u5316\u654f\u611f\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u9ed1\u76d2\u53ef\u8f6c\u79fb\u5bf9\u6297\u653b\u51fb\u4e3b\u8981\u662f\u6837\u672c\u7279\u5b9a\u7684\uff0c\u8de8\u8f93\u5165\u91cd\u7528\u6027\u6709\u9650\u3002\u672c\u6587\u7814\u7a76\u66f4\u4e25\u683c\u7684\u901a\u7528\u76ee\u6807\u53ef\u8f6c\u79fb\u5bf9\u6297\u653b\u51fb\uff08UTTAA\uff09\u8bbe\u7f6e\uff0c\u8981\u6c42\u5355\u4e2a\u6270\u52a8\u80fd\u591f\u4e00\u81f4\u5730\u5c06\u4efb\u610f\u8f93\u5165\u5bfc\u5411\u6307\u5b9a\u76ee\u6807\uff0c\u5e76\u5728\u672a\u77e5\u5546\u4e1a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u6709\u6548\u3002", "method": "\u63d0\u51faMCRMO-Attack\u65b9\u6cd5\uff1a1\uff09\u901a\u8fc7\u6ce8\u610f\u529b\u5f15\u5bfc\u88c1\u526a\u7684\u591a\u88c1\u526a\u805a\u5408\u7a33\u5b9a\u76d1\u7763\uff1b2\uff09\u901a\u8fc7\u53ef\u5bf9\u9f50\u6027\u95e8\u63a7\u7684\u8bcd\u5143\u8def\u7531\u63d0\u9ad8\u8bcd\u5143\u7ea7\u53ef\u9760\u6027\uff1b3\uff09\u5143\u5b66\u4e60\u8de8\u76ee\u6807\u6270\u52a8\u5148\u9a8c\u4ee5\u83b7\u5f97\u66f4\u5f3a\u7684\u6bcf\u76ee\u6807\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u5546\u4e1aMLLMs\u4e0a\uff0c\u76f8\u6bd4\u6700\u5f3a\u901a\u7528\u57fa\u7ebf\uff0c\u5728GPT-4o\u4e0a\u672a\u89c1\u56fe\u50cf\u653b\u51fb\u6210\u529f\u7387\u63d0\u5347+23.7%\uff0c\u5728Gemini-2.0\u4e0a\u63d0\u5347+19.9%\u3002", "conclusion": "MCRMO-Attack\u6709\u6548\u89e3\u51b3\u4e86\u901a\u7528\u76ee\u6807\u53ef\u8f6c\u79fb\u5bf9\u6297\u653b\u51fb\u4e2d\u7684\u6838\u5fc3\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8de8\u5546\u4e1a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u653b\u51fb\u6210\u529f\u7387\u3002"}}
{"id": "2601.23204", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23204", "abs": "https://arxiv.org/abs/2601.23204", "authors": ["Baoyu Jing", "Sanhorn Chen", "Lecheng Zheng", "Boyu Liu", "Zihao Li", "Jiaru Zou", "Tianxin Wei", "Zhining Liu", "Zhichen Zeng", "Ruizhong Qiu", "Xiao Lin", "Yuchen Yan", "Dongqi Fu", "Jingchao Ni", "Jingrui He", "Hanghang Tong"], "title": "TSAQA: Time Series Analysis Question And Answering Benchmark", "comment": "35 pages, 7 figures", "summary": "Time series data are integral to critical applications across domains such as finance, healthcare, transportation, and environmental science. While recent work has begun to explore multi-task time series question answering (QA), current benchmarks remain limited to forecasting and anomaly detection tasks. We introduce TSAQA, a novel unified benchmark designed to broaden task coverage and evaluate diverse temporal analysis capabilities. TSAQA integrates six diverse tasks under a single framework ranging from conventional analysis, including anomaly detection and classification, to advanced analysis, such as characterization, comparison, data transformation, and temporal relationship analysis. Spanning 210k samples across 13 domains, the dataset employs diverse formats, including true-or-false (TF), multiple-choice (MC), and a novel puzzling (PZ), to comprehensively assess time series analysis. Zero-shot evaluation demonstrates that these tasks are challenging for current Large Language Models (LLMs): the best-performing commercial LLM, Gemini-2.5-Flash, achieves an average score of only 65.08. Although instruction tuning boosts open-source performance: the best-performing open-source model, LLaMA-3.1-8B, shows significant room for improvement, highlighting the complexity of temporal analysis for LLMs.", "AI": {"tldr": "TSAQA\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u65f6\u95f4\u5e8f\u5217\u95ee\u7b54\u57fa\u51c6\uff0c\u5305\u542b6\u79cd\u4efb\u52a1\u7c7b\u578b\uff0c\u6db5\u76d613\u4e2a\u9886\u57df\u768421\u4e07\u4e2a\u6837\u672c\uff0c\u91c7\u7528\u591a\u79cd\u683c\u5f0f\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u591a\u4efb\u52a1\u65f6\u95f4\u5e8f\u5217\u95ee\u7b54\u57fa\u51c6\u4ec5\u9650\u4e8e\u9884\u6d4b\u548c\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u66f4\u5e7f\u6cdb\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u57fa\u51c6\u6765\u63a8\u52a8\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7814\u7a76\u3002", "method": "\u6784\u5efaTSAQA\u57fa\u51c6\uff0c\u6574\u54086\u79cd\u4e0d\u540c\u4efb\u52a1\uff1a\u5f02\u5e38\u68c0\u6d4b\u3001\u5206\u7c7b\u3001\u7279\u5f81\u63cf\u8ff0\u3001\u6bd4\u8f83\u3001\u6570\u636e\u8f6c\u6362\u548c\u65f6\u95f4\u5173\u7cfb\u5206\u6790\uff0c\u6db5\u76d613\u4e2a\u9886\u57df\uff0c\u91c7\u7528TF\u3001MC\u548c\u521b\u65b0\u7684PZ\u683c\u5f0f\uff0c\u517121\u4e07\u4e2a\u6837\u672c\u3002", "result": "\u96f6\u6837\u672c\u8bc4\u4f30\u663e\u793a\u5f53\u524dLLMs\u8868\u73b0\u6709\u9650\uff1a\u6700\u4f73\u5546\u4e1a\u6a21\u578bGemini-2.5-Flash\u5e73\u5747\u5f97\u5206\u4ec565.08\uff1b\u6307\u4ee4\u5fae\u8c03\u80fd\u63d0\u5347\u5f00\u6e90\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u6700\u4f73\u5f00\u6e90\u6a21\u578bLLaMA-3.1-8B\u4ecd\u6709\u5f88\u5927\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "TSAQA\u57fa\u51c6\u5c55\u793a\u4e86\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u5bf9LLMs\u7684\u6311\u6218\u6027\uff0c\u4e3a\u8bc4\u4f30\u548c\u63d0\u5347LLMs\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u80fd\u529b\u63d0\u4f9b\u4e86\u5168\u9762\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2601.23228", "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.23228", "abs": "https://arxiv.org/abs/2601.23228", "authors": ["Ed Li", "Junyu Ren", "Cat Yan"], "title": "Scaling Multiagent Systems with Process Rewards", "comment": null, "summary": "While multiagent systems have shown promise for tackling complex tasks via specialization, finetuning multiple agents simultaneously faces two key challenges: (1) credit assignment across agents, and (2) sample efficiency of expensive multiagent rollouts. In this work, we propose finetuning multiagent systems with per-action process rewards from AI feedback (MAPPA) to address both. Through assigning credit to individual agent actions rather than only at task completion, MAPPA enables fine-grained supervision without ground truth labels while extracting maximal training signal from each rollout. We demonstrate our approach on competition math problems and tool-augmented data analysis tasks. On unseen math problems, MAPPA achieves +5.0--17.5pp on AIME and +7.8--17.2pp on AMC. For data analysis tasks, our method improves success rate by +12.5pp while quality metrics improve by up to 30%, validating that per-action supervision can lead to improvements across different multiagent system on various domains. By addressing these challenges, our work takes a first step toward scaling multiagent systems for complex, long-horizon tasks with minimal human supervision.", "AI": {"tldr": "MAPPA\u65b9\u6cd5\u901a\u8fc7AI\u53cd\u9988\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6bcf\u4e2a\u52a8\u4f5c\u63d0\u4f9b\u8fc7\u7a0b\u5956\u52b1\uff0c\u89e3\u51b3\u4e86\u4fe1\u7528\u5206\u914d\u548c\u6837\u672c\u6548\u7387\u95ee\u9898\uff0c\u5728\u6570\u5b66\u7ade\u8d5b\u548c\u6570\u636e\u5206\u6790\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a1\uff09\u8de8\u667a\u80fd\u4f53\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff1b2\uff09\u6602\u8d35\u591a\u667a\u80fd\u4f53rollout\u7684\u6837\u672c\u6548\u7387\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u5728\u6ca1\u6709\u771f\u5b9e\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u76d1\u7763\uff0c\u540c\u65f6\u4ece\u6bcf\u6b21rollout\u4e2d\u63d0\u53d6\u6700\u5927\u8bad\u7ec3\u4fe1\u53f7\u3002", "method": "\u63d0\u51faMAPPA\u65b9\u6cd5\uff0c\u901a\u8fc7AI\u53cd\u9988\u4e3a\u6bcf\u4e2a\u667a\u80fd\u4f53\u52a8\u4f5c\u63d0\u4f9b\u8fc7\u7a0b\u5956\u52b1\uff0c\u800c\u4e0d\u662f\u4ec5\u5728\u4efb\u52a1\u5b8c\u6210\u65f6\u5206\u914d\u4fe1\u7528\u3002\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u4e3a\u4e2a\u4f53\u667a\u80fd\u4f53\u52a8\u4f5c\u5206\u914d\u4fe1\u7528\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u76d1\u7763\uff0c\u540c\u65f6\u6700\u5927\u5316\u6bcf\u6b21rollout\u7684\u8bad\u7ec3\u4fe1\u53f7\u63d0\u53d6\u3002", "result": "\u5728\u6570\u5b66\u7ade\u8d5b\u95ee\u9898\u4e0a\uff0cMAPPA\u5728AIME\u4e0a\u63d0\u53475.0-17.5\u4e2a\u767e\u5206\u70b9\uff0c\u5728AMC\u4e0a\u63d0\u53477.8-17.2\u4e2a\u767e\u5206\u70b9\u3002\u5728\u6570\u636e\u5206\u6790\u4efb\u52a1\u4e2d\uff0c\u6210\u529f\u7387\u63d0\u9ad812.5\u4e2a\u767e\u5206\u70b9\uff0c\u8d28\u91cf\u6307\u6807\u63d0\u5347\u9ad8\u8fbe30%\u3002\u9a8c\u8bc1\u4e86\u8de8\u4e0d\u540c\u9886\u57df\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6539\u8fdb\u6548\u679c\u3002", "conclusion": "\u901a\u8fc7\u89e3\u51b3\u4fe1\u7528\u5206\u914d\u548c\u6837\u672c\u6548\u7387\u6311\u6218\uff0cMAPPA\u4e3a\u5728\u590d\u6742\u3001\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u6269\u5c55\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8fc8\u51fa\u4e86\u7b2c\u4e00\u6b65\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u4eba\u5de5\u76d1\u7763\u9700\u6c42\u3002\u57fa\u4e8e\u52a8\u4f5c\u7684\u76d1\u7763\u80fd\u591f\u663e\u8457\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4e0d\u540c\u9886\u57df\u7684\u6027\u80fd\u3002"}}
{"id": "2601.23229", "categories": ["cs.AI", "cs.CC"], "pdf": "https://arxiv.org/pdf/2601.23229", "abs": "https://arxiv.org/abs/2601.23229", "authors": ["Ali Asadi", "Krishnendu Chatterjee", "Ehsan Goharshady", "Mehrdad Karrabi", "Alipasha Montaseri", "Carlo Pagano"], "title": "Strongly Polynomial Time Complexity of Policy Iteration for $L_\\infty$ Robust MDPs", "comment": null, "summary": "Markov decision processes (MDPs) are a fundamental model in sequential decision making. Robust MDPs (RMDPs) extend this framework by allowing uncertainty in transition probabilities and optimizing against the worst-case realization of that uncertainty. In particular, $(s, a)$-rectangular RMDPs with $L_\\infty$ uncertainty sets form a fundamental and expressive model: they subsume classical MDPs and turn-based stochastic games. We consider this model with discounted payoffs. The existence of polynomial and strongly-polynomial time algorithms is a fundamental problem for these optimization models. For MDPs, linear programming yields polynomial-time algorithms for any arbitrary discount factor, and the seminal work of Ye established strongly--polynomial time for a fixed discount factor. The generalization of such results to RMDPs has remained an important open problem. In this work, we show that a robust policy iteration algorithm runs in strongly-polynomial time for $(s, a)$-rectangular $L_\\infty$ RMDPs with a constant (fixed) discount factor, resolving an important algorithmic question.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u5bf9\u4e8e(s,a)-\u77e9\u5f62L\u221e\u4e0d\u786e\u5b9a\u6027\u96c6\u7684\u9c81\u68d2MDPs\uff0c\u5728\u56fa\u5b9a\u6298\u6263\u56e0\u5b50\u4e0b\uff0c\u9c81\u68d2\u7b56\u7565\u8fed\u4ee3\u7b97\u6cd5\u5177\u6709\u5f3a\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u7684\u4e00\u4e2a\u91cd\u8981\u7b97\u6cd5\u95ee\u9898\u3002", "motivation": "\u9c81\u68d2MDPs\u662f\u5e8f\u5217\u51b3\u7b56\u4e2d\u7684\u57fa\u672c\u6a21\u578b\uff0c\u80fd\u591f\u5904\u7406\u8f6c\u79fb\u6982\u7387\u7684\u4e0d\u786e\u5b9a\u6027\u5e76\u4f18\u5316\u6700\u574f\u60c5\u51b5\u3002\u867d\u7136MDPs\u5df2\u6709\u591a\u9879\u5f0f\u65f6\u95f4\u548c\u5f3a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u4f46\u5c06\u8fd9\u7c7b\u7ed3\u679c\u63a8\u5e7f\u5230RMDPs\u4e00\u76f4\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u5f00\u653e\u95ee\u9898\u3002", "method": "\u91c7\u7528\u9c81\u68d2\u7b56\u7565\u8fed\u4ee3\u7b97\u6cd5\u6765\u5904\u7406(s,a)-\u77e9\u5f62L\u221e\u4e0d\u786e\u5b9a\u6027\u96c6\u7684\u9c81\u68d2MDPs\uff0c\u8be5\u6a21\u578b\u5305\u542b\u4e86\u7ecf\u5178MDPs\u548c\u56de\u5408\u5236\u968f\u673a\u535a\u5f08\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u56fa\u5b9a\u6298\u6263\u56e0\u5b50\uff0c\u9c81\u68d2\u7b56\u7565\u8fed\u4ee3\u7b97\u6cd5\u5728(s,a)-\u77e9\u5f62L\u221e RMDPs\u4e0a\u5177\u6709\u5f3a\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86\u9c81\u68d2MDPs\u7b97\u6cd5\u590d\u6742\u6027\u7684\u4e00\u4e2a\u91cd\u8981\u5f00\u653e\u95ee\u9898\uff0c\u4e3a(s,a)-\u77e9\u5f62L\u221e\u4e0d\u786e\u5b9a\u6027\u96c6\u7684\u9c81\u68d2MDPs\u63d0\u4f9b\u4e86\u5f3a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u4fdd\u8bc1\u3002"}}
