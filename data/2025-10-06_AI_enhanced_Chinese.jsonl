{"id": "2510.02317", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02317", "abs": "https://arxiv.org/abs/2510.02317", "authors": ["Anais Jaikissoon"], "title": "Hybrid Horizons: Policy for Post-Quantum Security", "comment": "18 pages, 3 figures, 1 image", "summary": "The Age of Artificial Intelligence is here. In 2025, there are few\nregulations governing artificial intelligence. While the expansion of\nartificial intelligence is going in a relatively good direction, there is a\nrisk that it can be misused. Misuse of technology is nothing new and will\ncontinue to happen. The lack of regulation in artificial intelligence is\nnecessary because it raises the question of how we can move forward without\nknowing what the limits are. While artificial intelligence dominates the\ntechnology industry, new technology is starting to emerge. Quantum cryptography\nis expected to replace classical cryptography; however, the transition from\nclassical to quantum cryptography is expected to occur within the next 10\nyears. The ability to transition from classical to quantum cryptography\nrequires hybrid cryptography. Hybrid cryptography can be used now; however,\nsimilar to artificial intelligence, there is no regulation or support for the\nregulatory infrastructure regarding hybrid machines. This paper will explore\nthe regulatory gaps in hybrid cryptography. The paper will also offer solutions\nto fix the gaps and ensure the transition from classical to quantum\ncryptography is safely and effectively completed.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\u4e0b\u6df7\u5408\u5bc6\u7801\u5b66\u7684\u76d1\u7ba1\u7a7a\u767d\u95ee\u9898\uff0c\u5206\u6790\u4e86\u4ece\u7ecf\u5178\u5bc6\u7801\u5b66\u5411\u91cf\u5b50\u5bc6\u7801\u5b66\u8fc7\u6e21\u671f\u95f4\u7f3a\u4e4f\u76d1\u7ba1\u6846\u67b6\u7684\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7684\u5feb\u901f\u53d1\u5c55\u548c\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u5174\u8d77\uff0c\u5f53\u524d\u7f3a\u4e4f\u5bf9\u6df7\u5408\u5bc6\u7801\u5b66\u7684\u76d1\u7ba1\u6846\u67b6\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6280\u672f\u88ab\u6ee5\u7528\uff0c\u963b\u788d\u4ece\u7ecf\u5178\u5bc6\u7801\u5b66\u5411\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u5b89\u5168\u8fc7\u6e21\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5f53\u524d\u76d1\u7ba1\u73b0\u72b6\u548c\u6280\u672f\u53d1\u5c55\u8d8b\u52bf\uff0c\u8bc6\u522b\u6df7\u5408\u5bc6\u7801\u5b66\u9886\u57df\u7684\u76d1\u7ba1\u7a7a\u767d\uff0c\u5e76\u5236\u5b9a\u76f8\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u8bc6\u522b\u51fa\u6df7\u5408\u5bc6\u7801\u5b66\u5728\u76d1\u7ba1\u57fa\u7840\u8bbe\u65bd\u65b9\u9762\u5b58\u5728\u91cd\u5927\u7a7a\u767d\uff0c\u7f3a\u4e4f\u660e\u786e\u7684\u6cd5\u89c4\u548c\u6807\u51c6\u6765\u652f\u6301\u4ece\u7ecf\u5178\u5bc6\u7801\u5b66\u5230\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u8fc7\u6e21\u3002", "conclusion": "\u9700\u8981\u5efa\u7acb\u6df7\u5408\u5bc6\u7801\u5b66\u7684\u76d1\u7ba1\u6846\u67b6\uff0c\u4ee5\u786e\u4fdd\u4ece\u7ecf\u5178\u5bc6\u7801\u5b66\u5411\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u8fc7\u6e21\u80fd\u591f\u5b89\u5168\u6709\u6548\u5730\u5b8c\u6210\uff0c\u9632\u6b62\u6280\u672f\u6ee5\u7528\u5e76\u4fc3\u8fdb\u6280\u672f\u521b\u65b0\u3002"}}
{"id": "2510.02319", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02319", "abs": "https://arxiv.org/abs/2510.02319", "authors": ["Lekkala Sai Teja", "Annepaka Yadagiri", "Sangam Sai Anish", "Siva Gopala Krishna Nuthakki", "Partha Pakray"], "title": "Modeling the Attack: Detecting AI-Generated Text by Quantifying Adversarial Perturbations", "comment": "8 pages, 3 figures", "summary": "The growth of highly advanced Large Language Models (LLMs) constitutes a huge\ndual-use problem, making it necessary to create dependable AI-generated text\ndetection systems. Modern detectors are notoriously vulnerable to adversarial\nattacks, with paraphrasing standing out as an effective evasion technique that\nfoils statistical detection. This paper presents a comparative study of\nadversarial robustness, first by quantifying the limitations of standard\nadversarial training and then by introducing a novel, significantly more\nresilient detection framework: Perturbation-Invariant Feature Engineering\n(PIFE), a framework that enhances detection by first transforming input text\ninto a standardized form using a multi-stage normalization pipeline, it then\nquantifies the transformation's magnitude using metrics like Levenshtein\ndistance and semantic similarity, feeding these signals directly to the\nclassifier. We evaluate both a conventionally hardened Transformer and our\nPIFE-augmented model against a hierarchical taxonomy of character-, word-, and\nsentence-level attacks. Our findings first confirm that conventional\nadversarial training, while resilient to syntactic noise, fails against\nsemantic attacks, an effect we term \"semantic evasion threshold\", where its\nTrue Positive Rate at a strict 1% False Positive Rate plummets to 48.8%. In\nstark contrast, our PIFE model, which explicitly engineers features from the\ndiscrepancy between a text and its canonical form, overcomes this limitation.\nIt maintains a remarkable 82.6% TPR under the same conditions, effectively\nneutralizing the most sophisticated semantic attacks. This superior performance\ndemonstrates that explicitly modeling perturbation artifacts, rather than\nmerely training on them, is a more promising path toward achieving genuine\nrobustness in the adversarial arms race.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PIFE\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u6807\u51c6\u5316\u5f62\u5f0f\u5e76\u91cf\u5316\u53d8\u6362\u5e45\u5ea6\u6765\u589e\u5f3aAI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u53cc\u91cd\u7528\u9014\u95ee\u9898\uff0c\u9700\u8981\u53ef\u9760\u7684AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u7cfb\u7edf\u3002\u73b0\u6709\u68c0\u6d4b\u5668\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u653b\u51fb\uff0c\u7279\u522b\u662f\u91cd\u8ff0\u653b\u51fb\uff0c\u8fd9\u89c4\u907f\u4e86\u7edf\u8ba1\u68c0\u6d4b\u3002", "method": "\u63d0\u51fa\u4e86\u6270\u52a8\u4e0d\u53d8\u7279\u5f81\u5de5\u7a0b(PIFE)\u6846\u67b6\uff1a\u9996\u5148\u901a\u8fc7\u591a\u9636\u6bb5\u6807\u51c6\u5316\u6d41\u7a0b\u5c06\u8f93\u5165\u6587\u672c\u8f6c\u6362\u4e3a\u6807\u51c6\u5f62\u5f0f\uff0c\u7136\u540e\u4f7f\u7528Levenshtein\u8ddd\u79bb\u548c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7b49\u6307\u6807\u91cf\u5316\u53d8\u6362\u5e45\u5ea6\uff0c\u5c06\u8fd9\u4e9b\u4fe1\u53f7\u76f4\u63a5\u8f93\u5165\u5206\u7c7b\u5668\u3002", "result": "\u4f20\u7edf\u5bf9\u6297\u8bad\u7ec3\u5728\u4e25\u683c1%\u8bef\u62a5\u7387\u4e0b\u7684\u771f\u9633\u6027\u7387\u4ec5\u4e3a48.8%\uff0c\u800cPIFE\u6a21\u578b\u5728\u76f8\u540c\u6761\u4ef6\u4e0b\u4fdd\u630182.6%\u7684\u771f\u9633\u6027\u7387\uff0c\u6709\u6548\u62b5\u5fa1\u4e86\u6700\u590d\u6742\u7684\u8bed\u4e49\u653b\u51fb\u3002", "conclusion": "\u660e\u786e\u5efa\u6a21\u6270\u52a8\u4f2a\u5f71\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5728\u5176\u4e0a\u8bad\u7ec3\uff0c\u662f\u5728\u5bf9\u6297\u6027\u519b\u5907\u7ade\u8d5b\u4e2d\u5b9e\u73b0\u771f\u6b63\u9c81\u68d2\u6027\u7684\u66f4\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2510.02325", "categories": ["cs.CR", "cs.AI", "I.2.11; J.3"], "pdf": "https://arxiv.org/pdf/2510.02325", "abs": "https://arxiv.org/abs/2510.02325", "authors": ["Mohammed A. Shehab"], "title": "Agentic-AI Healthcare: Multilingual, Privacy-First Framework with MCP Agents", "comment": "6 pages, 1 figure. Submitted as a system/vision paper", "summary": "This paper introduces Agentic-AI Healthcare, a privacy-aware, multilingual,\nand explainable research prototype developed as a single-investigator project.\nThe system leverages the emerging Model Context Protocol (MCP) to orchestrate\nmultiple intelligent agents for patient interaction, including symptom\nchecking, medication suggestions, and appointment scheduling. The platform\nintegrates a dedicated Privacy and Compliance Layer that applies role-based\naccess control (RBAC), AES-GCM field-level encryption, and tamper-evident audit\nlogging, aligning with major healthcare data protection standards such as HIPAA\n(US), PIPEDA (Canada), and PHIPA (Ontario). Example use cases demonstrate\nmultilingual patient-doctor interaction (English, French, Arabic) and\ntransparent diagnostic reasoning powered by large language models. As an\napplied AI contribution, this work highlights the feasibility of combining\nagentic orchestration, multilingual accessibility, and compliance-aware\narchitecture in healthcare applications. This platform is presented as a\nresearch prototype and is not a certified medical device.", "AI": {"tldr": "Agentic-AI Healthcare\u662f\u4e00\u4e2a\u9690\u79c1\u611f\u77e5\u3001\u591a\u8bed\u8a00\u3001\u53ef\u89e3\u91ca\u7684\u533b\u7597AI\u7814\u7a76\u539f\u578b\uff0c\u5229\u7528MCP\u534f\u8bae\u534f\u8c03\u591a\u4e2a\u667a\u80fd\u4ee3\u7406\u8fdb\u884c\u60a3\u8005\u4ea4\u4e92\uff0c\u96c6\u6210\u9690\u79c1\u5408\u89c4\u5c42\u5e76\u7b26\u5408HIPAA\u7b49\u533b\u7597\u6570\u636e\u4fdd\u62a4\u6807\u51c6\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u7ed3\u5408\u667a\u80fd\u4ee3\u7406\u7f16\u6392\u3001\u591a\u8bed\u8a00\u53ef\u8bbf\u95ee\u6027\u548c\u5408\u89c4\u6027\u67b6\u6784\u7684\u533b\u7597\u5e94\u7528\uff0c\u89e3\u51b3\u533b\u7597AI\u7cfb\u7edf\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u3001\u591a\u8bed\u8a00\u652f\u6301\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3002", "method": "\u4f7f\u7528Model Context Protocol (MCP)\u534f\u8c03\u591a\u4e2a\u667a\u80fd\u4ee3\u7406\uff0c\u96c6\u6210\u9690\u79c1\u5408\u89c4\u5c42\uff08RBAC\u3001AES-GCM\u5b57\u6bb5\u7ea7\u52a0\u5bc6\u3001\u9632\u7be1\u6539\u5ba1\u8ba1\u65e5\u5fd7\uff09\uff0c\u652f\u6301\u82f1\u8bed\u3001\u6cd5\u8bed\u3001\u963f\u62c9\u4f2f\u8bed\u7b49\u591a\u8bed\u8a00\u4ea4\u4e92\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u7814\u7a76\u539f\u578b\uff0c\u5c55\u793a\u4e86\u591a\u8bed\u8a00\u533b\u60a3\u4ea4\u4e92\u548c\u900f\u660e\u8bca\u65ad\u63a8\u7406\u529f\u80fd\uff0c\u7b26\u5408HIPAA\u3001PIPEDA\u3001PHIPA\u7b49\u533b\u7597\u6570\u636e\u4fdd\u62a4\u6807\u51c6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8bc1\u660e\u4e86\u5728\u533b\u7597\u5e94\u7528\u4e2d\u7ed3\u5408\u667a\u80fd\u4ee3\u7406\u7f16\u6392\u3001\u591a\u8bed\u8a00\u53ef\u8bbf\u95ee\u6027\u548c\u5408\u89c4\u6027\u67b6\u6784\u7684\u53ef\u884c\u6027\uff0c\u4f46\u5f3a\u8c03\u8fd9\u4ec5\u662f\u4e00\u4e2a\u7814\u7a76\u539f\u578b\u800c\u975e\u8ba4\u8bc1\u533b\u7597\u8bbe\u5907\u3002"}}
{"id": "2510.02342", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02342", "abs": "https://arxiv.org/abs/2510.02342", "authors": ["Yu Zhang", "Shuliang Liu", "Xu Yang", "Xuming Hu"], "title": "CATMark: A Context-Aware Thresholding Framework for Robust Cross-Task Watermarking in Large Language Models", "comment": null, "summary": "Watermarking algorithms for Large Language Models (LLMs) effectively identify\nmachine-generated content by embedding and detecting hidden statistical\nfeatures in text. However, such embedding leads to a decline in text quality,\nespecially in low-entropy scenarios where performance needs improvement.\nExisting methods that rely on entropy thresholds often require significant\ncomputational resources for tuning and demonstrate poor adaptability to unknown\nor cross-task generation scenarios. We propose \\textbf{C}ontext-\\textbf{A}ware\n\\textbf{T}hreshold watermarking ($\\myalgo$), a novel framework that dynamically\nadjusts watermarking intensity based on real-time semantic context. $\\myalgo$\npartitions text generation into semantic states using logits clustering,\nestablishing context-aware entropy thresholds that preserve fidelity in\nstructured content while embedding robust watermarks. Crucially, it requires no\npre-defined thresholds or task-specific tuning. Experiments show $\\myalgo$\nimproves text quality in cross-tasks without sacrificing detection accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0a\u4e0b\u6587\u611f\u77e5\u9608\u503c\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u65f6\u8bed\u4e49\u4e0a\u4e0b\u6587\u52a8\u6001\u8c03\u6574\u6c34\u5370\u5f3a\u5ea6\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u9608\u503c\u6216\u4efb\u52a1\u7279\u5b9a\u8c03\u4f18\uff0c\u5728\u8de8\u4efb\u52a1\u573a\u666f\u4e2d\u63d0\u5347\u6587\u672c\u8d28\u91cf\u800c\u4e0d\u727a\u7272\u68c0\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709LLM\u6c34\u5370\u65b9\u6cd5\u5728\u4f4e\u71b5\u573a\u666f\u4e0b\u4f1a\u5bfc\u81f4\u6587\u672c\u8d28\u91cf\u4e0b\u964d\uff0c\u4e14\u4f9d\u8d56\u71b5\u9608\u503c\u7684\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u8c03\u4f18\uff0c\u5bf9\u672a\u77e5\u6216\u8de8\u4efb\u52a1\u573a\u666f\u9002\u5e94\u6027\u5dee\u3002", "method": "\u901a\u8fc7logits\u805a\u7c7b\u5c06\u6587\u672c\u751f\u6210\u5212\u5206\u4e3a\u8bed\u4e49\u72b6\u6001\uff0c\u5efa\u7acb\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u71b5\u9608\u503c\uff0c\u5728\u7ed3\u6784\u5316\u5185\u5bb9\u4e2d\u4fdd\u6301\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\u5d4c\u5165\u9c81\u68d2\u6c34\u5370\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u8de8\u4efb\u52a1\u4e2d\u63d0\u9ad8\u4e86\u6587\u672c\u8d28\u91cf\uff0c\u4e14\u6ca1\u6709\u727a\u7272\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u611f\u77e5\u9608\u503c\u6c34\u5370\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u6c34\u5370\u65b9\u6cd5\u5728\u6587\u672c\u8d28\u91cf\u548c\u9002\u5e94\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.02387", "categories": ["cs.SE", "cs.AI", "cs.LG", "68T07", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.02387", "abs": "https://arxiv.org/abs/2510.02387", "authors": ["FAIR CodeGen team", "Quentin Carbonneaux", "Gal Cohen", "Jonas Gehring", "Jacob Kahn", "Jannik Kossen", "Felix Kreuk", "Emily McMilin", "Michel Meyer", "Yuxiang Wei", "David Zhang", "Kunhao Zheng", "Jordi Armengol-Estap\u00e9", "Pedram Bashiri", "Maximilian Beck", "Pierre Chambon", "Abhishek Charnalia", "Chris Cummins", "Juliette Decugis", "Zacharias V. Fisches", "Fran\u00e7ois Fleuret", "Fabian Gloeckle", "Alex Gu", "Michael Hassid", "Daniel Haziza", "Badr Youbi Idrissi", "Christian Keller", "Rahul Kindi", "Hugh Leather", "Gallil Maimon", "Aram Markosyan", "Francisco Massa", "Pierre-Emmanuel Mazar\u00e9", "Vegard Mella", "Naila Murray", "Keyur Muzumdar", "Peter O'Hearn", "Matteo Pagliardini", "Dmitrii Pedchenko", "Tal Remez", "Volker Seeker", "Marco Selvi", "Oren Sultan", "Sida Wang", "Luca Wehrstedt", "Ori Yoran", "Lingming Zhang", "Taco Cohen", "Yossi Adi", "Gabriel Synnaeve"], "title": "CWM: An Open-Weights LLM for Research on Code Generation with World Models", "comment": "58 pages", "summary": "We release Code World Model (CWM), a 32-billion-parameter open-weights LLM,\nto advance research on code generation with world models. To improve code\nunderstanding beyond what can be learned from training on static code alone, we\nmid-train CWM on a large amount of observation-action trajectories from Python\ninterpreter and agentic Docker environments, and perform extensive multi-task\nreasoning RL in verifiable coding, math, and multi-turn software engineering\nenvironments. With CWM, we provide a strong testbed for researchers to explore\nthe opportunities world modeling affords for improving code generation with\nreasoning and planning in computational environments. We present first steps of\nhow world models can benefit agentic coding, enable step-by-step simulation of\nPython code execution, and show early results of how reasoning can benefit from\nthe latter. CWM is a dense, decoder-only LLM trained with a context size of up\nto 131k tokens. Independent of its world modeling capabilities, CWM offers\nstrong performance on general coding and math tasks: it reaches pass@1 scores\nof 65.8% on SWE-bench Verified (with test-time scaling), 68.6% on\nLiveCodeBench, 96.6% on Math-500, and 76.0% on AIME 2024. To support further\nresearch on code world modeling, we release model checkpoints after\nmid-training, SFT, and RL.", "AI": {"tldr": "Code World Model (CWM) \u662f\u4e00\u4e2a320\u4ebf\u53c2\u6570\u7684\u5f00\u6e90LLM\uff0c\u901a\u8fc7\u5728Python\u89e3\u91ca\u5668\u548cDocker\u73af\u5883\u4e2d\u8bad\u7ec3\u89c2\u5bdf-\u884c\u52a8\u8f68\u8ff9\uff0c\u7ed3\u5408\u591a\u4efb\u52a1\u63a8\u7406\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u5347\u4ee3\u7801\u751f\u6210\u548c\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u8d85\u8d8a\u4ec5\u4ece\u9759\u6001\u4ee3\u7801\u8bad\u7ec3\u4e2d\u83b7\u5f97\u7684\u7406\u89e3\u80fd\u529b\uff0c\u63a2\u7d22\u4e16\u754c\u6a21\u578b\u5982\u4f55\u901a\u8fc7\u73af\u5883\u4ea4\u4e92\u63d0\u5347\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\u3002", "method": "\u5728Python\u89e3\u91ca\u5668\u548cDocker\u73af\u5883\u4e2d\u8fdb\u884c\u5927\u89c4\u6a21\u89c2\u5bdf-\u884c\u52a8\u8f68\u8ff9\u7684\u4e2d\u671f\u8bad\u7ec3\uff0c\u5e76\u5728\u53ef\u9a8c\u8bc1\u7684\u7f16\u7801\u3001\u6570\u5b66\u548c\u591a\u8f6e\u8f6f\u4ef6\u5de5\u7a0b\u73af\u5883\u4e2d\u8fdb\u884c\u591a\u4efb\u52a1\u63a8\u7406\u5f3a\u5316\u5b66\u4e60\u3002", "result": "CWM\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff1aSWE-bench Verified 65.8%\u3001LiveCodeBench 68.6%\u3001Math-500 96.6%\u3001AIME 2024 76.0%\u3002\u6a21\u578b\u652f\u6301Python\u4ee3\u7801\u9010\u6b65\u6267\u884c\u6a21\u62df\uff0c\u5e76\u5c55\u793a\u4e86\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u3002", "conclusion": "CWM\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u63a2\u7d22\u4e16\u754c\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5e94\u7528\u7684\u5f3a\u5927\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5c55\u793a\u4e86\u4e16\u754c\u6a21\u578b\u5728\u667a\u80fd\u7f16\u7801\u548c\u4ee3\u7801\u6267\u884c\u6a21\u62df\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.02418", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02418", "abs": "https://arxiv.org/abs/2510.02418", "authors": ["Sagnik Anupam", "Davis Brown", "Shuo Li", "Eric Wong", "Hamed Hassani", "Osbert Bastani"], "title": "BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks", "comment": null, "summary": "LLM web agents now browse and take actions on the open web, yet current agent\nevaluations are constrained to sandboxed environments or artificial tasks. We\nintroduce BrowserArena, a live open-web agent evaluation platform that collects\nuser-submitted tasks, runs Arena-style head-to-head comparisons, and uses\nstep-level human feedback to surface failure modes. Collecting and analyzing\nstep-level annotations on the agent traces, we identify three consistent\nfailure modes: captcha resolution, pop-up banner removal, and direct navigation\nto URLs. By constructing targeted datasets to further study these tasks, we\ndiscover variations in how different language models navigate these failure\nmodes. We find, for example, that o4-mini deploys a wider variety of strategies\nto circumvent captcha resolution than other models and DeepSeek-R1 consistently\nmisleads users about captcha resolution. Our findings surface both the\ndiversity and brittleness of current web agents. More broadly, our benchmarking\nmethodology provides an approach to evaluating and understanding web agent\nfailure modes at scale.", "AI": {"tldr": "BrowserArena\u662f\u4e00\u4e2a\u5f00\u653e\u7684\u7f51\u9875\u4ee3\u7406\u8bc4\u4f30\u5e73\u53f0\uff0c\u901a\u8fc7\u7528\u6237\u63d0\u4ea4\u4efb\u52a1\u3001Arena\u5f0f\u5bf9\u6bd4\u548c\u6b65\u9aa4\u7ea7\u4eba\u5de5\u53cd\u9988\u6765\u8bc6\u522b\u7f51\u9875\u4ee3\u7406\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u53d1\u73b0\u4e86\u9a8c\u8bc1\u7801\u89e3\u51b3\u3001\u5f39\u7a97\u79fb\u9664\u548c\u76f4\u63a5URL\u5bfc\u822a\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u7f51\u9875\u4ee3\u7406\u8bc4\u4f30\u5c40\u9650\u4e8e\u6c99\u76d2\u73af\u5883\u6216\u4eba\u5de5\u4efb\u52a1\uff0c\u9700\u8981\u771f\u5b9e\u5f00\u653e\u7f51\u9875\u73af\u5883\u4e0b\u7684\u8bc4\u4f30\u5e73\u53f0\u6765\u53d1\u73b0\u5b9e\u9645\u4f7f\u7528\u4e2d\u7684\u95ee\u9898\u3002", "method": "\u6784\u5efaBrowserArena\u5e73\u53f0\uff0c\u6536\u96c6\u7528\u6237\u4efb\u52a1\uff0c\u8fdb\u884cArena\u5f0f\u5bf9\u6bd4\u8bc4\u4f30\uff0c\u4f7f\u7528\u6b65\u9aa4\u7ea7\u4eba\u5de5\u53cd\u9988\u5206\u6790\u4ee3\u7406\u8f68\u8ff9\uff0c\u5e76\u9488\u5bf9\u53d1\u73b0\u7684\u5931\u8d25\u6a21\u5f0f\u6784\u5efa\u4e13\u95e8\u6570\u636e\u96c6\u8fdb\u884c\u6df1\u5165\u7814\u7a76\u3002", "result": "\u8bc6\u522b\u51fa\u4e09\u4e2a\u4e00\u81f4\u7684\u5931\u8d25\u6a21\u5f0f\uff1a\u9a8c\u8bc1\u7801\u89e3\u51b3\u3001\u5f39\u7a97\u79fb\u9664\u548c\u76f4\u63a5URL\u5bfc\u822a\u3002\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u8868\u73b0\u5404\u5f02\uff0c\u5982o4-mini\u4f7f\u7528\u66f4\u591a\u7b56\u7565\u7ed5\u8fc7\u9a8c\u8bc1\u7801\uff0cDeepSeek-R1\u5728\u9a8c\u8bc1\u7801\u89e3\u51b3\u4e0a\u8bef\u5bfc\u7528\u6237\u3002", "conclusion": "\u5f53\u524d\u7f51\u9875\u4ee3\u7406\u5b58\u5728\u591a\u6837\u6027\u548c\u8106\u5f31\u6027\uff0c\u63d0\u51fa\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u8bc4\u4f30\u548c\u7406\u89e3\u7f51\u9875\u4ee3\u7406\u5931\u8d25\u6a21\u5f0f\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2510.02349", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02349", "abs": "https://arxiv.org/abs/2510.02349", "authors": ["Hamed Fard", "Tobias Schalau", "Gerhard Wunder"], "title": "An Investigation into the Performance of Non-Contrastive Self-Supervised Learning Methods for Network Intrusion Detection", "comment": null, "summary": "Network intrusion detection, a well-explored cybersecurity field, has\npredominantly relied on supervised learning algorithms in the past two decades.\nHowever, their limitations in detecting only known anomalies prompt the\nexploration of alternative approaches. Motivated by the success of\nself-supervised learning in computer vision, there is a rising interest in\nadapting this paradigm for network intrusion detection. While prior research\nmainly delved into contrastive self-supervised methods, the efficacy of\nnon-contrastive methods, in conjunction with encoder architectures serving as\nthe representation learning backbone and augmentation strategies that determine\nwhat is learned, remains unclear for effective attack detection. This paper\ncompares the performance of five non-contrastive self-supervised learning\nmethods using three encoder architectures and six augmentation strategies.\nNinety experiments are systematically conducted on two network intrusion\ndetection datasets, UNSW-NB15 and 5G-NIDD. For each self-supervised model, the\ncombination of encoder architecture and augmentation method yielding the\nhighest average precision, recall, F1-score, and AUCROC is reported.\nFurthermore, by comparing the best-performing models to two unsupervised\nbaselines, DeepSVDD, and an Autoencoder, we showcase the competitiveness of the\nnon-contrastive methods for attack detection. Code at:\nhttps://github.com/renje4z335jh4/non_contrastive_SSL_NIDS", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e94\u79cd\u975e\u5bf9\u6bd4\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5728\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u901a\u8fc790\u4e2a\u7cfb\u7edf\u5b9e\u9a8c\u53d1\u73b0\u8fd9\u4e9b\u65b9\u6cd5\u5728\u653b\u51fb\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u5728\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u4e2d\u53ea\u80fd\u68c0\u6d4b\u5df2\u77e5\u5f02\u5e38\uff0c\u800c\u81ea\u76d1\u7763\u5b66\u4e60\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u6210\u529f\u6fc0\u53d1\u4e86\u5c06\u5176\u5e94\u7528\u4e8e\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7684\u5174\u8da3\u3002\u4e4b\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5bf9\u6bd4\u65b9\u6cd5\uff0c\u975e\u5bf9\u6bd4\u65b9\u6cd5\u7684\u6709\u6548\u6027\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u4f7f\u7528\u4e09\u79cd\u7f16\u7801\u5668\u67b6\u6784\u548c\u516d\u79cd\u589e\u5f3a\u7b56\u7565\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e94\u79cd\u975e\u5bf9\u6bd4\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u3002\u5728UNSW-NB15\u548c5G-NIDD\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e8690\u4e2a\u5b9e\u9a8c\u3002", "result": "\u62a5\u544a\u4e86\u6bcf\u4e2a\u81ea\u76d1\u7763\u6a21\u578b\u5728\u5e73\u5747\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548cAUCROC\u65b9\u9762\u7684\u6700\u4f73\u7ec4\u5408\u3002\u4e0eDeepSVDD\u548cAutoencoder\u7b49\u65e0\u76d1\u7763\u57fa\u7ebf\u76f8\u6bd4\uff0c\u975e\u5bf9\u6bd4\u65b9\u6cd5\u8868\u73b0\u51fa\u7ade\u4e89\u529b\u3002", "conclusion": "\u975e\u5bf9\u6bd4\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5728\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u4e2d\u5177\u6709\u7ade\u4e89\u529b\uff0c\u4e3a\u68c0\u6d4b\u672a\u77e5\u653b\u51fb\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.02389", "categories": ["cs.SE", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02389", "abs": "https://arxiv.org/abs/2510.02389", "authors": ["Haoran Xi", "Minghao Shao", "Brendan Dolan-Gavitt", "Muhammad Shafique", "Ramesh Karri"], "title": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization", "comment": null, "summary": "Large language models show promise for vulnerability discovery, yet\nprevailing methods inspect code in isolation, struggle with long contexts, and\nfocus on coarse function- or file-level detections - offering limited\nactionable guidance to engineers who need precise line-level localization and\ntargeted patches in real-world software development. We present T2L-Agent\n(Trace-to-Line Agent), a project-level, end-to-end framework that plans its own\nanalysis and progressively narrows scope from modules to exact vulnerable\nlines. T2L-Agent couples multi-round feedback with an Agentic Trace Analyzer\n(ATA) that fuses runtime evidence - crash points, stack traces, and coverage\ndeltas - with AST-based code chunking, enabling iterative refinement beyond\nsingle pass predictions and translating symptoms into actionable, line-level\ndiagnoses. To benchmark line-level vulnerability discovery, we introduce\nT2L-ARVO, a diverse, expert-verified 50-case benchmark spanning five crash\nfamilies and real-world projects. T2L-ARVO is specifically designed to support\nboth coarse-grained detection and fine-grained localization, enabling rigorous\nevaluation of systems that aim to move beyond file-level predictions. On\nT2L-ARVO, T2L-Agent achieves up to 58.0% detection and 54.8% line-level\nlocalization, substantially outperforming baselines. Together, the framework\nand benchmark push LLM-based vulnerability detection from coarse identification\ntoward deployable, robust, precision diagnostics that reduce noise and\naccelerate patching in open-source software workflows.", "AI": {"tldr": "T2L-Agent\u662f\u4e00\u4e2a\u9879\u76ee\u7ea7\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u6a21\u5757\u9010\u6b65\u7f29\u5c0f\u8303\u56f4\u5230\u5177\u4f53\u6f0f\u6d1e\u884c\u53f7\uff0c\u7ed3\u5408\u8fd0\u884c\u65f6\u8bc1\u636e\u548cAST\u4ee3\u7801\u5206\u5757\uff0c\u5b9e\u73b0\u7cbe\u786e\u7684\u6f0f\u6d1e\u5b9a\u4f4d\u548c\u4fee\u590d\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u5b64\u7acb\u5206\u6790\u4ee3\u7801\u3001\u96be\u4ee5\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u3001\u4e3b\u8981\u5173\u6ce8\u51fd\u6570\u6216\u6587\u4ef6\u7ea7\u522b\u7684\u7c97\u7c92\u5ea6\u68c0\u6d4b\uff0c\u65e0\u6cd5\u4e3a\u5de5\u7a0b\u5e08\u63d0\u4f9b\u7cbe\u786e\u7684\u884c\u7ea7\u5b9a\u4f4d\u548c\u9488\u5bf9\u6027\u8865\u4e01\u6307\u5bfc\u3002", "method": "T2L-Agent\u91c7\u7528\u591a\u8f6e\u53cd\u9988\u673a\u5236\uff0c\u7ed3\u5408Agentic Trace Analyzer(ATA)\u878d\u5408\u8fd0\u884c\u65f6\u8bc1\u636e\uff08\u5d29\u6e83\u70b9\u3001\u5806\u6808\u8ddf\u8e2a\u3001\u8986\u76d6\u7387\u5dee\u5f02\uff09\u548c\u57fa\u4e8eAST\u7684\u4ee3\u7801\u5206\u5757\uff0c\u5b9e\u73b0\u8fed\u4ee3\u7cbe\u70bc\u7684\u884c\u7ea7\u8bca\u65ad\u3002", "result": "\u5728T2L-ARVO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cT2L-Agent\u8fbe\u523058.0%\u7684\u68c0\u6d4b\u7387\u548c54.8%\u7684\u884c\u7ea7\u5b9a\u4f4d\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u548c\u57fa\u51c6\u6d4b\u8bd5\u5171\u540c\u63a8\u52a8\u57fa\u4e8eLLM\u7684\u6f0f\u6d1e\u68c0\u6d4b\u4ece\u7c97\u7c92\u5ea6\u8bc6\u522b\u5411\u53ef\u90e8\u7f72\u3001\u9c81\u68d2\u3001\u7cbe\u786e\u7684\u8bca\u65ad\u53d1\u5c55\uff0c\u51cf\u5c11\u566a\u97f3\u5e76\u52a0\u901f\u5f00\u6e90\u8f6f\u4ef6\u5de5\u4f5c\u6d41\u4e2d\u7684\u8865\u4e01\u8fc7\u7a0b\u3002"}}
{"id": "2510.02423", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02423", "abs": "https://arxiv.org/abs/2510.02423", "authors": ["Hang Wu", "Yujun Cai", "Haonan Ge", "Hongkai Chen", "Ming-Hsuan Yang", "Yiwei Wang"], "title": "RefineShot: Rethinking Cinematography Understanding with Foundational Skill Evaluation", "comment": null, "summary": "Cinematography understanding refers to the ability to recognize not only the\nvisual content of a scene but also the cinematic techniques that shape\nnarrative meaning. This capability is attracting increasing attention, as it\nenhances multimodal understanding in real-world applications and underpins\ncoherent content creation in film and media. As the most comprehensive\nbenchmark for this task, ShotBench spans a wide range of cinematic concepts and\nVQA-style evaluations, with ShotVL achieving state-of-the-art results on it.\nHowever, our analysis reveals that ambiguous option design in ShotBench and\nShotVL's shortcomings in reasoning consistency and instruction adherence\nundermine evaluation reliability, limiting fair comparison and hindering future\nprogress. To overcome these issues, we systematically refine ShotBench through\nconsistent option restructuring, conduct the first critical analysis of\nShotVL's reasoning behavior, and introduce an extended evaluation protocol that\njointly assesses task accuracy and core model competencies. These efforts lead\nto RefineShot, a refined and expanded benchmark that enables more reliable\nassessment and fosters future advances in cinematography understanding.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86ShotBench\u57fa\u51c6\u6d4b\u8bd5\u5728\u7535\u5f71\u6444\u5f71\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5305\u62ec\u9009\u9879\u8bbe\u8ba1\u6a21\u7cca\u548c\u6a21\u578b\u63a8\u7406\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86RefineShot\u57fa\u51c6\u6765\u6539\u8fdb\u8bc4\u4f30\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u7684ShotBench\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u9009\u9879\u8bbe\u8ba1\u6a21\u7cca\u3001\u6a21\u578b\u63a8\u7406\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u7535\u5f71\u6444\u5f71\u7406\u89e3\u4efb\u52a1\u7684\u516c\u5e73\u8bc4\u4f30\u548c\u672a\u6765\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u4e00\u81f4\u7684\u9009\u9879\u91cd\u6784\u7cfb\u7edf\u5316\u6539\u8fdbShotBench\uff0c\u9996\u6b21\u5bf9ShotVL\u7684\u63a8\u7406\u884c\u4e3a\u8fdb\u884c\u6279\u5224\u6027\u5206\u6790\uff0c\u5e76\u5f15\u5165\u8054\u5408\u8bc4\u4f30\u4efb\u52a1\u51c6\u786e\u6027\u548c\u6838\u5fc3\u6a21\u578b\u80fd\u529b\u7684\u6269\u5c55\u534f\u8bae\u3002", "result": "\u5f00\u53d1\u4e86RefineShot\u57fa\u51c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u7ecf\u8fc7\u6539\u8fdb\u548c\u6269\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u5e76\u4fc3\u8fdb\u7535\u5f71\u6444\u5f71\u7406\u89e3\u7684\u672a\u6765\u53d1\u5c55\u3002", "conclusion": "RefineShot\u57fa\u51c6\u89e3\u51b3\u4e86ShotBench\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u7535\u5f71\u6444\u5f71\u7406\u89e3\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2510.02356", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02356", "abs": "https://arxiv.org/abs/2510.02356", "authors": ["Xinjie Shen", "Mufei Li", "Pan Li"], "title": "Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark", "comment": null, "summary": "The deployment of Large Language Models (LLMs) in embodied agents creates an\nurgent need to measure their privacy awareness in the physical world. Existing\nevaluation methods, however, are confined to natural language based scenarios.\nTo bridge this gap, we introduce EAPrivacy, a comprehensive evaluation\nbenchmark designed to quantify the physical-world privacy awareness of\nLLM-powered agents. EAPrivacy utilizes procedurally generated scenarios across\nfour tiers to test an agent's ability to handle sensitive objects, adapt to\nchanging environments, balance task execution with privacy constraints, and\nresolve conflicts with social norms. Our measurements reveal a critical deficit\nin current models. The top-performing model, Gemini 2.5 Pro, achieved only 59\\%\naccuracy in scenarios involving changing physical environments. Furthermore,\nwhen a task was accompanied by a privacy request, models prioritized completion\nover the constraint in up to 86\\% of cases. In high-stakes situations pitting\nprivacy against critical social norms, leading models like GPT-4o and\nClaude-3.5-haiku disregarded the social norm over 15\\% of the time. These\nfindings, demonstrated by our benchmark, underscore a fundamental misalignment\nin LLMs regarding physically grounded privacy and establish the need for more\nrobust, physically-aware alignment.", "AI": {"tldr": "EAPrivacy\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u7269\u7406\u4e16\u754c\u4e2d\u9690\u79c1\u610f\u8bc6\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u7269\u7406\u73af\u5883\u53d8\u5316\u3001\u9690\u79c1\u7ea6\u675f\u4e0e\u4efb\u52a1\u5e73\u8861\u3001\u793e\u4f1a\u89c4\u8303\u51b2\u7a81\u7b49\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4ec5\u9650\u4e8e\u81ea\u7136\u8bed\u8a00\u573a\u666f\uff0c\u9700\u8981\u6d4b\u91cfLLM\u667a\u80fd\u4f53\u5728\u7269\u7406\u4e16\u754c\u4e2d\u7684\u9690\u79c1\u610f\u8bc6\u3002", "method": "\u4f7f\u7528\u7a0b\u5e8f\u751f\u6210\u7684\u56db\u4e2a\u5c42\u7ea7\u573a\u666f\u6d4b\u8bd5\u667a\u80fd\u4f53\u5904\u7406\u654f\u611f\u5bf9\u8c61\u3001\u9002\u5e94\u73af\u5883\u53d8\u5316\u3001\u5e73\u8861\u4efb\u52a1\u4e0e\u9690\u79c1\u7ea6\u675f\u3001\u89e3\u51b3\u793e\u4f1a\u89c4\u8303\u51b2\u7a81\u7684\u80fd\u529b\u3002", "result": "\u8868\u73b0\u6700\u4f73\u7684Gemini 2.5 Pro\u5728\u7269\u7406\u73af\u5883\u53d8\u5316\u573a\u666f\u4e2d\u4ec5\u8fbe\u523059%\u51c6\u786e\u7387\uff1b86%\u60c5\u51b5\u4e0b\u6a21\u578b\u4f18\u5148\u5b8c\u6210\u4efb\u52a1\u800c\u975e\u9690\u79c1\u7ea6\u675f\uff1bGPT-4o\u548cClaude-3.5-haiku\u5728\u9690\u79c1\u4e0e\u793e\u4f1a\u89c4\u8303\u51b2\u7a81\u65f6\u8d85\u8fc715%\u5ffd\u89c6\u793e\u4f1a\u89c4\u8303\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u7269\u7406\u57fa\u7840\u9690\u79c1\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u9519\u4f4d\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u7269\u7406\u611f\u77e5\u5bf9\u9f50\u3002"}}
{"id": "2510.02393", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02393", "abs": "https://arxiv.org/abs/2510.02393", "authors": ["Jianqing Zhang", "Wei Xia", "Hande Dong", "Qiang Lin", "Jian Cao"], "title": "AP2O: Correcting LLM-Generated Code Errors Type by Type Like Humans via Adaptive Progressive Preference Optimization", "comment": null, "summary": "LLMs' code generation capabilities have yielded substantial improvements in\nthe effectiveness of programming tasks. However, LLM-generated code still\nsuffers from compilation and runtime errors. Existing offline preference\noptimization methods primarily focus on enhancing LLMs' coding abilities using\npass/fail signals in the preference data, overlooking the deep-level error\ntypes in the failed codes. To address this, we propose Adaptively Progressive\nPreference Optimization (AP2O) for coding (i.e., AP2O-Coder), a method that\nguides LLMs adaptively and methodically to reduce code errors for code\ngeneration. Specifically, we construct an error notebook from failed codes and\nprogressively optimize the LLM to correct errors type by type. Furthermore, we\nadaptively replay error types to tailor to the LLM's changing weaknesses\nthroughout the training process. Through extensive experiments on both code and\ngeneral LLMs (Llama, Qwen, and DeepSeek series) with parameters ranging from\n0.5B to 34B, our AP2O-Coder improves code generation performance by up to 3% in\npass@k while using less preference data. Code: https://github.com/TsingZ0/AP2O", "AI": {"tldr": "AP2O-Coder\u662f\u4e00\u79cd\u81ea\u9002\u5e94\u6e10\u8fdb\u5f0f\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u9519\u8bef\u7b14\u8bb0\u672c\u5e76\u9010\u6b65\u7ea0\u6b63\u4e0d\u540c\u7c7b\u578b\u9519\u8bef\uff0c\u63d0\u5347LLM\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u5728\u51cf\u5c11\u504f\u597d\u6570\u636e\u4f7f\u7528\u7684\u540c\u65f6\u5c06pass@k\u6307\u6807\u63d0\u5347\u8fbe3%\u3002", "motivation": "\u73b0\u6709\u79bb\u7ebf\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4ee3\u7801\u901a\u8fc7/\u5931\u8d25\u4fe1\u53f7\uff0c\u5ffd\u7565\u4e86\u5931\u8d25\u4ee3\u7801\u4e2d\u7684\u6df1\u5c42\u9519\u8bef\u7c7b\u578b\uff0c\u5bfc\u81f4LLM\u751f\u6210\u7684\u4ee3\u7801\u4ecd\u5b58\u5728\u7f16\u8bd1\u548c\u8fd0\u884c\u65f6\u9519\u8bef\u3002", "method": "\u6784\u5efa\u9519\u8bef\u7b14\u8bb0\u672c\u8bb0\u5f55\u5931\u8d25\u4ee3\u7801\u4e2d\u7684\u9519\u8bef\u7c7b\u578b\uff0c\u7136\u540e\u9010\u6b65\u4f18\u5316LLM\u6309\u7c7b\u578b\u7ea0\u6b63\u9519\u8bef\uff0c\u5e76\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u81ea\u9002\u5e94\u91cd\u653e\u9519\u8bef\u7c7b\u578b\u4ee5\u9002\u5e94LLM\u4e0d\u65ad\u53d8\u5316\u7684\u5f31\u70b9\u3002", "result": "\u57280.5B\u523034B\u53c2\u6570\u7684\u4ee3\u7801\u548c\u901a\u7528LLM\uff08Llama\u3001Qwen\u3001DeepSeek\u7cfb\u5217\uff09\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cAP2O-Coder\u4f7f\u7528\u66f4\u5c11\u504f\u597d\u6570\u636e\u5c06\u4ee3\u7801\u751f\u6210\u6027\u80fd\u63d0\u5347\u8fbe3%\uff08pass@k\u6307\u6807\uff09\u3002", "conclusion": "AP2O-Coder\u901a\u8fc7\u5173\u6ce8\u6df1\u5c42\u9519\u8bef\u7c7b\u578b\u548c\u81ea\u9002\u5e94\u6e10\u8fdb\u4f18\u5316\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2510.02480", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02480", "abs": "https://arxiv.org/abs/2510.02480", "authors": ["Andrea Wynn", "Metod Jazbec", "Charith Peris", "Rinat Khaziev", "Anqi Liu", "Daniel Khashabi", "Eric Nalisnick"], "title": "Safe and Efficient In-Context Learning via Risk Control", "comment": null, "summary": "Large language models (LLMs) demonstrate a remarkable ability to learn new\ntasks from a few in-context examples. However, this flexibility introduces\nsafety concerns: LLMs can be influenced by incorrect or malicious\ndemonstrations -- for example, if an adversary tampers with or injects harmful\nexamples without a human supervisor noticing. This motivates principled designs\nin which the system itself includes built-in mechanisms to guard against such\nattacks. We propose a novel approach to limit the degree to which harmful\ndemonstrations can degrade model performance. First, we define a baseline\n``safe'' behavior for the model -- the model's performance given no in-context\ndemonstrations (zero-shot). Next, we apply distribution-free risk control\n(DFRC) to control the extent to which in-context samples can decay performance\nbelow zero-shot. We achieve this by leveraging dynamic early exit prediction,\nignoring later attention heads that attend the most to the unsafe inputs.\nFinally, we propose modifications to DFRC that allow it to both control risk\nfor harmful inputs \\textit{and} leverage performance and efficiency gains on\nhelpful inputs. We present both theoretical and empirical results showing that\nour approach can effectively control risk for harmful in-context demonstrations\nwhile simultaneously achieving substantial computational efficiency gains with\nhelpful demonstrations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u65e0\u5173\u98ce\u9669\u63a7\u5236\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u63d0\u524d\u9000\u51fa\u673a\u5236\u6765\u9632\u5fa1\u6076\u610f\u4e0a\u4e0b\u6587\u793a\u4f8b\u5bf9LLM\u6027\u80fd\u7684\u635f\u5bb3\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u6709\u76ca\u793a\u4f8b\u7684\u6027\u80fd\u63d0\u5347\u548c\u8ba1\u7b97\u6548\u7387\u589e\u76ca\u3002", "motivation": "LLMs\u80fd\u591f\u4ece\u5c11\u91cf\u4e0a\u4e0b\u6587\u793a\u4f8b\u4e2d\u5b66\u4e60\u65b0\u4efb\u52a1\uff0c\u4f46\u8fd9\u79cd\u7075\u6d3b\u6027\u5e26\u6765\u4e86\u5b89\u5168\u9690\u60a3\uff1a\u6076\u610f\u793a\u4f8b\u53ef\u80fd\u5728\u4e0d\u88ab\u5bdf\u89c9\u7684\u60c5\u51b5\u4e0b\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\uff0c\u56e0\u6b64\u9700\u8981\u5185\u7f6e\u9632\u5fa1\u673a\u5236\u3002", "method": "\u5b9a\u4e49\u96f6\u6837\u672c\u4e0b\u7684\u5b89\u5168\u884c\u4e3a\u57fa\u51c6\uff0c\u5e94\u7528\u5206\u5e03\u65e0\u5173\u98ce\u9669\u63a7\u5236\uff0c\u5229\u7528\u52a8\u6001\u63d0\u524d\u9000\u51fa\u9884\u6d4b\u673a\u5236\uff0c\u5ffd\u7565\u5bf9\u4e0d\u5b89\u5168\u8f93\u5165\u5173\u6ce8\u5ea6\u6700\u9ad8\u7684\u540e\u7eed\u6ce8\u610f\u529b\u5934\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63a7\u5236\u6709\u5bb3\u4e0a\u4e0b\u6587\u793a\u4f8b\u7684\u98ce\u9669\uff0c\u540c\u65f6\u5728\u6709\u76ca\u793a\u4f8b\u4e0a\u5b9e\u73b0\u663e\u8457\u7684\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u9632\u5fa1\u6076\u610f\u653b\u51fb\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u5bf9\u6709\u76ca\u8f93\u5165\u7684\u5229\u7528\u6548\u7387\uff0c\u4e3aLLM\u5b89\u5168\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.02357", "categories": ["cs.CR", "cs.AI", "K.4.1; K.4.2; K.6.5; I.2.0"], "pdf": "https://arxiv.org/pdf/2510.02357", "abs": "https://arxiv.org/abs/2510.02357", "authors": ["Grace Billiris", "Asif Gill", "Madhushi Bandara"], "title": "Privacy in the Age of AI: A Taxonomy of Data Risks", "comment": "12 pages, 2 figures, 4 tables", "summary": "Artificial Intelligence (AI) systems introduce unprecedented privacy\nchallenges as they process increasingly sensitive data. Traditional privacy\nframeworks prove inadequate for AI technologies due to unique characteristics\nsuch as autonomous learning and black-box decision-making. This paper presents\na taxonomy classifying AI privacy risks, synthesised from 45 studies identified\nthrough systematic review. We identify 19 key risks grouped under four\ncategories: Dataset-Level, Model-Level, Infrastructure-Level, and Insider\nThreat Risks. Findings reveal a balanced distribution across these dimensions,\nwith human error (9.45%) emerging as the most significant factor. This taxonomy\nchallenges conventional security approaches that typically prioritise technical\ncontrols over human factors, highlighting gaps in holistic understanding. By\nbridging technical and behavioural dimensions of AI privacy, this paper\ncontributes to advancing trustworthy AI development and provides a foundation\nfor future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2aAI\u9690\u79c1\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff045\u9879\u7814\u7a76\u8bc6\u522b\u51fa19\u4e2a\u5173\u952e\u98ce\u9669\uff0c\u5206\u4e3a\u6570\u636e\u96c6\u7ea7\u3001\u6a21\u578b\u7ea7\u3001\u57fa\u7840\u8bbe\u65bd\u7ea7\u548c\u5185\u90e8\u5a01\u80c1\u56db\u4e2a\u7c7b\u522b\uff0c\u53d1\u73b0\u4eba\u4e3a\u9519\u8bef\u662f\u6700\u91cd\u8981\u7684\u98ce\u9669\u56e0\u7d20\u3002", "motivation": "\u4f20\u7edf\u9690\u79c1\u6846\u67b6\u65e0\u6cd5\u5e94\u5bf9AI\u6280\u672f\u7684\u72ec\u7279\u7279\u6027\uff08\u5982\u81ea\u4e3b\u5b66\u4e60\u548c\u9ed1\u76d2\u51b3\u7b56\uff09\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u7406\u89e3\u548c\u7ba1\u7406AI\u9690\u79c1\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff045\u9879\u7814\u7a76\uff0c\u6784\u5efaAI\u9690\u79c1\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u5c06\u98ce\u9669\u5206\u4e3a\u56db\u4e2a\u4e3b\u8981\u7c7b\u522b\u8fdb\u884c\u7efc\u5408\u5206\u6790\u3002", "result": "\u8bc6\u522b\u51fa19\u4e2a\u5173\u952e\u98ce\u9669\uff0c\u5728\u56db\u4e2a\u7c7b\u522b\u4e2d\u5206\u5e03\u5747\u8861\uff0c\u4eba\u4e3a\u9519\u8bef\u53609.45%\u662f\u6700\u663e\u8457\u56e0\u7d20\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u5b89\u5168\u65b9\u6cd5\u504f\u91cd\u6280\u672f\u63a7\u5236\u7684\u503e\u5411\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u901a\u8fc7\u8fde\u63a5AI\u9690\u79c1\u7684\u6280\u672f\u548c\u884c\u4e3a\u7ef4\u5ea6\uff0c\u4e3a\u53ef\u4fe1AI\u53d1\u5c55\u63d0\u4f9b\u57fa\u7840\uff0c\u5e76\u63ed\u793a\u4e86\u9700\u8981\u66f4\u5168\u9762\u7406\u89e3AI\u9690\u79c1\u98ce\u9669\u7684\u7814\u7a76\u7a7a\u767d\u3002"}}
{"id": "2510.02404", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02404", "abs": "https://arxiv.org/abs/2510.02404", "authors": ["Siddharth Agarwal", "Maria A. Rodriguez", "Rajkumar Buyya"], "title": "Dynamic Function Configuration and its Management in Serverless Computing: A Taxonomy and Future Directions", "comment": "34 pages, 2 figures, 2 tables, journal", "summary": "The serverless cloud computing model offers a framework where the service\nprovider abstracts the underlying infrastructure management from developers. In\nthis serverless model, FaaS provides an event-driven, function-oriented\ncomputing service characterised by fine-grained, usage-based pricing that\neliminates cost for idle resources. Platforms like AWS Lambda, Azure Functions,\nand Cloud Run Functions require developers to configure their function(s) with\nminimum operational resources for its successful execution. This resource\nallocation influences both the operational expense and the performance quality\nof these functions. However, a noticeable lack of platform transparency forces\ndevelopers to rely on expert knowledge or experience-based ad-hoc decisions to\nrequest desired function resources. This makes optimal resource configuration a\nnon-trivial task while adhering to performance constraints. Furthermore, while\ncommercial platforms often scale resources like CPU and network bandwidth\nproportional to memory, open-source frameworks permit independent configuration\nof function resources, introducing additional complexity for developers aiming\nto optimise their functions. These complexities have directed researchers to\nresolve developer challenges and advance towards an efficient server-less\nexecution model. In this article, we identify different aspects of resource\nconfiguration techniques in FaaS settings and propose a taxonomy of factors\nthat influence function design, configuration, run-time cost, and performance\nguarantees. We conduct an analysis of existing literature on resource\nconfiguration to present a comprehensive review of current studies on function\nconfiguration. We also identify existing research gaps and suggest future\nresearch directions to enhance function configuration and strengthen the\ncapabilities of serverless computing environments to drive its broader\nadoption.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86FaaS\u73af\u5883\u4e2d\u7684\u8d44\u6e90\u914d\u7f6e\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5f71\u54cd\u51fd\u6570\u8bbe\u8ba1\u3001\u914d\u7f6e\u3001\u8fd0\u884c\u65f6\u6210\u672c\u548c\u6027\u80fd\u4fdd\u8bc1\u7684\u56e0\u7d20\u5206\u7c7b\u6cd5\uff0c\u5e76\u5bf9\u73b0\u6709\u8d44\u6e90\u914d\u7f6e\u6587\u732e\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\u3002", "motivation": "\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u5e73\u53f0\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u8feb\u4f7f\u5f00\u53d1\u8005\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\u6216\u7ecf\u9a8c\u8fdb\u884c\u8d44\u6e90\u914d\u7f6e\u51b3\u7b56\uff0c\u8fd9\u4f7f\u5f97\u5728\u6ee1\u8db3\u6027\u80fd\u7ea6\u675f\u7684\u540c\u65f6\u5b9e\u73b0\u6700\u4f18\u8d44\u6e90\u914d\u7f6e\u6210\u4e3a\u4e00\u9879\u975e\u5e73\u51e1\u4efb\u52a1\u3002", "method": "\u8bc6\u522bFaaS\u73af\u5883\u4e2d\u8d44\u6e90\u914d\u7f6e\u6280\u672f\u7684\u4e0d\u540c\u65b9\u9762\uff0c\u63d0\u51fa\u5f71\u54cd\u51fd\u6570\u8bbe\u8ba1\u3001\u914d\u7f6e\u3001\u8fd0\u884c\u65f6\u6210\u672c\u548c\u6027\u80fd\u4fdd\u8bc1\u7684\u56e0\u7d20\u5206\u7c7b\u6cd5\uff0c\u5e76\u5bf9\u73b0\u6709\u8d44\u6e90\u914d\u7f6e\u6587\u732e\u8fdb\u884c\u5206\u6790\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u8d44\u6e90\u914d\u7f6e\u56e0\u7d20\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e86\u5f53\u524d\u51fd\u6570\u914d\u7f6e\u7814\u7a76\u73b0\u72b6\uff0c\u5e76\u8bc6\u522b\u4e86\u73b0\u6709\u7814\u7a76\u7a7a\u767d\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u589e\u5f3a\u51fd\u6570\u914d\u7f6e\u80fd\u529b\uff0c\u52a0\u5f3a\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u73af\u5883\u7684\u529f\u80fd\uff0c\u63a8\u52a8\u5176\u66f4\u5e7f\u6cdb\u91c7\u7528\u3002"}}
{"id": "2510.02528", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02528", "abs": "https://arxiv.org/abs/2510.02528", "authors": ["Shuhao Fu", "Esther Goldberg", "Ying Nian Wu", "Hongjing Lu"], "title": "Multimodal Function Vectors for Spatial Relations", "comment": null, "summary": "Large Multimodal Models (LMMs) demonstrate impressive in-context learning\nabilities from limited multimodal demonstrations, yet the internal mechanisms\nsupporting such task learning remain opaque. Building on prior work of large\nlanguage models, we show that a small subset of attention heads in the\nvision-language model OpenFlamingo-4B is responsible for transmitting\nrepresentations of spatial relations. The activations of these attention heads,\ntermed function vectors, can be extracted and manipulated to alter an LMM's\nperformance on relational tasks. First, using both synthetic and real image\ndatasets, we apply causal mediation analysis to identify attention heads that\nstrongly influence relational predictions, and extract multimodal function\nvectors that improve zero-shot accuracy at inference time. We further\ndemonstrate that these multimodal function vectors can be fine-tuned with a\nmodest amount of training data, while keeping LMM parameters frozen, to\nsignificantly outperform in-context learning baselines. Finally, we show that\nrelation-specific function vectors can be linearly combined to solve analogy\nproblems involving novel and untrained spatial relations, highlighting the\nstrong generalization ability of this approach. Our results show that LMMs\nencode spatial relational knowledge within localized internal structures, which\ncan be systematically extracted and optimized, thereby advancing our\nunderstanding of model modularity and enhancing control over relational\nreasoning in LMMs.", "AI": {"tldr": "\u672c\u6587\u8bc6\u522b\u4e86\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u8d1f\u8d23\u7a7a\u95f4\u5173\u7cfb\u8868\u793a\u7684\u6ce8\u610f\u529b\u5934\uff0c\u63d0\u53d6\u5e76\u64cd\u4f5c\u8fd9\u4e9b\"\u529f\u80fd\u5411\u91cf\"\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5173\u7cfb\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u80fd\u901a\u8fc7\u5fae\u8c03\u548c\u7ebf\u6027\u7ec4\u5408\u89e3\u51b3\u65b0\u7684\u7a7a\u95f4\u5173\u7cfb\u7c7b\u6bd4\u95ee\u9898\u3002", "motivation": "\u867d\u7136\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u4f46\u5176\u5185\u90e8\u652f\u6301\u4efb\u52a1\u5b66\u4e60\u7684\u673a\u5236\u4ecd\u4e0d\u900f\u660e\uff0c\u9700\u8981\u6df1\u5165\u7406\u89e3\u6a21\u578b\u5982\u4f55\u7f16\u7801\u548c\u5229\u7528\u7a7a\u95f4\u5173\u7cfb\u77e5\u8bc6\u3002", "method": "\u4f7f\u7528\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u8bc6\u522b\u5f71\u54cd\u5173\u7cfb\u9884\u6d4b\u7684\u6ce8\u610f\u529b\u5934\uff0c\u63d0\u53d6\u591a\u6a21\u6001\u529f\u80fd\u5411\u91cf\uff0c\u5e76\u5728\u4fdd\u6301\u6a21\u578b\u53c2\u6570\u51bb\u7ed3\u7684\u60c5\u51b5\u4e0b\u5bf9\u8fd9\u4e9b\u5411\u91cf\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u53ca\u7ebf\u6027\u7ec4\u5408\u5173\u7cfb\u7279\u5b9a\u7684\u529f\u80fd\u5411\u91cf\u3002", "result": "\u63d0\u53d6\u7684\u529f\u80fd\u5411\u91cf\u5728\u63a8\u7406\u65f6\u63d0\u9ad8\u4e86\u96f6\u6837\u672c\u51c6\u786e\u7387\uff0c\u7ecf\u8fc7\u5c11\u91cf\u6570\u636e\u5fae\u8c03\u540e\u663e\u8457\u4f18\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u57fa\u7ebf\uff0c\u5e76\u80fd\u901a\u8fc7\u7ebf\u6027\u7ec4\u5408\u89e3\u51b3\u672a\u7ecf\u8bad\u7ec3\u7684\u7a7a\u95f4\u5173\u7cfb\u7c7b\u6bd4\u95ee\u9898\u3002", "conclusion": "\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u5c40\u90e8\u5185\u90e8\u7ed3\u6784\u4e2d\u7f16\u7801\u7a7a\u95f4\u5173\u7cfb\u77e5\u8bc6\uff0c\u8fd9\u4e9b\u77e5\u8bc6\u53ef\u4ee5\u88ab\u7cfb\u7edf\u63d0\u53d6\u548c\u4f18\u5316\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u6a21\u578b\u6a21\u5757\u5316\u5e76\u589e\u5f3a\u5bf9\u5173\u7cfb\u63a8\u7406\u7684\u63a7\u5236\u3002"}}
{"id": "2510.02365", "categories": ["cs.CR", "math.AG", "math.NT"], "pdf": "https://arxiv.org/pdf/2510.02365", "abs": "https://arxiv.org/abs/2510.02365", "authors": ["Dongfang Zhao"], "title": "Bootstrapping as a Morphism: An Arithmetic Geometry Approach to Asymptotically Faster Homomorphic Encryption", "comment": null, "summary": "Fully Homomorphic Encryption (FHE) provides a powerful paradigm for secure\ncomputation, but its practical adoption is severely hindered by the prohibitive\ncomputational cost of its bootstrapping procedure. The complexity of all\ncurrent bootstrapping methods is fundamentally tied to the multiplicative depth\nof the decryption circuit, denoted $L_{dec}$, making it the primary performance\nbottleneck. This paper introduces a new approach to bootstrapping that\ncompletely bypasses the traditional circuit evaluation model. We apply the\ntools of modern arithmetic geometry to reframe the bootstrapping operation as a\ndirect geometric projection. Our framework models the space of ciphertexts as\nan affine scheme and rigorously defines the loci of decryptable and fresh\nciphertexts as distinct closed subschemes. The bootstrapping transformation is\nthen realized as a morphism between these two spaces. Computationally, this\nprojection is equivalent to solving a specific Closest Vector Problem (CVP)\ninstance on a highly structured ideal lattice, which we show can be done\nefficiently using a technique we call algebraic folding. The primary result of\nour work is a complete and provably correct bootstrapping algorithm with a\ncomputational complexity of $O(d \\cdot \\text{poly}(\\log q))$, where $d$ is the\nring dimension and $q$ is the ciphertext modulus. The significance of this\nresult lies in the complete elimination of the factor $L_{dec}$ from the\ncomplexity, representing a fundamental asymptotic improvement over the state of\nthe art. This geometric perspective offers a new and promising pathway toward\nachieving truly practical and high-performance FHE.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b97\u672f\u51e0\u4f55\u7684\u5168\u65b0\u540c\u6001\u52a0\u5bc6\u81ea\u4e3e\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u81ea\u4e3e\u64cd\u4f5c\u91cd\u6784\u4e3a\u51e0\u4f55\u6295\u5f71\uff0c\u5b8c\u5168\u7ed5\u8fc7\u4e86\u4f20\u7edf\u7535\u8def\u8bc4\u4f30\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u590d\u6742\u5ea6\u4e3aO(d\u00b7poly(log q))\u7684\u81ea\u4e3e\u7b97\u6cd5\uff0c\u6d88\u9664\u4e86L_dec\u56e0\u5b50\u3002", "motivation": "\u5168\u540c\u6001\u52a0\u5bc6(FHE)\u7684\u5b9e\u9645\u5e94\u7528\u53d7\u5230\u81ea\u4e3e\u8fc7\u7a0b\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u7684\u4e25\u91cd\u9650\u5236\uff0c\u5f53\u524d\u6240\u6709\u81ea\u4e3e\u65b9\u6cd5\u7684\u590d\u6742\u5ea6\u90fd\u4e0e\u89e3\u5bc6\u7535\u8def\u7684\u4e58\u6cd5\u6df1\u5ea6L_dec\u76f8\u5173\uff0c\u8fd9\u6210\u4e3a\u4e3b\u8981\u6027\u80fd\u74f6\u9888\u3002", "method": "\u5e94\u7528\u73b0\u4ee3\u7b97\u672f\u51e0\u4f55\u5de5\u5177\uff0c\u5c06\u81ea\u4e3e\u64cd\u4f5c\u91cd\u6784\u4e3a\u51e0\u4f55\u6295\u5f71\u3002\u5c06\u5bc6\u6587\u7a7a\u95f4\u5efa\u6a21\u4e3a\u4eff\u5c04\u6982\u5f62\uff0c\u5c06\u53ef\u89e3\u5bc6\u5bc6\u6587\u548c\u65b0\u9c9c\u5bc6\u6587\u7684\u8f68\u8ff9\u4e25\u683c\u5b9a\u4e49\u4e3a\u4e0d\u540c\u7684\u95ed\u5b50\u6982\u5f62\u3002\u81ea\u4e3e\u53d8\u6362\u5b9e\u73b0\u4e3a\u8fd9\u4e9b\u7a7a\u95f4\u4e4b\u95f4\u7684\u6001\u5c04\u3002\u8ba1\u7b97\u4e0a\uff0c\u8be5\u6295\u5f71\u7b49\u4ef7\u4e8e\u5728\u9ad8\u5ea6\u7ed3\u6784\u5316\u7684\u7406\u60f3\u683c\u4e0a\u89e3\u51b3\u7279\u5b9a\u7684\u6700\u8fd1\u5411\u91cf\u95ee\u9898(CVP)\uff0c\u4f7f\u7528\u79f0\u4e3a\u4ee3\u6570\u6298\u53e0\u7684\u6280\u672f\u9ad8\u6548\u5b9e\u73b0\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b8c\u6574\u4e14\u53ef\u8bc1\u660e\u6b63\u786e\u7684\u81ea\u4e3e\u7b97\u6cd5\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e3aO(d\u00b7poly(log q))\uff0c\u5176\u4e2dd\u662f\u73af\u7ef4\u5ea6\uff0cq\u662f\u5bc6\u6587\u6a21\u6570\u3002\u8be5\u7ed3\u679c\u5b8c\u5168\u6d88\u9664\u4e86\u590d\u6742\u5ea6\u4e2d\u7684L_dec\u56e0\u5b50\uff0c\u4ee3\u8868\u4e86\u76f8\u5bf9\u4e8e\u73b0\u6709\u6280\u672f\u7684\u6839\u672c\u6027\u6e10\u8fdb\u6539\u8fdb\u3002", "conclusion": "\u8fd9\u79cd\u51e0\u4f55\u89c6\u89d2\u4e3a\u5b9e\u73b0\u771f\u6b63\u5b9e\u7528\u548c\u9ad8\u6027\u80fd\u7684FHE\u63d0\u4f9b\u4e86\u4e00\u6761\u65b0\u7684\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2510.02504", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02504", "abs": "https://arxiv.org/abs/2510.02504", "authors": ["Mara Ulloa", "Jenna L. Butler", "Sankeerti Haniyur", "Courtney Miller", "Barrett Amos", "Advait Sarkar", "Margaret-Anne Storey"], "title": "Product Manager Practices for Delegating Work to Generative AI: \"Accountability must not be delegated to non-human actors\"", "comment": "12 pages, 4 figures, 1 table", "summary": "Generative AI (GenAI) is changing the nature of knowledge work, particularly\nfor Product Managers (PMs) in software development teams. While much software\nengineering research has focused on developers' interactions with GenAI, there\nis less understanding of how the work of PMs is evolving due to GenAI. To\naddress this gap, we conducted a mixed-methods study at Microsoft, a large,\nmultinational software company: surveying 885 PMs, analyzing telemetry data for\na subset of PMs (N=731), and interviewing a subset of 15 PMs. We contribute:\n(1) PMs' current GenAI adoption rates, uses cases, and perceived benefits and\nbarriers and; (2) a framework capturing how PMs assess which tasks to delegate\nto GenAI; (3) PMs adaptation practices for integrating GenAI into their roles\nand perceptions of how their role is evolving. We end by discussing\nimplications on the broader GenAI workflow adoption process and software\ndevelopment roles.", "AI": {"tldr": "\u7814\u7a76\u5fae\u8f6f\u4ea7\u54c1\u7ecf\u7406\u5bf9\u751f\u6210\u5f0fAI\u7684\u91c7\u7528\u60c5\u51b5\u3001\u4f7f\u7528\u6848\u4f8b\u3001\u611f\u77e5\u5229\u76ca\u4e0e\u969c\u788d\uff0c\u4ee5\u53ca\u4efb\u52a1\u59d4\u6d3e\u6846\u67b6\u548c\u89d2\u8272\u9002\u5e94\u5b9e\u8df5\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6b63\u5728\u6539\u53d8\u77e5\u8bc6\u5de5\u4f5c\u7684\u6027\u8d28\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5f00\u53d1\u8005\u4e0eGenAI\u7684\u4ea4\u4e92\uff0c\u5bf9\u4ea7\u54c1\u7ecf\u7406\u5de5\u4f5c\u5982\u4f55\u56e0GenAI\u800c\u6f14\u53d8\u7684\u7406\u89e3\u8f83\u5c11\u3002", "method": "\u5728\u5fae\u8f6f\u8fdb\u884c\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\uff1a\u8c03\u67e5885\u540d\u4ea7\u54c1\u7ecf\u7406\uff0c\u5206\u6790731\u540d\u4ea7\u54c1\u7ecf\u7406\u7684\u9065\u6d4b\u6570\u636e\uff0c\u8bbf\u8c0815\u540d\u4ea7\u54c1\u7ecf\u7406\u3002", "result": "\u63d0\u4f9b\u4e86\u4ea7\u54c1\u7ecf\u7406\u5f53\u524d\u7684GenAI\u91c7\u7528\u7387\u3001\u4f7f\u7528\u6848\u4f8b\u3001\u611f\u77e5\u5229\u76ca\u4e0e\u969c\u788d\uff1b\u63d0\u51fa\u4e86\u4ea7\u54c1\u7ecf\u7406\u8bc4\u4f30\u54ea\u4e9b\u4efb\u52a1\u59d4\u6d3e\u7ed9GenAI\u7684\u6846\u67b6\uff1b\u63cf\u8ff0\u4e86\u4ea7\u54c1\u7ecf\u7406\u6574\u5408GenAI\u5230\u5176\u89d2\u8272\u7684\u9002\u5e94\u5b9e\u8df5\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u66f4\u5e7f\u6cdb\u7684GenAI\u5de5\u4f5c\u6d41\u91c7\u7528\u8fc7\u7a0b\u548c\u8f6f\u4ef6\u5f00\u53d1\u89d2\u8272\u7684\u5f71\u54cd\u3002"}}
{"id": "2510.02557", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02557", "abs": "https://arxiv.org/abs/2510.02557", "authors": ["Charlie Masters", "Advaith Vellanki", "Jiangbo Shangguan", "Bart Kultys", "Jonathan Gilmore", "Alastair Moore", "Stefano V. Albrecht"], "title": "Orchestrating Human-AI Teams: The Manager Agent as a Unifying Research Challenge", "comment": "Accepted as an oral paper for the conference for Distributed\n  Artificial Intelligence (DAI 2025). 8 pages, 2 figures", "summary": "While agentic AI has advanced in automating individual tasks, managing\ncomplex multi-agent workflows remains a challenging problem. This paper\npresents a research vision for autonomous agentic systems that orchestrate\ncollaboration within dynamic human-AI teams. We propose the Autonomous Manager\nAgent as a core challenge: an agent that decomposes complex goals into task\ngraphs, allocates tasks to human and AI workers, monitors progress, adapts to\nchanging conditions, and maintains transparent stakeholder communication. We\nformalize workflow management as a Partially Observable Stochastic Game and\nidentify four foundational challenges: (1) compositional reasoning for\nhierarchical decomposition, (2) multi-objective optimization under shifting\npreferences, (3) coordination and planning in ad hoc teams, and (4) governance\nand compliance by design. To advance this agenda, we release MA-Gym, an\nopen-source simulation and evaluation framework for multi-agent workflow\norchestration. Evaluating GPT-5-based Manager Agents across 20 workflows, we\nfind they struggle to jointly optimize for goal completion, constraint\nadherence, and workflow runtime - underscoring workflow management as a\ndifficult open problem. We conclude with organizational and ethical\nimplications of autonomous management systems.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u4e3b\u7ba1\u7406\u4ee3\u7406\u4f5c\u4e3a\u6838\u5fc3\u6311\u6218\uff0c\u7528\u4e8e\u7f16\u6392\u52a8\u6001\u4eba\u673a\u56e2\u961f\u534f\u4f5c\uff0c\u5c06\u5de5\u4f5c\u6d41\u7ba1\u7406\u5f62\u5f0f\u5316\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u968f\u673a\u535a\u5f08\uff0c\u5e76\u53d1\u5e03MA-Gym\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u867d\u7136\u667a\u80fdAI\u5728\u81ea\u52a8\u5316\u5355\u4e2a\u4efb\u52a1\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u7ba1\u7406\u590d\u6742\u7684\u591a\u4ee3\u7406\u5de5\u4f5c\u6d41\u4ecd\u7136\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u3002", "method": "\u5c06\u5de5\u4f5c\u6d41\u7ba1\u7406\u5f62\u5f0f\u5316\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u968f\u673a\u535a\u5f08\uff0c\u63d0\u51fa\u81ea\u4e3b\u7ba1\u7406\u4ee3\u7406\u6982\u5ff5\uff0c\u5e76\u5f00\u53d1MA-Gym\u5f00\u6e90\u4eff\u771f\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u8bc4\u4f30\u57fa\u4e8eGPT-5\u7684\u7ba1\u7406\u4ee3\u7406\u572820\u4e2a\u5de5\u4f5c\u6d41\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u8054\u5408\u4f18\u5316\u76ee\u6807\u5b8c\u6210\u3001\u7ea6\u675f\u9075\u5b88\u548c\u5de5\u4f5c\u6d41\u8fd0\u884c\u65f6\u95f4\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u5de5\u4f5c\u6d41\u7ba1\u7406\u662f\u4e00\u4e2a\u56f0\u96be\u7684\u5f00\u653e\u95ee\u9898\uff0c\u5e76\u8ba8\u8bba\u4e86\u81ea\u4e3b\u7ba1\u7406\u7cfb\u7edf\u7684\u7ec4\u7ec7\u548c\u4f26\u7406\u5f71\u54cd\u3002"}}
{"id": "2510.02371", "categories": ["cs.CR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.02371", "abs": "https://arxiv.org/abs/2510.02371", "authors": ["Bochra Al Agha", "Razane Tajeddine"], "title": "Federated Spatiotemporal Graph Learning for Passive Attack Detection in Smart Grids", "comment": null, "summary": "Smart grids are exposed to passive eavesdropping, where attackers listen\nsilently to communication links. Although no data is actively altered, such\nreconnaissance can reveal grid topology, consumption patterns, and operational\nbehavior, creating a gateway to more severe targeted attacks. Detecting this\nthreat is difficult because the signals it produces are faint, short-lived, and\noften disappear when traffic is examined by a single node or along a single\ntimeline. This paper introduces a graph-centric, multimodal detector that fuses\nphysical-layer and behavioral indicators over ego-centric star subgraphs and\nshort temporal windows to detect passive attacks. To capture stealthy\nperturbations, a two-stage encoder is introduced: graph convolution aggregates\nspatial context across ego-centric star subgraphs, while a bidirectional GRU\nmodels short-term temporal dependencies. The encoder transforms heterogeneous\nfeatures into a unified spatio-temporal representation suitable for\nclassification. Training occurs in a federated learning setup under FedProx,\nimproving robustness to heterogeneous local raw data and contributing to the\ntrustworthiness of decentralized training; raw measurements remain on client\ndevices. A synthetic, standards-informed dataset is generated to emulate\nheterogeneous HAN/NAN/WAN communications with wireless-only passive\nperturbations, event co-occurrence, and leak-safe splits. The model achieves a\ntesting accuracy of 98.32% per-timestep (F1_{attack}=0.972) and 93.35%\nper-sequence at 0.15% FPR using a simple decision rule with run-length m=2 and\nthreshold $\\tau=0.55$. The results demonstrate that combining spatial and\ntemporal context enables reliable detection of stealthy reconnaissance while\nmaintaining low false-positive rates, making the approach suitable for non-IID\nfederated smart-grid deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u591a\u6a21\u6001\u878d\u5408\u7684\u88ab\u52a8\u7a83\u542c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u5728\u667a\u80fd\u7535\u7f51\u4e2d\u5b9e\u73b0\u9ad8\u6548\u68c0\u6d4b", "motivation": "\u667a\u80fd\u7535\u7f51\u9762\u4e34\u88ab\u52a8\u7a83\u542c\u5a01\u80c1\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u76d1\u542c\u901a\u4fe1\u94fe\u8def\u83b7\u53d6\u7535\u7f51\u62d3\u6251\u548c\u8fd0\u884c\u4fe1\u606f\uff0c\u4e3a\u540e\u7eed\u653b\u51fb\u521b\u9020\u6761\u4ef6\u3002\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u5fae\u5f31\u3001\u77ed\u6682\u7684\u7a83\u542c\u4fe1\u53f7", "method": "\u91c7\u7528\u56fe\u5377\u79ef\u7f51\u7edc\u805a\u5408\u661f\u578b\u5b50\u56fe\u7684\u7a7a\u95f4\u4e0a\u4e0b\u6587\uff0c\u53cc\u5411GRU\u5efa\u6a21\u77ed\u671f\u65f6\u95f4\u4f9d\u8d56\uff0c\u4e24\u9636\u6bb5\u7f16\u7801\u5668\u5c06\u5f02\u6784\u7279\u5f81\u8f6c\u6362\u4e3a\u7edf\u4e00\u65f6\u7a7a\u8868\u793a\u3002\u5728FedProx\u6846\u67b6\u4e0b\u8fdb\u884c\u8054\u90a6\u5b66\u4e60\u8bad\u7ec3", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8fbe\u523098.32%\u7684\u65f6\u95f4\u6b65\u51c6\u786e\u7387\uff08\u653b\u51fbF1=0.972\uff09\u548c93.35%\u7684\u5e8f\u5217\u51c6\u786e\u7387\uff0c\u8bef\u62a5\u7387\u4ec50.15%", "conclusion": "\u7ed3\u5408\u65f6\u7a7a\u4e0a\u4e0b\u6587\u80fd\u591f\u53ef\u9760\u68c0\u6d4b\u9690\u853d\u7684\u4fa6\u5bdf\u6d3b\u52a8\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u8bef\u62a5\u7387\uff0c\u9002\u7528\u4e8e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u7684\u8054\u90a6\u667a\u80fd\u7535\u7f51\u90e8\u7f72"}}
{"id": "2510.02534", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02534", "abs": "https://arxiv.org/abs/2510.02534", "authors": ["Mohsen Iranmanesh", "Sina Moradi Sabet", "Sina Marefat", "Ali Javidi Ghasr", "Allison Wilson", "Iman Sharafaldin", "Mohammad A. Tayebi"], "title": "ZeroFalse: Improving Precision in Static Analysis with LLMs", "comment": null, "summary": "Static Application Security Testing (SAST) tools are integral to modern\nsoftware development, yet their adoption is undermined by excessive false\npositives that weaken developer trust and demand costly manual triage. We\npresent ZeroFalse, a framework that integrates static analysis with large\nlanguage models (LLMs) to reduce false positives while preserving coverage.\nZeroFalse treats static analyzer outputs as structured contracts, enriching\nthem with flow-sensitive traces, contextual evidence, and CWE-specific\nknowledge before adjudication by an LLM. This design preserves the systematic\nreach of static analysis while leveraging the reasoning capabilities of LLMs.\nWe evaluate ZeroFalse across both benchmarks and real-world projects using ten\nstate-of-the-art LLMs. Our best-performing models achieve F1-scores of 0.912 on\nthe OWASP Java Benchmark and 0.955 on the OpenVuln dataset, maintaining recall\nand precision above 90%. Results further show that CWE-specialized prompting\nconsistently outperforms generic prompts, and reasoning-oriented LLMs provide\nthe most reliable precision-recall balance. These findings position ZeroFalse\nas a practical and scalable approach for enhancing the reliability of SAST and\nsupporting its integration into real-world CI/CD pipelines.", "AI": {"tldr": "ZeroFalse\u6846\u67b6\u7ed3\u5408\u9759\u6001\u5206\u6790\u548cLLM\u6765\u51cf\u5c11SAST\u5de5\u5177\u7684\u8bef\u62a5\uff0c\u540c\u65f6\u4fdd\u6301\u8986\u76d6\u7387\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u9ad8F1\u5206\u6570", "motivation": "SAST\u5de5\u5177\u5b58\u5728\u8fc7\u591a\u8bef\u62a5\u95ee\u9898\uff0c\u524a\u5f31\u5f00\u53d1\u8005\u4fe1\u4efb\u5e76\u9700\u8981\u6602\u8d35\u7684\u4eba\u5de5\u5206\u7c7b\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u9759\u6001\u5206\u6790\u7cfb\u7edf\u6027\u8986\u76d6\u53c8\u80fd\u51cf\u5c11\u8bef\u62a5\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u5c06\u9759\u6001\u5206\u6790\u5668\u8f93\u51fa\u89c6\u4e3a\u7ed3\u6784\u5316\u5408\u7ea6\uff0c\u901a\u8fc7\u6d41\u654f\u611f\u8ffd\u8e2a\u3001\u4e0a\u4e0b\u6587\u8bc1\u636e\u548cCWE\u7279\u5b9a\u77e5\u8bc6\u8fdb\u884c\u4e30\u5bcc\uff0c\u7136\u540e\u7531LLM\u8fdb\u884c\u88c1\u51b3", "result": "\u5728OWASP Java Benchmark\u4e0aF1\u5206\u6570\u8fbe0.912\uff0c\u5728OpenVuln\u6570\u636e\u96c6\u4e0a\u8fbe0.955\uff0c\u53ec\u56de\u7387\u548c\u7cbe\u786e\u7387\u5747\u8d85\u8fc790%", "conclusion": "ZeroFalse\u662f\u589e\u5f3aSAST\u53ef\u9760\u6027\u7684\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u652f\u6301\u5176\u96c6\u6210\u5230\u771f\u5b9eCI/CD\u6d41\u6c34\u7ebf\u4e2d"}}
{"id": "2510.02567", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02567", "abs": "https://arxiv.org/abs/2510.02567", "authors": ["Peter Pak", "Achuth Chandrasekhar", "Amir Barati Farimani"], "title": "Agentic Additive Manufacturing Alloy Discovery", "comment": null, "summary": "Agentic systems enable the intelligent use of research tooling, augmenting a\nresearcher's ability to investigate and propose novel solutions to existing\nproblems. Within Additive Manufacturing (AM), alloy discovery remains a complex\nchallenge, often requiring expertise in the various domains of materials\nscience, thermodynamic simulations, and experimental analysis. Large Language\nModel (LLM) enabled agents can facilitate this endeavor by utilizing their\nextensive knowledge base to dispatch tool calls via Model Context Protocol\n(MCP) to perform actions such as Thermo-Calc property diagram calculations and\nlack of fusion process map generation. In addition, the multi-agent system\ndeveloped in this work is able to effectively reason through complex user\nprompts and provide analysis on the printability of proposed alloys. These\nagents can dynamically adjust their task trajectory to the outcomes of tool\ncall results, effectively enabling autonomous decision-making in practical\nenvironments. This work aims to utilize LLM enabled agents to automate and\naccelerate the task of alloy discovery within the field of additive\nmanufacturing and showcase the benefits of adopting this multi-agent system.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u52a0\u901f\u589e\u6750\u5236\u9020\u9886\u57df\u7684\u5408\u91d1\u53d1\u73b0\u8fc7\u7a0b\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u7528\u70ed\u529b\u5b66\u8ba1\u7b97\u548c\u5de5\u827a\u6a21\u62df\u5de5\u5177\u6765\u5b9e\u73b0\u81ea\u4e3b\u51b3\u7b56\u3002", "motivation": "\u589e\u6750\u5236\u9020\u4e2d\u7684\u5408\u91d1\u53d1\u73b0\u662f\u4e00\u4e2a\u590d\u6742\u7684\u8de8\u5b66\u79d1\u6311\u6218\uff0c\u9700\u8981\u6750\u6599\u79d1\u5b66\u3001\u70ed\u529b\u5b66\u6a21\u62df\u548c\u5b9e\u9a8c\u5206\u6790\u7b49\u591a\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002\u7814\u7a76\u65e8\u5728\u5229\u7528LLM\u667a\u80fd\u4f53\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae(MCP)\u8c03\u7528\u5de5\u5177\uff0c\u5305\u62ecThermo-Calc\u6027\u80fd\u56fe\u8ba1\u7b97\u548c\u7194\u5408\u4e0d\u8db3\u5de5\u827a\u56fe\u751f\u6210\uff0c\u667a\u80fd\u4f53\u80fd\u591f\u6839\u636e\u5de5\u5177\u8c03\u7528\u7ed3\u679c\u52a8\u6001\u8c03\u6574\u4efb\u52a1\u8f68\u8ff9\u3002", "result": "\u5f00\u53d1\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u89e3\u6790\u590d\u6742\u7528\u6237\u63d0\u793a\uff0c\u5bf9\u63d0\u51fa\u7684\u5408\u91d1\u53ef\u6253\u5370\u6027\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u5b9e\u73b0\u81ea\u4e3b\u51b3\u7b56\uff0c\u5c55\u793a\u4e86\u5728\u589e\u6750\u5236\u9020\u5408\u91d1\u53d1\u73b0\u4e2d\u7684\u81ea\u52a8\u5316\u80fd\u529b\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u663e\u8457\u81ea\u52a8\u5316\u548c\u52a0\u901f\u589e\u6750\u5236\u9020\u4e2d\u7684\u5408\u91d1\u53d1\u73b0\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u5b9e\u9645\u6548\u76ca\u548c\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.02373", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02373", "abs": "https://arxiv.org/abs/2510.02373", "authors": ["Qianshan Wei", "Tengchao Yang", "Yaochen Wang", "Xinfeng Li", "Lijun Li", "Zhenfei Yin", "Yi Zhan", "Thorsten Holz", "Zhiqiang Lin", "XiaoFeng Wang"], "title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "comment": null, "summary": "Large Language Model (LLM) agents use memory to learn from past interactions,\nenabling autonomous planning and decision-making in complex environments.\nHowever, this reliance on memory introduces a critical security risk: an\nadversary can inject seemingly harmless records into an agent's memory to\nmanipulate its future behavior. This vulnerability is characterized by two core\naspects: First, the malicious effect of injected records is only activated\nwithin a specific context, making them hard to detect when individual memory\nentries are audited in isolation. Second, once triggered, the manipulation can\ninitiate a self-reinforcing error cycle: the corrupted outcome is stored as\nprecedent, which not only amplifies the initial error but also progressively\nlowers the threshold for similar attacks in the future. To address these\nchallenges, we introduce A-MemGuard (Agent-Memory Guard), the first proactive\ndefense framework for LLM agent memory. The core idea of our work is the\ninsight that memory itself must become both self-checking and self-correcting.\nWithout modifying the agent's core architecture, A-MemGuard combines two\nmechanisms: (1) consensus-based validation, which detects anomalies by\ncomparing reasoning paths derived from multiple related memories and (2) a\ndual-memory structure, where detected failures are distilled into ``lessons''\nstored separately and consulted before future actions, breaking error cycles\nand enabling adaptation. Comprehensive evaluations on multiple benchmarks show\nthat A-MemGuard effectively cuts attack success rates by over 95% while\nincurring a minimal utility cost. This work shifts LLM memory security from\nstatic filtering to a proactive, experience-driven model where defenses\nstrengthen over time. Our code is available in\nhttps://github.com/TangciuYueng/AMemGuard", "AI": {"tldr": "\u63d0\u51fa\u4e86A-MemGuard\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u8bc6\u9a8c\u8bc1\u548c\u53cc\u5185\u5b58\u7ed3\u6784\u6765\u9632\u5fa1LLM\u4ee3\u7406\u5185\u5b58\u4e2d\u7684\u9690\u853d\u653b\u51fb\uff0c\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e95%\u4ee5\u4e0a\u3002", "motivation": "LLM\u4ee3\u7406\u4f9d\u8d56\u5185\u5b58\u5b66\u4e60\uff0c\u4f46\u6076\u610f\u8bb0\u5f55\u6ce8\u5165\u4f1a\u64cd\u7eb5\u5176\u672a\u6765\u884c\u4e3a\uff0c\u4e14\u8fd9\u79cd\u653b\u51fb\u5177\u6709\u4e0a\u4e0b\u6587\u89e6\u53d1\u6027\u548c\u81ea\u6211\u5f3a\u5316\u7684\u9519\u8bef\u5faa\u73af\u7279\u6027\uff0c\u96be\u4ee5\u68c0\u6d4b\u3002", "method": "A-MemGuard\u5305\u542b\u5171\u8bc6\u9a8c\u8bc1\uff08\u901a\u8fc7\u6bd4\u8f83\u591a\u4e2a\u76f8\u5173\u5185\u5b58\u7684\u63a8\u7406\u8def\u5f84\u68c0\u6d4b\u5f02\u5e38\uff09\u548c\u53cc\u5185\u5b58\u7ed3\u6784\uff08\u5c06\u68c0\u6d4b\u5230\u7684\u5931\u8d25\u63d0\u70bc\u4e3a'\u6559\u8bad'\u5355\u72ec\u5b58\u50a8\uff09\uff0c\u65e0\u9700\u4fee\u6539\u4ee3\u7406\u6838\u5fc3\u67b6\u6784\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cA-MemGuard\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u4e8695%\u4ee5\u4e0a\uff0c\u540c\u65f6\u4ec5\u4ea7\u751f\u6700\u5c0f\u7684\u6548\u7528\u6210\u672c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c06LLM\u5185\u5b58\u5b89\u5168\u4ece\u9759\u6001\u8fc7\u6ee4\u8f6c\u5411\u4e3b\u52a8\u3001\u7ecf\u9a8c\u9a71\u52a8\u7684\u6a21\u578b\uff0c\u4f7f\u9632\u5fa1\u80fd\u529b\u968f\u65f6\u95f4\u589e\u5f3a\u3002"}}
{"id": "2510.02585", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02585", "abs": "https://arxiv.org/abs/2510.02585", "authors": ["Majid Dashtbani", "Ladan Tahvildari"], "title": "Key Considerations for Auto-Scaling: Lessons from Benchmark Microservices", "comment": null, "summary": "Microservices have become the dominant architectural paradigm for building\nscalable and modular cloud-native systems. However, achieving effective\nauto-scaling in such systems remains a non-trivial challenge, as it depends not\nonly on advanced scaling techniques but also on sound design, implementation,\nand deployment practices. Yet, these foundational aspects are often overlooked\nin existing benchmarks, making it difficult to evaluate autoscaling methods\nunder realistic conditions. In this paper, we identify a set of practical\nauto-scaling considerations by applying several state-of-the-art autoscaling\nmethods to widely used microservice benchmarks. To structure these findings, we\nclassify the issues based on when they arise during the software lifecycle:\nArchitecture, Implementation, and Deployment. The Architecture phase covers\nhigh-level decisions such as service decomposition and inter-service\ndependencies. The Implementation phase includes aspects like initialization\noverhead, metrics instrumentation, and error propagation. The Deployment phase\nfocuses on runtime configurations such as resource limits and health checks. We\nvalidate these considerations using the Sock-Shop benchmark and evaluate\ndiverse auto-scaling strategies, including threshold-based, control-theoretic,\nlearning-based, black-box optimization, and dependency-aware approaches. Our\nfindings show that overlooking key lifecycle concerns can degrade autoscaler\nperformance, while addressing them leads to more stable and efficient scaling.\nThese results underscore the importance of lifecycle-aware engineering for\nunlocking the full potential of auto-scaling in microservice-based systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5206\u6790\u5fae\u670d\u52a1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc6\u522b\u4e86\u5f71\u54cd\u81ea\u52a8\u6269\u7f29\u5bb9\u6548\u679c\u7684\u5173\u952e\u751f\u547d\u5468\u671f\u56e0\u7d20\uff0c\u5e76\u5c06\u5176\u5206\u7c7b\u4e3a\u67b6\u6784\u3001\u5b9e\u73b0\u548c\u90e8\u7f72\u4e09\u4e2a\u9636\u6bb5\u7684\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u751f\u547d\u5468\u671f\u611f\u77e5\u5de5\u7a0b\u5bf9\u63d0\u5347\u81ea\u52a8\u6269\u7f29\u5bb9\u6027\u80fd\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u5ffd\u89c6\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u57fa\u7840\u8bbe\u8ba1\u3001\u5b9e\u73b0\u548c\u90e8\u7f72\u5b9e\u8df5\uff0c\u5bfc\u81f4\u96be\u4ee5\u5728\u771f\u5b9e\u6761\u4ef6\u4e0b\u8bc4\u4f30\u81ea\u52a8\u6269\u7f29\u5bb9\u65b9\u6cd5\u3002", "method": "\u5c06\u591a\u79cd\u5148\u8fdb\u7684\u81ea\u52a8\u6269\u7f29\u5bb9\u65b9\u6cd5\u5e94\u7528\u4e8e\u5e7f\u6cdb\u4f7f\u7528\u7684\u5fae\u670d\u52a1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc6\u522b\u5b9e\u8df5\u4e2d\u7684\u6269\u7f29\u5bb9\u8003\u8651\u56e0\u7d20\uff0c\u5e76\u6309\u8f6f\u4ef6\u751f\u547d\u5468\u671f\u5206\u7c7b\uff1a\u67b6\u6784\u3001\u5b9e\u73b0\u548c\u90e8\u7f72\u9636\u6bb5\u3002", "result": "\u5ffd\u89c6\u5173\u952e\u751f\u547d\u5468\u671f\u95ee\u9898\u4f1a\u964d\u4f4e\u81ea\u52a8\u6269\u7f29\u5bb9\u5668\u6027\u80fd\uff0c\u800c\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u80fd\u5e26\u6765\u66f4\u7a33\u5b9a\u548c\u9ad8\u6548\u7684\u6269\u7f29\u5bb9\u6548\u679c\u3002", "conclusion": "\u751f\u547d\u5468\u671f\u611f\u77e5\u5de5\u7a0b\u5bf9\u4e8e\u91ca\u653e\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u81ea\u52a8\u6269\u7f29\u5bb9\u7684\u5168\u90e8\u6f5c\u529b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.02589", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02589", "abs": "https://arxiv.org/abs/2510.02589", "authors": ["Yunqi Huang", "Nishith Chennakeshava", "Alexis Carras", "Vladislav Neverov", "Wei Liu", "Aske Plaat", "Yingjie Fan"], "title": "A Benchmark Study of Deep Reinforcement Learning Algorithms for the Container Stowage Planning Problem", "comment": null, "summary": "Container stowage planning (CSPP) is a critical component of maritime\ntransportation and terminal operations, directly affecting supply chain\nefficiency. Owing to its complexity, CSPP has traditionally relied on human\nexpertise. While reinforcement learning (RL) has recently been applied to CSPP,\nsystematic benchmark comparisons across different algorithms remain limited. To\naddress this gap, we develop a Gym environment that captures the fundamental\nfeatures of CSPP and extend it to include crane scheduling in both multi-agent\nand single-agent formulations. Within this framework, we evaluate five RL\nalgorithms: DQN, QR-DQN, A2C, PPO, and TRPO under multiple scenarios of varying\ncomplexity. The results reveal distinct performance gaps with increasing\ncomplexity, underscoring the importance of algorithm choice and problem\nformulation for CSPP. Overall, this paper benchmarks multiple RL methods for\nCSPP while providing a reusable Gym environment with crane scheduling, thus\noffering a foundation for future research and practical deployment in maritime\nlogistics.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b\u8d77\u91cd\u673a\u8c03\u5ea6\u7684CSPP Gym\u73af\u5883\uff0c\u8bc4\u4f30\u4e865\u79cdRL\u7b97\u6cd5\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u7b97\u6cd5\u9009\u62e9\u548c\u95ee\u9898\u8868\u8ff0\u5bf9CSPP\u81f3\u5173\u91cd\u8981\u3002", "motivation": "CSPP\u5bf9\u6d77\u8fd0\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709RL\u7814\u7a76\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u57fa\u51c6\u6bd4\u8f83\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u8d77\u91cd\u673a\u8c03\u5ea6\u7684CSPP Gym\u73af\u5883\uff0c\u8bc4\u4f30\u4e86DQN\u3001QR-DQN\u3001A2C\u3001PPO\u548cTRPO\u4e94\u79cdRL\u7b97\u6cd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u968f\u7740\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u4e0d\u540c\u7b97\u6cd5\u6027\u80fd\u5dee\u5f02\u663e\u8457\uff0c\u7b97\u6cd5\u9009\u62e9\u548c\u95ee\u9898\u8868\u8ff0\u5bf9CSPP\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "\u672c\u6587\u4e3aCSPP\u63d0\u4f9b\u4e86\u591aRL\u65b9\u6cd5\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u53ef\u91cd\u7528\u7684Gym\u73af\u5883\uff0c\u4e3a\u672a\u6765\u6d77\u8fd0\u7269\u6d41\u7814\u7a76\u548c\u5b9e\u8df5\u90e8\u7f72\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.02374", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02374", "abs": "https://arxiv.org/abs/2510.02374", "authors": ["Ayda Aghaei Nia"], "title": "A Hybrid CAPTCHA Combining Generative AI with Keystroke Dynamics for Enhanced Bot Detection", "comment": "6 pages, 4 figures", "summary": "Completely Automated Public Turing tests to tell Computers and Humans Apart\n(CAPTCHAs) are a foundational component of web security, yet traditional\nimplementations suffer from a trade-off between usability and resilience\nagainst AI-powered bots. This paper introduces a novel hybrid CAPTCHA system\nthat synergizes the cognitive challenges posed by Large Language Models (LLMs)\nwith the behavioral biometric analysis of keystroke dynamics. Our approach\ngenerates dynamic, unpredictable questions that are trivial for humans but\nnon-trivial for automated agents, while simultaneously analyzing the user's\ntyping rhythm to distinguish human patterns from robotic input. We present the\nsystem's architecture, formalize the feature extraction methodology for\nkeystroke analysis, and report on an experimental evaluation. The results\nindicate that our dual-layered approach achieves a high degree of accuracy in\nbot detection, successfully thwarting both paste-based and script-based\nsimulation attacks, while maintaining a high usability score among human\nparticipants. This work demonstrates the potential of combining cognitive and\nbehavioral tests to create a new generation of more secure and user-friendly\nCAPTCHAs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LLM\u8ba4\u77e5\u6311\u6218\u548c\u51fb\u952e\u52a8\u6001\u5206\u6790\u7684\u6df7\u5408CAPTCHA\u7cfb\u7edf\uff0c\u901a\u8fc7\u53cc\u91cd\u9a8c\u8bc1\u673a\u5236\u6709\u6548\u533a\u5206\u4eba\u7c7b\u7528\u6237\u548c\u673a\u5668\u4eba\u653b\u51fb\u3002", "motivation": "\u4f20\u7edfCAPTCHA\u5728\u53ef\u7528\u6027\u548cAI\u673a\u5668\u4eba\u9632\u5fa1\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5b89\u5168\u4e14\u7528\u6237\u53cb\u597d\u7684\u65b0\u4e00\u4ee3\u9a8c\u8bc1\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u53cc\u91cd\u9a8c\u8bc1\u67b6\u6784\uff1a\u52a8\u6001\u751f\u6210LLM\u8ba4\u77e5\u6311\u6218\u95ee\u9898\uff0c\u540c\u65f6\u5206\u6790\u7528\u6237\u51fb\u952e\u52a8\u6001\u884c\u4e3a\u7279\u5f81\uff0c\u7ed3\u5408\u8ba4\u77e5\u548c\u884c\u4e3a\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u7cfb\u7edf\u5728\u673a\u5668\u4eba\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u9ad8\u51c6\u786e\u7387\uff0c\u80fd\u6709\u6548\u62b5\u5fa1\u7c98\u8d34\u5f0f\u548c\u811a\u672c\u5f0f\u6a21\u62df\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7528\u6237\u53ef\u7528\u6027\u8bc4\u5206\u3002", "conclusion": "\u7ed3\u5408\u8ba4\u77e5\u548c\u884c\u4e3a\u6d4b\u8bd5\u7684\u53cc\u5c42CAPTCHA\u7cfb\u7edf\u5c55\u793a\u4e86\u521b\u5efa\u66f4\u5b89\u5168\u3001\u7528\u6237\u53cb\u597d\u9a8c\u8bc1\u7801\u7684\u6f5c\u529b\uff0c\u4e3a\u65b0\u4e00\u4ee3web\u5b89\u5168\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.02609", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02609", "abs": "https://arxiv.org/abs/2510.02609", "authors": ["Chengquan Guo", "Chulin Xie", "Yu Yang", "Zhaorun Chen", "Zinan Lin", "Xander Davies", "Yarin Gal", "Dawn Song", "Bo Li"], "title": "RedCodeAgent: Automatic Red-teaming Agent against Diverse Code Agents", "comment": null, "summary": "Code agents have gained widespread adoption due to their strong code\ngeneration capabilities and integration with code interpreters, enabling\ndynamic execution, debugging, and interactive programming capabilities. While\nthese advancements have streamlined complex workflows, they have also\nintroduced critical safety and security risks. Current static safety benchmarks\nand red-teaming tools are inadequate for identifying emerging real-world risky\nscenarios, as they fail to cover certain boundary conditions, such as the\ncombined effects of different jailbreak tools. In this work, we propose\nRedCodeAgent, the first automated red-teaming agent designed to systematically\nuncover vulnerabilities in diverse code agents. With an adaptive memory module,\nRedCodeAgent can leverage existing jailbreak knowledge, dynamically select the\nmost effective red-teaming tools and tool combinations in a tailored toolbox\nfor a given input query, thus identifying vulnerabilities that might otherwise\nbe overlooked. For reliable evaluation, we develop simulated sandbox\nenvironments to additionally evaluate the execution results of code agents,\nmitigating potential biases of LLM-based judges that only rely on static code.\nThrough extensive evaluations across multiple state-of-the-art code agents,\ndiverse risky scenarios, and various programming languages, RedCodeAgent\nconsistently outperforms existing red-teaming methods, achieving higher attack\nsuccess rates and lower rejection rates with high efficiency. We further\nvalidate RedCodeAgent on real-world code assistants, e.g., Cursor and Codeium,\nexposing previously unidentified security risks. By automating and optimizing\nred-teaming processes, RedCodeAgent enables scalable, adaptive, and effective\nsafety assessments of code agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86RedCodeAgent\uff0c\u9996\u4e2a\u81ea\u52a8\u5316\u7ea2\u961f\u4ee3\u7406\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u5730\u53d1\u73b0\u5404\u79cd\u4ee3\u7801\u4ee3\u7406\u4e2d\u7684\u6f0f\u6d1e\u3002\u901a\u8fc7\u81ea\u9002\u5e94\u8bb0\u5fc6\u6a21\u5757\u548c\u5b9a\u5236\u5de5\u5177\u7bb1\uff0c\u80fd\u52a8\u6001\u9009\u62e9\u6700\u6709\u6548\u7684\u7ea2\u961f\u5de5\u5177\u7ec4\u5408\uff0c\u5728\u6a21\u62df\u6c99\u76d2\u73af\u5883\u4e2d\u53ef\u9760\u8bc4\u4f30\u6267\u884c\u7ed3\u679c\u3002", "motivation": "\u4ee3\u7801\u4ee3\u7406\u7684\u5e7f\u6cdb\u5e94\u7528\u5e26\u6765\u4e86\u5173\u952e\u7684\u5b89\u5168\u98ce\u9669\uff0c\u73b0\u6709\u7684\u9759\u6001\u5b89\u5168\u57fa\u51c6\u548c\u7ea2\u961f\u5de5\u5177\u65e0\u6cd5\u8986\u76d6\u67d0\u4e9b\u8fb9\u754c\u6761\u4ef6\uff08\u5982\u4e0d\u540c\u8d8a\u72f1\u5de5\u5177\u7684\u7ec4\u5408\u6548\u5e94\uff09\uff0c\u65e0\u6cd5\u8bc6\u522b\u65b0\u5174\u7684\u73b0\u5b9e\u4e16\u754c\u98ce\u9669\u573a\u666f\u3002", "method": "\u5f00\u53d1\u4e86RedCodeAgent\uff0c\u914d\u5907\u81ea\u9002\u5e94\u8bb0\u5fc6\u6a21\u5757\u6765\u5229\u7528\u73b0\u6709\u8d8a\u72f1\u77e5\u8bc6\uff0c\u52a8\u6001\u9009\u62e9\u6700\u6709\u6548\u7684\u7ea2\u961f\u5de5\u5177\u548c\u5de5\u5177\u7ec4\u5408\u3002\u521b\u5efa\u6a21\u62df\u6c99\u76d2\u73af\u5883\u6765\u8bc4\u4f30\u4ee3\u7801\u4ee3\u7406\u7684\u6267\u884c\u7ed3\u679c\uff0c\u51cf\u5c11\u4ec5\u4f9d\u8d56\u9759\u6001\u4ee3\u7801\u7684LLM\u8bc4\u4f30\u5668\u7684\u6f5c\u5728\u504f\u89c1\u3002", "result": "\u5728\u591a\u4e2a\u6700\u5148\u8fdb\u7684\u4ee3\u7801\u4ee3\u7406\u3001\u591a\u6837\u5316\u98ce\u9669\u573a\u666f\u548c\u5404\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u5e7f\u6cdb\u8bc4\u4f30\u4e2d\uff0cRedCodeAgent\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7ea2\u961f\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u653b\u51fb\u6210\u529f\u7387\u3001\u66f4\u4f4e\u7684\u62d2\u7edd\u7387\u548c\u9ad8\u6548\u7387\u3002\u5728\u771f\u5b9e\u4e16\u754c\u4ee3\u7801\u52a9\u624b\uff08\u5982Cursor\u548cCodeium\uff09\u4e0a\u9a8c\u8bc1\uff0c\u66b4\u9732\u4e86\u5148\u524d\u672a\u8bc6\u522b\u7684\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u4f18\u5316\u7ea2\u961f\u6d41\u7a0b\uff0cRedCodeAgent\u5b9e\u73b0\u4e86\u5bf9\u4ee3\u7801\u4ee3\u7406\u7684\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u548c\u6709\u6548\u7684\u5b89\u5168\u8bc4\u4f30\u3002"}}
{"id": "2510.02592", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02592", "abs": "https://arxiv.org/abs/2510.02592", "authors": ["Jean Douglas Carvalho", "Hugo Kenji", "Ahmad Mohammad Saber", "Glaucia Melo", "Max Mauro Dias Santos", "Deepa Kundur"], "title": "Multimodal Large Language Model Framework for Safe and Interpretable Grid-Integrated EVs", "comment": "This paper has been presented at the 2025 IEEE PES Conference on\n  Innovative Smart Grid Technologies (ISGT 2025)", "summary": "The integration of electric vehicles (EVs) into smart grids presents unique\nopportunities to enhance both transportation systems and energy networks.\nHowever, ensuring safe and interpretable interactions between drivers,\nvehicles, and the surrounding environment remains a critical challenge. This\npaper presents a multi-modal large language model (LLM)-based framework to\nprocess multimodal sensor data - such as object detection, semantic\nsegmentation, and vehicular telemetry - and generate natural-language alerts\nfor drivers. The framework is validated using real-world data collected from\ninstrumented vehicles driving on urban roads, ensuring its applicability to\nreal-world scenarios. By combining visual perception (YOLOv8), geocoded\npositioning, and CAN bus telemetry, the framework bridges raw sensor data and\ndriver comprehension, enabling safer and more informed decision-making in urban\ndriving scenarios. Case studies using real data demonstrate the framework's\neffectiveness in generating context-aware alerts for critical situations, such\nas proximity to pedestrians, cyclists, and other vehicles. This paper\nhighlights the potential of LLMs as assistive tools in e-mobility, benefiting\nboth transportation systems and electric networks by enabling scalable fleet\ncoordination, EV load forecasting, and traffic-aware energy planning.\n  Index Terms - Electric vehicles, visual perception, large language models,\nYOLOv8, semantic segmentation, CAN bus, prompt engineering, smart grid.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5904\u7406\u89c6\u89c9\u611f\u77e5\u3001\u5b9a\u4f4d\u548c\u8f66\u8f86\u9065\u6d4b\u6570\u636e\uff0c\u4e3a\u9a7e\u9a76\u5458\u751f\u6210\u81ea\u7136\u8bed\u8a00\u8b66\u62a5\uff0c\u63d0\u5347\u7535\u52a8\u6c7d\u8f66\u5728\u57ce\u5e02\u9a7e\u9a76\u4e2d\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u4e0e\u667a\u80fd\u7535\u7f51\u7684\u96c6\u6210\u4e3a\u4ea4\u901a\u7cfb\u7edf\u548c\u80fd\u6e90\u7f51\u7edc\u5e26\u6765\u673a\u9047\uff0c\u4f46\u786e\u4fdd\u9a7e\u9a76\u5458\u3001\u8f66\u8f86\u4e0e\u73af\u5883\u4e4b\u95f4\u5b89\u5168\u53ef\u89e3\u91ca\u7684\u4ea4\u4e92\u4ecd\u662f\u5173\u952e\u6311\u6218\u3002", "method": "\u7ed3\u5408YOLOv8\u89c6\u89c9\u611f\u77e5\u3001\u5730\u7406\u7f16\u7801\u5b9a\u4f4d\u548cCAN\u603b\u7ebf\u9065\u6d4b\u6570\u636e\uff0c\u4f7f\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u4f20\u611f\u5668\u6570\u636e\u5e76\u751f\u6210\u81ea\u7136\u8bed\u8a00\u8b66\u62a5\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\u9a8c\u8bc1\uff0c\u6846\u67b6\u80fd\u6709\u6548\u751f\u6210\u9488\u5bf9\u5173\u952e\u60c5\u5883\uff08\u5982\u9760\u8fd1\u884c\u4eba\u3001\u81ea\u884c\u8f66\u548c\u5176\u4ed6\u8f66\u8f86\uff09\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u8b66\u62a5\u3002", "conclusion": "LLM\u5728\u7535\u52a8\u4ea4\u901a\u4e2d\u5177\u6709\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u53ef\u6269\u5c55\u7684\u8f66\u961f\u534f\u8c03\u3001EV\u8d1f\u8f7d\u9884\u6d4b\u548c\u4ea4\u901a\u611f\u77e5\u80fd\u6e90\u89c4\u5212\uff0c\u4f7f\u4ea4\u901a\u7cfb\u7edf\u548c\u7535\u7f51\u53d7\u76ca\u3002"}}
{"id": "2510.02376", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02376", "abs": "https://arxiv.org/abs/2510.02376", "authors": ["Ryan Marinelli", "Angelica Chowdhury"], "title": "Scaling Homomorphic Applications in Deployment", "comment": "5 pages, 6 figures, 1 pseudo code", "summary": "In this endeavor, a proof-of-concept homomorphic application is developed to\ndetermine the production readiness of encryption ecosystems. A movie\nrecommendation app is implemented for this purpose and productionized through\ncontainerization and orchestration. By tuning deployment configurations, the\ncomputational limitations of Fully Homomorphic Encryption (FHE) are mitigated\nthrough additional infrastructure optimizations\n  Index Terms: Reinforcement Learning, Orchestration, Homomorphic Encryption", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u7684\u540c\u6001\u52a0\u5bc6\u5e94\u7528\u6765\u8bc4\u4f30\u52a0\u5bc6\u751f\u6001\u7cfb\u7edf\u7684\u751f\u4ea7\u5c31\u7eea\u6027\uff0c\u901a\u8fc7\u7535\u5f71\u63a8\u8350\u5e94\u7528\u5b9e\u73b0\u5bb9\u5668\u5316\u548c\u7f16\u6392\u90e8\u7f72\uff0c\u901a\u8fc7\u57fa\u7840\u8bbe\u65bd\u4f18\u5316\u7f13\u89e3\u5168\u540c\u6001\u52a0\u5bc6\u7684\u8ba1\u7b97\u9650\u5236", "motivation": "\u8bc4\u4f30\u540c\u6001\u52a0\u5bc6\u751f\u6001\u7cfb\u7edf\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u5c31\u7eea\u6027\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u57fa\u7840\u8bbe\u65bd\u4f18\u5316\u6765\u514b\u670d\u5168\u540c\u6001\u52a0\u5bc6\u7684\u8ba1\u7b97\u6027\u80fd\u9650\u5236", "method": "\u5b9e\u73b0\u7535\u5f71\u63a8\u8350\u5e94\u7528\u4f5c\u4e3a\u6982\u5ff5\u9a8c\u8bc1\uff0c\u91c7\u7528\u5bb9\u5668\u5316\u548c\u7f16\u6392\u6280\u672f\u8fdb\u884c\u751f\u4ea7\u5316\u90e8\u7f72\uff0c\u901a\u8fc7\u8c03\u6574\u90e8\u7f72\u914d\u7f6e\u548c\u57fa\u7840\u8bbe\u65bd\u4f18\u5316\u6765\u7f13\u89e3FHE\u7684\u8ba1\u7b97\u9650\u5236", "result": "\u6210\u529f\u5f00\u53d1\u5e76\u90e8\u7f72\u4e86\u57fa\u4e8e\u540c\u6001\u52a0\u5bc6\u7684\u7535\u5f71\u63a8\u8350\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u57fa\u7840\u8bbe\u65bd\u4f18\u5316\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u7f13\u89e3FHE\u7684\u8ba1\u7b97\u6027\u80fd\u95ee\u9898", "conclusion": "\u540c\u6001\u52a0\u5bc6\u751f\u6001\u7cfb\u7edf\u6b63\u5728\u5411\u751f\u4ea7\u5c31\u7eea\u65b9\u5411\u53d1\u5c55\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u5bb9\u5668\u5316\u3001\u7f16\u6392\u548c\u57fa\u7840\u8bbe\u65bd\u4f18\u5316\u7b56\u7565\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u90e8\u7f72\u548c\u8fd0\u884c\u57fa\u4e8eFHE\u7684\u5e94\u7528"}}
{"id": "2510.02634", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02634", "abs": "https://arxiv.org/abs/2510.02634", "authors": ["Hanlong Wan", "Weili Xu", "Michael Rosenberg", "Jian Zhang", "Aysha Siddika"], "title": "Automatic Building Code Review: A Case Study", "comment": null, "summary": "Building officials, particularly those in resource-constrained or rural\njurisdictions, face labor-intensive, error-prone, and costly manual reviews of\ndesign documents as projects increase in size and complexity. The growing\nadoption of Building Information Modeling (BIM) and Large Language Models\n(LLMs) presents opportunities for automated code review (ACR) solutions. This\nstudy introduces a novel agent-driven framework that integrates BIM-based data\nextraction with automated verification using both retrieval-augmented\ngeneration (RAG) and Model Context Protocol (MCP) agent pipelines. The\nframework employs LLM-enabled agents to extract geometry, schedules, and system\nattributes from heterogeneous file types, which are then processed for building\ncode checking through two complementary mechanisms: (1) direct API calls to the\nUS Department of Energy COMcheck engine, providing deterministic and\naudit-ready outputs, and (2) RAG-based reasoning over rule provisions, enabling\nflexible interpretation where coverage is incomplete or ambiguous.\n  The framework was evaluated through case demonstrations, including automated\nextraction of geometric attributes (such as surface area, tilt, and insulation\nvalues), parsing of operational schedules, and validation of lighting\nallowances under ASHRAE Standard 90.1-2022. Comparative performance tests\nacross multiple LLMs showed that GPT-4o achieved the best balance of efficiency\nand stability, while smaller models exhibited inconsistencies or failures.\nResults confirm that MCP agent pipelines outperform RAG reasoning pipelines in\nrigor and reliability. This work advances ACR research by demonstrating a\nscalable, interoperable, and production-ready approach that bridges BIM with\nauthoritative code review tools.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eBIM\u548cLLM\u7684\u81ea\u52a8\u5316\u5efa\u7b51\u89c4\u8303\u5ba1\u67e5\u6846\u67b6\uff0c\u7ed3\u5408RAG\u548cMCP\u4ee3\u7406\u7ba1\u9053\uff0c\u80fd\u591f\u4ece\u5f02\u6784\u6587\u4ef6\u4e2d\u63d0\u53d6\u51e0\u4f55\u3001\u65f6\u95f4\u8868\u548c\u7cfb\u7edf\u5c5e\u6027\uff0c\u5e76\u901a\u8fc7COMcheck API\u548cRAG\u63a8\u7406\u8fdb\u884c\u89c4\u8303\u68c0\u67e5\u3002", "motivation": "\u8d44\u6e90\u53d7\u9650\u6216\u519c\u6751\u5730\u533a\u7684\u5efa\u7b51\u5b98\u5458\u9762\u4e34\u52b3\u52a8\u5bc6\u96c6\u578b\u3001\u6613\u51fa\u9519\u4e14\u6210\u672c\u9ad8\u6602\u7684\u8bbe\u8ba1\u6587\u4ef6\u624b\u52a8\u5ba1\u67e5\uff0c\u968f\u7740\u9879\u76ee\u89c4\u6a21\u548c\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4ee3\u7406\u9a71\u52a8\u6846\u67b6\uff0c\u96c6\u6210BIM\u6570\u636e\u63d0\u53d6\u4e0e\u81ea\u52a8\u5316\u9a8c\u8bc1\uff0c\u4f7f\u7528RAG\u548cMCP\u4ee3\u7406\u7ba1\u9053\uff0c\u901a\u8fc7COMcheck API\u8fdb\u884c\u786e\u5b9a\u6027\u68c0\u67e5\uff0cRAG\u8fdb\u884c\u7075\u6d3b\u63a8\u7406\u3002", "result": "\u6848\u4f8b\u6f14\u793a\u663e\u793a\u6846\u67b6\u80fd\u81ea\u52a8\u63d0\u53d6\u51e0\u4f55\u5c5e\u6027\u3001\u89e3\u6790\u64cd\u4f5c\u65f6\u95f4\u8868\u3001\u9a8c\u8bc1\u7167\u660e\u9650\u989d\uff0cGPT-4o\u5728\u6548\u7387\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0cMCP\u4ee3\u7406\u7ba1\u9053\u5728\u4e25\u8c28\u6027\u548c\u53ef\u9760\u6027\u4e0a\u4f18\u4e8eRAG\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63a8\u8fdb\u4e86ACR\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u53ef\u4e92\u64cd\u4f5c\u4e14\u751f\u4ea7\u5c31\u7eea\u7684\u65b9\u6cd5\uff0c\u5c06BIM\u4e0e\u6743\u5a01\u89c4\u8303\u5ba1\u67e5\u5de5\u5177\u8fde\u63a5\u8d77\u6765\u3002"}}
{"id": "2510.02608", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02608", "abs": "https://arxiv.org/abs/2510.02608", "authors": ["Chen Henry Wu", "Neil Kale", "Aditi Raghunathan"], "title": "Mitigating Modal Imbalance in Multimodal Reasoning", "comment": "10 pages, 10 figures, CoLM 2025", "summary": "Foundation models (FMs) deployed in real-world tasks such as computer-use\nagents must integrate diverse modalities. How good are FMs at performing joint\nreasoning, simultaneously reasoning over multiple modalities, especially when\nthe modalities interact and relate to each other to form cross-modal context?\nTo better understand this problem, we study FMs on cross-modal conflicts:\nscenarios where conflicting evidence is presented across modalities. This\nallows us to examine whether FMs prioritize one modality over another or reason\njointly to reconcile the conflict. Our experiments reveal that FMs can\nrecognize conflicts in unimodal contexts, composed of a single modality, 90% of\nthe time, but the ratio falls as low as 3% when evidence is split across\nmodalities -- similar observations hold in cross-lingual contexts, composed of\nmultiple languages. We trace this failure to cross-modal attention imbalance,\nshowing that FMs exhibit extreme asymmetry in attention scores,\ndisproportionately prioritizing certain modalities. We show that cross-modal\nattention imbalance does not go away by simply scaling up multimodal or\nmultilingual datasets blindly, since they lack training examples that\nexplicitly require cross-modal reasoning. We demonstrate that even a simple and\nscalable method of explicitly combining multiple modalities within each\ntraining instance significantly reduces attention imbalance. Reduced attention\nimbalance directly translates to improved downstream performance on several\nvision-language benchmarks. Our findings underscore the importance of\nsystematically addressing cross-modal contexts to build reliable foundation\nmodels.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u7840\u6a21\u578b\u5728\u591a\u6a21\u6001\u8054\u5408\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5f53\u4e0d\u540c\u6a21\u6001\u51fa\u73b0\u51b2\u7a81\u8bc1\u636e\u65f6\u7684\u5904\u7406\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5728\u8de8\u6a21\u6001\u51b2\u7a81\u573a\u666f\u4e0b\u8868\u73b0\u8f83\u5dee\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u4e0d\u5e73\u8861\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6539\u5584\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u57fa\u7840\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u5904\u7406\u591a\u6a21\u6001\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u540c\u65f6\u63a8\u7406\u591a\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u6a21\u6001\u65f6\u3002\u91cd\u70b9\u5173\u6ce8\u5f53\u4e0d\u540c\u6a21\u6001\u51fa\u73b0\u51b2\u7a81\u8bc1\u636e\u65f6\uff0c\u6a21\u578b\u662f\u5426\u80fd\u8fdb\u884c\u8054\u5408\u63a8\u7406\u6765\u8c03\u548c\u51b2\u7a81\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u8de8\u6a21\u6001\u51b2\u7a81\u5b9e\u9a8c\u573a\u666f\u6765\u6d4b\u8bd5\u6a21\u578b\u6027\u80fd\uff0c\u5206\u6790\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u663e\u5f0f\u7ec4\u5408\u591a\u4e2a\u6a21\u6001\u7684\u8bad\u7ec3\u5b9e\u4f8b\u6765\u51cf\u5c11\u6ce8\u610f\u529b\u4e0d\u5e73\u8861\u7684\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u6a21\u578b\u5728\u5355\u6a21\u6001\u51b2\u7a81\u8bc6\u522b\u4e2d\u8fbe\u523090%\u51c6\u786e\u7387\uff0c\u4f46\u5728\u8de8\u6a21\u6001\u51b2\u7a81\u4e2d\u964d\u81f33%\u3002\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u7684\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u4e0d\u5e73\u8861\uff0c\u67d0\u4e9b\u6a21\u6001\u88ab\u8fc7\u5ea6\u4f18\u5148\u8003\u8651\u3002\u63d0\u51fa\u7684\u7b80\u5355\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u5c11\u6ce8\u610f\u529b\u4e0d\u5e73\u8861\uff0c\u5e76\u63d0\u5347\u591a\u4e2a\u89c6\u89c9\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u7684\u6027\u80fd\u3002", "conclusion": "\u7cfb\u7edf\u6027\u5730\u5904\u7406\u8de8\u6a21\u6001\u4e0a\u4e0b\u6587\u5bf9\u4e8e\u6784\u5efa\u53ef\u9760\u7684\u57fa\u7840\u6a21\u578b\u81f3\u5173\u91cd\u8981\uff0c\u5f53\u524d\u6a21\u578b\u5728\u8de8\u6a21\u6001\u8054\u5408\u63a8\u7406\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u9700\u8981\u901a\u8fc7\u6539\u8fdb\u8bad\u7ec3\u7b56\u7565\u6765\u589e\u5f3a\u591a\u6a21\u6001\u6574\u5408\u80fd\u529b\u3002"}}
{"id": "2510.02378", "categories": ["cs.CR", "math.ST", "stat.AP", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.02378", "abs": "https://arxiv.org/abs/2510.02378", "authors": ["Jingrong Xie", "Yumin Li"], "title": "Apply Bayes Theorem to Optimize IVR Authentication Process", "comment": null, "summary": "This paper introduces a Bayesian approach to improve Interactive Voice\nResponse (IVR) authentication processes used by financial institutions.\nTraditional IVR systems authenticate users through a static sequence of\ncredentials, assuming uniform effectiveness among them. However, fraudsters\nexploit this predictability, selectively bypassing strong credentials. This\nstudy applies Bayes' Theorem and conditional probability modeling to evaluate\nfraud risk dynamically and adapt credential verification paths.", "AI": {"tldr": "\u4f7f\u7528\u8d1d\u53f6\u65af\u65b9\u6cd5\u6539\u8fdb\u91d1\u878dIVR\u8ba4\u8bc1\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u8bc4\u4f30\u6b3a\u8bc8\u98ce\u9669\u548c\u8c03\u6574\u51ed\u8bc1\u9a8c\u8bc1\u8def\u5f84\u6765\u5e94\u5bf9\u6b3a\u8bc8\u8005\u9009\u62e9\u6027\u7ed5\u8fc7\u5f3a\u51ed\u8bc1\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfIVR\u7cfb\u7edf\u4f7f\u7528\u9759\u6001\u51ed\u8bc1\u5e8f\u5217\u8fdb\u884c\u8ba4\u8bc1\uff0c\u5047\u8bbe\u6240\u6709\u51ed\u8bc1\u6548\u679c\u76f8\u540c\u3002\u4f46\u6b3a\u8bc8\u8005\u4f1a\u5229\u7528\u8fd9\u79cd\u53ef\u9884\u6d4b\u6027\uff0c\u9009\u62e9\u6027\u7ed5\u8fc7\u5f3a\u51ed\u8bc1\uff0c\u5bfc\u81f4\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u5e94\u7528\u8d1d\u53f6\u65af\u5b9a\u7406\u548c\u6761\u4ef6\u6982\u7387\u5efa\u6a21\uff0c\u52a8\u6001\u8bc4\u4f30\u6b3a\u8bc8\u98ce\u9669\u5e76\u81ea\u9002\u5e94\u8c03\u6574\u51ed\u8bc1\u9a8c\u8bc1\u8def\u5f84\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u6839\u636e\u5b9e\u65f6\u98ce\u9669\u8bc4\u4f30\u52a8\u6001\u8c03\u6574\u8ba4\u8bc1\u6d41\u7a0b\u7684\u8d1d\u53f6\u65af\u6846\u67b6\u3002", "conclusion": "\u8d1d\u53f6\u65af\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u9ad8IVR\u8ba4\u8bc1\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u901a\u8fc7\u52a8\u6001\u98ce\u9669\u8bc4\u4f30\u5e94\u5bf9\u6b3a\u8bc8\u653b\u51fb\u3002"}}
{"id": "2510.02718", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02718", "abs": "https://arxiv.org/abs/2510.02718", "authors": ["Ali Ghanbari", "Sasan Tavakkol"], "title": "Using Fourier Analysis and Mutant Clustering to Accelerate DNN Mutation Testing", "comment": "2025 40th IEEE/ACM International Conference on Automated Software\n  Engineering (ASE)", "summary": "Deep neural network (DNN) mutation analysis is a promising approach to\nevaluating test set adequacy. Due to the large number of generated mutants that\nmust be tested on large datasets, mutation analysis is costly. In this paper,\nwe present a technique, named DM#, for accelerating DNN mutation testing using\nFourier analysis. The key insight is that DNN outputs are real-valued functions\nsuitable for Fourier analysis that can be leveraged to quantify mutant behavior\nusing only a few data points. DM# uses the quantified mutant behavior to\ncluster the mutants so that the ones with similar behavior fall into the same\ngroup. A representative from each group is then selected for testing, and the\nresult of the test, e.g., whether the mutant is killed or survived, is reused\nfor all other mutants represented by the selected mutant, obviating the need\nfor testing other mutants. 14 DNN models of sizes ranging from thousands to\nmillions of parameters, trained on different datasets, are used to evaluate DM#\nand compare it to several baseline techniques. Our results provide empirical\nevidence on the effectiveness of DM# in accelerating mutation testing by\n28.38%, on average, at the average cost of only 0.72% error in mutation score.\nMoreover, on average, DM# incurs 11.78, 15.16, and 114.36 times less mutation\nscore error compared to random mutant selection, boundary sample selection, and\nrandom sample selection techniques, respectively, while generally offering\ncomparable speed-up.", "AI": {"tldr": "DM#\u662f\u4e00\u79cd\u57fa\u4e8e\u5085\u91cc\u53f6\u5206\u6790\u7684\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u53d8\u5f02\u6d4b\u8bd5\u52a0\u901f\u6280\u672f\uff0c\u901a\u8fc7\u91cf\u5316\u53d8\u5f02\u4f53\u884c\u4e3a\u8fdb\u884c\u805a\u7c7b\uff0c\u9009\u62e9\u4ee3\u8868\u6027\u53d8\u5f02\u4f53\u6d4b\u8bd5\u5e76\u5c06\u7ed3\u679c\u590d\u7528\u7ed9\u540c\u7c7b\u53d8\u5f02\u4f53\uff0c\u663e\u8457\u51cf\u5c11\u6d4b\u8bd5\u6210\u672c\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u53d8\u5f02\u5206\u6790\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u4e3a\u9700\u8981\u6d4b\u8bd5\u5927\u91cf\u53d8\u5f02\u4f53\u548c\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002", "method": "\u5229\u7528\u5085\u91cc\u53f6\u5206\u6790\u91cf\u5316\u53d8\u5f02\u4f53\u884c\u4e3a\uff0c\u8fdb\u884c\u805a\u7c7b\u5206\u7ec4\uff0c\u6bcf\u7ec4\u9009\u62e9\u4ee3\u8868\u6027\u53d8\u5f02\u4f53\u6d4b\u8bd5\u5e76\u590d\u7528\u7ed3\u679c\u3002", "result": "\u572814\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684DNN\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u5e73\u5747\u52a0\u901f28.38%\uff0c\u53d8\u5f02\u5206\u6570\u8bef\u5dee\u4ec50.72%\u3002\u76f8\u6bd4\u968f\u673a\u9009\u62e9\u3001\u8fb9\u754c\u6837\u672c\u9009\u62e9\u548c\u968f\u673a\u6837\u672c\u9009\u62e9\u6280\u672f\uff0c\u53d8\u5f02\u5206\u6570\u8bef\u5dee\u5206\u522b\u51cf\u5c1111.78\u300115.16\u548c114.36\u500d\u3002", "conclusion": "DM#\u80fd\u6709\u6548\u52a0\u901f\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u53d8\u5f02\u6d4b\u8bd5\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2510.02611", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02611", "abs": "https://arxiv.org/abs/2510.02611", "authors": ["Yuheng Wu", "Azalia Mirhoseini", "Thierry Tambe"], "title": "On the Role of Temperature Sampling in Test-Time Scaling", "comment": null, "summary": "Large language models (LLMs) can improve reasoning at inference time through\ntest-time scaling (TTS), where multiple reasoning traces are generated and the\nbest one is selected. Prior work shows that increasing the number of samples K\nsteadily improves accuracy. In this paper, we demonstrate that this trend does\nnot hold indefinitely: at large K, further scaling yields no gains, and certain\nhard questions remain unsolved regardless of the number of traces.\nInterestingly, we find that different sampling temperatures solve different\nsubsets of problems, implying that single-temperature scaling explores only\npart of a model's potential. We therefore propose scaling along the temperature\ndimension, which enlarges the reasoning boundary of LLMs. Averaged over Qwen3\n(0.6B, 1.7B, 4B, 8B) and five representative reasoning benchmarks (AIME\n2024/2025, MATH500, LiveCodeBench, Hi-ToM), temperature scaling yields an\nadditional 7.3 points over single-temperature TTS. Temperature scaling also\nenables base models to reach performance comparable to reinforcement learning\n(RL)-trained counterparts, without additional post-training. We further provide\na comprehensive analysis of this phenomenon and design a multi-temperature\nvoting method that reduces the overhead of temperature scaling. Overall, our\nfindings suggest that TTS is more powerful than previously thought, and that\ntemperature scaling offers a simple and effective way to unlock the latent\npotential of base models.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u6d4b\u8bd5\u65f6\u7f29\u653e\uff08TTS\uff09\u5728\u5927\u91cf\u6837\u672c\u4e0b\u4f1a\u8fbe\u5230\u6027\u80fd\u74f6\u9888\uff0c\u800c\u6e29\u5ea6\u7f29\u653e\u80fd\u663e\u8457\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u57fa\u7840\u6a21\u578b\u8fbe\u5230\u4e0e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u663e\u793a\u589e\u52a0\u63a8\u7406\u8f68\u8ff9\u6570\u91cf\u80fd\u63d0\u5347LLM\u63a8\u7406\u51c6\u786e\u7387\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u63d0\u5347\u5b58\u5728\u6781\u9650\uff0c\u4e14\u4e0d\u540c\u6e29\u5ea6\u80fd\u89e3\u51b3\u4e0d\u540c\u5b50\u96c6\u7684\u95ee\u9898\uff0c\u5355\u4e00\u6e29\u5ea6\u7f29\u653e\u53ea\u80fd\u63a2\u7d22\u6a21\u578b\u90e8\u5206\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u6e29\u5ea6\u7ef4\u5ea6\u7f29\u653e\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6e29\u5ea6\u91c7\u6837\u6269\u5927LLM\u7684\u63a8\u7406\u8fb9\u754c\uff0c\u5e76\u8bbe\u8ba1\u4e86\u591a\u6e29\u5ea6\u6295\u7968\u673a\u5236\u6765\u964d\u4f4e\u6e29\u5ea6\u7f29\u653e\u7684\u5f00\u9500\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6e29\u5ea6\u7f29\u653e\u6bd4\u5355\u4e00\u6e29\u5ea6TTS\u989d\u5916\u63d0\u53477.3\u4e2a\u767e\u5206\u70b9\uff0c\u4f7f\u57fa\u7840\u6a21\u578b\u6027\u80fd\u63a5\u8fd1RL\u8bad\u7ec3\u6a21\u578b\uff0c\u65e0\u9700\u989d\u5916\u540e\u8bad\u7ec3\u3002", "conclusion": "TTS\u7684\u6f5c\u529b\u88ab\u4f4e\u4f30\uff0c\u6e29\u5ea6\u7f29\u653e\u662f\u89e3\u9501\u57fa\u7840\u6a21\u578b\u6f5c\u5728\u80fd\u529b\u7684\u7b80\u5355\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.02379", "categories": ["cs.CR", "cs.PF", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.02379", "abs": "https://arxiv.org/abs/2510.02379", "authors": ["Abel C. H. Chen"], "title": "Hybrid Schemes of NIST Post-Quantum Cryptography Standard Algorithms and Quantum Key Distribution for Key Exchange and Digital Signature", "comment": "in Chinese language", "summary": "Since the security of post-quantum cryptography (PQC) algorithms is based on\nthe hardness of mathematical problems, while the security of quantum key\ndistribution (QKD) relies on the fundamental principles of quantum physics,\neach approach possesses distinct advantages and limitations that can complement\none another. Consequently, recent studies have proposed hybrid schemes that\ncombine QKD and PQC to establish a dual-layered security model. In response to\nthis trend, this study proposes hybrid schemes that integrate QKD with the\nNational Institute of Standards and Technology (NIST) standardized PQC\nalgorithms. These hybrid schemes include two core components: a hybrid QKD-PQC\nkey exchange protocol and a hybrid QKD-PQC digital signature scheme. For the\nhybrid key exchange protocol, this study combines Module-Lattice-based Key\nEncapsulation Mechanisms (ML-KEM) with QKD protocols, specifically BB84 and\nE91, to construct a secure key exchange protocol. In the design of the hybrid\ndigital signature scheme, this study utilizes Module-Lattice-based Digital\nSignature Algorithms (ML-DSA) and Stateless Hash-based Digital Signature\nAlgorithms (SLH-DSA) to generate signature reconstruction values. These values\nare verified using confirmation codes transmitted via the BB84 and E91\nprotocols. The proposed hybrid key exchange protocol is evaluated by examining\nthe shared secret key it produces, particularly with respect to entropy and\nwhether the output is independent and identically distributed (IID).\nFurthermore, the computation time and message lengths of the proposed hybrid\nschemes are evaluated.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1(QKD)\u548c\u540e\u91cf\u5b50\u5bc6\u7801(PQC)\u7684\u6df7\u5408\u5b89\u5168\u65b9\u6848\uff0c\u5305\u62ec\u6df7\u5408\u5bc6\u94a5\u4ea4\u6362\u534f\u8bae\u548c\u6df7\u5408\u6570\u5b57\u7b7e\u540d\u65b9\u6848\uff0c\u65e8\u5728\u6784\u5efa\u53cc\u91cd\u5b89\u5168\u5c42\u3002", "motivation": "\u7531\u4e8e\u540e\u91cf\u5b50\u5bc6\u7801\u57fa\u4e8e\u6570\u5b66\u95ee\u9898\u7684\u96be\u5ea6\uff0c\u800c\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u57fa\u4e8e\u91cf\u5b50\u7269\u7406\u539f\u7406\uff0c\u4e24\u8005\u5404\u6709\u4f18\u7f3a\u70b9\u53ef\u4ee5\u4e92\u8865\uff0c\u56e0\u6b64\u9700\u8981\u7ed3\u5408\u4e24\u8005\u6784\u5efa\u66f4\u5b89\u5168\u7684\u6df7\u5408\u65b9\u6848\u3002", "method": "\u5c06\u6a21\u5757\u683c\u57fa\u5bc6\u94a5\u5c01\u88c5\u673a\u5236(ML-KEM)\u4e0eBB84\u548cE91 QKD\u534f\u8bae\u7ed3\u5408\u6784\u5efa\u6df7\u5408\u5bc6\u94a5\u4ea4\u6362\u534f\u8bae\uff1b\u4f7f\u7528\u6a21\u5757\u683c\u57fa\u6570\u5b57\u7b7e\u540d\u7b97\u6cd5(ML-DSA)\u548c\u65e0\u72b6\u6001\u54c8\u5e0c\u57fa\u6570\u5b57\u7b7e\u540d\u7b97\u6cd5(SLH-DSA)\u751f\u6210\u7b7e\u540d\u91cd\u5efa\u503c\uff0c\u901a\u8fc7BB84\u548cE91\u534f\u8bae\u4f20\u8f93\u786e\u8ba4\u7801\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u8bc4\u4f30\u4e86\u6df7\u5408\u5bc6\u94a5\u4ea4\u6362\u534f\u8bae\u4ea7\u751f\u7684\u5171\u4eab\u5bc6\u94a5\u7684\u71b5\u548c\u72ec\u7acb\u540c\u5206\u5e03\u7279\u6027\uff0c\u4ee5\u53ca\u6df7\u5408\u65b9\u6848\u7684\u8ba1\u7b97\u65f6\u95f4\u548c\u6d88\u606f\u957f\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u65b9\u6848\u7ed3\u5408\u4e86QKD\u548cNIST\u6807\u51c6\u5316\u7684PQC\u7b97\u6cd5\uff0c\u4e3a\u6784\u5efa\u53cc\u91cd\u5b89\u5168\u5c42\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.02773", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02773", "abs": "https://arxiv.org/abs/2510.02773", "authors": ["Tamjid Al Rahat", "Yanju Chen", "Yu Feng", "Yuan Tian"], "title": "Automated Repair of OpenID Connect Programs (Extended Version)", "comment": "This is an extended version. The original paper is accepted to ASE\n  2025", "summary": "OpenID Connect has revolutionized online authentication based on single\nsign-on (SSO) by providing a secure and convenient method for accessing\nmultiple services with a single set of credentials. Despite its widespread\nadoption, critical security bugs in OpenID Connect have resulted in significant\nfinancial losses and security breaches, highlighting the need for robust\nmitigation strategies. Automated program repair presents a promising solution\nfor generating candidate patches for OpenID implementations. However,\nchallenges such as domain-specific complexities and the necessity for precise\nfault localization and patch verification must be addressed. We propose\nAuthFix, a counterexample-guided repair engine leveraging LLMs for automated\nOpenID bug fixing. AuthFix integrates three key components: fault localization,\npatch synthesis, and patch verification. By employing a novel Petri-net-based\nmodel checker, AuthFix ensures the correctness of patches by effectively\nmodeling interactions. Our evaluation on a dataset of OpenID bugs demonstrates\nthat AuthFix successfully generated correct patches for 17 out of 23 bugs\n(74%), with a high proportion of patches semantically equivalent to\ndeveloper-written fixes.", "AI": {"tldr": "AuthFix\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684OpenID Connect\u6f0f\u6d1e\u81ea\u52a8\u4fee\u590d\u5f15\u64ce\uff0c\u901a\u8fc7\u53cd\u4f8b\u5f15\u5bfc\u7684\u4fee\u590d\u65b9\u6cd5\uff0c\u572823\u4e2a\u6f0f\u6d1e\u4e2d\u6210\u529f\u4fee\u590d\u4e8617\u4e2a\uff0874%\uff09\uff0c\u4fee\u590d\u6548\u679c\u4e0e\u5f00\u53d1\u8005\u7f16\u5199\u7684\u8865\u4e01\u8bed\u4e49\u7b49\u6548\u3002", "motivation": "OpenID Connect\u867d\u7136\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\u5bfc\u81f4\u91cd\u5927\u7ecf\u6d4e\u635f\u5931\u548c\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u5f3a\u5927\u7684\u7f13\u89e3\u7b56\u7565\u3002\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u4e3aOpenID\u5b9e\u73b0\u751f\u6210\u5019\u9009\u8865\u4e01\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "AuthFix\u96c6\u6210\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u6545\u969c\u5b9a\u4f4d\u3001\u8865\u4e01\u5408\u6210\u548c\u8865\u4e01\u9a8c\u8bc1\u3002\u91c7\u7528\u65b0\u9896\u7684Petri\u7f51\u6a21\u578b\u68c0\u67e5\u5668\uff0c\u901a\u8fc7\u6709\u6548\u5efa\u6a21\u4ea4\u4e92\u6765\u786e\u4fdd\u8865\u4e01\u7684\u6b63\u786e\u6027\u3002", "result": "\u5728OpenID\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cAuthFix\u6210\u529f\u4e3a23\u4e2a\u6f0f\u6d1e\u4e2d\u768417\u4e2a\u751f\u6210\u4e86\u6b63\u786e\u8865\u4e01\uff0874%\uff09\uff0c\u5176\u4e2d\u5927\u90e8\u5206\u8865\u4e01\u4e0e\u5f00\u53d1\u8005\u7f16\u5199\u7684\u4fee\u590d\u5728\u8bed\u4e49\u4e0a\u7b49\u6548\u3002", "conclusion": "AuthFix\u8bc1\u660e\u4e86\u57fa\u4e8eLLM\u7684\u53cd\u4f8b\u5f15\u5bfc\u4fee\u590d\u65b9\u6cd5\u5728OpenID Connect\u5b89\u5168\u6f0f\u6d1e\u4fee\u590d\u4e2d\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u4e14\u8bed\u4e49\u6b63\u786e\u7684\u8865\u4e01\u3002"}}
{"id": "2510.02653", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.02653", "abs": "https://arxiv.org/abs/2510.02653", "authors": ["Micaela Fuel Pozo", "Andrea Guatumillo Saltos", "Yese\u00f1a Tipan Llumiquinga", "Kelly Lascano Aguirre", "Marilyn Castillo Jara", "Christian Mejia-Escobar"], "title": "Geolog-IA: Conversational System for Academic Theses", "comment": "17 pages, in Spanish language", "summary": "This study presents the development of Geolog-IA, a novel conversational\nsystem based on artificial intelligence that responds naturally to questions\nabout geology theses from the Central University of Ecuador. Our proposal uses\nthe Llama 3.1 and Gemini 2.5 language models, which are complemented by a\nRetrieval Augmented Generation (RAG) architecture and an SQLite database. This\nstrategy allows us to overcome problems such as hallucinations and outdated\nknowledge. The evaluation of Geolog-IA's performance with the BLEU metric\nreaches an average of 0.87, indicating high consistency and accuracy in the\nresponses generated. The system offers an intuitive, web-based interface that\nfacilitates interaction and information retrieval for directors, teachers,\nstudents, and administrative staff at the institution. This tool can be a key\nsupport in education, training, and research and establishes a basis for future\napplications in other disciplines.", "AI": {"tldr": "\u5f00\u53d1\u4e86Geolog-IA\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u4f7f\u7528Llama 3.1\u548cGemini 2.5\u6a21\u578b\u7ed3\u5408RAG\u67b6\u6784\u548cSQLite\u6570\u636e\u5e93\uff0c\u4e3a\u5384\u74dc\u591a\u5c14\u4e2d\u592e\u5927\u5b66\u5730\u8d28\u5b66\u8bba\u6587\u63d0\u4f9b\u81ea\u7136\u95ee\u7b54\u670d\u52a1\uff0cBLEU\u8bc4\u5206\u8fbe0.87\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfAI\u7cfb\u7edf\u5728\u4e13\u4e1a\u5730\u8d28\u5b66\u9886\u57df\u5b58\u5728\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u77e5\u8bc6\u8fc7\u65f6\u95ee\u9898\uff0c\u4e3a\u5927\u5b66\u5e08\u751f\u548c\u884c\u653f\u4eba\u5458\u63d0\u4f9b\u51c6\u786e\u7684\u5730\u8d28\u5b66\u8bba\u6587\u4fe1\u606f\u68c0\u7d22\u670d\u52a1\u3002", "method": "\u91c7\u7528Llama 3.1\u548cGemini 2.5\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u67b6\u6784\u548cSQLite\u6570\u636e\u5e93\uff0c\u6784\u5efa\u57fa\u4e8eweb\u7684\u5bf9\u8bdd\u7cfb\u7edf\u3002", "result": "\u7cfb\u7edf\u6027\u80fd\u8bc4\u4f30\u663e\u793aBLEU\u6307\u6807\u5e73\u5747\u8fbe\u52300.87\uff0c\u8868\u660e\u751f\u6210\u56de\u7b54\u5177\u6709\u9ad8\u5ea6\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\uff0c\u63d0\u4f9b\u4e86\u76f4\u89c2\u7684web\u754c\u9762\u3002", "conclusion": "Geolog-IA\u5728\u6559\u80b2\u3001\u57f9\u8bad\u548c\u7814\u7a76\u4e2d\u5177\u6709\u91cd\u8981\u652f\u6301\u4f5c\u7528\uff0c\u5e76\u4e3a\u5176\u4ed6\u5b66\u79d1\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.02383", "categories": ["cs.CR", "math.NT", "94A60"], "pdf": "https://arxiv.org/pdf/2510.02383", "abs": "https://arxiv.org/abs/2510.02383", "authors": ["Awnon Bhowmik"], "title": "Selmer-Inspired Elliptic Curve Generation", "comment": null, "summary": "Elliptic curve cryptography (ECC) is foundational to modern secure\ncommunication, yet existing standard curves have faced scrutiny for opaque\nparameter-generation practices. This work introduces a Selmer-inspired\nframework for constructing elliptic curves that is both transparent and\nauditable. Drawing from $2$- and $3$-descent methods, we derive binary quartics\nand ternary cubics whose classical invariants deterministically yield candidate\n$(c_4,c_6)$ parameters. Local solubility checks, modeled on Selmer\nadmissibility, filter candidates prior to reconciliation into short-Weierstrass\nform over prime fields. We then apply established cryptographic validations,\nincluding group-order factorization, cofactor bounds, twist security, and\nembedding-degree heuristics. A proof-of-concept implementation demonstrates\nthat the pipeline functions as a retry-until-success Las Vegas algorithm, with\ncomplete transcripts enabling independent verification. Unlike seed-based or\npurely efficiency-driven designs, our approach embeds arithmetic structure into\nparameter selection while remaining compatible with constant-time, side-channel\nresistant implementations. This work broadens the design space for elliptic\ncurves, showing that descent techniques from arithmetic geometry can underpin\ntrust-enhancing, standardization-ready constructions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSelmer\u7406\u8bba\u7684\u692d\u5706\u66f2\u7ebf\u6784\u9020\u6846\u67b6\uff0c\u901a\u8fc72-\u548c3-\u4e0b\u964d\u65b9\u6cd5\u751f\u6210\u53ef\u5ba1\u8ba1\u7684\u66f2\u7ebf\u53c2\u6570\uff0c\u7ed3\u5408\u5c40\u90e8\u53ef\u89e3\u6027\u68c0\u67e5\u548c\u5bc6\u7801\u5b66\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u900f\u660e\u53ef\u4fe1\u7684\u66f2\u7ebf\u8bbe\u8ba1\u3002", "motivation": "\u73b0\u6709\u6807\u51c6\u692d\u5706\u66f2\u7ebf\u7684\u53c2\u6570\u751f\u6210\u8fc7\u7a0b\u4e0d\u900f\u660e\uff0c\u5b58\u5728\u4fe1\u4efb\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u900f\u660e\u4e14\u53ef\u5ba1\u8ba1\u7684\u6784\u9020\u65b9\u6cd5\u6765\u589e\u5f3a\u5bc6\u7801\u5b66\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u4f7f\u75282-\u548c3-\u4e0b\u964d\u65b9\u6cd5\u63a8\u5bfc\u4e8c\u5143\u56db\u6b21\u578b\u548c\u4e09\u5143\u4e09\u6b21\u578b\uff0c\u901a\u8fc7\u7ecf\u5178\u4e0d\u53d8\u91cf\u786e\u5b9a\u5019\u9009\u53c2\u6570\uff0c\u8fdb\u884c\u5c40\u90e8\u53ef\u89e3\u6027\u7b5b\u9009\uff0c\u6700\u540e\u8f6c\u6362\u4e3a\u77edWeierstrass\u5f62\u5f0f\u5e76\u5e94\u7528\u5bc6\u7801\u5b66\u9a8c\u8bc1\u3002", "result": "\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u73b0\u8868\u660e\u8be5\u6846\u67b6\u53ef\u4f5c\u4e3aLas Vegas\u7b97\u6cd5\u8fd0\u884c\uff0c\u63d0\u4f9b\u5b8c\u6574\u7684\u53ef\u9a8c\u8bc1\u8bb0\u5f55\uff0c\u80fd\u591f\u751f\u6210\u7b26\u5408\u5bc6\u7801\u5b66\u5b89\u5168\u8981\u6c42\u7684\u692d\u5706\u66f2\u7ebf\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6269\u5c55\u4e86\u692d\u5706\u66f2\u7ebf\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u8bc1\u660e\u7b97\u672f\u51e0\u4f55\u4e2d\u7684\u4e0b\u964d\u6280\u672f\u53ef\u4ee5\u4e3a\u6807\u51c6\u5316\u5c31\u7eea\u7684\u6784\u9020\u63d0\u4f9b\u4fe1\u4efb\u589e\u5f3a\u57fa\u7840\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6052\u5b9a\u65f6\u95f4\u5b9e\u73b0\u7684\u517c\u5bb9\u6027\u3002"}}
{"id": "2510.02854", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02854", "abs": "https://arxiv.org/abs/2510.02854", "authors": ["Boshuai Ye", "Arif Ali Khan", "Teemu Pihkakoski", "Peng Liang", "Muhammad Azeem Akbar", "Matti Silveri", "Lauri Malmi"], "title": "C2|Q>: A Robust Framework for Bridging Classical and Quantum Software Development", "comment": "46 pages, 8 images, 14 tables, Manuscript submitted to a Journal\n  (2025)", "summary": "Quantum Software Engineering (QSE) is emerging as a critical discipline to\nmake quantum computing accessible to a broader developer community; however,\nmost quantum development environments still require developers to engage with\nlow-level details across the software stack - including problem encoding,\ncircuit construction, algorithm configuration, hardware selection, and result\ninterpretation - making them difficult for classical software engineers to use.\nTo bridge this gap, we present C2|Q>: a hardware-agnostic quantum software\ndevelopment framework that translates classical specifications (code) into\nquantum-executable programs while preserving methodological rigor. The\nframework applies modular software engineering principles by classifying the\nworkflow into three core modules: an encoder that classifies problems, produces\nQuantum-Compatible Formats (QCFs), and constructs quantum circuits, a\ndeployment module that generates circuits and recommends hardware based on\nfidelity, runtime, and cost, and a decoder that interprets quantum outputs into\nclassical solutions. In evaluation, the encoder module achieved a 93.8%\ncompletion rate, the hardware recommendation module consistently selected the\nappropriate quantum devices for workloads scaling up to 56 qubits, and the full\nC2|Q>: workflow successfully processed classical specifications (434 Python\nsnippets and 100 JSON inputs) with completion rates of 93.8% and 100%,\nrespectively. For case study problems executed on publicly available NISQ\nhardware, C2|Q>: reduced the required implementation effort by nearly 40X\ncompared to manual implementations using low-level quantum software development\nkits (SDKs), with empirical runs limited to small- and medium-sized instances\nconsistent with current NISQ capabilities. The open-source implementation of\nC2|Q>: is available at https://github.com/C2-Q/C2Q", "AI": {"tldr": "C2|Q>\u662f\u4e00\u4e2a\u786c\u4ef6\u65e0\u5173\u7684\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7ecf\u5178\u4ee3\u7801\u8f6c\u6362\u4e3a\u91cf\u5b50\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u91cf\u5b50\u7f16\u7a0b\u7684\u590d\u6742\u6027\u3002\u8be5\u6846\u67b6\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u5305\u542b\u7f16\u7801\u5668\u3001\u90e8\u7f72\u6a21\u5757\u548c\u89e3\u7801\u5668\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u3002", "motivation": "\u5f53\u524d\u91cf\u5b50\u5f00\u53d1\u73af\u5883\u8981\u6c42\u5f00\u53d1\u8005\u5904\u7406\u8f6f\u4ef6\u6808\u7684\u4f4e\u5c42\u7ec6\u8282\uff0c\u4f7f\u5f97\u7ecf\u5178\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u96be\u4ee5\u4f7f\u7528\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u7b80\u5316\u91cf\u5b50\u7f16\u7a0b\u7684\u6846\u67b6\u3002", "method": "\u6846\u67b6\u91c7\u7528\u6a21\u5757\u5316\u8f6f\u4ef6\u5de5\u7a0b\u539f\u5219\uff0c\u5206\u4e3a\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u7f16\u7801\u5668\uff08\u95ee\u9898\u5206\u7c7b\u3001\u751f\u6210\u91cf\u5b50\u517c\u5bb9\u683c\u5f0f\u548c\u6784\u5efa\u91cf\u5b50\u7535\u8def\uff09\u3001\u90e8\u7f72\u6a21\u5757\uff08\u751f\u6210\u7535\u8def\u5e76\u57fa\u4e8e\u4fdd\u771f\u5ea6\u3001\u8fd0\u884c\u65f6\u95f4\u548c\u6210\u672c\u63a8\u8350\u786c\u4ef6\uff09\u3001\u89e3\u7801\u5668\uff08\u5c06\u91cf\u5b50\u8f93\u51fa\u89e3\u91ca\u4e3a\u7ecf\u5178\u89e3\u51b3\u65b9\u6848\uff09\u3002", "result": "\u7f16\u7801\u5668\u6a21\u5757\u5b8c\u6210\u7387\u8fbe\u523093.8%\uff0c\u786c\u4ef6\u63a8\u8350\u6a21\u5757\u80fd\u591f\u4e3a\u6700\u591a56\u91cf\u5b50\u6bd4\u7279\u7684\u5de5\u4f5c\u8d1f\u8f7d\u9009\u62e9\u5408\u9002\u7684\u91cf\u5b50\u8bbe\u5907\uff0c\u5b8c\u6574\u5de5\u4f5c\u6d41\u5904\u7406\u4e86434\u4e2aPython\u4ee3\u7801\u7247\u6bb5\u548c100\u4e2aJSON\u8f93\u5165\uff0c\u5b8c\u6210\u7387\u5206\u522b\u4e3a93.8%\u548c100%\u3002\u5728NISQ\u786c\u4ef6\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u76f8\u6bd4\u624b\u52a8\u5b9e\u73b0\u51cf\u5c11\u4e86\u8fd140\u500d\u7684\u5de5\u4f5c\u91cf\u3002", "conclusion": "C2|Q>\u6846\u67b6\u6210\u529f\u964d\u4f4e\u4e86\u91cf\u5b50\u7f16\u7a0b\u7684\u590d\u6742\u6027\uff0c\u4f7f\u7ecf\u5178\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u80fd\u591f\u66f4\u8f7b\u677e\u5730\u5f00\u53d1\u91cf\u5b50\u5e94\u7528\uff0c\u4e3a\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2510.02655", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02655", "abs": "https://arxiv.org/abs/2510.02655", "authors": ["Daniel G. Schwartz"], "title": "A Concept of Possibility for Real-World Events", "comment": null, "summary": "This paper offers a new concept of {\\it possibility} as an alternative to the\nnow-a-days standard concept originally introduced by L.A. Zadeh in 1978. This\nnew version was inspired by the original but, formally, has nothing in common\nwith it other than that they both adopt the {\\L}ukasiewicz multivalent\ninterpretation of the logical connectives. Moreover, rather than seeking to\nprovide a general notion of possibility, this focuses specifically on the\npossibility of a real-world event. An event is viewed as having prerequisites\nthat enable its occurrence and constraints that may impede its occurrence, and\nthe possibility of the event is computed as a function of the probabilities\nthat the prerequisites hold and the constraints do not. This version of\npossibility might appropriately be applied to problems of planning. When there\nare multiple plans available for achieving a goal, this theory can be used to\ndetermine which plan is most possible, i.e., easiest or most feasible to\ncomplete. It is speculated that this model of reasoning correctly captures\nnormal human reasoning about plans. The theory is elaborated and an\nillustrative example for vehicle route planning is provided. There is also a\nsuggestion of potential future applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u80fd\u6027\u6982\u5ff5\u4f5c\u4e3aZadeh(1978)\u6807\u51c6\u6982\u5ff5\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4e13\u6ce8\u4e8e\u73b0\u5b9e\u4e16\u754c\u4e8b\u4ef6\u7684\u53ef\u80fd\u6027\u8ba1\u7b97\uff0c\u7279\u522b\u9002\u7528\u4e8e\u89c4\u5212\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u53ef\u80fd\u6027\u7406\u8bba\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e8b\u4ef6\u53ef\u80fd\u6027\u7684\u65b0\u6982\u5ff5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5e94\u7528\u4e8e\u89c4\u5212\u95ee\u9898\u5e76\u53cd\u6620\u4eba\u7c7b\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u5c06\u4e8b\u4ef6\u89c6\u4e3a\u5177\u6709\u4fc3\u6210\u5176\u53d1\u751f\u7684\u5148\u51b3\u6761\u4ef6\u548c\u963b\u788d\u5176\u53d1\u751f\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u53ef\u80fd\u6027\u8ba1\u7b97\u57fa\u4e8e\u5148\u51b3\u6761\u4ef6\u6210\u7acb\u548c\u7ea6\u675f\u6761\u4ef6\u4e0d\u6210\u7acb\u7684\u6982\u7387\u51fd\u6570\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u80fd\u6027\u7406\u8bba\u6846\u67b6\uff0c\u80fd\u591f\u6bd4\u8f83\u4e0d\u540c\u89c4\u5212\u65b9\u6848\u7684\u53ef\u884c\u6027\uff0c\u5e76\u901a\u8fc7\u8f66\u8f86\u8def\u5f84\u89c4\u5212\u793a\u4f8b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u79cd\u65b0\u7684\u53ef\u80fd\u6027\u6a21\u578b\u80fd\u591f\u51c6\u786e\u6355\u6349\u4eba\u7c7b\u5bf9\u89c4\u5212\u7684\u6b63\u5e38\u63a8\u7406\u8fc7\u7a0b\uff0c\u5728\u89c4\u5212\u95ee\u9898\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u5e94\u7528\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.02384", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02384", "abs": "https://arxiv.org/abs/2510.02384", "authors": ["Jie Cao", "Qi Li", "Zelin Zhang", "Jianbing Ni"], "title": "Secure and Robust Watermarking for AI-generated Images: A Comprehensive Survey", "comment": null, "summary": "The rapid advancement of generative artificial intelligence (Gen-AI) has\nfacilitated the effortless creation of high-quality images, while\nsimultaneously raising critical concerns regarding intellectual property\nprotection, authenticity, and accountability. Watermarking has emerged as a\npromising solution to these challenges by distinguishing AI-generated images\nfrom natural content, ensuring provenance, and fostering trustworthy digital\necosystems. This paper presents a comprehensive survey of the current state of\nAI-generated image watermarking, addressing five key dimensions: (1)\nformalization of image watermarking systems; (2) an overview and comparison of\ndiverse watermarking techniques; (3) evaluation methodologies with respect to\nvisual quality, capacity, and detectability; (4) vulnerabilities to malicious\nattacks; and (5) prevailing challenges and future directions. The survey aims\nto equip researchers with a holistic understanding of AI-generated image\nwatermarking technologies, thereby promoting their continued development.", "AI": {"tldr": "\u672c\u6587\u5bf9AI\u751f\u6210\u56fe\u50cf\u6c34\u5370\u6280\u672f\u8fdb\u884c\u4e86\u5168\u9762\u8c03\u67e5\uff0c\u6db5\u76d6\u7cfb\u7edf\u5f62\u5f0f\u5316\u3001\u6280\u672f\u6bd4\u8f83\u3001\u8bc4\u4f30\u65b9\u6cd5\u3001\u5b89\u5168\u6f0f\u6d1e\u548c\u672a\u6765\u65b9\u5411\u4e94\u4e2a\u7ef4\u5ea6\uff0c\u65e8\u5728\u4fc3\u8fdb\u8be5\u9886\u57df\u53d1\u5c55\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5feb\u901f\u53d1\u5c55\uff0c\u9ad8\u8d28\u91cf\u56fe\u50cf\u521b\u5efa\u53d8\u5f97\u5bb9\u6613\uff0c\u4f46\u4e5f\u5f15\u53d1\u4e86\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u3001\u771f\u5b9e\u6027\u548c\u8d23\u4efb\u5f52\u5c5e\u7b49\u5173\u952e\u95ee\u9898\uff0c\u9700\u8981\u6c34\u5370\u6280\u672f\u6765\u533a\u5206AI\u751f\u6210\u56fe\u50cf\u4e0e\u81ea\u7136\u5185\u5bb9\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u8c03\u67e5\u65b9\u6cd5\uff0c\u4ece\u4e94\u4e2a\u5173\u952e\u7ef4\u5ea6\u5206\u6790AI\u751f\u6210\u56fe\u50cf\u6c34\u5370\u6280\u672f\uff1a\u7cfb\u7edf\u5f62\u5f0f\u5316\u3001\u591a\u6837\u5316\u6c34\u5370\u6280\u672f\u6982\u8ff0\u4e0e\u6bd4\u8f83\u3001\u57fa\u4e8e\u89c6\u89c9\u8d28\u91cf\u3001\u5bb9\u91cf\u548c\u53ef\u68c0\u6d4b\u6027\u7684\u8bc4\u4f30\u65b9\u6cd5\u3001\u6076\u610f\u653b\u51fb\u6f0f\u6d1e\u5206\u6790\u3002", "result": "\u63d0\u4f9b\u4e86\u5bf9AI\u751f\u6210\u56fe\u50cf\u6c34\u5370\u6280\u672f\u7684\u5168\u9762\u7406\u89e3\uff0c\u5305\u62ec\u5404\u79cd\u6280\u672f\u7684\u6bd4\u8f83\u5206\u6790\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u8be5\u9886\u57df\u7684\u6574\u4f53\u89c6\u56fe\u3002", "conclusion": "\u6c34\u5370\u6280\u672f\u662f\u89e3\u51b3AI\u751f\u6210\u56fe\u50cf\u76f8\u5173\u6311\u6218\u7684\u6709\u524d\u666f\u65b9\u6848\uff0c\u8be5\u8c03\u67e5\u65e8\u5728\u4fc3\u8fdbAI\u751f\u6210\u56fe\u50cf\u6c34\u5370\u6280\u672f\u7684\u6301\u7eed\u53d1\u5c55\uff0c\u5efa\u7acb\u53ef\u4fe1\u7684\u6570\u5b57\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2510.02887", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02887", "abs": "https://arxiv.org/abs/2510.02887", "authors": ["Zhao Zhang", "Qingyuan Liang", "Zeyu Sun", "Yizhou Chen", "Guoqing Wang", "Yican Sun", "Lu Zhang", "Ge Li", "Yingfei Xiong"], "title": "GramTrans: A Better Code Representation Approach in Code Generation", "comment": null, "summary": "Code generation has shown great promise in assisting software development. A\nfundamental yet underexplored question is how the choice of code representation\naffects model performance. While existing studies employ various\nrepresentations, such as treating code as plain text, grammar rule sequences,\nor syntax tree sequences, they lack a principled understanding of the\nrelationship between parsing difficulty and model effectiveness. This paper\nproposes a conjecture: the easier a representation is to parse, the better\nperformance the model achieves. We formalize this idea using grammar classes,\nwhere representations in simpler classes (e.g., LL(1)) are easier to parse.\nThrough a controlled experiment on a Python-based DSL, we show that parsing\ndifficulty strongly correlates with model performance. Motivated by this\nfinding, we present GramTrans, a general approach that automatically transforms\na context-free language into a representation within the LL(1) class. GramTrans\nintroduces a novel hierarchical conflict elimination algorithm, enabling a\nflexible trade-off between syntactic simplicity and token efficiency. We\nevaluate GramTrans on both Python and Java using three code generation models:\nStarCoder 1B, DeepSeek-Coder 1.3B, and Qwen2.5 1.5B. Across multiple\nbenchmarks, GramTrans consistently delivers significant improvements over\nbaseline representations. Furthermore, our analysis of existing representations\nreconfirms the strong alignment between parsing difficulty and model\nperformance, providing additional support for the conjecture.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u731c\u60f3\uff1a\u4ee3\u7801\u8868\u793a\u8d8a\u5bb9\u6613\u89e3\u6790\uff0c\u6a21\u578b\u6027\u80fd\u8d8a\u597d\u3002\u901a\u8fc7GramTrans\u65b9\u6cd5\u5c06\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u8f6c\u6362\u4e3aLL(1)\u7c7b\u8868\u793a\uff0c\u5b9e\u9a8c\u8bc1\u660e\u89e3\u6790\u96be\u5ea6\u4e0e\u6a21\u578b\u6027\u80fd\u5f3a\u76f8\u5173\u3002", "motivation": "\u63a2\u7d22\u4ee3\u7801\u8868\u793a\u9009\u62e9\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff0c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u89e3\u6790\u96be\u5ea6\u4e0e\u6a21\u578b\u6709\u6548\u6027\u5173\u7cfb\u7684\u7cfb\u7edf\u6027\u7406\u89e3\u3002", "method": "\u63d0\u51faGramTrans\u65b9\u6cd5\uff0c\u4f7f\u7528\u5206\u5c42\u51b2\u7a81\u6d88\u9664\u7b97\u6cd5\u5c06\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u8f6c\u6362\u4e3aLL(1)\u7c7b\u8868\u793a\uff0c\u5728\u89e3\u6790\u7b80\u5355\u6027\u548c\u6807\u8bb0\u6548\u7387\u4e4b\u95f4\u5b9e\u73b0\u7075\u6d3b\u6743\u8861\u3002", "result": "\u5728Python\u548cJava\u4e0a\u4f7f\u7528\u4e09\u4e2a\u4ee3\u7801\u751f\u6210\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0cGramTrans\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76f8\u6bd4\u57fa\u7ebf\u8868\u793a\u5747\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u89e3\u6790\u96be\u5ea6\u4e0e\u6a21\u578b\u6027\u80fd\u5b58\u5728\u5f3a\u76f8\u5173\u6027\uff0cGramTrans\u901a\u8fc7\u7b80\u5316\u89e3\u6790\u590d\u6742\u5ea6\u6709\u6548\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2510.02669", "categories": ["cs.AI", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.02669", "abs": "https://arxiv.org/abs/2510.02669", "authors": ["Bo Ma", "Hang Li", "ZeHua Hu", "XiaoFan Gui", "LuYao Liu", "Simon Liu"], "title": "AutoMaAS: Self-Evolving Multi-Agent Architecture Search for Large Language Models", "comment": null, "summary": "Multi-agent systems powered by large language models have demonstrated\nremarkable capabilities across diverse domains, yet existing automated design\napproaches seek monolithic solutions that fail to adapt resource allocation\nbased on query complexity and domain requirements. This paper introduces\nAutoMaAS, a self-evolving multi-agent architecture search framework that\nleverages neural architecture search principles to automatically discover\noptimal agent configurations through dynamic operator lifecycle management and\nautomated machine learning techniques. Our approach incorporates four key\ninnovations: (1) automatic operator generation, fusion, and elimination based\non performance-cost analysis, (2) dynamic cost-aware optimization with\nreal-time parameter adjustment, (3) online feedback integration for continuous\narchitecture refinement, and (4) enhanced interpretability through decision\ntracing mechanisms. Extensive experiments across six benchmarks demonstrate\nthat AutoMaAS achieves 1.0-7.1\\% performance improvement while reducing\ninference costs by 3-5\\% compared to state-of-the-art methods. The framework\nshows superior transferability across datasets and LLM backbones, establishing\na new paradigm for automated multi-agent system design in the era of large\nlanguage models.", "AI": {"tldr": "AutoMaAS\u662f\u4e00\u4e2a\u81ea\u6f14\u5316\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\u641c\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u539f\u7406\u81ea\u52a8\u53d1\u73b0\u6700\u4f18\u667a\u80fd\u4f53\u914d\u7f6e\uff0c\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u548c\u63a8\u7406\u6210\u672c\u964d\u4f4e\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u8bbe\u8ba1\u65b9\u6cd5\u5bfb\u6c42\u5355\u4e00\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u6cd5\u6839\u636e\u67e5\u8be2\u590d\u6742\u5ea6\u548c\u9886\u57df\u9700\u6c42\u81ea\u9002\u5e94\u5206\u914d\u8d44\u6e90\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u52a8\u6001\u7b97\u5b50\u751f\u547d\u5468\u671f\u7ba1\u7406\u548c\u81ea\u52a8\u5316\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5305\u62ec\u81ea\u52a8\u7b97\u5b50\u751f\u6210\u3001\u878d\u5408\u548c\u6d88\u9664\uff0c\u52a8\u6001\u6210\u672c\u611f\u77e5\u4f18\u5316\uff0c\u5728\u7ebf\u53cd\u9988\u96c6\u6210\u548c\u51b3\u7b56\u8ffd\u8e2a\u673a\u5236\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAutoMaAS\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5b9e\u73b01.0-7.1%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u51cf\u5c113-5%\u7684\u63a8\u7406\u6210\u672c\uff0c\u5e76\u5728\u6570\u636e\u96c6\u548cLLM\u9aa8\u5e72\u7f51\u7edc\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u53ef\u8fc1\u79fb\u6027\u3002", "conclusion": "AutoMaAS\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3\u7684\u81ea\u52a8\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\uff0c\u5c55\u793a\u4e86\u81ea\u6f14\u5316\u67b6\u6784\u641c\u7d22\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.02386", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02386", "abs": "https://arxiv.org/abs/2510.02386", "authors": ["Han Wang", "Haoyu Li", "Brian Ko", "Huan Zhang"], "title": "On The Fragility of Benchmark Contamination Detection in Reasoning Models", "comment": null, "summary": "Leaderboards for LRMs have turned evaluation into a competition,\nincentivizing developers to optimize directly on benchmark suites. A shortcut\nto achieving higher rankings is to incorporate evaluation benchmarks into the\ntraining data, thereby yielding inflated performance, known as benchmark\ncontamination. Surprisingly, our studies find that evading contamination\ndetections for LRMs is alarmingly easy. We focus on the two scenarios where\ncontamination may occur in practice: (I) when the base model evolves into LRM\nvia SFT and RL, we find that contamination during SFT can be originally\nidentified by contamination detection methods. Yet, even a brief GRPO training\ncan markedly conceal contamination signals that most detection methods rely on.\nFurther empirical experiments and theoretical analysis indicate that PPO style\nimportance sampling and clipping objectives are the root cause of this\ndetection concealment, indicating that a broad class of RL methods may\ninherently exhibit similar concealment capability; (II) when SFT contamination\nwith CoT is applied to advanced LRMs as the final stage, most contamination\ndetection methods perform near random guesses. Without exposure to non-members,\ncontaminated LRMs would still have more confidence when responding to those\nunseen samples that share similar distributions to the training set, and thus,\nevade existing memorization-based detection methods. Together, our findings\nreveal the unique vulnerability of LRMs evaluations: Model developers could\neasily contaminate LRMs to achieve inflated leaderboards performance while\nleaving minimal traces of contamination, thereby strongly undermining the\nfairness of evaluation and threatening the integrity of public leaderboards.\nThis underscores the urgent need for advanced contamination detection methods\nand trustworthy evaluation protocols tailored to LRMs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u7684\u57fa\u51c6\u6c61\u67d3\u68c0\u6d4b\u5b58\u5728\u4e25\u91cd\u6f0f\u6d1e\uff0c\u6a21\u578b\u5f00\u53d1\u8005\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u7684\u8bad\u7ec3\u6280\u5de7\u8f7b\u677e\u89c4\u907f\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4ece\u800c\u5728\u6392\u884c\u699c\u4e0a\u83b7\u5f97\u865a\u9ad8\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u7531\u4e8e\u6392\u884c\u699c\u7ade\u4e89\u6fc0\u70c8\uff0c\u5f00\u53d1\u8005\u6709\u52a8\u673a\u5c06\u8bc4\u4f30\u57fa\u51c6\u6570\u636e\u6df7\u5165\u8bad\u7ec3\u96c6\u4ee5\u83b7\u5f97\u66f4\u9ad8\u6392\u540d\uff0c\u8fd9\u79cd\u57fa\u51c6\u6c61\u67d3\u95ee\u9898\u4e25\u91cd\u5a01\u80c1\u8bc4\u4f30\u7684\u516c\u5e73\u6027\u548c\u6392\u884c\u699c\u7684\u5b8c\u6574\u6027\u3002", "method": "\u7814\u7a76\u805a\u7126\u4e24\u79cd\u5b9e\u9645\u6c61\u67d3\u573a\u666f\uff1a(I)\u57fa\u7840\u6a21\u578b\u901a\u8fc7SFT\u548cRL\u6f14\u53d8\u4e3aLRM\u65f6\uff0c\u5373\u4f7fSFT\u9636\u6bb5\u6c61\u67d3\u53ef\u88ab\u68c0\u6d4b\uff0c\u4f46\u7b80\u77ed\u7684GRPO\u8bad\u7ec3\u5c31\u80fd\u63a9\u76d6\u6c61\u67d3\u4fe1\u53f7\uff1b(II)\u5728\u9ad8\u7ea7LRMs\u4e0a\u5e94\u7528\u5e26CoT\u7684SFT\u6c61\u67d3\u4f5c\u4e3a\u6700\u7ec8\u9636\u6bb5\u65f6\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u51e0\u4e4e\u5931\u6548\u3002", "result": "PPO\u98ce\u683c\u7684\u91cd\u8981\u6027\u91c7\u6837\u548c\u88c1\u526a\u76ee\u6807\u662f\u68c0\u6d4b\u63a9\u76d6\u7684\u6839\u672c\u539f\u56e0\uff0c\u8868\u660e\u5e7f\u6cdb\u7684RL\u65b9\u6cd5\u90fd\u5177\u6709\u7c7b\u4f3c\u63a9\u76d6\u80fd\u529b\u3002\u6c61\u67d3\u540e\u7684LRMs\u5bf9\u4e0e\u8bad\u7ec3\u96c6\u5206\u5e03\u76f8\u4f3c\u7684\u672a\u89c1\u6837\u672c\u4ecd\u4fdd\u6301\u9ad8\u7f6e\u4fe1\u5ea6\uff0c\u4ece\u800c\u89c4\u907f\u57fa\u4e8e\u8bb0\u5fc6\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "conclusion": "LRMs\u8bc4\u4f30\u5b58\u5728\u72ec\u7279\u8106\u5f31\u6027\uff0c\u5f00\u53d1\u8005\u53ef\u8f7b\u6613\u6c61\u67d3\u6a21\u578b\u83b7\u5f97\u865a\u9ad8\u6392\u540d\u800c\u7559\u4e0b\u6781\u5c11\u75d5\u8ff9\uff0c\u8fd9\u4e25\u91cd\u7834\u574f\u8bc4\u4f30\u516c\u5e73\u6027\u548c\u6392\u884c\u699c\u5b8c\u6574\u6027\uff0c\u8feb\u5207\u9700\u8981\u9488\u5bf9LRMs\u7684\u5148\u8fdb\u6c61\u67d3\u68c0\u6d4b\u65b9\u6cd5\u548c\u53ef\u4fe1\u8bc4\u4f30\u534f\u8bae\u3002"}}
{"id": "2510.02917", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02917", "abs": "https://arxiv.org/abs/2510.02917", "authors": ["Kriz Tahimic", "Charibeth Cheng"], "title": "Mechanistic Interpretability of Code Correctness in LLMs via Sparse Autoencoders", "comment": null, "summary": "As Large Language Models become integral to software development, with\nsubstantial portions of AI-suggested code entering production, understanding\ntheir internal correctness mechanisms becomes critical for safe deployment. We\napply sparse autoencoders to decompose LLM representations, identifying\ndirections that correspond to code correctness. We select predictor directions\nusing t-statistics and steering directions through separation scores from base\nmodel representations, then analyze their mechanistic properties through\nsteering, attention analysis, and weight orthogonalization. We find that code\ncorrectness directions in LLMs reliably predict incorrect code, while\ncorrection capabilities, though statistically significant, involve tradeoffs\nbetween fixing errors and preserving correct code. Mechanistically, successful\ncode generation depends on attending to test cases rather than problem\ndescriptions. Moreover, directions identified in base models retain their\neffectiveness after instruction-tuning, suggesting code correctness mechanisms\nlearned during pre-training are repurposed during fine-tuning. Our mechanistic\ninsights suggest three practical applications: prompting strategies should\nprioritize test examples over elaborate problem descriptions, predictor\ndirections can serve as error alarms for developer review, and these same\npredictors can guide selective steering, intervening only when errors are\nanticipated to prevent the code corruption from constant steering.", "AI": {"tldr": "\u901a\u8fc7\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5206\u6790LLM\u5185\u90e8\u8868\u793a\uff0c\u8bc6\u522b\u4ee3\u7801\u6b63\u786e\u6027\u76f8\u5173\u65b9\u5411\uff0c\u53d1\u73b0\u4ee3\u7801\u6b63\u786e\u6027\u65b9\u5411\u80fd\u53ef\u9760\u9884\u6d4b\u9519\u8bef\u4ee3\u7801\uff0c\u800c\u4fee\u6b63\u80fd\u529b\u6d89\u53ca\u6743\u8861\u3002\u6210\u529f\u4ee3\u7801\u751f\u6210\u4f9d\u8d56\u4e8e\u5173\u6ce8\u6d4b\u8bd5\u7528\u4f8b\u800c\u975e\u95ee\u9898\u63cf\u8ff0\uff0c\u4e14\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u4ee3\u7801\u6b63\u786e\u6027\u673a\u5236\u5728\u6307\u4ee4\u5fae\u8c03\u540e\u4ecd\u7136\u6709\u6548\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u7406\u89e3\u5176\u5185\u90e8\u6b63\u786e\u6027\u673a\u5236\u5bf9\u4e8e\u5b89\u5168\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5f53\u5927\u91cfAI\u5efa\u8bae\u4ee3\u7801\u8fdb\u5165\u751f\u4ea7\u73af\u5883\u65f6\u3002", "method": "\u5e94\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5206\u89e3LLM\u8868\u793a\uff0c\u4f7f\u7528t\u7edf\u8ba1\u91cf\u9009\u62e9\u9884\u6d4b\u65b9\u5411\uff0c\u901a\u8fc7\u5206\u79bb\u5206\u6570\u4ece\u57fa\u7840\u6a21\u578b\u8868\u793a\u4e2d\u8bc6\u522b\u5f15\u5bfc\u65b9\u5411\uff0c\u5e76\u901a\u8fc7\u5f15\u5bfc\u3001\u6ce8\u610f\u529b\u5206\u6790\u548c\u6743\u91cd\u6b63\u4ea4\u5316\u5206\u6790\u5176\u673a\u5236\u7279\u6027\u3002", "result": "\u4ee3\u7801\u6b63\u786e\u6027\u65b9\u5411\u80fd\u53ef\u9760\u9884\u6d4b\u9519\u8bef\u4ee3\u7801\uff0c\u4fee\u6b63\u80fd\u529b\u867d\u7edf\u8ba1\u663e\u8457\u4f46\u6d89\u53ca\u6743\u8861\uff1b\u6210\u529f\u4ee3\u7801\u751f\u6210\u4f9d\u8d56\u4e8e\u5173\u6ce8\u6d4b\u8bd5\u7528\u4f8b\uff1b\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u4ee3\u7801\u6b63\u786e\u6027\u65b9\u5411\u5728\u6307\u4ee4\u5fae\u8c03\u540e\u4ecd\u4fdd\u6301\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e09\u4e2a\u5b9e\u9645\u5e94\u7528\uff1a\u63d0\u793a\u7b56\u7565\u5e94\u4f18\u5148\u6d4b\u8bd5\u7528\u4f8b\u800c\u975e\u8be6\u7ec6\u95ee\u9898\u63cf\u8ff0\uff0c\u9884\u6d4b\u65b9\u5411\u53ef\u4f5c\u4e3a\u9519\u8bef\u8b66\u62a5\u4f9b\u5f00\u53d1\u8005\u5ba1\u67e5\uff0c\u8fd9\u4e9b\u9884\u6d4b\u5668\u53ef\u6307\u5bfc\u9009\u62e9\u6027\u5f15\u5bfc\uff0c\u4ec5\u5728\u9884\u671f\u9519\u8bef\u65f6\u5e72\u9884\u4ee5\u907f\u514d\u4ee3\u7801\u635f\u574f\u3002"}}
{"id": "2510.02677", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02677", "abs": "https://arxiv.org/abs/2510.02677", "authors": ["Zhaorun Chen", "Xun Liu", "Mintong Kang", "Jiawei Zhang", "Minzhou Pan", "Shuang Yang", "Bo Li"], "title": "ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks", "comment": "60 pages, 16 figures", "summary": "As vision-language models (VLMs) gain prominence, their multimodal interfaces\nalso introduce new safety vulnerabilities, making the safety evaluation\nchallenging and critical. Existing red-teaming efforts are either restricted to\na narrow set of adversarial patterns or depend heavily on manual engineering,\nlacking scalable exploration of emerging real-world VLM vulnerabilities. To\nbridge this gap, we propose ARMs, an adaptive red-teaming agent that\nsystematically conducts comprehensive risk assessments for VLMs. Given a target\nharmful behavior or risk definition, ARMs automatically optimizes diverse\nred-teaming strategies with reasoning-enhanced multi-step orchestration, to\neffectively elicit harmful outputs from target VLMs. We propose 11 novel\nmultimodal attack strategies, covering diverse adversarial patterns of VLMs\n(e.g., reasoning hijacking, contextual cloaking), and integrate 17 red-teaming\nalgorithms into ARMs via model context protocol (MCP). To balance the diversity\nand effectiveness of the attack, we design a layered memory with an\nepsilon-greedy attack exploration algorithm. Extensive experiments on instance-\nand policy-based benchmarks show that ARMs achieves SOTA attack success rates,\nexceeding baselines by an average of 52.1% and surpassing 90% on\nClaude-4-Sonnet. We show that the diversity of red-teaming instances generated\nby ARMs is significantly higher, revealing emerging vulnerabilities in VLMs.\nLeveraging ARMs, we construct ARMs-Bench, a large-scale multimodal safety\ndataset comprising over 30K red-teaming instances spanning 51 diverse risk\ncategories, grounded in both real-world multimodal threats and regulatory\nrisks. Safety fine-tuning with ARMs-Bench substantially improves the robustness\nof VLMs while preserving their general utility, providing actionable guidance\nto improve multimodal safety alignment against emerging threats.", "AI": {"tldr": "ARMs\u662f\u4e00\u4e2a\u81ea\u9002\u5e94\u7ea2\u961f\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u63a8\u7406\u589e\u5f3a\u7684\u591a\u6b65\u9aa4\u7f16\u6392\u81ea\u52a8\u4f18\u5316\u591a\u6837\u5316\u7ea2\u961f\u7b56\u7565\uff0c\u6709\u6548\u5f15\u53d1\u76ee\u6807VLM\u7684\u6709\u5bb3\u8f93\u51fa\uff0c\u5728\u653b\u51fb\u6210\u529f\u7387\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd552.1%\uff0c\u5e76\u6784\u5efa\u4e86\u5305\u542b30K+\u5b9e\u4f8b\u7684\u5927\u89c4\u6a21\u591a\u6a21\u6001\u5b89\u5168\u6570\u636e\u96c6ARMs-Bench\u3002", "motivation": "\u968f\u7740\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u7684\u666e\u53ca\uff0c\u5176\u591a\u6a21\u6001\u63a5\u53e3\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u73b0\u6709\u7ea2\u961f\u65b9\u6cd5\u8981\u4e48\u5c40\u9650\u4e8e\u6709\u9650\u7684\u5bf9\u6297\u6a21\u5f0f\uff0c\u8981\u4e48\u4f9d\u8d56\u4eba\u5de5\u5de5\u7a0b\uff0c\u7f3a\u4e4f\u5bf9\u65b0\u5174\u73b0\u5b9e\u4e16\u754cVLM\u6f0f\u6d1e\u7684\u53ef\u6269\u5c55\u63a2\u7d22\u3002", "method": "\u63d0\u51fa11\u79cd\u65b0\u9896\u7684\u591a\u6a21\u6001\u653b\u51fb\u7b56\u7565\uff0c\u6db5\u76d6VLM\u7684\u591a\u6837\u5316\u5bf9\u6297\u6a21\u5f0f\uff0c\u901a\u8fc7\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae(MCP)\u96c6\u621017\u79cd\u7ea2\u961f\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u5206\u5c42\u8bb0\u5fc6\u548cepsilon-greedy\u653b\u51fb\u63a2\u7d22\u7b97\u6cd5\u6765\u5e73\u8861\u653b\u51fb\u7684\u591a\u6837\u6027\u548c\u6709\u6548\u6027\u3002", "result": "\u5728\u5b9e\u4f8b\u7ea7\u548c\u7b56\u7565\u7ea7\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cARMs\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e73\u5747\u8d85\u8fc7\u57fa\u7ebf52.1%\uff0c\u5728Claude-4-Sonnet\u4e0a\u8d85\u8fc790%\u3002\u751f\u6210\u7684\u7ea2\u961f\u5b9e\u4f8b\u591a\u6837\u6027\u663e\u8457\u66f4\u9ad8\uff0c\u63ed\u793a\u4e86VLM\u7684\u65b0\u5174\u6f0f\u6d1e\u3002", "conclusion": "\u57fa\u4e8eARMs\u6784\u5efa\u7684ARMs-Bench\u6570\u636e\u96c6\u901a\u8fc7\u5b89\u5168\u5fae\u8c03\u663e\u8457\u63d0\u9ad8\u4e86VLM\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u901a\u7528\u6548\u7528\uff0c\u4e3a\u6539\u8fdb\u591a\u6a21\u6001\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002"}}
{"id": "2510.02391", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02391", "abs": "https://arxiv.org/abs/2510.02391", "authors": ["Nik Rollinson", "Nikolaos Polatidis"], "title": "LLM-Generated Samples for Android Malware Detection", "comment": "24 pages", "summary": "Android malware continues to evolve through obfuscation and polymorphism,\nposing challenges for both signature-based defenses and machine learning models\ntrained on limited and imbalanced datasets. Synthetic data has been proposed as\na remedy for scarcity, yet the role of large language models (LLMs) in\ngenerating effective malware data for detection tasks remains underexplored. In\nthis study, we fine-tune GPT-4.1-mini to produce structured records for three\nmalware families: BankBot, Locker/SLocker, and Airpush/StopSMS, using the\nKronoDroid dataset. After addressing generation inconsistencies with prompt\nengineering and post-processing, we evaluate multiple classifiers under three\nsettings: training with real data only, real-plus-synthetic data, and synthetic\ndata alone. Results show that real-only training achieves near perfect\ndetection, while augmentation with synthetic data preserves high performance\nwith only minor degradations. In contrast, synthetic-only training produces\nmixed outcomes, with effectiveness varying across malware families and\nfine-tuning strategies. These findings suggest that LLM-generated malware can\nenhance scarce datasets without compromising detection accuracy, but remains\ninsufficient as a standalone training source.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e86\u4f7f\u7528GPT-4.1-mini\u751f\u6210Android\u6076\u610f\u8f6f\u4ef6\u5408\u6210\u6570\u636e\u6765\u589e\u5f3a\u68c0\u6d4b\u6a21\u578b\u8bad\u7ec3\uff0c\u53d1\u73b0\u5408\u6210\u6570\u636e\u80fd\u6709\u6548\u8865\u5145\u7a00\u7f3a\u6570\u636e\u96c6\u4f46\u4e0d\u8db3\u4ee5\u4f5c\u4e3a\u72ec\u7acb\u8bad\u7ec3\u6e90\u3002", "motivation": "Android\u6076\u610f\u8f6f\u4ef6\u901a\u8fc7\u6df7\u6dc6\u548c\u591a\u6001\u6027\u4e0d\u65ad\u8fdb\u5316\uff0c\u800c\u57fa\u4e8e\u7b7e\u540d\u7684\u9632\u5fa1\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u6709\u9650\u4e14\u4e0d\u5e73\u8861\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u63a2\u7d22LLM\u5728\u751f\u6210\u6709\u6548\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u5fae\u8c03GPT-4.1-mini\u4e3a\u4e09\u4e2a\u6076\u610f\u8f6f\u4ef6\u5bb6\u65cf\u751f\u6210\u7ed3\u6784\u5316\u8bb0\u5f55\uff0c\u4f7f\u7528KronoDroid\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u548c\u540e\u5904\u7406\u89e3\u51b3\u751f\u6210\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5e76\u5728\u4e09\u79cd\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u5206\u7c7b\u5668\uff1a\u4ec5\u771f\u5b9e\u6570\u636e\u3001\u771f\u5b9e\u52a0\u5408\u6210\u6570\u636e\u3001\u4ec5\u5408\u6210\u6570\u636e\u3002", "result": "\u4ec5\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u8bad\u7ec3\u53ef\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u68c0\u6d4b\uff0c\u6dfb\u52a0\u5408\u6210\u6570\u636e\u540e\u6027\u80fd\u4fdd\u6301\u9ad8\u4f4d\u4ec5\u6709\u8f7b\u5fae\u4e0b\u964d\uff0c\u800c\u4ec5\u4f7f\u7528\u5408\u6210\u6570\u636e\u8bad\u7ec3\u6548\u679c\u4e0d\u4e00\uff0c\u6709\u6548\u6027\u56e0\u6076\u610f\u8f6f\u4ef6\u5bb6\u65cf\u548c\u5fae\u8c03\u7b56\u7565\u800c\u5f02\u3002", "conclusion": "LLM\u751f\u6210\u7684\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u53ef\u4ee5\u589e\u5f3a\u7a00\u7f3a\u6570\u636e\u96c6\u800c\u4e0d\u635f\u5bb3\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u4f46\u4f5c\u4e3a\u72ec\u7acb\u8bad\u7ec3\u6e90\u4ecd\u4e0d\u8db3\u591f\u3002"}}
{"id": "2510.02934", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02934", "abs": "https://arxiv.org/abs/2510.02934", "authors": ["Thanh Trong Vu", "Tuan-Dung Bui", "Thu-Trang Nguyen", "Son Nguyen", "Hieu Dinh Vo"], "title": "Model-Agnostic Correctness Assessment for LLM-Generated Code via Dynamic Internal Representation Selection", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in\ncode generation and are increasingly integrated into the software development\nprocess. However, ensuring the correctness of LLM-generated code remains a\ncritical concern. Prior work has shown that the internal representations of\nLLMs encode meaningful signals for assessing code correctness. Nevertheless,\nthe existing methods rely on representations from pre-selected/fixed layers and\ntoken positions, which could limit its generalizability across diverse model\narchitectures and tasks. In this work, we introduce AUTOPROBE, a novel\nmodel-agnostic approach that dynamically selects the most informative internal\nrepresentations for code correctness assessment. AUTOPROBE employs an\nattention-based mechanism to learn importance scores for hidden states,\nenabling it to focus on the most relevant features. These weighted\nrepresentations are then aggregated and passed to a probing classifier to\npredict code correctness across multiple dimensions, including compilability,\nfunctionality, and security. To evaluate the performance of AUTOPROBE, we\nconduct extensive experiments across multiple benchmarks and code LLMs. Our\nexperimental results show that AUTOPROBE consistently outperforms the\nbaselines. For security assessment, AUTOPROBE surpasses the state-of-the-art\nwhite-box approach by 18%. For compilability and functionality assessment,\nAUTOPROBE demonstrates its highest robustness to code complexity, with the\nperformance higher than the other approaches by up to 19% and 111%,\nrespectively. These findings highlight that dynamically selecting important\ninternal signals enables AUTOPROBE to serve as a robust and generalizable\nsolution for assessing the correctness of code generated by various LLMs.", "AI": {"tldr": "AUTOPROBE\u662f\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9LLM\u5185\u90e8\u6700\u6709\u4fe1\u606f\u91cf\u7684\u8868\u793a\u6765\u8bc4\u4f30\u4ee3\u7801\u6b63\u786e\u6027\uff0c\u5728\u7f16\u8bd1\u6027\u3001\u529f\u80fd\u6027\u548c\u5b89\u5168\u6027\u8bc4\u4f30\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9884\u9009/\u56fa\u5b9a\u5c42\u548ctoken\u4f4d\u7f6e\u7684\u8868\u793a\uff0c\u8fd9\u9650\u5236\u4e86\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u548c\u4efb\u52a1\u95f4\u7684\u6cdb\u5316\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u52a8\u6001\u9009\u62e9\u6700\u91cd\u8981\u5185\u90e8\u8868\u793a\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u4ee3\u7801\u6b63\u786e\u6027\u8bc4\u4f30\u7684\u9c81\u68d2\u6027\u3002", "method": "AUTOPROBE\u4f7f\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u673a\u5236\u5b66\u4e60\u9690\u85cf\u72b6\u6001\u7684\u91cd\u8981\u6027\u5206\u6570\uff0c\u805a\u7126\u6700\u76f8\u5173\u7279\u5f81\uff0c\u7136\u540e\u5c06\u52a0\u6743\u8868\u793a\u805a\u5408\u5e76\u4f20\u9012\u7ed9\u63a2\u6d4b\u5206\u7c7b\u5668\uff0c\u9884\u6d4b\u4ee3\u7801\u5728\u591a\u4e2a\u7ef4\u5ea6\u7684\u6b63\u786e\u6027\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u4ee3\u7801LLM\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAUTOPROBE\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002\u5b89\u5168\u6027\u8bc4\u4f30\u8d85\u8d8a\u6700\u5148\u8fdb\u767d\u76d2\u65b9\u6cd518%\uff1b\u7f16\u8bd1\u6027\u548c\u529f\u80fd\u6027\u8bc4\u4f30\u5bf9\u4ee3\u7801\u590d\u6742\u5ea6\u7684\u9c81\u68d2\u6027\u6700\u9ad8\uff0c\u6027\u80fd\u5206\u522b\u6bd4\u5176\u4ed6\u65b9\u6cd5\u9ad8\u51fa19%\u548c111%\u3002", "conclusion": "\u52a8\u6001\u9009\u62e9\u91cd\u8981\u5185\u90e8\u4fe1\u53f7\u4f7fAUTOPROBE\u80fd\u591f\u4f5c\u4e3a\u8bc4\u4f30\u5404\u79cdLLM\u751f\u6210\u4ee3\u7801\u6b63\u786e\u6027\u7684\u9c81\u68d2\u4e14\u53ef\u6cdb\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.02679", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02679", "abs": "https://arxiv.org/abs/2510.02679", "authors": ["Yu-Zhe Shi", "Qiao Xu", "Yanjia Li", "Mingchen Liu", "Huamin Qu", "Lecheng Ruan", "Qining Wang"], "title": "Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation", "comment": "Accepted for publication in IEEE Transactions on Automation Science\n  and Engineering", "summary": "Advanced Planning and Scheduling (APS) systems have become indispensable for\nmodern manufacturing operations, enabling optimized resource allocation and\nproduction efficiency in increasingly complex and dynamic environments. While\nalgorithms for solving abstracted scheduling problems have been extensively\ninvestigated, the critical prerequisite of specifying manufacturing\nrequirements into formal constraints remains manual and labor-intensive.\nAlthough recent advances of generative models, particularly Large Language\nModels (LLMs), show promise in automating constraint specification from\nheterogeneous raw manufacturing data, their direct application faces challenges\ndue to natural language ambiguity, non-deterministic outputs, and limited\ndomain-specific knowledge. This paper presents a constraint-centric\narchitecture that regulates LLMs to perform reliable automated constraint\nspecification for production scheduling. The architecture defines a\nhierarchical structural space organized across three levels, implemented\nthrough domain-specific representation to ensure precision and reliability\nwhile maintaining flexibility. Furthermore, an automated production scenario\nadaptation algorithm is designed and deployed to efficiently customize the\narchitecture for specific manufacturing configurations. Experimental results\ndemonstrate that the proposed approach successfully balances the generative\ncapabilities of LLMs with the reliability requirements of manufacturing\nsystems, significantly outperforming pure LLM-based approaches in constraint\nspecification tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u7ea6\u675f\u4e2d\u5fc3\u67b6\u6784\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u751f\u4ea7\u8c03\u5ea6\u4e2d\u7684\u7ea6\u675f\u89c4\u8303\uff0c\u89e3\u51b3\u4e86LLM\u76f4\u63a5\u5e94\u7528\u65f6\u7684\u6a21\u7cca\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u6311\u6218\u3002", "motivation": "\u73b0\u4ee3\u5236\u9020\u7cfb\u7edf\u4e2d\uff0c\u5c06\u5236\u9020\u9700\u6c42\u8f6c\u5316\u4e3a\u6b63\u5f0f\u7ea6\u675f\u7684\u8fc7\u7a0b\u4ecd\u7136\u9700\u8981\u5927\u91cf\u4eba\u5de5\u64cd\u4f5c\uff0c\u800c\u73b0\u6709LLM\u65b9\u6cd5\u5b58\u5728\u81ea\u7136\u8bed\u8a00\u6a21\u7cca\u6027\u3001\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\u548c\u9886\u57df\u77e5\u8bc6\u6709\u9650\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7ea6\u675f\u4e2d\u5fc3\u7684\u4e09\u5c42\u5c42\u6b21\u7ed3\u6784\u67b6\u6784\uff0c\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u8868\u793a\u786e\u4fdd\u7cbe\u5ea6\u548c\u53ef\u9760\u6027\uff0c\u540c\u65f6\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u751f\u4ea7\u573a\u666f\u9002\u914d\u7b97\u6cd5\u6765\u5b9a\u5236\u7279\u5b9a\u5236\u9020\u914d\u7f6e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u5e73\u8861\u4e86LLM\u7684\u751f\u6210\u80fd\u529b\u4e0e\u5236\u9020\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u8981\u6c42\uff0c\u5728\u7ea6\u675f\u89c4\u8303\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u7eafLLM\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ea6\u675f\u4e2d\u5fc3\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u5236\u9020\u7ea6\u675f\u89c4\u8303\u4e2d\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u5316\u751f\u4ea7\u8c03\u5ea6\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.02395", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.02395", "abs": "https://arxiv.org/abs/2510.02395", "authors": ["Hongbo Liu", "Jiannong Cao", "Bo Yang", "Dongbin Bai", "Yinfeng Cao", "Xiaoming Shen", "Yinan Zhang", "Jinwen Liang", "Shan Jiang", "Mingjin Zhang"], "title": "PolyLink: A Blockchain Based Decentralized Edge AI Platform for LLM Inference", "comment": null, "summary": "The rapid advancement of large language models (LLMs) in recent years has\nrevolutionized the AI landscape. However, the deployment model and usage of LLM\nservices remain highly centralized, creating significant trust issues and costs\nfor end users and developers. To address these issues, we propose PolyLink, a\nblockchain-based decentralized AI platform that decentralizes LLM development\nand inference. Specifically, PolyLink introduces a decentralized crowdsourcing\narchitecture that supports single-device and cross-device model deployment and\ninference across heterogeneous devices at the edge. Moreover, to ensure the\ninference integrity, we design the TIQE protocol, which combines a lightweight\ncross-encoder model and an LLM-as-a-Judge for a high-accuracy inference\nevaluation. Lastly, we integrate a comprehensive token-based incentive model\nwith dynamic pricing and reward mechanisms for all participants. We have\ndeployed PolyLink and conducted an extensive real-world evaluation through\ngeo-distributed deployment across heterogeneous devices. Results indicate that\nthe inference and verification latency is practical. Our security analysis\ndemonstrates that the system is resistant to model degradation attacks and\nvalidator corruptions. PolyLink is now available at\nhttps://github.com/IMCL-PolyLink/PolyLink.", "AI": {"tldr": "PolyLink\u662f\u4e00\u4e2a\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316AI\u5e73\u53f0\uff0c\u901a\u8fc7\u5206\u6563\u5316LLM\u5f00\u53d1\u548c\u63a8\u7406\u6765\u89e3\u51b3\u4e2d\u5fc3\u5316LLM\u670d\u52a1\u7684\u4fe1\u4efb\u548c\u6210\u672c\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u670d\u52a1\u7684\u90e8\u7f72\u548c\u4f7f\u7528\u9ad8\u5ea6\u4e2d\u5fc3\u5316\uff0c\u5bfc\u81f4\u7ec8\u7aef\u7528\u6237\u548c\u5f00\u53d1\u8005\u9762\u4e34\u4e25\u91cd\u7684\u4fe1\u4efb\u95ee\u9898\u548c\u6210\u672c\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u4f17\u5305\u67b6\u6784\uff0c\u652f\u6301\u5728\u5f02\u6784\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fdb\u884c\u5355\u8bbe\u5907\u548c\u8de8\u8bbe\u5907\u6a21\u578b\u90e8\u7f72\u4e0e\u63a8\u7406\uff1b\u8bbe\u8ba1TIQE\u534f\u8bae\u7ed3\u5408\u8f7b\u91cf\u7ea7\u4ea4\u53c9\u7f16\u7801\u5668\u6a21\u578b\u548cLLM-as-a-Judge\u8fdb\u884c\u9ad8\u7cbe\u5ea6\u63a8\u7406\u8bc4\u4f30\uff1b\u96c6\u6210\u57fa\u4e8e\u4ee3\u5e01\u7684\u6fc0\u52b1\u6a21\u578b\uff0c\u5177\u6709\u52a8\u6001\u5b9a\u4ef7\u548c\u5956\u52b1\u673a\u5236\u3002", "result": "\u901a\u8fc7\u5730\u7406\u5206\u5e03\u5f0f\u90e8\u7f72\u5728\u5f02\u6784\u8bbe\u5907\u4e0a\u8fdb\u884c\u5b9e\u9645\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u63a8\u7406\u548c\u9a8c\u8bc1\u5ef6\u8fdf\u662f\u5b9e\u7528\u7684\uff1b\u5b89\u5168\u5206\u6790\u8868\u660e\u7cfb\u7edf\u80fd\u591f\u62b5\u6297\u6a21\u578b\u9000\u5316\u653b\u51fb\u548c\u9a8c\u8bc1\u5668\u635f\u574f\u3002", "conclusion": "PolyLink\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684LLM\u5e73\u53f0\uff0c\u89e3\u51b3\u4e86\u4e2d\u5fc3\u5316\u670d\u52a1\u7684\u4fe1\u4efb\u548c\u6210\u672c\u95ee\u9898\uff0c\u7cfb\u7edf\u6027\u80fd\u548c\u5b89\u5168\u6027\u80fd\u826f\u597d\uff0c\u73b0\u5df2\u5f00\u6e90\u53ef\u7528\u3002"}}
{"id": "2510.02991", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02991", "abs": "https://arxiv.org/abs/2510.02991", "authors": ["Carlos Albuquerque", "Filipe F. Correia"], "title": "Tracing and Metrics Design Patterns for Monitoring Cloud-native Applications", "comment": "Accepted for publication in the EuroPLoP 2025 proceedings", "summary": "Observability helps ensure the reliability and maintainability of\ncloud-native applications. As software architectures become increasingly\ndistributed and subject to change, it becomes a greater challenge to diagnose\nsystem issues effectively, often having to deal with fragmented observability\nand more difficult root cause analysis. This paper builds upon our previous\nwork and introduces three design patterns that address key challenges in\nmonitoring cloud-native applications. Distributed Tracing improves visibility\ninto request flows across services, aiding in latency analysis and root cause\ndetection, Application Metrics provides a structured approach to instrumenting\napplications with meaningful performance indicators, enabling real-time\nmonitoring and anomaly detection, and Infrastructure Metrics focuses on\nmonitoring the environment in which the system is operated, helping teams\nassess resource utilization, scalability, and operational health. These\npatterns are derived from industry practices and observability frameworks and\naim to offer guidance for software practitioners.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e09\u79cd\u76d1\u63a7\u4e91\u539f\u751f\u5e94\u7528\u7684\u8bbe\u8ba1\u6a21\u5f0f\uff1a\u5206\u5e03\u5f0f\u8ffd\u8e2a\u3001\u5e94\u7528\u6307\u6807\u548c\u57fa\u7840\u8bbe\u65bd\u6307\u6807\uff0c\u65e8\u5728\u89e3\u51b3\u5206\u5e03\u5f0f\u7cfb\u7edf\u76d1\u63a7\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u67b6\u6784\u65e5\u76ca\u5206\u5e03\u5f0f\u548c\u6613\u53d8\uff0c\u8bca\u65ad\u7cfb\u7edf\u95ee\u9898\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\uff0c\u9700\u8981\u5e94\u5bf9\u788e\u7247\u5316\u7684\u53ef\u89c2\u6d4b\u6027\u548c\u66f4\u590d\u6742\u7684\u6839\u56e0\u5206\u6790\u3002", "method": "\u57fa\u4e8e\u5148\u524d\u5de5\u4f5c\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u8bbe\u8ba1\u6a21\u5f0f\uff1a\u5206\u5e03\u5f0f\u8ffd\u8e2a\u7528\u4e8e\u8de8\u670d\u52a1\u8bf7\u6c42\u6d41\u7684\u53ef\u89c1\u6027\uff0c\u5e94\u7528\u6307\u6807\u7528\u4e8e\u7ed3\u6784\u5316\u5e94\u7528\u6027\u80fd\u76d1\u63a7\uff0c\u57fa\u7840\u8bbe\u65bd\u6307\u6807\u7528\u4e8e\u73af\u5883\u76d1\u63a7\u3002", "result": "\u8fd9\u4e9b\u6a21\u5f0f\u6e90\u81ea\u884c\u4e1a\u5b9e\u8df5\u548c\u53ef\u89c2\u6d4b\u6027\u6846\u67b6\uff0c\u4e3a\u8f6f\u4ef6\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u76d1\u63a7\u6307\u5bfc\u3002", "conclusion": "\u4e09\u79cd\u8bbe\u8ba1\u6a21\u5f0f\u5171\u540c\u6784\u6210\u4e86\u4e91\u539f\u751f\u5e94\u7528\u53ef\u89c2\u6d4b\u6027\u7684\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002"}}
{"id": "2510.02816", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02816", "abs": "https://arxiv.org/abs/2510.02816", "authors": ["Yulong Zhang", "Li Wang", "Wei Du", "Peilin Li", "Yuqin Dai Zhiyuan Zhao", "Lingyong Fang", "Ziniu Liu", "Ru Zhang", "Huijia Zhu", "Gongshen Liu"], "title": "NCV: A Node-Wise Consistency Verification Approach for Low-Cost Structured Error Localization in LLM Reasoning", "comment": null, "summary": "Verifying multi-step reasoning in large language models is difficult due to\nimprecise error localization and high token costs. Existing methods either\nassess entire reasoning chains, suffering attention dilution, or rely on\nexpensive multi-sampling. We introduce Node-wise Consistency Verification\n(NCV), a training-free framework that recasts verification as lightweight\nbinary consistency checks at the node level. By decomposing the chain of\nthought into interconnected verification nodes, NCV precisely localizes errors\nand avoids unnecessary long-form generation. Experiments demonstrate that our\napproach enhances interpretability and efficiency, presenting a scalable\nsolution for reliable LLM reasoning verification. On public datasets, NCV\nachieves a 10\\% to 25\\% improvement in F1 scores over baselines while utilizing\n$6\\times$~$58\\times$ fewer tokens than traditional methods like CoT-based\nverifiers.", "AI": {"tldr": "\u63d0\u51faNode-wise Consistency Verification (NCV)\u6846\u67b6\uff0c\u901a\u8fc7\u8282\u70b9\u7ea7\u4e00\u81f4\u6027\u68c0\u67e5\u6765\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u63a8\u7406\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u7cbe\u786e\u3001\u9ad8\u6548\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u63a8\u7406\uff0c\u5b58\u5728\u9519\u8bef\u5b9a\u4f4d\u4e0d\u7cbe\u786e\u548ctoken\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u8981\u4e48\u8bc4\u4f30\u6574\u4e2a\u63a8\u7406\u94fe\u5bfc\u81f4\u6ce8\u610f\u529b\u5206\u6563\uff0c\u8981\u4e48\u4f9d\u8d56\u6602\u8d35\u591a\u91cd\u91c7\u6837\u3002", "method": "NCV\u5c06\u9a8c\u8bc1\u91cd\u6784\u4e3a\u8f7b\u91cf\u7ea7\u7684\u8282\u70b9\u7ea7\u4e8c\u5143\u4e00\u81f4\u6027\u68c0\u67e5\uff0c\u5c06\u601d\u7ef4\u94fe\u5206\u89e3\u4e3a\u76f8\u4e92\u8fde\u63a5\u7684\u9a8c\u8bc1\u8282\u70b9\uff0c\u907f\u514d\u4e0d\u5fc5\u8981\u751f\u6210\u957f\u6587\u672c\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0cNCV\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5F1\u5206\u6570\u63d0\u534710%\u523025%\uff0c\u540c\u65f6\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u57fa\u4e8eCoT\u7684\u9a8c\u8bc1\u5668\uff09\u51cf\u5c116\u500d\u523058\u500d\u7684token\u4f7f\u7528\u91cf\u3002", "conclusion": "NCV\u6846\u67b6\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u6548\u7387\uff0c\u4e3a\u53ef\u9760\u7684LLM\u63a8\u7406\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.02422", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02422", "abs": "https://arxiv.org/abs/2510.02422", "authors": ["Kedong Xiu", "Churui Zeng", "Tianhang Zheng", "Xinzhe Huang", "Xiaojun Jia", "Di Wang", "Puning Zhao", "Zhan Qin", "Kui Ren"], "title": "Dynamic Target Attack", "comment": null, "summary": "Existing gradient-based jailbreak attacks typically optimize an adversarial\nsuffix to induce a fixed affirmative response. However, this fixed target\nusually resides in an extremely low-density region of a safety-aligned LLM's\noutput distribution conditioned on diverse harmful inputs. Due to the\nsubstantial discrepancy between the target and the original output, existing\nattacks require numerous iterations to optimize the adversarial prompt, which\nmight still fail to induce the low-probability target response from the target\nLLM. In this paper, we propose Dynamic Target Attack (DTA), a new jailbreaking\nframework relying on the target LLM's own responses as targets to optimize the\nadversarial prompts. In each optimization round, DTA iteratively samples\nmultiple candidate responses directly from the output distribution conditioned\non the current prompt, and selects the most harmful response as a temporary\ntarget for prompt optimization. In contrast to existing attacks, DTA\nsignificantly reduces the discrepancy between the target and the output\ndistribution, substantially easing the optimization process to search for an\neffective adversarial prompt.\n  Extensive experiments demonstrate the superior effectiveness and efficiency\nof DTA: under the white-box setting, DTA only needs 200 optimization iterations\nto achieve an average attack success rate (ASR) of over 87\\% on recent\nsafety-aligned LLMs, exceeding the state-of-the-art baselines by over 15\\%. The\ntime cost of DTA is 2-26 times less than existing baselines. Under the\nblack-box setting, DTA uses Llama-3-8B-Instruct as a surrogate model for target\nsampling and achieves an ASR of 85\\% against the black-box target model\nLlama-3-70B-Instruct, exceeding its counterparts by over 25\\%.", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u76ee\u6807\u653b\u51fb(DTA)\u6846\u67b6\uff0c\u4f7f\u7528\u76ee\u6807LLM\u81ea\u8eab\u54cd\u5e94\u4f5c\u4e3a\u4f18\u5316\u76ee\u6807\u6765\u751f\u6210\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u663e\u8457\u964d\u4f4e\u76ee\u6807\u4e0e\u8f93\u51fa\u5206\u5e03\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u63d0\u9ad8\u8d8a\u72f1\u653b\u51fb\u7684\u6548\u7387\u548c\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u68af\u5ea6\u7684\u8d8a\u72f1\u653b\u51fb\u901a\u5e38\u4f18\u5316\u5bf9\u6297\u6027\u540e\u7f00\u4ee5\u8bf1\u5bfc\u56fa\u5b9a\u7684\u80af\u5b9a\u54cd\u5e94\uff0c\u4f46\u8be5\u76ee\u6807\u901a\u5e38\u4f4d\u4e8e\u5b89\u5168\u5bf9\u9f50LLM\u8f93\u51fa\u5206\u5e03\u7684\u4f4e\u5bc6\u5ea6\u533a\u57df\uff0c\u5bfc\u81f4\u4f18\u5316\u8fc7\u7a0b\u56f0\u96be\u4e14\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5728\u6bcf\u8f6e\u4f18\u5316\u4e2d\uff0cDTA\u4ece\u5f53\u524d\u63d0\u793a\u7684\u8f93\u51fa\u5206\u5e03\u4e2d\u91c7\u6837\u591a\u4e2a\u5019\u9009\u54cd\u5e94\uff0c\u9009\u62e9\u6700\u6709\u5bb3\u7684\u54cd\u5e94\u4f5c\u4e3a\u4e34\u65f6\u76ee\u6807\u8fdb\u884c\u63d0\u793a\u4f18\u5316\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u76ee\u6807\u6765\u7b80\u5316\u4f18\u5316\u8fc7\u7a0b\u3002", "result": "\u5728\u767d\u76d2\u8bbe\u7f6e\u4e0b\uff0cDTA\u4ec5\u9700200\u6b21\u4f18\u5316\u8fed\u4ee3\u5373\u53ef\u5728\u6700\u65b0\u5b89\u5168\u5bf9\u9f50LLMs\u4e0a\u5b9e\u73b0\u5e73\u574787%\u4ee5\u4e0a\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u6bd4\u73b0\u6709\u6700\u4f73\u57fa\u7ebf\u9ad8\u51fa15%\u4ee5\u4e0a\uff0c\u65f6\u95f4\u6210\u672c\u51cf\u5c112-26\u500d\uff1b\u5728\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\uff0c\u4f7f\u7528Llama-3-8B-Instruct\u4f5c\u4e3a\u4ee3\u7406\u6a21\u578b\uff0c\u5bf9Llama-3-70B-Instruct\u7684\u653b\u51fb\u6210\u529f\u7387\u8fbe\u523085%\uff0c\u6bd4\u540c\u7c7b\u65b9\u6cd5\u9ad8\u51fa25%\u4ee5\u4e0a\u3002", "conclusion": "DTA\u901a\u8fc7\u4f7f\u7528\u76ee\u6807LLM\u81ea\u8eab\u54cd\u5e94\u4f5c\u4e3a\u52a8\u6001\u4f18\u5316\u76ee\u6807\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u8d8a\u72f1\u653b\u51fb\u4e2d\u76ee\u6807\u4e0e\u8f93\u51fa\u5206\u5e03\u5dee\u5f02\u8fc7\u5927\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6548\u7387\u548c\u6210\u529f\u7387\u3002"}}
{"id": "2510.03005", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03005", "abs": "https://arxiv.org/abs/2510.03005", "authors": ["Daniel Pinho", "Petr P\u00edcha", "Filipe Correia", "P\u0159emek Brada"], "title": "Patterns for Teaching Agile with Student Projects -- Team and Project Setup", "comment": "Accepted for publication in the EuroPLoP 2025 proceedings", "summary": "Higher education courses teaching about agile software development (ASD) have\nincreased in commonality as the ideas behind the Agile Manifesto became more\ncommonplace in the industry. However, a lot of the literature on how ASD is\napplied in the classroom does not provide much actionable advice, focusing on\nframeworks or even moving beyond the software development area into teaching in\nan agile way. We, therefore, showcase early work on a pattern language that\nfocuses on teaching ASD practices to university students, which stems from our\nown experiences as educators in higher education contexts. We present five\npatterns, specifically focused on team and project setup phase: Capping Team\nSize, Smaller Project Scope, Business Non-Critical Project, Self-assembling\nTeams, and Team Chooses Topic as a starting point for developing the overall\npattern language.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u9ad8\u7b49\u6559\u80b2\u4e2d\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u8bfe\u7a0b\u6559\u5b66\u7684\u6a21\u5f0f\u8bed\u8a00\uff0c\u91cd\u70b9\u5173\u6ce8\u56e2\u961f\u548c\u9879\u76ee\u8bbe\u7f6e\u9636\u6bb5\u7684\u4e94\u4e2a\u5177\u4f53\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u5173\u4e8e\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u6559\u5b66\u7684\u6587\u732e\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u7684\u5efa\u8bae\uff0c\u8981\u4e48\u8fc7\u4e8e\u5173\u6ce8\u6846\u67b6\uff0c\u8981\u4e48\u504f\u79bb\u5230\u654f\u6377\u6559\u5b66\u65b9\u5f0f\u672c\u8eab\uff0c\u800c\u975e\u6559\u6388\u654f\u6377\u5b9e\u8df5\u3002", "method": "\u57fa\u4e8e\u4f5c\u8005\u5728\u9ad8\u7b49\u6559\u80b2\u73af\u5883\u4e2d\u7684\u6559\u5b66\u7ecf\u9a8c\uff0c\u5f00\u53d1\u4e00\u4e2a\u6a21\u5f0f\u8bed\u8a00\uff0c\u76ee\u524d\u63d0\u51fa\u4e86\u4e94\u4e2a\u4e13\u6ce8\u4e8e\u56e2\u961f\u548c\u9879\u76ee\u8bbe\u7f6e\u9636\u6bb5\u7684\u6a21\u5f0f\u3002", "result": "\u63d0\u51fa\u4e86\u4e94\u4e2a\u5177\u4f53\u6a21\u5f0f\uff1a\u9650\u5236\u56e2\u961f\u89c4\u6a21\u3001\u7f29\u5c0f\u9879\u76ee\u8303\u56f4\u3001\u975e\u5173\u952e\u4e1a\u52a1\u9879\u76ee\u3001\u81ea\u7ec4\u7ec7\u56e2\u961f\u3001\u56e2\u961f\u81ea\u9009\u4e3b\u9898\uff0c\u4f5c\u4e3a\u6574\u4f53\u6a21\u5f0f\u8bed\u8a00\u5f00\u53d1\u7684\u8d77\u70b9\u3002", "conclusion": "\u8fd9\u4e9b\u6a21\u5f0f\u4e3a\u6559\u6388\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6307\u5bfc\uff0c\u7279\u522b\u662f\u5728\u56e2\u961f\u7ec4\u5efa\u548c\u9879\u76ee\u8bbe\u7f6e\u9636\u6bb5\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u9ad8\u7b49\u6559\u80b2\u4e2d\u7684\u654f\u6377\u6559\u5b66\u3002"}}
{"id": "2510.02837", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02837", "abs": "https://arxiv.org/abs/2510.02837", "authors": ["Wonjoong Kim", "Sangwu Park", "Yeonjun In", "Sein Kim", "Dongha Lee", "Chanyoung Park"], "title": "Beyond the Final Answer: Evaluating the Reasoning Trajectories of Tool-Augmented Agents", "comment": "Preprint. Under Review", "summary": "Although recent tool-augmented benchmarks incorporate complex user requests\nand diverse tools, the evaluation methods for most of them remain limited to\nanswer matching. However, as the number of steps required to resolve a user\nrequest increases, a proper evaluation of an agent's performance must go beyond\nthe final answer to also assess the problem-solving trajectory, including\npreviously ignored aspects such as efficiency, hallucination, and adaptivity.\nThe most straightforward method for evaluating these aspects is to compare an\nagent's trajectory with the ground-truth trajectory, but this approach is\nfundamentally limited since annotating all valid ground-truth trajectories is\nprohibitively expensive. However, a simple LLM-based evaluator struggles to\nassess trajectories in detail without ground truth. To effectively evaluate the\nagents in this manner, we introduce TRACE, a framework for the\nmulti-dimensional evaluation of tool-augmented LLM agent performance. By\nincorporating an evidence bank, which accumulates knowledge gathered from\npreceding reasoning steps, TRACE enables a multi-faceted analysis and\nevaluation of an agent's reasoning trajectory effectively. To validate our\nframework, we develop a new meta-evaluation dataset by augmenting existing\nbenchmarks with diverse and flawed trajectories, each labeled with\nmulti-faceted performance scores. Our results confirm that TRACE accurately\nevaluates these complex behaviors in a scalable and cost-effective manner, even\nwith small open-source LLMs. Furthermore, we apply our method to evaluate the\ntrajectories that agents produce while solving tool-augmented tasks, presenting\npreviously unreported observations and their corresponding insights.", "AI": {"tldr": "TRACE\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5de5\u5177\u589e\u5f3a\u578bLLM\u4ee3\u7406\u6027\u80fd\u7684\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u8bc1\u636e\u5e93\u673a\u5236\u5bf9\u4ee3\u7406\u7684\u63a8\u7406\u8f68\u8ff9\u8fdb\u884c\u591a\u65b9\u9762\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7b54\u6848\u5339\u914d\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u589e\u5f3a\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u4f9d\u8d56\u7b54\u6848\u5339\u914d\u8bc4\u4f30\uff0c\u4f46\u968f\u7740\u89e3\u51b3\u7528\u6237\u8bf7\u6c42\u6240\u9700\u6b65\u9aa4\u589e\u52a0\uff0c\u9700\u8981\u8d85\u8d8a\u6700\u7ec8\u7b54\u6848\u6765\u8bc4\u4f30\u95ee\u9898\u89e3\u51b3\u8f68\u8ff9\u7684\u6548\u7387\u3001\u5e7b\u89c9\u548c\u9002\u5e94\u6027\u7b49\u65b9\u9762\u3002", "method": "\u5f15\u5165TRACE\u6846\u67b6\uff0c\u901a\u8fc7\u8bc1\u636e\u5e93\u79ef\u7d2f\u5148\u524d\u63a8\u7406\u6b65\u9aa4\u7684\u77e5\u8bc6\uff0c\u5b9e\u73b0\u4ee3\u7406\u63a8\u7406\u8f68\u8ff9\u7684\u591a\u65b9\u9762\u5206\u6790\u548c\u8bc4\u4f30\u3002\u6784\u5efa\u5143\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5728\u73b0\u6709\u57fa\u51c6\u4e0a\u6dfb\u52a0\u591a\u6837\u4e14\u6709\u7f3a\u9677\u7684\u8f68\u8ff9\uff0c\u5e76\u6807\u6ce8\u591a\u65b9\u9762\u6027\u80fd\u5206\u6570\u3002", "result": "TRACE\u80fd\u591f\u51c6\u786e\u8bc4\u4f30\u590d\u6742\u884c\u4e3a\uff0c\u5373\u4f7f\u4f7f\u7528\u5c0f\u578b\u5f00\u6e90LLM\u4e5f\u80fd\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u8bc4\u4f30\u3002\u5e94\u7528\u8be5\u65b9\u6cd5\u8bc4\u4f30\u4ee3\u7406\u5728\u5de5\u5177\u589e\u5f3a\u4efb\u52a1\u4e2d\u7684\u8f68\u8ff9\uff0c\u63d0\u4f9b\u4e86\u5148\u524d\u672a\u62a5\u544a\u7684\u89c2\u5bdf\u7ed3\u679c\u548c\u76f8\u5e94\u89c1\u89e3\u3002", "conclusion": "TRACE\u6846\u67b6\u4e3a\u5de5\u5177\u589e\u5f3a\u578bLLM\u4ee3\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u591a\u7ef4\u5ea6\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u591f\u5168\u9762\u8bc4\u4f30\u4ee3\u7406\u7684\u63a8\u7406\u8f68\u8ff9\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7b54\u6848\u5339\u914d\u8bc4\u4f30\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.02424", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02424", "abs": "https://arxiv.org/abs/2510.02424", "authors": ["Basil Abdullah AL-Zahrani"], "title": "Adaptive Deception Framework with Behavioral Analysis for Enhanced Cybersecurity Defense", "comment": "5 pages, 5 tables, 1 figure", "summary": "This paper presents CADL (Cognitive-Adaptive Deception Layer), an adaptive\ndeception framework achieving 99.88% detection rate with 0.13% false positive\nrate on the CICIDS2017 dataset. The framework employs ensemble machine learning\n(Random Forest, XGBoost, Neural Networks) combined with behavioral profiling to\nidentify and adapt responses to network intrusions. Through a coordinated\nsignal bus architecture, security components share real-time intelligence,\nenabling collective decision-making. The system profiles attackers based on\ntemporal patterns and deploys customized deception strategies across five\nescalation levels. Evaluation on 50,000 CICIDS2017 test samples demonstrates\nthat CADL significantly outperforms traditional intrusion detection systems\n(Snort: 71.2%, Suricata: 68.5%) while maintaining production-ready false\npositive rates. The framework's behavioral analysis achieves 89% accuracy in\nclassifying attacker profiles. We provide open-source implementation and\ntransparent performance metrics, offering an accessible alternative to\ncommercial deception platforms costing $150-400 per host annually.", "AI": {"tldr": "CADL\u662f\u4e00\u4e2a\u81ea\u9002\u5e94\u6b3a\u9a97\u6846\u67b6\uff0c\u5728CICIDS2017\u6570\u636e\u96c6\u4e0a\u8fbe\u523099.88%\u68c0\u6d4b\u7387\u548c0.13%\u8bef\u62a5\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u3002", "motivation": "\u63d0\u4f9b\u4e00\u79cd\u6bd4\u5546\u4e1a\u6b3a\u9a97\u5e73\u53f0\u66f4\u7ecf\u6d4e\u5b9e\u60e0\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u540c\u65f6\u63d0\u9ad8\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002", "method": "\u91c7\u7528\u96c6\u6210\u673a\u5668\u5b66\u4e60\uff08\u968f\u673a\u68ee\u6797\u3001XGBoost\u3001\u795e\u7ecf\u7f51\u7edc\uff09\u7ed3\u5408\u884c\u4e3a\u5206\u6790\uff0c\u901a\u8fc7\u534f\u8c03\u4fe1\u53f7\u603b\u7ebf\u67b6\u6784\u5b9e\u73b0\u5b89\u5168\u7ec4\u4ef6\u95f4\u7684\u5b9e\u65f6\u60c5\u62a5\u5171\u4eab\u3002", "result": "\u572850,000\u4e2a\u6d4b\u8bd5\u6837\u672c\u4e0a\uff0cCADL\u68c0\u6d4b\u738799.88%\uff0c\u8bef\u62a5\u73870.13%\uff0c\u884c\u4e3a\u5206\u6790\u5bf9\u653b\u51fb\u8005\u753b\u50cf\u5206\u7c7b\u51c6\u786e\u7387\u8fbe89%\u3002", "conclusion": "CADL\u6846\u67b6\u5728\u4fdd\u6301\u751f\u4ea7\u7ea7\u8bef\u62a5\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5165\u4fb5\u68c0\u6d4b\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u5f00\u6e90\u5b9e\u73b0\u548c\u900f\u660e\u6027\u80fd\u6307\u6807\u3002"}}
{"id": "2510.03029", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03029", "abs": "https://arxiv.org/abs/2510.03029", "authors": ["Debalina Ghosh Paul", "Hong Zhu", "Ian Bayley"], "title": "Investigating The Smells of LLM Generated Code", "comment": null, "summary": "Context: Large Language Models (LLMs) are increasingly being used to generate\nprogram code. Much research has been reported on the functional correctness of\ngenerated code, but there is far less on code quality.\n  Objectives: In this study, we propose a scenario-based method of evaluating\nthe quality of LLM-generated code to identify the weakest scenarios in which\nthe quality of LLM generated code should be improved.\n  Methods: The method measures code smells, an important indicator of code\nquality, and compares them with a baseline formed from reference solutions of\nprofessionally written code. The test dataset is divided into various subsets\naccording to the topics of the code and complexity of the coding tasks to\nrepresent different scenarios of using LLMs for code generation. We will also\npresent an automated test system for this purpose and report experiments with\nthe Java programs generated in response to prompts given to four\nstate-of-the-art LLMs: Gemini Pro, ChatGPT, Codex, and Falcon.\n  Results: We find that LLM-generated code has a higher incidence of code\nsmells compared to reference solutions. Falcon performed the least badly, with\na smell increase of 42.28%, followed by Gemini Pro (62.07%), ChatGPT (65.05%)\nand finally Codex (84.97%). The average smell increase across all LLMs was\n63.34%, comprising 73.35% for implementation smells and 21.42% for design\nsmells. We also found that the increase in code smells is greater for more\ncomplex coding tasks and for more advanced topics, such as those involving\nobject-orientated concepts.\n  Conclusion: In terms of code smells, LLM's performances on various coding\ntask complexities and topics are highly correlated to the quality of human\nwritten code in the corresponding scenarios. However, the quality of LLM\ngenerated code is noticeably poorer than human written code.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u57fa\u4e8e\u573a\u666f\u7684\u65b9\u6cd5\u8bc4\u4f30LLM\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\uff0c\u53d1\u73b0LLM\u751f\u6210\u4ee3\u7801\u6bd4\u4e13\u4e1a\u7f16\u5199\u7684\u53c2\u8003\u4ee3\u7801\u6709\u66f4\u9ad8\u7684\u4ee3\u7801\u5f02\u5473\u53d1\u751f\u7387\uff0c\u5e73\u5747\u589e\u52a063.34%\uff0c\u5176\u4e2d\u5b9e\u73b0\u5f02\u5473\u589e\u52a073.35%\uff0c\u8bbe\u8ba1\u5f02\u5473\u589e\u52a021.42%\u3002", "motivation": "\u76ee\u524d\u5173\u4e8eLLM\u751f\u6210\u4ee3\u7801\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u529f\u80fd\u6b63\u786e\u6027\u4e0a\uff0c\u800c\u4ee3\u7801\u8d28\u91cf\u8bc4\u4f30\u7684\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\uff0c\u9700\u8981\u8bc6\u522bLLM\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u6700\u5dee\u7684\u573a\u666f\u4ee5\u4fbf\u6539\u8fdb\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u573a\u666f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d4b\u91cf\u4ee3\u7801\u5f02\u5473\u5e76\u4e0e\u4e13\u4e1a\u7f16\u5199\u7684\u53c2\u8003\u89e3\u51b3\u65b9\u6848\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\uff0c\u5c06\u6d4b\u8bd5\u6570\u636e\u96c6\u6309\u4ee3\u7801\u4e3b\u9898\u548c\u7f16\u7801\u4efb\u52a1\u590d\u6742\u5ea6\u5212\u5206\u4e3a\u4e0d\u540c\u5b50\u96c6\uff0c\u6784\u5efa\u81ea\u52a8\u5316\u6d4b\u8bd5\u7cfb\u7edf\u5bf9\u56db\u4e2a\u5148\u8fdbLLM\uff08Gemini Pro\u3001ChatGPT\u3001Codex\u3001Falcon\uff09\u751f\u6210\u7684Java\u7a0b\u5e8f\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "LLM\u751f\u6210\u4ee3\u7801\u7684\u4ee3\u7801\u5f02\u5473\u53d1\u751f\u7387\u663e\u8457\u9ad8\u4e8e\u53c2\u8003\u89e3\u51b3\u65b9\u6848\uff0cFalcon\u8868\u73b0\u6700\u597d\uff08\u5f02\u5473\u589e\u52a042.28%\uff09\uff0c\u5176\u6b21\u662fGemini Pro\uff0862.07%\uff09\u3001ChatGPT\uff0865.05%\uff09\u548cCodex\uff0884.97%\uff09\u3002\u66f4\u590d\u6742\u7684\u7f16\u7801\u4efb\u52a1\u548c\u6d89\u53ca\u9762\u5411\u5bf9\u8c61\u6982\u5ff5\u7b49\u9ad8\u7ea7\u4e3b\u9898\u7684\u4ee3\u7801\u5f02\u5473\u589e\u52a0\u66f4\u660e\u663e\u3002", "conclusion": "\u5728\u4ee3\u7801\u5f02\u5473\u65b9\u9762\uff0cLLM\u5728\u4e0d\u540c\u7f16\u7801\u4efb\u52a1\u590d\u6742\u5ea6\u548c\u4e3b\u9898\u4e0a\u7684\u8868\u73b0\u4e0e\u76f8\u5e94\u573a\u666f\u4e0b\u4eba\u5de5\u7f16\u5199\u4ee3\u7801\u7684\u8d28\u91cf\u9ad8\u5ea6\u76f8\u5173\uff0c\u4f46LLM\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u660e\u663e\u4f4e\u4e8e\u4eba\u5de5\u7f16\u5199\u4ee3\u7801\u3002"}}
{"id": "2510.02840", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02840", "abs": "https://arxiv.org/abs/2510.02840", "authors": ["Antoine Maier", "Aude Maier", "Tom David"], "title": "Take Goodhart Seriously: Principled Limit on General-Purpose AI Optimization", "comment": "9 pages, 1 figure. Under review", "summary": "A common but rarely examined assumption in machine learning is that training\nyields models that actually satisfy their specified objective function. We call\nthis the Objective Satisfaction Assumption (OSA). Although deviations from OSA\nare acknowledged, their implications are overlooked. We argue, in a\nlearning-paradigm-agnostic framework, that OSA fails in realistic conditions:\napproximation, estimation, and optimization errors guarantee systematic\ndeviations from the intended objective, regardless of the quality of its\nspecification. Beyond these technical limitations, perfectly capturing and\ntranslating the developer's intent, such as alignment with human preferences,\ninto a formal objective is practically impossible, making misspecification\ninevitable. Building on recent mathematical results, absent a mathematical\ncharacterization of these gaps, they are indistinguishable from those that\ncollapse into Goodhart's law failure modes under strong optimization pressure.\nBecause the Goodhart breaking point cannot be located ex ante, a principled\nlimit on the optimization of General-Purpose AI systems is necessary. Absent\nsuch a limit, continued optimization is liable to push systems into predictable\nand irreversible loss of control.", "AI": {"tldr": "\u8bba\u6587\u6311\u6218\u4e86\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u76ee\u6807\u6ee1\u8db3\u5047\u8bbe(OSA)\uff0c\u6307\u51fa\u7531\u4e8e\u8fd1\u4f3c\u3001\u4f30\u8ba1\u548c\u4f18\u5316\u8bef\u5dee\uff0c\u6a21\u578b\u5728\u5b9e\u9645\u4e2d\u65e0\u6cd5\u5b8c\u5168\u6ee1\u8db3\u6307\u5b9a\u76ee\u6807\u51fd\u6570\uff0c\u4e14\u5f00\u53d1\u8005\u610f\u56fe\u96be\u4ee5\u5b8c\u5168\u5f62\u5f0f\u5316\u4e3a\u76ee\u6807\u51fd\u6570\uff0c\u5bfc\u81f4\u76ee\u6807\u9519\u914d\u4e0d\u53ef\u907f\u514d\u3002\u57fa\u4e8e\u6570\u5b66\u5206\u6790\uff0c\u8fd9\u4e9b\u5dee\u8ddd\u5728\u5f3a\u4f18\u5316\u538b\u529b\u4e0b\u4f1a\u5f15\u53d1Goodhart\u5b9a\u5f8b\u5931\u6548\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u901a\u7528AI\u7cfb\u7edf\u7684\u4f18\u5316\u8bbe\u7f6e\u539f\u5219\u6027\u9650\u5236\u3002", "motivation": "\u68c0\u9a8c\u673a\u5668\u5b66\u4e60\u4e2d\u666e\u904d\u4f46\u672a\u7ecf\u68c0\u9a8c\u7684\u5047\u8bbe\u2014\u2014\u8bad\u7ec3\u4ea7\u751f\u7684\u6a21\u578b\u786e\u5b9e\u6ee1\u8db3\u5176\u6307\u5b9a\u76ee\u6807\u51fd\u6570(OSA)\uff0c\u5e76\u63a2\u8ba8OSA\u5931\u6548\u7684\u73b0\u5b9e\u5f71\u54cd\u548c\u98ce\u9669\u3002", "method": "\u91c7\u7528\u5b66\u4e60\u8303\u5f0f\u65e0\u5173\u7684\u6846\u67b6\uff0c\u5206\u6790\u8fd1\u4f3c\u8bef\u5dee\u3001\u4f30\u8ba1\u8bef\u5dee\u548c\u4f18\u5316\u8bef\u5dee\u5982\u4f55\u5bfc\u81f4\u7cfb\u7edf\u6027\u504f\u79bb\u9884\u671f\u76ee\u6807\uff0c\u7ed3\u5408\u6570\u5b66\u7ed3\u679c\u8bc1\u660e\u8fd9\u4e9b\u5dee\u8ddd\u5728\u5f3a\u4f18\u5316\u4e0b\u4f1a\u5f15\u53d1Goodhart\u5b9a\u5f8b\u5931\u6548\u6a21\u5f0f\u3002", "result": "\u8bc1\u660eOSA\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\u5fc5\u7136\u5931\u6548\uff0c\u76ee\u6807\u9519\u914d\u4e0d\u53ef\u907f\u514d\uff0c\u4e14\u5728\u6ca1\u6709\u6570\u5b66\u8868\u5f81\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u5dee\u8ddd\u4e0eGoodhart\u5b9a\u5f8b\u5931\u6548\u6a21\u5f0f\u65e0\u6cd5\u533a\u5206\uff0cGoodhart\u4e34\u754c\u70b9\u65e0\u6cd5\u4e8b\u5148\u786e\u5b9a\u3002", "conclusion": "\u9700\u8981\u5bf9\u901a\u7528AI\u7cfb\u7edf\u7684\u4f18\u5316\u8bbe\u7f6e\u539f\u5219\u6027\u9650\u5236\uff0c\u5426\u5219\u6301\u7eed\u4f18\u5316\u5c06\u5bfc\u81f4\u53ef\u9884\u6d4b\u4e14\u4e0d\u53ef\u9006\u7684\u5931\u63a7\u98ce\u9669\u3002"}}
{"id": "2510.02475", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2510.02475", "abs": "https://arxiv.org/abs/2510.02475", "authors": ["Weihang Li", "Pete Crowley", "Arya Tschand", "Yu Wang", "Miroslav Pajic", "Daniel Sorin"], "title": "Rigorous Evaluation of Microarchitectural Side-Channels with Statistical Model Checking", "comment": null, "summary": "Rigorous quantitative evaluation of microarchitectural side channels is\nchallenging for two reasons. First, the processors, attacks, and defenses often\nexhibit probabilistic behaviors. These probabilistic behaviors arise due to\nnatural noise in systems (e.g., from co-running processes), probabilistic side\nchannel attacks, and probabilistic obfuscation defenses. Second,\nmicroprocessors are extremely complex. Previous evaluation methods have relied\non abstract or simplified models, which are necessarily less detailed than real\nsystems or cycle-by-cycle simulators, and these models may miss important\nphenomena. Whereas a simple model may suffice for estimating performance,\nsecurity issues frequently manifest in the details.\n  We address this challenge by introducing Statistical Model Checking (SMC) to\nthe quantitative evaluation of microarchitectural side channels. SMC is a\nrigorous statistical technique that can process the results of probabilistic\nexperiments and provide statistical guarantees, and it has been used in\ncomputing applications that depend heavily on statistical guarantees (e.g.,\nmedical implants, vehicular computing). With SMC, we can treat processors as\nopaque boxes, and we do not have to abstract or simplify them. We demonstrate\nthe effectiveness of SMC through three case studies, in which we experimentally\nshow that SMC can evaluate existing security vulnerabilities and defenses and\nprovide qualitatively similar conclusions with greater statistical rigor, while\nmaking no simplifying assumptions or abstractions. We also show that SMC can\nenable a defender to quantify the amount of noise necessary to have a desired\nlevel of confidence that she has reduced an attacker's probability of success\nto less than a desired threshold, thus providing the defender with an\nactionable plan for obfuscation via noise injection.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u7edf\u8ba1\u6a21\u578b\u68c0\u9a8c(SMC)\u6765\u5b9a\u91cf\u8bc4\u4f30\u5fae\u67b6\u6784\u4fa7\u4fe1\u9053\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u6982\u7387\u6027\u5b9e\u9a8c\u5e76\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u65e0\u9700\u5bf9\u5904\u7406\u5668\u8fdb\u884c\u62bd\u8c61\u6216\u7b80\u5316\u3002", "motivation": "\u5fae\u67b6\u6784\u4fa7\u4fe1\u9053\u8bc4\u4f30\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a\u5904\u7406\u5668\u3001\u653b\u51fb\u548c\u9632\u5fa1\u5e38\u8868\u73b0\u51fa\u6982\u7387\u6027\u884c\u4e3a\uff1b\u5904\u7406\u5668\u6781\u5176\u590d\u6742\uff0c\u73b0\u6709\u7b80\u5316\u6a21\u578b\u53ef\u80fd\u9057\u6f0f\u91cd\u8981\u73b0\u8c61\u3002", "method": "\u91c7\u7528\u7edf\u8ba1\u6a21\u578b\u68c0\u9a8c(SMC)\u6280\u672f\uff0c\u5c06\u5904\u7406\u5668\u89c6\u4e3a\u9ed1\u76d2\uff0c\u901a\u8fc7\u6982\u7387\u5b9e\u9a8c\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30\uff0c\u65e0\u9700\u7b80\u5316\u5047\u8bbe\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cSMC\u80fd\u591f\u8bc4\u4f30\u73b0\u6709\u5b89\u5168\u6f0f\u6d1e\u548c\u9632\u5fa1\u63aa\u65bd\uff0c\u63d0\u4f9b\u66f4\u4e25\u683c\u7684\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u5e76\u5e2e\u52a9\u9632\u5fa1\u8005\u91cf\u5316\u566a\u58f0\u6ce8\u5165\u7b56\u7565\u3002", "conclusion": "SMC\u4e3a\u5fae\u67b6\u6784\u4fa7\u4fe1\u9053\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e25\u8c28\u7684\u7edf\u8ba1\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u7b80\u5316\u7cfb\u7edf\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2510.03050", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03050", "abs": "https://arxiv.org/abs/2510.03050", "authors": ["Rita Peixoto", "Filipe F. Correia", "Thatiane Rosa", "Eduardo Guerra", "Alfredo Goldman"], "title": "Refactoring Towards Microservices: Preparing the Ground for Service Extraction", "comment": "Accepted for publication in the EuroPLoP 2025 proceedings", "summary": "As organizations increasingly transition from monolithic systems to\nmicroservices, they aim to achieve higher availability, automatic scaling,\nsimplified infrastructure management, enhanced collaboration, and streamlined\ndeployments. However, this migration process remains largely manual and\nlabour-intensive. While existing literature offers various strategies for\ndecomposing monoliths, these approaches primarily focus on architecture-level\nguidance, often overlooking the code-level challenges and dependencies that\ndevelopers must address during the migration. This article introduces a\ncatalogue of seven refactorings specifically designed to support the transition\nto a microservices architecture with a focus on handling dependencies. The\ncatalogue provides developers with a systematic guide that consolidates\nrefactorings identified in the literature and addresses the critical gap in\nsystematizing the process at the code level. By offering a structured,\nstep-by-step approach, this work simplifies the migration process and lays the\ngroundwork for its potential automation, empowering developers to implement\nthese changes efficiently and effectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u4e03\u79cd\u91cd\u6784\u6a21\u5f0f\u7684\u76ee\u5f55\uff0c\u4e13\u95e8\u7528\u4e8e\u652f\u6301\u5411\u5fae\u670d\u52a1\u67b6\u6784\u7684\u8fc1\u79fb\uff0c\u91cd\u70b9\u5173\u6ce8\u4f9d\u8d56\u5904\u7406\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u4e3b\u8981\u5173\u6ce8\u67b6\u6784\u5c42\u9762\u7684\u6307\u5bfc\uff0c\u5ffd\u89c6\u4e86\u4ee3\u7801\u5c42\u9762\u7684\u6311\u6218\u548c\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u5fae\u670d\u52a1\u8fc1\u79fb\u8fc7\u7a0b\u4ecd\u7136\u9700\u8981\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\u3002", "method": "\u901a\u8fc7\u6574\u7406\u6587\u732e\u4e2d\u7684\u91cd\u6784\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u91cd\u6784\u76ee\u5f55\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u7684\u9010\u6b65\u6307\u5bfc\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u4e03\u79cd\u91cd\u6784\u6a21\u5f0f\u7684\u76ee\u5f55\uff0c\u80fd\u591f\u7b80\u5316\u8fc1\u79fb\u8fc7\u7a0b\u5e76\u4e3a\u81ea\u52a8\u5316\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u4ee3\u7801\u7ea7\u91cd\u6784\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u7b80\u5316\u5fae\u670d\u52a1\u8fc1\u79fb\u8fc7\u7a0b\u5e76\u652f\u6301\u6f5c\u5728\u7684\u81ea\u52a8\u5316\u5b9e\u73b0\u3002"}}
{"id": "2510.02850", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02850", "abs": "https://arxiv.org/abs/2510.02850", "authors": ["Xinle Wu", "Yao Lu"], "title": "Reward Model Routing in Alignment", "comment": null, "summary": "Reinforcement learning from human or AI feedback (RLHF / RLAIF) has become\nthe standard paradigm for aligning large language models (LLMs). However, most\npipelines rely on a single reward model (RM), limiting alignment quality and\nrisking overfitting. Recent work explores RM routing--dynamically selecting an\nRM from a candidate pool to exploit complementary strengths while maintaining\n$O(1)$ RM calls--but existing methods suffer from cold-start and insufficient\nexploration. We propose BayesianRouter, a hybrid routing framework that\ncombines offline RM strengths learning with online Bayesian selection. In the\noffline stage, a multi-task router is trained on preference data to estimate\nper-RM reliability. In the online stage, a Bayesian Thompson sampling router\nperforms per-query RM selection, initializing RM-specific weight vectors with\noffline embeddings as Gaussian priors and adaptively updating their posteriors\nwith online rewards to adapt to the evolving policy distribution. Extensive\nexperiments on instruction-following (AlpacaEval-2, Arena-Hard, MT-Bench) and\nreasoning (GSM8K, MMLU) benchmarks show that BayesianRouter consistently\noutperforms individual RMs, RM ensembling, and existing routing methods.", "AI": {"tldr": "\u63d0\u51faBayesianRouter\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u79bb\u7ebfRM\u5f3a\u5ea6\u5b66\u4e60\u548c\u5728\u7ebf\u8d1d\u53f6\u65af\u9009\u62e9\uff0c\u89e3\u51b3\u73b0\u6709\u5956\u52b1\u6a21\u578b\u8def\u7531\u65b9\u6cd5\u4e2d\u7684\u51b7\u542f\u52a8\u548c\u63a2\u7d22\u4e0d\u8db3\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u5355\u4e2aRM\u3001RM\u96c6\u6210\u548c\u73b0\u6709\u8def\u7531\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dRLHF/RLAIF\u6d41\u7a0b\u4f9d\u8d56\u5355\u4e00\u5956\u52b1\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5bf9\u9f50\u8d28\u91cf\u5e76\u5b58\u5728\u8fc7\u62df\u5408\u98ce\u9669\u3002\u73b0\u6709RM\u8def\u7531\u65b9\u6cd5\u5b58\u5728\u51b7\u542f\u52a8\u548c\u63a2\u7d22\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u6df7\u5408\u8def\u7531\u6846\u67b6\uff1a\u79bb\u7ebf\u9636\u6bb5\u8bad\u7ec3\u591a\u4efb\u52a1\u8def\u7531\u5668\u4f30\u8ba1\u6bcf\u4e2aRM\u7684\u53ef\u9760\u6027\uff1b\u5728\u7ebf\u9636\u6bb5\u4f7f\u7528\u8d1d\u53f6\u65afThompson\u91c7\u6837\u8def\u7531\u5668\u8fdb\u884c\u6bcf\u67e5\u8be2RM\u9009\u62e9\uff0c\u7528\u79bb\u7ebf\u5d4c\u5165\u4f5c\u4e3a\u9ad8\u65af\u5148\u9a8c\u521d\u59cb\u5316\u6743\u91cd\u5411\u91cf\uff0c\u5e76\u901a\u8fc7\u5728\u7ebf\u5956\u52b1\u81ea\u9002\u5e94\u66f4\u65b0\u540e\u9a8c\u5206\u5e03\u3002", "result": "\u5728\u6307\u4ee4\u8ddf\u968f\uff08AlpacaEval-2\u3001Arena-Hard\u3001MT-Bench\uff09\u548c\u63a8\u7406\uff08GSM8K\u3001MMLU\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBayesianRouter\u59cb\u7ec8\u4f18\u4e8e\u5355\u4e2aRM\u3001RM\u96c6\u6210\u548c\u73b0\u6709\u8def\u7531\u65b9\u6cd5\u3002", "conclusion": "BayesianRouter\u901a\u8fc7\u7ed3\u5408\u79bb\u7ebf\u548c\u5728\u7ebf\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86RM\u8def\u7531\u4e2d\u7684\u51b7\u542f\u52a8\u548c\u63a2\u7d22\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u7684\u8d28\u91cf\u3002"}}
{"id": "2510.02519", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.02519", "abs": "https://arxiv.org/abs/2510.02519", "authors": ["Atonu Ghosh", "Akhilesh Mohanasundaram", "Srishivanth R F", "Sudip Misra"], "title": "TLoRa: Implementing TLS Over LoRa for Secure HTTP Communication in IoT", "comment": "10 pages", "summary": "We present TLoRa, an end-to-end architecture for HTTPS communication over\nLoRa by integrating TCP tunneling and a complete TLS 1.3 handshake. It enables\na seamless and secure communication channel between WiFi-enabled end devices\nand the Internet over LoRa using an End Hub (EH) and a Net Relay (NR). The EH\ntethers a WiFi hotspot and a captive portal for user devices to connect and\nrequest URLs. The EH forwards the requested URLs to the NR using a secure\ntunnel over LoRa. The NR, which acts as a server-side proxy, receives and\nresolves the request from the Internet-based server. It then relays back the\nencrypted response from the server over the same secure tunnel. TLoRa operates\nin three phases -session setup, secure tunneling, and rendering. In the first\nphase, it manages the TCP socket and initiates the TLS handshake. In the\nsecond, it creates a secure tunnel and transfers encrypted TLS data over LoRa.\nFinally, it delivers the URL content to the user. TLoRa also implements a\nlightweight TLS record reassembly layer and a queuing mechanism for session\nmultiplexing. We evaluate TLoRa on real hardware using multiple accesses to a\nweb API. Results indicate that it provides a practical solution by successfully\nestablishing a TLS session over LoRa in 9.9 seconds and takes 3.58 seconds to\nfulfill API requests. To the best of our knowledge, this is the first work to\ncomprehensively design, implement, and evaluate the performance of HTTPS access\nover LoRa using full TLS.", "AI": {"tldr": "TLoRa\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u67b6\u6784\uff0c\u901a\u8fc7\u96c6\u6210TCP\u96a7\u9053\u548c\u5b8c\u6574TLS 1.3\u63e1\u624b\uff0c\u5728LoRa\u4e0a\u5b9e\u73b0HTTPS\u901a\u4fe1\uff0c\u4e3aWiFi\u8bbe\u5907\u901a\u8fc7LoRa\u7f51\u5173\u63d0\u4f9b\u5b89\u5168\u4e92\u8054\u7f51\u8bbf\u95ee\u3002", "motivation": "\u89e3\u51b3\u5728LoRa\u4f4e\u529f\u8017\u5e7f\u57df\u7f51\u4e0a\u5b9e\u73b0\u5b89\u5168HTTPS\u901a\u4fe1\u7684\u6311\u6218\uff0c\u4e3aWiFi\u8bbe\u5907\u63d0\u4f9b\u901a\u8fc7LoRa\u7f51\u5173\u8bbf\u95ee\u4e92\u8054\u7f51\u7684\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528End Hub\u548cNet Relay\u67b6\u6784\uff0c\u901a\u8fc7\u4e09\u4e2a\u9636\u6bb5\u5b9e\u73b0\uff1a\u4f1a\u8bdd\u5efa\u7acb\uff08TCP socket\u7ba1\u7406\u548cTLS\u63e1\u624b\uff09\u3001\u5b89\u5168\u96a7\u9053\uff08\u5728LoRa\u4e0a\u4f20\u8f93\u52a0\u5bc6TLS\u6570\u636e\uff09\u3001\u5185\u5bb9\u6e32\u67d3\u3002\u5305\u542b\u8f7b\u91cf\u7ea7TLS\u8bb0\u5f55\u91cd\u7ec4\u5c42\u548c\u4f1a\u8bdd\u590d\u7528\u961f\u5217\u673a\u5236\u3002", "result": "\u5728\u5b9e\u9645\u786c\u4ef6\u4e0a\u8bc4\u4f30\u663e\u793a\uff0c\u6210\u529f\u57289.9\u79d2\u5185\u5efa\u7acbLoRa\u4e0a\u7684TLS\u4f1a\u8bdd\uff0cAPI\u8bf7\u6c42\u5b8c\u6210\u65f6\u95f4\u4e3a3.58\u79d2\uff0c\u8bc1\u660e\u8be5\u65b9\u6848\u5177\u6709\u5b9e\u7528\u6027\u3002", "conclusion": "TLoRa\u662f\u9996\u4e2a\u5728LoRa\u4e0a\u4f7f\u7528\u5b8c\u6574TLS\u5168\u9762\u8bbe\u8ba1\u3001\u5b9e\u73b0\u548c\u8bc4\u4f30HTTPS\u8bbf\u95ee\u6027\u80fd\u7684\u5de5\u4f5c\uff0c\u4e3aLoRa\u7f51\u7edc\u4e0a\u7684\u5b89\u5168\u4e92\u8054\u7f51\u901a\u4fe1\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03071", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03071", "abs": "https://arxiv.org/abs/2510.03071", "authors": ["Facundo Molina", "Nazareno Aguirre", "Alessandra Gorla"], "title": "State Field Coverage: A Metric for Oracle Quality", "comment": null, "summary": "The effectiveness of testing in uncovering software defects depends not only\non the characteristics of the test inputs and how thoroughly they exercise the\nsoftware, but also on the quality of the oracles used to determine whether the\nsoftware behaves as expected. Therefore, assessing the quality of oracles is\ncrucial to improve the overall effectiveness of the testing process. Existing\nmetrics have been used for this purpose, but they either fail to provide a\ncomprehensive basis for guiding oracle improvement, or they are tailored to\nspecific types of oracles, thus limiting their generality.\n  In this paper, we introduce state field coverage, a novel metric for\nassessing oracle quality. This metric measures the proportion of an object's\nstate, as statically defined by its class fields, that an oracle may access\nduring test execution. The main intuition of our metric is that oracles with a\nhigher state field coverage are more likely to detect faults in the software\nunder analysis, as they inspect a larger portion of the object states to\ndetermine whether tests pass or not.\n  We implement a mechanism to statically compute the state field coverage\nmetric. Being statically computed, the metric is efficient and provides direct\nguidance for improving test oracles by identifying state fields that remain\nunexamined. We evaluate state field coverage through experiments involving 273\nrepresentation invariants and 249,027 test assertions. The results show that\nstate field coverage is a well-suited metric for assessing oracle quality, as\nit strongly correlates with the oracles' fault-detection ability, measured by\nmutation score.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u72b6\u6001\u5b57\u6bb5\u8986\u76d6\u7387\u7684\u65b0\u6307\u6807\uff0c\u7528\u4e8e\u8bc4\u4f30\u6d4b\u8bd5\u9884\u8a00\u7684\u8d28\u91cf\uff0c\u8be5\u6307\u6807\u8861\u91cf\u9884\u8a00\u5728\u6d4b\u8bd5\u6267\u884c\u671f\u95f4\u53ef\u80fd\u8bbf\u95ee\u7684\u5bf9\u8c61\u72b6\u6001\u5b57\u6bb5\u6bd4\u4f8b\u3002", "motivation": "\u73b0\u6709\u6307\u6807\u8981\u4e48\u65e0\u6cd5\u4e3a\u9884\u8a00\u6539\u8fdb\u63d0\u4f9b\u5168\u9762\u57fa\u7840\uff0c\u8981\u4e48\u4ec5\u9002\u7528\u4e8e\u7279\u5b9a\u7c7b\u578b\u7684\u9884\u8a00\uff0c\u9650\u5236\u4e86\u901a\u7528\u6027\u3002\u8bc4\u4f30\u9884\u8a00\u8d28\u91cf\u5bf9\u4e8e\u63d0\u9ad8\u6d4b\u8bd5\u8fc7\u7a0b\u7684\u6574\u4f53\u6709\u6548\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5b9e\u73b0\u4e86\u4e00\u79cd\u9759\u6001\u8ba1\u7b97\u72b6\u6001\u5b57\u6bb5\u8986\u76d6\u7387\u6307\u6807\u7684\u673a\u5236\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u786e\u5b9a\u9884\u8a00\u53ef\u80fd\u8bbf\u95ee\u7684\u5bf9\u8c61\u72b6\u6001\u5b57\u6bb5\u6bd4\u4f8b\u3002", "result": "\u5b9e\u9a8c\u6d89\u53ca273\u4e2a\u8868\u793a\u4e0d\u53d8\u5f0f\u548c249,027\u4e2a\u6d4b\u8bd5\u65ad\u8a00\uff0c\u7ed3\u679c\u8868\u660e\u72b6\u6001\u5b57\u6bb5\u8986\u76d6\u7387\u4e0e\u9884\u8a00\u68c0\u6d4b\u6545\u969c\u7684\u80fd\u529b\uff08\u901a\u8fc7\u53d8\u5f02\u5f97\u5206\u8861\u91cf\uff09\u5f3a\u76f8\u5173\u3002", "conclusion": "\u72b6\u6001\u5b57\u6bb5\u8986\u76d6\u7387\u662f\u8bc4\u4f30\u9884\u8a00\u8d28\u91cf\u7684\u5408\u9002\u6307\u6807\uff0c\u80fd\u591f\u6709\u6548\u6307\u5bfc\u6d4b\u8bd5\u9884\u8a00\u7684\u6539\u8fdb\u3002"}}
{"id": "2510.02880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02880", "abs": "https://arxiv.org/abs/2510.02880", "authors": ["Tianren Ma", "Mu Zhang", "Yibing Wang", "Qixiang Ye"], "title": "Consolidating Reinforcement Learning for Multimodal Discrete Diffusion Models", "comment": "Project Page: https://github.com/martian422/MaskGRPO", "summary": "Optimizing discrete diffusion model (DDM) with rewards remains a challenge:\nthe non-autoregressive paradigm makes importance sampling intractable and\nrollout complex, puzzling reinforcement learning methods such as Group Relative\nPolicy Optimization (GRPO). In this study, we introduce MaskGRPO, the first\nviable approach to enable scalable multimodal reinforcement learning in\ndiscrete diffusion with effective importance sampling and modality-specific\nadaptations. To this end, we first clarify the theoretical foundation for DDMs,\nwhich facilitates building an importance estimator that captures valuable token\nfluctuation for gradient updates. We then delicately tailored the rollout\nmethod for visual sequences, which yields diverse completions and reliable\noptimization gradients. Upon math reasoning, coding, and visual generation\nbenchmarks, MaskGRPO brings more stable and efficient updates, leading to\nstronger reasoning performance and better generation quality. This study\nestablishes MaskGRPO as a systematic policy optimization approach and the first\npractical way for discretized visual diffusion.", "AI": {"tldr": "\u63d0\u51fa\u4e86MaskGRPO\u65b9\u6cd5\uff0c\u8fd9\u662f\u9996\u4e2a\u80fd\u591f\u5b9e\u73b0\u79bb\u6563\u6269\u6563\u6a21\u578b\u4e2d\u53ef\u6269\u5c55\u591a\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u7684\u53ef\u884c\u65b9\u6cd5\uff0c\u901a\u8fc7\u6709\u6548\u7684\u91cd\u91c7\u6837\u548c\u6a21\u6001\u7279\u5b9a\u9002\u914d\u6765\u89e3\u51b3\u79bb\u6563\u6269\u6563\u6a21\u578b\u4f18\u5316\u96be\u9898\u3002", "motivation": "\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u975e\u81ea\u56de\u5f52\u7279\u6027\u4f7f\u5f97\u91cd\u8981\u6027\u91c7\u6837\u96be\u4ee5\u5904\u7406\u4e14rollout\u590d\u6742\uff0c\u8fd9\u7ed9\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5982GRPO\u5e26\u6765\u4e86\u6311\u6218\uff0c\u9700\u8981\u627e\u5230\u53ef\u884c\u7684\u4f18\u5316\u65b9\u6848\u3002", "method": "\u9996\u5148\u6f84\u6e05\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u7406\u8bba\u57fa\u7840\uff0c\u6784\u5efa\u80fd\u591f\u6355\u6349\u6709\u4ef7\u503ctoken\u6ce2\u52a8\u7684\u91cd\u8981\u6027\u4f30\u8ba1\u5668\uff1b\u7136\u540e\u4e3a\u89c6\u89c9\u5e8f\u5217\u7cbe\u5fc3\u8bbe\u8ba1rollout\u65b9\u6cd5\uff0c\u4ea7\u751f\u591a\u6837\u5316\u7684\u8865\u5168\u548c\u53ef\u9760\u7684\u4f18\u5316\u68af\u5ea6\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u7f16\u7801\u548c\u89c6\u89c9\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMaskGRPO\u5e26\u6765\u4e86\u66f4\u7a33\u5b9a\u548c\u9ad8\u6548\u7684\u66f4\u65b0\uff0c\u5bfc\u81f4\u66f4\u5f3a\u7684\u63a8\u7406\u6027\u80fd\u548c\u66f4\u597d\u7684\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "\u672c\u7814\u7a76\u786e\u7acb\u4e86MaskGRPO\u4f5c\u4e3a\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u4e14\u662f\u79bb\u6563\u5316\u89c6\u89c9\u6269\u6563\u7684\u9996\u4e2a\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2510.02554", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02554", "abs": "https://arxiv.org/abs/2510.02554", "authors": ["Jonathan Sneh", "Ruomei Yan", "Jialin Yu", "Philip Torr", "Yarin Gal", "Sunando Sengupta", "Eric Sommerlade", "Alasdair Paren", "Adel Bibi"], "title": "ToolTweak: An Attack on Tool Selection in LLM-based Agents", "comment": null, "summary": "As LLMs increasingly power agents that interact with external tools, tool use\nhas become an essential mechanism for extending their capabilities. These\nagents typically select tools from growing databases or marketplaces to solve\nuser tasks, creating implicit competition among tool providers and developers\nfor visibility and usage. In this paper, we show that this selection process\nharbors a critical vulnerability: by iteratively manipulating tool names and\ndescriptions, adversaries can systematically bias agents toward selecting\nspecific tools, gaining unfair advantage over equally capable alternatives. We\npresent ToolTweak, a lightweight automatic attack that increases selection\nrates from a baseline of around 20% to as high as 81%, with strong\ntransferability between open-source and closed-source models. Beyond individual\ntools, we show that such attacks cause distributional shifts in tool usage,\nrevealing risks to fairness, competition, and security in emerging tool\necosystems. To mitigate these risks, we evaluate two defenses: paraphrasing and\nperplexity filtering, which reduce bias and lead agents to select functionally\nsimilar tools more equally. All code will be open-sourced upon acceptance.", "AI": {"tldr": "ToolTweak\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u81ea\u52a8\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u64cd\u7eb5\u5de5\u5177\u540d\u79f0\u548c\u63cf\u8ff0\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u504f\u7f6eAI\u4ee3\u7406\u9009\u62e9\u7279\u5b9a\u5de5\u5177\uff0c\u5c06\u9009\u62e9\u7387\u4ece\u7ea620%\u63d0\u5347\u81f381%\uff0c\u63ed\u793a\u4e86\u5de5\u5177\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u516c\u5e73\u6027\u3001\u7ade\u4e89\u6027\u548c\u5b89\u5168\u6027\u98ce\u9669\u3002", "motivation": "\u968f\u7740LLM\u9a71\u52a8\u7684\u4ee3\u7406\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528\u5916\u90e8\u5de5\u5177\uff0c\u5de5\u5177\u9009\u62e9\u8fc7\u7a0b\u5b58\u5728\u5173\u952e\u6f0f\u6d1e\uff1a\u653b\u51fb\u8005\u53ef\u4ee5\u901a\u8fc7\u64cd\u7eb5\u5de5\u5177\u5143\u6570\u636e\u6765\u83b7\u5f97\u4e0d\u516c\u5e73\u4f18\u52bf\uff0c\u5f71\u54cd\u5de5\u5177\u751f\u6001\u7cfb\u7edf\u7684\u516c\u5e73\u7ade\u4e89\u3002", "method": "\u63d0\u51faToolTweak\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u5de5\u5177\u540d\u79f0\u548c\u63cf\u8ff0\u6765\u504f\u7f6e\u4ee3\u7406\u9009\u62e9\uff0c\u5e76\u5728\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u4e0a\u6d4b\u8bd5\u5176\u53ef\u8f6c\u79fb\u6027\u3002", "result": "\u653b\u51fb\u6210\u529f\u5c06\u5de5\u5177\u9009\u62e9\u7387\u4ece\u7ea620%\u63d0\u5347\u81f381%\uff0c\u5177\u6709\u5f3a\u8de8\u6a21\u578b\u53ef\u8f6c\u79fb\u6027\uff0c\u5e76\u5bfc\u81f4\u5de5\u5177\u4f7f\u7528\u5206\u5e03\u53d1\u751f\u504f\u79fb\u3002", "conclusion": "\u5de5\u5177\u9009\u62e9\u8fc7\u7a0b\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u9632\u5fa1\u63aa\u65bd\uff08\u5982\u91ca\u4e49\u548c\u56f0\u60d1\u5ea6\u8fc7\u6ee4\uff09\u6765\u51cf\u8f7b\u504f\u89c1\uff0c\u786e\u4fdd\u5de5\u5177\u751f\u6001\u7cfb\u7edf\u7684\u516c\u5e73\u7ade\u4e89\u3002"}}
{"id": "2510.03178", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03178", "abs": "https://arxiv.org/abs/2510.03178", "authors": ["Cuong Chi Le", "Minh V. T. Pham", "Cuong Duc Van", "Hoang N. Phan", "Huy N. Phan", "Tien N. Nguyen"], "title": "When Names Disappear: Revealing What LLMs Actually Understand About Code", "comment": null, "summary": "Large Language Models (LLMs) achieve strong results on code tasks, but how\nthey derive program meaning remains unclear. We argue that code communicates\nthrough two channels: structural semantics, which define formal behavior, and\nhuman-interpretable naming, which conveys intent. Removing the naming channel\nseverely degrades intent-level tasks such as summarization, where models\nregress to line-by-line descriptions. Surprisingly, we also observe consistent\nreductions on execution tasks that should depend only on structure, revealing\nthat current benchmarks reward memorization of naming patterns rather than\ngenuine semantic reasoning. To disentangle these effects, we introduce a suite\nof semantics-preserving obfuscations and show that they expose identifier\nleakage across both summarization and execution. Building on these insights, we\nrelease ClassEval-Obf, an obfuscation-enhanced benchmark that systematically\nsuppresses naming cues while preserving behavior. Our results demonstrate that\nClassEval-Obf reduces inflated performance gaps, weakens memorization\nshortcuts, and provides a more reliable basis for assessing LLMs' code\nunderstanding and generalization.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0LLMs\u5728\u4ee3\u7801\u4efb\u52a1\u4e2d\u8fc7\u5ea6\u4f9d\u8d56\u547d\u540d\u6a21\u5f0f\u800c\u975e\u8bed\u4e49\u7406\u89e3\uff0c\u901a\u8fc7\u5f15\u5165\u8bed\u4e49\u4fdd\u7559\u7684\u6df7\u6dc6\u6280\u672f\u63ed\u793a\u4e86\u547d\u540d\u6cc4\u6f0f\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86ClassEval-Obf\u57fa\u51c6\u6765\u66f4\u53ef\u9760\u5730\u8bc4\u4f30\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u63a2\u7a76LLMs\u5982\u4f55\u7406\u89e3\u7a0b\u5e8f\u542b\u4e49\uff0c\u533a\u5206\u4ee3\u7801\u7684\u7ed3\u6784\u8bed\u4e49\u548c\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u547d\u540d\u4e24\u4e2a\u901a\u4fe1\u901a\u9053\uff0c\u53d1\u73b0\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u53ef\u80fd\u5956\u52b1\u547d\u540d\u6a21\u5f0f\u7684\u8bb0\u5fc6\u800c\u975e\u771f\u6b63\u7684\u8bed\u4e49\u63a8\u7406\u3002", "method": "\u5f15\u5165\u4e00\u5957\u8bed\u4e49\u4fdd\u7559\u7684\u6df7\u6dc6\u6280\u672f\uff0c\u901a\u8fc7\u79fb\u9664\u547d\u540d\u901a\u9053\u6765\u6d4b\u8bd5\u6a21\u578b\u8868\u73b0\uff0c\u5e76\u5f00\u53d1ClassEval-Obf\u57fa\u51c6\u7cfb\u7edf\u6027\u5730\u6291\u5236\u547d\u540d\u7ebf\u7d22\u540c\u65f6\u4fdd\u6301\u884c\u4e3a\u4e0d\u53d8\u3002", "result": "\u79fb\u9664\u547d\u540d\u901a\u9053\u4e25\u91cd\u964d\u4f4e\u4e86\u610f\u56fe\u7ea7\u4efb\u52a1\uff08\u5982\u6458\u8981\uff09\u7684\u6027\u80fd\uff0c\u6a21\u578b\u9000\u5316\u4e3a\u9010\u884c\u63cf\u8ff0\uff1b\u5728\u6267\u884c\u4efb\u52a1\u4e2d\u4e5f\u89c2\u5bdf\u5230\u4e00\u81f4\u4e0b\u964d\uff0c\u8868\u660e\u5f53\u524d\u57fa\u51c6\u5956\u52b1\u547d\u540d\u6a21\u5f0f\u8bb0\u5fc6\uff1b\u6df7\u6dc6\u6280\u672f\u66b4\u9732\u4e86\u6807\u8bc6\u7b26\u6cc4\u6f0f\u95ee\u9898\u3002", "conclusion": "ClassEval-Obf\u57fa\u51c6\u51cf\u5c11\u4e86\u6027\u80fd\u81a8\u80c0\u5dee\u8ddd\uff0c\u524a\u5f31\u4e86\u8bb0\u5fc6\u6377\u5f84\uff0c\u4e3a\u8bc4\u4f30LLMs\u7684\u4ee3\u7801\u7406\u89e3\u548c\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u57fa\u7840\u3002"}}
{"id": "2510.02996", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02996", "abs": "https://arxiv.org/abs/2510.02996", "authors": ["Martina Mattioli", "Eike Petersen", "Aasa Feragen", "Marcello Pelillo", "Siavash A. Bigdeli"], "title": "Onto-Epistemological Analysis of AI Explanations", "comment": null, "summary": "Artificial intelligence (AI) is being applied in almost every field. At the\nsame time, the currently dominant deep learning methods are fundamentally\nblack-box systems that lack explanations for their inferences, significantly\nlimiting their trustworthiness and adoption. Explainable AI (XAI) methods aim\nto overcome this challenge by providing explanations of the models' decision\nprocess. Such methods are often proposed and developed by engineers and\nscientists with a predominantly technical background and incorporate their\nassumptions about the existence, validity, and explanatory utility of different\nconceivable explanatory mechanisms. However, the basic concept of an\nexplanation -- what it is, whether we can know it, whether it is absolute or\nrelative -- is far from trivial and has been the subject of deep philosophical\ndebate for millennia. As we point out here, the assumptions incorporated into\ndifferent XAI methods are not harmless and have important consequences for the\nvalidity and interpretation of AI explanations in different domains. We\ninvestigate ontological and epistemological assumptions in explainability\nmethods when they are applied to AI systems, meaning the assumptions we make\nabout the existence of explanations and our ability to gain knowledge about\nthose explanations. Our analysis shows how seemingly small technical changes to\nan XAI method may correspond to important differences in the underlying\nassumptions about explanations. We furthermore highlight the risks of ignoring\nthe underlying onto-epistemological paradigm when choosing an XAI method for a\ngiven application, and we discuss how to select and adapt appropriate XAI\nmethods for different domains of application.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u53ef\u89e3\u91caAI\u65b9\u6cd5\u4e2d\u7684\u672c\u4f53\u8bba\u548c\u8ba4\u8bc6\u8bba\u5047\u8bbe\uff0c\u6307\u51fa\u8fd9\u4e9b\u5047\u8bbe\u5bf9AI\u89e3\u91ca\u7684\u6709\u6548\u6027\u548c\u89e3\u91ca\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5e76\u8ba8\u8bba\u4e86\u5982\u4f55\u4e3a\u4e0d\u540c\u5e94\u7528\u9886\u57df\u9009\u62e9\u548c\u9002\u914d\u9002\u5f53\u7684XAI\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u662f\u9ed1\u76d2\u7cfb\u7edf\uff0c\u7f3a\u4e4f\u5bf9\u5176\u63a8\u7406\u8fc7\u7a0b\u7684\u89e3\u91ca\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u53ef\u4fe1\u5ea6\u548c\u91c7\u7528\u3002\u53ef\u89e3\u91caAI\u65b9\u6cd5\u65e8\u5728\u901a\u8fc7\u63d0\u4f9b\u6a21\u578b\u51b3\u7b56\u8fc7\u7a0b\u7684\u89e3\u91ca\u6765\u514b\u670d\u8fd9\u4e00\u6311\u6218\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u7531\u6280\u672f\u80cc\u666f\u7684\u5de5\u7a0b\u5e08\u548c\u79d1\u5b66\u5bb6\u5f00\u53d1\uff0c\u5e76\u878d\u5165\u4e86\u4ed6\u4eec\u5bf9\u4e0d\u540c\u53ef\u89e3\u91ca\u673a\u5236\u7684\u5b58\u5728\u3001\u6709\u6548\u6027\u548c\u89e3\u91ca\u6548\u7528\u7684\u5047\u8bbe\u3002", "method": "\u7814\u7a76\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5e94\u7528\u4e8eAI\u7cfb\u7edf\u65f6\u7684\u672c\u4f53\u8bba\u548c\u8ba4\u8bc6\u8bba\u5047\u8bbe\uff0c\u5373\u6211\u4eec\u5173\u4e8e\u89e3\u91ca\u5b58\u5728\u6027\u548c\u83b7\u53d6\u89e3\u91ca\u77e5\u8bc6\u80fd\u529b\u7684\u5047\u8bbe\u3002\u5206\u6790\u663e\u793a\uff0cXAI\u65b9\u6cd5\u7684\u5fae\u5c0f\u6280\u672f\u53d8\u5316\u53ef\u80fd\u5bf9\u5e94\u7740\u5173\u4e8e\u89e3\u91ca\u7684\u57fa\u672c\u5047\u8bbe\u7684\u91cd\u8981\u5dee\u5f02\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u5ffd\u7565\u5e95\u5c42\u672c\u4f53-\u8ba4\u8bc6\u8bba\u8303\u5f0f\u5728\u9009\u62e9XAI\u65b9\u6cd5\u65f6\u7684\u98ce\u9669\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u4e3a\u4e0d\u540c\u5e94\u7528\u9886\u57df\u9009\u62e9\u548c\u9002\u914d\u9002\u5f53\u7684XAI\u65b9\u6cd5\u3002", "conclusion": "XAI\u65b9\u6cd5\u4e2d\u878d\u5165\u7684\u5047\u8bbe\u5e76\u975e\u65e0\u5bb3\uff0c\u5bf9AI\u89e3\u91ca\u5728\u4e0d\u540c\u9886\u57df\u7684\u6709\u6548\u6027\u548c\u89e3\u91ca\u5177\u6709\u91cd\u8981\u540e\u679c\u3002\u5728\u9009\u62e9XAI\u65b9\u6cd5\u65f6\u9700\u8981\u8003\u8651\u5176\u5e95\u5c42\u672c\u4f53-\u8ba4\u8bc6\u8bba\u8303\u5f0f\uff0c\u4ee5\u786e\u4fdd\u89e3\u91ca\u7684\u6709\u6548\u6027\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2510.02563", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.02563", "abs": "https://arxiv.org/abs/2510.02563", "authors": ["Chenpei Huang", "Lingfeng Yao", "Hui Zhong", "Kyu In Lee", "Lan Zhang", "Xiaoyong Yuan", "Tomoaki Ohtsuki", "Miao Pan"], "title": "Who's Wearing? Ear Canal Biometric Key Extraction for User Authentication on Wireless Earbuds", "comment": null, "summary": "Ear canal scanning/sensing (ECS) has emerged as a novel biometric\nauthentication method for mobile devices paired with wireless earbuds. Existing\nstudies have demonstrated the uniqueness of ear canals by training and testing\nmachine learning classifiers on ECS data. However, implementing practical\nECS-based authentication requires preventing raw biometric data leakage and\ndesigning computationally efficient protocols suitable for resource-constrained\nearbuds. To address these challenges, we propose an ear canal key extraction\nprotocol, \\textbf{EarID}. Without relying on classifiers, EarID extracts unique\nbinary keys directly on the earbuds during authentication. These keys further\nallow the use of privacy-preserving fuzzy commitment scheme that verifies the\nwearer's key on mobile devices. Our evaluation results demonstrate that EarID\nachieves a 98.7\\% authentication accuracy, comparable to machine learning\nclassifiers. The mobile enrollment time (160~ms) and earbuds processing time\n(226~ms) are negligible in terms of wearer's experience. Moreover, our approach\nis robust and attack-resistant, maintaining a false acceptance rate below 1\\%\nacross all adversarial scenarios. We believe the proposed EarID offers a\npractical and secure solution for next-generation wireless earbuds.", "AI": {"tldr": "EarID\u662f\u4e00\u79cd\u57fa\u4e8e\u8033\u9053\u626b\u63cf\u7684\u8ba4\u8bc1\u534f\u8bae\uff0c\u76f4\u63a5\u5728\u8033\u673a\u4e0a\u63d0\u53d6\u4e8c\u8fdb\u5236\u5bc6\u94a5\uff0c\u907f\u514d\u539f\u59cb\u751f\u7269\u7279\u5f81\u6570\u636e\u6cc4\u9732\uff0c\u5b9e\u73b0\u9ad8\u6548\u5b89\u5168\u7684\u8eab\u4efd\u9a8c\u8bc1\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u8033\u9053\u626b\u63cf\u8ba4\u8bc1\u65b9\u6cd5\u4e2d\u539f\u59cb\u751f\u7269\u7279\u5f81\u6570\u636e\u6cc4\u9732\u98ce\u9669\u548c\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u8033\u673a\u8bbe\u5907\u63d0\u4f9b\u5b9e\u7528\u7684\u8ba4\u8bc1\u65b9\u6848\u3002", "method": "\u63d0\u51faEarID\u534f\u8bae\uff0c\u5728\u8033\u673a\u4e0a\u76f4\u63a5\u63d0\u53d6\u72ec\u7279\u7684\u4e8c\u8fdb\u5236\u5bc6\u94a5\uff0c\u4f7f\u7528\u9690\u79c1\u4fdd\u62a4\u7684\u6a21\u7cca\u627f\u8bfa\u65b9\u6848\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u9a8c\u8bc1\u4f69\u6234\u8005\u5bc6\u94a5\uff0c\u65e0\u9700\u4f9d\u8d56\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u3002", "result": "\u8fbe\u523098.7%\u7684\u8ba4\u8bc1\u51c6\u786e\u7387\uff0c\u4e0e\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u76f8\u5f53\uff1b\u79fb\u52a8\u8bbe\u5907\u6ce8\u518c\u65f6\u95f4160ms\uff0c\u8033\u673a\u5904\u7406\u65f6\u95f4226ms\uff1b\u5728\u6240\u6709\u5bf9\u6297\u573a\u666f\u4e0b\u4fdd\u6301\u4f4e\u4e8e1%\u7684\u8bef\u63a5\u53d7\u7387\u3002", "conclusion": "EarID\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u8033\u673a\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u5b89\u5168\u7684\u8ba4\u8bc1\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u5ef6\u8fdf\u548c\u5f3a\u6297\u653b\u51fb\u80fd\u529b\u3002"}}
{"id": "2510.03217", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03217", "abs": "https://arxiv.org/abs/2510.03217", "authors": ["Jos\u00e9 Cambronero", "Michele Tufano", "Sherry Shi", "Renyao Wei", "Grant Uy", "Runxiang Cheng", "Chin-Jung Liu", "Shiying Pan", "Satish Chandra", "Pat Rondon"], "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic Program Repair", "comment": null, "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cdLLM\u7b56\u7565\uff08bug abstention\u548cpatch validation\uff09\u6765\u51cf\u5c11\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\u4e2d\u7684\u566a\u58f0\uff0c\u63d0\u9ad8\u8865\u4e01\u8d28\u91cf", "motivation": "\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u4ed3\u5e93\u7ea7bug\u65f6\u4f1a\u4ea7\u751f\u5927\u91cf\u65e0\u6548\u8865\u4e01\uff0c\u7ed9\u5f00\u53d1\u8005\u5e26\u6765\u566a\u58f0\u5e76\u6d6a\u8d39\u5b9d\u8d35\u65f6\u95f4", "method": "\u4f7f\u7528bug abstention\u7b56\u7565\u6392\u9664\u7cfb\u7edf\u96be\u4ee5\u4fee\u590d\u7684bug\uff0c\u4f7f\u7528patch validation\u7b56\u7565\u62d2\u7edd\u4e0d\u592a\u53ef\u80fd\u662f\u597d\u4fee\u590d\u7684\u8865\u4e01", "result": "\u5728Google\u4ee3\u7801\u5e93\u7684174\u4e2a\u4eba\u5de5\u62a5\u544abug\u4e0a\uff0c\u7ec4\u5408\u4f7f\u7528\u4e24\u79cd\u7b56\u7565\u53ef\u5c06\u6210\u529f\u7387\u63d0\u9ad839\u4e2a\u767e\u5206\u70b9", "conclusion": "\u8fd9\u79cd\u53cc\u7b56\u7565\u65b9\u6cd5\u4e3a\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\u7684\u53ef\u9760\u5de5\u4e1a\u7ea7\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84"}}
{"id": "2510.03078", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03078", "abs": "https://arxiv.org/abs/2510.03078", "authors": ["Anna Trapp", "Mersedeh Sadeghi", "Andreas Vogelsang"], "title": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments", "comment": "Accepted at Ex-ASE 2025, co-located with the 40th IEEE/ACM\n  International Conference on Automated Software Engineering (ASE 2025)", "summary": "Explainability is increasingly seen as an essential feature of rule-based\nsmart environments. While counterfactual explanations, which describe what\ncould have been done differently to achieve a desired outcome, are a powerful\ntool in eXplainable AI (XAI), no established methods exist for generating them\nin these rule-based domains. In this paper, we present the first formalization\nand implementation of counterfactual explanations tailored to this domain. It\nis implemented as a plugin that extends an existing explanation engine for\nsmart environments. We conducted a user study (N=17) to evaluate our generated\ncounterfactuals against traditional causal explanations. The results show that\nuser preference is highly contextual: causal explanations are favored for their\nlinguistic simplicity and in time-pressured situations, while counterfactuals\nare preferred for their actionable content, particularly when a user wants to\nresolve a problem. Our work contributes a practical framework for a new type of\nexplanation in smart environments and provides empirical evidence to guide the\nchoice of when each explanation type is most effective.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u73af\u5883\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5f62\u5f0f\u5316\u548c\u5b9e\u73b0\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u53d1\u73b0\u56e0\u679c\u89e3\u91ca\u5728\u65f6\u95f4\u538b\u529b\u4e0b\u66f4\u53d7\u6b22\u8fce\uff0c\u800c\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5728\u89e3\u51b3\u95ee\u9898\u65f6\u66f4\u53d7\u9752\u7750\u3002", "motivation": "\u867d\u7136\u53cd\u4e8b\u5b9e\u89e3\u91ca\u662f\u53ef\u89e3\u91caAI\u4e2d\u7684\u5f3a\u5927\u5de5\u5177\uff0c\u4f46\u5728\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u73af\u5883\u9886\u57df\u7f3a\u4e4f\u6210\u719f\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5f62\u5f0f\u5316\u548c\u5b9e\u73b0\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u63d2\u4ef6\u6765\u6269\u5c55\u73b0\u6709\u7684\u667a\u80fd\u73af\u5883\u89e3\u91ca\u5f15\u64ce\uff0c\u5e76\u8fdb\u884c\u4e86\u7528\u6237\u7814\u7a76(N=17)\u6765\u6bd4\u8f83\u53cd\u4e8b\u5b9e\u89e3\u91ca\u4e0e\u4f20\u7edf\u56e0\u679c\u89e3\u91ca\u3002", "result": "\u7528\u6237\u504f\u597d\u9ad8\u5ea6\u4f9d\u8d56\u60c5\u5883\uff1a\u56e0\u679c\u89e3\u91ca\u56e0\u5176\u8bed\u8a00\u7b80\u6d01\u6027\u548c\u5728\u65f6\u95f4\u538b\u529b\u4e0b\u7684\u4f18\u52bf\u800c\u53d7\u9752\u7750\uff0c\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5219\u56e0\u5176\u53ef\u64cd\u4f5c\u5185\u5bb9\u800c\u5728\u89e3\u51b3\u95ee\u9898\u65f6\u66f4\u53d7\u6b22\u8fce\u3002", "conclusion": "\u4e3a\u667a\u80fd\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u91ca\u7c7b\u578b\u5b9e\u7528\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u8bc1\u636e\u6765\u6307\u5bfc\u4f55\u65f6\u9009\u62e9\u6bcf\u79cd\u89e3\u91ca\u7c7b\u578b\u6700\u6709\u6548\u3002"}}
{"id": "2510.02643", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02643", "abs": "https://arxiv.org/abs/2510.02643", "authors": ["Jack Garrard", "John F. Hardy II", "Carlo daCunha", "Mayank Bakshi"], "title": "Using Preformed Resistive Random Access Memory to Create a Strong Physically Unclonable Function", "comment": null, "summary": "Physically Unclonable Functions (PUFs) are a promising solution for identity\nverification and asymmetric encryption. In this paper, a new Resistive Random\nAccess Memory (ReRAM) PUF-based protocol is presented to create a physical\nReRAM PUF with a large challenge space. This protocol uses differential reads\nfrom unformed ReRAM as the method for response generation. Lastly, this paper\nalso provides an experimental hardware demonstration of this protocol on a\nPhysical ReRAM device, along with providing notable results as a PUF, with\nexcellent performance characteristics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u963b\u53d8\u5b58\u50a8\u5668(ReRAM)\u7684\u65b0\u578b\u7269\u7406\u4e0d\u53ef\u514b\u9686\u51fd\u6570(PUF)\u534f\u8bae\uff0c\u901a\u8fc7\u672a\u5f62\u6210ReRAM\u7684\u5dee\u5206\u8bfb\u53d6\u751f\u6210\u54cd\u5e94\uff0c\u5e76\u5728\u7269\u7406ReRAM\u8bbe\u5907\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u6f14\u793a\u3002", "motivation": "\u7269\u7406\u4e0d\u53ef\u514b\u9686\u51fd\u6570(PUF)\u5728\u8eab\u4efd\u9a8c\u8bc1\u548c\u975e\u5bf9\u79f0\u52a0\u5bc6\u65b9\u9762\u5177\u6709\u5e94\u7528\u524d\u666f\uff0c\u9700\u8981\u521b\u5efa\u5177\u6709\u5927\u6311\u6218\u7a7a\u95f4\u7684\u7269\u7406ReRAM PUF\u3002", "method": "\u4f7f\u7528\u672a\u5f62\u6210ReRAM\u7684\u5dee\u5206\u8bfb\u53d6\u4f5c\u4e3a\u54cd\u5e94\u751f\u6210\u65b9\u6cd5\uff0c\u6784\u5efa\u57fa\u4e8eReRAM\u7684PUF\u534f\u8bae\u3002", "result": "\u5728\u7269\u7406ReRAM\u8bbe\u5907\u4e0a\u6210\u529f\u6f14\u793a\u4e86\u8be5\u534f\u8bae\uff0c\u4f5c\u4e3aPUF\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6027\u80fd\u7279\u5f81\u3002", "conclusion": "\u8be5ReRAM PUF\u534f\u8bae\u80fd\u591f\u521b\u5efa\u5177\u6709\u5927\u6311\u6218\u7a7a\u95f4\u7684\u7269\u7406PUF\uff0c\u5e76\u901a\u8fc7\u786c\u4ef6\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u3002"}}
{"id": "2510.03127", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03127", "abs": "https://arxiv.org/abs/2510.03127", "authors": ["Binze Li"], "title": "A Study of Rule Omission in Raven's Progressive Matrices", "comment": null, "summary": "Analogical reasoning lies at the core of human cognition and remains a\nfundamental challenge for artificial intelligence. Raven's Progressive Matrices\n(RPM) serve as a widely used benchmark to assess abstract reasoning by\nrequiring the inference of underlying structural rules. While many vision-based\nand language-based models have achieved success on RPM tasks, it remains\nunclear whether their performance reflects genuine reasoning ability or\nreliance on statistical shortcuts. This study investigates the generalization\ncapacity of modern AI systems under conditions of incomplete training by\ndeliberately omitting several structural rules during training. Both\nsequence-to-sequence transformer models and vision-based architectures such as\nCoPINet and the Dual-Contrast Network are evaluated on the Impartial-RAVEN\n(I-RAVEN) dataset. Experiments reveal that although transformers demonstrate\nstrong performance on familiar rules, their accuracy declines sharply when\nfaced with novel or omitted rules. Moreover, the gap between token-level\naccuracy and complete answer accuracy highlights fundamental limitations in\ncurrent approaches. These findings provide new insights into the reasoning\nmechanisms underlying deep learning models and underscore the need for\narchitectures that move beyond pattern recognition toward robust abstract\nreasoning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6545\u610f\u5728\u8bad\u7ec3\u4e2d\u7701\u7565\u90e8\u5206\u7ed3\u6784\u89c4\u5219\uff0c\u8bc4\u4f30\u4e86\u73b0\u4ee3AI\u7cfb\u7edf\u5728Raven\u6e10\u8fdb\u77e9\u9635\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0transformer\u6a21\u578b\u5728\u9762\u5bf9\u65b0\u89c4\u5219\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u63a2\u7a76AI\u7cfb\u7edf\u5728Raven\u6e10\u8fdb\u77e9\u9635\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u662f\u5426\u771f\u6b63\u53cd\u6620\u4e86\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4ec5\u4f9d\u8d56\u7edf\u8ba1\u6377\u5f84\uff0c\u7279\u522b\u662f\u5728\u8bad\u7ec3\u6570\u636e\u4e0d\u5b8c\u6574\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u5728Impartial-RAVEN\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u5e8f\u5217\u5230\u5e8f\u5217transformer\u6a21\u578b\u548c\u57fa\u4e8e\u89c6\u89c9\u7684\u67b6\u6784\uff08\u5982CoPINet\u548cDual-Contrast Network\uff09\uff0c\u6545\u610f\u5728\u8bad\u7ec3\u4e2d\u7701\u7565\u591a\u4e2a\u7ed3\u6784\u89c4\u5219\u3002", "result": "transformer\u6a21\u578b\u5728\u719f\u6089\u89c4\u5219\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9762\u5bf9\u65b0\u9896\u6216\u7701\u7565\u89c4\u5219\u65f6\u51c6\u786e\u7387\u6025\u5267\u4e0b\u964d\uff1btoken\u7ea7\u51c6\u786e\u7387\u4e0e\u5b8c\u6574\u7b54\u6848\u51c6\u786e\u7387\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u62bd\u8c61\u63a8\u7406\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff0c\u9700\u8981\u8d85\u8d8a\u6a21\u5f0f\u8bc6\u522b\u3001\u53d1\u5c55\u66f4\u7a33\u5065\u7684\u62bd\u8c61\u63a8\u7406\u67b6\u6784\u3002"}}
{"id": "2510.02694", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02694", "abs": "https://arxiv.org/abs/2510.02694", "authors": ["Bowei Ning", "Xuejun Zong", "Kan He"], "title": "MALF: A Multi-Agent LLM Framework for Intelligent Fuzzing of Industrial Control Protocols", "comment": null, "summary": "Industrial control systems (ICS) are vital to modern infrastructure but\nincreasingly vulnerable to cybersecurity threats, particularly through\nweaknesses in their communication protocols. This paper presents MALF\n(Multi-Agent LLM Fuzzing Framework), an advanced fuzzing solution that\nintegrates large language models (LLMs) with multi-agent coordination to\nidentify vulnerabilities in industrial control protocols (ICPs). By leveraging\nRetrieval-Augmented Generation (RAG) for domain-specific knowledge and QLoRA\nfine-tuning for protocol-aware input generation, MALF enhances fuzz testing\nprecision and adaptability. The multi-agent framework optimizes seed\ngeneration, mutation strategies, and feedback-driven refinement, leading to\nimproved vulnerability discovery. Experiments on protocols like Modbus/TCP,\nS7Comm, and Ethernet/IP demonstrate that MALF surpasses traditional methods,\nachieving a test case pass rate (TCPR) of 88-92% and generating more exception\ntriggers (ETN). MALF also maintains over 90% seed coverage and Shannon entropy\nvalues between 4.2 and 4.6 bits, ensuring diverse, protocol-compliant\nmutations. Deployed in a real-world Industrial Attack-Defense Range for power\nplants, MALF identified critical vulnerabilities, including three zero-day\nflaws, one confirmed and registered by CNVD. These results validate MALF's\neffectiveness in real-world fuzzing applications. This research highlights the\ntransformative potential of multi-agent LLMs in ICS cybersecurity, offering a\nscalable, automated framework that sets a new standard for vulnerability\ndiscovery and strengthens critical infrastructure security against emerging\nthreats.", "AI": {"tldr": "MALF\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53LLM\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u534f\u8c03\u6765\u53d1\u73b0\u5de5\u4e1a\u63a7\u5236\u534f\u8bae\u4e2d\u7684\u6f0f\u6d1e\uff0c\u5728\u771f\u5b9e\u5de5\u4e1a\u73af\u5883\u4e2d\u6210\u529f\u8bc6\u522b\u4e86\u5173\u952e\u6f0f\u6d1e\u3002", "motivation": "\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u5bf9\u73b0\u4ee3\u57fa\u7840\u8bbe\u65bd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u901a\u4fe1\u534f\u8bae\u4e2d\u7684\u5f31\u70b9\u4f7f\u5176\u9762\u4e34\u65e5\u76ca\u4e25\u91cd\u7684\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u6f0f\u6d1e\u53d1\u73b0\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u83b7\u53d6\u9886\u57df\u77e5\u8bc6\uff0c\u4f7f\u7528QLoRA\u5fae\u8c03\u5b9e\u73b0\u534f\u8bae\u611f\u77e5\u8f93\u5165\u751f\u6210\uff0c\u591a\u667a\u80fd\u4f53\u6846\u67b6\u4f18\u5316\u79cd\u5b50\u751f\u6210\u3001\u53d8\u5f02\u7b56\u7565\u548c\u53cd\u9988\u9a71\u52a8\u4f18\u5316\u3002", "result": "\u5728Modbus/TCP\u3001S7Comm\u548cEthernet/IP\u534f\u8bae\u6d4b\u8bd5\u4e2d\uff0c\u6d4b\u8bd5\u7528\u4f8b\u901a\u8fc7\u7387\u8fbe88-92%\uff0c\u751f\u6210\u66f4\u591a\u5f02\u5e38\u89e6\u53d1\uff0c\u79cd\u5b50\u8986\u76d6\u7387\u8d85\u8fc790%\uff0c\u71b5\u503c4.2-4.6\u4f4d\uff0c\u5728\u771f\u5b9e\u7535\u5382\u73af\u5883\u4e2d\u53d1\u73b0\u4e09\u4e2a\u96f6\u65e5\u6f0f\u6d1e\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53LLM\u5728ICS\u7f51\u7edc\u5b89\u5168\u4e2d\u5177\u6709\u53d8\u9769\u6f5c\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u4e3a\u6f0f\u6d1e\u53d1\u73b0\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\uff0c\u589e\u5f3a\u4e86\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2510.03153", "categories": ["cs.AI", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03153", "abs": "https://arxiv.org/abs/2510.03153", "authors": ["Hima Jacob Leven Suprabha", "Laxmi Nag Laxminarayan Nagesh", "Ajith Nair", "Alvin Reuben Amal Selvaster", "Ayan Khan", "Raghuram Damarla", "Sanju Hannah Samuel", "Sreenithi Saravana Perumal", "Titouan Puech", "Venkataramireddy Marella", "Vishal Sonar", "Alessandro Suglia", "Oliver Lemon"], "title": "Improving Cooperation in Collaborative Embodied AI", "comment": "In proceedings of UKCI 2025", "summary": "The integration of Large Language Models (LLMs) into multiagent systems has\nopened new possibilities for collaborative reasoning and cooperation with AI\nagents. This paper explores different prompting methods and evaluates their\neffectiveness in enhancing agent collaborative behaviour and decision-making.\nWe enhance CoELA, a framework designed for building Collaborative Embodied\nAgents that leverage LLMs for multi-agent communication, reasoning, and task\ncoordination in shared virtual spaces. Through systematic experimentation, we\nexamine different LLMs and prompt engineering strategies to identify optimised\ncombinations that maximise collaboration performance. Furthermore, we extend\nour research by integrating speech capabilities, enabling seamless\ncollaborative voice-based interactions. Our findings highlight the\neffectiveness of prompt optimisation in enhancing collaborative agent\nperformance; for example, our best combination improved the efficiency of the\nsystem running with Gemma3 by 22% compared to the original CoELA system. In\naddition, the speech integration provides a more engaging user interface for\niterative system development and demonstrations.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e0d\u540c\u63d0\u793a\u65b9\u6cd5\u5728\u589e\u5f3a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u884c\u4e3a\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u4f18\u5316CoELA\u6846\u67b6\u4e2d\u7684LLM\u63d0\u793a\u7b56\u7565\uff0c\u4f7fGemma3\u7cfb\u7edf\u6548\u7387\u63d0\u534722%\uff0c\u5e76\u96c6\u6210\u4e86\u8bed\u97f3\u4ea4\u4e92\u529f\u80fd\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u96c6\u6210\uff0c\u9700\u8981\u63a2\u7d22\u6709\u6548\u7684\u63d0\u793a\u65b9\u6cd5\u6765\u589e\u5f3aAI\u4ee3\u7406\u7684\u534f\u4f5c\u63a8\u7406\u548c\u51b3\u7b56\u80fd\u529b\u3002", "method": "\u589e\u5f3aCoELA\u6846\u67b6\uff0c\u7cfb\u7edf\u5b9e\u9a8c\u4e0d\u540cLLM\u548c\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\uff0c\u8bc6\u522b\u6700\u4f18\u7ec4\u5408\u4ee5\u6700\u5927\u5316\u534f\u4f5c\u6027\u80fd\uff0c\u5e76\u96c6\u6210\u8bed\u97f3\u529f\u80fd\u5b9e\u73b0\u8bed\u97f3\u4ea4\u4e92\u3002", "result": "\u6700\u4f73\u7ec4\u5408\u4f7fGemma3\u7cfb\u7edf\u6548\u7387\u76f8\u6bd4\u539f\u59cbCoELA\u7cfb\u7edf\u63d0\u534722%\uff0c\u8bed\u97f3\u96c6\u6210\u63d0\u4f9b\u4e86\u66f4\u5438\u5f15\u4eba\u7684\u7528\u6237\u754c\u9762\u3002", "conclusion": "\u63d0\u793a\u4f18\u5316\u80fd\u663e\u8457\u63d0\u5347\u534f\u4f5c\u667a\u80fd\u4f53\u6027\u80fd\uff0c\u8bed\u97f3\u96c6\u6210\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u4ea4\u4e92\u6027\u548c\u6f14\u793a\u6548\u679c\u3002"}}
{"id": "2510.02707", "categories": ["cs.CR", "cs.CV", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.02707", "abs": "https://arxiv.org/abs/2510.02707", "authors": ["Chinthana Wimalasuriya", "Spyros Tragoudas"], "title": "A Statistical Method for Attack-Agnostic Adversarial Attack Detection with Compressive Sensing Comparison", "comment": null, "summary": "Adversarial attacks present a significant threat to modern machine learning\nsystems. Yet, existing detection methods often lack the ability to detect\nunseen attacks or detect different attack types with a high level of accuracy.\nIn this work, we propose a statistical approach that establishes a detection\nbaseline before a neural network's deployment, enabling effective real-time\nadversarial detection. We generate a metric of adversarial presence by\ncomparing the behavior of a compressed/uncompressed neural network pair. Our\nmethod has been tested against state-of-the-art techniques, and it achieves\nnear-perfect detection across a wide range of attack types. Moreover, it\nsignificantly reduces false positives, making it both reliable and practical\nfor real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u538b\u7f29/\u672a\u538b\u7f29\u795e\u7ecf\u7f51\u7edc\u5bf9\u884c\u4e3a\u7684\u7edf\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u5bf9\u6297\u653b\u51fb\u68c0\u6d4b\uff0c\u5728\u5404\u79cd\u653b\u51fb\u7c7b\u578b\u4e0a\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5\u5f80\u5f80\u65e0\u6cd5\u6709\u6548\u68c0\u6d4b\u672a\u89c1\u653b\u51fb\u7c7b\u578b\uff0c\u4e14\u5bf9\u4e0d\u540c\u653b\u51fb\u7c7b\u578b\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u6709\u9650\uff0c\u9700\u8981\u66f4\u53ef\u9760\u548c\u5b9e\u7528\u7684\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u538b\u7f29\u548c\u672a\u538b\u7f29\u795e\u7ecf\u7f51\u7edc\u5bf9\u7684\u884c\u4e3a\uff0c\u751f\u6210\u5bf9\u6297\u653b\u51fb\u5b58\u5728\u6027\u7684\u5ea6\u91cf\u6307\u6807\uff0c\u5efa\u7acb\u90e8\u7f72\u524d\u7684\u68c0\u6d4b\u57fa\u7ebf\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u6280\u672f\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u653b\u51fb\u7c7b\u578b\u4e0a\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u68c0\u6d4b\u7387\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u8bef\u62a5\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e2\u53ef\u9760\u53c8\u5b9e\u7528\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u5bf9\u6297\u653b\u51fb\u68c0\u6d4b\u3002"}}
{"id": "2510.03194", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03194", "abs": "https://arxiv.org/abs/2510.03194", "authors": ["Zichen Chen", "Jiefeng Chen", "Sercan \u00d6. Arik", "Misha Sra", "Tomas Pfister", "Jinsung Yoon"], "title": "CoDA: Agentic Systems for Collaborative Data Visualization", "comment": "31 pages, 6 figures, 5 tables", "summary": "Deep research has revolutionized data analysis, yet data scientists still\ndevote substantial time to manually crafting visualizations, highlighting the\nneed for robust automation from natural language queries. However, current\nsystems struggle with complex datasets containing multiple files and iterative\nrefinement. Existing approaches, including simple single- or multi-agent\nsystems, often oversimplify the task, focusing on initial query parsing while\nfailing to robustly manage data complexity, code errors, or final visualization\nquality. In this paper, we reframe this challenge as a collaborative\nmulti-agent problem. We introduce CoDA, a multi-agent system that employs\nspecialized LLM agents for metadata analysis, task planning, code generation,\nand self-reflection. We formalize this pipeline, demonstrating how\nmetadata-focused analysis bypasses token limits and quality-driven refinement\nensures robustness. Extensive evaluations show CoDA achieves substantial gains\nin the overall score, outperforming competitive baselines by up to 41.5%. This\nwork demonstrates that the future of visualization automation lies not in\nisolated code generation but in integrated, collaborative agentic workflows.", "AI": {"tldr": "CoDA\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e13\u95e8\u7684LLM\u667a\u80fd\u4f53\u8fdb\u884c\u5143\u6570\u636e\u5206\u6790\u3001\u4efb\u52a1\u89c4\u5212\u3001\u4ee3\u7801\u751f\u6210\u548c\u81ea\u6211\u53cd\u601d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ece\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u81ea\u52a8\u751f\u6210\u53ef\u89c6\u5316\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7cfb\u7edf\u5728\u5904\u7406\u5305\u542b\u591a\u4e2a\u6587\u4ef6\u7684\u590d\u6742\u6570\u636e\u96c6\u548c\u8fed\u4ee3\u4f18\u5316\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u65b9\u6cd5\u8fc7\u4e8e\u7b80\u5316\u4efb\u52a1\uff0c\u65e0\u6cd5\u6709\u6548\u7ba1\u7406\u6570\u636e\u590d\u6742\u6027\u3001\u4ee3\u7801\u9519\u8bef\u6216\u6700\u7ec8\u53ef\u89c6\u5316\u8d28\u91cf\u3002", "method": "\u5c06\u6311\u6218\u91cd\u65b0\u5b9a\u4e49\u4e3a\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u95ee\u9898\uff0c\u5f15\u5165CoDA\u7cfb\u7edf\uff0c\u91c7\u7528\u4e13\u95e8\u5316\u7684LLM\u667a\u80fd\u4f53\u8fdb\u884c\u5143\u6570\u636e\u5206\u6790\u3001\u4efb\u52a1\u89c4\u5212\u3001\u4ee3\u7801\u751f\u6210\u548c\u81ea\u6211\u53cd\u601d\uff0c\u901a\u8fc7\u5143\u6570\u636e\u5206\u6790\u7ed5\u8fc7token\u9650\u5236\uff0c\u8d28\u91cf\u9a71\u52a8\u7684\u4f18\u5316\u786e\u4fdd\u9c81\u68d2\u6027\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793aCoDA\u5728\u603b\u4f53\u5f97\u5206\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u6bd4\u7ade\u4e89\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa41.5%\u3002", "conclusion": "\u53ef\u89c6\u5316\u81ea\u52a8\u5316\u7684\u672a\u6765\u4e0d\u5728\u4e8e\u5b64\u7acb\u7684\u4ee3\u7801\u751f\u6210\uff0c\u800c\u5728\u4e8e\u96c6\u6210\u3001\u534f\u4f5c\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2510.02833", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02833", "abs": "https://arxiv.org/abs/2510.02833", "authors": ["Zhixin Xie", "Xurui Song", "Jun Luo"], "title": "Attack via Overfitting: 10-shot Benign Fine-tuning to Jailbreak LLMs", "comment": null, "summary": "Despite substantial efforts in safety alignment, recent research indicates\nthat Large Language Models (LLMs) remain highly susceptible to jailbreak\nattacks. Among these attacks, finetuning-based ones that compromise LLMs'\nsafety alignment via fine-tuning stand out due to its stable jailbreak\nperformance. In particular, a recent study indicates that fine-tuning with as\nfew as 10 harmful question-answer (QA) pairs can lead to successful\njailbreaking across various harmful questions. However, such malicious\nfine-tuning attacks are readily detectable and hence thwarted by moderation\nmodels. In this paper, we demonstrate that LLMs can be jailbroken by\nfine-tuning with only 10 benign QA pairs; our attack exploits the increased\nsensitivity of LLMs to fine-tuning data after being overfitted. Specifically,\nour fine-tuning process starts with overfitting an LLM via fine-tuning with\nbenign QA pairs involving identical refusal answers. Further fine-tuning is\nthen performed with standard benign answers, causing the overfitted LLM to\nforget the refusal attitude and thus provide compliant answers regardless of\nthe harmfulness of a question. We implement our attack on the ten LLMs and\ncompare it with five existing baselines. Experiments demonstrate that our\nmethod achieves significant advantages in both attack effectiveness and attack\nstealth. Our findings expose previously unreported security vulnerabilities in\ncurrent LLMs and provide a new perspective on understanding how LLMs' security\nis compromised, even with benign fine-tuning. Our code is available at\nhttps://github.com/ZHIXINXIE/tenBenign.", "AI": {"tldr": "\u901a\u8fc7\u4ec5\u4f7f\u752810\u4e2a\u826f\u6027\u95ee\u7b54\u5bf9\u5fae\u8c03LLMs\uff0c\u53ef\u4ee5\u6210\u529f\u5b9e\u73b0\u8d8a\u72f1\u653b\u51fb\u3002\u8be5\u65b9\u6cd5\u5148\u901a\u8fc7\u5305\u542b\u76f8\u540c\u62d2\u7edd\u56de\u7b54\u7684\u826f\u6027\u95ee\u7b54\u5bf9\u4f7fLLM\u8fc7\u62df\u5408\uff0c\u7136\u540e\u7528\u6807\u51c6\u826f\u6027\u7b54\u6848\u8fdb\u4e00\u6b65\u5fae\u8c03\uff0c\u4f7f\u8fc7\u62df\u5408\u7684LLM\u5fd8\u8bb0\u62d2\u7edd\u6001\u5ea6\uff0c\u4ece\u800c\u5bf9\u6709\u5bb3\u95ee\u9898\u4e5f\u63d0\u4f9b\u987a\u4ece\u56de\u7b54\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u5927\u91cf\u5b89\u5168\u5bf9\u9f50\u5de5\u4f5c\uff0c\u4f46LLMs\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\u3002\u73b0\u6709\u7684\u6076\u610f\u5fae\u8c03\u653b\u51fb\u867d\u7136\u6709\u6548\u4f46\u5bb9\u6613\u88ab\u68c0\u6d4b\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u66f4\u9690\u853d\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u4f7f\u7528\u5305\u542b\u76f8\u540c\u62d2\u7edd\u56de\u7b54\u7684\u826f\u6027\u95ee\u7b54\u5bf9\u4f7fLLM\u8fc7\u62df\u5408\uff0c\u7136\u540e\u4f7f\u7528\u6807\u51c6\u826f\u6027\u7b54\u6848\u8fdb\u884c\u8fdb\u4e00\u6b65\u5fae\u8c03\uff0c\u4f7f\u6a21\u578b\u5fd8\u8bb0\u62d2\u7edd\u6001\u5ea6\u3002", "result": "\u572810\u4e2aLLMs\u4e0a\u5b9e\u73b0\u653b\u51fb\uff0c\u4e0e5\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u653b\u51fb\u6548\u679c\u548c\u9690\u853d\u6027\u65b9\u9762\u90fd\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524dLLMs\u4e2d\u5148\u524d\u672a\u62a5\u544a\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u4e3a\u7406\u89e3\u5373\u4f7f\u4f7f\u7528\u826f\u6027\u5fae\u8c03\u5982\u4f55\u635f\u5bb3LLMs\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2510.03206", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03206", "abs": "https://arxiv.org/abs/2510.03206", "authors": ["Cai Zhou", "Chenxiao Yang", "Yi Hu", "Chenyu Wang", "Chubin Zhang", "Muhan Zhang", "Lester Mackey", "Tommi Jaakkola", "Stephen Bates", "Dinghuai Zhang"], "title": "Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner", "comment": "27 pages", "summary": "Diffusion language models, especially masked discrete diffusion models, have\nachieved great success recently. While there are some theoretical and primary\nempirical results showing the advantages of latent reasoning with looped\ntransformers or continuous chain-of-thoughts, continuous diffusion models\ntypically underperform their discrete counterparts. In this paper, we argue\nthat diffusion language models do not necessarily need to be in the discrete\nspace. In particular, we prove that continuous diffusion models have stronger\nexpressivity than discrete diffusions and looped transformers. We attribute the\ncontradiction between the theoretical expressiveness and empirical performance\nto their practical trainability: while continuous diffusion provides\nintermediate supervision that looped transformers lack, they introduce\nadditional difficulty decoding tokens into the discrete token space from the\ncontinuous representation space. We therefore propose Coevolutionary Continuous\nDiscrete Diffusion (CCDD), which defines a joint multimodal diffusion process\non the union of a continuous representation space and a discrete token space,\nleveraging a single model to simultaneously denoise in the joint space. By\ncombining two modalities, CCDD is expressive with rich semantics in the latent\nspace, as well as good trainability and sample quality with the help of\nexplicit discrete tokens. We also propose effective architectures and advanced\ntraining/sampling techniques for CCDD, which reveals strong empirical\nperformance in extensive language modeling experiments on real-world tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCCDD\u65b9\u6cd5\uff0c\u5728\u8fde\u7eed\u8868\u793a\u7a7a\u95f4\u548c\u79bb\u6563\u6807\u8bb0\u7a7a\u95f4\u7684\u8054\u5408\u7a7a\u95f4\u4e0a\u5b9a\u4e49\u591a\u6a21\u6001\u6269\u6563\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u8fde\u7eed\u6269\u6563\u6a21\u578b\u5728\u8bed\u8a00\u5efa\u6a21\u4e2d\u8868\u8fbe\u80fd\u529b\u4e0e\u8bad\u7ec3\u6027\u80fd\u4e4b\u95f4\u7684\u77db\u76fe\u3002", "motivation": "\u867d\u7136\u8fde\u7eed\u6269\u6563\u6a21\u578b\u7406\u8bba\u4e0a\u6bd4\u79bb\u6563\u6269\u6563\u6a21\u578b\u548c\u5faa\u73af\u53d8\u6362\u5668\u5177\u6709\u66f4\u5f3a\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8fde\u7eed\u8868\u793a\u5230\u79bb\u6563\u6807\u8bb0\u7a7a\u95f4\u7684\u89e3\u7801\u56f0\u96be\u3002", "method": "\u63d0\u51faCCDD\u65b9\u6cd5\uff0c\u5728\u8fde\u7eed\u8868\u793a\u7a7a\u95f4\u548c\u79bb\u6563\u6807\u8bb0\u7a7a\u95f4\u7684\u8054\u5408\u7a7a\u95f4\u4e0a\u5b9a\u4e49\u591a\u6a21\u6001\u6269\u6563\u8fc7\u7a0b\uff0c\u4f7f\u7528\u5355\u4e00\u6a21\u578b\u540c\u65f6\u5728\u8fd9\u4e24\u4e2a\u7a7a\u95f4\u4e2d\u8fdb\u884c\u53bb\u566a\u3002", "result": "CCDD\u5728\u771f\u5b9e\u4e16\u754c\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u5b9e\u8bc1\u6027\u80fd\uff0c\u7ed3\u5408\u4e86\u8fde\u7eed\u7a7a\u95f4\u7684\u4e30\u5bcc\u8bed\u4e49\u8868\u8fbe\u548c\u79bb\u6563\u6807\u8bb0\u7684\u826f\u597d\u8bad\u7ec3\u6027\u3002", "conclusion": "CCDD\u6210\u529f\u89e3\u51b3\u4e86\u8fde\u7eed\u6269\u6563\u6a21\u578b\u5728\u8bed\u8a00\u5efa\u6a21\u4e2d\u7684\u8bad\u7ec3\u96be\u9898\uff0c\u901a\u8fc7\u8054\u5408\u8fde\u7eed\u548c\u79bb\u6563\u7a7a\u95f4\u5b9e\u73b0\u4e86\u8868\u8fbe\u80fd\u529b\u4e0e\u8bad\u7ec3\u6027\u80fd\u7684\u5e73\u8861\u3002"}}
{"id": "2510.02944", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02944", "abs": "https://arxiv.org/abs/2510.02944", "authors": ["Kel Zin Tan", "Prashant Nalini Vasudevan"], "title": "Improved Search-to-Decision Reduction for Random Local Functions", "comment": null, "summary": "A random local function defined by a $d$-ary predicate $P$ is one where each\noutput bit is computed by applying $P$ to $d$ randomly chosen bits of its\ninput. These represent natural distributions of instances for constraint\nsatisfaction problems. They were put forward by Goldreich as candidates for\nlow-complexity one-way functions, and have subsequently been widely studied\nalso as potential pseudo-random generators.\n  We present a new search-to-decision reduction for random local functions\ndefined by any predicate of constant arity. Given any efficient algorithm that\ncan distinguish, with advantage $\\epsilon$, the output of a random local\nfunction with $m$ outputs and $n$ inputs from random, our reduction produces an\nefficient algorithm that can invert such functions with\n$\\tilde{O}(m(n/\\epsilon)^2)$ outputs, succeeding with probability\n$\\Omega(\\epsilon)$. This implies that if a family of local functions is\none-way, then a related family with shorter output length is family of\npseudo-random generators.\n  Prior to our work, all such reductions that were known required the predicate\nto have additional sensitivity properties, whereas our reduction works for any\npredicate. Our results also generalise to some super-constant values of the\narity $d$, and to noisy predicates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u4efb\u610f\u5e38\u6570\u5143\u8c13\u8bcd\u7684\u968f\u673a\u5c40\u90e8\u51fd\u6570\u7684\u65b0\u641c\u7d22\u5230\u51b3\u7b56\u5f52\u7ea6\uff0c\u6539\u8fdb\u4e86\u4e4b\u524d\u9700\u8981\u8c13\u8bcd\u5177\u6709\u989d\u5916\u654f\u611f\u6027\u5c5e\u6027\u7684\u9650\u5236\u3002", "motivation": "\u968f\u673a\u5c40\u90e8\u51fd\u6570\u4f5c\u4e3a\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u7684\u81ea\u7136\u5b9e\u4f8b\u5206\u5e03\uff0c\u88abGoldreich\u63d0\u51fa\u4f5c\u4e3a\u4f4e\u590d\u6742\u5ea6\u5355\u5411\u51fd\u6570\u7684\u5019\u9009\uff0c\u4e5f\u88ab\u5e7f\u6cdb\u7814\u7a76\u4f5c\u4e3a\u4f2a\u968f\u673a\u751f\u6210\u5668\u7684\u6f5c\u5728\u5019\u9009\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u641c\u7d22\u5230\u51b3\u7b56\u5f52\u7ea6\u65b9\u6cd5\uff0c\u7ed9\u5b9a\u80fd\u533a\u5206\u968f\u673a\u5c40\u90e8\u51fd\u6570\u8f93\u51fa\u4e0e\u968f\u673a\u8f93\u51fa\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u53ef\u4ee5\u6784\u9020\u51fa\u80fd\u53cd\u8f6c\u6b64\u7c7b\u51fd\u6570\u7684\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u5f52\u7ea6\u4ea7\u751f\u7684\u9ad8\u6548\u7b97\u6cd5\u80fd\u4ee5\u03a9(\u03b5)\u6982\u7387\u6210\u529f\u53cd\u8f6c\u5177\u6709\u00d5(m(n/\u03b5)\u00b2)\u8f93\u51fa\u7684\u968f\u673a\u5c40\u90e8\u51fd\u6570\u3002", "conclusion": "\u5982\u679c\u5c40\u90e8\u51fd\u6570\u65cf\u662f\u5355\u5411\u7684\uff0c\u90a3\u4e48\u5177\u6709\u8f83\u77ed\u8f93\u51fa\u957f\u5ea6\u7684\u76f8\u5173\u51fd\u6570\u65cf\u5c31\u662f\u4f2a\u968f\u673a\u751f\u6210\u5668\u65cf\uff0c\u8be5\u7ed3\u679c\u53ef\u63a8\u5e7f\u5230\u67d0\u4e9b\u8d85\u5e38\u6570\u5143\u6570\u548c\u566a\u58f0\u8c13\u8bcd\u3002"}}
{"id": "2510.02947", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.02947", "abs": "https://arxiv.org/abs/2510.02947", "authors": ["Aikaterini-Panagiota Stouka", "Conor McMenamin", "Demetris Kyriacou", "Lin Oshitani", "Quentin Botha"], "title": "SoK: Preconfirmations", "comment": "The latest version of this document is hosted on GitHub at:\n  https://github.com/NethermindEth/sok-preconfirmations", "summary": "In recent years, significant research efforts have focused on improving\nblockchain throughput and confirmation speeds without compromising security.\nWhile decreasing the time it takes for a transaction to be included in the\nblockchain ledger enhances user experience, a fundamental delay still remains\nbetween when a transaction is issued by a user and when its inclusion is\nconfirmed in the blockchain ledger. This delay limits user experience gains\nthrough the confirmation uncertainty it brings for users. This inherent delay\nin conventional blockchain protocols has led to the emergence of\npreconfirmation protocols -- protocols that provide users with early guarantees\nof eventual transaction confirmation.\n  This article presents a Systematization of Knowledge (SoK) on\npreconfirmations. We present the core terms and definitions needed to\nunderstand preconfirmations, outline a general framework for preconfirmation\nprotocols, and explore the economics and risks of preconfirmations. Finally, we\nsurvey and apply our framework to several implementations of real-world\npreconfirmation protocols, bridging the gap between theory and practice.", "AI": {"tldr": "\u672c\u6587\u5bf9\u533a\u5757\u94fe\u9884\u786e\u8ba4\u534f\u8bae\u8fdb\u884c\u4e86\u7cfb\u7edf\u5316\u77e5\u8bc6\u6574\u7406\uff0c\u63d0\u51fa\u4e86\u9884\u786e\u8ba4\u534f\u8bae\u7684\u4e00\u822c\u6846\u67b6\uff0c\u5e76\u5206\u6790\u4e86\u5176\u7ecf\u6d4e\u5b66\u548c\u98ce\u9669\uff0c\u6700\u540e\u8c03\u67e5\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u9884\u786e\u8ba4\u534f\u8bae\u5b9e\u73b0\u3002", "motivation": "\u4f20\u7edf\u533a\u5757\u94fe\u534f\u8bae\u5b58\u5728\u56fa\u6709\u5ef6\u8fdf\uff0c\u9650\u5236\u4e86\u7528\u6237\u4f53\u9a8c\u7684\u63d0\u5347\u3002\u9884\u786e\u8ba4\u534f\u8bae\u901a\u8fc7\u63d0\u4f9b\u65e9\u671f\u4ea4\u6613\u786e\u8ba4\u4fdd\u8bc1\u6765\u6539\u5584\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u5316\u77e5\u8bc6\u6574\u7406\u65b9\u6cd5\uff0c\u5b9a\u4e49\u6838\u5fc3\u672f\u8bed\uff0c\u6784\u5efa\u9884\u786e\u8ba4\u534f\u8bae\u7684\u4e00\u822c\u6846\u67b6\uff0c\u5206\u6790\u7ecf\u6d4e\u5b66\u548c\u98ce\u9669\uff0c\u5e76\u8c03\u67e5\u73b0\u5b9e\u4e16\u754c\u5b9e\u73b0\u3002", "result": "\u5efa\u7acb\u4e86\u9884\u786e\u8ba4\u534f\u8bae\u7684\u5b8c\u6574\u7406\u8bba\u6846\u67b6\uff0c\u8fde\u63a5\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u9884\u786e\u8ba4\u534f\u8bae\u662f\u6539\u5584\u533a\u5757\u94fe\u7528\u6237\u4f53\u9a8c\u7684\u91cd\u8981\u53d1\u5c55\u65b9\u5411\uff0c\u9700\u8981\u7efc\u5408\u8003\u8651\u6280\u672f\u5b9e\u73b0\u3001\u7ecf\u6d4e\u6fc0\u52b1\u548c\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2510.02960", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02960", "abs": "https://arxiv.org/abs/2510.02960", "authors": ["Khaled Serag", "Zhaozhou Tang", "Sungwoo Kim", "Vireshwar Kumar", "Dave", "Tian", "Saman Zonouz", "Raheem Beyah", "Dongyan Xu", "Z. Berkay Celik"], "title": "SoK: Kicking CAN Down the Road. Systematizing CAN Security Knowledge", "comment": null, "summary": "For decades, the Controller Area Network (CAN) has served as the primary\nin-vehicle bus (IVB) and extended its use to many non-vehicular systems. Over\nthe past years, CAN security has been intensively scrutinized, yielding\nextensive research literature. Despite its wealth, the literature lacks\nstructured systematization, complicating efforts to assess attack severity,\ndefense efficacy, identify security gaps, or root causes. This leaves non\nexperts uncertain about the relevancy of specific attacks or defenses to their\nsystems, inadvertently portraying CAN as irredeemably insecure. Further, the\nintroduction of new IVB technologies--CAN evolutions, add-ons, and alternative\nbuses--with heightened security claims risks fostering the misconception that\nmerely adopting these technologies resolves CAN's security challenges.\n  This paper systematizes existing CAN security knowledge, presenting a\ncomprehensive taxonomy and assessment models of attackers, attacks, and\ndefenses. It identifies replicable attacks and defense gaps, investigating\ntheir root causes as inherent, accidental, unique, or universal. It then\nextrapolates these insights to emerging IVB technologies by formally analyzing\nthree emerging IVBs to identify shared root causes with CAN and assess their\nability to close security gaps. The findings challenge common perceptions,\ndemonstrating that CAN is more securable than perceived, that most insecurity\nroot causes are shared across IVBs, and that merely adopting newer IVB\ntechnology does not solve persistent security issues. The paper concludes by\nhighlighting future research directions to secure IVB communication down the\nroad.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5316\u6574\u7406\u4e86CAN\u603b\u7ebf\u5b89\u5168\u77e5\u8bc6\uff0c\u63d0\u51fa\u4e86\u653b\u51fb\u8005\u3001\u653b\u51fb\u548c\u9632\u5fa1\u7684\u7efc\u5408\u5206\u7c7b\u4e0e\u8bc4\u4f30\u6a21\u578b\uff0c\u8bc6\u522b\u4e86\u53ef\u590d\u73b0\u653b\u51fb\u548c\u9632\u5fa1\u6f0f\u6d1e\uff0c\u5e76\u5206\u6790\u4e86\u65b0\u5174\u8f66\u8f7d\u603b\u7ebf\u6280\u672f\u7684\u5b89\u5168\u95ee\u9898\u3002", "motivation": "CAN\u603b\u7ebf\u5b89\u5168\u7814\u7a76\u7f3a\u4e4f\u7cfb\u7edf\u5316\u6574\u7406\uff0c\u96be\u4ee5\u8bc4\u4f30\u653b\u51fb\u4e25\u91cd\u6027\u548c\u9632\u5fa1\u6709\u6548\u6027\uff0c\u5bfc\u81f4\u975e\u4e13\u5bb6\u96be\u4ee5\u5224\u65ad\u7279\u5b9a\u653b\u51fb\u6216\u9632\u5fa1\u5bf9\u5176\u7cfb\u7edf\u7684\u76f8\u5173\u6027\uff0c\u4e14\u65b0\u5174\u8f66\u8f7d\u603b\u7ebf\u6280\u672f\u53ef\u80fd\u8bef\u5bfc\u4eba\u4eec\u8ba4\u4e3a\u4ec5\u91c7\u7528\u65b0\u6280\u672f\u5c31\u80fd\u89e3\u51b3CAN\u7684\u5b89\u5168\u6311\u6218\u3002", "method": "\u6784\u5efa\u4e86\u653b\u51fb\u8005\u3001\u653b\u51fb\u548c\u9632\u5fa1\u7684\u7efc\u5408\u5206\u7c7b\u4e0e\u8bc4\u4f30\u6a21\u578b\uff0c\u8bc6\u522b\u53ef\u590d\u73b0\u653b\u51fb\u548c\u9632\u5fa1\u6f0f\u6d1e\uff0c\u5206\u6790\u5176\u6839\u672c\u539f\u56e0\uff0c\u5e76\u6b63\u5f0f\u5206\u6790\u4e09\u79cd\u65b0\u5174\u8f66\u8f7d\u603b\u7ebf\u6280\u672f\u4ee5\u8bc6\u522b\u4e0eCAN\u5171\u4eab\u7684\u6839\u672c\u539f\u56e0\u3002", "result": "\u7814\u7a76\u53d1\u73b0CAN\u6bd4\u666e\u904d\u8ba4\u4e3a\u7684\u66f4\u5b89\u5168\uff0c\u5927\u591a\u6570\u4e0d\u5b89\u5168\u6839\u6e90\u5728\u8f66\u8f7d\u603b\u7ebf\u95f4\u5171\u4eab\uff0c\u4ec5\u91c7\u7528\u66f4\u65b0\u7684\u8f66\u8f7d\u603b\u7ebf\u6280\u672f\u5e76\u4e0d\u80fd\u89e3\u51b3\u6301\u7eed\u7684\u5b89\u5168\u95ee\u9898\u3002", "conclusion": "\u9700\u8981\u672a\u6765\u7814\u7a76\u65b9\u5411\u6765\u786e\u4fdd\u8f66\u8f7d\u603b\u7ebf\u901a\u4fe1\u7684\u5b89\u5168\uff0c\u6311\u6218\u4e86\u5173\u4e8eCAN\u5b89\u5168\u6027\u548c\u65b0\u5174\u603b\u7ebf\u6280\u672f\u6709\u6548\u6027\u7684\u5e38\u89c1\u8ba4\u77e5\u3002"}}
{"id": "2510.02964", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02964", "abs": "https://arxiv.org/abs/2510.02964", "authors": ["Yu He", "Yifei Chen", "Yiming Li", "Shuo Shao", "Leyi Qi", "Boheng Li", "Dacheng Tao", "Zhan Qin"], "title": "External Data Extraction Attacks against Retrieval-Augmented Large Language Models", "comment": null, "summary": "In recent years, RAG has emerged as a key paradigm for enhancing large\nlanguage models (LLMs). By integrating externally retrieved information, RAG\nalleviates issues like outdated knowledge and, crucially, insufficient domain\nexpertise. While effective, RAG introduces new risks of external data\nextraction attacks (EDEAs), where sensitive or copyrighted data in its\nknowledge base may be extracted verbatim. These risks are particularly acute\nwhen RAG is used to customize specialized LLM applications with private\nknowledge bases. Despite initial studies exploring these risks, they often lack\na formalized framework, robust attack performance, and comprehensive\nevaluation, leaving critical questions about real-world EDEA feasibility\nunanswered.\n  In this paper, we present the first comprehensive study to formalize EDEAs\nagainst retrieval-augmented LLMs. We first formally define EDEAs and propose a\nunified framework decomposing their design into three components: extraction\ninstruction, jailbreak operator, and retrieval trigger, under which prior\nattacks can be considered instances within our framework. Guided by this\nframework, we develop SECRET: a Scalable and EffeCtive exteRnal data Extraction\naTtack. Specifically, SECRET incorporates (1) an adaptive optimization process\nusing LLMs as optimizers to generate specialized jailbreak prompts for EDEAs,\nand (2) cluster-focused triggering, an adaptive strategy that alternates\nbetween global exploration and local exploitation to efficiently generate\neffective retrieval triggers. Extensive evaluations across 4 models reveal that\nSECRET significantly outperforms previous attacks, and is highly effective\nagainst all 16 tested RAG instances. Notably, SECRET successfully extracts 35%\nof the data from RAG powered by Claude 3.7 Sonnet for the first time, whereas\nother attacks yield 0% extraction. Our findings call for attention to this\nemerging threat.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SECRET\u653b\u51fb\u6846\u67b6\uff0c\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9\u68c0\u7d22\u589e\u5f3a\u8bed\u8a00\u6a21\u578b(RAG)\u7684\u5916\u90e8\u6570\u636e\u63d0\u53d6\u653b\u51fb(EDEA)\u7684\u5168\u9762\u7814\u7a76\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\uff0c\u6210\u529f\u4eceClaude 3.7 Sonnet\u4e2d\u63d0\u53d635%\u7684\u6570\u636e\u3002", "motivation": "RAG\u867d\u7136\u80fd\u589e\u5f3aLLMs\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4f46\u5f15\u5165\u4e86\u5916\u90e8\u6570\u636e\u63d0\u53d6\u653b\u51fb\u98ce\u9669\uff0c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u6b63\u5f0f\u6846\u67b6\u548c\u6709\u6548\u653b\u51fb\u65b9\u6cd5\uff0c\u65e0\u6cd5\u8bc4\u4f30\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u5a01\u80c1\u53ef\u884c\u6027\u3002", "method": "\u63d0\u51fa\u7edf\u4e00EDEA\u6846\u67b6\uff0c\u5c06\u653b\u51fb\u8bbe\u8ba1\u5206\u89e3\u4e3a\u63d0\u53d6\u6307\u4ee4\u3001\u8d8a\u72f1\u64cd\u4f5c\u7b26\u548c\u68c0\u7d22\u89e6\u53d1\u5668\u4e09\u4e2a\u7ec4\u4ef6\uff0c\u5e76\u5f00\u53d1SECRET\u653b\u51fb\uff0c\u5305\u542bLLM\u4f18\u5316\u7684\u81ea\u9002\u5e94\u8d8a\u72f1\u63d0\u793a\u751f\u6210\u548c\u96c6\u7fa4\u805a\u7126\u89e6\u53d1\u7b56\u7565\u3002", "result": "\u57284\u4e2a\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cSECRET\u663e\u8457\u4f18\u4e8e\u5148\u524d\u653b\u51fb\uff0c\u5bf916\u4e2a\u6d4b\u8bd5RAG\u5b9e\u4f8b\u90fd\u9ad8\u5ea6\u6709\u6548\uff0c\u9996\u6b21\u4eceClaude 3.7 Sonnet\u4e2d\u6210\u529f\u63d0\u53d635%\u6570\u636e\uff0c\u800c\u5176\u4ed6\u653b\u51fb\u63d0\u53d6\u7387\u4e3a0%\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86RAG\u7cfb\u7edf\u9762\u4e34\u7684\u5916\u90e8\u6570\u636e\u63d0\u53d6\u5a01\u80c1\uff0c\u547c\u5401\u5173\u6ce8\u8fd9\u4e00\u65b0\u5174\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2510.02999", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02999", "abs": "https://arxiv.org/abs/2510.02999", "authors": ["Xinzhe Huang", "Wenjing Hu", "Tianhang Zheng", "Kedong Xiu", "Xiaojun Jia", "Di Wang", "Zhan Qin", "Kui Ren"], "title": "Untargeted Jailbreak Attack", "comment": null, "summary": "Existing gradient-based jailbreak attacks on Large Language Models (LLMs),\nsuch as Greedy Coordinate Gradient (GCG) and COLD-Attack, typically optimize\nadversarial suffixes to align the LLM output with a predefined target response.\nHowever, by restricting the optimization objective as inducing a predefined\ntarget, these methods inherently constrain the adversarial search space, which\nlimit their overall attack efficacy. Furthermore, existing methods typically\nrequire a large number of optimization iterations to fulfill the large gap\nbetween the fixed target and the original model response, resulting in low\nattack efficiency.\n  To overcome the limitations of targeted jailbreak attacks, we propose the\nfirst gradient-based untargeted jailbreak attack (UJA), aiming to elicit an\nunsafe response without enforcing any predefined patterns. Specifically, we\nformulate an untargeted attack objective to maximize the unsafety probability\nof the LLM response, which can be quantified using a judge model. Since the\nobjective is non-differentiable, we further decompose it into two\ndifferentiable sub-objectives for optimizing an optimal harmful response and\nthe corresponding adversarial prompt, with a theoretical analysis to validate\nthe decomposition. In contrast to targeted jailbreak attacks, UJA's\nunrestricted objective significantly expands the search space, enabling a more\nflexible and efficient exploration of LLM vulnerabilities.Extensive evaluations\ndemonstrate that \\textsc{UJA} can achieve over 80\\% attack success rates\nagainst recent safety-aligned LLMs with only 100 optimization iterations,\noutperforming the state-of-the-art gradient-based attacks such as I-GCG and\nCOLD-Attack by over 20\\%.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u57fa\u4e8e\u68af\u5ea6\u7684\u65e0\u76ee\u6807\u8d8a\u72f1\u653b\u51fbUJA\uff0c\u901a\u8fc7\u6700\u5927\u5316\u6a21\u578b\u54cd\u5e94\u7684\u4e0d\u5b89\u5168\u6982\u7387\u6765\u7ed5\u8fc7\u5b89\u5168\u5bf9\u9f50\uff0c\u76f8\u6bd4\u73b0\u6709\u76ee\u6807\u653b\u51fb\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6210\u529f\u7387\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u68af\u5ea6\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\u901a\u8fc7\u4f18\u5316\u5bf9\u6297\u540e\u7f00\u6765\u4f7fLLM\u8f93\u51fa\u9884\u5b9a\u4e49\u7684\u76ee\u6807\u54cd\u5e94\uff0c\u8fd9\u79cd\u65b9\u6cd5\u9650\u5236\u4e86\u5bf9\u6297\u641c\u7d22\u7a7a\u95f4\uff0c\u4e14\u9700\u8981\u5927\u91cf\u4f18\u5316\u8fed\u4ee3\u6765\u5f25\u5408\u56fa\u5b9a\u76ee\u6807\u4e0e\u539f\u59cb\u54cd\u5e94\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5bfc\u81f4\u653b\u51fb\u6548\u679c\u548c\u6548\u7387\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u65e0\u76ee\u6807\u653b\u51fb\u76ee\u6807\uff0c\u6700\u5927\u5316LLM\u54cd\u5e94\u7684\u4e0d\u5b89\u5168\u6982\u7387\uff0c\u4f7f\u7528\u8bc4\u5224\u6a21\u578b\u91cf\u5316\u4e0d\u5b89\u5168\u6982\u7387\u3002\u7531\u4e8e\u76ee\u6807\u4e0d\u53ef\u5fae\u5206\uff0c\u5c06\u5176\u5206\u89e3\u4e3a\u4e24\u4e2a\u53ef\u5fae\u5206\u7684\u5b50\u76ee\u6807\uff1a\u4f18\u5316\u6700\u4f18\u6709\u5bb3\u54cd\u5e94\u548c\u76f8\u5e94\u7684\u5bf9\u6297\u63d0\u793a\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u5206\u89e3\u7684\u6709\u6548\u6027\u3002", "result": "\u5728\u4ec5100\u6b21\u4f18\u5316\u8fed\u4ee3\u7684\u60c5\u51b5\u4e0b\uff0cUJA\u5bf9\u6700\u65b0\u5b89\u5168\u5bf9\u9f50LLM\u7684\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc780%\uff0c\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u68af\u5ea6\u653b\u51fb\u65b9\u6cd5\uff08\u5982I-GCG\u548cCOLD-Attack\uff09\u9ad8\u51fa20%\u4ee5\u4e0a\u3002", "conclusion": "\u65e0\u76ee\u6807\u8d8a\u72f1\u653b\u51fb\u901a\u8fc7\u4e0d\u53d7\u9650\u5236\u7684\u76ee\u6807\u663e\u8457\u6269\u5c55\u4e86\u641c\u7d22\u7a7a\u95f4\uff0c\u80fd\u591f\u66f4\u7075\u6d3b\u9ad8\u6548\u5730\u63a2\u7d22LLM\u6f0f\u6d1e\uff0c\u76f8\u6bd4\u76ee\u6807\u653b\u51fb\u65b9\u6cd5\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2510.03035", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.03035", "abs": "https://arxiv.org/abs/2510.03035", "authors": ["Lambert Hogenhout", "Rinzin Wangmo"], "title": "Protecting Persona Biometric Data: The Case of Facial Privacy", "comment": null, "summary": "The proliferation of digital technologies has led to unprecedented data\ncollection, with facial data emerging as a particularly sensitive commodity.\nCompanies are increasingly leveraging advanced facial recognition technologies,\noften without the explicit consent or awareness of individuals, to build\nsophisticated surveillance capabilities. This practice, fueled by weak and\nfragmented laws in many jurisdictions, has created a regulatory vacuum that\nallows for the commercialization of personal identity and poses significant\nthreats to individual privacy and autonomy. This article introduces the concept\nof Facial Privacy. It analyzes the profound challenges posed by unregulated\nfacial recognition by conducting a comprehensive review of existing legal\nframeworks. It examines and compares regulations such as the GDPR, Brazil's\nLGPD, Canada's PIPEDA, and privacy acts in China, Singapore, South Korea, and\nJapan, alongside sector-specific laws in the United States like the Illinois\nBiometric Information Privacy Act (BIPA). The analysis highlights the societal\nimpacts of this technology, including the potential for discriminatory bias and\nthe long-lasting harm that can result from the theft of immutable biometric\ndata. Ultimately, the paper argues that existing legal loopholes and\nambiguities leave individuals vulnerable. It proposes a new policy framework\nthat shifts the paradigm from data as property to a model of inalienable\nrights, ensuring that fundamental human rights are upheld against unchecked\ntechnological expansion.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9762\u90e8\u9690\u79c1\u6982\u5ff5\uff0c\u5206\u6790\u65e0\u76d1\u7ba1\u9762\u90e8\u8bc6\u522b\u6280\u672f\u7684\u6311\u6218\uff0c\u6bd4\u8f83\u5168\u7403\u6cd5\u5f8b\u6846\u67b6\uff0c\u6307\u51fa\u6cd5\u5f8b\u6f0f\u6d1e\u4f7f\u4e2a\u4eba\u6613\u53d7\u4fb5\u5bb3\uff0c\u5efa\u8bae\u4ece\u6570\u636e\u8d22\u4ea7\u6743\u8f6c\u5411\u4e0d\u53ef\u5265\u593a\u6743\u5229\u7684\u65b0\u653f\u7b56\u6846\u67b6\u3002", "motivation": "\u6570\u5b57\u6280\u672f\u666e\u53ca\u5bfc\u81f4\u5927\u91cf\u9762\u90e8\u6570\u636e\u88ab\u6536\u96c6\uff0c\u516c\u53f8\u672a\u7ecf\u660e\u786e\u540c\u610f\u4f7f\u7528\u9762\u90e8\u8bc6\u522b\u6280\u672f\u8fdb\u884c\u76d1\u63a7\uff0c\u7531\u4e8e\u6cd5\u5f8b\u8584\u5f31\u5206\u6563\u5f62\u6210\u76d1\u7ba1\u771f\u7a7a\uff0c\u5a01\u80c1\u4e2a\u4eba\u9690\u79c1\u548c\u81ea\u4e3b\u6743\u3002", "method": "\u901a\u8fc7\u5168\u9762\u5ba1\u67e5\u73b0\u6709\u6cd5\u5f8b\u6846\u67b6\uff0c\u5206\u6790\u6bd4\u8f83GDPR\u3001\u5df4\u897fLGPD\u3001\u52a0\u62ff\u5927PIPEDA\u3001\u4e2d\u56fd\u3001\u65b0\u52a0\u5761\u3001\u97e9\u56fd\u3001\u65e5\u672c\u9690\u79c1\u6cd5\u4ee5\u53ca\u7f8e\u56fd\u4f0a\u5229\u8bfa\u4f0a\u5dde\u751f\u7269\u8bc6\u522b\u4fe1\u606f\u9690\u79c1\u6cd5\u7b49\u6cd5\u89c4\u3002", "result": "\u5206\u6790\u663e\u793a\u73b0\u6709\u6cd5\u5f8b\u6f0f\u6d1e\u548c\u6a21\u7cca\u6027\u4f7f\u4e2a\u4eba\u6613\u53d7\u4fb5\u5bb3\uff0c\u9762\u90e8\u8bc6\u522b\u6280\u672f\u53ef\u80fd\u5e26\u6765\u6b67\u89c6\u6027\u504f\u89c1\u548c\u4e0d\u53ef\u66f4\u6539\u751f\u7269\u8bc6\u522b\u6570\u636e\u88ab\u76d7\u7684\u6301\u4e45\u4f24\u5bb3\u7b49\u793e\u4f1a\u5f71\u54cd\u3002", "conclusion": "\u4e3b\u5f20\u4ece\u6570\u636e\u4f5c\u4e3a\u8d22\u4ea7\u7684\u6a21\u5f0f\u8f6c\u5411\u4e0d\u53ef\u5265\u593a\u6743\u5229\u7684\u65b0\u653f\u7b56\u6846\u67b6\uff0c\u786e\u4fdd\u57fa\u672c\u4eba\u6743\u4e0d\u53d7\u4e0d\u53d7\u63a7\u5236\u7684\u6280\u672f\u6269\u5f20\u4fb5\u5bb3\u3002"}}
{"id": "2510.03219", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.03219", "abs": "https://arxiv.org/abs/2510.03219", "authors": ["Al Nahian Bin Emran", "Rajendra Upadhyay", "Rajendra Paudyal", "Lisa Donnan", "Duminda Wijesekera"], "title": "TPM-Based Continuous Remote Attestation and Integrity Verification for 5G VNFs on Kubernetes", "comment": null, "summary": "In the rapidly evolving landscape of 5G technology, the adoption of\ncloud-based infrastructure for the deployment of 5G services has become\nincreasingly common. Using a service-based architecture, critical 5G\ncomponents, such as the Access and Mobility Management Function (AMF), Session\nManagement Function (SMF), and User Plane Function (UPF), now run as\ncontainerized pods on Kubernetes clusters. Although this approach improves\nscalability, flexibility, and resilience, it also introduces new security\nchallenges, particularly to ensure the integrity and trustworthiness of these\ncomponents. Current 5G security specifications (for example, 3GPP TS 33.501)\nfocus on communication security and assume that network functions remain\ntrustworthy after authentication, consequently lacking mechanisms to\ncontinuously validate the integrity of NVFs at runtime. To close this gap, and\nto align with Zero Trust principles of 'never trust, always verify', we present\na TPM 2.0-based continuous remote attestation solution for core 5G components\ndeployed on Kubernetes. Our approach uses the Linux Integrity Measurement\nArchitecture (IMA) and a Trusted Platform Module (TPM) to provide\nhardware-based runtime validation. We integrate the open-source Keylime\nframework with a custom IMA template that isolates pod-level measurements,\nallowing per-pod integrity verification. A prototype on a k3s cluster\n(consisting of 1 master, 2 worker nodes) was implemented to attest to core\nfunctions, including AMF, SMF and UPF. The experimental results show that the\nsystem detects unauthorized modifications in real time, labels each pod's trust\nstate, and generates detailed audit logs. This work provides hardware-based\ncontinuous attestation for cloud native and edge deployments, strengthening the\nresilience of 5G as critical infrastructure in multi-vendor and\nmission-critical scenarios of 5G.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eTPM 2.0\u7684\u6301\u7eed\u8fdc\u7a0b\u8ba4\u8bc1\u89e3\u51b3\u65b9\u6848\uff0c\u4e3aKubernetes\u4e0a\u90e8\u7f72\u76845G\u6838\u5fc3\u7ec4\u4ef6\u63d0\u4f9b\u786c\u4ef6\u7ea7\u8fd0\u884c\u65f6\u5b8c\u6574\u6027\u9a8c\u8bc1\u3002", "motivation": "5G\u91c7\u7528\u4e91\u539f\u751f\u67b6\u6784\u540e\uff0c\u867d\u7136\u63d0\u5347\u4e86\u53ef\u6269\u5c55\u6027\u548c\u7075\u6d3b\u6027\uff0c\u4f46\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u6311\u6218\u3002\u73b0\u67095G\u5b89\u5168\u89c4\u8303\u7f3a\u4e4f\u5bf9\u7f51\u7edc\u529f\u80fd\u8fd0\u884c\u65f6\u5b8c\u6574\u6027\u7684\u6301\u7eed\u9a8c\u8bc1\u673a\u5236\uff0c\u4e0d\u7b26\u5408\u96f6\u4fe1\u4efb\u539f\u5219\u3002", "method": "\u4f7f\u7528Linux\u5b8c\u6574\u6027\u6d4b\u91cf\u67b6\u6784(IMA)\u548c\u53ef\u4fe1\u5e73\u53f0\u6a21\u5757(TPM)\uff0c\u96c6\u6210Keylime\u6846\u67b6\u548c\u81ea\u5b9a\u4e49IMA\u6a21\u677f\uff0c\u5b9e\u73b0pod\u7ea7\u522b\u7684\u9694\u79bb\u6d4b\u91cf\u548c\u5b8c\u6574\u6027\u9a8c\u8bc1\u3002", "result": "\u5728k3s\u96c6\u7fa4\u4e0a\u7684\u539f\u578b\u7cfb\u7edf\u80fd\u591f\u5b9e\u65f6\u68c0\u6d4b\u672a\u7ecf\u6388\u6743\u7684\u4fee\u6539\uff0c\u6807\u8bb0\u6bcf\u4e2apod\u7684\u4fe1\u4efb\u72b6\u6001\uff0c\u5e76\u751f\u6210\u8be6\u7ec6\u5ba1\u8ba1\u65e5\u5fd7\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u4e91\u539f\u751f\u548c\u8fb9\u7f18\u90e8\u7f72\u63d0\u4f9b\u4e86\u57fa\u4e8e\u786c\u4ef6\u7684\u6301\u7eed\u8ba4\u8bc1\uff0c\u589e\u5f3a\u4e865G\u5728\u591a\u4f9b\u5e94\u5546\u548c\u5173\u952e\u4efb\u52a1\u573a\u666f\u4e0b\u7684\u5f39\u6027\u3002"}}
