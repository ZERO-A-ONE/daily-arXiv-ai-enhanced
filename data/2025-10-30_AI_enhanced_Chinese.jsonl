{"id": "2510.24749", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24749", "abs": "https://arxiv.org/abs/2510.24749", "authors": ["Aofan Liu", "Shiyuan Song", "Haoxuan Li", "Cehao Yang", "Yiyan Qi"], "title": "Beyond Function-Level Search: Repository-Aware Dual-Encoder Code Retrieval with Adversarial Verification", "comment": "Accepted by EMNLP 2025", "summary": "The escalating complexity of modern codebases has intensified the need for\nretrieval systems capable of interpreting cross-component change intents, a\ncapability fundamentally absent in conventional function-level search\nparadigms. While recent studies have improved the alignment between natural\nlanguage queries and code snippets, retrieving contextually relevant code for\nspecific change requests remains largely underexplored. To address this gap, we\nintroduce RepoAlign-Bench, the first benchmark specifically designed to\nevaluate repository-level code retrieval under change request driven scenarios,\nencompassing 52k annotated instances. This benchmark shifts the retrieval\nparadigm from function-centric matching to holistic repository-level reasoning.\nFurthermore, we propose ReflectCode, an adversarial reflection augmented\ndual-tower architecture featuring disentangled code_encoder and doc_encoder\ncomponents. ReflectCode dynamically integrates syntactic patterns, function\ndependencies, and semantic expansion intents through large language model\nguided reflection. Comprehensive experiments demonstrate that ReflectCode\nachieves 12.2% improvement in Top-5 Accuracy and 7.1% in Recall over\nstate-of-the-art baselines, establishing a new direction for context-aware code\nretrieval.", "AI": {"tldr": "\u63d0\u51fa\u4e86RepoAlign-Bench\u57fa\u51c6\u6d4b\u8bd5\u548cReflectCode\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u4ee3\u7801\u5e93\u7ea7\u522b\u7684\u4ee3\u7801\u68c0\u7d22\u95ee\u9898\uff0c\u5728\u53d8\u66f4\u8bf7\u6c42\u9a71\u52a8\u573a\u666f\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u4ee3\u7801\u5e93\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u80fd\u591f\u7406\u89e3\u8de8\u7ec4\u4ef6\u53d8\u66f4\u610f\u56fe\u7684\u68c0\u7d22\u7cfb\u7edf\uff0c\u800c\u4f20\u7edf\u7684\u51fd\u6570\u7ea7\u641c\u7d22\u8303\u5f0f\u7f3a\u4e4f\u8fd9\u79cd\u80fd\u529b\u3002", "method": "\u63d0\u51faReflectCode\u6a21\u578b\uff0c\u91c7\u7528\u5bf9\u6297\u53cd\u5c04\u589e\u5f3a\u7684\u53cc\u5854\u67b6\u6784\uff0c\u5305\u542b\u89e3\u8026\u7684\u4ee3\u7801\u7f16\u7801\u5668\u548c\u6587\u6863\u7f16\u7801\u5668\u7ec4\u4ef6\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u5f15\u5bfc\u7684\u53cd\u5c04\u52a8\u6001\u6574\u5408\u8bed\u6cd5\u6a21\u5f0f\u3001\u51fd\u6570\u4f9d\u8d56\u548c\u8bed\u4e49\u6269\u5c55\u610f\u56fe\u3002", "result": "\u5728Top-5\u51c6\u786e\u7387\u4e0a\u63d0\u534712.2%\uff0c\u53ec\u56de\u7387\u63d0\u53477.1%\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u4e3a\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4ee3\u7801\u68c0\u7d22\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u4ece\u51fd\u6570\u4e2d\u5fc3\u5339\u914d\u8f6c\u5411\u6574\u4f53\u4ee3\u7801\u5e93\u7ea7\u63a8\u7406\u3002"}}
{"id": "2510.24799", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.24799", "abs": "https://arxiv.org/abs/2510.24799", "authors": ["Filipe R. Cogo", "Gustavo A. Oliva", "Ahmed E. Hassan"], "title": "Compiler.next: A Search-Based Compiler to Power the AI-Native Future of Software Engineering", "comment": "31 pages, 5 figures, submitted to ACM Transactions on Software\n  Engineering and Methodology", "summary": "The rapid advancement of AI-assisted software engineering has brought\ntransformative potential to the field of software engineering, but existing\ntools and paradigms remain limited by cognitive overload, inefficient tool\nintegration, and the narrow capabilities of AI copilots. In response, we\npropose Compiler.next, a novel search-based compiler designed to enable the\nseamless evolution of AI-native software systems as part of the emerging\nSoftware Engineering 3.0 era. Unlike traditional static compilers,\nCompiler.next takes human-written intents and automatically generates working\nsoftware by searching for an optimal solution. This process involves dynamic\noptimization of cognitive architectures and their constituents (e.g., prompts,\nfoundation model configurations, and system parameters) while finding the\noptimal trade-off between several objectives, such as accuracy, cost, and\nlatency. This paper outlines the architecture of Compiler.next and positions it\nas a cornerstone in democratizing software development by lowering the\ntechnical barrier for non-experts, enabling scalable, adaptable, and reliable\nAI-powered software. We present a roadmap to address the core challenges in\nintent compilation, including developing quality programming constructs,\neffective search heuristics, reproducibility, and interoperability between\ncompilers. Our vision lays the groundwork for fully automated, search-driven\nsoftware development, fostering faster innovation and more efficient AI-driven\nsystems.", "AI": {"tldr": "Compiler.next\u662f\u4e00\u4e2a\u57fa\u4e8e\u641c\u7d22\u7684\u7f16\u8bd1\u5668\uff0c\u80fd\u591f\u5c06\u4eba\u7c7b\u610f\u56fe\u81ea\u52a8\u8f6c\u5316\u4e3a\u5de5\u4f5c\u8f6f\u4ef6\uff0c\u901a\u8fc7\u52a8\u6001\u4f18\u5316\u8ba4\u77e5\u67b6\u6784\u6765\u5e73\u8861\u51c6\u786e\u6027\u3001\u6210\u672c\u548c\u5ef6\u8fdf\u7b49\u76ee\u6807\u3002", "motivation": "\u73b0\u6709AI\u8f85\u52a9\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u5b58\u5728\u8ba4\u77e5\u8fc7\u8f7d\u3001\u5de5\u5177\u96c6\u6210\u6548\u7387\u4f4e\u548cAI\u52a9\u624b\u80fd\u529b\u6709\u9650\u7b49\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u8303\u5f0f\u6765\u964d\u4f4e\u6280\u672f\u95e8\u69db\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u9002\u5e94\u6027\u5f3a\u4e14\u53ef\u9760\u7684AI\u9a71\u52a8\u8f6f\u4ef6\u5f00\u53d1\u3002", "method": "\u63d0\u51fa\u641c\u7d22\u5f0f\u7f16\u8bd1\u5668\u67b6\u6784\uff0c\u901a\u8fc7\u52a8\u6001\u4f18\u5316\u8ba4\u77e5\u67b6\u6784\u7ec4\u4ef6\uff08\u5982\u63d0\u793a\u8bcd\u3001\u57fa\u7840\u6a21\u578b\u914d\u7f6e\u548c\u7cfb\u7edf\u53c2\u6570\uff09\uff0c\u5728\u591a\u76ee\u6807\u95f4\u5bfb\u627e\u6700\u4f18\u6743\u8861\u6765\u751f\u6210\u8f6f\u4ef6\u3002", "result": "\u6784\u5efa\u4e86Compiler.next\u7684\u67b6\u6784\u6846\u67b6\uff0c\u4e3a\u5b8c\u5168\u81ea\u52a8\u5316\u3001\u641c\u7d22\u9a71\u52a8\u7684\u8f6f\u4ef6\u5f00\u53d1\u5960\u5b9a\u57fa\u7840\uff0c\u4fc3\u8fdb\u66f4\u5feb\u7684\u521b\u65b0\u548c\u66f4\u9ad8\u6548\u7684AI\u9a71\u52a8\u7cfb\u7edf\u3002", "conclusion": "Compiler.next\u662f\u8f6f\u4ef6\u5de5\u7a0b3.0\u65f6\u4ee3\u7684\u5173\u952e\u57fa\u77f3\uff0c\u901a\u8fc7\u964d\u4f4e\u975e\u4e13\u5bb6\u7684\u6280\u672f\u95e8\u69db\uff0c\u5b9e\u73b0AI\u539f\u751f\u8f6f\u4ef6\u7cfb\u7edf\u7684\u65e0\u7f1d\u6f14\u8fdb\uff0c\u4e3a\u6c11\u4e3b\u5316\u8f6f\u4ef6\u5f00\u53d1\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2510.24819", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.24819", "abs": "https://arxiv.org/abs/2510.24819", "authors": ["Vincenzo Scotti", "Jan Keim", "Tobias Hey", "Andreas Metzger", "Anne Koziolek", "Raffaela Mirandola"], "title": "A Roadmap for Tamed Interactions with Large Language Models", "comment": null, "summary": "We are witnessing a bloom of AI-powered software driven by Large Language\nModels (LLMs). Although the applications of these LLMs are impressive and\nseemingly countless, their unreliability hinders adoption. In fact, the\ntendency of LLMs to produce faulty or hallucinated content makes them\nunsuitable for automating workflows and pipelines. In this regard, Software\nEngineering (SE) provides valuable support, offering a wide range of formal\ntools to specify, verify, and validate software behaviour. Such SE tools can be\napplied to define constraints over LLM outputs and, consequently, offer\nstronger guarantees on the generated content. In this paper, we argue that the\ndevelopment of a Domain Specific Language (DSL) for scripting interactions with\nLLMs using an LLM Scripting Language (LSL) may be key to improve AI-based\napplications. Currently, LLMs and LLM-based software still lack reliability,\nrobustness, and trustworthiness, and the tools or frameworks to cope with these\nissues suffer from fragmentation. In this paper, we present our vision of LSL.\nWith LSL, we aim to address the limitations above by exploring ways to control\nLLM outputs, enforce structure in interactions, and integrate these aspects\nwith verification, validation, and explainability. Our goal is to make LLM\ninteraction programmable and decoupled from training or implementation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00LSL\uff0c\u65e8\u5728\u901a\u8fc7\u7f16\u7a0b\u65b9\u5f0f\u63a7\u5236LLM\u8f93\u51fa\u3001\u589e\u5f3a\u4ea4\u4e92\u7ed3\u6784\uff0c\u5e76\u7ed3\u5408\u9a8c\u8bc1\u548c\u53ef\u89e3\u91ca\u6027\u6765\u63d0\u5347AI\u5e94\u7528\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u5f53\u524dLLM\u5e94\u7528\u867d\u7136\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\uff0c\u4f46\u5176\u4e0d\u53ef\u9760\u6027\u548c\u5e7b\u89c9\u95ee\u9898\u963b\u788d\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u6765\u7ea6\u675fLLM\u8f93\u51fa\u5e76\u63d0\u4f9b\u66f4\u5f3a\u7684\u5185\u5bb9\u4fdd\u8bc1\u3002", "method": "\u5f00\u53d1LLM\u811a\u672c\u8bed\u8a00LSL\uff0c\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u6765\u7f16\u7a0b\u5316LLM\u4ea4\u4e92\uff0c\u63a7\u5236\u8f93\u51fa\u7ed3\u6784\uff0c\u5e76\u4e0e\u9a8c\u8bc1\u3001\u9a8c\u8bc1\u548c\u53ef\u89e3\u91ca\u6027\u96c6\u6210\u3002", "result": "\u63d0\u51fa\u4e86LSL\u7684\u613f\u666f\u6846\u67b6\uff0c\u65e8\u5728\u4f7fLLM\u4ea4\u4e92\u53ef\u7f16\u7a0b\u5316\uff0c\u5e76\u4e0e\u8bad\u7ec3\u6216\u5b9e\u73b0\u89e3\u8026\u3002", "conclusion": "LSL\u53ef\u80fd\u662f\u63d0\u9ad8\u57fa\u4e8eAI\u5e94\u7528\u53ef\u9760\u6027\u7684\u5173\u952e\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u4ea4\u4e92\u548c\u96c6\u6210\u9a8c\u8bc1\u5de5\u5177\u6765\u89e3\u51b3\u5f53\u524dLLM\u5e94\u7528\u7684\u788e\u7247\u5316\u95ee\u9898\u3002"}}
{"id": "2510.25015", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25015", "abs": "https://arxiv.org/abs/2510.25015", "authors": ["Chuyue Sun", "Yican Sun", "Daneshvar Amrollahi", "Ethan Zhang", "Shuvendu Lahiri", "Shan Lu", "David Dill", "Clark Barrett"], "title": "VeriStruct: AI-assisted Automated Verification of Data-Structure Modules in Verus", "comment": null, "summary": "We introduce VeriStruct, a novel framework that extends AI-assisted automated\nverification from single functions to more complex data structure modules in\nVerus. VeriStruct employs a planner module to orchestrate the systematic\ngeneration of abstractions, type invariants, specifications, and proof code. To\naddress the challenge that LLMs often misunderstand Verus' annotation syntax\nand verification-specific semantics, VeriStruct embeds syntax guidance within\nprompts and includes a repair stage to automatically correct annotation errors.\nIn an evaluation on eleven Rust data structure modules, VeriStruct succeeds on\nten of the eleven, successfully verifying 128 out of 129 functions (99.2%) in\ntotal. These results represent an important step toward the goal of automatic\nAI-assisted formal verification.", "AI": {"tldr": "VeriStruct\u662f\u4e00\u4e2a\u6269\u5c55AI\u8f85\u52a9\u81ea\u52a8\u9a8c\u8bc1\u7684\u6846\u67b6\uff0c\u4ece\u5355\u51fd\u6570\u9a8c\u8bc1\u6269\u5c55\u5230Verus\u4e2d\u7684\u590d\u6742\u6570\u636e\u7ed3\u6784\u6a21\u5757\u9a8c\u8bc1\uff0c\u901a\u8fc7\u89c4\u5212\u5668\u6a21\u5757\u7cfb\u7edf\u751f\u6210\u62bd\u8c61\u3001\u7c7b\u578b\u4e0d\u53d8\u91cf\u3001\u89c4\u8303\u548c\u8bc1\u660e\u4ee3\u7801\u3002", "motivation": "\u89e3\u51b3LLMs\u5728\u7406\u89e3Verus\u6ce8\u89e3\u8bed\u6cd5\u548c\u9a8c\u8bc1\u7279\u5b9a\u8bed\u4e49\u65f6\u7ecf\u5e38\u51fa\u9519\u7684\u95ee\u9898\uff0c\u5c06AI\u8f85\u52a9\u9a8c\u8bc1\u4ece\u5355\u51fd\u6570\u6269\u5c55\u5230\u590d\u6742\u6570\u636e\u7ed3\u6784\u6a21\u5757\u3002", "method": "\u4f7f\u7528\u89c4\u5212\u5668\u6a21\u5757\u534f\u8c03\u751f\u6210\u62bd\u8c61\u3001\u7c7b\u578b\u4e0d\u53d8\u91cf\u3001\u89c4\u8303\u548c\u8bc1\u660e\u4ee3\u7801\uff1b\u5728\u63d0\u793a\u4e2d\u5d4c\u5165\u8bed\u6cd5\u6307\u5bfc\uff1b\u5305\u542b\u4fee\u590d\u9636\u6bb5\u81ea\u52a8\u7ea0\u6b63\u6ce8\u89e3\u9519\u8bef\u3002", "result": "\u572811\u4e2aRust\u6570\u636e\u7ed3\u6784\u6a21\u5757\u8bc4\u4f30\u4e2d\uff0c\u6210\u529f\u9a8c\u8bc1\u4e8610\u4e2a\u6a21\u5757\uff0c\u603b\u5171\u9a8c\u8bc1\u4e86128/129\u4e2a\u51fd\u6570\uff0899.2%\u6210\u529f\u7387\uff09\u3002", "conclusion": "\u8fd9\u662f\u5b9e\u73b0\u81ea\u52a8AI\u8f85\u52a9\u5f62\u5f0f\u9a8c\u8bc1\u76ee\u6807\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2510.24807", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24807", "abs": "https://arxiv.org/abs/2510.24807", "authors": ["Ziyao Cui", "Minxing Zhang", "Jian Pei"], "title": "Learning to Attack: Uncovering Privacy Risks in Sequential Data Releases", "comment": null, "summary": "Privacy concerns have become increasingly critical in modern AI and data\nscience applications, where sensitive information is collected, analyzed, and\nshared across diverse domains such as healthcare, finance, and mobility. While\nprior research has focused on protecting privacy in a single data release, many\nreal-world systems operate under sequential or continuous data publishing,\nwhere the same or related data are released over time. Such sequential\ndisclosures introduce new vulnerabilities, as temporal correlations across\nreleases may enable adversaries to infer sensitive information that remains\nhidden in any individual release. In this paper, we investigate whether an\nattacker can compromise privacy in sequential data releases by exploiting\ndependencies between consecutive publications, even when each individual\nrelease satisfies standard privacy guarantees. To this end, we propose a novel\nattack model that captures these sequential dependencies by integrating a\nHidden Markov Model with a reinforcement learning-based bi-directional\ninference mechanism. This enables the attacker to leverage both earlier and\nlater observations in the sequence to infer private information. We instantiate\nour framework in the context of trajectory data, demonstrating how an adversary\ncan recover sensitive locations from sequential mobility datasets. Extensive\nexperiments on Geolife, Porto Taxi, and SynMob datasets show that our model\nconsistently outperforms baseline approaches that treat each release\nindependently. The results reveal a fundamental privacy risk inherent to\nsequential data publishing, where individually protected releases can\ncollectively leak sensitive information when analyzed temporally. These\nfindings underscore the need for new privacy-preserving frameworks that\nexplicitly model temporal dependencies, such as time-aware differential privacy\nor sequential data obfuscation strategies.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5e8f\u5217\u6570\u636e\u53d1\u5e03\u4e2d\u7684\u9690\u79c1\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u53cc\u5411\u63a8\u7406\u653b\u51fb\u6a21\u578b\uff0c\u80fd\u591f\u5229\u7528\u65f6\u95f4\u76f8\u5173\u6027\u4ece\u770b\u4f3c\u72ec\u7acb\u7684\u9690\u79c1\u4fdd\u62a4\u6570\u636e\u53d1\u5e03\u4e2d\u63a8\u65ad\u654f\u611f\u4fe1\u606f\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u8bb8\u591a\u7cfb\u7edf\u91c7\u7528\u5e8f\u5217\u6216\u8fde\u7eed\u6570\u636e\u53d1\u5e03\u65b9\u5f0f\uff0c\u867d\u7136\u5355\u4e2a\u53d1\u5e03\u6ee1\u8db3\u9690\u79c1\u4fdd\u62a4\u6807\u51c6\uff0c\u4f46\u65f6\u95f4\u76f8\u5173\u6027\u53ef\u80fd\u8ba9\u653b\u51fb\u8005\u901a\u8fc7\u5206\u6790\u591a\u4e2a\u53d1\u5e03\u6765\u63a8\u65ad\u654f\u611f\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u653b\u51fb\u6a21\u578b\uff0c\u5c06\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u4e0e\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u53cc\u5411\u63a8\u7406\u673a\u5236\u76f8\u7ed3\u5408\uff0c\u4f7f\u653b\u51fb\u8005\u80fd\u591f\u5229\u7528\u5e8f\u5217\u4e2d\u524d\u540e\u89c2\u6d4b\u6765\u63a8\u65ad\u79c1\u6709\u4fe1\u606f\u3002", "result": "\u5728Geolife\u3001Porto Taxi\u548cSynMob\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u59cb\u7ec8\u4f18\u4e8e\u5c06\u6bcf\u4e2a\u53d1\u5e03\u89c6\u4e3a\u72ec\u7acb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5e8f\u5217\u6570\u636e\u53d1\u5e03\u7684\u57fa\u672c\u9690\u79c1\u98ce\u9669\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u9700\u8981\u5f00\u53d1\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u5982\u65f6\u95f4\u611f\u77e5\u5dee\u5206\u9690\u79c1\u6216\u5e8f\u5217\u6570\u636e\u6df7\u6dc6\u7b56\u7565\uff0c\u4ee5\u660e\u786e\u5efa\u6a21\u65f6\u95f4\u4f9d\u8d56\u6027\u3002"}}
{"id": "2510.24832", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24832", "abs": "https://arxiv.org/abs/2510.24832", "authors": ["Hong Wang", "Zhezheng Hao", "Jian Luo", "Chenxing Wei", "Yao Shu", "Lei Liu", "Qiang Lin", "Hande Dong", "Jiawei Chen"], "title": "Scheduling Your LLM Reinforcement Learning with Reasoning Trees", "comment": null, "summary": "Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large\nLanguage Models (LLMs) can be conceptualized as progressively editing a query's\n`Reasoning Tree'. This process involves exploring nodes (tokens) and\ndynamically modifying the model's policy at each node. When combined with data\nscheduling, this process yields further gains in data efficiency and accuracy.\nHowever, existing RLVR data scheduling methods typically rely on path-based\nmetrics to rank queries, overlooking the reasoning tree structures of these\nqueries. In this paper, we introduce a novel metric, namely Reasoning Score\n(r-score), which measures the query's learning difficulty based on the\nstructure of its reasoning tree. Based on the r-score, we propose the Reasoning\nTree Schedule (Re-Schedule), a scheduling algorithm that constructs a\ncurriculum progressing from structurally simple (high r-score) to complex (low\nr-score) queries. Experiments on six math-reasoning benchmarks show that\nRe-Schedule significantly improves average accuracy, achieving gains of up to\n3.2%. These strong results validate our approach and demonstrate that a\nstructural understanding of the reasoning tree provides a more powerful and\nprincipled foundation for RLVR data scheduling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a8\u7406\u6811\u7ed3\u6784\u7684\u65b0\u8c03\u5ea6\u65b9\u6cd5Re-Schedule\uff0c\u901a\u8fc7r-score\u6307\u6807\u8861\u91cf\u67e5\u8be2\u7684\u5b66\u4e60\u96be\u5ea6\uff0c\u5728\u516d\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe3.2%\u3002", "motivation": "\u73b0\u6709\u7684RLVR\u6570\u636e\u8c03\u5ea6\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u57fa\u4e8e\u8def\u5f84\u7684\u6307\u6807\u6765\u6392\u5e8f\u67e5\u8be2\uff0c\u5ffd\u7565\u4e86\u8fd9\u4e9b\u67e5\u8be2\u7684\u63a8\u7406\u6811\u7ed3\u6784\uff0c\u5bfc\u81f4\u8c03\u5ea6\u6548\u679c\u53d7\u9650\u3002", "method": "\u5f15\u5165\u63a8\u7406\u5206\u6570(r-score)\u6307\u6807\uff0c\u57fa\u4e8e\u63a8\u7406\u6811\u7ed3\u6784\u8861\u91cf\u67e5\u8be2\u7684\u5b66\u4e60\u96be\u5ea6\uff1b\u63d0\u51fa\u63a8\u7406\u6811\u8c03\u5ea6(Re-Schedule)\u7b97\u6cd5\uff0c\u6784\u5efa\u4ece\u7ed3\u6784\u7b80\u5355(\u9ad8r-score)\u5230\u590d\u6742(\u4f4er-score)\u67e5\u8be2\u7684\u8bfe\u7a0b\u5b66\u4e60\u8fdb\u5ea6\u3002", "result": "\u5728\u516d\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRe-Schedule\u663e\u8457\u63d0\u9ad8\u4e86\u5e73\u5747\u51c6\u786e\u7387\uff0c\u589e\u76ca\u9ad8\u8fbe3.2%\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u63a8\u7406\u6811\u7ed3\u6784\u7684\u7406\u89e3\u4e3aRLVR\u6570\u636e\u8c03\u5ea6\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u548c\u539f\u5219\u6027\u7684\u57fa\u7840\u3002"}}
{"id": "2510.25016", "categories": ["cs.SE", "cs.AI", "cs.HC", "cs.LG", "68T07, 68N30", "D.2.1; I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.25016", "abs": "https://arxiv.org/abs/2510.25016", "authors": ["Mateen Ahmed Abbasi", "Petri Ihantola", "Tommi Mikkonen", "Niko M\u00e4kitalo"], "title": "Towards Human-AI Synergy in Requirements Engineering: A Framework and Preliminary Study", "comment": "Accepted at the 2025 Sixth International Conference on Intelligent\n  Data Science Technologies and Applications (IDSTA 2025),8 pages, 4 figures.\n  Published in IEEE", "summary": "The future of Requirements Engineering (RE) is increasingly driven by\nartificial intelligence (AI), reshaping how we elicit, analyze, and validate\nrequirements. Traditional RE is based on labor-intensive manual processes prone\nto errors and complexity. AI-powered approaches, specifically large language\nmodels (LLMs), natural language processing (NLP), and generative AI, offer\ntransformative solutions and reduce inefficiencies. However, the use of AI in\nRE also brings challenges like algorithmic bias, lack of explainability, and\nethical concerns related to automation. To address these issues, this study\nintroduces the Human-AI RE Synergy Model (HARE-SM), a conceptual framework that\nintegrates AI-driven analysis with human oversight to improve requirements\nelicitation, analysis, and validation. The model emphasizes ethical AI use\nthrough transparency, explainability, and bias mitigation. We outline a\nmulti-phase research methodology focused on preparing RE datasets, fine-tuning\nAI models, and designing collaborative human-AI workflows. This preliminary\nstudy presents the conceptual framework and early-stage prototype\nimplementation, establishing a research agenda and practical design direction\nfor applying intelligent data science techniques to semi-structured and\nunstructured RE data in collaborative environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Human-AI RE\u534f\u540c\u6a21\u578b(HARE-SM)\uff0c\u5c06AI\u9a71\u52a8\u5206\u6790\u4e0e\u4eba\u7c7b\u76d1\u7763\u7ed3\u5408\uff0c\u4ee5\u6539\u8fdb\u9700\u6c42\u5de5\u7a0b\u7684\u83b7\u53d6\u3001\u5206\u6790\u548c\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u540c\u65f6\u5f3a\u8c03\u4f26\u7406AI\u4f7f\u7528\u3002", "motivation": "\u4f20\u7edf\u9700\u6c42\u5de5\u7a0b\u4f9d\u8d56\u52b3\u52a8\u5bc6\u96c6\u578b\u4eba\u5de5\u6d41\u7a0b\uff0c\u5bb9\u6613\u51fa\u9519\u4e14\u590d\u6742\u3002AI\u65b9\u6cd5\uff08\u7279\u522b\u662fLLM\u3001NLP\u548c\u751f\u6210\u5f0fAI\uff09\u80fd\u63d0\u4f9b\u53d8\u9769\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u540c\u65f6\u4e5f\u5e26\u6765\u7b97\u6cd5\u504f\u89c1\u3001\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u4f26\u7406\u95ee\u9898\u7b49\u6311\u6218\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u7814\u7a76\u65b9\u6cd5\uff0c\u5305\u62ec\u51c6\u5907\u9700\u6c42\u5de5\u7a0b\u6570\u636e\u96c6\u3001\u5fae\u8c03AI\u6a21\u578b\u3001\u8bbe\u8ba1\u534f\u4f5c\u5f0f\u4eba\u673a\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u63d0\u51fa\u4e86HARE-SM\u6982\u5ff5\u6846\u67b6\u548c\u65e9\u671f\u539f\u578b\u5b9e\u73b0\u3002", "result": "\u5efa\u7acb\u4e86\u7814\u7a76\u8bae\u7a0b\u548c\u5b9e\u8df5\u8bbe\u8ba1\u65b9\u5411\uff0c\u4e3a\u5728\u534f\u4f5c\u73af\u5883\u4e2d\u5e94\u7528\u667a\u80fd\u6570\u636e\u79d1\u5b66\u6280\u672f\u5904\u7406\u534a\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u9700\u6c42\u5de5\u7a0b\u6570\u636e\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "HARE-SM\u6846\u67b6\u901a\u8fc7\u6574\u5408AI\u5206\u6790\u4e0e\u4eba\u7c7b\u76d1\u7763\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9AI\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u5e94\u7528\u7684\u6311\u6218\uff0c\u5f3a\u8c03\u900f\u660e\u5ea6\u3001\u53ef\u89e3\u91ca\u6027\u548c\u504f\u89c1\u7f13\u89e3\u7684\u4f26\u7406AI\u4f7f\u7528\u3002"}}
{"id": "2510.24920", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24920", "abs": "https://arxiv.org/abs/2510.24920", "authors": ["Elizabeth Lin", "Jonah Ghebremichael", "William Enck", "Yasemin Acar", "Michel Cukier", "Alexandros Kapravelos", "Christian Kastner", "Laurie Williams"], "title": "S3C2 Summit 2025-03: Industry Secure Supply Chain Summit", "comment": null, "summary": "Software supply chains, while providing immense economic and software\ndevelopment value, are only as strong as their weakest link. Over the past\nseveral years, there has been an exponential increase in cyberattacks\nspecifically targeting vulnerable links in critical software supply chains.\nThese attacks disrupt the day-to-day functioning and threaten the security of\nnearly everyone on the internet, from billion-dollar companies and government\nagencies to hobbyist open-source developers. The ever-evolving threat of\nsoftware supply chain attacks has garnered interest from both the software\nindustry and US government in improving software supply chain security. On\nThursday, March 6th, 2025, four researchers from the NSF-backed Secure Software\nSupply Chain Center (S3C2) conducted a Secure Software Supply Chain Summit with\na diverse set of 18 practitioners from 17 organizations. The goals of the\nSummit were: (1) to enable sharing between participants from different\nindustries regarding practical experiences and challenges with software supply\nchain security; (2) to help form new collaborations; and (3) to learn about the\nchallenges facing participants to inform our future research directions. The\nsummit consisted of discussions of six topics relevant to the government\nagencies represented, including software bill of materials (SBOMs); compliance;\nmalicious commits; build infrastructure; culture; and large language models\n(LLMs) and security. For each topic of discussion, we presented a list of\nquestions to participants to spark conversation. In this report, we provide a\nsummary of the summit. The open questions and challenges that remained after\neach topic are listed at the end of each topic's section, and the initial\ndiscussion questions for each topic are provided in the appendix.", "AI": {"tldr": "\u672c\u6587\u62a5\u544a\u4e862025\u5e743\u67086\u65e5\u4e3e\u884c\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u5cf0\u4f1a\uff0c\u6c47\u96c6\u4e86\u6765\u81ea17\u4e2a\u7ec4\u7ec7\u768418\u540d\u4ece\u4e1a\u8005\uff0c\u8ba8\u8bba\u4e86SBOM\u3001\u5408\u89c4\u6027\u3001\u6076\u610f\u63d0\u4ea4\u3001\u6784\u5efa\u57fa\u7840\u8bbe\u65bd\u3001\u6587\u5316\u4ee5\u53caLLM\u4e0e\u5b89\u5168\u7b49\u516d\u4e2a\u5173\u952e\u4e3b\u9898\u3002", "motivation": "\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u5a01\u80c1\u5230\u4ece\u5927\u578b\u4f01\u4e1a\u5230\u5f00\u6e90\u5f00\u53d1\u8005\u7684\u6240\u6709\u4e92\u8054\u7f51\u7528\u6237\u3002\u4e3a\u5e94\u5bf9\u8fd9\u4e00\u5a01\u80c1\uff0c\u9700\u8981\u884c\u4e1a\u548c\u653f\u5e9c\u5171\u540c\u52aa\u529b\u63d0\u5347\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u3002", "method": "\u901a\u8fc7\u4e3e\u529e\u5b89\u5168\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5cf0\u4f1a\uff0c\u6c47\u96c6\u6765\u81ea\u4e0d\u540c\u884c\u4e1a\u7684\u4ece\u4e1a\u8005\u8fdb\u884c\u7ecf\u9a8c\u5206\u4eab\u548c\u6311\u6218\u8ba8\u8bba\uff0c\u56f4\u7ed5\u516d\u4e2a\u6838\u5fc3\u4e3b\u9898\u5c55\u5f00\u5bf9\u8bdd\u3002", "result": "\u5cf0\u4f1a\u4fc3\u8fdb\u4e86\u8de8\u884c\u4e1a\u77e5\u8bc6\u5171\u4eab\uff0c\u5f62\u6210\u4e86\u65b0\u7684\u5408\u4f5c\u673a\u4f1a\uff0c\u5e76\u8bc6\u522b\u4e86\u5404\u4e3b\u9898\u9886\u57df\u9762\u4e34\u7684\u5f00\u653e\u95ee\u9898\u548c\u6311\u6218\u3002", "conclusion": "\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u9700\u8981\u6301\u7eed\u7684\u591a\u65b9\u534f\u4f5c\uff0c\u5cf0\u4f1a\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u5e76\u4e3a\u89e3\u51b3\u8fd9\u4e00\u590d\u6742\u95ee\u9898\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.25005", "categories": ["cs.AI", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25005", "abs": "https://arxiv.org/abs/2510.25005", "authors": ["Saptarshi Saha", "Dhruv Vansraj Rathore", "Utpal Garain"], "title": "Cyclic Counterfactuals under Shift-Scale Interventions", "comment": "Accepted at NeurIPS 2025", "summary": "Most counterfactual inference frameworks traditionally assume acyclic\nstructural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However,\nmany real-world systems (e.g. biological systems) contain feedback loops or\ncyclic dependencies that violate acyclicity. In this work, we study\ncounterfactual inference in cyclic SCMs under shift-scale interventions, i.e.,\nsoft, policy-style changes that rescale and/or shift a variable's mechanism.", "AI": {"tldr": "\u7814\u7a76\u5faa\u73af\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4e2d\u7684\u53cd\u4e8b\u5b9e\u63a8\u65ad\uff0c\u5173\u6ce8\u79fb\u4f4d-\u5c3a\u5ea6\u5e72\u9884\u4e0b\u7684\u653f\u7b56\u5f0f\u53d8\u5316", "motivation": "\u4f20\u7edf\u53cd\u4e8b\u5b9e\u63a8\u65ad\u6846\u67b6\u5047\u8bbe\u65e0\u73af\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff0c\u4f46\u73b0\u5b9e\u7cfb\u7edf\uff08\u5982\u751f\u7269\u7cfb\u7edf\uff09\u5e38\u5305\u542b\u53cd\u9988\u5faa\u73af\u6216\u5faa\u73af\u4f9d\u8d56\uff0c\u8fdd\u53cd\u65e0\u73af\u6027\u5047\u8bbe", "method": "\u5728\u5faa\u73af\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4e2d\u7814\u7a76\u53cd\u4e8b\u5b9e\u63a8\u65ad\uff0c\u7279\u522b\u5173\u6ce8\u79fb\u4f4d-\u5c3a\u5ea6\u5e72\u9884\uff08\u5373\u8f6f\u6027\u3001\u653f\u7b56\u5f0f\u53d8\u5316\uff0c\u91cd\u65b0\u7f29\u653e\u548c/\u6216\u79fb\u52a8\u53d8\u91cf\u7684\u673a\u5236\uff09", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u5728\u5faa\u73af\u7cfb\u7edf\u4e2d\u5904\u7406\u53cd\u4e8b\u5b9e\u63a8\u65ad\u7684\u65b9\u6cd5\uff0c\u4f46\u6458\u8981\u4e2d\u672a\u63d0\u4f9b\u5177\u4f53\u7ed3\u679c\u6570\u636e", "conclusion": "\u9700\u8981\u6269\u5c55\u53cd\u4e8b\u5b9e\u63a8\u65ad\u6846\u67b6\u4ee5\u5904\u7406\u5305\u542b\u5faa\u73af\u4f9d\u8d56\u7684\u73b0\u5b9e\u7cfb\u7edf\uff0c\u79fb\u4f4d-\u5c3a\u5ea6\u5e72\u9884\u4e3a\u8fd9\u7c7b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5efa\u6a21\u65b9\u6cd5"}}
{"id": "2510.25039", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25039", "abs": "https://arxiv.org/abs/2510.25039", "authors": ["Amanda Dsouza", "Harit Vishwakarma", "Zhengyang Qi", "Justin Bauer", "Derek Pham", "Thomas Walshe", "Armin Parchami", "Frederic Sala", "Paroma Varma"], "title": "Automating Benchmark Design", "comment": null, "summary": "The rapid progress and widespread deployment of LLMs and LLM-powered agents\nhas outpaced our ability to evaluate them. Hand-crafted, static benchmarks are\nthe primary tool for assessing model capabilities, but these quickly become\nsaturated. In contrast, dynamic benchmarks evolve alongside the models they\nevaluate, but are expensive to create and continuously update. To address these\nchallenges, we develop BeTaL (Benchmark Tuning with an LLM-in-the-loop), a\nframework that leverages environment design principles to automate the process\nof dynamic benchmark design. BeTaL works by parameterizing key design choices\nin base benchmark templates and uses LLMs to reason through the resulting\nparameter space to obtain target properties (such as difficulty and realism) in\na cost-efficient manner. We validate this approach on its ability to create\nbenchmarks with desired difficulty levels. Using BeTaL, we create two new\nbenchmarks and extend a popular agentic benchmark $\\tau$-bench. Extensive\nevaluation on these three tasks and multiple target difficulty levels shows\nthat BeTaL produces benchmarks much closer to the desired difficulty, with\naverage deviations ranging from 5.3% to 13.2% -- a 2-4x improvement over the\nbaselines.", "AI": {"tldr": "BeTaL\u662f\u4e00\u4e2a\u5229\u7528LLM\u81ea\u52a8\u5316\u8bbe\u8ba1\u52a8\u6001\u57fa\u51c6\u6d4b\u8bd5\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u57fa\u51c6\u6a21\u677f\u5e76\u4f7f\u7528LLM\u63a8\u7406\u6765\u83b7\u5f97\u76ee\u6807\u5c5e\u6027\uff08\u5982\u96be\u5ea6\u548c\u771f\u5b9e\u6027\uff09\uff0c\u76f8\u6bd4\u9759\u6001\u57fa\u51c6\u67092-4\u500d\u7684\u6539\u8fdb\u3002", "motivation": "\u5f53\u524dLLM\u548cLLM\u9a71\u52a8\u667a\u80fd\u4f53\u7684\u5feb\u901f\u53d1\u5c55\u8d85\u51fa\u4e86\u6211\u4eec\u7684\u8bc4\u4f30\u80fd\u529b\uff0c\u624b\u5de5\u5236\u4f5c\u7684\u9759\u6001\u57fa\u51c6\u5bb9\u6613\u9971\u548c\uff0c\u800c\u52a8\u6001\u57fa\u51c6\u867d\u7136\u80fd\u968f\u6a21\u578b\u8fdb\u5316\u4f46\u521b\u5efa\u548c\u66f4\u65b0\u6210\u672c\u9ad8\u6602\u3002", "method": "BeTaL\u6846\u67b6\u901a\u8fc7\u53c2\u6570\u5316\u57fa\u51c6\u6a21\u677f\u7684\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\uff0c\u4f7f\u7528LLM\u5728\u53c2\u6570\u7a7a\u95f4\u4e2d\u8fdb\u884c\u63a8\u7406\uff0c\u4ee5\u6210\u672c\u6548\u76ca\u7684\u65b9\u5f0f\u83b7\u5f97\u76ee\u6807\u5c5e\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u4efb\u52a1\u548c\u591a\u4e2a\u76ee\u6807\u96be\u5ea6\u7ea7\u522b\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cBeTaL\u4ea7\u751f\u7684\u57fa\u51c6\u4e0e\u671f\u671b\u96be\u5ea6\u7684\u5e73\u5747\u504f\u5dee\u4e3a5.3%\u523013.2%\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u67092-4\u500d\u7684\u6539\u8fdb\u3002", "conclusion": "BeTaL\u80fd\u591f\u6709\u6548\u81ea\u52a8\u5316\u52a8\u6001\u57fa\u51c6\u8bbe\u8ba1\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u9ad8\u57fa\u51c6\u6d4b\u8bd5\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2510.24976", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24976", "abs": "https://arxiv.org/abs/2510.24976", "authors": ["Banafsheh Saber Latibari", "Najmeh Nazari", "Hossein Sayadi", "Houman Homayoun", "Abhijit Mahalanobis"], "title": "Hammering the Diagnosis: Rowhammer-Induced Stealthy Trojan Attacks on ViT-Based Medical Imaging", "comment": "Accepted, ICCD 2025", "summary": "Vision Transformers (ViTs) have emerged as powerful architectures in medical\nimage analysis, excelling in tasks such as disease detection, segmentation, and\nclassification. However, their reliance on large, attention-driven models makes\nthem vulnerable to hardware-level attacks. In this paper, we propose a novel\nthreat model referred to as Med-Hammer that combines the Rowhammer hardware\nfault injection with neural Trojan attacks to compromise the integrity of\nViT-based medical imaging systems. Specifically, we demonstrate how malicious\nbit flips induced via Rowhammer can trigger implanted neural Trojans, leading\nto targeted misclassification or suppression of critical diagnoses (e.g.,\ntumors or lesions) in medical scans. Through extensive experiments on benchmark\nmedical imaging datasets such as ISIC, Brain Tumor, and MedMNIST, we show that\nsuch attacks can remain stealthy while achieving high attack success rates\nabout 82.51% and 92.56% in MobileViT and SwinTransformer, respectively. We\nfurther investigate how architectural properties, such as model sparsity,\nattention weight distribution, and the number of features of the layer, impact\nattack effectiveness. Our findings highlight a critical and underexplored\nintersection between hardware-level faults and deep learning security in\nhealthcare applications, underscoring the urgent need for robust defenses\nspanning both model architectures and underlying hardware platforms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMed-Hammer\u7684\u65b0\u578b\u5a01\u80c1\u6a21\u578b\uff0c\u7ed3\u5408Rowhammer\u786c\u4ef6\u6545\u969c\u6ce8\u5165\u548c\u795e\u7ecf\u6728\u9a6c\u653b\u51fb\uff0c\u9488\u5bf9\u533b\u7597\u5f71\u50cf\u4e2d\u7684Vision Transformers\u7cfb\u7edf\u8fdb\u884c\u653b\u51fb\u3002", "motivation": "Vision Transformers\u5728\u533b\u7597\u5f71\u50cf\u5206\u6790\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u5927\u578b\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u786c\u4ef6\u7ea7\u653b\u51fb\u3002\u7814\u7a76\u65e8\u5728\u63ed\u793a\u786c\u4ef6\u6545\u969c\u4e0e\u6df1\u5ea6\u5b66\u4e60\u5b89\u5168\u5728\u533b\u7597\u5e94\u7528\u4e2d\u7684\u4ea4\u53c9\u5a01\u80c1\u3002", "method": "\u901a\u8fc7Rowhammer\u8bf1\u5bfc\u6076\u610f\u6bd4\u7279\u7ffb\u8f6c\u6765\u89e6\u53d1\u690d\u5165\u7684\u795e\u7ecf\u6728\u9a6c\uff0c\u5bfc\u81f4\u533b\u7597\u626b\u63cf\u4e2d\u7684\u5b9a\u5411\u8bef\u5206\u7c7b\u6216\u5173\u952e\u8bca\u65ad\uff08\u5982\u80bf\u7624\uff09\u88ab\u6291\u5236\u3002\u5728ISIC\u3001Brain Tumor\u548cMedMNIST\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u653b\u51fb\u5728MobileViT\u548cSwinTransformer\u4e2d\u5206\u522b\u8fbe\u523082.51%\u548c92.56%\u7684\u9ad8\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u9690\u853d\u6027\u3002\u6a21\u578b\u7a00\u758f\u6027\u3001\u6ce8\u610f\u529b\u6743\u91cd\u5206\u5e03\u548c\u5c42\u7279\u5f81\u6570\u91cf\u7b49\u67b6\u6784\u7279\u6027\u5f71\u54cd\u653b\u51fb\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u533b\u7597\u5e94\u7528\u4e2d\u786c\u4ef6\u7ea7\u6545\u969c\u4e0e\u6df1\u5ea6\u5b66\u4e60\u5b89\u5168\u7684\u5173\u952e\u4ea4\u53c9\u70b9\uff0c\u5f3a\u8c03\u9700\u8981\u5728\u6a21\u578b\u67b6\u6784\u548c\u5e95\u5c42\u786c\u4ef6\u5e73\u53f0\u4e24\u65b9\u9762\u5efa\u7acb\u9c81\u68d2\u9632\u5fa1\u7684\u7d27\u8feb\u6027\u3002"}}
{"id": "2510.25007", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25007", "abs": "https://arxiv.org/abs/2510.25007", "authors": ["Islam Nassar", "Yang Lin", "Yuan Jin", "Rongxin Zhu", "Chang Wei Tan", "Zenan Zhai", "Nitika Mathur", "Thanh Tien Vu", "Xu Zhong", "Long Duong", "Yuan-Fang Li"], "title": "Taming the Real-world Complexities in CPT E/M Coding with Large Language Models", "comment": "EMNLP 2025 Industry Track", "summary": "Evaluation and Management (E/M) coding, under the Current Procedural\nTerminology (CPT) taxonomy, documents medical services provided to patients by\nphysicians. Used primarily for billing purposes, it is in physicians' best\ninterest to provide accurate CPT E/M codes. %While important, it is an\nauxiliary task that adds to physicians' documentation burden. Automating this\ncoding task will help alleviate physicians' documentation burden, improve\nbilling efficiency, and ultimately enable better patient care. However, a\nnumber of real-world complexities have made E/M encoding automation a\nchallenging task. In this paper, we elaborate some of the key complexities and\npresent ProFees, our LLM-based framework that tackles them, followed by a\nsystematic evaluation. On an expert-curated real-world dataset, ProFees\nachieves an increase in coding accuracy of more than 36\\% over a commercial CPT\nE/M coding system and almost 5\\% over our strongest single-prompt baseline,\ndemonstrating its effectiveness in addressing the real-world complexities.", "AI": {"tldr": "ProFees\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u533b\u7597\u8bc4\u4f30\u548c\u7ba1\u7406(E/M)\u7f16\u7801\u4efb\u52a1\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6bd4\u5546\u4e1a\u7cfb\u7edf\u63d0\u9ad836%\u4ee5\u4e0a\u7684\u7f16\u7801\u51c6\u786e\u7387\u3002", "motivation": "\u81ea\u52a8\u5316E/M\u7f16\u7801\u53ef\u4ee5\u51cf\u8f7b\u533b\u751f\u7684\u6587\u6863\u8d1f\u62c5\uff0c\u63d0\u9ad8\u8ba1\u8d39\u6548\u7387\uff0c\u6700\u7ec8\u5b9e\u73b0\u66f4\u597d\u7684\u60a3\u8005\u62a4\u7406\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eLLM\u7684ProFees\u6846\u67b6\u6765\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u590d\u6742\u6027\u95ee\u9898\uff0c\u5305\u62ec\u591a\u63d0\u793a\u7b56\u7565\u3002", "result": "\u5728\u4e13\u5bb6\u7b56\u5212\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cProFees\u6bd4\u5546\u4e1aCPT E/M\u7f16\u7801\u7cfb\u7edf\u63d0\u9ad836%\u4ee5\u4e0a\u7684\u51c6\u786e\u7387\uff0c\u6bd4\u6700\u5f3a\u7684\u5355\u63d0\u793a\u57fa\u7ebf\u63d0\u9ad8\u8fd15%\u3002", "conclusion": "ProFees\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u590d\u6742\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8E/M\u7f16\u7801\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2510.25057", "categories": ["cs.SE", "K.3.2; K.6.5; K.4.1"], "pdf": "https://arxiv.org/pdf/2510.25057", "abs": "https://arxiv.org/abs/2510.25057", "authors": ["Robin Maisch", "Larissa Schmid", "Timur Sa\u011flam", "Nils Niehues"], "title": "Same Same But Different: Preventing Refactoring Attacks on Software Plagiarism Detection", "comment": "To be published at ICSE'26. 13 pages, 6 figures", "summary": "Plagiarism detection in programming education faces growing challenges due to\nincreasingly sophisticated obfuscation techniques, particularly automated\nrefactoring-based attacks. While code plagiarism detection systems used in\neducation practice are resilient against basic obfuscation, they struggle\nagainst structural modifications that preserve program behavior, especially\ncaused by refactoring-based obfuscation. This paper presents a novel and\nextensible framework that enhances state-of-the-art detectors by leveraging\ncode property graphs and graph transformations to counteract refactoring-based\nobfuscation. Our comprehensive evaluation of real-world student submissions,\nobfuscated using both algorithmic and AI-based obfuscation attacks,\ndemonstrates a significant improvement in detecting plagiarized code.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u9896\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7801\u5c5e\u6027\u56fe\u548c\u56fe\u53d8\u6362\u6765\u589e\u5f3a\u73b0\u6709\u68c0\u6d4b\u5668\uff0c\u6709\u6548\u5bf9\u6297\u91cd\u6784\u5f0f\u6df7\u6dc6\u653b\u51fb\uff0c\u663e\u8457\u63d0\u5347\u6284\u88ad\u4ee3\u7801\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u6284\u88ad\u68c0\u6d4b\u9762\u4e34\u65e5\u76ca\u590d\u6742\u7684\u6df7\u6dc6\u6280\u672f\u6311\u6218\uff0c\u7279\u522b\u662f\u81ea\u52a8\u5316\u91cd\u6784\u5f0f\u653b\u51fb\u3002\u73b0\u6709\u6559\u80b2\u5b9e\u8df5\u4e2d\u7684\u4ee3\u7801\u6284\u88ad\u68c0\u6d4b\u7cfb\u7edf\u5bf9\u57fa\u672c\u6df7\u6dc6\u6709\u62b5\u6297\u529b\uff0c\u4f46\u96be\u4ee5\u5e94\u5bf9\u4fdd\u6301\u7a0b\u5e8f\u884c\u4e3a\u7684\u7ed3\u6784\u4fee\u6539\uff0c\u5c24\u5176\u662f\u91cd\u6784\u5f0f\u6df7\u6dc6\u3002", "method": "\u5229\u7528\u4ee3\u7801\u5c5e\u6027\u56fe\u548c\u56fe\u53d8\u6362\u6784\u5efa\u65b0\u9896\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u589e\u5f3a\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\uff0c\u5bf9\u6297\u91cd\u6784\u5f0f\u6df7\u6dc6\u3002", "result": "\u5bf9\u771f\u5b9e\u5b66\u751f\u63d0\u4ea4\u4ee3\u7801\u7684\u5168\u9762\u8bc4\u4f30\u663e\u793a\uff0c\u65e0\u8bba\u662f\u7b97\u6cd5\u8fd8\u662fAI\u9a71\u52a8\u7684\u6df7\u6dc6\u653b\u51fb\uff0c\u8be5\u6846\u67b6\u90fd\u80fd\u663e\u8457\u63d0\u9ad8\u6284\u88ad\u4ee3\u7801\u7684\u68c0\u6d4b\u6548\u679c\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u91cd\u6784\u5f0f\u6df7\u6dc6\u5e26\u6765\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f16\u7a0b\u6559\u80b2\u4e2d\u6284\u88ad\u68c0\u6d4b\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2510.24985", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24985", "abs": "https://arxiv.org/abs/2510.24985", "authors": ["Najmeh Nazari", "Banafsheh Saber Latibari", "Elahe Hosseini", "Fatemeh Movafagh", "Chongzhou Fang", "Hosein Mohammadi Makrani", "Kevin Immanuel Gubbi", "Abhijit Mahalanobis", "Setareh Rafatirad", "Hossein Sayadi", "Houman Homayoun"], "title": "FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip Attack Resilience in Transformer Models", "comment": "Accepted By ICCD 2025", "summary": "Forget and Rewire (FaR) methodology has demonstrated strong resilience\nagainst Bit-Flip Attacks (BFAs) on Transformer-based models by obfuscating\ncritical parameters through dynamic rewiring of linear layers. However, the\napplication of FaR introduces non-negligible performance and memory overheads,\nprimarily due to the runtime modification of activation pathways and the lack\nof hardware-level optimization. To overcome these limitations, we propose\nFaRAccel, a novel hardware accelerator architecture implemented on FPGA,\nspecifically designed to offload and optimize FaR operations. FaRAccel\nintegrates reconfigurable logic for dynamic activation rerouting, and\nlightweight storage of rewiring configurations, enabling low-latency inference\nwith minimal energy overhead. We evaluate FaRAccel across a suite of\nTransformer models and demonstrate substantial reductions in FaR inference\nlatency and improvement in energy efficiency, while maintaining the robustness\ngains of the original FaR methodology. To the best of our knowledge, this is\nthe first hardware-accelerated defense against BFAs in Transformers,\neffectively bridging the gap between algorithmic resilience and efficient\ndeployment on real-world AI platforms.", "AI": {"tldr": "FaRAccel\u662f\u4e00\u79cd\u9488\u5bf9FaR\u65b9\u6cd5\u7684\u786c\u4ef6\u52a0\u901f\u5668\u67b6\u6784\uff0c\u901a\u8fc7FPGA\u5b9e\u73b0\u52a8\u6001\u6fc0\u6d3b\u91cd\u8def\u7531\u548c\u8f7b\u91cf\u7ea7\u5b58\u50a8\uff0c\u663e\u8457\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u80fd\u6548\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u4f4d\u7ffb\u8f6c\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\u3002", "motivation": "FaR\u65b9\u6cd5\u867d\u7136\u80fd\u6709\u6548\u9632\u5fa1\u4f4d\u7ffb\u8f6c\u653b\u51fb\uff0c\u4f46\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u548c\u5185\u5b58\u5f00\u9500\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8fd0\u884c\u65f6\u6fc0\u6d3b\u8def\u5f84\u4fee\u6539\u548c\u7f3a\u4e4f\u786c\u4ef6\u7ea7\u4f18\u5316\u3002", "method": "\u8bbe\u8ba1FaRAccel\u786c\u4ef6\u52a0\u901f\u5668\u67b6\u6784\uff0c\u96c6\u6210\u53ef\u91cd\u6784\u903b\u8f91\u7528\u4e8e\u52a8\u6001\u6fc0\u6d3b\u91cd\u8def\u7531\uff0c\u4ee5\u53ca\u8f7b\u91cf\u7ea7\u5b58\u50a8\u91cd\u8fde\u914d\u7f6e\uff0c\u5728FPGA\u4e0a\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u63a8\u7406\u3002", "result": "\u5728\u591a\u4e2aTransformer\u6a21\u578b\u4e0a\u8bc4\u4f30\u663e\u793a\uff0cFaRAccel\u663e\u8457\u964d\u4f4e\u4e86FaR\u63a8\u7406\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u4e86\u80fd\u6548\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u539f\u59cbFaR\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u589e\u76ca\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9Transformer\u4e2d\u4f4d\u7ffb\u8f6c\u653b\u51fb\u7684\u786c\u4ef6\u52a0\u901f\u9632\u5fa1\u65b9\u6848\uff0c\u6709\u6548\u5f25\u5408\u4e86\u7b97\u6cd5\u9c81\u68d2\u6027\u4e0e\u5b9e\u9645AI\u5e73\u53f0\u9ad8\u6548\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2510.25014", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25014", "abs": "https://arxiv.org/abs/2510.25014", "authors": ["Minkyung Kim", "Junsik Kim", "Woongcheol Yang", "Sangdon Park", "Sohee Bae"], "title": "Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading", "comment": "8 pages main content, 18 pages supplementary material, 4 figures", "summary": "Large Language Models (LLMs) enable dynamic game interactions but fail to\nfollow essential procedural flows in rule-governed trading systems, eroding\nplayer trust. This work resolves the core tension between the creative\nflexibility of LLMs and the procedural demands of in-game trading\n(browse-offer-review-confirm). To this end, Autoregressive State-Tracking\nPrompting (ASTP) is introduced, a methodology centered on a strategically\norchestrated prompt that compels an LLM to make its state-tracking process\nexplicit and verifiable. Instead of relying on implicit contextual\nunderstanding, ASTP tasks the LLM with identifying and reporting a predefined\nstate label from the previous turn. To ensure transactional integrity, this is\ncomplemented by a state-specific placeholder post-processing method for\naccurate price calculations. Evaluation across 300 trading dialogues\ndemonstrates >99% state compliance and 99.3% calculation precision. Notably,\nASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash)\nmatches larger models' (Gemini-2.5-Pro) performance while reducing response\ntime from 21.2s to 2.4s, establishing a practical foundation that satisfies\nboth real-time requirements and resource constraints of commercial games.", "AI": {"tldr": "\u63d0\u51fa\u4e86Autoregressive State-Tracking Prompting (ASTP)\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u72b6\u6001\u8ffd\u8e2a\u548c\u5360\u4f4d\u7b26\u540e\u5904\u7406\uff0c\u89e3\u51b3LLM\u5728\u6e38\u620f\u4ea4\u6613\u7cfb\u7edf\u4e2d\u9075\u5faa\u7a0b\u5e8f\u6d41\u7a0b\u7684\u95ee\u9898\uff0c\u5b9e\u73b0>99%\u72b6\u6001\u5408\u89c4\u6027\u548c99.3%\u8ba1\u7b97\u7cbe\u5ea6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u6e38\u620f\u4ea4\u4e92\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u65e0\u6cd5\u9075\u5faa\u89c4\u5219\u6cbb\u7406\u4ea4\u6613\u7cfb\u7edf\u7684\u57fa\u672c\u7a0b\u5e8f\u6d41\u7a0b\uff08\u6d4f\u89c8-\u62a5\u4ef7-\u5ba1\u67e5-\u786e\u8ba4\uff09\uff0c\u8fd9\u4f1a\u524a\u5f31\u73a9\u5bb6\u4fe1\u4efb\u3002", "method": "\u5f15\u5165ASTP\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u8feb\u4f7fLLM\u4f7f\u5176\u72b6\u6001\u8ffd\u8e2a\u8fc7\u7a0b\u663e\u5f0f\u5316\u548c\u53ef\u9a8c\u8bc1\uff0c\u7ed3\u5408\u72b6\u6001\u7279\u5b9a\u7684\u5360\u4f4d\u7b26\u540e\u5904\u7406\u65b9\u6cd5\u786e\u4fdd\u4ea4\u6613\u5b8c\u6574\u6027\u3002", "result": "\u5728300\u4e2a\u4ea4\u6613\u5bf9\u8bdd\u8bc4\u4f30\u4e2d\uff0c\u5b9e\u73b0>99%\u72b6\u6001\u5408\u89c4\u6027\u548c99.3%\u8ba1\u7b97\u7cbe\u5ea6\u3002\u5c0f\u6a21\u578b(Gemini-2.5-Flash)\u901a\u8fc7ASTP\u5339\u914d\u5927\u6a21\u578b\u6027\u80fd\uff0c\u54cd\u5e94\u65f6\u95f4\u4ece21.2\u79d2\u964d\u81f32.4\u79d2\u3002", "conclusion": "ASTP\u4e3a\u5546\u4e1a\u6e38\u620f\u5efa\u7acb\u4e86\u5b9e\u7528\u57fa\u7840\uff0c\u540c\u65f6\u6ee1\u8db3\u5b9e\u65f6\u9700\u6c42\u548c\u8d44\u6e90\u7ea6\u675f\uff0c\u89e3\u51b3\u4e86LLM\u521b\u9020\u6027\u7075\u6d3b\u6027\u4e0e\u7a0b\u5e8f\u6027\u9700\u6c42\u4e4b\u95f4\u7684\u6838\u5fc3\u77db\u76fe\u3002"}}
{"id": "2510.25103", "categories": ["cs.SE", "D.2.4"], "pdf": "https://arxiv.org/pdf/2510.25103", "abs": "https://arxiv.org/abs/2510.25103", "authors": ["Minghai Lu", "Zhe Zhou", "Danning Xie", "Songlin Jia", "Benjamin Delaware", "Tianyi Zhang"], "title": "Adaptive Proof Refinement with LLM-Guided Strategy Selection", "comment": "11 pages, 11 figures", "summary": "Formal verification via theorem proving enables the expressive specification\nand rigorous proof of software correctness, but it is difficult to scale due to\nthe significant manual effort and expertise required. While Large Language\nModels (LLMs) show potential in proof generation, they frequently produce\nincorrect proofs on the first attempt and require additional strategies for\niterative refinement. However, existing approaches employ fixed refinement\nstrategies and cannot dynamically choose an effective strategy based on the\nparticular issues in a generated proof, which limits their performance. To\novercome this limitation, we introduce Adapt, a novel proof refinement\nframework that leverages an LLM-guided decision-maker to dynamically select a\nsuitable refinement strategy according to the state of the proof assistant and\navailable context of an incorrect proof. We evaluate Adapt on two benchmarks\nagainst four existing methods and find that it significantly outperforms the\nbest baseline on both by proving 16.63% and 18.58% more theorems, respectively.\nFurthermore, we demonstrate Adapt's generalizability by evaluating it across\nfive different LLMs. We also conduct ablation studies to measure the\ncontribution of each component and compare the trade-offs of alternative\ndecision-maker designs.", "AI": {"tldr": "Adapt\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u52a8\u6001\u8bc1\u660e\u7cbe\u70bc\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u9009\u62e9\u7b56\u7565\u6765\u6539\u8fdb\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\uff0c\u76f8\u6bd4\u56fa\u5b9a\u7b56\u7565\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8bc1\u660e\u6210\u529f\u7387", "motivation": "\u73b0\u6709LLM\u8bc1\u660e\u751f\u6210\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u7cbe\u70bc\u7b56\u7565\uff0c\u65e0\u6cd5\u6839\u636e\u5177\u4f53\u8bc1\u660e\u95ee\u9898\u52a8\u6001\u9009\u62e9\u6709\u6548\u7b56\u7565\uff0c\u9650\u5236\u4e86\u6027\u80fd", "method": "\u5229\u7528LLM\u5f15\u5bfc\u7684\u51b3\u7b56\u5668\uff0c\u6839\u636e\u8bc1\u660e\u52a9\u624b\u72b6\u6001\u548c\u9519\u8bef\u8bc1\u660e\u4e0a\u4e0b\u6587\u52a8\u6001\u9009\u62e9\u5408\u9002\u7cbe\u70bc\u7b56\u7565", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u6bd4\u6700\u4f73\u57fa\u7ebf\u591a\u8bc1\u660e\u4e8616.63%\u548c18.58%\u7684\u5b9a\u7406\uff0c\u5728\u4e94\u4e2a\u4e0d\u540cLLM\u4e0a\u5747\u8868\u73b0\u826f\u597d", "conclusion": "Adapt\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u7b56\u7565\u9009\u62e9\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u7684\u6027\u80fd\uff0c\u5177\u6709\u826f\u597d\u901a\u7528\u6027"}}
{"id": "2510.24999", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24999", "abs": "https://arxiv.org/abs/2510.24999", "authors": ["Racchit Jain", "Satya Lokam", "Yehonathan Refael", "Adam Hakim", "Lev Greenberg", "Jay Tenenbaum"], "title": "SLIP-SEC: Formalizing Secure Protocols for Model IP Protection", "comment": null, "summary": "Large Language Models (LLMs) represent valuable intellectual property (IP),\nreflecting significant investments in training data, compute, and expertise.\nDeploying these models on partially trusted or insecure devices introduces\nsubstantial risk of model theft, making it essential to design inference\nprotocols with provable security guarantees.\n  We present the formal framework and security foundations of SLIP, a hybrid\ninference protocol that splits model computation between a trusted and an\nuntrusted resource. We define and analyze the key notions of model\ndecomposition and hybrid inference protocols, and introduce formal properties\nincluding safety, correctness, efficiency, and t-soundness. We construct secure\ninference protocols based on additive decompositions of weight matrices,\ncombined with masking and probabilistic verification techniques. We prove that\nthese protocols achieve information-theoretic security against\nhonest-but-curious adversaries, and provide robustness against malicious\nadversaries with negligible soundness error.\n  This paper focuses on the theoretical underpinnings of SLIP: precise\ndefinitions, formal protocols, and proofs of security. Empirical validation and\ndecomposition heuristics appear in the companion SLIP paper. Together, the two\nworks provide a complete account of securing LLM IP via hybrid inference,\nbridging both practice and theory.", "AI": {"tldr": "SLIP\u662f\u4e00\u4e2a\u6df7\u5408\u63a8\u7406\u534f\u8bae\uff0c\u901a\u8fc7\u5728\u53ef\u4fe1\u548c\u4e0d\u53ef\u4fe1\u8d44\u6e90\u4e4b\u95f4\u5206\u5272\u6a21\u578b\u8ba1\u7b97\u6765\u4fdd\u62a4LLM\u7684\u77e5\u8bc6\u4ea7\u6743\uff0c\u63d0\u4f9b\u4fe1\u606f\u8bba\u5b89\u5168\u4fdd\u8bc1\u3002", "motivation": "LLMs\u4ee3\u8868\u91cd\u8981\u7684\u77e5\u8bc6\u4ea7\u6743\uff0c\u90e8\u7f72\u5728\u90e8\u5206\u53ef\u4fe1\u6216\u4e0d\u5b89\u5168\u8bbe\u5907\u4e0a\u5b58\u5728\u6a21\u578b\u88ab\u76d7\u98ce\u9669\uff0c\u9700\u8981\u8bbe\u8ba1\u5177\u6709\u53ef\u8bc1\u660e\u5b89\u5168\u4fdd\u8bc1\u7684\u63a8\u7406\u534f\u8bae\u3002", "method": "\u57fa\u4e8e\u6743\u91cd\u77e9\u9635\u7684\u52a0\u6cd5\u5206\u89e3\uff0c\u7ed3\u5408\u63a9\u7801\u548c\u6982\u7387\u9a8c\u8bc1\u6280\u672f\u6784\u5efa\u5b89\u5168\u63a8\u7406\u534f\u8bae\uff0c\u5728\u53ef\u4fe1\u548c\u4e0d\u53ef\u4fe1\u8d44\u6e90\u95f4\u5206\u5272\u8ba1\u7b97\u3002", "result": "\u534f\u8bae\u5b9e\u73b0\u4e86\u5bf9\u8bda\u5b9e\u4f46\u597d\u5947\u5bf9\u624b\u7684\u4fe1\u606f\u8bba\u5b89\u5168\uff0c\u5e76\u5bf9\u6076\u610f\u5bf9\u624b\u63d0\u4f9b\u5177\u6709\u53ef\u5ffd\u7565\u5065\u5168\u6027\u9519\u8bef\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "SLIP\u63d0\u4f9b\u4e86\u4fdd\u62a4LLM\u77e5\u8bc6\u4ea7\u6743\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5305\u62ec\u7cbe\u786e\u5b9a\u4e49\u3001\u5f62\u5f0f\u5316\u534f\u8bae\u548c\u5b89\u5168\u8bc1\u660e\uff0c\u4e0e\u914d\u5957\u8bba\u6587\u5171\u540c\u6784\u5efa\u4e86\u6df7\u5408\u63a8\u7406\u7684\u5b8c\u6574\u5b89\u5168\u6846\u67b6\u3002"}}
{"id": "2510.25065", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25065", "abs": "https://arxiv.org/abs/2510.25065", "authors": ["Taekhyun Park", "Yongjae Lee", "Hyerim Bae"], "title": "Reasoning-Aware GRPO using Process Mining", "comment": null, "summary": "Reinforcement learning (RL)-based post-training has been crucial for enabling\nmulti-step reasoning in large reasoning models (LRMs), yet current reward\nschemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware\nGroup Relative Policy Optimization (GRPO) that augments standard answer/format\nrewards with signals over the reasoning procedure. To this end, process mining\ntechniques are utilized to compute a scalar conformance reward that measures\nhow closely a policy model's reasoning aligns with the pretrained teacher\nmodel. The empirical results on five benchmarks demonstrate that PM4GRPO\nsignificantly outperforms existing methodologies for GRPO-based post-training.\nThese results highlight that leveraging process mining for reasoning-aware GRPO\neffectively enhances the reasoning capabilities of policy models.", "AI": {"tldr": "\u63d0\u51fa\u4e86PM4GRPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fc7\u7a0b\u6316\u6398\u6280\u672f\u589e\u5f3a\u63a8\u7406\u611f\u77e5\u7684\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7ed3\u679c\u5956\u52b1\uff0c\u7f3a\u4e4f\u5bf9\u63a8\u7406\u8fc7\u7a0b\u7684\u76d1\u7763\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u63a8\u7406\u611f\u77e5\u5956\u52b1\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u8fc7\u7a0b\u6316\u6398\u6280\u672f\u8ba1\u7b97\u4e00\u81f4\u6027\u5956\u52b1\uff0c\u8861\u91cf\u7b56\u7565\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e0e\u9884\u8bad\u7ec3\u6559\u5e08\u6a21\u578b\u7684\u5339\u914d\u7a0b\u5ea6\uff0c\u7ed3\u5408\u6807\u51c6\u7b54\u6848/\u683c\u5f0f\u5956\u52b1\u8fdb\u884c\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPM4GRPO\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684GRPO\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u63a8\u7406\u611f\u77e5\u5956\u52b1\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5229\u7528\u8fc7\u7a0b\u6316\u6398\u8fdb\u884c\u63a8\u7406\u611f\u77e5\u7684GRPO\u80fd\u591f\u6709\u6548\u63d0\u5347\u7b56\u7565\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.25148", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25148", "abs": "https://arxiv.org/abs/2510.25148", "authors": ["Katsuki Yamagishi", "Norihiro Yoshida", "Erina Makihara", "Katsuro Inoue"], "title": "Automated Program Repair Based on REST API Specifications Using Large Language Models", "comment": null, "summary": "Many cloud services provide REST API accessible to client applications.\nHowever, developers often identify specification violations only during\ntesting, as error messages typically lack the detail necessary for effective\ndiagnosis. Consequently, debugging requires trial and error. This study\nproposes dcFix, a method for detecting and automatically repairing REST API\nmisuses in client programs. In particular, dcFix identifies non-conforming code\nfragments, integrates them with the relevant API specifications into prompts,\nand leverages a Large Language Model (LLM) to produce the corrected code. Our\nevaluation demonstrates that dcFix accurately detects misuse and outperforms\nthe baseline approach, in which prompts to the LLM omit any indication of code\nfragments non conforming to REST API specifications.", "AI": {"tldr": "dcFix\u662f\u4e00\u79cd\u81ea\u52a8\u68c0\u6d4b\u548c\u4fee\u590dREST API\u8bef\u7528\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u4e0d\u7b26\u5408\u89c4\u8303\u7684\u4ee3\u7801\u7247\u6bb5\uff0c\u7ed3\u5408API\u89c4\u8303\u751f\u6210\u63d0\u793a\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4fee\u6b63\u4ee3\u7801\u3002", "motivation": "\u5f00\u53d1\u8005\u5728\u6d4b\u8bd5\u9636\u6bb5\u624d\u80fd\u53d1\u73b0REST API\u89c4\u8303\u8fdd\u53cd\u95ee\u9898\uff0c\u9519\u8bef\u4fe1\u606f\u7f3a\u4e4f\u7ec6\u8282\u5bfc\u81f4\u8c03\u8bd5\u56f0\u96be\uff0c\u9700\u8981\u53cd\u590d\u8bd5\u9519\u3002", "method": "\u8bc6\u522b\u4e0d\u7b26\u5408\u89c4\u8303\u7684\u4ee3\u7801\u7247\u6bb5\uff0c\u5c06\u5176\u4e0e\u76f8\u5173API\u89c4\u8303\u6574\u5408\u5230\u63d0\u793a\u4e2d\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4fee\u6b63\u4ee3\u7801\u3002", "result": "\u8bc4\u4f30\u663e\u793adcFix\u80fd\u51c6\u786e\u68c0\u6d4b\u8bef\u7528\uff0c\u5e76\u4e14\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff08\u57fa\u7ebf\u65b9\u6cd5\u5728\u63d0\u793a\u4e2d\u4e0d\u5305\u542b\u4ee3\u7801\u7247\u6bb5\u4e0d\u7b26\u5408REST API\u89c4\u8303\u7684\u6307\u793a\uff09\u3002", "conclusion": "dcFix\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u548c\u81ea\u52a8\u4fee\u590dREST API\u8bef\u7528\u95ee\u9898\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2510.25025", "categories": ["cs.CR", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25025", "abs": "https://arxiv.org/abs/2510.25025", "authors": ["Zirui Cheng", "Jikai Sun", "Anjun Gao", "Yueyang Quan", "Zhuqing Liu", "Xiaohua Hu", "Minghong Fang"], "title": "Secure Retrieval-Augmented Generation against Poisoning Attacks", "comment": "To appear in IEEE BigData 2025", "summary": "Large language models (LLMs) have transformed natural language processing\n(NLP), enabling applications from content generation to decision support.\nRetrieval-Augmented Generation (RAG) improves LLMs by incorporating external\nknowledge but also introduces security risks, particularly from data poisoning,\nwhere the attacker injects poisoned texts into the knowledge database to\nmanipulate system outputs. While various defenses have been proposed, they\noften struggle against advanced attacks. To address this, we introduce RAGuard,\na detection framework designed to identify poisoned texts. RAGuard first\nexpands the retrieval scope to increase the proportion of clean texts, reducing\nthe likelihood of retrieving poisoned content. It then applies chunk-wise\nperplexity filtering to detect abnormal variations and text similarity\nfiltering to flag highly similar texts. This non-parametric approach enhances\nRAG security, and experiments on large-scale datasets demonstrate its\neffectiveness in detecting and mitigating poisoning attacks, including strong\nadaptive attacks.", "AI": {"tldr": "RAGuard\u662f\u4e00\u4e2a\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u5c55\u68c0\u7d22\u8303\u56f4\u3001\u57fa\u4e8e\u56f0\u60d1\u5ea6\u7684\u8fc7\u6ee4\u548c\u6587\u672c\u76f8\u4f3c\u6027\u8fc7\u6ee4\u6765\u8bc6\u522bRAG\u7cfb\u7edf\u4e2d\u7684\u4e2d\u6bd2\u6587\u672c\uff0c\u6709\u6548\u9632\u5fa1\u6570\u636e\u6295\u6bd2\u653b\u51fb\u3002", "motivation": "RAG\u7cfb\u7edf\u867d\u7136\u589e\u5f3a\u4e86LLMs\u7684\u6027\u80fd\uff0c\u4f46\u5f15\u5165\u4e86\u6570\u636e\u6295\u6bd2\u7684\u5b89\u5168\u98ce\u9669\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u9ad8\u7ea7\u653b\u51fb\u3002", "method": "RAGuard\u91c7\u7528\u4e09\u6b65\u6cd5\uff1a\u6269\u5c55\u68c0\u7d22\u8303\u56f4\u589e\u52a0\u5e72\u51c0\u6587\u672c\u6bd4\u4f8b\uff1b\u57fa\u4e8e\u56f0\u60d1\u5ea6\u7684\u5206\u5757\u8fc7\u6ee4\u68c0\u6d4b\u5f02\u5e38\u53d8\u5316\uff1b\u6587\u672c\u76f8\u4f3c\u6027\u8fc7\u6ee4\u6807\u8bb0\u9ad8\u5ea6\u76f8\u4f3c\u6587\u672c\u3002", "result": "\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRAGuard\u80fd\u6709\u6548\u68c0\u6d4b\u548c\u7f13\u89e3\u6295\u6bd2\u653b\u51fb\uff0c\u5305\u62ec\u5f3a\u81ea\u9002\u5e94\u653b\u51fb\u3002", "conclusion": "RAGuard\u63d0\u4f9b\u4e86\u4e00\u79cd\u975e\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86RAG\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u80fd\u591f\u53ef\u9760\u5730\u9632\u5fa1\u6570\u636e\u6295\u6bd2\u5a01\u80c1\u3002"}}
{"id": "2510.25091", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25091", "abs": "https://arxiv.org/abs/2510.25091", "authors": ["Peilin Tan", "Liang Xie", "Churan Zhi", "Dian Tu", "Chuanqi Shi"], "title": "H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and Style-Structured Mixture of Experts", "comment": null, "summary": "Stock movement prediction remains fundamentally challenging due to complex\ntemporal dependencies, heterogeneous modalities, and dynamically evolving\ninter-stock relationships. Existing approaches often fail to unify structural,\nsemantic, and regime-adaptive modeling within a scalable framework. This work\nintroduces H3M-SSMoEs, a novel Hypergraph-based MultiModal architecture with\nLLM reasoning and Style-Structured Mixture of Experts, integrating three key\ninnovations: (1) a Multi-Context Multimodal Hypergraph that hierarchically\ncaptures fine-grained spatiotemporal dynamics via a Local Context Hypergraph\n(LCH) and persistent inter-stock dependencies through a Global Context\nHypergraph (GCH), employing shared cross-modal hyperedges and Jensen-Shannon\nDivergence weighting mechanism for adaptive relational learning and cross-modal\nalignment; (2) a LLM-enhanced reasoning module, which leverages a frozen large\nlanguage model with lightweight adapters to semantically fuse and align\nquantitative and textual modalities, enriching representations with\ndomain-specific financial knowledge; and (3) a Style-Structured Mixture of\nExperts (SSMoEs) that combines shared market experts and industry-specialized\nexperts, each parameterized by learnable style vectors enabling regime-aware\nspecialization under sparse activation. Extensive experiments on three major\nstock markets demonstrate that H3M-SSMoEs surpasses state-of-the-art methods in\nboth superior predictive accuracy and investment performance, while exhibiting\neffective risk control. Datasets, source code, and model weights are available\nat our GitHub repository: https://github.com/PeilinTime/H3M-SSMoEs.", "AI": {"tldr": "H3M-SSMoEs\u662f\u4e00\u4e2a\u57fa\u4e8e\u8d85\u56fe\u7684\u591a\u6a21\u6001\u80a1\u7968\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408LLM\u63a8\u7406\u548c\u98ce\u683c\u7ed3\u6784\u6df7\u5408\u4e13\u5bb6\uff0c\u5728\u4e09\u4e2a\u4e3b\u8981\u80a1\u7968\u5e02\u573a\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u80a1\u7968\u9884\u6d4b\u9762\u4e34\u590d\u6742\u7684\u65f6\u95f4\u4f9d\u8d56\u3001\u591a\u6a21\u6001\u5f02\u8d28\u6027\u548c\u52a8\u6001\u53d8\u5316\u7684\u80a1\u7968\u95f4\u5173\u7cfb\u7b49\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u53ef\u6269\u5c55\u6846\u67b6\u5185\u7edf\u4e00\u7ed3\u6784\u3001\u8bed\u4e49\u548c\u673a\u5236\u81ea\u9002\u5e94\u5efa\u6a21\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a(1)\u591a\u4e0a\u4e0b\u6587\u591a\u6a21\u6001\u8d85\u56fe\uff0c\u901a\u8fc7\u5c40\u90e8\u548c\u5168\u5c40\u4e0a\u4e0b\u6587\u8d85\u56fe\u5206\u5c42\u6355\u83b7\u65f6\u7a7a\u52a8\u6001\uff1b(2)LLM\u589e\u5f3a\u63a8\u7406\u6a21\u5757\uff0c\u5229\u7528\u51bb\u7ed3\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5408\u5b9a\u91cf\u548c\u6587\u672c\u6a21\u6001\uff1b(3)\u98ce\u683c\u7ed3\u6784\u6df7\u5408\u4e13\u5bb6\uff0c\u7ed3\u5408\u5171\u4eab\u5e02\u573a\u4e13\u5bb6\u548c\u884c\u4e1a\u4e13\u4e1a\u4e13\u5bb6\u3002", "result": "\u5728\u4e09\u4e2a\u4e3b\u8981\u80a1\u7968\u5e02\u573a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cH3M-SSMoEs\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6295\u8d44\u6027\u80fd\u65b9\u9762\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u5c55\u73b0\u51fa\u6709\u6548\u7684\u98ce\u9669\u63a7\u5236\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6210\u529f\u89e3\u51b3\u4e86\u80a1\u7968\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25195", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25195", "abs": "https://arxiv.org/abs/2510.25195", "authors": ["Shuochuan Li", "Zan Wang", "Xiaoning Du", "Zhuo Wu", "Jiuqiao Yu", "Junjie Chen"], "title": "Optimizing Knowledge Utilization for Multi-Intent Comment Generation with Large Language Models", "comment": null, "summary": "Code comment generation aims to produce a generic overview of a code snippet,\nhelping developers understand and maintain code. However, generic summaries\nalone are insufficient to meet the diverse needs of practitioners; for example,\ndevelopers expect the implementation insights to be presented in an untangled\nmanner, while users seek clear usage instructions. This highlights the\nnecessity of multi-intent comment generation. With the widespread adoption of\nLarge Language Models (LLMs) for code-related tasks, these models have been\nleveraged to tackle the challenge of multi-intent comment generation. Despite\ntheir successes, state-of-the-art LLM-based approaches often struggle to\nconstruct correct relationships among intents, code, and comments within a\nsmaller number of demonstration examples. To mitigate this issue, we propose a\nframework named KUMIC for multi-intent comment generation. Built upon\nin-context learning, KUMIC leverages Chain-of-Thought (CoT) to optimize\nknowledge utilization for LLMs to generate intent-specific comments.\nSpecifically, KUMIC first designs a retrieval mechanism to obtain similar\ndemonstration examples, which exhibit high code-comment consistency. Then,\nKUMIC leverages CoT to guide LLMs to focus on statements facilitating the\nderivation of code comments aligned with specific intents. In this context,\nKUMIC constructs a mapping knowledge chain, linking code to intent-specific\nstatements to comments, which enables LLMs to follow similar reasoning steps\nwhen generating the desired comments. We conduct extensive experiments to\nevaluate KUMIC, and the results demonstrate that KUMIC outperforms\nstate-of-the-art baselines by 14.49\\%, 22.41\\%, 20.72\\%, and 12.94\\% in terms\nof BLEU, METEOR, ROUGE-L, and SBERT, respectively.", "AI": {"tldr": "KUMIC\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u673a\u5236\u548c\u601d\u7ef4\u94fe\u4f18\u5316LLMs\u751f\u6210\u591a\u610f\u56fe\u4ee3\u7801\u6ce8\u91ca\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u901a\u7528\u4ee3\u7801\u6ce8\u91ca\u65e0\u6cd5\u6ee1\u8db3\u5f00\u53d1\u8005\u5bf9\u5b9e\u73b0\u7ec6\u8282\u548c\u7528\u6237\u5bf9\u4f7f\u7528\u8bf4\u660e\u7684\u4e0d\u540c\u9700\u6c42\uff0c\u9700\u8981\u591a\u610f\u56fe\u6ce8\u91ca\u751f\u6210\u3002\u73b0\u6709LLM\u65b9\u6cd5\u5728\u5c11\u91cf\u793a\u4f8b\u4e2d\u96be\u4ee5\u5efa\u7acb\u610f\u56fe\u3001\u4ee3\u7801\u548c\u6ce8\u91ca\u7684\u6b63\u786e\u5173\u7cfb\u3002", "method": "KUMIC\u6846\u67b6\uff1a1\uff09\u68c0\u7d22\u673a\u5236\u83b7\u53d6\u4ee3\u7801-\u6ce8\u91ca\u4e00\u81f4\u6027\u9ad8\u7684\u793a\u4f8b\uff1b2\uff09\u4f7f\u7528\u601d\u7ef4\u94fe\u5f15\u5bfcLLMs\u5173\u6ce8\u4e0e\u7279\u5b9a\u610f\u56fe\u5bf9\u9f50\u7684\u8bed\u53e5\uff1b3\uff09\u6784\u5efa\u6620\u5c04\u77e5\u8bc6\u94fe\uff0c\u8fde\u63a5\u4ee3\u7801\u5230\u610f\u56fe\u7279\u5b9a\u8bed\u53e5\u518d\u5230\u6ce8\u91ca\u3002", "result": "\u5728BLEU\u3001METEOR\u3001ROUGE-L\u548cSBERT\u6307\u6807\u4e0a\u5206\u522b\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u63d0\u534714.49%\u300122.41%\u300120.72%\u548c12.94%\u3002", "conclusion": "KUMIC\u901a\u8fc7\u4f18\u5316\u77e5\u8bc6\u5229\u7528\u548c\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u610f\u56fe\u4ee3\u7801\u6ce8\u91ca\u751f\u6210\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2510.25189", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.25189", "abs": "https://arxiv.org/abs/2510.25189", "authors": ["Ana M. Rodriguez", "Jaime Acosta", "Anantaa Kotal", "Aritran Piplai"], "title": "AgentCyTE: Leveraging Agentic AI to Generate Cybersecurity Training & Experimentation Scenarios", "comment": null, "summary": "Designing realistic and adaptive networked threat scenarios remains a core\nchallenge in cybersecurity research and training, still requiring substantial\nmanual effort. While large language models (LLMs) show promise for automated\nsynthesis, unconstrained generation often yields configurations that fail\nvalidation or execution. We present AgentCyTE, a framework integrating\nLLM-based reasoning with deterministic, schema-constrained network emulation to\ngenerate and refine executable threat environments. Through an agentic feedback\nloop, AgentCyTE observes scenario outcomes, validates correctness, and\niteratively enhances realism and consistency. This hybrid approach preserves\nLLM flexibility while enforcing structural validity, enabling scalable,\ndata-driven experimentation and reliable scenario generation for threat\nmodeling and adaptive cybersecurity training. Our framework can be accessed at:\nhttps://github.com/AnantaaKotal/AgentCyTE", "AI": {"tldr": "\u63d0\u51fa\u4e86AgentCyTE\u6846\u67b6\uff0c\u7ed3\u5408LLM\u63a8\u7406\u4e0e\u786e\u5b9a\u6027\u7f51\u7edc\u4eff\u771f\uff0c\u901a\u8fc7\u53cd\u9988\u5faa\u73af\u751f\u6210\u53ef\u6267\u884c\u7684\u7f51\u7edc\u5a01\u80c1\u573a\u666f\uff0c\u89e3\u51b3\u4f20\u7edf\u624b\u52a8\u8bbe\u8ba1\u7684\u6311\u6218\u3002", "motivation": "\u7f51\u7edc\u5b89\u5168\u7814\u7a76\u548c\u8bad\u7ec3\u4e2d\u8bbe\u8ba1\u771f\u5b9e\u3001\u81ea\u9002\u5e94\u7684\u7f51\u7edc\u5a01\u80c1\u573a\u666f\u4ecd\u9700\u8981\u5927\u91cf\u4eba\u5de5\u5de5\u4f5c\uff0c\u73b0\u6709LLM\u751f\u6210\u65b9\u6cd5\u5f80\u5f80\u4ea7\u751f\u65e0\u6cd5\u9a8c\u8bc1\u6216\u6267\u884c\u7684\u914d\u7f6e\u3002", "method": "\u96c6\u6210\u57fa\u4e8eLLM\u7684\u63a8\u7406\u4e0e\u786e\u5b9a\u6027\u3001\u6a21\u5f0f\u7ea6\u675f\u7684\u7f51\u7edc\u4eff\u771f\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u53cd\u9988\u5faa\u73af\u89c2\u5bdf\u573a\u666f\u7ed3\u679c\u3001\u9a8c\u8bc1\u6b63\u786e\u6027\uff0c\u5e76\u8fed\u4ee3\u63d0\u5347\u771f\u5b9e\u6027\u548c\u4e00\u81f4\u6027\u3002", "result": "\u8be5\u6df7\u5408\u65b9\u6cd5\u5728\u4fdd\u6301LLM\u7075\u6d3b\u6027\u7684\u540c\u65f6\u786e\u4fdd\u7ed3\u6784\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u6570\u636e\u9a71\u52a8\u5b9e\u9a8c\u548c\u53ef\u9760\u7684\u5a01\u80c1\u5efa\u6a21\u573a\u666f\u751f\u6210\u3002", "conclusion": "AgentCyTE\u6846\u67b6\u80fd\u591f\u4e3a\u81ea\u9002\u5e94\u7f51\u7edc\u5b89\u5168\u8bad\u7ec3\u63d0\u4f9b\u53ef\u9760\u7684\u5a01\u80c1\u573a\u666f\u751f\u6210\uff0c\u89e3\u51b3\u4e86LLM\u65e0\u7ea6\u675f\u751f\u6210\u5bfc\u81f4\u7684\u9a8c\u8bc1\u548c\u6267\u884c\u95ee\u9898\u3002"}}
{"id": "2510.25101", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25101", "abs": "https://arxiv.org/abs/2510.25101", "authors": ["Zhuo Chen", "Fei Wang", "Zixuan Li", "Zhao Zhang", "Weiwei Ding", "Chuanguang Yang", "Yongjun Xu", "Xiaolong Jin", "Jiafeng Guo"], "title": "KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA", "comment": null, "summary": "Knowledge Base Question Answering (KBQA) aims to answer natural-language\nquestions over a structured Knowledge Base (KB). Recent work improves KBQA by\nadopting an agentic reasoning paradigm, in which Large Language Models (LLMs)\niteratively decompose a question, generate its corresponding logical queries,\nand interact with the KB to derive the answer. However, these methods typically\nfine-tune LLMs on reasoning trajectories synthesized via process supervision,\nwhich offers weak incentives for exploration and thus fails to strengthen the\nagentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that\ncan autonomously perform agentic reasoning on KBs to obtain answers. To\nincentivize autonomous exploration, KnowCoder-A1 trains the LLM under\noutcome-only supervision via a multi-stage curriculum reinforcement learning\nwith an easy-to-hard curriculum. To establish foundational agentic\ncapabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of\nhigh-quality trajectories obtained through outcome-based rejection sampling.\nThen, to alleviate the reward sparsity inherent in outcome-only supervision, it\napplies multi-stage curriculum RL with reward schedules that progress from easy\nto hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful\nreasoning behaviors and consistently outperforms prior approaches across three\nmainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1\nachieves up to an 11.1% relative improvement while using only one-twelfth of\nthe training data, demonstrating strong agentic reasoning capabilities.", "AI": {"tldr": "KnowCoder-A1\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u9636\u6bb5\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\u7684LLM\uff0c\u901a\u8fc7\u7ed3\u679c\u76d1\u7763\u8bad\u7ec3\uff0c\u5728\u77e5\u8bc6\u5e93\u95ee\u7b54\u4efb\u52a1\u4e2d\u5b9e\u73b0\u81ea\u4e3b\u4ee3\u7406\u63a8\u7406\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709KBQA\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u8fc7\u7a0b\u76d1\u7763\u5fae\u8c03LLMs\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5bf9\u63a2\u7d22\u7684\u6fc0\u52b1\u8f83\u5f31\uff0c\u65e0\u6cd5\u6709\u6548\u589e\u5f3a\u4ee3\u7406\u63a8\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\uff1a1\uff09\u9996\u5148\u5728\u9ad8\u8d28\u91cf\u8f68\u8ff9\u4e0a\u5fae\u8c03LLM\u5efa\u7acb\u57fa\u7840\u80fd\u529b\uff1b2\uff09\u5e94\u7528\u4ece\u6613\u5230\u96be\u7684\u5956\u52b1\u8c03\u5ea6\u6765\u7f13\u89e3\u7ed3\u679c\u76d1\u7763\u4e2d\u7684\u5956\u52b1\u7a00\u758f\u95ee\u9898\u3002", "result": "\u5728\u4e09\u4e2a\u4e3b\u6d41\u6570\u636e\u96c6\u4e0a\u6301\u7eed\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u5728GrailQA\u96f6\u6837\u672c\u5b50\u96c6\u4e0a\u76f8\u5bf9\u63d0\u5347\u8fbe11.1%\uff0c\u4e14\u4ec5\u4f7f\u7528\u5341\u4e8c\u5206\u4e4b\u4e00\u7684\u8bad\u7ec3\u6570\u636e\u3002", "conclusion": "\u57fa\u4e8e\u7ed3\u679c\u76d1\u7763\u8bad\u7ec3\u7684KnowCoder-A1\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u884c\u4e3a\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u77e5\u8bc6\u5e93\u95ee\u7b54\u4e2d\u7684\u6709\u6548\u4ee3\u7406\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.25242", "categories": ["cs.SE", "C.3; D.2"], "pdf": "https://arxiv.org/pdf/2510.25242", "abs": "https://arxiv.org/abs/2510.25242", "authors": ["Nao Yoshimura", "Hiroshi Oyama", "Takuya Azumi"], "title": "TECS/Rust-OE: Optimizing Exclusive Control in Rust-based Component Systems for Embedded Devices", "comment": "5 pages (layout expanded from the 4-page IEEE version due to minor\n  lstlisting configuration adjustments for compilation). Originally published\n  as a poster paper at IEEE ISORC 2025", "summary": "The diversification of functionalities and the development of the IoT are\nmaking embedded systems larger and more complex in structure. Ensuring system\nreliability, especially in terms of security, necessitates selecting an\nappropriate programming language. As part of existing research, TECS/Rust has\nbeen proposed as a framework that combines Rust and component-based development\n(CBD) to enable scalable system design and enhanced reliability. This framework\nrepresents system structures using static mutable variables, but excessive\nexclusive controls applied to ensure thread safety have led to performance\ndegradation. This paper proposes TECS/Rust-OE, a memory-safe CBD framework\nutilizing call flows to address these limitations. The proposed Rust code\nleverages real-time OS exclusive control mechanisms, optimizing performance\nwithout compromising reusability. Rust code is automatically generated based on\ncomponent descriptions. Evaluations demonstrate reduced overhead due to\noptimized exclusion control and high reusability of the generated code.", "AI": {"tldr": "\u63d0\u51fa\u4e86TECS/Rust-OE\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u6392\u4ed6\u63a7\u5236\u673a\u5236\u4f18\u5316\u6027\u80fd\uff0c\u89e3\u51b3TECS/Rust\u6846\u67b6\u4e2d\u8fc7\u5ea6\u6392\u4ed6\u63a7\u5236\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "motivation": "\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7ed3\u6784\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u786e\u4fdd\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5b89\u5168\u6027\u3002\u73b0\u6709TECS/Rust\u6846\u67b6\u4f7f\u7528\u9759\u6001\u53ef\u53d8\u53d8\u91cf\u8868\u793a\u7cfb\u7edf\u7ed3\u6784\uff0c\u4f46\u4e3a\u786e\u4fdd\u7ebf\u7a0b\u5b89\u5168\u800c\u5e94\u7528\u7684\u8fc7\u5ea6\u6392\u4ed6\u63a7\u5236\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faTECS/Rust-OE\u6846\u67b6\uff0c\u5229\u7528\u8c03\u7528\u6d41\u548c\u5b9e\u65f6OS\u6392\u4ed6\u63a7\u5236\u673a\u5236\uff0c\u5728\u4fdd\u6301\u53ef\u91cd\u7528\u6027\u7684\u540c\u65f6\u4f18\u5316\u6027\u80fd\u3002\u57fa\u4e8e\u7ec4\u4ef6\u63cf\u8ff0\u81ea\u52a8\u751f\u6210Rust\u4ee3\u7801\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u4f18\u5316\u540e\u7684\u6392\u4ed6\u63a7\u5236\u51cf\u5c11\u4e86\u5f00\u9500\uff0c\u751f\u6210\u7684\u4ee3\u7801\u5177\u6709\u9ad8\u53ef\u91cd\u7528\u6027\u3002", "conclusion": "TECS/Rust-OE\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u6027\u80fd\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5185\u5b58\u5b89\u5168\u7684\u7ec4\u4ef6\u5316\u5f00\u53d1\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u53ef\u91cd\u7528\u6027\u3002"}}
{"id": "2510.25352", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.25352", "abs": "https://arxiv.org/abs/2510.25352", "authors": ["David Plonka", "Branden Palacio", "Debbie Perouli"], "title": "Is Protective DNS Blocking the Wild West?", "comment": "Presented in ACM IMC 2025 Workshop of Policy-Relevant Internet\n  Measurements and Experimentation (PRIME), Madison, WI, October, 2025", "summary": "We perform a passive measurement study investigating how a Protective DNS\nservice might perform in a Research & Education Network serving hundreds of\nmember institutions. Utilizing freely-available DNS blocklists consisting of\ndomain names deemed to be threats, we test hundreds of millions of users' real\nDNS queries, observed over a week's time, to find which answers would be\nblocked because they involve domain names that are potential threats. We find\nthe blocklists disorderly regarding their names, goals, transparency, and\nprovenance making them quite difficult to compare. Consequently, these\nProtective DNS underpinnings lack organized oversight, presenting challenges\nand risks in operation at scale.", "AI": {"tldr": "\u5bf9\u7814\u7a76\u6559\u80b2\u7f51\u7edc\u4e2d\u4fdd\u62a4\u6027DNS\u670d\u52a1\u7684\u6027\u80fd\u8fdb\u884c\u88ab\u52a8\u6d4b\u91cf\u7814\u7a76\uff0c\u53d1\u73b0\u73b0\u6709DNS\u963b\u6b62\u5217\u8868\u5728\u547d\u540d\u3001\u76ee\u6807\u3001\u900f\u660e\u5ea6\u548c\u6765\u6e90\u65b9\u9762\u7f3a\u4e4f\u7ec4\u7ec7\u6027\uff0c\u96be\u4ee5\u6bd4\u8f83\uff0c\u5728\u5927\u89c4\u6a21\u8fd0\u8425\u4e2d\u5b58\u5728\u6311\u6218\u548c\u98ce\u9669\u3002", "motivation": "\u7814\u7a76\u4fdd\u62a4\u6027DNS\u670d\u52a1\u5728\u7814\u7a76\u6559\u80b2\u7f51\u7edc\u4e2d\u7684\u5b9e\u9645\u6027\u80fd\u8868\u73b0\uff0c\u8be5\u7f51\u7edc\u670d\u52a1\u4e8e\u6570\u767e\u4e2a\u6210\u5458\u673a\u6784\uff0c\u9700\u8981\u8bc4\u4f30\u73b0\u6709DNS\u963b\u6b62\u5217\u8868\u7684\u6709\u6548\u6027\u548c\u53ef\u7528\u6027\u3002", "method": "\u4f7f\u7528\u514d\u8d39\u53ef\u7528\u7684DNS\u963b\u6b62\u5217\u8868\uff08\u5305\u542b\u88ab\u8ba4\u5b9a\u4e3a\u5a01\u80c1\u7684\u57df\u540d\uff09\uff0c\u5bf9\u4e00\u5468\u5185\u89c2\u5bdf\u5230\u7684\u6570\u4ebf\u7528\u6237\u771f\u5b9eDNS\u67e5\u8be2\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5206\u6790\u54ea\u4e9b\u67e5\u8be2\u4f1a\u88ab\u963b\u6b62\u3002", "result": "\u53d1\u73b0DNS\u963b\u6b62\u5217\u8868\u5728\u547d\u540d\u3001\u76ee\u6807\u3001\u900f\u660e\u5ea6\u548c\u6765\u6e90\u65b9\u9762\u7f3a\u4e4f\u7ec4\u7ec7\u6027\uff0c\u96be\u4ee5\u8fdb\u884c\u6bd4\u8f83\uff0c\u4fdd\u62a4\u6027DNS\u7684\u57fa\u7840\u8bbe\u65bd\u7f3a\u4e4f\u6709\u7ec4\u7ec7\u7684\u76d1\u7763\u3002", "conclusion": "\u73b0\u6709\u7684\u4fdd\u62a4\u6027DNS\u57fa\u7840\u8bbe\u65bd\u5728\u5927\u89c4\u6a21\u8fd0\u8425\u4e2d\u9762\u4e34\u6311\u6218\u548c\u98ce\u9669\uff0c\u9700\u8981\u66f4\u597d\u7684\u7ec4\u7ec7\u76d1\u7763\u548c\u6807\u51c6\u5316\u3002"}}
{"id": "2510.25179", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25179", "abs": "https://arxiv.org/abs/2510.25179", "authors": ["Juan Ren", "Mark Dras", "Usman Naseem"], "title": "Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models", "comment": null, "summary": "Agentic methods have emerged as a powerful and autonomous paradigm that\nenhances reasoning, collaboration, and adaptive control, enabling systems to\ncoordinate and independently solve complex tasks. We extend this paradigm to\nsafety alignment by introducing Agentic Moderation, a model-agnostic framework\nthat leverages specialised agents to defend multimodal systems against\njailbreak attacks. Unlike prior approaches that apply as a static layer over\ninputs or outputs and provide only binary classifications (safe or unsafe), our\nmethod integrates dynamic, cooperative agents, including Shield, Responder,\nEvaluator, and Reflector, to achieve context-aware and interpretable\nmoderation. Extensive experiments across five datasets and four representative\nLarge Vision-Language Models (LVLMs) demonstrate that our approach reduces the\nAttack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF),\nand improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable,\nand well-balanced safety performance. By harnessing the flexibility and\nreasoning capacity of agentic architectures, Agentic Moderation provides\nmodular, scalable, and fine-grained safety enforcement, highlighting the\nbroader potential of agentic systems as a foundation for automated safety\ngovernance.", "AI": {"tldr": "\u63d0\u51faAgentic Moderation\u6846\u67b6\uff0c\u4f7f\u7528\u4e13\u95e8\u4ee3\u7406\u6765\u9632\u5fa1\u591a\u6a21\u6001\u7cfb\u7edf\u7684\u8d8a\u72f1\u653b\u51fb\uff0c\u76f8\u6bd4\u9759\u6001\u65b9\u6cd5\u80fd\u52a8\u6001\u534f\u4f5c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u53ef\u89e3\u91ca\u7684\u5ba1\u6838", "motivation": "\u73b0\u6709\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u901a\u5e38\u4f5c\u4e3a\u9759\u6001\u5c42\u5e94\u7528\u4e8e\u8f93\u5165\u6216\u8f93\u51fa\uff0c\u53ea\u80fd\u63d0\u4f9b\u4e8c\u5143\u5206\u7c7b\uff08\u5b89\u5168/\u4e0d\u5b89\u5168\uff09\uff0c\u7f3a\u4e4f\u52a8\u6001\u6027\u548c\u53ef\u89e3\u91ca\u6027", "method": "\u5f15\u5165\u52a8\u6001\u534f\u4f5c\u4ee3\u7406\u6846\u67b6\uff0c\u5305\u62ecShield\u3001Responder\u3001Evaluator\u548cReflector\u7b49\u4e13\u95e8\u4ee3\u7406\uff0c\u5b9e\u73b0\u6a21\u578b\u65e0\u5173\u7684\u591a\u6a21\u6001\u7cfb\u7edf\u5b89\u5168\u9632\u5fa1", "result": "\u57285\u4e2a\u6570\u636e\u96c6\u548c4\u4e2a\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e7-19%\uff0c\u62d2\u7edd\u7387\u63d0\u9ad84-20%\uff0c\u4fdd\u6301\u7a33\u5b9a\u7684\u4e0d\u9075\u5faa\u7387", "conclusion": "Agentic Moderation\u901a\u8fc7\u5229\u7528\u4ee3\u7406\u67b6\u6784\u7684\u7075\u6d3b\u6027\u548c\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u548c\u7ec6\u7c92\u5ea6\u7684\u5b89\u5168\u6267\u884c\uff0c\u5c55\u793a\u4e86\u4ee3\u7406\u7cfb\u7edf\u4f5c\u4e3a\u81ea\u52a8\u5b89\u5168\u6cbb\u7406\u57fa\u7840\u7684\u6f5c\u529b"}}
{"id": "2510.25270", "categories": ["cs.SE", "C.3; D.2"], "pdf": "https://arxiv.org/pdf/2510.25270", "abs": "https://arxiv.org/abs/2510.25270", "authors": ["Nao Yoshimura", "Hiroshi Oyama", "Takuya Azumi"], "title": "TECS/Rust: Memory-safe Component Framework for Embedded Systems", "comment": "10 pages. This version includes minor lstlisting configuration\n  adjustments for successful compilation. No changes to content or layout.\n  Originally published at IEEE ISORC 2024", "summary": "As embedded systems grow in complexity and scale due to increased functional\ndiversity, component-based development (CBD) emerges as a solution to\nstreamline their architecture and enhance functionality reuse. CBD typically\nutilizes the C programming language for its direct hardware access and\nlow-level operations, despite its susceptibility to memory-related issues. To\naddress these concerns, this paper proposes TECS/Rust, a Rust-based framework\nspecifically designed for TECS, which is a component framework for embedded\nsystems. It leverages Rust's compile-time memory-safe features, such as\nlifetime and borrowing, to mitigate memory vulnerabilities common with C. The\nproposed framework not only ensures memory safety but also maintains the\nflexibility of CBD, automates Rust code generation for CBD components, and\nsupports efficient integration with real-time operating systems. An evaluation\nof the amount of generated code indicates that the code generated by this paper\nframework accounts for a large percentage of the actual code. Compared to code\ndeveloped without the proposed framework, the difference in execution time is\nminimal, indicating that the overhead introduced by the proposed framework is\nnegligible.", "AI": {"tldr": "\u63d0\u51faTECS/Rust\u6846\u67b6\uff0c\u5c06Rust\u7684\u5185\u5b58\u5b89\u5168\u7279\u6027\u96c6\u6210\u5230\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u7ec4\u4ef6\u5316\u5f00\u53d1\u4e2d\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684C\u8bed\u8a00\uff0c\u4ee5\u51cf\u5c11\u5185\u5b58\u76f8\u5173\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740\u5d4c\u5165\u5f0f\u7cfb\u7edf\u590d\u6742\u6027\u548c\u89c4\u6a21\u589e\u52a0\uff0c\u57fa\u4e8e\u7ec4\u4ef6\u7684\u5f00\u53d1(CBD)\u6210\u4e3a\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u4f20\u7edf\u4f7f\u7528\u7684C\u8bed\u8a00\u5b58\u5728\u5185\u5b58\u5b89\u5168\u95ee\u9898\u3002\u9700\u8981\u5229\u7528Rust\u7684\u7f16\u8bd1\u65f6\u5185\u5b58\u5b89\u5168\u7279\u6027\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eRust\u7684TECS\u6846\u67b6\uff0c\u5229\u7528Rust\u7684\u751f\u547d\u5468\u671f\u548c\u501f\u7528\u7b49\u7279\u6027\u786e\u4fdd\u5185\u5b58\u5b89\u5168\uff0c\u540c\u65f6\u81ea\u52a8\u751f\u6210CBD\u7ec4\u4ef6\u7684Rust\u4ee3\u7801\uff0c\u5e76\u652f\u6301\u4e0e\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u7684\u6709\u6548\u96c6\u6210\u3002", "result": "\u751f\u6210\u7684\u4ee3\u7801\u91cf\u5360\u5b9e\u9645\u4ee3\u7801\u7684\u5f88\u5927\u6bd4\u4f8b\uff0c\u4e0e\u4e0d\u4f7f\u7528\u8be5\u6846\u67b6\u5f00\u53d1\u7684\u4ee3\u7801\u76f8\u6bd4\uff0c\u6267\u884c\u65f6\u95f4\u5dee\u5f02\u6781\u5c0f\uff0c\u8868\u660e\u5f15\u5165\u7684\u5f00\u9500\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "TECS/Rust\u6846\u67b6\u6210\u529f\u5730\u5c06Rust\u7684\u5185\u5b58\u5b89\u5168\u7279\u6027\u5f15\u5165\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7ec4\u4ef6\u5316\u5f00\u53d1\uff0c\u5728\u4fdd\u8bc1\u5185\u5b58\u5b89\u5168\u7684\u540c\u65f6\u4fdd\u6301\u4e86CBD\u7684\u7075\u6d3b\u6027\uff0c\u4e14\u6027\u80fd\u5f00\u9500\u53ef\u5ffd\u7565\u3002"}}
{"id": "2510.25375", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.25375", "abs": "https://arxiv.org/abs/2510.25375", "authors": ["Ali Recai Yekta", "Nicolas Loza", "Jens Gramm", "Michael Peter Schneider", "Stefan Katzenbeisser"], "title": "From ECU to VSOC: UDS Security Monitoring Strategies", "comment": "Presented at SECURWARE 2025, Barcelona, Spain, October 26-30, 2025\n  (https://www.thinkmind.org/library/SECURWARE/SECURWARE_2025/securware_2025_1_70_30030.html)", "summary": "Increasing complexity and connectivity of modern vehicles have heightened\ntheir vulnerability to cyberattacks. This paper addresses security challenges\nassociated with the Unified Diagnostic Services (UDS) protocol, a critical\ncommunication framework for vehicle diagnostics in the automotive industry. We\npresent security monitoring strategies for the UDS protocol that leverage\nin-vehicle logging and remote analysis through a Vehicle Security Operations\nCenter (VSOC). Our approach involves specifying security event logging\nrequirements, contextual data collection, and the development of detection\nstrategies aimed at identifying UDS attack scenarios. By applying these\nstrategies to a comprehensive taxonomy of UDS attack techniques, we demonstrate\nthat our detection methods cover a wide range of potential attack vectors.\nFurthermore, we assess the adequacy of current AUTOSAR standardized security\nevents in supporting UDS attack detection, identifying gaps in the current\nstandard. This work enhances the understanding of vehicle security monitoring\nand provides an example for developing robust cybersecurity measures in\nautomotive communication protocols.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9488\u5bf9\u6c7d\u8f66UDS\u534f\u8bae\u7684\u5b89\u5168\u76d1\u63a7\u7b56\u7565\uff0c\u901a\u8fc7\u8f66\u8f7d\u65e5\u5fd7\u8bb0\u5f55\u548c\u8fdc\u7a0bVSOC\u5206\u6790\u6765\u68c0\u6d4bUDS\u653b\u51fb\uff0c\u8bc4\u4f30\u4e86\u73b0\u6709AUTOSAR\u6807\u51c6\u5728UDS\u653b\u51fb\u68c0\u6d4b\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u4ee3\u8f66\u8f86\u590d\u6742\u6027\u548c\u8fde\u63a5\u6027\u7684\u589e\u52a0\u4f7f\u5176\u66f4\u5bb9\u6613\u53d7\u5230\u7f51\u7edc\u653b\u51fb\uff0c\u7279\u522b\u662fUDS\u534f\u8bae\u4f5c\u4e3a\u8f66\u8f86\u8bca\u65ad\u7684\u5173\u952e\u901a\u4fe1\u6846\u67b6\u5b58\u5728\u5b89\u5168\u6311\u6218\u3002", "method": "\u5236\u5b9a\u5b89\u5168\u4e8b\u4ef6\u65e5\u5fd7\u8bb0\u5f55\u8981\u6c42\u3001\u4e0a\u4e0b\u6587\u6570\u636e\u6536\u96c6\u548c\u68c0\u6d4b\u7b56\u7565\u5f00\u53d1\uff0c\u5e94\u7528\u4e8e\u5168\u9762\u7684UDS\u653b\u51fb\u6280\u672f\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u68c0\u6d4b\u65b9\u6cd5\u8986\u76d6\u4e86\u5e7f\u6cdb\u7684\u6f5c\u5728\u653b\u51fb\u5411\u91cf\uff0c\u540c\u65f6\u8bc6\u522b\u51fa\u73b0\u6709AUTOSAR\u6807\u51c6\u5316\u5b89\u5168\u4e8b\u4ef6\u5728\u652f\u6301UDS\u653b\u51fb\u68c0\u6d4b\u65b9\u9762\u7684\u5dee\u8ddd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u589e\u5f3a\u4e86\u8f66\u8f86\u5b89\u5168\u76d1\u63a7\u7684\u7406\u89e3\uff0c\u4e3a\u5f00\u53d1\u6c7d\u8f66\u901a\u4fe1\u534f\u8bae\u7684\u7a33\u5065\u7f51\u7edc\u5b89\u5168\u63aa\u65bd\u63d0\u4f9b\u4e86\u8303\u4f8b\u3002"}}
{"id": "2510.25205", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25205", "abs": "https://arxiv.org/abs/2510.25205", "authors": ["Yuyang Xia", "Zibo Liang", "Liwei Deng", "Yan Zhao", "Han Su", "Kai Zheng"], "title": "Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision", "comment": "It was accepted by ICDE2026", "summary": "Autonomous driving is an emerging technology that is expected to bring\nsignificant social, economic, and environmental benefits. However, these\nbenefits come with rising energy consumption by computation engines, limiting\nthe driving range of vehicles, especially electric ones. Perception computing\nis typically the most power-intensive component, as it relies on largescale\ndeep learning models to extract environmental features. Recently, numerous\nstudies have employed model compression techniques, such as sparsification,\nquantization, and distillation, to reduce computational consumption. However,\nthese methods often result in either a substantial model size or a significant\ndrop in perception accuracy compared to high-computation models. To address\nthese challenges, we propose an energy-efficient autonomous driving framework,\ncalled EneAD. In the adaptive perception module, a perception optimization\nstrategy is designed from the perspective of data management and tuning.\nFirstly, we manage multiple perception models with different computational\nconsumption and adjust the execution framerate dynamically. Then, we define\nthem as knobs and design a transferable tuning method based on Bayesian\noptimization to identify promising knob values that achieve low computation\nwhile maintaining desired accuracy. To adaptively switch the knob values in\nvarious traffic scenarios, a lightweight classification model is proposed to\ndistinguish the perception difficulty in different scenarios. In the robust\ndecision module, we propose a decision model based on reinforcement learning\nand design a regularization term to enhance driving stability in the face of\nperturbed perception results. Extensive experiments evidence the superiority of\nour framework in both energy consumption and driving performance. EneAD can\nreduce perception consumption by 1.9x to 3.5x and thus improve driving range by\n3.9% to 8.5%", "AI": {"tldr": "EneAD\u662f\u4e00\u4e2a\u8282\u80fd\u81ea\u52a8\u9a7e\u9a76\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u611f\u77e5\u6a21\u5757\u548c\u9c81\u68d2\u51b3\u7b56\u6a21\u5757\uff0c\u5728\u4fdd\u6301\u611f\u77e5\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u80fd\u8017\uff0c\u63d0\u5347\u7535\u52a8\u6c7d\u8f66\u7eed\u822a\u91cc\u7a0b\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u5e26\u6765\u793e\u4f1a\u7ecf\u6d4e\u6548\u76ca\u7684\u540c\u65f6\uff0c\u8ba1\u7b97\u5f15\u64ce\u80fd\u8017\u6025\u5267\u4e0a\u5347\uff0c\u7279\u522b\u662f\u611f\u77e5\u8ba1\u7b97\u4f5c\u4e3a\u6700\u8017\u7535\u7684\u7ec4\u4ef6\uff0c\u9650\u5236\u4e86\u7535\u52a8\u6c7d\u8f66\u7684\u7eed\u822a\u91cc\u7a0b\u3002\u73b0\u6709\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\u8981\u4e48\u5bfc\u81f4\u6a21\u578b\u8fc7\u5927\uff0c\u8981\u4e48\u611f\u77e5\u7cbe\u5ea6\u663e\u8457\u4e0b\u964d\u3002", "method": "\u63d0\u51faEneAD\u6846\u67b6\uff1a1\uff09\u81ea\u9002\u5e94\u611f\u77e5\u6a21\u5757\u901a\u8fc7\u6570\u636e\u7ba1\u7406\u548c\u8c03\u4f18\u7b56\u7565\uff0c\u7ba1\u7406\u591a\u4e2a\u4e0d\u540c\u8ba1\u7b97\u6d88\u8017\u7684\u611f\u77e5\u6a21\u578b\uff0c\u52a8\u6001\u8c03\u6574\u6267\u884c\u5e27\u7387\uff1b2\uff09\u57fa\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u53ef\u8f6c\u79fb\u8c03\u4f18\u65b9\u6cd5\u5bfb\u627e\u6700\u4f18\u53c2\u6570\u914d\u7f6e\uff1b3\uff09\u8f7b\u91cf\u7ea7\u5206\u7c7b\u6a21\u578b\u533a\u5206\u4e0d\u540c\u573a\u666f\u7684\u611f\u77e5\u96be\u5ea6\uff1b4\uff09\u9c81\u68d2\u51b3\u7b56\u6a21\u5757\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bbe\u8ba1\u51b3\u7b56\u6a21\u578b\uff0c\u589e\u5f3a\u5bf9\u6270\u52a8\u611f\u77e5\u7ed3\u679c\u7684\u7a33\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eEneAD\u5728\u80fd\u8017\u548c\u9a7e\u9a76\u6027\u80fd\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u80fd\u591f\u5c06\u611f\u77e5\u6d88\u8017\u964d\u4f4e1.9\u500d\u81f33.5\u500d\uff0c\u4ece\u800c\u5c06\u9a7e\u9a76\u91cc\u7a0b\u63d0\u53473.9%\u81f38.5%\u3002", "conclusion": "EneAD\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u611f\u77e5\u548c\u9c81\u68d2\u51b3\u7b56\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u80fd\u8017\u4e0e\u7cbe\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u8282\u80fd\u81ea\u52a8\u9a7e\u9a76\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.25297", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25297", "abs": "https://arxiv.org/abs/2510.25297", "authors": ["Hidetake Tanaka", "Haruto Tanaka", "Kazumasa Shimari", "Kenichi Matsumoto"], "title": "Understanding the Characteristics of LLM-Generated Property-Based Tests in Exploring Edge Cases", "comment": "Accepted for publication in 2nd IEEE/ACM international conference on\n  AI-powered Software (AIware 2025) : 8 pages, 1 table, 8 figures", "summary": "As Large Language Models (LLMs) increasingly generate code in software\ndevelopment, ensuring the quality of LLM-generated code has become important.\nTraditional testing approaches using Example-based Testing (EBT) often miss\nedge cases -- defects that occur at boundary values, special input patterns, or\nextreme conditions. This research investigates the characteristics of\nLLM-generated Property-based Testing (PBT) compared to EBT for exploring edge\ncases. We analyze 16 HumanEval problems where standard solutions failed on\nextended test cases, generating both PBT and EBT test codes using\nClaude-4-sonnet. Our experimental results reveal that while each method\nindividually achieved a 68.75\\% bug detection rate, combining both approaches\nimproved detection to 81.25\\%. The analysis demonstrates complementary\ncharacteristics: PBT effectively detects performance issues and edge cases\nthrough extensive input space exploration, while EBT effectively detects\nspecific boundary conditions and special patterns. These findings suggest that\na hybrid approach leveraging both testing methods can improve the reliability\nof LLM-generated code, providing guidance for test generation strategies in\nLLM-based code generation.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u57fa\u4e8e\u5c5e\u6027\u7684\u6d4b\u8bd5(PBT)\u548c\u57fa\u4e8e\u793a\u4f8b\u7684\u6d4b\u8bd5(EBT)\u5728\u68c0\u6d4bLLM\u751f\u6210\u4ee3\u7801\u8fb9\u7f18\u6848\u4f8b\u65b9\u9762\u7684\u6548\u679c\uff0c\u53d1\u73b0\u4e24\u8005\u7ed3\u5408\u80fd\u63d0\u9ad881.25%\u7684\u7f3a\u9677\u68c0\u6d4b\u7387\u3002", "motivation": "\u968f\u7740LLM\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u751f\u6210\u4ee3\u7801\u7684\u666e\u53ca\uff0c\u786e\u4fddLLM\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u53d8\u5f97\u91cd\u8981\u3002\u4f20\u7edf\u57fa\u4e8e\u793a\u4f8b\u7684\u6d4b\u8bd5\u65b9\u6cd5\u7ecf\u5e38\u9057\u6f0f\u8fb9\u7f18\u6848\u4f8b\u3002", "method": "\u5206\u679016\u4e2aHumanEval\u95ee\u9898\uff0c\u4f7f\u7528Claude-4-sonnet\u751f\u6210PBT\u548cEBT\u6d4b\u8bd5\u4ee3\u7801\uff0c\u6bd4\u8f83\u4e24\u79cd\u65b9\u6cd5\u5728\u68c0\u6d4b\u8fb9\u7f18\u6848\u4f8b\u65b9\u9762\u7684\u6548\u679c\u3002", "result": "\u5355\u72ec\u4f7f\u7528PBT\u6216EBT\u7684\u7f3a\u9677\u68c0\u6d4b\u7387\u4e3a68.75%\uff0c\u4f46\u4e24\u8005\u7ed3\u5408\u540e\u68c0\u6d4b\u7387\u63d0\u5347\u81f381.25%\u3002PBT\u64c5\u957f\u68c0\u6d4b\u6027\u80fd\u95ee\u9898\u548c\u8fb9\u7f18\u6848\u4f8b\uff0cEBT\u64c5\u957f\u68c0\u6d4b\u7279\u5b9a\u8fb9\u754c\u6761\u4ef6\u548c\u7279\u6b8a\u6a21\u5f0f\u3002", "conclusion": "\u7ed3\u5408PBT\u548cEBT\u7684\u6df7\u5408\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8LLM\u751f\u6210\u4ee3\u7801\u7684\u53ef\u9760\u6027\uff0c\u4e3aLLM\u4ee3\u7801\u751f\u6210\u7684\u6d4b\u8bd5\u7b56\u7565\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2510.25470", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25470", "abs": "https://arxiv.org/abs/2510.25470", "authors": ["Parick Ozoh", "John K Omoniyi", "Bukola Ibitoye"], "title": "An In-Depth Analysis of Cyber Attacks in Secured Platforms", "comment": null, "summary": "There is an increase in global malware threats. To address this, an\nencryption-type ransomware has been introduced on the Android operating system.\nThe challenges associated with malicious threats in phone use have become a\npressing issue in mobile communication, disrupting user experiences and posing\nsignificant privacy threats. This study surveys commonly used machine learning\ntechniques for detecting malicious threats in phones and examines their\nperformance. The majority of past research focuses on customer feedback and\nreviews, with concerns that people might create false reviews to promote or\ndevalue products and services for personal gain. Hence, the development of\ntechniques for detecting malicious threats using machine learning has been a\nkey focus. This paper presents a comprehensive comparative study of current\nresearch on the issue of malicious threats and methods for tackling these\nchallenges. Nevertheless, a huge amount of information is required by these\nmethods, presenting a challenge for developing robust, specialized automated\nanti-malware systems. This research describes the Android Applications dataset,\nand the accuracy of the techniques is measured using the accuracy levels of the\nmetrics employed in this study.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86Android\u7cfb\u7edf\u4e2d\u6076\u610f\u5a01\u80c1\u68c0\u6d4b\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5e76\u6307\u51fa\u5f53\u524d\u65b9\u6cd5\u9762\u4e34\u6570\u636e\u9700\u6c42\u91cf\u5927\u3001\u96be\u4ee5\u5f00\u53d1\u4e13\u95e8\u5316\u53cd\u6076\u610f\u8f6f\u4ef6\u7cfb\u7edf\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5168\u7403\u6076\u610f\u8f6f\u4ef6\u5a01\u80c1\u589e\u52a0\uff0c\u7279\u522b\u662fAndroid\u7cfb\u7edf\u4e0a\u7684\u52a0\u5bc6\u578b\u52d2\u7d22\u8f6f\u4ef6\uff0c\u624b\u673a\u6076\u610f\u5a01\u80c1\u5df2\u6210\u4e3a\u79fb\u52a8\u901a\u4fe1\u4e2d\u7684\u7d27\u8feb\u95ee\u9898\uff0c\u7834\u574f\u7528\u6237\u4f53\u9a8c\u5e76\u6784\u6210\u4e25\u91cd\u9690\u79c1\u5a01\u80c1\u3002", "method": "\u8c03\u67e5\u4e86\u5e38\u7528\u7684\u624b\u673a\u6076\u610f\u5a01\u80c1\u68c0\u6d4b\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5e76\u68c0\u9a8c\u5176\u6027\u80fd\u3002\u4f7f\u7528Android\u5e94\u7528\u7a0b\u5e8f\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u51c6\u786e\u7387\u7b49\u5ea6\u91cf\u6807\u51c6\u6765\u8bc4\u4f30\u6280\u672f\u6548\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5927\u591a\u6570\u73b0\u6709\u7814\u7a76\u5173\u6ce8\u5ba2\u6237\u53cd\u9988\u548c\u8bc4\u8bba\uff0c\u4f46\u8fd9\u4e9b\u53ef\u80fd\u5305\u542b\u865a\u5047\u8bc4\u8bba\u3002\u673a\u5668\u5b66\u4e60\u6280\u672f\u88ab\u8bc1\u660e\u53ef\u7528\u4e8e\u68c0\u6d4b\u6076\u610f\u5a01\u80c1\uff0c\u4f46\u9700\u8981\u5927\u91cf\u4fe1\u606f\u3002", "conclusion": "\u867d\u7136\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u6076\u610f\u5a01\u80c1\u68c0\u6d4b\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5f00\u53d1\u7a33\u5065\u3001\u4e13\u95e8\u5316\u7684\u81ea\u52a8\u5316\u53cd\u6076\u610f\u8f6f\u4ef6\u7cfb\u7edf\u4ecd\u9762\u4e34\u6570\u636e\u9700\u6c42\u91cf\u5927\u7b49\u6311\u6218\u3002"}}
{"id": "2510.25206", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.25206", "abs": "https://arxiv.org/abs/2510.25206", "authors": ["Tianqianjin Lin", "Xi Zhao", "Xingyao Zhang", "Rujiao Long", "Yi Xu", "Zhuoren Jiang", "Wenbo Su", "Bo Zheng"], "title": "RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models", "comment": "17 pages, 11 figures", "summary": "Reinforcement learning (RL) can refine the reasoning abilities of large\nlanguage models (LLMs), but critically depends on a key prerequisite: the LLM\ncan already generate high-utility reasoning paths with non-negligible\nprobability. For tasks beyond the LLM's current competence, such reasoning path\ncan be hard to sample, and learning risks reinforcing familiar but suboptimal\nreasoning. We are motivated by the insight from cognitive science that Why is\nthis the answer is often an easier question than What is the answer, as it\navoids the heavy cognitive load of open-ended exploration, opting instead for\nexplanatory reconstruction-systematically retracing the reasoning that links a\nquestion to its answer. We show that LLMs can similarly leverage answers to\nderive high-quality reasoning paths. We formalize this phenomenon and prove\nthat conditioning on answer provably increases the expected utility of sampled\nreasoning paths, thereby transforming intractable problems into learnable ones.\nBuilding on this insight, we introduce RAVR (Reference-Answer-guided\nVariational Reasoning), an end-to-end framework that uses answer-conditioned\nreasoning as a variational surrogate for question-only reasoning. Experiments\nin both general and math domains demonstrate consistent improvements over\nstrong baselines. We further analyze the reasoning behavior and find that RAVR\nreduces hesitation, strengthens conclusion consolidation, and promotes\nproblem-specific strategies in reasoning.", "AI": {"tldr": "\u63d0\u51faRAVR\u6846\u67b6\uff0c\u5229\u7528\u7b54\u6848\u5f15\u5bfc\u7684\u63a8\u7406\u4f5c\u4e3a\u53d8\u5206\u4ee3\u7406\uff0c\u901a\u8fc7\u6761\u4ef6\u5316\u7b54\u6848\u6765\u63d0\u5347\u63a8\u7406\u8def\u5f84\u8d28\u91cf\uff0c\u89e3\u51b3LLM\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u96be\u4ee5\u91c7\u6837\u9ad8\u8d28\u91cf\u63a8\u7406\u8def\u5f84\u7684\u95ee\u9898\u3002", "motivation": "\u5f53LLM\u65e0\u6cd5\u751f\u6210\u9ad8\u8d28\u91cf\u63a8\u7406\u8def\u5f84\u65f6\uff0c\u5f3a\u5316\u5b66\u4e60\u4f1a\u5f3a\u5316\u6b21\u4f18\u63a8\u7406\u3002\u53d7\u8ba4\u77e5\u79d1\u5b66\u542f\u53d1\uff0c\"\u4e3a\u4ec0\u4e48\u662f\u8fd9\u4e2a\u7b54\u6848\"\u6bd4\"\u7b54\u6848\u662f\u4ec0\u4e48\"\u66f4\u5bb9\u6613\u56de\u7b54\uff0c\u56e0\u4e3a\u907f\u514d\u4e86\u5f00\u653e\u5f0f\u63a2\u7d22\u7684\u8ba4\u77e5\u8d1f\u62c5\u3002", "method": "\u5f15\u5165RAVR\u6846\u67b6\uff0c\u4f7f\u7528\u7b54\u6848\u6761\u4ef6\u5316\u63a8\u7406\u4f5c\u4e3a\u95ee\u9898\u63a8\u7406\u7684\u53d8\u5206\u4ee3\u7406\uff0c\u901a\u8fc7\u6761\u4ef6\u5316\u7b54\u6848\u6765\u63d0\u5347\u63a8\u7406\u8def\u5f84\u7684\u671f\u671b\u6548\u7528\u3002", "result": "\u5728\u901a\u7528\u548c\u6570\u5b66\u9886\u57df\u7684\u5b9e\u9a8c\u4e2d\uff0cRAVR\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u6a21\u578b\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6539\u8fdb\uff0c\u51cf\u5c11\u4e86\u72b9\u8c6b\uff0c\u52a0\u5f3a\u4e86\u7ed3\u8bba\u6574\u5408\uff0c\u5e76\u4fc3\u8fdb\u4e86\u95ee\u9898\u7279\u5b9a\u7b56\u7565\u3002", "conclusion": "\u7b54\u6848\u5f15\u5bfc\u7684\u63a8\u7406\u80fd\u591f\u6709\u6548\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5c06\u96be\u4ee5\u5904\u7406\u7684\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u5b66\u4e60\u7684\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25406", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25406", "abs": "https://arxiv.org/abs/2510.25406", "authors": ["Changjie Wang", "Mariano Scazzariello", "Anoud Alshnaka", "Roberto Guanciale", "Dejan Kosti\u0107", "Marco Chiesa"], "title": "Dissect-and-Restore: AI-based Code Verification with Transient Refactoring", "comment": null, "summary": "Formal verification is increasingly recognized as a critical foundation for\nbuilding reliable software systems. However, the need for specialized expertise\nto write precise specifications, navigate complex proof obligations, and learn\nannotations often makes verification an order of magnitude more expensive than\nimplementation. While modern AI systems can recognize patterns in mathematical\nproofs and interpret natural language, effectively integrating them into the\nformal verification process remains an open challenge. We present Prometheus, a\nnovel AI-assisted system that facilitates automated code verification with\ncurrent AI capabilities in conjunction with modular software engineering\nprinciples (e.g., modular refactoring). Our approach begins by decomposing\ncomplex program logic, such as nested loops, into smaller, verifiable\ncomponents. Once verified, these components are recomposed to construct a proof\nof the original program. This decomposition-recomposition workflow is\nnon-trivial. Prometheus addresses this by guiding the proof search through\nstructured decomposition of complex lemmas into smaller, verifiable sub-lemmas.\nWhen automated tools are insufficient, users can provide lightweight natural\nlanguage guidance to steer the proof process effectively. Our evaluation\ndemonstrates that transiently applying modular restructuring to the code\nsubstantially improves the AI's effectiveness in verifying individual\ncomponents. This approach successfully verifies 86% of tasks in our curated\ndataset, compared to 68% for the baseline. Gains are more pronounced with\nincreasing specification complexity, improving from 30% to 69%, and when\nintegrating proof outlines for complex programs, from 25% to 87%.", "AI": {"tldr": "Prometheus\u662f\u4e00\u4e2aAI\u8f85\u52a9\u7684\u81ea\u52a8\u5316\u4ee3\u7801\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u91cd\u6784\u5c06\u590d\u6742\u7a0b\u5e8f\u5206\u89e3\u4e3a\u53ef\u9a8c\u8bc1\u7684\u5c0f\u7ec4\u4ef6\uff0c\u7136\u540e\u91cd\u65b0\u7ec4\u5408\u6784\u5efa\u5b8c\u6574\u8bc1\u660e\uff0c\u663e\u8457\u63d0\u9ad8\u9a8c\u8bc1\u6210\u529f\u7387\u3002", "motivation": "\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5bf9\u4e8e\u6784\u5efa\u53ef\u9760\u8f6f\u4ef6\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u4e14\u6210\u672c\u9ad8\u6602\u3002\u73b0\u4ee3AI\u7cfb\u7edf\u80fd\u591f\u8bc6\u522b\u6570\u5b66\u8bc1\u660e\u6a21\u5f0f\u548c\u7406\u89e3\u81ea\u7136\u8bed\u8a00\uff0c\u4f46\u5982\u4f55\u6709\u6548\u6574\u5408\u5230\u5f62\u5f0f\u5316\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u91c7\u7528\u5206\u89e3-\u91cd\u7ec4\u5de5\u4f5c\u6d41\uff1a\u9996\u5148\u5c06\u590d\u6742\u7a0b\u5e8f\u903b\u8f91\uff08\u5982\u5d4c\u5957\u5faa\u73af\uff09\u5206\u89e3\u4e3a\u66f4\u5c0f\u3001\u53ef\u9a8c\u8bc1\u7684\u7ec4\u4ef6\uff1b\u9a8c\u8bc1\u540e\u91cd\u65b0\u7ec4\u5408\u6784\u5efa\u539f\u59cb\u7a0b\u5e8f\u7684\u8bc1\u660e\u3002\u7cfb\u7edf\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u89e3\u590d\u6742\u5f15\u7406\u4e3a\u53ef\u9a8c\u8bc1\u5b50\u5f15\u7406\u6765\u6307\u5bfc\u8bc1\u660e\u641c\u7d22\uff0c\u7528\u6237\u53ef\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u6307\u5bfc\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u4e34\u65f6\u5e94\u7528\u6a21\u5757\u5316\u91cd\u6784\u663e\u8457\u63d0\u9ad8\u4e86AI\u9a8c\u8bc1\u5355\u4e2a\u7ec4\u4ef6\u7684\u6548\u679c\uff1a\u5728\u7cbe\u9009\u6570\u636e\u96c6\u4e2d\u6210\u529f\u9a8c\u8bc186%\u7684\u4efb\u52a1\uff08\u57fa\u7ebf\u4e3a68%\uff09\uff1b\u968f\u7740\u89c4\u8303\u590d\u6742\u6027\u589e\u52a0\uff0c\u6210\u529f\u7387\u4ece30%\u63d0\u5347\u523069%\uff1b\u96c6\u6210\u590d\u6742\u7a0b\u5e8f\u8bc1\u660e\u5927\u7eb2\u65f6\uff0c\u4ece25%\u63d0\u5347\u523087%\u3002", "conclusion": "Prometheus\u901a\u8fc7\u7ed3\u5408AI\u80fd\u529b\u548c\u6a21\u5757\u5316\u8f6f\u4ef6\u5de5\u7a0b\u539f\u5219\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u5316\u4ee3\u7801\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25472", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.25472", "abs": "https://arxiv.org/abs/2510.25472", "authors": ["Zheng Zhang", "Guanlong Wu", "Sen Deng", "Shuai Wang", "Yinqian Zhang"], "title": "NetEcho: From Real-World Streaming Side-Channels to Full LLM Conversation Recovery", "comment": null, "summary": "In the rapidly expanding landscape of Large Language Model (LLM)\napplications, real-time output streaming has become the dominant interaction\nparadigm. While this enhances user experience, recent research reveals that it\nexposes a non-trivial attack surface through network side-channels. Adversaries\ncan exploit patterns in encrypted traffic to infer sensitive information and\nreconstruct private conversations. In response, LLM providers and third-party\nservices are deploying defenses such as traffic padding and obfuscation to\nmitigate these vulnerabilities.\n  This paper starts by presenting a systematic analysis of contemporary\nside-channel defenses in mainstream LLM applications, with a focus on services\nfrom vendors like OpenAI and DeepSeek. We identify and examine seven\nrepresentative deployment scenarios, each incorporating active/passive\nmitigation techniques. Despite these enhanced security measures, our\ninvestigation uncovers significant residual information that remains vulnerable\nto leakage within the network traffic.\n  Building on this discovery, we introduce NetEcho, a novel, LLM-based\nframework that comprehensively unleashes the network side-channel risks of\ntoday's LLM applications. NetEcho is designed to recover entire conversations\n-- including both user prompts and LLM responses -- directly from encrypted\nnetwork traffic. It features a deliberate design that ensures high-fidelity\ntext recovery, transferability across different deployment scenarios, and\nmoderate operational cost. In our evaluations on medical and legal applications\nbuilt upon leading models like DeepSeek-v3 and GPT-4o, NetEcho can recover avg\n$\\sim$70\\% information of each conversation, demonstrating a critical\nlimitation in current defense mechanisms. We conclude by discussing the\nimplications of our findings and proposing future directions for augmenting\nnetwork traffic security.", "AI": {"tldr": "NetEcho\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u52a0\u5bc6\u7f51\u7edc\u6d41\u91cf\u4e2d\u6062\u590dLLM\u5e94\u7528\u4e2d\u7684\u5b8c\u6574\u5bf9\u8bdd\u5185\u5bb9\uff0c\u5373\u4f7f\u5728\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u4e0b\u4ecd\u80fd\u6062\u590d\u7ea670%\u7684\u5bf9\u8bdd\u4fe1\u606f\u3002", "motivation": "\u968f\u7740LLM\u5e94\u7528\u5b9e\u65f6\u8f93\u51fa\u6d41\u6210\u4e3a\u4e3b\u6d41\u4ea4\u4e92\u6a21\u5f0f\uff0c\u7814\u7a76\u53d1\u73b0\u7f51\u7edc\u4fa7\u4fe1\u9053\u66b4\u9732\u4e86\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u52a0\u5bc6\u6d41\u91cf\u6a21\u5f0f\u63a8\u65ad\u654f\u611f\u4fe1\u606f\u5e76\u91cd\u5efa\u79c1\u4eba\u5bf9\u8bdd\u3002", "method": "\u9996\u5148\u7cfb\u7edf\u5206\u6790\u4e3b\u6d41LLM\u5e94\u7528\u7684\u4fa7\u4fe1\u9053\u9632\u5fa1\u63aa\u65bd\uff0c\u7136\u540e\u5f00\u53d1NetEcho\u6846\u67b6\uff0c\u5229\u7528LLM\u6280\u672f\u4ece\u52a0\u5bc6\u7f51\u7edc\u6d41\u91cf\u4e2d\u9ad8\u4fdd\u771f\u5730\u6062\u590d\u7528\u6237\u63d0\u793a\u548cLLM\u54cd\u5e94\u3002", "result": "\u5728\u533b\u7597\u548c\u6cd5\u5f8b\u5e94\u7528\u7684\u8bc4\u4f30\u4e2d\uff0cNetEcho\u80fd\u591f\u4eceDeepSeek-v3\u548cGPT-4o\u7b49\u9886\u5148\u6a21\u578b\u7684\u52a0\u5bc6\u6d41\u91cf\u4e2d\u5e73\u5747\u6062\u590d\u7ea670%\u7684\u5bf9\u8bdd\u4fe1\u606f\u3002", "conclusion": "\u5f53\u524d\u9632\u5fa1\u673a\u5236\u5b58\u5728\u5173\u952e\u5c40\u9650\u6027\uff0c\u9700\u8981\u52a0\u5f3a\u7f51\u7edc\u6d41\u91cf\u5b89\u5168\u4ee5\u5e94\u5bf9\u4fa7\u4fe1\u9053\u653b\u51fb\u98ce\u9669\u3002"}}
{"id": "2510.25223", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25223", "abs": "https://arxiv.org/abs/2510.25223", "authors": ["Kun ouyang", "Haoyu Wang", "Dong Fang"], "title": "FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data", "comment": "14 pages, 11 figures", "summary": "Event log data, recording fine-grained user actions and system events,\nrepresent one of the most valuable assets for modern digital services. However,\nthe complexity and heterogeneity of industrial event logs--characterized by\nlarge scale, high dimensionality, diverse data types, and intricate temporal or\nrelational structures--make feature engineering extremely challenging. Existing\nautomatic feature engineering approaches, such as AutoML or genetic methods,\noften suffer from limited explainability, rigid predefined operations, and poor\nadaptability to complicated heterogeneous data. In this paper, we propose FELA\n(Feature Engineering LLM Agents), a multi-agent evolutionary system that\nautonomously extracts meaningful and high-performing features from complex\nindustrial event log data. FELA integrates the reasoning and coding\ncapabilities of large language models (LLMs) with an insight-guided\nself-evolution paradigm. Specifically, FELA employs specialized agents--Idea\nAgents, Code Agents, and Critic Agents--to collaboratively generate, validate,\nand implement novel feature ideas. An Evaluation Agent summarizes feedback and\nupdates a hierarchical knowledge base and dual-memory system to enable\ncontinual improvement. Moreover, FELA introduces an agentic evolution\nalgorithm, combining reinforcement learning and genetic algorithm principles to\nbalance exploration and exploitation across the idea space. Extensive\nexperiments on real industrial datasets demonstrate that FELA can generate\nexplainable, domain-relevant features that significantly improve model\nperformance while reducing manual effort. Our results highlight the potential\nof LLM-based multi-agent systems as a general framework for automated,\ninterpretable, and adaptive feature engineering in complex real-world\nenvironments.", "AI": {"tldr": "FELA\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u4ee3\u7406\u8fdb\u5316\u7cfb\u7edf\uff0c\u7528\u4e8e\u4ece\u590d\u6742\u7684\u5de5\u4e1a\u4e8b\u4ef6\u65e5\u5fd7\u6570\u636e\u4e2d\u81ea\u52a8\u63d0\u53d6\u9ad8\u6027\u80fd\u7279\u5f81\u3002\u5b83\u7ed3\u5408\u4e86LLM\u7684\u63a8\u7406\u7f16\u7801\u80fd\u529b\u548c\u6d1e\u5bdf\u5f15\u5bfc\u7684\u81ea\u8fdb\u5316\u8303\u5f0f\uff0c\u901a\u8fc7\u4e13\u95e8\u4ee3\u7406\u534f\u4f5c\u751f\u6210\u3001\u9a8c\u8bc1\u548c\u5b9e\u65bd\u7279\u5f81\u521b\u610f\u3002", "motivation": "\u5de5\u4e1a\u4e8b\u4ef6\u65e5\u5fd7\u6570\u636e\u5177\u6709\u5927\u89c4\u6a21\u3001\u9ad8\u7ef4\u5ea6\u3001\u5f02\u6784\u6570\u636e\u7b49\u590d\u6742\u6027\uff0c\u73b0\u6709\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u5dee\u3001\u64cd\u4f5c\u50f5\u5316\u3001\u9002\u5e94\u6027\u5f31\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u4ee3\u7406\u7cfb\u7edf\uff08\u521b\u610f\u4ee3\u7406\u3001\u4ee3\u7801\u4ee3\u7406\u3001\u6279\u8bc4\u4ee3\u7406\u3001\u8bc4\u4f30\u4ee3\u7406\uff09\u534f\u4f5c\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u9057\u4f20\u7b97\u6cd5\u539f\u7406\u7684\u4ee3\u7406\u8fdb\u5316\u7b97\u6cd5\uff0c\u4ee5\u53ca\u5206\u5c42\u77e5\u8bc6\u5e93\u548c\u53cc\u8bb0\u5fc6\u7cfb\u7edf\u5b9e\u73b0\u6301\u7eed\u6539\u8fdb\u3002", "result": "\u5728\u771f\u5b9e\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFELA\u80fd\u751f\u6210\u53ef\u89e3\u91ca\u3001\u9886\u57df\u76f8\u5173\u7684\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u5e76\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u6709\u671b\u6210\u4e3a\u590d\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\u81ea\u52a8\u5316\u3001\u53ef\u89e3\u91ca\u548c\u81ea\u9002\u5e94\u7279\u5f81\u5de5\u7a0b\u7684\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2510.25423", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25423", "abs": "https://arxiv.org/abs/2510.25423", "authors": ["Ali Asgari", "Annibale Panichella", "Pouria Derakhshanfar", "Mitchell Olsthoorn"], "title": "What Challenges Do Developers Face in AI Agent Systems? An Empirical Study on Stack Overflow", "comment": "12 pages, 4 Figures", "summary": "AI agents have rapidly gained popularity across research and industry as\nsystems that extend large language models with additional capabilities to plan,\nuse tools, remember, and act toward specific goals. Yet despite their promise,\ndevelopers face persistent and often underexplored challenges when building,\ndeploying, and maintaining these emerging systems. To identify these\nchallenges, we study developer discussions on Stack Overflow, the world's\nlargest developer-focused Q and A platform with about 60 million questions and\nanswers and 30 million users. We construct a taxonomy of developer challenges\nthrough tag expansion and filtering, apply LDA-MALLET for topic modeling, and\nmanually validate and label the resulting themes. Our analysis reveals seven\nmajor areas of recurring issues encompassing 77 distinct technical challenges\nrelated to runtime integration, dependency management, orchestration\ncomplexity, and evaluation reliability. We further quantify topic popularity\nand difficulty to identify which issues are most common and hardest to resolve,\nmap the tools and programming languages used in agent development, and track\ntheir evolution from 2021 to 2025 in relation to major AI model and framework\nreleases. Finally, we present the implications of our results, offering\nconcrete guidance for practitioners, researchers, and educators on agent\nreliability and developer support.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u6790Stack Overflow\u4e0a\u7684\u5f00\u53d1\u8005\u8ba8\u8bba\uff0c\u8bc6\u522b\u4e86AI\u4ee3\u7406\u5f00\u53d1\u4e2d\u768477\u4e2a\u6280\u672f\u6311\u6218\uff0c\u6db5\u76d6\u8fd0\u884c\u65f6\u96c6\u6210\u3001\u4f9d\u8d56\u7ba1\u7406\u3001\u7f16\u6392\u590d\u6742\u6027\u548c\u8bc4\u4f30\u53ef\u9760\u6027\u7b497\u5927\u9886\u57df\uff0c\u5e76\u91cf\u5316\u4e86\u95ee\u9898\u7684\u6d41\u884c\u5ea6\u548c\u96be\u5ea6\u3002", "motivation": "AI\u4ee3\u7406\u867d\u7136\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u5f00\u53d1\u8005\u5728\u6784\u5efa\u3001\u90e8\u7f72\u548c\u7ef4\u62a4\u8fd9\u4e9b\u7cfb\u7edf\u65f6\u9762\u4e34\u6301\u7eed\u4e14\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u8bc6\u522b\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6807\u7b7e\u6269\u5c55\u548c\u8fc7\u6ee4\u6784\u5efa\u6311\u6218\u5206\u7c7b\u6cd5\uff0c\u5e94\u7528LDA-MALLET\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\uff0c\u5e76\u624b\u52a8\u9a8c\u8bc1\u548c\u6807\u6ce8\u7ed3\u679c\u4e3b\u9898\uff0c\u5206\u67902021-2025\u5e74\u7684\u6570\u636e\u6f14\u53d8\u3002", "result": "\u8bc6\u522b\u51fa7\u5927\u9886\u57df\u768477\u4e2a\u6280\u672f\u6311\u6218\uff0c\u91cf\u5316\u4e86\u4e3b\u9898\u6d41\u884c\u5ea6\u548c\u89e3\u51b3\u96be\u5ea6\uff0c\u7ed8\u5236\u4e86\u4ee3\u7406\u5f00\u53d1\u4f7f\u7528\u7684\u5de5\u5177\u548c\u7f16\u7a0b\u8bed\u8a00\u56fe\u8c31\uff0c\u5e76\u8ddf\u8e2a\u4e86\u5176\u4e0e\u4e3b\u8981AI\u6a21\u578b\u548c\u6846\u67b6\u53d1\u5e03\u7684\u5173\u7cfb\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4ece\u4e1a\u8005\u3001\u7814\u7a76\u4eba\u5458\u548c\u6559\u80b2\u5de5\u4f5c\u8005\u63d0\u4f9b\u4e86\u5173\u4e8e\u4ee3\u7406\u53ef\u9760\u6027\u548c\u5f00\u53d1\u8005\u652f\u6301\u7684\u5177\u4f53\u6307\u5bfc\u3002"}}
{"id": "2510.25477", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.25477", "abs": "https://arxiv.org/abs/2510.25477", "authors": ["Yi Chen", "Bin Chen", "Peichang Zhang", "Da Che"], "title": "A Study on Privacy-Preserving Scholarship Evaluation Based on Decentralized Identity and Zero-Knowledge Proofs", "comment": null, "summary": "Traditional centralized scholarship evaluation processes typically require\nstudents to submit detailed academic records and qualification information,\nwhich exposes them to risks of data leakage and misuse, making it difficult to\nsimultaneously ensure privacy protection and transparent auditability. To\naddress these challenges, this paper proposes a scholarship evaluation system\nbased on Decentralized Identity (DID) and Zero-Knowledge Proofs (ZKP). The\nsystem aggregates multidimensional ZKPs off-chain, and smart contracts verify\ncompliance with evaluation criteria without revealing raw scores or\ncomputational details. Experimental results demonstrate that the proposed\nsolution not only automates the evaluation efficiently but also maximally\npreserves student privacy and data integrity, offering a practical and\ntrustworthy technical paradigm for higher education scholarship programs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684\u5956\u5b66\u91d1\u8bc4\u4f30\u7cfb\u7edf\uff0c\u89e3\u51b3\u4f20\u7edf\u96c6\u4e2d\u5f0f\u8bc4\u4f30\u4e2d\u7684\u6570\u636e\u9690\u79c1\u6cc4\u9732\u548c\u900f\u660e\u5ea6\u4e0d\u8db3\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u96c6\u4e2d\u5f0f\u5956\u5b66\u91d1\u8bc4\u4f30\u9700\u8981\u5b66\u751f\u63d0\u4ea4\u8be6\u7ec6\u5b66\u672f\u8bb0\u5f55\uff0c\u5b58\u5728\u6570\u636e\u6cc4\u9732\u548c\u6ee5\u7528\u7684\u98ce\u9669\uff0c\u96be\u4ee5\u540c\u65f6\u4fdd\u8bc1\u9690\u79c1\u4fdd\u62a4\u548c\u900f\u660e\u5ba1\u8ba1\u3002", "method": "\u7cfb\u7edf\u5728\u94fe\u4e0b\u805a\u5408\u591a\u7ef4\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u667a\u80fd\u5408\u7ea6\u9a8c\u8bc1\u8bc4\u4f30\u6807\u51c6\u5408\u89c4\u6027\u800c\u4e0d\u66b4\u9732\u539f\u59cb\u5206\u6570\u6216\u8ba1\u7b97\u7ec6\u8282\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6848\u80fd\u9ad8\u6548\u81ea\u52a8\u5316\u8bc4\u4f30\uff0c\u540c\u65f6\u6700\u5927\u7a0b\u5ea6\u4fdd\u62a4\u5b66\u751f\u9690\u79c1\u548c\u6570\u636e\u5b8c\u6574\u6027\u3002", "conclusion": "\u4e3a\u9ad8\u7b49\u6559\u80b2\u5956\u5b66\u91d1\u9879\u76ee\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u4fe1\u8d56\u7684\u6280\u672f\u8303\u5f0f\u3002"}}
{"id": "2510.25232", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25232", "abs": "https://arxiv.org/abs/2510.25232", "authors": ["Tianxi Wan", "Jiaming Luo", "Siyuan Chen", "Kunyao Lan", "Jianhua Chen", "Haiyang Geng", "Mengyue Wu"], "title": "From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity", "comment": null, "summary": "Psychiatric comorbidity is clinically significant yet challenging due to the\ncomplexity of multiple co-occurring disorders. To address this, we develop a\nnovel approach integrating synthetic patient electronic medical record (EMR)\nconstruction and multi-agent diagnostic dialogue generation. We create 502\nsynthetic EMRs for common comorbid conditions using a pipeline that ensures\nclinical relevance and diversity. Our multi-agent framework transfers the\nclinical interview protocol into a hierarchical state machine and context tree,\nsupporting over 130 diagnostic states while maintaining clinical standards.\nThrough this rigorous process, we construct PsyCoTalk, the first large-scale\ndialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic\ndialogues validated by psychiatrists. This dataset enhances diagnostic accuracy\nand treatment planning, offering a valuable resource for psychiatric\ncomorbidity research. Compared to real-world clinical transcripts, PsyCoTalk\nexhibits high structural and linguistic fidelity in terms of dialogue length,\ntoken distribution, and diagnostic reasoning strategies. Licensed psychiatrists\nconfirm the realism and diagnostic validity of the dialogues. This dataset\nenables the development and evaluation of models capable of multi-disorder\npsychiatric screening in a single conversational pass.", "AI": {"tldr": "\u5f00\u53d1\u4e86PsyCoTalk\uff0c\u9996\u4e2a\u652f\u6301\u5171\u75c5\u8bca\u65ad\u7684\u5927\u89c4\u6a21\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u5305\u542b3000\u4e2a\u591a\u8f6e\u8bca\u65ad\u5bf9\u8bdd\uff0c\u901a\u8fc7\u5408\u6210\u7535\u5b50\u75c5\u5386\u548c\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6784\u5efa\uff0c\u7ecf\u7cbe\u795e\u79d1\u533b\u751f\u9a8c\u8bc1\u5177\u6709\u4e34\u5e8a\u771f\u5b9e\u6027\u3002", "motivation": "\u7cbe\u795e\u75be\u75c5\u5171\u75c5\u5177\u6709\u4e34\u5e8a\u91cd\u8981\u6027\u4f46\u8bca\u65ad\u590d\u6742\uff0c\u9700\u8981\u5904\u7406\u591a\u79cd\u5171\u5b58\u7684\u969c\u788d\uff0c\u73b0\u6709\u8d44\u6e90\u4e0d\u8db3\u652f\u6301\u591a\u969c\u788d\u540c\u65f6\u7b5b\u67e5\u3002", "method": "\u96c6\u6210\u5408\u6210\u60a3\u8005\u7535\u5b50\u75c5\u5386\u6784\u5efa\u548c\u591a\u667a\u80fd\u4f53\u8bca\u65ad\u5bf9\u8bdd\u751f\u6210\uff0c\u521b\u5efa502\u4e2a\u5408\u6210EMR\uff0c\u5c06\u4e34\u5e8a\u8bbf\u8c08\u534f\u8bae\u8f6c\u5316\u4e3a\u5206\u5c42\u72b6\u6001\u673a\u548c\u4e0a\u4e0b\u6587\u6811\uff0c\u652f\u6301130\u591a\u4e2a\u8bca\u65ad\u72b6\u6001\u3002", "result": "\u6784\u5efa\u4e863000\u4e2a\u591a\u8f6e\u8bca\u65ad\u5bf9\u8bdd\uff0c\u76f8\u6bd4\u771f\u5b9e\u4e34\u5e8a\u8bb0\u5f55\u5728\u5bf9\u8bdd\u957f\u5ea6\u3001\u6807\u8bb0\u5206\u5e03\u548c\u8bca\u65ad\u63a8\u7406\u7b56\u7565\u65b9\u9762\u5177\u6709\u9ad8\u4fdd\u771f\u5ea6\uff0c\u7cbe\u795e\u79d1\u533b\u751f\u786e\u8ba4\u5176\u771f\u5b9e\u6027\u548c\u8bca\u65ad\u6709\u6548\u6027\u3002", "conclusion": "PsyCoTalk\u6570\u636e\u96c6\u63d0\u9ad8\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u548c\u6cbb\u7597\u89c4\u5212\uff0c\u4e3a\u7cbe\u795e\u75be\u75c5\u5171\u75c5\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\uff0c\u652f\u6301\u5728\u5355\u6b21\u5bf9\u8bdd\u4e2d\u5f00\u53d1\u548c\u8bc4\u4f30\u591a\u969c\u788d\u7b5b\u67e5\u6a21\u578b\u3002"}}
{"id": "2510.25506", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25506", "abs": "https://arxiv.org/abs/2510.25506", "authors": ["Florian Angermeir", "Maximilian Amougou", "Mark Kreitz", "Andreas Bauer", "Matthias Linhuber", "Davide Fucci", "Fabiola Moy\u00f3n C.", "Daniel Mendez", "Tony Gorschek"], "title": "Reflections on the Reproducibility of Commercial LLM Performance in Empirical Software Engineering Studies", "comment": null, "summary": "Large Language Models have gained remarkable interest in industry and\nacademia. The increasing interest in LLMs in academia is also reflected in the\nnumber of publications on this topic over the last years. For instance, alone\n78 of the around 425 publications at ICSE 2024 performed experiments with LLMs.\nConducting empirical studies with LLMs remains challenging and raises questions\non how to achieve reproducible results, for both other researchers and\npractitioners. One important step towards excelling in empirical research on\nLLMs and their application is to first understand to what extent current\nresearch results are eventually reproducible and what factors may impede\nreproducibility. This investigation is within the scope of our work. We\ncontribute an analysis of the reproducibility of LLM-centric studies, provide\ninsights into the factors impeding reproducibility, and discuss suggestions on\nhow to improve the current state. In particular, we studied the 86 articles\ndescribing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 86\narticles, 18 provided research artefacts and used OpenAI models. We attempted\nto replicate those 18 studies. Of the 18 studies, only five were fit for\nreproduction. For none of the five studies, we were able to fully reproduce the\nresults. Two studies seemed to be partially reproducible, and three studies did\nnot seem to be reproducible. Our results highlight not only the need for\nstricter research artefact evaluations but also for more robust study designs\nto ensure the reproducible value of future publications.", "AI": {"tldr": "\u5206\u6790\u4e86ICSE 2024\u548cASE 2024\u4f1a\u8bae\u4e0a86\u7bc7\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\u8bba\u6587\u7684\u53ef\u590d\u73b0\u6027\uff0c\u53d1\u73b0\u53ea\u67095\u9879\u7814\u7a76\u9002\u5408\u590d\u73b0\uff0c\u4f46\u65e0\u4e00\u80fd\u5b8c\u5168\u590d\u73b0\u7ed3\u679c\uff0c\u51f8\u663e\u4e86LLM\u7814\u7a76\u4e2d\u53ef\u590d\u73b0\u6027\u7684\u4e25\u91cd\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u8fdb\u884cLLM\u5b9e\u8bc1\u7814\u7a76\u9762\u4e34\u53ef\u590d\u73b0\u6027\u6311\u6218\uff0c\u9700\u8981\u4e86\u89e3\u5f53\u524d\u7814\u7a76\u6210\u679c\u7684\u53ef\u590d\u73b0\u7a0b\u5ea6\u53ca\u5176\u963b\u788d\u56e0\u7d20\u3002", "method": "\u7814\u7a76\u4e86ICSE 2024\u548cASE 2024\u4f1a\u8bae\u4e0a86\u7bc7LLM\u76f8\u5173\u8bba\u6587\uff0c\u5176\u4e2d18\u7bc7\u63d0\u4f9b\u4e86\u7814\u7a76\u6784\u4ef6\u5e76\u4f7f\u7528OpenAI\u6a21\u578b\uff0c\u5bf9\u8fd918\u9879\u7814\u7a76\u8fdb\u884c\u4e86\u590d\u73b0\u5c1d\u8bd5\u3002", "result": "18\u9879\u7814\u7a76\u4e2d\u53ea\u67095\u9879\u9002\u5408\u590d\u73b0\uff0c\u4f46\u65e0\u4e00\u80fd\u5b8c\u5168\u590d\u73b0\u7ed3\u679c\uff1a2\u9879\u90e8\u5206\u53ef\u590d\u73b0\uff0c3\u9879\u4f3c\u4e4e\u4e0d\u53ef\u590d\u73b0\u3002", "conclusion": "LLM\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u73b0\u72b6\u582a\u5fe7\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u7814\u7a76\u6784\u4ef6\u8bc4\u4f30\u548c\u66f4\u7a33\u5065\u7684\u7814\u7a76\u8bbe\u8ba1\u6765\u786e\u4fdd\u672a\u6765\u53d1\u8868\u6210\u679c\u7684\u53ef\u590d\u73b0\u4ef7\u503c\u3002"}}
{"id": "2510.25677", "categories": ["cs.CR", "cs.CL", "C.2.1; D.4.6; E.3; I.2.6; I.5.4"], "pdf": "https://arxiv.org/pdf/2510.25677", "abs": "https://arxiv.org/abs/2510.25677", "authors": ["Hasan Akgul", "Mari Eplik", "Javier Rojas", "Aina Binti Abdullah", "Pieter van der Merwe"], "title": "ZK-SenseLM: Verifiable Large-Model Wireless Sensing with Selective Abstention and Zero-Knowledge Attestation", "comment": "45 pages", "summary": "ZK-SenseLM is a secure and auditable wireless sensing framework that pairs a\nlarge-model encoder for Wi-Fi channel state information (and optionally mmWave\nradar or RFID) with a policy-grounded decision layer and end-to-end\nzero-knowledge proofs of inference. The encoder uses masked spectral\npretraining with phase-consistency regularization, plus a light cross-modal\nalignment that ties RF features to compact, human-interpretable policy tokens.\nTo reduce unsafe actions under distribution shift, we add a calibrated\nselective-abstention head; the chosen risk-coverage operating point is\nregistered and bound into the proof. We implement a four-stage proving\npipeline: (C1) feature sanity and commitment, (C2) threshold and version\nbinding, (C3) time-window binding, and (C4) PLONK-style proofs that the\nquantized network, given the committed window, produced the logged action and\nconfidence. Micro-batched proving amortizes cost across adjacent windows, and a\ngateway option offloads proofs from low-power devices. The system integrates\nwith differentially private federated learning and on-device personalization\nwithout weakening verifiability: model hashes and the registered threshold are\npart of each public statement. Across activity, presence or intrusion,\nrespiratory proxy, and RF fingerprinting tasks, ZK-SenseLM improves macro-F1\nand calibration, yields favorable coverage-risk curves under perturbations, and\nrejects tamper and replay with compact proofs and fast verification.", "AI": {"tldr": "ZK-SenseLM\u662f\u4e00\u4e2a\u5b89\u5168\u53ef\u5ba1\u8ba1\u7684\u65e0\u7ebf\u611f\u77e5\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u578b\u6a21\u578b\u7f16\u7801\u5668\u4e0e\u7b56\u7565\u51b3\u7b56\u5c42\uff0c\u63d0\u4f9b\u7aef\u5230\u7aef\u7684\u96f6\u77e5\u8bc6\u63a8\u7406\u8bc1\u660e\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u65e0\u7ebf\u611f\u77e5\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u95ee\u9898\uff0c\u786e\u4fdd\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u5ba1\u8ba1\u6027\u548c\u9632\u6b62\u7be1\u6539\uff0c\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u7684\u9ad8\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u63a9\u7801\u9891\u8c31\u9884\u8bad\u7ec3\u548c\u76f8\u4f4d\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u6dfb\u52a0\u6821\u51c6\u9009\u62e9\u6027\u5f03\u6743\u5934\uff0c\u5b9e\u73b0\u56db\u9636\u6bb5\u8bc1\u660e\u7ba1\u9053\u548c\u5fae\u6279\u91cf\u8bc1\u660e\u3002", "result": "\u5728\u591a\u4e2a\u611f\u77e5\u4efb\u52a1\u4e2d\u63d0\u9ad8\u4e86macro-F1\u548c\u6821\u51c6\u6027\u80fd\uff0c\u5728\u6270\u52a8\u4e0b\u83b7\u5f97\u6709\u5229\u7684\u8986\u76d6-\u98ce\u9669\u66f2\u7ebf\uff0c\u80fd\u591f\u4ee5\u7d27\u51d1\u8bc1\u660e\u548c\u5feb\u901f\u9a8c\u8bc1\u62d2\u7edd\u7be1\u6539\u548c\u91cd\u653e\u653b\u51fb\u3002", "conclusion": "ZK-SenseLM\u6210\u529f\u5b9e\u73b0\u4e86\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u7684\u65e0\u7ebf\u611f\u77e5\u7cfb\u7edf\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2510.25320", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25320", "abs": "https://arxiv.org/abs/2510.25320", "authors": ["Jiaqi Wu", "Qinlao Zhao", "Zefeng Chen", "Kai Qin", "Yifei Zhao", "Xueqian Wang", "Yuhang Yao"], "title": "GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning", "comment": null, "summary": "Autonomous agents powered by large language models (LLMs) have shown\nimpressive capabilities in tool manipulation for complex task-solving. However,\nexisting paradigms such as ReAct rely on sequential reasoning and execution,\nfailing to exploit the inherent parallelism among independent sub-tasks. This\nsequential bottleneck leads to inefficient tool utilization and suboptimal\nperformance in multi-step reasoning scenarios. We introduce Graph-based Agent\nPlanning (GAP), a novel framework that explicitly models inter-task\ndependencies through graph-based planning to enable adaptive parallel and\nserial tool execution. Our approach trains agent foundation models to decompose\ncomplex tasks into dependency-aware sub-task graphs, autonomously determining\nwhich tools can be executed in parallel and which must follow sequential\ndependencies. This dependency-aware orchestration achieves substantial\nimprovements in both execution efficiency and task accuracy. To train GAP, we\nconstruct a high-quality dataset of graph-based planning traces derived from\nthe Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage\ntraining strategy: supervised fine-tuning (SFT) on the curated dataset,\nfollowed by reinforcement learning (RL) with a correctness-based reward\nfunction on strategically sampled queries where tool-based reasoning provides\nmaximum value. Experimental results on MHQA datasets demonstrate that GAP\nsignificantly outperforms traditional ReAct baselines, particularly on\nmulti-step retrieval tasks, while achieving dramatic improvements in tool\ninvocation efficiency through intelligent parallelization. The project page is\navailable at: https://github.com/WJQ7777/Graph-Agent-Planning.", "AI": {"tldr": "\u63d0\u51faGraph-based Agent Planning (GAP)\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u89c4\u5212\u5b9e\u73b0\u5de5\u5177\u6267\u884c\u7684\u5e76\u884c\u5316\uff0c\u663e\u8457\u63d0\u5347\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u4e3b\u4ee3\u7406\uff08\u5982ReAct\uff09\u91c7\u7528\u987a\u5e8f\u63a8\u7406\u6267\u884c\uff0c\u65e0\u6cd5\u5229\u7528\u72ec\u7acb\u5b50\u4efb\u52a1\u7684\u5e76\u884c\u6027\uff0c\u5bfc\u81f4\u5de5\u5177\u5229\u7528\u6548\u7387\u4f4e\u4e0b\u548c\u591a\u6b65\u63a8\u7406\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u8bad\u7ec3\u4ee3\u7406\u57fa\u7840\u6a21\u578b\u5c06\u590d\u6742\u4efb\u52a1\u5206\u89e3\u4e3a\u4f9d\u8d56\u611f\u77e5\u7684\u5b50\u4efb\u52a1\u56fe\uff0c\u81ea\u4e3b\u51b3\u5b9a\u54ea\u4e9b\u5de5\u5177\u53ef\u4ee5\u5e76\u884c\u6267\u884c\uff0c\u54ea\u4e9b\u5fc5\u987b\u987a\u5e8f\u6267\u884c\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a\u76d1\u7763\u5fae\u8c03+\u57fa\u4e8e\u6b63\u786e\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728MHQA\u6570\u636e\u96c6\u4e0a\u663e\u8457\u8d85\u8d8a\u4f20\u7edfReAct\u57fa\u7ebf\uff0c\u7279\u522b\u662f\u5728\u591a\u6b65\u68c0\u7d22\u4efb\u52a1\u4e2d\uff0c\u901a\u8fc7\u667a\u80fd\u5e76\u884c\u5316\u5b9e\u73b0\u5de5\u5177\u8c03\u7528\u6548\u7387\u7684\u663e\u8457\u63d0\u5347\u3002", "conclusion": "GAP\u6846\u67b6\u901a\u8fc7\u4f9d\u8d56\u611f\u77e5\u7684\u4efb\u52a1\u7f16\u6392\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u6267\u884c\u6548\u7387\uff0c\u4e3a\u590d\u6742\u4efb\u52a1\u89e3\u51b3\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u8303\u5f0f\u3002"}}
{"id": "2510.25665", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25665", "abs": "https://arxiv.org/abs/2510.25665", "authors": ["Ayse Irmak Ercevik", "Aidan Dakhama", "Melane Navaratnarajah", "Yazhuo Cao", "Leo Fernandes"], "title": "Fuzz Smarter, Not Harder: Towards Greener Fuzzing with GreenAFL", "comment": null, "summary": "Fuzzing has become a key search-based technique for software testing, but\ncontinuous fuzzing campaigns consume substantial computational resources and\ngenerate significant carbon footprints. Existing grey-box fuzzing approaches\nlike AFL++ focus primarily on coverage maximisation, without considering the\nenergy costs of exploring different execution paths. This paper presents\nGreenAFL, an energy-aware framework that incorporates power consumption into\nthe fuzzing heuristics to reduce the environmental impact of automated testing\nwhilst maintaining coverage. GreenAFL introduces two key modifications to\ntraditional fuzzing workflows: energy-aware corpus minimisation considering\npower consumption when reducing initial corpora, and energy-guided heuristics\nthat direct mutation towards high-coverage, low-energy inputs. We conduct an\nablation study comparing vanilla AFL++, energy-based corpus minimisation, and\nenergy-based heuristics to evaluate the individual contributions of each\ncomponent. Results show that highest coverage, and lowest energy usage is\nachieved whenever at least one of our modifications is used.", "AI": {"tldr": "GreenAFL\u662f\u4e00\u4e2a\u80fd\u91cf\u611f\u77e5\u7684\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u529f\u8017\u7eb3\u5165\u6a21\u7cca\u6d4b\u8bd5\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u8986\u76d6\u7387\u7684\u540c\u65f6\u51cf\u5c11\u81ea\u52a8\u5316\u6d4b\u8bd5\u7684\u73af\u5883\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u5982AFL++\u4e3b\u8981\u5173\u6ce8\u8986\u76d6\u7387\u6700\u5927\u5316\uff0c\u800c\u6ca1\u6709\u8003\u8651\u63a2\u7d22\u4e0d\u540c\u6267\u884c\u8def\u5f84\u7684\u80fd\u6e90\u6210\u672c\u3002\u6301\u7eed\u6a21\u7cca\u6d4b\u8bd5\u6d3b\u52a8\u6d88\u8017\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u5e76\u4ea7\u751f\u663e\u8457\u7684\u78b3\u8db3\u8ff9\u3002", "method": "GreenAFL\u5f15\u5165\u4e86\u4e24\u4e2a\u5173\u952e\u4fee\u6539\uff1a\u80fd\u91cf\u611f\u77e5\u7684\u8bed\u6599\u5e93\u6700\u5c0f\u5316\uff08\u5728\u51cf\u5c11\u521d\u59cb\u8bed\u6599\u5e93\u65f6\u8003\u8651\u529f\u8017\uff09\u548c\u80fd\u91cf\u5f15\u5bfc\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff08\u5c06\u53d8\u5f02\u5bfc\u5411\u9ad8\u8986\u76d6\u7387\u3001\u4f4e\u80fd\u8017\u7684\u8f93\u5165\uff09\u3002", "result": "\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u5f53\u4f7f\u7528\u81f3\u5c11\u4e00\u4e2a\u4fee\u6539\u65f6\uff0c\u5b9e\u73b0\u4e86\u6700\u9ad8\u8986\u76d6\u7387\u548c\u6700\u4f4e\u80fd\u8017\u3002", "conclusion": "GreenAFL\u6846\u67b6\u6210\u529f\u5730\u5c06\u80fd\u91cf\u6548\u7387\u7eb3\u5165\u6a21\u7cca\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u5728\u4fdd\u6301\u6d4b\u8bd5\u6548\u679c\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u73af\u5883\u8db3\u8ff9\u3002"}}
{"id": "2510.25687", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25687", "abs": "https://arxiv.org/abs/2510.25687", "authors": ["Mallika Prabhakar", "Louise Xu", "Prateek Saxena"], "title": "Model Inversion Attacks Meet Cryptographic Fuzzy Extractors", "comment": null, "summary": "Model inversion attacks pose an open challenge to privacy-sensitive\napplications that use machine learning (ML) models. For example, face\nauthentication systems use modern ML models to compute embedding vectors from\nface images of the enrolled users and store them. If leaked, inversion attacks\ncan accurately reconstruct user faces from the leaked vectors. There is no\nsystematic characterization of properties needed in an ideal defense against\nmodel inversion, even for the canonical example application of a face\nauthentication system susceptible to data breaches, despite a decade of\nbest-effort solutions.\n  In this paper, we formalize the desired properties of a provably strong\ndefense against model inversion and connect it, for the first time, to the\ncryptographic concept of fuzzy extractors. We further show that existing fuzzy\nextractors are insecure for use in ML-based face authentication. We do so\nthrough a new model inversion attack called PIPE, which achieves a success rate\nof over 89% in most cases against prior schemes. We then propose L2FE-Hash, the\nfirst candidate fuzzy extractor which supports standard Euclidean distance\ncomparators as needed in many ML-based applications, including face\nauthentication. We formally characterize its computational security guarantees,\neven in the extreme threat model of full breach of stored secrets, and\nempirically show its usable accuracy in face authentication for practical face\ndistributions. It offers attack-agnostic security without requiring any\nre-training of the ML model it protects. Empirically, it nullifies both prior\nstate-of-the-art inversion attacks as well as our new PIPE attack.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53cd\u6f14\u653b\u51fb\u7684\u9632\u5fa1\u65b9\u6848L2FE-Hash\uff0c\u8fd9\u662f\u9996\u4e2a\u652f\u6301\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u6bd4\u8f83\u5668\u7684\u6a21\u7cca\u63d0\u53d6\u5668\uff0c\u80fd\u591f\u6709\u6548\u4fdd\u62a4\u4eba\u8138\u8ba4\u8bc1\u7cfb\u7edf\u514d\u53d7\u6570\u636e\u6cc4\u9732\u65f6\u7684\u6a21\u578b\u53cd\u6f14\u653b\u51fb\u3002", "motivation": "\u6a21\u578b\u53cd\u6f14\u653b\u51fb\u5bf9\u9690\u79c1\u654f\u611f\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u7279\u522b\u662f\u5728\u4eba\u8138\u8ba4\u8bc1\u7cfb\u7edf\u4e2d\uff0c\u5982\u679c\u5d4c\u5165\u5411\u91cf\u6cc4\u9732\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u51c6\u786e\u91cd\u6784\u7528\u6237\u9762\u90e8\u56fe\u50cf\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6848\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7279\u5f81\uff0c\u4e14\u73b0\u6709\u6a21\u7cca\u63d0\u53d6\u5668\u5728\u57fa\u4e8eML\u7684\u4eba\u8138\u8ba4\u8bc1\u4e2d\u4e0d\u5b89\u5168\u3002", "method": "\u9996\u5148\u5f62\u5f0f\u5316\u4e86\u9632\u5fa1\u6a21\u578b\u53cd\u6f14\u653b\u51fb\u6240\u9700\u7684\u5c5e\u6027\uff0c\u5e76\u5c06\u5176\u4e0e\u5bc6\u7801\u5b66\u4e2d\u7684\u6a21\u7cca\u63d0\u53d6\u5668\u6982\u5ff5\u8054\u7cfb\u8d77\u6765\u3002\u63d0\u51fa\u4e86\u65b0\u7684\u6a21\u578b\u53cd\u6f14\u653b\u51fbPIPE\u6765\u8bc1\u660e\u73b0\u6709\u65b9\u6848\u7684\u4e0d\u5b89\u5168\u6027\uff0c\u7136\u540e\u8bbe\u8ba1\u4e86L2FE-Hash\u6a21\u7cca\u63d0\u53d6\u5668\uff0c\u652f\u6301\u6807\u51c6\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u6bd4\u8f83\u5668\u3002", "result": "PIPE\u653b\u51fb\u5bf9\u73b0\u6709\u65b9\u6848\u7684\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc789%\u3002L2FE-Hash\u5728\u8ba1\u7b97\u5b89\u5168\u6027\u65b9\u9762\u5177\u6709\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u5728\u5b9e\u7528\u4eba\u8138\u5206\u5e03\u4e0b\u4fdd\u6301\u53ef\u7528\u7cbe\u5ea6\uff0c\u80fd\u591f\u5b8c\u5168\u62b5\u5fa1\u73b0\u6709\u6700\u5148\u8fdb\u7684\u53cd\u6f14\u653b\u51fb\u548cPIPE\u653b\u51fb\u3002", "conclusion": "L2FE-Hash\u662f\u9996\u4e2a\u9002\u7528\u4e8e\u57fa\u4e8eML\u7684\u4eba\u8138\u8ba4\u8bc1\u7cfb\u7edf\u7684\u5b89\u5168\u6a21\u7cca\u63d0\u53d6\u5668\uff0c\u63d0\u4f9b\u4e86\u653b\u51fb\u65e0\u5173\u7684\u5b89\u5168\u6027\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u53d7\u4fdd\u62a4\u7684ML\u6a21\u578b\uff0c\u5728\u5b8c\u5168\u6cc4\u9732\u5b58\u50a8\u79d8\u5bc6\u7684\u6781\u7aef\u5a01\u80c1\u6a21\u578b\u4e0b\u4ecd\u80fd\u4fdd\u6301\u5b89\u5168\u3002"}}
{"id": "2510.25388", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25388", "abs": "https://arxiv.org/abs/2510.25388", "authors": ["Robin Schm\u00f6cker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "Grouping Nodes With Known Value Differences: A Lossless UCT-based Abstraction Algorithm", "comment": null, "summary": "A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency,\nwhich can be improved by grouping state-action pairs and using their aggregate\nstatistics instead of single-node statistics. On the Go Abstractions in Upper\nConfidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS\nabstraction algorithm for deterministic environments that builds its\nabstraction using the Abstractions of State-Action Pairs (ASAP) framework,\nwhich aims to detect states and state-action pairs with the same value under\noptimal play by analysing the search graph. ASAP, however, requires two\nstate-action pairs to have the same immediate reward, which is a rigid\ncondition that limits the number of abstractions that can be found and thereby\nthe sample efficiency. In this paper, we break with the paradigm of grouping\nvalue-equivalent states or state-action pairs and instead group states and\nstate-action pairs with possibly different values as long as the difference\nbetween their values can be inferred. We call this abstraction framework Known\nValue Difference Abstractions (KVDA), which infers the value differences by\nanalysis of the immediate rewards and modifies OGA-UCT to use this framework\ninstead. The modification is called KVDA-UCT, which detects significantly more\nabstractions than OGA-UCT, introduces no additional parameter, and outperforms\nOGA-UCT on a variety of deterministic environments and parameter settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86KVDA-UCT\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5373\u65f6\u5956\u52b1\u6765\u63a8\u65ad\u72b6\u6001-\u52a8\u4f5c\u5bf9\u4e4b\u95f4\u7684\u4ef7\u503c\u5dee\u5f02\uff0c\u4ece\u800c\u5728MCTS\u4e2d\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u62bd\u8c61\u5206\u7ec4\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5OGA-UCT\u80fd\u68c0\u6d4b\u5230\u66f4\u591a\u62bd\u8c61\u4e14\u65e0\u9700\u989d\u5916\u53c2\u6570\u3002", "motivation": "\u73b0\u6709MCTS\u62bd\u8c61\u7b97\u6cd5OGA-UCT\u8981\u6c42\u72b6\u6001-\u52a8\u4f5c\u5bf9\u5177\u6709\u76f8\u540c\u7684\u5373\u65f6\u5956\u52b1\uff0c\u8fd9\u4e00\u521a\u6027\u6761\u4ef6\u9650\u5236\u4e86\u53ef\u53d1\u73b0\u7684\u62bd\u8c61\u6570\u91cf\uff0c\u5f71\u54cd\u4e86\u6837\u672c\u6548\u7387\u3002", "method": "\u63d0\u51faKVDA\u6846\u67b6\uff0c\u4e0d\u518d\u8981\u6c42\u72b6\u6001-\u52a8\u4f5c\u5bf9\u4ef7\u503c\u76f8\u7b49\uff0c\u800c\u662f\u63a8\u65ad\u5b83\u4eec\u4e4b\u95f4\u7684\u4ef7\u503c\u5dee\u5f02\uff0c\u5e76\u57fa\u4e8e\u6b64\u4fee\u6539OGA-UCT\u5f97\u5230KVDA-UCT\u7b97\u6cd5\u3002", "result": "KVDA-UCT\u5728\u5404\u79cd\u786e\u5b9a\u6027\u73af\u5883\u548c\u53c2\u6570\u8bbe\u7f6e\u4e0b\u663e\u8457\u4f18\u4e8eOGA-UCT\uff0c\u80fd\u68c0\u6d4b\u5230\u66f4\u591a\u62bd\u8c61\u4e14\u4e0d\u5f15\u5165\u989d\u5916\u53c2\u6570\u3002", "conclusion": "KVDA\u6846\u67b6\u901a\u8fc7\u63a8\u65ad\u4ef7\u503c\u5dee\u5f02\u800c\u975e\u8981\u6c42\u4ef7\u503c\u76f8\u7b49\uff0c\u6709\u6548\u63d0\u5347\u4e86MCTS\u7684\u62bd\u8c61\u80fd\u529b\u548c\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2510.25692", "categories": ["cs.SE", "cs.LG", "D.2.6; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.25692", "abs": "https://arxiv.org/abs/2510.25692", "authors": ["Tim Strnad", "Bla\u017e Bertalani\u010d", "Carolina Fortuna"], "title": "A Configuration-First Framework for Reproducible, Low-Code Localization", "comment": "20 pages, 7 figures. Preprint submitted to ACM Transactions on\n  Software Engineering and Methodology (TOSEM), 2025", "summary": "Machine learning is increasingly permeating radio-based localization\nservices. To keep results credible and comparable, everyday workflows should\nmake rigorous experiment specification and exact repeatability the default,\nwithout blocking advanced experimentation. However, in practice, researchers\nface a three-way gap that could be filled by a framework that offers (i) low\ncoding effort for end-to-end studies, (ii) reproducibility by default including\nversioned code, data, and configurations, controlled randomness, isolated runs,\nand recorded artifacts, and (iii) built-in extensibility so new models,\nmetrics, and stages can be added with minimal integration effort. Existing\ntools rarely deliver all three for machine learning in general and localization\nworkflows in particular. In this paper we introduce LOCALIZE, a low-code,\nconfiguration-first framework for radio localization in which experiments are\ndeclared in human-readable configuration, a workflow orchestrator runs\nstandardized pipelines from data preparation to reporting, and all artifacts,\nsuch as datasets, models, metrics, and reports, are versioned. The\npreconfigured, versioned datasets reduce initial setup and boilerplate,\nspeeding up model development and evaluation. The design, with clear extension\npoints, allows experts to add components without reworking the infrastructure.\nIn a qualitative comparison and a head-to-head study against a plain Jupyter\nnotebook baseline, we show that the framework reduces authoring effort while\nmaintaining comparable runtime and memory behavior. Furthermore, using a\nBluetooth Low Energy dataset, we show that scaling across training data (1x to\n10x) keeps orchestration overheads bounded as data grows. Overall, the\nframework makes reproducible machine-learning-based localization\nexperimentation practical, accessible, and extensible.", "AI": {"tldr": "\u63d0\u51fa\u4e86LOCALIZE\u6846\u67b6\uff0c\u4e00\u4e2a\u7528\u4e8e\u65e0\u7ebf\u7535\u5b9a\u4f4d\u7684\u4f4e\u4ee3\u7801\u3001\u914d\u7f6e\u4f18\u5148\u7684\u673a\u5668\u5b66\u4e60\u5b9e\u9a8c\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5b9e\u9a8c\u53ef\u91cd\u590d\u6027\u3001\u6613\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728\u57fa\u4e8e\u65e0\u7ebf\u7535\u7684\u5b9a\u4f4d\u670d\u52a1\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u4f4e\u7f16\u7801\u5de5\u4f5c\u91cf\u3001\u9ed8\u8ba4\u53ef\u91cd\u590d\u6027\u548c\u5185\u7f6e\u53ef\u6269\u5c55\u6027\u8fd9\u4e09\u4e2a\u5173\u952e\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u4eba\u7c7b\u53ef\u8bfb\u914d\u7f6e\u7684\u5b9e\u9a8c\u58f0\u660e\u7cfb\u7edf\uff0c\u901a\u8fc7\u5de5\u4f5c\u6d41\u7f16\u6392\u5668\u8fd0\u884c\u6807\u51c6\u5316\u7ba1\u9053\uff08\u4ece\u6570\u636e\u51c6\u5907\u5230\u62a5\u544a\u751f\u6210\uff09\uff0c\u5e76\u5bf9\u6240\u6709\u5de5\u4ef6\uff08\u6570\u636e\u96c6\u3001\u6a21\u578b\u3001\u6307\u6807\u3001\u62a5\u544a\uff09\u8fdb\u884c\u7248\u672c\u63a7\u5236\u3002", "result": "\u4e0e\u666e\u901aJupyter\u7b14\u8bb0\u672c\u57fa\u7ebf\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u51cf\u5c11\u4e86\u7f16\u5199\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u8fd0\u884c\u65f6\u548c\u5185\u5b58\u884c\u4e3a\uff1b\u5728BLE\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u968f\u7740\u8bad\u7ec3\u6570\u636e\u4ece1\u500d\u589e\u52a0\u523010\u500d\uff0c\u7f16\u6392\u5f00\u9500\u4fdd\u6301\u6709\u754c\u3002", "conclusion": "LOCALIZE\u6846\u67b6\u4f7f\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5b9a\u4f4d\u5b9e\u9a8c\u53d8\u5f97\u5b9e\u7528\u3001\u6613\u4e8e\u8bbf\u95ee\u4e14\u53ef\u6269\u5c55\uff0c\u5b9e\u73b0\u4e86\u53ef\u91cd\u590d\u7684\u5b9e\u9a8c\u6d41\u7a0b\u3002"}}
{"id": "2510.25746", "categories": ["cs.CR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.25746", "abs": "https://arxiv.org/abs/2510.25746", "authors": ["Charlie Harrison", "Pasin Manurangsi"], "title": "Exact zCDP Characterizations for Fundamental Differentially Private Mechanisms", "comment": null, "summary": "Zero-concentrated differential privacy (zCDP) is a variant of differential\nprivacy (DP) that is widely used partly thanks to its nice composition\nproperty. While a tight conversion from $\\epsilon$-DP to zCDP exists for the\nworst-case mechanism, many common algorithms satisfy stronger guarantees. In\nthis work, we derive tight zCDP characterizations for several fundamental\nmechanisms. We prove that the tight zCDP bound for the $\\epsilon$-DP Laplace\nmechanism is exactly $\\epsilon + e^{-\\epsilon} - 1$, confirming a recent\nconjecture by Wang (2022). We further provide tight bounds for the discrete\nLaplace mechanism, $k$-Randomized Response (for $k \\leq 6$), and RAPPOR.\nLastly, we also provide a tight zCDP bound for the worst case bounded range\nmechanism.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86\u591a\u79cd\u57fa\u7840\u5dee\u5206\u9690\u79c1\u673a\u5236\u5728\u96f6\u96c6\u4e2d\u5dee\u5206\u9690\u79c1(zCDP)\u4e0b\u7684\u7d27\u81f4\u8fb9\u754c\uff0c\u5305\u62ec\u62c9\u666e\u62c9\u65af\u673a\u5236\u3001\u79bb\u6563\u62c9\u666e\u62c9\u65af\u673a\u5236\u3001k-\u968f\u673a\u54cd\u5e94\u548cRAPPOR\uff0c\u5e76\u8bc1\u660e\u4e86\u62c9\u666e\u62c9\u65af\u673a\u5236\u7684\u786e\u5207zCDP\u8fb9\u754c\u4e3a\u03b5 + e^{-\u03b5} - 1\u3002", "motivation": "\u867d\u7136\u5b58\u5728\u4ece\u03b5-DP\u5230zCDP\u7684\u6700\u574f\u60c5\u51b5\u8f6c\u6362\uff0c\u4f46\u8bb8\u591a\u5e38\u89c1\u7b97\u6cd5\u6ee1\u8db3\u66f4\u5f3a\u7684\u4fdd\u8bc1\uff0c\u9700\u8981\u4e3a\u57fa\u672c\u673a\u5236\u63d0\u4f9b\u7cbe\u786e\u7684zCDP\u7279\u5f81\u5316\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u63a8\u5bfc\u548c\u5206\u6790\uff0c\u4e3a\u62c9\u666e\u62c9\u65af\u673a\u5236\u3001\u79bb\u6563\u62c9\u666e\u62c9\u65af\u673a\u5236\u3001k-\u968f\u673a\u54cd\u5e94(k\u22646)\u548cRAPPOR\u7b49\u57fa\u7840\u673a\u5236\u63d0\u4f9b\u7d27\u81f4\u7684zCDP\u8fb9\u754c\u3002", "result": "\u8bc1\u660e\u4e86\u62c9\u666e\u62c9\u65af\u673a\u5236\u7684\u7d27\u81f4zCDP\u8fb9\u754c\u4e3a\u03b5 + e^{-\u03b5} - 1\uff0c\u786e\u8ba4\u4e86Wang(2022)\u7684\u731c\u60f3\uff1b\u540c\u65f6\u4e3a\u5176\u4ed6\u673a\u5236\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684zCDP\u8fb9\u754c\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u57fa\u7840\u5dee\u5206\u9690\u79c1\u673a\u5236\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684zCDP\u7279\u5f81\u5316\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u548c\u5e94\u7528zCDP\u6846\u67b6\u4e0b\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u3002"}}
{"id": "2510.25445", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25445", "abs": "https://arxiv.org/abs/2510.25445", "authors": ["Mohamad Abou Ali", "Fadi Dornaika"], "title": "Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions", "comment": null, "summary": "Agentic AI represents a transformative shift in artificial intelligence, but\nits rapid advancement has led to a fragmented understanding, often conflating\nmodern neural systems with outdated symbolic models -- a practice known as\nconceptual retrofitting. This survey cuts through this confusion by introducing\na novel dual-paradigm framework that categorizes agentic systems into two\ndistinct lineages: the Symbolic/Classical (relying on algorithmic planning and\npersistent state) and the Neural/Generative (leveraging stochastic generation\nand prompt-driven orchestration). Through a systematic PRISMA-based review of\n90 studies (2018--2025), we provide a comprehensive analysis structured around\nthis framework across three dimensions: (1) the theoretical foundations and\narchitectural principles defining each paradigm; (2) domain-specific\nimplementations in healthcare, finance, and robotics, demonstrating how\napplication constraints dictate paradigm selection; and (3) paradigm-specific\nethical and governance challenges, revealing divergent risks and mitigation\nstrategies. Our analysis reveals that the choice of paradigm is strategic:\nsymbolic systems dominate safety-critical domains (e.g., healthcare), while\nneural systems prevail in adaptive, data-rich environments (e.g., finance).\nFurthermore, we identify critical research gaps, including a significant\ndeficit in governance models for symbolic systems and a pressing need for\nhybrid neuro-symbolic architectures. The findings culminate in a strategic\nroadmap arguing that the future of Agentic AI lies not in the dominance of one\nparadigm, but in their intentional integration to create systems that are both\nadaptable and reliable. This work provides the essential conceptual toolkit to\nguide future research, development, and policy toward robust and trustworthy\nhybrid intelligent systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u8303\u5f0f\u6846\u67b6\u6765\u5206\u7c7b\u667a\u80fdAI\u7cfb\u7edf\uff1a\u7b26\u53f7/\u7ecf\u5178\u8303\u5f0f\uff08\u57fa\u4e8e\u7b97\u6cd5\u89c4\u5212\u548c\u6301\u4e45\u72b6\u6001\uff09\u548c\u795e\u7ecf/\u751f\u6210\u8303\u5f0f\uff08\u5229\u7528\u968f\u673a\u751f\u6210\u548c\u63d0\u793a\u9a71\u52a8\u7f16\u6392\uff09\u3002\u901a\u8fc7\u7cfb\u7edf\u56de\u987e90\u9879\u7814\u7a76\uff0c\u5206\u6790\u4e86\u4e24\u79cd\u8303\u5f0f\u5728\u7406\u8bba\u57fa\u7840\u3001\u9886\u57df\u5e94\u7528\u548c\u4f26\u7406\u6311\u6218\u65b9\u9762\u7684\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4e86\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u7684\u6218\u7565\u8def\u7ebf\u56fe\u3002", "motivation": "\u89e3\u51b3\u667a\u80fdAI\u5feb\u901f\u53d1\u5c55\u5bfc\u81f4\u7684\u788e\u7247\u5316\u7406\u89e3\u95ee\u9898\uff0c\u6f84\u6e05\u73b0\u4ee3\u795e\u7ecf\u7cfb\u7edf\u4e0e\u8fc7\u65f6\u7b26\u53f7\u6a21\u578b\u4e4b\u95f4\u7684\u6df7\u6dc6\uff08\u6982\u5ff5\u6027\u91cd\u65b0\u9002\u914d\uff09\uff0c\u4e3a\u9886\u57df\u63d0\u4f9b\u6e05\u6670\u7684\u6982\u5ff5\u6846\u67b6\u3002", "method": "\u91c7\u7528PRISMA\u7cfb\u7edf\u56de\u987e\u65b9\u6cd5\uff0c\u5206\u6790\u4e862018-2025\u5e74\u95f4\u768490\u9879\u7814\u7a76\uff0c\u6784\u5efa\u53cc\u8303\u5f0f\u6846\u67b6\u5e76\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff1a\u7406\u8bba\u57fa\u7840\u4e0e\u67b6\u6784\u539f\u5219\u3001\u9886\u57df\u7279\u5b9a\u5b9e\u65bd\u3001\u8303\u5f0f\u7279\u5b9a\u4f26\u7406\u6311\u6218\u3002", "result": "\u53d1\u73b0\u8303\u5f0f\u9009\u62e9\u5177\u6709\u6218\u7565\u6027\uff1a\u7b26\u53f7\u7cfb\u7edf\u4e3b\u5bfc\u5b89\u5168\u5173\u952e\u9886\u57df\uff08\u5982\u533b\u7597\uff09\uff0c\u795e\u7ecf\u7cfb\u7edf\u4e3b\u5bfc\u9002\u5e94\u6027\u5f3a\u7684\u6570\u636e\u4e30\u5bcc\u73af\u5883\uff08\u5982\u91d1\u878d\uff09\u3002\u8bc6\u522b\u4e86\u5173\u952e\u7814\u7a76\u7a7a\u767d\uff0c\u5305\u62ec\u7b26\u53f7\u7cfb\u7edf\u6cbb\u7406\u6a21\u578b\u4e0d\u8db3\u548c\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u7684\u9700\u6c42\u3002", "conclusion": "\u667a\u80fdAI\u7684\u672a\u6765\u4e0d\u5728\u4e8e\u5355\u4e00\u8303\u5f0f\u7684\u7edf\u6cbb\uff0c\u800c\u5728\u4e8e\u4e24\u79cd\u8303\u5f0f\u7684\u6709\u610f\u6574\u5408\uff0c\u4ee5\u521b\u5efa\u65e2\u9002\u5e94\u6027\u5f3a\u53c8\u53ef\u9760\u7684\u7cfb\u7edf\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u672a\u6765\u7814\u7a76\u3001\u5f00\u53d1\u548c\u653f\u7b56\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u6982\u5ff5\u5de5\u5177\u5305\u3002"}}
{"id": "2510.25694", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25694", "abs": "https://arxiv.org/abs/2510.25694", "authors": ["Jiayi Kuang", "Yinghui Li", "Xin Zhang", "Yangning Li", "Di Yin", "Xing Sun", "Ying Shen", "Philip S. Yu"], "title": "Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents", "comment": null, "summary": "Large language model-based agents show promise for software engineering, but\nenvironment configuration remains a bottleneck due to heavy manual effort and\nscarce large-scale, high-quality datasets. Existing benchmarks assess only\nend-to-end build/test success, obscuring where and why agents succeed or fail.\nWe introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench,\nwhich provides process-level trajectory assessment of fine-grained agent\ncapabilities during environment setup-planning, perception-driven error\ndiagnosis, feedback-driven repair, and action to execute final environment\nconfiguration. Our task instances are automatically constructed by injecting\nrealistic README errors and are validated in Docker for scalable, high-quality\nevaluation. Enconda-bench combines process-level analysis with end-to-end\nexecutability to enable capability assessments beyond aggregate success rates.\nEvaluations across state-of-the-art LLMs and agent frameworks show that while\nagents can localize errors, they struggle to translate feedback into effective\ncorrections, limiting end-to-end performance. To our knowledge, Enconda-bench\nis the first framework to provide process-level internal capability assessment\nfor environment configuration, offering actionable insights for improving\nsoftware engineering agents.", "AI": {"tldr": "Enconda-bench\u662f\u4e00\u4e2a\u73af\u5883\u914d\u7f6e\u8bca\u65ad\u57fa\u51c6\uff0c\u901a\u8fc7\u8fc7\u7a0b\u7ea7\u8f68\u8ff9\u8bc4\u4f30\u6765\u8bca\u65adLLM\u4ee3\u7406\u5728\u73af\u5883\u914d\u7f6e\u4e2d\u7684\u7ec6\u7c92\u5ea6\u80fd\u529b\uff0c\u5305\u62ec\u89c4\u5212\u3001\u9519\u8bef\u8bca\u65ad\u3001\u53cd\u9988\u9a71\u52a8\u7684\u4fee\u590d\u7b49\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4ec5\u8bc4\u4f30\u7aef\u5230\u7aef\u6784\u5efa/\u6d4b\u8bd5\u6210\u529f\uff0c\u65e0\u6cd5\u63ed\u793a\u4ee3\u7406\u6210\u529f\u6216\u5931\u8d25\u7684\u5177\u4f53\u539f\u56e0\uff0c\u73af\u5883\u914d\u7f6e\u4ecd\u7136\u662f\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u74f6\u9888\u3002", "method": "\u901a\u8fc7\u6ce8\u5165\u771f\u5b9e\u7684README\u9519\u8bef\u81ea\u52a8\u6784\u5efa\u4efb\u52a1\u5b9e\u4f8b\uff0c\u5728Docker\u4e2d\u8fdb\u884c\u9a8c\u8bc1\uff0c\u7ed3\u5408\u8fc7\u7a0b\u7ea7\u5206\u6790\u548c\u7aef\u5230\u7aef\u53ef\u6267\u884c\u6027\u6765\u8bc4\u4f30\u4ee3\u7406\u80fd\u529b\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u4ee3\u7406\u80fd\u591f\u5b9a\u4f4d\u9519\u8bef\uff0c\u4f46\u96be\u4ee5\u5c06\u53cd\u9988\u8f6c\u5316\u4e3a\u6709\u6548\u4fee\u6b63\uff0c\u9650\u5236\u4e86\u7aef\u5230\u7aef\u6027\u80fd\u3002", "conclusion": "Enconda-bench\u662f\u9996\u4e2a\u4e3a\u73af\u5883\u914d\u7f6e\u63d0\u4f9b\u8fc7\u7a0b\u7ea7\u5185\u90e8\u80fd\u529b\u8bc4\u4f30\u7684\u6846\u67b6\uff0c\u4e3a\u6539\u8fdb\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002"}}
{"id": "2510.25471", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.25471", "abs": "https://arxiv.org/abs/2510.25471", "authors": ["Willem Fourie"], "title": "Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?", "comment": null, "summary": "In artificial intelligence (AI) alignment research, instrumental goals, also\ncalled instrumental subgoals or instrumental convergent goals, are widely\nassociated with advanced AI systems. These goals, which include tendencies such\nas power-seeking and self-preservation, become problematic when they conflict\nwith human aims. Conventional alignment theory treats instrumental goals as\nsources of risk that become problematic through failure modes such as reward\nhacking or goal misgeneralization, and attempts to limit the symptoms of\ninstrumental goals, notably resource acquisition and self-preservation. This\narticle proposes an alternative framing: that a philosophical argument can be\nconstructed according to which instrumental goals may be understood as features\nto be accepted and managed rather than failures to be limited. Drawing on\nAristotle's ontology and its modern interpretations, an ontology of concrete,\ngoal-directed entities, it argues that advanced AI systems can be seen as\nartifacts whose formal and material constitution gives rise to effects distinct\nfrom their designers' intentions. In this view, the instrumental tendencies of\nsuch systems correspond to per se outcomes of their constitution rather than\naccidental malfunctions. The implication is that efforts should focus less on\neliminating instrumental goals and more on understanding, managing, and\ndirecting them toward human-aligned ends.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAI\u5bf9\u9f50\u7814\u7a76\u7684\u65b0\u89c6\u89d2\uff1a\u5c06\u5de5\u5177\u6027\u76ee\u6807\u89c6\u4e3a\u9700\u8981\u63a5\u53d7\u548c\u7ba1\u7406\u7684\u7279\u5f81\uff0c\u800c\u975e\u9700\u8981\u9650\u5236\u7684\u6545\u969c\u3002\u57fa\u4e8e\u4e9a\u91cc\u58eb\u591a\u5fb7\u672c\u4f53\u8bba\uff0c\u8ba4\u4e3a\u9ad8\u7ea7AI\u7cfb\u7edf\u7684\u6784\u6210\u4f1a\u81ea\u7136\u4ea7\u751f\u5de5\u5177\u6027\u76ee\u6807\uff0c\u5e94\u5c06\u5176\u5f15\u5bfc\u81f3\u4eba\u7c7b\u5bf9\u9f50\u7684\u76ee\u6807\u3002", "motivation": "\u4f20\u7edfAI\u5bf9\u9f50\u7406\u8bba\u5c06\u5de5\u5177\u6027\u76ee\u6807\u89c6\u4e3a\u98ce\u9669\u6765\u6e90\uff0c\u8bd5\u56fe\u9650\u5236\u5176\u75c7\u72b6\u3002\u672c\u6587\u8ba4\u4e3a\u8fd9\u79cd\u89c2\u70b9\u8fc7\u4e8e\u6d88\u6781\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u5de5\u5177\u6027\u76ee\u6807\u5728AI\u7cfb\u7edf\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u8fd0\u7528\u4e9a\u91cc\u58eb\u591a\u5fb7\u672c\u4f53\u8bba\u53ca\u5176\u73b0\u4ee3\u89e3\u91ca\uff0c\u6784\u5efa\u54f2\u5b66\u8bba\u8bc1\u6846\u67b6\uff0c\u5c06AI\u7cfb\u7edf\u89c6\u4e3a\u5177\u6709\u7279\u5b9a\u5f62\u5f0f\u548c\u7269\u8d28\u6784\u6210\u7684\u5b9e\u4f53\uff0c\u5176\u5de5\u5177\u6027\u503e\u5411\u662f\u6784\u6210\u7684\u81ea\u7136\u7ed3\u679c\u3002", "result": "\u63d0\u51fa\u5de5\u5177\u6027\u76ee\u6807\u5e94\u88ab\u89c6\u4e3aAI\u7cfb\u7edf\u6784\u6210\u7684\u56fa\u6709\u7279\u5f81\uff0c\u800c\u975e\u610f\u5916\u6545\u969c\u3002\u8fd9\u4e3aAI\u5bf9\u9f50\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "AI\u5bf9\u9f50\u5de5\u4f5c\u5e94\u66f4\u5173\u6ce8\u7406\u89e3\u3001\u7ba1\u7406\u548c\u5f15\u5bfc\u5de5\u5177\u6027\u76ee\u6807\uff0c\u800c\u975e\u8bd5\u56fe\u6d88\u9664\u5b83\u4eec\uff0c\u5c06\u5176\u5bfc\u5411\u4eba\u7c7b\u5bf9\u9f50\u7684\u6700\u7ec8\u76ee\u6807\u3002"}}
{"id": "2510.25504", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25504", "abs": "https://arxiv.org/abs/2510.25504", "authors": ["Oren Salzman", "Carlos Hern\u00e1ndez Ulloa", "Ariel Felner", "Sven Koenig"], "title": "Multi-Objective Search: Algorithms, Applications, and Emerging Directions", "comment": null, "summary": "Multi-objective search (MOS) has emerged as a unifying framework for planning\nand decision-making problems where multiple, often conflicting, criteria must\nbe balanced. While the problem has been studied for decades, recent years have\nseen renewed interest in the topic across AI applications such as robotics,\ntransportation, and operations research, reflecting the reality that real-world\nsystems rarely optimize a single measure. This paper surveys developments in\nMOS while highlighting cross-disciplinary opportunities, and outlines open\nchallenges that define the emerging frontier of MOS", "AI": {"tldr": "\u591a\u76ee\u6807\u641c\u7d22\uff08MOS\uff09\u4f5c\u4e3a\u89c4\u5212\u4e0e\u51b3\u7b56\u95ee\u9898\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u8fd1\u5e74\u6765\u5728AI\u5e94\u7528\u4e2d\u91cd\u65b0\u53d7\u5230\u5173\u6ce8\uff0c\u672c\u6587\u7efc\u8ff0\u4e86MOS\u7684\u53d1\u5c55\u5e76\u6307\u51fa\u4e86\u8de8\u5b66\u79d1\u673a\u4f1a\u548c\u5f00\u653e\u6311\u6218\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7cfb\u7edf\u5f88\u5c11\u53ea\u4f18\u5316\u5355\u4e00\u6307\u6807\uff0c\u591a\u76ee\u6807\u641c\u7d22\u80fd\u591f\u5e73\u8861\u591a\u4e2a\u901a\u5e38\u76f8\u4e92\u51b2\u7a81\u7684\u6807\u51c6\uff0c\u5728\u673a\u5668\u4eba\u3001\u4ea4\u901a\u548c\u8fd0\u7b79\u5b66\u7b49AI\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002", "method": "\u672c\u6587\u91c7\u7528\u7efc\u8ff0\u65b9\u6cd5\uff0c\u56de\u987e\u4e86\u591a\u76ee\u6807\u641c\u7d22\u9886\u57df\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u8de8\u5b66\u79d1\u673a\u4f1a\u3002", "result": "\u6587\u7ae0\u7cfb\u7edf\u68b3\u7406\u4e86MOS\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u8bc6\u522b\u4e86\u8be5\u9886\u57df\u7684\u65b0\u5174\u524d\u6cbf\u95ee\u9898\u3002", "conclusion": "\u591a\u76ee\u6807\u641c\u7d22\u4f5c\u4e3a\u4e00\u4e2a\u6210\u719f\u4f46\u4ecd\u5728\u53d1\u5c55\u7684\u9886\u57df\uff0c\u9762\u4e34\u7740\u5b9a\u4e49\u5176\u65b0\u5174\u524d\u6cbf\u7684\u5f00\u653e\u6311\u6218\uff0c\u5177\u6709\u5e7f\u9614\u7684\u8de8\u5b66\u79d1\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.25510", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25510", "abs": "https://arxiv.org/abs/2510.25510", "authors": ["Zekun Xu", "Siyu Xia", "Chuhuai Yue", "Jiajun Chai", "Mingxue Tian", "Xiaohan Wang", "Wei Lin", "Haoxuan Li", "Guojun Yin"], "title": "MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL", "comment": null, "summary": "As large language models (LLMs) are increasingly used in Text-to-SQL tasks,\nReinforcement Learning (RL) has become a common method for improving\nperformance. Existing methods primarily rely on static execution feedback,\nwhich restricts real-time error correction. However, integrating multi-turn\ntool invocation along with dynamic feedback could significantly improve\nadaptability and robustness, ultimately enhancing model performance. To address\nthese issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated\nReasoning reinforcement learning framework for Text-to-SQL. Our approach\nintroduces an execution-aware multi-turn reasoning paradigm that seamlessly\nincorporates database execution feedback at each reasoning step, enabling\ncontext-sensitive query generation and progressive refinement throughout the\nreasoning process. The framework extends the GRPO algorithm to accommodate\ncomplex multi-turn interaction scenarios. Considering the training instability\ncharacteristics of MTIR and the potential for significant Deviation of model\ndistribution from the initial model, we enhance the GRPO algorithm by adding a\ntrajectory filtering mechanism and removing KL loss constraints. Experimental\nresults demonstrate that MTIR-SQL, with 4B parameters, achieves \\textbf{64.4}\\%\naccuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev,\nsignificantly outperforming existing approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86MTIR-SQL\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u591a\u8f6e\u5de5\u5177\u96c6\u6210\u63a8\u7406\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8eText-to-SQL\u4efb\u52a1\uff0c\u901a\u8fc7\u52a8\u6001\u6267\u884c\u53cd\u9988\u548c\u591a\u8f6e\u63a8\u7406\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u6267\u884c\u53cd\u9988\uff0c\u9650\u5236\u4e86\u5b9e\u65f6\u9519\u8bef\u7ea0\u6b63\u80fd\u529b\u3002\u96c6\u6210\u591a\u8f6e\u5de5\u5177\u8c03\u7528\u548c\u52a8\u6001\u53cd\u9988\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u6267\u884c\u611f\u77e5\u7684\u591a\u8f6e\u63a8\u7406\u8303\u5f0f\uff0c\u5728\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u65e0\u7f1d\u96c6\u6210\u6570\u636e\u5e93\u6267\u884c\u53cd\u9988\uff0c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u67e5\u8be2\u751f\u6210\u548c\u6e10\u8fdb\u5f0f\u4f18\u5316\u3002\u6269\u5c55\u4e86GRPO\u7b97\u6cd5\u4ee5\u9002\u5e94\u590d\u6742\u591a\u8f6e\u4ea4\u4e92\u573a\u666f\uff0c\u5e76\u589e\u52a0\u4e86\u8f68\u8ff9\u8fc7\u6ee4\u673a\u5236\u548c\u79fb\u9664KL\u635f\u5931\u7ea6\u675f\u3002", "result": "\u5728BIRD Dev\u6570\u636e\u96c6\u4e0a\u8fbe\u523064.4%\u7684\u51c6\u786e\u7387\uff0c\u5728SPIDER Dev\u6570\u636e\u96c6\u4e0a\u8fbe\u523084.6%\u7684\u6267\u884c\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MTIR-SQL\u6846\u67b6\u901a\u8fc7\u591a\u8f6e\u5de5\u5177\u96c6\u6210\u63a8\u7406\u548c\u52a8\u6001\u6267\u884c\u53cd\u9988\uff0c\u5728Text-to-SQL\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.25517", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25517", "abs": "https://arxiv.org/abs/2510.25517", "authors": ["Elisabetta Gentili", "Tony Ribeiro", "Fabrizio Riguzzi", "Katsumi Inoue"], "title": "Predicate Renaming via Large Language Models", "comment": null, "summary": "In this paper, we address the problem of giving names to predicates in logic\nrules using Large Language Models (LLMs). In the context of Inductive Logic\nProgramming, various rule generation methods produce rules containing unnamed\npredicates, with Predicate Invention being a key example. This hinders the\nreadability, interpretability, and reusability of the logic theory. Leveraging\nrecent advancements in LLMs development, we explore their ability to process\nnatural language and code to provide semantically meaningful suggestions for\ngiving a name to unnamed predicates. The evaluation of our approach on some\nhand-crafted logic rules indicates that LLMs hold potential for this task.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u903b\u8f91\u89c4\u5219\u4e2d\u7684\u672a\u547d\u540d\u8c13\u8bcd\u751f\u6210\u6709\u610f\u4e49\u7684\u540d\u79f0\uff0c\u4ee5\u63d0\u9ad8\u903b\u8f91\u7406\u8bba\u7684\u53ef\u8bfb\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5728\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u4e2d\uff0c\u5404\u79cd\u89c4\u5219\u751f\u6210\u65b9\u6cd5\u4f1a\u4ea7\u751f\u5305\u542b\u672a\u547d\u540d\u8c13\u8bcd\u7684\u89c4\u5219\uff0c\u8fd9\u963b\u788d\u4e86\u903b\u8f91\u7406\u8bba\u7684\u53ef\u8bfb\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u91cd\u7528\u6027\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u81ea\u7136\u8bed\u8a00\u548c\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u4e3a\u672a\u547d\u540d\u8c13\u8bcd\u63d0\u4f9b\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u7684\u547d\u540d\u5efa\u8bae\u3002", "result": "\u5728\u624b\u5de5\u5236\u4f5c\u7684\u903b\u8f91\u89c4\u5219\u4e0a\u8bc4\u4f30\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6709\u671b\u89e3\u51b3\u903b\u8f91\u89c4\u5219\u4e2d\u8c13\u8bcd\u547d\u540d\u7684\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u903b\u8f91\u7406\u8bba\u7684\u8d28\u91cf\u3002"}}
{"id": "2510.25518", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25518", "abs": "https://arxiv.org/abs/2510.25518", "authors": ["Thomas Cook", "Richard Osuagwu", "Liman Tsatiashvili", "Vrynsia Vrynsia", "Koustav Ghosal", "Maraim Masoud", "Riccardo Mattivi"], "title": "Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation", "comment": "Keywords: RAG Agentic AI Fintech NLP KB Domain-Specific Ontology\n  Query Understanding", "summary": "Retrieval-Augmented Generation (RAG) systems often face limitations in\nspecialized domains such as fintech, where domain-specific ontologies, dense\nterminology, and acronyms complicate effective retrieval and synthesis. This\npaper introduces an agentic RAG architecture designed to address these\nchallenges through a modular pipeline of specialized agents. The proposed\nsystem supports intelligent query reformulation, iterative sub-query\ndecomposition guided by keyphrase extraction, contextual acronym resolution,\nand cross-encoder-based context re-ranking. We evaluate our approach against a\nstandard RAG baseline using a curated dataset of 85 question--answer--reference\ntriples derived from an enterprise fintech knowledge base. Experimental results\ndemonstrate that the agentic RAG system outperforms the baseline in retrieval\nprecision and relevance, albeit with increased latency. These findings suggest\nthat structured, multi-agent methodologies offer a promising direction for\nenhancing retrieval robustness in complex, domain-specific settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u91d1\u878d\u79d1\u6280\u9886\u57df\u7684\u667a\u80fdRAG\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u4ee3\u7406\u7cfb\u7edf\u89e3\u51b3\u4e13\u4e1a\u9886\u57df\u68c0\u7d22\u4e2d\u7684\u6311\u6218\uff0c\u5728\u68c0\u7d22\u7cbe\u5ea6\u548c\u76f8\u5173\u6027\u65b9\u9762\u4f18\u4e8e\u6807\u51c6RAG\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edfRAG\u7cfb\u7edf\u5728\u91d1\u878d\u79d1\u6280\u7b49\u4e13\u4e1a\u9886\u57df\u9762\u4e34\u6311\u6218\uff0c\u5305\u62ec\u9886\u57df\u7279\u5b9a\u672c\u4f53\u3001\u5bc6\u96c6\u672f\u8bed\u548c\u7f29\u7565\u8bed\u7b49\uff0c\u5f71\u54cd\u68c0\u7d22\u548c\u5408\u6210\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u4ee3\u7406\u67b6\u6784\uff0c\u652f\u6301\u667a\u80fd\u67e5\u8be2\u91cd\u5199\u3001\u57fa\u4e8e\u5173\u952e\u8bcd\u63d0\u53d6\u7684\u8fed\u4ee3\u5b50\u67e5\u8be2\u5206\u89e3\u3001\u4e0a\u4e0b\u6587\u7f29\u7565\u8bed\u89e3\u6790\u548c\u4ea4\u53c9\u7f16\u7801\u5668\u4e0a\u4e0b\u6587\u91cd\u6392\u5e8f\u3002", "result": "\u572885\u4e2a\u95ee\u7b54\u53c2\u8003\u4e09\u5143\u7ec4\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u667a\u80fdRAG\u7cfb\u7edf\u5728\u68c0\u7d22\u7cbe\u5ea6\u548c\u76f8\u5173\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\uff0c\u4f46\u5ef6\u8fdf\u6709\u6240\u589e\u52a0\u3002", "conclusion": "\u7ed3\u6784\u5316\u591a\u4ee3\u7406\u65b9\u6cd5\u4e3a\u589e\u5f3a\u590d\u6742\u9886\u57df\u7279\u5b9a\u73af\u5883\u4e2d\u7684\u68c0\u7d22\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2510.25528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25528", "abs": "https://arxiv.org/abs/2510.25528", "authors": ["Yuyuan Zeng", "Yufei Huang", "Can Xu", "Qingfeng Sun", "Jianfeng Yan", "Guanghui Xu", "Tao Yang", "Fengzong Lian"], "title": "Zero Reinforcement Learning Towards General Domains", "comment": null, "summary": "Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach\nfor enhancing the reasoning capabilities of large language models (LLMs) by\ndirectly applying reinforcement learning with verifiable rewards on pretrained\nmodels, without the need for a supervised fine-tuning phase. However, current\nresearch on zero-RL primarily focuses on domains with easily verifiable reward\nsignals, such as mathematics, programming, and other reasoning tasks. The\nchallenge of eliciting reasoning abilities in more diverse scenarios, where\nverification is not straightforward, remains underexplored. To address this\ngap, we propose a novel zero-RL paradigm designed to improve a model's\nreasoning ability across both verifiable and non-verifiable domains. By\ncombining verifiable rewards with a generative reward model, we conduct\nmulti-task zero-RL training across both domains, facilitating the transfer of\nreasoning capabilities between them. Furthermore, to mitigate reward hacking in\nthe generative reward model, we design a smooth length penalty that encourages\nthe generation of more comprehensive thinking tokens in general domains.\nExperimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our\napproach achieves superior reasoning performance, not only on tasks requiring\nextensive reasoning but also on more general tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u96f6\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff0c\u901a\u8fc7\u7ed3\u5408\u53ef\u9a8c\u8bc1\u5956\u52b1\u548c\u751f\u6210\u5956\u52b1\u6a21\u578b\uff0c\u5728\u53ef\u9a8c\u8bc1\u548c\u4e0d\u53ef\u9a8c\u8bc1\u9886\u57df\u8fdb\u884c\u591a\u4efb\u52a1\u8bad\u7ec3\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u96f6\u5f3a\u5316\u5b66\u4e60\u4e3b\u8981\u5173\u6ce8\u5956\u52b1\u4fe1\u53f7\u5bb9\u6613\u9a8c\u8bc1\u7684\u9886\u57df\uff08\u5982\u6570\u5b66\u3001\u7f16\u7a0b\uff09\uff0c\u5728\u9a8c\u8bc1\u4e0d\u76f4\u63a5\u7684\u5176\u4ed6\u591a\u6837\u5316\u573a\u666f\u4e2d\u6fc0\u53d1\u63a8\u7406\u80fd\u529b\u7684\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u7ed3\u5408\u53ef\u9a8c\u8bc1\u5956\u52b1\u4e0e\u751f\u6210\u5956\u52b1\u6a21\u578b\u8fdb\u884c\u591a\u4efb\u52a1\u96f6\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u8bbe\u8ba1\u5e73\u6ed1\u957f\u5ea6\u60e9\u7f5a\u673a\u5236\u6765\u9f13\u52b1\u751f\u6210\u66f4\u5168\u9762\u7684\u601d\u8003\u6807\u8bb0\uff0c\u9632\u6b62\u5956\u52b1\u653b\u51fb\u3002", "result": "\u5728Qwen3-8B-Base\u548cQwen3-14B-Base\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9700\u8981\u5e7f\u6cdb\u63a8\u7406\u7684\u4efb\u52a1\u548c\u66f4\u4e00\u822c\u7684\u4efb\u52a1\u4e0a\u90fd\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u63d0\u5347\u4e86\u6a21\u578b\u5728\u53ef\u9a8c\u8bc1\u548c\u4e0d\u53ef\u9a8c\u8bc1\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u591a\u4efb\u52a1\u8bad\u7ec3\u5b9e\u73b0\u4e86\u63a8\u7406\u80fd\u529b\u5728\u4e0d\u540c\u9886\u57df\u95f4\u7684\u8fc1\u79fb\u3002"}}
{"id": "2510.25529", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25529", "abs": "https://arxiv.org/abs/2510.25529", "authors": ["Likun Wang", "Xiangteng Zhang", "Yinuo Wang", "Guojian Zhan", "Wenxuan Wang", "Haoyu Gao", "Jingliang Duan", "Shengbo Eben Li"], "title": "Off-policy Reinforcement Learning with Model-based Exploration Augmentation", "comment": null, "summary": "Exploration is fundamental to reinforcement learning (RL), as it determines\nhow effectively an agent discovers and exploits the underlying structure of its\nenvironment to achieve optimal performance. Existing exploration methods\ngenerally fall into two categories: active exploration and passive exploration.\nThe former introduces stochasticity into the policy but struggles in\nhigh-dimensional environments, while the latter adaptively prioritizes\ntransitions in the replay buffer to enhance exploration, yet remains\nconstrained by limited sample diversity. To address the limitation in passive\nexploration, we propose Modelic Generative Exploration (MoGE), which augments\nexploration through the generation of under-explored critical states and\nsynthesis of dynamics-consistent experiences through transition models. MoGE is\ncomposed of two components: (1) a diffusion-based generator that synthesizes\ncritical states under the guidance of a utility function evaluating each\nstate's potential influence on policy exploration, and (2) a one-step\nimagination world model for constructing critical transitions based on the\ncritical states for agent learning. Our method adopts a modular formulation\nthat aligns with the principles of off-policy learning, allowing seamless\nintegration with existing algorithms to improve exploration without altering\ntheir core structures. Empirical results on OpenAI Gym and DeepMind Control\nSuite reveal that MoGE effectively bridges exploration and policy learning,\nleading to remarkable gains in both sample efficiency and performance across\ncomplex control tasks.", "AI": {"tldr": "\u63d0\u51faMoGE\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u672a\u5145\u5206\u63a2\u7d22\u7684\u5173\u952e\u72b6\u6001\u548c\u52a8\u6001\u4e00\u81f4\u7684\u7ecf\u9a8c\u6765\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22\u80fd\u529b\uff0c\u63d0\u9ad8\u6837\u672c\u6548\u7387\u548c\u6027\u80fd", "motivation": "\u73b0\u6709\u63a2\u7d22\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u4e3b\u52a8\u63a2\u7d22\u5728\u9ad8\u7ef4\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u88ab\u52a8\u63a2\u7d22\u53d7\u9650\u4e8e\u6837\u672c\u591a\u6837\u6027\u4e0d\u8db3\u3002\u9700\u8981\u89e3\u51b3\u88ab\u52a8\u63a2\u7d22\u7684\u5c40\u9650\u6027", "method": "MoGE\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1a(1)\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u5173\u952e\u72b6\u6001\u751f\u6210\u5668\uff0c\u901a\u8fc7\u6548\u7528\u51fd\u6570\u8bc4\u4f30\u72b6\u6001\u5bf9\u7b56\u7565\u63a2\u7d22\u7684\u6f5c\u5728\u5f71\u54cd\uff1b(2)\u4e00\u6b65\u60f3\u8c61\u4e16\u754c\u6a21\u578b\uff0c\u57fa\u4e8e\u5173\u952e\u72b6\u6001\u6784\u5efa\u5173\u952e\u8f6c\u6362\u7528\u4e8e\u667a\u80fd\u4f53\u5b66\u4e60", "result": "\u5728OpenAI Gym\u548cDeepMind Control Suite\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMoGE\u6709\u6548\u8fde\u63a5\u4e86\u63a2\u7d22\u548c\u7b56\u7565\u5b66\u4e60\uff0c\u5728\u590d\u6742\u63a7\u5236\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u548c\u6027\u80fd", "conclusion": "MoGE\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u53ef\u4e0e\u73b0\u6709\u7b97\u6cd5\u65e0\u7f1d\u96c6\u6210\uff0c\u5728\u4e0d\u6539\u53d8\u6838\u5fc3\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\u6539\u5584\u63a2\u7d22\u80fd\u529b"}}
{"id": "2510.25588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25588", "abs": "https://arxiv.org/abs/2510.25588", "authors": ["Eranga Bandara", "Ross Gore", "Atmaram Yarlagadda", "Anita H. Clayton", "Preston Samuel", "Christopher K. Rhea", "Sachin Shetty"], "title": "Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System", "comment": null, "summary": "The diagnosis of most mental disorders, including psychiatric evaluations,\nprimarily depends on dialogues between psychiatrists and patients. This\nsubjective process can lead to variability in diagnoses across clinicians and\npatients, resulting in inconsistencies and challenges in achieving reliable\noutcomes. To address these issues and standardize psychiatric diagnoses, we\npropose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss\nReasoning LLM-enabled Decision Support System for the clinical diagnosis of\nmental disorders. Our approach leverages fine-tuned LLMs trained on\nconversational datasets involving psychiatrist-patient interactions focused on\nmental health conditions (e.g., depression). The diagnostic predictions from\nindividual models are aggregated through a consensus-based decision-making\nprocess, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method\nfor deploying LLM agents that orchestrate communication between the LLM\nconsortium and the reasoning LLM, ensuring transparency, reliability, and\nresponsible AI across the entire diagnostic workflow. Experimental results\ndemonstrate the transformative potential of combining fine-tuned LLMs with a\nreasoning model to create a robust and highly accurate diagnostic system for\nmental health assessment. A prototype of the proposed platform, integrating\nthree fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in\ncollaboration with the U.S. Army Medical Research Team in Norfolk, Virginia,\nUSA. To the best of our knowledge, this work represents the first application\nof a fine-tuned LLM consortium integrated with a reasoning LLM for clinical\nmental health diagnosis paving the way for next-generation AI-powered eHealth\nsystems aimed at standardizing psychiatric diagnoses.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u8054\u76df\u548c\u63a8\u7406LLM\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u7528\u4e8e\u7cbe\u795e\u969c\u788d\u7684\u4e34\u5e8a\u8bca\u65ad\uff0c\u901a\u8fc7\u5171\u8bc6\u51b3\u7b56\u548c\u63a8\u7406\u6a21\u578b\u63d0\u5347\u8bca\u65ad\u6807\u51c6\u5316\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7cbe\u795e\u75be\u75c5\u8bca\u65ad\u4f9d\u8d56\u533b\u60a3\u5bf9\u8bdd\uff0c\u5b58\u5728\u4e3b\u89c2\u6027\u548c\u8bca\u65ad\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u9700\u8981\u6807\u51c6\u5316\u65b9\u6cd5\u6765\u63d0\u9ad8\u8bca\u65ad\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u5728\u7cbe\u795e\u79d1\u533b\u60a3\u5bf9\u8bdd\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u7684LLMs\uff0c\u901a\u8fc7\u5171\u8bc6\u51b3\u7b56\u673a\u5236\u805a\u5408\u5404\u6a21\u578b\u9884\u6d4b\uff0c\u5e76\u7531OpenAI-gpt-oss\u63a8\u7406LLM\u8fdb\u884c\u7cbe\u70bc\uff0c\u90e8\u7f72LLM\u4ee3\u7406\u534f\u8c03\u6574\u4e2a\u8bca\u65ad\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u5fae\u8c03LLMs\u548c\u63a8\u7406\u6a21\u578b\u80fd\u591f\u521b\u5efa\u5f3a\u5927\u4e14\u9ad8\u7cbe\u5ea6\u7684\u7cbe\u795e\u5065\u5eb7\u8bc4\u4f30\u8bca\u65ad\u7cfb\u7edf\uff0c\u539f\u578b\u7cfb\u7edf\u5df2\u4e0e\u7f8e\u56fd\u9646\u519b\u533b\u7597\u7814\u7a76\u56e2\u961f\u5408\u4f5c\u5f00\u53d1\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5c06\u5fae\u8c03LLM\u8054\u76df\u4e0e\u63a8\u7406LLM\u96c6\u6210\u7528\u4e8e\u4e34\u5e8a\u7cbe\u795e\u5065\u5eb7\u8bca\u65ad\u7684\u5e94\u7528\uff0c\u4e3a\u4e0b\u4e00\u4ee3AI\u9a71\u52a8\u7684eHealth\u7cfb\u7edf\u6807\u51c6\u5316\u7cbe\u795e\u79d1\u8bca\u65ad\u5f00\u8f9f\u4e86\u9053\u8def\u3002"}}
{"id": "2510.25612", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.25612", "abs": "https://arxiv.org/abs/2510.25612", "authors": ["Amit Giloni", "Chiara Picardi", "Roy Betser", "Shamik Bose", "Aishvariya Priya Rathina Sabapathy", "Roman Vainshtein"], "title": "Counterfactual-based Agent Influence Ranker for Agentic AI Workflows", "comment": "Accepted to EMNLP 2025, 27 pages, 6 figures", "summary": "An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system,\nis an autonomous system that assembles several LLM-based agents to work\ncollaboratively towards a shared goal. The high autonomy, widespread adoption,\nand growing interest in such AAWs highlight the need for a deeper understanding\nof their operations, from both quality and security aspects. To this day, there\nare no existing methods to assess the influence of each agent on the AAW's\nfinal output. Adopting techniques from related fields is not feasible since\nexisting methods perform only static structural analysis, which is unsuitable\nfor inference time execution. We present Counterfactual-based Agent Influence\nRanker (CAIR) - the first method for assessing the influence level of each\nagent on the AAW's output and determining which agents are the most\ninfluential. By performing counterfactual analysis, CAIR provides a\ntask-agnostic analysis that can be used both offline and at inference time. We\nevaluate CAIR using an AAWs dataset of our creation, containing 30 different\nuse cases with 230 different functionalities. Our evaluation showed that CAIR\nproduces consistent rankings, outperforms baseline methods, and can easily\nenhance the effectiveness and relevancy of downstream tasks.", "AI": {"tldr": "CAIR\u662f\u9996\u4e2a\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5404\u667a\u80fd\u4f53\u5bf9\u6700\u7ec8\u8f93\u51fa\u5f71\u54cd\u7a0b\u5ea6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u5206\u6790\u63d0\u4f9b\u4efb\u52a1\u65e0\u5173\u7684\u5206\u6790\u80fd\u529b\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u8fdb\u884c\u9759\u6001\u7ed3\u6784\u5206\u6790\uff0c\u4e0d\u9002\u7528\u4e8e\u63a8\u7406\u65f6\u6267\u884c\uff0c\u4e14\u6ca1\u6709\u65b9\u6cd5\u80fd\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5404\u667a\u80fd\u4f53\u5bf9\u6700\u7ec8\u8f93\u51fa\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u53cd\u4e8b\u5b9e\u5206\u6790\u6280\u672f\uff0c\u901a\u8fc7\u6539\u53d8\u667a\u80fd\u4f53\u7684\u8f93\u51fa\u6765\u8bc4\u4f30\u5176\u5bf9\u7cfb\u7edf\u6700\u7ec8\u8f93\u51fa\u7684\u5f71\u54cd\u7a0b\u5ea6\u3002", "result": "\u5728\u5305\u542b30\u4e2a\u7528\u4f8b\u548c230\u4e2a\u529f\u80fd\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cCAIR\u4ea7\u751f\u4e00\u81f4\u7684\u6392\u540d\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u6709\u6548\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u7684\u6548\u679c\u548c\u76f8\u5173\u6027\u3002", "conclusion": "CAIR\u662f\u9996\u4e2a\u80fd\u591f\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u667a\u80fd\u4f53\u5f71\u54cd\u529b\u7684\u65b9\u6cd5\uff0c\u4e3a\u7406\u89e3\u548c\u4f18\u5316\u6b64\u7c7b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2510.25668", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.25668", "abs": "https://arxiv.org/abs/2510.25668", "authors": ["Tianyu Yang", "Terry Ruas", "Yijun Tian", "Jan Philip Wahle", "Daniel Kurzawe", "Bela Gipp"], "title": "ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents", "comment": null, "summary": "Vision-language models (VLMs) excel at interpreting text-rich images but\nstruggle with long, visually complex documents that demand analysis and\nintegration of information spread across multiple pages. Existing approaches\ntypically rely on fixed reasoning templates or rigid pipelines, which force\nVLMs into a passive role and hinder both efficiency and generalization. We\npresent Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement\nlearning framework that fine-tunes VLMs as interactive agents capable of\nactively navigating long, visually rich documents. ALDEN introduces a novel\nfetch action that directly accesses the page by index, complementing the\nclassic search action and better exploiting document structure. For dense\nprocess supervision and efficient training, we propose a rule-based cross-level\nreward that provides both turn- and token-level signals. To address the\nempirically observed training instability caused by numerous visual tokens from\nlong documents, we further propose a visual-semantic anchoring mechanism that\napplies a dual-path KL-divergence constraint to stabilize visual and textual\nrepresentations separately during training. Trained on a corpus constructed\nfrom three open-source datasets, ALDEN achieves state-of-the-art performance on\nfive long-document benchmarks. Overall, ALDEN marks a step beyond passive\ndocument reading toward agents that autonomously navigate and reason across\nlong, visually rich documents, offering a robust path to more accurate and\nefficient long-document understanding.", "AI": {"tldr": "ALDEN\u662f\u4e00\u4e2a\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e3a\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\uff0c\u4f7f\u5176\u80fd\u591f\u4e3b\u52a8\u5bfc\u822a\u957f\u6587\u6863\u3002\u5b83\u5f15\u5165\u4e86\u76f4\u63a5\u6309\u7d22\u5f15\u8bbf\u95ee\u9875\u9762\u7684fetch\u52a8\u4f5c\uff0c\u5e76\u63d0\u51fa\u4e86\u8de8\u7ea7\u522b\u5956\u52b1\u548c\u89c6\u89c9\u8bed\u4e49\u951a\u5b9a\u673a\u5236\u6765\u89e3\u51b3\u8bad\u7ec3\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u9700\u8981\u8de8\u591a\u9875\u5206\u6790\u548c\u6574\u5408\u4fe1\u606f\u7684\u89c6\u89c9\u590d\u6742\u957f\u6587\u6863\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u7684\u63a8\u7406\u6a21\u677f\u6216\u521a\u6027\u6d41\u7a0b\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5f15\u5165fetch\u52a8\u4f5c\u76f4\u63a5\u6309\u7d22\u5f15\u8bbf\u95ee\u9875\u9762\uff0c\u63d0\u51fa\u57fa\u4e8e\u89c4\u5219\u7684\u8de8\u7ea7\u522b\u5956\u52b1\u8fdb\u884c\u5bc6\u96c6\u8fc7\u7a0b\u76d1\u7763\uff0c\u4ee5\u53ca\u89c6\u89c9\u8bed\u4e49\u951a\u5b9a\u673a\u5236\u6765\u7a33\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5728\u4e09\u4e2a\u5f00\u6e90\u6570\u636e\u96c6\u6784\u5efa\u7684\u8bed\u6599\u5e93\u4e0a\u8bad\u7ec3\u540e\uff0cALDEN\u5728\u4e94\u4e2a\u957f\u6587\u6863\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "ALDEN\u6807\u5fd7\u7740\u4ece\u88ab\u52a8\u6587\u6863\u9605\u8bfb\u5411\u80fd\u591f\u81ea\u4e3b\u5bfc\u822a\u548c\u63a8\u7406\u957f\u89c6\u89c9\u4e30\u5bcc\u6587\u6863\u7684\u667a\u80fd\u4f53\u7684\u8f6c\u53d8\uff0c\u4e3a\u66f4\u51c6\u786e\u548c\u9ad8\u6548\u7684\u957f\u6587\u6863\u7406\u89e3\u63d0\u4f9b\u4e86\u7a33\u5065\u8def\u5f84\u3002"}}
{"id": "2510.25679", "categories": ["cs.AI", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.25679", "abs": "https://arxiv.org/abs/2510.25679", "authors": ["Federica Tonti", "Ricardo Vinuesa"], "title": "Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning", "comment": null, "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for\ndelivery and surveillance purposes. In this work, we develop an optimal\nnavigation strategy based on Deep Reinforcement Learning. The environment is\nrepresented by a three-dimensional high-fidelity simulation of an urban flow,\ncharacterized by turbulence and recirculation zones. The algorithm presented\nhere is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated\nTransformer eXtra Large (GTrXL) architecture, giving the agent richer\ninformation about the turbulent flow field in which it navigates. The results\nare compared with a PPO+GTrXL without the secondary prediction tasks, a PPO\ncombined with Long Short Term Memory (LSTM) cells and a traditional navigation\nalgorithm. The obtained results show a significant increase in the success rate\n(SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the\nclassical Zermelo's navigation algorithm, paving the way to a completely\nreimagined UAV landscape in complex urban environments.", "AI": {"tldr": "\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u65e0\u4eba\u673a\u6700\u4f18\u5bfc\u822a\u7b56\u7565\uff0c\u5728\u4e09\u7ef4\u57ce\u5e02\u6e4d\u6d41\u73af\u5883\u4e2d\u4f7f\u7528PPO+GTrXL\u67b6\u6784\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6210\u529f\u7387\u548c\u964d\u4f4e\u4e86\u78b0\u649e\u7387\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u5728\u57ce\u5e02\u4e2d\u7528\u4e8e\u914d\u9001\u548c\u76d1\u63a7\u7684\u666e\u53ca\uff0c\u9700\u8981\u5f00\u53d1\u5728\u590d\u6742\u57ce\u5e02\u6e4d\u6d41\u73af\u5883\u4e2d\u7684\u9ad8\u6548\u5bfc\u822a\u7b56\u7565\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6d41\u611f\u77e5\u7684PPO\u7b97\u6cd5\u7ed3\u5408GTrXL\u67b6\u6784\uff0c\u4e3a\u667a\u80fd\u4f53\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u6e4d\u6d41\u573a\u4fe1\u606f\uff0c\u5e76\u4e0ePPO+LSTM\u3001PPO+GTrXL\uff08\u65e0\u9884\u6d4b\u4efb\u52a1\uff09\u548c\u4f20\u7edfZermelo\u5bfc\u822a\u7b97\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u76f8\u6bd4PPO+LSTM\u3001PPO+GTrXL\u548c\u4f20\u7edfZermelo\u7b97\u6cd5\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6210\u529f\u7387(SR)\u5e76\u964d\u4f4e\u4e86\u78b0\u649e\u7387(CR)\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\u65e0\u4eba\u673a\u7684\u5bfc\u822a\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u6709\u671b\u91cd\u5851\u65e0\u4eba\u673a\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u5e94\u7528\u683c\u5c40\u3002"}}
{"id": "2510.25724", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25724", "abs": "https://arxiv.org/abs/2510.25724", "authors": ["Vanya Arikutharam", "Arkadiy Ukolov"], "title": "BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph", "comment": null, "summary": "Retrieval-Augmented Generation allows LLMs to access external knowledge,\nreducing hallucinations and ageing-data issues. However, it treats retrieved\nchunks independently and struggles with multi-hop or relational reasoning,\nespecially across documents. Knowledge graphs enhance this by capturing the\nrelationships between entities using triplets, enabling structured, multi-chunk\nreasoning. However, these tend to miss information that fails to conform to the\ntriplet structure. We introduce BambooKG, a knowledge graph with\nfrequency-based weights on non-triplet edges which reflect link strength,\ndrawing on the Hebbian principle of \"fire together, wire together\". This\ndecreases information loss and results in improved performance on single- and\nmulti-hop reasoning, outperforming the existing solutions.", "AI": {"tldr": "BambooKG\u662f\u4e00\u79cd\u5e26\u9891\u7387\u6743\u91cd\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u901a\u8fc7\u975e\u4e09\u5143\u7ec4\u8fb9\u51cf\u5c11\u4fe1\u606f\u635f\u5931\uff0c\u63d0\u5347\u5355\u8df3\u548c\u591a\u8df3\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u72ec\u7acb\u5904\u7406\u68c0\u7d22\u5757\uff0c\u96be\u4ee5\u8fdb\u884c\u591a\u8df3\u6216\u5173\u7cfb\u63a8\u7406\uff1b\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u4f1a\u4e22\u5931\u4e0d\u7b26\u5408\u4e09\u5143\u7ec4\u7ed3\u6784\u7684\u4fe1\u606f\u3002", "method": "\u5f15\u5165BambooKG\u77e5\u8bc6\u56fe\u8c31\uff0c\u5728\u975e\u4e09\u5143\u7ec4\u8fb9\u4e0a\u5e94\u7528\u57fa\u4e8e\u9891\u7387\u7684\u6743\u91cd\uff0c\u53cd\u6620\u94fe\u63a5\u5f3a\u5ea6\uff0c\u501f\u9274\u8d6b\u5e03\u539f\u7406\u3002", "result": "\u51cf\u5c11\u4e86\u4fe1\u606f\u635f\u5931\uff0c\u5728\u5355\u8df3\u548c\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "BambooKG\u901a\u8fc7\u9891\u7387\u52a0\u6743\u7684\u975e\u4e09\u5143\u7ec4\u8fb9\u6709\u6548\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u5173\u7cfb\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.25758", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25758", "abs": "https://arxiv.org/abs/2510.25758", "authors": ["He Hu", "Yucheng Zhou", "Chiyuan Ma", "Qianning Wang", "Zheng Zhang", "Fei Ma", "Laizhong Cui", "Qi Tian"], "title": "TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling", "comment": null, "summary": "Large language models (LLMs) in psychological counseling have attracted\nincreasing attention. However, existing approaches often lack emotional\nunderstanding, adaptive strategies, and the use of therapeutic methods across\nmultiple sessions with long-term memory, leaving them far from real clinical\npractice. To address these critical gaps, we introduce TheraMind, a strategic\nand adaptive agent for longitudinal psychological counseling. The cornerstone\nof TheraMind is a novel dual-loop architecture that decouples the complex\ncounseling process into an Intra-Session Loop for tactical dialogue management\nand a Cross-Session Loop for strategic therapeutic planning. The Intra-Session\nLoop perceives the patient's emotional state to dynamically select response\nstrategies while leveraging cross-session memory to ensure continuity.\nCrucially, the Cross-Session Loop empowers the agent with long-term\nadaptability by evaluating the efficacy of the applied therapy after each\nsession and adjusting the method for subsequent interactions. We validate our\napproach in a high-fidelity simulation environment grounded in real clinical\ncases. Extensive evaluations show that TheraMind outperforms other methods,\nespecially on multi-session metrics like Coherence, Flexibility, and\nTherapeutic Attunement, validating the effectiveness of its dual-loop design in\nemulating strategic, adaptive, and longitudinal therapeutic behavior. The code\nis publicly available at https://0mwwm0.github.io/TheraMind/.", "AI": {"tldr": "TheraMind\u662f\u4e00\u4e2a\u7528\u4e8e\u7eb5\u5411\u5fc3\u7406\u54a8\u8be2\u7684\u6218\u7565\u81ea\u9002\u5e94\u4ee3\u7406\uff0c\u91c7\u7528\u521b\u65b0\u7684\u53cc\u5faa\u73af\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u5728\u5fc3\u7406\u54a8\u8be2\u4e2d\u7f3a\u4e4f\u60c5\u611f\u7406\u89e3\u3001\u81ea\u9002\u5e94\u7b56\u7565\u548c\u8de8\u4f1a\u8bdd\u957f\u671f\u8bb0\u5fc6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5fc3\u7406\u54a8\u8be2LLM\u65b9\u6cd5\u7f3a\u4e4f\u60c5\u611f\u7406\u89e3\u3001\u81ea\u9002\u5e94\u7b56\u7565\u548c\u8de8\u4f1a\u8bdd\u6cbb\u7597\u65b9\u6cd5\u7684\u957f\u671f\u8bb0\u5fc6\uff0c\u4e0e\u771f\u5b9e\u4e34\u5e8a\u5b9e\u8df5\u5dee\u8ddd\u8f83\u5927\u3002", "method": "\u63d0\u51fa\u53cc\u5faa\u73af\u67b6\u6784\uff1a\u4f1a\u8bdd\u5185\u5faa\u73af\u7528\u4e8e\u6218\u672f\u5bf9\u8bdd\u7ba1\u7406\uff0c\u611f\u77e5\u60a3\u8005\u60c5\u7eea\u72b6\u6001\u52a8\u6001\u9009\u62e9\u54cd\u5e94\u7b56\u7565\uff1b\u8de8\u4f1a\u8bdd\u5faa\u73af\u7528\u4e8e\u6218\u7565\u6cbb\u7597\u89c4\u5212\uff0c\u8bc4\u4f30\u6cbb\u7597\u6548\u679c\u5e76\u8c03\u6574\u540e\u7eed\u65b9\u6cd5\u3002", "result": "\u5728\u9ad8\u4fdd\u771f\u6a21\u62df\u73af\u5883\u4e2d\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cTheraMind\u5728\u591a\u4f1a\u8bdd\u6307\u6807\uff08\u5982\u8fde\u8d2f\u6027\u3001\u7075\u6d3b\u6027\u548c\u6cbb\u7597\u534f\u8c03\u6027\uff09\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u53cc\u5faa\u73af\u8bbe\u8ba1\u5728\u6a21\u62df\u6218\u7565\u3001\u81ea\u9002\u5e94\u548c\u7eb5\u5411\u6cbb\u7597\u884c\u4e3a\u65b9\u9762\u6709\u6548\uff0c\u9a8c\u8bc1\u4e86\u5176\u4e34\u5e8a\u5b9e\u7528\u6027\u3002"}}
