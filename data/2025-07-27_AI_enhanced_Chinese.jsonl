{"id": "2507.17930", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.17930", "abs": "https://arxiv.org/abs/2507.17930", "authors": ["Vahid Garousi", "Zafar Jafarov"], "title": "How Software Engineers Engage with AI: A Pragmatic Process Model and Decision Framework Grounded in Industry Observations", "comment": null, "summary": "Artificial Intelligence (AI) has the potential to transform Software\nEngineering (SE) by enhancing productivity, efficiency, and decision support.\nTools like GitHub Copilot and ChatGPT have given rise to \"vibe coding\"-an\nexploratory, prompt-driven development style. Yet, how software engineers\nengage with these tools in daily tasks, especially in deciding whether to\ntrust, refine, or reject AI-generated outputs, remains underexplored. This\npaper presents two complementary contributions. First, a pragmatic process\nmodel capturing real-world AI-assisted SE activities, including prompt design,\ninspection, fallback, and refinement. Second, a 2D decision framework that\ncould help developers reason about trade-offs between effort saved and output\nquality. Grounded in practitioner reports and direct observations in three\nindustry settings across Turkiye and Azerbaijan, our work illustrates how\nengineers navigate AI use with human oversight. These models offer structured,\nlightweight guidance to support more deliberate and effective use of AI tools\nin SE, contributing to ongoing discussions on practical human-AI collaboration.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u5982\u4f55\u8f85\u52a9\u8f6f\u4ef6\u5de5\u7a0b\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fc7\u7a0b\u6a21\u578b\u548c\u51b3\u7b56\u6846\u67b6\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u6743\u8861AI\u751f\u6210\u5185\u5bb9\u7684\u6548\u7387\u4e0e\u8d28\u91cf\u3002", "motivation": "\u7814\u7a76AI\u5de5\u5177\uff08\u5982GitHub Copilot\u548cChatGPT\uff09\u5728\u65e5\u5e38\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u5c24\u5176\u662f\u5f00\u53d1\u8005\u5982\u4f55\u4fe1\u4efb\u3001\u6539\u8fdb\u6216\u62d2\u7eddAI\u751f\u6210\u7684\u5185\u5bb9\u3002", "method": "\u57fa\u4e8e\u5b9e\u8df5\u8005\u62a5\u544a\u548c\u571f\u8033\u5176\u3001\u963f\u585e\u62dc\u7586\u4e09\u4e2a\u884c\u4e1a\u73af\u5883\u7684\u76f4\u63a5\u89c2\u5bdf\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fc7\u7a0b\u6a21\u578b\u548c2D\u51b3\u7b56\u6846\u67b6\u3002", "result": "\u6a21\u578b\u548c\u6846\u67b6\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u3001\u8f7b\u91cf\u7ea7\u7684\u6307\u5bfc\uff0c\u652f\u6301\u66f4\u6709\u6548\u7684\u4eba\u673a\u534f\u4f5c\u3002", "conclusion": "\u7814\u7a76\u4e3aAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u63a8\u52a8\u4e86\u4eba\u673a\u534f\u4f5c\u7684\u8ba8\u8bba\u3002"}}
{"id": "2507.17991", "categories": ["cs.SE", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.17991", "abs": "https://arxiv.org/abs/2507.17991", "authors": ["Peter Eckmann", "Adrian Barnett", "Alexandra Bannach-Brown", "Elisa Pilar Bascunan Atria", "Guillaume Cabanac", "Louise Delwen Owen Franzen", "Ma\u0142gorzata Anna Gazda", "Kaitlyn Hair", "James Howison", "Halil Kilicoglu", "Cyril Labbe", "Sarah McCann", "Vladislav Nachev", "Martijn Roelandse", "Maia Salholz-Hillel", "Robert Schulz", "Gerben ter Riet", "Colby Vorland", "Anita Bandrowski", "Tracey Weissgerber"], "title": "Use as Directed? A Comparison of Software Tools Intended to Check Rigor and Transparency of Published Work", "comment": null, "summary": "The causes of the reproducibility crisis include lack of standardization and\ntransparency in scientific reporting. Checklists such as ARRIVE and CONSORT\nseek to improve transparency, but they are not always followed by authors and\npeer review often fails to identify missing items. To address these issues,\nthere are several automated tools that have been designed to check different\nrigor criteria. We have conducted a broad comparison of 11 automated tools\nacross 9 different rigor criteria from the ScreenIT group. We found some\ncriteria, including detecting open data, where the combination of tools showed\na clear winner, a tool which performed much better than other tools. In other\ncases, including detection of inclusion and exclusion criteria, the combination\nof tools exceeded the performance of any one tool. We also identified key areas\nwhere tool developers should focus their effort to make their tool maximally\nuseful. We conclude with a set of insights and recommendations for stakeholders\nin the development of rigor and transparency detection tools. The code and data\nfor the study is available at https://github.com/PeterEckmann1/tool-comparison.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e8611\u79cd\u81ea\u52a8\u5316\u5de5\u5177\u57289\u79cd\u4e25\u8c28\u6027\u6807\u51c6\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u67d0\u4e9b\u5de5\u5177\u5728\u7279\u5b9a\u6807\u51c6\uff08\u5982\u5f00\u653e\u6570\u636e\u68c0\u6d4b\uff09\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u800c\u5de5\u5177\u7ec4\u5408\u5728\u5176\u4ed6\u6807\u51c6\uff08\u5982\u7eb3\u5165\u6392\u9664\u6807\u51c6\u68c0\u6d4b\uff09\u4e0a\u66f4\u4f18\u3002", "motivation": "\u89e3\u51b3\u79d1\u5b66\u62a5\u544a\u4e2d\u6807\u51c6\u5316\u548c\u900f\u660e\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u8bc4\u4f30\u81ea\u52a8\u5316\u5de5\u5177\u5728\u63d0\u5347\u4e25\u8c28\u6027\u548c\u900f\u660e\u5ea6\u65b9\u9762\u7684\u6548\u679c\u3002", "method": "\u5bf911\u79cd\u81ea\u52a8\u5316\u5de5\u5177\u57289\u79cd\u4e25\u8c28\u6027\u6807\u51c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u6bd4\u8f83\u3002", "result": "\u67d0\u4e9b\u5de5\u5177\u5728\u7279\u5b9a\u6807\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5de5\u5177\u7ec4\u5408\u5728\u67d0\u4e9b\u6807\u51c6\u4e0a\u8868\u73b0\u66f4\u4f73\uff0c\u5e76\u63d0\u51fa\u4e86\u5de5\u5177\u5f00\u53d1\u7684\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5bf9\u4e25\u8c28\u6027\u548c\u900f\u660e\u5ea6\u68c0\u6d4b\u5de5\u5177\u5f00\u53d1\u7684\u89c1\u89e3\u548c\u5efa\u8bae\uff0c\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u5df2\u516c\u5f00\u3002"}}
{"id": "2507.18029", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18029", "abs": "https://arxiv.org/abs/2507.18029", "authors": ["Xiang Echo Chen", "Wenhan Zhu", "Guoshuai Albert Shi", "Michael W. Godfrey"], "title": "An Empirical Study of GenAI Adoption in Open-Source Game Development: Tools, Tasks, and Developer Challenges", "comment": null, "summary": "The growing capabilities of generative AI (GenAI) have begun to reshape how\ngames are designed and developed, offering new tools for content creation,\ngameplay simulation, and design ideation. While prior research has explored\ntraditional uses of AI in games, such as controlling agents or generating\nprocedural content. There is limited empirical understanding of how GenAI is\nadopted by developers in real-world contexts, especially within the open-source\ncommunity. This study aims to explore how GenAI technologies are discussed,\nadopted, and integrated into open-source game development by analyzing issue\ndiscussions on GitHub. We investigate the tools, tasks, and challenges\nassociated with GenAI by comparing GenAI-related issues to those involving\ntraditional AI (TradAI) and NonAI topics. Our goal is to uncover how GenAI\ndiffers from other approaches in terms of usage patterns, developer concerns,\nand integration practices. To address this objective, we construct a dataset of\nopen-source game repositories that discuss AI-related topics. We apply open\ncard sorting and thematic analysis to a stratified sample of GitHub issues,\nlabelling each by type and content. These annotations enable comparative\nanalysis across GenAI, TradAI, and NonAI groups, and provide insight into how\nGenAI is shaping the workflows and pain points of open-source game developers.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\uff08GenAI\uff09\u5728\u5f00\u6e90\u6e38\u620f\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u5206\u6790GitHub\u4e0a\u7684\u95ee\u9898\u8ba8\u8bba\uff0c\u6bd4\u8f83\u4e86GenAI\u4e0e\u4f20\u7edfAI\uff08TradAI\uff09\u53ca\u975eAI\u8bdd\u9898\u7684\u5dee\u5f02\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u6e38\u620f\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u5728\u5f00\u6e90\u793e\u533a\u4e2d\u5b9e\u9645\u5e94\u7528\u7684\u5b9e\u8bc1\u7814\u7a76\u3002", "method": "\u6784\u5efa\u5f00\u6e90\u6e38\u620f\u4ed3\u5e93\u6570\u636e\u96c6\uff0c\u5bf9GitHub\u95ee\u9898\u8fdb\u884c\u5f00\u653e\u5f0f\u5361\u7247\u5206\u7c7b\u548c\u4e3b\u9898\u5206\u6790\uff0c\u6bd4\u8f83GenAI\u3001TradAI\u548c\u975eAI\u8bdd\u9898\u3002", "result": "\u63ed\u793a\u4e86GenAI\u5728\u5f00\u6e90\u6e38\u620f\u5f00\u53d1\u4e2d\u7684\u4f7f\u7528\u6a21\u5f0f\u3001\u5f00\u53d1\u8005\u5173\u6ce8\u70b9\u53ca\u96c6\u6210\u5b9e\u8df5\u3002", "conclusion": "GenAI\u5728\u6e38\u620f\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u4e0e\u4f20\u7edfAI\u548c\u975eAI\u65b9\u6cd5\u6709\u660e\u663e\u5dee\u5f02\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u548c\u6311\u6218\u3002"}}
{"id": "2507.18037", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18037", "abs": "https://arxiv.org/abs/2507.18037", "authors": ["Sivana Hamer", "Jacob Bowen", "Md Nazmul Haque", "Chris Madden", "Laurie Williams"], "title": "Your ATs to Ts: MITRE ATT&CK Attack Technique to P-SSCRM Task Mapping", "comment": "Mapping generated from: arXiv:2503.12192", "summary": "The MITRE Adversarial Tactics, Techniques and Common Knowledge (MITRE ATT&CK)\nAttack Technique to Proactive Software Supply Chain Risk Management Framework\n(P-SSCRM) Task mapping described in this document helps software organizations\nto determine how different tasks mitigate the attack techniques of software\nsupply chain attacks. The mapping was created through four independent\nstrategies to find agreed-upon mappings. Because each P-SSCRM task is mapped to\none or more tasks from the 10 frameworks, the mapping we provide is also a\nmapping between MITRE ATT&CK and other prominent government and industry\nframeworks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63cf\u8ff0\u4e86MITRE ATT&CK\u653b\u51fb\u6280\u672f\u4e0eP-SSCRM\u6846\u67b6\u4efb\u52a1\u7684\u6620\u5c04\uff0c\u5e2e\u52a9\u8f6f\u4ef6\u7ec4\u7ec7\u8bc6\u522b\u4efb\u52a1\u5982\u4f55\u7f13\u89e3\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u3002", "motivation": "\u901a\u8fc7\u5c06MITRE ATT&CK\u653b\u51fb\u6280\u672f\u4e0eP-SSCRM\u4efb\u52a1\u6620\u5c04\uff0c\u5e2e\u52a9\u8f6f\u4ef6\u7ec4\u7ec7\u66f4\u6709\u6548\u5730\u7ba1\u7406\u4f9b\u5e94\u94fe\u98ce\u9669\u3002", "method": "\u91c7\u7528\u56db\u79cd\u72ec\u7acb\u7b56\u7565\u786e\u5b9a\u6620\u5c04\u5173\u7cfb\uff0c\u5e76\u5c06P-SSCRM\u4efb\u52a1\u4e0e10\u4e2a\u5176\u4ed6\u6846\u67b6\u4efb\u52a1\u5173\u8054\u3002", "result": "\u63d0\u4f9b\u4e86MITRE ATT&CK\u4e0e\u5176\u4ed6\u653f\u5e9c\u53ca\u884c\u4e1a\u6846\u67b6\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\u3002", "conclusion": "\u8be5\u6620\u5c04\u4e3a\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u7684\u98ce\u9669\u7ba1\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2507.17850", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17850", "abs": "https://arxiv.org/abs/2507.17850", "authors": ["Rodrigo Moreira", "Larissa F. Rodrigues Moreira", "Fl\u00e1vio de Oliveira Silva"], "title": "Performance Evaluation and Threat Mitigation in Large-scale 5G Core Deployment", "comment": null, "summary": "The deployment of large-scale software-based 5G core functions presents\nsignificant challenges due to their reliance on optimized and intelligent\nresource provisioning for their services. Many studies have focused on\nanalyzing the impact of resource allocation for complex deployments using\nmathematical models, queue theories, or even Artificial Intelligence (AI). This\npaper elucidates the effects of chaotic workloads, generated by Distributed\nDenial of Service (DDoS) on different Network Functions (NFs) on User Equipment\nregistration performance. Our findings highlight the necessity of diverse\nresource profiles to ensure Service-Level Agreement (SLA) compliance in\nlarge-scale 5G core deployments. Additionally, our analysis of packet capture\napproaches demonstrates the potential of kernel-based monitoring for scalable\nsecurity threat defense. Finally, our empirical evaluation provides insights\ninto the effective deployment of 5G NFs in complex scenarios.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u89c4\u6a215G\u6838\u5fc3\u7f51\u7edc\u90e8\u7f72\u4e2d\u8d44\u6e90\u5206\u914d\u5bf9\u7528\u6237\u8bbe\u5907\u6ce8\u518c\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5f3a\u8c03\u4e86\u591a\u6837\u5316\u8d44\u6e90\u914d\u7f6e\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5185\u6838\u76d1\u63a7\u5728\u5b89\u5168\u9632\u5fa1\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u7814\u7a765G\u6838\u5fc3\u7f51\u7edc\u5728\u590d\u6742\u90e8\u7f72\u4e2d\u8d44\u6e90\u5206\u914d\u7684\u6311\u6218\uff0c\u7279\u522b\u662fDDoS\u653b\u51fb\u5bf9\u7f51\u7edc\u529f\u80fd\u7684\u5f71\u54cd\uff0c\u4ee5\u786e\u4fddSLA\u5408\u89c4\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6df7\u6c8c\u5de5\u4f5c\u8d1f\u8f7d\uff08\u5982DDoS\u653b\u51fb\uff09\u5bf9\u7f51\u7edc\u529f\u80fd\u7684\u5f71\u54cd\uff0c\u7ed3\u5408\u5185\u6838\u76d1\u63a7\u548c\u5b9e\u8bc1\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u591a\u6837\u5316\u8d44\u6e90\u914d\u7f6e\u5bf9\u4fdd\u969cSLA\u5408\u89c4\u6027\u81f3\u5173\u91cd\u8981\uff0c\u5185\u6838\u76d1\u63a7\u5728\u5b89\u5168\u9632\u5fa1\u4e2d\u5177\u6709\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8bba\u6587\u4e3a\u590d\u6742\u573a\u666f\u4e0b5G\u7f51\u7edc\u529f\u80fd\u7684\u6709\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u8d44\u6e90\u4f18\u5316\u548c\u5b89\u5168\u76d1\u63a7\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.17777", "categories": ["cs.AI", "76A02"], "pdf": "https://arxiv.org/pdf/2507.17777", "abs": "https://arxiv.org/abs/2507.17777", "authors": ["Theofanis Aravanis", "Grigorios Chrimatopoulos", "Mohammad Ferdows", "Michalis Xenos", "Efstratios Em Tzirtzilakis"], "title": "ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics", "comment": "This research was implemented in the framework of the Action\n  \"Flagship actions in interdisciplinary scientific fields with a special focus\n  on the productive fabric'', which is implemented through the National\n  Recovery and Resilience Fund Greece 2.0 and funded by the European\n  Union--NextGenerationEU (Project ID: TAEDR-0535983)", "summary": "Unlike conventional Machine-Learning (ML) approaches, often criticized as\n\"black boxes\", Symbolic Regression (SR) stands out as a powerful tool for\nrevealing interpretable mathematical relationships in complex physical systems,\nrequiring no a priori assumptions about models' structures. Motivated by the\nrecognition that, in fluid mechanics, an understanding of the underlying flow\nphysics is as crucial as accurate prediction, this study applies SR to model a\nfundamental three-dimensional (3D) incompressible flow in a rectangular\nchannel, focusing on the (axial) velocity and pressure fields under laminar\nconditions. By employing the PySR library, compact symbolic equations were\nderived directly from numerical simulation data, revealing key characteristics\nof the flow dynamics. These equations not only approximate the parabolic\nvelocity profile and pressure drop observed in the studied fluid flow, but also\nperfectly coincide with analytical solutions from the literature. Furthermore,\nwe propose an innovative approach that integrates SR with the\nknowledge-representation framework of Answer Set Programming (ASP), combining\nthe generative power of SR with the declarative reasoning strengths of ASP. The\nproposed hybrid SR/ASP framework ensures that the SR-generated symbolic\nexpressions are not only statistically accurate, but also physically plausible,\nadhering to domain-specific principles. Overall, the study highlights two key\ncontributions: SR's ability to simplify complex flow behaviours into concise,\ninterpretable equations, and the potential of knowledge-representation\napproaches to improve the reliability and alignment of data-driven SR models\nwith domain principles. Insights from the examined 3D channel flow pave the way\nfor integrating such hybrid approaches into efficient frameworks, [...] where\nexplainable predictions and real-time data analysis are crucial.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u7b26\u53f7\u56de\u5f52\uff08SR\uff09\u548c\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u7684\u6df7\u5408\u6846\u67b6\uff0c\u4ece\u6570\u503c\u6a21\u62df\u6570\u636e\u4e2d\u63a8\u5bfc\u51fa\u4e09\u7ef4\u4e0d\u53ef\u538b\u7f29\u6d41\u52a8\u7684\u89e3\u6790\u65b9\u7a0b\uff0c\u5c55\u793a\u4e86SR\u5728\u7b80\u5316\u590d\u6742\u6d41\u52a8\u884c\u4e3a\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u7ed3\u5408\u77e5\u8bc6\u8868\u793a\u65b9\u6cd5\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027\u7684\u521b\u65b0\u601d\u8def\u3002", "motivation": "\u5728\u6d41\u4f53\u529b\u5b66\u4e2d\uff0c\u7406\u89e3\u6d41\u52a8\u7269\u7406\u673a\u5236\u4e0e\u51c6\u786e\u9884\u6d4b\u540c\u6837\u91cd\u8981\u3002\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u800cSR\u80fd\u63ed\u793a\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u6570\u5b66\u5173\u7cfb\uff0c\u65e0\u9700\u5148\u9a8c\u6a21\u578b\u5047\u8bbe\u3002", "method": "\u4f7f\u7528PySR\u5e93\u4ece\u6570\u503c\u6a21\u62df\u6570\u636e\u4e2d\u63a8\u5bfc\u7b26\u53f7\u65b9\u7a0b\uff0c\u5e76\u7ed3\u5408ASP\u6846\u67b6\u786e\u4fdd\u65b9\u7a0b\u4e0d\u4ec5\u7edf\u8ba1\u51c6\u786e\uff0c\u8fd8\u7b26\u5408\u7269\u7406\u539f\u7406\u3002", "result": "\u63a8\u5bfc\u7684\u65b9\u7a0b\u4e0d\u4ec5\u8fd1\u4f3c\u6a21\u62df\u4e86\u629b\u7269\u7ebf\u901f\u5ea6\u5206\u5e03\u548c\u538b\u529b\u964d\uff0c\u8fd8\u4e0e\u6587\u732e\u4e2d\u7684\u89e3\u6790\u89e3\u5b8c\u5168\u543b\u5408\u3002", "conclusion": "SR\u80fd\u7b80\u5316\u590d\u6742\u6d41\u52a8\u884c\u4e3a\u4e3a\u53ef\u89e3\u91ca\u65b9\u7a0b\uff0c\u7ed3\u5408\u77e5\u8bc6\u8868\u793a\u65b9\u6cd5\u53ef\u63d0\u5347\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u9886\u57df\u4e00\u81f4\u6027\u3002"}}
{"id": "2507.18039", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18039", "abs": "https://arxiv.org/abs/2507.18039", "authors": ["Ahmad D. Suleiman", "Yiming Tang", "Daqing Hou"], "title": "Factors Impacting Faculty Adoption of Project-Based Learning in Computing Education: a Survey", "comment": "Accepted at IEEE Frontiers in Education (FIE) 2025. This work has\n  been submitted to the IEEE for possible publication", "summary": "This research full paper investigates the factors influencing computing\neducators' adoption of project-based learning (PjBL) in software engineering\nand computing curricula. Recognized as a student-centered pedagogical approach,\nPjBL has the potential to enhance student motivation, engagement, critical\nthinking, collaboration, and problem-solving skills. Despite these benefits,\nfaculty adoption remains inconsistent due to challenges such as insufficient\ninstitutional support, time constraints, limited training opportunities,\ndesigning or sourcing projects, and aligning them with course objectives. This\nresearch explores these barriers and investigates the strategies and resources\nthat facilitate a successful adoption. Using a mixed-methods approach, data\nfrom 80 computing faculty were collected through an online survey comprising\nclosed-ended questions to quantify barriers, enablers, and resource needs,\nalong with an open-ended question to gather qualitative insights. Quantitative\ndata were analyzed using statistical methods, while qualitative responses\nunderwent thematic analysis. Results reveal that while PjBL is widely valued,\nits adoption is often selective and impacted by challenges in planning and\nmanaging the learning process, designing suitable projects, and a lack of\ninstitutional support, such as time, funding, and teaching assistants. Faculty\nare more likely to adopt or sustain PjBL when they have access to peer\ncollaboration, professional development, and institutional incentives. In\naddition, sourcing projects from research, industry partnerships, and borrowing\nfrom peers emerged as key facilitators for new projects. These findings\nunderscore the need for systemic support structures to empower faculty to\nexperiment with and scale PjBL practices.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5f71\u54cd\u8ba1\u7b97\u6559\u80b2\u8005\u91c7\u7528\u9879\u76ee\u5f0f\u5b66\u4e60\uff08PjBL\uff09\u7684\u56e0\u7d20\uff0c\u53d1\u73b0\u5c3d\u7ba1PjBL\u88ab\u5e7f\u6cdb\u8ba4\u53ef\uff0c\u4f46\u91c7\u7528\u4ecd\u53d7\u9650\u4e8e\u89c4\u5212\u3001\u7ba1\u7406\u3001\u9879\u76ee\u8bbe\u8ba1\u53ca\u673a\u6784\u652f\u6301\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "motivation": "\u9879\u76ee\u5f0f\u5b66\u4e60\uff08PjBL\uff09\u80fd\u63d0\u5347\u5b66\u751f\u52a8\u673a\u3001\u53c2\u4e0e\u5ea6\u53ca\u591a\u9879\u6280\u80fd\uff0c\u4f46\u6559\u5e08\u91c7\u7528\u7387\u4e0d\u4e00\u81f4\uff0c\u9700\u63a2\u7a76\u969c\u788d\u53ca\u4fc3\u8fdb\u7b56\u7565\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u7ebf\u8c03\u67e5\u6536\u96c680\u540d\u8ba1\u7b97\u6559\u5e08\u7684\u5b9a\u91cf\u548c\u5b9a\u6027\u6570\u636e\uff0c\u8fdb\u884c\u7edf\u8ba1\u548c\u4e3b\u9898\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793aPjBL\u867d\u53d7\u91cd\u89c6\uff0c\u4f46\u91c7\u7528\u53d7\u9650\u4e8e\u89c4\u5212\u3001\u9879\u76ee\u8bbe\u8ba1\u53ca\u673a\u6784\u652f\u6301\u4e0d\u8db3\uff1b\u540c\u884c\u534f\u4f5c\u3001\u4e13\u4e1a\u53d1\u5c55\u548c\u673a\u6784\u6fc0\u52b1\u662f\u4fc3\u8fdb\u56e0\u7d20\u3002", "conclusion": "\u9700\u7cfb\u7edf\u6027\u652f\u6301\u7ed3\u6784\u4ee5\u5e2e\u52a9\u6559\u5e08\u5b9e\u9a8c\u548c\u6269\u5c55PjBL\u5b9e\u8df5\u3002"}}
{"id": "2507.17888", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17888", "abs": "https://arxiv.org/abs/2507.17888", "authors": ["Nima Atashin", "Behrouz Tork Ladani", "Mohammadreza Sharbaf"], "title": "Learning to Locate: GNN-Powered Vulnerability Path Discovery in Open Source Code", "comment": "8 pages, 5 Figures", "summary": "Detecting security vulnerabilities in open-source software is a critical task\nthat is highly regarded in the related research communities. Several approaches\nhave been proposed in the literature for detecting vulnerable codes and\nidentifying the classes of vulnerabilities. However, there is still room to\nwork in explaining the root causes of detected vulnerabilities through locating\nvulnerable statements and the discovery of paths leading to the activation of\nthe vulnerability. While frameworks like SliceLocator offer explanations by\nidentifying vulnerable paths, they rely on rule-based sink identification that\nlimits their generalization. In this paper, we introduce VulPathFinder, an\nexplainable vulnerability path discovery framework that enhances SliceLocator's\nmethodology by utilizing a novel Graph Neural Network (GNN) model for detecting\nsink statements, rather than relying on predefined rules. The proposed GNN\ncaptures semantic and syntactic dependencies to find potential sink points\n(PSPs), which are candidate statements where vulnerable paths end. After\ndetecting PSPs, program slicing can be used to extract potentially vulnerable\npaths, which are then ranked by feeding them back into the target graph-based\ndetector. Ultimately, the most probable path is returned, explaining the root\ncause of the detected vulnerability. We demonstrated the effectiveness of the\nproposed approach by performing evaluations on a benchmark of the buffer\noverflow CWEs from the SARD dataset, providing explanations for the\ncorresponding detected vulnerabilities. The results show that VulPathFinder\noutperforms both original SliceLocator and GNNExplainer (as a general GNN\nexplainability tool) in discovery of vulnerability paths to identified PSPs.", "AI": {"tldr": "VulPathFinder\u662f\u4e00\u4e2a\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u6f0f\u6d1e\u8def\u5f84\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7\u6539\u8fdbSliceLocator\u7684\u65b9\u6cd5\uff0c\u63d0\u4f9b\u66f4\u901a\u7528\u7684\u6f0f\u6d1e\u6839\u56e0\u89e3\u91ca\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982SliceLocator\uff09\u4f9d\u8d56\u89c4\u5219\u8bc6\u522b\u6f0f\u6d1e\u8def\u5f84\uff0c\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u9700\u6539\u8fdb\u4ee5\u66f4\u51c6\u786e\u5730\u89e3\u91ca\u6f0f\u6d1e\u6839\u56e0\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eGNN\u7684\u6a21\u578b\uff0c\u6355\u6349\u8bed\u4e49\u548c\u53e5\u6cd5\u4f9d\u8d56\u4ee5\u8bc6\u522b\u6f5c\u5728\u6f0f\u6d1e\u7ec8\u70b9\uff08PSPs\uff09\uff0c\u5e76\u901a\u8fc7\u7a0b\u5e8f\u5207\u7247\u63d0\u53d6\u548c\u6392\u5e8f\u6f0f\u6d1e\u8def\u5f84\u3002", "result": "\u5728SARD\u6570\u636e\u96c6\u7684\u7f13\u51b2\u533a\u6ea2\u51faCWE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVulPathFinder\u4f18\u4e8eSliceLocator\u548cGNNExplainer\u3002", "conclusion": "VulPathFinder\u901a\u8fc7GNN\u6539\u8fdb\u6f0f\u6d1e\u8def\u5f84\u53d1\u73b0\uff0c\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u6f0f\u6d1e\u6839\u56e0\u89e3\u91ca\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.17874", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17874", "abs": "https://arxiv.org/abs/2507.17874", "authors": ["SaiBarath Sundar", "Pranav Satheesan", "Udayaadithya Avadhanam"], "title": "I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis", "comment": null, "summary": "Recent advances in agentic systems for data analysis have emphasized\nautomation of insight generation through multi-agent frameworks, and\norchestration layers. While these systems effectively manage tasks like query\ntranslation, data transformation, and visualization, they often overlook the\nstructured reasoning process underlying analytical thinking. Reasoning large\nlanguage models (LLMs) used for multi-step problem solving are trained as\ngeneral-purpose problem solvers. As a result, their reasoning or thinking steps\ndo not adhere to fixed processes for specific tasks. Real-world data analysis\nrequires a consistent cognitive workflow: interpreting vague goals, grounding\nthem in contextual knowledge, constructing abstract plans, and adapting\nexecution based on intermediate outcomes. We introduce I2I-STRADA\n(Information-to-Insight via Structured Reasoning Agent for Data Analysis), an\nagentic architecture designed to formalize this reasoning process. I2I-STRADA\nfocuses on modeling how analysis unfolds via modular sub-tasks that reflect the\ncognitive steps of analytical reasoning. Evaluations on the DABstep and DABench\nbenchmarks show that I2I-STRADA outperforms prior systems in planning coherence\nand insight alignment, highlighting the importance of structured cognitive\nworkflows in agent design for data analysis.", "AI": {"tldr": "I2I-STRADA\u662f\u4e00\u79cd\u65b0\u578b\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u8fc7\u7a0b\u6539\u8fdb\u6570\u636e\u5206\u6790\uff0c\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u5728\u6570\u636e\u5206\u6790\u4e2d\u5ffd\u89c6\u4e86\u7ed3\u6784\u5316\u63a8\u7406\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u63a8\u7406\u6b65\u9aa4\u7f3a\u4e4f\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51faI2I-STRADA\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u5b50\u4efb\u52a1\u6a21\u62df\u8ba4\u77e5\u6b65\u9aa4\uff0c\u5b9e\u73b0\u7ed3\u6784\u5316\u63a8\u7406\u3002", "result": "\u5728DABstep\u548cDABench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\uff0c\u89c4\u5212\u4e00\u81f4\u6027\u548c\u6d1e\u5bdf\u5bf9\u9f50\u6027\u66f4\u4f18\u3002", "conclusion": "\u7ed3\u6784\u5316\u8ba4\u77e5\u5de5\u4f5c\u6d41\u5bf9\u6570\u636e\u5206\u6790\u667a\u80fd\u4f53\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.18062", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18062", "abs": "https://arxiv.org/abs/2507.18062", "authors": ["Edward Abrokwah", "Taher A. Ghaleb"], "title": "An Empirical Study of Complexity, Heterogeneity, and Compliance of GitHub Actions Workflows", "comment": "Registered Report Accepted at the 41st IEEE International Conference\n  on Software Maintenance and Evolution 2025 (ICSME'25)", "summary": "Continuous Integration (CI) has evolved from a tooling strategy to a\nfundamental mindset in modern CI engineering. It enables teams to develop,\ntest, and deliver software rapidly and collaboratively. Among CI services,\nGitHub Actions (GHA) has emerged as a dominant service due to its deep\nintegration with GitHub and a vast ecosystem of reusable workflow actions.\nAlthough GHA provides official documentation and community-supported best\npractices, there appears to be limited empirical understanding of how\nopen-source real-world CI workflows align with such practices. Many workflows\nmight be unnecessarily complex and not aligned with the simplicity goals of CI\npractices. This study will investigate the structure, complexity,\nheterogeneity, and compliance of GHA workflows in open-source software\nrepositories. Using a large dataset of GHA workflows from Java, Python, and C++\nrepositories, our goal is to (a) identify workflow complexities, (b) analyze\nrecurring and heterogeneous structuring patterns, (c) assess compliance with\nGHA best practices, and (d) uncover differences in CI pipeline design across\nprogramming languages. Our findings are expected to reveal both areas of strong\nadherence to best practices and areas for improvement where needed. These\ninsights will also have implications for CI services, as they will highlight\nthe need for clearer guidelines and comprehensive examples in CI documentation.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86GitHub Actions (GHA) \u5728\u5f00\u6e90\u9879\u76ee\u4e2d\u7684\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\uff0c\u63a2\u8ba8\u5176\u590d\u6742\u6027\u3001\u7ed3\u6784\u6a21\u5f0f\u3001\u6700\u4f73\u5b9e\u8df5\u9075\u5faa\u60c5\u51b5\u4ee5\u53ca\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u95f4\u7684\u5dee\u5f02\u3002", "motivation": "\u5c3d\u7ba1GHA\u63d0\u4f9b\u4e86\u5b98\u65b9\u6587\u6863\u548c\u793e\u533a\u6700\u4f73\u5b9e\u8df5\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5f00\u6e90\u9879\u76ee\u4e2d\u5b9e\u9645CI\u5de5\u4f5c\u6d41\u662f\u5426\u7b26\u5408\u8fd9\u4e9b\u5b9e\u8df5\u7684\u5b9e\u8bc1\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5206\u6790Java\u3001Python\u548cC++\u4ed3\u5e93\u4e2d\u7684\u5927\u91cfGHA\u5de5\u4f5c\u6d41\u6570\u636e\uff0c\u7814\u7a76\u5176\u7ed3\u6784\u3001\u590d\u6742\u6027\u3001\u5f02\u8d28\u6027\u548c\u5408\u89c4\u6027\u3002", "result": "\u9884\u8ba1\u53d1\u73b0\u6700\u4f73\u5b9e\u8df5\u7684\u5f3a\u9075\u5faa\u533a\u57df\u548c\u9700\u8981\u6539\u8fdb\u7684\u9886\u57df\uff0c\u540c\u65f6\u63ed\u793a\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u5728CI\u8bbe\u8ba1\u4e0a\u7684\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5c06\u4e3aCI\u670d\u52a1\u63d0\u4f9b\u6539\u8fdb\u5efa\u8bae\uff0c\u5f3a\u8c03\u66f4\u6e05\u6670\u7684\u6307\u5357\u548c\u5168\u9762\u7684\u6587\u6863\u793a\u4f8b\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.17956", "categories": ["cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.17956", "abs": "https://arxiv.org/abs/2507.17956", "authors": ["Russell O'Connor", "Andrew Poelstra"], "title": "Formal Verification of the Safegcd Implementation", "comment": "15 pages; Coq sources can be found at\n  https://github.com/BlockstreamResearch/simplicity/tree/c1dddedd553b403da877377e658f17f0d2184cc4/Coq/C/secp256k1\n  ; Alectryon preview can be viewed at e.g.\n  https://html-preview.github.io/?url=https://github.com/BlockstreamResearch/simplicity/blob/c1dddedd553b403da877377e658f17f0d2184cc4/alectryon/verif_modinv64_impl.v.html", "summary": "The modular inverse is an essential piece of computation required for\nelliptic curve operations used for digital signatures in Bitcoin and other\napplications. A novel approach to the extended Euclidean algorithm has been\ndeveloped by Bernstein and Yang within the last few years and incorporated into\nthe libsecp256k1 cryptographic library used by Bitcoin. However, novel\nalgorithms introduce new risks of errors. To address this we have completed a\ncomputer verified proof of the correctness of (one of) libsecp256k1's modular\ninverse implementations with the Coq proof assistant using the Verifiable C's\nimplementation of separation logic.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7Coq\u8bc1\u660e\u52a9\u624b\u9a8c\u8bc1libsecp256k1\u5e93\u4e2d\u6a21\u9006\u5b9e\u73b0\u6b63\u786e\u6027\u7684\u65b9\u6cd5\u3002", "motivation": "\u6a21\u9006\u8ba1\u7b97\u5728\u6bd4\u7279\u5e01\u7b49\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u65b0\u7b97\u6cd5\u53ef\u80fd\u5f15\u5165\u9519\u8bef\uff0c\u56e0\u6b64\u9700\u8981\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\u3002", "method": "\u4f7f\u7528Coq\u8bc1\u660e\u52a9\u624b\u548cVerifiable C\u7684\u5206\u79bb\u903b\u8f91\u5b9e\u73b0\uff0c\u5bf9libsecp256k1\u7684\u6a21\u9006\u5b9e\u73b0\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5b8c\u6210\u4e86\u5bf9libsecp256k1\u6a21\u9006\u5b9e\u73b0\u7684\u8ba1\u7b97\u673a\u9a8c\u8bc1\u8bc1\u660e\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u786e\u4fdd\u4e86\u65b0\u7b97\u6cd5\u7684\u6b63\u786e\u6027\uff0c\u964d\u4f4e\u4e86\u6f5c\u5728\u9519\u8bef\u98ce\u9669\u3002"}}
{"id": "2507.17927", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17927", "abs": "https://arxiv.org/abs/2507.17927", "authors": ["Timothy Tin Long Yu", "Mahdi Mostajabdaveh", "Jabo Serge Byusa", "Rindra Ramamonjison", "Giuseppe Carenini", "Kun Mao", "Zirui Zhou", "Yong Zhang"], "title": "SMARTAPS: Tool-augmented LLMs for Operations Management", "comment": "https://aaai.org/conference/aaai/aaai-25/bridge-ai-orms/", "summary": "Large language models (LLMs) present intriguing opportunities to enhance user\ninteraction with traditional algorithms and tools in real-world applications.\nAn advanced planning system (APS) is a sophisticated software that leverages\noptimization to help operations planners create, interpret, and modify an\noperational plan. While highly beneficial, many customers are priced out of\nusing an APS due to the ongoing costs of consultants responsible for\ncustomization and maintenance. To address the need for a more accessible APS\nexpressed by supply chain planners, we present SmartAPS, a conversational\nsystem built on a tool-augmented LLM. Our system provides operations planners\nwith an intuitive natural language chat interface, allowing them to query\ninformation, perform counterfactual reasoning, receive recommendations, and\nexecute scenario analysis to better manage their operation. A short video\ndemonstrating the system has been released: https://youtu.be/KtIrJjlDbyw", "AI": {"tldr": "SmartAPS\u662f\u4e00\u4e2a\u57fa\u4e8e\u589e\u5f3a\u5de5\u5177\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u65e8\u5728\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u754c\u9762\u63d0\u5347\u4f9b\u5e94\u94fe\u89c4\u5212\u5e08\u7684\u64cd\u4f5c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u9ad8\u7ea7\u89c4\u5212\u7cfb\u7edf\uff08APS\uff09\u56e0\u5b9a\u5236\u548c\u7ef4\u62a4\u6210\u672c\u9ad8\u6602\u800c\u96be\u4ee5\u666e\u53ca\uff0cSmartAPS\u65e8\u5728\u63d0\u4f9b\u66f4\u6613\u8bbf\u95ee\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u5de5\u5177\u589e\u5f3a\u7684LLM\u6784\u5efa\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u3001\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u63a8\u8350\u548c\u573a\u666f\u5206\u6790\u3002", "result": "SmartAPS\u4e3a\u64cd\u4f5c\u89c4\u5212\u5e08\u63d0\u4f9b\u4e86\u76f4\u89c2\u7684\u4ea4\u4e92\u65b9\u5f0f\uff0c\u63d0\u5347\u4e86\u64cd\u4f5c\u7ba1\u7406\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002", "conclusion": "SmartAPS\u901a\u8fc7LLM\u6280\u672f\u964d\u4f4e\u4e86APS\u7684\u4f7f\u7528\u95e8\u69db\uff0c\u6ee1\u8db3\u4e86\u4f9b\u5e94\u94fe\u89c4\u5212\u5e08\u7684\u9700\u6c42\u3002"}}
{"id": "2507.18081", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18081", "abs": "https://arxiv.org/abs/2507.18081", "authors": ["Carol Wong", "Mai Abe", "Silvia De Benedictis", "Marissa Halim", "Anthony Peruma"], "title": "Identifier Name Similarities: An Exploratory Study", "comment": "The 19th ACM/IEEE International Symposium on Empirical Software\n  Engineering and Measurement - Emerging Results and Vision Track", "summary": "Identifier names, which comprise a significant portion of the codebase, are\nthe cornerstone of effective program comprehension. However, research has shown\nthat poorly chosen names can significantly increase cognitive load and hinder\ncollaboration. Even names that appear readable in isolation may lead to\nmisunderstandings in contexts when they closely resemble other names in either\nstructure or functionality. In this exploratory study, we present our\npreliminary findings on the occurrence of identifier name similarity in\nsoftware projects through the development of a taxonomy that categorizes\ndifferent forms of identifier name similarity. We envision our initial taxonomy\nproviding researchers with a platform to analyze and evaluate the impact of\nidentifier name similarity on code comprehension, maintainability, and\ncollaboration among developers, while also allowing for further refinement and\nexpansion of the taxonomy.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u6807\u8bc6\u7b26\u540d\u79f0\u76f8\u4f3c\u6027\u5bf9\u4ee3\u7801\u7406\u89e3\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u7c7b\u6cd5\u3002", "motivation": "\u6807\u8bc6\u7b26\u540d\u79f0\u5bf9\u7a0b\u5e8f\u7406\u89e3\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76f8\u4f3c\u540d\u79f0\u53ef\u80fd\u5bfc\u81f4\u8bef\u89e3\u548c\u8ba4\u77e5\u8d1f\u62c5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u7c7b\u6cd5\uff0c\u7528\u4e8e\u5206\u7c7b\u6807\u8bc6\u7b26\u540d\u79f0\u76f8\u4f3c\u6027\u7684\u4e0d\u540c\u5f62\u5f0f\u3002", "result": "\u521d\u6b65\u53d1\u73b0\u6807\u8bc6\u7b26\u540d\u79f0\u76f8\u4f3c\u6027\u5728\u8f6f\u4ef6\u9879\u76ee\u4e2d\u7684\u5b58\u5728\uff0c\u5e76\u63d0\u51fa\u4e86\u5206\u7c7b\u6cd5\u3002", "conclusion": "\u5206\u7c7b\u6cd5\u4e3a\u7814\u7a76\u6807\u8bc6\u7b26\u540d\u79f0\u76f8\u4f3c\u6027\u5bf9\u4ee3\u7801\u7406\u89e3\u548c\u534f\u4f5c\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u6269\u5c55\u3002"}}
{"id": "2507.17962", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.17962", "abs": "https://arxiv.org/abs/2507.17962", "authors": ["Nowfel Mashnoor", "Mohammad Akyash", "Hadi Kamali", "Kimia Azar"], "title": "TimelyHLS: LLM-Based Timing-Aware and Architecture-Specific FPGA HLS Optimization", "comment": null, "summary": "Achieving timing closure and design-specific optimizations in FPGA-targeted\nHigh-Level Synthesis (HLS) remains a significant challenge due to the complex\ninteraction between architectural constraints, resource utilization, and the\nabsence of automated support for platform-specific pragmas. In this work, we\npropose TimelyHLS, a novel framework integrating Large Language Models (LLMs)\nwith Retrieval-Augmented Generation (RAG) to automatically generate and\niteratively refine HLS code optimized for FPGA-specific timing and performance\nrequirements. TimelyHLS is driven by a structured architectural knowledge base\ncontaining FPGA-specific features, synthesis directives, and pragma templates.\nGiven a kernel, TimelyHLS generates HLS code annotated with both\ntiming-critical and design-specific pragmas. The synthesized RTL is then\nevaluated using commercial toolchains, and simulation correctness is verified\nagainst reference outputs via custom testbenches. TimelyHLS iteratively\nincorporates synthesis logs and performance reports into the LLM engine for\nrefinement in the presence of functional discrepancies. Experimental results\nacross 10 FPGA architectures and diverse benchmarks show that TimelyHLS reduces\nthe need for manual tuning by up to 70%, while achieving up to 4x latency\nspeedup (e.g., 3.85x for Matrix Multiplication, 3.7x for Bitonic Sort) and over\n50% area savings in certain cases (e.g., 57% FF reduction in Viterbi).\nTimelyHLS consistently achieves timing closure and functional correctness\nacross platforms, highlighting the effectiveness of LLM-driven,\narchitecture-aware synthesis in automating FPGA design.", "AI": {"tldr": "TimelyHLS\u662f\u4e00\u4e2a\u7ed3\u5408LLM\u548cRAG\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316FPGA\u7684HLS\u4ee3\u7801\uff0c\u663e\u8457\u51cf\u5c11\u624b\u52a8\u8c03\u6574\u9700\u6c42\uff0c\u63d0\u5347\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "FPGA\u7684\u9ad8\u5c42\u6b21\u7efc\u5408\uff08HLS\uff09\u5728\u5b9e\u73b0\u65f6\u5e8f\u6536\u655b\u548c\u8bbe\u8ba1\u4f18\u5316\u65f6\u9762\u4e34\u6311\u6218\uff0c\u7f3a\u4e4f\u5bf9\u5e73\u53f0\u7279\u5b9apragma\u7684\u81ea\u52a8\u5316\u652f\u6301\u3002", "method": "TimelyHLS\u901a\u8fc7LLM\u548cRAG\u751f\u6210\u5e76\u8fed\u4ee3\u4f18\u5316HLS\u4ee3\u7801\uff0c\u7ed3\u5408FPGA\u7279\u5b9a\u77e5\u8bc6\u5e93\u548c\u5408\u6210\u65e5\u5fd7\u8fdb\u884c\u6539\u8fdb\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cTimelyHLS\u51cf\u5c11\u624b\u52a8\u8c03\u657470%\uff0c\u63d0\u5347\u6027\u80fd\u8fbe4\u500d\uff0c\u8d44\u6e90\u8282\u7701\u8d8550%\u3002", "conclusion": "TimelyHLS\u8bc1\u660e\u4e86LLM\u9a71\u52a8\u7684\u67b6\u6784\u611f\u77e5\u5408\u6210\u5728\u81ea\u52a8\u5316FPGA\u8bbe\u8ba1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.17988", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17988", "abs": "https://arxiv.org/abs/2507.17988", "authors": ["Dario Della Monica", "Angelo Montanari", "Pietro Sala"], "title": "Synthesis of timeline-based planning strategies avoiding determinization", "comment": "arXiv admin note: text overlap with arXiv:2410.22757", "summary": "Qualitative timeline-based planning models domains as sets of independent,\nbut\n  interacting, components whose behaviors over time, the timelines, are\ngoverned\n  by sets of qualitative temporal constraints (ordering relations), called\n  synchronization rules.\n  Its plan-existence problem has been shown to be PSPACE-complete; in\n  particular, PSPACE-membership has been proved via reduction to the\n  nonemptiness problem for nondeterministic finite automata.\n  However, nondeterministic automata cannot be directly used to synthesize\n  planning strategies as a costly determinization step is needed.\n  In this paper, we identify a fragment of qualitative timeline-based planning\n  whose plan-existence problem can be directly mapped into the nonemptiness\n  problem of deterministic finite automata, which can then\n  synthesize strategies.\n  In addition, we identify a maximal subset of Allen's relations that fits into\n  such a deterministic fragment.", "AI": {"tldr": "\u5b9a\u6027\u65f6\u95f4\u7ebf\u89c4\u5212\u5c06\u9886\u57df\u5efa\u6a21\u4e3a\u72ec\u7acb\u4f46\u4ea4\u4e92\u7684\u7ec4\u4ef6\uff0c\u5176\u884c\u4e3a\u53d7\u540c\u6b65\u89c4\u5219\u7ea6\u675f\u3002\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7247\u6bb5\uff0c\u5176\u89c4\u5212\u95ee\u9898\u53ef\u76f4\u63a5\u6620\u5c04\u5230\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\u7684\u975e\u7a7a\u95ee\u9898\uff0c\u4ece\u800c\u5408\u6210\u7b56\u7565\u3002", "motivation": "\u5b9a\u6027\u65f6\u95f4\u7ebf\u89c4\u5212\u7684\u89c4\u5212\u5b58\u5728\u95ee\u9898\u662fPSPACE\u5b8c\u5168\u7684\uff0c\u4f46\u975e\u786e\u5b9a\u6027\u81ea\u52a8\u673a\u65e0\u6cd5\u76f4\u63a5\u7528\u4e8e\u5408\u6210\u7b56\u7565\uff0c\u9700\u786e\u5b9a\u6027\u5316\u6b65\u9aa4\u3002\u672c\u6587\u65e8\u5728\u627e\u5230\u53ef\u76f4\u63a5\u6620\u5c04\u5230\u786e\u5b9a\u6027\u81ea\u52a8\u673a\u7684\u7247\u6bb5\u3002", "method": "\u8bc6\u522b\u5b9a\u6027\u65f6\u95f4\u7ebf\u89c4\u5212\u7684\u4e00\u4e2a\u7247\u6bb5\uff0c\u5176\u89c4\u5212\u5b58\u5728\u95ee\u9898\u53ef\u76f4\u63a5\u6620\u5c04\u5230\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\u7684\u975e\u7a7a\u95ee\u9898\uff0c\u5e76\u786e\u5b9a\u9002\u5408\u8be5\u7247\u6bb5\u7684Allen\u5173\u7cfb\u7684\u6700\u5927\u5b50\u96c6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u76f4\u63a5\u6620\u5c04\u5230\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\u7684\u89c4\u5212\u7247\u6bb5\uff0c\u5e76\u786e\u5b9a\u4e86\u9002\u5408\u8be5\u7247\u6bb5\u7684Allen\u5173\u7cfb\u7684\u6700\u5927\u5b50\u96c6\u3002", "conclusion": "\u901a\u8fc7\u786e\u5b9a\u6027\u81ea\u52a8\u673a\u76f4\u63a5\u5408\u6210\u7b56\u7565\u7684\u89c4\u5212\u7247\u6bb5\u88ab\u6210\u529f\u8bc6\u522b\uff0c\u6269\u5c55\u4e86\u5b9a\u6027\u65f6\u95f4\u7ebf\u89c4\u5212\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2507.18105", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18105", "abs": "https://arxiv.org/abs/2507.18105", "authors": ["Yujie Ma", "Lili Quan", "Xiaofei Xie", "Qiang Hu", "Jiongchi Yu", "Yao Zhang", "Sen Chen"], "title": "Understanding the Supply Chain and Risks of Large Language Model Applications", "comment": "26 pages", "summary": "The rise of Large Language Models (LLMs) has led to the widespread deployment\nof LLM-based systems across diverse domains. As these systems proliferate,\nunderstanding the risks associated with their complex supply chains is\nincreasingly important. LLM-based systems are not standalone as they rely on\ninterconnected supply chains involving pretrained models, third-party\nlibraries, datasets, and infrastructure. Yet, most risk assessments narrowly\nfocus on model or data level, overlooking broader supply chain vulnerabilities.\nWhile recent studies have begun to address LLM supply chain risks, there\nremains a lack of benchmarks for systematic research.\n  To address this gap, we introduce the first comprehensive dataset for\nanalyzing and benchmarking LLM supply chain security. We collect 3,859\nreal-world LLM applications and perform interdependency analysis, identifying\n109,211 models, 2,474 datasets, and 9,862 libraries. We extract model\nfine-tuning paths, dataset reuse, and library reliance, mapping the ecosystem's\nstructure. To evaluate security, we gather 1,555 risk-related issues-50 for\napplications, 325 for models, 18 for datasets, and 1,229 for libraries from\npublic vulnerability databases.\n  Using this dataset, we empirically analyze component dependencies and risks.\nOur findings reveal deeply nested dependencies in LLM applications and\nsignificant vulnerabilities across the supply chain, underscoring the need for\ncomprehensive security analysis. We conclude with practical recommendations to\nguide researchers and developers toward safer, more trustworthy LLM-enabled\nsystems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5168\u9762\u5206\u6790LLM\u4f9b\u5e94\u94fe\u5b89\u5168\u7684\u6570\u636e\u96c6\uff0c\u63ed\u793a\u4e86\u6df1\u5ea6\u5d4c\u5957\u7684\u4f9d\u8d56\u5173\u7cfb\u548c\u4f9b\u5e94\u94fe\u4e2d\u7684\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u968f\u7740LLM\u7cfb\u7edf\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u590d\u6742\u7684\u4f9b\u5e94\u94fe\u98ce\u9669\u88ab\u5ffd\u89c6\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u57fa\u51c6\u3002", "method": "\u6536\u96c63,859\u4e2a\u771f\u5b9eLLM\u5e94\u7528\uff0c\u5206\u6790\u4f9d\u8d56\u5173\u7cfb\uff0c\u63d0\u53d61,555\u4e2a\u98ce\u9669\u95ee\u9898\uff0c\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u53d1\u73b0LLM\u5e94\u7528\u5b58\u5728\u6df1\u5ea6\u4f9d\u8d56\u548c\u4f9b\u5e94\u94fe\u6f0f\u6d1e\uff0c\u5f3a\u8c03\u5168\u9762\u5b89\u5168\u5206\u6790\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u5efa\u8bae\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u8005\u91c7\u53d6\u7efc\u5408\u5b89\u5168\u63aa\u65bd\uff0c\u6784\u5efa\u66f4\u53ef\u4fe1\u7684LLM\u7cfb\u7edf\u3002"}}
{"id": "2507.17978", "categories": ["cs.CR", "cs.AI", "cs.HC", "68P20 (Primary) 68T05, 68T07, 68T10 (Secondary)", "K.6.5; I.2.6; I.2.7; C.2.0"], "pdf": "https://arxiv.org/pdf/2507.17978", "abs": "https://arxiv.org/abs/2507.17978", "authors": ["Paulo Mendes", "Eva Maia", "Isabel Pra\u00e7a"], "title": "MeAJOR Corpus: A Multi-Source Dataset for Phishing Email Detection", "comment": "8 pages, 2 tables, WI-IAT 2025 conference", "summary": "Phishing emails continue to pose a significant threat to cybersecurity by\nexploiting human vulnerabilities through deceptive content and malicious\npayloads. While Machine Learning (ML) models are effective at detecting\nphishing threats, their performance largely relies on the quality and diversity\nof the training data. This paper presents MeAJOR (Merged email Assets from\nJoint Open-source Repositories) Corpus, a novel, multi-source phishing email\ndataset designed to overcome critical limitations in existing resources. It\nintegrates 135894 samples representing a broad number of phishing tactics and\nlegitimate emails, with a wide spectrum of engineered features. We evaluated\nthe dataset's utility for phishing detection research through systematic\nexperiments with four classification models (RF, XGB, MLP, and CNN) across\nmultiple feature configurations. Results highlight the dataset's effectiveness,\nachieving 98.34% F1 with XGB. By integrating broad features from multiple\ncategories, our dataset provides a reusable and consistent resource, while\naddressing common challenges like class imbalance, generalisability and\nreproducibility.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86MeAJOR Corpus\uff0c\u4e00\u4e2a\u591a\u6e90\u9493\u9c7c\u90ae\u4ef6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6539\u8fdb\u73b0\u6709\u8d44\u6e90\u7684\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u9493\u9c7c\u90ae\u4ef6\u901a\u8fc7\u6b3a\u9a97\u6027\u5185\u5bb9\u548c\u6076\u610f\u8d1f\u8f7d\u5bf9\u7f51\u7edc\u5b89\u5168\u6784\u6210\u5a01\u80c1\uff0c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u4f9d\u8d56\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u8d28\u91cf\u548c\u591a\u6837\u6027\u3002", "method": "\u6574\u5408\u4e86135,894\u4e2a\u6837\u672c\uff0c\u6db5\u76d6\u591a\u79cd\u9493\u9c7c\u7b56\u7565\u548c\u5408\u6cd5\u90ae\u4ef6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u591a\u79cd\u7279\u5f81\u3002\u4f7f\u7528\u56db\u79cd\u5206\u7c7b\u6a21\u578b\uff08RF\u3001XGB\u3001MLP\u548cCNN\uff09\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "XGB\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cF1\u5206\u6570\u8fbe\u523098.34%\u3002\u6570\u636e\u96c6\u89e3\u51b3\u4e86\u7c7b\u522b\u4e0d\u5e73\u8861\u3001\u6cdb\u5316\u6027\u548c\u53ef\u91cd\u590d\u6027\u7b49\u5e38\u89c1\u95ee\u9898\u3002", "conclusion": "MeAJOR Corpus\u662f\u4e00\u4e2a\u53ef\u91cd\u7528\u4e14\u4e00\u81f4\u7684\u8d44\u6e90\uff0c\u4e3a\u9493\u9c7c\u68c0\u6d4b\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u652f\u6301\u3002"}}
{"id": "2507.18004", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18004", "abs": "https://arxiv.org/abs/2507.18004", "authors": ["Yusen Peng", "Shuhua Mao"], "title": "E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI", "comment": "44 pages,11 figures", "summary": "How can AI move beyond imitation toward genuine creativity? This paper\nproposes the E.A.R.T.H. framework, a five-stage generative pipeline that\ntransforms model-generated errors into creative assets through Error\ngeneration, Amplification, Refine selection, Transform, and Harness feedback.\nDrawing on cognitive science and generative modeling, we posit that \"creative\npotential hides in failure\" and operationalize this via structured prompts,\nsemantic scoring, and human-in-the-loop evaluation. Implemented using\nLLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the\npipeline employs a composite reward function based on novelty, surprise, and\nrelevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to\n1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4%\nimprovement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a\n4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment\n(CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs\nscored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones\n(3.99). Feedback highlights stylistic precision and emotional resonance. These\nresults demonstrate that error-centered, feedback-driven generation enhances\ncreativity, offering a scalable path toward self-evolving, human-aligned\ncreative AI.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faE.A.R.T.H.\u6846\u67b6\uff0c\u901a\u8fc7\u9519\u8bef\u751f\u6210\u3001\u653e\u5927\u3001\u7cbe\u70bc\u9009\u62e9\u3001\u8f6c\u6362\u548c\u5229\u7528\u53cd\u9988\uff0c\u5c06AI\u751f\u6210\u7684\u9519\u8bef\u8f6c\u5316\u4e3a\u521b\u610f\u8d44\u4ea7\uff0c\u663e\u8457\u63d0\u5347\u521b\u9020\u529b\u3002", "motivation": "\u63a2\u8ba8AI\u5982\u4f55\u8d85\u8d8a\u6a21\u4eff\u5b9e\u73b0\u771f\u6b63\u521b\u9020\u529b\uff0c\u63d0\u51fa\u201c\u521b\u610f\u6f5c\u529b\u9690\u85cf\u5728\u5931\u8d25\u4e2d\u201d\u7684\u89c2\u70b9\u3002", "method": "\u91c7\u7528\u4e94\u9636\u6bb5\u751f\u6210\u7ba1\u9053\uff08E.A.R.T.H.\uff09\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u63d0\u793a\u3001\u8bed\u4e49\u8bc4\u5206\u548c\u4eba\u7c7b\u53cd\u9988\uff0c\u4f7f\u7528\u591a\u79cd\u6a21\u578b\uff08\u5982LLaMA-2-7B-Chat\u3001SBERT\u7b49\uff09\u548c\u590d\u5408\u5956\u52b1\u51fd\u6570\u3002", "result": "\u521b\u9020\u529b\u8bc4\u5206\u63d0\u534770.4%\uff0c\u7cbe\u70bc\u540e\u7684\u6807\u8bed\u66f4\u77ed\u3001\u66f4\u65b0\u9896\uff0c\u8de8\u6a21\u6001\u6d4b\u8bd5\u663e\u793a\u5f3a\u5bf9\u9f50\u6027\uff0c\u4eba\u7c7b\u8bc4\u4ef7\u4e2d60%\u8f93\u51fa\u5f97\u5206\u22654.0\u3002", "conclusion": "\u9519\u8bef\u9a71\u52a8\u548c\u53cd\u9988\u9a71\u52a8\u7684\u751f\u6210\u65b9\u6cd5\u80fd\u663e\u8457\u589e\u5f3aAI\u521b\u9020\u529b\uff0c\u4e3a\u81ea\u8fdb\u5316\u3001\u4eba\u7c7b\u5bf9\u9f50\u7684\u521b\u610fAI\u63d0\u4f9b\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2507.18130", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18130", "abs": "https://arxiv.org/abs/2507.18130", "authors": ["Le Deng", "Zhonghao Jiang", "Jialun Cao", "Michael Pradel", "Zhongxin Liu"], "title": "NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature Addition", "comment": null, "summary": "Natural language-driven no-code development allows users to specify software\nfunctionality using natural language (NL) instead of editing source code,\npromising increased productivity and democratized development. Large language\nmodels (LLMs) show potential in enabling this paradigm. In this context,\nsoftware documentation acts as an NL specification for functionality. This work\nintroduces NoCode-bench, a benchmark designed to evaluate LLMs on real-world\nNL-driven feature addition tasks, consisting of 634 tasks across 10 projects\nand 114k code changes. Each task pairs documentation updates with corresponding\ncode implementations, validated by developer-written test cases. A subset of\n114 high-quality, human-verified instances, NoCode-bench Verified, ensures\nreliable evaluation. Our experiments reveal that, despite high token usage, the\nbest LLMs achieve a task success rate of only 15.79%, highlighting challenges\nin cross-file editing, codebase understanding, and tool calling. These findings\nindicate that LLMs are not yet ready for fully NL-driven no-code development.\nNoCode-bench lays the foundation for future advances in this area.", "AI": {"tldr": "NoCode-bench\u662f\u4e00\u4e2a\u8bc4\u4f30LLMs\u5728\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u65e0\u4ee3\u7801\u5f00\u53d1\u4e2d\u8868\u73b0\u7684\u57fa\u51c6\uff0c\u5305\u542b634\u4e2a\u4efb\u52a1\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u6700\u4f73LLMs\u7684\u4efb\u52a1\u6210\u529f\u7387\u4ec5\u4e3a15.79%\uff0c\u8868\u660e\u5176\u5728\u8de8\u6587\u4ef6\u7f16\u8f91\u548c\u4ee3\u7801\u5e93\u7406\u89e3\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002", "motivation": "\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u65e0\u4ee3\u7801\u5f00\u53d1\u63d0\u9ad8\u751f\u4ea7\u529b\u548c\u666e\u53ca\u5f00\u53d1\uff0c\u5229\u7528LLMs\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002", "method": "\u5f15\u5165NoCode-bench\u57fa\u51c6\uff0c\u5305\u542b634\u4e2a\u4efb\u52a1\u548c114k\u4ee3\u7801\u53d8\u66f4\uff0c\u9a8c\u8bc1LLMs\u5728\u6587\u6863\u66f4\u65b0\u4e0e\u4ee3\u7801\u5b9e\u73b0\u914d\u5bf9\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u6700\u4f73LLMs\u7684\u4efb\u52a1\u6210\u529f\u7387\u4e3a15.79%\uff0c\u663e\u793a\u5176\u5728\u8de8\u6587\u4ef6\u7f16\u8f91\u548c\u4ee3\u7801\u5e93\u7406\u89e3\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "conclusion": "LLMs\u5c1a\u672a\u51c6\u5907\u597d\u5b8c\u5168\u652f\u6301\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u65e0\u4ee3\u7801\u5f00\u53d1\uff0cNoCode-bench\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.18034", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18034", "abs": "https://arxiv.org/abs/2507.18034", "authors": ["Haonan An", "Guang Hua", "Hangcheng Cao", "Zhengru Fang", "Guowen Xu", "Susanto Rahardja", "Yuguang Fang"], "title": "Removing Box-Free Watermarks for Image-to-Image Models via Query-Based Reverse Engineering", "comment": null, "summary": "The intellectual property of deep generative networks (GNets) can be\nprotected using a cascaded hiding network (HNet) which embeds watermarks (or\nmarks) into GNet outputs, known as box-free watermarking. Although both GNet\nand HNet are encapsulated in a black box (called operation network, or ONet),\nwith only the generated and marked outputs from HNet being released to end\nusers and deemed secure, in this paper, we reveal an overlooked vulnerability\nin such systems. Specifically, we show that the hidden GNet outputs can still\nbe reliably estimated via query-based reverse engineering, leaking the\ngenerated and unmarked images, despite the attacker's limited knowledge of the\nsystem. Our first attempt is to reverse-engineer an inverse model for HNet\nunder the stringent black-box condition, for which we propose to exploit the\nquery process with specially curated input images. While effective, this method\nyields unsatisfactory image quality. To improve this, we subsequently propose\nan alternative method leveraging the equivalent additive property of box-free\nmodel watermarking and reverse-engineering a forward surrogate model of HNet,\nwith better image quality preservation. Extensive experimental results on image\nprocessing and image generation tasks demonstrate that both attacks achieve\nimpressive watermark removal success rates (100%) while also maintaining\nexcellent image quality (reaching the highest PSNR of 34.69 dB), substantially\noutperforming existing attacks, highlighting the urgent need for robust\ndefensive strategies to mitigate the identified vulnerability in box-free model\nwatermarking.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u9ed1\u76d2\u64cd\u4f5c\u7f51\u7edc\uff08ONet\uff09\u4e2d\u9690\u85cf\u7684\u6f0f\u6d1e\uff0c\u901a\u8fc7\u67e5\u8be2\u9006\u5411\u5de5\u7a0b\u53ef\u4f30\u8ba1\u672a\u6807\u8bb0\u7684GNet\u8f93\u51fa\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u653b\u51fb\u65b9\u6cd5\uff0c\u6210\u529f\u7387\u9ad8\u4e14\u56fe\u50cf\u8d28\u91cf\u597d\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u66b4\u9732\u9ed1\u76d2\u6a21\u578b\u6c34\u5370\u7cfb\u7edf\u4e2d\u88ab\u5ffd\u89c6\u7684\u6f0f\u6d1e\uff0c\u4ee5\u63d0\u9192\u9632\u5fa1\u7b56\u7565\u7684\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u9006\u5411\u5de5\u7a0b\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u7279\u6b8a\u8f93\u5165\u56fe\u50cf\u9006\u5411HNet\u7684\u9006\u6a21\u578b\uff1b2) \u5229\u7528\u7b49\u6548\u52a0\u6027\u7279\u6027\u9006\u5411HNet\u7684\u524d\u5411\u4ee3\u7406\u6a21\u578b\u3002", "result": "\u4e24\u79cd\u653b\u51fb\u65b9\u6cd5\u5747\u5b9e\u73b0100%\u6c34\u5370\u53bb\u9664\u6210\u529f\u7387\uff0c\u56fe\u50cf\u8d28\u91cf\u4f18\u5f02\uff08\u6700\u9ad8PSNR\u8fbe34.69 dB\uff09\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u9ed1\u76d2\u6a21\u578b\u6c34\u5370\u7cfb\u7edf\u7684\u8106\u5f31\u6027\uff0c\u4e9f\u9700\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2507.18022", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.18022", "abs": "https://arxiv.org/abs/2507.18022", "authors": ["Victoria R. Li", "Johnathan Sun", "Martin Wattenberg"], "title": "Does visualization help AI understand data?", "comment": "5 pages, 6 figures", "summary": "Charts and graphs help people analyze data, but can they also be useful to AI\nsystems? To investigate this question, we perform a series of experiments with\ntwo commercial vision-language models: GPT 4.1 and Claude 3.5. Across three\nrepresentative analysis tasks, the two systems describe synthetic datasets more\nprecisely and accurately when raw data is accompanied by a scatterplot,\nespecially as datasets grow in complexity. Comparison with two baselines --\nproviding a blank chart and a chart with mismatched data -- shows that the\nimproved performance is due to the content of the charts. Our results are\ninitial evidence that AI systems, like humans, can benefit from visualization.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u56fe\u8868\u662f\u5426\u6709\u52a9\u4e8eAI\u7cfb\u7edf\u5206\u6790\u6570\u636e\uff0c\u5b9e\u9a8c\u8868\u660e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u8868\u8f85\u52a9\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u63a2\u8ba8\u56fe\u8868\u662f\u5426\u5bf9AI\u7cfb\u7edf\u5206\u6790\u6570\u636e\u6709\u5e2e\u52a9\uff0c\u586b\u8865AI\u4e0e\u53ef\u89c6\u5316\u7ed3\u5408\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u4f7f\u7528GPT 4.1\u548cClaude 3.5\u4e24\u79cd\u5546\u4e1a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u4e09\u79cd\u4ee3\u8868\u6027\u5206\u6790\u4efb\u52a1\u4e2d\u6d4b\u8bd5\u56fe\u8868\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u56fe\u8868\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u5408\u6210\u6570\u636e\u63cf\u8ff0\u7684\u7cbe\u786e\u6027\u548c\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u590d\u6742\u6570\u636e\u96c6\u4e2d\u3002", "conclusion": "\u521d\u6b65\u8bc1\u660eAI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u7c7b\u4f3c\uff0c\u80fd\u4ece\u53ef\u89c6\u5316\u4e2d\u53d7\u76ca\u3002"}}
{"id": "2507.18159", "categories": ["cs.SE", "cs.DL"], "pdf": "https://arxiv.org/pdf/2507.18159", "abs": "https://arxiv.org/abs/2507.18159", "authors": ["Stephan Ferenz", "Aida Jafarbigloo", "Oliver Werth", "Astrid Nie\u00dfe"], "title": "SMECS: A Software Metadata Extraction and Curation Software", "comment": null, "summary": "Metadata play a crucial role in adopting the FAIR principles for research\nsoftware and enables findability and reusability. However, creating\nhigh-quality metadata can be resource-intensive for researchers and research\nsoftware engineers. To address this challenge, we developed the Software\nMetadata Extraction and Curation Software (SMECS) which integrates the\nextraction of metadata from existing sources together with a user-friendly\ninterface for metadata curation. SMECS extracts metadata from online\nrepositories such as GitHub and presents it to researchers through an\ninteractive interface for further curation and export as a CodeMeta file. The\nusability of SMECS was evaluated through usability experiments which confirmed\nthat SMECS provides a satisfactory user experience. SMECS supports the\nFAIRification of research software by simplifying metadata creation.", "AI": {"tldr": "SMECS\u662f\u4e00\u4e2a\u7528\u4e8e\u63d0\u53d6\u548c\u6574\u7406\u7814\u7a76\u8f6f\u4ef6\u5143\u6570\u636e\u7684\u5de5\u5177\uff0c\u65e8\u5728\u7b80\u5316FAIR\u539f\u5219\u7684\u5b9e\u65bd\u3002", "motivation": "\u9ad8\u8d28\u91cf\u7684\u5143\u6570\u636e\u5bf9\u5b9e\u73b0FAIR\u539f\u5219\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u521b\u5efa\u8017\u65f6\u8017\u529b\u3002", "method": "SMECS\u4eceGitHub\u7b49\u5728\u7ebf\u4ed3\u5e93\u63d0\u53d6\u5143\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u4ea4\u4e92\u754c\u9762\u4f9b\u7528\u6237\u6574\u7406\u548c\u5bfc\u51fa\u4e3aCodeMeta\u6587\u4ef6\u3002", "result": "\u53ef\u7528\u6027\u5b9e\u9a8c\u8bc1\u5b9eSMECS\u63d0\u4f9b\u826f\u597d\u7684\u7528\u6237\u4f53\u9a8c\u3002", "conclusion": "SMECS\u901a\u8fc7\u7b80\u5316\u5143\u6570\u636e\u521b\u5efa\uff0c\u652f\u6301\u7814\u7a76\u8f6f\u4ef6\u7684FAIR\u5316\u3002"}}
{"id": "2507.18036", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.18036", "abs": "https://arxiv.org/abs/2507.18036", "authors": ["Haonan An", "Guang Hua", "Yu Guo", "Hangcheng Cao", "Susanto Rahardja", "Yuguang Fang"], "title": "NWaaS: Nonintrusive Watermarking as a Service for X-to-Image DNN", "comment": null, "summary": "The intellectual property of deep neural network (DNN) models can be\nprotected with DNN watermarking, which embeds copyright watermarks into model\nparameters (white-box), model behavior (black-box), or model outputs\n(box-free), and the watermarks can be subsequently extracted to verify model\nownership or detect model theft. Despite recent advances, these existing\nmethods are inherently intrusive, as they either modify the model parameters or\nalter the structure. This natural intrusiveness raises concerns about\nwatermarking-induced shifts in model behavior and the additional cost of\nfine-tuning, further exacerbated by the rapidly growing model size. As a\nresult, model owners are often reluctant to adopt DNN watermarking in practice,\nwhich limits the development of practical Watermarking as a Service (WaaS)\nsystems. To address this issue, we introduce Nonintrusive Watermarking as a\nService (NWaaS), a novel trustless paradigm designed for X-to-Image models, in\nwhich we hypothesize that with the model untouched, an owner-defined watermark\ncan still be extracted from model outputs. Building on this concept, we propose\nShadowMark, a concrete implementation of NWaaS which addresses critical\ndeployment challenges by establishing a robust and nonintrusive side channel in\nthe protected model's black-box API, leveraging a key encoder and a watermark\ndecoder. It is significantly distinctive from existing solutions by attaining\nthe so-called absolute fidelity and being applicable to different DNN\narchitectures, while being also robust against existing attacks, eliminating\nthe fidelity-robustness trade-off. Extensive experiments on image-to-image,\nnoise-to-image, noise-and-text-to-image, and text-to-image models, demonstrate\nthe efficacy and practicality of ShadowMark for real-world deployment of\nnonintrusive DNN watermarking.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u4fb5\u5165\u5f0f\u7684DNN\u6c34\u5370\u670d\u52a1\uff08NWaaS\uff09\uff0c\u901a\u8fc7ShadowMark\u5b9e\u73b0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u5bf9\u6a21\u578b\u53c2\u6570\u6216\u7ed3\u6784\u7684\u4fee\u6539\u95ee\u9898\u3002", "motivation": "\u73b0\u6709DNN\u6c34\u5370\u65b9\u6cd5\u5177\u6709\u4fb5\u5165\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u884c\u4e3a\u53d8\u5316\u548c\u989d\u5916\u8c03\u4f18\u6210\u672c\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faNWaaS\u8303\u5f0f\uff0c\u901a\u8fc7ShadowMark\u5728\u6a21\u578b\u7684\u9ed1\u76d2API\u4e2d\u5efa\u7acb\u975e\u4fb5\u5165\u5f0f\u4fa7\u4fe1\u9053\uff0c\u5229\u7528\u5173\u952e\u7f16\u7801\u5668\u548c\u6c34\u5370\u89e3\u7801\u5668\u5b9e\u73b0\u6c34\u5370\u63d0\u53d6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eShadowMark\u5728\u4e0d\u540cDNN\u67b6\u6784\u4e2d\u5177\u6709\u7edd\u5bf9\u4fdd\u771f\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u6d88\u9664\u4e86\u4fdd\u771f\u5ea6\u4e0e\u9c81\u68d2\u6027\u7684\u6743\u8861\u3002", "conclusion": "ShadowMark\u4e3a\u975e\u4fb5\u5165\u5f0fDNN\u6c34\u5370\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6a21\u578b\u7c7b\u578b\u3002"}}
{"id": "2507.18059", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.18059", "abs": "https://arxiv.org/abs/2507.18059", "authors": ["Yueheng Li", "Guangming Xie", "Zongqing Lu"], "title": "Multi-Agent Guided Policy Optimization", "comment": null, "summary": "Due to practical constraints such as partial observability and limited\ncommunication, Centralized Training with Decentralized Execution (CTDE) has\nbecome the dominant paradigm in cooperative Multi-Agent Reinforcement Learning\n(MARL). However, existing CTDE methods often underutilize centralized training\nor lack theoretical guarantees. We propose Multi-Agent Guided Policy\nOptimization (MAGPO), a novel framework that better leverages centralized\ntraining by integrating centralized guidance with decentralized execution.\nMAGPO uses an auto-regressive joint policy for scalable, coordinated\nexploration and explicitly aligns it with decentralized policies to ensure\ndeployability under partial observability. We provide theoretical guarantees of\nmonotonic policy improvement and empirically evaluate MAGPO on 43 tasks across\n6 diverse environments. Results show that MAGPO consistently outperforms strong\nCTDE baselines and matches or surpasses fully centralized approaches, offering\na principled and practical solution for decentralized multi-agent learning. Our\ncode and experimental data can be found in https://github.com/liyheng/MAGPO.", "AI": {"tldr": "MAGPO\u662f\u4e00\u4e2a\u65b0\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u96c6\u4e2d\u5f0f\u6307\u5bfc\u548c\u5206\u6563\u5f0f\u6267\u884c\uff0c\u4f18\u5316\u4e86CTDE\u8303\u5f0f\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709CTDE\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u6216\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\uff0cMAGPO\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "MAGPO\u4f7f\u7528\u81ea\u56de\u5f52\u8054\u5408\u7b56\u7565\u8fdb\u884c\u53ef\u6269\u5c55\u7684\u534f\u8c03\u63a2\u7d22\uff0c\u5e76\u660e\u786e\u5bf9\u9f50\u5206\u6563\u5f0f\u7b56\u7565\u4ee5\u786e\u4fdd\u53ef\u90e8\u7f72\u6027\u3002", "result": "\u57286\u4e2a\u73af\u5883\u768443\u4e2a\u4efb\u52a1\u4e2d\uff0cMAGPO\u8868\u73b0\u4f18\u4e8e\u73b0\u6709CTDE\u57fa\u7ebf\uff0c\u5e76\u5339\u914d\u6216\u8d85\u8d8a\u5b8c\u5168\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u3002", "conclusion": "MAGPO\u4e3a\u5206\u6563\u5f0f\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u7406\u8bba\u57fa\u7840\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.18223", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18223", "abs": "https://arxiv.org/abs/2507.18223", "authors": ["Nenad Petrovic", "Fengjunjie Pan", "Vahid Zolfaghari", "Krzysztof Lebioda", "Andre Schamschurko", "Alois Knoll"], "title": "GenAI for Automotive Software Development: From Requirements to Wheels", "comment": null, "summary": "This paper introduces a GenAI-empowered approach to automated development of\nautomotive software, with emphasis on autonomous and Advanced Driver Assistance\nSystems (ADAS) capabilities. The process starts with requirements as input,\nwhile the main generated outputs are test scenario code for simulation\nenvironment, together with implementation of desired ADAS capabilities\ntargeting hardware platform of the vehicle connected to testbench. Moreover, we\nintroduce additional steps for requirements consistency checking leveraging\nModel-Driven Engineering (MDE). In the proposed workflow, Large Language Models\n(LLMs) are used for model-based summarization of requirements (Ecore metamodel,\nXMI model instance and OCL constraint creation), test scenario generation,\nsimulation code (Python) and target platform code generation (C++).\nAdditionally, Retrieval Augmented Generation (RAG) is adopted to enhance test\nscenario generation from autonomous driving regulations-related documents. Our\napproach aims shorter compliance and re-engineering cycles, as well as reduced\ndevelopment and testing time when it comes to ADAS-related capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGenAI\u7684\u6c7d\u8f66\u8f6f\u4ef6\u5f00\u53d1\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u91cd\u70b9\u9488\u5bf9\u81ea\u52a8\u9a7e\u9a76\u548c\u9ad8\u7ea7\u9a7e\u9a76\u8f85\u52a9\u7cfb\u7edf\uff08ADAS\uff09\u3002", "motivation": "\u65e8\u5728\u7f29\u77ed\u5408\u89c4\u6027\u548c\u91cd\u65b0\u8bbe\u8ba1\u5468\u671f\uff0c\u51cf\u5c11ADAS\u76f8\u5173\u529f\u80fd\u7684\u5f00\u53d1\u548c\u6d4b\u8bd5\u65f6\u95f4\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u9700\u6c42\u6a21\u578b\u5316\u603b\u7ed3\u3001\u6d4b\u8bd5\u573a\u666f\u751f\u6210\u3001\u4eff\u771f\u4ee3\u7801\u548c\u76ee\u6807\u5e73\u53f0\u4ee3\u7801\u751f\u6210\uff0c\u5e76\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4f18\u5316\u6d4b\u8bd5\u573a\u666f\u751f\u6210\u3002", "result": "\u751f\u6210\u6d4b\u8bd5\u573a\u666f\u4ee3\u7801\u3001\u4eff\u771f\u73af\u5883\u548c\u76ee\u6807\u5e73\u53f0\u5b9e\u73b0\uff0c\u540c\u65f6\u901a\u8fc7\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\uff08MDE\uff09\u68c0\u67e5\u9700\u6c42\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347ADAS\u5f00\u53d1\u7684\u6548\u7387\u548c\u5408\u89c4\u6027\u3002"}}
{"id": "2507.18053", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.18053", "abs": "https://arxiv.org/abs/2507.18053", "authors": ["Haoran Gao", "Yuanhe Zhang", "Zhenhong Zhou", "Lei Jiang", "Fanyu Meng", "Yujia Xiao", "Kun Wang", "Yang Liu", "Junlan Feng"], "title": "RECALLED: An Unbounded Resource Consumption Attack on Large Vision-Language Models", "comment": null, "summary": "Resource Consumption Attacks (RCAs) have emerged as a significant threat to\nthe deployment of Large Language Models (LLMs). With the integration of vision\nmodalities, additional attack vectors exacerbate the risk of RCAs in large\nvision-language models (LVLMs). However, existing red-teaming studies have\nlargely overlooked visual inputs as a potential attack surface, resulting in\ninsufficient mitigation strategies against RCAs in LVLMs. To address this gap,\nwe propose RECALLED (\\textbf{RE}source \\textbf{C}onsumption \\textbf{A}ttack on\n\\textbf{L}arge Vision-\\textbf{L}anguag\\textbf{E} Mo\\textbf{D}els), the first\napproach for exploiting visual modalities to trigger unbounded RCAs\nred-teaming. First, we present \\textit{Vision Guided Optimization}, a\nfine-grained pixel-level optimization, to obtain \\textit{Output Recall}\nadversarial perturbations, which can induce repeating output. Then, we inject\nthe perturbations into visual inputs, triggering unbounded generations to\nachieve the goal of RCAs. Additionally, we introduce \\textit{Multi-Objective\nParallel Losses} to generate universal attack templates and resolve\noptimization conflicts when intending to implement parallel attacks. Empirical\nresults demonstrate that RECALLED increases service response latency by over 26\n$\\uparrow$, resulting in an additional 20\\% increase in GPU utilization and\nmemory consumption. Our study exposes security vulnerabilities in LVLMs and\nestablishes a red-teaming framework that can facilitate future defense\ndevelopment against RCAs.", "AI": {"tldr": "RECALLED\u662f\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u7684\u8d44\u6e90\u6d88\u8017\u653b\u51fb\uff08RCAs\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u89c6\u89c9\u8f93\u5165\u89e6\u53d1\u65e0\u9650\u5236\u7684\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5ffd\u89c6\u4e86\u89c6\u89c9\u8f93\u5165\u4f5c\u4e3a\u653b\u51fb\u9762\u7684\u6f5c\u529b\uff0c\u5bfc\u81f4\u5bf9LVLMs\u4e2dRCAs\u7684\u9632\u5fa1\u4e0d\u8db3\u3002", "method": "\u63d0\u51faVision Guided Optimization\u548cMulti-Objective Parallel Losses\uff0c\u751f\u6210\u5bf9\u6297\u6270\u52a8\u5e76\u5b9e\u73b0\u5e76\u884c\u653b\u51fb\u3002", "result": "RECALLED\u663e\u8457\u589e\u52a0\u4e86\u670d\u52a1\u54cd\u5e94\u5ef6\u8fdf\u548cGPU\u8d44\u6e90\u6d88\u8017\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LVLMs\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u4e3a\u672a\u6765\u9632\u5fa1RCAs\u63d0\u4f9b\u4e86\u6846\u67b6\u3002"}}
{"id": "2507.18074", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18074", "abs": "https://arxiv.org/abs/2507.18074", "authors": ["Yixiu Liu", "Yang Nan", "Weixian Xu", "Xiangkun Hu", "Lyumanshan Ye", "Zhen Qin", "Pengfei Liu"], "title": "AlphaGo Moment for Model Architecture Discovery", "comment": null, "summary": "While AI systems demonstrate exponentially improving capabilities, the pace\nof AI research itself remains linearly bounded by human cognitive capacity,\ncreating an increasingly severe development bottleneck. We present ASI-Arch,\nthe first demonstration of Artificial Superintelligence for AI research\n(ASI4AI) in the critical domain of neural architecture discovery--a fully\nautonomous system that shatters this fundamental constraint by enabling AI to\nconduct its own architectural innovation. Moving beyond traditional Neural\nArchitecture Search (NAS), which is fundamentally limited to exploring\nhuman-defined spaces, we introduce a paradigm shift from automated optimization\nto automated innovation. ASI-Arch can conduct end-to-end scientific research in\nthe domain of architecture discovery, autonomously hypothesizing novel\narchitectural concepts, implementing them as executable code, training and\nempirically validating their performance through rigorous experimentation and\npast experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000\nGPU hours, culminating in the discovery of 106 innovative, state-of-the-art\n(SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed\nunexpected strategic insights invisible to human players, our AI-discovered\narchitectures demonstrate emergent design principles that systematically\nsurpass human-designed baselines and illuminate previously unknown pathways for\narchitectural innovation. Crucially, we establish the first empirical scaling\nlaw for scientific discovery itself--demonstrating that architectural\nbreakthroughs can be scaled computationally, transforming research progress\nfrom a human-limited to a computation-scalable process. We provide\ncomprehensive analysis of the emergent design patterns and autonomous research\ncapabilities that enabled these breakthroughs, establishing a blueprint for\nself-accelerating AI systems.", "AI": {"tldr": "ASI-Arch\u662f\u9996\u4e2a\u7528\u4e8eAI\u7814\u7a76\u7684\u8d85\u7ea7\u667a\u80fd\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u4e3b\u53d1\u73b0\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7a81\u7834\u4eba\u7c7b\u8ba4\u77e5\u9650\u5236\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u521b\u65b0\u3002", "motivation": "\u89e3\u51b3AI\u7814\u7a76\u53d7\u9650\u4e8e\u4eba\u7c7b\u8ba4\u77e5\u80fd\u529b\u7684\u74f6\u9888\uff0c\u63a8\u52a8AI\u81ea\u4e3b\u521b\u65b0\u3002", "method": "\u63d0\u51faASI-Arch\u7cfb\u7edf\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u81ea\u4e3b\u7814\u7a76\uff0c\u5305\u62ec\u5047\u8bbe\u751f\u6210\u3001\u4ee3\u7801\u5b9e\u73b0\u3001\u8bad\u7ec3\u4e0e\u9a8c\u8bc1\u3002", "result": "\u572820,000 GPU\u5c0f\u65f6\u5185\u5b8c\u62101,773\u6b21\u5b9e\u9a8c\uff0c\u53d1\u73b0106\u79cd\u521b\u65b0\u67b6\u6784\uff0c\u6027\u80fd\u8d85\u8d8a\u4eba\u7c7b\u8bbe\u8ba1\u3002", "conclusion": "ASI-Arch\u4e3aAI\u81ea\u4e3b\u7814\u7a76\u63d0\u4f9b\u4e86\u84dd\u56fe\uff0c\u8bc1\u660e\u79d1\u5b66\u53d1\u73b0\u53ef\u901a\u8fc7\u8ba1\u7b97\u6269\u5c55\u3002"}}
{"id": "2507.18267", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18267", "abs": "https://arxiv.org/abs/2507.18267", "authors": ["Zeqin Liao", "Zibin Zheng", "Peifan Reng", "Henglong Liang", "Zixu Gao", "Zhixiang Chen", "Wei Li", "Yuhong Nan"], "title": "An Empirical Study on Embodied Artificial Intelligence Robot (EAIR) Software Bugs", "comment": null, "summary": "Embodied Artificial Intelligence Robots (EAIR) is an emerging and rapidly\nevolving technological domain. Ensuring their program correctness is\nfundamental to their successful deployment. However, a general and in-depth\nunderstanding of EAIR system bugs remains lacking, which hinders the\ndevelopment of practices and techniques to tackle EAIR system bugs.\n  To bridge this gap, we conducted the first systematic study of 885 EAIR\nsystem bugs collected from 80 EAIR system projects to investigate their\nsymptoms, underlying causes, and module distribution. Our analysis takes\nconsiderable effort, which classifies these bugs into 18 underlying causes, 15\ndistinct symptoms, and identifies 13 affected modules. It reveals several new\ninteresting findings and implications which help shed light on future research\non tackling or repairing EAIR system bugs. First, among the 15 identified\nsymptoms, our findings highlight 8 symptoms specific to EAIR systems, which is\ncharacterized by severe functional failures and potential physical hazards.\nSecond, within the 18 underlying causes, we define 8 EAIR-specific causes, the\nmajority of which stem from the intricate issues of AI- agent reasoning and\ndecision making. Finally, to facilitate precise and efficient bug prediction,\ndetection, and repair, we constructed a mapping between underlying causes and\nthe modules in which they most frequently occur, which enables researchers to\nfocus diagnostic efforts on the modules most susceptible to specific bug types.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86885\u4e2aEAIR\u7cfb\u7edf\u9519\u8bef\uff0c\u63ed\u793a\u4e8618\u79cd\u6839\u672c\u539f\u56e0\u300115\u79cd\u75c7\u72b6\u548c13\u4e2a\u53d7\u5f71\u54cd\u6a21\u5757\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002", "motivation": "EAIR\u7cfb\u7edf\u9519\u8bef\u7684\u666e\u904d\u6027\u548c\u590d\u6742\u6027\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\uff0c\u963b\u788d\u4e86\u76f8\u5173\u6280\u672f\u548c\u5b9e\u8df5\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u5206\u679080\u4e2aEAIR\u9879\u76ee\u4e2d\u7684885\u4e2a\u9519\u8bef\uff0c\u5206\u7c7b\u75c7\u72b6\u3001\u539f\u56e0\u548c\u6a21\u5757\u5206\u5e03\u3002", "result": "\u53d1\u73b08\u79cdEAIR\u7279\u6709\u75c7\u72b6\u548c8\u79cd\u7279\u6709\u539f\u56e0\uff0c\u5e76\u6784\u5efa\u4e86\u539f\u56e0\u4e0e\u6a21\u5757\u7684\u6620\u5c04\u5173\u7cfb\u3002", "conclusion": "\u7814\u7a76\u4e3aEAIR\u7cfb\u7edf\u9519\u8bef\u7684\u9884\u6d4b\u3001\u68c0\u6d4b\u548c\u4fee\u590d\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2507.18075", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18075", "abs": "https://arxiv.org/abs/2507.18075", "authors": ["Jacob Mahon", "Chenxi Hou", "Zhihao Yao"], "title": "PyPitfall: Dependency Chaos and Software Supply Chain Vulnerabilities in Python", "comment": null, "summary": "Python software development heavily relies on third-party packages. Direct\nand transitive dependencies create a labyrinth of software supply chains. While\nit is convenient to reuse code, vulnerabilities within these dependency chains\ncan propagate through dependencies, potentially affecting down-stream packages\nand applications. PyPI, the official Python package repository, hosts many\npackages and lacks a comprehensive analysis of the prevalence of vulnerable\ndependencies. This paper introduces PyPitfall, a quantitative analysis of\nvulnerable dependencies across the PyPI ecosystem. We analyzed the dependency\nstructures of 378,573 PyPI packages and identified 4,655 packages that\nexplicitly require at least one known-vulnerable version and 141,044 packages\nthat permit vulnerable versions within specified ranges. By characterizing the\necosystem-wide dependency landscape and the security impact of transitive\ndependencies, we aim to raise awareness of Python software supply chain\nsecurity.", "AI": {"tldr": "PyPitfall\u5206\u6790\u4e86PyPI\u751f\u6001\u7cfb\u7edf\u4e2d\u4f9d\u8d56\u94fe\u7684\u5b89\u5168\u95ee\u9898\uff0c\u53d1\u73b0\u5927\u91cf\u5305\u76f4\u63a5\u6216\u95f4\u63a5\u4f9d\u8d56\u5df2\u77e5\u6f0f\u6d1e\u7248\u672c\u3002", "motivation": "Python\u5f00\u53d1\u4f9d\u8d56\u7b2c\u4e09\u65b9\u5305\uff0c\u4f46\u4f9d\u8d56\u94fe\u4e2d\u7684\u6f0f\u6d1e\u53ef\u80fd\u4f20\u64ad\uff0cPyPI\u7f3a\u4e4f\u5bf9\u6b64\u7684\u5168\u9762\u5206\u6790\u3002", "method": "\u5206\u6790\u4e86378,573\u4e2aPyPI\u5305\u7684\u4f9d\u8d56\u7ed3\u6784\uff0c\u8bc6\u522b\u76f4\u63a5\u6216\u95f4\u63a5\u4f9d\u8d56\u5df2\u77e5\u6f0f\u6d1e\u7248\u672c\u7684\u5305\u3002", "result": "\u53d1\u73b04,655\u4e2a\u5305\u76f4\u63a5\u4f9d\u8d56\u6f0f\u6d1e\u7248\u672c\uff0c141,044\u4e2a\u5305\u5141\u8bb8\u6f0f\u6d1e\u7248\u672c\u8303\u56f4\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86Python\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u7684\u5b89\u5168\u98ce\u9669\uff0c\u547c\u5401\u63d0\u9ad8\u5b89\u5168\u610f\u8bc6\u3002"}}
{"id": "2507.18115", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.18115", "abs": "https://arxiv.org/abs/2507.18115", "authors": ["Soorya Ram Shimgekar", "Shayan Vassef", "Abhay Goyal", "Navin Kumar", "Koustuv Saha"], "title": "Agentic AI framework for End-to-End Medical Data Inference", "comment": "10 pages, 5 figures, 2 tables, BIBM conference", "summary": "Building and deploying machine learning solutions in healthcare remains\nexpensive and labor-intensive due to fragmented preprocessing workflows, model\ncompatibility issues, and stringent data privacy constraints. In this work, we\nintroduce an Agentic AI framework that automates the entire clinical data\npipeline, from ingestion to inference, through a system of modular,\ntask-specific agents. These agents handle both structured and unstructured\ndata, enabling automatic feature selection, model selection, and preprocessing\nrecommendation without manual intervention. We evaluate the system on publicly\navailable datasets from geriatrics, palliative care, and colonoscopy imaging.\nFor example, in the case of structured data (anxiety data) and unstructured\ndata (colonoscopy polyps data), the pipeline begins with file-type detection by\nthe Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring\nprivacy compliance, where we first identify the data type and then anonymize\nit. The Feature Extraction Agent identifies features using an embedding-based\napproach for tabular data, extracting all column names, and a multi-stage\nMedGemma-based approach for image data, which infers modality and disease name.\nThese features guide the Model-Data Feature Matcher Agent in selecting the\nbest-fit model from a curated repository. The Preprocessing Recommender Agent\nand Preprocessing Implementor Agent then apply tailored preprocessing based on\ndata type and model requirements. Finally, the ``Model Inference Agent\" runs\nthe selected model on the uploaded data and generates interpretable outputs\nusing tools like SHAP, LIME, and DETR attention maps. By automating these\nhigh-friction stages of the ML lifecycle, the proposed framework reduces the\nneed for repeated expert intervention, offering a scalable, cost-efficient\npathway for operationalizing AI in clinical environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cdAgentic AI\u6846\u67b6\uff0c\u81ea\u52a8\u5316\u4e34\u5e8a\u6570\u636e\u4ece\u8f93\u5165\u5230\u63a8\u7406\u7684\u6574\u4e2a\u6d41\u7a0b\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u4efb\u52a1\u4ee3\u7406\u89e3\u51b3\u533b\u7597\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u9ad8\u6210\u672c\u548c\u788e\u7247\u5316\u95ee\u9898\u3002", "motivation": "\u533b\u7597\u9886\u57df\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u7684\u6784\u5efa\u548c\u90e8\u7f72\u6210\u672c\u9ad8\u4e14\u52b3\u52a8\u5bc6\u96c6\uff0c\u4e3b\u8981\u7531\u4e8e\u9884\u5904\u7406\u6d41\u7a0b\u788e\u7247\u5316\u3001\u6a21\u578b\u517c\u5bb9\u6027\u95ee\u9898\u4ee5\u53ca\u4e25\u683c\u7684\u6570\u636e\u9690\u79c1\u9650\u5236\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u4efb\u52a1\u4ee3\u7406\u7cfb\u7edf\uff0c\u5904\u7406\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u6570\u636e\uff0c\u81ea\u52a8\u5b8c\u6210\u7279\u5f81\u9009\u62e9\u3001\u6a21\u578b\u9009\u62e9\u548c\u9884\u5904\u7406\u63a8\u8350\u3002", "result": "\u5728\u8001\u5e74\u533b\u5b66\u3001\u59d1\u606f\u6cbb\u7597\u548c\u7ed3\u80a0\u955c\u6210\u50cf\u7684\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\u3002", "conclusion": "\u8be5\u6846\u67b6\u51cf\u5c11\u4e86\u673a\u5668\u5b66\u4e60\u751f\u547d\u5468\u671f\u4e2d\u7684\u4e13\u5bb6\u5e72\u9884\u9700\u6c42\uff0c\u4e3a\u4e34\u5e8a\u73af\u5883\u4e2d\u7684AI\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.18289", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18289", "abs": "https://arxiv.org/abs/2507.18289", "authors": ["Yan Li", "Wenzhang Yang", "Yuekun Wang", "Jian Gao", "Shaohua Wang", "Yinxing Xue", "Lijun Zhang"], "title": "Scheduzz: Constraint-based Fuzz Driver Generation with Dual Scheduling", "comment": "15 pages, 12 figures, 5 tables", "summary": "Fuzzing a library requires experts to understand the library usage well and\ncraft high-quality fuzz drivers, which is tricky and tedious. Therefore, many\ntechniques have been proposed to automatically generate fuzz drivers. However,\nthey fail to generate rational fuzz drivers due to the lack of adherence to\nproper library usage conventions, such as ensuring a resource is closed after\nbeing opened. To make things worse, existing library fuzzing techniques\nunconditionally execute each driver, resulting in numerous irrational drivers\nthat waste computational resources while contributing little coverage and\ngenerating false positive bug reports.\n  To tackle these challenges, we propose a novel automatic library fuzzing\ntechnique, Scheduzz, an LLM-based library fuzzing technique. It leverages LLMs\nto understand rational usage of libraries and extract API combination\nconstraints. To optimize computational resource utilization, a dual scheduling\nframework is implemented to efficiently manage API combinations and fuzz\ndrivers. The framework models driver generation and the corresponding fuzzing\ncampaign as an online optimization problem. Within the scheduling loop,\nmultiple API combinations are selected to generate fuzz drivers, while\nsimultaneously, various optimized fuzz drivers are scheduled for execution or\nsuspension.\n  We implemented Scheduzz and evaluated it in 33 real-world libraries. Compared\nto baseline approaches, Scheduzz significantly reduces computational overhead\nand outperforms UTopia on 16 out of 21 libraries. It achieves 1.62x, 1.50x, and\n1.89x higher overall coverage than the state-of-the-art techniques CKGFuzzer,\nPromptfuzz, and the handcrafted project OSS-Fuzz, respectively. In addition,\nScheduzz discovered 33 previously unknown bugs in these well-tested libraries,\n3 of which have been assigned CVEs.", "AI": {"tldr": "Scheduzz\u662f\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5e93\u6a21\u7cca\u6d4b\u8bd5\u6280\u672f\uff0c\u901a\u8fc7\u7406\u89e3\u5e93\u7684\u5408\u7406\u4f7f\u7528\u65b9\u5f0f\u5e76\u63d0\u53d6API\u7ec4\u5408\u7ea6\u675f\uff0c\u4f18\u5316\u8ba1\u7b97\u8d44\u6e90\u5229\u7528\u3002", "motivation": "\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u6280\u672f\u96be\u4ee5\u751f\u6210\u5408\u7406\u7684\u6a21\u7cca\u9a71\u52a8\u7a0b\u5e8f\uff0c\u4e14\u65e0\u6761\u4ef6\u6267\u884c\u6d6a\u8d39\u8d44\u6e90\u3002", "method": "\u5229\u7528LLM\u7406\u89e3\u5e93\u4f7f\u7528\u65b9\u5f0f\uff0c\u63d0\u53d6API\u7ec4\u5408\u7ea6\u675f\uff0c\u5e76\u91c7\u7528\u53cc\u8c03\u5ea6\u6846\u67b6\u7ba1\u7406API\u7ec4\u5408\u548c\u6a21\u7cca\u9a71\u52a8\u7a0b\u5e8f\u3002", "result": "\u572833\u4e2a\u771f\u5b9e\u5e93\u4e2d\u6d4b\u8bd5\uff0cScheduzz\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u8986\u76d6\u7387\u548c\u6f0f\u6d1e\u53d1\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "Scheduzz\u5728\u5e93\u6a21\u7cca\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u9ad8\u4e86\u8986\u76d6\u7387\u548c\u6f0f\u6d1e\u53d1\u73b0\u6548\u7387\u3002"}}
{"id": "2507.18157", "categories": ["cs.CR", "quant-ph", "Primary:94A60, Secondary:68P25, Tertiary:81P94"], "pdf": "https://arxiv.org/pdf/2507.18157", "abs": "https://arxiv.org/abs/2507.18157", "authors": ["Chao Liu", "Shuai Zhao", "Chenhao Jia", "Gengran Hu", "Tingting Cui"], "title": "An Improved ChaCha Algorithm Based on Quantum Random Number", "comment": "20 pages,4 figures", "summary": "Due to the merits of high efficiency and strong security against timing and\nside-channel attacks, ChaCha has been widely applied in real-time communication\nand data streaming scenarios. However, with the rapid development of\nAI-assisted cryptanalysis and quantum computing technologies, there are serious\nchallenges to the secure implementation of ChaCha cipher. To further strengthen\nthe security of ChaCha cipher, we propose an improved variant based on quantum\nrandom numbers, i.e., Quantum Random Number Enhanced ChaCha (QRE-ChaCha).\nSpecifically, the design XORs the initial constants with quantum random numbers\nand periodically injects quantum random numbers into selected state words\nduring odd rounds to enhance diffusion. Compared with the original ChaCha, the\npresent variant shows stronger resistance to differential attacks and generates\na keystream with statistical randomness, thereby offering increased robustness\nagainst both classical and quantum attacks. To evaluate the security and\nperformance of the present ChaCha, our analysis proceeds in three main parts.\nFirstly, we analyze its theoretical security in terms of quantum randomness and\nattack testing, and conduct differential cryptanalysis with an automated search\nmethod based on the Boolean satisfiability problem (SAT). Secondly, we subject\nthe keystream generated by the cipher to randomness tests using the NIST\nstatistical test suite and the GM/T 0005-2021 randomness testing standard.\nFinally, we assess its encryption and decryption performance by measuring its\nencryption speed on files of various sizes. According to the results, the\npresent ChaCha is significantly improved to resist differential attacks while\nmaintaining the high efficiency of the original ChaCha cipher, and its\nkeystream successfully passes statistical randomness tests using the NIST and\nGM/T 0005-2021 standards, meeting cryptographic application requirements.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5b50\u968f\u673a\u6570\u7684\u6539\u8fdb\u7248ChaCha\u5bc6\u7801\uff08QRE-ChaCha\uff09\uff0c\u901a\u8fc7\u5f15\u5165\u91cf\u5b50\u968f\u673a\u6570\u589e\u5f3a\u6269\u6563\u6027\uff0c\u63d0\u5347\u4e86\u6297\u5dee\u5206\u653b\u51fb\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u539f\u7248\u7684\u9ad8\u6548\u6027\u3002", "motivation": "\u968f\u7740AI\u8f85\u52a9\u5bc6\u7801\u5206\u6790\u548c\u91cf\u5b50\u8ba1\u7b97\u6280\u672f\u7684\u53d1\u5c55\uff0c\u4f20\u7edfChaCha\u5bc6\u7801\u7684\u5b89\u5168\u5b9e\u73b0\u9762\u4e34\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u589e\u5f3a\u5176\u5b89\u5168\u6027\u3002", "method": "\u8bbe\u8ba1\u901a\u8fc7\u5c06\u521d\u59cb\u5e38\u6570\u4e0e\u91cf\u5b50\u968f\u673a\u6570\u5f02\u6216\uff0c\u5e76\u5728\u5947\u6570\u8f6e\u4e2d\u5b9a\u671f\u6ce8\u5165\u91cf\u5b50\u968f\u673a\u6570\u5230\u9009\u5b9a\u72b6\u6001\u5b57\u4e2d\uff0c\u4ee5\u589e\u5f3a\u6269\u6563\u6027\u3002", "result": "\u6539\u8fdb\u540e\u7684QRE-ChaCha\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6297\u5dee\u5206\u653b\u51fb\u80fd\u529b\uff0c\u751f\u6210\u7684\u5bc6\u94a5\u6d41\u5177\u6709\u7edf\u8ba1\u968f\u673a\u6027\uff0c\u5e76\u901a\u8fc7\u4e86NIST\u548cGM/T 0005-2021\u7684\u968f\u673a\u6027\u6d4b\u8bd5\u3002", "conclusion": "QRE-ChaCha\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u6027\uff0c\u9002\u7528\u4e8e\u5bc6\u7801\u5b66\u5e94\u7528\u3002"}}
{"id": "2507.18123", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.18123", "abs": "https://arxiv.org/abs/2507.18123", "authors": ["Sedigh Khademi", "Christopher Palmer", "Muhammad Javed", "Hazel Clothier", "Jim Buttery", "Gerardo Luis Dimaguila", "Jim Black"], "title": "Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes", "comment": "14 pages", "summary": "The rapid development of COVID-19 vaccines has showcased the global\ncommunitys ability to combat infectious diseases. However, the need for\npost-licensure surveillance systems has grown due to the limited window for\nsafety data collection in clinical trials and early widespread implementation.\nThis study aims to employ Natural Language Processing techniques and Active\nLearning to rapidly develop a classifier that detects potential vaccine safety\nissues from emergency department notes. ED triage notes, containing expert,\nsuccinct vital patient information at the point of entry to health systems, can\nsignificantly contribute to timely vaccine safety signal surveillance. While\nkeyword-based classification can be effective, it may yield false positives and\ndemand extensive keyword modifications. This is exacerbated by the infrequency\nof vaccination-related ED presentations and their similarity to other reasons\nfor ED visits. NLP offers a more accurate and efficient alternative, albeit\nrequiring annotated data, which is often scarce in the medical field. Active\nlearning optimizes the annotation process and the quality of annotated data,\nwhich can result in faster model implementation and improved model performance.\nThis work combines active learning, data augmentation, and active learning and\nevaluation techniques to create a classifier that is used to enhance vaccine\nsafety surveillance from ED triage notes.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u548c\u4e3b\u52a8\u5b66\u4e60\u6280\u672f\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u5206\u7c7b\u5668\uff0c\u7528\u4e8e\u4ece\u6025\u8bca\u79d1\u5206\u8bca\u8bb0\u5f55\u4e2d\u5feb\u901f\u68c0\u6d4b\u6f5c\u5728\u7684\u75ab\u82d7\u5b89\u5168\u95ee\u9898\uff0c\u4ee5\u5f25\u8865\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u5b89\u5168\u6570\u636e\u6536\u96c6\u7684\u4e0d\u8db3\u3002", "motivation": "\u7531\u4e8e\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u5b89\u5168\u6570\u636e\u6536\u96c6\u65f6\u95f4\u6709\u9650\uff0c\u4e14\u75ab\u82d7\u5e7f\u6cdb\u63a5\u79cd\u540e\u9700\u8981\u5feb\u901f\u76d1\u6d4b\u6f5c\u5728\u5b89\u5168\u95ee\u9898\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7NLP\u548c\u4e3b\u52a8\u5b66\u4e60\u6280\u672f\u63d0\u5347\u75ab\u82d7\u5b89\u5168\u4fe1\u53f7\u7684\u76d1\u6d4b\u6548\u7387\u3002", "method": "\u7ed3\u5408NLP\u3001\u4e3b\u52a8\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u5f00\u53d1\u5206\u7c7b\u5668\u4ee5\u5206\u6790\u6025\u8bca\u79d1\u5206\u8bca\u8bb0\u5f55\uff0c\u4f18\u5316\u6807\u6ce8\u8fc7\u7a0b\u5e76\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u51c6\u786e\u3001\u9ad8\u6548\u7684\u5206\u7c7b\u5668\uff0c\u80fd\u591f\u51cf\u5c11\u8bef\u62a5\u5e76\u5feb\u901f\u8bc6\u522b\u75ab\u82d7\u5b89\u5168\u95ee\u9898\u3002", "conclusion": "\u8be5\u5206\u7c7b\u5668\u4e3a\u75ab\u82d7\u5b89\u5168\u76d1\u6d4b\u63d0\u4f9b\u4e86\u53ca\u65f6\u3001\u6709\u6548\u7684\u5de5\u5177\uff0c\u5c24\u5176\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.18316", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18316", "abs": "https://arxiv.org/abs/2507.18316", "authors": ["Michael Konstantinou", "Renzo Degiovanni", "Jie M. Zhang", "Mark Harman", "Mike Papadakis"], "title": "YATE: The Role of Test Repair in LLM-Based Unit Test Generation", "comment": "12 pages, 4 figures", "summary": "Recent advances in automated test generation utilises language models to\nproduce unit tests. While effective, language models tend to generate many\nincorrect tests with respect to both syntax and semantics. Although such\nincorrect tests can be easily detected and discarded, they constitute a \"missed\nopportunity\" -- if fixed, they are often valuable as they directly add testing\nvalue (they effectively target the underlying program logic to be tested) and\nindirectly form good seeds for generating additional tests. To this end, we\npropose a simple technique for repairing some of these incorrect tests through\na combination of rule-based static analysis and re-prompting. We evaluate this\nsimple approach, named YATE, on a set of 6 open-source projects and show that\nit can effectively produce tests that cover on average 32.06% more lines and\nkill 21.77% more mutants than a plain LLM-based method. We also compare YATE\nwith four other LLM-based methods, namely HITS, SYMPROMPT, TESTSPARK and\nCOVERUP and show that it produces tests that cover substantially more code.\nYATE achieves 22% higher line coverage, 20% higher branch coverage and kill 20%\nmore mutants at a comparable cost (number of calls to LLMs).", "AI": {"tldr": "YATE\u662f\u4e00\u79cd\u901a\u8fc7\u9759\u6001\u5206\u6790\u548c\u91cd\u65b0\u63d0\u793a\u4fee\u590d\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u9519\u8bef\u6d4b\u8bd5\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u7a81\u53d8\u6740\u6b7b\u7387\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u6d4b\u8bd5\u5e38\u5b58\u5728\u8bed\u6cd5\u548c\u8bed\u4e49\u9519\u8bef\uff0c\u4fee\u590d\u8fd9\u4e9b\u9519\u8bef\u53ef\u4ee5\u63d0\u5347\u6d4b\u8bd5\u4ef7\u503c\u5e76\u4e3a\u751f\u6210\u66f4\u591a\u6d4b\u8bd5\u63d0\u4f9b\u826f\u597d\u79cd\u5b50\u3002", "method": "\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u9759\u6001\u5206\u6790\u548c\u91cd\u65b0\u63d0\u793a\u6280\u672f\u4fee\u590d\u9519\u8bef\u6d4b\u8bd5\u3002", "result": "YATE\u57286\u4e2a\u5f00\u6e90\u9879\u76ee\u4e0a\u5e73\u5747\u8986\u76d632.06%\u66f4\u591a\u4ee3\u7801\u884c\uff0c\u6740\u6b7b21.77%\u66f4\u591a\u7a81\u53d8\u4f53\uff0c\u4f18\u4e8e\u5176\u4ed6LLM\u65b9\u6cd5\u3002", "conclusion": "YATE\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6210\u672c\u53ef\u63a7\u7684\u6d4b\u8bd5\u4fee\u590d\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2507.18215", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18215", "abs": "https://arxiv.org/abs/2507.18215", "authors": ["Chang Gong", "Zhongwen Li", "Xiaoqi Li"], "title": "Information Security Based on LLM Approaches: A Review", "comment": null, "summary": "Information security is facing increasingly severe challenges, and\ntraditional protection means are difficult to cope with complex and changing\nthreats. In recent years, as an emerging intelligent technology, large language\nmodels (LLMs) have shown a broad application prospect in the field of\ninformation security. In this paper, we focus on the key role of LLM in\ninformation security, systematically review its application progress in\nmalicious behavior prediction, network threat analysis, system vulnerability\ndetection, malicious code identification, and cryptographic algorithm\noptimization, and explore its potential in enhancing security protection\nperformance. Based on neural networks and Transformer architecture, this paper\nanalyzes the technical basis of large language models and their advantages in\nnatural language processing tasks. It is shown that the introduction of large\nlanguage modeling helps to improve the detection accuracy and reduce the false\nalarm rate of security systems. Finally, this paper summarizes the current\napplication results and points out that it still faces challenges in model\ntransparency, interpretability, and scene adaptability, among other issues. It\nis necessary to explore further the optimization of the model structure and the\nimprovement of the generalization ability to realize a more intelligent and\naccurate information security protection system.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4fe1\u606f\u5b89\u5168\u9886\u57df\u7684\u5e94\u7528\u53ca\u5176\u6f5c\u529b\uff0c\u5206\u6790\u4e86\u5176\u5728\u6076\u610f\u884c\u4e3a\u9884\u6d4b\u3001\u5a01\u80c1\u5206\u6790\u7b49\u65b9\u9762\u7684\u8fdb\u5c55\uff0c\u5e76\u6307\u51fa\u5f53\u524d\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u4fe1\u606f\u5b89\u5168\u624b\u6bb5\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u591a\u53d8\u7684\u5a01\u80c1\uff0c\u800cLLMs\u4f5c\u4e3a\u4e00\u79cd\u65b0\u5174\u667a\u80fd\u6280\u672f\uff0c\u5c55\u73b0\u51fa\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\u3002", "method": "\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u548cTransformer\u67b6\u6784\uff0c\u5206\u6790LLMs\u7684\u6280\u672f\u57fa\u7840\u53ca\u5176\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u3002", "result": "LLMs\u7684\u5f15\u5165\u63d0\u9ad8\u4e86\u5b89\u5168\u7cfb\u7edf\u7684\u68c0\u6d4b\u7cbe\u5ea6\u5e76\u964d\u4f4e\u4e86\u8bef\u62a5\u7387\u3002", "conclusion": "\u5c3d\u7ba1\u53d6\u5f97\u4e86\u4e00\u5b9a\u6210\u679c\uff0c\u4f46LLMs\u5728\u6a21\u578b\u900f\u660e\u5ea6\u3001\u53ef\u89e3\u91ca\u6027\u548c\u573a\u666f\u9002\u5e94\u6027\u7b49\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u7ed3\u6784\u548c\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.18145", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.18145", "abs": "https://arxiv.org/abs/2507.18145", "authors": ["Moritz Sch\u00f6nherr", "Carsten Lutz"], "title": "Logical Characterizations of GNNs with Mean Aggregation", "comment": null, "summary": "We study the expressive power of graph neural networks (GNNs) with mean as\nthe aggregation function. In the non-uniform setting, we show that such GNNs\nhave exactly the same expressive power as ratio modal logic, which has modal\noperators expressing that at least a certain ratio of the successors of a\nvertex satisfies a specified property. The non-uniform expressive power of mean\nGNNs is thus higher than that of GNNs with max aggregation, but lower than for\nsum aggregation--the latter are characterized by modal logic and graded modal\nlogic, respectively. In the uniform setting, we show that the expressive power\nrelative to MSO is exactly that of alternation-free modal logic, under the\nnatural assumptions that combination functions are continuous and\nclassification functions are thresholds. This implies that, relative to MSO and\nin the uniform setting, mean GNNs are strictly less expressive than sum GNNs\nand max GNNs. When any of the assumptions is dropped, the expressive power\nincreases.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4f7f\u7528\u5747\u503c\u805a\u5408\u51fd\u6570\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u5728\u975e\u5747\u5300\u8bbe\u7f6e\u4e0b\u4e0e\u6bd4\u7387\u6a21\u6001\u903b\u8f91\u7b49\u4ef7\uff0c\u800c\u5728\u5747\u5300\u8bbe\u7f6e\u4e0b\u4f4e\u4e8e\u6c42\u548c\u4e0e\u6700\u5927\u503c\u805a\u5408\u7684GNNs\u3002", "motivation": "\u63a2\u8ba8\u5747\u503c\u805a\u5408GNNs\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u4e0e\u6c42\u548c\u3001\u6700\u5927\u503c\u805a\u5408GNNs\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u5728\u975e\u5747\u5300\u548c\u5747\u5300\u8bbe\u7f6e\u4e0b\u5206\u6790\u5747\u503c\u805a\u5408GNNs\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u4e0e\u6a21\u6001\u903b\u8f91\u548cMSO\uff08Monadic Second-Order Logic\uff09\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u975e\u5747\u5300\u8bbe\u7f6e\u4e0b\u5747\u503cGNNs\u8868\u8fbe\u80fd\u529b\u9ad8\u4e8e\u6700\u5927\u503c\u805a\u5408\u4f46\u4f4e\u4e8e\u6c42\u548c\u805a\u5408\uff1b\u5747\u5300\u8bbe\u7f6e\u4e0b\u4f4e\u4e8e\u4e24\u8005\u3002", "conclusion": "\u5747\u503cGNNs\u7684\u8868\u8fbe\u80fd\u529b\u53d7\u8bbe\u7f6e\u548c\u5047\u8bbe\u5f71\u54cd\uff0c\u7075\u6d3b\u6027\u8f83\u9ad8\u4f46\u5747\u5300\u8bbe\u7f6e\u4e0b\u8f83\u5f31\u3002"}}
{"id": "2507.18319", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18319", "abs": "https://arxiv.org/abs/2507.18319", "authors": ["Jesse Maarleveld", "Jiapan Guo", "Daniel Feitosa"], "title": "Gotta catch 'em all! Towards File Localisation from Issues at Large", "comment": "12 pages, 6 figures", "summary": "Bug localisation, the study of developing methods to localise the files\nrequiring changes to resolve bugs, has been researched for a long time to\ndevelop methods capable of saving developers' time. Recently, researchers are\nstarting to consider issues outside of bugs. Nevertheless, most existing\nresearch into file localisation from issues focusses on bugs or uses other\nselection methods to ensure only certain types of issues are considered as part\nof the focus of the work. Our goal is to work on all issues at large, without\nany specific selection.\n  In this work, we provide a data pipeline for the creation of issue file\nlocalisation datasets, capable of dealing with arbitrary branching and merging\npractices. We provide a baseline performance evaluation for the file\nlocalisation problem using traditional information retrieval approaches.\nFinally, we use statistical analysis to investigate the influence of biases\nknown in the bug localisation community on our dataset.\n  Our results show that methods designed using bug-specific heuristics perform\npoorly on general issue types, indicating a need for research into general\npurpose models. Furthermore, we find that there are small, but statistically\nsignificant differences in performance between different issue types. Finally,\nwe find that the presence of identifiers have a small effect on performance for\nmost issue types. Many results are project-dependent, encouraging the\ndevelopment of methods which can be tuned to project-specific characteristics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u6240\u6709\u7c7b\u578b\u95ee\u9898\u7684\u6587\u4ef6\u5b9a\u4f4d\u6570\u636e\u7ba1\u9053\uff0c\u5e76\u8bc4\u4f30\u4e86\u4f20\u7edf\u4fe1\u606f\u68c0\u7d22\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u9488\u5bf9\u7279\u5b9a\u95ee\u9898\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u901a\u7528\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u7814\u7a76\u76ee\u6807\u662f\u5f00\u53d1\u4e00\u79cd\u9002\u7528\u4e8e\u6240\u6709\u7c7b\u578b\u95ee\u9898\u7684\u6587\u4ef6\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u800c\u975e\u4ec5\u9650\u4e8e\u7279\u5b9a\u95ee\u9898\uff08\u5982\u7f3a\u9677\uff09\u3002", "method": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u6570\u636e\u7ba1\u9053\uff0c\u7528\u4e8e\u521b\u5efa\u95ee\u9898\u6587\u4ef6\u5b9a\u4f4d\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u4f20\u7edf\u4fe1\u606f\u68c0\u7d22\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u9488\u5bf9\u7279\u5b9a\u95ee\u9898\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u901a\u7528\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u9f13\u52b1\u5f00\u53d1\u53ef\u9002\u5e94\u9879\u76ee\u7279\u5b9a\u7279\u5f81\u7684\u901a\u7528\u6a21\u578b\u3002"}}
{"id": "2507.18249", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.18249", "abs": "https://arxiv.org/abs/2507.18249", "authors": ["Muhammad M. Roomi", "S. M. Suhail Hussain", "Ee-Chien Chang", "David M. Nicol", "Daisuke Mashima"], "title": "Auto-SGCR: Automated Generation of Smart Grid Cyber Range Using IEC 61850 Standard Models", "comment": "12 pages", "summary": "Digitalization of power grids have made them increasingly susceptible to\ncyber-attacks in the past decade. Iterative cybersecurity testing is\nindispensable to counter emerging attack vectors and to ensure dependability of\ncritical infrastructure. Furthermore, these can be used to evaluate\ncybersecurity configuration, effectiveness of the cybersecurity measures\nagainst various attack vectors, as well as to train smart grid cybersecurity\nexperts defending the system. Enabling extensive experiments narrows the gap\nbetween academic research and production environment. A high-fidelity cyber\nrange is vital as it is often infeasible to conduct such experiments and\ntraining using production environment. However, the design and implementation\nof cyber range requires extensive domain knowledge of physical and cyber aspect\nof the infrastructure. Furthermore, costs incurred for setup and maintenance of\ncyber range are significant. Moreover, most existing smart grid cyber ranges\nare designed as a one-off, proprietary system, and are limited in terms of\nconfigurability, accessibility, portability, and reproducibility. To address\nthese challenges, an automated Smart grid Cyber Range generation framework is\npresented in this paper. Initially a human-/machine-friendly, XML-based\nmodeling language called Smart Grid Modeling Language was defined, which\nincorporates IEC 61850 System Configuration Language files. Subsequently, a\ntoolchain to parse SG-ML model files and automatically instantiate a functional\nsmart grid cyber range was developed. The developed SG-ML models can be easily\nshared and/or modified to reproduce or customize for any cyber range. The\napplication of Auto-SGCR is demonstrated through case studies with large-scale\nsubstation models. The toolchain along with example SG-ML models have been\nopen-sourced.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u667a\u80fd\u7535\u7f51\u7f51\u7edc\u9776\u573a\u751f\u6210\u6846\u67b6\uff08Auto-SGCR\uff09\uff0c\u901a\u8fc7\u5b9a\u4e49SG-ML\u5efa\u6a21\u8bed\u8a00\u548c\u5f00\u53d1\u5de5\u5177\u94fe\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u9776\u573a\u5728\u53ef\u914d\u7f6e\u6027\u3001\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u91cd\u590d\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u968f\u7740\u7535\u7f51\u6570\u5b57\u5316\uff0c\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u589e\u52a0\uff0c\u73b0\u6709\u667a\u80fd\u7535\u7f51\u7f51\u7edc\u9776\u573a\u591a\u4e3a\u4e00\u6b21\u6027\u4e13\u6709\u7cfb\u7edf\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u4e14\u6210\u672c\u9ad8\u6602\u3002", "method": "\u5b9a\u4e49\u57fa\u4e8eXML\u7684SG-ML\u5efa\u6a21\u8bed\u8a00\uff0c\u7ed3\u5408IEC 61850\u914d\u7f6e\u8bed\u8a00\uff0c\u5f00\u53d1\u5de5\u5177\u94fe\u81ea\u52a8\u751f\u6210\u529f\u80fd\u5316\u667a\u80fd\u7535\u7f51\u7f51\u7edc\u9776\u573a\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86Auto-SGCR\u7684\u6709\u6548\u6027\uff0c\u5de5\u5177\u94fe\u548c\u793a\u4f8b\u6a21\u578b\u5df2\u5f00\u6e90\u3002", "conclusion": "Auto-SGCR\u6846\u67b6\u63d0\u5347\u4e86\u667a\u80fd\u7535\u7f51\u7f51\u7edc\u9776\u573a\u7684\u53ef\u914d\u7f6e\u6027\u3001\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u91cd\u590d\u6027\uff0c\u4e3a\u7f51\u7edc\u5b89\u5168\u6d4b\u8bd5\u548c\u4e13\u5bb6\u57f9\u8bad\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.18178", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18178", "abs": "https://arxiv.org/abs/2507.18178", "authors": ["Mutian Yang", "Jiandong Gao", "Ji Wu"], "title": "Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory", "comment": null, "summary": "While large language models (LLMs) leverage both knowledge and reasoning\nduring inference, the capacity to distinguish between them plays a pivotal role\nin model analysis, interpretability, and development. Inspired by dual-system\ncognitive theory, we propose a cognition attribution framework to decouple the\ncontribution of knowledge and reasoning. In particular, the cognition of LLMs\nis decomposed into two distinct yet complementary phases: knowledge retrieval\n(Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs\nare prompted to generate answers under two different cognitive modes, fast\nthinking and slow thinking, respectively. The performance under different\ncognitive modes is analyzed to quantify the contribution of knowledge and\nreasoning. This architecture is employed to 15 LLMs across 3 datasets. Results\nreveal: (1) reasoning adjustment is domain-specific, benefiting\nreasoning-intensive domains (e.g., mathematics, physics, and chemistry) and\npotentially imparing knowledge-intensive domains. (2) Parameter scaling\nimproves both knowledge and reasoning, with knowledge improvements being more\npronounced. Additionally, parameter scaling make LLMs reasoning significantly\nmore prudent, while moderately more intelligent. (3) Knowledge primarily\nresides in lower network layers, while reasoning operates in higher layers. Our\nframework not only helps understand LLMs from a \"decoupling\" perspective, but\nalso provides new insights into existing research, including scaling laws,\nhierarchical knowledge editing, and limitations of small-model reasoning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba4\u77e5\u5f52\u56e0\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u77e5\u8bc6\u68c0\u7d22\u548c\u63a8\u7406\u8c03\u6574\u4e24\u9636\u6bb5\uff0c\u91cf\u5316\u77e5\u8bc6\u63a8\u7406\u8d21\u732e\uff0c\u5e76\u5206\u6790\u4e8615\u4e2aLLMs\u57283\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u53d7\u53cc\u7cfb\u7edf\u8ba4\u77e5\u7406\u8bba\u542f\u53d1\uff0c\u533a\u5206\u77e5\u8bc6\u63a8\u7406\u5bf9\u6a21\u578b\u5206\u6790\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5feb\u901f\u601d\u7ef4\u548c\u6162\u901f\u601d\u7ef4\u4e24\u79cd\u8ba4\u77e5\u6a21\u5f0f\uff0c\u5206\u89e3\u77e5\u8bc6\u68c0\u7d22\uff08Phase 1\uff09\u548c\u63a8\u7406\u8c03\u6574\uff08Phase 2\uff09\uff0c\u91cf\u5316\u8d21\u732e\u3002", "result": "\u7ed3\u679c\u663e\u793a\u63a8\u7406\u8c03\u6574\u5177\u9886\u57df\u7279\u5f02\u6027\uff0c\u53c2\u6570\u6269\u5c55\u63d0\u5347\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u77e5\u8bc6\u4e3b\u8981\u5206\u5e03\u5728\u4f4e\u5c42\u7f51\u7edc\uff0c\u63a8\u7406\u5728\u9ad8\u5c42\u3002", "conclusion": "\u6846\u67b6\u4e3a\u7406\u89e3LLMs\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u5bf9\u6269\u5c55\u89c4\u5f8b\u3001\u77e5\u8bc6\u7f16\u8f91\u548c\u5c0f\u6a21\u578b\u63a8\u7406\u9650\u5236\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2507.18339", "categories": ["cs.SE", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.18339", "abs": "https://arxiv.org/abs/2507.18339", "authors": ["Nils Bosbach", "Meik Schmidt", "Lukas J\u00fcnger", "Matthias Berthold", "Rainer Leupers"], "title": "FMI Meets SystemC: A Framework for Cross-Tool Virtual Prototyping", "comment": "PREPRINT - accepted by the 16th International Modelica and FMI\n  Conference 2025", "summary": "As systems become more complex, the demand for thorough testing and virtual\nprototyping grows. To simulate whole systems, multiple tools are usually needed\nto cover different parts. These parts include the hardware of a system and the\nenvironment with which the system interacts. The Functional Mock-up Interface\n(FMI) standard for co-simulation can be used to connect these tools.\n  The control part of modern systems is usually a computing unit, such as a\nSystem-on-a-Chip (SoC) or Microcontroller Unit (MCU), which executes software\nfrom a connected memory and interacts with peripherals. To develop software\nwithout requiring access to physical hardware, full-system simulators, the\nso-called Virtual Platforms (VPs), are commonly used. The IEEE-standardized\nframework for VP development is SystemC TLM. SystemC provides interfaces and\nconcepts that enable modular design and model exchange. However, SystemC lacks\nnative FMI support, which limits the integration into broader co-simulation\nenvironments.\n  This paper presents a novel framework to control and interact with\nSystemC-based VPs using the FMI. We present a case study showing how a\nsimulated temperature sensor in a SystemC simulation can obtain temperature\nvalues from an external tool via FMI. This approach allows the unmodified\ntarget software to run on the VP and receive realistic environmental input data\nsuch as temperature, velocity, or acceleration values from other tools. Thus,\nextensive software testing and verification is enabled. By having tests ready\nand the software pre-tested using a VP once the physical hardware is available,\ncertifications like ISO 26262 can be done earlier.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7FMI\u6807\u51c6\u5b9e\u73b0SystemC\u865a\u62df\u5e73\u53f0\u4e0e\u5916\u90e8\u5de5\u5177\u7684\u534f\u540c\u4eff\u771f\uff0c\u4ee5\u652f\u6301\u66f4\u5168\u9762\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u6d4b\u8bd5\u548c\u865a\u62df\u539f\u578b\u8bbe\u8ba1\u3002SystemC\u7f3a\u4e4f\u539f\u751fFMI\u652f\u6301\uff0c\u9650\u5236\u4e86\u5176\u5728\u534f\u540c\u4eff\u771f\u4e2d\u7684\u96c6\u6210\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7FMI\u8fde\u63a5SystemC\u865a\u62df\u5e73\u53f0\u4e0e\u5916\u90e8\u5de5\u5177\uff0c\u5e76\u4ee5\u6e29\u5ea6\u4f20\u611f\u5668\u4e3a\u4f8b\u5c55\u793a\u4e86\u6570\u636e\u4ea4\u4e92\u3002", "result": "\u8be5\u6846\u67b6\u5141\u8bb8\u672a\u4fee\u6539\u7684\u76ee\u6807\u8f6f\u4ef6\u5728\u865a\u62df\u5e73\u53f0\u4e0a\u8fd0\u884c\uff0c\u5e76\u63a5\u6536\u6765\u81ea\u5916\u90e8\u5de5\u5177\u7684\u5b9e\u65f6\u73af\u5883\u6570\u636e\uff0c\u4ece\u800c\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u3002", "conclusion": "\u901a\u8fc7\u63d0\u524d\u5b8c\u6210\u8f6f\u4ef6\u6d4b\u8bd5\u548c\u9a8c\u8bc1\uff0c\u53ef\u4ee5\u52a0\u901f\u786c\u4ef6\u53ef\u7528\u540e\u7684\u8ba4\u8bc1\u6d41\u7a0b\uff0c\u5982ISO 26262\u3002"}}
{"id": "2507.18302", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.18302", "abs": "https://arxiv.org/abs/2507.18302", "authors": ["Delong Ran", "Xinlei He", "Tianshuo Cong", "Anyu Wang", "Qi Li", "Xiaoyun Wang"], "title": "LoRA-Leak: Membership Inference Attacks Against LoRA Fine-tuned Language Models", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Language Models (LMs) typically adhere to a \"pre-training and fine-tuning\"\nparadigm, where a universal pre-trained model can be fine-tuned to cater to\nvarious specialized domains. Low-Rank Adaptation (LoRA) has gained the most\nwidespread use in LM fine-tuning due to its lightweight computational cost and\nremarkable performance. Because the proportion of parameters tuned by LoRA is\nrelatively small, there might be a misleading impression that the LoRA\nfine-tuning data is invulnerable to Membership Inference Attacks (MIAs).\nHowever, we identify that utilizing the pre-trained model can induce more\ninformation leakage, which is neglected by existing MIAs. Therefore, we\nintroduce LoRA-Leak, a holistic evaluation framework for MIAs against the\nfine-tuning datasets of LMs. LoRA-Leak incorporates fifteen membership\ninference attacks, including ten existing MIAs, and five improved MIAs that\nleverage the pre-trained model as a reference. In experiments, we apply\nLoRA-Leak to three advanced LMs across three popular natural language\nprocessing tasks, demonstrating that LoRA-based fine-tuned LMs are still\nvulnerable to MIAs (e.g., 0.775 AUC under conservative fine-tuning settings).\nWe also applied LoRA-Leak to different fine-tuning settings to understand the\nresulting privacy risks. We further explore four defenses and find that only\ndropout and excluding specific LM layers during fine-tuning effectively\nmitigate MIA risks while maintaining utility. We highlight that under the\n\"pre-training and fine-tuning\" paradigm, the existence of the pre-trained model\nmakes MIA a more severe risk for LoRA-based LMs. We hope that our findings can\nprovide guidance on data privacy protection for specialized LM providers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLoRA-Leak\u6846\u67b6\uff0c\u8bc4\u4f30LoRA\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u9690\u79c1\u98ce\u9669\uff0c\u53d1\u73b0\u9884\u8bad\u7ec3\u6a21\u578b\u52a0\u5267\u4fe1\u606f\u6cc4\u9732\uff0c\u5e76\u63d0\u51fa\u9632\u5fa1\u63aa\u65bd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8bef\u4ee5\u4e3aLoRA\u5fae\u8c03\u6570\u636e\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\uff08MIA\uff09\u514d\u75ab\uff0c\u4f46\u9884\u8bad\u7ec3\u6a21\u578b\u53ef\u80fd\u5bfc\u81f4\u66f4\u591a\u4fe1\u606f\u6cc4\u9732\u3002", "method": "\u5f15\u5165LoRA-Leak\u6846\u67b6\uff0c\u6574\u540815\u79cdMIA\u65b9\u6cd5\uff0810\u79cd\u73b0\u6709\u548c5\u79cd\u6539\u8fdb\uff09\uff0c\u8bc4\u4f30LoRA\u5fae\u8c03\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLoRA\u5fae\u8c03\u6a21\u578b\u4ecd\u6613\u53d7MIA\u653b\u51fb\uff08\u5982AUC\u8fbe0.775\uff09\uff0c\u5e76\u63d0\u51fa\u6709\u6548\u9632\u5fa1\u63aa\u65bd\uff08\u5982dropout\uff09\u3002", "conclusion": "\u9884\u8bad\u7ec3\u6a21\u578b\u52a0\u5267LoRA\u5fae\u8c03\u6a21\u578b\u7684MIA\u98ce\u9669\uff0c\u9700\u5173\u6ce8\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2507.18198", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18198", "abs": "https://arxiv.org/abs/2507.18198", "authors": ["Felicidad Aguado", "Pedro Cabalar", "Brais Mu\u00f1iz", "Gilberto P\u00e9rez", "Concepci\u00f3n Vidal"], "title": "Comparing Non-minimal Semantics for Disjunction in Answer Set Programming", "comment": null, "summary": "In this paper, we compare four different semantics for disjunction in Answer\nSet Programming that, unlike stable models, do not adhere to the principle of\nmodel minimality. Two of these approaches, Cabalar and Mu\\~niz' \\emph{Justified\nModels} and Doherty and Szalas' \\emph{Strongly Supported Models}, directly\nprovide an alternative non-minimal semantics for disjunction. The other two,\nAguado et al's \\emph{Forks} and Shen and Eiter's \\emph{Determining Inference}\n(DI) semantics, actually introduce a new disjunction connective, but are\ncompared here as if they constituted new semantics for the standard disjunction\noperator. We are able to prove that three of these approaches (Forks, Justified\nModels and a reasonable relaxation of the DI semantics) actually coincide,\nconstituting a common single approach under different definitions. Moreover,\nthis common semantics always provides a superset of the stable models of a\nprogram (in fact, modulo any context) and is strictly stronger than the fourth\napproach (Strongly Supported Models), that actually treats disjunctions as in\nclassical logic.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u56db\u79cd\u4e0d\u9075\u5faa\u6a21\u578b\u6700\u5c0f\u5316\u539f\u5219\u7684\u6790\u53d6\u8bed\u4e49\uff0c\u8bc1\u660e\u5176\u4e2d\u4e09\u79cd\u65b9\u6cd5\uff08Forks\u3001Justified Models\u548cDI\u8bed\u4e49\u7684\u5408\u7406\u677e\u5f1b\uff09\u5b9e\u9645\u4e0a\u4e00\u81f4\uff0c\u4e14\u5f3a\u4e8e\u7b2c\u56db\u79cd\u65b9\u6cd5\uff08Strongly Supported Models\uff09\u3002", "motivation": "\u7814\u7a76\u6790\u53d6\u5728Answer Set Programming\u4e2d\u7684\u975e\u6700\u5c0f\u5316\u8bed\u4e49\uff0c\u63a2\u7d22\u4e0d\u540c\u65b9\u6cd5\u7684\u7b49\u4ef7\u6027\u548c\u5f3a\u5ea6\u3002", "method": "\u6bd4\u8f83\u56db\u79cd\u6790\u53d6\u8bed\u4e49\uff1aJustified Models\u3001Strongly Supported Models\u3001Forks\u548cDI\u8bed\u4e49\uff0c\u5206\u6790\u5176\u5b9a\u4e49\u548c\u5173\u7cfb\u3002", "result": "\u8bc1\u660eForks\u3001Justified Models\u548cDI\u8bed\u4e49\u7684\u5408\u7406\u677e\u5f1b\u5b9e\u9645\u4e0a\u4e00\u81f4\uff0c\u4e14\u5f3a\u4e8eStrongly Supported Models\u3002", "conclusion": "\u4e09\u79cd\u65b9\u6cd5\u6784\u6210\u4e86\u4e00\u79cd\u5171\u540c\u7684\u8bed\u4e49\uff0c\u63d0\u4f9b\u4e86\u6bd4\u7a33\u5b9a\u6a21\u578b\u66f4\u5e7f\u6cdb\u7684\u89e3\u96c6\uff0c\u4e14\u5f3a\u4e8e\u7ecf\u5178\u903b\u8f91\u5904\u7406\u6790\u53d6\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.18476", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18476", "abs": "https://arxiv.org/abs/2507.18476", "authors": ["Busra Icoz", "Goksel Biricik"], "title": "Automated Code Review Using Large Language Models with Symbolic Reasoning", "comment": null, "summary": "Code review is one of the key processes in the software development lifecycle\nand is essential to maintain code quality. However, manual code review is\nsubjective and time consuming. Given its rule-based nature, code review is well\nsuited for automation. In recent years, significant efforts have been made to\nautomate this process with the help of artificial intelligence. Recent\ndevelopments in Large Language Models (LLMs) have also emerged as a promising\ntool in this area, but these models often lack the logical reasoning\ncapabilities needed to fully understand and evaluate code. To overcome this\nlimitation, this study proposes a hybrid approach that integrates symbolic\nreasoning techniques with LLMs to automate the code review process. We tested\nour approach using the CodexGlue dataset, comparing several models, including\nCodeT5, CodeBERT, and GraphCodeBERT, to assess the effectiveness of combining\nsymbolic reasoning and prompting techniques with LLMs. Our results show that\nthis approach improves the accuracy and efficiency of automated code review.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7b26\u53f7\u63a8\u7406\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u624b\u52a8\u4ee3\u7801\u5ba1\u67e5\u4e3b\u89c2\u4e14\u8017\u65f6\uff0c\u81ea\u52a8\u5316\u9700\u6c42\u8feb\u5207\uff0c\u4f46\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u903b\u8f91\u63a8\u7406\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u7b26\u53f7\u63a8\u7406\u6280\u672f\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u6d4b\u8bd5\u4e86\u591a\u79cd\u6a21\u578b\uff08\u5982CodeT5\u3001CodeBERT\u7b49\uff09\u5728CodexGlue\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u6df7\u5408\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u7b26\u53f7\u63a8\u7406\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u5408\u662f\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.18360", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18360", "abs": "https://arxiv.org/abs/2507.18360", "authors": ["Andr\u00e9 Menolli", "Luiz Fernando Nunes", "Thiago A. Coleti"], "title": "Conformidade com os Requisitos Legais de Privacidade de Dados: Um Estudo sobre T\u00e9cnicas de Anonimiza\u00e7\u00e3o", "comment": "in Portuguese language", "summary": "The protection of personal data has become a central topic in software\ndevelopment, especially with the implementation of the General Data Protection\nLaw (LGPD) in Brazil and the General Data Protection Regulation (GDPR) in the\nEuropean Union. With the enforcement of these laws, certain software quality\ncriteria have become mandatory, such as data anonymization, which is one of the\nmain aspects addressed by these regulations. The aim of this article is to\nanalyze data anonymization techniques and assess their effectiveness in\nensuring compliance with legal requirements and the utility of the data for its\nintended purpose. Techniques such as aggregation, generalization, perturbation,\nand k-anonymity were investigated and applied to datasets containing personal\nand sensitive data. The analysis revealed significant variations in the\neffectiveness of each method, highlighting the need to balance privacy and data\nutility.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u6570\u636e\u533f\u540d\u5316\u6280\u672f\u5728\u6ee1\u8db3\u6cd5\u5f8b\u8981\u6c42\u548c\u6570\u636e\u5b9e\u7528\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u63a2\u8ba8\u4e86\u591a\u79cd\u6280\u672f\u5e76\u63ed\u793a\u4e86\u5176\u6548\u679c\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u5df4\u897fLGPD\u548c\u6b27\u76dfGDPR\u7684\u5b9e\u65bd\uff0c\u6570\u636e\u533f\u540d\u5316\u6210\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5408\u89c4\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u7814\u7a76\u4e86\u805a\u5408\u3001\u6cdb\u5316\u3001\u6270\u52a8\u548ck-\u533f\u540d\u7b49\u6280\u672f\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u5305\u542b\u4e2a\u4eba\u548c\u654f\u611f\u6570\u636e\u7684\u6570\u636e\u96c6\u3002", "result": "\u5206\u6790\u663e\u793a\u4e0d\u540c\u65b9\u6cd5\u7684\u6709\u6548\u6027\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u9700\u5e73\u8861\u9690\u79c1\u4e0e\u6570\u636e\u5b9e\u7528\u6027\u3002", "conclusion": "\u6570\u636e\u533f\u540d\u5316\u6280\u672f\u9700\u6839\u636e\u5177\u4f53\u9700\u6c42\u9009\u62e9\uff0c\u4ee5\u5b9e\u73b0\u5408\u89c4\u6027\u548c\u5b9e\u7528\u6027\u7684\u6700\u4f73\u5e73\u8861\u3002"}}
{"id": "2507.18290", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18290", "abs": "https://arxiv.org/abs/2507.18290", "authors": ["Antonino Rotolo", "Beatrice Ferrigno", "Jose Miguel Angel Garcia Godinez", "Claudio Novelli", "Giovanni Sartor"], "title": "Foundations for Risk Assessment of AI in Protecting Fundamental Rights", "comment": "24 pages, 1 figure. To be published in: The Philosophical Foundations\n  of Information Technology Law. Oxford University Press, Oxford", "summary": "This chapter introduces a conceptual framework for qualitative risk\nassessment of AI, particularly in the context of the EU AI Act. The framework\naddresses the complexities of legal compliance and fundamental rights\nprotection by itegrating definitional balancing and defeasible reasoning.\nDefinitional balancing employs proportionality analysis to resolve conflicts\nbetween competing rights, while defeasible reasoning accommodates the dynamic\nnature of legal decision-making. Our approach stresses the need for an analysis\nof AI deployment scenarios and for identifying potential legal violations and\nmulti-layered impacts on fundamental rights. On the basis of this analysis, we\nprovide philosophical foundations for a logical account of AI risk analysis. In\nparticular, we consider the basic building blocks for conceptually grasping the\ninteraction between AI deployment scenarios and fundamental rights,\nincorporating in defeasible reasoning definitional balancing and arguments\nabout the contextual promotion or demotion of rights. This layered approach\nallows for more operative models of assessment of both high-risk AI systems and\nGeneral Purpose AI (GPAI) systems, emphasizing the broader applicability of the\nlatter. Future work aims to develop a formal model and effective algorithms to\nenhance AI risk assessment, bridging theoretical insights with practical\napplications to support responsible AI governance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9a\u6027\u98ce\u9669\u8bc4\u4f30AI\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u7ed3\u5408\u5b9a\u4e49\u6027\u5e73\u8861\u548c\u53ef\u5e9f\u6b62\u63a8\u7406\uff0c\u4ee5\u5e94\u5bf9\u6b27\u76dfAI\u6cd5\u6848\u4e2d\u7684\u6cd5\u5f8b\u5408\u89c4\u6027\u548c\u57fa\u672c\u6743\u5229\u4fdd\u62a4\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3AI\u90e8\u7f72\u573a\u666f\u4e2d\u7684\u6cd5\u5f8b\u5408\u89c4\u6027\u548c\u57fa\u672c\u6743\u5229\u4fdd\u62a4\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6b27\u76dfAI\u6cd5\u6848\u7684\u80cc\u666f\u4e0b\u3002", "method": "\u91c7\u7528\u5b9a\u4e49\u6027\u5e73\u8861\uff08\u6bd4\u4f8b\u5206\u6790\uff09\u548c\u53ef\u5e9f\u6b62\u63a8\u7406\uff0c\u5206\u6790AI\u90e8\u7f72\u573a\u666f\u53ca\u5176\u5bf9\u57fa\u672c\u6743\u5229\u7684\u591a\u5c42\u6b21\u5f71\u54cd\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u903b\u8f91\u5316\u7684AI\u98ce\u9669\u5206\u6790\u57fa\u7840\uff0c\u652f\u6301\u5bf9\u9ad8\u98ce\u9669AI\u7cfb\u7edf\u548c\u901a\u7528AI\u7cfb\u7edf\u7684\u64cd\u4f5c\u6027\u8bc4\u4f30\u3002", "conclusion": "\u672a\u6765\u5de5\u4f5c\u5c06\u5f00\u53d1\u6b63\u5f0f\u6a21\u578b\u548c\u7b97\u6cd5\uff0c\u4ee5\u589e\u5f3aAI\u98ce\u9669\u8bc4\u4f30\uff0c\u652f\u6301\u8d1f\u8d23\u4efb\u7684AI\u6cbb\u7406\u3002"}}
{"id": "2507.18515", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18515", "abs": "https://arxiv.org/abs/2507.18515", "authors": ["Zezhou Yang", "Ting Peng", "Cuiyun Gao", "Chaozheng Wang", "Hailiang Huang", "Yuetang Deng"], "title": "A Deep Dive into Retrieval-Augmented Generation for Code Completion: Experience on WeChat", "comment": "Accepted in ICSME 25 Industry Track", "summary": "Code completion, a crucial task in software engineering that enhances\ndeveloper productivity, has seen substantial improvements with the rapid\nadvancement of large language models (LLMs). In recent years,\nretrieval-augmented generation (RAG) has emerged as a promising method to\nenhance the code completion capabilities of LLMs, which leverages relevant\ncontext from codebases without requiring model retraining. While existing\nstudies have demonstrated the effectiveness of RAG on public repositories and\nbenchmarks, the potential distribution shift between open-source and\nclosed-source codebases presents unique challenges that remain unexplored. To\nmitigate the gap, we conduct an empirical study to investigate the performance\nof widely-used RAG methods for code completion in the industrial-scale codebase\nof WeChat, one of the largest proprietary software systems. Specifically, we\nextensively explore two main types of RAG methods, namely identifier-based RAG\nand similarity-based RAG, across 26 open-source LLMs ranging from 0.5B to 671B\nparameters. For a more comprehensive analysis, we employ different retrieval\ntechniques for similarity-based RAG, including lexical and semantic retrieval.\nBased on 1,669 internal repositories, we achieve several key findings: (1) both\nRAG methods demonstrate effectiveness in closed-source repositories, with\nsimilarity-based RAG showing superior performance, (2) the effectiveness of\nsimilarity-based RAG improves with more advanced retrieval techniques, where\nBM25 (lexical retrieval) and GTE-Qwen (semantic retrieval) achieve superior\nperformance, and (3) the combination of lexical and semantic retrieval\ntechniques yields optimal results, demonstrating complementary strengths.\nFurthermore, we conduct a developer survey to validate the practical utility of\nRAG methods in real-world development environments.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5728\u95ed\u6e90\u4ee3\u7801\u5e93\u4e2d\u7684\u4ee3\u7801\u8865\u5168\u6548\u679c\uff0c\u53d1\u73b0\u76f8\u4f3c\u6027RAG\u4f18\u4e8e\u6807\u8bc6\u7b26RAG\uff0c\u4e14\u7ed3\u5408\u8bcd\u6cd5\u548c\u8bed\u4e49\u68c0\u7d22\u6280\u672f\u6548\u679c\u6700\u4f73\u3002", "motivation": "\u89e3\u51b3\u5f00\u6e90\u4e0e\u95ed\u6e90\u4ee3\u7801\u5e93\u4e4b\u95f4\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u9a8c\u8bc1RAG\u5728\u5de5\u4e1a\u7ea7\u4ee3\u7801\u5e93\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u5728\u5fae\u4fe1\u4ee3\u7801\u5e93\u4e2d\u6d4b\u8bd526\u4e2a\u5f00\u6e90LLM\uff0c\u6bd4\u8f83\u6807\u8bc6\u7b26RAG\u548c\u76f8\u4f3c\u6027RAG\uff0c\u5e76\u5206\u6790\u8bcd\u6cd5\u548c\u8bed\u4e49\u68c0\u7d22\u6280\u672f\u7684\u5f71\u54cd\u3002", "result": "\u76f8\u4f3c\u6027RAG\u8868\u73b0\u66f4\u4f18\uff0cBM25\u548cGTE-Qwen\u68c0\u7d22\u6280\u672f\u6548\u679c\u663e\u8457\uff0c\u8bcd\u6cd5\u4e0e\u8bed\u4e49\u68c0\u7d22\u7ed3\u5408\u6548\u679c\u6700\u4f73\u3002", "conclusion": "RAG\u5728\u95ed\u6e90\u4ee3\u7801\u5e93\u4e2d\u6709\u6548\uff0c\u7ed3\u5408\u591a\u79cd\u68c0\u7d22\u6280\u672f\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\uff0c\u5f00\u53d1\u8005\u8c03\u67e5\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2507.18478", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18478", "abs": "https://arxiv.org/abs/2507.18478", "authors": ["Shariq Murtuza"], "title": "Scout: Leveraging Large Language Models for Rapid Digital Evidence Discovery", "comment": null, "summary": "Recent technological advancements and the prevalence of technology in day to\nday activities have caused a major increase in the likelihood of the\ninvolvement of digital evidence in more and more legal investigations.\nConsumer-grade hardware is growing more powerful, with expanding memory and\nstorage sizes and enhanced processor capabilities. Forensics investigators\noften have to sift through gigabytes of data during an ongoing investigation\nmaking the process tedious. Memory forensics, disk analysis all are well\nsupported by state of the art tools that significantly lower the effort\nrequired to be put in by a forensic investigator by providing string searches,\nanalyzing images file etc. During the course of the investigation a lot of\nfalse positives are identified that need to be lowered. This work presents\nScout, a digital forensics framework that performs preliminary evidence\nprocessing and prioritizing using large language models. Scout deploys\nfoundational language models to identify relevant artifacts from a large number\nof potential evidence files (disk images, captured network packets, memory\ndumps etc.) which would have taken longer to get identified. Scout employs text\nbased large language models can easily process files with textual information.\nFor the forensic analysis of multimedia files like audio, image, video, office\ndocuments etc. multimodal models are employed by Scout. Scout was able to\nidentify and realize the evidence file that were of potential interest for the\ninvestigator.", "AI": {"tldr": "Scout\u662f\u4e00\u4e2a\u6570\u5b57\u53d6\u8bc1\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u6a21\u578b\u521d\u6b65\u5904\u7406\u548c\u4f18\u5148\u5904\u7406\u8bc1\u636e\uff0c\u51cf\u5c11\u8c03\u67e5\u4e2d\u7684\u8bef\u62a5\u548c\u8017\u65f6\u3002", "motivation": "\u968f\u7740\u6280\u672f\u7684\u666e\u53ca\u548c\u786c\u4ef6\u80fd\u529b\u7684\u63d0\u5347\uff0c\u6570\u5b57\u8bc1\u636e\u5728\u8c03\u67e5\u4e2d\u7684\u6bd4\u91cd\u589e\u52a0\uff0c\u4f46\u5904\u7406\u5927\u91cf\u6570\u636e\u8017\u65f6\u4e14\u7e41\u7410\uff0c\u9700\u8981\u51cf\u5c11\u8bef\u62a5\u3002", "method": "Scout\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u6587\u672c\u4fe1\u606f\uff0c\u591a\u6a21\u6001\u6a21\u578b\u5206\u6790\u591a\u5a92\u4f53\u6587\u4ef6\uff0c\u5feb\u901f\u8bc6\u522b\u6f5c\u5728\u8bc1\u636e\u3002", "result": "Scout\u80fd\u9ad8\u6548\u8bc6\u522b\u5bf9\u8c03\u67e5\u6709\u4ef7\u503c\u7684\u8bc1\u636e\u6587\u4ef6\uff0c\u51cf\u5c11\u4eba\u5de5\u7b5b\u9009\u65f6\u95f4\u3002", "conclusion": "Scout\u901a\u8fc7\u81ea\u52a8\u5316\u521d\u6b65\u8bc1\u636e\u5904\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b57\u53d6\u8bc1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.18337", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18337", "abs": "https://arxiv.org/abs/2507.18337", "authors": ["Peter Baumgartner", "Lachlan McGinness"], "title": "The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams", "comment": null, "summary": "We present our method for automatically marking Physics exams. The marking\nproblem consists in assessing typed student answers for correctness with\nrespect to a ground truth solution. This is a challenging problem that we seek\nto tackle using a combination of a computer algebra system, an SMT solver and a\nterm rewriting system. A Large Language Model is used to interpret and remove\nerrors from student responses and rewrite these in a machine readable format.\nOnce formalized and language-aligned, the next step then consists in applying\nautomated reasoning techniques for assessing student solution correctness. We\nconsider two methods of automated theorem proving: off-the-shelf SMT solving\nand term rewriting systems tailored for physics problems involving\ntrigonometric expressions. The development of the term rewrite system and\nestablishing termination and confluence properties was not trivial, and we\ndescribe it in some detail in the paper. We evaluate our system on a rich pool\nof over 1500 real-world student exam responses from the 2023 Australian Physics\nOlympiad.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u6279\u6539\u7269\u7406\u8003\u8bd5\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u8ba1\u7b97\u673a\u4ee3\u6570\u7cfb\u7edf\u3001SMT\u6c42\u89e3\u5668\u548c\u9879\u91cd\u5199\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u5b66\u751f\u7b54\u6848\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u63a8\u7406\u6280\u672f\u8bc4\u4f30\u6b63\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u8bc4\u4f30\u5b66\u751f\u7269\u7406\u8003\u8bd5\u7b54\u6848\u6b63\u786e\u6027\u7684\u6311\u6218\u6027\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u8ba1\u7b97\u673a\u4ee3\u6570\u7cfb\u7edf\u3001SMT\u6c42\u89e3\u5668\u548c\u9879\u91cd\u5199\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u5b66\u751f\u7b54\u6848\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u63a8\u7406\u6280\u672f\u8bc4\u4f30\u6b63\u786e\u6027\u3002", "result": "\u57282023\u5e74\u6fb3\u5927\u5229\u4e9a\u7269\u7406\u5965\u6797\u5339\u514b\u7ade\u8d5b\u76841500\u591a\u4efd\u771f\u5b9e\u5b66\u751f\u7b54\u6848\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u4f46\u9879\u91cd\u5199\u7cfb\u7edf\u7684\u5f00\u53d1\u5177\u6709\u6311\u6218\u6027\u3002"}}
{"id": "2507.18631", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18631", "abs": "https://arxiv.org/abs/2507.18631", "authors": ["Hao Li", "Lijun Li", "Zhenghao Lu", "Xianyi Wei", "Rui Li", "Jing Shao", "Lei Sha"], "title": "Layer-Aware Representation Filtering: Purifying Finetuning Data to Preserve LLM Safety Alignment", "comment": null, "summary": "With rapid advancement and increasing accessibility of LLMs, fine-tuning\naligned models has become a critical step for adapting them to real-world\napplications, which makes the safety of this fine-tuning process more important\nthan ever. However, recent studies have highlighted a critical challenge: even\nwhen fine-tuning with seemingly benign downstream datasets, the safety of\naligned LLMs can be compromised, making them more susceptible to malicious\ninstructions. In this paper, we show that fine-tuning datasets often contain\nsamples with safety-degrading features that are not easily identifiable on the\nsurface. These samples can significantly degrade the safety alignment of LLMs\nduring fine-tuning. To address this issue, we propose LARF, a\n\\textbf{L}ayer-\\textbf{A}ware \\textbf{R}epresentation \\textbf{F}iltering\nmethod. This method identifies safety-sensitive layers within the LLM and\nleverages their representations to detect which data samples in the\npost-training dataset contain safety-degrading features. Experimental results\ndemonstrate that LARF can effectively identify benign data with\nsafety-degrading features. After removing such data, the safety alignment\ndegradation caused by fine-tuning is mitigated. Please see our code at\n\\href{https://github.com/LLLeoLi/LARF}{https://github.com/LLLeoLi/LARF}.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLARF\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522bLLM\u4e2d\u5b89\u5168\u654f\u611f\u7684\u5c42\u6765\u68c0\u6d4b\u5fae\u8c03\u6570\u636e\u4e2d\u7684\u5b89\u5168\u9690\u60a3\uff0c\u4ece\u800c\u7f13\u89e3\u5b89\u5168\u5bf9\u9f50\u9000\u5316\u95ee\u9898\u3002", "motivation": "\u968f\u7740LLMs\u7684\u5feb\u901f\u53d1\u5c55\u548c\u666e\u53ca\uff0c\u5fae\u8c03\u5bf9\u9f50\u6a21\u578b\u7684\u5b89\u5168\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u662f\u770b\u4f3c\u65e0\u5bb3\u7684\u6570\u636e\u4e5f\u53ef\u80fd\u5bfc\u81f4\u5b89\u5168\u5bf9\u9f50\u9000\u5316\u3002", "method": "\u63d0\u51faLARF\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790LLM\u4e2d\u5b89\u5168\u654f\u611f\u7684\u5c42\uff0c\u68c0\u6d4b\u5fae\u8c03\u6570\u636e\u4e2d\u7684\u5b89\u5168\u9690\u60a3\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eLARF\u80fd\u6709\u6548\u8bc6\u522b\u542b\u5b89\u5168\u9690\u60a3\u7684\u6570\u636e\uff0c\u79fb\u9664\u540e\u7f13\u89e3\u4e86\u5b89\u5168\u5bf9\u9f50\u9000\u5316\u3002", "conclusion": "LARF\u4e3a\u5fae\u8c03LLMs\u65f6\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.18368", "categories": ["cs.AI", "I.2.0; I.2.6; J.4"], "pdf": "https://arxiv.org/pdf/2507.18368", "abs": "https://arxiv.org/abs/2507.18368", "authors": ["Zhuang Qiang Bok", "Watson Wei Khong Chua"], "title": "Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios", "comment": "Accepted by Agentic & GenAI Evaluation KDD2025: KDD workshop on\n  Evaluation and Trustworthiness of Agentic and Generative AI Models\n  https://kdd-eval-workshop.github.io/genai-evaluation-kdd2025/", "summary": "Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step\nlogic. In finance, however, professionals must not only converge on optimal\ndecisions but also generate creative, plausible futures under uncertainty. We\nintroduce ConDiFi, a benchmark that jointly evaluates divergent and convergent\nthinking in LLMs for financial tasks.\n  ConDiFi features 607 macro-financial prompts for divergent reasoning and 990\nmulti-hop adversarial MCQs for convergent reasoning. Using this benchmark, we\nevaluated 14 leading models and uncovered striking differences. Despite high\nfluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models\nlike DeepSeek-R1 and Cohere Command R+ rank among the top for generating\nactionable, insights suitable for investment decisions. ConDiFi provides a new\nperspective to assess reasoning capabilities essential to safe and strategic\ndeployment of LLMs in finance.", "AI": {"tldr": "ConDiFi\u662f\u4e00\u4e2a\u8bc4\u4f30LLMs\u5728\u91d1\u878d\u4efb\u52a1\u4e2d\u53d1\u6563\u548c\u6536\u655b\u601d\u7ef4\u7684\u57fa\u51c6\uff0c\u5305\u542b607\u4e2a\u5b8f\u89c2\u91d1\u878d\u63d0\u793a\u548c990\u4e2a\u591a\u8df3\u5bf9\u6297\u6027\u9009\u62e9\u9898\u3002\u6d4b\u8bd514\u4e2a\u9886\u5148\u6a21\u578b\u540e\u53d1\u73b0\uff0cGPT-4o\u5728\u65b0\u9896\u6027\u548c\u53ef\u64cd\u4f5c\u6027\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800cDeepSeek-R1\u548cCohere Command R+\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u91d1\u878d\u9886\u57df\u9700\u8981LLMs\u4e0d\u4ec5\u80fd\u505a\u51fa\u6700\u4f18\u51b3\u7b56\uff0c\u8fd8\u9700\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u751f\u6210\u521b\u9020\u6027\u3001\u5408\u7406\u7684\u672a\u6765\u60c5\u666f\uff0c\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u4e8b\u5b9e\u51c6\u786e\u6027\u6216\u9010\u6b65\u903b\u8f91\uff0c\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u5f00\u53d1ConDiFi\u57fa\u51c6\uff0c\u5305\u542b\u53d1\u6563\u601d\u7ef4\uff08\u5b8f\u89c2\u91d1\u878d\u63d0\u793a\uff09\u548c\u6536\u655b\u601d\u7ef4\uff08\u591a\u8df3\u5bf9\u6297\u6027\u9009\u62e9\u9898\uff09\u4e24\u90e8\u5206\uff0c\u8bc4\u4f3014\u4e2a\u9886\u5148\u6a21\u578b\u3002", "result": "GPT-4o\u6d41\u7545\u6027\u9ad8\u4f46\u5728\u65b0\u9896\u6027\u548c\u53ef\u64cd\u4f5c\u6027\u4e0a\u8868\u73b0\u4e0d\u4f73\uff1bDeepSeek-R1\u548cCohere Command R+\u5728\u751f\u6210\u53ef\u64cd\u4f5c\u89c1\u89e3\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "ConDiFi\u4e3a\u8bc4\u4f30LLMs\u5728\u91d1\u878d\u9886\u57df\u7684\u5b89\u5168\u548c\u6218\u7565\u90e8\u7f72\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2507.18391", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18391", "abs": "https://arxiv.org/abs/2507.18391", "authors": ["Shiye Lei", "Zhihao Cheng", "Kai Jia", "Dacheng Tao"], "title": "Revisiting LLM Reasoning via Information Bottleneck", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated remarkable progress\nin reasoning capabilities through reinforcement learning with verifiable\nrewards (RLVR). By leveraging simple rule-based rewards, RL effectively\nincentivizes LLMs to produce extended chain-of-thought (CoT) reasoning\ntrajectories, progressively guiding them toward correct answers. However,\nexisting approaches remain largely heuristic and intuition-driven, limiting the\ndevelopment of principled methodologies. In this paper, we present a\ntheoretical characterization of LLM reasoning grounded in information\nbottleneck (IB) principle, introducing IB-aware reasoning optimization (IBRO),\na framework that encourages reasoning trajectories to be both informative about\nthe final correct answer and generalizable across diverse prompts. We derive a\npractical token-level surrogate objective and propose an efficient\napproximation, resulting in the lightweight IB regularization method. This\ntechnique integrates seamlessly into existing RL-based post-training frameworks\nwithout additional computational overhead, requiring only a one-line code\nmodification. Empirically, we validate IB regularization across multiple\nmathematical reasoning benchmarks and RL algorithms, demonstrating consistent\nimprovements in LLM reasoning performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\uff08IB\uff09\u539f\u5219\u7684\u7406\u8bba\u6846\u67b6IBRO\uff0c\u7528\u4e8e\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7IB\u6b63\u5219\u5316\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u548c\u76f4\u89c9\uff0c\u7f3a\u4e4f\u7406\u8bba\u652f\u6301\uff0c\u9650\u5236\u4e86\u63a8\u7406\u80fd\u529b\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002", "method": "\u63d0\u51faIB-aware\u63a8\u7406\u4f18\u5316\uff08IBRO\uff09\u6846\u67b6\uff0c\u63a8\u5bfc\u51fa\u4ee4\u724c\u7ea7\u4ee3\u7406\u76ee\u6807\uff0c\u5e76\u8bbe\u8ba1\u8f7b\u91cf\u7ea7IB\u6b63\u5219\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u548cRL\u7b97\u6cd5\u4e2d\u9a8c\u8bc1\u4e86IB\u6b63\u5219\u5316\u7684\u6709\u6548\u6027\uff0c\u63a8\u7406\u6027\u80fd\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "IBRO\u6846\u67b6\u4e3aLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u8f7b\u91cf\u7ea7IB\u6b63\u5219\u5316\u65b9\u6cd5\u7b80\u5355\u9ad8\u6548\uff0c\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2507.18398", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18398", "abs": "https://arxiv.org/abs/2507.18398", "authors": ["Kwong Ho Li", "Wathsala Karunarathne"], "title": "Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation", "comment": "10 pages", "summary": "This paper investigates the application of Reinforcement Learning (RL) to\noptimise call routing in call centres to minimise client waiting time and staff\nidle time. Two methods are compared: a model-based approach using Value\nIteration (VI) under known system dynamics, and a model-free approach using\nProximal Policy Optimisation (PPO) that learns from experience. For the\nmodel-based approach, a theoretical model is used, while a simulation model\ncombining Discrete Event Simulation (DES) with the OpenAI Gym environment is\ndeveloped for model-free learning. Both models frame the problem as a Markov\nDecision Process (MDP) within a Skills-Based Routing (SBR) framework, with\nPoisson client arrivals and exponentially distributed service and abandonment\ntimes. For policy evaluation, random, VI, and PPO policies are evaluated using\nthe simulation model. After 1,000 test episodes, PPO consistently achives the\nhighest rewards, along with the lowest client waiting time and staff idle time,\ndespite requiring longer training time.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u57fa\u4e8e\u6a21\u578b\uff08VI\uff09\u548c\u65e0\u6a21\u578b\uff08PPO\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u547c\u53eb\u4e2d\u5fc3\u8def\u7531\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0cPPO\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u4f18\u5316\u547c\u53eb\u4e2d\u5fc3\u7684\u8def\u7531\u7b56\u7565\uff0c\u4ee5\u51cf\u5c11\u5ba2\u6237\u7b49\u5f85\u65f6\u95f4\u548c\u5458\u5de5\u7a7a\u95f2\u65f6\u95f4\u3002", "method": "\u6bd4\u8f83\u4e86\u57fa\u4e8e\u6a21\u578b\uff08VI\uff09\u548c\u65e0\u6a21\u578b\uff08PPO\uff09\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528MDP\u6846\u67b6\u548cSBR\u6a21\u578b\u3002", "result": "PPO\u57281000\u6b21\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u5ba2\u6237\u7b49\u5f85\u65f6\u95f4\u548c\u5458\u5de5\u7a7a\u95f2\u65f6\u95f4\u6700\u4f4e\u3002", "conclusion": "PPO\u662f\u547c\u53eb\u4e2d\u5fc3\u8def\u7531\u4f18\u5316\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5c3d\u7ba1\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\u3002"}}
{"id": "2507.18413", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18413", "abs": "https://arxiv.org/abs/2507.18413", "authors": ["Enrico Santi", "Fabio Tardivo", "Agostino Dovier", "Andrea Formisano"], "title": "GPU Accelerated Compact-Table Propagation", "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "summary": "Constraint Programming developed within Logic Programming in the Eighties;\nnowadays all Prolog systems encompass modules capable of handling constraint\nprogramming on finite domains demanding their solution to a constraint solver.\nThis work focuses on a specific form of constraint, the so-called table\nconstraint, used to specify conditions on the values of variables as an\nenumeration of alternative options. Since every condition on a set of finite\ndomain variables can be ultimately expressed as a finite set of cases, Table\ncan, in principle, simulate any other constraint. These characteristics make\nTable one of the most studied constraints ever, leading to a series of\nincreasingly efficient propagation algorithms. Despite this, it is not uncommon\nto encounter real-world problems with hundreds or thousands of valid cases that\nare simply too many to be handled effectively with standard CPU-based\napproaches. In this paper, we deal with the Compact-Table (CT) algorithm, the\nstate-of-the-art propagation algorithms for Table. We describe how CT can be\nenhanced by exploiting the massive computational power offered by modern GPUs\nto handle large Table constraints. In particular, we report on the design and\nimplementation of GPU-accelerated CT, on its integration into an existing\nconstraint solver, and on an experimental validation performed on a significant\nset of instances.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u73b0\u4ee3GPU\u7684\u8ba1\u7b97\u80fd\u529b\u589e\u5f3aCompact-Table\uff08CT\uff09\u7b97\u6cd5\uff0c\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u8868\u7ea6\u675f\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edfCPU\u5728\u5904\u7406\u5305\u542b\u6570\u767e\u6216\u6570\u5343\u4e2a\u6709\u6548\u6848\u4f8b\u7684\u8868\u7ea6\u675f\u95ee\u9898\u65f6\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u8981\u5229\u7528GPU\u7684\u5e76\u884c\u8ba1\u7b97\u80fd\u529b\u63d0\u5347\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86GPU\u52a0\u901f\u7684CT\u7b97\u6cd5\uff0c\u5c06\u5176\u96c6\u6210\u5230\u73b0\u6709\u7ea6\u675f\u6c42\u89e3\u5668\u4e2d\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGPU\u52a0\u901f\u7684CT\u7b97\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u8868\u7ea6\u675f\u95ee\u9898\u65f6\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u4f20\u7edfCPU\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7GPU\u52a0\u901f\uff0cCT\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u8868\u7ea6\u675f\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.18550", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.18550", "abs": "https://arxiv.org/abs/2507.18550", "authors": ["Manuel de Sousa Ribeiro", "Afonso Leote", "Jo\u00e3o Leite"], "title": "On the Performance of Concept Probing: The Influence of the Data (Extended Version)", "comment": "Extended version of the paper published in Proceedings of the\n  European Conference on Artificial Intelligence (ECAI 2025)", "summary": "Concept probing has recently garnered increasing interest as a way to help\ninterpret artificial neural networks, dealing both with their typically large\nsize and their subsymbolic nature, which ultimately renders them unfeasible for\ndirect human interpretation. Concept probing works by training additional\nclassifiers to map the internal representations of a model into human-defined\nconcepts of interest, thus allowing humans to peek inside artificial neural\nnetworks. Research on concept probing has mainly focused on the model being\nprobed or the probing model itself, paying limited attention to the data\nrequired to train such probing models. In this paper, we address this gap.\nFocusing on concept probing in the context of image classification tasks, we\ninvestigate the effect of the data used to train probing models on their\nperformance. We also make available concept labels for two widely used\ndatasets.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6982\u5ff5\u63a2\u6d4b\u4e2d\u8bad\u7ec3\u6570\u636e\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e24\u4e2a\u5e38\u7528\u6570\u636e\u96c6\u7684\u6807\u7b7e\u3002", "motivation": "\u6982\u5ff5\u63a2\u6d4b\u7528\u4e8e\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5ffd\u89c6\u4e86\u8bad\u7ec3\u6570\u636e\u7684\u5f71\u54cd\u3002", "method": "\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u7814\u7a76\u8bad\u7ec3\u6570\u636e\u5bf9\u6982\u5ff5\u63a2\u6d4b\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5206\u6790\u4e86\u6570\u636e\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u516c\u5f00\u4e86\u4e24\u4e2a\u6570\u636e\u96c6\u7684\u6807\u7b7e\u3002", "conclusion": "\u8bad\u7ec3\u6570\u636e\u5bf9\u6982\u5ff5\u63a2\u6d4b\u6a21\u578b\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u516c\u5f00\u6807\u7b7e\u6709\u52a9\u4e8e\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2507.18576", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.18576", "abs": "https://arxiv.org/abs/2507.18576", "authors": ["Shanghai AI Lab", ":", "Yicheng Bao", "Guanxu Chen", "Mingkang Chen", "Yunhao Chen", "Chiyu Chen", "Lingjie Chen", "Sirui Chen", "Xinquan Chen", "Jie Cheng", "Yu Cheng", "Dengke Deng", "Yizhuo Ding", "Dan Ding", "Xiaoshan Ding", "Yi Ding", "Zhichen Dong", "Lingxiao Du", "Yuyu Fan", "Xinshun Feng", "Yanwei Fu", "Yuxuan Gao", "Ruijun Ge", "Tianle Gu", "Lujun Gui", "Jiaxuan Guo", "Qianxi He", "Yuenan Hou", "Xuhao Hu", "Hong Huang", "Kaichen Huang", "Shiyang Huang", "Yuxian Jiang", "Shanzhe Lei", "Jie Li", "Lijun Li", "Hao Li", "Juncheng Li", "Xiangtian Li", "Yafu Li", "Lingyu Li", "Xueyan Li", "Haotian Liang", "Dongrui Liu", "Qihua Liu", "Zhixuan Liu", "Bangwei Liu", "Huacan Liu", "Yuexiao Liu", "Zongkai Liu", "Chaochao Lu", "Yudong Lu", "Xiaoya Lu", "Zhenghao Lu", "Qitan Lv", "Caoyuan Ma", "Jiachen Ma", "Xiaoya Ma", "Zhongtian Ma", "Lingyu Meng", "Ziqi Miao", "Yazhe Niu", "Yuezhang Peng", "Yuan Pu", "Han Qi", "Chen Qian", "Xingge Qiao", "Jingjing Qu", "Jiashu Qu", "Wanying Qu", "Wenwen Qu", "Xiaoye Qu", "Qihan Ren", "Qingnan Ren", "Qingyu Ren", "Jing Shao", "Wenqi Shao", "Shuai Shao", "Dongxing Shi", "Xin Song", "Xinhao Song", "Yan Teng", "Xuan Tong", "Yingchun Wang", "Xuhong Wang", "Shujie Wang", "Xin Wang", "Yige Wang", "Yixu Wang", "Yuanfu Wang", "Futing Wang", "Ruofan Wang", "Wenjie Wang", "Yajie Wang", "Muhao Wei", "Xiaoyu Wen", "Fenghua Weng", "Yuqi Wu", "Yingtong Xiong", "Xingcheng Xu", "Chao Yang", "Yue Yang", "Yang Yao", "Yulei Ye", "Zhenyun Yin", "Yi Yu", "Bo Zhang", "Qiaosheng Zhang", "Jinxuan Zhang", "Yexin Zhang", "Yinqiang Zheng", "Hefeng Zhou", "Zhanhui Zhou", "Pengyu Zhu", "Qingzi Zhu", "Yubo Zhu", "Bowen Zhou"], "title": "SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\\circ}$ Law", "comment": "47 pages, 18 figures, authors are listed in alphabetical order by\n  their last names", "summary": "We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that\ndemonstrates the coevolution of capabilities and safety. It is developed by our\nproposed SafeLadder framework, which incorporates large-scale, progressive,\nsafety-oriented reinforcement learning post-training, supported by a suite of\nmulti-principled verifiers. Unlike previous alignment methods such as RLHF that\nsimply learn human preferences, SafeLadder enables SafeWork-R1 to develop\nintrinsic safety reasoning and self-reflection abilities, giving rise to safety\n`aha' moments. Notably, SafeWork-R1 achieves an average improvement of\n$46.54\\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks\nwithout compromising general capabilities, and delivers state-of-the-art safety\nperformance compared to leading proprietary models such as GPT-4.1 and Claude\nOpus 4. To further bolster its reliability, we implement two distinct\ninference-time intervention methods and a deliberative search mechanism,\nenforcing step-level verification. Finally, we further develop\nSafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and\nSafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and\ncapability can co-evolve synergistically, highlighting the generalizability of\nour framework in building robust, reliable, and trustworthy general-purpose AI.", "AI": {"tldr": "SafeWork-R1\u662f\u4e00\u79cd\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\uff0c\u901a\u8fc7SafeLadder\u6846\u67b6\u5b9e\u73b0\u80fd\u529b\u4e0e\u5b89\u5168\u6027\u7684\u534f\u540c\u8fdb\u5316\uff0c\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982RLHF\uff09\u4ec5\u5b66\u4e60\u4eba\u7c7b\u504f\u597d\u800c\u7f3a\u4e4f\u5185\u5728\u5b89\u5168\u63a8\u7406\u80fd\u529b\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528SafeLadder\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u89c4\u6a21\u6e10\u8fdb\u5f0f\u5b89\u5168\u5bfc\u5411\u7684\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u548c\u591a\u539f\u5219\u9a8c\u8bc1\u5668\u3002", "result": "\u5728\u5b89\u5168\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u63d0\u534746.54%\uff0c\u4f18\u4e8eGPT-4.1\u548cClaude Opus 4\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u80fd\u529b\u3002", "conclusion": "SafeLadder\u6846\u67b6\u80fd\u6784\u5efa\u7a33\u5065\u3001\u53ef\u9760\u4e14\u53ef\u4fe1\u7684\u901a\u7528AI\uff0c\u8bc1\u660e\u5b89\u5168\u4e0e\u80fd\u529b\u53ef\u534f\u540c\u8fdb\u5316\u3002"}}
