{"id": "2509.18341", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.18341", "abs": "https://arxiv.org/abs/2509.18341", "authors": ["Christopher Simon Liu", "Fan Wang", "Patrick Gould", "Carter Yagemann"], "title": "SoK: A Beginner-Friendly Introduction to Fault Injection Attacks", "comment": "18 pages, 18 figures", "summary": "Fault Injection is the study of observing how systems behave under unusual\nstress, environmental or otherwise. In practice, fault injection involves\ntesting the limits of computer systems and finding novel ways to potentially\nbreak cyber-physical security.\n  The contributions of this paper are three-fold. First, we provide a\nbeginner-friendly introduction to this research topic and an in-depth taxonomy\nof fault injection techniques. Second, we highlight the current\nstate-of-the-art and provide a cost-benefit analysis of each attack method.\nThird, for those interested in doing fault injection research, we provide a\nreplication analysis of an existing vulnerability detection tool and identify a\nresearch focus for future work.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u6545\u969c\u6ce8\u5165\u7814\u7a76\u7684\u5165\u95e8\u4ecb\u7ecd\u3001\u6280\u672f\u5206\u7c7b\u3001\u6210\u672c\u6548\u76ca\u5206\u6790\u4ee5\u53ca\u73b0\u6709\u6f0f\u6d1e\u68c0\u6d4b\u5de5\u5177\u7684\u590d\u5236\u5206\u6790", "motivation": "\u6545\u969c\u6ce8\u5165\u662f\u7814\u7a76\u7cfb\u7edf\u5728\u5f02\u5e38\u538b\u529b\u4e0b\u7684\u884c\u4e3a\uff0c\u65e8\u5728\u6d4b\u8bd5\u8ba1\u7b97\u673a\u7cfb\u7edf\u7684\u6781\u9650\u5e76\u5bfb\u627e\u7834\u574f\u7f51\u7edc\u7269\u7406\u5b89\u5168\u7684\u65b0\u65b9\u6cd5", "method": "\u901a\u8fc7\u5efa\u7acb\u6545\u969c\u6ce8\u5165\u6280\u672f\u5206\u7c7b\u6cd5\uff0c\u8fdb\u884c\u6210\u672c\u6548\u76ca\u5206\u6790\uff0c\u5e76\u5bf9\u73b0\u6709\u6f0f\u6d1e\u68c0\u6d4b\u5de5\u5177\u8fdb\u884c\u590d\u5236\u5206\u6790", "result": "\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6545\u969c\u6ce8\u5165\u6280\u672f\u5206\u7c7b\u548c\u6210\u672c\u6548\u76ca\u8bc4\u4f30\uff0c\u8bc6\u522b\u4e86\u672a\u6765\u7814\u7a76\u7684\u91cd\u70b9\u65b9\u5411", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6545\u969c\u6ce8\u5165\u9886\u57df\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u6846\u67b6\u548c\u5b9e\u7528\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55"}}
{"id": "2509.18366", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.18366", "abs": "https://arxiv.org/abs/2509.18366", "authors": ["Aleksandr Dolgavin", "Jacob Gatlin", "Moti Yung", "Mark Yampolskiy"], "title": "Turning Hearsay into Discovery: Industrial 3D Printer Side Channel Information Translated to Stealing the Object Design", "comment": null, "summary": "The central security issue of outsourced 3D printing (aka AM: Additive\nManufacturing), an industry that is expected to dominate manufacturing, is the\nprotection of the digital design (containing the designers' model, which is\ntheir intellectual property) shared with the manufacturer. Here, we show, for\nthe first time, that side-channel attacks are, in fact, a concrete serious\nthreat to existing industrial grade 3D printers, enabling the reconstruction of\nthe model printed (regardless of employing ways to directly conceal the design,\ne.g. by encrypting it in transit and before loading it into the printer).\nPreviously, such attacks were demonstrated only on fairly simple FDM desktop 3D\nprinters, which play a negligible role in manufacturing of valuable designs. We\nfocus on the Powder Bed Fusion (PBF) AM process, which is popular for\nmanufacturing net-shaped parts with both polymers and metals. We demonstrate\nhow its individual actuators can be instrumented for the collection of power\nside-channel information during the printing process. We then present our\napproach to reconstruct the 3D printed model solely from the collected power\nside-channel data. Further, inspired by Differential Power Analysis, we\ndeveloped a method to improve the quality of the reconstruction based on\nmultiple traces. We tested our approach on two design models with different\ndegrees of complexity. For different models, we achieved as high as 90.29~\\% of\nTrue Positives and as low as 7.02~\\% and 9.71~\\% of False Positives and False\nNegatives by voxel-based volumetric comparison between reconstructed and\noriginal designs. The lesson learned from our attack is that the security of\ndesign files cannot solely rely on protecting the files themselves in an\nindustrial environment, but must instead also rely on assuring no leakage of\npower, noise and similar signals to potential eavesdroppers in the printer's\nvicinity.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u8bc1\u660e\u4fa7\u4fe1\u9053\u653b\u51fb\u5bf9\u5de5\u4e1a\u7ea73D\u6253\u5370\u673a\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u80fd\u591f\u901a\u8fc7\u529f\u7387\u4fa7\u4fe1\u9053\u6570\u636e\u91cd\u5efa\u6253\u5370\u6a21\u578b\uff0c\u5373\u4f7f\u8bbe\u8ba1\u6587\u4ef6\u5df2\u52a0\u5bc6\u3002", "motivation": "\u4fdd\u62a43D\u6253\u5370\u4e2d\u7684\u6570\u5b57\u8bbe\u8ba1\u77e5\u8bc6\u4ea7\u6743\uff0c\u7279\u522b\u662f\u5de5\u4e1a\u7ea7\u6253\u5370\u673a\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u6b64\u524d\u4fa7\u4fe1\u9053\u653b\u51fb\u4ec5\u5728\u7b80\u5355\u7684\u684c\u97623D\u6253\u5370\u673a\u4e0a\u6f14\u793a\u8fc7\u3002", "method": "\u9488\u5bf9\u7c89\u672b\u5e8a\u7194\u878d(PBF)3D\u6253\u5370\u5de5\u827a\uff0c\u901a\u8fc7\u4eea\u5668\u5316\u6267\u884c\u5668\u6536\u96c6\u529f\u7387\u4fa7\u4fe1\u9053\u6570\u636e\uff0c\u5f00\u53d1\u57fa\u4e8e\u591a\u8f68\u8ff9\u7684\u91cd\u5efa\u65b9\u6cd5\uff0c\u53d7\u5dee\u5206\u529f\u7387\u5206\u6790\u542f\u53d1\u63d0\u9ad8\u91cd\u5efa\u8d28\u91cf\u3002", "result": "\u5728\u4e24\u4e2a\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u8bbe\u8ba1\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0c\u901a\u8fc7\u4f53\u7d20\u4f53\u79ef\u6bd4\u8f83\uff0c\u91cd\u5efa\u6a21\u578b\u8fbe\u523090.29%\u7684\u771f\u9633\u6027\u7387\uff0c\u5047\u9633\u6027\u548c\u5047\u9634\u6027\u7387\u5206\u522b\u4e3a7.02%\u548c9.71%\u3002", "conclusion": "\u5de5\u4e1a\u73af\u5883\u4e2d\u8bbe\u8ba1\u6587\u4ef6\u7684\u5b89\u5168\u4e0d\u80fd\u4ec5\u4f9d\u8d56\u6587\u4ef6\u672c\u8eab\u4fdd\u62a4\uff0c\u8fd8\u5fc5\u987b\u9632\u6b62\u529f\u7387\u3001\u566a\u58f0\u7b49\u4fe1\u53f7\u6cc4\u6f0f\u7ed9\u6f5c\u5728\u7a83\u542c\u8005\u3002"}}
{"id": "2509.18413", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18413", "abs": "https://arxiv.org/abs/2509.18413", "authors": ["Efthymios Tsaprazlis", "Thanathai Lertpetchpun", "Tiantian Feng", "Sai Praneeth Karimireddy", "Shrikanth Narayanan"], "title": "VoxGuard: Evaluating User and Attribute Privacy in Speech via Membership Inference Attacks", "comment": null, "summary": "Voice anonymization aims to conceal speaker identity and attributes while\npreserving intelligibility, but current evaluations rely almost exclusively on\nEqual Error Rate (EER) that obscures whether adversaries can mount\nhigh-precision attacks. We argue that privacy should instead be evaluated in\nthe low false-positive rate (FPR) regime, where even a small number of\nsuccessful identifications constitutes a meaningful breach. To this end, we\nintroduce VoxGuard, a framework grounded in differential privacy and membership\ninference that formalizes two complementary notions: User Privacy, preventing\nspeaker re-identification, and Attribute Privacy, protecting sensitive traits\nsuch as gender and accent. Across synthetic and real datasets, we find that\ninformed adversaries, especially those using fine-tuned models and\nmax-similarity scoring, achieve orders-of-magnitude stronger attacks at low-FPR\ndespite similar EER. For attributes, we show that simple transparent attacks\nrecover gender and accent with near-perfect accuracy even after anonymization.\nOur results demonstrate that EER substantially underestimates leakage,\nhighlighting the need for low-FPR evaluation, and recommend VoxGuard as a\nbenchmark for evaluating privacy leakage.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86VoxGuard\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u8bed\u97f3\u533f\u540d\u5316\u5728\u4f4e\u8bef\u62a5\u7387\uff08FPR\uff09\u4e0b\u7684\u9690\u79c1\u4fdd\u62a4\u6548\u679c\uff0c\u53d1\u73b0\u4f20\u7edf\u7b49\u9519\u8bef\u7387\uff08EER\uff09\u8bc4\u4f30\u4e25\u91cd\u4f4e\u4f30\u4e86\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u533f\u540d\u5316\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u7b49\u9519\u8bef\u7387\uff08EER\uff09\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u63a9\u76d6\u4e86\u653b\u51fb\u8005\u5728\u4f4e\u8bef\u62a5\u7387\u4e0b\u53ef\u80fd\u53d1\u8d77\u7684\u7cbe\u51c6\u653b\u51fb\u98ce\u9669\u3002", "method": "\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\u548c\u6210\u5458\u63a8\u7406\uff0c\u63d0\u51faVoxGuard\u6846\u67b6\uff0c\u5f62\u5f0f\u5316\u5b9a\u4e49\u7528\u6237\u9690\u79c1\uff08\u9632\u6b62\u8bf4\u8bdd\u4eba\u91cd\u8bc6\u522b\uff09\u548c\u5c5e\u6027\u9690\u79c1\uff08\u4fdd\u62a4\u6027\u522b\u3001\u53e3\u97f3\u7b49\u654f\u611f\u7279\u5f81\uff09\u4e24\u4e2a\u4e92\u8865\u6982\u5ff5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4f4eFPR\u4e0b\uff0c\u7279\u522b\u662f\u4f7f\u7528\u5fae\u8c03\u6a21\u578b\u548c\u6700\u5927\u76f8\u4f3c\u5ea6\u8bc4\u5206\u7684\u653b\u51fb\u8005\u80fd\u591f\u5b9e\u73b0\u6570\u91cf\u7ea7\u66f4\u5f3a\u7684\u653b\u51fb\uff1b\u7b80\u5355\u900f\u660e\u653b\u51fb\u51e0\u4e4e\u80fd\u5b8c\u7f8e\u6062\u590d\u533f\u540d\u5316\u540e\u7684\u6027\u522b\u548c\u53e3\u97f3\u4fe1\u606f\u3002", "conclusion": "EER\u8bc4\u4f30\u4e25\u91cd\u4f4e\u4f30\u9690\u79c1\u6cc4\u9732\uff0c\u9700\u8981\u91c7\u7528\u4f4eFPR\u8bc4\u4f30\u6807\u51c6\uff0c\u63a8\u8350VoxGuard\u4f5c\u4e3a\u9690\u79c1\u6cc4\u9732\u8bc4\u4f30\u7684\u57fa\u51c6\u6846\u67b6\u3002"}}
{"id": "2509.18415", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18415", "abs": "https://arxiv.org/abs/2509.18415", "authors": ["Sumana Malkapuram", "Sameera Gangavarapu", "Kailashnath Reddy Kavalakuntla", "Ananya Gangavarapu"], "title": "Context Lineage Assurance for Non-Human Identities in Critical Multi-Agent Systems", "comment": null, "summary": "The proliferation of autonomous software agents necessitates rigorous\nframeworks for establishing secure and verifiable agent-to-agent (A2A)\ninteractions, particularly when such agents are instantiated as non-human\nidentities(NHIs). We extend the A2A paradigm [1 , 2] by introducing a\ncryptographically grounded mechanism for lineage verification, wherein the\nprovenance and evolution of NHIs are anchored in append-only Merkle tree\nstructures modeled after Certificate Transparency (CT) logs. Unlike traditional\nA2A models that primarily secure point-to-point interactions, our approach\nenables both agents and external verifiers to cryptographically validate\nmulti-hop provenance, thereby ensuring the integrity of the entire call chain.\n  A federated proof server acts as an auditor across one or more Merkle logs,\naggregating inclusion proofs and consistency checks into compact, signed\nattestations that external parties can verify without access to the full\nexecution trace. In parallel, we augment the A2A agent card to incorporate\nexplicit identity verification primitives, enabling both peer agents and human\napprovers to authenticate the legitimacy of NHI representations in a\nstandardized manner. Together, these contributions establish a cohesive model\nthat integrates identity attestation, lineage verification, and independent\nproof auditing, thereby advancing the security posture of inter-agent\necosystems and providing a foundation for robust governance of NHIs in\nregulated environments such as FedRAMP.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bc6\u7801\u5b66\u7684\u673a\u5236\uff0c\u7528\u4e8e\u9a8c\u8bc1\u975e\u4eba\u7c7b\u8eab\u4efd\uff08NHI\uff09\u7684\u8c31\u7cfb\uff0c\u901a\u8fc7Merkle\u6811\u7ed3\u6784\u548c\u8054\u90a6\u8bc1\u660e\u670d\u52a1\u5668\u6765\u786e\u4fdd\u591a\u8df3\u6765\u6e90\u7684\u5b8c\u6574\u6027\u9a8c\u8bc1\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b\u8f6f\u4ef6\u4ee3\u7406\u7684\u6fc0\u589e\uff0c\u9700\u8981\u5efa\u7acb\u5b89\u5168\u53ef\u9a8c\u8bc1\u7684\u4ee3\u7406\u95f4\u4ea4\u4e92\u6846\u67b6\uff0c\u7279\u522b\u662f\u5728\u975e\u4eba\u7c7b\u8eab\u4efd\u5b9e\u4f8b\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u4f20\u7edfA2A\u6a21\u578b\u53ea\u80fd\u4fdd\u62a4\u70b9\u5bf9\u70b9\u4ea4\u4e92\uff0c\u65e0\u6cd5\u9a8c\u8bc1\u6574\u4e2a\u8c03\u7528\u94fe\u7684\u5b8c\u6574\u6027\u3002", "method": "\u6269\u5c55A2A\u8303\u5f0f\uff0c\u5f15\u5165\u57fa\u4e8eMerkle\u6811\u7684\u8c31\u7cfb\u9a8c\u8bc1\u673a\u5236\uff0c\u4f7f\u7528\u7c7b\u4f3c\u8bc1\u4e66\u900f\u660e\u5ea6\u65e5\u5fd7\u7684\u53ea\u8ffd\u52a0\u6570\u636e\u7ed3\u6784\uff1b\u5efa\u7acb\u8054\u90a6\u8bc1\u660e\u670d\u52a1\u5668\u4f5c\u4e3a\u5ba1\u8ba1\u5668\uff0c\u805a\u5408\u5305\u542b\u8bc1\u660e\u548c\u4e00\u81f4\u6027\u68c0\u67e5\uff1b\u589e\u5f3aA2A\u4ee3\u7406\u5361\u4ee5\u5305\u542b\u8eab\u4efd\u9a8c\u8bc1\u539f\u8bed\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u96c6\u6210\u8eab\u4efd\u8bc1\u660e\u3001\u8c31\u7cfb\u9a8c\u8bc1\u548c\u72ec\u7acb\u8bc1\u660e\u5ba1\u8ba1\u7684\u5b8c\u6574\u6a21\u578b\uff0c\u4f7f\u4ee3\u7406\u548c\u5916\u90e8\u9a8c\u8bc1\u8005\u80fd\u591f\u5bc6\u7801\u5b66\u9a8c\u8bc1\u591a\u8df3\u6765\u6e90\uff0c\u786e\u4fdd\u6574\u4e2a\u8c03\u7528\u94fe\u7684\u5b8c\u6574\u6027\u3002", "conclusion": "\u8be5\u6a21\u578b\u63d0\u5347\u4e86\u4ee3\u7406\u95f4\u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u6001\u52bf\uff0c\u4e3a\u5728\u53d7\u76d1\u7ba1\u73af\u5883\uff08\u5982FedRAMP\uff09\u4e2d\u7a33\u5065\u6cbb\u7406\u975e\u4eba\u7c7b\u8eab\u4efd\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.18337", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18337", "abs": "https://arxiv.org/abs/2509.18337", "authors": ["Bo Xiong", "Linghao Zhang", "Chong Wang", "Peng Liang"], "title": "CoRaCMG: Contextual Retrieval-Augmented Framework for Commit Message Generation", "comment": "15 pages, 4 images, 6 tables, Manuscript submitted to a Journal\n  (2025)", "summary": "Commit messages play a key role in documenting the intent behind code\nchanges. However, they are often low-quality, vague, or incomplete, limiting\ntheir usefulness. Commit Message Generation (CMG) aims to automatically\ngenerate descriptive commit messages from code diffs to reduce developers'\neffort and improve message quality. Although recent advances in LLMs have shown\npromise in automating CMG, their performance remains limited. This paper aims\nto enhance CMG performance by retrieving similar diff-message pairs to guide\nLLMs to generate commit messages that are more precise and informative. We\nproposed CoRaCMG, a Contextual Retrieval-augmented framework for Commit Message\nGeneration, structured in three phases: (1) Retrieve: retrieving the similar\ndiff-message pairs; (2) Augment: combining them with the query diff into a\nstructured prompt; and (3) Generate: generating commit messages corresponding\nto the query diff via LLMs. CoRaCMG enables LLMs to learn project-specific\nterminologies and writing styles from the retrieved diff-message pairs, thereby\nproducing high-quality commit messages. We evaluated our method on various\nLLMs, including closed-source GPT models and open-source DeepSeek models.\nExperimental results show that CoRaCMG significantly boosts LLM performance\nacross four metrics (BLEU, Rouge-L, METEOR, and CIDEr). Specifically,\nDeepSeek-R1 achieves relative improvements of 76% in BLEU and 71% in CIDEr when\naugmented with a single retrieved example pair. After incorporating the single\nexample pair, GPT-4o achieves the highest improvement rate, with BLEU\nincreasing by 89%. Moreover, performance gains plateau after more than three\nexamples are used, indicating diminishing returns. Further analysis shows that\nthe improvements are attributed to the model's ability to capture the\nterminologies and writing styles of human-written commit messages from the\nretrieved example pairs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CoRaCMG\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u76f8\u4f3c\u7684diff-message\u5bf9\u6765\u589e\u5f3aLLMs\u751f\u6210\u63d0\u4ea4\u6d88\u606f\u7684\u6027\u80fd\uff0c\u663e\u8457\u63d0\u5347\u4e86BLEU\u3001Rouge-L\u3001METEOR\u548cCIDEr\u7b49\u6307\u6807\u3002", "motivation": "\u63d0\u4ea4\u6d88\u606f\u5728\u8bb0\u5f55\u4ee3\u7801\u53d8\u66f4\u610f\u56fe\u65b9\u9762\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u63d0\u4ea4\u6d88\u606f\u5f80\u5f80\u8d28\u91cf\u4f4e\u4e0b\u3001\u6a21\u7cca\u6216\u4e0d\u5b8c\u6574\u3002\u867d\u7136LLMs\u5728\u81ea\u52a8\u751f\u6210\u63d0\u4ea4\u6d88\u606f\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u6027\u80fd\u4ecd\u6709\u5c40\u9650\u3002", "method": "CoRaCMG\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a(1)\u68c0\u7d22\u76f8\u4f3c\u7684diff-message\u5bf9\uff1b(2)\u5c06\u8fd9\u4e9b\u5bf9\u4e0e\u67e5\u8be2diff\u7ed3\u5408\u6210\u7ed3\u6784\u5316\u63d0\u793a\uff1b(3)\u901a\u8fc7LLMs\u751f\u6210\u5bf9\u5e94\u7684\u63d0\u4ea4\u6d88\u606f\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCoRaCMG\u663e\u8457\u63d0\u5347\u4e86LLM\u6027\u80fd\uff0cDeepSeek-R1\u5728BLEU\u548cCIDEr\u4e0a\u5206\u522b\u63d0\u5347\u4e8676%\u548c71%\uff0cGPT-4o\u7684BLEU\u63d0\u5347\u4e8689%\u3002\u4f7f\u7528\u8d85\u8fc7\u4e09\u4e2a\u793a\u4f8b\u540e\u6027\u80fd\u63d0\u5347\u8d8b\u4e8e\u5e73\u7a33\u3002", "conclusion": "CoRaCMG\u901a\u8fc7\u8ba9LLMs\u4ece\u68c0\u7d22\u5230\u7684\u793a\u4f8b\u5bf9\u4e2d\u5b66\u4e60\u9879\u76ee\u7279\u5b9a\u672f\u8bed\u548c\u5199\u4f5c\u98ce\u683c\uff0c\u80fd\u591f\u751f\u6210\u66f4\u7cbe\u786e\u548c\u4fe1\u606f\u4e30\u5bcc\u7684\u9ad8\u8d28\u91cf\u63d0\u4ea4\u6d88\u606f\u3002"}}
{"id": "2509.18101", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18101", "abs": "https://arxiv.org/abs/2509.18101", "authors": ["Guanzhong Pan", "Haibo Wang"], "title": "A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services", "comment": null, "summary": "Large language models (LLMs) are becoming increasingly widespread.\nOrganizations that want to use AI for productivity now face an important\ndecision. They can subscribe to commercial LLM services or deploy models on\ntheir own infrastructure. Cloud services from providers such as OpenAI,\nAnthropic, and Google are attractive because they provide easy access to\nstate-of-the-art models and are easy to scale. However, concerns about data\nprivacy, the difficulty of switching service providers, and long-term operating\ncosts have driven interest in local deployment of open-source models. This\npaper presents a cost-benefit analysis framework to help organizations\ndetermine when on-premise LLM deployment becomes economically viable compared\nto commercial subscription services. We consider the hardware requirements,\noperational expenses, and performance benchmarks of the latest open-source\nmodels, including Qwen, Llama, Mistral, and etc. Then we compare the total cost\nof deploying these models locally with the major cloud providers subscription\nfee. Our findings provide an estimated breakeven point based on usage levels\nand performance needs. These results give organizations a practical framework\nfor planning their LLM strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6210\u672c\u6548\u76ca\u5206\u6790\u6846\u67b6\uff0c\u5e2e\u52a9\u7ec4\u7ec7\u786e\u5b9a\u4f55\u65f6\u672c\u5730\u90e8\u7f72\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u6bd4\u5546\u4e1a\u8ba2\u9605\u670d\u52a1\u66f4\u5177\u7ecf\u6d4e\u53ef\u884c\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7ec4\u7ec7\u9762\u4e34\u9009\u62e9\u5546\u4e1a\u4e91\u670d\u52a1\u8fd8\u662f\u672c\u5730\u90e8\u7f72\u7684\u51b3\u7b56\u3002\u867d\u7136\u4e91\u670d\u52a1\u63d0\u4f9b\u5148\u8fdb\u6a21\u578b\u548c\u6613\u6269\u5c55\u6027\uff0c\u4f46\u6570\u636e\u9690\u79c1\u3001\u4f9b\u5e94\u5546\u9501\u5b9a\u548c\u957f\u671f\u6210\u672c\u95ee\u9898\u63a8\u52a8\u4e86\u672c\u5730\u90e8\u7f72\u7684\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6700\u65b0\u5f00\u6e90\u6a21\u578b\uff08\u5982Qwen\u3001Llama\u3001Mistral\u7b49\uff09\u7684\u786c\u4ef6\u9700\u6c42\u3001\u8fd0\u8425\u6210\u672c\u548c\u6027\u80fd\u57fa\u51c6\uff0c\u5e76\u4e0e\u4e3b\u8981\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u8ba2\u9605\u8d39\u7528\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u4e8e\u4f7f\u7528\u6c34\u5e73\u548c\u6027\u80fd\u9700\u6c42\u7684\u76c8\u4e8f\u5e73\u8861\u70b9\u4f30\u8ba1\uff0c\u4e3a\u7ec4\u7ec7\u89c4\u5212LLM\u7b56\u7565\u63d0\u4f9b\u5b9e\u7528\u6846\u67b6\u3002", "conclusion": "\u8be5\u5206\u6790\u6846\u67b6\u5e2e\u52a9\u7ec4\u7ec7\u5728\u7ecf\u6d4e\u5c42\u9762\u505a\u51fa\u66f4\u660e\u667a\u7684LLM\u90e8\u7f72\u51b3\u7b56\uff0c\u5e73\u8861\u6210\u672c\u6548\u76ca\u4e0e\u8fd0\u8425\u9700\u6c42\u3002"}}
{"id": "2509.18520", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18520", "abs": "https://arxiv.org/abs/2509.18520", "authors": ["Steve Huntsman"], "title": "Coherence-driven inference for cybersecurity", "comment": "LLM4Sec - Workshop on the use of Large Language Models for\n  Cybersecurity (https://llm4sec-workshop.github.io/)", "summary": "Large language models (LLMs) can compile weighted graphs on natural language\ndata to enable automatic coherence-driven inference (CDI) relevant to red and\nblue team operations in cybersecurity. This represents an early application of\nautomatic CDI that holds near- to medium-term promise for decision-making in\ncybersecurity and eventually also for autonomous blue team operations.", "AI": {"tldr": "LLMs\u5229\u7528\u81ea\u7136\u8bed\u8a00\u6570\u636e\u6784\u5efa\u52a0\u6743\u56fe\uff0c\u5b9e\u73b0\u81ea\u52a8\u8fde\u8d2f\u6027\u9a71\u52a8\u63a8\u7406\uff0c\u5e94\u7528\u4e8e\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u7ea2\u84dd\u961f\u64cd\u4f5c\u3002", "motivation": "\u5c06\u81ea\u52a8\u8fde\u8d2f\u6027\u9a71\u52a8\u63a8\u7406\u5e94\u7528\u4e8e\u7f51\u7edc\u5b89\u5168\u51b3\u7b56\u652f\u6301\uff0c\u7279\u522b\u662f\u7ea2\u84dd\u961f\u64cd\u4f5c\uff0c\u4ee5\u63d0\u5347\u51b3\u7b56\u6548\u7387\u548c\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u81ea\u7136\u8bed\u8a00\u6570\u636e\uff0c\u6784\u5efa\u52a0\u6743\u56fe\uff0c\u5e76\u57fa\u4e8e\u8fde\u8d2f\u6027\u9a71\u52a8\u63a8\u7406\u8fdb\u884c\u81ea\u52a8\u63a8\u7406\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u5c55\u73b0\u51fa\u8fd1\u4e2d\u671f\u5e94\u7528\u6f5c\u529b\uff0c\u80fd\u591f\u652f\u6301\u51b3\u7b56\u5236\u5b9a\uff0c\u5e76\u6709\u671b\u5b9e\u73b0\u81ea\u4e3b\u84dd\u961f\u64cd\u4f5c\u3002", "conclusion": "\u81ea\u52a8\u8fde\u8d2f\u6027\u9a71\u52a8\u63a8\u7406\u662f\u7f51\u7edc\u5b89\u5168\u9886\u57df\u4e00\u4e2a\u6709\u524d\u666f\u7684\u6280\u672f\u65b9\u5411\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.18361", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.18361", "abs": "https://arxiv.org/abs/2509.18361", "authors": ["Daye Nam", "Malgorzata Salawa", "Satish Chandra"], "title": "Reading Between the Lines: Scalable User Feedback via Implicit Sentiment in Developer Prompts", "comment": null, "summary": "Evaluating developer satisfaction with conversational AI assistants at scale\nis critical but challenging. User studies provide rich insights, but are\nunscalable, while large-scale quantitative signals from logs or in-product\nratings are often too shallow or sparse to be reliable. To address this gap, we\npropose and evaluate a new approach: using sentiment analysis of developer\nprompts to identify implicit signals of user satisfaction. With an analysis of\nindustrial usage logs of 372 professional developers, we show that this\napproach can identify a signal in ~8% of all interactions, a rate more than 13\ntimes higher than explicit user feedback, with reasonable accuracy even with an\noff-the-shelf sentiment analysis approach. This new practical approach to\ncomplement existing feedback channels would open up new directions for building\na more comprehensive understanding of the developer experience at scale.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u5206\u6790\u5f00\u53d1\u8005\u63d0\u793a\u7684\u60c5\u611f\u6765\u8bc4\u4f30\u5bf9\u8bddAI\u52a9\u624b\u6ee1\u610f\u5ea6\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u6bd4\u663e\u5f0f\u7528\u6237\u53cd\u9988\u7684\u8bc6\u522b\u7387\u9ad813\u500d\u4ee5\u4e0a", "motivation": "\u5927\u89c4\u6a21\u8bc4\u4f30\u5f00\u53d1\u8005\u5bf9\u5bf9\u8bddAI\u52a9\u624b\u7684\u6ee1\u610f\u5ea6\u5f88\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\uff0c\u7528\u6237\u7814\u7a76\u96be\u4ee5\u6269\u5c55\uff0c\u800c\u5927\u89c4\u6a21\u5b9a\u91cf\u4fe1\u53f7\u5f80\u5f80\u8fc7\u4e8e\u6d45\u5c42\u6216\u7a00\u758f", "method": "\u4f7f\u7528\u60c5\u611f\u5206\u6790\u6280\u672f\u5206\u6790\u5f00\u53d1\u8005\u63d0\u793a\u4e2d\u7684\u9690\u542b\u6ee1\u610f\u5ea6\u4fe1\u53f7\uff0c\u57fa\u4e8e372\u540d\u4e13\u4e1a\u5f00\u53d1\u8005\u7684\u5de5\u4e1a\u4f7f\u7528\u65e5\u5fd7\u8fdb\u884c\u5206\u6790", "result": "\u8be5\u65b9\u6cd5\u53ef\u5728\u7ea68%\u7684\u4ea4\u4e92\u4e2d\u8bc6\u522b\u51fa\u4fe1\u53f7\uff0c\u8bc6\u522b\u7387\u6bd4\u663e\u5f0f\u7528\u6237\u53cd\u9988\u9ad813\u500d\u4ee5\u4e0a\uff0c\u5373\u4f7f\u4f7f\u7528\u73b0\u6210\u7684\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u4e5f\u80fd\u8fbe\u5230\u5408\u7406\u51c6\u786e\u5ea6", "conclusion": "\u8fd9\u79cd\u65b0\u65b9\u6cd5\u4e3a\u8865\u5145\u73b0\u6709\u53cd\u9988\u6e20\u9053\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\uff0c\u4e3a\u5927\u89c4\u6a21\u7406\u89e3\u5f00\u53d1\u8005\u4f53\u9a8c\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411"}}
{"id": "2509.18123", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18123", "abs": "https://arxiv.org/abs/2509.18123", "authors": ["Yeonju Lee", "Rui Qi Chen", "Joseph Oboamah", "Po Nien Su", "Wei-zhen Liang", "Yeyin Shi", "Lu Gan", "Yongsheng Chen", "Xin Qiao", "Jing Li"], "title": "SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture", "comment": null, "summary": "Accurate interpretation of soil moisture patterns is critical for irrigation\nscheduling and crop management, yet existing approaches for soil moisture\ntime-series analysis either rely on threshold-based rules or data-hungry\nmachine learning or deep learning models that are limited in adaptability and\ninterpretability. In this study, we introduce SPADE (Soil moisture Pattern and\nAnomaly DEtection), an integrated framework that leverages large language\nmodels (LLMs) to jointly detect irrigation patterns and anomalies in soil\nmoisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced\nreasoning and instruction-following capabilities, enabling zero-shot analysis\nwithout requiring task-specific annotation or fine-tuning. By converting\ntime-series data into a textual representation and designing domain-informed\nprompt templates, SPADE identifies irrigation events, estimates net irrigation\ngains, detects, classifies anomalies, and produces structured, interpretable\nreports. Experiments were conducted on real-world soil moisture sensor data\nfrom commercial and experimental farms cultivating multiple crops across the\nUnited States. Results demonstrate that SPADE outperforms the existing method\nin anomaly detection, achieving higher recall and F1 scores and accurately\nclassifying anomaly types. Furthermore, SPADE achieved high precision and\nrecall in detecting irrigation events, indicating its strong capability to\ncapture irrigation patterns accurately. SPADE's reports provide\ninterpretability and usability of soil moisture analytics. This study\nhighlights the potential of LLMs as scalable, adaptable tools for precision\nagriculture, which is capable of integrating qualitative knowledge and\ndata-driven reasoning to produce actionable insights for accurate soil moisture\nmonitoring and improved irrigation scheduling from soil moisture time-series\ndata.", "AI": {"tldr": "SPADE\u662f\u4e00\u4e2a\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u571f\u58e4\u6e7f\u5ea6\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7684\u96c6\u6210\u6846\u67b6\uff0c\u80fd\u591f\u68c0\u6d4b\u704c\u6e89\u6a21\u5f0f\u548c\u5f02\u5e38\uff0c\u65e0\u9700\u7279\u5b9a\u4efb\u52a1\u6807\u6ce8\u6216\u5fae\u8c03\u3002", "motivation": "\u73b0\u6709\u571f\u58e4\u6e7f\u5ea6\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u65b9\u6cd5\u4f9d\u8d56\u57fa\u4e8e\u9608\u503c\u7684\u89c4\u5219\u6216\u6570\u636e\u5bc6\u96c6\u578b\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5b58\u5728\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u9650\u5236\u3002", "method": "SPADE\u5229\u7528ChatGPT-4.1\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u8f6c\u6362\u4e3a\u6587\u672c\u8868\u793a\uff0c\u901a\u8fc7\u9886\u57df\u77e5\u8bc6\u63d0\u793a\u6a21\u677f\u8fdb\u884c\u96f6\u6837\u672c\u5206\u6790\uff0c\u68c0\u6d4b\u704c\u6e89\u4e8b\u4ef6\u3001\u4f30\u8ba1\u51c0\u704c\u6e89\u589e\u76ca\u3001\u5206\u7c7b\u5f02\u5e38\u3002", "result": "\u5728\u771f\u5b9e\u519c\u7530\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cSPADE\u5728\u5f02\u5e38\u68c0\u6d4b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u53ec\u56de\u7387\u548cF1\u5206\u6570\uff0c\u5e76\u80fd\u51c6\u786e\u5206\u7c7b\u5f02\u5e38\u7c7b\u578b\u3002", "conclusion": "LLMs\u53ef\u4f5c\u4e3a\u7cbe\u51c6\u519c\u4e1a\u7684\u53ef\u6269\u5c55\u3001\u9002\u5e94\u6027\u5de5\u5177\uff0c\u6574\u5408\u5b9a\u6027\u77e5\u8bc6\u548c\u6570\u636e\u9a71\u52a8\u63a8\u7406\uff0c\u4e3a\u571f\u58e4\u6e7f\u5ea6\u76d1\u6d4b\u548c\u704c\u6e89\u8c03\u5ea6\u63d0\u4f9b\u53ef\u64cd\u4f5c\u89c1\u89e3\u3002"}}
{"id": "2509.18572", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.18572", "abs": "https://arxiv.org/abs/2509.18572", "authors": ["Kemi Akanbi", "Sunkanmi Oluwadare", "Jess Kropczynski", "Jacques Bou Abdo"], "title": "Examining I2P Resilience: Effect of Centrality-based Attack", "comment": null, "summary": "This study examines the robustness of I2P, a well-regarded anonymous and\ndecentralized peer-to-peer network designed to ensure anonymity,\nconfidentiality, and circumvention of censorship. Unlike its more widely\nresearched counterpart, TOR, I2P's resilience has received less scholarly\nattention. Employing network analysis, this research evaluates I2P's\nsusceptibility to adversarial percolation. By utilizing the degree centrality\nas a measure of nodes' influence in the network, the finding suggests the\nnetwork is vulnerable to targeted disruptions. Before percolation, the network\nexhibited a density of 0.01065443 and an average path length of 6.842194. At\nthe end of the percolation process, the density decreased by approximately 10%,\nand the average path length increased by 33%, indicating a decline in\nefficiency and connectivity. These results highlight that even decentralized\nnetworks, such as I2P, exhibit structural fragility under targeted attacks,\nemphasizing the need for improved design strategies to enhance resilience\nagainst adversarial disruptions.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86I2P\u533f\u540d\u7f51\u7edc\u5bf9\u9488\u5bf9\u6027\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u8be5\u7f51\u7edc\u5728\u5bf9\u6297\u6027\u6e17\u900f\u653b\u51fb\u4e0b\u8868\u73b0\u51fa\u7ed3\u6784\u8106\u5f31\u6027\uff0c\u7f51\u7edc\u5bc6\u5ea6\u4e0b\u964d\u7ea610%\uff0c\u5e73\u5747\u8def\u5f84\u957f\u5ea6\u589e\u52a033%\u3002", "motivation": "I2P\u4f5c\u4e3a\u4e00\u4e2a\u77e5\u540d\u7684\u533f\u540d\u53bb\u4e2d\u5fc3\u5316P2P\u7f51\u7edc\uff0c\u867d\u7136\u8bbe\u8ba1\u7528\u4e8e\u786e\u4fdd\u533f\u540d\u6027\u3001\u673a\u5bc6\u6027\u548c\u89c4\u907f\u5ba1\u67e5\uff0c\u4f46\u5176\u6297\u653b\u51fb\u80fd\u529b\u76f8\u6bd4TOR\u7f51\u7edc\u7814\u7a76\u8f83\u5c11\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5bf9\u6297\u6027\u6e17\u900f\u7684\u8106\u5f31\u6027\u3002", "method": "\u91c7\u7528\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\uff0c\u4f7f\u7528\u5ea6\u4e2d\u5fc3\u6027\u4f5c\u4e3a\u8282\u70b9\u5f71\u54cd\u529b\u7684\u5ea6\u91cf\u6307\u6807\uff0c\u8bc4\u4f30I2P\u7f51\u7edc\u5bf9\u9488\u5bf9\u6027\u7834\u574f\u7684\u654f\u611f\u6027\u3002", "result": "\u6e17\u900f\u524d\u7f51\u7edc\u5bc6\u5ea6\u4e3a0.01065443\uff0c\u5e73\u5747\u8def\u5f84\u957f\u5ea6\u4e3a6.842194\uff1b\u6e17\u900f\u540e\u5bc6\u5ea6\u4e0b\u964d\u7ea610%\uff0c\u5e73\u5747\u8def\u5f84\u957f\u5ea6\u589e\u52a033%\uff0c\u8868\u660e\u7f51\u7edc\u6548\u7387\u548c\u8fde\u63a5\u6027\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u5373\u4f7f\u662f\u53bb\u4e2d\u5fc3\u5316\u7f51\u7edc\u5982I2P\uff0c\u5728\u9488\u5bf9\u6027\u653b\u51fb\u4e0b\u4e5f\u8868\u73b0\u51fa\u7ed3\u6784\u8106\u5f31\u6027\uff0c\u9700\u8981\u6539\u8fdb\u8bbe\u8ba1\u7b56\u7565\u4ee5\u589e\u5f3a\u5bf9\u6297\u6027\u7834\u574f\u7684\u97e7\u6027\u3002"}}
{"id": "2509.18454", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18454", "abs": "https://arxiv.org/abs/2509.18454", "authors": ["Andrzej Bia\u0142ecki", "Piotr Bia\u0142ecki", "Piotr Sowi\u0144ski", "Mateusz Budziak", "Jan Gajewski"], "title": "SC2Tools: StarCraft II Toolset and Dataset API", "comment": null, "summary": "Computer games, as fully controlled simulated environments, have been\nutilized in significant scientific studies demonstrating the application of\nReinforcement Learning (RL). Gaming and esports are key areas influenced by the\napplication of Artificial Intelligence (AI) and Machine Learning (ML) solutions\nat scale. Tooling simplifies scientific workloads and is essential for\ndeveloping the gaming and esports research area.\n  In this work, we present ``SC2Tools'', a toolset containing multiple\nsubmodules responsible for working with, and producing larger datasets. We\nprovide a modular structure of the implemented tooling, leaving room for future\nextensions where needed. Additionally, some of the tools are not StarCraft~2\nexclusive and can be used with other types of data for dataset creation.\n  The tools we present were leveraged in creating one of the largest\nStarCraft~2 tournament datasets to date with a separate PyTorch and PyTorch\nLightning application programming interface (API) for easy access to the data.\n  We conclude that alleviating the burden of data collection, preprocessing,\nand custom code development is essential for less technically proficient\nresearchers to engage in the growing gaming and esports research area. Finally,\nour solution provides some foundational work toward normalizing experiment\nworkflow in StarCraft~2", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SC2Tools\u5de5\u5177\u96c6\uff0c\u7528\u4e8e\u7b80\u5316\u661f\u9645\u4e89\u97382\u7b49\u6e38\u620f\u6570\u636e\u7684\u5904\u7406\u548c\u5927\u89c4\u6a21\u6570\u636e\u96c6\u521b\u5efa\uff0c\u65e8\u5728\u964d\u4f4e\u6e38\u620f\u548c\u7535\u7ade\u7814\u7a76\u7684\u6280\u672f\u95e8\u69db\u3002", "motivation": "\u6e38\u620f\u4f5c\u4e3a\u53d7\u63a7\u6a21\u62df\u73af\u5883\u5728\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4f46\u6570\u636e\u6536\u96c6\u3001\u9884\u5904\u7406\u548c\u5b9a\u5236\u4ee3\u7801\u5f00\u53d1\u7b49\u6280\u672f\u8d1f\u62c5\u963b\u788d\u4e86\u975e\u6280\u672f\u80cc\u666f\u7814\u7a76\u4eba\u5458\u53c2\u4e0e\u6e38\u620f\u548c\u7535\u7ade\u7814\u7a76\u9886\u57df\u3002", "method": "\u5f00\u53d1\u4e86\u6a21\u5757\u5316\u7684SC2Tools\u5de5\u5177\u96c6\uff0c\u5305\u542b\u591a\u4e2a\u5b50\u6a21\u5757\u7528\u4e8e\u6570\u636e\u5904\u7406\u548c\u6570\u636e\u96c6\u521b\u5efa\uff0c\u63d0\u4f9bPyTorch\u548cPyTorch Lightning API\u63a5\u53e3\uff0c\u90e8\u5206\u5de5\u5177\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u7c7b\u578b\u6570\u636e\u3002", "result": "\u5229\u7528\u8be5\u5de5\u5177\u96c6\u521b\u5efa\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u661f\u9645\u4e89\u97382\u6bd4\u8d5b\u6570\u636e\u96c6\uff0c\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u4fbf\u6377\u7684\u6570\u636e\u8bbf\u95ee\u65b9\u5f0f\u3002", "conclusion": "\u51cf\u8f7b\u6570\u636e\u6536\u96c6\u548c\u5904\u7406\u7684\u6280\u672f\u8d1f\u62c5\u5bf9\u4e8e\u4fc3\u8fdb\u6e38\u620f\u548c\u7535\u7ade\u7814\u7a76\u81f3\u5173\u91cd\u8981\uff0c\u8be5\u5de5\u5177\u96c6\u4e3a\u661f\u9645\u4e89\u97382\u5b9e\u9a8c\u6d41\u7a0b\u6807\u51c6\u5316\u63d0\u4f9b\u4e86\u57fa\u7840\u5de5\u4f5c\u3002"}}
{"id": "2509.18132", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18132", "abs": "https://arxiv.org/abs/2509.18132", "authors": ["Xiuyi Fan"], "title": "Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI", "comment": "Accepted at the International Joint Conference on Neural Networks,\n  IJCNN 2025", "summary": "Uncertainty is a fundamental challenge in medical practice, but current\nmedical AI systems fail to explicitly quantify or communicate uncertainty in a\nway that aligns with clinical reasoning. Existing XAI works focus on\ninterpreting model predictions but do not capture the confidence or reliability\nof these predictions. Conversely, uncertainty estimation (UE) techniques\nprovide confidence measures but lack intuitive explanations. The disconnect\nbetween these two areas limits AI adoption in medicine. To address this gap, we\npropose Explainable Uncertainty Estimation (XUE) that integrates explainability\nwith uncertainty quantification to enhance trust and usability in medical AI.\nWe systematically map medical uncertainty to AI uncertainty concepts and\nidentify key challenges in implementing XUE. We outline technical directions\nfor advancing XUE, including multimodal uncertainty quantification,\nmodel-agnostic visualization techniques, and uncertainty-aware decision support\nsystems. Lastly, we propose guiding principles to ensure effective XUE\nrealisation. Our analysis highlights the need for AI systems that not only\ngenerate reliable predictions but also articulate confidence levels in a\nclinically meaningful way. This work contributes to the development of\ntrustworthy medical AI by bridging explainability and uncertainty, paving the\nway for AI systems that are aligned with real-world clinical complexities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53ef\u89e3\u91ca\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff08XUE\uff09\u6846\u67b6\uff0c\u5c06\u53ef\u89e3\u91ca\u6027\u4e0e\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u76f8\u7ed3\u5408\uff0c\u4ee5\u89e3\u51b3\u533b\u7597AI\u4e2d\u4e0d\u786e\u5b9a\u6027\u6c9f\u901a\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u533b\u7597AI\u7cfb\u7edf\u672a\u80fd\u4ee5\u7b26\u5408\u4e34\u5e8a\u63a8\u7406\u7684\u65b9\u5f0f\u660e\u786e\u91cf\u5316\u6216\u4f20\u8fbe\u4e0d\u786e\u5b9a\u6027\uff0c\u73b0\u6709\u53ef\u89e3\u91caAI\uff08XAI\uff09\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u6355\u6349\uff0c\u800c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff08UE\uff09\u6280\u672f\u53c8\u7f3a\u4e4f\u76f4\u89c2\u89e3\u91ca\uff0c\u8fd9\u79cd\u8131\u8282\u9650\u5236\u4e86AI\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faXUE\u6846\u67b6\uff0c\u7cfb\u7edf\u5730\u5c06\u533b\u7597\u4e0d\u786e\u5b9a\u6027\u6620\u5c04\u5230AI\u4e0d\u786e\u5b9a\u6027\u6982\u5ff5\uff0c\u8bc6\u522bXUE\u5b9e\u65bd\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u89c4\u5212\u6280\u672f\u65b9\u5411\u5305\u62ec\u591a\u6a21\u6001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3001\u6a21\u578b\u65e0\u5173\u7684\u53ef\u89c6\u5316\u6280\u672f\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002", "result": "\u5206\u6790\u5f3a\u8c03\u4e86\u9700\u8981\u5f00\u53d1\u4e0d\u4ec5\u80fd\u751f\u6210\u53ef\u9760\u9884\u6d4b\uff0c\u8fd8\u80fd\u4ee5\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u65b9\u5f0f\u8868\u8fbe\u7f6e\u4fe1\u6c34\u5e73\u7684AI\u7cfb\u7edf\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u6865\u63a5\u53ef\u89e3\u91ca\u6027\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u5f00\u53d1\u53ef\u4fe1\u8d56\u7684\u533b\u7597AI\u505a\u51fa\u8d21\u732e\uff0c\u4e3a\u7b26\u5408\u73b0\u5b9e\u4e16\u754c\u4e34\u5e8a\u590d\u6742\u6027\u7684AI\u7cfb\u7edf\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2509.18578", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.18578", "abs": "https://arxiv.org/abs/2509.18578", "authors": ["Xinwei Zhang", "Haibo Hu", "Qingqing Ye", "Li Bai", "Huadi Zheng"], "title": "MER-Inspector: Assessing model extraction risks from an attack-agnostic perspective", "comment": "Published in ACM WWW 2025", "summary": "Information leakage issues in machine learning-based Web applications have\nattracted increasing attention. While the risk of data privacy leakage has been\nrigorously analyzed, the theory of model function leakage, known as Model\nExtraction Attacks (MEAs), has not been well studied. In this paper, we are the\nfirst to understand MEAs theoretically from an attack-agnostic perspective and\nto propose analytical metrics for evaluating model extraction risks. By using\nthe Neural Tangent Kernel (NTK) theory, we formulate the linearized MEA as a\nregularized kernel classification problem and then derive the fidelity gap and\ngeneralization error bounds of the attack performance. Based on these\ntheoretical analyses, we propose a new theoretical metric called Model Recovery\nComplexity (MRC), which measures the distance of weight changes between the\nvictim and surrogate models to quantify risk. Additionally, we find that victim\nmodel accuracy, which shows a strong positive correlation with model extraction\nrisk, can serve as an empirical metric. By integrating these two metrics, we\npropose a framework, namely Model Extraction Risk Inspector (MER-Inspector), to\ncompare the extraction risks of models under different model architectures by\nutilizing relative metric values. We conduct extensive experiments on 16 model\narchitectures and 5 datasets. The experimental results demonstrate that the\nproposed metrics have a high correlation with model extraction risks, and\nMER-Inspector can accurately compare the extraction risks of any two models\nwith up to 89.58%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u4ece\u653b\u51fb\u65e0\u5173\u7684\u89d2\u5ea6\u7406\u8bba\u5206\u6790\u6a21\u578b\u63d0\u53d6\u653b\u51fb(MEAs)\uff0c\u63d0\u51fa\u6a21\u578b\u63d0\u53d6\u98ce\u9669\u8bc4\u4f30\u7684\u5206\u6790\u6307\u6807\uff0c\u5305\u62ec\u7406\u8bba\u6307\u6807MRC\u548c\u5b9e\u8bc1\u6307\u6807\u6a21\u578b\u7cbe\u5ea6\uff0c\u5e76\u5f00\u53d1MER-Inspector\u6846\u67b6\u6765\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u7684\u63d0\u53d6\u98ce\u9669\u3002", "motivation": "\u673a\u5668\u5b66\u4e60Web\u5e94\u7528\u4e2d\u7684\u4fe1\u606f\u6cc4\u9732\u95ee\u9898\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u6a21\u578b\u529f\u80fd\u6cc4\u9732\uff08\u5373\u6a21\u578b\u63d0\u53d6\u653b\u51fb\uff09\u7684\u7406\u8bba\u7814\u7a76\u5c1a\u672a\u6df1\u5165\uff0c\u9700\u8981\u4ece\u7406\u8bba\u89d2\u5ea6\u5206\u6790\u6a21\u578b\u63d0\u53d6\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u6b63\u5207\u6838(NTK)\u7406\u8bba\u5c06\u7ebf\u6027\u5316MEA\u5efa\u6a21\u4e3a\u6b63\u5219\u5316\u6838\u5206\u7c7b\u95ee\u9898\uff0c\u63a8\u5bfc\u653b\u51fb\u6027\u80fd\u7684\u4fdd\u771f\u5ea6\u5dee\u8ddd\u548c\u6cdb\u5316\u8bef\u5dee\u754c\uff0c\u63d0\u51fa\u6a21\u578b\u6062\u590d\u590d\u6742\u5ea6(MRC)\u7406\u8bba\u6307\u6807\uff0c\u7ed3\u5408\u6a21\u578b\u7cbe\u5ea6\u5b9e\u8bc1\u6307\u6807\uff0c\u6784\u5efaMER-Inspector\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u572816\u79cd\u6a21\u578b\u67b6\u6784\u548c5\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u6307\u6807\u4e0e\u6a21\u578b\u63d0\u53d6\u98ce\u9669\u9ad8\u5ea6\u76f8\u5173\uff0cMER-Inspector\u80fd\u51c6\u786e\u6bd4\u8f83\u4efb\u610f\u4e24\u4e2a\u6a21\u578b\u7684\u63d0\u53d6\u98ce\u9669\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe89.58%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6a21\u578b\u63d0\u53d6\u653b\u51fb\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u8bc4\u4f30\u5de5\u5177\uff0c\u63d0\u51fa\u7684\u6307\u6807\u80fd\u6709\u6548\u91cf\u5316\u6a21\u578b\u63d0\u53d6\u98ce\u9669\uff0cMER-Inspector\u6846\u67b6\u53ef\u5e2e\u52a9\u5f00\u53d1\u8005\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u7684\u6297\u63d0\u53d6\u653b\u51fb\u80fd\u529b\u3002"}}
{"id": "2509.18548", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18548", "abs": "https://arxiv.org/abs/2509.18548", "authors": ["Steven R Brandt", "Max Morris", "Patrick Diehl", "Christopher Bowen", "Jacob Tucker", "Lauren Bristol", "Golden G. Richard III"], "title": "Locking Down Science Gateways", "comment": null, "summary": "The most recent Linux kernels have a new feature for securing applications:\nLandlock. Like Seccomp before it, Landlock makes it possible for a running\nprocess to give up access to resources. For applications running as Science\nGateways, network access is required while starting up MPI, but for the sake of\nsecurity, it should be taken away prior to the reading of user-supplied\nparameter files. We explore the usefulness of Landlock by modifying and locking\ndown three mature scientific codes: The Einstein Toolkit (a code that studies\nthe dynamics of relativistic astrophysics, e.g. neutron star collisions),\nOcto-Tiger (a code for studying the dynamics of non-relativistic astrophysics,\ne.g. white dwarfs), and FUKA (an initial data solver for relativistic codes).\nFinally, we implement a fully-functioning FUKA science gateway that relies on\nLandlock (instead of user authentication) for security.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86Linux\u5185\u6838\u65b0\u5b89\u5168\u7279\u6027Landlock\u5728\u79d1\u5b66\u7f51\u5173\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u901a\u8fc7\u4fee\u6539\u4e09\u4e2a\u6210\u719f\u7684\u79d1\u5b66\u4ee3\u7801\uff08Einstein Toolkit\u3001Octo-Tiger\u3001FUKA\uff09\u6765\u5b9e\u73b0\u5b89\u5168\u9501\u5b9a\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eLandlock\u7684FUKA\u79d1\u5b66\u7f51\u5173\u3002", "motivation": "\u79d1\u5b66\u7f51\u5173\u5e94\u7528\u5728\u542f\u52a8MPI\u65f6\u9700\u8981\u7f51\u7edc\u8bbf\u95ee\uff0c\u4f46\u4e3a\u4e86\u5b89\u5168\u8003\u8651\uff0c\u5728\u8bfb\u53d6\u7528\u6237\u63d0\u4f9b\u7684\u53c2\u6570\u6587\u4ef6\u4e4b\u524d\u5e94\u8be5\u64a4\u9500\u8fd9\u4e9b\u8bbf\u95ee\u6743\u9650\u3002Landlock\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u5b89\u5168\u673a\u5236\uff0c\u80fd\u591f\u5e2e\u52a9\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002", "method": "\u901a\u8fc7\u4fee\u6539\u4e09\u4e2a\u6210\u719f\u7684\u79d1\u5b66\u4ee3\u7801\uff08Einstein Toolkit\u3001Octo-Tiger\u3001FUKA\uff09\u6765\u5e94\u7528Landlock\u5b89\u5168\u673a\u5236\uff0c\u5b9e\u73b0\u5bf9\u8fd9\u4e9b\u4ee3\u7801\u7684\u5b89\u5168\u9501\u5b9a\u3002\u7279\u522b\u5730\uff0c\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5b8c\u5168\u529f\u80fd\u7684FUKA\u79d1\u5b66\u7f51\u5173\uff0c\u8be5\u7f51\u5173\u4f9d\u8d56Landlock\u800c\u4e0d\u662f\u7528\u6237\u8ba4\u8bc1\u6765\u786e\u4fdd\u5b89\u5168\u3002", "result": "\u6210\u529f\u5c55\u793a\u4e86Landlock\u5728\u79d1\u5b66\u7f51\u5173\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u80fd\u591f\u6709\u6548\u63a7\u5236\u5e94\u7528\u7a0b\u5e8f\u5bf9\u8d44\u6e90\u7684\u8bbf\u95ee\u6743\u9650\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u4e34\u65f6\u7f51\u7edc\u8bbf\u95ee\u540e\u53ca\u65f6\u64a4\u9500\u6743\u9650\u7684\u5b89\u5168\u573a\u666f\u4e2d\u3002", "conclusion": "Landlock\u662f\u4e00\u79cd\u6709\u6548\u7684\u5b89\u5168\u673a\u5236\uff0c\u53ef\u4ee5\u66ff\u4ee3\u4f20\u7edf\u7684\u7528\u6237\u8ba4\u8bc1\u65b9\u6cd5\uff0c\u4e3a\u79d1\u5b66\u7f51\u5173\u5e94\u7528\u63d0\u4f9b\u66f4\u597d\u7684\u5b89\u5168\u4fdd\u969c\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u52a8\u6001\u8c03\u6574\u8d44\u6e90\u8bbf\u95ee\u6743\u9650\u7684\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.18168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18168", "abs": "https://arxiv.org/abs/2509.18168", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics", "comment": null, "summary": "Semantic parsing of long documents remains challenging due to quadratic\ngrowth in pairwise composition and memory requirements. We introduce\n\\textbf{Hierarchical Segment-Graph Memory (HSGM)}, a novel framework that\ndecomposes an input of length $N$ into $M$ meaningful segments, constructs\n\\emph{Local Semantic Graphs} on each segment, and extracts compact\n\\emph{summary nodes} to form a \\emph{Global Graph Memory}. HSGM supports\n\\emph{incremental updates} -- only newly arrived segments incur local graph\nconstruction and summary-node integration -- while \\emph{Hierarchical Query\nProcessing} locates relevant segments via top-$K$ retrieval over summary nodes\nand then performs fine-grained reasoning within their local graphs.\n  Theoretically, HSGM reduces worst-case complexity from $O(N^2)$ to\n$O\\!\\left(N\\,k + (N/k)^2\\right)$, with segment size $k \\ll N$, and we derive\nFrobenius-norm bounds on the approximation error introduced by node\nsummarization and sparsification thresholds. Empirically, on three benchmarks\n-- long-document AMR parsing, segment-level semantic role labeling (OntoNotes),\nand legal event extraction -- HSGM achieves \\emph{2--4$\\times$ inference\nspeedup}, \\emph{$>60\\%$ reduction} in peak memory, and \\emph{$\\ge 95\\%$} of\nbaseline accuracy. Our approach unlocks scalable, accurate semantic modeling\nfor ultra-long texts, enabling real-time and resource-constrained NLP\napplications.", "AI": {"tldr": "HSGM\u662f\u4e00\u79cd\u5206\u5c42\u5206\u6bb5\u56fe\u5185\u5b58\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u957f\u6587\u6863\u5206\u89e3\u4e3a\u6709\u610f\u4e49\u7684\u5206\u6bb5\uff0c\u6784\u5efa\u5c40\u90e8\u8bed\u4e49\u56fe\u5e76\u63d0\u53d6\u6458\u8981\u8282\u70b9\u6765\u5f62\u6210\u5168\u5c40\u56fe\u5185\u5b58\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u957f\u6587\u6863\u8bed\u4e49\u89e3\u6790\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u5185\u5b58\u9700\u6c42\u3002", "motivation": "\u957f\u6587\u6863\u8bed\u4e49\u89e3\u6790\u9762\u4e34\u4e8c\u6b21\u590d\u6742\u5ea6\u589e\u957f\u548c\u5185\u5b58\u9700\u6c42\u8fc7\u9ad8\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9ad8\u6548\u5904\u7406\u8d85\u957f\u6587\u672c\u7684\u8bed\u4e49\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "HSGM\u6846\u67b6\u5c06\u8f93\u5165\u6587\u6863\u5206\u89e3\u4e3aM\u4e2a\u5206\u6bb5\uff0c\u5728\u6bcf\u4e2a\u5206\u6bb5\u4e0a\u6784\u5efa\u5c40\u90e8\u8bed\u4e49\u56fe\uff0c\u63d0\u53d6\u6458\u8981\u8282\u70b9\u5f62\u6210\u5168\u5c40\u56fe\u5185\u5b58\uff0c\u652f\u6301\u589e\u91cf\u66f4\u65b0\u548c\u5206\u5c42\u67e5\u8be2\u5904\u7406\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHSGM\u5b9e\u73b0\u4e862-4\u500d\u7684\u63a8\u7406\u52a0\u901f\uff0c\u5cf0\u503c\u5185\u5b58\u51cf\u5c11\u8d85\u8fc760%\uff0c\u540c\u65f6\u4fdd\u6301\u57fa\u7ebf\u51c6\u786e\u7387\u768495%\u4ee5\u4e0a\u3002", "conclusion": "HSGM\u4e3a\u8d85\u957f\u6587\u672c\u7684\u53ef\u6269\u5c55\u3001\u51c6\u786e\u8bed\u4e49\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u5b9e\u65f6\u548c\u8d44\u6e90\u53d7\u9650\u7684NLP\u5e94\u7528\u3002"}}
{"id": "2509.18696", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.18696", "abs": "https://arxiv.org/abs/2509.18696", "authors": ["Xiaohui Yang", "Ping Ping", "Feng Xu"], "title": "FlowCrypt: Flow-Based Lightweight Encryption with Near-Lossless Recovery for Cloud Photo Privacy", "comment": null, "summary": "The widespread adoption of smartphone photography has led users to\nincreasingly rely on cloud storage for personal photo archiving and sharing,\nraising critical privacy concerns. Existing deep learning-based image\nencryption schemes, typically built upon CNNs or GANs, often depend on\ntraditional cryptographic algorithms and lack inherent architectural\nreversibility, resulting in limited recovery quality and poor robustness.\nInvertible neural networks (INNs) have emerged to address this issue by\nenabling reversible transformations, yet the first INN-based encryption scheme\nstill relies on an auxiliary reference image and discards by-product\ninformation before decryption, leading to degraded recovery and limited\npracticality. To address these limitations, this paper proposes FlowCrypt, a\nnovel flow-based image encryption framework that simultaneously achieves\nnear-lossless recovery, high security, and lightweight model design. FlowCrypt\nbegins by applying a key-conditioned random split to the input image, enhancing\nforward-process randomness and encryption strength. The resulting components\nare processed through a Flow-based Encryption/Decryption (FED) module composed\nof invertible blocks, which share parameters across encryption and decryption.\nThanks to its reversible architecture and reference-free design, FlowCrypt\nensures high-fidelity image recovery. Extensive experiments show that FlowCrypt\nachieves recovery quality with 100dB on three datasets, produces uniformly\ndistributed cipher images, and maintains a compact architecture with only 1M\nparameters, making it suitable for mobile and edge-device applications.", "AI": {"tldr": "FlowCrypt\u662f\u4e00\u79cd\u57fa\u4e8e\u6d41\u6a21\u578b\u7684\u65b0\u578b\u56fe\u50cf\u52a0\u5bc6\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u9006\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u8fd1\u65e0\u635f\u6062\u590d\u3001\u9ad8\u5b89\u5168\u6027\u548c\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\uff0c\u9002\u7528\u4e8e\u79fb\u52a8\u548c\u8fb9\u7f18\u8bbe\u5907\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u57fa\u4e8eCNN\u6216GAN\u7684\u56fe\u50cf\u52a0\u5bc6\u65b9\u6848\u4f9d\u8d56\u4f20\u7edf\u5bc6\u7801\u7b97\u6cd5\u3001\u7f3a\u4e4f\u56fa\u6709\u53ef\u9006\u6027\u5bfc\u81f4\u7684\u6062\u590d\u8d28\u91cf\u5dee\u548c\u9c81\u68d2\u6027\u5dee\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u9996\u4e2a\u57fa\u4e8eINN\u7684\u52a0\u5bc6\u65b9\u6848\u4ecd\u9700\u8f85\u52a9\u53c2\u8003\u56fe\u50cf\u548c\u4e22\u5f03\u526f\u4ea7\u54c1\u4fe1\u606f\u5bfc\u81f4\u7684\u6062\u590d\u8d28\u91cf\u4e0b\u964d\u548c\u5b9e\u7528\u6027\u6709\u9650\u7684\u95ee\u9898\u3002", "method": "FlowCrypt\u91c7\u7528\u57fa\u4e8e\u6d41\u7684\u56fe\u50cf\u52a0\u5bc6\u6846\u67b6\uff0c\u9996\u5148\u5bf9\u8f93\u5165\u56fe\u50cf\u8fdb\u884c\u5bc6\u94a5\u6761\u4ef6\u968f\u673a\u5206\u5272\u4ee5\u589e\u5f3a\u524d\u5411\u8fc7\u7a0b\u968f\u673a\u6027\u548c\u52a0\u5bc6\u5f3a\u5ea6\uff0c\u7136\u540e\u901a\u8fc7\u7531\u53ef\u9006\u5757\u7ec4\u6210\u7684\u6d41\u57fa\u52a0\u5bc6/\u89e3\u5bc6\u6a21\u5757\u5904\u7406\u5206\u5272\u540e\u7684\u7ec4\u4ef6\uff0c\u8be5\u6a21\u5757\u5728\u52a0\u5bc6\u548c\u89e3\u5bc6\u8fc7\u7a0b\u4e2d\u5171\u4eab\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFlowCrypt\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0100dB\u7684\u6062\u590d\u8d28\u91cf\uff0c\u4ea7\u751f\u5747\u5300\u5206\u5e03\u7684\u5bc6\u6587\u56fe\u50cf\uff0c\u5e76\u4fdd\u6301\u4ec51M\u53c2\u6570\u7684\u7d27\u51d1\u67b6\u6784\u3002", "conclusion": "FlowCrypt\u901a\u8fc7\u5176\u53ef\u9006\u67b6\u6784\u548c\u65e0\u53c2\u8003\u8bbe\u8ba1\u786e\u4fdd\u4e86\u9ad8\u4fdd\u771f\u56fe\u50cf\u6062\u590d\uff0c\u9002\u7528\u4e8e\u79fb\u52a8\u548c\u8fb9\u7f18\u8bbe\u5907\u5e94\u7528\u3002"}}
{"id": "2509.18808", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18808", "abs": "https://arxiv.org/abs/2509.18808", "authors": ["Zexun Zhan", "Shuzheng Gao", "Ruida Hu", "Cuiyun Gao"], "title": "SR-Eval: Evaluating LLMs on Code Generation under Stepwise Requirement Refinement", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable progress in code\ngeneration. However, existing benchmarks mainly formalize the task as a static,\nsingle-turn problem, overlooking the stepwise requirement changes and iterative\nworkflows in real-world software development. This mismatch limits the\nunderstanding of how well LLMs can support real-world development workflows.\nConstructing such iterative benchmarks is challenging due to the lack of public\ninteraction traces and the difficulty of creating discriminative, turn-specific\ntest cases.\n  To bridge this gap, we present SR-Eval, a benchmark specifically designed to\nassess LLMs on iterative code generation under Stepwise requirements\nRefinement. SR-Eval spans both function-level and repository-level tasks in\nPython and Java, enabling fine-grained and progressive evaluation across\nevolving requirements. The construction of SR-Eval follows a carefully designed\npipeline that first leverages a multi-agent-based requirement generation method\nto simulate the development process and recover the multi-round interaction\nprocess from final requirements, then employs a semantic-aware discriminative\ntest case generation component to ensure discriminative and consistent\nevaluation at each turn. SR-Eval comprises 443 multi-turn tasks and 1,857\nquestions at both function and repository levels. Using SR-Eval, we evaluate 11\nrepresentative LLMs with three prompting strategies that simulate different\nusage patterns. Results show that iterative code generation under stepwise\nrequirement refinement remains highly challenging: the best-performing model\nachieves only 22.67% completion rate on function-level tasks and 20.00% on\nrepository-level tasks. We further observe that prompting strategies\nsubstantially influence performance, highlighting the need for the development\nof advanced methods.", "AI": {"tldr": "SR-Eval\u662f\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30LLMs\u5728\u9010\u6b65\u9700\u6c42\u7ec6\u5316\u4e0b\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u51fd\u6570\u7ea7\u548c\u4ed3\u5e93\u7ea7\u4efb\u52a1\uff0c\u7ed3\u679c\u663e\u793a\u5f53\u524d\u6700\u4f73\u6a21\u578b\u5b8c\u6210\u7387\u4ec5\u4e3a22.67%\uff08\u51fd\u6570\u7ea7\uff09\u548c20.00%\uff08\u4ed3\u5e93\u7ea7\uff09\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5c06\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3a\u9759\u6001\u3001\u5355\u8f6e\u95ee\u9898\uff0c\u5ffd\u7565\u4e86\u73b0\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u9010\u6b65\u9700\u6c42\u53d8\u5316\u548c\u8fed\u4ee3\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8fd9\u79cd\u4e0d\u5339\u914d\u9650\u5236\u4e86\u5bf9LLMs\u652f\u6301\u771f\u5b9e\u5f00\u53d1\u6d41\u7a0b\u80fd\u529b\u7684\u7406\u89e3\u3002", "method": "SR-Eval\u91c7\u7528\u591a\u667a\u80fd\u4f53\u9700\u6c42\u751f\u6210\u65b9\u6cd5\u6a21\u62df\u5f00\u53d1\u8fc7\u7a0b\uff0c\u4ece\u6700\u7ec8\u9700\u6c42\u4e2d\u6062\u590d\u591a\u8f6e\u4ea4\u4e92\u8fc7\u7a0b\uff0c\u5e76\u4f7f\u7528\u8bed\u4e49\u611f\u77e5\u7684\u5224\u522b\u6027\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u7ec4\u4ef6\u786e\u4fdd\u6bcf\u8f6e\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\u548c\u5224\u522b\u6027\u3002", "result": "\u8bc4\u4f3011\u4e2a\u4ee3\u8868\u6027LLMs\u548c\u4e09\u79cd\u63d0\u793a\u7b56\u7565\uff0c\u7ed3\u679c\u663e\u793a\u9010\u6b65\u9700\u6c42\u7ec6\u5316\u4e0b\u7684\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u4ecd\u7136\u6781\u5177\u6311\u6218\u6027\uff0c\u6700\u4f73\u6a21\u578b\u5b8c\u6210\u7387\u8f83\u4f4e\uff0c\u4e14\u63d0\u793a\u7b56\u7565\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u5728\u9010\u6b65\u9700\u6c42\u7ec6\u5316\u4e0b\u4ecd\u7136\u662f\u4e00\u4e2a\u9ad8\u5ea6\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5148\u8fdb\u7684\u65b9\u6cd5\u6765\u63d0\u5347LLMs\u5728\u6b64\u7c7b\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002"}}
{"id": "2509.18178", "categories": ["cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18178", "abs": "https://arxiv.org/abs/2509.18178", "authors": ["Ling Yue", "Nithin Somasekharan", "Tingwen Zhang", "Yadi Cao", "Shaowu Pan"], "title": "Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM", "comment": null, "summary": "Computational Fluid Dynamics (CFD) is an essential simulation tool in\nengineering, yet its steep learning curve and complex manual setup create\nsignificant barriers. To address these challenges, we introduce Foam-Agent, a\nmulti-agent framework that automates the entire end-to-end OpenFOAM workflow\nfrom a single natural language prompt. Our key innovations address critical\ngaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation:\nFoam-Agent is the first system to manage the full simulation pipeline,\nincluding advanced pre-processing with a versatile Meshing Agent capable of\nhandling external mesh files and generating new geometries via Gmsh, automatic\ngeneration of HPC submission scripts, and post-simulation visualization via\nParaView. 2. Composable Service Architecture: Going beyond a monolithic agent,\nthe framework uses Model Context Protocol (MCP) to expose its core functions as\ndiscrete, callable tools. This allows for flexible integration and use by other\nagentic systems, such as Claude-code, for more exploratory workflows. 3.\nHigh-Fidelity Configuration Generation: We achieve superior accuracy through a\nHierarchical Multi-Index RAG for precise context retrieval and a\ndependency-aware generation process that ensures configuration consistency.\nEvaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2%\nsuccess rate with Claude 3.5 Sonnet, significantly outperforming existing\nframeworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the\nexpertise barrier for CFD, demonstrating how specialized multi-agent systems\ncan democratize complex scientific computing. The code is public at\nhttps://github.com/csml-rpi/Foam-Agent.", "AI": {"tldr": "Foam-Agent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u81ea\u52a8\u5316\u6574\u4e2aOpenFOAM CFD\u4eff\u771f\u6d41\u7a0b\uff0c\u5305\u62ec\u7f51\u683c\u751f\u6210\u3001HPC\u811a\u672c\u521b\u5efa\u548c\u540e\u5904\u7406\u53ef\u89c6\u5316\uff0c\u663e\u8457\u964d\u4f4e\u4e86CFD\u7684\u4f7f\u7528\u95e8\u69db\u3002", "motivation": "CFD\u4eff\u771f\u7684\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u4e14\u8bbe\u7f6e\u590d\u6742\uff0c\u73b0\u6709\u7cfb\u7edf\u65e0\u6cd5\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\uff0c\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u548c\u5927\u91cf\u624b\u52a8\u64cd\u4f5c\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u4f7f\u7528Model Context Protocol\u66b4\u9732\u6838\u5fc3\u529f\u80fd\u4e3a\u53ef\u8c03\u7528\u5de5\u5177\uff0c\u901a\u8fc7\u5206\u5c42\u591a\u7d22\u5f15RAG\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u914d\u7f6e\u751f\u6210\uff0c\u5305\u542b\u7f51\u683c\u751f\u6210\u3001HPC\u811a\u672c\u81ea\u52a8\u751f\u6210\u548c\u53ef\u89c6\u5316\u540e\u5904\u7406\u7b49\u6a21\u5757\u3002", "result": "\u5728110\u4e2a\u4eff\u771f\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528Claude 3.5 Sonnet\u8fbe\u523088.2%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\uff08MetaOpenFOAM\u4e3a55.5%\uff09\u3002", "conclusion": "Foam-Agent\u6709\u6548\u964d\u4f4e\u4e86CFD\u7684\u4e13\u4e1a\u95e8\u69db\uff0c\u5c55\u793a\u4e86\u4e13\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5982\u4f55\u6c11\u4e3b\u5316\u590d\u6742\u79d1\u5b66\u8ba1\u7b97\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2509.18761", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18761", "abs": "https://arxiv.org/abs/2509.18761", "authors": ["Aicha War", "Serge L. B. Nikiema", "Jordan Samhi", "Jacques Klein", "Tegawende F. Bissyande"], "title": "Security smells in infrastructure as code: a taxonomy update beyond the seven sins", "comment": null, "summary": "Infrastructure as Code (IaC) has become essential for modern software\nmanagement, yet security flaws in IaC scripts can have severe consequences, as\nexemplified by the recurring exploits of Cloud Web Services. Prior work has\nrecognized the need to build a precise taxonomy of security smells in IaC\nscripts as a first step towards developing approaches to improve IaC security.\nThis first effort led to the unveiling of seven sins, limited by the focus on a\nsingle IaC tool as well as by the extensive, and potentially biased, manual\neffort that was required. We propose, in our work, to revisit this taxonomy:\nfirst, we extend the study of IaC security smells to a more diverse dataset\nwith scripts associated with seven popular IaC tools, including Terraform,\nAnsible, Chef, Puppet, Pulumi, Saltstack, and Vagrant; second, we bring in some\nautomation for the analysis by relying on an LLM. While we leverage LLMs for\ninitial pattern processing, all taxonomic decisions underwent systematic human\nvalidation and reconciliation with established security standards. Our study\nyields a comprehensive taxonomy of 62 security smell categories, significantly\nexpanding beyond the previously known seven. We demonstrate actionability by\nimplementing new security checking rules within linters for seven popular IaC\ntools, often achieving 1.00 precision score. Our evolution study of security\nsmells in GitHub projects reveals that these issues persist for extended\nperiods, likely due to inadequate detection and mitigation tools. This work\nprovides IaC practitioners with insights for addressing common security smells\nand systematically adopting DevSecOps practices to build safer infrastructure\ncode.", "AI": {"tldr": "\u672c\u7814\u7a76\u91cd\u65b0\u5ba1\u89c6\u4e86\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\uff08IaC\uff09\u5b89\u5168\u6c14\u5473\u7684\u5206\u7c7b\u6cd5\uff0c\u901a\u8fc7\u6269\u5c55\u6570\u636e\u96c6\u52307\u79cd\u6d41\u884cIaC\u5de5\u5177\u5e76\u5f15\u5165LLM\u8f85\u52a9\u5206\u6790\uff0c\u6784\u5efa\u4e86\u5305\u542b62\u4e2a\u5b89\u5168\u6c14\u5473\u7c7b\u522b\u7684\u5168\u9762\u5206\u7c7b\u6cd5\uff0c\u663e\u8457\u8d85\u8d8a\u4e86\u4e4b\u524d\u76847\u4e2a\u7c7b\u522b\u3002", "motivation": "\u73b0\u6709IaC\u5b89\u5168\u6c14\u5473\u5206\u7c7b\u6cd5\u5c40\u9650\u4e8e\u5355\u4e00\u5de5\u5177\u4e14\u4f9d\u8d56\u5927\u91cf\u4eba\u5de5\u5206\u6790\uff0c\u5b58\u5728\u6f5c\u5728\u504f\u89c1\u3002\u9700\u8981\u66f4\u5168\u9762\u7684\u5206\u7c7b\u6765\u652f\u6301IaC\u5b89\u5168\u6539\u8fdb\u65b9\u6cd5\u7684\u53d1\u5c55\u3002", "method": "\u6269\u5c55\u7814\u7a76\u52307\u79cd\u6d41\u884cIaC\u5de5\u5177\uff08Terraform\u3001Ansible\u7b49\uff09\uff0c\u5229\u7528LLM\u8fdb\u884c\u521d\u6b65\u6a21\u5f0f\u5904\u7406\uff0c\u6240\u6709\u5206\u7c7b\u51b3\u7b56\u90fd\u7ecf\u8fc7\u7cfb\u7edf\u5316\u4eba\u5de5\u9a8c\u8bc1\u5e76\u4e0e\u5b89\u5168\u6807\u51c6\u5bf9\u9f50\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b62\u4e2a\u5b89\u5168\u6c14\u5473\u7c7b\u522b\u7684\u5168\u9762\u5206\u7c7b\u6cd5\uff0c\u4e3a7\u79cdIaC\u5de5\u5177\u5b9e\u73b0\u4e86\u65b0\u7684\u5b89\u5168\u68c0\u67e5\u89c4\u5219\uff0c\u7cbe\u5ea6\u5e38\u8fbe\u52301.00\u3002GitHub\u9879\u76ee\u7814\u7a76\u8868\u660e\u8fd9\u4e9b\u5b89\u5168\u95ee\u9898\u957f\u671f\u5b58\u5728\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aIaC\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u89e3\u51b3\u5e38\u89c1\u5b89\u5168\u6c14\u5473\u548c\u7cfb\u7edf\u91c7\u7528DevSecOps\u5b9e\u8df5\u7684\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u5b89\u5168\u7684\u57fa\u7840\u8bbe\u65bd\u4ee3\u7801\u3002"}}
{"id": "2509.19136", "categories": ["cs.SE", "cs.AI", "D.2.4; D.2.5; F.3.1"], "pdf": "https://arxiv.org/pdf/2509.19136", "abs": "https://arxiv.org/abs/2509.19136", "authors": ["S\u00e9bastien Salva", "Redha Taguelmimt"], "title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "comment": null, "summary": "The use of natural language (NL) test cases for validating graphical user\ninterface (GUI) applications is emerging as a promising direction to manually\nwritten executable test scripts, which are costly to develop and difficult to\nmaintain. Recent advances in large language models (LLMs) have opened the\npossibility of the direct execution of NL test cases by LLM agents. This paper\ninvestigates this direction, focusing on the impact on NL test case unsoundness\nand on test case execution consistency. NL test cases are inherently unsound,\nas they may yield false failures due to ambiguous instructions or unpredictable\nagent behaviour. Furthermore, repeated executions of the same NL test case may\nlead to inconsistent outcomes, undermining test reliability. To address these\nchallenges, we propose an algorithm for executing NL test cases with guardrail\nmechanisms and specialised agents that dynamically verify the correct execution\nof each test step. We introduce measures to evaluate the capabilities of LLMs\nin test execution and one measure to quantify execution consistency. We propose\na definition of weak unsoundness to characterise contexts in which NL test case\nexecution remains acceptable, with respect to the industrial quality levels Six\nSigma. Our experimental evaluation with eight publicly available LLMs, ranging\nfrom 3B to 70B parameters, demonstrates both the potential and current\nlimitations of current LLM agents for GUI testing. Our experiments show that\nMeta Llama 3.1 70B demonstrates acceptable capabilities in NL test case\nexecution with high execution consistency (above the level 3-sigma). We provide\nprototype tools, test suites, and results.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u6267\u884c\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u8fdb\u884cGUI\u6d4b\u8bd5\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u9632\u62a4\u673a\u5236\u548c\u4e13\u95e8\u4ee3\u7406\u6765\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u7684\u4e0d\u5065\u5168\u6027\u548c\u6267\u884c\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e868\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684LLM\u5728\u6d4b\u8bd5\u6267\u884c\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u7684\u624b\u5199\u53ef\u6267\u884c\u6d4b\u8bd5\u811a\u672c\u5f00\u53d1\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u7ef4\u62a4\uff0c\u800c\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u7ed3\u5408LLM\u76f4\u63a5\u6267\u884cGUI\u6d4b\u8bd5\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u4f46\u5b58\u5728\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u4e0d\u5065\u5168\u548c\u6267\u884c\u4e0d\u4e00\u81f4\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5e26\u6709\u9632\u62a4\u673a\u5236\u7684\u7b97\u6cd5\uff0c\u4f7f\u7528\u4e13\u95e8\u4ee3\u7406\u52a8\u6001\u9a8c\u8bc1\u6bcf\u4e2a\u6d4b\u8bd5\u6b65\u9aa4\u7684\u6b63\u786e\u6267\u884c\uff0c\u5f15\u5165\u4e86\u8bc4\u4f30LLM\u6d4b\u8bd5\u6267\u884c\u80fd\u529b\u7684\u6307\u6807\u548c\u6267\u884c\u4e00\u81f4\u6027\u7684\u91cf\u5316\u65b9\u6cd5\uff0c\u5e76\u5b9a\u4e49\u4e86\u5f31\u4e0d\u5065\u5168\u6027\u6982\u5ff5\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u4e868\u4e2a\u4ece3B\u523070B\u53c2\u6570\u7684\u516c\u5f00LLM\uff0c\u7ed3\u679c\u663e\u793aMeta Llama 3.1 70B\u5728\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u6267\u884c\u4e2d\u8868\u73b0\u51fa\u53ef\u63a5\u53d7\u7684\u80fd\u529b\uff0c\u6267\u884c\u4e00\u81f4\u6027\u9ad8\u4e8e3-sigma\u6c34\u5e73\u3002", "conclusion": "LLM\u4ee3\u7406\u5728GUI\u6d4b\u8bd5\u4e2d\u5177\u6709\u6f5c\u529b\u4f46\u4ecd\u6709\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u8bc4\u4f30\u6307\u6807\u4e3a\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u3002"}}
{"id": "2509.18180", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18180", "abs": "https://arxiv.org/abs/2509.18180", "authors": ["Yang Wang", "Kai Li"], "title": "Large Language Models and Operations Research: A Structured Survey", "comment": null, "summary": "Operations research (OR) provides fundamental methodologies for complex\nsystem decision-making, with established applications in transportation, supply\nchain management, and production scheduling. Traditional approaches, which\ndepend on expert-based modeling and manual parameter adjustment, often face\nchallenges in handling large-scale, dynamic, and multi-constraint problems.\nRecently, large language models (LLMs) have shown potential to address these\nlimitations through semantic understanding, structured generation, and\nreasoning control. LLMs can translate natural language descriptions into\nmathematical models or executable code, generate heuristics, evolve algorithms,\nand directly tackle optimization tasks. This paper surveys recent progress on\nthe integration of LLMs into OR, organizing methods into three main directions:\nautomatic modeling, auxiliary optimization, and direct solving. It further\nreviews evaluation benchmarks and domain-specific applications, and summarizes\nkey open issues such as unstable semantic-to-structure mapping, fragmented\nresearch progress, limited generalization, and insufficient evaluation systems.\nFinally, the survey outlines possible research avenues for advancing the role\nof LLMs in OR.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8fd0\u7b79\u5b66\u4e2d\u7684\u5e94\u7528\u8fdb\u5c55\uff0c\u4e3b\u8981\u6db5\u76d6\u81ea\u52a8\u5efa\u6a21\u3001\u8f85\u52a9\u4f18\u5316\u548c\u76f4\u63a5\u6c42\u89e3\u4e09\u4e2a\u65b9\u5411\uff0c\u5e76\u8ba8\u8bba\u4e86\u5f53\u524d\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u8fd0\u7b79\u5b66\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u5efa\u6a21\u548c\u624b\u52a8\u53c2\u6570\u8c03\u6574\uff0c\u96be\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u3001\u52a8\u6001\u548c\u591a\u7ea6\u675f\u95ee\u9898\u3002LLMs\u901a\u8fc7\u8bed\u4e49\u7406\u89e3\u3001\u7ed3\u6784\u5316\u751f\u6210\u548c\u63a8\u7406\u63a7\u5236\u663e\u793a\u51fa\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u7684\u6f5c\u529b\u3002", "method": "\u5c06LLMs\u4e0eOR\u96c6\u6210\u7684\u65b9\u6cd5\u5206\u4e3a\u4e09\u7c7b\uff1a\u81ea\u52a8\u5efa\u6a21\uff08\u5c06\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u8f6c\u6362\u4e3a\u6570\u5b66\u6a21\u578b\u6216\u53ef\u6267\u884c\u4ee3\u7801\uff09\u3001\u8f85\u52a9\u4f18\u5316\uff08\u751f\u6210\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u6f14\u5316\u7b97\u6cd5\uff09\u3001\u76f4\u63a5\u6c42\u89e3\u4f18\u5316\u4efb\u52a1\u3002", "result": "LLMs\u80fd\u591f\u6709\u6548\u63d0\u5347OR\u95ee\u9898\u7684\u5904\u7406\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7cfb\u7edf\u51b3\u7b56\u652f\u6301\u65b9\u9762\u3002\u4f46\u5b58\u5728\u8bed\u4e49\u5230\u7ed3\u6784\u6620\u5c04\u4e0d\u7a33\u5b9a\u3001\u7814\u7a76\u8fdb\u5c55\u788e\u7247\u5316\u3001\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7b49\u6311\u6218\u3002", "conclusion": "LLMs\u5728OR\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u524d\u666f\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u89e3\u51b3\u73b0\u6709\u6311\u6218\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.18790", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18790", "abs": "https://arxiv.org/abs/2509.18790", "authors": ["Aicha War", "Adnan A. Rawass", "Abdoul K. Kabore", "Jordan Samhi", "Jacques Klein", "Tegawende F. Bissyande"], "title": "Detection of security smells in IaC scripts through semantics-aware code and language processing", "comment": null, "summary": "Infrastructure as Code (IaC) automates the provisioning and management of IT\ninfrastructure through scripts and tools, streamlining software deployment.\nPrior studies have shown that IaC scripts often contain recurring security\nmisconfigurations, and several detection and mitigation approaches have been\nproposed. Most of these rely on static analysis, using statistical code\nrepresentations or Machine Learning (ML) classifiers to distinguish insecure\nconfigurations from safe code.\n  In this work, we introduce a novel approach that enhances static analysis\nwith semantic understanding by jointly leveraging natural language and code\nrepresentations. Our method builds on two complementary ML models: CodeBERT, to\ncapture semantics across code and text, and LongFormer, to represent long IaC\nscripts without losing contextual information. We evaluate our approach on\nmisconfiguration datasets from two widely used IaC tools, Ansible and Puppet.\nTo validate its effectiveness, we conduct two ablation studies (removing code\ntext from the natural language input and truncating scripts to reduce context)\nand compare against four large language models (LLMs) and prior work. Results\nshow that semantic enrichment substantially improves detection, raising\nprecision and recall from 0.46 and 0.79 to 0.92 and 0.88 on Ansible, and from\n0.55 and 0.97 to 0.87 and 0.75 on Puppet, respectively.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u548c\u4ee3\u7801\u8868\u793a\u7684\u8bed\u4e49\u589e\u5f3a\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\uff08IaC\uff09\u811a\u672c\u4e2d\u7684\u5b89\u5168\u9519\u8bef\u914d\u7f6e\uff0c\u76f8\u6bd4\u4f20\u7edf\u9759\u6001\u5206\u6790\u65b9\u6cd5\u5728\u7cbe\u786e\u5ea6\u548c\u53ec\u56de\u7387\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684IaC\u5b89\u5168\u9519\u8bef\u914d\u7f6e\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u5206\u6790\uff0c\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u548c\u4ee3\u7801\u7684\u8bed\u4e49\u4fe1\u606f\u6765\u63d0\u9ad8\u68c0\u6d4b\u6548\u679c\u3002", "method": "\u4f7f\u7528CodeBERT\u6355\u83b7\u4ee3\u7801\u548c\u6587\u672c\u7684\u8bed\u4e49\u4fe1\u606f\uff0cLongFormer\u5904\u7406\u957f\u811a\u672c\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5728\u4e24\u4e2a\u4e3b\u6d41IaC\u5de5\u5177\uff08Ansible\u548cPuppet\uff09\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bed\u4e49\u589e\u5f3a\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u6027\u80fd\uff1a\u5728Ansible\u4e0a\u7cbe\u786e\u5ea6\u4ece0.46\u63d0\u5347\u52300.92\uff0c\u53ec\u56de\u7387\u4ece0.79\u63d0\u5347\u52300.88\uff1b\u5728Puppet\u4e0a\u7cbe\u786e\u5ea6\u4ece0.55\u63d0\u5347\u52300.87\uff0c\u53ec\u56de\u7387\u4ece0.97\u63d0\u5347\u52300.75\u3002", "conclusion": "\u8bed\u4e49\u7406\u89e3\u80fd\u591f\u6709\u6548\u589e\u5f3aIaC\u811a\u672c\u5b89\u5168\u9519\u8bef\u914d\u7f6e\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u8be5\u65b9\u6cd5\u5728\u7cbe\u786e\u5ea6\u548c\u53ec\u56de\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u9759\u6001\u5206\u6790\u65b9\u6cd5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2509.19185", "categories": ["cs.SE", "cs.ET"], "pdf": "https://arxiv.org/pdf/2509.19185", "abs": "https://arxiv.org/abs/2509.19185", "authors": ["Mohammed Mehedi Hasan", "Hao Li", "Emad Fallahzadeh", "Gopi Krishnan Rajbahadur", "Bram Adams", "Ahmed E. Hassan"], "title": "An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications", "comment": null, "summary": "Foundation model (FM)-based AI agents are rapidly gaining adoption across\ndiverse domains, but their inherent non-determinism and non-reproducibility\npose testing and quality assurance challenges. While recent benchmarks provide\ntask-level evaluations, there is limited understanding of how developers verify\nthe internal correctness of these agents during development.\n  To address this gap, we conduct the first large-scale empirical study of\ntesting practices in the AI agent ecosystem, analyzing 39 open-source agent\nframeworks and 439 agentic applications. We identify ten distinct testing\npatterns and find that novel, agent-specific methods like DeepEval are seldom\nused (around 1%), while traditional patterns like negative and membership\ntesting are widely adapted to manage FM uncertainty. By mapping these patterns\nto canonical architectural components of agent frameworks and agentic\napplications, we uncover a fundamental inversion of testing effort:\ndeterministic components like Resource Artifacts (tools) and Coordination\nArtifacts (workflows) consume over 70% of testing effort, while the FM-based\nPlan Body receives less than 5%. Crucially, this reveals a critical blind spot,\nas the Trigger component (prompts) remains neglected, appearing in around 1% of\nall tests.\n  Our findings offer the first empirical testing baseline in FM-based agent\nframeworks and agentic applications, revealing a rational but incomplete\nadaptation to non-determinism. To address it, framework developers should\nimprove support for novel testing methods, application developers must adopt\nprompt regression testing, and researchers should explore barriers to adoption.\nStrengthening these practices is vital for building more robust and dependable\nAI agents.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684AI\u4ee3\u7406\u6d4b\u8bd5\u5b9e\u8df5\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u4ecd\u5360\u4e3b\u5bfc\uff0c\u800c\u4ee3\u7406\u7279\u5b9a\u7684\u65b0\u65b9\u6cd5\u4f7f\u7528\u7387\u6781\u4f4e\uff0c\u6d4b\u8bd5\u52aa\u529b\u5b58\u5728\u4e25\u91cd\u4e0d\u5e73\u8861\uff0c\u7279\u522b\u662f\u63d0\u793a\u7ec4\u4ef6\u88ab\u5ffd\u89c6\u3002", "motivation": "\u57fa\u7840\u6a21\u578bAI\u4ee3\u7406\u7684\u975e\u786e\u5b9a\u6027\u548c\u4e0d\u53ef\u91cd\u73b0\u6027\u7ed9\u6d4b\u8bd5\u548c\u8d28\u91cf\u4fdd\u8bc1\u5e26\u6765\u6311\u6218\uff0c\u4f46\u5f00\u53d1\u8005\u5728\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u5982\u4f55\u9a8c\u8bc1\u8fd9\u4e9b\u4ee3\u7406\u5185\u90e8\u6b63\u786e\u6027\u7684\u7406\u89e3\u6709\u9650\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5206\u6790\u4e8639\u4e2a\u5f00\u6e90\u4ee3\u7406\u6846\u67b6\u548c439\u4e2a\u4ee3\u7406\u5e94\u7528\uff0c\u8bc6\u522b\u4e86\u5341\u79cd\u4e0d\u540c\u7684\u6d4b\u8bd5\u6a21\u5f0f\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6a21\u5f0f\u6620\u5c04\u5230\u4ee3\u7406\u6846\u67b6\u548c\u5e94\u7528\u7684\u89c4\u8303\u67b6\u6784\u7ec4\u4ef6\u4e2d\u3002", "result": "\u53d1\u73b0\u786e\u5b9a\u6027\u7ec4\u4ef6\u6d88\u8017\u4e86\u8d85\u8fc770%\u7684\u6d4b\u8bd5\u52aa\u529b\uff0c\u800c\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u8ba1\u5212\u4e3b\u4f53\u4ec5\u83b7\u5f97\u4e0d\u52305%\u7684\u6d4b\u8bd5\uff0c\u89e6\u53d1\u7ec4\u4ef6\uff08\u63d0\u793a\uff09\u51e0\u4e4e\u88ab\u5ffd\u89c6\uff08\u7ea61%\uff09\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u6d4b\u8bd5\u5b9e\u8df5\u7684\u4e0d\u5b8c\u6574\u9002\u5e94\uff0c\u5efa\u8bae\u6846\u67b6\u5f00\u53d1\u8005\u6539\u8fdb\u5bf9\u65b0\u6d4b\u8bd5\u65b9\u6cd5\u7684\u652f\u6301\uff0c\u5e94\u7528\u5f00\u53d1\u8005\u91c7\u7528\u63d0\u793a\u56de\u5f52\u6d4b\u8bd5\uff0c\u7814\u7a76\u8005\u63a2\u7d22\u91c7\u7528\u969c\u788d\uff0c\u4ee5\u6784\u5efa\u66f4\u7a33\u5065\u53ef\u9760\u7684AI\u4ee3\u7406\u3002"}}
{"id": "2509.18181", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18181", "abs": "https://arxiv.org/abs/2509.18181", "authors": ["Mustafa Sameen", "Xiaojian Zhang", "Xilei Zhao"], "title": "Synthesizing Attitudes, Predicting Actions (SAPA): Behavioral Theory-Guided LLMs for Ridesourcing Mode Choice Modeling", "comment": null, "summary": "Accurate modeling of ridesourcing mode choices is essential for designing and\nimplementing effective traffic management policies for reducing congestion,\nimproving mobility, and allocating resources more efficiently. Existing models\nfor predicting ridesourcing mode choices often suffer from limited predictive\naccuracy due to their inability to capture key psychological factors, and are\nfurther challenged by severe class imbalance, as ridesourcing trips comprise\nonly a small fraction of individuals' daily travel. To address these\nlimitations, this paper introduces the Synthesizing Attitudes, Predicting\nActions (SAPA) framework, a hierarchical approach that uses Large Language\nModels (LLMs) to synthesize theory-grounded latent attitudes to predict\nridesourcing choices. SAPA first uses an LLM to generate qualitative traveler\npersonas from raw travel survey data and then trains a propensity-score model\non demographic and behavioral features, enriched by those personas, to produce\nan individual-level score. Next, the LLM assigns quantitative scores to\ntheory-driven latent variables (e.g., time and cost sensitivity), and a final\nclassifier integrates the propensity score, latent-variable scores (with their\ninteraction terms), and observable trip attributes to predict ridesourcing mode\nchoice. Experiments on a large-scale, multi-year travel survey show that SAPA\nsignificantly outperforms state-of-the-art baselines, improving ridesourcing\nchoice predictions by up to 75.9% in terms of PR-AUC on a held-out test set.\nThis study provides a powerful tool for accurately predicting ridesourcing mode\nchoices, and provides a methodology that is readily transferable to various\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SAPA\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5408\u6210\u7406\u8bba\u9a71\u52a8\u7684\u6f5c\u5728\u6001\u5ea6\u6765\u9884\u6d4b\u7f51\u7ea6\u8f66\u9009\u62e9\u6a21\u5f0f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u56e0\u5ffd\u7565\u5fc3\u7406\u56e0\u7d20\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u5bfc\u81f4\u7684\u9884\u6d4b\u7cbe\u5ea6\u4e0d\u8db3\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7f51\u7ea6\u8f66\u9009\u62e9\u9884\u6d4b\u6a21\u578b\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\uff1a\u4e00\u662f\u65e0\u6cd5\u6355\u6349\u5173\u952e\u5fc3\u7406\u56e0\u7d20\u5bfc\u81f4\u9884\u6d4b\u7cbe\u5ea6\u6709\u9650\uff1b\u4e8c\u662f\u9762\u4e34\u4e25\u91cd\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff08\u7f51\u7ea6\u8f66\u51fa\u884c\u4ec5\u5360\u65e5\u5e38\u51fa\u884c\u7684\u5f88\u5c0f\u6bd4\u4f8b\uff09\u3002", "method": "SAPA\u91c7\u7528\u5206\u5c42\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528LLM\u4ece\u539f\u59cb\u51fa\u884c\u8c03\u67e5\u6570\u636e\u751f\u6210\u5b9a\u6027\u65c5\u884c\u8005\u753b\u50cf\uff1b2\uff09\u57fa\u4e8e\u4eba\u53e3\u7edf\u8ba1\u548c\u884c\u4e3a\u7279\u5f81\u8bad\u7ec3\u503e\u5411\u5f97\u5206\u6a21\u578b\uff1b3\uff09LLM\u4e3a\u7406\u8bba\u9a71\u52a8\u7684\u6f5c\u5728\u53d8\u91cf\u5206\u914d\u5b9a\u91cf\u5206\u6570\uff1b4\uff09\u6700\u7ec8\u5206\u7c7b\u5668\u6574\u5408\u503e\u5411\u5f97\u5206\u3001\u6f5c\u5728\u53d8\u91cf\u5206\u6570\u548c\u53ef\u89c2\u5bdf\u51fa\u884c\u5c5e\u6027\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5728\u5927\u89c4\u6a21\u591a\u5e74\u51fa\u884c\u8c03\u67e5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSAPA\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684PR-AUC\u6307\u6807\u4e0a\uff0c\u7f51\u7ea6\u8f66\u9009\u62e9\u9884\u6d4b\u6027\u80fd\u63d0\u5347\u4e86\u9ad8\u8fbe75.9%\u3002", "conclusion": "SAPA\u4e3a\u51c6\u786e\u9884\u6d4b\u7f51\u7ea6\u8f66\u9009\u62e9\u6a21\u5f0f\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\uff0c\u5176\u65b9\u6cd5\u8bba\u53ef\u8f7b\u677e\u8fc1\u79fb\u5230\u5404\u79cd\u5e94\u7528\u4e2d\uff0c\u4e3a\u4ea4\u901a\u7ba1\u7406\u653f\u7b56\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u652f\u6301\u3002"}}
{"id": "2509.18800", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18800", "abs": "https://arxiv.org/abs/2509.18800", "authors": ["Alioune Diallo", "Anta Diop", "Abdoul Kader Kabore", "Jordan Samhi", "Aleksandr Pilgun", "Tegawend\u00e9 F. Bissyande", "Jacque Klein"], "title": "Security Evaluation of Android apps in budget African Mobile Devices", "comment": "13 pages, 3 figures, submitted (wating for notification)", "summary": "Android's open-source nature facilitates widespread smartphone accessibility,\nparticularly in price-sensitive markets. System and vendor applications that\ncome pre-installed on budget Android devices frequently operate with elevated\nprivileges, yet they receive limited independent examination. To address this\ngap, we developed a framework that extracts APKs from physical devices and\napplies static analysis to identify privacy and security issues in embedded\nsoftware. Our study examined 1,544 APKs collected from seven African\nsmartphones. The analysis revealed that 145 applications (9%) disclose\nsensitive data, 249 (16%) expose critical components without sufficient\nsafeguards, and many present additional risks: 226 execute privileged or\ndangerous commands, 79 interact with SMS messages (read, send, or delete), and\n33 perform silent installation operations. We also uncovered a vendor-supplied\npackage that appears to transmit device identifiers and location details to an\nexternal third party. These results demonstrate that pre-installed applications\non widely distributed low-cost devices represent a significant and\nunderexplored threat to user security and privacy.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\u6765\u5206\u6790\u5ec9\u4ef7\u5b89\u5353\u8bbe\u5907\u4e0a\u7684\u9884\u88c5\u5e94\u7528\uff0c\u53d1\u73b0\u8fd9\u4e9b\u5e94\u7528\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u548c\u9690\u79c1\u98ce\u9669\uff0c\u5305\u62ec\u654f\u611f\u6570\u636e\u6cc4\u9732\u3001\u5173\u952e\u7ec4\u4ef6\u66b4\u9732\u7b49\u3002", "motivation": "\u5ec9\u4ef7\u5b89\u5353\u8bbe\u5907\u7684\u9884\u88c5\u5e94\u7528\u62e5\u6709\u9ad8\u6743\u9650\u4f46\u7f3a\u4e4f\u72ec\u7acb\u5ba1\u67e5\uff0c\u5b58\u5728\u5b89\u5168\u76f2\u70b9\u3002", "method": "\u5f00\u53d1\u6846\u67b6\u4ece\u7269\u7406\u8bbe\u5907\u63d0\u53d6APK\u5e76\u8fdb\u884c\u9759\u6001\u5206\u6790\uff0c\u68c0\u67e5\u4e867\u6b3e\u975e\u6d32\u667a\u80fd\u624b\u673a\u76841544\u4e2aAPK\u3002", "result": "9%\u7684\u5e94\u7528\u6cc4\u9732\u654f\u611f\u6570\u636e\uff0c16%\u66b4\u9732\u5173\u952e\u7ec4\u4ef6\uff0c\u8fd8\u6709\u5927\u91cf\u5e94\u7528\u6267\u884c\u7279\u6743\u547d\u4ee4\u3001\u64cd\u4f5c\u77ed\u4fe1\u3001\u9759\u9ed8\u5b89\u88c5\u7b49\u5371\u9669\u884c\u4e3a\u3002", "conclusion": "\u5ec9\u4ef7\u8bbe\u5907\u7684\u9884\u88c5\u5e94\u7528\u662f\u7528\u6237\u5b89\u5168\u548c\u9690\u79c1\u7684\u91cd\u8981\u5a01\u80c1\uff0c\u9700\u8981\u66f4\u591a\u5173\u6ce8\u3002"}}
{"id": "2509.18186", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18186", "abs": "https://arxiv.org/abs/2509.18186", "authors": ["Nursultan Askarbekuly", "Timur Fayzrakhmanov", "Sladjan Babarogi\u0107", "Ivan Lukovi\u0107"], "title": "An Outcome-Based Educational Recommender System", "comment": null, "summary": "Most educational recommender systems are tuned and judged on click- or\nrating-based relevance, leaving their true pedagogical impact unclear. We\nintroduce OBER-an Outcome-Based Educational Recommender that embeds learning\noutcomes and assessment items directly into the data schema, so any algorithm\ncan be evaluated on the mastery it fosters. OBER uses a minimalist\nentity-relation model, a log-driven mastery formula, and a plug-in\narchitecture. Integrated into an e-learning system in non-formal domain, it was\nevaluated trough a two-week randomized split test with over 5 700 learners\nacross three methods: fixed expert trajectory, collaborative filtering (CF),\nand knowledge-based (KB) filtering. CF maximized retention, but the fixed path\nachieved the highest mastery. Because OBER derives business, relevance, and\nlearning metrics from the same logs, it lets practitioners weigh relevance and\nengagement against outcome mastery with no extra testing overhead. The\nframework is method-agnostic and readily extensible to future adaptive or\ncontext-aware recommenders.", "AI": {"tldr": "OBER\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b66\u4e60\u6210\u679c\u7684\u6559\u80b2\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u5b66\u4e60\u6210\u679c\u548c\u8bc4\u4f30\u9879\u5d4c\u5165\u6570\u636e\u6a21\u5f0f\uff0c\u4f7f\u4efb\u4f55\u63a8\u8350\u7b97\u6cd5\u90fd\u80fd\u6839\u636e\u5176\u4fc3\u8fdb\u5b66\u751f\u638c\u63e1\u7a0b\u5ea6\u7684\u6548\u679c\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "\u5927\u591a\u6570\u6559\u80b2\u63a8\u8350\u7cfb\u7edf\u4ec5\u57fa\u4e8e\u70b9\u51fb\u7387\u6216\u8bc4\u5206\u8fdb\u884c\u4f18\u5316\u548c\u8bc4\u4f30\uff0c\u65e0\u6cd5\u8861\u91cf\u5176\u771f\u5b9e\u7684\u6559\u5b66\u5f71\u54cd\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u76f4\u63a5\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u5bf9\u5b66\u4e60\u6210\u679c\u5f71\u54cd\u7684\u65b9\u6cd5\u3002", "method": "OBER\u91c7\u7528\u7b80\u7ea6\u7684\u5b9e\u4f53\u5173\u7cfb\u6a21\u578b\u3001\u57fa\u4e8e\u65e5\u5fd7\u7684\u638c\u63e1\u5ea6\u8ba1\u7b97\u516c\u5f0f\u548c\u63d2\u4ef6\u67b6\u6784\u3002\u5728\u975e\u6b63\u5f0f\u5b66\u4e60\u9886\u57df\u7684\u7535\u5b50\u5b66\u4e60\u7cfb\u7edf\u4e2d\u8fdb\u884c\u4e86\u4e3a\u671f\u4e24\u5468\u7684\u968f\u673a\u5206\u7ec4\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e86\u56fa\u5b9a\u4e13\u5bb6\u8def\u5f84\u3001\u534f\u540c\u8fc7\u6ee4\u548c\u57fa\u4e8e\u77e5\u8bc6\u7684\u8fc7\u6ee4\u4e09\u79cd\u65b9\u6cd5\u3002", "result": "\u534f\u540c\u8fc7\u6ee4\u65b9\u6cd5\u6700\u5927\u5316\u4e86\u7528\u6237\u7559\u5b58\u7387\uff0c\u4f46\u56fa\u5b9a\u8def\u5f84\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u5b66\u4e60\u638c\u63e1\u5ea6\u3002OBER\u6846\u67b6\u53ef\u4ee5\u4ece\u76f8\u540c\u7684\u65e5\u5fd7\u6570\u636e\u4e2d\u540c\u65f6\u83b7\u53d6\u4e1a\u52a1\u6307\u6807\u3001\u76f8\u5173\u6027\u6307\u6807\u548c\u5b66\u4e60\u6307\u6807\u3002", "conclusion": "OBER\u6846\u67b6\u662f\u65b9\u6cd5\u65e0\u5173\u7684\uff0c\u53ef\u4ee5\u8f7b\u677e\u6269\u5c55\u5230\u672a\u6765\u7684\u81ea\u9002\u5e94\u6216\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u8350\u7cfb\u7edf\uff0c\u8ba9\u4ece\u4e1a\u8005\u80fd\u591f\u5728\u6ca1\u6709\u989d\u5916\u6d4b\u8bd5\u8d1f\u62c5\u7684\u60c5\u51b5\u4e0b\u6743\u8861\u76f8\u5173\u6027\u548c\u53c2\u4e0e\u5ea6\u4e0e\u5b66\u4e60\u6210\u679c\u638c\u63e1\u5ea6\u3002"}}
{"id": "2509.18871", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.18871", "abs": "https://arxiv.org/abs/2509.18871", "authors": ["Tamer Ahmed Eltaras", "Qutaibah Malluhi", "Alessandro Savino", "Stefano Di Carlo", "Adnan Qayyum"], "title": "R-CONV++: Uncovering Privacy Vulnerabilities through Analytical Gradient Inversion Attacks", "comment": null, "summary": "Federated learning has emerged as a prominent privacy-preserving technique\nfor leveraging large-scale distributed datasets by sharing gradients instead of\nraw data. However, recent studies indicate that private training data can still\nbe exposed through gradient inversion attacks. While earlier analytical methods\nhave demonstrated success in reconstructing input data from fully connected\nlayers, their effectiveness significantly diminishes when applied to\nconvolutional layers, high-dimensional inputs, and scenarios involving multiple\ntraining examples. This paper extends our previous work \\cite{eltaras2024r} and\nproposes three advanced algorithms to broaden the applicability of gradient\ninversion attacks. The first algorithm presents a novel data leakage method\nthat efficiently exploits convolutional layer gradients, demonstrating that\neven with non-fully invertible activation functions, such as ReLU, training\nsamples can be analytically reconstructed directly from gradients without the\nneed to reconstruct intermediate layer outputs. Building on this foundation,\nthe second algorithm extends this analytical approach to support\nhigh-dimensional input data, substantially enhancing its utility across complex\nreal-world datasets. The third algorithm introduces an innovative analytical\nmethod for reconstructing mini-batches, addressing a critical gap in current\nresearch that predominantly focuses on reconstructing only a single training\nexample. Unlike previous studies that focused mainly on the weight constraints\nof convolutional layers, our approach emphasizes the pivotal role of gradient\nconstraints, revealing that successful attacks can be executed with fewer than\n5\\% of the constraints previously deemed necessary in certain layers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u5148\u8fdb\u7684\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u7b97\u6cd5\uff0c\u6269\u5c55\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u7684\u653b\u51fb\u8303\u56f4\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5377\u79ef\u5c42\u3001\u9ad8\u7ef4\u8f93\u5165\u548c\u6279\u91cf\u8bad\u7ec3\u6837\u672c\u7684\u91cd\u5efa\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u65b9\u6cd5\u5728\u5904\u7406\u5377\u79ef\u5c42\u3001\u9ad8\u7ef4\u8f93\u5165\u548c\u6279\u91cf\u8bad\u7ec3\u6837\u672c\u65f6\u6548\u679c\u663e\u8457\u4e0b\u964d\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u653b\u51fb\u6280\u672f\u6765\u63ed\u793a\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "method": "1\uff09\u9488\u5bf9\u5377\u79ef\u5c42\u7684\u65b0\u578b\u6570\u636e\u6cc4\u9732\u65b9\u6cd5\uff0c\u76f4\u63a5\u4ece\u68af\u5ea6\u91cd\u5efa\u8bad\u7ec3\u6837\u672c\u800c\u65e0\u9700\u91cd\u5efa\u4e2d\u95f4\u5c42\u8f93\u51fa\uff1b2\uff09\u6269\u5c55\u5206\u6790\u65b9\u6cd5\u652f\u6301\u9ad8\u7ef4\u8f93\u5165\u6570\u636e\uff1b3\uff09\u521b\u65b0\u7684\u6279\u91cf\u91cd\u5efa\u5206\u6790\u65b9\u6cd5\uff0c\u89e3\u51b3\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u6837\u672c\u91cd\u5efa\u7684\u5c40\u9650\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5173\u6ce8\u68af\u5ea6\u7ea6\u675f\u800c\u975e\u6743\u91cd\u7ea6\u675f\uff0c\u6210\u529f\u653b\u51fb\u6240\u9700\u7684\u7ea6\u675f\u6570\u91cf\u53ef\u51cf\u5c11\u5230\u4e4b\u524d\u8ba4\u4e3a\u5fc5\u8981\u76845%\u4ee5\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u6548\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u663e\u8457\u63a8\u8fdb\u4e86\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u4e2d\u6f5c\u5728\u7684\u9690\u79c1\u6f0f\u6d1e\uff0c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2509.18198", "categories": ["cs.AI", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.18198", "abs": "https://arxiv.org/abs/2509.18198", "authors": ["Rui Liu", "Zikang Wang", "Peng Gao", "Yu Shen", "Pratap Tokekar", "Ming Lin"], "title": "MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation", "comment": null, "summary": "Autonomous systems have advanced significantly, but challenges persist in\naccident-prone environments where robust decision-making is crucial. A single\nvehicle's limited sensor range and obstructed views increase the likelihood of\naccidents. Multi-vehicle connected systems and multi-modal approaches,\nleveraging RGB images and LiDAR point clouds, have emerged as promising\nsolutions. However, existing methods often assume the availability of all data\nmodalities and connected vehicles during both training and testing, which is\nimpractical due to potential sensor failures or missing connected vehicles. To\naddress these challenges, we introduce a novel framework MMCD (Multi-Modal\nCollaborative Decision-making) for connected autonomy. Our framework fuses\nmulti-modal observations from ego and collaborative vehicles to enhance\ndecision-making under challenging conditions. To ensure robust performance when\ncertain data modalities are unavailable during testing, we propose an approach\nbased on cross-modal knowledge distillation with a teacher-student model\nstructure. The teacher model is trained with multiple data modalities, while\nthe student model is designed to operate effectively with reduced modalities.\nIn experiments on $\\textit{connected autonomous driving with ground vehicles}$\nand $\\textit{aerial-ground vehicles collaboration}$, our method improves\ndriving safety by up to ${\\it 20.7}\\%$, surpassing the best-existing baseline\nin detecting potential accidents and making safe driving decisions. More\ninformation can be found on our website https://ruiiu.github.io/mmcd.", "AI": {"tldr": "\u63d0\u51faMMCD\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u534f\u4f5c\u51b3\u7b56\u548c\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u4e2d\u4f20\u611f\u5668\u6545\u969c\u6216\u8fde\u63a5\u8f66\u8f86\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u63d0\u5347\u9a7e\u9a76\u5b89\u5168\u6027\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u4e8b\u6545\u6613\u53d1\u73af\u5883\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u5355\u4e2a\u8f66\u8f86\u4f20\u611f\u5668\u8303\u56f4\u6709\u9650\u4e14\u89c6\u91ce\u53d7\u963b\u3002\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u8bad\u7ec3\u548c\u6d4b\u8bd5\u65f6\u6240\u6709\u6570\u636e\u6a21\u6001\u548c\u8fde\u63a5\u8f66\u8f86\u90fd\u53ef\u7528\uff0c\u8fd9\u4e0d\u5207\u5b9e\u9645\u3002", "method": "MMCD\u6846\u67b6\u878d\u5408\u81ea\u8f66\u548c\u534f\u4f5c\u8f66\u8f86\u7684\u591a\u6a21\u6001\u89c2\u6d4b\u6570\u636e\uff0c\u91c7\u7528\u57fa\u4e8e\u6559\u5e08-\u5b66\u751f\u6a21\u578b\u7684\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\uff0c\u6559\u5e08\u6a21\u578b\u4f7f\u7528\u591a\u6a21\u6001\u6570\u636e\u8bad\u7ec3\uff0c\u5b66\u751f\u6a21\u578b\u80fd\u5728\u6a21\u6001\u51cf\u5c11\u65f6\u6709\u6548\u8fd0\u884c\u3002", "result": "\u5728\u8fde\u63a5\u81ea\u52a8\u9a7e\u9a76\u548c\u7a7a\u5730\u8f66\u8f86\u534f\u4f5c\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5c06\u9a7e\u9a76\u5b89\u5168\u6027\u63d0\u5347\u9ad8\u8fbe20.7%\uff0c\u5728\u6f5c\u5728\u4e8b\u6545\u68c0\u6d4b\u548c\u5b89\u5168\u9a7e\u9a76\u51b3\u7b56\u65b9\u9762\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u57fa\u7ebf\u3002", "conclusion": "MMCD\u6846\u67b6\u901a\u8fc7\u591a\u6a21\u6001\u534f\u4f5c\u548c\u77e5\u8bc6\u84b8\u998f\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u52a8\u9a7e\u9a76\u4e2d\u6570\u636e\u6a21\u6001\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2509.18909", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.18909", "abs": "https://arxiv.org/abs/2509.18909", "authors": ["Jan Wichelmann", "Anja Rabich", "Anna P\"atschke", "Thomas Eisenbarth"], "title": "Obelix: Mitigating Side-Channels Through Dynamic Obfuscation", "comment": null, "summary": "Trusted execution environments (TEEs) offer hardware-assisted means to\nprotect code and data. However, as shown in numerous results over the years,\nattackers can use side-channels to leak data access patterns and even\nsingle-step the code. While the vendors are slowly introducing hardware-based\ncountermeasures for some attacks, others will stay unaddressed. This makes a\nsoftware-level countermeasure desirable, but current available solutions only\naddress very specific attack vectors or have a narrow leakage model.\n  In this work, we take a holistic view at the vulnerabilities of TEEs and\ndesign a tool named Obelix, which is the first to protect both code and data\nagainst a wide range of TEE attacks, from cache attacks over single-stepping to\nciphertext side-channels. We analyze the practically achievable precision of\nstate-of-the-art single-stepping tools, and present an algorithm which uses\nthat knowledge to divide a program into uniform code blocks, that are\nindistinguishable for a strong attacker. By storing these blocks and the\nprogram data in oblivious RAM, the attacker cannot follow execution,\neffectively protecting both secret code and data. We describe how we automate\nour approach to make it available for developers who are unfamiliar with\nside-channels. As an obfuscation tool, Obelix comes with a considerable\nperformance overhead, but compensates this with strong security guarantees and\neasy applicability without requiring any expert knowledge.", "AI": {"tldr": "Obelix\u662f\u4e00\u4e2a\u4fdd\u62a4\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEE)\u4e2d\u4ee3\u7801\u548c\u6570\u636e\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u5c06\u7a0b\u5e8f\u5212\u5206\u4e3a\u7edf\u4e00\u7684\u4ee3\u7801\u5757\u5e76\u4f7f\u7528\u4e0d\u7ecf\u610fRAM\u6765\u62b5\u5fa1\u591a\u79cd\u4fa7\u4fe1\u9053\u653b\u51fb\u3002", "motivation": "TEE\u867d\u7136\u63d0\u4f9b\u786c\u4ef6\u7ea7\u522b\u7684\u4fdd\u62a4\uff0c\u4f46\u653b\u51fb\u8005\u4ecd\u53ef\u901a\u8fc7\u4fa7\u4fe1\u9053\u6cc4\u9732\u6570\u636e\u8bbf\u95ee\u6a21\u5f0f\u751a\u81f3\u5355\u6b65\u6267\u884c\u4ee3\u7801\u3002\u73b0\u6709\u7684\u8f6f\u4ef6\u7ea7\u9632\u62a4\u63aa\u65bd\u8981\u4e48\u53ea\u9488\u5bf9\u7279\u5b9a\u653b\u51fb\u5411\u91cf\uff0c\u8981\u4e48\u6cc4\u6f0f\u6a21\u578b\u8fc7\u4e8e\u72ed\u7a84\u3002", "method": "\u5206\u6790\u73b0\u6709\u5355\u6b65\u6267\u884c\u5de5\u5177\u7684\u5b9e\u9645\u7cbe\u5ea6\uff0c\u8bbe\u8ba1\u7b97\u6cd5\u5c06\u7a0b\u5e8f\u5212\u5206\u4e3a\u653b\u51fb\u8005\u65e0\u6cd5\u533a\u5206\u7684\u7edf\u4e00\u4ee3\u7801\u5757\uff0c\u5c06\u8fd9\u4e9b\u5757\u548c\u7a0b\u5e8f\u6570\u636e\u5b58\u50a8\u5728\u4e0d\u7ecf\u610fRAM\u4e2d\uff0c\u4f7f\u653b\u51fb\u8005\u65e0\u6cd5\u8ddf\u8e2a\u6267\u884c\u8fc7\u7a0b\u3002", "result": "Obelix\u80fd\u591f\u4fdd\u62a4\u4ee3\u7801\u548c\u6570\u636e\u514d\u53d7\u7f13\u5b58\u653b\u51fb\u3001\u5355\u6b65\u6267\u884c\u653b\u51fb\u548c\u5bc6\u6587\u4fa7\u4fe1\u9053\u7b49\u591a\u79cdTEE\u653b\u51fb\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u6613\u4e8e\u4f7f\u7528\u7684\u9632\u62a4\u65b9\u6848\u3002", "conclusion": "\u867d\u7136Obelix\u4f5c\u4e3a\u6df7\u6dc6\u5de5\u5177\u4f1a\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u5f00\u9500\uff0c\u4f46\u5b83\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u4e14\u65e0\u9700\u4e13\u4e1a\u77e5\u8bc6\u5373\u53ef\u5e94\u7528\uff0c\u662f\u9996\u4e2a\u80fd\u5168\u9762\u4fdd\u62a4TEE\u4ee3\u7801\u548c\u6570\u636e\u514d\u53d7\u591a\u79cd\u653b\u51fb\u7684\u5de5\u5177\u3002"}}
{"id": "2509.18215", "categories": ["cs.AI", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.18215", "abs": "https://arxiv.org/abs/2509.18215", "authors": ["Timotheus Kampik", "Kristijonas \u010cyras", "Jos\u00e9 Ruiz Alarc\u00f3n"], "title": "Change in Quantitative Bipolar Argumentation: Sufficient, Necessary, and Counterfactual Explanations", "comment": "The publisher's version contains a notation glitch in Example 3, 5th\n  line, first sub-script G should be G'. This has always been G' in authors'\n  version. Thanks to J. Lanser for pointing this out", "summary": "This paper presents a formal approach to explaining change of inference in\nQuantitative Bipolar Argumentation Frameworks (QBAFs). When drawing conclusions\nfrom a QBAF and updating the QBAF to then again draw conclusions (and so on),\nour approach traces changes -- which we call strength inconsistencies -- in the\npartial order over argument strengths that a semantics establishes on some\narguments of interest, called topic arguments. We trace the causes of strength\ninconsistencies to specific arguments, which then serve as explanations. We\nidentify sufficient, necessary, and counterfactual explanations for strength\ninconsistencies and show that strength inconsistency explanations exist if and\nonly if an update leads to strength inconsistency. We define a heuristic-based\napproach to facilitate the search for strength inconsistency explanations, for\nwhich we also provide an implementation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f62\u5f0f\u5316\u65b9\u6cd5\u6765\u89e3\u91ca\u5b9a\u91cf\u53cc\u6781\u8bba\u8bc1\u6846\u67b6(QBAF)\u4e2d\u63a8\u7406\u53d8\u5316\u7684\u539f\u56e0\u3002\u5f53\u4eceQBAF\u5f97\u51fa\u7ed3\u8bba\u5e76\u66f4\u65b0QBAF\u540e\u518d\u6b21\u5f97\u51fa\u7ed3\u8bba\u65f6\uff0c\u8be5\u65b9\u6cd5\u8ffd\u8e2a\u8bed\u4e49\u5728\u611f\u5174\u8da3\u53c2\u6570(\u4e3b\u9898\u53c2\u6570)\u4e0a\u5efa\u7acb\u7684\u5f3a\u5ea6\u504f\u5e8f\u5173\u7cfb\u7684\u53d8\u5316(\u79f0\u4e3a\u5f3a\u5ea6\u4e0d\u4e00\u81f4\u6027)\u3002", "motivation": "\u5728\u52a8\u6001\u8bba\u8bc1\u7cfb\u7edf\u4e2d\uff0c\u5f53\u66f4\u65b0QBAF\u65f6\uff0c\u53c2\u6570\u5f3a\u5ea6\u7684\u6392\u5e8f\u5173\u7cfb\u53ef\u80fd\u53d1\u751f\u53d8\u5316\uff0c\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u8ffd\u8e2a\u548c\u89e3\u91ca\u8fd9\u4e9b\u53d8\u5316\u7684\u539f\u56e0\u3002", "method": "\u5c06\u5f3a\u5ea6\u4e0d\u4e00\u81f4\u6027\u7684\u539f\u56e0\u8ffd\u6eaf\u5230\u7279\u5b9a\u53c2\u6570\uff0c\u8bc6\u522b\u5145\u5206\u3001\u5fc5\u8981\u548c\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002\u5b9a\u4e49\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\u6765\u4fc3\u8fdb\u5f3a\u5ea6\u4e0d\u4e00\u81f4\u6027\u89e3\u91ca\u7684\u641c\u7d22\uff0c\u5e76\u63d0\u4f9b\u5b9e\u73b0\u3002", "result": "\u8bc1\u660e\u4e86\u5f3a\u5ea6\u4e0d\u4e00\u81f4\u6027\u89e3\u91ca\u5b58\u5728\u7684\u5145\u8981\u6761\u4ef6\u662f\u66f4\u65b0\u5bfc\u81f4\u5f3a\u5ea6\u4e0d\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aQBAF\u4e2d\u7684\u63a8\u7406\u53d8\u5316\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u7684\u89e3\u91ca\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u52a8\u6001\u8bba\u8bc1\u7cfb\u7edf\u4e2d\u7684\u63a8\u7406\u6f14\u53d8\u3002"}}
{"id": "2509.18934", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.18934", "abs": "https://arxiv.org/abs/2509.18934", "authors": ["Yating Liu", "Xing Su", "Hao Wu", "Sijin Li", "Yuxi Cheng", "Fengyuan Xu", "Sheng Zhong"], "title": "Generic Adversarial Smart Contract Detection with Semantics and Uncertainty-Aware LLM", "comment": null, "summary": "Adversarial smart contracts, mostly on EVM-compatible chains like Ethereum\nand BSC, are deployed as EVM bytecode to exploit vulnerable smart contracts\ntypically for financial gains. Detecting such malicious contracts at the time\nof deployment is an important proactive strategy preventing loss from victim\ncontracts. It offers a better cost-benefit than detecting vulnerabilities on\ndiverse potential victims. However, existing works are not generic with limited\ndetection types and effectiveness due to imbalanced samples, while the emerging\nLLM technologies, which show its potentials in generalization, have two key\nproblems impeding its application in this task: hard digestion of compiled-code\ninputs, especially those with task-specific logic, and hard assessment of LLMs'\ncertainty in their binary answers, i.e., yes-or-no answers. Therefore, we\npropose a generic adversarial smart contracts detection framework FinDet, which\nleverages LLMs with two enhancements addressing above two problems. FinDet\ntakes as input only the EVM-bytecode contracts and identifies adversarial ones\namong them with high balanced accuracy. The first enhancement extracts concise\nsemantic intentions and high-level behavioral logic from the low-level bytecode\ninputs, unleashing the LLM reasoning capability restricted by the task input.\nThe second enhancement probes and measures the LLM uncertainty to its\nmulti-round answering to the same query, improving the LLM answering robustness\nfor binary classifications required by the task output. Our comprehensive\nevaluation shows that FinDet achieves a BAC of 0.9223 and a TPR of 0.8950,\nsignificantly outperforming existing baselines. It remains robust under\nchallenging conditions including unseen attack patterns, low-data settings, and\nfeature obfuscation. FinDet detects all 5 public and 20+ unreported adversarial\ncontracts in a 10-day real-world test, confirmed manually.", "AI": {"tldr": "FinDet\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u901a\u7528\u5bf9\u6297\u6027\u667a\u80fd\u5408\u7ea6\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u610f\u56fe\u63d0\u53d6\u548c\u4e0d\u786e\u5b9a\u6027\u6d4b\u91cf\u6280\u672f\uff0c\u5728EVM\u5b57\u8282\u7801\u5c42\u9762\u6709\u6548\u8bc6\u522b\u6076\u610f\u5408\u7ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u68c0\u6d4b\u7c7b\u578b\u6709\u9650\u4e14\u6548\u679c\u4e0d\u4f73\uff0c\u800cLLM\u6280\u672f\u867d\u7136\u5177\u6709\u6cdb\u5316\u6f5c\u529b\uff0c\u4f46\u5728\u5904\u7406\u7f16\u8bd1\u4ee3\u7801\u8f93\u5165\u548c\u8bc4\u4f30\u4e8c\u8fdb\u5236\u5206\u7c7b\u786e\u5b9a\u6027\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "method": "FinDet\u91c7\u7528\u4e24\u79cd\u589e\u5f3a\u6280\u672f\uff1a1\uff09\u4ece\u4f4e\u7ea7\u5b57\u8282\u7801\u4e2d\u63d0\u53d6\u8bed\u4e49\u610f\u56fe\u548c\u884c\u4e3a\u903b\u8f91\uff1b2\uff09\u901a\u8fc7\u591a\u8f6e\u95ee\u7b54\u63a2\u6d4bLLM\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u9ad8\u4e8c\u8fdb\u5236\u5206\u7c7b\u7684\u9c81\u68d2\u6027\u3002", "result": "FinDet\u8fbe\u52300.9223\u7684\u5e73\u8861\u51c6\u786e\u7387\u548c0.8950\u7684\u771f\u9633\u6027\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u572810\u5929\u771f\u5b9e\u6d4b\u8bd5\u4e2d\u6210\u529f\u68c0\u6d4b\u6240\u670925\u4e2a\u5bf9\u6297\u6027\u5408\u7ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u672a\u89c1\u653b\u51fb\u6a21\u5f0f\u3001\u4f4e\u6570\u636e\u8bbe\u7f6e\u548c\u7279\u5f81\u6df7\u6dc6\u7b49\u6311\u6218\u6761\u4ef6\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u4e3a\u667a\u80fd\u5408\u7ea6\u5b89\u5168\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.19117", "categories": ["cs.CR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.19117", "abs": "https://arxiv.org/abs/2509.19117", "authors": ["Felix Weissberg", "Lukas Pirch", "Erik Imgrund", "Jonas M\u00f6ller", "Thorsten Eisenhofer", "Konrad Rieck"], "title": "LLM-based Vulnerability Discovery through the Lens of Code Metrics", "comment": null, "summary": "Large language models (LLMs) excel in many tasks of software engineering, yet\nprogress in leveraging them for vulnerability discovery has stalled in recent\nyears. To understand this phenomenon, we investigate LLMs through the lens of\nclassic code metrics. Surprisingly, we find that a classifier trained solely on\nthese metrics performs on par with state-of-the-art LLMs for vulnerability\ndiscovery. A root-cause analysis reveals a strong correlation and a causal\neffect between LLMs and code metrics: When the value of a metric is changed,\nLLM predictions tend to shift by a corresponding magnitude. This dependency\nsuggests that LLMs operate at a similarly shallow level as code metrics,\nlimiting their ability to grasp complex patterns and fully realize their\npotential in vulnerability discovery. Based on these findings, we derive\nrecommendations on how research should more effectively address this challenge.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u5728\u6f0f\u6d1e\u53d1\u73b0\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0e\u57fa\u4e8e\u4f20\u7edf\u4ee3\u7801\u5ea6\u91cf\u7684\u5206\u7c7b\u5668\u76f8\u5f53\uff0c\u8868\u660eLLMs\u5bf9\u6f0f\u6d1e\u7684\u7406\u89e3\u505c\u7559\u5728\u6d45\u5c42\u6c34\u5e73\uff0c\u9650\u5236\u4e86\u5176\u53d1\u73b0\u590d\u6742\u6f0f\u6d1e\u7684\u80fd\u529b\u3002", "motivation": "\u7406\u89e3\u4e3a\u4ec0\u4e48LLMs\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5176\u4ed6\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u6f0f\u6d1e\u53d1\u73b0\u65b9\u9762\u7684\u8fdb\u5c55\u5374\u505c\u6ede\u4e0d\u524d\u3002", "method": "\u901a\u8fc7\u7ecf\u5178\u4ee3\u7801\u5ea6\u91cf\u7684\u89c6\u89d2\u7814\u7a76LLMs\uff0c\u8bad\u7ec3\u57fa\u4e8e\u4ee3\u7801\u5ea6\u91cf\u7684\u5206\u7c7b\u5668\u4e0e\u6700\u5148\u8fdbLLMs\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5e76\u8fdb\u884c\u6839\u56e0\u5206\u6790\u3002", "result": "\u53d1\u73b0LLMs\u9884\u6d4b\u4e0e\u4ee3\u7801\u5ea6\u91cf\u5b58\u5728\u5f3a\u76f8\u5173\u6027\u548c\u56e0\u679c\u5173\u7cfb\uff0c\u5f53\u5ea6\u91cf\u503c\u6539\u53d8\u65f6\uff0cLLM\u9884\u6d4b\u4f1a\u76f8\u5e94\u53d8\u5316\u3002", "conclusion": "LLMs\u5728\u6f0f\u6d1e\u53d1\u73b0\u4e2d\u4ec5\u505c\u7559\u5728\u6d45\u5c42\u5206\u6790\u6c34\u5e73\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u66f4\u6709\u6548\u5730\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002"}}
{"id": "2509.18216", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18216", "abs": "https://arxiv.org/abs/2509.18216", "authors": ["Amitava Das"], "title": "nDNA -- the Semantic Helix of Artificial Cognition", "comment": null, "summary": "As AI foundation models grow in capability, a deeper question emerges: What\nshapes their internal cognitive identity -- beyond fluency and output?\nBenchmarks measure behavior, but the soul of a model resides in its latent\ngeometry. In this work, we propose Neural DNA (nDNA) as a semantic-genotypic\nrepresentation that captures this latent identity through the intrinsic\ngeometry of belief. At its core, nDNA is synthesized from three principled and\nindispensable dimensions of latent geometry: spectral curvature, which reveals\nthe curvature of conceptual flow across layers; thermodynamic length, which\nquantifies the semantic effort required to traverse representational\ntransitions through layers; and belief vector field, which delineates the\nsemantic torsion fields that guide a model's belief directional orientations.\nLike biological DNA, it encodes ancestry, mutation, and semantic inheritance,\nfound in finetuning and alignment scars, cultural imprints, and architectural\ndrift. In naming it, we open a new field: Neural Genomics, where models are not\njust tools, but digital semantic organisms with traceable inner cognition.\n  Modeling statement. We read AI foundation models as semantic fluid--dynamics:\nmeaning is transported through layers like fluid in a shaped conduit; nDNA is\nthe physics-grade readout of that flow -- a geometry-first measure of how\nmeaning is bent, paid for, and pushed -- yielding a stable, coordinate-free\nneural DNA fingerprint tied to on-input behavior; with this fingerprint we\ncross into biology: tracing lineages across pretraining, fine-tuning,\nalignment, pruning, distillation, and merges; measuring inheritance between\ncheckpoints; detecting drift as traits shift under new data or objectives; and,\nultimately, studying the evolution of artificial cognition to compare models,\ndiagnose risks, and govern change over time.", "AI": {"tldr": "\u63d0\u51fa\u4e86Neural DNA\uff08nDNA\uff09\u4f5c\u4e3aAI\u57fa\u7840\u6a21\u578b\u7684\u8bed\u4e49\u57fa\u56e0\u578b\u8868\u793a\uff0c\u901a\u8fc7\u6f5c\u5728\u51e0\u4f55\u7ed3\u6784\u6355\u6349\u6a21\u578b\u7684\u5185\u5728\u8ba4\u77e5\u8eab\u4efd\u3002nDNA\u57fa\u4e8e\u4e09\u4e2a\u51e0\u4f55\u7ef4\u5ea6\uff1a\u8c31\u66f2\u7387\u3001\u70ed\u529b\u5b66\u957f\u5ea6\u548c\u4fe1\u5ff5\u5411\u91cf\u573a\uff0c\u7528\u4e8e\u8ffd\u8e2a\u6a21\u578b\u7684\u8c31\u7cfb\u3001\u7a81\u53d8\u548c\u8bed\u4e49\u7ee7\u627f\u3002", "motivation": "\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u8861\u91cf\u6a21\u578b\u884c\u4e3a\uff0c\u4f46\u6a21\u578b\u7684\u672c\u8d28\u5728\u4e8e\u5176\u6f5c\u5728\u51e0\u4f55\u7ed3\u6784\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6355\u6349\u6a21\u578b\u5185\u5728\u8ba4\u77e5\u8eab\u4efd\u7684\u65b9\u6cd5\uff0c\u4ee5\u7406\u89e3AI\u6a21\u578b\u7684\u8c31\u7cfb\u3001\u6587\u5316\u5370\u8bb0\u548c\u67b6\u6784\u6f02\u79fb\u3002", "method": "\u4ece\u4e09\u4e2a\u51e0\u4f55\u7ef4\u5ea6\u5408\u6210nDNA\uff1a\u8c31\u66f2\u7387\uff08\u63ed\u793a\u8de8\u5c42\u7684\u6982\u5ff5\u6d41\u66f2\u7387\uff09\u3001\u70ed\u529b\u5b66\u957f\u5ea6\uff08\u91cf\u5316\u8868\u793a\u8f6c\u6362\u7684\u8bed\u4e49\u52aa\u529b\uff09\u548c\u4fe1\u5ff5\u5411\u91cf\u573a\uff08\u63cf\u8ff0\u5f15\u5bfc\u6a21\u578b\u4fe1\u5ff5\u65b9\u5411\u7684\u8bed\u4e49\u626d\u8f6c\u573a\uff09\u3002", "result": "nDNA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5b9a\u3001\u5750\u6807\u65e0\u5173\u7684\u795e\u7ecfDNA\u6307\u7eb9\uff0c\u53ef\u7528\u4e8e\u8ffd\u8e2a\u9884\u8bad\u7ec3\u3001\u5fae\u8c03\u3001\u5bf9\u9f50\u3001\u526a\u679d\u3001\u84b8\u998f\u548c\u6a21\u578b\u5408\u5e76\u7b49\u8fc7\u7a0b\u4e2d\u7684\u8c31\u7cfb\uff0c\u6d4b\u91cf\u68c0\u67e5\u70b9\u4e4b\u95f4\u7684\u7ee7\u627f\u5173\u7cfb\uff0c\u68c0\u6d4b\u65b0\u6570\u636e\u6216\u76ee\u6807\u4e0b\u7684\u7279\u5f81\u6f02\u79fb\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f00\u542f\u4e86\u795e\u7ecf\u57fa\u56e0\u7ec4\u5b66\u65b0\u9886\u57df\uff0c\u5c06AI\u6a21\u578b\u89c6\u4e3a\u5177\u6709\u53ef\u8ffd\u8e2a\u5185\u5728\u8ba4\u77e5\u7684\u6570\u5b57\u8bed\u4e49\u6709\u673a\u4f53\uff0c\u4e3a\u6bd4\u8f83\u6a21\u578b\u3001\u8bca\u65ad\u98ce\u9669\u548c\u6cbb\u7406\u8ba4\u77e5\u6f14\u5316\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2509.19101", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.19101", "abs": "https://arxiv.org/abs/2509.19101", "authors": ["Gejian Zhao", "Hanzhou Wu", "Xinpeng Zhang"], "title": "Trigger Where It Hurts: Unveiling Hidden Backdoors through Sensitivity with Sensitron", "comment": null, "summary": "Backdoor attacks pose a significant security threat to natural language\nprocessing (NLP) systems, but existing methods lack explainable trigger\nmechanisms and fail to quantitatively model vulnerability patterns. This work\npioneers the quantitative connection between explainable artificial\nintelligence (XAI) and backdoor attacks, introducing Sensitron, a novel modular\nframework for crafting stealthy and robust backdoor triggers. Sensitron employs\na progressive refinement approach where Dynamic Meta-Sensitivity Analysis\n(DMSA) first identifies potentially vulnerable input tokens, Hierarchical SHAP\nEstimation (H-SHAP) then provides explainable attribution to precisely pinpoint\nthe most influential tokens, and finally a Plug-and-Rank mechanism that\ngenerates contextually appropriate triggers. We establish the first\nmathematical correlation (Sensitivity Ranking Correlation, SRC=0.83) between\nexplainability scores and empirical attack success, enabling precise targeting\nof model vulnerabilities. Sensitron achieves 97.8% Attack Success Rate (ASR)\n(+5.8% over state-of-the-art (SOTA)) with 85.4% ASR at 0.1% poisoning rate,\ndemonstrating robust resistance against multiple SOTA defenses. This work\nreveals fundamental NLP vulnerabilities and provides new attack vectors through\nweaponized explainability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSensitron\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u89e3\u91caAI\u6280\u672f\u91cf\u5316\u5206\u6790NLP\u6a21\u578b\u6f0f\u6d1e\uff0c\u6784\u5efa\u9690\u853d\u4e14\u9c81\u68d2\u7684\u540e\u95e8\u653b\u51fb\u89e6\u53d1\u5668\uff0c\u5728\u653b\u51fb\u6210\u529f\u7387\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u5e76\u6709\u6548\u62b5\u6297\u9632\u5fa1\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u7684\u89e6\u53d1\u673a\u5236\uff0c\u65e0\u6cd5\u5b9a\u91cf\u5efa\u6a21\u6f0f\u6d1e\u6a21\u5f0f\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u89e3\u91caAI\u4e0e\u540e\u95e8\u653b\u51fb\u4e4b\u95f4\u7684\u5b9a\u91cf\u8054\u7cfb\u3002", "method": "Sensitron\u91c7\u7528\u6e10\u8fdb\u5f0f\u7cbe\u70bc\u65b9\u6cd5\uff1a\u52a8\u6001\u5143\u654f\u611f\u5ea6\u5206\u6790\u8bc6\u522b\u6613\u53d7\u653b\u51fb\u7684\u8f93\u5165token\uff0c\u5206\u5c42SHAP\u4f30\u8ba1\u63d0\u4f9b\u53ef\u89e3\u91ca\u5f52\u56e0\uff0cPlug-and-Rank\u673a\u5236\u751f\u6210\u4e0a\u4e0b\u6587\u5408\u9002\u7684\u89e6\u53d1\u5668\u3002", "result": "\u5efa\u7acb\u4e86\u53ef\u89e3\u91ca\u6027\u5206\u6570\u4e0e\u653b\u51fb\u6210\u529f\u7387\u4e4b\u95f4\u7684\u6570\u5b66\u76f8\u5173\u6027(SRC=0.83)\uff0c\u653b\u51fb\u6210\u529f\u7387\u8fbe97.8%(\u6bd4SOTA\u63d0\u53475.8%)\uff0c\u57280.1%\u6295\u6bd2\u7387\u4e0b\u4ecd\u4fdd\u630185.4%ASR\uff0c\u5bf9\u591a\u79cdSOTA\u9632\u5fa1\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63ed\u793a\u4e86NLP\u6a21\u578b\u7684\u57fa\u672c\u6f0f\u6d1e\uff0c\u901a\u8fc7\u6b66\u5668\u5316\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u653b\u51fb\u5411\u91cf\u3002"}}
{"id": "2509.19153", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.19153", "abs": "https://arxiv.org/abs/2509.19153", "authors": ["Massimo Bartoletti", "Enrico Lipparini", "Livio Pompianu"], "title": "LLMs as verification oracles for Solidity", "comment": null, "summary": "Ensuring the correctness of smart contracts is critical, as even subtle flaws\ncan lead to severe financial losses. While bug detection tools able to spot\ncommon vulnerability patterns can serve as a first line of defense, most\nreal-world exploits and losses stem from errors in the contract business logic.\nFormal verification tools such as SolCMC and the Certora Prover address this\nchallenge, but their impact remains limited by steep learning curves and\nrestricted specification languages. Recent works have begun to explore the use\nof large language models (LLMs) for security-related tasks such as\nvulnerability detection and test generation. Yet, a fundamental question\nremains open: can LLMs serve as verification oracles, capable of reasoning\nabout arbitrary contract-specific properties? In this paper, we provide the\nfirst systematic evaluation of GPT-5, a state-of-the-art reasoning LLM, in this\nrole. We benchmark its performance on a large dataset of verification tasks,\ncompare its outputs against those of established formal verification tools, and\nassess its practical effectiveness in real-world auditing scenarios. Our study\ncombines quantitative metrics with qualitative analysis, and shows that recent\nreasoning-oriented LLMs can be surprisingly effective as verification oracles,\nsuggesting a new frontier in the convergence of AI and formal methods for\nsecure smart contract development and auditing.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86GPT-5\u4f5c\u4e3a\u667a\u80fd\u5408\u7ea6\u9a8c\u8bc1\u9884\u8a00\u673a\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u63a8\u7406\u5bfc\u5411\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9a8c\u8bc1\u4efb\u610f\u5408\u7ea6\u7279\u5b9a\u5c5e\u6027\u65b9\u9762\u5177\u6709\u51fa\u4eba\u610f\u6599\u7684\u6548\u529b\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u7684\u6b63\u786e\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\u5b58\u5728\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u548c\u89c4\u8303\u8bed\u8a00\u53d7\u9650\u7684\u95ee\u9898\u3002\u867d\u7136LLMs\u5df2\u7528\u4e8e\u5b89\u5168\u76f8\u5173\u4efb\u52a1\uff0c\u4f46\u80fd\u5426\u4f5c\u4e3a\u9a8c\u8bc1\u9884\u8a00\u673a\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u5728\u5927\u578b\u9a8c\u8bc1\u4efb\u52a1\u6570\u636e\u96c6\u4e0a\u5bf9GPT-5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c06\u5176\u8f93\u51fa\u4e0e\u5df2\u5efa\u7acb\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\u8fdb\u884c\u6bd4\u8f83\uff0c\u5e76\u8bc4\u4f30\u5176\u5728\u771f\u5b9e\u5ba1\u8ba1\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u6548\u679c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8fd1\u671f\u7684\u63a8\u7406\u5bfc\u5411LLMs\u4f5c\u4e3a\u9a8c\u8bc1\u9884\u8a00\u673a\u5177\u6709\u51fa\u4eba\u610f\u6599\u7684\u6548\u529b\uff0c\u7ed3\u5408\u5b9a\u91cf\u6307\u6807\u548c\u5b9a\u6027\u5206\u6790\u8bc1\u5b9e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6807\u5fd7\u7740AI\u548c\u5f62\u5f0f\u5316\u65b9\u6cd5\u5728\u5b89\u5168\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u548c\u5ba1\u8ba1\u9886\u57df\u878d\u5408\u7684\u65b0\u524d\u6cbf\u3002"}}
{"id": "2509.18218", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18218", "abs": "https://arxiv.org/abs/2509.18218", "authors": ["Kei-Sing Ng"], "title": "Similarity Field Theory: A Mathematical Framework for Intelligence", "comment": null, "summary": "We posit that persisting and transforming similarity relations form the\nstructural basis of any comprehensible dynamic system. This paper introduces\nSimilarity Field Theory, a mathematical framework that formalizes the\nprinciples governing similarity values among entities and their evolution. We\ndefine: (1) a similarity field $S: U \\times U \\to [0,1]$ over a universe of\nentities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed\nrelational field (asymmetry and non-transitivity are allowed); (2) the\nevolution of a system through a sequence $Z_p = (X_p, S^{(p)})$ indexed by\n$p=0,1,2,\\ldots$; (3) concepts $K$ as entities that induce fibers\n$F_{\\alpha}(K) = { E \\in U \\mid S(E,K) \\ge \\alpha }$, i.e., superlevel sets of\nthe unary map $S_K(E) := S(E,K)$; and (4) a generative operator $G$ that\nproduces new entities. Within this framework, we formalize a generative\ndefinition of intelligence: an operator $G$ is intelligent with respect to a\nconcept $K$ if, given a system containing entities belonging to the fiber of\n$K$, it generates new entities that also belong to that fiber. Similarity Field\nTheory thus offers a foundational language for characterizing, comparing, and\nconstructing intelligent systems. We prove two theorems: (i) asymmetry blocks\nmutual inclusion; and (ii) stability requires either an anchor coordinate or\neventual confinement within a level set of $f$. These results ensure that the\nevolution of similarity fields is both constrained and interpretable,\nculminating in an exploration of how the framework allows us to interpret large\nlanguage models and use them as experimental probes into societal cognition.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u76f8\u4f3c\u6027\u573a\u7406\u8bba\uff0c\u8fd9\u662f\u4e00\u4e2a\u6570\u5b66\u6846\u67b6\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u5b9e\u4f53\u95f4\u76f8\u4f3c\u6027\u5173\u7cfb\u53ca\u5176\u6f14\u5316\u7684\u539f\u5219\u3002\u8be5\u7406\u8bba\u5b9a\u4e49\u4e86\u76f8\u4f3c\u6027\u573a\u3001\u7cfb\u7edf\u6f14\u5316\u3001\u6982\u5ff5\u7ea4\u7ef4\u548c\u751f\u6210\u7b97\u5b50\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f62\u5f0f\u5316\u5730\u5b9a\u4e49\u4e86\u667a\u80fd\u7684\u6982\u5ff5\u3002", "motivation": "\u4f5c\u8005\u8ba4\u4e3a\u6301\u4e45\u5316\u548c\u8f6c\u6362\u76f8\u4f3c\u6027\u5173\u7cfb\u662f\u4efb\u4f55\u53ef\u7406\u89e3\u52a8\u6001\u7cfb\u7edf\u7684\u7ed3\u6784\u57fa\u7840\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u6570\u5b66\u6846\u67b6\u6765\u5f62\u5f0f\u5316\u8fd9\u4e9b\u539f\u5219\uff0c\u4e3a\u8868\u5f81\u3001\u6bd4\u8f83\u548c\u6784\u5efa\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\u8bed\u8a00\u3002", "method": "\u5b9a\u4e49\u4e86\u76f8\u4f3c\u6027\u573aS: U\u00d7U\u2192[0,1]\uff0c\u6ee1\u8db3\u81ea\u53cd\u6027\u4f46\u5141\u8bb8\u4e0d\u5bf9\u79f0\u6027\u548c\u975e\u4f20\u9012\u6027\uff1b\u7cfb\u7edf\u6f14\u5316\u5e8f\u5217Zp=(Xp,S(p))\uff1b\u6982\u5ff5K\u8bf1\u5bfc\u7ea4\u7ef4F\u03b1(K)\uff1b\u751f\u6210\u7b97\u5b50G\u3002\u901a\u8fc7\u5b9a\u7406\u8bc1\u660e\u76f8\u4f3c\u6027\u573a\u6f14\u5316\u7684\u7ea6\u675f\u6761\u4ef6\u3002", "result": "\u8bc1\u660e\u4e86\u4e24\u4e2a\u5b9a\u7406\uff1a(i)\u4e0d\u5bf9\u79f0\u6027\u963b\u6b62\u76f8\u4e92\u5305\u542b\uff1b(ii)\u7a33\u5b9a\u6027\u9700\u8981\u951a\u5750\u6807\u6216\u6700\u7ec8\u9650\u5236\u5728f\u7684\u6c34\u5e73\u96c6\u5185\u3002\u8fd9\u4e9b\u7ed3\u679c\u786e\u4fdd\u76f8\u4f3c\u6027\u573a\u7684\u6f14\u5316\u65e2\u53d7\u7ea6\u675f\u53c8\u53ef\u89e3\u91ca\u3002", "conclusion": "\u76f8\u4f3c\u6027\u573a\u7406\u8bba\u4e3a\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\uff0c\u80fd\u591f\u89e3\u91ca\u5927\u8bed\u8a00\u6a21\u578b\u5e76\u5c06\u5176\u4f5c\u4e3a\u793e\u4f1a\u8ba4\u77e5\u7684\u5b9e\u9a8c\u63a2\u9488\u3002"}}
{"id": "2509.18221", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18221", "abs": "https://arxiv.org/abs/2509.18221", "authors": ["Dingxin Lu", "Shurui Wu", "Xinyi Huang"], "title": "Multimodal Health Risk Prediction System for Chronic Diseases via Vision-Language Fusion and Large Language Models", "comment": null, "summary": "With the rising global burden of chronic diseases and the multimodal and\nheterogeneous clinical data (medical imaging, free-text recordings, wearable\nsensor streams, etc.), there is an urgent need for a unified multimodal AI\nframework that can proactively predict individual health risks. We propose\nVL-RiskFormer, a hierarchical stacked visual-language multimodal Transformer\nwith a large language model (LLM) inference head embedded in its top layer. The\nsystem builds on the dual-stream architecture of existing visual-linguistic\nmodels (e.g., PaLM-E, LLaVA) with four key innovations: (i) pre-training with\ncross-modal comparison and fine-grained alignment of radiological images,\nfundus maps, and wearable device photos with corresponding clinical narratives\nusing momentum update encoders and debiased InfoNCE losses; (ii) a time fusion\nblock that integrates irregular visit sequences into the causal Transformer\ndecoder through adaptive time interval position coding; (iii) a disease\nontology map adapter that injects ICD-10 codes into visual and textual channels\nin layers and infers comorbid patterns with the help of a graph attention\nmechanism. On the MIMIC-IV longitudinal cohort, VL-RiskFormer achieved an\naverage AUROC of 0.90 with an expected calibration error of 2.7 percent.", "AI": {"tldr": "VL-RiskFormer\u662f\u4e00\u4e2a\u7528\u4e8e\u9884\u6d4b\u4e2a\u4f53\u5065\u5eb7\u98ce\u9669\u7684\u591a\u6a21\u6001AI\u6846\u67b6\uff0c\u7ed3\u5408\u89c6\u89c9\u548c\u8bed\u8a00\u6570\u636e\uff0c\u5728MIMIC-IV\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e860.90\u7684AUROC\u3002", "motivation": "\u968f\u7740\u6162\u6027\u75be\u75c5\u8d1f\u62c5\u589e\u52a0\u548c\u591a\u6a21\u6001\u4e34\u5e8a\u6570\u636e\u7684\u6d8c\u73b0\uff0c\u9700\u8981\u7edf\u4e00\u7684AI\u6846\u67b6\u6765\u4e3b\u52a8\u9884\u6d4b\u4e2a\u4f53\u5065\u5eb7\u98ce\u9669\u3002", "method": "\u91c7\u7528\u5c42\u6b21\u5316\u5806\u53e0\u7684\u89c6\u89c9-\u8bed\u8a00\u591a\u6a21\u6001Transformer\u67b6\u6784\uff0c\u5305\u542b\u9884\u8bad\u7ec3\u3001\u65f6\u95f4\u878d\u5408\u5757\u548c\u75be\u75c5\u672c\u4f53\u56fe\u9002\u914d\u5668\u4e09\u4e2a\u5173\u952e\u521b\u65b0\u3002", "result": "\u5728MIMIC-IV\u7eb5\u5411\u961f\u5217\u4e2d\uff0c\u5e73\u5747AUROC\u8fbe\u52300.90\uff0c\u9884\u671f\u6821\u51c6\u8bef\u5dee\u4e3a2.7%\u3002", "conclusion": "VL-RiskFormer\u5c55\u793a\u4e86\u5728\u591a\u6a21\u6001\u4e34\u5e8a\u6570\u636e\u4e0a\u8fdb\u884c\u5065\u5eb7\u98ce\u9669\u9884\u6d4b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.18226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18226", "abs": "https://arxiv.org/abs/2509.18226", "authors": ["Yu Fu", "Linyue Cai", "Ruoyu Wu", "Yong Zhao"], "title": "From \"What to Eat?\" to Perfect Recipe: ChefMind's Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation", "comment": "5 pages, 3 figures, submitted to icassp 2026", "summary": "Personalized recipe recommendation faces challenges in handling fuzzy user\nintent, ensuring semantic accuracy, and providing sufficient detail coverage.\nWe propose ChefMind, a hybrid architecture combining Chain of Exploration\n(CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large\nLanguage Model (LLM). CoE refines ambiguous queries into structured conditions,\nKG offers semantic reasoning and interpretability, RAG supplements contextual\nculinary details, and LLM integrates outputs into coherent recommendations. We\nevaluate ChefMind on the Xiachufang dataset and manually annotated queries,\ncomparing it with LLM-only, KG-only, and RAG-only baselines. Results show that\nChefMind achieves superior performance in accuracy, relevance, completeness,\nand clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models.\nMoreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in\nhandling fuzzy demands.", "AI": {"tldr": "ChefMind\u662f\u4e00\u4e2a\u6df7\u5408\u67b6\u6784\uff0c\u7ed3\u5408\u4e86\u63a2\u7d22\u94fe\u3001\u77e5\u8bc6\u56fe\u8c31\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u4e2a\u6027\u5316\u98df\u8c31\u63a8\u8350\u4e2d\u7684\u6a21\u7cca\u7528\u6237\u610f\u56fe\u3001\u8bed\u4e49\u51c6\u786e\u6027\u548c\u7ec6\u8282\u8986\u76d6\u95ee\u9898\u3002", "motivation": "\u4e2a\u6027\u5316\u98df\u8c31\u63a8\u8350\u9762\u4e34\u5904\u7406\u6a21\u7cca\u7528\u6237\u610f\u56fe\u3001\u786e\u4fdd\u8bed\u4e49\u51c6\u786e\u6027\u548c\u63d0\u4f9b\u8db3\u591f\u7ec6\u8282\u8986\u76d6\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faChefMind\u6df7\u5408\u67b6\u6784\uff1a\u63a2\u7d22\u94fe(CoE)\u5c06\u6a21\u7cca\u67e5\u8be2\u7ec6\u5316\u4e3a\u7ed3\u6784\u5316\u6761\u4ef6\uff0c\u77e5\u8bc6\u56fe\u8c31(KG)\u63d0\u4f9b\u8bed\u4e49\u63a8\u7406\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u8865\u5145\u4e0a\u4e0b\u6587\u70f9\u996a\u7ec6\u8282\uff0c\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u5c06\u8f93\u51fa\u6574\u5408\u4e3a\u8fde\u8d2f\u63a8\u8350\u3002", "result": "\u5728Xiachufang\u6570\u636e\u96c6\u548c\u624b\u52a8\u6807\u6ce8\u67e5\u8be2\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cChefMind\u5728\u51c6\u786e\u6027\u3001\u76f8\u5173\u6027\u3001\u5b8c\u6574\u6027\u548c\u6e05\u6670\u5ea6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u5f97\u52068.7\uff0c\u800c\u6d88\u878d\u6a21\u578b\u4e3a6.4-6.7\u3002\u672a\u5904\u7406\u67e5\u8be2\u964d\u81f31.6%\uff0c\u8bc1\u660e\u5176\u5728\u5904\u7406\u6a21\u7cca\u9700\u6c42\u65b9\u9762\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "ChefMind\u901a\u8fc7\u6df7\u5408\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u98df\u8c31\u63a8\u8350\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u65b9\u6cd5\u57fa\u7ebf\u3002"}}
{"id": "2509.18229", "categories": ["cs.AI", "70, 74, 76, 80"], "pdf": "https://arxiv.org/pdf/2509.18229", "abs": "https://arxiv.org/abs/2509.18229", "authors": ["Anthony Patera", "Rohan Abeyaratne"], "title": "An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems", "comment": null, "summary": "Generative AI, and specifically GPT, can produce a remarkable solution to a\nmechanical engineering analysis problem - but also, on occasion, a flawed\nsolution. For example, an elementary mechanics problem is solved flawlessly in\none GPT instance and incorrectly in a subsequent GPT instance, with a success\nprobability of only 85%. This unreliability renders \"out-of-the-box\" GPT\nunsuitable for deployment in education or engineering practice. We introduce an\n\"N-Plus-1\" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering\nProblem Statements. Agency first launches N instantiations of Agent Solve to\nyield N independent Proposed Problem Solution Realizations; Agency then invokes\nAgent Compare to summarize and compare the N Proposed Problem Solution\nRealizations and to provide a Recommended Problem Solution. We argue from\nCondorcet's Jury Theorem that, for a Problem Statement characterized by\nper-Solve success probability greater than 1/2 (and N sufficiently large), the\nPredominant (Agent Compare) Proposed Problem Solution will, with high\nprobability, correspond to a Correct Proposed Problem Solution. Furthermore,\nAgent Compare can also incorporate aspects of Secondary (Agent Compare)\nProposed Problem Solutions, in particular when the latter represent alternative\nProblem Statement interpretations - different Mathematical Models - or\nalternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a\ncommercial multi-agent model, show similarities in design and performance, but\nalso important differences in emphasis: our Agency focuses on transparency and\npedagogical value.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\"N-Plus-1\"GPT\u4ee3\u7406\u67b6\u6784\uff0c\u7528\u4e8e\u673a\u68b0\u5de5\u7a0b\u95ee\u9898\u7684\u521d\u6b65\u5206\u6790\uff0c\u901a\u8fc7\u591a\u4e2a\u72ec\u7acb\u6c42\u89e3\u4ee3\u7406\u548c\u6bd4\u8f83\u4ee3\u7406\u6765\u63d0\u9ad8GPT\u5728\u5de5\u7a0b\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u53ef\u9760\u6027\u3002", "motivation": "GPT\u5728\u673a\u68b0\u5de5\u7a0b\u5206\u6790\u4e2d\u8868\u73b0\u51fa\u4e0d\u7a33\u5b9a\u6027\uff0c\u6210\u529f\u7387\u4ec5\u4e3a85%\uff0c\u8fd9\u79cd\u4e0d\u53ef\u9760\u6027\u4f7f\u5176\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u6559\u80b2\u6216\u5de5\u7a0b\u5b9e\u8df5\u3002", "method": "\u91c7\u7528N+1\u4ee3\u7406\u67b6\u6784\uff1a\u9996\u5148\u542f\u52a8N\u4e2a\u72ec\u7acb\u6c42\u89e3\u4ee3\u7406\u751f\u6210N\u4e2a\u95ee\u9898\u89e3\u51b3\u65b9\u6848\uff0c\u7136\u540e\u901a\u8fc7\u6bd4\u8f83\u4ee3\u7406\u5bf9\u8fd9\u4e9b\u65b9\u6848\u8fdb\u884c\u603b\u7ed3\u3001\u6bd4\u8f83\u5e76\u63a8\u8350\u6700\u4f18\u89e3\u3002\u57fa\u4e8e\u5b54\u591a\u585e\u966a\u5ba1\u56e2\u5b9a\u7406\uff0c\u5f53\u6bcf\u4e2a\u6c42\u89e3\u4ee3\u7406\u7684\u6210\u529f\u6982\u7387\u5927\u4e8e1/2\u65f6\uff0c\u591a\u6570\u6295\u7968\u7ed3\u679c\u5927\u6982\u7387\u6b63\u786e\u3002", "result": "\u4e0e\u5546\u4e1a\u591a\u4ee3\u7406\u6a21\u578bGrok Heavy\u76f8\u6bd4\uff0c\u8be5\u67b6\u6784\u5728\u8bbe\u8ba1\u548c\u6027\u80fd\u4e0a\u5177\u6709\u76f8\u4f3c\u6027\uff0c\u4f46\u66f4\u6ce8\u91cd\u900f\u660e\u5ea6\u548c\u6559\u5b66\u4ef7\u503c\u3002", "conclusion": "N-Plus-1\u4ee3\u7406\u67b6\u6784\u80fd\u591f\u6709\u6548\u63d0\u9ad8GPT\u5728\u673a\u68b0\u5de5\u7a0b\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u7279\u522b\u9002\u5408\u6559\u80b2\u573a\u666f\uff0c\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\u548c\u900f\u660e\u6bd4\u8f83\u8fc7\u7a0b\u589e\u5f3a\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2509.18230", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18230", "abs": "https://arxiv.org/abs/2509.18230", "authors": ["Zihan Dong", "Xinyu Fan", "Zixiang Tang", "Yunqing Li"], "title": "Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces", "comment": null, "summary": "Controlling desktop applications via software remains a fundamental yet\nunder-served problem. Existing multi-modal large language models (MLLMs) ingest\nscreenshots and task instructions to generate keystrokes and mouse events, but\nthey suffer from prohibitive inference latency, poor sample efficiency on\nlong-horizon sparse-reward tasks, and infeasible on-device deployment. We\nintroduce a lightweight hierarchical reinforcement learning framework,\nComputerAgent, that formulates OS control as a two-level option process\n(manager and subpolicy), employs a triple-modal state encoder (screenshot, task\nID, numeric state) to handle visual and contextual diversity, integrates\nmeta-actions with an early-stop mechanism to reduce wasted interactions, and\nuses a compact vision backbone plus small policy networks for on-device\ninference (15M parameters). On a suite of 135 real-world desktop tasks,\nComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on\nhard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on\nsimple scenarios while reducing model size by over four orders of magnitude and\nhalving inference time. These results demonstrate that hierarchical RL offers a\npractical, scalable alternative to monolithic MLLM-based automation for\ncomputer control.", "AI": {"tldr": "ComputerAgent\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u5c42\u7ea7\u9009\u9879\u8fc7\u7a0b\uff08\u7ba1\u7406\u5668\u548c\u5b50\u7b56\u7565\uff09\u63a7\u5236\u684c\u9762\u5e94\u7528\uff0c\u4f7f\u7528\u4e09\u91cd\u6a21\u6001\u72b6\u6001\u7f16\u7801\u5668\u5904\u7406\u89c6\u89c9\u548c\u4e0a\u4e0b\u6587\u591a\u6837\u6027\uff0c\u96c6\u6210\u5143\u52a8\u4f5c\u548c\u63d0\u524d\u505c\u6b62\u673a\u5236\u51cf\u5c11\u65e0\u6548\u4ea4\u4e92\uff0c\u5b9e\u73b0\u8bbe\u5907\u7aef\u63a8\u7406\uff081500\u4e07\u53c2\u6570\uff09\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u684c\u9762\u5e94\u7528\u63a7\u5236\u4e2d\u5b58\u5728\u63a8\u7406\u5ef6\u8fdf\u9ad8\u3001\u957f\u89c6\u91ce\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u6837\u672c\u6548\u7387\u5dee\u3001\u8bbe\u5907\u7aef\u90e8\u7f72\u4e0d\u53ef\u884c\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u7ba1\u7406\u5668\u548c\u5b50\u7b56\u7565\u4e24\u5c42\u7ed3\u6784\uff0c\u4f7f\u7528\u622a\u56fe\u3001\u4efb\u52a1ID\u548c\u6570\u503c\u72b6\u6001\u7684\u4e09\u91cd\u6a21\u6001\u7f16\u7801\uff0c\u96c6\u6210\u5143\u52a8\u4f5c\u548c\u63d0\u524d\u505c\u6b62\u673a\u5236\uff0c\u4f7f\u7528\u7d27\u51d1\u89c6\u89c9\u9aa8\u5e72\u7f51\u7edc\u548c\u5c0f\u578b\u7b56\u7565\u7f51\u7edc\u3002", "result": "\u5728135\u4e2a\u771f\u5b9e\u4e16\u754c\u684c\u9762\u4efb\u52a1\u6d4b\u8bd5\u4e2d\uff0c\u7b80\u5355\u4efb\u52a1\uff08<8\u6b65\uff09\u6210\u529f\u738792.1%\uff0c\u56f0\u96be\u4efb\u52a1\uff08\u22658\u6b65\uff09\u6210\u529f\u738758.8%\uff0c\u6027\u80fd\u5339\u914d\u6216\u8d85\u8fc72000\u4ebf\u53c2\u6570MLLM\u57fa\u7ebf\uff0c\u6a21\u578b\u5927\u5c0f\u51cf\u5c114\u4e2a\u6570\u91cf\u7ea7\uff0c\u63a8\u7406\u65f6\u95f4\u51cf\u534a\u3002", "conclusion": "\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u4e3a\u8ba1\u7b97\u673a\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u76f8\u6bd4\u5355\u4e00\u7684\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u65b9\u6cd5\u66f4\u5177\u4f18\u52bf\u3002"}}
{"id": "2509.18234", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18234", "abs": "https://arxiv.org/abs/2509.18234", "authors": ["Yu Gu", "Jingjing Fu", "Xiaodong Liu", "Jeya Maria Jose Valanarasu", "Noel Codella", "Reuben Tan", "Qianchu Liu", "Ying Jin", "Sheng Zhang", "Jinyu Wang", "Rui Wang", "Lei Song", "Guanghui Qin", "Naoto Usuyama", "Cliff Wong", "Cheng Hao", "Hohin Lee", "Praneeth Sanapathi", "Sarah Hilado", "Bian Jiang", "Javier Alvarez-Valle", "Mu Wei", "Jianfeng Gao", "Eric Horvitz", "Matt Lungren", "Hoifung Poon", "Paul Vozila"], "title": "The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks", "comment": "35 pages", "summary": "Large frontier models like GPT-5 now achieve top scores on medical\nbenchmarks. But our stress tests tell a different story. Leading systems often\nguess correctly even when key inputs like images are removed, flip answers\nunder trivial prompt changes, and fabricate convincing yet flawed reasoning.\nThese aren't glitches; they expose how today's benchmarks reward test-taking\ntricks over medical understanding. We evaluate six flagship models across six\nwidely used benchmarks and find that high leaderboard scores hide brittleness\nand shortcut learning. Through clinician-guided rubric evaluation, we show that\nbenchmarks vary widely in what they truly measure yet are treated\ninterchangeably, masking failure modes. We caution that medical benchmark\nscores do not directly reflect real-world readiness. If we want AI to earn\ntrust in healthcare, we must demand more than leaderboard wins and must hold\nsystems accountable for robustness, sound reasoning, and alignment with real\nmedical demands.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5bf9\u516d\u4e2a\u524d\u6cbf\u6a21\u578b\u5728\u516d\u4e2a\u533b\u7597\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u538b\u529b\u6d4b\u8bd5\uff0c\u53d1\u73b0\u9ad8\u5206\u6570\u63a9\u76d6\u4e86\u6a21\u578b\u7684\u8106\u5f31\u6027\u548c\u6377\u5f84\u5b66\u4e60\u95ee\u9898\uff0c\u533b\u7597\u57fa\u51c6\u5206\u6570\u4e0d\u80fd\u76f4\u63a5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u7684\u51c6\u5907\u5ea6", "motivation": "\u63ed\u793a\u5f53\u524d\u533b\u7597AI\u57fa\u51c6\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\uff0c\u8bc1\u660e\u9ad8\u5206\u6570\u53ef\u80fd\u6e90\u4e8e\u5e94\u8bd5\u6280\u5de7\u800c\u975e\u771f\u6b63\u7684\u533b\u5b66\u7406\u89e3\uff0c\u63d0\u9192\u4e1a\u754c\u4e0d\u5e94\u4ec5\u4f9d\u8d56\u6392\u884c\u699c\u5206\u6570\u8bc4\u4f30\u533b\u7597AI\u7684\u5b9e\u9645\u80fd\u529b", "method": "\u5bf9\u516d\u4e2a\u65d7\u8230\u6a21\u578b\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\uff0c\u5305\u62ec\u79fb\u9664\u5173\u952e\u8f93\u5165\u3001\u6539\u53d8\u63d0\u793a\u8bcd\u7b49\u65b9\u5f0f\uff0c\u7ed3\u5408\u4e34\u5e8a\u533b\u751f\u6307\u5bfc\u7684\u8bc4\u4f30\u6807\u51c6\u5206\u6790\u57fa\u51c6\u6d4b\u8bd5\u7684\u771f\u5b9e\u6d4b\u91cf\u5185\u5bb9", "result": "\u9886\u5148\u7cfb\u7edf\u5728\u5173\u952e\u8f93\u5165\u88ab\u79fb\u9664\u65f6\u4ecd\u80fd\u731c\u5bf9\u7b54\u6848\uff0c\u5728\u5fae\u5c0f\u63d0\u793a\u53d8\u5316\u4e0b\u4f1a\u7ffb\u8f6c\u7b54\u6848\uff0c\u5e76\u751f\u6210\u770b\u4f3c\u5408\u7406\u4f46\u6709\u7f3a\u9677\u7684\u63a8\u7406\uff0c\u57fa\u51c6\u6d4b\u8bd5\u4e4b\u95f4\u5b58\u5728\u5de8\u5927\u5dee\u5f02\u4f46\u88ab\u7b49\u540c\u5bf9\u5f85", "conclusion": "\u533b\u7597AI\u8981\u83b7\u5f97\u533b\u7597\u9886\u57df\u7684\u4fe1\u4efb\uff0c\u5fc5\u987b\u8981\u6c42\u8d85\u8d8a\u6392\u884c\u699c\u80dc\u5229\uff0c\u786e\u4fdd\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3001\u5408\u7406\u63a8\u7406\u80fd\u529b\u4ee5\u53ca\u4e0e\u771f\u5b9e\u533b\u7597\u9700\u6c42\u7684\u4e00\u81f4\u6027"}}
{"id": "2509.18382", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18382", "abs": "https://arxiv.org/abs/2509.18382", "authors": ["Adarsha Balaji", "Le Chen", "Rajeev Thakur", "Franck Cappello", "Sandeep Madireddy"], "title": "Evaluating the Safety and Skill Reasoning of Large Reasoning Models Under Compute Constraints", "comment": null, "summary": "Test-time compute scaling has demonstrated the ability to improve the\nperformance of reasoning language models by generating longer chain-of-thought\n(CoT) sequences. However, this increase in performance comes with a significant\nincrease in computational cost. In this work, we investigate two compute\nconstraint strategies: (1) reasoning length constraint and (2) model\nquantization, as methods to reduce the compute demand of reasoning models and\nstudy their impact on their safety performance. Specifically, we explore two\napproaches to apply compute constraints to reasoning models: (1) fine-tuning\nreasoning models using a length controlled policy optimization (LCPO) based\nreinforcement learning method to satisfy a user-defined CoT reasoning length,\nand (2) applying quantization to maximize the generation of CoT sequences\nwithin a user-defined compute constraint. Furthermore, we study the trade-off\nbetween the computational efficiency and the safety of the model.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e24\u79cd\u8ba1\u7b97\u7ea6\u675f\u7b56\u7565\uff08\u63a8\u7406\u957f\u5ea6\u7ea6\u675f\u548c\u6a21\u578b\u91cf\u5316\uff09\u6765\u964d\u4f4e\u63a8\u7406\u6a21\u578b\u7684\u8ba1\u7b97\u9700\u6c42\uff0c\u5e76\u5206\u6790\u5b83\u4eec\u5bf9\u6a21\u578b\u5b89\u5168\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u867d\u7136\u80fd\u901a\u8fc7\u751f\u6210\u957f\u94fe\u601d\u7ef4\u5e8f\u5217\u63d0\u9ad8\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u663e\u8457\u589e\u52a0\u3002\u9700\u8981\u63a2\u7d22\u5728\u8ba1\u7b97\u7ea6\u675f\u4e0b\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u548c\u5b89\u5168\u6027\u7684\u65b9\u6cd5\u3002", "method": "1\uff09\u4f7f\u7528\u57fa\u4e8e\u957f\u5ea6\u63a7\u5236\u7b56\u7565\u4f18\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5fae\u8c03\u63a8\u7406\u6a21\u578b\uff0c\u6ee1\u8db3\u7528\u6237\u5b9a\u4e49\u7684CoT\u63a8\u7406\u957f\u5ea6\uff1b2\uff09\u5e94\u7528\u91cf\u5316\u6280\u672f\uff0c\u5728\u7528\u6237\u5b9a\u4e49\u7684\u8ba1\u7b97\u7ea6\u675f\u4e0b\u6700\u5927\u5316CoT\u5e8f\u5217\u751f\u6210\u3002", "result": "\u7814\u7a76\u8ba1\u7b97\u6548\u7387\u4e0e\u6a21\u578b\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e24\u79cd\u6709\u6548\u7684\u8ba1\u7b97\u7ea6\u675f\u65b9\u6cd5\uff0c\u4e3a\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u90e8\u7f72\u5b89\u5168\u9ad8\u6548\u7684\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.18383", "categories": ["cs.AI", "cs.DM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18383", "abs": "https://arxiv.org/abs/2509.18383", "authors": ["Moran Feldman", "Amin Karbasi"], "title": "G\u00f6del Test: Can Large Language Models Solve Easy Conjectures?", "comment": null, "summary": "Recent announcements from frontier AI model labs have highlighted strong\nresults on high-school and undergraduate math competitions. Yet it remains\nunclear whether large language models can solve new, simple conjectures in more\nadvanced areas of mathematics. We propose the G\\\"odel Test: evaluating whether\na model can produce correct proofs for very simple, previously unsolved\nconjectures. To this end, we study the performance of GPT-5 on five conjectures\nin combinatorial optimization. For each problem, we provided one or two source\npapers from which the conjecture arose, withheld our own conjecture, and then\nassessed the model's reasoning in detail. On the three easier problems, GPT-5\nproduced nearly correct solutions; for Problem 2 it even derived a different\napproximation guarantee that, upon checking, refuted our conjecture while\nproviding a valid solution. The model failed on Problem 4, which required\ncombining results from two papers. On Problem 5, a harder case without a\nvalidated conjecture, GPT-5 proposed the same algorithm we had in mind but\nfailed in the analysis, suggesting the proof is more challenging than expected.\nAlthough our sample is small, the results point to meaningful progress on\nroutine reasoning, occasional flashes of originality, and clear limitations\nwhen cross-paper synthesis is required. GPT-5 may represent an early step\ntoward frontier models eventually passing the G\\\"odel Test.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86G\u00f6del\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u89e3\u51b3\u6570\u5b66\u4e2d\u7b80\u5355\u4f46\u672a\u89e3\u51b3\u7684\u731c\u60f3\uff0c\u5e76\u5728\u7ec4\u5408\u4f18\u5316\u9886\u57df\u7684\u4e94\u4e2a\u731c\u60f3\u4e0a\u6d4b\u8bd5\u4e86GPT-5\u7684\u8868\u73b0\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u7ea7\u6570\u5b66\u9886\u57df\u89e3\u51b3\u65b0\u7b80\u5355\u731c\u60f3\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5df2\u77e5\u6570\u5b66\u7ade\u8d5b\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86G\u00f6del\u6d4b\u8bd5\uff0c\u9009\u62e9\u4e94\u4e2a\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u672a\u89e3\u51b3\u731c\u60f3\uff0c\u5411GPT-5\u63d0\u4f9b\u76f8\u5173\u8bba\u6587\u4f46\u4e0d\u544a\u77e5\u731c\u60f3\u5185\u5bb9\uff0c\u8be6\u7ec6\u8bc4\u4f30\u5176\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "GPT-5\u5728\u4e09\u4e2a\u8f83\u7b80\u5355\u95ee\u9898\u4e0a\u7ed9\u51fa\u63a5\u8fd1\u6b63\u786e\u7684\u89e3\uff0c\u5728\u95ee\u98982\u4e2d\u751a\u81f3\u63a8\u7ffb\u4e86\u539f\u731c\u60f3\u5e76\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\uff1b\u5728\u9700\u8981\u8de8\u8bba\u6587\u7efc\u5408\u7684\u95ee\u98984\u4e0a\u5931\u8d25\uff1b\u5728\u66f4\u590d\u6742\u7684\u95ee\u98985\u4e0a\u63d0\u51fa\u4e86\u6b63\u786e\u7b97\u6cd5\u4f46\u5206\u6790\u5931\u8d25\u3002", "conclusion": "GPT-5\u5728\u5e38\u89c4\u63a8\u7406\u65b9\u9762\u6709\u663e\u8457\u8fdb\u6b65\uff0c\u5076\u5c14\u5c55\u73b0\u539f\u521b\u6027\uff0c\u4f46\u5728\u8de8\u8bba\u6587\u7efc\u5408\u63a8\u7406\u65b9\u9762\u4ecd\u6709\u660e\u663e\u5c40\u9650\uff0c\u53ef\u80fd\u4ee3\u8868\u4e86\u524d\u6cbf\u6a21\u578b\u901a\u8fc7G\u00f6del\u6d4b\u8bd5\u7684\u65e9\u671f\u8fdb\u5c55\u3002"}}
{"id": "2509.18400", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18400", "abs": "https://arxiv.org/abs/2509.18400", "authors": ["Pritish Yuvraj", "Siva Devarakonda"], "title": "ATLAS: Benchmarking and Adapting LLMs for Global Trade via Harmonized Tariff Code Classification", "comment": null, "summary": "Accurate classification of products under the Harmonized Tariff Schedule\n(HTS) is a critical bottleneck in global trade, yet it has received little\nattention from the machine learning community. Misclassification can halt\nshipments entirely, with major postal operators suspending deliveries to the\nU.S. due to incomplete customs documentation. We introduce the first benchmark\nfor HTS code classification, derived from the U.S. Customs Rulings Online\nSearch System (CROSS). Evaluating leading LLMs, we find that our fine-tuned\nAtlas model (LLaMA-3.3-70B) achieves 40 percent fully correct 10-digit\nclassifications and 57.5 percent correct 6-digit classifications, improvements\nof 15 points over GPT-5-Thinking and 27.5 points over Gemini-2.5-Pro-Thinking.\nBeyond accuracy, Atlas is roughly five times cheaper than GPT-5-Thinking and\neight times cheaper than Gemini-2.5-Pro-Thinking, and can be self-hosted to\nguarantee data privacy in high-stakes trade and compliance workflows. While\nAtlas sets a strong baseline, the benchmark remains highly challenging, with\nonly 40 percent 10-digit accuracy. By releasing both dataset and model, we aim\nto position HTS classification as a new community benchmark task and invite\nfuture work in retrieval, reasoning, and alignment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u57fa\u4e8e\u7f8e\u56fd\u6d77\u5173\u5728\u7ebf\u641c\u7d22\u7cfb\u7edf\u7684HTS\u4ee3\u7801\u5206\u7c7b\u57fa\u51c6\uff0c\u5e76\u5f00\u53d1\u4e86Atlas\u6a21\u578b\uff08\u57fa\u4e8eLLaMA-3.3-70B\uff09\uff0c\u572810\u4f4d\u6570\u5206\u7c7b\u4e0a\u8fbe\u523040%\u51c6\u786e\u7387\uff0c\u6bd4GPT-5\u548cGemini-2.5\u5206\u522b\u63d0\u534715\u548c27.5\u4e2a\u767e\u5206\u70b9\uff0c\u4e14\u6210\u672c\u66f4\u4f4e\u3001\u53ef\u81ea\u6258\u7ba1\u4fdd\u969c\u6570\u636e\u9690\u79c1\u3002", "motivation": "HTS\u4ee3\u7801\u5206\u7c7b\u662f\u5168\u7403\u8d38\u6613\u4e2d\u7684\u5173\u952e\u74f6\u9888\uff0c\u4f46\u673a\u5668\u5b66\u4e60\u793e\u533a\u5bf9\u6b64\u5173\u6ce8\u4e0d\u8db3\u3002\u9519\u8bef\u5206\u7c7b\u4f1a\u5bfc\u81f4\u8d27\u7269\u8fd0\u8f93\u4e2d\u65ad\uff0c\u4e3b\u8981\u90ae\u653f\u8fd0\u8425\u5546\u66fe\u56e0\u6d77\u5173\u6587\u4ef6\u4e0d\u5b8c\u6574\u800c\u6682\u505c\u5bf9\u7f8e\u9001\u8d27\u3002", "method": "\u57fa\u4e8e\u7f8e\u56fd\u6d77\u5173CROSS\u7cfb\u7edf\u6784\u5efa\u9996\u4e2aHTS\u4ee3\u7801\u5206\u7c7b\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5bf9\u9886\u5148\u7684LLM\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u5fae\u8c03Atlas\u6a21\u578b\uff08\u57fa\u4e8eLLaMA-3.3-70B\uff09\u8fdb\u884cHTS\u4ee3\u7801\u5206\u7c7b\u3002", "result": "Atlas\u6a21\u578b\u572810\u4f4d\u6570HTS\u5206\u7c7b\u4e0a\u8fbe\u523040%\u51c6\u786e\u7387\uff0c6\u4f4d\u6570\u5206\u7c7b\u8fbe\u523057.5%\u51c6\u786e\u7387\uff0c\u5206\u522b\u6bd4GPT-5\u548cGemini-2.5\u63d0\u534715\u548c27.5\u4e2a\u767e\u5206\u70b9\u3002\u6210\u672c\u7ea6\u4e3aGPT-5\u76841/5\u3001Gemini-2.5\u76841/8\uff0c\u4e14\u53ef\u81ea\u6258\u7ba1\u4fdd\u969c\u6570\u636e\u9690\u79c1\u3002", "conclusion": "Atlas\u6a21\u578b\u4e3aHTS\u5206\u7c7b\u8bbe\u7acb\u4e86\u5f3a\u57fa\u7ebf\uff0c\u4f46\u8be5\u4efb\u52a1\u4ecd\u6781\u5177\u6311\u6218\u6027\uff0810\u4f4d\u6570\u51c6\u786e\u7387\u4ec540%\uff09\u3002\u901a\u8fc7\u53d1\u5e03\u6570\u636e\u96c6\u548c\u6a21\u578b\uff0c\u65e8\u5728\u5c06HTS\u5206\u7c7b\u5b9a\u4f4d\u4e3a\u65b0\u7684\u793e\u533a\u57fa\u51c6\u4efb\u52a1\uff0c\u5e76\u4fc3\u8fdb\u68c0\u7d22\u3001\u63a8\u7406\u548c\u5bf9\u9f50\u65b9\u9762\u7684\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2509.18420", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18420", "abs": "https://arxiv.org/abs/2509.18420", "authors": ["Nikolai Skripko"], "title": "Instruction-Following Evaluation in Function Calling for Large Language Models", "comment": null, "summary": "Function calling is a core capability of large language models, essential for\nAI agents. Existing benchmarks such as the Berkeley Function Calling\nLeaderboard (BFCL), tau^2-Bench (arXiv:2506.07982), and ACEBench\n(arXiv:2501.12851) evaluate argument correctness but do not test adherence to\nformat instructions embedded in parameter descriptions, such as enclosing\nvalues in double quotes or using ISO date formats.\n  We introduce IFEval-FC, a benchmark inspired by IFEval (arXiv:2311.07911)\nthat assesses precise instruction following in function calling. IFEval-FC\nencodes verifiable formats directly within JSON schema descriptions, for\nexample specifying that a value must not contain punctuation. It includes 750\ntest cases, each consisting of a function with an embedded format for one of\nits input parameters and a corresponding user query. Evaluation is fully\nalgorithmic, ensuring objectivity, reproducibility, and scalability.\n  Our results show that even state-of-the-art proprietary models, including\nGPT-5 and Claude 4.1 Opus, frequently fail to follow basic formatting rules,\nhighlighting a practical limitation for real-world agent systems. The complete\ncodebase and data are publicly available at\nhttps://github.com/Skripkon/IFEval-FC.", "AI": {"tldr": "IFEval-FC\u662f\u4e00\u4e2a\u65b0\u7684\u51fd\u6570\u8c03\u7528\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u95e8\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u53c2\u6570\u63cf\u8ff0\u4e2d\u683c\u5f0f\u6307\u4ee4\u7684\u9075\u5faa\u80fd\u529b\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u53ea\u5173\u6ce8\u53c2\u6570\u6b63\u786e\u6027\u800c\u5ffd\u7565\u683c\u5f0f\u8981\u6c42\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u7684\u51fd\u6570\u8c03\u7528\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982BFCL\u3001tau^2-Bench\u3001ACEBench\uff09\u53ea\u8bc4\u4f30\u53c2\u6570\u6b63\u786e\u6027\uff0c\u4f46\u4e0d\u6d4b\u8bd5\u5bf9\u53c2\u6570\u63cf\u8ff0\u4e2d\u683c\u5f0f\u6307\u4ee4\uff08\u5982\u53cc\u5f15\u53f7\u3001ISO\u65e5\u671f\u683c\u5f0f\uff09\u7684\u9075\u5faa\u80fd\u529b\uff0c\u8fd9\u5728\u5b9e\u9645AI\u4ee3\u7406\u7cfb\u7edf\u4e2d\u662f\u4e00\u4e2a\u91cd\u8981\u7f3a\u9677\u3002", "method": "IFEval-FC\u53d7IFEval\u542f\u53d1\uff0c\u5728JSON schema\u63cf\u8ff0\u4e2d\u76f4\u63a5\u7f16\u7801\u53ef\u9a8c\u8bc1\u7684\u683c\u5f0f\u8981\u6c42\uff0c\u5305\u542b750\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u6bcf\u4e2a\u7528\u4f8b\u5305\u542b\u4e00\u4e2a\u51fd\u6570\u53ca\u5176\u8f93\u5165\u53c2\u6570\u7684\u683c\u5f0f\u8981\u6c42\uff0c\u4ee5\u53ca\u5bf9\u5e94\u7684\u7528\u6237\u67e5\u8be2\u3002\u8bc4\u4f30\u5b8c\u5168\u57fa\u4e8e\u7b97\u6cd5\uff0c\u786e\u4fdd\u5ba2\u89c2\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u662fGPT-5\u548cClaude 4.1 Opus\u7b49\u6700\u5148\u8fdb\u7684\u4e13\u6709\u6a21\u578b\uff0c\u4e5f\u7ecf\u5e38\u65e0\u6cd5\u9075\u5faa\u57fa\u672c\u7684\u683c\u5f0f\u89c4\u5219\uff0c\u8fd9\u63ed\u793a\u4e86\u73b0\u5b9e\u4e16\u754c\u4ee3\u7406\u7cfb\u7edf\u7684\u5b9e\u9645\u5c40\u9650\u6027\u3002", "conclusion": "IFEval-FC\u586b\u8865\u4e86\u51fd\u6570\u8c03\u7528\u8bc4\u4f30\u7684\u91cd\u8981\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7cbe\u786e\u9075\u5faa\u683c\u5f0f\u6307\u4ee4\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3a\u6539\u8fdbAI\u4ee3\u7406\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u3002\u4ee3\u7801\u548c\u6570\u636e\u5df2\u516c\u5f00\u3002"}}
{"id": "2509.18436", "categories": ["cs.AI", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2509.18436", "abs": "https://arxiv.org/abs/2509.18436", "authors": ["Hongda Jiang", "Xinyuan Zhang", "Siddhant Garg", "Rishab Arora", "Shiun-Zu Kuo", "Jiayang Xu", "Christopher Brossman", "Yue Liu", "Aaron Colak", "Ahmed Aly", "Anuj Kumar", "Xin Luna Dong"], "title": "Memory-QA: Answering Recall Questions Based on Multimodal Memories", "comment": null, "summary": "We introduce Memory-QA, a novel real-world task that involves answering\nrecall questions about visual content from previously stored multimodal\nmemories. This task poses unique challenges, including the creation of\ntask-oriented memories, the effective utilization of temporal and location\ninformation within memories, and the ability to draw upon multiple memories to\nanswer a recall question. To address these challenges, we propose a\ncomprehensive pipeline, Pensieve, integrating memory-specific augmentation,\ntime- and location-aware multi-signal retrieval, and multi-memory QA\nfine-tuning. We created a multimodal benchmark to illustrate various real\nchallenges in this task, and show the superior performance of Pensieve over\nstate-of-the-art solutions (up to 14% on QA accuracy).", "AI": {"tldr": "Memory-QA\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u89c6\u89c9\u8bb0\u5fc6\u95ee\u7b54\u4efb\u52a1\uff0cPensieve\u7ba1\u9053\u901a\u8fc7\u8bb0\u5fc6\u589e\u5f3a\u3001\u65f6\u7a7a\u611f\u77e5\u68c0\u7d22\u548c\u591a\u8bb0\u5fc6QA\u5fae\u8c03\uff0c\u5728QA\u51c6\u786e\u7387\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u9ad8\u8fbe14%", "motivation": "\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4e2d\u57fa\u4e8e\u591a\u6a21\u6001\u8bb0\u5fc6\u7684\u89c6\u89c9\u5185\u5bb9\u56de\u5fc6\u95ee\u7b54\u4efb\u52a1\uff0c\u5e94\u5bf9\u4efb\u52a1\u5bfc\u5411\u8bb0\u5fc6\u521b\u5efa\u3001\u65f6\u7a7a\u4fe1\u606f\u5229\u7528\u548c\u591a\u8bb0\u5fc6\u878d\u5408\u7b49\u72ec\u7279\u6311\u6218", "method": "\u63d0\u51faPensieve\u7efc\u5408\u7ba1\u9053\uff0c\u5305\u542b\u8bb0\u5fc6\u7279\u5b9a\u589e\u5f3a\u3001\u65f6\u7a7a\u611f\u77e5\u591a\u4fe1\u53f7\u68c0\u7d22\u548c\u591a\u8bb0\u5fc6QA\u5fae\u8c03\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6", "result": "\u5728\u521b\u5efa\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPensieve\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5728QA\u51c6\u786e\u7387\u4e0a\u63d0\u5347\u9ad8\u8fbe14%", "conclusion": "Pensieve\u7ba1\u9053\u6709\u6548\u89e3\u51b3\u4e86Memory-QA\u4efb\u52a1\u7684\u6311\u6218\uff0c\u4e3a\u57fa\u4e8e\u591a\u6a21\u6001\u8bb0\u5fc6\u7684\u89c6\u89c9\u95ee\u7b54\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.18527", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18527", "abs": "https://arxiv.org/abs/2509.18527", "authors": ["Ziwen Chen", "Zhong Wang"], "title": "FERA: Foil Fencing Referee Assistant Using Pose-Based Multi-Label Move Recognition and Rule Reasoning", "comment": null, "summary": "The sport of fencing, like many other sports, faces challenges in refereeing:\nsubjective calls, human errors, bias, and limited availability in practice\nenvironments. We present FERA (Fencing Referee Assistant), a prototype AI\nreferee for foil fencing which integrates pose-based multi-label action\nrecognition and rule-based reasoning. FERA extracts 2D joint positions from\nvideo, normalizes them, computes a 101-dimensional kinematic feature set, and\napplies a Transformer for multi-label move and blade classification. To\ndetermine priority and scoring, FERA applies a distilled language model with\nencoded right-of-way rules, producing both a decision and an explanation for\neach exchange. With limited hand-labeled data, a 5-fold cross-validation\nachieves an average macro-F1 score of 0.549, outperforming multiple baselines,\nincluding a Temporal Convolutional Network (TCN), BiLSTM, and a vanilla\nTransformer. While not ready for deployment, these results demonstrate a\npromising path towards automated referee assistance in foil fencing and new\nopportunities for AI applications, such as coaching in the field of fencing.", "AI": {"tldr": "FERA\u662f\u4e00\u4e2a\u7528\u4e8e\u51fb\u5251\u88c1\u5224\u8f85\u52a9\u7684AI\u539f\u578b\u7cfb\u7edf\uff0c\u901a\u8fc7\u59ff\u6001\u8bc6\u522b\u548c\u89c4\u5219\u63a8\u7406\u6765\u89e3\u51b3\u51fb\u5251\u88c1\u5224\u4e2d\u7684\u4e3b\u89c2\u6027\u3001\u4eba\u4e3a\u9519\u8bef\u7b49\u95ee\u9898", "motivation": "\u51fb\u5251\u8fd0\u52a8\u5728\u88c1\u5224\u65b9\u9762\u9762\u4e34\u4e3b\u89c2\u5224\u7f5a\u3001\u4eba\u4e3a\u9519\u8bef\u3001\u504f\u89c1\u4ee5\u53ca\u5728\u8bad\u7ec3\u73af\u5883\u4e2d\u88c1\u5224\u8d44\u6e90\u6709\u9650\u7b49\u6311\u6218", "method": "\u7cfb\u7edf\u4ece\u89c6\u9891\u4e2d\u63d0\u53d62D\u5173\u8282\u4f4d\u7f6e\uff0c\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\uff0c\u8ba1\u7b97101\u7ef4\u8fd0\u52a8\u5b66\u7279\u5f81\u96c6\uff0c\u4f7f\u7528Transformer\u8fdb\u884c\u591a\u6807\u7b7e\u52a8\u4f5c\u548c\u5251\u5c16\u5206\u7c7b\uff0c\u5e76\u5e94\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u6765\u786e\u5b9a\u4f18\u5148\u6743\u548c\u5f97\u5206", "result": "\u5728\u6709\u9650\u7684\u624b\u52a8\u6807\u6ce8\u6570\u636e\u4e0b\uff0c5\u6298\u4ea4\u53c9\u9a8c\u8bc1\u7684\u5e73\u5747\u5b8fF1\u5f97\u5206\u4e3a0.549\uff0c\u4f18\u4e8eTCN\u3001BiLSTM\u548c\u666e\u901aTransformer\u7b49\u591a\u4e2a\u57fa\u7ebf\u6a21\u578b", "conclusion": "\u867d\u7136\u5c1a\u672a\u8fbe\u5230\u90e8\u7f72\u6807\u51c6\uff0c\u4f46\u7ed3\u679c\u8868\u660e\u8fd9\u662f\u5b9e\u73b0\u51fb\u5251\u81ea\u52a8\u88c1\u5224\u8f85\u52a9\u7684\u6709\u5e0c\u671b\u8def\u5f84\uff0c\u5e76\u4e3aAI\u5728\u51fb\u5251\u9886\u57df\u7684\u5e94\u7528\uff08\u5982\u6559\u7ec3\u8f85\u52a9\uff09\u5f00\u8f9f\u4e86\u65b0\u673a\u4f1a"}}
{"id": "2509.18557", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18557", "abs": "https://arxiv.org/abs/2509.18557", "authors": ["Tom Pawelek", "Raj Patel", "Charlotte Crowell", "Noorbakhsh Amiri", "Sudip Mittal", "Shahram Rahimi", "Andy Perkins"], "title": "LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs", "comment": "7 pages, 5 figures, to be published and presented at ICMLA 2025", "summary": "Compared to traditional models, agentic AI represents a highly valuable\ntarget for potential attackers as they possess privileged access to data\nsources and API tools, which are traditionally not incorporated into classical\nagents. Unlike a typical software application residing in a Demilitarized Zone\n(DMZ), agentic LLMs consciously rely on nondeterministic behavior of the AI\n(only defining a final goal, leaving the path selection to LLM). This\ncharacteristic introduces substantial security risk to both operational\nsecurity and information security. Most common existing defense mechanism rely\non detection of malicious intent and preventing it from reaching the LLM agent,\nthus protecting against jailbreak attacks such as prompt injection. In this\npaper, we present an alternative approach, LLMZ+, which moves beyond\ntraditional detection-based approaches by implementing prompt whitelisting.\nThrough this method, only contextually appropriate and safe messages are\npermitted to interact with the agentic LLM. By leveraging the specificity of\ncontext, LLMZ+ guarantees that all exchanges between external users and the LLM\nconform to predefined use cases and operational boundaries. Our approach\nstreamlines the security framework, enhances its long-term resilience, and\nreduces the resources required for sustaining LLM information security. Our\nempirical evaluation demonstrates that LLMZ+ provides strong resilience against\nthe most common jailbreak prompts. At the same time, legitimate business\ncommunications are not disrupted, and authorized traffic flows seamlessly\nbetween users and the agentic LLM. We measure the effectiveness of approach\nusing false positive and false negative rates, both of which can be reduced to\n0 in our experimental setting.", "AI": {"tldr": "LLMZ+\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63d0\u793a\u767d\u540d\u5355\u7684\u65b0\u578b\u9632\u5fa1\u673a\u5236\uff0c\u901a\u8fc7\u53ea\u5141\u8bb8\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u5b89\u5168\u6d88\u606f\u4e0e\u667a\u80fdLLM\u4ea4\u4e92\uff0c\u6709\u6548\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u5408\u6cd5\u4e1a\u52a1\u901a\u4fe1\u7684\u6d41\u7545\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6076\u610f\u610f\u56fe\u68c0\u6d4b\u7684\u9632\u5fa1\u673a\u5236\u5b58\u5728\u5c40\u9650\u6027\uff0c\u667a\u80fdAI\u7531\u4e8e\u5176\u7279\u6743\u6570\u636e\u8bbf\u95ee\u548cAPI\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u6210\u4e3a\u653b\u51fb\u8005\u7684\u9ad8\u4ef7\u503c\u76ee\u6807\u3002\u667a\u80fdLLM\u7684\u975e\u786e\u5b9a\u6027\u884c\u4e3a\u7279\u6027\u5e26\u6765\u4e86\u91cd\u5927\u7684\u8fd0\u8425\u5b89\u5168\u548c\u4fe1\u606f\u5b89\u5168\u98ce\u9669\u3002", "method": "LLMZ+\u91c7\u7528\u63d0\u793a\u767d\u540d\u5355\u65b9\u6cd5\uff0c\u4ec5\u5141\u8bb8\u7b26\u5408\u9884\u5b9a\u4e49\u7528\u4f8b\u548c\u64cd\u4f5c\u8fb9\u754c\u7684\u4e0a\u4e0b\u6587\u9002\u5f53\u4e14\u5b89\u5168\u7684\u6d88\u606f\u4e0e\u667a\u80fdLLM\u8fdb\u884c\u4ea4\u4e92\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u57fa\u4e8e\u68c0\u6d4b\u7684\u65b9\u6cd5\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cLLMZ+\u5bf9\u6700\u5e38\u89c1\u7684\u8d8a\u72f1\u63d0\u793a\u5177\u6709\u5f3a\u5927\u7684\u62b5\u5fa1\u80fd\u529b\uff0c\u540c\u65f6\u4e0d\u4f1a\u5e72\u6270\u5408\u6cd5\u7684\u4e1a\u52a1\u901a\u4fe1\u3002\u5728\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\uff0c\u8bef\u62a5\u7387\u548c\u6f0f\u62a5\u7387\u5747\u53ef\u964d\u81f30\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7b80\u5316\u4e86\u5b89\u5168\u6846\u67b6\uff0c\u589e\u5f3a\u4e86\u957f\u671f\u5f39\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u7ef4\u6301LLM\u4fe1\u606f\u5b89\u5168\u6240\u9700\u7684\u8d44\u6e90\uff0c\u4e3a\u667a\u80fdAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2509.18565", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18565", "abs": "https://arxiv.org/abs/2509.18565", "authors": ["Mitchell Piehl", "Dillon Wilson", "Ananya Kalita", "Jugal Kalita"], "title": "Solving Math Word Problems Using Estimation Verification and Equation Generation", "comment": "Accepted to IEEE ICMLA 2025", "summary": "Large Language Models (LLMs) excel at various tasks, including\nproblem-solving and question-answering. However, LLMs often find Math Word\nProblems (MWPs) challenging because solving them requires a range of reasoning\nand mathematical abilities with which LLMs seem to struggle. Recent efforts\nhave helped LLMs solve more complex MWPs with improved prompts. This study\nproposes a novel method that initially prompts an LLM to create equations from\na decomposition of the question, followed by using an external symbolic\nequation solver to produce an answer. To ensure the accuracy of the obtained\nanswer, inspired by an established recommendation of math teachers, the LLM is\ninstructed to solve the MWP a second time, but this time with the objective of\nestimating the correct answer instead of solving it exactly. The estimation is\nthen compared to the generated answer to verify. If verification fails, an\niterative rectification process is employed to ensure the correct answer is\neventually found. This approach achieves new state-of-the-art results on\ndatasets used by prior published research on numeric and algebraic MWPs,\nimproving the previous best results by nearly two percent on average. In\naddition, the approach obtains satisfactory results on trigonometric MWPs, a\ntask not previously attempted to the authors' best knowledge. This study also\nintroduces two new datasets, SVAMPClean and Trig300, to further advance the\ntesting of LLMs' reasoning abilities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u89e3\u6570\u5b66\u95ee\u9898\u3001\u4f7f\u7528\u5916\u90e8\u7b26\u53f7\u65b9\u7a0b\u6c42\u89e3\u5668\u4ee5\u53ca\u7b54\u6848\u9a8c\u8bc1\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u6570\u5b66\u5e94\u7528\u9898\u65b9\u9762\u7684\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u89e3\u51b3\u6570\u5b66\u5e94\u7528\u9898\u65f6\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u8fd9\u7c7b\u95ee\u9898\u9700\u8981\u590d\u6742\u7684\u63a8\u7406\u548c\u6570\u5b66\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u6539\u8fdb\u63d0\u793a\u8bcd\u6765\u5e2e\u52a9LLM\u89e3\u51b3\u66f4\u590d\u6742\u7684MWPs\uff0c\u4f46\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u8be5\u65b9\u6cd5\u9996\u5148\u63d0\u793aLLM\u4ece\u95ee\u9898\u5206\u89e3\u4e2d\u521b\u5efa\u65b9\u7a0b\uff0c\u7136\u540e\u4f7f\u7528\u5916\u90e8\u7b26\u53f7\u65b9\u7a0b\u6c42\u89e3\u5668\u751f\u6210\u7b54\u6848\u3002\u4e3a\u786e\u4fdd\u7b54\u6848\u51c6\u786e\u6027\uff0c\u8ba9LLM\u7b2c\u4e8c\u6b21\u89e3\u51b3MWP\u4f46\u76ee\u6807\u662f\u4f30\u8ba1\u6b63\u786e\u7b54\u6848\u800c\u975e\u7cbe\u786e\u6c42\u89e3\uff0c\u901a\u8fc7\u6bd4\u8f83\u4f30\u8ba1\u503c\u4e0e\u751f\u6210\u7b54\u6848\u8fdb\u884c\u9a8c\u8bc1\u3002\u5982\u679c\u9a8c\u8bc1\u5931\u8d25\uff0c\u91c7\u7528\u8fed\u4ee3\u4fee\u6b63\u8fc7\u7a0b\u786e\u4fdd\u6700\u7ec8\u627e\u5230\u6b63\u786e\u7b54\u6848\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5148\u524d\u7814\u7a76\u4f7f\u7528\u7684\u6570\u503c\u548c\u4ee3\u6570MWPs\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u5c06\u4e4b\u524d\u7684\u6700\u4f73\u7ed3\u679c\u5e73\u5747\u63d0\u9ad8\u4e86\u8fd1\u4e24\u4e2a\u767e\u5206\u70b9\u3002\u5728\u4e09\u89d2\u51fd\u6570MWPs\u4e0a\u4e5f\u83b7\u5f97\u4e86\u4ee4\u4eba\u6ee1\u610f\u7684\u7ed3\u679c\uff0c\u8fd9\u662f\u4e4b\u524d\u672a\u5c1d\u8bd5\u8fc7\u7684\u4efb\u52a1\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86LLM\u89e3\u51b3\u6570\u5b66\u5e94\u7528\u9898\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002\u7814\u7a76\u8fd8\u5f15\u5165\u4e86\u4e24\u4e2a\u65b0\u6570\u636e\u96c6SVAMPClean\u548cTrig300\uff0c\u4e3a\u8fdb\u4e00\u6b65\u6d4b\u8bd5LLM\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2509.18633", "categories": ["cs.AI", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2509.18633", "abs": "https://arxiv.org/abs/2509.18633", "authors": ["Yara Mohajerani"], "title": "Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents", "comment": "Submitted and accepted to Tackling Climate Change with Machine\n  Learning workshop at NeurIPS 2025. 5 pages, 1 figure. Source code and\n  documentation available at\n  https://github.com/yaramohajerani/spatial-climate-ABM", "summary": "Climate risk assessment requires modelling complex interactions between\nspatially heterogeneous hazards and adaptive economic systems. We present a\nnovel geospatial agent-based model that integrates climate hazard data with\nevolutionary learning for economic agents. Our framework combines Mesa-based\nspatial modelling with CLIMADA climate impact assessment, introducing adaptive\nlearning behaviours that allow firms to evolve strategies for budget\nallocation, pricing, wages, and risk adaptation through fitness-based selection\nand mutation. We demonstrate the framework using riverine flood projections\nunder RCP8.5 until 2100, showing that evolutionary adaptation enables firms to\nconverge with baseline (no hazard) production levels after decades of\ndisruption due to climate stress. Our results reveal systemic risks where even\nagents that are not directly exposed to floods face impacts through supply\nchain disruptions, with the end-of-century average price of goods 5.6% higher\nunder RCP8.5 compared to the baseline. This open-source framework provides\nfinancial institutions and companies with tools to quantify both direct and\ncascading climate risks while evaluating cost-effective adaptation strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u6c14\u5019\u707e\u5bb3\u6570\u636e\u548c\u8fdb\u5316\u5b66\u4e60\u7684\u5730\u7406\u7a7a\u95f4\u4ee3\u7406\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u6c14\u5019\u98ce\u9669\u5bf9\u7ecf\u6d4e\u7cfb\u7edf\u7684\u5f71\u54cd\u3002", "motivation": "\u6c14\u5019\u98ce\u9669\u8bc4\u4f30\u9700\u8981\u6a21\u62df\u7a7a\u95f4\u5f02\u8d28\u6027\u707e\u5bb3\u4e0e\u9002\u5e94\u6027\u7ecf\u6d4e\u7cfb\u7edf\u4e4b\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\uff0c\u73b0\u6709\u6a21\u578b\u7f3a\u4e4f\u5bf9\u7ecf\u6d4e\u4e3b\u4f53\u9002\u5e94\u6027\u884c\u4e3a\u7684\u5145\u5206\u8003\u8651\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u5c06Mesa\u7a7a\u95f4\u5efa\u6a21\u4e0eCLIMADA\u6c14\u5019\u5f71\u54cd\u8bc4\u4f30\u76f8\u7ed3\u5408\uff0c\u5f15\u5165\u57fa\u4e8e\u9002\u5e94\u5ea6\u7684\u9009\u62e9\u548c\u7a81\u53d8\u673a\u5236\uff0c\u8ba9\u4f01\u4e1a\u80fd\u591f\u8fdb\u5316\u9884\u7b97\u5206\u914d\u3001\u5b9a\u4ef7\u3001\u5de5\u8d44\u548c\u98ce\u9669\u9002\u5e94\u7b56\u7565\u3002", "result": "\u4f7f\u7528RCP8.5\u60c5\u666f\u4e0b\u7684\u6cb3\u6d41\u6d2a\u6c34\u9884\u6d4b\u663e\u793a\uff0c\u8fdb\u5316\u9002\u5e94\u4f7f\u4f01\u4e1a\u80fd\u591f\u5728\u7ecf\u5386\u6570\u5341\u5e74\u6c14\u5019\u538b\u529b\u540e\u6062\u590d\u5230\u57fa\u7ebf\u751f\u4ea7\u6c34\u5e73\uff1b\u672a\u76f4\u63a5\u66b4\u9732\u4e8e\u6d2a\u6c34\u7684\u4f01\u4e1a\u4e5f\u4f1a\u901a\u8fc7\u4f9b\u5e94\u94fe\u4e2d\u65ad\u53d7\u5230\u5f71\u54cd\uff0c\u5230\u4e16\u7eaa\u672b\u5546\u54c1\u5e73\u5747\u4ef7\u683c\u6bd4\u57fa\u7ebf\u9ad85.6%\u3002", "conclusion": "\u8be5\u5f00\u6e90\u6846\u67b6\u4e3a\u91d1\u878d\u673a\u6784\u548c\u516c\u53f8\u63d0\u4f9b\u4e86\u91cf\u5316\u76f4\u63a5\u548c\u7ea7\u8054\u6c14\u5019\u98ce\u9669\u7684\u5de5\u5177\uff0c\u540c\u65f6\u8bc4\u4f30\u6210\u672c\u6548\u76ca\u9ad8\u7684\u9002\u5e94\u7b56\u7565\u3002"}}
{"id": "2509.18667", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18667", "abs": "https://arxiv.org/abs/2509.18667", "authors": ["Qiao Xiao", "Hong Ting Tsang", "Jiaxin Bai"], "title": "TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation", "comment": "16 pages, 2 figures, 4 tables. Submitted to the 2026 18th\n  International Conference on Machine Learning and Computing (ICMLC 2026),\n  under review", "summary": "Graph-based Retrieval-augmented generation (RAG) has become a widely studied\napproach for improving the reasoning, accuracy, and factuality of Large\nLanguage Models. However, many existing graph-based RAG systems overlook the\nhigh cost associated with LLM token usage during graph construction, hindering\nlarge-scale adoption. To address this, we propose TERAG, a simple yet effective\nframework designed to build informative graphs at a significantly lower cost.\nInspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the\nretrieval phase, and we achieve at least 80% of the accuracy of widely used\ngraph-based RAG methods while consuming only 3%-11% of the output tokens.", "AI": {"tldr": "TERAG\u662f\u4e00\u4e2a\u4f4e\u6210\u672c\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u4e2a\u6027\u5316PageRank\u5728\u68c0\u7d22\u9636\u6bb5\u663e\u8457\u51cf\u5c11LLM\u4ee4\u724c\u4f7f\u7528\uff0c\u4ec5\u75283%-11%\u7684\u8f93\u51fa\u4ee4\u724c\u8fbe\u5230\u4e3b\u6d41\u56feRAG\u65b9\u6cd580%\u4ee5\u4e0a\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u56feRAG\u7cfb\u7edf\u5728\u6784\u5efa\u56fe\u65f6LLM\u4ee4\u724c\u4f7f\u7528\u6210\u672c\u8fc7\u9ad8\uff0c\u963b\u788d\u4e86\u5927\u89c4\u6a21\u5e94\u7528\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7ecf\u6d4e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u53d7HippoRAG\u542f\u53d1\uff0c\u5728\u68c0\u7d22\u9636\u6bb5\u5f15\u5165\u4e2a\u6027\u5316PageRank(PPR)\u6765\u6784\u5efa\u4fe1\u606f\u4e30\u5bcc\u7684\u56fe\uff0c\u5927\u5e45\u964d\u4f4e\u4ee4\u724c\u6d88\u8017\u3002", "result": "TERAG\u4ec5\u6d88\u80173%-11%\u7684\u8f93\u51fa\u4ee4\u724c\uff0c\u4f46\u80fd\u8fbe\u5230\u5e7f\u6cdb\u4f7f\u7528\u7684\u56feRAG\u65b9\u6cd5\u81f3\u5c1180%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "TERAG\u8bc1\u660e\u4e86\u5728\u663e\u8457\u964d\u4f4e\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u56feRAG\u7684\u5927\u89c4\u6a21\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.18681", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18681", "abs": "https://arxiv.org/abs/2509.18681", "authors": ["Nicolas Valot", "Louis Fabre", "Benjamin Lesage", "Ammar Mechouche", "Claire Pagetti"], "title": "Implementation of airborne ML models with semantics preservation", "comment": null, "summary": "Machine Learning (ML) may offer new capabilities in airborne systems.\nHowever, as any piece of airborne systems, ML-based systems will be required to\nguarantee their safe operation. Thus, their development will have to be\ndemonstrated to be compliant with the adequate guidance. So far, the European\nUnion Aviation Safety Agency (EASA) has published a concept paper and an\nEUROCAE/SAE group is preparing ED-324. Both approaches delineate high-level\nobjectives to confirm the ML model achieves its intended function and maintains\ntraining performance in the target environment. The paper aims to clarify the\ndifference between an ML model and its corresponding unambiguous description,\nreferred to as the Machine Learning Model Description (MLMD). It then refines\nthe essential notion of semantics preservation to ensure the accurate\nreplication of the model. We apply our contributions to several industrial use\ncases to build and compare several target models.", "AI": {"tldr": "\u672c\u6587\u65e8\u5728\u6f84\u6e05\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0e\u5176\u660e\u786e\u63cf\u8ff0\u4e4b\u95f4\u7684\u533a\u522b\uff0c\u5e76\u5b8c\u5584\u8bed\u4e49\u4fdd\u6301\u7684\u6982\u5ff5\u4ee5\u786e\u4fdd\u6a21\u578b\u7684\u51c6\u786e\u590d\u5236\uff0c\u5e94\u7528\u4e8e\u591a\u4e2a\u5de5\u4e1a\u7528\u4f8b\u6765\u6784\u5efa\u548c\u6bd4\u8f83\u76ee\u6807\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u5728\u822a\u7a7a\u7cfb\u7edf\u4e2d\u5e94\u7528\u7684\u589e\u52a0\uff0c\u9700\u8981\u786e\u4fddML\u7cfb\u7edf\u7684\u5b89\u5168\u64cd\u4f5c\u5e76\u7b26\u5408\u76f8\u5173\u6307\u5bfc\u6807\u51c6\u3002EASA\u548cEUROCAE/SAE\u5df2\u53d1\u5e03\u9ad8\u7ea7\u76ee\u6807\uff0c\u4f46\u9700\u8981\u66f4\u5177\u4f53\u7684\u65b9\u6cd5\u6765\u9a8c\u8bc1ML\u6a21\u578b\u5728\u76ee\u6807\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63cf\u8ff0\uff08MLMD\uff09\u6765\u660e\u786e\u6a21\u578b\u4e0e\u5176\u63cf\u8ff0\u7684\u533a\u522b\uff0c\u5b8c\u5584\u8bed\u4e49\u4fdd\u6301\u6982\u5ff5\uff0c\u5e76\u5728\u591a\u4e2a\u5de5\u4e1a\u7528\u4f8b\u4e2d\u5e94\u7528\u8fd9\u4e9b\u6982\u5ff5\u6765\u6784\u5efa\u548c\u6bd4\u8f83\u76ee\u6807\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u4e86MLMD\u7684\u6982\u5ff5\u548c\u8bed\u4e49\u4fdd\u6301\u7684\u7ec6\u5316\u5b9a\u4e49\uff0c\u901a\u8fc7\u5de5\u4e1a\u7528\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u786e\u4fddML\u6a21\u578b\u5728\u76ee\u6807\u73af\u5883\u4e2d\u51c6\u786e\u590d\u5236\u5176\u8bad\u7ec3\u6027\u80fd\u3002", "conclusion": "MLMD\u548c\u8bed\u4e49\u4fdd\u6301\u6982\u5ff5\u7684\u660e\u786e\u5316\u6709\u52a9\u4e8e\u786e\u4fddML\u6a21\u578b\u5728\u822a\u7a7a\u7b49\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u7684\u5408\u89c4\u6027\u548c\u5b89\u5168\u6027\uff0c\u4e3aML\u7cfb\u7edf\u7684\u8ba4\u8bc1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2509.18690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18690", "abs": "https://arxiv.org/abs/2509.18690", "authors": ["Zhiyu Kan", "Wensheng Gan", "Zhenlian Qi", "Philip S. Yu"], "title": "Advances in Large Language Models for Medicine", "comment": "Preprint. 5 figures, 4 tables", "summary": "Artificial intelligence (AI) technology has advanced rapidly in recent years,\nwith large language models (LLMs) emerging as a significant breakthrough. LLMs\nare increasingly making an impact across various industries, with the medical\nfield standing out as the most prominent application area. This paper\nsystematically reviews the up-to-date research progress of LLMs in the medical\nfield, providing an in-depth analysis of training techniques for large medical\nmodels, their adaptation in healthcare settings, related applications, as well\nas their strengths and limitations. Furthermore, it innovatively categorizes\nmedical LLMs into three distinct types based on their training methodologies\nand classifies their evaluation approaches into two categories. Finally, the\nstudy proposes solutions to existing challenges and outlines future research\ndirections based on identified issues in the field of medical LLMs. By\nsystematically reviewing previous and advanced research findings, we aim to\nhighlight the necessity of developing medical LLMs, provide a deeper\nunderstanding of their current state of development, and offer clear guidance\nfor subsequent research.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\uff0c\u5305\u62ec\u8bad\u7ec3\u6280\u672f\u3001\u533b\u7597\u5e94\u7528\u3001\u4f18\u52bf\u5c40\u9650\uff0c\u5e76\u5bf9\u533b\u7597LLMs\u8fdb\u884c\u5206\u7c7b\u548c\u8bc4\u4f30\u65b9\u6cd5\u5206\u7c7b\uff0c\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740AI\u6280\u672f\u5feb\u901f\u53d1\u5c55\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u5c55\u73b0\u51fa\u5de8\u5927\u5e94\u7528\u6f5c\u529b\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u5f53\u524d\u7814\u7a76\u8fdb\u5c55\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u6df1\u5165\u5206\u6790\u533b\u7597\u5927\u6a21\u578b\u7684\u8bad\u7ec3\u6280\u672f\u3001\u9002\u5e94\u65b9\u6cd5\u3001\u5e94\u7528\u573a\u666f\uff0c\u5e76\u521b\u65b0\u6027\u5730\u5c06\u533b\u7597LLMs\u5206\u4e3a\u4e09\u7c7b\uff0c\u8bc4\u4f30\u65b9\u6cd5\u5206\u4e3a\u4e24\u7c7b\u3002", "result": "\u5168\u9762\u68b3\u7406\u4e86\u533b\u7597LLMs\u7684\u53d1\u5c55\u73b0\u72b6\uff0c\u8bc6\u522b\u4e86\u73b0\u6709\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u533b\u7597LLMs\u5177\u6709\u91cd\u8981\u53d1\u5c55\u5fc5\u8981\u6027\uff0c\u672c\u6587\u4e3a\u5176\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u7406\u89e3\u548c\u6e05\u6670\u7684\u6307\u5bfc\u65b9\u5411\u3002"}}
{"id": "2509.18710", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18710", "abs": "https://arxiv.org/abs/2509.18710", "authors": ["Yanjie Fu", "Dongjie Wang", "Wangyang Ying", "Xiangliang Zhang", "Huan Liu", "Jian Pei"], "title": "Autonomous Data Agents: A New Opportunity for Smart Data", "comment": null, "summary": "As data continues to grow in scale and complexity, preparing, transforming,\nand analyzing it remains labor-intensive, repetitive, and difficult to scale.\nSince data contains knowledge and AI learns knowledge from it, the alignment\nbetween AI and data is essential. However, data is often not structured in ways\nthat are optimal for AI utilization. Moreover, an important question arises:\nhow much knowledge can we pack into data through intensive data operations?\nAutonomous data agents (DataAgents), which integrate LLM reasoning with task\ndecomposition, action reasoning and grounding, and tool calling, can\nautonomously interpret data task descriptions, decompose tasks into subtasks,\nreason over actions, ground actions into python code or tool calling, and\nexecute operations. Unlike traditional data management and engineering tools,\nDataAgents dynamically plan workflows, call powerful tools, and adapt to\ndiverse data tasks at scale. This report argues that DataAgents represent a\nparadigm shift toward autonomous data-to-knowledge systems. DataAgents are\ncapable of handling collection, integration, preprocessing, selection,\ntransformation, reweighing, augmentation, reprogramming, repairs, and\nretrieval. Through these capabilities, DataAgents transform complex and\nunstructured data into coherent and actionable knowledge. We first examine why\nthe convergence of agentic AI and data-to-knowledge systems has emerged as a\ncritical trend. We then define the concept of DataAgents and discuss their\narchitectural design, training strategies, as well as the new skills and\ncapabilities they enable. Finally, we call for concerted efforts to advance\naction workflow optimization, establish open datasets and benchmark ecosystems,\nsafeguard privacy, balance efficiency with scalability, and develop trustworthy\nDataAgent guardrails to prevent malicious actions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u4e3b\u6570\u636e\u4ee3\u7406\uff08DataAgents\uff09\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u96c6\u6210LLM\u63a8\u7406\u4e0e\u4efb\u52a1\u5206\u89e3\u3001\u884c\u52a8\u63a8\u7406\u548c\u5de5\u5177\u8c03\u7528\uff0c\u5b9e\u73b0\u4ece\u6570\u636e\u5230\u77e5\u8bc6\u7684\u81ea\u52a8\u5316\u8f6c\u6362\uff0c\u4ee3\u8868\u6570\u636e\u7ba1\u7406\u5411\u81ea\u4e3b\u7cfb\u7edf\u7684\u8303\u5f0f\u8f6c\u53d8\u3002", "motivation": "\u968f\u7740\u6570\u636e\u89c4\u6a21\u548c\u590d\u6742\u6027\u7684\u589e\u957f\uff0c\u6570\u636e\u51c6\u5907\u3001\u8f6c\u6362\u548c\u5206\u6790\u5de5\u4f5c\u4ecd\u7136\u52b3\u52a8\u5bc6\u96c6\u3001\u91cd\u590d\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u6570\u636e\u4e0eAI\u4e4b\u95f4\u7684\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6570\u636e\u7ed3\u6784\u5f80\u5f80\u4e0d\u9002\u5408AI\u5229\u7528\u3002", "method": "DataAgents\u901a\u8fc7\u52a8\u6001\u89c4\u5212\u5de5\u4f5c\u6d41\u3001\u8c03\u7528\u5f3a\u5927\u5de5\u5177\u548c\u9002\u5e94\u591a\u6837\u5316\u6570\u636e\u4efb\u52a1\uff0c\u80fd\u591f\u5904\u7406\u6570\u636e\u6536\u96c6\u3001\u96c6\u6210\u3001\u9884\u5904\u7406\u3001\u9009\u62e9\u3001\u8f6c\u6362\u3001\u91cd\u65b0\u52a0\u6743\u3001\u589e\u5f3a\u3001\u91cd\u7f16\u7a0b\u3001\u4fee\u590d\u548c\u68c0\u7d22\u7b49\u64cd\u4f5c\u3002", "result": "DataAgents\u80fd\u591f\u5c06\u590d\u6742\u548c\u975e\u7ed3\u6784\u5316\u6570\u636e\u8f6c\u5316\u4e3a\u8fde\u8d2f\u4e14\u53ef\u64cd\u4f5c\u7684\u77e5\u8bc6\uff0c\u4e3a\u6570\u636e\u5230\u77e5\u8bc6\u7cfb\u7edf\u63d0\u4f9b\u81ea\u4e3b\u5316\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u9700\u8981\u534f\u540c\u52aa\u529b\u63a8\u8fdb\u884c\u52a8\u5de5\u4f5c\u6d41\u4f18\u5316\u3001\u5efa\u7acb\u5f00\u653e\u6570\u636e\u96c6\u548c\u57fa\u51c6\u751f\u6001\u7cfb\u7edf\u3001\u4fdd\u62a4\u9690\u79c1\u3001\u5e73\u8861\u6548\u7387\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u5f00\u53d1\u53ef\u4fe1\u8d56\u7684DataAgent\u9632\u62a4\u673a\u5236\u4ee5\u9632\u6b62\u6076\u610f\u884c\u4e3a\u3002"}}
{"id": "2509.18771", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18771", "abs": "https://arxiv.org/abs/2509.18771", "authors": ["Xingkun Yin", "Kaibin Huang", "Dong In Kim", "Hongyang Du"], "title": "Experience Scaling: Post-Deployment Evolution For Large Language Models", "comment": null, "summary": "Scaling model size, training data, and compute power have driven advances in\nlarge language models (LLMs), but these approaches are reaching saturation as\nhuman-generated text is exhausted and further gains diminish. We propose\nexperience scaling, a framework for continuous post-deployment evolution for\nLLMs through autonomous interaction with the environment and collaborative\nsharing of accumulated experience. The framework captures raw interactions,\ndistills them into compact, reusable knowledge, and periodically refines stored\ncontent to preserve relevance and efficiency. We validate the framework in\nsimulated real-world scenarios involving generalization to previously unseen\nbut related tasks, repetitive queries, and over-saturated knowledge stores.\nAcross all settings, experience scaling improves accuracy, sustains performance\nover time, and maintains gains when applied to novel situations. These results\ndemonstrate that structured post-deployment learning can extend LLM\ncapabilities beyond the limits of static human-generated data, offering a\nscalable path for continued intelligence progress.", "AI": {"tldr": "\u63d0\u51fa\u7ecf\u9a8c\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u4e3b\u73af\u5883\u4ea4\u4e92\u548c\u534f\u4f5c\u7ecf\u9a8c\u5171\u4eab\u5b9e\u73b0LLM\u7684\u6301\u7eed\u8fdb\u5316\uff0c\u7a81\u7834\u9759\u6001\u4eba\u7c7b\u751f\u6210\u6570\u636e\u7684\u9650\u5236", "motivation": "\u4f20\u7edf\u901a\u8fc7\u6269\u5927\u6a21\u578b\u89c4\u6a21\u3001\u8bad\u7ec3\u6570\u636e\u548c\u8ba1\u7b97\u80fd\u529b\u7684\u65b9\u6cd5\u5df2\u63a5\u8fd1\u9971\u548c\uff0c\u4eba\u7c7b\u751f\u6210\u6587\u672c\u8d44\u6e90\u8017\u5c3d\uff0c\u8fdb\u4e00\u6b65\u589e\u76ca\u9012\u51cf", "method": "\u7ecf\u9a8c\u6269\u5c55\u6846\u67b6\uff1a\u6355\u83b7\u539f\u59cb\u4ea4\u4e92\u3001\u63d0\u70bc\u4e3a\u7d27\u51d1\u53ef\u91cd\u7528\u77e5\u8bc6\u3001\u5b9a\u671f\u4f18\u5316\u5b58\u50a8\u5185\u5bb9\u4ee5\u4fdd\u6301\u76f8\u5173\u6027\u548c\u6548\u7387", "result": "\u5728\u6a21\u62df\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\uff0c\u5305\u62ec\u6cdb\u5316\u5230\u672a\u89c1\u76f8\u5173\u4efb\u52a1\u3001\u91cd\u590d\u67e5\u8be2\u548c\u8fc7\u9971\u548c\u77e5\u8bc6\u5b58\u50a8\uff0c\u7ecf\u9a8c\u6269\u5c55\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3001\u7ef4\u6301\u6027\u80fd\u5e76\u4fdd\u6301\u5bf9\u65b0\u60c5\u51b5\u7684\u589e\u76ca", "conclusion": "\u7ed3\u6784\u5316\u90e8\u7f72\u540e\u5b66\u4e60\u53ef\u4ee5\u6269\u5c55LLM\u80fd\u529b\u8d85\u8d8a\u9759\u6001\u4eba\u7c7b\u751f\u6210\u6570\u636e\u7684\u9650\u5236\uff0c\u4e3a\u6301\u7eed\u667a\u80fd\u8fdb\u6b65\u63d0\u4f9b\u53ef\u6269\u5c55\u8def\u5f84"}}
{"id": "2509.18787", "categories": ["cs.AI", "C.2.4"], "pdf": "https://arxiv.org/pdf/2509.18787", "abs": "https://arxiv.org/abs/2509.18787", "authors": ["Luca Muscariello", "Vijoy Pandey", "Ramiz Polic"], "title": "The AGNTCY Agent Directory Service: Architecture and Implementation", "comment": null, "summary": "The Agent Directory Service (ADS) is a distributed directory for the\ndiscovery of AI agent capabilities, metadata, and provenance. It leverages\ncontent-addressed storage, hierarchical taxonomies, and cryptographic signing\nto enable efficient, verifiable, and multi-dimensional discovery across\nheterogeneous Multi-Agent Systems (MAS). Built on the Open Agentic Schema\nFramework (OASF), ADS decouples capability indexing from content location\nthrough a two-level mapping realized over a Kademlia-based Distributed Hash\nTable (DHT). It reuses mature OCI / ORAS infrastructure for artifact\ndistribution, integrates Sigstore for provenance, and supports schema-driven\nextensibility for emerging agent modalities (LLM prompt agents, MCP servers,\nA2A-enabled components). This paper formalizes the architectural model,\ndescribes storage and discovery layers, explains security and performance\nproperties, and positions ADS within the broader landscape of emerging agent\nregistry and interoperability initiatives.", "AI": {"tldr": "ADS\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u76ee\u5f55\u670d\u52a1\uff0c\u7528\u4e8e\u53d1\u73b0AI\u4ee3\u7406\u7684\u80fd\u529b\u3001\u5143\u6570\u636e\u548c\u6765\u6e90\uff0c\u91c7\u7528\u5185\u5bb9\u5bfb\u5740\u5b58\u50a8\u3001\u5c42\u6b21\u5206\u7c7b\u6cd5\u548c\u52a0\u5bc6\u7b7e\u540d\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u9a8c\u8bc1\u7684\u591a\u7ef4\u5ea6\u53d1\u73b0\u3002", "motivation": "\u89e3\u51b3\u5f02\u6784\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u4ee3\u7406\u80fd\u529b\u53d1\u73b0\u3001\u5143\u6570\u636e\u7ba1\u7406\u548c\u6765\u6e90\u9a8c\u8bc1\u7684\u95ee\u9898\uff0c\u4fc3\u8fdb\u4ee3\u7406\u95f4\u7684\u4e92\u64cd\u4f5c\u6027\u3002", "method": "\u57fa\u4e8eOpen Agentic Schema Framework\u6784\u5efa\uff0c\u91c7\u7528\u4e24\u7ea7\u6620\u5c04\u7684Kademlia\u5206\u5e03\u5f0f\u54c8\u5e0c\u8868\uff0c\u91cd\u7528OCI/ORAS\u57fa\u7840\u8bbe\u65bd\u8fdb\u884c\u5de5\u4ef6\u5206\u53d1\uff0c\u96c6\u6210Sigstore\u8fdb\u884c\u6765\u6e90\u9a8c\u8bc1\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u53ef\u9a8c\u8bc1\u7684\u4ee3\u7406\u80fd\u529b\u53d1\u73b0\u7cfb\u7edf\uff0c\u652f\u6301\u65b0\u5174\u4ee3\u7406\u6a21\u5f0f\uff08\u5982LLM\u63d0\u793a\u4ee3\u7406\u3001MCP\u670d\u52a1\u5668\u7b49\uff09\u7684\u6a21\u5f0f\u9a71\u52a8\u6269\u5c55\u6027\u3002", "conclusion": "ADS\u4e3a\u65b0\u5174\u4ee3\u7406\u6ce8\u518c\u548c\u4e92\u64cd\u4f5c\u6027\u5021\u8bae\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u67b6\u6784\u6a21\u578b\uff0c\u5177\u6709\u5b89\u5168\u6027\u548c\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2509.18836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18836", "abs": "https://arxiv.org/abs/2509.18836", "authors": ["Dennis Gross", "Helge Spieker", "Arnaud Gotlieb"], "title": "Bounded PCTL Model Checking of Large Language Model Outputs", "comment": "ICTAI 2025", "summary": "In this paper, we introduce LLMCHECKER, a model-checking-based verification\nmethod to verify the probabilistic computation tree logic (PCTL) properties of\nan LLM text generation process. We empirically show that only a limited number\nof tokens are typically chosen during text generation, which are not always the\nsame. This insight drives the creation of $\\alpha$-$k$-bounded text generation,\nnarrowing the focus to the $\\alpha$ maximal cumulative probability on the\ntop-$k$ tokens at every step of the text generation process. Our verification\nmethod considers an initial string and the subsequent top-$k$ tokens while\naccommodating diverse text quantification methods, such as evaluating text\nquality and biases. The threshold $\\alpha$ further reduces the selected tokens,\nonly choosing those that exceed or meet it in cumulative probability.\nLLMCHECKER then allows us to formally verify the PCTL properties of\n$\\alpha$-$k$-bounded LLMs. We demonstrate the applicability of our method in\nseveral LLMs, including Llama, Gemma, Mistral, Genstruct, and BERT. To our\nknowledge, this is the first time PCTL-based model checking has been used to\ncheck the consistency of the LLM text generation process.", "AI": {"tldr": "LLMCHECKER\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u68c0\u67e5\u7684\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u7528\u4e8e\u9a8c\u8bc1LLM\u6587\u672c\u751f\u6210\u8fc7\u7a0b\u7684\u6982\u7387\u8ba1\u7b97\u6811\u903b\u8f91(PCTL)\u5c5e\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u03b1-k\u6709\u754c\u6587\u672c\u751f\u6210\u6765\u9650\u5236\u9a8c\u8bc1\u8303\u56f4\uff0c\u91cd\u70b9\u5173\u6ce8\u6bcf\u4e2a\u751f\u6210\u6b65\u9aa4\u4e2dtop-k\u6807\u8bb0\u7684\u7d2f\u79ef\u6982\u7387\u3002", "motivation": "\u73b0\u6709LLM\u6587\u672c\u751f\u6210\u8fc7\u7a0b\u7f3a\u4e4f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u65e0\u6cd5\u786e\u4fdd\u751f\u6210\u6587\u672c\u7684\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\u3002\u4f5c\u8005\u53d1\u73b0\u6587\u672c\u751f\u6210\u8fc7\u7a0b\u4e2d\u901a\u5e38\u53ea\u6709\u6709\u9650\u6570\u91cf\u7684\u6807\u8bb0\u88ab\u9009\u62e9\uff0c\u8fd9\u4e3a\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002", "method": "\u63d0\u51fa\u03b1-k\u6709\u754c\u6587\u672c\u751f\u6210\u65b9\u6cd5\uff0c\u5728\u6bcf\u4e2a\u751f\u6210\u6b65\u9aa4\u4e2d\u53ea\u8003\u8651\u7d2f\u79ef\u6982\u7387\u8d85\u8fc7\u9608\u503c\u03b1\u7684top-k\u6807\u8bb0\u3002LLMCHECKER\u57fa\u4e8e\u6a21\u578b\u68c0\u67e5\u6280\u672f\uff0c\u80fd\u591f\u9a8c\u8bc1PCTL\u5c5e\u6027\uff0c\u652f\u6301\u591a\u79cd\u6587\u672c\u91cf\u5316\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2aLLM\u6a21\u578b\uff08\u5305\u62ecLlama\u3001Gemma\u3001Mistral\u3001Genstruct\u548cBERT\uff09\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u9002\u7528\u6027\u3002\u8fd9\u662f\u9996\u6b21\u5c06PCTL\u6a21\u578b\u68c0\u67e5\u5e94\u7528\u4e8eLLM\u6587\u672c\u751f\u6210\u8fc7\u7a0b\u7684\u4e00\u81f4\u6027\u9a8c\u8bc1\u3002", "conclusion": "LLMCHECKER\u4e3aLLM\u6587\u672c\u751f\u6210\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6846\u67b6\uff0c\u80fd\u591f\u786e\u4fdd\u751f\u6210\u6587\u672c\u7684\u8d28\u91cf\u548c\u4e00\u81f4\u6027\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7a7a\u767d\u3002"}}
{"id": "2509.18846", "categories": ["cs.AI", "I.2.6; I.2.7; J.3"], "pdf": "https://arxiv.org/pdf/2509.18846", "abs": "https://arxiv.org/abs/2509.18846", "authors": ["Hong-Jie Dai", "Zheng-Hao Li", "An-Tai Lu", "Bo-Tsz Shain", "Ming-Ta Li", "Tatheer Hussain Mir", "Kuang-Te Wang", "Min-I Su", "Pei-Kang Liu", "Ming-Ju Tsai"], "title": "Model selection meets clinical semantics: Optimizing ICD-10-CM prediction via LLM-as-Judge evaluation, redundancy-aware sampling, and section-aware fine-tuning", "comment": "28 Pages, 4 Figures, 2 Tables", "summary": "Accurate International Classification of Diseases (ICD) coding is critical\nfor clinical documentation, billing, and healthcare analytics, yet it remains a\nlabour-intensive and error-prone task. Although large language models (LLMs)\nshow promise in automating ICD coding, their challenges in base model\nselection, input contextualization, and training data redundancy limit their\neffectiveness. We propose a modular framework for ICD-10 Clinical Modification\n(ICD-10-CM) code prediction that addresses these challenges through principled\nmodel selection, redundancy-aware data sampling, and structured input design.\nThe framework integrates an LLM-as-judge evaluation protocol with Plackett-Luce\naggregation to assess and rank open-source LLMs based on their intrinsic\ncomprehension of ICD-10-CM code definitions. We introduced embedding-based\nsimilarity measures, a redundancy-aware sampling strategy to remove\nsemantically duplicated discharge summaries. We leverage structured discharge\nsummaries from Taiwanese hospitals to evaluate contextual effects and examine\nsection-wise content inclusion under universal and section-specific modelling\nparadigms. Experiments across two institutional datasets demonstrate that the\nselected base model after fine-tuning consistently outperforms baseline LLMs in\ninternal and external evaluations. Incorporating more clinical sections\nconsistently improves prediction performance. This study uses open-source LLMs\nto establish a practical and principled approach to ICD-10-CM code prediction.\nThe proposed framework provides a scalable, institution-ready solution for\nreal-world deployment of automated medical coding systems by combining informed\nmodel selection, efficient data refinement, and context-aware prompting.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\u7528\u4e8eICD-10-CM\u7f16\u7801\u9884\u6d4b\uff0c\u901a\u8fc7\u539f\u5219\u6027\u6a21\u578b\u9009\u62e9\u3001\u5197\u4f59\u611f\u77e5\u6570\u636e\u91c7\u6837\u548c\u7ed3\u6784\u5316\u8f93\u5165\u8bbe\u8ba1\u6765\u89e3\u51b3\u73b0\u6709LLM\u5728\u533b\u7597\u7f16\u7801\u4e2d\u7684\u6311\u6218\u3002", "motivation": "ICD\u7f16\u7801\u5bf9\u4e34\u5e8a\u6587\u6863\u3001\u8ba1\u8d39\u548c\u533b\u7597\u5206\u6790\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u4ecd\u662f\u52b3\u52a8\u5bc6\u96c6\u578b\u4e14\u6613\u51fa\u9519\u7684\u4efb\u52a1\u3002LLM\u5728\u81ea\u52a8\u5316ICD\u7f16\u7801\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u57fa\u7840\u6a21\u578b\u9009\u62e9\u3001\u8f93\u5165\u4e0a\u4e0b\u6587\u5316\u548c\u8bad\u7ec3\u6570\u636e\u5197\u4f59\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5305\u62ec\uff1a1\uff09\u4f7f\u7528LLM-as-judge\u8bc4\u4f30\u534f\u8bae\u548cPlackett-Luce\u805a\u5408\u8bc4\u4f30\u5f00\u6e90LLM\uff1b2\uff09\u5f15\u5165\u5d4c\u5165\u76f8\u4f3c\u6027\u5ea6\u91cf\u548c\u5197\u4f59\u611f\u77e5\u91c7\u6837\u7b56\u7565\uff1b3\uff09\u5229\u7528\u53f0\u6e7e\u533b\u9662\u7684\u7ed3\u6784\u5316\u51fa\u9662\u6458\u8981\u8bc4\u4f30\u4e0a\u4e0b\u6587\u6548\u679c\u3002", "result": "\u5728\u4e24\u4e2a\u673a\u6784\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u7ecf\u8fc7\u5fae\u8c03\u7684\u9009\u62e9\u57fa\u7840\u6a21\u578b\u5728\u5185\u90e8\u548c\u5916\u90e8\u8bc4\u4f30\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebfLLM\u3002\u5305\u542b\u66f4\u591a\u4e34\u5e8a\u90e8\u5206\u6301\u7eed\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4f7f\u7528\u5f00\u6e90LLM\u5efa\u7acb\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u539f\u5219\u6027\u7684ICD-10-CM\u7f16\u7801\u9884\u6d4b\u65b9\u6cd5\uff0c\u4e3a\u81ea\u52a8\u5316\u533b\u7597\u7f16\u7801\u7cfb\u7edf\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u673a\u6784\u5c31\u7eea\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.18849", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18849", "abs": "https://arxiv.org/abs/2509.18849", "authors": ["Wenke Huang", "Quan Zhang", "Yiyang Fang", "Jian Liang", "Xuankun Rong", "Huanjin Yao", "Guancheng Wan", "Ke Liang", "Wenwen He", "Mingjun Li", "Leszek Rutkowski", "Mang Ye", "Bo Du", "Dacheng Tao"], "title": "MAPO: Mixed Advantage Policy Optimization", "comment": null, "summary": "Recent advances in reinforcement learning for foundation models, such as\nGroup Relative Policy Optimization (GRPO), have significantly improved the\nperformance of foundation models on reasoning tasks. Notably, the advantage\nfunction serves as a central mechanism in GRPO for ranking the trajectory\nimportance. However, existing explorations encounter both advantage reversion\nand advantage mirror problems, which hinder the reasonable advantage allocation\nacross different query samples. In this work, we propose an easy but effective\nGRPO strategy, Mixed Advantage Policy Optimization (MAPO). We reveal that the\ntrajectory appears with different certainty and propose the advantage percent\ndeviation for samples with high-certainty trajectories. Furthermore, we\ndynamically reweight the advantage function for samples with varying trajectory\ncertainty, thereby adaptively configuring the advantage function to account for\nsample-specific characteristics. Comparison with related state-of-the-art\nmethods, along with ablation studies on different advantage variants, validates\nthe effectiveness of our approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMAPO\uff08\u6df7\u5408\u4f18\u52bf\u7b56\u7565\u4f18\u5316\uff09\u7684\u65b0GRPO\u7b56\u7565\uff0c\u901a\u8fc7\u52a8\u6001\u91cd\u52a0\u6743\u4f18\u52bf\u51fd\u6570\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u4f18\u52bf\u53cd\u8f6c\u548c\u4f18\u52bf\u955c\u50cf\u95ee\u9898\uff0c\u4ece\u800c\u66f4\u5408\u7406\u5730\u5206\u914d\u4e0d\u540c\u67e5\u8be2\u6837\u672c\u95f4\u7684\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u7684GRPO\u65b9\u6cd5\u5728\u57fa\u7840\u6a21\u578b\u63a8\u7406\u4efb\u52a1\u4e2d\u9762\u4e34\u4f18\u52bf\u53cd\u8f6c\u548c\u4f18\u52bf\u955c\u50cf\u95ee\u9898\uff0c\u5bfc\u81f4\u4e0d\u540c\u67e5\u8be2\u6837\u672c\u95f4\u7684\u4f18\u52bf\u5206\u914d\u4e0d\u5408\u7406\uff0c\u5f71\u54cd\u4e86\u7b56\u7565\u4f18\u5316\u7684\u6548\u679c\u3002", "method": "\u63d0\u51faMAPO\u65b9\u6cd5\uff0c\u8bc6\u522b\u8f68\u8ff9\u7684\u4e0d\u540c\u786e\u5b9a\u6027\uff0c\u4e3a\u9ad8\u786e\u5b9a\u6027\u8f68\u8ff9\u6837\u672c\u5f15\u5165\u4f18\u52bf\u767e\u5206\u6bd4\u504f\u5dee\uff0c\u5e76\u6839\u636e\u8f68\u8ff9\u786e\u5b9a\u6027\u52a8\u6001\u91cd\u52a0\u6743\u4f18\u52bf\u51fd\u6570\uff0c\u4f7f\u5176\u80fd\u591f\u81ea\u9002\u5e94\u5730\u8003\u8651\u6837\u672c\u7279\u5b9a\u7279\u5f81\u3002", "result": "\u901a\u8fc7\u4e0e\u76f8\u5173\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6bd4\u8f83\u4ee5\u53ca\u5bf9\u4e0d\u540c\u4f18\u52bf\u53d8\u4f53\u7684\u6d88\u878d\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "MAPO\u662f\u4e00\u79cd\u7b80\u5355\u4f46\u6709\u6548\u7684GRPO\u7b56\u7565\u6539\u8fdb\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u8f68\u8ff9\u786e\u5b9a\u6027\u5dee\u5f02\uff0c\u63d0\u5347\u57fa\u7840\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2509.18864", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18864", "abs": "https://arxiv.org/abs/2509.18864", "authors": ["Yingxin Li", "Jianbo Zhao", "Xueyu Ren", "Jie Tang", "Wangjie You", "Xu Chen", "Kan Zhou", "Chao Feng", "Jiao Ran", "Yuan Meng", "Zhi Wang"], "title": "Conf-Profile: A Confidence-Driven Reasoning Paradigm for Label-Free User Profiling", "comment": null, "summary": "User profiling, as a core technique for user understanding, aims to infer\nstructural attributes from user information. Large Language Models (LLMs)\nprovide a promising avenue for user profiling, yet the progress is hindered by\nthe lack of comprehensive benchmarks. To bridge this gap, we propose\nProfileBench, an industrial benchmark derived from a real-world video platform,\nencompassing heterogeneous user data and a well-structured profiling taxonomy.\nHowever, the profiling task remains challenging due to the difficulty of\ncollecting large-scale ground-truth labels, and the heterogeneous and noisy\nuser information can compromise the reliability of LLMs. To approach label-free\nand reliable user profiling, we propose a Confidence-driven Profile reasoning\nframework Conf-Profile, featuring a two-stage paradigm. We first synthesize\nhigh-quality labels by leveraging advanced LLMs with confidence hints, followed\nby confidence-weighted voting for accuracy improvement and confidence\ncalibration for a balanced distribution. The multiple profile results,\nrationales, and confidence scores are aggregated and distilled into a\nlightweight LLM. We further enhance the reasoning ability via confidence-guided\nunsupervised reinforcement learning, which exploits confidence for difficulty\nfiltering, quasi-ground truth voting, and reward weighting. Experimental\nresults demonstrate that Conf-Profile delivers substantial performance through\nthe two-stage training, improving F1 by 13.97 on Qwen3-8B.", "AI": {"tldr": "\u63d0\u51fa\u4e86ProfileBench\u57fa\u51c6\u548cConf-Profile\u6846\u67b6\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u9a71\u52a8\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\u89e3\u51b3\u7528\u6237\u753b\u50cf\u4e2d\u7684\u6807\u7b7e\u7a00\u7f3a\u548c\u566a\u58f0\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u7528\u6237\u753b\u50cf\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u7528\u6237\u753b\u50cf\u4f5c\u4e3a\u7528\u6237\u7406\u89e3\u7684\u6838\u5fc3\u6280\u672f\uff0cLLMs\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\uff0c\u4f46\u7f3a\u4e4f\u5168\u9762\u57fa\u51c6\u548c\u9762\u4e34\u6807\u7b7e\u7a00\u7f3a\u3001\u6570\u636e\u5f02\u6784\u566a\u58f0\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faConf-Profile\u6846\u67b6\uff1a1\uff09\u5229\u7528\u7f6e\u4fe1\u5ea6\u63d0\u793a\u5408\u6210\u9ad8\u8d28\u91cf\u6807\u7b7e\uff1b2\uff09\u7f6e\u4fe1\u5ea6\u52a0\u6743\u6295\u7968\u548c\u6821\u51c6\uff1b3\uff09\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u96be\u5ea6\u8fc7\u6ee4\u548c\u5956\u52b1\u52a0\u6743\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aConf-Profile\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5728Qwen3-8B\u6a21\u578b\u4e0aF1\u5206\u6570\u63d0\u9ad8\u4e8613.97\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u89e3\u51b3\u7528\u6237\u753b\u50cf\u4e2d\u7684\u6807\u7b7e\u7a00\u7f3a\u548c\u53ef\u9760\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u7f6e\u4fe1\u5ea6\u9a71\u52a8\u65b9\u6cd5\u5728\u63d0\u5347LLM\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.18868", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18868", "abs": "https://arxiv.org/abs/2509.18868", "authors": ["Dianxing Zhang", "Wendong Li", "Kani Song", "Jiaye Lu", "Gang Li", "Liuchun Yang", "Sheng Li"], "title": "Memory in Large Language Models: Mechanisms, Evaluation and Evolution", "comment": "50 pages, 1 figure, 8 tables This is a survey/framework paper on LLM\n  memory mechanisms and evaluation", "summary": "Under a unified operational definition, we define LLM memory as a persistent\nstate written during pretraining, finetuning, or inference that can later be\naddressed and that stably influences outputs. We propose a four-part taxonomy\n(parametric, contextual, external, procedural/episodic) and a memory quadruple\n(location, persistence, write/access path, controllability). We link mechanism,\nevaluation, and governance via the chain write -> read -> inhibit/update. To\navoid distorted comparisons across heterogeneous setups, we adopt a\nthree-setting protocol (parametric only, offline retrieval, online retrieval)\nthat decouples capability from information availability on the same data and\ntimeline. On this basis we build a layered evaluation: parametric (closed-book\nrecall, edit differential, memorization/privacy), contextual (position curves\nand the mid-sequence drop), external (answer correctness vs snippet\nattribution/faithfulness), and procedural/episodic (cross-session consistency\nand timeline replay, E MARS+). The framework integrates temporal governance and\nleakage auditing (freshness hits, outdated answers, refusal slices) and\nuncertainty reporting via inter-rater agreement plus paired tests with\nmultiple-comparison correction. For updating and forgetting, we present DMM\nGov: coordinating DAPT/TAPT, PEFT, model editing (ROME, MEND, MEMIT, SERAC),\nand RAG to form an auditable loop covering admission thresholds, rollout,\nmonitoring, rollback, and change audits, with specs for timeliness, conflict\nhandling, and long-horizon consistency. Finally, we give four testable\npropositions: minimum identifiability; a minimal evaluation card; causally\nconstrained editing with verifiable forgetting; and when retrieval with\nsmall-window replay outperforms ultra-long-context reading. This yields a\nreproducible, comparable, and governable coordinate system for research and\ndeployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684LLM\u8bb0\u5fc6\u5b9a\u4e49\u548c\u56db\u90e8\u5206\u5206\u7c7b\u6cd5\uff08\u53c2\u6570\u5316\u3001\u4e0a\u4e0b\u6587\u3001\u5916\u90e8\u3001\u7a0b\u5e8f\u6027/\u60c5\u666f\u6027\uff09\uff0c\u5efa\u7acb\u4e86\u8bb0\u5fc6\u56db\u5143\u7ec4\u6846\u67b6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5206\u5c42\u8bc4\u4f30\u534f\u8bae\u6765\u907f\u514d\u5f02\u6784\u8bbe\u7f6e\u4e0b\u7684\u5931\u771f\u6bd4\u8f83\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3LLM\u8bb0\u5fc6\u7814\u7a76\u4e2d\u7684\u5b9a\u4e49\u4e0d\u4e00\u81f4\u3001\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u7edf\u4e00\u3001\u7f3a\u4e4f\u53ef\u6bd4\u8f83\u6846\u67b6\u7684\u95ee\u9898\uff0c\u5efa\u7acb\u4e00\u4e2a\u53ef\u590d\u73b0\u3001\u53ef\u6bd4\u8f83\u548c\u53ef\u6cbb\u7406\u7684\u5750\u6807\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u4e09\u8bbe\u7f6e\u534f\u8bae\uff08\u4ec5\u53c2\u6570\u5316\u3001\u79bb\u7ebf\u68c0\u7d22\u3001\u5728\u7ebf\u68c0\u7d22\uff09\u89e3\u8026\u80fd\u529b\u4e0e\u4fe1\u606f\u53ef\u7528\u6027\uff0c\u6784\u5efa\u5206\u5c42\u8bc4\u4f30\u6846\u67b6\uff0c\u6574\u5408\u65f6\u95f4\u6cbb\u7406\u548c\u6cc4\u6f0f\u5ba1\u8ba1\uff0c\u5e76\u63d0\u51faDMM Gov\u66f4\u65b0\u548c\u9057\u5fd8\u534f\u8c03\u673a\u5236\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u5305\u542b\u8bb0\u5fc6\u5b9a\u4e49\u3001\u5206\u7c7b\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u6cbb\u7406\u6846\u67b6\u7684\u5b8c\u6574\u4f53\u7cfb\uff0c\u80fd\u591f\u652f\u6301\u53ef\u590d\u73b0\u7684\u7814\u7a76\u548c\u53ef\u90e8\u7f72\u7684\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aLLM\u8bb0\u5fc6\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u5750\u6807\u7cfb\u7edf\uff0c\u652f\u6301\u8bb0\u5fc6\u673a\u5236\u3001\u8bc4\u4f30\u548c\u6cbb\u7406\u7684\u7edf\u4e00\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4e86\u56db\u4e2a\u53ef\u6d4b\u8bd5\u7684\u547d\u9898\u6765\u6307\u5bfc\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2509.18883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18883", "abs": "https://arxiv.org/abs/2509.18883", "authors": ["Meituan LongCat Team", "Anchun Gui", "Bei Li", "Bingyang Tao", "Bole Zhou", "Borun Chen", "Chao Zhang", "Chao Zhang", "Chengcheng Han", "Chenhui Yang", "Chi Zhang", "Chong Peng", "Chuyu Zhang", "Cong Chen", "Fengcun Li", "Gang Xu", "Guoyuan Lin", "Hao Jiang", "Hao Liang", "Haomin Fu", "Haoxiang Ma", "Hong Liu", "Hongyan Hao", "Hongyin Tang", "Hongyu Zang", "Hongzhi Ni", "Hui Su", "Jiahao Liu", "Jiahuan Li", "Jialin Liu", "Jianfei Zhang", "Jianhao Xu", "Jianing Wang", "Jiaqi Sun", "Jiaqi Zhang", "Jiarong Shi", "Jiawei Yang", "Jingang Wang", "Jinrui Ding", "Jun Kuang", "Jun Xu", "Ke He", "Kefeng Zhang", "Keheng Wang", "Keqing He", "Li Wei", "Liang Shi", "Lin Qiu", "Lingbin Kong", "Lingchuan Liu", "Linsen Guo", "Longfei An", "Mai Xia", "Meng Zhou", "Mengshen Zhu", "Peng Pei", "Pengcheng Jia", "Qi Gu", "Qi Guo", "Qiong Huang", "Quan Chen", "Quanchi Weng", "Rongxiang Weng", "Ruichen Shao", "Rumei Li", "Shanglin Lei", "Shuai Du", "Shuaikang Liu", "Shuang Zhou", "Shuhao Hu", "Siyu Xu", "Songshan Gong", "Tao Liang", "Tianhao Hu", "Wei He", "Wei Shi", "Wei Wang", "Wei Wu", "Wei Zhuo", "Weifeng Tang", "Wenjie Shi", "Wenlong Zhu", "Xi Su", "Xiangcheng Liu", "Xiangyu Xi", "Xiangzhou Huang", "Xiao Liu", "Xiaochen Jiang", "Xiaowei Shi", "Xiaowen Shi", "Xiaoyu Li", "Xin Chen", "Xinyue Zhao", "Xuan Huang", "Xuemiao Zhang", "Xuezhi Cao", "Xunliang Cai", "Yajie Zhang", "Yang Chen", "Yang Liu", "Yang Liu", "Yang Zheng", "Yaoming Wang", "Yaqi Huo", "Yerui Sun", "Yifan Lu", "Yiyang Li", "Youshao Xiao", "Yuanzhe Lei", "Yuchen Xie", "Yueqing Sun", "Yufei Zhang", "Yuhuai Wei", "Yulei Qian", "Yunke Zhao", "Yuqing Ding", "Yuwei Jiang", "Zhaohua Yang", "Zhengyu Chen", "Zhijian Liu", "Zhikang Xia", "Zhongda Su", "Ziran Li", "Ziwen Wang", "Ziyuan Zhuang", "Zongyu Wang", "Zunyuan Yang"], "title": "LongCat-Flash-Thinking Technical Report", "comment": null, "summary": "We present LongCat-Flash-Thinking, an efficient 560-billion-parameter\nopen-source Mixture-of-Experts (MoE) reasoning model. Its advanced capabilities\nare cultivated through a meticulously crafted training process, beginning with\nlong Chain-of-Thought (CoT) data cold-start and culminating in large-scale\nReinforcement Learning (RL). We first employ a well-designed cold-start\ntraining strategy, which significantly enhances the reasoning potential and\nequips the model with specialized skills in both formal and agentic reasoning.\nThen, a core innovation is our domain-parallel training scheme, which decouples\noptimization across distinct domains (e.g., STEM, Code, Agentic) and\nsubsequently fuses the resulting expert models into a single, nearly\nPareto-optimal model. This entire process is powered by our Dynamic\nORchestration for Asynchronous rollout (DORA) system, a large-scale RL\nframework that delivers a greater than threefold training speedup over\nsynchronous methods on tens of thousands of accelerators. As a result,\nLongCat-Flash-Thinking achieves state-of-the-art performance among open-source\nmodels on a suite of complex reasoning tasks. The model exhibits exceptional\nefficiency in agentic reasoning, reducing average token consumption by 64.5%\n(from 19, 653 to 6, 965) on AIME-25, without degrading task accuracy. We\nrelease LongCat-Flash-Thinking to promote further advances in reasoning systems\nand agentic AI research.", "AI": {"tldr": "LongCat-Flash-Thinking\u662f\u4e00\u4e2a5600\u4ebf\u53c2\u6570\u7684\u5f00\u653e\u6e90\u4ee3\u7801MoE\u63a8\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8bad\u7ec3\u6d41\u7a0b\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u80fd\u529b\uff0c\u5305\u62ec\u957f\u94fe\u601d\u7ef4\u6570\u636e\u51b7\u542f\u52a8\u548c\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u9ad8\u6548\u7684\u5f00\u653e\u6e90\u4ee3\u7801\u63a8\u7406\u6a21\u578b\uff0c\u89e3\u51b3\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u7279\u522b\u662f\u5728STEM\u3001\u4ee3\u7801\u548c\u667a\u80fd\u4f53\u63a8\u7406\u7b49\u9886\u57df\u5b9e\u73b0\u66f4\u597d\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u67b6\u6784\uff0c\u7ed3\u5408\u957f\u94fe\u601d\u7ef4\u6570\u636e\u51b7\u542f\u52a8\u8bad\u7ec3\u548c\u9886\u57df\u5e76\u884c\u8bad\u7ec3\u65b9\u6848\uff0c\u4f7f\u7528DORA\u7cfb\u7edf\u8fdb\u884c\u5927\u89c4\u6a21\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e09\u500d\u4ee5\u4e0a\u7684\u8bad\u7ec3\u52a0\u901f\u3002", "result": "\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230\u5f00\u6e90\u6a21\u578b\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728AIME-25\u4efb\u52a1\u4e0a\u5e73\u5747token\u6d88\u8017\u51cf\u5c1164.5%\uff0c\u4ece19,653\u964d\u81f36,965\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u51c6\u786e\u6027\u3002", "conclusion": "LongCat-Flash-Thinking\u5c55\u793a\u4e86\u5728\u63a8\u7406\u7cfb\u7edf\u548c\u667a\u80fd\u4f53AI\u7814\u7a76\u65b9\u9762\u7684\u663e\u8457\u8fdb\u6b65\uff0c\u8be5\u6a21\u578b\u5df2\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u76f8\u5173\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2509.18905", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18905", "abs": "https://arxiv.org/abs/2509.18905", "authors": ["Songsong Yu", "Yuxin Chen", "Hao Ju", "Lianjie Jia", "Fuxi Zhang", "Shaofei Huang", "Yuhan Wu", "Rundi Cui", "Binghao Ran", "Zaibin Zhang", "Zhedong Zheng", "Zhipeng Zhang", "Yifan Wang", "Lin Song", "Lijun Wang", "Yanwei Li", "Ying Shan", "Huchuan Lu"], "title": "How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective", "comment": "a comprehensive visual spatial reasoning evaluation tool, 25 pages,\n  16 figures", "summary": "Visual Spatial Reasoning (VSR) is a core human cognitive ability and a\ncritical requirement for advancing embodied intelligence and autonomous\nsystems. Despite recent progress in Vision-Language Models (VLMs), achieving\nhuman-level VSR remains highly challenging due to the complexity of\nrepresenting and reasoning over three-dimensional space. In this paper, we\npresent a systematic investigation of VSR in VLMs, encompassing a review of\nexisting methodologies across input modalities, model architectures, training\nstrategies, and reasoning mechanisms. Furthermore, we categorize spatial\nintelligence into three levels of capability, ie, basic perception, spatial\nunderstanding, spatial planning, and curate SIBench, a spatial intelligence\nbenchmark encompassing nearly 20 open-source datasets across 23 task settings.\nExperiments with state-of-the-art VLMs reveal a pronounced gap between\nperception and reasoning, as models show competence in basic perceptual tasks\nbut consistently underperform in understanding and planning tasks, particularly\nin numerical estimation, multi-view reasoning, temporal dynamics, and spatial\nimagination. These findings underscore the substantial challenges that remain\nin achieving spatial intelligence, while providing both a systematic roadmap\nand a comprehensive benchmark to drive future research in the field. The\nrelated resources of this study are accessible at\nhttps://sibench.github.io/Awesome-Visual-Spatial-Reasoning/.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u89c6\u89c9\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u7a7a\u95f4\u667a\u80fd\u7684\u4e09\u4e2a\u80fd\u529b\u5c42\u6b21\uff0c\u5e76\u521b\u5efa\u4e86\u5305\u542b20\u4e2a\u5f00\u6e90\u6570\u636e\u96c6\u7684SIBench\u57fa\u51c6\u6d4b\u8bd5\u3002\u5b9e\u9a8c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u57fa\u7840\u611f\u77e5\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7406\u89e3\u548c\u89c4\u5212\u4efb\u52a1\u4e0a\u5b58\u5728\u660e\u663e\u5dee\u8ddd\u3002", "motivation": "\u89c6\u89c9\u7a7a\u95f4\u63a8\u7406\u662f\u4eba\u7c7b\u6838\u5fc3\u8ba4\u77e5\u80fd\u529b\uff0c\u4e5f\u662f\u63a8\u8fdb\u5177\u8eab\u667a\u80fd\u548c\u81ea\u4e3b\u7cfb\u7edf\u7684\u5173\u952e\u8981\u6c42\u3002\u5c3d\u7ba1\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u7531\u4e8e\u4e09\u7ef4\u7a7a\u95f4\u8868\u793a\u548c\u63a8\u7406\u7684\u590d\u6742\u6027\uff0c\u5b9e\u73b0\u4eba\u7c7b\u6c34\u5e73\u7684\u89c6\u89c9\u7a7a\u95f4\u63a8\u7406\u4ecd\u7136\u6781\u5177\u6311\u6218\u3002", "method": "\u7cfb\u7edf\u8c03\u67e5\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684VSR\u65b9\u6cd5\uff0c\u5305\u62ec\u8f93\u5165\u6a21\u6001\u3001\u6a21\u578b\u67b6\u6784\u3001\u8bad\u7ec3\u7b56\u7565\u548c\u63a8\u7406\u673a\u5236\u3002\u5c06\u7a7a\u95f4\u667a\u80fd\u5206\u4e3a\u4e09\u4e2a\u80fd\u529b\u5c42\u6b21\uff08\u57fa\u7840\u611f\u77e5\u3001\u7a7a\u95f4\u7406\u89e3\u3001\u7a7a\u95f4\u89c4\u5212\uff09\uff0c\u5e76\u521b\u5efa\u4e86SIBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d623\u4e2a\u4efb\u52a1\u8bbe\u7f6e\u7684\u8fd120\u4e2a\u5f00\u6e90\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u611f\u77e5\u548c\u63a8\u7406\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002\u6a21\u578b\u5728\u57fa\u7840\u611f\u77e5\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7406\u89e3\u548c\u89c4\u5212\u4efb\u52a1\u4e0a\u6301\u7eed\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u6570\u503c\u4f30\u8ba1\u3001\u591a\u89c6\u89d2\u63a8\u7406\u3001\u65f6\u95f4\u52a8\u6001\u548c\u7a7a\u95f4\u60f3\u8c61\u65b9\u9762\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u5728\u5b9e\u73b0\u7a7a\u95f4\u667a\u80fd\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u7684\u91cd\u5927\u6311\u6218\uff0c\u540c\u65f6\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8def\u7ebf\u56fe\u548c\u5168\u9762\u57fa\u51c6\u3002\u7814\u7a76\u8d44\u6e90\u53ef\u5728\u6307\u5b9a\u7f51\u7ad9\u83b7\u53d6\u3002"}}
{"id": "2509.18942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18942", "abs": "https://arxiv.org/abs/2509.18942", "authors": ["Xiao Han", "Zimo Zhao", "Wanyu Wang", "Maolin Wang", "Zitao Liu", "Yi Chang", "Xiangyu Zhao"], "title": "Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have emphasized the\ncritical role of fine-tuning (FT) techniques in adapting LLMs to specific\ntasks, especially when retraining from scratch is computationally infeasible.\nFine-tuning enables LLMs to leverage task- or domain-specific data, producing\nmodels that more effectively meet the requirements of targeted applications.\nHowever, con- ventional FT approaches often suffer from catastrophic forgetting\nand suboptimal data efficiency, limiting their real-world applicability. To\naddress these challenges, this paper proposes DEAL, a novel framework that\nintegrates Low-Rank Adapta- tion (LoRA) with a continuous fine-tuning strategy.\nBy incorporating knowledge retention and adaptive parameter update modules, the\nframework mitigates the lim- itations of existing FT methods while maintaining\nefficiency in privacy-preserving settings. Experiments on 15 diverse datasets\nshow that DEAL consistently outper- forms baseline methods, yielding\nsubstantial gains in task accuracy and resource efficiency. These findings\ndemonstrate the potential of our approach to advance continual adaptation in\nLLMs by enhancing task performance while improving resource efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDEAL\u6846\u67b6\uff0c\u7ed3\u5408LoRA\u548c\u6301\u7eed\u5fae\u8c03\u7b56\u7565\uff0c\u89e3\u51b3\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u548c\u6570\u636e\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u572815\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u548c\u6570\u636e\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002", "method": "DEAL\u6846\u67b6\u6574\u5408\u4e86\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u548c\u6301\u7eed\u5fae\u8c03\u7b56\u7565\uff0c\u5305\u542b\u77e5\u8bc6\u4fdd\u7559\u548c\u81ea\u9002\u5e94\u53c2\u6570\u66f4\u65b0\u6a21\u5757\u3002", "result": "\u572815\u4e2a\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDEAL\u5728\u4efb\u52a1\u51c6\u786e\u6027\u548c\u8d44\u6e90\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u548c\u8d44\u6e90\u6548\u7387\uff0c\u5c55\u793a\u4e86\u5728LLMs\u4e2d\u63a8\u8fdb\u6301\u7eed\u9002\u5e94\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.18970", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18970", "abs": "https://arxiv.org/abs/2509.18970", "authors": ["Xixun Lin", "Yucheng Ning", "Jingwen Zhang", "Yan Dong", "Yilong Liu", "Yongxuan Wu", "Xiaohua Qi", "Nan Sun", "Yanmin Shang", "Pengfei Cao", "Lixin Zou", "Xu Chen", "Chuan Zhou", "Jia Wu", "Shirui Pan", "Bin Wang", "Yanan Cao", "Kai Chen", "Songlin Hu", "Li Guo"], "title": "LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions", "comment": null, "summary": "Driven by the rapid advancements of Large Language Models (LLMs), LLM-based\nagents have emerged as powerful intelligent systems capable of human-like\ncognition, reasoning, and interaction. These agents are increasingly being\ndeployed across diverse real-world applications, including student education,\nscientific research, and financial analysis. However, despite their remarkable\npotential, LLM-based agents remain vulnerable to hallucination issues, which\ncan result in erroneous task execution and undermine the reliability of the\noverall system design. Addressing this critical challenge requires a deep\nunderstanding and a systematic consolidation of recent advances on LLM-based\nagents. To this end, we present the first comprehensive survey of\nhallucinations in LLM-based agents. By carefully analyzing the complete\nworkflow of agents, we propose a new taxonomy that identifies different types\nof agent hallucinations occurring at different stages. Furthermore, we conduct\nan in-depth examination of eighteen triggering causes underlying the emergence\nof agent hallucinations. Through a detailed review of a large number of\nexisting studies, we summarize approaches for hallucination mitigation and\ndetection, and highlight promising directions for future research. We hope this\nsurvey will inspire further efforts toward addressing hallucinations in\nLLM-based agents, ultimately contributing to the development of more robust and\nreliable agent systems.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u8fdb\u884c\u4e86\u9996\u6b21\u5168\u9762\u8c03\u67e5\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e8618\u79cd\u89e6\u53d1\u539f\u56e0\uff0c\u5e76\u603b\u7ed3\u4e86\u5e7b\u89c9\u7f13\u89e3\u548c\u68c0\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740LLM\u667a\u80fd\u4ee3\u7406\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u5e7f\u6cdb\u90e8\u7f72\uff0c\u5176\u5e7b\u89c9\u95ee\u9898\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u4efb\u52a1\u6267\u884c\u5e76\u5f71\u54cd\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u7406\u89e3\u548c\u89e3\u51b3\u8fd9\u4e00\u5173\u952e\u6311\u6218\u3002", "method": "\u901a\u8fc7\u4ed4\u7ec6\u5206\u6790\u4ee3\u7406\u7684\u5b8c\u6574\u5de5\u4f5c\u6d41\u7a0b\uff0c\u63d0\u51fa\u4e86\u5728\u4e0d\u540c\u9636\u6bb5\u53d1\u751f\u7684\u4ee3\u7406\u5e7b\u89c9\u65b0\u5206\u7c7b\u6cd5\uff0c\u6df1\u5165\u7814\u7a76\u4e8618\u79cd\u5e7b\u89c9\u89e6\u53d1\u539f\u56e0\uff0c\u5e76\u7efc\u8ff0\u4e86\u5927\u91cf\u73b0\u6709\u7814\u7a76\u4e2d\u7684\u7f13\u89e3\u548c\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86\u57fa\u4e8eLLM\u4ee3\u7406\u5e7b\u89c9\u7684\u7cfb\u7edf\u6027\u5206\u6790\u6846\u67b6\uff0c\u4e3a\u7406\u89e3\u3001\u68c0\u6d4b\u548c\u7f13\u89e3\u4ee3\u7406\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\u3002", "conclusion": "\u8fd9\u9879\u8c03\u67e5\u6709\u671b\u6fc0\u53d1\u66f4\u591a\u89e3\u51b3LLM\u4ee3\u7406\u5e7b\u89c9\u95ee\u9898\u7684\u7814\u7a76\uff0c\u6700\u7ec8\u4fc3\u8fdb\u66f4\u7a33\u5065\u53ef\u9760\u7684\u4ee3\u7406\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2509.18980", "categories": ["cs.AI", "cs.HC", "cs.IR", "H.3.3; H.5.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.18980", "abs": "https://arxiv.org/abs/2509.18980", "authors": ["Maxime Manderlier", "Fabian Lecron", "Olivier Vu Thanh", "Nicolas Gillis"], "title": "From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system", "comment": null, "summary": "We investigate whether large language models (LLMs) can generate effective,\nuser-facing explanations from a mathematically interpretable recommendation\nmodel. The model is based on constrained matrix factorization, where user types\nare explicitly represented and predicted item scores share the same scale as\nobserved ratings, making the model's internal representations and predicted\nscores directly interpretable. This structure is translated into natural\nlanguage explanations using carefully designed LLM prompts. Many works in\nexplainable AI rely on automatic evaluation metrics, which often fail to\ncapture users' actual needs and perceptions. In contrast, we adopt a\nuser-centered approach: we conduct a study with 326 participants who assessed\nthe quality of the explanations across five key dimensions-transparency,\neffectiveness, persuasion, trust, and satisfaction-as well as the\nrecommendations themselves.To evaluate how different explanation strategies are\nperceived, we generate multiple explanation types from the same underlying\nmodel, varying the input information provided to the LLM. Our analysis reveals\nthat all explanation types are generally well received, with moderate\nstatistical differences between strategies. User comments further underscore\nhow participants react to each type of explanation, offering complementary\ninsights beyond the quantitative results.", "AI": {"tldr": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u4ece\u6570\u5b66\u53ef\u89e3\u91ca\u7684\u63a8\u8350\u6a21\u578b\u4e2d\u751f\u6210\u6709\u6548\u7684\u7528\u6237\u89e3\u91ca\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8bc4\u4f30\u4e0d\u540c\u89e3\u91ca\u7b56\u7565\u7684\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91caAI\u7814\u7a76\u591a\u4f9d\u8d56\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\uff0c\u4f46\u8fd9\u4e9b\u6307\u6807\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u7528\u6237\u7684\u771f\u5b9e\u9700\u6c42\u548c\u611f\u77e5\uff0c\u56e0\u6b64\u9700\u8981\u91c7\u7528\u7528\u6237\u4e2d\u5fc3\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u89e3\u91ca\u8d28\u91cf\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u7ea6\u675f\u77e9\u9635\u5206\u89e3\u7684\u53ef\u89e3\u91ca\u63a8\u8350\u6a21\u578b\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684LLM\u63d0\u793a\u5c06\u6a21\u578b\u7ed3\u6784\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u5e76\u5728326\u540d\u53c2\u4e0e\u8005\u4e2d\u8fdb\u884c\u7528\u6237\u7814\u7a76\uff0c\u8bc4\u4f30\u4e94\u79cd\u5173\u952e\u7ef4\u5ea6\u7684\u89e3\u91ca\u8d28\u91cf\u3002", "result": "\u6240\u6709\u89e3\u91ca\u7c7b\u578b\u90fd\u666e\u904d\u53d7\u5230\u597d\u8bc4\uff0c\u4e0d\u540c\u7b56\u7565\u4e4b\u95f4\u5b58\u5728\u4e2d\u7b49\u7edf\u8ba1\u5dee\u5f02\uff0c\u7528\u6237\u8bc4\u8bba\u63d0\u4f9b\u4e86\u8d85\u8d8a\u5b9a\u91cf\u7ed3\u679c\u7684\u8865\u5145\u89c1\u89e3\u3002", "conclusion": "LLM\u80fd\u591f\u4ece\u6570\u5b66\u53ef\u89e3\u91ca\u7684\u63a8\u8350\u6a21\u578b\u4e2d\u751f\u6210\u6709\u6548\u7684\u7528\u6237\u89e3\u91ca\uff0c\u7528\u6237\u4e2d\u5fc3\u8bc4\u4f30\u65b9\u6cd5\u4e3a\u89e3\u91ca\u8d28\u91cf\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u7406\u89e3\u3002"}}
{"id": "2509.18986", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18986", "abs": "https://arxiv.org/abs/2509.18986", "authors": ["Erik Penther", "Michael Grohs", "Jana-Rebecca Rehse"], "title": "Remaining Time Prediction in Outbound Warehouse Processes: A Case Study (Short Paper)", "comment": "Short paper at the ML4PM Workshop 2025, held in conjunction with the\n  ICPM 2025 in Montevideo, Uruguay", "summary": "Predictive process monitoring is a sub-domain of process mining which aims to\nforecast the future of ongoing process executions. One common prediction target\nis the remaining time, meaning the time that will elapse until a process\nexecution is completed. In this paper, we compare four different remaining time\nprediction approaches in a real-life outbound warehouse process of a logistics\ncompany in the aviation business. For this process, the company provided us\nwith a novel and original event log with 169,523 traces, which we can make\npublicly available. Unsurprisingly, we find that deep learning models achieve\nthe highest accuracy, but shallow methods like conventional boosting techniques\nachieve competitive accuracy and require significantly fewer computational\nresources.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u56db\u79cd\u5269\u4f59\u65f6\u95f4\u9884\u6d4b\u65b9\u6cd5\u5728\u7269\u6d41\u516c\u53f8\u51fa\u5e93\u4ed3\u5e93\u6d41\u7a0b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u51c6\u786e\u7387\u6700\u9ad8\uff0c\u4f46\u6d45\u5c42\u65b9\u6cd5\u5982\u4f20\u7edf\u63d0\u5347\u6280\u672f\u5728\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u4e0a\u66f4\u4f18\u3002", "motivation": "\u9884\u6d4b\u6d41\u7a0b\u76d1\u63a7\u662f\u6d41\u7a0b\u6316\u6398\u7684\u5b50\u9886\u57df\uff0c\u65e8\u5728\u9884\u6d4b\u6b63\u5728\u8fdb\u884c\u7684\u6d41\u7a0b\u6267\u884c\u7684\u672a\u6765\u3002\u5269\u4f59\u65f6\u95f4\u9884\u6d4b\u662f\u5e38\u89c1\u76ee\u6807\u4e4b\u4e00\uff0c\u5373\u6d41\u7a0b\u6267\u884c\u5b8c\u6210\u6240\u9700\u7684\u65f6\u95f4\u3002", "method": "\u5728\u822a\u7a7a\u4e1a\u52a1\u7269\u6d41\u516c\u53f8\u7684\u771f\u5b9e\u51fa\u5e93\u4ed3\u5e93\u6d41\u7a0b\u4e2d\uff0c\u6bd4\u8f83\u4e86\u56db\u79cd\u4e0d\u540c\u7684\u5269\u4f59\u65f6\u95f4\u9884\u6d4b\u65b9\u6cd5\u3002\u4f7f\u7528\u4e86\u5305\u542b169,523\u6761\u8f68\u8ff9\u7684\u65b0\u9896\u539f\u59cb\u4e8b\u4ef6\u65e5\u5fd7\u3002", "result": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fbe\u5230\u6700\u9ad8\u51c6\u786e\u7387\uff0c\u4f46\u6d45\u5c42\u65b9\u6cd5\u5982\u4f20\u7edf\u63d0\u5347\u6280\u672f\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u7684\u51c6\u786e\u7387\uff0c\u4e14\u9700\u8981\u663e\u8457\u66f4\u5c11\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "conclusion": "\u867d\u7136\u6df1\u5ea6\u5b66\u4e60\u5728\u51c6\u786e\u7387\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u6d45\u5c42\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2509.19030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19030", "abs": "https://arxiv.org/abs/2509.19030", "authors": ["Victoire Herv\u00e9", "Henrik Warpefelt", "Christoph Salge"], "title": "Landmarks, Monuments, and Beacons: Understanding Generative Calls to Action", "comment": null, "summary": "Algorithmic evaluation of procedurally generated content struggles to find\nmetrics that align with human experience, particularly for composite artefacts.\nAutomatic decomposition as a possible solution requires concepts that meet a\nrange of properties. To this end, drawing on Games Studies and Game AI\nresearch, we introduce the nested concepts of \\textit{Landmarks},\n\\textit{Monuments}, and \\textit{Beacons}. These concepts are based on the\nartefact's perceivability, evocativeness, and Call to Action, all from a\nplayer-centric perspective. These terms are generic to games and usable across\ngenres. We argue that these entities can be found and evaluated with techniques\ncurrently used in both research and industry, opening a path towards a fully\nautomated decomposition of PCG, and evaluation of the salient sub-components.\nAlthough the work presented here emphasises mixed-initiative PCG and\ncompositional PCG, we believe it applies beyond those domains. With this\napproach, we intend to create a connection between humanities and technical\ngame research and allow for better computational PCG evaluation", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u73a9\u5bb6\u89c6\u89d2\u7684Landmarks\u3001Monuments\u548cBeacons\u6982\u5ff5\uff0c\u7528\u4e8e\u89e3\u51b3\u7a0b\u5e8f\u751f\u6210\u5185\u5bb9\u8bc4\u4f30\u4e2d\u5ea6\u91cf\u6807\u51c6\u4e0e\u4eba\u7c7b\u4f53\u9a8c\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002", "motivation": "\u7a0b\u5e8f\u751f\u6210\u5185\u5bb9\u7684\u7b97\u6cd5\u8bc4\u4f30\u96be\u4ee5\u627e\u5230\u4e0e\u4eba\u7c7b\u4f53\u9a8c\u4e00\u81f4\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u590d\u5408\u4eba\u5de5\u5236\u54c1\u3002\u81ea\u52a8\u5206\u89e3\u9700\u8981\u6ee1\u8db3\u4e00\u7cfb\u5217\u5c5e\u6027\u7684\u6982\u5ff5\u3002", "method": "\u501f\u9274\u6e38\u620f\u7814\u7a76\u548c\u6e38\u620fAI\u7814\u7a76\uff0c\u5f15\u5165\u57fa\u4e8e\u4eba\u5de5\u5236\u54c1\u7684\u53ef\u611f\u77e5\u6027\u3001\u5524\u8d77\u6027\u548c\u884c\u52a8\u53ec\u5524\u6027\u7684\u5d4c\u5957\u6982\u5ff5\uff1aLandmarks\u3001Monuments\u548cBeacons\u3002\u8fd9\u4e9b\u6982\u5ff5\u662f\u901a\u7528\u7684\uff0c\u53ef\u8de8\u6e38\u620f\u7c7b\u578b\u4f7f\u7528\u3002", "result": "\u8fd9\u4e9b\u5b9e\u4f53\u53ef\u4ee5\u901a\u8fc7\u5f53\u524d\u7814\u7a76\u548c\u5de5\u4e1a\u4e2d\u4f7f\u7528\u7684\u6280\u672f\u6765\u53d1\u73b0\u548c\u8bc4\u4f30\uff0c\u4e3a\u7a0b\u5e8f\u751f\u6210\u5185\u5bb9\u7684\u5b8c\u5168\u81ea\u52a8\u5206\u89e3\u548c\u91cd\u8981\u5b50\u7ec4\u4ef6\u7684\u8bc4\u4f30\u5f00\u8f9f\u4e86\u9053\u8def\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e8\u5728\u5efa\u7acb\u4eba\u6587\u5b66\u79d1\u4e0e\u6280\u672f\u6e38\u620f\u7814\u7a76\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u8ba1\u7b97\u7a0b\u5e8f\u751f\u6210\u5185\u5bb9\u8bc4\u4f30\uff0c\u867d\u7136\u91cd\u70b9\u5f3a\u8c03\u6df7\u5408\u4e3b\u52a8\u7a0b\u5e8f\u751f\u6210\u548c\u7ec4\u5408\u7a0b\u5e8f\u751f\u6210\uff0c\u4f46\u9002\u7528\u8303\u56f4\u66f4\u5e7f\u3002"}}
{"id": "2509.19058", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19058", "abs": "https://arxiv.org/abs/2509.19058", "authors": ["Kwonho Kim", "Heejeong Nam", "Inwoo Hwang", "Sanghack Lee"], "title": "Towards Causal Representation Learning with Observable Sources as Auxiliaries", "comment": null, "summary": "Causal representation learning seeks to recover latent factors that generate\nobservational data through a mixing function. Needing assumptions on latent\nstructures or relationships to achieve identifiability in general, prior works\noften build upon conditional independence given known auxiliary variables.\nHowever, prior frameworks limit the scope of auxiliary variables to be external\nto the mixing function. Yet, in some cases, system-driving latent factors can\nbe easily observed or extracted from data, possibly facilitating\nidentification. In this paper, we introduce a framework of observable sources\nbeing auxiliaries, serving as effective conditioning variables. Our main\nresults show that one can identify entire latent variables up to subspace-wise\ntransformations and permutations using volume-preserving encoders. Moreover,\nwhen multiple known auxiliary variables are available, we offer a\nvariable-selection scheme to choose those that maximize recoverability of the\nlatent factors given knowledge of the latent causal graph. Finally, we\ndemonstrate the effectiveness of our framework through experiments on synthetic\ngraph and image data, thereby extending the boundaries of current approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56e0\u679c\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u53ef\u89c2\u6d4b\u6e90\u4f5c\u4e3a\u8f85\u52a9\u53d8\u91cf\u6765\u8bc6\u522b\u6f5c\u5728\u53d8\u91cf\uff0c\u901a\u8fc7\u4f53\u79ef\u4fdd\u6301\u7f16\u7801\u5668\u5b9e\u73b0\u5b50\u7a7a\u95f4\u7ea7\u522b\u7684\u53d8\u6362\u548c\u7f6e\u6362\u8bc6\u522b\uff0c\u5e76\u63d0\u4f9b\u4e86\u53d8\u91cf\u9009\u62e9\u65b9\u6848\u6765\u6700\u5927\u5316\u6f5c\u5728\u56e0\u7d20\u7684\u53ef\u6062\u590d\u6027\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5916\u90e8\u8f85\u52a9\u53d8\u91cf\u8fdb\u884c\u6761\u4ef6\u72ec\u7acb\u6027\u5047\u8bbe\uff0c\u4f46\u9650\u5236\u4e86\u8f85\u52a9\u53d8\u91cf\u7684\u8303\u56f4\u3002\u5b9e\u9645\u4e0a\uff0c\u7cfb\u7edf\u9a71\u52a8\u7684\u6f5c\u5728\u56e0\u7d20\u53ef\u80fd\u5bb9\u6613\u4ece\u6570\u636e\u4e2d\u89c2\u6d4b\u6216\u63d0\u53d6\uff0c\u8fd9\u6709\u52a9\u4e8e\u8bc6\u522b\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165\u53ef\u89c2\u6d4b\u6e90\u4f5c\u4e3a\u8f85\u52a9\u53d8\u91cf\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u4f53\u79ef\u4fdd\u6301\u7f16\u7801\u5668\u8fdb\u884c\u6f5c\u5728\u53d8\u91cf\u8bc6\u522b\uff0c\u5f53\u5b58\u5728\u591a\u4e2a\u5df2\u77e5\u8f85\u52a9\u53d8\u91cf\u65f6\uff0c\u63d0\u4f9b\u53d8\u91cf\u9009\u62e9\u65b9\u6848\u6765\u9009\u62e9\u80fd\u6700\u5927\u5316\u6f5c\u5728\u56e0\u7d20\u53ef\u6062\u590d\u6027\u7684\u53d8\u91cf\u3002", "result": "\u5b9e\u9a8c\u5728\u5408\u6210\u56fe\u6570\u636e\u548c\u56fe\u50cf\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u8bc6\u522b\u6574\u4e2a\u6f5c\u5728\u53d8\u91cf\u5230\u5b50\u7a7a\u95f4\u53d8\u6362\u548c\u7f6e\u6362\u7684\u7a0b\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u6269\u5c55\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u8fb9\u754c\uff0c\u901a\u8fc7\u5229\u7528\u53ef\u89c2\u6d4b\u6e90\u4f5c\u4e3a\u8f85\u52a9\u53d8\u91cf\uff0c\u4e3a\u56e0\u679c\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc6\u522b\u9014\u5f84\u3002"}}
{"id": "2509.19077", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19077", "abs": "https://arxiv.org/abs/2509.19077", "authors": ["Zikang Tian", "Shaohui Peng", "Du Huang", "Jiaming Guo", "Ruizhi Chen", "Rui Zhang", "Xishan Zhang", "Yuxuan Guo", "Zidong Du", "Qi Guo", "Ling Li", "Yewen Pu", "Xing Hu", "Yunji Chen"], "title": "Code Driven Planning with Domain-Adaptive Critic", "comment": null, "summary": "Large Language Models (LLMs) have been widely adopted as task planners for AI\nagents in sequential decision-making problems, leveraging their extensive world\nknowledge. However, the gap between their general knowledge and\nenvironment-specific requirements often leads to inaccurate plans. To address\nthis, existing approaches rely on frequent LLM queries to iteratively refine\nplans based on immediate environmental feedback, which incurs substantial query\ncosts. However, this refinement is typically guided by short-term environmental\nfeedback, limiting LLMs from developing plans aligned with long-term rewards.\nWe propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of\nrelying on frequent queries, CoPiC employs LLMs to generate a diverse set of\nhigh-level planning programs, which iteratively produce and refine candidate\nplans. A trained domain-adaptive critic then evaluates these candidates and\nselects the one most aligned with long-term rewards for execution. Using\nhigh-level planning programs as planner and domain-adaptive critic as\nestimator, CoPiC improves planning while significantly reducing query costs.\nResults in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC\noutperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving\nan average (1) 23.33% improvement in success rate and (2) 91.27% reduction in\nquery costs.", "AI": {"tldr": "CoPiC\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7801\u9a71\u52a8\u89c4\u5212\u548c\u9886\u57df\u81ea\u9002\u5e94\u8bc4\u4f30\u5668\u7684LLM\u4efb\u52a1\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u591a\u6837\u5316\u9ad8\u5c42\u89c4\u5212\u7a0b\u5e8f\u5e76\u5229\u7528\u8bad\u7ec3\u597d\u7684\u8bc4\u4f30\u5668\u9009\u62e9\u957f\u671f\u5956\u52b1\u6700\u4f18\u7684\u8ba1\u5212\uff0c\u663e\u8457\u51cf\u5c11LLM\u67e5\u8be2\u6b21\u6570\u5e76\u63d0\u9ad8\u89c4\u5212\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709LLM\u89c4\u5212\u65b9\u6cd5\u4f9d\u8d56\u9891\u7e41\u67e5\u8be2\u548c\u73af\u5883\u53cd\u9988\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u5bfc\u81f4\u9ad8\u67e5\u8be2\u6210\u672c\u4e14\u96be\u4ee5\u5b9e\u73b0\u957f\u671f\u5956\u52b1\u5bf9\u9f50\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u51cf\u5c11\u67e5\u8be2\u6b21\u6570\u53c8\u80fd\u4f18\u5316\u957f\u671f\u89c4\u5212\u6548\u679c\u7684\u65b9\u6cd5\u3002", "method": "1) \u4f7f\u7528LLM\u751f\u6210\u591a\u6837\u5316\u9ad8\u5c42\u89c4\u5212\u7a0b\u5e8f\uff1b2) \u8fd9\u4e9b\u7a0b\u5e8f\u8fed\u4ee3\u4ea7\u751f\u548c\u4f18\u5316\u5019\u9009\u8ba1\u5212\uff1b3) \u8bad\u7ec3\u9886\u57df\u81ea\u9002\u5e94\u8bc4\u4f30\u5668\u8bc4\u4f30\u5019\u9009\u8ba1\u5212\uff1b4) \u9009\u62e9\u957f\u671f\u5956\u52b1\u6700\u4f18\u7684\u8ba1\u5212\u6267\u884c\u3002", "result": "\u5728ALFWorld\u3001NetHack\u548cStarCraft II Unit Building\u4e09\u4e2a\u73af\u5883\u4e2d\uff0cCoPiC\u76f8\u6bd4AdaPlanner\u548cReflexion\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747\u6210\u529f\u7387\u63d0\u534723.33%\uff0c\u67e5\u8be2\u6210\u672c\u964d\u4f4e91.27%\u3002", "conclusion": "CoPiC\u901a\u8fc7\u4ee3\u7801\u9a71\u52a8\u89c4\u5212\u548c\u9886\u57df\u81ea\u9002\u5e94\u8bc4\u4f30\u5668\u7684\u7ed3\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u89c4\u5212\u4e2d\u7684\u67e5\u8be2\u6210\u672c\u9ad8\u548c\u957f\u671f\u5956\u52b1\u5bf9\u9f50\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2509.19236", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19236", "abs": "https://arxiv.org/abs/2509.19236", "authors": ["Chunhao Tian", "Yutong Wang", "Xuebo Liu", "Zhexuan Wang", "Liang Ding", "Miao Zhang", "Min Zhang"], "title": "AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration", "comment": "EMNLP 2025 Findings", "summary": "Proper initialization is crucial for any system, particularly in multi-agent\nsystems (MAS), where it plays a pivotal role in determining both the system's\nefficiency and effectiveness. However, existing MAS initialization methods do\nnot fully account for the collaborative needs of the generated agents in\nsubsequent stages. Inspired by the principles of effective team composition, we\npropose AgentInit, which aims to optimize the structure of agent teams.\nSpecifically, in addition to multi-round interactions and reflections between\nagents during agent generation, AgentInit incorporates a Natural Language to\nFormat mechanism to ensure consistency and standardization. Balanced team\nselection strategies using Pareto principles are subsequently applied to\njointly consider agent team diversity and task relevance to promote effective\nand efficient collaboration and enhance overall system performance. Experiments\nshow that AgentInit consistently outperforms state-of-the-art initialization\nmethods and pre-defined strategies across various frameworks and tasks,\nachieving an overall performance improvement of up to 1.2 and 1.6,\nrespectively, while also significantly reducing token consumption. Further\nanalysis confirms its strong transferability to similar tasks and verifies the\neffectiveness of its key components, demonstrating its capability and\nadaptability as a reliable MAS initialization method. Source code and models\nare available at https://github.com/1737423697/AgentInit.", "AI": {"tldr": "AgentInit\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u667a\u80fd\u4f53\u56e2\u961f\u7ed3\u6784\u6765\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5230\u683c\u5f0f\u8f6c\u6362\u673a\u5236\u548c\u5e15\u7d2f\u6258\u5e73\u8861\u9009\u62e9\u7b56\u7565\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709MAS\u521d\u59cb\u5316\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8003\u8651\u667a\u80fd\u4f53\u5728\u540e\u7eed\u9636\u6bb5\u7684\u534f\u4f5c\u9700\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4f18\u5316\u667a\u80fd\u4f53\u56e2\u961f\u7ed3\u6784\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u7cfb\u7edf\u6548\u7387\u548c\u6548\u679c\u3002", "method": "\u63d0\u51faAgentInit\u65b9\u6cd5\uff0c\u5305\u542b\u591a\u8f6e\u667a\u80fd\u4f53\u4ea4\u4e92\u548c\u53cd\u601d\u3001\u81ea\u7136\u8bed\u8a00\u5230\u683c\u5f0f\u8f6c\u6362\u673a\u5236\u786e\u4fdd\u4e00\u81f4\u6027\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5e15\u7d2f\u6258\u539f\u5219\u7684\u5e73\u8861\u56e2\u961f\u9009\u62e9\u7b56\u7565\u6765\u517c\u987e\u591a\u6837\u6027\u548c\u4efb\u52a1\u76f8\u5173\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793aAgentInit\u5728\u5404\u79cd\u6846\u67b6\u548c\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u521d\u59cb\u5316\u65b9\u6cd5\u548c\u9884\u5b9a\u4e49\u7b56\u7565\uff0c\u6027\u80fd\u63d0\u5347\u5206\u522b\u8fbe\u52301.2\u548c1.6\u500d\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11token\u6d88\u8017\uff0c\u5e76\u8868\u73b0\u51fa\u826f\u597d\u7684\u4efb\u52a1\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "AgentInit\u4f5c\u4e3a\u4e00\u79cd\u53ef\u9760\u7684MAS\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u80fd\u529b\u548c\u9002\u5e94\u6027\uff0c\u5176\u5173\u952e\u7ec4\u4ef6\u7684\u6709\u6548\u6027\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2509.19265", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.19265", "abs": "https://arxiv.org/abs/2509.19265", "authors": ["Saeed Almheiri", "Rania Hossam", "Mena Attia", "Chenxi Wang", "Preslav Nakov", "Timothy Baldwin", "Fajri Koto"], "title": "Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World", "comment": "EMNLP 2025 - Findings", "summary": "Large language models (LLMs) often reflect Western-centric biases, limiting\ntheir effectiveness in diverse cultural contexts. Although some work has\nexplored cultural alignment, the potential for cross-cultural transfer, using\nalignment in one culture to improve performance in others, remains\nunderexplored. This paper investigates cross-cultural transfer of commonsense\nreasoning in the Arab world, where linguistic and historical similarities\ncoexist with local cultural differences. Using a culturally grounded\ncommonsense reasoning dataset covering 13 Arab countries, we evaluate\nlightweight alignment methods such as in-context learning and\ndemonstration-based reinforcement (DITTO), alongside baselines like supervised\nfine-tuning and direct preference optimization. Our results show that merely 12\nculture-specific examples from one country can improve performance in others by\n10\\% on average, within multilingual models. In addition, we demonstrate that\nout-of-culture demonstrations from Indonesia and US contexts can match or\nsurpass in-culture alignment for MCQ reasoning, highlighting cultural\ncommonsense transferability beyond the Arab world. These findings demonstrate\nthat efficient cross-cultural alignment is possible and offer a promising\napproach to adapt LLMs to low-resource cultural settings.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLMs\u5728\u963f\u62c9\u4f2f\u4e16\u754c\u7684\u8de8\u6587\u5316\u5e38\u8bc6\u63a8\u7406\u8fc1\u79fb\uff0c\u53d1\u73b0\u4ec5\u970012\u4e2a\u6587\u5316\u7279\u5b9a\u793a\u4f8b\u5373\u53ef\u5e73\u5747\u63d0\u534710%\u6027\u80fd\uff0c\u4e14\u6765\u81ea\u5370\u5c3c\u548c\u7f8e\u56fd\u7684\u8de8\u6587\u5316\u6f14\u793a\u4e5f\u80fd\u5b9e\u73b0\u7c7b\u4f3c\u6548\u679c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u897f\u65b9\u4e2d\u5fc3\u504f\u89c1\uff0c\u9650\u5236\u4e86\u5176\u5728\u591a\u5143\u6587\u5316\u80cc\u666f\u4e0b\u7684\u6709\u6548\u6027\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u63a2\u7d22\u6587\u5316\u5bf9\u9f50\uff0c\u4f46\u8de8\u6587\u5316\u8fc1\u79fb\u6f5c\u529b\uff08\u5229\u7528\u4e00\u79cd\u6587\u5316\u7684\u5bf9\u9f50\u6765\u6539\u8fdb\u5176\u4ed6\u6587\u5316\u7684\u6027\u80fd\uff09\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u7528\u8986\u76d613\u4e2a\u963f\u62c9\u4f2f\u56fd\u5bb6\u7684\u6587\u5316\u57fa\u7840\u5e38\u8bc6\u63a8\u7406\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u8f7b\u91cf\u7ea7\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u6f14\u793a\u5f3a\u5316DITTO\uff09\u4ee5\u53ca\u57fa\u7ebf\u65b9\u6cd5\uff08\u76d1\u7763\u5fae\u8c03\u3001\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff09\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4ec5\u9700\u6765\u81ea\u4e00\u4e2a\u56fd\u5bb6\u768412\u4e2a\u6587\u5316\u7279\u5b9a\u793a\u4f8b\uff0c\u5c31\u80fd\u5728\u591a\u8bed\u8a00\u6a21\u578b\u4e2d\u5e73\u5747\u63d0\u5347\u5176\u4ed6\u56fd\u5bb6\u7684\u6027\u80fd10%\u3002\u6765\u81ea\u5370\u5c3c\u548c\u7f8e\u56fd\u7684\u8de8\u6587\u5316\u6f14\u793a\u5728MCQ\u63a8\u7406\u4e2d\u4e5f\u80fd\u8fbe\u5230\u6216\u8d85\u8d8a\u6587\u5316\u5185\u5bf9\u9f50\u6548\u679c\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\u9ad8\u6548\u7684\u8de8\u6587\u5316\u5bf9\u9f50\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u5c06LLMs\u9002\u914d\u5230\u4f4e\u8d44\u6e90\u6587\u5316\u73af\u5883\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002"}}
