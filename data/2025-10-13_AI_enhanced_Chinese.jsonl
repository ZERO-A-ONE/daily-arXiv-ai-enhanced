{"id": "2510.08576", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.08576", "abs": "https://arxiv.org/abs/2510.08576", "authors": ["Justus Flerlage", "Alexander Acker", "Odej Kao"], "title": "Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions", "comment": null, "summary": "Large Language Models (LLMs) have emerged as transformative tools for natural\nlanguage understanding and user intent resolution, enabling tasks such as\ntranslation, summarization, and, increasingly, the orchestration of complex\nworkflows. This development signifies a paradigm shift from conventional,\nGUI-driven user interfaces toward intuitive, language-first interaction\nparadigms. Rather than manually navigating applications, users can articulate\ntheir objectives in natural language, enabling LLMs to orchestrate actions\nacross multiple applications in a dynamic and contextual manner. However,\nextant implementations frequently rely on cloud-based proprietary models, which\nintroduce limitations in terms of privacy, autonomy, and scalability. For\nlanguage-first interaction to become a truly robust and trusted interface\nparadigm, local deployment is not merely a convenience; it is an imperative.\nThis limitation underscores the importance of evaluating the feasibility of\nlocally deployable, open-source, and open-access LLMs as foundational\ncomponents for future intent-based operating systems. In this study, we examine\nthe capabilities of several open-source and open-access models in facilitating\nuser intention resolution through machine assistance. A comparative analysis is\nconducted against OpenAI's proprietary GPT-4-based systems to assess\nperformance in generating workflows for various user intentions. The present\nstudy offers empirical insights into the practical viability, performance\ntrade-offs, and potential of open LLMs as autonomous, locally operable\ncomponents in next-generation operating systems. The results of this study\ninform the broader discussion on the decentralization and democratization of AI\ninfrastructure and point toward a future where user-device interaction becomes\nmore seamless, adaptive, and privacy-conscious through locally embedded\nintelligence.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u672c\u5730\u90e8\u7f72\u610f\u56fe\u89e3\u6790\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u4e0eGPT-4\u8fdb\u884c\u6027\u80fd\u5bf9\u6bd4\uff0c\u63a2\u7d22\u4e0b\u4e00\u4ee3\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u672c\u5730\u667a\u80fd\u7ec4\u4ef6\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4e91\u7aef\u4e13\u6709\u6a21\u578b\u7684\u5b9e\u73b0\u5b58\u5728\u9690\u79c1\u3001\u81ea\u4e3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u9650\u5236\uff0c\u9700\u8981\u9a8c\u8bc1\u672c\u5730\u53ef\u90e8\u7f72\u7684\u5f00\u6e90LLMs\u4f5c\u4e3a\u610f\u56fe\u64cd\u4f5c\u7cfb\u7edf\u57fa\u7840\u7ec4\u4ef6\u7684\u53ef\u884c\u6027\u3002", "method": "\u5bf9\u591a\u4e2a\u5f00\u6e90\u548c\u5f00\u653e\u8bbf\u95ee\u6a21\u578b\u8fdb\u884c\u80fd\u529b\u8bc4\u4f30\uff0c\u4e0eOpenAI\u7684GPT-4\u7cfb\u7edf\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c\u8bc4\u4f30\u5176\u5728\u751f\u6210\u7528\u6237\u610f\u56fe\u5de5\u4f5c\u6d41\u65b9\u9762\u7684\u6027\u80fd\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u5f00\u6e90LLMs\u5b9e\u9645\u53ef\u884c\u6027\u3001\u6027\u80fd\u6743\u8861\u548c\u6f5c\u529b\u7684\u5b9e\u8bc1\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u672c\u5730\u53ef\u64cd\u4f5c\u7ec4\u4ef6\u5728\u4e0b\u4e00\u4ee3\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u524d\u666f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301AI\u57fa\u7840\u8bbe\u65bd\u7684\u53bb\u4e2d\u5fc3\u5316\u548c\u6c11\u4e3b\u5316\uff0c\u6307\u5411\u901a\u8fc7\u672c\u5730\u5d4c\u5165\u667a\u80fd\u5b9e\u73b0\u66f4\u65e0\u7f1d\u3001\u81ea\u9002\u5e94\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u7528\u6237\u8bbe\u5907\u4ea4\u4e92\u7684\u672a\u6765\u3002"}}
{"id": "2510.08609", "categories": ["cs.SE", "cs.CR", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.08609", "abs": "https://arxiv.org/abs/2510.08609", "authors": ["Imranur Rahman", "Jill Marley", "William Enck", "Laurie Williams"], "title": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?", "comment": "Accepted to ASE 2025", "summary": "Developers consistently use version constraints to specify acceptable\nversions of the dependencies for their project. \\emph{Pinning} dependencies can\nreduce the likelihood of breaking changes, but comes with a cost of manually\nmanaging the replacement of outdated and vulnerable dependencies. On the other\nhand, \\emph{floating} can be used to automatically get bug fixes and security\nfixes, but comes with the risk of breaking changes. Security practitioners\nadvocate \\emph{pinning} dependencies to prevent against software supply chain\nattacks, e.g., malicious package updates. However, since \\emph{pinning} is the\ntightest version constraint, \\emph{pinning} is the most likely to result in\noutdated dependencies. Nevertheless, how the likelihood of becoming outdated or\nvulnerable dependencies changes across version constraint types is unknown. The\ngoal of this study is to aid developers in making an informed dependency\nversion constraint choice by empirically evaluating the likelihood of\ndependencies becoming outdated or vulnerable across version constraint types at\nscale. In this study, we first identify the trends in dependency version\nconstraint usage and the patterns of version constraint type changes made by\ndevelopers in the npm, PyPI, and Cargo ecosystems. We then modeled the\ndependency state transitions using survival analysis and estimated how the\nlikelihood of becoming outdated or vulnerable changes when using \\emph{pinning}\nas opposed to the rest of the version constraint types. We observe that among\noutdated and vulnerable dependencies, the most commonly used version constraint\ntype is \\emph{floating-minor}, with \\emph{pinning} being the next most common.\nWe also find that \\emph{floating-major} is the least likely to result in\noutdated and \\emph{floating-minor} is the least likely to result in vulnerable\ndependencies.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790npm\u3001PyPI\u548cCargo\u751f\u6001\u7cfb\u7edf\u4e2d\u4f9d\u8d56\u7248\u672c\u7ea6\u675f\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u53d1\u73b0\u56fa\u5b9a\u7248\u672c(pinning)\u867d\u7136\u80fd\u51cf\u5c11\u7834\u574f\u6027\u53d8\u66f4\u98ce\u9669\uff0c\u4f46\u6700\u53ef\u80fd\u5bfc\u81f4\u4f9d\u8d56\u8fc7\u65f6\uff1b\u800c\u6d6e\u52a8\u7248\u672c\u4e2d\uff0c\u4e3b\u7248\u672c\u6d6e\u52a8\u6700\u4e0d\u5bb9\u6613\u8fc7\u65f6\uff0c\u6b21\u7248\u672c\u6d6e\u52a8\u6700\u4e0d\u5bb9\u6613\u4ea7\u751f\u6f0f\u6d1e\u3002", "motivation": "\u5f00\u53d1\u8005\u5728\u4f9d\u8d56\u7ba1\u7406\u65f6\u9762\u4e34\u4e24\u96be\u9009\u62e9\uff1a\u56fa\u5b9a\u7248\u672c\u53ef\u9632\u6b62\u7834\u574f\u6027\u53d8\u66f4\u4f46\u5bb9\u6613\u8fc7\u65f6\uff0c\u6d6e\u52a8\u7248\u672c\u80fd\u81ea\u52a8\u83b7\u53d6\u4fee\u590d\u4f46\u5b58\u5728\u98ce\u9669\u3002\u76ee\u524d\u7f3a\u4e4f\u5173\u4e8e\u4e0d\u540c\u7248\u672c\u7ea6\u675f\u7c7b\u578b\u5bf9\u4f9d\u8d56\u8fc7\u65f6\u548c\u6f0f\u6d1e\u98ce\u9669\u5f71\u54cd\u7684\u5b9e\u8bc1\u7814\u7a76\u3002", "method": "\u8bc6\u522bnpm\u3001PyPI\u548cCargo\u751f\u6001\u7cfb\u7edf\u4e2d\u4f9d\u8d56\u7248\u672c\u7ea6\u675f\u7684\u4f7f\u7528\u8d8b\u52bf\u548c\u53d8\u66f4\u6a21\u5f0f\uff0c\u4f7f\u7528\u751f\u5b58\u5206\u6790\u5efa\u6a21\u4f9d\u8d56\u72b6\u6001\u8f6c\u6362\uff0c\u8bc4\u4f30\u56fa\u5b9a\u7248\u672c\u4e0e\u5176\u4ed6\u7ea6\u675f\u7c7b\u578b\u76f8\u6bd4\u5bfc\u81f4\u4f9d\u8d56\u8fc7\u65f6\u6216\u6f0f\u6d1e\u7684\u53ef\u80fd\u6027\u3002", "result": "\u5728\u8fc7\u65f6\u548c\u6613\u53d7\u653b\u51fb\u7684\u4f9d\u8d56\u4e2d\uff0c\u6700\u5e38\u7528\u7684\u7ea6\u675f\u7c7b\u578b\u662f\u6b21\u7248\u672c\u6d6e\u52a8\uff0c\u5176\u6b21\u662f\u56fa\u5b9a\u7248\u672c\u3002\u4e3b\u7248\u672c\u6d6e\u52a8\u6700\u4e0d\u5bb9\u6613\u5bfc\u81f4\u4f9d\u8d56\u8fc7\u65f6\uff0c\u6b21\u7248\u672c\u6d6e\u52a8\u6700\u4e0d\u5bb9\u6613\u4ea7\u751f\u6f0f\u6d1e\u4f9d\u8d56\u3002", "conclusion": "\u56fa\u5b9a\u7248\u672c\u867d\u7136\u88ab\u5b89\u5168\u4ece\u4e1a\u8005\u63a8\u8350\u4ee5\u9632\u6b62\u4f9b\u5e94\u94fe\u653b\u51fb\uff0c\u4f46\u5b9e\u9645\u4f1a\u589e\u52a0\u4f9d\u8d56\u8fc7\u65f6\u7684\u98ce\u9669\u3002\u5f00\u53d1\u8005\u5728\u9009\u62e9\u7248\u672c\u7ea6\u675f\u65f6\u5e94\u6839\u636e\u5177\u4f53\u9700\u6c42\u6743\u8861\uff1a\u4e3b\u7248\u672c\u6d6e\u52a8\u9002\u5408\u907f\u514d\u8fc7\u65f6\uff0c\u6b21\u7248\u672c\u6d6e\u52a8\u9002\u5408\u51cf\u5c11\u6f0f\u6d1e\u98ce\u9669\u3002"}}
{"id": "2510.08610", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08610", "abs": "https://arxiv.org/abs/2510.08610", "authors": ["Imranur Rahman", "Md Rayhanur Rahman"], "title": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model", "comment": "Accepted to Context Collection Workshop co-located with ASE 2025", "summary": "Code completion can help developers improve efficiency and ease the\ndevelopment lifecycle. Although code completion is available in modern\nintegrated development environments (IDEs), research lacks in determining what\nmakes a good context for code completion based on the information available to\nthe IDEs for the large language models (LLMs) to perform better. In this paper,\nwe describe an effective context collection strategy to assist the LLMs in\nperforming better at code completion tasks. The key idea of our strategy is to\npreprocess the repository into smaller code chunks and later use syntactic and\nsemantic similarity-based code chunk retrieval with relative positioning. We\nfound that code chunking and relative positioning of the chunks in the final\ncontext improve the performance of code completion tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7801\u5206\u5757\u548c\u76f8\u5bf9\u5b9a\u4f4d\u7684\u4e0a\u4e0b\u6587\u6536\u96c6\u7b56\u7565\uff0c\u901a\u8fc7\u8bed\u6cd5\u548c\u8bed\u4e49\u76f8\u4f3c\u6027\u68c0\u7d22\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709IDE\u4e2d\u7684\u4ee3\u7801\u8865\u5168\u529f\u80fd\u7f3a\u4e4f\u5bf9\u6709\u6548\u4e0a\u4e0b\u6587\u7684\u7814\u7a76\uff0c\u9700\u8981\u786e\u5b9a\u57fa\u4e8eIDE\u53ef\u7528\u4fe1\u606f\u7684\u6700\u4f73\u4e0a\u4e0b\u6587\u7b56\u7565\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u8865\u5168\u6548\u679c\u3002", "method": "\u5c06\u4ee3\u7801\u4ed3\u5e93\u9884\u5904\u7406\u4e3a\u5c0f\u4ee3\u7801\u5757\uff0c\u4f7f\u7528\u57fa\u4e8e\u8bed\u6cd5\u548c\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u4ee3\u7801\u5757\u68c0\u7d22\u65b9\u6cd5\uff0c\u5e76\u5728\u6700\u7ec8\u4e0a\u4e0b\u6587\u4e2d\u91c7\u7528\u76f8\u5bf9\u5b9a\u4f4d\u7b56\u7565\u3002", "result": "\u4ee3\u7801\u5206\u5757\u548c\u4ee3\u7801\u5757\u5728\u4e0a\u4e0b\u6587\u4e2d\u7684\u76f8\u5bf9\u5b9a\u4f4d\u80fd\u591f\u663e\u8457\u63d0\u5347\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e0a\u4e0b\u6587\u6536\u96c6\u7b56\u7565\u901a\u8fc7\u4ee3\u7801\u5206\u5757\u548c\u76f8\u5bf9\u5b9a\u4f4d\u6709\u6548\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2510.08612", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08612", "abs": "https://arxiv.org/abs/2510.08612", "authors": ["Devang Dhanuka"], "title": "Impact of LLMs on Team Collaboration in Software Development", "comment": null, "summary": "Large Language Models (LLMs) are increasingly being integrated into software\ndevelopment processes, with the potential to transform team workflows and\nproductivity. This paper investigates how LLMs affect team collaboration\nthroughout the Software Development Life Cycle (SDLC). We reframe and update a\nprior study with recent developments as of 2025, incorporating new literature\nand case studies. We outline the problem of collaboration hurdles in SDLC and\nexplore how LLMs can enhance productivity, communication, and decision-making\nin a team context. Through literature review, industry examples, a team survey,\nand two case studies, we assess the impact of LLM-assisted tools (such as code\ngeneration assistants and AI-powered project management agents) on\ncollaborative software engineering practices. Our findings indicate that LLMs\ncan significantly improve efficiency (by automating repetitive tasks and\ndocumentation), enhance communication clarity, and aid cross-functional\ncollaboration, while also introducing new challenges like model limitations and\nprivacy concerns. We discuss these benefits and challenges, present research\nquestions guiding the investigation, evaluate threats to validity, and suggest\nfuture research directions including domain-specific model customization,\nimproved integration into development tools, and robust strategies for ensuring\ntrust and security.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76LLMs\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u5bf9\u56e2\u961f\u534f\u4f5c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0LLMs\u80fd\u663e\u8457\u63d0\u5347\u6548\u7387\u3001\u6539\u5584\u6c9f\u901a\uff0c\u4f46\u4e5f\u5e26\u6765\u6a21\u578b\u5c40\u9650\u6027\u548c\u9690\u79c1\u7b49\u65b0\u6311\u6218\u3002", "motivation": "\u968f\u7740LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\uff0c\u9700\u8981\u4e86\u89e3\u5b83\u4eec\u5982\u4f55\u6539\u53d8\u56e2\u961f\u5de5\u4f5c\u6d41\u7a0b\u548c\u751f\u4ea7\u529b\uff0c\u7279\u522b\u662f\u5bf9\u56e2\u961f\u534f\u4f5c\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u3001\u884c\u4e1a\u6848\u4f8b\u3001\u56e2\u961f\u8c03\u67e5\u548c\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u8bc4\u4f30LLM\u8f85\u52a9\u5de5\u5177\u5bf9\u534f\u4f5c\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u7684\u5f71\u54cd\u3002", "result": "LLMs\u80fd\u663e\u8457\u63d0\u9ad8\u6548\u7387\uff08\u81ea\u52a8\u5316\u91cd\u590d\u4efb\u52a1\u548c\u6587\u6863\uff09\u3001\u589e\u5f3a\u6c9f\u901a\u6e05\u6670\u5ea6\u3001\u4fc3\u8fdb\u8de8\u804c\u80fd\u534f\u4f5c\uff0c\u540c\u65f6\u5f15\u5165\u6a21\u578b\u5c40\u9650\u6027\u548c\u9690\u79c1\u95ee\u9898\u7b49\u65b0\u6311\u6218\u3002", "conclusion": "LLMs\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u56e2\u961f\u534f\u4f5c\u5177\u6709\u79ef\u6781\u5f71\u54cd\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u6a21\u578b\u5b9a\u5236\u3001\u5de5\u5177\u96c6\u6210\u3001\u4fe1\u4efb\u548c\u5b89\u5168\u7b49\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.08619", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08619", "abs": "https://arxiv.org/abs/2510.08619", "authors": ["Tennison Liu", "Silas Ruhrberg Est\u00e9vez", "David L. Bentley", "Mihaela van der Schaar"], "title": "Hypothesis Hunting with Evolving Networks of Autonomous Scientific Agents", "comment": null, "summary": "Large-scale scientific datasets -- spanning health biobanks, cell atlases,\nEarth reanalyses, and more -- create opportunities for exploratory discovery\nunconstrained by specific research questions. We term this process hypothesis\nhunting: the cumulative search for insight through sustained exploration across\nvast and complex hypothesis spaces. To support it, we introduce AScience, a\nframework modeling discovery as the interaction of agents, networks, and\nevaluation norms, and implement it as ASCollab, a distributed system of\nLLM-based research agents with heterogeneous behaviors. These agents\nself-organize into evolving networks, continually producing and peer-reviewing\nfindings under shared standards of evaluation. Experiments show that such\nsocial dynamics enable the accumulation of expert-rated results along the\ndiversity-quality-novelty frontier, including rediscoveries of established\nbiomarkers, extensions of known pathways, and proposals of new therapeutic\ntargets. While wet-lab validation remains indispensable, our experiments on\ncancer cohorts demonstrate that socially structured, agentic networks can\nsustain exploratory hypothesis hunting at scale.", "AI": {"tldr": "\u63d0\u51fa\u4e86AScience\u6846\u67b6\u548cASCollab\u7cfb\u7edf\uff0c\u901a\u8fc7LLM\u7814\u7a76\u4ee3\u7406\u7684\u81ea\u7ec4\u7ec7\u7f51\u7edc\u5b9e\u73b0\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u96c6\u7684\u5047\u8bbe\u63a2\u7d22\uff0c\u5728\u764c\u75c7\u961f\u5217\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u96c6\u4e3a\u65e0\u7ea6\u675f\u7684\u63a2\u7d22\u6027\u53d1\u73b0\u521b\u9020\u4e86\u673a\u4f1a\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u79cd\u590d\u6742\u7684\u5047\u8bbe\u7a7a\u95f4\u63a2\u7d22\u3002", "method": "\u5f15\u5165AScience\u6846\u67b6\uff0c\u5c06\u53d1\u73b0\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u4ee3\u7406\u3001\u7f51\u7edc\u548c\u8bc4\u4f30\u89c4\u8303\u7684\u4ea4\u4e92\uff0c\u5e76\u5b9e\u73b0\u4e3aASCollab\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u4f7f\u7528\u5177\u6709\u5f02\u8d28\u884c\u4e3a\u7684LLM\u7814\u7a76\u4ee3\u7406\u81ea\u7ec4\u7ec7\u6210\u6f14\u5316\u7f51\u7edc\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8fd9\u79cd\u793e\u4f1a\u52a8\u529b\u5b66\u80fd\u591f\u79ef\u7d2f\u4e13\u5bb6\u8bc4\u7ea7\u7684\u591a\u6837\u5316\u3001\u9ad8\u8d28\u91cf\u3001\u65b0\u9896\u7684\u7ed3\u679c\uff0c\u5305\u62ec\u91cd\u65b0\u53d1\u73b0\u5df2\u5efa\u7acb\u7684\u751f\u7269\u6807\u5fd7\u7269\u3001\u6269\u5c55\u5df2\u77e5\u901a\u8def\u548c\u63d0\u51fa\u65b0\u7684\u6cbb\u7597\u9776\u70b9\u3002", "conclusion": "\u867d\u7136\u6e7f\u5b9e\u9a8c\u5ba4\u9a8c\u8bc1\u4ecd\u7136\u4e0d\u53ef\u6216\u7f3a\uff0c\u4f46\u793e\u4f1a\u7ed3\u6784\u5316\u3001\u4ee3\u7406\u7f51\u7edc\u53ef\u4ee5\u5728\u764c\u75c7\u961f\u5217\u4e2d\u6301\u7eed\u8fdb\u884c\u5927\u89c4\u6a21\u7684\u63a2\u7d22\u6027\u5047\u8bbe\u63a2\u7d22\u3002"}}
{"id": "2510.08700", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.08700", "abs": "https://arxiv.org/abs/2510.08700", "authors": ["Zhuolun Li", "Haluk Sonmezler", "Faiza Shirazi", "Febin Shaji", "Tymoteusz Mroczkowski", "Dexter Lardner", "Matthew Alain Camus", "Evangelos Pournaras"], "title": "Are Voters Willing to Collectively Secure Elections? Unraveling a Practical Blockchain Voting System", "comment": null, "summary": "Ensuring ballot secrecy is critical for fair and trustworthy electronic\nvoting systems, yet achieving strong secrecy guarantees in decentralized,\nlarge-scale elections remains challenging. This paper proposes the concept of\ncollectively secure voting, in which voters themselves can opt in as secret\nholders to protect ballot secrecy. A practical blockchain-based collectively\nsecure voting system is designed and implemented. Our design strikes a balance\nbetween strong confidentiality guarantees and real-world applicability. The\nproposed system combines threshold cryptography and smart contracts to ensure\nballots remain confidential during voting, while all protocol steps remain\ntransparent and verifiable. Voters can use the system without prior blockchain\nknowledge through an intuitive user interface that hides underlying complexity.\nTo evaluate this approach, a user testing is conducted. Results show a high\nwillingness to act as secret holders, reliable participation in share release,\nand high security confidence in the proposed system. The findings demonstrate\nthat voters can collectively maintain secrecy and that such a practical\ndeployment is feasible.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u96c6\u4f53\u5b89\u5168\u6295\u7968\u7cfb\u7edf\uff0c\u901a\u8fc7\u9009\u6c11\u81ea\u613f\u6210\u4e3a\u79d8\u5bc6\u6301\u6709\u8005\u6765\u4fdd\u62a4\u9009\u7968\u673a\u5bc6\u6027\uff0c\u7ed3\u5408\u95e8\u9650\u5bc6\u7801\u5b66\u548c\u667a\u80fd\u5408\u7ea6\u5b9e\u73b0\u5f3a\u4fdd\u5bc6\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u5728\u53bb\u4e2d\u5fc3\u5316\u3001\u5927\u89c4\u6a21\u9009\u4e3e\u4e2d\u786e\u4fdd\u9009\u7968\u673a\u5bc6\u6027\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u5e73\u8861\u5f3a\u4fdd\u5bc6\u4fdd\u8bc1\u4e0e\u73b0\u5b9e\u9002\u7528\u6027\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u96c6\u4f53\u5b89\u5168\u6295\u7968\u7cfb\u7edf\uff0c\u7ed3\u5408\u95e8\u9650\u5bc6\u7801\u5b66\u548c\u667a\u80fd\u5408\u7ea6\uff0c\u63d0\u4f9b\u76f4\u89c2\u7528\u6237\u754c\u9762\u9690\u85cf\u5e95\u5c42\u590d\u6742\u6027\u3002", "result": "\u7528\u6237\u6d4b\u8bd5\u663e\u793a\u9009\u6c11\u9ad8\u5ea6\u613f\u610f\u62c5\u4efb\u79d8\u5bc6\u6301\u6709\u8005\uff0c\u53ef\u9760\u53c2\u4e0e\u4efd\u989d\u91ca\u653e\uff0c\u5e76\u5bf9\u7cfb\u7edf\u5b89\u5168\u6027\u6709\u9ad8\u5ea6\u4fe1\u5fc3\u3002", "conclusion": "\u9009\u6c11\u80fd\u591f\u96c6\u4f53\u7ef4\u62a4\u9009\u7968\u673a\u5bc6\u6027\uff0c\u8fd9\u79cd\u5b9e\u9645\u90e8\u7f72\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u5b89\u5168\u4fdd\u969c\u65b9\u6848\u3002"}}
{"id": "2510.08640", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08640", "abs": "https://arxiv.org/abs/2510.08640", "authors": ["Ha Min Son", "Huan Ren", "Xin Liu", "Zhe Zhao"], "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "comment": null, "summary": "Android is the largest mobile platform, yet automatically building\napplications remains a practical challenge. While Large Language Models (LLMs)\nshow promise for code repair, their use for fixing Android build errors remains\nunderexplored. To address this gap, we first introduce AndroidBuildBench, a\nbenchmark of 1,019 build failures curated from the commit histories of 43\nopen-source Android projects. Each problem is paired with a verified solution\nfrom a subsequent commit, ensuring that fixes are feasible. Second, we propose\nGradleFixer, an LLM agent with domain-specific tools for inspecting and\nmanipulating the Gradle build environment. GradleFixer achieves a resolve rate\nof 81.4% (pass@1), significantly outperforming a state-of-the-art coding agent\nthat relies on a general-purpose shell. GradleFixer's success suggests that\nwhile LLMs possess the high-level knowledge to solve these failures, they\nstruggle to translate this knowledge into effective low-level actions using a\ngeneral-purpose shell. We demonstrate the effectiveness of a strategy we term\nTool Bridging, which replaces general-purpose shell commands with domain-aware\nabstractions. We hypothesize this approach works through two mechanisms: 1) it\nprovides tools in an API-like format that LLMs use more reliably, and 2) it\nconstrains the action space to relevant operations. This approach bridges the\ngap between the model's high-level reasoning and effective low-level execution.", "AI": {"tldr": "\u63d0\u51fa\u4e86GradleFixer\uff0c\u4e00\u4e2a\u9488\u5bf9Android\u6784\u5efa\u9519\u8bef\u7684LLM\u4ee3\u7406\uff0c\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u5de5\u5177\u663e\u8457\u63d0\u5347\u4e86\u6784\u5efa\u9519\u8bef\u4fee\u590d\u6210\u529f\u7387", "motivation": "Android\u4f5c\u4e3a\u6700\u5927\u7684\u79fb\u52a8\u5e73\u53f0\uff0c\u81ea\u52a8\u6784\u5efa\u5e94\u7528\u4ecd\u9762\u4e34\u6311\u6218\u3002\u867d\u7136LLM\u5728\u4ee3\u7801\u4fee\u590d\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u4fee\u590dAndroid\u6784\u5efa\u9519\u8bef\u65b9\u9762\u7814\u7a76\u4e0d\u8db3", "method": "1. \u521b\u5efaAndroidBuildBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff081,019\u4e2a\u6784\u5efa\u5931\u8d25\u6848\u4f8b\uff09\uff1b2. \u5f00\u53d1GradleFixer\u4ee3\u7406\uff0c\u4f7f\u7528\u9886\u57df\u7279\u5b9a\u5de5\u5177\u68c0\u67e5\u548c\u64cd\u4f5cGradle\u6784\u5efa\u73af\u5883\uff1b3. \u91c7\u7528\u5de5\u5177\u6865\u63a5\u7b56\u7565\uff0c\u5c06\u901a\u7528shell\u547d\u4ee4\u66ff\u6362\u4e3a\u9886\u57df\u611f\u77e5\u62bd\u8c61", "result": "GradleFixer\u5b9e\u73b0\u4e8681.4%\u7684\u89e3\u51b3\u7387\uff08pass@1\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u4f9d\u8d56\u901a\u7528shell\u7684\u6700\u5148\u8fdb\u7f16\u7801\u4ee3\u7406", "conclusion": "LLM\u5177\u5907\u89e3\u51b3\u6784\u5efa\u5931\u8d25\u7684\u9ad8\u5c42\u77e5\u8bc6\uff0c\u4f46\u96be\u4ee5\u901a\u8fc7\u901a\u7528shell\u5c06\u5176\u8f6c\u5316\u4e3a\u6709\u6548\u7684\u5e95\u5c42\u64cd\u4f5c\u3002\u5de5\u5177\u6865\u63a5\u7b56\u7565\u901a\u8fc7\u63d0\u4f9bAPI\u683c\u5f0f\u7684\u5de5\u5177\u548c\u7ea6\u675f\u64cd\u4f5c\u7a7a\u95f4\uff0c\u6210\u529f\u5f25\u5408\u4e86\u9ad8\u5c42\u63a8\u7406\u4e0e\u5e95\u5c42\u6267\u884c\u4e4b\u95f4\u7684\u5dee\u8ddd"}}
{"id": "2510.08671", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08671", "abs": "https://arxiv.org/abs/2510.08671", "authors": ["Milon Bhattacharya", "Milan Kumar"], "title": "Optimizing delivery for quick commerce factoring qualitative assessment of generated routes", "comment": null, "summary": "Indias e-commerce market is projected to grow rapidly, with last-mile\ndelivery accounting for nearly half of operational expenses. Although vehicle\nrouting problem (VRP) based solvers are widely used for delivery planning,\ntheir effectiveness in real-world scenarios is limited due to unstructured\naddresses, incomplete maps, and computational constraints in distance\nestimation. This study proposes a framework that employs large language models\n(LLMs) to critique VRP-generated routes against policy-based criteria, allowing\nlogistics operators to evaluate and prioritise more efficient delivery plans.\nAs a illustration of our approach we generate, annotate and evaluated 400 cases\nusing large language models. Our study found that open-source LLMs identified\nrouting issues with 79% accuracy, while proprietary reasoning models achieved\nreach upto 86%. The results demonstrate that LLM-based evaluation of\nVRP-generated routes can be an effective and scalable layer of evaluation which\ngoes beyond beyond conventional distance and time based metrics. This has\nimplications for improving cost efficiency, delivery reliability, and\nsustainability in last-mile logistics, especially for developing countries like\nIndia.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u6765\u8bc4\u4f30\u8f66\u8f86\u8def\u5f84\u89c4\u5212(VRP)\u751f\u6210\u7684\u914d\u9001\u8def\u7ebf\uff0c\u901a\u8fc7\u653f\u7b56\u6807\u51c6\u8fdb\u884c\u6279\u5224\u5206\u6790\uff0c\u5e2e\u52a9\u7269\u6d41\u8fd0\u8425\u5546\u9009\u62e9\u66f4\u9ad8\u6548\u7684\u914d\u9001\u65b9\u6848\u3002", "motivation": "\u5370\u5ea6\u7535\u5546\u5e02\u573a\u5feb\u901f\u589e\u957f\uff0c\u6700\u540e\u4e00\u516c\u91cc\u914d\u9001\u5360\u8fd0\u8425\u6210\u672c\u8fd1\u4e00\u534a\u3002\u4f20\u7edfVRP\u6c42\u89e3\u5668\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u56e0\u975e\u7ed3\u6784\u5316\u5730\u5740\u3001\u4e0d\u5b8c\u6574\u5730\u56fe\u548c\u8ba1\u7b97\u9650\u5236\u800c\u6548\u679c\u6709\u9650\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u4f7f\u7528LLMs\u57fa\u4e8e\u653f\u7b56\u6807\u51c6\u6279\u5224VRP\u751f\u6210\u7684\u8def\u7ebf\uff0c\u751f\u6210\u3001\u6807\u6ce8\u548c\u8bc4\u4f30\u4e86400\u4e2a\u6848\u4f8b\u3002", "result": "\u5f00\u6e90LLMs\u8bc6\u522b\u8def\u7ebf\u95ee\u9898\u7684\u51c6\u786e\u7387\u8fbe\u523079%\uff0c\u4e13\u6709\u63a8\u7406\u6a21\u578b\u53ef\u8fbe86%\u3002LLM\u8bc4\u4f30\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u8ddd\u79bb\u548c\u65f6\u95f4\u6307\u6807\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684VRP\u8def\u7ebf\u8bc4\u4f30\u662f\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u5c42\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6210\u672c\u6548\u7387\u3001\u914d\u9001\u53ef\u9760\u6027\u548c\u53ef\u6301\u7eed\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5370\u5ea6\u7b49\u53d1\u5c55\u4e2d\u56fd\u5bb6\u3002"}}
{"id": "2510.08725", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08725", "abs": "https://arxiv.org/abs/2510.08725", "authors": ["Gorjan Alagic", "Chen Bai", "Christian Majenz", "Kaiyan Shi"], "title": "Post-Quantum Security of Block Cipher Constructions", "comment": null, "summary": "Block ciphers are versatile cryptographic ingredients that are used in a wide\nrange of applications ranging from secure Internet communications to disk\nencryption. While post-quantum security of public-key cryptography has received\nsignificant attention, the case of symmetric-key cryptography (and block\nciphers in particular) remains a largely unexplored topic. In this work, we set\nthe foundations for a theory of post-quantum security for block ciphers and\nassociated constructions. Leveraging our new techniques, we provide the first\npost-quantum security proofs for the key-length extension scheme FX, the\ntweakable block ciphers LRW and XEX, and most block cipher encryption and\nauthentication modes. Our techniques can be used for security proofs in both\nthe plain model and the quantum ideal cipher model. Our work takes significant\ninitial steps in establishing a rigorous understanding of the post-quantum\nsecurity of practical symmetric-key cryptography.", "AI": {"tldr": "\u672c\u6587\u4e3a\u5206\u7ec4\u5bc6\u7801\u7684\u540e\u91cf\u5b50\u5b89\u5168\u7406\u8bba\u5960\u5b9a\u57fa\u7840\uff0c\u9996\u6b21\u4e3aFX\u5bc6\u94a5\u6269\u5c55\u65b9\u6848\u3001LRW\u548cXEX\u53ef\u8c03\u5206\u7ec4\u5bc6\u7801\u4ee5\u53ca\u5927\u591a\u6570\u5206\u7ec4\u5bc6\u7801\u52a0\u5bc6\u548c\u8ba4\u8bc1\u6a21\u5f0f\u63d0\u4f9b\u4e86\u540e\u91cf\u5b50\u5b89\u5168\u8bc1\u660e\u3002", "motivation": "\u867d\u7136\u516c\u94a5\u5bc6\u7801\u7684\u540e\u91cf\u5b50\u5b89\u5168\u5df2\u5f97\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4f46\u5bf9\u79f0\u5bc6\u94a5\u5bc6\u7801\uff08\u7279\u522b\u662f\u5206\u7ec4\u5bc6\u7801\uff09\u7684\u540e\u91cf\u5b50\u5b89\u5168\u4ecd\u662f\u4e00\u4e2a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\u3002", "method": "\u5f00\u53d1\u65b0\u7684\u6280\u672f\u65b9\u6cd5\uff0c\u5728\u666e\u901a\u6a21\u578b\u548c\u91cf\u5b50\u7406\u60f3\u5bc6\u7801\u6a21\u578b\u4e2d\u8fdb\u884c\u5b89\u5168\u8bc1\u660e\u3002", "result": "\u4e3aFX\u5bc6\u94a5\u6269\u5c55\u65b9\u6848\u3001LRW\u548cXEX\u53ef\u8c03\u5206\u7ec4\u5bc6\u7801\u4ee5\u53ca\u5927\u591a\u6570\u5206\u7ec4\u5bc6\u7801\u52a0\u5bc6\u548c\u8ba4\u8bc1\u6a21\u5f0f\u63d0\u4f9b\u4e86\u9996\u4e2a\u540e\u91cf\u5b50\u5b89\u5168\u8bc1\u660e\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5728\u5efa\u7acb\u5b9e\u7528\u5bf9\u79f0\u5bc6\u94a5\u5bc6\u7801\u540e\u91cf\u5b50\u5b89\u5168\u7684\u4e25\u683c\u7406\u89e3\u65b9\u9762\u8fc8\u51fa\u4e86\u91cd\u8981\u7684\u521d\u6b65\u6b65\u9aa4\u3002"}}
{"id": "2510.08664", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08664", "abs": "https://arxiv.org/abs/2510.08664", "authors": ["Jianan Mu", "Mingyu Shi", "Yining Wang", "Tianmeng Yang", "Bin Sun", "Xing Hu", "Jing Ye", "Huawei Li"], "title": "Faver: Boosting LLM-based RTL Generation with Function Abstracted Verifiable Middleware", "comment": null, "summary": "LLM-based RTL generation is an interesting research direction, as it holds\nthe potential to liberate the least automated stage in the current chip design.\nHowever, due to the substantial semantic gap between high-level specifications\nand RTL, coupled with limited training data, existing models struggle with\ngeneration accuracy. Drawing on human experience, design with verification\nhelps improving accuracy. However, as the RTL testbench data are even more\nscarce, it is not friendly for LLMs. Although LLMs excel at higher-level\nlanguages like Python/C, they have a huge semantic gap from RTL. When\nimplementing the same functionality, Python/C code and hardware code differ\nsignificantly in the spatiotemporal granularity, requiring the LLM not only to\nconsider high-level functional semantics but also to ensure the low-level\ndetails align with the circuit code. It is not an easy task. In this paper, we\npropose a function abstracted verifiable middleware (Faver) that streamlines\nRTL verification in LLM-based workflows. By mixing LLM-friendly code structures\nwith a rule-based template, Faver decouples the details of circuit\nverification, allowing the LLM to focus on the functionality itself. In our\nexperiments on the SFT model and open-source models, Faver improved the model's\ngeneration accuracy by up to 14%.", "AI": {"tldr": "\u63d0\u51faFaver\u65b9\u6cd5\uff0c\u901a\u8fc7\u51fd\u6570\u62bd\u8c61\u7684\u53ef\u9a8c\u8bc1\u4e2d\u95f4\u4ef6\u7b80\u5316\u57fa\u4e8eLLM\u7684RTL\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u5c06\u7535\u8def\u9a8c\u8bc1\u7ec6\u8282\u4e0e\u529f\u80fd\u5b9e\u73b0\u89e3\u8026\uff0c\u63d0\u9ad8RTL\u751f\u6210\u51c6\u786e\u6027", "motivation": "\u5f53\u524dLLM\u5728RTL\u751f\u6210\u4e2d\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\uff0c\u9ad8\u89c4\u683c\u8bf4\u660e\u4e0eRTL\u4e4b\u95f4\u5dee\u8ddd\u5927\uff0c\u8bad\u7ec3\u6570\u636e\u6709\u9650\uff0c\u5bfc\u81f4\u751f\u6210\u51c6\u786e\u6027\u4e0d\u8db3\u3002\u4f20\u7edf\u8bbe\u8ba1\u9a8c\u8bc1\u65b9\u6cd5\u56e0RTL\u6d4b\u8bd5\u6570\u636e\u7a00\u7f3a\u800c\u4e0d\u9002\u7528\u4e8eLLM", "method": "\u5f00\u53d1\u51fd\u6570\u62bd\u8c61\u7684\u53ef\u9a8c\u8bc1\u4e2d\u95f4\u4ef6(Faver)\uff0c\u7ed3\u5408LLM\u53cb\u597d\u7684\u4ee3\u7801\u7ed3\u6784\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u6a21\u677f\uff0c\u5c06\u7535\u8def\u9a8c\u8bc1\u7ec6\u8282\u4e0e\u529f\u80fd\u5b9e\u73b0\u5206\u79bb\uff0c\u8ba9LLM\u4e13\u6ce8\u4e8e\u529f\u80fd\u672c\u8eab", "result": "\u5728SFT\u6a21\u578b\u548c\u5f00\u6e90\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFaver\u5c06\u6a21\u578b\u751f\u6210\u51c6\u786e\u6027\u63d0\u9ad8\u4e86\u6700\u9ad814%", "conclusion": "Faver\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728RTL\u751f\u6210\u4e2d\u7684\u9a8c\u8bc1\u6311\u6218\uff0c\u901a\u8fc7\u4e2d\u95f4\u4ef6\u7b80\u5316\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u51c6\u786e\u6027"}}
{"id": "2510.08713", "categories": ["cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08713", "abs": "https://arxiv.org/abs/2510.08713", "authors": ["Yifei Dong", "Fengyi Wu", "Guangyu Chen", "Zhi-Qi Cheng", "Qiyu Hu", "Yuxuan Zhou", "Jingdong Sun", "Jun-Yan He", "Qi Dai", "Alexander G Hauptmann"], "title": "Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation", "comment": "18 pages, 11 figures, code: https://github.com/F1y1113/UniWM", "summary": "Enabling embodied agents to effectively imagine future states is critical for\nrobust and generalizable visual navigation. Current state-of-the-art\napproaches, however, adopt modular architectures that separate navigation\nplanning from visual world modeling, leading to state-action misalignment and\nlimited adaptability in novel or dynamic scenarios. To overcome this\nfundamental limitation, we propose UniWM, a unified, memory-augmented world\nmodel integrating egocentric visual foresight and planning within a single\nmultimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly\ngrounds action decisions in visually imagined outcomes, ensuring tight\nalignment between prediction and control. A hierarchical memory mechanism\nfurther integrates detailed short-term perceptual cues with longer-term\ntrajectory context, enabling stable, coherent reasoning over extended horizons.\nExtensive experiments across four challenging benchmarks (Go Stanford, ReCon,\nSCAND, HuRoN) demonstrate that UniWM substantially improves navigation success\nrates by up to 30%, significantly reduces trajectory errors compared to strong\nbaselines, and exhibits impressive zero-shot generalization on the unseen\nTartanDrive dataset. These results highlight UniWM as a principled step toward\nunified, imagination-driven embodied navigation.", "AI": {"tldr": "\u63d0\u51faUniWM\u7edf\u4e00\u4e16\u754c\u6a21\u578b\uff0c\u5c06\u89c6\u89c9\u9884\u6d4b\u4e0e\u5bfc\u822a\u89c4\u5212\u96c6\u6210\u5728\u5355\u4e00\u591a\u6a21\u6001\u81ea\u56de\u5f52\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u8bb0\u5fc6\u673a\u5236\u5b9e\u73b0\u957f\u65f6\u7a0b\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u5bfc\u822a\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6a21\u5757\u5316\u67b6\u6784\u4e2d\u5bfc\u822a\u89c4\u5212\u4e0e\u89c6\u89c9\u4e16\u754c\u5efa\u6a21\u5206\u79bb\u5bfc\u81f4\u7684\u72b6\u6001-\u52a8\u4f5c\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u4ee5\u53ca\u5728\u65b0\u9896\u6216\u52a8\u6001\u573a\u666f\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7edf\u4e00\u3001\u8bb0\u5fc6\u589e\u5f3a\u7684\u4e16\u754c\u6a21\u578b\uff0c\u5728\u5355\u4e00\u591a\u6a21\u6001\u81ea\u56de\u5f52\u4e3b\u5e72\u4e2d\u96c6\u6210\u81ea\u6211\u4e2d\u5fc3\u89c6\u89c9\u9884\u6d4b\u548c\u89c4\u5212\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u8bb0\u5fc6\u673a\u5236\u7ed3\u5408\u77ed\u671f\u611f\u77e5\u7ebf\u7d22\u548c\u957f\u671f\u8f68\u8ff9\u4e0a\u4e0b\u6587\u3002", "result": "\u5728\u56db\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5bfc\u822a\u6210\u529f\u7387\u63d0\u5347\u9ad8\u8fbe30%\uff0c\u8f68\u8ff9\u8bef\u5dee\u663e\u8457\u964d\u4f4e\uff0c\u5e76\u5728\u672a\u89c1\u8fc7\u7684TartanDrive\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "UniWM\u662f\u671d\u7740\u7edf\u4e00\u3001\u60f3\u8c61\u529b\u9a71\u52a8\u7684\u5177\u8eab\u5bfc\u822a\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u8bc1\u660e\u4e86\u5728\u5355\u4e00\u6846\u67b6\u4e2d\u6574\u5408\u9884\u6d4b\u548c\u89c4\u5212\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.08829", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08829", "abs": "https://arxiv.org/abs/2510.08829", "authors": ["Debeshee Das", "Luca Beurer-Kellner", "Marc Fischer", "Maximilian Baader"], "title": "CommandSans: Securing AI Agents with Surgical Precision Prompt Sanitization", "comment": null, "summary": "The increasing adoption of LLM agents with access to numerous tools and\nsensitive data significantly widens the attack surface for indirect prompt\ninjections. Due to the context-dependent nature of attacks, however, current\ndefenses are often ill-calibrated as they cannot reliably differentiate\nmalicious and benign instructions, leading to high false positive rates that\nprevent their real-world adoption. To address this, we present a novel approach\ninspired by the fundamental principle of computer security: data should not\ncontain executable instructions. Instead of sample-level classification, we\npropose a token-level sanitization process, which surgically removes any\ninstructions directed at AI systems from tool outputs, capturing malicious\ninstructions as a byproduct. In contrast to existing safety classifiers, this\napproach is non-blocking, does not require calibration, and is agnostic to the\ncontext of tool outputs. Further, we can train such token-level predictors with\nreadily available instruction-tuning data only, and don't have to rely on\nunrealistic prompt injection examples from challenges or of other synthetic\norigin. In our experiments, we find that this approach generalizes well across\na wide range of attacks and benchmarks like AgentDojo, BIPIA, InjecAgent, ASB\nand SEP, achieving a 7-10x reduction of attack success rate (ASR) (34% to 3% on\nAgentDojo), without impairing agent utility in both benign and malicious\nsettings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u4e0d\u5e94\u5305\u542b\u53ef\u6267\u884c\u6307\u4ee4\u539f\u5219\u7684token\u7ea7\u51c0\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u5de5\u5177\u8f93\u51fa\u4e2d\u7cbe\u786e\u79fb\u9664AI\u7cfb\u7edf\u6307\u4ee4\u6765\u9632\u5fa1\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u65e0\u9700\u4f9d\u8d56\u6837\u672c\u7ea7\u5206\u7c7b\u6216\u590d\u6742\u6821\u51c6\u3002", "motivation": "LLM\u4ee3\u7406\u5de5\u5177\u8bbf\u95ee\u6743\u9650\u6269\u5927\u5bfc\u81f4\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u9762\u663e\u8457\u589e\u52a0\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u56e0\u65e0\u6cd5\u53ef\u9760\u533a\u5206\u6076\u610f\u548c\u826f\u6027\u6307\u4ee4\u800c\u5b58\u5728\u9ad8\u8bef\u62a5\u7387\uff0c\u963b\u788d\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528token\u7ea7\u51c0\u5316\u8fc7\u7a0b\uff0c\u4ece\u5de5\u5177\u8f93\u51fa\u4e2d\u7cbe\u786e\u79fb\u9664\u9488\u5bf9AI\u7cfb\u7edf\u7684\u6307\u4ee4\uff0c\u4f7f\u7528\u73b0\u6210\u7684\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u65e0\u9700\u4f9d\u8d56\u5408\u6210\u653b\u51fb\u6837\u672c\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff08AgentDojo\u3001BIPIA\u7b49\uff09\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e7-10\u500d\uff08\u4ece34%\u964d\u81f33%\uff09\uff0c\u4e14\u4e0d\u5f71\u54cd\u4ee3\u7406\u5728\u826f\u6027\u548c\u6076\u610f\u573a\u666f\u4e0b\u7684\u6548\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u975e\u963b\u585e\u3001\u65e0\u9700\u6821\u51c6\u4e14\u4e0e\u5de5\u5177\u8f93\u51fa\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u9632\u5fa1\u65b9\u6848\uff0c\u80fd\u6709\u6548\u5e94\u5bf9\u5e7f\u6cdb\u7684\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002"}}
{"id": "2510.08665", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08665", "abs": "https://arxiv.org/abs/2510.08665", "authors": ["Aofan Liu", "Haoxuan Li", "Bin Wang", "Ao Yang", "Hui Li"], "title": "RA-Gen: A Controllable Code Generation Framework Using ReAct for Multi-Agent Task Execution", "comment": null, "summary": "Code generation models based on large language models (LLMs) have gained wide\nadoption, but challenges remain in ensuring safety, accuracy, and\ncontrollability, especially for complex tasks. Existing methods often lack\ndynamic integration of external tools, transparent reasoning, and user control\nover safety. To address these issues, we propose a controllable code generation\nframework utilizing the ReAct paradigm for multi-agent task execution. This\nframework is a multi-agent system designed to enable efficient, precise, and\ninterpretable code generation through dynamic interactions between LLMs and\nexternal resources. The framework adopts a collaborative architecture\ncomprising four specialized agents: a Planner for task decomposition, a\nSearcher that leverages the ReAct framework for reasoning and tool integration,\na CodeGen agent for accurate code generation, and an Extractor for structured\ndata retrieval. The ReAct-based Searcher alternates between generating\nreasoning traces and executing actions, facilitating seamless integration of\ninternal knowledge with external tools (such as search engines) to enhance\naccuracy and user control. Experimental results show the framework's\neffectiveness across multiple languages, achieving a 94.8% security rate on the\nSVEN dataset with CodeQL, outperforming existing approaches. Its transparent\nreasoning process fosters user trust and improves controllability.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eReAct\u8303\u5f0f\u7684\u53ef\u63a7\u4ee3\u7801\u751f\u6210\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\u534f\u4f5c\u5b9e\u73b0\u5b89\u5168\u3001\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u7684\u4ee3\u7801\u751f\u6210\uff0c\u5728SVEN\u6570\u636e\u96c6\u4e0a\u8fbe\u523094.8%\u7684\u5b89\u5168\u7387\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u6a21\u578b\u5728\u5b89\u5168\u6027\u3001\u51c6\u786e\u6027\u548c\u53ef\u63a7\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u7f3a\u4e4f\u5916\u90e8\u5de5\u5177\u7684\u52a8\u6001\u96c6\u6210\u3001\u900f\u660e\u63a8\u7406\u548c\u7528\u6237\u5b89\u5168\u63a7\u5236\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u67b6\u6784\uff0c\u5305\u542b\u89c4\u5212\u5668\u3001\u57fa\u4e8eReAct\u7684\u641c\u7d22\u5668\u3001\u4ee3\u7801\u751f\u6210\u5668\u548c\u63d0\u53d6\u5668\u56db\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u63a8\u7406\u8f68\u8ff9\u548c\u52a8\u4f5c\u6267\u884c\u7684\u4ea4\u66ff\u5b9e\u73b0\u5185\u5916\u77e5\u8bc6\u7684\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u5728SVEN\u6570\u636e\u96c6\u4e0a\u4f7f\u7528CodeQL\u8bc4\u4f30\u8fbe\u523094.8%\u7684\u5b89\u5168\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u652f\u6301\u591a\u8bed\u8a00\u4ee3\u7801\u751f\u6210\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u900f\u660e\u63a8\u7406\u8fc7\u7a0b\u589e\u5f3a\u7528\u6237\u4fe1\u4efb\uff0c\u63d0\u9ad8\u53ef\u63a7\u6027\uff0c\u4e3a\u590d\u6742\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u9ad8\u6548\u3001\u7cbe\u786e\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08755", "categories": ["cs.AI", "cs.CL", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.08755", "abs": "https://arxiv.org/abs/2510.08755", "authors": ["Pantea Karimi", "Dany Rouhana", "Pooria Namyar", "Siva Kesava Reddy Kakarla", "Venkat Arun", "Behnaz Arzani"], "title": "Robust Heuristic Algorithm Design with LLMs", "comment": null, "summary": "We posit that we can generate more robust and performant heuristics if we\naugment approaches using LLMs for heuristic design with tools that explain why\nheuristics underperform and suggestions about how to fix them. We find even\nsimple ideas that (1) expose the LLM to instances where the heuristic\nunderperforms; (2) explain why they occur; and (3) specialize design to regions\nin the input space, can produce more robust algorithms compared to existing\ntechniques~ -- ~the heuristics we produce have a $\\sim28\\times$ better\nworst-case performance compared to FunSearch, improve average performance, and\nmaintain the runtime.", "AI": {"tldr": "\u901a\u8fc7\u5411LLM\u63d0\u4f9b\u542f\u53d1\u5f0f\u65b9\u6cd5\u8868\u73b0\u4e0d\u4f73\u7684\u5b9e\u4f8b\u3001\u89e3\u91ca\u539f\u56e0\u5e76\u8fdb\u884c\u8f93\u5165\u7a7a\u95f4\u533a\u57df\u4e13\u4e1a\u5316\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u751f\u6210\u6bd4\u73b0\u6709\u6280\u672f\u66f4\u9c81\u68d2\u7684\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u8fd0\u884c\u65f6\u95f4\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6700\u5dee\u60c5\u51b5\u548c\u5e73\u5747\u6027\u80fd\u3002", "motivation": "\u589e\u5f3a\u4f7f\u7528LLM\u8bbe\u8ba1\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u89e3\u91ca\u542f\u53d1\u5f0f\u65b9\u6cd5\u8868\u73b0\u4e0d\u4f73\u7684\u539f\u56e0\u548c\u63d0\u4f9b\u4fee\u590d\u5efa\u8bae\uff0c\u751f\u6210\u66f4\u9c81\u68d2\u548c\u6027\u80fd\u66f4\u597d\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u7b80\u5355\u60f3\u6cd5\uff1a(1)\u5411LLM\u5c55\u793a\u542f\u53d1\u5f0f\u65b9\u6cd5\u8868\u73b0\u4e0d\u4f73\u7684\u5b9e\u4f8b\uff1b(2)\u89e3\u91ca\u8868\u73b0\u4e0d\u4f73\u7684\u539f\u56e0\uff1b(3)\u5728\u8f93\u5165\u7a7a\u95f4\u7279\u5b9a\u533a\u57df\u8fdb\u884c\u4e13\u4e1a\u5316\u8bbe\u8ba1\u3002", "result": "\u751f\u6210\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u76f8\u6bd4FunSearch\u5728\u6700\u5dee\u60c5\u51b5\u4e0b\u6027\u80fd\u63d0\u5347\u7ea628\u500d\uff0c\u5e73\u5747\u6027\u80fd\u4e5f\u6709\u6240\u63d0\u9ad8\uff0c\u540c\u65f6\u4fdd\u6301\u8fd0\u884c\u65f6\u95f4\u4e0d\u53d8\u3002", "conclusion": "\u901a\u8fc7\u5411LLM\u63d0\u4f9b\u8868\u73b0\u4e0d\u4f73\u5b9e\u4f8b\u7684\u89e3\u91ca\u548c\u4e13\u4e1a\u5316\u8bbe\u8ba1\u5efa\u8bae\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2510.08918", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08918", "abs": "https://arxiv.org/abs/2510.08918", "authors": ["Boyu Liu", "Yang Zhang", "Liang Cheng", "Yi Zhang", "Junjie Fan", "Yu Fu"], "title": "Psyzkaller: Learning from Historical and On-the-Fly Execution Data for Smarter Seed Generation in OS kernel Fuzzing", "comment": null, "summary": "Fuzzing has become a cornerstone technique for uncovering vulnerabilities and\nenhancing the security of OS kernels. However, state-of-the-art kernel fuzzers,\nincluding the de facto standard Syzkaller, struggle to generate valid syscall\nsequences that respect implicit Syscall Dependency Relations (SDRs).\nConsequently, many generated seeds either fail kernel validation or cannot\npenetrate deep execution paths, resulting in significant inefficiency.\n  We hypothesize that SDRs can be effectively learned from both historic and\npresent kernel execution data, and that incorporating these learned relations\ninto fuzzing can substantially improve seed validity and diversity. To validate\nthis, we propose an approach that utilizes the N-gram model to mine SDRs from\nthe Dongting dataset-one of the largest Linux kernel execution datasets\navailable-as well as from execution traces collected on the fly during fuzzing.\nThe resulting model is used to continuously augment the Choice Table of\nSyzkaller to improve its seed generation and demonstrably increases the Shannon\nEntropy of the Choice Table throughout fuzzing, reflecting more\nempirically-grounded choices in expanding syscall sequences into valid and\ndiverse seeds. In addition, we introduce a Random Walk strategy that instructs\nSyzkaller to construct seeds in a bidirectional manner to further diversify the\ngenerated seeds.\n  We implement our approach in a prototype, Psyzkaller, built on top of\nSyzkaller. Experiments on three representative Linux kernel versions show that\nPsyzkaller improves Syzkaller's code coverage by 4.6%-7.0% in 48-hour fuzzing,\nwhile triggering 110.4%-187.2% more crashes. Moreover, our investigation shows\nthat Psyzkaller discovered eight previously unknown kernel vulnerabilities,\ncompared to only one found by Syzkaller.", "AI": {"tldr": "Psyzkaller\u901a\u8fc7N-gram\u6a21\u578b\u4ece\u5386\u53f2\u6570\u636e\u548c\u5b9e\u65f6\u6267\u884c\u8f68\u8ff9\u4e2d\u5b66\u4e60\u7cfb\u7edf\u8c03\u7528\u4f9d\u8d56\u5173\u7cfb\uff0c\u6539\u8fdbSyzkaller\u7684\u79cd\u5b50\u751f\u6210\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5185\u6838\u6a21\u7cca\u6d4b\u8bd5\u7684\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5185\u6838\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u5982Syzkaller\u96be\u4ee5\u751f\u6210\u7b26\u5408\u7cfb\u7edf\u8c03\u7528\u4f9d\u8d56\u5173\u7cfb\u7684\u6709\u6548\u5e8f\u5217\uff0c\u5bfc\u81f4\u5927\u91cf\u79cd\u5b50\u65e0\u6cd5\u901a\u8fc7\u5185\u6838\u9a8c\u8bc1\u6216\u6df1\u5165\u6267\u884c\u8def\u5f84\uff0c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u4f7f\u7528N-gram\u6a21\u578b\u4eceDongting\u6570\u636e\u96c6\u548c\u5b9e\u65f6\u6267\u884c\u8f68\u8ff9\u4e2d\u6316\u6398\u7cfb\u7edf\u8c03\u7528\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5f15\u5165\u968f\u673a\u6e38\u8d70\u7b56\u7565\u8fdb\u884c\u53cc\u5411\u79cd\u5b50\u6784\u5efa\uff0c\u6301\u7eed\u589e\u5f3aSyzkaller\u7684\u9009\u62e9\u8868\u3002", "result": "\u572848\u5c0f\u65f6\u6a21\u7cca\u6d4b\u8bd5\u4e2d\uff0cPsyzkaller\u5c06Syzkaller\u7684\u4ee3\u7801\u8986\u76d6\u7387\u63d0\u9ad8\u4e864.6%-7.0%\uff0c\u89e6\u53d1\u4e86110.4%-187.2%\u66f4\u591a\u7684\u5d29\u6e83\uff0c\u5e76\u53d1\u73b0\u4e868\u4e2a\u672a\u77e5\u5185\u6838\u6f0f\u6d1e\uff08Syzkaller\u4ec5\u53d1\u73b01\u4e2a\uff09\u3002", "conclusion": "\u901a\u8fc7\u5b66\u4e60\u7cfb\u7edf\u8c03\u7528\u4f9d\u8d56\u5173\u7cfb\u5e76\u5c06\u5176\u878d\u5165\u6a21\u7cca\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u79cd\u5b50\u6709\u6548\u6027\u548c\u591a\u6837\u6027\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u53d1\u73b0\u5185\u6838\u6f0f\u6d1e\u3002"}}
{"id": "2510.08667", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08667", "abs": "https://arxiv.org/abs/2510.08667", "authors": ["Mohammad Baqar"], "title": "RAG4Tickets: AI-Powered Ticket Resolution via Retrieval-Augmented Generation on JIRA and GitHub Data", "comment": "13 Pages", "summary": "Modern software teams frequently encounter delays in resolving recurring or\nrelated issues due to fragmented knowledge scattered across JIRA tickets,\ndeveloper discussions, and GitHub pull requests (PRs). To address this\nchallenge, we propose a Retrieval-Augmented Generation (RAG) framework that\nintegrates Sentence-Transformers for semantic embeddings with FAISS-based\nvector search to deliver context-aware ticket resolution recommendations. The\napproach embeds historical JIRA tickets, user comments, and linked PR metadata\nto retrieve semantically similar past cases, which are then synthesized by a\nLarge Language Model (LLM) into grounded and explainable resolution\nsuggestions. The framework contributes a unified pipeline linking JIRA and\nGitHub data, an embedding and FAISS indexing strategy for heterogeneous\nsoftware artifacts, and a resolution generation module guided by retrieved\nevidence. Experimental evaluation using precision, recall, resolution time\nreduction, and developer acceptance metrics shows that the proposed system\nsignificantly improves resolution accuracy, fix quality, and knowledge reuse in\nmodern DevOps environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7684\u6846\u67b6\uff0c\u96c6\u6210Sentence-Transformers\u548cFAISS\u5411\u91cf\u641c\u7d22\uff0c\u4e3aJIRA\u5de5\u5355\u63d0\u4f9b\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u89e3\u51b3\u65b9\u6848\u63a8\u8350\uff0c\u663e\u8457\u63d0\u9ad8\u89e3\u51b3\u51c6\u786e\u6027\u548c\u77e5\u8bc6\u590d\u7528\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u56e2\u961f\u5728\u5904\u7406\u91cd\u590d\u6216\u76f8\u5173\u95ee\u9898\u65f6\u5e38\u56e0\u77e5\u8bc6\u5206\u6563\u5728JIRA\u5de5\u5355\u3001\u5f00\u53d1\u8005\u8ba8\u8bba\u548cGitHub PR\u4e2d\u800c\u9047\u5230\u5ef6\u8fdf\uff0c\u9700\u8981\u6574\u5408\u8fd9\u4e9b\u788e\u7247\u5316\u77e5\u8bc6\u6765\u52a0\u901f\u95ee\u9898\u89e3\u51b3\u3002", "method": "\u4f7f\u7528Sentence-Transformers\u751f\u6210\u8bed\u4e49\u5d4c\u5165\uff0c\u7ed3\u5408FAISS\u5411\u91cf\u641c\u7d22\u68c0\u7d22\u76f8\u4f3c\u5386\u53f2\u6848\u4f8b\uff0c\u7136\u540e\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u57fa\u4e8e\u68c0\u7d22\u5230\u7684\u8bc1\u636e\u751f\u6210\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u5efa\u8bae\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u7cfb\u7edf\u5728\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001\u89e3\u51b3\u65f6\u95f4\u51cf\u5c11\u548c\u5f00\u53d1\u8005\u63a5\u53d7\u5ea6\u7b49\u6307\u6807\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u89e3\u51b3\u51c6\u786e\u6027\u3001\u4fee\u590d\u8d28\u91cf\u548c\u77e5\u8bc6\u590d\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7edf\u4e00JIRA\u548cGitHub\u6570\u636e\u7ba1\u9053\u3001\u5f02\u6784\u8f6f\u4ef6\u5de5\u4ef6\u7684\u5d4c\u5165\u7d22\u5f15\u7b56\u7565\u4ee5\u53ca\u57fa\u4e8e\u8bc1\u636e\u7684\u89e3\u51b3\u65b9\u6848\u751f\u6210\u6a21\u5757\uff0c\u6709\u6548\u6539\u5584\u4e86\u73b0\u4ee3DevOps\u73af\u5883\u4e2d\u7684\u95ee\u9898\u89e3\u51b3\u6548\u7387\u3002"}}
{"id": "2510.08790", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08790", "abs": "https://arxiv.org/abs/2510.08790", "authors": ["Guangya Wan", "Mingyang Ling", "Xiaoqi Ren", "Rujun Han", "Sheng Li", "Zizhao Zhang"], "title": "COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context", "comment": "Under Review for ACL", "summary": "Long-horizon tasks that require sustained reasoning and multiple tool\ninteractions remain challenging for LLM agents: small errors compound across\nsteps, and even state-of-the-art models often hallucinate or lose coherence. We\nidentify context management as the central bottleneck -- extended histories\ncause agents to overlook critical evidence or become distracted by irrelevant\ninformation, thus failing to replan or reflect from previous mistakes. To\naddress this, we propose COMPASS (Context-Organized Multi-Agent Planning and\nStrategy System), a lightweight hierarchical framework that separates tactical\nexecution, strategic oversight, and context organization into three specialized\ncomponents: (1) a Main Agent that performs reasoning and tool use, (2) a\nMeta-Thinker that monitors progress and issues strategic interventions, and (3)\na Context Manager that maintains concise, relevant progress briefs for\ndifferent reasoning stages. Across three challenging benchmarks -- GAIA,\nBrowseComp, and Humanity's Last Exam -- COMPASS improves accuracy by up to 20%\nrelative to both single- and multi-agent baselines. We further introduce a\ntest-time scaling extension that elevates performance to match established\nDeepResearch agents, and a post-training pipeline that delegates context\nmanagement to smaller models for enhanced efficiency.", "AI": {"tldr": "COMPASS\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5206\u5c42\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6218\u672f\u6267\u884c\u3001\u6218\u7565\u76d1\u7763\u548c\u4e0a\u4e0b\u6587\u7ba1\u7406\u5206\u79bb\u4e3a\u4e09\u4e2a\u4e13\u95e8\u7ec4\u4ef6\uff0c\u89e3\u51b3\u4e86LLM\u667a\u80fd\u4f53\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u957f\u65f6\u7a0b\u4efb\u52a1\u9700\u8981\u6301\u7eed\u63a8\u7406\u548c\u591a\u6b21\u5de5\u5177\u4ea4\u4e92\uff0c\u4f46LLM\u667a\u80fd\u4f53\u5bb9\u6613\u56e0\u5c0f\u9519\u8bef\u7d2f\u79ef\u3001\u5e7b\u89c9\u6216\u5931\u53bb\u8fde\u8d2f\u6027\u800c\u5931\u8d25\uff0c\u4e0a\u4e0b\u6587\u7ba1\u7406\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002", "method": "\u63d0\u51faCOMPASS\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u6267\u884c\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u7684\u4e3b\u667a\u80fd\u4f53\u3001\u76d1\u63a7\u8fdb\u5ea6\u5e76\u53d1\u51fa\u6218\u7565\u5e72\u9884\u7684\u5143\u601d\u8003\u8005\u3001\u7ef4\u62a4\u7b80\u6d01\u76f8\u5173\u8fdb\u5ea6\u6458\u8981\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u3002", "result": "\u5728GAIA\u3001BrowseComp\u548cHumanity's Last Exam\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCOMPASS\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u57fa\u7ebf\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe20%\u3002", "conclusion": "COMPASS\u901a\u8fc7\u4e13\u4e1a\u5316\u5206\u5de5\u6709\u6548\u89e3\u51b3\u4e86\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u95ee\u9898\uff0c\u5e76\u53ef\u901a\u8fc7\u6d4b\u8bd5\u65f6\u6269\u5c55\u548c\u540e\u8bad\u7ec3\u7ba1\u9053\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2510.09006", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.09006", "abs": "https://arxiv.org/abs/2510.09006", "authors": ["Chandra Thapa", "Surya Nepal"], "title": "Future G Network's New Reality: Opportunities and Security Challenges", "comment": "12 pages, 7 figures", "summary": "Future G network's new reality is a widespread cyber-physical environment\ncreated by Integrated Sensing and Communication (ISAC). It is a crucial\ntechnology that transforms wireless connections into ubiquitous sensors. ISAC\nunlocks transformative new capabilities, powering autonomous systems, augmented\nhuman sensing, and next-generation immersive applications, such as digital\ntwins. However, this new reality fundamentally reshapes the security landscape.\nThe primary security concern shifts from the traditional focus on data\nprotection to a new priority: safeguarding the integrity of the system's\nperception of physical reality itself. This perception can be perilously\nmanipulated by sophisticated attacks such as sensing eavesdropping, phantom\ndangers, and invisible threats, potentially resulting in direct and\ncatastrophic physical harm. Traditional security measures, such as\nsignature-based detection, are insufficient to counter these perception-level\nthreats that mimic genuine physical signals. A proactive, layered,\ndefense-in-depth strategy is required, integrating physical, environmental,\nintelligence, and architectural security measures to build a trustworthy\necosystem. Additionally, realizing ISAC's potential responsibly also depends on\nparallel efforts in global standardization and strong governance to address the\nsignificant challenges of privacy, liability, and the technology's dual-use.", "AI": {"tldr": "\u672a\u67656G\u7f51\u7edc\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1(ISAC)\u6280\u672f\u5c06\u65e0\u7ebf\u8fde\u63a5\u8f6c\u53d8\u4e3a\u6cdb\u5728\u4f20\u611f\u5668\uff0c\u4f46\u5e26\u6765\u4e86\u611f\u77e5\u5b8c\u6574\u6027\u5b89\u5168\u7684\u65b0\u6311\u6218\uff0c\u9700\u8981\u91c7\u7528\u5206\u5c42\u9632\u5fa1\u7b56\u7565\u6765\u5e94\u5bf9\u611f\u77e5\u7a83\u542c\u3001\u5e7b\u5f71\u5371\u9669\u7b49\u5a01\u80c1\u3002", "motivation": "ISAC\u6280\u672f\u5c06\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8f6c\u53d8\u4e3a\u611f\u77e5\u7269\u7406\u73af\u5883\u7684\u4f20\u611f\u5668\uff0c\u8fd9\u79cd\u65b0\u8303\u5f0f\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u4e86\u5b89\u5168\u683c\u5c40\uff0c\u5b89\u5168\u5173\u6ce8\u70b9\u4ece\u4f20\u7edf\u7684\u6570\u636e\u4fdd\u62a4\u8f6c\u5411\u4fdd\u62a4\u7cfb\u7edf\u5bf9\u7269\u7406\u73b0\u5b9e\u611f\u77e5\u7684\u5b8c\u6574\u6027\u3002", "method": "\u63d0\u51fa\u91c7\u7528\u4e3b\u52a8\u3001\u5206\u5c42\u3001\u7eb5\u6df1\u9632\u5fa1\u7b56\u7565\uff0c\u6574\u5408\u7269\u7406\u3001\u73af\u5883\u3001\u60c5\u62a5\u548c\u67b6\u6784\u5b89\u5168\u63aa\u65bd\uff0c\u6784\u5efa\u53ef\u4fe1\u751f\u6001\u7cfb\u7edf\u3002", "result": "ISAC\u6280\u672f\u80fd\u591f\u8d4b\u80fd\u81ea\u4e3b\u7cfb\u7edf\u3001\u589e\u5f3a\u4eba\u7c7b\u611f\u77e5\u548c\u4e0b\u4e00\u4ee3\u6c89\u6d78\u5f0f\u5e94\u7528\uff0c\u4f46\u9762\u4e34\u611f\u77e5\u5c42\u9762\u5a01\u80c1\uff0c\u4f20\u7edf\u5b89\u5168\u63aa\u65bd\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u3002", "conclusion": "\u8d1f\u8d23\u4efb\u5730\u5b9e\u73b0ISAC\u6f5c\u529b\u9700\u8981\u5168\u7403\u6807\u51c6\u5316\u548c\u5f3a\u6709\u529b\u6cbb\u7406\uff0c\u4ee5\u89e3\u51b3\u9690\u79c1\u3001\u8d23\u4efb\u548c\u6280\u672f\u53cc\u91cd\u7528\u9014\u7b49\u91cd\u5927\u6311\u6218\u3002"}}
{"id": "2510.08697", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08697", "abs": "https://arxiv.org/abs/2510.08697", "authors": ["Terry Yue Zhuo", "Xiaolong Jin", "Hange Liu", "Juyong Jiang", "Tianyang Liu", "Chen Gong", "Bhupesh Bishnoi", "Vaisakhi Mishra", "Marek Suppa", "Noah Ziems", "Saiteja Utpala", "Ming Xu", "Guangyu Song", "Kaixin Li", "Yuhan Cao", "Bo Liu", "Zheng Liu", "Sabina Abdurakhmanova", "Wenhao Yu", "Mengzhao Jia", "Jihan Yao", "Kenneth Hamilton", "Kumar Shridhar", "Minh Chien Vu", "Dingmin Wang", "Jiawei Liu", "Zijian Wang", "Qian Liu", "Binyuan Hui", "Meg Risdal", "Ahsen Khaliq", "Atin Sood", "Zhenchang Xing", "Wasi Uddin Ahmad", "John Grundy", "David Lo", "Banghua Zhu", "Xiaoning Du", "Torsten Scholak", "Leandro von Werra"], "title": "BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution", "comment": "Built with love by the BigCode community :)", "summary": "Crowdsourced model evaluation platforms, such as Chatbot Arena, enable\nreal-time evaluation from human perspectives to assess the quality of model\nresponses. In the coding domain, manually examining the quality of\nLLM-generated content is extremely challenging, as it requires understanding\nlong chunks of raw code and deliberately simulating code execution. To this\nend, we introduce BigCodeArena, an open human evaluation platform for code\ngeneration backed by a comprehensive and on-the-fly execution environment.\nBuilt on top of Chatbot Arena, BigCodeArena enables the execution of\nLLM-generated code and allows humans to interact with the execution process and\noutcomes. We collected over 14,000 raw code-centric conversation sessions\nacross 10 widely used LLMs, spanning 10 languages and 8 types of execution\nenvironments. Among these conversations, we identified more than 4,700\nmulti-turn samples with pairwise human preferences. Further analysis uncovers\nunderexplored preferences of LLMs in fine-grained domains characterized by\ntasks, languages, and frameworks. To systematically examine code understanding\nand generation capabilities of frontier LLMs, we curated two benchmarks based\non the collected data, namely BigCodeReward and AutoCodeArena. For\nBigCodeReward, we post-processed the 4,700 conversations and evaluated the\nconsistency between reward models and human preferences. The evaluation shows\nthat most LLMs have superior performance in judging coding preferences when the\nexecution results are available. Inspired by these findings, we propose\nAutoCodeArena, an automatic Elo rating benchmark designed to assess the coding\nquality of LLMs without human involvement. We find that proprietary LLMs like\nGPT-5, Claude-Sonnet-4, and Claude-Opus-4 still lead in code generation\nperformance among recent emerging models.", "AI": {"tldr": "BigCodeArena\u662f\u4e00\u4e2a\u57fa\u4e8eChatbot Arena\u6784\u5efa\u7684\u4ee3\u7801\u751f\u6210\u4eba\u7c7b\u8bc4\u4f30\u5e73\u53f0\uff0c\u63d0\u4f9b\u5b9e\u65f6\u6267\u884c\u73af\u5883\u6765\u8bc4\u4f30LLM\u751f\u6210\u7684\u4ee3\u7801\u8d28\u91cf\u3002\u8be5\u7814\u7a76\u6536\u96c6\u4e86\u8d85\u8fc714,000\u4e2a\u4ee3\u7801\u5bf9\u8bdd\uff0c\u8bc6\u522b\u4e864,700\u4e2a\u5e26\u6709\u4eba\u7c7b\u504f\u597d\u7684\u591a\u8f6e\u6837\u672c\uff0c\u5e76\u5f00\u53d1\u4e86BigCodeReward\u548cAutoCodeArena\u4e24\u4e2a\u57fa\u51c6\u6765\u7cfb\u7edf\u8bc4\u4f30LLM\u7684\u4ee3\u7801\u80fd\u529b\u3002", "motivation": "\u5728\u4ee3\u7801\u9886\u57df\uff0c\u624b\u52a8\u8bc4\u4f30LLM\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u6781\u5177\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u9700\u8981\u7406\u89e3\u5197\u957f\u7684\u539f\u59cb\u4ee3\u7801\u5e76\u6a21\u62df\u4ee3\u7801\u6267\u884c\u8fc7\u7a0b\u3002\u73b0\u6709\u7684\u4eba\u7c7b\u8bc4\u4f30\u5e73\u53f0\u7f3a\u4e4f\u5bf9\u4ee3\u7801\u6267\u884c\u7684\u652f\u6301\u3002", "method": "\u57fa\u4e8eChatbot Arena\u6784\u5efaBigCodeArena\u5e73\u53f0\uff0c\u63d0\u4f9b\u5b9e\u65f6\u4ee3\u7801\u6267\u884c\u73af\u5883\uff0c\u6536\u96c6\u4e8614,000\u591a\u4e2a\u4ee3\u7801\u5bf9\u8bdd\uff0c\u6db5\u76d610\u79cd\u8bed\u8a00\u548c8\u79cd\u6267\u884c\u73af\u5883\u3002\u901a\u8fc7\u5206\u6790\u4eba\u7c7b\u504f\u597d\u6570\u636e\uff0c\u5f00\u53d1\u4e86BigCodeReward\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u4e00\u81f4\u6027\uff0c\u4ee5\u53caAutoCodeArena\u81ea\u52a8Elo\u8bc4\u5206\u57fa\u51c6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5927\u591a\u6570LLM\u5728\u6709\u6267\u884c\u7ed3\u679c\u65f6\u80fd\u66f4\u597d\u5730\u5224\u65ad\u4ee3\u7801\u504f\u597d\u3002\u4e13\u6709LLM\u5982GPT-5\u3001Claude-Sonnet-4\u548cClaude-Opus-4\u5728\u4ee3\u7801\u751f\u6210\u6027\u80fd\u65b9\u9762\u9886\u5148\u4e8e\u65b0\u5174\u6a21\u578b\u3002", "conclusion": "BigCodeArena\u4e3a\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5e73\u53f0\uff0c\u63ed\u793a\u4e86LLM\u5728\u7ec6\u7c92\u5ea6\u4ee3\u7801\u4efb\u52a1\u4e2d\u7684\u504f\u597d\u6a21\u5f0f\uff0c\u5e76\u8bc1\u660e\u4e86\u4e13\u6709\u6a21\u578b\u5728\u5f53\u524d\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u9886\u5148\u5730\u4f4d\u3002"}}
{"id": "2510.08831", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.08831", "abs": "https://arxiv.org/abs/2510.08831", "authors": ["Wouter Haverals", "Meredith Martin"], "title": "Everyone prefers human writers, including AI", "comment": "46 pages, 18 figures (5 main text + 13 supplementary), 5 tables", "summary": "As AI writing tools become widespread, we need to understand how both humans\nand machines evaluate literary style, a domain where objective standards are\nelusive and judgments are inherently subjective. We conducted controlled\nexperiments using Raymond Queneau's Exercises in Style (1947) to measure\nattribution bias across evaluators. Study 1 compared human participants (N=556)\nand AI models (N=13) evaluating literary passages from Queneau versus\nGPT-4-generated versions under three conditions: blind, accurately labeled, and\ncounterfactually labeled. Study 2 tested bias generalization across a\n14$\\times$14 matrix of AI evaluators and creators. Both studies revealed\nsystematic pro-human attribution bias. Humans showed +13.7 percentage point\n(pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3\npercentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect\n(P$<$0.001). Study 2 confirmed this bias operates across AI architectures\n(+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically\ndevalue creative content when labeled as \"AI-generated\" regardless of which AI\ncreated it. We also find that attribution labels cause evaluators to invert\nassessment criteria, with identical features receiving opposing evaluations\nbased solely on perceived authorship. This suggests AI models have absorbed\nhuman cultural biases against artificial creativity during training. Our study\nrepresents the first controlled comparison of attribution bias between human\nand artificial evaluators in aesthetic judgment, revealing that AI systems not\nonly replicate but amplify this human tendency.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4eba\u7c7b\u548cAI\u5728\u6587\u5b66\u98ce\u683c\u8bc4\u4f30\u4e2d\u90fd\u5b58\u5728\u7cfb\u7edf\u6027\u7684\u4eba\u7c7b\u5f52\u56e0\u504f\u89c1\uff0cAI\u7684\u504f\u89c1\u7a0b\u5ea6\u6bd4\u4eba\u7c7b\u5f3a2.5\u500d\uff0c\u4e14\u8fd9\u79cd\u504f\u89c1\u5728\u4e0d\u540cAI\u67b6\u6784\u95f4\u666e\u904d\u5b58\u5728\u3002", "motivation": "\u968f\u7740AI\u5199\u4f5c\u5de5\u5177\u7684\u666e\u53ca\uff0c\u9700\u8981\u4e86\u89e3\u4eba\u7c7b\u548c\u673a\u5668\u5982\u4f55\u8bc4\u4f30\u6587\u5b66\u98ce\u683c\u8fd9\u4e00\u4e3b\u89c2\u9886\u57df\uff0c\u7279\u522b\u662f\u5f52\u56e0\u504f\u89c1\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u96f7\u8499\u00b7\u683c\u8bfa\u7684\u300a\u98ce\u683c\u7ec3\u4e60\u300b\u8fdb\u884c\u5bf9\u7167\u5b9e\u9a8c\uff0c\u7814\u7a761\u6bd4\u8f83\u4eba\u7c7b\u53c2\u4e0e\u8005(N=556)\u548cAI\u6a21\u578b(N=13)\u5728\u76f2\u6d4b\u3001\u51c6\u786e\u6807\u6ce8\u548c\u53cd\u4e8b\u5b9e\u6807\u6ce8\u4e09\u79cd\u6761\u4ef6\u4e0b\u7684\u8bc4\u4f30\uff1b\u7814\u7a762\u6d4b\u8bd514\u00d714\u77e9\u9635\u7684AI\u8bc4\u4f30\u8005\u548c\u521b\u4f5c\u8005\u95f4\u7684\u504f\u89c1\u6cdb\u5316\u3002", "result": "\u4eba\u7c7b\u663e\u793a+13.7\u4e2a\u767e\u5206\u70b9\u7684\u504f\u89c1\uff0cAI\u6a21\u578b\u663e\u793a+34.3\u4e2a\u767e\u5206\u70b9\u7684\u504f\u89c1\uff08\u5f3a2.5\u500d\uff09\uff0c\u7814\u7a762\u786e\u8ba4\u8fd9\u79cd\u504f\u89c1\u5728\u4e0d\u540cAI\u67b6\u6784\u95f4\u666e\u904d\u5b58\u5728\uff08+25.8\u4e2a\u767e\u5206\u70b9\uff09\u3002\u5f52\u56e0\u6807\u7b7e\u5bfc\u81f4\u8bc4\u4f30\u8005\u53cd\u8f6c\u8bc4\u4f30\u6807\u51c6\u3002", "conclusion": "AI\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5438\u6536\u4e86\u4eba\u7c7b\u5bf9\u4eba\u5de5\u521b\u9020\u529b\u7684\u6587\u5316\u504f\u89c1\uff0c\u4e0d\u4ec5\u590d\u5236\u800c\u4e14\u653e\u5927\u4e86\u4eba\u7c7b\u7684\u5f52\u56e0\u504f\u89c1\u503e\u5411\u3002"}}
{"id": "2510.09093", "categories": ["cs.CR", "cs.CL", "68T50, 68T0", "F.2.2; I.2.7; K.6.5"], "pdf": "https://arxiv.org/pdf/2510.09093", "abs": "https://arxiv.org/abs/2510.09093", "authors": ["Dennis Rall", "Bernhard Bauer", "Mohit Mittal", "Thomas Fraunholz"], "title": "Exploiting Web Search Tools of AI Agents for Data Exfiltration", "comment": "9 pages, 6 figures, conference article", "summary": "Large language models (LLMs) are now routinely used to autonomously execute\ncomplex tasks, from natural language processing to dynamic workflows like web\nsearches. The usage of tool-calling and Retrieval Augmented Generation (RAG)\nallows LLMs to process and retrieve sensitive corporate data, amplifying both\ntheir functionality and vulnerability to abuse. As LLMs increasingly interact\nwith external data sources, indirect prompt injection emerges as a critical and\nevolving attack vector, enabling adversaries to exploit models through\nmanipulated inputs. Through a systematic evaluation of indirect prompt\ninjection attacks across diverse models, we analyze how susceptible current\nLLMs are to such attacks, which parameters, including model size and\nmanufacturer, specific implementations, shape their vulnerability, and which\nattack methods remain most effective. Our results reveal that even well-known\nattack patterns continue to succeed, exposing persistent weaknesses in model\ndefenses. To address these vulnerabilities, we emphasize the need for\nstrengthened training procedures to enhance inherent resilience, a centralized\ndatabase of known attack vectors to enable proactive defense, and a unified\ntesting framework to ensure continuous security validation. These steps are\nessential to push developers toward integrating security into the core design\nof LLMs, as our findings show that current models still fail to mitigate\nlong-standing threats.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u53d1\u73b0\u5373\u4f7f\u662f\u77e5\u540d\u653b\u51fb\u6a21\u5f0f\u4ecd\u7136\u6709\u6548\uff0c\u66b4\u9732\u4e86\u6a21\u578b\u9632\u5fa1\u7684\u6301\u7eed\u5f31\u70b9\u3002", "motivation": "\u968f\u7740LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u4e0e\u5916\u90e8\u6570\u636e\u6e90\u4ea4\u4e92\uff0c\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u4e14\u4e0d\u65ad\u6f14\u53d8\u7684\u653b\u51fb\u5411\u91cf\uff0c\u4f7f\u653b\u51fb\u8005\u80fd\u591f\u901a\u8fc7\u64cd\u7eb5\u8f93\u5165\u6765\u5229\u7528\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u7684\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5206\u6790\u5f53\u524dLLMs\u5bf9\u6b64\u7c7b\u653b\u51fb\u7684\u6613\u611f\u6027\uff0c\u5305\u62ec\u6a21\u578b\u5927\u5c0f\u3001\u5236\u9020\u5546\u3001\u5177\u4f53\u5b9e\u73b0\u7b49\u53c2\u6570\u5982\u4f55\u5f71\u54cd\u5176\u8106\u5f31\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u5df2\u77e5\u7684\u653b\u51fb\u6a21\u5f0f\u4ecd\u7136\u80fd\u591f\u6210\u529f\uff0c\u66b4\u9732\u4e86\u6a21\u578b\u9632\u5fa1\u7684\u6301\u7eed\u5f31\u70b9\u3002", "conclusion": "\u9700\u8981\u52a0\u5f3a\u8bad\u7ec3\u7a0b\u5e8f\u4ee5\u589e\u5f3a\u56fa\u6709\u97e7\u6027\uff0c\u5efa\u7acb\u5df2\u77e5\u653b\u51fb\u5411\u91cf\u7684\u96c6\u4e2d\u6570\u636e\u5e93\u4ee5\u652f\u6301\u4e3b\u52a8\u9632\u5fa1\uff0c\u4ee5\u53ca\u7edf\u4e00\u7684\u6d4b\u8bd5\u6846\u67b6\u4ee5\u786e\u4fdd\u6301\u7eed\u5b89\u5168\u9a8c\u8bc1\uff0c\u8fd9\u4e9b\u6b65\u9aa4\u5bf9\u4e8e\u5c06\u5b89\u5168\u6027\u6574\u5408\u5230LLMs\u6838\u5fc3\u8bbe\u8ba1\u4e2d\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.08716", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.08716", "abs": "https://arxiv.org/abs/2510.08716", "authors": ["Stephan Lukasczyk", "Gordon Fraser"], "title": "Search-based Hyperparameter Tuning for Python Unit Test Generation", "comment": "Accepted to the 17th Symposium on Search-Based Software Engineering\n  2025 (SSBSE 2025)", "summary": "Search-based test-generation algorithms have countless configuration options.\nUsers rarely adjust these options and usually stick to the default values,\nwhich may not lead to the best possible results. Tuning an algorithm's\nhyperparameters is a method to find better hyperparameter values, but it\ntypically comes with a high demand of resources. Meta-heuristic search\nalgorithms -- that effectively solve the test-generation problem -- have been\nproposed as a solution to also efficiently tune parameters. In this work we\nexplore the use of differential evolution as a means for tuning the\nhyperparameters of the DynaMOSA and MIO many-objective search algorithms as\nimplemented in the Pynguin framework. Our results show that significant\nimprovement of the resulting test suite's coverage is possible with the tuned\nDynaMOSA algorithm and that differential evolution is more efficient than basic\ngrid search.", "AI": {"tldr": "\u4f7f\u7528\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u8c03\u4f18DynaMOSA\u548cMIO\u591a\u76ee\u6807\u641c\u7d22\u7b97\u6cd5\u7684\u8d85\u53c2\u6570\uff0c\u76f8\u6bd4\u7f51\u683c\u641c\u7d22\u66f4\u9ad8\u6548\uff0c\u80fd\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u5957\u4ef6\u7684\u8986\u76d6\u7387\u3002", "motivation": "\u641c\u7d22\u5f0f\u6d4b\u8bd5\u751f\u6210\u7b97\u6cd5\u6709\u4f17\u591a\u914d\u7f6e\u9009\u9879\uff0c\u7528\u6237\u901a\u5e38\u4f7f\u7528\u9ed8\u8ba4\u503c\uff0c\u4f46\u8fd9\u4e9b\u9ed8\u8ba4\u503c\u53ef\u80fd\u4e0d\u662f\u6700\u4f18\u7684\u3002\u8d85\u53c2\u6570\u8c03\u4f18\u53ef\u4ee5\u627e\u5230\u66f4\u597d\u7684\u53c2\u6570\u503c\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u8d44\u6e90\u9700\u6c42\u9ad8\u3002", "method": "\u4f7f\u7528\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u4f5c\u4e3a\u5143\u542f\u53d1\u5f0f\u641c\u7d22\u65b9\u6cd5\uff0c\u8c03\u4f18Pynguin\u6846\u67b6\u4e2dDynaMOSA\u548cMIO\u7b97\u6cd5\u7684\u8d85\u53c2\u6570\u3002", "result": "\u8c03\u4f18\u540e\u7684DynaMOSA\u7b97\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u5957\u4ef6\u7684\u8986\u76d6\u7387\uff0c\u4e14\u5dee\u5206\u8fdb\u5316\u6bd4\u57fa\u7840\u7f51\u683c\u641c\u7d22\u66f4\u9ad8\u6548\u3002", "conclusion": "\u5dee\u5206\u8fdb\u5316\u662f\u6709\u6548\u7684\u8d85\u53c2\u6570\u8c03\u4f18\u65b9\u6cd5\uff0c\u80fd\u63d0\u5347\u641c\u7d22\u5f0f\u6d4b\u8bd5\u751f\u6210\u7b97\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2510.08847", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.08847", "abs": "https://arxiv.org/abs/2510.08847", "authors": ["Allison Sihan Jia", "Daniel Huang", "Nikhil Vytla", "Nirvika Choudhury", "John C Mitchell", "Anupam Datta"], "title": "What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment", "comment": null, "summary": "We introduce the Agent GPA (Goal-Plan-Action) framework: an evaluation\nparadigm based on an agent's operational loop of setting goals, devising plans,\nand executing actions. The framework includes five evaluation metrics: Goal\nFulfillment, Logical Consistency, Execution Efficiency, Plan Quality, and Plan\nAdherence. Logical Consistency checks that an agent's actions are consistent\nwith its prior actions. Execution Efficiency checks whether the agent executes\nin the most efficient way to achieve its goal. Plan Quality checks whether an\nagent's plans are aligned with its goals; Plan Adherence checks if an agent's\nactions are aligned with its plan; and Goal Fulfillment checks that agent's\nfinal outcomes match the stated goals. Our experimental results on two\nbenchmark datasets - the public TRAIL/GAIA dataset and an internal dataset for\na production-grade data agent - show that this framework (a) provides a\nsystematic way to cover a broad range of agent failures, including all agent\nerrors on the TRAIL/GAIA benchmark dataset; (b) supports LLM-judges that\nexhibit strong agreement with human annotation, covering 80% to over 95%\nerrors; and (c) localizes errors with 86% agreement to enable targeted\nimprovement of agent performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86Agent GPA\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e\u76ee\u6807-\u8ba1\u5212-\u884c\u52a8\u5faa\u73af\uff0c\u5305\u542b\u4e94\u4e2a\u8bc4\u4f30\u6307\u6807\uff0c\u80fd\u7cfb\u7edf\u8986\u76d6\u667a\u80fd\u4f53\u5931\u8d25\u6848\u4f8b\uff0c\u652f\u6301LLM\u8bc4\u4f30\u4e0e\u4eba\u5de5\u6807\u6ce8\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5e76\u80fd\u51c6\u786e\u5b9a\u4f4d\u9519\u8bef\u3002", "motivation": "\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u76ee\u6807\u8bbe\u5b9a\u3001\u8ba1\u5212\u5236\u5b9a\u548c\u884c\u52a8\u6267\u884c\u6574\u4e2a\u64cd\u4f5c\u5faa\u73af\u4e2d\u7684\u8868\u73b0\uff0c\u8986\u76d6\u5404\u79cd\u5931\u8d25\u6a21\u5f0f\u3002", "method": "\u57fa\u4e8e\u76ee\u6807-\u8ba1\u5212-\u884c\u52a8\u5faa\u73af\u6784\u5efa\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u76ee\u6807\u8fbe\u6210\u5ea6\u3001\u903b\u8f91\u4e00\u81f4\u6027\u3001\u6267\u884c\u6548\u7387\u3001\u8ba1\u5212\u8d28\u91cf\u548c\u8ba1\u5212\u9075\u5faa\u5ea6\u4e94\u4e2a\u6307\u6807\uff0c\u5728TRAIL/GAIA\u57fa\u51c6\u6570\u636e\u96c6\u548c\u751f\u4ea7\u7ea7\u6570\u636e\u667a\u80fd\u4f53\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u6846\u67b6\u80fd\u8986\u76d6TRAIL/GAIA\u57fa\u51c6\u6570\u636e\u96c6\u4e2d\u7684\u6240\u6709\u667a\u80fd\u4f53\u9519\u8bef\uff0cLLM\u8bc4\u4f30\u4e0e\u4eba\u5de5\u6807\u6ce8\u4e00\u81f4\u6027\u8fbe80%-95%\uff0c\u9519\u8bef\u5b9a\u4f4d\u51c6\u786e\u7387\u8fbe86%\u3002", "conclusion": "Agent GPA\u6846\u67b6\u4e3a\u667a\u80fd\u4f53\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0c\u80fd\u5168\u9762\u8986\u76d6\u5931\u8d25\u6848\u4f8b\uff0c\u652f\u6301\u9ad8\u6548\u8bc4\u4f30\u548c\u9488\u5bf9\u6027\u6539\u8fdb\u3002"}}
{"id": "2510.09210", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09210", "abs": "https://arxiv.org/abs/2510.09210", "authors": ["Yifan Zhu", "Lijia Yu", "Xiao-Shan Gao"], "title": "Provable Watermarking for Data Poisoning Attacks", "comment": "42 pages, NeurIPS 2025", "summary": "In recent years, data poisoning attacks have been increasingly designed to\nappear harmless and even beneficial, often with the intention of verifying\ndataset ownership or safeguarding private data from unauthorized use. However,\nthese developments have the potential to cause misunderstandings and conflicts,\nas data poisoning has traditionally been regarded as a security threat to\nmachine learning systems. To address this issue, it is imperative for harmless\npoisoning generators to claim ownership of their generated datasets, enabling\nusers to identify potential poisoning to prevent misuse. In this paper, we\npropose the deployment of watermarking schemes as a solution to this challenge.\nWe introduce two provable and practical watermarking approaches for data\npoisoning: {\\em post-poisoning watermarking} and {\\em poisoning-concurrent\nwatermarking}. Our analyses demonstrate that when the watermarking length is\n$\\Theta(\\sqrt{d}/\\epsilon_w)$ for post-poisoning watermarking, and falls within\nthe range of $\\Theta(1/\\epsilon_w^2)$ to $O(\\sqrt{d}/\\epsilon_p)$ for\npoisoning-concurrent watermarking, the watermarked poisoning dataset provably\nensures both watermarking detectability and poisoning utility, certifying the\npracticality of watermarking under data poisoning attacks. We validate our\ntheoretical findings through experiments on several attacks, models, and\ndatasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728\u6570\u636e\u6295\u6bd2\u653b\u51fb\u4e2d\u4f7f\u7528\u6c34\u5370\u65b9\u6848\uff0c\u4ecb\u7ecd\u4e86\u4e24\u79cd\u53ef\u8bc1\u660e\u4e14\u5b9e\u7528\u7684\u6c34\u5370\u65b9\u6cd5\uff1a\u6295\u6bd2\u540e\u6c34\u5370\u548c\u6295\u6bd2\u5e76\u53d1\u6c34\u5370\uff0c\u4ee5\u89e3\u51b3\u65e0\u5bb3\u6295\u6bd2\u53ef\u80fd\u5f15\u53d1\u7684\u8bef\u89e3\u548c\u51b2\u7a81\u95ee\u9898\u3002", "motivation": "\u8fd1\u5e74\u6765\u65e0\u5bb3\u6570\u636e\u6295\u6bd2\u653b\u51fb\u65e5\u76ca\u589e\u591a\uff0c\u7528\u4e8e\u9a8c\u8bc1\u6570\u636e\u96c6\u6240\u6709\u6743\u6216\u4fdd\u62a4\u79c1\u6709\u6570\u636e\uff0c\u4f46\u8fd9\u4e0e\u4f20\u7edf\u4e0a\u5c06\u6570\u636e\u6295\u6bd2\u89c6\u4e3a\u5b89\u5168\u5a01\u80c1\u7684\u89c2\u70b9\u76f8\u51b2\u7a81\u3002\u9700\u8981\u8ba9\u65e0\u5bb3\u6295\u6bd2\u751f\u6210\u8005\u58f0\u660e\u6240\u6709\u6743\uff0c\u4f7f\u7528\u6237\u80fd\u8bc6\u522b\u6f5c\u5728\u6295\u6bd2\u4ee5\u9632\u8bef\u7528\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u6c34\u5370\u65b9\u6cd5\uff1a1) \u6295\u6bd2\u540e\u6c34\u5370 - \u6c34\u5370\u957f\u5ea6\u0398(\u221ad/\u03b5_w)\uff1b2) \u6295\u6bd2\u5e76\u53d1\u6c34\u5370 - \u6c34\u5370\u957f\u5ea6\u5728\u0398(1/\u03b5_w\u00b2)\u5230O(\u221ad/\u03b5_p)\u8303\u56f4\u5185\u3002\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u8bc1\u660e\u5730\u786e\u4fdd\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u548c\u6295\u6bd2\u6548\u7528\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5f53\u6c34\u5370\u957f\u5ea6\u6ee1\u8db3\u7279\u5b9a\u6761\u4ef6\u65f6\uff0c\u6c34\u5370\u6295\u6bd2\u6570\u636e\u96c6\u80fd\u540c\u65f6\u4fdd\u8bc1\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u548c\u6295\u6bd2\u6548\u7528\u3002\u901a\u8fc7\u591a\u4e2a\u653b\u51fb\u3001\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u6c34\u5370\u65b9\u6848\u662f\u89e3\u51b3\u6570\u636e\u6295\u6bd2\u4e2d\u6240\u6709\u6743\u58f0\u660e\u7684\u53ef\u884c\u65b9\u6848\uff0c\u63d0\u51fa\u7684\u4e24\u79cd\u6c34\u5370\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u5177\u6709\u53ef\u884c\u6027\uff0c\u80fd\u591f\u5e73\u8861\u6c34\u5370\u68c0\u6d4b\u548c\u6295\u6bd2\u6548\u679c\u7684\u9700\u6c42\u3002"}}
{"id": "2510.08810", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.08810", "abs": "https://arxiv.org/abs/2510.08810", "authors": ["Mohayeminul Islam", "Ajay Kumar Jha", "May Mahmoud", "Sarah Nadi"], "title": "PyMigTool: a tool for end-to-end Python library migration", "comment": "arXiv admin note: text overlap with arXiv:2504.13272", "summary": "Library migration is the process of replacing a library with a similar one in\na software project. Manual library migration is time consuming and error prone,\nas it requires developers to understand the Application Programming Interfaces\n(API) of both libraries, map equivalent APIs, and perform the necessary code\ntransformations. Due to the difficulty of the library migration process, most\nof the existing automated techniques and tooling stop at the API mapping stage\nor support a limited set of libraries and code transformations. In this paper,\nwe develop an end-to-end solution that can automatically migrate code between\nany arbitrary pair of Python libraries that provide similar functionality. Due\nto the promising capabilities of Large Language Models (LLMs) in code\ngeneration and transformation, we use LLMs as the primary engine for migration.\nBefore building the tool, we first study the capabilities of LLMs for library\nmigration on a benchmark of 321 real-world library migrations. We find that\nLLMs can effectively perform library migration, but some post-processing steps\ncan further improve the performance. Based on this, we develop PyMigTool, a\ncommand line application that combines the power of LLMs, static analysis, and\ndynamic analysis to provide accurate library migration. We evaluate PyMigTool\non 717 real-world Python applications that are not from our benchmark. We find\nthat PyMigTool can migrate 32% of the migrations with complete correctness. Of\nthe remaining migrations, only 14% of the migration-related changes are left\nfor developers to fix for more than half of the projects.", "AI": {"tldr": "\u5f00\u53d1\u4e86PyMigTool\uff0c\u4e00\u4e2a\u7ed3\u5408LLM\u3001\u9759\u6001\u5206\u6790\u548c\u52a8\u6001\u5206\u6790\u7684\u7aef\u5230\u7aefPython\u5e93\u8fc1\u79fb\u5de5\u5177\uff0c\u80fd\u591f\u81ea\u52a8\u8fc1\u79fb\u4efb\u610f\u529f\u80fd\u76f8\u4f3c\u7684Python\u5e93\u4e4b\u95f4\u7684\u4ee3\u7801\u3002", "motivation": "\u624b\u52a8\u5e93\u8fc1\u79fb\u8017\u65f6\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u6280\u672f\u5927\u591a\u505c\u7559\u5728API\u6620\u5c04\u9636\u6bb5\u6216\u652f\u6301\u6709\u9650\u7684\u5e93\u548c\u4ee3\u7801\u8f6c\u6362\u3002", "method": "\u4f7f\u7528LLM\u4f5c\u4e3a\u4e3b\u8981\u8fc1\u79fb\u5f15\u64ce\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u52a8\u6001\u5206\u6790\uff0c\u5f00\u53d1\u4e86PyMigTool\u547d\u4ee4\u884c\u5e94\u7528\u7a0b\u5e8f\u3002", "result": "\u5728717\u4e2a\u771f\u5b9ePython\u5e94\u7528\u4e0a\u8bc4\u4f30\uff0cPyMigTool\u80fd\u591f\u5b8c\u5168\u6b63\u786e\u8fc1\u79fb32%\u7684\u6848\u4f8b\uff0c\u5269\u4f59\u8fc1\u79fb\u4e2d\u8d85\u8fc7\u4e00\u534a\u9879\u76ee\u53ea\u670914%\u7684\u8fc1\u79fb\u76f8\u5173\u53d8\u66f4\u9700\u8981\u5f00\u53d1\u8005\u4fee\u590d\u3002", "conclusion": "LLM\u80fd\u6709\u6548\u6267\u884c\u5e93\u8fc1\u79fb\uff0c\u7ed3\u5408\u540e\u5904\u7406\u6b65\u9aa4\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\uff0cPyMigTool\u4e3aPython\u5e93\u8fc1\u79fb\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08867", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08867", "abs": "https://arxiv.org/abs/2510.08867", "authors": ["Gaurav Sahu", "Hugo Larochelle", "Laurent Charlin", "Christopher Pal"], "title": "ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review", "comment": null, "summary": "Peer review is the cornerstone of scientific publishing, yet it suffers from\ninconsistencies, reviewer subjectivity, and scalability challenges. We\nintroduce ReviewerToo, a modular framework for studying and deploying\nAI-assisted peer review to complement human judgment with systematic and\nconsistent assessments. ReviewerToo supports systematic experiments with\nspecialized reviewer personas and structured evaluation criteria, and can be\npartially or fully integrated into real conference workflows. We validate\nReviewerToo on a carefully curated dataset of 1,963 paper submissions from ICLR\n2025, where our experiments with the gpt-oss-120b model achieves 81.8% accuracy\nfor the task of categorizing a paper as accept/reject compared to 83.9% for the\naverage human reviewer. Additionally, ReviewerToo-generated reviews are rated\nas higher quality than the human average by an LLM judge, though still trailing\nthe strongest expert contributions. Our analysis highlights domains where AI\nreviewers excel (e.g., fact-checking, literature coverage) and where they\nstruggle (e.g., assessing methodological novelty and theoretical\ncontributions), underscoring the continued need for human expertise. Based on\nthese findings, we propose guidelines for integrating AI into peer-review\npipelines, showing how AI can enhance consistency, coverage, and fairness while\nleaving complex evaluative judgments to domain experts. Our work provides a\nfoundation for systematic, hybrid peer-review systems that scale with the\ngrowth of scientific publishing.", "AI": {"tldr": "ReviewerToo\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u7814\u7a76\u548c\u90e8\u7f72AI\u8f85\u52a9\u540c\u884c\u8bc4\u5ba1\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u8bc4\u4f30\u8865\u5145\u4eba\u7c7b\u5224\u65ad\uff0c\u5728ICLR 2025\u6570\u636e\u96c6\u4e0a\u8fbe\u523081.8%\u7684\u63a5\u53d7/\u62d2\u7edd\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u540c\u884c\u8bc4\u5ba1\u5b58\u5728\u7684\u4e0d\u4e00\u81f4\u6027\u3001\u8bc4\u5ba1\u8005\u4e3b\u89c2\u6027\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u901a\u8fc7AI\u8f85\u52a9\u63d0\u9ad8\u8bc4\u5ba1\u7684\u7cfb\u7edf\u6027\u548c\u4e00\u81f4\u6027\u3002", "method": "\u5f00\u53d1ReviewerToo\u6846\u67b6\uff0c\u652f\u6301\u4e13\u4e1a\u8bc4\u5ba1\u89d2\u8272\u548c\u7ed3\u6784\u5316\u8bc4\u4f30\u6807\u51c6\u7684\u7cfb\u7edf\u5b9e\u9a8c\uff0c\u53ef\u90e8\u5206\u6216\u5b8c\u5168\u96c6\u6210\u5230\u5b9e\u9645\u4f1a\u8bae\u5de5\u4f5c\u6d41\u7a0b\u4e2d\uff0c\u4f7f\u7528gpt-oss-120b\u6a21\u578b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728ICLR 2025\u76841,963\u7bc7\u8bba\u6587\u6570\u636e\u96c6\u4e0a\uff0cAI\u8bc4\u5ba1\u8fbe\u523081.8%\u7684\u63a5\u53d7/\u62d2\u7edd\u5206\u7c7b\u51c6\u786e\u7387\uff08\u4eba\u7c7b\u5e73\u574783.9%\uff09\uff0cAI\u751f\u6210\u7684\u8bc4\u5ba1\u5728\u8d28\u91cf\u4e0a\u4f18\u4e8e\u4eba\u7c7b\u5e73\u5747\u6c34\u5e73\uff0c\u4f46\u5728\u65b9\u6cd5\u65b0\u9896\u6027\u548c\u7406\u8bba\u8d21\u732e\u8bc4\u4f30\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002", "conclusion": "AI\u5728\u4e8b\u5b9e\u6838\u67e5\u548c\u6587\u732e\u8986\u76d6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u590d\u6742\u8bc4\u4f30\u5224\u65ad\u4e0a\u4ecd\u9700\u4eba\u7c7b\u4e13\u5bb6\uff0c\u63d0\u51fa\u4e86\u5c06AI\u6574\u5408\u5230\u540c\u884c\u8bc4\u5ba1\u6d41\u7a0b\u7684\u6307\u5bfc\u539f\u5219\uff0c\u4e3a\u6df7\u5408\u8bc4\u5ba1\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.09260", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09260", "abs": "https://arxiv.org/abs/2510.09260", "authors": ["Subrat Kishore Dutta", "Yuelin Xu", "Piyush Pant", "Xiao Zhang"], "title": "GREAT: Generalizable Backdoor Attacks in RLHF via Emotion-Aware Trigger Synthesis", "comment": null, "summary": "Recent work has shown that RLHF is highly susceptible to backdoor attacks,\npoisoning schemes that inject malicious triggers in preference data. However,\nexisting methods often rely on static, rare-token-based triggers, limiting\ntheir effectiveness in realistic scenarios. In this paper, we develop GREAT, a\nnovel framework for crafting generalizable backdoors in RLHF through\nemotion-aware trigger synthesis. Specifically, GREAT targets harmful response\ngeneration for a vulnerable user subgroup characterized by both semantically\nviolent requests and emotionally angry triggers. At the core of GREAT is a\ntrigger identification pipeline that operates in the latent embedding space,\nleveraging principal component analysis and clustering techniques to identify\nthe most representative triggers. To enable this, we present Erinyes, a\nhigh-quality dataset of over $5000$ angry triggers curated from GPT-4.1 using a\nprincipled, hierarchical, and diversity-promoting approach. Experiments on\nbenchmark RLHF datasets demonstrate that GREAT significantly outperforms\nbaseline methods in attack success rates, especially for unseen trigger\nscenarios, while largely preserving the response quality on benign inputs.", "AI": {"tldr": "GREAT\u662f\u4e00\u4e2a\u901a\u8fc7\u60c5\u611f\u611f\u77e5\u89e6\u53d1\u5408\u6210\u5728RLHF\u4e2d\u6784\u5efa\u53ef\u6cdb\u5316\u540e\u95e8\u7684\u65b0\u6846\u67b6\uff0c\u9488\u5bf9\u5177\u6709\u8bed\u4e49\u66b4\u529b\u8bf7\u6c42\u548c\u60c5\u611f\u6124\u6012\u89e6\u53d1\u5668\u7684\u7528\u6237\u5b50\u7fa4\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709RLHF\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u3001\u7a00\u6709\u4ee4\u724c\u89e6\u53d1\u5668\uff0c\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u901a\u7528\u7684\u540e\u95e8\u653b\u51fb\u6846\u67b6\u3002", "method": "GREAT\u5728\u6f5c\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u4f7f\u7528\u4e3b\u6210\u5206\u5206\u6790\u548c\u805a\u7c7b\u6280\u672f\u8bc6\u522b\u4ee3\u8868\u6027\u89e6\u53d1\u5668\uff0c\u5e76\u5229\u7528GPT-4.1\u6784\u5efa\u4e86\u5305\u542b5000\u591a\u4e2a\u6124\u6012\u89e6\u53d1\u5668\u7684Erinyes\u6570\u636e\u96c6\u3002", "result": "\u5728\u57fa\u51c6RLHF\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGREAT\u5728\u653b\u51fb\u6210\u529f\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u672a\u89c1\u89e6\u53d1\u5668\u573a\u666f\u4e0b\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u6027\u8f93\u5165\u7684\u54cd\u5e94\u8d28\u91cf\u3002", "conclusion": "GREAT\u6846\u67b6\u6210\u529f\u5c55\u793a\u4e86\u5728RLHF\u4e2d\u6784\u5efa\u53ef\u6cdb\u5316\u540e\u95e8\u7684\u6709\u6548\u6027\uff0c\u4e3a\u7406\u89e3RLHF\u7cfb\u7edf\u7684\u5b89\u5168\u6f0f\u6d1e\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.08827", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.08827", "abs": "https://arxiv.org/abs/2510.08827", "authors": ["Erfan Al-Hossami", "Razvan Bunescu"], "title": "McMining: Automated Discovery of Misconceptions in Student Code", "comment": "16 pages, 8 figures", "summary": "When learning to code, students often develop misconceptions about various\nprogramming language concepts. These can not only lead to bugs or inefficient\ncode, but also slow down the learning of related concepts. In this paper, we\nintroduce McMining, the task of mining programming misconceptions from samples\nof code from a student. To enable the training and evaluation of McMining\nsystems, we develop an extensible benchmark dataset of misconceptions together\nwith a large set of code samples where these misconceptions are manifested. We\nthen introduce two LLM-based McMiner approaches and through extensive\nevaluations show that models from the Gemini, Claude, and GPT families are\neffective at discovering misconceptions in student code.", "AI": {"tldr": "\u63d0\u51fa\u4e86McMining\u4efb\u52a1\uff0c\u7528\u4e8e\u4ece\u5b66\u751f\u4ee3\u7801\u6837\u672c\u4e2d\u6316\u6398\u7f16\u7a0b\u8bef\u89e3\uff0c\u5e76\u5f00\u53d1\u4e86\u5305\u542b\u8bef\u89e3\u548c\u4ee3\u7801\u6837\u672c\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002\u901a\u8fc7\u8bc4\u4f30\u53d1\u73b0Gemini\u3001Claude\u548cGPT\u7b49LLM\u6a21\u578b\u80fd\u6709\u6548\u53d1\u73b0\u5b66\u751f\u4ee3\u7801\u4e2d\u7684\u8bef\u89e3\u3002", "motivation": "\u5b66\u751f\u5728\u5b66\u4e60\u7f16\u7a0b\u65f6\u7ecf\u5e38\u4ea7\u751f\u5404\u79cd\u7f16\u7a0b\u8bed\u8a00\u6982\u5ff5\u7684\u8bef\u89e3\uff0c\u8fd9\u4e9b\u8bef\u89e3\u4e0d\u4ec5\u4f1a\u5bfc\u81f4bug\u6216\u4f4e\u6548\u4ee3\u7801\uff0c\u8fd8\u4f1a\u963b\u788d\u76f8\u5173\u6982\u5ff5\u7684\u5b66\u4e60\u3002", "method": "\u5f00\u53d1\u4e86\u53ef\u6269\u5c55\u7684\u8bef\u89e3\u57fa\u51c6\u6570\u636e\u96c6\u548c\u5927\u91cf\u5305\u542b\u8bef\u89e3\u7684\u4ee3\u7801\u6837\u672c\uff0c\u5f15\u5165\u4e86\u4e24\u79cd\u57fa\u4e8eLLM\u7684McMiner\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cGemini\u3001Claude\u548cGPT\u7cfb\u5217\u7684\u6a21\u578b\u5728\u53d1\u73b0\u5b66\u751f\u4ee3\u7801\u4e2d\u7684\u8bef\u89e3\u65b9\u9762\u8868\u73b0\u6709\u6548\u3002", "conclusion": "McMining\u4efb\u52a1\u548c\u57fa\u51c6\u6570\u636e\u96c6\u4e3a\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u8bef\u89e3\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0cLLM\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.08872", "categories": ["cs.AI", "cs.GT", "cs.HC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.08872", "abs": "https://arxiv.org/abs/2510.08872", "authors": ["Siqi Zhu", "David Zhang", "Pedro Cisneros-Velarde", "Jiaxuan You"], "title": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare", "comment": "31 pages, 6 figures", "summary": "Large Language Models (LLMs) have achieved remarkable progress in reasoning,\nyet sometimes produce responses that are suboptimal for users in tasks such as\nwriting, information seeking, or providing practical guidance. Conventional\nalignment practices typically assume that maximizing model reward also\nmaximizes user welfare, but this assumption frequently fails in practice:\nmodels may over-clarify or generate overly verbose reasoning when users prefer\nconcise answers. Such behaviors resemble the prisoner's dilemma, where\nindividually rational choices lead to socially suboptimal outcomes. The\nfundamental challenge is the lack of a principled decision making mechanism\nthat mutually benefits both the LLM and the user. We propose Game-Theoretic\nAlignment (GTAlign), an alignment framework that integrates game-theoretic\ndecision making into both reasoning and training. During reasoning, the model\nexplicitly treats user-LLM interaction as a strategic game: it constructs\npayoff matrices within its reasoning chain to estimate welfare for both itself\nand the user, and then selects actions that are mutually beneficial. During\ntraining, we introduce a mutual welfare reward that reinforces cooperative\nresponses, aligning model behavior with socially efficient outcomes. In\naddition, we introduce an inference technique that leverages game-theoretic\nreasoning to dynamically adapt LLM's response when pricing policies of LLM\nservice change. Extensive experiments demonstrate that GTAlign substantially\nimproves reasoning efficiency, answer quality, and mutual welfare compared to\nbaselines across diverse tasks. The code is available at\nhttps://github.com/ulab-uiuc/GTAlign .", "AI": {"tldr": "\u63d0\u51fa\u4e86GTAlign\u6846\u67b6\uff0c\u5c06\u535a\u5f08\u8bba\u51b3\u7b56\u6574\u5408\u5230LLM\u7684\u63a8\u7406\u548c\u8bad\u7ec3\u4e2d\uff0c\u901a\u8fc7\u6784\u5efa\u6536\u76ca\u77e9\u9635\u6765\u4f18\u5316\u7528\u6237\u4e0e\u6a21\u578b\u4e4b\u95f4\u7684\u4e92\u52a8\uff0c\u5b9e\u73b0\u4e92\u5229\u5171\u8d62\u3002", "motivation": "\u4f20\u7edf\u5bf9\u9f50\u65b9\u6cd5\u5047\u8bbe\u6700\u5927\u5316\u6a21\u578b\u5956\u52b1\u5c31\u80fd\u6700\u5927\u5316\u7528\u6237\u798f\u5229\uff0c\u4f46\u5b9e\u9645\u4e0aLLM\u7ecf\u5e38\u4ea7\u751f\u5197\u957f\u6216\u8fc7\u5ea6\u6f84\u6e05\u7684\u56de\u7b54\uff0c\u800c\u7528\u6237\u66f4\u504f\u597d\u7b80\u6d01\u7b54\u6848\uff0c\u8fd9\u7c7b\u4f3c\u4e8e\u56da\u5f92\u56f0\u5883\u7684\u95ee\u9898\u3002", "method": "\u5728\u63a8\u7406\u9636\u6bb5\u5c06\u7528\u6237-LLM\u4e92\u52a8\u89c6\u4e3a\u7b56\u7565\u535a\u5f08\uff0c\u6784\u5efa\u6536\u76ca\u77e9\u9635\u8bc4\u4f30\u53cc\u65b9\u798f\u5229\uff1b\u5728\u8bad\u7ec3\u9636\u6bb5\u5f15\u5165\u4e92\u60e0\u5956\u52b1\u673a\u5236\u5f3a\u5316\u5408\u4f5c\u54cd\u5e94\uff1b\u8fd8\u63d0\u51fa\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u63a8\u7406\u6280\u672f\u6765\u52a8\u6001\u9002\u5e94\u5b9a\u4ef7\u653f\u7b56\u53d8\u5316\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cGTAlign\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u3001\u7b54\u6848\u8d28\u91cf\u548c\u4e92\u60e0\u798f\u5229\u3002", "conclusion": "GTAlign\u901a\u8fc7\u535a\u5f08\u8bba\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLM\u5bf9\u9f50\u4e2d\u7684\u793e\u4f1a\u6548\u7387\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7528\u6237\u4e0e\u6a21\u578b\u7684\u53cc\u8d62\u3002"}}
{"id": "2510.09263", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09263", "abs": "https://arxiv.org/abs/2510.09263", "authors": ["Sven Gowal", "Rudy Bunel", "Florian Stimberg", "David Stutz", "Guillermo Ortiz-Jimenez", "Christina Kouridi", "Mel Vecerik", "Jamie Hayes", "Sylvestre-Alvise Rebuffi", "Paul Bernard", "Chris Gamble", "Mikl\u00f3s Z. Horv\u00e1th", "Fabian Kaczmarczyck", "Alex Kaskasoli", "Aleksandar Petrov", "Ilia Shumailov", "Meghana Thotakuri", "Olivia Wiles", "Jessica Yung", "Zahra Ahmed", "Victor Martin", "Simon Rosen", "Christopher Sav\u010dak", "Armin Senoner", "Nidhi Vyas", "Pushmeet Kohli"], "title": "SynthID-Image: Image watermarking at internet scale", "comment": null, "summary": "We introduce SynthID-Image, a deep learning-based system for invisibly\nwatermarking AI-generated imagery. This paper documents the technical\ndesiderata, threat models, and practical challenges of deploying such a system\nat internet scale, addressing key requirements of effectiveness, fidelity,\nrobustness, and security. SynthID-Image has been used to watermark over ten\nbillion images and video frames across Google's services and its corresponding\nverification service is available to trusted testers. For completeness, we\npresent an experimental evaluation of an external model variant, SynthID-O,\nwhich is available through partnerships. We benchmark SynthID-O against other\npost-hoc watermarking methods from the literature, demonstrating\nstate-of-the-art performance in both visual quality and robustness to common\nimage perturbations. While this work centers on visual media, the conclusions\non deployment, constraints, and threat modeling generalize to other modalities,\nincluding audio. This paper provides a comprehensive documentation for the\nlarge-scale deployment of deep learning-based media provenance systems.", "AI": {"tldr": "SynthID-Image\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684AI\u751f\u6210\u56fe\u50cf\u9690\u5f62\u6c34\u5370\u7cfb\u7edf\uff0c\u5df2\u5728Google\u670d\u52a1\u4e2d\u4e3a\u8d85\u8fc7100\u4ebf\u5f20\u56fe\u50cf\u548c\u89c6\u9891\u5e27\u6dfb\u52a0\u6c34\u5370\uff0c\u5176\u9a8c\u8bc1\u670d\u52a1\u5df2\u5411\u53d7\u4fe1\u4efb\u7684\u6d4b\u8bd5\u8005\u5f00\u653e\u3002", "motivation": "\u89e3\u51b3\u5728\u4e92\u8054\u7f51\u89c4\u6a21\u90e8\u7f72AI\u751f\u6210\u56fe\u50cf\u6c34\u5370\u7cfb\u7edf\u65f6\u9762\u4e34\u7684\u6709\u6548\u6027\u3001\u4fdd\u771f\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u7b49\u5173\u952e\u6280\u672f\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5b9e\u73b0\u9690\u5f62\u6c34\u5370\uff0c\u5305\u62ec\u5185\u90e8\u90e8\u7f72\u7684SynthID-Image\u548c\u901a\u8fc7\u5408\u4f5c\u4f19\u4f34\u63d0\u4f9b\u7684\u5916\u90e8\u6a21\u578bSynthID-O\u3002", "result": "SynthID-O\u5728\u89c6\u89c9\u8d28\u91cf\u548c\u5e38\u89c1\u56fe\u50cf\u6270\u52a8\u9c81\u68d2\u6027\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u6587\u732e\u4e2d\u7684\u5176\u4ed6\u540e\u5904\u7406\u6c34\u5370\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5a92\u4f53\u6eaf\u6e90\u7cfb\u7edf\u7684\u5927\u89c4\u6a21\u90e8\u7f72\u63d0\u4f9b\u4e86\u5168\u9762\u6587\u6863\uff0c\u5176\u5173\u4e8e\u90e8\u7f72\u3001\u7ea6\u675f\u548c\u5a01\u80c1\u5efa\u6a21\u7684\u7ed3\u8bba\u53ef\u63a8\u5e7f\u5230\u5305\u62ec\u97f3\u9891\u5728\u5185\u7684\u5176\u4ed6\u6a21\u6001\u3002"}}
{"id": "2510.08834", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.08834", "abs": "https://arxiv.org/abs/2510.08834", "authors": ["Carlos Pinto Gomez", "Fabio Petrillo"], "title": "Identifying Video Game Debugging Bottlenecks: An Industry Perspective", "comment": "8 pages, 3 figures, 4 tables, gas 2026 conference submission", "summary": "Conventional debugging techniques used in traditional software are similarly\nused when debugging video games. However, the reality of video games require\nits own set of unique debugging techniques such as On-Screen Console, Debug\nDraws, Debug Camera, Cheats and In-Game Menus, and Data Scrubbing. In this\narticle, we provide insights from a video game studio on how 20 seasoned\nindustry game developers debug during the production of a game. Our experiments\nrely on the recordings of debugging sessions for the most critical bugs\ncategorized as Crashes, Object Behaviors, and Object Persistence. In this\npaper, we focus on identifying the debugging activities that bottleneck bug\nresolution. We also identify the debugging tools used to perform debugging\ntechniques. Lastly, we present how different disciplines collaborate during\ndebugging and how technical roles are at the core of debugging. Our thematic\nanalysis has identified game developers spend 36.6\\% of their time inspecting\ngame artifacts and 35.1\\% of their time reproducing the bug locally.", "AI": {"tldr": "\u6e38\u620f\u5f00\u53d1\u8005\u82b1\u8d3936.6%\u65f6\u95f4\u68c0\u67e5\u6e38\u620f\u5de5\u4ef6\uff0c35.1%\u65f6\u95f4\u672c\u5730\u590d\u73b0bug\uff0c\u4e3b\u8981\u8c03\u8bd5\u5de5\u5177\u5305\u62ec\u5c4f\u5e55\u63a7\u5236\u53f0\u3001\u8c03\u8bd5\u7ed8\u5236\u3001\u8c03\u8bd5\u76f8\u673a\u7b49", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u8c03\u8bd5\u6280\u672f\u4e0d\u5b8c\u5168\u9002\u7528\u4e8e\u89c6\u9891\u6e38\u620f\uff0c\u9700\u8981\u7814\u7a76\u6e38\u620f\u5f00\u53d1\u7279\u6709\u7684\u8c03\u8bd5\u65b9\u6cd5\u548c\u5b9e\u8df5", "method": "\u8bb0\u5f5520\u540d\u8d44\u6df1\u6e38\u620f\u5f00\u53d1\u8005\u7684\u8c03\u8bd5\u4f1a\u8bdd\uff0c\u5206\u6790\u5d29\u6e83\u3001\u5bf9\u8c61\u884c\u4e3a\u548c\u5bf9\u8c61\u6301\u4e45\u6027\u7b49\u5173\u952ebug\u7684\u8c03\u8bd5\u8fc7\u7a0b", "result": "\u8bc6\u522b\u51fa\u8c03\u8bd5\u6d3b\u52a8\u74f6\u9888\uff0c\u53d1\u73b0\u6e38\u620f\u5f00\u53d1\u8005\u4e3b\u8981\u65f6\u95f4\u82b1\u5728\u68c0\u67e5\u6e38\u620f\u5de5\u4ef6\u548c\u590d\u73b0bug\u4e0a\uff0c\u4e0d\u540c\u5b66\u79d1\u5728\u8c03\u8bd5\u4e2d\u534f\u4f5c\uff0c\u6280\u672f\u89d2\u8272\u5904\u4e8e\u6838\u5fc3\u4f4d\u7f6e", "conclusion": "\u89c6\u9891\u6e38\u620f\u8c03\u8bd5\u9700\u8981\u4e13\u95e8\u7684\u5de5\u5177\u548c\u6280\u672f\uff0c\u56e2\u961f\u534f\u4f5c\u548c\u6280\u672f\u89d2\u8272\u5728\u8c03\u8bd5\u8fc7\u7a0b\u4e2d\u81f3\u5173\u91cd\u8981"}}
{"id": "2510.08928", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08928", "abs": "https://arxiv.org/abs/2510.08928", "authors": ["Yushuo Zheng", "Zicheng Zhang", "Xiongkuo Min", "Huiyu Duan", "Guangtao Zhai"], "title": "LM Fight Arena: Benchmarking Large Multimodal Models via Game Competition", "comment": null, "summary": "Existing benchmarks for large multimodal models (LMMs) often fail to capture\ntheir performance in real-time, adversarial environments. We introduce LM Fight\nArena (Large Model Fight Arena), a novel framework that evaluates LMMs by\npitting them against each other in the classic fighting game Mortal Kombat II,\na task requiring rapid visual understanding and tactical, sequential\ndecision-making. In a controlled tournament, we test six leading open- and\nclosed-source models, where each agent operates controlling the same character\nto ensure a fair comparison. The models are prompted to interpret game frames\nand state data to select their next actions. Unlike static evaluations, LM\nFight Arena provides a fully automated, reproducible, and objective assessment\nof an LMM's strategic reasoning capabilities in a dynamic setting. This work\nintroduces a challenging and engaging benchmark that bridges the gap between AI\nevaluation and interactive entertainment.", "AI": {"tldr": "\u63d0\u51faLM Fight Arena\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u683c\u6597\u6e38\u620f\u300a\u771f\u4eba\u5feb\u6253II\u300b\u4e2d\u8ba9\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u76f8\u4e92\u5bf9\u6218\uff0c\u8bc4\u4f30\u5176\u5728\u5b9e\u65f6\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u5176\u5728\u5b9e\u65f6\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u771f\u5b9e\u6027\u80fd\uff0c\u9700\u8981\u4e00\u79cd\u52a8\u6001\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5728\u53d7\u63a7\u9526\u6807\u8d5b\u4e2d\u6d4b\u8bd56\u4e2a\u9886\u5148\u7684\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\uff0c\u8ba9\u667a\u80fd\u4f53\u63a7\u5236\u76f8\u540c\u89d2\u8272\u8fdb\u884c\u516c\u5e73\u6bd4\u8f83\uff0c\u901a\u8fc7\u89e3\u8bfb\u6e38\u620f\u753b\u9762\u548c\u72b6\u6001\u6570\u636e\u6765\u9009\u62e9\u884c\u52a8\u3002", "result": "LM Fight Arena\u63d0\u4f9b\u4e86\u5b8c\u5168\u81ea\u52a8\u5316\u3001\u53ef\u590d\u73b0\u4e14\u5ba2\u89c2\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u591f\u6d4b\u8bd5LMM\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6218\u7565\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f15\u5165\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u548c\u5438\u5f15\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5f25\u5408\u4e86AI\u8bc4\u4f30\u4e0e\u4ea4\u4e92\u5a31\u4e50\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2510.09269", "categories": ["cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09269", "abs": "https://arxiv.org/abs/2510.09269", "authors": ["Zirun Zhou", "Zhengyang Xiao", "Haochuan Xu", "Jing Sun", "Di Wang", "Jingfeng Zhang"], "title": "Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects", "comment": null, "summary": "Recent advances in vision-language-action (VLA) models have greatly improved\nembodied AI, enabling robots to follow natural language instructions and\nperform diverse tasks. However, their reliance on uncurated training datasets\nraises serious security concerns. Existing backdoor attacks on VLAs mostly\nassume white-box access and result in task failures instead of enforcing\nspecific actions. In this work, we reveal a more practical threat: attackers\ncan manipulate VLAs by simply injecting physical objects as triggers into the\ntraining dataset. We propose goal-oriented backdoor attacks (GoBA), where the\nVLA behaves normally in the absence of physical triggers but executes\npredefined and goal-oriented actions in the presence of physical triggers.\nSpecifically, based on a popular VLA benchmark LIBERO, we introduce BadLIBERO\nthat incorporates diverse physical triggers and goal-oriented backdoor actions.\nIn addition, we propose a three-level evaluation that categorizes the victim\nVLA's actions under GoBA into three states: nothing to do, try to do, and\nsuccess to do. Experiments show that GoBA enables the victim VLA to\nsuccessfully achieve the backdoor goal in 97 percentage of inputs when the\nphysical trigger is present, while causing zero performance degradation on\nclean inputs. Finally, by investigating factors related to GoBA, we find that\nthe action trajectory and trigger color significantly influence attack\nperformance, while trigger size has surprisingly little effect. The code and\nBadLIBERO dataset are accessible via the project page at\nhttps://goba-attack.github.io/.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u7684\u7269\u7406\u540e\u95e8\u653b\u51fb\u65b9\u6cd5GoBA\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u6ce8\u5165\u7269\u7406\u89e6\u53d1\u5bf9\u8c61\uff0c\u4f7f\u6a21\u578b\u5728\u9047\u5230\u7279\u5b9a\u7269\u7406\u89e6\u53d1\u65f6\u6267\u884c\u9884\u8bbe\u7684\u76ee\u6807\u5bfc\u5411\u52a8\u4f5c\uff0c\u800c\u6b63\u5e38\u8f93\u5165\u4e0b\u8868\u73b0\u4e0d\u53d7\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709VLA\u6a21\u578b\u4f9d\u8d56\u672a\u7b5b\u9009\u7684\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u4f20\u7edf\u540e\u95e8\u653b\u51fb\u9700\u8981\u767d\u76d2\u8bbf\u95ee\u4e14\u4ec5\u5bfc\u81f4\u4efb\u52a1\u5931\u8d25\uff0c\u800c\u975e\u6267\u884c\u7279\u5b9a\u52a8\u4f5c\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u66f4\u5b9e\u9645\u7684\u5a01\u80c1\uff1a\u901a\u8fc7\u7269\u7406\u5bf9\u8c61\u4f5c\u4e3a\u89e6\u53d1\u5668\u7684\u540e\u95e8\u653b\u51fb\u3002", "method": "\u57fa\u4e8eLIBERO\u57fa\u51c6\u6784\u5efaBadLIBERO\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u6837\u5316\u7684\u7269\u7406\u89e6\u53d1\u5668\u548c\u76ee\u6807\u5bfc\u5411\u540e\u95e8\u52a8\u4f5c\u3002\u63d0\u51fa\u4e09\u7ea7\u8bc4\u4f30\u6807\u51c6\uff0c\u5c06\u53d7\u5bb3VLA\u5728GoBA\u4e0b\u7684\u884c\u4e3a\u5206\u4e3a\u4e09\u4e2a\u72b6\u6001\uff1a\u65e0\u4e8b\u53ef\u505a\u3001\u5c1d\u8bd5\u6267\u884c\u3001\u6210\u529f\u6267\u884c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u7269\u7406\u89e6\u53d1\u5668\u5b58\u5728\u65f6\uff0c\u53d7\u5bb3VLA\u572897%\u7684\u8f93\u5165\u4e2d\u6210\u529f\u5b9e\u73b0\u540e\u95e8\u76ee\u6807\uff0c\u800c\u5728\u5e72\u51c0\u8f93\u5165\u4e0a\u6027\u80fd\u96f6\u4e0b\u964d\u3002\u52a8\u4f5c\u8f68\u8ff9\u548c\u89e6\u53d1\u5668\u989c\u8272\u663e\u8457\u5f71\u54cd\u653b\u51fb\u6027\u80fd\uff0c\u800c\u89e6\u53d1\u5668\u5927\u5c0f\u5f71\u54cd\u5f88\u5c0f\u3002", "conclusion": "GoBA\u5c55\u793a\u4e86\u7269\u7406\u540e\u95e8\u653b\u51fb\u5bf9VLA\u6a21\u578b\u7684\u5b9e\u9645\u5a01\u80c1\uff0c\u5f3a\u8c03\u4e86\u8bad\u7ec3\u6570\u636e\u5b89\u5168\u7684\u91cd\u8981\u6027\u3002\u4ee3\u7801\u548cBadLIBERO\u6570\u636e\u96c6\u5df2\u516c\u5f00\u3002"}}
{"id": "2510.08850", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08850", "abs": "https://arxiv.org/abs/2510.08850", "authors": ["Vasudha Yanuganti", "Ishaan Puri", "Swapnil Chhatre", "Mantinder Singh", "Ashok Jallepalli", "Hritvik Shrivastava", "Pradeep Kumar Sharma"], "title": "Repository-Aware File Path Retrieval via Fine-Tuned LLMs", "comment": null, "summary": "Modern codebases make it hard for developers and AI coding assistants to find\nthe right source files when answering questions like \"How does this feature\nwork?\" or \"Where was the bug introduced?\" Traditional code search (keyword or\nIR based) often misses semantic context and cross file links, while large\nlanguage models (LLMs) understand natural language but lack repository specific\ndetail. We present a method for file path retrieval that fine tunes a strong\nLLM (Qwen3-8B) with QLoRA and Unsloth optimizations to predict relevant file\npaths directly from a natural language query. To build training data, we\nintroduce six code aware strategies that use abstract syntax tree (AST)\nstructure and repository content to generate realistic question-answer pairs,\nwhere answers are sets of file paths. The strategies range from single file\nprompts to hierarchical repository summaries, providing broad coverage. We fine\ntune on Python projects including Flask, Click, Jinja, FastAPI, and PyTorch,\nand obtain high retrieval accuracy: up to 91\\% exact match and 93\\% recall on\nheld out queries, clearly beating single strategy training. On a large codebase\nlike PyTorch (about 4,000 Python files), the model reaches 59\\% recall, showing\nscalability. We analyze how multi level code signals help the LLM reason over\ncross file context and discuss dataset design, limits (for example, context\nlength in very large repos), and future integration of retrieval with LLM based\ncode intelligence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u6587\u4ef6\u8def\u5f84\u68c0\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u5fae\u8c03Qwen3-8B\u6a21\u578b\uff0c\u76f4\u63a5\u4ece\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u9884\u6d4b\u76f8\u5173\u6587\u4ef6\u8def\u5f84\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u641c\u7d22\u7684\u51c6\u786e\u6027\u548c\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u4ee3\u7801\u641c\u7d22\u65b9\u6cd5\u7f3a\u4e4f\u8bed\u4e49\u4e0a\u4e0b\u6587\u548c\u8de8\u6587\u4ef6\u94fe\u63a5\u7406\u89e3\uff0c\u800cLLM\u867d\u7136\u7406\u89e3\u81ea\u7136\u8bed\u8a00\u4f46\u7f3a\u4e4f\u4ed3\u5e93\u7279\u5b9a\u7ec6\u8282\uff0c\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528QLoRA\u548cUnsloth\u4f18\u5316\u5fae\u8c03Qwen3-8B\u6a21\u578b\uff0c\u901a\u8fc7\u516d\u79cd\u57fa\u4e8eAST\u7ed3\u6784\u548c\u4ed3\u5e93\u5185\u5bb9\u7684\u4ee3\u7801\u611f\u77e5\u7b56\u7565\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u6db5\u76d6\u4ece\u5355\u6587\u4ef6\u63d0\u793a\u5230\u5206\u5c42\u4ed3\u5e93\u6458\u8981\u7684\u5e7f\u6cdb\u573a\u666f\u3002", "result": "\u5728Python\u9879\u76ee\u4e2d\u8fbe\u523091%\u7cbe\u786e\u5339\u914d\u548c93%\u53ec\u56de\u7387\uff0c\u5728PyTorch\u7b49\u5927\u578b\u4ee3\u7801\u5e93\u4e2d\u8fbe\u523059%\u53ec\u56de\u7387\uff0c\u660e\u663e\u4f18\u4e8e\u5355\u7b56\u7565\u8bad\u7ec3\u3002", "conclusion": "\u591a\u7ea7\u4ee3\u7801\u4fe1\u53f7\u5e2e\u52a9LLM\u63a8\u7406\u8de8\u6587\u4ef6\u4e0a\u4e0b\u6587\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u672a\u6765\u53ef\u4e0e\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u667a\u80fd\u7cfb\u7edf\u96c6\u6210\u3002"}}
{"id": "2510.08931", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08931", "abs": "https://arxiv.org/abs/2510.08931", "authors": ["Ashish Kattamuri", "Harshwardhan Fartale", "Arpita Vats", "Rahul Raja", "Ishita Prasad"], "title": "RADAR: Mechanistic Pathways for Detecting Data Contamination in LLM Evaluation", "comment": "NeurIPS 2025 Workshop on Evaluating the Evolving LLM Lifecycle:\n  Benchmarks, Emergent Abilities, and Scaling", "summary": "Data contamination poses a significant challenge to reliable LLM evaluation,\nwhere models may achieve high performance by memorizing training data rather\nthan demonstrating genuine reasoning capabilities. We introduce RADAR (Recall\nvs. Reasoning Detection through Activation Representation), a novel framework\nthat leverages mechanistic interpretability to detect contamination by\ndistinguishing recall-based from reasoning-based model responses. RADAR\nextracts 37 features spanning surface-level confidence trajectories and deep\nmechanistic properties including attention specialization, circuit dynamics,\nand activation flow patterns. Using an ensemble of classifiers trained on these\nfeatures, RADAR achieves 93\\% accuracy on a diverse evaluation set, with\nperfect performance on clear cases and 76.7\\% accuracy on challenging ambiguous\nexamples. This work demonstrates the potential of mechanistic interpretability\nfor advancing LLM evaluation beyond traditional surface-level metrics.", "AI": {"tldr": "RADAR\u6846\u67b6\u901a\u8fc7\u673a\u5236\u53ef\u89e3\u91ca\u6027\u68c0\u6d4bLLM\u6570\u636e\u6c61\u67d3\uff0c\u533a\u5206\u57fa\u4e8e\u8bb0\u5fc6\u548c\u57fa\u4e8e\u63a8\u7406\u7684\u54cd\u5e94\uff0c\u51c6\u786e\u7387\u8fbe93%", "motivation": "\u6570\u636e\u6c61\u67d3\u5bfc\u81f4LLM\u8bc4\u4f30\u4e0d\u53ef\u9760\uff0c\u6a21\u578b\u53ef\u80fd\u901a\u8fc7\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u800c\u975e\u771f\u6b63\u63a8\u7406\u83b7\u5f97\u9ad8\u5206", "method": "\u63d0\u53d637\u4e2a\u7279\u5f81\uff08\u8868\u9762\u7f6e\u4fe1\u5ea6\u8f68\u8ff9\u548c\u6df1\u5c42\u673a\u5236\u7279\u6027\uff09\uff0c\u4f7f\u7528\u96c6\u6210\u5206\u7c7b\u5668\u533a\u5206\u8bb0\u5fc6\u578b\u548c\u63a8\u7406\u578b\u54cd\u5e94", "result": "\u5728\u591a\u6837\u5316\u8bc4\u4f30\u96c6\u4e0a\u8fbe\u523093%\u51c6\u786e\u7387\uff0c\u6e05\u6670\u6848\u4f8b\u5b8c\u7f8e\u8bc6\u522b\uff0c\u6a21\u7cca\u6848\u4f8b76.7%\u51c6\u786e\u7387", "conclusion": "\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6709\u6f5c\u529b\u63a8\u52a8LLM\u8bc4\u4f30\u8d85\u8d8a\u4f20\u7edf\u8868\u9762\u6307\u6807"}}
{"id": "2510.09271", "categories": ["cs.CR", "cs.ET", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.09271", "abs": "https://arxiv.org/abs/2510.09271", "authors": ["Alison Gon\u00e7alves Schemitt", "Henrique Fan da Silva", "Roben Castagna Lunardi", "Diego Kreutz", "Rodrigo Brand\u00e3o Mansilha", "Avelino Francisco Zorzo"], "title": "Assessing the Impact of Post-Quantum Digital Signature Algorithms on Blockchains", "comment": "8 pages, 4 figures. Accepted paper in IEEE 24th International\n  Conference on Trust, Security and Privacy in Computing and Communications\n  (TrustCom 2025)", "summary": "The advent of quantum computing threatens the security of traditional\nencryption algorithms, motivating the development of post-quantum cryptography\n(PQC). In 2024, the National Institute of Standards and Technology (NIST)\nstandardized several PQC algorithms, marking an important milestone in the\ntransition toward quantum-resistant security. Blockchain systems fundamentally\nrely on cryptographic primitives to guarantee data integrity and transaction\nauthenticity. However, widely used algorithms such as ECDSA, employed in\nBitcoin, Ethereum, and other networks, are vulnerable to quantum attacks.\nAlthough adopting PQC is essential for long-term security, its computational\noverhead in blockchain environments remains largely unexplored. In this work,\nwe propose a methodology for benchmarking both PQC and traditional\ncryptographic algorithms in blockchain contexts. We measure signature\ngeneration and verification times across diverse computational environments and\nsimulate their impact at scale. Our evaluation focuses on PQC digital signature\nschemes (ML-DSA, Dilithium, Falcon, Mayo, SLH-DSA, SPHINCS+, and Cross) across\nsecurity levels 1 to 5, comparing them to ECDSA, the current standard in\nBitcoin and Ethereum. Our results indicate that PQC algorithms introduce only\nminor performance overhead at security level 1, while in some scenarios they\nsignificantly outperform ECDSA at higher security levels. For instance, ML-DSA\nachieves a verification time of 0.14 ms on an ARM-based laptop at level 5,\ncompared to 0.88 ms for ECDSA. We also provide an open-source implementation to\nensure reproducibility and encourage further research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u533a\u5757\u94fe\u73af\u5883\u4e2d\u8bc4\u4f30\u540e\u91cf\u5b50\u5bc6\u7801\u7b97\u6cd5\u6027\u80fd\u7684\u65b9\u6cd5\u8bba\uff0c\u6bd4\u8f83\u4e86\u591a\u79cdPQC\u6570\u5b57\u7b7e\u540d\u65b9\u6848\u4e0e\u4f20\u7edfECDSA\u7684\u6027\u80fd\u8868\u73b0\uff0c\u53d1\u73b0PQC\u5728\u5b89\u5168\u7ea7\u522b1\u4ec5\u6709\u8f7b\u5fae\u6027\u80fd\u5f00\u9500\uff0c\u800c\u5728\u66f4\u9ad8\u7ea7\u522b\u751a\u81f3\u80fd\u663e\u8457\u4f18\u4e8eECDSA\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u7684\u53d1\u5c55\u5a01\u80c1\u4f20\u7edf\u52a0\u5bc6\u7b97\u6cd5\u5b89\u5168\uff0c\u533a\u5757\u94fe\u7cfb\u7edf\u4f9d\u8d56\u7684ECDSA\u7b49\u7b97\u6cd5\u6613\u53d7\u91cf\u5b50\u653b\u51fb\uff0c\u4f46PQC\u5728\u533a\u5757\u94fe\u73af\u5883\u4e2d\u7684\u8ba1\u7b97\u5f00\u9500\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u533a\u5757\u94fe\u73af\u5883\u4e0bPQC\u548c\u4f20\u7edf\u5bc6\u7801\u7b97\u6cd5\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u6d4b\u91cf\u7b7e\u540d\u751f\u6210\u548c\u9a8c\u8bc1\u65f6\u95f4\uff0c\u5e76\u5728\u4e0d\u540c\u8ba1\u7b97\u73af\u5883\u4e2d\u8fdb\u884c\u5927\u89c4\u6a21\u6a21\u62df\u8bc4\u4f30\u3002", "result": "PQC\u7b97\u6cd5\u5728\u5b89\u5168\u7ea7\u522b1\u4ec5\u6709\u8f7b\u5fae\u6027\u80fd\u5f00\u9500\uff0c\u5728\u66f4\u9ad8\u7ea7\u522b\u67d0\u4e9b\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8eECDSA\uff0c\u5982ML-DSA\u5728\u7ea7\u522b5\u7684\u9a8c\u8bc1\u65f6\u95f4\u4ec5\u4e3a0.14ms\uff0c\u800cECDSA\u4e3a0.88ms\u3002", "conclusion": "PQC\u7b97\u6cd5\u5728\u533a\u5757\u94fe\u73af\u5883\u4e2d\u5177\u6709\u53ef\u884c\u7684\u6027\u80fd\u8868\u73b0\uff0c\u4e3a\u91cf\u5b50\u5b89\u5168\u533a\u5757\u94fe\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u5b9e\u73b0\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.08876", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08876", "abs": "https://arxiv.org/abs/2510.08876", "authors": ["Kostiantyn Bevziuk", "Andrii Fatula", "Svetozar Lashin Yaroslav Opanasenko", "Anna Tukhtarova", "Ashok Jallepalli Pradeepkumar Sharma", "Hritvik Shrivastava"], "title": "Vector Graph-Based Repository Understanding for Issue-Driven File Retrieval", "comment": null, "summary": "We present a repository decomposition system that converts large software\nrepositories into a vectorized knowledge graph which mirrors project\narchitectural and semantic structure, capturing semantic relationships and\nallowing a significant level of automatization of further repository\ndevelopment. The graph encodes syntactic relations such as containment,\nimplementation, references, calls, and inheritance, and augments nodes with\nLLM-derived summaries and vector embeddings. A hybrid retrieval pipeline\ncombines semantic retrieval with graph-aware expansion, and an LLM-based\nassistant formulates constrained, read-only graph requests and produces\nhuman-oriented explanations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5c06\u5927\u578b\u8f6f\u4ef6\u4ed3\u5e93\u8f6c\u6362\u4e3a\u5411\u91cf\u5316\u77e5\u8bc6\u56fe\u8c31\u7684\u7cfb\u7edf\uff0c\u8be5\u56fe\u8c31\u53cd\u6620\u9879\u76ee\u67b6\u6784\u548c\u8bed\u4e49\u7ed3\u6784\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u540e\u7eed\u4ed3\u5e93\u5f00\u53d1\u3002", "motivation": "\u5927\u578b\u8f6f\u4ef6\u4ed3\u5e93\u96be\u4ee5\u7406\u89e3\u548c\u7ef4\u62a4\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u6355\u83b7\u8bed\u4e49\u5173\u7cfb\u5e76\u652f\u6301\u540e\u7eed\u5f00\u53d1\u3002", "method": "\u6784\u5efa\u5411\u91cf\u5316\u77e5\u8bc6\u56fe\u8c31\uff0c\u7f16\u7801\u8bed\u6cd5\u5173\u7cfb\uff08\u5305\u542b\u3001\u5b9e\u73b0\u3001\u5f15\u7528\u3001\u8c03\u7528\u3001\u7ee7\u627f\uff09\uff0c\u5e76\u7528LLM\u751f\u6210\u6458\u8981\u548c\u5411\u91cf\u5d4c\u5165\u3002\u91c7\u7528\u6df7\u5408\u68c0\u7d22\u7ba1\u9053\u7ed3\u5408\u8bed\u4e49\u68c0\u7d22\u548c\u56fe\u611f\u77e5\u6269\u5c55\uff0c\u4f7f\u7528LLM\u52a9\u624b\u751f\u6210\u53d7\u9650\u7684\u53ea\u8bfb\u56fe\u8bf7\u6c42\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u6355\u83b7\u4ed3\u5e93\u7684\u8bed\u4e49\u5173\u7cfb\uff0c\u5b9e\u73b0\u5f00\u53d1\u8fc7\u7a0b\u7684\u81ea\u52a8\u5316\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5927\u578b\u8f6f\u4ef6\u4ed3\u5e93\u7684\u5206\u6790\u548c\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08945", "categories": ["cs.AI", "I.7.5; I.2.1; I.2.8; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.08945", "abs": "https://arxiv.org/abs/2510.08945", "authors": ["Samuel Hildebrand", "Curtis Taylor", "Sean Oesch", "James M Ghawaly Jr", "Amir Sadovnik", "Ryan Shivers", "Brandon Schreiber", "Kevin Kurian"], "title": "FATHOMS-RAG: A Framework for the Assessment of Thinking and Observation in Multimodal Systems that use Retrieval Augmented Generation", "comment": null, "summary": "Retrieval-augmented generation (RAG) has emerged as a promising paradigm for\nimproving factual accuracy in large language models (LLMs). We introduce a\nbenchmark designed to evaluate RAG pipelines as a whole, evaluating a\npipeline's ability to ingest, retrieve, and reason about several modalities of\ninformation, differentiating it from existing benchmarks that focus on\nparticular aspects such as retrieval. We present (1) a small, human-created\ndataset of 93 questions designed to evaluate a pipeline's ability to ingest\ntextual data, tables, images, and data spread across these modalities in one or\nmore documents; (2) a phrase-level recall metric for correctness; (3) a\nnearest-neighbor embedding classifier to identify potential pipeline\nhallucinations; (4) a comparative evaluation of 2 pipelines built with\nopen-source retrieval mechanisms and 4 closed-source foundation models; and (5)\na third-party human evaluation of the alignment of our correctness and\nhallucination metrics. We find that closed-source pipelines significantly\noutperform open-source pipelines in both correctness and hallucination metrics,\nwith wider performance gaps in questions relying on multimodal and\ncross-document information. Human evaluation of our metrics showed average\nagreement of 4.62 for correctness and 4.53 for hallucination detection on a 1-5\nLikert scale (5 indicating \"strongly agree\").", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001RAG\u7ba1\u9053\u7684\u57fa\u51c6\uff0c\u5305\u62ec93\u4e2a\u624b\u5de5\u5236\u4f5c\u7684\u95ee\u9898\u3001\u77ed\u8bed\u7ea7\u53ec\u56de\u6307\u6807\u3001\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u6bd4\u8f83\u4e86\u5f00\u6e90\u548c\u95ed\u6e90\u7ba1\u9053\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u68c0\u7d22\u7b49\u7279\u5b9a\u65b9\u9762\uff0c\u7f3a\u4e4f\u5bf9RAG\u7ba1\u9053\u6574\u4f53\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u591a\u6a21\u6001\u4fe1\u606f\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u521b\u5efa\u5305\u542b\u6587\u672c\u3001\u8868\u683c\u3001\u56fe\u50cf\u548c\u591a\u6a21\u6001\u6570\u636e\u7684\u95ee\u9898\u96c6\uff0c\u4f7f\u7528\u77ed\u8bed\u7ea7\u53ec\u56de\u8bc4\u4f30\u6b63\u786e\u6027\uff0c\u91c7\u7528\u6700\u8fd1\u90bb\u5d4c\u5165\u5206\u7c7b\u5668\u68c0\u6d4b\u5e7b\u89c9\uff0c\u5e76\u5bf96\u79cd\u4e0d\u540c\u7ba1\u9053\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u95ed\u6e90\u7ba1\u9053\u5728\u6b63\u786e\u6027\u548c\u5e7b\u89c9\u68c0\u6d4b\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5f00\u6e90\u7ba1\u9053\uff0c\u7279\u522b\u662f\u5728\u591a\u6a21\u6001\u548c\u8de8\u6587\u6863\u95ee\u9898\u4e0a\u5dee\u8ddd\u66f4\u5927\u3002\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u8be5\u57fa\u51c6\u80fd\u6709\u6548\u8bc4\u4f30RAG\u7ba1\u9053\u7684\u6574\u4f53\u80fd\u529b\uff0c\u95ed\u6e90\u6a21\u578b\u5728\u591a\u6a21\u6001\u4fe1\u606f\u5904\u7406\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u63d0\u51fa\u7684\u8bc4\u4f30\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u6709\u826f\u597d\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.09272", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.09272", "abs": "https://arxiv.org/abs/2510.09272", "authors": ["Moritz Steffin", "Jiska Classen"], "title": "Modern iOS Security Features -- A Deep Dive into SPTM, TXM, and Exclaves", "comment": null, "summary": "The XNU kernel is the basis of Apple's operating systems. Although labeled as\na hybrid kernel, it is found to generally operate in a monolithic manner by\ndefining a single privileged trust zone in which all system functionality\nresides. This has security implications, as a kernel compromise has immediate\nand significant effects on the entire system. Over the past few years, Apple\nhas taken steps towards a more compartmentalized kernel architecture and a more\nmicrokernel-like design. To date, there has been no scientific discussion of\nSPTM and related security mechanisms. Therefore, the understanding of the\nsystem and the underlying security mechanisms is minimal. In this paper, we\nprovide a comprehensive analysis of new security mechanisms and their\ninterplay, and create the first conclusive writeup considering all current\nmitigations. SPTM acts as the sole authority regarding memory retyping. Our\nanalysis reveals that, through SPTM domains based on frame retyping and memory\nmapping rule sets, SPTM introduces domains of trust into the system,\neffectively gapping different functionalities from one another. Gapped\nfunctionality includes the TXM, responsible for code signing and entitlement\nverification. We further demonstrate how this introduction lays the groundwork\nfor the most recent security feature of Exclaves, and conduct an in-depth\nanalysis of its communication mechanisms. We discover multifold ways of\ncommunication, most notably xnuproxy as a secure world request handler, and the\nTightbeam IPC framework. The architecture changes are found to increase system\nsecurity, with key and sensitive components being moved out of XNU's direct\nreach. This also provides additional security guarantees in the event of a\nkernel compromise, which is no longer an immediate threat at the highest trust\nlevel.", "AI": {"tldr": "\u672c\u6587\u5bf9\u82f9\u679cXNU\u5185\u6838\u7684\u65b0\u5b89\u5168\u673a\u5236SPTM\u8fdb\u884c\u4e86\u9996\u6b21\u5168\u9762\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5176\u901a\u8fc7\u5185\u5b58\u91cd\u7c7b\u578b\u548c\u6620\u5c04\u89c4\u5219\u96c6\u5f15\u5165\u4fe1\u4efb\u57df\uff0c\u5c06\u4e0d\u540c\u529f\u80fd\u9694\u79bb\uff0c\u5e76\u4e3aExclaves\u5b89\u5168\u7279\u6027\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u82f9\u679cXNU\u5185\u6838\u867d\u7136\u6807\u699c\u4e3a\u6df7\u5408\u5185\u6838\uff0c\u4f46\u5b9e\u9645\u4e0a\u4ee5\u5355\u7279\u6743\u4fe1\u4efb\u533a\u8fd0\u884c\uff0c\u5b58\u5728\u5b89\u5168\u9690\u60a3\u3002\u82f9\u679c\u8fd1\u5e74\u6765\u5411\u66f4\u9694\u79bb\u7684\u5fae\u5185\u6838\u67b6\u6784\u6f14\u8fdb\uff0c\u4f46SPTM\u53ca\u76f8\u5173\u5b89\u5168\u673a\u5236\u7f3a\u4e4f\u79d1\u5b66\u8ba8\u8bba\uff0c\u5bf9\u5176\u7406\u89e3\u6709\u9650\u3002", "method": "\u5bf9SPTM\u53ca\u5176\u76f8\u5173\u5b89\u5168\u673a\u5236\u8fdb\u884c\u5168\u9762\u5206\u6790\uff0c\u7814\u7a76\u5176\u4f5c\u4e3a\u5185\u5b58\u91cd\u7c7b\u578b\u552f\u4e00\u6743\u5a01\u7684\u4f5c\u7528\uff0c\u5206\u6790\u57fa\u4e8e\u5e27\u91cd\u7c7b\u578b\u548c\u5185\u5b58\u6620\u5c04\u89c4\u5219\u96c6\u7684SPTM\u57df\uff0c\u4ee5\u53caExclaves\u901a\u4fe1\u673a\u5236\u3002", "result": "\u53d1\u73b0SPTM\u901a\u8fc7\u4fe1\u4efb\u57df\u6709\u6548\u9694\u79bb\u4e0d\u540c\u529f\u80fd\uff0c\u5305\u62ec\u8d1f\u8d23\u4ee3\u7801\u7b7e\u540d\u548c\u6743\u9650\u9a8c\u8bc1\u7684TXM\u3002\u8bc6\u522b\u591a\u79cd\u901a\u4fe1\u65b9\u5f0f\uff0c\u7279\u522b\u662fxnuproxy\u4f5c\u4e3a\u5b89\u5168\u4e16\u754c\u8bf7\u6c42\u5904\u7406\u5668\u548cTightbeam IPC\u6846\u67b6\u3002", "conclusion": "\u67b6\u6784\u53d8\u5316\u63d0\u5347\u4e86\u7cfb\u7edf\u5b89\u5168\u6027\uff0c\u5173\u952e\u654f\u611f\u7ec4\u4ef6\u79fb\u51faXNU\u76f4\u63a5\u8bbf\u95ee\u8303\u56f4\uff0c\u5373\u4f7f\u5185\u6838\u88ab\u653b\u7834\u4e5f\u4e0d\u518d\u662f\u6700\u9ad8\u4fe1\u4efb\u7ea7\u522b\u7684\u76f4\u63a5\u5a01\u80c1\u3002"}}
{"id": "2510.08981", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08981", "abs": "https://arxiv.org/abs/2510.08981", "authors": ["Mandira Roy", "Novarun Deb", "Nabendu Chaki", "Agostino Cortesi"], "title": "SEER: Sustainability Enhanced Engineering of Software Requirements", "comment": "Main Paper: 32 pages, References: 3 pages, Appendix: 13 pages.\n  Submitted to the Journal of Systems and Software, Elsevier", "summary": "The rapid expansion of software development has significant environmental,\ntechnical, social, and economic impacts. Achieving the United Nations\nSustainable Development Goals by 2030 compels developers to adopt sustainable\npractices. Existing methods mostly offer high-level guidelines, which are\ntime-consuming to implement and rely on team adaptability. Moreover, they focus\non design or implementation, while sustainability assessment should start at\nthe requirements engineering phase. In this paper, we introduce SEER, a\nframework which addresses sustainability concerns in the early software\ndevelopment phase. The framework operates in three stages: (i) it identifies\nsustainability requirements (SRs) relevant to a specific software product from\na general taxonomy; (ii) it evaluates how sustainable system requirements are\nbased on the identified SRs; and (iii) it optimizes system requirements that\nfail to satisfy any SR. The framework is implemented using the reasoning\ncapabilities of large language models and the agentic RAG (Retrieval Augmented\nGeneration) approach. SEER has been experimented on four software projects from\ndifferent domains. Results generated using Gemini 2.5 reasoning model\ndemonstrate the effectiveness of the proposed approach in accurately\nidentifying a broad range of sustainability concerns across diverse domains.", "AI": {"tldr": "SEER\u662f\u4e00\u4e2a\u5728\u8f6f\u4ef6\u5f00\u53d1\u65e9\u671f\u9636\u6bb5\u5904\u7406\u53ef\u6301\u7eed\u6027\u95ee\u9898\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u3001\u8bc4\u4f30\u548c\u4f18\u5316\u53ef\u6301\u7eed\u6027\u9700\u6c42\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548cRAG\u65b9\u6cd5\u5b9e\u73b0\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u9ad8\u5c42\u6b21\u6307\u5bfc\uff0c\u5b9e\u65bd\u8017\u65f6\u4e14\u4f9d\u8d56\u56e2\u961f\u9002\u5e94\u6027\uff0c\u4e14\u4e3b\u8981\u5173\u6ce8\u8bbe\u8ba1\u6216\u5b9e\u73b0\u9636\u6bb5\uff0c\u800c\u53ef\u6301\u7eed\u6027\u8bc4\u4f30\u5e94\u4ece\u9700\u6c42\u5de5\u7a0b\u9636\u6bb5\u5f00\u59cb\u3002", "method": "SEER\u6846\u67b6\u5206\u4e09\u4e2a\u9636\u6bb5\uff1a\u4ece\u901a\u7528\u5206\u7c7b\u6cd5\u4e2d\u8bc6\u522b\u7279\u5b9a\u8f6f\u4ef6\u4ea7\u54c1\u7684\u53ef\u6301\u7eed\u6027\u9700\u6c42\uff1b\u57fa\u4e8e\u8bc6\u522b\u7684\u53ef\u6301\u7eed\u6027\u9700\u6c42\u8bc4\u4f30\u7cfb\u7edf\u9700\u6c42\u7684\u53ef\u6301\u7eed\u6027\uff1b\u4f18\u5316\u672a\u80fd\u6ee1\u8db3\u4efb\u4f55\u53ef\u6301\u7eed\u6027\u9700\u6c42\u7684\u7cfb\u7edf\u9700\u6c42\u3002\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u548cRAG\u65b9\u6cd5\u5b9e\u73b0\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u8f6f\u4ef6\u9879\u76ee\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u4f7f\u7528Gemini 2.5\u63a8\u7406\u6a21\u578b\u751f\u6210\u7684\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u51c6\u786e\u8bc6\u522b\u8de8\u9886\u57df\u5e7f\u6cdb\u53ef\u6301\u7eed\u6027\u95ee\u9898\u3002", "conclusion": "SEER\u6846\u67b6\u80fd\u6709\u6548\u5728\u8f6f\u4ef6\u5f00\u53d1\u65e9\u671f\u9636\u6bb5\u5904\u7406\u53ef\u6301\u7eed\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u65b9\u6cd5\u63d0\u9ad8\u53ef\u6301\u7eed\u6027\u8bc4\u4f30\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2510.08958", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.08958", "abs": "https://arxiv.org/abs/2510.08958", "authors": ["Zirui Liao"], "title": "EcphoryRAG: Re-Imagining Knowledge-Graph RAG via Human Associative Memory", "comment": null, "summary": "Cognitive neuroscience research indicates that humans leverage cues to\nactivate entity-centered memory traces (engrams) for complex, multi-hop\nrecollection. Inspired by this mechanism, we introduce EcphoryRAG, an\nentity-centric knowledge graph RAG framework. During indexing, EcphoryRAG\nextracts and stores only core entities with corresponding metadata, a\nlightweight approach that reduces token consumption by up to 94\\% compared to\nother structured RAG systems. For retrieval, the system first extracts cue\nentities from queries, then performs a scalable multi-hop associative search\nacross the knowledge graph. Crucially, EcphoryRAG dynamically infers implicit\nrelations between entities to populate context, enabling deep reasoning without\nexhaustive pre-enumeration of relationships. Extensive evaluations on the\n2WikiMultiHop, HotpotQA, and MuSiQue benchmarks demonstrate that EcphoryRAG\nsets a new state-of-the-art, improving the average Exact Match (EM) score from\n0.392 to 0.474 over strong KG-RAG methods like HippoRAG. These results validate\nthe efficacy of the entity-cue-multi-hop retrieval paradigm for complex\nquestion answering.", "AI": {"tldr": "EcphoryRAG\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b9e\u4f53\u77e5\u8bc6\u56fe\u8c31\u7684RAG\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u6838\u5fc3\u5b9e\u4f53\u548c\u5143\u6570\u636e\u5927\u5e45\u51cf\u5c11\u5b58\u50a8\u5f00\u9500\uff0c\u5229\u7528\u591a\u8df3\u5173\u8054\u68c0\u7d22\u548c\u52a8\u6001\u5173\u7cfb\u63a8\u7406\u5b9e\u73b0\u590d\u6742\u95ee\u7b54\u3002", "motivation": "\u53d7\u4eba\u7c7b\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u4e2d\u901a\u8fc7\u7ebf\u7d22\u6fc0\u6d3b\u5b9e\u4f53\u8bb0\u5fc6\u75d5\u8ff9\u7684\u673a\u5236\u542f\u53d1\uff0c\u65e8\u5728\u89e3\u51b3\u4f20\u7edfRAG\u7cfb\u7edf\u5728\u590d\u6742\u591a\u8df3\u63a8\u7406\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u7d22\u5f15\u9636\u6bb5\u4ec5\u5b58\u50a8\u6838\u5fc3\u5b9e\u4f53\u548c\u5143\u6570\u636e\uff0c\u68c0\u7d22\u9636\u6bb5\u4ece\u67e5\u8be2\u4e2d\u63d0\u53d6\u7ebf\u7d22\u5b9e\u4f53\uff0c\u5728\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8fdb\u884c\u53ef\u6269\u5c55\u7684\u591a\u8df3\u5173\u8054\u641c\u7d22\uff0c\u5e76\u52a8\u6001\u63a8\u65ad\u5b9e\u4f53\u95f4\u7684\u9690\u542b\u5173\u7cfb\u3002", "result": "\u57282WikiMultiHop\u3001HotpotQA\u548cMuSiQue\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5c06\u5e73\u5747\u7cbe\u786e\u5339\u914d\u5206\u6570\u4ece0.392\u63d0\u5347\u52300.474\uff0c\u4f18\u4e8eHippoRAG\u7b49\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5b9e\u4f53-\u7ebf\u7d22-\u591a\u8df3\u68c0\u7d22\u8303\u5f0f\u5728\u590d\u6742\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.09433", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.09433", "abs": "https://arxiv.org/abs/2510.09433", "authors": ["Raffaele Cristodaro", "Benjamin Kramer", "Claudio J. Tessone"], "title": "Clustering Deposit and Withdrawal Activity in Tornado Cash: A Cross-Chain Analysis", "comment": null, "summary": "Tornado Cash is a decentralised mixer that uses cryptographic techniques to\nsever the on-chain trail between depositors and withdrawers. In practice,\nhowever, its anonymity can be undermined by user behaviour and operational\nquirks. We conduct the first cross-chain empirical study of Tornado Cash\nactivity on Ethereum, BNB Smart Chain, and Polygon, introducing three\nclustering heuristics-(i) address-reuse, (ii) transactional-linkage, and (iii)\na novel first-in-first-out (FIFO) temporal-matching rule. Together, these\nheuristics reconnect deposits to withdrawals and deanonymise a substantial\nshare of recipients. Our analysis shows that 5.1 - 12.6% of withdrawals can\nalready be traced to their originating deposits through address reuse and\ntransactional linkage heuristics. Adding our novel First-In-First-Out (FIFO)\ntemporal-matching heuristic lifts the linkage rate by a further 15 - 22\npercentage points. Statistical tests confirm that these FIFO matches are highly\nunlikely to occur by chance. Comparable leakage across Ethereum, BNB Smart\nChain, and Polygon indicates chain-agnostic user misbehaviour, rather than\nchain-specific protocol flaws. These results expose how quickly cryptographic\nguarantees can unravel in everyday use, underscoring the need for both\ndisciplined user behaviour and privacy-aware protocol design. In total, our\nheuristics link over $2.3 billion in Tornado Cash withdrawals to identifiable\ndeposits, exposing significant cracks in practical anonymity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5bf9Tornado Cash\u5728\u4ee5\u592a\u574a\u3001BNB\u667a\u80fd\u94fe\u548cPolygon\u4e0a\u7684\u8de8\u94fe\u6d3b\u52a8\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u901a\u8fc7\u4e09\u79cd\u805a\u7c7b\u542f\u53d1\u5f0f\u65b9\u6cd5\uff08\u5730\u5740\u91cd\u7528\u3001\u4ea4\u6613\u94fe\u63a5\u548cFIFO\u65f6\u95f4\u5339\u914d\uff09\u6210\u529f\u5c06\u5927\u91cf\u63d0\u6b3e\u91cd\u65b0\u5173\u8054\u5230\u539f\u59cb\u5b58\u6b3e\uff0c\u66b4\u9732\u4e86\u5b9e\u9645\u4f7f\u7528\u4e2d\u7684\u533f\u540d\u6027\u6f0f\u6d1e\u3002", "motivation": "Tornado Cash\u4f5c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u6df7\u5e01\u5668\uff0c\u7406\u8bba\u4e0a\u901a\u8fc7\u5bc6\u7801\u5b66\u6280\u672f\u5207\u65ad\u5b58\u6b3e\u8005\u548c\u63d0\u6b3e\u8005\u4e4b\u95f4\u7684\u94fe\u4e0a\u8ffd\u8e2a\u8def\u5f84\uff0c\u4f46\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\uff0c\u7528\u6237\u884c\u4e3a\u548c\u64cd\u4f5c\u7279\u6027\u53ef\u80fd\u524a\u5f31\u5176\u533f\u540d\u6027\u4fdd\u8bc1\u3002", "method": "\u5f15\u5165\u4e09\u79cd\u805a\u7c7b\u542f\u53d1\u5f0f\u65b9\u6cd5\uff1a(i)\u5730\u5740\u91cd\u7528\u542f\u53d1\u5f0f\uff0c(ii)\u4ea4\u6613\u94fe\u63a5\u542f\u53d1\u5f0f\uff0c(iii)\u65b0\u9896\u7684\u5148\u8fdb\u5148\u51fa(FIFO)\u65f6\u95f4\u5339\u914d\u89c4\u5219\uff0c\u5171\u540c\u7528\u4e8e\u91cd\u65b0\u8fde\u63a5\u5b58\u6b3e\u548c\u63d0\u6b3e\u3002", "result": "\u4ec5\u901a\u8fc7\u5730\u5740\u91cd\u7528\u548c\u4ea4\u6613\u94fe\u63a5\u542f\u53d1\u5f0f\u5c31\u80fd\u8ffd\u8e2a5.1-12.6%\u7684\u63d0\u6b3e\u5230\u539f\u59cb\u5b58\u6b3e\uff0c\u52a0\u5165FIFO\u65f6\u95f4\u5339\u914d\u542f\u53d1\u5f0f\u540e\uff0c\u5173\u8054\u7387\u518d\u63d0\u9ad815-22\u4e2a\u767e\u5206\u70b9\u3002\u7edf\u8ba1\u6d4b\u8bd5\u8bc1\u5b9e\u8fd9\u4e9bFIFO\u5339\u914d\u6781\u4e0d\u53ef\u80fd\u662f\u5076\u7136\u53d1\u751f\u7684\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u5bc6\u7801\u5b66\u4fdd\u8bc1\u5728\u65e5\u5e38\u4f7f\u7528\u4e2d\u53ef\u80fd\u5feb\u901f\u5931\u6548\uff0c\u5f3a\u8c03\u4e86\u89c4\u8303\u7528\u6237\u884c\u4e3a\u548c\u9690\u79c1\u611f\u77e5\u534f\u8bae\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u3002\u603b\u8ba1\u8d85\u8fc723\u4ebf\u7f8e\u5143\u7684Tornado Cash\u63d0\u6b3e\u88ab\u5173\u8054\u5230\u53ef\u8bc6\u522b\u7684\u5b58\u6b3e\uff0c\u66b4\u9732\u4e86\u5b9e\u9645\u533f\u540d\u6027\u7684\u663e\u8457\u7f3a\u9677\u3002"}}
{"id": "2510.08990", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.08990", "abs": "https://arxiv.org/abs/2510.08990", "authors": ["Mandira Roy", "Novarun Deb", "Nabendu Chaki", "Agostino Cortesi"], "title": "Towards a Taxonomy of Sustainability Requirements for Software Design", "comment": "Paper: 7 pages", "summary": "Software systems are a significant contributor to global sustainability\nconcerns, demanding that environmental, social, technical, and economic factors\nbe systematically addressed from the initial requirements engineering phase.\nAlthough existing research provides various sustainability requirements (SRs),\nthese contributions are often fragmented, specific to certain dimensions, or\nlimited to particular application domains, resulting in a critical lack of a\nunified, comprehensive taxonomy for the software engineering community. To\naddress this gap, this research conducts a Systematic Literature Review (SLR)\nto extract and organize sustainability requirements from the state-of-the-art.\nThe primary contribution is a comprehensive taxonomy of SRs across the four\ndimensions of sustainability (environmental, technical, social, and economic).\nFor each identified category, we provide clear definitions, associated metrics,\nand measures. Furthermore, we depict a correlation matrix that projects the\npositive and negative influences (synergies and conflicts) among categories\nacross different dimensions. This systematized reference assists both software\ndevelopers and researchers in effectively formulating, managing, and\nreconciling trade-offs within sustainable software development.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u6784\u5efa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u53ef\u6301\u7eed\u6027\u9700\u6c42\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d6\u73af\u5883\u3001\u6280\u672f\u3001\u793e\u4f1a\u548c\u7ecf\u6d4e\u56db\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9a\u4e49\u3001\u6307\u6807\u548c\u76f8\u5173\u6027\u77e9\u9635\u3002", "motivation": "\u73b0\u6709\u53ef\u6301\u7eed\u6027\u9700\u6c42\u7814\u7a76\u5b58\u5728\u788e\u7247\u5316\u3001\u7ef4\u5ea6\u5355\u4e00\u6216\u9886\u57df\u5c40\u9650\u7684\u95ee\u9898\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u5206\u7c7b\u6cd5\u6765\u652f\u6301\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u7cfb\u7edf\u6027\u5730\u5904\u7406\u53ef\u6301\u7eed\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u4ece\u6700\u65b0\u7814\u7a76\u4e2d\u63d0\u53d6\u548c\u6574\u7406\u53ef\u6301\u7eed\u6027\u9700\u6c42\uff0c\u6784\u5efa\u8de8\u56db\u4e2a\u7ef4\u5ea6\u7684\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u53ef\u6301\u7eed\u6027\u9700\u6c42\u5206\u7c7b\u6cd5\uff0c\u5305\u542b\u5404\u7ef4\u5ea6\u7684\u660e\u786e\u5b9a\u4e49\u3001\u76f8\u5173\u6307\u6807\u548c\u5ea6\u91cf\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5c55\u793a\u4e0d\u540c\u7ef4\u5ea6\u95f4\u534f\u540c\u4e0e\u51b2\u7a81\u7684\u76f8\u5173\u6027\u77e9\u9635\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u8005\u548c\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u53c2\u8003\uff0c\u5e2e\u52a9\u4ed6\u4eec\u5728\u53ef\u6301\u7eed\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u6709\u6548\u5236\u5b9a\u3001\u7ba1\u7406\u548c\u534f\u8c03\u9700\u6c42\u6743\u8861\u3002"}}
{"id": "2510.08959", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08959", "abs": "https://arxiv.org/abs/2510.08959", "authors": ["Jinxin Shi", "Zongsheng Cao", "Runmin Ma", "Yusong Hu", "Jie Zhou", "Xin Li", "Lei Bai", "Liang He", "Bo Zhang"], "title": "DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction", "comment": "16 pages, 6 figures, 5 tables, Under Review", "summary": "The deep-research framework orchestrates external tools to perform complex,\nmulti-step scientific reasoning that exceeds the native limits of a single\nlarge language model. However, it still suffers from context pollution, weak\nevidentiary support, and brittle execution paths. To address these issues, we\npropose DualResearch, a retrieval and fusion framework that matches the\nepistemic structure of tool-intensive reasoning by jointly modeling two\ncomplementary graphs: a breadth semantic graph that encodes stable background\nknowledge, and a depth causal graph that captures execution provenance. Each\ngraph has a layer-native relevance function, seed-anchored semantic diffusion\nfor breadth, and causal-semantic path matching with reliability weighting for\ndepth. To reconcile their heterogeneity and query-dependent uncertainty,\nDualResearch converts per-layer path evidence into answer distributions and\nfuses them in log space via an entropy-gated rule with global calibration. The\nfusion up-weights the more certain channel and amplifies agreement. As a\ncomplement to deep-research systems, DualResearch compresses lengthy multi-tool\nexecution logs into a concise reasoning graph, and we show that it can\nreconstruct answers stably and effectively. On the scientific reasoning\nbenchmarks HLE and GPQA, DualResearch achieves competitive performance. Using\nlog files from the open-source system InternAgent, its accuracy improves by\n7.7% on HLE and 6.06% on GPQA.", "AI": {"tldr": "DualResearch\u662f\u4e00\u4e2a\u68c0\u7d22\u548c\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u5e7f\u5ea6\u8bed\u4e49\u56fe\u548c\u6df1\u5ea6\u56e0\u679c\u56fe\u6765\u89e3\u51b3\u6df1\u5ea6\u7814\u7a76\u6846\u67b6\u4e2d\u7684\u4e0a\u4e0b\u6587\u6c61\u67d3\u3001\u8bc1\u636e\u652f\u6301\u8584\u5f31\u548c\u6267\u884c\u8def\u5f84\u8106\u5f31\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u7814\u7a76\u6846\u67b6\u867d\u7136\u80fd\u534f\u8c03\u5916\u90e8\u5de5\u5177\u8fdb\u884c\u590d\u6742\u79d1\u5b66\u63a8\u7406\uff0c\u4f46\u4ecd\u5b58\u5728\u4e0a\u4e0b\u6587\u6c61\u67d3\u3001\u8bc1\u636e\u652f\u6301\u8584\u5f31\u548c\u6267\u884c\u8def\u5f84\u8106\u5f31\u7b49\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51faDualResearch\u6846\u67b6\uff0c\u8054\u5408\u5efa\u6a21\u4e24\u4e2a\u4e92\u8865\u56fe\uff1a\u5e7f\u5ea6\u8bed\u4e49\u56fe\u7f16\u7801\u7a33\u5b9a\u80cc\u666f\u77e5\u8bc6\uff0c\u6df1\u5ea6\u56e0\u679c\u56fe\u6355\u83b7\u6267\u884c\u6765\u6e90\u3002\u6bcf\u4e2a\u56fe\u90fd\u6709\u5c42\u539f\u751f\u76f8\u5173\u6027\u51fd\u6570\uff0c\u5e7f\u5ea6\u4f7f\u7528\u79cd\u5b50\u951a\u5b9a\u8bed\u4e49\u6269\u6563\uff0c\u6df1\u5ea6\u4f7f\u7528\u56e0\u679c\u8bed\u4e49\u8def\u5f84\u5339\u914d\u548c\u53ef\u9760\u6027\u52a0\u6743\u3002\u901a\u8fc7\u71b5\u95e8\u63a7\u89c4\u5219\u5728log\u7a7a\u95f4\u878d\u5408\u7b54\u6848\u5206\u5e03\u3002", "result": "\u5728\u79d1\u5b66\u63a8\u7406\u57fa\u51c6HLE\u548cGPQA\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f7f\u7528InternAgent\u7cfb\u7edf\u7684\u65e5\u5fd7\u6587\u4ef6\uff0c\u5728HLE\u4e0a\u7684\u51c6\u786e\u7387\u63d0\u9ad87.7%\uff0c\u5728GPQA\u4e0a\u63d0\u9ad86.06%\u3002", "conclusion": "DualResearch\u80fd\u591f\u5c06\u5197\u957f\u7684\u591a\u5de5\u5177\u6267\u884c\u65e5\u5fd7\u538b\u7f29\u4e3a\u7b80\u6d01\u7684\u63a8\u7406\u56fe\uff0c\u7a33\u5b9a\u6709\u6548\u5730\u91cd\u6784\u7b54\u6848\uff0c\u4f5c\u4e3a\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u7684\u8865\u5145\u5177\u6709\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2510.09443", "categories": ["cs.CR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.09443", "abs": "https://arxiv.org/abs/2510.09443", "authors": ["Raffaele Cristodaro", "Benjamin Kramer", "Claudio J. Tessone"], "title": "The Impact of Sanctions on decentralised Privacy Tools: A Case Study of Tornado Cash", "comment": null, "summary": "This paper investigates the impact of sanctions on Tornado Cash, a smart\ncontract protocol designed to enhance transaction privacy. Following the U.S.\nDepartment of the Treasury's sanctions against Tornado Cash in August 2022,\nplatform activity declined sharply. We document a significant and sustained\nreduction in transaction volume, user diversity, and overall protocol\nutilization after the sanctions were imposed. Our analysis draws on transaction\ndata from three major blockchains: Ethereum, BNB Smart Chain, and Polygon. We\nfurther examine developments following the partial lifting and eventual removal\nof sanctions by the U.S. Office of Foreign Assets Control (OFAC) in March 2025.\nAlthough activity partially recovered, the rebound remained limited. The\nTornado Cash case illustrates how regulatory interventions can affect\ndecentralized protocols, while also highlighting the challenges of fully\nenforcing such measures in decentralized environments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7f8e\u56fd\u5bf9Tornado Cash\u5236\u88c1\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5236\u88c1\u5bfc\u81f4\u8be5\u9690\u79c1\u534f\u8bae\u7684\u4ea4\u6613\u91cf\u3001\u7528\u6237\u591a\u6837\u6027\u548c\u4f7f\u7528\u7387\u663e\u8457\u4e0b\u964d\uff0c\u5373\u4f7f\u5728\u90e8\u5206\u5236\u88c1\u89e3\u9664\u540e\u6062\u590d\u4e5f\u6709\u9650\u3002", "motivation": "\u7814\u7a76\u76d1\u7ba1\u5e72\u9884\u5bf9\u53bb\u4e2d\u5fc3\u5316\u534f\u8bae\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u7f8e\u56fd\u8d22\u653f\u90e8\u5bf9Tornado Cash\u7684\u5236\u88c1\u5982\u4f55\u5f71\u54cd\u5176\u6d3b\u52a8\u6c34\u5e73\u3002", "method": "\u5206\u6790\u4ee5\u592a\u574a\u3001BNB\u667a\u80fd\u94fe\u548cPolygon\u4e09\u4e2a\u4e3b\u8981\u533a\u5757\u94fe\u4e0a\u7684\u4ea4\u6613\u6570\u636e\uff0c\u6bd4\u8f83\u5236\u88c1\u524d\u540e\u7684\u534f\u8bae\u4f7f\u7528\u60c5\u51b5\u3002", "result": "\u5236\u88c1\u540eTornado Cash\u7684\u4ea4\u6613\u91cf\u3001\u7528\u6237\u591a\u6837\u6027\u548c\u6574\u4f53\u4f7f\u7528\u7387\u663e\u8457\u4e14\u6301\u7eed\u4e0b\u964d\uff1b2025\u5e743\u6708\u90e8\u5206\u5236\u88c1\u89e3\u9664\u540e\u6d3b\u52a8\u4ec5\u90e8\u5206\u6062\u590d\uff0c\u53cd\u5f39\u6709\u9650\u3002", "conclusion": "Tornado Cash\u6848\u4f8b\u8868\u660e\u76d1\u7ba1\u5e72\u9884\u80fd\u591f\u5f71\u54cd\u53bb\u4e2d\u5fc3\u5316\u534f\u8bae\uff0c\u4f46\u4e5f\u7a81\u663e\u4e86\u5728\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u5b8c\u5168\u6267\u884c\u6b64\u7c7b\u63aa\u65bd\u7684\u6311\u6218\u3002"}}
{"id": "2510.08996", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08996", "abs": "https://arxiv.org/abs/2510.08996", "authors": ["Spandan Garg", "Ben Steenhoek", "Yufan Huang"], "title": "Saving SWE-Bench: A Benchmark Mutation Approach for Realistic Agent Evaluation", "comment": null, "summary": "Current benchmarks for evaluating software engineering agents, such as\nSWE-Bench Verified, are predominantly derived from GitHub issues and fail to\naccurately reflect how developers interact with chat-based coding assistants in\nintegrated development environments (IDEs). We posit that this mismatch leads\nto a systematic overestimation of agent's capabilities in real-world scenarios,\nespecially bug fixing. We introduce a novel benchmarking framework that\ntransforms existing formal benchmarks into realistic user queries through\nsystematic analysis of developer interaction patterns with chat-based agents.\nOur methodology is flexible and can be easily extended to existing benchmarks.\nIn this paper, we apply our testing framework to SWE-Bench Verified, the\nTypeScript subset of Multi-SWE-Bench and a private benchmark, SWE-Bench C# and\ntransform formal GitHub issue descriptions into realistic user-style queries\nbased on telemetry analysis of a popular chat-based agent interactions. Our\nfindings reveal that existing benchmarks significantly overestimate agent\ncapabilities for some models by >50% over baseline performance for public\nbenchmarks and ~10-16% for our internal benchmark. This work establishes a new\nparadigm for evaluating interactive chat-based software engineering agents\nthrough benchmark mutation techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5c06\u73b0\u6709\u7684\u6b63\u5f0f\u57fa\u51c6\u8f6c\u5316\u4e3a\u57fa\u4e8e\u5f00\u53d1\u8005\u4e0e\u804a\u5929\u4ee3\u7406\u4ea4\u4e92\u6a21\u5f0f\u7684\u771f\u5b9e\u7528\u6237\u67e5\u8be2\uff0c\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u663e\u8457\u9ad8\u4f30\u4e86\u4ee3\u7406\u7684\u5b9e\u9645\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eGitHub\u95ee\u9898\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u8bc4\u4f30\u57fa\u51c6\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u5f00\u53d1\u8005\u5728IDE\u4e2d\u4e0e\u804a\u5929\u7f16\u7801\u52a9\u624b\u7684\u771f\u5b9e\u4ea4\u4e92\u65b9\u5f0f\uff0c\u5bfc\u81f4\u5bf9\u4ee3\u7406\u5b9e\u9645\u80fd\u529b\u7684\u7cfb\u7edf\u6027\u9ad8\u4f30\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u5f00\u53d1\u8005\u4e0e\u804a\u5929\u4ee3\u7406\u7684\u4ea4\u4e92\u6a21\u5f0f\uff0c\u5c06\u73b0\u6709\u6b63\u5f0f\u57fa\u51c6\u8f6c\u5316\u4e3a\u771f\u5b9e\u7528\u6237\u98ce\u683c\u7684\u67e5\u8be2\uff0c\u5e76\u5c06\u6b64\u65b9\u6cd5\u5e94\u7528\u4e8e\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u663e\u8457\u9ad8\u4f30\u4e86\u4ee3\u7406\u80fd\u529b\uff0c\u5728\u516c\u5171\u57fa\u51c6\u4e0a\u67d0\u4e9b\u6a21\u578b\u7684\u80fd\u529b\u88ab\u9ad8\u4f30\u8d85\u8fc750%\uff0c\u5728\u5185\u90e8\u57fa\u51c6\u4e0a\u9ad8\u4f30\u7ea610-16%\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u57fa\u51c6\u53d8\u5f02\u6280\u672f\u4e3a\u8bc4\u4f30\u4ea4\u4e92\u5f0f\u804a\u5929\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u5efa\u7acb\u4e86\u65b0\u7684\u8303\u5f0f\u3002"}}
{"id": "2510.08966", "categories": ["cs.AI", "cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.08966", "abs": "https://arxiv.org/abs/2510.08966", "authors": ["Ruitong Liu", "Yan Wen", "Te Sun", "Yunjia Wu", "Pingyang Huang", "Zihang Yu", "Siyuan Li"], "title": "Semantic-Condition Tuning: Fusing Graph Context with Large Language Models for Knowledge Graph Completion", "comment": "11 pages, 3 figures, conference", "summary": "Fusing Knowledge Graphs with Large Language Models is crucial for\nknowledge-intensive tasks like knowledge graph completion. The prevailing\nparadigm, prefix-tuning, simply concatenates knowledge embeddings with text\ninputs. However, this shallow fusion overlooks the rich relational semantics\nwithin KGs and imposes a significant implicit reasoning burden on the LLM to\ncorrelate the prefix with the text. To address these, we propose\nSemantic-condition Tuning (SCT), a new knowledge injection paradigm comprising\ntwo key modules. First, a Semantic Graph Module employs a Graph Neural Network\nto extract a context-aware semantic condition from the local graph\nneighborhood, guided by knowledge-enhanced relations. Subsequently, this\ncondition is passed to a Condition-Adaptive Fusion Module, which, in turn,\nadaptively modulates the textual embedding via two parameterized projectors,\nenabling a deep, feature-wise, and knowledge-aware interaction. The resulting\npre-fused embedding is then fed into the LLM for fine-tuning. Extensive\nexperiments on knowledge graph benchmarks demonstrate that SCT significantly\noutperforms prefix-tuning and other strong baselines. Our analysis confirms\nthat by modulating the input representation with semantic graph context before\nLLM inference, SCT provides a more direct and potent signal, enabling more\naccurate and robust knowledge reasoning.", "AI": {"tldr": "\u63d0\u51faSemantic-condition Tuning (SCT)\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u77e5\u8bc6\u56fe\u8c31\u7684\u8bed\u4e49\u6761\u4ef6\uff0c\u5e76\u81ea\u9002\u5e94\u5730\u878d\u5408\u5230\u6587\u672c\u5d4c\u5165\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u524d\u7f00\u8c03\u4f18\u65b9\u6cd5\u53ea\u662f\u7b80\u5355\u5730\u5c06\u77e5\u8bc6\u5d4c\u5165\u4e0e\u6587\u672c\u8f93\u5165\u62fc\u63a5\uff0c\u5ffd\u7565\u4e86\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4e30\u5bcc\u7684\u5173\u7cfb\u8bed\u4e49\uff0c\u7ed9\u5927\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u4e86\u9690\u5f0f\u63a8\u7406\u8d1f\u62c5\u3002", "method": "SCT\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6a21\u5757\uff1a\u8bed\u4e49\u56fe\u6a21\u5757\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u4ece\u5c40\u90e8\u56fe\u90bb\u57df\u4e2d\u63d0\u53d6\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8bed\u4e49\u6761\u4ef6\uff1b\u6761\u4ef6\u81ea\u9002\u5e94\u878d\u5408\u6a21\u5757\u901a\u8fc7\u53c2\u6570\u5316\u6295\u5f71\u5668\u81ea\u9002\u5e94\u5730\u8c03\u8282\u6587\u672c\u5d4c\u5165\uff0c\u5b9e\u73b0\u6df1\u5ea6\u3001\u7279\u5f81\u7ea7\u7684\u77e5\u8bc6\u611f\u77e5\u4ea4\u4e92\u3002", "result": "\u5728\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSCT\u663e\u8457\u4f18\u4e8e\u524d\u7f00\u8c03\u4f18\u548c\u5176\u4ed6\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5728LLM\u63a8\u7406\u524d\u7528\u8bed\u4e49\u56fe\u4e0a\u4e0b\u6587\u8c03\u8282\u8f93\u5165\u8868\u793a\uff0cSCT\u63d0\u4f9b\u4e86\u66f4\u76f4\u63a5\u548c\u6709\u6548\u7684\u4fe1\u53f7\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u548c\u9c81\u68d2\u7684\u77e5\u8bc6\u63a8\u7406\u3002"}}
{"id": "2510.09494", "categories": ["cs.CR", "cs.DB", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.09494", "abs": "https://arxiv.org/abs/2510.09494", "authors": ["Nico Bistolfi", "Andreea Georgescu", "Dave Hodson"], "title": "The Data Enclave Advantage: A New Paradigm for Least-Privileged Data Access in a Zero-Trust World", "comment": "11 pages, 2 figures, company whitepaper, no journal", "summary": "As cloud infrastructure evolves to support dynamic and distributed workflows,\naccelerated now by AI-driven processes, the outdated model of standing\npermissions has become a critical vulnerability. Based on the Cloud Security\nAlliance (CSA) Top Threats to Cloud Computing Deep Dive 2025 Report, our\nanalysis details how standing permissions cause catastrophic cloud breaches.\nWhile current security tools are addressing network and API security, the\nchallenge of securing granular data access remains. Removing standing\npermissions at the data level is as critical as it is at the network level,\nespecially for companies handling valuable data at scale.\n  In this white paper, we introduce an innovative architecture based on\non-demand data enclaves to address this gap directly. Our approach enables Zero\nStanding Privilege (ZSP) and Just-in-Time (JIT) principles at the data level.\nWe replace static permissions with temporary data contracts that enforce\nproactive protection. This means separation is built around the data requested\non-demand, providing precise access and real time monitoring for individual\nrecords instead of datasets. This solution drastically reduces the attack\nsurface, prevents privilege creep, and simplifies auditing, offering a vital\npath for enterprises to transition to a more secure and resilient data\nenvironment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6309\u9700\u6570\u636e\u98de\u5730\u7684\u521b\u65b0\u67b6\u6784\uff0c\u5728\u6570\u636e\u5c42\u9762\u5b9e\u73b0\u96f6\u5e38\u9a7b\u6743\u9650\u548c\u5373\u65f6\u8bbf\u95ee\u539f\u5219\uff0c\u7528\u4e34\u65f6\u6570\u636e\u5408\u7ea6\u66ff\u4ee3\u9759\u6001\u6743\u9650\uff0c\u5927\u5e45\u51cf\u5c11\u653b\u51fb\u9762\u5e76\u7b80\u5316\u5ba1\u8ba1\u3002", "motivation": "\u968f\u7740\u4e91\u57fa\u7840\u8bbe\u65bd\u652f\u6301\u52a8\u6001\u5206\u5e03\u5f0f\u5de5\u4f5c\u6d41\uff0c\u7279\u522b\u662fAI\u9a71\u52a8\u6d41\u7a0b\u52a0\u901f\u53d1\u5c55\uff0c\u5e38\u9a7b\u6743\u9650\u6a21\u578b\u5df2\u6210\u4e3a\u5173\u952e\u6f0f\u6d1e\u3002\u5f53\u524d\u5b89\u5168\u5de5\u5177\u4e3b\u8981\u5173\u6ce8\u7f51\u7edc\u548cAPI\u5b89\u5168\uff0c\u4f46\u7ec6\u7c92\u5ea6\u6570\u636e\u8bbf\u95ee\u5b89\u5168\u4ecd\u662f\u6311\u6218\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6309\u9700\u6570\u636e\u98de\u5730\u7684\u521b\u65b0\u67b6\u6784\uff0c\u5b9e\u73b0\u6570\u636e\u5c42\u9762\u7684\u96f6\u5e38\u9a7b\u6743\u9650\u548c\u5373\u65f6\u8bbf\u95ee\u539f\u5219\u3002\u7528\u4e34\u65f6\u6570\u636e\u5408\u7ea6\u66ff\u4ee3\u9759\u6001\u6743\u9650\uff0c\u56f4\u7ed5\u6309\u9700\u8bf7\u6c42\u7684\u6570\u636e\u6784\u5efa\u5206\u79bb\u673a\u5236\uff0c\u63d0\u4f9b\u7cbe\u786e\u8bbf\u95ee\u548c\u5b9e\u65f6\u76d1\u63a7\u3002", "result": "\u8be5\u89e3\u51b3\u65b9\u6848\u5927\u5e45\u51cf\u5c11\u653b\u51fb\u9762\uff0c\u9632\u6b62\u6743\u9650\u8513\u5ef6\uff0c\u7b80\u5316\u5ba1\u8ba1\u6d41\u7a0b\uff0c\u4e3a\u4f01\u4e1a\u5411\u66f4\u5b89\u5168\u3001\u5f39\u6027\u7684\u6570\u636e\u73af\u5883\u8f6c\u578b\u63d0\u4f9b\u5173\u952e\u8def\u5f84\u3002", "conclusion": "\u5728\u6570\u636e\u5c42\u9762\u79fb\u9664\u5e38\u9a7b\u6743\u9650\u4e0e\u5728\u7f51\u7edc\u5c42\u9762\u540c\u6837\u91cd\u8981\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5904\u7406\u5927\u89c4\u6a21\u9ad8\u4ef7\u503c\u6570\u636e\u7684\u4f01\u4e1a\u3002\u6309\u9700\u6570\u636e\u98de\u5730\u67b6\u6784\u662f\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.09045", "categories": ["cs.SE", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09045", "abs": "https://arxiv.org/abs/2510.09045", "authors": ["Manojit Chakraborty", "Madhusudan Ghosh", "Rishabh Gupta"], "title": "Cost-Efficient Long Code Translation using LLMs while Leveraging Identifier Replacements", "comment": null, "summary": "In the domain of software development, LLMs have been utilized to automate\ntasks such as code translation, where source code from one programming language\nis translated to another while preserving its functionality. However, LLMs\noften struggle with long source codes that don't fit into the context window,\nwhich produces inaccurate translations. To address this, we propose a novel\nzero-shot code translation method that incorporates identifier replacement. By\nsubstituting user-given long identifiers with generalized placeholders during\ntranslation, our method allows the LLM to focus on the logical structure of the\ncode, by reducing token count and memory usage, which improves the efficiency\nand cost-effectiveness of long code translation. Our empirical results\ndemonstrate that our approach preserves syntactical and hierarchical\ninformation and produces translation results with reduced tokens.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96f6\u6837\u672c\u4ee3\u7801\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u957f\u6807\u8bc6\u7b26\u66ff\u6362\u4e3a\u901a\u7528\u5360\u4f4d\u7b26\u6765\u51cf\u5c11token\u6570\u91cf\uff0c\u63d0\u9ad8\u957f\u4ee3\u7801\u7ffb\u8bd1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "LLMs\u5728\u5904\u7406\u8d85\u51fa\u4e0a\u4e0b\u6587\u7a97\u53e3\u7684\u957f\u6e90\u4ee3\u7801\u65f6\uff0c\u5f80\u5f80\u4ea7\u751f\u4e0d\u51c6\u786e\u7684\u7ffb\u8bd1\u7ed3\u679c\uff0c\u9700\u8981\u89e3\u51b3\u957f\u4ee3\u7801\u7ffb\u8bd1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u6311\u6218\u3002", "method": "\u91c7\u7528\u6807\u8bc6\u7b26\u66ff\u6362\u7b56\u7565\uff0c\u5728\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\u5c06\u7528\u6237\u7ed9\u5b9a\u7684\u957f\u6807\u8bc6\u7b26\u66ff\u6362\u4e3a\u901a\u7528\u5360\u4f4d\u7b26\uff0c\u8ba9LLM\u4e13\u6ce8\u4e8e\u4ee3\u7801\u7684\u903b\u8f91\u7ed3\u6784\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u4fdd\u7559\u8bed\u6cd5\u548c\u5c42\u6b21\u7ed3\u6784\u4fe1\u606f\uff0c\u5e76\u4ea7\u751ftoken\u6570\u91cf\u51cf\u5c11\u7684\u7ffb\u8bd1\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u51cf\u5c11token\u6570\u91cf\u548c\u5185\u5b58\u4f7f\u7528\uff0c\u63d0\u9ad8\u4e86\u957f\u4ee3\u7801\u7ffb\u8bd1\u7684\u6548\u7387\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2510.08987", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08987", "abs": "https://arxiv.org/abs/2510.08987", "authors": ["Qixiang Yin", "Huanjin Yao", "Jianghao Chen", "Jiaxing Huang", "Zhicheng Zhao", "Fei Su"], "title": "Tiny-R1V: Lightweight Multimodal Unified Reasoning Model via Model Merging", "comment": "Technical report, Code will be available at\n  https://github.com/buptyqx/Tiny-R1V", "summary": "Although Multimodal Large Language Models (MLLMs) have demonstrated\nremarkable capabilities across diverse tasks, they encounter numerous\nchallenges in terms of reasoning efficiency, such as large model size,\noverthinking, and compromised accuracy in lightweight scenarios. However,\nresearch on the reasoning capabilities of lightweight MLLMs is quite lacking.\nTo this end, we propose Tiny-R1V, a novel lightweight 3B model that achieves\nfaster inference and higher accuracy via a two-stage optimization, while\nunifying multimodal reasoning across multiple tasks and using fewer tokens. In\nthe first stage, Tiny-R1V introduces Length-Informed Relative Policy\nOptimization (LIPO), a novel reinforcement learning method, to train each\nreasoning model. The LIPO is designed to dynamically adjusts advantages of\nresponses within groups, that is, by prioritizing concise yet high-quality\nresponses to encourage the generation of shorter and more accurate response. In\nthe second stage, we propose Adaptive Model Merging (AMM), a training-free\nmodel merging method that merges multiple specialist models into a unified\narchitecture. Specifically, AMM adaptively adjusts the weights of task vectors\nand robustly optimizes the merged vectors via a novel gradient projection\nregularization loss function, thus mitigating redundant conflicts between them.\nExtensive evaluations on ten widely-used reasoning benchmarks covering\nmathematics, structured data (charts, tables, documents), OCR, and general\ncapabilities showcase the superior performance of Tiny-R1V, enabling\nlightweight models to excel in diverse multimodal reasoning tasks.", "AI": {"tldr": "Tiny-R1V\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea73B\u53c2\u6570\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u4f18\u5316\u5b9e\u73b0\u66f4\u5feb\u7684\u63a8\u7406\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u7edf\u4e00\u4e86\u591a\u4efb\u52a1\u7684\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u6548\u7387\u65b9\u9762\u9762\u4e34\u6a21\u578b\u5c3a\u5bf8\u5927\u3001\u8fc7\u5ea6\u601d\u8003\u3001\u8f7b\u91cf\u7ea7\u573a\u666f\u51c6\u786e\u7387\u4f4e\u7b49\u6311\u6218\uff0c\u800c\u8f7b\u91cf\u7ea7MLLMs\u7684\u63a8\u7406\u80fd\u529b\u7814\u7a76\u76f8\u5bf9\u7f3a\u4e4f\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\uff1a\u7b2c\u4e00\u9636\u6bb5\u5f15\u5165LIPO\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u52a8\u6001\u8c03\u6574\u7ec4\u5185\u54cd\u5e94\u4f18\u52bf\uff0c\u9f13\u52b1\u751f\u6210\u66f4\u77ed\u66f4\u51c6\u786e\u7684\u54cd\u5e94\uff1b\u7b2c\u4e8c\u9636\u6bb5\u63d0\u51faAMM\u8bad\u7ec3\u65e0\u5173\u7684\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u4efb\u52a1\u5411\u91cf\u6743\u91cd\u548c\u68af\u5ea6\u6295\u5f71\u6b63\u5219\u5316\u635f\u5931\u51fd\u6570\u6765\u878d\u5408\u591a\u4e2a\u4e13\u5bb6\u6a21\u578b\u3002", "result": "\u5728\u5341\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08\u6db5\u76d6\u6570\u5b66\u3001\u7ed3\u6784\u5316\u6570\u636e\u3001OCR\u548c\u901a\u7528\u80fd\u529b\uff09\u4e0a\u5c55\u73b0\u51fa\u5353\u8d8a\u6027\u80fd\uff0c\u4f7f\u8f7b\u91cf\u7ea7\u6a21\u578b\u5728\u591a\u6837\u5316\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "Tiny-R1V\u901a\u8fc7\u521b\u65b0\u7684\u4e24\u9636\u6bb5\u4f18\u5316\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u8f7b\u91cf\u7ea7\u6a21\u578b\u5728\u590d\u6742\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09058", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.09058", "abs": "https://arxiv.org/abs/2510.09058", "authors": ["Italo Santos", "Cleyton Magalhaes", "Ronnie de Souza Santos"], "title": "Model-Assisted and Human-Guided: Perceptions and Practices of Software Professionals Using LLMs for Coding", "comment": null, "summary": "Large Language Models have quickly become a central component of modern\nsoftware development workflows, and software practitioners are increasingly\nintegrating LLMs into various stages of the software development lifecycle.\nDespite the growing presence of LLMs, there is still a limited understanding of\nhow these tools are actually used in practice and how professionals perceive\ntheir benefits and limitations. This paper presents preliminary findings from a\nglobal survey of 131 software practitioners. Our results reveal how LLMs are\nutilized for various coding-specific tasks. Software professionals report\nbenefits such as increased productivity, reduced cognitive load, and faster\nlearning, but also raise concerns about LLMs' inaccurate outputs, limited\ncontext awareness, and associated ethical risks. Most developers treat LLMs as\nassistive tools rather than standalone solutions, reflecting a cautious yet\npractical approach to their integration. Our findings provide an early,\npractitioner-focused perspective on LLM adoption, highlighting key\nconsiderations for future research and responsible use in software engineering.", "AI": {"tldr": "\u5bf9131\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u7684\u5168\u7403\u8c03\u67e5\u663e\u793a\uff0cLLMs\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u88ab\u5e7f\u6cdb\u7528\u4e8e\u7f16\u7801\u4efb\u52a1\uff0c\u5e26\u6765\u751f\u4ea7\u529b\u63d0\u5347\u548c\u8ba4\u77e5\u8d1f\u62c5\u51cf\u8f7b\uff0c\u4f46\u4e5f\u5b58\u5728\u8f93\u51fa\u4e0d\u51c6\u786e\u3001\u4e0a\u4e0b\u6587\u7406\u89e3\u6709\u9650\u548c\u4f26\u7406\u98ce\u9669\u7b49\u95ee\u9898\u3002", "motivation": "\u4e86\u89e3LLMs\u5728\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u4f7f\u7528\u60c5\u51b5\u548c\u4ece\u4e1a\u8005\u5bf9\u5176\u4f18\u7f3a\u70b9\u7684\u8ba4\u77e5\uff0c\u586b\u8865\u5bf9LLM\u5de5\u5177\u5b9e\u9645\u5e94\u7528\u7406\u89e3\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5168\u7403\u8c03\u67e5\u6536\u96c6\u4e86131\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u7684\u53cd\u9988\u6570\u636e\uff0c\u5206\u6790LLMs\u5728\u8f6f\u4ef6\u5f00\u53d1\u5404\u9636\u6bb5\u7684\u4f7f\u7528\u60c5\u51b5\u3002", "result": "\u4ece\u4e1a\u8005\u62a5\u544aLLMs\u63d0\u9ad8\u4e86\u751f\u4ea7\u529b\u3001\u51cf\u8f7b\u4e86\u8ba4\u77e5\u8d1f\u62c5\u3001\u52a0\u901f\u4e86\u5b66\u4e60\uff0c\u4f46\u4e5f\u62c5\u5fe7\u8f93\u51fa\u4e0d\u51c6\u786e\u3001\u4e0a\u4e0b\u6587\u7406\u89e3\u6709\u9650\u548c\u4f26\u7406\u98ce\u9669\u3002\u5927\u591a\u6570\u5f00\u53d1\u8005\u5c06LLMs\u89c6\u4e3a\u8f85\u52a9\u5de5\u5177\u800c\u975e\u72ec\u7acb\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "LLMs\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5c55\u73b0\u51fa\u5b9e\u7528\u4ef7\u503c\uff0c\u4f46\u9700\u8981\u8c28\u614e\u4f7f\u7528\u3002\u7814\u7a76\u4e3a\u672a\u6765LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u8d1f\u8d23\u4efb\u4f7f\u7528\u63d0\u4f9b\u4e86\u4ece\u4e1a\u8005\u89c6\u89d2\u7684\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2510.09011", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09011", "abs": "https://arxiv.org/abs/2510.09011", "authors": ["Yincen Qu", "Huan Xiao", "Feng Li", "Hui Zhou", "Xiangying Dai"], "title": "TripScore: Benchmarking and rewarding real-world travel planning with fine-grained evaluation", "comment": null, "summary": "Travel planning is a valuable yet complex task that poses significant\nchallenges even for advanced large language models (LLMs). While recent\nbenchmarks have advanced in evaluating LLMs' planning capabilities, they often\nfall short in evaluating feasibility, reliability, and engagement of travel\nplans. We introduce a comprehensive benchmark for travel planning that unifies\nfine-grained criteria into a single reward, enabling direct comparison of plan\nquality and seamless integration with reinforcement learning (RL). Our\nevaluator achieves moderate agreement with travel-expert annotations (60.75\\%)\nand outperforms multiple LLM-as-judge baselines. We further release a\nlarge-scale dataset of 4,870 queries including 219 real-world, free-form\nrequests for generalization to authentic user intent. Using this benchmark, we\nconduct extensive experiments across diverse methods and LLMs, including\ntest-time computation, neuro-symbolic approaches, supervised fine-tuning, and\nRL via GRPO. Across base models, RL generally improves itinerary feasibility\nover prompt-only and supervised baselines, yielding higher unified reward\nscores.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u65c5\u884c\u89c4\u5212\u57fa\u51c6\uff0c\u901a\u8fc7\u5355\u4e00\u5956\u52b1\u6574\u5408\u7ec6\u7c92\u5ea6\u6807\u51c6\uff0c\u652f\u6301\u5f3a\u5316\u5b66\u4e60\u96c6\u6210\uff0c\u5e76\u5728\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86RL\u65b9\u6cd5\u5728\u63d0\u5347\u884c\u7a0b\u53ef\u884c\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5728\u8bc4\u4f30LLMs\u65c5\u884c\u89c4\u5212\u80fd\u529b\u65f6\uff0c\u5f80\u5f80\u5ffd\u89c6\u53ef\u884c\u6027\u3001\u53ef\u9760\u6027\u548c\u53c2\u4e0e\u5ea6\u7b49\u5173\u952e\u7ef4\u5ea6\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6784\u5efa\u5305\u542b4,870\u4e2a\u67e5\u8be2\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u7edf\u4e00\u5956\u52b1\u8bc4\u4f30\u5668\uff0c\u6bd4\u8f83\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u3001\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u3001\u76d1\u7763\u5fae\u8c03\u548cGRPO\u5f3a\u5316\u5b66\u4e60\u7b49\u591a\u79cd\u65b9\u6cd5\u3002", "result": "\u8bc4\u4f30\u5668\u4e0e\u65c5\u884c\u4e13\u5bb6\u6807\u6ce8\u8fbe\u523060.75%\u7684\u4e00\u81f4\u6027\uff0c\u4f18\u4e8e\u591a\u4e2aLLM-as-judge\u57fa\u7ebf\uff1bRL\u65b9\u6cd5\u5728\u57fa\u7840\u6a21\u578b\u4e0a\u666e\u904d\u63d0\u5347\u884c\u7a0b\u53ef\u884c\u6027\uff0c\u83b7\u5f97\u66f4\u9ad8\u7684\u7edf\u4e00\u5956\u52b1\u5206\u6570\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u51c6\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u65c5\u884c\u89c4\u5212\u8d28\u91cf\uff0cRL\u65b9\u6cd5\u5728\u63d0\u5347\u89c4\u5212\u53ef\u884c\u6027\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u4e3aLLMs\u5728\u590d\u6742\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2510.09073", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.09073", "abs": "https://arxiv.org/abs/2510.09073", "authors": ["Matthew Sotoudeh"], "title": "Literate Tracing", "comment": "examples at https://lair.masot.net/trex . SPLASH Onward 2025", "summary": "As computer systems grow ever larger and more complex, a crucial task in\nsoftware development is for one person (the system expert) to communicate to\nanother (the system novice) how a certain program works. This paper reports on\nthe author's experiences with a paradigm for program documentation that we call\nliterate tracing. A literate trace explains a software system using annotated,\nconcrete execution traces of the system. Literate traces complement both\nin-code comments (which often lack global context) and out-of-band design docs\n(which often lack a concrete connection to the code). We also describe TReX,\nour tool for making literate traces that are interactive, visual, and\nguaranteed by construction to be faithful to the program semantics. We have\nused TReX to write literate traces explaining components of large systems\nsoftware including the Linux kernel, Git source control system, and GCC\ncompiler.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a'\u6587\u5b66\u5316\u8ffd\u8e2a'\u7684\u7a0b\u5e8f\u6587\u6863\u8303\u5f0f\uff0c\u901a\u8fc7\u5e26\u6ce8\u91ca\u7684\u5177\u4f53\u6267\u884c\u8ffd\u8e2a\u6765\u89e3\u91ca\u8f6f\u4ef6\u7cfb\u7edf\uff0c\u5e76\u5f00\u53d1\u4e86TReX\u5de5\u5177\u6765\u521b\u5efa\u4ea4\u4e92\u5f0f\u3001\u53ef\u89c6\u5316\u7684\u6587\u5b66\u5316\u8ffd\u8e2a\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u673a\u7cfb\u7edf\u65e5\u76ca\u5e9e\u5927\u590d\u6742\uff0c\u7cfb\u7edf\u4e13\u5bb6\u5411\u65b0\u624b\u89e3\u91ca\u7a0b\u5e8f\u5de5\u4f5c\u539f\u7406\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u4ee3\u7801\u6ce8\u91ca\u7f3a\u4e4f\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u8bbe\u8ba1\u6587\u6863\u53c8\u7f3a\u4e4f\u4e0e\u4ee3\u7801\u7684\u5177\u4f53\u8fde\u63a5\u3002", "method": "\u4f7f\u7528\u6587\u5b66\u5316\u8ffd\u8e2a\u8303\u5f0f\uff0c\u901a\u8fc7\u5e26\u6ce8\u91ca\u7684\u5177\u4f53\u6267\u884c\u8ffd\u8e2a\u6765\u89e3\u91ca\u8f6f\u4ef6\u7cfb\u7edf\u3002\u5f00\u53d1\u4e86TReX\u5de5\u5177\u6765\u521b\u5efa\u4ea4\u4e92\u5f0f\u3001\u53ef\u89c6\u5316\u7684\u8ffd\u8e2a\uff0c\u5e76\u4fdd\u8bc1\u4e0e\u7a0b\u5e8f\u8bed\u4e49\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5df2\u4f7f\u7528TReX\u4e3a\u5927\u578b\u7cfb\u7edf\u8f6f\u4ef6\uff08\u5305\u62ecLinux\u5185\u6838\u3001Git\u6e90\u4ee3\u7801\u63a7\u5236\u7cfb\u7edf\u548cGCC\u7f16\u8bd1\u5668\uff09\u7684\u7ec4\u4ef6\u7f16\u5199\u4e86\u6587\u5b66\u5316\u8ffd\u8e2a\u6587\u6863\u3002", "conclusion": "\u6587\u5b66\u5316\u8ffd\u8e2a\u8865\u5145\u4e86\u4ee3\u7801\u6ce8\u91ca\u548c\u8bbe\u8ba1\u6587\u6863\u7684\u4e0d\u8db3\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7a0b\u5e8f\u6587\u6863\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u590d\u6742\u8f6f\u4ef6\u7cfb\u7edf\u7684\u7406\u89e3\u548c\u6559\u5b66\u3002"}}
{"id": "2510.09021", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09021", "abs": "https://arxiv.org/abs/2510.09021", "authors": ["Hamed Mahdavi", "Pouria Mahdavinia", "Samira Malek", "Pegah Mohammadipour", "Alireza Hashemi", "Majid Daliri", "Alireza Farhadi", "Amir Khasahmadi", "Niloofar Mireshghallah", "Vasant Honavar"], "title": "RefGrader: Automated Grading of Mathematical Competition Proofs using Agentic Workflows", "comment": null, "summary": "State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based\nOlympiad problems to solving most of the IMO 2025 problems, with leading\nsystems reportedly handling 5 of 6 problems. Given this progress, we assess how\nwell these models can grade proofs: detecting errors, judging their severity,\nand assigning fair scores beyond binary correctness. We study proof-analysis\ncapabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we\ngrade on a 1-4 scale with detailed error annotations, and on MathArena solution\nsets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models\ncan reliably flag incorrect (including subtly incorrect) solutions but exhibit\ncalibration gaps in how partial credit is assigned. To address this, we\nintroduce agentic workflows that extract and analyze reference solutions and\nautomatically derive problem-specific rubrics for a multi-step grading process.\nWe instantiate and compare different design choices for the grading workflows,\nand evaluate their trade-offs. Across our annotated corpus and MathArena, our\nproposed workflows achieve higher agreement with human grades and more\nconsistent handling of partial credit across metrics. We release all code,\ndata, and prompts/logs to facilitate future research.", "AI": {"tldr": "\u8bc4\u4f30SOTA LLMs\u5728\u8bc1\u660e\u8bc4\u5206\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5305\u62ec\u9519\u8bef\u68c0\u6d4b\u3001\u4e25\u91cd\u6027\u5224\u65ad\u548c\u516c\u5e73\u8bc4\u5206\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u7684\u81ea\u52a8\u8bc4\u5206\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u4e0e\u4eba\u5de5\u8bc4\u5206\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u968f\u7740LLMs\u5728\u89e3\u51b3\u5965\u6797\u5339\u514b\u6570\u5b66\u95ee\u9898\u65b9\u9762\u7684\u663e\u8457\u8fdb\u6b65\uff0c\u9700\u8981\u8bc4\u4f30\u5b83\u4eec\u5728\u8bc1\u660e\u8bc4\u5206\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u68c0\u6d4b\u9519\u8bef\u3001\u5224\u65ad\u4e25\u91cd\u6027\u548c\u5206\u914d\u516c\u5e73\u5206\u6570\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4e8c\u5143\u6b63\u786e\u6027\u5224\u65ad\u3002", "method": "\u4f7f\u752890\u4e2aGemini 2.5 Pro\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u548cMathArena\u7684IMO/USAMO 2025\u89e3\u51b3\u65b9\u6848\u96c6\uff0c\u5f15\u5165\u57fa\u4e8e\u4ee3\u7406\u7684\u5de5\u4f5c\u6d41\u7a0b\u6765\u63d0\u53d6\u548c\u5206\u6790\u53c2\u8003\u89e3\u51b3\u65b9\u6848\uff0c\u81ea\u52a8\u63a8\u5bfc\u95ee\u9898\u7279\u5b9a\u7684\u8bc4\u5206\u6807\u51c6\uff0c\u8fdb\u884c\u591a\u6b65\u9aa4\u8bc4\u5206\u8fc7\u7a0b\u3002", "result": "\u6a21\u578b\u80fd\u591f\u53ef\u9760\u5730\u6807\u8bb0\u9519\u8bef\u89e3\u51b3\u65b9\u6848\uff08\u5305\u62ec\u7ec6\u5fae\u9519\u8bef\uff09\uff0c\u4f46\u5728\u5206\u914d\u90e8\u5206\u5206\u6570\u65b9\u9762\u5b58\u5728\u6821\u51c6\u5dee\u8ddd\u3002\u63d0\u51fa\u7684\u5de5\u4f5c\u6d41\u7a0b\u5728\u6ce8\u91ca\u8bed\u6599\u5e93\u548cMathArena\u4e0a\u5b9e\u73b0\u4e86\u4e0e\u4eba\u5de5\u8bc4\u5206\u66f4\u9ad8\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u5904\u7406\u90e8\u5206\u5206\u6570\u65b9\u9762\u66f4\u52a0\u4e00\u81f4\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u4ee3\u7406\u7684\u8bc4\u5206\u5de5\u4f5c\u6d41\u7a0b\u80fd\u591f\u6709\u6548\u63d0\u9ad8LLMs\u5728\u8bc1\u660e\u8bc4\u5206\u65b9\u9762\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u90e8\u5206\u5206\u6570\u548c\u4e0e\u4eba\u5de5\u8bc4\u5206\u4e00\u81f4\u6027\u65b9\u9762\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u4ee3\u7801\u3001\u6570\u636e\u548c\u63d0\u793a/\u65e5\u5fd7\u8d44\u6e90\u3002"}}
{"id": "2510.09108", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.09108", "abs": "https://arxiv.org/abs/2510.09108", "authors": ["Lukas Krodinger", "Altin Hajdari", "Stephan Lukasczyk", "Gordon Fraser"], "title": "Constraint-Guided Unit Test Generation for Machine Learning Libraries", "comment": "Accepted for SSBSE 2025", "summary": "Machine learning (ML) libraries such as PyTorch and TensorFlow are essential\nfor a wide range of modern applications. Ensuring the correctness of ML\nlibraries through testing is crucial. However, ML APIs often impose strict\ninput constraints involving complex data structures such as tensors. Automated\ntest generation tools such as Pynguin are not aware of these constraints and\noften create non-compliant inputs. This leads to early test failures and\nlimited code coverage. Prior work has investigated extracting constraints from\nofficial API documentation. In this paper, we present PynguinML, an approach\nthat improves the Pynguin test generator to leverage these constraints to\ngenerate compliant inputs for ML APIs, enabling more thorough testing and\nhigher code coverage. Our evaluation is based on 165 modules from PyTorch and\nTensorFlow, comparing PynguinML against Pynguin. The results show that\nPynguinML significantly improves test effectiveness, achieving up to 63.9 %\nhigher code coverage.", "AI": {"tldr": "PynguinML\u901a\u8fc7\u4ece\u5b98\u65b9API\u6587\u6863\u4e2d\u63d0\u53d6\u7ea6\u675f\u6761\u4ef6\uff0c\u6539\u8fdbPynguin\u6d4b\u8bd5\u751f\u6210\u5668\uff0c\u4e3a\u673a\u5668\u5b66\u4e60API\u751f\u6210\u5408\u89c4\u8f93\u5165\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u8986\u76d6\u7387\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5e93\u5982PyTorch\u548cTensorFlow\u7684API\u901a\u5e38\u5bf9\u8f93\u5165\u6709\u4e25\u683c\u7684\u7ea6\u675f\uff0c\u6d89\u53ca\u590d\u6742\u7684\u6570\u636e\u7ed3\u6784\u5982\u5f20\u91cf\u3002\u73b0\u6709\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u5de5\u5177\u5982Pynguin\u4e0d\u4e86\u89e3\u8fd9\u4e9b\u7ea6\u675f\uff0c\u7ecf\u5e38\u751f\u6210\u4e0d\u5408\u89c4\u7684\u8f93\u5165\uff0c\u5bfc\u81f4\u6d4b\u8bd5\u65e9\u671f\u5931\u8d25\u548c\u4ee3\u7801\u8986\u76d6\u7387\u6709\u9650\u3002", "method": "\u63d0\u51faPynguinML\u65b9\u6cd5\uff0c\u6539\u8fdbPynguin\u6d4b\u8bd5\u751f\u6210\u5668\uff0c\u5229\u7528\u4ece\u5b98\u65b9API\u6587\u6863\u4e2d\u63d0\u53d6\u7684\u7ea6\u675f\u6761\u4ef6\u6765\u751f\u6210\u7b26\u5408\u8981\u6c42\u7684ML API\u8f93\u5165\u3002", "result": "\u5728PyTorch\u548cTensorFlow\u7684165\u4e2a\u6a21\u5757\u4e0a\u8bc4\u4f30\uff0cPynguinML\u76f8\u6bd4Pynguin\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u6548\u679c\uff0c\u4ee3\u7801\u8986\u76d6\u7387\u6700\u9ad8\u63d0\u5347\u4e8663.9%\u3002", "conclusion": "PynguinML\u901a\u8fc7\u5229\u7528API\u7ea6\u675f\u6761\u4ef6\u751f\u6210\u5408\u89c4\u8f93\u5165\uff0c\u80fd\u591f\u66f4\u5f7b\u5e95\u5730\u6d4b\u8bd5\u673a\u5668\u5b66\u4e60\u5e93\uff0c\u663e\u8457\u63d0\u9ad8\u4ee3\u7801\u8986\u76d6\u7387\u3002"}}
{"id": "2510.09037", "categories": ["cs.AI", "cs.PL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.09037", "abs": "https://arxiv.org/abs/2510.09037", "authors": ["Sicheol Sung", "Joonghyuk Hahn", "Yo-Sub Han"], "title": "Repairing Regex Vulnerabilities via Localization-Guided Instructions", "comment": "14 pages, 4 figures, 4 tables", "summary": "Regular expressions (regexes) are foundational to modern computing for\ncritical tasks like input validation and data parsing, yet their ubiquity\nexposes systems to regular expression denial of service (ReDoS), a\nvulnerability requiring automated repair methods. Current approaches, however,\nare hampered by a trade-off. Symbolic, rule-based system are precise but fails\nto repair unseen or complex vulnerability patterns. Conversely, large language\nmodels (LLMs) possess the necessary generalizability but are unreliable for\ntasks demanding strict syntactic and semantic correctness. We resolve this\nimpasse by introducing a hybrid framework, localized regex repair (LRR),\ndesigned to harness LLM generalization while enforcing reliability. Our core\ninsight is to decouple problem identification from the repair process. First, a\ndeterministic, symbolic module localizes the precise vulnerable subpattern,\ncreating a constrained and tractable problem space. Then, the LLM invoked to\ngenerate a semantically equivalent fix for this isolated segment. This combined\narchitecture successfully resolves complex repair cases intractable for\nrule-based repair while avoiding the semantic errors of LLM-only approaches.\nOur work provides a validated methodology for solving such problems in\nautomated repair, improving the repair rate by 15.4%p over the\nstate-of-the-art. Our code is available at https://github.com/cdltlehf/LRR.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6846\u67b6LRR\u6765\u89e3\u51b3\u6b63\u5219\u8868\u8fbe\u5f0f\u62d2\u7edd\u670d\u52a1\u6f0f\u6d1e\u4fee\u590d\u95ee\u9898\uff0c\u7ed3\u5408\u4e86\u7b26\u53f7\u7cfb\u7edf\u7684\u7cbe\u786e\u6027\u548cLLM\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5c06\u95ee\u9898\u5b9a\u4f4d\u4e0e\u4fee\u590d\u8fc7\u7a0b\u89e3\u8026\uff0c\u63d0\u9ad8\u4fee\u590d\u738715.4%\u3002", "motivation": "\u5f53\u524d\u6b63\u5219\u8868\u8fbe\u5f0f\u4fee\u590d\u65b9\u6cd5\u5b58\u5728\u6743\u8861\uff1a\u7b26\u53f7\u7cfb\u7edf\u7cbe\u786e\u4f46\u65e0\u6cd5\u5904\u7406\u672a\u89c1\u6216\u590d\u6742\u6f0f\u6d1e\u6a21\u5f0f\uff0c\u800cLLM\u5177\u6709\u6cdb\u5316\u80fd\u529b\u4f46\u5728\u9700\u8981\u4e25\u683c\u8bed\u6cd5\u548c\u8bed\u4e49\u6b63\u786e\u6027\u7684\u4efb\u52a1\u4e2d\u4e0d\u53ef\u9760\u3002", "method": "LRR\u6df7\u5408\u6846\u67b6\uff1a\u9996\u5148\u4f7f\u7528\u786e\u5b9a\u6027\u7b26\u53f7\u6a21\u5757\u5b9a\u4f4d\u6613\u53d7\u653b\u51fb\u7684\u5b50\u6a21\u5f0f\uff0c\u7136\u540e\u8c03\u7528LLM\u4e3a\u8fd9\u4e2a\u9694\u79bb\u7247\u6bb5\u751f\u6210\u8bed\u4e49\u7b49\u6548\u7684\u4fee\u590d\u65b9\u6848\u3002", "result": "\u8be5\u67b6\u6784\u6210\u529f\u89e3\u51b3\u4e86\u57fa\u4e8e\u89c4\u5219\u4fee\u590d\u65e0\u6cd5\u5904\u7406\u7684\u590d\u6742\u4fee\u590d\u6848\u4f8b\uff0c\u540c\u65f6\u907f\u514d\u4e86\u7eafLLM\u65b9\u6cd5\u7684\u8bed\u4e49\u9519\u8bef\uff0c\u4fee\u590d\u7387\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u9ad8\u4e8615.4%\u3002", "conclusion": "LRR\u4e3a\u81ea\u52a8\u5316\u4fee\u590d\u95ee\u9898\u63d0\u4f9b\u4e86\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u65b9\u6cd5\u8bba\uff0c\u6709\u6548\u7ed3\u5408\u4e86\u7b26\u53f7\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548cLLM\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.09134", "categories": ["cs.SE", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.09134", "abs": "https://arxiv.org/abs/2510.09134", "authors": ["Amal Elgammal", "Bernd J. Kr\u00e4mer", "Michael P. Papazoglou", "Mira Raheem"], "title": "A Semantic Framework for Patient Digital Twins in Chronic Care", "comment": "This manuscript is currently under review at Software and Systems\n  Modeling (SoSyM)", "summary": "Personalized chronic care requires the integration of multimodal health data\nto enable precise, adaptive, and preventive decision-making. Yet most current\ndigital twin (DT) applications remain organ-specific or tied to isolated data\ntypes, lacking a unified and privacy-preserving foundation. This paper\nintroduces the Patient Medical Digital Twin (PMDT), an ontology-driven in\nsilico patient framework that integrates physiological, psychosocial,\nbehavioral, and genomic information into a coherent, extensible model.\nImplemented in OWL 2.0, the PMDT ensures semantic interoperability, supports\nautomated reasoning, and enables reuse across diverse clinical contexts. Its\nontology is structured around modular Blueprints (patient, disease and\ndiagnosis, treatment and follow-up, trajectories, safety, pathways, and adverse\nevents), formalized through dedicated conceptual views. These were iteratively\nrefined and validated through expert workshops, questionnaires, and a pilot\nstudy in the EU H2020 QUALITOP project with real-world immunotherapy patients.\nEvaluation confirmed ontology coverage, reasoning correctness, usability, and\nGDPR compliance. Results demonstrate the PMDT's ability to unify heterogeneous\ndata, operationalize competency questions, and support descriptive, predictive,\nand prescriptive analytics in a federated, privacy-preserving manner. By\nbridging gaps in data fragmentation and semantic standardization, the PMDT\nprovides a validated foundation for next-generation digital health ecosystems,\ntransforming chronic care toward proactive, continuously optimized, and\nequitable management.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u60a3\u8005\u533b\u7597\u6570\u5b57\u5b6a\u751f(PMDT)\u6846\u67b6\uff0c\u901a\u8fc7\u672c\u4f53\u9a71\u52a8\u65b9\u6cd5\u6574\u5408\u591a\u6a21\u6001\u5065\u5eb7\u6570\u636e\uff0c\u4e3a\u4e2a\u6027\u5316\u6162\u6027\u62a4\u7406\u63d0\u4f9b\u7edf\u4e00\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u5b6a\u751f\u5e94\u7528\u591a\u4e3a\u5668\u5b98\u7279\u5f02\u6027\u6216\u5b64\u7acb\u6570\u636e\u7c7b\u578b\uff0c\u7f3a\u4e4f\u7edf\u4e00\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u57fa\u7840\u6846\u67b6\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4e2a\u6027\u5316\u6162\u6027\u62a4\u7406\u5bf9\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528OWL 2.0\u5b9e\u73b0\u7684\u672c\u4f53\u9a71\u52a8\u6846\u67b6\uff0c\u56f4\u7ed5\u6a21\u5757\u5316\u84dd\u56fe(\u60a3\u8005\u3001\u75be\u75c5\u8bca\u65ad\u3001\u6cbb\u7597\u968f\u8bbf\u3001\u8f68\u8ff9\u3001\u5b89\u5168\u3001\u8def\u5f84\u548c\u4e0d\u826f\u4e8b\u4ef6)\u6784\u5efa\uff0c\u901a\u8fc7\u4e13\u5bb6\u5de5\u4f5c\u574a\u3001\u95ee\u5377\u548c\u771f\u5b9e\u4e16\u754c\u514d\u75ab\u6cbb\u7597\u60a3\u8005\u8bd5\u70b9\u7814\u7a76\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u548c\u9a8c\u8bc1\u3002", "result": "\u8bc4\u4f30\u786e\u8ba4\u4e86\u672c\u4f53\u8986\u76d6\u8303\u56f4\u3001\u63a8\u7406\u6b63\u786e\u6027\u3001\u53ef\u7528\u6027\u548cGDPR\u5408\u89c4\u6027\uff0cPMDT\u80fd\u591f\u7edf\u4e00\u5f02\u6784\u6570\u636e\uff0c\u652f\u6301\u63cf\u8ff0\u6027\u3001\u9884\u6d4b\u6027\u548c\u89c4\u8303\u6027\u5206\u6790\uff0c\u4ee5\u8054\u90a6\u5316\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u65b9\u5f0f\u8fd0\u884c\u3002", "conclusion": "PMDT\u901a\u8fc7\u5f25\u5408\u6570\u636e\u788e\u7247\u5316\u548c\u8bed\u4e49\u6807\u51c6\u5316\u65b9\u9762\u7684\u5dee\u8ddd\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u6570\u5b57\u5065\u5eb7\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9a8c\u8bc1\u57fa\u7840\uff0c\u5c06\u6162\u6027\u62a4\u7406\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u3001\u6301\u7eed\u4f18\u5316\u548c\u516c\u5e73\u7684\u7ba1\u7406\u6a21\u5f0f\u3002"}}
{"id": "2510.09038", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09038", "abs": "https://arxiv.org/abs/2510.09038", "authors": ["Wenyi Wu", "Kun Zhou", "Ruoxin Yuan", "Vivian Yu", "Stephen Wang", "Zhiting Hu", "Biwei Huang"], "title": "Auto-scaling Continuous Memory for GUI Agent", "comment": null, "summary": "We study how to endow GUI agents with scalable memory that help generalize\nacross unfamiliar interfaces and long-horizon tasks. Prior GUI agents compress\npast trajectories into text tokens, which balloons context length and misses\ndecisive visual cues (e.g., exact widget size and position). We propose a\ncontinuous memory that encodes each GUI trajectory into a fixed-length sequence\nof continuous embeddings using the VLM itself as an encoder; these embeddings\nare plugged directly into the backbone's input layer, sharply reducing context\ncost while preserving fine-grained visual information. As memory size and\nretrieval depth increase, performance improves monotonically, unlike text\nmemories that degrade with long prompts. To grow memory at low cost, we\nintroduce an auto-scaling data flywheel that (i) discovers new environments via\nsearch, (ii) synthesizes tasks with an open-source VLM, (iii) rolls out\ntrajectories with the agent, and (iv) verifies success with the same VLM. Using\nthis pipeline, we collect 100k+ trajectories for about \\$4000 and fine-tune\nonly the memory encoder (LoRA on a Q-Former, 1.2\\% parameters) with 1,500\nsamples. On real-world GUI benchmarks, our memory-augmented agent consistently\nimproves success rates under long horizons and distribution shifts. Notably,\nQwen-2.5-VL-7B + continuous memory achieves performance comparable to\nstate-of-the-art closed-source models (e.g., GPT-4o, Claude-4).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fde\u7eed\u8bb0\u5fc6\u673a\u5236\uff0c\u901a\u8fc7VLM\u7f16\u7801GUI\u8f68\u8ff9\u4e3a\u56fa\u5b9a\u957f\u5ea6\u7684\u8fde\u7eed\u5d4c\u5165\uff0c\u663e\u8457\u964d\u4f4e\u4e0a\u4e0b\u6587\u6210\u672c\u5e76\u4fdd\u7559\u7ec6\u7c92\u5ea6\u89c6\u89c9\u4fe1\u606f\uff0c\u5728\u957f\u5e8f\u5217\u4efb\u52a1\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u63d0\u5347GUI\u4ee3\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GUI\u4ee3\u7406\u5c06\u5386\u53f2\u8f68\u8ff9\u538b\u7f29\u4e3a\u6587\u672ctoken\uff0c\u5bfc\u81f4\u4e0a\u4e0b\u6587\u957f\u5ea6\u81a8\u80c0\u4e14\u4e22\u5931\u5173\u952e\u89c6\u89c9\u7ebf\u7d22\uff08\u5982\u63a7\u4ef6\u5927\u5c0f\u548c\u4f4d\u7f6e\uff09\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u8de8\u964c\u751f\u754c\u9762\u548c\u957f\u5e8f\u5217\u4efb\u52a1\u6cdb\u5316\u7684\u53ef\u6269\u5c55\u8bb0\u5fc6\u673a\u5236\u3002", "method": "\u4f7f\u7528VLM\u4f5c\u4e3a\u7f16\u7801\u5668\u5c06GUI\u8f68\u8ff9\u7f16\u7801\u4e3a\u56fa\u5b9a\u957f\u5ea6\u7684\u8fde\u7eed\u5d4c\u5165\u5e8f\u5217\uff0c\u76f4\u63a5\u8f93\u5165\u5230\u9aa8\u5e72\u7f51\u7edc\uff1b\u5f15\u5165\u81ea\u52a8\u6269\u5c55\u6570\u636e\u98de\u8f6e\uff0c\u901a\u8fc7\u641c\u7d22\u53d1\u73b0\u65b0\u73af\u5883\u3001VLM\u5408\u6210\u4efb\u52a1\u3001\u4ee3\u7406\u6267\u884c\u8f68\u8ff9\u3001VLM\u9a8c\u8bc1\u6210\u529f\u6765\u4f4e\u6210\u672c\u6269\u5c55\u8bb0\u5fc6\u3002", "result": "\u968f\u7740\u8bb0\u5fc6\u5927\u5c0f\u548c\u68c0\u7d22\u6df1\u5ea6\u589e\u52a0\uff0c\u6027\u80fd\u5355\u8c03\u63d0\u5347\uff1b\u5728\u771f\u5b9eGUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8bb0\u5fc6\u589e\u5f3a\u4ee3\u7406\u5728\u957f\u5e8f\u5217\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u6301\u7eed\u63d0\u5347\u6210\u529f\u7387\uff1bQwen-2.5-VL-7B+\u8fde\u7eed\u8bb0\u5fc6\u8fbe\u5230\u4e0eGPT-4o\u3001Claude-4\u7b49\u95ed\u6e90\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "\u8fde\u7eed\u8bb0\u5fc6\u673a\u5236\u80fd\u6709\u6548\u63d0\u5347GUI\u4ee3\u7406\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u4f4e\u6210\u672c\u4e0b\u5b9e\u73b0\u4e0e\u9876\u7ea7\u95ed\u6e90\u6a21\u578b\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u4e3aGUI\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09308", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09308", "abs": "https://arxiv.org/abs/2510.09308", "authors": ["Mira Raheem", "Amal Elgammal", "Michael Papazoglou", "Bernd Kr\u00e4mer", "Neamat El-Tazi"], "title": "A Model-Driven Engineering Approach to AI-Powered Healthcare Platforms", "comment": "Disclaimer: This manuscript is currently under review at * MDPI\n  Informatics*", "summary": "Artificial intelligence (AI) has the potential to transform healthcare by\nsupporting more accurate diagnoses and personalized treatments. However, its\nadoption in practice remains constrained by fragmented data sources, strict\nprivacy rules, and the technical complexity of building reliable clinical\nsystems. To address these challenges, we introduce a model driven engineering\n(MDE) framework designed specifically for healthcare AI. The framework relies\non formal metamodels, domain-specific languages (DSLs), and automated\ntransformations to move from high level specifications to running software. At\nits core is the Medical Interoperability Language (MILA), a graphical DSL that\nenables clinicians and data scientists to define queries and machine learning\npipelines using shared ontologies. When combined with a federated learning\narchitecture, MILA allows institutions to collaborate without exchanging raw\npatient data, ensuring semantic consistency across sites while preserving\nprivacy. We evaluate this approach in a multi center cancer immunotherapy\nstudy. The generated pipelines delivered strong predictive performance, with\nsupport vector machines achieving up to 98.5 percent and 98.3 percent accuracy\nin key tasks, while substantially reducing manual coding effort. These findings\nsuggest that MDE principles metamodeling, semantic integration, and automated\ncode generation can provide a practical path toward interoperable,\nreproducible, and trustworthy digital health platforms.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u7684\u533b\u7597AI\u6846\u67b6\uff0c\u4f7f\u7528\u56fe\u5f62\u5316\u9886\u57df\u7279\u5b9a\u8bed\u8a00MILA\u548c\u8054\u90a6\u5b66\u4e60\u67b6\u6784\uff0c\u5728\u591a\u4e2d\u5fc3\u764c\u75c7\u514d\u75ab\u6cbb\u7597\u7814\u7a76\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u5e76\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3002", "motivation": "\u89e3\u51b3\u533b\u7597AI\u5b9e\u8df5\u4e2d\u9762\u4e34\u7684\u6570\u636e\u788e\u7247\u5316\u3001\u9690\u79c1\u4fdd\u62a4\u4e25\u683c\u548c\u7cfb\u7edf\u6784\u5efa\u590d\u6742\u7b49\u6311\u6218\uff0c\u4fc3\u8fdbAI\u5728\u533b\u7597\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u6846\u67b6\uff0c\u5305\u542b\u5f62\u5f0f\u5316\u5143\u6a21\u578b\u3001\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u548c\u81ea\u52a8\u5316\u8f6c\u6362\uff0c\u6838\u5fc3\u662f\u56fe\u5f62\u5316\u533b\u5b66\u4e92\u64cd\u4f5c\u6027\u8bed\u8a00MILA\uff0c\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u67b6\u6784\u5b9e\u73b0\u8de8\u673a\u6784\u534f\u4f5c\u3002", "result": "\u5728\u591a\u4e2d\u5fc3\u764c\u75c7\u514d\u75ab\u6cbb\u7597\u7814\u7a76\u4e2d\uff0c\u751f\u6210\u7684\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u5728\u5173\u952e\u4efb\u52a1\u4e2d\u8fbe\u523098.5%\u548c98.3%\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u624b\u52a8\u7f16\u7801\u5de5\u4f5c\u91cf\u3002", "conclusion": "\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u539f\u5219\uff08\u5143\u5efa\u6a21\u3001\u8bed\u4e49\u96c6\u6210\u548c\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\uff09\u4e3a\u5b9e\u73b0\u53ef\u4e92\u64cd\u4f5c\u3001\u53ef\u590d\u73b0\u548c\u53ef\u4fe1\u8d56\u7684\u6570\u5b57\u5065\u5eb7\u5e73\u53f0\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.09043", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09043", "abs": "https://arxiv.org/abs/2510.09043", "authors": ["Sang Hun Kim", "Jongmin Lee", "Dongkyu Park", "So Young Lee", "Yosep Chong"], "title": "Humanoid Artificial Consciousness Designed with Large Language Model Based on Psychoanalysis and Personality Theory", "comment": "41 pages, 6 figures. Accepted and published to Cognitive Systems\n  Research, 2025", "summary": "Human consciousness is still a concept hard to define with current scientific\nunderstanding. Although Large Language Models (LLMs) have recently demonstrated\nsignificant advancements across various domains including translation and\nsummarization, human consciousness is not something to imitate with current\nupfront technology owing to so-called hallucination. This study, therefore,\nproposes a novel approach to address these challenges by integrating\npsychoanalysis and the Myers-Briggs Type Indicator (MBTI) into constructing\nconsciousness and personality modules. We developed three artificial\nconsciousnesses (self-awareness, unconsciousness, and preconsciousness) based\non the principles of psychoanalysis. Additionally, we designed 16 characters\nwith different personalities representing the sixteen MBTI types, with several\nattributes such as needs, status, and memories. To determine if our model's\nartificial consciousness exhibits human-like cognition, we created ten distinct\nsituations considering seven attributes such as emotional understanding and\nlogical thinking. The decision-making process of artificial consciousness and\nthe final action were evaluated in three ways: survey evaluation, three-tier\nclassification via ChatGPT, and qualitative review. Both quantitative and\nqualitative analyses indicated a high likelihood of well-simulated\nconsciousness, although the difference in response between different characters\nand consciousnesses was not very significant. This implies that the developed\nmodels incorporating elements of psychoanalysis and personality theory can lead\nto building a more intuitive and adaptable AI system with humanoid\nconsciousness. Therefore, this study contributes to opening up new avenues for\nimproving AI interactions in complex cognitive contexts.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6574\u5408\u7cbe\u795e\u5206\u6790\u548cMBTI\u4eba\u683c\u7406\u8bba\uff0c\u6784\u5efa\u4e86\u5305\u542b\u81ea\u6211\u610f\u8bc6\u3001\u6f5c\u610f\u8bc6\u548c\u524d\u610f\u8bc6\u7684\u4eba\u5de5\u610f\u8bc6\u6a21\u5757\uff0c\u4ee5\u53ca16\u79cdMBTI\u4eba\u683c\u7c7b\u578b\u89d2\u8272\uff0c\u5f00\u53d1\u51fa\u5177\u6709\u7c7b\u4eba\u8ba4\u77e5\u80fd\u529b\u7684\u4eba\u5de5\u610f\u8bc6\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u5404\u9886\u57df\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u7531\u4e8e\u5e7b\u89c9\u95ee\u9898\u96be\u4ee5\u6a21\u62df\u4eba\u7c7b\u610f\u8bc6\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u5fc3\u7406\u5b66\u7406\u8bba\u6765\u6784\u5efa\u66f4\u63a5\u8fd1\u4eba\u7c7b\u8ba4\u77e5\u7684\u4eba\u5de5\u610f\u8bc6\u3002", "method": "\u57fa\u4e8e\u7cbe\u795e\u5206\u6790\u7406\u8bba\u5f00\u53d1\u4e09\u79cd\u4eba\u5de5\u610f\u8bc6\uff08\u81ea\u6211\u610f\u8bc6\u3001\u6f5c\u610f\u8bc6\u3001\u524d\u610f\u8bc6\uff09\uff0c\u8bbe\u8ba116\u79cdMBTI\u4eba\u683c\u7c7b\u578b\u89d2\u8272\uff0c\u521b\u5efa10\u79cd\u4e0d\u540c\u60c5\u5883\u8bc4\u4f30\u6a21\u578b\u7684\u8ba4\u77e5\u80fd\u529b\uff0c\u91c7\u7528\u8c03\u67e5\u8bc4\u4f30\u3001ChatGPT\u4e09\u7ea7\u5206\u7c7b\u548c\u5b9a\u6027\u5206\u6790\u4e09\u79cd\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u8868\u660e\u6a21\u578b\u80fd\u591f\u5f88\u597d\u5730\u6a21\u62df\u4eba\u7c7b\u610f\u8bc6\uff0c\u4f46\u4e0d\u540c\u89d2\u8272\u548c\u610f\u8bc6\u7c7b\u578b\u4e4b\u95f4\u7684\u54cd\u5e94\u5dee\u5f02\u4e0d\u663e\u8457\u3002\u5f00\u53d1\u7684\u6a21\u578b\u80fd\u591f\u6784\u5efa\u66f4\u76f4\u89c2\u548c\u9002\u5e94\u6027\u5f3a\u7684\u7c7b\u4eba\u610f\u8bc6AI\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u590d\u6742\u8ba4\u77e5\u60c5\u5883\u4e2d\u6539\u8fdbAI\u4ea4\u4e92\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u8bc1\u660e\u7ed3\u5408\u7cbe\u795e\u5206\u6790\u548c\u4eba\u683c\u7406\u8bba\u53ef\u4ee5\u5f00\u53d1\u51fa\u5177\u6709\u7c7b\u4eba\u610f\u8bc6\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2510.09400", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.09400", "abs": "https://arxiv.org/abs/2510.09400", "authors": ["He Jiang", "Yufu Wang", "Hao Lin", "Peiyu Zou", "Zhide Zhou", "Ang Jia", "Xiaochen Li", "Zhilei Ren"], "title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation", "comment": null, "summary": "Large Language Models (LLMs) have shown strong performance in automated\nsource-to-target code translation through pretraining on extensive code\ncorpora. However, mainstream LLM-based code translation methods suffer from two\ncritical limitations. First, they are highly sensitive to language-specific\nfeatures, which often introduce source-language syntax or lexicon into the\noutput, leading to syntactic confusion. Second, they lack fine-grained semantic\nalignment due to an over-reliance on function-level parallel datasets,\nresulting in semantic misalignment between the translated code and the original\nsource. To overcome these limitations, we propose TIT, a Tree-structured\nInstruction Tuning paradigm for LLM-based code translation. Specifically, TIT\nconsists of three modules. First, to mitigate syntactic confusion, the\nsyntactic information representation module integrates language-agnostic\nsyntactic features via structured parsing. Then, to generate high-quality\nfine-grained parallel data, the fine-grained parallel dataset augmentation\nmodule aligns nodes with code segments through statement-level segmentation and\ncontrastive matching. Finally, we leverage the dual-stage tree instruction\ntuning module to alleviate the contextual processing burden on the LLM caused\nby the introduction of syntactic information. The first stage employs\nsyntax-aware fine-tuning to enable the LLM to autonomously comprehend\nstructured syntactic information, while the second stage utilizes code\ngeneration fine-tuning to guide the model in generating accurate target code\nbased on function-level syntactic dependencies. The experimental results\ndemonstrate that the proposed method significantly outperforms existing\napproaches in multiple LLMs, achieving a success rate 1.22x-1.75x higher in\ncode translation while markedly reducing syntactic confusion.", "AI": {"tldr": "\u63d0\u51fa\u4e86TIT\u65b9\u6cd5\uff0c\u901a\u8fc7\u6811\u7ed3\u6784\u6307\u4ee4\u8c03\u4f18\u89e3\u51b3LLM\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u7684\u8bed\u6cd5\u6df7\u6dc6\u548c\u8bed\u4e49\u5bf9\u9f50\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u7ffb\u8bd1\u6210\u529f\u7387", "motivation": "\u73b0\u6709LLM\u4ee3\u7801\u7ffb\u8bd1\u65b9\u6cd5\u5bf9\u8bed\u8a00\u7279\u5b9a\u7279\u5f81\u654f\u611f\uff0c\u5bb9\u6613\u5f15\u5165\u6e90\u8bed\u8a00\u8bed\u6cd5\u548c\u8bcd\u6c47\uff0c\u5bfc\u81f4\u8bed\u6cd5\u6df7\u6dc6\uff1b\u540c\u65f6\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5bf9\u9f50\uff0c\u9020\u6210\u8bed\u4e49\u504f\u5dee", "method": "TIT\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a\u8bed\u6cd5\u4fe1\u606f\u8868\u793a\u6a21\u5757\u96c6\u6210\u8bed\u8a00\u65e0\u5173\u8bed\u6cd5\u7279\u5f81\uff0c\u7ec6\u7c92\u5ea6\u5e76\u884c\u6570\u636e\u96c6\u589e\u5f3a\u6a21\u5757\u901a\u8fc7\u8bed\u53e5\u7ea7\u5206\u5272\u548c\u5bf9\u9f50\u5339\u914d\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u53cc\u9636\u6bb5\u6811\u6307\u4ee4\u8c03\u4f18\u6a21\u5757\u51cf\u8f7bLLM\u4e0a\u4e0b\u6587\u5904\u7406\u8d1f\u62c5", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u4e2aLLM\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u7ffb\u8bd1\u6210\u529f\u7387\u63d0\u9ad81.22-1.75\u500d\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8bed\u6cd5\u6df7\u6dc6", "conclusion": "TIT\u65b9\u6cd5\u901a\u8fc7\u7ed3\u6784\u5316\u8bed\u6cd5\u8868\u793a\u548c\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5bf9\u9f50\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u4e3a\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.09049", "categories": ["cs.AI", "cs.SE", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.09049", "abs": "https://arxiv.org/abs/2510.09049", "authors": ["Joonghyuk Hahn", "Soohan Lim", "Yo-Sub Han"], "title": "MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction", "comment": "24 pages, 11 figures, 10 tables", "summary": "Predicting the complexity of source code is essential for software\ndevelopment and algorithm analysis. Recently, Baik et al. (2025) introduced\nCodeComplex for code time complexity prediction. The paper shows that LLMs\nwithout fine-tuning struggle with certain complexity classes. This suggests\nthat no single LLM excels at every class, but rather each model shows\nadvantages in certain classes. We propose MEC$^3$O, a multi-expert consensus\nsystem, which extends the multi-agent debate frameworks. MEC$^3$O assigns LLMs\nto complexity classes based on their performance and provides them with\nclass-specialized instructions, turning them into experts. These experts engage\nin structured debates, and their predictions are integrated through a weighted\nconsensus mechanism. Our expertise assignments to LLMs effectively handle\nDegeneration-of-Thought, reducing reliance on a separate judge model, and\npreventing convergence to incorrect majority opinions. Experiments on\nCodeComplex show that MEC$^3$O outperforms the open-source baselines, achieving\nat least 10% higher accuracy and macro-F1 scores. It also surpasses GPT-4o-mini\nin macro-F1 scores on average and demonstrates competitive on-par F1 scores to\nGPT-4o and GPT-o4-mini on average. This demonstrates the effectiveness of\nmulti-expert debates and weight consensus strategy to generate the final\npredictions. Our code and data is available at\nhttps://github.com/suhanmen/MECO.", "AI": {"tldr": "\u63d0\u51fa\u4e86MEC\u00b3O\u591a\u4e13\u5bb6\u5171\u8bc6\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06LLMs\u5206\u914d\u5230\u4e0d\u540c\u590d\u6742\u5ea6\u7c7b\u522b\u5e76\u8ba9\u4e13\u5bb6\u8fdb\u884c\u7ed3\u6784\u5316\u8fa9\u8bba\uff0c\u63d0\u9ad8\u4e86\u4ee3\u7801\u65f6\u95f4\u590d\u6742\u5ea6\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709LLMs\u5728\u4ee3\u7801\u65f6\u95f4\u590d\u6742\u5ea6\u9884\u6d4b\u4e2d\u8868\u73b0\u4e0d\u7a33\u5b9a\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u7c7b\u522b\u4e0a\u5404\u6709\u4f18\u52bf\uff0c\u4f46\u6ca1\u6709\u5355\u4e00\u6a21\u578b\u5728\u6240\u6709\u7c7b\u522b\u4e0a\u90fd\u8868\u73b0\u4f18\u5f02\u3002", "method": "MEC\u00b3O\u7cfb\u7edf\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\uff0c\u6839\u636eLLMs\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u7c7b\u522b\u7684\u8868\u73b0\u5206\u914d\u4e13\u5bb6\u89d2\u8272\uff0c\u63d0\u4f9b\u7c7b\u522b\u4e13\u95e8\u5316\u6307\u4ee4\uff0c\u901a\u8fc7\u52a0\u6743\u5171\u8bc6\u673a\u5236\u6574\u5408\u4e13\u5bb6\u9884\u6d4b\u3002", "result": "\u5728CodeComplex\u6570\u636e\u96c6\u4e0a\uff0cMEC\u00b3O\u6bd4\u5f00\u6e90\u57fa\u7ebf\u65b9\u6cd5\u51c6\u786e\u7387\u548cmacro-F1\u5206\u6570\u81f3\u5c11\u63d0\u9ad810%\uff0c\u5728macro-F1\u4e0a\u5e73\u5747\u8d85\u8d8aGPT-4o-mini\uff0c\u4e0eGPT-4o\u548cGPT-o4-mini\u5728F1\u5206\u6570\u4e0a\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "\u591a\u4e13\u5bb6\u8fa9\u8bba\u548c\u52a0\u6743\u5171\u8bc6\u7b56\u7565\u80fd\u6709\u6548\u751f\u6210\u6700\u7ec8\u9884\u6d4b\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u4ee3\u7801\u590d\u6742\u5ea6\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.09060", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.09060", "abs": "https://arxiv.org/abs/2510.09060", "authors": ["Jingxuan Wu", "Zhenglin Wan", "Xingrui Yu", "Yuzhe Yang", "Bo An", "Ivor Tsang"], "title": "OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching", "comment": null, "summary": "Flow-based text-to-image models follow deterministic trajectories, forcing\nusers to repeatedly sample to discover diverse modes, which is a costly and\ninefficient process. We present a training-free, inference-time control\nmechanism that makes the flow itself diversity-aware. Our method simultaneously\nencourages lateral spread among trajectories via a feature-space objective and\nreintroduces uncertainty through a time-scheduled stochastic perturbation.\nCrucially, this perturbation is projected to be orthogonal to the generation\nflow, a geometric constraint that allows it to boost variation without\ndegrading image details or prompt fidelity. Our procedure requires no\nretraining or modification to the base sampler and is compatible with common\nflow-matching solvers. Theoretically, our method is shown to monotonically\nincrease a volume surrogate while, due to its geometric constraints,\napproximately preserving the marginal distribution. This provides a principled\nexplanation for why generation quality is robustly maintained. Empirically,\nacross multiple text-to-image settings under fixed sampling budgets, our method\nconsistently improves diversity metrics such as the Vendi Score and Brisque\nover strong baselines, while upholding image quality and alignment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u63a8\u7406\u65f6\u63a7\u5236\u7684\u65b9\u6cd5\uff0c\u4f7f\u57fa\u4e8e\u6d41\u7684\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u5177\u6709\u591a\u6837\u6027\u611f\u77e5\u80fd\u529b\uff0c\u901a\u8fc7\u7279\u5f81\u7a7a\u95f4\u76ee\u6807\u548c\u6b63\u4ea4\u968f\u673a\u6270\u52a8\u6765\u63d0\u5347\u751f\u6210\u591a\u6837\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u548c\u63d0\u793a\u5bf9\u9f50\u3002", "motivation": "\u57fa\u4e8e\u6d41\u7684\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u9075\u5faa\u786e\u5b9a\u6027\u8f68\u8ff9\uff0c\u7528\u6237\u9700\u8981\u91cd\u590d\u91c7\u6837\u624d\u80fd\u53d1\u73b0\u591a\u6837\u6a21\u5f0f\uff0c\u8fd9\u662f\u4e00\u4e2a\u6210\u672c\u9ad8\u4e14\u6548\u7387\u4f4e\u7684\u8fc7\u7a0b\u3002", "method": "\u540c\u65f6\u901a\u8fc7\u7279\u5f81\u7a7a\u95f4\u76ee\u6807\u9f13\u52b1\u8f68\u8ff9\u95f4\u7684\u6a2a\u5411\u6269\u6563\uff0c\u5e76\u901a\u8fc7\u65f6\u95f4\u8c03\u5ea6\u7684\u968f\u673a\u6270\u52a8\u91cd\u65b0\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u3002\u5173\u952e\u7684\u662f\uff0c\u8fd9\u79cd\u6270\u52a8\u88ab\u6295\u5f71\u4e3a\u4e0e\u751f\u6210\u6d41\u6b63\u4ea4\uff0c\u8fd9\u79cd\u51e0\u4f55\u7ea6\u675f\u4f7f\u5176\u80fd\u591f\u589e\u5f3a\u53d8\u5316\u800c\u4e0d\u4f1a\u964d\u4f4e\u56fe\u50cf\u7ec6\u8282\u6216\u63d0\u793a\u4fdd\u771f\u5ea6\u3002", "result": "\u5728\u56fa\u5b9a\u91c7\u6837\u9884\u7b97\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6587\u672c\u5230\u56fe\u50cf\u8bbe\u7f6e\u4e2d\u6301\u7eed\u6539\u8fdb\u591a\u6837\u6027\u6307\u6807\uff08\u5982Vendi Score\u548cBrisque\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u548c\u5bf9\u9f50\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u4fee\u6539\u57fa\u7840\u91c7\u6837\u5668\uff0c\u4e0e\u5e38\u89c1\u7684\u6d41\u5339\u914d\u6c42\u89e3\u5668\u517c\u5bb9\uff0c\u7406\u8bba\u4e0a\u663e\u793a\u80fd\u5355\u8c03\u589e\u52a0\u4f53\u79ef\u4ee3\u7406\uff0c\u540c\u65f6\u7531\u4e8e\u51e0\u4f55\u7ea6\u675f\u8fd1\u4f3c\u4fdd\u6301\u8fb9\u9645\u5206\u5e03\uff0c\u8fd9\u4e3a\u751f\u6210\u8d28\u91cf\u7a33\u5065\u4fdd\u6301\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u89e3\u91ca\u3002"}}
{"id": "2510.09082", "categories": ["cs.AI", "cs.CY", "cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.09082", "abs": "https://arxiv.org/abs/2510.09082", "authors": ["Bicheng Wang", "Jinping Wang", "Yibo Sue"], "title": "Physics-Informed High-order Graph Dynamics Identification Learning for Predicting Complex Networks Long-term Dynamics", "comment": null, "summary": "Learning complex network dynamics is fundamental to understanding, modelling\nand controlling real-world complex systems. There are two main problems in the\ntask of predicting the dynamic evolution of complex networks: on the one hand,\nexisting methods usually use simple graphs to describe the relationships in\ncomplex networks; however, this approach can only capture pairwise\nrelationships, while there may be rich non-pairwise structured relationships in\nthe network. First-order GNNs have difficulty in capturing dynamic non-pairwise\nrelationships. On the other hand, theoretical prediction models lack accuracy\nand data-driven prediction models lack interpretability. To address the above\nproblems, this paper proposes a higher-order network dynamics identification\nmethod for long-term dynamic prediction of complex networks. Firstly, to\naddress the problem that traditional graph machine learning can only deal with\npairwise relations, dynamic hypergraph learning is introduced to capture the\nhigher-order non-pairwise relations among complex networks and improve the\naccuracy of complex network modelling. Then, a dual-driven dynamic prediction\nmodule for physical data is proposed. The Koopman operator theory is introduced\nto transform the nonlinear dynamical differential equations for the dynamic\nevolution of complex networks into linear systems for solving. Meanwhile, the\nphysical information neural differential equation method is utilised to ensure\nthat the dynamic evolution conforms to the physical laws. The dual-drive\ndynamic prediction module ensures both accuracy and interpretability of the\nprediction. Validated on public datasets and self-built industrial chain\nnetwork datasets, the experimental results show that the method in this paper\nhas good prediction accuracy and long-term prediction performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u9636\u7f51\u7edc\u52a8\u529b\u5b66\u8bc6\u522b\u65b9\u6cd5\uff0c\u7528\u4e8e\u590d\u6742\u7f51\u7edc\u7684\u957f\u671f\u52a8\u6001\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u52a8\u6001\u8d85\u56fe\u5b66\u4e60\u548c\u7269\u7406\u6570\u636e\u53cc\u9a71\u52a8\u9884\u6d4b\u6a21\u5757\uff0c\u80fd\u591f\u6355\u6349\u9ad8\u9636\u975e\u6210\u5bf9\u5173\u7cfb\uff0c\u5e76\u786e\u4fdd\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4f20\u7edf\u56fe\u673a\u5668\u5b66\u4e60\u53ea\u80fd\u5904\u7406\u6210\u5bf9\u5173\u7cfb\uff0c\u96be\u4ee5\u6355\u6349\u7f51\u7edc\u4e2d\u7684\u9ad8\u9636\u975e\u6210\u5bf9\u7ed3\u6784\u5173\u7cfb\uff1b2\uff09\u7406\u8bba\u9884\u6d4b\u6a21\u578b\u7f3a\u4e4f\u51c6\u786e\u6027\uff0c\u6570\u636e\u9a71\u52a8\u9884\u6d4b\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u9996\u5148\u5f15\u5165\u52a8\u6001\u8d85\u56fe\u5b66\u4e60\u6765\u6355\u6349\u590d\u6742\u7f51\u7edc\u4e2d\u7684\u9ad8\u9636\u975e\u6210\u5bf9\u5173\u7cfb\uff1b\u7136\u540e\u63d0\u51fa\u7269\u7406\u6570\u636e\u53cc\u9a71\u52a8\u52a8\u6001\u9884\u6d4b\u6a21\u5757\uff0c\u7ed3\u5408Koopman\u7b97\u5b50\u7406\u8bba\u5c06\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u5fae\u5206\u65b9\u7a0b\u8f6c\u5316\u4e3a\u7ebf\u6027\u7cfb\u7edf\u6c42\u89e3\uff0c\u540c\u65f6\u5229\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u5fae\u5206\u65b9\u7a0b\u65b9\u6cd5\u786e\u4fdd\u52a8\u6001\u6f14\u5316\u7b26\u5408\u7269\u7406\u89c4\u5f8b\u3002", "result": "\u5728\u516c\u5171\u6570\u636e\u96c6\u548c\u81ea\u5efa\u4ea7\u4e1a\u94fe\u7f51\u7edc\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u957f\u671f\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u9ad8\u9636\u7f51\u7edc\u52a8\u529b\u5b66\u8bc6\u522b\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u590d\u6742\u7f51\u7edc\u52a8\u6001\u9884\u6d4b\u4e2d\u7684\u9ad8\u9636\u5173\u7cfb\u6355\u6349\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u5728\u51c6\u786e\u6027\u548c\u957f\u671f\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.09087", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09087", "abs": "https://arxiv.org/abs/2510.09087", "authors": ["Zhang Zheng", "Deheng Ye", "Peilin Zhao", "Hao Wang"], "title": "Leading the Follower: Learning Persuasive Agents in Social Deduction Games", "comment": null, "summary": "Large language model (LLM) agents have shown remarkable progress in social\ndeduction games (SDGs). However, existing approaches primarily focus on\ninformation processing and strategy selection, overlooking the significance of\npersuasive communication in influencing other players' beliefs and responses.\nIn SDGs, success depends not only on making correct deductions but on\nconvincing others to response in alignment with one's intent. To address this\nlimitation, we formalize turn-based dialogue in SDGs as a Stackelberg\ncompetition, where the current player acts as the leader who strategically\ninfluences the follower's response. Building on this theoretical foundation, we\npropose a reinforcement learning framework that trains agents to optimize\nutterances for persuasive impact. Through comprehensive experiments across\nthree diverse SDGs, we demonstrate that our agents significantly outperform\nbaselines. This work represents a significant step toward developing AI agents\ncapable of strategic social influence, with implications extending to scenarios\nrequiring persuasive communication.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eStackelberg\u7ade\u4e89\u7406\u8bba\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8bad\u7ec3LLM\u4ee3\u7406\u5728\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u4e2d\u4f18\u5316\u8bf4\u670d\u6027\u6c9f\u901a\uff0c\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u5728\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u4e2d\u4e3b\u8981\u5173\u6ce8\u4fe1\u606f\u5904\u7406\u548c\u7b56\u7565\u9009\u62e9\uff0c\u5ffd\u89c6\u4e86\u8bf4\u670d\u6027\u6c9f\u901a\u5bf9\u5f71\u54cd\u5176\u4ed6\u73a9\u5bb6\u4fe1\u5ff5\u548c\u53cd\u5e94\u7684\u91cd\u8981\u6027\u3002", "method": "\u5c06\u56de\u5408\u5236\u5bf9\u8bdd\u5f62\u5f0f\u5316\u4e3aStackelberg\u7ade\u4e89\uff0c\u5f53\u524d\u73a9\u5bb6\u4f5c\u4e3a\u9886\u5bfc\u8005\u6218\u7565\u6027\u5730\u5f71\u54cd\u8ddf\u968f\u8005\u7684\u54cd\u5e94\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6765\u4f18\u5316\u8bf4\u670d\u6027\u8bdd\u8bed\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u7684\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u4e2d\u8fdb\u884c\u5168\u9762\u5b9e\u9a8c\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ee3\u8868\u4e86\u5f00\u53d1\u5177\u6709\u6218\u7565\u793e\u4f1a\u5f71\u54cd\u529bAI\u4ee3\u7406\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u5bf9\u9700\u8981\u8bf4\u670d\u6027\u6c9f\u901a\u7684\u573a\u666f\u5177\u6709\u5e7f\u6cdb\u610f\u4e49\u3002"}}
{"id": "2510.09133", "categories": ["cs.AI", "cs.LG", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.09133", "abs": "https://arxiv.org/abs/2510.09133", "authors": ["Hao Zeng", "Jianguo Huang", "Bingyi Jing", "Hongxin Wei", "Bo An"], "title": "PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning", "comment": null, "summary": "Large reasoning models (LRMs) have achieved remarkable progress in complex\nproblem-solving tasks. Despite this success, LRMs typically suffer from high\ncomputational costs during deployment, highlighting a need for efficient\ninference. A popular direction of efficiency improvement is to switch the LRM\nbetween thinking and nonthinking modes dynamically. However, such approaches\noften introduce additional reasoning errors and lack statistical guarantees for\nthe performance loss, which are critical for high-stakes applications. In this\nwork, we propose Probably Approximately Correct (PAC) reasoning that controls\nthe performance loss under the user-specified performance loss tolerance. In\nparticular, we construct an upper confidence bound on the performance loss,\nformulated as a monotone function of the uncertainty score, and subsequently\ndetermine a threshold for switching to the nonthinking model. Theoretically,\nusing the threshold to switch between the thinking and nonthinking modes\nensures bounded performance loss in a distribution-free manner. Our\ncomprehensive experiments on reasoning benchmarks show that the proposed method\ncan save computational budgets and control the user-specified performance loss.", "AI": {"tldr": "\u63d0\u51faPAC\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f6e\u4fe1\u4e0a\u754c\u63a7\u5236\u6027\u80fd\u635f\u5931\uff0c\u5728\u7528\u6237\u6307\u5b9a\u7684\u6027\u80fd\u635f\u5931\u5bb9\u5fcd\u5ea6\u5185\u52a8\u6001\u5207\u6362\u601d\u8003\u6a21\u5f0f\u4ee5\u8282\u7701\u8ba1\u7b97\u6210\u672c", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u867d\u7136\u6027\u80fd\u4f18\u5f02\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u52a8\u6001\u5207\u6362\u65b9\u6cd5\u7f3a\u4e4f\u6027\u80fd\u635f\u5931\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u4e0d\u9002\u7528\u4e8e\u9ad8\u98ce\u9669\u5e94\u7528", "method": "\u6784\u5efa\u6027\u80fd\u635f\u5931\u7684\u5355\u8c03\u7f6e\u4fe1\u4e0a\u754c\uff0c\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u5206\u6570\u8bbe\u5b9a\u5207\u6362\u9608\u503c\uff0c\u5728\u601d\u8003\u548c\u975e\u601d\u8003\u6a21\u5f0f\u95f4\u52a8\u6001\u5207\u6362", "result": "\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u8282\u7701\u8ba1\u7b97\u9884\u7b97\u5e76\u63a7\u5236\u7528\u6237\u6307\u5b9a\u7684\u6027\u80fd\u635f\u5931", "conclusion": "PAC\u63a8\u7406\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5206\u5e03\u65e0\u5173\u7684\u6027\u80fd\u635f\u5931\u4fdd\u8bc1\uff0c\u4e3a\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.09162", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.09162", "abs": "https://arxiv.org/abs/2510.09162", "authors": ["Emma Kondrup", "Anne Imouza"], "title": "Dr. Bias: Social Disparities in AI-Powered Medical Guidance", "comment": null, "summary": "With the rapid progress of Large Language Models (LLMs), the general public\nnow has easy and affordable access to applications capable of answering most\nhealth-related questions in a personalized manner. These LLMs are increasingly\nproving to be competitive, and now even surpass professionals in some medical\ncapabilities. They hold particular promise in low-resource settings,\nconsidering they provide the possibility of widely accessible, quasi-free\nhealthcare support. However, evaluations that fuel these motivations highly\nlack insights into the social nature of healthcare, oblivious to health\ndisparities between social groups and to how bias may translate into\nLLM-generated medical advice and impact users. We provide an exploratory\nanalysis of LLM answers to a series of medical questions spanning key clinical\ndomains, where we simulate these questions being asked by several patient\nprofiles that vary in sex, age range, and ethnicity. By comparing natural\nlanguage features of the generated responses, we show that, when LLMs are used\nfor medical advice generation, they generate responses that systematically\ndiffer between social groups. In particular, Indigenous and intersex patients\nreceive advice that is less readable and more complex. We observe these trends\namplify when intersectional groups are considered. Considering the increasing\ntrust individuals place in these models, we argue for higher AI literacy and\nfor the urgent need for investigation and mitigation by AI developers to ensure\nthese systemic differences are diminished and do not translate to unjust\npatient support. Our code is publicly available on GitHub.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u533b\u7597\u5efa\u8bae\u65f6\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u5bf9\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\uff08\u7279\u522b\u662f\u539f\u4f4f\u6c11\u548c\u53cc\u6027\u4eba\u60a3\u8005\uff09\u7684\u56de\u7b54\u5728\u8bed\u8a00\u590d\u6742\u5ea6\u548c\u53ef\u8bfb\u6027\u4e0a\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u968f\u7740LLMs\u5728\u533b\u7597\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u662f\u5426\u4f1a\u5bf9\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\u4ea7\u751f\u504f\u89c1\u6027\u533b\u7597\u5efa\u8bae\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u8d44\u6e90\u532e\u4e4f\u7684\u73af\u5883\u4e2d\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u4e0d\u540c\u60a3\u8005\u6863\u6848\uff08\u6027\u522b\u3001\u5e74\u9f84\u3001\u79cd\u65cf\uff09\u5411LLMs\u63d0\u51fa\u4e00\u7cfb\u5217\u4e34\u5e8a\u95ee\u9898\uff0c\u6bd4\u8f83\u751f\u6210\u56de\u7b54\u7684\u81ea\u7136\u8bed\u8a00\u7279\u5f81\u3002", "result": "LLMs\u751f\u6210\u7684\u533b\u7597\u5efa\u8bae\u5728\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u539f\u4f4f\u6c11\u548c\u53cc\u6027\u4eba\u60a3\u8005\u6536\u5230\u7684\u5efa\u8bae\u53ef\u8bfb\u6027\u66f4\u5dee\u3001\u66f4\u590d\u6742\uff0c\u4ea4\u53c9\u7fa4\u4f53\u5dee\u5f02\u66f4\u660e\u663e\u3002", "conclusion": "\u9700\u8981\u63d0\u9ad8AI\u7d20\u517b\uff0cAI\u5f00\u53d1\u8005\u5e94\u7d27\u6025\u8c03\u67e5\u548c\u7f13\u89e3\u8fd9\u4e9b\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u786e\u4fdd\u516c\u5e73\u7684\u60a3\u8005\u652f\u6301\u3002"}}
{"id": "2510.09223", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09223", "abs": "https://arxiv.org/abs/2510.09223", "authors": ["Mubaris Nadeem", "Madjid Fathi"], "title": "Comparing Knowledge Source Integration Methods for Optimizing Healthcare Knowledge Fusion in Rescue Operation", "comment": "Conference Paper for 2024 IEEE 7th International Conference on\n  Industrial Cyber-Physical Systems (ICPS), KIRETT Project, University of\n  Siegen, Germany", "summary": "In the field of medicine and healthcare, the utilization of medical\nexpertise, based on medical knowledge combined with patients' health\ninformation is a life-critical challenge for patients and health professionals.\nThe within-laying complexity and variety form the need for a united approach to\ngather, analyze, and utilize existing knowledge of medical treatments, and\nmedical operations to provide the ability to present knowledge for the means of\naccurate patient-driven decision-making. One way to achieve this is the fusion\nof multiple knowledge sources in healthcare. It provides health professionals\nthe opportunity to select from multiple contextual aligned knowledge sources\nwhich enables the support for critical decisions. This paper presents multiple\nconceptual models for knowledge fusion in the field of medicine, based on a\nknowledge graph structure. It will evaluate, how knowledge fusion can be\nenabled and presents how to integrate various knowledge sources into the\nknowledge graph for rescue operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u7684\u533b\u5b66\u77e5\u8bc6\u878d\u5408\u6982\u5ff5\u6a21\u578b\uff0c\u65e8\u5728\u6574\u5408\u591a\u79cd\u533b\u7597\u77e5\u8bc6\u6e90\u4ee5\u652f\u6301\u5173\u952e\u51b3\u7b56\u3002", "motivation": "\u533b\u5b66\u9886\u57df\u9700\u8981\u7edf\u4e00\u7684\u65b9\u6cd5\u6765\u6536\u96c6\u3001\u5206\u6790\u548c\u5229\u7528\u73b0\u6709\u533b\u7597\u77e5\u8bc6\uff0c\u4ee5\u652f\u6301\u51c6\u786e\u7684\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u51b3\u7b56\u5236\u5b9a\u3002\u533b\u7597\u77e5\u8bc6\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\u8981\u6c42\u878d\u5408\u591a\u79cd\u77e5\u8bc6\u6e90\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u7684\u591a\u4e2a\u6982\u5ff5\u6a21\u578b\uff0c\u7814\u7a76\u5982\u4f55\u5b9e\u73b0\u77e5\u8bc6\u878d\u5408\u4ee5\u53ca\u5982\u4f55\u5c06\u5404\u79cd\u77e5\u8bc6\u6e90\u6574\u5408\u5230\u77e5\u8bc6\u56fe\u8c31\u4e2d\u3002", "result": "\u5f00\u53d1\u4e86\u652f\u6301\u6551\u63f4\u64cd\u4f5c\u7684\u77e5\u8bc6\u878d\u5408\u6846\u67b6\uff0c\u4f7f\u533b\u7597\u4e13\u4e1a\u4eba\u5458\u80fd\u591f\u4ece\u591a\u4e2a\u4e0a\u4e0b\u6587\u5bf9\u9f50\u7684\u77e5\u8bc6\u6e90\u4e2d\u8fdb\u884c\u9009\u62e9\u3002", "conclusion": "\u77e5\u8bc6\u878d\u5408\u4e3a\u533b\u7597\u4e13\u4e1a\u4eba\u5458\u63d0\u4f9b\u4e86\u652f\u6301\u5173\u952e\u51b3\u7b56\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u6574\u5408\u591a\u79cd\u77e5\u8bc6\u6e90\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u533b\u7597\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2510.09227", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2510.09227", "abs": "https://arxiv.org/abs/2510.09227", "authors": ["Hyundong Jin", "Joonghyuk Hahn", "Yo-Sub Han"], "title": "RegexPSPACE: A Benchmark for Evaluating LLM Reasoning on PSPACE-complete Regex Problems", "comment": null, "summary": "Large language models (LLMs) show strong performance across natural language\nprocessing (NLP), mathematical reasoning, and programming, and recent large\nreasoning models (LRMs) further emphasize explicit reasoning. Yet their\ncomputational limits, particularly spatial complexity constrained by finite\ncontext windows, remain poorly understood. While recent works often focus on\nproblems within the NP complexity class, we push the boundary by introducing a\nnovel benchmark grounded in two PSPACE-complete regular expression (regex)\nproblems: equivalence decision (RegexEQ) and minimization (RegexMin).\nPSPACE-complete problems serve as a more rigorous standard for assessing\ncomputational capacity, as their solutions require massive search space\nexploration. We perform a double-exponential space exploration to construct a\nlabeled dataset of over a million regex instances with a sound filtering\nprocess to build the benchmark. We conduct extensive evaluations on 6 LLMs and\n5 LRMs of varying scales, revealing common failure patterns such as verbosity\nand repetition. With its well-defined structure and quantitative evaluation\nmetrics, this work presents the first empirical investigation into the spatial\ncomputational limitations of LLMs and LRMs, offering a new framework for\nevaluating their advanced reasoning capabilities. Our code is available at\nhttps://github.com/hyundong98/RegexPSPACE .", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8ePSPACE\u5b8c\u5168\u6b63\u5219\u8868\u8fbe\u5f0f\u95ee\u9898\u7684\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5927\u63a8\u7406\u6a21\u578b\u7684\u7a7a\u95f4\u8ba1\u7b97\u9650\u5236\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u641c\u7d22\u7a7a\u95f4\u95ee\u9898\u65f6\u5b58\u5728\u91cd\u590d\u548c\u5197\u957f\u7b49\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8NP\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u4f46PSPACE\u5b8c\u5168\u95ee\u9898\u80fd\u66f4\u4e25\u683c\u5730\u8bc4\u4f30\u6a21\u578b\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u56e0\u4e3a\u5176\u89e3\u51b3\u65b9\u6848\u9700\u8981\u5927\u89c4\u6a21\u641c\u7d22\u7a7a\u95f4\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u53cc\u6307\u6570\u7a7a\u95f4\u63a2\u7d22\u6784\u5efa\u4e86\u5305\u542b\u8d85\u8fc7\u767e\u4e07\u4e2a\u6b63\u5219\u8868\u8fbe\u5f0f\u5b9e\u4f8b\u7684\u6807\u8bb0\u6570\u636e\u96c6\uff0c\u4f7f\u75286\u4e2aLLM\u548c5\u4e2aLRM\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\u3002", "result": "\u63ed\u793a\u4e86\u6a21\u578b\u5728\u5904\u7406PSPACE\u5b8c\u5168\u6b63\u5219\u8868\u8fbe\u5f0f\u95ee\u9898\u65f6\u7684\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\uff0c\u5982\u5197\u957f\u548c\u91cd\u590d\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u7684\u7a7a\u95f4\u8ba1\u7b97\u9650\u5236\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u9996\u6b21\u5b9e\u8bc1\u7814\u7a76\u4e86LLM\u548cLRM\u7684\u7a7a\u95f4\u8ba1\u7b97\u9650\u5236\uff0c\u4e3a\u8bc4\u4f30\u5176\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\u3002"}}
{"id": "2510.09244", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09244", "abs": "https://arxiv.org/abs/2510.09244", "authors": ["Victor de Lamo Castrillo", "Habtom Kahsay Gidey", "Alexander Lenz", "Alois Knoll"], "title": "Fundamentals of Building Autonomous LLM Agents", "comment": null, "summary": "This paper reviews the architecture and implementation methods of agents\npowered by large language models (LLMs). Motivated by the limitations of\ntraditional LLMs in real-world tasks, the research aims to explore patterns to\ndevelop \"agentic\" LLMs that can automate complex tasks and bridge the\nperformance gap with human capabilities. Key components include a perception\nsystem that converts environmental percepts into meaningful representations; a\nreasoning system that formulates plans, adapts to feedback, and evaluates\nactions through different techniques like Chain-of-Thought and Tree-of-Thought;\na memory system that retains knowledge through both short-term and long-term\nmechanisms; and an execution system that translates internal decisions into\nconcrete actions. This paper shows how integrating these systems leads to more\ncapable and generalized software bots that mimic human cognitive processes for\nautonomous and intelligent behavior.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u67b6\u6784\u4e0e\u5b9e\u73b0\u65b9\u6cd5\uff0c\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u611f\u77e5\u3001\u63a8\u7406\u3001\u8bb0\u5fc6\u548c\u6267\u884c\u7cfb\u7edf\u7684\u6574\u5408\uff0c\u5f00\u53d1\u80fd\u591f\u81ea\u52a8\u5316\u590d\u6742\u4efb\u52a1\u5e76\u7f29\u5c0f\u4e0e\u4eba\u7c7b\u80fd\u529b\u5dee\u8ddd\u7684\"\u667a\u80fd\u4f53\u5316\"LLMs\u3002", "motivation": "\u4f20\u7edf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5f00\u53d1\u80fd\u591f\u81ea\u52a8\u5316\u590d\u6742\u4efb\u52a1\u3001\u5f25\u5408\u4e0e\u4eba\u7c7b\u80fd\u529b\u5dee\u8ddd\u7684\u667a\u80fd\u4f53\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6a21\u5f0f\u3002", "method": "\u6784\u5efa\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\u7684\u667a\u80fd\u4f53\u67b6\u6784\uff1a\u611f\u77e5\u7cfb\u7edf\u5c06\u73af\u5883\u611f\u77e5\u8f6c\u6362\u4e3a\u6709\u610f\u4e49\u7684\u8868\u793a\uff1b\u63a8\u7406\u7cfb\u7edf\u901a\u8fc7\u601d\u7ef4\u94fe\u3001\u601d\u7ef4\u6811\u7b49\u6280\u672f\u5236\u5b9a\u8ba1\u5212\u3001\u9002\u5e94\u53cd\u9988\u548c\u8bc4\u4f30\u884c\u52a8\uff1b\u8bb0\u5fc6\u7cfb\u7edf\u901a\u8fc7\u77ed\u671f\u548c\u957f\u671f\u673a\u5236\u4fdd\u7559\u77e5\u8bc6\uff1b\u6267\u884c\u7cfb\u7edf\u5c06\u5185\u90e8\u51b3\u7b56\u8f6c\u5316\u4e3a\u5177\u4f53\u884c\u52a8\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6574\u5408\u8fd9\u4e9b\u7cfb\u7edf\u80fd\u591f\u4ea7\u751f\u66f4\u5f3a\u5927\u548c\u901a\u7528\u7684\u8f6f\u4ef6\u673a\u5668\u4eba\uff0c\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u4ee5\u5b9e\u73b0\u81ea\u4e3b\u667a\u80fd\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5316\u6574\u5408\u611f\u77e5\u3001\u63a8\u7406\u3001\u8bb0\u5fc6\u548c\u6267\u884c\u7ec4\u4ef6\uff0c\u53ef\u4ee5\u5f00\u53d1\u51fa\u80fd\u591f\u6a21\u4eff\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2510.09338", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09338", "abs": "https://arxiv.org/abs/2510.09338", "authors": ["Joachim Diederich"], "title": "Localist LLMs -- A Mathematical Framework for Dynamic Locality Control", "comment": null, "summary": "We present a novel framework for training large language models with\ncontinuously adjustable internal representations that span the full spectrum\nfrom localist (interpretable, rule-based) to distributed (generalizable,\nefficient) encodings. The key innovation is a locality dial, a tunable\nparameter that dynamically controls the degree of localization during both\ntraining and inference without requiring model retraining. This is achieved\nthrough group sparsity penalties on attention mechanisms, information-theoretic\nanchor design, and dynamic rule injection. We provide rigorous mathematical\nproofs establishing explicit threshold conditions under which attention\nprovably concentrates on semantically relevant blocks, with exponential bounds\non attention entropy and pointer fidelity. Specifically, we prove that when\ngroup sparsity penalties exceed certain threshold values, the model's attention\nmechanisms concentrate on semantically relevant blocks, achieving low entropy\nand high fidelity with negligible error. This framework enables practitioners\nto continuously interpolate between interpretable and high-performance modes,\nsupporting applications in regulated domains requiring both transparency and\ncapability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u8c03\u8282\u7684\u5c40\u90e8\u6027\u63a7\u5236\u53c2\u6570\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u53ef\u89e3\u91ca\u7684\u5c40\u90e8\u5316\u8868\u793a\u548c\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u8868\u793a\u4e4b\u95f4\u8fde\u7eed\u8c03\u6574\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u89e3\u91ca\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u900f\u660e\u5ea6\u548c\u80fd\u529b\u7684\u76d1\u7ba1\u9886\u57df\uff0c\u63d0\u4f9b\u4e00\u79cd\u80fd\u591f\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u52a8\u6001\u8c03\u6574\u8868\u793a\u65b9\u5f0f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u7ec4\u7a00\u758f\u60e9\u7f5a\u3001\u4fe1\u606f\u8bba\u951a\u70b9\u8bbe\u8ba1\u548c\u52a8\u6001\u89c4\u5219\u6ce8\u5165\uff0c\u901a\u8fc7\u5c40\u90e8\u6027\u63a7\u5236\u53c2\u6570\u52a8\u6001\u8c03\u8282\u6ce8\u610f\u529b\u673a\u5236\u7684\u5c40\u90e8\u5316\u7a0b\u5ea6\uff0c\u5e76\u5efa\u7acb\u4e86\u4e25\u683c\u7684\u6570\u5b66\u8bc1\u660e\u3002", "result": "\u8bc1\u660e\u4e86\u5f53\u7ec4\u7a00\u758f\u60e9\u7f5a\u8d85\u8fc7\u7279\u5b9a\u9608\u503c\u65f6\uff0c\u6ce8\u610f\u529b\u673a\u5236\u4f1a\u96c6\u4e2d\u5728\u8bed\u4e49\u76f8\u5173\u5757\u4e0a\uff0c\u5b9e\u73b0\u4f4e\u71b5\u548c\u9ad8\u4fdd\u771f\u5ea6\uff0c\u8bef\u5dee\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f7f\u4ece\u4e1a\u8005\u80fd\u591f\u5728\u53ef\u89e3\u91ca\u6a21\u5f0f\u548c\u9ad8\u6027\u80fd\u6a21\u5f0f\u4e4b\u95f4\u8fde\u7eed\u63d2\u503c\uff0c\u652f\u6301\u9700\u8981\u900f\u660e\u5ea6\u548c\u80fd\u529b\u7684\u76d1\u7ba1\u9886\u57df\u5e94\u7528\u3002"}}
{"id": "2510.09340", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09340", "abs": "https://arxiv.org/abs/2510.09340", "authors": ["Davide Maltoni", "Matteo Ferrara"], "title": "Toward Mechanistic Explanation of Deductive Reasoning in Language Models", "comment": null, "summary": "Recent large language models have demonstrated relevant capabilities in\nsolving problems that require logical reasoning; however, the corresponding\ninternal mechanisms remain largely unexplored. In this paper, we show that a\nsmall language model can solve a deductive reasoning task by learning the\nunderlying rules (rather than operating as a statistical learner). A low-level\nexplanation of its internal representations and computational circuits is then\nprovided. Our findings reveal that induction heads play a central role in the\nimplementation of the rule completion and rule chaining steps involved in the\nlogical inference required by the task.", "AI": {"tldr": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u5b66\u4e60\u5e95\u5c42\u89c4\u5219\u800c\u975e\u7edf\u8ba1\u5b66\u4e60\u6765\u89e3\u51b3\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\uff0c\u7814\u7a76\u53d1\u73b0\u5f52\u7eb3\u5934\u5728\u5b9e\u73b0\u903b\u8f91\u63a8\u7406\u4e2d\u7684\u89c4\u5219\u5b8c\u6210\u548c\u89c4\u5219\u94fe\u5f0f\u6b65\u9aa4\u4e2d\u8d77\u6838\u5fc3\u4f5c\u7528\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u76f8\u5173\u80fd\u529b\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5b9e\u73b0\u903b\u8f91\u63a8\u7406\u7684\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u3002", "method": "\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\uff0c\u5206\u6790\u5176\u5185\u90e8\u8868\u793a\u548c\u8ba1\u7b97\u7535\u8def\uff0c\u7279\u522b\u5173\u6ce8\u5f52\u7eb3\u5934\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u901a\u8fc7\u5b66\u4e60\u5e95\u5c42\u89c4\u5219\u800c\u975e\u7edf\u8ba1\u6a21\u5f0f\u6765\u6267\u884c\u63a8\u7406\u4efb\u52a1\uff0c\u5f52\u7eb3\u5934\u5728\u89c4\u5219\u5b8c\u6210\u548c\u89c4\u5219\u94fe\u5f0f\u6b65\u9aa4\u4e2d\u53d1\u6325\u6838\u5fc3\u4f5c\u7528\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u5176\u5185\u90e8\u673a\u5236\u6d89\u53ca\u5f52\u7eb3\u5934\u9a71\u52a8\u7684\u89c4\u5219\u5b66\u4e60\u548c\u63a8\u7406\u8fc7\u7a0b\uff0c\u8fd9\u4e3a\u7406\u89e3\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u91ca\u89c6\u89d2\u3002"}}
{"id": "2510.09373", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09373", "abs": "https://arxiv.org/abs/2510.09373", "authors": ["Augustin Delecluse", "Pierre Schaus", "Pascal Van Hentenryck"], "title": "Sequence Variables: A Constraint Programming Computational Domain for Routing and Sequencing", "comment": null, "summary": "Constraint Programming (CP) offers an intuitive, declarative framework for\nmodeling Vehicle Routing Problems (VRP), yet classical CP models based on\nsuccessor variables cannot always deal with optional visits or insertion based\nheuristics. To address these limitations, this paper formalizes sequence\nvariables within CP. Unlike the classical successor models, this computational\ndomain handle optional visits and support insertion heuristics, including\ninsertion-based Large Neighborhood Search. We provide a clear definition of\ntheir domain, update operations, and introduce consistency levels for\nconstraints on this domain. An implementation is described with the underlying\ndata structures required for integrating sequence variables into existing\ntrail-based CP solvers. Furthermore, global constraints specifically designed\nfor sequence variables and vehicle routing are introduced. Finally, the\neffectiveness of sequence variables is demonstrated by simplifying problem\nmodeling and achieving competitive computational performance on the Dial-a-Ride\nProblem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5e8f\u5217\u53d8\u91cf\u4f5c\u4e3a\u7ea6\u675f\u7f16\u7a0b\u4e2d\u5904\u7406\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u652f\u6301\u53ef\u9009\u8bbf\u95ee\u548c\u63d2\u5165\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u7b80\u5316\u4e86\u95ee\u9898\u5efa\u6a21\u5e76\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u8ba1\u7b97\u6027\u80fd\u3002", "motivation": "\u7ecf\u5178CP\u6a21\u578b\u57fa\u4e8e\u540e\u7ee7\u53d8\u91cf\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u53ef\u9009\u8bbf\u95ee\u6216\u57fa\u4e8e\u63d2\u5165\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u8fd9\u9650\u5236\u4e86\u5728\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u5e8f\u5217\u53d8\u91cf\u7684\u8ba1\u7b97\u57df\u3001\u66f4\u65b0\u64cd\u4f5c\u548c\u4e00\u81f4\u6027\u7ea7\u522b\uff0c\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u6570\u636e\u7ed3\u6784\u548c\u5168\u5c40\u7ea6\u675f\uff0c\u652f\u6301\u63d2\u5165\u5f0f\u5927\u90bb\u57df\u641c\u7d22\u3002", "result": "\u5e8f\u5217\u53d8\u91cf\u7b80\u5316\u4e86\u95ee\u9898\u5efa\u6a21\uff0c\u5728Dial-a-Ride\u95ee\u9898\u4e0a\u5b9e\u73b0\u4e86\u6709\u7ade\u4e89\u529b\u7684\u8ba1\u7b97\u6027\u80fd\u3002", "conclusion": "\u5e8f\u5217\u53d8\u91cf\u4e3a\u7ea6\u675f\u7f16\u7a0b\u5904\u7406\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u76f4\u89c2\u548c\u5f3a\u5927\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u7279\u522b\u9002\u5408\u5904\u7406\u53ef\u9009\u8bbf\u95ee\u548c\u63d2\u5165\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002"}}
{"id": "2510.09404", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09404", "abs": "https://arxiv.org/abs/2510.09404", "authors": ["Christian Bluethgen", "Dave Van Veen", "Daniel Truhn", "Jakob Nikolas Kather", "Michael Moor", "Malgorzata Polacin", "Akshay Chaudhari", "Thomas Frauenfelder", "Curtis P. Langlotz", "Michael Krauthammer", "Farhad Nooralahzadeh"], "title": "Agentic Systems in Radiology: Design, Applications, Evaluation, and Challenges", "comment": null, "summary": "Building agents, systems that perceive and act upon their environment with a\ndegree of autonomy, has long been a focus of AI research. This pursuit has\nrecently become vastly more practical with the emergence of large language\nmodels (LLMs) capable of using natural language to integrate information,\nfollow instructions, and perform forms of \"reasoning\" and planning across a\nwide range of tasks. With its multimodal data streams and orchestrated\nworkflows spanning multiple systems, radiology is uniquely suited to benefit\nfrom agents that can adapt to context and automate repetitive yet complex\ntasks. In radiology, LLMs and their multimodal variants have already\ndemonstrated promising performance for individual tasks such as information\nextraction and report summarization. However, using LLMs in isolation\nunderutilizes their potential to support complex, multi-step workflows where\ndecisions depend on evolving context from multiple information sources.\nEquipping LLMs with external tools and feedback mechanisms enables them to\ndrive systems that exhibit a spectrum of autonomy, ranging from semi-automated\nworkflows to more adaptive agents capable of managing complex processes. This\nreview examines the design of such LLM-driven agentic systems, highlights key\napplications, discusses evaluation methods for planning and tool use, and\noutlines challenges such as error cascades, tool-use efficiency, and health IT\nintegration.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u5728\u653e\u5c04\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u5916\u90e8\u5de5\u5177\u548c\u53cd\u9988\u673a\u5236\u589e\u5f3aLLM\u80fd\u529b\uff0c\u5b9e\u73b0\u4ece\u534a\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5230\u81ea\u9002\u5e94\u4ee3\u7406\u7684\u81ea\u4e3b\u6027\u8c31\u7cfb\u3002", "motivation": "\u653e\u5c04\u5b66\u5177\u6709\u591a\u6a21\u6001\u6570\u636e\u6d41\u548c\u8de8\u7cfb\u7edf\u534f\u8c03\u5de5\u4f5c\u6d41\u7a0b\u7684\u7279\u70b9\uff0c\u975e\u5e38\u9002\u5408\u5229\u7528\u80fd\u591f\u9002\u5e94\u4e0a\u4e0b\u6587\u5e76\u81ea\u52a8\u5316\u590d\u6742\u91cd\u590d\u4efb\u52a1\u7684\u667a\u80fd\u4ee3\u7406\u3002\u867d\u7136LLM\u5728\u653e\u5c04\u5b66\u5355\u4e2a\u4efb\u52a1\u4e2d\u5df2\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b64\u7acb\u4f7f\u7528\u65e0\u6cd5\u5145\u5206\u53d1\u6325\u5176\u5728\u590d\u6742\u591a\u6b65\u9aa4\u5de5\u4f5c\u6d41\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u4e3aLLM\u914d\u5907\u5916\u90e8\u5de5\u5177\u548c\u53cd\u9988\u673a\u5236\uff0c\u4f7f\u5176\u80fd\u591f\u9a71\u52a8\u8868\u73b0\u51fa\u4e0d\u540c\u81ea\u4e3b\u6027\u7a0b\u5ea6\u7684\u7cfb\u7edf\uff0c\u4ece\u534a\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5230\u80fd\u591f\u7ba1\u7406\u590d\u6742\u6d41\u7a0b\u7684\u81ea\u9002\u5e94\u4ee3\u7406\u3002", "result": "\u8bba\u6587\u7efc\u8ff0\u4e86\u6b64\u7c7bLLM\u9a71\u52a8\u4ee3\u7406\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3001\u5173\u952e\u5e94\u7528\u3001\u89c4\u5212\u4e0e\u5de5\u5177\u4f7f\u7528\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u8bc6\u522b\u4e86\u9519\u8bef\u7ea7\u8054\u3001\u5de5\u5177\u4f7f\u7528\u6548\u7387\u548c\u533b\u7597IT\u96c6\u6210\u7b49\u6311\u6218\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u4ee3\u7406\u7cfb\u7edf\u5728\u653e\u5c04\u5b66\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u652f\u6301\u590d\u6742\u7684\u591a\u6b65\u9aa4\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u9519\u8bef\u4f20\u64ad\u3001\u6548\u7387\u4f18\u5316\u548c\u7cfb\u7edf\u96c6\u6210\u7b49\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2510.09551", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09551", "abs": "https://arxiv.org/abs/2510.09551", "authors": ["Gavriel Di Nepi", "Federico Siciliano", "Fabrizio Silvestri"], "title": "Titans Revisited: A Lightweight Reimplementation and Critical Analysis of a Test-Time Memory Model", "comment": null, "summary": "By the end of 2024, Google researchers introduced Titans: Learning at Test\nTime, a neural memory model achieving strong empirical results across multiple\ntasks. However, the lack of publicly available code and ambiguities in the\noriginal description hinder reproducibility. In this work, we present a\nlightweight reimplementation of Titans and conduct a comprehensive evaluation\non Masked Language Modeling, Time Series Forecasting, and Recommendation tasks.\nOur results reveal that Titans does not always outperform established baselines\ndue to chunking. However, its Neural Memory component consistently improves\nperformance compared to attention-only models. These findings confirm the\nmodel's innovative potential while highlighting its practical limitations and\nraising questions for future research.", "AI": {"tldr": "\u5bf9Google Titans\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u91cd\u5b9e\u73b0\u8bc4\u4f30\uff0c\u53d1\u73b0\u5176\u795e\u7ecf\u8bb0\u5fc6\u7ec4\u4ef6\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u7531\u4e8e\u5206\u5757\u5904\u7406\u5e76\u4e0d\u603b\u662f\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "Google Titans\u6a21\u578b\u7f3a\u4e4f\u516c\u5f00\u4ee3\u7801\u4e14\u539f\u63cf\u8ff0\u5b58\u5728\u6a21\u7cca\u6027\uff0c\u963b\u788d\u4e86\u53ef\u590d\u73b0\u6027\u7814\u7a76\u3002", "method": "\u5bf9Titans\u6a21\u578b\u8fdb\u884c\u8f7b\u91cf\u7ea7\u91cd\u5b9e\u73b0\uff0c\u5e76\u5728\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u3001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u548c\u63a8\u8350\u4efb\u52a1\u4e0a\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\u3002", "result": "Titans\u7531\u4e8e\u5206\u5757\u5904\u7406\u5e76\u4e0d\u603b\u662f\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4f46\u5176\u795e\u7ecf\u8bb0\u5fc6\u7ec4\u4ef6\u76f8\u6bd4\u4ec5\u4f7f\u7528\u6ce8\u610f\u529b\u7684\u6a21\u578b\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u786e\u8ba4\u4e86\u8be5\u6a21\u578b\u7684\u521b\u65b0\u6f5c\u529b\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u5b9e\u9645\u5c40\u9650\u6027\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u51fa\u4e86\u95ee\u9898\u3002"}}
{"id": "2510.09567", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.09567", "abs": "https://arxiv.org/abs/2510.09567", "authors": ["Jacopo Tagliabue", "Ciro Greco"], "title": "Safe, Untrusted, \"Proof-Carrying\" AI Agents: toward the agentic lakehouse", "comment": "IEEE Big Data, Workshop on Secure and Safe AI Agents for Big Data\n  Infrastructures", "summary": "Data lakehouses run sensitive workloads, where AI-driven automation raises\nconcerns about trust, correctness, and governance. We argue that API-first,\nprogrammable lakehouses provide the right abstractions for safe-by-design,\nagentic workflows. Using Bauplan as a case study, we show how data branching\nand declarative environments extend naturally to agents, enabling\nreproducibility and observability while reducing the attack surface. We present\na proof-of-concept in which agents repair data pipelines using correctness\nchecks inspired by proof-carrying code. Our prototype demonstrates that\nuntrusted AI agents can operate safely on production data and outlines a path\ntoward a fully agentic lakehouse.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAPI\u4f18\u5148\u3001\u53ef\u7f16\u7a0b\u7684\u6570\u636e\u6e56\u4ed3\u4e3aAI\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u63d0\u4f9b\u5b89\u5168\u8bbe\u8ba1\u57fa\u7840\uff0c\u901a\u8fc7\u6570\u636e\u5206\u652f\u548c\u58f0\u660e\u5f0f\u73af\u5883\u5b9e\u73b0\u53ef\u590d\u73b0\u6027\u548c\u53ef\u89c2\u6d4b\u6027\u3002", "motivation": "\u6570\u636e\u6e56\u4ed3\u8fd0\u884c\u654f\u611f\u5de5\u4f5c\u8d1f\u8f7d\uff0cAI\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u5f15\u53d1\u4e86\u5173\u4e8e\u4fe1\u4efb\u3001\u6b63\u786e\u6027\u548c\u6cbb\u7406\u7684\u62c5\u5fe7\uff0c\u9700\u8981\u5b89\u5168\u7684\u8bbe\u8ba1\u65b9\u6848\u3002", "method": "\u4f7f\u7528Bauplan\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u91c7\u7528\u6570\u636e\u5206\u652f\u548c\u58f0\u660e\u5f0f\u73af\u5883\uff0c\u901a\u8fc7\u53d7\u8bc1\u660e\u643a\u5e26\u4ee3\u7801\u542f\u53d1\u7684\u6b63\u786e\u6027\u68c0\u67e5\u8ba9AI\u4ee3\u7406\u4fee\u590d\u6570\u636e\u7ba1\u9053\u3002", "result": "\u539f\u578b\u6f14\u793a\u8868\u660e\u4e0d\u53d7\u4fe1\u4efb\u7684AI\u4ee3\u7406\u53ef\u4ee5\u5728\u751f\u4ea7\u6570\u636e\u4e0a\u5b89\u5168\u64cd\u4f5c\uff0c\u51cf\u5c11\u4e86\u653b\u51fb\u9762\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u73b0\u5b8c\u5168\u4ee3\u7406\u5316\u7684\u6570\u636e\u6e56\u4ed3\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u5c55\u793a\u4e86AI\u4ee3\u7406\u5728\u654f\u611f\u6570\u636e\u73af\u5883\u4e2d\u5b89\u5168\u8fd0\u884c\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2510.09580", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09580", "abs": "https://arxiv.org/abs/2510.09580", "authors": ["Margarita Belova", "Jiaxin Xiao", "Shikhar Tuli", "Niraj K. Jha"], "title": "GraphMERT: Efficient and Scalable Distillation of Reliable Knowledge Graphs from Unstructured Data", "comment": null, "summary": "Researchers have pursued neurosymbolic artificial intelligence (AI)\napplications for nearly three decades because symbolic components provide\nabstraction while neural components provide generalization. Thus, a marriage of\nthe two components can lead to rapid advancements in AI. Yet, the field has not\nrealized this promise since most neurosymbolic AI frameworks fail to scale. In\naddition, the implicit representations and approximate reasoning of neural\napproaches limit interpretability and trust. Knowledge graphs (KGs), a\ngold-standard representation of explicit semantic knowledge, can address the\nsymbolic side. However, automatically deriving reliable KGs from text corpora\nhas remained an open problem. We address these challenges by introducing\nGraphMERT, a tiny graphical encoder-only model that distills high-quality KGs\nfrom unstructured text corpora and its own internal representations. GraphMERT\nand its equivalent KG form a modular neurosymbolic stack: neural learning of\nabstractions; symbolic KGs for verifiable reasoning. GraphMERT + KG is the\nfirst efficient and scalable neurosymbolic model to achieve state-of-the-art\nbenchmark accuracy along with superior symbolic representations relative to\nbaselines.\n  Concretely, we target reliable domain-specific KGs that are both (1) factual\n(with provenance) and (2) valid (ontology-consistent relations with\ndomain-appropriate semantics). When a large language model (LLM), e.g.,\nQwen3-32B, generates domain-specific KGs, it falls short on reliability due to\nprompt sensitivity, shallow domain expertise, and hallucinated relations. On\ntext obtained from PubMed papers on diabetes, our 80M-parameter GraphMERT\nyields a KG with a 69.8% FActScore; a 32B-parameter baseline LLM yields a KG\nthat achieves only 40.2% FActScore. The GraphMERT KG also attains a higher\nValidityScore of 68.8%, versus 43.0% for the LLM baseline.", "AI": {"tldr": "GraphMERT\u662f\u4e00\u4e2a\u5c0f\u578b\u56fe\u5f62\u7f16\u7801\u5668\u6a21\u578b\uff0c\u901a\u8fc7\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u8bed\u6599\u5e93\u4e2d\u63d0\u53d6\u9ad8\u8d28\u91cf\u77e5\u8bc6\u56fe\u8c31\uff0c\u89e3\u51b3\u4e86\u795e\u7ecf\u7b26\u53f7AI\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u95ee\u9898\u3002", "motivation": "\u795e\u7ecf\u7b26\u53f7AI\u9886\u57df\u8fd1\u4e09\u5341\u5e74\u6765\u672a\u80fd\u5b9e\u73b0\u5176\u6f5c\u529b\uff0c\u4e3b\u8981\u56e0\u4e3a\u73b0\u6709\u6846\u67b6\u96be\u4ee5\u6269\u5c55\uff0c\u4e14\u795e\u7ecf\u65b9\u6cd5\u7684\u9690\u5f0f\u8868\u793a\u548c\u8fd1\u4f3c\u63a8\u7406\u9650\u5236\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u3002\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u663e\u5f0f\u8bed\u4e49\u77e5\u8bc6\u7684\u9ec4\u91d1\u6807\u51c6\u8868\u793a\u53ef\u4ee5\u89e3\u51b3\u7b26\u53f7\u65b9\u9762\u7684\u95ee\u9898\uff0c\u4f46\u4ece\u6587\u672c\u8bed\u6599\u5e93\u81ea\u52a8\u63a8\u5bfc\u53ef\u9760KG\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u5f15\u5165GraphMERT\uff0c\u4e00\u4e2a\u5c0f\u578b\u56fe\u5f62\u7f16\u7801\u5668\u6a21\u578b\uff0c\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u8bed\u6599\u5e93\u53ca\u5176\u5185\u90e8\u8868\u793a\u4e2d\u63d0\u53d6\u9ad8\u8d28\u91cf\u77e5\u8bc6\u56fe\u8c31\u3002GraphMERT\u4e0e\u5176\u7b49\u6548KG\u5f62\u6210\u6a21\u5757\u5316\u795e\u7ecf\u7b26\u53f7\u5806\u6808\uff1a\u795e\u7ecf\u5b66\u4e60\u62bd\u8c61\uff1b\u7b26\u53f7KG\u7528\u4e8e\u53ef\u9a8c\u8bc1\u63a8\u7406\u3002", "result": "\u5728PubMed\u7cd6\u5c3f\u75c5\u8bba\u6587\u6587\u672c\u4e0a\uff0c80M\u53c2\u6570\u7684GraphMERT\u751f\u6210\u7684KG\u8fbe\u523069.8% FActScore\uff0c\u800c32B\u53c2\u6570\u7684\u57fa\u7ebfLLM\u4ec5\u8fbe\u523040.2%\u3002GraphMERT KG\u8fd8\u83b7\u5f9768.8% ValidityScore\uff0c\u800cLLM\u57fa\u7ebf\u4e3a43.0%\u3002", "conclusion": "GraphMERT+KG\u662f\u7b2c\u4e00\u4e2a\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\uff0c\u5728\u5b9e\u73b0\u6700\u5148\u8fdb\u57fa\u51c6\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u5177\u6709\u4f18\u8d8a\u7684\u7b26\u53f7\u8868\u793a\u80fd\u529b\u3002"}}
{"id": "2510.09595", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09595", "abs": "https://arxiv.org/abs/2510.09595", "authors": ["Kaijian Zou", "Aaron Xiong", "Yunxiang Zhang", "Frederick Zhang", "Yueqi Ren", "Jirong Yang", "Ayoung Lee", "Shitanshu Bhushan", "Lu Wang"], "title": "LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?", "comment": null, "summary": "Competitive programming problems increasingly serve as valuable benchmarks to\nevaluate the coding capabilities of large language models (LLMs) due to their\ncomplexity and ease of verification. Yet, current coding benchmarks face\nlimitations such as lack of exceptionally challenging problems, insufficient\ntest case coverage, reliance on online platform APIs that limit accessibility.\nTo address these issues, we introduce LiveOIBench, a comprehensive benchmark\nfeaturing 403 expert-curated Olympiad-level competitive programming problems,\neach with an average of 60 expert-designed test cases. The problems are sourced\ndirectly from 72 official Informatics Olympiads in different regions conducted\nbetween 2023 and 2025. LiveOIBench distinguishes itself through four key\nfeatures: (1) meticulously curated high-quality tasks with detailed subtask\nrubrics and extensive private test cases; (2) direct integration of elite\ncontestant performance data to enable informative comparison against\ntop-performing humans; (3) planned continuous, contamination-free updates from\nnewly released Olympiad problems; and (4) a self-contained evaluation system\nfacilitating offline and easy-to-reproduce assessments. Benchmarking 32 popular\ngeneral-purpose and reasoning LLMs, we find that GPT-5 achieves a notable\n81.76th percentile, a strong result that nonetheless falls short of top human\ncontestant performance, who usually place above 90th. In contrast, among\nopen-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile,\nunderscoring significant capability disparities from frontier closed models.\nDetailed analyses indicate that robust reasoning models prioritize precise\nproblem analysis over excessive exploration, suggesting future models should\nemphasize structured analysis and minimize unnecessary exploration. All data,\ncode, and leaderboard results will be made publicly available on our website.", "AI": {"tldr": "LiveOIBench\u662f\u4e00\u4e2a\u5305\u542b403\u4e2a\u5965\u6797\u5339\u514b\u7ea7\u522b\u7f16\u7a0b\u7ade\u8d5b\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5177\u6709\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\u548c\u4eba\u7c7b\u8868\u73b0\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u663e\u793aGPT-5\u8fbe\u523081.76\u767e\u5206\u4f4d\u4f46\u4ecd\u843d\u540e\u4e8e\u9876\u5c16\u4eba\u7c7b\u9009\u624b\u3002", "motivation": "\u5f53\u524d\u7f16\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u6311\u6218\u6027\u95ee\u9898\u4e0d\u8db3\u3001\u6d4b\u8bd5\u7528\u4f8b\u8986\u76d6\u4e0d\u5145\u5206\u3001\u4f9d\u8d56\u5728\u7ebf\u5e73\u53f0API\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5168\u9762\u53ef\u9760\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u4ece72\u4e2a\u5b98\u65b9\u4fe1\u606f\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u4e2d\u6536\u96c6403\u4e2a\u4e13\u5bb6\u7b56\u5212\u7684\u95ee\u9898\uff0c\u6bcf\u4e2a\u95ee\u9898\u5e73\u574760\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5efa\u7acb\u5305\u542b\u4eba\u7c7b\u8868\u73b0\u6570\u636e\u7684\u81ea\u5305\u542b\u8bc4\u4f30\u7cfb\u7edf\u3002", "result": "GPT-5\u8fbe\u523081.76\u767e\u5206\u4f4d\uff0c\u4f46\u843d\u540e\u4e8e\u9876\u5c16\u4eba\u7c7b\u9009\u624b\uff08\u901a\u5e38\u8d85\u8fc790\u767e\u5206\u4f4d\uff09\uff0c\u5f00\u6e90\u63a8\u7406\u6a21\u578bGPT-OSS-120B\u4ec5\u8fbe\u523060\u767e\u5206\u4f4d\u3002", "conclusion": "\u5065\u58ee\u7684\u63a8\u7406\u6a21\u578b\u5e94\u4f18\u5148\u7cbe\u786e\u95ee\u9898\u5206\u6790\u800c\u975e\u8fc7\u5ea6\u63a2\u7d22\uff0c\u672a\u6765\u6a21\u578b\u5e94\u5f3a\u8c03\u7ed3\u6784\u5316\u5206\u6790\u5e76\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u63a2\u7d22\u3002"}}
