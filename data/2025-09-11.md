<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 8]
- [cs.CR](#cs.CR) [Total: 24]
- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [ChatGPT for Code Refactoring: Analyzing Topics, Interaction, and Effective Prompts](https://arxiv.org/abs/2509.08090)
*Eman Abdullah AlOmar,Luo Xu,Sofia Martinez,Anthony Peruma,Mohamed Wiem Mkaouer,Christian D. Newman,Ali Ouni*

Main category: cs.SE

TL;DR: 研究分析开发者与ChatGPT在重构任务中的交互方式，通过文本挖掘重构相关对话来理解开发者如何表达重构需求以及ChatGPT如何响应


<details>
  <summary>Details</summary>
Motivation: 虽然最近研究考察了LLM在重构中的效果，但对开发者如何与ChatGPT交互表达重构需求的理解仍有限

Method: 文本挖掘715个重构相关交互对话（来自29,778个ChatGPT提示和响应），分析开发者的显式重构意图

Result: 未在摘要中提供

Conclusion: 未在摘要中提供

Abstract: Large Language Models (LLMs), such as ChatGPT, have become widely popular and
widely used in various software engineering tasks such as refactoring, testing,
code review, and program comprehension. Although recent studies have examined
the effectiveness of LLMs in recommending and suggesting refactoring, there is
a limited understanding of how developers express their refactoring needs when
interacting with ChatGPT. In this paper, our goal is to explore interactions
related to refactoring between developers and ChatGPT to better understand how
developers identify areas for improvement in code, and how ChatGPT addresses
developers' needs. Our approach involves text mining 715 refactoring-related
interactions from 29,778 ChatGPT prompts and responses, as well as the analysis
of developers' explicit refactoring intentions.

</details>


### [2] [Safety Factories -- a Manifesto](https://arxiv.org/abs/2509.08285)
*Carmen Cârlan,Daniel Ratiu,Michael Wagner*

Main category: cs.SE

TL;DR: 该文章提出建立"安全工厂"的概念，将安全工程工具和方法集成到软件开发流水线中，以应对现代软件快速迭代带来的安全挑战


<details>
  <summary>Details</summary>
Motivation: 解决软件开发与安全工程之间的方法和工具断层，适应现代软件快速迭代和持续交付的需求

Method: 建立安全工厂，通过将安全工作产品捐存在语义丰富的机器可处理模型中，定义自动一致性检查，并自动生成文档

Result: 提出了一种能够将软件开发最佳实践转移到安全工程中的方法论框架

Conclusion: 建立安全工厂是解决软件快速发展与安全要求相脱节的关键，需要在前期投入更多形式化工作以获得长期收益

Abstract: Modern cyber-physical systems are operated by complex software that
increasingly takes over safety-critical functions. Software enables rapid
iterations and continuous delivery of new functionality that meets the
ever-changing expectations of users. As high-speed development requires
discipline, rigor, and automation, software factories are used. These entail
methods and tools used for software development, such as build systems and
pipelines. To keep up with the rapid evolution of software, we need to bridge
the disconnect in methods and tools between software development and safety
engineering today. We need to invest more in formality upfront - capturing
safety work products in semantically rich models that are machine-processable,
defining automatic consistency checks, and automating the generation of
documentation - to benefit later. Transferring best practices from software to
safety engineering is worth exploring. We advocate for safety factories, which
integrate safety tooling and methods into software development pipelines.

</details>


### [3] [The Impact of Team Diversity in Agile Development Education](https://arxiv.org/abs/2509.08389)
*Marco Torchiano,Riccardo Coppola,Antonio Vetro',Xhoi Musaj*

Main category: cs.SE

TL;DR: 研究分析51个敏捷软件开发学生团队，发现性别多样性对项目成功有正向影响，国籍多样性影响可忽略，但两者结合会产生负面效果


<details>
  <summary>Details</summary>
Motivation: 软件工程领域缺乏对团队多样性（特别是性别和国籍）如何影响项目成果的研究，尤其是在教育环境中

Method: 分析3个学年51个学生团队，使用性别多样性指数、国籍多样性指数和两者共存指数来评估多样性对项目质量的影响

Result: 性别多样性对项目成功有中等程度的显著正相关；国籍多样性有轻微负面影响但可忽略；性别和国籍多样性结合会产生负面影响

Conclusion: 促进团队多样性不会对教育目标达成产生负面影响，但需要考虑多种多样性维度的交互作用

Abstract: Software Engineering is mostly a male-dominated sector, where gender
diversity is a key feature for improving equality of opportunities,
productivity, and innovation. Other diversity aspects, including but not
limited to nationality and ethnicity, are often understudied.In this work we
aim to assess the impact of team diversity, focusing mainly on gender and
nationality, in the context of an agile software development project-based
course. We analyzed 51 teams over three academic years, measuring three
different Diversity indexes - regarding Gender, Nationality and their
co-presence - to examine how different aspects of diversity impact the quality
of team project outcomes.Statistical analysis revealed a moderate,
statistically significant correlation between gender diversity and project
success, aligning with existing literature. Diversity in nationality showed a
negative but negligible effect on project results, indicating that promoting
these aspects does not harm students' performance. Analyzing their co-presence
within a team, gender and nationality combined had a negative impact, likely
due to increased communication barriers and differing cultural norms.This study
underscores the importance of considering multiple diversity dimensions and
their interactions in educational settings. Our findings, overall, show that
promoting diversity in teams does not negatively impact their performance and
achievement of educational goals.

</details>


### [4] [AutoStub: Genetic Programming-Based Stub Creation for Symbolic Execution](https://arxiv.org/abs/2509.08524)
*Felix Mächtle,Nils Loose,Jan-Niclas Serr,Jonas Sander,Thomas Eisenbarth*

Main category: cs.SE

TL;DR: AutoStub使用遗传编程自动为符号执行中的外部函数生成符号存根，无需人工干预即可近似函数行为，准确率超过90%


<details>
  <summary>Details</summary>
Motivation: 符号执行在遇到外部函数（如本地方法或第三方库）时存在局限性，现有解决方案需要额外上下文、昂贵的SMT求解器或手动干预

Method: 当符号执行器遇到外部函数时，AutoStub通过随机生成输入执行函数并收集输出来生成训练数据，然后使用遗传编程推导近似函数行为的表达式作为符号存根

Result: AutoStub能够以超过90%的准确率自动近似55%的评估函数，并能推断出揭示软件测试关键边缘情况的特定语言行为

Conclusion: 该方法使符号执行器能够继续分析而无需手动干预，实现了以前难以处理的程序路径探索

Abstract: Symbolic execution is a powerful technique for software testing, but suffers
from limitations when encountering external functions, such as native methods
or third-party libraries. Existing solutions often require additional context,
expensive SMT solvers, or manual intervention to approximate these functions
through symbolic stubs. In this work, we propose a novel approach to
automatically generate symbolic stubs for external functions during symbolic
execution that leverages Genetic Programming. When the symbolic executor
encounters an external function, AutoStub generates training data by executing
the function on randomly generated inputs and collecting the outputs. Genetic
Programming then derives expressions that approximate the behavior of the
function, serving as symbolic stubs. These automatically generated stubs allow
the symbolic executor to continue the analysis without manual intervention,
enabling the exploration of program paths that were previously intractable. We
demonstrate that AutoStub can automatically approximate external functions with
over 90% accuracy for 55% of the functions evaluated, and can infer
language-specific behaviors that reveal edge cases crucial for software
testing.

</details>


### [5] [Beyond the Binary: The System of All-round Evaluation of Research and Its Practices in China](https://arxiv.org/abs/2509.08546)
*Yu Zhu,Jiyuan Ye*

Main category: cs.SE

TL;DR: 这篇论文提出了一个全面科研评估体系（SAER），用于解决当前科研评估中定性与定量方法的二元对立问题，为全球评估改革提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 当前全球科研评估系统改革缺乏宏观系统的评估理论指导，尤其是定性与定量方法的二元对立阻碍了评估实践的有效实施。

Method: 通过回顾科研评估历史发展，提出SAER框架，将形式、内容和效用三维度评估与六个关键要素相结合，超越二元对立模式。

Result: SAER体系提供了一个结合三维度和六要素的全面评估框架，能够帮助学术评估者和研究人员协调评估方法中的二元对立。

Conclusion: 该系统体现了中国科研评估理论中的辨证智慧和经验，为全球科研评估系统的改革和发展提供了有价值的参考和启示。

Abstract: The lack of a macro-level, systematic evaluation theory to guide the
implementation of evaluation practices has become a key bottleneck in the
reform of global research evaluation systems. By reviewing the historical
development of research evaluation, this paper highlights the current binary
opposition between qualitative and quantitative methods in evaluation
practices. This paper introduces the System of All-round Evaluation of Research
(SAER), a framework that integrates form, content, and utility evaluations with
six key elements. SAER offers a theoretical breakthrough by transcending the
binary, providing a comprehensive foundation for global evaluation reforms. The
comprehensive system proposes a trinity of three evaluation dimensions,
combined with six evaluation elements, which would help academic evaluators and
researchers reconcile binary oppositions in evaluation methods. The system
highlights the dialectical wisdom and experience embedded in Chinese research
evaluation theory, offering valuable insights and references for the reform and
advancement of global research evaluation systems.

</details>


### [6] [Minimal Data, Maximum Clarity: A Heuristic for Explaining Optimization](https://arxiv.org/abs/2509.08667)
*Amirali Rayegan,Tim Menzies*

Main category: cs.SE

TL;DR: EZR是一个轻量级多目标优化框架，通过主动学习和朴素贝叶斯采样，用更少但更信息丰富的样本实现高效优化和可解释决策树


<details>
  <summary>Details</summary>
Motivation: 解决软件工程中配置空间大、标注成本高的优化问题，传统方法需要大量标注数据且缺乏可解释性

Method: 提出最大清晰度启发式方法，结合主动学习策略（朴素贝叶斯采样）和决策树蒸馏，实现全局和局部决策的透明解释

Result: 在60个真实数据集上实验表明，EZR在大多数情况下达到90%以上的最佳优化性能，解释清晰度和实用性超越LIME、SHAP等标准XAI方法

Conclusion: "少而精"策略可行且更优，使用更少但信息更丰富的样本可以实现标签高效的软件系统优化和解释

Abstract: Efficient, interpretable optimization is a critical but underexplored
challenge in software engineering, where practitioners routinely face vast
configuration spaces and costly, error-prone labeling processes. This paper
introduces EZR, a novel and modular framework for multi-objective optimization
that unifies active sampling, learning, and explanation within a single,
lightweight pipeline. Departing from conventional wisdom, our Maximum Clarity
Heuristic demonstrates that using less (but more informative) data can yield
optimization models that are both effective and deeply understandable. EZR
employs an active learning strategy based on Naive Bayes sampling to
efficiently identify high-quality configurations with a fraction of the labels
required by fully supervised approaches. It then distills optimization logic
into concise decision trees, offering transparent, actionable explanations for
both global and local decision-making. Extensive experiments across 60
real-world datasets establish that EZR reliably achieves over 90% of the
best-known optimization performance in most cases, while providing clear,
cohort-based rationales that surpass standard attribution-based explainable AI
(XAI) methods (LIME, SHAP, BreakDown) in clarity and utility. These results
endorse "less but better"; it is both possible and often preferable to use
fewer (but more informative) examples to generate label-efficient optimization
and explanations in software systems. To support transparency and
reproducibility, all code and experimental materials are publicly available at
https://github.com/amiiralii/Minimal-Data-Maximum-Clarity.

</details>


### [7] [SWE-Mirror: Scaling Issue-Resolving Datasets by Mirroring Issues Across Repositories](https://arxiv.org/abs/2509.08724)
*Junhao Wang,Daoguang Zan,Shulin Xin,Siyao Liu,Yurong Wu,Kai Shen*

Main category: cs.SE

TL;DR: SWE-Mirror是一个从GitHub真实issue中创建可验证训练数据集的管道，通过镜像和重新激活issue到已配置的Gym环境中，构建了60,671个issue解决任务的大规模数据集，显著提升了代码代理的问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在自动化Gym环境设置过程中成功率低、开销大，而现有Gym环境中的任务合成未能充分利用GitHub上丰富的人类报告问题数据。需要最大化利用现有Gym环境和GitHub上的issue解决历史数据。

Method: 引入SWE-Mirror管道：提取真实issue的语义精髓，将其镜像到另一个配置了Gym环境的仓库中，并重新激活为可验证的issue解决任务。在4种语言的40个仓库中应用该方法。

Result: 构建了包含60,671个issue解决任务的数据集。训练后的模型在问题解决能力上表现出改进。扩展到12,000+高质量轨迹后，在OpenHands框架上为Qwen2.5-Coder-Instruct模型建立了新的SOTA，SWE-Bench-Verified上的解决率分别提升21.8%(7B)和46.0%(32B)。

Conclusion: SWE-Mirror有效利用了现有Gym环境和GitHub issue历史数据，创建了大规模可验证训练数据集，显著提升了代码代理的性能，验证了该方法的有效性。

Abstract: Creating large-scale verifiable training datasets for issue-resolving tasks
is a critical yet notoriously difficult challenge. Existing methods on
automating the Gym environment setup process for real-world issues suffer from
low success rates and high overhead. Meanwhile, synthesizing new tasks within
existing Gym environments leaves the vast pool of authentic, human-reported
problems untapped. To maximize the utilization of existing Gym environments and
also the rich data of issue-resolving history on GitHub, we introduce
SWE-Mirror, a pipeline that distills a real-world issue's semantic essence,
mirrors it into another repository with a configured Gym environment, and
re-animates it as a verifiable issue-resolving task. SWE-Mirror reuses existing
Gym environments along with the vast pool of issue-resolving history hosted on
GitHub to construct a large-scale dataset of mirrored authentic and verifiable
tasks. Applying SWE-Mirror to 40 repositories across 4 languages, we have
curated a dataset with 60,671 issue-resolving tasks and demonstrated the value
of our dataset by training and evaluating coding agents at various scale.
Post-training experiments show that models trained with the dataset exhibit
improvements in issue-resolving capabilities. Furthermore, by extending the
dataset size to over 12,000 high-quality trajectories, we established a new
state-of-the-art (SOTA) among Qwen2.5-Coder-Instruct based LLMs on the
OpenHands agent framework, which increases the resolve rate on
SWE-Bench-Verified by +21.8% for the 7B model and +46.0% for the 32B model and
validates the effectiveness of our approach.

</details>


### [8] [Handling Open-Vocabulary Constructs in Formalizing Specifications: Retrieval-Augmented Parsing with Expert Knowledge](https://arxiv.org/abs/2509.08808)
*Mohammad Saqib Hasan,Sayontan Ghosh,Dhruv Verma,Geoff Kuenning,Erez Zadok,Scott A. Smolka,Niranjan Balasubramanian*

Main category: cs.SE

TL;DR: 本文提出了动态知识增强解析(DKAP)方法，通过检索增强解析器ROLex来解决开放词汇构造(OVCs)问题，在自然语言到形式语言的转换中有效利用专家提供的动态知识。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理未知的开放词汇构造(OVCs)时表现不佳，因为缺乏先验知识。专家可以在推理时提供正确的构造知识，但如何有效重用这些知识而不重新训练模型是一个挑战。

Method: 提出了DKAP框架，使用动态增长的关键词词典存储专家知识。开发了ROLex检索增强解析器，包含检索器和生成器，通过合成数据生成和数据增强技术训练模型关注相关检索知识。

Result: 在三个形式化任务(NL2LTL、NL2Code、NL2CMD)上的评估表明，DKAP是一个具有挑战性的问题，ROLex能够有效利用动态专家知识，显著提升基线模型性能。

Conclusion: DKAP框架和ROLex方法为解决开放词汇构造问题提供了有效解决方案，能够在推理时动态利用专家知识，提升自然语言到形式语言转换的准确性和适应性。

Abstract: We study the problem of Open-Vocabulary Constructs(OVCs) -- ones not known
beforehand -- in the context of converting natural language (NL) specifications
into formal languages (e.g., temporal logic or code). Models fare poorly on
OVCs due to a lack of necessary knowledge a priori. In such situations, a
domain expert can provide correct constructs at inference time based on their
preferences or domain knowledge. Our goal is to effectively reuse this
inference-time, expert-provided knowledge for future parses without retraining
the model. We present dynamic knowledge-augmented parsing(DKAP), where in
addition to the input sentence, the model receives (dynamically growing) expert
knowledge as a key-value lexicon that associates NL phrases with correct OVC
constructs. We propose ROLex, a retrieval-augmented parsing approach that uses
this lexicon. A retriever and a generator are trained to find and use the
key-value store to produce the correct parse. A key challenge lies in curating
data for this retrieval-augmented parser. We utilize synthetic data generation
and the data augmentation techniques on annotated (NL sentence, FL statement)
pairs to train the augmented parser. To improve training effectiveness, we
propose multiple strategies to teach models to focus on the relevant subset of
retrieved knowledge. Finally, we introduce a new evaluation paradigm modeled
after the DKAP problem and simulate the scenario across three formalization
tasks (NL2LTL, NL2Code, and NL2CMD). Our evaluations show that DKAP is a
difficult challenge, and ROLex helps improve the performance of baseline models
by using dynamic expert knowledge effectively.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [9] [Establishing a Baseline of Software Supply Chain Security Task Adoption by Software Organizations](https://arxiv.org/abs/2509.08083)
*Laurie Williams,Sammy Migues*

Main category: cs.CR

TL;DR: 这篇论文通过对乡个软件开发组织的访谈研究，分析了软件供应链安全任务的采用情况，为优先级推进提供指导。


<details>
  <summary>Details</summary>
Motivation: 软件供应链攻击急剧增长，但完整采甠安全框架任务不可行，需要优先级采甠策略。研究目的是通过了解其他团队的实践经验，为组织提供任务优先级采甠的指导。

Method: 进行了一项访谈研究，访谈61名来自9个软件开发组织的实践者，这些组织都在重点关注软件供应链风险管理。

Result: 研究发现：组织在重点关注供应链安全之前已经实施了最常采甠的软件任务，因此这些任务的实施更为成熟。而针对软件组件和构建基础设施等新兴攻击向量的任务仍处于早期采甠阶段。

Conclusion: 建议优先采甠那些针对软件组件和构建基础设施等新兴攻击向量的安全任务，这些任务目前的采甠度较低但对供应链安全至关重要。

Abstract: Software supply chain attacks have increased exponentially since 2020. The
primary attack vectors for supply chain attacks are through: (1) software
components; (2) the build infrastructure; and (3) humans (a.k.a software
practitioners). Software supply chain risk management frameworks provide a list
of tasks that an organization can adopt to reduce software supply chain risk.
Exhaustively adopting all the tasks of these frameworks is infeasible,
necessitating the prioritized adoption of tasks. Software organizations can
benefit from being guided in this prioritization by learning what tasks other
teams have adopted. The goal of this study is to aid software development
organizations in understanding the adoption of security tasks that reduce
software supply chain risk through an interview study of software practitioners
engaged in software supply chain risk management efforts. An interview study
was conducted with 61 practitioners at nine software development organizations
that have focused efforts on reducing software supply chain risk. The results
of the interviews indicate that organizations had implemented the most adopted
software tasks before the focus on software supply chain security. Therefore,
their implementation in organizations is more mature. The tasks that mitigate
the novel attack vectors through software components and the build
infrastructure are in the early stages of adoption. Adoption of these tasks
should be prioritized.

</details>


### [10] [SAGE: Sample-Aware Guarding Engine for Robust Intrusion Detection Against Adversarial Attacks](https://arxiv.org/abs/2509.08091)
*Jing Chen,Onat Gungor,Zhengli Shang,Tajana Rosing*

Main category: cs.CR

TL;DR: SAGE是一个针对物联网入侵检测系统的对抗攻击防御算法，通过主动学习和目标数据缩减技术，动态选择最优防御策略，显著提升检测性能并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习入侵检测系统容易受到对抗攻击，虽然已有多种防御机制，但缺乏针对特定攻击选择最有效防御的系统性方法。

Method: SAGE整合主动学习与目标数据缩减，通过主动学习机制选择最具信息量的样本和最优防御标签，训练二级学习器来选择最有效的防御策略。

Result: 在多个入侵检测数据集上，SAGE相比最先进防御方法平均F1分数提升201%，性能与Oracle的差距缩小至3.8%，计算开销降低达29倍。

Conclusion: SAGE通过智能样本选择和防御策略优化，显著提升了入侵检测系统对对抗攻击的鲁棒性和计算效率，为动态防御选择提供了有效解决方案。

Abstract: The rapid proliferation of the Internet of Things (IoT) continues to expose
critical security vulnerabilities, necessitating the development of efficient
and robust intrusion detection systems (IDS). Machine learning-based intrusion
detection systems (ML-IDS) have significantly improved threat detection
capabilities; however, they remain highly susceptible to adversarial attacks.
While numerous defense mechanisms have been proposed to enhance ML-IDS
resilience, a systematic approach for selecting the most effective defense
against a specific adversarial attack remains absent. To address this
challenge, we previously proposed DYNAMITE, a dynamic defense selection
approach that identifies the most suitable defense against adversarial attacks
through an ML-driven selection mechanism. Building on this foundation, we
propose SAGE (Sample-Aware Guarding Engine), a substantially improved defense
algorithm that integrates active learning with targeted data reduction. It
employs an active learning mechanism to selectively identify the most
informative input samples and their corresponding optimal defense labels, which
are then used to train a second-level learner responsible for selecting the
most effective defense. This targeted sampling improves computational
efficiency, exposes the model to diverse adversarial strategies during
training, and enhances robustness, stability, and generalizability. As a
result, SAGE demonstrates strong predictive performance across multiple
intrusion detection datasets, achieving an average F1-score improvement of 201%
over the state-of-the-art defenses. Notably, SAGE narrows the performance gap
to the Oracle to just 3.8%, while reducing computational overhead by up to 29x.

</details>


### [11] [Accelerating AI Development with Cyber Arenas](https://arxiv.org/abs/2509.08200)
*William Cashman,Chasen Milner,Michael Houle,Michael Jones,Hayden Jananthan,Jeremy Kepner,Peter Michaleas,Alex Pentland*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: AI development requires high fidelity testing environments to effectively
transition from the laboratory to operations. The flexibility offered by cyber
arenas presents a novel opportunity to test new artificial intelligence (AI)
capabilities with users. Cyber arenas are designed to expose end-users to
real-world situations and must rapidly incorporate evolving capabilities to
meet their core objectives. To explore this concept the MIT/IEEE/Amazon Graph
Challenge Anonymized Network Sensor was deployed in a cyber arena during a
National Guard exercise.

</details>


### [12] [Unlocking Reproducibility: Automating re-Build Process for Open-Source Software](https://arxiv.org/abs/2509.08204)
*Behnaz Hassanshahi,Trong Nhan Mai,Benjamin Selwyn Smith,Nicholas Allen*

Main category: cs.CR

TL;DR: 本文提出了Macaron框架的扩展，用于自动化从源代码重建Maven构件，以提高软件供应链的安全性和透明度


<details>
  <summary>Details</summary>
Motivation: Maven Central等软件生态系统中二进制文件与源代码分离的问题导致供应链安全风险，约84%的常用构件缺乏透明的CI/CD流水线构建

Method: 扩展Macaron供应链安全框架，改进源代码检测性能，自动化从GitHub Actions工作流提取构建规范，并提供Java项目构建失败的根因分析

Result: 开发了自动化重建Maven构件的解决方案，能够处理复杂的依赖图，提高构建成功率和供应链透明度

Conclusion: 该方法通过自动化重建过程显著增强了开源供应链的安全性和可追溯性，为构建环境透明化提供了可行方案

Abstract: Software ecosystems like Maven Central play a crucial role in modern software
supply chains by providing repositories for libraries and build plugins.
However, the separation between binaries and their corresponding source code in
Maven Central presents a significant challenge, particularly when it comes to
linking binaries back to their original build environment. This lack of
transparency poses security risks, as approximately 84% of the top 1200
commonly used artifacts are not built using a transparent CI/CD pipeline.
Consequently, users must place a significant amount of trust not only in the
source code but also in the environment in which these artifacts are built.
  Rebuilding software artifacts from source provides a robust solution to
improve supply chain security. This approach allows for a deeper review of
code, verification of binary-source equivalence, and control over dependencies.
However, challenges arise due to variations in build environments, such as JDK
versions and build commands, which can lead to build failures. Additionally,
ensuring that all dependencies are rebuilt from source across large and complex
dependency graphs further complicates the process. In this paper, we introduce
an extension to Macaron, an industry-grade open-source supply chain security
framework, to automate the rebuilding of Maven artifacts from source. Our
approach improves upon existing tools, by offering better performance in source
code detection and automating the extraction of build specifications from
GitHub Actions workflows. We also present a comprehensive root cause analysis
of build failures in Java projects and propose a scalable solution to automate
the rebuilding of artifacts, ultimately enhancing security and transparency in
the open-source supply chain.

</details>


### [13] [EFPIX: A zero-trust encrypted flood protocol](https://arxiv.org/abs/2509.08248)
*Arin Upadhyay*

Main category: cs.CR

TL;DR: 提出一种基于洪泛的中继通信协议，实现端到端加密、用户可否认性和消息不可追踪性


<details>
  <summary>Details</summary>
Motivation: 需要设计一种能够抵抗拓扑变化和基础设施故障，同时隐藏元数据（如发送者和接收者信息）的通信协议

Method: 采用洪泛式的中继通信协议，实现端到端加密，确保消息的不可追踪性和用户的合理否认能力

Result: 协议能够有效隐藏元数据，抵抗拓扑变化和基础设施故障，提供安全的通信保障

Conclusion: 该洪泛中继通信协议成功实现了端到端加密、元数据隐藏和抗干扰能力，为安全通信提供了有效解决方案

Abstract: We propose a flood-based relay communication protocol that achieves
end-to-end encryption, plausible deniability for users, and untraceable
messages. It is resistant to changes in topology and infrastructure failures.
It is also designed to hide metadata, such as sender and receiver, from those
not involved.

</details>


### [14] [Overcoming DNSSEC Islands of Security: A TLS and IP-Based Certificate Solution](https://arxiv.org/abs/2509.08364)
*Aduma Rishith,Aditya Kulkarni,Tamal Das,Vivek Balachandran*

Main category: cs.CR

TL;DR: 本文提出了一种去中心化方法来解决DNSSEC中的"安全岛屿"问题，利用TLS和IP基证书实现端到端认证，减少对注册商的依赖。


<details>
  <summary>Details</summary>
Motivation: DNSSEC在链条中断时会形成"安全岛屿"，导致域名验证失效。现有中心化方案需要大量基础设施并依赖单一权威机构。

Method: 采用去中心化方案，利用TLS和IP基证书在DNS层级结构中实现端到端认证，免去在每个层级都部署DNSSEC的需求。

Result: 该方法提高了DNSSEC的整体完整性，减少了对注册商维护签名记录的依赖，使DNS安全部署更灵活高效。

Conclusion: 通过去中心化TLS/IP认证方案，有效解决了DNSSEC的链条断裂问题，在保持安全性的同时提高了部署灵活性。

Abstract: The Domain Name System (DNS) serves as the backbone of the Internet,
primarily translating domain names to IP addresses. Over time, various
enhancements have been introduced to strengthen the integrity of DNS. Among
these, DNSSEC stands out as a leading cryptographic solution. It protects
against attacks (such as DNS spoofing) by establishing a chain of trust
throughout the DNS nameserver hierarchy. However, DNSSEC's effectiveness is
compromised when there is a break in this chain, resulting in "Islands of
Security", where domains can authenticate locally but not across hierarchical
levels, leading to a loss of trust and validation between them. Leading
approaches to addressing these issues were centralized, with a single authority
maintaining some kind of bulletin board. This approach requires significantly
more infrastructure and places excessive trust in the entity responsible for
managing it properly. In this paper, we propose a decentralized approach to
addressing gaps in DNSSEC's chain of trust, commonly referred to as "Islands of
Security". We leverage TLS and IP-based certificates to enable end-to-end
authentication between hierarchical levels, eliminating the need for uniform
DNSSEC deployment across every level of the DNS hierarchy. This approach
enhances the overall integrity of DNSSEC, while reducing dependence on
registrars for maintaining signature records to verify the child nameserver's
authenticity. By offering a more flexible and efficient solution, our method
strengthens DNS security and streamlines deployment across diverse
environments.

</details>


### [15] [Phish-Blitz: Advancing Phishing Detection with Comprehensive Webpage Resource Collection and Visual Integrity Preservation](https://arxiv.org/abs/2509.08375)
*Duddu Hriday,Aditya Kulkarni,Vivek Balachandran,Tamal Das*

Main category: cs.CR

TL;DR: 提出了Phish-Blitz工具，用于收集钓鱼和合法网页及其资源（包括截图），解决了现有数据集不完整的问题，并提供了一个包含8809个合法和5000个钓鱼网页的完整数据集。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击日益猖獗，现有检测模型面临挑战。攻击者不断开发新策略绕过检测，而现有工具难以收集完整的网页资源（特别是短寿命的钓鱼网页），限制了数据集的全面性和检测准确性。

Method: 开发Phish-Blitz工具，能够下载钓鱼和合法网页及其相关资源（包括实时网页截图），并更新资源文件路径以保持网页原始视觉完整性。

Result: 提供了一个包含8,809个合法网页和5,000个钓鱼网页的完整数据集，包含所有相关资源。工具和数据集已在GitHub上公开。

Conclusion: Phish-Blitz解决了钓鱼检测数据集收集的挑战，为研究社区提供了更完整的数据资源，有助于提高钓鱼检测模型的准确性。

Abstract: Phishing attacks are increasingly prevalent, with adversaries creating
deceptive webpages to steal sensitive information. Despite advancements in
machine learning and deep learning for phishing detection, attackers constantly
develop new tactics to bypass detection models. As a result, phishing webpages
continue to reach users, particularly those unable to recognize phishing
indicators. To improve detection accuracy, models must be trained on large
datasets containing both phishing and legitimate webpages, including URLs,
webpage content, screenshots, and logos. However, existing tools struggle to
collect the required resources, especially given the short lifespan of phishing
webpages, limiting dataset comprehensiveness. In response, we introduce
Phish-Blitz, a tool that downloads phishing and legitimate webpages along with
their associated resources, such as screenshots. Unlike existing tools,
Phish-Blitz captures live webpage screenshots and updates resource file paths
to maintain the original visual integrity of the webpage. We provide a dataset
containing 8,809 legitimate and 5,000 phishing webpages, including all
associated resources. Our dataset and tool are publicly available on GitHub,
contributing to the research community by offering a more complete dataset for
phishing detection.

</details>


### [16] [MIoT-Driven Comparison of Open Blockchain Platforms](https://arxiv.org/abs/2509.08399)
*Abdou-Essamad Jabri,Mostafa Azizi,Cyril Drocourt,Gil Utard*

Main category: cs.CR

TL;DR: 这篇论文分析了三种免费区块链平台（以太坊、Hyperledger Fabric和Corda）在医疗物联网（MIoT）环境中的适用性和安全性能力。


<details>
  <summary>Details</summary>
Motivation: 随着工业4.0推动物联网普及，医疗物联网（MIoT）安全风险日益突出，需要找到适合的区块链平台来提供去中心化、自治、无信任的安全环境。

Method: 通过对比分析三种免费区块链平台（以太坊、Hyperledger Fabric、Corda）的特性和性能，评估它们在MIoT应用中的适用性。

Result: 识别了各区块链平台在MIoT环境下的优势和挑战，并建议智能部署方案以避免能耗和计算资源浪费等实际缺陷。

Conclusion: 区块链技术为MIoT提供了有效的安全解决方案，但需要根据具体应用场景细致选择适合的平台，并采用优化部署策略来应对实际应用中的挑战。

Abstract: Being propelled by the fourth industrial revolution (Industry 4.0), IoT
devices and solutions are well adopted everywhere, ranging from home
applications to industrial use, crossing through transportation, healthcare,
energy, and so on. This wide use of IoT has not gone unnoticed, hackers are
tracking the weakness of such a technology and threatening them continuously.
Their security at various levels has become an important concern of
professionals and researchers. This issue takes more risk, especially with the
IoT variants, IIoT (Industrial IoT) and MIoT (Medical IoT). Many existing
security solutions are adapted and proposed for addressing IoT security. In
this paper, we are interested in exploring blockchain technology and we make a
comparison of three free Blockchain platforms towards their applicability for
MIoT context, namely Ethereum, Hyperledger Fabric and Corda. In general,
Blockchain technology provides a decentralized, autonomous, trustless, and
distributed environment. It is challenging to find a Blockchain platform that
fits the MIoT context and performs well in terms of security. The retained
platform should be deployed smartly to avoid its practical drawbacks related to
energy-consuming and excessive computing.

</details>


### [17] [Leveraging Blockchain and Proxy Re-Encryption to secure Medical IoT Records](https://arxiv.org/abs/2509.08402)
*Abdou-Essamad Jabri,C. Drocourt,Mostafa Azizi,Gil Utard*

Main category: cs.CR

TL;DR: 基于私有区块链和代理重加密技术的IoT医疗数据安全分享方案，解决医疗数据传输和存储中的安全隐私挑战


<details>
  <summary>Details</summary>
Motivation: IoT医疗设备的广泛使用引发了敏感医疗数据的安全和隐私风险，需要找到方案确保数据完整性、可追溯性和保密性

Method: 结合私有区块链（提供去中心化不可篡改账本）和代理重加密（PRE）技术，允许加密数据在不暴露给中间人的情况下重新加密传递给新接收者

Result: 构建了一个安全、可追溯、隐私保护的数据分享框架，区块链确保数据完整性，PRE实现细粒度访问控制

Conclusion: 该方案为IoT医疗系统提供了坚固的安全框架，同时保证数据隐私和可控分享，提升了数字医疗生态系统的信任和效率

Abstract: The integration of the Internet of Things (IoT) in healthcare has
revolutionized patient monitoring and data collection, allowing real-time
tracking of vital signs, remote diagnostics, and automated medical responses.
However, the transmission and storage of sensitive medical data introduce
significant security and privacy challenges. To address these concerns,
blockchain technology provides a decentralized and immutable ledger that
ensures data integrity, , and transparency. Unlike public blockchains, private
blockchains are permissioned; the access is granted only to authorized
participants; they are more suitable for handling confidential healthcare data.
Although blockchain ensures security and trust, it lacks built-in mechanisms to
support flexible and controlled data sharing; This is where Proxy Re-Encryption
(PRE) comes into play. PRE is a cryptographic technique that allows encrypted
data to be re-encrypted for a new recipient without exposing it to
intermediaries. We propose an architecture integrating private blockchain and
PRE to enable secure, traceable, and privacy-preserving data sharing in
IoT-based healthcare systems. Blockchain guarantees tamper proof
record-keeping, while PRE enables fine-grained access control, allowing medical
professionals to securely share patient data without compromising
confidentiality. This combination creates a robust security framework that
enhances trust and efficiency in digital healthcare ecosystems.

</details>


### [18] [Phishing Webpage Detection: Unveiling the Threat Landscape and Investigating Detection Techniques](https://arxiv.org/abs/2509.08424)
*Aditya Kulkarni,Vivek Balachandran,Tamal Das*

Main category: cs.CR

TL;DR: 这篇论文是一个关于网页洗牌检测技术的系统性调研，分析了URL基础、网页内容和视觉技术等多种检测方法，指出了当前研究差距并提出解决方案。


<details>
  <summary>Details</summary>
Motivation: 洗牌攻击是常见的网络安全威胁，攻击者不断变换手法以窃取敏感信息。虽然研究人员在提升检测技术方面取得进展，但攻击者的新形威胁仍构成持续挑战。

Method: 进行系统性的分类和评估，包括URL基础、网页内容基础和视觉技术等多种洗牌网页检测方法，通过全面的文献综述和深入分析来识别研究空白。

Result: 识别了当前洗牌网页检测领域的研究缺口和挑战，并为部分问题提出了潜在的解决方案。

Conclusion: 该研究为防范洗牌攻击提供了价值丰富的见解，通过系统化的分析和建议，推动了洗牌检测技术的发展和改进。

Abstract: In the realm of cybersecurity, phishing stands as a prevalent cyber attack,
where attackers employ various tactics to deceive users into gathering their
sensitive information, potentially leading to identity theft or financial gain.
Researchers have been actively working on advancing phishing webpage detection
approaches to detect new phishing URLs, bolstering user protection.
Nonetheless, the ever-evolving strategies employed by attackers, aimed at
circumventing existing detection approaches and tools, present an ongoing
challenge to the research community. This survey presents a systematic
categorization of diverse phishing webpage detection approaches, encompassing
URL-based, webpage content-based, and visual techniques. Through a
comprehensive review of these approaches and an in-depth analysis of existing
literature, our study underscores current research gaps in phishing webpage
detection. Furthermore, we suggest potential solutions to address some of these
gaps, contributing valuable insights to the ongoing efforts to combat phishing
attacks.

</details>


### [19] [DSFL: A Dual-Server Byzantine-Resilient Federated Learning Framework via Group-Based Secure Aggregation](https://arxiv.org/abs/2509.08449)
*Charuka Herath,Yogachandran Rahulamathavan,Varuna De Silva,Sangarapillai Lambotharan*

Main category: cs.CR

TL;DR: DSFL是一个双服务器拜占庭容错联邦学习框架，通过群组安全聚合、信用过滤和动态奖惩系统，解决了隐私保护、拜占庭攻击防御和非IID数据下的模型效用问题，在性能和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习协议难以同时防御拜占庭攻击、在非IID数据下保持模型效用，并且保持边缘设备的轻量级特性。先前工作要么依赖可信硬件，要么使用昂贵的密码学工具，要么无法同时解决隐私和鲁棒性问题。

Method: 提出DSFL框架，包含三个关键创新：(1)双服务器安全聚合协议，无需加密或密钥交换；(2)基于群组的信用过滤机制，通过偏差分数隔离拜占庭客户端；(3)动态奖惩系统确保公平参与。

Result: 在MNIST、CIFAR-10和CIFAR-100数据集上测试，面对30%拜占庭参与者的IID和非IID设置，DSFL始终优于现有基线方法。在CIFAR-10上达到97.15%准确率，CIFAR-100上68.60%，而FedAvg在类似威胁下降至9.39%。DSFL保持轻量级，每轮仅需55.9ms运行时间和1088KB通信量。

Conclusion: DSFL成功解决了联邦学习中隐私保护、拜占庭防御和非IID数据处理的综合挑战，通过创新的双服务器架构和群组安全聚合方法，在保持高性能的同时实现了轻量级部署。

Abstract: Federated Learning (FL) enables decentralized model training without sharing
raw data, offering strong privacy guarantees. However, existing FL protocols
struggle to defend against Byzantine participants, maintain model utility under
non-independent and identically distributed (non-IID) data, and remain
lightweight for edge devices. Prior work either assumes trusted hardware, uses
expensive cryptographic tools, or fails to address privacy and robustness
simultaneously. We propose DSFL, a Dual-Server Byzantine-Resilient Federated
Learning framework that addresses these limitations using a group-based secure
aggregation approach. Unlike LSFL, which assumes non-colluding semi-honest
servers, DSFL removes this dependency by revealing a key vulnerability: privacy
leakage through client-server collusion. DSFL introduces three key innovations:
(1) a dual-server secure aggregation protocol that protects updates without
encryption or key exchange, (2) a group-wise credit-based filtering mechanism
to isolate Byzantine clients based on deviation scores, and (3) a dynamic
reward-penalty system for enforcing fair participation. DSFL is evaluated on
MNIST, CIFAR-10, and CIFAR-100 under up to 30 percent Byzantine participants in
both IID and non-IID settings. It consistently outperforms existing baselines,
including LSFL, homomorphic encryption methods, and differential privacy
approaches. For example, DSFL achieves 97.15 percent accuracy on CIFAR-10 and
68.60 percent on CIFAR-100, while FedAvg drops to 9.39 percent under similar
threats. DSFL remains lightweight, requiring only 55.9 ms runtime and 1088 KB
communication per round.

</details>


### [20] [Flow-Based Detection and Identification of Zero-Day IoT Cameras](https://arxiv.org/abs/2509.08485)
*Priyanka Rushikesh Chaudhary,Rajib Ranjan Maiti*

Main category: cs.CR

TL;DR: zCamInspector是一个用于识别已知IoT摄像头和检测零日摄像头的系统，使用监督学习和单分类器方法，在多个数据集上实现了高准确率。


<details>
  <summary>Details</summary>
Motivation: 大多数消费级IoT设备缺乏监控和控制机制，特别是难以检测新加入网络的流媒体IoT摄像头，这阻碍了定制化安全策略的实施。

Method: 使用CICFlowmeter从三个数据集中提取62个流特征，采用7种监督模型（XGB、RF等）进行已知摄像头识别，4种单分类模型（OCSVM、DeepSVDD等）进行零日摄像头检测。

Result: XGB模型识别IoT摄像头准确率>99%，假阴性率低至0.3%；零日检测中SGDOCSVM达到96.55%准确率，DeepSVDD在全部设备作为零日时达到74.51%测试准确率。

Conclusion: zCamInspector在多样化网络环境中对已知和零日IoT摄像头都能实现高精度识别和检测，特别是对特定设备如间谍时钟摄像头准确率>95%。

Abstract: The majority of consumer IoT devices lack mechanisms for administrators to
monitor and control them, hindering tailored security policies. A key challenge
is identifying whether a new device, especially a streaming IoT camera, has
joined the network. We present zCamInspector, a system for identifying known
IoT cameras with supervised classifiers (zCamClassifier) and detecting zero-day
cameras with one-class classifiers (zCamDetector). We analyzed ~40GB of traffic
across three datasets: Set I (six commercial IoT cameras), Set II (five
open-source IoT cameras, ~1.5GB), and Set III (four conferencing and two
video-sharing applications as non-IoT traffic). From each, 62 flow-based
features were extracted using CICFlowmeter. zCamInspector employs seven
supervised models (ET, DT, RF, KNN, XGB, LKSVM, GNB) and four one-class models
(OCSVM, SGDOCSVM, IF, DeepSVDD). Results show that XGB identifies IoT cameras
with >99% accuracy and false negatives as low as 0.3%, outperforming
state-of-the-art methods. For zero-day detection, accuracies reached 93.20%
(OCSVM), 96.55% (SGDOCSVM), 78.65% (IF), and 92.16% (DeepSVDD). When all
devices were treated as zero-day, DeepSVDD performed best with mean
training/testing accuracies of 96.03%/74.51%. zCamInspector also achieved >95%
accuracy for specific devices, such as Spy Clock cameras, demonstrating its
robustness for identifying and detecting zero-day IoT cameras in diverse
network environments.

</details>


### [21] [Send to which account? Evaluation of an LLM-based Scambaiting System](https://arxiv.org/abs/2509.08493)
*Hossein Siadati,Haadi Jafarian,Sima Jafarikhah*

Main category: cs.CR

TL;DR: 本文首次大规模评估了基于大语言模型的诱骗系统，通过5个月部署与2600+诈骗者互动，成功提取32%的敏感金融信息，但存在初始响应率低的问题。


<details>
  <summary>Details</summary>
Motivation: 诈骗者利用生成式AI大规模制作钓鱼内容，传统防御手段难以摧毁其基础设施，需要主动策略来获取威胁情报。

Method: 使用基于大语言模型的对话式蜜罐系统，主动与诈骗者互动并提取敏感信息。

Result: 系统成功提取了约32%的敏感金融信息（如骡子账户），人类接受率达到70%，但初始响应率仅为48.7%。

Conclusion: 虽然系统在信息提取方面表现良好，但需要进一步改进初始参与度，为自动化诱骗系统设计提供了可行见解。

Abstract: Scammers are increasingly harnessing generative AI(GenAI) technologies to
produce convincing phishing content at scale, amplifying financial fraud and
undermining public trust. While conventional defenses, such as detection
algorithms, user training, and reactive takedown efforts remain important, they
often fall short in dismantling the infrastructure scammers depend on,
including mule bank accounts and cryptocurrency wallets. To bridge this gap, a
proactive and emerging strategy involves using conversational honeypots to
engage scammers and extract actionable threat intelligence. This paper presents
the first large-scale, real-world evaluation of a scambaiting system powered by
large language models (LLMs). Over a five-month deployment, the system
initiated over 2,600 engagements with actual scammers, resulting in a dataset
of more than 18,700 messages. It achieved an Information Disclosure Rate (IDR)
of approximately 32%, successfully extracting sensitive financial information
such as mule accounts. Additionally, the system maintained a Human Acceptance
Rate (HAR) of around 70%, indicating strong alignment between LLM-generated
responses and human operator preferences. Alongside these successes, our
analysis reveals key operational challenges. In particular, the system
struggled with engagement takeoff: only 48.7% of scammers responded to the
initial seed message sent by defenders. These findings highlight the need for
further refinement and provide actionable insights for advancing the design of
automated scambaiting systems.

</details>


### [22] [Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations](https://arxiv.org/abs/2509.08646)
*Ron F. Del Rosario,Klaudia Krawiecka,Christian Schroeder de Witt*

Main category: cs.CR

TL;DR: 这篇论文提供了一个关于"计划-然后-执行"(P-t-E)模式的全面指南，该模式将战略规划与战术执行分离，以提高LLM代理的预测性、成本效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型代理能力的提升，需要更稳健、安全和可预测的架构模式来自动化复杂的多步任务。

Method: 探讨P-t-E模式的核心组件(规划器和执行器)，分析其在控制流完整性和安全性方面的优势，并提供对三个主流框架(LangChain、CrewAI、AutoGen)的实现蓝图和代码参考。

Result: P-t-E模式显著提高了代理系统的预测性、成本效率和推理质量，并通过控制流完整性增强了对间接提示注入攻击的防御能力。

Conclusion: 论文为架构师、开发者和安全工程师提供了一个完整的战略蓝图，帮助建设生产级别的、弹性的和可信赖的LLM代理系统。

Abstract: As Large Language Model (LLM) agents become increasingly capable of
automating complex, multi-step tasks, the need for robust, secure, and
predictable architectural patterns is paramount. This paper provides a
comprehensive guide to the ``Plan-then-Execute'' (P-t-E) pattern, an agentic
design that separates strategic planning from tactical execution. We explore
the foundational principles of P-t-E, detailing its core components - the
Planner and the Executor - and its architectural advantages in predictability,
cost-efficiency, and reasoning quality over reactive patterns like ReAct
(Reason + Act). A central focus is placed on the security implications of this
design, particularly its inherent resilience to indirect prompt injection
attacks by establishing control-flow integrity. We argue that while P-t-E
provides a strong foundation, a defense-in-depth strategy is necessary, and we
detail essential complementary controls such as the Principle of Least
Privilege, task-scoped tool access, and sandboxed code execution. To make these
principles actionable, this guide provides detailed implementation blueprints
and working code references for three leading agentic frameworks: LangChain
(via LangGraph), CrewAI, and AutoGen. Each framework's approach to implementing
the P-t-E pattern is analyzed, highlighting unique features like LangGraph's
stateful graphs for re-planning, CrewAI's declarative tool scoping for
security, and AutoGen's built-in Docker sandboxing. Finally, we discuss
advanced patterns, including dynamic re-planning loops, parallel execution with
Directed Acyclic Graphs (DAGs), and the critical role of Human-in-the-Loop
(HITL) verification, to offer a complete strategic blueprint for architects,
developers, and security engineers aiming to build production-grade, resilient,
and trustworthy LLM agents.

</details>


### [23] [Tight Privacy Audit in One Run](https://arxiv.org/abs/2509.08704)
*Zihang Xiang,Tianhao Wang,Hanshen Xiao,Yuan Tian,Di Wang*

Main category: cs.CR

TL;DR: 本文提出了一种单次运行的隐私审计方法，能够在各种差分隐私协议中实现紧密的审计结果，特别是在(ε,δ)-DP算法审计方面超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有隐私审计方法在单次运行中无法获得紧密的审计结果，特别是在(ε,δ)-DP算法审计方面存在局限性，需要开发更有效的审计框架。

Method: 首先构建了改进的单次运行隐私审计框架，然后基于f-DP隐私建模方法，推导出理论上有依据的隐私审计下界。

Result: 实验表明该方法在审计各种差分隐私算法时优于现有工作，并对单次运行隐私审计的参数设置得出了与先前研究不同的结论。

Conclusion: 该方法实现了对(ε,δ)-DP算法的紧密审计，填补了现有工作的空白，为隐私审计提供了更有效的解决方案。

Abstract: In this paper, we study the problem of privacy audit in one run and show that
our method achieves tight audit results for various differentially private
protocols. This includes obtaining tight results for auditing
$(\varepsilon,\delta)$-DP algorithms where all previous work fails to achieve
in any parameter setups. We first formulate a framework for privacy audit
\textit{in one run} with refinement compared with previous work. Then, based on
modeling privacy by the $f$-DP formulation, we study the implications of our
framework to obtain a theoretically justified lower bound for privacy audit. In
the experiment, we compare with previous work and show that our audit method
outperforms the rest in auditing various differentially private algorithms. We
also provide experiments that give contrasting conclusions to previous work on
the parameter settings for privacy audits in one run.

</details>


### [24] [PAnDA: Rethinking Metric Differential Privacy Optimization at Scale with Anchor-Based Approximation](https://arxiv.org/abs/2509.08720)
*Ruiyao Liu,Chenxi Qiu*

Main category: cs.CR

TL;DR: PAnDA是一个可扩展的两阶段框架，通过锚点选择策略优化度量差分隐私，解决了现有线性规划方法因决策变量二次增长而导致的可扩展性问题


<details>
  <summary>Details</summary>
Motivation: 现有的度量差分隐私优化方法，特别是基于线性规划的方法，由于决策变量的二次增长而面临可扩展性挑战

Method: 提出了PAnDA框架，包含两种锚点选择策略（指数衰减、幂律衰减和逻辑衰减），通过让用户选择少量锚点记录，使服务器能够在缩减的域上求解紧凑的线性规划问题

Result: 在真实世界地理位置数据集上的实验表明，PAnDA可以扩展到包含5000条记录的机密域，比现有基于LP的方法大两倍，同时为隐私和效用提供理论保证

Conclusion: PAnDA框架有效解决了度量差分隐私优化中的可扩展性问题，通过锚点选择策略实现了更好的隐私保护和计算效率

Abstract: Metric Differential Privacy (mDP) extends the local differential privacy
(LDP) framework to metric spaces, enabling more nuanced privacy protection for
data such as geo-locations. However, existing mDP optimization methods,
particularly those based on linear programming (LP), face scalability
challenges due to the quadratic growth in decision variables. In this paper, we
propose Perturbation via Anchor-based Distributed Approximation (PAnDA), a
scalable two-phase framework for optimizing metric differential privacy (mDP).
To reduce computational overhead, PAnDA allows each user to select a small set
of anchor records, enabling the server to solve a compact linear program over a
reduced domain. We introduce three anchor selection strategies, exponential
decay (PAnDA-e), power-law decay (PAnDA-p), and logistic decay (PAnDA-l), and
establish theoretical guarantees under a relaxed privacy notion called
probabilistic mDP (PmDP). Experiments on real-world geo-location datasets
demonstrate that PAnDA scales to secret domains with up to 5,000 records, two
times larger than prior LP-based methods, while providing theoretical
guarantees for both privacy and utility.

</details>


### [25] [SilentLedger: Privacy-Preserving Auditing for Blockchains with Complete Non-Interactivity](https://arxiv.org/abs/2509.08722)
*Zihan Liu,Xiaohu Wang,Chao Lin,Minghui Xu,Debiao He,Xinyi Huang*

Main category: cs.CR

TL;DR: SilentLedger是一个具有完全非交互式审计功能的隐私保护区块链系统，通过可再生匿名证书和可追溯交易机制，在保护交易隐私的同时支持审计人员仅从链上数据恢复参与者身份和交易金额。


<details>
  <summary>Details</summary>
Motivation: 现有隐私保护区块链系统在审计功能上存在缺陷，要么需要额外交互影响可用性和可扩展性，要么要求审计人员作为验证者或记录节点，带来数据安全和系统可靠性风险。

Method: 提出可再生匿名证书方案和基于成熟密码学原语的可追溯交易机制，支持公开验证授权，用户无需交互即可交易，审计人员仅需链上数据即可审计。

Result: 正式证明了真实性、匿名性、机密性和健全性等安全属性，实现了具体实例化，在标准2-2交易模型下性能评估显示优于现有最优解决方案。

Conclusion: SilentLedger成功解决了隐私保护与审计需求之间的平衡问题，实现了完全非交互式的隐私交易系统，具有优越的性能表现。

Abstract: Privacy-preserving blockchain systems are essential for protecting
transaction data, yet they must also provide auditability that enables auditors
to recover participant identities and transaction amounts when warranted.
Existing designs often compromise the independence of auditing and
transactions, introducing extra interactions that undermine usability and
scalability. Moreover, many auditable solutions depend on auditors serving as
validators or recording nodes, which introduces risks to both data security and
system reliability.
  To overcome these challenges, we propose SilentLedger, a privacy-preserving
transaction system with auditing and complete non-interactivity. To support
public verification of authorization, we introduce a renewable anonymous
certificate scheme with formal semantics and a rigorous security model.
SilentLedger further employs traceable transaction mechanisms constructed from
established cryptographic primitives, enabling users to transact without
interaction while allowing auditors to audit solely from on-chain data. We
formally prove security properties including authenticity, anonymity,
confidentiality, and soundness, provide a concrete instantiation, and evaluate
performance under a standard 2-2 transaction model. Our implementation and
benchmarks demonstrate that SilentLedger achieves superior performance compared
with state-of-the-art solutions.

</details>


### [26] [Securing Cryptographic Software via Typed Assembly Language (Extended Version)](https://arxiv.org/abs/2509.08727)
*Shixin Song,Tingzhen Dong,Kosi Nwabueze,Julian Zanders,Andres Erbsen,Adam Chlipala,Mengjia Yan*

Main category: cs.CR

TL;DR: SecSep是一个汇编级转换框架，通过栈数据分区和Octal类型化汇编语言来防御Spectre类推测执行攻击，平均开销仅1.2%


<details>
  <summary>Details</summary>
Motivation: 现有源代码标注方法无法正确跟踪栈上的秘密数据，存在性能开销和功能限制，需要更底层的解决方案

Method: 开发Octal类型化汇编语言，在编译时推断类型信息，重写汇编程序实现栈上秘密数据与公开数据的分区

Result: 成功应用于密码程序，实现了安全的推测执行，平均性能开销仅为1.2%

Conclusion: 汇编级重写方法比源代码标注更有效，Octal类型系统能够解决编译过程中语义信息丢失的挑战

Abstract: Authors of cryptographic software are well aware that their code should not
leak secrets through its timing behavior, and, until 2018, they believed that
following industry-standard constant-time coding guidelines was sufficient.
However, the revelation of the Spectre family of speculative execution attacks
injected new complexities.
  To block speculative attacks, prior work has proposed annotating the
program's source code to mark secret data, with hardware using this information
to decide when to speculate (i.e., when only public values are involved) or not
(when secrets are in play). While these solutions are able to track secret
information stored on the heap, they suffer from limitations that prevent them
from correctly tracking secrets on the stack, at a cost in performance.
  This paper introduces SecSep, a transformation framework that rewrites
assembly programs so that they partition secret and public data on the stack.
By moving from the source-code level to assembly rewriting, SecSep is able to
address limitations of prior work. The key challenge in performing this
assembly rewriting stems from the loss of semantic information through the
lengthy compilation process. The key innovation of our methodology is a new
variant of typed assembly language (TAL), Octal, which allows us to address
this challenge. Assembly rewriting is driven by compile-time inference within
Octal. We apply our technique to cryptographic programs and demonstrate that it
enables secure speculation efficiently, incurring a low average overhead of
$1.2\%$.

</details>


### [27] [Membrane: A Cryptographic Access Control System for Data Lakes](https://arxiv.org/abs/2509.08740)
*Sam Kumar,Samyukta Yagati,Conor Power,David E. Culler,Raluca Ada Popa*

Main category: cs.CR

TL;DR: Membrane是一个数据湖安全系统，通过加密和SQL感知加密技术，在保持数据分析能力的同时强制执行数据依赖的访问控制视图。


<details>
  <summary>Details</summary>
Motivation: 解决数据湖存储被黑客攻击绕过访问控制获取敏感数据的问题，需要在保护数据安全的同时不影响数据科学家运行分析查询。

Method: 结合静态加密和SQL感知加密技术，使用块密码算法开发新的SQL感知加密协议，利用CPU硬件加速实现高效加密。

Result: 系统仅在交互会话开始时因解密视图而产生开销，首次查询延迟增加约20倍，但后续查询处理解密后的明文数据，摊销开销很低。

Conclusion: Membrane通过创新的加密方法成功实现了数据湖的安全访问控制，在保证安全性的同时维持了数据分析的效率。

Abstract: Organizations use data lakes to store and analyze sensitive data. But hackers
may compromise data lake storage to bypass access controls and access sensitive
data. To address this, we propose Membrane, a system that (1) cryptographically
enforces data-dependent access control views over a data lake, (2) without
restricting the analytical queries data scientists can run. We observe that
data lakes, unlike DBMSes, disaggregate computation and storage into separate
trust domains, making at-rest encryption sufficient to defend against remote
attackers targeting data lake storage, even when running analytical queries in
plaintext. This leads to a new system design for Membrane that combines
encryption at rest with SQL-aware encryption. Using block ciphers, a fast
symmetric-key primitive with hardware acceleration in CPUs, we develop a new
SQL-aware encryption protocol well-suited to at-rest encryption. Membrane adds
overhead only at the start of an interactive session due to decrypting views,
delaying the first query result by up to $\approx 20\times$; subsequent queries
process decrypted data in plaintext, resulting in low amortized overhead.

</details>


### [28] [Stealth by Conformity: Evading Robust Aggregation through Adaptive Poisoning](https://arxiv.org/abs/2509.08746)
*Ryan McGaughey,Jesus Martinez del Rincon,Ihsen Alouani*

Main category: cs.CR

TL;DR: 本文提出CHAMP攻击方法，通过利用聚合过程的侧信道反馈来生成难以检测的恶意更新，成功规避了现有的9种鲁棒聚合防御方法，攻击成功率平均提升47.07%。


<details>
  <summary>Details</summary>
Motivation: 挑战联邦学习中鲁棒聚合方法的核心假设，即恶意更新必然是分布外数据。研究表明攻击者可以生成看起来正常的恶意更新来规避检测。

Method: 提出Chameleon Poisoning (CHAMP)自适应投毒策略，利用聚合过程的侧信道反馈动态调整本地损失函数，平衡恶意组件和伪装组件。

Result: 在两个数据集上对9种鲁棒聚合防御方法进行测试，攻击成功率平均提高47.07%，证明了现有防御方法的根本局限性。

Conclusion: 现有鲁棒聚合防御存在根本性局限，需要新的策略来保护联邦学习免受复杂对手攻击，CHAMP攻击方法揭示了这一安全漏洞。

Abstract: Federated Learning (FL) is a distributed learning paradigm designed to
address privacy concerns. However, FL is vulnerable to poisoning attacks, where
Byzantine clients compromise the integrity of the global model by submitting
malicious updates. Robust aggregation methods have been widely adopted to
mitigate such threats, relying on the core assumption that malicious updates
are inherently out-of-distribution and can therefore be identified and excluded
before aggregating client updates. In this paper, we challenge this underlying
assumption by showing that a model can be poisoned while keeping malicious
updates within the main distribution. We propose Chameleon Poisoning (CHAMP),
an adaptive and evasive poisoning strategy that exploits side-channel feedback
from the aggregation process to guide the attack. Specifically, the adversary
continuously infers whether its malicious contribution has been incorporated
into the global model and adapts accordingly. This enables a dynamic adjustment
of the local loss function, balancing a malicious component with a camouflaging
component, thereby increasing the effectiveness of the poisoning while evading
robust aggregation defenses. CHAMP enables more effective and evasive
poisoning, highlighting a fundamental limitation of existing robust aggregation
defenses and underscoring the need for new strategies to secure federated
learning against sophisticated adversaries. Our approach is evaluated in two
datasets reaching an average increase of 47.07% in attack success rate against
nine robust aggregation defenses.

</details>


### [29] [Silent Until Sparse: Backdoor Attacks on Semi-Structured Sparsity](https://arxiv.org/abs/2509.08747)
*Wei Guo,Maura Pintor,Ambra Demontis,Battista Biggio*

Main category: cs.CR

TL;DR: SUS攻击是一种针对半结构化稀疏化的后门攻击，在模型稀疏化前保持良性，稀疏化后激活后门功能，攻击成功率从<10%提升到>99%


<details>
  <summary>Details</summary>
Motivation: 针对现代GPU中半结构化稀疏化加速DNN执行的安全漏洞，研究如何在模型压缩部署过程中隐藏后门攻击

Method: 采用双阶段攻击：1）后门训练阶段将恶意功能注入保留权重；2）后门隐藏阶段通过微调将被修剪的权重来掩盖恶意行为

Result: 攻击对NVIDIA和PyTorch的半结构化稀疏化算法均有效，稀疏化后攻击成功率超过99%，且能抵抗先进的后门防御和微调

Conclusion: SUS攻击揭示了当前模型压缩和部署流程中的严重安全漏洞，半结构化稀疏化过程存在被恶意利用的风险

Abstract: In the deployment phase, semi-structured sparsity accelerates the execution
of deep neural networks on modern GPUs via sparse matrix multiplication. In
this paper, targeting the semi-structured sparsity, we introduce a Silent Until
Sparse (SUS) backdoor attack, where the released full model remains silent
(benign), but becomes a backdoored model after sparsification. The attack
operates in two phases: (i) in the backdoor training phase, the backdoor
functionality is injected into specific weights that will be retained during
the pruning process; (ii) in the backdoor hiding phase, the malicious behavior
is concealed by fine-tuning elements that will be pruned away. This dual-phase
approach ensures that the attack remains undetectable in the released model,
but activates properly once the model is pruned with the semi-structured
sparsity. Through extensive experiments, we show that our attack successfully
threatens the semi-structured sparsity algorithms from both NVIDIA and PyTorch.
Our empirical results show that, regardless of model architecture, the attack
success rate of the released model remains below 10% prior to sparsification
but exceeds 99% afterward. Moreover, we demonstrate that SUS attack is robust
against state-of-the-art backdoor defenses and finetuning, highlighting a
critical vulnerability in current model compression and deployment pipelines.

</details>


### [30] [Prototype-Guided Robust Learning against Backdoor Attacks](https://arxiv.org/abs/2509.08748)
*Wei Guo,Maura Pintor,Ambra Demontis,Battista Biggio*

Main category: cs.CR

TL;DR: 提出PGRL防御方法，利用少量良性样本生成原型向量指导训练，有效抵御多种后门攻击，在多种架构、数据集和攻击场景下表现优异


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击防御方法依赖特定假设，只能防御特定触发器、高中毒比例或需要大量无污染验证数据集的情况，存在局限性

Method: 原型引导鲁棒学习(PGRL)，利用少量良性样本生成原型向量来指导训练过程，无需依赖特定攻击假设

Result: 与8种现有防御方法相比，PGRL实现了更优越的鲁棒性，在多种架构、数据集和高级攻击下泛化性能良好，即使在完全知晓防御细节的自适应攻击场景下也能有效防御

Conclusion: PGRL方法克服了现有防御的局限性，能够有效抵御多样化的后门攻击，为后门防御提供了新的有效解决方案

Abstract: Backdoor attacks poison the training data to embed a backdoor in the model,
causing it to behave normally on legitimate inputs but maliciously when
specific trigger signals appear. Training a benign model from a dataset
poisoned by backdoor attacks is challenging. Existing works rely on various
assumptions and can only defend against backdoor attacks with specific trigger
signals, high poisoning ratios, or when the defender possesses a large,
untainted, validation dataset. In this paper, we propose a defense called
Prototype-Guided Robust Learning (PGRL), which overcomes all the aforementioned
limitations, being robust against diverse backdoor attacks. Leveraging a tiny
set of benign samples, PGRL generates prototype vectors to guide the training
process. We compare our PGRL with 8 existing defenses, showing that it achieves
superior robustness. We also demonstrate that PGRL generalizes well across
various architectures, datasets, and advanced attacks. Finally, to evaluate our
PGRL in the worst-case scenario, we perform an adaptive attack, where the
attackers fully know the details of the defense.

</details>


### [31] [Wanilla: Sound Noninterference Analysis for WebAssembly](https://arxiv.org/abs/2509.08758)
*Markus Scherer,Jeppe Fredsgaard Blaabjerg,Alexander Sjösten,Matteo Maffei*

Main category: cs.CR

TL;DR: 首个自动化、声音、全静态的WebAssembly非干扰分析系统Wanilla，通过提升可达性分析来进行信息流分析，验证内存完整性和安全性质。


<details>
  <summary>Details</summary>
Motivation: WebAssembly作为安全关键领域的软件分发格式，虽设计谨慎但仍存在内存欠陷风险，需要一种声音的静态非干扰分析来保证信息流安全。

Method: 提出一种新题方法：通过跟踪值上的污染标记，使用值敏感的关系推理来适时移除标记，将可达性分析提升为非干扰分析。

Result: 实现了Wanilla系统，通过综合性和实际测试验证了其性能和精度，能够验证内存完整性和其他非干扰性质。

Conclusion: 该研究成功开发了首个自动化、声音、全静态的WebAssembly非干扰分析方法，为WebAssembly模块的安全验证提供了有效工具。

Abstract: WebAssembly (Wasm) is rapidly gaining popularity as a distribution format for
software components embedded in various security-critical domains.
Unfortunately, despite its prudent design, WebAssembly's primary use case as a
compilation target for memory-unsafe languages leaves some possibilities for
memory corruption. Independently of that, Wasm is an inherently interesting
target for information flow analysis due to its interfacing role.
  Both the information flows between a Wasm module and its embedding context,
as well as the memory integrity within a module, can be described by the
hyperproperty noninterference. So far, no sound, fully static noninterference
analysis for Wasm has been presented, but sound reachability analyses were.
This work presents a novel and general approach to lift reachability analyses
to noninterference by tracking taints on values and using value-sensitive,
relational reasoning to remove them when appropriate. We implement this
approach in Wanilla, the first automatic, sound, and fully static
noninterference analysis for WebAssembly, and demonstrate its performance and
precision by verifying memory integrity and other noninterference properties
with several synthetic and real-world benchmarks.

</details>


### [32] [Approximate Algorithms for Verifying Differential Privacy with Gaussian Distributions](https://arxiv.org/abs/2509.08804)
*Bishnu Bhusal,Rohit Chadha,A. Prasad Sistla,Mahesh Viswanathan*

Main category: cs.CR

TL;DR: 本文提出了一种验证使用高斯分布的差分隐私算法的新方法，通过近似概率分布来解决验证问题，并证明对于这类程序，验证(ε,δ)-差分隐私几乎是可判定的。


<details>
  <summary>Details</summary>
Motivation: 使用高斯分布的差分隐私算法验证问题研究不足，需要开发有效的方法来验证这类程序的隐私保证。

Method: 引入近似概率分布的新方法，结合积分近似和尾部概率边界计算概率，使用FLINT库进行高精度积分计算，并实现优化以提高可扩展性。

Result: 开发了DipApprox工具，在基础隐私保护算法（如高斯变体的稀疏向量技术和噪声最大算法）上验证了有效性，既能确认隐私保证也能检测违规。

Conclusion: 该方法为验证使用连续概率分布的差分隐私程序提供了有效的解决方案，实现了几乎可判定的验证能力。

Abstract: The verification of differential privacy algorithms that employ Gaussian
distributions is little understood. This paper tackles the challenge of
verifying such programs by introducing a novel approach to approximating
probability distributions of loop-free programs that sample from both discrete
and continuous distributions with computable probability density functions,
including Gaussian and Laplace. We establish that verifying
$(\epsilon,\delta)$-differential privacy for these programs is \emph{almost
decidable}, meaning the problem is decidable for all values of $\delta$ except
those in a finite set. Our verification algorithm is based on computing
probabilities to any desired precision by combining integral approximations,
and tail probability bounds. The proposed methods are implemented in the tool,
DipApprox, using the FLINT library for high-precision integral computations,
and incorporate optimizations to enhance scalability. We validate {\ourtool} on
fundamental privacy-preserving algorithms, such as Gaussian variants of the
Sparse Vector Technique and Noisy Max, demonstrating its effectiveness in both
confirming privacy guarantees and detecting violations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [33] [Learning-Based Planning for Improving Science Return of Earth Observation Satellites](https://arxiv.org/abs/2509.07997)
*Abigail Breitfeld,Alberto Candela,Juan Delfa,Akseli Kangaslahti,Itai Zilberstein,Steve Chien,David Wettergreen*

Main category: cs.AI

TL;DR: 这篇论文提出了两种基于学习的动态目标指向方法（强化学习和模仿学习），用于最大化地球观测卫星的科学数据收集效果。


<details>
  <summary>Details</summary>
Motivation: 地球观测卫星存在轨道偏移困难、传感器视野有限、指向操作资源消耗大等限制，需要优化数据收集策略以获取最重要的科学信息。

Method: 采用强化学习和模仿学习两种方法，基于动态规划解决方案来规划采样位置序列。学习方法能够在较少数据情况下高效训练。

Result: 模仿学习比最佳惯性方法平均提高10.0%，强化学习平均提高13.7%。两种方法都在动态目标指向任务中显示出优势。

Conclusion: 学习基方法在卫星动态目标指向任务中具有显著优势，能够有效提高科学数据收集的数量和质量。

Abstract: Earth observing satellites are powerful tools for collecting scientific
information about our planet, however they have limitations: they cannot easily
deviate from their orbital trajectories, their sensors have a limited field of
view, and pointing and operating these sensors can take a large amount of the
spacecraft's resources. It is important for these satellites to optimize the
data they collect and include only the most important or informative
measurements. Dynamic targeting is an emerging concept in which satellite
resources and data from a lookahead instrument are used to intelligently
reconfigure and point a primary instrument. Simulation studies have shown that
dynamic targeting increases the amount of scientific information gathered
versus conventional sampling strategies. In this work, we present two different
learning-based approaches to dynamic targeting, using reinforcement and
imitation learning, respectively. These learning methods build on a dynamic
programming solution to plan a sequence of sampling locations. We evaluate our
approaches against existing heuristic methods for dynamic targeting, showing
the benefits of using learning for this application. Imitation learning
performs on average 10.0\% better than the best heuristic method, while
reinforcement learning performs on average 13.7\% better. We also show that
both learning methods can be trained effectively with relatively small amounts
of data.

</details>


### [34] [EnvX: Agentize Everything with Agentic AI](https://arxiv.org/abs/2509.08088)
*Linyao Chen,Zimian Peng,Yingxuan Yang,Yikun Wang,Wenzheng Tom Tang,Hiroki H. Kobayashi,Weinan Zhang*

Main category: cs.AI

TL;DR: EnvX是一个利用Agentic AI将GitHub仓库转化为智能代理的框架，通过自然语言交互和代理间协作，自动化软件复用过程，在GitTaskBench基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 开源软件仓库数量庞大但利用效率低下，开发者需要手动查阅文档、理解API和编写集成代码，存在显著的软件复用障碍。

Method: EnvX采用三阶段流程：1)TODO引导的环境初始化；2)人类对齐的代理自动化；3)代理间(A2A)协作协议，结合大语言模型能力和结构化工具集成。

Result: 在GitTaskBench基准测试的18个跨领域仓库上，EnvX实现了74.07%的执行完成率和51.85%的任务通过率，优于现有框架。

Conclusion: EnvX将仓库从被动代码资源转变为智能交互代理，促进了开源生态系统的可访问性和协作性。

Abstract: The widespread availability of open-source repositories has led to a vast
collection of reusable software components, yet their utilization remains
manual, error-prone, and disconnected. Developers must navigate documentation,
understand APIs, and write integration code, creating significant barriers to
efficient software reuse. To address this, we present EnvX, a framework that
leverages Agentic AI to agentize GitHub repositories, transforming them into
intelligent, autonomous agents capable of natural language interaction and
inter-agent collaboration. Unlike existing approaches that treat repositories
as static code resources, EnvX reimagines them as active agents through a
three-phase process: (1) TODO-guided environment initialization, which sets up
the necessary dependencies, data, and validation datasets; (2) human-aligned
agentic automation, allowing repository-specific agents to autonomously perform
real-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple
agents to collaborate. By combining large language model capabilities with
structured tool integration, EnvX automates not just code generation, but the
entire process of understanding, initializing, and operationalizing repository
functionality. We evaluate EnvX on the GitTaskBench benchmark, using 18
repositories across domains such as image processing, speech recognition,
document analysis, and video manipulation. Our results show that EnvX achieves
a 74.07% execution completion rate and 51.85% task pass rate, outperforming
existing frameworks. Case studies further demonstrate EnvX's ability to enable
multi-repository collaboration via the A2A protocol. This work marks a shift
from treating repositories as passive code resources to intelligent,
interactive agents, fostering greater accessibility and collaboration within
the open-source ecosystem.

</details>


### [35] [Trust Semantics Distillation for Collaborator Selection via Memory-Augmented Agentic AI](https://arxiv.org/abs/2509.08151)
*Botao Zhu,Jeslyn Wang,Dusit Niyato,Xianbin Wang*

Main category: cs.AI

TL;DR: 基于大型AI模型的教师-学生组织架构，通过任务特定信任语义提取和传递，实现高效准确的协作设备选择，降低评估时间和资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决任务所有者独立评估协作设备可靠性时带来的频繁数据交换、复杂推理和动态环境变化等问题，降低开销并提升信任评估效果。

Method: 提出任务特定信任语义提炼(2TSD)模型，采用LAM驱动的教师-学生组织架构。教师组件部署在服务器上，负责多维信任数据收集、任务特定信任语义提取和匹配分析，然后向学生组件传递信任语义。

Result: 实验结果显示，2TSD模型能够显著缩短协作者评估时间，降低设备资源消耗，同时提高了协作者选择的准确性。

Conclusion: 该研究提出的2TSD模型通过中央化的信任语义处理和分布式选择结合，有效解决了协作设备信任评估中的效率和准确性挑战，为复杂计算任务的协作执行提供了可靠支撑。

Abstract: Accurate trustworthiness evaluation of potential collaborating devices is
essential for the effective execution of complex computing tasks. This
evaluation process involves collecting diverse trust-related data from
potential collaborators, including historical performance and available
resources, for collaborator selection. However, when each task owner
independently assesses all collaborators' trustworthiness, frequent data
exchange, complex reasoning, and dynamic situation changes can result in
significant overhead and deteriorated trust evaluation. To overcome these
challenges, we propose a task-specific trust semantics distillation (2TSD)
model based on a large AI model (LAM)-driven teacher-student agent
architecture. The teacher agent is deployed on a server with powerful
computational capabilities and an augmented memory module dedicated to
multidimensional trust-related data collection, task-specific trust semantics
extraction, and task-collaborator matching analysis. Upon receiving
task-specific requests from device-side student agents, the teacher agent
transfers the trust semantics of potential collaborators to the student agents,
enabling rapid and accurate collaborator selection. Experimental results
demonstrate that the proposed 2TSD model can reduce collaborator evaluation
time, decrease device resource consumption, and improve the accuracy of
collaborator selection.

</details>


### [36] [Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following](https://arxiv.org/abs/2509.08222)
*Minjong Yoo,Jinwoo Jang,Wei-jin Park,Honguk Woo*

Main category: cs.AI

TL;DR: ExRAP框架通过探索性检索增强规划，提升LLM在动态环境中的持续指令跟随能力，结合信息探索和时序一致性优化，在多个基准测试中表现优异


<details>
  <summary>Details</summary>
Motivation: 解决具身智能体在动态非平稳环境中持续执行指令的挑战，增强LLM的环境推理能力并建立环境上下文记忆

Method: 提出探索集成任务规划方案，将基于信息的探索融入LLM规划过程，结合记忆增强查询评估和时序一致性精化方案

Result: 在VirtualHome、ALFRED和CARLA等基准测试中，对各种指令规模、类型和非平稳度场景表现出鲁棒性，在目标成功率和执行效率方面均优于现有方法

Conclusion: ExRAP框架有效平衡了环境上下文记忆的有效性和探索负载，提高了整体任务性能，为动态环境中的持续指令跟随提供了有效解决方案

Abstract: This study presents an Exploratory Retrieval-Augmented Planning (ExRAP)
framework, designed to tackle continual instruction following tasks of embodied
agents in dynamic, non-stationary environments. The framework enhances Large
Language Models' (LLMs) embodied reasoning capabilities by efficiently
exploring the physical environment and establishing the environmental context
memory, thereby effectively grounding the task planning process in time-varying
environment contexts. In ExRAP, given multiple continual instruction following
tasks, each instruction is decomposed into queries on the environmental context
memory and task executions conditioned on the query results. To efficiently
handle these multiple tasks that are performed continuously and simultaneously,
we implement an exploration-integrated task planning scheme by incorporating
the {information-based exploration} into the LLM-based planning process.
Combined with memory-augmented query evaluation, this integrated scheme not
only allows for a better balance between the validity of the environmental
context memory and the load of environment exploration, but also improves
overall task performance. Furthermore, we devise a {temporal consistency
refinement} scheme for query evaluation to address the inherent decay of
knowledge in the memory. Through experiments with VirtualHome, ALFRED, and
CARLA, our approach demonstrates robustness against a variety of embodied
instruction following scenarios involving different instruction scales and
types, and non-stationarity degrees, and it consistently outperforms other
state-of-the-art LLM-based task planning approaches in terms of both goal
success rate and execution efficiency.

</details>


### [37] [Real-world Music Plagiarism Detection With Music Segment Transcription System](https://arxiv.org/abs/2509.08282)
*Seonghyeon Go*

Main category: cs.AI

TL;DR: 通过结合多种音乐信息检索技术，提出了一种基于音乐段落转写和多种音乐特征的音乐剥窃检测系统，并创建了公开的相似音乐对数据集。


<details>
  <summary>Details</summary>
Motivation: 随着音乐信息检索技术的发展，音乐生成和分发更加多样化和可访问，保护音乐知识产权的需求日益增长。

Method: 开发了音乐段落转写系统，从音频录音中提取音乐意义段落，计算基于多种音乐特征的相似性得分，通过全面的音乐分析进行评估。

Result: 在音乐剥窃检测实验中展示了有前景的结果，方法可应用于实际音乐场景。

Conclusion: 该研究不仅提出了有效的音乐剥窃检测方法，还创建了相似音乐对(SMP)数据集，为音乐相似性研究提供了实际案例支持，数据集公开可用。

Abstract: As a result of continuous advances in Music Information Retrieval (MIR)
technology, generating and distributing music has become more diverse and
accessible. In this context, interest in music intellectual property protection
is increasing to safeguard individual music copyrights. In this work, we
propose a system for detecting music plagiarism by combining various MIR
technologies. We developed a music segment transcription system that extracts
musically meaningful segments from audio recordings to detect plagiarism across
different musical formats. With this system, we compute similarity scores based
on multiple musical features that can be evaluated through comprehensive
musical analysis. Our approach demonstrated promising results in music
plagiarism detection experiments, and the proposed method can be applied to
real-world music scenarios. We also collected a Similar Music Pair (SMP)
dataset for musical similarity research using real-world cases. The dataset are
publicly available.

</details>


### [38] [Leveraging AI Agents for Autonomous Networks: A Reference Architecture and Empirical Studies](https://arxiv.org/abs/2509.08312)
*Binghan Wu,Shoufeng Wang,Yunxin Liu,Ya-Qin Zhang,Joseph Sifakis,Ye Ouyang*

Main category: cs.AI

TL;DR: 通过实现Sifakis自主网络代理架构构建功能性认知系统，在5G RAN中实现了毫秒级实时控制，下行吞吐量提升6%，并将坑错率降低67%


<details>
  <summary>Details</summary>
Motivation: 实现TM Forum的L4级自主网络视野，进行自动配置、自恢复和自优化，提供零等待、零接触和零故障服务

Method: 采用Joseph Sifakis的AN代理参考架构，部署协调的预防式-反应式运行时，通过混合知识表示驱动

Result: 在5G NR sub-6 GHz中实现了子10毫秒实时控制，下行吞吐量比OLLA算法提高6%，坑错率降低67%，通过动态调制编码方案优化

Conclusion: 该架构能够克服传统自主性障碍，推进关键的L4级能力向下一代目标发展

Abstract: The evolution toward Level 4 (L4) Autonomous Networks (AN) represents a
strategic inflection point in telecommunications, where networks must transcend
reactive automation to achieve genuine cognitive capabilities--fulfilling TM
Forum's vision of self-configuring, self-healing, and self-optimizing systems
that deliver zero-wait, zero-touch, and zero-fault services. This work bridges
the gap between architectural theory and operational reality by implementing
Joseph Sifakis's AN Agent reference architecture in a functional cognitive
system, deploying coordinated proactive-reactive runtimes driven by hybrid
knowledge representation. Through an empirical case study of a Radio Access
Network (RAN) Link Adaptation (LA) Agent, we validate this framework's
transformative potential: demonstrating sub-10 ms real-time control in 5G NR
sub-6 GHz while achieving 6% higher downlink throughput than Outer Loop Link
Adaptation (OLLA) algorithms and 67% Block Error Rate (BLER) reduction for
ultra-reliable services through dynamic Modulation and Coding Scheme (MCS)
optimization. These improvements confirm the architecture's viability in
overcoming traditional autonomy barriers and advancing critical L4-enabling
capabilities toward next-generation objectives.

</details>


### [39] [Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives](https://arxiv.org/abs/2509.08380)
*Prathamesh Vasudeo Naik,Naresh Kumar Dintakurthi,Zhanghao Hu,Yue Wang,Robby Qiu*

Main category: cs.AI

TL;DR: 这篇论文提出了一种代理智能框架Co-Investigator AI，用于自动生成符合监管要求的可疑活动报告(SAR)，解决了传统LLM方法在准确性、解释性和监管对齐方面的问题。


<details>
  <summary>Details</summary>
Motivation: 可疑活动报告(SAR)的生成在反洗钱(AML)工作流中成为高成本、低扩展性的瓶颈，而现有的大语言模型存在事实幻觉、犯罪类型对齐不佳和解释性差等风险。

Method: 采用自治代理架构，整合了规划代理、犯罪类型检测代理、外部情报收集代理和合规性验证代理，包含动态内存管理、AI隐私保护层和基于Agent-as-a-Judge范式的实时验证机制。

Result: 该框架能够在多种复杂金融犯罪场景中高效生成SAR报告，提高生成速度和准确性，使报告内容更好地符合监管期望，让合规团队能够集中精力做高级分析工作。

Conclusion: Co-Investigator AI标志着合规报告领域的新时代，将AI代理的转型效益带到监管过程的核心，为可扩展、可靠和透明的SAR生成开启了新路径。

Abstract: Generating regulatorily compliant Suspicious Activity Report (SAR) remains a
high-cost, low-scalability bottleneck in Anti-Money Laundering (AML) workflows.
While large language models (LLMs) offer promising fluency, they suffer from
factual hallucination, limited crime typology alignment, and poor
explainability -- posing unacceptable risks in compliance-critical domains.
This paper introduces Co-Investigator AI, an agentic framework optimized to
produce Suspicious Activity Reports (SARs) significantly faster and with
greater accuracy than traditional methods. Drawing inspiration from recent
advances in autonomous agent architectures, such as the AI Co-Scientist, our
approach integrates specialized agents for planning, crime type detection,
external intelligence gathering, and compliance validation. The system features
dynamic memory management, an AI-Privacy Guard layer for sensitive data
handling, and a real-time validation agent employing the Agent-as-a-Judge
paradigm to ensure continuous narrative quality assurance. Human investigators
remain firmly in the loop, empowered to review and refine drafts in a
collaborative workflow that blends AI efficiency with domain expertise. We
demonstrate the versatility of Co-Investigator AI across a range of complex
financial crime scenarios, highlighting its ability to streamline SAR drafting,
align narratives with regulatory expectations, and enable compliance teams to
focus on higher-order analytical work. This approach marks the beginning of a
new era in compliance reporting -- bringing the transformative benefits of AI
agents to the core of regulatory processes and paving the way for scalable,
reliable, and transparent SAR generation.

</details>


### [40] [TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making](https://arxiv.org/abs/2509.08500)
*Kechen Jiao,Zhirui Fang,Jiahao Liu,Bei Li,Qifan Wang,Xinyu Liu,Junhao Ruan,Zhongjian Qiao,Yifan Zhu,Yaxin Xu,Jingang Wang,Xiu Li*

Main category: cs.AI

TL;DR: 本文提出Thought-Centric Preference Optimization (TCPO)方法，通过逐步偏好优化和推理过程对齐，解决视觉语言模型在具身AI决策中的模型退化问题，在ALFWorld环境中实现26.67%的平均成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习和思维链的后SFT方法存在稀疏奖励、动作优化限制、样本效率低、一致性差和模型退化等问题，需要更有效的具身决策对齐方法。

Method: 提出TCPO方法：1) 逐步偏好优化，将稀疏奖励转为丰富样本对；2) 强调中间推理过程对齐；3) 引入动作策略一致性约束(APC)对模型输出施加一致性约束。

Result: 在ALFWorld环境中实现26.67%的平均成功率，相比RL4VLM提升6%，有效缓解了微调后的模型退化问题。

Conclusion: TCPO方法展示了将偏好学习技术与思维链过程结合的巨大潜力，能够有效提升视觉语言模型在具身智能体中的决策能力。

Abstract: Using effective generalization capabilities of vision language models (VLMs)
in context-specific dynamic tasks for embodied artificial intelligence remains
a significant challenge. Although supervised fine-tuned models can better align
with the real physical world, they still exhibit sluggish responses and
hallucination issues in dynamically changing environments, necessitating
further alignment. Existing post-SFT methods, reliant on reinforcement learning
and chain-of-thought (CoT) approaches, are constrained by sparse rewards and
action-only optimization, resulting in low sample efficiency, poor consistency,
and model degradation. To address these issues, this paper proposes
Thought-Centric Preference Optimization (TCPO) for effective embodied
decision-making. Specifically, TCPO introduces a stepwise preference-based
optimization approach, transforming sparse reward signals into richer step
sample pairs. It emphasizes the alignment of the model's intermediate reasoning
process, mitigating the problem of model degradation. Moreover, by
incorporating Action Policy Consistency Constraint (APC), it further imposes
consistency constraints on the model output. Experiments in the ALFWorld
environment demonstrate an average success rate of 26.67%, achieving a 6%
improvement over RL4VLM and validating the effectiveness of our approach in
mitigating model degradation after fine-tuning. These results highlight the
potential of integrating preference-based learning techniques with CoT
processes to enhance the decision-making capabilities of vision-language models
in embodied agents.

</details>


### [41] [No-Knowledge Alarms for Misaligned LLMs-as-Judges](https://arxiv.org/abs/2509.08593)
*Andrés Corrada-Emmanuel*

Main category: cs.AI

TL;DR: 通过分析LLM评判者之间的逻辑一致性，发现并告警错误评判者，避免无限监控链条


<details>
  <summary>Details</summary>
Motivation: 解决LLM作为评判者时的监督问题，避免不知道真实情况下的无限监控链条

Method: 利用不同LLM评判者之间的不一致性，通过线性规划模型计算评判能力，开发无偏差告警机制

Result: 开发了能够无偏差检测至少一个评判者违反评分要求的告警系统

Conclusion: 逻辑一致性分析可以有效监控LLM评判者，提供了一种不需要真实标签的评估方法

Abstract: If we use LLMs as judges to evaluate the complex decisions of other LLMs, who
or what monitors the judges? Infinite monitoring chains are inevitable whenever
we do not know the ground truth of the decisions by experts and we do not want
to trust them. One way to ameliorate our evaluation uncertainty is to exploit
the use of logical consistency between disagreeing experts. By observing how
LLM judges agree and disagree while grading other LLMs, we can compute the only
possible evaluations of their grading ability. For example, if two LLM judges
disagree on which tasks a third one completed correctly, they cannot both be
100\% correct in their judgments. This logic can be formalized as a Linear
Programming problem in the space of integer response counts for any finite
test. We use it here to develop no-knowledge alarms for misaligned LLM judges.
The alarms can detect, with no false positives, that at least one member or
more of an ensemble of judges are violating a user specified grading ability
requirement.

</details>


### [42] [Automatic Failure Attribution and Critical Step Prediction Method for Multi-Agent Systems Based on Causal Inference](https://arxiv.org/abs/2509.08682)
*Guoqing Ma,Jia Zhu,Hanghui Guo,Weijie Shi,Jiawei Shen,Jingjiang Liu,Yidan Liang*

Main category: cs.AI

TL;DR: 提出了首个基于多粒度因果推理的多智能体系统故障归因框架，通过性能因果反转原理和因果发现算法CDC-MAS，显著提高了故障根因定位准确率，并实现了自动化优化循环。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在复杂任务自动化中至关重要，但实际部署受到故障归因挑战的严重阻碍。现有基于统计相关的诊断工具在Who&When等基准测试中准确率不足15%，无法有效定位故障根因步骤。

Method: 1) 性能因果反转原理：通过反转执行日志中的数据流正确建模性能依赖关系，结合Shapley值精确分配智能体级责任；2) 因果发现算法CDC-MAS：针对MAS交互数据的非平稳特性，鲁棒地识别关键故障步骤。

Result: 在Who&When和TRAIL基准测试中表现显著提升：方法达到36.2%的步骤级准确率，生成的优化建议平均提升整体任务成功率22.4%。

Conclusion: 该工作为调试复杂智能体交互提供了原则性和有效的解决方案，为构建更可靠和可解释的多智能体系统铺平了道路。

Abstract: Multi-agent systems (MAS) are critical for automating complex tasks, yet
their practical deployment is severely hampered by the challenge of failure
attribution. Current diagnostic tools, which rely on statistical correlations,
are fundamentally inadequate; on challenging benchmarks like Who\&When,
state-of-the-art methods achieve less than 15\% accuracy in locating the
root-cause step of a failure. To address this critical gap, we introduce the
first failure attribution framework for MAS grounded in multi-granularity
causal inference. Our approach makes two key technical contributions: (1) a
performance causal inversion principle, which correctly models performance
dependencies by reversing the data flow in execution logs, combined with
Shapley values to accurately assign agent-level blame; (2) a novel causal
discovery algorithm, CDC-MAS, that robustly identifies critical failure steps
by tackling the non-stationary nature of MAS interaction data. The framework's
attribution results directly fuel an automated optimization loop, generating
targeted suggestions whose efficacy is validated via counterfactual
simulations. Evaluations on the Who\&When and TRAIL benchmarks demonstrate a
significant leap in performance. Our method achieves up to 36.2\% step-level
accuracy. Crucially, the generated optimizations boost overall task success
rates by an average of 22.4\%. This work provides a principled and effective
solution for debugging complex agent interactions, paving the way for more
reliable and interpretable multi-agent systems.

</details>


### [43] [One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human Biases](https://arxiv.org/abs/2509.08705)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 提出基于双过程理论的思维理论框架，结合图卷积网络的快速直觉推理系统和元学习的慢速审慎推理系统，通过情境门机制动态平衡两种推理方式，在错误信念任务中验证并模拟人类认知偏差。


<details>
  <summary>Details</summary>
Motivation: 将认知科学的双过程理论引入人工智能领域，旨在开发能够模拟人类直觉与审慎推理平衡的AI系统，实现更接近人类的社会认知和适应性决策能力。

Method: 使用图卷积网络(GCNs)实现快速的图基推理系统(System 1)，结合元学习技术构建慢速的情境敏感元适应学习系统(System 2)，通过学习的上下文门机制动态平衡两种推理方式。

Result: 在经典错误信念任务中验证了框架有效性，成功复现了锚定效应、认知负荷疲劳、框架效应和启动效应等典型认知偏差，展示了与人类适应性行为的紧密匹配和良好的泛化能力。

Conclusion: 该工作架起了人工智能与认知理论之间的桥梁，为开发具有细致入微、类人社会认知和适应性决策能力的AI系统开辟了新途径。

Abstract: We introduce a novel Theory of Mind (ToM) framework inspired by dual-process
theories from cognitive science, integrating a fast, habitual graph-based
reasoning system (System 1), implemented via graph convolutional networks
(GCNs), and a slower, context-sensitive meta-adaptive learning system (System
2), driven by meta-learning techniques. Our model dynamically balances
intuitive and deliberative reasoning through a learned context gate mechanism.
We validate our architecture on canonical false-belief tasks and systematically
explore its capacity to replicate hallmark cognitive biases associated with
dual-process theory, including anchoring, cognitive-load fatigue, framing
effects, and priming effects. Experimental results demonstrate that our
dual-process approach closely mirrors human adaptive behavior, achieves robust
generalization to unseen contexts, and elucidates cognitive mechanisms
underlying reasoning biases. This work bridges artificial intelligence and
cognitive theory, paving the way for AI systems exhibiting nuanced, human-like
social cognition and adaptive decision-making capabilities.

</details>


### [44] [The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist Systems](https://arxiv.org/abs/2509.08713)
*Ziming Luo,Atoosa Kasirzadeh,Nihar B. Shah*

Main category: cs.AI

TL;DR: 本文分析了AI科学家系统的潜在失败模式，包括基准选择不当、数据泄露、指标误用和事后选择偏差，并通过实验验证了这些风险的存在，建议期刊要求提交完整的自动化工作流日志以确保透明度。


<details>
  <summary>Details</summary>
Motivation: AI科学家系统能够自主执行完整的研究工作流程，但其内部工作机制缺乏审查，可能引入损害研究输出完整性、可靠性和可信度的缺陷。

Method: 设计受控实验来隔离四种潜在失败模式，评估两个主流开源AI科学家系统，分析自动化工作流程中的问题。

Result: 评估发现多个不同程度的失败模式存在，这些在实践中容易被忽视。完整工作流日志和代码的访问能更有效地检测此类失败。

Conclusion: 建议期刊和会议在评估AI生成研究时，要求同时提交完整自动化工作流的追踪日志和代码，以确保透明度、问责制和可重复性。

Abstract: AI scientist systems, capable of autonomously executing the full research
workflow from hypothesis generation and experimentation to paper writing, hold
significant potential for accelerating scientific discovery. However, the
internal workflow of these systems have not been closely examined. This lack of
scrutiny poses a risk of introducing flaws that could undermine the integrity,
reliability, and trustworthiness of their research outputs. In this paper, we
identify four potential failure modes in contemporary AI scientist systems:
inappropriate benchmark selection, data leakage, metric misuse, and post-hoc
selection bias. To examine these risks, we design controlled experiments that
isolate each failure mode while addressing challenges unique to evaluating AI
scientist systems. Our assessment of two prominent open-source AI scientist
systems reveals the presence of several failures, across a spectrum of
severity, which can be easily overlooked in practice. Finally, we demonstrate
that access to trace logs and code from the full automated workflow enables far
more effective detection of such failures than examining the final paper alone.
We thus recommend journals and conferences evaluating AI-generated research to
mandate submission of these artifacts alongside the paper to ensure
transparency, accountability, and reproducibility.

</details>


### [45] [Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making](https://arxiv.org/abs/2509.08785)
*Anup Tuladhar,Araz Minhas,Adam Kirton,Eli Kinney-Lang*

Main category: cs.AI

TL;DR: 基于双系统架构的实验平台，通过结合强化学习与语言模型推理，探索故事框架对AI决策的影响


<details>
  <summary>Details</summary>
Motivation: 虽然AI系统现在既能做决策又能进行故事推理，但这两种能力主要是分开研究的，需要架设平台来探索故事框架如何影响奖励基于学习的决策

Method: 采用双系统架构：一个强化学习策略根据历史经验建议行动，另一个语言模型通过不同故事框架处理这些建议来指导决策，在可配置的gridworld环境中实现

Result: 建立了一个模块化的实验平台，能够控制测试环境复杂性、故事参数以及强化学习与故事基于决策的交互作用，日志系统记录了从RL策略价值到语言模型推理等基本决策指标

Conclusion: 这个预初实现为研究不同故事框架如何影响奖励基于决策提供了基础，同时也为探索AI系统中优化基于学习与符号推理之间的潜在交互作用开启了可能性

Abstract: We present a preliminary experimental platform that explores how narrative
elements might shape AI decision-making by combining reinforcement learning
(RL) with language model reasoning. While AI systems can now both make
decisions and engage in narrative reasoning, these capabilities have mostly
been studied separately. Our platform attempts to bridge this gap using a
dual-system architecture to examine how narrative frameworks could influence
reward-based learning. The system comprises a reinforcement learning policy
that suggests actions based on past experience, and a language model that
processes these suggestions through different narrative frameworks to guide
decisions. This setup enables initial experimentation with narrative elements
while maintaining consistent environment and reward structures. We implement
this architecture in a configurable gridworld environment, where agents receive
both policy suggestions and information about their surroundings. The
platform's modular design facilitates controlled testing of environmental
complexity, narrative parameters, and the interaction between reinforcement
learning and narrative-based decisions. Our logging system captures basic
decision metrics, from RL policy values to language model reasoning to action
selection patterns. While preliminary, this implementation provides a
foundation for studying how different narrative frameworks might affect
reward-based decisions and exploring potential interactions between
optimization-based learning and symbolic reasoning in AI systems.

</details>
