<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 68]
- [cs.CR](#cs.CR) [Total: 15]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Application Modernization with LLMs: Addressing Core Challenges in Reliability, Security, and Quality](https://arxiv.org/abs/2506.10984)
*Ahilan Ayyachamy Nadar Ponnusamy*

Main category: cs.SE

TL;DR: 本文探讨了AI辅助代码生成工具在应用现代化中的潜力与挑战，提出了一种结合LLM代码推理与生成能力及人类专家指导的框架，并通过案例研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管AI辅助代码生成工具提高了开发效率，但仍存在安全性、可靠性和代码质量等问题。本文旨在通过结合LLM能力与人类专家指导，解决这些问题。

Method: 提出了一种框架，整合LLM的代码推理与生成能力，并强调人类专家的参与。通过案例研究验证框架的实际应用效果。

Result: 案例研究表明，该框架能有效解决应用现代化中的挑战，并强调了人类指导的关键作用。

Conclusion: 本文为AI驱动的应用现代化提供了实用框架和未来研究方向，强调了人机协作的重要性。

Abstract: AI-assisted code generation tools have revolutionized software development,
offering unprecedented efficiency and scalability. However, multiple studies
have consistently highlighted challenges such as security vulnerabilities,
reliability issues, and inconsistencies in the generated code. Addressing these
concerns is crucial to unlocking the full potential of this transformative
technology. While advancements in foundational and code-specialized language
models have made notable progress in mitigating some of these issues,
significant gaps remain, particularly in ensuring high-quality, trustworthy
outputs.
  This paper builds upon existing research on leveraging large language models
(LLMs) for application modernization. It explores an opinionated approach that
emphasizes two core capabilities of LLMs: code reasoning and code generation.
The proposed framework integrates these capabilities with human expertise to
tackle application modernization challenges effectively. It highlights the
indispensable role of human involvement and guidance in ensuring the success of
AI-assisted processes.
  To demonstrate the framework's utility, this paper presents a detailed case
study, walking through its application in a real-world scenario. The analysis
includes a step-by-step breakdown, assessing alternative approaches where
applicable. This work aims to provide actionable insights and a robust
foundation for future research in AI-driven application modernization. The
reference implementation created for this paper is available on GitHub.

</details>


### [2] [Collaboration Tools and their Role in Agile Software Projects](https://arxiv.org/abs/2506.10985)
*Raman Mohammed Hussein,Bryar A. Hassan*

Main category: cs.SE

TL;DR: 本文探讨了协作工具（如Slack、Microsoft Teams、Confluence）在敏捷和软件项目中的重要性，分析了它们如何支持敏捷原则、促进迭代开发，并提升任务协调和知识共享。


<details>
  <summary>Details</summary>
Motivation: 敏捷方法依赖灵活性，但远程团队在协作和沟通方面仍面临挑战。协作工具能提升工作效率和互动效果，因此研究其如何支持敏捷开发具有重要意义。

Method: 通过分析Slack、Microsoft Teams和Confluence的功能，探讨它们如何适应敏捷原则、促进任务管理和团队协作。

Result: 这些工具在任务协调、知识共享和敏捷价值观的推广中发挥了关键作用，尤其适用于跨职能团队。

Conclusion: 协作工具是敏捷项目成功的关键，它们通过提升沟通效率和任务管理能力，显著增强了团队的生产力。

Abstract: The purpose of this review is to understand the importance of collaboration
tools which are Slack, Microsoft Teams, Confluence in Agile and software
projects. Agile methodologies rely on flexibility, using cycles and integration
throughout various levels of developing cycles. However, it is still a great
problem for many teams to collaborate and communicate even if staff members and
teams are working remotely. In terms of collaboration, the applications and
technologies mean better organization of work, increased mutually
understandable openness and fast and efficient inter team and interpersonal
interactions to enhance results of projects into productivity. This paper
examines how these tools fit the Agile principles, how they facilitate
iterative development, and encouraging effective initiation and tracking of
tasks in small and large projects. The insights focus on how Slack, Microsoft
Teams, and Confluence are essential for gaining better task coordination,
supporting knowledge sharing, and adopting agile values across cross-functional
contexts.

</details>


### [3] [CoMRAT: Commit Message Rationale Analysis Tool](https://arxiv.org/abs/2506.10986)
*Mouna Dhaouadi,Bentley James Oakes,Michalis Famelis*

Main category: cs.SE

TL;DR: CoMRAT是一个分析提交消息中决策和理由句的工具，支持研究者和开发者量化与分析代码变更理由。


<details>
  <summary>Details</summary>
Motivation: 提交消息中蕴含丰富的代码变更理由信息，但相关研究有限，因此开发了CoMRAT工具以填补这一空白。

Method: 开发了CoMRAT工具，用于分析GitHub模块中的提交消息，提取决策和理由句子。

Result: 初步评估表明，CoMRAT在研究开发和实际开发中均具有实用性和可用性。

Conclusion: CoMRAT为研究者和开发者提供了分析提交消息中理由信息的有效工具，填补了相关研究的不足。

Abstract: In collaborative open-source development, the rationale for code changes is
often captured in commit messages, making them a rich source of valuable
information. However, research on rationale in commit messages remains limited.
In this paper, we present CoMRAT, a tool for analyzing decision and rationale
sentences rationale in commit messages. CoMRAT enables a) researchers to
produce metrics and analyses on rationale information in any Github module, and
b) developers to check the amount of rationale in their commit messages. A
preliminary evaluation suggests the tool's usefulness and usability in both
these research and development contexts.

</details>


### [4] [Chain of Draft for Software Engineering: Challenges in Applying Concise Reasoning to Code Tasks](https://arxiv.org/abs/2506.10987)
*Shaoyi Yang*

Main category: cs.SE

TL;DR: 该研究将Chain of Draft (CoD)方法扩展到软件工程领域，通过实验证明CoD变体在代码任务中显著减少了令牌使用量，同时保持了90%以上的代码质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在软件开发中需要冗长的中间推理，导致高延迟和成本。研究旨在优化这一过程。

Method: 设计并评估了针对代码任务的多种CoD变体，使用SWE-bench基准的300个样本进行实验。

Result: Baseline CoD仅使用CoT的55.4%令牌，效率提升显著，但软件任务的复杂性导致效率提升不如数学推理领域明显。代码质量保持在CoT的90%以上。

Conclusion: 研究表明，领域特性影响提示策略效果，为软件工程中平衡效率与质量提供了框架和实用指导。

Abstract: Large language models (LLMs) have become vital tools for software
development, but they often require verbose intermediate reasoning for complex
code tasks, leading to high latency and costs. This research extends the Chain
of Draft (CoD) method to software engineering, designing and evaluating
multiple CoD variants tailored for code tasks. Through comprehensive
experiments on all 300 samples from the SWE-bench benchmark, we found that all
CoD variants used significantly fewer tokens than Chain of Thought (CoT), with
Baseline CoD being most efficient at 55.4% of CoT's tokens. While this
represents substantial efficiency gains - translating to approximately 45%
reduction in processing time and API costs - it differs from the extreme 7.6%
reported in the original CoD paper for mathematical reasoning. This difference
stems from the inherent complexity and context-dependency of software tasks,
which require more detailed reasoning to maintain solution quality. Our
multi-dimensional quality assessment revealed that CoD variants maintain over
90% of CoT's code quality across key metrics including correctness,
compatibility, and maintainability, making them practical alternatives for
real-world development scenarios where efficiency matters. This research
demonstrates how domain-specific characteristics influence prompting strategy
effectiveness and provides a framework for balancing efficiency with solution
quality in software engineering applications. Our findings offer practical
guidance for optimizing LLM-based development workflows through appropriate
prompting strategy selection based on project requirements.

</details>


### [5] [You Only Train Once: A Flexible Training Framework for Code Vulnerability Detection Driven by Vul-Vector](https://arxiv.org/abs/2506.10988)
*Bowen Tian,Zhengyang Xu,Mingqiang Wu,Songning Lai,Yutai Yue*

Main category: cs.SE

TL;DR: 论文提出YOTO框架，通过参数融合实现多类型漏洞检测模型的集成，避免联合训练，快速适应新漏洞，减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现代软件工程中漏洞检测需求迫切，但现有深度学习方法需要大量标注数据和频繁重训练，资源消耗大。

Method: 提出YOTO框架，通过参数融合集成多种漏洞检测模型，无需联合训练。

Result: YOTO能快速适应新漏洞，显著减少模型更新的时间和计算资源。

Conclusion: YOTO为漏洞检测提供了一种高效、资源友好的解决方案。

Abstract: With the pervasive integration of computer applications across industries,
the presence of vulnerabilities within code bases poses significant risks. The
diversity of software ecosystems coupled with the intricate nature of modern
software engineering has led to a shift from manual code vulnerability
identification towards the adoption of automated tools. Among these, deep
learning-based approaches have risen to prominence due to their superior
accuracy; however, these methodologies encounter several obstacles. Primarily,
they necessitate extensive labeled datasets and prolonged training periods, and
given the rapid emergence of new vulnerabilities, the frequent retraining of
models becomes a resource-intensive endeavor, thereby limiting their
applicability in cutting-edge scenarios. To mitigate these challenges, this
paper introduces the \underline{\textbf{YOTO}}--\underline{\textbf{Y}}ou
\underline{\textbf{O}}nly \underline{\textbf{T}}rain \underline{\textbf{O}}nce
framework. This innovative approach facilitates the integration of multiple
types of vulnerability detection models via parameter fusion, eliminating the
need for joint training. Consequently, YOTO enables swift adaptation to newly
discovered vulnerabilities, significantly reducing both the time and
computational resources required for model updates.

</details>


### [6] [Prompt engineering and framework: implementation to increase code reliability based guideline for LLMs](https://arxiv.org/abs/2506.10989)
*Rogelio Cruz,Jonatan Contreras,Francisco Guerrero,Ezequiel Rodriguez,Carlos Valdez,Citlali Carrillo*

Main category: cs.SE

TL;DR: 提出了一种新的提示方法，提升大语言模型生成准确Python代码的能力，实验证明其优于零样本和思维链方法，且更高效。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型生成代码的质量和正确性，减少计算资源消耗。

Method: 设计了一种提示模板，通过实验在HumanEval数据集上验证其效果。

Result: 在Pass@k指标上优于零样本和思维链方法，且显著减少token使用。

Conclusion: 定制化提示策略能优化代码生成性能，为AI驱动的编程任务提供更广泛应用。

Abstract: In this paper, we propose a novel prompting approach aimed at enhancing the
ability of Large Language Models (LLMs) to generate accurate Python code.
Specifically, we introduce a prompt template designed to improve the quality
and correctness of generated code snippets, enabling them to pass tests and
produce reliable results. Through experiments conducted on two state-of-the-art
LLMs using the HumanEval dataset, we demonstrate that our approach outperforms
widely studied zero-shot and Chain-of-Thought (CoT) methods in terms of the
Pass@k metric. Furthermore, our method achieves these improvements with
significantly reduced token usage compared to the CoT approach, making it both
effective and resource-efficient, thereby lowering the computational demands
and improving the eco-footprint of LLM capabilities. These findings highlight
the potential of tailored prompting strategies to optimize code generation
performance, paving the way for broader applications in AI-driven programming
tasks.

</details>


### [7] [On the Effectiveness of the 'Follow-the-Sun' Strategy in Mitigating the Carbon Footprint of AI in Cloud Instances](https://arxiv.org/abs/2506.10990)
*Roberto Vergallo,Luís Cruz,Alessio Errico,Luca Mainetti*

Main category: cs.SE

TL;DR: 论文提出'Follow-the-Sun'（FtS）模型以减少AI工作负载的碳足迹，并通过实验验证其效果。


<details>
  <summary>Details</summary>
Motivation: AI的高能耗问题引发广泛讨论，但缺乏科学证据支持FtS在减少碳足迹方面的优势。

Method: 在部分合成场景中，通过对比四种策略（无策略、FtS、Flexible Start、Pause and Resume）下四种AI算法的碳排放差异。

Result: FtS策略平均减少14.6%碳排放（峰值16.3%），同时保持训练时间。

Conclusion: FtS是一种有效的碳减排策略，适用于AI工作负载。

Abstract: 'Follow-the-Sun' (FtS) is a theoretical computational model aimed at
minimizing the carbon footprint of computer workloads. It involves dynamically
moving workloads to regions with cleaner energy sources as demand increases and
energy production relies more on fossil fuels. With the significant power
consumption of Artificial Intelligence (AI) being a subject of extensive
debate, FtS is proposed as a strategy to mitigate the carbon footprint of
training AI models. However, the literature lacks scientific evidence on the
advantages of FtS to mitigate the carbon footprint of AI workloads. In this
paper, we present the results of an experiment conducted in a partial synthetic
scenario to address this research gap. We benchmarked four AI algorithms in the
anomaly detection domain and measured the differences in carbon emissions in
four cases: no strategy, FtS, and two strategies previously introduced in the
state of the art, namely Flexible Start and Pause and Resume. To conduct our
experiment, we utilized historical carbon intensity data from the year 2021 for
seven European cities. Our results demonstrate that the FtS strategy not only
achieves average reductions of up to 14.6% in carbon emissions (with peaks of
16.3%) but also helps in preserving the time needed for training.

</details>


### [8] [What is Business Process Automation Anyway?](https://arxiv.org/abs/2506.10991)
*Hoang Vu,Henrik Leopold,Han van der Aa*

Main category: cs.SE

TL;DR: 本文通过分析18家主要供应商的市场情况，全面概述了当前工业界提供的业务流程自动化能力，并探讨了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 学术界主要关注机器人流程自动化（RPA），而实际供应商提供的自动化能力远超于此，因此需要更全面的理解。

Method: 对Gartner认定的18家主要业务流程自动化供应商进行结构化市场分析。

Result: 提供了当前工业界业务流程自动化能力的综合概述，展示了自动化类型和未来潜力方向。

Conclusion: 业务流程自动化在工业界具有多样化能力，未来发展方向值得关注。

Abstract: Many organizations strive to increase the level of automation in their
business processes. While automation historically was mainly concerned with
automating physical labor, current automation efforts mostly focus on
automation in a digital manner, thus targeting work that is related to the
interaction between humans and computers. This type of automation, commonly
referred to as business process automation, has many facets. Yet, academic
literature mainly focuses on Robotic Process Automation, a specific automation
capability. Recognizing that leading vendors offer automation capabilities
going way beyond that, we use this paper to develop a detailed understanding of
business process automation in industry. To this end, we conduct a structured
market analysis of the 18 predominant vendors of business process automation
solutions as identified by Gartner. As a result, we provide a comprehensive
overview of the business process automation capabilities currently offered by
industrial vendors. We show which types and facets of automation exist and
which aspects represent promising directions for the future.

</details>


### [9] [Towards a Theory on Process Automation Effects](https://arxiv.org/abs/2506.10992)
*Hoang Vu,Jennifer Haase,Henrik Leopold,Jan Mendling*

Main category: cs.SE

TL;DR: 本文探讨了流程自动化对操作后效果的研究不足，通过文献综述提出了人机交互的模型和建议。


<details>
  <summary>Details</summary>
Motivation: 研究流程自动化在实际操作中对人类的影响，填补现有研究的空白。

Method: 通过文献综述分析人类对自动化技术的感知，提出人机交互的模型。

Result: 提出了一个有效的技术、流程参与者、管理者和开发者之间的互动模型。

Conclusion: 为组织优化流程自动化提供了建议，并提出了新的研究问题。

Abstract: Process automation is a crucial strategy for improving business processes,
but little attention has been paid to the effects that automation has once it
is operational. This paper addresses this research problem by reviewing the
literature on human-automation interaction. Although many of the studies in
this field have been conducted in different domains, they provide a foundation
for developing propositions about process automation effects. Our analysis
focuses on how humans perceive automation technology when working within a
process, allowing us to propose an effective engagement model between
technology, process participants, process managers, and software developers.
This paper offers insights and recommendations that can help organizations
optimize their use of process automation. We further derive novel research
questions for a discourse within the process automation community.

</details>


### [10] [Contract-based Verification of Digital Twins](https://arxiv.org/abs/2506.10993)
*Muhammad Naeem,Cristina Seceleanu*

Main category: cs.SE

TL;DR: 本文提出了一种创新的黑盒验证方法，通过将模型检查集成到过程中，验证基于神经网络的数字孪生模型。


<details>
  <summary>Details</summary>
Motivation: 数字孪生在工业应用中日益重要，但其验证因大数据集而具有挑战性。

Method: 开发自动化解决方案，通过模拟数字孪生模型输入，将预测输出与输入输入到UPPAAL模型检查器中，验证是否满足系统级合约。

Result: 在锅炉系统案例中，通过合约验证识别了预测错误。

Conclusion: 模型检查与数字孪生模型的结合对持续改进具有显著效果。

Abstract: Digital twins are becoming powerful tools in industrial applications,
offering virtual representations of cyber-physical systems. However,
verification of these models remains a significant challenge due to the
potentially large datasets used by the digital twin. This paper introduces an
innovative methodology for verifying neural network-based digital twin models,
in a black-box fashion, by integrating model checking into the process. The
latter relies on defining and applying system-level contracts that capture the
system's requirements, to verify the behavior of digital twin models,
implemented in Simulink. We develop an automated solution that simulates the
digital twin model for certain inputs, and feeds the predicted outputs together
with the inputs to the contract model described as a network of timed automata
in the UPPAAL model checker. The latter verifies whether the predicted outputs
fulfill the specified contracts. This approach allows us to identify scenarios
where the digital twin's behavior fails to meet the contracts, without
requiring the digital twin's design technicalities. We apply our method to a
boiler system case study for which we identify prediction errors via contract
verification. Our work demonstrates the effectiveness of integrating model
checking with digital twin models for continuous improvement.

</details>


### [11] [Improving Software Team Communication Through Social Interventions in Project Management Tools](https://arxiv.org/abs/2506.10994)
*April Clarke*

Main category: cs.SE

TL;DR: 研究旨在通过社交网络分析开发项目管理工具功能，帮助学生改善软件工程团队中的沟通与协作行为。


<details>
  <summary>Details</summary>
Motivation: 软件工程团队常因沟通与协作不足影响项目成功，而大学项目课程是学生练习这些技能的机会，但缺乏有效指导方法。

Method: 首先评估社交网络分析技术对识别团队沟通改进领域的适用性，随后开发工具功能并在软件工程小组项目中评估。

Result: 预期开发出能帮助学生识别和解决沟通问题的项目管理工具功能。

Conclusion: 通过社交网络分析指导的工具功能有望提升学生在软件工程项目中的沟通与协作能力。

Abstract: Productive software engineering teams require effective communication and
balanced contributions between team members. However, teams are often
ineffective at these skills, which is detrimental to project success.
Project-based university courses are an opportunity for students to practise
these skills, but we have yet to establish how we can guide students towards
improving their communication and coordination. We aim to develop project
management tool features, informed by social network analysis, that nudge
students in software engineering group projects towards beneficial behaviours.
To do this, we will first evaluate the suitability of social network analysis
techniques for identifying areas of improvement in teams' communication. Then,
we will develop features in a project management tool that aid students in
identifying and addressing these areas of improvement, and evaluate them in the
context of a software engineering group project.

</details>


### [12] [Evaluating Small-Scale Code Models for Code Clone Detection](https://arxiv.org/abs/2506.10995)
*Jorge Martinez-Gil*

Main category: cs.SE

TL;DR: 本文研究了小型代码模型在检测代码克隆中的性能，评估了六种模型在五个数据集上的表现，发现大多数模型表现良好，但仍存在部分难以检测的克隆情况。


<details>
  <summary>Details</summary>
Motivation: 代码克隆检测对软件维护和重构至关重要，但结构相似性不反映功能等价时仍存在挑战，因此需要系统评估新型小型代码模型的性能。

Method: 使用五个数据集（BigCloneBench、CodeJam、Karnalim、POJ104、PoolC）和六种代码模型（CodeBERT、GraphCodeBERT、Salesforce T5、UniXCoder、PLBART、Polycoder）进行性能评估。

Result: 大多数模型在准确率、精确率、召回率和F1分数等标准指标上表现良好，但仍有少量克隆难以检测，尤其是代码相似但功能不同的情况。

Conclusion: 小型代码模型在代码克隆检测中表现优异，但仍需改进以解决功能不同但结构相似的克隆检测问题。

Abstract: Detecting code clones is relevant to software maintenance and code
refactoring. This challenge still presents unresolved cases, mainly when
structural similarity does not reflect functional equivalence, though recent
code models show promise. Therefore, this research aims to systematically
measure the performance of several newly introduced small code models in
classifying code pairs as clones or non-clones. The evaluation is based on five
datasets: BigCloneBench, CodeJam, Karnalim, POJ104, and PoolC, as well as six
code models: CodeBERT, GraphCodeBERT, Salesforce T5, UniXCoder, PLBART, and
Polycoder. Most models performed well across standard metrics, including
accuracy, precision, recall, and F1-score. However, a marginal fraction of
clones remains challenging to detect, especially when the code looks similar
but performs different operations. The source code that illustrates our
approach is available at:
https://github.com/jorge-martinez-gil/small-code-models

</details>


### [13] [Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox](https://arxiv.org/abs/2506.11022)
*Shivani Shukla,Himanshu Joshi,Romilla Syed*

Main category: cs.SE

TL;DR: 研究发现，通过LLM迭代生成的代码安全漏洞增加了37.6%，挑战了迭代改进能提升代码安全的假设，并强调了人工验证的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM迭代反馈对代码安全漏洞的影响，填补研究空白。

Method: 通过400个代码样本和40轮改进实验，使用四种提示策略分析安全退化。

Result: 五轮迭代后，关键漏洞增加了37.6%，不同提示策略导致不同的漏洞模式。

Conclusion: 迭代LLM改进可能引入新安全问题，需加强人工验证，并提出实用指南以降低风险。

Abstract: The rapid adoption of Large Language Models(LLMs) for code generation has
transformed software development, yet little attention has been given to how
security vulnerabilities evolve through iterative LLM feedback. This paper
analyzes security degradation in AI-generated code through a controlled
experiment with 400 code samples across 40 rounds of "improvements" using four
distinct prompting strategies. Our findings show a 37.6% increase in critical
vulnerabilities after just five iterations, with distinct vulnerability
patterns emerging across different prompting approaches. This evidence
challenges the assumption that iterative LLM refinement improves code security
and highlights the essential role of human expertise in the loop. We propose
practical guidelines for developers to mitigate these risks, emphasizing the
need for robust human validation between LLM iterations to prevent the
paradoxical introduction of new security issues during supposedly beneficial
code "improvements".

</details>


### [14] [Evaluating LLMs for Visualization Tasks](https://arxiv.org/abs/2506.10996)
*Saadiq Rauf Khan,Vinit Chandak,Sougata Mukherjea*

Main category: cs.SE

TL;DR: 该论文探讨了大型语言模型（LLMs）在生成可视化代码和理解常见可视化方面的能力，并指出了其局限性。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在信息可视化领域的潜力，探索其能否通过简单提示生成可视化代码并理解常见可视化。

Method: 使用不同流行的LLMs，基于简单提示生成可视化代码，并测试其回答关于常见可视化问题的能力。

Result: LLMs能够生成部分可视化代码并回答相关问题，但也存在一些局限性。

Conclusion: 研究结果为改进LLMs和信息可视化系统提供了有价值的见解。

Abstract: Information Visualization has been utilized to gain insights from complex
data. In recent times, Large Language Models (LLMs) have performed very well in
many tasks. In this paper, we showcase the capabilities of different popular
LLMs to generate code for visualization based on simple prompts. We also
analyze the power of LLMs to understand some common visualizations by answering
simple questions. Our study shows that LLMs could generate code for some
visualizations as well as answer questions about them. However, LLMs also have
several limitations. We believe that our insights can be used to improve both
LLMs and Information Visualization systems.

</details>


### [15] [A Theory-driven Interpretation and Elaboration of Verification and Validation](https://arxiv.org/abs/2506.10997)
*Hanumanthrao Kannan,Alejandro Salado*

Main category: cs.SE

TL;DR: 本文提出了一种基于动态认知模态逻辑的系统工程中验证与确认（V&V）的形式化理论，强调V&V是知识构建活动。


<details>
  <summary>Details</summary>
Motivation: 传统V&V实践存在模糊性，需形式化理论以提升系统工程方法的精确性和一致性。

Method: 使用动态认知模态逻辑，定义V&V的精确角色，形式化知识状态、证据和推理过程的交互。

Result: 推导出阐明V&V概念基础的定理，为系统工程提供结构化框架。

Conclusion: 该理论为学术研究和实际应用提供了对V&V作为工程知识生成关键组成部分的深入理解。

Abstract: This paper presents a formal theory of verification and validation (V&V)
within systems engineering, grounded in the axiom that V&V are fundamentally
knowledge-building activities. Using dynamic epistemic modal logic, we develop
precise definitions of verification and validation, articulating their roles in
confirming and contextualizing knowledge about systems. The theory formalizes
the interplay between epistemic states, evidence, and reasoning processes,
allowing for the derivation of theorems that clarify the conceptual
underpinnings of V&V. By providing a formal foundation, this work addresses
ambiguities in traditional V&V practices, offering a structured framework to
enhance precision and consistency in systems engineering methodologies. The
insights gained have implications for both academic research and practical
applications, fostering a deeper understanding of V&V as critical components of
engineering knowledge generation.

</details>


### [16] [Towards Automated Formal Verification of Backend Systems with LLMs](https://arxiv.org/abs/2506.10998)
*Kangping Xu,Yifan Luo,Yang Yuan,Andrew Chi-Chih Yao*

Main category: cs.SE

TL;DR: 提出了一种利用函数式编程和类型系统将Scala后端代码转换为形式化Lean表示的新框架，自动生成定理并通过LLM验证，验证成功则无需测试，失败则确认错误，无法验证需人工干预。实验表明可自动化50%测试需求，成本低且可扩展。


<details>
  <summary>Details</summary>
Motivation: 现有自动化测试方法在测试局部性、通用可靠性和业务逻辑盲区方面存在不足，无法匹敌人工程师能力。

Method: 将Scala代码转为Lean形式化表示，自动生成定理并通过LLM验证，验证结果分为成功（无需测试）、失败（确认错误）或需人工干预。

Result: 实验验证了50%的测试需求，每个API平均成本仅2.19美元，显著优于人工测试且易于扩展。

Conclusion: 该方法为可扩展的AI驱动软件测试提供了有前景的方向，有望大幅提升工程效率。

Abstract: Software testing plays a critical role in ensuring that systems behave as
intended. However, existing automated testing approaches struggle to match the
capabilities of human engineers due to key limitations such as test locality,
lack of general reliability, and business logic blindness. In this work, we
propose a novel framework that leverages functional programming and type
systems to translate Scala backend code into formal Lean representations. Our
pipeline automatically generates theorems that specify the intended behavior of
APIs and database operations, and uses LLM-based provers to verify them. When a
theorem is proved, the corresponding logic is guaranteed to be correct and no
further testing is needed. If the negation of a theorem is proved instead, it
confirms a bug. In cases where neither can be proved, human intervention is
required. We evaluate our method on realistic backend systems and find that it
can formally verify over 50% of the test requirements, which suggests that half
of a testing engineer's workload can be automated. Additionally, with an
average cost of only $2.19 per API, LLM-based verification is significantly
more cost-effective than manual testing and can be scaled easily through
parallel execution. Our results indicate a promising direction for scalable,
AI-powered software testing, with the potential to greatly improve engineering
productivity as models continue to advance.

</details>


### [17] [Automated Validation of COBOL to Java Transformation](https://arxiv.org/abs/2506.10999)
*Atul Kumar,Diptikalyan Saha,Toshikai Yasue,Kohichi Ono,Saravanan Krishnan,Sandeep Hans,Fumiko Satoh,Gerald Mitchell,Sachin Kumar*

Main category: cs.SE

TL;DR: 提出了一种基于符号执行的测试生成框架，用于验证COBOL到Java代码转换的正确性，并通过生成等效的JUnit测试用例检查语义等价性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM生成的代码转换结果令人鼓舞，但无法确保其正确性，因此需要一种验证和修复机制。

Method: 开发了基于符号执行的测试生成工具，自动为COBOL程序生成单元测试，并模拟外部资源调用，生成等效的JUnit测试用例以验证语义等价性。

Result: 通过生成的测试用例验证了转换后代码的语义等价性，并提供修复和反馈机制。

Conclusion: 该框架有效验证了代码转换的正确性，并为LLM模型提供了改进反馈。

Abstract: Recent advances in Large Language Model (LLM) based Generative AI techniques
have made it feasible to translate enterpriselevel code from legacy languages
such as COBOL to modern languages such as Java or Python. While the results of
LLM-based automatic transformation are encouraging, the resulting code cannot
be trusted to correctly translate the original code. We propose a framework and
a tool to help validate the equivalence of COBOL and translated Java. The
results can also help repair the code if there are some issues and provide
feedback to the AI model to improve. We have developed a
symbolic-execution-based test generation to automatically generate unit tests
for the source COBOL programs which also mocks the external resource calls. We
generate equivalent JUnit test cases with equivalent mocking as COBOL and run
them to check semantic equivalence between original and translated programs.

</details>


### [18] [Ever-Improving Test Suite by Leveraging Large Language Models](https://arxiv.org/abs/2506.11000)
*Ketai Qiu*

Main category: cs.SE

TL;DR: E-Test利用大型语言模型增量扩充测试套件，覆盖生产中未测试行为，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为长期软件系统维持质量，需补充反映实际使用情况的测试用例。

Method: 利用大型语言模型识别已测试、未测试及易错单元执行场景，增量扩充测试套件。

Result: 实验表明E-Test在识别未充分测试行为和优化测试套件方面优于现有方法。

Conclusion: E-Test能有效提升测试套件的覆盖率和质量。

Abstract: Augmenting test suites with test cases that reflect the actual usage of the
software system is extremely important to sustain the quality of long lasting
software systems. In this paper, we propose E-Test, an approach that
incrementally augments a test suite with test cases that exercise behaviors
that emerge in production and that are not been tested yet. E-Test leverages
Large Language Models to identify already-tested, not-yet-tested, and
error-prone unit execution scenarios, and augment the test suite accordingly.
Our experimental evaluation shows that E-Test outperforms the main
state-of-the-art approaches to identify inadequately tested behaviors and
optimize test suites.

</details>


### [19] [Rethinking Technological Readiness in the Era of AI Uncertainty](https://arxiv.org/abs/2506.11001)
*S. Tucker Browne,Mark M. Bailey*

Main category: cs.SE

TL;DR: 提出了一种新的AI准备框架，用于评估军事系统中AI组件的成熟度和可信度，以解决现有技术准备评估未能涵盖AI特定因素的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的技术准备评估未能充分捕捉AI特有的关键因素，导致部署时存在潜在风险。

Method: 提出了一个类似于传统技术准备水平（TRL）但针对AI扩展的框架，结合现有数据评估工具和测试实践。

Result: 展示了该框架在短期内实施的可行性，为军事决策者提供了更清晰的AI系统性能、透明度和人机整合标准。

Conclusion: 该框架有助于提升国防技术管理和风险评估，确保AI系统在军事应用中的可靠性和安全性。

Abstract: Artificial intelligence (AI) is poised to revolutionize military combat
systems, but ensuring these AI-enabled capabilities are truly mission-ready
presents new challenges. We argue that current technology readiness assessments
fail to capture critical AI-specific factors, leading to potential risks in
deployment. We propose a new AI Readiness Framework to evaluate the maturity
and trustworthiness of AI components in military systems. The central thesis is
that a tailored framework - analogous to traditional Technology Readiness
Levels (TRL) but expanded for AI - can better gauge an AI system's reliability,
safety, and suitability for combat use. Using current data evaluation tools and
testing practices, we demonstrate the framework's feasibility for near-term
implementation. This structured approach provides military decision-makers with
clearer insight into whether an AI-enabled system has met the necessary
standards of performance, transparency, and human integration to be deployed
with confidence, thus advancing the field of defense technology management and
risk assessment.

</details>


### [20] [Notes On Writing Effective Empirical Software Engineering Papers: An Opinionated Primer](https://arxiv.org/abs/2506.11002)
*Roberto Verdecchia,Justus Bogner*

Main category: cs.SE

TL;DR: 本文为实证软件工程（ESE）研究提供科学写作指南，旨在帮助初学者和有经验的研究者。


<details>
  <summary>Details</summary>
Motivation: 实证软件工程领域的科学写作实践缺乏系统讨论，但却是会议和期刊的评估标准之一。作者希望通过个人经验提供实用建议。

Method: 作者基于自身经验，为BSc、MSc和PhD学生等目标群体提供主观但实用的写作建议。

Result: 作者认为其写作方法在实践中表现良好，并希望指南能对他人有所帮助。

Conclusion: 本文是一份主观但实用的写作指南，适用于实证软件工程领域的研究者。

Abstract: While mastered by some, good scientific writing practices within Empirical
Software Engineering (ESE) research appear to be seldom discussed and
documented. Despite this, these practices are implicit or even explicit
evaluation criteria of typical software engineering conferences and journals.
In this pragmatic, educational-first document, we want to provide guidance to
those who may feel overwhelmed or confused by writing ESE papers, but also
those more experienced who still might find an opinionated collection of
writing advice useful. The primary audience we had in mind for this paper were
our own BSc, MSc, and PhD students, but also students of others. Our documented
advice therefore reflects a subjective and personal vision of writing ESE
papers. By no means do we claim to be fully objective, generalizable, or
representative of the whole discipline. With that being said, writing papers in
this way has worked pretty well for us so far. We hope that this guide can at
least partially do the same for others.

</details>


### [21] [EmbedAgent: Benchmarking Large Language Models in Embedded System Development](https://arxiv.org/abs/2506.11003)
*Ruiyang Xu,Jialun Cao,Mingyuan Wu,Wenliang Zhong,Yaojie Lu,Ben He,Xianpei Han,Shing-Chi Cheung,Le Sun*

Main category: cs.SE

TL;DR: 论文提出了EmbedAgent和Embedbench，用于评估大语言模型在嵌入式系统开发中的能力，发现其表现参差不齐，并提出两种改进策略。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在嵌入式系统开发领域的评估不足，需要更全面的测试方法。

Method: 通过EmbedAgent模拟嵌入式系统开发角色，使用Embedbench（包含126个案例）评估10种主流大语言模型。

Result: 模型表现差异显著，DeepSeek-R1在提供电路图时通过率为55.6%，无图时为50.0%；跨平台任务中，MicroPython表现较好（73.8%），ESP-IDF较差（29.4%）。

Conclusion: 提出检索增强生成和编译器反馈策略，显著提升了模型性能。

Abstract: Large Language Models (LLMs) have shown promise in various tasks, yet few
benchmarks assess their capabilities in embedded system development.In this
paper, we introduce EmbedAgent, a paradigm designed to simulate real-world
roles in embedded system development, such as Embedded System Programmer,
Architect, and Integrator. This paradigm enables LLMs to be tested in tasks
that bridge the gap between digital and physical systems, allowing for a more
comprehensive assessment of their capabilities. To evaluate LLMs on these
tasks, we propose Embedbench, the first comprehensive benchmark for embedded
system programming, circuit design, and cross-platform migration.Embedbench
consists of 126 cases, covering 9 electronic components across 3 hardware
platforms. Through extensive experiments on 10 mainstream LLMs, we uncover
several key findings. Surprisingly, despite the simplicity of the cases,
DeepSeek-R1 achieves only a 55.6% pass@1 rate when provided with schematic
information, and 50.0% when tasked with generating the schematics itself. In
the cross-platform migration tasks, LLMs show relatively strong performance
with MicroPython on the Raspberry Pi Pico (with the top model achieving 73.8%
pass@1), but perform poorly on ESP-IDF, where the best model reaches only 29.4%
pass@1.Interestingly, we observe that general-purpose chat LLMs like
DeepSeek-V3 often fail to utilize relevant pre-trained knowledge in this
domain, while reasoning LLMs tend to overthink and overlook efficient knowledge
during pretraining. Based on these insights, we propose two strategies:
retrieval augmented generation and compiler feedback-to enhance LLM
performance. These strategies result in significant improvements, with
Deepseek-R1 reaching a 65.1% pass@1 with correct schematics, and 53.1% without.
Additionally, the accuracy of the Arduino to ESP32 migration task improves from
21.4% to 27.8%.

</details>


### [22] [Automated Extraction and Analysis of Developer's Rationale in Open Source Software](https://arxiv.org/abs/2506.11005)
*Mouna Dhaouadi,Bentley Oakes,Michalis Famelis*

Main category: cs.SE

TL;DR: 提出了一种基于Kantara架构的自动化方法，用于开源项目的理由分析，通过预训练模型和大语言模型检测设计冲突和推理问题。


<details>
  <summary>Details</summary>
Motivation: 开源贡献者需理解项目历史以避免冲突，但现有方法依赖人工，缺乏自动化工具。

Method: 基于Kantara架构，结合预训练模型和大语言模型，设计结构机制检测冲突和设计侵蚀。

Result: 在Linux内核等项目上验证了方法的可行性，能有效发现潜在冲突和推理问题。

Conclusion: 自动化方法可帮助开发者主动解决隐藏问题，确保新变更与历史决策一致。

Abstract: Contributors to open source software must deeply understand a project's
history to make coherent decisions which do not conflict with past reasoning.
However, inspecting all related changes to a proposed contribution requires
intensive manual effort, and previous research has not yet produced an
automated mechanism to expose and analyze these conflicts. In this article, we
propose such an automated approach for rationale analyses, based on an
instantiation of Kantara, an existing high-level rationale extraction and
management architecture. Our implementation leverages pre-trained models and
Large Language Models, and includes structure-based mechanisms to detect
reasoning conflicts and problems which could cause design erosion in a project
over time. We show the feasibility of our extraction and analysis approach
using the OOM-Killer module of the Linux Kernel project, and investigate the
approach's generalization to five other highly active open source projects. The
results confirm that our automated approach can support rationale analyses with
reasonable performance, by finding interesting relationships and to detect
potential conflicts and reasoning problems. We also show the effectiveness of
the automated extraction of decision and rationale sentences and the prospects
for generalizing this to other open source projects. This automated approach
could therefore be used by open source software developers to proactively
address hidden issues and to ensure that new changes do not conflict with past
decisions.

</details>


### [23] [Test code generation at Ericsson using Program Analysis Augmented Fine Tuned LLMs](https://arxiv.org/abs/2506.11006)
*Sai Krishna,Balvinder Singh,Sujoy Roychowdhury,Giriprasad Sridhara,Sourav Mazumdar,Magnus Sandelin,Dimitris Rentas,Maciej Nalepa,Karol Sawicki,Jakub Gajda*

Main category: cs.SE

TL;DR: 论文描述了在爱立信中使用大型语言模型（LLM）生成测试代码的方法，通过检索增强生成（RAG）和提示工程优化生成结果，并通过微调模型进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决直接提示LLM生成测试代码时假设不存在的函数和签名的问题，提高生成代码与开发者编写代码的一致性。

Method: 结合RAG和提示工程扩展上下文信息，并通过静态程序分析优化提示；进一步微调LLM，使用自定义提示模板和RAG生成的示例输出。

Result: 微调后的8x7b混合专家（MoE）模型比基础模型平均提升8%，性能接近更大的8x22b MoE模型。

Conclusion: 通过RAG、提示工程和微调，显著提升了LLM生成测试代码的准确性和一致性。

Abstract: We describe test code generation using Large Language Models (LLMs) in
Ericsson. Our input is a test step in natural language (English) and our output
is code (Java) which accomplishes the test step. We describe how straight
forward prompting does not suffice and results in LLM assuming functions and
signatures which are not present in the code repository. We then show how we
alleviate the problem by a combination of Retrieval Augmented Generation (RAG)
along with prompt engineering that expanded the simple prompt with additional
contextual information using static program analysis. We then describe further
improvements that we obtained by fine-tuning the underlying LLM. The fine
tuning is done based on a custom designed prompt template which has
pre-dependent classes, their public methods as well two exemplar outputs
obtained from RAG. Our results establish that our fine tuned models help
improve the correspondence or conformity with the original developer written
test code as measured by the traditional metrics of F1-score based on the
methods used in the generated code. Fine tuning of a 8x7b Mixture of Experts
(MoE) model leads to an average improvement of 8\% over the base model and is
comparable to the scores on a much larger 8x22b MoE model.

</details>


### [24] [Impact of Comments on LLM Comprehension of Legacy Code](https://arxiv.org/abs/2506.11007)
*Rock Sabetto,Emily Escamilla,Devesh Agarwal,Sujay Kandwal,Justin F. Brunelle,Scott Rosen,Nitin Naik,Samruddhi Thaker,Eric O. Scott,Jacob Zimmer,Amit Madan,Arun Sridharan,Doug Wendt,Michael Doyle,Christopher Glasz,Jasper Phillips,William Macke,Colin Diggs,Michael Bartholf,Zachary Robin,Paul Ursino*

Main category: cs.SE

TL;DR: 该论文探讨了大型语言模型（LLMs）在理解遗留代码方面的能力，并提出了一种基于多选问答（MCQA）的客观评估方法。


<details>
  <summary>Details</summary>
Motivation: 由于LLMs在现代编程任务中表现出色，但其对遗留语言的理解能力尚不明确，尤其是在缺乏或不准确的文档情况下，因此需要一种客观的评估方法。

Method: 采用多选问答（MCQA）方法，评估LLMs对遗留代码的理解能力，并研究文档的普遍性和准确性对其的影响。

Result: 初步结果显示文档对LLMs理解遗留代码有显著影响，并提出了未来研究的战略目标。

Conclusion: 论文强调了文档质量对LLMs理解遗留代码的重要性，并提出了进一步研究的框架。

Abstract: Large language models (LLMs) have been increasingly integrated into software
engineering and maintenance tasks due to their high performance with software
engineering tasks and robust understanding of modern programming languages.
However, the ability of LLMs to comprehend code written with legacy languages
remains a research gap challenged by real-world legacy systems lacking or
containing inaccurate documentation that may impact LLM comprehension. To
assess LLM comprehension of legacy languages, there is a need for objective LLM
evaluation. In order to objectively measure LLM comprehension of legacy
languages, we need an efficient, quantitative evaluation method. We leverage
multiple-choice question answering (MCQA), an emerging LLM evaluation
methodology, to evaluate LLM comprehension of legacy code and the impact of
comment prevalence and inaccurate comments. In this work, we present
preliminary findings on the impact of documentation on LLM comprehension of
legacy code and outline strategic objectives for future work.

</details>


### [25] [Encoding Software For Perpetuity: A Compact Representation Of Apollo 11 Guidance Code](https://arxiv.org/abs/2506.11008)
*David Noever*

Main category: cs.SE

TL;DR: 将阿波罗11号登月舱导航计算机代码压缩为单个QR码，实现历史软件的高效保存与传播。


<details>
  <summary>Details</summary>
Motivation: 解决历史重要软件在现代移动设备上的可访问性问题，无需专用硬件或网络连接。

Method: 通过标记化、选择性内容保留和最小化HTML/JavaScript技术，将原始汇编语言代码压缩为3KB的QR码。

Result: 成功压缩关键代码为可扫描、可分享的QR码，评估了多种压缩策略的权衡。

Conclusion: 该方法为计算遗产保护提供了一种补充方案，通过现代移动技术实现历史软件的即时访问。

Abstract: This brief note presents a novel method for encoding historic Apollo 11 Lunar
Module guidance computer code into a single, compact Quick Response Code (QR
code) format, creating an accessible digital artifact for transmission and
archival purposes. By applying tokenization, selective content preservation,
and minimal HTML/JavaScript techniques, we successfully compressed key
components of the original Assembly Language Code (AGC) into a shareable,
preservable, and scannable 3 kilobyte (KB) image. We evaluate multiple
compression strategies and their tradeoffs in terms of size, readability, and
historical significance. This method addresses the challenge of making
historically significant software artifacts available through modern mobile
devices without requiring specialized hardware or internet connectivity. While
numerous digital preservation methods exist for historic software, this
approach balances accessibility with historical significance, offering a
complementary method to traditional archival techniques. This work contributes
to the broader field of computing heritage preservation by demonstrating how
landmark software can be made accessible instantly through contemporary mobile
technologies.

</details>


### [26] [Human-In-The-Loop Software Development Agents: Challenges and Future Directions](https://arxiv.org/abs/2506.11009)
*Jirat Pasuksmit,Wannita Takerngsaksiri,Patanamon Thongtanunam,Chakkrit Tantithamthavorn,Ruixiong Zhang,Shiyan Wang,Fan Jiang,Jing Li,Evan Cook,Kun Chen,Ming Wu*

Main category: cs.SE

TL;DR: 论文探讨了多智能体LLM驱动系统在软件开发中的应用，重点分析了计算成本高和评估不一致的问题，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过Human-in-the-Loop方法提升软件开发效率，并解决现有评估框架的不足。

Method: 使用功能正确性测试和基于GPT的相似性评分评估生成的代码质量。

Result: 发现单元测试的高计算成本和LLM评估的不一致性是主要挑战。

Conclusion: 未来研究应优化评估框架，以提升Human-in-the-Loop工具的效果。

Abstract: Multi-agent LLM-driven systems for software development are rapidly gaining
traction, offering new opportunities to enhance productivity. At Atlassian, we
deployed Human-in-the-Loop Software Development Agents to resolve Jira work
items and evaluated the generated code quality using functional correctness
testing and GPT-based similarity scoring. This paper highlights two major
challenges: the high computational costs of unit testing and the variability in
LLM-based evaluations. We also propose future research directions to improve
evaluation frameworks for Human-In-The-Loop software development tools.

</details>


### [27] [Enhancing Inventory Management with Progressive Web Applications (PWAs): A Scalable Solution for Small and Large Enterprises](https://arxiv.org/abs/2506.11011)
*Abhi Desai*

Main category: cs.SE

TL;DR: 本文探讨了如何利用渐进式网络应用（PWA）技术优化库存管理，提出了一种集成了条码扫描、地理定位等功能的应用方案，并分析了其优缺点。


<details>
  <summary>Details</summary>
Motivation: 高效的库存管理对大小企业都至关重要，但传统解决方案成本高且不够灵活，因此需要一种更高效、低成本的替代方案。

Method: 开发并实现了一个PWA应用，集成了条码扫描、地理定位等功能，并测试了其离线能力和跨平台适应性。

Result: PWA在库存管理中表现出色，具备离线功能和跨平台优势，但性能略逊于原生应用。

Conclusion: PWA为库存管理提供了一种可扩展且经济高效的解决方案，未来开发者可参考本研究进一步优化企业应用。

Abstract: Efficient inventory management is crucial for both small and large
enterprises to optimize operational workflows and reduce overhead costs. This
paper explores the development and implementation of a Progressive Web
Application (PWA) designed to enhance the inventory management experience. The
application integrates key functionalities such as barcode and QR code
scanning, geolocation-based warehouse identification, and cross-device
accessibility. By leveraging PWA technology, the solution ensures offline
capabilities, responsive user experience, and seamless adaptability across
various platforms. The study discusses the challenges and benefits of
implementing PWA in inventory management systems, including its limitations in
performance compared to native applications. Insights from the development
process provide a roadmap for future developers looking to integrate PWA
technology into enterprise applications. This research contributes to the
growing domain of web-based inventory solutions, offering a scalable and
cost-effective alternative to traditional inventory management software.

</details>


### [28] [Toward a Brazilian Research Agenda in Quantum Software Engineering: A Systematic Mapping Study](https://arxiv.org/abs/2506.11013)
*Filipe Fernandes,Cláudia Werner*

Main category: cs.SE

TL;DR: 该研究通过系统映射研究分析了量子软件工程（QSE）的现状，发现其仍处于发展阶段，缺乏标准化方法和实证研究，并提出了巴西研究议程以推动该领域发展。


<details>
  <summary>Details</summary>
Motivation: 量子软件工程（QSE）领域知识分散，缺乏标准化方法和工具，且巴西等国家参与有限，研究旨在填补这一空白并指导未来研究。

Method: 采用系统映射研究方法，基于纳入和排除标准分析文献，并按研究类型、研究方法和SWEBOK知识领域分类。

Result: 多数研究为英文初级研究文章，集中于软件工程模型、架构和测试，技术方案为主，实证研究较少。

Conclusion: QSE是一个有前景但尚未成熟的领域，需标准化实践、扩展实证研究并纳入发展中国家研究者。研究提出了巴西QSE研究议程以推动本地科学发展。

Abstract: Context: Quantum Software Engineering (QSE) has emerged as a key field to
support the development of reliable, maintainable, and scalable quantum
applications, bridging advances in quantum computing with established practices
in software engineering. Problem: Despite its growth, the field still suffers
from fragmented knowledge, with a lack of standardized methodologies, tools,
and guidelines tailored to the unique features of the quantum paradigm.
Additionally, countries like Brazil have had limited participation in the
development of this emerging domain. Objective: This study aims to map the
state of the art in QSE by identifying current research trends, recurring
contributions, and existing gaps that can guide future investigations and
strategic initiatives. Methodology: A systematic mapping study was conducted
analyzing selected publications based on inclusion and exclusion criteria.
Articles were categorized by study type, research type, and alignment with the
SWEBOK knowledge areas. Results: Most of the reviewed studies are primary
research articles written in English, with a strong focus on Software
Engineering Models and Methods, Software Architecture, and Software Testing.
Conceptual proposals and technical solutions predominate, while empirical
validations remain limited. Conclusions: Findings confirm that QSE is a
promising but still maturing field. The standardization of practices, expansion
of empirical studies, and inclusion of researchers from developing countries
are crucial for advancing the discipline. Additionally, Brazilian contributions
are still scarce, highlighting the urgent need to establish a national research
agenda. As a main contribution, this study proposes a Brazilian Research Agenda
in QSE, outlining priority areas and opportunities to foster a local scientific
community and accelerate progress in this emerging field.

</details>


### [29] [MultiMind: A Plug-in for the Implementation of Development Tasks Aided by AI Assistants](https://arxiv.org/abs/2506.11014)
*Benedetta Donato,Leonardo Mariani,Daniela Micucci,Oliviero Riganelli,Marco Somaschini*

Main category: cs.SE

TL;DR: MultiMind是一个Visual Studio Code插件，旨在简化AI辅助开发任务的创建，解决IDE中嵌入AI助手时的挑战。


<details>
  <summary>Details</summary>
Motivation: AI助手在软件开发中的应用日益广泛，但如何将其无缝集成到开发工作流中仍面临挑战。

Method: MultiMind提供了一个模块化和可扩展的框架，支持开发者低成本实现和实验新的AI交互功能。

Result: MultiMind已在两个用例中测试：自动生成代码注释和定义AI驱动的聊天功能。

Conclusion: MultiMind为开发者提供了一种高效且灵活的方式，将AI助手集成到开发工作流中。

Abstract: The integration of AI assistants into software development workflows is
rapidly evolving, shifting from automation-assisted tasks to collaborative
interactions between developers and AI. Large Language Models (LLMs) have
demonstrated their effectiveness in several development activities, including
code completion, test case generation, and documentation production. However,
embedding AI-assisted tasks within Integrated Development Environments (IDEs)
presents significant challenges. It requires designing mechanisms to invoke AI
assistants at the appropriate time, coordinate interactions with multiple
assistants, process the generated outputs, and present feedback in a way that
seamlessly integrates with the development workflow. To address these issues,
we introduce MultiMind, a Visual Studio Code plug-in that streamlines the
creation of AI-assisted development tasks. MultiMind provides a modular and
extensible framework, enabling developers to cost-effectively implement and
experiment with new AI-powered interactions without the need for complex IDE
customizations. MultiMind has been tested in two use cases: one for the
automatic generation of code comments and the other about the definition of
AI-powered chat.

</details>


### [30] [ZjsComponent: A Pragmatic Approach to Modular, Reusable UI Fragments for Web Development](https://arxiv.org/abs/2506.11016)
*Lelanthran Manickum*

Main category: cs.SE

TL;DR: ZjsComponent是一个轻量级、框架无关的Web组件，用于创建模块化、可复用的UI元素，无需构建步骤或依赖。


<details>
  <summary>Details</summary>
Motivation: 解决传统组件开发中需要构建步骤、依赖特定生态系统的问题，提供更简单、灵活的组件开发方式。

Method: 通过纯HTML实现组件和对象实例，支持动态加载和隔离HTML+JS片段，提供生命周期钩子和类方法。

Result: 实现了依赖自由、DOM和代码隔离的轻量级组件，支持动态加载和复用。

Conclusion: ZjsComponent为开发者提供了一种简单、灵活且无需依赖的组件开发方案。

Abstract: In this paper, I present ZjsComponent, a lightweight and framework-agnostic
web component designed for creating modular, reusable UI elements with minimal
developer overhead. ZjsComponent is an example implementation of an approach to
creating components and object instances that can be used purely from HTML.
Unlike traditional approaches to components, the approach implemented by
ZjsComponent does not require build-steps, transpiling, pre-compilation, any
specific ecosystem or any other dependency. All that is required is that the
browser can load and execute Javascript as needed by Web Components.
ZjsComponent allows dynamic loading and isolation of HTML+JS fragments,
offering developers a simple way to build reusable interfaces with ease. This
approach is dependency-free, provides significant DOM and code isolation, and
supports simple lifecycle hooks as well as traditional methods expected of an
instance of a class.

</details>


### [31] [Formation of requirements traceability in the process of information systems design](https://arxiv.org/abs/2506.11018)
*Grigory Tsiperman*

Main category: cs.SE

TL;DR: 论文提出了一种基于自适应聚类方法（ACM）的需求可追溯性解决方案，以解决其在信息系统设计过程中的集成问题。


<details>
  <summary>Details</summary>
Motivation: 需求可追溯性是信息系统设计中的关键质量特性，但其集成到设计过程中仍是一个挑战。

Method: 采用作者开发的自适应聚类方法（ACM），通过无缝系统架构实现不同抽象层次项目工件的显式互连。

Result: ACM方法能够显式连接项目工件，从而简化系统设计并减少对开发者的依赖。

Conclusion: ACM方法为需求可追溯性提供了有效的集成方案，有助于提升系统设计的质量和效率。

Abstract: The traceability of requirements in the information system design process is
considered an essential property of the project, one of its quality
characteristics. The point here is that traceability provides the methods of
validation and verification of software systems, and that the system model
based on requirements traceability reduces the system's dependence on
developers and, in general, makes it as straightforward as possible. One of the
challenges of the traceability process, dubbed "The grand challenge of
traceability" among traceability researchers, is its integration into the
design process. In this paper, to achieve this goal, we propose the application
of the Adaptive Clustering Method (ACM) of Information Systems developed by the
author, which is based on the idea of a seamless system architecture that
provides explicit interconnection of project artifacts of different levels of
abstraction.

</details>


### [32] [Mind the Metrics: Patterns for Telemetry-Aware In-IDE AI Application Development using the Model Context Protocol (MCP)](https://arxiv.org/abs/2506.11019)
*Vincent Koc,Jacques Verre,Douglas Blank,Abigail Morgan*

Main category: cs.SE

TL;DR: 论文提出了一种基于模型上下文协议（MCP）的遥测感知集成开发环境（IDE），支持实时优化和反馈，适用于AI开发工作流。


<details>
  <summary>Details</summary>
Motivation: 随着AI开发环境向可观测性优先的平台发展，需要一种能够集成实时遥测、提示跟踪和评估反馈的系统，以提升开发效率。

Method: 通过MCP系统连接IDE与提示指标、跟踪日志和版本控制，支持本地提示迭代、基于CI的优化和自适应代理行为。

Result: 展示了开源MCP服务器Opik，并验证了其在LLMOps生态系统中的适用性。

Conclusion: 该架构为未来提示优化、IDE代理工具和实证基准测试研究奠定了基础。

Abstract: AI development environments are evolving into observability first platforms
that integrate real time telemetry, prompt traces, and evaluation feedback into
the developer workflow. This paper introduces telemetry aware integrated
development environments (IDEs) enabled by the Model Context Protocol (MCP), a
system that connects IDEs with prompt metrics, trace logs, and versioned
control for real time refinement. We present design patterns for local prompt
iteration, CI based optimization, and autonomous agents that adapt behavior
using telemetry. Rather than focusing on a single algorithm, we describe an
architecture that supports integration with frameworks like DSPy, PromptWizard,
and Prompts as Programs. We demonstrate this through Opik, an open source MCP
server for LLM telemetry, and position our approach within the emerging LLMOps
ecosystem. This work lays a foundation for future research on prompt
optimization, IDE agent tooling, and empirical benchmarking in telemetry rich
AI development workflows.

</details>


### [33] [Extracting Knowledge Graphs from User Stories using LangChain](https://arxiv.org/abs/2506.11020)
*Thayná Camargo da Silva*

Main category: cs.SE

TL;DR: 论文提出了一种利用大语言模型自动从用户故事生成知识图谱的新方法，通过LangChain框架开发了用户故事图转换模块，实现了全自动化流程。


<details>
  <summary>Details</summary>
Motivation: 提升用户需求与软件功能的对齐，增强用户中心化的软件开发过程。

Method: 基于LangChain框架，开发用户故事图转换模块，利用大语言模型提取节点和关系，构建知识图谱。

Result: 实现了知识图谱的自动化生成和评估，提升了用户需求的可视化和理解。

Conclusion: 该方法有效改善了软件开发中对用户需求的理解和实现，推动了用户中心化的开发流程。

Abstract: This thesis introduces a novel methodology for the automated generation of
knowledge graphs from user stories by leveraging the advanced capabilities of
Large Language Models. Utilizing the LangChain framework as a basis, the User
Story Graph Transformer module was developed to extract nodes and relationships
from user stories using an LLM to construct accurate knowledge graphs.This
innovative technique was implemented in a script to fully automate the
knowledge graph extraction process. Additionally, the evaluation was automated
through a dedicated evaluation script, utilizing an annotated dataset for
assessment. By enhancing the visualization and understanding of user
requirements and domain concepts, this method fosters better alignment between
software functionalities and user expectations, ultimately contributing to more
effective and user-centric software development processes.

</details>


### [34] [Eliminating Hallucination-Induced Errors in LLM Code Generation with Functional Clustering](https://arxiv.org/abs/2506.11021)
*Chaitanya Ravuri,Saman Amarasinghe*

Main category: cs.SE

TL;DR: 论文提出了一种名为“功能聚类”的黑盒包装方法，通过生成多个候选程序并执行自生成的测试套件，显著减少了代码生成LLM的幻觉错误，同时提供可调的置信度分数。


<details>
  <summary>Details</summary>
Motivation: 现代代码生成LLM虽然能解决大部分编程问题，但仍会产生细微的错误，使其输出不适合自主部署。

Method: 通过采样多个候选程序，执行自生成测试套件，并聚类I/O行为相同的候选程序，利用最大聚类的经验质量作为精确置信度估计。

Result: 在LiveCodeBench上，该方法将错误率从约65%降至2%，保守阈值下可降至0%，同时仍能回答15.6%的提示。

Conclusion: 该方法仅需采样和沙盒执行，适用于闭源API和未来模型，为可靠的自主代码生成提供了实用路径。

Abstract: Modern code-generation LLMs can already solve a large fraction of programming
problems, yet they still hallucinate subtle bugs that make their outputs unsafe
for autonomous deployment. We present functional clustering, a black-box
wrapper that eliminates nearly all hallucination-induced errors while providing
a tunable confidence score. The wrapper samples many candidate programs,
executes each on a self-generated test suite, and clusters candidates whose I/O
behavior is identical; the empirical mass of the largest cluster serves as an
exact confidence estimate. A single scalar threshold on this estimate lets
users trade coverage for reliability with exponential guarantees. On
LiveCodeBench our verifier preserves baseline pass@1 on solvable tasks yet
slashes the error rate of returned answers from ~65% to 2%, and drives it to 0%
at a conservative threshold while still answering 15.6% of prompts. Manual
audits show that the few residual mistakes stem from prompt misinterpretation,
not random generation noise, narrowing future work to specification clarity.
Because the method requires only sampling and sandbox execution, it applies
unchanged to closed-source APIs and future models, offering a practical path
toward dependable, autonomous code generation. Our code is available on Github
(https://github.com/20ChaituR/functional-clustering).

</details>


### [35] [Software Security Mapping Framework: Operationalization of Security Requirements](https://arxiv.org/abs/2506.11051)
*Sung Une Lee,Liming Dong,Zhenchang Xing,Muhammad Ejaz Ahmed,Stefan Avgoustakis*

Main category: cs.SE

TL;DR: 本文提出了一种软件安全映射框架，将抽象的安全原则转化为具体的操作步骤，覆盖从高层标准到技术活动的多层次需求。


<details>
  <summary>Details</summary>
Motivation: 现代软件开发环境日益复杂，现有框架难以将抽象安全原则转化为具体实践，亟需一种结构化解决方案。

Method: 基于KAOS目标建模方法，开发了包含131项安全需求和400多个操作步骤的框架，并提供基于网络的导航工具和OSCAL目录模型。

Result: 通过Log4j漏洞案例验证了框架的实用性，生成了符合行业最佳实践的定制清单。

Conclusion: 该框架通过系统化映射安全需求，提升了清晰度、责任性和实施效率，支持自动化合规和风险应对。

Abstract: The escalating complexity of modern software development environments has
heightened concerns around supply chain security. However, existing frameworks
often fall short in translating abstract security principles into concrete,
actionable practices. This paper introduces the Software Security Mapping
Framework, a structured solution designed to operationalize security
requirements across hierarchical levels -- from high-level regulatory standards
(e.g., ISM, Australia cybersecurity standard published by the Australian
Signals Directorate), through mid-level frameworks (e.g., NIST SSDF, the U.S.
Secure Software Development Framework), to fine-grained technical activities
(e.g., SLSA, a software supply chain security framework). Developed through
collaborative research with academic experts and industry practitioners, the
framework systematically maps 131 refined security requirements to over 400
actionable operational steps spanning the software development lifecycle. It is
grounded in four core security goals: Secure Software Environment, Secure
Software Development, Software Traceability, and Vulnerability Management. Our
approach leverages the KAOS goal modeling methodology to establish traceable
linkages between strategic goals and tactical operations, enhancing clarity,
accountability, and practical implementation. To facilitate adoption, we
provide a web-based navigation tool for interactive exploration of the
framework. A real-world case study based on the Log4j vulnerability illustrates
the framework's utility by generating a tailored checklist aligned with
industry best practices. Additionally, we offer a structured, machine-readable
OSCAL Catalog Model of the Software Security Mapping Framework, enabling
organizations to automate implementation, streamline compliance processes, and
respond effectively to evolving security risks.

</details>


### [36] [Refactoring Codebases through Library Design](https://arxiv.org/abs/2506.11058)
*Ziga Kovacic,Celine Lee,Justin Chiu,Wenting Zhao,Kevin Ellis*

Main category: cs.SE

TL;DR: 论文研究了代码代理在支持代码重用和可维护性方面的能力，提出了Librarian方法和Minicode基准，结果显示Librarian在压缩率和正确性上优于现有代码代理。


<details>
  <summary>Details</summary>
Motivation: 随着代码代理在解决独立编程问题上的准确性提高，如何将其能力扩展到支持代码重构和重用成为关键问题。

Method: 提出了Librarian方法（一种采样和重排方法）和Minicode基准，用于生成可重用库和评估代码代理的重构能力。

Result: Librarian在Minicode基准上表现优异，压缩率比现有代码代理高1.6-2倍，同时提高了正确性。

Conclusion: Librarian方法和Minicode基准为代码代理的重构能力提供了有效工具，支持代码的可维护性和重用性。

Abstract: Maintainable and general software allows developers to build robust
applications efficiently, yet achieving these qualities often requires
refactoring specialized solutions into reusable components. This challenge
becomes particularly relevant as code agents become increasingly accurate at
solving isolated programming problems. We investigate code agents' capacity to
refactor code in ways supporting growth and reusability. We present both a
method and a benchmark for refactoring: Librarian, a sample-and-rerank method
for generating reusable libraries, and Minicode, a benchmark where code agents
must minimize and refactor multiple independent solutions into a joint library.
Compared to state-of-the-art code agents, Librarian achieves strong results on
both compression and correctness on Minicode, obtaining compression rates
1.6-2x better than coding agents while also improving correctness. We
open-source our code and benchmark at https://code-refactor.github.io/.

</details>


### [37] [CodeMirage: A Multi-Lingual Benchmark for Detecting AI-Generated and Paraphrased Source Code from Production-Level LLMs](https://arxiv.org/abs/2506.11059)
*Hanxi Guo,Siyuan Cheng,Kaiyuan Zhang,Guangyu Shen,Xiangyu Zhang*

Main category: cs.SE

TL;DR: CodeMirage是一个全面的基准测试，用于检测AI生成的代码，覆盖10种编程语言和10种先进LLM，评估了10种检测器，揭示了当前技术的优缺点。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在软件开发中的广泛应用，AI生成的代码可能带来抄袭、许可证违规和安全风险，因此需要可靠的检测工具。现有基准测试覆盖范围有限，无法满足需求。

Method: CodeMirage通过覆盖10种编程语言、包含原始和改写代码样本，并整合10种先进LLM的输出，构建了一个全面的基准测试。随后评估了10种检测器在四种配置下的表现。

Result: 分析揭示了当前检测器的9个关键优缺点，并指出了未来研究的挑战。CodeMirage为开发更鲁棒的AI代码检测器提供了实用测试平台。

Conclusion: CodeMirage填补了现有基准测试的不足，为AI生成代码检测领域提供了更全面的评估工具，推动了该领域的发展。

Abstract: Large language models (LLMs) have become integral to modern software
development, producing vast amounts of AI-generated source code. While these
models boost programming productivity, their misuse introduces critical risks,
including code plagiarism, license violations, and the propagation of insecure
programs. As a result, robust detection of AI-generated code is essential. To
support the development of such detectors, a comprehensive benchmark that
reflects real-world conditions is crucial. However, existing benchmarks fall
short -- most cover only a limited set of programming languages and rely on
less capable generative models. In this paper, we present CodeMirage, a
comprehensive benchmark that addresses these limitations through three major
advancements: (1) it spans ten widely used programming languages, (2) includes
both original and paraphrased code samples, and (3) incorporates outputs from
ten state-of-the-art production-level LLMs, including both reasoning and
non-reasoning models from six major providers. Using CodeMirage, we evaluate
ten representative detectors across four methodological paradigms under four
realistic evaluation configurations, reporting results using three
complementary metrics. Our analysis reveals nine key findings that uncover the
strengths and weaknesses of current detectors, and identify critical challenges
for future work. We believe CodeMirage offers a rigorous and practical testbed
to advance the development of robust and generalizable AI-generated code
detectors.

</details>


### [38] [Code Researcher: Deep Research Agent for Large Systems Code and Commit History](https://arxiv.org/abs/2506.11060)
*Ramneet Singh,Sathvik Joel,Abhav Mehrotra,Nalin Wadhwa,Ramakrishna B Bairi,Aditya Kanade,Nagarajan Natarajan*

Main category: cs.SE

TL;DR: 论文提出了Code Researcher，一种基于大语言模型的深度研究代理，用于生成系统代码补丁，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 系统代码的复杂性和规模使得修改任务极具挑战性，需要深入研究代码库及其提交历史。

Method: 设计Code Researcher，通过多步推理分析代码语义、模式和提交历史，并将上下文存储在结构化内存中以合成补丁。

Result: 在Linux内核崩溃基准测试中，Code Researcher的崩溃解决率达到58%，显著优于SWE-agent的37.5%，并能深入探索代码库。

Conclusion: 全局上下文收集和多方面推理对大型代码库至关重要，Code Researcher展示了其有效性和通用性。

Abstract: Large Language Model (LLM)-based coding agents have shown promising results
on coding benchmarks, but their effectiveness on systems code remains
underexplored. Due to the size and complexities of systems code, making changes
to a systems codebase is a daunting task, even for humans. It requires
researching about many pieces of context, derived from the large codebase and
its massive commit history, before making changes. Inspired by the recent
progress on deep research agents, we design the first deep research agent for
code, called Code Researcher, and apply it to the problem of generating patches
for mitigating crashes reported in systems code. Code Researcher performs
multi-step reasoning about semantics, patterns, and commit history of code to
gather sufficient context. The context is stored in a structured memory which
is used for synthesizing a patch. We evaluate Code Researcher on kBenchSyz, a
benchmark of Linux kernel crashes, and show that it significantly outperforms
strong baselines, achieving a crash-resolution rate of 58%, compared to 37.5%
by SWE-agent. On an average, Code Researcher explores 10 files in each
trajectory whereas SWE-agent explores only 1.33 files, highlighting Code
Researcher's ability to deeply explore the codebase. Through another experiment
on an open-source multimedia software, we show the generalizability of Code
Researcher. Our experiments highlight the importance of global context
gathering and multi-faceted reasoning for large codebases.

</details>


### [39] [CoQuIR: A Comprehensive Benchmark for Code Quality-Aware Information Retrieval](https://arxiv.org/abs/2506.11066)
*Jiahui Geng,Fengyu Cai,Shaobo Cui,Qing Li,Liangwei Chen,Chenyang Lyu,Haonan Li,Derui Zhu,Walter Pretschner,Heinz Koeppl,Fakhri Karray*

Main category: cs.SE

TL;DR: CoQuIR是一个多语言、大规模的质量感知代码检索基准，专注于代码的正确性、效率、安全性和可维护性，并评估了23种检索模型。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注功能相关性，忽视了软件质量的关键维度，因此需要开发一个质量感知的代码检索基准。

Method: 引入CoQuIR基准，包含42,725个查询和134,907个代码片段的质量标注，并提出两种质量中心评估指标。

Result: 即使表现最佳的模型也经常无法区分有缺陷或不安全的代码，但通过合成数据集的训练方法，质量感知指标有所提升。

Conclusion: 将质量信号整合到代码检索系统中至关重要，为更可信和稳健的软件开发工具奠定了基础。

Abstract: Code retrieval is essential in modern software development, as it boosts code
reuse and accelerates debugging. However, current benchmarks primarily
emphasize functional relevance while neglecting critical dimensions of software
quality. Motivated by this gap, we introduce CoQuIR, the first large-scale,
multilingual benchmark specifically designed to evaluate quality-aware code
retrieval across four key dimensions: correctness, efficiency, security, and
maintainability. CoQuIR provides fine-grained quality annotations for 42,725
queries and 134,907 code snippets in 11 programming languages, and is
accompanied by two quality-centric evaluation metrics: Pairwise Preference
Accuracy and Margin-based Ranking Score. Using CoQuIR, we benchmark 23
retrieval models, covering both open-source and proprietary systems, and find
that even top-performing models frequently fail to distinguish buggy or
insecure code from their more robust counterparts. Furthermore, we conduct
preliminary investigations into training methods that explicitly encourage
retrievers to recognize code quality. Using synthetic datasets, we demonstrate
promising improvements in quality-aware metrics across various models, without
sacrificing semantic relevance. Downstream code generation experiments further
validate the effectiveness of our approach. Overall, our work highlights the
importance of integrating quality signals into code retrieval systems, laying
the groundwork for more trustworthy and robust software development tools.

</details>


### [40] [DCE-LLM: Dead Code Elimination with Large Language Models](https://arxiv.org/abs/2506.11076)
*Minyu Chen,Guoqiang Li,Ling-I Wu,Ruibang Liu*

Main category: cs.SE

TL;DR: DCE-LLM是一个基于CodeBERT和LLM的自动化死代码消除框架，通过高效定位、判断和修复死代码，显著优于现有工具和GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 死代码增加二进制大小和维护难度，可能误导LLM并引发安全问题，现有工具需大量手动操作，亟需自动化解决方案。

Method: 结合CodeBERT模型和LLM，利用基于归因的代码行选择器定位死代码，并通过大规模标注数据集微调生成解释和修复建议。

Result: DCE-LLM在未使用和不可达代码检测中F1分数超过94%，显著优于GPT-4o 30%。

Conclusion: DCE-LLM为死代码消除提供了高效、自动化的解决方案，支持多语言并显著提升性能。

Abstract: Dead code introduces several challenges in software development, such as
increased binary size and maintenance difficulties. It can also obscure logical
errors and be exploited for obfuscation in malware. For LLM-based code-related
tasks, dead code introduces vulnerabilities that can mislead these models,
raising security concerns. Although modern compilers and IDEs offer dead code
elimination, sophisticated patterns can bypass these tools. A universal
approach that includes classification, location, explanation, and correction is
needed, yet current tools often require significant manual effort. We present
DCE-LLM, a framework for automated dead code elimination using a small CodeBERT
model with an attribution-based line selector to efficiently locate suspect
code. LLMs then generate judgments and explanations, fine-tuned on a
large-scale, annotated dead code dataset to provide detailed explanations and
patches. DCE-LLM outperforms existing tools, with advanced unreachability
detection, automated correction, and support for multiple programming
languages. Experimental results show DCE-LLM achieves over 94% F1 scores for
unused and unreachable code, significantly surpassing GPT-4o by 30%.

</details>


### [41] [Research and Analysis of Employers' Opinion on the Necessary Skills that Students in the Field of Web Programming Should Possess](https://arxiv.org/abs/2506.11084)
*Yordan Kalmukov*

Main category: cs.SE

TL;DR: 论文探讨了在AI和聊天机器人时代，雇主对Web编程毕业生技能需求的变化，调查了IT雇主认为毕业生应具备的技术技能。


<details>
  <summary>Details</summary>
Motivation: 随着AI和自动化工具的普及，雇主对毕业生的技能需求发生了变化，研究旨在明确现代Web编程学生应掌握哪些技能以适应职场。

Method: 通过调查IT雇主，分析他们对Web编程毕业生所需技术技能的看法。

Result: 调查揭示了雇主更看重毕业生使用现成工具的能力还是从零开发的基本原理。

Conclusion: 研究为教育者提供了指导，帮助调整课程以满足现代IT行业的需求。

Abstract: In the era of artificial intelligence (AI) and chatbots, based on large
language models that can generate programming code in any language, write texts
and summarize information, it is obvious that the requirements of employers for
graduating students have already changed. The modern IT world offers
significant automation of programming through software frameworks and a huge
set of third-party libraries and application programming interfaces (APIs). All
these tools provide most of the necessary functionality out of the box (already
implemented), and quite naturally the question arises as to what is more useful
for students - to teach how to use these ready-made tools or the basic
principles of working and development of web applications from scratch. This
paper analyzes the results of a survey conducted among IT employers, aimed to
identify what, in their opinion, are the necessary technical skills that
graduating students in the field of Web Programming should possess in order to
join the company's work as quickly and effectively as possible.

</details>


### [42] [LeanExplore: A search engine for Lean 4 declarations](https://arxiv.org/abs/2506.11085)
*Justin Asher*

Main category: cs.SE

TL;DR: LeanExplore是一个为Lean 4设计的搜索引擎，支持语义搜索声明，结合多种排名策略，并可通过网站或API访问。


<details>
  <summary>Details</summary>
Motivation: 解决Lean 4生态系统中导航庞大库的挑战。

Method: 采用混合排名策略，结合语义嵌入模型、BM25+和PageRank评分。

Result: 提供搜索功能，支持AI助手交互，并可通过MCP与LLM集成。

Conclusion: LeanExplore能提升Lean 4工作流和AI驱动的数学研究效率。

Abstract: The expanding Lean 4 ecosystem poses challenges for navigating its vast
libraries. This paper introduces LeanExplore, a search engine for Lean 4
declarations. LeanExplore enables users to semantically search for statements,
both formally and informally, across select Lean 4 packages (including
Batteries, Init, Lean, Mathlib, PhysLean, and Std). This search capability is
powered by a hybrid ranking strategy, integrating scores from a multi-source
semantic embedding model (capturing conceptual meaning from formal Lean code,
docstrings, AI-generated informal translations, and declaration titles), BM25+
for keyword-based lexical relevance, and a PageRank-based score reflecting
declaration importance and interconnectedness. The search engine is accessible
via a dedicated website (https://www.leanexplore.com/) and a Python API
(https://github.com/justincasher/lean-explore). Furthermore, the database can
be downloaded, allowing users to self-host the service. LeanExplore integrates
easily with LLMs via the model context protocol (MCP), enabling users to chat
with an AI assistant about Lean declarations or utilize the search engine for
building theorem-proving agents. This work details LeanExplore's architecture,
data processing, functionalities, and its potential to enhance Lean 4 workflows
and AI-driven mathematical research

</details>


### [43] [Denoising Programming Knowledge Tracing with a Code Graph-based Tuning Adaptor](https://arxiv.org/abs/2506.11107)
*Weibo Gao,Qi Liu,Rui Li,Yuze Zhao,Hao Wang,Linan Yre,Fangzhou Yao,Zheng Zhang*

Main category: cs.SE

TL;DR: Coda是一个基于代码图的调适器，用于提升编程知识追踪（PKT）模型的性能，通过识别和减少噪声信号的影响。


<details>
  <summary>Details</summary>
Motivation: 当前PKT研究主要关注代码内容与知识评估的隐式关系，但忽略了长期编程活动中的噪声信号（如无关提交和微小修改），这限制了模型性能。

Method: Coda将松散代码序列转换为紧凑代码图，利用语义相似性识别噪声，并应用聚类感知GCN增强弱信号区分能力，最后通过轻量级调适器优化PKT任务。

Result: 在四个真实数据集上的实验表明，Coda在噪声编程记录下有效提升了PKT任务性能，优于典型基线。

Conclusion: Coda是一个模型无关的框架，可适配大多数现有PKT解决方案，有效解决了噪声问题。

Abstract: Programming Knowledge Tracking (PKT) aims to dynamically diagnose learners'
mastery levels of programming knowledge based on their coding activities,
facilitating more effective and personalized programming education. However,
current PKT studies primarily focus on the implicit relationship between code
content and knowledge assessment, often overlooking two types of noise signals
in long-term programming activities: unwanted signals from unrelated
submissions and weak signals from minor modifications. This practical challenge
significantly limits model performance and application. To address this issue,
we propose Coda, a Code graph-based tuning adaptor designed to enhance existing
PKT models by identifying and mitigating the impact of noise. Specifically,
Coda first transforms the loose code sequences submitted by each learner into a
compact code graph. By leveraging this code graph, unwanted signals can be
identified from a semantic similarity perspective. We then apply a
cluster-aware GCN to the code graph, which improves the discrimination of weak
signals and enables their clustering for identification. Finally, a lightweight
yet effective adaptor is incorporated into the PKT task through optimization
with two noise feature-based constraints and a navigational regularization
term, to correct knowledge states affected by noise. It is worth mentioning
that the Coda framework is model-agnostic and can be adapted to most existing
PKT solutions. Extensive experimental results on four real-world datasets
demonstrate that Coda effectively performs the PKT task in the presence of
noisy programming records, outperforming typical baselines.

</details>


### [44] [From over-reliance to smart integration: using Large-Language Models as translators between specialized modeling and simulation tools](https://arxiv.org/abs/2506.11141)
*Philippe J. Giabbanelli,John Beverley,Istvan David,Andreas Tolk*

Main category: cs.SE

TL;DR: 论文探讨了如何将大语言模型（LLMs）作为中间件或翻译器集成到建模与仿真（M&S）任务中，以简化工作流程并提升互操作性，同时避免过度依赖带来的质量问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在M&S中具有简化工作流程的潜力，但过度依赖可能导致歧义、逻辑捷径和幻觉问题，因此需要一种平衡的方法。

Method: 提出将LLMs作为中间件或翻译器，集成到多形式、多语义和多范式的系统中，并探索LLM介导的工作流程和结构化工具集成。

Result: 推荐使用基于低秩自适应的架构，实现高效的任务特定适配，确保LLMs补充而非替代专业工具。

Conclusion: 通过合理集成LLMs，可以提升M&S任务的质量和可靠性，同时避免性能瓶颈。

Abstract: Large Language Models (LLMs) offer transformative potential for Modeling &
Simulation (M&S) through natural language interfaces that simplify workflows.
However, over-reliance risks compromising quality due to ambiguities, logical
shortcuts, and hallucinations. This paper advocates integrating LLMs as
middleware or translators between specialized tools to mitigate complexity in
M&S tasks. Acting as translators, LLMs can enhance interoperability across
multi-formalism, multi-semantics, and multi-paradigm systems. We address two
key challenges: identifying appropriate languages and tools for modeling and
simulation tasks, and developing efficient software architectures that
integrate LLMs without performance bottlenecks. To this end, the paper explores
LLM-mediated workflows, emphasizes structured tool integration, and recommends
Low-Rank Adaptation-based architectures for efficient task-specific
adaptations. This approach ensures LLMs complement rather than replace
specialized tools, fostering high-quality, reliable M&S processes.

</details>


### [45] [Mutual-Supervised Learning for Sequential-to-Parallel Code Translation](https://arxiv.org/abs/2506.11153)
*Changxin Ke,Rui Zhang,Shuo Wang,Li Ding,Guangli Li,Yuanbo Wen,Shuoming Zhang,Ruiyuan Xu,Jin Qin,Jiaming Guo,Chenxi Wang,Ling Li,Qi Guo,Yunji Chen*

Main category: cs.SE

TL;DR: 提出了一种名为MuSL的框架，通过互监督学习解决序列到并行代码翻译中的功能等价问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: GPU高性能计算的普及需要自动化的序列到并行代码翻译方法，但现有方法在功能等价性上存在问题。

Method: MuSL框架包含一个翻译器和一个测试器，通过协同验证和协同进化的迭代循环相互提升。

Result: 实验显示MuSL显著提升了基础模型的性能，包括Pass@1提升28.91%，测试器性能提升68.90%，并在BLEU和CodeBLEU分数上超越现有方法。

Conclusion: MuSL框架有效解决了功能等价性问题，性能接近或超越当前最先进方法。

Abstract: The rise of GPU-based high-performance computing (HPC) has driven the
widespread adoption of parallel programming models such as CUDA. Yet, the
inherent complexity of parallel programming creates a demand for the automated
sequential-to-parallel approaches. However, data scarcity poses a significant
challenge for machine learning-based sequential-to-parallel code translation.
Although recent back-translation methods show promise, they still fail to
ensure functional equivalence in the translated code. In this paper, we propose
a novel Mutual-Supervised Learning (MSL) framework for sequential-to-parallel
code translation to address the functional equivalence issue. MSL consists of
two models, a Translator and a Tester. Through an iterative loop consisting of
Co-verify and Co-evolve steps, the Translator and the Tester mutually generate
data for each other and improve collectively. The Tester generates unit tests
to verify and filter functionally equivalent translated code, thereby evolving
the Translator, while the Translator generates translated code as augmented
input to evolve the Tester. Experimental results demonstrate that MuSL
significantly enhances the performance of the base model: when applied to
Qwen2.5-Coder, it not only improves Pass@1 by up to 28.91% and boosts Tester
performance by 68.90%, but also outperforms the previous state-of-the-art
method CodeRosetta by 1.56 and 6.92 in BLEU and CodeBLEU scores, while
achieving performance comparable to DeepSeek-R1 and GPT-4.1. Our code is
available at https://github.com/kcxain/musl.

</details>


### [46] [Model Discovery and Graph Simulation: A Lightweight Alternative to Chaos Engineering](https://arxiv.org/abs/2506.11176)
*Anatoly A. Krasnovsky,Alexander Zorkin*

Main category: cs.SE

TL;DR: 论文提出了一种自动化的模型发现方法，通过从跟踪数据中提取依赖图来预测微服务应用的弹性，实验表明该方法准确性高。


<details>
  <summary>Details</summary>
Motivation: 微服务应用因密集的服务间依赖容易发生级联故障，传统方法需在生产环境中进行故障注入实验，成本高且复杂。

Method: 提出模型发现方法，从跟踪数据中自动提取依赖图，并通过蒙特卡洛模拟故障，与实际混沌实验对比验证。

Result: 实验结果显示，依赖图模型与实际结果高度吻合，预测误差极低（平均绝对误差≤0.0004）。

Conclusion: 该方法能高效预测微服务可用性，无需大规模故障测试，为设计阶段提供快速洞察。

Abstract: Microservice applications are prone to cascading failures because of dense
inter-service dependencies. Ensuring resilience usually demands fault-injection
experiments in production-like setups. We propose \textit{model discovery} --
an automated CI/CD step that extracts a live dependency graph from trace data
-- and show that this lightweight representation is sufficient for accurate
resilience prediction. Using the DeathStarBench Social Network, we build the
graph, simulate failures via Monte-Carlo, and run matching chaos experiments on
the real system. The graph model closely matches reality: with no replication,
16 trials yield an observed resilience of 0.186 versus a predicted 0.161; with
replication, both observed and predicted values converge to 0.305 (mean
absolute error \leq 0.0004). These results indicate that even a simple,
automatically discovered graph can estimate microservice availability with high
fidelity, offering rapid design-time insight without full-scale failure
testing.

</details>


### [47] [Beyond Formal Semantics for Capabilities and Skills: Model Context Protocol in Manufacturing](https://arxiv.org/abs/2506.11180)
*Luis Miguel Vieira da Silva,Aljosha Köcher,Felix Gehlhoff*

Main category: cs.SE

TL;DR: 论文提出了一种基于模型上下文协议（MCP）的方法，使系统功能能够通过标准化接口直接供大型语言模型（LLM）使用，从而避免显式语义建模的复杂性。


<details>
  <summary>Details</summary>
Motivation: 显式建模能力和技能需要大量手动工作，且结果难以被LLM直接使用。

Method: 使用MCP标准化接口，使系统功能可直接供LLM调用，并在实验室规模的制造系统中进行原型评估。

Result: 实验表明，该方法能实现灵活的工业自动化，无需依赖显式语义模型。

Conclusion: 为LLM驱动的生产系统中外部工具集成提供了进一步探索的基础。

Abstract: Explicit modeling of capabilities and skills -- whether based on ontologies,
Asset Administration Shells, or other technologies -- requires considerable
manual effort and often results in representations that are not easily
accessible to Large Language Models (LLMs). In this work-in-progress paper, we
present an alternative approach based on the recently introduced Model Context
Protocol (MCP). MCP allows systems to expose functionality through a
standardized interface that is directly consumable by LLM-based agents. We
conduct a prototypical evaluation on a laboratory-scale manufacturing system,
where resource functions are made available via MCP. A general-purpose LLM is
then tasked with planning and executing a multi-step process, including
constraint handling and the invocation of resource functions via MCP. The
results indicate that such an approach can enable flexible industrial
automation without relying on explicit semantic models. This work lays the
basis for further exploration of external tool integration in LLM-driven
production systems.

</details>


### [48] [LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation](https://arxiv.org/abs/2506.11237)
*Ngoc Phuoc An Vo,Brent Paulovicks,Vadim Sheinin*

Main category: cs.SE

TL;DR: 论文提出了一种基于LLM的自动化评估方法，用于改进IT自动化中的代码生成质量，并通过双向功能匹配和逻辑表示提升评估准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在评估自动生成的修复代码时存在局限性，需要更高效且准确的评估手段。

Method: 采用LLM作为评估工具，结合双向功能匹配和逻辑表示，并与执行基准评估对比验证。

Result: LLM评估方法在准确性上优于基线（提升8%），并通过反馈机制进一步提升了代码优化效果（提升24%）。

Conclusion: LLM评估方法能有效提升代码生成质量，为IT自动化中的代码优化提供了新思路。

Abstract: In an effort to automatically evaluate and select the best model and improve
code quality for automatic incident remediation in IT Automation, it is crucial
to verify if the generated code for remediation action is syntactically and
semantically correct and whether it can be executed correctly as intended.
There are three approaches: 1) conventional methods use surface form similarity
metrics (token match, exact match, etc.) which have numerous limitations, 2)
execution-based evaluation focuses more on code functionality based on
pass/fail judgments for given test-cases, and 3) LLM-as-a-Judge employs LLMs
for automated evaluation to judge if it is a correct answer for a given problem
based on pre-defined metrics. In this work, we focused on enhancing
LLM-as-a-Judge using bidirectional functionality matching and logic
representation for reference-less automatic validation and refinement for Bash
code generation to select the best model for automatic incident remediation in
IT Automation. We used execution-based evaluation as ground-truth to evaluate
our LLM-as-a-Judge metrics. Results show high accuracy and agreement with
execution-based evaluation (and up to 8% over baseline). Finally, we built
Reflection code agents to utilize judgments and feedback from our evaluation
metrics which achieved significant improvement (up to 24% increase in accuracy)
for automatic code refinement.

</details>


### [49] [Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation](https://arxiv.org/abs/2506.11266)
*Benjamin Elder,Anupama Murthi,Jungkoo Kang,Ankita Rajaram Naik,Kiran Kate,Kinjal Basu,Danish Contractor*

Main category: cs.SE

TL;DR: 论文探讨了如何利用NL2SQL数据集自动生成NL2API数据集，并通过实验评估了10种公开LLM在工具调用任务中的表现，发现其完成率较低，仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 企业部署中，LLM需要与复杂API集合交互，但现有数据集缺乏相关特性，因此研究如何从NL2SQL数据集生成NL2API数据集。

Method: 提出一种数据生成流程，利用SQL查询语法构建功能等效的API调用序列，并将其应用于BIRD-SQL数据集，生成2500多个API。

Result: 实验显示，所有LLM在工具调用任务中表现不佳，任务完成率仅为7-47%，ReACT代理模式下提升至50%，但仍远未达到实用水平。

Conclusion: 当前工具调用LLM的性能仍有显著提升空间，需进一步优化模型能力。

Abstract: Large language models (LLMs) are routinely deployed as agentic systems, with
access to tools that interact with live environments to accomplish tasks. In
enterprise deployments these systems need to interact with API collections that
can be extremely large and complex, often backed by databases. In order to
create datasets with such characteristics, we explore how existing NL2SQL
(Natural Language to SQL query) datasets can be used to automatically create
NL2API datasets. Specifically, this work describes a novel data generation
pipeline that exploits the syntax of SQL queries to construct a functionally
equivalent sequence of API calls. We apply this pipeline to one of the largest
NL2SQL datasets, BIRD-SQL to create a collection of over 2500 APIs that can be
served as invocable tools or REST-endpoints. We pair natural language queries
from BIRD-SQL to ground-truth API sequences based on this API pool. We use this
collection to study the performance of 10 public LLMs and find that all models
struggle to determine the right set of tools (consisting of tasks of intent
detection, sequencing with nested function calls, and slot-filling). We find
that models have extremely low task completion rates (7-47 percent - depending
on the dataset) which marginally improves to 50 percent when models are
employed as ReACT agents that interact with the live API environment. The best
task completion rates are far below what may be required for effective
general-use tool-calling agents, suggesting substantial scope for improvement
in current state-of-the-art tool-calling LLMs. We also conduct detailed
ablation studies, such as assessing the impact of the number of tools available
as well as the impact of tool and slot-name obfuscation. We compare the
performance of models on the original SQL generation tasks and find that
current models are sometimes able to exploit SQL better than APIs.

</details>


### [50] [A Tale of Two Systems: Characterizing Architectural Complexity on Machine Learning-Enabled Systems](https://arxiv.org/abs/2506.11295)
*Renato Cordeiro Ferreira*

Main category: cs.SE

TL;DR: 研究提出了一种基于指标的架构模型，用于管理ML系统的复杂性，并通过两个案例研究（SPIRA和Ocean Guard MLES）验证模型。


<details>
  <summary>Details</summary>
Motivation: 探讨复杂性对ML系统的影响，为系统架构决策提供指导。

Method: 引入基于指标的架构模型，结合SPIRA和Ocean Guard MLES两个案例研究。

Result: 提出了一种能够支持ML系统架构决策的模型。

Conclusion: 该模型为ML系统的初始设计和扩展提供了有效指导。

Abstract: How can the complexity of ML-enabled systems be managed effectively? The goal
of this research is to investigate how complexity affects ML-Enabled Systems
(MLES). To address this question, this research aims to introduce a
metrics-based architectural model to characterize the complexity of MLES. The
goal is to support architectural decisions, providing a guideline for the
inception and growth of these systems. This paper brings, side-by-side, the
architecture representation of two systems that can be used as case studies for
creating the metrics-based architectural model: the SPIRA and the Ocean Guard
MLES.

</details>


### [51] [A Step-by-Step Guide to Creating a Robust Autonomous Drone Testing Pipeline](https://arxiv.org/abs/2506.11400)
*Yupeng Jiang,Yao Deng,Sebastian Schroder,Linfeng Liang,Suhaas Gambhir,Alice James,Avishkar Seth,James Pirrie,Yihao Zhang,Xi Zheng*

Main category: cs.SE

TL;DR: 本文提出了一种分阶段的无人机测试流程，包括仿真测试、硬件在环测试、实际测试和现场测试，以验证无人机系统的安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着无人机从研究原型转向关键任务平台，确保其安全、可靠和高效运行至关重要。

Method: 通过分阶段测试流程（SIL、HIL、实际测试和现场测试）及实际案例（如标记自主着陆系统）验证无人机行为。

Result: 展示了如何系统性验证无人机行为、识别集成问题并优化性能，同时探讨了未来测试趋势（如神经符号与LLM结合）。

Conclusion: 该测试流程能帮助开发者和研究者全面验证无人机，降低部署风险，确保其安全可靠运行。

Abstract: Autonomous drones are rapidly reshaping industries ranging from aerial
delivery and infrastructure inspection to environmental monitoring and disaster
response. Ensuring the safety, reliability, and efficiency of these systems is
paramount as they transition from research prototypes to mission-critical
platforms. This paper presents a step-by-step guide to establishing a robust
autonomous drone testing pipeline, covering each critical stage:
Software-in-the-Loop (SIL) Simulation Testing, Hardware-in-the-Loop (HIL)
Testing, Controlled Real-World Testing, and In-Field Testing. Using practical
examples, including the marker-based autonomous landing system, we demonstrate
how to systematically verify drone system behaviors, identify integration
issues, and optimize performance. Furthermore, we highlight emerging trends
shaping the future of drone testing, including the integration of Neurosymbolic
and LLMs, creating co-simulation environments, and Digital Twin-enabled
simulation-based testing techniques. By following this pipeline, developers and
researchers can achieve comprehensive validation, minimize deployment risks,
and prepare autonomous drones for safe and reliable real-world operations.

</details>


### [52] [ReVeal: Self-Evolving Code Agents via Iterative Generation-Verification](https://arxiv.org/abs/2506.11442)
*Yiyang Jin,Kunzhao Xu,Hang Li,Xueting Han,Yanmin Zhou,Cheng Li,Jing Bai*

Main category: cs.SE

TL;DR: ReVeal是一个多轮强化学习框架，结合代码生成与显式自验证和工具评估，提升LLMs的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏真实环境的验证信号和显式优化，导致自验证不可靠。

Method: ReVeal通过多轮RL框架，生成测试用例、调用外部工具反馈，并使用密集奖励优化性能。

Result: 在LiveCodeBench上显著提升Pass@k，推理时代码随轮次增加持续优化，超越DeepSeek-R1-Zero-Qwen-32B。

Conclusion: ReVeal是构建更强大自主AI代理的可扩展有效范式。

Abstract: Recent advances in reinforcement learning (RL) with verifiable outcome
rewards have significantly improved the reasoning capabilities of large
language models (LLMs), especially when combined with multi-turn tool
interactions. However, existing methods lack both meaningful verification
signals from realistic environments and explicit optimization for verification,
leading to unreliable self-verification. To address these limitations, we
propose ReVeal, a multi-turn reinforcement learning framework that interleaves
code generation with explicit self-verification and tool-based evaluation.
ReVeal enables LLMs to autonomously generate test cases, invoke external tools
for precise feedback, and improves performance via a customized RL algorithm
with dense, per-turn rewards. As a result, ReVeal fosters the co-evolution of a
model's generation and verification capabilities through RL training, expanding
the reasoning boundaries of the base model, demonstrated by significant gains
in Pass@k on LiveCodeBench. It also enables test-time scaling into deeper
inference regimes, with code consistently evolving as the number of turns
increases during inference, ultimately surpassing DeepSeek-R1-Zero-Qwen-32B.
These findings highlight the promise of ReVeal as a scalable and effective
paradigm for building more robust and autonomous AI agents.

</details>


### [53] [Understanding the Issue Types in Open Source Blockchain-based Software Projects with the Transformer-based BERTopic](https://arxiv.org/abs/2506.11451)
*Md Nahidul Islam Opu,Md Shahidul Islam,Sara Rouhani,Shaiful Chowdhury*

Main category: cs.SE

TL;DR: 该论文通过对1209个开源区块链项目的497,742个问题进行分析，使用BERTopic技术识别出49个问题主题，并归类为11个子类。研究发现，钱包管理和UI增强是最突出的问题，且钱包问题的解决时间最长。


<details>
  <summary>Details</summary>
Motivation: 区块链软件系统的开发挑战缺乏系统性理解，因此通过大规模实证研究填补这一空白。

Method: 使用BERTopic技术对GitHub上的开源区块链项目问题进行主题建模和分类。

Result: 发现钱包管理和UI增强是最常见的问题，钱包问题的解决时间最长，而机制问题解决最快。问题频率在2016年后激增，2022年后下降。

Conclusion: 研究结果有助于理解区块链软件维护，为开发专用工具和实践提供依据。

Abstract: Blockchain-based software systems are increasingly deployed across diverse
domains, yet a systematic understanding of their development challenges remains
limited. This paper presents a large-scale empirical study of 497,742 issues
mined from 1,209 open-source blockchain projects hosted on GitHub. Employing
BERTopic, a transformer-based topic modeling technique, we identify 49 distinct
issue topics and organize them hierarchically into 11 major subcategories. Our
analysis reveals that both general software development issues and
blockchain-specific concerns are nearly equally represented, with Wallet
Management and UI Enhancement emerging as the most prominent topics. We further
examine the temporal evolution of issue categories and resolution times,
finding that Wallet issues not only dominate in frequency but also exhibit the
longest resolution time. Conversely, Mechanisms issues are resolved
significantly faster. Issue frequency surged after 2016 with the rise of
Ethereum and decentralized applications, but declined after 2022. These
findings enhance our understanding of blockchain software maintenance,
informing the development of specialized tools and practices to improve
robustness and maintainability.

</details>


### [54] [VulStamp: Vulnerability Assessment using Large Language Model](https://arxiv.org/abs/2506.11484)
*Haoshen,Ming Hu,Xiaofei Xie,Jiaye Li,Mingsong Chen*

Main category: cs.SE

TL;DR: VulStamp是一个基于意图引导的漏洞评估框架，通过结合静态分析和大型语言模型（LLM）提取漏洞代码的意图信息，并使用强化学习（RL）优化提示调优模型，解决了现有方法依赖人工描述的问题。


<details>
  <summary>Details</summary>
Motivation: 现有漏洞评估方法依赖人工描述，但描述质量参差不齐且意图解释主观，限制了性能。VulStamp旨在通过无描述的意图引导方法优化漏洞评估。

Method: VulStamp结合静态分析和LLM提取漏洞代码意图信息，采用提示调优模型进行评估，并通过RL解决漏洞类型数据不平衡问题。

Result: VulStamp实现了无描述的漏洞评估，提高了评估效率和准确性。

Conclusion: VulStamp通过意图引导和RL优化，显著提升了漏洞评估的性能，为软件开发效率优化提供了新思路。

Abstract: Although modern vulnerability detection tools enable developers to
efficiently identify numerous security flaws, indiscriminate remediation
efforts often lead to superfluous development expenses. This is particularly
true given that a substantial portion of detected vulnerabilities either
possess low exploitability or would incur negligible impact in practical
operational environments. Consequently, vulnerability severity assessment has
emerged as a critical component in optimizing software development efficiency.
Existing vulnerability assessment methods typically rely on manually crafted
descriptions associated with source code artifacts. However, due to variability
in description quality and subjectivity in intention interpretation, the
performance of these methods is seriously limited. To address this issue, this
paper introduces VulStamp, a novel intention-guided framework, to facilitate
description-free vulnerability assessment. Specifically, VulStamp adopts static
analysis together with Large Language Model (LLM) to extract the intention
information of vulnerable code. Based on the intention information, VulStamp
uses a prompt-tuned model for vulnerability assessment. Furthermore, to
mitigate the problem of imbalanced data associated with vulnerability types,
VulStamp integrates a Reinforcement Learning (RL)-based prompt-tuning method to
train the assessment model.

</details>


### [55] [A Procedural Framework for Assessing the Desirability of Process Deviations](https://arxiv.org/abs/2506.11525)
*Michael Grohs,Nadine Cordes,Jana-Rebecca Rehse*

Main category: cs.SE

TL;DR: 本文提出了一个程序化框架，用于系统评估流程执行中的偏差合意性，帮助分析师更高效、客观地分类偏差并推荐行动。


<details>
  <summary>Details</summary>
Motivation: 现有的一致性检查技术无法判断偏差的合意性（问题性、可接受性或益处），而手动评估耗时、主观且不可复制。

Method: 基于文献综述和实证访谈，开发了一个分步框架，指导分析师按顺序考虑输入因素，将偏差分类为互斥的合意性类别，并链接行动建议。

Result: 通过与从业者的评估任务验证，框架能有效简化评估过程，实现全面而简洁的合意性判断。

Conclusion: 该框架为流程分析师提供了一种系统化、可复制的偏差合意性评估方法，填补了现有技术的空白。

Abstract: Conformance checking techniques help process analysts to identify where and
how process executions deviate from a process model. However, they cannot
determine the desirability of these deviations, i.e., whether they are
problematic, acceptable or even beneficial for the process. Such desirability
assessments are crucial to derive actions, but process analysts typically
conduct them in a manual, ad-hoc way, which can be time-consuming, subjective,
and irreplicable. To address this problem, this paper presents a procedural
framework to guide process analysts in systematically assessing deviation
desirability. It provides a step-by-step approach for identifying which input
factors to consider in what order to categorize deviations into mutually
exclusive desirability categories, each linked to action recommendations. The
framework is based on a review and conceptualization of existing literature on
deviation desirability, which is complemented by empirical insights from
interviews with process analysis practitioners and researchers. We evaluate the
framework through a desirability assessment task conducted with practitioners,
indicating that the framework effectively enables them to streamline the
assessment for a thorough yet concise evaluation.

</details>


### [56] [Augmenting the Generality and Performance of Large Language Models for Software Engineering](https://arxiv.org/abs/2506.11548)
*Fabian C. Peña*

Main category: cs.SE

TL;DR: 研究探讨了大型语言模型（LLMs）在软件工程（SE）中非代码任务的应用，旨在提升其通用性和性能，并检测幻觉问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在代码生成和分析方面表现突出，但在SE的其他非代码任务中应用不足，需要进一步探索。

Method: 研究通过分析不同LLMs在非代码任务中的表现、评估其作为SE基础知识的来源，以及检测SE陈述中的幻觉。

Result: 初步结果显示在多种非代码任务上性能有所提升。

Conclusion: 研究将为SE领域提供训练好的LLMs、新基准和幻觉检测方法，推动LLMs在SE中的广泛应用。

Abstract: Large Language Models (LLMs) are revolutionizing software engineering (SE),
with special emphasis on code generation and analysis. However, their
applications to broader SE practices including conceptualization, design, and
other non-code tasks, remain partially underexplored. This research aims to
augment the generality and performance of LLMs for SE by (1) advancing the
understanding of how LLMs with different characteristics perform on various
non-code tasks, (2) evaluating them as sources of foundational knowledge in SE,
and (3) effectively detecting hallucinations on SE statements. The expected
contributions include a variety of LLMs trained and evaluated on
domain-specific datasets, new benchmarks on foundational knowledge in SE, and
methods for detecting hallucinations. Initial results in terms of performance
improvements on various non-code tasks are promising.

</details>


### [57] [Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation](https://arxiv.org/abs/2506.11559)
*Gábor Antal,Dénes Bán,Martin Isztin,Rudolf Ferenc,Péter Hegedűs*

Main category: cs.SE

TL;DR: 论文探讨了GPT-4在自动生成单元测试方面的能力，特别是在漏洞修复场景下的表现。结果表明，GPT-4能生成语法正确的测试用例，但语义正确性验证有限。


<details>
  <summary>Details</summary>
Motivation: 软件测试在质量保障中至关重要，但手动创建测试复杂且耗时。研究旨在利用GPT-4自动生成漏洞相关的单元测试，减轻开发者和安全专家的工作负担。

Method: 使用VUL4J数据集中的真实漏洞及其修复代码，评估GPT-4生成测试用例的能力，重点关注代码上下文、自我修正能力和测试用例的实用性。

Result: GPT-4能生成66.5%语法正确的测试用例，但语义正确性仅能自动验证7.5%。主观评估显示其生成的测试模板可进一步开发为功能完整的测试。

Conclusion: GPT-4在漏洞测试生成中具有潜力，虽不完全自主，但可作为部分自动化工具，显著减少手动工作量。

Abstract: In the life-cycle of software development, testing plays a crucial role in
quality assurance. Proper testing not only increases code coverage and prevents
regressions but it can also ensure that any potential vulnerabilities in the
software are identified and effectively fixed. However, creating such tests is
a complex, resource-consuming manual process. To help developers and security
experts, this paper explores the automatic unit test generation capability of
one of the most widely used large language models, GPT-4, from the perspective
of vulnerabilities. We examine a subset of the VUL4J dataset containing real
vulnerabilities and their corresponding fixes to determine whether GPT-4 can
generate syntactically and/or semantically correct unit tests based on the code
before and after the fixes as evidence of vulnerability mitigation. We focus on
the impact of code contexts, the effectiveness of GPT-4's self-correction
ability, and the subjective usability of the generated test cases. Our results
indicate that GPT-4 can generate syntactically correct test cases 66.5\% of the
time without domain-specific pre-training. Although the semantic correctness of
the fixes could be automatically validated in only 7. 5\% of the cases, our
subjective evaluation shows that GPT-4 generally produces test templates that
can be further developed into fully functional vulnerability-witnessing tests
with relatively minimal manual effort.
  Therefore, despite the limited data, our initial findings suggest that GPT-4
can be effectively used in the generation of vulnerability-witnessing tests. It
may not operate entirely autonomously, but it certainly plays a significant
role in a partially automated process.

</details>


### [58] [Identifying Helpful Context for LLM-based Vulnerability Repair: A Preliminary Study](https://arxiv.org/abs/2506.11561)
*Gábor Antal,Bence Bogenfürst,Rudolf Ferenc,Péter Hegedűs*

Main category: cs.SE

TL;DR: GPT-4o在修复Java漏洞时表现比GPT-4差11.9%，但能修复更多独特漏洞。CVE信息显著提升修复率，而任务描述长度影响较小。结合CVE和代码上下文效果最佳，Top-3提示策略使修复率提升至62%。


<details>
  <summary>Details</summary>
Motivation: 研究GPT-4o在自动化漏洞修复（AVR）中的性能，探索不同上下文信息对修复能力的影响。

Method: 使用Vul4J数据集，比较GPT-4o和GPT-4的表现，测试9种包含不同上下文信息的提示，每种提示执行3次，共42个漏洞。

Result: GPT-4o修复率比GPT-4低11.9%，但能修复更多独特漏洞（+10.5%）。CVE信息显著提升修复率，Top-3提示策略使修复率达62%。

Conclusion: 结合CVE和代码上下文的提示策略能显著提升漏洞修复效果，为零样本修复提供了新思路。

Abstract: Recent advancements in large language models (LLMs) have shown promise for
automated vulnerability detection and repair in software systems. This paper
investigates the performance of GPT-4o in repairing Java vulnerabilities from a
widely used dataset (Vul4J), exploring how different contextual information
affects automated vulnerability repair (AVR) capabilities. We compare the
latest GPT-4o's performance against previous results with GPT-4 using identical
prompts. We evaluated nine additional prompts crafted by us that contain
various contextual information such as CWE or CVE information, and manually
extracted code contexts. Each prompt was executed three times on 42
vulnerabilities, and the resulting fix candidates were validated using Vul4J's
automated testing framework.
  Our results show that GPT-4o performed 11.9\% worse on average than GPT-4
with the same prompt, but was able to fix 10.5\% more distinct vulnerabilities
in the three runs together. CVE information significantly improved repair
rates, while the length of the task description had minimal impact. Combining
CVE guidance with manually extracted code context resulted in the best
performance. Using our \textsc{Top}-3 prompts together, GPT-4o repaired 26
(62\%) vulnerabilities at least once, outperforming both the original baseline
(40\%) and its reproduction (45\%), suggesting that ensemble prompt strategies
could improve vulnerability repair in zero-shot settings.

</details>


### [59] [MBSR at Work: Perspectives from an Instructor and Software Developers](https://arxiv.org/abs/2506.11588)
*Simone Romano,Alberto Conforti,Gloria Guidetti,Sara Viotti,Rachele Ceschin,Giuseppe Scanniello*

Main category: cs.SE

TL;DR: 该研究通过半结构化访谈探讨了正念减压训练（MBSR）在软件开发（SD）工作环境中的应用效果，发现开发者虽对其效果持怀疑态度，但最终认可其个人改善作用，尽管将MBSR技术融入工作环境仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索MBSR在高压力软件开发环境中的应用，填补了该领域的研究空白。

Method: 采用定性研究方法（半结构化访谈），访谈对象为参与MBSR项目的软件开发者和项目导师。

Result: 研究发现，尽管开发者最初对MBSR持怀疑态度，但最终认可其对个人压力的改善作用，但将MBSR技术融入工作环境仍存在挑战。

Conclusion: 研究结论表明，MBSR在软件开发环境中具有潜在价值，但需进一步解决其与工作环境的融合问题。

Abstract: In this paper, we present the preliminary findings from a qualitative study
(i.e., semi-structured interviews) on how a Mindfulness-Based Stress Reduction
(MBSR) program, carried out in the Software Development (SD) working context,
is perceived by the software developers of a multinational company who
participated in the MBSR program and by the instructor who led it. MBSR is a
deeply personal and experiential practice in helping individuals manage stress,
particularly in high-pressure environments such as workplaces, healthcare
settings, education, and other demanding professional or personal situations.
Although MBSR has been experimented in different working contexts;
surprisingly, it has never been studied in the SD working context where there
are several stress factors that developers experience (e.g., time pressure and
uncertainty about the content of a particular task and its outcome). In this
respect, qualitative research can generate valuable insights into the
application of MBSR in the SD working context that cannot be captured by
standardized quantitative measures. Being MBSR instructors and software
developers the key stakeholders in delivering an MBSR program in the SD working
context, understanding their first-hand experiences can provide a more detailed
picture of the investigated phenomenon. The most important takeaway result of
our research can be summarized as follows: despite initial skepticism, the
developers recognized personal improvements due to the MBSR practice, though
the integration of MBSR techniques in the working context remained challenging.

</details>


### [60] [Retrieval-Augmented Code Review Comment Generation](https://arxiv.org/abs/2506.11591)
*Hyunsun Hong,Jongmoon Baik*

Main category: cs.SE

TL;DR: 论文提出了一种结合检索与生成的方法（RAG）来自动生成代码审查评论，优于现有的生成或检索方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法中，生成式方法难以处理低频但语义重要的词汇，而检索式方法缺乏对新代码上下文的适应性。

Method: 采用检索增强生成（RAG），通过检索相似代码审查示例来指导预训练语言模型生成评论。

Result: 在Tufano基准测试中，RAG方法在精确匹配和BLEU得分上分别提升了1.67%和4.25%，低频词汇生成提升了24.01%。

Conclusion: RAG方法有效结合了生成与检索的优势，显著提升了代码审查评论生成的性能。

Abstract: Automated code review comment generation (RCG) aims to assist developers by
automatically producing natural language feedback for code changes. Existing
approaches are primarily either generation-based, using pretrained language
models, or information retrieval-based (IR), reusing comments from similar past
examples. While generation-based methods leverage code-specific pretraining on
large code-natural language corpora to learn semantic relationships between
code and natural language, they often struggle to generate low-frequency but
semantically important tokens due to their probabilistic nature. In contrast,
IR-based methods excel at recovering such rare tokens by copying from existing
examples but lack flexibility in adapting to new code contexts-for example,
when input code contains identifiers or structures not found in the retrieval
database. To bridge the gap between generation-based and IR-based methods, this
work proposes to leverage retrieval-augmented generation (RAG) for RCG by
conditioning pretrained language models on retrieved code-review exemplars. By
providing relevant examples that illustrate how similar code has been
previously reviewed, the model is better guided to generate accurate review
comments. Our evaluation on the Tufano et al. benchmark shows that RAG-based
RCG outperforms both generation-based and IR-based RCG. It achieves up to
+1.67% higher exact match and +4.25% higher BLEU scores compared to
generation-based RCG. It also improves the generation of low-frequency
ground-truth tokens by up to 24.01%. We additionally find that performance
improves as the number of retrieved exemplars increases.

</details>


### [61] [Further Evidence on a Controversial Topic about Human-Based Experiments: Professionals vs. Students](https://arxiv.org/abs/2506.11597)
*Simone Romano,Francesco Paolo Sferratore,Giuseppe Scanniello*

Main category: cs.SE

TL;DR: 研究比较了62名学生和42名软件专业人员在Java程序上的bug修复任务表现，发现学生表现优于专业人员，引发了对学生参与实验外部有效性的讨论。


<details>
  <summary>Details</summary>
Motivation: 探讨学生作为实验参与者的外部有效性及其结果对软件行业的适用性。

Method: 比较62名学生和42名专业人员在相同Java程序上的bug修复任务表现，实验环境对专业人员更真实。

Result: 学生在bug修复任务中表现优于专业人员，与以往实证结果有所不同。

Conclusion: 研究旨在促进关于学生参与实验的讨论，并鼓励未来研究更真实地模拟SE任务。

Abstract: Most Software Engineering (SE) human-based controlled experiments rely on
students as participants, raising concerns about their external validity.
Specifically, the realism of results obtained from students and their
applicability to the software industry remains in question. In this short
paper, we bring further evidence on this controversial point. To do so, we
compare 62 students and 42 software professionals on a bug-fixing task on the
same Java program. The students were enrolled in a Bachelor's program in
Computer Science, while the professionals were employed by two multinational
companies (for one of them, the professionals were from two offices). Some
variations in the experimental settings of the two groups (students and
professionals) were present. For instance, the experimental environment of the
experiment with professionals was more realistic; i.e., they faced some stress
factors such as interruptions during the bug-fixing task. Considering the
differences between the two groups of participants, the gathered data show that
the students outperformed the professionals in fixing bugs. This diverges to
some extent from past empirical evidence. Rather than presenting definitive
conclusions, our results aim to catalyze the discussion on the use of students
in experiments and pave the way for future investigations. Specifically, our
results encourage us to examine the complex factors influencing SE tasks,
making experiments as more realistic as possible.

</details>


### [62] [Understanding API Usage and Testing: An Empirical Study of C Libraries](https://arxiv.org/abs/2506.11598)
*Ahmed Zaki,Cristian Cadar*

Main category: cs.SE

TL;DR: 该论文通过分析21个流行的开源C库的API使用情况，发现开发者未根据客户端使用情况优先测试API，并提出利用客户端测试套件改进库测试的方法。


<details>
  <summary>Details</summary>
Motivation: 理解API的实际使用情况对库开发者至关重要，可帮助其基于数据驱动决策优化测试和功能开发。

Method: 研究分析了21个C库及其3061个客户端，比较API使用与测试覆盖率，并开发了LibProbe框架进行大规模分析。

Result: 研究发现许多常用API测试不足，例如LMDB中45%的API被使用但未测试；利用客户端测试可提升库测试覆盖率14.7%。

Conclusion: 库开发者应更关注客户端API使用情况以优化测试，LibProbe框架为大规模分析提供了实用工具。

Abstract: For library developers, understanding how their Application Programming
Interfaces (APIs) are used in the field can be invaluable. Knowing how clients
are using their APIs allows for data-driven decisions on prioritising bug
reports, feature requests, and testing activities. For example, the priority of
a bug report concerning an API can be partly determined by how widely that API
is used.
  In this paper, we present an empirical study in which we analyse API usage
across 21 popular open-source C libraries, such as OpenSSL and SQLite, with a
combined total of 3,061 C/C++ clients. We compare API usage by clients with how
well library test suites exercise the APIs to offer actionable insights for
library developers. To our knowledge, this is the first study that compares API
usage and API testing at scale for the C/C++ ecosystem. Our study shows that
library developers do not prioritise their effort based on how clients use
their API, with popular APIs often poorly tested. For example, in LMDB, a
popular key-value store, 45% of the APIs are used by clients but not tested by
the library test suite. We further show that client test suites can be
leveraged to improve library testing e.g., improving coverage in LMDB by 14.7%
with the important advantage that those tests are representative of how the
APIs are used in the field.
  For our empirical study, we have developed LibProbe, a framework that can be
used to analyse a large corpus of clients for a given library and produce
various metrics useful to library developers.

</details>


### [63] [Accelerating Delta Debugging through Probabilistic Monotonicity Assessment](https://arxiv.org/abs/2506.11614)
*Yonggang Tao,Jingling Xue*

Main category: cs.SE

TL;DR: 论文提出了一种概率单调性评估（PMA）方法，提升DDMIN类算法的效率，同时保持其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统Delta调试假设搜索空间单调性，但实践中这一假设并不总是成立，导致效率低下。

Method: PMA动态建模并评估搜索空间的单调性，通过置信函数量化单调性，概率性地排除非失败诱导程序子集。

Result: PMA显著减少冗余测试，处理时间比CHISEL减少59.2%，比ProbDD减少22.0%，并进一步缩小最终程序的体积。

Conclusion: PMA在提升Delta调试效率的同时，保持或增强了其有效性。

Abstract: Delta debugging assumes search space monotonicity: if a program causes a
failure, any supersets of that program will also induce the same failure,
permitting the exclusion of subsets of non-failure-inducing programs. However,
this assumption does not always hold in practice. This paper introduces
Probabilistic Monotonicity Assessment (PMA), enhancing the efficiency of
DDMIN-style algorithms without sacrificing effectiveness. PMA dynamically
models and assesses the search space's monotonicity based on prior tests tried
during the debugging process and uses a confidence function to quantify
monotonicity, thereby enabling the probabilistic exclusion of subsets of
non-failure-inducing programs. Our approach significantly reduces redundant
tests that would otherwise be performed, without compromising the quality of
the reduction.
  We evaluated PMA against two leading DDMIN-style tools, CHISEL and ProbDD.
Our findings indicate that PMA cuts processing time by 59.2% compared to
CHISEL, accelerates the reduction process (i.e., the number of tokens deleted
per second) by 3.32x, and decreases the sizes of the final reduced programs by
6.7%. Against ProbDD, PMA reduces processing time by 22.0%, achieves a 1.34x
speedup in the reduction process, and further decreases the sizes of the final
reduced programs by 3.0%. These findings affirm PMA's role in significantly
improving delta debugging's efficiency while maintaining or enhancing its
effectiveness.

</details>


### [64] [An Empirical study on LLM-based Log Retrieval for Software Engineering Metadata Management](https://arxiv.org/abs/2506.11659)
*Simin Sun,Yuchuan Jin,Miroslaw Staron*

Main category: cs.SE

TL;DR: 论文提出了一种基于大型语言模型（LLM）的方法，结合信号日志数据和测试驾驶视频，通过自然语言搜索驾驶场景，减少了对专业知识的依赖。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统（ADS）测试中生成的大量日志数据难以查询，传统SQL方法需要专业知识且结果难以验证。

Method: 结合信号日志与视频数据，利用场景距离图和相对间隙指标提供量化评估，通过API实现高效查询和可视化。

Result: 在工业数据集上的评估显示，该方法提高了场景检索的效率和可靠性，减少了对单一数据源和SQL的依赖。

Conclusion: 该方法为自动驾驶系统的场景检索提供了一种更直观、高效且可靠的解决方案。

Abstract: Developing autonomous driving systems (ADSs) involves generating and storing
extensive log data from test drives, which is essential for verification,
research, and simulation. However, these high-frequency logs, recorded over
varying durations, pose challenges for developers attempting to locate specific
driving scenarios. This difficulty arises due to the wide range of signals
representing various vehicle components and driving conditions, as well as
unfamiliarity of some developers' with the detailed meaning of these signals.
Traditional SQL-based querying exacerbates this challenge by demanding both
domain expertise and database knowledge, often yielding results that are
difficult to verify for accuracy.
  This paper introduces a Large Language Model (LLM)-supported approach that
combines signal log data with video recordings from test drives, enabling
natural language based scenario searches while reducing the need for
specialized knowledge. By leveraging scenario distance graphs and relative gap
indicators, it provides quantifiable metrics to evaluate the reliability of
query results. The method is implemented as an API for efficient database
querying and retrieval of relevant records, paired with video frames for
intuitive visualization. Evaluation on an open industrial dataset demonstrates
improved efficiency and reliability in scenario retrieval, eliminating
dependency on a single data source and conventional SQL.

</details>


### [65] [SoK: Automated Vulnerability Repair: Methods, Tools, and Assessments](https://arxiv.org/abs/2506.11697)
*Yiwei Hu,Zhen Li,Kedie Shu,Shenghua Guan,Deqing Zou,Shouhuai Xu,Bin Yuan,Hai Jin*

Main category: cs.SE

TL;DR: 本文系统化整理了自动化漏洞修复（AVR）方法，包括漏洞分析、补丁生成和补丁验证三个步骤，并构建了首个C/C++漏洞修复基准数据集Vul4C，用于评估七种AVR工具。


<details>
  <summary>Details</summary>
Motivation: 软件复杂性的增加导致漏洞增多，手动修复效率低，凸显了AVR的重要性。

Method: 通过三个步骤系统化AVR方法，并构建Vul4C数据集评估C/C++和Java的AVR工具。

Result: 评估了七种C/C++工具和两种Java工具，并讨论了未来研究方向。

Conclusion: AVR工具在漏洞修复中具有潜力，但仍需进一步研究。

Abstract: The increasing complexity of software has led to the steady growth of
vulnerabilities. Vulnerability repair investigates how to fix software
vulnerabilities. Manual vulnerability repair is labor-intensive and
time-consuming because it relies on human experts, highlighting the importance
of Automated Vulnerability Repair (AVR). In this SoK, we present the
systematization of AVR methods through the three steps of AVR workflow:
vulnerability analysis, patch generation, and patch validation. We assess AVR
tools for C/C++ and Java programs as they have been widely studied by the
community. Since existing AVR tools for C/C++ programs are evaluated with
different datasets, which often consist of a few vulnerabilities, we construct
the first C/C++ vulnerability repair benchmark dataset, dubbed Vul4C, which
contains 144 vulnerabilities as well as their exploits and patches. We use
Vul4C to evaluate seven AVR tools for C/C++ programs and use the third-party
Vul4J dataset to evaluate two AVR tools for Java programs. We also discuss
future research directions.

</details>


### [66] [Classification of Quality Characteristics in Online User Feedback using Linguistic Analysis, Crowdsourcing and LLMs](https://arxiv.org/abs/2506.11722)
*Eduard C. Groen,Fabiano Dalpiaz,Martijn van Vliet,Boris Winter,Joerg Doerr,Sjaak Brinkkemper*

Main category: cs.SE

TL;DR: 论文研究了在低数据环境下自动识别移动应用用户反馈中质量特征的三种方法：基于语言模式（LPs）、众包微任务和大型语言模型（LLM）提示，发现众包和LLM方法更准确。


<details>
  <summary>Details</summary>
Motivation: 移动应用的用户反馈是质量改进的重要来源，但反馈的异质性和缺乏训练数据限制了监督学习的应用。

Method: 比较了三种方法：基于关键词的语言模式、众包微任务和LLM提示，评估了它们的准确性和可行性。

Result: 众包方法在两阶段中平均准确率最高（0.63, 0.72），LLM的最佳条件（0.66）和多数投票（0.68）也能匹配；LPs方法精度波动大（0.38-0.92），召回率低。

Conclusion: 在低数据环境下，众包和LLM方法比LPs更有效，且可能用于构建训练语料库。

Abstract: Software qualities such as usability or reliability are among the strongest
determinants of mobile app user satisfaction and constitute a significant
portion of online user feedback on software products, making it a valuable
source of quality-related feedback to guide the development process. The
abundance of online user feedback warrants the automated identification of
quality characteristics, but the online user feedback's heterogeneity and the
lack of appropriate training corpora limit the applicability of supervised
machine learning. We therefore investigate the viability of three approaches
that could be effective in low-data settings: language patterns (LPs) based on
quality-related keywords, instructions for crowdsourced micro-tasks, and large
language model (LLM) prompts. We determined the feasibility of each approach
and then compared their accuracy. For the complex multiclass classification of
quality characteristics, the LP-based approach achieved a varied precision
(0.38-0.92) depending on the quality characteristic, and low recall;
crowdsourcing achieved the best average accuracy in two consecutive phases
(0.63, 0.72), which could be matched by the best-performing LLM condition
(0.66) and a prediction based on the LLMs' majority vote (0.68). Our findings
show that in this low-data setting, the two approaches that use crowdsourcing
or LLMs instead of involving experts achieve accurate classifications, while
the LP-based approach has only limited potential. The promise of crowdsourcing
and LLMs in this context might even extend to building training corpora.

</details>


### [67] [A Short Survey on Formalising Software Requirements using Large Language Models](https://arxiv.org/abs/2506.11874)
*Arshad Beg,Diarmuid O'Donoghue,Rosemary Monahan*

Main category: cs.SE

TL;DR: 本文综述了大型语言模型（LLM）在辅助编写软件形式化规范中的应用，总结了35篇关键论文，并提供了Dafny、C和Java的示例。


<details>
  <summary>Details</summary>
Motivation: 解决从自然语言需求编写形式化规范的挑战，源于VERIFAI项目。

Method: 使用多个学术数据库识别相关研究，AI工具Elicit辅助初步筛选，手动完成最终选择。

Result: 综述提供了利用LLM形式化软件需求的宝贵见解和未来方向。

Conclusion: LLM在形式化规范领域具有潜力，未来研究可进一步探索其应用。

Abstract: This paper presents a focused literature survey on the use of large language
models (LLM) to assist in writing formal specifications for software. A summary
of thirty-five key papers is presented, including examples for specifying
programs written in Dafny, C and Java. This paper arose from the project
VERIFAI - Traceability and verification of natural language requirements that
addresses the challenges in writing formal specifications from requirements
that are expressed in natural language. Our methodology employed multiple
academic databases to identify relevant research. The AI-assisted tool Elicit
facilitated the initial paper selection, which were manually screened for final
selection. The survey provides valuable insights and future directions for
utilising LLMs while formalising software requirements.

</details>


### [68] [LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive Programming?](https://arxiv.org/abs/2506.11928)
*Zihan Zheng,Zerui Cheng,Zeyu Shen,Shang Zhou,Kaiyuan Liu,Hansen He,Dongruixuan Li,Stanley Wei,Hangyi Hao,Jianzhu Yao,Peiyao Sheng,Zixuan Wang,Wenhao Chai,Aleksandra Korolova,Peter Henderson,Sanjeev Arora,Pramod Viswanath,Jingbo Shang,Saining Xie*

Main category: cs.SE

TL;DR: 论文通过LiveCodeBench Pro基准测试发现，前沿大语言模型在编程竞赛中仍存在显著局限性，尤其在算法推理和复杂案例分析方面表现不佳，与人类专家差距明显。


<details>
  <summary>Details</summary>
Motivation: 重新评估大语言模型（LLMs）在编程竞赛中的表现，探究其与人类专家的差异及局限性。

Method: 引入LiveCodeBench Pro基准，由国际竞赛奖牌得主标注问题并分析模型失败案例，评估模型表现。

Result: 前沿模型在中等难度问题中仅53%通过率，高难度问题中为0%，且依赖工具增强而非推理能力。

Conclusion: LLMs在编程竞赛中仍远未达到人类专家水平，需改进算法推理能力。

Abstract: Recent reports claim that large language models (LLMs) now outperform elite
humans in competitive programming. Drawing on knowledge from a group of
medalists in international algorithmic contests, we revisit this claim,
examining how LLMs differ from human experts and where limitations still
remain. We introduce LiveCodeBench Pro, a benchmark composed of problems from
Codeforces, ICPC, and IOI that are continuously updated to reduce the
likelihood of data contamination. A team of Olympiad medalists annotates every
problem for algorithmic categories and conducts a line-by-line analysis of
failed model-generated submissions. Using this new data and benchmark, we find
that frontier models still have significant limitations: without external
tools, the best model achieves only 53% pass@1 on medium-difficulty problems
and 0% on hard problems, domains where expert humans still excel. We also find
that LLMs succeed at implementation-heavy problems but struggle with nuanced
algorithmic reasoning and complex case analysis, often generating confidently
incorrect justifications. High performance appears largely driven by
implementation precision and tool augmentation, not superior reasoning.
LiveCodeBench Pro thus highlights the significant gap to human grandmaster
levels, while offering fine-grained diagnostics to steer future improvements in
code-centric LLM reasoning.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [69] [User Perceptions and Attitudes Toward Untraceability in Messaging Platforms](https://arxiv.org/abs/2506.11212)
*Carla F. Griggio,Boel Nelson,Zefan Sramek,Aslan Askarov*

Main category: cs.CR

TL;DR: 研究用户对“不可追踪性”的感知，探讨如何设计隐私增强功能和通信协议。


<details>
  <summary>Details</summary>
Motivation: 研究用户对消息元数据隐私的认知，以指导隐私增强功能和不可追踪通信协议的设计。

Method: 通过虚构平台Texty和Chatty的案例调查189名参与者，分析用户对不可追踪性的理解。

Result: 用户对不可追踪性的理解多样，涉及多种隐私威胁模型，且常将其与匿名性混淆。

Conclusion: 用户认知与协议设计存在差距，隐私态度为不可追踪工具的采用带来挑战与机遇。

Abstract: Mainstream messaging platforms offer a variety of features designed to
enhance user privacy, such as disappearing messages, password-protected chats,
and end-to-end encryption (E2EE), which primarily protect message contents.
Beyond contents, the transmission of messages generates metadata that can
reveal who communicates with whom, when and how often. In this paper, we study
user perceptions of "untraceability", i.e., preventing third parties from
tracing who communicates with whom, with the goal of informing the design of
privacy-enhancing features in messaging platforms and untraceable communication
protocols that depend on large anonymity sets and widespread user adoption. We
explore this from a broad conceptual standpoint: rather than studying mental
models of a particular solution, we analyze how users reason about what
features should be incorporated by two fictitious platforms, Texty and Chatty,
to prevent third parties from knowing who communicates with whom. Through a
vignette-based survey with 189 participants, we found that users associate the
concept of untraceability with a wide range of privacy enhancing technologies,
implying a diverse set of threat models. Overall, the features suggested by
participants show awareness of privacy threats stemming from forms of
surveillance and unauthorized access to message contents. Many participants
also associated untraceability with the notion of anonymity, but interpreted it
as senders and receivers concealing their identity from each other rather than
only from third parties. We discuss the gap between users' perceptions of
untraceability and the threat models addressed by untraceable communication
protocols, as well as how different privacy attitudes point to challenges and
opportunities for the adoption of untraceable communication tools in messaging
platforms.

</details>


### [70] [Uncovering Reliable Indicators: Improving IoC Extraction from Threat Reports](https://arxiv.org/abs/2506.11325)
*Evangelos Froudakis,Athanasios Avgetidis,Sean Tyler Frankum,Roberto Perdisci,Manos Antonakakis,Angelos Keromytis*

Main category: cs.CR

TL;DR: 论文提出了一种结合大型语言模型（LANCE）和专家验证的混合人机协作IoC提取管道，解决了现有方法因缺乏高质量真实数据导致的效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 现有IoC提取工具依赖人工或自动化方法生成真实数据，前者成本高，后者易产生误报，限制了威胁检测的可靠性。

Method: 引入混合人机协作管道，结合LANCE模型和专家验证，通过上下文感知标签提高精度，减少人工工作量。

Result: 系统将分析师工作量减少43%，并生成PRISM基准，包含1,791个标记IoC，支持公平评估和训练。

Conclusion: 该方法显著提升了IoC提取的效率和可靠性，为可重复研究提供了高质量基准。

Abstract: Indicators of Compromise (IoCs) are critical for threat detection and
response, marking malicious activity across networks and systems. Yet, the
effectiveness of automated IoC extraction systems is fundamentally limited by
one key issue: the lack of high-quality ground truth. Current extraction tools
rely either on manually extracted ground truth, which is labor-intensive and
costly, or on automated ground truth creation methods that include
non-malicious artifacts, leading to inflated false positive (FP) rates and
unreliable threat intelligence. In this work, we analyze the shortcomings of
existing ground truth creation strategies and address them by introducing the
first hybrid human-in-the-loop pipeline for IoC extraction, which combines a
large language model-based classifier (LANCE) with expert analyst validation.
Our system improves precision through explainable, context-aware labeling and
reduces analysts' work factor by 43% compared to manual annotation, as
demonstrated in our evaluation with six analysts. Using this approach, we
produce PRISM, a high-quality, publicly available benchmark of 1,791 labeled
IoCs from 50 real-world threat reports. PRISM supports both fair evaluation and
training of IoC extraction methods and enables reproducible research grounded
in expert-validated indicators.

</details>


### [71] [Bhatt Conjectures: On Necessary-But-Not-Sufficient Benchmark Tautology for Human Like Reasoning](https://arxiv.org/abs/2506.11423)
*Manish Bhatt*

Main category: cs.CR

TL;DR: 论文讨论了大型语言或推理模型（LLMs/LRMs）是否真正具备推理能力还是仅模式匹配，并提出了两个分析基准来澄清这一问题。


<details>
  <summary>Details</summary>
Motivation: 作者希望通过明确自己的思维模型，解决关于LLMs/LRMs是否真正推理的争论。

Method: 提出了两个“分析性”基准，用于评估模型的推理能力。

Result: 通过具体化的思维模型，为相关讨论提供了清晰的分析框架。

Conclusion: 论文旨在通过明确的分析基准，澄清关于LLMs/LRMs能力的争议。

Abstract: Debates about whether Large Language or Reasoning Models (LLMs/LRMs) truly
reason or merely pattern-match suffer from shifting goal posts. In my personal
opinion, two analytic--hence "tautological"--benchmarks cut through that fog in
my mental model. In this paper, I attempt to write down my mental model in
concrete terms.

</details>


### [72] [GaussMarker: Robust Dual-Domain Watermark for Diffusion Models](https://arxiv.org/abs/2506.11444)
*Kecen Li,Zhicong Huang,Xinwen Hou,Cheng Hong*

Main category: cs.CR

TL;DR: 本文提出了一种双域扩散模型水印方法，通过空间和频域嵌入水印，并结合高斯噪声恢复器提升鲁棒性，在多种攻击下表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型生成图像越来越逼真，版权和滥用问题日益突出，现有单域水印方法鲁棒性不足。

Method: 采用双域水印嵌入方法，结合空间和频域，并引入高斯噪声恢复器（GNR）增强鲁棒性。

Result: 在八种图像失真和四种高级攻击下，GaussMarker在三个Stable Diffusion版本中表现最佳，召回率高且误报率低。

Conclusion: 双域水印方法显著提升了水印的鲁棒性，适用于实际应用。

Abstract: As Diffusion Models (DM) generate increasingly realistic images, related
issues such as copyright and misuse have become a growing concern. Watermarking
is one of the promising solutions. Existing methods inject the watermark into
the single-domain of initial Gaussian noise for generation, which suffers from
unsatisfactory robustness. This paper presents the first dual-domain DM
watermarking approach using a pipelined injector to consistently embed
watermarks in both the spatial and frequency domains. To further boost
robustness against certain image manipulations and advanced attacks, we
introduce a model-independent learnable Gaussian Noise Restorer (GNR) to refine
Gaussian noise extracted from manipulated images and enhance detection
robustness by integrating the detection scores of both watermarks. GaussMarker
efficiently achieves state-of-the-art performance under eight image distortions
and four advanced attacks across three versions of Stable Diffusion with better
recall and lower false positive rates, as preferred in real applications.

</details>


### [73] [Computational Attestations of Polynomial Integrity Towards Verifiable Machine-Learning](https://arxiv.org/abs/2506.11458)
*Dustin Ray,Caroline El Jazmi*

Main category: cs.CR

TL;DR: 论文提出了一种基于零知识密码学的方法，用于验证机器学习即服务（MLaaS）中隐私和计算正确性，并在差分隐私线性回归任务上实现了快速验证。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习系统的规模和复杂性增加，确保外包计算中的隐私和正确性成为挑战。零知识密码学的进展为解决这一问题提供了可能。

Method: 利用零知识密码学生成计算完整性的证明，并在差分隐私线性回归任务中验证其正确性。

Result: 在单机上对50,000样本的数据集进行差分隐私线性回归训练，耗时不到6分钟，验证仅需0.17秒，是目前已知最快的可证明差分隐私实现。

Conclusion: 该成果为端到端私有MLaaS的实现迈出了关键一步。

Abstract: Machine-learning systems continue to advance at a rapid pace, demonstrating
remarkable utility in various fields and disciplines. As these systems continue
to grow in size and complexity, a nascent industry is emerging which aims to
bring machine-learning-as-a-service (MLaaS) to market. Outsourcing the
operation and training of these systems to powerful hardware carries numerous
advantages, but challenges arise when privacy and the correctness of work
carried out must be ensured. Recent advancements in the field of zero-knowledge
cryptography have led to a means of generating arguments of integrity for any
computation, which in turn can be efficiently verified by any party, in any
place, at any time. In this work we prove the correct training of a
differentially-private (DP) linear regression over a dataset of 50,000 samples
on a single machine in less than 6 minutes, verifying the entire computation in
0.17 seconds. To our knowledge, this result represents the fastest known
instance in the literature of provable-DP over a dataset of this size. We
believe this result constitutes a key stepping-stone towards end-to-end private
MLaaS.

</details>


### [74] [Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models](https://arxiv.org/abs/2506.11521)
*Jinming Wen,Xinyi Wu,Shuai Zhao,Yanhao Jia,Yuwen Li*

Main category: cs.CR

TL;DR: 多模态大语言模型（MLLMs）在音频-视觉任务中表现优异，但依赖第三方数据和开源模型带来安全风险。研究表明，MLLMs可通过指令或输入被操纵生成恶意内容。本文系统综述了音频-视觉攻击类型（如对抗攻击、后门攻击和越狱攻击），并探讨了未来研究的挑战与趋势。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在音频-视觉任务中表现卓越，但其依赖第三方数据和开源模型的安全风险尚未被充分研究。本文旨在填补这一空白，系统分析音频-视觉攻击的多样性和潜在威胁。

Method: 通过综述现有文献，本文系统分析了音频-视觉攻击的类型，包括对抗攻击、后门攻击和越狱攻击，并特别关注了最新MLLMs中的攻击方式。

Result: 研究发现，MLLMs易受多种攻击方式影响，现有综述未能全面覆盖这些攻击类型。本文提供了更全面的综述，揭示了安全漏洞和潜在威胁。

Conclusion: 本文强调了音频-视觉攻击的多样性和复杂性，呼吁未来研究关注防御机制的开发，并指出了该领域的挑战与新兴趋势。

Abstract: Multimodal large language models (MLLMs), which bridge the gap between
audio-visual and natural language processing, achieve state-of-the-art
performance on several audio-visual tasks. Despite the superior performance of
MLLMs, the scarcity of high-quality audio-visual training data and
computational resources necessitates the utilization of third-party data and
open-source MLLMs, a trend that is increasingly observed in contemporary
research. This prosperity masks significant security risks. Empirical studies
demonstrate that the latest MLLMs can be manipulated to produce malicious or
harmful content. This manipulation is facilitated exclusively through
instructions or inputs, including adversarial perturbations and malevolent
queries, effectively bypassing the internal security mechanisms embedded within
the models. To gain a deeper comprehension of the inherent security
vulnerabilities associated with audio-visual-based multimodal models, a series
of surveys investigates various types of attacks, including adversarial and
backdoor attacks. While existing surveys on audio-visual attacks provide a
comprehensive overview, they are limited to specific types of attacks, which
lack a unified review of various types of attacks. To address this issue and
gain insights into the latest trends in the field, this paper presents a
comprehensive and systematic review of audio-visual attacks, which include
adversarial attacks, backdoor attacks, and jailbreak attacks. Furthermore, this
paper also reviews various types of attacks in the latest audio-visual-based
MLLMs, a dimension notably absent in existing surveys. Drawing upon
comprehensive insights from a substantial review, this paper delineates both
challenges and emergent trends for future research on audio-visual attacks and
defense.

</details>


### [75] [SecONNds: Secure Outsourced Neural Network Inference on ImageNet](https://arxiv.org/abs/2506.11586)
*Shashank Balla*

Main category: cs.CR

TL;DR: SecONNds是一个针对大规模卷积神经网络的安全推理框架，通过优化计算和通信开销，显著提升了隐私保护推理的效率和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决外包神经网络推理中的隐私问题，现有框架因高计算和通信成本而不实用。

Method: 采用完全布尔GMW协议、NTT预处理和GPU加速，优化线性和非线性操作。

Result: 在线非线性操作速度提升17倍，通信开销降低；GPU上端到端推理时间为2.8秒。

Conclusion: SecONNds高效且适合资源受限环境中的隐私敏感应用，已开源。

Abstract: The widespread adoption of outsourced neural network inference presents
significant privacy challenges, as sensitive user data is processed on
untrusted remote servers. Secure inference offers a privacy-preserving
solution, but existing frameworks suffer from high computational overhead and
communication costs, rendering them impractical for real-world deployment. We
introduce SecONNds, a non-intrusive secure inference framework optimized for
large ImageNet-scale Convolutional Neural Networks. SecONNds integrates a novel
fully Boolean Goldreich-Micali-Wigderson (GMW) protocol for secure comparison
-- addressing Yao's millionaires' problem -- using preprocessed Beaver's bit
triples generated from Silent Random Oblivious Transfer. Our novel protocol
achieves an online speedup of 17$\times$ in nonlinear operations compared to
state-of-the-art solutions while reducing communication overhead. To further
enhance performance, SecONNds employs Number Theoretic Transform (NTT)
preprocessing and leverages GPU acceleration for homomorphic encryption
operations, resulting in speedups of 1.6$\times$ on CPU and 2.2$\times$ on GPU
for linear operations. We also present SecONNds-P, a bit-exact variant that
ensures verifiable full-precision results in secure computation, matching the
results of plaintext computations. Evaluated on a 37-bit quantized SqueezeNet
model, SecONNds achieves an end-to-end inference time of 2.8 s on GPU and 3.6 s
on CPU, with a total communication of just 420 MiB. SecONNds' efficiency and
reduced computational load make it well-suited for deploying privacy-sensitive
applications in resource-constrained environments. SecONNds is open source and
can be accessed from: https://github.com/shashankballa/SecONNds.

</details>


### [76] [KEENHash: Hashing Programs into Function-Aware Embeddings for Large-Scale Binary Code Similarity Analysis](https://arxiv.org/abs/2506.11612)
*Zhijie Liu,Qiyi Tang,Sen Nie,Shi Wu,Liang Feng Zhang,Yutian Tang*

Main category: cs.CR

TL;DR: KEENHash是一种基于大语言模型生成函数嵌入的新型哈希方法，用于高效且有效的程序级二进制代码相似性分析。


<details>
  <summary>Details</summary>
Motivation: 现有的函数级匹配工具在大型场景下时间复杂度过高，无法扩展。

Method: 通过K-Means和特征哈希将二进制文件压缩为固定长度的程序嵌入。

Result: KEENHash比现有工具快至少215倍，且在53亿次相似性评估中仅需395.83秒。

Conclusion: KEENHash在大型二进制代码相似性分析中表现出显著优势，尤其在恶意软件检测中。

Abstract: Binary code similarity analysis (BCSA) is a crucial research area in many
fields such as cybersecurity. Specifically, function-level diffing tools are
the most widely used in BCSA: they perform function matching one by one for
evaluating the similarity between binary programs. However, such methods need a
high time complexity, making them unscalable in large-scale scenarios (e.g.,
1/n-to-n search). Towards effective and efficient program-level BCSA, we
propose KEENHash, a novel hashing approach that hashes binaries into
program-level representations through large language model (LLM)-generated
function embeddings. KEENHash condenses a binary into one compact and
fixed-length program embedding using K-Means and Feature Hashing, allowing us
to do effective and efficient large-scale program-level BCSA, surpassing the
previous state-of-the-art methods. The experimental results show that KEENHash
is at least 215 times faster than the state-of-the-art function matching tools
while maintaining effectiveness. Furthermore, in a large-scale scenario with
5.3 billion similarity evaluations, KEENHash takes only 395.83 seconds while
these tools will cost at least 56 days. We also evaluate KEENHash on the
program clone search of large-scale BCSA across extensive datasets in 202,305
binaries. Compared with 4 state-of-the-art methods, KEENHash outperforms all of
them by at least 23.16%, and displays remarkable superiority over them in the
large-scale BCSA security scenario of malware detection.

</details>


### [77] [FAA Framework: A Large Language Model-Based Approach for Credit Card Fraud Investigations](https://arxiv.org/abs/2506.11635)
*Shaun Shuster,Eyal Zaloof,Asaf Shabtai,Rami Puzis*

Main category: cs.CR

TL;DR: 论文提出了一种基于多模态大语言模型（LLM）的欺诈分析师助手（FAA）框架，用于自动化信用卡欺诈调查并生成解释性报告，以减轻分析师的工作负担。


<details>
  <summary>Details</summary>
Motivation: 电子商务行业的快速增长导致信用卡欺诈行为增多，分析师因处理大量警报而疲劳。

Method: FAA框架利用LLM的推理、代码执行和视觉能力，分七步自动化完成欺诈调查。

Result: 对500起信用卡欺诈调查的实证评估表明，FAA框架能高效可靠地完成调查。

Conclusion: FAA框架可显著减轻分析师的工作负担，提高欺诈调查效率。

Abstract: The continuous growth of the e-commerce industry attracts fraudsters who
exploit stolen credit card details. Companies often investigate suspicious
transactions in order to retain customer trust and address gaps in their fraud
detection systems. However, analysts are overwhelmed with an enormous number of
alerts from credit card transaction monitoring systems. Each alert
investigation requires from the fraud analysts careful attention, specialized
knowledge, and precise documentation of the outcomes, leading to alert fatigue.
To address this, we propose a fraud analyst assistant (FAA) framework, which
employs multi-modal large language models (LLMs) to automate credit card fraud
investigations and generate explanatory reports. The FAA framework leverages
the reasoning, code execution, and vision capabilities of LLMs to conduct
planning, evidence collection, and analysis in each investigation step. A
comprehensive empirical evaluation of 500 credit card fraud investigations
demonstrates that the FAA framework produces reliable and efficient
investigations comprising seven steps on average. Thus we found that the FAA
framework can automate large parts of the workload and help reduce the
challenges faced by fraud analysts.

</details>


### [78] [DTHA: A Digital Twin-Assisted Handover Authentication Scheme for 5G and Beyond](https://arxiv.org/abs/2506.11669)
*Guanjie Li,Tom H. Luan,Chengzhe Lai,Jinkai Zheng,Rongxing Lu*

Main category: cs.CR

TL;DR: 本文提出了一种基于数字孪生的高效安全切换认证方案，用于解决5G及未来网络中移动设备在快速移动时的频繁切换认证问题。


<details>
  <summary>Details</summary>
Motivation: 5G及未来网络中，毫米波、太赫兹频段和超密集网络技术的使用导致移动设备在快速移动时频繁切换基站，易引发连接中断和安全攻击。

Method: 利用数字孪生作为智能中介，预先处理计算并协助移动设备在切换基站前完成安全互认证和密钥协商。

Result: 方案通过形式化验证（BAN逻辑、RoR模型和ProVerif）和非正式分析，证明其具备多样化的安全功能，并在信令、计算和通信开销方面优于现有方案。

Conclusion: 所提方案能有效解决5G及未来网络中的切换认证挑战，提升安全性和效率。

Abstract: With the rapid development and extensive deployment of the fifth-generation
wireless system (5G), it has achieved ubiquitous high-speed connectivity and
improved overall communication performance. Additionally, as one of the
promising technologies for integration beyond 5G, digital twin in cyberspace
can interact with the core network, transmit essential information, and further
enhance the wireless communication quality of the corresponding mobile device
(MD). However, the utilization of millimeter-wave, terahertz band, and
ultra-dense network technologies presents urgent challenges for MD in 5G and
beyond, particularly in terms of frequent handover authentication with target
base stations during faster mobility, which can cause connection interruption
and incur malicious attacks. To address such challenges in 5G and beyond, in
this paper, we propose a secure and efficient handover authentication scheme by
utilizing digital twin. Acting as an intelligent intermediate, the authorized
digital twin can handle computations and assist the corresponding MD in
performing secure mutual authentication and key negotiation in advance before
attaching the target base stations in both intra-domain and inter-domain
scenarios. In addition, we provide the formal verification based on BAN logic,
RoR model, and ProVerif, and informal analysis to demonstrate that the proposed
scheme can offer diverse security functionality. Performance evaluation shows
that the proposed scheme outperforms most related schemes in terms of
signaling, computation, and communication overheads.

</details>


### [79] [LLMs on support of privacy and security of mobile apps: state of the art and research directions](https://arxiv.org/abs/2506.11679)
*Tran Thanh Lam Nguyen,Barbara Carminati,Elena Ferrari*

Main category: cs.CR

TL;DR: 本文探讨了如何利用大语言模型（LLMs）检测和缓解移动应用中的安全与隐私风险，并展示了其在替代传统分析方法上的潜力。


<details>
  <summary>Details</summary>
Motivation: 移动设备普及带来便利的同时，安全与隐私风险日益复杂，需要更先进的检测方法。

Method: 应用大语言模型（LLMs）识别和缓解移动应用中的安全风险，特别是针对智能手机平台的十大常见风险。

Result: LLMs在检测敏感数据泄露（如图片分享中的隐私问题）方面表现出可行性，有望替代传统分析方法。

Conclusion: LLMs在移动应用安全领域具有潜力，但仍面临开放的研究挑战。

Abstract: Modern life has witnessed the explosion of mobile devices. However, besides
the valuable features that bring convenience to end users, security and privacy
risks still threaten users of mobile apps. The increasing sophistication of
these threats in recent years has underscored the need for more advanced and
efficient detection approaches. In this chapter, we explore the application of
Large Language Models (LLMs) to identify security risks and privacy violations
and mitigate them for the mobile application ecosystem. By introducing
state-of-the-art research that applied LLMs to mitigate the top 10 common
security risks of smartphone platforms, we highlight the feasibility and
potential of LLMs to replace traditional analysis methods, such as dynamic and
hybrid analysis of mobile apps. As a representative example of LLM-based
solutions, we present an approach to detect sensitive data leakage when users
share images online, a common behavior of smartphone users nowadays. Finally,
we discuss open research challenges.

</details>


### [80] [Differential Privacy in Machine Learning: From Symbolic AI to LLMs](https://arxiv.org/abs/2506.11687)
*Francisco Aguilera-Martínez,Fernando Berzal*

Main category: cs.CR

TL;DR: 这篇综述论文探讨了差分隐私的基础定义、原始表述及其演变，并深入分析了差分隐私在机器学习中的应用、现有方法以及实践中的评估方式。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型不应泄露不可访问的特定信息，差分隐私提供了一种正式框架来减轻隐私风险。

Method: 综述了差分隐私的定义和演变，分析了其在机器学习中的集成方法，并探讨了实践中的评估技术。

Result: 论文提供了差分隐私在机器学习中的全面概述，展示了其应用潜力及面临的挑战。

Conclusion: 通过综述差分隐私在机器学习中的应用，本文旨在促进安全且负责任的AI系统的发展。

Abstract: Machine learning models should not reveal particular information that is not
otherwise accessible. Differential privacy provides a formal framework to
mitigate privacy risks by ensuring that the inclusion or exclusion of any
single data point does not significantly alter the output of an algorithm, thus
limiting the exposure of private information. This survey paper explores the
foundational definitions of differential privacy, reviews its original
formulations and tracing its evolution through key research contributions. It
then provides an in-depth examination of how DP has been integrated into
machine learning models, analyzing existing proposals and methods to preserve
privacy when training ML models. Finally, it describes how DP-based ML
techniques can be evaluated in practice. %Finally, it discusses the broader
implications of DP, highlighting its potential for public benefit, its
real-world applications, and the challenges it faces, including vulnerabilities
to adversarial attacks. By offering a comprehensive overview of differential
privacy in machine learning, this work aims to contribute to the ongoing
development of secure and responsible AI systems.

</details>


### [81] [Today's Cat Is Tomorrow's Dog: Accounting for Time-Based Changes in the Labels of ML Vulnerability Detection Approaches](https://arxiv.org/abs/2506.11939)
*Ranindya Paramitha,Yuan Feng,Fabio Massacci*

Main category: cs.CR

TL;DR: 论文提出了一种方法，通过将数据集重构为一系列随时间变化的训练和测试标签，以解决漏洞检测中标签随时间变化的问题，并验证了模型性能随时间的变化趋势。


<details>
  <summary>Details</summary>
Motivation: 漏洞数据集在ML测试中隐含了回顾性信息，而实际应用中只能使用训练和测试时的标签。过去的方法要么过于乐观（使用整个历史数据），要么过于保守（仅考虑连续版本）。

Method: 提出一种方法，将数据集重构为一系列数据集，训练和测试标签随时间变化以反映可用知识。使用Mann-Kendall检验验证模型是否随时间学习。

Result: 在4个时间数据集和5个ML模型上验证，结果显示性能随时间变化不一致，表明大多数模型并未真正学习。

Conclusion: 模型性能并未随数据增加而稳定提升，说明当前模型在漏洞检测中的学习能力有限。

Abstract: Vulnerability datasets used for ML testing implicitly contain retrospective
information. When tested on the field, one can only use the labels available at
the time of training and testing (e.g. seen and assumed negatives). As
vulnerabilities are discovered across calendar time, labels change and past
performance is not necessarily aligned with future performance. Past works only
considered the slices of the whole history (e.g. DiverseVUl) or individual
differences between releases (e.g. Jimenez et al. ESEC/FSE 2019). Such
approaches are either too optimistic in training (e.g. the whole history) or
too conservative (e.g. consecutive releases). We propose a method to
restructure a dataset into a series of datasets in which both training and
testing labels change to account for the knowledge available at the time. If
the model is actually learning, it should improve its performance over time as
more data becomes available and data becomes more stable, an effect that can be
checked with the Mann-Kendall test. We validate our methodology for
vulnerability detection with 4 time-based datasets (3 projects from BigVul
dataset + Vuldeepecker's NVD) and 5 ML models (Code2Vec, CodeBERT, LineVul,
ReGVD, and Vuldeepecker). In contrast to the intuitive expectation (more
retrospective information, better performance), the trend results show that
performance changes inconsistently across the years, showing that most models
are not learning.

</details>


### [82] [Technical Evaluation of a Disruptive Approach in Homomorphic AI](https://arxiv.org/abs/2506.11954)
*Eric Filiol*

Main category: cs.CR

TL;DR: HbHAI是一种新型加密技术，支持在加密数据上直接使用现有AI算法，性能优于现有同态加密方案。


<details>
  <summary>Details</summary>
Motivation: 解决传统同态加密在AI处理加密数据时的性能瓶颈，同时保持数据安全性。

Method: 基于新型键控哈希函数，保留数据的相似性特性，支持未修改的AI算法直接处理加密数据。

Result: 测试表明HbHAI在安全性和性能上表现优异，仅少数小问题需注意。

Conclusion: HbHAI为加密数据上的AI处理提供了高效且安全的解决方案。

Abstract: We present a technical evaluation of a new, disruptive cryptographic approach
to data security, known as HbHAI (Hash-based Homomorphic Artificial
Intelligence). HbHAI is based on a novel class of key-dependent hash functions
that naturally preserve most similarity properties, most AI algorithms rely on.
As a main claim, HbHAI makes now possible to analyze and process data in its
cryptographically secure form while using existing native AI algorithms without
modification, with unprecedented performances compared to existing homomorphic
encryption schemes.
  We tested various HbHAI-protected datasets (non public preview) using
traditional unsupervised and supervised learning techniques (clustering,
classification, deep neural networks) with classical unmodified AI algorithms.
This paper presents technical results from an independent analysis conducted
with those different, off-the-shelf AI algorithms. The aim was to assess the
security, operability and performance claims regarding HbHAI techniques. As a
results, our results confirm most these claims, with only a few minor
reservations.

</details>


### [83] [CnC-PRAC: Coalesce, not Cache, Per Row Activation Counts for an Efficient in-DRAM Rowhammer Mitigation](https://arxiv.org/abs/2506.11970)
*Chris S. Lin,Jeonghyun Woo,Prashant J. Nair,Gururaj Saileshwar*

Main category: cs.CR

TL;DR: CnC-PRAC是一种针对DDR5和未来DRAM的PRAC实现，通过重新排序和合并对同一物理行的计数器访问，显著减少了性能与能耗开销。


<details>
  <summary>Details</summary>
Motivation: 现有PRAC实现虽能缓解Rowhammer攻击，但带来10%的性能下降或额外能耗，需要一种兼顾性能与能耗的解决方案。

Method: 通过将计数器访问与数据访问的关键路径解耦，优化计数器请求的缓冲与合并，减少行激活次数。

Result: 相比现有方案，计数器访问的行激活减少75%-83%，性能开销可忽略，动态能耗仅增加0.84%-1%。

Conclusion: CnC-PRAC在保证安全性的同时，显著降低了PRAC的性能与能耗开销。

Abstract: JEDEC has introduced the Per Row Activation Counting (PRAC) framework for
DDR5 and future DRAMs to enable precise counting of DRAM row activations using
per-row activation counts. While recent PRAC implementations enable holistic
mitigation of Rowhammer attacks, they impose slowdowns of up to 10% due to the
increased DRAM timings for performing a read-modify-write of the counter.
Alternatively, recent work, Chronus, addresses these slowdowns, but incurs
energy overheads due to the additional DRAM activations for counters. In this
paper, we propose CnC-PRAC, a PRAC implementation that addresses both
performance and energy overheads. Unlike prior works focusing on caching
activation counts to reduce their overheads, our key idea is to reorder and
coalesce accesses to activation counts located in the same physical row. Our
design achieves this by decoupling counter access from the critical path of
data accesses. This enables optimizations such as buffering counter
read-modify-write requests and coalescing requests to the same row. Together,
these enable a reduction in row activations for counter accesses by almost
75%-83% compared to state-of-the-art solutions like Chronus and enable a PRAC
implementation with negligible slowdown and a minimal dynamic energy overhead
of 0.84%-1% compared to insecure DDR5 DRAM.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [84] [Shapley Machine: A Game-Theoretic Framework for N-Agent Ad Hoc Teamwork](https://arxiv.org/abs/2506.11285)
*Jianhong Wang,Yang Li,Samuel Kaski,Jonathan Lawry*

Main category: cs.MA

TL;DR: 本文提出了一种基于合作博弈论的方法来解决开放多智能体系统中的n智能体临时团队（NAHT）问题，通过扩展游戏空间和状态空间，并利用Shapley值分配贡献，提出了一种名为Shapley Machine的强化学习算法。


<details>
  <summary>Details</summary>
Motivation: 开放多智能体系统在现实应用中日益重要，但现有方法缺乏理论严谨性和明确的信用分配机制。本文旨在通过合作博弈论解决这些问题。

Method: 通过扩展合作游戏空间和状态空间建模NAHT，利用Shapley值分配贡献，并提出TD(λ)-like算法Shapley Machine。

Result: 实验验证了Shapley Machine的有效性，并证明了理论的合理性。

Conclusion: 本文首次将合作博弈论概念直接与强化学习结合，为开放多智能体系统提供了一种理论严谨的解决方案。

Abstract: Open multi-agent systems are increasingly important in modeling real-world
applications, such as smart grids, swarm robotics, etc. In this paper, we aim
to investigate a recently proposed problem for open multi-agent systems,
referred to as n-agent ad hoc teamwork (NAHT), where only a number of agents
are controlled. Existing methods tend to be based on heuristic design and
consequently lack theoretical rigor and ambiguous credit assignment among
agents. To address these limitations, we model and solve NAHT through the lens
of cooperative game theory. More specifically, we first model an open
multi-agent system, characterized by its value, as an instance situated in a
space of cooperative games, generated by a set of basis games. We then extend
this space, along with the state space, to accommodate dynamic scenarios,
thereby characterizing NAHT. Exploiting the justifiable assumption that basis
game values correspond to a sequence of n-step returns with different horizons,
we represent the state values for NAHT in a form similar to $\lambda$-returns.
Furthermore, we derive Shapley values to allocate state values to the
controlled agents, as credits for their contributions to the ad hoc team.
Different from the conventional approach to shaping Shapley values in an
explicit form, we shape Shapley values by fulfilling the three axioms uniquely
describing them, well defined on the extended game space describing NAHT. To
estimate Shapley values in dynamic scenarios, we propose a TD($\lambda$)-like
algorithm. The resulting reinforcement learning (RL) algorithm is referred to
as Shapley Machine. To our best knowledge, this is the first time that the
concepts from cooperative game theory are directly related to RL concepts. In
experiments, we demonstrate the effectiveness of Shapley Machine and verify
reasonableness of our theory.

</details>


### [85] [AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction](https://arxiv.org/abs/2506.11475)
*Syeda Kisaa Fatima,Tehreem Zubair,Noman Ahmed,Asifullah Khan*

Main category: cs.MA

TL;DR: LUCID-MA是一个多智能体协作分析犯罪数据的AI框架，包含分析助手、反馈组件和预测组件，通过离线运行和自我改进实现高效分析。


<details>
  <summary>Details</summary>
Motivation: 解决犯罪数据分析中的人工干预多、隐私保护难的问题，探索多智能体在社会科学领域的应用潜力。

Method: 采用LLaMA-2-13B-Chat-GPTQ模型，设计三个核心组件（分析、反馈、预测），通过100轮通信实现自我改进，并引入评分函数评估性能。

Result: 系统能够离线运行，减少人工干预，通过可视化图表跟踪学习进度，实现犯罪数据的自主、可扩展分析。

Conclusion: LUCID-MA展示了多智能体在社会科学领域的潜力，尤其适合隐私敏感场景，为犯罪分析提供了新思路。

Abstract: This paper introduces LUCID-MA (Learning and Understanding Crime through
Dialogue of Multiple Agents), an innovative AI powered framework where multiple
AI agents collaboratively analyze and understand crime data. Our system that
consists of three core components: an analysis assistant that highlights
spatiotemporal crime patterns, a feedback component that reviews and refines
analytical results and a prediction component that forecasts future crime
trends. With a well-designed prompt and the LLaMA-2-13B-Chat-GPTQ model, it
runs completely offline and allows the agents undergo self-improvement through
100 rounds of communication with less human interaction. A scoring function is
incorporated to evaluate agent's performance, providing visual plots to track
learning progress. This work demonstrates the potential of AutoGen-style agents
for autonomous, scalable, and iterative analysis in social science domains
maintaining data privacy through offline execution.

</details>


### [86] [PE-MA: Parameter-Efficient Co-Evolution of Multi-Agent Systems](https://arxiv.org/abs/2506.11803)
*Yingfan Deng,Anhao Zhou,Yuan Yuan,Xian Zhang,Yifei Zou,Dongxiao Yu*

Main category: cs.MA

TL;DR: 提出了PE-MA框架，通过轻量级个性化适配器和共享适配器，解决多智能体系统中的通信开销和个性化不足问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在协作推理和解决复杂任务方面具有潜力，但面临通信开销高和个性化不足的挑战。

Method: PE-MA框架中，每个智能体维护轻量级个性化适配器，同时共享适配器在邻近智能体间协作优化。

Result: 实现了渐进最优收敛速率O(1/(NK)^(1/2)，其中N为智能体数量，K为本地更新步数。

Conclusion: PE-MA框架在异构环境下平衡了全局协调与本地适应，支持高效、可扩展和个性化的协作进化。

Abstract: Multi-Agent Systems have recently emerged as a promising paradigm for
collaborative reasoning and solving complex tasks. However, the design of
collaborative learning algorithms in multi-agent systems faces several
challenges, including high communication overhead and insufficient agent-level
personalization. In this paper, we propose PE-MA (Parameter-Efficient
Multi-Agent Co-Evolution), a novel collaboration framework that supports
efficient, scalable, and personalized co-evolution in multi-agent systems. In
PE-MA, each agent maintains a lightweight personalized adapter to support
agent-specific behavior, while a shared adapter is collaboratively optimized
across neighboring agents. This design balances global coordination with local
adaptation under heterogeneous environments. We achieve an asymptotically
optimal convergence rate of O( 1/(NK)^(1/2) ), where N is the number of agents
and K the local update steps.

</details>
