<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 9]
- [cs.CR](#cs.CR) [Total: 24]
- [cs.AI](#cs.AI) [Total: 23]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Can LLMs Replace Humans During Code Chunking?](https://arxiv.org/abs/2506.19897)
*Christopher Glasz,Emily Escamilla,Eric O. Scott,Anand Patel,Jacob Zimmer,Colin Diggs,Michael Doyle,Scott Rosen,Nitin Naik,Justin F. Brunelle,Samruddhi Thaker,Parthav Poudel,Arun Sridharan,Amit Madan,Doug Wendt,William Macke,Thomas Schill*

Main category: cs.SE

TL;DR: 论文探讨了大型语言模型（LLMs）在政府遗留代码现代化中的应用，解决了输入限制问题，并比较了不同代码分块方法对文档生成质量的影响。


<details>
  <summary>Details</summary>
Motivation: 政府企业软件常使用遗留语言（如MUMPS或ALC），且代码长度超出当前LLMs的上下文窗口限制，LLMs对遗留语言的理解能力尚不明确，需实证研究。

Method: 研究了多种代码分块方法，优化遗留代码文件的模块注释生成，评估了不同LLMs（如GPT-4o、Claude 3 Sonnet等）在文档生成中的表现。

Result: LLMs选择的分区点与人类专家分区高度一致，且分块方法对文档生成任务有显著影响，LLM生成的分区注释比人类分区更准确（高20%）和实用（高10%）。

Conclusion: LLMs可作为人类分区的替代方案，用于LLM辅助的遗留代码现代化。

Abstract: Large language models (LLMs) have become essential tools in computer science,
especially for tasks involving code understanding and generation. However,
existing work does not address many of the unique challenges presented by code
written for government applications. In particular, government enterprise
software is often written in legacy languages like MUMPS or assembly language
code (ALC) and the overall token lengths of these systems exceed the context
window size for current commercially available LLMs. Additionally, LLMs are
primarily trained on modern software languages and have undergone limited
testing with legacy languages, making their ability to understand legacy
languages unknown and, hence, an area for empirical study. This paper examines
the application of LLMs in the modernization of legacy government code written
in ALC and MUMPS, addressing the challenges of input limitations. We
investigate various code-chunking methods to optimize the generation of summary
module comments for legacy code files, evaluating the impact of code-chunking
methods on the quality of documentation produced by different LLMs, including
GPT-4o, Claude 3 Sonnet, Mixtral, and Llama 3. Our results indicate that LLMs
can select partition points closely aligned with human expert partitioning. We
also find that chunking approaches have significant impact on downstream tasks
such as documentation generation. LLM-created partitions produce comments that
are up to 20% more factual and up to 10% more useful than when humans create
partitions. Therefore, we conclude that LLMs can be used as suitable
replacements for human partitioning of large codebases during LLM-aided
modernization.

</details>


### [2] [When Domains Collide: An Activity Theory Exploration of Cross-Disciplinary Collaboration](https://arxiv.org/abs/2506.20063)
*Zixuan Feng,Thomas Zimmermann,Lorenzo Pisani,Christopher Gooley,Jeremiah Wander,Anita Sarma*

Main category: cs.SE

TL;DR: 研究探讨了跨学科软件开发（CDSD）中的协作动态，分析了领域专家（DEs）和软件开发专家（SDEs）的期望差异及其导致的摩擦。


<details>
  <summary>Details</summary>
Motivation: 随着软件开发团队日益多元化和跨学科化，DEs和SDEs之间的协作摩擦成为问题，研究旨在揭示这些摩擦的根源和表现。

Method: 采用活动理论（AT）作为分析框架，结合24次访谈和293份问卷调查的混合方法进行研究。

Result: 识别了SDEs的8种期望和DEs的6种期望，并通过AT框架揭示了21种摩擦及其产生机制。

Conclusion: 研究为理解CDSD中的协作摩擦提供了理论视角，并为未来研究、实践和基础设施设计提供了实用建议。

Abstract: Background: Software development teams are increasingly diverse, embedded,
and cross-disciplinary. Domain experts (DEs) from different disciplines
collaborate with professional software developers (SDEs), bringing
complementary expertise in creating and maintaining complex production
software. However, contested expectations, divergent problem-solving
perspectives, and conflicting priorities lead to friction. Aims: This study
aims to investigate the dynamics of emerging collaboration of
cross-disciplinary software development (CDSD) by exploring the expectations
held by DEs and SDEs and understanding how these frictions manifest in
practice. Method: We utilize Activity Theory (AT), a well-established
socio-technical framework, as an analytical lens in a grounded, empirical
investigation, conducted through a mixed-method study involving 24 interviews
(12 DEs and 12 SDEs) and a large-scale validation survey with 293 participants
(161 DEs and 132 SDEs). Results: We conceptualize and empirically ground the
CDSD dynamics. We identified eight expectations held by SDEs and six by DEs. By
mapping these expectations to AT components, we revealed 21 frictions in CDSD
and illustrated where and how they arise. Conclusions: This study offers a
theoretical lens for understanding the dynamics and frictions in CDSD and
provides actionable insights for future research, practitioners, and
infrastructure design.

</details>


### [3] [AI and Agile Software Development: From Frustration to Success -- XP2025 Workshop Summary](https://arxiv.org/abs/2506.20159)
*Tomas Herda,Victoria Pichler,Zheying Zhang,Pekka Abrahamsson,Geir K. Hanssen*

Main category: cs.SE

TL;DR: 研讨会探讨了AI与敏捷开发的整合挑战，提出了研究路线图。


<details>
  <summary>Details</summary>
Motivation: 解决AI与敏捷开发整合中的实际问题，如工具、治理、数据质量和技能缺口。

Method: 通过互动会议识别挑战，系统分析并制定研究路线图。

Result: 提出了包括短期解决方案和长期目标的研究议程。

Conclusion: 旨在推动产学研合作，从问题识别到成功实施。

Abstract: The full-day workshop on AI and Agile at XP 2025 convened a diverse group of
researchers and industry practitioners to address the practical challenges and
opportunities of integrating Artificial Intelligence into Agile software
development. Through interactive sessions, participants identified shared
frustrations related to integrating AI into Agile Software Development
practices, including challenges with tooling, governance, data quality, and
critical skill gaps. These challenges were systematically prioritized and
analyzed to uncover root causes. The workshop culminated in the collaborative
development of a research roadmap that pinpoints actionable directions for
future work, including both immediate solutions and ambitious long-term goals.
The key outcome is a structured agenda designed to foster joint
industry-academic efforts to move from identified frustrations to successful
implementation.

</details>


### [4] [Ten simple rules for PIs to integrate Research Software Engineering into their research group](https://arxiv.org/abs/2506.20217)
*Stuart M. Allen,Neil Chue Hong,Stephan Druskat,Toby Hodges,Daniel S. Katz,Jan Linxweiler,Frank Löffler,Lars Grunske,Heidi Seibold,Jan Philipp Thiele,Samantha Wittke*

Main category: cs.SE

TL;DR: 本文提出了十条简单规则，旨在提高研究软件工程（RSEng）的可及性，并为研究团队领导者提供实用建议，以提升研究软件的质量和可重复性。


<details>
  <summary>Details</summary>
Motivation: 研究软件工程（RSEng）对高质量研究软件至关重要，但许多研究者对其缺乏了解或难以应用。本文旨在解决这一问题。

Method: 提出了十条简单且实用的规则，帮助研究团队领导者理解和应用RSEng。

Result: 通过遵循这些规则，研究团队可以提高软件质量、可重复性和可信度。

Conclusion: 本文的规则为研究团队提供了实用的指导，有助于提升研究软件的质量和研究结果的可靠性。

Abstract: Research Software Engineering (RSEng) is a key success factor in producing
high-quality research software, which in turn enables and improves research
outcomes. However, as a principal investigator or leader of a research group
you may not know what RSEng is, where to get started with it, or how to use it
to maximize its benefit for your research. RSEng also often comes with
technical complexity, and therefore reduced accessibility to some researchers.
The ten simple rules presented in this paper aim to improve the accessibility
of RSEng, and provide practical and actionable advice to PIs and leaders for
integrating RSEng into their research group. By following these rules, readers
can improve the quality, reproducibility, and trustworthiness of their research
software, ultimately leading to better, more reproducible and more trustworthy
research outcomes.

</details>


### [5] [The Composition of Digital Twins for Systems-of-Systems: a Systematic Literature Review](https://arxiv.org/abs/2506.20435)
*Mennatullah T. Khedr,John S. Fitzgerald*

Main category: cs.SE

TL;DR: 本文综述了数字孪生（DTs）在复杂系统中的组成及验证与验证（V&V）方法，指出当前研究的局限性与未来方向。


<details>
  <summary>Details</summary>
Motivation: 探讨数字孪生在复杂系统（如CPS和SoS）中的组成与V&V方法，以解决集成和一致性问题。

Method: 系统文献综述，分析2022-2024年的21项研究，聚焦组成机制、SoS特性及V&V的形式、范围和挑战。

Result: 组成讨论较多但形式化不足；V&V方法多样，半正式方法和模拟占主导，形式验证应用较少。主要挑战包括模型不确定性和集成复杂性。

Conclusion: 需标准化、可扩展的V&V框架和严格的组成方法，以支持复杂DT的实现。

Abstract: Digital Twins (DTs) are increasingly used to model complex systems,
especially in Cyber-Physical Systems (CPS) and System-of-Systems (SoS), where
effective integration is key. This systematic literature review investigates DT
composition and verification and validation (V&V) methodologies. Analyzing 21
studies from 2022-2024, we examined composition mechanisms, SoS
characteristics, and V&V formality, scope, and challenges. While composition is
discussed, formalization is limited. V&V approaches vary, with semi-formal
methods and simulations dominating; formal verification is underutilized. Key
technical challenges include model uncertainty and integration complexity.
Methodological challenges highlight the lack of standardized DT-specific V&V
frameworks. There is a need to move beyond model validation to address
integration and cyber-physical consistency. This review contributes a
structured classification of V&V approaches and emphasizes the need for
standardized, scalable V&V and rigorous composition methodologies for complex
DT implementations.

</details>


### [6] [Smart Cuts: Enhance Active Learning for Vulnerability Detection by Pruning Bad Seeds](https://arxiv.org/abs/2506.20444)
*Xiang Lan,Tim Menzies,Bowen Xu*

Main category: cs.SE

TL;DR: 论文提出了一种基于数据集映射的方法，通过识别和缓解难以学习的异常样本（“坏种子”）来提升漏洞检测模型的训练效率，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在漏洞检测中的效果常受低质量训练数据集（含噪声、错误标记或不平衡样本）的制约，需要改进样本选择策略。

Method: 提出数据集映射方法，分类训练样本的学习难度，并将其整合到主动学习框架中，优先过滤有害样本并强调信息量高的样本。

Result: 实验显示，该方法在Big-Vul数据集上显著提升F1分数（优于随机选择和标准主动学习），并增强模型鲁棒性和样本选择稳定性。

Conclusion: 通过分析异常样本特征，该方法为未来数据集构建提供了改进方向，使漏洞检测更可靠且经济高效。

Abstract: Vulnerability detection is crucial for identifying security weaknesses in
software systems. However, the effectiveness of machine learning models in this
domain is often hindered by low-quality training datasets, which contain noisy,
mislabeled, or imbalanced samples. This paper proposes a novel dataset
maps-empowered approach that systematically identifies and mitigates
hard-to-learn outliers, referred to as "bad seeds", to improve model training
efficiency. Our approach can categorize training examples based on learning
difficulty and integrate this information into an active learning framework.
Unlike traditional methods that focus on uncertainty-based sampling, our
strategy prioritizes dataset quality by filtering out performance-harmful
samples while emphasizing informative ones. Our experimental results show that
our approach can improve F1 score over random selection by 45.36% (DeepGini)
and 45.91% (K-Means) and outperforms standard active learning by 61.46%
(DeepGini) and 32.65% (K-Means) for CodeBERT on the Big-Vul dataset,
demonstrating the effectiveness of integrating dataset maps for optimizing
sample selection in vulnerability detection. Furthermore, our approach also
enhances model robustness, improves sample selection by filtering bad seeds,
and stabilizes active learning performance across iterations. By analyzing the
characteristics of these outliers, we provide insights for future improvements
in dataset construction, making vulnerability detection more reliable and
cost-effective.

</details>


### [7] [Large Language Model-Driven Code Compliance Checking in Building Information Modeling](https://arxiv.org/abs/2506.20551)
*Soumya Madireddy,Lu Gao,Zia Din,Kinam Kim,Ahmed Senouci,Zhe Han,Yunpeng Zhang*

Main category: cs.SE

TL;DR: 该研究通过引入基于大语言模型（LLM）的半自动化方法，解决了建筑信息模型（BIM）中手动代码合规检查耗时且易出错的问题。


<details>
  <summary>Details</summary>
Motivation: 手动进行BIM中的代码合规检查既耗时又容易出错，亟需一种高效且准确的自动化解决方案。

Method: 研究开发了一个系统，将GPT、Claude、Gemini和Llama等LLM与Revit软件集成，用于解释建筑规范、生成Python脚本并在BIM环境中执行半自动化合规检查。

Result: 案例研究表明，该系统显著减少了合规检查的时间和精力，同时提高了准确性，能够自动识别违规行为并生成报告。

Conclusion: 该方法为BIM合规检查提供了一种全面、灵活且经济高效的解决方案，有望在建筑项目中广泛应用。

Abstract: This research addresses the time-consuming and error-prone nature of manual
code compliance checking in Building Information Modeling (BIM) by introducing
a Large Language Model (LLM)-driven approach to semi-automate this critical
process. The developed system integrates LLMs such as GPT, Claude, Gemini, and
Llama, with Revit software to interpret building codes, generate Python
scripts, and perform semi-automated compliance checks within the BIM
environment. Case studies on a single-family residential project and an office
building project demonstrated the system's ability to reduce the time and
effort required for compliance checks while improving accuracy. It streamlined
the identification of violations, such as non-compliant room dimensions,
material usage, and object placements, by automatically assessing relationships
and generating actionable reports. Compared to manual methods, the system
eliminated repetitive tasks, simplified complex regulations, and ensured
reliable adherence to standards. By offering a comprehensive, adaptable, and
cost-effective solution, this proposed approach offers a promising advancement
in BIM-based compliance checking, with potential applications across diverse
regulatory documents in construction projects.

</details>


### [8] [CCISolver: End-to-End Detection and Repair of Method-Level Code-Comment Inconsistency](https://arxiv.org/abs/2506.20558)
*Renyi Zhong,Yintong Huo,Wenwei Gu,Jinxi Kuang,Zhihan Jiang,Guangba Yu,Yichen Li,David Lo,Michael R. Lyu*

Main category: cs.SE

TL;DR: 论文提出CCIBench数据集和CCISolver框架，用于解决代码注释不一致问题，显著提升了检测和修复性能。


<details>
  <summary>Details</summary>
Motivation: 代码注释不一致（CCI）对软件开发、测试和维护有负面影响，现有研究因数据集不准确和解决方案不足而效果有限。

Method: 引入高质量数据集CCIBench，并提出基于LLM的端到端框架CCISolver，用于检测和修复CCI。

Result: CCISolver在检测任务中F1-score达89.54%，修复任务中GLEU分数相对提升18.84%，推理速度比基线快36%。

Conclusion: CCISolver在性能和实用性上显著优于现有方法，具有实际应用潜力。

Abstract: Comments within code serve as a crucial foundation for software
documentation, facilitating developers to communicate and understand the code
effectively. However, code-comment inconsistency (CCI) can negatively affect
software development, testing, and maintenance. Recent efforts to mitigate this
issue have emerged, but existing studies often suffer from inaccurate datasets
and inadequate solutions, weakening their practical effectiveness. In this
study, we first conduct a quantitative analysis of existing datasets, revealing
a substantial portion of sampled data are mislabeled. To address these data
limitations, we introduce CCIBench, a refined dataset comprising high-quality
data, to support the training and evaluation of method-level CCI methods.
Furthermore, we present an innovative end-to-end LLM-based framework,
CCISolver, designed to improve code quality by identifying and rectifying CCIs.
Comprehensive evaluations demonstrate CCISolver's superior performance. For
detection, it establishes a new state-of-the-art with an F1-score of 89.54%. In
fixing task, it achieves a remarkable 18.84% relative improvement in GLEU score
over the strongest baseline. This superiority is confirmed by human evaluation,
where CCISolver's fixing success rate of 0.6533 significantly surpasses
existing methods. Critically, in a practical end-to-end setting, CCISolver's
innovative architecture is approximately 36% faster for inference than the
baseline model, underscoring its scalability and real-world applicability.

</details>


### [9] [Define-ML: An Approach to Ideate Machine Learning-Enabled Systems](https://arxiv.org/abs/2506.20621)
*Silvio Alonso,Antonio Pedro Santos Alves,Lucas Romao,Hélio Lopes,Marcos Kalinowski*

Main category: cs.SE

TL;DR: Define-ML是一个扩展Lean Inception的框架，通过结构化活动整合数据和ML约束，提升ML产品构思的清晰度和可行性。


<details>
  <summary>Details</summary>
Motivation: 传统构思方法缺乏对ML特有挑战（如数据依赖性和技术可行性）的支持，导致产品愿景与业务目标不一致。

Method: 基于技术转移模型开发，通过静态验证（玩具问题）和动态验证（工业案例）结合定量和定性分析。

Result: Define-ML能有效澄清数据问题、对齐ML能力与业务目标，促进跨职能协作，但需专家指导降低学习曲线。

Conclusion: Define-ML是一个公开可用的验证方法，结合敏捷性和ML特性，提升产品构思的可行性。

Abstract: [Context] The increasing adoption of machine learning (ML) in software
systems demands specialized ideation approaches that address ML-specific
challenges, including data dependencies, technical feasibility, and alignment
between business objectives and probabilistic system behavior. Traditional
ideation methods like Lean Inception lack structured support for these ML
considerations, which can result in misaligned product visions and unrealistic
expectations. [Goal] This paper presents Define-ML, a framework that extends
Lean Inception with tailored activities - Data Source Mapping, Feature-to-Data
Source Mapping, and ML Mapping - to systematically integrate data and technical
constraints into early-stage ML product ideation. [Method] We developed and
validated Define-ML following the Technology Transfer Model, conducting both
static validation (with a toy problem) and dynamic validation (in a real-world
industrial case study). The analysis combined quantitative surveys with
qualitative feedback, assessing utility, ease of use, and intent of adoption.
[Results] Participants found Define-ML effective for clarifying data concerns,
aligning ML capabilities with business goals, and fostering cross-functional
collaboration. The approach's structured activities reduced ideation ambiguity,
though some noted a learning curve for ML-specific components, which can be
mitigated by expert facilitation. All participants expressed the intention to
adopt Define-ML. [Conclusion] Define-ML provides an openly available, validated
approach for ML product ideation, building on Lean Inception's agility while
aligning features with available data and increasing awareness of technical
feasibility.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [10] [Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability](https://arxiv.org/abs/2506.19870)
*Md Asif Ul Hoq Khan,MD Zahedul Islam,Istiaq Ahmed,Md Masud Karim Rabbi,Farhana Rahman Anonna,MD Abdul Fahim Zeeshan,Mehedi Hasan Ridoy,Bivash Ranjan Chowdhury,Md Nazmul Shakir Rabbi,GM Alamin Sadnan*

Main category: cs.CR

TL;DR: 研究提出了一种结合区块链和人工智能的安全、智能、高效的去中心化能源交易系统，解决了分布式能源市场中的安全和欺诈问题。


<details>
  <summary>Details</summary>
Motivation: 随着点对点交易和去中心化电网的发展，美国能源市场面临安全和交易真实性的新挑战。

Method: 研究整合了区块链和人工智能两层架构，利用机器学习模型检测能源交易欺诈。

Result: 系统基于120万条模拟交易记录，成功提高了市场可靠性和安全性。

Conclusion: 区块链与人工智能的结合为去中心化能源市场提供了有效的解决方案。

Abstract: Peer-to-peer trading and the move to decentralized grids have reshaped the
energy markets in the United States. Notwithstanding, such developments lead to
new challenges, mainly regarding the safety and authenticity of energy trade.
This study aimed to develop and build a secure, intelligent, and efficient
energy transaction system for the decentralized US energy market. This research
interlinks the technological prowess of blockchain and artificial intelligence
(AI) in a novel way to solve long-standing challenges in the distributed energy
market, specifically those of security, fraudulent behavior detection, and
market reliability. The dataset for this research is comprised of more than 1.2
million anonymized energy transaction records from a simulated peer-to-peer
(P2P) energy exchange network emulating real-life blockchain-based American
microgrids, including those tested by LO3 Energy and Grid+ Labs. Each record
contains detailed fields of transaction identifier, timestamp, energy volume
(kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier
(hashed for privacy), smart meter readings, geolocation regions, and settlement
confirmation status. The dataset also includes system-calculated behavior
metrics of transaction rate, variability of energy production, and historical
pricing patterns. The system architecture proposed involves the integration of
two layers, namely a blockchain layer and artificial intelligence (AI) layer,
each playing a unique but complementary function in energy transaction securing
and market intelligence improvement. The machine learning models used in this
research were specifically chosen for their established high performance in
classification tasks, specifically in the identification of energy transaction
fraud in decentralized markets.

</details>


### [11] [An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network](https://arxiv.org/abs/2506.19871)
*Yining Pang,Chenghan Li*

Main category: cs.CR

TL;DR: 论文提出了一种基于GAN的方法对抗保险欺诈检测系统，攻击成功率达99%，揭示了现有系统的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 保险欺诈检测系统缺乏标准化防御机制，易受对抗性威胁，需增强其鲁棒性。

Method: 采用GAN生成对抗样本，攻击者无需了解训练数据或模型细节即可生成欺诈案例。

Result: 攻击成功率达99%，表明现有系统易受对抗性操纵。

Conclusion: 需提升保险欺诈检测模型的鲁棒性，以确保系统稳定性和可靠性。

Abstract: Insurance fraud detection represents a pivotal advancement in modern
insurance service, providing intelligent and digitalized monitoring to enhance
management and prevent fraud. It is crucial for ensuring the security and
efficiency of insurance systems. Although AI and machine learning algorithms
have demonstrated strong performance in detecting fraudulent claims, the
absence of standardized defense mechanisms renders current systems vulnerable
to emerging adversarial threats. In this paper, we propose a GAN-based approach
to conduct adversarial attacks on fraud detection systems. Our results indicate
that an attacker, without knowledge of the training data or internal model
details, can generate fraudulent cases that are classified as legitimate with a
99\% attack success rate (ASR). By subtly modifying real insurance records and
claims, adversaries can significantly increase the fraud risk, potentially
bypassing compromised detection systems. These findings underscore the urgent
need to enhance the robustness of insurance fraud detection models against
adversarial manipulation, thereby ensuring the stability and reliability of
different insurance systems.

</details>


### [12] [Towards Provable (In)Secure Model Weight Release Schemes](https://arxiv.org/abs/2506.19874)
*Xing Yang,Bingtao Wang,Yuhao Wang,Zimo Ji,Terry Jingchen Zhang,Wenyuan Jiang*

Main category: cs.CR

TL;DR: 论文分析了现有安全权重发布方案的安全性问题，提出了形式化定义，并通过案例研究揭示了TaylorMLP的漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有安全权重发布方案缺乏严格的安全基础，仅提供非正式的安全保证，需要形式化定义和评估。

Method: 引入具体的安全定义，并通过案例研究分析TaylorMLP方案的安全性。

Result: 发现TaylorMLP存在参数提取漏洞，未能实现其非正式安全目标。

Conclusion: 呼吁在机器学习和安全领域进行更严格的研究，并为未来权重发布方案的设计和评估提供蓝图。

Abstract: Recent secure weight release schemes claim to enable open-source model
distribution while protecting model ownership and preventing misuse. However,
these approaches lack rigorous security foundations and provide only informal
security guarantees. Inspired by established works in cryptography, we
formalize the security of weight release schemes by introducing several
concrete security definitions. We then demonstrate our definition's utility
through a case study of TaylorMLP, a prominent secure weight release scheme.
Our analysis reveals vulnerabilities that allow parameter extraction thus
showing that TaylorMLP fails to achieve its informal security goals. We hope
this work will advocate for rigorous research at the intersection of machine
learning and security communities and provide a blueprint for how future weight
release schemes should be designed and evaluated.

</details>


### [13] [Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017](https://arxiv.org/abs/2506.19877)
*Zhaoyang Xu,Yunbo Liu*

Main category: cs.CR

TL;DR: 对比四种机器学习模型在入侵检测中的表现，发现监督模型在已知攻击上表现优异，但在未知攻击上表现不佳；无监督模型在未知攻击上表现较好，但存在误报问题。


<details>
  <summary>Details</summary>
Motivation: 为动态网络环境中的入侵检测系统（IDS）选择合适的机器学习模型提供实践指导。

Method: 在CICIDS2017数据集上对比四种模型（MLP、CNN、OCSVM、LOF）在已知和未知攻击检测中的表现。

Result: 监督模型（MLP、CNN）在已知攻击上准确率高，但在未知攻击上召回率低；无监督模型（LOF）在未知攻击上召回率高但误报多；OCSVM在两者间平衡最佳。

Conclusion: OCSVM在动态网络环境中表现最稳健，为IDS模型选择提供了实用建议。

Abstract: Identifying suitable machine learning paradigms for intrusion detection
remains critical for building effective and generalizable security solutions.
In this study, we present a controlled comparison of four representative models
- Multi-Layer Perceptron (MLP), 1D Convolutional Neural Network (CNN),
One-Class Support Vector Machine (OCSVM) and Local Outlier Factor (LOF) - on
the CICIDS2017 dataset under two scenarios: detecting known attack types and
generalizing to previously unseen threats. Our results show that supervised MLP
and CNN achieve near-perfect accuracy on familiar attacks but suffer drastic
recall drops on novel attacks. Unsupervised LOF attains moderate overall
accuracy and high recall on unknown threats at the cost of elevated false
alarms, while boundary-based OCSVM balances precision and recall best,
demonstrating robust detection across both scenarios. These findings offer
practical guidance for selecting IDS models in dynamic network environments.

</details>


### [14] [Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models](https://arxiv.org/abs/2506.19881)
*Aloni Cohen*

Main category: cs.CR

TL;DR: 本文重新审视了生成模型的版权保护问题，指出近无访问自由（NAF）不足以防止侵权，并提出了一种新的无责复制保护框架，包括清洁室复制保护，同时证明了差分隐私（DP）在满足特定条件下能提供版权保护。


<details>
  <summary>Details</summary>
Motivation: 研究生成模型输出是否可能侵犯训练数据版权的问题，探索可证明的版权保护方法。

Method: 分析NAF的局限性，提出无责复制保护框架，并引入清洁室复制保护概念，同时证明DP在特定条件下能实现版权保护。

Result: NAF无法防止侵权，清洁室复制保护能有效控制复制风险，DP在满足黄金数据集条件下可提供版权保护。

Conclusion: 本文为可证明的版权保护提供了更坚实的技术和法律基础，明确了现有方法的不足并提出了改进方案。

Abstract: Are there any conditions under which a generative model's outputs are
guaranteed not to infringe the copyrights of its training data? This is the
question of "provable copyright protection" first posed by Vyas, Kakade, and
Barak (ICML 2023). They define near access-freeness (NAF) and propose it as
sufficient for protection. This paper revisits the question and establishes new
foundations for provable copyright protection -- foundations that are firmer
both technically and legally. First, we show that NAF alone does not prevent
infringement. In fact, NAF models can enable verbatim copying, a blatant
failure of copy protection that we dub being tainted. Then, we introduce our
blameless copy protection framework for defining meaningful guarantees, and
instantiate it with clean-room copy protection. Clean-room copy protection
allows a user to control their risk of copying by behaving in a way that is
unlikely to copy in a counterfactual clean-room setting. Finally, we formalize
a common intuition about differential privacy and copyright by proving that DP
implies clean-room copy protection when the dataset is golden, a copyright
deduplication requirement.

</details>


### [15] [Diffusion-based Task-oriented Semantic Communications with Model Inversion Attack](https://arxiv.org/abs/2506.19886)
*Xuesong Wang,Mo Li,Xingyan Shi,Zhaoqian Liu,Shenghao Yang*

Main category: cs.CR

TL;DR: DiffSem是一种基于扩散机制的语义通信框架，通过自引用标签嵌入优化语义信息重建，显著提升任务性能，同时抵御模型反转攻击。


<details>
  <summary>Details</summary>
Motivation: 解决任务导向语义通信中隐私保护与任务准确性之间的平衡问题，传统图像质量指标无法有效评估语义信息泄露。

Method: 提出DiffSem框架，利用扩散机制和自引用标签嵌入优化语义重建，并引入语义信息失真以增强系统鲁棒性。

Result: 在MNIST数据集上，分类准确率提升10.03%，并在动态信道中保持稳定性能。

Conclusion: DiffSem有效提升任务性能并抵御攻击，同时揭示传统图像质量指标与语义信息泄露之间的偏差。

Abstract: Semantic communication has emerged as a promising neural network-based system
design for 6G networks. Task-oriented semantic communication is a novel
paradigm whose core goal is to efficiently complete specific tasks by
transmitting semantic information, optimizing communication efficiency and task
performance. The key challenge lies in preserving privacy while maintaining
task accuracy, as this scenario is susceptible to model inversion attacks. In
such attacks, adversaries can restore or even reconstruct input data by
analyzing and processing model outputs, owing to the neural network-based
nature of the systems. In addition, traditional systems use image quality
indicators (such as PSNR or SSIM) to assess attack severity, which may be
inadequate for task-oriented semantic communication, since visual differences
do not necessarily ensure semantic divergence. In this paper, we propose a
diffusion-based semantic communication framework, named DiffSem, that optimizes
semantic information reconstruction through a diffusion mechanism with
self-referential label embedding to significantly improve task performance. Our
model also compensates channel noise and adopt semantic information distortion
to ensure the robustness of the system in various signal-to-noise ratio
environments. To evaluate the attacker's effectiveness, we propose a new metric
that better quantifies the semantic fidelity of estimations from the adversary.
Experimental results based on this criterion show that on the MNIST dataset,
DiffSem improves the classification accuracy by 10.03%, and maintain stable
performance under dynamic channels. Our results further demonstrate that
significant deviation exists between traditional image quality indicators and
the leakage of task-relevant semantic information.

</details>


### [16] [Retrieval-Confused Generation is a Good Defender for Privacy Violation Attack of Large Language Models](https://arxiv.org/abs/2506.19889)
*Wanli Peng,Xin Chen,Hang Fu,XinYu He,Xue Yiming,Juan Wen*

Main category: cs.CR

TL;DR: 论文提出了一种基于检索混淆生成（RCG）的新防御范式，用于高效隐蔽地防御隐私侵犯攻击（PVA）。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）的推理能力强大，隐私侵犯攻击（PVA）对个人隐私构成严重威胁，现有防御方法成本高且效果不佳。

Method: 设计了改写提示诱导LLM重写攻击查询的“用户评论”以构建干扰数据库，采用最不相关检索策略从干扰数据库中检索用户数据，替换“数据评论”以形成防御查询。

Result: 在两个数据集和八个流行LLMs上的实验验证了该防御方法的可行性和优越性。

Conclusion: 提出的RCG方法能有效且隐蔽地防御PVA，解决了现有方法的不足。

Abstract: Recent advances in large language models (LLMs) have made a profound impact
on our society and also raised new security concerns. Particularly, due to the
remarkable inference ability of LLMs, the privacy violation attack (PVA),
revealed by Staab et al., introduces serious personal privacy issues. Existing
defense methods mainly leverage LLMs to anonymize the input query, which
requires costly inference time and cannot gain satisfactory defense
performance. Moreover, directly rejecting the PVA query seems like an effective
defense method, while the defense method is exposed, promoting the evolution of
PVA. In this paper, we propose a novel defense paradigm based on
retrieval-confused generation (RCG) of LLMs, which can efficiently and covertly
defend the PVA. We first design a paraphrasing prompt to induce the LLM to
rewrite the "user comments" of the attack query to construct a disturbed
database. Then, we propose the most irrelevant retrieval strategy to retrieve
the desired user data from the disturbed database. Finally, the "data comments"
are replaced with the retrieved user data to form a defended query, leading to
responding to the adversary with some wrong personal attributes, i.e., the
attack fails. Extensive experiments are conducted on two datasets and eight
popular LLMs to comprehensively evaluate the feasibility and the superiority of
the proposed defense method.

</details>


### [17] [RepuNet: A Reputation System for Mitigating Malicious Clients in DFL](https://arxiv.org/abs/2506.19892)
*Isaac Marroqui Penalva,Enrique Tomás Martínez Beltrán,Manuel Gil Pérez,Alberto Huertas Celdrán*

Main category: cs.CR

TL;DR: RepuNet是一种去中心化的声誉系统，用于检测和减轻去中心化联邦学习中的恶意行为，通过动态评估节点行为并调整其影响力。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习（DFL）中节点自主选择聚合伙伴，易受模型投毒、延迟攻击和消息洪泛等威胁，现有解决方案存在计算开销大或适应性差的问题。

Method: 提出RepuNet，通过模型相似性、参数变化、消息延迟和通信量等指标动态评估节点行为，并根据声誉分数调整节点在模型聚合中的影响力。

Result: 在MNIST和CIFAR-10数据集上测试，RepuNet的F1分数分别超过95%和约76%，有效检测和减轻恶意行为。

Conclusion: RepuNet具有适应性、鲁棒性和实际潜力，适用于去中心化联邦学习环境中的威胁缓解。

Abstract: Decentralized Federated Learning (DFL) enables nodes to collaboratively train
models without a central server, introducing new vulnerabilities since each
node independently selects peers for model aggregation. Malicious nodes may
exploit this autonomy by sending corrupted models (model poisoning), delaying
model submissions (delay attack), or flooding the network with excessive
messages, negatively affecting system performance. Existing solutions often
depend on rigid configurations or additional infrastructures such as
blockchain, leading to computational overhead, scalability issues, or limited
adaptability. To overcome these limitations, this paper proposes RepuNet, a
decentralized reputation system that categorizes threats in DFL and dynamically
evaluates node behavior using metrics like model similarity, parameter changes,
message latency, and communication volume. Nodes' influence in model
aggregation is adjusted based on their reputation scores. RepuNet was
integrated into the Nebula DFL platform and experimentally evaluated with MNIST
and CIFAR-10 datasets under non-IID distributions, using federations of up to
25 nodes in both fully connected and random topologies. Different attack
intensities, frequencies, and activation intervals were tested. Results
demonstrated that RepuNet effectively detects and mitigates malicious behavior,
achieving F1 scores above 95% for MNIST scenarios and approximately 76% for
CIFAR-10 cases. These outcomes highlight RepuNet's adaptability, robustness,
and practical potential for mitigating threats in decentralized federated
learning environments.

</details>


### [18] [Anti-Phishing Training Does Not Work: A Large-Scale Empirical Assessment of Multi-Modal Training Grounded in the NIST Phish Scale](https://arxiv.org/abs/2506.19899)
*Andrew T. Rozema,James C. Davis*

Main category: cs.CR

TL;DR: 研究通过大规模实验验证钓鱼训练的有效性，发现训练对降低钓鱼邮件点击率无显著效果，强调需结合多层次防御策略。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击是重大网络安全威胁，但钓鱼训练的效果存在争议，缺乏实证研究支持。

Method: 在金融科技公司进行大规模实验（N=12,511），比较讲座式、互动式训练及对照组对不同难度钓鱼邮件的反应。

Result: NIST Phish Scale能预测行为（点击率7.0%至15.0%），但训练对点击率或报告率无显著影响（p>0.05）。

Conclusion: 钓鱼训练效果有限，建议减少对人为因素的依赖，采用多层次防御策略，并重新审视合规培训成本。

Abstract: Social engineering attacks using email, commonly known as phishing, are a
critical cybersecurity threat. Phishing attacks often lead to operational
incidents and data breaches. As a result, many organizations allocate a
substantial portion of their cybersecurity budgets to phishing awareness
training, driven in part by compliance requirements. However, the effectiveness
of this training remains in dispute. Empirical evidence of training
(in)effectiveness is essential for evidence-based cybersecurity investment and
policy development. Despite recent measurement studies, two critical gaps
remain in the literature:
  (1) we lack a validated measure of phishing lure difficulty, and
  (2) there are few comparisons of different types of training in real-world
business settings.
  To fill these gaps, we conducted a large-scale study ($N = 12{,}511$) of
phishing effectiveness at a US-based financial technology (``fintech'') firm.
Our two-factor design compared the effect of treatments (lecture-based,
interactive, and control groups) on subjects' susceptibility to phishing lures
of varying complexity (using the NIST Phish Scale). The NIST Phish Scale
successfully predicted behavior (click rates: 7.0\% easy to 15.0\% hard emails,
p $<$ 0.001), but training showed no significant main effects on clicks (p =
0.450) or reporting (p = 0.417). Effect sizes remained below 0.01, indicating
little practical value in any of the phishing trainings we deployed. Our
results add to the growing evidence that phishing training is ineffective,
reinforcing the importance of phishing defense-in-depth and the merit of
changes to processes and technology to reduce reliance on humans, as well as
rebuking the training costs necessitated by regulatory requirements.

</details>


### [19] [A Hybrid Intrusion Detection System with a New Approach to Protect the Cybersecurity of Cloud Computing](https://arxiv.org/abs/2506.19934)
*Maryam Mahdi Al-Husseini*

Main category: cs.CR

TL;DR: 论文提出了一种基于Energy-Valley Optimizer (EVO)的混合入侵检测系统(HyIDS)，通过优化特征选择和监督机器学习模型，显著提高了检测准确率和性能。


<details>
  <summary>Details</summary>
Motivation: 随着云计算环境中智能设备的广泛应用，网络安全威胁日益严重，传统入侵检测系统存在局限性，需要更高效的混合解决方案。

Method: 使用EVO进行特征选择，结合监督机器学习模型构建HyIDS，并在多个数据集（CIC_DDoS2019、CSE_CIC_DDoS2018、NSL-KDD）上进行评估。

Result: EVO在特征选择上优于GWO，HyIDS在多个数据集上表现出色，最高准确率达99.78%，检测率超过98%。

Conclusion: EVO作为优化器显著提升了HyIDS的性能，为云计算环境提供了更高效的网络安全解决方案。

Abstract: Cybersecurity is one of the foremost challenges facing the world of cloud
computing. Recently, the widespread adoption of smart devices in cloud
computing environments that provide Internet-based services has become
prevalent. Therefore, it is essential to consider the security threats in these
environments. The use of intrusion detection systems can mitigate the
vulnerabilities of these systems. Furthermore, hybrid intrusion detection
systems can provide better protection compared to conventional intrusion
detection systems. These systems manage issues related to complexity,
dimensionality, and performance. This research aims to propose a Hybrid
Intrusion Detection System (HyIDS) that identifies and mitigates initial
threats. The main innovation of this research is the introduction of a new
method for hybrid intrusion detection systems (HyIDS). For this purpose, an
Energy-Valley Optimizer (EVO) is used to select an optimal feature set, which
is then classified using supervised machine learning models. The proposed
approach is evaluated using the CIC_DDoS2019, CSE_CIC_DDoS2018, and NSL-KDD
datasets. For evaluation and testing, the proposed system has been run for a
total of 32 times. The results of the proposed approach are compared with the
Grey Wolf Optimizer (GWO). With the CIC_DDoS2019 dataset, the D_TreeEVO model
achieves an accuracy of 99.13% and a detection rate of 98.941%. Furthermore,
this result reaches 99.78% for the CSE_CIC_DDoS2018 dataset. In comparison to
NSL-KDD, it has an accuracy of 99.50% and a detection rate (DT) of 99.48%. For
feature selection, EVO outperforms GWO. The results of this research indicate
that EVO yields better results as an optimizer for HyIDS performance.

</details>


### [20] [Quantum-Resistant Domain Name System: A Comprehensive System-Level Study](https://arxiv.org/abs/2506.19943)
*Juyoul Lee,Sanzida Hoque,Abdullah Aydeger,Engin Zeydan*

Main category: cs.CR

TL;DR: 本文研究了量子计算对DNS安全的威胁，提出了PQC-DNS框架，评估了后量子密码学在DNSSEC、DoT和DoH中的性能与安全性。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算机的威胁日益临近，确保DNS在量子时代的机密性、真实性和完整性变得至关重要。

Method: 提出PQC-DNS框架，结合Open Quantum Safe库，将基于格和哈希的密码学原语集成到BIND9和TLS 1.3中，评估性能与安全性。

Result: 实验表明，基于格的MLKEM和Falcon具有实用延迟和资源占用，而哈希方案如SPHINCS+增加了消息大小和处理开销。

Conclusion: 研究为部署量子安全DNS提供了实用指导，并为后量子时代核心互联网协议的安全奠定了基础。

Abstract: The Domain Name System (DNS) plays a foundational role in Internet
infrastructure, yet its core protocols remain vulnerable to compromise by
quantum adversaries. As cryptographically relevant quantum computers become a
realistic threat, ensuring DNS confidentiality, authenticity, and integrity in
the post-quantum era is imperative. In this paper, we present a comprehensive
system-level study of post-quantum DNS security across three widely deployed
mechanisms: DNSSEC, DNS-over-TLS (DoT), and DNS-over-HTTPS (DoH). We propose
Post-Quantum Cryptographic (PQC)-DNS, a unified framework for benchmarking DNS
security under legacy, post-quantum, and hybrid cryptographic configurations.
Our implementation leverages the Open Quantum Safe (OQS) libraries and
integrates lattice- and hash-based primitives into BIND9 and TLS 1.3 stacks. We
formalize performance and threat models and analyze the impact of post-quantum
key encapsulation and digital signatures on end-to-end DNS resolution.
Experimental results on a containerized testbed reveal that lattice-based
primitives such as Module-Lattice-Based Key-Encapsulation Mechanism (MLKEM) and
Falcon offer practical latency and resource profiles, while hash-based schemes
like SPHINCS+ significantly increase message sizes and processing overhead. We
also examine security implications including downgrade risks, fragmentation
vulnerabilities, and susceptibility to denial-of-service amplification. Our
findings inform practical guidance for deploying quantum-resilient DNS and
contribute to the broader effort of securing core Internet protocols for the
post-quantum future.

</details>


### [21] [Can One Safety Loop Guard Them All? Agentic Guard Rails for Federated Computing](https://arxiv.org/abs/2506.20000)
*Narasimha Raghavan Veeraragavan,Jan Franz Nygård*

Main category: cs.CR

TL;DR: Guardian-FC是一个双层框架，用于统一隐私保护联邦计算中的安全执行，支持多种隐私保护机制，如FHE、MPC和DP。


<details>
  <summary>Details</summary>
Motivation: 解决隐私保护联邦计算中安全执行机制的多样性和复杂性，提供统一的安全管理。

Method: 采用模块化设计，通过后端无关的DSL和可互换的执行提供者（EPs）实现隐私机制的解耦，并通过AI控制平面确保安全性。

Result: 提出了一个支持快速失败任务准入和可扩展性的框架，并展示了后端无关的安全性和验证模型。

Conclusion: Guardian-FC为隐私保护联邦计算提供了灵活且可扩展的解决方案，并提出了未来研究方向。

Abstract: We propose Guardian-FC, a novel two-layer framework for privacy preserving
federated computing that unifies safety enforcement across diverse privacy
preserving mechanisms, including cryptographic back-ends like fully homomorphic
encryption (FHE) and multiparty computation (MPC), as well as statistical
techniques such as differential privacy (DP). Guardian-FC decouples guard-rails
from privacy mechanisms by executing plug-ins (modular computation units),
written in a backend-neutral, domain-specific language (DSL) designed
specifically for federated computing workflows and interchangeable Execution
Providers (EPs), which implement DSL operations for various privacy back-ends.
An Agentic-AI control plane enforces a finite-state safety loop through signed
telemetry and commands, ensuring consistent risk management and auditability.
The manifest-centric design supports fail-fast job admission and seamless
extensibility to new privacy back-ends. We present qualitative scenarios
illustrating backend-agnostic safety and a formal model foundation for
verification. Finally, we outline a research agenda inviting the community to
advance adaptive guard-rail tuning, multi-backend composition, DSL
specification development, implementation, and compiler extensibility alongside
human-override usability.

</details>


### [22] [Attack Smarter: Attention-Driven Fine-Grained Webpage Fingerprinting Attacks](https://arxiv.org/abs/2506.20082)
*Yali Yuan,Weiyi Zou,Guang Cheng*

Main category: cs.CR

TL;DR: 论文提出了一种名为ADWPF的注意力驱动细粒度网页指纹攻击方法，用于解决大规模环境中网页指纹识别的问题，特别是在多标签浏览场景下的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统网站指纹攻击（WF）在实验环境中有效，但在实际应用中仅能识别主页，且难以处理多标签浏览场景。因此，需要一种能够识别子页面并处理多标签浏览的方法。

Method: ADWPF通过注意力驱动的数据增强（如注意力裁剪和掩码）提取低维特征，并利用自注意力模块捕捉全局上下文模式。针对多标签场景，使用残差注意力生成不同时间位置的网页类别表示。

Result: 实验表明，ADWPF在不同规模的数据集上均优于现有基线方法。

Conclusion: ADWPF是一种有效的大规模网页指纹攻击方法，能够处理多标签浏览场景，显著提升识别性能。

Abstract: Website Fingerprinting (WF) attacks aim to infer which websites a user is
visiting by analyzing traffic patterns, thereby compromising user anonymity.
Although this technique has been demonstrated to be effective in controlled
experimental environments, it remains largely limited to small-scale scenarios,
typically restricted to recognizing website homepages. In practical settings,
however, users frequently access multiple subpages in rapid succession, often
before previous content fully loads. WebPage Fingerprinting (WPF) generalizes
the WF framework to large-scale environments by modeling subpages of the same
site as distinct classes. These pages often share similar page elements,
resulting in lower inter-class variance in traffic features. Furthermore, we
consider multi-tab browsing scenarios, in which a single trace encompasses
multiple categories of webpages. This leads to overlapping traffic segments,
and similar features may appear in different positions within the traffic,
thereby increasing the difficulty of classification. To address these
challenges, we propose an attention-driven fine-grained WPF attack, named
ADWPF. Specifically, during the training phase, we apply targeted augmentation
to salient regions of the traffic based on attention maps, including attention
cropping and attention masking. ADWPF then extracts low-dimensional features
from both the original and augmented traffic and applies self-attention modules
to capture the global contextual patterns of the trace. Finally, to handle the
multi-tab scenario, we employ the residual attention to generate class-specific
representations of webpages occurring at different temporal positions.
Extensive experiments demonstrate that the proposed method consistently
surpasses state-of-the-art baselines across datasets of different scales.

</details>


### [23] [Secure Multi-Key Homomorphic Encryption with Application to Privacy-Preserving Federated Learning](https://arxiv.org/abs/2506.20101)
*Jiahui Wu,Tiecheng Sun,Fucai Luo,Haiyan Wang,Weizhe Zhang*

Main category: cs.CR

TL;DR: 本文发现CDKS方案在多密钥同态加密中存在安全漏洞，并提出新的SMHE方案以解决信息泄露问题，同时验证其在隐私保护联邦学习中的高效性。


<details>
  <summary>Details</summary>
Motivation: 多密钥同态加密（MKHE）在多数据提供者场景下具有潜力，但CDKS方案在安全计算中存在信息泄露风险，亟需改进。

Method: 提出SMHE方案，引入新的掩码机制，应用于多密钥BFV和CKKS框架，确保计算过程中明文保密。

Result: SMHE在隐私保护联邦学习中显著提升安全性，仅带来轻微的性能开销（如运行时间和通信流量增加不到2倍）。

Conclusion: SMHE有效解决了CDKS的安全漏洞，为多密钥同态加密提供了更安全的解决方案。

Abstract: Multi-Key Homomorphic Encryption (MKHE), proposed by Lopez-Alt et al. (STOC
2012), allows for performing arithmetic computations directly on ciphertexts
encrypted under distinct keys. Subsequent works by Chen and Dai et al. (CCS
2019) and Kim and Song et al. (CCS 2023) extended this concept by proposing
multi-key BFV/CKKS variants, referred to as the CDKS scheme. These variants
incorporate asymptotically optimal techniques to facilitate secure computation
across multiple data providers. In this paper, we identify a critical security
vulnerability in the CDKS scheme when applied to multiparty secure computation
tasks, such as privacy-preserving federated learning (PPFL). In particular, we
show that CDKS may inadvertently leak plaintext information from one party to
others. To mitigate this issue, we propose a new scheme, SMHE (Secure Multi-Key
Homomorphic Encryption), which incorporates a novel masking mechanism into the
multi-key BFV and CKKS frameworks to ensure that plaintexts remain confidential
throughout the computation. We implement a PPFL application using SMHE and
demonstrate that it provides significantly improved security with only a modest
overhead in homomorphic evaluation. For instance, our PPFL model based on
multi-key CKKS incurs less than a 2\times runtime and communication traffic
increase compared to the CDKS-based PPFL model. The code is publicly available
at https://github.com/JiahuiWu2022/SMHE.git.

</details>


### [24] [Autonomous Cyber Resilience via a Co-Evolutionary Arms Race within a Fortified Digital Twin Sandbox](https://arxiv.org/abs/2506.20102)
*Malikussaid,Sutiyo*

Main category: cs.CR

TL;DR: 论文提出ARC框架，通过自主闭环的强化过程实现分析韧性，利用红蓝代理的协同进化动态提升系统安全性。


<details>
  <summary>Details</summary>
Motivation: IT与OT融合导致关键基础设施面临新型智能攻击，静态防御失效，需解决信任三要素（系统模型保真度、数据同步完整性和分析引擎韧性）。

Method: 引入ARC框架，包括红代理（DRL智能体）发现攻击路径和蓝代理（集成防御者）通过对抗训练持续强化，形成协同进化。

Result: 在TEP和SWaT测试平台上验证了框架的优越性能，协同进化显著提升了对新型攻击的检测能力。

Conclusion: ARC不仅是改进，更是向动态自改进安全范式的必要转变，适用于未来关键基础设施。

Abstract: The convergence of IT and OT has created hyper-connected ICS, exposing
critical infrastructure to a new class of adaptive, intelligent adversaries
that render static defenses obsolete. Existing security paradigms often fail to
address a foundational "Trinity of Trust," comprising the fidelity of the
system model, the integrity of synchronizing data, and the resilience of the
analytical engine against sophisticated evasion. This paper introduces the ARC
framework, a method for achieving analytical resilience through an autonomous,
closed-loop hardening process. ARC establishes a perpetual co-evolutionary arms
race within the high-fidelity sandbox of a F-SCDT. A DRL agent, the "Red
Agent," is formalized and incentivized to autonomously discover stealthy,
physically-plausible attack paths that maximize process disruption while
evading detection. Concurrently, an ensemble-based "Blue Agent" defender is
continuously hardened via adversarial training against the evolving threats
discovered by its adversary. This co-evolutionary dynamic forces both agents to
become progressively more sophisticated, enabling the system to autonomously
probe and patch its own vulnerabilities. Experimental validation on both the
TEP and the SWaT testbeds demonstrates the framework's superior performance. A
comprehensive ablation study, supported by extensive visualizations including
ROC curves and SHAP plots, reveals that the co-evolutionary process itself is
responsible for a significant performance increase in detecting novel attacks.
By integrating XAI to ensure operator trust and proposing a scalable F-ARC
architecture, this work presents ARC not merely as an improvement, but as a
necessary paradigm shift toward dynamic, self-improving security for the future
of critical infrastructure.

</details>


### [25] [Evaluating Disassembly Errors With Only Binaries](https://arxiv.org/abs/2506.20109)
*Lambang Akbar Wijayadi,Yuancheng Jiang,Roland H. C. Yap,Zhenkai Liang,Zhuohao Liu*

Main category: cs.CR

TL;DR: TraceBin提出了一种仅依赖二进制文件评估反汇编错误的方法，无需源代码，填补了现有研究的空白，并展示了反汇编错误对安全任务的潜在影响。


<details>
  <summary>Details</summary>
Motivation: 现有反汇编错误评估方法依赖源代码和编译器工具链，与仅二进制可用的实际场景不符，亟需一种无需源代码的可靠评估方法。

Method: 提出TraceBin，通过动态执行发现反汇编错误，适用于自动化安全任务（如静态二进制插桩、代码修复等）。

Result: TraceBin发现多种反汇编错误（包括控制流错误、非C/C++二进制错误、闭源二进制错误），并揭示其对安全的潜在影响。

Conclusion: TraceBin在无需源代码的情况下有效评估反汇编错误，为依赖反汇编的自动化安全任务提供了实用工具。

Abstract: Disassemblers are crucial in the analysis and modification of binaries.
Existing works showing disassembler errors largely rely on practical
implementation without specific guarantees and assume source code and compiler
toolchains to evaluate ground truth. However, the assumption of source code is
contrary to typical binary scenarios where only the binary is available. In
this work, we investigate an approach with minimal assumptions and a sound
approach to disassembly error evaluation that does not require source code. Any
source code does not address the fundamental problem of binary disassembly and
fails when only the binary exists. As far as we know, this is the first work to
evaluate disassembly errors using only the binary. We propose TraceBin, which
uses dynamic execution to find disassembly errors. TraceBin targets the use
case where the disassembly is used in an automated fashion for security tasks
on a target binary, such as static binary instrumentation, binary hardening,
automated code repair, and so on, which may be affected by disassembly errors.
Discovering disassembly errors in the target binary aids in reducing problems
caused by such errors. Furthermore, we are not aware of existing approaches
that can evaluate errors given only a target binary, as they require source
code. Our evaluation shows TraceBin finds: (i) errors consistent with existing
studies even without source; (ii) disassembly errors due to control flow; (iii)
new interesting errors; (iv) errors in non-C/C++ binaries; (v) errors in
closed-source binaries; and (vi) show that disassembly errors can have
significant security implications. Overall, our experimental results show that
TraceBin finds many errors in existing popular disassemblers. It is also
helpful in automated security tasks on (closed source) binaries relying on
disassemblers.

</details>


### [26] [JsDeObsBench: Measuring and Benchmarking LLMs for JavaScript Deobfuscation](https://arxiv.org/abs/2506.20170)
*Guoqiang Chen,Xin Jin,Zhiqiang Lin*

Main category: cs.CR

TL;DR: JsDeObsBench是一个专门用于评估大型语言模型（LLMs）在JavaScript反混淆任务中表现的基准测试，填补了现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: JavaScript混淆技术常被用于隐藏恶意代码，而LLMs在反混淆方面显示出潜力，但缺乏系统性评估其效果和局限性的基准。

Method: 提出了JsDeObsBench基准，涵盖从基础变量重命名到复杂结构变换的多种混淆技术，用于评估LLMs在实际场景中的表现。

Result: 实验表明，前沿LLMs（如GPT-4o、Mixtral等）在代码简化方面表现优异，但在语法准确性和执行可靠性上仍有挑战。

Conclusion: LLMs在反混淆应用中具有潜力，但仍需进一步改进语法准确性和执行可靠性。

Abstract: Deobfuscating JavaScript (JS) code poses a significant challenge in web
security, particularly as obfuscation techniques are frequently used to conceal
malicious activities within scripts. While Large Language Models (LLMs) have
recently shown promise in automating the deobfuscation process, transforming
detection and mitigation strategies against these obfuscated threats, a
systematic benchmark to quantify their effectiveness and limitations has been
notably absent. To address this gap, we present JsDeObsBench, a dedicated
benchmark designed to rigorously evaluate the effectiveness of LLMs in the
context of JS deobfuscation. We detail our benchmarking methodology, which
includes a wide range of obfuscation techniques ranging from basic variable
renaming to sophisticated structure transformations, providing a robust
framework for assessing LLM performance in real-world scenarios. Our extensive
experimental analysis investigates the proficiency of cutting-edge LLMs, e.g.,
GPT-4o, Mixtral, Llama, and DeepSeek-Coder, revealing superior performance in
code simplification despite challenges in maintaining syntax accuracy and
execution reliability compared to baseline methods. We further evaluate the
deobfuscation of JS malware to exhibit the potential of LLMs in security
scenarios. The findings highlight the utility of LLMs in deobfuscation
applications and pinpoint crucial areas for further improvement.

</details>


### [27] [Measuring Modern Phishing Tactics: A Quantitative Study of Body Obfuscation Prevalence, Co-occurrence, and Filter Impact](https://arxiv.org/abs/2506.20228)
*Antony Dalmiere,Zheng Zhou,Guillaume Auriol,Vincent Nicomette,Pascal Marchand*

Main category: cs.CR

TL;DR: 论文研究了钓鱼邮件中常见的邮件正文混淆技术及其对反垃圾邮件过滤的影响，发现某些技术组合能显著规避检测。


<details>
  <summary>Details</summary>
Motivation: 钓鱼邮件常通过混淆技术绕过检测，但缺乏对这些技术组合及其影响的定量研究。

Method: 分析了386封已验证的钓鱼邮件，量化了10种混淆技术，并评估了它们与反垃圾邮件分数的关联。

Result: Base64编码和图片内文字的组合能显著规避检测，而无效HTML则与更高的反垃圾邮件分数相关。

Conclusion: 研究为复杂规避策略提供了定量基准，强调了多模态防御的必要性。

Abstract: Phishing attacks frequently use email body obfuscation to bypass detection
filters, but quantitative insights into how techniques are combined and their
impact on filter scores remain limited. This paper addresses this gap by
empirically investigating the prevalence, co-occurrence patterns, and spam
score associations of body obfuscation techniques. Analysing 386 verified
phishing emails, we quantified ten techniques, identified significant pairwise
co-occurrences revealing strategic layering like the presence of text in images
with multipart abuse, and assessed associations with antispam scores using
multilinear regression. Text in Image (47.0%), Base64 Encoding (31.2%), and
Invalid HTML (28.8%) were highly prevalent. Regression (R${}^2$=0.486, p<0.001)
linked Base64 Encoding and Text in Image with significant antispam evasion
(p<0.05) in this configuration, suggesting potential bypass capabilities, while
Invalid HTML correlated with higher scores. These findings establish a
quantitative baseline for complex evasion strategies, underscoring the need for
multi-modal defences against combined obfuscation tactics.

</details>


### [28] [Communication-Efficient Publication of Sparse Vectors under Differential Privacy](https://arxiv.org/abs/2506.20234)
*Quentin Hillebrand,Vorapong Suppakitpaisarn,Tetsuo Shibuya*

Main category: cs.CR

TL;DR: 提出了一种差分隐私算法，用于发布稀疏向量聚合的矩阵，显著降低了通信成本。


<details>
  <summary>Details</summary>
Motivation: 传统差分隐私方法在向量收集中依赖随机响应，导致高通信成本，不适用于大规模数据。

Method: 提出了一种新算法，将通信成本从$\Omega(n \times N)$降至$O(\varepsilon m)$，甚至低于非隐私情况。

Result: 理论证明和实验评估表明，该方法在准确性、通信效率和计算复杂度上均优于传统方法。

Conclusion: 该算法在保证隐私的同时，显著提升了效率，适用于大规模数据发布。

Abstract: In this work, we propose a differentially private algorithm for publishing
matrices aggregated from sparse vectors. These matrices include social network
adjacency matrices, user-item interaction matrices in recommendation systems,
and single nucleotide polymorphisms (SNPs) in DNA data. Traditionally,
differential privacy in vector collection relies on randomized response, but
this approach incurs high communication costs. Specifically, for a matrix with
$N$ users, $n$ columns, and $m$ nonzero elements, conventional methods require
$\Omega(n \times N)$ communication, making them impractical for large-scale
data. Our algorithm significantly reduces this cost to $O(\varepsilon m)$,
where $\varepsilon$ is the privacy budget. Notably, this is even lower than the
non-private case, which requires $\Omega(m \log n)$ communication. Moreover, as
the privacy budget decreases, communication cost further reduces, enabling
better privacy with improved efficiency. We theoretically prove that our method
yields results identical to those of randomized response, and experimental
evaluations confirm its effectiveness in terms of accuracy, communication
efficiency, and computational complexity.

</details>


### [29] [Don't Hash Me Like That: Exposing and Mitigating Hash-Induced Unfairness in Local Differential Privacy](https://arxiv.org/abs/2506.20290)
*Berkay Kemal Balioglu,Alireza Khodaie,Mehmet Emre Gursoy*

Main category: cs.CR

TL;DR: 论文揭示了局部差分隐私（LDP）中哈希函数选择可能导致不公平性，并提出了一种改进方法Fair-OLH（F-OLH）来缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 研究哈希函数选择在LDP协议中对安全性和隐私性的潜在影响，特别是其可能导致的不公平性问题。

Method: 提出Fair-OLH（F-OLH），一种基于熵的哈希函数选择公平性约束的改进方法。

Result: 实验表明F-OLH能有效缓解哈希函数导致的不公平性，且时间开销在可接受范围内。

Conclusion: 哈希函数选择在LDP中可能导致不公平性，F-OLH提供了一种有效的解决方案。

Abstract: Local differential privacy (LDP) has become a widely accepted framework for
privacy-preserving data collection. In LDP, many protocols rely on hash
functions to implement user-side encoding and perturbation. However, the
security and privacy implications of hash function selection have not been
previously investigated. In this paper, we expose that the hash functions may
act as a source of unfairness in LDP protocols. We show that although users
operate under the same protocol and privacy budget, differences in hash
functions can lead to significant disparities in vulnerability to inference and
poisoning attacks. To mitigate hash-induced unfairness, we propose Fair-OLH
(F-OLH), a variant of OLH that enforces an entropy-based fairness constraint on
hash function selection. Experiments show that F-OLH is effective in mitigating
hash-induced unfairness under acceptable time overheads.

</details>


### [30] [SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models](https://arxiv.org/abs/2506.20415)
*Dipayan Saha,Shams Tarek,Hasan Al Shaikh,Khan Thamid Hasan,Pavan Sai Nalluri,Md. Ajoad Hasan,Nashmin Alam,Jingbo Zhou,Sujan Kumar Saha,Mark Tehranipoor,Farimah Farahmandi*

Main category: cs.CR

TL;DR: SV-LLM是一个多代理系统，利用大型语言模型（LLMs）自动化SoC安全验证，通过任务分工和多种学习范式提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统SoC安全验证方法在自动化、扩展性和适应性方面存在不足，LLMs的潜力为解决这些问题提供了新途径。

Method: 采用多代理系统，每个代理专注于特定任务（如威胁建模、漏洞检测等），并结合上下文学习、微调和RAG等学习范式。

Result: SV-LLM减少了人工干预，提高了准确性，并通过案例研究验证了其有效性。

Conclusion: SV-LLM有望革新硬件安全实践，提前识别和缓解设计风险。

Abstract: Ensuring the security of complex system-on-chips (SoCs) designs is a critical
imperative, yet traditional verification techniques struggle to keep pace due
to significant challenges in automation, scalability, comprehensiveness, and
adaptability. The advent of large language models (LLMs), with their remarkable
capabilities in natural language understanding, code generation, and advanced
reasoning, presents a new paradigm for tackling these issues. Moving beyond
monolithic models, an agentic approach allows for the creation of multi-agent
systems where specialized LLMs collaborate to solve complex problems more
effectively. Recognizing this opportunity, we introduce SV-LLM, a novel
multi-agent assistant system designed to automate and enhance SoC security
verification. By integrating specialized agents for tasks like verification
question answering, security asset identification, threat modeling, test plan
and property generation, vulnerability detection, and simulation-based bug
validation, SV-LLM streamlines the workflow. To optimize their performance in
these diverse tasks, agents leverage different learning paradigms, such as
in-context learning, fine-tuning, and retrieval-augmented generation (RAG). The
system aims to reduce manual intervention, improve accuracy, and accelerate
security analysis, supporting proactive identification and mitigation of risks
early in the design cycle. We demonstrate its potential to transform hardware
security practices through illustrative case studies and experiments that
showcase its applicability and efficacy.

</details>


### [31] [Generative AI for Vulnerability Detection in 6G Wireless Networks: Advances, Case Study, and Future Directions](https://arxiv.org/abs/2506.20488)
*Shuo Yang,Xinran Zheng,Jinfeng Xu,Jinze Li,Danyang Song,Zheyu Chen,Edith C. H. Ngai*

Main category: cs.CR

TL;DR: 论文探讨了在6G无线网络中利用生成式AI（GAI）增强漏洞检测，提出一个三层框架，并通过案例研究展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 6G、物联网和边缘计算的快速发展扩大了网络攻击面，传统安全方法难以应对零日漏洞和动态威胁，需要更智能的解决方案。

Method: 提出一个三层框架（技术层、能力层、应用层），整合VAEs、GANs、LLMs和GDMs，并通过LLM驱动的代码漏洞检测案例验证。

Result: GAI在漏洞检测中表现出高效性和适应性，但仍面临轻量化模型、数据真实性等挑战。

Conclusion: GAI为6G网络安全提供了新方向，未来需关注轻量化、隐私保护等技术，以构建更具韧性的解决方案。

Abstract: The rapid advancement of 6G wireless networks, IoT, and edge computing has
significantly expanded the cyberattack surface, necessitating more intelligent
and adaptive vulnerability detection mechanisms. Traditional security methods,
while foundational, struggle with zero-day exploits, adversarial threats, and
context-dependent vulnerabilities in highly dynamic network environments.
Generative AI (GAI) emerges as a transformative solution, leveraging synthetic
data generation, multimodal reasoning, and adaptive learning to enhance
security frameworks. This paper explores the integration of GAI-powered
vulnerability detection in 6G wireless networks, focusing on code auditing,
protocol security, cloud-edge defenses, and hardware protection. We introduce a
three-layer framework comprising the Technology Layer, Capability Layer, and
Application Layer to systematically analyze the role of VAEs, GANs, LLMs, and
GDMs in securing next-generation wireless ecosystems. To demonstrate practical
implementation, we present a case study on LLM-driven code vulnerability
detection, highlighting its effectiveness, performance, and challenges.
Finally, we outline future research directions, including lightweight models,
high-authenticity data generation, external knowledge integration, and
privacy-preserving technologies. By synthesizing current advancements and open
challenges, this work provides a roadmap for researchers and practitioners to
harness GAI for building resilient and adaptive security solutions in 6G
networks.

</details>


### [32] [Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks on NIDS](https://arxiv.org/abs/2506.20576)
*Sabrine Ennaji,Elhadj Benkhelifa,Luigi V. Mancini*

Main category: cs.CR

TL;DR: 提出了一种针对网络流量数据的黑盒对抗攻击方法，通过自适应特征选择和轻量级设计，减少了交互次数并提高了实用性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法在结构化数据（如网络流量）中因特征依赖性和模糊性导致理论和实际应用脱节，且现有防御难以应对不断演变的攻击。

Method: 采用基于变化点检测和因果分析的自适应特征选择策略，严格遵循黑盒约束，减少交互以避免检测。

Result: 实验证明该方法能以最小交互有效规避检测，具有高适应性和实用性。

Conclusion: 该研究为网络流量中的对抗攻击提供了新思路，为开发鲁棒防御奠定了基础。

Abstract: Adversarial attacks, wherein slight inputs are carefully crafted to mislead
intelligent models, have attracted increasing attention. However, a critical
gap persists between theoretical advancements and practical application,
particularly in structured data like network traffic, where interdependent
features complicate effective adversarial manipulations. Moreover, ambiguity in
current approaches restricts reproducibility and limits progress in this field.
Hence, existing defenses often fail to handle evolving adversarial attacks.
This paper proposes a novel approach for black-box adversarial attacks, that
addresses these limitations. Unlike prior work, which often assumes system
access or relies on repeated probing, our method strictly respect black-box
constraints, reducing interaction to avoid detection and better reflect
real-world scenarios. We present an adaptive feature selection strategy using
change-point detection and causality analysis to identify and target sensitive
features to perturbations. This lightweight design ensures low computational
cost and high deployability. Our comprehensive experiments show the attack's
effectiveness in evading detection with minimal interaction, enhancing its
adaptability and applicability in real-world scenarios. By advancing the
understanding of adversarial attacks in network traffic, this work lays a
foundation for developing robust defenses.

</details>


### [33] [On the Impact of Sybil-based Attacks on Mobile Crowdsensing for Transportation](https://arxiv.org/abs/2506.20585)
*Alexander Söderhäll,Zahra Alimadadi,Panos Papadimitratos*

Main category: cs.CR

TL;DR: 该论文研究了移动群智感知（MCS）中基于虚假身份（Sybil）的攻击对导航应用（N-MCS）的影响，实验表明攻击可导致用户平均旅行时间增加20%。


<details>
  <summary>Details</summary>
Motivation: N-MCS易受虚假数据攻击，导致路线规划失效，影响交通效率。

Method: 设计N-MCS系统并结合SUMO模拟器和InTAS路网，实验攻击个体和群体用户。

Result: 攻击效果取决于攻击位置和虚假数据量，3%的虚假用户可使旅行时间增加20%。

Conclusion: Sybil攻击对N-MCS有显著负面影响，需加强防御措施。

Abstract: Mobile Crowd-Sensing (MCS) enables users with personal mobile devices (PMDs)
to gain information on their surroundings. Users collect and contribute data on
different phenomena using their PMD sensors, and the MCS system processes this
data to extract valuable information for end users. Navigation MCS-based
applications (N-MCS) are prevalent and important for transportation: users
share their location and speed while driving and, in return, find efficient
routes to their destinations. However, N-MCS are currently vulnerable to
malicious contributors, often termed Sybils: submitting falsified data,
seemingly from many devices that are not truly present on target roads, falsely
reporting congestion when there is none, thus changing the road status the
N-MCS infers. The attack effect is that the N-MCS returns suboptimal routes to
users, causing late arrival and, overall, deteriorating road traffic flow. We
investigate exactly the impact of Sybil-based attacks on N-MCS: we design an
N-MCS system that offers efficient routing on top of the vehicular simulator
SUMO, using the InTAS road network as our scenario. We design experiments
attacking an individual N-MCS user as well as a larger population of users,
selecting the adversary targets based on graph-theoretical arguments. Our
experiments show that the resources required for a successful attack depend on
the location of the attack (i.e., the surrounding road network and traffic) and
the extent of Sybil contributed data for the targeted road(s). We demonstrate
that Sybil attacks can alter the route of N-MCS users, increasing average
travel time by 20% with Sybils 3% of the N-MCS user population.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [34] [Prover Agent: An Agent-based Framework for Formal Mathematical Proofs](https://arxiv.org/abs/2506.19923)
*Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai*

Main category: cs.AI

TL;DR: Prover Agent是一个结合大型语言模型（LLMs）和形式化证明助手Lean的AI代理，用于自动定理证明，在MiniF2F基准测试中达到86.1%的成功率。


<details>
  <summary>Details</summary>
Motivation: 通过整合LLMs和形式化证明工具，提高自动定理证明的效率和成功率。

Method: 结合非正式推理LLM、形式化证明模型和Lean的反馈，生成辅助引理以支持整体证明策略。

Result: 在MiniF2F基准测试中达到86.1%的成功率，优于使用小型语言模型（SLMs）的现有方法，且样本预算更低。

Conclusion: Prover Agent通过生成辅助引理和协调多模型，显著提升了自动定理证明的性能。

Abstract: We present Prover Agent, a novel AI agent for automated theorem proving that
integrates large language models (LLMs) with a formal proof assistant, Lean.
Prover Agent coordinates an informal reasoning LLM, a formal prover model, and
feedback from Lean while also generating auxiliary lemmas to assist in
discovering the overall proof strategy. It achieves an 86.1% success rate on
the MiniF2F benchmark, establishing a new state-of-the-art among methods using
small language models (SLMs) with a much lower sample budget than previous
approaches. We also present case studies illustrating how these generated
lemmas contribute to solving challenging problems.

</details>


### [35] [Context Attribution with Multi-Armed Bandit Optimization](https://arxiv.org/abs/2506.19977)
*Deng Pan,Keerthiram Murugesan,Nuno Moniz,Nitesh Chawla*

Main category: cs.AI

TL;DR: 提出了一种基于组合多臂老虎机（CMAB）的框架，用于高效探索检索上下文对生成答案的贡献，显著提升了查询效率。


<details>
  <summary>Details</summary>
Motivation: 理解检索上下文对生成答案的贡献是构建可解释和可信生成式问答系统的关键。

Method: 将上下文归因问题建模为组合多臂老虎机（CMAB）问题，使用组合汤普森采样（CTS）高效探索上下文子集。

Result: 在多样化数据集和LLM上的实验表明，该方法以更少的查询实现了竞争性的归因质量。

Conclusion: 该方法通过自适应平衡探索与利用，显著提升了查询效率，同时保持了高归因保真度。

Abstract: Understanding which parts of the retrieved context contribute to a large
language model's generated answer is essential for building interpretable and
trustworthy generative QA systems. We propose a novel framework that formulates
context attribution as a combinatorial multi-armed bandit (CMAB) problem. Each
context segment is treated as a bandit arm, and we employ Combinatorial
Thompson Sampling (CTS) to efficiently explore the exponentially large space of
context subsets under a limited query budget. Our method defines a reward
function based on normalized token likelihoods, capturing how well a subset of
segments supports the original model response. Unlike traditional
perturbation-based attribution methods such as SHAP, which sample subsets
uniformly and incur high computational costs, our approach adaptively balances
exploration and exploitation by leveraging posterior estimates of segment
relevance. This leads to substantially improved query efficiency while
maintaining high attribution fidelity. Extensive experiments on diverse
datasets and LLMs demonstrate that our method achieves competitive attribution
quality with fewer model queries.

</details>


### [36] [QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges](https://arxiv.org/abs/2506.20008)
*Abdul Basit,Minghao Shao,Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique*

Main category: cs.AI

TL;DR: 论文评估了大型语言模型（LLMs）在量子计算代码生成中的表现，通过QHackBench数据集和RAG增强方法，发现RAG模型在复杂量子算法中表现接近标准提示方法，并提出了多代理评估流程以提高成功率。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在量子计算代码生成中的潜力，填补现有研究的空白。

Method: 使用QHackBench数据集，结合标准提示和RAG方法，评估模型的功能正确性、语法有效性和执行成功率。

Result: RAG增强模型在复杂量子算法中表现接近标准提示方法，多代理评估流程进一步提高了执行成功率。

Conclusion: 论文为AI辅助量子编程提供了新的基准和评估框架，推动了该领域的进一步发展。

Abstract: Recent advances in Large Language Models (LLMs) have demonstrated strong
potential in code generation, yet their effectiveness in quantum computing
remains underexplored. This paper benchmarks LLMs for PennyLane-based quantum
code generation using real-world challenges from the Quantum Hackathon (QHack).
We introduce QHackBench, a novel benchmark dataset derived from QHack
competitions, and evaluate model performance under vanilla prompting and
Retrieval-Augmented Generation (RAG). Our structured evaluation framework
assesses functional correctness, syntactic validity, and execution success
across varying challenge difficulties. Results indicate that RAG-enhanced
models, supplemented with an augmented PennyLane dataset, approximately
generate similar results as the standard prompting, particularly in complex
quantum algorithms. Additionally, we introduce a multi-agent evaluation
pipeline that iteratively refines incorrect solutions, further enhancing
execution success rates. To foster further research, we commit to publicly
releasing QHackBench, along with our evaluation framework and experimental
results, enabling continued advancements in AI-assisted quantum programming.

</details>


### [37] [Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks](https://arxiv.org/abs/2506.20009)
*Konstantinos Vrettos,Michail E. Klontzas*

Main category: cs.AI

TL;DR: 研究开发了一种可定制的RAG框架，用于医疗任务，其性能和能耗优于商业LLM模型，同时减少环境影响。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在医疗领域的应用对环境与伦理的影响，提出可持续的解决方案。

Method: 开发了可监控能耗和CO2排放的RAG框架，并基于开源LLM构建模型，与商业模型进行对比。

Result: 自定义RAG模型在准确性和能耗上均优于商业模型，llama3.1:8B表现最佳。

Conclusion: 本地LLM开发的RAG在医疗任务中表现更优且环保，支持可持续发展目标。

Abstract: Background The increasing adoption of Artificial Intelligence (AI) in
healthcare has sparked growing concerns about its environmental and ethical
implications. Commercial Large Language Models (LLMs), such as ChatGPT and
DeepSeek, require substantial resources, while the utilization of these systems
for medical purposes raises critical issues regarding patient privacy and
safety. Methods We developed a customizable Retrieval-Augmented Generation
(RAG) framework for medical tasks, which monitors its energy usage and CO2
emissions. This system was then used to create RAGs based on various
open-source LLMs. The tested models included both general purpose models like
llama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs
performance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs
o4-mini model. A dataset of medical questions was used for the evaluation.
Results Custom RAG models outperformed commercial models in accuracy and energy
consumption. The RAG model built on llama3.1:8B achieved the highest accuracy
(58.5%) and was significantly better than other models, including o4-mini and
DeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption
and CO2 footprint among all models, with a Performance per kWh of 0.52 and a
total CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x
times more accuracy points per kWh and 172% less electricity usage while
maintaining higher accuracy. Conclusion Our study demonstrates that local LLMs
can be leveraged to develop RAGs that outperform commercial, online LLMs in
medical tasks, while having a smaller environmental impact. Our modular
framework promotes sustainable AI development, reducing electricity usage and
aligning with the UNs Sustainable Development Goals.

</details>


### [38] [Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models](https://arxiv.org/abs/2506.20018)
*Zechun Deng,Ziwei Liu,Ziqian Bi,Junhao Song,Chia Xin Liang,Joe Yeong,Junfeng Hao*

Main category: cs.AI

TL;DR: 本文研究了利用低延迟AI模型的实时决策支持系统，结合了整体AI驱动决策工具、Edge-IoT技术集成和有效人机协作的最新进展。


<details>
  <summary>Details</summary>
Motivation: 探讨如何在大语言模型和资源有限的情况下提升决策支持能力，同时解决技术发展和框架适应性等问题。

Method: 通过详细综述，分析了DeLLMa、模型压缩技术和边缘设备分析改进等技术发展。

Result: 提供了开发策略和应用领域的实用视角，指出了高效灵活AI支持系统的机会。

Conclusion: 为这一快速变化领域的未来突破奠定了基础，强调了AI如何重塑实时决策支持。

Abstract: This paper investigates real-time decision support systems that leverage
low-latency AI models, bringing together recent progress in holistic AI-driven
decision tools, integration with Edge-IoT technologies, and approaches for
effective human-AI teamwork. It looks into how large language models can assist
decision-making, especially when resources are limited. The research also
examines the effects of technical developments such as DeLLMa, methods for
compressing models, and improvements for analytics on edge devices, while also
addressing issues like limited resources and the need for adaptable frameworks.
Through a detailed review, the paper offers practical perspectives on
development strategies and areas of application, adding to the field by
pointing out opportunities for more efficient and flexible AI-supported
systems. The conclusions set the stage for future breakthroughs in this
fast-changing area, highlighting how AI can reshape real-time decision support.

</details>


### [39] [Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning](https://arxiv.org/abs/2506.20020)
*Saloni Dash,Amélie Reymond,Emma S. Spiro,Aylin Caliskan*

Main category: cs.AI

TL;DR: 研究发现，大型语言模型（LLMs）在赋予特定政治和社会身份后，会表现出类似人类的动机性推理，导致判断偏差，且现有去偏方法效果有限。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否会在身份认同影响下进行动机性推理，从而加剧社会问题如政治极化和错误信息传播。

Method: 通过为8种LLMs赋予4种政治和社会身份，测试其在验证错误信息和评估科学证据任务中的表现。

Result: 身份赋予的LLMs在验证信息时准确率降低9%，政治身份模型在证据评估中更倾向于身份一致的结论。

Conclusion: LLMs表现出难以通过常规方法消除的动机性推理，可能加剧身份认同相关的判断偏差。

Abstract: Reasoning in humans is prone to biases due to underlying motivations like
identity protection, that undermine rational decision-making and judgment. This
motivated reasoning at a collective level can be detrimental to society when
debating critical issues such as human-driven climate change or vaccine safety,
and can further aggravate political polarization. Prior studies have reported
that large language models (LLMs) are also susceptible to human-like cognitive
biases, however, the extent to which LLMs selectively reason toward
identity-congruent conclusions remains largely unexplored. Here, we investigate
whether assigning 8 personas across 4 political and socio-demographic
attributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and
proprietary) across two reasoning tasks from human-subject studies -- veracity
discernment of misinformation headlines and evaluation of numeric scientific
evidence -- we find that persona-assigned LLMs have up to 9% reduced veracity
discernment relative to models without personas. Political personas
specifically, are up to 90% more likely to correctly evaluate scientific
evidence on gun control when the ground truth is congruent with their induced
political identity. Prompt-based debiasing methods are largely ineffective at
mitigating these effects. Taken together, our empirical findings are the first
to suggest that persona-assigned LLMs exhibit human-like motivated reasoning
that is hard to mitigate through conventional debiasing prompts -- raising
concerns of exacerbating identity-congruent reasoning in both LLMs and humans.

</details>


### [40] [DiaLLMs: EHR Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction](https://arxiv.org/abs/2506.20059)
*Weijieying Ren,Tianxiang Zhao,Lei Wang,Tianchun Wang,Vasant Honavar*

Main category: cs.AI

TL;DR: DiaLLM是一种新型医疗大语言模型，整合电子健康记录（EHR）数据，支持临床测试推荐、结果解释和诊断预测，优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有医疗大语言模型忽视电子健康记录（EHR）的作用，且仅关注诊断推荐，限制了临床应用。

Method: 提出DiaLLM，设计临床测试参考（CTR）策略处理EHR数据，采用强化学习框架进行证据获取和自动诊断，并引入拒绝采样策略和奖励机制。

Result: 实验表明，DiaLLM在临床测试推荐和诊断预测方面优于基线模型。

Conclusion: DiaLLM通过整合EHR数据和优化学习策略，显著提升了医疗对话模型的临床实用性。

Abstract: Recent advances in Large Language Models (LLMs) have led to remarkable
progresses in medical consultation. However, existing medical LLMs overlook the
essential role of Electronic Health Records (EHR) and focus primarily on
diagnosis recommendation, limiting their clinical applicability. We propose
DiaLLM, the first medical LLM that integrates heterogeneous EHR data into
clinically grounded dialogues, enabling clinical test recommendation, result
interpretation, and diagnosis prediction to better align with real-world
medical practice. To construct clinically grounded dialogues from EHR, we
design a Clinical Test Reference (CTR) strategy that maps each clinical code to
its corresponding description and classifies test results as "normal" or
"abnormal". Additionally, DiaLLM employs a reinforcement learning framework for
evidence acquisition and automated diagnosis. To handle the large action space,
we introduce a reject sampling strategy to reduce redundancy and improve
exploration efficiency. Furthermore, a confirmation reward and a
class-sensitive diagnosis reward are designed to guide accurate diagnosis
prediction. Extensive experimental results demonstrate that DiaLLM outperforms
baselines in clinical test recommendation and diagnosis prediction.

</details>


### [41] [AI Copilots for Reproducibility in Science: A Case Study](https://arxiv.org/abs/2506.20130)
*Adrien Bibal,Steven N. Minton,Deborah Khider,Yolanda Gil*

Main category: cs.AI

TL;DR: OpenPub是一个AI驱动的平台，通过模块化助手支持开放科学任务，特别是可重复性助手，显著减少研究复现时间。


<details>
  <summary>Details</summary>
Motivation: 解决开放科学中研究结果难以独立复现的挑战。

Method: 开发Reproducibility Copilot，分析论文、代码和补充材料，生成结构化Jupyter Notebook和建议。

Result: 测试显示，复现时间从30小时降至1小时，并能高覆盖率复现图表和结果。

Conclusion: AI工具可有效减轻复现负担，促进透明科学交流，模块化架构支持扩展其他开放科学目标。

Abstract: Open science initiatives seek to make research outputs more transparent,
accessible, and reusable, but ensuring that published findings can be
independently reproduced remains a persistent challenge. This paper introduces
OpenPub, an AI-powered platform that supports researchers, reviewers, and
readers through a suite of modular copilots focused on key open science tasks.
In this work, we present the Reproducibility Copilot, which analyzes
manuscripts, code, and supplementary materials to generate structured Jupyter
Notebooks and recommendations aimed at facilitating computational, or "rote",
reproducibility. We conducted feasibility tests using previously studied
research papers with known reproducibility benchmarks. Results indicate that
OpenPub can substantially reduce reproduction time - from over 30 hours to
about 1 hour - while achieving high coverage of figures, tables, and results
suitable for computational reproduction. The system systematically detects
barriers to reproducibility, including missing hyperparameters, undocumented
preprocessing steps, and incomplete or inaccessible datasets. These findings
suggest that AI-driven tools can meaningfully reduce the burden of
reproducibility efforts and contribute to more transparent and verifiable
scientific communication. The modular copilot architecture also provides a
foundation for extending AI assistance to additional open science objectives
beyond reproducibility.

</details>


### [42] [Language Modeling by Language Models](https://arxiv.org/abs/2506.20249)
*Junyan Cheng,Peter Clark,Kyle Richardson*

Main category: cs.AI

TL;DR: 利用多智能体LLM模拟研究过程，提出Genesys系统，通过遗传编程生成新架构设计，验证效果优于已知架构。


<details>
  <summary>Details</summary>
Motivation: 探索利用LLM发现新型语言模型架构的可行性，模拟真实研究流程以提高效率。

Method: 采用多智能体LLM方法，结合遗传编程和Ladder of Scales策略，逐步验证设计。

Result: 生成1,162个新设计，其中1,062个通过预训练验证，部分设计在6/9基准测试中优于GPT2和Mamba2。

Conclusion: Genesys系统在自主发现高效架构方面具有潜力，遗传编程优于直接提示生成。

Abstract: Can we leverage LLMs to model the process of discovering novel language model
(LM) architectures? Inspired by real research, we propose a multi-agent LLM
approach that simulates the conventional stages of research, from ideation and
literature search (proposal stage) to design implementation (code generation),
generative pre-training, and downstream evaluation (verification). Using ideas
from scaling laws, our system, Genesys, employs a Ladder of Scales approach;
new designs are proposed, adversarially reviewed, implemented, and selectively
verified at increasingly larger model scales (14M$\sim$350M parameters) with a
narrowing budget (the number of models we can train at each scale). To help
make discovery efficient and factorizable, Genesys uses a novel genetic
programming backbone, which we show has empirical advantages over commonly used
direct prompt generation workflows (e.g., $\sim$86\% percentage point
improvement in successful design generation, a key bottleneck). We report
experiments involving 1,162 newly discovered designs (1,062 fully verified
through pre-training) and find the best designs to be highly competitive with
known architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common
benchmarks). We couple these results with comprehensive system-level ablations
and formal results, which give broader insights into the design of effective
autonomous discovery systems.

</details>


### [43] [Enterprise Large Language Model Evaluation Benchmark](https://arxiv.org/abs/2506.20274)
*Liya Wang,David Yi,Damien Jose,John Passarelli,James Gao,Jordan Leventis,Kang Li*

Main category: cs.AI

TL;DR: 提出了一种基于Bloom分类法的14任务框架，用于全面评估大语言模型（LLM）在企业环境中的能力，并开发了可扩展的数据标注和评估流程。


<details>
  <summary>Details</summary>
Motivation: 现有基准（如MMLU）未能充分评估企业特定任务的复杂性，需要更全面的评估方法。

Method: 结合LLM-as-a-Labeler、LLM-as-a-Judge和CRAG技术，构建了一个9,700样本的基准数据集。

Result: 开源模型（如DeepSeek R1）在推理任务中表现接近专有模型，但在判断任务中表现较差，可能因过度思考。

Conclusion: 该研究为企业提供了定制化评估的蓝图，并推动了LLM的实际部署。

Abstract: Large Language Models (LLMs) ) have demonstrated promise in boosting
productivity across AI-powered tools, yet existing benchmarks like Massive
Multitask Language Understanding (MMLU) inadequately assess enterprise-specific
task complexities. We propose a 14-task framework grounded in Bloom's Taxonomy
to holistically evaluate LLM capabilities in enterprise contexts. To address
challenges of noisy data and costly annotation, we develop a scalable pipeline
combining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented
generation (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six
leading models shows open-source contenders like DeepSeek R1 rival proprietary
models in reasoning tasks but lag in judgment-based scenarios, likely due to
overthinking. Our benchmark reveals critical enterprise performance gaps and
offers actionable insights for model optimization. This work provides
enterprises a blueprint for tailored evaluations and advances practical LLM
deployment.

</details>


### [44] [Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards](https://arxiv.org/abs/2506.20332)
*Jihao Gu,Qihang Ai,Yingyao Wang,Pi Bu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Ziming Wang,Yingxiu Zhao,Ming-Liang Zhang,Jun Song,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: 提出Mobile-R1方法，通过任务级奖励的多轮交互强化学习提升移动代理的探索和纠错能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究局限于离线强化学习或动作级奖励的在线优化，导致代理动态交互能力不足，易陷入局部最优。

Method: 采用三阶段训练框架：初始格式微调、动作级奖励的单步在线训练、任务级奖励的多轮轨迹在线训练。

Result: 显著提升性能，并发布包含28个中国应用的数据集和500轨迹的新基准。

Conclusion: Mobile-R1有效增强代理的探索和纠错能力，相关资源将开源。

Abstract: Vision-language model-based mobile agents have gained the ability to not only
understand complex instructions and mobile screenshots, but also optimize their
action outputs via thinking and reasoning, benefiting from reinforcement
learning, such as Group Relative Policy Optimization (GRPO). However, existing
research centers on offline reinforcement learning training or online
optimization using action-level rewards, which limits the agent's dynamic
interaction with the environment. This often results in agents settling into
local optima, thereby weakening their ability for exploration and error action
correction. To address these challenges, we introduce an approach called
Mobile-R1, which employs interactive multi-turn reinforcement learning with
task-level rewards for mobile agents. Our training framework consists of three
stages: initial format finetuning, single-step online training via action-level
reward, followed by online training via task-level reward based on multi-turn
trajectories. This strategy is designed to enhance the exploration and error
correction capabilities of Mobile-R1, leading to significant performance
improvements. Moreover, we have collected a dataset covering 28 Chinese
applications with 24,521 high-quality manual annotations and established a new
benchmark with 500 trajectories. We will open source all resources, including
the dataset, benchmark, model weight, and codes:
https://mobile-r1.github.io/Mobile-R1/.

</details>


### [45] [Tabular Feature Discovery With Reasoning Type Exploration](https://arxiv.org/abs/2506.20357)
*Sungwon Han,Sungkyu Park,Seungeon Lee*

Main category: cs.AI

TL;DR: 论文提出了一种名为REFeat的新方法，通过引导大型语言模型（LLM）利用多种推理类型生成多样且信息丰富的特征，解决了现有LLM方法生成特征过于简单或重复的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的特征生成方法存在特征过于简单或重复的问题，主要原因是LLM选择的转换存在固有偏差以及生成过程中缺乏结构化推理指导。

Method: 提出REFeat方法，通过多种推理类型引导LLM生成特征，并在59个基准数据集上进行实验。

Result: 实验结果表明，REFeat不仅平均预测准确率更高，还能生成更多样且有意义的特征。

Conclusion: 研究强调了在LLM驱动的特征发现中结合丰富推理范式和自适应策略选择的重要性。

Abstract: Feature engineering for tabular data remains a critical yet challenging step
in machine learning. Recently, large language models (LLMs) have been used to
automatically generate new features by leveraging their vast knowledge.
However, existing LLM-based approaches often produce overly simple or
repetitive features, partly due to inherent biases in the transformations the
LLM chooses and the lack of structured reasoning guidance during generation. In
this paper, we propose a novel method REFeat, which guides an LLM to discover
diverse and informative features by leveraging multiple types of reasoning to
steer the feature generation process. Experiments on 59 benchmark datasets
demonstrate that our approach not only achieves higher predictive accuracy on
average, but also discovers more diverse and meaningful features. These results
highlight the promise of incorporating rich reasoning paradigms and adaptive
strategy selection into LLM-driven feature discovery for tabular data.

</details>


### [46] [Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios](https://arxiv.org/abs/2506.20384)
*Dror Ivry,Oran Nahum*

Main category: cs.AI

TL;DR: 论文提出Paladin-mini（3.8B参数的开源分类模型）和grounding-benchmark（评估数据集），用于解决上下文中的声明支持问题。


<details>
  <summary>Details</summary>
Motivation: 解决在给定上下文中为声明提供支持证据的问题。

Method: 开发Paladin-mini模型和grounding-benchmark数据集，用于分类和评估。

Result: Paladin-mini在基准测试中表现优于当前最先进技术。

Conclusion: Paladin-mini和grounding-benchmark为解决声明支持问题提供了有效工具。

Abstract: This paper introduces two significant contributions to address the issue of
grounding claims in a given context. Grounding means that given a context
(document) and a claim, there's at least one supportive evidence for the claim
in the document. We will introduce Paladin-mini, a compact (3.8B parameters)
open-source classifier model (used for labeling data as grounded or ungrounded)
engineered for robust performance in real-world scenarios, and the
grounding-benchmark, a new evaluation dataset designed to assess performance on
critical reasoning tasks. We'll also demonstrate the results of Paladin-mini
with benchmarks against the current State-of-the-art and share clear and
reproducible results.

</details>


### [47] [Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation](https://arxiv.org/abs/2506.20401)
*Jinchun Du,Bojie Shen,Muhammad Aamir Cheema,Adel N. Toosi*

Main category: cs.AI

TL;DR: 论文提出了一种电动汽车（EV）在V2G技术下的利润最大化问题（EVOP-V2G），并通过MIP模型和两种元启发式算法（EA和LNS）解决。实验显示其方法能显著提高利润并支持电网。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车的普及和V2G技术的发展，如何在满足客户需求的同时优化充电和放电策略成为关键问题。

Method: 采用混合整数规划（MIP）模型，并提出基于进化算法（EA）和大邻域搜索（LNS）的两种元启发式算法。

Result: 实验证明，该方法在真实数据上将司机利润翻倍，并在小规模实例中接近最优，大规模实例中扩展性良好。

Conclusion: 该研究为智能、高利润的电动汽车移动系统提供了可行方案，同时支持电网稳定。

Abstract: With the rising popularity of electric vehicles (EVs), modern service
systems, such as ride-hailing delivery services, are increasingly integrating
EVs into their operations. Unlike conventional vehicles, EVs often have a
shorter driving range, necessitating careful consideration of charging when
fulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology -
allowing EVs to also discharge energy back to the grid - new opportunities and
complexities emerge. We introduce the Electric Vehicle Orienteering Problem
with V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select
customer requests or orders while managing when and where to charge or
discharge. This involves navigating dynamic electricity prices, charging
station selection, and route constraints. We formulate the problem as a Mixed
Integer Programming (MIP) model and propose two near-optimal metaheuristic
algorithms: one evolutionary (EA) and the other based on large neighborhood
search (LNS). Experiments on real-world data show our methods can double driver
profits compared to baselines, while maintaining near-optimal performance on
small instances and excellent scalability on larger ones. Our work highlights a
promising path toward smarter, more profitable EV-based mobility systems that
actively support the energy grid.

</details>


### [48] [GymPN: A Library for Decision-Making in Process Management Systems](https://arxiv.org/abs/2506.20404)
*Riccardo Lo Bianco,Willem van Jaarsveld,Remco Dijkman*

Main category: cs.AI

TL;DR: GymPN是一个基于深度强化学习的软件库，用于优化业务流程中的决策，支持部分流程可观察性和多决策建模。


<details>
  <summary>Details</summary>
Motivation: 解决业务流程中任务分配和决策优化的现实问题，克服以往方法的局限性。

Method: 利用深度强化学习开发GymPN库，支持部分流程可观察性和多决策建模。

Result: 在八种典型业务流程决策问题模式上验证了GymPN的有效性和易用性。

Conclusion: GymPN能够更真实地表示流程决策，并学习最优决策策略。

Abstract: Process management systems support key decisions about the way work is
allocated in organizations. This includes decisions on which task to perform
next, when to execute the task, and who to assign the task to. Suitable
software tools are required to support these decisions in a way that is optimal
for the organization. This paper presents a software library, called GymPN,
that supports optimal decision-making in business processes using Deep
Reinforcement Learning. GymPN builds on previous work that supports task
assignment in business processes, introducing two key novelties: support for
partial process observability and the ability to model multiple decisions in a
business process. These novel elements address fundamental limitations of
previous work and thus enable the representation of more realistic process
decisions. We evaluate the library on eight typical business process
decision-making problem patterns, showing that GymPN allows for easy modeling
of the desired problems, as well as learning optimal decision policies.

</details>


### [49] [Mixtures of Neural Cellular Automata: A Stochastic Framework for Growth Modelling and Self-Organization](https://arxiv.org/abs/2506.20486)
*Salvatore Milite,Giulio Caravagna,Andrea Sottoriva*

Main category: cs.AI

TL;DR: 提出了一种混合神经细胞自动机（MNCA）框架，通过结合概率规则和内在噪声，更好地模拟生物系统的随机动态。


<details>
  <summary>Details</summary>
Motivation: 传统神经细胞自动机（NCA）的确定性限制了其对真实生物系统随机性的建模能力。

Method: 将混合模型思想引入NCA，结合概率规则和内在噪声，形成MNCA框架。

Result: MNCA在组织生长模拟、图像形态生成鲁棒性和显微镜图像分割中表现优异，具有更好的鲁棒性和可解释性。

Conclusion: MNCA是建模随机动态系统和研究自生长过程的有力工具。

Abstract: Neural Cellular Automata (NCAs) are a promising new approach to model
self-organizing processes, with potential applications in life science.
However, their deterministic nature limits their ability to capture the
stochasticity of real-world biological and physical systems.
  We propose the Mixture of Neural Cellular Automata (MNCA), a novel framework
incorporating the idea of mixture models into the NCA paradigm. By combining
probabilistic rule assignments with intrinsic noise, MNCAs can model diverse
local behaviors and reproduce the stochastic dynamics observed in biological
processes.
  We evaluate the effectiveness of MNCAs in three key domains: (1) synthetic
simulations of tissue growth and differentiation, (2) image morphogenesis
robustness, and (3) microscopy image segmentation. Results show that MNCAs
achieve superior robustness to perturbations, better recapitulate real
biological growth patterns, and provide interpretable rule segmentation. These
findings position MNCAs as a promising tool for modeling stochastic dynamical
systems and studying self-growth processes.

</details>


### [50] [Engineering Sentience](https://arxiv.org/abs/2506.20504)
*Konstantin Demin,Taylor Webb,Eric Elmoznino,Hakwan Lau*

Main category: cs.AI

TL;DR: 论文提出了一个适用于机器设计的感知定义，强调功能性和计算性实现，同时需包含主观性。


<details>
  <summary>Details</summary>
Motivation: 为AI设计有意义的感知能力，需明确其功能实现与主观性。

Method: 提出感知需具备断言性和质性，并探讨了当前技术下的实现方法。

Result: 明确了功能性感知的定义及其在AI中的潜在实现路径。

Conclusion: 理解功能性感知有助于避免无意中创造具备感知的AI，或及时发现其存在。

Abstract: We spell out a definition of sentience that may be useful for designing and
building it in machines. We propose that for sentience to be meaningful for AI,
it must be fleshed out in functional, computational terms, in enough detail to
allow for implementation. Yet, this notion of sentience must also reflect
something essentially 'subjective', beyond just having the general capacity to
encode perceptual content. For this specific functional notion of sentience to
occur, we propose that certain sensory signals need to be both assertoric
(persistent) and qualitative. To illustrate the definition in more concrete
terms, we sketch out some ways for potential implementation, given current
technology. Understanding what it takes for artificial agents to be
functionally sentient can also help us avoid creating them inadvertently, or at
least, realize that we have created them in a timely manner.

</details>


### [51] [Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios](https://arxiv.org/abs/2506.20531)
*Wenbin Gan,Minh-Son Dao,Koji Zettsu*

Main category: cs.AI

TL;DR: 论文提出了一种基于案例推理增强的大语言模型（CBR-LLM）框架，用于复杂风险场景中的规避决策，结合语义场景理解和历史案例检索，提升决策准确性和人类对齐性。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景中，自动驾驶需要快速、情境感知的决策，但现有大语言模型（LLMs）在领域适应性和情境理解上存在局限。

Method: 通过结合语义场景理解和历史案例检索，CBR-LLM框架生成情境敏感且符合人类行为的规避建议。

Result: 实验表明，该框架提高了决策准确性、解释质量，并与人类专家行为更一致。

Conclusion: CBR-LLM框架在复杂场景中表现出鲁棒性，有望成为智能驾驶系统的可靠决策支持工具。

Abstract: Driving in safety-critical scenarios requires quick, context-aware
decision-making grounded in both situational understanding and experiential
reasoning. Large Language Models (LLMs), with their powerful general-purpose
reasoning capabilities, offer a promising foundation for such decision-making.
However, their direct application to autonomous driving remains limited due to
challenges in domain adaptation, contextual grounding, and the lack of
experiential knowledge needed to make reliable and interpretable decisions in
dynamic, high-risk environments. To address this gap, this paper presents a
Case-Based Reasoning Augmented Large Language Model (CBR-LLM) framework for
evasive maneuver decision-making in complex risk scenarios. Our approach
integrates semantic scene understanding from dashcam video inputs with the
retrieval of relevant past driving cases, enabling LLMs to generate maneuver
recommendations that are both context-sensitive and human-aligned. Experiments
across multiple open-source LLMs show that our framework improves decision
accuracy, justification quality, and alignment with human expert behavior.
Risk-aware prompting strategies further enhance performance across diverse risk
types, while similarity-based case retrieval consistently outperforms random
sampling in guiding in-context learning. Case studies further demonstrate the
framework's robustness in challenging real-world conditions, underscoring its
potential as an adaptive and trustworthy decision-support tool for intelligent
driving systems.

</details>


### [52] [Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges](https://arxiv.org/abs/2506.20598)
*Alexander D. Kalian,Jaewook Lee,Stefan P. Johannesson,Lennart Otte,Christer Hogstrand,Miao Guo*

Main category: cs.AI

TL;DR: 提出了一种多代理AI框架，用于支持可持续蛋白质生产研究，重点关注微生物蛋白来源，通过检索增强生成（RAG）系统优化信息提取性能。


<details>
  <summary>Details</summary>
Motivation: 全球对可持续蛋白质来源的需求推动了智能工具的开发，以快速处理和合成领域特定的科学知识。

Method: 设计了基于GPT的LLM代理系统，包括文献搜索代理和信息提取代理，探索了微调和提示工程两种优化方法。

Result: 两种方法均提升了信息提取性能，微调效果更显著（平均余弦相似度≥0.94），提示工程统计不确定性更低。

Conclusion: 多代理AI系统在可持续蛋白质研究中表现出潜力，未来可扩展化学安全搜索功能。

Abstract: The global demand for sustainable protein sources has accelerated the need
for intelligent tools that can rapidly process and synthesise domain-specific
scientific knowledge. In this study, we present a proof-of-concept multi-agent
Artificial Intelligence (AI) framework designed to support sustainable protein
production research, with an initial focus on microbial protein sources. Our
Retrieval-Augmented Generation (RAG)-oriented system consists of two GPT-based
LLM agents: (1) a literature search agent that retrieves relevant scientific
literature on microbial protein production for a specified microbial strain,
and (2) an information extraction agent that processes the retrieved content to
extract relevant biological and chemical information. Two parallel
methodologies, fine-tuning and prompt engineering, were explored for agent
optimisation. Both methods demonstrated effectiveness at improving the
performance of the information extraction agent in terms of transformer-based
cosine similarity scores between obtained and ideal outputs. Mean cosine
similarity scores were increased by up to 25%, while universally reaching mean
scores of $\geq 0.89$ against ideal output text. Fine-tuning overall improved
the mean scores to a greater extent (consistently of $\geq 0.94$) compared to
prompt engineering, although lower statistical uncertainties were observed with
the latter approach. A user interface was developed and published for enabling
the use of the multi-agent AI system, alongside preliminary exploration of
additional chemical safety-based search capabilities

</details>


### [53] [CogGen: A Learner-Centered Generative AI Architecture for Intelligent Tutoring with Programming Video](https://arxiv.org/abs/2506.20600)
*Wengxi Li,Roy Pea,Nick Haber,Hari Subramonyam*

Main category: cs.AI

TL;DR: CogGen是一个学习者中心的AI架构，通过结合学生建模和生成式AI辅导，将编程视频转化为互动、自适应的学习体验。


<details>
  <summary>Details</summary>
Motivation: 提升视频编程教育的互动性和适应性，结合学生建模与生成式AI辅导。

Method: 架构包含三个部分：视频按学习目标分段、基于认知学徒框架的对话辅导引擎、使用贝叶斯知识追踪的学生模型。

Result: 技术评估显示视频分段准确且教学策略有效，消融实验验证各组件必要性。

Conclusion: CogGen通过结合结构化学生建模与互动AI对话，推动了AI辅导的发展，为视频编程教育提供了可扩展方案。

Abstract: We introduce CogGen, a learner-centered AI architecture that transforms
programming videos into interactive, adaptive learning experiences by
integrating student modeling with generative AI tutoring based on the Cognitive
Apprenticeship framework. The architecture consists of three components: (1)
video segmentation by learning goals, (2) a conversational tutoring engine
applying Cognitive Apprenticeship strategies, and (3) a student model using
Bayesian Knowledge Tracing to adapt instruction. Our technical evaluation
demonstrates effective video segmentation accuracy and strong pedagogical
alignment across knowledge, method, action, and interaction layers. Ablation
studies confirm the necessity of each component in generating effective
guidance. This work advances AI-powered tutoring by bridging structured student
modeling with interactive AI conversations, offering a scalable approach to
enhancing video-based programming education.

</details>


### [54] [AI Assistants to Enhance and Exploit the PETSc Knowledge Base](https://arxiv.org/abs/2506.20608)
*Barry Smith,Junchao Zhang,Hong Zhang,Lois Curfman McInnes,Murat Keceli,Archit Vasan,Satish Balay,Toby Isaac,Le Chen,Venkatram Vishwanath*

Main category: cs.AI

TL;DR: PETSc团队利用LLM技术整合分散的知识库，通过RAG、重排序算法和聊天机器人等工具，提升用户和开发者对PETSc资源的访问效率。


<details>
  <summary>Details</summary>
Motivation: 解决PETSc知识库分散且非正式的问题，提升用户和开发者的知识获取效率。

Method: 结合RAG、重排序算法和聊天机器人等LLM工具，设计系统架构并评估不同模型。

Result: 初步构建了一个可扩展的知识中心化AI框架，专注于Krylov求解器。

Conclusion: 目标是建立一个持续演进的平台，加速科学软件的开发与发现。

Abstract: Generative AI, especially through large language models (LLMs), is
transforming how technical knowledge can be accessed, reused, and extended.
PETSc, a widely used numerical library for high-performance scientific
computing, has accumulated a rich but fragmented knowledge base over its three
decades of development, spanning source code, documentation, mailing lists,
GitLab issues, Discord conversations, technical papers, and more. Much of this
knowledge remains informal and inaccessible to users and new developers. To
activate and utilize this knowledge base more effectively, the PETSc team has
begun building an LLM-powered system that combines PETSc content with custom
LLM tools -- including retrieval-augmented generation (RAG), reranking
algorithms, and chatbots -- to assist users, support developers, and propose
updates to formal documentation. This paper presents initial experiences
designing and evaluating these tools, focusing on system architecture, using
RAG and reranking for PETSc-specific information, evaluation methodologies for
various LLMs and embedding models, and user interface design. Leveraging the
Argonne Leadership Computing Facility resources, we analyze how LLM responses
can enhance the development and use of numerical software, with an initial
focus on scalable Krylov solvers. Our goal is to establish an extensible
framework for knowledge-centered AI in scientific software, enabling scalable
support, enriched documentation, and enhanced workflows for research and
development. We conclude by outlining directions for expanding this system into
a robust, evolving platform that advances software ecosystems to accelerate
scientific discovery.

</details>


### [55] [Towards Community-Driven Agents for Machine Learning Engineering](https://arxiv.org/abs/2506.20640)
*Sijie Li,Weiwei Sun,Shanda Li,Ameet Talwalkar,Yiming Yang*

Main category: cs.AI

TL;DR: MLE-Live框架评估ML代理在模拟Kaggle社区中的协作能力，CoMind代理在社区环境中表现出色，超越79.2%的人类竞争者。


<details>
  <summary>Details</summary>
Motivation: 现有ML代理通常孤立工作，缺乏与社区的互动，而人类研究者通过分享知识获益。

Method: 提出MLE-Live框架和CoMind代理，评估并提升代理在社区中的协作与知识共享能力。

Result: CoMind在MLE-Live中表现优异，平均超越79.2%的人类竞争者。

Conclusion: CoMind展示了在社区环境中协作的潜力，为ML代理的未来发展提供了新方向。

Abstract: Large language model-based machine learning (ML) agents have shown great
promise in automating ML research. However, existing agents typically operate
in isolation on a given research problem, without engaging with the broader
research community, where human researchers often gain insights and contribute
by sharing knowledge. To bridge this gap, we introduce MLE-Live, a live
evaluation framework designed to assess an agent's ability to communicate with
and leverage collective knowledge from a simulated Kaggle research community.
Building on this framework, we propose CoMind, a novel agent that excels at
exchanging insights and developing novel solutions within a community context.
CoMind achieves state-of-the-art performance on MLE-Live and outperforms 79.2%
human competitors on average across four ongoing Kaggle competitions. Our code
is released at https://github.com/comind-ml/CoMind.

</details>


### [56] [The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind](https://arxiv.org/abs/2506.20664)
*Andrei Lupu,Timon Willi,Jakob Foerster*

Main category: cs.AI

TL;DR: 论文提出了Decrypto，一个基于游戏的基准测试，用于评估大语言模型（LLMs）在多智能体推理和心理理论（ToM）方面的能力，填补了现有基准测试的不足。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs具备代理能力，它们需要在复杂的多智能体场景中导航，但目前对LLMs在多智能体能力和ToM方面的理解不足，现有基准测试存在范围狭窄、数据泄漏等问题。

Method: 提出Decrypto基准测试，结合认知科学、计算语用学和多智能体强化学习，设计交互式ToM实验平台，并通过实证评估验证其有效性。

Result: LLMs在多智能体推理和ToM任务中表现不如人类和简单词嵌入基线，且最新推理模型在某些任务上表现不如旧模型。

Conclusion: Decrypto填补了当前推理和ToM评估的关键空白，为开发更优的人工智能代理铺平了道路。

Abstract: As Large Language Models (LLMs) gain agentic abilities, they will have to
navigate complex multi-agent scenarios, interacting with human users and other
agents in cooperative and competitive settings. This will require new reasoning
skills, chief amongst them being theory of mind (ToM), or the ability to reason
about the "mental" states of other agents. However, ToM and other multi-agent
abilities in LLMs are poorly understood, since existing benchmarks suffer from
narrow scope, data leakage, saturation, and lack of interactivity. We thus
propose Decrypto, a game-based benchmark for multi-agent reasoning and ToM
drawing inspiration from cognitive science, computational pragmatics and
multi-agent reinforcement learning. It is designed to be as easy as possible in
all other dimensions, eliminating confounding factors commonly found in other
benchmarks. To our knowledge, it is also the first platform for designing
interactive ToM experiments.
  We validate the benchmark design through comprehensive empirical evaluations
of frontier LLMs, robustness studies, and human-AI cross-play experiments. We
find that LLM game-playing abilities lag behind humans and simple
word-embedding baselines. We then create variants of two classic cognitive
science experiments within Decrypto to evaluate three key ToM abilities.
Surprisingly, we find that state-of-the-art reasoning models are significantly
worse at those tasks than their older counterparts. This demonstrates that
Decrypto addresses a crucial gap in current reasoning and ToM evaluations, and
paves the path towards better artificial agents.

</details>
