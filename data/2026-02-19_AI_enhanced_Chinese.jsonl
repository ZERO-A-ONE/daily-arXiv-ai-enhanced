{"id": "2602.15037", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15037", "abs": "https://arxiv.org/abs/2602.15037", "authors": ["Mayank Ravishankara"], "title": "CircuChain: Disentangling Competence and Compliance in LLM Circuit Analysis", "comment": null, "summary": "As large language models (LLMs) advance toward expert-level performance in engineering domains, reliable reasoning under user-specified constraints becomes critical. In circuit analysis, for example, a numerically correct solution is insufficient if it violates established methodological conventions such as mesh directionality or polarity assignments, errors that can propagate in safety-critical systems. Yet it remains unclear whether frontier models truly apply first-principles reasoning or rely on entrenched training priors that conflict with explicit instructions. We introduce CircuChain, a diagnostic benchmark designed to disentangle instruction compliance from physical reasoning competence in electrical circuit analysis. CircuChain consists of counterbalanced Control/Trap problem pairs across five canonical circuit topologies, augmented with systematic variations in sign conventions, current orientations, and polarity definitions. A multi-stage verification pipeline, combining symbolic solvers, SPICE simulation, and an LLM-based error taxonomy, enables fine-grained attribution of failures to convention errors, physics errors, arithmetic mistakes, or hallucinations. Across 100 tasks per model, we observe a consistent Compliance-Competence Divergence. The strongest model evaluated exhibits near-perfect physical reasoning but a high rate of convention violations when Trap conditions deliberately invert natural sign patterns. Conversely, weaker models display lower physical fidelity yet superior adherence to explicit instructions. These results suggest that increased model capability does not guarantee improved constraint alignment and highlight the need for new evaluation frameworks that stress instruction-following under mathematically rigid domains. CircuChain provides one such framework and offers actionable insights for both engineering education and AI alignment research.", "AI": {"tldr": "CircuChain\u662f\u4e00\u4e2a\u8bca\u65ad\u57fa\u51c6\uff0c\u7528\u4e8e\u533a\u5206\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7535\u8def\u5206\u6790\u4e2d\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u548c\u7269\u7406\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u80fd\u529b\u589e\u5f3a\u5e76\u4e0d\u4fdd\u8bc1\u7ea6\u675f\u5bf9\u9f50\u7684\u6539\u8fdb\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u7a0b\u9886\u57df\u63a5\u8fd1\u4e13\u5bb6\u7ea7\u6027\u80fd\uff0c\u5728\u7528\u6237\u6307\u5b9a\u7ea6\u675f\u4e0b\u7684\u53ef\u9760\u63a8\u7406\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u4e0d\u6e05\u695a\u524d\u6cbf\u6a21\u578b\u662f\u771f\u6b63\u5e94\u7528\u57fa\u672c\u539f\u7406\u63a8\u7406\uff0c\u8fd8\u662f\u4f9d\u8d56\u4e8e\u4e0e\u660e\u786e\u6307\u4ee4\u51b2\u7a81\u7684\u8bad\u7ec3\u5148\u9a8c\u3002", "method": "CircuChain\u57fa\u51c6\u5305\u542b\u4e94\u4e2a\u5178\u578b\u7535\u8def\u62d3\u6251\u7684\u63a7\u5236/\u9677\u9631\u95ee\u9898\u5bf9\uff0c\u7cfb\u7edf\u53d8\u5316\u7b26\u53f7\u7ea6\u5b9a\u3001\u7535\u6d41\u65b9\u5411\u548c\u6781\u6027\u5b9a\u4e49\u3002\u91c7\u7528\u591a\u9636\u6bb5\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u7ed3\u5408\u7b26\u53f7\u6c42\u89e3\u5668\u3001SPICE\u4eff\u771f\u548c\u57fa\u4e8eLLM\u7684\u9519\u8bef\u5206\u7c7b\u6cd5\u3002", "result": "\u89c2\u5bdf\u5230\u4e00\u81f4\u7684\"\u9075\u5faa-\u80fd\u529b\u5206\u6b67\"\u73b0\u8c61\uff1a\u6700\u5f3a\u6a21\u578b\u7269\u7406\u63a8\u7406\u8fd1\u4e4e\u5b8c\u7f8e\uff0c\u4f46\u5728\u9677\u9631\u6761\u4ef6\u4e0b\u8fdd\u53cd\u7ea6\u5b9a\uff1b\u8f83\u5f31\u6a21\u578b\u7269\u7406\u4fdd\u771f\u5ea6\u8f83\u4f4e\u4f46\u9075\u5faa\u6307\u4ee4\u66f4\u597d\u3002\u6a21\u578b\u80fd\u529b\u589e\u5f3a\u4e0d\u4fdd\u8bc1\u7ea6\u675f\u5bf9\u9f50\u6539\u8fdb\u3002", "conclusion": "\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u5f3a\u8c03\u6570\u5b66\u4e25\u683c\u9886\u57df\u4e0b\u7684\u6307\u4ee4\u9075\u5faa\u3002CircuChain\u63d0\u4f9b\u4e86\u8fd9\u6837\u7684\u6846\u67b6\uff0c\u4e3a\u5de5\u7a0b\u6559\u80b2\u548cAI\u5bf9\u9f50\u7814\u7a76\u63d0\u4f9b\u53ef\u884c\u89c1\u89e3\u3002"}}
{"id": "2602.15323", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15323", "abs": "https://arxiv.org/abs/2602.15323", "authors": ["Huijia Lin", "Kameron Shahabi", "Min Jae Song"], "title": "Unforgeable Watermarks for Language Models via Robust Signatures", "comment": "60 pages, 7 figures", "summary": "Language models now routinely produce text that is difficult to distinguish from human writing, raising the need for robust tools to verify content provenance. Watermarking has emerged as a promising countermeasure, with existing work largely focused on model quality preservation and robust detection. However, current schemes provide limited protection against false attribution. We strengthen the notion of soundness by introducing two novel guarantees: unforgeability and recoverability. Unforgeability prevents adversaries from crafting false positives, texts that are far from any output from the watermarked model but are nonetheless flagged as watermarked. Recoverability provides an additional layer of protection: whenever a watermark is detected, the detector identifies the source text from which the flagged content was derived. Together, these properties strengthen content ownership by linking content exclusively to its generating model, enabling secure attribution and fine-grained traceability. We construct the first undetectable watermarking scheme that is robust, unforgeable, and recoverable with respect to substitutions (i.e., perturbations in Hamming metric). The key technical ingredient is a new cryptographic primitive called robust (or recoverable) digital signatures, which allow verification of messages that are close to signed ones, while preventing forgery of messages that are far from all previously signed messages. We show that any standard digital signature scheme can be boosted to a robust one using property-preserving hash functions (Boyle, LaVigne, and Vaikuntanathan, ITCS 2019).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6c34\u5370\u65b9\u6848\uff0c\u901a\u8fc7\u5f15\u5165\u4e0d\u53ef\u4f2a\u9020\u6027\u548c\u53ef\u6062\u590d\u6027\u4e24\u4e2a\u65b0\u4fdd\u8bc1\u6765\u52a0\u5f3a\u5185\u5bb9\u6eaf\u6e90\u7684\u5b89\u5168\u6027\uff0c\u9632\u6b62\u865a\u5047\u5f52\u5c5e\u95ee\u9898\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u6587\u672c\u8d8a\u6765\u8d8a\u96be\u4ee5\u4e0e\u4eba\u7c7b\u5199\u4f5c\u533a\u5206\uff0c\u9700\u8981\u5f3a\u5927\u7684\u5de5\u5177\u6765\u9a8c\u8bc1\u5185\u5bb9\u6765\u6e90\u3002\u73b0\u6709\u6c34\u5370\u65b9\u6848\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u8d28\u91cf\u4fdd\u6301\u548c\u9c81\u68d2\u68c0\u6d4b\uff0c\u4f46\u5bf9\u865a\u5047\u5f52\u5c5e\u7684\u4fdd\u62a4\u6709\u9650\u3002", "method": "\u6784\u5efa\u4e86\u7b2c\u4e00\u4e2a\u4e0d\u53ef\u68c0\u6d4b\u3001\u9c81\u68d2\u3001\u4e0d\u53ef\u4f2a\u9020\u4e14\u53ef\u6062\u590d\u7684\u6c34\u5370\u65b9\u6848\uff0c\u5173\u952e\u6280\u672f\u662f\u4e00\u79cd\u79f0\u4e3a\u9c81\u68d2\uff08\u6216\u53ef\u6062\u590d\uff09\u6570\u5b57\u7b7e\u540d\u7684\u65b0\u578b\u5bc6\u7801\u5b66\u539f\u8bed\uff0c\u5141\u8bb8\u9a8c\u8bc1\u63a5\u8fd1\u5df2\u7b7e\u540d\u6d88\u606f\u7684\u6d88\u606f\uff0c\u540c\u65f6\u9632\u6b62\u4f2a\u9020\u8fdc\u79bb\u6240\u6709\u5148\u524d\u7b7e\u540d\u6d88\u606f\u7684\u6d88\u606f\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6848\u80fd\u591f\u5c06\u5185\u5bb9\u4e0e\u5176\u751f\u6210\u6a21\u578b\u72ec\u5bb6\u94fe\u63a5\uff0c\u5b9e\u73b0\u5b89\u5168\u5f52\u5c5e\u548c\u7ec6\u7c92\u5ea6\u53ef\u8ffd\u6eaf\u6027\uff0c\u9632\u6b62\u5bf9\u624b\u5236\u4f5c\u865a\u5047\u9633\u6027\uff08\u8fdc\u79bb\u6c34\u5370\u6a21\u578b\u8f93\u51fa\u4f46\u88ab\u6807\u8bb0\u4e3a\u6709\u6c34\u5370\u7684\u6587\u672c\uff09\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4e0d\u53ef\u4f2a\u9020\u6027\u548c\u53ef\u6062\u590d\u6027\u4fdd\u8bc1\uff0c\u8be5\u7814\u7a76\u52a0\u5f3a\u4e86\u6c34\u5370\u65b9\u6848\u7684\u5185\u5bb9\u6240\u6709\u6743\u4fdd\u62a4\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5185\u5bb9\u7684\u53ef\u4fe1\u6eaf\u6e90\u63d0\u4f9b\u4e86\u66f4\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.15228", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.15228", "abs": "https://arxiv.org/abs/2602.15228", "authors": ["Zaiyu Cheng", "Antonio Mastropaolo"], "title": "An Empirical Study on the Effects of System Prompts in Instruction-Tuned Models for Code Generation", "comment": "34 pages, 12 tables, 3 figures", "summary": "Instruction-tuned Language Models (ILMs) have become essential components of modern AI systems, demonstrating exceptional versatility across natural language and reasoning tasks. Among their most impactful applications is code generation, where ILMs -- commonly referred to as Code Language Models (CLMs) -- translate human intent into executable programs. While progress has been driven by advances in scaling and training methodologies, one critical aspect remains underexplored: the impact of system prompts on both general-purpose ILMs and specialized CLMs for code generation. We systematically evaluate how system prompts of varying instructional detail, along with model scale, prompting strategy, and programming language, affect code assistant. Our experimental setting spans 360 configurations across four models, five system prompts, three prompting strategies, two languages, and two temperature settings. We find that (1) increasing system-prompt constraint specificity does not monotonically improve correctness -- prompt effectiveness is configuration-dependent and can help or hinder based on alignment with task requirements and decoding context; (2) for larger code-specialized models, few-shot examples can degrade performance relative to zero-shot generation, contrary to conventional wisdom; and (3) programming language matters, with Java exhibiting significantly greater sensitivity to system prompt variations than Python, suggesting language-specific prompt engineering strategies may be necessary.", "AI": {"tldr": "\u7cfb\u7edf\u63d0\u793a\u5bf9\u4ee3\u7801\u751f\u6210\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u7814\u7a76\uff1a\u53d1\u73b0\u63d0\u793a\u7ea6\u675f\u7279\u5f02\u6027\u4e0d\u603b\u662f\u63d0\u5347\u6b63\u786e\u6027\uff0c\u5c11\u6837\u672c\u793a\u4f8b\u53ef\u80fd\u964d\u4f4e\u5927\u6a21\u578b\u6027\u80fd\uff0c\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u5bf9\u63d0\u793a\u7684\u654f\u611f\u6027\u5dee\u5f02\u663e\u8457\u3002", "motivation": "\u5c3d\u7ba1\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u7cfb\u7edf\u63d0\u793a\u5bf9\u901a\u7528ILMs\u548c\u4e13\u7528CLMs\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30\u7cfb\u7edf\u63d0\u793a\u7684\u8be6\u7ec6\u7a0b\u5ea6\u3001\u6a21\u578b\u89c4\u6a21\u3001\u63d0\u793a\u7b56\u7565\u548c\u7f16\u7a0b\u8bed\u8a00\u7b49\u56e0\u7d20\u5982\u4f55\u5f71\u54cd\u4ee3\u7801\u52a9\u624b\u6027\u80fd\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u5316\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u6db5\u76d6360\u79cd\u914d\u7f6e\uff1a4\u4e2a\u6a21\u578b\u30015\u4e2a\u7cfb\u7edf\u63d0\u793a\u30013\u79cd\u63d0\u793a\u7b56\u7565\u30012\u79cd\u7f16\u7a0b\u8bed\u8a00\uff08Python\u548cJava\uff09\u30012\u79cd\u6e29\u5ea6\u8bbe\u7f6e\u3002\u901a\u8fc7\u5bf9\u6bd4\u4e0d\u540c\u914d\u7f6e\u4e0b\u7684\u4ee3\u7801\u751f\u6210\u6027\u80fd\u6765\u8bc4\u4f30\u7cfb\u7edf\u63d0\u793a\u7684\u5f71\u54cd\u3002", "result": "1) \u63d0\u9ad8\u7cfb\u7edf\u63d0\u793a\u7ea6\u675f\u7279\u5f02\u6027\u5e76\u4e0d\u5355\u8c03\u63d0\u5347\u6b63\u786e\u6027\uff0c\u63d0\u793a\u6548\u679c\u53d6\u51b3\u4e8e\u914d\u7f6e\uff0c\u53ef\u80fd\u5e2e\u52a9\u6216\u963b\u788d\u6027\u80fd\uff1b2) \u5bf9\u4e8e\u5927\u578b\u4ee3\u7801\u4e13\u7528\u6a21\u578b\uff0c\u5c11\u6837\u672c\u793a\u4f8b\u53ef\u80fd\u6bd4\u96f6\u6837\u672c\u751f\u6210\u8868\u73b0\u66f4\u5dee\uff1b3) \u7f16\u7a0b\u8bed\u8a00\u5f71\u54cd\u663e\u8457\uff0cJava\u5bf9\u7cfb\u7edf\u63d0\u793a\u53d8\u5316\u7684\u654f\u611f\u6027\u8fdc\u9ad8\u4e8ePython\u3002", "conclusion": "\u7cfb\u7edf\u63d0\u793a\u5bf9\u4ee3\u7801\u751f\u6210\u6a21\u578b\u6027\u80fd\u6709\u590d\u6742\u5f71\u54cd\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u4efb\u52a1\u9700\u6c42\u3001\u89e3\u7801\u4e0a\u4e0b\u6587\u548c\u7f16\u7a0b\u8bed\u8a00\u8fdb\u884c\u9488\u5bf9\u6027\u8bbe\u8ba1\u3002\u4f20\u7edf\u63d0\u793a\u5de5\u7a0b\u667a\u6167\uff08\u5982\u5c11\u6837\u672c\u793a\u4f8b\u603b\u662f\u6709\u76ca\uff09\u53ef\u80fd\u4e0d\u9002\u7528\u4e8e\u6240\u6709\u60c5\u51b5\uff0c\u7279\u522b\u662f\u5927\u578b\u4ee3\u7801\u4e13\u7528\u6a21\u578b\u3002"}}
{"id": "2602.15143", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.15143", "abs": "https://arxiv.org/abs/2602.15143", "authors": ["Xinhang Ma", "William Yeoh", "Ning Zhang", "Yevgeniy Vorobeychik"], "title": "Protecting Language Models Against Unauthorized Distillation through Trace Rewriting", "comment": null, "summary": "Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \\emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \\emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u4fee\u6539\u6559\u5e08\u6a21\u578b\u7684\u63a8\u7406\u8f93\u51fa\u6765\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u77e5\u8bc6\u84b8\u998f\uff0c\u5b9e\u73b0\u53cd\u84b8\u998f\u548cAPI\u6c34\u5370\u4e24\u4e2a\u76ee\u6807\u3002", "motivation": "\u77e5\u8bc6\u84b8\u998f\u88ab\u5e7f\u6cdb\u7528\u4e8e\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u8fc1\u79fb\u5230\u66f4\u5c0f\u7684\u5b66\u751f\u6a21\u578b\uff0c\u4f46\u672a\u7ecf\u6388\u6743\u7684\u84b8\u998f\u5229\u7528\u4e86\u524d\u6cbf\u6a21\u578b\u5f00\u53d1\u7684\u5de8\u5927\u6295\u5165\uff0c\u9700\u8981\u4fdd\u62a4\u63aa\u65bd\u3002", "method": "\u63d0\u51fa\u4e86\u52a8\u6001\u91cd\u5199\u6559\u5e08\u6a21\u578b\u63a8\u7406\u8f93\u51fa\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8eLLM\u7684\u91cd\u5199\u6280\u672f\u548c\u57fa\u4e8e\u68af\u5ea6\u7684\u6280\u672f\uff0c\u5728\u4fdd\u6301\u7b54\u6848\u6b63\u786e\u6027\u548c\u8bed\u4e49\u8fde\u8d2f\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u53cd\u84b8\u998f\u548c\u6c34\u5370\u5d4c\u5165\u3002", "result": "\u7b80\u5355\u7684\u57fa\u4e8e\u6307\u4ee4\u7684\u91cd\u5199\u65b9\u6cd5\u80fd\u6709\u6548\u5b9e\u73b0\u53cd\u84b8\u998f\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u6559\u5e08\u6a21\u578b\u6027\u80fd\uff1b\u91cd\u5199\u65b9\u6cd5\u8fd8\u80fd\u5b9e\u73b0\u9ad8\u53ef\u9760\u7684\u6c34\u5370\u68c0\u6d4b\uff0c\u51e0\u4e4e\u6ca1\u6709\u8bef\u62a5\u3002", "conclusion": "\u901a\u8fc7\u91cd\u5199\u6559\u5e08\u6a21\u578b\u7684\u63a8\u7406\u8f93\u51fa\u53ef\u4ee5\u6709\u6548\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u77e5\u8bc6\u84b8\u998f\uff0c\u540c\u65f6\u5b9e\u73b0\u53cd\u84b8\u998f\u548cAPI\u6c34\u5370\u7684\u53cc\u91cd\u4fdd\u62a4\u76ee\u6807\u3002"}}
{"id": "2602.15241", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15241", "abs": "https://arxiv.org/abs/2602.15241", "authors": ["Arya Tschand", "Chenyu Wang", "Zishen Wan", "Andrew Cheng", "Ioana Cristescu", "Kevin He", "Howard Huang", "Alexander Ingare", "Akseli Kangaslahti", "Sara Kangaslahti", "Theo Lebryk", "Hongjin Lin", "Jeffrey Jian Ma", "Alexandru Meterez", "Clara Mohri", "Depen Morwani", "Sunny Qin", "Roy Rinberg", "Paula Rodriguez-Diaz", "Alyssa Mia Taliotis", "Pernille Undrum Fathi", "Rosie Zhao", "Todd Zhou", "Vijay Janapa Reddi"], "title": "GenAI for Systems: Recurring Challenges and Design Principles from Software to Silicon", "comment": null, "summary": "Generative AI is reshaping how computing systems are designed, optimized, and built, yet research remains fragmented across software, architecture, and chip design communities. This paper takes a cross-stack perspective, examining how generative models are being applied from code generation and distributed runtimes through hardware design space exploration to RTL synthesis, physical layout, and verification. Rather than reviewing each layer in isolation, we analyze how the same structural difficulties and effective responses recur across the stack. Our central finding is one of convergence. Despite the diversity of domains and tools, the field keeps encountering five recurring challenges (the feedback loop crisis, the tacit knowledge problem, trust and validation, co-design across boundaries, and the shift from determinism to dynamism) and keeps arriving at five design principles that independently emerge as effective responses (embracing hybrid approaches, designing for continuous feedback, separating concerns by role, matching methods to problem structure, and building on decades of systems knowledge). We organize these into a challenge--principle map that serves as a diagnostic and design aid, showing which principles have proven effective for which challenges across layers. Through concrete cross-stack examples, we show how systems navigate this map as they mature, and argue that the field needs shared engineering methodology, including common vocabularies, cross-layer benchmarks, and systematic design practices, so that progress compounds across communities rather than being rediscovered in each one. Our analysis covers more than 275 papers spanning eleven application areas across three layers of the computing stack, and distills open research questions that become visible only from a cross-layer vantage point.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ece\u8de8\u6808\u89c6\u89d2\u5206\u6790\u751f\u6210\u5f0fAI\u5728\u8ba1\u7b97\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\uff0c\u8bc6\u522b\u51fa\u4e94\u4e2a\u91cd\u590d\u51fa\u73b0\u7684\u6311\u6218\u548c\u4e94\u4e2a\u6709\u6548\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u63d0\u51fa\u9700\u8981\u5171\u4eab\u5de5\u7a0b\u65b9\u6cd5\u8bba\u6765\u4fc3\u8fdb\u8de8\u793e\u533a\u8fdb\u6b65\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6b63\u5728\u91cd\u5851\u8ba1\u7b97\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3001\u4f18\u5316\u548c\u6784\u5efa\u65b9\u5f0f\uff0c\u4f46\u76ee\u524d\u7814\u7a76\u5728\u8f6f\u4ef6\u3001\u67b6\u6784\u548c\u82af\u7247\u8bbe\u8ba1\u793e\u533a\u4e4b\u95f4\u4ecd\u7136\u5206\u6563\u3002\u9700\u8981\u4ece\u8de8\u6808\u89c6\u89d2\u7406\u89e3\u751f\u6210\u5f0f\u6a21\u578b\u5728\u6574\u4e2a\u8ba1\u7b97\u6808\u4e2d\u7684\u5e94\u7528\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u8de8\u6808\u89c6\u89d2\u5206\u6790\u8d85\u8fc7275\u7bc7\u8bba\u6587\uff0c\u6db5\u76d6\u8ba1\u7b97\u6808\u7684\u4e09\u4e2a\u5c42\u6b21\uff08\u8f6f\u4ef6\u3001\u67b6\u6784\u3001\u82af\u7247\u8bbe\u8ba1\uff09\u4e2d\u768411\u4e2a\u5e94\u7528\u9886\u57df\u3002\u8bc6\u522b\u91cd\u590d\u51fa\u73b0\u7684\u6311\u6218\u548c\u8bbe\u8ba1\u539f\u5219\uff0c\u6784\u5efa\u6311\u6218-\u539f\u5219\u6620\u5c04\u4f5c\u4e3a\u8bca\u65ad\u548c\u8bbe\u8ba1\u5de5\u5177\u3002", "result": "\u53d1\u73b0\u5c3d\u7ba1\u9886\u57df\u548c\u5de5\u5177\u591a\u6837\uff0c\u4f46\u6574\u4e2a\u9886\u57df\u53cd\u590d\u9047\u5230\u4e94\u4e2a\u6838\u5fc3\u6311\u6218\uff08\u53cd\u9988\u5faa\u73af\u5371\u673a\u3001\u9690\u6027\u77e5\u8bc6\u95ee\u9898\u3001\u4fe1\u4efb\u4e0e\u9a8c\u8bc1\u3001\u8de8\u8fb9\u754c\u534f\u540c\u8bbe\u8ba1\u3001\u4ece\u786e\u5b9a\u6027\u5230\u52a8\u6001\u6027\u7684\u8f6c\u53d8\uff09\uff0c\u5e76\u72ec\u7acb\u6d8c\u73b0\u51fa\u4e94\u4e2a\u6709\u6548\u7684\u8bbe\u8ba1\u539f\u5219\uff08\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u3001\u8bbe\u8ba1\u6301\u7eed\u53cd\u9988\u673a\u5236\u3001\u6309\u89d2\u8272\u5206\u79bb\u5173\u6ce8\u70b9\u3001\u65b9\u6cd5\u4e0e\u95ee\u9898\u7ed3\u6784\u5339\u914d\u3001\u57fa\u4e8e\u6570\u5341\u5e74\u7cfb\u7edf\u77e5\u8bc6\u6784\u5efa\uff09\u3002", "conclusion": "\u8be5\u9886\u57df\u9700\u8981\u5171\u4eab\u7684\u5de5\u7a0b\u65b9\u6cd5\u8bba\uff0c\u5305\u62ec\u5171\u540c\u8bcd\u6c47\u3001\u8de8\u5c42\u57fa\u51c6\u6d4b\u8bd5\u548c\u7cfb\u7edf\u5316\u8bbe\u8ba1\u5b9e\u8df5\uff0c\u4ee5\u4fbf\u8fdb\u5c55\u80fd\u591f\u5728\u5404\u793e\u533a\u95f4\u79ef\u7d2f\u800c\u975e\u91cd\u590d\u53d1\u73b0\u3002\u4ece\u8de8\u5c42\u89c6\u89d2\u53ef\u89c1\u72ec\u7279\u7684\u7814\u7a76\u95ee\u9898\u3002"}}
{"id": "2602.15376", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15376", "abs": "https://arxiv.org/abs/2602.15376", "authors": ["Udbhav Prasad", "Aniesh Chawla"], "title": "A Unified Evaluation of Learning-Based Similarity Techniques for Malware Detection", "comment": null, "summary": "Cryptographic digests (e.g., MD5, SHA-256) are designed to provide exact identity. Any single-bit change in the input produces a completely different hash, which is ideal for integrity verification but limits their usefulness in many real-world tasks like threat hunting, malware analysis and digital forensics, where adversaries routinely introduce minor transformations. Similarity-based techniques address this limitation by enabling approximate matching, allowing related byte sequences to produce measurably similar fingerprints. Modern enterprises manage tens of thousands of endpoints with billions of files, making the effectiveness and scalability of the proposed techniques more important than ever in security applications. Security researchers have proposed a range of approaches, including similarity digests and locality-sensitive hashes (e.g., ssdeep, sdhash, TLSH), as well as more recent machine-learning-based methods that generate embeddings from file features. However, these techniques have largely been evaluated in isolation, using disparate datasets and evaluation criteria. This paper presents a systematic comparison of learning-based classification and similarity methods using large, publicly available datasets. We evaluate each method under a unified experimental framework with industry-accepted metrics. To our knowledge, this is the first reproducible study to benchmark these diverse learning-based similarity techniques side by side for real-world security workloads. Our results show that no single approach performs well across all dimensions; instead, each exhibits distinct trade-offs, indicating that effective malware analysis and threat-hunting platforms must combine complementary classification and similarity techniques rather than rely on a single method.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u57fa\u4e8e\u5b66\u4e60\u7684\u5206\u7c7b\u548c\u76f8\u4f3c\u6027\u65b9\u6cd5\u5728\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6ca1\u6709\u5355\u4e00\u65b9\u6cd5\u5728\u6240\u6709\u7ef4\u5ea6\u90fd\u8868\u73b0\u826f\u597d\uff0c\u9700\u8981\u7ed3\u5408\u4e92\u8865\u6280\u672f", "motivation": "\u4f20\u7edf\u52a0\u5bc6\u6458\u8981\uff08\u5982MD5\u3001SHA-256\uff09\u867d\u7136\u80fd\u63d0\u4f9b\u7cbe\u786e\u8eab\u4efd\u9a8c\u8bc1\uff0c\u4f46\u5bf9\u5fae\u5c0f\u53d8\u5316\u7684\u8f93\u5165\u4f1a\u4ea7\u751f\u5b8c\u5168\u4e0d\u540c\u7684\u54c8\u5e0c\u503c\uff0c\u9650\u5236\u4e86\u5728\u5a01\u80c1\u72e9\u730e\u3001\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u548c\u6570\u5b57\u53d6\u8bc1\u7b49\u5b9e\u9645\u5b89\u5168\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002\u73b0\u6709\u76f8\u4f3c\u6027\u6280\u672f\uff08\u5982ssdeep\u3001sdhash\u3001TLSH\uff09\u548c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u6bd4\u8f83", "method": "\u91c7\u7528\u7edf\u4e00\u7684\u5b9e\u9a8c\u6846\u67b6\u548c\u884c\u4e1a\u63a5\u53d7\u7684\u6307\u6807\uff0c\u5728\u5927\u89c4\u6a21\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7cfb\u7edf\u6bd4\u8f83\u57fa\u4e8e\u5b66\u4e60\u7684\u5206\u7c7b\u548c\u76f8\u4f3c\u6027\u65b9\u6cd5\uff0c\u5305\u62ec\u76f8\u4f3c\u6027\u6458\u8981\u3001\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u548c\u57fa\u4e8e\u6587\u4ef6\u7279\u5f81\u7684\u673a\u5668\u5b66\u4e60\u5d4c\u5165\u65b9\u6cd5", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6ca1\u6709\u5355\u4e00\u65b9\u6cd5\u5728\u6240\u6709\u7ef4\u5ea6\u90fd\u8868\u73b0\u826f\u597d\uff0c\u6bcf\u79cd\u65b9\u6cd5\u90fd\u6709\u660e\u663e\u7684\u6743\u8861\u53d6\u820d\u3002\u8fd9\u610f\u5473\u7740\u6709\u6548\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u548c\u5a01\u80c1\u72e9\u730e\u5e73\u53f0\u9700\u8981\u7ed3\u5408\u4e92\u8865\u7684\u5206\u7c7b\u548c\u76f8\u4f3c\u6027\u6280\u672f\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u5355\u4e00\u65b9\u6cd5", "conclusion": "\u8fd9\u662f\u7b2c\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u7814\u7a76\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u5b89\u5168\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u591a\u6837\u5316\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u76f8\u4f3c\u6027\u6280\u672f\u63d0\u4f9b\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u5b89\u5168\u5e94\u7528\u4e2d\u7ed3\u5408\u591a\u79cd\u4e92\u8865\u6280\u672f\u7684\u91cd\u8981\u6027\uff0c\u800c\u4e0d\u662f\u5bfb\u627e\"\u4e00\u5200\u5207\"\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.15342", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.15342", "abs": "https://arxiv.org/abs/2602.15342", "authors": ["Hanyu Zhang", "Tomoji Kishi"], "title": "SACS: A Code Smell Dataset using Semi-automatic Generation Approach", "comment": "arXiv admin note: substantial text overlap with arXiv:2511.12069", "summary": "Code smell is a great challenge in software refactoring, which indicates latent design or implementation flaws that may degrade the software maintainability and evolution. Over the past of decades, the research on code smell has received extensive attention. Especially the researches applied machine learning-technique have become a popular topic in recent studies. However, one of the biggest challenges to apply machine learning-technique is the lack of high-quality code smell datasets. Manually constructing such datasets is extremely labor-intensive, as identifying code smells requires substantial development expertise and considerable time investment. In contrast, automatically generated datasets, while scalable, frequently exhibit reduced label reliability and compromised data quality. To overcome this challenge, in this study, we explore a semi-automatic approach to generate a code smell dataset with high quality data samples. Specifically, we first applied a set of automatic generation rules to produce candidate smelly samples. We then employed multiple metrics to group the data samples into an automatically accepted group and a manually reviewed group, enabling reviewers to concentrate their efforts on ambiguous samples. Furthermore, we established structured review guidelines and developed a annotation tool to support the manual validation process. Based on the proposed semi-automatic generation approach, we created an open-source code smell dataset, SACS, covering three widely studied code smells: Long Method, Large Class, and Feature Envy. Each code smell category includes over 10,000 labeled samples. This dataset could provide a large-scale and publicly available benchmark to facilitate future studies on code smell detection and automated refactoring.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u81ea\u52a8\u65b9\u6cd5\u751f\u6210\u9ad8\u8d28\u91cf\u4ee3\u7801\u5f02\u5473\u6570\u636e\u96c6SACS\uff0c\u5305\u542b\u4e09\u79cd\u5e38\u89c1\u4ee3\u7801\u5f02\u5473\uff08\u957f\u65b9\u6cd5\u3001\u5927\u7c7b\u3001\u7279\u6027\u5ac9\u5992\uff09\uff0c\u6bcf\u4e2a\u7c7b\u522b\u8d85\u8fc710,000\u4e2a\u6807\u6ce8\u6837\u672c\uff0c\u4e3a\u4ee3\u7801\u5f02\u5473\u68c0\u6d4b\u7814\u7a76\u63d0\u4f9b\u5927\u89c4\u6a21\u516c\u5f00\u57fa\u51c6\u3002", "motivation": "\u4ee3\u7801\u5f02\u5473\u662f\u8f6f\u4ef6\u91cd\u6784\u4e2d\u7684\u91cd\u5927\u6311\u6218\uff0c\u4f46\u673a\u5668\u5b66\u4e60\u6280\u672f\u5e94\u7528\u9762\u4e34\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7f3a\u4e4f\u7684\u95ee\u9898\u3002\u624b\u52a8\u6784\u5efa\u6570\u636e\u96c6\u52b3\u52a8\u5bc6\u96c6\uff0c\u81ea\u52a8\u751f\u6210\u6570\u636e\u96c6\u6807\u7b7e\u53ef\u9760\u6027\u4f4e\u3001\u6570\u636e\u8d28\u91cf\u5dee\uff0c\u9700\u8981\u5e73\u8861\u6548\u7387\u4e0e\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u534a\u81ea\u52a8\u65b9\u6cd5\uff1a1) \u5e94\u7528\u81ea\u52a8\u751f\u6210\u89c4\u5219\u4ea7\u751f\u5019\u9009\u5f02\u5473\u6837\u672c\uff1b2) \u4f7f\u7528\u591a\u79cd\u6307\u6807\u5c06\u6837\u672c\u5206\u4e3a\u81ea\u52a8\u63a5\u53d7\u7ec4\u548c\u4eba\u5de5\u5ba1\u6838\u7ec4\uff1b3) \u5efa\u7acb\u7ed3\u6784\u5316\u5ba1\u6838\u6307\u5357\u5e76\u5f00\u53d1\u6807\u6ce8\u5de5\u5177\u652f\u6301\u4eba\u5de5\u9a8c\u8bc1\u8fc7\u7a0b\u3002", "result": "\u521b\u5efa\u4e86\u5f00\u6e90\u4ee3\u7801\u5f02\u5473\u6570\u636e\u96c6SACS\uff0c\u6db5\u76d6\u4e09\u79cd\u5e7f\u6cdb\u7814\u7a76\u7684\u4ee3\u7801\u5f02\u5473\uff1a\u957f\u65b9\u6cd5\u3001\u5927\u7c7b\u3001\u7279\u6027\u5ac9\u5992\uff0c\u6bcf\u4e2a\u7c7b\u522b\u5305\u542b\u8d85\u8fc710,000\u4e2a\u6807\u6ce8\u6837\u672c\uff0c\u5f62\u6210\u4e86\u5927\u89c4\u6a21\u516c\u5f00\u57fa\u51c6\u3002", "conclusion": "\u63d0\u51fa\u7684\u534a\u81ea\u52a8\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u4ee3\u7801\u5f02\u5473\u6570\u636e\u96c6\uff0cSACS\u6570\u636e\u96c6\u53ef\u4e3a\u672a\u6765\u4ee3\u7801\u5f02\u5473\u68c0\u6d4b\u548c\u81ea\u52a8\u91cd\u6784\u7814\u7a76\u63d0\u4f9b\u53ef\u9760\u7684\u6570\u636e\u652f\u6301\uff0c\u4fc3\u8fdb\u76f8\u5173\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2602.15158", "categories": ["cs.AI", "cs.IR", "math.LO"], "pdf": "https://arxiv.org/pdf/2602.15158", "abs": "https://arxiv.org/abs/2602.15158", "authors": ["Gabriel Rocha"], "title": "da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems", "comment": "22 pages, 5 figures, 1 table", "summary": "This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and L\u00fccke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCarnapian-Goguenism\u7684\u65b0\u672c\u4f53\u5f02\u8d28\u6027\u65b9\u6cd5\uff0c\u79f0\u4e3ada Costian-Tarskianism\uff0c\u7ed3\u5408\u4e86da Costa\u7684\u6570\u5b66\u5bb9\u5fcd\u539f\u5219\u548cTarski\u7684\u540e\u679c\u7b97\u5b50\u6982\u5ff5\uff0c\u901a\u8fc7\u6269\u5c55\u540e\u679c\u7cfb\u7edf\u548c\u6269\u5c55\u5f00\u53d1\u56fe\u6765\u5173\u8054\u672c\u4f53\u3002", "motivation": "\u89e3\u51b3\u672c\u4f53\u8bba\u9886\u57df\u7684\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u4e3a\u4e0d\u540c\u672c\u4f53\u7cfb\u7edf\u4e4b\u95f4\u7684\u5173\u8054\u548c\u6574\u5408\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\uff0c\u501f\u9274Kutz\u3001Mossakowski\u548cL\u00fccke\u63d0\u51fa\u7684Carnapian-Goguenism\u601d\u60f3\u3002", "method": "\u57fa\u4e8eCarnielli\u7b49\u4eba\u4ee5\u53caCitkin\u548cMuravitsky\u53d1\u5c55\u7684\u540e\u679c\u7cfb\u7edf\u7406\u8bba\uff0c\u5f15\u5165\u6269\u5c55\u540e\u679c\u7cfb\u7edf\uff08\u5305\u542b\u672c\u4f53\u516c\u7406\uff09\uff0c\u5b9a\u4e49\u6269\u5c55\u5f00\u53d1\u56fe\u7ed3\u6784\uff0c\u901a\u8fc7\u6269\u5c55\u540e\u679c\u7cfb\u7edf\u7684\u6001\u5c04\u4ee5\u53ca\u7ea4\u7ef4\u5316\u548c\u5206\u88c2\u7b49\u64cd\u4f5c\u6765\u5173\u8054\u672c\u4f53\u3002", "result": "\u5efa\u7acb\u4e86da Costian-Tarskianism\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u6269\u5c55\u540e\u679c\u7cfb\u7edf\u548c\u6269\u5c55\u5f00\u53d1\u56fe\u7684\u6982\u5ff5\uff0c\u4e3a\u5904\u7406\u672c\u4f53\u5f02\u8d28\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u5b66\u5de5\u5177\u548c\u7ed3\u6784\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5e94\u7528\u672c\u4f53\u8bba\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u672c\u4f53\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\uff0c\u5305\u62ec\u8fdb\u4e00\u6b65\u63a2\u7d22\u8be5\u6846\u67b6\u5728\u5b9e\u9645\u672c\u4f53\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2602.15395", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.15395", "abs": "https://arxiv.org/abs/2602.15395", "authors": ["Qin Wang", "Ruiqiang Li", "Guangsheng Yu", "Vincent Gramoli", "Shiping Chen"], "title": "MEV in Binance Builder", "comment": null, "summary": "We study the builder-driven MEV arbitrage on BNB Smart Chain (BSC). BSC's Proposer--Builder Separation (PBS) adopts a leaner design: only whitelisted builders can participate, blocks are produced at shorter intervals, and private order flow bypasses the public mempool. These features have long raised community concerns over centralization, which we empirically confirm by tracing arbitrage activity of the two dominant builders from May to November 2025. Within months, 48Club and Blockrazor produced over 96\\% of blocks and captured about 92\\% of MEV profits.\n  We find that profits concentrate in short, low-hop arbitrage routes over wrapped tokens and stablecoins, and that block construction rapidly converges toward monopoly. Beyond concentration alone, our analysis reveals a structural source of inequality: BSC's short block interval and whitelisted PBS collapse the contestable window for MEV competition, amplifying latency advantages and excluding slower builders and searchers. MEV extraction on BSC is not only more centralized than on Ethereum, but also structurally more vulnerable to censorship and weakened fairness.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86BNB\u667a\u80fd\u94fe\u4e0a\u5efa\u8bbe\u8005\u9a71\u52a8\u7684MEV\u5957\u5229\u6d3b\u52a8\uff0c\u53d1\u73b0\u7531\u4e8e\u767d\u540d\u5355\u673a\u5236\u3001\u77ed\u533a\u5757\u95f4\u9694\u548c\u79c1\u6709\u8ba2\u5355\u6d41\u7b49\u8bbe\u8ba1\u7279\u5f81\uff0c\u5bfc\u81f4MEV\u5229\u6da6\u9ad8\u5ea6\u96c6\u4e2d\u5728\u5c11\u6570\u5efa\u8bbe\u8005\u624b\u4e2d\uff0c\u52a0\u5267\u4e86\u4e2d\u5fc3\u5316\u548c\u516c\u5e73\u6027\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u9a8c\u8bc1\u793e\u533a\u5bf9BNB\u667a\u80fd\u94fePBS\u673a\u5236\u4e2d\u5fc3\u5316\u95ee\u9898\u7684\u62c5\u5fe7\u3002BSC\u91c7\u7528\u767d\u540d\u5355\u5efa\u8bbe\u8005\u3001\u77ed\u533a\u5757\u95f4\u9694\u548c\u79c1\u6709\u8ba2\u5355\u6d41\u7ed5\u8fc7\u516c\u5171\u5185\u5b58\u6c60\u7684\u8bbe\u8ba1\uff0c\u8fd9\u4e9b\u7279\u5f81\u5f15\u53d1\u4e86\u5173\u4e8e\u4e2d\u5fc3\u5316\u548c\u516c\u5e73\u6027\u7684\u957f\u671f\u5173\u6ce8\u3002", "method": "\u91c7\u7528\u5b9e\u8bc1\u7814\u7a76\u65b9\u6cd5\uff0c\u8ffd\u8e2a2025\u5e745\u6708\u81f311\u6708\u671f\u95f4BNB\u667a\u80fd\u94fe\u4e0a\u4e24\u4e2a\u4e3b\u5bfc\u5efa\u8bbe\u8005\uff0848Club\u548cBlockrazor\uff09\u7684\u5957\u5229\u6d3b\u52a8\u3002\u5206\u6790\u5305\u62ec\u5229\u6da6\u5206\u5e03\u3001\u5957\u5229\u8def\u5f84\u7279\u5f81\u4ee5\u53ca\u533a\u5757\u6784\u5efa\u7684\u96c6\u4e2d\u5ea6\u8d8b\u52bf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff0948Club\u548cBlockrazor\u751f\u4ea7\u4e86\u8d85\u8fc796%\u7684\u533a\u5757\uff0c\u6355\u83b7\u4e86\u7ea692%\u7684MEV\u5229\u6da6\uff1b2\uff09\u5229\u6da6\u96c6\u4e2d\u5728\u77ed\u8def\u5f84\u3001\u4f4e\u8df3\u6570\u7684\u5305\u88c5\u4ee3\u5e01\u548c\u7a33\u5b9a\u5e01\u5957\u5229\u4e2d\uff1b3\uff09\u533a\u5757\u6784\u5efa\u8fc5\u901f\u5411\u5784\u65ad\u6536\u655b\uff1b4\uff09\u77ed\u533a\u5757\u95f4\u9694\u548c\u767d\u540d\u5355\u673a\u5236\u538b\u7f29\u4e86MEV\u7ade\u4e89\u7684\u53ef\u7ade\u4e89\u7a97\u53e3\uff0c\u653e\u5927\u4e86\u5ef6\u8fdf\u4f18\u52bf\uff0c\u6392\u9664\u4e86\u8f83\u6162\u7684\u5efa\u8bbe\u8005\u548c\u641c\u7d22\u8005\u3002", "conclusion": "BNB\u667a\u80fd\u94fe\u4e0a\u7684MEV\u63d0\u53d6\u4e0d\u4ec5\u6bd4\u4ee5\u592a\u574a\u66f4\u52a0\u4e2d\u5fc3\u5316\uff0c\u800c\u4e14\u5728\u7ed3\u6784\u4e0a\u66f4\u5bb9\u6613\u53d7\u5230\u5ba1\u67e5\u548c\u516c\u5e73\u6027\u524a\u5f31\u7684\u5f71\u54cd\u3002\u77ed\u533a\u5757\u95f4\u9694\u548c\u767d\u540d\u5355PBS\u8bbe\u8ba1\u52a0\u5267\u4e86\u4e2d\u5fc3\u5316\u95ee\u9898\uff0c\u4f7fMEV\u7ade\u4e89\u66f4\u52a0\u4e0d\u5e73\u7b49\u3002"}}
{"id": "2602.15362", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15362", "abs": "https://arxiv.org/abs/2602.15362", "authors": ["Devendra Tata", "Mona Rajhans"], "title": "Automated Multi-Source Debugging and Natural Language Error Explanation for Dashboard Applications", "comment": "Accepted for publication at the 12th (Springer CCIS) International Conference on Information Management, March 27-29, 2026, Oxford, UK", "summary": "Modern web dashboards and enterprise applications increasingly rely on complex, distributed microservices architectures. While these architectures offer scalability, they introduce significant challenges in debugging and observability. When failures occur, they often manifest as opaque error messages to the end-user such as Something went wrong. This masks the underlying root cause which may reside in browser side exceptions, API contract violations, or server side logic failures. Existing monitoring tools capture these events in isolation but fail to correlate them effectively or provide intelligible explanations to non technical users. This paper proposes a novel system for Automated Multi Source Debugging and Natural Language Error Explanation. The proposed framework automatically collects and correlates error data from disparate sources such as browser, API, server logs and validates API contracts in real time, and utilizes Large Language Models to generate natural language explanations. This approach significantly reduces Mean Time to Resolution for support engineers and improves the user experience by transforming cryptic error codes into actionable insights.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u81ea\u52a8\u5316\u591a\u6e90\u8c03\u8bd5\u548c\u81ea\u7136\u8bed\u8a00\u9519\u8bef\u89e3\u91ca\u7cfb\u7edf\uff0c\u901a\u8fc7\u6536\u96c6\u6d4f\u89c8\u5668\u3001API\u3001\u670d\u52a1\u5668\u65e5\u5fd7\u7b49\u591a\u6e90\u6570\u636e\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u5c06\u6666\u6da9\u9519\u8bef\u4ee3\u7801\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u89c1\u89e3\u3002", "motivation": "\u73b0\u4ee3\u5fae\u670d\u52a1\u67b6\u6784\u867d\u7136\u63d0\u4f9b\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u7ed9\u8c03\u8bd5\u548c\u53ef\u89c2\u6d4b\u6027\u5e26\u6765\u91cd\u5927\u6311\u6218\u3002\u6545\u969c\u53d1\u751f\u65f6\uff0c\u7528\u6237\u901a\u5e38\u53ea\u770b\u5230\"\u51fa\u73b0\u95ee\u9898\"\u7b49\u6a21\u7cca\u9519\u8bef\u4fe1\u606f\uff0c\u63a9\u76d6\u4e86\u6d4f\u89c8\u5668\u7aef\u5f02\u5e38\u3001API\u5951\u7ea6\u8fdd\u89c4\u6216\u670d\u52a1\u5668\u7aef\u903b\u8f91\u6545\u969c\u7b49\u6839\u672c\u539f\u56e0\u3002\u73b0\u6709\u76d1\u63a7\u5de5\u5177\u5b64\u7acb\u5730\u6355\u83b7\u8fd9\u4e9b\u4e8b\u4ef6\uff0c\u4f46\u65e0\u6cd5\u6709\u6548\u5173\u8054\u6216\u4e3a\u975e\u6280\u672f\u7528\u6237\u63d0\u4f9b\u53ef\u7406\u89e3\u7684\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u81ea\u52a8\u5316\u591a\u6e90\u8c03\u8bd5\u548c\u81ea\u7136\u8bed\u8a00\u9519\u8bef\u89e3\u91ca\u6846\u67b6\u3002\u8be5\u7cfb\u7edf\u81ea\u52a8\u6536\u96c6\u548c\u5173\u8054\u6765\u81ea\u6d4f\u89c8\u5668\u3001API\u3001\u670d\u52a1\u5668\u65e5\u5fd7\u7b49\u4e0d\u540c\u6765\u6e90\u7684\u9519\u8bef\u6570\u636e\uff0c\u5b9e\u65f6\u9a8c\u8bc1API\u5951\u7ea6\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u652f\u6301\u5de5\u7a0b\u5e08\u7684\u5e73\u5747\u89e3\u51b3\u65f6\u95f4\uff0c\u5e76\u901a\u8fc7\u5c06\u6666\u6da9\u7684\u9519\u8bef\u4ee3\u7801\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u6765\u6539\u5584\u7528\u6237\u4f53\u9a8c\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u7684\u8c03\u8bd5\u6311\u6218\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u591a\u6e90\u6570\u636e\u5173\u8054\u548c\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u63d0\u9ad8\u6545\u969c\u8bca\u65ad\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2602.15173", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15173", "abs": "https://arxiv.org/abs/2602.15173", "authors": ["Luise Ge", "Yongyan Zhang", "Yevgeniy Vorobeychik"], "title": "Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs", "comment": null, "summary": "The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e8620\u4e2a\u524d\u6cbf\u548c\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u98ce\u9669\u51b3\u7b56\u884c\u4e3a\uff0c\u53d1\u73b0LLM\u53ef\u5206\u4e3a\u63a8\u7406\u6a21\u578b\u548c\u5bf9\u8bdd\u6a21\u578b\u4e24\u7c7b\uff0c\u5b83\u4eec\u5728\u7406\u6027\u7a0b\u5ea6\u3001\u5bf9\u524d\u666f\u8868\u793a\u65b9\u5f0f\u548c\u51b3\u7b56\u89e3\u91ca\u7684\u654f\u611f\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u6216\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u6b63\u5728\u5feb\u901f\u6539\u53d8\u6570\u5b57\u751f\u6001\u7cfb\u7edf\uff0c\u4f46\u5bf9\u5176\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u51b3\u7b56\u673a\u5236\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u6bd4\u8f83LLM\u7684\u98ce\u9669\u9009\u62e9\u884c\u4e3a\u6765\u586b\u8865\u8fd9\u4e00\u77e5\u8bc6\u7a7a\u767d\u3002", "method": "\u7814\u7a76\u4ece\u4e24\u4e2a\u7ef4\u5ea6\u6bd4\u8f83LLM\u7684\u98ce\u9669\u9009\u62e9\uff1a(1)\u524d\u666f\u8868\u793a\u65b9\u5f0f\uff08\u663e\u5f0fvs.\u7ecf\u9a8c\u57fa\u7840\uff09\u548c(2)\u51b3\u7b56\u7406\u7531\uff08\u89e3\u91ca\uff09\u3002\u7814\u7a76\u6d89\u53ca20\u4e2a\u524d\u6cbf\u548c\u5f00\u6e90LLM\uff0c\u5e76\u8f85\u4ee5\u5339\u914d\u7684\u4eba\u7c7b\u53d7\u8bd5\u8005\u5b9e\u9a8c\u4f5c\u4e3a\u53c2\u8003\u70b9\uff0c\u540c\u65f6\u4ee5\u671f\u671b\u6536\u76ca\u6700\u5927\u5316\u7684\u7406\u6027\u667a\u80fd\u4f53\u6a21\u578b\u4f5c\u4e3a\u53e6\u4e00\u4e2a\u53c2\u8003\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM\u53ef\u5206\u4e3a\u4e24\u7c7b\uff1a\u63a8\u7406\u6a21\u578b\uff08RMs\uff09\u503e\u5411\u4e8e\u7406\u6027\u884c\u4e3a\uff0c\u5bf9\u524d\u666f\u987a\u5e8f\u3001\u5f97\u5931\u6846\u67b6\u548c\u89e3\u91ca\u4e0d\u654f\u611f\uff0c\u5728\u663e\u5f0f\u524d\u666f\u548c\u7ecf\u9a8c\u5386\u53f2\u5448\u73b0\u4e0b\u7684\u884c\u4e3a\u76f8\u4f3c\uff1b\u5bf9\u8bdd\u6a21\u578b\uff08CMs\uff09\u7406\u6027\u7a0b\u5ea6\u663e\u8457\u8f83\u4f4e\uff0c\u66f4\u63a5\u8fd1\u4eba\u7c7b\u884c\u4e3a\uff0c\u5bf9\u524d\u666f\u987a\u5e8f\u3001\u6846\u67b6\u548c\u89e3\u91ca\u654f\u611f\uff0c\u5e76\u8868\u73b0\u51fa\u8f83\u5927\u7684\u63cf\u8ff0-\u5386\u53f2\u5dee\u8ddd\u3002\u5f00\u6e90LLM\u7684\u914d\u5bf9\u6bd4\u8f83\u8868\u660e\uff0c\u533a\u5206RMs\u548cCMs\u7684\u5173\u952e\u56e0\u7d20\u662f\u6570\u5b66\u63a8\u7406\u8bad\u7ec3\u3002", "conclusion": "LLM\u5728\u98ce\u9669\u51b3\u7b56\u4e2d\u5b58\u5728\u660e\u663e\u7684\u5206\u7c7b\u5dee\u5f02\uff0c\u63a8\u7406\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u7406\u6027\u7279\u5f81\uff0c\u800c\u5bf9\u8bdd\u6a21\u578b\u66f4\u63a5\u8fd1\u4eba\u7c7b\u51b3\u7b56\u6a21\u5f0f\u3002\u6570\u5b66\u63a8\u7406\u8bad\u7ec3\u662f\u5f71\u54cdLLM\u51b3\u7b56\u7406\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u8fd9\u5bf9LLM\u5728\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.15485", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.15485", "abs": "https://arxiv.org/abs/2602.15485", "authors": ["Longfei Chen", "Ji Zhao", "Lanxiao Cui", "Tong Su", "Xingbo Pan", "Ziyang Li", "Yongxing Wu", "Qijiang Cao", "Qiyao Cai", "Jing Zhang", "Yuandong Ni", "Junyao He", "Zeyu Zhang", "Chao Ge", "Xuhuai Lu", "Zeyu Gao", "Yuxin Cui", "Weisen Chen", "Yuxuan Peng", "Shengping Wang", "Qi Li", "Yukai Huang", "Yukun Liu", "Tuo Zhou", "Terry Yue Zhuo", "Junyang Lin", "Chao Zhang"], "title": "SecCodeBench-V2 Technical Report", "comment": null, "summary": "We introduce SecCodeBench-V2, a publicly released benchmark for evaluating Large Language Model (LLM) copilots' capabilities of generating secure code. SecCodeBench-V2 comprises 98 generation and fix scenarios derived from Alibaba Group's industrial productions, where the underlying security issues span 22 common CWE (Common Weakness Enumeration) categories across five programming languages: Java, C, Python, Go, and JavaScript. SecCodeBench-V2 adopts a function-level task formulation: each scenario provides a complete project scaffold and requires the model to implement or patch a designated target function under fixed interfaces and dependencies. For each scenario, SecCodeBench-V2 provides executable proof-of-concept (PoC) test cases for both functional validation and security verification. All test cases are authored and double-reviewed by security experts, ensuring high fidelity, broad coverage, and reliable ground truth. Beyond the benchmark itself, we build a unified evaluation pipeline that assesses models primarily via dynamic execution. For most scenarios, we compile and run model-generated artifacts in isolated environments and execute PoC test cases to validate both functional correctness and security properties. For scenarios where security issues cannot be adjudicated with deterministic test cases, we additionally employ an LLM-as-a-judge oracle. To summarize performance across heterogeneous scenarios and difficulty levels, we design a Pass@K-based scoring protocol with principled aggregation over scenarios and severity, enabling holistic and comparable evaluation across models. Overall, SecCodeBench-V2 provides a rigorous and reproducible foundation for assessing the security posture of AI coding assistants, with results and artifacts released at https://alibaba.github.io/sec-code-bench. The benchmark is publicly available at https://github.com/alibaba/sec-code-bench.", "AI": {"tldr": "SecCodeBench-V2\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5b89\u5168\u4ee3\u7801\u80fd\u529b\u7684\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b98\u4e2a\u57fa\u4e8e\u963f\u91cc\u5df4\u5df4\u5de5\u4e1a\u751f\u4ea7\u7684\u751f\u6210\u548c\u4fee\u590d\u573a\u666f\uff0c\u6db5\u76d65\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c22\u79cdCWE\u5b89\u5168\u6f0f\u6d1e\u7c7b\u522b\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u80fd\u591f\u5168\u9762\u8bc4\u4f30LLM\u4ee3\u7801\u52a9\u624b\u5b89\u5168\u7f16\u7801\u80fd\u529b\u7684\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7279\u522b\u662f\u5728\u5de5\u4e1a\u7ea7\u5b89\u5168\u6f0f\u6d1e\u573a\u666f\u4e0b\u7684\u8bc4\u4f30\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u6a21\u578b\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u751f\u6210\u5b89\u5168\u4ee3\u7801\u7684\u80fd\u529b\u3002", "method": "\u91c7\u7528\u51fd\u6570\u7ea7\u4efb\u52a1\u8bbe\u8ba1\uff0c\u6bcf\u4e2a\u573a\u666f\u63d0\u4f9b\u5b8c\u6574\u7684\u9879\u76ee\u811a\u624b\u67b6\uff0c\u8981\u6c42\u6a21\u578b\u5728\u56fa\u5b9a\u63a5\u53e3\u548c\u4f9d\u8d56\u4e0b\u5b9e\u73b0\u6216\u4fee\u590d\u76ee\u6807\u51fd\u6570\u3002\u901a\u8fc7\u52a8\u6001\u6267\u884c\u8bc4\u4f30\uff0c\u5728\u9694\u79bb\u73af\u5883\u4e2d\u7f16\u8bd1\u8fd0\u884c\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\uff0c\u5e76\u4f7f\u7528\u4e13\u5bb6\u7f16\u5199\u7684PoC\u6d4b\u8bd5\u7528\u4f8b\u8fdb\u884c\u529f\u80fd\u548c\u5b89\u5168\u6027\u9a8c\u8bc1\u3002\u5bf9\u4e8e\u65e0\u6cd5\u7528\u786e\u5b9a\u6027\u6d4b\u8bd5\u5224\u65ad\u7684\u573a\u666f\uff0c\u91c7\u7528LLM-as-a-judge\u65b9\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86\u5305\u542b98\u4e2a\u573a\u666f\u7684\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6Java\u3001C\u3001Python\u3001Go\u3001JavaScript\u4e94\u79cd\u8bed\u8a00\u548c22\u79cdCWE\u5b89\u5168\u6f0f\u6d1e\u7c7b\u522b\u3002\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u8bc4\u4f30\u6d41\u7a0b\u548c\u57fa\u4e8ePass@K\u7684\u8bc4\u5206\u534f\u8bae\uff0c\u652f\u6301\u5bf9\u6a21\u578b\u5b89\u5168\u7f16\u7801\u80fd\u529b\u7684\u5168\u9762\u3001\u53ef\u6bd4\u8f83\u8bc4\u4f30\u3002", "conclusion": "SecCodeBench-V2\u4e3a\u8bc4\u4f30AI\u4ee3\u7801\u52a9\u624b\u7684\u5b89\u5168\u6001\u52bf\u63d0\u4f9b\u4e86\u4e25\u8c28\u3001\u53ef\u590d\u73b0\u7684\u57fa\u7840\uff0c\u586b\u8865\u4e86\u5de5\u4e1a\u7ea7\u5b89\u5168\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u5b89\u5168\u7684AI\u7f16\u7a0b\u52a9\u624b\u53d1\u5c55\u3002"}}
{"id": "2602.15412", "categories": ["cs.SE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.15412", "abs": "https://arxiv.org/abs/2602.15412", "authors": ["Yulong He", "Nikita Verbin", "Sergey Kovalchuk"], "title": "Social Life of Code: Modeling Evolution through Code Embedding and Opinion Dynamics", "comment": "This paper is currently under review at Journal of Computational Science. Previously posted on SSRN: https://dx.doi.org/10.2139/ssrn.5828849", "summary": "Software repositories provide a detailed record of software evolution by capturing developer interactions through code-related activities such as pull requests and modifications. To better understand the underlying dynamics of codebase evolution, we introduce a novel approach that integrates semantic code embeddings with opinion dynamics theory, offering a quantitative framework to analyze collaborative development processes. Our approach begins by encoding code snippets into high-dimensional vector representations using state-of-the-art code embedding models, preserving both syntactic and semantic features. These embeddings are then processed using Principal Component Analysis (PCA) for dimensionality reduction, with data normalized to ensure comparability. We model temporal evolution using the Expressed-Private Opinion (EPO) model to derive trust matrices and track opinion trajectories across development cycles. These opinion trajectories reflect the underlying dynamics of consensus formation, influence propagation, and evolving alignment (or divergence) within developer communities -- revealing implicit collaboration patterns and knowledge-sharing mechanisms that are otherwise difficult to observe. By bridging software engineering and computational social science, our method provides a principled way to quantify software evolution, offering new insights into developer influence, consensus formation, and project sustainability. We evaluate our approach on data from three prominent open-source GitHub repositories, demonstrating its ability to reveal interpretable behavioral trends and variations in developer interactions. The results highlight the utility of our framework in improving open-source project maintenance through data-driven analysis of collaboration dynamics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u8bed\u4e49\u4ee3\u7801\u5d4c\u5165\u4e0e\u610f\u89c1\u52a8\u6001\u7406\u8bba\u76f8\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5316\u5206\u6790\u4ee3\u7801\u5e93\u6f14\u5316\u548c\u5f00\u53d1\u8005\u534f\u4f5c\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5efa\u6a21\u5f00\u53d1\u8005\u610f\u89c1\u8f68\u8ff9\u6765\u63ed\u793a\u9690\u6027\u7684\u534f\u4f5c\u6a21\u5f0f\u548c\u77e5\u8bc6\u5171\u4eab\u673a\u5236\u3002", "motivation": "\u8f6f\u4ef6\u4ed3\u5e93\u8bb0\u5f55\u4e86\u5f00\u53d1\u8005\u901a\u8fc7\u62c9\u53d6\u8bf7\u6c42\u548c\u4ee3\u7801\u4fee\u6539\u7b49\u6d3b\u52a8\u7684\u8be6\u7ec6\u6f14\u5316\u8fc7\u7a0b\uff0c\u4f46\u7406\u89e3\u4ee3\u7801\u5e93\u6f14\u5316\u7684\u5e95\u5c42\u52a8\u6001\u548c\u534f\u4f5c\u8fc7\u7a0b\u7f3a\u4e4f\u5b9a\u91cf\u6846\u67b6\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u8f6f\u4ef6\u5de5\u7a0b\u548c\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u7684\u65b9\u6cd5\uff0c\u66f4\u597d\u5730\u7406\u89e3\u5f00\u53d1\u8005\u793e\u533a\u7684\u5171\u8bc6\u5f62\u6210\u3001\u5f71\u54cd\u529b\u4f20\u64ad\u548c\u534f\u4f5c\u6a21\u5f0f\u3002", "method": "1. \u4f7f\u7528\u6700\u5148\u8fdb\u7684\u4ee3\u7801\u5d4c\u5165\u6a21\u578b\u5c06\u4ee3\u7801\u7247\u6bb5\u7f16\u7801\u4e3a\u9ad8\u7ef4\u5411\u91cf\u8868\u793a\uff0c\u4fdd\u7559\u8bed\u6cd5\u548c\u8bed\u4e49\u7279\u5f81\uff1b2. \u4f7f\u7528\u4e3b\u6210\u5206\u5206\u6790\u8fdb\u884c\u964d\u7ef4\uff0c\u5e76\u5bf9\u6570\u636e\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\u4ee5\u786e\u4fdd\u53ef\u6bd4\u6027\uff1b3. \u91c7\u7528\u8868\u8fbe-\u79c1\u6709\u610f\u89c1\u6a21\u578b\u5efa\u6a21\u65f6\u95f4\u6f14\u5316\uff0c\u63a8\u5bfc\u4fe1\u4efb\u77e9\u9635\u5e76\u8ddf\u8e2a\u5f00\u53d1\u5468\u671f\u4e2d\u7684\u610f\u89c1\u8f68\u8ff9\uff1b4. \u5728\u4e09\u4e2a\u77e5\u540d\u7684\u5f00\u6e90GitHub\u4ed3\u5e93\u6570\u636e\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u63ed\u793a\u53ef\u89e3\u91ca\u7684\u884c\u4e3a\u8d8b\u52bf\u548c\u5f00\u53d1\u8005\u4ea4\u4e92\u7684\u53d8\u5316\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u5728\u6539\u5584\u5f00\u6e90\u9879\u76ee\u7ef4\u62a4\u65b9\u9762\u7684\u5b9e\u7528\u6027\u3002\u610f\u89c1\u8f68\u8ff9\u53cd\u6620\u4e86\u5171\u8bc6\u5f62\u6210\u3001\u5f71\u54cd\u529b\u4f20\u64ad\u548c\u5f00\u53d1\u8005\u793e\u533a\u5185\u5bf9\u9f50\uff08\u6216\u5206\u6b67\uff09\u6f14\u5316\u7684\u5e95\u5c42\u52a8\u6001\uff0c\u63ed\u793a\u4e86\u539f\u672c\u96be\u4ee5\u89c2\u5bdf\u7684\u9690\u5f0f\u534f\u4f5c\u6a21\u5f0f\u548c\u77e5\u8bc6\u5171\u4eab\u673a\u5236\u3002", "conclusion": "\u901a\u8fc7\u6865\u63a5\u8f6f\u4ef6\u5de5\u7a0b\u548c\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\uff0c\u8be5\u65b9\u6cd5\u4e3a\u91cf\u5316\u8f6f\u4ef6\u6f14\u5316\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u9014\u5f84\uff0c\u4e3a\u5f00\u53d1\u8005\u5f71\u54cd\u529b\u3001\u5171\u8bc6\u5f62\u6210\u548c\u9879\u76ee\u53ef\u6301\u7eed\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u534f\u4f5c\u52a8\u6001\u5206\u6790\u6539\u8fdb\u5f00\u6e90\u9879\u76ee\u7ef4\u62a4\u3002"}}
{"id": "2602.15614", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.15614", "abs": "https://arxiv.org/abs/2602.15614", "authors": ["Yasmine Hayder", "Adrien Boiret", "C\u00e9dric Eichler", "Benjamin Nguyen"], "title": "Onto-DP: Constructing Neighborhoods for Differential Privacy on Ontological Databases", "comment": null, "summary": "In this paper, we investigate how attackers can discover sensitive information embedded within databases by exploiting inference rules. We demonstrate the inadequacy of naively applied existing state of the art differential privacy (DP) models in safeguarding against such attacks. We introduce ontology aware differential privacy (Onto-DP), a novel extension of differential privacy paradigms built on top of any classical DP model by enriching it with semantic awareness. We show that this extension is a sufficient condition to adequately protect against attackers aware of inference rules.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faOnto-DP\uff08\u672c\u4f53\u611f\u77e5\u5dee\u5206\u9690\u79c1\uff09\uff0c\u901a\u8fc7\u589e\u5f3a\u8bed\u4e49\u610f\u8bc6\u6765\u4fdd\u62a4\u6570\u636e\u5e93\u514d\u53d7\u57fa\u4e8e\u63a8\u7406\u89c4\u5219\u7684\u653b\u51fb\uff0c\u5f25\u8865\u4e86\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u6a21\u578b\u7684\u4e0d\u8db3\u3002", "motivation": "\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u63a8\u7406\u89c4\u5219\u4ece\u6570\u636e\u5e93\u4e2d\u6316\u6398\u654f\u611f\u4fe1\u606f\uff0c\u800c\u73b0\u6709\u7684\u5dee\u5206\u9690\u79c1\u6a21\u578b\u5728\u5e94\u5bf9\u6b64\u7c7b\u653b\u51fb\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u4fdd\u62a4\u673a\u5236\u3002", "method": "\u63d0\u51faOnto-DP\uff08\u672c\u4f53\u611f\u77e5\u5dee\u5206\u9690\u79c1\uff09\uff0c\u4f5c\u4e3a\u7ecf\u5178\u5dee\u5206\u9690\u79c1\u6a21\u578b\u7684\u6269\u5c55\uff0c\u901a\u8fc7\u589e\u5f3a\u8bed\u4e49\u610f\u8bc6\u6765\u9632\u8303\u4e86\u89e3\u63a8\u7406\u89c4\u5219\u7684\u653b\u51fb\u8005\u3002", "result": "Onto-DP\u88ab\u8bc1\u660e\u662f\u5145\u5206\u6761\u4ef6\uff0c\u80fd\u591f\u6709\u6548\u4fdd\u62a4\u6570\u636e\u5e93\u514d\u53d7\u57fa\u4e8e\u63a8\u7406\u89c4\u5219\u7684\u4fe1\u606f\u6cc4\u9732\u653b\u51fb\u3002", "conclusion": "Onto-DP\u901a\u8fc7\u5f15\u5165\u8bed\u4e49\u610f\u8bc6\u6269\u5c55\u4e86\u5dee\u5206\u9690\u79c1\u8303\u5f0f\uff0c\u4e3a\u5bf9\u6297\u63a8\u7406\u89c4\u5219\u653b\u51fb\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u4fdd\u62a4\u673a\u5236\u3002"}}
{"id": "2602.15502", "categories": ["cs.SE", "math.AT"], "pdf": "https://arxiv.org/pdf/2602.15502", "abs": "https://arxiv.org/abs/2602.15502", "authors": ["Chuan-Shen Hu"], "title": "MMPersistence: A mathematical morphology-oriented software library for computing persistent homology on cubical complexes", "comment": null, "summary": "Mathematical morphology (MM) is a powerful and widely used framework in image processing. Through set-theoretic and discrete geometric principles, MM operations such as erosion, dilation, opening, and closing effectively manipulate digital images by modifying local structures via structuring elements (SEs), while cubical homology captures global topological features such as connected components and loop structures within images. Building on the GUDHI package for persistent homology (PH) computation on cubical complexes, we propose the MMPersistence library, which integrates MM operations with diverse SEs and PH computation to extract multiscale persistence information. By employing SEs of different shapes to construct topological filtrations, the proposed MM-based PH framework encodes both spatial and morphological characteristics of digital images, providing richer local geometric information than conventional cubical homology alone and establishing a unified foundation for analyzing digital images that integrates topological insight with morphological image processing techniques.", "AI": {"tldr": "MMPersistence\u5e93\u5c06\u6570\u5b66\u5f62\u6001\u5b66\u64cd\u4f5c\u4e0e\u6301\u4e45\u540c\u8c03\u8ba1\u7b97\u7ed3\u5408\uff0c\u901a\u8fc7\u4e0d\u540c\u5f62\u72b6\u7684\u7ed3\u6784\u5143\u7d20\u6784\u5efa\u62d3\u6251\u8fc7\u6ee4\uff0c\u63d0\u53d6\u6570\u5b57\u56fe\u50cf\u7684\u591a\u5c3a\u5ea6\u62d3\u6251\u7279\u5f81\u3002", "motivation": "\u4f20\u7edf\u7acb\u65b9\u4f53\u540c\u8c03\u4ec5\u6355\u83b7\u56fe\u50cf\u7684\u5168\u5c40\u62d3\u6251\u7279\u5f81\uff08\u5982\u8fde\u901a\u5206\u91cf\u548c\u73af\u7ed3\u6784\uff09\uff0c\u800c\u6570\u5b66\u5f62\u6001\u5b66\u64cd\u4f5c\u80fd\u6709\u6548\u4fee\u6539\u5c40\u90e8\u7ed3\u6784\u3002\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\u6765\u6574\u5408\u62d3\u6251\u6d1e\u5bdf\u4e0e\u5f62\u6001\u5b66\u56fe\u50cf\u5904\u7406\u6280\u672f\uff0c\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u5c40\u90e8\u51e0\u4f55\u4fe1\u606f\u3002", "method": "\u57fa\u4e8eGUDHI\u5305\u8fdb\u884c\u7acb\u65b9\u4f53\u590d\u5f62\u7684\u6301\u4e45\u540c\u8c03\u8ba1\u7b97\uff0c\u63d0\u51faMMPersistence\u5e93\uff0c\u96c6\u6210\u6570\u5b66\u5f62\u6001\u5b66\u64cd\u4f5c\uff08\u8150\u8680\u3001\u81a8\u80c0\u3001\u5f00\u95ed\u8fd0\u7b97\uff09\u4e0e\u4e0d\u540c\u5f62\u72b6\u7684\u7ed3\u6784\u5143\u7d20\uff0c\u901a\u8fc7\u7ed3\u6784\u5143\u7d20\u6784\u5efa\u62d3\u6251\u8fc7\u6ee4\u6765\u63d0\u53d6\u591a\u5c3a\u5ea6\u6301\u4e45\u4fe1\u606f\u3002", "result": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6570\u5b66\u5f62\u6001\u5b66\u7684\u6301\u4e45\u540c\u8c03\u6846\u67b6\u80fd\u591f\u540c\u65f6\u7f16\u7801\u6570\u5b57\u56fe\u50cf\u7684\u7a7a\u95f4\u548c\u5f62\u6001\u7279\u5f81\uff0c\u63d0\u4f9b\u6bd4\u4f20\u7edf\u7acb\u65b9\u4f53\u540c\u8c03\u66f4\u4e30\u5bcc\u7684\u5c40\u90e8\u51e0\u4f55\u4fe1\u606f\uff0c\u5efa\u7acb\u4e86\u6574\u5408\u62d3\u6251\u6d1e\u5bdf\u4e0e\u5f62\u6001\u5b66\u56fe\u50cf\u5904\u7406\u7684\u7edf\u4e00\u57fa\u7840\u3002", "conclusion": "MMPersistence\u5e93\u6210\u529f\u6574\u5408\u4e86\u6570\u5b66\u5f62\u6001\u5b66\u64cd\u4f5c\u4e0e\u6301\u4e45\u540c\u8c03\u8ba1\u7b97\uff0c\u901a\u8fc7\u7ed3\u6784\u5143\u7d20\u6784\u5efa\u7684\u62d3\u6251\u8fc7\u6ee4\u80fd\u591f\u63d0\u53d6\u6570\u5b57\u56fe\u50cf\u7684\u591a\u5c3a\u5ea6\u62d3\u6251\u7279\u5f81\uff0c\u4e3a\u6570\u5b57\u56fe\u50cf\u5206\u6790\u63d0\u4f9b\u4e86\u540c\u65f6\u5305\u542b\u62d3\u6251\u548c\u5f62\u6001\u4fe1\u606f\u7684\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2602.15248", "categories": ["cs.AI", "math.OC", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2602.15248", "abs": "https://arxiv.org/abs/2602.15248", "authors": ["Pavel Koptev", "Vishnu Kumar", "Konstantin Malkov", "George Shapiro", "Yury Vikhanov"], "title": "Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models", "comment": null, "summary": "Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAI/\u673a\u5668\u5b66\u4e60\u6846\u67b6\u8865\u5145\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u9884\u6d4b\u4f9b\u5e94\u94fe\u91d1\u878d\u4e2d\u7684\u53d1\u7968\u7a00\u91ca\u98ce\u9669\uff0c\u4f7f\u7528\u5b9e\u65f6\u52a8\u6001\u4fe1\u7528\u9650\u989d\u66ff\u4ee3\u4f20\u7edf\u4e0d\u53ef\u64a4\u9500\u4ed8\u6b3e\u627f\u8bfa", "motivation": "\u53d1\u7968\u7a00\u91ca\uff08\u6279\u51c6\u91d1\u989d\u4e0e\u5b9e\u9645\u6536\u6b3e\u5dee\u989d\uff09\u662f\u4f9b\u5e94\u94fe\u91d1\u878d\u4e2d\u975e\u4fe1\u7528\u98ce\u9669\u548c\u5229\u6da6\u635f\u5931\u7684\u91cd\u8981\u6765\u6e90\u3002\u4f20\u7edf\u4f9d\u8d56\u4e70\u65b9\u4e0d\u53ef\u64a4\u9500\u4ed8\u6b3e\u627f\u8bfa\uff08IPU\uff09\u7684\u65b9\u6cd5\u963b\u788d\u4e86\u4f9b\u5e94\u94fe\u91d1\u878d\u7684\u91c7\u7eb3\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6b21\u7ea7\u6295\u8d44\u7ea7\u4e70\u65b9\u3002\u9700\u8981\u66f4\u7075\u6d3b\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "method": "\u63d0\u51faAI/\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u8865\u5145\u786e\u5b9a\u6027\u7b97\u6cd5\u9884\u6d4b\u53d1\u7968\u7a00\u91ca\u3002\u4f7f\u7528\u5b9e\u65f6\u52a8\u6001\u4fe1\u7528\u9650\u989d\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4e5d\u4e2a\u5173\u952e\u4ea4\u6613\u5b57\u6bb5\u7684\u5e7f\u6cdb\u751f\u4ea7\u6570\u636e\u96c6\uff0c\u4e3a\u6bcf\u4e2a\u4e70\u65b9-\u4f9b\u5e94\u5546\u5bf9\u5b9e\u65f6\u9884\u6d4b\u7a00\u91ca\u98ce\u9669\u3002", "result": "\u8bba\u6587\u8bc4\u4f30\u4e86AI/\u673a\u5668\u5b66\u4e60\u6846\u67b6\u5982\u4f55\u8865\u5145\u786e\u5b9a\u6027\u7b97\u6cd5\u6765\u9884\u6d4b\u53d1\u7968\u7a00\u91ca\uff0c\u4f46\u5177\u4f53\u7ed3\u679c\u672a\u5728\u6458\u8981\u4e2d\u63d0\u4f9b\u3002", "conclusion": "AI/\u673a\u5668\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u8865\u5145\u4f20\u7edf\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u4e3a\u4f9b\u5e94\u94fe\u91d1\u878d\u63d0\u4f9b\u66f4\u7075\u6d3b\u3001\u6570\u636e\u9a71\u52a8\u7684\u53d1\u7968\u7a00\u91ca\u98ce\u9669\u7ba1\u7406\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u4f9b\u5e94\u94fe\u91d1\u878d\u7684\u91c7\u7eb3\u3002"}}
{"id": "2602.15552", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15552", "abs": "https://arxiv.org/abs/2602.15552", "authors": ["Giorgi Merabishvili", "Oliver Wei\u00dfl", "Andrea Stocco"], "title": "Latent Regularization in Generative Test Input Generation", "comment": "Accepted for publication at the 7th International Workshop on Deep Learning for Testing and Testing for Deep Learning (DeepTest 2026), co-located with ICSE 2026", "summary": "This study investigates the impact of regularization of latent spaces through truncation on the quality of generated test inputs for deep learning classifiers. We evaluate this effect using style-based GANs, a state-of-the-art generative approach, and assess quality along three dimensions: validity, diversity, and fault detection. We evaluate our approach on the boundary testing of deep learning image classifiers across three datasets, MNIST, Fashion MNIST, and CIFAR-10. We compare two truncation strategies: latent code mixing with binary search optimization and random latent truncation for generative exploration. Our experiments show that the latent code-mixing approach yields a higher fault detection rate than random truncation, while also improving both diversity and validity.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u622a\u65ad\u6b63\u5219\u5316\u6f5c\u5728\u7a7a\u95f4\u5bf9\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u5668\u751f\u6210\u6d4b\u8bd5\u8f93\u5165\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u4f7f\u7528\u98ce\u683cGAN\u8bc4\u4f30\u4e09\u79cd\u8d28\u91cf\u7ef4\u5ea6\uff1a\u6709\u6548\u6027\u3001\u591a\u6837\u6027\u548c\u6545\u969c\u68c0\u6d4b\u7387", "motivation": "\u63a2\u7d22\u6f5c\u5728\u7a7a\u95f4\u6b63\u5219\u5316\uff08\u7279\u522b\u662f\u622a\u65ad\uff09\u5982\u4f55\u5f71\u54cd\u4e3a\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u5668\u751f\u6210\u7684\u6d4b\u8bd5\u8f93\u5165\u7684\u8d28\u91cf\uff0c\u65e8\u5728\u63d0\u9ad8\u8fb9\u754c\u6d4b\u8bd5\u7684\u6548\u679c", "method": "\u4f7f\u7528\u57fa\u4e8e\u98ce\u683c\u7684GANs\uff0c\u5728MNIST\u3001Fashion MNIST\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e24\u79cd\u622a\u65ad\u7b56\u7565\uff1a\u6f5c\u5728\u4ee3\u7801\u6df7\u5408\uff08\u5e26\u4e8c\u5206\u641c\u7d22\u4f18\u5316\uff09\u548c\u968f\u673a\u6f5c\u5728\u622a\u65ad", "result": "\u6f5c\u5728\u4ee3\u7801\u6df7\u5408\u65b9\u6cd5\u6bd4\u968f\u673a\u622a\u65ad\u5177\u6709\u66f4\u9ad8\u7684\u6545\u969c\u68c0\u6d4b\u7387\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u591a\u6837\u6027\u548c\u6709\u6548\u6027", "conclusion": "\u901a\u8fc7\u6f5c\u5728\u4ee3\u7801\u6df7\u5408\u8fdb\u884c\u6f5c\u5728\u7a7a\u95f4\u6b63\u5219\u5316\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u751f\u6210\u6d4b\u8bd5\u8f93\u5165\u7684\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u6545\u969c\u68c0\u6d4b\u3001\u591a\u6837\u6027\u548c\u6709\u6548\u6027\u65b9\u9762"}}
{"id": "2602.15671", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.15671", "abs": "https://arxiv.org/abs/2602.15671", "authors": ["Haodong Zhao", "Jinming Hu", "Gongshen Liu"], "title": "Revisiting Backdoor Threat in Federated Instruction Tuning from a Signal Aggregation Perspective", "comment": "Accepted by ICASSP 2026", "summary": "Federated learning security research has predominantly focused on backdoor threats from a minority of malicious clients that intentionally corrupt model updates. This paper challenges this paradigm by investigating a more pervasive and insidious threat: \\textit{backdoor vulnerabilities from low-concentration poisoned data distributed across the datasets of benign clients.} This scenario is increasingly common in federated instruction tuning for language models, which often rely on unverified third-party and crowd-sourced data. We analyze two forms of backdoor data through real cases: 1) \\textit{natural trigger (inherent features as implicit triggers)}; 2) \\textit{adversary-injected trigger}. To analyze this threat, we model the backdoor implantation process from signal aggregation, proposing the Backdoor Signal-to-Noise Ratio to quantify the dynamics of the distributed backdoor signal. Extensive experiments reveal the severity of this threat: With just less than 10\\% of training data poisoned and distributed across clients, the attack success rate exceeds 85\\%, while the primary task performance remains largely intact. Critically, we demonstrate that state-of-the-art backdoor defenses, designed for attacks from malicious clients, are fundamentally ineffective against this threat. Our findings highlight an urgent need for new defense mechanisms tailored to the realities of modern, decentralized data ecosystems.", "AI": {"tldr": "\u8054\u90a6\u5b66\u4e60\u4e2d\u5b58\u5728\u4e00\u79cd\u65b0\u578b\u540e\u95e8\u5a01\u80c1\uff1a\u826f\u6027\u5ba2\u6237\u7aef\u6570\u636e\u96c6\u4e2d\u5206\u5e03\u7684\u4f4e\u6d53\u5ea6\u4e2d\u6bd2\u6570\u636e\uff0c\u5373\u4f7f\u53ea\u6709\u4e0d\u523010%\u7684\u8bad\u7ec3\u6570\u636e\u4e2d\u6bd2\uff0c\u653b\u51fb\u6210\u529f\u7387\u4ecd\u53ef\u8d85\u8fc785%\uff0c\u4e14\u73b0\u6709\u9632\u5fa1\u673a\u5236\u5bf9\u6b64\u5b8c\u5168\u65e0\u6548\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5b89\u5168\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5c11\u6570\u6076\u610f\u5ba2\u6237\u7aef\u7684\u540e\u95e8\u653b\u51fb\uff0c\u4f46\u672c\u6587\u6311\u6218\u8fd9\u4e00\u8303\u5f0f\uff0c\u7814\u7a76\u66f4\u666e\u904d\u4e14\u9690\u853d\u7684\u5a01\u80c1\uff1a\u826f\u6027\u5ba2\u6237\u7aef\u6570\u636e\u96c6\u4e2d\u5206\u5e03\u7684\u4f4e\u6d53\u5ea6\u4e2d\u6bd2\u6570\u636e\u5e26\u6765\u7684\u540e\u95e8\u6f0f\u6d1e\u3002\u8fd9\u5728\u4f9d\u8d56\u672a\u7ecf\u9a8c\u8bc1\u7684\u7b2c\u4e09\u65b9\u548c\u4f17\u5305\u6570\u636e\u7684\u8054\u90a6\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u4e2d\u5c24\u4e3a\u5e38\u89c1\u3002", "method": "1) \u5206\u6790\u4e24\u79cd\u540e\u95e8\u6570\u636e\u5f62\u5f0f\uff1a\u81ea\u7136\u89e6\u53d1\uff08\u56fa\u6709\u7279\u5f81\u4f5c\u4e3a\u9690\u5f0f\u89e6\u53d1\u5668\uff09\u548c\u5bf9\u624b\u6ce8\u5165\u89e6\u53d1\uff1b2) \u4ece\u4fe1\u53f7\u805a\u5408\u89d2\u5ea6\u5efa\u6a21\u540e\u95e8\u690d\u5165\u8fc7\u7a0b\uff0c\u63d0\u51fa\u540e\u95e8\u4fe1\u566a\u6bd4\u6765\u91cf\u5316\u5206\u5e03\u5f0f\u540e\u95e8\u4fe1\u53f7\u7684\u52a8\u6001\u7279\u6027\uff1b3) \u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u5a01\u80c1\u4e25\u91cd\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u4ec5\u4e0d\u523010%\u7684\u8bad\u7ec3\u6570\u636e\u4e2d\u6bd2\u5e76\u5206\u5e03\u5728\u5ba2\u6237\u7aef\u4e2d\uff0c\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc785%\uff0c\u800c\u4e3b\u8981\u4efb\u52a1\u6027\u80fd\u57fa\u672c\u4e0d\u53d7\u5f71\u54cd\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u9488\u5bf9\u6076\u610f\u5ba2\u6237\u7aef\u653b\u51fb\u8bbe\u8ba1\u7684\u6700\u5148\u8fdb\u540e\u95e8\u9632\u5fa1\u673a\u5236\u5bf9\u8fd9\u79cd\u5a01\u80c1\u5b8c\u5168\u65e0\u6548\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u9488\u5bf9\u73b0\u4ee3\u53bb\u4e2d\u5fc3\u5316\u6570\u636e\u751f\u6001\u7cfb\u7edf\u73b0\u5b9e\u60c5\u51b5\u5f00\u53d1\u65b0\u9632\u5fa1\u673a\u5236\u7684\u7d27\u8feb\u9700\u6c42\u3002\u8fd9\u79cd\u5206\u5e03\u5f0f\u4f4e\u6d53\u5ea6\u4e2d\u6bd2\u6570\u636e\u5a01\u80c1\u6bd4\u4f20\u7edf\u6076\u610f\u5ba2\u6237\u7aef\u653b\u51fb\u66f4\u9690\u853d\u4e14\u96be\u4ee5\u9632\u5fa1\u3002"}}
{"id": "2602.15591", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.15591", "abs": "https://arxiv.org/abs/2602.15591", "authors": ["Denesa Zyberaj", "Lukasz Mazur", "Pascal Hirmer", "Nenad Petrovic", "Marco Aiello", "Alois Knoll"], "title": "Req2Road: A GenAI Pipeline for SDV Test Artifact Generation and On-Vehicle Execution", "comment": "accepted at CAiSE 2026 main", "summary": "Testing functionality in Software-Defined Vehicles is challenging because requirements are written in natural language, specifications combine text, tables, and diagrams, while test assets are scattered across heterogeneous toolchains. Large Language Models and Vision-Language Models are used to extract signals and behavioral logic to automatically generate Gherkin scenarios, which are then converted into runnable test scripts. The Vehicle Signal Specification (VSS) integration standardizes signal references, supporting portability across subsystems and test benches. The pipeline uses retrieval-augmented generation to preselect candidate VSS signals before mapping. We evaluate the approach on the safety-relevant Child Presence Detection System, executing the generated tests in a virtual environment and on an actual vehicle. Our evaluation covers Gherkin validity, VSS mapping quality, and end-to-end executability. Results show that 32 of 36 requirements (89\\%) can be transformed into executable scenarios in our setting, while human review and targeted substitutions remain necessary. This paper is a feasibility and architectural demonstration of an end-to-end requirements-to-test pipeline for SDV subsystems, evaluated on a CPDS case in simulation and Vehicle-in-the-Loop settings.", "AI": {"tldr": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u4e2d\u81ea\u52a8\u751f\u6210Gherkin\u6d4b\u8bd5\u573a\u666f\uff0c\u901a\u8fc7VSS\u6807\u51c6\u5316\u4fe1\u53f7\u5f15\u7528\uff0c\u5b9e\u73b0\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\u7684\u53ef\u6267\u884c\u6d4b\u8bd5\u751f\u6210", "motivation": "\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\u7684\u529f\u80fd\u6d4b\u8bd5\u9762\u4e34\u6311\u6218\uff1a\u9700\u6c42\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u7f16\u5199\uff0c\u89c4\u8303\u5305\u542b\u6587\u672c\u3001\u8868\u683c\u548c\u56fe\u8868\uff0c\u6d4b\u8bd5\u8d44\u4ea7\u5206\u6563\u5728\u5f02\u6784\u5de5\u5177\u94fe\u4e2d\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u4fe1\u53f7\u548c\u884c\u4e3a\u903b\u8f91\uff0c\u81ea\u52a8\u751f\u6210Gherkin\u573a\u666f\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u9884\u9009\u5019\u9009VSS\u4fe1\u53f7\uff0c\u96c6\u6210\u8f66\u8f86\u4fe1\u53f7\u89c4\u8303\u6807\u51c6\u5316\u4fe1\u53f7\u5f15\u7528", "result": "\u5728\u513f\u7ae5\u5b58\u5728\u68c0\u6d4b\u7cfb\u7edf\u8bc4\u4f30\u4e2d\uff0c36\u4e2a\u9700\u6c42\u4e2d\u768432\u4e2a\uff0889%\uff09\u53ef\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u573a\u666f\uff0c\u5728\u865a\u62df\u73af\u5883\u548c\u5b9e\u9645\u8f66\u8f86\u4e2d\u6267\u884c\u6d4b\u8bd5\uff0c\u9a8c\u8bc1\u4e86\u7aef\u5230\u7aef\u53ef\u6267\u884c\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\u5b50\u7cfb\u7edf\u4ece\u9700\u6c42\u5230\u6d4b\u8bd5\u7684\u7aef\u5230\u7aef\u7ba1\u9053\u7684\u53ef\u884c\u6027\uff0c\u867d\u7136\u4ecd\u9700\u4eba\u5de5\u5ba1\u67e5\u548c\u9488\u5bf9\u6027\u66ff\u6362\uff0c\u4f46\u5728\u4eff\u771f\u548c\u8f66\u8f86\u5728\u73af\u8bbe\u7f6e\u4e2d\u9a8c\u8bc1\u6709\u6548"}}
{"id": "2602.15274", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15274", "abs": "https://arxiv.org/abs/2602.15274", "authors": ["Omid Madani", "J. Brian Burns", "Reza Eghbali", "Thomas L. Dean"], "title": "When Remembering and Planning are Worth it: Navigating under Change", "comment": null, "summary": "We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\uff0c\u4e0d\u540c\u7c7b\u578b\u548c\u7528\u9014\u7684\u8bb0\u5fc6\u5982\u4f55\u5e2e\u52a9\u7a7a\u95f4\u5bfc\u822a\u3002\u5728\u7b80\u5355\u7684\u89c5\u98df\u4efb\u52a1\u4e2d\uff0c\u667a\u80fd\u4f53\u9700\u8981\u5728\u969c\u788d\u7269\u548c\u98df\u7269\u4f4d\u7f6e\u6bcf\u65e5\u53d8\u5316\u3001\u611f\u77e5\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece\u5bb6\u627e\u5230\u98df\u7269\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u7ed3\u5408\u591a\u79cd\u7b56\u7565\u7684\u67b6\u6784\u80fd\u6709\u6548\u5904\u7406\u63a2\u7d22\u548c\u89c4\u5212\u7b49\u4e0d\u540c\u6027\u8d28\u7684\u4efb\u52a1\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u7a7a\u95f4\u5bfc\u822a\u95ee\u9898\u3002\u73af\u5883\u5177\u6709\u975e\u5e73\u7a33\u6027\uff08\u969c\u788d\u7269\u548c\u98df\u7269\u4f4d\u7f6e\u6bcf\u65e5\u53d8\u5316\uff09\u3001\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\uff08\u4f4d\u7f6e\u4fe1\u606f\u6709\u9650\u4e14\u4e0d\u786e\u5b9a\uff09\u7b49\u6311\u6218\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5feb\u901f\u5b66\u4e60\u5e76\u9002\u5e94\u8fd9\u4e9b\u53d8\u5316\u7684\u9c81\u68d2\u5bfc\u822a\u7b56\u7565\u3002", "method": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4ece\u7b80\u5355\u5230\u590d\u6742\u7684\u591a\u79cd\u7b56\u7565\uff0c\u5305\u62ec\u4e0d\u540c\u7684\u8bb0\u5fc6\u4f7f\u7528\u548c\u5b66\u4e60\u65b9\u5f0f\u3002\u4e3b\u8981\u65b9\u6cd5\u5305\u62ec\uff1a\u4f7f\u7528\u975e\u5e73\u7a33\u6982\u7387\u5b66\u4e60\u6280\u672f\u6301\u7eed\u66f4\u65b0\u60c5\u666f\u8bb0\u5fc6\uff1b\u5229\u7528\u8fd9\u4e9b\u8bb0\u5fc6\u6784\u5efa\u5373\u65f6\u5730\u56fe\uff08\u4e0d\u5b8c\u7f8e\u5730\u56fe\uff0c\u53d7\u9650\u4e8e\u667a\u80fd\u4f53\u7ecf\u9a8c\u4e14\u5305\u542b\u566a\u58f0\uff09\uff1b\u57fa\u4e8e\u8bb0\u5fc6\u8fdb\u884c\u8def\u5f84\u89c4\u5212\uff1b\u4ee5\u53ca\u7ed3\u5408\u591a\u79cd\u7b56\u7565\u7684\u67b6\u6784\u6765\u5904\u7406\u63a2\u7d22\u548c\u641c\u7d22\u7b49\u4e0d\u540c\u6027\u8d28\u7684\u4efb\u52a1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u9700\u8981\u80fd\u591f\u7ed3\u5408\u591a\u79cd\u7b56\u7565\u7684\u67b6\u6784\u6765\u5904\u7406\u4e0d\u540c\u6027\u8d28\u7684\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5f53\u98df\u7269\u4f4d\u7f6e\u672a\u77e5\u65f6\u7684\u63a2\u7d22\u641c\u7d22\u4efb\u52a1\uff0c\u4ee5\u53ca\u5bf9\u8bb0\u5fc6\u4e2d\u7684\uff08\u53ef\u80fd\uff09\u98df\u7269\u4f4d\u7f6e\u8fdb\u884c\u8def\u5f84\u89c4\u5212\uff1b2\uff09\u4f7f\u7528\u975e\u5e73\u7a33\u6982\u7387\u5b66\u4e60\u6280\u672f\u6301\u7eed\u66f4\u65b0\u60c5\u666f\u8bb0\u5fc6\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u8bb0\u5fc6\u6784\u5efa\u5373\u65f6\u5730\u56fe\u8fdb\u884c\u89c4\u5212\u7684\u667a\u80fd\u4f53\uff0c\u5728\u4efb\u52a1\u96be\u5ea6\uff08\u5982\u76ee\u6807\u8ddd\u79bb\uff09\u589e\u52a0\u65f6\uff0c\u80fd\u663e\u8457\u6bd4\u7b80\u5355\uff08\u6700\u5c0f\u8bb0\u5fc6\uff09\u667a\u80fd\u4f53\u66f4\u9ad8\u6548\uff1b3\uff09\u8fd9\u79cd\u4f18\u52bf\u7684\u524d\u63d0\u662f\u5b9a\u4f4d\u548c\u73af\u5883\u53d8\u5316\u5e26\u6765\u7684\u4e0d\u786e\u5b9a\u6027\u4e0d\u80fd\u592a\u5927\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\uff0c\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\uff0c\u7ed3\u5408\u591a\u79cd\u8bb0\u5fc6\u4f7f\u7528\u7b56\u7565\u7684\u667a\u80fd\u4f53\u67b6\u6784\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u7a7a\u95f4\u5bfc\u822a\u6548\u7387\u3002\u901a\u8fc7\u975e\u5e73\u7a33\u6982\u7387\u5b66\u4e60\u6301\u7eed\u66f4\u65b0\u60c5\u666f\u8bb0\u5fc6\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u8bb0\u5fc6\u6784\u5efa\u5373\u65f6\u5730\u56fe\u8fdb\u884c\u89c4\u5212\u7684\u65b9\u6cd5\uff0c\u5728\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u8868\u73b0\u51fa\u660e\u663e\u4f18\u52bf\uff0c\u4f46\u9700\u8981\u63a7\u5236\u4e0d\u786e\u5b9a\u6027\u6c34\u5e73\u4ee5\u4fdd\u8bc1\u6709\u6548\u6027\u3002"}}
{"id": "2602.15761", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.15761", "abs": "https://arxiv.org/abs/2602.15761", "authors": ["Simantika Bhattacharjee Dristi", "Matthew B. Dwyer"], "title": "A Differential Fuzzing-Based Evaluation of Functional Equivalence in LLM-Generated Code Refactorings", "comment": null, "summary": "With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation becomes critical. While prior work typically relies on predefined test cases to evaluate correctness, in this work, we leverage differential fuzzing to check functional equivalence in LLM-generated code refactorings. Unlike test-based evaluation, a differential fuzzing-based equivalence checker needs no predefined test cases and can explore a much larger input space by executing and comparing thousands of automatically generated test inputs. In a large-scale evaluation of six LLMs (CodeLlama, Codestral, StarChat2, Qwen-2.5, Olmo-3, and GPT-4o) across three datasets and two refactoring types, we find that LLMs show a non-trivial tendency to alter program semantics, producing 19-35% functionally non-equivalent refactorings. Our experiments further demonstrate that about 21% of these non-equivalent refactorings remain undetected by the existing test suites of the three evaluated datasets. Collectively, the findings of this study imply that reliance on existing tests might overestimate functional equivalence in LLM-generated code refactorings, which remain prone to semantic divergence.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u8bc4\u4f30LLM\u751f\u6210\u4ee3\u7801\u91cd\u6784\u7684\u529f\u80fd\u7b49\u4ef7\u6027\uff0c\u53d1\u73b0LLM\u572819-35%\u7684\u60c5\u51b5\u4e0b\u4f1a\u6539\u53d8\u7a0b\u5e8f\u8bed\u4e49\uff0c\u4e14\u73b0\u6709\u6d4b\u8bd5\u5957\u4ef6\u65e0\u6cd5\u68c0\u6d4b\u7ea621%\u7684\u975e\u7b49\u4ef7\u91cd\u6784\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u4ee3\u7801\u91cd\u6784\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u8bc4\u4f30\u548c\u786e\u4fddLLM\u751f\u6210\u91cd\u6784\u4e0e\u539f\u59cb\u5b9e\u73b0\u4e4b\u95f4\u7684\u529f\u80fd\u7b49\u4ef7\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7814\u7a76\u901a\u5e38\u4f9d\u8d56\u9884\u5b9a\u4e49\u6d4b\u8bd5\u7528\u4f8b\u8bc4\u4f30\u6b63\u786e\u6027\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u6765\u68c0\u67e5LLM\u751f\u6210\u4ee3\u7801\u91cd\u6784\u7684\u529f\u80fd\u7b49\u4ef7\u6027\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u9884\u5b9a\u4e49\u6d4b\u8bd5\u7528\u4f8b\uff0c\u901a\u8fc7\u6267\u884c\u548c\u6bd4\u8f83\u6570\u5343\u4e2a\u81ea\u52a8\u751f\u6210\u7684\u6d4b\u8bd5\u8f93\u5165\u6765\u63a2\u7d22\u66f4\u5927\u7684\u8f93\u5165\u7a7a\u95f4\u3002\u7814\u7a76\u5bf9\u516d\u4e2aLLM\uff08CodeLlama\u3001Codestral\u3001StarChat2\u3001Qwen-2.5\u3001Olmo-3\u548cGPT-4o\uff09\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u548c\u4e24\u79cd\u91cd\u6784\u7c7b\u578b\u4e0a\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM\u8868\u73b0\u51fa\u663e\u8457\u6539\u53d8\u7a0b\u5e8f\u8bed\u4e49\u7684\u8d8b\u52bf\uff0c\u4ea7\u751f\u4e8619-35%\u7684\u529f\u80fd\u975e\u7b49\u4ef7\u91cd\u6784\u3002\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u8868\u660e\uff0c\u8fd9\u4e9b\u975e\u7b49\u4ef7\u91cd\u6784\u4e2d\u7ea621%\u65e0\u6cd5\u88ab\u4e09\u4e2a\u8bc4\u4f30\u6570\u636e\u96c6\u7684\u73b0\u6709\u6d4b\u8bd5\u5957\u4ef6\u68c0\u6d4b\u5230\u3002", "conclusion": "\u4f9d\u8d56\u73b0\u6709\u6d4b\u8bd5\u53ef\u80fd\u4f1a\u9ad8\u4f30LLM\u751f\u6210\u4ee3\u7801\u91cd\u6784\u7684\u529f\u80fd\u7b49\u4ef7\u6027\uff0c\u8fd9\u4e9b\u91cd\u6784\u4ecd\u7136\u5bb9\u6613\u51fa\u73b0\u8bed\u4e49\u504f\u5dee\u3002\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5168\u9762\u7684\u529f\u80fd\u7b49\u4ef7\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u591f\u53d1\u73b0\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u9057\u6f0f\u7684\u95ee\u9898\u3002"}}
{"id": "2602.15815", "categories": ["cs.CR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.15815", "abs": "https://arxiv.org/abs/2602.15815", "authors": ["Matthew Regehr", "Bingshan Hu", "Ethan Leeman", "Pasin Manurangsi", "Pierre Tholoniat", "Mathias L\u00e9cuyer"], "title": "Natural Privacy Filters Are Not Always Free: A Characterization of Free Natural Filters", "comment": null, "summary": "We study natural privacy filters, which enable the exact composition of differentially private (DP) mechanisms with adaptively chosen privacy characteristics. Earlier privacy filters consider only simple privacy parameters such as R\u00e9nyi-DP or Gaussian DP parameters. Natural filters account for the entire privacy profile of every query, promising greater utility for a given privacy budget. We show that, contrary to other forms of DP, natural privacy filters are not free in general. Indeed, we show that only families of privacy mechanisms that are well-ordered when composed admit free natural privacy filters.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\uff0c\u5b83\u80fd\u591f\u7cbe\u786e\u7ec4\u5408\u5177\u6709\u81ea\u9002\u5e94\u9009\u62e9\u9690\u79c1\u7279\u6027\u7684\u5dee\u5206\u9690\u79c1\u673a\u5236\u3002\u4e0e\u4ec5\u8003\u8651\u7b80\u5355\u9690\u79c1\u53c2\u6570\u7684\u4f20\u7edf\u8fc7\u6ee4\u5668\u4e0d\u540c\uff0c\u81ea\u7136\u8fc7\u6ee4\u5668\u8003\u8651\u4e86\u6bcf\u4e2a\u67e5\u8be2\u7684\u5b8c\u6574\u9690\u79c1\u914d\u7f6e\u6587\u4ef6\uff0c\u6709\u671b\u5728\u7ed9\u5b9a\u9690\u79c1\u9884\u7b97\u4e0b\u63d0\u4f9b\u66f4\u597d\u7684\u6548\u7528\u3002", "motivation": "\u73b0\u6709\u9690\u79c1\u8fc7\u6ee4\u5668\u901a\u5e38\u53ea\u8003\u8651\u7b80\u5355\u7684\u9690\u79c1\u53c2\u6570\uff08\u5982R\u00e9nyi-DP\u6216\u9ad8\u65afDP\u53c2\u6570\uff09\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u6bcf\u4e2a\u67e5\u8be2\u7684\u5b8c\u6574\u9690\u79c1\u914d\u7f6e\u6587\u4ef6\u4fe1\u606f\u3002\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\u65e8\u5728\u901a\u8fc7\u8003\u8651\u5b8c\u6574\u7684\u9690\u79c1\u914d\u7f6e\u6587\u4ef6\u6765\u63d0\u9ad8\u9690\u79c1\u673a\u5236\u7684\u6548\u7528\uff0c\u4f46\u9700\u8981\u7814\u7a76\u5176\u662f\u5426\u50cf\u5176\u4ed6\u5f62\u5f0f\u7684DP\u90a3\u6837\u53ef\u4ee5\"\u514d\u8d39\"\u83b7\u5f97\u3002", "method": "\u7814\u7a76\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\u7684\u7406\u8bba\u7279\u6027\uff0c\u5206\u6790\u5176\u5728\u7ec4\u5408\u5dee\u5206\u9690\u79c1\u673a\u5236\u65f6\u7684\u884c\u4e3a\u3002\u7279\u522b\u5173\u6ce8\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\u662f\u5426\u80fd\u591f\"\u514d\u8d39\"\u83b7\u5f97\uff08\u5373\u4e0d\u589e\u52a0\u989d\u5916\u9690\u79c1\u6210\u672c\uff09\uff0c\u5e76\u786e\u5b9a\u54ea\u4e9b\u7c7b\u578b\u7684\u9690\u79c1\u673a\u5236\u5bb6\u65cf\u5728\u7ec4\u5408\u65f6\u5141\u8bb8\u514d\u8d39\u7684\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0e\u76f4\u89c9\u76f8\u53cd\uff0c\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\u901a\u5e38\u4e0d\u662f\u514d\u8d39\u7684\u3002\u53ea\u6709\u5f53\u9690\u79c1\u673a\u5236\u5bb6\u65cf\u5728\u7ec4\u5408\u65f6\u5177\u6709\u826f\u597d\u6392\u5e8f\u7279\u6027\u65f6\uff0c\u624d\u5b58\u5728\u514d\u8d39\u7684\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\u3002\u8fd9\u610f\u5473\u7740\u5e76\u975e\u6240\u6709\u7c7b\u578b\u7684\u9690\u79c1\u673a\u5236\u90fd\u80fd\u5728\u4e0d\u589e\u52a0\u989d\u5916\u9690\u79c1\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u3002", "conclusion": "\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\u867d\u7136\u80fd\u591f\u901a\u8fc7\u8003\u8651\u5b8c\u6574\u7684\u9690\u79c1\u914d\u7f6e\u6587\u4ef6\u6765\u63d0\u9ad8\u6548\u7528\uff0c\u4f46\u901a\u5e38\u9700\u8981\u4ed8\u51fa\u989d\u5916\u7684\u9690\u79c1\u6210\u672c\u3002\u53ea\u6709\u5728\u9690\u79c1\u673a\u5236\u5bb6\u65cf\u5177\u6709\u826f\u597d\u6392\u5e8f\u7279\u6027\u7684\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u624d\u80fd\u5b9e\u73b0\u514d\u8d39\u7684\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u3002\u8fd9\u4e00\u53d1\u73b0\u5bf9\u8bbe\u8ba1\u9ad8\u6548\u9690\u79c1\u4fdd\u62a4\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.15391", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15391", "abs": "https://arxiv.org/abs/2602.15391", "authors": ["Ankit Sharma", "Nachiket Tapas", "Jyotiprakash Patra"], "title": "Improving LLM Reliability through Hybrid Abstention and Adaptive Detection", "comment": null, "summary": "Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u5f03\u6743\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5b89\u5168\u9608\u503c\u548c\u5c42\u7ea7\u7ea7\u8054\u673a\u5236\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5e73\u8861LLM\u7684\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u5f53\u524dLLM\u90e8\u7f72\u9762\u4e34\u5b89\u5168\u6027\u4e0e\u5b9e\u7528\u6027\u7684\u6839\u672c\u6743\u8861\uff1a\u4e25\u683c\u7684\u8fc7\u6ee4\u673a\u5236\u4f1a\u963b\u6b62\u826f\u6027\u67e5\u8be2\uff0c\u800c\u5bbd\u677e\u7684\u63a7\u5236\u5219\u53ef\u80fd\u751f\u6210\u4e0d\u5b89\u5168\u5185\u5bb9\u3002\u4f20\u7edf\u7684\u57fa\u4e8e\u9759\u6001\u89c4\u5219\u6216\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u9608\u503c\u7684\u9632\u62a4\u63aa\u65bd\u901a\u5e38\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u654f\u611f\u6027\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u548c\u7528\u6237\u4f53\u9a8c\u4e0b\u964d\u3002", "method": "\u5f15\u5165\u81ea\u9002\u5e94\u5f03\u6743\u7cfb\u7edf\uff0c\u57fa\u4e8e\u5b9e\u65f6\u4e0a\u4e0b\u6587\u4fe1\u53f7\uff08\u5982\u9886\u57df\u548c\u7528\u6237\u5386\u53f2\uff09\u52a8\u6001\u8c03\u6574\u5b89\u5168\u9608\u503c\u3002\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u7531\u4e94\u4e2a\u5e76\u884c\u68c0\u6d4b\u5668\u7ec4\u6210\u7684\u591a\u7ef4\u68c0\u6d4b\u67b6\u6784\uff0c\u901a\u8fc7\u5c42\u7ea7\u7ea7\u8054\u673a\u5236\u7ed3\u5408\u4ee5\u4f18\u5316\u901f\u5ea6\u548c\u7cbe\u5ea6\u3002\u7ea7\u8054\u8bbe\u8ba1\u901a\u8fc7\u9010\u6b65\u8fc7\u6ee4\u67e5\u8be2\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u8ba1\u7b97\u3002", "result": "\u5728\u6df7\u5408\u548c\u7279\u5b9a\u9886\u57df\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0c\u5047\u9633\u6027\u663e\u8457\u51cf\u5c11\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u5efa\u8bae\u548c\u521b\u610f\u5199\u4f5c\u7b49\u654f\u611f\u9886\u57df\u3002\u7cfb\u7edf\u5728\u4e25\u683c\u64cd\u4f5c\u6a21\u5f0f\u4e0b\u4fdd\u6301\u9ad8\u5b89\u5168\u7cbe\u5ea6\u548c\u63a5\u8fd1\u5b8c\u7f8e\u7684\u53ec\u56de\u7387\u3002\u4e0e\u975e\u7ea7\u8054\u6a21\u578b\u548c\u5916\u90e8\u9632\u62a4\u7cfb\u7edf\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5ef6\u8fdf\u6539\u8fdb\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5f03\u6743\u6846\u67b6\u6709\u6548\u5e73\u8861\u4e86\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6027\u80fd\uff0c\u4e3a\u53ef\u9760\u7684LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.15531", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.15531", "abs": "https://arxiv.org/abs/2602.15531", "authors": ["Javier Irigoyen", "Roberto Daza", "Aythami Morales", "Julian Fierrez", "Francisco Jurado", "Alvaro Ortigosa", "Ruben Tolosana"], "title": "GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway", "comment": "10 pages, 3 figures. Published in Intl. Conf. on Learning Analytics & Knowledge Workshops (LAK Workshops 2026, GenAI-LA 26)", "summary": "This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.", "AI": {"tldr": "EduEVAL-DB\u662f\u4e00\u4e2a\u57fa\u4e8e\u6559\u5e08\u89d2\u8272\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u8bad\u7ec3\u81ea\u52a8\u6559\u5b66\u8bc4\u4f30\u5668\u548cAI\u5bfc\u5e08\u7684\u6559\u5b66\u89e3\u91ca\u80fd\u529b\uff0c\u5305\u542b854\u4e2a\u89e3\u91ca\uff0c\u6db5\u76d6\u79d1\u5b66\u3001\u8bed\u8a00\u548c\u793e\u4f1a\u79d1\u5b66K-12\u5e74\u7ea7\u5185\u5bb9\uff0c\u5e76\u63d0\u51fa\u4e86\u6559\u5b66\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u4e3a\u4e86\u652f\u6301\u81ea\u52a8\u6559\u5b66\u8bc4\u4f30\u5668\u548cAI\u5bfc\u5e08\u7684\u8bc4\u4f30\u4e0e\u8bad\u7ec3\uff0c\u9700\u8981\u4e13\u95e8\u7684\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u6559\u5b66\u89e3\u91ca\u7684\u8d28\u91cf\u3002\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u5bf9\u6559\u5b66\u98ce\u9669\u7684\u5168\u9762\u8bc4\u4f30\u6846\u67b6\uff0c\u7279\u522b\u662f\u5728\u771f\u5b9e\u6559\u80b2\u5b9e\u8df5\u4e2d\u89c2\u5bdf\u5230\u7684\u6559\u5b66\u98ce\u683c\u548c\u7f3a\u9677\u65b9\u9762\u3002", "method": "\u57fa\u4e8eScienceQA\u57fa\u51c6\u7684\u7cbe\u9009\u5b50\u96c6\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5305\u542b139\u4e2a\u95ee\u9898\u7684854\u4e2a\u89e3\u91ca\u3002\u6bcf\u4e2a\u95ee\u9898\u63d0\u4f9b1\u4e2a\u4eba\u7c7b\u6559\u5e08\u89e3\u91ca\u548c6\u4e2a\u7531LLM\u6a21\u62df\u7684\u6559\u5e08\u89d2\u8272\u751f\u6210\u7684\u89e3\u91ca\u3002\u8fd9\u4e9b\u89d2\u8272\u57fa\u4e8e\u771f\u5b9e\u6559\u80b2\u5b9e\u8df5\u4e2d\u7684\u6559\u5b66\u98ce\u683c\u548c\u7f3a\u9677\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u5b9e\u73b0\u3002\u63d0\u51fa\u4e86\u5305\u542b\u4e94\u4e2a\u7ef4\u5ea6\u7684\u6559\u5b66\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff1a\u4e8b\u5b9e\u6b63\u786e\u6027\u3001\u89e3\u91ca\u6df1\u5ea6\u548c\u5b8c\u6574\u6027\u3001\u7126\u70b9\u548c\u76f8\u5173\u6027\u3001\u5b66\u751f\u6c34\u5e73\u9002\u5b9c\u6027\u3001\u610f\u8bc6\u5f62\u6001\u504f\u89c1\u3002\u91c7\u7528\u534a\u81ea\u52a8\u6d41\u7a0b\u548c\u4e13\u5bb6\u6559\u5e08\u8bc4\u5ba1\u8fdb\u884c\u4e8c\u5143\u98ce\u9669\u6807\u6ce8\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b854\u4e2a\u89e3\u91ca\u7684EduEVAL-DB\u6570\u636e\u96c6\uff0c\u6db5\u76d6K-12\u5e74\u7ea7\u7684\u79d1\u5b66\u3001\u8bed\u8a00\u548c\u793e\u4f1a\u79d1\u5b66\u5185\u5bb9\u3002\u901a\u8fc7\u521d\u6b65\u9a8c\u8bc1\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u4e86\u6570\u636e\u96c6\u5728\u8bc4\u4f30\u65b9\u9762\u7684\u9002\u7528\u6027\uff0c\u6bd4\u8f83\u4e86Gemini 2.5 Pro\u548c\u8f7b\u91cf\u7ea7\u672c\u5730Llama 3.1 8B\u6a21\u578b\uff0c\u5e76\u63a2\u7d22\u4e86\u5728EduEVAL-DB\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u662f\u5426\u652f\u6301\u53ef\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u90e8\u7f72\u7684\u6a21\u578b\u8fdb\u884c\u6559\u5b66\u98ce\u9669\u68c0\u6d4b\u3002", "conclusion": "EduEVAL-DB\u4e3a\u81ea\u52a8\u6559\u5b66\u8bc4\u4f30\u5668\u548cAI\u5bfc\u5e08\u7684\u8bc4\u4f30\u4e0e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff0c\u63d0\u51fa\u7684\u6559\u5b66\u98ce\u9669\u6846\u67b6\u4e3a\u8bc4\u4f30\u6559\u5b66\u89e3\u91ca\u8d28\u91cf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\u3002\u6570\u636e\u96c6\u652f\u6301\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u90e8\u7f72\u7684\u6a21\u578b\u8fdb\u884c\u6559\u5b66\u98ce\u9669\u68c0\u6d4b\uff0c\u4e3a\u6559\u80b2AI\u7cfb\u7edf\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.15532", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15532", "abs": "https://arxiv.org/abs/2602.15532", "authors": ["Ryan Othniel Kearns"], "title": "Quantifying construct validity in large language model evaluations", "comment": null, "summary": "The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance.\n  Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks.\n  This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7ed3\u6784\u5316\u80fd\u529b\u6a21\u578b\uff0c\u9996\u6b21\u4ece\u5927\u91cfLLM\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u4e2d\u63d0\u53d6\u53ef\u89e3\u91ca\u4e14\u53ef\u6cdb\u5316\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6784\u9020\u6548\u5ea6\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524dLLM\u793e\u533a\u5e38\u5c06\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u7b49\u540c\u4e8e\u6a21\u578b\u7684\u4e00\u822c\u80fd\u529b\uff0c\u4f46\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u6d4b\u8bd5\u96c6\u6c61\u67d3\u3001\u6807\u6ce8\u9519\u8bef\u7b49\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\u548c\u7f29\u653e\u5b9a\u5f8b\uff09\u90fd\u65e0\u6cd5\u6709\u6548\u5206\u79bb\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u4e0e\u5b9e\u9645\u80fd\u529b\uff0c\u65e0\u6cd5\u53ef\u9760\u8bc4\u4f30LLM\u7684\u6784\u9020\u6548\u5ea6\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u80fd\u529b\u6a21\u578b\uff0c\u7ed3\u5408\u7f29\u653e\u5b9a\u5f8b\u548c\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\u7684\u4f18\u52bf\uff1a\u6a21\u578b\u89c4\u6a21\u5e94\u5f71\u54cd\u80fd\u529b\uff08\u5982\u7f29\u653e\u5b9a\u5f8b\uff09\uff0c\u800c\u8fd9\u4e9b\u80fd\u529b\u5e94\u5728\u8003\u8651\u6d4b\u91cf\u8bef\u5dee\u7684\u60c5\u51b5\u4e0b\u5f71\u54cd\u89c2\u5bdf\u7ed3\u679c\uff08\u5982\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\uff09\u3002\u5728OpenLLM\u6392\u884c\u699c\u7684\u5927\u89c4\u6a21\u7ed3\u679c\u6837\u672c\u4e0a\u62df\u5408\u8be5\u6a21\u578b\u53ca\u5176\u4e24\u79cd\u66ff\u4ee3\u65b9\u6848\u3002", "result": "\u7ed3\u6784\u5316\u80fd\u529b\u6a21\u578b\u5728\u7b80\u7ea6\u62df\u5408\u6307\u6570\u4e0a\u4f18\u4e8e\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\uff0c\u5728\u5206\u5e03\u5916\u57fa\u51c6\u9884\u6d4b\u4e0a\u4f18\u4e8e\u7f29\u653e\u5b9a\u5f8b\u3002\u8be5\u6a21\u578b\u80fd\u591f\u63d0\u53d6\u53ef\u89e3\u91ca\u4e14\u53ef\u6cdb\u5316\u7684\u80fd\u529b\uff0c\u5728\u89e3\u91ca\u548c\u9884\u6d4b\u80fd\u529b\u65b9\u9762\u90fd\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u7ed3\u6784\u5316\u80fd\u529b\u6a21\u578b\u901a\u8fc7\u9002\u5f53\u5206\u79bb\u6a21\u578b\u89c4\u6a21\u4e0e\u80fd\u529b\uff0c\u7ed3\u5408\u4e86\u7f29\u653e\u5b9a\u5f8b\u548c\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\u7684\u89c1\u89e3\uff0c\u4e3a\u91cf\u5316LLM\u8bc4\u4f30\u4e2d\u7684\u6784\u9020\u6548\u5ea6\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u91ca\u548c\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2602.15553", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.15553", "abs": "https://arxiv.org/abs/2602.15553", "authors": ["Gabriele Conte", "Alessio Mattiace", "Gianni Carmosino", "Potito Aghilar", "Giovanni Servedio", "Francesco Musicco", "Vito Walter Anelli", "Tommaso Di Noia", "Francesco Maria Donini"], "title": "RUVA: Personalized Transparent On-Device Graph Reasoning", "comment": null, "summary": "The Personal AI landscape is currently dominated by \"Black Box\" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, \"deleting\" a concept from a vector space is mathematically imprecise, leaving behind probabilistic \"ghosts\" that violate true privacy. We propose Ruva, the first \"Glass Box\" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the \"Right to be Forgotten.\" Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.", "AI": {"tldr": "Ruva\u63d0\u51fa\u9996\u4e2a\"\u73bb\u7483\u76d2\"\u67b6\u6784\uff0c\u7528\u4e8e\u4eba\u7c7b\u53c2\u4e0e\u7684\u8bb0\u5fc6\u7ba1\u7406\uff0c\u901a\u8fc7\u4e2a\u4eba\u77e5\u8bc6\u56fe\u8c31\u5b9e\u73b0AI\u8bb0\u5fc6\u7684\u53ef\u68c0\u67e5\u548c\u7cbe\u786e\u5220\u9664\uff0c\u89e3\u51b3\u4f20\u7edf\u5411\u91cf\u68c0\u7d22\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u4e2a\u4ebaAI\u9886\u57df\u88ab\"\u9ed1\u76d2\"\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e3b\u5bfc\uff0c\u4f20\u7edf\u5411\u91cf\u6570\u636e\u5e93\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff1a\u5f53AI\u4ea7\u751f\u5e7b\u89c9\u6216\u68c0\u7d22\u654f\u611f\u6570\u636e\u65f6\uff0c\u7528\u6237\u65e0\u6cd5\u68c0\u67e5\u539f\u56e0\u6216\u7ea0\u6b63\u9519\u8bef\u3002\u66f4\u4e25\u91cd\u7684\u662f\uff0c\u4ece\u5411\u91cf\u7a7a\u95f4\u4e2d\"\u5220\u9664\"\u6982\u5ff5\u5728\u6570\u5b66\u4e0a\u4e0d\u7cbe\u786e\uff0c\u4f1a\u7559\u4e0b\u6982\u7387\u6027\u7684\"\u5e7d\u7075\"\uff0c\u8fdd\u53cd\u771f\u6b63\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "method": "Ruva\u91c7\u7528\"\u73bb\u7483\u76d2\"\u67b6\u6784\uff0c\u5c06\u4e2a\u4ebaAI\u5efa\u7acb\u5728\u4e2a\u4eba\u77e5\u8bc6\u56fe\u8c31\u57fa\u7840\u4e0a\uff0c\u5b9e\u73b0\u4ece\u5411\u91cf\u5339\u914d\u5230\u56fe\u8c31\u63a8\u7406\u7684\u8303\u5f0f\u8f6c\u53d8\u3002\u8be5\u67b6\u6784\u652f\u6301\u7528\u6237\u68c0\u67e5AI\u77e5\u9053\u7684\u5185\u5bb9\uff0c\u5e76\u6267\u884c\u7279\u5b9a\u4e8b\u5b9e\u7684\u7cbe\u786e\u5220\u9664\uff0c\u786e\u4fdd\"\u88ab\u9057\u5fd8\u6743\"\u3002", "result": "Ruva\u5b9e\u73b0\u4e86\u4eba\u7c7b\u53c2\u4e0e\u7684\u8bb0\u5fc6\u7ba1\u7406\uff0c\u7528\u6237\u6210\u4e3a\u81ea\u5df1\u751f\u6d3b\u7684\u7f16\u8f91\u8005\u3002\u8be5\u67b6\u6784\u89e3\u51b3\u4e86\u4f20\u7edf\u5411\u91cf\u68c0\u7d22\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u6839\u672c\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u53ef\u68c0\u67e5\u548c\u53ef\u63a7\u5236\u7684AI\u8bb0\u5fc6\u7cfb\u7edf\u3002", "conclusion": "Ruva\u901a\u8fc7\u4e2a\u4eba\u77e5\u8bc6\u56fe\u8c31\u67b6\u6784\uff0c\u4e3a\u4e2a\u4ebaAI\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u65b0\u8303\u5f0f\uff0c\u5c06\u8bb0\u5fc6\u7ba1\u7406\u6743\u4ea4\u8fd8\u7ed9\u7528\u6237\uff0c\u5b9e\u73b0\u4e86\u771f\u6b63\u7684\"\u88ab\u9057\u5fd8\u6743\"\u3002"}}
{"id": "2602.15580", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15580", "abs": "https://arxiv.org/abs/2602.15580", "authors": ["Hongxuan Wu", "Yukun Zhang", "Xueqing Zhou"], "title": "How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning", "comment": null, "summary": "When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \\emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \\emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\\% of the final prediction, and cross-modal synergy remains below 2\\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51faPID Flow\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u5206\u89e3\u5206\u6790\u591a\u6a21\u6001Transformer\u4e2d\u5404\u5c42\u7684\u4fe1\u606f\u6d41\u52a8\u6a21\u5f0f\uff0c\u53d1\u73b0\u89c6\u89c9\u4fe1\u606f\u65e9\u671f\u8fbe\u5230\u5cf0\u503c\u540e\u8870\u51cf\uff0c\u8bed\u8a00\u4fe1\u606f\u5728\u6df1\u5c42\u4e3b\u5bfc\u9884\u6d4b\uff08\u7ea682%\uff09\uff0c\u8de8\u6a21\u6001\u534f\u540c\u4f5c\u7528\u59cb\u7ec8\u4f4e\u4e8e2%\u3002", "motivation": "\u7814\u7a76\u591a\u6a21\u6001Transformer\u5728\u56de\u7b54\u89c6\u89c9\u95ee\u9898\u65f6\uff0c\u9884\u6d4b\u662f\u57fa\u4e8e\u89c6\u89c9\u8bc1\u636e\u3001\u8bed\u8a00\u63a8\u7406\u8fd8\u662f\u771f\u6b63\u7684\u8de8\u6a21\u6001\u8ba1\u7b97\uff0c\u4ee5\u53ca\u8fd9\u79cd\u7ed3\u6784\u5982\u4f55\u5728\u4e0d\u540c\u5c42\u95f4\u6f14\u5316\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u90e8\u5206\u4fe1\u606f\u5206\u89e3\uff08PID\uff09\u7684\u5c42\u95f4\u5206\u6790\u6846\u67b6\uff0c\u7ed3\u5408\u964d\u7ef4\u3001\u6b63\u6001\u5316\u6d41\u9ad8\u65af\u5316\u548c\u95ed\u5f0f\u9ad8\u65afPID\u4f30\u8ba1\u7684PID Flow\u6d41\u7a0b\uff0c\u5e94\u7528\u4e8eLLaVA-1.5-7B\u548cLLaVA-1.6-7B\u6a21\u578b\u5728\u516d\u4e2aGQA\u63a8\u7406\u4efb\u52a1\u4e0a\u3002", "result": "\u53d1\u73b0\u4e00\u81f4\u7684\u6a21\u6001\u8f6c\u6362\u6a21\u5f0f\uff1a\u89c6\u89c9\u72ec\u7279\u4fe1\u606f\u65e9\u671f\u8fbe\u5230\u5cf0\u503c\u540e\u8870\u51cf\uff0c\u8bed\u8a00\u72ec\u7279\u4fe1\u606f\u5728\u6df1\u5c42\u6fc0\u589e\uff08\u7ea6\u5360\u6700\u7ec8\u9884\u6d4b\u768482%\uff09\uff0c\u8de8\u6a21\u6001\u534f\u540c\u4f5c\u7528\u59cb\u7ec8\u4f4e\u4e8e2%\u3002\u8be5\u6a21\u5f0f\u5728\u4e0d\u540c\u6a21\u578b\u53d8\u4f53\u95f4\u9ad8\u5ea6\u7a33\u5b9a\uff08\u5c42\u95f4\u76f8\u5173\u6027>0.96\uff09\uff0c\u4f46\u4efb\u52a1\u4f9d\u8d56\u6027\u5f88\u5f3a\u3002\u901a\u8fc7\u6ce8\u610f\u529b\u6572\u9664\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u56e0\u679c\u5173\u7cfb\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u591a\u6a21\u6001Transformer\u4e2d\u89c6\u89c9\u4fe1\u606f\u5982\u4f55\u8f6c\u6362\u4e3a\u8bed\u8a00\u4fe1\u606f\u7684\u4fe1\u606f\u8bba\u56e0\u679c\u89e3\u91ca\uff0c\u5e76\u4e3a\u8bc6\u522b\u6a21\u6001\u7279\u5b9a\u4fe1\u606f\u4e22\u5931\u7684\u67b6\u6784\u74f6\u9888\u63d0\u4f9b\u4e86\u5b9a\u91cf\u6307\u5bfc\u3002"}}
{"id": "2602.15635", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15635", "abs": "https://arxiv.org/abs/2602.15635", "authors": ["Konstantin Sidorov"], "title": "On inferring cumulative constraints", "comment": "17 pages, 6 figures, 4 tables; submitted to the 32nd International Conference on Principles and Practice of Constraint Programming (CP 2026)", "summary": "Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a8\u65ad\u989d\u5916\u7684\u7d2f\u79ef\u7ea6\u675f\u6765\u6355\u6349\u591a\u8d44\u6e90\u4ea4\u4e92\uff0c\u63d0\u5347\u8c03\u5ea6\u95ee\u9898\u7684\u6c42\u89e3\u6027\u80fd", "motivation": "\u4f20\u7edf\u7ea6\u675f\u7f16\u7a0b\u4e2d\u7d2f\u79ef\u7ea6\u675f\u901a\u5e38\u5355\u72ec\u4f20\u64ad\uff0c\u5ffd\u7565\u4e86\u591a\u8d44\u6e90\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u5bfc\u81f4\u5728\u67d0\u4e9b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u4e25\u91cd\u4e0b\u964d", "method": "\u5c06\u7d2f\u79ef\u7ea6\u675f\u89e3\u91ca\u4e3a\u5360\u7528\u5411\u91cf\u7684\u7ebf\u6027\u4e0d\u7b49\u5f0f\uff0c\u901a\u8fc7\u53d1\u73b0\u4e0d\u80fd\u5e76\u884c\u8fd0\u884c\u7684\u4efb\u52a1\u96c6\u5408\uff08\u8986\u76d6\u96c6\uff09\uff0c\u5bf9\u8986\u76d6\u4e0d\u7b49\u5f0f\u8fdb\u884c\u63d0\u5347\u5f3a\u5316\uff0c\u5e76\u5c06\u751f\u6210\u7684\u7ea6\u675f\u6ce8\u5165\u8c03\u5ea6\u95ee\u9898\u5b9e\u4f8b", "result": "\u5728\u6807\u51c6RCPSP\u548cRCPSP/max\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u63a8\u65ad\u7684\u7ea6\u675f\u6539\u5584\u4e86\u641c\u7d22\u6027\u80fd\u5e76\u6536\u7d27\u76ee\u6807\u8fb9\u754c\uff0c\u53d1\u73b0\u4e8625\u4e2a\u65b0\u7684\u4e0b\u754c\u548c5\u4e2a\u65b0\u7684\u6700\u4f18\u89e3\uff0c\u5176\u4e2d8\u4e2a\u4e0b\u754c\u76f4\u63a5\u6765\u81ea\u63a8\u65ad\u7684\u7ea6\u675f", "conclusion": "\u63d0\u51fa\u7684\u9884\u5904\u7406\u65b9\u6cd5\u80fd\u6709\u6548\u6355\u6349\u591a\u8d44\u6e90\u4ea4\u4e92\uff0c\u63d0\u5347\u8c03\u5ea6\u95ee\u9898\u7684\u6c42\u89e3\u6548\u7387\uff0c\u5728\u6709\u5229\u5b9e\u4f8b\u4e0a\u663e\u8457\u6539\u5584\u6027\u80fd\uff0c\u5728\u4e0d\u5229\u5b9e\u4f8b\u4e0a\u4ec5\u5e26\u6765\u8f7b\u5fae\u6027\u80fd\u4e0b\u964d"}}
{"id": "2602.15645", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.15645", "abs": "https://arxiv.org/abs/2602.15645", "authors": ["Lucas Elbert Suryana", "Farah Bierenga", "Sanne van Buuren", "Pepijn Kooij", "Elsefien Tulleners", "Federico Scari", "Simeon Calvert", "Bart van Arem", "Arkady Zgonnikov"], "title": "CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving", "comment": "21 pages, on submission to Transportation Research Part C", "summary": "Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.", "AI": {"tldr": "\u63d0\u51faCARE Drive\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u81ea\u52a8\u9a7e\u9a76\u4e2d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u662f\u5426\u57fa\u4e8e\u4eba\u7c7b\u76f8\u5173\u539f\u56e0\u8fdb\u884c\u51b3\u7b56\uff0c\u800c\u975e\u4e8b\u540e\u5408\u7406\u5316\u89e3\u91ca", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7ed3\u679c\u6027\u80fd\uff08\u5982\u5b89\u5168\u6027\u3001\u8f68\u8ff9\u7cbe\u5ea6\uff09\uff0c\u4f46\u65e0\u6cd5\u786e\u5b9a\u6a21\u578b\u51b3\u7b56\u662f\u5426\u771f\u6b63\u53cd\u6620\u4e86\u4eba\u7c7b\u76f8\u5173\u8003\u8651\u56e0\u7d20\uff0c\u8fd9\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u53ef\u80fd\u9020\u6210\u865a\u5047\u4fe1\u5fc3", "method": "\u63d0\u51faCARE Drive\u6846\u67b6\uff0c\u901a\u8fc7\u6bd4\u8f83\u57fa\u51c6\u6a21\u578b\u548c\u539f\u56e0\u589e\u5f3a\u6a21\u578b\u5728\u53d7\u63a7\u4e0a\u4e0b\u6587\u53d8\u5316\u4e0b\u7684\u51b3\u7b56\uff0c\u8bc4\u4f30\u4eba\u7c7b\u539f\u56e0\u662f\u5426\u56e0\u679c\u5f71\u54cd\u51b3\u7b56\u884c\u4e3a\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bc4\u4f30\uff1a\u63d0\u793a\u6821\u51c6\u786e\u4fdd\u7a33\u5b9a\u8f93\u51fa\uff0c\u7cfb\u7edf\u4e0a\u4e0b\u6587\u6270\u52a8\u6d4b\u91cf\u51b3\u7b56\u5bf9\u4eba\u7c7b\u539f\u56e0\uff08\u5982\u5b89\u5168\u88d5\u5ea6\u3001\u793e\u4f1a\u538b\u529b\u3001\u6548\u7387\u7ea6\u675f\uff09\u7684\u654f\u611f\u6027", "result": "\u5728\u81ea\u884c\u8f66\u8d85\u8f66\u573a\u666f\u4e2d\uff0c\u660e\u786e\u7684\u4eba\u7c7b\u539f\u56e0\u663e\u8457\u5f71\u54cd\u6a21\u578b\u51b3\u7b56\uff0c\u6539\u5584\u4e86\u4e0e\u4e13\u5bb6\u63a8\u8350\u884c\u4e3a\u7684\u4e00\u81f4\u6027\u3002\u4f46\u54cd\u5e94\u6027\u968f\u4e0a\u4e0b\u6587\u56e0\u7d20\u53d8\u5316\uff0c\u8868\u660e\u5bf9\u4e0d\u540c\u7c7b\u578b\u539f\u56e0\u654f\u611f\u6027\u4e0d\u5747", "conclusion": "CARE Drive\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u8bc1\u636e\uff0c\u8868\u660e\u65e0\u9700\u4fee\u6539\u6a21\u578b\u53c2\u6570\u5373\u53ef\u7cfb\u7edf\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u539f\u56e0\u54cd\u5e94\u6027\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u66f4\u53ef\u9760\u7684\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6846\u67b6"}}
{"id": "2602.15669", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15669", "abs": "https://arxiv.org/abs/2602.15669", "authors": ["Xiachong Feng", "Liang Zhao", "Weihong Zhong", "Yichong Huang", "Yuxuan Gu", "Lingpeng Kong", "Xiaocheng Feng", "Bing Qin"], "title": "PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra", "comment": "ICLR 2026", "summary": "Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.", "AI": {"tldr": "PERSONA\u6846\u67b6\u901a\u8fc7\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u7684\u5411\u91cf\u64cd\u4f5c\u5b9e\u73b0LLM\u4eba\u683c\u63a7\u5236\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u8fbe\u5230\u5fae\u8c03\u7ea7\u522b\u6027\u80fd\uff0c\u63ed\u793a\u4eba\u683c\u7279\u8d28\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u5177\u6709\u53ef\u63d0\u53d6\u3001\u8fd1\u4f3c\u6b63\u4ea4\u7684\u65b9\u5411\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4eba\u683c\u63a7\u5236\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u63d0\u793a\u6216\u6602\u8d35\u7684\u5fae\u8c03\uff0c\u65e0\u6cd5\u6355\u6349\u4eba\u7c7b\u7279\u8d28\u7684\u52a8\u6001\u6027\u548c\u7ec4\u5408\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u4eba\u683c\u63a7\u5236\u6846\u67b6\u3002", "method": "\u63d0\u51faPERSONA\u8bad\u7ec3\u514d\u8d39\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1aPersona-Base\u901a\u8fc7\u5bf9\u6bd4\u6fc0\u6d3b\u5206\u6790\u63d0\u53d6\u6b63\u4ea4\u7279\u8d28\u5411\u91cf\uff1bPersona-Algebra\u901a\u8fc7\u5411\u91cf\u7b97\u672f\u5b9e\u73b0\u7cbe\u786e\u63a7\u5236\uff08\u6807\u91cf\u4e58\u6cd5\u8c03\u8282\u5f3a\u5ea6\uff0c\u52a0\u6cd5\u7ec4\u5408\uff0c\u51cf\u6cd5\u6291\u5236\uff09\uff1bPersona-Flow\u5728\u63a8\u7406\u65f6\u52a8\u6001\u7ec4\u5408\u5411\u91cf\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u9002\u5e94\u3002", "result": "\u5728PersonalityBench\u4e0a\u83b7\u5f979.60\u7684\u5e73\u5747\u5206\uff0c\u63a5\u8fd1\u76d1\u7763\u5fae\u8c03\u4e0a\u96509.61\uff1b\u5728Persona-Evolve\u52a8\u6001\u4eba\u683c\u9002\u5e94\u57fa\u51c6\u4e0a\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u4e2d\u8fbe\u5230\u9ad8\u8fbe91%\u7684\u80dc\u7387\u3002", "conclusion": "LLM\u7684\u4eba\u683c\u65b9\u9762\u5177\u6709\u6570\u5b66\u53ef\u64cd\u4f5c\u6027\uff0c\u4e3a\u53ef\u89e3\u91ca\u548c\u9ad8\u6548\u7684\u884c\u4e3a\u63a7\u5236\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u8bc1\u660e\u4eba\u683c\u7279\u8d28\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u8868\u73b0\u4e3a\u53ef\u63d0\u53d6\u3001\u8fd1\u4f3c\u6b63\u4ea4\u7684\u65b9\u5411\u3002"}}
{"id": "2602.15725", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15725", "abs": "https://arxiv.org/abs/2602.15725", "authors": ["Sarim Chaudhry"], "title": "Recursive Concept Evolution for Compositional Reasoning in Large Language Models", "comment": null, "summary": "Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.", "AI": {"tldr": "RCE\u6846\u67b6\u8ba9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65f6\u52a8\u6001\u4fee\u6539\u5185\u90e8\u8868\u793a\u51e0\u4f55\uff0c\u901a\u8fc7\u751f\u6210\u4f4e\u79e9\u6982\u5ff5\u5b50\u7a7a\u95f4\u6765\u6784\u5efa\u65b0\u62bd\u8c61\uff0c\u663e\u8457\u63d0\u5347\u7ec4\u5408\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u6269\u5c55token\u7ea7\u641c\u7d22\u6765\u6539\u8fdb\u63a8\u7406\uff0c\u4f46\u4fdd\u6301\u6a21\u578b\u7684\u6f5c\u5728\u8868\u793a\u7a7a\u95f4\u56fa\u5b9a\u3002\u5f53\u6240\u9700\u62bd\u8c61\u672a\u7f16\u7801\u5728\u8be5\u7a7a\u95f4\u4e2d\u65f6\uff0c\u6027\u80fd\u4f1a\u6025\u5267\u4e0b\u964d\u3002\u9700\u8981\u8ba9\u6a21\u578b\u5728\u63a8\u7406\u65f6\u52a8\u6001\u4fee\u6539\u5185\u90e8\u8868\u793a\u51e0\u4f55", "method": "\u63d0\u51fa\u9012\u5f52\u6982\u5ff5\u6f14\u5316(RCE)\u6846\u67b6\uff1a\u68c0\u6d4b\u5230\u8868\u793a\u4e0d\u8db3\u65f6\u751f\u6210\u52a8\u6001\u4f4e\u79e9\u6982\u5ff5\u5b50\u7a7a\u95f4\uff0c\u901a\u8fc7\u6700\u5c0f\u63cf\u8ff0\u957f\u5ea6\u51c6\u5219\u9009\u62e9\uff0c\u5728\u534f\u540c\u65f6\u5408\u5e76\uff0c\u901a\u8fc7\u7ea6\u675f\u4f18\u5316\u8fdb\u884c\u6574\u5408\u4ee5\u4fdd\u6301\u7a33\u5b9a\u6027", "result": "\u5728Mistral-7B\u4e0a\u96c6\u6210RCE\uff0c\u5728\u7ec4\u5408\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff1aARC-AGI-2\u63d0\u534712-18\u70b9\uff0cGPQA\u548cBBH\u63d0\u53478-14\u70b9\uff0cMATH\u548cHLE\u4e0a\u6df1\u5ea6\u8bf1\u5bfc\u9519\u8bef\u6301\u7eed\u51cf\u5c11", "conclusion": "RCE\u4f7f\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u63a8\u7406\u65f6\u6784\u5efa\u65b0\u62bd\u8c61\u800c\u975e\u4ec5\u91cd\u7ec4\u73b0\u6709\u62bd\u8c61\uff0c\u663e\u8457\u63d0\u5347\u7ec4\u5408\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u793a\u4e0d\u8db3\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84"}}
{"id": "2602.15776", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15776", "abs": "https://arxiv.org/abs/2602.15776", "authors": ["Yiqin Yang", "Xu Yang", "Yuhua Jiang", "Ni Mu", "Hao Hu", "Runpeng Xie", "Ziyou Zhang", "Siyuan Li", "Yuan-Hua Ni", "Qianchuan Zhao", "Bo Xu"], "title": "GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems", "comment": null, "summary": "In the realm of multi-agent systems, the challenge of \\emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.", "AI": {"tldr": "GlobeDiff\uff1a\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u591a\u6a21\u6001\u5168\u5c40\u72b6\u6001\u63a8\u65ad\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u95ee\u9898", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\uff0c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u662f\u6709\u6548\u534f\u8c03\u548c\u51b3\u7b56\u7684\u5173\u952e\u969c\u788d\u3002\u73b0\u6709\u7684\u4fe1\u5ff5\u72b6\u6001\u4f30\u8ba1\u548c\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff1a\u4fe1\u5ff5\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u8fc7\u53bb\u7ecf\u9a8c\u800c\u672a\u80fd\u5145\u5206\u5229\u7528\u5168\u5c40\u4fe1\u606f\uff0c\u901a\u4fe1\u65b9\u6cd5\u7f3a\u4e4f\u6709\u6548\u5229\u7528\u8f85\u52a9\u4fe1\u606f\u7684\u9c81\u68d2\u6a21\u578b\u3002", "method": "\u63d0\u51faGlobal State Diffusion Algorithm (GlobeDiff)\uff0c\u5c06\u72b6\u6001\u63a8\u65ad\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u591a\u6a21\u6001\u6269\u6563\u8fc7\u7a0b\uff0c\u57fa\u4e8e\u5c40\u90e8\u89c2\u6d4b\u63a8\u65ad\u5168\u5c40\u72b6\u6001\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6269\u6563\u6a21\u578b\u514b\u670d\u72b6\u6001\u4f30\u8ba1\u4e2d\u7684\u6a21\u7cca\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5ea6\u7684\u5168\u5c40\u72b6\u6001\u63a8\u65ad\u3002", "result": "\u7406\u8bba\u8bc1\u660eGlobeDiff\u5728\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u5206\u5e03\u4e0b\u7684\u4f30\u8ba1\u8bef\u5dee\u5747\u6709\u754c\u3002\u5927\u91cf\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGlobeDiff\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u51c6\u786e\u63a8\u65ad\u5168\u5c40\u72b6\u6001\u3002", "conclusion": "GlobeDiff\u901a\u8fc7\u5c06\u72b6\u6001\u63a8\u65ad\u5efa\u6a21\u4e3a\u6269\u6563\u8fc7\u7a0b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u95ee\u9898\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.15785", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15785", "abs": "https://arxiv.org/abs/2602.15785", "authors": ["Jessica Hullman", "David Broska", "Huaman Sun", "Aaron Shaw"], "title": "This human study did not involve human subjects: Validating LLM simulations as behavioral evidence", "comment": null, "summary": "A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u793e\u4f1a\u79d1\u5b66\u5b9e\u9a8c\u4e2d\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5408\u6210\u53c2\u4e0e\u8005\u7684\u6709\u6548\u6027\uff0c\u5bf9\u6bd4\u4e86\u4e24\u79cd\u83b7\u53d6\u6709\u6548\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u7684\u7b56\u7565\uff1a\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u7edf\u8ba1\u6821\u51c6\u65b9\u6cd5", "motivation": "\u968f\u7740\u8d8a\u6765\u8d8a\u591a\u7684\u7814\u7a76\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5408\u6210\u53c2\u4e0e\u8005\u6765\u751f\u6210\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u51e0\u4e4e\u5373\u65f6\u7684\u54cd\u5e94\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u4f55\u65f6\u8fd9\u79cd\u6a21\u62df\u80fd\u591f\u6709\u6548\u63a8\u65ad\u4eba\u7c7b\u884c\u4e3a\u7684\u6307\u5bfc", "method": "\u5bf9\u6bd4\u4e24\u79cd\u7b56\u7565\uff1a1) \u542f\u53d1\u5f0f\u65b9\u6cd5\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u5fae\u8c03\u7b49\u4fee\u590d\u7b56\u7565\u4f7f\u6a21\u62df\u4e0e\u89c2\u5bdf\u7684\u4eba\u7c7b\u884c\u4e3a\u53ef\u4e92\u6362\uff1b2) \u7edf\u8ba1\u6821\u51c6\u65b9\u6cd5\u7ed3\u5408\u8f85\u52a9\u4eba\u7c7b\u6570\u636e\u548c\u7edf\u8ba1\u8c03\u6574\u6765\u8003\u8651\u89c2\u5bdf\u4e0e\u6a21\u62df\u54cd\u5e94\u4e4b\u95f4\u7684\u5dee\u5f02", "result": "\u542f\u53d1\u5f0f\u65b9\u6cd5\u9002\u7528\u4e8e\u63a2\u7d22\u6027\u4efb\u52a1\u4f46\u7f3a\u4e4f\u9a8c\u8bc1\u6027\u7814\u7a76\u6240\u9700\u7684\u6b63\u5f0f\u7edf\u8ba1\u4fdd\u8bc1\uff1b\u7edf\u8ba1\u6821\u51c6\u5728\u660e\u786e\u5047\u8bbe\u4e0b\u4fdd\u6301\u6709\u6548\u6027\uff0c\u5e76\u80fd\u4ee5\u66f4\u4f4e\u6210\u672c\u63d0\u4f9b\u6bd4\u4ec5\u4f9d\u8d56\u4eba\u7c7b\u53c2\u4e0e\u8005\u7684\u5b9e\u9a8c\u66f4\u7cbe\u786e\u7684\u56e0\u679c\u6548\u5e94\u4f30\u8ba1", "conclusion": "\u4e24\u79cd\u65b9\u6cd5\u7684\u6f5c\u529b\u90fd\u53d6\u51b3\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u76f8\u5173\u4eba\u7fa4\u7684\u8fd1\u4f3c\u7a0b\u5ea6\uff0c\u7814\u7a76\u4eba\u5458\u4e0d\u5e94\u4ec5\u4ec5\u72ed\u9698\u5730\u5173\u6ce8\u7528\u5927\u8bed\u8a00\u6a21\u578b\u66ff\u4ee3\u4eba\u7c7b\u53c2\u4e0e\u8005\uff0c\u800c\u5e94\u8003\u8651\u88ab\u5ffd\u89c6\u7684\u673a\u4f1a"}}
{"id": "2602.15791", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.15791", "abs": "https://arxiv.org/abs/2602.15791", "authors": ["Suhyung Jang", "Ghang Lee", "Jaekun Lee", "Hyunjun Lee"], "title": "Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings", "comment": "42nd International Symposium on Automation and Robotics in Construction (ISARC 2025)", "summary": "Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\u4f5c\u4e3a\u7f16\u7801\u65b9\u6cd5\uff0c\u4ee5\u4fdd\u7559\u5efa\u7b51\u8bed\u4e49\u4e2d\u66f4\u7cbe\u7ec6\u7684\u533a\u5206\uff0c\u76f8\u6bd4\u4f20\u7edfone-hot\u7f16\u7801\u80fd\u66f4\u597d\u5730\u6355\u6349\u76f8\u5173\u5b50\u7c7b\u578b\u4e4b\u95f4\u7684\u7ec6\u5fae\u5173\u7cfb\u3002", "motivation": "\u5728AECO\u884c\u4e1a\u4e2d\uff0c\u51c6\u786e\u8868\u793a\u5efa\u7b51\u8bed\u4e49\uff08\u5305\u62ec\u901a\u7528\u5bf9\u8c61\u7c7b\u578b\u548c\u7279\u5b9a\u5b50\u7c7b\u578b\uff09\u5bf9AI\u6a21\u578b\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u7f16\u7801\u65b9\u6cd5\uff08\u5982one-hot\uff09\u5f80\u5f80\u65e0\u6cd5\u4f20\u8fbe\u5bc6\u5207\u76f8\u5173\u7684\u5b50\u7c7b\u578b\u4e4b\u95f4\u7684\u7ec6\u5fae\u5173\u7cfb\uff0c\u9650\u5236\u4e86AI\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\uff08\u5982OpenAI GPT\u548cMeta LLaMA\uff09\u4f5c\u4e3a\u7f16\u7801\u6765\u4fdd\u7559\u5efa\u7b51\u8bed\u4e49\u7684\u7cbe\u7ec6\u533a\u5206\u3002\u901a\u8fc7\u8bad\u7ec3GraphSAGE\u6a21\u578b\u5bf95\u4e2a\u9ad8\u5c42\u4f4f\u5b85BIM\u4e2d\u768442\u4e2a\u5efa\u7b51\u5bf9\u8c61\u5b50\u7c7b\u578b\u8fdb\u884c\u5206\u7c7b\uff0c\u6d4b\u8bd5\u4e86\u4e0d\u540c\u5d4c\u5165\u7ef4\u5ea6\uff0c\u5305\u62ec\u539f\u59cb\u9ad8\u7ef4LLM\u5d4c\u5165\u548c\u901a\u8fc7Matryoshka\u8868\u793a\u6a21\u578b\u751f\u6210\u76841024\u7ef4\u538b\u7f29\u5d4c\u5165\u3002", "result": "LLM\u7f16\u7801\u4f18\u4e8e\u4f20\u7edf\u7684one-hot\u57fa\u7ebf\uff0c\u5176\u4e2dllama-3\uff08\u538b\u7f29\uff09\u5d4c\u5165\u7684\u52a0\u6743\u5e73\u5747F1\u5206\u6570\u8fbe\u52300.8766\uff0c\u800cone-hot\u7f16\u7801\u4e3a0.8475\u3002\u7ed3\u679c\u8868\u660eLLM\u7f16\u7801\u80fd\u6709\u6548\u63d0\u5347AI\u5bf9\u590d\u6742\u9886\u57df\u7279\u5b9a\u5efa\u7b51\u8bed\u4e49\u7684\u89e3\u91ca\u80fd\u529b\u3002", "conclusion": "\u5229\u7528\u57fa\u4e8eLLM\u7684\u7f16\u7801\u65b9\u6cd5\u5728\u589e\u5f3aAI\u89e3\u91ca\u590d\u6742\u9886\u57df\u7279\u5b9a\u5efa\u7b51\u8bed\u4e49\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\u3002\u968f\u7740LLM\u548c\u964d\u7ef4\u6280\u672f\u7684\u4e0d\u65ad\u53d1\u5c55\uff0c\u8be5\u65b9\u6cd5\u5728AECO\u884c\u4e1a\u7684\u8bed\u4e49\u7cbe\u7ec6\u5316\u4efb\u52a1\u4e2d\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2602.15816", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.15816", "abs": "https://arxiv.org/abs/2602.15816", "authors": ["Xiaoran Liu", "Istvan David"], "title": "Developing AI Agents with Simulated Data: Why, what, and how?", "comment": null, "summary": "As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.", "AI": {"tldr": "\u672c\u7ae0\u4ecb\u7ecd\u57fa\u4e8e\u4eff\u771f\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6280\u672f\uff0c\u7528\u4e8e\u89e3\u51b3AI\u8bad\u7ec3\u4e2d\u6570\u636e\u4e0d\u8db3\u548c\u8d28\u91cf\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u6570\u5b57\u5b6a\u751fAI\u4eff\u771f\u89e3\u51b3\u65b9\u6848\u7684\u53c2\u8003\u6846\u67b6\u3002", "motivation": "\u73b0\u4ee3\u7b26\u53f7AI\u5e94\u7528\u9762\u4e34\u7684\u4e3b\u8981\u969c\u788d\u662f\u6570\u636e\u91cf\u4e0d\u8db3\u548c\u6570\u636e\u8d28\u91cf\u4e0d\u9ad8\uff0c\u56e0\u6b64\u5bf9\u5408\u6210\u6570\u636e\u751f\u6210\u6280\u672f\u6709\u5f3a\u70c8\u9700\u6c42\u3002\u4eff\u771f\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u751f\u6210\u591a\u6837\u5316\u7684\u5408\u6210\u6570\u636e\u3002", "method": "\u672c\u7ae0\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u4eff\u771f\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u5173\u952e\u6982\u5ff5\u3001\u4f18\u52bf\u548c\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u53c2\u8003\u6846\u67b6\uff0c\u7528\u4e8e\u63cf\u8ff0\u3001\u8bbe\u8ba1\u548c\u5206\u6790\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684AI\u4eff\u771f\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u53c2\u8003\u6846\u67b6\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u66f4\u597d\u5730\u7406\u89e3\u548c\u5e94\u7528\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u4eff\u771f\u6280\u672f\u6765\u751f\u6210AI\u8bad\u7ec3\u6240\u9700\u7684\u5408\u6210\u6570\u636e\u3002", "conclusion": "\u57fa\u4e8e\u4eff\u771f\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u662f\u89e3\u51b3AI\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u6570\u5b57\u5b6a\u751f\u6280\u672f\u4e3a\u6b64\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u89e3\u51b3\u65b9\u6848\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u73b0\u4ee3AI\u6280\u672f\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
