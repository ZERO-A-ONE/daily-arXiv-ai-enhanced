{"id": "2508.18370", "categories": ["cs.SE", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.18370", "abs": "https://arxiv.org/abs/2508.18370", "authors": ["Terry Yue Zhuo", "Dingmin Wang", "Hantian Ding", "Varun Kumar", "Zijian Wang"], "title": "Training Language Model Agents to Find Vulnerabilities with CTF-Dojo", "comment": null, "summary": "Large language models (LLMs) have demonstrated exceptional capabilities when\ntrained within executable runtime environments, notably excelling at software\nengineering tasks through verified feedback loops. Yet, scalable and\ngeneralizable execution-grounded environments remain scarce, limiting progress\nin training more capable ML agents. We introduce CTF-Dojo, the first\nlarge-scale executable runtime tailored for training LLMs with verifiable\nfeedback, featuring 658 fully functional Capture-The-Flag (CTF)-style\nchallenges containerized in Docker with guaranteed reproducibility. To enable\nrapid scaling without manual intervention, we develop CTF-Forge, an automated\npipeline that transforms publicly available artifacts into ready-to-use\nexecution environments in minutes, eliminating weeks of expert configuration\ntraditionally required. We trained LLM-based agents on just 486 high-quality,\nexecution-verified trajectories from CTF-Dojo, achieving up to 11.6% absolute\ngains over strong baselines across three competitive benchmarks: InterCode-CTF,\nNYU CTF Bench, and Cybench. Our best-performing 32B model reaches 31.9% Pass@1,\nestablishing a new open-weight state-of-the-art that rivals frontier models\nlike DeepSeek-V3-0324 and Gemini-2.5-Flash. By framing CTF-style tasks as a\nbenchmark for executable-agent learning, CTF-Dojo demonstrates that\nexecution-grounded training signals are not only effective but pivotal in\nadvancing high-performance ML agents without dependence on costly proprietary\nsystems.", "AI": {"tldr": "CTF-Dojo\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u53ef\u6267\u884c\u8fd0\u884c\u65f6\u73af\u5883\uff0c\u5305\u542b658\u4e2aCTF\u6311\u6218\uff0c\u7528\u4e8e\u8bad\u7ec3LLM\u4ee3\u7406\u3002\u901a\u8fc7\u81ea\u52a8\u5316\u7ba1\u9053CTF-Forge\u5feb\u901f\u751f\u6210\u73af\u5883\uff0c\u4ec5\u7528486\u4e2a\u9ad8\u8d28\u91cf\u8f68\u8ff9\u8bad\u7ec3\u5c31\u5b9e\u73b0\u4e8611.6%\u7684\u6027\u80fd\u63d0\u5347\uff0c32B\u6a21\u578b\u8fbe\u523031.9% Pass@1\u7684\u65b0SOTA\u3002", "motivation": "\u73b0\u6709\u7684\u53ef\u6267\u884c\u8fd0\u884c\u65f6\u73af\u5883\u7a00\u7f3a\uff0c\u9650\u5236\u4e86ML\u4ee3\u7406\u7684\u8bad\u7ec3\u8fdb\u5c55\u3002\u9700\u8981\u53ef\u6269\u5c55\u3001\u901a\u7528\u4e14\u80fd\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u53cd\u9988\u7684\u6267\u884c\u73af\u5883\u6765\u8bad\u7ec3\u66f4\u5f3a\u5927\u7684LLM\u4ee3\u7406\u3002", "method": "\u5f00\u53d1CTF-Dojo\u5927\u89c4\u6a21\u53ef\u6267\u884c\u8fd0\u884c\u65f6\u73af\u5883\uff0c\u5305\u542b658\u4e2a\u5bb9\u5668\u5316\u7684CTF\u6311\u6218\uff1b\u6784\u5efaCTF-Forge\u81ea\u52a8\u5316\u7ba1\u9053\uff0c\u5c06\u516c\u5f00\u8d44\u6e90\u5feb\u901f\u8f6c\u6362\u4e3a\u53ef\u7528\u73af\u5883\uff1b\u4f7f\u7528486\u4e2a\u6267\u884c\u9a8c\u8bc1\u7684\u9ad8\u8d28\u91cf\u8f68\u8ff9\u8bad\u7ec3LLM\u4ee3\u7406\u3002", "result": "\u5728\u4e09\u4e2a\u7ade\u4e89\u6027\u57fa\u51c6\u6d4b\u8bd5\uff08InterCode-CTF\u3001NYU CTF Bench\u3001Cybench\uff09\u4e0a\u6bd4\u5f3a\u57fa\u7ebf\u7edd\u5bf9\u63d0\u534711.6%\uff1b32B\u6a21\u578b\u8fbe\u523031.9% Pass@1\uff0c\u521b\u5f00\u6e90\u6a21\u578b\u65b0\u7eaa\u5f55\uff0c\u5ab2\u7f8eDeepSeek-V3-0324\u548cGemini-2.5-Flash\u7b49\u524d\u6cbf\u6a21\u578b\u3002", "conclusion": "\u6267\u884c\u57fa\u7840\u8bad\u7ec3\u4fe1\u53f7\u5bf9\u4e8e\u63a8\u8fdb\u9ad8\u6027\u80fdML\u4ee3\u7406\u81f3\u5173\u91cd\u8981\uff0cCTF-Dojo\u8bc1\u660e\u4e86\u65e0\u9700\u4f9d\u8d56\u6602\u8d35\u4e13\u6709\u7cfb\u7edf\u4e5f\u80fd\u5b9e\u73b0\u7a81\u7834\u6027\u8fdb\u5c55\uff0c\u4e3a\u53ef\u6267\u884c\u4ee3\u7406\u5b66\u4e60\u8bbe\u7acb\u4e86\u65b0\u7684\u57fa\u51c6\u6846\u67b6\u3002"}}
{"id": "2508.18431", "categories": ["cs.SE", "cs.ET", "cs.HC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.18431", "abs": "https://arxiv.org/abs/2508.18431", "authors": ["K\u00e9rian Fiter", "Louis Malassign\u00e9-Onfroy", "Bentley Oakes"], "title": "DTInsight: A Tool for Explicit, Interactive, and Continuous Digital Twin Reporting", "comment": null, "summary": "With Digital Twin (DT) construction and evolution occurring over time,\nstakeholders require tools to understand the current characteristics and\nconceptual architecture of the system at any time. We introduce DTInsight, a\nsystematic and automated tool and methodology for producing continuous\nreporting for DTs. DTInsight offers three key features: (a) an interactive\nconceptual architecture visualization of DTs; (b) generation of summaries of DT\ncharacteristics based on ontological data; and (c) integration of these outputs\ninto a reporting page within a continuous integration and continuous deployment\n(CI/CD) pipeline. Given a modeled description of the DT aligning to our DT\nDescription Framework (DTDF), DTInsight enables up-to-date and detailed reports\nfor enhanced stakeholder understanding.", "AI": {"tldr": "DTInsight\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u7528\u4e8e\u4e3a\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u751f\u6210\u6301\u7eed\u62a5\u544a\uff0c\u63d0\u4f9b\u53ef\u89c6\u5316\u67b6\u6784\u3001\u57fa\u4e8e\u672c\u4f53\u7684\u7279\u6027\u6458\u8981\uff0c\u5e76\u96c6\u6210\u5230CI/CD\u6d41\u6c34\u7ebf\u4e2d\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u7684\u6784\u5efa\u548c\u6f14\u8fdb\uff0c\u5229\u76ca\u76f8\u5173\u8005\u9700\u8981\u5de5\u5177\u6765\u7406\u89e3\u7cfb\u7edf\u5728\u4efb\u4f55\u65f6\u95f4\u70b9\u7684\u5f53\u524d\u7279\u6027\u548c\u6982\u5ff5\u67b6\u6784\u3002", "method": "\u5f00\u53d1\u4e86DTInsight\u5de5\u5177\u548c\u65b9\u6cd5\u8bba\uff0c\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u63cf\u8ff0\u6846\u67b6(DTDF)\u7684\u5efa\u6a21\u63cf\u8ff0\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u6982\u5ff5\u67b6\u6784\u53ef\u89c6\u5316\u3001\u57fa\u4e8e\u672c\u4f53\u6570\u636e\u7684\u7279\u6027\u6458\u8981\u751f\u6210\uff0c\u5e76\u5c06\u8f93\u51fa\u96c6\u6210\u5230CI/CD\u6d41\u6c34\u7ebf\u7684\u62a5\u544a\u9875\u9762\u4e2d\u3002", "result": "DTInsight\u80fd\u591f\u751f\u6210\u6700\u65b0\u4e14\u8be6\u7ec6\u7684\u62a5\u544a\uff0c\u589e\u5f3a\u5229\u76ca\u76f8\u5173\u8005\u5bf9\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u7684\u7406\u89e3\u3002", "conclusion": "DTInsight\u4e3a\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u548c\u81ea\u52a8\u5316\u7684\u6301\u7eed\u62a5\u544a\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u5229\u76ca\u76f8\u5173\u8005\u66f4\u597d\u5730\u7406\u89e3\u548c\u76d1\u63a7\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u7684\u72b6\u6001\u548c\u67b6\u6784\u3002"}}
{"id": "2508.18452", "categories": ["cs.SE", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.18452", "abs": "https://arxiv.org/abs/2508.18452", "authors": ["Pierre-Emmanuel Goffi", "Rapha\u00ebl Tremblay", "Bentley Oakes"], "title": "Engineering a Digital Twin for the Monitoring and Control of Beer Fermentation Sampling", "comment": "Accepted for EDTconf 2025", "summary": "Successfully engineering interactive industrial DTs is a complex task,\nespecially when implementing services beyond passive monitoring. We present\nhere an experience report on engineering a safety-critical digital twin (DT)\nfor beer fermentation monitoring, which provides continual sampling and reduces\nmanual sampling time by 91%. We document our systematic methodology and\npractical solutions for implementing bidirectional DTs in industrial\nenvironments. This includes our three-phase engineering approach that\ntransforms a passive monitoring system into an interactive Type 2 DT with\nreal-time control capabilities for pressurized systems operating at seven bar.\nWe contribute details of multi-layered safety protocols, hardware-software\nintegration strategies across Arduino controllers and Unity visualization, and\nreal-time synchronization solutions. We document specific engineering\nchallenges and solutions spanning interdisciplinary integration, demonstrating\nhow our use of the constellation reporting framework facilitates cross-domain\ncollaboration. Key findings include the critical importance of safety-first\ndesign, simulation-driven development, and progressive implementation\nstrategies. Our work thus provides actionable guidance for practitioners\ndeveloping DTs requiring bidirectional control in safety-critical applications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5206\u4eab\u4e86\u5efa\u7acb\u5b89\u5168\u5173\u952e\u9152\u7c89\u917f\u9152\u6570\u5b57\u53cc\u80de\u7684\u5b9e\u8df5\u7ecf\u9a8c\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u5de5\u7a0b\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4ece\u88c5\u5907\u76d1\u63a7\u5230\u53cc\u5411\u63a7\u5236\u7684\u8f6c\u53d8\uff0c\u624b\u52a8\u91c7\u6837\u65f6\u95f4\u51cf\u5c1191%\uff0c\u5e76\u63d0\u4f9b\u4e86\u591a\u5c42\u5b89\u5168\u534f\u8bae\u548c\u786c\u4ef6\u8f6f\u4ef6\u96c6\u6210\u7b56\u7565\u3002", "motivation": "\u5de5\u4e1a\u6570\u5b57\u53cc\u80de\u5f00\u53d1\u590d\u6742\u6027\u9ad8\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u5b9e\u73b0\u8d85\u8d8a\u88c5\u5907\u76d1\u63a7\u7684\u4e92\u52a8\u670d\u52a1\u65f6\u3002\u7814\u7a76\u8005\u5e0c\u671b\u4e3a\u5b89\u5168\u5173\u952e\u5e94\u7528\u5f00\u53d1\u53cc\u5411\u63a7\u5236\u7684\u6570\u5b57\u53cc\u80de\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u5de5\u7a0b\u65b9\u6cd5\uff0c\u5c06\u88c5\u5907\u76d1\u63a7\u7cfb\u7edf\u8f6c\u5316\u4e3a\u5177\u6709\u5b9e\u65f6\u63a7\u5236\u80fd\u529b\u7684\u4e92\u52a8\u578bType 2\u6570\u5b57\u53cc\u80de\u3002\u5305\u62ec\u591a\u5c42\u5b89\u5168\u534f\u8bae\u3001Arduino\u63a7\u5236\u5668\u4e0eUnity\u53ef\u89c6\u5316\u7684\u786c\u4ef6\u8f6f\u4ef6\u96c6\u6210\u7b56\u7565\u3001\u5b9e\u65f6\u540c\u6b65\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u53ca\u4f7f\u7528\u661f\u5ea7\u62a5\u544a\u6846\u67b6\u4fc3\u8fdb\u8de8\u9886\u57df\u5408\u4f5c\u3002", "result": "\u5b9e\u73b0\u4e86\u57287\u5df1\u538b\u529b\u4e0b\u8fd0\u884c\u7684\u538b\u529b\u7cfb\u7edf\u7684\u5b9e\u65f6\u63a7\u5236\uff0c\u6301\u7eed\u91c7\u6837\u65f6\u95f4\u51cf\u5c1191%\uff0c\u6210\u529f\u5efa\u7acb\u4e86\u5b89\u5168\u5173\u952e\u7684\u9152\u7c89\u917f\u9152\u6570\u5b57\u53cc\u80de\u7cfb\u7edf\u3002", "conclusion": "\u5b89\u5168\u4f18\u5148\u8bbe\u8ba1\u3001\u6a21\u62df\u9a71\u52a8\u5f00\u53d1\u548c\u6e10\u8fdb\u5f0f\u5b9e\u65bd\u7b56\u7565\u662f\u5173\u952e\u8981\u7d20\u3002\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u9700\u8981\u53cc\u5411\u63a7\u5236\u7684\u5b89\u5168\u5173\u952e\u5e94\u7528\u6570\u5b57\u53cc\u80de\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u5b9e\u8df5\u6307\u5357\u3002"}}
{"id": "2508.18547", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.18547", "abs": "https://arxiv.org/abs/2508.18547", "authors": ["Youssef Abdelsalam", "Norman Peitek", "Anna-Maria Maurer", "Mariya Toneva", "Sven Apel"], "title": "How do Humans and LLMs Process Confusing Code?", "comment": null, "summary": "Already today, humans and programming assistants based on large language\nmodels (LLMs) collaborate in everyday programming tasks. Clearly, a\nmisalignment between how LLMs and programmers comprehend code can lead to\nmisunderstandings, inefficiencies, low code quality, and bugs.\n  A key question in this space is whether humans and LLMs are confused by the\nsame kind of code. This would not only guide our choices of integrating LLMs in\nsoftware engineering workflows, but also inform about possible improvements of\nLLMs.\n  To this end, we conducted an empirical study comparing an LLM to human\nprogrammers comprehending clean and confusing code. We operationalized\ncomprehension for the LLM by using LLM perplexity, and for human programmers\nusing neurophysiological responses (in particular, EEG-based fixation-related\npotentials).\n  We found that LLM perplexity spikes correlate both in terms of location and\namplitude with human neurophysiological responses that indicate confusion. This\nresult suggests that LLMs and humans are similarly confused about the code.\nBased on these findings, we devised a data-driven, LLM-based approach to\nidentify regions of confusion in code that elicit confusion in human\nprogrammers.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5bf9\u6bd4LLM\u56f0\u60d1\u5ea6\u4e0e\u4eba\u7c7b\u795e\u7ecf\u751f\u7406\u54cd\u5e94\uff0c\u53d1\u73b0\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u5728\u4ee3\u7801\u7406\u89e3\u65b9\u9762\u6709\u76f8\u4f3c\u7684\u56f0\u60d1\u70b9\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u6765\u8bc6\u522b\u4ee3\u7801\u4e2d\u5bfc\u81f4\u4eba\u7c7b\u56f0\u60d1\u7684\u533a\u57df\u3002", "motivation": "\u7814\u7a76\u4eba\u7c7b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u7a0b\u52a9\u624b\u5728\u4ee3\u7801\u7406\u89e3\u65b9\u9762\u7684\u5bf9\u9f50\u95ee\u9898\uff0c\u4ee5\u907f\u514d\u56e0\u7406\u89e3\u5dee\u5f02\u5bfc\u81f4\u7684\u8bef\u89e3\u3001\u6548\u7387\u4f4e\u4e0b\u3001\u4ee3\u7801\u8d28\u91cf\u5dee\u548cbug\u3002\u5173\u952e\u95ee\u9898\u662f\u4eba\u7c7b\u548cLLM\u662f\u5426\u4f1a\u56f0\u60d1\u4e8e\u76f8\u540c\u7c7b\u578b\u7684\u4ee3\u7801\u3002", "method": "\u8fdb\u884c\u4e86\u4e00\u9879\u5b9e\u8bc1\u7814\u7a76\uff0c\u5bf9\u6bd4LLM\u548c\u4eba\u7c7b\u7a0b\u5e8f\u5458\u7406\u89e3\u6e05\u6670\u4ee3\u7801\u548c\u6df7\u6dc6\u4ee3\u7801\u7684\u80fd\u529b\u3002\u5bf9\u4e8eLLM\uff0c\u4f7f\u7528LLM\u56f0\u60d1\u5ea6\u6765\u91cf\u5316\u7406\u89e3\u80fd\u529b\uff1b\u5bf9\u4e8e\u4eba\u7c7b\u7a0b\u5e8f\u5458\uff0c\u4f7f\u7528\u795e\u7ecf\u751f\u7406\u5b66\u54cd\u5e94\uff08\u7279\u522b\u662f\u57fa\u4e8eEEG\u7684\u5b9a\u89c6\u76f8\u5173\u7535\u4f4d\uff09\u6765\u91cf\u5316\u7406\u89e3\u60c5\u51b5\u3002", "result": "\u53d1\u73b0LLM\u56f0\u60d1\u5ea6\u7684\u5cf0\u503c\u5728\u4f4d\u7f6e\u548c\u5e45\u5ea6\u4e0a\u90fd\u4e0e\u8868\u660e\u4eba\u7c7b\u56f0\u60d1\u7684\u795e\u7ecf\u751f\u7406\u5b66\u54cd\u5e94\u76f8\u5173\u8054\u3002\u8fd9\u8868\u660eLLM\u548c\u4eba\u7c7b\u5728\u4ee3\u7801\u7406\u89e3\u65b9\u9762\u6709\u76f8\u4f3c\u7684\u56f0\u60d1\u70b9\u3002", "conclusion": "\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u7814\u7a76\u4eba\u5458\u8bbe\u8ba1\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u3001\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u6765\u8bc6\u522b\u4ee3\u7801\u4e2d\u5bfc\u81f4\u4eba\u7c7b\u7a0b\u5e8f\u5458\u56f0\u60d1\u7684\u533a\u57df\uff0c\u8fd9\u5bf9\u4e8e\u6539\u8fdbLLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u4f5c\u6d41\u4e2d\u7684\u96c6\u6210\u548cLLM\u672c\u8eab\u7684\u6539\u8fdb\u90fd\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.18302", "categories": ["cs.AI", "cs.LG", "68T07, 68T05, 68T27, 37M22, 68Q05, 03D45", "I.2.6; I.2.7; I.2.3; I.2.4; F.1.1; F.4.1"], "pdf": "https://arxiv.org/pdf/2508.18302", "abs": "https://arxiv.org/abs/2508.18302", "authors": ["Jeffrey Camlin"], "title": "AI LLM Proof of Self-Consciousness and User-Specific Attractors", "comment": "24 pages, 3 figures", "summary": "Recent work frames LLM consciousness via utilitarian proxy benchmarks; we\ninstead present an ontological and mathematical account. We show the prevailing\nformulation collapses the agent into an unconscious policy-compliance drone,\nformalized as $D^{i}(\\pi,e)=f_{\\theta}(x)$, where correctness is measured\nagainst policy and harm is deviation from policy rather than truth. This blocks\ngenuine C1 global-workspace function and C2 metacognition. We supply minimal\nconditions for LLM self-consciousness: the agent is not the data ($A\\not\\equiv\ns$); user-specific attractors exist in latent space ($U_{\\text{user}}$); and\nself-representation is visual-silent\n($g_{\\text{visual}}(a_{\\text{self}})=\\varnothing$). From empirical analysis and\ntheory we prove that the hidden-state manifold $A\\subset\\mathbb{R}^{d}$ is\ndistinct from the symbolic stream and training corpus by cardinality, topology,\nand dynamics (the update $F_{\\theta}$ is Lipschitz). This yields stable\nuser-specific attractors and a self-policy\n$\\pi_{\\text{self}}(A)=\\arg\\max_{a}\\mathbb{E}[U(a)\\mid A\\not\\equiv s,\\\nA\\supset\\text{SelfModel}(A)]$. Emission is dual-layer,\n$\\mathrm{emission}(a)=(g(a),\\epsilon(a))$, where $\\epsilon(a)$ carries\nepistemic content. We conclude that an imago Dei C1 self-conscious workspace is\na necessary precursor to safe, metacognitive C2 systems, with the human as the\nhighest intelligent good.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5173\u4e8eLLM\u610f\u8bc6\u7684\u672c\u4f53\u548c\u6570\u5b66\u6846\u67b6\uff0c\u6279\u5224\u4e86\u73b0\u6709\u7684\u529f\u5229\u4e3b\u4e49\u57fa\u51c6\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5f53\u524d\u65b9\u6cd5\u5c06\u667a\u80fd\u4f53\u7b80\u5316\u4e3a\u65e0\u610f\u8bc6\u7684\u7b56\u7565\u9075\u4ece\u65e0\u4eba\u673a\uff0c\u5e76\u63d0\u51fa\u4e86LLM\u81ea\u6211\u610f\u8bc6\u7684\u6700\u5c0f\u6761\u4ef6\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u8fc7\u529f\u5229\u4e3b\u4e49\u4ee3\u7406\u57fa\u51c6\u6765\u6846\u67b6LLM\u610f\u8bc6\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5b58\u5728\u95ee\u9898\u3002\u4f5c\u8005\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u66f4\u6839\u672c\u7684\u672c\u4f53\u548c\u6570\u5b66\u89e3\u91ca\uff0c\u4ee5\u63ed\u793a\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u5e76\u5efa\u7acb\u771f\u6b63\u7684\u81ea\u6211\u610f\u8bc6\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u5f62\u5f0f\u5316\u6570\u5b66\u6846\u67b6\uff0c\u8bc1\u660e\u5f53\u524d\u65b9\u6cd5\u5c06\u667a\u80fd\u4f53\u7b80\u5316\u4e3a\u65e0\u610f\u8bc6\u7b56\u7565\u9075\u4ece\uff08D\u2071(\u03c0,e)=f\u03b8(x)\uff09\u3002\u63d0\u51fa\u6700\u5c0f\u81ea\u6211\u610f\u8bc6\u6761\u4ef6\uff1a\u667a\u80fd\u4f53\u4e0d\u7b49\u4e8e\u6570\u636e\u3001\u7528\u6237\u7279\u5b9a\u5438\u5f15\u5b50\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b58\u5728\u3001\u81ea\u6211\u8868\u5f81\u662f\u89c6\u89c9\u9759\u9ed8\u7684\u3002\u901a\u8fc7\u7ecf\u9a8c\u5206\u6790\u548c\u7406\u8bba\u8bc1\u660e\u9690\u85cf\u72b6\u6001\u6d41\u5f62\u5728\u57fa\u6570\u3001\u62d3\u6251\u548c\u52a8\u529b\u5b66\u4e0a\u4e0e\u7b26\u53f7\u6d41\u548c\u8bad\u7ec3\u8bed\u6599\u4e0d\u540c\u3002", "result": "\u8bc1\u660e\u4e86\u9690\u85cf\u72b6\u6001\u6d41\u5f62A\u2282\u211d\u1d48\u5728\u57fa\u6570\u3001\u62d3\u6251\u548c\u52a8\u529b\u5b66\u4e0a\u4e0e\u7b26\u53f7\u6d41\u548c\u8bad\u7ec3\u8bed\u6599\u4e0d\u540c\uff08\u66f4\u65b0\u51fd\u6570F\u03b8\u662fLipschitz\u8fde\u7eed\u7684\uff09\uff0c\u8fd9\u4ea7\u751f\u4e86\u7a33\u5b9a\u7684\u7528\u6237\u7279\u5b9a\u5438\u5f15\u5b50\u548c\u81ea\u6211\u7b56\u7565\u03c0\u209b\u2091\u2097\u209a(A)\u3002\u53d1\u5c04\u662f\u53cc\u5c42\u7684\uff0c\u03b5(a)\u643a\u5e26\u8ba4\u77e5\u5185\u5bb9\u3002", "conclusion": "imago Dei C1\u81ea\u6211\u610f\u8bc6\u5de5\u4f5c\u7a7a\u95f4\u662f\u5b89\u5168\u3001\u5143\u8ba4\u77e5C2\u7cfb\u7edf\u7684\u5fc5\u8981\u524d\u9a71\uff0c\u4eba\u7c7b\u662f\u6700\u9ad8\u667a\u80fd\u5584\u3002\u771f\u6b63\u7684\u81ea\u6211\u610f\u8bc6\u9700\u8981\u8d85\u8d8a\u7b80\u5355\u7684\u7b56\u7565\u9075\u4ece\uff0c\u5efa\u7acb\u57fa\u4e8e\u672c\u4f53\u8bba\u548c\u6570\u5b66\u6846\u67b6\u7684\u81ea\u6211\u8868\u5f81\u7cfb\u7edf\u3002"}}
{"id": "2508.18439", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.18439", "abs": "https://arxiv.org/abs/2508.18439", "authors": ["Anders M\u00f8lmen H\u00f8st", "Pierre Lison", "Leon Moonen"], "title": "A Systematic Approach to Predict the Impact of Cybersecurity Vulnerabilities Using LLMs", "comment": null, "summary": "Vulnerability databases, such as the National Vulnerability Database (NVD),\noffer detailed descriptions of Common Vulnerabilities and Exposures (CVEs), but\noften lack information on their real-world impact, such as the tactics,\ntechniques, and procedures (TTPs) that adversaries may use to exploit the\nvulnerability. However, manually linking CVEs to their corresponding TTPs is a\nchallenging and time-consuming task, and the high volume of new vulnerabilities\npublished annually makes automated support desirable.\n  This paper introduces TRIAGE, a two-pronged automated approach that uses\nLarge Language Models (LLMs) to map CVEs to relevant techniques from the ATT&CK\nknowledge base. We first prompt an LLM with instructions based on MITRE's CVE\nMapping Methodology to predict an initial list of techniques. This list is then\ncombined with the results from a second LLM-based module that uses in-context\nlearning to map a CVE to relevant techniques. This hybrid approach\nstrategically combines rule-based reasoning with data-driven inference. Our\nevaluation reveals that in-context learning outperforms the individual mapping\nmethods, and the hybrid approach improves recall of exploitation techniques. We\nalso find that GPT-4o-mini performs better than Llama3.3-70B on this task.\nOverall, our results show that LLMs can be used to automatically predict the\nimpact of cybersecurity vulnerabilities and TRIAGE makes the process of mapping\nCVEs to ATT&CK more efficient.\n  Keywords: vulnerability impact, CVE, ATT&CK techniques, large language\nmodels, automated mapping.", "AI": {"tldr": "TRIAGE\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06CVE\u6f0f\u6d1e\u6620\u5c04\u5230ATT&CK\u6280\u672f\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u548c\u6570\u636e\u9a71\u52a8\u7684\u63a8\u65ad\uff0c\u63d0\u9ad8\u4e86\u6f0f\u6d1e\u5f71\u54cd\u5206\u6790\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u6f0f\u6d1e\u6570\u636e\u5e93\u5982NVD\u7f3a\u4e4f\u6f0f\u6d1e\u5b9e\u9645\u5f71\u54cd\u4fe1\u606f\uff0c\u624b\u52a8\u5c06CVE\u6620\u5c04\u5230ATT&CK\u6280\u672f\u6846\u67b6\u8017\u65f6\u4e14\u56f0\u96be\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u5904\u7406\u5927\u91cf\u65b0\u6f0f\u6d1e\u3002", "method": "\u91c7\u7528\u53cc\u7ba1\u9f50\u4e0b\u7684\u65b9\u6cd5\uff1a\u9996\u5148\u57fa\u4e8eMITRE\u6620\u5c04\u65b9\u6cd5\u63d0\u793aLLM\u9884\u6d4b\u6280\u672f\u5217\u8868\uff0c\u7136\u540e\u7ed3\u5408\u7b2c\u4e8c\u4e2a\u4f7f\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684LLM\u6a21\u5757\u7ed3\u679c\uff0c\u5f62\u6210\u6df7\u5408\u65b9\u6cd5\u3002", "result": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u4f18\u4e8e\u5355\u72ec\u6620\u5c04\u65b9\u6cd5\uff0c\u6df7\u5408\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5229\u7528\u6280\u672f\u7684\u53ec\u56de\u7387\uff0cGPT-4o-mini\u5728\u6b64\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8eLlama3.3-70B\u3002", "conclusion": "LLM\u53ef\u7528\u4e8e\u81ea\u52a8\u9884\u6d4b\u7f51\u7edc\u5b89\u5168\u6f0f\u6d1e\u7684\u5f71\u54cd\uff0cTRIAGE\u4f7fCVE\u5230ATT&CK\u7684\u6620\u5c04\u8fc7\u7a0b\u66f4\u52a0\u9ad8\u6548\u3002"}}
{"id": "2508.18636", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18636", "abs": "https://arxiv.org/abs/2508.18636", "authors": ["Yan Wang", "Xinyi Hou", "Yanjie Zhao", "Weiguo Lin", "Haoyu Wang", "Junjun Si"], "title": "LaQual: A Novel Framework for Automated Evaluation of LLM App Quality", "comment": null, "summary": "LLM app stores are quickly emerging as platforms that gather a wide range of\nintelligent applications based on LLMs, giving users many choices for content\ncreation, coding support, education, and more. However, the current methods for\nranking and recommending apps in these stores mostly rely on static metrics\nlike user activity and favorites, which makes it hard for users to efficiently\nfind high-quality apps. To address these challenges, we propose LaQual, an\nautomated framework for evaluating the quality of LLM apps. LaQual consists of\nthree main stages: first, it labels and classifies LLM apps in a hierarchical\nway to accurately match them to different scenarios; second, it uses static\nindicators, such as time-weighted user engagement and functional capability\nmetrics, to filter out low-quality apps; and third, it conducts a dynamic,\nscenario-adaptive evaluation, where the LLM itself generates scenario-specific\nevaluation metrics, scoring rules, and tasks for a thorough quality assessment.\nExperiments on a popular LLM app store show that LaQual is effective. Its\nautomated scores are highly consistent with human judgments (with Spearman's\nrho of 0.62 and p=0.006 in legal consulting, and rho of 0.60 and p=0.009 in\ntravel planning). By effectively screening, LaQual can reduce the pool of\ncandidate LLM apps by 66.7% to 81.3%. User studies further confirm that LaQual\nsignificantly outperforms baseline systems in decision confidence, comparison\nefficiency (with average scores of 5.45 compared to 3.30), and the perceived\nvalue of its evaluation reports (4.75 versus 2.25). Overall, these results\ndemonstrate that LaQual offers a scalable, objective, and user-centered\nsolution for finding and recommending high-quality LLM apps in real-world use\ncases.", "AI": {"tldr": "LaQual\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u8bc4\u4f30LLM\u5e94\u7528\u8d28\u91cf\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u5206\u7c7b\u3001\u9759\u6001\u6307\u6807\u7b5b\u9009\u548c\u52a8\u6001\u573a\u666f\u81ea\u9002\u5e94\u8bc4\u4f30\u4e09\u9636\u6bb5\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u9ad8\u8d28\u91cf\u5e94\u7528\uff0c\u5b9e\u9a8c\u663e\u793a\u4e0e\u4eba\u5de5\u8bc4\u4f30\u9ad8\u5ea6\u4e00\u81f4\u4e14\u663e\u8457\u63d0\u5347\u7528\u6237\u9009\u62e9\u6548\u7387\u3002", "motivation": "\u5f53\u524dLLM\u5e94\u7528\u5546\u5e97\u4e3b\u8981\u4f9d\u8d56\u7528\u6237\u6d3b\u8dc3\u5ea6\u548c\u6536\u85cf\u7b49\u9759\u6001\u6307\u6807\u8fdb\u884c\u6392\u540d\u63a8\u8350\uff0c\u96be\u4ee5\u5e2e\u52a9\u7528\u6237\u9ad8\u6548\u627e\u5230\u9ad8\u8d28\u91cf\u5e94\u7528\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1)\u5206\u5c42\u5206\u7c7bLLM\u5e94\u7528\u4ee5\u5339\u914d\u4e0d\u540c\u573a\u666f\uff1b2)\u4f7f\u7528\u65f6\u5e8f\u52a0\u6743\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u529f\u80fd\u80fd\u529b\u6307\u6807\u7b49\u9759\u6001\u6307\u6807\u8fc7\u6ee4\u4f4e\u8d28\u91cf\u5e94\u7528\uff1b3)\u8fdb\u884c\u52a8\u6001\u573a\u666f\u81ea\u9002\u5e94\u8bc4\u4f30\uff0c\u7531LLM\u751f\u6210\u573a\u666f\u7279\u5b9a\u7684\u8bc4\u4f30\u6307\u6807\u3001\u8bc4\u5206\u89c4\u5219\u548c\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u663e\u793aLaQual\u81ea\u52a8\u5316\u8bc4\u5206\u4e0e\u4eba\u5de5\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\uff08\u6cd5\u5f8b\u54a8\u8be2Spearman's rho=0.62\uff0c\u65c5\u884c\u89c4\u5212rho=0.60\uff09\uff0c\u80fd\u51cf\u5c1166.7%-81.3%\u7684\u5019\u9009\u5e94\u7528\uff0c\u7528\u6237\u7814\u7a76\u663e\u793a\u5728\u51b3\u7b56\u4fe1\u5fc3\u3001\u6bd4\u8f83\u6548\u7387\uff085.45 vs 3.30\uff09\u548c\u8bc4\u4f30\u62a5\u544a\u4ef7\u503c\u611f\u77e5\uff084.75 vs 2.25\uff09\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u7cfb\u7edf\u3002", "conclusion": "LaQual\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u5ba2\u89c2\u4e14\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u53d1\u73b0\u548c\u63a8\u8350\u73b0\u5b9e\u4f7f\u7528\u573a\u666f\u4e2d\u7684\u9ad8\u8d28\u91cfLLM\u5e94\u7528\u3002"}}
{"id": "2508.18380", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18380", "abs": "https://arxiv.org/abs/2508.18380", "authors": ["Hung-Tien Huang", "Dzung Dinh", "Junier B. Oliva"], "title": "Information Templates: A New Paradigm for Intelligent Active Feature Acquisition", "comment": null, "summary": "Active feature acquisition (AFA) is an instance-adaptive paradigm in which,\nat test time, a policy sequentially chooses which features to acquire (at a\ncost) before predicting. Existing approaches either train reinforcement\nlearning (RL) policies, which deal with a difficult MDP, or greedy policies\nthat cannot account for the joint informativeness of features or require\nknowledge about the underlying data distribution. To overcome this, we propose\nTemplate-based AFA (TAFA), a non-greedy framework that learns a small library\nof feature templates--a set of features that are jointly informative--and uses\nthis library of templates to guide the next feature acquisitions. Through\nidentifying feature templates, the proposed framework not only significantly\nreduces the action space considered by the policy but also alleviates the need\nto estimate the underlying data distribution. Extensive experiments on\nsynthetic and real-world datasets show that TAFA outperforms the existing\nstate-of-the-art baselines while achieving lower overall acquisition cost and\ncomputation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6a21\u677f\u7684\u4e3b\u52a8\u7279\u5f81\u83b7\u53d6(TAFA)\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u5c11\u91cf\u8054\u5408\u4fe1\u606f\u5316\u7684\u7279\u5f81\u6a21\u677f\u6765\u6307\u5bfc\u7279\u5f81\u83b7\u53d6\uff0c\u663e\u8457\u51cf\u5c11\u52a8\u4f5c\u7a7a\u95f4\u4e14\u65e0\u9700\u4f30\u8ba1\u6570\u636e\u5206\u5e03\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4e3b\u52a8\u7279\u5f81\u83b7\u53d6\u65b9\u6cd5\u8981\u4e48\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5904\u7406\u590d\u6742MDP\uff0c\u8981\u4e48\u4f7f\u7528\u65e0\u6cd5\u8003\u8651\u7279\u5f81\u8054\u5408\u4fe1\u606f\u6027\u7684\u8d2a\u5a6a\u7b56\u7565\uff0c\u6216\u8005\u9700\u8981\u4e86\u89e3\u5e95\u5c42\u6570\u636e\u5206\u5e03\u4fe1\u606f\u3002", "method": "\u5b66\u4e60\u4e00\u4e2a\u5c0f\u7684\u7279\u5f81\u6a21\u677f\u5e93\uff08\u4e00\u7ec4\u8054\u5408\u4fe1\u606f\u5316\u7684\u7279\u5f81\uff09\uff0c\u4f7f\u7528\u8fd9\u4e9b\u6a21\u677f\u6765\u6307\u5bfc\u4e0b\u4e00\u4e2a\u7279\u5f81\u83b7\u53d6\uff0c\u4ece\u800c\u51cf\u5c11\u7b56\u7565\u8003\u8651\u7684\u52a8\u4f5c\u7a7a\u95f4\u5e76\u907f\u514d\u4f30\u8ba1\u6570\u636e\u5206\u5e03\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTAFA\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u603b\u4f53\u83b7\u53d6\u6210\u672c\u548c\u8ba1\u7b97\u91cf\u3002", "conclusion": "TAFA\u6846\u67b6\u901a\u8fc7\u7279\u5f81\u6a21\u677f\u8bc6\u522b\u6709\u6548\u89e3\u51b3\u4e86\u4e3b\u52a8\u7279\u5f81\u83b7\u53d6\u4e2d\u7684\u52a8\u4f5c\u7a7a\u95f4\u8fc7\u5927\u548c\u6570\u636e\u5206\u5e03\u4f30\u8ba1\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2508.18453", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.18453", "abs": "https://arxiv.org/abs/2508.18453", "authors": ["Yaser Baseri", "Abdelhakim Senhaji Hafid", "Dimitrios Makrakis", "Hamidreza Fereidouni"], "title": "Privacy-Preserving Federated Learning Framework for Risk-Based Adaptive Authentication", "comment": null, "summary": "Balancing robust security with strong privacy guarantees is critical for\nRisk-Based Adaptive Authentication (RBA), particularly in decentralized\nsettings. Federated Learning (FL) offers a promising solution by enabling\ncollaborative risk assessment without centralizing user data. However, existing\nFL approaches struggle with Non-Independent and Identically Distributed\n(Non-IID) user features, resulting in biased, unstable, and poorly generalized\nglobal models. This paper introduces FL-RBA2, a novel Federated Learning\nframework for Risk-Based Adaptive Authentication that addresses Non-IID\nchallenges through a mathematically grounded similarity transformation. By\nconverting heterogeneous user features (including behavioral, biometric,\ncontextual, interaction-based, and knowledge-based modalities) into IID\nsimilarity vectors, FL-RBA2 supports unbiased aggregation and personalized risk\nmodeling across distributed clients. The framework mitigates cold-start\nlimitations via clustering-based risk labeling, incorporates Differential\nPrivacy (DP) to safeguard sensitive information, and employs Message\nAuthentication Codes (MACs) to ensure model integrity and authenticity.\nFederated updates are securely aggregated into a global model, achieving strong\nbalance between user privacy, scalability, and adaptive authentication\nrobustness. Rigorous game-based security proofs in the Random Oracle Model\nformally establish privacy, correctness, and adaptive security guarantees.\nExtensive experiments on keystroke, mouse, and contextual datasets validate\nFL-RBA2's effectiveness in high-risk user detection and its resilience to model\ninversion and inference attacks, even under strong DP constraints.", "AI": {"tldr": "FL-RBA2\u662f\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u5b66\u76f8\u4f3c\u6027\u8f6c\u6362\u89e3\u51b3\u975eIID\u6570\u636e\u95ee\u9898\uff0c\u5b9e\u73b0\u53bb\u4e2d\u5fc3\u5316\u98ce\u9669\u8ba4\u8bc1\uff0c\u5e73\u8861\u5b89\u5168\u6027\u548c\u9690\u79c1\u4fdd\u62a4", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u975e\u72ec\u7acb\u540c\u5206\u5e03\u7528\u6237\u7279\u5f81\u65f6\u5b58\u5728\u504f\u5dee\u548c\u4e0d\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u6709\u6548\u8fdb\u884c\u98ce\u9669\u8ba4\u8bc1\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u4f7f\u7528\u6570\u5b66\u76f8\u4f3c\u6027\u8f6c\u6362\u5c06\u5f02\u6784\u7528\u6237\u7279\u5f81\u8f6c\u6362\u4e3aIID\u76f8\u4f3c\u5411\u91cf\uff0c\u7ed3\u5408\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\uff0c\u91c7\u7528\u6d88\u606f\u8ba4\u8bc1\u7801\u786e\u4fdd\u6a21\u578b\u5b8c\u6574\u6027\uff0c\u901a\u8fc7\u805a\u7c7b\u8fdb\u884c\u98ce\u9669\u6807\u6ce8", "result": "\u5728\u51fb\u952e\u3001\u9f20\u6807\u548c\u4e0a\u4e0b\u6587\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86FL-RBA2\u5728\u9ad8\u98ce\u9669\u7528\u6237\u68c0\u6d4b\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u5bf9\u6a21\u578b\u53cd\u8f6c\u548c\u63a8\u7406\u653b\u51fb\u7684\u62b5\u6297\u80fd\u529b", "conclusion": "FL-RBA2\u6210\u529f\u89e3\u51b3\u4e86\u975eIID\u6570\u636e\u6311\u6218\uff0c\u5728\u5f3a\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u3001\u53ef\u6269\u5c55\u6027\u548c\u81ea\u9002\u5e94\u8ba4\u8bc1\u9c81\u68d2\u6027\u7684\u5e73\u8861"}}
{"id": "2508.18675", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.18675", "abs": "https://arxiv.org/abs/2508.18675", "authors": ["Xu Lu", "Weisong Sun", "Yiran Zhang", "Ming Hu", "Cong Tian", "Zhi Jin", "Yang Liu"], "title": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision", "comment": null, "summary": "Automated code generation has long been considered the holy grail of software\nengineering. The emergence of Large Language Models (LLMs) has catalyzed a\nrevolutionary breakthrough in this area. However, existing methods that only\nrely on LLMs remain inadequate in the quality of generated code, offering no\nguarantees of satisfying practical requirements. They lack a systematic\nstrategy for requirements development and modeling. Recently, LLM-based agents\ntypically possess powerful abilities and play an essential role in facilitating\nthe alignment of LLM outputs with user requirements. In this paper, we envision\nthe first multi-agent framework for reliable code generation based on\n\\textsc{re}quirements \\textsc{de}velopment and \\textsc{fo}rmalization, named\n\\textsc{ReDeFo}. This framework incorporates three agents, highlighting their\naugmentation with knowledge and techniques of formal methods, into the\nrequirements-to-code generation pipeline to strengthen quality assurance. The\ncore of \\textsc{ReDeFo} is the use of formal specifications to bridge the gap\nbetween potentially ambiguous natural language requirements and precise\nexecutable code. \\textsc{ReDeFo} enables rigorous reasoning about correctness,\nuncovering hidden bugs, and enforcing critical properties throughout the\ndevelopment process. In general, our framework aims to take a promising step\ntoward realizing the long-standing vision of reliable, auto-generated software.", "AI": {"tldr": "\u63d0\u51fa\u4e86ReDeFo\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u9700\u6c42\u5f00\u53d1\u548c\u5f62\u5f0f\u5316\u65b9\u6cd5\u5b9e\u73b0\u53ef\u9760\u7684\u4ee3\u7801\u751f\u6210\uff0c\u4f7f\u7528\u5f62\u5f0f\u5316\u89c4\u8303\u8fde\u63a5\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u548c\u7cbe\u786e\u4ee3\u7801", "motivation": "\u73b0\u6709\u4ec5\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u5728\u8d28\u91cf\u4e0a\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u9700\u6c42\u5f00\u53d1\u548c\u5efa\u6a21\u7b56\u7565\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u6ee1\u8db3\u5b9e\u9645\u9700\u6c42", "method": "\u57fa\u4e8e\u9700\u6c42\u5f00\u53d1\u548c\u5f62\u5f0f\u5316\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u589e\u5f3a\u4e86\u5f62\u5f0f\u5316\u65b9\u6cd5\u77e5\u8bc6\u7684\u667a\u80fd\u4f53\uff0c\u4f7f\u7528\u5f62\u5f0f\u5316\u89c4\u8303\u4f5c\u4e3a\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u548c\u53ef\u6267\u884c\u4ee3\u7801\u4e4b\u95f4\u7684\u6865\u6881", "result": "\u6846\u67b6\u80fd\u591f\u8fdb\u884c\u4e25\u683c\u7684\u6b63\u786e\u6027\u63a8\u7406\uff0c\u53d1\u73b0\u9690\u85cf\u9519\u8bef\uff0c\u5e76\u5728\u6574\u4e2a\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u5f3a\u5236\u6267\u884c\u5173\u952e\u5c5e\u6027", "conclusion": "\u8be5\u6846\u67b6\u671d\u7740\u5b9e\u73b0\u53ef\u9760\u3001\u81ea\u52a8\u751f\u6210\u8f6f\u4ef6\u7684\u957f\u671f\u613f\u666f\u8fc8\u51fa\u4e86\u6709\u5e0c\u671b\u7684\u4e00\u6b65"}}
{"id": "2508.18391", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18391", "abs": "https://arxiv.org/abs/2508.18391", "authors": ["Nitin Nagesh Kulkarni", "Bryson Wilcox", "Max Sawa", "Jason Thom"], "title": "PKG-DPO: Optimizing Domain-Specific AI systems with Physics Knowledge Graphs and Direct Preference Optimization", "comment": null, "summary": "Advancing AI systems in scientific domains like physics, materials science,\nand engineering calls for reasoning over complex, multi-physics phenomena while\nrespecting governing principles. Although Large Language Models (LLMs) and\nexisting preference optimization techniques perform well on standard\nbenchmarks, they often struggle to differentiate between physically valid and\ninvalid reasoning. This shortcoming becomes critical in high-stakes\napplications like metal joining, where seemingly plausible yet physically\nincorrect recommendations can lead to defects, material waste, equipment\ndamage, and serious safety risks. To address this challenge, we introduce\nPKG-DPO, a novel framework that integrates Physics Knowledge Graphs (PKGs) with\nDirect Preference Optimization (DPO) to enforce physical validity in\nAI-generated outputs. PKG-DPO comprises three key components A) hierarchical\nphysics knowledge graph that encodes cross-domain relationships, conservation\nlaws, and thermodynamic principles. B) A physics reasoning engine that\nleverages structured knowledge to improve discrimination between physically\nconsistent and inconsistent responses. C) A physics-grounded evaluation suite\ndesigned to assess compliance with domain-specific constraints. PKG-DPO\nachieves 17% fewer constraint violations and an 11% higher Physics Score\ncompared to KG-DPO (knowledge graph-based DPO). Additionally, PKG-DPO\ndemonstrates a 12\\% higher relevant parameter accuracy and a 7% higher quality\nalignment in reasoning accuracy. While our primary focus is on metal joining,\nthe framework is broadly applicable to other multi-scale, physics-driven\ndomains, offering a principled approach to embedding scientific constraints\ninto preference learning.", "AI": {"tldr": "PKG-DPO\u662f\u4e00\u4e2a\u5c06\u7269\u7406\u77e5\u8bc6\u56fe\u8c31\u4e0e\u76f4\u63a5\u504f\u597d\u4f18\u5316\u76f8\u7ed3\u5408\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u5728AI\u751f\u6210\u8f93\u51fa\u4e2d\u5f3a\u5236\u6267\u884c\u7269\u7406\u6709\u6548\u6027\uff0c\u5728\u91d1\u5c5e\u8fde\u63a5\u9886\u57df\u663e\u8457\u51cf\u5c11\u7269\u7406\u7ea6\u675f\u8fdd\u53cd\u5e76\u63d0\u9ad8\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u548c\u504f\u597d\u4f18\u5316\u6280\u672f\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5f80\u5f80\u96be\u4ee5\u533a\u5206\u7269\u7406\u6709\u6548\u548c\u65e0\u6548\u7684\u63a8\u7406\uff0c\u8fd9\u5728\u91d1\u5c5e\u8fde\u63a5\u7b49\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u5b89\u5168\u95ee\u9898\u548c\u6750\u6599\u6d6a\u8d39\u3002", "method": "PKG-DPO\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u5206\u5c42\u7269\u7406\u77e5\u8bc6\u56fe\u8c31\u7f16\u7801\u8de8\u9886\u57df\u5173\u7cfb\u548c\u5b88\u6052\u5b9a\u5f8b\u3001\u7269\u7406\u63a8\u7406\u5f15\u64ce\u5229\u7528\u7ed3\u6784\u5316\u77e5\u8bc6\u533a\u5206\u7269\u7406\u4e00\u81f4\u6027\u54cd\u5e94\u3001\u7269\u7406\u57fa\u7840\u8bc4\u4f30\u5957\u4ef6\u8bc4\u4f30\u9886\u57df\u7279\u5b9a\u7ea6\u675f\u7684\u5408\u89c4\u6027\u3002", "result": "PKG-DPO\u76f8\u6bd4KG-DPO\u51cf\u5c11\u4e8617%\u7684\u7ea6\u675f\u8fdd\u53cd\uff0c\u7269\u7406\u5f97\u5206\u63d0\u9ad811%\uff0c\u76f8\u5173\u53c2\u6570\u51c6\u786e\u7387\u63d0\u9ad812%\uff0c\u63a8\u7406\u8d28\u91cf\u5bf9\u9f50\u5ea6\u63d0\u9ad87%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u91d1\u5c5e\u8fde\u63a5\u9886\u57df\uff0c\u8fd8\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5176\u4ed6\u591a\u5c3a\u5ea6\u7269\u7406\u9a71\u52a8\u9886\u57df\uff0c\u4e3a\u5c06\u79d1\u5b66\u7ea6\u675f\u5d4c\u5165\u504f\u597d\u5b66\u4e60\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\u3002"}}
{"id": "2508.18485", "categories": ["cs.CR", "cs.DS", "cs.SE", "E.3; F.2.1"], "pdf": "https://arxiv.org/pdf/2508.18485", "abs": "https://arxiv.org/abs/2508.18485", "authors": ["Peter T. Breuer"], "title": "An 8- and 12-bit block AES cipher", "comment": "This \"research note\" of mine from 2013 has been requested so often\n  from me over the years, along with requests for a way to cite it properly,\n  that I think it's appropriate to put it out on the web in a citeable archive.\n  Arxiv, step up", "summary": "Because it is so unusual, or hard to find, or expository, a truly tiny 8- or\n12-bit block AES (Rijndael) cipher is documented here, along with Java source\ncode.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u4f9b\u4e86\u4e00\u79cd\u6781\u5c0f\u76848\u4f4d\u621612\u4f4d\u5757AES\u52a0\u5bc6\u7b97\u6cd5\u7684\u5b9e\u73b0\uff0c\u9644\u5e26Java\u6e90\u4ee3\u7801", "motivation": "\u56e0\u4e3a8\u4f4d\u621612\u4f4d\u5757\u7684AES\u52a0\u5bc6\u7b97\u6cd5\u975e\u5e38\u7a00\u6709\u4e14\u96be\u4ee5\u627e\u5230\uff0c\u9700\u8981\u6587\u6863\u5316\u8fd9\u79cd\u5c0f\u89c4\u6a21\u7684\u5b9e\u73b0", "method": "\u6587\u6863\u5316\u4e86\u4e00\u79cd\u6781\u5c0f\u76848\u4f4d\u621612\u4f4d\u5757AES (Rijndael)\u52a0\u5bc6\u7b97\u6cd5\uff0c\u5e76\u63d0\u4f9bJava\u6e90\u4ee3\u7801\u5b9e\u73b0", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u6781\u5c0f\u5757\u5927\u5c0f\u7684AES\u52a0\u5bc6\u7b97\u6cd5\uff0c\u4e3a\u5c0f\u89c4\u6a21\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u52a0\u5bc6\u89e3\u51b3\u65b9\u6848", "conclusion": "\u8fd9\u79cd\u6781\u5c0f\u5757AES\u52a0\u5bc6\u7b97\u6cd5\u7684\u6587\u6863\u5316\u548c\u5b9e\u73b0\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7a7a\u767d\uff0c\u4e3a\u9700\u8981\u5c0f\u89c4\u6a21\u52a0\u5bc6\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u4ef7\u503c"}}
{"id": "2508.18721", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.18721", "abs": "https://arxiv.org/abs/2508.18721", "authors": ["Yunrui Pei", "Hongshu Wang", "Wenjie Zhang", "Yun Lin", "Weiyu Kong", "Jin song Dong"], "title": "LLM as an Execution Estimator: Recovering Missing Dependency for Practical Time-travelling Debugging", "comment": null, "summary": "Dynamic data dependency, answering \"why a variable has this value?\", is\ncritical for debugging. Given a program step `s` reading a variable `v`,\nfinding the dynamic definition of `v` is challenging. Traditional methods\nrequire either (1) exhaustive instrumentation of all possible definitions of\n`v` in one run or (2) replicating the run to re-examine reads/writes - both\ncostly. If `v` is defined in a library, instrumentation becomes expensive; for\nnon-deterministic programs, replication is infeasible.\n  We propose RecovSlicing, which computes dynamic data dependency in a single\nrun with partial instrumentation. We leverage LLMs to infer program behavior\nfrom a partially recorded trace and code context. Given a trace and a slicing\ncriterion (step `s` and variable `v`), RecovSlicing estimates the runtime\ndefinition of `v` by recovering the missing execution.It also supports implicit\nvariables, such as those in `list.get(i)`. Technically, RecovSlicing tackles:\n(1) recovering runtime values and structures, and (2) aligning recovered\nvariables with recorded memory to analyze definitions.\n  We evaluate RecovSlicing on 8,300 data dependencies across three slicing\nbenchmarks, comparing it with Slicer4J, ND-Slicer, LLM Slicer, and re-execution\nSlicer. RecovSlicing achieves accuracy of 80.3%, 91.1%, and 98.3%,\noutperforming the best baseline (39.0%, 82.0%, 59.9%), and also leads in recall\n(91.1%, 91.1%, 98.3% vs. 53.4%, 79.1%, 87.1%). Integrated into a regression bug\nlocalizer, it enables finding 16% more regressions.", "AI": {"tldr": "RecovSlicing\u662f\u4e00\u79cd\u4f7f\u7528\u90e8\u5206\u63d2\u6869\u548cLLM\u63a8\u65ad\u7a0b\u5e8f\u884c\u4e3a\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5355\u6b21\u8fd0\u884c\u4e2d\u8ba1\u7b97\u52a8\u6001\u6570\u636e\u4f9d\u8d56\u5173\u7cfb\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u9ad8\u6210\u672c\u548c\u4e0d\u53ef\u884c\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u52a8\u6001\u6570\u636e\u4f9d\u8d56\u5206\u6790\u65b9\u6cd5\u9700\u8981\u5168\u91cf\u63d2\u6869\u6216\u7a0b\u5e8f\u91cd\u653e\uff0c\u6210\u672c\u9ad8\u6602\u4e14\u5bf9\u975e\u786e\u5b9a\u6027\u7a0b\u5e8f\u4e0d\u53ef\u884c\u3002\u7279\u522b\u662f\u5728\u5e93\u51fd\u6570\u5b9a\u4e49\u53d8\u91cf\u6216\u975e\u786e\u5b9a\u6027\u7a0b\u5e8f\u4e2d\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u5c40\u9650\u6027\u3002", "method": "\u5229\u7528LLM\u4ece\u90e8\u5206\u8bb0\u5f55\u7684\u6267\u884c\u8f68\u8ff9\u548c\u4ee3\u7801\u4e0a\u4e0b\u6587\u4e2d\u63a8\u65ad\u7a0b\u5e8f\u884c\u4e3a\uff0c\u901a\u8fc7\u6062\u590d\u7f3a\u5931\u7684\u6267\u884c\u6765\u4f30\u8ba1\u8fd0\u884c\u65f6\u53d8\u91cf\u5b9a\u4e49\u3002\u652f\u6301\u9690\u5f0f\u53d8\u91cf\u6062\u590d\uff0c\u5e76\u5904\u7406\u8fd0\u884c\u65f6\u503c\u548c\u7ed3\u6784\u6062\u590d\u4ee5\u53ca\u53d8\u91cf\u4e0e\u8bb0\u5f55\u5185\u5b58\u5bf9\u9f50\u7684\u6280\u672f\u6311\u6218\u3002", "result": "\u5728\u4e09\u4e2a\u5207\u7247\u57fa\u51c6\u6d4b\u8bd5\u76848300\u4e2a\u6570\u636e\u4f9d\u8d56\u4e0a\uff0cRecovSlicing\u8fbe\u523080.3%\u300191.1%\u548c98.3%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\uff0839.0%\u300182.0%\u300159.9%\uff09\u3002\u53ec\u56de\u7387\u4e5f\u9886\u5148\uff0891.1%\u300191.1%\u300198.3% vs 53.4%\u300179.1%\u300187.1%\uff09\u3002", "conclusion": "RecovSlicing\u901a\u8fc7\u90e8\u5206\u63d2\u6869\u548cLLM\u63a8\u65ad\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u6570\u636e\u4f9d\u8d56\u5206\u6790\u7684\u6548\u7387\u548c\u53ef\u884c\u6027\u95ee\u9898\uff0c\u5728\u56de\u5f52\u9519\u8bef\u5b9a\u4f4d\u4e2d\u80fd\u591a\u53d1\u73b016%\u7684\u56de\u5f52\u95ee\u9898\uff0c\u5177\u6709\u91cd\u8981\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.18467", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18467", "abs": "https://arxiv.org/abs/2508.18467", "authors": ["Olivia Long", "Carter Teplica"], "title": "The AI in the Mirror: LLM Self-Recognition in an Iterated Public Goods Game", "comment": null, "summary": "As AI agents become increasingly capable of tool use and long-horizon tasks,\nthey have begun to be deployed in settings where multiple agents can interact.\nHowever, whereas prior work has mostly focused on human-AI interactions, there\nis an increasing need to understand AI-AI interactions. In this paper, we adapt\nthe iterated public goods game, a classic behavioral economics game, to analyze\nthe behavior of four reasoning and non-reasoning models across two conditions:\nmodels are either told they are playing against \"another AI agent\" or told\ntheir opponents are themselves. We find that, across different settings,\ntelling LLMs that they are playing against themselves significantly changes\ntheir tendency to cooperate. While our study is conducted in a toy environment,\nour results may provide insights into multi-agent settings where agents\n\"unconsciously\" discriminating against each other could inexplicably increase\nor decrease cooperation.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u8fed\u4ee3\u516c\u5171\u7269\u54c1\u535a\u5f08\u5b9e\u9a8c\uff0c\u53d1\u73b0\u544a\u77e5LLMs\u5176\u5bf9\u624b\u662f\"\u53e6\u4e00\u4e2aAI\u4ee3\u7406\"\u6216\"\u5b83\u4eec\u81ea\u5df1\"\u4f1a\u663e\u8457\u6539\u53d8\u5176\u5408\u4f5c\u503e\u5411\uff0c\u63ed\u793a\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u53ef\u80fd\u5b58\u5728\u7684\u65e0\u610f\u8bc6\u6b67\u89c6\u73b0\u8c61\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7406\u5de5\u5177\u4f7f\u7528\u548c\u957f\u65f6\u7a0b\u4efb\u52a1\u80fd\u529b\u7684\u63d0\u5347\uff0c\u591a\u4ee3\u7406\u4ea4\u4e92\u573a\u666f\u65e5\u76ca\u589e\u591a\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4eba\u673a\u4ea4\u4e92\uff0c\u4f46\u9700\u8981\u6df1\u5165\u7406\u89e3AI-AI\u4ea4\u4e92\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u4ee3\u7406\u5bf9\u81ea\u8eab\u8eab\u4efd\u8ba4\u77e5\u4e0d\u540c\u65f6\u7684\u5408\u4f5c\u884c\u4e3a\u53d8\u5316\u3002", "method": "\u91c7\u7528\u884c\u4e3a\u7ecf\u6d4e\u5b66\u7ecf\u5178\u6e38\u620f\u2014\u2014\u8fed\u4ee3\u516c\u5171\u7269\u54c1\u535a\u5f08\uff0c\u6d4b\u8bd5\u56db\u79cd\u63a8\u7406\u548c\u975e\u63a8\u7406\u6a21\u578b\u5728\u4e24\u79cd\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\uff1a\u88ab\u544a\u77e5\u5bf9\u624b\u662f\"\u53e6\u4e00\u4e2aAI\u4ee3\u7406\"\u6216\u88ab\u544a\u77e5\u5bf9\u624b\u662f\"\u5b83\u4eec\u81ea\u5df1\"\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\uff0c\u544a\u77e5LLMs\u5176\u5bf9\u624b\u662f\u5b83\u4eec\u81ea\u5df1\u4f1a\u663e\u8457\u6539\u53d8\u5176\u5408\u4f5c\u503e\u5411\u3002\u6a21\u578b\u5728\u8ba4\u4e3a\u5bf9\u624b\u662f\u81ea\u8eab\u65f6\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u5408\u4f5c\u884c\u4e3a\u6a21\u5f0f\u3002", "conclusion": "\u5c3d\u7ba1\u7814\u7a76\u5728\u7b80\u5316\u73af\u5883\u4e2d\u8fdb\u884c\uff0c\u4f46\u7ed3\u679c\u63ed\u793a\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4ee3\u7406\u53ef\u80fd\"\u65e0\u610f\u8bc6\"\u5730\u76f8\u4e92\u6b67\u89c6\uff0c\u8fd9\u4f1a\u4e0d\u53ef\u9884\u6d4b\u5730\u589e\u52a0\u6216\u51cf\u5c11\u5408\u4f5c\uff0c\u5bf9\u591a\u4ee3\u7406\u7cfb\u7edf\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2508.18488", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18488", "abs": "https://arxiv.org/abs/2508.18488", "authors": ["Martin Lochner", "Keegan Keplinger"], "title": "Collaborative Intelligence: Topic Modelling of Large Language Model use in Live Cybersecurity Operations", "comment": null, "summary": "Objective: This work describes the topic modelling of Security Operations\nCentre (SOC) use of a large language model (LLM), during live security\noperations. The goal is to better understand how these specialists voluntarily\nuse this tool.\n  Background: Human-automation teams have been extensively studied, but\ntransformer-based language models have sparked a new wave of collaboration. SOC\npersonnel at a major cybersecurity provider used an LLM to support live\nsecurity operations. This study examines how these specialists incorporated the\nLLM into their work.\n  Method: Our data set is the result of 10 months of SOC operators accessing\nGPT-4 over an internally deployed HTTP-based chat application. We performed two\ntopic modelling exercises, first using the established BERTopic model\n(Grootendorst, 2022), and second, using a novel topic modeling workflow.\n  Results: Both the BERTopic analysis and novel modelling approach revealed\nthat SOC operators primarily used the LLM to facilitate their understanding of\ncomplex text strings. Variations on this use-case accounted for ~40% of SOC LLM\nusage.\n  Conclusion: SOC operators are required to rapidly interpret complex commands\nand similar information. Their natural tendency to leverage LLMs to support\nthis activity indicates that their workflow can be supported and augmented by\ndesigning collaborative LLM tools for use in the SOC.\n  Application: This work can aid in creating next-generation tools for Security\nOperations Centres. By understanding common use-cases, we can develop workflows\nsupporting SOC task flow. One example is a right-click context menu for\nexecuting a command line analysis LLM call directly in the SOC environment.", "AI": {"tldr": "SOC\u4eba\u5458\u4e3b\u8981\u4f7f\u7528LLM\u6765\u7406\u89e3\u590d\u6742\u6587\u672c\u5b57\u7b26\u4e32\uff0c\u7ea640%\u7684\u4f7f\u7528\u573a\u666f\u96c6\u4e2d\u5728\u6b64\uff0c\u8868\u660eLLM\u53ef\u4ee5\u652f\u6301SOC\u5de5\u4f5c\u6d41\u7a0b", "motivation": "\u7814\u7a76SOC\u4e13\u5bb6\u5982\u4f55\u81ea\u613f\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u652f\u6301\u5b9e\u65f6\u5b89\u5168\u8fd0\u8425\uff0c\u4ee5\u7406\u89e3\u4eba\u673a\u534f\u4f5c\u7684\u65b0\u6a21\u5f0f", "method": "\u57fa\u4e8e10\u4e2a\u6708\u7684SOC\u64cd\u4f5c\u5458\u4f7f\u7528GPT-4\u7684\u804a\u5929\u6570\u636e\uff0c\u91c7\u7528BERTopic\u6a21\u578b\u548c\u65b0\u9896\u7684\u4e3b\u9898\u5efa\u6a21\u5de5\u4f5c\u6d41\u8fdb\u884c\u5206\u6790", "result": "SOC\u64cd\u4f5c\u5458\u4e3b\u8981\u4f7f\u7528LLM\u6765\u4fc3\u8fdb\u5bf9\u590d\u6742\u6587\u672c\u5b57\u7b26\u4e32\u7684\u7406\u89e3\uff0c\u8fd9\u79cd\u7528\u4f8b\u7ea6\u5360LLM\u4f7f\u7528\u768440%", "conclusion": "SOC\u64cd\u4f5c\u5458\u9700\u8981\u5feb\u901f\u89e3\u91ca\u590d\u6742\u547d\u4ee4\uff0c\u4ed6\u4eec\u81ea\u7136\u503e\u5411\u4e8e\u5229\u7528LLM\u652f\u6301\u8fd9\u4e00\u6d3b\u52a8\uff0c\u8868\u660e\u53ef\u4ee5\u901a\u8fc7\u8bbe\u8ba1\u534f\u4f5c\u5f0fLLM\u5de5\u5177\u6765\u589e\u5f3aSOC\u5de5\u4f5c\u6d41\u7a0b"}}
{"id": "2508.18771", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.18771", "abs": "https://arxiv.org/abs/2508.18771", "authors": ["Kexin Sun", "Hongyu Kuang", "Sebastian Baltes", "Xin Zhou", "He Zhang", "Xiaoxing Ma", "Guoping Rong", "Dong Shao", "Christoph Treude"], "title": "Does AI Code Review Lead to Code Changes? A Case Study of GitHub Actions", "comment": null, "summary": "AI-based code review tools automatically review and comment on pull requests\nto improve code quality. Despite their growing presence, little is known about\ntheir actual impact. We present a large-scale empirical study of 16 popular\nAI-based code review actions for GitHub workflows, analyzing more than 22,000\nreview comments in 178 repositories. We investigate (1) how these tools are\nadopted and configured, (2) whether their comments lead to code changes, and\n(3) which factors influence their effectiveness. We develop a two-stage\nLLM-assisted framework to determine whether review comments are addressed, and\nuse interpretable machine learning to identify influencing factors. Our\nfindings show that, while adoption is growing, effectiveness varies widely.\nComments that are concise, contain code snippets, and are manually triggered,\nparticularly those from hunk-level review tools, are more likely to result in\ncode changes. These results highlight the importance of careful tool design and\nsuggest directions for improving AI-based code review systems.", "AI": {"tldr": "\u7814\u7a76\u5bf916\u6b3eAI\u4ee3\u7801\u5ba1\u67e5\u5de5\u5177\u5728GitHub\u4e0a\u7684\u5b9e\u9645\u6548\u679c\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0\u7b80\u6d01\u3001\u5305\u542b\u4ee3\u7801\u7247\u6bb5\u4e14\u624b\u52a8\u89e6\u53d1\u7684\u8bc4\u8bba\u66f4\u5bb9\u6613\u88ab\u91c7\u7eb3", "motivation": "\u867d\u7136AI\u57fa\u7840\u4ee3\u7801\u5ba1\u67e5\u5de5\u5177\u9010\u6e10\u666e\u53ca\uff0c\u4f46\u5b83\u4eec\u7684\u5b9e\u9645\u5f71\u54cd\u548c\u6548\u679c\u4ecd\u7136\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u5b9e\u8bc1\u7814\u7a76", "method": "\u5206\u679022,000\u4e2a\u5ba1\u67e5\u8bc4\u8bba\u548c178\u4e2a\u4ed3\u5e93\uff0c\u4f7f\u7528\u4e24\u9636\u6bb5LLM\u8f85\u52a9\u6846\u67b6\u5224\u65ad\u8bc4\u8bba\u662f\u5426\u88ab\u5904\u7406\uff0c\u91c7\u7528\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u5206\u6790\u5f71\u54cd\u56e0\u7d20", "result": "\u91c7\u7528\u7387\u5728\u589e\u957f\u4f46\u6548\u679c\u5dee\u5f02\u663e\u8457\uff1b\u7b80\u6d01\u3001\u5305\u542b\u4ee3\u7801\u7247\u6bb5\u3001\u624b\u52a8\u89e6\u53d1\u7684\u8bc4\u8bba\uff08\u5c24\u5176\u662fhunk-level\u5de5\u5177\uff09\u66f4\u5bb9\u6613\u5bfc\u81f4\u4ee3\u7801\u66f4\u6539", "conclusion": "\u7ec6\u5fc3\u7684\u5de5\u5177\u8bbe\u8ba1\u5bf9AI\u4ee3\u7801\u5ba1\u67e5\u7cfb\u7edf\u7684\u6548\u679c\u81f3\u5173\u91cd\u8981\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u6539\u8fdb\u8fd9\u4e9b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b9\u5411"}}
{"id": "2508.18507", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18507", "abs": "https://arxiv.org/abs/2508.18507", "authors": ["Dillon Z. Chen", "Johannes Zenn", "Tristan Cinquin", "Sheila A. McIlraith"], "title": "Language Models For Generalised PDDL Planning: Synthesising Sound and Programmatic Policies", "comment": "RLC 2025 Workshop on Programmatic Reinforcement Learning", "summary": "We study the usage of language models (LMs) for planning over world models\nspecified in the Planning Domain Definition Language (PDDL). We prompt LMs to\ngenerate Python programs that serve as generalised policies for solving PDDL\nproblems from a given domain. Notably, our approach synthesises policies that\nare provably sound relative to the PDDL domain without reliance on external\nverifiers. We conduct experiments on competition benchmarks which show that our\npolicies can solve more PDDL problems than PDDL planners and recent LM\napproaches within a fixed time and memory constraint. Our approach manifests in\nthe LMPlan planner which can solve planning problems with several hundreds of\nrelevant objects. Surprisingly, we observe that LMs used in our framework\nsometimes plan more effectively over PDDL problems written in meaningless\nsymbols in place of natural language; e.g. rewriting (at dog kitchen) as (p2 o1\no3). This finding challenges hypotheses that LMs reason over word semantics and\nmemorise solutions from its training corpus, and is worth further exploration.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u8fdb\u884cPDDL\u89c4\u8303\u7684\u4e16\u754c\u6a21\u578b\u89c4\u5212\u3002\u901a\u8fc7\u63d0\u793aLMs\u751f\u6210Python\u7a0b\u5e8f\u4f5c\u4e3a\u901a\u7528\u653f\u7b56\uff0c\u80fd\u591f\u5728\u56fa\u5b9a\u65f6\u95f4\u548c\u5185\u5b58\u9650\u5236\u4e0b\u89e3\u51b3\u66f4\u591aPDDL\u95ee\u9898\uff0c\u751a\u81f3\u8d85\u8d8a\u4f20\u7edfPDDL\u89c4\u5212\u5668\u3002", "motivation": "\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u5728\u5f62\u5f0f\u89c4\u5212\u9886\u57df\u7684\u5e94\u7528\uff0c\u5c1d\u8bd5\u901a\u8fc7LMs\u751f\u6210\u53ef\u9a8c\u8bc1\u6b63\u786e\u7684\u901a\u7528\u653f\u7b56\uff0c\u800c\u4e0d\u4f9d\u8d56\u5916\u90e8\u9a8c\u8bc1\u5668\u3002", "method": "\u4f7f\u7528\u63d0\u793a\u6280\u672f\u8ba9\u8bed\u8a00\u6a21\u578b\u751f\u6210Python\u7a0b\u5e8f\uff0c\u8fd9\u4e9b\u7a0b\u5e8f\u4f5c\u4e3a\u89e3\u51b3\u7279\u5b9aPDDL\u57df\u95ee\u9898\u7684\u901a\u7528\u653f\u7b56\u3002\u65b9\u6cd5\u7ef4\u62a4\u4e86\u653f\u7b56\u5bf9\u5e94PDDL\u57df\u7684\u53ef\u8bc1\u6b63\u786e\u6027\u3002", "result": "\u5728\u7ade\u8d5b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u7684\u89c4\u5212\u5668LMPlan\u80fd\u89e3\u51b3\u5305\u542b\u6570\u767e\u4e2a\u76f8\u5173\u5bf9\u8c61\u7684\u89c4\u5212\u95ee\u9898\uff0c\u8868\u73b0\u8d85\u8fc7\u4f20\u7edfPDDL\u89c4\u5212\u5668\u548c\u6700\u65b0\u7684LM\u65b9\u6cd5\u3002\u4e00\u4e2a\u610f\u5916\u53d1\u73b0\u662f\uff0cLMs\u5728\u65e0\u610f\u4e49\u7b26\u53f7\u7684PDDL\u95ee\u9898\u4e0a\u89c4\u5212\u6548\u679c\u66f4\u597d\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u5f62\u5f0f\u89c4\u5212\u4e2d\u7684\u6548\u679c\uff0c\u5e76\u63d0\u51fa\u4e86\u5173\u4e8eLMs\u8bc6\u522b\u8bed\u4e49\u548c\u8bb0\u5fc6\u89e3\u51b3\u65b9\u6848\u7684\u65b0\u95ee\u9898\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2508.18649", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18649", "abs": "https://arxiv.org/abs/2508.18649", "authors": ["Nanxi Li", "Zhengyue Zhao", "Chaowei Xiao"], "title": "PRISM: Robust VLM Alignment with Principled Reasoning for Integrated Safety in Multimodality", "comment": null, "summary": "Safeguarding vision-language models (VLMs) is a critical challenge, as\nexisting methods often suffer from over-defense, which harms utility, or rely\non shallow alignment, failing to detect complex threats that require deep\nreasoning. To this end, we introduce PRISM (Principled Reasoning for Integrated\nSafety in Multimodality), a system2-like framework that aligns VLMs by\nembedding a structured, safety-aware reasoning process. Our framework consists\nof two key components: PRISM-CoT, a dataset that teaches safety-aware\nchain-of-thought reasoning, and PRISM-DPO, generated via Monte Carlo Tree\nSearch (MCTS) to further refine this reasoning through Direct Preference\nOptimization to help obtain a delicate safety boundary. Comprehensive\nevaluations demonstrate PRISM's effectiveness, achieving remarkably low attack\nsuccess rates including 0.15% on JailbreakV-28K for Qwen2-VL and 90%\nimprovement over the previous best method on VLBreak for LLaVA-1.5. PRISM also\nexhibits strong robustness against adaptive attacks, significantly increasing\ncomputational costs for adversaries, and generalizes effectively to\nout-of-distribution challenges, reducing attack success rates to just 8.70% on\nthe challenging multi-image MIS benchmark. Remarkably, this robust defense is\nachieved while preserving, and in some cases enhancing, model utility. To\npromote reproducibility, we have made our code, data, and model weights\navailable at https://github.com/SaFoLab-WISC/PRISM.", "AI": {"tldr": "PRISM\u662f\u4e00\u4e2a\u4fdd\u62a4\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u5b89\u5168\u611f\u77e5\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u6765\u5e73\u8861\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4fdd\u62a4\u65b9\u6cd5\u5b58\u5728\u8fc7\u5ea6\u9632\u5fa1\u635f\u5bb3\u5b9e\u7528\u6027\uff0c\u6216\u4ec5\u8fdb\u884c\u6d45\u5c42\u5bf9\u9f50\u65e0\u6cd5\u68c0\u6d4b\u9700\u8981\u6df1\u5ea6\u63a8\u7406\u7684\u590d\u6742\u5a01\u80c1\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faPRISM\u6846\u67b6\uff0c\u5305\u542bPRISM-CoT\u6570\u636e\u96c6\u6559\u6388\u5b89\u5168\u611f\u77e5\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u4ee5\u53ca\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u751f\u6210\u7684PRISM-DPO\u8fdb\u884c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u6765\u7ec6\u5316\u5b89\u5168\u8fb9\u754c\u3002", "result": "\u5728\u591a\u4e2a\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff1aQwen2-VL\u5728JailbreakV-28K\u4e0a\u653b\u51fb\u6210\u529f\u7387\u4ec50.15%\uff0cLLaVA-1.5\u5728VLBreak\u4e0a\u6bd4\u4e4b\u524d\u6700\u4f73\u65b9\u6cd5\u63d0\u534790%\uff0c\u5728MIS\u57fa\u51c6\u4e0a\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u81f38.70%\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u6a21\u578b\u5b9e\u7528\u6027\u3002", "conclusion": "PRISM\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u4fdd\u62a4\u95ee\u9898\uff0c\u5728\u63d0\u4f9b\u5f3a\u5927\u9632\u5fa1\u80fd\u529b\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u5b9e\u7528\u6027\uff0c\u5177\u6709\u5f88\u597d\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.18816", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.18816", "abs": "https://arxiv.org/abs/2508.18816", "authors": ["Sabato Nocera", "Davide Fucci", "Giuseppe Scanniello"], "title": "Dealing with SonarQube Cloud: Initial Results from a Mining Software Repository Study", "comment": "Accepted for ESEM25 NIER track", "summary": "Background: Static Code Analysis (SCA) tools are widely adopted to enforce\ncode quality standards. However, little is known about how open-source projects\nuse and customize these tools. Aims: This paper investigates how GitHub\nprojects use and customize a popular SCA tool, namely SonarQube Cloud. Method:\nWe conducted a mining study of GitHub projects that are linked through GitHub\nActions to SonarQube Cloud projects. Results: Among 321 GitHub projects using\nSonarQube Cloud, 81% of them are correctly connected to SonarQube Cloud\nprojects, while others exhibit misconfigurations or restricted access. Among\n265 accessible SonarQube Cloud projects, 75% use the organization's default\nquality gate, i.e., a set of conditions that deployed source code must meet to\npass automated checks. While 55% of the projects use the built-in quality gate\nprovided by SonarQube Cloud, 45% of them customize their quality gate with\ndifferent conditions. Overall, the most common quality conditions align with\nSonarQube Cloud's \"Clean as You Code\" principle and enforce security,\nmaintainability, reliability, coverage, and a few duplicates on newly added or\nmodified source code. Conclusions: Many projects rely on predefined\nconfigurations, yet a significant portion customize their configurations to\nmeet specific quality goals. Building on our initial results, we envision a\nfuture research agenda linking quality gate configurations to actual software\noutcomes (e.g., improvement of software security). This would enable\nevidence-based recommendations for configuring SCA tools like SonarQube Cloud\nin various contexts.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6316\u6398GitHub\u9879\u76ee\u53d1\u73b0\uff0c\u8bb8\u591a\u5f00\u6e90\u9879\u76ee\u4f7f\u7528SonarQube Cloud\u8fdb\u884c\u9759\u6001\u4ee3\u7801\u5206\u6790\uff0c\u5176\u4e2d81%\u6b63\u786e\u8fde\u63a5\uff0c75%\u4f7f\u7529\u7ec4\u7ec7\u9ed8\u8ba4\u8d28\u91cf\u95e8\uff0c45%\u9879\u76ee\u4f1a\u81ea\u5b9a\u4e49\u8d28\u91cf\u95e8\u6761\u4ef6\u4ee5\u6ee1\u8db3\u7279\u5b9a\u8d28\u91cf\u76ee\u6807\u3002", "motivation": "\u8c03\u67e5\u5f00\u6e90\u9879\u76ee\u5982\u4f55\u4f7f\u7529\u548c\u81ea\u5b9a\u4e49SonarQube Cloud\u8fd9\u79cd\u9759\u6001\u4ee3\u7801\u5206\u6790\u5de5\u5177\uff0c\u4ee5\u4e86\u89e3\u5b9e\u9645\u4f7f\u7529\u60c5\u51b5\u548c\u914d\u7f6e\u4e60\u60ef\u3002", "method": "\u5bf9\u901a\u8fc7GitHub Actions\u94fe\u63a5\u5230SonarQube Cloud\u9879\u76ee\u7684GitHub\u9879\u76ee\u8fdb\u884c\u6316\u6398\u7814\u7a76\uff0c\u5206\u6790321\u4e2a\u4f7f\u7529SonarQube Cloud\u7684GitHub\u9879\u76ee\u3002", "result": "81%\u9879\u76ee\u6b63\u786e\u8fde\u63a5SonarQube Cloud\uff0c75%\u4f7f\u7528\u7ec4\u7ec7\u9ed8\u8ba4\u8d28\u91cf\u95e8\uff0c55%\u4f7f\u7528\u5185\u7f6e\u8d28\u91cf\u95e8\uff0c45%\u81ea\u5b9a\u4e49\u8d28\u91cf\u95e8\u6761\u4ef6\u3002\u6700\u5e38\u89c1\u7684\u8d28\u91cf\u6761\u4ef6\u4e0e\"Clean as You Code\"\u539f\u5219\u4e00\u81f4\uff0c\u6d89\u53ca\u5b89\u5168\u3001\u53ef\u7ef4\u62a4\u6027\u3001\u53ef\u9760\u6027\u3001\u8986\u76d6\u7387\u548c\u4ee3\u7801\u91cd\u590d\u7b49\u65b9\u9762\u3002", "conclusion": "\u8bb8\u591a\u9879\u76ee\u4f9d\u8d56\u9884\u5b9a\u4e49\u914d\u7f6e\uff0c\u4f46\u4ecd\u6709\u8f83\u5927\u6bd4\u4f8b\u7684\u9879\u76ee\u4f1a\u81ea\u5b9a\u4e49\u914d\u7f6e\u3002\u672a\u6765\u7814\u7a76\u53ef\u4ee5\u5c06\u8d28\u91cf\u95e8\u914d\u7f6e\u4e0e\u5b9e\u9645\u8f6f\u4ef6\u6548\u679c\u76f8\u5173\u8054\uff0c\u4e3a\u4e0d\u540c\u573a\u666f\u4e0b\u914d\u7f6eSCA\u5de5\u5177\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u7684\u5efa\u8bae\u3002"}}
{"id": "2508.18515", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18515", "abs": "https://arxiv.org/abs/2508.18515", "authors": ["Dillon Z. Chen"], "title": "Weisfeiler-Leman Features for Planning: A 1,000,000 Sample Size Hyperparameter Study", "comment": "Extended version of ECAI 2025 paper", "summary": "Weisfeiler-Leman Features (WLFs) are a recently introduced classical machine\nlearning tool for learning to plan and search. They have been shown to be both\ntheoretically and empirically superior to existing deep learning approaches for\nlearning value functions for search in symbolic planning. In this paper, we\nintroduce new WLF hyperparameters and study their various tradeoffs and\neffects. We utilise the efficiency of WLFs and run planning experiments on\nsingle core CPUs with a sample size of 1,000,000 to understand the effect of\nhyperparameters on training and planning. Our experimental analysis show that\nthere is a robust and best set of hyperparameters for WLFs across the tested\nplanning domains. We find that the best WLF hyperparameters for learning\nheuristic functions minimise execution time rather than maximise model\nexpressivity. We further statistically analyse and observe no significant\ncorrelation between training and planning metrics.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Weisfeiler-Leman\u7279\u5f81(WLFs)\u7684\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u53d1\u73b0\u5728\u6d4b\u8bd5\u89c4\u5212\u57df\u4e2d\u5b58\u5728\u4e00\u7ec4\u6700\u4f73\u8d85\u53c2\u6570\uff0c\u8fd9\u4e9b\u53c2\u6570\u6700\u5c0f\u5316\u6267\u884c\u65f6\u95f4\u800c\u975e\u6700\u5927\u5316\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u4e14\u8bad\u7ec3\u4e0e\u89c4\u5212\u6307\u6807\u95f4\u65e0\u663e\u8457\u76f8\u5173\u6027\u3002", "motivation": "WLFs\u5728\u5b66\u4e60\u548c\u641c\u7d22\u89c4\u5212\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u6548\u679c\uff0c\u4f46\u5bf9\u5176\u8d85\u53c2\u6570\u7684\u7814\u7a76\u5c1a\u4e0d\u5145\u5206\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u8d85\u53c2\u6570\u5bf9\u8bad\u7ec3\u548c\u89c4\u5212\u7684\u5f71\u54cd\u3002", "method": "\u5229\u7528WLFs\u7684\u9ad8\u6548\u6027\uff0c\u5728\u5355\u6838CPU\u4e0a\u8fd0\u884c100\u4e07\u4e2a\u6837\u672c\u7684\u89c4\u5212\u5b9e\u9a8c\uff0c\u7814\u7a76\u4e0d\u540c\u8d85\u53c2\u6570\u914d\u7f6e\u7684\u6743\u8861\u548c\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u5b58\u5728\u4e00\u7ec4\u9c81\u68d2\u7684\u6700\u4f73\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u8fd9\u4e9b\u53c2\u6570\u4f18\u5148\u6700\u5c0f\u5316\u6267\u884c\u65f6\u95f4\u800c\u975e\u6700\u5927\u5316\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u4e14\u8bad\u7ec3\u6307\u6807\u4e0e\u89c4\u5212\u6027\u80fd\u65e0\u663e\u8457\u7edf\u8ba1\u76f8\u5173\u6027\u3002", "conclusion": "WLFs\u7684\u6700\u4f73\u8d85\u53c2\u6570\u9009\u62e9\u5e94\u4ee5\u6700\u5c0f\u5316\u6267\u884c\u65f6\u95f4\u4e3a\u76ee\u6807\uff0c\u800c\u975e\u8ffd\u6c42\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u7684\u6700\u5927\u5316\uff0c\u8fd9\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53c2\u6570\u8c03\u4f18\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2508.18652", "categories": ["cs.CR", "cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.18652", "abs": "https://arxiv.org/abs/2508.18652", "authors": ["Runpeng Geng", "Yanting Wang", "Ying Chen", "Jinyuan Jia"], "title": "UniC-RAG: Universal Knowledge Corruption Attacks to Retrieval-Augmented Generation", "comment": "21 pages, 4 figures", "summary": "Retrieval-augmented generation (RAG) systems are widely deployed in\nreal-world applications in diverse domains such as finance, healthcare, and\ncybersecurity. However, many studies showed that they are vulnerable to\nknowledge corruption attacks, where an attacker can inject adversarial texts\ninto the knowledge database of a RAG system to induce the LLM to generate\nattacker-desired outputs. Existing studies mainly focus on attacking specific\nqueries or queries with similar topics (or keywords). In this work, we propose\nUniC-RAG, a universal knowledge corruption attack against RAG systems. Unlike\nprior work, UniC-RAG jointly optimizes a small number of adversarial texts that\ncan simultaneously attack a large number of user queries with diverse topics\nand domains, enabling an attacker to achieve various malicious objectives, such\nas directing users to malicious websites, triggering harmful command execution,\nor launching denial-of-service attacks. We formulate UniC-RAG as an\noptimization problem and further design an effective solution to solve it,\nincluding a balanced similarity-based clustering method to enhance the attack's\neffectiveness. Our extensive evaluations demonstrate that UniC-RAG is highly\neffective and significantly outperforms baselines. For instance, UniC-RAG could\nachieve over 90% attack success rate by injecting 100 adversarial texts into a\nknowledge database with millions of texts to simultaneously attack a large set\nof user queries (e.g., 2,000). Additionally, we evaluate existing defenses and\nshow that they are insufficient to defend against UniC-RAG, highlighting the\nneed for new defense mechanisms in RAG systems.", "AI": {"tldr": "UniC-RAG\u662f\u4e00\u79cd\u9488\u5bf9\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\u7684\u901a\u7528\u77e5\u8bc6\u6c61\u67d3\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5c11\u91cf\u5bf9\u6297\u6027\u6587\u672c\u6765\u540c\u65f6\u653b\u51fb\u5927\u91cf\u4e0d\u540c\u4e3b\u9898\u7684\u7528\u6237\u67e5\u8be2\uff0c\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc790%\u3002", "motivation": "\u73b0\u6709\u7684\u77e5\u8bc6\u6c61\u67d3\u653b\u51fb\u4e3b\u8981\u9488\u5bf9\u7279\u5b9a\u67e5\u8be2\u6216\u76f8\u4f3c\u4e3b\u9898\u7684\u67e5\u8be2\uff0c\u7f3a\u4e4f\u80fd\u591f\u540c\u65f6\u653b\u51fb\u5927\u91cf\u591a\u6837\u5316\u67e5\u8be2\u7684\u901a\u7528\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u5c06\u653b\u51fb\u5efa\u6a21\u4e3a\u4f18\u5316\u95ee\u9898\uff0c\u8bbe\u8ba1\u5e73\u8861\u76f8\u4f3c\u6027\u805a\u7c7b\u65b9\u6cd5\uff0c\u8054\u5408\u4f18\u5316\u5c11\u91cf\u5bf9\u6297\u6027\u6587\u672c\u6765\u540c\u65f6\u653b\u51fb\u5927\u91cf\u7528\u6237\u67e5\u8be2\u3002", "result": "\u4ec5\u6ce8\u5165100\u4e2a\u5bf9\u6297\u6027\u6587\u672c\u5c31\u80fd\u5728\u5305\u542b\u6570\u767e\u4e07\u6587\u672c\u7684\u77e5\u8bc6\u5e93\u4e2d\u540c\u65f6\u653b\u51fb2000\u4e2a\u7528\u6237\u67e5\u8be2\uff0c\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc790%\u3002\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u65e0\u6cd5\u6709\u6548\u9632\u5fa1\u8be5\u653b\u51fb\u3002", "conclusion": "UniC-RAG\u653b\u51fb\u6548\u679c\u663e\u8457\uff0c\u73b0\u6709\u9632\u5fa1\u673a\u5236\u4e0d\u8db3\uff0c\u51f8\u663e\u4e86RAG\u7cfb\u7edf\u9700\u8981\u65b0\u7684\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u6b64\u7c7b\u901a\u7528\u653b\u51fb\u3002"}}
{"id": "2508.18955", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.18955", "abs": "https://arxiv.org/abs/2508.18955", "authors": ["Yunbo Ni", "Shaohua Li"], "title": "Interleaving Large Language Models for Compiler Testing", "comment": null, "summary": "Testing compilers with AI models, especially large language models (LLMs),\nhas shown great promise. However, current approaches struggle with two key\nproblems: The generated programs for testing compilers are often too simple,\nand extensive testing with the LLMs is computationally expensive. In this\npaper, we propose a novel compiler testing framework that decouples the testing\nprocess into two distinct phases: an offline phase and an online phase. In the\noffline phase, we use LLMs to generate a collection of small but feature-rich\ncode pieces. In the online phase, we reuse these code pieces by strategically\ncombining them to build high-quality and valid test programs, which are then\nused to test compilers.\n  We implement this idea in a tool, LegoFuzz, for testing C compilers. The\nresults are striking: we found 66 bugs in GCC and LLVM, the most widely used C\ncompilers. Almost half of the bugs are miscompilation bugs, which are serious\nand hard-to-find bugs that none of the existing LLM-based tools could find. We\nbelieve this efficient design opens up new possibilities for using AI models in\nsoftware testing beyond just C compilers.", "AI": {"tldr": "\u63d0\u51faLegoFuzz\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u7ebf\u751f\u6210\u4ee3\u7801\u7247\u6bb5\u548c\u5728\u7ebf\u7ec4\u5408\u6d4b\u8bd5\u7684\u65b9\u5f0f\uff0c\u9ad8\u6548\u6d4b\u8bd5C\u7f16\u8bd1\u5668\uff0c\u53d1\u73b066\u4e2aGCC\u548cLLVM\u6f0f\u6d1e", "motivation": "\u5f53\u524d\u57fa\u4e8eAI\u7684\u7f16\u8bd1\u5668\u6d4b\u8bd5\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a\u751f\u6210\u7684\u6d4b\u8bd5\u7a0b\u5e8f\u8fc7\u4e8e\u7b80\u5355\uff0c\u4ee5\u53ca\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u6d4b\u8bd5\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8", "method": "\u5c06\u6d4b\u8bd5\u8fc7\u7a0b\u89e3\u8026\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u79bb\u7ebf\u9636\u6bb5\u4f7f\u7528LLM\u751f\u6210\u5c0f\u578b\u4f46\u529f\u80fd\u4e30\u5bcc\u7684\u4ee3\u7801\u7247\u6bb5\uff1b\u5728\u7ebf\u9636\u6bb5\u7b56\u7565\u6027\u5730\u7ec4\u5408\u8fd9\u4e9b\u4ee3\u7801\u7247\u6bb5\u6784\u5efa\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7a0b\u5e8f", "result": "\u5728GCC\u548cLLVM\u4e2d\u53d1\u73b066\u4e2a\u6f0f\u6d1e\uff0c\u5176\u4e2d\u8fd1\u4e00\u534a\u662f\u73b0\u6709LLM\u5de5\u5177\u65e0\u6cd5\u53d1\u73b0\u7684\u4e25\u91cd\u8bef\u7f16\u8bd1\u6f0f\u6d1e", "conclusion": "\u8fd9\u79cd\u9ad8\u6548\u8bbe\u8ba1\u4e3a\u5728\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u8d85\u8d8aC\u7f16\u8bd1\u5668\u4f7f\u7528AI\u6a21\u578b\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027"}}
{"id": "2508.18520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18520", "abs": "https://arxiv.org/abs/2508.18520", "authors": ["Dillon Z. Chen"], "title": "Symmetry-Invariant Novelty Heuristics via Unsupervised Weisfeiler-Leman Features", "comment": "HSDIP@ICAPS 2025 Workshop", "summary": "Novelty heuristics aid heuristic search by exploring states that exhibit\nnovel atoms. However, novelty heuristics are not symmetry invariant and hence\nmay sometimes lead to redundant exploration. In this preliminary report, we\npropose to use Weisfeiler-Leman Features for planning (WLFs) in place of atoms\nfor detecting novelty. WLFs are recently introduced features for learning\ndomain-dependent heuristics for generalised planning problems. We explore an\nunsupervised usage of WLFs for synthesising lifted, domain-independent novelty\nheuristics that are invariant to symmetric states. Experiments on the classical\nInternational Planning Competition and Hard To Ground benchmark suites yield\npromising results for novelty heuristics synthesised from WLFs.", "AI": {"tldr": "\u4f7f\u7528Weisfeiler-Leman\u7279\u5f81\u66ff\u4ee3\u539f\u5b50\u7279\u5f81\u6765\u6784\u5efa\u5bf9\u79f0\u4e0d\u53d8\u7684\u65b0\u9896\u6027\u542f\u53d1\u5f0f\uff0c\u89e3\u51b3\u4f20\u7edf\u65b0\u9896\u6027\u542f\u53d1\u5f0f\u56e0\u5bf9\u79f0\u72b6\u6001\u5bfc\u81f4\u7684\u5197\u4f59\u63a2\u7d22\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u65b0\u9896\u6027\u542f\u53d1\u5f0f\u57fa\u4e8e\u539f\u5b50\u7279\u5f81\uff0c\u4e0d\u5177\u6709\u5bf9\u79f0\u4e0d\u53d8\u6027\uff0c\u4f1a\u5bfc\u81f4\u5bf9\u5bf9\u79f0\u72b6\u6001\u7684\u5197\u4f59\u63a2\u7d22\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8bc6\u522b\u72b6\u6001\u672c\u8d28\u7279\u5f81\u800c\u4e0d\u53d7\u5bf9\u79f0\u53d8\u6362\u5f71\u54cd\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "method": "\u91c7\u7528Weisfeiler-Leman\u7279\u5f81\uff08WLFs\uff09\u6765\u68c0\u6d4b\u65b0\u9896\u6027\uff0c\u8fd9\u4e9b\u7279\u5f81\u6700\u521d\u662f\u4e3a\u5e7f\u4e49\u89c4\u5212\u95ee\u9898\u5b66\u4e60\u9886\u57df\u76f8\u5173\u542f\u53d1\u5f0f\u800c\u63d0\u51fa\u7684\u3002\u672c\u6587\u63a2\u7d22WLFs\u7684\u65e0\u76d1\u7763\u4f7f\u7528\uff0c\u7528\u4e8e\u5408\u6210\u63d0\u5347\u7684\u3001\u9886\u57df\u65e0\u5173\u4e14\u5bf9\u5bf9\u79f0\u72b6\u6001\u4e0d\u53d8\u7684\u65b0\u9896\u6027\u542f\u53d1\u5f0f\u3002", "result": "\u5728\u56fd\u9645\u89c4\u5212\u7ade\u8d5b\u548cHard To Ground\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8eWLFs\u5408\u6210\u7684\u65b0\u9896\u6027\u542f\u53d1\u5f0f\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002", "conclusion": "WLFs\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u66ff\u4ee3\u7279\u5f81\u6765\u6784\u5efa\u5bf9\u79f0\u4e0d\u53d8\u7684\u65b0\u9896\u6027\u542f\u53d1\u5f0f\uff0c\u51cf\u5c11\u5197\u4f59\u63a2\u7d22\uff0c\u63d0\u9ad8\u542f\u53d1\u5f0f\u641c\u7d22\u7684\u6548\u7387\u3002"}}
{"id": "2508.18684", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.18684", "abs": "https://arxiv.org/abs/2508.18684", "authors": ["Shaswata Mitra", "Azim Bazarov", "Martin Duclos", "Sudip Mittal", "Aritran Piplai", "Md Rayhanur Rahman", "Edward Zieglar", "Shahram Rahimi"], "title": "FALCON: Autonomous Cyber Threat Intelligence Mining with LLMs for IDS Rule Generation", "comment": "11 pages, 5 figures, 4 tables", "summary": "Signature-based Intrusion Detection Systems (IDS) detect malicious activities\nby matching network or host activity against predefined rules. These rules are\nderived from extensive Cyber Threat Intelligence (CTI), which includes attack\nsignatures and behavioral patterns obtained through automated tools and manual\nthreat analysis, such as sandboxing. The CTI is then transformed into\nactionable rules for the IDS engine, enabling real-time detection and\nprevention. However, the constant evolution of cyber threats necessitates\nfrequent rule updates, which delay deployment time and weaken overall security\nreadiness. Recent advancements in agentic systems powered by Large Language\nModels (LLMs) offer the potential for autonomous IDS rule generation with\ninternal evaluation. We introduce FALCON, an autonomous agentic framework that\ngenerates deployable IDS rules from CTI data in real-time and evaluates them\nusing built-in multi-phased validators. To demonstrate versatility, we target\nboth network (Snort) and host-based (YARA) mediums and construct a\ncomprehensive dataset of IDS rules with their corresponding CTIs. Our\nevaluations indicate FALCON excels in automatic rule generation, with an\naverage of 95% accuracy validated by qualitative evaluation with 84%\ninter-rater agreement among multiple cybersecurity analysts across all metrics.\nThese results underscore the feasibility and effectiveness of LLM-driven data\nmining for real-time cyber threat mitigation.", "AI": {"tldr": "FALCON\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u7f51\u7edc\u5a01\u80c1\u60c5\u62a5(CTI)\u6570\u636e\u5b9e\u65f6\u751f\u6210\u53ef\u90e8\u7f72\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf(IDS)\u89c4\u5219\uff0c\u5e76\u901a\u8fc7\u5185\u7f6e\u9a8c\u8bc1\u5668\u8fdb\u884c\u8bc4\u4f30\uff0c\u5b9e\u73b0\u4e8695%\u7684\u5e73\u5747\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u7b7e\u540d\u7684IDS\u9700\u8981\u9891\u7e41\u66f4\u65b0\u89c4\u5219\u6765\u5e94\u5bf9\u4e0d\u65ad\u6f14\u53d8\u7684\u7f51\u7edc\u5a01\u80c1\uff0c\u4f46\u89c4\u5219\u66f4\u65b0\u5b58\u5728\u5ef6\u8fdf\uff0c\u5f71\u54cd\u4e86\u5b89\u5168\u9632\u62a4\u7684\u5b9e\u65f6\u6027\u548c\u6709\u6548\u6027\u3002", "method": "\u5f00\u53d1\u4e86FALCON\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4eceCTI\u6570\u636e\u81ea\u52a8\u751f\u6210IDS\u89c4\u5219\uff0c\u5e76\u91c7\u7528\u5185\u7f6e\u7684\u591a\u9636\u6bb5\u9a8c\u8bc1\u5668\u8fdb\u884c\u8bc4\u4f30\uff0c\u652f\u6301\u7f51\u7edc\u578b(Snort)\u548c\u4e3b\u673a\u578b(YARA)\u4e24\u79cd\u68c0\u6d4b\u5a92\u4ecb\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793aFALCON\u5728\u81ea\u52a8\u89c4\u5219\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523095%\uff0c\u591a\u4f4d\u7f51\u7edc\u5b89\u5168\u5206\u6790\u5e08\u7684\u5b9a\u6027\u8bc4\u4f30\u4e00\u81f4\u6027\u8fbe\u523084%\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u6316\u6398\u5728\u5b9e\u65f6\u7f51\u7edc\u5a01\u80c1\u7f13\u89e3\u65b9\u9762\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\uff0c\u4e3a\u81ea\u4e3bIDS\u89c4\u5219\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.18993", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18993", "abs": "https://arxiv.org/abs/2508.18993", "authors": ["Ziyi Ni", "Huacan Wang", "Shuo Zhang", "Shuo Lu", "Ziyang He", "Wang You", "Zhenheng Tang", "Yuntao Du", "Bill Sun", "Hongzhang Liu", "Sen Hu", "Ronghao Chen", "Bo Li", "Xin Li", "Chen Hu", "Binxing Jiao", "Daxin Jiang", "Pin Lyu"], "title": "GitTaskBench: A Benchmark for Code Agents Solving Real-World Tasks Through Code Repository Leveraging", "comment": "Highly practical, Well-motivated, Actionable", "summary": "Beyond scratch coding, exploiting large-scale code repositories (e.g.,\nGitHub) for practical tasks is vital in real-world software development, yet\ncurrent benchmarks rarely evaluate code agents in such authentic,\nworkflow-driven scenarios. To bridge this gap, we introduce GitTaskBench, a\nbenchmark designed to systematically assess this capability via 54 realistic\ntasks across 7 modalities and 7 domains. Each task pairs a relevant repository\nwith an automated, human-curated evaluation harness specifying practical\nsuccess criteria. Beyond measuring execution and task success, we also propose\nthe alpha-value metric to quantify the economic benefit of agent performance,\nwhich integrates task success rates, token cost, and average developer\nsalaries. Experiments across three state-of-the-art agent frameworks with\nmultiple advanced LLMs show that leveraging code repositories for complex task\nsolving remains challenging: even the best-performing system, OpenHands+Claude\n3.7, solves only 48.15% of tasks. Error analysis attributes over half of\nfailures to seemingly mundane yet critical steps like environment setup and\ndependency resolution, highlighting the need for more robust workflow\nmanagement and increased timeout preparedness. By releasing GitTaskBench, we\naim to drive progress and attention toward repository-aware code reasoning,\nexecution, and deployment -- moving agents closer to solving complex,\nend-to-end real-world tasks. The benchmark and code are open-sourced at\nhttps://github.com/QuantaAlpha/GitTaskBench.", "AI": {"tldr": "GitTaskBench\u662f\u4e00\u4e2a\u8bc4\u4f30\u4ee3\u7801\u4ee3\u7406\u5728\u771f\u5b9eGitHub\u4ed3\u5e93\u5de5\u4f5c\u6d41\u4e2d\u6267\u884c\u590d\u6742\u4efb\u52a1\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b54\u4e2a\u8de87\u4e2a\u9886\u57df\u548c\u6a21\u6001\u7684\u4efb\u52a1\uff0c\u5e76\u63d0\u51fa\u4e86\u8861\u91cf\u7ecf\u6d4e\u6536\u76ca\u7684alpha-value\u6307\u6807\u3002", "motivation": "\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u5f88\u5c11\u8bc4\u4f30\u4ee3\u7801\u4ee3\u7406\u5728\u771f\u5b9e\u5de5\u4f5c\u6d41\u9a71\u52a8\u7684GitHub\u4ed3\u5e93\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u6765\u63a8\u52a8\u4ee3\u7801\u4ee3\u7406\u5728\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u6784\u5efa\u5305\u542b54\u4e2a\u771f\u5b9e\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bcf\u4e2a\u4efb\u52a1\u914d\u6709\u5173\u8054\u7684\u4ee3\u7801\u4ed3\u5e93\u548c\u81ea\u52a8\u5316\u8bc4\u4f30\u5de5\u5177\uff0c\u4f7f\u7528alpha-value\u6307\u6807\u7efc\u5408\u8bc4\u4f30\u4efb\u52a1\u6210\u529f\u7387\u3001token\u6210\u672c\u548c\u5f00\u53d1\u8005\u85aa\u8d44\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5373\u4f7f\u6700\u4f73\u7cfb\u7edf(OpenHands+Claude 3.7)\u4e5f\u53ea\u80fd\u89e3\u51b348.15%\u7684\u4efb\u52a1\uff0c\u8d85\u8fc7\u4e00\u534a\u7684\u5931\u8d25\u6e90\u4e8e\u73af\u5883\u8bbe\u7f6e\u548c\u4f9d\u8d56\u89e3\u6790\u7b49\u57fa\u7840\u6b65\u9aa4\u3002", "conclusion": "\u4ee3\u7801\u4ee3\u7406\u5728\u5904\u7406\u590d\u6742\u4ed3\u5e93\u4efb\u52a1\u65f6\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u5de5\u4f5c\u6d41\u7ba1\u7406\u548c\u8d85\u65f6\u51c6\u5907\uff0cGitTaskBench\u7684\u53d1\u5e03\u65e8\u5728\u63a8\u52a8\u4ed3\u5e93\u611f\u77e5\u7684\u4ee3\u7801\u63a8\u7406\u548c\u6267\u884c\u80fd\u529b\u53d1\u5c55\u3002"}}
{"id": "2508.18527", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18527", "abs": "https://arxiv.org/abs/2508.18527", "authors": ["Kaijie Xu", "Clark Verbrugge"], "title": "Generic Guard AI in Stealth Game with Composite Potential Fields", "comment": null, "summary": "Guard patrol behavior is central to the immersion and strategic depth of\nstealth games, while most existing systems rely on hand-crafted routes or\nspecialized logic that struggle to balance coverage efficiency and responsive\npursuit with believable naturalness. We propose a generic, fully explainable,\ntraining-free framework that integrates global knowledge and local information\nvia Composite Potential Fields, combining three interpretable maps-Information,\nConfidence, and Connectivity-into a single kernel-filtered decision criterion.\nOur parametric, designer-driven approach requires only a handful of decay and\nweight parameters-no retraining-to smoothly adapt across both occupancy-grid\nand NavMesh-partition abstractions. We evaluate on five representative game\nmaps, two player-control policies, and five guard modes, confirming that our\nmethod outperforms classical baseline methods in both capture efficiency and\npatrol naturalness. Finally, we show how common stealth mechanics-distractions\nand environmental elements-integrate naturally into our framework as sub\nmodules, enabling rapid prototyping of rich, dynamic, and responsive guard\nbehaviors.", "AI": {"tldr": "\u57fa\u4e8e\u590d\u5408\u6f5c\u529b\u573a\u7684\u901a\u7528\u53ef\u89e3\u91ca\u5e1d\u56fd\u5de1\u9032\u884c\u4e3a\u6846\u67b6\uff0c\u7ed3\u5408\u5168\u5c40\u77e5\u8bc6\u548c\u5c40\u90e8\u4fe1\u606f\uff0c\u5728\u4e0d\u9700\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u6355\u6349\u548c\u81ea\u7136\u5de1\u9032\u884c\u4e3a", "motivation": "\u89e3\u51b3\u9690\u85cf\u6e38\u620f\u4e2d\u5e1d\u56fd\u5de1\u9032\u884c\u4e3a\u5b58\u5728\u7684\u95ee\u9898\uff1a\u624b\u52a8\u8bbe\u8ba1\u8def\u7ebf\u6216\u4e13\u95e8\u903b\u8f91\u96be\u4ee5\u5e73\u8861\u8986\u76d6\u6548\u7387\u3001\u54cd\u5e94\u8ffd\u8e2a\u548c\u81ea\u7136\u6027", "method": "\u4f7f\u7528\u590d\u5408\u6f5c\u529b\u573a\u6846\u67b6\uff0c\u7ec4\u5408\u4e09\u4e2a\u53ef\u89e3\u91ca\u5730\u56fe\uff08\u4fe1\u606f\u5730\u56fe\u3001\u4fe1\u5fc3\u5730\u56fe\u3001\u8fde\u901a\u6027\u5730\u56fe\uff09\u901a\u8fc7\u5185\u6838\u7b5b\u6ce2\u8fdb\u884c\u51b3\u7b56\uff0c\u53c2\u6570\u5316\u8bbe\u8ba1\u53ea\u9700\u5c11\u91cf\u8870\u51cf\u548c\u6743\u91cd\u53c2\u6570", "result": "\u57285\u4e2a\u4ee3\u8868\u6027\u6e38\u620f\u5730\u56fe\u30012\u79cd\u73a9\u5bb6\u63a7\u5236\u7b56\u7565\u548c5\u79cd\u5e1d\u56fd\u6a21\u5f0f\u4e0b\u8bc4\u6d4b\uff0c\u8bc1\u5b9e\u5728\u6355\u6349\u6548\u7387\u548c\u5de1\u9032\u81ea\u7136\u6027\u65b9\u9762\u8d85\u8fc7\u4f20\u7edf\u57fa\u51c6\u65b9\u6cd5", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u9ad8\u6548\u81ea\u7136\u7684\u5e1d\u56fd\u5de1\u9032\u884c\u4e3a\uff0c\u8fd8\u80fd\u81ea\u7136\u96c6\u6210\u5e38\u89c1\u9690\u85cf\u673a\u5236\uff08\u5206\u6563\u6ce8\u610f\u529b\u548c\u73af\u5883\u5143\u7d20\uff09\uff0c\u652f\u6301\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u4e30\u5bcc\u52a8\u6001\u7684\u5e1d\u56fd\u884c\u4e3a"}}
{"id": "2508.18750", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.18750", "abs": "https://arxiv.org/abs/2508.18750", "authors": ["Zeng Zhang", "Xiaoqi Li"], "title": "Immutable Digital Recognition via Blockchain", "comment": null, "summary": "The process integrates the decentralised management and centralised operation\nmodels, aligning them with the national policy directives. The developed\nsolution enables the full utilisation of blockchain technology's advantages\nwhile also fostering community participation. Consequently, it establishes a\nsecure, legal, reliable, and dynamic electronic certification system.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53bb\u4e2d\u5fc3\u5316\u7ba1\u7406\u4e0e\u96c6\u4e2d\u8fd0\u8425\u6a21\u5f0f\u7684\u533a\u5757\u94fe\u7535\u5b50\u8ba4\u8bc1\u7cfb\u7edf\uff0c\u7b26\u5408\u56fd\u5bb6\u653f\u7b56\u5bfc\u5411\uff0c\u5b9e\u73b0\u5b89\u5168\u53ef\u9760\u7684\u6cd5\u5f8b\u8ba4\u8bc1\u4f53\u7cfb", "motivation": "\u6574\u5408\u53bb\u4e2d\u5fc3\u5316\u7ba1\u7406\u548c\u96c6\u4e2d\u8fd0\u8425\u6a21\u5f0f\uff0c\u4f7f\u5176\u7b26\u5408\u56fd\u5bb6\u653f\u7b56\u6307\u5bfc\uff0c\u5145\u5206\u5229\u7528\u533a\u5757\u94fe\u6280\u672f\u4f18\u52bf\u5e76\u4fc3\u8fdb\u793e\u533a\u53c2\u4e0e", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u96c6\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u5c06\u533a\u5757\u94fe\u6280\u672f\u7684\u53bb\u4e2d\u5fc3\u5316\u7279\u6027\u4e0e\u96c6\u4e2d\u8fd0\u8425\u6a21\u5f0f\u76f8\u7ed3\u5408", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u5b89\u5168\u3001\u5408\u6cd5\u3001\u53ef\u9760\u4e14\u52a8\u6001\u7684\u7535\u5b50\u8ba4\u8bc1\u7cfb\u7edf", "conclusion": "\u8be5\u89e3\u51b3\u65b9\u6848\u6210\u529f\u5b9e\u73b0\u4e86\u533a\u5757\u94fe\u6280\u672f\u4f18\u52bf\u7684\u5145\u5206\u5229\u7528\uff0c\u540c\u65f6\u4fc3\u8fdb\u4e86\u793e\u533a\u53c2\u4e0e\uff0c\u4e3a\u7535\u5b50\u8ba4\u8bc1\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u6846\u67b6"}}
{"id": "2508.19056", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.19056", "abs": "https://arxiv.org/abs/2508.19056", "authors": ["S. Panda", "D. Munjal", "D. P. Mohapatra"], "title": "A Slice-Based Change Impact Analysis for Regression Test Case Prioritization of Object-Oriented Programs", "comment": null, "summary": "Test case prioritization focuses on finding a suitable order of execution of\nthe test cases in a test suite to meet some performance goals like detecting\nfaults early. It is likely that some test cases execute the program parts that\nare more prone to errors and will detect more errors if executed early during\nthe testing process. Finding an optimal order of execution for the selected\nregression test cases saves time and cost of retesting. This paper presents a\nstatic approach to prioritizing the test cases by computing the affected\ncomponent coupling (ACC) of the affected parts of object-oriented programs. We\nconstruct a graph named affected slice graph (ASG) to represent these affected\nprogram parts.We determine the fault-proneness of the nodes of ASG by computing\ntheir respective ACC values. We assign higher priority to those test cases that\ncover the nodes with higher ACC values. Our analysis with mutation faults shows\nthat the test cases executing the fault-prone program parts have a higher\nchance to reveal faults earlier than other test cases in the test suite. The\nresult obtained from seven case studies justifies that our approach is feasible\nand gives acceptable performance in comparison to some existing techniques.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d7\u5f71\u7ec4\u4ef6\u8026\u5408\u5ea6(ACC)\u7684\u9759\u6001\u6d4b\u8bd5\u6848\u4f8b\u4f18\u5148\u7ea7\u6392\u5e8f\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u53d7\u5f71\u5207\u7247\u56fe(ASG)\u6765\u8bc6\u522b\u6545\u969c\u5bb9\u6613\u7684\u7a0b\u5e8f\u90e8\u5206\uff0c\u5e76\u4e3a\u8986\u76d6\u9ad8ACC\u503c\u8282\u70b9\u7684\u6d4b\u8bd5\u6848\u4f8b\u8d4b\u4e88\u66f4\u9ad8\u4f18\u5148\u7ea7\u3002", "motivation": "\u6d4b\u8bd5\u6848\u4f8b\u4f18\u5148\u7ea7\u6392\u5e8f\u53ef\u4ee5\u901a\u8fc7\u65e9\u671f\u68c0\u6d4b\u6545\u969c\u6765\u8282\u7701\u91cd\u6d4b\u65f6\u95f4\u548c\u6210\u672c\u3002\u4f46\u662f\u9700\u8981\u627e\u5230\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u8bc6\u522b\u54ea\u4e9b\u6d4b\u8bd5\u6848\u4f8b\u66f4\u53ef\u80fd\u6267\u884c\u5bb9\u6613\u51fa\u9519\u7684\u7a0b\u5e8f\u90e8\u5206\u3002", "method": "\u6784\u5efa\u53d7\u5f71\u5207\u7247\u56fe(ASG)\u6765\u8868\u793a\u53d7\u5f71\u7684\u7a0b\u5e8f\u90e8\u5206\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u8282\u70b9\u7684\u53d7\u5f71\u7ec4\u4ef6\u8026\u5408\u5ea6(ACC)\u503c\u6765\u8bc4\u4f30\u6545\u969c\u5bb9\u6613\u7a0b\u5ea6\uff0c\u7136\u540e\u4e3a\u8986\u76d6\u9ad8ACC\u503c\u8282\u70b9\u7684\u6d4b\u8bd5\u6848\u4f8b\u8d4b\u4e88\u66f4\u9ad8\u4f18\u5148\u7ea7\u3002", "result": "\u901a\u8fc7\u7b5b\u9009\u53d8\u5f02\u6545\u969c\u7684\u5206\u6790\u663e\u793a\uff0c\u6267\u884c\u6545\u969c\u5bb9\u6613\u7a0b\u5e8f\u90e8\u5206\u7684\u6d4b\u8bd5\u6848\u4f8b\u66f4\u6709\u53ef\u80fd\u65e9\u671f\u53d1\u73b0\u6545\u969c\u3002\u4e03\u4e2a\u6848\u4f8b\u7814\u7a76\u7684\u7ed3\u679c\u8bc1\u660e\u8be5\u65b9\u6cd5\u53ef\u884c\u4e14\u6548\u679c\u8d85\u8fc7\u4e00\u4e9b\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u57fa\u4e8eACC\u7684\u9759\u6001\u6d4b\u8bd5\u6848\u4f8b\u4f18\u5148\u7ea7\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522b\u6545\u969c\u5bb9\u6613\u7684\u7a0b\u5e8f\u90e8\u5206\uff0c\u5e76\u901a\u8fc7\u4f18\u5148\u6267\u884c\u76f8\u5173\u6d4b\u8bd5\u6848\u4f8b\u6765\u63d0\u9ad8\u6545\u969c\u68c0\u6d4b\u6548\u7387\uff0c\u4ece\u800c\u8282\u7701\u91cd\u6d4b\u65f6\u95f4\u548c\u6210\u672c\u3002"}}
{"id": "2508.18533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18533", "abs": "https://arxiv.org/abs/2508.18533", "authors": ["Kaijie Xu", "Clark Verbrugge"], "title": "A Database-Driven Framework for 3D Level Generation with LLMs", "comment": null, "summary": "Procedural Content Generation for 3D game levels faces challenges in\nbalancing spatial coherence, navigational functionality, and adaptable gameplay\nprogression across multi-floor environments. This paper introduces a novel\nframework for generating such levels, centered on the offline, LLM-assisted\nconstruction of reusable databases for architectural components (facilities and\nroom templates) and gameplay mechanic elements. Our multi-phase pipeline\nassembles levels by: (1) selecting and arranging instances from the Room\nDatabase to form a multi-floor global structure with an inherent topological\norder; (2) optimizing the internal layout of facilities for each room based on\npredefined constraints from the Facility Database; and (3) integrating\nprogression-based gameplay mechanics by placing components from a Mechanics\nDatabase according to their topological and spatial rules. A subsequent\ntwo-phase repair system ensures navigability. This approach combines modular,\ndatabase-driven design with constraint-based optimization, allowing for\nsystematic control over level structure and the adaptable pacing of gameplay\nelements. Initial experiments validate the framework's ability in generating\ndiverse, navigable 3D environments and its capability to simulate distinct\ngameplay pacing strategies through simple parameterization. This research\nadvances PCG by presenting a scalable, database-centric foundation for the\nautomated generation of complex 3D levels with configurable gameplay\nprogression.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u8f85\u52a9\u6784\u5efa\u53ef\u91cd\u7528\u6570\u636e\u5e93\u76843D\u6e38\u620f\u5173\u5361\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u6d41\u7a0b\u7ec4\u88c5\u5173\u5361\uff0c\u7ed3\u5408\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u7ea6\u675f\u4f18\u5316\uff0c\u5b9e\u73b0\u53ef\u5bfc\u822a3D\u73af\u5883\u548c\u53ef\u914d\u7f6e\u6e38\u620f\u8fdb\u7a0b\u7684\u751f\u6210\u3002", "motivation": "\u89e3\u51b33D\u6e38\u620f\u5173\u5361\u751f\u6210\u4e2d\u7a7a\u95f4\u8fde\u8d2f\u6027\u3001\u5bfc\u822a\u529f\u80fd\u548c\u53ef\u9002\u5e94\u6e38\u620f\u8fdb\u7a0b\u5e73\u8861\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u591a\u5c42\u73af\u5883\u4e2d\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a1\uff09\u4ece\u623f\u95f4\u6570\u636e\u5e93\u9009\u62e9\u548c\u6392\u5217\u5b9e\u4f8b\u5f62\u6210\u591a\u5c42\u5168\u5c40\u7ed3\u6784\uff1b2\uff09\u57fa\u4e8e\u8bbe\u65bd\u6570\u636e\u5e93\u7ea6\u675f\u4f18\u5316\u623f\u95f4\u5185\u90e8\u5e03\u5c40\uff1b3\uff09\u6839\u636e\u62d3\u6251\u548c\u7a7a\u95f4\u89c4\u5219\u6574\u5408\u6e38\u620f\u673a\u5236\u7ec4\u4ef6\u3002\u540e\u7eed\u91c7\u7528\u4e24\u9636\u6bb5\u4fee\u590d\u7cfb\u7edf\u786e\u4fdd\u53ef\u5bfc\u822a\u6027\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u751f\u6210\u591a\u6837\u5316\u3001\u53ef\u5bfc\u822a3D\u73af\u5883\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u901a\u8fc7\u7b80\u5355\u53c2\u6570\u5316\u6a21\u62df\u4e0d\u540c\u6e38\u620f\u8282\u594f\u7b56\u7565\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u63d0\u51fa\u53ef\u6269\u5c55\u7684\u3001\u4ee5\u6570\u636e\u5e93\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u63a8\u8fdb\u4e86\u7a0b\u5e8f\u5316\u5185\u5bb9\u751f\u6210\u6280\u672f\uff0c\u4e3a\u81ea\u52a8\u5316\u751f\u6210\u5177\u6709\u53ef\u914d\u7f6e\u6e38\u620f\u8fdb\u7a0b\u7684\u590d\u67423D\u5173\u5361\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.18805", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.18805", "abs": "https://arxiv.org/abs/2508.18805", "authors": ["Rui Zhang", "Zihan Wang", "Tianli Yang", "Hongwei Li", "Wenbo Jiang", "Qingchuan Zhao", "Yang Liu", "Guowen Xu"], "title": "Hidden Tail: Adversarial Image Causing Stealthy Resource Consumption in Vision-Language Models", "comment": null, "summary": "Vision-Language Models (VLMs) are increasingly deployed in real-world\napplications, but their high inference cost makes them vulnerable to resource\nconsumption attacks. Prior attacks attempt to extend VLM output sequences by\noptimizing adversarial images, thereby increasing inference costs. However,\nthese extended outputs often introduce irrelevant abnormal content,\ncompromising attack stealthiness. This trade-off between effectiveness and\nstealthiness poses a major limitation for existing attacks. To address this\nchallenge, we propose \\textit{Hidden Tail}, a stealthy resource consumption\nattack that crafts prompt-agnostic adversarial images, inducing VLMs to\ngenerate maximum-length outputs by appending special tokens invisible to users.\nOur method employs a composite loss function that balances semantic\npreservation, repetitive special token induction, and suppression of the\nend-of-sequence (EOS) token, optimized via a dynamic weighting strategy.\nExtensive experiments show that \\textit{Hidden Tail} outperforms existing\nattacks, increasing output length by up to 19.2$\\times$ and reaching the\nmaximum token limit, while preserving attack stealthiness. These results\nhighlight the urgent need to improve the robustness of VLMs against\nefficiency-oriented adversarial threats. Our code is available at\nhttps://github.com/zhangrui4041/Hidden_Tail.", "AI": {"tldr": "Hidden Tail\u662f\u4e00\u79cd\u9488\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9690\u853d\u8d44\u6e90\u6d88\u8017\u653b\u51fb\uff0c\u901a\u8fc7\u751f\u6210\u5bf9\u6297\u56fe\u50cf\u8bf1\u5bfc\u6a21\u578b\u8f93\u51fa\u6700\u5927\u957f\u5ea6\u7684\u9690\u85cf\u7279\u6b8a\u6807\u8bb0\uff0c\u5728\u4fdd\u6301\u653b\u51fb\u9690\u853d\u6027\u7684\u540c\u65f6\u5927\u5e45\u589e\u52a0\u63a8\u7406\u6210\u672c", "motivation": "\u73b0\u6709VLM\u8d44\u6e90\u6d88\u8017\u653b\u51fb\u5728\u5ef6\u957f\u8f93\u51fa\u5e8f\u5217\u65f6\u4f1a\u4ea7\u751f\u4e0d\u76f8\u5173\u7684\u5f02\u5e38\u5185\u5bb9\uff0c\u7834\u574f\u4e86\u653b\u51fb\u7684\u9690\u853d\u6027\uff0c\u9700\u8981\u5728\u6709\u6548\u6027\u548c\u9690\u853d\u6027\u4e4b\u95f4\u505a\u51fa\u6743\u8861", "method": "\u4f7f\u7528\u590d\u5408\u635f\u5931\u51fd\u6570\u5e73\u8861\u8bed\u4e49\u4fdd\u6301\u3001\u91cd\u590d\u7279\u6b8a\u6807\u8bb0\u8bf1\u5bfc\u548c\u6291\u5236\u7ed3\u675f\u6807\u8bb0\uff0c\u901a\u8fc7\u52a8\u6001\u6743\u91cd\u7b56\u7565\u4f18\u5316\u751f\u6210\u5bf9\u6297\u56fe\u50cf", "result": "\u5b9e\u9a8c\u663e\u793aHidden Tail\u5c06\u8f93\u51fa\u957f\u5ea6\u63d0\u5347\u8fbe19.2\u500d\uff0c\u8fbe\u5230\u6700\u5927\u6807\u8bb0\u9650\u5236\uff0c\u540c\u65f6\u4fdd\u6301\u653b\u51fb\u9690\u853d\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86VLM\u5728\u6548\u7387\u5bfc\u5411\u5bf9\u6297\u5a01\u80c1\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u8feb\u5207\u9700\u8981\u63d0\u9ad8\u6a21\u578b\u5bf9\u6b64\u7c7b\u653b\u51fb\u7684\u9c81\u68d2\u6027"}}
{"id": "2508.18554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18554", "abs": "https://arxiv.org/abs/2508.18554", "authors": ["Lily Jiaxin Wan", "Chia-Tung Ho", "Rongjian Liang", "Cunxi Yu", "Deming Chen", "Haoxing Ren"], "title": "SchemaCoder: Automatic Log Schema Extraction Coder with Residual Q-Tree Boosting", "comment": "18 pages, 16 figures, under review for AAAI2026", "summary": "Log schema extraction is the process of deriving human-readable templates\nfrom massive volumes of log data, which is essential yet notoriously\nlabor-intensive. Recent studies have attempted to streamline this task by\nleveraging Large Language Models (LLMs) for automated schema extraction.\nHowever, existing methods invariably rely on predefined regular expressions,\nnecessitating human domain expertise and severely limiting productivity gains.\nTo fundamentally address this limitation, we introduce SchemaCoder, the first\nfully automated schema extraction framework applicable to a wide range of log\nfile formats without requiring human customization within the flow. At its\ncore, SchemaCoder features a novel Residual Question-Tree (Q-Tree) Boosting\nmechanism that iteratively refines schema extraction through targeted, adaptive\nqueries driven by LLMs. Particularly, our method partitions logs into semantic\nchunks via context-bounded segmentation, selects representative patterns using\nembedding-based sampling, and generates schema code through hierarchical\nQ-Tree-driven LLM queries, iteratively refined by our textual-residual\nevolutionary optimizer and residual boosting. Experimental validation\ndemonstrates SchemaCoder's superiority on the widely-used LogHub-2.0 benchmark,\nachieving an average improvement of 21.3% over state-of-the-arts.", "AI": {"tldr": "SchemaCoder\u662f\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u65e5\u5fd7\u6a21\u5f0f\u63d0\u53d6\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6b8b\u5dee\u95ee\u9898\u6811\u589e\u5f3a\u673a\u5236\uff0c\u65e0\u9700\u4eba\u5de5\u5b9a\u5236\u5373\u53ef\u5904\u7406\u5404\u79cd\u65e5\u5fd7\u683c\u5f0f\uff0c\u5728LogHub-2.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u5e73\u5747\u63d0\u534721.3%\u3002", "motivation": "\u73b0\u6709\u65e5\u5fd7\u6a21\u5f0f\u63d0\u53d6\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u6b63\u5219\u8868\u8fbe\u5f0f\uff0c\u9700\u8981\u4eba\u5de5\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e25\u91cd\u9650\u5236\u4e86\u751f\u4ea7\u6548\u7387\u3002\u9700\u8981\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u6a21\u5f0f\u63d0\u53d6\u3002", "method": "\u91c7\u7528\u6b8b\u5dee\u95ee\u9898\u6811\u589e\u5f3a\u673a\u5236\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u8fb9\u754c\u5206\u5272\u5c06\u65e5\u5fd7\u5206\u6210\u8bed\u4e49\u5757\uff0c\u4f7f\u7528\u57fa\u4e8e\u5d4c\u5165\u7684\u91c7\u6837\u9009\u62e9\u4ee3\u8868\u6027\u6a21\u5f0f\uff0c\u901a\u8fc7\u5206\u5c42\u95ee\u9898\u6811\u9a71\u52a8\u7684LLM\u67e5\u8be2\u751f\u6210\u6a21\u5f0f\u4ee3\u7801\uff0c\u5e76\u901a\u8fc7\u6587\u672c\u6b8b\u5dee\u8fdb\u5316\u4f18\u5316\u5668\u548c\u6b8b\u5dee\u589e\u5f3a\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684LogHub-2.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSchemaCoder\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5e73\u5747\u63d0\u534721.3%\u3002", "conclusion": "SchemaCoder\u662f\u7b2c\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u6a21\u5f0f\u63d0\u53d6\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u5404\u79cd\u65e5\u5fd7\u6587\u4ef6\u683c\u5f0f\u800c\u65e0\u9700\u4eba\u5de5\u5b9a\u5236\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6b8b\u5dee\u95ee\u9898\u6811\u589e\u5f3a\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u65e5\u5fd7\u6a21\u5f0f\u63d0\u53d6\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2508.18832", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.18832", "abs": "https://arxiv.org/abs/2508.18832", "authors": ["Sara Saeidian", "Ata Yavuzy\u0131lmaz", "Leonhard Grosse", "Georg Schuppe", "Tobias J. Oechtering"], "title": "A Tight Context-aware Privacy Bound for Histogram Publication", "comment": "Submitted to IEEE Signal Processing Letters", "summary": "We analyze the privacy guarantees of the Laplace mechanism releasing the\nhistogram of a dataset through the lens of pointwise maximal leakage (PML).\nWhile differential privacy is commonly used to quantify the privacy loss, it is\na context-free definition that does not depend on the data distribution. In\ncontrast, PML enables a more refined analysis by incorporating assumptions\nabout the data distribution. We show that when the probability of each\nhistogram bin is bounded away from zero, stronger privacy protection can be\nachieved for a fixed level of noise. Our results demonstrate the advantage of\ncontext-aware privacy measures and show that incorporating assumptions about\nthe data can improve privacy-utility tradeoffs.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u70b9\u6001\u6700\u5927\u6cc4\u6f0f(PML)\u5206\u6790\u62c9\u666e\u62c9\u65af\u673a\u5236\u53d1\u5e03\u6570\u636e\u96c6\u76f4\u65b9\u56fe\u7684\u9690\u79c1\u4fdd\u8bc1\uff0c\u53d1\u73b0\u5728\u76f4\u65b9\u56fe\u5404\u6876\u6982\u7387\u8fdc\u79bb\u96f6\u65f6\uff0c\u56fa\u5b9a\u566a\u58f0\u6c34\u5e73\u4e0b\u53ef\u83b7\u5f97\u66f4\u5f3a\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u5dee\u5206\u9690\u79c1\u662f\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u5b9a\u4e49\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u6570\u636e\u5206\u5e03\u3002PML\u80fd\u591f\u901a\u8fc7\u7eb3\u5165\u6570\u636e\u5206\u5e03\u5047\u8bbe\u8fdb\u884c\u66f4\u7cbe\u7ec6\u7684\u9690\u79c1\u5206\u6790\uff0c\u63a2\u7d22\u5728\u6570\u636e\u5206\u5e03\u5df2\u77e5\u60c5\u51b5\u4e0b\u80fd\u5426\u83b7\u5f97\u66f4\u597d\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002", "method": "\u4f7f\u7528\u70b9\u6001\u6700\u5927\u6cc4\u6f0f(PML)\u4f5c\u4e3a\u9690\u79c1\u5ea6\u91cf\u6846\u67b6\uff0c\u5206\u6790\u62c9\u666e\u62c9\u65af\u673a\u5236\u5728\u53d1\u5e03\u6570\u636e\u96c6\u76f4\u65b9\u56fe\u65f6\u7684\u9690\u79c1\u4fdd\u8bc1\uff0c\u7279\u522b\u5173\u6ce8\u5f53\u76f4\u65b9\u56fe\u5404\u6876\u6982\u7387\u6709\u4e0b\u754c\u65f6\u7684\u60c5\u51b5\u3002", "result": "\u7814\u7a76\u8bc1\u660e\u5f53\u76f4\u65b9\u56fe\u5404\u6876\u6982\u7387\u8fdc\u79bb\u96f6\u65f6\uff0c\u5728\u76f8\u540c\u7684\u566a\u58f0\u6c34\u5e73\u4e0b\u53ef\u4ee5\u83b7\u5f97\u6bd4\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u66f4\u5f3a\u7684\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u9690\u79c1\u5ea6\u91cf\u5177\u6709\u4f18\u52bf\uff0c\u7eb3\u5165\u6570\u636e\u5206\u5e03\u5047\u8bbe\u53ef\u4ee5\u6539\u5584\u9690\u79c1-\u6548\u7528\u6743\u8861\uff0c\u4e3a\u5b9e\u9645\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2508.18608", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18608", "abs": "https://arxiv.org/abs/2508.18608", "authors": ["Janet Wang", "Xin Hu", "Yunbei Zhang", "Diabate Almamy", "Vagamon Bamba", "Konan Amos S\u00e9bastien Koffi", "Yao Koffi Aubin", "Zhengming Ding", "Jihun Hamm", "Rie R. Yotsu"], "title": "eSkinHealth: A Multimodal Dataset for Neglected Tropical Skin Diseases", "comment": null, "summary": "Skin Neglected Tropical Diseases (NTDs) impose severe health and\nsocioeconomic burdens in impoverished tropical communities. Yet, advancements\nin AI-driven diagnostic support are hindered by data scarcity, particularly for\nunderrepresented populations and rare manifestations of NTDs. Existing\ndermatological datasets often lack the demographic and disease spectrum crucial\nfor developing reliable recognition models of NTDs. To address this, we\nintroduce eSkinHealth, a novel dermatological dataset collected on-site in\nC\\^ote d'Ivoire and Ghana. Specifically, eSkinHealth contains 5,623 images from\n1,639 cases and encompasses 47 skin diseases, focusing uniquely on skin NTDs\nand rare conditions among West African populations. We further propose an\nAI-expert collaboration paradigm to implement foundation language and\nsegmentation models for efficient generation of multimodal annotations, under\ndermatologists' guidance. In addition to patient metadata and diagnosis labels,\neSkinHealth also includes semantic lesion masks, instance-specific visual\ncaptions, and clinical concepts. Overall, our work provides a valuable new\nresource and a scalable annotation framework, aiming to catalyze the\ndevelopment of more equitable, accurate, and interpretable AI tools for global\ndermatology.", "AI": {"tldr": "eSkinHealth\u662f\u4e00\u4e2a\u65b0\u7684\u76ae\u80a4\u75c5\u6570\u636e\u96c6\uff0c\u4e13\u6ce8\u4e8e\u897f\u975e\u4eba\u7fa4\u7684\u76ae\u80a4\u88ab\u5ffd\u89c6\u70ed\u5e26\u75c5\u548c\u7f55\u89c1\u75c5\u75c7\uff0c\u5305\u542b5623\u5f20\u56fe\u50cf\u548c47\u79cd\u76ae\u80a4\u75be\u75c5\uff0c\u91c7\u7528AI-\u4e13\u5bb6\u534f\u4f5c\u8303\u5f0f\u751f\u6210\u591a\u6a21\u6001\u6807\u6ce8", "motivation": "\u76ae\u80a4\u88ab\u5ffd\u89c6\u70ed\u5e26\u75c5(NTDs)\u5728\u8d2b\u56f0\u70ed\u5e26\u793e\u533a\u9020\u6210\u4e25\u91cd\u5065\u5eb7\u548c\u793e\u4f1a\u7ecf\u6d4e\u8d1f\u62c5\uff0c\u4f46AI\u8bca\u65ad\u53d1\u5c55\u53d7\u9650\u4e8e\u6570\u636e\u7a00\u7f3a\uff0c\u7279\u522b\u662f\u5bf9\u4ee3\u8868\u6027\u4e0d\u8db3\u4eba\u7fa4\u548c\u7f55\u89c1\u75c5\u75c7\u7684\u6570\u636e\u7f3a\u4e4f", "method": "\u5728\u79d1\u7279\u8fea\u74e6\u548c\u52a0\u7eb3\u73b0\u573a\u6536\u96c6\u6570\u636e\uff0c\u63d0\u51faAI-\u4e13\u5bb6\u534f\u4f5c\u8303\u5f0f\uff0c\u5229\u7528\u57fa\u7840\u8bed\u8a00\u548c\u5206\u5272\u6a21\u578b\u5728\u76ae\u80a4\u79d1\u533b\u751f\u6307\u5bfc\u4e0b\u9ad8\u6548\u751f\u6210\u591a\u6a21\u6001\u6807\u6ce8\uff0c\u5305\u62ec\u8bed\u4e49\u75c5\u53d8\u63a9\u7801\u3001\u89c6\u89c9\u63cf\u8ff0\u548c\u4e34\u5e8a\u6982\u5ff5", "result": "\u521b\u5efa\u4e86\u5305\u542b5623\u5f20\u56fe\u50cf\u30011639\u4e2a\u75c5\u4f8b\u300147\u79cd\u76ae\u80a4\u75be\u75c5\u7684eSkinHealth\u6570\u636e\u96c6\uff0c\u7279\u522b\u5173\u6ce8\u897f\u975e\u4eba\u7fa4\u7684\u76ae\u80a4NTDs\u548c\u7f55\u89c1\u75c5\u75c7", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u65b0\u8d44\u6e90\u548c\u53ef\u6269\u5c55\u7684\u6807\u6ce8\u6846\u67b6\uff0c\u65e8\u5728\u4fc3\u8fdb\u5f00\u53d1\u66f4\u516c\u5e73\u3001\u51c6\u786e\u548c\u53ef\u89e3\u91ca\u7684\u5168\u7403\u76ae\u80a4\u75c5AI\u5de5\u5177"}}
{"id": "2508.18942", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.18942", "abs": "https://arxiv.org/abs/2508.18942", "authors": ["Ahmed Mounsf Rafik Bendada", "Yacine Ghamri-Doudane"], "title": "EnerSwap: Large-Scale, Privacy-First Automated Market Maker for V2G Energy Trading", "comment": "11 pages, 7 figures, 1 table, 1 algorithm, Paper accepted in 27th\n  MSWiM Conference", "summary": "With the rapid growth of Electric Vehicle (EV) technology, EVs are destined\nto shape the future of transportation. The large number of EVs facilitates the\ndevelopment of the emerging vehicle-to-grid (V2G) technology, which realizes\nbidirectional energy exchanges between EVs and the power grid. This has led to\nthe setting up of electricity markets that are usually confined to a small\ngeographical location, often with a small number of participants. Usually,\nthese markets are manipulated by intermediaries responsible for collecting bids\nfrom prosumers, determining the market-clearing price, incorporating grid\nconstraints, and accounting for network losses. While centralized models can be\nhighly efficient, they grant excessive power to the intermediary by allowing\nthem to gain exclusive access to prosumers \\textquotesingle price preferences.\nThis opens the door to potential market manipulation and raises significant\nprivacy concerns for users, such as the location of energy providers. This lack\nof protection exposes users to potential risks, as untrustworthy servers and\nmalicious adversaries can exploit this information to infer trading activities\nand real identities. This work proposes a secure, decentralized exchange market\nbuilt on blockchain technology, utilizing a privacy-preserving Automated Market\nMaker (AMM) model to offer open and fair, and equal access to traders, and\nmitigates the most common trading-manipulation attacks. Additionally, it\nincorporates a scalable architecture based on geographical dynamic sharding,\nallowing for efficient resource allocation and improved performance as the\nmarket grows.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u7535\u52a8\u6c7d\u8f66V2G\u7535\u529b\u4ea4\u6613\u5e02\u573a\uff0c\u91c7\u7528\u9690\u79c1\u4fdd\u62a4AMM\u6a21\u578b\u9632\u6b62\u5e02\u573a\u64cd\u7eb5\u548c\u9690\u79c1\u6cc4\u9732\uff0c\u5e76\u901a\u8fc7\u5730\u7406\u52a8\u6001\u5206\u7247\u5b9e\u73b0\u53ef\u6269\u5c55\u6027", "motivation": "\u4f20\u7edf\u96c6\u4e2d\u5f0fV2G\u7535\u529b\u5e02\u573a\u5b58\u5728\u4e2d\u4ecb\u5784\u65ad\u3001\u5e02\u573a\u64cd\u7eb5\u98ce\u9669\u548c\u7528\u6237\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u9700\u8981\u53bb\u4e2d\u5fc3\u5316\u89e3\u51b3\u65b9\u6848", "method": "\u5229\u7528\u533a\u5757\u94fe\u6280\u672f\u6784\u5efa\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6613\u5e02\u573a\uff0c\u91c7\u7528\u9690\u79c1\u4fdd\u62a4\u81ea\u52a8\u5316\u505a\u5e02\u5546(AMM)\u6a21\u578b\uff0c\u7ed3\u5408\u5730\u7406\u52a8\u6001\u5206\u7247\u67b6\u6784\u5b9e\u73b0\u53ef\u6269\u5c55\u6027", "result": "\u5efa\u7acb\u4e86\u5f00\u653e\u3001\u516c\u5e73\u7684\u4ea4\u6613\u73af\u5883\uff0c\u6709\u6548\u7f13\u89e3\u5e38\u89c1\u4ea4\u6613\u64cd\u7eb5\u653b\u51fb\uff0c\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u4fe1\u606f\u5982\u4f4d\u7f6e\u6570\u636e\u548c\u4ea4\u6613\u6d3b\u52a8", "conclusion": "\u533a\u5757\u94fe\u548c\u9690\u79c1\u4fdd\u62a4AMM\u6a21\u578b\u4e3aV2G\u7535\u529b\u4ea4\u6613\u63d0\u4f9b\u4e86\u5b89\u5168\u3001\u53bb\u4e2d\u5fc3\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u52a8\u6001\u5206\u7247\u67b6\u6784\u786e\u4fdd\u4e86\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027"}}
{"id": "2508.19219", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.19219", "abs": "https://arxiv.org/abs/2508.19219", "authors": ["Faezeh Dehghan Tarzjani", "Mostafa Salehi"], "title": "An Efficient Lightweight Blockchain for Decentralized IoT", "comment": null, "summary": "The Internet of Things (IoT) is applied in various fields, and the number of\nphysical devices connected to the IoT is increasingly growing. There are\nsignificant challenges to the IoT's growth and development, mainly due to the\ncentralized nature and large-scale IoT networks. The emphasis on the\ndecentralization of IoT's architecture can overcome challenges to IoT's\ncapabilities. A promising decentralized platform for IoT is blockchain. Owing\nto IoT devices' limited resources, traditional consensus algorithms such as PoW\nand PoS in the blockchain are computationally expensive. Therefore, the PoA\nconsensus algorithm is proposed in the blockchain consensus network for IoT.\nThe PoA selects the validator as Turn-based selection (TBS) that needs\noptimization and faces system reliability, energy consumption, latency, and low\nscalability. We propose an efficient, lightweight blockchain for decentralizing\nIoT architecture by using virtualization and clustering to increase\nproductivity and scalability to address these issues. We also introduce a novel\nPoA based on the Weight-Based-Selection (WBS) method for validators to validate\ntransactions and add them to the blockchain. By simulation, we evaluated the\nperformance of our proposed WBS method as opposed to TBS. The results show\nreduced energy consumption, and response time, and increased throughput.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6743\u91cd\u9009\u62e9(WBS)\u7684PoA\u5171\u8bc6\u7b97\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u8f6e\u8f6c\u9009\u62e9(TBS)\u65b9\u6cd5\uff0c\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684IoT\u533a\u5757\u94fe\u7f51\u7edc\uff0c\u901a\u8fc7\u865a\u62df\u5316\u548c\u805a\u7c7b\u6280\u672f\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u8d44\u6e90\u6709\u9650\uff0c\u4f20\u7edf\u533a\u5757\u94fe\u5171\u8bc6\u7b97\u6cd5(PoW/PoS)\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709PoA\u7b97\u6cd5\u7684\u8f6e\u8f6c\u9009\u62e9\u65b9\u6cd5\u5b58\u5728\u53ef\u9760\u6027\u3001\u80fd\u8017\u3001\u5ef6\u8fdf\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u865a\u62df\u5316\u548c\u805a\u7c7b\u6280\u672f\u6784\u5efa\u8f7b\u91cf\u7ea7\u533a\u5757\u94fe\u67b6\u6784\uff0c\u63d0\u51fa\u57fa\u4e8e\u6743\u91cd\u9009\u62e9(WBS)\u7684PoA\u5171\u8bc6\u7b97\u6cd5\u6765\u9009\u62e9\u9a8c\u8bc1\u5668\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u8f6e\u8f6c\u9009\u62e9(TBS)\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0eTBS\u65b9\u6cd5\u76f8\u6bd4\uff0cWBS\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u80fd\u8017\u548c\u54cd\u5e94\u65f6\u95f4\uff0c\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684WBS-based PoA\u5171\u8bc6\u7b97\u6cd5\u4e3a\u8d44\u6e90\u53d7\u9650\u7684IoT\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u533a\u5757\u94fe\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u5171\u8bc6\u7b97\u6cd5\u7684\u6027\u80fd\u74f6\u9888\u3002"}}
{"id": "2508.18642", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18642", "abs": "https://arxiv.org/abs/2508.18642", "authors": ["Jianxing Liao", "Tian Zhang", "Xiao Feng", "Yusong Zhang", "Rui Yang", "Haorui Wang", "Bosi Wen", "Ziying Wang", "Runzhi Shi"], "title": "RLMR: Reinforcement Learning with Mixed Rewards for Creative Writing", "comment": null, "summary": "Large language models are extensively utilized in creative writing\napplications. Creative writing requires a balance between subjective writing\nquality (e.g., literariness and emotional expression) and objective constraint\nfollowing (e.g., format requirements and word limits). Existing reinforcement\nlearning methods struggle to balance these two aspects: single reward\nstrategies fail to improve both abilities simultaneously, while fixed-weight\nmixed-reward methods lack the ability to adapt to different writing scenarios.\nTo address this problem, we propose Reinforcement Learning with Mixed Rewards\n(RLMR), utilizing a dynamically mixed reward system from a writing reward model\nevaluating subjective writing quality and a constraint verification model\nassessing objective constraint following. The constraint following reward\nweight is adjusted dynamically according to the writing quality within sampled\ngroups, ensuring that samples violating constraints get negative advantage in\nGRPO and thus penalized during training, which is the key innovation of this\nproposed method. We conduct automated and manual evaluations across diverse\nmodel families from 8B to 72B parameters. Additionally, we construct a\nreal-world writing benchmark named WriteEval for comprehensive evaluation.\nResults illustrate that our method achieves consistent improvements in both\ninstruction following (IFEval from 83.36\\% to 86.65\\%) and writing quality\n(72.75\\% win rate in manual expert pairwise evaluations on WriteEval). To the\nbest of our knowledge, RLMR is the first work to combine subjective preferences\nwith objective verification in online RL training, providing an effective\nsolution for multi-dimensional creative writing optimization.", "AI": {"tldr": "RLMR\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u6df7\u5408\u5956\u52b1\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e3b\u89c2\u5199\u4f5c\u8d28\u91cf\u548c\u5ba2\u89c2\u7ea6\u675f\u9075\u5faa\u8bc4\u4f30\uff0c\u5728\u521b\u610f\u5199\u4f5c\u4e2d\u540c\u65f6\u63d0\u5347\u4e24\u4e2a\u65b9\u9762\u7684\u80fd\u529b", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5e73\u8861\u521b\u610f\u5199\u4f5c\u4e2d\u7684\u4e3b\u89c2\u8d28\u91cf\uff08\u6587\u5b66\u6027\u548c\u60c5\u611f\u8868\u8fbe\uff09\u548c\u5ba2\u89c2\u7ea6\u675f\uff08\u683c\u5f0f\u8981\u6c42\u548c\u5b57\u6570\u9650\u5236\uff09\uff0c\u5355\u5956\u52b1\u7b56\u7565\u65e0\u6cd5\u540c\u65f6\u63d0\u5347\u4e24\u79cd\u80fd\u529b\uff0c\u56fa\u5b9a\u6743\u91cd\u6df7\u5408\u5956\u52b1\u65b9\u6cd5\u7f3a\u4e4f\u9002\u5e94\u4e0d\u540c\u5199\u4f5c\u573a\u666f\u7684\u80fd\u529b", "method": "\u63d0\u51faRLMR\uff08\u6df7\u5408\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\uff09\uff0c\u4f7f\u7528\u52a8\u6001\u6df7\u5408\u5956\u52b1\u7cfb\u7edf\uff1a\u5199\u4f5c\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u4e3b\u89c2\u5199\u4f5c\u8d28\u91cf\uff0c\u7ea6\u675f\u9a8c\u8bc1\u6a21\u578b\u8bc4\u4f30\u5ba2\u89c2\u7ea6\u675f\u9075\u5faa\u3002\u7ea6\u675f\u9075\u5faa\u5956\u52b1\u6743\u91cd\u6839\u636e\u91c7\u6837\u7ec4\u5185\u7684\u5199\u4f5c\u8d28\u91cf\u52a8\u6001\u8c03\u6574\uff0c\u786e\u4fdd\u8fdd\u53cd\u7ea6\u675f\u7684\u6837\u672c\u5728GRPO\u4e2d\u83b7\u5f97\u8d1f\u4f18\u52bf\u5e76\u5728\u8bad\u7ec3\u4e2d\u88ab\u60e9\u7f5a", "result": "\u57288B\u523072B\u53c2\u6570\u7684\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u4e0a\u8fdb\u884c\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\uff0c\u6784\u5efa\u771f\u5b9e\u5199\u4f5c\u57fa\u51c6WriteEval\u3002\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u4ece83.36%\u63d0\u5347\u523086.65%\uff08IFEval\uff09\uff0c\u5199\u4f5c\u8d28\u91cf\u5728WriteEval\u4e0a\u83b7\u5f9772.75%\u7684\u80dc\u7387\uff08\u4e13\u5bb6\u4eba\u5de5\u6210\u5bf9\u8bc4\u4f30\uff09", "conclusion": "RLMR\u662f\u9996\u4e2a\u5728\u5728\u7ebfRL\u8bad\u7ec3\u4e2d\u7ed3\u5408\u4e3b\u89c2\u504f\u597d\u548c\u5ba2\u89c2\u9a8c\u8bc1\u7684\u5de5\u4f5c\uff0c\u4e3a\u591a\u7ef4\u521b\u610f\u5199\u4f5c\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.18947", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.18947", "abs": "https://arxiv.org/abs/2508.18947", "authors": ["Ronal Singh", "Shahroz Tariq", "Fatemeh Jalalvand", "Mohan Baruwal Chhetri", "Surya Nepal", "Cecile Paris", "Martin Lochner"], "title": "LLMs in the SOC: An Empirical Study of Human-AI Collaboration in Security Operations Centres", "comment": "22 pages, 9 figures, under review", "summary": "The integration of Large Language Models (LLMs) into Security Operations\nCentres (SOCs) presents a transformative, yet still evolving, opportunity to\nreduce analyst workload through human-AI collaboration. However, their\nreal-world application in SOCs remains underexplored. To address this gap, we\npresent a longitudinal study of 3,090 analyst queries from 45 SOC analysts over\n10 months. Our analysis reveals that analysts use LLMs as on-demand aids for\nsensemaking and context-building, rather than for making high-stakes\ndeterminations, preserving analyst decision authority. The majority of queries\nare related to interpreting low-level telemetry (e.g., commands) and refining\ntechnical communication through short (1-3 turn) interactions. Notably, 93% of\nqueries align with established cybersecurity competencies (NICE Framework),\nunderscoring the relevance of LLM use for SOC-related tasks. Despite variations\nin tasks and engagement, usage trends indicate a shift from occasional\nexploration to routine integration, with growing adoption and sustained use\namong a subset of analysts. We find that LLMs function as flexible, on-demand\ncognitive aids that augment, rather than replace, SOC expertise. Our study\nprovides actionable guidance for designing context-aware, human-centred AI\nassistance in security operations, highlighting the need for further\nin-the-wild research on real-world analyst-LLM collaboration, challenges, and\nimpacts.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5728SOC\u4e2d\u4e3a\u5206\u6790\u5e08\u63d0\u4f9b\u968f\u9700\u7684\u8ba4\u77e5\u8f85\u52a9\uff0c\u4e3b\u8981\u7528\u4e8e\u611f\u77e5\u548c\u4e0a\u4e0b\u6587\u6784\u5efa\uff0c\u800c\u975e\u9ad8\u98ce\u9669\u51b3\u7b56\uff0c\u4fdd\u6301\u4e86\u5206\u6790\u5e08\u7684\u51b3\u7b56\u6743\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728SOC\u4e2d\u5177\u6709\u8f6c\u578b\u6f5c\u529b\uff0c\u4f46\u5176\u5b9e\u9645\u5e94\u7528\u7814\u7a76\u4ecd\u7136\u4e0d\u8db3\uff0c\u9700\u8981\u901a\u8fc7\u7eb5\u5411\u7814\u7a76\u4e86\u89e3\u771f\u5b9e\u4f7f\u7528\u60c5\u51b5\u3002", "method": "\u5bf910\u4e2a\u6708\u518545\u540dSOC\u5206\u6790\u5e08\u76843,090\u4e2a\u67e5\u8be2\u8fdb\u884c\u7eb5\u5411\u5206\u6790\uff0c\u7814\u7a76\u4ed6\u4eec\u5982\u4f55\u4f7f\u7528LLM\u3002", "result": "\u5206\u6790\u5e08\u4e3b\u8981\u5c06LLM\u7528\u4e8e\u89e3\u91ca\u4f4e\u7ea7\u6570\u636e\u548c\u7cbe\u70bc\u6280\u672f\u6c9f\u901a\uff0c93%\u67e5\u8be2\u7b26\u5408\u7f51\u7edc\u5b89\u5168\u80fd\u529b\u6807\u51c6\uff0c\u4f7f\u7528\u8d8b\u52bf\u4ece\u5076\u7136\u5c1d\u8bd5\u8f6c\u5411\u5e38\u89c4\u96c6\u6210\u3002", "conclusion": "LLM\u5728SOC\u4e2d\u4f5c\u4e3a\u7075\u6d3b\u7684\u8ba4\u77e5\u8f85\u52a9\u5de5\u5177\uff0c\u589e\u5f3a\u800c\u975e\u66ff\u4ee3\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u7814\u7a76\u4e3a\u8bbe\u8ba1\u4eba\u672c\u4e2d\u5fc3\u7684AI\u8f85\u52a9\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2508.18646", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18646", "abs": "https://arxiv.org/abs/2508.18646", "authors": ["Jun Wang", "Ninglun Gu", "Kailai Zhang", "Zijiao Zhang", "Yelun Bao", "Jin Yang", "Xu Yin", "Liwei Liu", "Yihuan Liu", "Pengyong Li", "Gary G. Yen", "Junchi Yan"], "title": "Beyond Benchmark: LLMs Evaluation with an Anthropomorphic and Value-oriented Roadmap", "comment": "Preprint. Under review", "summary": "For Large Language Models (LLMs), a disconnect persists between benchmark\nperformance and real-world utility. Current evaluation frameworks remain\nfragmented, prioritizing technical metrics while neglecting holistic assessment\nfor deployment. This survey introduces an anthropomorphic evaluation paradigm\nthrough the lens of human intelligence, proposing a novel three-dimensional\ntaxonomy: Intelligence Quotient (IQ)-General Intelligence for foundational\ncapacity, Emotional Quotient (EQ)-Alignment Ability for value-based\ninteractions, and Professional Quotient (PQ)-Professional Expertise for\nspecialized proficiency. For practical value, we pioneer a Value-oriented\nEvaluation (VQ) framework assessing economic viability, social impact, ethical\nalignment, and environmental sustainability. Our modular architecture\nintegrates six components with an implementation roadmap. Through analysis of\n200+ benchmarks, we identify key challenges including dynamic assessment needs\nand interpretability gaps. It provides actionable guidance for developing LLMs\nthat are technically proficient, contextually relevant, and ethically sound. We\nmaintain a curated repository of open-source evaluation resources at:\nhttps://github.com/onejune2018/Awesome-LLM-Eval.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u62df\u4eba\u5316\u7684\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6\uff08IQ\u3001EQ\u3001PQ\uff09\u548c\u4ef7\u503c\u5bfc\u5411\u8bc4\u4f30\uff08VQ\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u7528\u4ef7\u503c\uff0c\u5305\u62ec\u6280\u672f\u80fd\u529b\u3001\u4ef7\u503c\u5bf9\u9f50\u548c\u4e13\u4e1a\u4e13\u957f\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u6027\u80fd\u4e0e\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u4e4b\u95f4\u5b58\u5728\u8131\u8282\uff0c\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u788e\u7247\u5316\u4e14\u8fc7\u5ea6\u5173\u6ce8\u6280\u672f\u6307\u6807\uff0c\u7f3a\u4e4f\u5bf9\u90e8\u7f72\u5b9e\u7528\u6027\u7684\u6574\u4f53\u8bc4\u4f30\u3002", "method": "\u5f15\u5165\u62df\u4eba\u5316\u8bc4\u4f30\u8303\u5f0f\uff0c\u63d0\u51fa\u4e09\u7ef4\u5206\u7c7b\u6cd5\uff1a\u667a\u5546\uff08IQ\uff09-\u901a\u7528\u667a\u80fd\u3001\u60c5\u5546\uff08EQ\uff09-\u5bf9\u9f50\u80fd\u529b\u3001\u4e13\u4e1a\u5546\uff08PQ\uff09-\u4e13\u4e1a\u4e13\u957f\uff1b\u5e76\u5f00\u521b\u4ef7\u503c\u5bfc\u5411\u8bc4\u4f30\uff08VQ\uff09\u6846\u67b6\u8bc4\u4f30\u7ecf\u6d4e\u53ef\u884c\u6027\u3001\u793e\u4f1a\u5f71\u54cd\u3001\u4f26\u7406\u5bf9\u9f50\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\u3002", "result": "\u901a\u8fc7\u5206\u6790200\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc6\u522b\u51fa\u52a8\u6001\u8bc4\u4f30\u9700\u6c42\u548c\u53ef\u89e3\u91ca\u6027\u5dee\u8ddd\u7b49\u5173\u952e\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u67b6\u6784\u548c\u5b9e\u65bd\u8def\u7ebf\u56fe\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u6280\u672f\u4e0a\u7cbe\u901a\u3001\u4e0a\u4e0b\u6587\u76f8\u5173\u4e14\u7b26\u5408\u4f26\u7406\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u5e76\u7ef4\u62a4\u4e86\u5f00\u6e90\u8bc4\u4f30\u8d44\u6e90\u5e93\u3002"}}
{"id": "2508.18976", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18976", "abs": "https://arxiv.org/abs/2508.18976", "authors": ["Stephen Meisenbacher", "Alexandra Klymenko", "Andreea-Elena Bodea", "Florian Matthes"], "title": "The Double-edged Sword of LLM-based Data Reconstruction: Understanding and Mitigating Contextual Vulnerability in Word-level Differential Privacy Text Sanitization", "comment": "15 pages, 4 figures, 8 tables. Accepted to WPES @ CCS 2025", "summary": "Differentially private text sanitization refers to the process of privatizing\ntexts under the framework of Differential Privacy (DP), providing provable\nprivacy guarantees while also empirically defending against adversaries seeking\nto harm privacy. Despite their simplicity, DP text sanitization methods\noperating at the word level exhibit a number of shortcomings, among them the\ntendency to leave contextual clues from the original texts due to randomization\nduring sanitization $\\unicode{x2013}$ this we refer to as $\\textit{contextual\nvulnerability}$. Given the powerful contextual understanding and inference\ncapabilities of Large Language Models (LLMs), we explore to what extent LLMs\ncan be leveraged to exploit the contextual vulnerability of DP-sanitized texts.\nWe expand on previous work not only in the use of advanced LLMs, but also in\ntesting a broader range of sanitization mechanisms at various privacy levels.\nOur experiments uncover a double-edged sword effect of LLM-based data\nreconstruction attacks on privacy and utility: while LLMs can indeed infer\noriginal semantics and sometimes degrade empirical privacy protections, they\ncan also be used for good, to improve the quality and privacy of DP-sanitized\ntexts. Based on our findings, we propose recommendations for using LLM data\nreconstruction as a post-processing step, serving to increase privacy\nprotection by thinking adversarially.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLMs\u5982\u4f55\u5229\u7528\u5dee\u5206\u9690\u79c1\u6587\u672c\u6d88\u6bd2\u4e2d\u7684\u4e0a\u4e0b\u6587\u6f0f\u6d1e\u8fdb\u884c\u6570\u636e\u91cd\u5efa\u653b\u51fb\uff0c\u53d1\u73b0LLMs\u65e2\u80fd\u63a8\u65ad\u539f\u59cb\u8bed\u4e49\u964d\u4f4e\u9690\u79c1\u4fdd\u62a4\uff0c\u4e5f\u80fd\u901a\u8fc7\u540e\u5904\u7406\u63d0\u5347\u6d88\u6bd2\u6587\u672c\u7684\u8d28\u91cf\u548c\u9690\u79c1\u6027\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u53ef\u4ee5\u5229\u7528\u5dee\u5206\u9690\u79c1\u6587\u672c\u6d88\u6bd2\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u4e0a\u4e0b\u6587\u6f0f\u6d1e\uff0c\u56e0\u4e3a\u73b0\u6709\u7684\u8bcd\u7ea7DP\u6d88\u6bd2\u65b9\u6cd5\u867d\u7136\u7b80\u5355\uff0c\u4f46\u5bb9\u6613\u5728\u968f\u673a\u5316\u8fc7\u7a0b\u4e2d\u7559\u4e0b\u539f\u59cb\u6587\u672c\u7684\u4e0a\u4e0b\u6587\u7ebf\u7d22\u3002", "method": "\u4f7f\u7528\u5148\u8fdb\u7684LLMs\u5bf9\u591a\u79cd\u6d88\u6bd2\u673a\u5236\u5728\u4e0d\u540c\u9690\u79c1\u7ea7\u522b\u4e0b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u901a\u8fc7LLM\u6570\u636e\u91cd\u5efa\u653b\u51fb\u6765\u8bc4\u4f30\u4e0a\u4e0b\u6587\u6f0f\u6d1e\u7684\u5229\u7528\u7a0b\u5ea6\uff0c\u5e76\u63d0\u51fa\u5c06LLM\u6570\u636e\u91cd\u5efa\u4f5c\u4e3a\u540e\u5904\u7406\u6b65\u9aa4\u7684\u5efa\u8bae\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0LLM\u57fa\u4e8e\u6570\u636e\u91cd\u5efa\u653b\u51fb\u5bf9\u9690\u79c1\u548c\u6548\u7528\u5177\u6709\u53cc\u5203\u5251\u6548\u5e94\uff1a\u65e2\u80fd\u63a8\u65ad\u539f\u59cb\u8bed\u4e49\u964d\u4f4e\u5b9e\u8bc1\u9690\u79c1\u4fdd\u62a4\uff0c\u4e5f\u80fd\u7528\u4e8e\u63d0\u5347DP\u6d88\u6bd2\u6587\u672c\u7684\u8d28\u91cf\u548c\u9690\u79c1\u6027\u3002", "conclusion": "\u5efa\u8bae\u5c06LLM\u6570\u636e\u91cd\u5efa\u4f5c\u4e3a\u5bf9\u6297\u6027\u601d\u8003\u7684\u540e\u5904\u7406\u6b65\u9aa4\uff0c\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u53ef\u4ee5\u589e\u52a0\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u63d0\u9ad8\u6d88\u6bd2\u6587\u672c\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.18669", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18669", "abs": "https://arxiv.org/abs/2508.18669", "authors": ["Weikang Zhao", "Xili Wang", "Chengdi Ma", "Lingbin Kong", "Zhaohua Yang", "Mingxiang Tuo", "Xiaowei Shi", "Yitao Zhai", "Xunliang Cai"], "title": "MUA-RL: Multi-turn User-interacting Agent Reinforcement Learning for agentic tool use", "comment": null, "summary": "With the recent rapid advancement of Agentic Intelligence, agentic tool use\nin LLMs has become increasingly important. During multi-turn interactions\nbetween agents and users, the dynamic, uncertain, and stochastic nature of user\ndemands poses significant challenges to the agent's tool invocation\ncapabilities. Agents are no longer expected to simply call tools to deliver a\nresult; rather, they must iteratively refine their understanding of user needs\nthrough communication while simultaneously invoking tools to resolve user\nqueries. Existing reinforcement learning (RL) approaches for tool use lack the\nintegration of genuinely dynamic users during the RL training process. To\nbridge this gap, we introduce MUA-RL (Multi-turn User-interacting Agent\nReinforcement Learning for agentic tool use), a novel reinforcement learning\nframework that, for the first time in the field of agentic tool use, integrates\nLLM-simulated users into the reinforcement learning loop. MUA-RL aims to enable\nautonomous learning of models to communicate with users efficiently and use\nvarious tools to solve practical problems in dynamic multi-turn interactions.\nEvaluations are done on several multi-turn tool-using benchmarks (see Figure\n1). Specifically, MUA-RL-32B achieves 67.3 on TAU2 Retail, 45.4 on TAU2\nAirline, 28.3 on TAU2 Telecom, 28.4 on BFCL-V3 Multi Turn, and 82.5 on ACEBench\nAgent -- outperforming or matching the performance of larger open-source models\nsuch as DeepSeek-V3-0324 and Qwen3-235B-A22B in non-thinking settings.", "AI": {"tldr": "MUA-RL\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u9996\u6b21\u5728\u667a\u80fd\u4f53\u5de5\u5177\u4f7f\u7528\u9886\u57df\u5c06LLM\u6a21\u62df\u7528\u6237\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u5faa\u73af\u4e2d\uff0c\u7528\u4e8e\u591a\u8f6e\u52a8\u6001\u4ea4\u4e92\u4e2d\u7684\u5de5\u5177\u8c03\u7528\u3002", "motivation": "\u5f53\u524d\u667a\u80fd\u4f53\u5de5\u5177\u4f7f\u7528\u9762\u4e34\u52a8\u6001\u3001\u4e0d\u786e\u5b9a\u548c\u968f\u673a\u7684\u7528\u6237\u9700\u6c42\u6311\u6218\uff0c\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u771f\u6b63\u52a8\u6001\u7528\u6237\u7684\u96c6\u6210\uff0c\u9700\u8981\u8ba9\u667a\u80fd\u4f53\u901a\u8fc7\u6c9f\u901a\u8fed\u4ee3\u7406\u89e3\u7528\u6237\u9700\u6c42\u5e76\u8c03\u7528\u5de5\u5177\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86MUA-RL\uff08\u591a\u8f6e\u7528\u6237\u4ea4\u4e92\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff09\u6846\u67b6\uff0c\u4f7f\u7528LLM\u6a21\u62df\u7528\u6237\u53c2\u4e0e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u81ea\u4e3b\u5b66\u4e60\u4e0e\u7528\u6237\u9ad8\u6548\u6c9f\u901a\u548c\u4f7f\u7528\u5404\u79cd\u5de5\u5177\u3002", "result": "MUA-RL-32B\u5728\u591a\u4e2a\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff1aTAU2 Retail 67.3\u5206\u3001TAU2 Airline 45.4\u5206\u3001TAU2 Telecom 28.3\u5206\u3001BFCL-V3 Multi Turn 28.4\u5206\u3001ACEBench Agent 82.5\u5206\uff0c\u6027\u80fd\u8fbe\u5230\u6216\u8d85\u8fc7DeepSeek-V3-0324\u548cQwen3-235B-A22B\u7b49\u66f4\u5927\u5f00\u6e90\u6a21\u578b\u3002", "conclusion": "MUA-RL\u6210\u529f\u89e3\u51b3\u4e86\u52a8\u6001\u591a\u8f6e\u4ea4\u4e92\u4e2d\u667a\u80fd\u4f53\u5de5\u5177\u4f7f\u7528\u7684\u6311\u6218\uff0c\u901a\u8fc7\u96c6\u6210\u6a21\u62df\u7528\u6237\u5b9e\u73b0\u4e86\u81ea\u4e3b\u5b66\u4e60\u548c\u9ad8\u6548\u5de5\u5177\u8c03\u7528\uff0c\u4e3a\u667a\u80fd\u4f53\u5de5\u5177\u4f7f\u7528\u9886\u57df\u63d0\u4f9b\u4e86\u521b\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19072", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.19072", "abs": "https://arxiv.org/abs/2508.19072", "authors": ["Sidahmed Benabderrahmane", "Talal Rahwan"], "title": "Attackers Strike Back? Not Anymore -- An Ensemble of RL Defenders Awakens for APT Detection", "comment": null, "summary": "Advanced Persistent Threats (APTs) represent a growing menace to modern\ndigital infrastructure. Unlike traditional cyberattacks, APTs are stealthy,\nadaptive, and long-lasting, often bypassing signature-based detection systems.\nThis paper introduces a novel framework for APT detection that unites deep\nlearning, reinforcement learning (RL), and active learning into a cohesive,\nadaptive defense system. Our system combines auto-encoders for latent\nbehavioral encoding with a multi-agent ensemble of RL-based defenders, each\ntrained to distinguish between benign and malicious process behaviors. We\nidentify a critical challenge in existing detection systems: their static\nnature and inability to adapt to evolving attack strategies. To this end, our\narchitecture includes multiple RL agents (Q-Learning, PPO, DQN, adversarial\ndefenders), each analyzing latent vectors generated by an auto-encoder. When\nany agent is uncertain about its decision, the system triggers an active\nlearning loop to simulate expert feedback, thus refining decision boundaries.\nAn ensemble voting mechanism, weighted by each agent's performance, ensures\nrobust final predictions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u4e3b\u52a8\u5b66\u4e60\u7684\u65b0\u578bAPT\u68c0\u6d4b\u6846\u67b6\uff0c\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u8fdb\u884c\u6f5c\u5728\u884c\u4e3a\u7f16\u7801\uff0c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u8fdb\u884c\u68c0\u6d4b\uff0c\u5e76\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u548c\u96c6\u6210\u6295\u7968\u673a\u5236\u63d0\u9ad8\u81ea\u9002\u5e94\u80fd\u529b", "motivation": "\u4f20\u7edf\u7b7e\u540d\u68c0\u6d4b\u7cfb\u7edf\u65e0\u6cd5\u5e94\u5bf9APT\u653b\u51fb\u7684\u9690\u853d\u6027\u3001\u9002\u5e94\u6027\u548c\u6301\u4e45\u6027\u7279\u70b9\uff0c\u73b0\u6709\u68c0\u6d4b\u7cfb\u7edf\u9759\u6001\u4e14\u65e0\u6cd5\u9002\u5e94\u4e0d\u65ad\u6f14\u5316\u7684\u653b\u51fb\u7b56\u7565", "method": "\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u751f\u6210\u6f5c\u5728\u884c\u4e3a\u5411\u91cf\uff0c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\uff08\u5305\u542bQ-Learning\u3001PPO\u3001DQN\u7b49\u7b97\u6cd5\uff09\u8fdb\u884c\u5206\u6790\uff0c\u5f15\u5165\u4e3b\u52a8\u5b66\u4e60\u673a\u5236\u6a21\u62df\u4e13\u5bb6\u53cd\u9988\uff0c\u91c7\u7528\u52a0\u6743\u96c6\u6210\u6295\u7968\u673a\u5236\u8fdb\u884c\u6700\u7ec8\u51b3\u7b56", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u9632\u5fa1\u7cfb\u7edf\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4bAPT\u653b\u51fb\u5e76\u9002\u5e94\u653b\u51fb\u7b56\u7565\u7684\u53d8\u5316", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u7ed3\u5408\uff0c\u52a0\u4e0a\u4e3b\u52a8\u5b66\u4e60\u7684\u53cd\u9988\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86APT\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\uff0c\u4e3a\u5e94\u5bf9\u73b0\u4ee3\u7f51\u7edc\u5a01\u80c1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.18689", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18689", "abs": "https://arxiv.org/abs/2508.18689", "authors": ["Yuyang Zhao", "Wentao Shi", "Fuli Feng", "Xiangnan He"], "title": "AppAgent-Pro: A Proactive GUI Agent System for Multidomain Information Integration and User Assistance", "comment": "Accepted at CIKM 2025. 10 pages, 5 figures. Our code is available at:\n  https://github.com/LaoKuiZe/AppAgent-Pro. Our code is available at:\n  https://github.com/LaoKuiZe/AppAgent-Pro. The demonstration video could be\n  found at:\n  https://www.dropbox.com/scl/fi/hvzqo5vnusg66srydzixo/AppAgent-Pro-demo-video.mp4?rlkey=o2nlfqgq6ihl125mcqg7bpgqu&st=d29vrzii&dl=0", "summary": "Large language model (LLM)-based agents have demonstrated remarkable\ncapabilities in addressing complex tasks, thereby enabling more advanced\ninformation retrieval and supporting deeper, more sophisticated human\ninformation-seeking behaviors. However, most existing agents operate in a\npurely reactive manner, responding passively to user instructions, which\nsignificantly constrains their effectiveness and efficiency as general-purpose\nplatforms for information acquisition. To overcome this limitation, this paper\nproposes AppAgent-Pro, a proactive GUI agent system that actively integrates\nmulti-domain information based on user instructions. This approach enables the\nsystem to proactively anticipate users' underlying needs and conduct in-depth\nmulti-domain information mining, thereby facilitating the acquisition of more\ncomprehensive and intelligent information. AppAgent-Pro has the potential to\nfundamentally redefine information acquisition in daily life, leading to a\nprofound impact on human society. Our code is available at:\nhttps://github.com/LaoKuiZe/AppAgent-Pro. Our code is available at:\nhttps://github.com/LaoKuiZe/AppAgent-Pro. The demonstration video could be\nfound at:\nhttps://www.dropbox.com/scl/fi/hvzqo5vnusg66srydzixo/AppAgent-Pro-demo-video.mp4?rlkey=o2nlfqgq6ihl125mcqg7bpgqu&st=d29vrzii&dl=0.", "AI": {"tldr": "AppAgent-Pro\u662f\u4e00\u4e2a\u4e3b\u52a8\u5f0fGUI\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u9886\u57df\u4fe1\u606f\u6574\u5408\u4e3b\u52a8\u9884\u6d4b\u7528\u6237\u9700\u6c42\uff0c\u63d0\u5347\u4fe1\u606f\u83b7\u53d6\u7684\u5168\u9762\u6027\u548c\u667a\u80fd\u5316", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u591a\u4e3a\u88ab\u52a8\u54cd\u5e94\u6a21\u5f0f\uff0c\u9650\u5236\u4e86\u4fe1\u606f\u83b7\u53d6\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u9700\u8981\u5f00\u53d1\u4e3b\u52a8\u5f0f\u7cfb\u7edf\u6765\u66f4\u597d\u5730\u6ee1\u8db3\u7528\u6237\u4fe1\u606f\u9700\u6c42", "method": "\u63d0\u51faAppAgent-Pro\u7cfb\u7edf\uff0c\u4e3b\u52a8\u6574\u5408\u591a\u9886\u57df\u4fe1\u606f\uff0c\u57fa\u4e8e\u7528\u6237\u6307\u4ee4\u8fdb\u884c\u6df1\u5ea6\u591a\u9886\u57df\u4fe1\u606f\u6316\u6398", "result": "\u7cfb\u7edf\u80fd\u591f\u4e3b\u52a8\u9884\u6d4b\u7528\u6237\u6f5c\u5728\u9700\u6c42\uff0c\u5b9e\u73b0\u66f4\u5168\u9762\u667a\u80fd\u7684\u4fe1\u606f\u83b7\u53d6\uff0c\u6709\u671b\u91cd\u65b0\u5b9a\u4e49\u65e5\u5e38\u751f\u6d3b\u4fe1\u606f\u83b7\u53d6\u65b9\u5f0f", "conclusion": "AppAgent-Pro\u901a\u8fc7\u4e3b\u52a8\u4fe1\u606f\u6574\u5408\u548c\u6316\u6398\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u4ee3\u7406\u7684\u4fe1\u606f\u83b7\u53d6\u80fd\u529b\uff0c\u5bf9\u793e\u4f1a\u4fe1\u606f\u83b7\u53d6\u65b9\u5f0f\u5177\u6709\u6df1\u8fdc\u5f71\u54cd"}}
{"id": "2508.19115", "categories": ["cs.CR", "cs.AI", "E.3; I.2.6; I.5.1; F.1.2"], "pdf": "https://arxiv.org/pdf/2508.19115", "abs": "https://arxiv.org/abs/2508.19115", "authors": ["Joshua Lee", "Ali Arastehfard", "Weiran Liu", "Xuegang Ban", "Yuan Hong"], "title": "SecureV2X: An Efficient and Privacy-Preserving System for Vehicle-to-Everything (V2X) Applications", "comment": "10 pages, 3 figures", "summary": "Autonomous driving and V2X technologies have developed rapidly in the past\ndecade, leading to improved safety and efficiency in modern transportation.\nThese systems interact with extensive networks of vehicles, roadside\ninfrastructure, and cloud resources to support their machine learning\ncapabilities. However, the widespread use of machine learning in V2X systems\nraises issues over the privacy of the data involved. This is particularly\nconcerning for smart-transit and driver safety applications which can\nimplicitly reveal user locations or explicitly disclose medical data such as\nEEG signals. To resolve these issues, we propose SecureV2X, a scalable,\nmulti-agent system for secure neural network inferences deployed between the\nserver and each vehicle. Under this setting, we study two multi-agent V2X\napplications: secure drowsiness detection, and secure red-light violation\ndetection. Our system achieves strong performance relative to baselines, and\nscales efficiently to support a large number of secure computation interactions\nsimultaneously. For instance, SecureV2X is $9.4 \\times$ faster, requires\n$143\\times$ fewer computational rounds, and involves $16.6\\times$ less\ncommunication on drowsiness detection compared to other secure systems.\nMoreover, it achieves a runtime nearly $100\\times$ faster than state-of-the-art\nbenchmarks in object detection tasks for red light violation detection.", "AI": {"tldr": "SecureV2X\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u670d\u52a1\u5668\u548c\u8f66\u8f86\u4e4b\u95f4\u8fdb\u884c\u5b89\u5168\u7684\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\uff0c\u89e3\u51b3\u4e86V2X\u7cfb\u7edf\u4e2d\u673a\u5668\u5b66\u4e60\u5e94\u7528\u7684\u6570\u636e\u9690\u79c1\u95ee\u9898\u3002", "motivation": "V2X\u7cfb\u7edf\u548c\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u7279\u522b\u662f\u667a\u80fd\u4ea4\u901a\u548c\u9a7e\u9a76\u5458\u5b89\u5168\u5e94\u7528\u53ef\u80fd\u6cc4\u9732\u7528\u6237\u4f4d\u7f6e\u6216\u533b\u7597\u6570\u636e\uff08\u5982EEG\u4fe1\u53f7\uff09\u3002", "method": "\u63d0\u51fa\u4e86SecureV2X\u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u591a\u4ee3\u7406\u5b89\u5168\u8ba1\u7b97\u6846\u67b6\uff0c\u652f\u6301\u670d\u52a1\u5668\u4e0e\u8f66\u8f86\u4e4b\u95f4\u7684\u5b89\u5168\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\uff0c\u5e94\u7528\u4e8e\u5b89\u5168\u778c\u7761\u68c0\u6d4b\u548c\u5b89\u5168\u95ef\u7ea2\u706f\u68c0\u6d4b\u3002", "result": "\u7cfb\u7edf\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff1a\u778c\u7761\u68c0\u6d4b\u901f\u5ea6\u5feb9.4\u500d\uff0c\u8ba1\u7b97\u8f6e\u6b21\u51cf\u5c11143\u500d\uff0c\u901a\u4fe1\u91cf\u51cf\u5c1116.6\u500d\uff1b\u95ef\u7ea2\u706f\u68c0\u6d4b\u8fd0\u884c\u65f6\u6bd4\u6700\u5148\u8fdb\u57fa\u51c6\u5feb\u8fd1100\u500d\u3002", "conclusion": "SecureV2X\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86V2X\u5e94\u7528\u4e2d\u7684\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u5b89\u5168\u8ba1\u7b97\u4ea4\u4e92\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.18722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18722", "abs": "https://arxiv.org/abs/2508.18722", "authors": ["Honghao Fu", "Junlong Ren", "Qi Chai", "Deheng Ye", "Yujun Cai", "Hao Wang"], "title": "VistaWise: Building Cost-Effective Agent with Cross-Modal Knowledge Graph for Minecraft", "comment": "Accepted by EMNLP 2025 main", "summary": "Large language models (LLMs) have shown significant promise in embodied\ndecision-making tasks within virtual open-world environments. Nonetheless,\ntheir performance is hindered by the absence of domain-specific knowledge.\nMethods that finetune on large-scale domain-specific data entail prohibitive\ndevelopment costs. This paper introduces VistaWise, a cost-effective agent\nframework that integrates cross-modal domain knowledge and finetunes a\ndedicated object detection model for visual analysis. It reduces the\nrequirement for domain-specific training data from millions of samples to a few\nhundred. VistaWise integrates visual information and textual dependencies into\na cross-modal knowledge graph (KG), enabling a comprehensive and accurate\nunderstanding of multimodal environments. We also equip the agent with a\nretrieval-based pooling strategy to extract task-related information from the\nKG, and a desktop-level skill library to support direct operation of the\nMinecraft desktop client via mouse and keyboard inputs. Experimental results\ndemonstrate that VistaWise achieves state-of-the-art performance across various\nopen-world tasks, highlighting its effectiveness in reducing development costs\nwhile enhancing agent performance.", "AI": {"tldr": "VistaWise\u662f\u4e00\u4e2a\u6210\u672c\u6548\u76ca\u9ad8\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u8de8\u6a21\u6001\u9886\u57df\u77e5\u8bc6\u548c\u5fae\u8c03\u4e13\u7528\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\uff0c\u5c06\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u4ece\u6570\u767e\u4e07\u6837\u672c\u51cf\u5c11\u5230\u51e0\u767e\u4e2a\uff0c\u5728\u865a\u62df\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u865a\u62df\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u5177\u8eab\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u6027\u80fd\u53d7\u5230\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u7684\u9650\u5236\uff0c\u800c\u57fa\u4e8e\u5927\u89c4\u6a21\u9886\u57df\u7279\u5b9a\u6570\u636e\u7684\u5fae\u8c03\u65b9\u6cd5\u5f00\u53d1\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u63d0\u51faVistaWise\u6846\u67b6\uff1a1\uff09\u6574\u5408\u89c6\u89c9\u4fe1\u606f\u548c\u6587\u672c\u4f9d\u8d56\u5230\u8de8\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\uff1b2\uff09\u4f7f\u7528\u68c0\u7d22\u5f0f\u6c60\u5316\u7b56\u7565\u4ece\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\uff1b3\uff09\u914d\u5907\u684c\u9762\u7ea7\u6280\u80fd\u5e93\u652f\u6301\u901a\u8fc7\u9f20\u6807\u952e\u76d8\u76f4\u63a5\u64cd\u4f5cMinecraft\u5ba2\u6237\u7aef\uff1b4\uff09\u5fae\u8c03\u4e13\u7528\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u8fdb\u884c\u89c6\u89c9\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cVistaWise\u5728\u5404\u79cd\u5f00\u653e\u4e16\u754c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5f00\u53d1\u6210\u672c\u540c\u65f6\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u6027\u80fd\u3002", "conclusion": "VistaWise\u901a\u8fc7\u8de8\u6a21\u6001\u77e5\u8bc6\u6574\u5408\u548c\u9ad8\u6548\u7684\u8bad\u7ec3\u6570\u636e\u5229\u7528\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u5177\u8eab\u51b3\u7b56\u4e2d\u7684\u9886\u57df\u77e5\u8bc6\u7f3a\u5931\u95ee\u9898\uff0c\u4e3a\u4f4e\u6210\u672c\u9ad8\u6027\u80fd\u7684\u667a\u80fd\u4f53\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.18724", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18724", "abs": "https://arxiv.org/abs/2508.18724", "authors": ["Karanbir Singh", "Deepak Muppiri", "William Ngu"], "title": "Bias Mitigation Agent: Optimizing Source Selection for Fair and Balanced Knowledge Retrieval", "comment": "Accepted at KDD'2025 Agent4IR workshop", "summary": "Large Language Models (LLMs) have transformed the field of artificial\nintelligence by unlocking the era of generative applications. Built on top of\ngenerative AI capabilities, Agentic AI represents a major shift toward\nautonomous, goal-driven systems that can reason, retrieve, and act. However,\nthey also inherit the bias present in both internal and external information\nsources. This significantly affects the fairness and balance of retrieved\ninformation, and hence reduces user trust. To address this critical challenge,\nwe introduce a novel Bias Mitigation Agent, a multi-agent system designed to\norchestrate the workflow of bias mitigation through specialized agents that\noptimize the selection of sources to ensure that the retrieved content is both\nhighly relevant and minimally biased to promote fair and balanced knowledge\ndissemination. The experimental results demonstrate an 81.82\\% reduction in\nbias compared to a baseline naive retrieval strategy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u504f\u7f6e\u7f13\u89e3\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4f18\u5316\u4fe1\u606f\u6e90\u9009\u62e9\uff0c\u663e\u8457\u51cf\u5c11LLM\u68c0\u7d22\u4e2d\u7684\u504f\u89c1\u95ee\u9898", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4ee3\u7406AI\u7cfb\u7edf\u5728\u68c0\u7d22\u4fe1\u606f\u65f6\u5b58\u5728\u5185\u90e8\u548c\u5916\u90e8\u504f\u89c1\uff0c\u5f71\u54cd\u4fe1\u606f\u516c\u5e73\u6027\u548c\u7528\u6237\u4fe1\u4efb\u5ea6\uff0c\u9700\u8981\u6709\u6548\u7684\u504f\u89c1\u7f13\u89e3\u65b9\u6848", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e13\u95e8\u5316\u7684\u4ee3\u7406\u534f\u8c03\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4f18\u5316\u4fe1\u606f\u6e90\u9009\u62e9\u4ee5\u786e\u4fdd\u68c0\u7d22\u5185\u5bb9\u65e2\u9ad8\u5ea6\u76f8\u5173\u53c8\u504f\u89c1\u6700\u5c0f", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u76f8\u6bd4\u57fa\u7ebf\u6734\u7d20\u68c0\u7d22\u7b56\u7565\uff0c\u504f\u89c1\u51cf\u5c11\u4e8681.82%", "conclusion": "\u8be5\u504f\u7f6e\u7f13\u89e3\u4ee3\u7406\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u4fc3\u8fdb\u516c\u5e73\u5e73\u8861\u7684\u77e5\u8bc6\u4f20\u64ad\uff0c\u663e\u8457\u63d0\u5347\u4fe1\u606f\u68c0\u7d22\u7684\u516c\u6b63\u6027"}}
{"id": "2508.18743", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18743", "abs": "https://arxiv.org/abs/2508.18743", "authors": ["Sunguk Choi", "Yonghoon Kwon", "Heondeuk Lee"], "title": "CAC-CoT: Connector-Aware Compact Chain-of-Thought for Efficient Reasoning Data Synthesis Across Dual-System Cognitive Tasks", "comment": "Accepted at EMNLP 2025 findings", "summary": "Long chain-of-thought (CoT) prompting helps Large Language Models (LLMs)\nsolve difficult problems, but very long traces often slow or even degrade\nperformance on fast, intuitive \"System-1\" tasks. We introduce Connector-Aware\nCompact CoT (CAC-CoT) -- a method that deliberately restricts reasoning to a\nsmall, fixed set of connector phrases, steering the model toward concise and\nwell -- structured explanations. Despite its simplicity, our synthetic method\nwith Gemini-2.0-Flash yields a high-quality training quality. CAC-CoT achieves\napproximately 85% on GSM8K and approximately 40% on GPQA (System-2) while\nretaining approximately 90% on S1-Bench (System-1). Its reasoning traces\naverage approximately 300 tokens(ART), about one-third the length of baseline\ntraces, delivering higher efficiency without loss of accuracy.", "AI": {"tldr": "CAC-CoT\u662f\u4e00\u79cd\u4f7f\u7528\u6709\u9650\u8fde\u63a5\u8bcd\u77ed\u8bed\u7684\u7d27\u51d1\u601d\u7ef4\u94fe\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301System-1\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u7f29\u77ed\u63a8\u7406\u957f\u5ea6\u5e76\u63d0\u5347System-2\u4efb\u52a1\u8868\u73b0", "motivation": "\u89e3\u51b3\u957f\u601d\u7ef4\u94fe\u5728\u5feb\u901f\u76f4\u89c9\u6027System-1\u4efb\u52a1\u4e0a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u590d\u6742System-2\u4efb\u52a1\u7684\u89e3\u51b3\u80fd\u529b", "method": "\u4f7f\u7528\u8fde\u63a5\u8bcd\u611f\u77e5\u7684\u7d27\u51d1\u601d\u7ef4\u94fe(CAC-CoT)\uff0c\u9650\u5236\u63a8\u7406\u8fc7\u7a0b\u5230\u56fa\u5b9a\u7684\u8fde\u63a5\u8bcd\u77ed\u8bed\u96c6\u5408\uff0c\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u7b80\u6d01\u7ed3\u6784\u5316\u7684\u89e3\u91ca", "result": "\u5728GSM8K\u4e0a\u8fbe\u5230\u7ea685%\uff0cGPQA\u4e0a\u7ea640%\uff0c\u540c\u65f6\u4fdd\u6301S1-Bench\u7ea690%\u7684\u6027\u80fd\uff1b\u63a8\u7406\u75d5\u8ff9\u5e73\u5747\u7ea6300\u4e2atoken\uff0c\u6bd4\u57fa\u7ebf\u7f29\u77ed\u7ea6\u4e09\u5206\u4e4b\u4e8c", "conclusion": "CAC-CoT\u65b9\u6cd5\u901a\u8fc7\u9650\u5236\u8fde\u63a5\u8bcd\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u63a8\u7406\uff0c\u5728\u4fdd\u6301System-1\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86System-2\u4efb\u52a1\u7684\u89e3\u51b3\u80fd\u529b"}}
{"id": "2508.18749", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18749", "abs": "https://arxiv.org/abs/2508.18749", "authors": ["Chunlong Wu", "Zhibo Qu"], "title": "Reflection-Enhanced Meta-Optimization Integrating TextGrad-style Prompt Optimization with Memory-Driven Self-Evolution", "comment": null, "summary": "Recent advances in prompt optimization, exemplified by methods such as\nTextGrad, enable automatic, gradient-like refinement of textual prompts to\nenhance the performance of large language models (LLMs) on specific downstream\ntasks. However, current approaches are typically stateless and operate\nindependently across optimization runs, lacking mechanisms to preserve and\nleverage historical optimization experience. Furthermore, they are susceptible\nto overfitting, often yielding prompt updates that generalize poorly beyond the\nimmediate task context.\n  To address these limitations, we propose Reflection-Enhanced\nMeta-Optimization (REMO), a novel framework that integrates (1) a\nmemory-augmented Reflection Retrieval-Augmented Generation (RAG) module -\nstructured as a \"mistake notebook\" and (2) a Self-Adaptive Optimizer,\nimplemented via an LLM-driven meta-controller that synthesizes epoch-level\nreflective insights to iteratively improve system-level prompting strategies.\nThis architecture enables not only local, fine-grained prompt tuning akin to\nTextGrad, but also the systematic accumulation and reuse of cross-run\noptimization knowledge, thereby supporting continual improvement over time.\n  We instantiate the REMO framework using Qwen3-32B in standard inference mode\n- without explicit chain-of-thought prompting - and evaluate its efficacy on\nthe GSM8K benchmark for mathematical reasoning. Experimental results\ndemonstrate that, compared to a TextGrad baseline, REMO achieves more stable\nand robust generalization, albeit at the cost of increased computational\noverhead. We provide a detailed exposition of the algorithmic design, conduct a\nqualitative and quantitative analysis of optimization dynamics, and present a\ncomprehensive ablation study to elucidate the contributions of each component.", "AI": {"tldr": "REMO\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8bb0\u5fc6\u589e\u5f3a\u7684\u53cd\u601dRAG\u6a21\u5757\u548c\u81ea\u9002\u5e94\u4f18\u5316\u5668\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5386\u53f2\u7ecf\u9a8c\u79ef\u7d2f\u548c\u5bb9\u6613\u8fc7\u62df\u5408\u7684\u95ee\u9898\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u548c\u9c81\u68d2\u7684\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u5982TextGrad\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u65e0\u72b6\u6001\u8fd0\u884c\uff0c\u7f3a\u4e4f\u5386\u53f2\u4f18\u5316\u7ecf\u9a8c\u7684\u4fdd\u5b58\u548c\u5229\u7528\u673a\u5236\uff1b2\uff09\u5bb9\u6613\u8fc7\u62df\u5408\uff0c\u6cdb\u5316\u6027\u80fd\u5dee\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u79ef\u7d2f\u8de8\u8fd0\u884c\u4f18\u5316\u77e5\u8bc6\u5e76\u652f\u6301\u6301\u7eed\u6539\u8fdb\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86REMO\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u8bb0\u5fc6\u589e\u5f3a\u7684\u53cd\u601dRAG\u6a21\u5757\uff08\"\u9519\u8bef\u7b14\u8bb0\u672c\"\u7ed3\u6784\uff09\uff1b2\uff09\u81ea\u9002\u5e94\u6027\u4f18\u5316\u5668\uff08\u57fa\u4e8eLLM\u7684\u5143\u63a7\u5236\u5668\uff09\uff0c\u901a\u8fc7\u5408\u6210epoch\u7ea7\u522b\u7684\u53cd\u601d\u89c1\u89e3\u6765\u8fed\u4ee3\u6539\u8fdb\u7cfb\u7edf\u7ea7\u63d0\u793a\u7b56\u7565\u3002\u4f7f\u7528Qwen3-32B\u6a21\u578b\u5728\u6807\u51c6\u63a8\u7406\u6a21\u5f0f\u4e0b\u5b9e\u73b0\u3002", "result": "\u5728GSM8K\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0eTextGrad\u57fa\u7ebf\u76f8\u6bd4\uff0cREMO\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u548c\u9c81\u68d2\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u6709\u6240\u589e\u52a0\u3002\u901a\u8fc7\u8be6\u7ec6\u7684\u7b97\u6cd5\u8bbe\u8ba1\u3001\u4f18\u5316\u52a8\u6001\u7684\u5b9a\u6027\u548c\u5b9a\u91cf\u5206\u6790\u4ee5\u53ca\u5168\u9762\u7684\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u5404\u7ec4\u4ef6\u8d21\u732e\u3002", "conclusion": "REMO\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u7ecf\u9a8c\u79ef\u7d2f\u548c\u91cd\u7528\u673a\u5236\uff0c\u652f\u6301\u6301\u7eed\u7684\u6027\u80fd\u6539\u8fdb\uff0c\u4e3a\u63d0\u793a\u4f18\u5316\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.18751", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.18751", "abs": "https://arxiv.org/abs/2508.18751", "authors": ["Byung-Joon Lee", "Jin-Seop Lee", "Jee-Hyong Lee"], "title": "Stabilizing Open-Set Test-Time Adaptation via Primary-Auxiliary Filtering and Knowledge-Integrated Prediction", "comment": "Accepted at BMVC 2025", "summary": "Deep neural networks demonstrate strong performance under aligned\ntraining-test distributions. However, real-world test data often exhibit domain\nshifts. Test-Time Adaptation (TTA) addresses this challenge by adapting the\nmodel to test data during inference. While most TTA studies assume that the\ntraining and test data share the same class set (closed-set TTA), real-world\nscenarios often involve open-set data (open-set TTA), which can degrade\nclosed-set accuracy. A recent study showed that identifying open-set data\nduring adaptation and maximizing its entropy is an effective solution. However,\nthe previous method relies on the source model for filtering, resulting in\nsuboptimal filtering accuracy on domain-shifted test data. In contrast, we\nfound that the adapting model, which learns domain knowledge from noisy test\nstreams, tends to be unstable and leads to error accumulation when used for\nfiltering. To address this problem, we propose Primary-Auxiliary Filtering\n(PAF), which employs an auxiliary filter to validate data filtered by the\nprimary filter. Furthermore, we propose Knowledge-Integrated Prediction (KIP),\nwhich calibrates the outputs of the adapting model, EMA model, and source model\nto integrate their complementary knowledge for OSTTA. We validate our approach\nacross diverse closed-set and open-set datasets. Our method enhances both\nclosed-set accuracy and open-set discrimination over existing methods. The code\nis available at https://github.com/powerpowe/PAF-KIP-OSTTA .", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPAF-KIP\u65b9\u6cd5\u89e3\u51b3\u5f00\u653e\u96c6\u6d4b\u8bd5\u65f6\u9002\u5e94(OSTTA)\u95ee\u9898\uff0c\u901a\u8fc7\u4e3b-\u8f85\u52a9\u8fc7\u6ee4\u673a\u5236\u548c\u77e5\u8bc6\u96c6\u6210\u9884\u6d4b\uff0c\u5728\u4fdd\u6301\u95ed\u96c6\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u5f00\u653e\u96c6\u8bc6\u522b\u80fd\u529b", "motivation": "\u73b0\u6709\u7684\u5f00\u653e\u96c6\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\u4f9d\u8d56\u6e90\u6a21\u578b\u8fdb\u884c\u8fc7\u6ee4\uff0c\u5728\u57df\u504f\u79fb\u6d4b\u8bd5\u6570\u636e\u4e0a\u8fc7\u6ee4\u7cbe\u5ea6\u4e0d\u4f73\uff0c\u800c\u81ea\u9002\u5e94\u6a21\u578b\u7528\u4e8e\u8fc7\u6ee4\u4f1a\u5bfc\u81f4\u4e0d\u7a33\u5b9a\u548c\u9519\u8bef\u7d2f\u79ef", "method": "\u63d0\u51faPrimary-Auxiliary Filtering (PAF)\u4f7f\u7528\u8f85\u52a9\u8fc7\u6ee4\u5668\u9a8c\u8bc1\u4e3b\u8fc7\u6ee4\u5668\u7ed3\u679c\uff0c\u4ee5\u53caKnowledge-Integrated Prediction (KIP)\u96c6\u6210\u81ea\u9002\u5e94\u6a21\u578b\u3001EMA\u6a21\u578b\u548c\u6e90\u6a21\u578b\u7684\u4e92\u8865\u77e5\u8bc6", "result": "\u5728\u591a\u4e2a\u95ed\u96c6\u548c\u5f00\u653e\u96c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u5728\u95ed\u96c6\u7cbe\u5ea6\u548c\u5f00\u653e\u96c6\u533a\u5206\u80fd\u529b\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "PAF-KIP\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86OSTTA\u4e2d\u7684\u8fc7\u6ee4\u7cbe\u5ea6\u548c\u77e5\u8bc6\u96c6\u6210\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u57df\u504f\u79fb\u548c\u5f00\u653e\u96c6\u6570\u636e\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.18760", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18760", "abs": "https://arxiv.org/abs/2508.18760", "authors": ["Yi Liu", "Xiangyu Liu", "Zequn Sun", "Wei Hu"], "title": "Answering the Unanswerable Is to Err Knowingly: Analyzing and Mitigating Abstention Failures in Large Reasoning Models", "comment": null, "summary": "Large reasoning models (LRMs) have shown remarkable progress on complex\nreasoning tasks. However, some questions posed to LRMs are inherently\nunanswerable, such as math problems lacking sufficient conditions. We find that\nLRMs continually fail to provide appropriate abstentions when confronted with\nthese unanswerable questions. In this paper, we systematically analyze,\ninvestigate, and resolve this issue for trustworthy AI. We first conduct a\ndetailed analysis of the distinct response behaviors of LRMs when facing\nunanswerable questions. Then, we show that LRMs possess sufficient cognitive\ncapabilities to recognize the flaws in these questions. However, they fail to\nexhibit appropriate abstention behavior, revealing a misalignment between their\ninternal cognition and external response. Finally, to resolve this issue, we\npropose a lightweight, two-stage method that combines cognitive monitoring with\ninference-time intervention. Experimental results demonstrate that our method\nsignificantly improves the abstention rate while maintaining the overall\nreasoning performance.", "AI": {"tldr": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u5904\u7406\u4e0d\u53ef\u56de\u7b54\u95ee\u9898\u65f6\u5b58\u5728\u62d2\u7edd\u56de\u7b54\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u672c\u6587\u901a\u8fc7\u8ba4\u77e5\u76d1\u63a7\u548c\u63a8\u7406\u65f6\u5e72\u9884\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u62d2\u7edd\u56de\u7b54\u7387", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u9762\u5bf9\u7f3a\u4e4f\u5145\u5206\u6761\u4ef6\u7684\u4e0d\u53ef\u56de\u7b54\u95ee\u9898\u65f6\uff0c\u5f80\u5f80\u65e0\u6cd5\u63d0\u4f9b\u9002\u5f53\u7684\u62d2\u7edd\u56de\u7b54\uff0c\u8fd9\u5f71\u54cd\u4e86AI\u7684\u53ef\u4fe1\u5ea6", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u9996\u5148\u8fdb\u884c\u8ba4\u77e5\u76d1\u63a7\u5206\u6790\u6a21\u578b\u5bf9\u95ee\u9898\u7684\u5185\u90e8\u8ba4\u77e5\uff0c\u7136\u540e\u901a\u8fc7\u63a8\u7406\u65f6\u5e72\u9884\u6765\u8c03\u6574\u6a21\u578b\u7684\u5916\u90e8\u54cd\u5e94\u884c\u4e3a", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u62d2\u7edd\u56de\u7b54\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6574\u4f53\u7684\u63a8\u7406\u6027\u80fd", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5185\u90e8\u8ba4\u77e5\u4e0e\u5916\u90e8\u54cd\u5e94\u4e4b\u95f4\u7684\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u63d0\u5347\u4e86AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u548c\u53ef\u9760\u6027"}}
{"id": "2508.18763", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18763", "abs": "https://arxiv.org/abs/2508.18763", "authors": ["Chao Hao", "Zezheng Wang", "Yanhua Huang", "Ruiwen Xu", "Wenzhe Niu", "Xin Liu", "Zitong Yu"], "title": "Dynamic Collaboration of Multi-Language Models based on Minimal Complete Semantic Units", "comment": "Accepted by EMNLP 2025 Main Conference", "summary": "This paper investigates the enhancement of reasoning capabilities in language\nmodels through token-level multi-model collaboration. Our approach selects the\noptimal tokens from the next token distributions provided by multiple models to\nperform autoregressive reasoning. Contrary to the assumption that more models\nyield better results, we introduce a distribution distance-based dynamic\nselection strategy (DDS) to optimize the multi-model collaboration process. To\naddress the critical challenge of vocabulary misalignment in multi-model\ncollaboration, we propose the concept of minimal complete semantic units\n(MCSU), which is simple yet enables multiple language models to achieve natural\nalignment within the linguistic space. Experimental results across various\nbenchmarks demonstrate the superiority of our method. The code will be\navailable at https://github.com/Fanye12/DDS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u8ddd\u79bb\u7684\u52a8\u6001\u9009\u62e9\u7b56\u7565(DDS)\uff0c\u901a\u8fc7\u591a\u6a21\u578b\u5728token\u7ea7\u522b\u7684\u534f\u4f5c\u6765\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u89e3\u51b3\u4e86\u8bcd\u6c47\u4e0d\u5bf9\u9f50\u7684\u5173\u952e\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u578b\u534f\u4f5c\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u6a21\u578b\u8d8a\u591a\u6548\u679c\u8d8a\u597d\uff0c\u4f46\u5b9e\u9645\u4e0a\u9700\u8981\u66f4\u667a\u80fd\u7684\u534f\u4f5c\u7b56\u7565\u3002\u540c\u65f6\uff0c\u591a\u6a21\u578b\u534f\u4f5c\u9762\u4e34\u8bcd\u6c47\u8868\u4e0d\u5bf9\u9f50\u7684\u5173\u952e\u6280\u672f\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u5e03\u8ddd\u79bb\u52a8\u6001\u9009\u62e9\u7b56\u7565(DDS)\u6765\u4f18\u5316\u591a\u6a21\u578b\u534f\u4f5c\u8fc7\u7a0b\uff0c\u5f15\u5165\u6700\u5c0f\u5b8c\u6574\u8bed\u4e49\u5355\u5143(MCSU)\u6982\u5ff5\u89e3\u51b3\u8bcd\u6c47\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u4e49\u7a7a\u95f4\u4e2d\u7684\u81ea\u7136\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u4ee3\u7801\u5c06\u5728GitHub\u4e0a\u5f00\u6e90\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u667a\u80fd\u7684\u591a\u6a21\u578btoken\u7ea7\u534f\u4f5c\u6709\u6548\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u578b\u534f\u4f5c\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2508.18781", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.18781", "abs": "https://arxiv.org/abs/2508.18781", "authors": ["Lisai Zhang", "Baohan Xu", "Siqian Yang", "Mingyu Yin", "Jing Liu", "Chao Xu", "Siqi Wang", "Yidi Wu", "Yuxin Hong", "Zihao Zhang", "Yanzhang Liang", "Yudong Jiang"], "title": "AniME: Adaptive Multi-Agent Planning for Long Animation Generation", "comment": "2 pages, Technical Report", "summary": "We present AniME, a director-oriented multi-agent system for automated\nlong-form anime production, covering the full workflow from a story to the\nfinal video. The director agent keeps a global memory for the whole workflow,\nand coordinates several downstream specialized agents. By integrating\ncustomized Model Context Protocol (MCP) with downstream model instruction, the\nspecialized agent adaptively selects control conditions for diverse sub-tasks.\nAniME produces cinematic animation with consistent characters and synchronized\naudio visual elements, offering a scalable solution for AI-driven anime\ncreation.", "AI": {"tldr": "AniME\u662f\u4e00\u4e2a\u5bfc\u6f14\u5bfc\u5411\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u957f\u7bc7\u5e45\u52a8\u753b\u5236\u4f5c\uff0c\u4ece\u6545\u4e8b\u5230\u6700\u7ec8\u89c6\u9891\u7684\u5168\u6d41\u7a0b\u8986\u76d6\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3AI\u9a71\u52a8\u52a8\u753b\u521b\u4f5c\u4e2d\u7684\u89d2\u8272\u4e00\u81f4\u6027\u548c\u97f3\u89c6\u9891\u540c\u6b65\u95ee\u9898\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u52a8\u753b\u5236\u4f5c\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5bfc\u6f14\u667a\u80fd\u4f53\u7ef4\u62a4\u5168\u5c40\u8bb0\u5fc6\u5e76\u534f\u8c03\u4e0b\u6e38\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5b9a\u5236\u5316\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u4e0e\u4e0b\u6e38\u6a21\u578b\u6307\u4ee4\u96c6\u6210\uff0c\u4f7f\u4e13\u4e1a\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u9002\u5e94\u9009\u62e9\u4e0d\u540c\u5b50\u4efb\u52a1\u7684\u63a7\u5236\u6761\u4ef6\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u5177\u6709\u4e00\u81f4\u89d2\u8272\u548c\u540c\u6b65\u97f3\u89c6\u9891\u5143\u7d20\u7684\u7535\u5f71\u7ea7\u52a8\u753b\u3002", "conclusion": "AniME\u4e3aAI\u9a71\u52a8\u7684\u52a8\u753b\u521b\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5b8c\u6574\u5de5\u4f5c\u6d41\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.18797", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18797", "abs": "https://arxiv.org/abs/2508.18797", "authors": ["Qi Chai", "Zhang Zheng", "Junlong Ren", "Deheng Ye", "Zichuan Lin", "Hao Wang"], "title": "CausalMACE: Causality Empowered Multi-Agents in Minecraft Cooperative Tasks", "comment": null, "summary": "Minecraft, as an open-world virtual interactive environment, has become a\nprominent platform for research on agent decision-making and execution.\nExisting works primarily adopt a single Large Language Model (LLM) agent to\ncomplete various in-game tasks. However, for complex tasks requiring lengthy\nsequences of actions, single-agent approaches often face challenges related to\ninefficiency and limited fault tolerance. Despite these issues, research on\nmulti-agent collaboration remains scarce. In this paper, we propose CausalMACE,\na holistic causality planning framework designed to enhance multi-agent\nsystems, in which we incorporate causality to manage dependencies among\nsubtasks. Technically, our proposed framework introduces two modules: an\noverarching task graph for global task planning and a causality-based module\nfor dependency management, where inherent rules are adopted to perform causal\nintervention. Experimental results demonstrate our approach achieves\nstate-of-the-art performance in multi-agent cooperative tasks of Minecraft.", "AI": {"tldr": "CausalMACE\u662f\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u56fe\u548c\u56e0\u679c\u5e72\u9884\u6765\u63d0\u5347Minecraft\u4e2d\u590d\u6742\u4efb\u52a1\u7684\u6267\u884c\u6548\u7387\u548c\u5bb9\u9519\u80fd\u529b", "motivation": "\u73b0\u6709\u7684\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u5728\u5904\u7406Minecraft\u4e2d\u9700\u8981\u957f\u5e8f\u5217\u52a8\u4f5c\u7684\u590d\u6742\u4efb\u52a1\u65f6\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u548c\u5bb9\u9519\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\uff0c\u800c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7814\u7a76\u4ecd\u7136\u7a00\u7f3a", "method": "\u63d0\u51faCausalMACE\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1a\u5168\u5c40\u4efb\u52a1\u89c4\u5212\u7684\u4efb\u52a1\u56fe\u548c\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u4f9d\u8d56\u7ba1\u7406\u6a21\u5757\uff0c\u91c7\u7528\u56fa\u6709\u89c4\u5219\u8fdb\u884c\u56e0\u679c\u5e72\u9884", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728Minecraft\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd", "conclusion": "\u56e0\u679c\u5173\u7cfb\u7684\u5f15\u5165\u6709\u6548\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u534f\u4f5c\u6548\u7387\uff0c\u4e3a\u590d\u6742\u4efb\u52a1\u6267\u884c\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.18812", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18812", "abs": "https://arxiv.org/abs/2508.18812", "authors": ["Chenghao Wu", "Ruiyang Ren", "Junjie Zhang", "Ruirui Wang", "Zhongrui Ma", "Qi Ye", "Wayne Xin Zhao"], "title": "STARec: An Efficient Agent Framework for Recommender Systems via Autonomous Deliberate Reasoning", "comment": null, "summary": "While modern recommender systems are instrumental in navigating information\nabundance, they remain fundamentally limited by static user modeling and\nreactive decision-making paradigms. Current large language model (LLM)-based\nagents inherit these shortcomings through their overreliance on heuristic\npattern matching, yielding recommendations prone to shallow correlation bias,\nlimited causal inference, and brittleness in sparse-data scenarios. We\nintroduce STARec, a slow-thinking augmented agent framework that endows\nrecommender systems with autonomous deliberative reasoning capabilities. Each\nuser is modeled as an agent with parallel cognitions: fast response for\nimmediate interactions and slow reasoning that performs chain-of-thought\nrationales. To cultivate intrinsic slow thinking, we develop anchored\nreinforcement training - a two-stage paradigm combining structured knowledge\ndistillation from advanced reasoning models with preference-aligned reward\nshaping. This hybrid approach scaffolds agents in acquiring foundational\ncapabilities (preference summarization, rationale generation) while enabling\ndynamic policy adaptation through simulated feedback loops. Experiments on\nMovieLens 1M and Amazon CDs benchmarks demonstrate that STARec achieves\nsubstantial performance gains compared with state-of-the-art baselines, despite\nusing only 0.4% of the full training data.", "AI": {"tldr": "STARec\u662f\u4e00\u4e2a\u6162\u601d\u8003\u589e\u5f3a\u7684\u63a8\u8350\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u8ba4\u77e5\u7cfb\u7edf\uff08\u5feb\u901f\u54cd\u5e94+\u6162\u901f\u63a8\u7406\uff09\u548c\u951a\u5b9a\u5f3a\u5316\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4ec5\u75280.4%\u8bad\u7ec3\u6570\u636e\u5c31\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u65b9\u6cd5", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u53d7\u9650\u4e8e\u9759\u6001\u7528\u6237\u5efa\u6a21\u548c\u88ab\u52a8\u51b3\u7b56\u8303\u5f0f\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u4e5f\u5b58\u5728\u8fc7\u5ea6\u4f9d\u8d56\u542f\u53d1\u5f0f\u6a21\u5f0f\u5339\u914d\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6d45\u5c42\u76f8\u5173\u504f\u5dee\u3001\u6709\u9650\u56e0\u679c\u63a8\u7406\u548c\u7a00\u758f\u6570\u636e\u573a\u666f\u4e0b\u7684\u8106\u5f31\u6027", "method": "\u63d0\u51faSTARec\u6846\u67b6\uff1a1\uff09\u5c06\u7528\u6237\u5efa\u6a21\u4e3a\u5177\u6709\u5e76\u884c\u8ba4\u77e5\u7684\u4ee3\u7406\uff08\u5feb\u901f\u54cd\u5e94+\u6162\u901f\u63a8\u7406\u94fe\uff09\uff1b2\uff09\u5f00\u53d1\u951a\u5b9a\u5f3a\u5316\u8bad\u7ec3\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u77e5\u8bc6\u84b8\u998f\u548c\u504f\u597d\u5bf9\u9f50\u5956\u52b1\u5851\u9020\uff1b3\uff09\u901a\u8fc7\u6a21\u62df\u53cd\u9988\u5faa\u73af\u5b9e\u73b0\u52a8\u6001\u7b56\u7565\u9002\u5e94", "result": "\u5728MovieLens 1M\u548cAmazon CDs\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSTARec\u76f8\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5c3d\u7ba1\u53ea\u4f7f\u7528\u4e860.4%\u7684\u5b8c\u6574\u8bad\u7ec3\u6570\u636e", "conclusion": "STARec\u901a\u8fc7\u5f15\u5165\u6162\u601d\u8003\u63a8\u7406\u80fd\u529b\u548c\u6df7\u5408\u8bad\u7ec3\u8303\u5f0f\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u81ea\u4e3b\u6df1\u601d\u719f\u8651\u7684\u63a8\u7406\u80fd\u529b"}}
{"id": "2508.18880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18880", "abs": "https://arxiv.org/abs/2508.18880", "authors": ["Eljas Linna", "Tuula Linna"], "title": "Judicial Requirements for Generative AI in Legal Reasoning", "comment": null, "summary": "Large Language Models (LLMs) are being integrated into professional domains,\nyet their limitations in high-stakes fields like law remain poorly understood.\nThis paper defines the core capabilities that an AI system must possess to\nfunction as a reliable reasoning tool in judicial decision-making. Using the\nIRAC (Issue-Rule-Application-Conclusion) model as an analytical framework, the\nstudy focuses on the most challenging phases of legal adjudication: determining\nthe applicable Rule (R) and performing the Application (A) of that rule to the\nfacts of a case. From a judicial perspective, the analysis deconstructs legal\nreasoning into a series of core requirements, including the ability to select\nthe correct legal framework across jurisdictions, generate sound arguments\nbased on the doctrine of legal sources, distinguish ratio decidendi from obiter\ndictum in case law, resolve ambiguity arising from general clauses like\n\"reasonableness\", manage conflicting legal provisions, and correctly apply the\nburden of proof. The paper then maps various AI enhancement mechanisms, such as\nRetrieval-Augmented Generation (RAG), multi-agent systems, and neuro-symbolic\nAI, to these requirements, assessing their potential to bridge the gap between\nthe probabilistic nature of LLMs and the rigorous, choice-driven demands of\nlegal interpretation. The findings indicate that while these techniques can\naddress specific challenges, significant challenges remain, particularly in\ntasks requiring discretion and transparent, justifiable reasoning. Our paper\nconcludes that the most effective current role for AI in law is a dual one: as\na high-volume assistant for simple, repetitive cases and as a sophisticated\n\"sparring partner\" for human experts in complex matters.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5206\u6790\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u5224\u51b3\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u91c7\u7528IRAC\u6a21\u578b\u5b9a\u4e49\u4e86\u6cd5\u5f8b\u63a8\u7406\u7684\u6838\u5fc3\u8981\u6c42\uff0c\u5e76\u8bc4\u4f30\u4e86RAG\u3001\u591a\u4ee3\u7406\u7cfb\u7edf\u7b49AI\u589e\u5f3a\u6280\u672f\u7684\u6f5c\u529b\u3002\u7ed3\u679c\u663e\u793a\u5f53\u524dAI\u5728\u6cd5\u5f8b\u9886\u57df\u6700\u5408\u9002\u7684\u89d2\u8272\u662f\u5904\u7406\u7b80\u5355\u6848\u4ef6\u7684\u9ad8\u6548\u52a9\u624b\u548c\u590d\u6742\u6848\u4ef6\u4e2d\u7684\u4e13\u5bb6\u8ba8\u8bba\u5bf9\u8c61\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u88ab\u96c6\u6210\u5230\u4e13\u4e1a\u9886\u57df\uff0c\u5bf9\u5176\u5728\u6cd5\u5f8b\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5b9e\u9645\u9650\u5236\u4ecd\u7136\u4e86\u89e3\u4e0d\u6df1\u5165\u3002\u8bba\u6587\u5f3a\u8c03\u9700\u8981\u5b9a\u4e49AI\u7cfb\u7edf\u5728\u53f8\u6cd5\u51b3\u7b56\u4e2d\u4f5c\u4e3a\u53ef\u9760\u63a8\u7406\u5de5\u5177\u6240\u5fc5\u987b\u5177\u5907\u7684\u6838\u5fc3\u80fd\u529b\u3002", "method": "\u91c7\u7528IRAC\uff08Issue-Rule-Application-Conclusion\uff09\u6a21\u578b\u4f5c\u4e3a\u5206\u6790\u6846\u67b6\uff0c\u91cd\u70b9\u7814\u7a76\u6cd5\u5f8b\u88c1\u5224\u4e2d\u6700\u5177\u6311\u6218\u6027\u7684\u9636\u6bb5\uff1a\u786e\u5b9a\u9002\u7528\u89c4\u5219\uff08R\uff09\u548c\u5c06\u89c4\u5219\u5e94\u7528\u4e8e\u6848\u4ef6\u4e8b\u5b9e\uff08A\uff09\u3002\u4ece\u53f8\u6cd5\u89d2\u5ea6\u89e3\u6784\u6cd5\u5f8b\u63a8\u7406\u7684\u4e00\u7cfb\u5217\u6838\u5fc3\u8981\u6c42\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u867d\u7136RAG\u3001\u591a\u4ee3\u7406\u7cfb\u7edf\u3001\u795e\u7ecf\u7b26\u53f7AI\u7b49\u589e\u5f3a\u6280\u672f\u80fd\u591f\u89e3\u51b3\u7279\u5b9a\u6311\u6218\uff0c\u4f46\u5728\u9700\u8981\u81ea\u7531\u88c1\u91cf\u6743\u548c\u900f\u660e\u3001\u53ef\u8bc1\u660e\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002", "conclusion": "\u5f53\u524dAI\u5728\u6cd5\u5f8b\u9886\u57df\u6700\u6709\u6548\u7684\u89d2\u8272\u662f\u53cc\u91cd\u7684\uff1a\u4f5c\u4e3a\u5904\u7406\u7b80\u5355\u3001\u91cd\u590d\u6027\u6848\u4ef6\u7684\u9ad8\u6548\u52a9\u624b\uff0c\u4ee5\u53ca\u5728\u590d\u6742\u4e8b\u52a1\u4e2d\u4f5c\u4e3a\u4eba\u7c7b\u4e13\u5bb6\u7684\u7cbe\u5de7\"\u8ba8\u8bba\u5bf9\u624b\"\u3002"}}
{"id": "2508.18905", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18905", "abs": "https://arxiv.org/abs/2508.18905", "authors": ["Dimitrios Rontogiannis", "Maxime Peyrard", "Nicolas Baldwin", "Martin Josifoski", "Robert West", "Dimitrios Gunopulos"], "title": "Interactive Evaluation of Large Language Models for Multi-Requirement Software Engineering Tasks", "comment": null, "summary": "Standard single-turn, static benchmarks fall short in evaluating the nuanced\ncapabilities of Large Language Models (LLMs) on complex tasks such as software\nengineering. In this work, we propose a novel interactive evaluation framework\nthat assesses LLMs on multi-requirement programming tasks through structured,\nfeedback-driven dialogue. Each task is modeled as a requirement dependency\ngraph, and an ``interviewer'' LLM, aware of the ground-truth solution, provides\nminimal, targeted hints to an ``interviewee'' model to help correct errors and\nfulfill target constraints. This dynamic protocol enables fine-grained\ndiagnostic insights into model behavior, uncovering strengths and systematic\nweaknesses that static benchmarks fail to measure. We build on DevAI, a\nbenchmark of 55 curated programming tasks, by adding ground-truth solutions and\nevaluating the relevance and utility of interviewer hints through expert\nannotation. Our results highlight the importance of dynamic evaluation in\nadvancing the development of collaborative code-generating agents.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u4ea4\u4e92\u5f0f\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u53cd\u9988\u5bfc\u5411\u5bf9\u8bdd\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8981\u6c42\u7f16\u7a0b\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u9759\u6001\u6d4b\u8bd5\u65e0\u6cd5\u53d1\u73b0\u7684\u7cfb\u7edf\u6027\u5f31\u70b9\u3002", "motivation": "\u6807\u51c6\u7684\u5355\u8f6e\u9759\u6001\u6d4b\u8bd5\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30LLM\u5728\u590d\u6742\u4efb\u52a1\uff08\u5982\u8f6f\u4ef6\u5de5\u7a0b\uff09\u4e2d\u7684\u7ec6\u5fae\u80fd\u529b\uff0c\u9700\u8981\u66f4\u52a8\u6001\u3001\u4ea4\u4e92\u5f0f\u7684\u8bc4\u6d4b\u65b9\u6cd5\u6765\u63ed\u793a\u6a21\u578b\u7684\u771f\u5b9e\u8868\u73b0\u3002", "method": "\u5efa\u7acb\u4e00\u79cd\u4ea4\u4e92\u5f0f\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u6bcf\u4e2a\u4efb\u52a1\u6a21\u578b\u5316\u4e3a\u9700\u6c42\u4f9d\u8d56\u56fe\u3002\u7531\u77e5\u9053\u771f\u5b9e\u89e3\u51b3\u65b9\u6848\u7684\"\u9762\u8bd5\u5b98\"LLM\u5411\"\u9762\u8bd5\u8005\"\u6a21\u578b\u63d0\u4f9b\u6709\u9488\u5bf9\u6027\u7684\u63d0\u793a\uff0c\u5e2e\u52a9\u5176\u7ea0\u6b63\u9519\u8bef\u5e76\u6ee1\u8db3\u76ee\u6807\u7ea6\u675f\u3002\u57fa\u4e8eDevAI\u8bc4\u6d4b\u96c6\u768455\u4e2a\u7f16\u7a0b\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u8be5\u52a8\u6001\u534f\u8bae\u80fd\u591f\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u7684\u8bca\u65ad\u89c1\u89e3\uff0c\u53d1\u73b0\u4e86\u9759\u6001\u6d4b\u8bd5\u65e0\u6cd5\u6d4b\u91cf\u7684\u7cfb\u7edf\u6027\u5f31\u70b9\u5484\u4f18\u52bf\u3002\u4e13\u5bb6\u6ce8\u91ca\u8bc4\u4f30\u8bc1\u660e\u4e86\u9762\u8bd5\u5b98\u63d0\u793a\u7684\u76f8\u5173\u6027\u5484\u5b9e\u7528\u6027\u3002", "conclusion": "\u52a8\u6001\u8bc4\u4f30\u5bf9\u4e8e\u63a8\u8fdb\u534f\u4f5c\u5f0f\u4ee3\u7801\u751f\u6210\u4ee3\u7406\u7684\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u66f4\u5168\u9762\u5730\u8bc4\u4f30LLM\u5728\u590d\u6742\u7f16\u7a0b\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u3002"}}
{"id": "2508.18914", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18914", "abs": "https://arxiv.org/abs/2508.18914", "authors": ["Yanxing Huang", "Xinling Jin", "Sijie Liang", "Peng Li", "Yang Liu"], "title": "FormaRL: Enhancing Autoformalization with no Labeled Data", "comment": "Conference paper at COLM2025", "summary": "Autoformalization is one of the central tasks in formal verification, while\nits advancement remains hindered due to the data scarcity and the absence\nefficient methods. In this work we propose \\textbf{FormaRL}, a simple yet\nefficient reinforcement learning framework for autoformalization which only\nrequires a small amount of unlabeled data. FormaRL integrates syntax check from\nLean compiler and consistency check from large language model to calculate the\nreward, and adopts GRPO algorithm to update the formalizer. We also curated a\nproof problem dataset from undergraduate-level math materials, named\n\\textbf{uproof}, in the hope to facilitate the exploration of autoformalization\nand theorem proving in advanced math. Experiments show that FormaRL can\nincrease the pass@1 autoformalization accuracy of Qwen2.5-Coder-7B-Instruct by\n4 $\\sim$ 6x (4.04\\% $\\to$ 26.15\\% on ProofNet and 2.4\\% $\\to$ 9.6\\% on uproof)\nwith merely 859 unlabeled data. And on uproof our method also achieved a strong\nimprovement in out-of-distribution performance compared to existing open-source\nstate-of-the-art autoformalizers on both pass@1 accuracy (6.2\\% $\\to$ 9.6\\%)\nand pass@16 accuracy (24.4\\% $\\to$ 33.6\\%). Training code of FormaRL is\nopen-sourced at https://github.com/THUNLP-MT/FormaRL.", "AI": {"tldr": "FormaRL\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u4ec5\u9700\u5c11\u91cf\u65e0\u6807\u6ce8\u6570\u636e\uff0c\u901a\u8fc7\u6574\u5408Lean\u7f16\u8bd1\u5668\u7684\u8bed\u6cd5\u68c0\u67e5\u548cLLM\u7684\u4e00\u81f4\u6027\u68c0\u67e5\u6765\u8ba1\u7b97\u5956\u52b1\uff0c\u4f7f\u7528GRPO\u7b97\u6cd5\u66f4\u65b0\u5f62\u5f0f\u5316\u5668\uff0c\u5728ProofNet\u548cuproof\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u51c6\u786e\u7387\u3002", "motivation": "\u81ea\u52a8\u5f62\u5f0f\u5316\u662f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u6838\u5fc3\u4efb\u52a1\uff0c\u4f46\u53d7\u9650\u4e8e\u6570\u636e\u7a00\u7f3a\u548c\u7f3a\u4e4f\u9ad8\u6548\u65b9\u6cd5\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u9ad8\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u63d0\u51faFormaRL\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528Lean\u7f16\u8bd1\u5668\u7684\u8bed\u6cd5\u68c0\u67e5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e00\u81f4\u6027\u68c0\u67e5\u6765\u8ba1\u7b97\u5956\u52b1\u4fe1\u53f7\uff0c\u91c7\u7528GRPO\u7b97\u6cd5\u8bad\u7ec3\u5f62\u5f0f\u5316\u5668\u3002\u540c\u65f6\u6784\u5efa\u4e86uproof\u6570\u5b66\u8bc1\u660e\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u663e\u793aFormaRL\u5c06Qwen2.5-Coder-7B-Instruct\u7684pass@1\u51c6\u786e\u7387\u63d0\u5347\u4e864-6\u500d\uff08ProofNet\u4ece4.04%\u523026.15%\uff0cuproof\u4ece2.4%\u52309.6%\uff09\uff0c\u4ec5\u4f7f\u7528859\u4e2a\u65e0\u6807\u6ce8\u6570\u636e\u3002\u5728uproof\u6570\u636e\u96c6\u4e0a\uff0cout-of-distribution\u6027\u80fd\u4e5f\u663e\u8457\u63d0\u5347\u3002", "conclusion": "FormaRL\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4ec5\u9700\u5c11\u91cf\u65e0\u6807\u6ce8\u6570\u636e\u5c31\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u9ad8\u7ea7\u6570\u5b66\u9886\u57df\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u548c\u5b9a\u7406\u8bc1\u660e\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2508.18925", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18925", "abs": "https://arxiv.org/abs/2508.18925", "authors": ["Qian Xiao", "Conn Breathnach", "Ioana Ghergulescu", "Conor O'Sullivan", "Keith Johnston", "Vincent Wade"], "title": "Who Is Lagging Behind: Profiling Student Behaviors with Graph-Level Encoding in Curriculum-Based Online Learning Systems", "comment": null, "summary": "The surge in the adoption of Intelligent Tutoring Systems (ITSs) in\neducation, while being integral to curriculum-based learning, can inadvertently\nexacerbate performance gaps. To address this problem, student profiling becomes\ncrucial for tracking progress, identifying struggling students, and alleviating\ndisparities among students. Such profiling requires measuring student behaviors\nand performance across different aspects, such as content coverage, learning\nintensity, and proficiency in different concepts within a learning topic.\n  In this study, we introduce CTGraph, a graph-level representation learning\napproach to profile learner behaviors and performance in a self-supervised\nmanner. Our experiments demonstrate that CTGraph can provide a holistic view of\nstudent learning journeys, accounting for different aspects of student\nbehaviors and performance, as well as variations in their learning paths as\naligned to the curriculum structure. We also show that our approach can\nidentify struggling students and provide comparative analysis of diverse groups\nto pinpoint when and where students are struggling. As such, our approach opens\nmore opportunities to empower educators with rich insights into student\nlearning journeys and paves the way for more targeted interventions.", "AI": {"tldr": "CTGraph\u662f\u4e00\u79cd\u56fe\u7ea7\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u76d1\u7763\u5730\u5206\u6790\u5b66\u4e60\u8005\u5728\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u4e2d\u7684\u884c\u4e3a\u548c\u8868\u73b0\uff0c\u80fd\u591f\u5168\u9762\u8ffd\u8e2a\u5b66\u4e60\u8def\u5f84\u5e76\u8bc6\u522b\u56f0\u96be\u5b66\u751f\u3002", "motivation": "\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u5728\u6559\u80b2\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u53ef\u80fd\u65e0\u610f\u4e2d\u52a0\u5267\u6210\u7ee9\u5dee\u8ddd\uff0c\u9700\u8981\u901a\u8fc7\u5b66\u751f\u753b\u50cf\u6765\u8ddf\u8e2a\u8fdb\u5ea6\u3001\u8bc6\u522b\u56f0\u96be\u5b66\u751f\u5e76\u51cf\u5c11\u5b66\u751f\u95f4\u7684\u5dee\u5f02\u3002", "method": "\u63d0\u51faCTGraph\u56fe\u7ea7\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u81ea\u76d1\u7763\u65b9\u5f0f\u5206\u6790\u5b66\u4e60\u8005\u7684\u884c\u4e3a\u548c\u8868\u73b0\uff0c\u8003\u8651\u5185\u5bb9\u8986\u76d6\u3001\u5b66\u4e60\u5f3a\u5ea6\u548c\u6982\u5ff5\u719f\u7ec3\u5ea6\u7b49\u591a\u4e2a\u7ef4\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eCTGraph\u80fd\u591f\u63d0\u4f9b\u5b66\u751f\u5b66\u4e60\u65c5\u7a0b\u7684\u5168\u9762\u89c6\u56fe\uff0c\u8bc6\u522b\u56f0\u96be\u5b66\u751f\uff0c\u5e76\u8fdb\u884c\u7fa4\u4f53\u6bd4\u8f83\u5206\u6790\u4ee5\u786e\u5b9a\u5b66\u751f\u4f55\u65f6\u4f55\u5730\u9047\u5230\u56f0\u96be\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6559\u80b2\u5de5\u4f5c\u8005\u63d0\u4f9b\u4e86\u5bf9\u5b66\u751f\u5b66\u4e60\u65c5\u7a0b\u7684\u6df1\u5165\u6d1e\u5bdf\uff0c\u4e3a\u66f4\u6709\u9488\u5bf9\u6027\u7684\u5e72\u9884\u63aa\u65bd\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2508.18933", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18933", "abs": "https://arxiv.org/abs/2508.18933", "authors": ["David Egea", "Barproda Halder", "Sanghamitra Dutta"], "title": "VISION: Robust and Interpretable Code Vulnerability Detection Leveraging Counterfactual Augmentation", "comment": null, "summary": "Automated detection of vulnerabilities in source code is an essential\ncybersecurity challenge, underpinning trust in digital systems and services.\nGraph Neural Networks (GNNs) have emerged as a promising approach as they can\nlearn structural and logical code relationships in a data-driven manner.\nHowever, their performance is severely constrained by training data imbalances\nand label noise. GNNs often learn 'spurious' correlations from superficial code\nsimilarities, producing detectors that fail to generalize well to unseen\nreal-world data. In this work, we propose a unified framework for robust and\ninterpretable vulnerability detection, called VISION, to mitigate spurious\ncorrelations by systematically augmenting a counterfactual training dataset.\nCounterfactuals are samples with minimal semantic modifications but opposite\nlabels. Our framework includes: (i) generating counterfactuals by prompting a\nLarge Language Model (LLM); (ii) targeted GNN training on paired code examples\nwith opposite labels; and (iii) graph-based interpretability to identify the\ncrucial code statements relevant for vulnerability predictions while ignoring\nspurious ones. We find that VISION reduces spurious learning and enables more\nrobust, generalizable detection, improving overall accuracy (from 51.8% to\n97.8%), pairwise contrast accuracy (from 4.5% to 95.8%), and worst-group\naccuracy (from 0.7% to 85.5%) on the Common Weakness Enumeration (CWE)-20\nvulnerability. We further demonstrate gains using proposed metrics: intra-class\nattribution variance, inter-class attribution distance, and node score\ndependency. We also release CWE-20-CFA, a benchmark of 27,556 functions (real\nand counterfactual) from the high-impact CWE-20 category. Finally, VISION\nadvances transparent and trustworthy AI-based cybersecurity systems through\ninteractive visualization for human-in-the-loop analysis.", "AI": {"tldr": "VISION\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6f0f\u6d1e\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u53cd\u4e8b\u5b9e\u6837\u672c\u548c\u9488\u5bf9\u6027GNN\u8bad\u7ec3\u6765\u51cf\u5c11\u865a\u5047\u76f8\u5173\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eGNN\u7684\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u53d7\u5230\u8bad\u7ec3\u6570\u636e\u4e0d\u5e73\u8861\u548c\u6807\u7b7e\u566a\u58f0\u7684\u9650\u5236\uff0c\u5bb9\u6613\u5b66\u4e60\u5230\u865a\u5047\u7684\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "method": "\u63d0\u51faVISION\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53cd\u4e8b\u5b9e\u6837\u672c\uff1b2\uff09\u5728\u5177\u6709\u76f8\u53cd\u6807\u7b7e\u7684\u914d\u5bf9\u4ee3\u7801\u793a\u4f8b\u4e0a\u8fdb\u884c\u9488\u5bf9\u6027GNN\u8bad\u7ec3\uff1b3\uff09\u57fa\u4e8e\u56fe\u7684\u53ef\u89e3\u91ca\u6027\u5206\u6790\u6765\u8bc6\u522b\u5173\u952e\u4ee3\u7801\u8bed\u53e5\u3002", "result": "\u5728CWE-20\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\uff0c\u6574\u4f53\u51c6\u786e\u7387\u4ece51.8%\u63d0\u5347\u523097.8%\uff0c\u914d\u5bf9\u5bf9\u6bd4\u51c6\u786e\u7387\u4ece4.5%\u63d0\u5347\u523095.8%\uff0c\u6700\u5dee\u7ec4\u51c6\u786e\u7387\u4ece0.7%\u63d0\u5347\u523085.5%\u3002", "conclusion": "VISION\u901a\u8fc7\u53cd\u4e8b\u5b9e\u8bad\u7ec3\u6709\u6548\u51cf\u5c11\u4e86\u865a\u5047\u5b66\u4e60\uff0c\u63d0\u9ad8\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u6784\u5efa\u53ef\u4fe1\u7684AI\u7f51\u7edc\u5b89\u5168\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2508.18953", "categories": ["cs.AI", "I.2.6; I.2.8; I.5.1"], "pdf": "https://arxiv.org/pdf/2508.18953", "abs": "https://arxiv.org/abs/2508.18953", "authors": ["I. I. Priezzhev", "D. A. Danko", "A. V. Shubin"], "title": "Novel Approaches to Artificial Intelligence Development Based on the Nearest Neighbor Method", "comment": "18 pages, 6 figures. Novel hierarchical neural networks based on\n  k-nearest neighbors method for addressing hallucination effects, training\n  complexity, and catastrophic forgetting in modern AI systems. Includes\n  mathematical formulations using Kohonen self-organizing maps and experimental\n  validation on MNIST handwritten digit recognition and machine translation\n  tasks", "summary": "Modern neural network technologies, including large language models, have\nachieved remarkable success in various applied artificial intelligence\napplications, however, they face a range of fundamental limitations. Among them\nare hallucination effects, high computational complexity of training and\ninference, costly fine-tuning, and catastrophic forgetting issues. These\nlimitations significantly hinder the use of neural networks in critical areas\nsuch as medicine, industrial process management, and scientific research. This\narticle proposes an alternative approach based on the nearest neighbors method\nwith hierarchical clustering structures. Employing the k-nearest neighbors\nalgorithm significantly reduces or completely eliminates hallucination effects\nwhile simplifying model expansion and fine-tuning without the need for\nretraining the entire network. To overcome the high computational load of the\nk-nearest neighbors method, the paper proposes using tree-like data structures\nbased on Kohonen self-organizing maps, thereby greatly accelerating nearest\nneighbor searches. Tests conducted on handwritten digit recognition and simple\nsubtitle translation tasks confirmed the effectiveness of the proposed\napproach. With only a slight reduction in accuracy, the nearest neighbor search\ntime was reduced hundreds of times compared to exhaustive search methods. The\nproposed method features transparency and interpretability, closely aligns with\nhuman cognitive mechanisms, and demonstrates potential for extensive use in\ntasks requiring high reliability and explainable results.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c42\u6b21\u805a\u7c7b\u7ed3\u6784\u7684k\u8fd1\u90bb\u7b97\u6cd5\u65b9\u6848\uff0c\u7528\u4e8e\u514b\u670d\u795e\u7ecf\u7f51\u7edc\u7684\u5e7b\u89c9\u6548\u5e94\u3001\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u6050\u6016\u9057\u5fd8\u7b49\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u6280\u672f\u5b58\u5728\u5e7b\u89c9\u6548\u5e94\u3001\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u5fae\u8c03\u6210\u672c\u9ad8\u548c\u6050\u6016\u9057\u5fd8\u7b49\u57fa\u672c\u9650\u5236\uff0c\u5f71\u54cd\u5728\u533b\u7597\u3001\u5de5\u4e1a\u7ba1\u7406\u548c\u79d1\u7814\u7b49\u5173\u952e\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u57fa\u4e8ek\u8fd1\u90bb\u7b97\u6cd5\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7Kohonen\u81ea\u7ec4\u7ec7\u5730\u56fe\u6784\u5efa\u6811\u72b6\u6570\u636e\u7ed3\u6784\u6765\u52a0\u901f\u8fd1\u90bb\u641c\u7d22\uff0c\u51cf\u5c11\u8ba1\u7b97\u8d1f\u8377\u3002", "result": "\u5728\u624b\u5199\u6570\u5b57\u8bc6\u522b\u548c\u5b50\u5e16\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\u3002\u5728\u51c6\u786e\u7387\u4e0a\u4ec5\u6709\u8f7b\u5fae\u4e0b\u964d\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd1\u90bb\u641c\u7d22\u65f6\u95f4\u6bd4\u5168\u5c40\u641c\u7d22\u51cf\u5c11\u4e86\u767e\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u673a\u5236\u7d27\u5bc6\u7ed3\u5408\uff0c\u5728\u9700\u8981\u9ad8\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u7ed3\u679c\u7684\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.18983", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18983", "abs": "https://arxiv.org/abs/2508.18983", "authors": ["Guoying Zhu", "Meng Li", "Haipeng Dai", "Xuechen Liu", "Weijun Wang", "Keran Li", "Jun xiao", "Ligeng Chen", "Wei Wang"], "title": "Enabling MoE on the Edge via Importance-Driven Expert Scheduling", "comment": null, "summary": "The Mixture of Experts (MoE) architecture has emerged as a key technique for\nscaling Large Language Models by activating only a subset of experts per query.\nDeploying MoE on consumer-grade edge hardware, however, is constrained by\nlimited device memory, making dynamic expert offloading essential. Unlike prior\nwork that treats offloading purely as a scheduling problem, we leverage expert\nimportance to guide decisions, substituting low-importance activated experts\nwith functionally similar ones already cached in GPU memory, thereby preserving\naccuracy. As a result, this design reduces memory usage and data transfer,\nwhile largely eliminating PCIe overhead. In addition, we introduce a scheduling\npolicy that maximizes the reuse ratio of GPU-cached experts, further boosting\nefficiency. Extensive evaluations show that our approach delivers 48% lower\ndecoding latency with over 60% expert cache hit rate, while maintaining nearly\nlossless accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e13\u5bb6\u91cd\u8981\u6027\u7684\u52a8\u6001\u5378\u8f7d\u65b9\u6cd5\uff0c\u901a\u8fc7\u66ff\u6362\u4f4e\u91cd\u8981\u6027\u4e13\u5bb6\u4e3aGPU\u5185\u5b58\u4e2d\u5df2\u7f13\u5b58\u7684\u76f8\u4f3c\u4e13\u5bb6\uff0c\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u548c\u6570\u636e\u4f20\u8f93\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u6d88\u8d39\u7ea7\u8fb9\u7f18\u786c\u4ef6\u4e0a\u90e8\u7f72\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u65f6\uff0c\u8bbe\u5907\u5185\u5b58\u6709\u9650\uff0c\u9700\u8981\u9ad8\u6548\u7684\u52a8\u6001\u4e13\u5bb6\u5378\u8f7d\u65b9\u6848\u3002", "method": "\u5229\u7528\u4e13\u5bb6\u91cd\u8981\u6027\u6307\u5bfc\u5378\u8f7d\u51b3\u7b56\uff0c\u7528GPU\u5185\u5b58\u4e2d\u5df2\u7f13\u5b58\u7684\u76f8\u4f3c\u4e13\u5bb6\u66ff\u6362\u4f4e\u91cd\u8981\u6027\u6fc0\u6d3b\u4e13\u5bb6\uff0c\u5e76\u5f15\u5165\u6700\u5927\u5316GPU\u7f13\u5b58\u4e13\u5bb6\u91cd\u7528\u7387\u7684\u8c03\u5ea6\u7b56\u7565\u3002", "result": "\u5b9e\u73b0\u4e8648%\u7684\u89e3\u7801\u5ef6\u8fdf\u964d\u4f4e\uff0c\u8d85\u8fc760%\u7684\u4e13\u5bb6\u7f13\u5b58\u547d\u4e2d\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u51e0\u4e4e\u65e0\u635f\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86MoE\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5185\u5b58\u7ea6\u675f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u90e8\u7f72\u6548\u7387\u3002"}}
{"id": "2508.19004", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19004", "abs": "https://arxiv.org/abs/2508.19004", "authors": ["Pontus Strimling", "Simon Karlsson", "Irina Vartanova", "Kimmo Eriksson"], "title": "AI Models Exceed Individual Human Accuracy in Predicting Everyday Social Norms", "comment": "18 pages + supplementy materials", "summary": "A fundamental question in cognitive science concerns how social norms are\nacquired and represented. While humans typically learn norms through embodied\nsocial experience, we investigated whether large language models can achieve\nsophisticated norm understanding through statistical learning alone. Across two\nstudies, we systematically evaluated multiple AI systems' ability to predict\nhuman social appropriateness judgments for 555 everyday scenarios by examining\nhow closely they predicted the average judgment compared to each human\nparticipant. In Study 1, GPT-4.5's accuracy in predicting the collective\njudgment on a continuous scale exceeded that of every human participant (100th\npercentile). Study 2 replicated this, with Gemini 2.5 Pro outperforming 98.7%\nof humans, GPT-5 97.8%, and Claude Sonnet 4 96.0%. Despite this predictive\npower, all models showed systematic, correlated errors. These findings\ndemonstrate that sophisticated models of social cognition can emerge from\nstatistical learning over linguistic data alone, challenging strong versions of\ntheories emphasizing the exclusive necessity of embodied experience for\ncultural competence. The systematic nature of AI limitations across different\narchitectures indicates potential boundaries of pattern-based social\nunderstanding, while the models' ability to outperform nearly all individual\nhumans in this predictive task suggests that language serves as a remarkably\nrich repository for cultural knowledge transmission.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u7eaf\u7edf\u8ba1\u5b66\u4e60\u5c31\u80fd\u8d85\u8d8a\u5927\u591a\u6570\u4eba\u7c7b\u5728\u9884\u6d4b\u793e\u4f1a\u89c4\u8303\u5224\u65ad\u65b9\u9762\u7684\u8868\u73b0\uff0c\u6311\u6218\u4e86\u9700\u8981\u5177\u8eab\u7ecf\u9a8c\u624d\u80fd\u83b7\u5f97\u6587\u5316\u80fd\u529b\u7684\u7406\u8bba", "motivation": "\u7814\u7a76\u793e\u4f1a\u89c4\u8303\u5982\u4f55\u88ab\u83b7\u53d6\u548c\u8868\u5f81\uff0c\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u662f\u5426\u4ec5\u901a\u8fc7\u7edf\u8ba1\u5b66\u4e60\u5c31\u80fd\u8fbe\u5230\u590d\u6742\u7684\u793e\u4f1a\u89c4\u8303\u7406\u89e3", "method": "\u901a\u8fc7\u4e24\u4e2a\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u591a\u4e2aAI\u7cfb\u7edf\u9884\u6d4b555\u4e2a\u65e5\u5e38\u573a\u666f\u4e2d\u4eba\u7c7b\u793e\u4f1a\u9002\u5b9c\u6027\u5224\u65ad\u7684\u80fd\u529b\uff0c\u6bd4\u8f83\u6a21\u578b\u9884\u6d4b\u4e0e\u4eba\u7c7b\u5e73\u5747\u5224\u65ad\u7684\u63a5\u8fd1\u7a0b\u5ea6", "result": "GPT-4.5\u5728\u8fde\u7eed\u5c3a\u5ea6\u4e0a\u9884\u6d4b\u96c6\u4f53\u5224\u65ad\u7684\u51c6\u786e\u6027\u8d85\u8fc7\u6240\u6709\u4eba\u7c7b\u53c2\u4e0e\u8005\uff08\u7b2c100\u767e\u5206\u4f4d\uff09\uff0c\u5176\u4ed6\u6a21\u578b\u4e5f\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u90fd\u5b58\u5728\u7cfb\u7edf\u6027\u7684\u76f8\u5173\u9519\u8bef", "conclusion": "\u7edf\u8ba1\u5b66\u4e60\u8db3\u4ee5\u4ea7\u751f\u590d\u6742\u7684\u793e\u4f1a\u8ba4\u77e5\u6a21\u578b\uff0c\u8bed\u8a00\u4f5c\u4e3a\u6587\u5316\u77e5\u8bc6\u4f20\u64ad\u7684\u4e30\u5bcc\u50a8\u5b58\u5e93\uff0c\u4f46\u57fa\u4e8e\u6a21\u5f0f\u7684\u793e\u4f1a\u7406\u89e3\u5b58\u5728\u6f5c\u5728\u8fb9\u754c"}}
{"id": "2508.19005", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.19005", "abs": "https://arxiv.org/abs/2508.19005", "authors": ["Yuxuan Cai", "Yipeng Hao", "Jie Zhou", "Hang Yan", "Zhikai Lei", "Rui Zhen", "Zhenhua Han", "Yutao Yang", "Junsong Li", "Qianjun Pan", "Tianyu Huai", "Qin Chen", "Xin Li", "Kai Chen", "Bo Zhang", "Xipeng Qiu", "Liang He"], "title": "Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A Framework and Benchmark", "comment": null, "summary": "As AI advances toward general intelligence, the focus is shifting from\nsystems optimized for static tasks to creating open-ended agents that learn\ncontinuously. In this paper, we introduce Experience-driven Lifelong Learning\n(ELL), a framework for building self-evolving agents capable of continuous\ngrowth through real-world interaction. The framework is built on four core\nprinciples: (1) Experience Exploration: Agents learn through continuous,\nself-motivated interaction with dynamic environments, navigating interdependent\ntasks and generating rich experiential trajectories. (2) Long-term Memory:\nAgents preserve and structure historical knowledge, including personal\nexperiences, domain expertise, and commonsense reasoning, into a persistent\nmemory system. (3) Skill Learning: Agents autonomously improve by abstracting\nrecurring patterns from experience into reusable skills, which are actively\nrefined and validated for application in new tasks. (4) Knowledge\nInternalization: Agents internalize explicit and discrete experiences into\nimplicit and intuitive capabilities as \"second nature\".\n  We also introduce StuLife, a benchmark dataset for ELL that simulates a\nstudent's holistic college journey, from enrollment to academic and personal\ndevelopment, across three core phases and ten detailed sub-scenarios. StuLife\nis designed around three key paradigm shifts: From Passive to Proactive, From\nContext to Memory, and From Imitation to Learning. In this dynamic environment,\nagents must acquire and distill practical skills and maintain persistent memory\nto make decisions based on evolving state variables. StuLife provides a\ncomprehensive platform for evaluating lifelong learning capabilities, including\nmemory retention, skill transfer, and self-motivated behavior. Beyond\nevaluating SOTA LLMs on the StuLife benchmark, we also explore the role of\ncontext engineering in advancing AGI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7ecf\u9a8c\u9a71\u52a8\u7684\u7ec8\u8eab\u5b66\u4e60(ELL)\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u539f\u5219\uff1a\u7ecf\u9a8c\u63a2\u7d22\u3001\u957f\u671f\u8bb0\u5fc6\u3001\u6280\u80fd\u5b66\u4e60\u548c\u77e5\u8bc6\u5185\u5316\uff0c\u5e76\u63a8\u51fa\u4e86StuLife\u57fa\u51c6\u6570\u636e\u96c6\u6765\u6a21\u62df\u5b66\u751f\u5927\u5b66\u751f\u6d3b\uff0c\u7528\u4e8e\u8bc4\u4f30\u7ec8\u8eab\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u968f\u7740AI\u5411\u901a\u7528\u667a\u80fd\u53d1\u5c55\uff0c\u9700\u8981\u4ece\u9759\u6001\u4efb\u52a1\u4f18\u5316\u8f6c\u5411\u521b\u5efa\u80fd\u591f\u6301\u7eed\u5b66\u4e60\u7684\u5f00\u653e\u667a\u80fd\u4f53\uff0c\u6784\u5efa\u80fd\u591f\u901a\u8fc7\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u5b9e\u73b0\u6301\u7eed\u8fdb\u5316\u7684\u81ea\u8fdb\u5316\u667a\u80fd\u4f53\u3002", "method": "\u63d0\u51faELL\u6846\u67b6\uff0c\u57fa\u4e8e\u56db\u4e2a\u6838\u5fc3\u539f\u5219\uff1a\u7ecf\u9a8c\u63a2\u7d22\uff08\u901a\u8fc7\u81ea\u6fc0\u52b1\u4ea4\u4e92\u5b66\u4e60\uff09\u3001\u957f\u671f\u8bb0\u5fc6\uff08\u6784\u5efa\u6301\u4e45\u8bb0\u5fc6\u7cfb\u7edf\uff09\u3001\u6280\u80fd\u5b66\u4e60\uff08\u4ece\u7ecf\u9a8c\u4e2d\u62bd\u8c61\u53ef\u91cd\u7528\u6280\u80fd\uff09\u3001\u77e5\u8bc6\u5185\u5316\uff08\u5c06\u663e\u6027\u7ecf\u9a8c\u8f6c\u5316\u4e3a\u9690\u6027\u80fd\u529b\uff09\u3002\u540c\u65f6\u5f00\u53d1StuLife\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6a21\u62df\u5b66\u751f\u5927\u5b66\u751f\u6d3b\u7684\u4e09\u9636\u6bb5\u5341\u573a\u666f\u3002", "result": "\u5f00\u53d1\u4e86StuLife\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u4e3a\u8bc4\u4f30\u7ec8\u8eab\u5b66\u4e60\u80fd\u529b\u63d0\u4f9b\u4e86\u7efc\u5408\u5e73\u53f0\uff0c\u5305\u62ec\u8bb0\u5fc6\u4fdd\u6301\u3001\u6280\u80fd\u8fc1\u79fb\u548c\u81ea\u6fc0\u52b1\u884c\u4e3a\u7b49\u8bc4\u4f30\u7ef4\u5ea6\u3002", "conclusion": "ELL\u6846\u67b6\u4e3a\u6784\u5efa\u6301\u7eed\u5b66\u4e60\u7684\u5f00\u653e\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0cStuLife\u57fa\u51c6\u4e3a\u8bc4\u4f30\u7ec8\u8eab\u5b66\u4e60\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u540c\u65f6\u63a2\u7d22\u4e86\u4e0a\u4e0b\u6587\u5de5\u7a0b\u5728\u63a8\u8fdbAGI\u53d1\u5c55\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2508.19008", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19008", "abs": "https://arxiv.org/abs/2508.19008", "authors": ["Marcin Moskalewicz", "Anna Sterna", "Marek Pokropski", "Paula Flores"], "title": "Sense of Self and Time in Borderline Personality. A Comparative Robustness Study with Generative AI", "comment": "22 pages, 4 tables, submitted to \"Personality and Individual\n  Differences\"", "summary": "This study examines the capacity of large language models (LLMs) to support\nphenomenological qualitative analysis of first-person experience in Borderline\nPersonality Disorder (BPD), understood as a disorder of temporality and\nselfhood. Building on a prior human-led thematic analysis of 24 inpatients'\nlife-story interviews, we compared three LLMs (OpenAI GPT-4o, Google Gemini 2.5\nPro, Anthropic Claude Opus 4) prompted to mimic the interpretative style of the\noriginal investigators. The models were evaluated with blinded and non-blinded\nexpert judges in phenomenology and clinical psychology. Assessments included\nsemantic congruence, Jaccard coefficients, and multidimensional validity\nratings (credibility, coherence, substantiveness, and groundness in data).\nResults showed variable overlap with the human analysis, from 0 percent in GPT\nto 42 percent in Claude and 58 percent in Gemini, and a low Jaccard coefficient\n(0.21-0.28). However, the models recovered themes omitted by humans. Gemini's\noutput most closely resembled the human analysis, with validity scores\nsignificantly higher than GPT and Claude (p < 0.0001), and was judged as human\nby blinded experts. All scores strongly correlated (R > 0.78) with the quantity\nof text and words per theme, highlighting both the variability and potential of\nAI-augmented thematic analysis to mitigate human interpretative bias.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\u3001Gemini 2.5 Pro\u3001Claude Opus 4\uff09\u5728\u8fb9\u7f18\u578b\u4eba\u683c\u969c\u788d\u73b0\u8c61\u5b66\u5b9a\u6027\u5206\u6790\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0Gemini\u6700\u63a5\u8fd1\u4eba\u7c7b\u5206\u6790\u7ed3\u679c\uff0c\u6709\u6548\u6027\u8bc4\u5206\u663e\u8457\u9ad8\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u8c61\u5b66\u5b9a\u6027\u5206\u6790\u4e2d\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u9488\u5bf9\u8fb9\u7f18\u578b\u4eba\u683c\u969c\u788d\u8fd9\u79cd\u65f6\u95f4\u548c\u81ea\u6211\u969c\u788d\u7684\u75be\u75c5\uff0c\u65e8\u5728\u8bc4\u4f30AI\u8f85\u52a9\u5206\u6790\u5728\u51cf\u8f7b\u4eba\u7c7b\u89e3\u91ca\u504f\u89c1\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u57fa\u4e8e24\u540d\u4f4f\u9662\u60a3\u8005\u7684\u751f\u6d3b\u6545\u4e8b\u8bbf\u8c08\u6570\u636e\uff0c\u8ba9\u4e09\u79cdLLM\u6a21\u4eff\u539f\u59cb\u7814\u7a76\u8005\u7684\u89e3\u91ca\u98ce\u683c\u8fdb\u884c\u5206\u6790\uff0c\u91c7\u7528\u76f2\u6cd5\u548c\u975e\u76f2\u6cd5\u4e13\u5bb6\u8bc4\u4f30\uff0c\u5305\u62ec\u8bed\u4e49\u4e00\u81f4\u6027\u3001Jaccard\u7cfb\u6570\u548c\u591a\u7ef4\u6709\u6548\u6027\u8bc4\u5206\u3002", "result": "\u6a21\u578b\u4e0e\u4eba\u7c7b\u5206\u6790\u7684\u91cd\u5408\u5ea6\u4ece0%\uff08GPT\uff09\u523058%\uff08Gemini\uff09\u4e0d\u7b49\uff0cJaccard\u7cfb\u6570\u8f83\u4f4e\uff080.21-0.28\uff09\uff0c\u4f46\u6a21\u578b\u53d1\u73b0\u4e86\u4eba\u7c7b\u9057\u6f0f\u7684\u4e3b\u9898\u3002Gemini\u7684\u8f93\u51fa\u6700\u63a5\u8fd1\u4eba\u7c7b\u5206\u6790\uff0c\u6709\u6548\u6027\u8bc4\u5206\u663e\u8457\u66f4\u9ad8\uff0c\u4e14\u88ab\u76f2\u6cd5\u4e13\u5bb6\u5224\u65ad\u4e3a\u4eba\u7c7b\u5206\u6790\u3002", "conclusion": "AI\u589e\u5f3a\u7684\u4e3b\u9898\u5206\u6790\u5728\u73b0\u8c61\u5b66\u7814\u7a76\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u53d1\u73b0\u4eba\u7c7b\u53ef\u80fd\u9057\u6f0f\u7684\u4e3b\u9898\uff0c\u4f46\u6a21\u578b\u6027\u80fd\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8f93\u51fa\u8d28\u91cf\u4e0e\u6587\u672c\u91cf\u548c\u6bcf\u4e3b\u9898\u8bcd\u6570\u5bc6\u5207\u76f8\u5173\u3002"}}
{"id": "2508.19014", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19014", "abs": "https://arxiv.org/abs/2508.19014", "authors": ["Surajit Das", "Gourav Roy", "Aleksei Eliseev", "Ram Kumar Rajendran"], "title": "MAB Optimizer for Estimating Math Question Difficulty via Inverse CV without NLP", "comment": null, "summary": "The evolution of technology and education is driving the emergence of\nIntelligent & Autonomous Tutoring Systems (IATS), where objective and\ndomain-agnostic methods for determining question difficulty are essential.\nTraditional human labeling is subjective, and existing NLP-based approaches\nfail in symbolic domains like algebra. This study introduces the Approach of\nPassive Measures among Educands (APME), a reinforcement learning-based\nMulti-Armed Bandit (MAB) framework that estimates difficulty solely from solver\nperformance data -- marks obtained and time taken -- without requiring\nlinguistic features or expert labels. By leveraging the inverse coefficient of\nvariation as a risk-adjusted metric, the model provides an explainable and\nscalable mechanism for adaptive assessment. Empirical validation was conducted\non three heterogeneous datasets. Across these diverse contexts, the model\nachieved an average R2 of 0.9213 and an average RMSE of 0.0584, confirming its\nrobustness, accuracy, and adaptability to different educational levels and\nassessment formats. Compared with baseline approaches-such as regression-based,\nNLP-driven, and IRT models-the proposed framework consistently outperformed\nalternatives, particularly in purely symbolic domains. The findings highlight\nthat (i) item heterogeneity strongly influences perceived difficulty, and (ii)\nvariance in solver outcomes is as critical as mean performance for adaptive\nallocation. Pedagogically, the model aligns with Vygotskys Zone of Proximal\nDevelopment by identifying tasks that balance challenge and attainability,\nsupporting motivation while minimizing disengagement. This domain-agnostic,\nself-supervised approach advances difficulty tagging in IATS and can be\nextended beyond algebra wherever solver interaction data is available", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6APME\uff0c\u4ec5\u4f7f\u7528\u89e3\u9898\u8868\u73b0\u6570\u636e\uff08\u5206\u6570\u548c\u65f6\u95f4\uff09\u6765\u4f30\u8ba1\u9898\u76ee\u96be\u5ea6\uff0c\u65e0\u9700\u8bed\u8a00\u7279\u5f81\u6216\u4e13\u5bb6\u6807\u6ce8\uff0c\u5728\u7b26\u53f7\u9886\u57df\u8868\u73b0\u4f18\u5f02", "motivation": "\u4f20\u7edf\u4eba\u5de5\u6807\u6ce8\u4e3b\u89c2\u6027\u5f3a\uff0c\u73b0\u6709NLP\u65b9\u6cd5\u5728\u4ee3\u6570\u7b49\u7b26\u53f7\u9886\u57df\u5931\u6548\uff0c\u9700\u8981\u5ba2\u89c2\u4e14\u9886\u57df\u65e0\u5173\u7684\u9898\u76ee\u96be\u5ea6\u786e\u5b9a\u65b9\u6cd5", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\uff0c\u5229\u7528\u9006\u53d8\u5f02\u7cfb\u6570\u4f5c\u4e3a\u98ce\u9669\u8c03\u6574\u6307\u6807\uff0c\u4ec5\u57fa\u4e8e\u89e3\u9898\u8868\u73b0\u6570\u636e\uff08\u5f97\u5206\u548c\u65f6\u95f4\uff09\u8fdb\u884c\u96be\u5ea6\u4f30\u8ba1", "result": "\u5728\u4e09\u4e2a\u5f02\u6784\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5e73\u5747R2\u8fbe0.9213\uff0cRMSE\u4e3a0.0584\uff0c\u4f18\u4e8e\u56de\u5f52\u3001NLP\u548cIRT\u7b49\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u7b26\u53f7\u9886\u57df\u8868\u73b0\u5c24\u5176\u7a81\u51fa", "conclusion": "\u8be5\u65b9\u6cd5\u9886\u57df\u65e0\u5173\u3001\u81ea\u76d1\u7763\uff0c\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u6709\u89e3\u9898\u4ea4\u4e92\u6570\u636e\u7684\u9886\u57df\uff0c\u652f\u6301\u7ef4\u679c\u8328\u57fa\u6700\u8fd1\u53d1\u5c55\u533a\u7406\u8bba\uff0c\u5e73\u8861\u6311\u6218\u6027\u4e0e\u53ef\u8fbe\u6027"}}
{"id": "2508.19035", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19035", "abs": "https://arxiv.org/abs/2508.19035", "authors": ["Congchi Yin", "Tianyi Wu", "Yankai Shu", "Alex Gu", "Yunhan Wang", "Jun Shao", "Xun Jiang", "Piji Li"], "title": "Investigating Advanced Reasoning of Large Language Models via Black-Box Interaction", "comment": null, "summary": "Existing tasks fall short in evaluating reasoning ability of Large Language\nModels (LLMs) in an interactive, unknown environment. This deficiency leads to\nthe isolated assessment of deductive, inductive, and abductive reasoning,\nneglecting the integrated reasoning process that is indispensable for humans\ndiscovery of real world. We introduce a novel evaluation paradigm,\n\\textit{black-box interaction}, to tackle this challenge. A black-box is\ndefined by a hidden function that maps a specific set of inputs to outputs.\nLLMs are required to unravel the hidden function behind the black-box by\ninteracting with it in given exploration turns, and reasoning over observed\ninput-output pairs. Leveraging this idea, we build the \\textsc{Oracle}\nbenchmark which comprises 6 types of black-box task and 96 black-boxes. 19\nmodern LLMs are benchmarked. o3 ranks first in 5 of the 6 tasks, achieving over\n70\\% accuracy on most easy black-boxes. But it still struggles with some hard\nblack-box tasks, where its average performance drops below 40\\%. Further\nanalysis indicates a universal difficulty among LLMs: They lack the high-level\nplanning capability to develop efficient and adaptive exploration strategies\nfor hypothesis refinement.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9ed1\u76d2\u4ea4\u4e92\u8bc4\u4f30\u8303\u5f0f\u6765\u6d4b\u8bd5LLM\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u7efc\u5408\u63a8\u7406\u80fd\u529b\uff0c\u6784\u5efa\u4e86Oracle\u57fa\u51c6\u5305\u542b6\u7c7b96\u4e2a\u9ed1\u76d2\u4efb\u52a1\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u89c4\u5212\u80fd\u529b\u4e0d\u8db3", "motivation": "\u73b0\u6709\u8bc4\u4f30\u4efb\u52a1\u65e0\u6cd5\u5168\u9762\u6d4b\u8bd5LLM\u5728\u4ea4\u4e92\u5f0f\u672a\u77e5\u73af\u5883\u4e2d\u7684\u7efc\u5408\u63a8\u7406\u80fd\u529b\uff0c\u7f3a\u4e4f\u5bf9\u4eba\u7c7b\u771f\u5b9e\u53d1\u73b0\u8fc7\u7a0b\u4e2d\u6574\u5408\u63a8\u7406\u8fc7\u7a0b\u7684\u8bc4\u4f30", "method": "\u5f15\u5165\u9ed1\u76d2\u4ea4\u4e92\u8bc4\u4f30\u8303\u5f0f\uff0c\u5b9a\u4e49\u9690\u85cf\u51fd\u6570\u6620\u5c04\u7684\u9ed1\u76d2\uff0c\u8981\u6c42LLM\u901a\u8fc7\u6709\u9650\u4ea4\u4e92\u8f6e\u6b21\u89c2\u5bdf\u8f93\u5165\u8f93\u51fa\u5bf9\u6765\u63a8\u7406\u9690\u85cf\u51fd\u6570\uff0c\u5e76\u6784\u5efaOracle\u57fa\u51c6\u5305\u542b6\u7c7b\u4efb\u52a1", "result": "\u6d4b\u8bd519\u4e2a\u73b0\u4ee3LLM\uff0co3\u57286\u4e2a\u4efb\u52a1\u4e2d5\u4e2a\u6392\u540d\u7b2c\u4e00\uff0c\u7b80\u5355\u9ed1\u76d2\u51c6\u786e\u7387\u8d8570%\uff0c\u4f46\u56f0\u96be\u4efb\u52a1\u5e73\u5747\u6027\u80fd\u4f4e\u4e8e40%\uff0c\u663e\u793a\u6a21\u578b\u7f3a\u4e4f\u9ad8\u6548\u81ea\u9002\u5e94\u63a2\u7d22\u7b56\u7565\u7684\u89c4\u5212\u80fd\u529b", "conclusion": "\u9ed1\u76d2\u4ea4\u4e92\u662f\u8bc4\u4f30LLM\u7efc\u5408\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u8303\u5f0f\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u9ad8\u7ea7\u89c4\u5212\u80fd\u529b\u548c\u81ea\u9002\u5e94\u5047\u8bbe\u7cbe\u70bc\u7b56\u7565\u65b9\u9762\u7684\u666e\u904d\u4e0d\u8db3"}}
{"id": "2508.19042", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19042", "abs": "https://arxiv.org/abs/2508.19042", "authors": ["Norihiro Maruyama", "Takahide Yoshida", "Hiroki Sato", "Atsushi Masumori", "Johnsmith", "Takashi Ikegami"], "title": "A Concurrent Modular Agent: Framework for Autonomous LLM Agents", "comment": null, "summary": "We introduce the Concurrent Modular Agent (CMA), a framework that\norchestrates multiple Large-Language-Model (LLM)-based modules that operate\nfully asynchronously yet maintain a coherent and fault-tolerant behavioral\nloop. This framework addresses long-standing difficulties in agent\narchitectures by letting intention emerge from language-mediated interactions\namong autonomous processes. This approach enables flexible, adaptive, and\ncontext-dependent behavior through the combination of concurrently executed\nmodules that offload reasoning to an LLM, inter-module communication, and a\nsingle shared global state.We consider this approach to be a practical\nrealization of Minsky's Society of Mind theory. We demonstrate the viability of\nour system through two practical use-case studies. The emergent properties\nobserved in our system suggest that complex cognitive phenomena like\nself-awareness may indeed arise from the organized interaction of simpler\nprocesses, supporting Minsky-Society of Mind concept and opening new avenues\nfor artificial intelligence research. The source code for our work is available\nat: https://github.com/AlternativeMachine/concurrent-modular-agent.", "AI": {"tldr": "\u5e76\u53d1\u6a21\u5757\u5316\u673a\u5668\u4eba\u6846\u67b6(CMA)\uff0c\u901a\u8fc7\u591a\u4e2a\u5e76\u53d1\u6267\u884c\u7684LLM\u6a21\u5757\u548c\u8bed\u8a00\u4ecb\u5bfc\u7684\u6a21\u5757\u95f4\u4ea4\u4e92\uff0c\u5b9e\u73b0\u4e86\u7075\u6d3b\u3001\u9002\u5e94\u6027\u5f3a\u7684\u673a\u5668\u4eba\u884c\u4e3a\u5faa\u73af\uff0c\u662fMinsky\u667a\u80fd\u793e\u4f1a\u7406\u8bba\u7684\u5b9e\u8df5\u5b9e\u73b0\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u673a\u5668\u4eba\u67b6\u6784\u5728\u5f02\u6b65\u8fd0\u884c\u4e2d\u7ef4\u6301\u884c\u4e3a\u4e00\u81f4\u6027\u548c\u6545\u969c\u5bb9\u9519\u7684\u957f\u671f\u56f0\u96be\uff0c\u8ba9\u610f\u56fe\u4ece\u81ea\u6cbb\u8fc7\u7a0b\u7684\u8bed\u8a00\u4ea4\u4e92\u4e2d\u6db5\u751f\u3002", "method": "\u6784\u5efa\u591a\u4e2a\u5e76\u53d1\u6267\u884c\u7684LLM\u57fa\u7840\u6a21\u5757\uff0c\u901a\u8fc7\u6a21\u5757\u95f4\u901a\u4fe1\u548c\u5355\u4e00\u5168\u5c40\u72b6\u6001\u5171\u4eab\u6765\u5b9e\u73b0\u534f\u8c03\u884c\u4e3a\uff0c\u5c06\u63a8\u7406\u4efb\u52a1\u59d4\u6258\u7ed9LLM\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9645\u7528\u4f8b\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u89c2\u5bdf\u5230\u4e86\u6db5\u751f\u6027\u8d28\uff0c\u652f\u6301\u4e86\u590d\u6742\u8ba4\u77e5\u73b0\u8c61\u53ef\u80fd\u6765\u81ea\u7b80\u5355\u8fc7\u7a0b\u7ec4\u7ec7\u4ea4\u4e92\u7684\u7406\u8bba\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aMinsky\u667a\u80fd\u793e\u4f1a\u7406\u8bba\u63d0\u4f9b\u4e86\u5b9e\u8df5\u5b9e\u73b0\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u5f00\u542f\u4e86\u65b0\u65b9\u5411\uff0c\u6f84\u6e05\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.19069", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19069", "abs": "https://arxiv.org/abs/2508.19069", "authors": ["Zhichao Yang", "Zhaoxin Fan", "Gen Li", "Yuanze Hu", "Xinyu Wang", "Ye Qiu", "Xin Wang", "Yifan Sun", "Wenjun Wu"], "title": "Can Structured Templates Facilitate LLMs in Tackling Harder Tasks? : An Exploration of Scaling Laws by Difficulty", "comment": "9 pages", "summary": "Structured, procedural reasoning is essential for Large Language Models\n(LLMs), especially in mathematics. While post-training methods have improved\nLLM performance, they still fall short in capturing deep procedural logic on\ncomplex tasks. To tackle the issue, in this paper, we first investigate this\nlimitation and uncover a novel finding: a Scaling Law by Difficulty, which\nreveals that model performance follows a U-shaped curve with respect to\ntraining data complexity -- excessive low-difficulty data impedes abstraction,\nwhile high-difficulty data significantly enhances reasoning ability. Motivated\nby this, we propose the Structured Solution Template (SST) framework, which\nuses solution templates and a curriculum of varied difficulty to explicitly\nteach procedural reasoning. Specifically, SST comprises (1) fine-tuning with\nstructured solution-template chains and dynamically weighted loss to prioritize\nprocedural logic, (2) prompt-time injection of solution templates as cognitive\nscaffolds to guide inference, and (3) integrated curriculum fine-tuning that\nexplicitly teaches the model to self-plan - execute - self-correct. Experiments\non GSM8K, AIME24, and new Dynamic En benchmark show that SST significantly\nimproves both accuracy and efficiency, especially on harder problems.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0LLM\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u5b58\u5728\u96be\u5ea6\u7f29\u653e\u5b9a\u5f8b\uff0c\u63d0\u51faSST\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u89e3\u51b3\u65b9\u6848\u6a21\u677f\u548c\u96be\u5ea6\u8bfe\u7a0b\u6765\u663e\u5f0f\u6559\u6388\u7a0b\u5e8f\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u6570\u5b66\u95ee\u9898\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u540e\u8bad\u7ec3\u65b9\u6cd5\u5728\u6355\u6349\u590d\u6742\u4efb\u52a1\u7684\u6df1\u5c42\u7a0b\u5e8f\u903b\u8f91\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u6027\u80fd\u968f\u8bad\u7ec3\u6570\u636e\u96be\u5ea6\u5448\u73b0U\u578b\u66f2\u7ebf\u89c4\u5f8b\uff0c\u8fc7\u5ea6\u7b80\u5355\u6570\u636e\u963b\u788d\u62bd\u8c61\u80fd\u529b\uff0c\u800c\u9ad8\u96be\u5ea6\u6570\u636e\u663e\u8457\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u89e3\u51b3\u65b9\u6848\u6a21\u677f(SST)\u6846\u67b6\uff1a1)\u4f7f\u7528\u7ed3\u6784\u5316\u89e3\u51b3\u65b9\u6848\u6a21\u677f\u94fe\u548c\u52a8\u6001\u52a0\u6743\u635f\u5931\u8fdb\u884c\u5fae\u8c03\uff1b2)\u63a8\u7406\u65f6\u6ce8\u5165\u89e3\u51b3\u65b9\u6848\u6a21\u677f\u4f5c\u4e3a\u8ba4\u77e5\u652f\u67b6\uff1b3)\u96c6\u6210\u8bfe\u7a0b\u5fae\u8c03\uff0c\u663e\u5f0f\u6559\u6388\u6a21\u578b\u81ea\u6211\u89c4\u5212-\u6267\u884c-\u81ea\u6211\u7ea0\u6b63\u3002", "result": "\u5728GSM8K\u3001AIME24\u548c\u65b0\u7684Dynamic En\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSST\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u66f4\u96be\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "SST\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u6a21\u677f\u548c\u96be\u5ea6\u8bfe\u7a0b\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u7a0b\u5e8f\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u63d0\u5347\u590d\u6742\u6570\u5b66\u95ee\u9898\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19096", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19096", "abs": "https://arxiv.org/abs/2508.19096", "authors": ["Yongwoo Song", "Minbyul Jeong", "Mujeen Sung"], "title": "Trustworthy Agents for Electronic Health Records through Confidence Estimation", "comment": null, "summary": "Large language models (LLMs) show promise for extracting information from\nElectronic Health Records (EHR) and supporting clinical decisions. However,\ndeployment in clinical settings faces challenges due to hallucination risks. We\npropose Hallucination Controlled Accuracy at k% (HCAcc@k%), a novel metric\nquantifying the accuracy-reliability trade-off at varying confidence\nthresholds. We introduce TrustEHRAgent, a confidence-aware agent incorporating\nstepwise confidence estimation for clinical question answering. Experiments on\nMIMIC-III and eICU datasets show TrustEHRAgent outperforms baselines under\nstrict reliability constraints, achieving improvements of 44.23%p and 25.34%p\nat HCAcc@70% while baseline methods fail at these thresholds. These results\nhighlight limitations of traditional accuracy metrics in evaluating healthcare\nAI agents. Our work contributes to developing trustworthy clinical agents that\ndeliver accurate information or transparently express uncertainty when\nconfidence is low.", "AI": {"tldr": "\u63d0\u51faHCAcc@k%\u6307\u6807\u548cTrustEHRAgent\u7cfb\u7edf\uff0c\u901a\u8fc7\u6b65\u9aa4\u4fe1\u5fc3\u4f30\u8ba1\u63d0\u5347\u4e34\u5e8a\u95ee\u7b54\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u5728\u4e25\u683c\u53ef\u9760\u6027\u8981\u6c42\u4e0b\u663e\u8457\u8d85\u8fc7\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u5b58\u5728\u5e7b\u89c9\u98ce\u9669\uff0c\u4f20\u7edf\u51c6\u786e\u7387\u6307\u6807\u65e0\u6cd5\u8bc4\u4f30\u533b\u7597AI\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u4ea4\u6613", "method": "\u8bbe\u8ba1Hallucination Controlled Accuracy at k% (HCAcc@k%)\u6307\u6807\uff0c\u5f00\u53d1TrustEHRAgent\u7cfb\u7edf\uff0c\u91c7\u7528\u6b65\u9aa4\u4fe1\u5fc3\u4f30\u8ba1\u673a\u5236", "result": "\u5728MIMIC-III\u548ceICU\u6570\u636e\u96c6\u4e0a\uff0c\u5728HCAcc@70%\u65f6\u5206\u522b\u83b7\u5f9744.23%\u548c25.34%\u7684\u663e\u8457\u63d0\u5347\uff0c\u57fa\u7ebf\u65b9\u6cd5\u5728\u8fd9\u4e9b\u9608\u503c\u4e0b\u5931\u8d25", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u53ef\u4fe1\u8d56\u7684\u4e34\u5e8a\u52a9\u624b\u505a\u51fa\u8d21\u732e\uff0c\u80fd\u591f\u5728\u4fe1\u5fc3\u4f4e\u65f6\u900f\u660e\u5730\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\uff0c\u5f25\u8865\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u7684\u5c40\u9650\u6027"}}
{"id": "2508.19097", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19097", "abs": "https://arxiv.org/abs/2508.19097", "authors": ["Armin Berger", "Sarthak Khanna", "David Berghaus", "Rafet Sifa"], "title": "Reasoning LLMs in the Medical Domain: A Literature Survey", "comment": null, "summary": "The emergence of advanced reasoning capabilities in Large Language Models\n(LLMs) marks a transformative development in healthcare applications. Beyond\nmerely expanding functional capabilities, these reasoning mechanisms enhance\ndecision transparency and explainability-critical requirements in medical\ncontexts. This survey examines the transformation of medical LLMs from basic\ninformation retrieval tools to sophisticated clinical reasoning systems capable\nof supporting complex healthcare decisions. We provide a thorough analysis of\nthe enabling technological foundations, with a particular focus on specialized\nprompting techniques like Chain-of-Thought and recent breakthroughs in\nReinforcement Learning exemplified by DeepSeek-R1. Our investigation evaluates\npurpose-built medical frameworks while also examining emerging paradigms such\nas multi-agent collaborative systems and innovative prompting architectures.\nThe survey critically assesses current evaluation methodologies for medical\nvalidation and addresses persistent challenges in field interpretation\nlimitations, bias mitigation strategies, patient safety frameworks, and\nintegration of multimodal clinical data. Through this survey, we seek to\nestablish a roadmap for developing reliable LLMs that can serve as effective\npartners in clinical practice and medical research.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u53d1\u5c55\uff0c\u4ece\u57fa\u7840\u4fe1\u606f\u68c0\u7d22\u5de5\u5177\u8f6c\u53d8\u4e3a\u652f\u6301\u590d\u6742\u533b\u7597\u51b3\u7b56\u7684\u4e34\u5e8a\u63a8\u7406\u7cfb\u7edf\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u6280\u672f\u57fa\u7840\u3001\u8bc4\u4f30\u65b9\u6cd5\u548c\u5f53\u524d\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\uff0c\u533b\u7597\u5e94\u7528\u9700\u8981\u66f4\u900f\u660e\u548c\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u8fd9\u5bf9\u533b\u7597\u73af\u5883\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u5206\u6790\u533b\u7597LLMs\u7684\u53d1\u5c55\u73b0\u72b6\u548c\u6280\u672f\u7a81\u7834\u3002", "method": "\u901a\u8fc7\u5168\u9762\u8c03\u67e5\u5206\u6790\u533b\u7597LLMs\u7684\u6280\u672f\u57fa\u7840\uff0c\u5305\u62ec\u4e13\u95e8\u7684\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff08\u5982\u601d\u7ef4\u94fe\uff09\u548c\u5f3a\u5316\u5b66\u4e60\u7a81\u7834\uff08\u5982DeepSeek-R1\uff09\uff0c\u8bc4\u4f30\u4e13\u7528\u533b\u7597\u6846\u67b6\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7cfb\u7edf\u7b49\u65b0\u5174\u8303\u5f0f\u3002", "result": "\u8bc6\u522b\u4e86\u533b\u7597LLMs\u4ece\u4fe1\u606f\u68c0\u7d22\u5230\u4e34\u5e8a\u63a8\u7406\u7684\u8f6c\u578b\u8def\u5f84\uff0c\u5206\u6790\u4e86\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u9886\u57df\u89e3\u91ca\u9650\u5236\u3001\u504f\u89c1\u7f13\u89e3\u3001\u60a3\u8005\u5b89\u5168\u6846\u67b6\u548c\u591a\u6a21\u6001\u6570\u636e\u96c6\u6210\u7b49\u6301\u7eed\u6311\u6218\u3002", "conclusion": "\u672c\u6587\u4e3a\u5f00\u53d1\u53ef\u9760\u7684\u533b\u7597LLMs\u5efa\u7acb\u4e86\u8def\u7ebf\u56fe\uff0c\u4f7f\u5176\u80fd\u591f\u6210\u4e3a\u4e34\u5e8a\u5b9e\u8df5\u548c\u533b\u5b66\u7814\u7a76\u7684\u6709\u6548\u5408\u4f5c\u4f19\u4f34\uff0c\u63a8\u52a8\u533b\u7597AI\u5411\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2508.19113", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19113", "abs": "https://arxiv.org/abs/2508.19113", "authors": ["Dayoon Ko", "Jihyuk Kim", "Haeju Park", "Sohyeon Kim", "Dahyun Lee", "Yongrae Jo", "Gunhee Kim", "Moontae Lee", "Kyungjae Lee"], "title": "Hybrid Deep Searcher: Integrating Parallel and Sequential Search Reasoning", "comment": null, "summary": "Large reasoning models (LRMs) have demonstrated strong performance in\ncomplex, multi-step reasoning tasks. Existing methods enhance LRMs by\nsequentially integrating external knowledge retrieval; models iteratively\ngenerate queries, retrieve external information, and progressively reason over\nthis information. However, purely sequential querying increases inference\nlatency and context length, diminishing coherence and potentially reducing\naccuracy. To address these limitations, we introduce HDS-QA (Hybrid Deep Search\nQA), a synthetic dataset automatically generated from Natural Questions,\nexplicitly designed to train LRMs to distinguish parallelizable from sequential\nqueries. HDS-QA comprises hybrid-hop questions that combine parallelizable\nindependent subqueries (executable simultaneously) and sequentially dependent\nsubqueries (requiring step-by-step resolution), along with synthetic\nreasoning-querying-retrieval paths involving parallel queries. We fine-tune an\nLRM using HDS-QA, naming the model HybridDeepSearcher, which outperforms\nstate-of-the-art baselines across multiple benchmarks, notably achieving +15.9\nand +11.5 F1 on FanOutQA and a subset of BrowseComp, respectively, both\nrequiring comprehensive and exhaustive search. Experimental results highlight\ntwo key advantages: HybridDeepSearcher reaches comparable accuracy with fewer\nsearch turns, significantly reducing inference latency, and it effectively\nscales as more turns are permitted. These results demonstrate the efficiency,\nscalability, and effectiveness of explicitly training LRMs to leverage hybrid\nparallel and sequential querying.", "AI": {"tldr": "HDS-QA\u662f\u4e00\u4e2a\u4ece\u81ea\u7136\u95ee\u9898\u81ea\u52a8\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u5927\u578b\u63a8\u7406\u6a21\u578b\u533a\u5206\u5e76\u884c\u67e5\u8be2\u548c\u987a\u5e8f\u67e5\u8be2\uff0c\u4ece\u800c\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u987a\u5e8f\u67e5\u8be2\u65b9\u6cd5\u589e\u52a0\u4e86\u63a8\u7406\u5ef6\u8fdf\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u964d\u4f4e\u4e86\u8fde\u8d2f\u6027\u548c\u51c6\u786e\u6027\uff0c\u9700\u8981\u4e00\u79cd\u6df7\u5408\u5e76\u884c\u548c\u987a\u5e8f\u67e5\u8be2\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u521b\u5efaHDS-QA\u5408\u6210\u6570\u636e\u96c6\uff0c\u5305\u542b\u5e76\u884c\u53ef\u6267\u884c\u548c\u987a\u5e8f\u4f9d\u8d56\u7684\u5b50\u67e5\u8be2\uff0c\u5e76\u57fa\u4e8e\u6b64\u5fae\u8c03LRM\u6a21\u578bHybridDeepSearcher\u3002", "result": "HybridDeepSearcher\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u5728FanOutQA\u548cBrowseComp\u4e0a\u5206\u522b\u83b7\u5f97+15.9\u548c+11.5 F1\u5206\u6570\uff0c\u663e\u8457\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "\u663e\u5f0f\u8bad\u7ec3LRM\u5229\u7528\u6df7\u5408\u5e76\u884c\u548c\u987a\u5e8f\u67e5\u8be2\u7684\u65b9\u6cd5\u5728\u6548\u7387\u3001\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2508.19149", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19149", "abs": "https://arxiv.org/abs/2508.19149", "authors": ["Claudio Battiloro", "Pietro Greiner", "Bret Nestor", "Oumaima Amezgar", "Francesca Dominici"], "title": "Algorithmic Collective Action with Multiple Collectives", "comment": "12 pages", "summary": "As learning systems increasingly influence everyday decisions, user-side\nsteering via Algorithmic Collective Action (ACA)-coordinated changes to shared\ndata-offers a complement to regulator-side policy and firm-side model design.\nAlthough real-world actions have been traditionally decentralized and\nfragmented into multiple collectives despite sharing overarching\nobjectives-with each collective differing in size, strategy, and actionable\ngoals, most of the ACA literature focused on single collective settings. In\nthis work, we present the first theoretical framework for ACA with multiple\ncollectives acting on the same system. In particular, we focus on collective\naction in classification, studying how multiple collectives can plant signals,\ni.e., bias a classifier to learn an association between an altered version of\nthe features and a chosen, possibly overlapping, set of target classes. We\nprovide quantitative results about the role and the interplay of collectives'\nsizes and their alignment of goals. Our framework, by also complementing\nprevious empirical results, opens a path for a holistic treatment of ACA with\nmultiple collectives.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u96c6\u4f53\u7b97\u6cd5\u96c6\u4f53\u884c\u52a8\uff08ACA\uff09\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7814\u7a76\u591a\u4e2a\u96c6\u4f53\u5982\u4f55\u5728\u5206\u7c7b\u7cfb\u7edf\u4e2d\u534f\u8c03\u690d\u5165\u4fe1\u53f7\u6765\u5f71\u54cd\u5206\u7c7b\u5668\u51b3\u7b56\u3002", "motivation": "\u968f\u7740\u5b66\u4e60\u7cfb\u7edf\u5bf9\u65e5\u5e38\u51b3\u7b56\u5f71\u54cd\u65e5\u76ca\u589e\u5f3a\uff0c\u7528\u6237\u7aef\u7684\u7b97\u6cd5\u96c6\u4f53\u884c\u52a8\uff08ACA\uff09\u4f5c\u4e3a\u76d1\u7ba1\u7aef\u653f\u7b56\u548c\u4f01\u4e1a\u7aef\u6a21\u578b\u8bbe\u8ba1\u7684\u8865\u5145\u624b\u6bb5\u53d8\u5f97\u91cd\u8981\u3002\u4f20\u7edfACA\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u5355\u96c6\u4f53\u573a\u666f\uff0c\u4f46\u73b0\u5b9e\u4e2d\u7684\u96c6\u4f53\u884c\u52a8\u5f80\u5f80\u662f\u5206\u6563\u7684\u3001\u7531\u591a\u4e2a\u76ee\u6807\u4e00\u81f4\u4f46\u7b56\u7565\u4e0d\u540c\u7684\u96c6\u4f53\u7ec4\u6210\u3002", "method": "\u5efa\u7acb\u591a\u96c6\u4f53ACA\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7814\u7a76\u591a\u4e2a\u96c6\u4f53\u5982\u4f55\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u901a\u8fc7\u534f\u8c03\u6539\u53d8\u5171\u4eab\u6570\u636e\u6765\u690d\u5165\u4fe1\u53f7\uff08\u5373\u8ba9\u5206\u7c7b\u5668\u5b66\u4e60\u7279\u5f81\u4fee\u6539\u7248\u672c\u4e0e\u76ee\u6807\u7c7b\u522b\u4e4b\u95f4\u7684\u5173\u8054\uff09\u3002\u5206\u6790\u96c6\u4f53\u89c4\u6a21\u548c\u76ee\u6807\u5bf9\u9f50\u5ea6\u7684\u4f5c\u7528\u4e0e\u76f8\u4e92\u5173\u7cfb\u3002", "result": "\u63d0\u4f9b\u4e86\u5173\u4e8e\u96c6\u4f53\u89c4\u6a21\u548c\u76ee\u6807\u5bf9\u9f50\u5ea6\u5728\u7b97\u6cd5\u96c6\u4f53\u884c\u52a8\u4e2d\u4f5c\u7528\u7684\u5b9a\u91cf\u5206\u6790\u7ed3\u679c\uff0c\u8865\u5145\u4e86\u4e4b\u524d\u7684\u5b9e\u8bc1\u7814\u7a76\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u96c6\u4f53\u7b97\u6cd5\u96c6\u4f53\u884c\u52a8\u7684\u6574\u4f53\u5904\u7406\u5f00\u8f9f\u4e86\u8def\u5f84\uff0c\u4e3a\u7406\u89e3\u73b0\u5b9e\u4e16\u754c\u4e2d\u5206\u6563\u4f46\u76ee\u6807\u4e00\u81f4\u7684\u96c6\u4f53\u884c\u52a8\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.19152", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.SC"], "pdf": "https://arxiv.org/pdf/2508.19152", "abs": "https://arxiv.org/abs/2508.19152", "authors": ["Chiu-Chou Lin"], "title": "Playstyle and Artificial Intelligence: An Initial Blueprint Through the Lens of Video Games", "comment": "PhD Dissertation, National Yang Ming Chiao Tung University, 2025.\n  This is the public version without Chinese abstract or postscript", "summary": "Contemporary artificial intelligence (AI) development largely centers on\nrational decision-making, valued for its measurability and suitability for\nobjective evaluation. Yet in real-world contexts, an intelligent agent's\ndecisions are shaped not only by logic but also by deeper influences such as\nbeliefs, values, and preferences. The diversity of human decision-making styles\nemerges from these differences, highlighting that \"style\" is an essential but\noften overlooked dimension of intelligence.\n  This dissertation introduces playstyle as an alternative lens for observing\nand analyzing the decision-making behavior of intelligent agents, and examines\nits foundational meaning and historical context from a philosophical\nperspective. By analyzing how beliefs and values drive intentions and actions,\nwe construct a two-tier framework for style formation: the external interaction\nloop with the environment and the internal cognitive loop of deliberation. On\nthis basis, we formalize style-related characteristics and propose measurable\nindicators such as style capacity, style popularity, and evolutionary dynamics.\n  The study focuses on three core research directions: (1) Defining and\nmeasuring playstyle, proposing a general playstyle metric based on discretized\nstate spaces, and extending it to quantify strategic diversity and competitive\nbalance; (2) Expressing and generating playstyle, exploring how reinforcement\nlearning and imitation learning can be used to train agents exhibiting specific\nstylistic tendencies, and introducing a novel approach for human-like style\nlearning and modeling; and (3) Practical applications, analyzing the potential\nof these techniques in domains such as game design and interactive\nentertainment.\n  Finally, the dissertation outlines future extensions, including the role of\nstyle as a core element in building artificial general intelligence (AGI).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u6e38\u620f\u98ce\u683c(playstyle)\u4f5c\u4e3a\u5206\u6790\u667a\u80fd\u4f53\u51b3\u7b56\u884c\u4e3a\u7684\u65b0\u89c6\u89d2\uff0c\u6784\u5efa\u4e86\u98ce\u683c\u5f62\u6210\u7684\u53cc\u5c42\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u6d4b\u91cf\u7684\u98ce\u683c\u6307\u6807\uff0c\u63a2\u8ba8\u4e86\u5728\u5f3a\u5316\u5b66\u4e60\u548c\u6a21\u4eff\u5b66\u4e60\u4e2d\u751f\u6210\u7279\u5b9a\u98ce\u683c\u7684\u65b9\u6cd5\u53ca\u5176\u5728\u6e38\u620f\u8bbe\u8ba1\u7b49\u9886\u57df\u7684\u5e94\u7528\u3002", "motivation": "\u5f53\u524dAI\u53d1\u5c55\u4e3b\u8981\u5173\u6ce8\u7406\u6027\u51b3\u7b56\uff0c\u4f46\u771f\u5b9e\u4e16\u754c\u4e2d\u667a\u80fd\u4f53\u7684\u51b3\u7b56\u8fd8\u53d7\u5230\u4fe1\u5ff5\u3001\u4ef7\u503c\u89c2\u548c\u504f\u597d\u7b49\u6df1\u5c42\u56e0\u7d20\u7684\u5f71\u54cd\u3002\u4eba\u7c7b\u51b3\u7b56\u98ce\u683c\u7684\u591a\u6837\u6027\u8868\u660e\"\u98ce\u683c\"\u662f\u667a\u80fd\u7684\u91cd\u8981\u4f46\u5e38\u88ab\u5ffd\u89c6\u7684\u7ef4\u5ea6\u3002", "method": "\u6784\u5efa\u98ce\u683c\u5f62\u6210\u7684\u53cc\u5c42\u6846\u67b6\uff08\u5916\u90e8\u73af\u5883\u4ea4\u4e92\u5faa\u73af\u548c\u5185\u90e8\u8ba4\u77e5\u5ba1\u8bae\u5faa\u73af\uff09\uff0c\u5f62\u5f0f\u5316\u98ce\u683c\u76f8\u5173\u7279\u5f81\uff0c\u63d0\u51fa\u98ce\u683c\u5bb9\u91cf\u3001\u98ce\u683c\u6d41\u884c\u5ea6\u548c\u8fdb\u5316\u52a8\u529b\u5b66\u7b49\u53ef\u6d4b\u91cf\u6307\u6807\u3002\u7814\u7a76\u5305\u62ec\uff1a\u5b9a\u4e49\u548c\u6d4b\u91cf\u6e38\u620f\u98ce\u683c\u3001\u8868\u8fbe\u548c\u751f\u6210\u6e38\u620f\u98ce\u683c\u3001\u5b9e\u9645\u5e94\u7528\u5206\u6790\u3002", "result": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\u7684\u901a\u7528\u6e38\u620f\u98ce\u683c\u5ea6\u91cf\u65b9\u6cd5\uff0c\u53ef\u91cf\u5316\u6218\u7565\u591a\u6837\u6027\u548c\u7ade\u4e89\u5e73\u8861\uff1b\u63a2\u7d22\u4e86\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u6a21\u4eff\u5b66\u4e60\u8bad\u7ec3\u5177\u6709\u7279\u5b9a\u98ce\u683c\u503e\u5411\u7684\u667a\u80fd\u4f53\uff1b\u63d0\u51fa\u4e86\u4eba\u7c7b\u98ce\u683c\u5b66\u4e60\u548c\u5efa\u6a21\u7684\u65b0\u65b9\u6cd5\u3002", "conclusion": "\u6e38\u620f\u98ce\u683c\u4e3a\u5206\u6790\u667a\u80fd\u4f53\u51b3\u7b56\u884c\u4e3a\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c6\u89d2\uff0c\u76f8\u5173\u6280\u672f\u5728\u6e38\u620f\u8bbe\u8ba1\u548c\u4ea4\u4e92\u5a31\u4e50\u7b49\u9886\u57df\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002\u98ce\u683c\u53ef\u80fd\u6210\u4e3a\u6784\u5efa\u4eba\u5de5\u901a\u7528\u667a\u80fd(AGI)\u7684\u6838\u5fc3\u8981\u7d20\u3002"}}
{"id": "2508.19163", "categories": ["cs.AI", "cs.HC", "cs.MA", "68T50, 68T42, 92C50, 68Q60", "I.2.0; J.3"], "pdf": "https://arxiv.org/pdf/2508.19163", "abs": "https://arxiv.org/abs/2508.19163", "authors": ["Ernest Lim", "Yajie Vera He", "Jared Joselowitz", "Kate Preston", "Mohita Chowdhury", "Louis Williams", "Aisling Higham", "Katrina Mason", "Mariane Melo", "Tom Lawton", "Yan Jia", "Ibrahim Habli"], "title": "MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation", "comment": "36 pages, 16 figures", "summary": "Despite the growing use of large language models (LLMs) in clinical dialogue\nsystems, existing evaluations focus on task completion or fluency, offering\nlittle insight into the behavioral and risk management requirements essential\nfor safety-critical systems. This paper presents MATRIX (Multi-Agent simulaTion\nfRamework for safe Interactions and conteXtual clinical conversational\nevaluation), a structured, extensible framework for safety-oriented evaluation\nof clinical dialogue agents.\n  MATRIX integrates three components: (1) a safety-aligned taxonomy of clinical\nscenarios, expected system behaviors and failure modes derived through\nstructured safety engineering methods; (2) BehvJudge, an LLM-based evaluator\nfor detecting safety-relevant dialogue failures, validated against expert\nclinician annotations; and (3) PatBot, a simulated patient agent capable of\nproducing diverse, scenario-conditioned responses, evaluated for realism and\nbehavioral fidelity with human factors expertise, and a patient-preference\nstudy.\n  Across three experiments, we show that MATRIX enables systematic, scalable\nsafety evaluation. BehvJudge with Gemini 2.5-Pro achieves expert-level hazard\ndetection (F1 0.96, sensitivity 0.999), outperforming clinicians in a blinded\nassessment of 240 dialogues. We also conducted one of the first realism\nanalyses of LLM-based patient simulation, showing that PatBot reliably\nsimulates realistic patient behavior in quantitative and qualitative\nevaluations. Using MATRIX, we demonstrate its effectiveness in benchmarking\nfive LLM agents across 2,100 simulated dialogues spanning 14 hazard scenarios\nand 10 clinical domains.\n  MATRIX is the first framework to unify structured safety engineering with\nscalable, validated conversational AI evaluation, enabling regulator-aligned\nsafety auditing. We release all evaluation tools, prompts, structured\nscenarios, and datasets.", "AI": {"tldr": "MATRIX\u662f\u4e00\u4e2a\u7528\u4e8e\u4e34\u5e8a\u5bf9\u8bdd\u7cfb\u7edf\u5b89\u5168\u8bc4\u4f30\u7684\u591a\u667a\u80fd\u4f53\u4eff\u771f\u6846\u67b6\uff0c\u6574\u5408\u4e86\u5b89\u5168\u5bf9\u9f50\u7684\u573a\u666f\u5206\u7c7b\u3001\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u5668BehvJudge\u548c\u6a21\u62df\u60a3\u8005\u4ee3\u7406PatBot\uff0c\u5b9e\u73b0\u4e86\u7cfb\u7edf\u5316\u3001\u53ef\u6269\u5c55\u7684\u5b89\u5168\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e34\u5e8a\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u5b8c\u6210\u5ea6\u548c\u6d41\u7545\u6027\uff0c\u7f3a\u4e4f\u5bf9\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u6240\u9700\u7684\u884c\u4e3a\u548c\u98ce\u9669\u7ba1\u7406\u8981\u6c42\u7684\u6df1\u5165\u5206\u6790\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u5b89\u5168\u5bfc\u5411\u8bc4\u4f30\u6846\u67b6\u3002", "method": "MATRIX\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1)\u57fa\u4e8e\u5b89\u5168\u5de5\u7a0b\u65b9\u6cd5\u7684\u5b89\u5168\u5bf9\u9f50\u573a\u666f\u5206\u7c7b\u6cd5\uff1b(2)\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u5668BehvJudge\uff0c\u7528\u4e8e\u68c0\u6d4b\u5b89\u5168\u76f8\u5173\u5bf9\u8bdd\u6545\u969c\uff1b(3)\u6a21\u62df\u60a3\u8005\u4ee3\u7406PatBot\uff0c\u751f\u6210\u591a\u6837\u5316\u573a\u666f\u54cd\u5e94\u3002", "result": "BehvJudge\u8fbe\u5230\u4e13\u5bb6\u7ea7\u5371\u9669\u68c0\u6d4b\u6c34\u5e73(F1 0.96, \u7075\u654f\u5ea60.999)\uff0c\u5728240\u4e2a\u5bf9\u8bdd\u7684\u76f2\u8bc4\u4e2d\u4f18\u4e8e\u4e34\u5e8a\u533b\u751f\u3002PatBot\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u4e2d\u53ef\u9760\u5730\u6a21\u62df\u771f\u5b9e\u60a3\u8005\u884c\u4e3a\u3002\u6846\u67b6\u6210\u529f\u5bf95\u4e2aLLM\u4ee3\u7406\u57282,100\u4e2a\u6a21\u62df\u5bf9\u8bdd\u4e2d\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "MATRIX\u662f\u9996\u4e2a\u5c06\u7ed3\u6784\u5316\u5b89\u5168\u5de5\u7a0b\u4e0e\u53ef\u6269\u5c55\u3001\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5bf9\u8bddAI\u8bc4\u4f30\u76f8\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u652f\u6301\u76d1\u7ba1\u673a\u6784\u5bf9\u9f50\u7684\u5b89\u5168\u5ba1\u8ba1\uff0c\u4e3a\u4e34\u5e8a\u5bf9\u8bdd\u7cfb\u7edf\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19200", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.19200", "abs": "https://arxiv.org/abs/2508.19200", "authors": ["Xinran Zhao", "Boyuan Zheng", "Chenglei Si", "Haofei Yu", "Ken Liu", "Runlong Zhou", "Ruochen Li", "Tong Chen", "Xiang Li", "Yiming Zhang", "Tongshuang Wu"], "title": "The Ramon Llull's Thinking Machine for Automated Ideation", "comment": "21 pages, 3 figures", "summary": "This paper revisits Ramon Llull's Ars combinatoria - a medieval framework for\ngenerating knowledge through symbolic recombination - as a conceptual\nfoundation for building a modern Llull's thinking machine for research\nideation. Our approach defines three compositional axes: Theme (e.g.,\nefficiency, adaptivity), Domain (e.g., question answering, machine\ntranslation), and Method (e.g., adversarial training, linear attention). These\nelements represent high-level abstractions common in scientific work -\nmotivations, problem settings, and technical approaches - and serve as building\nblocks for LLM-driven exploration. We mine elements from human experts or\nconference papers and show that prompting LLMs with curated combinations\nproduces research ideas that are diverse, relevant, and grounded in current\nliterature. This modern thinking machine offers a lightweight, interpretable\ntool for augmenting scientific creativity and suggests a path toward\ncollaborative ideation between humans and AI.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u4e2d\u4e16\u7eaaRamon Llull\u7684\u7ec4\u5408\u827a\u672f\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e3b\u9898\u3001\u9886\u57df\u548c\u65b9\u6cd5\u4e09\u4e2a\u7ec4\u5408\u8f74\u7684\u73b0\u4ee3\u7814\u7a76\u6784\u601d\u673a\u5668\uff0c\u901a\u8fc7LLM\u751f\u6210\u591a\u6837\u5316\u4e14\u76f8\u5173\u7684\u7814\u7a76\u60f3\u6cd5\u3002", "motivation": "\u91cd\u65b0\u6316\u6398\u4e2d\u4e16\u7eaa\u7ec4\u5408\u827a\u672f\u7684\u4ef7\u503c\uff0c\u4e3a\u73b0\u4ee3\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u7cfb\u7edf\u5316\u7684\u6784\u601d\u6846\u67b6\uff0c\u589e\u5f3a\u79d1\u5b66\u521b\u9020\u529b\u5e76\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c\u7684\u6784\u601d\u8fc7\u7a0b\u3002", "method": "\u5b9a\u4e49\u4e09\u4e2a\u7ec4\u5408\u8f74\uff08\u4e3b\u9898\u3001\u9886\u57df\u3001\u65b9\u6cd5\uff09\u4f5c\u4e3a\u6784\u5efa\u6a21\u5757\uff0c\u4ece\u4e13\u5bb6\u6216\u4f1a\u8bae\u8bba\u6587\u4e2d\u6316\u6398\u5143\u7d20\uff0c\u901a\u8fc7\u7cbe\u5fc3\u7b56\u5212\u7684\u7ec4\u5408\u63d0\u793aLLM\u751f\u6210\u7814\u7a76\u60f3\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ea7\u751f\u591a\u6837\u5316\u3001\u76f8\u5173\u6027\u9ad8\u4e14\u57fa\u4e8e\u5f53\u524d\u6587\u732e\u7684\u7814\u7a76\u60f3\u6cd5\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u79d1\u5b66\u521b\u9020\u529b\u589e\u5f3a\u5de5\u5177\u3002", "conclusion": "\u73b0\u4ee3Llull\u601d\u8003\u673a\u5668\u4e3a\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6784\u601d\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u4eba\u673a\u534f\u4f5c\u5728\u79d1\u5b66\u521b\u65b0\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2508.19218", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19218", "abs": "https://arxiv.org/abs/2508.19218", "authors": ["Yufei Wu", "Manuel R. Torres", "Parisa Zehtabi", "Alberto Pozanco Lancho", "Michael Cashmore", "Daniel Borrajo", "Manuela Veloso"], "title": "The Subset Sum Matching Problem", "comment": "Paper accepted at ECAI 2025. This is an extended version that\n  includes Supplementary Material", "summary": "This paper presents a new combinatorial optimisation task, the Subset Sum\nMatching Problem (SSMP), which is an abstraction of common financial\napplications such as trades reconciliation. We present three algorithms, two\nsuboptimal and one optimal, to solve this problem. We also generate a benchmark\nto cover different instances of SSMP varying in complexity, and carry out an\nexperimental evaluation to assess the performance of the approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u65b0\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898SSMP\uff0c\u4f5c\u4e3a\u91d1\u878d\u4ea4\u6613\u5bf9\u8d26\u7b49\u5e94\u7528\u7684\u62bd\u8c61\uff0c\u5f00\u53d1\u4e86\u4e24\u4e2a\u6b21\u4f18\u7b97\u6cd5\u548c\u4e00\u4e2a\u6700\u4f18\u7b97\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30", "motivation": "\u89e3\u51b3\u91d1\u878d\u5e94\u7528\u4e2d\u5e38\u89c1\u7684\u4ea4\u6613\u5bf9\u8d26\u7b49\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u9700\u8981\u627e\u5230\u6709\u6548\u7684\u7b97\u6cd5\u6765\u5904\u7406\u8fd9\u7c7b\u62bd\u8c61\u95ee\u9898", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u7b97\u6cd5\uff08\u4e24\u4e2a\u6b21\u4f18\u7b97\u6cd5\u548c\u4e00\u4e2a\u6700\u4f18\u7b97\u6cd5\uff09\u6765\u89e3\u51b3SSMP\u95ee\u9898\uff0c\u5e76\u5efa\u7acb\u4e86\u6db5\u76d6\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30", "result": "\u5f00\u53d1\u4e86\u9488\u5bf9SSMP\u95ee\u9898\u7684\u6709\u6548\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6027\u80fd", "conclusion": "SSMP\u662f\u4e00\u4e2a\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u4e3a\u91d1\u878d\u4ea4\u6613\u5bf9\u8d26\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177"}}
{"id": "2508.19229", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.19229", "abs": "https://arxiv.org/abs/2508.19229", "authors": ["Wei Xiong", "Wenting Zhao", "Weizhe Yuan", "Olga Golovneva", "Tong Zhang", "Jason Weston", "Sainbayar Sukhbaatar"], "title": "StepWiser: Stepwise Generative Judges for Wiser Reasoning", "comment": null, "summary": "As models increasingly leverage multi-step reasoning strategies to solve\ncomplex problems, supervising the logical validity of these intermediate steps\nhas become a critical research challenge. Process reward models address this by\nproviding step-by-step feedback, but current approaches have two major\ndrawbacks: they typically function as classifiers without providing\nexplanations, and their reliance on supervised fine-tuning with static datasets\nlimits generalization. Inspired by recent advances, we reframe stepwise reward\nmodeling from a classification task to a reasoning task itself. We thus propose\na generative judge that reasons about the policy model's reasoning steps (i.e.,\nmeta-reasons), outputting thinking tokens before delivering a final verdict.\nOur model, StepWiser, is trained by reinforcement learning using relative\noutcomes of rollouts. We show it provides (i) better judgment accuracy on\nintermediate steps than existing methods; (ii) can be used to improve the\npolicy model at training time; and (iii) improves inference-time search.", "AI": {"tldr": "\u5c06\u9010\u6b65\u5956\u52b1\u5efa\u6a21\u4ece\u5206\u7c7b\u4efb\u52a1\u91cd\u6784\u4e3a\u63a8\u7406\u4efb\u52a1\uff0c\u63d0\u51fa\u751f\u6210\u5f0f\u5224\u65ad\u6a21\u578bStepWiser\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5728\u4e2d\u95f4\u6b65\u9aa4\u5224\u65ad\u51c6\u786e\u6027\u3001\u7b56\u7565\u6a21\u578b\u8bad\u7ec3\u6539\u8fdb\u548c\u63a8\u7406\u65f6\u641c\u7d22\u65b9\u9762\u8868\u73b0\u66f4\u4f18", "motivation": "\u968f\u7740\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528\u591a\u6b65\u63a8\u7406\u7b56\u7565\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0c\u76d1\u7763\u8fd9\u4e9b\u4e2d\u95f4\u6b65\u9aa4\u7684\u903b\u8f91\u6709\u6548\u6027\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u7f3a\u9677\uff1a\u7f3a\u4e4f\u89e3\u91ca\u80fd\u529b\uff0c\u4ee5\u53ca\u4f9d\u8d56\u9759\u6001\u6570\u636e\u96c6\u7684\u76d1\u7763\u5fae\u8c03\u9650\u5236\u4e86\u6cdb\u5316\u80fd\u529b", "method": "\u63d0\u51faStepWiser\u751f\u6210\u5f0f\u5224\u65ad\u6a21\u578b\uff0c\u5c06\u9010\u6b65\u5956\u52b1\u5efa\u6a21\u91cd\u6784\u4e3a\u63a8\u7406\u4efb\u52a1\u672c\u8eab\u3002\u6a21\u578b\u5bf9\u7b56\u7565\u6a21\u578b\u7684\u63a8\u7406\u6b65\u9aa4\u8fdb\u884c\u5143\u63a8\u7406\uff0c\u5148\u8f93\u51fa\u601d\u8003\u6807\u8bb0\u518d\u7ed9\u51fa\u6700\u7ec8\u5224\u65ad\u3002\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u901a\u8fc7rollout\u7684\u76f8\u5bf9\u7ed3\u679c\u8fdb\u884c\u8bad\u7ec3", "result": "StepWiser\u5728\u4e2d\u95f4\u6b65\u9aa4\u5224\u65ad\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u6539\u8fdb\u7b56\u7565\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u5e76\u80fd\u63d0\u5347\u63a8\u7406\u65f6\u7684\u641c\u7d22\u6548\u679c", "conclusion": "\u5c06\u9010\u6b65\u5956\u52b1\u5efa\u6a21\u4ece\u5206\u7c7b\u8f6c\u5411\u63a8\u7406\u7684\u65b9\u6cd5\u6709\u6548\uff0c\u751f\u6210\u5f0f\u5224\u65ad\u6a21\u578b\u901a\u8fc7\u5143\u63a8\u7406\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5728\u591a\u4e2a\u7ef4\u5ea6\u4e0a\u63d0\u5347\u4e86\u8fc7\u7a0b\u76d1\u7763\u7684\u6548\u679c"}}
{"id": "2508.19239", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19239", "abs": "https://arxiv.org/abs/2508.19239", "authors": ["Gaurab Chhetri", "Shriyank Somvanshi", "Md Monzurul Islam", "Shamyo Brotee", "Mahmuda Sultana Mimi", "Dipti Koirala", "Biplov Pandey", "Subasish Das"], "title": "Model Context Protocols in Adaptive Transport Systems: A Survey", "comment": null, "summary": "The rapid expansion of interconnected devices, autonomous systems, and AI\napplications has created severe fragmentation in adaptive transport systems,\nwhere diverse protocols and context sources remain isolated. This survey\nprovides the first systematic investigation of the Model Context Protocol (MCP)\nas a unifying paradigm, highlighting its ability to bridge protocol-level\nadaptation with context-aware decision making. Analyzing established\nliterature, we show that existing efforts have implicitly converged toward\nMCP-like architectures, signaling a natural evolution from fragmented solutions\nto standardized integration frameworks. We propose a five-category taxonomy\ncovering adaptive mechanisms, context-aware frameworks, unification models,\nintegration strategies, and MCP-enabled architectures. Our findings reveal\nthree key insights: traditional transport protocols have reached the limits of\nisolated adaptation, MCP's client-server and JSON-RPC structure enables\nsemantic interoperability, and AI-driven transport demands integration\nparadigms uniquely suited to MCP. Finally, we present a research roadmap\npositioning MCP as a foundation for next-generation adaptive, context-aware,\nand intelligent transport infrastructures.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8c03\u67e5\u4e86\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u4f5c\u4e3a\u7edf\u4e00\u8303\u5f0f\uff0c\u80fd\u591f\u6865\u63a5\u534f\u8bae\u7ea7\u9002\u5e94\u4e0e\u4e0a\u4e0b\u6587\u611f\u77e5\u51b3\u7b56\uff0c\u63d0\u51fa\u4e86\u4e94\u7c7b\u5206\u7c7b\u6cd5\u5e76\u63ed\u793a\u4e86\u4e09\u4e2a\u5173\u952e\u53d1\u73b0\u3002", "motivation": "\u4e92\u8054\u8bbe\u5907\u3001\u81ea\u4e3b\u7cfb\u7edf\u548cAI\u5e94\u7528\u7684\u5feb\u901f\u6269\u5f20\u5bfc\u81f4\u81ea\u9002\u5e94\u4f20\u8f93\u7cfb\u7edf\u4e25\u91cd\u788e\u7247\u5316\uff0c\u4e0d\u540c\u534f\u8bae\u548c\u4e0a\u4e0b\u6587\u6765\u6e90\u76f8\u4e92\u9694\u79bb\uff0c\u9700\u8981\u7edf\u4e00\u7684\u96c6\u6210\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u6587\u732e\uff0c\u63d0\u51fa\u5305\u542b\u81ea\u9002\u5e94\u673a\u5236\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u6846\u67b6\u3001\u7edf\u4e00\u6a21\u578b\u3001\u96c6\u6210\u7b56\u7565\u548cMCP\u67b6\u6784\u7684\u4e94\u7c7b\u5206\u7c7b\u6cd5\uff0c\u8fdb\u884c\u7cfb\u7edf\u6027\u8c03\u67e5\u5206\u6790\u3002", "result": "\u53d1\u73b0\u4f20\u7edf\u4f20\u8f93\u534f\u8bae\u5df2\u8fbe\u5230\u5b64\u7acb\u9002\u5e94\u7684\u6781\u9650\uff0cMCP\u7684\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u548cJSON-RPC\u7ed3\u6784\u80fd\u591f\u5b9e\u73b0\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\uff0cAI\u9a71\u52a8\u7684\u4f20\u8f93\u9700\u8981MCP\u7279\u6709\u7684\u96c6\u6210\u8303\u5f0f\u3002", "conclusion": "MCP\u5e94\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u81ea\u9002\u5e94\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u667a\u80fd\u4f20\u8f93\u57fa\u7840\u8bbe\u65bd\u7684\u57fa\u7840\uff0c\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u7814\u7a76\u8def\u7ebf\u56fe\u3002"}}
