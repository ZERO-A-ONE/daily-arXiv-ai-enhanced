<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 12]
- [cs.CR](#cs.CR) [Total: 16]
- [cs.AI](#cs.AI) [Total: 39]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Towards the Datasets Used in Requirements Engineering of Mobile Apps: Preliminary Findings from a Systematic Mapping Study](https://arxiv.org/abs/2509.03541)
*Chong Wang,Haoning Wu,Peng Liang,Maya Daneva,Marten van Sinderen*

Main category: cs.SE

TL;DR: 这篇论文通过系统映射研究分析了移动应用需求工程研究中使用的数据集来源和需求活动分布，发现Google Play和Apple App Store占据了超过90%的研究数据来源，并指出这可能导致知识偏差。


<details>
  <summary>Details</summary>
Motivation: 调查移动应用需求工程研究中使用的数据集状况，了解数据集的平台来源和对应的RE活动分布。

Method: 采用Kitchenham等人的指南进行系统映射研究，基于43篇选定的论文进行分析。

Result: 发现Google Play和Apple App Store提供了超过90%的移动应用RE研究数据集；最常规研究的RE活动是需求获取和需求分析。

Conclusion: 自2012年以来移动应用RE研究中数据集使用增长；Google Play和Apple App Store的过度使用可能导致知识偏差；需要扩展其他数据源和研究其他RE活动以获得更具普遍性的结果。

Abstract: [Background] Research on requirements engineering (RE) for mobile apps
employs datasets formed by app users, developers or vendors. However, little is
known about the sources of these datasets in terms of platforms and the RE
activities that were researched with the help of the respective datasets.
[Aims] The goal of this paper is to investigate the state-of-the-art of the
datasets of mobile apps used in existing RE research. [Method] We carried out a
systematic mapping study by following the guidelines of Kitchenham et al.
[Results] Based on 43 selected papers, we found that Google Play and Apple App
Store provide the datasets for more than 90% of published research in RE for
mobile apps. We also found that the most investigated RE activities - based on
datasets, are requirements elicitation and requirements analysis. [Conclusions]
Our most important conclusions are: (1) there is a growth in the use of
datasets for RE research of mobile apps since 2012, (2) the RE knowledge for
mobile apps might be skewed due to the overuse of Google Play and Apple App
Store, (3) there are attempts to supplement reviews of apps from repositories
with other data sources, (4) there is a need to expand the alternative sources
and experiments with complimentary use of multiple sources, if the community
wants more generalizable results. Plus, it is expected to expand the research
on other RE activities, beyond elicitation and analysis.

</details>


### [2] [A Multi-stage Error Diagnosis for APB Transaction](https://arxiv.org/abs/2509.03554)
*Cheng-Yang Tsai,Tzu-Wei Huang,Jen-Wei Shih,I-Hsiang Wang,Yu-Cheng Lin,Rung-Bin Lin*

Main category: cs.SE

TL;DR: 采用分层随机森林算法的自动化APB交易错误诊断框架，在ICCAD 2025竞赛中获得91.36%的整体准确率和测试阶段第一名


<details>
  <summary>Details</summary>
Motivation: 解决手动检测APB交易错误在大规模VCD文件中效率低下、易出错的问题

Method: 使用四个预训练二元分类器构成的分层随机森林架构，按序检测超出范围访问、地址污染和数据污染错误

Result: 整体准确率91.36%，地址相关错误的精度和召回率近优，数据错误表现稳健，在ICCAD 2025竞赛测试阶段获得第一名

Conclusion: 验证了分层机器学习在EDA硬件调试中作为强大自动化工具的潜力

Abstract: Functional verification and debugging are critical bottlenecks in modern
System-on-Chip (SoC) design, with manual detection of Advanced Peripheral Bus
(APB) transaction errors in large Value Change Dump (VCD) files being
inefficient and error-prone. Addressing the 2025 ICCAD Contest Problem D, this
study proposes an automated error diagnosis framework using a hierarchical
Random Forest-based architecture. The multi-stage error diagnosis employs four
pre-trained binary classifiers to sequentially detect Out-of-Range Access,
Address Corruption, and Data Corruption errors, prioritizing high-certainty
address-related faults before tackling complex data errors to enhance
efficiency. Experimental results show an overall accuracy of 91.36%, with
near-perfect precision and recall for address errors and robust performance for
data errors. Although the final results of the ICCAD 2025 CAD Contest are yet
to be announced as of the submission date, our team achieved first place in the
beta stage, highlighting the method's competitive strength. This research
validates the potential of hierarchical machine learning as a powerful
automated tool for hardware debugging in Electronic Design Automation (EDA).

</details>


### [3] [Parse Tree Tracking Through Time for Programming Process Analysis at Scale](https://arxiv.org/abs/2509.03668)
*Matt Rau,Chris Brown,John Edwards*

Main category: cs.SE

TL;DR: 这篇论文提出了首个算法来跟踪编程过程中的抽象语法树节点变化，并利用该算法对CS1课程学生的键盘操作数据进行分析，发现了许多新的编程行为统计规律。


<details>
  <summary>Details</summary>
Motivation: 传统的编程过程数据分析主要使用高级描述统计，无法自动跟踪高级代码表示如抽象语法树的时间变化，导致在上下文中分析学生编程行为非常困难。

Method: 提出两种算法来跟踪解析树节点的时间变化并为无法解析的代码状态构建树表示，并将其应用于2021年CS1课程的公开键盘数据进行分析。

Result: 发现了多个新的可观测统计：条件语句和循环内外的代码删除率相似，三分之一的注释掉代码最终会恢复，以及学生在代码中跳转的频率可能不代表困难程度。

Conclusion: 跟踪解析树的能力为理解学生编程的新维度打开了大门，包括代码结构发展的最佳实践、语法构造困难度的定量测量、重构行为和代码内注意力转移等。

Abstract: Background and Context: Programming process data can be utilized to
understand the processes students use to write computer programming
assignments. Keystroke- and line-level event logs have been used in the past in
various ways, primarily in high-level descriptive statistics (e.g., timings,
character deletion rate, etc). Analysis of behavior in context (e.g., how much
time students spend working on loops) has been cumbersome because of our
inability to automatically track high-level code representations, such as
abstract syntax trees, through time and unparseable states.
  Objective: Our study has two goals. The first is to design the first
algorithm that tracks parse tree nodes through time. Second, we utilize this
algorithm to perform a partial replication study of prior work that used manual
tracking of code representations, as well as other novel analyses of student
programming behavior that can now be done at scale.
  Method: We use two algorithms presented in this paper to track parse tree
nodes through time and construct tree representations for unparseable code
states. We apply these algorithms to a public keystroke data from student
coursework in a 2021 CS1 course and conduct analysis on the resulting parse
trees.
  Findings: We discover newly observable statistics at scale, including that
code is deleted at similar rates inside and outside of conditionals and loops,
a third of commented out code is eventually restored, and that frequency with
which students jump around in their code may not be indicative of struggle.
  Implications: The ability to track parse trees through time opens the door to
understanding new dimensions of student programming, such as best practices of
structural development of code over time, quantitative measurement of what
syntactic constructs students struggle most with, refactoring behavior, and
attention shifting within the code.

</details>


### [4] [Towards an Understanding of Developer Experience-Driven Transparency in Software Ecosystems](https://arxiv.org/abs/2509.03848)
*Rodrigo Oliveira Zacarias,Rodrigo Pereira dos Santos,Patricia Lago*

Main category: cs.SE

TL;DR: 这篇论文提出了SECO-TransDX概念模型，从开发者体验角度系统性概念化了软件生态系统中的透明性问题，识别了63个相关概念并通过專家调查验证。


<details>
  <summary>Details</summary>
Motivation: 虽然透明性被认为对信任、公平和参与度至关重要，但其与开发者体验的关系尚未系统化概念化，需要从开发者中心角度探索透明性在软件生态系统中的作用。

Method: 基于先前研究构建SECO-TransDX概念模型，通过Delphi研究方法使用学术界和业界專家进行精炼。模型包含条件因素、生态系统程序、产出物和关系动态等8类63个相互关联概念。

Result: 建立了一个结构化的概念模型SECO-TransDX，提出了DX驱动的透明性概念，为研究人员提供了未来研究和工具开发的基础，为实践者支持设计可信赖、以开发者为中心的平台。

Conclusion: SECO-TransDX模型为理论研究和实践应用提供了一个结构化的视角，用于分析透明性如何在技术、社会和组织层面中介导开发者体验，有助于提高透明性并促进软件生态系统的长期参与度。

Abstract: Software ecosystems (SECO) have become a dominant paradigm in the software
industry, enabling third-party developers to co-create value through
complementary components and services. While Developer Experience (DX) is
increasingly recognized as critical for sustainable SECO, transparency remains
an underexplored factor shaping how developers perceive and interact with
ecosystems. Existing studies acknowledge transparency as essential for trust,
fairness, and engagement, yet its relationship with DX has not been
systematically conceptualized. Hence, this work aims to advance the
understanding of transparency in SECO from a developer-centered perspective. To
this end, we propose SECO-TransDX (Transparency in Software Ecosystems from a
Developer Experience Perspective), a conceptual model that introduces the
notion of DX-driven transparency. The model identifies 63 interrelated
concepts, including conditioning factors, ecosystem procedures, artifacts, and
relational dynamics that influence how transparency is perceived and
constructed during developer interactions. SECO-TransDX was built upon prior
research and refined through a Delphi study with experts from academia and
industry. It offers a structured lens to examine how transparency mediates DX
across technical, social, and organizational layers. For researchers, it lays
the groundwork for future studies and tool development; for practitioners, it
supports the design of trustworthy, developer-centered platforms that improve
transparency and foster long-term engagement in SECO.

</details>


### [5] [VulRTex: A Reasoning-Guided Approach to Identify Vulnerabilities from Rich-Text Issue Report](https://arxiv.org/abs/2509.03875)
*Ziyou Jiang,Mingyang Li,Guowei Yang,Lin Shi,Qing Wang*

Main category: cs.SE

TL;DR: VulRTex是一个基于大语言模型推理能力的漏洞相关issue报告识别方法，通过构建漏洞推理数据库和检索相关案例来指导LLM分析目标IR的富文本信息，在数据不平衡时表现最佳，比最佳基线提升11.0% F1分数，时间成本降低2倍


<details>
  <summary>Details</summary>
Motivation: 开源软件中存在漏洞，开发者提交的issue报告需要安全从业者手动识别漏洞相关报告，耗时且存在时间差可能被攻击者利用。现有方法主要关注文本描述，缺乏对IR富文本信息的综合分析

Method: 首先利用LLM的推理能力构建漏洞推理数据库，然后检索相关案例生成推理指导，引导LLM对目标IR的富文本信息进行推理分析来识别漏洞

Result: 在973,572个IRs上的实验显示，VulRTex在数据不平衡时识别漏洞相关IRs和预测CWE-ID方面性能最高，比最佳基线提升+11.0% F1、+20.2% AUPRC、+10.5% Macro-F1，时间成本降低2倍。在2024年GitHub IRs中成功识别30个新兴漏洞，其中11个获得CVE-ID

Conclusion: VulRTex通过利用LLM的推理能力和富文本信息分析，有效提高了漏洞相关issue报告的识别效率和准确性，具有实际应用价值

Abstract: Software vulnerabilities exist in open-source software (OSS), and the
developers who discover these vulnerabilities may submit issue reports (IRs) to
describe their details. Security practitioners need to spend a lot of time
manually identifying vulnerability-related IRs from the community, and the time
gap may be exploited by attackers to harm the system. Previously, researchers
have proposed automatic approaches to facilitate identifying these
vulnerability-related IRs, but these works focus on textual descriptions but
lack the comprehensive analysis of IR's rich-text information. In this paper,
we propose VulRTex, a reasoning-guided approach to identify
vulnerability-related IRs with their rich-text information. In particular,
VulRTex first utilizes the reasoning ability of the Large Language Model (LLM)
to prepare the Vulnerability Reasoning Database with historical IRs. Then, it
retrieves the relevant cases from the prepared reasoning database to generate
reasoning guidance, which guides LLM to identify vulnerabilities by reasoning
analysis on target IRs' rich-text information. To evaluate the performance of
VulRTex, we conduct experiments on 973,572 IRs, and the results show that
VulRTex achieves the highest performance in identifying the
vulnerability-related IRs and predicting CWE-IDs when the dataset is
imbalanced, outperforming the best baseline with +11.0% F1, +20.2% AUPRC, and
+10.5% Macro-F1, and 2x lower time cost than baseline reasoning approaches.
Furthermore, VulRTex has been applied to identify 30 emerging vulnerabilities
across 10 representative OSS projects in 2024's GitHub IRs, and 11 of them are
successfully assigned CVE-IDs, which illustrates VulRTex's practicality.

</details>


### [6] [Vulnerability-Affected Versions Identification: How Far Are We?](https://arxiv.org/abs/2509.03876)
*Xingchu Chen,Chengwei Liu,Jialun Cao,Yang Xiao,Xinyue Cai,Yeting Li,Jingyi Shi,Tianqi Sun,Haiming Chen ang Wei Huo*

Main category: cs.SE

TL;DR: 本文对12种漏洞影响版本识别工具进行了全面实证研究，发现所有工具准确率均不超过45%，揭示了现有方法在启发式依赖、语义推理和匹配逻辑方面的根本局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管存在多种漏洞影响版本识别工具，但由于评估范围狭窄、技术过时和小规模数据集等问题，这些工具在现实世界中的有效性仍不明确。

Method: 构建了包含1,128个真实C/C++漏洞的高质量基准，从跟踪和匹配两种范式系统评估了12种代表性工具，涵盖漏洞级别和版本级别的有效性、误报误诊根因分析、对补丁特性的敏感性以及集成潜力四个维度。

Result: 研究发现所有工具准确率均不超过45.0%，主要挑战来自启发式依赖、有限的语义推理和僵化的匹配逻辑。仅添加和跨文件更改等补丁结构进一步影响性能。集成策略最多可提升10.1%的准确率，但总体准确率仍低于60.0%。

Conclusion: 现有工具存在根本性局限，需要全新的方法突破。研究为工具开发、组合策略和未来研究提供了可操作的见解，并发布了复现代码和基准数据集以促进后续贡献。

Abstract: Identifying which software versions are affected by a vulnerability is
critical for patching, risk mitigation.Despite a growing body of tools, their
real-world effectiveness remains unclear due to narrow evaluation scopes often
limited to early SZZ variants, outdated techniques, and small or
coarse-graineddatasets. In this paper, we present the first comprehensive
empirical study of vulnerability affected versions identification. We curate a
high quality benchmark of 1,128 real-world C/C++ vulnerabilities and
systematically evaluate 12 representative tools from both tracing and matching
paradigms across four dimensions: effectiveness at both vulnerability and
version levels, root causes of false positives and negatives, sensitivity to
patch characteristics, and ensemble potential. Our findings reveal fundamental
limitations: no tool exceeds 45.0% accuracy, with key challenges stemming from
heuristic dependence, limited semantic reasoning, and rigid matching logic.
Patch structures such as add-only and cross-file changes further hinder
performance. Although ensemble strategies can improve results by up to 10.1%,
overall accuracy remains below 60.0%, highlighting the need for fundamentally
new approaches. Moreover, our study offers actionable insights to guide tool
development, combination strategies, and future research in this critical area.
Finally, we release the replicated code and benchmark on our website to
encourage future contributions.outdated techniques, and small or coarse grained
datasets.

</details>


### [7] [Analyzing Variations in Dependency Distributions Due to Code Smell Interactions](https://arxiv.org/abs/2509.03896)
*Zushuai Zhang,Elliott Wen,Ewan Tempero*

Main category: cs.SE

TL;DR: 代码异味之间的相互作用会增加模块间的依赖关系，导致维护复杂性和成本增加，应优先处理相互作用的代码异味。


<details>
  <summary>Details</summary>
Motivation: 代码异味可能会相互作用并增加模块间的依赖关系，这会给软件维护带来复杂性和成本。需要证实以前的观察并研究代码异味相互作用对静态依赖分布的影响。

Method: 对116个开源Java系统进行依赖分析，量化代码异味之间的相互作用，并比较代码异味之间以及代码异味与非代码异味之间的作用。

Result: 代码异味对之间的相互作用会导致某些依赖关系的增加和其他依赖关系的减少，但总体依赖关系增加。例如，Feature Envy方法与Data Classes之间的依赖关系数量中位数是非Feature Envy方法的7倍（从1增加到7）。

Conclusion: 开发者应优先处理相互作用的代码异味，而不是单独存在的代码异味，以减少模块间的依赖关系和降低维护复杂性。

Abstract: The existence of dependencies between modules, such as classes, can mean that
changing a module triggers ripple effects that make maintenance complex and
costly, so the advice is to minimize dependencies between modules. It is
therefore important to understand the circumstances that can lead to increased
dependencies. Recent studies suggest that code smells, which are
characteristics of code that indicate potential design issues, may interact in
ways that increase dependencies between modules. In this study, we aim to
confirm previous observations and investigate whether and how the distribution
of static dependencies changes in the presence of code smell interactions. We
conducted a dependency analysis on 116 open-source Java systems to quantify the
interactions, comparing interactions among code smells and interactions between
code smells and non-code smells. Our results suggest that while interactions
between code smell pairs are associated with increases in certain dependencies
and decreases in others, overall, they are associated with an increase in total
dependencies. For example, the median number of dependencies between Feature
Envy methods and Data Classes is seven times as many as when the methods are
non-Feature Envy methods, increasing from 1 to 7. This implies that developers
should prioritize addressing code smells that interact with each other, rather
than code smells that exist only in isolation.

</details>


### [8] [The Auth Shim: A Lightweight Architectural Pattern for Integrating Enterprise SSO with Standalone Open-Source Applications](https://arxiv.org/abs/2509.03900)
*Yuvraj Agrawal*

Main category: cs.SE

TL;DR: 本文提出了Auth Shim架构模式，通过外部代理服务解决开源软件缺乏企业级身份验证协议支持的问题，实现了OSS工具与企业SSO生态系统的安全集成。


<details>
  <summary>Details</summary>
Motivation: 企业广泛采用开源软件，但许多OSS工具缺乏对SAML、OIDC等企业级身份验证协议的原生支持，导致安全集成存在重大缺口。

Method: Auth Shim是一种轻量级架构模式，作为外部代理服务充当兼容层，将企业身份提供商的请求转换为目标应用程序的原生会话管理机制。目标应用需要提供安全的程序化管理API。

Result: 在Adobe的案例研究中，成功将流行的OSS BI工具与Okta SAML集成，实现了基于IAM组映射的自动化RBAC，消除了手动用户配置。

Conclusion: Auth Shim提供了一个可重用、安全且成本效益高的蓝图，使组织能够在保持安全治理的同时采用开源创新。

Abstract: Open-source software OSS is widely adopted in enterprise settings, but
standalone tools often lack native support for protocols like SAML or OIDC,
creating a critical security integration gap. This paper introduces and
formalizes the Auth Shim, a lightweight architectural pattern designed to solve
this problem. The Auth Shim is a minimal, external proxy service that acts as a
compatibility layer, translating requests from an enterprise Identity Provider
IdP into the native session management mechanism of a target application. A key
prerequisite for this pattern is that the target application must expose a
programmatic, secure administrative API. We present a case study of the
pattern's implementation at Adobe to integrate a popular OSS BI tool with Okta
SAML, which enabled automated Role-Based Access Control RBAC via IAM group
mapping and eliminated manual user provisioning. By defining its components,
interactions, and production deployment considerations, this paper provides a
reusable, secure, and cost-effective blueprint for integrating any standalone
OSS tool into an enterprise SSO ecosystem, thereby enabling organizations to
embrace open-source innovation without compromising on security governance.

</details>


### [9] [RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models](https://arxiv.org/abs/2509.04078)
*Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang*

Main category: cs.SE

TL;DR: RepoDebug是一个多任务、多语言的仓库级代码调试数据集，包含22种错误子类型、8种编程语言和3种调试任务，用于评估LLM在复杂仓库级调试场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有调试数据集主要关注函数级代码修复，忽略了更复杂和现实的仓库级场景，导致对LLM在仓库级调试中面临的挑战理解不完整。

Method: 构建RepoDebug数据集，包含22种错误子类型、支持8种常用编程语言和3种调试任务，并在10个LLM上进行评估实验。

Result: 即使是表现最好的Claude 3.5 Sonnet模型，在仓库级调试任务中仍然表现不佳。

Conclusion: 仓库级代码调试对LLM来说仍然是一个重大挑战，需要更全面的数据集来推动该领域的发展。

Abstract: Large Language Models (LLMs) have exhibited significant proficiency in code
debugging, especially in automatic program repair, which may substantially
reduce the time consumption of developers and enhance their efficiency.
Significant advancements in debugging datasets have been made to promote the
development of code debugging. However, these datasets primarily focus on
assessing the LLM's function-level code repair capabilities, neglecting the
more complex and realistic repository-level scenarios, which leads to an
incomplete understanding of the LLM's challenges in repository-level debugging.
While several repository-level datasets have been proposed, they often suffer
from limitations such as limited diversity of tasks, languages, and error
types. To mitigate this challenge, this paper introduces RepoDebug, a
multi-task and multi-language repository-level code debugging dataset with 22
subtypes of errors that supports 8 commonly used programming languages and 3
debugging tasks. Furthermore, we conduct evaluation experiments on 10 LLMs,
where Claude 3.5 Sonnect, the best-performing model, still cannot perform well
in repository-level debugging.

</details>


### [10] [An Empirical Study of Vulnerabilities in Python Packages and Their Detection](https://arxiv.org/abs/2509.04260)
*Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du*

Main category: cs.SE

TL;DR: PyVul是首个全面的Python包漏洞基准测试套件，包含1,157个已验证漏洞，支持多种检测技术，并揭示了现有工具在检测Python包安全漏洞方面的显著不足。


<details>
  <summary>Details</summary>
Motivation: Python包作为组织、重用和分发单元存在大量漏洞报告，且Python常与其他语言协作增加了漏洞复杂性，当前漏洞检测工具的有效性尚未充分探索。

Method: 引入PyVul基准套件，包含1,157个公开报告的开发者验证漏洞，提供提交和函数级注释，采用LLM辅助数据清洗方法提高标签准确性。

Result: PyVul达到100%提交级和94%函数级准确率，是多语言Python包漏洞的最精确大规模基准；评估显示现有工具能力与真实需求存在显著差距。

Conclusion: Python包漏洞涉及多种编程语言和类型，多语言Python包更易受攻击；当前检测工具存在细粒度限制，需要未来技术发展来有效识别真实安全威胁。

Abstract: In the rapidly evolving software development landscape, Python stands out for
its simplicity, versatility, and extensive ecosystem. Python packages, as units
of organization, reusability, and distribution, have become a pressing concern,
highlighted by the considerable number of vulnerability reports. As a scripting
language, Python often cooperates with other languages for performance or
interoperability. This adds complexity to the vulnerabilities inherent to
Python packages, and the effectiveness of current vulnerability detection tools
remains underexplored. This paper addresses these gaps by introducing PyVul,
the first comprehensive benchmark suite of Python-package vulnerabilities.
PyVul includes 1,157 publicly reported, developer-verified vulnerabilities,
each linked to its affected packages. To accommodate diverse detection
techniques, it provides annotations at both commit and function levels. An
LLM-assisted data cleansing method is incorporated to improve label accuracy,
achieving 100% commit-level and 94% function-level accuracy, establishing PyVul
as the most precise large-scale Python vulnerability benchmark. We further
carry out a distribution analysis of PyVul, which demonstrates that
vulnerabilities in Python packages involve multiple programming languages and
exhibit a wide variety of types. Moreover, our analysis reveals that
multi-lingual Python packages are potentially more susceptible to
vulnerabilities. Evaluation of state-of-the-art detectors using this benchmark
reveals a significant discrepancy between the capabilities of existing tools
and the demands of effectively identifying real-world security issues in Python
packages. Additionally, we conduct an empirical review of the top-ranked CWEs
observed in Python packages, to diagnose the fine-grained limitations of
current detection tools and highlight the necessity for future advancements in
the field.

</details>


### [11] [FaaSGuard: Secure CI/CD for Serverless Applications -- An OpenFaaS Case Study](https://arxiv.org/abs/2509.04328)
*Amine Barrak,Emna Ksontini,Ridouane Atike,Fehmi Jaafar*

Main category: cs.SE

TL;DR: FaaSGuard是一个针对开源无服务器环境的统一DevSecOps管道，通过在开发生命周期的各个阶段嵌入轻量级安全检查，有效检测和防止关键漏洞。


<details>
  <summary>Details</summary>
Motivation: 无服务器计算虽然简化了基础设施管理，但其短暂执行和细粒度扩展等特性带来了独特的安全挑战，特别是对于OpenFaaS等开源平台。现有方法通常只处理DevSecOps生命周期的孤立阶段，缺乏集成化的全面安全策略。

Method: 提出FaaSGuard统一DevSecOps管道，在开发生命周期的规划、编码、构建、部署和监控等每个阶段系统性地嵌入轻量级、故障关闭的安全检查，以应对注入攻击、硬编码密钥和资源耗尽等威胁。

Result: 通过对20个真实世界无服务器函数的案例研究验证，FaaSGuard有效检测和防止关键漏洞，表现出高精度（95%）和高召回率（91%），且不会显著干扰现有的CI/CD实践。

Conclusion: FaaSGuard为开源无服务器环境提供了一个有效的集成安全解决方案，能够在保持开发效率的同时显著提升安全性。

Abstract: Serverless computing significantly alters software development by abstracting
infrastructure management and enabling rapid, modular, event-driven
deployments. Despite its benefits, the distinct characteristics of serverless
functions, such as ephemeral execution and fine-grained scalability, pose
unique security challenges, particularly in open-source platforms like
OpenFaaS. Existing approaches typically address isolated phases of the
DevSecOps lifecycle, lacking an integrated and comprehensive security strategy.
To bridge this gap, we propose FaaSGuard, a unified DevSecOps pipeline
explicitly designed for open-source serverless environments. FaaSGuard
systematically embeds lightweight, fail-closed security checks into every stage
of the development lifecycle-planning, coding, building, deployment, and
monitoring-effectively addressing threats such as injection attacks, hard-coded
secrets, and resource exhaustion. We validate our approach empirically through
a case study involving 20 real-world serverless functions from public GitHub
repositories. Results indicate that FaaSGuard effectively detects and prevents
critical vulnerabilities, demonstrating high precision (95%) and recall (91%)
without significant disruption to established CI/CD practices.

</details>


### [12] [Design and Development of a Web Platform for Blood Donation Management](https://arxiv.org/abs/2509.04423)
*Fatima Zulfiqar Ali,Atrooba Ilyas*

Main category: cs.SE

TL;DR: 开发了一个基于网络的献血平台，使用现代Web技术连接患者、献血者和管理员，通过集中式数字空间提高紧急情况下的血液获取效率。


<details>
  <summary>Details</summary>
Motivation: 解决紧急情况下寻找合适献血者的挑战，减少血液获取的延迟和复杂性，提高献血服务的整体效率。

Method: 采用用例图、数据库图、类图和序列图指导平台设计，使用PHP(Laravel框架)、HTML、CSS、Bootstrap和MySQL等技术实现动态交互式平台。

Result: 开发了一个用户友好的网络平台，允许献血者注册个人信息，患者基于血型和位置搜索献血者，系统提供附近可用献血者列表。

Conclusion: 该平台通过简化献血者注册、血液请求和沟通流程，显著改善了紧急情况下血液的及时可及性，提升了献血服务的整体效率。

Abstract: Blood donation is a critical component of healthcare, yet locating suitable
donors in emergencies often presents significant challenges. This paper
presents the design and development of a Blood Donation Web Platform, a
web-based system that connects patients, donors, and administrators within a
centralized digital space. The platform allows interested donors to register
their personal information, including blood group, contact details, and
availability. Patients can search for donors based on blood group and location,
and the system provides a list of nearby donors who are ready to donate. The
platform design was guided by use case, database, class, and sequence diagrams
to ensure a well-structured and efficient system architecture. Modern web
technologies, including PHP (Laravel framework), HTML, CSS, Bootstrap, and
MySQL, supported by XAMPP and Visual Studio Code, were employed to implement a
dynamic, interactive, and user-friendly platform. By streamlining donor
refgistration, blood requests, and communication, the proposed system reduces
delays and complexities in emergencies, improving timely accessibility of blood
and enhancing overall efficiency in blood donation services.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [13] [Reactive Bottom-Up Testing](https://arxiv.org/abs/2509.03711)
*Siddharth Muralee,Sourag Cherupattamoolayil,James C. Davis,Antonio Bianchi,Aravind Machiry*

Main category: cs.CR

TL;DR: 提出Reactive Bottom-Up Testing新范式，通过三阶段方法（识别漏洞函数、模糊测试提取约束、验证消除误报）来检测深层函数漏洞，在基准测试中成功检测28个已知漏洞，并在实际应用中发现6个新漏洞。


<details>
  <summary>Details</summary>
Motivation: 传统动态测试技术采用自上而下方法，难以触及调用图深处的函数。虽然已有自下而上方法提出，但仍面临误报和生成符合程序上下文的有效输入等挑战。

Method: 三阶段自下而上测试方案：1)识别可能漏洞函数并生成类型和上下文感知的测试框架；2)通过模糊测试发现崩溃并用符号执行提取输入约束；3)结合约束验证崩溃以消除误报。开发了自动化原型Griller。

Result: 在包含5个开源项目48个已知漏洞的基准测试中，成功检测28个已知漏洞。在实际应用如Pacman中发现了6个先前未知的漏洞。

Conclusion: Reactive Bottom-Up Testing能显著增强复杂系统中漏洞检测能力，为更强大的安全实践铺平道路。

Abstract: Modern computing systems remain rife with software vulnerabilities. Engineers
apply many means to detect them, of which dynamic testing is one of the most
common and effective. However, most dynamic testing techniques follow a
top-down paradigm, and struggle to reach and exercise functions deep within the
call graph. While recent works have proposed Bottom-Up approaches to address
these limitations, they face challenges with false positives and generating
valid inputs that adhere to the context of the entire program.
  In this work, we introduce a new paradigm that we call Reactive Bottom-Up
Testing. Our insight is that function-level testing is necessary but not
sufficient for the validation of vulnerabilities in functions. What we need is
a systematic approach that not only tests functions in isolation but also
validates their behavior within the broader program context, ensuring that
detected vulnerabilities are both reachable and triggerable. We develop a
three-stage bottom-up testing scheme: (1) identify likely-vulnerable functions
and generate type- and context-aware harnesses; (2) fuzz to find crashes and
extract input constraints via symbolic execution; (3) verify crashes by
combining constraints to remove false positives. We implemented an automated
prototype, which we call Griller. We evaluated Griller in a controlled setting
using a benchmark of 48 known vulnerabilities across 5 open-source projects,
where we successfully detected 28 known vulnerabilities. Additionally, we
evaluated Griller on several real-world applications such as Pacman, and it
discovered 6 previously unknown vulnerabilities. Our findings suggest that
Reactive Bottom-Up Testing can significantly enhance the detection of
vulnerabilities in complex systems, paving the way for more robust security
practices.

</details>


### [14] [A Quantum Genetic Algorithm-Enhanced Self-Supervised Intrusion Detection System for Wireless Sensor Networks in the Internet of Things](https://arxiv.org/abs/2509.03744)
*Hamid Barati*

Main category: cs.CR

TL;DR: 重新设计了一种新的混合入侵检测系统，结合量子遗传算法和自监督学习，以解决IoT环境中传统IDS计算成本高、依赖标签数据集的问题。


<details>
  <summary>Details</summary>
Motivation: IoT和WSN的快速扩展大大增加了系统的攻击面，传统入侵检测系统因计算成本高、依赖大量标签数据而无法满足资源受限IoT环境的严格要求。

Method: 提出一种新的混合入侵检测系统，集成量子遗传算法(QGA)和自监督学习(SSL)。QGA利用量子启发的进化运算符优化特征选择和模型参数微调，SSL允许系统从无标签数据中学习健壮表征。

Result: 在标准IoT入侵数据集上评估，显示出在检测准确率、假正率和计算效率方面都超过传统进化和深度学习IDS模型的优秀性能。

Conclusion: 结合量子启发的优化技术与自监督学习范式，有力为IoT和WSN环境设计下一代入侵检测解决方案。

Abstract: The rapid expansion of the Internet of Things (IoT) and Wireless Sensor
Networks (WSNs) has significantly increased the attack surface of such systems,
making them vulnerable to a wide range of cyber threats. Traditional Intrusion
Detection Systems (IDS) often fail to meet the stringent requirements of
resource-constrained IoT environments due to their high computational cost and
reliance on large labeled datasets. To address these challenges, this paper
proposes a novel hybrid Intrusion Detection System that integrates a Quantum
Genetic Algorithm (QGA) with Self-Supervised Learning (SSL). The QGA leverages
quantum-inspired evolutionary operators to optimize feature selection and
fine-tune model parameters, ensuring lightweight yet efficient detection in
resource-limited networks. Meanwhile, SSL enables the system to learn robust
representations from unlabeled data, thereby reducing dependency on manually
labeled training sets. The proposed framework is evaluated on benchmark IoT
intrusion datasets, demonstrating superior performance in terms of detection
accuracy, false positive rate, and computational efficiency compared to
conventional evolutionary and deep learning-based IDS models. The results
highlight the potential of combining quantum-inspired optimization with
self-supervised paradigms to design next-generation intrusion detection
solutions for IoT and WSN environments.

</details>


### [15] [Peekaboo, I See Your Queries: Passive Attacks Against DSSE Via Intermittent Observations](https://arxiv.org/abs/2509.03806)
*Hao Nie,Wei Wang,Peng Xu,Wei Chen,Laurence T. Yang,Mauro Conti,Kaitai Liang*

Main category: cs.CR

TL;DR: Peekaboo是一个针对动态可搜索对称加密(DSSE)的新型通用攻击框架，能够在间歇性观察的实用威胁模型下有效恢复搜索模式，攻击准确率显著优于现有方法，并能抵抗现有防护措施。


<details>
  <summary>Details</summary>
Motivation: 现有DSSE被动攻击需要持续监控泄漏模式，而实际应用中攻击者往往只能进行间歇性观察。本文针对这种更实用的威胁模型，旨在开发在有限观察条件下仍能有效攻击DSSE的方法。

Method: 提出Peekaboo通用攻击框架，通过推断搜索模式并结合辅助知识和其他泄漏信息。在Sap和Jigsaw等最先进攻击方法基础上实例化，开发出Sap+和Jigsaw+变体。

Result: 实验表明，Peekaboo在搜索模式恢复方面达到>0.9的调整兰德指数，查询准确率达到90%（相比FMA的30%）。攻击准确率随观察轮次和查询数量增加而提升，且能抵抗文件大小填充（>40%准确率）和混淆（>80%准确率）等防护措施。

Conclusion: Peekaboo证明了在间歇性观察的实用威胁模型下，DSSE仍然面临严重的安全风险。该框架具有通用性，能够有效提升现有攻击方法的性能，并对当前防护措施构成挑战。

Abstract: Dynamic Searchable Symmetric Encryption (DSSE) allows secure searches over a
dynamic encrypted database but suffers from inherent information leakage.
Existing passive attacks against DSSE rely on persistent leakage monitoring to
infer leakage patterns, whereas this work targets intermittent observation - a
more practical threat model. We propose Peekaboo - a new universal attack
framework - and the core design relies on inferring the search pattern and
further combining it with auxiliary knowledge and other leakage. We instantiate
Peekaboo over the SOTA attacks, Sap (USENIX' 21) and Jigsaw (USENIX' 24), to
derive their "+" variants (Sap+ and Jigsaw+). Extensive experiments demonstrate
that our design achieves >0.9 adjusted rand index for search pattern recovery
and 90% query accuracy vs. FMA's 30% (CCS' 23). Peekaboo's accuracy scales with
observation rounds and the number of observed queries but also it resists SOTA
countermeasures, with >40% accuracy against file size padding and >80% against
obfuscation.

</details>


### [16] [BIDO: A Unified Approach to Address Obfuscation and Concept Drift Challenges in Image-based Malware Detection](https://arxiv.org/abs/2509.03807)
*Junhui Li,Chengbin Feng,Zhiwei Yang,Qi Mo,Wei Wang*

Main category: cs.CR

TL;DR: BIDO是一个基于图像的混合恶意软件检测器，通过局部特征选择、跨模态依赖建模和可学习度量，同时增强对混淆和概念漂移的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的Android恶意软件检测方法在面对混淆和概念漂移时性能显著下降，且现有解决方案往往将这两个挑战视为独立问题，忽略了它们共同的统计根源——分布外问题

Method: 1) 局部特征选择模块识别恶意软件图像中的信息子区域；2) 在外积空间中建模跨模态依赖关系提取稳定共现模式；3) 设计可学习度量使相同标签样本靠近、不同标签样本远离

Result: 在真实数据集上的大量实验表明，BIDO显著优于现有基线方法，对概念漂移和混淆都实现了更高的鲁棒性

Conclusion: BIDO通过同时处理混淆和概念漂移的共同统计根源，有效提升了基于图像的恶意软件检测的鲁棒性和性能

Abstract: To identify malicious Android applications, various malware detection
techniques have been proposed. Among them, image-based approaches are
considered potential alternatives due to their efficiency and scalability.
Recent studies have reported that these approaches suffer significant
performance declines when confronted with obfuscation or concept drift.
However, existing solutions often treat these two challenges as different
problems, offering independent solutions. These techniques overlook the fact
that both challenges share a common statistical root, out-of-distribution, and
research from this perspective remains limited. In response, we propose BIDO, a
hybrid image-based malware detector designed to enhance robustness against both
obfuscation and concept drift simultaneously. Specifically, to improve the
discriminative power of image features, we introduce a local feature selection
module that identifies informative subregions within malware images. Second, to
enhance feature robustness, we model pairwise cross-modal dependencies in an
outer product space, enabling the extraction of stable co-occurrence patterns.
Third, to ensure feature compactness, we design a learnable metric that pulls
samples with identical labels closer while pushing apart those with different
labels, regardless of obfuscation or concept drift. Extensive experiments on
the real-world datasets demonstrate that BIDO significantly outperforms
existing baselines, achieving higher robustness against both concept drift and
obfuscation. The source code is available at:
https://github.com/whatishope/BIDO/.

</details>


### [17] [Rethinking Tamper-Evident Logging: A High-Performance, Co-Designed Auditing System](https://arxiv.org/abs/2509.03821)
*Rui Zhao,Muhammad Shoaib,Viet Tung Hoang,Wajih Ul Hassan*

Main category: cs.CR

TL;DR: Nitro是一个高性能防篡改审计日志系统，使用eBPF技术避免内核重编译，提供细粒度篡改检测，性能比现有系统提升10-25倍，数据丢失率接近零


<details>
  <summary>Details</summary>
Motivation: 现有防篡改日志系统在高负载下性能开销大、数据丢失严重，只能提供粗粒度检测，且需要重新编译内核代码

Method: 使用eBPF技术避免内核重编译，密码学设计与日志前后处理协同优化，提供形式化安全框架，开发Nitro-R变体引入内核日志缩减技术

Result: 在高压力条件下性能提升10-25倍，真实场景下提升2-10倍，数据丢失率接近零

Conclusion: Nitro系统成功解决了现有防篡改日志系统的性能和数据丢失问题，通过eBPF和系统级优化实现了高性能的细粒度篡改检测

Abstract: Existing tamper-evident logging systems suffer from high overhead and severe
data loss in high-load settings, yet only provide coarse-grained tamper
detection. Moreover, installing such systems requires recompiling kernel code.
To address these challenges, we present Nitro, a high-performance,
tamper-evident audit logging system that supports fine-grained detection of log
tampering. Even better, our system avoids kernel recompilation by using the
eBPF technology. To formally justify the security of Nitro, we provide a new
definitional framework for logging systems, and give a practical cryptographic
construction meeting this new goal. Unlike prior work that focus only on the
cryptographic processing, we codesign the cryptographic part with the pre- and
post-processing of the logs to exploit all system-level optimizations. Our
evaluations demonstrate Nitro's superior performance, achieving 10X-25X
improvements in high-stress conditions and 2X-10X in real-world scenarios while
maintaining near-zero data loss. We also provide an advanced variant, Nitro-R
that introduces in-kernel log reduction techniques to reduce runtime overhead
even further.

</details>


### [18] [KGBERT4Eth: A Feature-Complete Transformer Powered by Knowledge Graph for Multi-Task Ethereum Fraud Detection](https://arxiv.org/abs/2509.03860)
*Yifan Jia,Ye Tian,Liguo Zhang,Yanbin Wang,Jianguo Sun,Liangliang Song*

Main category: cs.CR

TL;DR: KGBERT4Eth是一个融合交易语义提取和知识图谱的预训练编码器，通过联合优化两个组件来生成特征完整的嵌入表示，在钓鱼账户检测和去匿名化任务中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 以太坊生态快速扩张和交易匿名性导致恶意活动激增，现有检测机制分为专家定义特征、图嵌入和序列交易模式三种技术路线，但缺乏跨范式集成机制，迫使实践者需要在不同特征之间做出取舍

Method: 提出KGBERT4Eth，包含两个关键组件：(1)交易语义提取器，训练增强的交易语言模型学习上下文语义表示；(2)交易知识图谱，将专家领域知识融入图节点嵌入。通过联合优化预训练目标融合互补特征，设计偏置掩码预测任务关注异常交易，使用链接预测学习潜在交易关系，并通过掩码不变注意力协调模块确保稳定信息交换

Result: 在钓鱼账户检测和去匿名化任务中显著优于最先进基线方法，在三个钓鱼检测基准上F1分数绝对提升8-16%，在四个去匿名化数据集上提升6-26%

Conclusion: KGBERT4Eth成功解决了现有检测机制缺乏跨范式集成的问题，通过融合语义表示和知识图谱特征，为以太坊恶意活动检测提供了特征完整的解决方案

Abstract: Ethereum's rapid ecosystem expansion and transaction anonymity have triggered
a surge in malicious activity. Detection mechanisms currently bifurcate into
three technical strands: expert-defined features, graph embeddings, and
sequential transaction patterns, collectively spanning the complete feature
sets of Ethereum's native data layer. Yet the absence of cross-paradigm
integration mechanisms forces practitioners to choose between sacrificing
sequential context awareness, structured fund-flow patterns, or human-curated
feature insights in their solutions. To bridge this gap, we propose KGBERT4Eth,
a feature-complete pre-training encoder that synergistically combines two key
components: (1) a Transaction Semantic Extractor, where we train an enhanced
Transaction Language Model (TLM) to learn contextual semantic representations
from conceptualized transaction records, and (2) a Transaction Knowledge Graph
(TKG) that incorporates expert-curated domain knowledge into graph node
embeddings to capture fund flow patterns and human-curated feature insights. We
jointly optimize pre-training objectives for both components to fuse these
complementary features, generating feature-complete embeddings. To emphasize
rare anomalous transactions, we design a biased masking prediction task for TLM
to focus on statistical outliers, while the Transaction TKG employs link
prediction to learn latent transaction relationships and aggregate knowledge.
Furthermore, we propose a mask-invariant attention coordination module to
ensure stable dynamic information exchange between TLM and TKG during
pre-training. KGBERT4Eth significantly outperforms state-of-the-art baselines
in both phishing account detection and de-anonymization tasks, achieving
absolute F1-score improvements of 8-16% on three phishing detection benchmarks
and 6-26% on four de-anonymization datasets.

</details>


### [19] [ShieldMMU: Detecting and Defending against Controlled-Channel Attacks in Shielding Memory System](https://arxiv.org/abs/2509.03879)
*Gang Liu,Ningjie Li,Cen Chen*

Main category: cs.CR

TL;DR: ShieldMMU是一个针对Intel SGX侧信道攻击的防御方案，通过DD-Tree保护页表项完整性，检测和恢复被攻击的PTE，平衡兼容性、性能和可用性。


<details>
  <summary>Details</summary>
Motivation: Intel SGX和虚拟机监控程序虽然能隔离非特权程序，但侧信道攻击仍然威胁其安全，恶意操作系统可通过操纵PTE存在位来窃取内存访问痕迹。现有防御方案要么专注于检测，要么依赖不实用的解决方案。

Method: 采用受Merkle Tree启发的防御树（DD-Tree）来保护PTE完整性，能够检测、定位和恢复被攻击的PTE。系统识别MMU页表查找事件和侧信道攻击，及时恢复PTE参数以防止页面错误陷阱。

Result: 实验证实ShieldMMU具有增强的安全性和可接受的延迟性能。

Conclusion: ShieldMMU提供了一个全面的解决方案，有效缓解受控信道攻击，在兼容性、性能和可用性之间取得了良好平衡。

Abstract: Intel SGX and hypervisors isolate non-privileged programs from other
software, ensuring confidentiality and integrity. However, side-channel attacks
continue to threaten Intel SGX's security, enabling malicious OS to manipulate
PTE present bits, induce page faults, and steal memory access traces. Despite
extensive research, existing defenses focus on detection or rely on impractical
solutions. This paper presents ShieldMMU, a comprehensive solution for
mitigating controlled channel attacks, balancing compatibility, performance,
and usability. Leveraging a Merkle Tree-inspired Defense Tree (DD-Tree),
ShieldMMU protects PTE integrity by detecting, locating, and restoring attacked
PTEs. It identifies MMU page table lookup events and side-channel attacks,
promptly restoring PTE parameters to prevent page fault traps and ensure secure
non-privileged application operation within SGX. Our experiments confirm
ShieldMMU's enhanced security and acceptable latency performance.

</details>


### [20] [LMAE4Eth: Generalizable and Robust Ethereum Fraud Detection by Exploring Transaction Semantics and Masked Graph Embedding](https://arxiv.org/abs/2509.03939)
*Yifan Jia,Yanbin Wang,Jianguo Sun,Ye Tian,Peng Qian*

Main category: cs.CR

TL;DR: LMAE4Eth是一个多视图学习框架，融合交易语义、掩码图嵌入和专家知识，用于以太坊欺诈检测，在F1分数上比最佳基线方法提升超过10%。


<details>
  <summary>Details</summary>
Motivation: 当前以太坊欺诈检测方法存在三个主要问题：1）依赖上下文无关的数值交易序列，无法捕捉账户交易语义；2）交易记录同质性高，难以学习区分性账户嵌入；3）现有自监督图学习方法主要关注图重构，在节点级任务上表现不佳且可扩展性差。

Method: 提出LMAE4Eth框架：1）TxCLM模型将数值交易记录转换为语言表示；2）MAGAE使用生成式自监督学习重构账户节点特征；3）集成层邻居采样提高可扩展性；4）使用交叉注意力融合网络统一TxCLM和MAGAE的嵌入。

Result: 在三个数据集上与21个基线方法对比，实验结果表明该方法在两个数据集上的F1分数比最佳基线方法高出10%以上。

Conclusion: LMAE4Eth通过融合多视图学习和自监督技术，有效解决了以太坊欺诈检测中的语义捕捉、表示学习和可扩展性问题，显著提升了检测性能。

Abstract: Current Ethereum fraud detection methods rely on context-independent,
numerical transaction sequences, failing to capture semantic of account
transactions. Furthermore, the pervasive homogeneity in Ethereum transaction
records renders it challenging to learn discriminative account embeddings.
Moreover, current self-supervised graph learning methods primarily learn node
representations through graph reconstruction, resulting in suboptimal
performance for node-level tasks like fraud account detection, while these
methods also encounter scalability challenges. To tackle these challenges, we
propose LMAE4Eth, a multi-view learning framework that fuses transaction
semantics, masked graph embedding, and expert knowledge. We first propose a
transaction-token contrastive language model (TxCLM) that transforms
context-independent numerical transaction records into logically cohesive
linguistic representations. To clearly characterize the semantic differences
between accounts, we also use a token-aware contrastive learning pre-training
objective together with the masked transaction model pre-training objective,
learns high-expressive account representations. We then propose a masked
account graph autoencoder (MAGAE) using generative self-supervised learning,
which achieves superior node-level account detection by focusing on
reconstructing account node features. To enable MAGAE to scale for large-scale
training, we propose to integrate layer-neighbor sampling into the graph, which
reduces the number of sampled vertices by several times without compromising
training quality. Finally, using a cross-attention fusion network, we unify the
embeddings of TxCLM and MAGAE to leverage the benefits of both. We evaluate our
method against 21 baseline approaches on three datasets. Experimental results
show that our method outperforms the best baseline by over 10% in F1-score on
two of the datasets.

</details>


### [21] [NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models](https://arxiv.org/abs/2509.03985)
*Chuhan Zhang,Ye Zhang,Bowen Shi,Yuyou Gan,Tianyu Du,Shouling Ji,Dazhan Deng,Yingcai Wu*

Main category: cs.CR

TL;DR: NeuroBreak是一个自上而下的越狱分析系统，通过神经元层面的安全机制分析来识别和缓解大语言模型的安全漏洞，提供对模型决策过程和关键神经元的深入分析。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在部署时需要安全对齐以防止非法和不道德输出，但越狱攻击技术的不断发展给LLM的安全防御带来压力。由于LLM参数庞大、结构复杂，从内部视角分析安全弱点具有挑战性。

Method: 设计NeuroBreak系统，通过分层表示探测分析提供模型生成步骤中决策过程的新视角，支持从语义和功能角度分析关键神经元，并与AI安全领域专家合作确定系统需求。

Result: 通过定量评估和案例研究验证了系统的有效性，为开发下一代防御策略提供了机制性见解。

Conclusion: NeuroBreak系统能够深入分析神经元层面的安全机制，帮助理解和缓解LLM的安全漏洞，为对抗不断演变的越狱攻击提供重要工具和见解。

Abstract: In deployment and application, large language models (LLMs) typically undergo
safety alignment to prevent illegal and unethical outputs. However, the
continuous advancement of jailbreak attack techniques, designed to bypass
safety mechanisms with adversarial prompts, has placed increasing pressure on
the security defenses of LLMs. Strengthening resistance to jailbreak attacks
requires an in-depth understanding of the security mechanisms and
vulnerabilities of LLMs. However, the vast number of parameters and complex
structure of LLMs make analyzing security weaknesses from an internal
perspective a challenging task. This paper presents NeuroBreak, a top-down
jailbreak analysis system designed to analyze neuron-level safety mechanisms
and mitigate vulnerabilities. We carefully design system requirements through
collaboration with three experts in the field of AI security. The system
provides a comprehensive analysis of various jailbreak attack methods. By
incorporating layer-wise representation probing analysis, NeuroBreak offers a
novel perspective on the model's decision-making process throughout its
generation steps. Furthermore, the system supports the analysis of critical
neurons from both semantic and functional perspectives, facilitating a deeper
exploration of security mechanisms. We conduct quantitative evaluations and
case studies to verify the effectiveness of our system, offering mechanistic
insights for developing next-generation defense strategies against evolving
jailbreak attacks.

</details>


### [22] [Systematic Timing Leakage Analysis of NIST PQDSS Candidates: Tooling and Lessons Learned](https://arxiv.org/abs/2509.04010)
*Olivier Adjonyo,Sebastien Bardin,Emanuele Bellini,Gilbert Ndollane Dione,Mahmudul Faisal Al Ameen,Robert Merget,Frederic Recoules,Yanis Sellami*

Main category: cs.CR

TL;DR: 这篇论文为NIST PQDSS标准化过程开发了一个自动化工具链，用于验证加密算法的常数时间实现和检测侦测时间流漏，并在NIST PQDSS第1和第2轮实现中发现了26个安全问题。


<details>
  <summary>Details</summary>
Motivation: 确保PQDSS标准化过程中加密原语无时间和缓存侦测漏洞，需要常数时间实现。手动分析二进制代码极其困难，而现有自动化工具存在易用性问题，因此需要开发更实用的工具链。

Method: 开发了一个自动化工具链，集成了TIMECOP和Binsec/Rel2用于二进制层面的常数时间政策验证，以及dudect和RTLF用于通过执行时间统计分析检测侦测漏洞。该工具链自动化了配置、执行和结析过程。

Result: 在NIST PQDSS第1和第2轮实现中识别出26个安全问题，其中5个已经修复。评估了各种工具的优缺点和效果。

Conclusion: 该自动化工具链能够有效地验证常数时间实现和检测侦测漏洞，为PQDSS标准化过程提供了重要技术支持，并在实际应用中证明了其实用性和效果。

Abstract: The PQDSS standardization process requires cryptographic primitives to be
free from vulnerabilities, including timing and cache side-channels. Resistance
to timing leakage is therefore an essential property, and achieving this
typically relies on software implementations that follow constant-time
principles. Moreover, ensuring that all implementations are constant-time is
crucial for fair performance comparisons, as secure implementations often incur
additional overhead. Such analysis also helps identify scheme proposals that
are inherently difficult to implement in constant time. Because constant-time
properties can be broken during compilation, it is often necessary to analyze
the compiled binary directly. Since manual binary analysis is extremely
challenging, automated analysis becomes highly important. Although several
tools exist to assist with such analysis, they often have usability limitations
and are difficult to set up correctly. To support the developers besides the
NIST committee in verifying candidates, we developed a toolchain that automates
configuration, execution, and result analysis for several widely used
constant-time analysis tools. We selected TIMECOP and Binsec/Rel2 to verify
constant-time policy compliance at the binary level, and dudect and RTLF to
detect side-channel vulnerabilities through statistical analysis of execution
time behavior. We demonstrate its effectiveness and practicability by
evaluating the NIST PQDSS round 1 and round 2 implementations. We reported 26
issues in total to the respective developers, and 5 of them have already been
fixed. We also discuss our different findings, as well as the benefits of
shortcomings of the different tools.

</details>


### [23] [Error Detection Schemes for Barrett Reduction of CT-BU on FPGA in Post Quantum Cryptography](https://arxiv.org/abs/2509.04070)
*Paresh Baidya,Rourab Paul,Vikas Srivastava,Sumit Kumar Debnath*

Main category: cs.CR

TL;DR: 这篇论文提出了三种高效轻量效的故障检测方法（RESWO、RENO、RESO），用于防范Kyber等后醻子加密算法中Barrett约化模块的故意故障注入攻击。RESWO方法在保持高故障检测效率的同时减少了延迟。


<details>
  <summary>Details</summary>
Motivation: 后醻子加密算法（如Kyber）的硬件加速器容易受到故意故障注入攻击，可能泄露敏感信息。需要有效的故障检测方法来保护实现的可靠性。

Method: 提出了三种重计算基于的故障检测方法：RESWO（交换操作数重计算）、RENO（取反操作数重计算）和RESO（位移操作数重计算）。这些方法应用于Kyber算法中的Barrett约化模块。

Result: 三种方法的故障检测效率都近似100%。RESWO消耗的逸出资源与RENO和RESO相似，但延迟更小。

Conclusion: 提出的RESWO方法在保持高故障检测能力的同时，体现了更优的性能表现，适用于后醻子加密算法硬件实现的安全保护。

Abstract: A fault can occur naturally or intentionally. However, intentionally
injecting faults into hardware accelerators of Post-Quantum Cryptographic (PQC)
algorithms may leak sensitive information. This intentional fault injection in
side-channel attacks compromises the reliability of PQC implementations. The
recently NIST-standardized key encapsulation mechanism (KEM), Kyber may also
leak information at the hardware implementation level. This work proposes three
efficient and lightweight recomputation-based fault detection methods for
Barrett Reduction in the Cooley-Tukey Butterfly Unit (CT-BU) of Kyber on a
Field Programmable Gate Array (FPGA). The CT-BU and Barrett Reduction are
fundamental components in structured lattice-based PQC algorithms, including
Kyber, NTRU, Falcon, CRYSTALS-Dilithium, etc. This paper introduces a new
algorithm, Recomputation with Swapped Operand (RESWO), for fault detection.
While Recomputation with Negated Operand (RENO) and Recomputation with Shifted
Operand (RESO) are existing methods used in other PQC hardware algorithms. To
the best of our knowledge, RENO and RESO have never been used in Barrett
Reduction before. The proposed RESWO method consumes a similar number of slices
compared to RENO and RESO. However, RESWO shows lesser delay compared to both
RENO and RESO. The fault detection efficiency of RESWO, RENO, and RESO is
nearly 100%.

</details>


### [24] [ICSLure: A Very High Interaction Honeynet for PLC-based Industrial Control Systems](https://arxiv.org/abs/2509.04080)
*Francesco Aurelio Pironti,Angelo Furfaro,Francesco Blefari,Carmelo Felicetti,Matteo Lupinacci,Francesco Romeo*

Main category: cs.CR

TL;DR: 提出了ICSLure模块化蜜网框架，通过整合物理PLC和虚拟化网络组件来模拟真实的工业控制系统环境，提高威胁数据收集质量和分析能力


<details>
  <summary>Details</summary>
Motivation: 工业控制系统安全至关重要，IIoT技术扩展了功能但增加了攻击面，传统ICS蜜罐缺乏真实性难以吸引复杂攻击者

Method: 设计模块化蜜网框架，集成物理PLC与实时数据源通过工业协议交互，包含虚拟化网络组件和全面监控能力

Result: 实现了真实工业工厂的高保真模拟，显著提升了威胁数据收集质量，支持对ICS特定攻击策略的高级分析

Conclusion: ICSLure框架提供了高交互性环境，有助于开发更有效的检测和缓解技术，提升工业控制系统安全防护能力

Abstract: The security of Industrial Control Systems (ICSs) is critical to ensuring the
safety of industrial processes and personnel. The rapid adoption of Industrial
Internet of Things (IIoT) technologies has expanded system functionality but
also increased the attack surface, exposing ICSs to a growing range of cyber
threats. Honeypots provide a means to detect and analyze such threats by
emulating target systems and capturing attacker behavior. However, traditional
ICS honeypots, often limited to software-based simulations of a single
Programmable Logic Controller (PLC), lack the realism required to engage
sophisticated adversaries. In this work, we introduce a modular honeynet
framework named ICSLure. The framework has been designed to emulate realistic
ICS environments. Our approach integrates physical PLCs interacting with live
data sources via industrial protocols such as Modbus and Profinet RTU, along
with virtualized network components including routers, switches, and Remote
Terminal Units (RTUs). The system incorporates comprehensive monitoring
capabilities to collect detailed logs of attacker interactions. We demonstrate
that our framework enables coherent and high-fidelity emulation of real-world
industrial plants. This high-interaction environment significantly enhances the
quality of threat data collected and supports advanced analysis of ICS-specific
attack strategies, contributing to more effective detection and mitigation
techniques.

</details>


### [25] [Revisiting Third-Party Library Detection: A Ground Truth Dataset and Its Implications Across Security Tasks](https://arxiv.org/abs/2509.04091)
*Jintao Gu,Haolang Lu,Guoshun Nan,Yihan Lin,Kun Wang,Yuchun Guo,Yigui Cao,Yang Liu*

Main category: cs.CR

TL;DR: 首个大规模Android第三方库检测工具实证研究，发现现有工具在R8优化、版本区分、性能等方面存在显著缺陷


<details>
  <summary>Details</summary>
Motivation: 虽然有许多Android第三方库检测工具，但它们在实际环境中的效果仍不明确，需要系统性评估

Method: 使用新的精确版本标注真实数据集，对10种最先进的TPL检测技术在6000+应用上进行大规模实证研究

Result: 发现工具对R8优化敏感、版本区分能力弱、库匹配不准、相似度阈值难以通用、大规模运行时间/内存成本高

Conclusion: 研究不仅评估了检测工具，还分析了TPL对漏洞分析、恶意软件检测等安全任务的影响，为安全分析的未来改进提供了具体见解

Abstract: Accurate detection of third-party libraries (TPLs) is fundamental to Android
security, supporting vulnerability tracking, malware detection, and supply
chain auditing. Despite many proposed tools, their real-world effectiveness
remains unclear.We present the first large-scale empirical study of ten
state-of-the-art TPL detection techniques across over 6,000 apps, enabled by a
new ground truth dataset with precise version-level annotations for both remote
and local dependencies.Our evaluation exposes tool fragility to R8-era
transformations, weak version discrimination, inaccurate correspondence of
candidate libraries, difficulty in generalizing similarity thresholds, and
prohibitive runtime/memory overheads at scale.Beyond tool assessment, we
further analyze how TPLs shape downstream tasks, including vulnerability
analysis, malware detection, secret leakage assessment, and LLM-based
evaluation. From this perspective, our study provides concrete insights into
how TPL characteristics affect these tasks and informs future improvements in
security analysis.

</details>


### [26] [ECCFROG522PP: An Enhanced 522-bit Weierstrass Elliptic Curve](https://arxiv.org/abs/2509.04097)
*Víctor Duarte Melo,William J. Buchanan*

Main category: cs.CR

TL;DR: ECCFROG522PP是一个522位素数域椭圆曲线，提供约260位经典安全性，通过BLAKE3确定性生成所有参数，具有完全可重现性和可验证性


<details>
  <summary>Details</summary>
Motivation: 满足对透明、可重现的256位安全级别椭圆曲线的需求，替代NIST P-521等现有高安全选项

Method: 使用BLAKE3哈希函数从固定公共种子确定性派生所有曲线参数，确保零隐藏选择，具有素数阶、验证扭曲、安全嵌入度等特性

Result: 成功设计了ECCFROG522PP曲线，提供与NIST P-521相当的安全性，但具有完全透明和可验证的特性

Conclusion: ECCFROG522PP不是要在原始速度上超越NIST P-521，而是在同等安全级别下最大化信任、可验证性和长期可审计性

Abstract: Whilst many key exchange and digital signature systems still rely on NIST
P-256 (secp256r1) and secp256k1, offering around 128-bit security, there is an
increasing demand for transparent and reproducible curves at the 256-bit
security level. Standard higher-security options include NIST P-521, Curve448,
and Brainpool-P512. This paper presents ECCFROG522PP ("Presunto Powered"), a
522-bit prime-field elliptic curve that delivers security in the same classical
approx 260-bit ballpark as NIST P-521, but with a fundamentally different
design philosophy. All of the curve parameters are deterministically derived
from a fixed public seed via BLAKE3, with zero hidden choices. The curve has
prime order (cofactor = 1), a verified twist with a proven approx 505-bit prime
factor, safe embedding degree (greater than or equal to 14), and passes
anti-MOV checks up to k less than or equal to 200 and CM discriminant sanity up
to 100k. Unlike prior opaque or ad-hoc constructions, ECCFROG522PP is fully
reproducible: anyone can regenerate and verify it byte-for-byte using the
published scripts. The intent is not to outperform NIST P-521 in raw speed, but
to maximise trust, verifiability, and long-term auditability in a practical
curve of equivalent security level

</details>


### [27] [KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and Runtime Logs Analysis](https://arxiv.org/abs/2509.04191)
*Omri Sgan Cohen,Ehud Malul,Yair Meidan,Dudu Mimran,Yuval Elovici,Asaf Shabtai*

Main category: cs.CR

TL;DR: KubeGuard是一个基于运行时日志的Kubernetes安全推荐框架，使用大语言模型分析配置清单和运行时日志，通过资源创建和资源优化两个互补任务来减少过度权限配置，实现最小权限原则。


<details>
  <summary>Details</summary>
Motivation: Kubernetes的广泛采用带来了严重的安全挑战，如错误配置和过度权限设置，可能导致未授权访问和权限提升。现有解决方案主要关注检测错误配置，而缺乏针对过度权限配置的缓解措施。

Method: KubeGuard利用大语言模型（LLMs）分析配置清单和运行时日志，采用模块化提示链工作流程，通过资源创建（为新资源创建最小权限配置）和资源优化（优化现有清单减少攻击面）两个任务来加强K8s环境安全。

Result: 评估显示KubeGuard能有效生成和优化Roles、NetworkPolicies和Deployments的K8s清单，使用专有和开源LLMs均获得高精度、召回率和F1分数，证明其实际应用价值。

Conclusion: KubeGuard是一个实用的框架，能够将运行时可观测性转化为可操作的最小权限配置指导，帮助开发者和运维人员通过审查和采纳推荐配置来增强集群安全性。

Abstract: The widespread adoption of Kubernetes (K8s) for orchestrating cloud-native
applications has introduced significant security challenges, such as
misconfigured resources and overly permissive configurations. Failing to
address these issues can result in unauthorized access, privilege escalation,
and lateral movement within clusters. Most existing K8s security solutions
focus on detecting misconfigurations, typically through static analysis or
anomaly detection. In contrast, this paper presents KubeGuard, a novel runtime
log-driven recommender framework aimed at mitigating risks by addressing overly
permissive configurations. KubeGuard is designed to harden K8s environments
through two complementary tasks: Resource Creation and Resource Refinement. It
leverages large language models (LLMs) to analyze manifests and runtime logs
reflecting actual system behavior, using modular prompt-chaining workflows.
This approach enables KubeGuard to create least-privilege configurations for
new resources and refine existing manifests to reduce the attack surface.
KubeGuard's output manifests are presented as recommendations that users (e.g.,
developers and operators) can review and adopt to enhance cluster security. Our
evaluation demonstrates that KubeGuard effectively generates and refines K8s
manifests for Roles, NetworkPolicies, and Deployments, leveraging both
proprietary and open-source LLMs. The high precision, recall, and F1-scores
affirm KubeGuard's practicality as a framework that translates runtime
observability into actionable, least-privilege configuration guidance.

</details>


### [28] [An Automated, Scalable Machine Learning Model Inversion Assessment Pipeline](https://arxiv.org/abs/2509.04214)
*Tyler Shumaker,Jessica Carpenter,David Saranchak,Nathaniel D. Bastian*

Main category: cs.CR

TL;DR: 这篇论文提出了一种新的自动化开发测试评估(DT&E)工具，用于量化机器学习模型反向工程攻击(MIAs)导致的数据隐私风险。该工具结合视觉语言模型(VLMs)来提高效果和可扩展性，并引入四个风险维度来量化隐私损失。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在军事应用中存在隐私攻击风险，尤其是模型反向工程攻击可能泄漏训练数据。目前缺乏有效的自动化工具来量化这种风险，而且人工评估主观难以扩展。

Method: 设计了一种新的DT&E流水线，结合了模型反向技术和视觉语言模型(VLMs)，配置为零样本分类和图像描述。引入四个对抗性风险维度来量化隐私损失。

Result: 在计算机视觉领域的图像分类任务中，使用多种最新的MIA技术和VLMs进行了效果验证，证明了该流水线的有效性。

Conclusion: 该创新流水线通过提高效果和可扩展性，扩展了当前模型反向DT&E的能力，能够以自动化方式进行隐私损失分析。

Abstract: Machine learning (ML) models have the potential to transform military
battlefields, presenting a large external pressure to rapidly incorporate them
into operational settings. However, it is well-established that these ML models
are vulnerable to a number of adversarial attacks throughout the model
deployment pipeline that threaten to negate battlefield advantage. One broad
category is privacy attacks (such as model inversion) where an adversary can
reverse engineer information from the model, such as the sensitive data used in
its training. The ability to quantify the risk of model inversion attacks
(MIAs) is not well studied, and there is a lack of automated developmental test
and evaluation (DT&E) tools and metrics to quantify the effectiveness of
privacy loss of the MIA. The current DT&E process is difficult because ML model
inversions can be hard for a human to interpret, subjective when they are
interpretable, and difficult to quantify in terms of inversion quality.
Additionally, scaling the DT&E process is challenging due to many ML model
architectures and data modalities that need to be assessed. In this work, we
present a novel DT&E tool that quantifies the risk of data privacy loss from
MIAs and introduces four adversarial risk dimensions to quantify privacy loss.
Our DT&E pipeline combines inversion with vision language models (VLMs) to
improve effectiveness while enabling scalable analysis. We demonstrate
effectiveness using multiple MIA techniques and VLMs configured for zero-shot
classification and image captioning. We benchmark the pipeline using several
state-of-the-art MIAs in the computer vision domain with an image
classification task that is typical in military applications. In general, our
innovative pipeline extends the current model inversion DT&E capabilities by
improving the effectiveness and scalability of the privacy loss analysis in an
automated fashion.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [29] [PG-Agent: An Agent Powered by Page Graph](https://arxiv.org/abs/2509.03536)
*Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang*

Main category: cs.AI

TL;DR: 该论文提出了一种将GUI操作序列转换为页面图的方法，并基于此构建了PG-Agent多智能体框架，通过检索增强生成技术提升GUI智能体在新场景中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体使用顺序操作序列作为先验知识，无法捕捉页面间的复杂转换关系，限制了智能体对GUI环境的深度感知和新场景的泛化能力。

Method: 设计自动化流水线将顺序操作片段转换为页面图，显式建模页面间的图结构关系；引入RAG技术从页面图中检索可靠的GUI感知指南；提出PG-Agent多智能体框架，结合任务分解策略注入感知指南。

Result: 在各种基准测试上的大量实验证明了PG-Agent的有效性，即使在页面图构建的片段有限的情况下也能取得良好效果。

Conclusion: 通过页面图建模和RAG技术，PG-Agent能够更好地理解GUI环境结构，显著提升在未见场景中的泛化性能，为GUI智能体发展提供了新思路。

Abstract: Graphical User Interface (GUI) agents possess significant commercial and
social value, and GUI agents powered by advanced multimodal large language
models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI
agents usually utilize sequential episodes of multi-step operations across
pages as the prior GUI knowledge, which fails to capture the complex transition
relationship between pages, making it challenging for the agents to deeply
perceive the GUI environment and generalize to new scenarios. Therefore, we
design an automated pipeline to transform the sequential episodes into page
graphs, which explicitly model the graph structure of the pages that are
naturally connected by actions. To fully utilize the page graphs, we further
introduce Retrieval-Augmented Generation (RAG) technology to effectively
retrieve reliable perception guidelines of GUI from them, and a tailored
multi-agent framework PG-Agent with task decomposition strategy is proposed to
be injected with the guidelines so that it can generalize to unseen scenarios.
Extensive experiments on various benchmarks demonstrate the effectiveness of
PG-Agent, even with limited episodes for page graph construction.

</details>


### [30] [Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models](https://arxiv.org/abs/2509.03548)
*João P. Arroyo,João G. Rodrigues,Daniel Lawand,Denis D. Mauá,Junkyu Lee,Radu Marinescu,Alex Gray,Eduardo R. Laurentino,Fabio G. Cozman*

Main category: cs.AI

TL;DR: 本文研究准马尔可夫因果模型中部分可识别查询的概率边界计算问题，提出了基于列生成技术的新算法，通过辅助线性整数程序序列有效计算概率边界。


<details>
  <summary>Details</summary>
Motivation: 在准马尔可夫因果模型中，当外生变量未完全指定时，无法精确计算感兴趣的概率值，需要研究如何计算紧概率边界。

Method: 提出新算法利用内生变量的输入概率简化多线性规划构造；对单干预场景应用列生成技术，通过线性整数程序序列计算概率边界。

Result: 实验表明列生成技术优于现有方法，证明了外生变量多项式基数表示的可能性。

Conclusion: 列生成技术为准马尔可夫因果模型中的概率边界计算提供了有效解决方案，显著提升了计算效率。

Abstract: We investigate partially identifiable queries in a class of causal models. We
focus on acyclic Structural Causal Models that are quasi-Markovian (that is,
each endogenous variable is connected with at most one exogenous confounder).
We look into scenarios where endogenous variables are observed (and a
distribution over them is known), while exogenous variables are not fully
specified. This leads to a representation that is in essence a Bayesian network
where the distribution of root variables is not uniquely determined. In such
circumstances, it may not be possible to precisely compute a probability value
of interest. We thus study the computation of tight probability bounds, a
problem that has been solved by multilinear programming in general, and by
linear programming when a single confounded component is intervened upon. We
present a new algorithm to simplify the construction of such programs by
exploiting input probabilities over endogenous variables. For scenarios with a
single intervention, we apply column generation to compute a probability bound
through a sequence of auxiliary linear integer programs, thus showing that a
representation with polynomial cardinality for exogenous variables is possible.
Experiments show column generation techniques to be superior to existing
methods.

</details>


### [31] [Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method](https://arxiv.org/abs/2509.03550)
*Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang*

Main category: cs.AI

TL;DR: 本文提出Diffusion-AC框架，将扩散概率模型应用于空中交通冲突检测与解决，通过多模态决策能力显著提升安全性和成功率


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法存在"单模态偏差"，在复杂动态约束下缺乏决策灵活性，导致"决策死锁"问题

Method: 提出Diffusion-AC框架，将策略建模为价值函数引导的反向去噪过程，生成丰富的高质量多模态动作分布，并采用密度渐进安全课程(DPSC)训练机制

Result: 在最具挑战性的高密度场景中，成功率高达94.1%，近距空中碰撞发生率比次优基线降低约59%

Conclusion: 扩散概率模型为安全关键任务中的冲突解决提供了新的有效途径，多模态决策能力显著增强了系统的安全边际和灵活性

Abstract: In the context of continuously rising global air traffic, efficient and safe
Conflict Detection and Resolution (CD&R) is paramount for air traffic
management. Although Deep Reinforcement Learning (DRL) offers a promising
pathway for CD&R automation, existing approaches commonly suffer from a
"unimodal bias" in their policies. This leads to a critical lack of
decision-making flexibility when confronted with complex and dynamic
constraints, often resulting in "decision deadlocks." To overcome this
limitation, this paper pioneers the integration of diffusion probabilistic
models into the safety-critical task of CD&R, proposing a novel autonomous
conflict resolution framework named Diffusion-AC. Diverging from conventional
methods that converge to a single optimal solution, our framework models its
policy as a reverse denoising process guided by a value function, enabling it
to generate a rich, high-quality, and multimodal action distribution. This core
architecture is complemented by a Density-Progressive Safety Curriculum (DPSC),
a training mechanism that ensures stable and efficient learning as the agent
progresses from sparse to high-density traffic environments. Extensive
simulation experiments demonstrate that the proposed method significantly
outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the
most challenging high-density scenarios, Diffusion-AC not only maintains a high
success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions
(NMACs) by approximately 59% compared to the next-best-performing baseline,
significantly enhancing the system's safety margin. This performance leap stems
from its unique multimodal decision-making capability, which allows the agent
to flexibly switch to effective alternative maneuvers.

</details>


### [32] [Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents](https://arxiv.org/abs/2509.03581)
*Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel*

Main category: cs.AI

TL;DR: 提出动态规划框架，让LLM智能体灵活决定何时进行规划，通过两阶段训练（监督微调+强化学习）在长时程任务中实现更高效和可控的性能


<details>
  <summary>Details</summary>
Motivation: 现有方法如ReAct要求LLM在每个动作前都进行规划，计算成本高且在长时程任务中性能下降，而完全不规划又限制性能提升

Method: 两阶段训练：1）在多样化合成数据上进行监督微调，为动态规划做准备；2）在长时程环境中使用强化学习精炼该能力

Result: 在Crafter环境中，动态规划智能体样本效率更高，能持续实现更复杂的目标，且可被人编写的规划有效引导，超越独立能力

Conclusion: 这是首个探索训练LLM智能体进行动态测试时计算分配的研究，为更高效、自适应和可控的智能体系统开辟了道路

Abstract: Training large language models (LLMs) to reason via reinforcement learning
(RL) significantly improves their problem-solving capabilities. In agentic
settings, existing methods like ReAct prompt LLMs to explicitly plan before
every action; however, we demonstrate that always planning is computationally
expensive and degrades performance on long-horizon tasks, while never planning
further limits performance. To address this, we introduce a conceptual
framework formalizing dynamic planning for LLM agents, enabling them to
flexibly decide when to allocate test-time compute for planning. We propose a
simple two-stage training pipeline: (1) supervised fine-tuning on diverse
synthetic data to prime models for dynamic planning, and (2) RL to refine this
capability in long-horizon environments. Experiments on the Crafter environment
show that dynamic planning agents trained with this approach are more
sample-efficient and consistently achieve more complex objectives.
Additionally, we demonstrate that these agents can be effectively steered by
human-written plans, surpassing their independent capabilities. To our
knowledge, this work is the first to explore training LLM agents for dynamic
test-time compute allocation in sequential decision-making tasks, paving the
way for more efficient, adaptive, and controllable agentic systems.

</details>


### [33] [Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE](https://arxiv.org/abs/2509.03626)
*Zahra Zehtabi Sabeti Moghaddam,Zeinab Dehghani,Maneeha Rani,Koorosh Aslansefat,Bhupesh Kumar Mishra,Rameez Raja Kureshi,Dhavalkumar Thakker*

Main category: cs.AI

TL;DR: 提出了KG-SMILE框架，通过扰动分析和线性代理模型为Graph RAG提供token和组件级别的可解释性，提高生成AI的透明度和可信度


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型产生幻觉和不可验证声明的问题，特别是在医疗等敏感领域需要精确性的场景中，RAG方法虽然能提高准确性但仍缺乏透明度

Method: 开发了方法无关的基于扰动的框架，通过控制扰动、计算相似度和训练加权线性代理模型，识别图中对生成输出最有影响的实体和关系

Result: KG-SMILE能够产生稳定且与人类认知一致的解释，在保真度、忠实度、一致性、稳定性和准确性等指标上表现良好

Conclusion: KG-SMILE框架能够在保持模型有效性的同时提供可解释性，促进机器学习技术的透明度和信任度

Abstract: Generative AI, such as Large Language Models (LLMs), has achieved impressive
progress but still produces hallucinations and unverifiable claims, limiting
reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves
accuracy by grounding outputs in external knowledge, especially in domains like
healthcare, where precision is vital. However, RAG remains opaque and
essentially a black box, heavily dependent on data quality. We developed a
method-agnostic, perturbation-based framework that provides token and
component-level interoperability for Graph RAG using SMILE and named it as
Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing
similarities, and training weighted linear surrogates, KG-SMILE identifies the
graph entities and relations most influential to generated outputs, thereby
making RAG more transparent. We evaluate KG-SMILE using comprehensive
attribution metrics, including fidelity, faithfulness, consistency, stability,
and accuracy. Our findings show that KG-SMILE produces stable, human-aligned
explanations, demonstrating its capacity to balance model effectiveness with
interpretability and thereby fostering greater transparency and trust in
machine learning technologies.

</details>


### [34] [CausalARC: Abstract Reasoning with Causal World Models](https://arxiv.org/abs/2509.03636)
*Jacqueline Maasch,John Kalantari,Kia Khezeli*

Main category: cs.AI

TL;DR: CausalARC是一个用于AI推理的测试平台，专注于低数据和分布外场景，基于因果世界模型提供观测、干预和反事实反馈。


<details>
  <summary>Details</summary>
Motivation: 解决AI系统在有限数据和分布偏移下进行推理的适应性问题，需要一个能够系统评估推理能力的测试环境。

Method: 构建基于结构因果模型的因果世界模型，通过原则性数据增强提供观测、干预和反事实的少样本学习演示。

Result: 开发了CausalARC测试平台，并在四个语言模型评估场景中验证其有效性：抽象推理、反事实推理、程序合成和因果发现。

Conclusion: CausalARC为评估AI系统在复杂推理任务中的表现提供了系统化的测试框架，特别是在低数据和分布外场景下。

Abstract: Reasoning requires adaptation to novel problem settings under limited data
and distribution shift. This work introduces CausalARC: an experimental testbed
for AI reasoning in low-data and out-of-distribution regimes, modeled after the
Abstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is
sampled from a fully specified causal world model, formally expressed as a
structural causal model. Principled data augmentations provide observational,
interventional, and counterfactual feedback about the world model in the form
of few-shot, in-context learning demonstrations. As a proof-of-concept, we
illustrate the use of CausalARC for four language model evaluation settings:
(1) abstract reasoning with test-time training, (2) counterfactual reasoning
with in-context learning, (3) program synthesis, and (4) causal discovery with
logical reasoning.

</details>


### [35] [Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations](https://arxiv.org/abs/2509.03644)
*François Olivier,Zied Bouraoui*

Main category: cs.AI

TL;DR: 一种基于图像模式的神经符号系统Embodied-LM，通过将语言模型基于体验性认知结构来提升逻辑推理能力和可解释性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在逻辑推理方面存在错误，缺乏人类类似的健壮心智表征，需要基于体验性认知结构来改善

Method: 使用图像模式基于感知运动经验的重复模式，通过声明式空间推理在答案集编程中实现运算

Result: 证明语言模型可以被引导通过体验认知结构解释场景，这些结构可以形式化为可执行程序，并支持更有效的逻辑推理

Conclusion: 该系统为融合更复杂和动态表征的认知结构奠定了计算基础，虽然当前重点在空间原语

Abstract: Despite significant progress in natural language understanding, Large
Language Models (LLMs) remain error-prone when performing logical reasoning,
often lacking the robust mental representations that enable human-like
comprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that
grounds understanding and logical reasoning in schematic representations based
on image schemas-recurring patterns derived from sensorimotor experience that
structure human cognition. Our system operationalizes the spatial foundations
of these cognitive structures using declarative spatial reasoning within Answer
Set Programming. Through evaluation on logical deduction problems, we
demonstrate that LLMs can be guided to interpret scenarios through embodied
cognitive structures, that these structures can be formalized as executable
programs, and that the resulting representations support effective logical
reasoning with enhanced interpretability. While our current implementation
focuses on spatial primitives, it establishes the computational foundation for
incorporating more complex and dynamic representations.

</details>


### [36] [Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning](https://arxiv.org/abs/2509.03646)
*Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen*

Main category: cs.AI

TL;DR: 研究发现RL提升LLM推理能力的关键机制是层次化推理结构的涌现，揭示了从低级程序执行到高级战略规划的两阶段学习动态，并提出了HICRA算法来优化高层规划token的信用分配。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习能有效提升大语言模型的复杂推理能力，但其成功背后的机制仍然不明确，需要深入理解RL训练过程中的关键动态和瓶颈。

Method: 通过分析RL训练过程中的现象，发现了层次化推理结构的涌现模式，并提出了HIerarchy-Aware Credit Assignment (HICRA)算法，专注于优化高层规划token的信用分配。

Result: HICRA算法显著优于现有基线方法，验证了语义熵作为战略探索度量指标的优越性，表明关注战略瓶颈是解锁高级推理的关键。

Conclusion: RL提升LLM推理能力的核心机制在于层次化推理结构的涌现，通过针对性优化高层战略规划可以更有效地提升模型推理性能，语义熵是衡量战略探索的可靠指标。

Abstract: Reinforcement Learning (RL) has proven highly effective at enhancing the
complex reasoning abilities of Large Language Models (LLMs), yet underlying
mechanisms driving this success remain largely opaque. Our analysis reveals
that puzzling phenomena like ``aha moments", ``length-scaling'' and entropy
dynamics are not disparate occurrences but hallmarks of an emergent reasoning
hierarchy, akin to the separation of high-level strategic planning from
low-level procedural execution in human cognition. We uncover a compelling
two-phase dynamic: initially, a model is constrained by procedural correctness
and must improve its low-level skills. The learning bottleneck then decisively
shifts, with performance gains being driven by the exploration and mastery of
high-level strategic planning. This insight exposes a core inefficiency in
prevailing RL algorithms like GRPO, which apply optimization pressure
agnostically and dilute the learning signal across all tokens. To address this,
we propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that
concentrates optimization efforts on high-impact planning tokens. HICRA
significantly outperforms strong baselines, demonstrating that focusing on this
strategic bottleneck is key to unlocking advanced reasoning. Furthermore, we
validate semantic entropy as a superior compass for measuring strategic
exploration over misleading metrics such as token-level entropy.

</details>


### [37] [An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification](https://arxiv.org/abs/2509.03649)
*Davide Italo Serramazza,Nikos Papadeas,Zahraa Abdallah,Georgiana Ifrim*

Main category: cs.AI

TL;DR: 时间序列分类中的SHAP解释方法通过分段策略提高计算效率，等长度分段方法表现最佳，分段数量对解释质量影响更大。


<details>
  <summary>Details</summary>
Motivation: 解决SHAP在长时间序列上计算复杂度高的问题，探索最优的时间序列分段策略来提高解释效率和质量。

Method: 研究了8种不同的时间序列分段算法，使用InterpretTime和AUC Difference两种评估方法，在单复变量时间序列上进行实验。

Result: 发现分段数量对解释质量的影响更大于分段方法，等长度分段方法表现最好，新的归一化技术能提高归因质量。

Conclusion: 等长度分段是最优的SHAP解释策略，分段长度归一化技术能显著改善解释效果。

Abstract: Explainable AI (XAI) has become an increasingly important topic for
understanding and attributing the predictions made by complex Time Series
Classification (TSC) models. Among attribution methods, SHapley Additive
exPlanations (SHAP) is widely regarded as an excellent attribution method; but
its computational complexity, which scales exponentially with the number of
features, limits its practicality for long time series. To address this, recent
studies have shown that aggregating features via segmentation, to compute a
single attribution value for a group of consecutive time points, drastically
reduces SHAP running time. However, the choice of the optimal segmentation
strategy remains an open question. In this work, we investigated eight
different Time Series Segmentation algorithms to understand how segment
compositions affect the explanation quality. We evaluate these approaches using
two established XAI evaluation methodologies: InterpretTime and AUC Difference.
Through experiments on both Multivariate (MTS) and Univariate Time Series
(UTS), we find that the number of segments has a greater impact on explanation
quality than the specific segmentation method. Notably, equal-length
segmentation consistently outperforms most of the custom time series
segmentation algorithms. Furthermore, we introduce a novel attribution
normalisation technique that weights segments by their length and we show that
it consistently improves attribution quality.

</details>


### [38] [PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming](https://arxiv.org/abs/2509.03728)
*Wesley Hanwen Deng,Sunnie S. Y. Kim,Akshita Jha,Ken Holstein,Motahhare Eslami,Lauren Wilcox,Leon A Gatys*

Main category: cs.AI

TL;DR: 本文提出了PersonaTeaming方法，通过引入角色身份来增强自动化红队测试，在保持提示多样性的同时显著提高了攻击成功率


<details>
  <summary>Details</summary>
Motivation: 当前自动化红队测试方法忽视了测试者身份背景对风险发现的影响，需要将人类红队测试中的身份因素融入自动化方法中

Method: 开发了基于"红队专家"和"普通AI用户"角色的提示变异方法，以及动态角色生成算法，并提出了新的"变异距离"度量指标

Result: 实验显示PersonaTeaming相比最先进的RainbowPlus方法，攻击成功率提升高达144.1%，同时保持了提示多样性

Conclusion: 角色变异方法有效提升了自动化红队测试效果，为探索自动化与人工红队测试的互补性提供了新方向

Abstract: Recent developments in AI governance and safety research have called for
red-teaming methods that can effectively surface potential risks posed by AI
models. Many of these calls have emphasized how the identities and backgrounds
of red-teamers can shape their red-teaming strategies, and thus the kinds of
risks they are likely to uncover. While automated red-teaming approaches
promise to complement human red-teaming by enabling larger-scale exploration of
model behavior, current approaches do not consider the role of identity. As an
initial step towards incorporating people's background and identities in
automated red-teaming, we develop and evaluate a novel method, PersonaTeaming,
that introduces personas in the adversarial prompt generation process to
explore a wider spectrum of adversarial strategies. In particular, we first
introduce a methodology for mutating prompts based on either "red-teaming
expert" personas or "regular AI user" personas. We then develop a dynamic
persona-generating algorithm that automatically generates various persona types
adaptive to different seed prompts. In addition, we develop a set of new
metrics to explicitly measure the "mutation distance" to complement existing
diversity measurements of adversarial prompts. Our experiments show promising
improvements (up to 144.1%) in the attack success rates of adversarial prompts
through persona mutation, while maintaining prompt diversity, compared to
RainbowPlus, a state-of-the-art automated red-teaming method. We discuss the
strengths and limitations of different persona types and mutation methods,
shedding light on future opportunities to explore complementarities between
automated and human red-teaming approaches.

</details>


### [39] [The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs](https://arxiv.org/abs/2509.03730)
*Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez*

Main category: cs.AI

TL;DR: 本研究系统分析了大型语言模型的人格特征，发现指令对齐能稳定特质表达但自述特质无法可靠预测行为，人格注入对行为影响有限


<details>
  <summary>Details</summary>
Motivation: 理解LLMs是否表现出类似人类的人格特质模式，以及这些特质是否能预测行为，现有研究主要依赖简化的自报告和启发式提示，缺乏行为验证

Method: 从三个维度系统分析LLM人格：(1)训练阶段特质轮廓的动态演变；(2)自述特质在行为任务中的预测效度；(3)人格注入等干预措施对自报告和行为的影响

Result: 指令对齐（如RLHF、指令微调）显著稳定特质表达并增强特质相关性，但自述特质无法可靠预测行为，人格注入能引导自报告但行为影响有限或不一致

Conclusion: 研究挑战了关于LLM人格的假设，强调需要区分表面特质表达和行为一致性，在对齐和可解释性方面需要更深入的评估

Abstract: Personality traits have long been studied as predictors of human
behavior.Recent advances in Large Language Models (LLMs) suggest similar
patterns may emerge in artificial systems, with advanced LLMs displaying
consistent behavioral tendencies resembling human traits like agreeableness and
self-regulation. Understanding these patterns is crucial, yet prior work
primarily relied on simplified self-reports and heuristic prompting, with
little behavioral validation. In this study, we systematically characterize LLM
personality across three dimensions: (1) the dynamic emergence and evolution of
trait profiles throughout training stages; (2) the predictive validity of
self-reported traits in behavioral tasks; and (3) the impact of targeted
interventions, such as persona injection, on both self-reports and behavior.
Our findings reveal that instructional alignment (e.g., RLHF, instruction
tuning) significantly stabilizes trait expression and strengthens trait
correlations in ways that mirror human data. However, these self-reported
traits do not reliably predict behavior, and observed associations often
diverge from human patterns. While persona injection successfully steers
self-reports in the intended direction, it exerts little or inconsistent effect
on actual behavior. By distinguishing surface-level trait expression from
behavioral consistency, our findings challenge assumptions about LLM
personality and underscore the need for deeper evaluation in alignment and
interpretability.

</details>


### [40] [Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation](https://arxiv.org/abs/2509.03736)
*James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在人类研究替代方面存在内部不一致性问题，虽然能生成类似人类的回答，但缺乏内部一致性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM生成代理是否能真正替代人类研究参与者，关注其内部一致性而非仅表面回答的相似性。

Method: 设计实验研究：(a)揭示代理内部状态；(b)在基础对话设置中检查代理行为，通过行为假设评估对话行为与内部状态的一致性。

Result: 发现不同模型家族和规模的LLM都存在显著的内部不一致性，尽管能生成匹配人类的对答，但无法保持内部一致性。

Conclusion: LLM代理缺乏内部一致性，这是其准确替代人类研究参与者的关键能力缺陷，限制了其在人类主体研究中的适用性。

Abstract: The impressive capabilities of Large Language Models (LLMs) have fueled the
notion that synthetic agents can serve as substitutes for real participants in
human-subject research. In an effort to evaluate the merits of this claim,
social science researchers have largely focused on whether LLM-generated survey
data corresponds to that of a human counterpart whom the LLM is prompted to
represent. In contrast, we address a more fundamental question: Do agents
maintain internal consistency, retaining similar behaviors when examined under
different experimental settings? To this end, we develop a study designed to
(a) reveal the agent's internal state and (b) examine agent behavior in a basic
dialogue setting. This design enables us to explore a set of behavioral
hypotheses to assess whether an agent's conversation behavior is consistent
with what we would expect from their revealed internal state. Our findings on
these hypotheses show significant internal inconsistencies in LLMs across model
families and at differing model sizes. Most importantly, we find that, although
agents may generate responses matching those of their human counterparts, they
fail to be internally consistent, representing a critical gap in their
capabilities to accurately substitute for real participants in human-subject
research. Our simulation code and data are publicly accessible.

</details>


### [41] [RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs](https://arxiv.org/abs/2509.03768)
*Connor Walker,Koorosh Aslansefat,Mohammad Naveed Akram,Yiannis Papadopoulos*

Main category: cs.AI

TL;DR: RAGuard是一个增强的RAG框架，通过并行查询技术文档和安全文档，在海上风电维护中显著提升安全召回率至50%以上，同时保持60%以上的技术召回率。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在处理高度专业化或意外场景时存在安全风险，特别是在海上风电维护等关键领域需要同时保证技术准确性和安全性。

Method: 提出RAGuard框架，对技术手册和安全关键文档建立两个独立索引，并行查询并分配单独的检索预算；进一步开发SafetyClamp扩展，通过硬钳位机制确保安全槽位保证。

Result: 在稀疏(BM25)、稠密(DPR)和混合检索范式下，安全召回率从RAG的几乎0%提升到RAGuard的50%以上，技术召回率保持在60%以上。

Conclusion: RAGuard和SafetyClamp有潜力为关键维护场景中LLM驱动的决策支持建立新的安全保证标准。

Abstract: Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet
conventional Large Language Models (LLMs) often fail when confronted with
highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced
Retrieval-Augmented Generation (RAG) framework that explicitly integrates
safety-critical documents alongside technical manuals.By issuing parallel
queries to two indices and allocating separate retrieval budgets for knowledge
and safety, RAGuard guarantees both technical depth and safety coverage. We
further develop a SafetyClamp extension that fetches a larger candidate pool,
"hard-clamping" exact slot guarantees to safety. We evaluate across sparse
(BM25), dense (Dense Passage Retrieval) and hybrid retrieval paradigms,
measuring Technical Recall@K and Safety Recall@K. Both proposed extensions of
RAG show an increase in Safety Recall@K from almost 0\% in RAG to more than
50\% in RAGuard, while maintaining Technical Recall above 60\%. These results
demonstrate that RAGuard and SafetyClamp have the potential to establish a new
standard for integrating safety assurance into LLM-powered decision support in
critical maintenance contexts.

</details>


### [42] [Leveraging LLM-Based Agents for Intelligent Supply Chain Planning](https://arxiv.org/abs/2509.03811)
*Yongzhi Qi,Jiaheng Yin,Jianshen Zhang,Dongyang Geng,Zhengyu Chen,Hao Hu,Wei Qi,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: 基于大语言模型构建的供应链规划组件（SCPA）框架，能够理解域知识、分解任务并生成基于证据的规划报告，在JD.com真实场景中有效提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 供应链规划涉及多个实体和环节，需要采集数据、制定长期计划并根据环境变化动态调整，同时确保解释性、效率和可靠性。AI技术的发展为解决这些实际问题提供了新工具。

Method: 构建供应链规划组件（SCPA）框架，能够理解域知识、理解运营商需求、分解任务、利用或创建新工具，生成基于证据的规划报告。

Result: 在JD.com真实场景中部署，证明了LLM-agent在供应链中的可行性，有效减少人工劳动力，提高了准确性、库存可用性等关键指标。

Conclusion: 该研究展示了大语言模型作为组件在供应链规划中的应用潜力，为解决复杂的实际商业问题提供了有效的新方法。

Abstract: In supply chain management, planning is a critical concept. The movement of
physical products across different categories, from suppliers to warehouse
management, to sales, and logistics transporting them to customers, entails the
involvement of many entities. It covers various aspects such as demand
forecasting, inventory management, sales operations, and replenishment. How to
collect relevant data from an e-commerce platform's perspective, formulate
long-term plans, and dynamically adjust them based on environmental changes,
while ensuring interpretability, efficiency, and reliability, is a practical
and challenging problem. In recent years, the development of AI technologies,
especially the rapid progress of large language models, has provided new tools
to address real-world issues. In this work, we construct a Supply Chain
Planning Agent (SCPA) framework that can understand domain knowledge,
comprehend the operator's needs, decompose tasks, leverage or create new tools,
and return evidence-based planning reports. We deploy this framework in
JD.com's real-world scenario, demonstrating the feasibility of LLM-agent
applications in the supply chain. It effectively reduced labor and improved
accuracy, stock availability, and other key metrics.

</details>


### [43] [Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning](https://arxiv.org/abs/2509.03817)
*Wei Yang,Jesse Thomason*

Main category: cs.AI

TL;DR: 提出了Meta-Policy Deliberation Framework (MPDF)框架，让LLM智能体学习去中心化的元认知策略，通过SoftRankPO算法稳定训练，在数学和通用推理任务上比现有方法提升4-5%准确率


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统采用固定协作协议，忽视了智能体内部的元认知能力，无法根据不确定性或置信度等内部认知状态自适应调整策略

Method: MPDF框架让智能体学习Persist、Refine、Concede三种高层元认知动作的去中心化策略，开发SoftRankPO强化学习算法，通过平滑正态分位数映射奖励排名来稳定训练

Result: 在五个数学和通用推理基准测试中，MPDF+SoftRankPO相比六种最先进的启发式和基于学习的多智能体推理算法，平均准确率绝对提升4-5%

Conclusion: 该工作提出了学习自适应元认知策略的新范式，将重点从设计固定协议转向学习动态的、深思熟虑的策略

Abstract: Multi-agent systems of large language models (LLMs) show promise for complex
reasoning, but their effectiveness is often limited by fixed collaboration
protocols. These frameworks typically focus on macro-level orchestration while
overlooking agents' internal deliberative capabilities. This critical
meta-cognitive blindspot treats agents as passive executors unable to adapt
their strategy based on internal cognitive states like uncertainty or
confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where
agents learn a decentralized policy over a set of high-level meta-cognitive
actions: Persist, Refine, and Concede. To overcome the instability of
traditional policy gradients in this setting, we develop SoftRankPO, a novel
reinforcement learning algorithm. SoftRankPO stabilizes training by shaping
advantages based on the rank of rewards mapped through smooth normal quantiles,
making the learning process robust to reward variance. Experiments show that
MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across
five mathematical and general reasoning benchmarks compared to six
state-of-the-art heuristic and learning-based multi-agent reasoning algorithms.
Our work presents a paradigm for learning adaptive, meta-cognitive policies for
multi-agent LLM systems, shifting the focus from designing fixed protocols to
learning dynamic, deliberative strategies.

</details>


### [44] [What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models](https://arxiv.org/abs/2509.03827)
*Pierre Le Coz,Jia An Liu,Debarun Bhattacharjya,Georgina Curto,Serge Stinckwich*

Main category: cs.AI

TL;DR: 评估大语言模型在无家可归问题政策制定中与领域专家的一致性，开发包含四个地理区域的决策场景基准，并通过基于代理的模型模拟政策影响


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在高风险领域的应用增加，需要评估其在复杂社会政策制定中与专家的一致性，特别是在影响全球1.5亿人的无家可归问题上

Method: 开发包含四个地理区域（美国南本德、西班牙巴塞罗那、南非约翰内斯堡、中国澳门）决策场景的新基准，基于能力方法框架，建立连接基准政策与基于代理模型的自动化流程

Result: 结果显示大语言模型在社会政策制定方面具有潜力，通过与当地领域专家合作引入负责任的安全护栏和情境校准，能够大规模提供有价值的替代政策见解

Conclusion: 大语言模型在社会政策制定中展现出前景，但需要与领域专家合作建立适当的保障措施和情境调整机制

Abstract: Large language models (LLMs) are increasingly being adopted in high-stakes
domains. Their capacity to process vast amounts of unstructured data, explore
flexible scenarios, and handle a diversity of contextual factors can make them
uniquely suited to provide new insights for the complexity of social
policymaking. This article evaluates whether LLMs' are aligned with domain
experts (and among themselves) to inform social policymaking on the subject of
homelessness alleviation - a challenge affecting over 150 million people
worldwide. We develop a novel benchmark comprised of decision scenarios with
policy choices across four geographies (South Bend, USA; Barcelona, Spain;
Johannesburg, South Africa; Macau SAR, China). The policies in scope are
grounded in the conceptual framework of the Capability Approach for human
development. We also present an automated pipeline that connects the
benchmarked policies to an agent-based model, and we explore the social impact
of the recommended policies through simulated social scenarios. The paper
results reveal promising potential to leverage LLMs for social policy making.
If responsible guardrails and contextual calibrations are introduced in
collaboration with local domain experts, LLMs can provide humans with valuable
insights, in the form of alternative policies at scale.

</details>


### [45] [An Agentic Model Context Protocol Framework for Medical Concept Standardization](https://arxiv.org/abs/2509.03828)
*Jaerong Ahn,Andrew Wen,Nan Wang,Heling Jia,Zhiyi Yue,Sunyang Fu,Hongfang Liu*

Main category: cs.AI

TL;DR: 基于Model Context Protocol的无训练、防幽灵的OMOP CDM医学术语映射系统，通过外部资源查询提高映射效率和准确性


<details>
  <summary>Details</summary>
Motivation: OMOP CDM数据标准化过程中，源医学术语向标准概念的映射工作资源浪费且容易出错，而大语言模型存在幽灵问题，不适合直接于临床部署

Method: 采用Model Context Protocol(MCP)标准化框架，允许LLM与外部资源和工具交互，实现零训练、可解释的映射系统

Result: 系统能够提供实时词汇查询和结构化推理输出，显著提高了映射效率和准确性

Conclusion: 该方法在不需训练的情况下有效预防LLM幽灵问题，适合直接在探索性和生产环境中使用

Abstract: The Observational Medical Outcomes Partnership (OMOP) common data model (CDM)
provides a standardized representation of heterogeneous health data to support
large-scale, multi-institutional research. One critical step in data
standardization using OMOP CDM is the mapping of source medical terms to OMOP
standard concepts, a procedure that is resource-intensive and error-prone.
While large language models (LLMs) have the potential to facilitate this
process, their tendency toward hallucination makes them unsuitable for clinical
deployment without training and expert validation. Here, we developed a
zero-training, hallucination-preventive mapping system based on the Model
Context Protocol (MCP), a standardized and secure framework allowing LLMs to
interact with external resources and tools. The system enables explainable
mapping and significantly improves efficiency and accuracy with minimal effort.
It provides real-time vocabulary lookups and structured reasoning outputs
suitable for immediate use in both exploratory and production environments.

</details>


### [46] [A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai](https://arxiv.org/abs/2509.03830)
*Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng*

Main category: cs.AI

TL;DR: 一种多维度AI框架，通过社交媒体多模态数据分析游客对历史城区的视觉关注、艺术偏好和情感反应，为可持续城市规划提供决策支持


<details>
  <summary>Details</summary>
Motivation: 历史城区在保护文化遗产和促进旅游中具有重要作用，理解游客对这些环境的感知对于可持续、人本化的城市规划至关重要

Method: 采用多模态AI框架，整合焦点提取、色彩主题分析和情感挖掘。通过细调语义分割模型识别视觉关注区域，使用聚类方法提取主导颜色，采用混合情感分析方法（规则基础和多任务BERT模型）评估游客评论

Result: 在上海12个历史城区的应用显示，视觉期望与实际环境存在显著差异，反映了风格偏好和感知偏差。在美学吸引力和情感反应方面存在空间差异

Conclusion: 该框架提供了一种整合的、数据驱动的方法来解码游客感知，为旅游业、遗产保护和公共空间设计的知惃决策做出了贡献

Abstract: Historic urban quarters play a vital role in preserving cultural heritage
while serving as vibrant spaces for tourism and everyday life. Understanding
how tourists perceive these environments is essential for sustainable,
human-centered urban planning. This study proposes a multidimensional
AI-powered framework for analyzing tourist perception in historic urban
quarters using multimodal data from social media. Applied to twelve historic
quarters in central Shanghai, the framework integrates focal point extraction,
color theme analysis, and sentiment mining. Visual focus areas are identified
from tourist-shared photos using a fine-tuned semantic segmentation model. To
assess aesthetic preferences, dominant colors are extracted using a clustering
method, and their spatial distribution across quarters is analyzed. Color
themes are further compared between social media photos and real-world street
views, revealing notable shifts. This divergence highlights potential gaps
between visual expectations and the built environment, reflecting both
stylistic preferences and perceptual bias. Tourist reviews are evaluated
through a hybrid sentiment analysis approach combining a rule-based method and
a multi-task BERT model. Satisfaction is assessed across four dimensions:
tourist activities, built environment, service facilities, and business
formats. The results reveal spatial variations in aesthetic appeal and
emotional response. Rather than focusing on a single technical innovation, this
framework offers an integrated, data-driven approach to decoding tourist
perception and contributes to informed decision-making in tourism, heritage
conservation, and the design of aesthetically engaging public spaces.

</details>


### [47] [Continuous Monitoring of Large-Scale Generative AI via Deterministic Knowledge Graph Structures](https://arxiv.org/abs/2509.03857)
*Kishor Datta Gupta,Mohd Ariful Haque,Hasmot Ali,Marufa Kamal,Syed Bahauddin Alam,Mohammad Ashiqur Rahman*

Main category: cs.AI

TL;DR: 通过构建确定性知识图和LLM生成知识图的对比监控，提出了一种可扩展的自动化方法来评估生成式AI的可靠性和检测幻觉现象


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI模型存在的可靠性问题（如幻觉、语义偏移、偏见），充当黑盒模型评估主观性强、缩放性差的问题

Method: 构建两个并行知识图：确定性KG（规则基础）和LLM生成KG（实时文本流），通过ICR、IPR、CI等KG指标计算结构偏移，设置动态异常阈值进行监控

Result: 开发了一种自动化实时监控框架，能够主动识别和标记显著偏移，及时检测语义异常或幻觉现象

Conclusion: 该结构化、指标驱动的方法提供了一种健壁、可扩展的评估框架，有效解决了生成式AI可靠性评估的挑战

Abstract: Generative AI (GEN AI) models have revolutionized diverse application domains
but present substantial challenges due to reliability concerns, including
hallucinations, semantic drift, and inherent biases. These models typically
operate as black-boxes, complicating transparent and objective evaluation.
Current evaluation methods primarily depend on subjective human assessment,
limiting scalability, transparency, and effectiveness. This research proposes a
systematic methodology using deterministic and Large Language Model
(LLM)-generated Knowledge Graphs (KGs) to continuously monitor and evaluate GEN
AI reliability. We construct two parallel KGs: (i) a deterministic KG built
using explicit rule-based methods, predefined ontologies, domain-specific
dictionaries, and structured entity-relation extraction rules, and (ii) an
LLM-generated KG dynamically derived from real-time textual data streams such
as live news articles. Utilizing real-time news streams ensures authenticity,
mitigates biases from repetitive training, and prevents adaptive LLMs from
bypassing predefined benchmarks through feedback memorization. To quantify
structural deviations and semantic discrepancies, we employ several established
KG metrics, including Instantiated Class Ratio (ICR), Instantiated Property
Ratio (IPR), and Class Instantiation (CI). An automated real-time monitoring
framework continuously computes deviations between deterministic and
LLM-generated KGs. By establishing dynamic anomaly thresholds based on
historical structural metric distributions, our method proactively identifies
and flags significant deviations, thus promptly detecting semantic anomalies or
hallucinations. This structured, metric-driven comparison between deterministic
and dynamically generated KGs delivers a robust and scalable evaluation
framework.

</details>


### [48] [Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata](https://arxiv.org/abs/2509.03863)
*Sina Khajehabdollahi,Gautier Hamon,Marko Cvjetko,Pierre-Yves Oudeyer,Clément Moulin-Frier,Cédric Colas*

Main category: cs.AI

TL;DR: 提出E&E混合策略，结合局部新颖性搜索和目标导向探索，利用视觉语言模型生成语义目标，在连续细胞自动机中发现更多样化的模式


<details>
  <summary>Details</summary>
Motivation: 传统新颖性搜索方法在探索高维行为空间时容易陷入局部最优，无法到达遥远未探索区域，需要新的探索策略来突破局部新颖性边界

Method: E&E混合策略：交替进行局部新颖性驱动的扩展和目标导向的远征，使用视觉语言模型生成语言目标来描述假设的有趣模式，在语义空间中进行评估和目标生成

Result: 在Flow Lenia连续细胞自动机上测试，E&E比现有探索方法发现更多样化的解决方案，谱系分析显示远征产生的解决方案对长期探索有不成比例的影响

Conclusion: E&E能够突破局部新颖性边界，以人类可理解的方式探索行为景观，为人工生命等领域的开放式探索提供了有前景的模板

Abstract: Discovering diverse visual patterns in continuous cellular automata (CA) is
challenging due to the vastness and redundancy of high-dimensional behavioral
spaces. Traditional exploration methods like Novelty Search (NS) expand locally
by mutating known novel solutions but often plateau when local novelty is
exhausted, failing to reach distant, unexplored regions. We introduce
Expedition and Expansion (E&E), a hybrid strategy where exploration alternates
between local novelty-driven expansions and goal-directed expeditions. During
expeditions, E&E leverages a Vision-Language Model (VLM) to generate linguistic
goals--descriptions of interesting but hypothetical patterns that drive
exploration toward uncharted regions. By operating in semantic spaces that
align with human perception, E&E both evaluates novelty and generates goals in
conceptually meaningful ways, enhancing the interpretability and relevance of
discovered behaviors. Tested on Flow Lenia, a continuous CA known for its rich,
emergent behaviors, E&E consistently uncovers more diverse solutions than
existing exploration methods. A genealogical analysis further reveals that
solutions originating from expeditions disproportionately influence long-term
exploration, unlocking new behavioral niches that serve as stepping stones for
subsequent search. These findings highlight E&E's capacity to break through
local novelty boundaries and explore behavioral landscapes in human-aligned,
interpretable ways, offering a promising template for open-ended exploration in
artificial life and beyond.

</details>


### [49] [FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace](https://arxiv.org/abs/2509.03890)
*Yineng Yan,Xidong Wang,Jin Seng Cheng,Ran Hu,Wentao Guan,Nahid Farahmand,Hengte Lin,Yue Li*

Main category: cs.AI

TL;DR: 论文介绍了基于LLM的FaMA助手，通过对话式AI代理简化C2C电商平台的复杂交互，替代传统GUI界面，实现了98%的任务成功率和2倍的交互速度提升。


<details>
  <summary>Details</summary>
Motivation: C2C电商平台的复杂GUI界面给买卖双方带来时间消耗，需要一种更直观的交互方式来简化操作流程。

Method: 开发基于LLM的对话式AI代理FaMA，通过自然语言命令自动化关键工作流程，为买卖双方提供简化的操作界面。

Result: FaMA在复杂任务上达到98%的成功率，交互时间最多可缩短2倍。

Conclusion: 基于LLM的对话式AI代理为电商平台提供了轻量级、易用的替代方案，显著提升了用户体验和操作效率。

Abstract: The emergence of agentic AI, powered by Large Language Models (LLMs), marks a
paradigm shift from reactive generative systems to proactive, goal-oriented
autonomous agents capable of sophisticated planning, memory, and tool use. This
evolution presents a novel opportunity to address long-standing challenges in
complex digital environments. Core tasks on Consumer-to-Consumer (C2C)
e-commerce platforms often require users to navigate complex Graphical User
Interfaces (GUIs), making the experience time-consuming for both buyers and
sellers. This paper introduces a novel approach to simplify these interactions
through an LLM-powered agentic assistant. This agent functions as a new,
conversational entry point to the marketplace, shifting the primary interaction
model from a complex GUI to an intuitive AI agent. By interpreting natural
language commands, the agent automates key high-friction workflows. For
sellers, this includes simplified updating and renewal of listings, and the
ability to send bulk messages. For buyers, the agent facilitates a more
efficient product discovery process through conversational search. We present
the architecture for Facebook Marketplace Assistant (FaMA), arguing that this
agentic, conversational paradigm provides a lightweight and more accessible
alternative to traditional app interfaces, allowing users to manage their
marketplace activities with greater efficiency. Experiments show FaMA achieves
a 98% task success rate on solving complex tasks on the marketplace and enables
up to a 2x speedup on interaction time.

</details>


### [50] [A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning](https://arxiv.org/abs/2509.03906)
*Qika Lin,Yifan Zhu,Bin Pu,Ling Huang,Haoran Luo,Jingying Ma,Zhen Peng,Tianzhe Zhao,Fangzhi Xu,Jian Zhang,Kai He,Zhonghong Ou,Swapnil Mishra,Mengling Feng*

Main category: cs.AI

TL;DR: DeepMedix-R1是一个用于胸部X光片解读的医疗基础模型，通过三阶段训练实现透明推理和局部可解释性，在报告生成和视觉问答任务上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前医疗基础模型通常以黑盒方式生成答案，缺乏透明的推理过程和局部可解释性，这阻碍了其在临床实践中的部署应用。

Method: 采用顺序训练流程：1）在精选的CXR指令数据上微调获得基础解读能力；2）使用高质量合成推理样本实现冷启动推理；3）通过在线强化学习提升推理质量和生成性能，使模型能够生成答案和与图像局部区域相关的推理步骤。

Result: 在报告生成任务上分别比LLaVA-Rad和MedGemma提升14.54%和31.32%；在视觉问答任务上分别比MedGemma和CheXagent提升57.75%和23.06%；专家评审显示相比Qwen2.5-VL-7B模型具有更好的可解释性和临床合理性（0.7416 vs 0.2584总体偏好）。

Conclusion: 该研究推动了医疗基础模型向整体性、透明性和临床可操作性方向发展，为CXR解读提供了更可靠的解决方案。

Abstract: Medical foundation models (FMs) have shown tremendous promise amid the rapid
advancements in artificial intelligence (AI) technologies. However, current
medical FMs typically generate answers in a black-box manner, lacking
transparent reasoning processes and locally grounded interpretability, which
hinders their practical clinical deployments. To this end, we introduce
DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It
leverages a sequential training pipeline: initially fine-tuned on curated CXR
instruction data to equip with fundamental CXR interpretation capabilities,
then exposed to high-quality synthetic reasoning samples to enable cold-start
reasoning, and finally refined via online reinforcement learning to enhance
both grounded reasoning quality and generation performance. Thus, the model
produces both an answer and reasoning steps tied to the image's local regions
for each query. Quantitative evaluation demonstrates substantial improvements
in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and
visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent)
tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking
framework using advanced language models to evaluate answer quality, further
highlighting the superiority of DeepMedix-R1. Expert review of generated
reasoning steps reveals greater interpretability and clinical plausibility
compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall
preference). Collectively, our work advances medical FM development toward
holistic, transparent, and clinically actionable modeling for CXR
interpretation.

</details>


### [51] [Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions](https://arxiv.org/abs/2509.03953)
*Ángel Aso-Mollar,Diego Aineto,Enrico Scala,Eva Onaindia*

Main category: cs.AI

TL;DR: 这篇论文提出了一种高效的搜索算法，将控制参数作为真正的决策点显式处理，而非作为约束来处理。


<details>
  <summary>Details</summary>
Motivation: 现有方法将控制参数隐式当作附加约束处理，而非将其视为搜索空间中的真正决策点，需要更高效的显式处理方法。

Method: 开发了一种最优优先质量搜索算法，操作于由控制参数定义的无穷决策空间，采用延迟部分扩展概念来增量式扩展状态后继者。

Result: 证明了算法在某些条件下具有极限完备性，并显示出与现有解决控制参数规划问题方法相竞争的性能。

Conclusion: 该新颖的搜索算法是解决涉及控制参数的规划问题的竞争性替代方案。

Abstract: In automated planning, control parameters extend standard action
representations through the introduction of continuous numeric decision
variables. Existing state-of-the-art approaches have primarily handled control
parameters as embedded constraints alongside other temporal and numeric
restrictions, and thus have implicitly treated them as additional constraints
rather than as decision points in the search space. In this paper, we propose
an efficient alternative that explicitly handles control parameters as true
decision points within a systematic search scheme. We develop a best-first,
heuristic search algorithm that operates over infinite decision spaces defined
by control parameters and prove a notion of completeness in the limit under
certain conditions. Our algorithm leverages the concept of delayed partial
expansion, where a state is not fully expanded but instead incrementally
expands a subset of its successors. Our results demonstrate that this novel
search algorithm is a competitive alternative to existing approaches for
solving planning problems involving control parameters.

</details>


### [52] [World Model Implanting for Test-time Adaptation of Embodied Agents](https://arxiv.org/abs/2509.03956)
*Minjong Yoo,Jinwoo Jang,Sihyung Yoon,Honguk Woo*

Main category: cs.AI

TL;DR: WorMI框架通过将大语言模型与领域特定世界模型进行测试时组合，实现具身智能体在新领域的零样本和少样本自适应，无需大量数据收集或重新训练。


<details>
  <summary>Details</summary>
Motivation: 解决具身AI中智能体在新领域自适应需要大量数据收集和重新训练的问题，提高数据效率和适应性。

Method: 采用原型化世界模型检索方法，通过轨迹抽象表示匹配，结合世界级复合注意力机制整合多个世界模型知识并对齐中间表示。

Result: 在VirtualHome和ALFWorld基准测试中表现出优于其他基于LLM方法的零样本和少样本性能。

Conclusion: WorMI框架展示了在需要适应性和数据效率的具身智能场景中可扩展实际部署的潜力。

Abstract: In embodied AI, a persistent challenge is enabling agents to robustly adapt
to novel domains without requiring extensive data collection or retraining. To
address this, we present a world model implanting framework (WorMI) that
combines the reasoning capabilities of large language models (LLMs) with
independently learned, domain-specific world models through test-time
composition. By allowing seamless implantation and removal of the world models,
the embodied agent's policy achieves and maintains cross-domain adaptability.
In the WorMI framework, we employ a prototype-based world model retrieval
approach, utilizing efficient trajectory-based abstract representation
matching, to incorporate relevant models into test-time composition. We also
develop a world-wise compound attention method that not only integrates the
knowledge from the retrieved world models but also aligns their intermediate
representations with the reasoning model's representation within the agent's
policy. This framework design effectively fuses domain-specific knowledge from
multiple world models, ensuring robust adaptation to unseen domains. We
evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating
superior zero-shot and few-shot performance compared to several LLM-based
approaches across a range of unseen domains. These results highlight the
frameworks potential for scalable, real-world deployment in embodied agent
scenarios where adaptability and data efficiency are essential.

</details>


### [53] [Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent](https://arxiv.org/abs/2509.03990)
*Chunlong Wu,Zhibo Qu*

Main category: cs.AI

TL;DR: MPR是一个混合框架，通过元策略记忆和双重机制提升LLM智能体的跨任务适应性和执行稳定性


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM智能体在重复失败、探索效率低和跨任务适应性有限的问题，同时避免强化学习需要大量参数更新的缺点

Method: 将LLM生成的反思整合成结构化元策略记忆(MPM)，通过软内存引导解码和硬规则可接受性检查(HAC)两种机制在推理时应用

Result: 相比Reflexion基线，在执行准确性和鲁棒性方面获得一致提升，规则可接受性进一步提高了稳定性

Conclusion: MPR无需模型权重更新即可外部化可重用纠正知识，强制执行领域约束，同时保持基于语言反思的适应性

Abstract: Large language model (LLM) agents achieve impressive single-task performance
but commonly exhibit repeated failures, inefficient exploration, and limited
cross-task adaptability. Existing reflective strategies (e.g., Reflexion,
ReAct) improve per-episode behavior but typically produce ephemeral,
task-specific traces that are not reused across tasks. Reinforcement-learning
based alternatives can produce transferable policies but require substantial
parameter updates and compute. In this work we introduce Meta-Policy Reflexion
(MPR): a hybrid framework that consolidates LLM-generated reflections into a
structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at
inference time through two complementary mechanisms soft memory-guided decoding
and hard rule admissibility checks(HAC). MPR (i) externalizes reusable
corrective knowledge without model weight updates, (ii) enforces domain
constraints to reduce unsafe or invalid actions, and (iii) retains the
adaptability of language-based reflection. We formalize the MPM representation,
present algorithms for update and decoding, and validate the approach in a
text-based agent environment following the experimental protocol described in
the provided implementation (AlfWorld-based). Empirical results reported in the
supplied material indicate consistent gains in execution accuracy and
robustness when compared to Reflexion baselines; rule admissibility further
improves stability. We analyze mechanisms that explain these gains, discuss
scalability and failure modes, and outline future directions for multimodal and
multi?agent extensions.

</details>


### [54] [AutoPBO: LLM-powered Optimization for Local Search PBO Solvers](https://arxiv.org/abs/2509.04007)
*Jinyuan Li,Yi Chu,Yiwen Sun,Mengchuan Zou,Shaowei Cai*

Main category: cs.AI

TL;DR: AutoPBO是一个基于大语言模型的框架，用于自动优化伪布尔优化(PBO)局部搜索求解器，在多个基准测试中显著提升了性能表现。


<details>
  <summary>Details</summary>
Motivation: 伪布尔优化(PBO)局部搜索求解器的性能高度依赖内部启发式策略，但设计过程需要大量专家经验和手动调优。大语言模型在算法设计自动化方面展现潜力，但在PBO求解器优化方面的应用尚未探索。

Method: 提出AutoPBO框架，利用大语言模型自动增强PBO局部搜索求解器。在四个公共基准测试上进行实验评估，包括真实世界基准、PB竞赛基准、整数线性规划优化基准和组合基准。

Result: AutoPBO相比之前的局部搜索方法有显著改进，与六种最先进竞争对手相比保持竞争力，包括NuPBO、OraSLS、PBO-IHS、RoundingSat、Gurobi和SCIP。

Conclusion: AutoPBO为自动化局部搜索求解器设计提供了一种有前景的方法，证明了LLM在优化PBO求解器方面的有效性。

Abstract: Pseudo-Boolean Optimization (PBO) provides a powerful framework for modeling
combinatorial problems through pseudo-Boolean (PB) constraints. Local search
solvers have shown excellent performance in PBO solving, and their efficiency
is highly dependent on their internal heuristics to guide the search. Still,
their design often requires significant expert effort and manual tuning in
practice. While Large Language Models (LLMs) have demonstrated potential in
automating algorithm design, their application to optimizing PBO solvers
remains unexplored. In this work, we introduce AutoPBO, a novel LLM-powered
framework to automatically enhance PBO local search solvers. We conduct
experiments on a broad range of four public benchmarks, including one
real-world benchmark, a benchmark from PB competition, an integer linear
programming optimization benchmark, and a crafted combinatorial benchmark, to
evaluate the performance improvement achieved by AutoPBO and compare it with
six state-of-the-art competitors, including two local search PBO solvers NuPBO
and OraSLS, two complete PB solvers PBO-IHS and RoundingSat, and two mixed
integer programming (MIP) solvers Gurobi and SCIP. AutoPBO demonstrates
significant improvements over previous local search approaches, while
maintaining competitive performance compared to state-of-the-art competitors.
The results suggest that AutoPBO offers a promising approach to automating
local search solver design.

</details>


### [55] [CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.04027)
*Zeyu Gan,Hao Yi,Yong Liu*

Main category: cs.AI

TL;DR: CoT-Space框架将LLM推理从离散的token预测重新定义为连续语义空间中的优化过程，揭示了最优思维链长度是欠拟合与过拟合权衡的自然结果


<details>
  <summary>Details</summary>
Motivation: 传统token级RL框架无法与多步思维过程（如Chain-of-Thought）的推理级性质对齐，存在显著理论空白

Method: 引入CoT-Space理论框架，从噪声视角和风险视角分析推理过程，将LLM推理重新构建为连续推理级语义空间中的优化问题

Result: 理论证明最优CoT长度收敛是欠拟合与过拟合基本权衡的自然结果，大量实验为理论发现提供了强有力的实证验证

Conclusion: 该框架不仅为过度思考等经验现象提供了合理解释，还为开发更有效和可泛化的推理智能体奠定了坚实的理论基础

Abstract: Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought processes
like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,
a novel theoretical framework that recasts LLM reasoning from a discrete
token-prediction task to an optimization process within a continuous,
reasoning-level semantic space. By analyzing this process from both a noise
perspective and a risk perspective, we demonstrate that the convergence to an
optimal CoT length is a natural consequence of the fundamental trade-off
between underfitting and overfitting. Furthermore, extensive experiments
provide strong empirical validation for our theoretical findings. Our framework
not only provides a coherent explanation for empirical phenomena such as
overthinking but also offers a solid theoretical foundation to guide the future
development of more effective and generalizable reasoning agents.

</details>


### [56] [Oruga: An Avatar of Representational Systems Theory](https://arxiv.org/abs/2509.04041)
*Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng*

Main category: cs.AI

TL;DR: Oruga是一个基于表示系统理论(RST)的实现框架，旨在让机器能够像人类一样灵活使用不同表示形式，包括绘制图表、转换表示和跨领域类比。


<details>
  <summary>Details</summary>
Motivation: 人类能够灵活使用各种表示形式（如图表、不同表示间的转换、跨领域类比），希望让机器也具备这种能力以更好地与人类协作。

Method: 开发了Oruga系统，包含：1)RST概念对应的核心数据结构；2)与核心通信的语言；3)通过结构转移方法进行转换的引擎。

Result: 提出了Oruga系统的核心架构和语言，并展示了结构转移方法能够执行的转换示例。

Conclusion: Oruga实现了表示系统理论的关键方面，为机器获得人类般的表示灵活性提供了技术基础。

Abstract: Humans use representations flexibly. We draw diagrams, change representations
and exploit creative analogies across different domains. We want to harness
this kind of power and endow machines with it to make them more compatible with
human use. Previously we developed Representational Systems Theory (RST) to
study the structure and transformations of representations. In this paper we
present Oruga (caterpillar in Spanish; a symbol of transformation), an
implementation of various aspects of RST. Oruga consists of a core of data
structures corresponding to concepts in RST, a language for communicating with
the core, and an engine for producing transformations using a method we call
structure transfer. In this paper we present an overview of the core and
language of Oruga, with a brief example of the kind of transformation that
structure transfer can execute.

</details>


### [57] [Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning](https://arxiv.org/abs/2509.04083)
*Alexander Beiser,David Penz,Nysret Musliu*

Main category: cs.AI

TL;DR: 本文研究发现，在神经符号LLM推理中，形式语言的选择是一个被忽视但重要的因素，会影响推理性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在形式推理能力方面仍有不足，神经符号LLM推理方法虽然有效，但其成功因素尚不清楚，特别是形式语言选择的影响未被充分研究。

Method: 通过比较四种形式语言在三个数据集和七个LLM上的表现，分析形式语言选择对句法和语义推理能力的影响。

Result: 研究发现形式语言的选择确实会影响神经符号推理的性能，不同LLM受到的影响程度不同。

Conclusion: 形式语言的选择是神经符号LLM推理成功的关键因素之一，需要根据具体任务和模型特点进行选择。

Abstract: Large language models (LLMs) achieve astonishing results on a wide range of
tasks. However, their formal reasoning ability still lags behind. A promising
approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators
from natural to formal languages and symbolic solvers for deriving correct
results. Still, the contributing factors to the success of Neurosymbolic LLM
reasoning remain unclear. This paper demonstrates that one previously
overlooked factor is the choice of the formal language. We introduce the
intermediate language challenge: selecting a suitable formal language for
neurosymbolic reasoning. By comparing four formal languages across three
datasets and seven LLMs, we show that the choice of formal language affects
both syntactic and semantic reasoning capabilities. We also discuss the varying
effects across different LLMs.

</details>


### [58] [Hybrid Reinforcement Learning and Search for Flight Trajectory Planning](https://arxiv.org/abs/2509.04100)
*Alberto Luise,Michele Lombardi,Florent Teichteil Koenigsbuch*

Main category: cs.AI

TL;DR: 使用强化学习预计计划路径来约束搜索空间，在续航路径优化中实现计算速度提升50%，燃油消耗仍保持在无约束解的1%偏差内


<details>
  <summary>Details</summary>
Motivation: 在紧急情况下需要快速重新计算航空路径，传统路径规划器计算速度较慢，需要提高优化效率

Method: 训练强化学习组件预先计算近优路径，然后用这些路径作为约束来缩小路径规划器的搜索空间

Result: 使用Airbus飞机性能模型进行实验，燃油消耗与无约束解几乎相同（偏差通常在1%以内），计算速度提高了最50%

Conclusion: 强化学习与搜索基于路径规划的结合方法能够在保持解的质量同时显著提高计算效率，适用于需要快速路径重新规划的紧急情况

Abstract: This paper explores the combination of Reinforcement Learning (RL) and
search-based path planners to speed up the optimization of flight paths for
airliners, where in case of emergency a fast route re-calculation can be
crucial. The fundamental idea is to train an RL Agent to pre-compute
near-optimal paths based on location and atmospheric data and use those at
runtime to constrain the underlying path planning solver and find a solution
within a certain distance from the initial guess. The approach effectively
reduces the size of the solver's search space, significantly speeding up route
optimization. Although global optimality is not guaranteed, empirical results
conducted with Airbus aircraft's performance models show that fuel consumption
remains nearly identical to that of an unconstrained solver, with deviations
typically within 1%. At the same time, computation speed can be improved by up
to 50% as compared to using a conventional solver alone.

</details>


### [59] [Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker](https://arxiv.org/abs/2509.04125)
*Tarik Zaciragic,Aske Plaat,K. Joost Batenburg*

Main category: cs.AI

TL;DR: 研究DQN和CFR算法在简化扑克游戏Leduc Hold'em中是否表现出诈唬行为，发现两种算法都以不同方式展现诈唬，但成功率相似，表明诈唬是游戏本质而非算法特性


<details>
  <summary>Details</summary>
Motivation: 虽然诈唬是扑克游戏中的关键技能，但现有计算机扑克研究主要关注胜率等性能指标，而忽略了诈唬行为的研究

Method: 设计实验让基于强化学习的DQN算法和基于博弈论的CFR算法在Leduc Hold'em中对战，记录并分析它们的行动数据

Result: 两种算法都表现出诈唬行为但方式不同：诈唬尝试率有差异，但成功诈唬（对手弃牌）的比例大致相同

Conclusion: 诈唬是扑克游戏的基本要素，而非特定算法的特性；未来研究应关注不同诈唬风格和完整扑克游戏

Abstract: In the game of poker, being unpredictable, or bluffing, is an essential
skill. When humans play poker, they bluff. However, most works on
computer-poker focus on performance metrics such as win rates, while bluffing
is overlooked. In this paper we study whether two popular algorithms, DQN
(based on reinforcement learning) and CFR (based on game theory), exhibit
bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed
an experiment where we let the DQN and CFR agent play against each other while
we log their actions. We find that both DQN and CFR exhibit bluffing behavior,
but they do so in different ways. Although both attempt to perform bluffs at
different rates, the percentage of successful bluffs (where the opponent folds)
is roughly the same. This suggests that bluffing is an essential aspect of the
game, not of the algorithm. Future work should look at different bluffing
styles and at the full game of poker. Code at
https://github.com/TarikZ03/Bluffing-by-DQN-and-CFR-in-Leduc-Hold-em-Poker-Codebase.

</details>


### [60] [The human biological advantage over AI](https://arxiv.org/abs/2509.04130)
*William Stewart*

Main category: cs.AI

TL;DR: 诺大人工智能可能在许多方面超越人类，但因缺乏生物学中央神经系统而无法真正体验情感和理解行为后果，不能成为宇宙领导者


<details>
  <summary>Details</summary>
Motivation: 探讨AI系统在达到通用智能后是否能够超越人类并成为宇宙的合格领导者

Method: 通过对比人类中央神经系统(CNS)与AI系统的根本差异，分析情感体验和道德理解的生物学基础

Result: 识别出CNS是人类与AI的关键区别，CNS使人类能够真正体验情感和理解行为后果，而这是发展持续道德体系的前提

Conclusion: 尽管AI可能在许多方面超越人类，但因缺乏生物学CNS而无法真正理解情感和道德，生物DNA永远比硅晶芯片更适合作为宇宙领导者的基础

Abstract: Recent advances in AI raise the possibility that AI systems will one day be
able to do anything humans can do, only better. If artificial general
intelligence (AGI) is achieved, AI systems may be able to understand, reason,
problem solve, create, and evolve at a level and speed that humans will
increasingly be unable to match, or even understand. These possibilities raise
a natural question as to whether AI will eventually become superior to humans,
a successor "digital species", with a rightful claim to assume leadership of
the universe. However, a deeper consideration suggests the overlooked
differentiator between human beings and AI is not the brain, but the central
nervous system (CNS), providing us with an immersive integration with physical
reality. It is our CNS that enables us to experience emotion including pain,
joy, suffering, and love, and therefore to fully appreciate the consequences of
our actions on the world around us. And that emotional understanding of the
consequences of our actions is what is required to be able to develop
sustainable ethical systems, and so be fully qualified to be the leaders of the
universe. A CNS cannot be manufactured or simulated; it must be grown as a
biological construct. And so, even the development of consciousness will not be
sufficient to make AI systems superior to humans. AI systems may become more
capable than humans on almost every measure and transform our society. However,
the best foundation for leadership of our universe will always be DNA, not
silicon.

</details>


### [61] [Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs](https://arxiv.org/abs/2509.04159)
*Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das*

Main category: cs.AI

TL;DR: 提出一种可扩展的培培域特定语言（DSL），通过有向动作图表示食谱，形式化地模型复杂的燕饪过程


<details>
  <summary>Details</summary>
Motivation: 因为燕饪过程具有内在的复杂性和模糊性，形式化燕饪程序仍然是一项具有挑战性的任务

Method: 设计了一种可扩展的培培域特定语言，将食谱表示为有向动作图，捕获过程、转移、环境、并发性和组合结构

Result: 通过对英式全套早餐食谱的初步手动评估，证明了DSL的表达能力和适用性

Conclusion: 这项工作是构建以动作为中心的燕饪本体论的初步措施，利用时间图形式实现结构化的机器理解、精确解释和可扩展的燕饪过程自动化

Abstract: Formalizing cooking procedures remains a challenging task due to their
inherent complexity and ambiguity. We introduce an extensible domain-specific
language for representing recipes as directed action graphs, capturing
processes, transfers, environments, concurrency, and compositional structure.
Our approach enables precise, modular modeling of complex culinary workflows.
Initial manual evaluation on a full English breakfast recipe demonstrates the
DSL's expressiveness and suitability for future automated recipe analysis and
execution. This work represents initial steps towards an action-centric
ontology for cooking, using temporal graphs to enable structured machine
understanding, precise interpretation, and scalable automation of culinary
processes - both in home kitchens and professional culinary settings.

</details>


### [62] [Domain size asymptotics for Markov logic networks](https://arxiv.org/abs/2509.04192)
*Vera Koponen*

Main category: cs.AI

TL;DR: 该论文研究了马尔可夫逻辑网络(MLN)在域大小趋于无穷时的概率分布特性，分析了三种具体MLN示例的极限行为，并证明了量化器无关MLN与提升贝叶斯网络在渐近意义上的不可比性。


<details>
  <summary>Details</summary>
Motivation: 研究MLN在无限大域上的分布特性，探索不同软约束对随机结构极限行为的影响，以及比较不同形式主义在渐近表达能力上的差异。

Method: 通过分析三种具体MLN示例：(1)单一元关系符号的量化器无关MLN；(2)偏好较少三角形的图MLN；(3)偏好较少高度数顶点的图MLN，研究其在大域上的极限行为。

Result: 发现软约束对极限行为的影响各不相同，权重可能影响也可能不影响极限行为；证明了量化器无关MLN与提升贝叶斯网络的渐近不可比性；显示MLN分布在大域上集中于与均匀分布完全不同的可能世界区域。

Conclusion: MLN的极限行为取决于所使用的软约束类型，不同形式主义在渐近表达能力上存在本质差异，MLN在大域上的概率分布特性与均匀分布有显著不同。

Abstract: A Markov logic network (MLN) determines a probability distribution on the set
of structures, or ``possible worlds'', with an arbitrary finite domain. We
study the properties of such distributions as the domain size tends to
infinity. Three types of concrete examples of MLNs will be considered, and the
properties of random structures with domain sizes tending to infinity will be
studied: (1) Arbitrary quantifier-free MLNs over a language with only one
relation symbol which has arity 1. In this case we give a pretty complete
characterization of the possible limit behaviours of random structures. (2) An
MLN that favours graphs with fewer triangles (or more generally, fewer
k-cliques). As a corollary of the analysis a ``$\delta$-approximate 0-1 law''
for first-order logic is obtained. (3) An MLN that favours graphs with fewer
vertices with degree higher than a fixed (but arbitrary) number. The analysis
shows that depending on which ``soft constraints'' an MLN uses the limit
behaviour of random structures can be quite different, and the weights of the
soft constraints may, or may not, have influence on the limit behaviour. It
will also be demonstrated, using (1), that quantifier-free MLNs and lifted
Bayesian networks (in a broad sense) are asymptotically incomparable, roughly
meaning that there is a sequence of distributions on possible worlds with
increasing domain sizes that can be defined by one of the formalisms but not
even approximated by the other. In a rather general context it is also shown
that on large domains the distribution determined by an MLN concentrates almost
all its probability mass on a totally different part of the space of possible
worlds than the uniform distribution does.

</details>


### [63] [Evaluating Quality of Gaming Narratives Co-created with AI](https://arxiv.org/abs/2509.04239)
*Arturo Valdivia,Paolo Burelli*

Main category: cs.AI

TL;DR: 一种利用Delphi研究结构和Kano模型的结构化方法，通过故事设计专家评估AI生成游戏故事的质量，以指导游戏开发者优先考虑满意度关键因素。


<details>
  <summary>Details</summary>
Motivation: 解决AI生成游戏故事质量评估缺乏结构化方法的问题，为游戏开发者提供专业的质量优先级指南。

Method: 采用Delphi研究结构，组织故事设计专家小组，结合文献综合故事质量维度，并映射到Kano模型框架中分析对玩家满意度的影响。

Result: 得到了一套结构化的质量评估指标体系，能够明确呈现各质量维度对玩家满意度的关键影响程度，为开发者提供优先级判断依据。

Conclusion: 该方法为AI生成游戏故事的质量评估提供了结构化框架，有助于游戏开发者在与生成式AI协同创作时更有效地优先考虑关键质量因素。

Abstract: This paper proposes a structured methodology to evaluate AI-generated game
narratives, leveraging the Delphi study structure with a panel of narrative
design experts. Our approach synthesizes story quality dimensions from
literature and expert insights, mapping them into the Kano model framework to
understand their impact on player satisfaction. The results can inform game
developers on prioritizing quality aspects when co-creating game narratives
with generative AI.

</details>


### [64] [EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation](https://arxiv.org/abs/2509.04310)
*Yunbo Long,Liming Xu,Lukas Beckenbauer,Yuhan Liu,Alexandra Brintrup*

Main category: cs.AI

TL;DR: EvoEmo是一个进化强化学习框架，通过优化动态情感表达来提升LLM在多轮谈判中的表现，显著优于传统策略


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在谈判中忽视了情感的功能性作用，仅生成被动、偏好驱动的情感响应，容易受到对抗性对手的操纵和战略利用

Method: 将情感状态转换建模为马尔可夫决策过程，采用基于种群的遗传优化算法，在不同谈判场景中演化高奖励的情感策略

Result: EvoEmo在广泛实验和消融研究中始终优于两种基线方法（普通策略和固定情感策略），实现了更高的成功率、效率和买家节省

Conclusion: 自适应情感表达对于构建更有效的多轮谈判LLM代理具有重要意义

Abstract: Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models
(LLMs) has demonstrated that agents can engage in \textit{complex},
\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,
existing LLM agents largely overlook the functional role of emotions in such
negotiations, instead generating passive, preference-driven emotional responses
that make them vulnerable to manipulation and strategic exploitation by
adversarial counterparts. To address this gap, we present EvoEmo, an
evolutionary reinforcement learning framework that optimizes dynamic emotional
expression in negotiations. EvoEmo models emotional state transitions as a
Markov Decision Process and employs population-based genetic optimization to
evolve high-reward emotion policies across diverse negotiation scenarios. We
further propose an evaluation framework with two baselines -- vanilla
strategies and fixed-emotion strategies -- for benchmarking emotion-aware
negotiation. Extensive experiments and ablation studies show that EvoEmo
consistently outperforms both baselines, achieving higher success rates, higher
efficiency, and increased buyer savings. This findings highlight the importance
of adaptive emotional expression in enabling more effective LLM agents for
multi-turn negotiation.

</details>


### [65] [Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes](https://arxiv.org/abs/2509.04317)
*Isidoro Tamassia,Wendelin Böhmer*

Main category: cs.AI

TL;DR: 本文分析了AlphaZero在测试环境可能变化时的部署问题，通过简单修改标准框架显著提升性能，即使在低规划预算下也有效


<details>
  <summary>Details</summary>
Motivation: AlphaZero通常假设训练和测试环境不变，这限制了其适用性。研究如何在环境可能变化的测试环境中部署AlphaZero代理

Method: 对标准AlphaZero框架进行简单修改，结合蒙特卡洛规划和预训练策略价值神经网络

Result: 显著提升了在变化测试环境中的性能表现，即使在低规划预算情况下也有效

Conclusion: 通过简单修改AlphaZero框架可以显著增强其在变化环境中的适应能力，扩展了该框架的适用性

Abstract: The AlphaZero framework provides a standard way of combining Monte Carlo
planning with prior knowledge provided by a previously trained policy-value
neural network. AlphaZero usually assumes that the environment on which the
neural network was trained will not change at test time, which constrains its
applicability. In this paper, we analyze the problem of deploying AlphaZero
agents in potentially changed test environments and demonstrate how the
combination of simple modifications to the standard framework can significantly
boost performance, even in settings with a low planning budget available. The
code is publicly available on GitHub.

</details>


### [66] [Psychologically Enhanced AI Agents](https://arxiv.org/abs/2509.04343)
*Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler*

Main category: cs.AI

TL;DR: MBTI-in-Thoughts框架通过MBTI人格类型提示工程，为LLM智能体注入心理学人格特质，在不微调的情况下实现人格化行为控制。


<details>
  <summary>Details</summary>
Motivation: 将心理学人格理论融入LLM智能体设计，通过人格条件化提升智能体在多样化任务中的行为一致性和可解释性。

Method: 基于MBTI人格类型进行提示工程，在认知和情感两个心理学基础维度上对智能体进行人格化条件设定，并整合16Personalities测试进行特质持续性验证。

Result: 情感表达型智能体在叙事生成中表现优异，分析型智能体在博弈论场景中采用更稳定策略；自我反思能提升合作和推理质量；方法可泛化到Big Five等其他心理学框架。

Conclusion: 该框架为无需微调的心理学增强AI智能体奠定了基础，成功桥接了心理学理论与LLM行为设计。

Abstract: We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases across diverse tasks: emotionally expressive
agents excel in narrative generation, while analytically primed agents adopt
more stable strategies in game-theoretic settings. Our framework supports
experimenting with structured multi-agent communication protocols and reveals
that self-reflection prior to interaction improves cooperation and reasoning
quality. To ensure trait persistence, we integrate the official 16Personalities
test for automated verification. While our focus is on MBTI, we show that our
approach generalizes seamlessly to other psychological frameworks such as Big
Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior
design, we establish a foundation for psychologically enhanced AI agents
without any fine-tuning.

</details>


### [67] [ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory](https://arxiv.org/abs/2509.04439)
*Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: 该论文提出了一种概念级外部记忆方法，通过从推理轨迹中提取可重用的模块化抽象概念，实现无需权重更新的测试时持续学习，在ARC-AGI基准上取得了7.5%的相对性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有推理时缩放技术虽然使LLMs能够进行更长的推理，但推理过程中发现的模式和见解在上下文窗口重置后立即丢失。外部记忆可以持久化这些发现，但现有方法局限于基于实例的记忆条目，缺乏可重用性和扩展性。

Method: 提出概念级记忆方法：从解决方案轨迹中提取可重用的模块化自然语言抽象概念；引入新的抽象策略从推演中提取要点；选择性检索相关概念并整合到提示中；支持动态更新记忆。

Result: 在ARC-AGI基准测试中，相比无记忆基线获得7.5%的相对性能提升；性能随推理计算规模持续扩展；抽象概念在所有测试的计算规模上都优于基线；动态更新记忆优于固定记忆设置。

Conclusion: 概念级外部记忆方法有效实现了测试时持续学习，通过抽象和重用推理模式实现了自我改进，证明了该方法在复杂推理任务中的有效性和可扩展性。

Abstract: While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g. exact query/response pairs, or
summaries tightly coupled with the original problem context) toward
concept-level memory: reusable, modular abstractions distilled from solution
traces and stored in natural language. For future queries, relevant concepts
are selectively retrieved and integrated into the prompt, enabling test-time
continual learning without weight updates. Our design introduces new strategies
for abstracting takeaways from rollouts and retrieving entries for new queries,
promoting reuse and allowing memory to expand with additional experiences. On
the challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over
a strong no-memory baseline with performance continuing to scale with inference
compute. We find abstract concepts to be the most consistent memory design,
outscoring the baseline at all tested inference compute scales. Moreover, we
confirm that dynamically updating memory during test-time outperforms an
otherwise identical fixed memory setting with additional attempts, supporting
the hypothesis that solving more problems and abstracting more patterns to
memory enables further solutions in a form of self-improvement. Code available
at https://github.com/matt-seb-ho/arc_memo.

</details>
