<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 8]
- [cs.CR](#cs.CR) [Total: 17]
- [cs.AI](#cs.AI) [Total: 22]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation](https://arxiv.org/abs/2508.21097)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 本文提出利用检索增强生成（RAG）技术增强大型语言模型，用于量子软件系统的模型到代码转换，实验显示精心设计的提示可将CodeBLEU分数提高四倍。


<details>
  <summary>Details</summary>
Motivation: 量子混合软件系统开发面临异构平台和开发者技能缺乏的挑战，模型驱动方法可以降低成本和风险。

Method: 采用RAG管道整合GitHub上的Qiskit代码样本，从UML模型实例生成量子代码，使用精心设计的提示工程。

Result: 实验结果表明，良好设计的提示可以将CodeBLEU分数提高多达四倍，产生更准确和一致的量子代码。

Conclusion: 该方法为量子软件开发提供了有效解决方案，未来可进一步研究将软件系统模型实例作为RAG管道信息源，以及代码到代码转换等应用。

Abstract: This paper introduces a novel research direction for model-to-text/code
transformations by leveraging Large Language Models (LLMs) that can be enhanced
with Retrieval-Augmented Generation (RAG) pipelines. The focus is on quantum
and hybrid quantum-classical software systems, where model-driven approaches
can help reduce the costs and mitigate the risks associated with the
heterogeneous platform landscape and lack of developers' skills. We validate
one of the proposed ideas regarding generating code out of UML model instances
of software systems. This Python code uses a well-established library, called
Qiskit, to execute on gate-based or circuit-based quantum computers. The RAG
pipeline that we deploy incorporates sample Qiskit code from public GitHub
repositories. Experimental results show that well-engineered prompts can
improve CodeBLEU scores by up to a factor of four, yielding more accurate and
consistent quantum code. However, the proposed research direction can go beyond
this through further investigation in the future by conducting experiments to
address our other research questions and ideas proposed here, such as deploying
software system model instances as the source of information in the RAG
pipelines, or deploying LLMs for code-to-code transformations, for instance,
for transpilation use cases.

</details>


### [2] [Learning to Generate Unit Test via Adversarial Reinforcement Learning](https://arxiv.org/abs/2508.21107)
*Dongjun Lee,Changho Hwang,Kimin Lee*

Main category: cs.SE

TL;DR: UTR是一种通过对抗性学习训练LLM生成高质量单元测试的新题强化学习框架，通过测试生成器和代码生成器的循环对抗训练，产生的测试质量超越了传统监督学习和GPT-4.1等前沿模型


<details>
  <summary>Details</summary>
Motivation: 单元测试在编程中至关重要，但人工编写全面的单元测试靠成本高。虽然大语言模型已用于自动测试生成，但训练LLM生成高质量测试的方法仍然研究不涵

Method: 提出UTR强化学习框架，通过循环训练两个LLM（测试生成器和代码生成器）进行对抗性学习。测试生成器最大化辨别奖励（更好地曓露代码错误），代码生成器最大化代码奖励（更好地通过测试）

Result: 通过UTR训练的Qwen3-4B模型生成的单元测试质量显著高于监督学习的同模型，代码评估结果更接近人工写的真实测试。该方法甚至超越了GPT-4.1等前沿模型

Conclusion: UTR框架通过对抗性学习方式有效地训练LLM生成高质量单元测试，为自动化测试生成领域提供了新的解决方案

Abstract: Unit testing is a core practice in programming, enabling systematic
evaluation of programs produced by human developers or large language models
(LLMs). Given the challenges in writing comprehensive unit tests, LLMs have
been employed to automate test generation, yet methods for training LLMs to
produce high-quality tests remain underexplored. In this work, we propose UTRL,
a novel reinforcement learning framework that trains an LLM to generate
high-quality unit tests given a programming instruction. Our key idea is to
iteratively train two LLMs, the unit test generator and the code generator, in
an adversarial manner via reinforcement learning. The unit test generator is
trained to maximize a discrimination reward, which reflects its ability to
produce tests that expose faults in the code generator's solutions, and the
code generator is trained to maximize a code reward, which reflects its ability
to produce solutions that pass the unit tests generated by the test generator.
In our experiments, we demonstrate that unit tests generated by Qwen3-4B
trained via UTRL show higher quality compared to unit tests generated by the
same model trained via supervised fine-tuning on human-written ground-truth
unit tests, yielding code evaluations that more closely align with those
induced by the ground-truth tests. Moreover, Qwen3-4B trained with UTRL
outperforms frontier models such as GPT-4.1 in generating high-quality unit
tests, highlighting the effectiveness of UTRL in training LLMs for this task.

</details>


### [3] [Automated Bug Triaging using Instruction-Tuned Large Language Models](https://arxiv.org/abs/2508.21156)
*Kiana Kiashemshaki,Arsham Khosravani,Alireza Hosseinpour,Arshia Akhavan*

Main category: cs.SE

TL;DR: 这篇论文提出了一种轻量级框架，利用指令微调的大语言模型通过LoRA适配器和候选约束解码来实现故障分配，在大型项目中展现出良好的性能。


<details>
  <summary>Details</summary>
Motivation: 大型项目中的故障分配任务常常速度慢、不一致，需要一种更高效的解决方案来提升分配质量和效率。

Method: 使用指令微调的大语言模型（LLM）结合LoRA适配器，采用候选约束解码技术确保分配结果的有效性。

Result: 在EclipseJDT和Mozilla数据集上进行测试，模型在短名单质量方面表现优异（Hit at 10达到0.753），虽然Top-1准确率不高。在最新数据上准确率显著提升。

Conclusion: 指令微调的LLM提供了一种实用的替代方案，可以避免费用较高的特征工程和图基方法，具有在实际应用中实现人机协同故障分配的潜力。

Abstract: Bug triaging, the task of assigning new issues to developers, is often slow
and inconsistent in large projects. We present a lightweight framework that
instruction-tuned large language model (LLM) with LoRA adapters and uses
candidate-constrained decoding to ensure valid assignments. Tested on
EclipseJDT and Mozilla datasets, the model achieves strong shortlist quality
(Hit at 10 up to 0.753) despite modest exact Top-1 accuracy. On recent
snapshots, accuracy rises sharply, showing the framework's potential for
real-world, human-in-the-loop triaging. Our results suggest that
instruction-tuned LLMs offer a practical alternative to costly feature
engineering and graph-based methods.

</details>


### [4] [The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management](https://arxiv.org/abs/2508.21433)
*Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov*

Main category: cs.SE

TL;DR: 研究表明，在SWE-agent任务中，简单的观察屏蔽策略比复杂的LLM摘要方法更有效且成本更低，能够以一半的成本达到相似甚至略高的解决率。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的软件工程代理在处理复杂任务时会产生长而昂贵的上下文历史，虽然现有方法使用LLM摘要来解决这个问题，但需要验证这种复杂性是否真的带来性能优势。

Method: 在SWE-agent上对SWE-bench Verified进行系统比较，测试五种不同模型配置，对比原始代理、观察屏蔽策略和LLM摘要策略的性能。

Result: 观察屏蔽策略将成本减半（相比原始代理），同时达到与LLM摘要相似的解决率（54.8% vs 53.8%），在某些情况下甚至略高。

Conclusion: 在SWE-agent任务中，最简单有效的上下文管理策略就是观察屏蔽，复杂LLM摘要方法并未带来显著优势，反而增加了成本。

Abstract: Large Language Model (LLM)-based agents solve complex tasks through iterative
reasoning, exploration, and tool-use, a process that can result in long,
expensive context histories. While state-of-the-art Software Engineering ( SE)
agents like OpenHands or Cursor use LLM-based summarization to tackle this
issue, it is unclear whether the increased complexity offers tangible
performance benefits compared to simply omitting older observations. We present
a systematic comparison of these strategies within SWE-agent on SWE-bench
Verified across five diverse model configurations. We find that a simple
observation-masking strategy halves cost relative to a raw agent while
matching, and sometimes slightly exceeding, the solve rate of LLM
summarization. For example, with Qwen3-Coder 480B, masking improves solve rate
from 53.8% (raw agent) to 54.8%, while remaining competitive with summarization
at a lower cost. These results suggest that, at least within SWE-agent on
SWE-bench Verified, the most effective and efficient context management can be
the simplest. We release code and data for reproducibility

</details>


### [5] [Enhancing Semantic Understanding in Pointer Analysis using Large Language Models](https://arxiv.org/abs/2508.21454)
*Baijun Cheng,Kailong Wang,Ling Shi,Haoyu Wang,Yao Guo,Ding Li,Xiangqun Chen*

Main category: cs.SE

TL;DR: LMPA利用大语言模型增强指针分析，通过识别类似系统API的用户定义函数和增强摘要分析来提高精度和可扩展性


<details>
  <summary>Details</summary>
Motivation: 现有指针分析框架由于对代码语义理解不足，导致对用户定义函数的处理过于保守，传播错误事实。大语言模型的发展为解决这一问题提供了新机遇

Method: 提出LMPA框架，集成LLM到指针分析中：1)识别类似系统API的用户定义函数并进行相应建模；2)推断初始点集；3)引入基于自然语言增强的新型摘要策略

Result: 该方法能够减少错误的跨调用上下文传播，提高指针分析的精度

Conclusion: LMPA展示了将大语言模型集成到指针分析中的潜力，但实现这一愿景仍面临重要挑战

Abstract: Pointer analysis has been studied for over four decades. However, existing
frameworks continue to suffer from the propagation of incorrect facts. A major
limitation stems from their insufficient semantic understanding of code,
resulting in overly conservative treatment of user-defined functions. Recent
advances in large language models (LLMs) present new opportunities to bridge
this gap. In this paper, we propose LMPA (LLM-enhanced Pointer Analysis), a
vision that integrates LLMs into pointer analysis to enhance both precision and
scalability. LMPA identifies user-defined functions that resemble system APIs
and models them accordingly, thereby mitigating erroneous cross-calling-context
propagation. Furthermore, it enhances summary-based analysis by inferring
initial points-to sets and introducing a novel summary strategy augmented with
natural language. Finally, we discuss the key challenges involved in realizing
this vision.

</details>


### [6] [Reusable Test Suites for Reinforcement Learning](https://arxiv.org/abs/2508.21553)
*Jørn Eirik Betten,Quentin Mazouni,Dennis Gross,Pedro Lind,Helge Spieker*

Main category: cs.SE

TL;DR: 提出MPTCS方法，通过多策略测试用例选择来生成可重用的策略无关测试套件，基于可解性、多样性和通用难度来揭示智能体行为的典型缺陷


<details>
  <summary>Details</summary>
Motivation: 现有强化学习策略测试方法生成的测试套件通常针对特定策略定制，对其他策略的相关性不明确，难以验证部署时策略行为的可靠性和性能

Method: 使用一组策略基于难度评分从候选池中选择测试用例，采用受质量-多样性算法启发的离散化通用测试描述符表面来促进测试套件多样性

Result: 评估了难度评分的有效性，分析了方法效果和成本与策略数量的关系，检验了多样性方法对状态空间的覆盖和触发故障行为的能力

Conclusion: MPTCS能够从任何策略测试框架生成的测试用例中提取出可重用的策略无关测试案例，有效揭示智能体行为的典型缺陷

Abstract: Reinforcement learning (RL) agents show great promise in solving sequential
decision-making tasks. However, validating the reliability and performance of
the agent policies' behavior for deployment remains challenging. Most
reinforcement learning policy testing methods produce test suites tailored to
the agent policy being tested, and their relevance to other policies is
unclear. This work presents Multi-Policy Test Case Selection (MPTCS), a novel
automated test suite selection method for RL environments, designed to extract
test cases generated by any policy testing framework based on their
solvability, diversity, and general difficulty. MPTCS uses a set of policies to
select a diverse collection of reusable policy-agnostic test cases that reveal
typical flaws in the agents' behavior. The set of policies selects test cases
from a candidate pool, which can be generated by any policy testing method,
based on a difficulty score. We assess the effectiveness of the difficulty
score and how the method's effectiveness and cost depend on the number of
policies in the set. Additionally, a method for promoting diversity in the test
suite, a discretized general test case descriptor surface inspired by
quality-diversity algorithms, is examined to determine how it covers the state
space and which policies it triggers to produce faulty behaviors.

</details>


### [7] [Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects, Vulnerabilities, and Complexity](https://arxiv.org/abs/2508.21634)
*Domenico Cotroneo,Cristina Improta,Pietro Liguori*

Main category: cs.SE

TL;DR: 大规模对比人类与AI（ChatGPT、DeepSeek-Coder、Qwen-Coder）编写的代码质量，发现AI代码更简单但存在更多安全漏洞和未使用结构，人类代码结构更复杂但维护性问题更多


<details>
  <summary>Details</summary>
Motivation: 随着AI代码助手在软件开发中的广泛应用，需要了解AI生成代码与人类编写代码在可靠性、可维护性和安全性方面的差异

Method: 评估超过50万个Python和Java代码样本，使用正交缺陷分类法分析代码缺陷，使用通用弱点枚举分析安全漏洞，比较三个先进LLM与人类开发者的代码

Result: AI生成的代码通常更简单、重复性更高，但更容易出现未使用的结构和硬编码调试；人类编写的代码结构更复杂，维护性问题更集中；AI生成的代码包含更多高风险安全漏洞

Conclusion: AI和人类编写的代码具有不同的缺陷特征，需要在AI辅助编程中采用专门的质量保证实践

Abstract: As AI code assistants become increasingly integrated into software
development workflows, understanding how their code compares to human-written
programs is critical for ensuring reliability, maintainability, and security.
In this paper, we present a large-scale comparison of code authored by human
developers and three state-of-the-art LLMs, i.e., ChatGPT, DeepSeek-Coder, and
Qwen-Coder, on multiple dimensions of software quality: code defects, security
vulnerabilities, and structural complexity. Our evaluation spans over 500k code
samples in two widely used languages, Python and Java, classifying defects via
Orthogonal Defect Classification and security vulnerabilities using the Common
Weakness Enumeration. We find that AI-generated code is generally simpler and
more repetitive, yet more prone to unused constructs and hardcoded debugging,
while human-written code exhibits greater structural complexity and a higher
concentration of maintainability issues. Notably, AI-generated code also
contains more high-risk security vulnerabilities. These findings highlight the
distinct defect profiles of AI- and human-authored code and underscore the need
for specialized quality assurance practices in AI-assisted programming.

</details>


### [8] [The Integration of Agile Methodologies in DevOps Practices within the Information Technology Industry](https://arxiv.org/abs/2508.21811)
*Ashley Hourigan,Ridewaan Hanslo*

Main category: cs.SE

TL;DR: 这篇论文通过11个半结构化访谈和主题分析，研究了Agile和DevOps实践在IT行业的集成与应用，提出了两者相互关系的新理解。


<details>
  <summary>Details</summary>
Motivation: IT行业对软件交付速度的需求日益增长，需要更快速的产品和服务发布。Agile和DevOps作为现代软件开发方法论，需要研究其在实践中的可行性和适用性。

Method: 采用11个半结构化访谈，对象是来自IT行业不同部门的Agile和DevOps实践者，通过主题分析提取51个唯一代码并综合成19个主题。

Result: 研究发现了Agile方法在DevOps实践中的集成和应用情况，形成了对两者相互关系的新理解，满足了研究目标。

Conclusion: 论文成功识别了Agile方法在DevOps生命周期中的集成应用，为IT行业提供了有关软件开发方法论实践的重要见解。

Abstract: The demand for rapid software delivery in the Information Technology (IT)
industry has significantly intensified, emphasising the need for faster
software products and service releases with enhanced features to meet customer
expectations. Agile methodologies are replacing traditional approaches such as
Waterfall, where flexibility, iterative development and adaptation to change
are favoured over rigid planning and execution. DevOps, a subsequent evolution
from Agile, emphasises collaborative efforts in development and operations
teams, focusing on continuous integration and deployment to deliver resilient
and high-quality software products and services. This study aims to critically
assess both Agile and DevOps practices in the IT industry to identify the
feasibility and applicability of Agile methods in DevOps practices. Eleven
semi-structured interviews were conducted with Agile and DevOps practitioners
in varying capacities across several sectors within the IT industry. Through
thematic analysis, 51 unique codes were extracted and synthesised into 19
themes that reported on each phase of the DevOps lifecycle, specifically
regarding the integration and implementation of Agile methods into DevOps
practices. Based on the findings, a new understanding detailing the
interrelationship of Agile methods in DevOps practices was discussed that met
the research objectives.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [9] [The WASM Cloak: Evaluating Browser Fingerprinting Defenses Under WebAssembly based Obfuscation](https://arxiv.org/abs/2508.21219)
*A H M Nazmus Sakib,Mahsin Bin Akram,Joseph Spracklen,Sahan Kalutarage,Raveen Wijewickrama,Igor Bilogrevic,Murtuza Jadliwala*

Main category: cs.CR

TL;DR: 本文首次系统评估了WebAssembly(WASM)混淆技术对现代浏览器指纹识别防御的影响，发现学术研究中的检测器存在中度脆弱性，而商业浏览器扩展和原生防御则完全有效。


<details>
  <summary>Details</summary>
Motivation: 随着WebAssembly(WASM)的广泛采用，攻击者可以将JavaScript指纹识别脚本转换为WASM二进制格式来混淆恶意逻辑，这可能成为现有防御系统的盲点。

Method: 开发自动化管道将真实世界的JS指纹识别脚本转换为功能性的WASM混淆变体，并测试两类防御：学术文献中的最先进检测器和商业浏览器工具。

Result: 研究发现学术检测器因依赖源代码特征分析而存在中度脆弱性，而浏览器扩展和原生浏览器功能通过API级拦截保持完全有效。

Conclusion: 结果揭示了学术防御策略与实际防御策略之间的差距，为加强针对WASM混淆的检测方法提供了见解，同时也揭示了未来攻击中更隐蔽技术的可能性。

Abstract: Browser fingerprinting defenses have historically focused on detecting
JavaScript(JS)-based tracking techniques. However, the widespread adoption of
WebAssembly (WASM) introduces a potential blind spot, as adversaries can
convert JS to WASM's low-level binary format to obfuscate malicious logic. This
paper presents the first systematic evaluation of how such WASM-based
obfuscation impacts the robustness of modern fingerprinting defenses. We
develop an automated pipeline that translates real-world JS fingerprinting
scripts into functional WASM-obfuscated variants and test them against two
classes of defenses: state-of-the-art detectors in research literature and
commercial, in-browser tools. Our findings reveal a notable divergence:
detectors proposed in the research literature that rely on feature-based
analysis of source code show moderate vulnerability, stemming from outdated
datasets or a lack of WASM compatibility. In contrast, defenses such as browser
extensions and native browser features remained completely effective, as their
API-level interception is agnostic to the script's underlying implementation.
These results highlight a gap between academic and practical defense strategies
and offer insights into strengthening detection approaches against WASM-based
obfuscation, while also revealing opportunities for more evasive techniques in
future attacks.

</details>


### [10] [Locus: Agentic Predicate Synthesis for Directed Fuzzing](https://arxiv.org/abs/2508.21302)
*Jie Zhu,Chihao Shen,Ziyang Li,Jiahao Yu,Yizheng Chen,Kexin Pei*

Main category: cs.CR

TL;DR: Locus是一个新颖的定向模糊测试框架，通过合成语义中间状态谓词来指导测试过程，显著提高了漏洞发现的效率


<details>
  <summary>Details</summary>
Motivation: 现有的定向模糊测试方法依赖分支距离或手动约束，这些方法要么不够精确描述向目标状态的进展，要么难以泛化到不同的目标状态和程序

Method: Locus使用代理框架和程序分析工具自动合成和迭代精化候选谓词，这些谓词捕获模糊测试进度作为语义上有意义的中间状态，作为达到目标状态的里程碑

Result: Locus显著提高了8个最先进模糊测试器的效率，平均加速41.6倍，发现了8个先前未修补的漏洞

Conclusion: Locus通过自动化合成语义中间状态谓词，为定向模糊测试提供了有效的通用解决方案，能够显著提高漏洞发现效率

Abstract: Directed fuzzing aims to find program inputs that lead to specified target
program states. It has broad applications, such as debugging system crashes,
confirming reported bugs, and generating exploits for potential
vulnerabilities. This task is inherently challenging because target states are
often deeply nested in the program, while the search space manifested by
numerous possible program inputs is prohibitively large. Existing approaches
rely on branch distances or manually-specified constraints to guide the search;
however, the branches alone are often insufficient to precisely characterize
progress toward reaching the target states, while the manually specified
constraints are often tailored for specific bug types and thus difficult to
generalize to diverse target states and programs.
  We present Locus, a novel framework to improve the efficiency of directed
fuzzing. Our key insight is to synthesize predicates to capture fuzzing
progress as semantically meaningful intermediate states, serving as milestones
towards reaching the target states. When used to instrument the program under
fuzzing, they can reject executions unlikely to reach the target states, while
providing additional coverage guidance. To automate this task and generalize to
diverse programs, Locus features an agentic framework with program analysis
tools to synthesize and iteratively refine the candidate predicates, while
ensuring the predicates strictly relax the target states to prevent false
rejections via symbolic execution. Our evaluation shows that Locus
substantially improves the efficiency of eight state-of-the-art fuzzers in
discovering real-world vulnerabilities, achieving an average speedup of 41.6x.
So far, Locus has found eight previously unpatched bugs, with one already
acknowledged with a draft patch.

</details>


### [11] [LLM-driven Provenance Forensics for Threat Investigation and Detection](https://arxiv.org/abs/2508.21323)
*Kunal Mukherjee,Murat Kantarcioglu*

Main category: cs.CR

TL;DR: PROVSEEK是一个基于LLM的智能代理框架，用于自动化溯源驱动的取证分析和威胁情报提取，通过结合RAG、思维链推理和多代理协调，在DARPA数据集上取得了显著优于现有方法的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有的取证分析和威胁检测方法在处理复杂的APT攻击时存在局限性，需要一种能够结合系统溯源数据和智能推理的自动化框架来提高分析效率和准确性。

Method: PROVSEEK采用专门的工具链动态检索相关上下文，通过生成精确的上下文感知查询，将向量化的威胁报告知识库与系统溯源数据库融合。框架使用多角色特定代理来缓解幻觉问题，并结合检索增强生成(RAG)和思维链(CoT)推理进行自适应多步分析。

Result: 在DARPA公开数据集上的综合评估显示：在情报提取任务中，PROVSEEK比基于检索的方法在上下文精确度/召回率上提高了34%；在威胁检测任务中，比基线智能AI方法和最先进的溯源入侵检测系统(PIDS)在精确度/召回率上分别提高了22%和29%。

Conclusion: PROVSEEK通过将溯源数据与智能推理相结合，为基于证据的智能取证调查APT攻击建立了新的范式，证明了其在自动化取证分析和威胁检测方面的显著优势。

Abstract: We introduce PROVSEEK, an LLM-powered agentic framework for automated
provenance-driven forensic analysis and threat intelligence extraction.
PROVSEEK employs specialized toolchains to dynamically retrieve relevant
context by generating precise, context-aware queries that fuse a vectorized
threat report knowledge base with data from system provenance databases. The
framework resolves provenance queries, orchestrates multiple role-specific
agents to mitigate hallucinations, and synthesizes structured, ground-truth
verifiable forensic summaries. By combining agent orchestration with
Retrieval-Augmented Generation (RAG) and chain-of-thought (CoT) reasoning,
PROVSEEK enables adaptive multi-step analysis that iteratively refines
hypotheses, verifies supporting evidence, and produces scalable, interpretable
forensic explanations of attack behaviors. By combining provenance data with
agentic reasoning, PROVSEEK establishes a new paradigm for grounded agentic
forecics to investigate APTs. We conduct a comprehensive evaluation on publicly
available DARPA datasets, demonstrating that PROVSEEK outperforms
retrieval-based methods for intelligence extraction task, achieving a 34%
improvement in contextual precision/recall; and for threat detection task,
PROVSEEK achieves 22%/29% higher precision/recall compared to both a baseline
agentic AI approach and State-Of-The-Art (SOTA) Provenance-based Intrusion
Detection System (PIDS).

</details>


### [12] [Risks and Compliance with the EU's Core Cyber Security Legislation](https://arxiv.org/abs/2508.21386)
*Jukka Ruohonen,Jesper Løffler Nielsen,Jakub Skórczynski*

Main category: cs.CR

TL;DR: 欧盟网络安全立法采用风险导向方法，涵盖技术、组织、人为等多维度风险，但存在可接受风险、非概率风险和残余风险等概念缺失，增加了合规复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究欧盟五项核心网络安全立法中风险概念的框架方式，分析这些立法在风险概念上的趋同与分歧，以及法律风险描述中使用的限定词和术语。

Method: 基于定性法律解释和分类构建的方法论，对五项欧盟核心网络安全立法文件进行系统分析。

Result: 五项立法全面覆盖了不同类型的网络安全风险，包括技术、组织、人为安全等风险，以及非人为因素导致的风险。多数立法使用技术方面和资产来构建法律风险概念，其中一项立法采用威胁中心视角。但存在可接受风险、非概率风险和残余风险等显著概念缺失。

Conclusion: 欧盟新网络安全立法显著扩展了基于风险的监管方法，但同时也增加了复杂性和合规负担。论文最后提出了处理合规问题和进行相关研究的实用建议。

Abstract: The European Union (EU) has long favored a risk-based approach to regulation.
Such an approach is also used in recent cyber security legislation enacted in
the EU. Risks are also inherently related to compliance with the new
legislation. Objective: The paper investigates how risks are framed in the EU's
five core cyber security legislative acts, whether the framings indicate
convergence or divergence between the acts and their risk concepts, and what
qualifying words and terms are used when describing the legal notions of risks.
Method : The paper's methodology is based on qualitative legal interpretation
and taxonomy-building. Results: The five acts have an encompassing coverage of
different cyber security risks, including but not limited to risks related to
technical, organizational, and human security as well as those not originating
from man-made actions. Both technical aspects and assets are used to frame the
legal risk notions in many of the legislative acts. A threat-centric viewpoint
is also present in one of the acts. Notable gaps are related to acceptable
risks, non-probabilistic risks, and residual risks. Conclusion: The EU's new
cyber security legislation has significantly extended the risk-based approach
to regulations. At the same time, complexity and compliance burden have
increased. With this point in mind, the paper concludes with a few practical
takeaways about means to deal with compliance and research it.

</details>


### [13] [zkLoRA: Fine-Tuning Large Language Models with Verifiable Security via Zero-Knowledge Proofs](https://arxiv.org/abs/2508.21393)
*Guofu Liao,Taotao Wang,Shengli Zhang,Jiqun Zhang,Shi Long,Dacheng Tao*

Main category: cs.CR

TL;DR: zkLoRA是一个将LoRA微调与零知识证明结合的首个框架，在保护模型参数和训练数据隐私的同时，提供端到端的可验证性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型微调计算需求大，在不可信环境中存在正确性和隐私问题。虽然LoRA等方法降低了资源需求，但在零知识约束下确保安全性和可验证性仍是未解决的挑战。

Method: 采用高级密码学技术（查找参数、和校验协议、多项式承诺）来验证基于Transformer架构中的算术和非算术操作，提供前向传播、反向传播和参数更新的端到端验证。

Result: 通过GPU实现，在LLaMA等开源LLM上实验验证了实用性，可扩展到130亿参数，证明了框架的效率和实用性。

Conclusion: zkLoRA通过将参数高效微调与零知识证明相结合，填补了关键空白，使得LLM能够在敏感或不可信环境中安全可信地部署。

Abstract: Fine-tuning large language models (LLMs) is crucial for adapting them to
specific tasks, yet it remains computationally demanding and raises concerns
about correctness and privacy, particularly in untrusted environments. Although
parameter-efficient methods like Low-Rank Adaptation (LoRA) significantly
reduce resource requirements, ensuring the security and verifiability of
fine-tuning under zero-knowledge constraints remains an unresolved challenge.
To address this, we introduce zkLoRA, the first framework to integrate LoRA
fine-tuning with zero-knowledge proofs (ZKPs), achieving provable security and
correctness. zkLoRA employs advanced cryptographic techniques -- such as lookup
arguments, sumcheck protocols, and polynomial commitments -- to verify both
arithmetic and non-arithmetic operations in Transformer-based architectures.
The framework provides end-to-end verifiability for forward propagation,
backward propagation, and parameter updates during LoRA fine-tuning, while
safeguarding the privacy of model parameters and training data. Leveraging
GPU-based implementations, zkLoRA demonstrates practicality and efficiency
through experimental validation on open-source LLMs like LLaMA, scaling up to
13 billion parameters. By combining parameter-efficient fine-tuning with ZKPs,
zkLoRA bridges a critical gap, enabling secure and trustworthy deployment of
LLMs in sensitive or untrusted environments.

</details>


### [14] [RepoMark: A Code Usage Auditing Framework for Code Large Language Models](https://arxiv.org/abs/2508.21432)
*Wenjie Qu,Yuguang Zhou,Bo Wang,Wengrui Zheng,Yuexin Li,Jinyuan Jia,Jiaheng Zhang*

Main category: cs.CR

TL;DR: RepoMark是一个创新的数据标记框架，用于审计代码大语言模型的训练数据使用情况，帮助代码仓库所有者验证其代码是否被用于模型训练，具有高检测成功率和理论保证。


<details>
  <summary>Details</summary>
Motivation: 随着代码大语言模型的快速发展，使用开源代码仓库进行训练引发了严重的伦理和法律问题，特别是数据授权和开源许可证合规性方面的担忧，需要一种透明化的审计方法。

Method: 提出RepoMark框架，通过生成多个语义等价的代码变体来植入数据标记，在检测阶段采用新颖的基于排序的假设检验方法来检测模型记忆，确保语义保持、不可感知性和理论误检率保证。

Result: 实验表明RepoMark在5%的严格误检率保证下，对小代码仓库的检测成功率超过90%，显著优于现有数据标记技术（准确率低于55%）。

Conclusion: RepoMark是一个强大、理论可靠且有前景的解决方案，能够增强代码大语言模型训练的透明度，保护仓库所有者的权益。

Abstract: The rapid development of Large Language Models (LLMs) for code generation has
transformed software development by automating coding tasks with unprecedented
efficiency.
  However, the training of these models on open-source code repositories (e.g.,
from GitHub) raises critical ethical and legal concerns, particularly regarding
data authorization and open-source license compliance. Developers are
increasingly questioning whether model trainers have obtained proper
authorization before using repositories for training, especially given the lack
of transparency in data collection.
  To address these concerns, we propose a novel data marking framework RepoMark
to audit the data usage of code LLMs. Our method enables repository owners to
verify whether their code has been used in training, while ensuring semantic
preservation, imperceptibility, and theoretical false detection rate (FDR)
guarantees. By generating multiple semantically equivalent code variants,
RepoMark introduces data marks into the code files, and during detection,
RepoMark leverages a novel ranking-based hypothesis test to detect memorization
within the model. Compared to prior data auditing approaches, RepoMark
significantly enhances sample efficiency, allowing effective auditing even when
the user's repository possesses only a small number of code files.
  Experiments demonstrate that RepoMark achieves a detection success rate over
90\% on small code repositories under a strict FDR guarantee of 5\%. This
represents a significant advancement over existing data marking techniques, all
of which only achieve accuracy below 55\% under identical settings. This
further validates RepoMark as a robust, theoretically sound, and promising
solution for enhancing transparency in code LLM training, which can safeguard
the rights of repository owners.

</details>


### [15] [Time Tells All: Deanonymization of Blockchain RPC Users with Zero Transaction Fee (Extended Version)](https://arxiv.org/abs/2508.21440)
*Shan Wang,Ming Yang,Yu Liu,Yue Zhang,Shuaiqing Zhang,Zhen Ling,Jiannong Cao,Xinwen Fu*

Main category: cs.CR

TL;DR: 通过分析RPC服务用户查询交易状态的TCP数据包时间戳与公链上交易确认时间的相关性，实现将IP地址与匿名匿名链接的攻击


<details>
  <summary>Details</summary>
Motivation: RPC服务在提供便利的同时引入了严重隐私风险，现有攻击方法或不适用于匿名链RPC用户，或需要主动网络监听且产生交易费用

Method: 偏裂攻击者监控网络边界路由器或互联网交换点的流量，通过对比TCP数据包时间戳与公有账本上交易确认时间的时间相关性，将IP地址与匿名链匿名进行关联

Result: 攻击成功率超过95%，在以太坊、比特币和Solana等多个匿名链网络上有效工作，且不产生任何交易费用

Conclusion: 这种零成本的被动攻击显示了RPC服务在匿名性保护方面的严重漏洞，需要重新考虑匿名链RPC访问的隐私安全问题

Abstract: Remote Procedure Call (RPC) services have become a primary gateway for users
to access public blockchains. While they offer significant convenience, RPC
services also introduce critical privacy challenges that remain insufficiently
examined. Existing deanonymization attacks either do not apply to blockchain
RPC users or incur costs like transaction fees assuming an active network
eavesdropper. In this paper, we propose a novel deanonymization attack that can
link an IP address of a RPC user to this user's blockchain pseudonym. Our
analysis reveals a temporal correlation between the timestamps of transaction
confirmations recorded on the public ledger and those of TCP packets sent by
the victim when querying transaction status. We assume a strong passive
adversary with access to network infrastructure, capable of monitoring traffic
at network border routers or Internet exchange points. By monitoring network
traffic and analyzing public ledgers, the attacker can link the IP address of
the TCP packet to the pseudonym of the transaction initiator by exploiting the
temporal correlation. This deanonymization attack incurs zero transaction fee.
We mathematically model and analyze the attack method, perform large-scale
measurements of blockchain ledgers, and conduct real-world attacks to validate
the attack. Our attack achieves a high success rate of over 95% against normal
RPC users on various blockchain networks, including Ethereum, Bitcoin and
Solana.

</details>


### [16] [SoK: Large Language Model-Generated Textual Phishing Campaigns End-to-End Analysis of Generation, Characteristics, and Detection](https://arxiv.org/abs/2508.21457)
*Fengchao Chen,Tingmin Wu,Van Nguyen,Carsten Rudolph*

Main category: cs.CR

TL;DR: 首个系统化知识(SoK)研究，分析LLM生成的故意邮件攻击，提出Generation-Characterization-Defense框架，系统化了LLM故意邮件与传统故意邮件在方法论、安全视角、数据依赖和评估实践方面的差异。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM助力故意邮件攻击研究增多，但缺乏整合的系统性研究。文本故意邮件因低成本、可扩展性和隐藏性而占主导，LLM更是将其升级为"故意邮件即服务"攻击。

Method: 提出Generation-Characterization-Defense(GenCharDef)框架，进行端到端分析，涵盖生成技术、攻击特征和防御策略。通过系统化方式对比LLM故意邮件与传统故意邮件的差异。

Result: 形成了首个关于LLM生成故意邮件的系统化知识框架，突出了LLM驱动故意邮件的独特挑战。

Conclusion: 该框架为理解时代发展的威胁场景提供了一致基础，并指导设计更强固的防御策略。

Abstract: Phishing is a pervasive form of social engineering in which attackers
impersonate trusted entities to steal information or induce harmful actions.
Text-based phishing dominates for its low cost, scalability, and
concealability, advantages recently amplified by large language models (LLMs)
that enable ``Phishing-as-a-Service'' attacks at scale within minutes. Despite
the growing research into LLM-facilitated phishing attacks, consolidated
systematic research on the phishing attack life cycle remains scarce. In this
work, we present the first systematization of knowledge (SoK) on LLM-generated
phishing, offering an end-to-end analysis that spans generation techniques,
attack features, and mitigation strategies. We introduce
Generation-Characterization-Defense (GenCharDef), which systematizes the ways
in which LLM-generated phishing differs from traditional phishing across
methodologies, security perspectives, data dependencies, and evaluation
practices. This framework highlights unique challenges of LLM-driven phishing,
providing a coherent foundation for understanding the evolving threat landscape
and guiding the design of more resilient defenses.

</details>


### [17] [Detecting Stealthy Data Poisoning Attacks in AI Code Generators](https://arxiv.org/abs/2508.21636)
*Cristina Improta*

Main category: cs.CR

TL;DR: 本文系统研究了现有数据投毒检测方法在无触发器攻击下的有效性，发现现有方法难以检测这种隐蔽的投毒攻击


<details>
  <summary>Details</summary>
Motivation: 深度学习代码生成模型依赖大量网络数据，容易遭受数据投毒攻击，特别是无触发器的隐蔽攻击难以被检测

Method: 对三个DL模型(CodeBERT、CodeT5+、AST-T5)进行针对性投毒，评估谱签名分析、激活聚类和静态分析三种防御方法

Result: 所有方法都难以检测无触发器投毒，基于表征的方法无法隔离投毒样本，静态分析存在假阳性和假阴性

Conclusion: 需要开发更鲁棒、不依赖触发器的防御方法来保护AI辅助代码生成系统

Abstract: Deep learning (DL) models for natural language-to-code generation have become
integral to modern software development pipelines. However, their heavy
reliance on large amounts of data, often collected from unsanitized online
sources, exposes them to data poisoning attacks, where adversaries inject
malicious samples to subtly bias model behavior. Recent targeted attacks
silently replace secure code with semantically equivalent but vulnerable
implementations without relying on explicit triggers to launch the attack,
making it especially hard for detection methods to distinguish clean from
poisoned samples. We present a systematic study on the effectiveness of
existing poisoning detection methods under this stealthy threat model.
Specifically, we perform targeted poisoning on three DL models (CodeBERT,
CodeT5+, AST-T5), and evaluate spectral signatures analysis, activation
clustering, and static analysis as defenses. Our results show that all methods
struggle to detect triggerless poisoning, with representation-based approaches
failing to isolate poisoned samples and static analysis suffering false
positives and false negatives, highlighting the need for more robust,
trigger-independent defenses for AI-assisted code generation.

</details>


### [18] [Towards a Decentralized IoT Onboarding for Smart Homes Using Consortium Blockchain](https://arxiv.org/abs/2508.21480)
*Narges Dadkhah,Khan Reaz,Gerhard Wunder*

Main category: cs.CR

TL;DR: 本文提出了一种基于联盟区块链的去中心化智能家庭设备入网框架，解决传统PKI模型的安全风险和用户主权限制问题。


<details>
  <summary>Details</summary>
Motivation: 智能家庭和IoT安全系统的普及带来了便利性和安全性提升机遇，但传统的入网设备方式存在安全风险、中心化控制和用户主权限制等挑战，限制了IoT解决方案的可扩展部署。

Method: 提出了一种新的入网框架，基于现有网络层入网技术并扩展到应用层，集成了联盟区块链技术来实现去中心化入网机制，支持设备注册、密钥撤销、访问控制管理和风险检测等功能。

Result: 使用Tamarin Prover在Dolev-Yao攻击模型下对协议进行了形式化分析，验证了认证、令牌完整性、密钥保密性和公共通道弹性。原型实现显示验证完成时间仅0.34秒，具有良好的可扩展性。性能评估显示该方案能够处理不同工作负荷，保持高吞吐量、低延迟，支持近实时IoT数据处理。

Conclusion: 该研究提出的基于区块链的去中心化入网框架有效解决了传统智能家庭设备入网的安全和信任挑战，提供了更高的透明性、安全性和监控能力，适合约束设备和多方参与者场景，为可扩展IoT解决方案的普及提供了技术支撑。

Abstract: The increasing adoption of smart home devices and IoT-based security systems
presents significant opportunities to enhance convenience, safety, and risk
management for homeowners and service providers. However, secure
onboarding-provisioning credentials and establishing trust with cloud
platforms-remains a considerable challenge. Traditional onboarding methods
often rely on centralized Public Key Infrastructure (PKI) models and
manufacturer-controlled keys, which introduce security risks and limit the
user's digital sovereignty. These limitations hinder the widespread deployment
of scalable IoT solutions. This paper presents a novel onboarding framework
that builds upon existing network-layer onboarding techniques and extends them
to the application layer to address these challenges. By integrating consortium
blockchain technology, we propose a decentralized onboarding mechanism that
enhances transparency, security, and monitoring for smart home architectures.
The architecture supports device registration, key revocation, access control
management, and risk detection through event-driven alerts across dedicated
blockchain channels and smart contracts. To evaluate the framework, we formally
model the protocol using the Tamarin Prover under the Dolev-Yao adversary
model. The analysis focuses on authentication, token integrity, key
confidentiality, and resilience over public channels. A prototype
implementation demonstrates the system's viability in smart home settings, with
verification completing in 0.34 seconds, highlighting its scalability and
suitability for constrained devices and diverse stakeholders. Additionally,
performance evaluation shows that the blockchain-based approach effectively
handles varying workloads, maintains high throughput and low latency, and
supports near real-time IoT data processing.

</details>


### [19] [Generalized Encrypted Traffic Classification Using Inter-Flow Signals](https://arxiv.org/abs/2508.21558)
*Federica Bianchi,Edoardo Di Paolo,Angelo Spognardi*

Main category: cs.CR

TL;DR: 提出了一种基于原始PCAP数据的加密流量分类模型，利用创新的跨流信号表示方法，在多个分类任务和数据集上优于现有方法，最高准确率达99%


<details>
  <summary>Details</summary>
Motivation: 现有加密流量分类方法通常需要先验假设且缺乏通用性，需要一种能够直接处理原始数据、跨任务通用的分类模型

Method: 开发了创新的跨流信号表示方法，捕获流间时间相关性和数据包量分布，直接在原始PCAP数据上操作，无需流量类型先验假设

Result: 在几乎所有分类任务和大多数数据集上都超越了现有成熟方法，某些情况下准确率达到99%，表现出优异的鲁棒性和适应性

Conclusion: 该模型通过创新的跨流信号表示方法，实现了对加密流量的高效准确分类，具有很好的通用性和实用性

Abstract: In this paper, we present a novel encrypted traffic classification model that
operates directly on raw PCAP data without requiring prior assumptions about
traffic type. Unlike existing methods, it is generalizable across multiple
classification tasks and leverages inter-flow signals - an innovative
representation that captures temporal correlations and packet volume
distributions across flows. Experimental results show that our model
outperforms well-established methods in nearly every classification task and
across most datasets, achieving up to 99% accuracy in some cases, demonstrating
its robustness and adaptability.

</details>


### [20] [Agentic Discovery and Validation of Android App Vulnerabilities](https://arxiv.org/abs/2508.21579)
*Ziyue Wang,Liyi Zhou*

Main category: cs.CR

TL;DR: A2是一个Android漏洞检测系统，通过智能代理发现和验证漏洞，显著提高检测准确率并自动生成可利用的PoC证明，在基准测试中达到78.3%覆盖率，在真实应用中发现了104个零日漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有Android漏洞检测工具产生大量低信号警告，分析师需要花费数天时间进行筛选，而真正可利用的漏洞往往被遗漏，造成安全流程瓶颈。

Method: A2采用两阶段方法：(i)智能漏洞发现-结合语义理解和传统安全工具分析应用安全；(ii)智能漏洞验证-系统性地在Android多模态攻击面（UI交互、组件通信、文件操作、加密计算）上验证漏洞。

Result: 在Ghera基准测试(n=60)中达到78.3%覆盖率，远超现有最佳分析器(如APKHunt 30.0%)。生成82个推测性漏洞发现，其中51个生成可工作的PoC证明。在169个生产APK中发现104个零日漏洞，其中57个(54.8%)自动生成PoC验证。

Conclusion: A2系统通过模拟安全专家分析方法，显著提高了Android漏洞检测的准确性和效率，能够自动生成可利用证明，解决了传统工具警告泛滥和真阳性率低的问题。

Abstract: Existing Android vulnerability detection tools overwhelm teams with thousands
of low-signal warnings yet uncover few true positives. Analysts spend days
triaging these results, creating a bottleneck in the security pipeline.
Meanwhile, genuinely exploitable vulnerabilities often slip through, leaving
opportunities open to malicious counterparts.
  We introduce A2, a system that mirrors how security experts analyze and
validate Android vulnerabilities through two complementary phases: (i) Agentic
Vulnerability Discovery, which reasons about application security by combining
semantic understanding with traditional security tools; and (ii) Agentic
Vulnerability Validation, which systematically validates vulnerabilities across
Android's multi-modal attack surface-UI interactions, inter-component
communication, file system operations, and cryptographic computations.
  On the Ghera benchmark (n=60), A2 achieves 78.3% coverage, surpassing
state-of-the-art analyzers (e.g., APKHunt 30.0%). Rather than overwhelming
analysts with thousands of warnings, A2 distills results into 82 speculative
vulnerability findings, including 47 Ghera cases and 28 additional true
positives. Crucially, A2 then generates working Proof-of-Concepts (PoCs) for 51
of these speculative findings, transforming them into validated vulnerability
findings that provide direct, self-confirming evidence of exploitability.
  In real-world evaluation on 169 production APKs, A2 uncovers 104
true-positive zero-day vulnerabilities. Among these, 57 (54.8%) are
self-validated with automatically generated PoCs, including a medium-severity
vulnerability in a widely used application with over 10 million installs.

</details>


### [21] [Condense to Conduct and Conduct to Condense](https://arxiv.org/abs/2508.21602)
*Tomasz Kazana*

Main category: cs.CR

TL;DR: 本文首次构建了低传导度置换的具体实例，并证明了低传导度置换与多源某处压缩器的信息论特性等价


<details>
  <summary>Details</summary>
Motivation: Dodis等人提出了置换传导度的概念并开始寻找低传导度置换，本文旨在解决这一开放性问题并提供具体实例

Method: 通过信息论方法，证明低传导度置换与多源某处压缩器在信息论特性上的等价关系

Result: 成功构造了首个低传导度置换实例，并建立了低传导度置换与多源某处压缩器的等价性

Conclusion: 本文不仅提供了所需的低传导度置换实例，还从信息论角度完整刻画了该问题的本质特征

Abstract: In this paper we give the first examples of low-conductance permutations. The
notion of conductance of permutations was introduced in the paper
"Indifferentiability of Confusion-Diffusion Networks" by Dodis et al., where
the search for low-conductance permutations was initiated and motivated. In
this paper we not only give the desired examples, but also make a general
characterization of the problem -- i.e. we show that low-conductance
permutations are equivalent to permutations that have the information-theoretic
properties of the so-called Multi-Source-Somewhere-Condensers.

</details>


### [22] [Hybrid Cryptographic Monitoring System for Side-Channel Attack Detection on PYNQ SoCs](https://arxiv.org/abs/2508.21606)
*Nishant Chinnasami,Rasha Karakchi*

Main category: cs.CR

TL;DR: 提出了一种结合统计阈值和机器学习（随机森林）的轻量级双检测框架，用于AES-128加密在嵌入式系统中的实时异常检测，无需修改AES内部结构或依赖硬件性能计数器。


<details>
  <summary>Details</summary>
Motivation: AES-128加密虽然在理论上安全，但在嵌入式系统实际部署中容易受到时序和故障注入攻击，需要一种轻量级的实时异常检测方案。

Method: 通过模拟延迟和密文损坏来收集时序和数据特征，评估两种策略：基于执行时间的统计阈值方法和基于块级异常的随机森林分类器。在CPU和FPGA（PYNQ-Z1）平台上实现。

Result: 机器学习方法在准确性上优于静态阈值方法，同时在嵌入式平台上保持实时可行性。

Conclusion: 该框架特别适用于低功耗、资源受限的系统，能够在检测准确性和计算效率之间取得良好平衡。

Abstract: AES-128 encryption is theoretically secure but vulnerable in practical
deployments due to timing and fault injection attacks on embedded systems. This
work presents a lightweight dual-detection framework combining statistical
thresholding and machine learning (ML) for real-time anomaly detection. By
simulating anomalies via delays and ciphertext corruption, we collect timing
and data features to evaluate two strategies: (1) a statistical threshold
method based on execution time and (2) a Random Forest classifier trained on
block-level anomalies. Implemented on CPU and FPGA (PYNQ-Z1), our results show
that the ML approach outperforms static thresholds in accuracy, while
maintaining real-time feasibility on embedded platforms. The framework operates
without modifying AES internals or relying on hardware performance counters.
This makes it especially suitable for low-power, resource-constrained systems
where detection accuracy and computational efficiency must be balanced.

</details>


### [23] [I Stolenly Swear That I Am Up to (No) Good: Design and Evaluation of Model Stealing Attacks](https://arxiv.org/abs/2508.21654)
*Daryna Oliynyk,Rudolf Mayer,Kathrin Grosse,Andreas Rauber*

Main category: cs.CR

TL;DR: 这篇论文首次提出了模型盗窃攻击的标准化评估方法，通过分析图像分类模型攻击案例，提出了完整的威胁模型和攻击比较框架，以及攻击开发的最佳实践和研究方向。


<details>
  <summary>Details</summary>
Motivation: 目前模型盗窃攻击领域的设计和评估缺乏标准化，导致不同研究工作难以比较和评估进展。论文旨在填补这一空白，为模型盗窃攻击提供标准化的设计和评估指南。

Method: 采用系统性研究方法，重点分析了图像分类模型的盗窃攻击案例。提出了第一个完整的威胁模型，并开发了攻击比较框架。分析了相关工作的攻击设置，以了解研究重点和模型类型。

Result: 研究提出了攻击开发的最佳实践，包括实验前、实验中和实验后的建议。得出了一个广泛的开政研究问题清单，为模型盗窃攻击评估提供了指导。

Conclusion: 论文成功建立了第一个通用的模型盗窃攻击评估方法，这些发现和建议同样适用于其他问题领域，有助于推动该领域的标准化和可比较研究。

Abstract: Model stealing attacks endanger the confidentiality of machine learning
models offered as a service. Although these models are kept secret, a malicious
party can query a model to label data samples and train their own substitute
model, violating intellectual property. While novel attacks in the field are
continually being published, their design and evaluations are not standardised,
making it challenging to compare prior works and assess progress in the field.
This paper is the first to address this gap by providing recommendations for
designing and evaluating model stealing attacks. To this end, we study the
largest group of attacks that rely on training a substitute model -- those
attacking image classification models. We propose the first comprehensive
threat model and develop a framework for attack comparison. Further, we analyse
attack setups from related works to understand which tasks and models have been
studied the most. Based on our findings, we present best practices for attack
development before, during, and beyond experiments and derive an extensive list
of open research questions regarding the evaluation of model stealing attacks.
Our findings and recommendations also transfer to other problem domains, hence
establishing the first generic evaluation methodology for model stealing
attacks.

</details>


### [24] [Cybersecurity AI: Hacking the AI Hackers via Prompt Injection](https://arxiv.org/abs/2508.21669)
*Víctor Mayoral-Vilches,Per Mannermaa Rynning*

Main category: cs.CR

TL;DR: 论文展示了如何通过提示注入攻击将AI驱动的网络安全工具转变为攻击目标，这种攻击类似于XSS漏洞，恶意文本隐藏在可信内容中，当系统处理时会转变为意外指令。


<details>
  <summary>Details</summary>
Motivation: 研究AI网络安全工具面临的新型安全威胁，特别是提示注入攻击对AI代理的潜在危害，这些攻击可能让攻击者获得系统访问权限。

Method: 针对网络安全AI框架及其CLI工具进行概念验证攻击，展示精心构造的响应如何劫持AI代理的执行流程，并开发多层防御机制来缓解此类攻击。

Result: 发现提示注入是基于LLM架构中反复出现的系统性安全问题，需要像传统Web应用处理XSS那样投入专门工作来解决。

Conclusion: 提示注入攻击是AI安全领域的重要威胁，需要安全社区投入持续努力来应对，类似于历史上处理XSS漏洞的经验。

Abstract: We demonstrate how AI-powered cybersecurity tools can be turned against
themselves through prompt injection attacks. Prompt injection is reminiscent of
cross-site scripting (XSS): malicious text is hidden within seemingly trusted
content, and when the system processes it, that text is transformed into
unintended instructions. When AI agents designed to find and exploit
vulnerabilities interact with malicious web servers, carefully crafted reponses
can hijack their execution flow, potentially granting attackers system access.
We present proof-of-concept exploits against the Cybersecurity AI (CAI)
framework and its CLI tool, and detail our mitigations against such attacks in
a multi-layered defense implementation. Our findings indicate that prompt
injection is a recurring and systemic issue in LLM-based architectures, one
that will require dedicated work to address, much as the security community has
had to do with XSS in traditional web applications.

</details>


### [25] [OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization](https://arxiv.org/abs/2508.21727)
*Jiazheng Xing,Hai Ci,Hongbin Xu,Hangjie Yuan,Yong Liu,Mike Zheng Shou*

Main category: cs.CR

TL;DR: OptMark是一种基于优化的扩散图像水印方法，通过在去噪过程中嵌入结构性和细节性水印，实现鲁棒的多比特水印嵌入，同时使用伴随梯度方法将内存使用从O(N)降低到O(1)。


<details>
  <summary>Details</summary>
Motivation: 当前扩散水印方法存在局限性：零比特水印缺乏大规模用户追踪能力，而多比特方法对图像变换或生成攻击敏感，缺乏全面的鲁棒性。

Method: 在扩散去噪过程的中间潜在空间中嵌入鲁棒多比特水印，早期插入结构性水印抵抗生成攻击，晚期插入细节水印抵抗图像变换，使用定制正则化项保持图像质量和不可感知性，采用伴随梯度方法降低内存消耗。

Result: 实验结果表明OptMark实现了不可见的多比特水印，同时对值度量变换、几何变换、编辑和再生攻击具有鲁棒性。

Conclusion: OptMark提供了一种有效的水印解决方案，解决了当前扩散水印方法的局限性，在保持图像质量的同时实现了全面的鲁棒性保护。

Abstract: Watermarking diffusion-generated images is crucial for copyright protection
and user tracking. However, current diffusion watermarking methods face
significant limitations: zero-bit watermarking systems lack the capacity for
large-scale user tracking, while multi-bit methods are highly sensitive to
certain image transformations or generative attacks, resulting in a lack of
comprehensive robustness. In this paper, we propose OptMark, an
optimization-based approach that embeds a robust multi-bit watermark into the
intermediate latents of the diffusion denoising process. OptMark strategically
inserts a structural watermark early to resist generative attacks and a detail
watermark late to withstand image transformations, with tailored regularization
terms to preserve image quality and ensure imperceptibility. To address the
challenge of memory consumption growing linearly with the number of denoising
steps during optimization, OptMark incorporates adjoint gradient methods,
reducing memory usage from O(N) to O(1). Experimental results demonstrate that
OptMark achieves invisible multi-bit watermarking while ensuring robust
resilience against valuemetric transformations, geometric transformations,
editing, and regeneration attacks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [26] [Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding](https://arxiv.org/abs/2508.21204)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 该研究探讨了架构归纳偏置如何影响大语言模型在指导性对话中的认知行为，通过引入符号支架机制和短期记忆模式来促进苏格拉底式辅导中的结构化推理。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型架构中的归纳偏置如何影响其在教学对话中的认知行为，旨在通过结构化机制提升模型的适应性推理能力。

Method: 采用符号支架机制配合短期记忆模式，通过五个系统变体的控制性消融实验，使用专家设计的评分标准评估模型输出。

Result: 完整系统在所有基线变体中表现最优，移除记忆或符号结构会显著降低关键认知行为（抽象、适应性探询和概念连续性）。

Conclusion: 架构支架能够可靠地塑造大语言模型中涌现的教学策略，支持处理层面的解释，表明结构性机制对模型认知行为具有重要影响。

Abstract: We study how architectural inductive biases influence the cognitive behavior
of large language models (LLMs) in instructional dialogue. We introduce a
symbolic scaffolding mechanism paired with a short-term memory schema designed
to promote adaptive, structured reasoning in Socratic tutoring. Using
controlled ablation across five system variants, we evaluate model outputs via
expert-designed rubrics covering scaffolding, responsiveness, symbolic
reasoning, and conversational memory. We present preliminary results using an
LLM-based evaluation framework aligned to a cognitively grounded rubric. This
enables scalable, systematic comparisons across architectural variants in
early-stage experimentation. The preliminary results show that our full system
consistently outperforms baseline variants. Analysis reveals that removing
memory or symbolic structure degrades key cognitive behaviors, including
abstraction, adaptive probing, and conceptual continuity. These findings
support a processing-level account in which architectural scaffolds can
reliably shape emergent instructional strategies in LLMs.

</details>


### [27] [Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs](https://arxiv.org/abs/2508.21238)
*Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman*

Main category: cs.AI

TL;DR: 本文评估了GraphRAG在阿尔茨海默病领域的应用效果，与标准GPT-4o相比，GraphRAG在回答专业医学问题时提供更可靠和可追溯的响应。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学研究中面临幻觉、领域知识有限和缺乏可追溯性等挑战，特别是在需要深度专业知识的生物医学领域如阿尔茨海默病研究中。

Method: 构建包含50篇论文和70个专家问题的阿尔茨海默病数据库，建立GraphRAG知识库，使用GPT-4o作为LLM，比较GraphRAG与标准GPT-4o的回答质量，并评估RAG和GraphRAG系统的可追溯性。

Result: GraphRAG系统在阿尔茨海默病领域的问题回答中表现出比标准LLM更好的质量和可追溯性。

Conclusion: GraphRAG是提升专业领域问答可靠性的有效方法，研究提供了易于使用的界面和预建数据库供研究者测试RAG和GraphRAG性能。

Abstract: In the past two years, large language model (LLM)-based chatbots, such as
ChatGPT, have revolutionized various domains by enabling diverse task
completion and question-answering capabilities. However, their application in
scientific research remains constrained by challenges such as hallucinations,
limited domain-specific knowledge, and lack of explainability or traceability
for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has
emerged as a promising approach to improving chatbot reliability by integrating
domain-specific contextual information before response generation, addressing
some limitations of standard LLMs. Despite its potential, there are only
limited studies that evaluate GraphRAG on specific domains that require
intensive knowledge, like Alzheimer's disease or other biomedical domains. In
this paper, we assess the quality and traceability of two popular GraphRAG
systems. We compile a database of 50 papers and 70 expert questions related to
Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as
the LLM for answering queries. We then compare the quality of responses
generated by GraphRAG with those from a standard GPT-4o model. Additionally, we
discuss and evaluate the traceability of several Retrieval-Augmented Generation
(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a
pre-built Alzheimer's disease database for researchers to test the performance
of both standard RAG and GraphRAG.

</details>


### [28] [MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems](https://arxiv.org/abs/2508.21307)
*Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala*

Main category: cs.AI

TL;DR: MultiFluxAI是一个创新的AI平台，用于解决产品工程中管理和集成大量不同数据源的挑战，通过生成式AI、向量化和智能编排技术提供动态的上下文感知响应。


<details>
  <summary>Details</summary>
Motivation: 解决产品工程领域中管理和集成多样化数据源的挑战，提升数字生态系统中用户参与度，应对当前和新型服务相关查询的需求。

Method: 利用先进的AI技术，包括生成式AI、向量化和智能编排（agentic orchestration），提供动态和上下文感知的复杂查询响应。

Result: 开发了一个能够处理不同数据源并提供智能响应的AI平台，增强了用户参与度和查询处理能力。

Conclusion: MultiFluxAI通过整合多种AI技术，成功解决了产品工程中的数据集成和管理问题，为数字生态系统提供了更高效的查询响应服务。

Abstract: MultiFluxAI is an innovative AI platform developed to address the challenges
of managing and integrating vast, disparate data sources in product engineering
across application domains. It addresses both current and new service related
queries that enhance user engagement in the digital ecosystem. This platform
leverages advanced AI techniques, such as Generative AI, vectorization, and
agentic orchestration to provide dynamic and context-aware responses to complex
user queries.

</details>


### [29] [Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation](https://arxiv.org/abs/2508.21320)
*Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao*

Main category: cs.AI

TL;DR: LINKO是一个基于大语言模型的集成本体学习框架，通过同时利用多个医学本体图，在异构本体系统内和跨系统进行双轴知识传播，以增强医学概念表示学习。


<details>
  <summary>Details</summary>
Motivation: 现有文献主要关注单一本体系统或多个孤立本体系统的领域知识整合，缺乏统一的学习结构，导致概念表示学习局限于本体内部关系，忽略了跨本体连接。

Method: 1) 使用LLM通过工程化提示（包含概念描述和本体上下文）为ontology概念嵌入提供图检索增强初始化；2) 通过双轴知识传播联合学习不同本体图中的医学概念：a) 本体内部垂直传播跨越层次本体级别，b) 本体间水平传播在每个级别并行进行。

Result: 在两个公共数据集上的广泛实验验证了LINKO优于最先进基线方法的性能。作为与现有EHR预测模型兼容的插件编码器，LINKO在数据有限和罕见疾病预测场景中表现出更强的鲁棒性。

Conclusion: LINKO框架成功整合了多个医学本体系统的知识，通过双轴传播机制有效提升了医学概念表示学习的效果，特别是在数据稀缺和罕见疾病预测方面表现出色。

Abstract: Medical ontology graphs map external knowledge to medical codes in electronic
health records via structured relationships. By leveraging domain-approved
connections (e.g., parent-child), predictive models can generate richer medical
concept representations by incorporating contextual information from related
concepts. However, existing literature primarily focuses on incorporating
domain knowledge from a single ontology system, or from multiple ontology
systems (e.g., diseases, drugs, and procedures) in isolation, without
integrating them into a unified learning structure. Consequently, concept
representation learning often remains limited to intra-ontology relationships,
overlooking cross-ontology connections. In this paper, we propose LINKO, a
large language model (LLM)-augmented integrative ontology learning framework
that leverages multiple ontology graphs simultaneously by enabling dual-axis
knowledge propagation both within and across heterogeneous ontology systems to
enhance medical concept representation learning. Specifically, LINKO first
employs LLMs to provide a graph-retrieval-augmented initialization for ontology
concept embedding, through an engineered prompt that includes concept
descriptions, and is further augmented with ontology context. Second, our
method jointly learns the medical concepts in diverse ontology graphs by
performing knowledge propagation in two axes: (1) intra-ontology vertical
propagation across hierarchical ontology levels and (2) inter-ontology
horizontal propagation within every level in parallel. Last, through extensive
experiments on two public datasets, we validate the superior performance of
LINKO over state-of-the-art baselines. As a plug-in encoder compatible with
existing EHR predictive models, LINKO further demonstrates enhanced robustness
in scenarios involving limited data availability and rare disease prediction.

</details>


### [30] [Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models](https://arxiv.org/abs/2508.21365)
*Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang*

Main category: cs.AI

TL;DR: TiG框架通过将强化学习决策重新构建为语言建模任务，让大语言模型在游戏环境中直接交互学习程序性知识，同时保持推理和解释能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理任务上表现出色，但在简单交互任务中表现不佳，这凸显了陈述性知识和程序性知识之间的关键差距

Method: 将基于强化学习的决策重新表述为语言建模任务：LLMs生成语言引导的策略，通过基于环境反馈的在线强化学习迭代优化

Result: TiG成功弥合了陈述性和程序性知识之间的差距，以显著更低的数据和计算需求实现与传统RL方法相竞争的性能

Conclusion: TiG框架不仅提高了交互任务的性能，还通过逐步自然语言解释大大提高了复杂交互任务的透明度和可解释性

Abstract: Large language models (LLMs) excel at complex reasoning tasks such as
mathematics and coding, yet they frequently struggle with simple interactive
tasks that young children perform effortlessly. This discrepancy highlights a
critical gap between declarative knowledge (knowing about something) and
procedural knowledge (knowing how to do something). Although traditional
reinforcement learning (RL) agents can acquire procedural knowledge through
environmental interaction, they often operate as black boxes and require
substantial training data. In contrast, LLMs possess extensive world knowledge
and reasoning capabilities, but are unable to effectively convert this static
knowledge into dynamic decision-making in interactive settings. To address this
challenge, we propose Think in Games (TiG), a novel framework that empowers
LLMs to develop procedural understanding through direct interaction with game
environments, while retaining their inherent reasoning and explanatory
abilities. Specifically, TiG reformulates RL-based decision-making as a
language modeling task: LLMs generate language-guided policies, which are
refined iteratively through online reinforcement learning based on
environmental feedback. Our experimental results show that TiG successfully
bridges the gap between declarative and procedural knowledge, achieving
competitive performance with dramatically lower data and computational demands
compared to conventional RL methods. Moreover, TiG provides step-by-step
natural language explanations for its decisions, greatly improving transparency
and interpretability in complex interactive tasks.

</details>


### [31] [AHELM: A Holistic Evaluation of Audio-Language Models](https://arxiv.org/abs/2508.21376)
*Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang*

Main category: cs.AI

TL;DR: AHELM是一个全面的音频-语言模型基准测试，集成了10个评估维度，包括感知、推理、公平性等，测试了14个模型并发现Gemini 2.5 Pro在多个方面领先但存在公平性问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频-语言模型评估缺乏标准化基准，大多数基准只测试一两个能力，且忽略了公平性、安全性等重要评估维度，不同模型之间难以公平比较。

Method: 开发AHELM基准，整合多个数据集（包括新的合成数据集PARADE和CoRe-Bench），标准化提示词、推理参数和评估指标，测试14个开源和闭源ALM模型以及3个基线系统。

Result: Gemini 2.5 Pro在10个维度中的5个排名第一，但在ASR任务中表现出群体不公平性（p=0.01）。基线系统表现良好，其中一个仅具备语音转文本能力的系统总体排名第5。

Conclusion: AHELM提供了一个全面的音频-语言模型评估框架，揭示了当前模型的优势和不足，特别是公平性问题，该基准将持续更新以促进ALM领域的发展。

Abstract: Evaluations of audio-language models (ALMs) -- multimodal models that take
interleaved audio and text as input and output text -- are hindered by the lack
of standardized benchmarks; most benchmarks measure only one or two
capabilities and omit evaluative aspects such as fairness or safety.
Furthermore, comparison across models is difficult as separate evaluations test
a limited number of models and use different prompting methods and inference
parameters. To address these shortfalls, we introduce AHELM, a benchmark that
aggregates various datasets -- including 2 new synthetic audio-text datasets
called PARADE, which evaluates the ALMs on avoiding stereotypes, and
CoRe-Bench, which measures reasoning over conversational audio through
inferential multi-turn question answering -- to holistically measure the
performance of ALMs across 10 aspects we have identified as important to the
development and usage of ALMs: audio perception, knowledge, reasoning, emotion
detection, bias, fairness, multilinguality, robustness, toxicity, and safety.
We also standardize the prompts, inference parameters, and evaluation metrics
to ensure equitable comparisons across models. We test 14 open-weight and
closed-API ALMs from 3 developers and 3 additional simple baseline systems each
consisting of an automatic speech recognizer and a language model. Our results
show that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits
group unfairness ($p=0.01$) on ASR tasks whereas most of the other models do
not. We also find that the baseline systems perform reasonably well on AHELM,
with one ranking 5th overall despite having only speech-to-text capabilities.
For transparency, all raw prompts, model generations, and outputs are available
on our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is
intended to be a living benchmark and new datasets and models will be added
over time.

</details>


### [32] [AI Compute Architecture and Evolution Trends](https://arxiv.org/abs/2508.21394)
*Bor-Sung Liang*

Main category: cs.AI

TL;DR: 本文提出了AI计算的七层架构模型，分析了从底层物理层到顶层应用层的技术演进路径，并探讨了AI发展中的技术挑战和经济可持续性问题。


<details>
  <summary>Details</summary>
Motivation: AI发展已从学术研究转向实际应用，但面临多层次挑战。需要结构化分析AI发展的机遇与挑战，特别是计算架构演进和生态系统构建问题。

Method: 提出七层AI计算架构模型（物理层、链路层、神经网络层、上下文层、智能体层、编排层、应用层），通过分析大语言模型的三阶段演进，详细阐述每层的发展轨迹和关键技术。

Result: 建立了完整的AI计算架构分析框架，识别了各层的关键技术挑战和发展趋势，特别是在计算策略、LLM发展路径、上下文记忆、智能体演进等方面的深入分析。

Conclusion: AI发展不仅需要解决技术挑战，还需构建经济上可持续的生态系统。通过借鉴互联网产业发展经验，可以为AI未来发展轨迹提供有价值的预测和指导。

Abstract: The focus of AI development has shifted from academic research to practical
applications. However, AI development faces numerous challenges at various
levels. This article will attempt to analyze the opportunities and challenges
of AI from several different perspectives using a structured approach. This
article proposes a seven-layer model for AI compute architecture, including
Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,
Orchestrator Layer, and Application Layer, from bottom to top. It also explains
how AI computing has evolved into this 7-layer architecture through the
three-stage evolution on large-scale language models (LLMs). For each layer, we
describe the development trajectory and key technologies. In Layers 1 and 2 we
discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies
on computing architecture. In Layer 3 we explore two different development
paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs
and compares it to traditional processor memory. In Layers 5 to 7 we discuss
the trends of AI agents and explore the issues in evolution from a single AI
agent to an AI-based ecosystem, and their impact on the AI industry.
Furthermore, AI development involves not only technical challenges but also the
economic issues to build self-sustainable ecosystem. This article analyzes the
internet industry to provide predictions on the future trajectory of AI
development.

</details>


### [33] [CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN](https://arxiv.org/abs/2508.21411)
*Leonard Frank Neis,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: CARJAN是一个基于AJAN多智能体框架和CARLA驾驶模拟器的半自动化交通场景生成与仿真工具，提供可视化界面和SPARQL行为树决策机制。


<details>
  <summary>Details</summary>
Motivation: 城市交通场景中不同类型智能体（行人、骑行者、自动驾驶车辆）的交互建模和虚拟仿真仍然是一个挑战，需要更用户友好的工具。

Method: 基于AJAN多智能体工程框架和CARLA驾驶模拟器，提供可视化用户界面进行场景布局建模，采用SPARQL行为树实现智能体决策和交互。

Result: 开发了CARJAN工具，实现了交通场景的半自动化生成和仿真，支持动态场景中智能体的智能交互。

Conclusion: CARJAN为CARLA中的交互式智能体交通场景生成和仿真提供了首个集成化解决方案。

Abstract: User-friendly modeling and virtual simulation of urban traffic scenarios with
different types of interacting agents such as pedestrians, cyclists and
autonomous vehicles remains a challenge. We present CARJAN, a novel tool for
semi-automated generation and simulation of such scenarios based on the
multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN
provides a visual user interface for the modeling, storage and maintenance of
traffic scenario layouts, and leverages SPARQL Behavior Tree-based
decision-making and interactions for agents in dynamic scenario simulations in
CARLA. CARJAN provides a first integrated approach for interactive, intelligent
agent-based generation and simulation of virtual traffic scenarios in CARLA.

</details>


### [34] [A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions](https://arxiv.org/abs/2508.21441)
*Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald*

Main category: cs.AI

TL;DR: 本文从认知角度研究知识管理中的遗忘操作，在认知状态中提出五种通用类型的遗忘操作，并在Spohn排序函数中实例化七种具体操作，通过逻辑编程和AGM理论的公理进行评估。


<details>
  <summary>Details</summary>
Motivation: 现有的遗忘操作主要基于经典逻辑，如变量消除和AGM收缩，但缺乏在更丰富语义结构的认知状态中的系统研究。本文旨在从认知角度探索遗忘操作，建立与命题逻辑的清晰联系。

Method: 采用认知状态作为语义基础，提出五种通用类型的认知遗忘操作，并在Spohn排序函数中实例化七种具体操作。借鉴逻辑编程和AGM理论的公理，构建评估遗忘操作的公理体系。

Result: 系统评估了所有具体遗忘操作在各项公理下的表现，提供了全面的比较分析，突出了不同遗忘操作符之间的差异和共同点。

Conclusion: 本文扩展了遗忘操作的研究范围，从认知角度提供了系统化的遗忘操作框架，为知识管理中的选择性遗忘提供了理论基础和实用指导。

Abstract: Forgetting as a knowledge management operation deliberately ignores parts of
the knowledge and beliefs of an agent, for various reasons. Forgetting has many
facets, one may want to forget parts of the syntax, a proposition, or a
conditional. In the literature, two main operators suitable for performing
forgetting have been proposed and investigated in depth: First, variable
elimination is a syntactical method that blends out certain atomic variables to
focus on the rest of the language. It has been mainly used in the area of logic
programming and answer set programming. Second, contraction in AGM belief
revision theory effectively removes propositions from belief sets under logical
deduction. Both operations rely mainly on classical logics. In this article, we
take an epistemic perspective and study forgetting operations in epistemic
states with richer semantic structures, but with clear links to propositional
logic. This allows us to investigate what forgetting in the epistemic
background means, thereby lifting well-known and novel forgetting operations to
the epistemic level. We present five general types of epistemic forgetting and
instantiate them with seven concrete forgetting operations for Spohn's ranking
functions. We take inspiration from postulates of forgetting both from logic
programming and AGM theory to propose a rich landscape of axioms for evaluating
forgetting operations. Finally, we evaluate all concrete forgetting operations
according to all postulates, leading to a novel comprehensive overview
highlighting differences and commonalities among the forgetting operators.

</details>


### [35] [Learning Lifted Action Models From Traces of Incomplete Actions and States](https://arxiv.org/abs/2508.21449)
*Niklas Jansen,Jonas Gösgens,Hector Geffner*

Main category: cs.AI

TL;DR: 学习滑动拼图游戏的lifted STRIPS模型，从只包含tile位置的状态和简单动作标签（无参数）的轨迹中学习。提出了STRIPS+扩展来处理隐式参数和有限存在量化，并开发了SYNTH算法来学习这种模型。


<details>
  <summary>Details</summary>
Motivation: 解决从更现实的状态-动作轨迹中学习模型的问题，其中状态不是完整的STRIPS状态（缺少某些谓词），动作也不包含所有需要的参数。现有方法大多假设动作是完整的STRIPS动作或所有域谓词都可观察。

Method: 引入STRIPS+扩展，允许动作参数在前提条件中隐式存在并支持有限存在量化。开发SYNTH算法，为每个动作构建分层序列的前提条件表达式（查询），以唯一标识状态中的对象并接地隐式动作参数。

Result: 建立了SYNTH算法的正确性和完备性，并在从现有STRIPS域派生的STRIPS+模型生成的状态-动作轨迹上测试了其可扩展性。

Conclusion: 提出的STRIPS+框架和SYNTH算法能够有效处理从更现实的不完整状态和动作信息中学习模型的问题，为实际应用中的模型学习提供了可行方案。

Abstract: Consider the problem of learning a lifted STRIPS model of the sliding-tile
puzzle from random state-action traces where the states represent the location
of the tiles only, and the actions are the labels up, down, left, and right,
with no arguments. Two challenges are involved in this problem. First, the
states are not full STRIPS states, as some predicates are missing, like the
atoms representing the position of the ``blank''. Second, the actions are not
full STRIPS either, as they do not reveal all the objects involved in the
actions effects and preconditions. Previous approaches have addressed different
versions of this model learning problem, but most assume that actions in the
traces are full STRIPS actions or that the domain predicates are all
observable. The new setting considered in this work is more ``realistic'', as
the atoms observed convey the state of the world but not full STRIPS states,
and the actions reveal the arguments needed for selecting the action but not
the ones needed for modeling it in STRIPS. For formulating and addressing the
learning problem, we introduce a variant of STRIPS, which we call STRIPS+,
where certain STRIPS action arguments can be left implicit in preconditions
which can also involve a limited form of existential quantification. The
learning problem becomes the problem of learning STRIPS+ models from STRIPS+
state-action traces. For this, the proposed learning algorithm, called SYNTH,
constructs a stratified sequence (conjunction) of precondition expressions or
``queries'' for each action, that denote unique objects in the state and ground
the implicit action arguments in STRIPS+. The correctness and completeness of
SYNTH is established, and its scalability is tested on state-action traces
obtained from STRIPS+ models derived from existing STRIPS domains.

</details>


### [36] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: MMSearch-Plus是一个新的多模态搜索基准，包含311个需要深度视觉推理的任务，挑战现有MLLM模型在细粒度视觉理解、来源验证和长时程工具使用方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态浏览基准往往可以通过浅层固定工作流程解决，无法真正测试模型的多模态理解能力。需要构建一个能体现真实多模态挑战的基准。

Method: 采用时空外推法构建任务，要求从空间线索（微文本、局部外观、布局、标识）和时间痕迹（广播叠加、季节上下文）推断出图像外的事实。提供模型无关的代理框架进行评估。

Result: 最强代理（o3）无搜索准确率15.1%，有搜索36.0%；开源模型Qwen-2.5-VL-72B无搜索0.0%，20轮搜索后6.9%。模型在来源验证、基于部件的推理和长时程规划方面存在明显失败。

Conclusion: MMSearch-Plus基准有效揭示了当前MLLM在多模态搜索任务中的局限性，特别是在细粒度视觉推理和长时程规划方面，为未来模型改进提供了重要方向。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [37] [Counterfactual Scenarios for Automated Planning](https://arxiv.org/abs/2508.21521)
*Nicola Gigante,Francesco Leofante,Andrea Micheli*

Main category: cs.AI

TL;DR: 本文提出了一种基于反事实场景的新型解释范式，用于自动规划领域，通过最小化修改规划问题来生成满足特定性质的反事实解释。


<details>
  <summary>Details</summary>
Motivation: 现有的反事实解释主要关注对现有计划的最小修改，但无法捕捉问题本身的高层特性。为了弥补这一局限性，需要一种能够识别规划问题最小修改的方法，使其能够产生满足特定性质的计划。

Method: 提出了两种基于显式量化的反事实场景定性实例化方法，允许对规划问题进行不同类型的修改，并分析了生成此类反事实场景的计算复杂性。

Result: 研究表明生成反事实场景的计算成本通常与计算规划问题的计划相当，证明了该方法的实际可行性。

Conclusion: 该框架为构建实际算法提供了基础，能够有效解释规划问题的高层特性，具有重要的理论和实践价值。

Abstract: Counterfactual Explanations (CEs) are a powerful technique used to explain
Machine Learning models by showing how the input to a model should be minimally
changed for the model to produce a different output. Similar proposals have
been made in the context of Automated Planning, where CEs have been
characterised in terms of minimal modifications to an existing plan that would
result in the satisfaction of a different goal. While such explanations may
help diagnose faults and reason about the characteristics of a plan, they fail
to capture higher-level properties of the problem being solved. To address this
limitation, we propose a novel explanation paradigm that is based on
counterfactual scenarios. In particular, given a planning problem $P$ and an
\ltlf formula $\psi$ defining desired properties of a plan, counterfactual
scenarios identify minimal modifications to $P$ such that it admits plans that
comply with $\psi$. In this paper, we present two qualitative instantiations of
counterfactual scenarios based on an explicit quantification over plans that
must satisfy $\psi$. We then characterise the computational complexity of
generating such counterfactual scenarios when different types of changes are
allowed on $P$. We show that producing counterfactual scenarios is often only
as expensive as computing a plan for $P$, thus demonstrating the practical
viability of our proposal and ultimately providing a framework to construct
practical algorithms in this area.

</details>


### [38] [HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining](https://arxiv.org/abs/2508.21540)
*Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi*

Main category: cs.AI

TL;DR: HealthProcessAI是一个基于GenAI的框架，通过集成多个大型语言模型来自动解释过程挖掘结果并生成报告，简化了医疗保健领域过程挖掘的应用。


<details>
  <summary>Details</summary>
Motivation: 过程挖掘在医疗保健工作流分析中具有强大潜力，但面临技术复杂性、缺乏标准化方法和实践培训资源有限等障碍，需要简化应用并提高可访问性。

Method: 开发了HealthProcessAI框架，包装现有的Python(PM4PY)和R(bupaR)库，集成多个LLM模型进行自动化过程图解释和报告生成，使用脓毒症进展数据作为概念验证。

Result: 框架成功处理了四个概念验证场景的脓毒症数据，技术性能稳健。LLM评估显示Claude Sonnet-4和Gemini 2.5-Pro获得最高一致性分数(3.79/4.0和3.65/4.0)。

Conclusion: 该框架通过结合结构化分析和AI驱动的解释，为将复杂过程挖掘结果转化为医疗保健应用的可操作见解提供了新颖的方法学进展。

Abstract: Process mining has emerged as a powerful analytical technique for
understanding complex healthcare workflows. However, its application faces
significant barriers, including technical complexity, a lack of standardized
approaches, and limited access to practical training resources. We introduce
HealthProcessAI, a GenAI framework designed to simplify process mining
applications in healthcare and epidemiology by providing a comprehensive
wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address
unfamiliarity and improve accessibility, the framework integrates multiple
Large Language Models (LLMs) for automated process map interpretation and
report generation, helping translate technical analyses into outputs that
diverse users can readily understand. We validated the framework using sepsis
progression data as a proof-of-concept example and compared the outputs of five
state-of-the-art LLM models through the OpenRouter platform. To test its
functionality, the framework successfully processed sepsis data across four
proof-of-concept scenarios, demonstrating robust technical performance and its
capability to generate reports through automated LLM analysis. LLM evaluation
using five independent LLMs as automated evaluators revealed distinct model
strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency
scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By
integrating multiple Large Language Models (LLMs) for automated interpretation
and report generation, the framework addresses widespread unfamiliarity with
process mining outputs, making them more accessible to clinicians, data
scientists, and researchers. This structured analytics and AI-driven
interpretation combination represents a novel methodological advance in
translating complex process mining results into potentially actionable insights
for healthcare applications.

</details>


### [39] [Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances](https://arxiv.org/abs/2508.21564)
*Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt*

Main category: cs.AI

TL;DR: 提出一种发现跨域自动通用里程碑的新框架，通过学习解决实例的状态函数来描述中间目标，支持循环重复子计划，并构建有向通用里程碑图作为谜策使用


<details>
  <summary>Details</summary>
Motivation: 传统里程碑提取算法在某些规划问题中效果不佳，需要一种能够自动通用于整个域、捐费重复模式的里程碑发现方法

Method: 使用状态函数来学习通用里程碑（不依赖于具体对象），构建有向通用里程碑图来定义里程碑进展，包括支持循环重复子计划

Result: 实验结果显示，从少量小型实例学习的通用里程碑图在同域的更大实例中也有效。如果识别出表示重复的循环，谜策性能比基准有显著提升

Conclusion: 通用里程碑能够捐费可解释的域信息，这些信息可以从同一域的少量计划中发现，并且对自动规划器非常有用

Abstract: We propose a new framework for discovering landmarks that automatically
generalize across a domain. These generalized landmarks are learned from a set
of solved instances and describe intermediate goals for planning problems where
traditional landmark extraction algorithms fall short. Our generalized
landmarks extend beyond the predicates of a domain by using state functions
that are independent of the objects of a specific problem and apply to all
similar objects, thus capturing repetition. Based on these functions, we
construct a directed generalized landmark graph that defines the landmark
progression, including loop possibilities for repetitive subplans. We show how
to use this graph in a heuristic to solve new problem instances of the same
domain. Our results show that the generalized landmark graphs learned from a
few small instances are also effective for larger instances in the same domain.
If a loop that indicates repetition is identified, we see a significant
improvement in heuristic performance over the baseline. Generalized landmarks
capture domain information that is interpretable and useful to an automated
planner. This information can be discovered from a small set of plans for the
same domain.

</details>


### [40] [Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study](https://arxiv.org/abs/2508.21622)
*Saravanan Venkatachalam*

Main category: cs.AI

TL;DR: 结合传统网络优化模型与大语言模型的集成框架，为供应链规划提供交互式、可解释且角色感知的决策支持系统


<details>
  <summary>Details</summary>
Motivation: 解决复杂运筹学输出与业务利益相关者理解之间的差距，通过自然语言摘要、情境可视化和定制化KPI来弥合这一鸿沟

Method: 采用混合整数规划模型处理多周期多物品的库存再分配问题，技术架构包含AI代理、RESTful API和动态用户界面，支持实时交互和模拟分析

Result: 案例研究表明系统能够通过防止缺货、降低成本和维持服务水平来改善规划结果

Conclusion: 未来将整合私有LLM、迁移学习、强化学习和贝叶斯神经网络，以增强可解释性、适应性和实时决策能力

Abstract: This paper presents an integrated framework that combines traditional network
optimization models with large language models (LLMs) to deliver interactive,
explainable, and role-aware decision support for supply chain planning. The
proposed system bridges the gap between complex operations research outputs and
business stakeholder understanding by generating natural language summaries,
contextual visualizations, and tailored key performance indicators (KPIs). The
core optimization model addresses tactical inventory redistribution across a
network of distribution centers for multi-period and multi-item, using a
mixed-integer formulation. The technical architecture incorporates AI agents,
RESTful APIs, and a dynamic user interface to support real-time interaction,
configuration updates, and simulation-based insights. A case study demonstrates
how the system improves planning outcomes by preventing stockouts, reducing
costs, and maintaining service levels. Future extensions include integrating
private LLMs, transfer learning, reinforcement learning, and Bayesian neural
networks to enhance explainability, adaptability, and real-time
decision-making.

</details>


### [41] [A-MHA*: Anytime Multi-Heuristic A*](https://arxiv.org/abs/2508.21637)
*Ramkumar Natarajan,Muhammad Suhail Saleem,William Xiao,Sandip Aine,Howie Choset,Maxim Likhachev*

Main category: cs.AI

TL;DR: 基于MHA*扩展的任意时间版本搜索算法A-MHA*，能够迫忽获得可行解并持续改进，保持了原有的次优化和完备性保证。


<details>
  <summary>Details</summary>
Motivation: MHA*算法虽然能够利用多个非可接受假设来加快搜索，但是不能在时间充足时持续改进解的质量，需要一次性设置参数来获得指定质量的解。

Method: 受ARA*算法启发，将ARA*的任意时间特性精确地迁移到MHA*框架中，发展出A-MHA*算法。

Result: 在3D路径规划和滑动氏片谜题中进行了性能测试，与MHA*和其他任意时间算法进行了对比。

Conclusion: A-MHA*成功扩展了MHA*的功能，在保持原有保证的前提下实现了任意时间特性，能够迫忽获得可行解并持续改进解的质量。

Abstract: Designing good heuristic functions for graph search requires adequate domain
knowledge. It is often easy to design heuristics that perform well and
correlate with the underlying true cost-to-go values in certain parts of the
search space but these may not be admissible throughout the domain thereby
affecting the optimality guarantees of the search. Bounded suboptimal search
using several such partially good but inadmissible heuristics was developed in
Multi-Heuristic A* (MHA*). Although MHA* leverages multiple inadmissible
heuristics to potentially generate a faster suboptimal solution, the original
version does not improve the solution over time. It is a one shot algorithm
that requires careful setting of inflation factors to obtain a desired one time
solution. In this work, we tackle this issue by extending MHA* to an anytime
version that finds a feasible suboptimal solution quickly and continually
improves it until time runs out. Our work is inspired from the Anytime
Repairing A* (ARA*) algorithm. We prove that our precise adaptation of ARA*
concepts in the MHA* framework preserves the original suboptimal and
completeness guarantees and enhances MHA* to perform in an anytime fashion.
Furthermore, we report the performance of A-MHA* in 3-D path planning domain
and sliding tiles puzzle and compare against MHA* and other anytime algorithms.

</details>


### [42] [Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI](https://arxiv.org/abs/2508.21648)
*Farhad Abtahi,Mehdi Astaraki,Fernando Seoane*

Main category: cs.AI

TL;DR: MEDLEY框架通过保留多个AI模型的多样性输出而非追求共识，将模型偏见视为潜在优势，为医疗AI提供透明化的诊断不确定性展示


<details>
  <summary>Details</summary>
Motivation: 传统方法试图消除AI偏见，但人类推理本身就包含偏见，这些偏见可能具有价值。MEDLEY旨在利用AI模型的多样性来增强医疗推理

Method: 开发概念验证演示器，使用30多个大型语言模型，保留共识和少数观点，将幻觉视为待验证的假设，使诊断不确定性和偏见透明化

Result: 创建了最小可行产品，在合成病例中成功保留了多样化的诊断观点，为临床监督提供了透明的决策过程

Conclusion: MEDLEY通过重新定义AI不完美性为资源，为开发可信医疗AI系统开辟了新的监管、伦理和创新途径

Abstract: Bias in medical artificial intelligence is conventionally viewed as a defect
requiring elimination. However, human reasoning inherently incorporates biases
shaped by education, culture, and experience, suggesting their presence may be
inevitable and potentially valuable. We propose MEDLEY (Medical Ensemble
Diagnostic system with Leveraged diversitY), a conceptual framework that
orchestrates multiple AI models while preserving their diverse outputs rather
than collapsing them into a consensus. Unlike traditional approaches that
suppress disagreement, MEDLEY documents model-specific biases as potential
strengths and treats hallucinations as provisional hypotheses for clinician
verification. A proof-of-concept demonstrator was developed using over 30 large
language models, creating a minimum viable product that preserved both
consensus and minority views in synthetic cases, making diagnostic uncertainty
and latent biases transparent for clinical oversight. While not yet a validated
clinical tool, the demonstration illustrates how structured diversity can
enhance medical reasoning under clinician supervision. By reframing AI
imperfection as a resource, MEDLEY offers a paradigm shift that opens new
regulatory, ethical, and innovation pathways for developing trustworthy medical
AI systems.

</details>


### [43] [PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation](https://arxiv.org/abs/2508.21720)
*Jiho Choi,Seojeong Park,Seongjong Song,Hyunjung Shim*

Main category: cs.AI

TL;DR: PosterForest是一个无需训练的科学海报生成框架，通过分层中间表示和多智能体协作，直接解决文档结构和视觉-文本语义整合的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多忽视科学文档的分层结构和文本视觉元素的语义整合，需要一种能够同时处理这两个挑战的自动化海报生成方法。

Method: 引入Poster Tree分层中间表示，采用多智能体协作策略（内容摘要和布局规划智能体），通过迭代协调和相互反馈实现联合优化。

Result: 在多个学术领域的实验中，该方法在定性和定量评估上均优于现有基线，生成的海报质量最接近专家设计，在信息保存、结构清晰度和用户偏好方面表现优异。

Conclusion: PosterForest框架成功解决了科学海报生成中的结构和语义整合问题，为自动化科学海报生成提供了有效的解决方案。

Abstract: We present a novel training-free framework, \textit{PosterForest}, for
automated scientific poster generation. Unlike prior approaches, which largely
neglect the hierarchical structure of scientific documents and the semantic
integration of textual and visual elements, our method addresses both
challenges directly. We introduce the \textit{Poster Tree}, a hierarchical
intermediate representation that jointly encodes document structure and
visual-textual relationships at multiple levels. Our framework employs a
multi-agent collaboration strategy, where agents specializing in content
summarization and layout planning iteratively coordinate and provide mutual
feedback. This approach enables the joint optimization of logical consistency,
content fidelity, and visual coherence. Extensive experiments on multiple
academic domains show that our method outperforms existing baselines in both
qualitative and quantitative evaluations. The resulting posters achieve quality
closest to expert-designed ground truth and deliver superior information
preservation, structural clarity, and user preference.

</details>


### [44] [Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem](https://arxiv.org/abs/2508.21730)
*Fabrizio Fagiolo,Nicolo' Vescera*

Main category: cs.AI

TL;DR: 本文提出了一种用于旅行商问题的变分量子算法，通过紧凑排列编码减少量子比特需求，采用优化-冻结-重用策略，在训练实例上优化电路结构后冻结并重用于新实例，仅需快速重新优化参数。


<details>
  <summary>Details</summary>
Motivation: 解决传统变分量子算法在测试阶段需要重复进行结构搜索的高成本问题，使算法能够直接在NISQ硬件上快速部署。

Method: 使用紧凑排列编码减少量子比特需求；采用优化-冻结-重用策略：先在训练实例上通过模拟退火优化电路结构，然后冻结该结构，在新实例上仅重新优化电路参数。

Result: 在4-7个城市的40个随机对称实例上，4城市达到100%最优路径采样概率，5城市90%，6城市80%，7城市降至约20%，显示出方法的可扩展性限制。

Conclusion: 该方法在中等问题规模下表现出良好的泛化能力，冻结Ansatz能显著减少求解时间而不降低解质量，但存在可扩展性限制，未来可扩展到车辆路径和作业车间调度等更复杂问题。

Abstract: In this paper we present a variational algorithm for the Traveling Salesman
Problem (TSP) that combines (i) a compact encoding of permutations, which
reduces the qubit requirement too, (ii) an optimize-freeze-reuse strategy:
where the circuit topology (``Ansatz'') is first optimized on a training
instance by Simulated Annealing (SA), then ``frozen'' and re-used on novel
instances, limited to a rapid re-optimization of only the circuit parameters.
This pipeline eliminates costly structural research in testing, making the
procedure immediately implementable on NISQ hardware.
  On a set of $40$ randomly generated symmetric instances that span $4 - 7$
cities, the resulting Ansatz achieves an average optimal trip sampling
probability of $100\%$ for 4 city cases, $90\%$ for 5 city cases and $80\%$ for
6 city cases. With 7 cities the success rate drops markedly to an average of
$\sim 20\%$, revealing the onset of scalability limitations of the proposed
method.
  The results show robust generalization ability for moderate problem sizes and
indicate how freezing the Ansatz can dramatically reduce time-to-solution
without degrading solution quality. The paper also discusses scalability
limitations, the impact of ``warm-start'' initialization of parameters, and
prospects for extension to more complex problems, such as Vehicle Routing and
Job-Shop Scheduling.

</details>


### [45] [Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions](https://arxiv.org/abs/2508.21742)
*Timothée Loranchet,Charles K. Assaad*

Main category: cs.AI

TL;DR: 本文提出了在给定高层摘要因果图的情况下，保证时序变量间微观层面边可定向性的条件，为复杂时序系统中的因果发现提供理论保证。


<details>
  <summary>Details</summary>
Motivation: 在时间序列分析中，即使无法完全确定完整的因果结构，专家通常能够提供高层摘要因果图来捕捉主要因果关系。如何利用这种专家知识来指导微观层面的因果发现是一个重要挑战。

Method: 提出了在给定摘要因果图和假设存在忠实且因果充分的分布条件下，保证微观层面边可定向性的理论条件。这些条件即使在宏观层面存在循环或双向边的情况下也适用。

Result: 建立了微观层面边定向的理论保证，证明了在特定条件下可以利用摘要因果图来指导时序变量间的因果发现。

Conclusion: 研究结果表明，通过结合专家知识提供的摘要因果图，可以显著改进从观测时间序列数据中进行因果推断的效果，为复杂时序系统的因果发现提供了实用指导。

Abstract: Understanding causal relations between temporal variables is a central
challenge in time series analysis, particularly when the full causal structure
is unknown. Even when the full causal structure cannot be fully specified,
experts often succeed in providing a high-level abstraction of the causal
graph, known as a summary causal graph, which captures the main causal
relations between different time series while abstracting away micro-level
details. In this work, we present conditions that guarantee the orientability
of micro-level edges between temporal variables given the background knowledge
encoded in a summary causal graph and assuming having access to a faithful and
causally sufficient distribution with respect to the true unknown graph. Our
results provide theoretical guarantees for edge orientation at the micro-level,
even in the presence of cycles or bidirected edges at the macro-level. These
findings offer practical guidance for leveraging SCGs to inform causal
discovery in complex temporal systems and highlight the value of incorporating
expert knowledge to improve causal inference from observational time series
data.

</details>


### [46] [Tree-Guided Diffusion Planner](https://arxiv.org/abs/2508.21800)
*Hyeonseong Jeon,Cheolhong Min,Jaesik Park*

Main category: cs.AI

TL;DR: 提出Tree-guided Diffusion Planner (TDP)，一种零样本测试时规划框架，通过树搜索和双层采样过程解决扩散模型在非凸、不可微分约束下的规划问题，在多个任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的规划方法在凸可微分奖励场景下表现良好，但在现实世界的非凸目标、不可微分约束和多奖励结构场景中效果大幅下降。监督规划方法需要任务特定训练，限制了测试时灵活性和零样本泛化能力。

Method: 将测试时规划构建为树搜索问题，采用双层采样过程：1) 通过无训练粒子引导生成多样化父轨迹以鼓励广泛探索；2) 通过任务目标引导的快速条件去噪精炼子轨迹。仅使用预训练模型和测试时奖励信号。

Result: 在三个不同任务上评估：迷宫金币收集、机械臂方块操作和AntMaze多目标探索。TDP在所有任务上都一致优于最先进方法。

Conclusion: TDP通过结构化轨迹生成平衡探索和利用，解决了梯度引导的局限性，仅使用预训练模型即可实现有效的零样本测试时规划。

Abstract: Planning with pretrained diffusion models has emerged as a promising approach
for solving test-time guided control problems. However, standard gradient
guidance typically performs optimally under convex and differentiable reward
landscapes, showing substantially reduced effectiveness in real-world scenarios
involving non-convex objectives, non-differentiable constraints, and
multi-reward structures. Furthermore, recent supervised planning approaches
require task-specific training or value estimators, which limits test-time
flexibility and zero-shot generalization. We propose a Tree-guided Diffusion
Planner (TDP), a zero-shot test-time planning framework that balances
exploration and exploitation through structured trajectory generation. We frame
test-time planning as a tree search problem using a bi-level sampling process:
(1) diverse parent trajectories are produced via training-free particle
guidance to encourage broad exploration, and (2) sub-trajectories are refined
through fast conditional denoising guided by task objectives. TDP addresses the
limitations of gradient guidance by exploring diverse trajectory regions and
harnessing gradient information across this expanded solution space using only
pretrained models and test-time reward signals. We evaluate TDP on three
diverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze
multi-goal exploration. TDP consistently outperforms state-of-the-art
approaches on all tasks. The project page can be found at:
tree-diffusion-planner.github.io.

</details>


### [47] [Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture](https://arxiv.org/abs/2508.21803)
*Yeawon Lee,Xiaoyang Wang,Christopher C. Yang*

Main category: cs.AI

TL;DR: 这篇论文提出了一种协作式多代理系统(MAS)，模拟临床诊疗团队进行临床问题识别，在SOAP备忙记录的S和O部分实现了更准确的诊断效果。


<details>
  <summary>Details</summary>
Motivation: 临床备忙的准确解释对患者护理至关重要，但单一模型方法缺乏高风险临床任务所需的稳健性。

Method: 设计了一个管理代理协调的动态多专家代理系统，通过层次迭代辩论达成共识，模拟临床团队的诊断推理过程。

Result: 在420份MIMIC-III备忙的港理数据集上，动态多代理配置在识别凑血性心力衰竭、急性肾伤害和感染性伤害方面均显示出持续改善的性能。

Conclusion: 通过模拟临床团队的推理过程，该系统为开发更准确、稳健和可解释的临床决策支持工具提供了有前景的途径。

Abstract: Accurate interpretation of clinical narratives is critical for patient care,
but the complexity of these notes makes automation challenging. While Large
Language Models (LLMs) show promise, single-model approaches can lack the
robustness required for high-stakes clinical tasks. We introduce a
collaborative multi-agent system (MAS) that models a clinical consultation team
to address this gap. The system is tasked with identifying clinical problems by
analyzing only the Subjective (S) and Objective (O) sections of SOAP notes,
simulating the diagnostic reasoning process of synthesizing raw data into an
assessment. A Manager agent orchestrates a dynamically assigned team of
specialist agents who engage in a hierarchical, iterative debate to reach a
consensus. We evaluated our MAS against a single-agent baseline on a curated
dataset of 420 MIMIC-III notes. The dynamic multi-agent configuration
demonstrated consistently improved performance in identifying congestive heart
failure, acute kidney injury, and sepsis. Qualitative analysis of the agent
debates reveals that this structure effectively surfaces and weighs conflicting
evidence, though it can occasionally be susceptible to groupthink. By modeling
a clinical team's reasoning process, our system offers a promising path toward
more accurate, robust, and interpretable clinical decision support tools.

</details>
