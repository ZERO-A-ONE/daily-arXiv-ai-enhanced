{"id": "2507.10583", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.10583", "abs": "https://arxiv.org/abs/2507.10583", "authors": ["Daniil Orel", "Indraneil Paul", "Iryna Gurevych", "Preslav Nakov"], "title": "$\\texttt{Droid}$: A Resource Suite for AI-Generated Code Detection", "comment": null, "summary": "In this work, we compile $\\textbf{$\\texttt{DroidCollection}$}$, the most\nextensive open data suite for training and evaluating machine-generated code\ndetectors, comprising over a million code samples, seven programming languages,\noutputs from 43 coding models, and over three real-world coding domains.\nAlongside fully AI-generated samples, our collection includes human-AI\nco-authored code, as well as adversarial samples explicitly crafted to evade\ndetection. Subsequently, we develop $\\textbf{$\\texttt{DroidDetect}$}$, a suite\nof encoder-only detectors trained using a multi-task objective over\n$\\texttt{DroidCollection}$. Our experiments show that existing detectors'\nperformance fails to generalise to diverse coding domains and programming\nlanguages outside of their narrow training data. Additionally, we demonstrate\nthat while most detectors are easily compromised by humanising the output\ndistributions using superficial prompting and alignment approaches, this\nproblem can be easily amended by training on a small amount of adversarial\ndata. Finally, we demonstrate the effectiveness of metric learning and\nuncertainty-based resampling as means to enhance detector training on possibly\nnoisy distributions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86DroidCollection\uff0c\u4e00\u4e2a\u5305\u542b\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u5f00\u653e\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u4e86DroidDetect\u68c0\u6d4b\u5668\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u673a\u5668\u751f\u6210\u4ee3\u7801\u7684\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4b\u5668\u5728\u591a\u6837\u5316\u7684\u7f16\u7a0b\u8bed\u8a00\u548c\u9886\u57df\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u4e14\u6613\u53d7\u5bf9\u6297\u6027\u6837\u672c\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5168\u9762\u7684\u6570\u636e\u96c6\u548c\u6539\u8fdb\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86DroidCollection\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u79cd\u4ee3\u7801\u6837\u672c\u548c\u5bf9\u6297\u6027\u6837\u672c\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u591a\u4efb\u52a1\u76ee\u6807\u7684DroidDetect\u68c0\u6d4b\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u73b0\u6709\u68c0\u6d4b\u5668\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u4f46\u901a\u8fc7\u5bf9\u6297\u6027\u6570\u636e\u8bad\u7ec3\u53ef\u4ee5\u6539\u8fdb\u6027\u80fd\uff1b\u540c\u65f6\uff0c\u5ea6\u91cf\u5b66\u4e60\u548c\u4e0d\u786e\u5b9a\u6027\u91cd\u91c7\u6837\u80fd\u6709\u6548\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "conclusion": "DroidCollection\u548cDroidDetect\u4e3a\u673a\u5668\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5bf9\u6297\u6027\u6570\u636e\u548c\u6539\u8fdb\u7684\u8bad\u7ec3\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2507.10584", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10584", "abs": "https://arxiv.org/abs/2507.10584", "authors": ["Francesco Romeo", "Luigi Arena", "Francesco Blefari", "Francesco Aurelio Pironti", "Matteo Lupinacci", "Angelo Furfaro"], "title": "ARPaCCino: An Agentic-RAG for Policy as Code Compliance", "comment": null, "summary": "Policy as Code (PaC) is a paradigm that encodes security and compliance\npolicies into machine-readable formats, enabling automated enforcement in\nInfrastructure as Code (IaC) environments. However, its adoption is hindered by\nthe complexity of policy languages and the risk of misconfigurations. In this\nwork, we present ARPaCCino, an agentic system that combines Large Language\nModels (LLMs), Retrieval-Augmented-Generation (RAG), and tool-based validation\nto automate the generation and verification of PaC rules. Given natural\nlanguage descriptions of the desired policies, ARPaCCino generates formal Rego\nrules, assesses IaC compliance, and iteratively refines the IaC configurations\nto ensure conformance. Thanks to its modular agentic architecture and\nintegration with external tools and knowledge bases, ARPaCCino supports policy\nvalidation across a wide range of technologies, including niche or emerging IaC\nframeworks. Experimental evaluation involving a Terraform-based case study\ndemonstrates ARPaCCino's effectiveness in generating syntactically and\nsemantically correct policies, identifying non-compliant infrastructures, and\napplying corrective modifications, even when using smaller, open-weight LLMs.\nOur results highlight the potential of agentic RAG architectures to enhance the\nautomation, reliability, and accessibility of PaC workflows.", "AI": {"tldr": "ARPaCCino\u662f\u4e00\u4e2a\u7ed3\u5408LLM\u3001RAG\u548c\u5de5\u5177\u9a8c\u8bc1\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u751f\u6210\u548c\u9a8c\u8bc1Policy as Code\u89c4\u5219\uff0c\u63d0\u5347IaC\u73af\u5883\u4e2d\u7684\u7b56\u7565\u5408\u89c4\u6027\u3002", "motivation": "Policy as Code\u7684\u91c7\u7528\u53d7\u9650\u4e8e\u7b56\u7565\u8bed\u8a00\u7684\u590d\u6742\u6027\u548c\u914d\u7f6e\u9519\u8bef\u7684\u98ce\u9669\uff0cARPaCCino\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "ARPaCCino\u5229\u7528LLM\u3001RAG\u548c\u5de5\u5177\u9a8c\u8bc1\uff0c\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u751f\u6210Rego\u89c4\u5219\uff0c\u5e76\u9a8c\u8bc1\u548c\u4f18\u5316IaC\u914d\u7f6e\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eARPaCCino\u80fd\u751f\u6210\u6b63\u786e\u7b56\u7565\uff0c\u8bc6\u522b\u4e0d\u5408\u89c4\u57fa\u7840\u8bbe\u65bd\u5e76\u8fdb\u884c\u4fee\u6b63\uff0c\u5373\u4f7f\u4f7f\u7528\u5c0f\u578bLLM\u4e5f\u6709\u6548\u3002", "conclusion": "ARPaCCino\u5c55\u793a\u4e86\u57fa\u4e8eRAG\u7684\u67b6\u6784\u5728\u63d0\u5347PaC\u81ea\u52a8\u5316\u3001\u53ef\u9760\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.10590", "categories": ["cs.SE", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.10590", "abs": "https://arxiv.org/abs/2507.10590", "authors": ["Mojtaba Eshghie"], "title": "Repairing Language Model Pipelines by Meta Self-Refining Competing Constraints at Runtime", "comment": null, "summary": "Language Model (LM) pipelines can dynamically refine their outputs against\nprogrammatic constraints. However, their effectiveness collapses when faced\nwith competing soft constraints, leading to inefficient backtracking loops\nwhere satisfying one constraint violates another. We introduce Meta\nSelf-Refining, a framework that equips LM pipelines with a meta-corrective\nlayer to repair these competitions at runtime/inference-time. Our approach\nmonitors the pipeline's execution history to detect oscillatory failures. Upon\ndetection, it invokes a meta-repairer LM that analyzes the holistic state of\nthe backtracking attempts and synthesizes a strategic instruction to balance\nthe competing requirements. This self-repair instruction guides the original LM\nout of a failing refining loop towards a successful output. Our results show\nMeta Self-Refining can successfully repair these loops, leading to more\nefficient LM programs.", "AI": {"tldr": "Meta Self-Refining\u6846\u67b6\u901a\u8fc7\u5143\u6821\u6b63\u5c42\u4fee\u590d\u8bed\u8a00\u6a21\u578b\u7ba1\u9053\u4e2d\u7684\u7ade\u4e89\u6027\u8f6f\u7ea6\u675f\u95ee\u9898\uff0c\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u7ba1\u9053\u5728\u52a8\u6001\u4f18\u5316\u8f93\u51fa\u65f6\uff0c\u9762\u5bf9\u7ade\u4e89\u6027\u8f6f\u7ea6\u675f\u4f1a\u5bfc\u81f4\u4f4e\u6548\u7684\u56de\u6eaf\u5faa\u73af\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u4fee\u590d\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f15\u5165Meta Self-Refining\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u63a7\u6267\u884c\u5386\u53f2\u68c0\u6d4b\u632f\u8361\u6027\u5931\u8d25\uff0c\u5e76\u8c03\u7528\u5143\u4fee\u590d\u5668LM\u751f\u6210\u5e73\u8861\u7ade\u4e89\u9700\u6c42\u7684\u7b56\u7565\u6307\u4ee4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u6210\u529f\u4fee\u590d\u56de\u6eaf\u5faa\u73af\uff0c\u4f7f\u8bed\u8a00\u6a21\u578b\u7a0b\u5e8f\u66f4\u9ad8\u6548\u3002", "conclusion": "Meta Self-Refining\u6709\u6548\u89e3\u51b3\u4e86\u7ade\u4e89\u6027\u8f6f\u7ea6\u675f\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u7ba1\u9053\u7684\u6027\u80fd\u3002"}}
{"id": "2507.10593", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10593", "abs": "https://arxiv.org/abs/2507.10593", "authors": ["Peng Ding"], "title": "ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs", "comment": null, "summary": "Large Language Model (LLM) applications are increasingly relying on external\ntools to extend their capabilities beyond text generation. However, current\ntool integration approaches suffer from fragmentation, protocol limitations,\nand implementation complexity, leading to substantial development overhead.\nThis paper presents Toolregistry, a protocol-agnostic tool management library\nthat simplifies tool registration, representation, execution, and lifecycle\nmanagement via a unified interface. Our evaluation demonstrates that\n\\toolregistry achieves 60-80% reduction in tool integration code, up to 3.1x\nperformance improvements through concurrent execution, and 100% compatibility\nwith OpenAI function calling standards. Real-world case studies show\nsignificant improvements in development efficiency and code maintainability\nacross diverse integration scenarios. \\toolregistry is open-source and\navailable at https://github.com/Oaklight/ToolRegistry, with comprehensive\ndocumentation at https://toolregistry.readthedocs.io/.", "AI": {"tldr": "Toolregistry\u662f\u4e00\u4e2a\u534f\u8bae\u65e0\u5173\u7684\u5de5\u5177\u7ba1\u7406\u5e93\uff0c\u901a\u8fc7\u7edf\u4e00\u63a5\u53e3\u7b80\u5316\u5de5\u5177\u6ce8\u518c\u3001\u8868\u793a\u3001\u6267\u884c\u548c\u751f\u547d\u5468\u671f\u7ba1\u7406\uff0c\u663e\u8457\u51cf\u5c11\u96c6\u6210\u4ee3\u7801\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f53\u524dLLM\u5e94\u7528\u7684\u5de5\u5177\u96c6\u6210\u65b9\u6cd5\u5b58\u5728\u788e\u7247\u5316\u3001\u534f\u8bae\u9650\u5236\u548c\u5b9e\u73b0\u590d\u6742\u6027\u95ee\u9898\uff0c\u5bfc\u81f4\u5f00\u53d1\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faToolregistry\uff0c\u4e00\u4e2a\u534f\u8bae\u65e0\u5173\u7684\u5de5\u5177\u7ba1\u7406\u5e93\uff0c\u63d0\u4f9b\u7edf\u4e00\u63a5\u53e3\u7ba1\u7406\u5de5\u5177\u3002", "result": "Toolregistry\u51cf\u5c1160-80%\u7684\u96c6\u6210\u4ee3\u7801\uff0c\u6027\u80fd\u63d0\u53473.1\u500d\uff0c\u517c\u5bb9OpenAI\u51fd\u6570\u8c03\u7528\u6807\u51c6\u3002", "conclusion": "Toolregistry\u663e\u8457\u63d0\u5347\u5f00\u53d1\u6548\u7387\u548c\u4ee3\u7801\u53ef\u7ef4\u62a4\u6027\uff0c\u5df2\u5728\u5f00\u6e90\u793e\u533a\u53d1\u5e03\u3002"}}
{"id": "2507.10578", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10578", "abs": "https://arxiv.org/abs/2507.10578", "authors": ["Jeremy Styborski", "Mingzhi Lyu", "Jiayou Lu", "Nupur Kapur", "Adams Kong"], "title": "When and Where do Data Poisons Attack Textual Inversion?", "comment": "Accepted to ICCV", "summary": "Poisoning attacks pose significant challenges to the robustness of diffusion\nmodels (DMs). In this paper, we systematically analyze when and where poisoning\nattacks textual inversion (TI), a widely used personalization technique for\nDMs. We first introduce Semantic Sensitivity Maps, a novel method for\nvisualizing the influence of poisoning on text embeddings. Second, we identify\nand experimentally verify that DMs exhibit non-uniform learning behavior across\ntimesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias\nand inject adversarial signals predominantly at lower timesteps. Lastly, we\nobserve that adversarial signals distract learning away from relevant concept\nregions within training data, corrupting the TI process. Based on these\ninsights, we propose Safe-Zone Training (SZT), a novel defense mechanism\ncomprised of 3 key components: (1) JPEG compression to weaken high-frequency\npoison signals, (2) restriction to high timesteps during TI training to avoid\nadversarial signals at lower timesteps, and (3) loss masking to constrain\nlearning to relevant regions. Extensive experiments across multiple poisoning\nmethods demonstrate that SZT greatly enhances the robustness of TI against all\npoisoning attacks, improving generative quality beyond prior published\ndefenses. Code: www.github.com/JStyborski/Diff_Lab Data:\nwww.github.com/JStyborski/NC10", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u6269\u6563\u6a21\u578b\uff08DMs\uff09\u4e2d\u6bd2\u653b\u51fb\u5bf9\u6587\u672c\u53cd\u8f6c\uff08TI\uff09\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89c6\u5316\u65b9\u6cd5\uff08Semantic Sensitivity Maps\uff09\uff0c\u5e76\u53d1\u73b0DMs\u5728\u4f4e\u566a\u58f0\u6837\u672c\u4e2d\u8868\u73b0\u51fa\u975e\u5747\u5300\u5b66\u4e60\u884c\u4e3a\u3002\u57fa\u4e8e\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86Safe-Zone Training\uff08SZT\uff09\u9632\u5fa1\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86TI\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4e2d\u6bd2\u653b\u51fb\u5bf9\u6269\u6563\u6a21\u578b\u7684\u9c81\u68d2\u6027\u6784\u6210\u91cd\u5927\u5a01\u80c1\uff0c\u5c24\u5176\u662f\u5bf9\u6587\u672c\u53cd\u8f6c\uff08TI\uff09\u8fd9\u4e00\u5e7f\u6cdb\u4f7f\u7528\u7684\u4e2a\u6027\u5316\u6280\u672f\u3002\u7814\u7a76\u65e8\u5728\u5206\u6790\u653b\u51fb\u7684\u65f6\u673a\u548c\u4f4d\u7f6e\uff0c\u5e76\u63d0\u51fa\u6709\u6548\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "1. \u5f15\u5165Semantic Sensitivity Maps\u53ef\u89c6\u5316\u4e2d\u6bd2\u653b\u51fb\u5bf9\u6587\u672c\u5d4c\u5165\u7684\u5f71\u54cd\uff1b2. \u53d1\u73b0DMs\u5728\u4f4e\u566a\u58f0\u6837\u672c\u4e2d\u8868\u73b0\u51fa\u975e\u5747\u5300\u5b66\u4e60\u884c\u4e3a\uff1b3. \u63d0\u51faSafe-Zone Training\uff08SZT\uff09\u9632\u5fa1\u673a\u5236\uff0c\u5305\u62ecJPEG\u538b\u7f29\u3001\u9650\u5236\u9ad8\u65f6\u95f4\u6b65\u8bad\u7ec3\u548c\u635f\u5931\u63a9\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSZT\u663e\u8457\u63d0\u5347\u4e86TI\u5bf9\u591a\u79cd\u4e2d\u6bd2\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u751f\u6210\u8d28\u91cf\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "SZT\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u9632\u5fa1\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6269\u6563\u6a21\u578b\u5728\u6587\u672c\u53cd\u8f6c\u4efb\u52a1\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.10640", "categories": ["cs.SE", "cs.LG", "cs.SI", "D.2.2"], "pdf": "https://arxiv.org/pdf/2507.10640", "abs": "https://arxiv.org/abs/2507.10640", "authors": ["Labiba Farah", "Mohammad Ridwan Kabir", "Shohel Ahmed", "MD Mohaymen Ul Anam", "Md. Sakibul Islam"], "title": "SENSOR: An ML-Enhanced Online Annotation Tool to Uncover Privacy Concerns from User Reviews in Social-Media Applications", "comment": "26 pages, 9 figures, 5 tables", "summary": "The widespread use of social media applications has raised significant\nprivacy concerns, often highlighted in user reviews. These reviews also provide\ndevelopers with valuable insights into improving apps by addressing issues and\nintroducing better features. However, the sheer volume and nuanced nature of\nreviews make manual identification and prioritization of privacy-related\nconcerns challenging for developers. Previous studies have developed software\nutilities to automatically classify user reviews as privacy-relevant,\nprivacy-irrelevant, bug reports, feature requests, etc., using machine\nlearning. Notably, there is a lack of focus on classifying reviews specifically\nas privacy-related feature requests, privacy-related bug reports, or\nprivacy-irrelevant. This paper introduces SENtinel SORt (SENSOR), an automated\nonline annotation tool designed to help developers annotate and classify user\nreviews into these categories. For automating the annotation of such reviews,\nthis paper introduces the annotation model, GRACE (GRU-based Attention with\nCBOW Embedding), using Gated Recurrent Units (GRU) with Continuous Bag of Words\n(CBOW) and Attention mechanism. Approximately 16000 user reviews from seven\npopular social media apps on Google Play Store, including Instagram, Facebook,\nWhatsApp, Snapchat, X (formerly Twitter), Facebook Lite, and Line were\nanalyzed. Two annotators manually labelled the reviews, achieving a Cohen's\nKappa value of 0.87, ensuring a labeled dataset with high inter-rater agreement\nfor training machine learning models. Among the models tested, GRACE\ndemonstrated the best performance (macro F1-score: 0.9434, macro ROC-AUC:\n0.9934, and accuracy: 95.10%) despite class imbalance. SENSOR demonstrates\nsignificant potential to assist developers with extracting and addressing\nprivacy-related feature requests or bug reports from user reviews, enhancing\nuser privacy and trust.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSENSOR\u5de5\u5177\u548cGRACE\u6a21\u578b\uff0c\u7528\u4e8e\u81ea\u52a8\u5206\u7c7b\u7528\u6237\u8bc4\u8bba\u4e2d\u7684\u9690\u79c1\u76f8\u5173\u9700\u6c42\u6216\u95ee\u9898\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u9ad8\u6548\u5904\u7406\u9690\u79c1\u95ee\u9898\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u7684\u9690\u79c1\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u4f46\u624b\u52a8\u5206\u7c7b\u6d77\u91cf\u7528\u6237\u8bc4\u8bba\u6548\u7387\u4f4e\u4e0b\uff0c\u73b0\u6709\u5de5\u5177\u7f3a\u4e4f\u5bf9\u9690\u79c1\u76f8\u5173\u9700\u6c42\u6216\u95ee\u9898\u7684\u4e13\u95e8\u5206\u7c7b\u3002", "method": "\u63d0\u51faGRACE\u6a21\u578b\uff08\u57fa\u4e8eGRU\u3001CBOW\u548c\u6ce8\u610f\u529b\u673a\u5236\uff09\uff0c\u7528\u4e8e\u81ea\u52a8\u6807\u6ce8\u7528\u6237\u8bc4\u8bba\uff0c\u5e76\u901a\u8fc7SENSOR\u5de5\u5177\u5b9e\u73b0\u5206\u7c7b\u3002\u5206\u6790\u4e8616000\u6761\u7528\u6237\u8bc4\u8bba\uff0c\u4eba\u5de5\u6807\u6ce8\u540e\u8bad\u7ec3\u6a21\u578b\u3002", "result": "GRACE\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff08\u5b8fF1\u5206\u6570\uff1a0.9434\uff0c\u5b8fROC-AUC\uff1a0.9934\uff0c\u51c6\u786e\u7387\uff1a95.10%\uff09\uff0cSENSOR\u5de5\u5177\u80fd\u6709\u6548\u8f85\u52a9\u5f00\u53d1\u8005\u5904\u7406\u9690\u79c1\u95ee\u9898\u3002", "conclusion": "SENSOR\u548cGRACE\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u9ad8\u6548\u5904\u7406\u9690\u79c1\u76f8\u5173\u8bc4\u8bba\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u7528\u6237\u9690\u79c1\u548c\u4fe1\u4efb\u3002"}}
{"id": "2507.10592", "categories": ["cs.CR", "68Q12, 81P68, 11T71"], "pdf": "https://arxiv.org/pdf/2507.10592", "abs": "https://arxiv.org/abs/2507.10592", "authors": ["Steve Tippeconnic"], "title": "Breaking a 5-Bit Elliptic Curve Key using a 133-Qubit Quantum Computer", "comment": "32 pages, 5 figures, real hardware results from IBM Quantum, all\n  code, circuits, and raw data are publicly available for replication", "summary": "This experiment breaks a 5-bit elliptic curve cryptographic key using a\nShor-style quantum attack. Executed on IBM's 133-qubit ibm_torino with Qiskit\nRuntime 2.0, a 15-qubit circuit, comprised of 10 logical qubits and 5 ancilla,\ninterferes over an order-32 elliptic curve subgroup to extract the secret\nscalar k from the public key relation Q = kP, without ever encoding k directly\ninto the oracle. From 16,384 shots, the quantum interference reveals a diagonal\nridge in the 32 x 32 QFT outcome space. The quantum circuit, over 67,000 layers\ndeep, produced valid interference patterns despite extreme circuit depth, and\nclassical post-processing revealed k = 7 in the top 100 invertible (a, b)\nresults. All code, circuits, and raw data are publicly available for\nreplication.", "AI": {"tldr": "\u5b9e\u9a8c\u901a\u8fc7\u91cf\u5b50\u653b\u51fb\u6210\u529f\u7834\u89e35\u4f4d\u692d\u5706\u66f2\u7ebf\u5bc6\u7801\u5bc6\u94a5\uff0c\u4f7f\u7528IBM\u7684133\u91cf\u5b50\u6bd4\u7279\u8bbe\u5907\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u8ba1\u7b97\u7684\u6f5c\u529b\u3002", "motivation": "\u63a2\u7d22\u91cf\u5b50\u8ba1\u7b97\u5728\u5bc6\u7801\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u9a8c\u8bc1Shor\u7b97\u6cd5\u5bf9\u692d\u5706\u66f2\u7ebf\u5bc6\u7801\u7684\u5b9e\u9645\u653b\u51fb\u6548\u679c\u3002", "method": "\u4f7f\u752815\u91cf\u5b50\u6bd4\u7279\u7535\u8def\uff0810\u903b\u8f91\u6bd4\u7279\u548c5\u8f85\u52a9\u6bd4\u7279\uff09\uff0c\u5728IBM\u7684133\u91cf\u5b50\u6bd4\u7279\u8bbe\u5907\u4e0a\u8fd0\u884c\uff0c\u901a\u8fc7\u91cf\u5b50\u5e72\u6d89\u63d0\u53d6\u5bc6\u94a5\u3002", "result": "\u5b9e\u9a8c\u6210\u529f\u4ece16,384\u6b21\u8fd0\u884c\u4e2d\u63d0\u53d6\u51fa\u5bc6\u94a5k=7\uff0c\u9a8c\u8bc1\u4e86\u91cf\u5b50\u5e72\u6d89\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u91cf\u5b50\u8ba1\u7b97\u5bf9\u692d\u5706\u66f2\u7ebf\u5bc6\u7801\u6784\u6210\u5b9e\u9645\u5a01\u80c1\uff0c\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u5df2\u516c\u5f00\u4f9b\u590d\u73b0\u3002"}}
{"id": "2507.10641", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10641", "abs": "https://arxiv.org/abs/2507.10641", "authors": ["Jayant Havare", "Saurav Chaudhary", "Ganesh Ramakrishnan", "Kaushik Maharajan", "Srikanth Tamilselvam"], "title": "A Code Comprehension Benchmark for Large Language Models for Code", "comment": "10 Pages, 5 Figures", "summary": "Large Language Models have shown impressive capabilities in coding tasks like\ncode generation and code completion, as they have been trained on a large\namount of code data. Also, since one of the core pretraining objectives is Next\nToken Prediction, these models tends to learn surface-level syntactic patterns\nin code. However, this does not guarantee code comprehension ability i.e. the\nability to capture the semantics of the code. In our opinion, this is the\nreason why these models often underperform on tasks that require deeper\nsemantic understanding, such as code debugging and code optimization. To\naddress this, we propose fine-tuning these models specifically for code\ncomprehension tasks using large-scale datasets, enabling them to develop a more\nrobust understanding of code semantics. We evaluate three code models of\nvarying sizes on a suite of code comprehension tasks designed to assess\nsemantic understanding beyond surface-level syntactic pattern matching. In\nparticular, we analyze performance on the Subjectivity Grading Task and observe\nthat model performance improves after fine-tuning on relevant downstream tasks.\nThe most significant improvement is seen in the QWQ-32B model, where accuracy\nincreases from 70% to 83.47%. A similar or explainable trend is observed across\nother models, clearly indicating an enhancement in code comprehension ability.\nAmong the models studied, the DPO-fine-tuned Codestral-22B achieves the highest\nmicro-accuracy of 87.66% on the Subjectivity Grading Task.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u548c\u8865\u5168\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4ee3\u7801\u8bed\u4e49\u7684\u6df1\u5c42\u7406\u89e3\u3002\u901a\u8fc7\u9488\u5bf9\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u8fdb\u884c\u5fae\u8c03\uff0c\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5728\u9700\u8981\u6df1\u5c42\u8bed\u4e49\u7406\u89e3\u7684\u4efb\u52a1\uff08\u5982\u4ee3\u7801\u8c03\u8bd5\u548c\u4f18\u5316\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u539f\u56e0\u662f\u5176\u9884\u8bad\u7ec3\u76ee\u6807\u4ec5\u5173\u6ce8\u8868\u9762\u8bed\u6cd5\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u5bf9\u6a21\u578b\u8fdb\u884c\u9488\u5bf9\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u7684\u5fae\u8c03\uff0c\u4f7f\u7528\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4ee5\u589e\u5f3a\u5bf9\u4ee3\u7801\u8bed\u4e49\u7684\u7406\u89e3\u3002", "result": "\u5fae\u8c03\u540e\uff0c\u6a21\u578b\u5728\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u4e2d\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u7279\u522b\u662fQWQ-32B\u6a21\u578b\u51c6\u786e\u7387\u4ece70%\u63d0\u5347\u81f383.47%\u3002", "conclusion": "\u5fae\u8c03\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u5bf9\u4ee3\u7801\u8bed\u4e49\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5176\u4e2dDPO\u5fae\u8c03\u7684Codestral-22B\u5728\u4e3b\u89c2\u8bc4\u5206\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\u3002"}}
{"id": "2507.10610", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10610", "abs": "https://arxiv.org/abs/2507.10610", "authors": ["Zihe Yan", "Zhuosheng Zhang"], "title": "LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents", "comment": "10 pages, 9 figures", "summary": "Graphical user interface (GUI) agents built on multimodal large language\nmodels (MLLMs) have recently demonstrated strong decision-making abilities in\nscreen-based interaction tasks. However, they remain highly vulnerable to\npop-up-based environmental injection attacks, where malicious visual elements\ndivert model attention and lead to unsafe or incorrect actions. Existing\ndefense methods either require costly retraining or perform poorly under\ninductive interference. In this work, we systematically study how such attacks\nalter the attention behavior of GUI agents and uncover a layer-wise attention\ndivergence pattern between correct and incorrect outputs. Based on this\ninsight, we propose \\textbf{LaSM}, a \\textit{Layer-wise Scaling Mechanism} that\nselectively amplifies attention and MLP modules in critical layers. LaSM\nimproves the alignment between model saliency and task-relevant regions without\nadditional training. Extensive experiments across 12 types of pop-up\nperturbations and 4 different model backbones show that LaSM consistently\nenhances the defense success rate. When combined with prompt-level alerts, LaSM\nachieves over 98\\% robustness even under strong inductive attacks. Our findings\nreveal that attention misalignment is a core vulnerability in MLLM agents and\ncan be effectively addressed through selective layer-wise modulation.", "AI": {"tldr": "LaSM\u662f\u4e00\u79cd\u5c42\u95f4\u7f29\u653e\u673a\u5236\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u653e\u5927\u5173\u952e\u5c42\u7684\u6ce8\u610f\u529b\u548cMLP\u6a21\u5757\uff0c\u6709\u6548\u9632\u5fa1GUI\u4ee3\u7406\u7684\u5f39\u51fa\u5f0f\u73af\u5883\u6ce8\u5165\u653b\u51fb\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709\u7684\u9632\u5fa1\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u6602\u8d35\u7684\u91cd\u65b0\u8bad\u7ec3\uff0c\u8981\u4e48\u5728\u5f52\u7eb3\u5e72\u6270\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u800cGUI\u4ee3\u7406\u5bf9\u5f39\u51fa\u5f0f\u653b\u51fb\u9ad8\u5ea6\u8106\u5f31\u3002", "method": "\u901a\u8fc7\u7814\u7a76\u653b\u51fb\u5982\u4f55\u6539\u53d8GUI\u4ee3\u7406\u7684\u6ce8\u610f\u529b\u884c\u4e3a\uff0c\u53d1\u73b0\u5c42\u95f4\u6ce8\u610f\u529b\u5dee\u5f02\u6a21\u5f0f\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51faLaSM\u673a\u5236\u3002", "result": "\u572812\u79cd\u5f39\u51fa\u5f0f\u6270\u52a8\u548c4\u79cd\u6a21\u578b\u9aa8\u5e72\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cLaSM\u663e\u8457\u63d0\u9ad8\u4e86\u9632\u5fa1\u6210\u529f\u7387\uff0c\u7ed3\u5408\u63d0\u793a\u7ea7\u8b66\u62a5\u540e\u7a33\u5065\u6027\u8d85\u8fc798%\u3002", "conclusion": "\u6ce8\u610f\u529b\u9519\u4f4d\u662fMLLM\u4ee3\u7406\u7684\u6838\u5fc3\u6f0f\u6d1e\uff0cLaSM\u901a\u8fc7\u9009\u62e9\u6027\u5c42\u95f4\u8c03\u5236\u6709\u6548\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u3002"}}
{"id": "2507.10646", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10646", "abs": "https://arxiv.org/abs/2507.10646", "authors": ["Myeongsoo Kim", "Shweta Garg", "Baishakhi Ray", "Varun Kumar", "Anoop Deoras"], "title": "CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance", "comment": null, "summary": "Programming assistants powered by large language models have transformed\nsoftware development, yet most benchmarks focus narrowly on code generation\ntasks. Recent efforts like InfiBench and StackEval attempt to address this gap\nusing Stack Overflow data but remain limited to single-turn interactions in\nisolated contexts, require significant manual curation, and fail to represent\ncomplete project environments. We introduce CodeAssistBench (CAB), the first\nbenchmark framework for evaluating multi-turn programming assistance in\nrealistic settings that address real-world questions about actual codebases.\nUnlike existing programming Q&A benchmarks, CAB automatically generates\nscalable datasets from question-related GitHub issues using configurable\nparameters (e.g., repository creation date, star count, programming languages),\nand includes automatic containerization of codebases for evaluation. It then\nevaluates models through simulated users in these containerized environments\nwith full codebase access. Using this framework, we constructed a test set of\n3,286 real-world programming questions across 231 repositories, spanning seven\nprogramming languages and diverse problem domains. Our evaluation of leading\nLLMs reveals a substantial capability gap: while models perform well on Stack\nOverflow questions with success rates of 70-83%, they resolve only up to 16.49%\nof CAB's recent issues. This discrepancy highlights the challenges of providing\nassistance in complex, project-specific contexts versus answering standalone\nquestions.", "AI": {"tldr": "CodeAssistBench (CAB) \u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u8f6e\u7f16\u7a0b\u8f85\u52a9\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u5728\u9879\u76ee\u73af\u5883\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\uff08\u5982InfiBench\u548cStackEval\uff09\u5c40\u9650\u4e8e\u5355\u8f6e\u4ea4\u4e92\u548c\u5b64\u7acb\u73af\u5883\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u9879\u76ee\u4e2d\u7684\u590d\u6742\u9700\u6c42\u3002CAB\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "CAB\u901a\u8fc7\u4eceGitHub\u95ee\u9898\u81ea\u52a8\u751f\u6210\u53ef\u6269\u5c55\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528\u5bb9\u5668\u5316\u4ee3\u7801\u5e93\u8fdb\u884c\u591a\u8f6e\u4ea4\u4e92\u8bc4\u4f30\u3002", "result": "\u6d4b\u8bd5\u96c6\u5305\u542b3,286\u4e2a\u771f\u5b9e\u7f16\u7a0b\u95ee\u9898\uff0c\u8986\u76d67\u79cd\u8bed\u8a00\u3002\u8bc4\u4f30\u663e\u793a\uff0c\u6a21\u578b\u5728Stack Overflow\u4e0a\u8868\u73b0\u826f\u597d\uff0870-83%\u6210\u529f\u7387\uff09\uff0c\u4f46\u5728CAB\u4e2d\u4ec5\u89e3\u51b316.49%\u7684\u95ee\u9898\u3002", "conclusion": "CAB\u63ed\u793a\u4e86\u6a21\u578b\u5728\u590d\u6742\u9879\u76ee\u73af\u5883\u4e2d\u7684\u80fd\u529b\u5dee\u8ddd\uff0c\u5f3a\u8c03\u4e86\u771f\u5b9e\u7f16\u7a0b\u8f85\u52a9\u7684\u6311\u6218\u3002"}}
{"id": "2507.10621", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.GT"], "pdf": "https://arxiv.org/pdf/2507.10621", "abs": "https://arxiv.org/abs/2507.10621", "authors": ["Quanyan Zhu"], "title": "Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats", "comment": null, "summary": "Protecting cyberspace requires not only advanced tools but also a shift in\nhow we reason about threats, trust, and autonomy. Traditional cybersecurity\nmethods rely on manual responses and brittle heuristics. To build proactive and\nintelligent defense systems, we need integrated theoretical frameworks and\nsoftware tools. Game theory provides a rigorous foundation for modeling\nadversarial behavior, designing strategic defenses, and enabling trust in\nautonomous systems. Meanwhile, software tools process cyber data, visualize\nattack surfaces, verify compliance, and suggest mitigations. Yet a disconnect\nremains between theory and practical implementation.\n  The rise of Large Language Models (LLMs) and agentic AI offers a new path to\nbridge this gap. LLM-powered agents can operationalize abstract strategies into\nreal-world decisions. Conversely, game theory can inform the reasoning and\ncoordination of these agents across complex workflows. LLMs also challenge\nclassical game-theoretic assumptions, such as perfect rationality or static\npayoffs, prompting new models aligned with cognitive and computational\nrealities. This co-evolution promises richer theoretical foundations and novel\nsolution concepts. Agentic AI also reshapes software design: systems must now\nbe modular, adaptive, and trust-aware from the outset.\n  This chapter explores the intersection of game theory, agentic AI, and\ncybersecurity. We review key game-theoretic frameworks (e.g., static, dynamic,\nBayesian, and signaling games) and solution concepts. We then examine how LLM\nagents can enhance cyber defense and introduce LLM-driven games that embed\nreasoning into AI agents. Finally, we explore multi-agent workflows and\ncoordination games, outlining how this convergence fosters secure, intelligent,\nand adaptive cyber systems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u7ed3\u5408\u535a\u5f08\u8bba\u548c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4ee3\u7406\u6765\u63d0\u5347\u7f51\u7edc\u5b89\u5168\u7684\u4e3b\u52a8\u6027\u548c\u667a\u80fd\u5316\u3002", "motivation": "\u4f20\u7edf\u7f51\u7edc\u5b89\u5168\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u54cd\u5e94\u548c\u8106\u5f31\u7684\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u7f3a\u4e4f\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u7d27\u5bc6\u7ed3\u5408\u3002", "method": "\u901a\u8fc7\u535a\u5f08\u8bba\u5efa\u6a21\u5bf9\u6297\u884c\u4e3a\uff0c\u7ed3\u5408LLM\u4ee3\u7406\u5c06\u62bd\u8c61\u7b56\u7565\u8f6c\u5316\u4e3a\u5b9e\u9645\u51b3\u7b56\uff0c\u5e76\u8bbe\u8ba1\u6a21\u5757\u5316\u3001\u81ea\u9002\u5e94\u7684\u7cfb\u7edf\u3002", "result": "\u63d0\u51fa\u4e86\u535a\u5f08\u8bba\u4e0eLLM\u4ee3\u7406\u534f\u540c\u7684\u65b0\u6846\u67b6\uff0c\u4e3a\u7f51\u7edc\u5b89\u5168\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u7406\u8bba\u57fa\u7840\u548c\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u535a\u5f08\u8bba\u4e0e\u667a\u80fd\u4ee3\u7406\u7684\u7ed3\u5408\u4e3a\u6784\u5efa\u5b89\u5168\u3001\u667a\u80fd\u548c\u81ea\u9002\u5e94\u7684\u7f51\u7edc\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84\u3002"}}
{"id": "2507.10729", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10729", "abs": "https://arxiv.org/abs/2507.10729", "authors": ["Duong Nguyen", "Thanh Le-Cong", "Triet Huynh Minh Le", "M. Ali Babar", "Quyet-Thang Huynh"], "title": "Toward Realistic Evaluations of Just-In-Time Vulnerability Prediction", "comment": null, "summary": "Modern software systems are increasingly complex, presenting significant\nchallenges in quality assurance. Just-in-time vulnerability prediction (JIT-VP)\nis a proactive approach to identifying vulnerable commits and providing early\nwarnings about potential security risks. However, we observe that current\nJIT-VP evaluations rely on an idealized setting, where the evaluation datasets\nare artificially balanced, consisting exclusively of vulnerability-introducing\nand vulnerability-fixing commits.\n  To address this limitation, this study assesses the effectiveness of JIT-VP\ntechniques under a more realistic setting that includes both\nvulnerability-related and vulnerability-neutral commits. To enable a reliable\nevaluation, we introduce a large-scale public dataset comprising over one\nmillion commits from FFmpeg and the Linux kernel. Our empirical analysis of\neight state-of-the-art JIT-VP techniques reveals a significant decline in\npredictive performance when applied to real-world conditions; for example, the\naverage PR-AUC on Linux drops 98\\% from 0.805 to 0.016. This discrepancy is\nmainly attributed to the severe class imbalance in real-world datasets, where\nvulnerability-introducing commits constitute only a small fraction of all\ncommits.\n  To mitigate this issue, we explore the effectiveness of widely adopted\ntechniques for handling dataset imbalance, including customized loss functions,\noversampling, and undersampling. Surprisingly, our experimental results\nindicate that these techniques are ineffective in addressing the imbalance\nproblem in JIT-VP. These findings underscore the importance of realistic\nevaluations of JIT-VP and the need for domain-specific techniques to address\ndata imbalance in such scenarios.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u5373\u65f6\u6f0f\u6d1e\u9884\u6d4b\uff08JIT-VP\uff09\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u5176\u5728\u73b0\u5b9e\u6570\u636e\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u5e76\u63d0\u51fa\u9700\u9886\u57df\u7279\u5b9a\u65b9\u6cd5\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u5f53\u524dJIT-VP\u8bc4\u4f30\u4f9d\u8d56\u7406\u60f3\u5316\u6570\u636e\u96c6\uff0c\u7f3a\u4e4f\u5bf9\u73b0\u5b9e\u573a\u666f\u4e2d\u6570\u636e\u4e0d\u5e73\u8861\u7684\u8003\u91cf\uff0c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5f15\u5165\u5305\u542b100\u591a\u4e07\u4e2a\u63d0\u4ea4\u7684\u5927\u89c4\u6a21\u516c\u5f00\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u516b\u79cd\u5148\u8fdbJIT-VP\u6280\u672f\u5728\u771f\u5b9e\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u63a2\u7d22\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u7684\u65b9\u6cd5\u3002", "result": "\u73b0\u5b9e\u6761\u4ef6\u4e0bJIT-VP\u6027\u80fd\u5927\u5e45\u4e0b\u964d\uff08\u5982PR-AUC\u4ece0.805\u964d\u81f30.016\uff09\uff0c\u73b0\u6709\u4e0d\u5e73\u8861\u5904\u7406\u6280\u672f\u6548\u679c\u4e0d\u4f73\u3002", "conclusion": "\u5f3a\u8c03\u771f\u5b9e\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u5e76\u547c\u5401\u5f00\u53d1\u9886\u57df\u7279\u5b9a\u6280\u672f\u4ee5\u89e3\u51b3JIT-VP\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002"}}
{"id": "2507.10622", "categories": ["cs.CR", "cond-mat.dis-nn", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10622", "abs": "https://arxiv.org/abs/2507.10622", "authors": ["HyeYoung Lee", "Muhammad Nadeem", "Pavel Tsoi"], "title": "Spectral Feature Extraction for Robust Network Intrusion Detection Using MFCCs", "comment": null, "summary": "The rapid expansion of Internet of Things (IoT) networks has led to a surge\nin security vulnerabilities, emphasizing the critical need for robust anomaly\ndetection and classification techniques. In this work, we propose a novel\napproach for identifying anomalies in IoT network traffic by leveraging the\nMel-frequency cepstral coefficients (MFCC) and ResNet-18, a deep learning model\nknown for its effectiveness in feature extraction and image-based tasks.\nLearnable MFCCs enable adaptive spectral feature representation, capturing the\ntemporal patterns inherent in network traffic more effectively than traditional\nfixed MFCCs. We demonstrate that transforming raw signals into MFCCs maps the\ndata into a higher-dimensional space, enhancing class separability and enabling\nmore effective multiclass classification. Our approach combines the strengths\nof MFCCs with the robust feature extraction capabilities of ResNet-18, offering\na powerful framework for anomaly detection. The proposed model is evaluated on\nthree widely used IoT intrusion detection datasets: CICIoT2023, NSL-KDD, and\nIoTID20. The experimental results highlight the potential of integrating\nadaptive signal processing techniques with deep learning architectures to\nachieve robust and scalable anomaly detection in heterogeneous IoT network\nlandscapes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eMFCC\u548cResNet-18\u7684\u7269\u8054\u7f51\u7f51\u7edc\u6d41\u91cf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9891\u8c31\u7279\u5f81\u8868\u793a\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u5347\u5206\u7c7b\u6548\u679c\u3002", "motivation": "\u7269\u8054\u7f51\u7f51\u7edc\u6269\u5c55\u5e26\u6765\u7684\u5b89\u5168\u6f0f\u6d1e\u95ee\u9898\u4e9f\u9700\u9ad8\u6548\u7684\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\u3002", "method": "\u5229\u7528\u53ef\u5b66\u4e60\u7684MFCC\u548cResNet-18\u6a21\u578b\uff0c\u5c06\u539f\u59cb\u4fe1\u53f7\u8f6c\u6362\u4e3a\u9ad8\u7ef4\u7a7a\u95f4\u4ee5\u589e\u5f3a\u5206\u7c7b\u6548\u679c\u3002", "result": "\u5728CICIoT2023\u3001NSL-KDD\u548cIoTID20\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u5408\u81ea\u9002\u5e94\u4fe1\u53f7\u5904\u7406\u548c\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u4e3a\u7269\u8054\u7f51\u7f51\u7edc\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6848\u3002"}}
{"id": "2507.10562", "categories": ["cs.AI", "cs.CR", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10562", "abs": "https://arxiv.org/abs/2507.10562", "authors": ["Hari Masoor"], "title": "SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents", "comment": "7 pages, 4 figures, 3 implementation examples. Original work\n  submitted as a preprint", "summary": "Current AI agent architectures suffer from ephemeral memory limitations,\npreventing effective collaboration and knowledge sharing across sessions and\nagent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a\nnovel framework that enables persistent, secure, and semantically searchable\nmemory sharing among AI agents. Our protocol addresses three critical\nchallenges: (1) persistent context preservation across agent sessions, (2)\nsecure multi-agent collaboration with fine-grained access control, and (3)\nefficient semantic discovery of relevant historical context. SAMEP implements a\ndistributed memory repository with vector-based semantic search, cryptographic\naccess controls (AES-256-GCM), and standardized APIs compatible with existing\nagent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness\nacross diverse domains including multi-agent software development, healthcare\nAI with HIPAA compliance, and multi-modal processing pipelines. Experimental\nresults show 73% reduction in redundant computations, 89% improvement in\ncontext relevance scores, and complete compliance with regulatory requirements\nincluding audit trail generation. SAMEP enables a new paradigm of persistent,\ncollaborative AI agent ecosystems while maintaining security and privacy\nguarantees.", "AI": {"tldr": "SAMEP\u534f\u8bae\u89e3\u51b3\u4e86AI\u4ee3\u7406\u95f4\u8bb0\u5fc6\u5171\u4eab\u7684\u77ed\u6682\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u6301\u4e45\u3001\u5b89\u5168\u4e14\u53ef\u8bed\u4e49\u641c\u7d22\u7684\u8bb0\u5fc6\u4ea4\u6362\u6846\u67b6\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u67b6\u6784\u5b58\u5728\u8bb0\u5fc6\u77ed\u6682\u6027\u95ee\u9898\uff0c\u9650\u5236\u4e86\u8de8\u4f1a\u8bdd\u548c\u4ee3\u7406\u95f4\u7684\u534f\u4f5c\u4e0e\u77e5\u8bc6\u5171\u4eab\u3002", "method": "\u63d0\u51faSAMEP\u6846\u67b6\uff0c\u5305\u62ec\u5206\u5e03\u5f0f\u8bb0\u5fc6\u5b58\u50a8\u3001\u5411\u91cf\u8bed\u4e49\u641c\u7d22\u3001\u52a0\u5bc6\u8bbf\u95ee\u63a7\u5236\u548c\u6807\u51c6\u5316API\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u51cf\u5c11\u4e8673%\u5197\u4f59\u8ba1\u7b97\uff0c\u63d0\u5347\u4e8689%\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff0c\u5e76\u5b8c\u5168\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u3002", "conclusion": "SAMEP\u4e3a\u6301\u4e45\u534f\u4f5c\u7684AI\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b89\u5168\u3001\u9690\u79c1\u4fdd\u969c\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2507.10753", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10753", "abs": "https://arxiv.org/abs/2507.10753", "authors": ["Kasper Lien Oftebro", "Anh Nguyen-Duc", "Kai-Kristian Kemell"], "title": "GenAI-Enabled Backlog Grooming in Agile Software Projects: An Empirical Study", "comment": null, "summary": "Effective backlog management is critical for ensuring that development teams\nremain aligned with evolving requirements and stakeholder expectations.\nHowever, as product backlogs consistently grow in scale and complexity, they\ntend to become cluttered with redundant, outdated, or poorly defined tasks,\ncomplicating prioritization and decision making processes. This study\ninvestigates whether a generative-AI (GenAI) assistant can automate backlog\ngrooming in Agile software projects without sacrificing accuracy or\ntransparency. Through Design Science cycles, we developed a Jira plug-in that\nembeds backlog issues with the vector database, detects duplicates via cosine\nsimilarity, and leverage the GPT-4o model to propose merges, deletions, or new\nissues. We found that AI-assisted backlog grooming achieved 100 percent\nprecision while reducing the time-to-completion by 45 percent. The findings\ndemonstrated the tool's potential to streamline backlog refinement processes\nwhile improving user experiences.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u52a9\u624b\u80fd\u5426\u5728\u4e0d\u727a\u7272\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u7684\u524d\u63d0\u4e0b\uff0c\u81ea\u52a8\u5316\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5f85\u529e\u4e8b\u9879\u6574\u7406\u3002\u901a\u8fc7\u8bbe\u8ba1\u79d1\u5b66\u65b9\u6cd5\u5f00\u53d1\u7684Jira\u63d2\u4ef6\uff0c\u7ed3\u5408\u5411\u91cf\u6570\u636e\u5e93\u548cGPT-4o\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u968f\u7740\u4ea7\u54c1\u5f85\u529e\u4e8b\u9879\u89c4\u6a21\u548c\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u5197\u4f59\u3001\u8fc7\u65f6\u6216\u5b9a\u4e49\u4e0d\u6e05\u7684\u4efb\u52a1\u5806\u79ef\uff0c\u5bfc\u81f4\u4f18\u5148\u7ea7\u6392\u5e8f\u548c\u51b3\u7b56\u8fc7\u7a0b\u590d\u6742\u5316\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u79d1\u5b66\u5faa\u73af\u5f00\u53d1\u4e86\u4e00\u4e2aJira\u63d2\u4ef6\uff0c\u5229\u7528\u5411\u91cf\u6570\u636e\u5e93\u5d4c\u5165\u5f85\u529e\u4e8b\u9879\uff0c\u901a\u8fc7\u4f59\u5f26\u76f8\u4f3c\u5ea6\u68c0\u6d4b\u91cd\u590d\u9879\uff0c\u5e76\u501f\u52a9GPT-4o\u6a21\u578b\u63d0\u51fa\u5408\u5e76\u3001\u5220\u9664\u6216\u65b0\u589e\u4efb\u52a1\u7684\u5efa\u8bae\u3002", "result": "AI\u8f85\u52a9\u7684\u5f85\u529e\u4e8b\u9879\u6574\u7406\u5b9e\u73b0\u4e86100%\u7684\u7cbe\u786e\u5ea6\uff0c\u5e76\u5c06\u5b8c\u6210\u65f6\u95f4\u51cf\u5c11\u4e8645%\u3002", "conclusion": "\u8be5\u5de5\u5177\u5c55\u793a\u4e86\u5728\u4f18\u5316\u5f85\u529e\u4e8b\u9879\u7ec6\u5316\u6d41\u7a0b\u548c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.10627", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.10627", "abs": "https://arxiv.org/abs/2507.10627", "authors": ["Xiaojian Zhang", "Junqing Wang", "Kerui Chen", "Peiyuan Zhao", "Huiyuan Bai"], "title": "Crypto-Assisted Graph Degree Sequence Release under Local Differential Privacy", "comment": null, "summary": "Given a graph $G$ defined in a domain $\\mathcal{G}$, we investigate locally\ndifferentially private mechanisms to release a degree sequence on $\\mathcal{G}$\nthat accurately approximates the actual degree distribution. Existing solutions\nfor this problem mostly use graph projection techniques based on edge deletion\nprocess, using a threshold parameter $\\theta$ to bound node degrees. However,\nthis approach presents a fundamental trade-off in threshold parameter\nselection. While large $\\theta$ values introduce substantial noise in the\nreleased degree sequence, small $\\theta$ values result in more edges removed\nthan necessary. Furthermore, $\\theta$ selection leads to an excessive\ncommunication cost. To remedy existing solutions' deficiencies, we present\nCADR-LDP, an efficient framework incorporating encryption techniques and\ndifferentially private mechanisms to release the degree sequence. In CADR-LDP,\nwe first use the crypto-assisted Optimal-$\\theta$-Selection method to select\nthe optimal parameter with a low communication cost. Then, we use the LPEA-LOW\nmethod to add some edges for each node with the edge addition process in local\nprojection. LPEA-LOW prioritizes the projection with low-degree nodes, which\ncan retain more edges for such nodes and reduce the projection error.\nTheoretical analysis shows that CADR-LDP satisfies $\\epsilon$-node local\ndifferential privacy. The experimental results on eight graph datasets show\nthat our solution outperforms existing methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCADR-LDP\u7684\u9ad8\u6548\u6846\u67b6\uff0c\u7ed3\u5408\u52a0\u5bc6\u6280\u672f\u548c\u5dee\u5206\u9690\u79c1\u673a\u5236\uff0c\u7528\u4e8e\u53d1\u5e03\u8fd1\u4f3c\u5b9e\u9645\u5ea6\u5206\u5e03\u7684\u5ea6\u5e8f\u5217\u3002\u901a\u8fc7\u4f18\u5316\u9608\u503c\u9009\u62e9\u548c\u8fb9\u7f18\u6dfb\u52a0\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u901a\u4fe1\u6210\u672c\u548c\u51c6\u786e\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u53d1\u5e03\u56fe\u7684\u5ea6\u5e8f\u5217\u65f6\uff0c\u5b58\u5728\u9608\u503c\u9009\u62e9\u56f0\u96be\u3001\u901a\u4fe1\u6210\u672c\u9ad8\u548c\u51c6\u786e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u8bba\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "CADR-LDP\u6846\u67b6\u7ed3\u5408\u4e86\u52a0\u5bc6\u8f85\u52a9\u7684\u6700\u4f18\u9608\u503c\u9009\u62e9\u65b9\u6cd5\uff08Optimal-\u03b8-Selection\uff09\u548c\u5c40\u90e8\u6295\u5f71\u7684\u8fb9\u7f18\u6dfb\u52a0\u65b9\u6cd5\uff08LPEA-LOW\uff09\uff0c\u4f18\u5148\u5904\u7406\u4f4e\u5ea6\u8282\u70b9\u4ee5\u51cf\u5c11\u8bef\u5dee\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660eCADR-LDP\u6ee1\u8db3\u03b5-\u8282\u70b9\u5c40\u90e8\u5dee\u5206\u9690\u79c1\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u5728\u516b\u4e2a\u56fe\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CADR-LDP\u901a\u8fc7\u4f18\u5316\u9608\u503c\u9009\u62e9\u548c\u8fb9\u7f18\u6dfb\u52a0\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5ea6\u5e8f\u5217\u53d1\u5e03\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.10566", "categories": ["cs.AI", "cs.GT", "cs.LG", "cs.MA", "cs.NE", "68T07, 68T40, 91A20", "I.2.6; I.2.11; I.2.4"], "pdf": "https://arxiv.org/pdf/2507.10566", "abs": "https://arxiv.org/abs/2507.10566", "authors": ["Hung Ming Liu"], "title": "AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems", "comment": "30 pages, 4 figures", "summary": "In Decentralized Multi-Agent Reinforcement Learning (MARL), the development\nof Emergent Communication has long been constrained by the ``Joint Exploration\nDilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .\nTraditional methods address this by introducing inductive biases to facilitate\ncommunication emergence . This study fundamentally questions whether such\nartificial inductive biases are, in fact, over-engineering. Through experiments\nwith the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized\nVariational Autoencoder (VQ-VAE), we demonstrate that when agents possess an\nendogenous symbol system, their neural representations naturally exhibit\nspontaneous semantic compression and Nash equilibrium-driven semantic\nconvergence, achieving effective symbolic communication without external\ninductive biases. This aligns with recent neuroscience findings suggesting that\nthe human brain does not directly use human language for internal thought , and\nresonates with research on ``soft thinking'' capabilities in Large Language\nModels (LLMs) . Compared to traditional explicit communication methods, AIM\ndemonstrates stronger generality and efficiency. The interpretable analysis\ntoolkit developed in this study confirms that symbol usage exhibits a\nsignificant power-law distribution, leading to three major theoretical\ninsights: the ``Neural Communication Hypothesis'', the ``Tool-First\nPrinciple'', and the ``Semantic Interpretability Paradigm''. Future research\nwill explore the integration of Hierarchical Quantized Variational Autoencoders\n(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the\npotential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This\ndiscovery offers new avenues for bridging symbolism and connectionism.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7AIM\u6846\u67b6\u8bc1\u660e\uff0c\u5728\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u53ef\u5b9e\u73b0\u81ea\u7136\u8bed\u4e49\u538b\u7f29\u4e0e\u7eb3\u4ec0\u5747\u8861\u9a71\u52a8\u7684\u8bed\u4e49\u6536\u655b\uff0c\u65e0\u9700\u5916\u90e8\u5f52\u7eb3\u504f\u7f6e\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u5f52\u7eb3\u504f\u7f6e\u4fc3\u8fdb\u901a\u4fe1\uff0c\u4f46\u672c\u7814\u7a76\u8d28\u7591\u5176\u662f\u5426\u8fc7\u5ea6\u5de5\u7a0b\u5316\uff0c\u63a2\u7d22\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u7684\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u57fa\u4e8eVQ-VAE\u7684AIM\u6846\u67b6\uff0c\u5206\u6790\u667a\u80fd\u4f53\u7684\u795e\u7ecf\u8868\u5f81\u4e0e\u7b26\u53f7\u901a\u4fe1\u884c\u4e3a\u3002", "result": "AIM\u6846\u67b6\u5b9e\u73b0\u9ad8\u6548\u7b26\u53f7\u901a\u4fe1\uff0c\u7b26\u53f7\u4f7f\u7528\u5448\u73b0\u5e42\u5f8b\u5206\u5e03\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u9879\u7406\u8bba\u89c1\u89e3\u3002", "conclusion": "\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u4e3a\u8fde\u63a5\u7b26\u53f7\u4e3b\u4e49\u4e0e\u8fde\u63a5\u4e3b\u4e49\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u672a\u6765\u5c06\u63a2\u7d22HQ-VAE\u589e\u5f3a\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2507.10785", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10785", "abs": "https://arxiv.org/abs/2507.10785", "authors": ["Michael Neumann", "Eva-Maria Sch\u00f6n", "Mali Senapathi", "Maria Rauschenberger", "Tiago Silva da Silva"], "title": "Towards a Closer Collaboration Between Practice and Research in Agile Software Development Workshop: A Summary and Research Agenda", "comment": null, "summary": "Agile software development principles and values have been widely adopted\nacross various industries, influencing products and services globally. Despite\nits increasing popularity, a significant gap remains between research and\npractical implementation. This paper presents the findings of the first\ninternational workshop designed to foster collaboration between research and\npractice in agile software development. We discuss the main themes and factors\nidentified by the workshop participants that contribute to this gap, strategies\nto bridge it, and the challenges that require further research attention.", "AI": {"tldr": "\u672c\u6587\u603b\u7ed3\u4e86\u9996\u6b21\u56fd\u9645\u7814\u8ba8\u4f1a\u7684\u6210\u679c\uff0c\u63a2\u8ba8\u4e86\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7814\u7a76\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\u53ca\u5176\u89e3\u51b3\u7b56\u7565\u3002", "motivation": "\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u867d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u7814\u7a76\u4e0e\u5b9e\u9645\u5b9e\u65bd\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u9700\u4fc3\u8fdb\u4e24\u8005\u7684\u534f\u4f5c\u3002", "method": "\u901a\u8fc7\u56fd\u9645\u7814\u8ba8\u4f1a\u6536\u96c6\u53c2\u4e0e\u8005\u610f\u89c1\uff0c\u5206\u6790\u4e3b\u8981\u4e3b\u9898\u548c\u56e0\u7d20\u3002", "result": "\u8bc6\u522b\u4e86\u5bfc\u81f4\u5dee\u8ddd\u7684\u56e0\u7d20\u3001\u89e3\u51b3\u7b56\u7565\u53ca\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u6311\u6218\u3002", "conclusion": "\u7814\u8ba8\u4f1a\u4e3a\u7f29\u5c0f\u7814\u7a76\u4e0e\u5b9e\u8df5\u7684\u5dee\u8ddd\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u4f46\u4ecd\u9700\u66f4\u591a\u7814\u7a76\u3002"}}
{"id": "2507.10730", "categories": ["cs.CR", "cs.DB", "cs.DC", "cs.DS", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.10730", "abs": "https://arxiv.org/abs/2507.10730", "authors": ["Yin Li", "Sharad Mehrota", "Shantanu Sharma", "Komal Kumari"], "title": "Access Control for Information-Theoretically Secure Key-Document Stores", "comment": "An extended abstract of this version has been accepted in VLDB 2025", "summary": "This paper presents a novel key-based access control technique for secure\noutsourcing key-value stores where values correspond to documents that are\nindexed and accessed using keys. The proposed approach adopts Shamir's\nsecret-sharing that offers unconditional or information-theoretic security. It\nsupports keyword-based document retrieval while preventing leakage of the data,\naccess rights of users, or the size (\\textit{i}.\\textit{e}., volume of the\noutput that satisfies a query). The proposed approach allows servers to detect\n(and abort) malicious clients from gaining unauthorized access to data, and\nprevents malicious servers from altering data undetected while ensuring\nefficient access -- it takes 231.5ms over 5,000 keywords across 500,000 files.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bc6\u94a5\u7684\u8bbf\u95ee\u63a7\u5236\u6280\u672f\uff0c\u7528\u4e8e\u5b89\u5168\u5916\u5305\u952e\u503c\u5b58\u50a8\uff0c\u652f\u6301\u5173\u952e\u8bcd\u68c0\u7d22\u4e14\u9632\u6b62\u6570\u636e\u6cc4\u9732\u3002", "motivation": "\u89e3\u51b3\u5916\u5305\u952e\u503c\u5b58\u50a8\u4e2d\u7684\u6570\u636e\u5b89\u5168\u3001\u8bbf\u95ee\u6743\u9650\u548c\u67e5\u8be2\u8f93\u51fa\u5927\u5c0f\u6cc4\u9732\u95ee\u9898\u3002", "method": "\u91c7\u7528Shamir\u7684\u79d8\u5bc6\u5171\u4eab\u6280\u672f\uff0c\u63d0\u4f9b\u65e0\u6761\u4ef6\u5b89\u5168\u6027\uff0c\u652f\u6301\u5173\u952e\u8bcd\u68c0\u7d22\u5e76\u9632\u6b62\u6076\u610f\u8bbf\u95ee\u3002", "result": "\u5728500,000\u6587\u4ef6\u4e2d\u5904\u74065,000\u4e2a\u5173\u952e\u8bcd\u8017\u65f6231.5ms\uff0c\u80fd\u68c0\u6d4b\u5e76\u963b\u6b62\u6076\u610f\u5ba2\u6237\u7aef\u548c\u670d\u52a1\u5668\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u9ad8\u6548\u8bbf\u95ee\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b89\u5168\u6027\u548c\u9632\u7be1\u6539\u80fd\u529b\u3002"}}
{"id": "2507.10571", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10571", "abs": "https://arxiv.org/abs/2507.10571", "authors": ["Konstantinos I. Roumeliotis", "Ranjan Sapkota", "Manoj Karkee", "Nikolaos D. Tselikas"], "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning", "comment": null, "summary": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent\narchitectures that blend visual and language understanding. Yet, a pressing\nchallenge remains: How can we trust these agents especially in zero-shot\nsettings with no fine-tuning? We introduce a novel modular Agentic AI visual\nclassification framework that integrates generalist multimodal agents with a\nnon-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)\nmodule. Applied to apple leaf disease diagnosis, we benchmark three\nconfigurations: (I) zero-shot with confidence-based orchestration, (II)\nfine-tuned agents with improved performance, and (III) trust-calibrated\norchestration enhanced by CLIP-based image retrieval and re-evaluation loops.\nUsing confidence calibration metrics (ECE, OCR, CCC), the orchestrator\nmodulates trust across agents. Our results demonstrate a 77.94\\% accuracy\nimprovement in the zero-shot setting using trust-aware orchestration and RAG,\nachieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL\ndisplayed overconfidence. Furthermore, image-RAG grounded predictions with\nvisually similar cases, enabling correction of agent overconfidence via\niterative re-evaluation. The proposed system separates perception (vision\nagents) from meta-reasoning (orchestrator), enabling scalable and interpretable\nmulti-agent AI. This blueprint is extensible to diagnostics, biology, and other\ntrust-critical domains. All models, prompts, results, and system components\nincluding the complete software source code are openly released to support\nreproducibility, transparency, and community benchmarking at Github:\nhttps://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684\u591a\u667a\u80fd\u4f53AI\u89c6\u89c9\u5206\u7c7b\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u901a\u7528\u591a\u6a21\u6001\u667a\u80fd\u4f53\u3001\u975e\u89c6\u89c9\u63a8\u7406\u534f\u8c03\u5668\u548cRAG\u6a21\u5757\uff0c\u7528\u4e8e\u82f9\u679c\u53f6\u75c5\u8bca\u65ad\uff0c\u663e\u8457\u63d0\u5347\u4e86\u96f6\u6837\u672c\u8bbe\u7f6e\u7684\u51c6\u786e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53AI\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e2d\u7684\u53ef\u4fe1\u5ea6\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u7406\u89e3\u7ed3\u5408\u7684\u9886\u57df\u3002", "method": "\u5f15\u5165\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5305\u62ec\u591a\u6a21\u6001\u667a\u80fd\u4f53\u3001\u534f\u8c03\u5668\u548cRAG\u6a21\u5757\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u6821\u51c6\u548c\u56fe\u50cf\u68c0\u7d22\u4f18\u5316\u4fe1\u4efb\u5206\u914d\u3002", "result": "\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u51c6\u786e\u7387\u63d0\u534777.94%\uff0c\u603b\u4f53\u8fbe\u523085.63%\uff0cGPT-4o\u8868\u73b0\u66f4\u4f18\u6821\u51c6\uff0cQwen-2.5-VL\u5b58\u5728\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5206\u79bb\u611f\u77e5\u4e0e\u5143\u63a8\u7406\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u548c\u53ef\u89e3\u91ca\u7684\u591a\u667a\u80fd\u4f53AI\uff0c\u9002\u7528\u4e8e\u8bca\u65ad\u548c\u751f\u7269\u7b49\u4fe1\u4efb\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2507.10818", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10818", "abs": "https://arxiv.org/abs/2507.10818", "authors": ["Jasmine Latendresse", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow", "comment": null, "summary": "Software libraries are central to the functionality, security, and\nmaintainability of modern code. As developers increasingly turn to Large\nLanguage Models (LLMs) to assist with programming tasks, understanding how\nthese models recommend libraries is essential. In this paper, we conduct an\nempirical study of six state-of-the-art LLMs, both proprietary and open-source,\nby prompting them to solve real-world Python problems sourced from Stack\nOverflow. We analyze the types of libraries they import, the characteristics of\nthose libraries, and the extent to which the recommendations are usable out of\nthe box. Our results show that LLMs predominantly favour third-party libraries\nover standard ones, and often recommend mature, popular, and permissively\nlicensed dependencies. However, we also identify gaps in usability: 4.6% of the\nlibraries could not be resolved automatically due to structural mismatches\nbetween import names and installable packages, and only two models (out of six)\nprovided installation guidance. While the generated code is technically valid,\nthe lack of contextual support places the burden of manually resolving\ndependencies on the user. Our findings offer actionable insights for both\ndevelopers and researchers, and highlight opportunities to improve the\nreliability and usability of LLM-generated code in the context of software\ndependencies.", "AI": {"tldr": "LLMs\u63a8\u8350Python\u5e93\u65f6\u503e\u5411\u4e8e\u7b2c\u4e09\u65b9\u5e93\uff0c\u4f46\u5b58\u5728\u53ef\u7528\u6027\u5dee\u8ddd\uff0c\u5982\u5e93\u540d\u4e0e\u5b89\u88c5\u5305\u4e0d\u5339\u914d\uff0c\u4e14\u7f3a\u4e4f\u5b89\u88c5\u6307\u5bfc\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u7f16\u7a0b\u4efb\u52a1\u4e2d\u63a8\u8350\u5e93\u7684\u884c\u4e3a\uff0c\u4ee5\u4e86\u89e3\u5176\u5bf9\u8f6f\u4ef6\u529f\u80fd\u3001\u5b89\u5168\u548c\u7ef4\u62a4\u7684\u5f71\u54cd\u3002", "method": "\u5bf9\u516d\u79cd\u5148\u8fdbLLMs\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u901a\u8fc7Stack Overflow\u7684Python\u95ee\u9898\u6d4b\u8bd5\u5176\u5e93\u63a8\u8350\u884c\u4e3a\u3002", "result": "LLMs\u504f\u597d\u6210\u719f\u3001\u6d41\u884c\u7684\u7b2c\u4e09\u65b9\u5e93\uff0c\u4f464.6%\u7684\u5e93\u56e0\u540d\u79f0\u95ee\u9898\u65e0\u6cd5\u81ea\u52a8\u89e3\u6790\uff0c\u4ec5\u4e24\u79cd\u6a21\u578b\u63d0\u4f9b\u5b89\u88c5\u6307\u5bfc\u3002", "conclusion": "LLM\u751f\u6210\u7684\u4ee3\u7801\u5728\u4f9d\u8d56\u7ba1\u7406\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u6539\u8fdb\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u3002"}}
{"id": "2507.10733", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.10733", "abs": "https://arxiv.org/abs/2507.10733", "authors": ["Jianyao Yin", "Luca Arnaboldi", "Honglong Chen", "Pascal Berrang"], "title": "3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models", "comment": "14 pages, 10 figures", "summary": "Backdoor attacks involve either poisoning the training data or directly\nmodifying the model in order to implant a hidden behavior, that causes the\nmodel to misclassify inputs when a specific trigger is present. During\ninference, the model maintains high accuracy on benign samples but\nmisclassifies poisoned samples into an attacker-specified target class.\nExisting research on backdoor attacks has explored developing triggers in the\nspatial, spectral (frequency), and semantic (feature) domains, aiming to make\nthem stealthy. While some approaches have considered designing triggers that\nare imperceptible in both spatial and spectral domains, few have incorporated\nthe semantic domain. In this paper, we propose a novel backdoor attack, termed\n3S-attack, which is stealthy across the spatial, spectral, and semantic\ndomains. The key idea is to exploit the semantic features of benign samples as\ntriggers, using Gradient-weighted Class Activation Mapping (Grad-CAM) and a\npreliminary model for extraction. The trigger is then embedded in the spectral\ndomain, followed by pixel-level restrictions after converting the samples back\nto the spatial domain. This process minimizes the distance between poisoned and\nbenign samples, making the attack harder to detect by existing defenses and\nhuman inspection. Extensive experiments on various datasets, along with\ntheoretical analysis, demonstrate the stealthiness of 3S-attack and highlight\nthe need for stronger defenses to ensure AI security. Our code is available at:\nhttps://anonymous.4open.science/r/anon-project-3776/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u540e\u95e8\u653b\u51fb3S-attack\uff0c\u901a\u8fc7\u7ed3\u5408\u7a7a\u95f4\u3001\u9891\u8c31\u548c\u8bed\u4e49\u57df\u5b9e\u73b0\u9690\u853d\u6027\uff0c\u5229\u7528Grad-CAM\u63d0\u53d6\u8bed\u4e49\u7279\u5f81\u4f5c\u4e3a\u89e6\u53d1\u5668\uff0c\u5e76\u901a\u8fc7\u9891\u8c31\u5d4c\u5165\u548c\u50cf\u7d20\u9650\u5236\u964d\u4f4e\u53ef\u68c0\u6d4b\u6027\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u653b\u51fb\u7814\u7a76\u591a\u96c6\u4e2d\u5728\u7a7a\u95f4\u548c\u9891\u8c31\u57df\uff0c\u8bed\u4e49\u57df\u8f83\u5c11\u6d89\u53ca\uff0c3S-attack\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5b9e\u73b0\u66f4\u9690\u853d\u7684\u653b\u51fb\u3002", "method": "\u5229\u7528Grad-CAM\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u63d0\u53d6\u8bed\u4e49\u7279\u5f81\u4f5c\u4e3a\u89e6\u53d1\u5668\uff0c\u5d4c\u5165\u9891\u8c31\u57df\u540e\u901a\u8fc7\u50cf\u7d20\u9650\u5236\u6700\u5c0f\u5316\u4e0e\u826f\u6027\u6837\u672c\u7684\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e3S-attack\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u5177\u6709\u9ad8\u5ea6\u9690\u853d\u6027\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u96be\u4ee5\u68c0\u6d4b\u3002", "conclusion": "3S-attack\u5c55\u793a\u4e86\u540e\u95e8\u653b\u51fb\u7684\u65b0\u65b9\u5411\uff0c\u5f3a\u8c03\u4e86AI\u5b89\u5168\u9700\u8981\u66f4\u5f3a\u7684\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2507.10624", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10624", "abs": "https://arxiv.org/abs/2507.10624", "authors": ["Zheng Zhang"], "title": "Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning", "comment": "Substantial change to previous version (experiments, theorem,\n  analysis and related work); currently under review at TMLR", "summary": "Large Language Models (LLMs) display striking surface fluency yet\nsystematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,\nand logical consistency. This paper offers a structural diagnosis of such\nfailures, revealing a persistent gap between \\textit{comprehension} and\n\\textit{competence}. Through controlled experiments and architectural analysis,\nwe demonstrate that LLMs often articulate correct principles without reliably\napplying them--a failure rooted not in knowledge access, but in computational\nexecution. We term this phenomenon the computational \\textit{split-brain\nsyndrome}, where instruction and action pathways are geometrically and\nfunctionally dissociated. This core limitation recurs across domains, from\nmathematical operations to relational inferences, and explains why model\nbehavior remains brittle even under idealized prompting. We argue that LLMs\nfunction as powerful pattern completion engines, but lack the architectural\nscaffolding for principled, compositional reasoning. Our findings delineate the\nboundary of current LLM capabilities and motivate future models with\nmetacognitive control, principle lifting, and structurally grounded execution.\nThis diagnosis also clarifies why mechanistic interpretability findings may\nreflect training-specific pattern coordination rather than universal\ncomputational principles, and why the geometric separation between instruction\nand execution pathways suggests limitations in neural introspection and\nmechanistic analysis.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7b26\u53f7\u63a8\u7406\u3001\u7b97\u672f\u51c6\u786e\u6027\u548c\u903b\u8f91\u4e00\u81f4\u6027\u4efb\u52a1\u4e2d\u7684\u7cfb\u7edf\u6027\u5931\u8d25\uff0c\u63d0\u51fa\u4e86\u201c\u8ba1\u7b97\u5206\u88c2\u8111\u7efc\u5408\u5f81\u201d\u7684\u6982\u5ff5\uff0c\u6307\u51fa\u5176\u6839\u6e90\u5728\u4e8e\u8ba1\u7b97\u6267\u884c\u800c\u975e\u77e5\u8bc6\u8bbf\u95ee\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u8bca\u65adLLMs\u5728\u4efb\u52a1\u5931\u8d25\u4e2d\u7684\u7ed3\u6784\u6027\u95ee\u9898\uff0c\u63ed\u793a\u5176\u8868\u9762\u6d41\u7545\u6027\u4e0e\u5b9e\u9645\u80fd\u529b\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u548c\u67b6\u6784\u5206\u6790\uff0c\u7814\u7a76\u4e86LLMs\u5728\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u539f\u5219\u8868\u8fbe\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u3002", "result": "LLMs\u4f5c\u4e3a\u6a21\u5f0f\u5b8c\u6210\u5f15\u64ce\u5f3a\u5927\uff0c\u4f46\u7f3a\u4e4f\u7ec4\u5408\u63a8\u7406\u7684\u67b6\u6784\u652f\u6301\uff0c\u5bfc\u81f4\u884c\u4e3a\u8106\u5f31\u3002", "conclusion": "\u7814\u7a76\u660e\u786e\u4e86\u5f53\u524dLLMs\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u6a21\u578b\u9700\u8981\u5177\u5907\u5143\u8ba4\u77e5\u63a7\u5236\u3001\u539f\u5219\u63d0\u5347\u548c\u7ed3\u6784\u5316\u6267\u884c\u80fd\u529b\u3002"}}
{"id": "2507.10822", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10822", "abs": "https://arxiv.org/abs/2507.10822", "authors": ["Omar Elsisi", "Glaucia Melo"], "title": "Past, Present and Future: Exploring Adaptive AI in Software Development Bots", "comment": null, "summary": "Conversational agents, such as chatbots and virtual assistants, have become\nessential in software development, boosting productivity, collaboration, and\nautomating various tasks. This paper examines the role of adaptive AI-powered\nconversational agents in software development, highlighting their ability to\noffer dynamic, context-aware assistance to developers. Unlike traditional\nrule-based systems, adaptive AI agents use machine learning and natural\nlanguage processing to learn from interactions and improve over time, providing\nmore personalized and responsive help. We look at how these tools have evolved\nfrom simple query-based systems to advanced AI-driven solutions like GitHub\nCopilot and Microsoft Teams bots. We also explore the challenges of integrating\nadaptive AI into software development processes. The study aims to assess the\nbenefits and limitations of these systems, address concerns like data privacy\nand ethical issues, and offer insights into their future use in the field.\nUltimately, adaptive AI chatbots have great potential to revolutionize software\ndevelopment by delivering real-time, customized support and enhancing the\nefficiency of development cycles.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u81ea\u9002\u5e94AI\u9a71\u52a8\u7684\u5bf9\u8bdd\u4ee3\u7406\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u4f5c\u7528\uff0c\u5f3a\u8c03\u5176\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8f85\u52a9\u80fd\u529b\uff0c\u5e76\u5206\u6790\u4e86\u5176\u4ece\u7b80\u5355\u67e5\u8be2\u7cfb\u7edf\u5230\u9ad8\u7ea7AI\u89e3\u51b3\u65b9\u6848\u7684\u6f14\u53d8\u3002", "motivation": "\u7814\u7a76\u81ea\u9002\u5e94AI\u5bf9\u8bdd\u4ee3\u7406\u5982\u4f55\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u7684\u751f\u4ea7\u529b\u548c\u534f\u4f5c\u6548\u7387\uff0c\u540c\u65f6\u89e3\u51b3\u6570\u636e\u9690\u79c1\u548c\u4f26\u7406\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u81ea\u9002\u5e94AI\u4ee3\u7406\u7684\u673a\u5668\u5b66\u4e60\u4e0e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\uff0c\u4ee5\u53ca\u5176\u5728GitHub Copilot\u7b49\u5de5\u5177\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u81ea\u9002\u5e94AI\u4ee3\u7406\u80fd\u63d0\u4f9b\u4e2a\u6027\u5316\u3001\u54cd\u5e94\u8fc5\u901f\u7684\u5e2e\u52a9\uff0c\u663e\u8457\u63d0\u5347\u5f00\u53d1\u6548\u7387\u3002", "conclusion": "\u81ea\u9002\u5e94AI\u5bf9\u8bdd\u4ee3\u7406\u6709\u671b\u901a\u8fc7\u5b9e\u65f6\u5b9a\u5236\u652f\u6301\u5f7b\u5e95\u6539\u53d8\u8f6f\u4ef6\u5f00\u53d1\uff0c\u4f46\u9700\u89e3\u51b3\u9690\u79c1\u548c\u4f26\u7406\u6311\u6218\u3002"}}
{"id": "2507.10808", "categories": ["cs.CR", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.10808", "abs": "https://arxiv.org/abs/2507.10808", "authors": ["Mohammad Alikhani", "Reza Kazemi"], "title": "Contrastive-KAN: A Semi-Supervised Intrusion Detection Framework for Cybersecurity with scarce Labeled Data", "comment": null, "summary": "In the era of the Fourth Industrial Revolution, cybersecurity and intrusion\ndetection systems are vital for the secure and reliable operation of IoT and\nIIoT environments. A key challenge in this domain is the scarcity of labeled\ncyber-attack data, as most industrial systems operate under normal conditions.\nThis data imbalance, combined with the high cost of annotation, hinders the\neffective training of machine learning models. Moreover, rapid detection of\nattacks is essential, especially in critical infrastructure, to prevent\nlarge-scale disruptions. To address these challenges, we propose a real-time\nintrusion detection system based on a semi-supervised contrastive learning\nframework using the Kolmogorov-Arnold Network (KAN). Our method leverages\nabundant unlabeled data to distinguish between normal and attack behaviors\neffectively. We validate our approach on three benchmark datasets: UNSW-NB15,\nBoT-IoT, and Gas Pipeline, using only 2.20 percent, 1.28 percent, and 8 percent\nof labeled samples, respectively, to simulate real-world conditions.\nExperimental results show that our method outperforms existing contrastive\nlearning-based approaches. We further compare KAN with a traditional multilayer\nperceptron (MLP), demonstrating KAN's superior performance in both detection\naccuracy and robustness under limited supervision. KAN's ability to model\ncomplex relationships and its learnable activation functions are also explored\nand visualized, offering interpretability and potential for rule extraction.\nThe method supports multi-class classification and proves effective in\nsafety-critical environments where reliability is paramount.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u534a\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u7684\u5b9e\u65f6\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5229\u7528Kolmogorov-Arnold\u7f51\u7edc\uff08KAN\uff09\u89e3\u51b3\u6570\u636e\u6807\u6ce8\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u5728\u7b2c\u56db\u6b21\u5de5\u4e1a\u9769\u547d\u65f6\u4ee3\uff0c\u7f51\u7edc\u5b89\u5168\u548c\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u5bf9\u7269\u8054\u7f51\u548c\u5de5\u4e1a\u7269\u8054\u7f51\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u548c\u9ad8\u6210\u672c\u963b\u788d\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6709\u6548\u8bad\u7ec3\u3002", "method": "\u91c7\u7528\u534a\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u548cKAN\u7f51\u7edc\uff0c\u5229\u7528\u5927\u91cf\u672a\u6807\u6ce8\u6570\u636e\u533a\u5206\u6b63\u5e38\u548c\u653b\u51fb\u884c\u4e3a\u3002", "result": "\u5728UNSW-NB15\u3001BoT-IoT\u548cGas Pipeline\u6570\u636e\u96c6\u4e0a\uff0c\u4ec5\u7528\u5c11\u91cf\u6807\u6ce8\u6837\u672c\u5373\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0cKAN\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edfMLP\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u591a\u7c7b\u5206\u7c7b\u548c\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u53ef\u89e3\u91ca\u6027\u548c\u89c4\u5219\u63d0\u53d6\u6f5c\u529b\u3002"}}
{"id": "2507.10630", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10630", "abs": "https://arxiv.org/abs/2507.10630", "authors": ["Ye Yang", "Xue Xiao", "Ping Yin", "Taotao Xie"], "title": "Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs", "comment": null, "summary": "API calls by large language models (LLMs) offer a cutting-edge approach for\ndata analysis. However, their ability to effectively utilize tools via API\ncalls remains underexplored in knowledge-intensive domains like meteorology.\nThis paper introduces KG2data, a system that integrates knowledge graphs, LLMs,\nReAct agents, and tool-use technologies to enable intelligent data acquisition\nand query handling in the meteorological field. Using a virtual API, we\nevaluate API call accuracy across three metrics: name recognition failure,\nhallucination failure, and call correctness. KG2data achieves superior\nperformance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and\nchat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based\nsystems by addressing their limited access to domain-specific knowledge, which\nhampers performance on complex or terminology-rich queries. By using a\nknowledge graph as persistent memory, our system enhances content retrieval,\ncomplex query handling, domain-specific reasoning, semantic relationship\nresolution, and heterogeneous data integration. It also mitigates the high cost\nof fine-tuning LLMs, making the system more adaptable to evolving domain\nknowledge and API structures. In summary, KG2data provides a novel solution for\nintelligent, knowledge-based question answering and data analysis in domains\nwith high knowledge demands.", "AI": {"tldr": "KG2data\u662f\u4e00\u4e2a\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u3001LLM\u3001ReAct\u4ee3\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6280\u672f\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u6c14\u8c61\u9886\u57df\u7684\u6570\u636e\u83b7\u53d6\u548c\u67e5\u8be2\u5904\u7406\uff0c\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22LLM\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\uff08\u5982\u6c14\u8c61\u5b66\uff09\u4e2d\u901a\u8fc7API\u8c03\u7528\u6709\u6548\u5229\u7528\u5de5\u5177\u7684\u80fd\u529b\u3002", "method": "\u96c6\u6210\u77e5\u8bc6\u56fe\u8c31\u3001LLM\u3001ReAct\u4ee3\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6280\u672f\uff0c\u901a\u8fc7\u865a\u62dfAPI\u8bc4\u4f30API\u8c03\u7528\u51c6\u786e\u6027\u3002", "result": "KG2data\u5728\u540d\u79f0\u8bc6\u522b\u5931\u8d25\u3001\u5e7b\u89c9\u5931\u8d25\u548c\u8c03\u7528\u6b63\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff081.43%\u30010%\u300188.57%\uff09\uff0c\u4f18\u4e8eRAG2data\u548cchat2data\u3002", "conclusion": "KG2data\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u89e3\u51b3\u4e86LLM\u5728\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u4e0a\u7684\u9650\u5236\uff0c\u4e3a\u9ad8\u77e5\u8bc6\u9700\u6c42\u9886\u57df\u63d0\u4f9b\u4e86\u667a\u80fd\u95ee\u7b54\u548c\u6570\u636e\u5206\u6790\u7684\u65b0\u65b9\u6848\u3002"}}
{"id": "2507.10906", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10906", "abs": "https://arxiv.org/abs/2507.10906", "authors": ["Qunhong Zeng", "Yuxia Zhang", "Zexiong Ma", "Bo Jiang", "Ningyuan Sun", "Klaas-Jan Stol", "Xingyu Mou", "Hui Liu"], "title": "Evaluating Generated Commit Messages with Large Language Models", "comment": null, "summary": "Commit messages are essential in software development as they serve to\ndocument and explain code changes. Yet, their quality often falls short in\npractice, with studies showing significant proportions of empty or inadequate\nmessages. While automated commit message generation has advanced significantly,\nparticularly with Large Language Models (LLMs), the evaluation of generated\nmessages remains challenging. Traditional reference-based automatic metrics\nlike BLEU, ROUGE-L, and METEOR have notable limitations in assessing commit\nmessage quality, as they assume a one-to-one mapping between code changes and\ncommit messages, leading researchers to rely on resource-intensive human\nevaluation. This study investigates the potential of LLMs as automated\nevaluators for commit message quality. Through systematic experimentation with\nvarious prompt strategies and state-of-the-art LLMs, we demonstrate that LLMs\ncombining Chain-of-Thought reasoning with few-shot demonstrations achieve near\nhuman-level evaluation proficiency. Our LLM-based evaluator significantly\noutperforms traditional metrics while maintaining acceptable reproducibility,\nrobustness, and fairness levels despite some inherent variability. This work\nconducts a comprehensive preliminary study on using LLMs for commit message\nevaluation, offering a scalable alternative to human assessment while\nmaintaining high-quality evaluation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u81ea\u52a8\u8bc4\u4f30\u63d0\u4ea4\u6d88\u606f\u8d28\u91cf\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u63a5\u8fd1\u4eba\u7c7b\u8bc4\u4f30\u6c34\u5e73\uff0c\u4f18\u4e8e\u4f20\u7edf\u6307\u6807\u3002", "motivation": "\u63d0\u4ea4\u6d88\u606f\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b9e\u8df5\u4e2d\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\uff0c\u4f20\u7edf\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u8d44\u6e90\u5bc6\u96c6\u578b\u7684\u4eba\u5de5\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\uff0c\u7ed3\u5408Chain-of-Thought\u63a8\u7406\u548c\u5c11\u91cf\u793a\u4f8b\uff0c\u4f7f\u7528\u5148\u8fdb\u7684LLMs\u8bc4\u4f30\u63d0\u4ea4\u6d88\u606f\u8d28\u91cf\u3002", "result": "LLM\u8bc4\u4f30\u5668\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6307\u6807\uff0c\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u518d\u73b0\u6027\u3001\u9c81\u68d2\u6027\u548c\u516c\u5e73\u6027\u3002", "conclusion": "LLMs\u4e3a\u63d0\u4ea4\u6d88\u606f\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9ad8\u8d28\u91cf\u66ff\u4ee3\u65b9\u6848\uff0c\u51cf\u5c11\u4e86\u4eba\u5de5\u8bc4\u4f30\u7684\u9700\u6c42\u3002"}}
{"id": "2507.10819", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.10819", "abs": "https://arxiv.org/abs/2507.10819", "authors": ["Pedro Almansa Jim\u00e9nez", "Lorenzo Fern\u00e1ndez Maim\u00f3", "\u00c1ngel Luis Per\u00e1les G\u00f3mez"], "title": "Reporte de vulnerabilidades en IIoT. Proyecto DEFENDER", "comment": "Language: Spanish", "summary": "The main objective of this technical report is to conduct a comprehensive\nstudy on devices operating within Industrial Internet of Things (IIoT)\nenvironments, describing the scenarios that define this category and analysing\nthe vulnerabilities that compromise their security. To this end, the report\nseeks to identify and examine the main classes of IIoT devices, detailing their\ncharacteristics, functionalities, and roles within industrial systems. This\nanalysis enables a better understanding of how these devices interact and\nfulfil the requirements of critical industrial environments. The report also\nexplores the specific contexts in which these devices operate, highlighting the\ndistinctive features of industrial scenarios and the conditions under which the\ndevices function. Furthermore, it analyses the vulnerabilities affecting IIoT\ndevices, outlining their vectors, targets, impact, and consequences. The report\nthen describes the typical phases of an attack, along with a selection of\nreal-world documented incidents. These cases are classified according to the\ntaxonomy presented in Section 3, providing a comprehensive view of the\npotential threats to security and assessing the impact these vulnerabilities\nmay have on industrial environments. Finally, the report presents a compilation\nof some of the most recent and effective security countermeasures as potential\nsolutions to the security challenges faced by industrial systems. Special\nemphasis is placed on the role of Machine Learning in the development of these\napproaches, underscoring its importance in enhancing industrial cybersecurity.", "AI": {"tldr": "\u8be5\u6280\u672f\u62a5\u544a\u5168\u9762\u7814\u7a76\u4e86\u5de5\u4e1a\u7269\u8054\u7f51\uff08IIoT\uff09\u8bbe\u5907\uff0c\u5206\u6790\u4e86\u5176\u573a\u666f\u3001\u6f0f\u6d1e\u53ca\u5b89\u5168\u5a01\u80c1\uff0c\u5e76\u63d0\u51fa\u4e86\u6700\u65b0\u7684\u5b89\u5168\u5bf9\u7b56\uff0c\u7279\u522b\u5f3a\u8c03\u4e86\u673a\u5668\u5b66\u4e60\u5728\u5de5\u4e1a\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u5de5\u4e1a\u7269\u8054\u7f51\u8bbe\u5907\u5728\u5173\u952e\u5de5\u4e1a\u73af\u5883\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5b89\u5168\u6027\u9762\u4e34\u4e25\u5cfb\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u7814\u7a76\u548c\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u62a5\u544a\u901a\u8fc7\u5206\u7c7bIIoT\u8bbe\u5907\u3001\u5206\u6790\u5176\u529f\u80fd\u548c\u6f0f\u6d1e\uff0c\u5e76\u7ed3\u5408\u5b9e\u9645\u653b\u51fb\u6848\u4f8b\uff0c\u63d0\u51fa\u5b89\u5168\u5bf9\u7b56\u3002", "result": "\u62a5\u544a\u63ed\u793a\u4e86IIoT\u8bbe\u5907\u7684\u6f0f\u6d1e\u548c\u653b\u51fb\u6a21\u5f0f\uff0c\u5e76\u603b\u7ed3\u4e86\u6709\u6548\u7684\u5b89\u5168\u63aa\u65bd\uff0c\u5c24\u5176\u662f\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u5e94\u7528\u3002", "conclusion": "IIoT\u8bbe\u5907\u7684\u5b89\u5168\u95ee\u9898\u9700\u591a\u7ef4\u5ea6\u89e3\u51b3\uff0c\u673a\u5668\u5b66\u4e60\u5728\u63d0\u5347\u5de5\u4e1a\u7f51\u7edc\u5b89\u5168\u4e2d\u5177\u6709\u91cd\u8981\u6f5c\u529b\u3002"}}
{"id": "2507.10644", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.HC", "cs.MA", "I.2.11; I.2.7; C.2.4; K.6.5; I.2.4"], "pdf": "https://arxiv.org/pdf/2507.10644", "abs": "https://arxiv.org/abs/2507.10644", "authors": ["Tatiana Petrova", "Aleksandr Puzikov", "Boris Bliznukov", "Radu State"], "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "comment": "33 pages, 9 figures, 8 tables", "summary": "The concept of the Web of Agents (WoA), which transforms the static,\ndocument-centric Web into an environment of autonomous agents acting on users'\nbehalf, has attracted growing interest as large language models (LLMs) become\nmore capable. However, research in this area is still fragmented across\ndifferent communities. Contemporary surveys catalog the latest LLM-powered\nframeworks, while the rich histories of Multi-Agent Systems (MAS) and the\nSemantic Web are often treated as separate, legacy domains. This fragmentation\nobscures the intellectual lineage of modern systems and hinders a holistic\nunderstanding of the field's trajectory. We present the first comprehensive\nevolutionary overview of the WoA. We show that modern protocols like A2A and\nthe MCP, are direct evolutionary responses to the well-documented limitations\nof earlier standards like FIPA standards and OWL-based semantic agents. To\nsystematize this analysis, we introduce a four-axis taxonomy (semantic\nfoundation, communication paradigm, locus of intelligence, discovery\nmechanism). This framework provides a unified analytical lens for comparing\nagent architectures across all generations, revealing a clear line of descent\nwhere others have seen a disconnect. Our analysis identifies a paradigm shift\nin the 'locus of intelligence': from being encoded in external data (Semantic\nWeb) or the platform (MAS) to being embedded within the agent's core model\n(LLM). This shift is foundational to modern Agentic AI, enabling the scalable\nand adaptive systems the WoA has long envisioned. We conclude that while new\nprotocols are essential, they are insufficient for building a robust, open,\ntrustworthy ecosystem. Finally, we argue that the next research frontier lies\nin solving persistent socio-technical challenges, and we map out a new agenda\nfocused on decentralized identity, economic models, security, and governance\nfor the emerging WoA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684Web of Agents\uff08WoA\uff09\u8fdb\u5316\u6982\u8ff0\uff0c\u63ed\u793a\u4e86\u73b0\u4ee3\u534f\u8bae\u4e0e\u65e9\u671f\u6807\u51c6\u7684\u76f4\u63a5\u8054\u7cfb\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u56db\u8f74\u5206\u7c7b\u6cd5\u6765\u7edf\u4e00\u5206\u6790\u4e0d\u540c\u4e16\u4ee3\u7684\u4ee3\u7406\u67b6\u6784\u3002", "motivation": "\u7814\u7a76WoA\u9886\u57df\u7684\u788e\u7247\u5316\u95ee\u9898\uff0c\u63ed\u793a\u73b0\u4ee3\u7cfb\u7edf\u4e0e\u65e9\u671f\u6807\u51c6\uff08\u5982FIPA\u548cOWL\uff09\u7684\u5173\u8054\uff0c\u4ee5\u4fc3\u8fdb\u5bf9\u8be5\u9886\u57df\u53d1\u5c55\u7684\u6574\u4f53\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u56db\u8f74\u5206\u7c7b\u6cd5\uff08\u8bed\u4e49\u57fa\u7840\u3001\u901a\u4fe1\u8303\u5f0f\u3001\u667a\u80fd\u4f4d\u7f6e\u3001\u53d1\u73b0\u673a\u5236\uff09\u7cfb\u7edf\u5316\u5206\u6790\u4ee3\u7406\u67b6\u6784\uff0c\u6bd4\u8f83\u4e0d\u540c\u4e16\u4ee3\u7684\u6280\u672f\u6f14\u53d8\u3002", "result": "\u53d1\u73b0\u667a\u80fd\u4f4d\u7f6e\u4ece\u5916\u90e8\u6570\u636e\u6216\u5e73\u53f0\u8f6c\u79fb\u5230\u4ee3\u7406\u6838\u5fc3\u6a21\u578b\uff08LLM\uff09\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u8fd9\u662f\u73b0\u4ee3Agentic AI\u7684\u57fa\u7840\u3002", "conclusion": "\u65b0\u534f\u8bae\u867d\u5fc5\u8981\u4f46\u4e0d\u8db3\uff0c\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u3001\u7ecf\u6d4e\u6a21\u578b\u3001\u5b89\u5168\u548c\u6cbb\u7406\u7b49\u793e\u4f1a\u6280\u672f\u6311\u6218\u3002"}}
{"id": "2507.11059", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11059", "abs": "https://arxiv.org/abs/2507.11059", "authors": ["Pavel Adamenko", "Mikhail Ivanov", "Aidar Valeev", "Rodion Levichev", "Pavel Zadorozhny", "Ivan Lopatin", "Dmitry Babayev", "Alena Fenogenova", "Valentin Malykh"], "title": "SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks", "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) in software engineering\nhas revealed critical limitations in existing benchmarks, particularly the\nwidely used SWE-bench dataset. Recent studies have uncovered severe data\ncontamination issues, e.g. SWE-bench reports 32.67% of successful patches\ninvolve direct solution leakage and 31.08\\% pass due to inadequate test cases.\nWe introduce SWE-MERA, a dynamic, continuously updated benchmark designed to\naddress these fundamental challenges through an automated collection of\nreal-world GitHub issues and rigorous quality validation. Our approach\nimplements a reliable pipeline that ensures quality while minimizing\ncontamination risks, resulting in approximately 10,000 potential tasks with 300\nsamples currently available. Evaluation using the Aider coding agent\ndemonstrates strong discriminative power in state-of-the-art models. We report\nperformance across a dozen recent LLMs evaluated on tasks collected between\nSeptember 2024 and June 2025.", "AI": {"tldr": "SWE-MERA\u662f\u4e00\u4e2a\u52a8\u6001\u66f4\u65b0\u7684\u57fa\u51c6\uff0c\u65e8\u5728\u89e3\u51b3SWE-bench\u4e2d\u7684\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6536\u96c6GitHub\u95ee\u9898\u5e76\u4e25\u683c\u9a8c\u8bc1\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\uff08\u5982SWE-bench\uff09\u5b58\u5728\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u5982\u89e3\u51b3\u65b9\u6848\u6cc4\u6f0f\u548c\u6d4b\u8bd5\u7528\u4f8b\u4e0d\u8db3\uff0c\u5f71\u54cd\u4e86\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u81ea\u52a8\u5316\u7ba1\u9053\u6536\u96c6\u771f\u5b9eGitHub\u95ee\u9898\uff0c\u5e76\u8fdb\u884c\u4e25\u683c\u8d28\u91cf\u9a8c\u8bc1\uff0c\u786e\u4fdd\u6570\u636e\u8d28\u91cf\u3002", "result": "\u751f\u6210\u4e86\u7ea610,000\u4e2a\u6f5c\u5728\u4efb\u52a1\uff0c\u76ee\u524d\u6709300\u4e2a\u6837\u672c\u53ef\u7528\uff0c\u8bc4\u4f30\u663e\u793a\u5bf9\u6700\u65b0LLMs\u5177\u6709\u5f3a\u533a\u5206\u80fd\u529b\u3002", "conclusion": "SWE-MERA\u901a\u8fc7\u52a8\u6001\u66f4\u65b0\u548c\u4e25\u683c\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u53ef\u9760\u7684\u57fa\u51c6\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2507.10836", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.10836", "abs": "https://arxiv.org/abs/2507.10836", "authors": ["Zhonghao Zhan", "Huichi Zhou", "Hamed Haddadi"], "title": "REAL-IoT: Characterizing GNN Intrusion Detection Robustness under Practical Adversarial Attack", "comment": null, "summary": "Graph Neural Network (GNN)-based network intrusion detection systems (NIDS)\nare often evaluated on single datasets, limiting their ability to generalize\nunder distribution drift. Furthermore, their adversarial robustness is\ntypically assessed using synthetic perturbations that lack realism. This\nmeasurement gap leads to an overestimation of GNN-based NIDS resilience. To\naddress the limitations, we propose \\textbf{REAL-IoT}, a comprehensive\nframework for robustness evaluation of GNN-based NIDS in IoT environments. Our\nframework presents a methodology that creates a unified dataset from canonical\ndatasets to assess generalization under drift. In addition, it features a novel\nintrusion dataset collected from a physical IoT testbed, which captures network\ntraffic and attack scenarios under real-world settings. Furthermore, using\nREAL-IoT, we explore the usage of Large Language Models (LLMs) to analyze\nnetwork data and mitigate the impact of adversarial examples by filtering\nsuspicious flows. Our evaluations using REAL-IoT reveal performance drops in\nGNN models compared to results from standard benchmarks, quantifying their\nsusceptibility to drift and realistic attacks. We also demonstrate the\npotential of LLM-based filtering to enhance robustness. These findings\nemphasize the necessity of realistic threat modeling and rigorous measurement\npractices for developing resilient IoT intrusion detection systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faREAL-IoT\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30GNN\u5728\u7269\u8054\u7f51\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u63ed\u793a\u5176\u5728\u5206\u5e03\u6f02\u79fb\u548c\u771f\u5b9e\u653b\u51fb\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u5e76\u63a2\u7d22LLM\u589e\u5f3a\u9c81\u68d2\u6027\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709GNN\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u8bc4\u4f30\u5c40\u9650\u4e8e\u5355\u4e00\u6570\u636e\u96c6\uff0c\u4e14\u5bf9\u6297\u9c81\u68d2\u6027\u8bc4\u4f30\u7f3a\u4e4f\u771f\u5b9e\u6027\uff0c\u5bfc\u81f4\u9ad8\u4f30\u5176\u6027\u80fd\u3002", "method": "\u63d0\u51faREAL-IoT\u6846\u67b6\uff0c\u6574\u5408\u591a\u6570\u636e\u96c6\u8bc4\u4f30\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u57fa\u4e8e\u771f\u5b9eIoT\u6d4b\u8bd5\u5e8a\u751f\u6210\u653b\u51fb\u6570\u636e\u96c6\uff0c\u540c\u65f6\u63a2\u7d22LLM\u8fc7\u6ee4\u53ef\u7591\u6d41\u91cf\u7684\u65b9\u6cd5\u3002", "result": "\u8bc4\u4f30\u663e\u793aGNN\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u6027\u80fd\u4e0b\u964d\uff0cLLM\u8fc7\u6ee4\u53ef\u63d0\u5347\u9c81\u68d2\u6027\u3002", "conclusion": "\u5f3a\u8c03\u771f\u5b9e\u5a01\u80c1\u5efa\u6a21\u548c\u4e25\u683c\u8bc4\u4f30\u5bf9\u5f00\u53d1\u9c81\u68d2\u7269\u8054\u7f51\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.10740", "categories": ["cs.AI", "cs.NE", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.10740", "abs": "https://arxiv.org/abs/2507.10740", "authors": ["Maziar Kanani", "Sean O Leary", "James McDermott"], "title": "Parsing Musical Structure to Enable Meaningful Variations", "comment": null, "summary": "This paper presents a novel rule-based approach for generating music by\nvarying existing tunes. We parse each tune to find the Pathway Assembly (PA) [\n1], that is a structure representing all repetitions in the tune. The Sequitur\nalgorithm [2 ] is used for this. The result is a grammar. We then carry out\nmutation on the grammar, rather than on a tune directly. There are potentially\n19 types of mutations such as adding, removing, swapping or reversing parts of\nthe grammar that can be applied to the grammars. The system employs one of the\nmutations randomly in this step to automatically manipulate the grammar.\nFollowing the mutation, we need to expand the grammar which returns a new tune.\nThe output after 1 or more mutations will be a new tune related to the original\ntune. Our study examines how tunes change gradually over the course of multiple\nmutations. Edit distances, structural complexity and length of the tunes are\nused to show how a tune is changed after multiple mutations. In addition, the\nsize of effect of each mutation type is analyzed. As a final point, we review\nthe musical aspect of the output tunes. It should be noted that the study only\nfocused on generating new pitch sequences. The study is based on an Irish\ntraditional tune dataset and a list of integers has been used to represent each\ntune's pitch values.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u7684\u97f3\u4e50\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5f02\u73b0\u6709\u66f2\u8c03\u751f\u6210\u65b0\u97f3\u4e50\u3002\u5229\u7528Sequitur\u7b97\u6cd5\u89e3\u6790\u66f2\u8c03\u4e3a\u8bed\u6cd5\u7ed3\u6784\uff0c\u968f\u673a\u5e94\u752819\u79cd\u53d8\u5f02\u7c7b\u578b\uff0c\u751f\u6210\u65b0\u66f2\u8c03\u5e76\u5206\u6790\u5176\u53d8\u5316\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u53d8\u5f02\u73b0\u6709\u66f2\u8c03\u751f\u6210\u65b0\u97f3\u4e50\uff0c\u63a2\u7d22\u66f2\u8c03\u5728\u591a\u6b21\u53d8\u5f02\u4e2d\u7684\u53d8\u5316\u89c4\u5f8b\u3002", "method": "\u4f7f\u7528Sequitur\u7b97\u6cd5\u89e3\u6790\u66f2\u8c03\u4e3a\u8bed\u6cd5\u7ed3\u6784\uff08PA\uff09\uff0c\u968f\u673a\u5e94\u752819\u79cd\u53d8\u5f02\u7c7b\u578b\uff08\u5982\u6dfb\u52a0\u3001\u5220\u9664\u3001\u4ea4\u6362\u7b49\uff09\uff0c\u751f\u6210\u65b0\u66f2\u8c03\u3002", "result": "\u901a\u8fc7\u7f16\u8f91\u8ddd\u79bb\u3001\u7ed3\u6784\u590d\u6742\u5ea6\u548c\u66f2\u8c03\u957f\u5ea6\u5206\u6790\u53d8\u5f02\u6548\u679c\uff0c\u5e76\u8bc4\u4f30\u6bcf\u79cd\u53d8\u5f02\u7c7b\u578b\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u4e0e\u539f\u66f2\u8c03\u76f8\u5173\u7684\u65b0\u97f3\u4e50\uff0c\u4f46\u4ec5\u5173\u6ce8\u97f3\u9ad8\u5e8f\u5217\u751f\u6210\uff0c\u672a\u6d89\u53ca\u5176\u4ed6\u97f3\u4e50\u5143\u7d20\u3002"}}
{"id": "2507.11092", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11092", "abs": "https://arxiv.org/abs/2507.11092", "authors": ["Gong Chen", "Wenjie Liu", "Xiaoyuan Xie", "Xunzhu Tang", "Tegawend\u00e9 F. Bissyand\u00e9", "Songqiang Chen"], "title": "MT4DP: Data Poisoning Attack Detection for DL-based Code Search Models via Metamorphic Testing", "comment": "27 pages", "summary": "Recently, several studies have indicated that data poisoning attacks pose a\nsevere security threat to deep learning-based (DL-based) code search models.\nAttackers inject carefully crafted malicious patterns into the training data,\nmisleading the code search model to learn these patterns during training.\nDuring the usage of the poisoned code search model for inference, once the\nmalicious pattern is triggered, the model tends to rank the vulnerability code\nhigher. However, existing detection methods for data poisoning attacks on\nDL-based code search models remain insufficiently effective. To address this\ncritical security issue, we propose MT4DP, a Data Poisoning Attack Detection\nFramework for DL-based Code Search Models via Metamorphic Testing. MT4DP\nintroduces a novel Semantically Equivalent Metamorphic Relation (SE-MR)\ndesigned to detect data poisoning attacks on DL-based code search models.\nSpecifically, MT4DP first identifies the high-frequency words from search\nqueries as potential poisoning targets and takes their corresponding queries as\nthe source queries. For each source query, MT4DP generates two semantically\nequivalent follow-up queries and retrieves its source ranking list. Then, each\nsource ranking list is re-ranked based on the semantic similarities between its\ncode snippets and the follow-up queries. Finally, variances between the source\nand re-ranked lists are calculated to reveal violations of the SE-MR and warn\nthe data poisoning attack. Experimental results demonstrate that MT4DP\nsignificantly enhances the detection of data poisoning attacks on DL-based code\nsearch models, outperforming the best baseline by 191% on average F1 score and\n265% on average precision. Our work aims to promote further research into\neffective techniques for mitigating data poisoning threats on DL-based code\nsearch models.", "AI": {"tldr": "MT4DP\u662f\u4e00\u79cd\u57fa\u4e8e\u8715\u53d8\u6d4b\u8bd5\u7684\u6570\u636e\u6295\u6bd2\u653b\u51fb\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u4ee3\u7801\u641c\u7d22\u6a21\u578b\uff0c\u901a\u8fc7\u8bed\u4e49\u7b49\u6548\u8715\u53d8\u5173\u7cfb\u68c0\u6d4b\u653b\u51fb\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5bf9\u6df1\u5ea6\u5b66\u4e60\u4ee3\u7801\u641c\u7d22\u6a21\u578b\u7684\u6570\u636e\u6295\u6bd2\u653b\u51fb\u68c0\u6d4b\u6548\u679c\u4e0d\u8db3\uff0c\u9700\u63d0\u51fa\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "MT4DP\u5229\u7528\u9ad8\u9891\u7387\u8bcd\u4f5c\u4e3a\u6f5c\u5728\u6295\u6bd2\u76ee\u6807\uff0c\u751f\u6210\u8bed\u4e49\u7b49\u6548\u67e5\u8be2\u5e76\u91cd\u65b0\u6392\u5e8f\uff0c\u901a\u8fc7\u65b9\u5dee\u8ba1\u7b97\u63ed\u793a\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u663e\u793aMT4DP\u5728F1\u5206\u6570\u548c\u7cbe\u5ea6\u4e0a\u5206\u522b\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347191%\u548c265%\u3002", "conclusion": "MT4DP\u6709\u6548\u63d0\u5347\u6570\u636e\u6295\u6bd2\u653b\u51fb\u68c0\u6d4b\u80fd\u529b\uff0c\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2507.10845", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10845", "abs": "https://arxiv.org/abs/2507.10845", "authors": ["Wenxuan Shi", "Hongwei Li", "Jiahao Yu", "Xinqian Sun", "Wenbo Guo", "Xinyu Xing"], "title": "BandFuzz: An ML-powered Collaborative Fuzzing Framework", "comment": null, "summary": "Collaborative fuzzing has recently emerged as a technique that combines\nmultiple individual fuzzers and dynamically chooses the appropriate\ncombinations suited for different programs. Unlike individual fuzzers, which\nrely on specific assumptions to maintain their effectiveness, collaborative\nfuzzing relaxes the assumptions on target programs, providing constant and\nrobust performance across various programs. Ideally, collaborative fuzzing\nshould be a more promising direction toward generic fuzzing solutions, as it\nmitigates the need for manual cherry-picking of individual fuzzers. However,\nthe effectiveness of existing collaborative fuzzing frameworks is limited by\nmajor challenges, such as the need for additional computational resources\ncompared to individual fuzzers and the inefficient allocation of resources\namong the various fuzzers.", "AI": {"tldr": "\u534f\u4f5c\u6a21\u7cca\u6d4b\u8bd5\u901a\u8fc7\u7ed3\u5408\u591a\u4e2a\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u52a8\u6001\u9009\u62e9\u9002\u5408\u4e0d\u540c\u7a0b\u5e8f\u7684\u7ec4\u5408\uff0c\u63d0\u4f9b\u66f4\u7a33\u5b9a\u548c\u901a\u7528\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u73b0\u6709\u6846\u67b6\u9762\u4e34\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u589e\u52a0\u548c\u8d44\u6e90\u5206\u914d\u6548\u7387\u4f4e\u7684\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u4f9d\u8d56\u7279\u5b9a\u5047\u8bbe\uff0c\u800c\u534f\u4f5c\u6a21\u7cca\u6d4b\u8bd5\u653e\u5bbd\u8fd9\u4e9b\u5047\u8bbe\uff0c\u65e8\u5728\u63d0\u4f9b\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u52a8\u6001\u7ec4\u5408\u591a\u4e2a\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u9002\u5e94\u4e0d\u540c\u7a0b\u5e8f\u7684\u9700\u6c42\u3002", "result": "\u534f\u4f5c\u6a21\u7cca\u6d4b\u8bd5\u5728\u6027\u80fd\u4e0a\u66f4\u7a33\u5b9a\u548c\u901a\u7528\uff0c\u4f46\u8d44\u6e90\u6d88\u8017\u548c\u5206\u914d\u6548\u7387\u662f\u4e3b\u8981\u9650\u5236\u3002", "conclusion": "\u534f\u4f5c\u6a21\u7cca\u6d4b\u8bd5\u662f\u901a\u7528\u6a21\u7cca\u6d4b\u8bd5\u7684\u6709\u524d\u666f\u65b9\u5411\uff0c\u4f46\u9700\u89e3\u51b3\u8d44\u6e90\u95ee\u9898\u3002"}}
{"id": "2507.10750", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10750", "abs": "https://arxiv.org/abs/2507.10750", "authors": ["Pandu Devarakota", "Nicolas Tsesmetzis", "Faruk O. Alpak", "Apurva Gala", "Detlef Hohl"], "title": "AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition", "comment": "Technical article to be submitted to Data Centric Engineering Journal", "summary": "Thanks to the availability of massive amounts of data, computing resources,\nand advanced algorithms, AI has entered nearly every sector. This has sparked\nsignificant investment and interest, particularly in building data centers with\nthe necessary hardware and software to develop and operate AI models and\nAI-based workflows. In this technical review article, we present energy\nconsumption scenarios of data centers and impact on GHG emissions, considering\nboth near-term projections (up to 2030) and long-term outlook (2035 and\nbeyond). We address the quintessential question of whether AI will have a net\npositive, neutral, or negative impact on CO2 emissions by 2035. Additionally,\nwe discuss AI's potential to automate, create efficient and disruptive\nworkflows across various fields related to energy production, supply and\nconsumption. In the near-term scenario, the growing demand for AI will likely\nstrain computing resources, lead to increase in electricity consumption and\ntherefore associated CO2 emissions. This is due to the power-hungry nature of\nbig data centers and the requirements for training and running of large and\ncomplex AI models, as well as the penetration of AI assistant search and\napplications for public use. However, the long-term outlook could be more\npromising. AI has the potential to be a game-changer in CO2 reduction. Its\nability to further automate and optimize processes across industries, from\nenergy production to logistics, could significantly decrease our carbon\nfootprint. This positive impact is anticipated to outweigh the initial\nemissions bump, creating value for businesses and society in areas where\ntraditional solutions have fallen short. In essence, AI might cause some\ninitial growing pains for the environment, but it has the potential to support\nclimate mitigation efforts.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u5bf9\u6570\u636e\u4e2d\u5fc3\u7684\u80fd\u6e90\u6d88\u8017\u548c\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u7684\u5f71\u54cd\uff0c\u5206\u6790\u4e86\u77ed\u671f\uff082030\u5e74\u524d\uff09\u548c\u957f\u671f\uff082035\u5e74\u540e\uff09\u7684\u60c5\u666f\uff0c\u5e76\u8ba8\u8bba\u4e86AI\u5728\u51cf\u6392\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u968f\u7740AI\u6280\u672f\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u6570\u636e\u4e2d\u5fc3\u7684\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u6392\u653e\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5bf9\u73af\u5883\u7684\u5b9e\u9645\u5f71\u54cd\u4ee5\u53ca\u6f5c\u5728\u7684\u51cf\u6392\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6570\u636e\u4e2d\u5fc3\u7684\u80fd\u6e90\u6d88\u8017\u60c5\u666f\u548cAI\u5728\u80fd\u6e90\u751f\u4ea7\u3001\u4f9b\u5e94\u53ca\u6d88\u8d39\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u8bc4\u4f30\u5176\u5bf9CO2\u6392\u653e\u7684\u77ed\u671f\u548c\u957f\u671f\u5f71\u54cd\u3002", "result": "\u77ed\u671f\u5185\uff0cAI\u7684\u666e\u53ca\u53ef\u80fd\u5bfc\u81f4\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u6392\u653e\u589e\u52a0\uff1b\u4f46\u957f\u671f\u6765\u770b\uff0cAI\u7684\u81ea\u52a8\u5316\u548c\u4f18\u5316\u80fd\u529b\u6709\u671b\u663e\u8457\u51cf\u5c11\u78b3\u8db3\u8ff9\u3002", "conclusion": "\u5c3d\u7ba1AI\u521d\u671f\u53ef\u80fd\u5bf9\u73af\u5883\u9020\u6210\u538b\u529b\uff0c\u4f46\u5176\u5728\u6c14\u5019\u7f13\u89e3\u65b9\u9762\u7684\u6f5c\u529b\u6709\u671b\u8d85\u8fc7\u8d1f\u9762\u5f71\u54cd\uff0c\u4e3a\u53ef\u6301\u7eed\u53d1\u5c55\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2507.11146", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11146", "abs": "https://arxiv.org/abs/2507.11146", "authors": ["Tom Yaacov", "Gera Weiss", "Gal Amram", "Avi Hayoun"], "title": "Automata Models for Effective Bug Description", "comment": "Accepted to the ACM/IEEE 28th International Conference on Model\n  Driven Engineering Languages and Systems (MODELS 2025)", "summary": "Debugging complex systems is a crucial yet time-consuming task. This paper\npresents the use of automata learning and testing techniques to obtain concise\nand informative bug descriptions. We introduce the concepts of Failure\nExplanations (FE), Eventual Failure Explanations (EFE), and Early Detection\n(ED) to provide meaningful summaries of failing behavior patterns. By factoring\nout irrelevant information and focusing on essential test patterns, our\napproach aims to enhance bug detection and understanding. We evaluate our\nmethods using various test patterns and real-world benchmarks, demonstrating\ntheir effectiveness in producing compact and informative bug descriptions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u52a8\u673a\u5b66\u4e60\u548c\u6d4b\u8bd5\u6280\u672f\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u7b80\u6d01\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u9519\u8bef\u63cf\u8ff0\uff0c\u5305\u62ec\u5931\u8d25\u89e3\u91ca\uff08FE\uff09\u3001\u6700\u7ec8\u5931\u8d25\u89e3\u91ca\uff08EFE\uff09\u548c\u65e9\u671f\u68c0\u6d4b\uff08ED\uff09\u3002", "motivation": "\u8c03\u8bd5\u590d\u6742\u7cfb\u7edf\u8017\u65f6\u4e14\u56f0\u96be\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u751f\u6210\u6709\u610f\u4e49\u7684\u9519\u8bef\u884c\u4e3a\u603b\u7ed3\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u673a\u5b66\u4e60\u548c\u6d4b\u8bd5\u6280\u672f\uff0c\u63d0\u53d6\u5173\u952e\u6d4b\u8bd5\u6a21\u5f0f\uff0c\u6392\u9664\u65e0\u5173\u4fe1\u606f\uff0c\u751f\u6210\u9519\u8bef\u63cf\u8ff0\u3002", "result": "\u5728\u591a\u79cd\u6d4b\u8bd5\u6a21\u5f0f\u548c\u5b9e\u9645\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u751f\u6210\u7d27\u51d1\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u9519\u8bef\u63cf\u8ff0\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u9519\u8bef\u68c0\u6d4b\u548c\u7406\u89e3\u7684\u80fd\u529b\u3002"}}
{"id": "2507.10854", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10854", "abs": "https://arxiv.org/abs/2507.10854", "authors": ["Thomas Dalton", "Hemanth Gowda", "Girish Rao", "Sachin Pargi", "Alireza Hadj Khodabakhshi", "Joseph Rombs", "Stephan Jou", "Manish Marwah"], "title": "PhreshPhish: A Real-World, High-Quality, Large-Scale Phishing Website Dataset and Benchmark", "comment": null, "summary": "Phishing remains a pervasive and growing threat, inflicting heavy economic\nand reputational damage. While machine learning has been effective in real-time\ndetection of phishing attacks, progress is hindered by lack of large,\nhigh-quality datasets and benchmarks. In addition to poor-quality due to\nchallenges in data collection, existing datasets suffer from leakage and\nunrealistic base rates, leading to overly optimistic performance results. In\nthis paper, we introduce PhreshPhish, a large-scale, high-quality dataset of\nphishing websites that addresses these limitations. Compared to existing public\ndatasets, PhreshPhish is substantially larger and provides significantly higher\nquality, as measured by the estimated rate of invalid or mislabeled data\npoints. Additionally, we propose a comprehensive suite of benchmark datasets\nspecifically designed for realistic model evaluation by minimizing leakage,\nincreasing task difficulty, enhancing dataset diversity, and adjustment of base\nrates more likely to be seen in the real world. We train and evaluate multiple\nsolution approaches to provide baseline performance on the benchmark sets. We\nbelieve the availability of this dataset and benchmarks will enable realistic,\nstandardized model comparison and foster further advances in phishing\ndetection. The datasets and benchmarks are available on Hugging Face\n(https://huggingface.co/datasets/phreshphish/phreshphish).", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86PhreshPhish\uff0c\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u5927\u89c4\u6a21\u9493\u9c7c\u7f51\u7ad9\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4ee5\u4fc3\u8fdb\u9493\u9c7c\u68c0\u6d4b\u7814\u7a76\u7684\u8fdb\u6b65\u3002", "motivation": "\u9493\u9c7c\u653b\u51fb\u5bf9\u7ecf\u6d4e\u548c\u58f0\u8a89\u9020\u6210\u4e25\u91cd\u635f\u5bb3\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u8d28\u91cf\u4f4e\u3001\u6cc4\u6f0f\u548c\u57fa\u51c6\u7387\u4e0d\u73b0\u5b9e\u7b49\u95ee\u9898\uff0c\u963b\u788d\u4e86\u673a\u5668\u5b66\u4e60\u5728\u9493\u9c7c\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faPhreshPhish\u6570\u636e\u96c6\uff0c\u89c4\u6a21\u66f4\u5927\u3001\u8d28\u91cf\u66f4\u9ad8\uff1b\u8bbe\u8ba1\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u51cf\u5c11\u6cc4\u6f0f\u3001\u589e\u52a0\u4efb\u52a1\u96be\u5ea6\u3001\u589e\u5f3a\u591a\u6837\u6027\u5e76\u8c03\u6574\u57fa\u51c6\u7387\u3002", "result": "PhreshPhish\u6570\u636e\u96c6\u8d28\u91cf\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u516c\u5f00\u6570\u636e\u96c6\uff0c\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e3a\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u7684\u6807\u51c6\u3002", "conclusion": "PhreshPhish\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u7684\u53d1\u5e03\u5c06\u63a8\u52a8\u9493\u9c7c\u68c0\u6d4b\u7814\u7a76\u7684\u6807\u51c6\u5316\u548c\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2507.10758", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10758", "abs": "https://arxiv.org/abs/2507.10758", "authors": ["Nikesh Prajapati", "Bimal Karki", "Saroj Gopali", "Akbar Siami Namin"], "title": "IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models", "comment": null, "summary": "This paper intends to detect IoT malicious attacks through deep learning\nmodels and demonstrates a comprehensive evaluation of the deep learning and\ngraph-based models regarding malicious network traffic detection. The models\nparticularly are based on GraphSAGE, Bidirectional encoder representations from\ntransformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head\nAttention, together with Bidirectional Long Short-Term Memory (BI-LSTM)\nMulti-Head Attention and BI-LSTM and LSTM models. The chosen models\ndemonstrated great performance to model temporal patterns and detect feature\nsignificance. The observed performance are mainly due to the fact that IoT\nsystem traffic patterns are both sequential and diverse, leaving a rich set of\ntemporal patterns for the models to learn. Experimental results showed that\nBERT maintained the best performance. It achieved 99.94% accuracy rate\nalongside high precision and recall, F1-score and AUC-ROC score of 99.99% which\ndemonstrates its capabilities through temporal dependency capture. The\nMulti-Head Attention offered promising results by providing good detection\ncapabilities with interpretable results. On the other side, the Multi-Head\nAttention model required significant processing time like BI-LSTM variants. The\nGraphSAGE model achieved good accuracy while requiring the shortest training\ntime but yielded the lowest accuracy, precision, and F1 score compared to the\nother models", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u68c0\u6d4b\u7269\u8054\u7f51\u6076\u610f\u653b\u51fb\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u6a21\u578b\uff08\u5982GraphSAGE\u3001BERT\u3001TCN\u7b49\uff09\u7684\u6027\u80fd\uff0c\u5176\u4e2dBERT\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u7269\u8054\u7f51\u7cfb\u7edf\u6d41\u91cf\u6a21\u5f0f\u5177\u6709\u65f6\u5e8f\u6027\u548c\u591a\u6837\u6027\uff0c\u9002\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5b66\u4e60\uff0c\u4ee5\u68c0\u6d4b\u6076\u610f\u653b\u51fb\u3002", "method": "\u91c7\u7528GraphSAGE\u3001BERT\u3001TCN\u3001Multi-Head Attention\u3001BI-LSTM\u7b49\u6a21\u578b\uff0c\u8bc4\u4f30\u5176\u5728\u6076\u610f\u6d41\u91cf\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\u3002", "result": "BERT\u8868\u73b0\u6700\u4f18\uff0c\u51c6\u786e\u7387\u8fbe99.94%\uff0c\u5176\u4ed6\u6307\u6807\uff08\u5982F1-score\uff09\u63a5\u8fd1100%\uff1bMulti-Head Attention\u63d0\u4f9b\u53ef\u89e3\u91ca\u7ed3\u679c\u4f46\u8017\u65f6\u8f83\u957f\uff1bGraphSAGE\u8bad\u7ec3\u6700\u5feb\u4f46\u6027\u80fd\u6700\u4f4e\u3002", "conclusion": "BERT\u5728\u6355\u83b7\u65f6\u5e8f\u4f9d\u8d56\u65b9\u9762\u8868\u73b0\u5353\u8d8a\uff0c\u9002\u5408\u7269\u8054\u7f51\u6076\u610f\u653b\u51fb\u68c0\u6d4b\uff1b\u5176\u4ed6\u6a21\u578b\u5404\u6709\u4f18\u52a3\uff0c\u9700\u6839\u636e\u9700\u6c42\u9009\u62e9\u3002"}}
{"id": "2507.11199", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11199", "abs": "https://arxiv.org/abs/2507.11199", "authors": ["Jinhan Kim", "Nargiz Humbatova", "Gunel Jahangirova", "Shin Yoo", "Paolo Tonella"], "title": "New Formulation of DNN Statistical Mutation Killing for Ensuring Monotonicity: A Technical Report", "comment": null, "summary": "Mutation testing has emerged as a powerful technique for evaluating the\neffectiveness of test suites for Deep Neural Networks. Among existing\napproaches, the statistical mutant killing criterion of DeepCrime has leveraged\nstatistical testing to determine whether a mutant significantly differs from\nthe original model. However, it suffers from a critical limitation: it violates\nthe monotonicity property, meaning that expanding a test set may result in\npreviously killed mutants no longer being classified as killed. In this\ntechnical report, we propose a new formulation of statistical mutant killing\nbased on Fisher exact test that preserves the statistical rigour of it while\nensuring monotonicity.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFisher\u7cbe\u786e\u68c0\u9a8c\u7684\u7edf\u8ba1\u7a81\u53d8\u6740\u6b7b\u51c6\u5219\uff0c\u89e3\u51b3\u4e86DeepCrime\u8fdd\u53cd\u5355\u8c03\u6027\u7684\u95ee\u9898\u3002", "motivation": "DeepCrime\u7684\u7edf\u8ba1\u7a81\u53d8\u6740\u6b7b\u51c6\u5219\u5b58\u5728\u5355\u8c03\u6027\u88ab\u8fdd\u53cd\u7684\u7f3a\u9677\uff0c\u5373\u6269\u5927\u6d4b\u8bd5\u96c6\u53ef\u80fd\u5bfc\u81f4\u5148\u524d\u88ab\u6740\u6b7b\u7684\u7a81\u53d8\u4e0d\u518d\u88ab\u5206\u7c7b\u4e3a\u6740\u6b7b\u3002", "method": "\u91c7\u7528Fisher\u7cbe\u786e\u68c0\u9a8c\u91cd\u65b0\u5b9a\u4e49\u7edf\u8ba1\u7a81\u53d8\u6740\u6b7b\u51c6\u5219\uff0c\u4fdd\u6301\u7edf\u8ba1\u4e25\u8c28\u6027\u7684\u540c\u65f6\u786e\u4fdd\u5355\u8c03\u6027\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u4fdd\u6301\u7edf\u8ba1\u4e25\u8c28\u6027\u7684\u540c\u65f6\u89e3\u51b3\u4e86\u5355\u8c03\u6027\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u7684Fisher\u7cbe\u786e\u68c0\u9a8c\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86DeepCrime\u7684\u5355\u8c03\u6027\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7edf\u8ba1\u4e25\u8c28\u6027\u3002"}}
{"id": "2507.10873", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.10873", "abs": "https://arxiv.org/abs/2507.10873", "authors": ["Danyu Sun", "Jinghuai Zhang", "Jiacen Xu", "Yu Zheng", "Yuan Tian", "Zhou Li"], "title": "From Alerts to Intelligence: A Novel LLM-Aided Framework for Host-based Intrusion Detection", "comment": null, "summary": "Host-based intrusion detection system (HIDS) is a key defense component to\nprotect the organizations from advanced threats like Advanced Persistent\nThreats (APT). By analyzing the fine-grained logs with approaches like data\nprovenance, HIDS has shown successes in capturing sophisticated attack traces.\nDespite the progresses embarked by the research community and industry, HIDS\nstill frequently encounters backlash from their operators in the deployed\nenvironments, due to issues like high false-positive rate, inconsistent\noutcomes across environments and human-unfriendly detection results. Large\nLanguage Models (LLMs) have great potentials to advance the state of HIDS,\ngiven their extensive knowledge of attack techniques and their ability to\ndetect anomalies through semantic analysis, anchored by recent studies. Yet,\nour preliminary analysis indicates that building an HIDS by naively prompting\nan LLM is unlikely to succeed. In this work, we explore the direction of\nbuilding a customized LLM pipeline for HIDS and develop a system named SHIELD.\nSHIELD addresses challenges related to LLM's token limits, confusion of\nbackground noises, etc., by integrating a variety of techniques like\nevent-level Masked Autoencoder (MAE) for attack window detection, attack\nevidence identification and expansion, Deterministic Data Augmentation (DDA)\nfor profiling normal activities, and multi-purpose prompting that guides the\nLLM to conduct precise and interpretable attack investigations. Extensive\nexperiments on three log datasets (DARPA-E3, NodLink-simulated-data and\nATLASv2) show that SHIELD consistently achieves outstanding performance in\ncomparison with 5 representative HIDS. These findings highlight the potential\nof LLMs as powerful tools for intrusion detection and pave the way for future\nresearch in this domain.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5b9a\u5236\u5316HIDS\u7cfb\u7edfSHIELD\uff0c\u901a\u8fc7\u6574\u5408\u591a\u79cd\u6280\u672f\u89e3\u51b3LLM\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5165\u4fb5\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "HIDS\u5728\u90e8\u7f72\u4e2d\u5e38\u56e0\u9ad8\u8bef\u62a5\u7387\u3001\u7ed3\u679c\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\u53d7\u5230\u6279\u8bc4\uff0c\u800cLLM\u56e0\u5176\u8bed\u4e49\u5206\u6790\u80fd\u529b\u6709\u671b\u6539\u8fdbHIDS\uff0c\u4f46\u76f4\u63a5\u5e94\u7528LLM\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5f00\u53d1\u4e86SHIELD\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e8b\u4ef6\u7ea7MAE\u3001\u653b\u51fb\u8bc1\u636e\u8bc6\u522b\u4e0e\u6269\u5c55\u3001\u786e\u5b9a\u6027\u6570\u636e\u589e\u5f3a\uff08DDA\uff09\u7b49\u6280\u672f\uff0c\u4f18\u5316LLM\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "result": "\u5728\u4e09\u4e2a\u65e5\u5fd7\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSHIELD\u6027\u80fd\u4f18\u4e8e5\u79cd\u4ee3\u8868\u6027HIDS\u3002", "conclusion": "SHIELD\u5c55\u793a\u4e86LLM\u5728\u5165\u4fb5\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.10761", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.10761", "abs": "https://arxiv.org/abs/2507.10761", "authors": ["Tyler King", "Nikolos Gurney", "John H. Miller", "Volkan Ustun"], "title": "Detecting AI Assistance in Abstract Complex Tasks", "comment": "Accepted to HCII 2025", "summary": "Detecting assistance from artificial intelligence is increasingly important\nas they become ubiquitous across complex tasks such as text generation, medical\ndiagnosis, and autonomous driving. Aid detection is challenging for humans,\nespecially when looking at abstract task data. Artificial neural networks excel\nat classification thanks to their ability to quickly learn from and process\nlarge amounts of data -- assuming appropriate preprocessing. We posit detecting\nhelp from AI as a classification task for such models. Much of the research in\nthis space examines the classification of complex but concrete data classes,\nsuch as images. Many AI assistance detection scenarios, however, result in data\nthat is not machine learning-friendly. We demonstrate that common models can\neffectively classify such data when it is appropriately preprocessed. To do so,\nwe construct four distinct neural network-friendly image formulations along\nwith an additional time-series formulation that explicitly encodes the\nexploration/exploitation of users, which allows for generalizability to other\nabstract tasks. We benchmark the quality of each image formulation across three\nclassical deep learning architectures, along with a parallel CNN-RNN\narchitecture that leverages the additional time series to maximize testing\nperformance, showcasing the importance of encoding temporal and spatial\nquantities for detecting AI aid in abstract tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06AI\u8f85\u52a9\u68c0\u6d4b\u4f5c\u4e3a\u5206\u7c7b\u4efb\u52a1\uff0c\u901a\u8fc7\u9884\u5904\u7406\u6570\u636e\u4f7f\u5e38\u89c1\u6a21\u578b\u80fd\u6709\u6548\u5206\u7c7b\u62bd\u8c61\u4efb\u52a1\u6570\u636e\uff0c\u5e76\u5c55\u793a\u4e86\u56db\u79cd\u56fe\u50cf\u548c\u65f6\u95f4\u5e8f\u5217\u7684\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u6548\u679c\u3002", "motivation": "\u968f\u7740AI\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u666e\u53ca\uff0c\u68c0\u6d4bAI\u8f85\u52a9\u53d8\u5f97\u91cd\u8981\uff0c\u4f46\u62bd\u8c61\u4efb\u52a1\u6570\u636e\u5bf9\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u6784\u5efa\u56db\u79cd\u795e\u7ecf\u7f51\u7edc\u53cb\u597d\u7684\u56fe\u50cf\u9884\u5904\u7406\u65b9\u6cd5\u548c\u4e00\u79cd\u65f6\u95f4\u5e8f\u5217\u65b9\u6cd5\uff0c\u7ed3\u5408CNN-RNN\u67b6\u6784\u8fdb\u884c\u68c0\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u9884\u5904\u7406\u540e\u7684\u6570\u636e\u80fd\u6709\u6548\u5206\u7c7b\uff0c\u65f6\u95f4\u5e8f\u5217\u65b9\u6cd5\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "\u7f16\u7801\u65f6\u7a7a\u4fe1\u606f\u5bf9\u68c0\u6d4b\u62bd\u8c61\u4efb\u52a1\u4e2d\u7684AI\u8f85\u52a9\u81f3\u5173\u91cd\u8981\uff0c\u9884\u5904\u7406\u65b9\u6cd5\u5177\u6709\u901a\u7528\u6027\u3002"}}
{"id": "2507.11272", "categories": ["cs.SE", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.11272", "abs": "https://arxiv.org/abs/2507.11272", "authors": ["Anh Nguyen-Duc", "Chien Vu Manh", "Bao Anh Tran", "Viet Phuong Ngo", "Luan Le Chi", "Anh Quang Nguyen"], "title": "An Empirical Study of Multi-Agent RAG for Real-World University Admissions Counseling", "comment": null, "summary": "This paper presents MARAUS (Multi-Agent and Retrieval-Augmented University\nAdmission System), a real-world deployment of a conversational AI platform for\nhigher education admissions counseling in Vietnam. While large language models\n(LLMs) offer potential for automating advisory tasks, most existing solutions\nremain limited to prototypes or synthetic benchmarks. MARAUS addresses this gap\nby combining hybrid retrieval, multi-agent orchestration, and LLM-based\ngeneration into a system tailored for real-world university admissions. In\ncollaboration with the University of Transport Technology (UTT) in Hanoi, we\nconducted a two-phase study involving technical development and real-world\nevaluation. MARAUS processed over 6,000 actual user interactions, spanning six\ncategories of queries. Results show substantial improvements over LLM-only\nbaselines: on average 92 percent accuracy, hallucination rates reduced from 15\nprecent to 1.45 percent, and average response times below 4 seconds. The system\noperated cost-effectively, with a two-week deployment cost of 11.58 USD using\nGPT-4o mini. This work provides actionable insights for the deployment of\nagentic RAG systems in low-resource educational settings.", "AI": {"tldr": "MARAUS\u662f\u4e00\u4e2a\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u3001\u68c0\u7d22\u589e\u5f3a\u548cLLM\u7684\u5bf9\u8bddAI\u5e73\u53f0\uff0c\u7528\u4e8e\u8d8a\u5357\u9ad8\u7b49\u6559\u80b2\u62db\u751f\u54a8\u8be2\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u89e3\u51b3\u65b9\u6848\u591a\u4e3a\u539f\u578b\u6216\u5408\u6210\u57fa\u51c6\uff0cMARAUS\u586b\u8865\u4e86\u5b9e\u9645\u90e8\u7f72\u7684\u7a7a\u767d\uff0c\u4e3a\u4f4e\u8d44\u6e90\u6559\u80b2\u73af\u5883\u63d0\u4f9b\u5b9e\u7528\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u6df7\u5408\u68c0\u7d22\u3001\u591a\u667a\u80fd\u4f53\u534f\u8c03\u548cLLM\u751f\u6210\uff0c\u4e0e\u8d8a\u5357\u8fd0\u8f93\u6280\u672f\u5927\u5b66\u5408\u4f5c\u8fdb\u884c\u6280\u672f\u5f00\u53d1\u548c\u5b9e\u9645\u8bc4\u4f30\u3002", "result": "\u5904\u74066000+\u5b9e\u9645\u7528\u6237\u67e5\u8be2\uff0c\u5e73\u5747\u51c6\u786e\u738792%\uff0c\u5e7b\u89c9\u7387\u4ece15%\u964d\u81f31.45%\uff0c\u54cd\u5e94\u65f6\u95f4\u4f4e\u4e8e4\u79d2\uff0c\u6210\u672c\u4ec511.58\u7f8e\u5143\u3002", "conclusion": "MARAUS\u4e3a\u4f4e\u8d44\u6e90\u6559\u80b2\u73af\u5883\u4e2d\u90e8\u7f72\u667a\u80fdRAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u548c\u5b9e\u7528\u7ecf\u9a8c\u3002"}}
{"id": "2507.10898", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10898", "abs": "https://arxiv.org/abs/2507.10898", "authors": ["Jugal Gajjar", "Kamalasankari Subramaniakuppusamy", "Noha El Kachach"], "title": "MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning", "comment": "6 pages, 4 figures, accepted for publication in IEEE 26th\n  International Conference on Information Reuse and Integration (IRI 2025)", "summary": "The growing complexity of cyber threats and the limitations of traditional\nvulnerability detection tools necessitate novel approaches for securing\nsoftware systems. We introduce MalCodeAI, a language-agnostic, multi-stage AI\npipeline for autonomous code security analysis and remediation. MalCodeAI\ncombines code decomposition and semantic reasoning using fine-tuned\nQwen2.5-Coder-3B-Instruct models, optimized through Low-Rank Adaptation (LoRA)\nwithin the MLX framework, and delivers scalable, accurate results across 14\nprogramming languages. In Phase 1, the model achieved a validation loss as low\nas 0.397 for functional decomposition and summarization of code segments after\n200 iterations, 6 trainable layers, and a learning rate of 2 x 10^(-5). In\nPhase 2, for vulnerability detection and remediation, it achieved a best\nvalidation loss of 0.199 using the same number of iterations and trainable\nlayers but with an increased learning rate of 4 x 10^(-5), effectively\nidentifying security flaws and suggesting actionable fixes. MalCodeAI supports\nred-hat-style exploit tracing, CVSS-based risk scoring, and zero-shot\ngeneralization to detect complex, zero-day vulnerabilities. In a qualitative\nevaluation involving 15 developers, the system received high scores in\nusefulness (mean 8.06/10), interpretability (mean 7.40/10), and readability of\noutputs (mean 7.53/10), confirming its practical value in real-world\ndevelopment workflows. This work marks a significant advancement toward\nintelligent, explainable, and developer-centric software security solutions.", "AI": {"tldr": "MalCodeAI\u662f\u4e00\u79cd\u8bed\u8a00\u65e0\u5173\u7684\u591a\u9636\u6bb5AI\u7ba1\u9053\uff0c\u7528\u4e8e\u81ea\u4e3b\u4ee3\u7801\u5b89\u5168\u5206\u6790\u548c\u4fee\u590d\uff0c\u7ed3\u5408\u4e86\u4ee3\u7801\u5206\u89e3\u548c\u8bed\u4e49\u63a8\u7406\uff0c\u572814\u79cd\u7f16\u7a0b\u8bed\u8a00\u4e2d\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u51c6\u786e\u7684\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u6f0f\u6d1e\u68c0\u6d4b\u5de5\u5177\u7684\u5c40\u9650\u6027\u53ca\u7f51\u7edc\u5a01\u80c1\u7684\u590d\u6742\u6027\u589e\u52a0\uff0c\u9700\u8981\u65b0\u7684\u8f6f\u4ef6\u7cfb\u7edf\u5b89\u5168\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7ecf\u8fc7\u5fae\u8c03\u7684Qwen2.5-Coder-3B-Instruct\u6a21\u578b\uff0c\u901a\u8fc7LoRA\u4f18\u5316\uff0c\u5206\u4e24\u9636\u6bb5\u8fdb\u884c\u529f\u80fd\u5206\u89e3\u548c\u6f0f\u6d1e\u68c0\u6d4b\u4fee\u590d\u3002", "result": "\u5728\u9a8c\u8bc1\u635f\u5931\u548c\u5f00\u53d1\u8005\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u529f\u80fd\u5206\u89e3\u9636\u6bb5\u9a8c\u8bc1\u635f\u59310.397\uff0c\u6f0f\u6d1e\u68c0\u6d4b\u9636\u6bb50.199\uff0c\u5f00\u53d1\u8005\u8bc4\u5206\u9ad8\u3002", "conclusion": "MalCodeAI\u4e3a\u667a\u80fd\u3001\u53ef\u89e3\u91ca\u4e14\u4ee5\u5f00\u53d1\u8005\u4e3a\u4e2d\u5fc3\u7684\u8f6f\u4ef6\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2507.10798", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10798", "abs": "https://arxiv.org/abs/2507.10798", "authors": ["Asim H. Gazi", "Bhanu T. Gullapalli", "Daiqi Gao", "Benjamin M. Marlin", "Vivek Shetty", "Susan A. Murphy"], "title": "Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions", "comment": "4 pages, 3 figures", "summary": "Timely decision making is critical to the effectiveness of mobile health\n(mHealth) interventions. At predefined timepoints called \"decision points,\"\nintelligent mHealth systems such as just-in-time adaptive interventions\n(JITAIs) estimate an individual's biobehavioral context from sensor or survey\ndata and determine whether and how to intervene. For interventions targeting\nhabitual behavior (e.g., oral hygiene), effectiveness often hinges on\ndelivering support shortly before the target behavior is likely to occur.\nCurrent practice schedules decision points at a fixed interval (e.g., one hour)\nbefore user-provided behavior times, and the fixed interval is kept the same\nfor all individuals. However, this one-size-fits-all approach performs poorly\nfor individuals with irregular routines, often scheduling decision points after\nthe target behavior has already occurred, rendering interventions ineffective.\nIn this paper, we propose SigmaScheduling, a method to dynamically schedule\ndecision points based on uncertainty in predicted behavior times. When behavior\ntiming is more predictable, SigmaScheduling schedules decision points closer to\nthe predicted behavior time; when timing is less certain, SigmaScheduling\nschedules decision points earlier, increasing the likelihood of timely\nintervention. We evaluated SigmaScheduling using real-world data from 68\nparticipants in a 10-week trial of Oralytics, a JITAI designed to improve daily\ntoothbrushing. SigmaScheduling increased the likelihood that decision points\npreceded brushing events in at least 70% of cases, preserving opportunities to\nintervene and impact behavior. Our results indicate that SigmaScheduling can\nadvance precision mHealth, particularly for JITAIs targeting time-sensitive,\nhabitual behaviors such as oral hygiene or dietary habits.", "AI": {"tldr": "SigmaScheduling\u52a8\u6001\u8c03\u6574\u51b3\u7b56\u70b9\u65f6\u95f4\uff0c\u63d0\u9ad8\u79fb\u52a8\u5065\u5eb7\u5e72\u9884\u7684\u53ca\u65f6\u6027\u3002", "motivation": "\u56fa\u5b9a\u95f4\u9694\u7684\u51b3\u7b56\u70b9\u8c03\u5ea6\u5bf9\u4e60\u60ef\u6027\u884c\u4e3a\u5e72\u9884\u6548\u679c\u4e0d\u4f73\uff0c\u5c24\u5176\u662f\u5bf9\u4f5c\u606f\u4e0d\u89c4\u5f8b\u7684\u7528\u6237\u3002", "method": "\u63d0\u51faSigmaScheduling\u65b9\u6cd5\uff0c\u6839\u636e\u884c\u4e3a\u65f6\u95f4\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u52a8\u6001\u8c03\u6574\u51b3\u7b56\u70b9\u3002", "result": "\u572868\u540d\u53c2\u4e0e\u8005\u7684\u771f\u5b9e\u6570\u636e\u4e2d\uff0cSigmaScheduling\u572870%\u4ee5\u4e0a\u7684\u60c5\u51b5\u4e0b\u786e\u4fdd\u51b3\u7b56\u70b9\u65e9\u4e8e\u76ee\u6807\u884c\u4e3a\u3002", "conclusion": "SigmaScheduling\u63d0\u5347\u4e86\u79fb\u52a8\u5065\u5eb7\u5e72\u9884\u7684\u7cbe\u51c6\u6027\uff0c\u9002\u7528\u4e8e\u65f6\u95f4\u654f\u611f\u7684\u4e60\u60ef\u6027\u884c\u4e3a\u3002"}}
{"id": "2507.11346", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11346", "abs": "https://arxiv.org/abs/2507.11346", "authors": ["Pedro Sim\u00f5es", "Rohit Gheyi", "Rian Melo", "Jonhnanthan Oliveira", "M\u00e1rcio Ribeiro", "Wesley K. G. Assun\u00e7\u00e3o"], "title": "RefModel: Detecting Refactorings using Foundation Models", "comment": "Accepted at Brazilian Symposium on Software Engineering (SBES 2025)", "summary": "Refactoring is a common software engineering practice that improves code\nquality without altering program behavior. Although tools like ReExtractor+,\nRefactoringMiner, and RefDiff have been developed to detect refactorings\nautomatically, they rely on complex rule definitions and static analysis,\nmaking them difficult to extend and generalize to other programming languages.\nIn this paper, we investigate the viability of using foundation models for\nrefactoring detection, implemented in a tool named RefModel. We evaluate\nPhi4-14B, and Claude 3.5 Sonnet on a dataset of 858 single-operation\ntransformations applied to artificially generated Java programs, covering\nwidely-used refactoring types. We also extend our evaluation by including\nGemini 2.5 Pro and o4-mini-high, assessing their performance on 44 real-world\nrefactorings extracted from four open-source projects. These models are\ncompared against RefactoringMiner, RefDiff, and ReExtractor+. RefModel is\ncompetitive with, and in some cases outperform, traditional tools. In\nreal-world settings, Claude 3.5 Sonnet and Gemini 2.5 Pro jointly identified\n97% of all refactorings, surpassing the best-performing static-analysis-based\ntools. The models showed encouraging generalization to Python and Golang. They\nprovide natural language explanations and require only a single sentence to\ndefine each refactoring type.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u57fa\u7840\u6a21\u578b\uff08\u5982Phi4-14B\u3001Claude 3.5 Sonnet\u7b49\uff09\u68c0\u6d4b\u4ee3\u7801\u91cd\u6784\u7684\u53ef\u884c\u6027\uff0c\u5f00\u53d1\u4e86\u5de5\u5177RefModel\uff0c\u5e76\u5728\u6027\u80fd\u548c\u901a\u7528\u6027\u4e0a\u8d85\u8d8a\u4e86\u4f20\u7edf\u9759\u6001\u5206\u6790\u5de5\u5177\u3002", "motivation": "\u4f20\u7edf\u91cd\u6784\u68c0\u6d4b\u5de5\u5177\u4f9d\u8d56\u590d\u6742\u89c4\u5219\u548c\u9759\u6001\u5206\u6790\uff0c\u96be\u4ee5\u6269\u5c55\u548c\u901a\u7528\u5316\uff0c\u56e0\u6b64\u7814\u7a76\u63a2\u7d22\u4e86\u57fa\u7840\u6a21\u578b\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528Phi4-14B\u3001Claude 3.5 Sonnet\u7b49\u6a21\u578b\uff0c\u8bc4\u4f30\u4e86858\u4e2a\u4eba\u5de5\u751f\u6210\u7684Java\u7a0b\u5e8f\u91cd\u6784\u548c44\u4e2a\u771f\u5b9e\u9879\u76ee\u4e2d\u7684\u91cd\u6784\uff0c\u5e76\u4e0e\u4f20\u7edf\u5de5\u5177\u5bf9\u6bd4\u3002", "result": "RefModel\u5728\u90e8\u5206\u60c5\u51b5\u4e0b\u4f18\u4e8e\u4f20\u7edf\u5de5\u5177\uff0cClaude 3.5 Sonnet\u548cGemini 2.5 Pro\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u8bc6\u522b\u4e8697%\u7684\u91cd\u6784\uff0c\u4e14\u80fd\u6cdb\u5316\u5230Python\u548cGolang\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u5728\u91cd\u6784\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63d0\u4f9b\u4e86\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u4e14\u5b9a\u4e49\u7b80\u5355\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.10927", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.10927", "abs": "https://arxiv.org/abs/2507.10927", "authors": ["Jie Zhang", "Xiaohong Li", "Man Zheng", "Zhe Hou", "Guangdong Bai", "Ruitao Feng"], "title": "DVFS: A Dynamic Verifiable Fuzzy Search Service for Encrypted Cloud Data", "comment": null, "summary": "Cloud storage introduces critical privacy challenges for encrypted data\nretrieval, where fuzzy multi-keyword search enables approximate matching while\npreserving data confidentiality. Existing solutions face fundamental trade-offs\nbetween security and efficiency: linear-search mechanisms provide adaptive\nsecurity but incur prohibitive overhead for large-scale data, while tree-based\nindexes improve performance at the cost of branch leakage vulnerabilities.\n  To address these limitations, we propose DVFS - a dynamic verifiable fuzzy\nsearch service with three core innovations: (1) An \\textit{adaptive-secure\nfuzzy search} method integrating locality-sensitive hashing with virtual binary\ntrees, eliminating branch leakage while reducing search complexity from linear\nto sublinear ($O(\\log n)$ time); (2) A \\textit{dual-repository version control}\nmechanism supporting dynamic updates with forward privacy, preventing\ninformation leakage during operations; (3) A \\textit{blockchain-based\nverification system} that ensures correctness and completeness via smart\ncontracts, achieving $O(\\log n)$ verification complexity.\n  Our solution advances secure encrypted retrieval by simultaneously resolving\nthe security-performance paradox and enabling trustworthy dynamic operations.", "AI": {"tldr": "DVFS\u662f\u4e00\u79cd\u52a8\u6001\u53ef\u9a8c\u8bc1\u7684\u6a21\u7cca\u641c\u7d22\u670d\u52a1\uff0c\u89e3\u51b3\u4e86\u4e91\u5b58\u50a8\u4e2d\u52a0\u5bc6\u6570\u636e\u68c0\u7d22\u7684\u5b89\u5168\u4e0e\u6548\u7387\u77db\u76fe\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5b89\u5168\u6a21\u7cca\u641c\u7d22\u3001\u53cc\u5b58\u50a8\u5e93\u7248\u672c\u63a7\u5236\u548c\u533a\u5757\u94fe\u9a8c\u8bc1\u7cfb\u7edf\u5b9e\u73b0\u9ad8\u6548\u3001\u5b89\u5168\u7684\u52a8\u6001\u64cd\u4f5c\u3002", "motivation": "\u4e91\u5b58\u50a8\u4e2d\u7684\u52a0\u5bc6\u6570\u636e\u68c0\u7d22\u5b58\u5728\u5b89\u5168\u4e0e\u6548\u7387\u7684\u77db\u76fe\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u9ad8\u5b89\u5168\u6027\u548c\u9ad8\u6548\u7387\u7684\u9700\u6c42\u3002", "method": "DVFS\u7ed3\u5408\u4e86\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u548c\u865a\u62df\u4e8c\u53c9\u6811\u7684\u81ea\u9002\u5e94\u5b89\u5168\u6a21\u7cca\u641c\u7d22\u65b9\u6cd5\uff0c\u652f\u6301\u52a8\u6001\u66f4\u65b0\u7684\u53cc\u5b58\u50a8\u5e93\u7248\u672c\u63a7\u5236\u673a\u5236\uff0c\u4ee5\u53ca\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u9a8c\u8bc1\u7cfb\u7edf\u3002", "result": "DVFS\u5c06\u641c\u7d22\u590d\u6742\u5ea6\u4ece\u7ebf\u6027\u964d\u81f3\u4e9a\u7ebf\u6027\uff08O(log n)\uff09\uff0c\u540c\u65f6\u6d88\u9664\u4e86\u5206\u652f\u6cc4\u6f0f\u98ce\u9669\uff0c\u5e76\u901a\u8fc7\u533a\u5757\u94fe\u9a8c\u8bc1\u786e\u4fdd\u64cd\u4f5c\u7684\u6b63\u786e\u6027\u548c\u5b8c\u6574\u6027\u3002", "conclusion": "DVFS\u6210\u529f\u89e3\u51b3\u4e86\u5b89\u5168\u4e0e\u6027\u80fd\u7684\u77db\u76fe\uff0c\u4e3a\u52a0\u5bc6\u6570\u636e\u68c0\u7d22\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u5b89\u5168\u4e14\u53ef\u4fe1\u7684\u52a8\u6001\u64cd\u4f5c\u65b9\u6848\u3002"}}
{"id": "2507.10803", "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.10803", "abs": "https://arxiv.org/abs/2507.10803", "authors": ["JaMor Hairston", "Ritvik Ranjan", "Sahithi Lakamana", "Anthony Spadaro", "Selen Bozkurt", "Jeanmarie Perrone", "Abeed Sarker"], "title": "Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case", "comment": "Pages: 19, Abstract word count: 151 words, Manuscript word count:\n  2185 words, References: 14, Figures: 3, Tables: 2", "summary": "Background Large language models (LLMs) face challenges in inductive thematic\nanalysis, a task requiring deep interpretive and domain-specific expertise. We\nevaluated the feasibility of using LLMs to replicate expert-driven thematic\nanalysis of social media data. Methods Using two temporally non-intersecting\nReddit datasets on xylazine (n=286 and n=686, for model optimization and\nvalidation, respectively) with twelve expert-derived themes, we evaluated five\nLLMs against expert coding. We modeled the task as a series of binary\nclassifications, rather than a single, multi-label classification, employing\nzero-, single-, and few-shot prompting strategies and measuring performance via\naccuracy, precision, recall, and F1-score. Results On the validation set,\nGPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:\n0.71). For high-prevalence themes, model-derived thematic distributions closely\nmirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:\n16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based\napproaches can automate thematic analyses, offering a scalable supplement for\nqualitative research. Keywords: thematic analysis, large language models,\nnatural language processing, qualitative analysis, social media, prompt\nengineering, public health", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e3b\u9898\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0GPT-4o\u5728\u5c11\u91cf\u6837\u672c\u63d0\u793a\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u53ef\u4f5c\u4e3a\u5b9a\u6027\u7814\u7a76\u7684\u8865\u5145\u5de5\u5177\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u9700\u8981\u6df1\u5ea6\u89e3\u91ca\u548c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u7684\u4e3b\u9898\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u66ff\u4ee3\u6216\u8f85\u52a9\u4e13\u5bb6\u5206\u6790\u3002", "method": "\u4f7f\u7528\u4e24\u4e2aReddit\u6570\u636e\u96c6\uff0c\u5c06\u4efb\u52a1\u5efa\u6a21\u4e3a\u4e00\u7cfb\u5217\u4e8c\u5143\u5206\u7c7b\uff0c\u91c7\u7528\u96f6\u6837\u672c\u3001\u5355\u6837\u672c\u548c\u5c11\u91cf\u6837\u672c\u63d0\u793a\u7b56\u7565\uff0c\u8bc4\u4f30\u4e94\u4e2aLLMs\u7684\u6027\u80fd\u3002", "result": "GPT-4o\u5728\u5c11\u91cf\u6837\u672c\u63d0\u793a\u4e0b\u8868\u73b0\u6700\u4f73\uff08\u51c6\u786e\u738790.9%\uff0cF1\u5206\u65700.71\uff09\uff0c\u9ad8\u6d41\u884c\u4e3b\u9898\u7684\u5206\u5e03\u4e0e\u4e13\u5bb6\u5206\u7c7b\u63a5\u8fd1\u3002", "conclusion": "\u5c11\u91cf\u6837\u672cLLM\u65b9\u6cd5\u53ef\u81ea\u52a8\u5316\u4e3b\u9898\u5206\u6790\uff0c\u4e3a\u5b9a\u6027\u7814\u7a76\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u8865\u5145\u5de5\u5177\u3002"}}
{"id": "2507.11362", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11362", "abs": "https://arxiv.org/abs/2507.11362", "authors": ["Chaima Boufaied", "Taher Ghaleb", "Zainab Masood"], "title": "Security Debt in Practice: Nuanced Insights from Practitioners", "comment": null, "summary": "With the increasing reliance on software and automation nowadays, tight\ndeadlines, limited resources, and prioritization of functionality over security\ncan lead to insecure coding practices. When not handled properly, these\nconstraints cause unaddressed security vulnerabilities to accumulate over time,\nforming Security Debts (SDs). Despite their critical importance, there is\nlimited empirical evidence on how software practitioners perceive, manage, and\ncommunicate SDs in real-world settings. In this paper, we present a qualitative\nempirical study based on semi-structured interviews with 22 software\npractitioners across various roles, organizations, and countries. We address\nfour research questions: i) we assess software practitioners' knowledge of SDs\nand awareness of associated security risks, ii) we investigate their behavior\ntowards SDs, iii) we explore common tools and strategies used to mitigate SDs,\nand iv) we analyze how security risks are communicated within teams and to\ndecision makers. We observe variations in how practitioners perceive and manage\nSDs, with some prioritizing delivery speed over security, while others\nconsistently maintain security as a priority. Our findings emphasize the need\nfor stronger integration of security practices across the Software Development\nLife Cycle (SDLC), more consistent use of mitigation strategies, better\nbalancing of deadlines, resources, and security-related tasks, with attention\nto the Confidentiality, Integrity, and Availability (CIA) triad.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5b9a\u6027\u5b9e\u8bc1\u7814\u7a76\u63a2\u8ba8\u4e86\u8f6f\u4ef6\u4ece\u4e1a\u8005\u5bf9\u5b89\u5168\u503a\u52a1\uff08SDs\uff09\u7684\u8ba4\u77e5\u3001\u7ba1\u7406\u548c\u6c9f\u901a\u65b9\u5f0f\uff0c\u5f3a\u8c03\u4e86\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u52a0\u5f3a\u5b89\u5168\u5b9e\u8df5\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u8f6f\u4ef6\u884c\u4e1a\u56e0\u65f6\u95f4\u3001\u8d44\u6e90\u9650\u5236\u548c\u529f\u80fd\u4f18\u5148\u4e8e\u5b89\u5168\u7684\u505a\u6cd5\uff0c\u5bfc\u81f4\u5b89\u5168\u503a\u52a1\u79ef\u7d2f\uff0c\u4f46\u7f3a\u4e4f\u5b9e\u8bc1\u7814\u7a76\u63a2\u8ba8\u4ece\u4e1a\u8005\u5982\u4f55\u5e94\u5bf9\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u8c03\u67e5\u4e8622\u540d\u6765\u81ea\u4e0d\u540c\u89d2\u8272\u3001\u7ec4\u7ec7\u548c\u56fd\u5bb6\u7684\u8f6f\u4ef6\u4ece\u4e1a\u8005\uff0c\u56f4\u7ed5\u56db\u4e2a\u7814\u7a76\u95ee\u9898\u5c55\u5f00\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4ece\u4e1a\u8005\u5bf9SDs\u7684\u8ba4\u77e5\u548c\u7ba1\u7406\u5b58\u5728\u5dee\u5f02\uff0c\u90e8\u5206\u4eba\u4f18\u5148\u8003\u8651\u4ea4\u4ed8\u901f\u5ea6\u800c\u975e\u5b89\u5168\uff0c\u9700\u52a0\u5f3a\u5b89\u5168\u5b9e\u8df5\u548c\u98ce\u9669\u6c9f\u901a\u3002", "conclusion": "\u9700\u5728SDLC\u4e2d\u66f4\u7d27\u5bc6\u5730\u6574\u5408\u5b89\u5168\u5b9e\u8df5\uff0c\u5e73\u8861\u8d44\u6e90\u4e0e\u5b89\u5168\u4efb\u52a1\uff0c\u5e76\u5173\u6ce8CIA\u4e09\u8981\u7d20\u3002"}}
{"id": "2507.11137", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11137", "abs": "https://arxiv.org/abs/2507.11137", "authors": ["Yuan Yao", "Jin Song", "Jian Jin"], "title": "Hashed Watermark as a Filter: Defeating Forging and Overwriting Attacks in Weight-based Neural Network Watermarking", "comment": null, "summary": "As valuable digital assets, deep neural networks necessitate robust ownership\nprotection, positioning neural network watermarking (NNW) as a promising\nsolution. Among various NNW approaches, weight-based methods are favored for\ntheir simplicity and practicality; however, they remain vulnerable to forging\nand overwriting attacks. To address those challenges, we propose NeuralMark, a\nrobust method built around a hashed watermark filter. Specifically, we utilize\na hash function to generate an irreversible binary watermark from a secret key,\nwhich is then used as a filter to select the model parameters for embedding.\nThis design cleverly intertwines the embedding parameters with the hashed\nwatermark, providing a robust defense against both forging and overwriting\nattacks. An average pooling is also incorporated to resist fine-tuning and\npruning attacks. Furthermore, it can be seamlessly integrated into various\nneural network architectures, ensuring broad applicability. Theoretically, we\nanalyze its security boundary. Empirically, we verify its effectiveness and\nrobustness across 13 distinct Convolutional and Transformer architectures,\ncovering five image classification tasks and one text generation task. The\nsource codes are available at https://github.com/AIResearch-Group/NeuralMark.", "AI": {"tldr": "NeuralMark\u662f\u4e00\u79cd\u57fa\u4e8e\u54c8\u5e0c\u6c34\u5370\u8fc7\u6ee4\u5668\u7684\u795e\u7ecf\u7f51\u7edc\u6c34\u5370\u65b9\u6cd5\uff0c\u65e8\u5728\u4fdd\u62a4\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u7248\u6743\uff0c\u62b5\u5fa1\u4f2a\u9020\u548c\u8986\u76d6\u653b\u51fb\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u6709\u4ef7\u503c\u7684\u6570\u5b57\u8d44\u4ea7\u9700\u8981\u7248\u6743\u4fdd\u62a4\uff0c\u800c\u73b0\u6709\u7684\u6743\u91cd\u6c34\u5370\u65b9\u6cd5\u6613\u53d7\u653b\u51fb\u3002", "method": "\u5229\u7528\u54c8\u5e0c\u51fd\u6570\u4ece\u5bc6\u94a5\u751f\u6210\u4e0d\u53ef\u9006\u4e8c\u8fdb\u5236\u6c34\u5370\uff0c\u4f5c\u4e3a\u8fc7\u6ee4\u5668\u9009\u62e9\u5d4c\u5165\u53c2\u6570\uff0c\u5e76\u7ed3\u5408\u5e73\u5747\u6c60\u5316\u62b5\u6297\u5fae\u8c03\u548c\u526a\u679d\u653b\u51fb\u3002", "result": "\u572813\u79cd\u5377\u79ef\u548cTransformer\u67b6\u6784\u30015\u4e2a\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u548c1\u4e2a\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "NeuralMark\u8bbe\u8ba1\u5de7\u5999\uff0c\u9002\u7528\u8303\u56f4\u5e7f\uff0c\u7406\u8bba\u5b89\u5168\u8fb9\u754c\u660e\u786e\uff0c\u5b9e\u8df5\u6548\u679c\u663e\u8457\u3002"}}
{"id": "2507.10831", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10831", "abs": "https://arxiv.org/abs/2507.10831", "authors": ["Yilin Xia", "Heng Zheng", "Shawn Bowers", "Bertram Lud\u00e4scher"], "title": "AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks", "comment": "International Conference on Artificial Intelligence and Law (ICAIL),\n  June 16-20, 2025. Chicago, IL, USA", "summary": "Argumentation frameworks (AFs) provide formal approaches for legal reasoning,\nbut identifying sources of ambiguity and explaining argument acceptance remains\nchallenging for non-experts. We present AF-XRAY, an open-source toolkit for\nexploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY\nintroduces: (i) layered visualizations based on game-theoretic argument length\nrevealing well-founded derivation structures; (ii) classification of attack\nedges by semantic roles (primary, secondary, blunders); (iii) overlay\nvisualizations of alternative 2-valued solutions on ambiguous 3-valued grounded\nsemantics; and (iv) identification of critical attack sets whose suspension\nresolves undecided arguments. Through systematic generation of critical attack\nsets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling\nusers to pinpoint specific causes of ambiguity and explore alternative\nresolutions. We use real-world legal cases (e.g., Wild Animals as modeled by\nBench-Capon) to show that our tool supports teleological legal reasoning by\nrevealing how different assumptions lead to different justified conclusions.", "AI": {"tldr": "AF-XRAY\u662f\u4e00\u4e2a\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u63a2\u7d22\u3001\u5206\u6790\u548c\u53ef\u89c6\u5316\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff08AFs\uff09\uff0c\u5e2e\u52a9\u975e\u4e13\u5bb6\u8bc6\u522b\u6b67\u4e49\u6765\u6e90\u5e76\u89e3\u91ca\u8bba\u8bc1\u63a5\u53d7\u6027\u3002", "motivation": "\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u8bba\u8bc1\u6846\u67b6\uff08AFs\uff09\u5b58\u5728\u6b67\u4e49\u548c\u89e3\u91ca\u96be\u9898\uff0c\u975e\u4e13\u5bb6\u96be\u4ee5\u7406\u89e3\u3002AF-XRAY\u65e8\u5728\u901a\u8fc7\u53ef\u89c6\u5316\u5de5\u5177\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "AF-XRAY\u63d0\u4f9b\u5206\u5c42\u53ef\u89c6\u5316\u3001\u653b\u51fb\u8fb9\u5206\u7c7b\u3001\u66ff\u4ee3\u89e3\u51b3\u65b9\u6848\u53e0\u52a0\u53ef\u89c6\u5316\uff0c\u4ee5\u53ca\u5173\u952e\u653b\u51fb\u96c6\u8bc6\u522b\u529f\u80fd\u3002", "result": "AF-XRAY\u80fd\u5c06\u6b67\u4e49\u573a\u666f\u8f6c\u5316\u4e3a\u660e\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e2e\u52a9\u7528\u6237\u5b9a\u4f4d\u6b67\u4e49\u539f\u56e0\u5e76\u63a2\u7d22\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "AF-XRAY\u901a\u8fc7\u5b9e\u9645\u6cd5\u5f8b\u6848\u4f8b\u9a8c\u8bc1\uff0c\u652f\u6301\u76ee\u7684\u6027\u6cd5\u5f8b\u63a8\u7406\uff0c\u5c55\u793a\u4e0d\u540c\u5047\u8bbe\u5982\u4f55\u5bfc\u81f4\u4e0d\u540c\u7ed3\u8bba\u3002"}}
{"id": "2507.11138", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.11138", "abs": "https://arxiv.org/abs/2507.11138", "authors": ["Adriano Castro", "Simon Hanisch", "Matin Fallahi", "Thorsten Strufe"], "title": "FacialMotionID: Identifying Users of Mixed Reality Headsets using Abstract Facial Motion Representations", "comment": null, "summary": "Facial motion capture in mixed reality headsets enables real-time avatar\nanimation, allowing users to convey non-verbal cues during virtual\ninteractions. However, as facial motion data constitutes a behavioral\nbiometric, its use raises novel privacy concerns. With mixed reality systems\nbecoming more immersive and widespread, understanding whether face motion data\ncan lead to user identification or inference of sensitive attributes is\nincreasingly important.\n  To address this, we conducted a study with 116 participants using three types\nof headsets across three sessions, collecting facial, eye, and head motion data\nduring verbal and non-verbal tasks. The data used is not raw video, but rather,\nabstract representations that are used to animate digital avatars. Our analysis\nshows that individuals can be re-identified from this data with up to 98%\nbalanced accuracy, are even identifiable across device types, and that\nemotional states can be inferred with up to 86% accuracy. These results\nunderscore the potential privacy risks inherent in face motion tracking in\nmixed reality environments.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u6df7\u5408\u73b0\u5b9e\u5934\u6234\u8bbe\u5907\u4e2d\u9762\u90e8\u8fd0\u52a8\u6570\u636e\u7684\u9690\u79c1\u98ce\u9669\uff0c\u53d1\u73b0\u7528\u6237\u53ef\u901a\u8fc7\u6570\u636e\u88ab\u9ad8\u7cbe\u5ea6\u8bc6\u522b\uff0c\u4e14\u60c5\u7eea\u72b6\u6001\u4e5f\u53ef\u88ab\u63a8\u65ad\u3002", "motivation": "\u968f\u7740\u6df7\u5408\u73b0\u5b9e\u8bbe\u5907\u666e\u53ca\uff0c\u9762\u90e8\u8fd0\u52a8\u6570\u636e\u4f5c\u4e3a\u884c\u4e3a\u751f\u7269\u7279\u5f81\u53ef\u80fd\u5f15\u53d1\u9690\u79c1\u95ee\u9898\uff0c\u9700\u8bc4\u4f30\u5176\u662f\u5426\u4f1a\u5bfc\u81f4\u7528\u6237\u8eab\u4efd\u6216\u654f\u611f\u4fe1\u606f\u6cc4\u9732\u3002", "method": "\u7814\u7a76\u6536\u96c6\u4e86116\u540d\u53c2\u4e0e\u8005\u5728\u4e09\u79cd\u5934\u6234\u8bbe\u5907\u4e0a\u7684\u9762\u90e8\u3001\u773c\u90e8\u548c\u5934\u90e8\u8fd0\u52a8\u6570\u636e\uff0c\u5206\u6790\u5176\u62bd\u8c61\u8868\u793a\u5f62\u5f0f\u7684\u8bc6\u522b\u80fd\u529b\u3002", "result": "\u7528\u6237\u53ef\u4ece\u6570\u636e\u4e2d\u4ee598%\u7684\u5e73\u8861\u51c6\u786e\u7387\u88ab\u91cd\u65b0\u8bc6\u522b\uff0c\u4e14\u60c5\u7eea\u72b6\u6001\u63a8\u65ad\u51c6\u786e\u7387\u8fbe86%\u3002", "conclusion": "\u9762\u90e8\u8fd0\u52a8\u6570\u636e\u5728\u6df7\u5408\u73b0\u5b9e\u73af\u5883\u4e2d\u5b58\u5728\u663e\u8457\u7684\u9690\u79c1\u98ce\u9669\uff0c\u9700\u5f15\u8d77\u91cd\u89c6\u3002"}}
{"id": "2507.10894", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10894", "abs": "https://arxiv.org/abs/2507.10894", "authors": ["Zongtao He", "Liuyi Wang", "Lu Chen", "Chengju Liu", "Qijun Chen"], "title": "NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization", "comment": null, "summary": "Language-guided navigation is a cornerstone of embodied AI, enabling agents\nto interpret language instructions and navigate complex environments. However,\nexpert-provided instructions are limited in quantity, while synthesized\nannotations often lack quality, making them insufficient for large-scale\nresearch. To address this, we propose NavComposer, a novel framework for\nautomatically generating high-quality navigation instructions. NavComposer\nexplicitly decomposes semantic entities such as actions, scenes, and objects,\nand recomposes them into natural language instructions. Its modular\narchitecture allows flexible integration of state-of-the-art techniques, while\nthe explicit use of semantic entities enhances both the richness and accuracy\nof instructions. Moreover, it operates in a data-agnostic manner, supporting\nadaptation to diverse navigation trajectories without domain-specific training.\nComplementing NavComposer, we introduce NavInstrCritic, a comprehensive\nannotation-free evaluation system that assesses navigation instructions on\nthree dimensions: contrastive matching, semantic consistency, and linguistic\ndiversity. NavInstrCritic provides a holistic evaluation of instruction\nquality, addressing limitations of traditional metrics that rely heavily on\nexpert annotations. By decoupling instruction generation and evaluation from\nspecific navigation agents, our method enables more scalable and generalizable\nresearch. Extensive experiments provide direct and practical evidence for the\neffectiveness of our method.", "AI": {"tldr": "NavComposer\u662f\u4e00\u4e2a\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u5bfc\u822a\u6307\u4ee4\u7684\u6846\u67b6\uff0c\u7ed3\u5408NavInstrCritic\u8fdb\u884c\u65e0\u6807\u6ce8\u8bc4\u4f30\uff0c\u63d0\u5347\u8bed\u8a00\u5bfc\u822a\u7814\u7a76\u7684\u53ef\u6269\u5c55\u6027\u548c\u901a\u7528\u6027\u3002", "motivation": "\u89e3\u51b3\u4e13\u5bb6\u63d0\u4f9b\u7684\u5bfc\u822a\u6307\u4ee4\u6570\u91cf\u6709\u9650\uff0c\u5408\u6210\u6307\u4ee4\u8d28\u91cf\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "NavComposer\u901a\u8fc7\u5206\u89e3\u548c\u91cd\u7ec4\u8bed\u4e49\u5b9e\u4f53\u751f\u6210\u6307\u4ee4\uff0cNavInstrCritic\u4ece\u5bf9\u6bd4\u5339\u914d\u3001\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u8bed\u8a00\u591a\u6837\u6027\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u6307\u4ee4\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u652f\u6301\u5927\u89c4\u6a21\u7814\u7a76\u3002", "conclusion": "NavComposer\u548cNavInstrCritic\u4e3a\u8bed\u8a00\u5bfc\u822a\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11155", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11155", "abs": "https://arxiv.org/abs/2507.11155", "authors": ["Yiting Qu", "Michael Backes", "Yang Zhang"], "title": "Bridging the Gap in Vision Language Models in Identifying Unsafe Concepts Across Modalities", "comment": "To Appear in the 34th USENIX Security Symposium, August 2025", "summary": "Vision-language models (VLMs) are increasingly applied to identify unsafe or\ninappropriate images due to their internal ethical standards and powerful\nreasoning abilities. However, it is still unclear whether they can recognize\nvarious unsafe concepts when presented in different modalities, such as text\nand images. To address this, we first compile the UnsafeConcepts dataset,\nfeaturing 75 unsafe concepts, i.e., ``Swastika,'' ``Sexual Harassment,'' and\n``Assaults,'' along with associated 1.5K images. We then conduct a systematic\nevaluation of VLMs' perception (concept recognition) and alignment (ethical\nreasoning) capabilities. We assess eight popular VLMs and find that, although\nmost VLMs accurately perceive unsafe concepts, they sometimes mistakenly\nclassify these concepts as safe. We also identify a consistent modality gap\namong open-source VLMs in distinguishing between visual and textual unsafe\nconcepts. To bridge this gap, we introduce a simplified reinforcement learning\n(RL)-based approach using proximal policy optimization (PPO) to strengthen the\nability to identify unsafe concepts from images. Our approach uses reward\nscores based directly on VLM responses, bypassing the need for collecting\nhuman-annotated preference data to train a new reward model. Experimental\nresults show that our approach effectively enhances VLM alignment on images\nwhile preserving general capabilities. It outperforms baselines such as\nsupervised fine-tuning (SFT) and direct preference optimization (DPO). We hope\nour dataset, evaluation findings, and proposed alignment solution contribute to\nthe community's efforts in advancing safe VLMs.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u8bc6\u522b\u591a\u6a21\u6001\u4e0d\u5b89\u5168\u6982\u5ff5\u65f6\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u4e86UnsafeConcepts\u6570\u636e\u96c6\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u9f50\u80fd\u529b\u3002", "motivation": "\u63a2\u8ba8VLMs\u5728\u4e0d\u540c\u6a21\u6001\uff08\u6587\u672c\u548c\u56fe\u50cf\uff09\u4e0b\u8bc6\u522b\u4e0d\u5b89\u5168\u6982\u5ff5\u7684\u80fd\u529b\uff0c\u5e76\u89e3\u51b3\u5176\u5b58\u5728\u7684\u6a21\u6001\u5dee\u8ddd\u95ee\u9898\u3002", "method": "\u6784\u5efaUnsafeConcepts\u6570\u636e\u96c6\uff0c\u8bc4\u4f308\u79cd\u6d41\u884cVLMs\u7684\u611f\u77e5\u548c\u5bf9\u9f50\u80fd\u529b\uff0c\u63d0\u51fa\u57fa\u4e8ePPO\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6765\u4f18\u5316\u6a21\u578b\u5bf9\u9f50\u3002", "result": "\u53d1\u73b0VLMs\u80fd\u51c6\u786e\u611f\u77e5\u4e0d\u5b89\u5168\u6982\u5ff5\u4f46\u6709\u65f6\u8bef\u5224\u4e3a\u5b89\u5168\uff0c\u5f00\u6e90VLMs\u5b58\u5728\u6a21\u6001\u5dee\u8ddd\uff1b\u63d0\u51fa\u7684RL\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63a8\u8fdb\u5b89\u5168VLMs\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u7ed3\u679c\u548c\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2507.10911", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10911", "abs": "https://arxiv.org/abs/2507.10911", "authors": ["Yicong Wu", "Ting Chen", "Irit Hochberg", "Zhoujian Sun", "Ruth Edry", "Zhengxing Huang", "Mor Peleg"], "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "comment": null, "summary": "Therapy recommendation for chronic patients with multimorbidity is\nchallenging due to risks of treatment conflicts. Existing decision support\nsystems face scalability limitations. Inspired by the way in which general\npractitioners (GP) manage multimorbidity patients, occasionally convening\nmultidisciplinary team (MDT) collaboration, this study investigated the\nfeasibility and value of using a Large Language Model (LLM)-based multi-agent\nsystem (MAS) for safer therapy recommendations. We designed a single agent and\na MAS framework simulating MDT decision-making by enabling discussion among LLM\nagents to resolve medical conflicts. The systems were evaluated on therapy\nplanning tasks for multimorbidity patients using benchmark cases. We compared\nMAS performance with single-agent approaches and real-world benchmarks. An\nimportant contribution of our study is the definition of evaluation metrics\nthat go beyond the technical precision and recall and allow the inspection of\nclinical goals met and medication burden of the proposed advices to a gold\nstandard benchmark. Our results show that with current LLMs, a single agent GP\nperforms as well as MDTs. The best-scoring models provide correct\nrecommendations that address all clinical goals, yet the advices are\nincomplete. Some models also present unnecessary medications, resulting in\nunnecessary conflicts between medication and conditions or drug-drug\ninteractions.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff08MAS\uff09\u4e3a\u591a\u75c5\u5171\u5b58\u60a3\u8005\u63d0\u4f9b\u66f4\u5b89\u5168\u7684\u6cbb\u7597\u5efa\u8bae\u7684\u53ef\u884c\u6027\u548c\u4ef7\u503c\uff0c\u53d1\u73b0\u5355\u4ee3\u7406\u7cfb\u7edf\u4e0e\u591a\u5b66\u79d1\u56e2\u961f\uff08MDT\uff09\u8868\u73b0\u76f8\u5f53\uff0c\u4f46\u5efa\u8bae\u4ecd\u5b58\u5728\u4e0d\u5b8c\u6574\u548c\u4e0d\u5fc5\u8981\u7684\u836f\u7269\u95ee\u9898\u3002", "motivation": "\u591a\u75c5\u5171\u5b58\u60a3\u8005\u7684\u6cbb\u7597\u5efa\u8bae\u56e0\u6cbb\u7597\u51b2\u7a81\u98ce\u9669\u800c\u590d\u6742\u5316\uff0c\u73b0\u6709\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u5b58\u5728\u53ef\u6269\u5c55\u6027\u9650\u5236\uff0c\u7814\u7a76\u65e8\u5728\u6a21\u62dfMDT\u534f\u4f5c\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u5355\u4ee3\u7406\u548cMAS\u6846\u67b6\uff0c\u6a21\u62dfMDT\u51b3\u7b56\u8fc7\u7a0b\uff0c\u901a\u8fc7LLM\u4ee3\u7406\u95f4\u7684\u8ba8\u8bba\u89e3\u51b3\u533b\u7597\u51b2\u7a81\uff0c\u5e76\u5728\u591a\u75c5\u5171\u5b58\u60a3\u8005\u7684\u6cbb\u7597\u89c4\u5212\u4efb\u52a1\u4e2d\u8bc4\u4f30\u7cfb\u7edf\u6027\u80fd\u3002", "result": "\u5f53\u524dLLM\u4e0b\uff0c\u5355\u4ee3\u7406GP\u8868\u73b0\u4e0eMDT\u76f8\u5f53\uff0c\u6700\u4f73\u6a21\u578b\u80fd\u63d0\u4f9b\u6ee1\u8db3\u6240\u6709\u4e34\u5e8a\u76ee\u6807\u7684\u6b63\u786e\u5efa\u8bae\uff0c\u4f46\u5efa\u8bae\u4e0d\u5b8c\u6574\u4e14\u5b58\u5728\u4e0d\u5fc5\u8981\u7684\u836f\u7269\u51b2\u7a81\u3002", "conclusion": "LLM-MAS\u7cfb\u7edf\u5728\u591a\u75c5\u5171\u5b58\u6cbb\u7597\u5efa\u8bae\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u6539\u8fdb\u5efa\u8bae\u5b8c\u6574\u6027\u548c\u51cf\u5c11\u836f\u7269\u51b2\u7a81\u3002"}}
{"id": "2507.11083", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11083", "abs": "https://arxiv.org/abs/2507.11083", "authors": ["Longhui Zhang", "Bin Wang", "Jiahao Wang", "Xiaofeng Zhao", "Min Zhang", "Hao Yang", "Meishan Zhang", "Yu Li", "Jing Li", "Jun Yu", "Min Zhang"], "title": "Function-to-Style Guidance of LLMs for Code Translation", "comment": "This paper has been accepted by ICML 2025. Models and benchmarks can\n  be found at https://www.modelscope.cn/collections/F2STrans-42526ff95dd843", "summary": "Large language models (LLMs) have made significant strides in code\ntranslation tasks. However, ensuring both the correctness and readability of\ntranslated code remains a challenge, limiting their effective adoption in\nreal-world software development. In this work, we propose F2STrans, a\nfunction-to-style guiding paradigm designed to progressively improve the\nperformance of LLMs in code translation. Our approach comprises two key stages:\n(1) Functional learning, which optimizes translation correctness using\nhigh-quality source-target code pairs mined from online programming platforms,\nand (2) Style learning, which improves translation readability by incorporating\nboth positive and negative style examples. Additionally, we introduce a novel\ncode translation benchmark that includes up-to-date source code, extensive test\ncases, and manually annotated ground-truth translations, enabling comprehensive\nfunctional and stylistic evaluations. Experiments on both our new benchmark and\nexisting datasets demonstrate that our approach significantly improves code\ntranslation performance. Notably, our approach enables Qwen-1.5B to outperform\nprompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code\ntranslation scenarios.", "AI": {"tldr": "F2STrans\u662f\u4e00\u79cd\u5206\u9636\u6bb5\u7684\u4ee3\u7801\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u901a\u8fc7\u529f\u80fd\u5b66\u4e60\u548c\u98ce\u683c\u5b66\u4e60\u63d0\u5347LLMs\u7684\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3LLMs\u5728\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u6b63\u786e\u6027\u548c\u53ef\u8bfb\u6027\u7684\u6311\u6218\uff0c\u4ee5\u4fc3\u8fdb\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5206\u4e24\u9636\u6bb5\uff1a\u529f\u80fd\u5b66\u4e60\u4f18\u5316\u7ffb\u8bd1\u6b63\u786e\u6027\uff0c\u98ce\u683c\u5b66\u4e60\u63d0\u5347\u53ef\u8bfb\u6027\uff0c\u5e76\u7ed3\u5408\u65b0\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "F2STrans\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0cQwen-1.5B\u572820\u79cd\u573a\u666f\u4e2d\u5e73\u5747\u4f18\u4e8eQwen-32B\u548cGPT-4\u3002", "conclusion": "F2STrans\u4e3a\u4ee3\u7801\u7ffb\u8bd1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u529f\u80fd\u4e0e\u98ce\u683c\u4f18\u5316\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.11310", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11310", "abs": "https://arxiv.org/abs/2507.11310", "authors": ["Fengxiao Tang", "Huan Li", "Ming Zhao", "Zongzong Wu", "Shisong Peng", "Tao Yin"], "title": "LRCTI: A Large Language Model-Based Framework for Multi-Step Evidence Retrieval and Reasoning in Cyber Threat Intelligence Credibility Verification", "comment": null, "summary": "Verifying the credibility of Cyber Threat Intelligence (CTI) is essential for\nreliable cybersecurity defense. However, traditional approaches typically treat\nthis task as a static classification problem, relying on handcrafted features\nor isolated deep learning models. These methods often lack the robustness\nneeded to handle incomplete, heterogeneous, or noisy intelligence, and they\nprovide limited transparency in decision-making-factors that reduce their\neffectiveness in real-world threat environments. To address these limitations,\nwe propose LRCTI, a Large Language Model (LLM)-based framework designed for\nmulti-step CTI credibility verification. The framework first employs a text\nsummarization module to distill complex intelligence reports into concise and\nactionable threat claims. It then uses an adaptive multi-step evidence\nretrieval mechanism that iteratively identifies and refines supporting\ninformation from a CTI-specific corpus, guided by LLM feedback. Finally, a\nprompt-based Natural Language Inference (NLI) module is applied to evaluate the\ncredibility of each claim while generating interpretable justifications for the\nclassification outcome. Experiments conducted on two benchmark datasets,\nCTI-200 and PolitiFact show that LRCTI improves F1-Macro and F1-Micro scores by\nover 5%, reaching 90.9% and 93.6%, respectively, compared to state-of-the-art\nbaselines. These results demonstrate that LRCTI effectively addresses the core\nlimitations of prior methods, offering a scalable, accurate, and explainable\nsolution for automated CTI credibility verification", "AI": {"tldr": "LRCTI\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6b65\u9aa4\u9a8c\u8bc1\u7f51\u7edc\u5a01\u80c1\u60c5\u62a5\uff08CTI\uff09\u7684\u53ef\u4fe1\u5ea6\uff0c\u901a\u8fc7\u6587\u672c\u6458\u8981\u3001\u81ea\u9002\u5e94\u8bc1\u636e\u68c0\u7d22\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edfCTI\u53ef\u4fe1\u5ea6\u9a8c\u8bc1\u65b9\u6cd5\u7f3a\u4e4f\u9c81\u68d2\u6027\u548c\u900f\u660e\u5ea6\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u4e0d\u5b8c\u6574\u6216\u5608\u6742\u7684\u60c5\u62a5\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "LRCTI\u6846\u67b6\u5305\u62ec\u6587\u672c\u6458\u8981\u6a21\u5757\u3001\u81ea\u9002\u5e94\u591a\u6b65\u9aa4\u8bc1\u636e\u68c0\u7d22\u673a\u5236\u548c\u57fa\u4e8e\u63d0\u793a\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u6a21\u5757\uff0c\u9010\u6b65\u9a8c\u8bc1CTI\u7684\u53ef\u4fe1\u5ea6\u3002", "result": "\u5728CTI-200\u548cPolitiFact\u6570\u636e\u96c6\u4e0a\uff0cLRCTI\u7684F1-Macro\u548cF1-Micro\u5206\u6570\u5206\u522b\u8fbe\u523090.9%\u548c93.6%\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e865%\u4ee5\u4e0a\u3002", "conclusion": "LRCTI\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u81ea\u52a8\u5316CTI\u53ef\u4fe1\u5ea6\u9a8c\u8bc1\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2507.10923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10923", "abs": "https://arxiv.org/abs/2507.10923", "authors": ["Yuhao Wang", "Keyan Ding", "Kehua Feng", "Zeyuan Wang", "Ming Qin", "Xiaotong Li", "Qiang Zhang", "Huajun Chen"], "title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization", "comment": "Accepted at ACL 2025 (Main Conference)", "summary": "Protein language models have emerged as powerful tools for sequence\ngeneration, offering substantial advantages in functional optimization and\ndenovo design. However, these models also present significant risks of\ngenerating harmful protein sequences, such as those that enhance viral\ntransmissibility or evade immune responses. These concerns underscore critical\nbiosafety and ethical challenges. To address these issues, we propose a\nKnowledge-guided Preference Optimization (KPO) framework that integrates prior\nknowledge via a Protein Safety Knowledge Graph. This framework utilizes an\nefficient graph pruning strategy to identify preferred sequences and employs\nreinforcement learning to minimize the risk of generating harmful proteins.\nExperimental results demonstrate that KPO effectively reduces the likelihood of\nproducing hazardous sequences while maintaining high functionality, offering a\nrobust safety assurance framework for applying generative models in\nbiotechnology.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u77e5\u8bc6\u5f15\u5bfc\u7684\u504f\u597d\u4f18\u5316\uff08KPO\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u86cb\u767d\u8d28\u5b89\u5168\u77e5\u8bc6\u56fe\u8c31\u6574\u5408\u5148\u9a8c\u77e5\u8bc6\uff0c\u51cf\u5c11\u6709\u5bb3\u86cb\u767d\u8d28\u5e8f\u5217\u7684\u751f\u6210\u98ce\u9669\u3002", "motivation": "\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u5728\u529f\u80fd\u4f18\u5316\u548c\u8bbe\u8ba1\u4e2d\u6709\u4f18\u52bf\uff0c\u4f46\u53ef\u80fd\u751f\u6210\u6709\u5bb3\u5e8f\u5217\uff0c\u5e26\u6765\u751f\u7269\u5b89\u5168\u548c\u4f26\u7406\u6311\u6218\u3002", "method": "\u7ed3\u5408\u86cb\u767d\u8d28\u5b89\u5168\u77e5\u8bc6\u56fe\u8c31\uff0c\u91c7\u7528\u56fe\u526a\u679d\u7b56\u7565\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u4f18\u5316\u5e8f\u5217\u751f\u6210\u3002", "result": "KPO\u663e\u8457\u964d\u4f4e\u6709\u5bb3\u5e8f\u5217\u751f\u6210\u6982\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u529f\u80fd\u6027\u3002", "conclusion": "KPO\u4e3a\u751f\u7269\u6280\u672f\u4e2d\u751f\u6210\u6a21\u578b\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5b89\u5168\u4fdd\u8bc1\u3002"}}
{"id": "2507.11467", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11467", "abs": "https://arxiv.org/abs/2507.11467", "authors": ["Daniel Nichols", "Konstantinos Parasyris", "Harshitha Menon", "Brian R. Bartoldson", "Giorgis Georgakoudis", "Tal Ben-Nun", "Abhinav Bhatele"], "title": "Modeling Code: Is Text All You Need?", "comment": null, "summary": "Code LLMs have become extremely popular recently for modeling source code\nacross a variety of tasks, such as generation, translation, and summarization.\nHowever, transformer-based models are limited in their capabilities to reason\nthrough structured, analytical properties of code, such as control and data\nflow. Previous work has explored the modeling of these properties with\nstructured data and graph neural networks. However, these approaches lack the\ngenerative capabilities and scale of modern LLMs. In this work, we introduce a\nnovel approach to combine the strengths of modeling both code as text and more\nstructured forms.", "AI": {"tldr": "\u7ed3\u5408\u4ee3\u7801\u6587\u672c\u4e0e\u7ed3\u6784\u5316\u5efa\u6a21\u4f18\u52bf\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709Transformer\u6a21\u578b\u5728\u4ee3\u7801\u7ed3\u6784\u5316\u5206\u6790\uff08\u5982\u63a7\u5236\u6d41\u548c\u6570\u636e\u6d41\uff09\u4e0a\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u4ee3\u7801\u6587\u672c\u4e0e\u7ed3\u6784\u5316\u5efa\u6a21\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u65e8\u5728\u5f25\u8865\u73b0\u6709LLMs\u5728\u4ee3\u7801\u7ed3\u6784\u5316\u5206\u6790\u4e0a\u7684\u4e0d\u8db3\u3002"}}
{"id": "2507.11324", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.11324", "abs": "https://arxiv.org/abs/2507.11324", "authors": ["Frederik Marinus Trudslev", "Matteo Lissandrini", "Juan Manuel Rodriguez", "Martin B\u00f8gsted", "Daniele Dell'Aglio"], "title": "A Review of Privacy Metrics for Privacy-Preserving Synthetic Data Generation", "comment": null, "summary": "Privacy Preserving Synthetic Data Generation (PP-SDG) has emerged to produce\nsynthetic datasets from personal data while maintaining privacy and utility.\nDifferential privacy (DP) is the property of a PP-SDG mechanism that\nestablishes how protected individuals are when sharing their sensitive data. It\nis however difficult to interpret the privacy loss ($\\varepsilon$) expressed by\nDP. To make the actual risk associated with the privacy loss more transparent,\nmultiple privacy metrics (PMs) have been proposed to assess the privacy risk of\nthe data. These PMs are utilized in separate studies to assess newly introduced\nPP-SDG mechanisms. Consequently, these PMs embody the same assumptions as the\nPP-SDG mechanism they were made to assess. Therefore, a thorough definition of\nhow these are calculated is necessary. In this work, we present the assumptions\nand mathematical formulations of 17 distinct privacy metrics.", "AI": {"tldr": "PP-SDG\u673a\u5236\u901a\u8fc7\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u4fdd\u62a4\u4e2a\u4eba\u6570\u636e\u9690\u79c1\uff0c\u4f46\u9690\u79c1\u635f\u5931\uff08\u03b5\uff09\u96be\u4ee5\u89e3\u91ca\u3002\u672c\u6587\u63d0\u51fa17\u79cd\u9690\u79c1\u5ea6\u91cf\uff08PMs\uff09\u7684\u5047\u8bbe\u548c\u6570\u5b66\u516c\u5f0f\uff0c\u4ee5\u900f\u660e\u5316\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u89e3\u51b3\u5dee\u5206\u9690\u79c1\u4e2d\u9690\u79c1\u635f\u5931\uff08\u03b5\uff09\u96be\u4ee5\u89e3\u91ca\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u9690\u79c1\u5ea6\u91cf\uff08PMs\uff09\u900f\u660e\u5316\u5b9e\u9645\u9690\u79c1\u98ce\u9669\u3002", "method": "\u63d0\u51fa17\u79cd\u9690\u79c1\u5ea6\u91cf\u7684\u5047\u8bbe\u548c\u6570\u5b66\u516c\u5f0f\uff0c\u8be6\u7ec6\u5b9a\u4e49\u5176\u8ba1\u7b97\u65b9\u6cd5\u3002", "result": "\u660e\u786e\u4e8617\u79cd\u9690\u79c1\u5ea6\u91cf\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0c\u4e3aPP-SDG\u673a\u5236\u7684\u9690\u79c1\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u900f\u660e\u5316\u5de5\u5177\u3002", "conclusion": "\u901a\u8fc7\u5b9a\u4e49\u9690\u79c1\u5ea6\u91cf\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0c\u589e\u5f3a\u4e86PP-SDG\u673a\u5236\u9690\u79c1\u98ce\u9669\u7684\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.10993", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10993", "abs": "https://arxiv.org/abs/2507.10993", "authors": ["Emir Durakovic", "Min-Hong Shih"], "title": "Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction", "comment": "This paper uses a lightly modified version of the AAAI 2025 LaTeX\n  style for formatting consistency. It is not a submission to AAAI and does not\n  include any AAAI-specific headers, footers, or metadata", "summary": "Due to climate-induced changes, many habitats are experiencing range shifts\naway from their traditional geographic locations (Piguet, 2011). We propose a\nsolution to accurately model whether bird species are present in a specific\nhabitat through the combination of Convolutional Neural Networks (CNNs)\n(O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery\nand environmental features (e.g., temperature, precipitation, elevation) to\npredict bird presence across various climates. The CNN model captures spatial\ncharacteristics of landscapes such as forestation, water bodies, and\nurbanization, whereas the tabular method uses ecological and geographic data.\nBoth systems predict the distribution of birds with an average accuracy of 85%,\noffering a scalable but reliable method to understand bird migration.", "AI": {"tldr": "\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u548c\u8868\u683c\u6570\u636e\uff0c\u51c6\u786e\u9884\u6d4b\u9e1f\u7c7b\u5728\u7279\u5b9a\u6816\u606f\u5730\u7684\u5b58\u5728\u60c5\u51b5\u3002", "motivation": "\u7531\u4e8e\u6c14\u5019\u53d8\u5316\u5bfc\u81f4\u6816\u606f\u5730\u8303\u56f4\u53d8\u5316\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u8ffd\u8e2a\u9e1f\u7c7b\u5206\u5e03\u3002", "method": "\u5229\u7528\u536b\u661f\u56fe\u50cf\u548c\u73af\u5883\u7279\u5f81\uff08\u5982\u6e29\u5ea6\u3001\u964d\u6c34\u3001\u6d77\u62d4\uff09\uff0c\u7ed3\u5408CNN\u548c\u8868\u683c\u6570\u636e\u5efa\u6a21\u3002", "result": "\u6a21\u578b\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523085%\uff0c\u80fd\u6709\u6548\u9884\u6d4b\u9e1f\u7c7b\u5206\u5e03\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7406\u89e3\u9e1f\u7c7b\u8fc1\u5f99\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11499", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11499", "abs": "https://arxiv.org/abs/2507.11499", "authors": ["Adhwaa Alchaab", "Ayman Younis", "Dario Pompili"], "title": "Demo: Secure Edge Server for Network Slicing and Resource Allocation in Open RAN", "comment": null, "summary": "Next-Generation Radio Access Networks (NGRAN) aim to support diverse vertical\napplications with strict security, latency, and Service-Level Agreement (SLA)\nrequirements. These demands introduce challenges in securing the\ninfrastructure, allocating resources dynamically, and enabling real-time\nreconfiguration. This demo presents SnSRIC, a secure and intelligent network\nslicing framework that mitigates a range of Distributed Denial-of-Service\n(DDoS) attacks in Open RAN environments. SnSRIC incorporates an AI-driven xApp\nthat dynamically allocates Physical Resource Blocks (PRBs) to active users\nwhile enforcing slice-level security. The system detects anomalous behavior,\ndistinguishes between benign and malicious devices, and uses the E2 interface\nto throttle rogue signaling while maintaining service continuity for legitimate\nusers.", "AI": {"tldr": "SnSRIC\u662f\u4e00\u4e2a\u667a\u80fd\u7f51\u7edc\u5207\u7247\u6846\u67b6\uff0c\u7528\u4e8e\u5728Open RAN\u73af\u5883\u4e2d\u9632\u5fa1DDoS\u653b\u51fb\uff0c\u901a\u8fc7AI\u52a8\u6001\u5206\u914d\u8d44\u6e90\u5e76\u786e\u4fdd\u5b89\u5168\u3002", "motivation": "NGRAN\u9700\u8981\u6ee1\u8db3\u4e25\u683c\u7684\u5b89\u5168\u3001\u5ef6\u8fdf\u548cSLA\u8981\u6c42\uff0c\u4f46\u9762\u4e34\u57fa\u7840\u8bbe\u65bd\u5b89\u5168\u3001\u8d44\u6e90\u52a8\u6001\u5206\u914d\u548c\u5b9e\u65f6\u91cd\u914d\u7f6e\u7684\u6311\u6218\u3002", "method": "SnSRIC\u91c7\u7528AI\u9a71\u52a8\u7684xApp\u52a8\u6001\u5206\u914dPRB\uff0c\u68c0\u6d4b\u5f02\u5e38\u884c\u4e3a\uff0c\u533a\u5206\u6076\u610f\u8bbe\u5907\uff0c\u5e76\u901a\u8fc7E2\u63a5\u53e3\u9650\u5236\u6076\u610f\u4fe1\u53f7\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u9632\u5fa1DDoS\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u969c\u5408\u6cd5\u7528\u6237\u7684\u670d\u52a1\u8fde\u7eed\u6027\u3002", "conclusion": "SnSRIC\u4e3aNGRAN\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b89\u5168\u3001\u667a\u80fd\u7684\u7f51\u7edc\u5207\u7247\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11060", "abs": "https://arxiv.org/abs/2507.11060", "authors": ["Yilmazcan Ozyurt", "Tunaberk Almaci", "Stefan Feuerriegel", "Mrinmaya Sachan"], "title": "Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing", "comment": null, "summary": "We introduce ExRec, a general framework for personalized exercise\nrecommendation with semantically-grounded knowledge tracing. Our method builds\non the observation that existing exercise recommendation approaches simulate\nstudent performance via knowledge tracing (KT) but they often overlook two key\naspects: (a) the semantic content of questions and (b) the sequential,\nstructured progression of student learning. To address this, our ExRec presents\nan end-to-end pipeline, from annotating the KCs of questions and learning their\nsemantic representations to training KT models and optimizing several\nreinforcement learning (RL) methods. Moreover, we improve standard\nQ-learning-based continuous RL methods via a tailored model-based value\nestimation (MVE) approach that directly leverages the components of KT model in\nestimating cumulative knowledge improvement. We validate the effectiveness of\nour ExRec using various RL methods across four real-world tasks with different\neducational goals in online math learning. We further show that ExRec\ngeneralizes robustly to new, unseen questions and that it produces\ninterpretable student learning trajectories. Together, our findings highlight\nthe promise of KT-guided RL for effective personalization in education.", "AI": {"tldr": "ExRec\u662f\u4e00\u4e2a\u4e2a\u6027\u5316\u4e60\u9898\u63a8\u8350\u6846\u67b6\uff0c\u7ed3\u5408\u8bed\u4e49\u77e5\u8bc6\u8ffd\u8e2a\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u95ee\u9898\u8bed\u4e49\u548c\u5b66\u4e60\u5e8f\u5217\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u4e60\u9898\u63a8\u8350\u65b9\u6cd5\u901a\u5e38\u5ffd\u89c6\u95ee\u9898\u7684\u8bed\u4e49\u5185\u5bb9\u548c\u5b66\u4e60\u7684\u5e8f\u5217\u6027\uff0cExRec\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "ExRec\u901a\u8fc7\u7aef\u5230\u7aef\u6d41\u7a0b\uff0c\u4ece\u95ee\u9898\u6807\u6ce8\u5230\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u8bad\u7ec3\uff0c\u4f18\u5316\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u6a21\u578b\u57fa\u503c\u4f30\u8ba1\uff08MVE\uff09\u6539\u8fdbQ\u5b66\u4e60\u3002", "result": "\u5728\u56db\u4e2a\u5b9e\u9645\u6570\u5b66\u5b66\u4e60\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86ExRec\u7684\u6709\u6548\u6027\uff0c\u80fd\u6cdb\u5316\u5230\u65b0\u95ee\u9898\u5e76\u751f\u6210\u53ef\u89e3\u91ca\u7684\u5b66\u4e60\u8f68\u8ff9\u3002", "conclusion": "ExRec\u5c55\u793a\u4e86\u77e5\u8bc6\u8ffd\u8e2a\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u6559\u80b2\u4e2a\u6027\u5316\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.11500", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.11500", "abs": "https://arxiv.org/abs/2507.11500", "authors": ["Zhengyue Zhao", "Yingzi Ma", "Somesh Jha", "Marco Pavone", "Chaowei Xiao"], "title": "ARMOR: Aligning Secure and Safe Large Language Models via Meticulous Reasoning", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable generative\ncapabilities. However, their susceptibility to misuse has raised significant\nsafety concerns. While post-training safety alignment methods have been widely\nadopted, LLMs remain vulnerable to malicious instructions that can bypass\nsafety constraints. Recent efforts have introduced inference-time safety\nreasoning (system-2 alignment), where LLMs conduct a reasoning process to\nperform safety verification before final response. We show, however, that these\nchecks are driven by ad-hoc reasoning that diverges from the structured human\nprocess, where they first discern a user's true intent, then evaluate the\nassociated risk based on the true intent. Consequently, these defenses remain\nvulnerable to sophisticated jailbreak prompts that cloak harmful goals in\nseemingly benign language. To build secure and safe LLMs, we propose a\nreasoning-based safety alignment framework, ARMOR, that replaces the ad-hoc\nchains of thought reasoning process with human-aligned, structured one. At\ninference, ARMOR (1) detects likely jailbreak strategies, (2) extracts the\nuser's core intent while discarding deceptive instructions, and (3) applies a\npolicy-grounded safety analysis to the purified request. ARMOR is evaluated on\nadaptive jailbreak attacks and multiple safety benchmarks, and a test-time\nscaling is conducted to further improve its performance. Results demonstrate\nthat ARMOR significantly enhances the robustness against state-of-the-art\nadaptive jailbreak attacks and outperforms recent reasoning-based aligned\nmodels across various safety benchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faARMOR\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u589e\u5f3aLLMs\u7684\u5b89\u5168\u6027\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u6076\u610f\u6307\u4ee4\u7684\u9632\u5fa1\u80fd\u529b\u3002", "motivation": "\u73b0\u6709LLMs\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u6613\u88ab\u7ed5\u8fc7\uff0c\u9700\u8981\u66f4\u7ed3\u6784\u5316\u7684\u63a8\u7406\u8fc7\u7a0b\u6765\u8bc6\u522b\u7528\u6237\u771f\u5b9e\u610f\u56fe\u548c\u98ce\u9669\u3002", "method": "\u63d0\u51faARMOR\u6846\u67b6\uff0c\u5206\u4e09\u6b65\uff1a\u68c0\u6d4b\u8d8a\u72f1\u7b56\u7565\u3001\u63d0\u53d6\u6838\u5fc3\u610f\u56fe\u3001\u5e94\u7528\u5b89\u5168\u7b56\u7565\u5206\u6790\u3002", "result": "ARMOR\u5728\u81ea\u9002\u5e94\u8d8a\u72f1\u653b\u51fb\u548c\u591a\u4e2a\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ARMOR\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u6709\u6548\u63d0\u5347LLMs\u7684\u5b89\u5168\u6027\uff0c\u4e3a\u672a\u6765\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.11079", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11079", "abs": "https://arxiv.org/abs/2507.11079", "authors": ["Li Wang", "Qizhen Wu", "Lei Chen"], "title": "Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander", "comment": null, "summary": "In multiple unmanned ground vehicle confrontations, autonomously evolving\nmulti-agent tactical decisions from situational awareness remain a significant\nchallenge. Traditional handcraft rule-based methods become vulnerable in the\ncomplicated and transient battlefield environment, and current reinforcement\nlearning methods mainly focus on action manipulation instead of strategic\ndecisions due to lack of interpretability. Here, we propose a vision-language\nmodel-based commander to address the issue of intelligent\nperception-to-decision reasoning in autonomous confrontations. Our method\nintegrates a vision language model for scene understanding and a lightweight\nlarge language model for strategic reasoning, achieving unified perception and\ndecision within a shared semantic space, with strong adaptability and\ninterpretability. Unlike rule-based search and reinforcement learning methods,\nthe combination of the two modules establishes a full-chain process, reflecting\nthe cognitive process of human commanders. Simulation and ablation experiments\nvalidate that the proposed approach achieves a win rate of over 80% compared\nwith baseline models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u6307\u6325\u5b98\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u51b3\u65e0\u4eba\u5730\u9762\u8f66\u8f86\u5bf9\u6297\u4e2d\u7684\u667a\u80fd\u611f\u77e5\u5230\u51b3\u7b56\u63a8\u7406\u95ee\u9898\uff0c\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u624b\u5de5\u89c4\u5219\u65b9\u6cd5\u5728\u590d\u6742\u6218\u573a\u73af\u5883\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u800c\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u4e14\u4e3b\u8981\u5173\u6ce8\u52a8\u4f5c\u64cd\u4f5c\u800c\u975e\u6218\u7565\u51b3\u7b56\u3002", "method": "\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u573a\u666f\u7406\u89e3\u548c\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6218\u7565\u63a8\u7406\uff0c\u5b9e\u73b0\u611f\u77e5\u4e0e\u51b3\u7b56\u7684\u7edf\u4e00\u3002", "result": "\u4eff\u771f\u548c\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u57fa\u7ebf\u6a21\u578b\u5bf9\u6bd4\u4e2d\u80dc\u7387\u8d85\u8fc780%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u6307\u6325\u5b98\u7684\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u5168\u94fe\u6761\u611f\u77e5-\u51b3\u7b56\u63a8\u7406\u3002"}}
{"id": "2507.11117", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11117", "abs": "https://arxiv.org/abs/2507.11117", "authors": ["Ailiya Borjigin", "Cong He", "Charles CC Lee", "Wei Zhou"], "title": "AI Agent Architecture for Decentralized Trading of Alternative Assets", "comment": "8 Pages, 1 figure", "summary": "Decentralized trading of real-world alternative assets (e.g., gold) requires\nbridging physical asset custody with blockchain systems while meeting strict\nrequirements for compliance, liquidity, and risk management. We present\nGoldMine OS, a research oriented architecture that employs multiple specialized\nAI agents to automate and secure the tokenization and exchange of physical gold\ninto a blockchain based stablecoin (\"OZ\"). Our approach combines on chain smart\ncontracts for critical risk controls with off chain AI agents for decision\nmaking, blending the transparency and reliability of blockchains with the\nflexibility of AI driven automation. We describe four cooperative agents\n(Compliance, Token Issuance, Market Making, and Risk Control) and a\ncoordinating core, and evaluate the system through simulation and a controlled\npilot deployment. In experiments the prototype delivers on demand token\nissuance in under 1.2 s, more than 100 times faster than manual workflows. The\nMarket Making agent maintains tight liquidity with spreads often below 0.5\npercent even under volatile conditions. Fault injection tests show resilience:\nan oracle price spoofing attack is detected and mitigated within 10 s, and a\nsimulated vault mis reporting halts issuance immediately with minimal user\nimpact. The architecture scales to 5000 transactions per second with 10000\nconcurrent users in benchmarks. These results indicate that an AI agent based\ndecentralized exchange for alternative assets can satisfy rigorous performance\nand safety requirements. We discuss broader implications for democratizing\naccess to traditionally illiquid assets and explain how our governance model --\nmulti signature agent updates and on chain community voting on risk parameters\n-- provides ongoing transparency, adaptability, and formal assurance of system\nintegrity.", "AI": {"tldr": "GoldMine OS\u662f\u4e00\u4e2a\u7814\u7a76\u5bfc\u5411\u7684\u67b6\u6784\uff0c\u5229\u7528\u591a\u4e2a\u4e13\u7528AI\u4ee3\u7406\u81ea\u52a8\u5316\u5e76\u5b89\u5168\u5730\u5c06\u5b9e\u7269\u9ec4\u91d1\u4ee3\u5e01\u5316\u4e3a\u533a\u5757\u94fe\u7a33\u5b9a\u5e01\uff08OZ\uff09\uff0c\u7ed3\u5408\u94fe\u4e0a\u667a\u80fd\u5408\u7ea6\u548c\u94fe\u4e0bAI\u4ee3\u7406\uff0c\u6ee1\u8db3\u5408\u89c4\u6027\u3001\u6d41\u52a8\u6027\u548c\u98ce\u9669\u7ba1\u7406\u9700\u6c42\u3002", "motivation": "\u89e3\u51b3\u5b9e\u7269\u8d44\u4ea7\u4e0e\u533a\u5757\u94fe\u7cfb\u7edf\u4e4b\u95f4\u7684\u4ee3\u5e01\u5316\u4e0e\u4ea4\u6613\u95ee\u9898\uff0c\u540c\u65f6\u6ee1\u8db3\u4e25\u683c\u7684\u5408\u89c4\u6027\u3001\u6d41\u52a8\u6027\u548c\u98ce\u9669\u7ba1\u7406\u8981\u6c42\u3002", "method": "\u91c7\u7528\u94fe\u4e0a\u667a\u80fd\u5408\u7ea6\u8fdb\u884c\u5173\u952e\u98ce\u9669\u63a7\u5236\uff0c\u94fe\u4e0bAI\u4ee3\u7406\u8fdb\u884c\u51b3\u7b56\uff0c\u5305\u62ec\u56db\u4e2a\u534f\u4f5c\u4ee3\u7406\uff08\u5408\u89c4\u3001\u4ee3\u5e01\u53d1\u884c\u3001\u505a\u5e02\u3001\u98ce\u9669\u63a7\u5236\uff09\u548c\u4e00\u4e2a\u534f\u8c03\u6838\u5fc3\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u5b9e\u73b01.2\u79d2\u5185\u7684\u6309\u9700\u4ee3\u5e01\u53d1\u884c\uff0c\u505a\u5e02\u4ee3\u7406\u5728\u6ce2\u52a8\u6761\u4ef6\u4e0b\u4fdd\u63010.5%\u4ee5\u5185\u7684\u4ef7\u5dee\uff0c\u7cfb\u7edf\u5728\u6545\u969c\u6ce8\u5165\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u9ad8\u97e7\u6027\uff0c\u652f\u63015000 TPS\u548c10000\u5e76\u53d1\u7528\u6237\u3002", "conclusion": "\u57fa\u4e8eAI\u4ee3\u7406\u7684\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6613\u6240\u80fd\u591f\u6ee1\u8db3\u9ad8\u6027\u80fd\u548c\u5b89\u5168\u8981\u6c42\uff0c\u4e3a\u4f20\u7edf\u975e\u6d41\u52a8\u6027\u8d44\u4ea7\u63d0\u4f9b\u6c11\u4e3b\u5316\u8bbf\u95ee\uff0c\u5e76\u901a\u8fc7\u591a\u7b7e\u540d\u4ee3\u7406\u66f4\u65b0\u548c\u94fe\u4e0a\u793e\u533a\u6295\u7968\u786e\u4fdd\u7cfb\u7edf\u900f\u660e\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2507.11127", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11127", "abs": "https://arxiv.org/abs/2507.11127", "authors": ["Lennert De Smet", "Luc De Raedt"], "title": "Defining neurosymbolic AI", "comment": null, "summary": "Neurosymbolic AI focuses on integrating learning and reasoning, in\nparticular, on unifying logical and neural representations. Despite the\nexistence of an alphabet soup of neurosymbolic AI systems, the field is lacking\na generally accepted formal definition of what neurosymbolic models and\ninference really are. We introduce a formal definition for neurosymbolic AI\nthat makes abstraction of its key ingredients. More specifically, we define\nneurosymbolic inference as the computation of an integral over a product of a\nlogical and a belief function. We show that our neurosymbolic AI definition\nmakes abstraction of key representative neurosymbolic AI systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7AI\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u62bd\u8c61\u4e86\u5176\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u5c06\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u5b9a\u4e49\u4e3a\u903b\u8f91\u51fd\u6570\u548c\u4fe1\u5ff5\u51fd\u6570\u4e58\u79ef\u7684\u79ef\u5206\u8ba1\u7b97\u3002", "motivation": "\u795e\u7ecf\u7b26\u53f7AI\u9886\u57df\u7f3a\u4e4f\u666e\u904d\u63a5\u53d7\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u5bfc\u81f4\u96be\u4ee5\u7edf\u4e00\u7406\u89e3\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u548c\u63a8\u7406\u7684\u672c\u8d28\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u62bd\u8c61\u795e\u7ecf\u7b26\u53f7AI\u7684\u5173\u952e\u6210\u5206\uff0c\u5177\u4f53\u5b9a\u4e49\u4e3a\u903b\u8f91\u51fd\u6570\u4e0e\u4fe1\u5ff5\u51fd\u6570\u4e58\u79ef\u7684\u79ef\u5206\u3002", "result": "\u8be5\u5b9a\u4e49\u80fd\u591f\u62bd\u8c61\u4ee3\u8868\u795e\u7ecf\u7b26\u53f7AI\u7cfb\u7edf\u7684\u5173\u952e\u7279\u5f81\u3002", "conclusion": "\u63d0\u51fa\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\u6709\u52a9\u4e8e\u7edf\u4e00\u795e\u7ecf\u7b26\u53f7AI\u9886\u57df\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2507.11135", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11135", "abs": "https://arxiv.org/abs/2507.11135", "authors": ["Selma Saidi", "Omar Laimona", "Christoph Schmickler", "Dirk Ziegenbein"], "title": "Collaborative Trustworthiness for Good Decision Making in Autonomous Systems", "comment": null, "summary": "Autonomous systems are becoming an integral part of many application domains,\nlike in the mobility sector. However, ensuring their safe and correct behaviour\nin dynamic and complex environments remains a significant challenge, where\nsystems should autonomously make decisions e.g., about manoeuvring. We propose\nin this paper a general collaborative approach for increasing the level of\ntrustworthiness in the environment of operation and improve reliability and\ngood decision making in autonomous system. In the presence of conflicting\ninformation, aggregation becomes a major issue for trustworthy decision making\nbased on collaborative data sharing. Unlike classical approaches in the\nliterature that rely on consensus or majority as aggregation rule, we exploit\nthe fact that autonomous systems have different quality attributes like\nperception quality. We use this criteria to determine which autonomous systems\nare trustworthy and borrow concepts from social epistemology to define\naggregation and propagation rules, used for automated decision making. We use\nBinary Decision Diagrams (BDDs) as formal models for beliefs aggregation and\npropagation, and formulate reduction rules to reduce the size of the BDDs and\nallow efficient computation structures for collaborative automated reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u534f\u4f5c\u6570\u636e\u5171\u4eab\u7684\u81ea\u4e3b\u7cfb\u7edf\u53ef\u4fe1\u51b3\u7b56\u65b9\u6cd5\uff0c\u5229\u7528\u611f\u77e5\u8d28\u91cf\u7b49\u5c5e\u6027\u8bc4\u4f30\u7cfb\u7edf\u53ef\u4fe1\u5ea6\uff0c\u5e76\u91c7\u7528BDD\u8fdb\u884c\u9ad8\u6548\u4fe1\u5ff5\u805a\u5408\u4e0e\u4f20\u64ad\u3002", "motivation": "\u81ea\u4e3b\u7cfb\u7edf\u5728\u52a8\u6001\u590d\u6742\u73af\u5883\u4e2d\u786e\u4fdd\u5b89\u5168\u6b63\u786e\u884c\u4e3a\u5b58\u5728\u6311\u6218\uff0c\u9700\u63d0\u9ad8\u5176\u51b3\u7b56\u7684\u53ef\u4fe1\u5ea6\u548c\u53ef\u9760\u6027\u3002", "method": "\u5229\u7528\u611f\u77e5\u8d28\u91cf\u7b49\u5c5e\u6027\u8bc4\u4f30\u7cfb\u7edf\u53ef\u4fe1\u5ea6\uff0c\u7ed3\u5408\u793e\u4f1a\u8ba4\u8bc6\u8bba\u5b9a\u4e49\u805a\u5408\u4e0e\u4f20\u64ad\u89c4\u5219\uff0c\u4f7f\u7528BDD\u8fdb\u884c\u4fe1\u5ff5\u5efa\u6a21\u4e0e\u8ba1\u7b97\u4f18\u5316\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u53ef\u4fe1\u51b3\u7b56\u6846\u67b6\uff0c\u901a\u8fc7BDD\u4f18\u5316\u5b9e\u73b0\u534f\u4f5c\u81ea\u52a8\u63a8\u7406\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u81ea\u4e3b\u7cfb\u7edf\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u53ef\u4fe1\u51b3\u7b56\u80fd\u529b\uff0c\u4e3a\u534f\u4f5c\u6570\u636e\u5171\u4eab\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.11150", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.11150", "abs": "https://arxiv.org/abs/2507.11150", "authors": ["Alessandro Bertagnon", "Marcello Dalpasso", "Michele Favalli", "Marco Gavanelli"], "title": "Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming", "comment": "Accepted for publication in the issues of Theory and Practice of\n  Logic Programming (TPLP) dedicated to ICLP 2025, 16 pages, 9 figures", "summary": "In the design of integrated circuits, one critical metric is the maximum\ndelay introduced by combinational modules within the circuit. This delay is\ncrucial because it represents the time required to perform a computation: in an\nArithmetic-Logic Unit it represents the maximum time taken by the circuit to\nperform an arithmetic operation. When such a circuit is part of a larger,\nsynchronous system, like a CPU, the maximum delay directly impacts the maximum\nclock frequency of the entire system. Typically, hardware designers use Static\nTiming Analysis to compute an upper bound of the maximum delay because it can\nbe determined in polynomial time. However, relying on this upper bound can lead\nto suboptimal processor speeds, thereby missing performance opportunities. In\nthis work, we tackle the challenging task of computing the actual maximum\ndelay, rather than an approximate value. Since the problem is computationally\nhard, we model it in Answer Set Programming (ASP), a logic language featuring\nextremely efficient solvers. We propose non-trivial encodings of the problem\ninto ASP. Experimental results show that ASP is a viable solution to address\ncomplex problems in hardware design.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u8ba1\u7b97\u7ec4\u5408\u6a21\u5757\u5b9e\u9645\u6700\u5927\u5ef6\u8fdf\u7684\u65b9\u6cd5\uff0c\u4ee5\u66ff\u4ee3\u4f20\u7edf\u7684\u9759\u6001\u65f6\u5e8f\u5206\u6790\uff0c\u4ece\u800c\u63d0\u9ad8\u5904\u7406\u5668\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u65f6\u5e8f\u5206\u6790\u8ba1\u7b97\u7684\u662f\u5ef6\u8fdf\u7684\u4e0a\u754c\uff0c\u53ef\u80fd\u5bfc\u81f4\u5904\u7406\u5668\u6027\u80fd\u672a\u88ab\u5145\u5206\u5229\u7528\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\uff0c\u5e76\u63d0\u51fa\u975e\u5e73\u51e1\u7684\u7f16\u7801\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cASP\u80fd\u6709\u6548\u89e3\u51b3\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u590d\u6742\u95ee\u9898\u3002", "conclusion": "ASP\u662f\u89e3\u51b3\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u590d\u6742\u95ee\u9898\u7684\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.11229", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11229", "abs": "https://arxiv.org/abs/2507.11229", "authors": ["Jin Li", "Zezhong Ding", "Xike Xie"], "title": "DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion", "comment": null, "summary": "Knowledge graphs (KGs) are vital for enabling knowledge reasoning across\nvarious domains. Recent KG reasoning methods that integrate both global and\nlocal information have achieved promising results. However, existing methods\noften suffer from score over-smoothing, which blurs the distinction between\ncorrect and incorrect answers and hinders reasoning effectiveness. To address\nthis, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with\ndual-pathway global-local fusion. DuetGraph tackles over-smoothing by\nsegregating -- rather than stacking -- the processing of local (via message\npassing) and global (via attention) information into two distinct pathways,\npreventing mutual interference and preserving representational discrimination.\nIn addition, DuetGraph introduces a coarse-to-fine optimization, which\npartitions entities into high- and low-score subsets. This strategy narrows the\ncandidate space and sharpens the score gap between the two subsets, which\nalleviates over-smoothing and enhances inference quality. Extensive experiments\non various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA)\nperformance, with up to an 8.7% improvement in reasoning quality and a\n1.8$\\times$ acceleration in training efficiency.", "AI": {"tldr": "DuetGraph\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u8def\u5f84\u5168\u5c40-\u5c40\u90e8\u878d\u5408\u7684KG\u63a8\u7406\u673a\u5236\uff0c\u901a\u8fc7\u5206\u79bb\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\u5904\u7406\u8def\u5f84\u89e3\u51b3\u5206\u6570\u8fc7\u5e73\u6ed1\u95ee\u9898\uff0c\u5e76\u7ed3\u5408\u7c97\u5230\u7ec6\u4f18\u5316\u7b56\u7565\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709KG\u63a8\u7406\u65b9\u6cd5\u56e0\u5206\u6570\u8fc7\u5e73\u6ed1\u95ee\u9898\u5bfc\u81f4\u63a8\u7406\u6548\u679c\u4e0b\u964d\uff0c\u9700\u6539\u8fdb\u4ee5\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u7b54\u6848\u3002", "method": "DuetGraph\u91c7\u7528\u53cc\u8def\u5f84\u673a\u5236\u5206\u79bb\u5c40\u90e8\uff08\u6d88\u606f\u4f20\u9012\uff09\u548c\u5168\u5c40\uff08\u6ce8\u610f\u529b\uff09\u4fe1\u606f\u5904\u7406\uff0c\u5e76\u5f15\u5165\u7c97\u5230\u7ec6\u4f18\u5316\u7b56\u7565\u5212\u5206\u5b9e\u4f53\u5b50\u96c6\u3002", "result": "\u5b9e\u9a8c\u663e\u793aDuetGraph\u5728\u63a8\u7406\u8d28\u91cf\u548c\u8bad\u7ec3\u6548\u7387\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u63a8\u7406\u8d28\u91cf\u6700\u9ad8\u63d0\u53478.7%\uff0c\u8bad\u7ec3\u6548\u7387\u52a0\u901f1.8\u500d\u3002", "conclusion": "DuetGraph\u901a\u8fc7\u53cc\u8def\u5f84\u878d\u5408\u548c\u7c97\u5230\u7ec6\u4f18\u5316\u6709\u6548\u89e3\u51b3\u4e86\u5206\u6570\u8fc7\u5e73\u6ed1\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\u3002"}}
{"id": "2507.11277", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.11277", "abs": "https://arxiv.org/abs/2507.11277", "authors": ["Dany Moshkovich", "Sergey Zeltyn"], "title": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed within agentic\nsystems-collections of interacting, LLM-powered agents that execute complex,\nadaptive workflows using memory, tools, and dynamic planning. While enabling\npowerful new capabilities, these systems also introduce unique forms of\nuncertainty stemming from probabilistic reasoning, evolving memory states, and\nfluid execution paths. Traditional software observability and operations\npractices fall short in addressing these challenges.\n  This paper introduces AgentOps: a comprehensive framework for observing,\nanalyzing, optimizing, and automating operation of agentic AI systems. We\nidentify distinct needs across four key roles-developers, testers, site\nreliability engineers (SREs), and business users-each of whom engages with the\nsystem at different points in its lifecycle. We present the AgentOps Automation\nPipeline, a six-stage process encompassing behavior observation, metric\ncollection, issue detection, root cause analysis, optimized recommendations,\nand runtime automation. Throughout, we emphasize the critical role of\nautomation in managing uncertainty and enabling self-improving AI systems-not\nby eliminating uncertainty, but by taming it to ensure safe, adaptive, and\neffective operation.", "AI": {"tldr": "AgentOps\u6846\u67b6\u4e3a\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u5168\u9762\u7684\u64cd\u4f5c\u7ba1\u7406\uff0c\u6db5\u76d6\u89c2\u5bdf\u3001\u5206\u6790\u3001\u4f18\u5316\u548c\u81ea\u52a8\u5316\uff0c\u4ee5\u5e94\u5bf9\u5176\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u64cd\u4f5c\u5b9e\u8df5\u65e0\u6cd5\u6709\u6548\u7ba1\u7406LLM\u4ee3\u7406\u7cfb\u7edf\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u65b0\u65b9\u6cd5\u652f\u6301\u5f00\u53d1\u8005\u3001\u6d4b\u8bd5\u8005\u3001SRE\u548c\u4e1a\u52a1\u7528\u6237\u3002", "method": "\u63d0\u51faAgentOps\u81ea\u52a8\u5316\u7ba1\u9053\uff0c\u5305\u62ec\u884c\u4e3a\u89c2\u5bdf\u3001\u6307\u6807\u6536\u96c6\u3001\u95ee\u9898\u68c0\u6d4b\u3001\u6839\u56e0\u5206\u6790\u3001\u4f18\u5316\u5efa\u8bae\u548c\u8fd0\u884c\u65f6\u81ea\u52a8\u5316\u516d\u4e2a\u9636\u6bb5\u3002", "result": "\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u5316\u7ba1\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u652f\u6301\u4ee3\u7406\u7cfb\u7edf\u7684\u5b89\u5168\u3001\u81ea\u9002\u5e94\u548c\u9ad8\u6548\u8fd0\u884c\u3002", "conclusion": "AgentOps\u901a\u8fc7\u81ea\u52a8\u5316\u9a6f\u670d\u4e0d\u786e\u5b9a\u6027\uff0c\u63a8\u52a8\u81ea\u6539\u8fdbAI\u7cfb\u7edf\u7684\u5b89\u5168\u4e0e\u9002\u5e94\u6027\u3002"}}
{"id": "2507.11288", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11288", "abs": "https://arxiv.org/abs/2507.11288", "authors": ["Th\u00e9o Fagnoni", "Mahsun Altin", "Chia En Chung", "Phillip Kingston", "Alan Tuning", "Dana O. Mohamed", "In\u00e8s Adnani"], "title": "Opus: A Prompt Intention Framework for Complex Workflow Generation", "comment": "39 pages, 24 figures", "summary": "This paper introduces the Opus Prompt Intention Framework, designed to\nimprove complex Workflow Generation with instruction-tuned Large Language\nModels (LLMs). We propose an intermediate Intention Capture layer between user\nqueries and Workflow Generation, implementing the Opus Workflow Intention\nFramework, which consists of extracting Workflow Signals from user queries,\ninterpreting them into structured Workflow Intention objects, and generating\nWorkflows based on these Intentions. Our results show that this layer enables\nLLMs to produce logical and meaningful outputs that scale reliably as query\ncomplexity increases. On a synthetic benchmark of 1,000 multi-intent\nquery-Workflow(s) pairs, applying the Opus Prompt Intention Framework to\nWorkflow Generation yields consistent improvements in semantic Workflow\nsimilarity metrics. In this paper, we introduce the Opus Prompt Intention\nFramework by applying the concepts of Workflow Signal and Workflow Intention to\nLLM-driven Workflow Generation. We present a reproducible, customizable\nLLM-based Intention Capture system to extract Workflow Signals and Workflow\nIntentions from user queries. Finally, we provide empirical evidence that the\nproposed system significantly improves Workflow Generation quality compared to\ndirect generation from user queries, particularly in cases of Mixed Intention\nElicitation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Opus Prompt Intention Framework\uff0c\u901a\u8fc7\u5f15\u5165\u4e2d\u95f4\u5c42\uff08Intention Capture\uff09\u63d0\u5347\u57fa\u4e8eLLM\u7684\u590d\u6742\u5de5\u4f5c\u6d41\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u76f4\u63a5\u57fa\u4e8e\u7528\u6237\u67e5\u8be2\u751f\u6210\u5de5\u4f5c\u6d41\u65f6\u903b\u8f91\u6027\u548c\u6269\u5c55\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faOpus Workflow Intention Framework\uff0c\u5305\u62ec\u4ece\u7528\u6237\u67e5\u8be2\u4e2d\u63d0\u53d6Workflow Signals\u3001\u89e3\u6790\u4e3a\u7ed3\u6784\u5316Workflow Intention\u5bf9\u8c61\uff0c\u5e76\u57fa\u4e8e\u6b64\u751f\u6210\u5de5\u4f5c\u6d41\u3002", "result": "\u57281000\u4e2a\u591a\u610f\u56fe\u67e5\u8be2-\u5de5\u4f5c\u6d41\u5bf9\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6307\u6807\u663e\u8457\u63d0\u5347\u3002", "conclusion": "Opus\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u5de5\u4f5c\u6d41\u751f\u6210\u8d28\u91cf\uff0c\u5c24\u5176\u5728\u6df7\u5408\u610f\u56fe\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2507.11323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11323", "abs": "https://arxiv.org/abs/2507.11323", "authors": ["Xiang Yin", "Nico Potyka", "Antonio Rago", "Timotheus Kampik", "Francesca Toni"], "title": "Contestability in Quantitative Argumentation", "comment": null, "summary": "Contestable AI requires that AI-driven decisions align with human\npreferences. While various forms of argumentation have been shown to support\ncontestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks\n(EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs\ncan be deployed for this purpose. Specifically, we introduce the contestability\nproblem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences)\nto achieve a desired strength for a specific argument of interest (i.e., a\ntopic argument). To address this problem, we propose gradient-based relation\nattribution explanations (G-RAEs), which quantify the sensitivity of the topic\nargument's strength to changes in individual edge weights, thus providing\ninterpretable guidance for weight adjustments towards contestability. Building\non G-RAEs, we develop an iterative algorithm that progressively adjusts the\nedge weights to attain the desired strength. We evaluate our approach\nexperimentally on synthetic EW-QBAFs that simulate the structural\ncharacteristics of personalised recommender systems and multi-layer\nperceptrons, and demonstrate that it can solve the problem effectively.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u8fb9\u52a0\u6743\u5b9a\u91cf\u53cc\u6781\u8bba\u8bc1\u6846\u67b6\uff08EW-QBAFs\uff09\u5b9e\u73b0\u53ef\u4e89\u8baeAI\u51b3\u7b56\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\uff08G-RAEs\uff09\u6765\u8c03\u6574\u8fb9\u6743\u91cd\u4ee5\u8fbe\u5230\u76ee\u6807\u8bba\u8bc1\u5f3a\u5ea6\u3002", "motivation": "\u786e\u4fddAI\u9a71\u52a8\u7684\u51b3\u7b56\u7b26\u5408\u4eba\u7c7b\u504f\u597d\uff0c\u4f46\u76ee\u524dEW-QBAFs\u5728\u652f\u6301\u53ef\u4e89\u8bae\u6027\u65b9\u9762\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u63d0\u51faG-RAEs\u65b9\u6cd5\u91cf\u5316\u8fb9\u6743\u91cd\u5bf9\u76ee\u6807\u8bba\u8bc1\u5f3a\u5ea6\u7684\u5f71\u54cd\uff0c\u5e76\u5f00\u53d1\u8fed\u4ee3\u7b97\u6cd5\u8c03\u6574\u6743\u91cd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u63a8\u8350\u7cfb\u7edf\u548c\u591a\u5c42\u611f\u77e5\u5668\u7684\u5408\u6210EW-QBAFs\u4e2d\u6709\u6548\u3002", "conclusion": "G-RAEs\u548c\u8fed\u4ee3\u7b97\u6cd5\u4e3aEW-QBAFs\u7684\u53ef\u4e89\u8bae\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11334", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11334", "abs": "https://arxiv.org/abs/2507.11334", "authors": ["Yuehao Huang", "Liang Liu", "Shuangming Lei", "Yukai Ma", "Hao Su", "Jianbiao Mei", "Pengxiang Zhao", "Yaqing Gu", "Yong Liu", "Jiajun Lv"], "title": "CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking", "comment": "Accepted by ACM MM 2025", "summary": "Mobile robots are increasingly required to navigate and interact within\nunknown and unstructured environments to meet human demands. Demand-driven\nnavigation (DDN) enables robots to identify and locate objects based on\nimplicit human intent, even when object locations are unknown. However,\ntraditional data-driven DDN methods rely on pre-collected data for model\ntraining and decision-making, limiting their generalization capability in\nunseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that\nemulates the human cognitive and learning mechanisms by integrating fast and\nslow thinking systems and selectively identifying key objects essential to\nfulfilling user demands. CogDDN identifies appropriate target objects by\nsemantically aligning detected objects with the given instructions.\nFurthermore, it incorporates a dual-process decision-making module, comprising\na Heuristic Process for rapid, efficient decisions and an Analytic Process that\nanalyzes past errors, accumulates them in a knowledge base, and continuously\nimproves performance. Chain of Thought (CoT) reasoning strengthens the\ndecision-making process. Extensive closed-loop evaluations on the AI2Thor\nsimulator with the ProcThor dataset show that CogDDN outperforms single-view\ncamera-only methods by 15%, demonstrating significant improvements in\nnavigation accuracy and adaptability. The project page is available at\nhttps://yuehaohuang.github.io/CogDDN/.", "AI": {"tldr": "CogDDN\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u548c\u5b66\u4e60\u673a\u5236\uff0c\u63d0\u5347\u673a\u5668\u4eba\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u548c\u4ea4\u4e92\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u7684\u9700\u6c42\u5bfc\u822a\uff08DDN\uff09\u65b9\u6cd5\u4f9d\u8d56\u9884\u6536\u96c6\u6570\u636e\uff0c\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002CogDDN\u65e8\u5728\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u673a\u5236\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "CogDDN\u6574\u5408\u5feb\u901f\u548c\u6162\u901f\u601d\u7ef4\u7cfb\u7edf\uff0c\u8bed\u4e49\u5bf9\u9f50\u68c0\u6d4b\u5bf9\u8c61\u4e0e\u6307\u4ee4\uff0c\u5e76\u91c7\u7528\u53cc\u8fc7\u7a0b\u51b3\u7b56\u6a21\u5757\uff08\u542f\u53d1\u5f0f\u548c\u5206\u6790\u5f0f\uff09\u548c\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u63a8\u7406\u3002", "result": "\u5728AI2Thor\u6a21\u62df\u5668\u548cProcThor\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cCogDDN\u6bd4\u5355\u89c6\u89d2\u76f8\u673a\u65b9\u6cd5\u6027\u80fd\u63d0\u534715%\uff0c\u5bfc\u822a\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "CogDDN\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.11352", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2507.11352", "abs": "https://arxiv.org/abs/2507.11352", "authors": ["Yunhao Yang", "Neel P. Bhatt", "Christian Ellis", "Alvaro Velasquez", "Zhangyang Wang", "Ufuk Topcu"], "title": "Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces", "comment": null, "summary": "Logistics operators, from battlefield coordinators rerouting airlifts ahead\nof a storm to warehouse managers juggling late trucks, often face life-critical\ndecisions that demand both domain expertise and rapid and continuous\nreplanning. While popular methods like integer programming yield logistics\nplans that satisfy user-defined logical constraints, they are slow and assume\nan idealized mathematical model of the environment that does not account for\nuncertainty. On the other hand, large language models (LLMs) can handle\nuncertainty and promise to accelerate replanning while lowering the barrier to\nentry by translating free-form utterances into executable plans, yet they\nremain prone to misinterpretations and hallucinations that jeopardize safety\nand cost. We introduce a neurosymbolic framework that pairs the accessibility\nof natural-language dialogue with verifiable guarantees on goal interpretation.\nIt converts user requests into structured planning specifications, quantifies\nits own uncertainty at the field and token level, and invokes an interactive\nclarification loop whenever confidence falls below an adaptive threshold. A\nlightweight model, fine-tuned on just 100 uncertainty-filtered examples,\nsurpasses the zero-shot performance of GPT-4.1 while cutting inference latency\nby nearly 50%. These preliminary results highlight a practical path toward\ncertifiable, real-time, and user-aligned decision-making for complex logistics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd\u4e0e\u53ef\u9a8c\u8bc1\u4fdd\u8bc1\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7528\u4e8e\u590d\u6742\u7269\u6d41\u51b3\u7b56\uff0c\u63d0\u5347\u5b9e\u65f6\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u7269\u6d41\u51b3\u7b56\u9700\u8981\u5feb\u901f\u54cd\u5e94\u548c\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u6574\u6570\u89c4\u5212\uff09\u901f\u5ea6\u6162\u4e14\u5047\u8bbe\u7406\u60f3\u73af\u5883\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6613\u4ea7\u751f\u8bef\u89e3\u548c\u5e7b\u89c9\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u5c06\u7528\u6237\u8bf7\u6c42\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u89c4\u5212\u89c4\u8303\uff0c\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5728\u7f6e\u4fe1\u5ea6\u4e0d\u8db3\u65f6\u89e6\u53d1\u4ea4\u4e92\u5f0f\u6f84\u6e05\u5faa\u73af\u3002", "result": "\u8f7b\u91cf\u7ea7\u6a21\u578b\u5728100\u4e2a\u4e0d\u786e\u5b9a\u6027\u8fc7\u6ee4\u793a\u4f8b\u4e0a\u5fae\u8c03\u540e\uff0c\u6027\u80fd\u8d85\u8fc7GPT-4.1\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u8fd150%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u590d\u6742\u7269\u6d41\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9a8c\u8bc1\u3001\u5b9e\u65f6\u4e14\u7528\u6237\u5bf9\u9f50\u7684\u51b3\u7b56\u8def\u5f84\u3002"}}
{"id": "2507.11473", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.11473", "abs": "https://arxiv.org/abs/2507.11473", "authors": ["Tomek Korbak", "Mikita Balesni", "Elizabeth Barnes", "Yoshua Bengio", "Joe Benton", "Joseph Bloom", "Mark Chen", "Alan Cooney", "Allan Dafoe", "Anca Dragan", "Scott Emmons", "Owain Evans", "David Farhi", "Ryan Greenblatt", "Dan Hendrycks", "Marius Hobbhahn", "Evan Hubinger", "Geoffrey Irving", "Erik Jenner", "Daniel Kokotajlo", "Victoria Krakovna", "Shane Legg", "David Lindner", "David Luan", "Aleksander M\u0105dry", "Julian Michael", "Neel Nanda", "Dave Orr", "Jakub Pachocki", "Ethan Perez", "Mary Phuong", "Fabien Roger", "Joshua Saxe", "Buck Shlegeris", "Mart\u00edn Soto", "Eric Steinberger", "Jasmine Wang", "Wojciech Zaremba", "Bowen Baker", "Rohin Shah", "Vlad Mikulik"], "title": "Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety", "comment": null, "summary": "AI systems that \"think\" in human language offer a unique opportunity for AI\nsafety: we can monitor their chains of thought (CoT) for the intent to\nmisbehave. Like all other known AI oversight methods, CoT monitoring is\nimperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows\npromise and we recommend further research into CoT monitorability and\ninvestment in CoT monitoring alongside existing safety methods. Because CoT\nmonitorability may be fragile, we recommend that frontier model developers\nconsider the impact of development decisions on CoT monitorability.", "AI": {"tldr": "AI\u7cfb\u7edf\u901a\u8fc7\u4eba\u7c7b\u8bed\u8a00\u601d\u8003\uff0c\u4e3aAI\u5b89\u5168\u63d0\u4f9b\u4e86\u76d1\u63a7\u5176\u601d\u7ef4\u94fe\uff08CoT\uff09\u610f\u56fe\u7684\u673a\u4f1a\u3002\u5c3d\u7ba1CoT\u76d1\u63a7\u4e0d\u5b8c\u7f8e\uff0c\u4f46\u6709\u6f5c\u529b\uff0c\u5efa\u8bae\u8fdb\u4e00\u6b65\u7814\u7a76\u5e76\u6295\u8d44\u3002", "motivation": "\u63a2\u7d22AI\u7cfb\u7edf\u901a\u8fc7\u4eba\u7c7b\u8bed\u8a00\u601d\u8003\u7684\u7279\u6027\uff0c\u4ee5\u76d1\u63a7\u5176\u610f\u56fe\uff0c\u63d0\u5347AI\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51fa\u76d1\u63a7\u601d\u7ef4\u94fe\uff08CoT\uff09\u7684\u65b9\u6cd5\uff0c\u8bc4\u4f30\u5176\u53ef\u884c\u6027\u548c\u5c40\u9650\u6027\u3002", "result": "CoT\u76d1\u63a7\u867d\u4e0d\u5b8c\u7f8e\uff0c\u4f46\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u5efa\u8bae\u7ed3\u5408\u73b0\u6709\u5b89\u5168\u65b9\u6cd5\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "conclusion": "\u5efa\u8bae\u524d\u6cbf\u6a21\u578b\u5f00\u53d1\u8005\u8003\u8651\u5f00\u53d1\u51b3\u7b56\u5bf9CoT\u53ef\u76d1\u63a7\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u6295\u8d44\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2507.11479", "categories": ["cs.AI", "cs.GR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.11479", "abs": "https://arxiv.org/abs/2507.11479", "authors": ["Daniel Platnick", "Matti Gruener", "Marjan Alirezaie", "Kent Larson", "Dava J. Newman", "Hossein Rahnama"], "title": "Perspective-Aware AI in Extended Reality", "comment": "Accepted to the International Conference on eXtended Reality (2025),\n  12 pages, 3 figures", "summary": "AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive\nexperiences-yet current systems fall short due to shallow user modeling and\nlimited cognitive context. We introduce Perspective-Aware AI in Extended\nReality (PAiR), a foundational framework for integrating Perspective-Aware AI\n(PAi) with XR to enable interpretable, context-aware experiences grounded in\nuser identity. PAi is built on Chronicles: reasoning-ready identity models\nlearned from multimodal digital footprints that capture users' cognitive and\nexperiential evolution. PAiR employs these models in a closed-loop system\nlinking dynamic user states with immersive environments. We present PAiR's\narchitecture, detailing its modules and system flow, and demonstrate its\nutility through two proof-of-concept scenarios implemented in the Unity-based\nOpenDome engine. PAiR opens a new direction for human-AI interaction by\nembedding perspective-based identity models into immersive systems.", "AI": {"tldr": "PAiR\u6846\u67b6\u901a\u8fc7\u6574\u5408Perspective-Aware AI\u4e0eXR\uff0c\u5229\u7528\u7528\u6237\u7684\u591a\u6a21\u6001\u6570\u5b57\u8db3\u8ff9\u6784\u5efa\u8eab\u4efd\u6a21\u578b\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u3001\u60c5\u5883\u611f\u77e5\u7684\u6c89\u6d78\u5f0f\u4f53\u9a8c\u3002", "motivation": "\u5f53\u524dAI\u589e\u5f3a\u7684XR\u7cfb\u7edf\u56e0\u7528\u6237\u5efa\u6a21\u6d45\u8584\u548c\u8ba4\u77e5\u60c5\u5883\u6709\u9650\u800c\u8868\u73b0\u4e0d\u8db3\uff0cPAiR\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u57fa\u4e8eChronicles\uff08\u591a\u6a21\u6001\u6570\u5b57\u8db3\u8ff9\u6784\u5efa\u7684\u8eab\u4efd\u6a21\u578b\uff09\uff0cPAiR\u91c7\u7528\u95ed\u73af\u7cfb\u7edf\u52a8\u6001\u94fe\u63a5\u7528\u6237\u72b6\u6001\u4e0e\u6c89\u6d78\u5f0f\u73af\u5883\u3002", "result": "\u901a\u8fc7Unity\u5f15\u64ce\u4e2d\u7684\u4e24\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u573a\u666f\u5c55\u793a\u4e86PAiR\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "PAiR\u4e3a\u4eba\u7c7b-AI\u4ea4\u4e92\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u5c06\u57fa\u4e8e\u89c6\u89d2\u7684\u8eab\u4efd\u6a21\u578b\u5d4c\u5165\u6c89\u6d78\u5f0f\u7cfb\u7edf\u3002"}}
{"id": "2507.11482", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11482", "abs": "https://arxiv.org/abs/2507.11482", "authors": ["Mani Hamidi", "Terrence W. Deacon"], "title": "Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light", "comment": null, "summary": "Three core tenets of reinforcement learning (RL)--concerning the definition\nof agency, the objective of learning, and the scope of the reward\nhypothesis--have been highlighted as key targets for conceptual revision, with\nmajor implications for theory and application. We propose a framework, inspired\nby open-ended evolutionary theory, to reconsider these three \"dogmas.\" We\nrevisit each assumption and address related concerns raised alongside them. To\nmake our arguments relevant to RL as a model of biological learning, we first\nestablish that evolutionary dynamics can plausibly operate within living brains\nover an individual's lifetime, and are not confined to cross-generational\nprocesses. We begin by revisiting the second dogma, drawing on evolutionary\ninsights to enrich the \"adaptation-rather-than-search\" view of learning. We\nthen address the third dogma regarding the limits of the reward hypothesis,\nusing analogies from evolutionary fitness to illuminate the scalar reward vs.\nmulti-objective debate. After discussing practical implications for exploration\nin RL, we turn to the first--and arguably most fundamental--issue: the absence\nof a formal account of agency. We argue that unlike the other two problems, the\nevolutionary paradigm alone cannot resolve the agency question, though it\ngestures in a productive direction. We advocate integrating ideas from\norigins-of-life theory, where the thermodynamics of sustenance and replication\noffer promising foundations for understanding agency and resource-constrained\nreinforcement learning in biological systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5f00\u653e\u8fdb\u5316\u7406\u8bba\u7684\u6846\u67b6\uff0c\u91cd\u65b0\u5ba1\u89c6\u5f3a\u5316\u5b66\u4e60\u7684\u4e09\u4e2a\u6838\u5fc3\u5047\u8bbe\uff0c\u5e76\u63a2\u8ba8\u5176\u5bf9\u7406\u8bba\u548c\u5e94\u7528\u7684\u5f71\u54cd\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u7684\u4e09\u4e2a\u6838\u5fc3\u5047\u8bbe\uff08\u5173\u4e8e\u4ee3\u7406\u7684\u5b9a\u4e49\u3001\u5b66\u4e60\u76ee\u6807\u548c\u5956\u52b1\u5047\u8bbe\u7684\u8303\u56f4\uff09\u9700\u8981\u6982\u5ff5\u6027\u4fee\u8ba2\uff0c\u4ee5\u63a8\u52a8\u7406\u8bba\u548c\u5e94\u7528\u7684\u53d1\u5c55\u3002", "method": "\u501f\u9274\u5f00\u653e\u8fdb\u5316\u7406\u8bba\uff0c\u91cd\u65b0\u5ba1\u89c6\u8fd9\u4e09\u4e2a\u5047\u8bbe\uff0c\u5e76\u7ed3\u5408\u751f\u7269\u5b66\u5b66\u4e60\u7684\u80cc\u666f\uff0c\u63a2\u8ba8\u8fdb\u5316\u52a8\u529b\u5b66\u5728\u4e2a\u4f53\u751f\u547d\u5468\u671f\u5185\u7684\u4f5c\u7528\u3002", "result": "\u901a\u8fc7\u8fdb\u5316\u89c6\u89d2\u4e30\u5bcc\u4e86\u5b66\u4e60\u7684\u76ee\u6807\u548c\u5956\u52b1\u5047\u8bbe\u7684\u8ba8\u8bba\uff0c\u4f46\u4ee3\u7406\u95ee\u9898\u4ecd\u9700\u7ed3\u5408\u751f\u547d\u8d77\u6e90\u7406\u8bba\u6765\u89e3\u51b3\u3002", "conclusion": "\u8fdb\u5316\u7406\u8bba\u4e3a\u5f3a\u5316\u5b66\u4e60\u7684\u6838\u5fc3\u5047\u8bbe\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u4f46\u4ee3\u7406\u95ee\u9898\u9700\u8981\u8fdb\u4e00\u6b65\u7ed3\u5408\u751f\u547d\u8d77\u6e90\u7684\u70ed\u529b\u5b66\u7406\u8bba\u6765\u89e3\u51b3\u3002"}}
{"id": "2507.11527", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.11527", "abs": "https://arxiv.org/abs/2507.11527", "authors": ["Yinsheng Li", "Zhen Dong", "Yi Shao"], "title": "DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering", "comment": "Project page: https://github.com/Eason-Li-AIS/DrafterBench", "summary": "Large Language Model (LLM) agents have shown great potential for solving\nreal-world problems and promise to be a solution for tasks automation in\nindustry. However, more benchmarks are needed to systematically evaluate\nautomation agents from an industrial perspective, for example, in Civil\nEngineering. Therefore, we propose DrafterBench for the comprehensive\nevaluation of LLM agents in the context of technical drawing revision, a\nrepresentation task in civil engineering. DrafterBench contains twelve types of\ntasks summarized from real-world drawing files, with 46 customized\nfunctions/tools and 1920 tasks in total. DrafterBench is an open-source\nbenchmark to rigorously test AI agents' proficiency in interpreting intricate\nand long-context instructions, leveraging prior knowledge, and adapting to\ndynamic instruction quality via implicit policy awareness. The toolkit\ncomprehensively assesses distinct capabilities in structured data\ncomprehension, function execution, instruction following, and critical\nreasoning. DrafterBench offers detailed analysis of task accuracy and error\nstatistics, aiming to provide deeper insight into agent capabilities and\nidentify improvement targets for integrating LLMs in engineering applications.\nOur benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench,\nwith the test set hosted at\nhttps://huggingface.co/datasets/Eason666/DrafterBench.", "AI": {"tldr": "DrafterBench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u571f\u6728\u5de5\u7a0b\u56fe\u7eb8\u4fee\u8ba2\u4efb\u52a1\u4e2d\u7684\u5f00\u6e90\u57fa\u51c6\uff0c\u5305\u542b12\u7c7b\u4efb\u52a1\u300146\u4e2a\u5b9a\u5236\u529f\u80fd\u548c1920\u4e2a\u4efb\u52a1\uff0c\u65e8\u5728\u5168\u9762\u6d4b\u8bd5\u4ee3\u7406\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u4ece\u5de5\u4e1a\u89d2\u5ea6\uff08\u5982\u571f\u6728\u5de5\u7a0b\uff09\u7cfb\u7edf\u8bc4\u4f30\u81ea\u52a8\u5316\u4ee3\u7406\u7684\u57fa\u51c6\uff0cDrafterBench\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u603b\u7ed3\u771f\u5b9e\u56fe\u7eb8\u6587\u4ef6\u4e2d\u7684\u4efb\u52a1\uff0c\u8bbe\u8ba1\u5305\u542b\u591a\u79cd\u80fd\u529b\u7684\u6d4b\u8bd5\u96c6\uff0c\u5e76\u5f00\u53d1\u5de5\u5177\u5305\u8bc4\u4f30\u4ee3\u7406\u7684\u51c6\u786e\u6027\u3002", "result": "DrafterBench\u63d0\u4f9b\u4e86\u4efb\u52a1\u51c6\u786e\u6027\u548c\u9519\u8bef\u7edf\u8ba1\u7684\u8be6\u7ec6\u5206\u6790\uff0c\u63ed\u793a\u4e86\u4ee3\u7406\u7684\u80fd\u529b\u548c\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "DrafterBench\u4e3aLLM\u5728\u5de5\u7a0b\u5e94\u7528\u4e2d\u7684\u96c6\u6210\u63d0\u4f9b\u4e86\u6df1\u5165\u89c1\u89e3\uff0c\u5e76\u8bc6\u522b\u4e86\u6539\u8fdb\u76ee\u6807\u3002"}}
{"id": "2507.11538", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11538", "abs": "https://arxiv.org/abs/2507.11538", "authors": ["Daniel Jaroslawicz", "Brendan Whiting", "Parth Shah", "Karime Maamari"], "title": "How Many Instructions Can LLMs Follow at Once?", "comment": null, "summary": "Production-grade LLM systems require robust adherence to dozens or even\nhundreds of instructions simultaneously. However, the instruction-following\ncapabilities of LLMs at high instruction densities have not yet been\ncharacterized, as existing benchmarks only evaluate models on tasks with a\nsingle or few instructions. We introduce IFScale, a simple benchmark of 500\nkeyword-inclusion instructions for a business report writing task to measure\nhow instruction-following performance degrades as instruction density\nincreases. We evaluate 20 state-of-the-art models across seven major providers\nand find that even the best frontier models only achieve 68% accuracy at the\nmax density of 500 instructions. Our analysis reveals model size and reasoning\ncapability to correlate with 3 distinct performance degradation patterns, bias\ntowards earlier instructions, and distinct categories of instruction-following\nerrors. Our insights can help inform design of instruction-dense prompts in\nreal-world applications and highlight important performance-latency tradeoffs.\nWe open-source the benchmark and all results for further analysis at\nhttps://distylai.github.io/IFScale.", "AI": {"tldr": "IFScale\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u5728\u9ad8\u5bc6\u5ea6\u6307\u4ee4\u4e0b\u6027\u80fd\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u524d\u6cbf\u6a21\u578b\u5728500\u6761\u6307\u4ee4\u4e0b\u4ec568%\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u8bc4\u4f30\u5355\u4e00\u6216\u5c11\u91cf\u6307\u4ee4\u7684\u4efb\u52a1\uff0c\u65e0\u6cd5\u53cd\u6620\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u9ad8\u5bc6\u5ea6\u6307\u4ee4\u7684\u9700\u6c42\u3002", "method": "\u5f15\u5165IFScale\u57fa\u51c6\uff0c\u5305\u542b500\u6761\u5173\u952e\u8bcd\u5305\u542b\u6307\u4ee4\uff0c\u8bc4\u4f3020\u4e2a\u524d\u6cbf\u6a21\u578b\u5728\u9ad8\u5bc6\u5ea6\u6307\u4ee4\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u6700\u4f73\u6a21\u578b\u5728500\u6761\u6307\u4ee4\u4e0b\u51c6\u786e\u7387\u4ec5\u4e3a68%\uff0c\u6a21\u578b\u89c4\u6a21\u548c\u63a8\u7406\u80fd\u529b\u4e0e\u6027\u80fd\u4e0b\u964d\u6a21\u5f0f\u76f8\u5173\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u8bbe\u8ba1\u9ad8\u5bc6\u5ea6\u6307\u4ee4\u63d0\u793a\uff0c\u5e76\u63ed\u793a\u4e86\u6027\u80fd\u4e0e\u5ef6\u8fdf\u7684\u6743\u8861\uff0c\u6240\u6709\u6570\u636e\u548c\u7ed3\u679c\u5df2\u5f00\u6e90\u3002"}}
