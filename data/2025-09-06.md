<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 12]
- [cs.CR](#cs.CR) [Total: 16]
- [cs.AI](#cs.AI) [Total: 39]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Towards the Datasets Used in Requirements Engineering of Mobile Apps: Preliminary Findings from a Systematic Mapping Study](https://arxiv.org/abs/2509.03541)
*Chong Wang,Haoning Wu,Peng Liang,Maya Daneva,Marten van Sinderen*

Main category: cs.SE

TL;DR: 这篇论文通过系统映射研究分析了移动应用需求工程研究中数据集使用状况，发现Google Play和Apple App Store占据了超过90%的研究数据来源，并指出这可能导致知识偏差。


<details>
  <summary>Details</summary>
Motivation: 调查移动应用需求工程研究中数据集的使用状况和来源平台，了解当前研究基于哪些数据源进行哪些RE活动的研究。

Method: 采用Kitchenham等人的指南进行系统映射研究，基于43篇选定的论文进行分析。

Result: 发现Google Play和Apple App Store为90%以上的移动应用RE研究提供数据集；最常研究的RE活动是需求获取和需求分析。

Conclusion: 自2012年以来移动应用RE研究中数据集使用增长；Google Play和Apple App Store的过度使用可能导致知识偏差；需要扩大其他数据源和研究其他RE活动以获得更具普遍性的结果。

Abstract: [Background] Research on requirements engineering (RE) for mobile apps
employs datasets formed by app users, developers or vendors. However, little is
known about the sources of these datasets in terms of platforms and the RE
activities that were researched with the help of the respective datasets.
[Aims] The goal of this paper is to investigate the state-of-the-art of the
datasets of mobile apps used in existing RE research. [Method] We carried out a
systematic mapping study by following the guidelines of Kitchenham et al.
[Results] Based on 43 selected papers, we found that Google Play and Apple App
Store provide the datasets for more than 90% of published research in RE for
mobile apps. We also found that the most investigated RE activities - based on
datasets, are requirements elicitation and requirements analysis. [Conclusions]
Our most important conclusions are: (1) there is a growth in the use of
datasets for RE research of mobile apps since 2012, (2) the RE knowledge for
mobile apps might be skewed due to the overuse of Google Play and Apple App
Store, (3) there are attempts to supplement reviews of apps from repositories
with other data sources, (4) there is a need to expand the alternative sources
and experiments with complimentary use of multiple sources, if the community
wants more generalizable results. Plus, it is expected to expand the research
on other RE activities, beyond elicitation and analysis.

</details>


### [2] [A Multi-stage Error Diagnosis for APB Transaction](https://arxiv.org/abs/2509.03554)
*Cheng-Yang Tsai,Tzu-Wei Huang,Jen-Wei Shih,I-Hsiang Wang,Yu-Cheng Lin,Rung-Bin Lin*

Main category: cs.SE

TL;DR: 基于层次随机森林的自动化APB交易错误诊断框架，在ICCAD 2025竞赛中获得了91.36%的整体准确率


<details>
  <summary>Details</summary>
Motivation: 手动检测APB交易错误在大型VCD文件中效率低且容易出错，需要自动化解决方案来提高硬件设计验证效率

Method: 使用层次随机森林架构，通过4个预训练二元分类器按序检测超出范围访问、地址污染和数据污染错误，优先处理地址相关故障

Result: 整体准确率91.36%，地址错误的精度和召回率接近完美，数据错误表现稳健，在ICCAD 2025竞赛测试阶段获得第一名

Conclusion: 层次机器学习是EDA中硬件调试的强大自动化工具，具有异常检测的竞争力

Abstract: Functional verification and debugging are critical bottlenecks in modern
System-on-Chip (SoC) design, with manual detection of Advanced Peripheral Bus
(APB) transaction errors in large Value Change Dump (VCD) files being
inefficient and error-prone. Addressing the 2025 ICCAD Contest Problem D, this
study proposes an automated error diagnosis framework using a hierarchical
Random Forest-based architecture. The multi-stage error diagnosis employs four
pre-trained binary classifiers to sequentially detect Out-of-Range Access,
Address Corruption, and Data Corruption errors, prioritizing high-certainty
address-related faults before tackling complex data errors to enhance
efficiency. Experimental results show an overall accuracy of 91.36%, with
near-perfect precision and recall for address errors and robust performance for
data errors. Although the final results of the ICCAD 2025 CAD Contest are yet
to be announced as of the submission date, our team achieved first place in the
beta stage, highlighting the method's competitive strength. This research
validates the potential of hierarchical machine learning as a powerful
automated tool for hardware debugging in Electronic Design Automation (EDA).

</details>


### [3] [Parse Tree Tracking Through Time for Programming Process Analysis at Scale](https://arxiv.org/abs/2509.03668)
*Matt Rau,Chris Brown,John Edwards*

Main category: cs.SE

TL;DR: 这篇论文提出了首个自动跟踪解析树节点时间变化的算法，并利用它在CS1课程学生编程数据中进行了新的规模化行为分析。


<details>
  <summary>Details</summary>
Motivation: 传统的编程过程数据分析主要依赖高级描述统计，无法自动跟踪代码高级表示如解析树的时间变化，导致在上下文中分析学生行为非常繁琐。

Method: 设计了两种算法来跟踪解析树节点的时间变化，并为无法解析的代码状态构建树表示。应用这些算法到公开的键盘数据集进行分析。

Result: 发现了多个新的观测统计：条件语句和循环内外的代码删除率相似，三分之一的注释代码最终会恢复，以及学生在代码中跳转的频率可能不代表困难。

Conclusion: 跟踪解析树时间变化的能力为理解学生编程的新维度打开了大门，包括代码结构发展的最佳实践、语法构造困难度量化、重构行为和代码内注意力转移等。

Abstract: Background and Context: Programming process data can be utilized to
understand the processes students use to write computer programming
assignments. Keystroke- and line-level event logs have been used in the past in
various ways, primarily in high-level descriptive statistics (e.g., timings,
character deletion rate, etc). Analysis of behavior in context (e.g., how much
time students spend working on loops) has been cumbersome because of our
inability to automatically track high-level code representations, such as
abstract syntax trees, through time and unparseable states.
  Objective: Our study has two goals. The first is to design the first
algorithm that tracks parse tree nodes through time. Second, we utilize this
algorithm to perform a partial replication study of prior work that used manual
tracking of code representations, as well as other novel analyses of student
programming behavior that can now be done at scale.
  Method: We use two algorithms presented in this paper to track parse tree
nodes through time and construct tree representations for unparseable code
states. We apply these algorithms to a public keystroke data from student
coursework in a 2021 CS1 course and conduct analysis on the resulting parse
trees.
  Findings: We discover newly observable statistics at scale, including that
code is deleted at similar rates inside and outside of conditionals and loops,
a third of commented out code is eventually restored, and that frequency with
which students jump around in their code may not be indicative of struggle.
  Implications: The ability to track parse trees through time opens the door to
understanding new dimensions of student programming, such as best practices of
structural development of code over time, quantitative measurement of what
syntactic constructs students struggle most with, refactoring behavior, and
attention shifting within the code.

</details>


### [4] [Towards an Understanding of Developer Experience-Driven Transparency in Software Ecosystems](https://arxiv.org/abs/2509.03848)
*Rodrigo Oliveira Zacarias,Rodrigo Pereira dos Santos,Patricia Lago*

Main category: cs.SE

TL;DR: 这篇论文提出了SECO-TransDX概念模型，从开发者体验角度系统性概念化了软件生态系统中的透明性问题，识别了63个相互关联概念并通过Delphi研究精炼模型。


<details>
  <summary>Details</summary>
Motivation: 软件生态系统中透明性对于开发者体验和可持续发展至关重要，但现有研究缺乏系统性的概念化。论文旨在从开发者中心视角提升对透明性的理解。

Method: 基于先前研究，通过Delphi研究方法与学术界和业界专家合作，构建和精炼SECO-TransDX概念模型，识别了63个相互关联的概念。

Result: 建立了SECO-TransDX概念模型，提出了DX驱动的透明性概念，涵盖条件因素、生态系统程序、产物和关系动态等多个层面，为研究者和实践者提供结构化的分析视角。

Conclusion: SECO-TransDX模型为软件生态系统中的透明性研究奠定了理论基础，有助于设计更可信赖、以开发者为中心的平台，提高透明性并促进生态系统的长期参与。

Abstract: Software ecosystems (SECO) have become a dominant paradigm in the software
industry, enabling third-party developers to co-create value through
complementary components and services. While Developer Experience (DX) is
increasingly recognized as critical for sustainable SECO, transparency remains
an underexplored factor shaping how developers perceive and interact with
ecosystems. Existing studies acknowledge transparency as essential for trust,
fairness, and engagement, yet its relationship with DX has not been
systematically conceptualized. Hence, this work aims to advance the
understanding of transparency in SECO from a developer-centered perspective. To
this end, we propose SECO-TransDX (Transparency in Software Ecosystems from a
Developer Experience Perspective), a conceptual model that introduces the
notion of DX-driven transparency. The model identifies 63 interrelated
concepts, including conditioning factors, ecosystem procedures, artifacts, and
relational dynamics that influence how transparency is perceived and
constructed during developer interactions. SECO-TransDX was built upon prior
research and refined through a Delphi study with experts from academia and
industry. It offers a structured lens to examine how transparency mediates DX
across technical, social, and organizational layers. For researchers, it lays
the groundwork for future studies and tool development; for practitioners, it
supports the design of trustworthy, developer-centered platforms that improve
transparency and foster long-term engagement in SECO.

</details>


### [5] [VulRTex: A Reasoning-Guided Approach to Identify Vulnerabilities from Rich-Text Issue Report](https://arxiv.org/abs/2509.03875)
*Ziyou Jiang,Mingyang Li,Guowei Yang,Lin Shi,Qing Wang*

Main category: cs.SE

TL;DR: VulRTex是一个基于大语言模型推理能力的漏洞相关issue报告识别方法，通过构建漏洞推理数据库和检索相关案例来指导LLM分析目标IR的富文本信息，在数据不平衡情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 开源软件中存在漏洞，开发者提交的issue报告需要安全从业者手动识别漏洞相关IR，耗时且存在时间差可能被攻击者利用。现有方法主要关注文本描述，缺乏对IR富文本信息的综合分析。

Method: VulRTex首先利用LLM的推理能力构建漏洞推理数据库，然后检索相关案例生成推理指导，引导LLM对目标IR的富文本信息进行推理分析来识别漏洞。

Result: 在973,572个IR上的实验显示，VulRTex在识别漏洞相关IR和预测CWE-ID方面表现最佳，比最佳基线F1提高11.0%，AUPRC提高20.2%，Macro-F1提高10.5%，时间成本降低2倍。成功识别2024年GitHub IR中10个代表性OSS项目的30个新兴漏洞，其中11个获得CVE-ID。

Conclusion: VulRTex通过利用LLM的推理能力和富文本信息分析，有效解决了漏洞相关IR识别问题，具有实际应用价值。

Abstract: Software vulnerabilities exist in open-source software (OSS), and the
developers who discover these vulnerabilities may submit issue reports (IRs) to
describe their details. Security practitioners need to spend a lot of time
manually identifying vulnerability-related IRs from the community, and the time
gap may be exploited by attackers to harm the system. Previously, researchers
have proposed automatic approaches to facilitate identifying these
vulnerability-related IRs, but these works focus on textual descriptions but
lack the comprehensive analysis of IR's rich-text information. In this paper,
we propose VulRTex, a reasoning-guided approach to identify
vulnerability-related IRs with their rich-text information. In particular,
VulRTex first utilizes the reasoning ability of the Large Language Model (LLM)
to prepare the Vulnerability Reasoning Database with historical IRs. Then, it
retrieves the relevant cases from the prepared reasoning database to generate
reasoning guidance, which guides LLM to identify vulnerabilities by reasoning
analysis on target IRs' rich-text information. To evaluate the performance of
VulRTex, we conduct experiments on 973,572 IRs, and the results show that
VulRTex achieves the highest performance in identifying the
vulnerability-related IRs and predicting CWE-IDs when the dataset is
imbalanced, outperforming the best baseline with +11.0% F1, +20.2% AUPRC, and
+10.5% Macro-F1, and 2x lower time cost than baseline reasoning approaches.
Furthermore, VulRTex has been applied to identify 30 emerging vulnerabilities
across 10 representative OSS projects in 2024's GitHub IRs, and 11 of them are
successfully assigned CVE-IDs, which illustrates VulRTex's practicality.

</details>


### [6] [Vulnerability-Affected Versions Identification: How Far Are We?](https://arxiv.org/abs/2509.03876)
*Xingchu Chen,Chengwei Liu,Jialun Cao,Yang Xiao,Xinyue Cai,Yeting Li,Jingyi Shi,Tianqi Sun,Haiming Chen ang Wei Huo*

Main category: cs.SE

TL;DR: 首个全面的漏洞影响版本识别实证研究，评估12种代表性工具在1,128个真实漏洞上的表现，发现现有工具准确率不超过45%，集成策略最多提升10.1%，但仍低于60%


<details>
  <summary>Details</summary>
Motivation: 尽管已有多种工具用于识别受漏洞影响的软件版本，但由于评估范围狭窄、技术过时、数据集小且粒度粗，这些工具在真实环境中的有效性仍不明确

Method: 构建包含1,128个真实C/C++漏洞的高质量基准，从追踪和匹配两种范式系统评估12种代表性工具，涵盖漏洞和版本级别的有效性、误报误诊根因、对补丁特性的敏感性以及集成潜力四个维度

Result: 发现根本性局限：没有工具准确率超过45.0%，主要挑战来自启发式依赖、有限语义推理和僵化匹配逻辑。仅添加和跨文件更改等补丁结构进一步降低性能。集成策略最多可提升10.1%但总体准确率仍低于60.0%

Conclusion: 现有方法存在根本性局限，需要全新的技术途径。研究为工具开发、组合策略和未来研究提供了可操作的见解，并发布了复现代码和基准以鼓励未来贡献

Abstract: Identifying which software versions are affected by a vulnerability is
critical for patching, risk mitigation.Despite a growing body of tools, their
real-world effectiveness remains unclear due to narrow evaluation scopes often
limited to early SZZ variants, outdated techniques, and small or
coarse-graineddatasets. In this paper, we present the first comprehensive
empirical study of vulnerability affected versions identification. We curate a
high quality benchmark of 1,128 real-world C/C++ vulnerabilities and
systematically evaluate 12 representative tools from both tracing and matching
paradigms across four dimensions: effectiveness at both vulnerability and
version levels, root causes of false positives and negatives, sensitivity to
patch characteristics, and ensemble potential. Our findings reveal fundamental
limitations: no tool exceeds 45.0% accuracy, with key challenges stemming from
heuristic dependence, limited semantic reasoning, and rigid matching logic.
Patch structures such as add-only and cross-file changes further hinder
performance. Although ensemble strategies can improve results by up to 10.1%,
overall accuracy remains below 60.0%, highlighting the need for fundamentally
new approaches. Moreover, our study offers actionable insights to guide tool
development, combination strategies, and future research in this critical area.
Finally, we release the replicated code and benchmark on our website to
encourage future contributions.outdated techniques, and small or coarse grained
datasets.

</details>


### [7] [Analyzing Variations in Dependency Distributions Due to Code Smell Interactions](https://arxiv.org/abs/2509.03896)
*Zushuai Zhang,Elliott Wen,Ewan Tempero*

Main category: cs.SE

TL;DR: 代码异味之间的相互作用会显著增加模块间的依赖关系，导致维护复杂性和成本增加


<details>
  <summary>Details</summary>
Motivation: 理解代码异味如何影响模块间依赖关系，以减少维护成本和复杂性

Method: 对116个开源Java系统进行依赖分析，比较代码异味之间以及代码异味与非异味代码的相互作用

Result: 代码异味对之间相互作用会增加总依赖关系数量，例如Feature Envy方法与Data Classes相互作用时依赖关系数量增加了7倍

Conclusion: 开发者应优先处理相互作用的代码异味，而非单独存在的异味

Abstract: The existence of dependencies between modules, such as classes, can mean that
changing a module triggers ripple effects that make maintenance complex and
costly, so the advice is to minimize dependencies between modules. It is
therefore important to understand the circumstances that can lead to increased
dependencies. Recent studies suggest that code smells, which are
characteristics of code that indicate potential design issues, may interact in
ways that increase dependencies between modules. In this study, we aim to
confirm previous observations and investigate whether and how the distribution
of static dependencies changes in the presence of code smell interactions. We
conducted a dependency analysis on 116 open-source Java systems to quantify the
interactions, comparing interactions among code smells and interactions between
code smells and non-code smells. Our results suggest that while interactions
between code smell pairs are associated with increases in certain dependencies
and decreases in others, overall, they are associated with an increase in total
dependencies. For example, the median number of dependencies between Feature
Envy methods and Data Classes is seven times as many as when the methods are
non-Feature Envy methods, increasing from 1 to 7. This implies that developers
should prioritize addressing code smells that interact with each other, rather
than code smells that exist only in isolation.

</details>


### [8] [The Auth Shim: A Lightweight Architectural Pattern for Integrating Enterprise SSO with Standalone Open-Source Applications](https://arxiv.org/abs/2509.03900)
*Yuvraj Agrawal*

Main category: cs.SE

TL;DR: 本文提出Auth Shim架构模式，通过外部代理服务解决开源软件缺乏企业级身份验证协议支持的问题，实现OSS工具与企业SSO生态系统的安全集成。


<details>
  <summary>Details</summary>
Motivation: 企业广泛采用开源软件，但许多OSS工具缺乏对SAML、OIDC等企业级身份验证协议的原生支持，导致安全集成缺口，阻碍了开源创新在企业环境中的应用。

Method: Auth Shim是一种轻量级架构模式，作为外部代理服务，在企业IdP和目标应用之间充当兼容层，将IdP请求转换为目标应用的原生会话管理机制。目标应用需要提供安全的程序化管理API。

Result: 通过在Adobe的案例研究中实施该模式，成功将流行的OSS BI工具与Okta SAML集成，实现了基于IAM组映射的自动化RBAC，消除了手动用户配置。

Conclusion: Auth Shim提供了一个可重用、安全且成本效益高的蓝图，使企业能够在保持安全治理的同时集成任何独立的OSS工具到企业SSO生态系统中。

Abstract: Open-source software OSS is widely adopted in enterprise settings, but
standalone tools often lack native support for protocols like SAML or OIDC,
creating a critical security integration gap. This paper introduces and
formalizes the Auth Shim, a lightweight architectural pattern designed to solve
this problem. The Auth Shim is a minimal, external proxy service that acts as a
compatibility layer, translating requests from an enterprise Identity Provider
IdP into the native session management mechanism of a target application. A key
prerequisite for this pattern is that the target application must expose a
programmatic, secure administrative API. We present a case study of the
pattern's implementation at Adobe to integrate a popular OSS BI tool with Okta
SAML, which enabled automated Role-Based Access Control RBAC via IAM group
mapping and eliminated manual user provisioning. By defining its components,
interactions, and production deployment considerations, this paper provides a
reusable, secure, and cost-effective blueprint for integrating any standalone
OSS tool into an enterprise SSO ecosystem, thereby enabling organizations to
embrace open-source innovation without compromising on security governance.

</details>


### [9] [RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models](https://arxiv.org/abs/2509.04078)
*Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang*

Main category: cs.SE

TL;DR: RepoDebug是一个多任务、多语言的仓库级代码调试数据集，包含22种错误子类型、8种编程语言和3种调试任务，用于评估LLM在复杂仓库级场景下的调试能力。


<details>
  <summary>Details</summary>
Motivation: 现有调试数据集主要关注函数级代码修复，忽略了更复杂和现实的仓库级场景，导致对LLM在仓库级调试中面临的挑战理解不完整。

Method: 构建RepoDebug数据集，包含22种错误子类型、支持8种编程语言和3种调试任务，并在10个LLM上进行评估实验。

Result: 实验表明，即使是表现最好的Claude 3.5 Sonnet模型在仓库级调试任务上仍表现不佳。

Conclusion: 仓库级代码调试对LLM来说仍然是一个具有挑战性的任务，需要更先进的数据集和方法来提升其性能。

Abstract: Large Language Models (LLMs) have exhibited significant proficiency in code
debugging, especially in automatic program repair, which may substantially
reduce the time consumption of developers and enhance their efficiency.
Significant advancements in debugging datasets have been made to promote the
development of code debugging. However, these datasets primarily focus on
assessing the LLM's function-level code repair capabilities, neglecting the
more complex and realistic repository-level scenarios, which leads to an
incomplete understanding of the LLM's challenges in repository-level debugging.
While several repository-level datasets have been proposed, they often suffer
from limitations such as limited diversity of tasks, languages, and error
types. To mitigate this challenge, this paper introduces RepoDebug, a
multi-task and multi-language repository-level code debugging dataset with 22
subtypes of errors that supports 8 commonly used programming languages and 3
debugging tasks. Furthermore, we conduct evaluation experiments on 10 LLMs,
where Claude 3.5 Sonnect, the best-performing model, still cannot perform well
in repository-level debugging.

</details>


### [10] [An Empirical Study of Vulnerabilities in Python Packages and Their Detection](https://arxiv.org/abs/2509.04260)
*Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du*

Main category: cs.SE

TL;DR: PyVul是首个全面的Python包漏洞基准测试套件，包含1,157个公开报告的漏洞，提供提交和函数级注释，评估显示现有检测工具能力与实际需求存在显著差距。


<details>
  <summary>Details</summary>
Motivation: Python包作为组织、重用和分发单元存在大量漏洞报告，且Python常与其他语言协作增加了漏洞复杂性，当前漏洞检测工具的有效性尚未充分探索。

Method: 引入PyVul基准套件，采用LLM辅助的数据清洗方法提高标签准确性，进行分布分析并评估最先进的检测工具。

Result: PyVul实现了100%提交级和94%函数级准确性，是多语言Python包漏洞的最精确大规模基准；分析发现多语言Python包更容易受到漏洞影响；现有检测工具存在显著能力差距。

Conclusion: PyVul为Python包漏洞检测提供了高质量基准，揭示了当前工具的局限性，强调了该领域未来发展的必要性。

Abstract: In the rapidly evolving software development landscape, Python stands out for
its simplicity, versatility, and extensive ecosystem. Python packages, as units
of organization, reusability, and distribution, have become a pressing concern,
highlighted by the considerable number of vulnerability reports. As a scripting
language, Python often cooperates with other languages for performance or
interoperability. This adds complexity to the vulnerabilities inherent to
Python packages, and the effectiveness of current vulnerability detection tools
remains underexplored. This paper addresses these gaps by introducing PyVul,
the first comprehensive benchmark suite of Python-package vulnerabilities.
PyVul includes 1,157 publicly reported, developer-verified vulnerabilities,
each linked to its affected packages. To accommodate diverse detection
techniques, it provides annotations at both commit and function levels. An
LLM-assisted data cleansing method is incorporated to improve label accuracy,
achieving 100% commit-level and 94% function-level accuracy, establishing PyVul
as the most precise large-scale Python vulnerability benchmark. We further
carry out a distribution analysis of PyVul, which demonstrates that
vulnerabilities in Python packages involve multiple programming languages and
exhibit a wide variety of types. Moreover, our analysis reveals that
multi-lingual Python packages are potentially more susceptible to
vulnerabilities. Evaluation of state-of-the-art detectors using this benchmark
reveals a significant discrepancy between the capabilities of existing tools
and the demands of effectively identifying real-world security issues in Python
packages. Additionally, we conduct an empirical review of the top-ranked CWEs
observed in Python packages, to diagnose the fine-grained limitations of
current detection tools and highlight the necessity for future advancements in
the field.

</details>


### [11] [FaaSGuard: Secure CI/CD for Serverless Applications -- An OpenFaaS Case Study](https://arxiv.org/abs/2509.04328)
*Amine Barrak,Emna Ksontini,Ridouane Atike,Fehmi Jaafar*

Main category: cs.SE

TL;DR: FaaSGuard是一个针对开源无服务器环境的统一DevSecOps管道，通过在开发生命周期的各个阶段嵌入轻量级安全检查，有效检测和防止关键漏洞。


<details>
  <summary>Details</summary>
Motivation: 无服务器计算虽然简化了基础设施管理，但其短暂执行和细粒度扩展等特性带来了独特的安全挑战，特别是在OpenFaaS等开源平台中。现有方法通常只解决DevSecOps生命周期的孤立阶段，缺乏集成的全面安全策略。

Method: 提出FaaSGuard统一DevSecOps管道，在开发生命周期的每个阶段（规划、编码、构建、部署和监控）系统性地嵌入轻量级、故障关闭的安全检查，针对注入攻击、硬编码密钥和资源耗尽等威胁。

Result: 通过对20个真实世界无服务器函数的案例研究验证，FaaSGuard有效检测和防止关键漏洞，表现出高精度（95%）和高召回率（91%），且不会显著干扰现有的CI/CD实践。

Conclusion: FaaSGuard为开源无服务器环境提供了一个有效的集成安全解决方案，能够在不影响开发流程的情况下显著提升安全性。

Abstract: Serverless computing significantly alters software development by abstracting
infrastructure management and enabling rapid, modular, event-driven
deployments. Despite its benefits, the distinct characteristics of serverless
functions, such as ephemeral execution and fine-grained scalability, pose
unique security challenges, particularly in open-source platforms like
OpenFaaS. Existing approaches typically address isolated phases of the
DevSecOps lifecycle, lacking an integrated and comprehensive security strategy.
To bridge this gap, we propose FaaSGuard, a unified DevSecOps pipeline
explicitly designed for open-source serverless environments. FaaSGuard
systematically embeds lightweight, fail-closed security checks into every stage
of the development lifecycle-planning, coding, building, deployment, and
monitoring-effectively addressing threats such as injection attacks, hard-coded
secrets, and resource exhaustion. We validate our approach empirically through
a case study involving 20 real-world serverless functions from public GitHub
repositories. Results indicate that FaaSGuard effectively detects and prevents
critical vulnerabilities, demonstrating high precision (95%) and recall (91%)
without significant disruption to established CI/CD practices.

</details>


### [12] [Design and Development of a Web Platform for Blood Donation Management](https://arxiv.org/abs/2509.04423)
*Fatima Zulfiqar Ali,Atrooba Ilyas*

Main category: cs.SE

TL;DR: 基于现代web技术的血液捐献网络平台，通过数据库设计和系统架构，实现捐血者注册、血液需求搜索和紧急沟通功能


<details>
  <summary>Details</summary>
Motivation: 解决紧急情况下找到合适捐血者的挑战，缩短血液获取时间，提高血液捐献服务效率

Method: 使用用例图、数据库图、类图和序列图进行系统设计，采用PHP(Laravel框架)、HTML、CSS、Bootstrap和MySQL等现代web技术实现

Result: 开发出一个动态、交互式、用户友好的平台，可以实现捐血者注册、按血型和位置搜索捐血者、提供附近可捐血者列表

Conclusion: 该平台有效减少紧急情况下的延误和复杂性，提高血液及时可用性，改善血液捐献服务的整体效率

Abstract: Blood donation is a critical component of healthcare, yet locating suitable
donors in emergencies often presents significant challenges. This paper
presents the design and development of a Blood Donation Web Platform, a
web-based system that connects patients, donors, and administrators within a
centralized digital space. The platform allows interested donors to register
their personal information, including blood group, contact details, and
availability. Patients can search for donors based on blood group and location,
and the system provides a list of nearby donors who are ready to donate. The
platform design was guided by use case, database, class, and sequence diagrams
to ensure a well-structured and efficient system architecture. Modern web
technologies, including PHP (Laravel framework), HTML, CSS, Bootstrap, and
MySQL, supported by XAMPP and Visual Studio Code, were employed to implement a
dynamic, interactive, and user-friendly platform. By streamlining donor
refgistration, blood requests, and communication, the proposed system reduces
delays and complexities in emergencies, improving timely accessibility of blood
and enhancing overall efficiency in blood donation services.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [13] [Reactive Bottom-Up Testing](https://arxiv.org/abs/2509.03711)
*Siddharth Muralee,Sourag Cherupattamoolayil,James C. Davis,Antonio Bianchi,Aravind Machiry*

Main category: cs.CR

TL;DR: 提出Reactive Bottom-Up Testing新范式，通过三阶段自底向上测试方案（识别漏洞函数、模糊测试、约束验证）来检测软件漏洞，在基准测试中成功检测28个已知漏洞，并在实际应用中发现6个新漏洞。


<details>
  <summary>Details</summary>
Motivation: 传统动态测试技术采用自上而下方法，难以深入调用图深层函数。虽然已有自底向上方法，但仍面临误报和生成符合程序上下文的有效输入的挑战。

Method: 三阶段自底向上测试方案：1)识别可能易受攻击函数并生成类型和上下文感知的测试框架；2)通过模糊测试发现崩溃并使用符号执行提取输入约束；3)结合约束验证崩溃以消除误报。开发了自动化原型Griller。

Result: 在包含5个开源项目48个已知漏洞的基准测试中，成功检测28个已知漏洞。在实际应用如Pacman中发现了6个先前未知的漏洞。

Conclusion: Reactive Bottom-Up Testing能显著增强复杂系统中漏洞检测能力，为更强大的安全实践铺平道路。

Abstract: Modern computing systems remain rife with software vulnerabilities. Engineers
apply many means to detect them, of which dynamic testing is one of the most
common and effective. However, most dynamic testing techniques follow a
top-down paradigm, and struggle to reach and exercise functions deep within the
call graph. While recent works have proposed Bottom-Up approaches to address
these limitations, they face challenges with false positives and generating
valid inputs that adhere to the context of the entire program.
  In this work, we introduce a new paradigm that we call Reactive Bottom-Up
Testing. Our insight is that function-level testing is necessary but not
sufficient for the validation of vulnerabilities in functions. What we need is
a systematic approach that not only tests functions in isolation but also
validates their behavior within the broader program context, ensuring that
detected vulnerabilities are both reachable and triggerable. We develop a
three-stage bottom-up testing scheme: (1) identify likely-vulnerable functions
and generate type- and context-aware harnesses; (2) fuzz to find crashes and
extract input constraints via symbolic execution; (3) verify crashes by
combining constraints to remove false positives. We implemented an automated
prototype, which we call Griller. We evaluated Griller in a controlled setting
using a benchmark of 48 known vulnerabilities across 5 open-source projects,
where we successfully detected 28 known vulnerabilities. Additionally, we
evaluated Griller on several real-world applications such as Pacman, and it
discovered 6 previously unknown vulnerabilities. Our findings suggest that
Reactive Bottom-Up Testing can significantly enhance the detection of
vulnerabilities in complex systems, paving the way for more robust security
practices.

</details>


### [14] [A Quantum Genetic Algorithm-Enhanced Self-Supervised Intrusion Detection System for Wireless Sensor Networks in the Internet of Things](https://arxiv.org/abs/2509.03744)
*Hamid Barati*

Main category: cs.CR

TL;DR: 重新设计了一种新型混合入侵检测系统，结合量子遗传算法和自监督学习，以满足物联网环境的资源约束需求


<details>
  <summary>Details</summary>
Motivation: 传统入侵检测系统在物联网环境中面临计算成本高、依赖标签数据集的挑战，无法满足资源受限网络的严格要求

Method: 提出一种混合方法，结合量子遗传算法（QGA）进行特征选择和模型参数调优，以及自监督学习（SSL）从无标签数据中学习演绎表征

Result: 在标准物联网入侵数据集上评估，显示出在检测准确性、假正率和计算效率方面都超过传统进化算法和深度学习基于的IDS模型

Conclusion: 结合量子受启发的优化技术与自监督学习范式，为物联网和无线传感器网络设计下一代入侵检测解决方案具有很大潜力

Abstract: The rapid expansion of the Internet of Things (IoT) and Wireless Sensor
Networks (WSNs) has significantly increased the attack surface of such systems,
making them vulnerable to a wide range of cyber threats. Traditional Intrusion
Detection Systems (IDS) often fail to meet the stringent requirements of
resource-constrained IoT environments due to their high computational cost and
reliance on large labeled datasets. To address these challenges, this paper
proposes a novel hybrid Intrusion Detection System that integrates a Quantum
Genetic Algorithm (QGA) with Self-Supervised Learning (SSL). The QGA leverages
quantum-inspired evolutionary operators to optimize feature selection and
fine-tune model parameters, ensuring lightweight yet efficient detection in
resource-limited networks. Meanwhile, SSL enables the system to learn robust
representations from unlabeled data, thereby reducing dependency on manually
labeled training sets. The proposed framework is evaluated on benchmark IoT
intrusion datasets, demonstrating superior performance in terms of detection
accuracy, false positive rate, and computational efficiency compared to
conventional evolutionary and deep learning-based IDS models. The results
highlight the potential of combining quantum-inspired optimization with
self-supervised paradigms to design next-generation intrusion detection
solutions for IoT and WSN environments.

</details>


### [15] [Peekaboo, I See Your Queries: Passive Attacks Against DSSE Via Intermittent Observations](https://arxiv.org/abs/2509.03806)
*Hao Nie,Wei Wang,Peng Xu,Wei Chen,Laurence T. Yang,Mauro Conti,Kaitai Liang*

Main category: cs.CR

TL;DR: Peekaboo是一个针对动态可搜索对称加密(DSSE)的新型通用攻击框架，能够在间歇性观察的实用威胁模型下，通过推断搜索模式并结合辅助知识和其他泄漏信息，显著提升攻击准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的DSSE被动攻击需要持续监控泄漏模式，而实际场景中攻击者往往只能进行间歇性观察。本文旨在解决这种更实用的威胁模型下的攻击问题。

Method: 提出Peekaboo攻击框架，核心设计是通过推断搜索模式，并结合辅助知识和其他泄漏信息。在Sap和Jigsaw等SOTA攻击基础上实例化，生成Sap+和Jigsaw+变体。

Result: 实验表明，搜索模式恢复的调整兰德指数>0.9，查询准确率达到90%（相比FMA的30%）。准确率随观察轮次和查询数量增加而提升，且能抵抗SOTA防御措施：对文件大小填充保持>40%准确率，对混淆保持>80%准确率。

Conclusion: Peekaboo在间歇性观察的实用威胁模型下表现出色，显著提升了DSSE攻击的准确性和鲁棒性，对现有防御措施具有较强抵抗力。

Abstract: Dynamic Searchable Symmetric Encryption (DSSE) allows secure searches over a
dynamic encrypted database but suffers from inherent information leakage.
Existing passive attacks against DSSE rely on persistent leakage monitoring to
infer leakage patterns, whereas this work targets intermittent observation - a
more practical threat model. We propose Peekaboo - a new universal attack
framework - and the core design relies on inferring the search pattern and
further combining it with auxiliary knowledge and other leakage. We instantiate
Peekaboo over the SOTA attacks, Sap (USENIX' 21) and Jigsaw (USENIX' 24), to
derive their "+" variants (Sap+ and Jigsaw+). Extensive experiments demonstrate
that our design achieves >0.9 adjusted rand index for search pattern recovery
and 90% query accuracy vs. FMA's 30% (CCS' 23). Peekaboo's accuracy scales with
observation rounds and the number of observed queries but also it resists SOTA
countermeasures, with >40% accuracy against file size padding and >80% against
obfuscation.

</details>


### [16] [BIDO: A Unified Approach to Address Obfuscation and Concept Drift Challenges in Image-based Malware Detection](https://arxiv.org/abs/2509.03807)
*Junhui Li,Chengbin Feng,Zhiwei Yang,Qi Mo,Wei Wang*

Main category: cs.CR

TL;DR: BIDO是一种基于图像的混合恶意软件检测器，通过局部特征选择、跨模态依赖建模和可学习度量，同时提升对混淆和概念漂移的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的Android恶意软件检测方法在面对混淆和概念漂移时性能显著下降，且通常将这两个问题分开处理，忽略了它们共同的统计根源——分布外问题。

Method: 1) 局部特征选择模块识别恶意软件图像中的信息子区域；2) 在外部积空间中建模跨模态依赖关系提取稳定共现模式；3) 设计可学习度量确保特征紧凑性，拉近同类样本、推远异类样本。

Result: 在真实数据集上的大量实验表明，BIDO显著优于现有基线方法，对概念漂移和混淆都具有更高的鲁棒性。

Conclusion: BIDO通过统一处理混淆和概念漂移的共同统计根源，有效提升了基于图像的恶意软件检测的鲁棒性和性能。

Abstract: To identify malicious Android applications, various malware detection
techniques have been proposed. Among them, image-based approaches are
considered potential alternatives due to their efficiency and scalability.
Recent studies have reported that these approaches suffer significant
performance declines when confronted with obfuscation or concept drift.
However, existing solutions often treat these two challenges as different
problems, offering independent solutions. These techniques overlook the fact
that both challenges share a common statistical root, out-of-distribution, and
research from this perspective remains limited. In response, we propose BIDO, a
hybrid image-based malware detector designed to enhance robustness against both
obfuscation and concept drift simultaneously. Specifically, to improve the
discriminative power of image features, we introduce a local feature selection
module that identifies informative subregions within malware images. Second, to
enhance feature robustness, we model pairwise cross-modal dependencies in an
outer product space, enabling the extraction of stable co-occurrence patterns.
Third, to ensure feature compactness, we design a learnable metric that pulls
samples with identical labels closer while pushing apart those with different
labels, regardless of obfuscation or concept drift. Extensive experiments on
the real-world datasets demonstrate that BIDO significantly outperforms
existing baselines, achieving higher robustness against both concept drift and
obfuscation. The source code is available at:
https://github.com/whatishope/BIDO/.

</details>


### [17] [Rethinking Tamper-Evident Logging: A High-Performance, Co-Designed Auditing System](https://arxiv.org/abs/2509.03821)
*Rui Zhao,Muhammad Shoaib,Viet Tung Hoang,Wajih Ul Hassan*

Main category: cs.CR

TL;DR: Nitro是一个基于eBPF的高性能防篡改审计日志系统，相比现有系统性能提升10-25倍，支持细粒度检测且无需内核重编译


<details>
  <summary>Details</summary>
Motivation: 现有防篡改日志系统在高负载下开销大、数据丢失严重，只能提供粗粒度检测，且需要重新编译内核代码

Method: 使用eBPF技术避免内核重编译，密码学部分与日志前后处理协同设计以充分利用系统级优化，提供Nitro-R变体引入内核内日志缩减技术

Result: 在高压力条件下实现10-25倍性能提升，真实场景中2-10倍提升，同时保持接近零数据丢失

Conclusion: Nitro系统成功解决了现有防篡改日志系统的性能瓶颈和部署难题，通过eBPF和协同设计实现了高性能的细粒度日志防篡改

Abstract: Existing tamper-evident logging systems suffer from high overhead and severe
data loss in high-load settings, yet only provide coarse-grained tamper
detection. Moreover, installing such systems requires recompiling kernel code.
To address these challenges, we present Nitro, a high-performance,
tamper-evident audit logging system that supports fine-grained detection of log
tampering. Even better, our system avoids kernel recompilation by using the
eBPF technology. To formally justify the security of Nitro, we provide a new
definitional framework for logging systems, and give a practical cryptographic
construction meeting this new goal. Unlike prior work that focus only on the
cryptographic processing, we codesign the cryptographic part with the pre- and
post-processing of the logs to exploit all system-level optimizations. Our
evaluations demonstrate Nitro's superior performance, achieving 10X-25X
improvements in high-stress conditions and 2X-10X in real-world scenarios while
maintaining near-zero data loss. We also provide an advanced variant, Nitro-R
that introduces in-kernel log reduction techniques to reduce runtime overhead
even further.

</details>


### [18] [KGBERT4Eth: A Feature-Complete Transformer Powered by Knowledge Graph for Multi-Task Ethereum Fraud Detection](https://arxiv.org/abs/2509.03860)
*Yifan Jia,Ye Tian,Liguo Zhang,Yanbin Wang,Jianguo Sun,Liangliang Song*

Main category: cs.CR

TL;DR: KGBERT4Eth是一个融合交易语义和图知识的预训练编码器，在以太坊恶意活动检测中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有以太坊恶意活动检测方法分为三类技术路线（专家定义特征、图嵌入、序列交易模式），但缺乏跨范式集成机制，导致需要在不同特征优势间做出取舍

Method: 提出KGBERT4Eth，包含两个关键组件：(1)交易语义提取器，训练增强的交易语言模型学习上下文语义表示；(2)交易知识图谱，将专家领域知识融入图节点嵌入。通过联合优化预训练目标融合互补特征，并设计偏置掩码预测任务和链接预测来关注异常交易

Result: 在钓鱼账户检测和去匿名化任务中显著优于最先进基线，在三个钓鱼检测基准上F1分数绝对提升8-16%，在四个去匿名化数据集上提升6-26%

Conclusion: KGBERT4Eth成功融合了不同检测范式的优势，为以太坊恶意活动检测提供了特征完整的解决方案，在多个任务上取得了显著性能提升

Abstract: Ethereum's rapid ecosystem expansion and transaction anonymity have triggered
a surge in malicious activity. Detection mechanisms currently bifurcate into
three technical strands: expert-defined features, graph embeddings, and
sequential transaction patterns, collectively spanning the complete feature
sets of Ethereum's native data layer. Yet the absence of cross-paradigm
integration mechanisms forces practitioners to choose between sacrificing
sequential context awareness, structured fund-flow patterns, or human-curated
feature insights in their solutions. To bridge this gap, we propose KGBERT4Eth,
a feature-complete pre-training encoder that synergistically combines two key
components: (1) a Transaction Semantic Extractor, where we train an enhanced
Transaction Language Model (TLM) to learn contextual semantic representations
from conceptualized transaction records, and (2) a Transaction Knowledge Graph
(TKG) that incorporates expert-curated domain knowledge into graph node
embeddings to capture fund flow patterns and human-curated feature insights. We
jointly optimize pre-training objectives for both components to fuse these
complementary features, generating feature-complete embeddings. To emphasize
rare anomalous transactions, we design a biased masking prediction task for TLM
to focus on statistical outliers, while the Transaction TKG employs link
prediction to learn latent transaction relationships and aggregate knowledge.
Furthermore, we propose a mask-invariant attention coordination module to
ensure stable dynamic information exchange between TLM and TKG during
pre-training. KGBERT4Eth significantly outperforms state-of-the-art baselines
in both phishing account detection and de-anonymization tasks, achieving
absolute F1-score improvements of 8-16% on three phishing detection benchmarks
and 6-26% on four de-anonymization datasets.

</details>


### [19] [ShieldMMU: Detecting and Defending against Controlled-Channel Attacks in Shielding Memory System](https://arxiv.org/abs/2509.03879)
*Gang Liu,Ningjie Li,Cen Chen*

Main category: cs.CR

TL;DR: 基于Merkle Tree的DD-Tree防御机制，ShieldMMU通过检测、定位和恢复被攻击PTE来防范Intel SGX的控制通道攻击，在保持兼容性和性能的同时提升安全性


<details>
  <summary>Details</summary>
Motivation: Intel SGX虽然能隔离非特权程序保证机密性和完整性，但偷流溜道攻击仍然威胁其安全，恶意OS可操纵PTE存在位引发页缺陷监听内存访问迹迹，现有防御方案存在局限性

Method: 设计ShieldMMU系统，利用Merkle Tree受启发的防御树(DD-Tree)保护PTE完整性，能够检测、定位和恢复被攻击的PTE，识别MMU页表查找事件和偷流溜道攻击

Result: 实验结果证实ShieldMMU能够提供更高的安全性保障，同时保持可接受的延迟性能

Conclusion: ShieldMMU为Intel SGX提供了一种综合性的控制通道攻击防御方案，在安全性、性能和可用性之间取得了良好平衡

Abstract: Intel SGX and hypervisors isolate non-privileged programs from other
software, ensuring confidentiality and integrity. However, side-channel attacks
continue to threaten Intel SGX's security, enabling malicious OS to manipulate
PTE present bits, induce page faults, and steal memory access traces. Despite
extensive research, existing defenses focus on detection or rely on impractical
solutions. This paper presents ShieldMMU, a comprehensive solution for
mitigating controlled channel attacks, balancing compatibility, performance,
and usability. Leveraging a Merkle Tree-inspired Defense Tree (DD-Tree),
ShieldMMU protects PTE integrity by detecting, locating, and restoring attacked
PTEs. It identifies MMU page table lookup events and side-channel attacks,
promptly restoring PTE parameters to prevent page fault traps and ensure secure
non-privileged application operation within SGX. Our experiments confirm
ShieldMMU's enhanced security and acceptable latency performance.

</details>


### [20] [LMAE4Eth: Generalizable and Robust Ethereum Fraud Detection by Exploring Transaction Semantics and Masked Graph Embedding](https://arxiv.org/abs/2509.03939)
*Yifan Jia,Yanbin Wang,Jianguo Sun,Ye Tian,Peng Qian*

Main category: cs.CR

TL;DR: LMAE4Eth是一个多视图学习框架，融合交易语义、掩码图嵌入和专家知识，用于以太坊欺诈检测，在F1分数上比最佳基线方法提升超过10%。


<details>
  <summary>Details</summary>
Motivation: 当前以太坊欺诈检测方法依赖上下文无关的数值交易序列，无法捕捉账户交易语义；交易记录同质化严重导致难以学习区分性账户嵌入；现有自监督图学习方法主要关注图重构，在节点级任务上表现不佳且存在可扩展性问题。

Method: 提出TxCLM交易-令牌对比语言模型将数值交易记录转换为语言表示；使用令牌感知对比学习和掩码交易模型预训练目标学习高表达性账户表示；设计MAGAE掩码账户图自编码器通过重构账户节点特征实现节点级检测；集成层邻居采样提升大规模训练可扩展性；使用交叉注意力融合网络统一TxCLM和MAGAE嵌入。

Result: 在三个数据集上评估21个基线方法，实验结果显示在两个数据集上F1分数比最佳基线方法提升超过10%。

Conclusion: LMAE4Eth通过融合多视图学习和自监督方法，有效解决了以太坊欺诈检测中的语义捕捉、表示学习和可扩展性问题，显著提升了检测性能。

Abstract: Current Ethereum fraud detection methods rely on context-independent,
numerical transaction sequences, failing to capture semantic of account
transactions. Furthermore, the pervasive homogeneity in Ethereum transaction
records renders it challenging to learn discriminative account embeddings.
Moreover, current self-supervised graph learning methods primarily learn node
representations through graph reconstruction, resulting in suboptimal
performance for node-level tasks like fraud account detection, while these
methods also encounter scalability challenges. To tackle these challenges, we
propose LMAE4Eth, a multi-view learning framework that fuses transaction
semantics, masked graph embedding, and expert knowledge. We first propose a
transaction-token contrastive language model (TxCLM) that transforms
context-independent numerical transaction records into logically cohesive
linguistic representations. To clearly characterize the semantic differences
between accounts, we also use a token-aware contrastive learning pre-training
objective together with the masked transaction model pre-training objective,
learns high-expressive account representations. We then propose a masked
account graph autoencoder (MAGAE) using generative self-supervised learning,
which achieves superior node-level account detection by focusing on
reconstructing account node features. To enable MAGAE to scale for large-scale
training, we propose to integrate layer-neighbor sampling into the graph, which
reduces the number of sampled vertices by several times without compromising
training quality. Finally, using a cross-attention fusion network, we unify the
embeddings of TxCLM and MAGAE to leverage the benefits of both. We evaluate our
method against 21 baseline approaches on three datasets. Experimental results
show that our method outperforms the best baseline by over 10% in F1-score on
two of the datasets.

</details>


### [21] [NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models](https://arxiv.org/abs/2509.03985)
*Chuhan Zhang,Ye Zhang,Bowen Shi,Yuyou Gan,Tianyu Du,Shouling Ji,Dazhan Deng,Yingcai Wu*

Main category: cs.CR

TL;DR: NeuroBreak是一个自上而下的越狱分析系统，通过神经元层面的安全机制分析来识别和缓解LLM漏洞，提供对模型决策过程的新视角和关键神经元分析。


<details>
  <summary>Details</summary>
Motivation: 随着越狱攻击技术的不断发展，LLM的安全防御面临巨大压力。由于LLM参数量庞大、结构复杂，从内部视角分析安全弱点具有挑战性。

Method: 设计了一个与AI安全专家合作开发的系统，包含分层表示探测分析，从语义和功能角度分析关键神经元，提供全面的越狱攻击方法分析。

Result: 通过定量评估和案例研究验证了系统的有效性，为开发下一代防御策略提供了机制性见解。

Conclusion: NeuroBreak系统能够深入分析LLM的安全机制和漏洞，为应对不断演变的越狱攻击提供了有价值的工具和见解。

Abstract: In deployment and application, large language models (LLMs) typically undergo
safety alignment to prevent illegal and unethical outputs. However, the
continuous advancement of jailbreak attack techniques, designed to bypass
safety mechanisms with adversarial prompts, has placed increasing pressure on
the security defenses of LLMs. Strengthening resistance to jailbreak attacks
requires an in-depth understanding of the security mechanisms and
vulnerabilities of LLMs. However, the vast number of parameters and complex
structure of LLMs make analyzing security weaknesses from an internal
perspective a challenging task. This paper presents NeuroBreak, a top-down
jailbreak analysis system designed to analyze neuron-level safety mechanisms
and mitigate vulnerabilities. We carefully design system requirements through
collaboration with three experts in the field of AI security. The system
provides a comprehensive analysis of various jailbreak attack methods. By
incorporating layer-wise representation probing analysis, NeuroBreak offers a
novel perspective on the model's decision-making process throughout its
generation steps. Furthermore, the system supports the analysis of critical
neurons from both semantic and functional perspectives, facilitating a deeper
exploration of security mechanisms. We conduct quantitative evaluations and
case studies to verify the effectiveness of our system, offering mechanistic
insights for developing next-generation defense strategies against evolving
jailbreak attacks.

</details>


### [22] [Systematic Timing Leakage Analysis of NIST PQDSS Candidates: Tooling and Lessons Learned](https://arxiv.org/abs/2509.04010)
*Olivier Adjonyo,Sebastien Bardin,Emanuele Bellini,Gilbert Ndollane Dione,Mahmudul Faisal Al Ameen,Robert Merget,Frederic Recoules,Yanis Sellami*

Main category: cs.CR

TL;DR: 开发了一个自动化工具链，用于分析后量子密码方案的常数时间实现安全性，通过整合多个现有工具来检测时序侧信道漏洞


<details>
  <summary>Details</summary>
Motivation: PQDSS标准化需要密码原语免受时序和缓存侧信道攻击，确保常数时间实现对于安全性和公平性能比较至关重要，但现有工具配置复杂难用

Method: 开发自动化工具链整合TIMECOP、Binsec/Rel2进行二进制级常数时间验证，以及dudect、RTLF进行执行时间统计分析

Result: 评估了NIST PQDSS第1轮和第2轮实现，共报告26个问题，其中5个已修复，展示了工具的有效性和实用性

Conclusion: 自动化工具链显著提高了常数时间分析的效率和可访问性，为后量子密码方案的安全实现提供了重要支持

Abstract: The PQDSS standardization process requires cryptographic primitives to be
free from vulnerabilities, including timing and cache side-channels. Resistance
to timing leakage is therefore an essential property, and achieving this
typically relies on software implementations that follow constant-time
principles. Moreover, ensuring that all implementations are constant-time is
crucial for fair performance comparisons, as secure implementations often incur
additional overhead. Such analysis also helps identify scheme proposals that
are inherently difficult to implement in constant time. Because constant-time
properties can be broken during compilation, it is often necessary to analyze
the compiled binary directly. Since manual binary analysis is extremely
challenging, automated analysis becomes highly important. Although several
tools exist to assist with such analysis, they often have usability limitations
and are difficult to set up correctly. To support the developers besides the
NIST committee in verifying candidates, we developed a toolchain that automates
configuration, execution, and result analysis for several widely used
constant-time analysis tools. We selected TIMECOP and Binsec/Rel2 to verify
constant-time policy compliance at the binary level, and dudect and RTLF to
detect side-channel vulnerabilities through statistical analysis of execution
time behavior. We demonstrate its effectiveness and practicability by
evaluating the NIST PQDSS round 1 and round 2 implementations. We reported 26
issues in total to the respective developers, and 5 of them have already been
fixed. We also discuss our different findings, as well as the benefits of
shortcomings of the different tools.

</details>


### [23] [Error Detection Schemes for Barrett Reduction of CT-BU on FPGA in Post Quantum Cryptography](https://arxiv.org/abs/2509.04070)
*Paresh Baidya,Rourab Paul,Vikas Srivastava,Sumit Kumar Debnath*

Main category: cs.CR

TL;DR: 这篇论文提出了三种高效轻量敏错检测方法（RESWO、RENO、RESO），用于防范Kyber等后量子加密算法中Barrett约化模块的敏错注入攻击，敏错检测效率近依100%。


<details>
  <summary>Details</summary>
Motivation: 敏错注入攻击可能导致后量子加密算法的硬件实现泄漏敏感信息，需要有效的敏错检测方法来保障安全性。

Method: 提出了RESWO（交换操作数重计算）新算法，并将RENO（取反操作数重计算）和RESO（位移操作数重计算）应用于Barrett约化模块的敏错检测。

Result: RESWO消耗的逸代逸位数量与RENO和RESO相似，但延迟更小，三种方法的敏错检测效率都近依100%。

Conclusion: 提出的三种重计算基敏错检测方法能够高效地防范Kyber等后量子加密算法中的敏错注入攻击，特别是RESWO方法在保持高检测效率的同时还具有更低的延迟。

Abstract: A fault can occur naturally or intentionally. However, intentionally
injecting faults into hardware accelerators of Post-Quantum Cryptographic (PQC)
algorithms may leak sensitive information. This intentional fault injection in
side-channel attacks compromises the reliability of PQC implementations. The
recently NIST-standardized key encapsulation mechanism (KEM), Kyber may also
leak information at the hardware implementation level. This work proposes three
efficient and lightweight recomputation-based fault detection methods for
Barrett Reduction in the Cooley-Tukey Butterfly Unit (CT-BU) of Kyber on a
Field Programmable Gate Array (FPGA). The CT-BU and Barrett Reduction are
fundamental components in structured lattice-based PQC algorithms, including
Kyber, NTRU, Falcon, CRYSTALS-Dilithium, etc. This paper introduces a new
algorithm, Recomputation with Swapped Operand (RESWO), for fault detection.
While Recomputation with Negated Operand (RENO) and Recomputation with Shifted
Operand (RESO) are existing methods used in other PQC hardware algorithms. To
the best of our knowledge, RENO and RESO have never been used in Barrett
Reduction before. The proposed RESWO method consumes a similar number of slices
compared to RENO and RESO. However, RESWO shows lesser delay compared to both
RENO and RESO. The fault detection efficiency of RESWO, RENO, and RESO is
nearly 100%.

</details>


### [24] [ICSLure: A Very High Interaction Honeynet for PLC-based Industrial Control Systems](https://arxiv.org/abs/2509.04080)
*Francesco Aurelio Pironti,Angelo Furfaro,Francesco Blefari,Carmelo Felicetti,Matteo Lupinacci,Francesco Romeo*

Main category: cs.CR

TL;DR: 提出了ICSLure模块化蜜网框架，通过整合物理PLC和虚拟化网络组件来模拟真实ICS环境，提高威胁数据收集质量


<details>
  <summary>Details</summary>
Motivation: 工业控制系统安全至关重要，但传统ICS蜜罐缺乏真实性，无法有效应对复杂攻击

Method: 使用物理PLC与实时数据源交互（Modbus、Profinet RTU协议），结合虚拟化网络组件（路由器、交换机、RTU），并配备全面监控能力

Result: 实现了真实工业工厂的高保真模拟，显著提升了威胁数据收集质量

Conclusion: 该高交互环境支持对ICS特定攻击策略的先进分析，有助于开发更有效的检测和缓解技术

Abstract: The security of Industrial Control Systems (ICSs) is critical to ensuring the
safety of industrial processes and personnel. The rapid adoption of Industrial
Internet of Things (IIoT) technologies has expanded system functionality but
also increased the attack surface, exposing ICSs to a growing range of cyber
threats. Honeypots provide a means to detect and analyze such threats by
emulating target systems and capturing attacker behavior. However, traditional
ICS honeypots, often limited to software-based simulations of a single
Programmable Logic Controller (PLC), lack the realism required to engage
sophisticated adversaries. In this work, we introduce a modular honeynet
framework named ICSLure. The framework has been designed to emulate realistic
ICS environments. Our approach integrates physical PLCs interacting with live
data sources via industrial protocols such as Modbus and Profinet RTU, along
with virtualized network components including routers, switches, and Remote
Terminal Units (RTUs). The system incorporates comprehensive monitoring
capabilities to collect detailed logs of attacker interactions. We demonstrate
that our framework enables coherent and high-fidelity emulation of real-world
industrial plants. This high-interaction environment significantly enhances the
quality of threat data collected and supports advanced analysis of ICS-specific
attack strategies, contributing to more effective detection and mitigation
techniques.

</details>


### [25] [Revisiting Third-Party Library Detection: A Ground Truth Dataset and Its Implications Across Security Tasks](https://arxiv.org/abs/2509.04091)
*Jintao Gu,Haolang Lu,Guoshun Nan,Yihan Lin,Kun Wang,Yuchun Guo,Yigui Cao,Yang Liu*

Main category: cs.CR

TL;DR: 对10种最先进的第三方库检测工具进行大规模实证研究，发现现有工具在R8时代转换、版本识别、运行效率等方面存在显著问题，并分析了TPL特性对安全分析任务的影响


<details>
  <summary>Details</summary>
Motivation: 准确检测第三方库对Android安全至关重要，但现有工具的实际效果不明确，需要进行大规模实证评估

Method: 构建包含精确版本标注的新基准数据集，对6000多个应用中的10种先进TPL检测技术进行大规模评估

Result: 暴露了工具对R8转换的脆弱性、版本区分能力弱、候选库对应不准确、相似度阈值泛化困难以及大规模运行时/内存开销过大等问题

Conclusion: 研究不仅评估了工具性能，还深入分析了TPL特性如何影响漏洞分析、恶意软件检测等下游安全任务，为未来安全分析改进提供了具体见解

Abstract: Accurate detection of third-party libraries (TPLs) is fundamental to Android
security, supporting vulnerability tracking, malware detection, and supply
chain auditing. Despite many proposed tools, their real-world effectiveness
remains unclear.We present the first large-scale empirical study of ten
state-of-the-art TPL detection techniques across over 6,000 apps, enabled by a
new ground truth dataset with precise version-level annotations for both remote
and local dependencies.Our evaluation exposes tool fragility to R8-era
transformations, weak version discrimination, inaccurate correspondence of
candidate libraries, difficulty in generalizing similarity thresholds, and
prohibitive runtime/memory overheads at scale.Beyond tool assessment, we
further analyze how TPLs shape downstream tasks, including vulnerability
analysis, malware detection, secret leakage assessment, and LLM-based
evaluation. From this perspective, our study provides concrete insights into
how TPL characteristics affect these tasks and informs future improvements in
security analysis.

</details>


### [26] [ECCFROG522PP: An Enhanced 522-bit Weierstrass Elliptic Curve](https://arxiv.org/abs/2509.04097)
*Víctor Duarte Melo,William J. Buchanan*

Main category: cs.CR

TL;DR: ECCFROG522PP是一个522位素数域椭圆曲线，提供约260位经典安全性，通过BLAKE3确定性生成参数，具有完全可重现性和可验证性


<details>
  <summary>Details</summary>
Motivation: 满足对透明、可重现的256位安全级别椭圆曲线的需求，替代NIST P-521等现有高安全选项

Method: 使用BLAKE3从固定公共种子确定性派生所有曲线参数，确保无隐藏选择，具有素数阶、验证扭曲、安全嵌入度等特性

Result: 成功设计出安全性与NIST P-521相当但完全透明的椭圆曲线，通过了抗MOV检查和CM判别式验证

Conclusion: ECCFROG522PP在保持同等安全性的同时，最大化了信任度、可验证性和长期可审计性，为高安全应用提供了透明选择

Abstract: Whilst many key exchange and digital signature systems still rely on NIST
P-256 (secp256r1) and secp256k1, offering around 128-bit security, there is an
increasing demand for transparent and reproducible curves at the 256-bit
security level. Standard higher-security options include NIST P-521, Curve448,
and Brainpool-P512. This paper presents ECCFROG522PP ("Presunto Powered"), a
522-bit prime-field elliptic curve that delivers security in the same classical
approx 260-bit ballpark as NIST P-521, but with a fundamentally different
design philosophy. All of the curve parameters are deterministically derived
from a fixed public seed via BLAKE3, with zero hidden choices. The curve has
prime order (cofactor = 1), a verified twist with a proven approx 505-bit prime
factor, safe embedding degree (greater than or equal to 14), and passes
anti-MOV checks up to k less than or equal to 200 and CM discriminant sanity up
to 100k. Unlike prior opaque or ad-hoc constructions, ECCFROG522PP is fully
reproducible: anyone can regenerate and verify it byte-for-byte using the
published scripts. The intent is not to outperform NIST P-521 in raw speed, but
to maximise trust, verifiability, and long-term auditability in a practical
curve of equivalent security level

</details>


### [27] [KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and Runtime Logs Analysis](https://arxiv.org/abs/2509.04191)
*Omri Sgan Cohen,Ehud Malul,Yair Meidan,Dudu Mimran,Yuval Elovici,Asaf Shabtai*

Main category: cs.CR

TL;DR: KubeGuard是一个基于运行时日志的Kubernetes安全推荐框架，使用LLM分析清单和日志来创建和优化最小权限配置，有效降低攻击面。


<details>
  <summary>Details</summary>
Motivation: Kubernetes的广泛采用带来了安全挑战，如错误配置和过度权限配置，可能导致未授权访问和权限提升等问题。现有解决方案主要关注检测而非缓解。

Method: 提出KubeGuard框架，通过两个互补任务（资源创建和资源优化）利用LLM分析清单和运行时日志，采用模块化提示链工作流生成最小权限配置建议。

Result: 评估显示KubeGuard能有效生成和优化Roles、NetworkPolicies和Deployments的清单，在使用专有和开源LLM时都表现出高精度、召回率和F1分数。

Conclusion: KubeGuard是一个实用的框架，能够将运行时可观测性转化为可操作的最小权限配置指导，提升Kubernetes集群安全性。

Abstract: The widespread adoption of Kubernetes (K8s) for orchestrating cloud-native
applications has introduced significant security challenges, such as
misconfigured resources and overly permissive configurations. Failing to
address these issues can result in unauthorized access, privilege escalation,
and lateral movement within clusters. Most existing K8s security solutions
focus on detecting misconfigurations, typically through static analysis or
anomaly detection. In contrast, this paper presents KubeGuard, a novel runtime
log-driven recommender framework aimed at mitigating risks by addressing overly
permissive configurations. KubeGuard is designed to harden K8s environments
through two complementary tasks: Resource Creation and Resource Refinement. It
leverages large language models (LLMs) to analyze manifests and runtime logs
reflecting actual system behavior, using modular prompt-chaining workflows.
This approach enables KubeGuard to create least-privilege configurations for
new resources and refine existing manifests to reduce the attack surface.
KubeGuard's output manifests are presented as recommendations that users (e.g.,
developers and operators) can review and adopt to enhance cluster security. Our
evaluation demonstrates that KubeGuard effectively generates and refines K8s
manifests for Roles, NetworkPolicies, and Deployments, leveraging both
proprietary and open-source LLMs. The high precision, recall, and F1-scores
affirm KubeGuard's practicality as a framework that translates runtime
observability into actionable, least-privilege configuration guidance.

</details>


### [28] [An Automated, Scalable Machine Learning Model Inversion Assessment Pipeline](https://arxiv.org/abs/2509.04214)
*Tyler Shumaker,Jessica Carpenter,David Saranchak,Nathaniel D. Bastian*

Main category: cs.CR

TL;DR: 本文提出了一种新的自动化开发测试与评估工具，用于量化机器学习模型反向工程攻击的隐私风险，通过结合视觉语言模型提高效果和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在军事战场上存在隐私攻击风险，而当前缺乏自动化的开发测试与评估工具来量化模型反向攻击的隐私损失效果。

Method: 设计了一种新的DT&E流水线，结合视觉语言模型（VLMs）进行反向工程，并提出四个对抗风险维度来量化隐私损失。

Result: 在计算机视觉领域的图像分类任务中，采用多种先进的MIA技术和VLM配置进行验证，证明了该工具的有效性。

Conclusion: 该创新流水线通过提高效果和可扩展性，扩展了当前模型反向DT&E的能力，以自动化方式进行隐私损失分析。

Abstract: Machine learning (ML) models have the potential to transform military
battlefields, presenting a large external pressure to rapidly incorporate them
into operational settings. However, it is well-established that these ML models
are vulnerable to a number of adversarial attacks throughout the model
deployment pipeline that threaten to negate battlefield advantage. One broad
category is privacy attacks (such as model inversion) where an adversary can
reverse engineer information from the model, such as the sensitive data used in
its training. The ability to quantify the risk of model inversion attacks
(MIAs) is not well studied, and there is a lack of automated developmental test
and evaluation (DT&E) tools and metrics to quantify the effectiveness of
privacy loss of the MIA. The current DT&E process is difficult because ML model
inversions can be hard for a human to interpret, subjective when they are
interpretable, and difficult to quantify in terms of inversion quality.
Additionally, scaling the DT&E process is challenging due to many ML model
architectures and data modalities that need to be assessed. In this work, we
present a novel DT&E tool that quantifies the risk of data privacy loss from
MIAs and introduces four adversarial risk dimensions to quantify privacy loss.
Our DT&E pipeline combines inversion with vision language models (VLMs) to
improve effectiveness while enabling scalable analysis. We demonstrate
effectiveness using multiple MIA techniques and VLMs configured for zero-shot
classification and image captioning. We benchmark the pipeline using several
state-of-the-art MIAs in the computer vision domain with an image
classification task that is typical in military applications. In general, our
innovative pipeline extends the current model inversion DT&E capabilities by
improving the effectiveness and scalability of the privacy loss analysis in an
automated fashion.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [29] [PG-Agent: An Agent Powered by Page Graph](https://arxiv.org/abs/2509.03536)
*Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang*

Main category: cs.AI

TL;DR: 这篇论文提出了PG-Agent，通过将序列化GUI操作转换为页面图构建，结合检索增强生成技术，提升GUI代理的环境感知能力和演续性。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理使用序列化多步操作作为知识，无法抓取页面间复杂的迁移关系，导致代理难以深度感知GUI环境并法法演续到新场景。

Method: 设计自动化流水线将序列化操作转换为页面图，显式建模页面图结构；结合RAG技术从页面图中检索可靠的GUI感知指南；提出任务分解策略的多代理框架PG-Agent。

Result: 在多个标准测试集上进行了广泛实验，证明了PG-Agent的有效性，即使在用于页面图构建的有限播放次数下也能获得良好效果。

Conclusion: 通过页面图构建和RAG技术，PG-Agent能够更好地感知GUI环境并演续到未见场景，为GUI代理的开发提供了新的解决方案。

Abstract: Graphical User Interface (GUI) agents possess significant commercial and
social value, and GUI agents powered by advanced multimodal large language
models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI
agents usually utilize sequential episodes of multi-step operations across
pages as the prior GUI knowledge, which fails to capture the complex transition
relationship between pages, making it challenging for the agents to deeply
perceive the GUI environment and generalize to new scenarios. Therefore, we
design an automated pipeline to transform the sequential episodes into page
graphs, which explicitly model the graph structure of the pages that are
naturally connected by actions. To fully utilize the page graphs, we further
introduce Retrieval-Augmented Generation (RAG) technology to effectively
retrieve reliable perception guidelines of GUI from them, and a tailored
multi-agent framework PG-Agent with task decomposition strategy is proposed to
be injected with the guidelines so that it can generalize to unseen scenarios.
Extensive experiments on various benchmarks demonstrate the effectiveness of
PG-Agent, even with limited episodes for page graph construction.

</details>


### [30] [Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models](https://arxiv.org/abs/2509.03548)
*João P. Arroyo,João G. Rodrigues,Daniel Lawand,Denis D. Mauá,Junkyu Lee,Radu Marinescu,Alex Gray,Eduardo R. Laurentino,Fabio G. Cozman*

Main category: cs.AI

TL;DR: 本文研究准马尔可夫因果模型中部分可识别查询的概率边界计算问题，提出了基于列生成技术的新算法，通过辅助线性整数程序序列有效计算单干预场景下的概率边界。


<details>
  <summary>Details</summary>
Motivation: 在准马尔可夫因果模型中，当外生变量未完全指定时，无法精确计算感兴趣的概率值，需要研究如何计算紧致的概率边界。

Method: 利用内生变量的输入概率简化多线性规划构造，对单干预场景应用列生成技术，通过一系列辅助线性整数程序计算概率边界，证明外生变量的多项式基数表示是可行的。

Result: 实验表明列生成技术优于现有方法，能够有效计算概率边界。

Conclusion: 提出的列生成算法为准马尔可夫因果模型中的部分可识别查询提供了有效的概率边界计算方法，特别是在单干预场景下表现出优越性能。

Abstract: We investigate partially identifiable queries in a class of causal models. We
focus on acyclic Structural Causal Models that are quasi-Markovian (that is,
each endogenous variable is connected with at most one exogenous confounder).
We look into scenarios where endogenous variables are observed (and a
distribution over them is known), while exogenous variables are not fully
specified. This leads to a representation that is in essence a Bayesian network
where the distribution of root variables is not uniquely determined. In such
circumstances, it may not be possible to precisely compute a probability value
of interest. We thus study the computation of tight probability bounds, a
problem that has been solved by multilinear programming in general, and by
linear programming when a single confounded component is intervened upon. We
present a new algorithm to simplify the construction of such programs by
exploiting input probabilities over endogenous variables. For scenarios with a
single intervention, we apply column generation to compute a probability bound
through a sequence of auxiliary linear integer programs, thus showing that a
representation with polynomial cardinality for exogenous variables is possible.
Experiments show column generation techniques to be superior to existing
methods.

</details>


### [31] [Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method](https://arxiv.org/abs/2509.03550)
*Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang*

Main category: cs.AI

TL;DR: 本文提出Diffusion-AC框架，将扩散概率模型应用于空中交通冲突检测与解决，通过多模态决策能力显著提升安全性和灵活性


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法在冲突检测与解决中存在"单模态偏差"，导致决策僵化和灵活性不足，难以应对复杂动态约束

Method: 提出Diffusion-AC框架，将策略建模为价值函数引导的反向去噪过程，生成高质量多模态动作分布；采用密度递进安全课程(DPSC)训练机制

Result: 在最具挑战性的高密度场景中，成功率94.1%，近距空中碰撞减少59%，显著优于现有最先进DRL基准方法

Conclusion: 扩散概率模型为安全关键型冲突解决任务提供了有效解决方案，多模态决策能力使系统能够灵活切换有效替代机动策略

Abstract: In the context of continuously rising global air traffic, efficient and safe
Conflict Detection and Resolution (CD&R) is paramount for air traffic
management. Although Deep Reinforcement Learning (DRL) offers a promising
pathway for CD&R automation, existing approaches commonly suffer from a
"unimodal bias" in their policies. This leads to a critical lack of
decision-making flexibility when confronted with complex and dynamic
constraints, often resulting in "decision deadlocks." To overcome this
limitation, this paper pioneers the integration of diffusion probabilistic
models into the safety-critical task of CD&R, proposing a novel autonomous
conflict resolution framework named Diffusion-AC. Diverging from conventional
methods that converge to a single optimal solution, our framework models its
policy as a reverse denoising process guided by a value function, enabling it
to generate a rich, high-quality, and multimodal action distribution. This core
architecture is complemented by a Density-Progressive Safety Curriculum (DPSC),
a training mechanism that ensures stable and efficient learning as the agent
progresses from sparse to high-density traffic environments. Extensive
simulation experiments demonstrate that the proposed method significantly
outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the
most challenging high-density scenarios, Diffusion-AC not only maintains a high
success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions
(NMACs) by approximately 59% compared to the next-best-performing baseline,
significantly enhancing the system's safety margin. This performance leap stems
from its unique multimodal decision-making capability, which allows the agent
to flexibly switch to effective alternative maneuvers.

</details>


### [32] [Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents](https://arxiv.org/abs/2509.03581)
*Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel*

Main category: cs.AI

TL;DR: 该论文提出了动态规划框架，让LLM智能体能够灵活决定何时进行规划，通过监督微调和强化学习两阶段训练，在长时程任务中实现更高效的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法如ReAct要求LLM在每次行动前都进行规划，这在计算上昂贵且在长时程任务中性能下降，而完全不规划又会限制性能，因此需要动态规划能力。

Method: 提出两阶段训练流程：1）在多样化合成数据上进行监督微调，为动态规划奠定基础；2）在长时程环境中使用强化学习来精炼这种能力。

Result: 在Crafter环境中的实验表明，动态规划智能体样本效率更高，能持续实现更复杂的目标，并且能够有效利用人类编写的规划来超越其独立能力。

Conclusion: 这是首个探索训练LLM智能体进行动态测试时计算分配的研究，为更高效、自适应和可控的智能体系统铺平了道路。

Abstract: Training large language models (LLMs) to reason via reinforcement learning
(RL) significantly improves their problem-solving capabilities. In agentic
settings, existing methods like ReAct prompt LLMs to explicitly plan before
every action; however, we demonstrate that always planning is computationally
expensive and degrades performance on long-horizon tasks, while never planning
further limits performance. To address this, we introduce a conceptual
framework formalizing dynamic planning for LLM agents, enabling them to
flexibly decide when to allocate test-time compute for planning. We propose a
simple two-stage training pipeline: (1) supervised fine-tuning on diverse
synthetic data to prime models for dynamic planning, and (2) RL to refine this
capability in long-horizon environments. Experiments on the Crafter environment
show that dynamic planning agents trained with this approach are more
sample-efficient and consistently achieve more complex objectives.
Additionally, we demonstrate that these agents can be effectively steered by
human-written plans, surpassing their independent capabilities. To our
knowledge, this work is the first to explore training LLM agents for dynamic
test-time compute allocation in sequential decision-making tasks, paving the
way for more efficient, adaptive, and controllable agentic systems.

</details>


### [33] [Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE](https://arxiv.org/abs/2509.03626)
*Zahra Zehtabi Sabeti Moghaddam,Zeinab Dehghani,Maneeha Rani,Koorosh Aslansefat,Bhupesh Kumar Mishra,Rameez Raja Kureshi,Dhavalkumar Thakker*

Main category: cs.AI

TL;DR: KG-SMILE是一个基于扰动的框架，为Graph RAG提供标记和组件级可解释性，通过识别对生成输出最有影响的图实体和关系来提高透明度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在幻觉和不可验证声明的问题，特别是在医疗等敏感领域。虽然检索增强生成(RAG)通过外部知识提高了准确性，但仍是一个黑盒系统，依赖数据质量且缺乏透明度。

Method: 开发了方法无关的、基于扰动的框架KG-SMILE，通过应用受控扰动、计算相似性并训练加权线性替代模型，来识别图实体和关系对生成输出的影响。

Result: KG-SMILE在保真度、忠实度、一致性、稳定性和准确性等综合归因指标上表现良好，产生稳定且与人类对齐的解释。

Conclusion: KG-SMILE能够在保持模型有效性的同时提供可解释性，从而促进机器学习技术的透明度和信任度。

Abstract: Generative AI, such as Large Language Models (LLMs), has achieved impressive
progress but still produces hallucinations and unverifiable claims, limiting
reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves
accuracy by grounding outputs in external knowledge, especially in domains like
healthcare, where precision is vital. However, RAG remains opaque and
essentially a black box, heavily dependent on data quality. We developed a
method-agnostic, perturbation-based framework that provides token and
component-level interoperability for Graph RAG using SMILE and named it as
Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing
similarities, and training weighted linear surrogates, KG-SMILE identifies the
graph entities and relations most influential to generated outputs, thereby
making RAG more transparent. We evaluate KG-SMILE using comprehensive
attribution metrics, including fidelity, faithfulness, consistency, stability,
and accuracy. Our findings show that KG-SMILE produces stable, human-aligned
explanations, demonstrating its capacity to balance model effectiveness with
interpretability and thereby fostering greater transparency and trust in
machine learning technologies.

</details>


### [34] [CausalARC: Abstract Reasoning with Causal World Models](https://arxiv.org/abs/2509.03636)
*Jacqueline Maasch,John Kalantari,Kia Khezeli*

Main category: cs.AI

TL;DR: CausalARC是一个基于因果世界模型的AI推理测试平台，专为低数据和分布外场景设计，提供观测、干预和反事实反馈来评估语言模型的多维推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI在有限数据和分布偏移条件下进行推理适应的挑战，需要构建一个能够系统评估模型在因果推理、反事实推理等复杂场景下表现的测试环境。

Method: 基于结构因果模型构建完全指定的因果世界模型，通过原则性数据增强提供观测、干预和反事实三种反馈形式，作为少样本上下文学习演示。

Result: 成功开发了CausalARC测试平台，并展示了其在四个语言模型评估场景中的应用：测试时训练的抽象推理、上下文学习的反事实推理、程序合成以及因果发现与逻辑推理。

Conclusion: CausalARC为评估AI系统在因果推理和分布外泛化能力方面提供了系统化的测试框架，特别是在低数据环境下展现出了实用价值。

Abstract: Reasoning requires adaptation to novel problem settings under limited data
and distribution shift. This work introduces CausalARC: an experimental testbed
for AI reasoning in low-data and out-of-distribution regimes, modeled after the
Abstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is
sampled from a fully specified causal world model, formally expressed as a
structural causal model. Principled data augmentations provide observational,
interventional, and counterfactual feedback about the world model in the form
of few-shot, in-context learning demonstrations. As a proof-of-concept, we
illustrate the use of CausalARC for four language model evaluation settings:
(1) abstract reasoning with test-time training, (2) counterfactual reasoning
with in-context learning, (3) program synthesis, and (4) causal discovery with
logical reasoning.

</details>


### [35] [Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations](https://arxiv.org/abs/2509.03644)
*François Olivier,Zied Bouraoui*

Main category: cs.AI

TL;DR: 提出了Embodied-LM原型系统，通过基于图像图式的符号化空间推理来增强大语言模型的逻辑推理能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型在逻辑推理方面容易出错，缺乏人类基于感知运动经验的稳健心理表征

Method: 使用基于图像图式的模式化表征，通过答案集编程进行声明式空间推理，将认知结构形式化为可执行程序

Result: 在逻辑演绎问题上证明LLMs可以通过具身认知结构解释场景，这些结构支持有效的逻辑推理并提高可解释性

Conclusion: 虽然当前实现专注于空间原语，但为纳入更复杂动态表征奠定了计算基础

Abstract: Despite significant progress in natural language understanding, Large
Language Models (LLMs) remain error-prone when performing logical reasoning,
often lacking the robust mental representations that enable human-like
comprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that
grounds understanding and logical reasoning in schematic representations based
on image schemas-recurring patterns derived from sensorimotor experience that
structure human cognition. Our system operationalizes the spatial foundations
of these cognitive structures using declarative spatial reasoning within Answer
Set Programming. Through evaluation on logical deduction problems, we
demonstrate that LLMs can be guided to interpret scenarios through embodied
cognitive structures, that these structures can be formalized as executable
programs, and that the resulting representations support effective logical
reasoning with enhanced interpretability. While our current implementation
focuses on spatial primitives, it establishes the computational foundation for
incorporating more complex and dynamic representations.

</details>


### [36] [Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning](https://arxiv.org/abs/2509.03646)
*Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen*

Main category: cs.AI

TL;DR: 研究发现RL提升LLM推理能力的关键机制是层次化推理结构的涌现，提出了HICRA算法专注于高层策略规划token，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 揭示RL增强大语言模型复杂推理能力的内在机制，解释诸如"顿悟时刻"、长度缩放和熵动态等令人困惑的现象

Method: 提出HIerarchy-Aware Credit Assignment (HICRA)算法，专注于高层策略规划token的优化，并使用语义熵作为策略探索的度量指标

Result: HICRA显著优于现有基线方法，验证了专注于策略瓶颈是解锁高级推理的关键

Conclusion: RL成功提升LLM推理能力源于层次化推理结构的涌现，HICRA算法通过集中优化高层规划token有效解决了现有RL算法的效率问题

Abstract: Reinforcement Learning (RL) has proven highly effective at enhancing the
complex reasoning abilities of Large Language Models (LLMs), yet underlying
mechanisms driving this success remain largely opaque. Our analysis reveals
that puzzling phenomena like ``aha moments", ``length-scaling'' and entropy
dynamics are not disparate occurrences but hallmarks of an emergent reasoning
hierarchy, akin to the separation of high-level strategic planning from
low-level procedural execution in human cognition. We uncover a compelling
two-phase dynamic: initially, a model is constrained by procedural correctness
and must improve its low-level skills. The learning bottleneck then decisively
shifts, with performance gains being driven by the exploration and mastery of
high-level strategic planning. This insight exposes a core inefficiency in
prevailing RL algorithms like GRPO, which apply optimization pressure
agnostically and dilute the learning signal across all tokens. To address this,
we propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that
concentrates optimization efforts on high-impact planning tokens. HICRA
significantly outperforms strong baselines, demonstrating that focusing on this
strategic bottleneck is key to unlocking advanced reasoning. Furthermore, we
validate semantic entropy as a superior compass for measuring strategic
exploration over misleading metrics such as token-level entropy.

</details>


### [37] [An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification](https://arxiv.org/abs/2509.03649)
*Davide Italo Serramazza,Nikos Papadeas,Zahraa Abdallah,Georgiana Ifrim*

Main category: cs.AI

TL;DR: 本文研究了时间序列分类中SHAP解释方法的优化，发现分段数量比具体分段算法更重要，等长分段优于大多数定制算法，并提出了一种新的基于长度的归一化技术来提升解释质量。


<details>
  <summary>Details</summary>
Motivation: SHAP方法在时间序列分类中计算复杂度高，现有研究通过分段聚合来降低计算成本，但最优分段策略选择仍是一个开放问题。

Method: 研究了8种不同的时间序列分割算法，使用InterpretTime和AUC Difference两种评估方法，在多变量和单变量时间序列上进行实验。

Result: 发现分段数量对解释质量的影响大于具体分段方法，等长分段表现优于大多数定制算法，新提出的长度加权归一化技术能持续提升解释质量。

Conclusion: 在时间序列解释中，简单的等长分段配合长度加权归一化是实用且有效的策略，分段数量是关键因素而非复杂的定制算法。

Abstract: Explainable AI (XAI) has become an increasingly important topic for
understanding and attributing the predictions made by complex Time Series
Classification (TSC) models. Among attribution methods, SHapley Additive
exPlanations (SHAP) is widely regarded as an excellent attribution method; but
its computational complexity, which scales exponentially with the number of
features, limits its practicality for long time series. To address this, recent
studies have shown that aggregating features via segmentation, to compute a
single attribution value for a group of consecutive time points, drastically
reduces SHAP running time. However, the choice of the optimal segmentation
strategy remains an open question. In this work, we investigated eight
different Time Series Segmentation algorithms to understand how segment
compositions affect the explanation quality. We evaluate these approaches using
two established XAI evaluation methodologies: InterpretTime and AUC Difference.
Through experiments on both Multivariate (MTS) and Univariate Time Series
(UTS), we find that the number of segments has a greater impact on explanation
quality than the specific segmentation method. Notably, equal-length
segmentation consistently outperforms most of the custom time series
segmentation algorithms. Furthermore, we introduce a novel attribution
normalisation technique that weights segments by their length and we show that
it consistently improves attribution quality.

</details>


### [38] [PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming](https://arxiv.org/abs/2509.03728)
*Wesley Hanwen Deng,Sunnie S. Y. Kim,Akshita Jha,Ken Holstein,Motahhare Eslami,Lauren Wilcox,Leon A Gatys*

Main category: cs.AI

TL;DR: 提出了PersonaTeaming方法，通过在对抗提示生成中引入人物角色来增强自动化红队测试的效果，相比现有方法攻击成功率提升最高达144.1%


<details>
  <summary>Details</summary>
Motivation: 当前自动化红队测试方法忽视了测试者身份背景对测试策略的影响，无法充分发现AI模型潜在风险，需要将人物角色融入自动化测试过程

Method: 开发了基于"红队专家"和"普通AI用户"角色的提示变异方法，以及动态角色生成算法，并提出了新的"变异距离"度量指标

Result: 实验显示PersonaTeaming相比最先进的RainbowPlus方法，在保持提示多样性的同时，攻击成功率提升最高达144.1%

Conclusion: 人物角色变异能有效提升自动化红队测试效果，为探索自动化与人工红队测试的互补性提供了新方向

Abstract: Recent developments in AI governance and safety research have called for
red-teaming methods that can effectively surface potential risks posed by AI
models. Many of these calls have emphasized how the identities and backgrounds
of red-teamers can shape their red-teaming strategies, and thus the kinds of
risks they are likely to uncover. While automated red-teaming approaches
promise to complement human red-teaming by enabling larger-scale exploration of
model behavior, current approaches do not consider the role of identity. As an
initial step towards incorporating people's background and identities in
automated red-teaming, we develop and evaluate a novel method, PersonaTeaming,
that introduces personas in the adversarial prompt generation process to
explore a wider spectrum of adversarial strategies. In particular, we first
introduce a methodology for mutating prompts based on either "red-teaming
expert" personas or "regular AI user" personas. We then develop a dynamic
persona-generating algorithm that automatically generates various persona types
adaptive to different seed prompts. In addition, we develop a set of new
metrics to explicitly measure the "mutation distance" to complement existing
diversity measurements of adversarial prompts. Our experiments show promising
improvements (up to 144.1%) in the attack success rates of adversarial prompts
through persona mutation, while maintaining prompt diversity, compared to
RainbowPlus, a state-of-the-art automated red-teaming method. We discuss the
strengths and limitations of different persona types and mutation methods,
shedding light on future opportunities to explore complementarities between
automated and human red-teaming approaches.

</details>


### [39] [The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs](https://arxiv.org/abs/2509.03730)
*Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez*

Main category: cs.AI

TL;DR: 大语言模型在训练过程中显示出类似人格特质的行为趋向，但自我报告特质与实际行为存在明显脱节，人设插入影响表面特质表达但无法稳定改变行为


<details>
  <summary>Details</summary>
Motivation: 以往研究主要依赖简化的自我报告和启发式提问，缺乏行为验证。需要系统性地分析LLM人格特质的动态演化、预测效度和应急应对策略的影响

Method: 从三个维度系统分析LLM人格：(1)训练阶段中特质派生成和演化动态；(2)自我报告特质在行为任务中的预测效度；(3)目标干预如人设注入对自我报告和行为的影响

Result: 指令对齐显著稳定特质表达并增强特质相关性，但自我报告特质无法可靠预测行为，关联模式与人类数据存在差异。人设注入能够控制表面特质表达，但对实际行为影响微小或不一致

Conclusion: 研究挖掘了LLM表面特质表达与行为一致性之间的脱节，挐战了对LLM人格的偏见假设，强调在对齐和可解释性方面进行更深入评估的必要性

Abstract: Personality traits have long been studied as predictors of human
behavior.Recent advances in Large Language Models (LLMs) suggest similar
patterns may emerge in artificial systems, with advanced LLMs displaying
consistent behavioral tendencies resembling human traits like agreeableness and
self-regulation. Understanding these patterns is crucial, yet prior work
primarily relied on simplified self-reports and heuristic prompting, with
little behavioral validation. In this study, we systematically characterize LLM
personality across three dimensions: (1) the dynamic emergence and evolution of
trait profiles throughout training stages; (2) the predictive validity of
self-reported traits in behavioral tasks; and (3) the impact of targeted
interventions, such as persona injection, on both self-reports and behavior.
Our findings reveal that instructional alignment (e.g., RLHF, instruction
tuning) significantly stabilizes trait expression and strengthens trait
correlations in ways that mirror human data. However, these self-reported
traits do not reliably predict behavior, and observed associations often
diverge from human patterns. While persona injection successfully steers
self-reports in the intended direction, it exerts little or inconsistent effect
on actual behavior. By distinguishing surface-level trait expression from
behavioral consistency, our findings challenge assumptions about LLM
personality and underscore the need for deeper evaluation in alignment and
interpretability.

</details>


### [40] [Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation](https://arxiv.org/abs/2509.03736)
*James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang*

Main category: cs.AI

TL;DR: 这篇论文通过实验证明了大语言模型在人类实验研究中存在内部不一致性问题，无法真正替代真实参与者


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型是否能够作为真实参与者的替代品用于人类实验研究，而不仅仅是关注其生成的数据是否与人类相似

Method: 设计了一个研究方案，包括(a)揭示模型的内部状态，(b)在基础对话环境中观察模型行为，通过一系列行为假设来评估其内部一致性

Result: 在不同模型家族和不同模型大小上都发现了显著的内部不一致性，虽然模型可能生成与人类相似的响应，但在不同实验设置下行为不一致

Conclusion: 大语言模型在内部一致性方面存在严重缺陷，无法准确地替代真实参与者在人类实验研究中的作用

Abstract: The impressive capabilities of Large Language Models (LLMs) have fueled the
notion that synthetic agents can serve as substitutes for real participants in
human-subject research. In an effort to evaluate the merits of this claim,
social science researchers have largely focused on whether LLM-generated survey
data corresponds to that of a human counterpart whom the LLM is prompted to
represent. In contrast, we address a more fundamental question: Do agents
maintain internal consistency, retaining similar behaviors when examined under
different experimental settings? To this end, we develop a study designed to
(a) reveal the agent's internal state and (b) examine agent behavior in a basic
dialogue setting. This design enables us to explore a set of behavioral
hypotheses to assess whether an agent's conversation behavior is consistent
with what we would expect from their revealed internal state. Our findings on
these hypotheses show significant internal inconsistencies in LLMs across model
families and at differing model sizes. Most importantly, we find that, although
agents may generate responses matching those of their human counterparts, they
fail to be internally consistent, representing a critical gap in their
capabilities to accurately substitute for real participants in human-subject
research. Our simulation code and data are publicly accessible.

</details>


### [41] [RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs](https://arxiv.org/abs/2509.03768)
*Connor Walker,Koorosh Aslansefat,Mohammad Naveed Akram,Yiannis Papadopoulos*

Main category: cs.AI

TL;DR: RAGuard是一个增强的RAG框架，通过并行查询技术文档和安全文档索引，在海上风电维护中显著提升安全召回率从接近0%到50%以上，同时保持技术召回率在60%以上。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在海上风电维护等安全关键场景中处理高度专业化或意外情况时表现不佳，需要确保技术准确性和安全性的双重保障。

Method: 提出RAGuard框架，并行查询两个索引（技术手册和安全关键文档），为知识和安全分配单独的检索预算；开发SafetyClamp扩展，获取更大的候选池并进行硬钳位处理确保安全槽位保证。

Result: 在稀疏(BM25)、稠密(Dense Passage Retrieval)和混合检索范式下评估，安全召回率从RAG的接近0%提升到RAGuard的50%以上，技术召回率保持在60%以上。

Conclusion: RAGuard和SafetyClamp有潜力为关键维护场景中LLM驱动的决策支持系统建立安全保证的新标准。

Abstract: Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet
conventional Large Language Models (LLMs) often fail when confronted with
highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced
Retrieval-Augmented Generation (RAG) framework that explicitly integrates
safety-critical documents alongside technical manuals.By issuing parallel
queries to two indices and allocating separate retrieval budgets for knowledge
and safety, RAGuard guarantees both technical depth and safety coverage. We
further develop a SafetyClamp extension that fetches a larger candidate pool,
"hard-clamping" exact slot guarantees to safety. We evaluate across sparse
(BM25), dense (Dense Passage Retrieval) and hybrid retrieval paradigms,
measuring Technical Recall@K and Safety Recall@K. Both proposed extensions of
RAG show an increase in Safety Recall@K from almost 0\% in RAG to more than
50\% in RAGuard, while maintaining Technical Recall above 60\%. These results
demonstrate that RAGuard and SafetyClamp have the potential to establish a new
standard for integrating safety assurance into LLM-powered decision support in
critical maintenance contexts.

</details>


### [42] [Leveraging LLM-Based Agents for Intelligent Supply Chain Planning](https://arxiv.org/abs/2509.03811)
*Yongzhi Qi,Jiaheng Yin,Jianshen Zhang,Dongyang Geng,Zhengyu Chen,Hao Hu,Wei Qi,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: 基于大语言模型构建的供应链规划组件(SCPA)框架，能够理解领域知识、分解任务并生成基于证据的规划报告，在JD.com实际部署中有效提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 供应链规划涉及多个实体和多个环节，需要在环境变化中动态调整计划并确保解释性、效率和可靠性，这是一个实践性强且具有挑战性的问题。

Method: 构建了一个供应链规划组件(SCPA)框架，能够理解领域知识、理解运营商需求、分解任务、利用或创建新工具，并返回基于证据的规划报告。

Result: 在JD.com的实际场景中部署该框架，证明了LLM-agent在供应链中应用的可行性，有效减少了人工工作量，提高了准确性、库存可用性等关键指标。

Conclusion: 这项工作展示了大语言模型作为代理在供应链管理领域的应用潜力，为解决复杂的实际问题提供了新的工具和方法。

Abstract: In supply chain management, planning is a critical concept. The movement of
physical products across different categories, from suppliers to warehouse
management, to sales, and logistics transporting them to customers, entails the
involvement of many entities. It covers various aspects such as demand
forecasting, inventory management, sales operations, and replenishment. How to
collect relevant data from an e-commerce platform's perspective, formulate
long-term plans, and dynamically adjust them based on environmental changes,
while ensuring interpretability, efficiency, and reliability, is a practical
and challenging problem. In recent years, the development of AI technologies,
especially the rapid progress of large language models, has provided new tools
to address real-world issues. In this work, we construct a Supply Chain
Planning Agent (SCPA) framework that can understand domain knowledge,
comprehend the operator's needs, decompose tasks, leverage or create new tools,
and return evidence-based planning reports. We deploy this framework in
JD.com's real-world scenario, demonstrating the feasibility of LLM-agent
applications in the supply chain. It effectively reduced labor and improved
accuracy, stock availability, and other key metrics.

</details>


### [43] [Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning](https://arxiv.org/abs/2509.03817)
*Wei Yang,Jesse Thomason*

Main category: cs.AI

TL;DR: 提出了Meta-Policy Deliberation Framework (MPDF)和SoftRankPO算法，通过让LLM智能体学习元认知策略来提升多智能体推理性能，在数学和通用推理基准上取得4-5%的准确率提升


<details>
  <summary>Details</summary>
Motivation: 现有多智能体LLM系统采用固定的协作协议，忽视了智能体内部的审议能力，将其视为被动执行者，无法根据不确定性或置信度等内部认知状态调整策略

Method: MPDF框架让智能体学习去中心化的元认知动作策略（Persist、Refine、Concede），并开发SoftRankPO强化学习算法，通过基于平滑正态分位数映射的奖励排序来稳定训练过程

Result: 在五个数学和通用推理基准测试中，MPDF+SoftRankPO相比六种最先进的启发式和基于学习的多智能体推理算法，平均准确率绝对提升4-5%

Conclusion: 该工作提出了学习自适应元认知策略的新范式，将重点从设计固定协议转向学习动态审议策略，为多智能体LLM系统提供了新的发展方向

Abstract: Multi-agent systems of large language models (LLMs) show promise for complex
reasoning, but their effectiveness is often limited by fixed collaboration
protocols. These frameworks typically focus on macro-level orchestration while
overlooking agents' internal deliberative capabilities. This critical
meta-cognitive blindspot treats agents as passive executors unable to adapt
their strategy based on internal cognitive states like uncertainty or
confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where
agents learn a decentralized policy over a set of high-level meta-cognitive
actions: Persist, Refine, and Concede. To overcome the instability of
traditional policy gradients in this setting, we develop SoftRankPO, a novel
reinforcement learning algorithm. SoftRankPO stabilizes training by shaping
advantages based on the rank of rewards mapped through smooth normal quantiles,
making the learning process robust to reward variance. Experiments show that
MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across
five mathematical and general reasoning benchmarks compared to six
state-of-the-art heuristic and learning-based multi-agent reasoning algorithms.
Our work presents a paradigm for learning adaptive, meta-cognitive policies for
multi-agent LLM systems, shifting the focus from designing fixed protocols to
learning dynamic, deliberative strategies.

</details>


### [44] [What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models](https://arxiv.org/abs/2509.03827)
*Pierre Le Coz,Jia An Liu,Debarun Bhattacharjya,Georgina Curto,Serge Stinckwich*

Main category: cs.AI

TL;DR: 评估大语言模型在无家可归问题政策制定中与领域专家的一致性，开发包含四个地区政策选择的新基准，并通过基于代理的模型模拟社会影响


<details>
  <summary>Details</summary>
Motivation: LLMs在处理非结构化数据、探索灵活场景和处理多样化情境因素方面具有独特优势，可能为复杂的社会政策制定提供新见解，特别是在影响全球1.5亿人的无家可归问题上

Method: 开发包含南本德、巴塞罗那、约翰内斯堡和澳门四个地区政策选择的新基准，基于人类发展能力方法框架，建立自动化管道将基准政策连接到基于代理的模型，通过模拟社会场景探索政策影响

Result: 研究结果显示利用LLMs进行社会政策制定具有良好潜力，在引入负责任的安全护栏和情境校准后，LLMs能够以规模化替代政策的形式为人类提供有价值的见解

Conclusion: 通过与当地领域专家合作引入负责任的安全护栏和情境校准，LLMs可以为社会政策制定提供有价值的规模化见解

Abstract: Large language models (LLMs) are increasingly being adopted in high-stakes
domains. Their capacity to process vast amounts of unstructured data, explore
flexible scenarios, and handle a diversity of contextual factors can make them
uniquely suited to provide new insights for the complexity of social
policymaking. This article evaluates whether LLMs' are aligned with domain
experts (and among themselves) to inform social policymaking on the subject of
homelessness alleviation - a challenge affecting over 150 million people
worldwide. We develop a novel benchmark comprised of decision scenarios with
policy choices across four geographies (South Bend, USA; Barcelona, Spain;
Johannesburg, South Africa; Macau SAR, China). The policies in scope are
grounded in the conceptual framework of the Capability Approach for human
development. We also present an automated pipeline that connects the
benchmarked policies to an agent-based model, and we explore the social impact
of the recommended policies through simulated social scenarios. The paper
results reveal promising potential to leverage LLMs for social policy making.
If responsible guardrails and contextual calibrations are introduced in
collaboration with local domain experts, LLMs can provide humans with valuable
insights, in the form of alternative policies at scale.

</details>


### [45] [An Agentic Model Context Protocol Framework for Medical Concept Standardization](https://arxiv.org/abs/2509.03828)
*Jaerong Ahn,Andrew Wen,Nan Wang,Heling Jia,Zhiyi Yue,Sunyang Fu,Hongfang Liu*

Main category: cs.AI

TL;DR: 基于Model Context Protocol的无训练、防幽灵映射的OMOP CDM医学术语映射系统，通过外部资源调用提高映射准确性和效率


<details>
  <summary>Details</summary>
Motivation: OMOP CDM数据标准化过程中，源医学术语向标准概念的映射工作资源浪费且容易出错，而大语言模型存在幽灵映射问题不适合直接于临床部署

Method: 基于Model Context Protocol(MCP)标准化框架，让LLM能够与外部资源和工具进行交互，实现零训练、可解释的映射系统

Result: 系统显著提高了映射效率和准确性，支持实时词汇查找和结构化推理输出，适用于探索性和生产环境

Conclusion: 该方法为OMOP CDM数据标准化提供了一种高效、准确且无需训练的映射解决方案，免除了LLM幽灵映射的风险

Abstract: The Observational Medical Outcomes Partnership (OMOP) common data model (CDM)
provides a standardized representation of heterogeneous health data to support
large-scale, multi-institutional research. One critical step in data
standardization using OMOP CDM is the mapping of source medical terms to OMOP
standard concepts, a procedure that is resource-intensive and error-prone.
While large language models (LLMs) have the potential to facilitate this
process, their tendency toward hallucination makes them unsuitable for clinical
deployment without training and expert validation. Here, we developed a
zero-training, hallucination-preventive mapping system based on the Model
Context Protocol (MCP), a standardized and secure framework allowing LLMs to
interact with external resources and tools. The system enables explainable
mapping and significantly improves efficiency and accuracy with minimal effort.
It provides real-time vocabulary lookups and structured reasoning outputs
suitable for immediate use in both exploratory and production environments.

</details>


### [46] [A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai](https://arxiv.org/abs/2509.03830)
*Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng*

Main category: cs.AI

TL;DR: 一种多维度AI框架，利用多模态社交媒体数据分析上海历史街区游客感知，包括视觉重点、颜色主题和情感分析


<details>
  <summary>Details</summary>
Motivation: 理解游客对历史城市街区的感知，为可持续、以人为本的城市规划提供支撑

Method: 多模态AI框架，整合语义分割模型提取视觉重点、聚类方法提取主导颜色、混合情感分析（规则基础和多任务BERT模型）

Result: 发现视觉期望与实际环境存在差异，美学吸引力和情感响应存在空间差异，满意度在游客活动、建筑环境、服务设施和商业格式四个维度上有所不同

Conclusion: 该框架提供了一种整合的、数据驱动的方法来解码游客感知，为旅游业、遗产保护和公共空间设计的决策提供了有价值的见解

Abstract: Historic urban quarters play a vital role in preserving cultural heritage
while serving as vibrant spaces for tourism and everyday life. Understanding
how tourists perceive these environments is essential for sustainable,
human-centered urban planning. This study proposes a multidimensional
AI-powered framework for analyzing tourist perception in historic urban
quarters using multimodal data from social media. Applied to twelve historic
quarters in central Shanghai, the framework integrates focal point extraction,
color theme analysis, and sentiment mining. Visual focus areas are identified
from tourist-shared photos using a fine-tuned semantic segmentation model. To
assess aesthetic preferences, dominant colors are extracted using a clustering
method, and their spatial distribution across quarters is analyzed. Color
themes are further compared between social media photos and real-world street
views, revealing notable shifts. This divergence highlights potential gaps
between visual expectations and the built environment, reflecting both
stylistic preferences and perceptual bias. Tourist reviews are evaluated
through a hybrid sentiment analysis approach combining a rule-based method and
a multi-task BERT model. Satisfaction is assessed across four dimensions:
tourist activities, built environment, service facilities, and business
formats. The results reveal spatial variations in aesthetic appeal and
emotional response. Rather than focusing on a single technical innovation, this
framework offers an integrated, data-driven approach to decoding tourist
perception and contributes to informed decision-making in tourism, heritage
conservation, and the design of aesthetically engaging public spaces.

</details>


### [47] [Continuous Monitoring of Large-Scale Generative AI via Deterministic Knowledge Graph Structures](https://arxiv.org/abs/2509.03857)
*Kishor Datta Gupta,Mohd Ariful Haque,Hasmot Ali,Marufa Kamal,Syed Bahauddin Alam,Mohammad Ashiqur Rahman*

Main category: cs.AI

TL;DR: 通过构建确定性知识图和LLM生成知识图的对比监控，提出了一种系统化的方法来评估生成式AI的可靠性，可以实时检测语义异常和幻觉现象


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI模型的可靠性问题（如幻觉、语义偏移、偏见），充当黑盒模型导致评估困难，以及依赖主观人工评估的限制

Method: 构建两个并行知识图：确定性KG（使用规则基础方法、预定义本体论、领域词典和结构化实体关系提取规则）和LLM生成KG（来自实时文本数据流），使用KG指标（ICR、IPR、CI）量化结构偏移和语义差异，通过历史结构指标分布设置动态异常阈值

Result: 开发了一个自动化实时监控框架，能够连续计算确定性KG与LLM生成KG之间的偏移，主动识别和标记显著异常，及时发现语义异常或幻觉现象

Conclusion: 通过结构化、指标驱动的确定性KG与动态生成KG的对比，提供了一个健壁、可扩展的生成式AI可靠性评估框架，充分利用实时新闻流确保真实性并减轻偏见

Abstract: Generative AI (GEN AI) models have revolutionized diverse application domains
but present substantial challenges due to reliability concerns, including
hallucinations, semantic drift, and inherent biases. These models typically
operate as black-boxes, complicating transparent and objective evaluation.
Current evaluation methods primarily depend on subjective human assessment,
limiting scalability, transparency, and effectiveness. This research proposes a
systematic methodology using deterministic and Large Language Model
(LLM)-generated Knowledge Graphs (KGs) to continuously monitor and evaluate GEN
AI reliability. We construct two parallel KGs: (i) a deterministic KG built
using explicit rule-based methods, predefined ontologies, domain-specific
dictionaries, and structured entity-relation extraction rules, and (ii) an
LLM-generated KG dynamically derived from real-time textual data streams such
as live news articles. Utilizing real-time news streams ensures authenticity,
mitigates biases from repetitive training, and prevents adaptive LLMs from
bypassing predefined benchmarks through feedback memorization. To quantify
structural deviations and semantic discrepancies, we employ several established
KG metrics, including Instantiated Class Ratio (ICR), Instantiated Property
Ratio (IPR), and Class Instantiation (CI). An automated real-time monitoring
framework continuously computes deviations between deterministic and
LLM-generated KGs. By establishing dynamic anomaly thresholds based on
historical structural metric distributions, our method proactively identifies
and flags significant deviations, thus promptly detecting semantic anomalies or
hallucinations. This structured, metric-driven comparison between deterministic
and dynamically generated KGs delivers a robust and scalable evaluation
framework.

</details>


### [48] [Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata](https://arxiv.org/abs/2509.03863)
*Sina Khajehabdollahi,Gautier Hamon,Marko Cvjetko,Pierre-Yves Oudeyer,Clément Moulin-Frier,Cédric Colas*

Main category: cs.AI

TL;DR: 提出E&E混合策略，结合局部新颖性搜索和基于VLM的目标导向探索，在连续细胞自动机中发现更多样化的视觉模式


<details>
  <summary>Details</summary>
Motivation: 传统新颖性搜索方法在局部新颖性耗尽时容易陷入停滞，无法探索遥远未开发区域，需要新的探索策略来突破局部边界

Method: E&E策略交替进行局部新颖性驱动的扩展和基于视觉语言模型生成语言目标的目标导向远征，在语义空间中进行概念上有意义的探索

Result: 在Flow Lenia连续细胞自动机上测试，E&E比现有方法发现更多样化解决方案，远征产生的解决方案对长期探索影响更大

Conclusion: E&E能够突破局部新颖性边界，以人类可理解的方式探索行为空间，为人工生命等领域的开放式探索提供了有前景的模板

Abstract: Discovering diverse visual patterns in continuous cellular automata (CA) is
challenging due to the vastness and redundancy of high-dimensional behavioral
spaces. Traditional exploration methods like Novelty Search (NS) expand locally
by mutating known novel solutions but often plateau when local novelty is
exhausted, failing to reach distant, unexplored regions. We introduce
Expedition and Expansion (E&E), a hybrid strategy where exploration alternates
between local novelty-driven expansions and goal-directed expeditions. During
expeditions, E&E leverages a Vision-Language Model (VLM) to generate linguistic
goals--descriptions of interesting but hypothetical patterns that drive
exploration toward uncharted regions. By operating in semantic spaces that
align with human perception, E&E both evaluates novelty and generates goals in
conceptually meaningful ways, enhancing the interpretability and relevance of
discovered behaviors. Tested on Flow Lenia, a continuous CA known for its rich,
emergent behaviors, E&E consistently uncovers more diverse solutions than
existing exploration methods. A genealogical analysis further reveals that
solutions originating from expeditions disproportionately influence long-term
exploration, unlocking new behavioral niches that serve as stepping stones for
subsequent search. These findings highlight E&E's capacity to break through
local novelty boundaries and explore behavioral landscapes in human-aligned,
interpretable ways, offering a promising template for open-ended exploration in
artificial life and beyond.

</details>


### [49] [FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace](https://arxiv.org/abs/2509.03890)
*Yineng Yan,Xidong Wang,Jin Seng Cheng,Ran Hu,Wentao Guan,Nahid Farahmand,Hengte Lin,Yue Li*

Main category: cs.AI

TL;DR: 基于大语言模型的人工智能助所FaMA，通过自然语言交互简化C2C电子商务平台操作，实现了2倍操作速度提升和98%任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决C2C电子商务平台复杂GUI界面导致的用户体验问题，简化买家和卖家的交互流程。

Method: 设计了基于LLM的主动式助所FaMA，将传统GUI交互转换为自然语言对话模式，支持商品上下架、批量消息和会话式搜索等功能。

Result: 实验结果显示FaMA在复杂任务上达到98%成功率，操作时间提升达2倍，为用户提供了更高效的平台管理方式。

Conclusion: 以人工智能助所为入口的会话式交互模式是传统应用界面的轻量代替方案，能够显著提升用户效率和体验。

Abstract: The emergence of agentic AI, powered by Large Language Models (LLMs), marks a
paradigm shift from reactive generative systems to proactive, goal-oriented
autonomous agents capable of sophisticated planning, memory, and tool use. This
evolution presents a novel opportunity to address long-standing challenges in
complex digital environments. Core tasks on Consumer-to-Consumer (C2C)
e-commerce platforms often require users to navigate complex Graphical User
Interfaces (GUIs), making the experience time-consuming for both buyers and
sellers. This paper introduces a novel approach to simplify these interactions
through an LLM-powered agentic assistant. This agent functions as a new,
conversational entry point to the marketplace, shifting the primary interaction
model from a complex GUI to an intuitive AI agent. By interpreting natural
language commands, the agent automates key high-friction workflows. For
sellers, this includes simplified updating and renewal of listings, and the
ability to send bulk messages. For buyers, the agent facilitates a more
efficient product discovery process through conversational search. We present
the architecture for Facebook Marketplace Assistant (FaMA), arguing that this
agentic, conversational paradigm provides a lightweight and more accessible
alternative to traditional app interfaces, allowing users to manage their
marketplace activities with greater efficiency. Experiments show FaMA achieves
a 98% task success rate on solving complex tasks on the marketplace and enables
up to a 2x speedup on interaction time.

</details>


### [50] [A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning](https://arxiv.org/abs/2509.03906)
*Qika Lin,Yifan Zhu,Bin Pu,Ling Huang,Haoran Luo,Jingying Ma,Zhen Peng,Tianzhe Zhao,Fangzhi Xu,Jian Zhang,Kai He,Zhonghong Ou,Swapnil Mishra,Mengling Feng*

Main category: cs.AI

TL;DR: DeepMedix-R1是一个用于胸部X光片解读的医学基础模型，通过三阶段训练实现透明推理和局部可解释性，在报告生成和视觉问答任务上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前医学基础模型以黑盒方式生成答案，缺乏透明的推理过程和局部可解释性，阻碍了临床实际部署。

Method: 采用顺序训练流程：先在精选的CXR指令数据上微调获得基础解读能力，然后通过高质量合成推理样本实现冷启动推理，最后通过在线强化学习优化推理质量和生成性能。

Result: 在报告生成任务上比LLaVA-Rad和MedGemma分别提升14.54%和31.32%，在视觉问答任务上比MedGemma和CheXagent分别提升57.75%和23.06%。专家评审显示推理步骤的可解释性和临床合理性显著优于Qwen2.5-VL-7B模型。

Conclusion: 该工作推动了医学基础模型向整体性、透明性和临床可操作性方向发展，为CXR解读提供了更可靠的解决方案。

Abstract: Medical foundation models (FMs) have shown tremendous promise amid the rapid
advancements in artificial intelligence (AI) technologies. However, current
medical FMs typically generate answers in a black-box manner, lacking
transparent reasoning processes and locally grounded interpretability, which
hinders their practical clinical deployments. To this end, we introduce
DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It
leverages a sequential training pipeline: initially fine-tuned on curated CXR
instruction data to equip with fundamental CXR interpretation capabilities,
then exposed to high-quality synthetic reasoning samples to enable cold-start
reasoning, and finally refined via online reinforcement learning to enhance
both grounded reasoning quality and generation performance. Thus, the model
produces both an answer and reasoning steps tied to the image's local regions
for each query. Quantitative evaluation demonstrates substantial improvements
in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and
visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent)
tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking
framework using advanced language models to evaluate answer quality, further
highlighting the superiority of DeepMedix-R1. Expert review of generated
reasoning steps reveals greater interpretability and clinical plausibility
compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall
preference). Collectively, our work advances medical FM development toward
holistic, transparent, and clinically actionable modeling for CXR
interpretation.

</details>


### [51] [Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions](https://arxiv.org/abs/2509.03953)
*Ángel Aso-Mollar,Diego Aineto,Enrico Scala,Eva Onaindia*

Main category: cs.AI

TL;DR: 这篇论文提出了一种高效的搜索算法，将控制参数作为真正的决策点来处理，而非作为约束来待。该算法基于最优优先搜索和延迟部分扩展概念，能够在无限决策空间中进行系统搜索。


<details>
  <summary>Details</summary>
Motivation: 现有方法将控制参数作为嵌入式约束处理，而非将其视为搜索空间中的真正决策点。这使得控制参数的处理效率低下，需要一种更高效的方法来明确地将其作为决策变量来处理。

Method: 提出一种最优优先、含机器学习的搜索算法，在控制参数定义的无限决策空间中进行系统搜索。算法采用延迟部分扩展策略，逐步扩展状态的子集，而非一次性完全扩展。

Result: 证明了在某些条件下算法具有极限完备性。实验结果显示，这种新颖的搜索算法在解决含控制参数的规划问题时，与现有方法相比具有竞争力。

Conclusion: 该研究提供了一种高效的替代方案，通过明确将控制参数作为真正决策点来处理，显著提高了含控制参数规划问题的解决效率。

Abstract: In automated planning, control parameters extend standard action
representations through the introduction of continuous numeric decision
variables. Existing state-of-the-art approaches have primarily handled control
parameters as embedded constraints alongside other temporal and numeric
restrictions, and thus have implicitly treated them as additional constraints
rather than as decision points in the search space. In this paper, we propose
an efficient alternative that explicitly handles control parameters as true
decision points within a systematic search scheme. We develop a best-first,
heuristic search algorithm that operates over infinite decision spaces defined
by control parameters and prove a notion of completeness in the limit under
certain conditions. Our algorithm leverages the concept of delayed partial
expansion, where a state is not fully expanded but instead incrementally
expands a subset of its successors. Our results demonstrate that this novel
search algorithm is a competitive alternative to existing approaches for
solving planning problems involving control parameters.

</details>


### [52] [World Model Implanting for Test-time Adaptation of Embodied Agents](https://arxiv.org/abs/2509.03956)
*Minjong Yoo,Jinwoo Jang,Sihyung Yoon,Honguk Woo*

Main category: cs.AI

TL;DR: 提出了WorMI框架，通过测试时组合将LLM推理能力与领域特定世界模型结合，实现智能体在未见领域的零样本和少样本自适应


<details>
  <summary>Details</summary>
Motivation: 解决具身AI中智能体在新领域需要大量数据收集和重新训练的问题，实现跨域鲁棒自适应

Method: 采用原型化世界模型检索方法，基于轨迹的抽象表示匹配，开发世界级复合注意力机制来整合多世界模型知识并对齐表示

Result: 在VirtualHome和ALFWorld基准测试中表现出优于多个LLM方法的零样本和少样本性能

Conclusion: 该框架在需要适应性和数据效率的具身智能体场景中具有可扩展的实际部署潜力

Abstract: In embodied AI, a persistent challenge is enabling agents to robustly adapt
to novel domains without requiring extensive data collection or retraining. To
address this, we present a world model implanting framework (WorMI) that
combines the reasoning capabilities of large language models (LLMs) with
independently learned, domain-specific world models through test-time
composition. By allowing seamless implantation and removal of the world models,
the embodied agent's policy achieves and maintains cross-domain adaptability.
In the WorMI framework, we employ a prototype-based world model retrieval
approach, utilizing efficient trajectory-based abstract representation
matching, to incorporate relevant models into test-time composition. We also
develop a world-wise compound attention method that not only integrates the
knowledge from the retrieved world models but also aligns their intermediate
representations with the reasoning model's representation within the agent's
policy. This framework design effectively fuses domain-specific knowledge from
multiple world models, ensuring robust adaptation to unseen domains. We
evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating
superior zero-shot and few-shot performance compared to several LLM-based
approaches across a range of unseen domains. These results highlight the
frameworks potential for scalable, real-world deployment in embodied agent
scenarios where adaptability and data efficiency are essential.

</details>


### [53] [Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent](https://arxiv.org/abs/2509.03990)
*Chunlong Wu,Zhibo Qu*

Main category: cs.AI

TL;DR: 提出了Meta-Policy Reflexion (MPR)框架，通过结构化元策略记忆和双重推理机制，解决LLM智能体重复失败、探索效率低和跨任务适应性差的问题，无需模型权重更新即可实现知识重用和约束执行。


<details>
  <summary>Details</summary>
Motivation: 现有反思策略（如Reflexion、ReAct）产生的跟踪信息是临时性的、任务特定的，无法跨任务重用；而基于强化学习的方法需要大量参数更新和计算资源。需要一种既能重用纠正知识又不需权重更新的方法。

Method: MPR框架将LLM生成的反思整合为结构化谓词式元策略记忆(MPM)，通过软内存引导解码和硬规则可接受性检查(HAC)两种机制在推理时应用记忆。

Result: 实验结果显示，与Reflexion基线相比，在执行准确性和鲁棒性方面获得一致提升，规则可接受性检查进一步提高了稳定性。

Conclusion: MPR能够外部化可重用纠正知识、强制执行领域约束，同时保持基于语言的反思的适应性，为多模态和多智能体扩展提供了方向。

Abstract: Large language model (LLM) agents achieve impressive single-task performance
but commonly exhibit repeated failures, inefficient exploration, and limited
cross-task adaptability. Existing reflective strategies (e.g., Reflexion,
ReAct) improve per-episode behavior but typically produce ephemeral,
task-specific traces that are not reused across tasks. Reinforcement-learning
based alternatives can produce transferable policies but require substantial
parameter updates and compute. In this work we introduce Meta-Policy Reflexion
(MPR): a hybrid framework that consolidates LLM-generated reflections into a
structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at
inference time through two complementary mechanisms soft memory-guided decoding
and hard rule admissibility checks(HAC). MPR (i) externalizes reusable
corrective knowledge without model weight updates, (ii) enforces domain
constraints to reduce unsafe or invalid actions, and (iii) retains the
adaptability of language-based reflection. We formalize the MPM representation,
present algorithms for update and decoding, and validate the approach in a
text-based agent environment following the experimental protocol described in
the provided implementation (AlfWorld-based). Empirical results reported in the
supplied material indicate consistent gains in execution accuracy and
robustness when compared to Reflexion baselines; rule admissibility further
improves stability. We analyze mechanisms that explain these gains, discuss
scalability and failure modes, and outline future directions for multimodal and
multi?agent extensions.

</details>


### [54] [AutoPBO: LLM-powered Optimization for Local Search PBO Solvers](https://arxiv.org/abs/2509.04007)
*Jinyuan Li,Yi Chu,Yiwen Sun,Mengchuan Zou,Shaowei Cai*

Main category: cs.AI

TL;DR: AutoPBO是一个基于大语言模型的框架，用于自动优化伪布尔优化(PBO)局部搜索求解器，在多个基准测试中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 伪布尔优化是组合问题建模的强大框架，局部搜索求解器性能优异但设计需要大量专家经验和手动调优。大语言模型在算法设计自动化方面展现潜力，但在优化PBO求解器方面尚未探索。

Method: 提出了AutoPBO框架，利用大语言模型自动增强PBO局部搜索求解器，在四个公共基准测试上进行实验评估。

Result: AutoPBO相比之前的局部搜索方法有显著改进，与六种最先进竞争对手相比保持竞争力，包括NuPBO、OraSLS、PBO-IHS、RoundingSat、Gurobi和SCIP。

Conclusion: AutoPBO为自动化局部搜索求解器设计提供了一种有前景的方法。

Abstract: Pseudo-Boolean Optimization (PBO) provides a powerful framework for modeling
combinatorial problems through pseudo-Boolean (PB) constraints. Local search
solvers have shown excellent performance in PBO solving, and their efficiency
is highly dependent on their internal heuristics to guide the search. Still,
their design often requires significant expert effort and manual tuning in
practice. While Large Language Models (LLMs) have demonstrated potential in
automating algorithm design, their application to optimizing PBO solvers
remains unexplored. In this work, we introduce AutoPBO, a novel LLM-powered
framework to automatically enhance PBO local search solvers. We conduct
experiments on a broad range of four public benchmarks, including one
real-world benchmark, a benchmark from PB competition, an integer linear
programming optimization benchmark, and a crafted combinatorial benchmark, to
evaluate the performance improvement achieved by AutoPBO and compare it with
six state-of-the-art competitors, including two local search PBO solvers NuPBO
and OraSLS, two complete PB solvers PBO-IHS and RoundingSat, and two mixed
integer programming (MIP) solvers Gurobi and SCIP. AutoPBO demonstrates
significant improvements over previous local search approaches, while
maintaining competitive performance compared to state-of-the-art competitors.
The results suggest that AutoPBO offers a promising approach to automating
local search solver design.

</details>


### [55] [CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.04027)
*Zeyu Gan,Hao Yi,Yong Liu*

Main category: cs.AI

TL;DR: CoT-Space框架将LLM推理重新定义为连续语义空间中的优化过程，从噪声和风险角度分析，证明了最优CoT长度的收敛是欠拟合与过拟合权衡的自然结果。


<details>
  <summary>Details</summary>
Motivation: 传统token级RL框架无法与多步推理过程（如Chain-of-Thought）的推理级性质对齐，存在显著理论空白。

Method: 引入CoT-Space理论框架，将LLM推理从离散token预测任务重新构建为连续推理级语义空间中的优化过程，从噪声和风险两个角度进行分析。

Result: 理论分析表明最优CoT长度的收敛是欠拟合与过拟合权衡的自然结果，大量实验为理论发现提供了强有力实证验证。

Conclusion: 该框架不仅为过思考等经验现象提供了连贯解释，还为开发更有效和可泛化推理代理的未来发展奠定了坚实理论基础。

Abstract: Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought processes
like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,
a novel theoretical framework that recasts LLM reasoning from a discrete
token-prediction task to an optimization process within a continuous,
reasoning-level semantic space. By analyzing this process from both a noise
perspective and a risk perspective, we demonstrate that the convergence to an
optimal CoT length is a natural consequence of the fundamental trade-off
between underfitting and overfitting. Furthermore, extensive experiments
provide strong empirical validation for our theoretical findings. Our framework
not only provides a coherent explanation for empirical phenomena such as
overthinking but also offers a solid theoretical foundation to guide the future
development of more effective and generalizable reasoning agents.

</details>


### [56] [Oruga: An Avatar of Representational Systems Theory](https://arxiv.org/abs/2509.04041)
*Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng*

Main category: cs.AI

TL;DR: Oruga是一个实现表示系统理论(RST)的系统，包含核心数据结构、通信语言和结构转换引擎，旨在让机器具备人类灵活使用表示的能力


<details>
  <summary>Details</summary>
Motivation: 人类能够灵活使用各种表示形式（如图表、类比等），希望让机器也具备这种能力以更好地与人类协作

Method: 基于表示系统理论(RST)，开发了Oruga系统，包含核心数据结构、专用通信语言和结构转换引擎，采用结构转移方法进行表示转换

Result: 实现了Oruga系统的核心框架和语言，展示了结构转移方法能够执行的表示转换示例

Conclusion: Oruga系统为实现机器灵活表示转换提供了理论基础和实现框架，是向人机兼容性迈出的重要一步

Abstract: Humans use representations flexibly. We draw diagrams, change representations
and exploit creative analogies across different domains. We want to harness
this kind of power and endow machines with it to make them more compatible with
human use. Previously we developed Representational Systems Theory (RST) to
study the structure and transformations of representations. In this paper we
present Oruga (caterpillar in Spanish; a symbol of transformation), an
implementation of various aspects of RST. Oruga consists of a core of data
structures corresponding to concepts in RST, a language for communicating with
the core, and an engine for producing transformations using a method we call
structure transfer. In this paper we present an overview of the core and
language of Oruga, with a brief example of the kind of transformation that
structure transfer can execute.

</details>


### [57] [Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning](https://arxiv.org/abs/2509.04083)
*Alexander Beiser,David Penz,Nysret Musliu*

Main category: cs.AI

TL;DR: 本文研究发现，在神经符号LLM推理中，形式语言的选择是一个被忽视但关键的因素，不同形式语言对LLM的语法和语义推理能力有显著影响。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在多种任务上表现优异，但其形式推理能力仍然不足。神经符号LLM推理方法使用LLM作为自然语言到形式语言的翻译器，但该方法成功的关键因素尚不明确。

Method: 通过比较四种形式语言在三个数据集和七个LLM上的表现，分析形式语言选择对神经符号推理的影响。

Result: 研究发现形式语言的选择显著影响LLM的语法和语义推理能力，且不同LLM受到的影响程度不同。

Conclusion: 形式语言的选择是神经符号LLM推理成功的关键因素之一，需要根据具体任务和模型特性进行精心选择。

Abstract: Large language models (LLMs) achieve astonishing results on a wide range of
tasks. However, their formal reasoning ability still lags behind. A promising
approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators
from natural to formal languages and symbolic solvers for deriving correct
results. Still, the contributing factors to the success of Neurosymbolic LLM
reasoning remain unclear. This paper demonstrates that one previously
overlooked factor is the choice of the formal language. We introduce the
intermediate language challenge: selecting a suitable formal language for
neurosymbolic reasoning. By comparing four formal languages across three
datasets and seven LLMs, we show that the choice of formal language affects
both syntactic and semantic reasoning capabilities. We also discuss the varying
effects across different LLMs.

</details>


### [58] [Hybrid Reinforcement Learning and Search for Flight Trajectory Planning](https://arxiv.org/abs/2509.04100)
*Alberto Luise,Michele Lombardi,Florent Teichteil Koenigsbuch*

Main category: cs.AI

TL;DR: 结合强化学习和搜索路径规划，通过RL智能体预计算近似最优路径来约束求解器搜索空间，在保持燃油消耗几乎不变（偏差<1%）的同时，将计算速度提升高达50%


<details>
  <summary>Details</summary>
Motivation: 在紧急情况下需要快速重新计算航班路径，传统求解器计算速度较慢，需要一种能够加速路径优化同时保持接近最优解的方法

Method: 训练RL智能体基于位置和大气数据预计算近似最优路径，运行时用这些路径约束底层路径规划求解器的搜索空间

Result: 燃油消耗与传统无约束求解器几乎相同（偏差通常在1%以内），计算速度相比传统求解器单独使用提升高达50%

Conclusion: 该方法能有效加速航班路径优化，在保持接近最优解的同时显著提高计算效率，特别适用于需要快速路径重计算的紧急情况

Abstract: This paper explores the combination of Reinforcement Learning (RL) and
search-based path planners to speed up the optimization of flight paths for
airliners, where in case of emergency a fast route re-calculation can be
crucial. The fundamental idea is to train an RL Agent to pre-compute
near-optimal paths based on location and atmospheric data and use those at
runtime to constrain the underlying path planning solver and find a solution
within a certain distance from the initial guess. The approach effectively
reduces the size of the solver's search space, significantly speeding up route
optimization. Although global optimality is not guaranteed, empirical results
conducted with Airbus aircraft's performance models show that fuel consumption
remains nearly identical to that of an unconstrained solver, with deviations
typically within 1%. At the same time, computation speed can be improved by up
to 50% as compared to using a conventional solver alone.

</details>


### [59] [Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker](https://arxiv.org/abs/2509.04125)
*Tarik Zaciragic,Aske Plaat,K. Joost Batenburg*

Main category: cs.AI

TL;DR: 研究DQN和CFR算法在Leduc Hold'em扑克游戏中是否表现出虚张声势（bluffing）行为，发现两种算法都表现出虚张声势但方式不同，成功虚张声势的比例大致相同


<details>
  <summary>Details</summary>
Motivation: 在扑克游戏中，虚张声势是不可预测性的重要技能，但现有计算机扑克研究多关注胜率等性能指标，而忽略了虚张声势行为的研究

Method: 设计实验让基于强化学习的DQN算法和基于博弈论的CFR算法在Leduc Hold'em游戏中相互对战，记录并分析它们的行动

Result: DQN和CFR都表现出虚张声势行为，但方式不同；虽然尝试虚张声势的频率不同，但成功让对手弃牌的比例大致相同

Conclusion: 虚张声势是游戏本身的基本要素，而非特定算法的特性；未来研究应关注不同的虚张声势风格和完整扑克游戏

Abstract: In the game of poker, being unpredictable, or bluffing, is an essential
skill. When humans play poker, they bluff. However, most works on
computer-poker focus on performance metrics such as win rates, while bluffing
is overlooked. In this paper we study whether two popular algorithms, DQN
(based on reinforcement learning) and CFR (based on game theory), exhibit
bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed
an experiment where we let the DQN and CFR agent play against each other while
we log their actions. We find that both DQN and CFR exhibit bluffing behavior,
but they do so in different ways. Although both attempt to perform bluffs at
different rates, the percentage of successful bluffs (where the opponent folds)
is roughly the same. This suggests that bluffing is an essential aspect of the
game, not of the algorithm. Future work should look at different bluffing
styles and at the full game of poker. Code at
https://github.com/TarikZ03/Bluffing-by-DQN-and-CFR-in-Leduc-Hold-em-Poker-Codebase.

</details>


### [60] [The human biological advantage over AI](https://arxiv.org/abs/2509.04130)
*William Stewart*

Main category: cs.AI

TL;DR: 论文认为AI即使达到通用人工智能水平，也无法超越人类成为宇宙领导者，因为人类的中枢神经系统提供了与物理现实的沉浸式整合和情感体验，这是AI无法复制的关键差异。


<details>
  <summary>Details</summary>
Motivation: 探讨AI系统是否能够超越人类成为宇宙的合法领导者，分析人类与AI之间的根本差异。

Method: 通过哲学和神经科学的角度，比较人类中枢神经系统与AI系统的本质区别，论证情感体验和道德理解的重要性。

Result: 发现中枢神经系统提供的沉浸式现实体验和情感理解是人类独有的特质，这是AI无法通过制造或模拟获得的，因此人类在道德领导力方面具有不可替代的优势。

Conclusion: 即使AI在能力上超越人类，但基于DNA的生物构造和情感体验使人类始终是宇宙领导的最佳基础，而非硅基的AI系统。

Abstract: Recent advances in AI raise the possibility that AI systems will one day be
able to do anything humans can do, only better. If artificial general
intelligence (AGI) is achieved, AI systems may be able to understand, reason,
problem solve, create, and evolve at a level and speed that humans will
increasingly be unable to match, or even understand. These possibilities raise
a natural question as to whether AI will eventually become superior to humans,
a successor "digital species", with a rightful claim to assume leadership of
the universe. However, a deeper consideration suggests the overlooked
differentiator between human beings and AI is not the brain, but the central
nervous system (CNS), providing us with an immersive integration with physical
reality. It is our CNS that enables us to experience emotion including pain,
joy, suffering, and love, and therefore to fully appreciate the consequences of
our actions on the world around us. And that emotional understanding of the
consequences of our actions is what is required to be able to develop
sustainable ethical systems, and so be fully qualified to be the leaders of the
universe. A CNS cannot be manufactured or simulated; it must be grown as a
biological construct. And so, even the development of consciousness will not be
sufficient to make AI systems superior to humans. AI systems may become more
capable than humans on almost every measure and transform our society. However,
the best foundation for leadership of our universe will always be DNA, not
silicon.

</details>


### [61] [Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs](https://arxiv.org/abs/2509.04159)
*Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das*

Main category: cs.AI

TL;DR: 提出了一种可扩展的域特定语言（DSL），通过有向动作图表示烹饪操作流程，实现对复杂燕饪过程的精确模型化


<details>
  <summary>Details</summary>
Motivation: 烹饪操作流程具有内在的复杂性和模糊性，需要一种结构化的方法来正式化表示烹饪程序

Method: 设计了一种可扩展的域特定语言，将食谱表示为有向动作图，包含过程、传输、环境、并发性和组合结构

Result: 通过对英式全套早餐食谱的初步手动评估，证明了该DSL的表达能力和适用性

Conclusion: 这项工作是构建以动作为中心的烹饪本体论的初步措施，利用时间图实现结构化的机器理解、精确解释和可扩展的烹饪过程自动化

Abstract: Formalizing cooking procedures remains a challenging task due to their
inherent complexity and ambiguity. We introduce an extensible domain-specific
language for representing recipes as directed action graphs, capturing
processes, transfers, environments, concurrency, and compositional structure.
Our approach enables precise, modular modeling of complex culinary workflows.
Initial manual evaluation on a full English breakfast recipe demonstrates the
DSL's expressiveness and suitability for future automated recipe analysis and
execution. This work represents initial steps towards an action-centric
ontology for cooking, using temporal graphs to enable structured machine
understanding, precise interpretation, and scalable automation of culinary
processes - both in home kitchens and professional culinary settings.

</details>


### [62] [Domain size asymptotics for Markov logic networks](https://arxiv.org/abs/2509.04192)
*Vera Koponen*

Main category: cs.AI

TL;DR: 该论文研究马尔可夫逻辑网络(MLN)在域大小趋于无穷时的分布特性，分析了三种具体MLN示例的极限行为，发现软约束权重对极限行为的影响不同，并证明了量化自由MLN与提升贝叶斯网络的渐近不可比性。


<details>
  <summary>Details</summary>
Motivation: 研究MLN在无限大域上的分布特性，探索不同软约束对随机结构极限行为的影响，以及比较不同概率图模型的表达能力。

Method: 通过分析三种具体MLN示例：(1)单一元关系符号的量化自由MLN；(2)偏好较少三角形的图MLN；(3)偏好较少高度数顶点的图MLN，研究其在大域极限下的行为特性。

Result: 发现软约束权重对极限行为的影响因MLN类型而异，证明了量化自由MLN与提升贝叶斯网络在渐近意义下不可比，且MLN在大域上的分布与均匀分布集中在完全不同的可能世界空间区域。

Conclusion: MLN的极限行为取决于所使用的软约束类型，不同形式化方法在表达能力上存在本质差异，这为理解概率图模型的理论性质提供了重要见解。

Abstract: A Markov logic network (MLN) determines a probability distribution on the set
of structures, or ``possible worlds'', with an arbitrary finite domain. We
study the properties of such distributions as the domain size tends to
infinity. Three types of concrete examples of MLNs will be considered, and the
properties of random structures with domain sizes tending to infinity will be
studied: (1) Arbitrary quantifier-free MLNs over a language with only one
relation symbol which has arity 1. In this case we give a pretty complete
characterization of the possible limit behaviours of random structures. (2) An
MLN that favours graphs with fewer triangles (or more generally, fewer
k-cliques). As a corollary of the analysis a ``$\delta$-approximate 0-1 law''
for first-order logic is obtained. (3) An MLN that favours graphs with fewer
vertices with degree higher than a fixed (but arbitrary) number. The analysis
shows that depending on which ``soft constraints'' an MLN uses the limit
behaviour of random structures can be quite different, and the weights of the
soft constraints may, or may not, have influence on the limit behaviour. It
will also be demonstrated, using (1), that quantifier-free MLNs and lifted
Bayesian networks (in a broad sense) are asymptotically incomparable, roughly
meaning that there is a sequence of distributions on possible worlds with
increasing domain sizes that can be defined by one of the formalisms but not
even approximated by the other. In a rather general context it is also shown
that on large domains the distribution determined by an MLN concentrates almost
all its probability mass on a totally different part of the space of possible
worlds than the uniform distribution does.

</details>


### [63] [Evaluating Quality of Gaming Narratives Co-created with AI](https://arxiv.org/abs/2509.04239)
*Arturo Valdivia,Paolo Burelli*

Main category: cs.AI

TL;DR: 一种结构化方法，利用Delphi研究和Kano模型来评估AI生成游戏故事的质量，以指导游戏开发者优先考虑满意度影响因素


<details>
  <summary>Details</summary>
Motivation: 为了系统化地评估AI生成游戏故事的质量，并为游戏开发者提供优先级指南，以提高游戏故事的满意度

Method: 采用Delphi研究结构，组织故事设计专家对话，综合文献中的故事质量维度，并通过Kano模型框架分析对玩家满意度的影响

Result: 得到了一套结构化的评估方法，能够识别和优先考虑各种故事质量维度对玩家满意度的关键影响

Conclusion: 该方法为游戏开发者提供了一个实用的框架，可以在与生成式AI共同创作游戏故事时有效地优先考虑质量因素，提升玩家体验

Abstract: This paper proposes a structured methodology to evaluate AI-generated game
narratives, leveraging the Delphi study structure with a panel of narrative
design experts. Our approach synthesizes story quality dimensions from
literature and expert insights, mapping them into the Kano model framework to
understand their impact on player satisfaction. The results can inform game
developers on prioritizing quality aspects when co-creating game narratives
with generative AI.

</details>


### [64] [EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation](https://arxiv.org/abs/2509.04310)
*Yunbo Long,Liming Xu,Lukas Beckenbauer,Yuhan Liu,Alexandra Brintrup*

Main category: cs.AI

TL;DR: EvoEmo是一个进化强化学习框架，通过优化动态情绪表达来提升LLM在多轮谈判中的表现，解决了现有模型忽视情绪功能作用的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在复杂多轮谈判中忽视了情绪的功能性作用，仅生成被动、偏好驱动的情绪响应，使其容易受到对手操纵和战略利用。

Method: 使用进化强化学习框架，将情绪状态转换建模为马尔可夫决策过程，并采用基于种群的遗传优化来演化高奖励情绪策略。提出了包含普通策略和固定情绪策略的评估基准。

Result: EvoEmo在广泛实验和消融研究中始终优于两个基线方法，实现了更高的成功率、更高效率和更多买家节省。

Conclusion: 自适应情绪表达对于实现更有效的多轮谈判LLM代理至关重要，EvoEmo框架为此提供了有效解决方案。

Abstract: Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models
(LLMs) has demonstrated that agents can engage in \textit{complex},
\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,
existing LLM agents largely overlook the functional role of emotions in such
negotiations, instead generating passive, preference-driven emotional responses
that make them vulnerable to manipulation and strategic exploitation by
adversarial counterparts. To address this gap, we present EvoEmo, an
evolutionary reinforcement learning framework that optimizes dynamic emotional
expression in negotiations. EvoEmo models emotional state transitions as a
Markov Decision Process and employs population-based genetic optimization to
evolve high-reward emotion policies across diverse negotiation scenarios. We
further propose an evaluation framework with two baselines -- vanilla
strategies and fixed-emotion strategies -- for benchmarking emotion-aware
negotiation. Extensive experiments and ablation studies show that EvoEmo
consistently outperforms both baselines, achieving higher success rates, higher
efficiency, and increased buyer savings. This findings highlight the importance
of adaptive emotional expression in enabling more effective LLM agents for
multi-turn negotiation.

</details>


### [65] [Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes](https://arxiv.org/abs/2509.04317)
*Isidoro Tamassia,Wendelin Böhmer*

Main category: cs.AI

TL;DR: AlphaZero框架在测试环境可能变化时的适应性改进研究，通过简单修改显著提升性能


<details>
  <summary>Details</summary>
Motivation: AlphaZero通常假设训练和测试环境不变，这限制了其实际应用。本文研究如何在测试环境可能变化的情况下部署AlphaZero智能体

Method: 对标准AlphaZero框架进行简单修改，结合蒙特卡洛规划和预训练策略-价值神经网络，在有限规划预算下提升性能

Result: 实验证明所提出的修改方法能够显著提升AlphaZero在变化测试环境中的性能表现

Conclusion: 通过简单的框架修改可以有效增强AlphaZero在环境变化场景下的适应能力，代码已在GitHub开源

Abstract: The AlphaZero framework provides a standard way of combining Monte Carlo
planning with prior knowledge provided by a previously trained policy-value
neural network. AlphaZero usually assumes that the environment on which the
neural network was trained will not change at test time, which constrains its
applicability. In this paper, we analyze the problem of deploying AlphaZero
agents in potentially changed test environments and demonstrate how the
combination of simple modifications to the standard framework can significantly
boost performance, even in settings with a low planning budget available. The
code is publicly available on GitHub.

</details>


### [66] [Psychologically Enhanced AI Agents](https://arxiv.org/abs/2509.04343)
*Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler*

Main category: cs.AI

TL;DR: MBTI-in-Thoughts框架通过MBTI人格类型提示工程，为LLM智能体注入心理学人格特质，无需微调即可控制其在认知和情感维度的行为表现，提升任务表现和可解释性。


<details>
  <summary>Details</summary>
Motivation: 将心理学人格理论融入LLM智能体设计，通过人格条件化来增强智能体的行为一致性和可解释性，同时探索多智能体交互中的结构化通信协议。

Method: 基于Myers-Briggs类型指标(MBTI)进行提示工程，为智能体注入不同人格原型，使用官方16Personalities测试进行特质持续性验证，并可推广到Big Five等其他心理学框架。

Result: 人格条件化在不同任务中产生一致的行为偏差：情感表达型智能体在叙事生成中表现优异，分析型智能体在博弈论设置中采用更稳定策略；自我反思能提升合作和推理质量。

Conclusion: 该框架成功将心理学理论与LLM行为设计结合，为无需微调的心理增强AI智能体奠定了基础，展示了人格条件化在提升智能体性能和可解释性方面的潜力。

Abstract: We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases across diverse tasks: emotionally expressive
agents excel in narrative generation, while analytically primed agents adopt
more stable strategies in game-theoretic settings. Our framework supports
experimenting with structured multi-agent communication protocols and reveals
that self-reflection prior to interaction improves cooperation and reasoning
quality. To ensure trait persistence, we integrate the official 16Personalities
test for automated verification. While our focus is on MBTI, we show that our
approach generalizes seamlessly to other psychological frameworks such as Big
Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior
design, we establish a foundation for psychologically enhanced AI agents
without any fine-tuning.

</details>


### [67] [ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory](https://arxiv.org/abs/2509.04439)
*Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: 提出概念级记忆方法，从推理轨迹中抽象可重用模块，实现无需权重更新的测试时持续学习，在ARC-AGI基准上相对基线提升7.5%


<details>
  <summary>Details</summary>
Motivation: 现有推理时缩放技术产生的推理轨迹和洞察在上下文重置后即被丢弃，需要更可重用和可扩展的外部记忆系统

Method: 从解决方案轨迹中提取概念级抽象记忆，以自然语言存储，通过选择性检索和集成到提示中实现测试时持续学习

Result: 在ARC-AGI基准上获得7.5%相对提升，性能随推理计算规模扩展，概念抽象记忆在所有测试规模上都优于基线

Conclusion: 概念级记忆设计是最一致有效的，动态更新记忆在测试时表现优于固定记忆设置，支持通过解决更多问题和抽象更多模式实现自我改进

Abstract: While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g. exact query/response pairs, or
summaries tightly coupled with the original problem context) toward
concept-level memory: reusable, modular abstractions distilled from solution
traces and stored in natural language. For future queries, relevant concepts
are selectively retrieved and integrated into the prompt, enabling test-time
continual learning without weight updates. Our design introduces new strategies
for abstracting takeaways from rollouts and retrieving entries for new queries,
promoting reuse and allowing memory to expand with additional experiences. On
the challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over
a strong no-memory baseline with performance continuing to scale with inference
compute. We find abstract concepts to be the most consistent memory design,
outscoring the baseline at all tested inference compute scales. Moreover, we
confirm that dynamically updating memory during test-time outperforms an
otherwise identical fixed memory setting with additional attempts, supporting
the hypothesis that solving more problems and abstracting more patterns to
memory enables further solutions in a form of self-improvement. Code available
at https://github.com/matt-seb-ho/arc_memo.

</details>
