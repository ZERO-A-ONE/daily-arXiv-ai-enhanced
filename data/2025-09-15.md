<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 11]
- [cs.CR](#cs.CR) [Total: 15]
- [cs.AI](#cs.AI) [Total: 22]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints](https://arxiv.org/abs/2509.09853)
*Zhiyu Fan,Kirill Vasilevski,Dayi Lin,Boyuan Chen,Yihao Chen,Zhiqing Zhong,Jie M. Zhang,Pinjia He,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: SWE-Effi是一个新的评估框架，通过综合考虑准确性和资源消耗（token和时间）来重新评估AI系统在软件工程任务中的整体效能，发现模型集成效果、token雪球效应和昂贵失败模式是影响效能的关键因素。


<details>
  <summary>Details</summary>
Motivation: 现有AI软件工程排行榜（如SWE-bench）仅关注解决方案准确性，忽略了资源受限环境下的效能问题。任何AI系统不仅需要正确，还必须具备成本效益。

Method: 提出SWE-Effi多维度量标准，在SWE-bench基准的子集上重新评估流行的AI问题解决系统，综合考虑结果准确性和资源消耗（token和时间）的平衡。

Result: 发现AI系统效能不仅取决于框架本身，还取决于与基础模型的集成效果；识别出系统性挑战包括"token雪球"效应和"昂贵失败"模式；观察到token预算和时间预算下的效能存在明显权衡。

Conclusion: 需要综合考虑准确性和资源消耗来评估AI系统效能，模型集成质量是关键因素，资源效率对于实际部署和强化学习训练的可扩展性至关重要。

Abstract: The advancement of large language models (LLMs) and code agents has
demonstrated significant potential to assist software engineering (SWE) tasks,
such as autonomous issue resolution and feature addition. Existing AI for
software engineering leaderboards (e.g., SWE-bench) focus solely on solution
accuracy, ignoring the crucial factor of effectiveness in a
resource-constrained world. This is a universal problem that also exists beyond
software engineering tasks: any AI system should be more than correct - it must
also be cost-effective. To address this gap, we introduce SWE-Effi, a set of
new metrics to re-evaluate AI systems in terms of holistic effectiveness
scores. We define effectiveness as the balance between the accuracy of outcome
(e.g., issue resolve rate) and the resources consumed (e.g., token and time).
In this paper, we specifically focus on the software engineering scenario by
re-ranking popular AI systems for issue resolution on a subset of the SWE-bench
benchmark using our new multi-dimensional metrics. We found that AI system's
effectiveness depends not just on the scaffold itself, but on how well it
integrates with the base model, which is key to achieving strong performance in
a resource-efficient manner. We also identified systematic challenges such as
the "token snowball" effect and, more significantly, a pattern of "expensive
failures". In these cases, agents consume excessive resources while stuck on
unsolvable tasks - an issue that not only limits practical deployment but also
drives up the cost of failed rollouts during RL training. Lastly, we observed a
clear trade-off between effectiveness under the token budget and effectiveness
under the time budget, which plays a crucial role in managing project budgets
and enabling scalable reinforcement learning, where fast responses are
essential.

</details>


### [2] [From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem](https://arxiv.org/abs/2509.09873)
*James Jewitt,Hao Li,Bram Adams,Gopi Krishnan Rajbahadur,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 首个对Hugging Face数据集和模型许可证的结构化审计，发现开源AI生态中存在系统性许可证违规问题，35.5%模型到应用的转换会消除限制性许可证条款


<details>
  <summary>Details</summary>
Motivation: 隐藏的开源许可证冲突带来严重法律和道德风险，但缺乏数据驱动的理解，需要系统性分析许可证冲突的频率、来源和影响范围

Method: 对Hugging Face上364千个数据集、1.6百万个模型以及14万个GitHub项目进行许可证审计，并构建了可扩展的规则引擎来编码近200个SPDX和模型特定条款

Result: 发现35.5%的模型到应用转换会通过重新授权消除限制性许可证条款，规则引擎能解决86.4%的软件应用许可证冲突

Conclusion: 许可证遵循是开源AI领域的关键治理挑战，研究提供了支持自动化大规模遵规的数据和工具

Abstract: Hidden license conflicts in the open-source AI ecosystem pose serious legal
and ethical risks, exposing organizations to potential litigation and users to
undisclosed risk. However, the field lacks a data-driven understanding of how
frequently these conflicts occur, where they originate, and which communities
are most affected. We present the first end-to-end audit of licenses for
datasets and models on Hugging Face, as well as their downstream integration
into open-source software applications, covering 364 thousand datasets, 1.6
million models, and 140 thousand GitHub projects. Our empirical analysis
reveals systemic non-compliance in which 35.5% of model-to-application
transitions eliminate restrictive license clauses by relicensing under
permissive terms. In addition, we prototype an extensible rule engine that
encodes almost 200 SPDX and model-specific clauses for detecting license
conflicts, which can solve 86.4% of license conflicts in software applications.
To support future research, we release our dataset and the prototype engine.
Our study highlights license compliance as a critical governance challenge in
open-source AI and provides both the data and tools necessary to enable
automated, AI-aware compliance at scale.

</details>


### [3] [SLD-Spec: Enhancement LLM-assisted Specification Generation for Complex Loop Functions via Program Slicing and Logical Deletion](https://arxiv.org/abs/2509.09917)
*Zehan Chen,Long Zhang,Zhiwei Zhang,JingJing Zhang,Ruoyu Zhou,Yulong Shen,JianFeng Ma,Lin Yang*

Main category: cs.SE

TL;DR: SLD-Spec是一种针对复杂循环程序的LLM辅助规范生成方法，通过程序切片和逻辑删除两阶段显著提升规范的正确性、相关性和完整性


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的方法在处理包含复杂循环结构的程序时往往生成不相关的规范，且验证工具的严格证明义务和设计约束会导致不完整和模糊的规范

Method: 引入两个新阶段：1)切片阶段-将函数分解为包含独立循环结构的代码片段；2)逻辑删除阶段-基于LLM推理过滤错误候选规范

Result: 在简单数据集上比最先进的AutoSpec多验证5个程序，运行时间减少23.73%；在复杂循环数据集上95.1%的断言和90.91%的程序通过验证

Conclusion: 逻辑删除对提升规范正确性和相关性至关重要，程序切片对规范完整性贡献显著，SLD-Spec能有效处理复杂循环程序的规范生成问题

Abstract: Automatically generating formal specifications from program code can greatly
enhance the efficiency of program verification and enable end-to-end automation
from requirements to reliable software. However, existing LLM-based approaches
often struggle with programs that include complex loop structures, leading to
irrelevant specifications. Moreover, the rigorous proof obligations and design
constraints imposed by verification tools can further result in incomplete and
ambiguous specifications. To address these challenges, we propose SLD-Spec, an
LLM-assisted specification generation method tailored for programs with complex
loop constructs. SLD-Spec introduces two novel phases into the traditional
specification generation framework: (1) A slicing phase, which decomposes each
function into code fragments containing independent loop structures, thereby
reducing the complexity of specification generation; and (2) A logical deletion
phase, which applies LLM-based reasoning to filter out incorrect candidate
specifications--especially those not easily identified by verification
tool--while retaining valid ones. Experimental results show that on the simple
dataset, SLD-Spec successfully verifies five more programs than the
state-of-the-art AutoSpec and reduces runtime by 23.73%. To address the
limitations of existing research, we manually construct a dataset comprising
four categories of complex loop programs. On this dataset, SLD-Spec
significantly improves the correctness, relevance, and completeness of
generated specifications compared to baseline methods, enabling 95.1% of
assertions and 90.91% of programs to pass verification. Ablation studies
further reveal that logical deletion is critical for enhancing specification
correctness and relevance, while program slicing contributes significantly to
specification completeness. Our code and data are publicly available.

</details>


### [4] [WALL: A Web Application for Automated Quality Assurance using Large Language Models](https://arxiv.org/abs/2509.09918)
*Seyed Moein Abtahi,Akramul Azim*

Main category: cs.SE

TL;DR: WALL是一个集成SonarQube和大型语言模型的Web应用，通过三个模块自动化代码问题检测、修复和评估，在563个文件中处理7599个问题，有效减少人工工作量并保持高质量修复。


<details>
  <summary>Details</summary>
Motivation: 随着软件项目复杂度增加，代码问题数量和种类大幅增长，需要高效的自动化工具来处理问题检测、修复和评估。

Method: 开发WALL Web应用，集成SonarQube和LLMs（GPT-3.5 Turbo和GPT-4o），包含问题提取工具、代码问题修订器和代码比较工具三个模块。

Result: 在563个文件7599个问题上实验证明，WALL能有效减少人工工作量，保持高质量修订，混合使用经济型和先进LLMs可显著降低成本并提高修订率。

Conclusion: WALL展示了自动化代码质量管理的有效性，未来工作将集成开源LLMs并消除人工干预，实现完全自动化的代码质量管理。

Abstract: As software projects become increasingly complex, the volume and variety of
issues in code files have grown substantially. Addressing this challenge
requires efficient issue detection, resolution, and evaluation tools. This
paper presents WALL, a web application that integrates SonarQube and large
language models (LLMs) such as GPT-3.5 Turbo and GPT-4o to automate these
tasks. WALL comprises three modules: an issue extraction tool, code issues
reviser, and code comparison tool. Together, they enable a seamless pipeline
for detecting software issues, generating automated code revisions, and
evaluating the accuracy of revisions. Our experiments, conducted on 563 files
with over 7,599 issues, demonstrate WALL's effectiveness in reducing human
effort while maintaining high-quality revisions. Results show that employing a
hybrid approach of cost-effective and advanced LLMs can significantly lower
costs and improve revision rates. Future work aims to enhance WALL's
capabilities by integrating open-source LLMs and eliminating human
intervention, paving the way for fully automated code quality management.

</details>


### [5] [Toward Green Code: Prompting Small Language Models for Energy-Efficient Code Generation](https://arxiv.org/abs/2509.09947)
*Humza Ashraf,Syed Muhammad Danish,Zeeshan Sattar*

Main category: cs.SE

TL;DR: 研究通过提示工程提高小型语言模型在代码生成中的能源效率，发现Chain-of-Thought提示对某些模型有显著节能效果


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件开发中带来高能耗和碳踹痕问题，小型语言模型作为更可持续的替代方案

Method: 评估四个开源SLM模型在150道Python问题上的性能，测量运行时间、内存使用和能耗，比较四种提示策略（角色提示、零样本、少样本、Chain-of-Thought）

Result: CoT提示对Qwen2.5-Coder和StableCode-3B产生一致的节能效果，而CodeLlama-7B和Phi-3-Mini-4K在任何提示策略下都无法超过基准水平

Conclusion: 提示工程的好处取决于模型特性，细心设计的提示可以引导SLM向更绿色的软件开发发展

Abstract: There is a growing concern about the environmental impact of large language
models (LLMs) in software development, particularly due to their high energy
use and carbon footprint. Small Language Models (SLMs) offer a more sustainable
alternative, requiring fewer computational resources while remaining effective
for fundamental programming tasks. In this study, we investigate whether prompt
engineering can improve the energy efficiency of SLMs in code generation. We
evaluate four open-source SLMs, StableCode-Instruct-3B,
Qwen2.5-Coder-3B-Instruct, CodeLlama-7B-Instruct, and Phi-3-Mini-4K-Instruct,
across 150 Python problems from LeetCode, evenly distributed into easy, medium,
and hard categories. Each model is tested under four prompting strategies: role
prompting, zero-shot, few-shot, and chain-of-thought (CoT). For every generated
solution, we measure runtime, memory usage, and energy consumption, comparing
the results with a human-written baseline. Our findings show that CoT prompting
provides consistent energy savings for Qwen2.5-Coder and StableCode-3B, while
CodeLlama-7B and Phi-3-Mini-4K fail to outperform the baseline under any
prompting strategy. These results highlight that the benefits of prompting are
model-dependent and that carefully designed prompts can guide SLMs toward
greener software development.

</details>


### [6] [Development of Automated Software Design Document Review Methods Using Large Language Models](https://arxiv.org/abs/2509.09975)
*Takasaburo Fukuda,Takao Nakagawa,Keisuke Miyazaki,Susumu Tokumoto*

Main category: cs.SE

TL;DR: 使用LLM自动化软件设计文档评审过程，识别设计文档中的不一致性问题


<details>
  <summary>Details</summary>
Motivation: 自动化软件设计文档评审过程，提高评审效率和准确性，减轻人工评审负担

Method: 分析设计文档评审方法，整理11个评审视角，开发新技术使LLM能够理解包含表格数据的复杂设计文档，使用GPT评估不同设计文档间设计项和描述的一致性

Result: 确认LLM可以在评审过程中识别软件设计文档中的不一致性

Conclusion: LLM能够有效用于软件设计文档的自动化评审，特别是在识别不一致性方面表现出良好效果

Abstract: In this study, we explored an approach to automate the review process of
software design documents by using LLM. We first analyzed the review methods of
design documents and organized 11 review perspectives. Additionally, we
analyzed the issues of utilizing LLMs for these 11 review perspectives and
determined which perspectives can be reviewed by current general-purpose LLMs
instead of humans. For the reviewable perspectives, we specifically developed
new techniques to enable LLMs to comprehend complex design documents that
include table data. For evaluation, we conducted experiments using GPT to
assess the consistency of design items and descriptions across different design
documents in the design process used in actual business operations. Our results
confirmed that LLMs can be utilized to identify inconsistencies in software
design documents during the review process.

</details>


### [7] [Sustaining Research Software: A Fitness Function Approach](https://arxiv.org/abs/2509.10085)
*Philipp Zech,Irdin Pekaric*

Main category: cs.SE

TL;DR: 通过应用进化架构中的适应性函数概念，为科研软件定制自动化指标，提高其可发现性、可访问性、互操性和可重用性，以促进长期可持续性。


<details>
  <summary>Details</summary>
Motivation: 科研软件面临维护性差、适应性不足和潜在激测等长期可持续性挑战，需要主动控制措施来保障其持久科学影响。

Method: 采用进化架构中的适应性函数概念，定制一系列自动化持续评估的指标，重点关注FAIR原则（可发现、可访问、互操作、可重用），并将其集成到开发生命周期中。

Result: 案例研究和实验结果证明，该方法能够有效提升科研软件的长期FAIR性能，缩小短期项目开发与持久科学价值之间的差距。

Conclusion: 通过适应性函数推动模块化设计、全面文档、版本控制等最佳实践，可在科研社区培养可持续性文化，确保科研软件的长期生存能力和科学价值。

Abstract: The long-term sustainability of research software is a critical challenge, as
it usually suffers from poor maintainability, lack of adaptability, and
eventual obsolescence. This paper proposes a novel approach to addressing this
issue by leveraging the concept of fitness functions from evolutionary
architecture. Fitness functions are automated, continuously evaluated metrics
designed to ensure that software systems meet desired non-functional,
architectural qualities over time. We define a set of fitness functions
tailored to the unique requirements of research software, focusing on
findability, accessibility, interoperability and reusability (FAIR). These
fitness functions act as proactive safeguards, promoting practices such as
modular design, comprehensive documentation, version control, and compatibility
with evolving technological ecosystems. By integrating these metrics into the
development life cycle, we aim to foster a culture of sustainability within the
research community. Case studies and experimental results demonstrate the
potential of this approach to enhance the long-term FAIR of research software,
bridging the gap between ephemeral project-based development and enduring
scientific impact.

</details>


### [8] [Generating Energy-Efficient Code via Large-Language Models -- Where are we now?](https://arxiv.org/abs/2509.10099)
*Radu Apsan,Vincenzo Stoico,Michel Albonico,Rudra Dhar,Karthik Vaidhyanathan,Ivano Malavolta*

Main category: cs.SE

TL;DR: 大语言模型生成的Python代码在能耗效率方面与人类开发者存在差异，绿色软件专家的代码能耗效率最高


<details>
  <summary>Details</summary>
Motivation: 评估LLM生成的Python代码的能量效率，与人类开发者和绿色软件专家的代码进行对比

Method: 使用6个普遍LLM和4种提示技术，测试363个解决方案，在3种硬件平台上测量能量消耗，总计约36.7天

Result: 人类解决方案在服务器上能耗效率高出16%，在PC上LLM能耗效率高出25%，绿色软件专家代码在所有平台上能耗效率都最高（至30%）

Conclusion: 虽然LLM展现了较好的代码生成能力，但无法超越经验丰富的绿色软件开发者，人类专业知识在开发能效Python代码中仍至关重要

Abstract: Context. The rise of Large Language Models (LLMs) has led to their widespread
adoption in development pipelines. Goal. We empirically assess the energy
efficiency of Python code generated by LLMs against human-written code and code
developed by a Green software expert. Method. We test 363 solutions to 9 coding
problems from the EvoEval benchmark using 6 widespread LLMs with 4 prompting
techniques, and comparing them to human-developed solutions. Energy consumption
is measured on three different hardware platforms: a server, a PC, and a
Raspberry Pi for a total of ~881h (36.7 days). Results. Human solutions are 16%
more energy-efficient on the server and 3% on the Raspberry Pi, while LLMs
outperform human developers by 25% on the PC. Prompting does not consistently
lead to energy savings, where the most energy-efficient prompts vary by
hardware platform. The code developed by a Green software expert is
consistently more energy-efficient by at least 17% to 30% against all LLMs on
all hardware platforms. Conclusions. Even though LLMs exhibit relatively good
code generation capabilities, no LLM-generated code was more energy-efficient
than that of an experienced Green software developer, suggesting that as of
today there is still a great need of human expertise for developing
energy-efficient Python code.

</details>


### [9] [Stencil-Lifting: Hierarchical Recursive Lifting System for Extracting Summary of Stencil Kernel in Legacy Codes](https://arxiv.org/abs/2509.10236)
*Mingyi Li,Junmin Xiao,Siyan Chen,Hui Ma,Xi Chen,Peihua Bao,Liang Yuan,Guangming Tan*

Main category: cs.SE

TL;DR: Stencil-Lifting是一个自动将低级语言编写的模板内核转换为等效DSL实现的系统，通过分层递归提升理论和算法实现高效转换，相比现有系统速度提升显著。


<details>
  <summary>Details</summary>
Motivation: 针对现有验证提升系统在效率上的瓶颈，需要一种能够高效将遗留代码中的低级模板内核转换为现代DSL实现的方法，以弥合传统优化技术与现代DSL范式之间的差距。

Method: 提出分层递归提升理论，使用不变子图表示模板内核，每个顶点关联基于谓词的摘要；开发分层递归提升算法，通过收敛递归过程保证终止性，避免基于搜索的合成低效问题。

Result: 在两个不同测试套件的多样化模板基准和四个实际应用上评估，相比最先进的STNG和Dexter系统分别实现31.62倍和5.8倍的速度提升，同时保持完全语义等价。

Conclusion: Stencil-Lifting显著提高了低级模板内核到DSL实现的翻译效率，有效连接了传统优化技术和现代DSL范式。

Abstract: We introduce Stencil-Lifting, a novel system for automatically converting
stencil kernels written in low-level languages in legacy code into semantically
equivalent Domain-Specific Language (DSL) implementations. Targeting the
efficiency bottlenecks of existing verified lifting systems, Stencil-Lifting
achieves scalable stencil kernel abstraction through two key innovations.
First, we propose a hierarchical recursive lifting theory that represents
stencil kernels, structured as nested loops, using invariant subgraphs, which
are customized data dependency graphs that capture loop-carried computation and
structural invariants. Each vertex in the invariant subgraph is associated with
a predicate-based summary, encoding its computational semantics. By enforcing
self-consistency across these summaries, Stencil-Lifting ensures the derivation
of correct loop invariants and postconditions for nested loops, eliminating the
need for external verification. Second, we develop a hierarchical recursive
lifting algorithm that guarantees termination through a convergent recursive
process, avoiding the inefficiencies of search-based synthesis. The algorithm
efficiently derives the valid summaries of stencil kernels, and its
completeness is formally proven. We evaluate Stencil-Lifting on diverse stencil
benchmarks from two different suites and on four real-world applications.
Experimental results demonstrate that Stencil-Lifting achieves 31.62$\times$
and 5.8$\times$ speedups compared to the state-of-the-art verified lifting
systems STNG and Dexter, respectively, while maintaining full semantic
equivalence. Our work significantly enhances the translation efficiency of
low-level stencil kernels to DSL implementations, effectively bridging the gap
between legacy optimization techniques and modern DSL-based paradigms.

</details>


### [10] [Targeted Test Selection Approach in Continuous Integration](https://arxiv.org/abs/2509.10279)
*Pavel Plyusnin,Aleksey Antonov,Vasilii Ermakov,Aleksandr Khaybriev,Margarita Kikot,Ilseyar Alimova,Stanislav Moiseev*

Main category: cs.SE

TL;DR: T-TS是一种基于机器学习的工业测试选择方法，通过将代码提交表示为变更文件的词袋，避免使用覆盖率映射，显著提高了测试效率。


<details>
  <summary>Details</summary>
Motivation: 随着代码库扩展和测试套件增长，在高频率代码提交环境下，高效管理测试过程变得日益困难，需要更智能的测试选择方法。

Method: 使用机器学习方法，将代码提交表示为变更文件的词袋表示，融入跨文件和额外预测特征，避免使用传统的覆盖率映射。

Result: 在生产环境中，T-TS仅选择15%的测试，执行时间减少5.9倍，流水线加速5.6倍，检测超过95%的测试失败。

Conclusion: T-TS在工业环境中表现出色，显著提升测试效率，实现已公开以支持进一步研究和实际应用。

Abstract: In modern software development change-based testing plays a crucial role.
However, as codebases expand and test suites grow, efficiently managing the
testing process becomes increasingly challenging, especially given the high
frequency of daily code commits. We propose Targeted Test Selection (T-TS), a
machine learning approach for industrial test selection. Our key innovation is
a data representation that represent commits as Bags-of-Words of changed files,
incorporates cross-file and additional predictive features, and notably avoids
the use of coverage maps. Deployed in production, T-TS was comprehensively
evaluated against industry standards and recent methods using both internal and
public datasets, measuring time efficiency and fault detection. On live
industrial data, T-TS selects only 15% of tests, reduces execution time by
$5.9\times$, accelerates the pipeline by $5.6\times$, and detects over 95% of
test failures. The implementation is publicly available to support further
research and practical adoption.

</details>


### [11] [Developer-LLM Conversations: An Empirical Study of Interactions and Generated Code Quality](https://arxiv.org/abs/2509.10402)
*Suzhen Zhong,Ying Zou,Bram Adams*

Main category: cs.SE

TL;DR: 基于82,845个真实开发者-LLM对话的分析显示，LLM响应比开发者提示长14倍，68%为多轮对话，Python和JavaScript代码存在大量未定义变量问题，Java缺乏注释，C++缺少头文件，C#有命名空间问题。错误修正提示最有效。


<details>
  <summary>Details</summary>
Motivation: 了解开发者在实际工作中如何与LLM进行交互，以及这些对话动态如何影响任务结果、代码质量和软件开发工作流程。

Method: 使用CodeChat数据集（包含82,845个真实开发者-LLM对话，368,506个代码片段，覆盖20+编程语言），分析对话长度、多轮对话比例、主题分布，并评估5种主要语言的代码质量问题。

Result: LLM响应长度是提示的14倍；68%为多轮对话；主要任务为网页设计（9.6%）和神经网络训练（8.7%）；Python和JavaScript存在83.4%和75.3%的未定义变量问题；Java缺少75.9%的必要注释；C++缺少41.1%的头文件；C#有49.2%的未解析命名空间。错误修正提示能有效改善代码质量。

Conclusion: 开发者与LLM的对话主要是多轮迭代过程，LLM生成的代码存在语言特定的质量问题，但通过明确的错误修正请求可以逐步改善代码质量，这对优化LLM辅助编程工具具有重要意义。

Abstract: Large Language Models (LLMs) are becoming integral to modern software
development workflows, assisting developers with code generation, API
explanation, and iterative problem-solving through natural language
conversations. Despite widespread adoption, there is limited understanding of
how developers interact with LLMs in practice and how these conversational
dynamics influence task outcomes, code quality, and software engineering
workflows. To address this, we leverage CodeChat, a large dataset comprising
82,845 real-world developer-LLM conversations, containing 368,506 code snippets
generated across over 20 programming languages, derived from the WildChat
dataset. We find that LLM responses are substantially longer than developer
prompts, with a median token-length ratio of 14:1. Multi-turn conversations
account for 68% of the dataset and often evolve due to shifting requirements,
incomplete prompts, or clarification requests. Topic analysis identifies web
design (9.6% of conversations) and neural network training (8.7% of
conversations) as the most frequent LLM-assisted tasks. Evaluation across five
languages (i.e., Python, JavaScript, C++, Java, and C#) reveals prevalent and
language-specific issues in LLM-generated code: generated Python and JavaScript
code often include undefined variables (83.4% and 75.3% of code snippets,
respectively); Java code lacks required comments (75.9%); C++ code frequently
omits headers (41.1%) and C# code shows unresolved namespaces (49.2%). During a
conversation, syntax and import errors persist across turns; however,
documentation quality in Java improves by up to 14.7%, and import handling in
Python improves by 3.7% over 5 turns. Prompts that point out mistakes in code
generated in prior turns and explicitly request a fix are most effective for
resolving errors.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [Differential Robustness in Transformer Language Models: Empirical Evaluation Under Adversarial Text Attacks](https://arxiv.org/abs/2509.09706)
*Taniya Gidatkar,Oluwaseun Ajao,Matthew Shardlow*

Main category: cs.CR

TL;DR: 本研究评估了Flan-T5、BERT和RoBERTa-Base等大型语言模型对抗对抗性攻击的韧性，发现RoBERTa-Base和FlanT5表现出色（攻击成功率0%），而BERT-Base存在显著漏洞（TextFooler攻击成功率93.75%）。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在对抗性攻击下的安全性和韧性，识别现有防护机制的优缺点，为开发更有效的防御策略提供依据。

Method: 使用TextFooler和BERTAttack系统设计对抗性测试，对Flan-T5、BERT和RoBERTa-Base模型进行攻击测试，比较不同模型的鲁棒性表现。

Result: RoBERTa-Base和FlanT5表现出卓越的韧性，攻击成功率为0%；BERT-Base准确率从48%降至3%，TextFooler攻击成功率达93.75%。

Conclusion: 某些LLMs已具备有效防御机制但计算资源需求高，研究为LLM安全提供了重要见解，并提出了开发更高效防御策略的实用建议。

Abstract: This study evaluates the resilience of large language models (LLMs) against
adversarial attacks, specifically focusing on Flan-T5, BERT, and RoBERTa-Base.
Using systematically designed adversarial tests through TextFooler and
BERTAttack, we found significant variations in model robustness. RoBERTa-Base
and FlanT5 demonstrated remarkable resilience, maintaining accuracy even when
subjected to sophisticated attacks, with attack success rates of 0%. In
contrast. BERT-Base showed considerable vulnerability, with TextFooler
achieving a 93.75% success rate in reducing model accuracy from 48% to just 3%.
Our research reveals that while certain LLMs have developed effective defensive
mechanisms, these safeguards often require substantial computational resources.
This study contributes to the understanding of LLM security by identifying
existing strengths and weaknesses in current safeguarding approaches and
proposes practical recommendations for developing more efficient and effective
defensive strategies.

</details>


### [13] [ZORRO: Zero-Knowledge Robustness and Privacy for Split Learning (Full Version)](https://arxiv.org/abs/2509.09787)
*Nojan Sheybani,Alessandro Pegoraro,Jonathan Knauer,Phillip Rieger,Elissa Mollakuqe,Farinaz Koushanfar,Ahmad-Reza Sadeghi*

Main category: cs.CR

TL;DR: ZORRO是一种基于零知识证明的分割学习防御方案，可验证客户端正确执行防御算法，有效抵御恶意客户端通过中毒中间梯度注入后门的攻击，将攻击成功率降至6%以下，且客户端开销小于10秒。


<details>
  <summary>Details</summary>
Motivation: 分割学习在资源受限环境中处理敏感数据时很有效，但分布式特性使恶意客户端能够通过发送有毒中间梯度来操纵训练过程并注入后门。现有防御方案主要关注服务器端保护且引入额外开销，客户端防御面临确保恶意客户端正确执行防御算法的挑战。

Method: 提出ZORRO方案，采用交互式零知识证明(ZKPs)，客户端证明其正确执行客户端防御算法，生成计算完整性证明。利用模型分区的频率表示，在不可信环境中深度检查本地训练模型，确保每个客户端向前传递良性检查点。

Result: 在涵盖不同模型架构、攻击策略和数据场景的广泛评估中，ZORRO将攻击成功率降低至6%以下，即使对于客户端存储100万个参数的模型，开销也小于10秒。

Conclusion: ZORRO提供了一种私有、可验证且鲁棒的分割学习防御方案，通过零知识证明有效解决客户端防御的执行验证问题，在保持低开销的同时显著提升系统安全性。

Abstract: Split Learning (SL) is a distributed learning approach that enables
resource-constrained clients to collaboratively train deep neural networks
(DNNs) by offloading most layers to a central server while keeping in- and
output layers on the client-side. This setup enables SL to leverage server
computation capacities without sharing data, making it highly effective in
resource-constrained environments dealing with sensitive data. However, the
distributed nature enables malicious clients to manipulate the training
process. By sending poisoned intermediate gradients, they can inject backdoors
into the shared DNN. Existing defenses are limited by often focusing on
server-side protection and introducing additional overhead for the server. A
significant challenge for client-side defenses is enforcing malicious clients
to correctly execute the defense algorithm.
  We present ZORRO, a private, verifiable, and robust SL defense scheme.
Through our novel design and application of interactive zero-knowledge proofs
(ZKPs), clients prove their correct execution of a client-located defense
algorithm, resulting in proofs of computational integrity attesting to the
benign nature of locally trained DNN portions. Leveraging the frequency
representation of model partitions enables ZORRO to conduct an in-depth
inspection of the locally trained models in an untrusted environment, ensuring
that each client forwards a benign checkpoint to its succeeding client. In our
extensive evaluation, covering different model architectures as well as various
attack strategies and data scenarios, we show ZORRO's effectiveness, as it
reduces the attack success rate to less than 6\% while causing even for models
storing \numprint{1000000} parameters on the client-side an overhead of less
than 10 seconds.

</details>


### [14] [SmartCoder-R1: Towards Secure and Explainable Smart Contract Generation with Security-Aware Group Relative Policy Optimization](https://arxiv.org/abs/2509.09942)
*Lei Yu,Jingyuan Zhang,Xin Wang,Jiajia Ma,Li Yang,Fengjun Zhang*

Main category: cs.CR

TL;DR: SmartCoder-R1是一个基于Qwen2.5-Coder-7B的新型框架，通过持续预训练、长思维链监督微调和安全感知强化学习，实现了安全且可解释的智能合约生成，在多个关键指标上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在智能合约生成中的两个关键问题：作为不可审计的"黑盒"缺乏透明推理过程，以及生成的代码存在严重安全漏洞。智能合约管理高价值资产，漏洞可能导致灾难性财务损失。

Method: 1) 持续预训练(CPT)进行模型专业化；2) 在7,998个专家验证的推理-代码样本上进行长思维链监督微调(L-CoT SFT)；3) 使用安全感知组相对策略优化(S-GRPO)进行强化学习，优化编译成功、安全合规和格式正确的加权奖励信号。

Result: 在756个真实世界函数的基准测试中，SmartCoder-R1在17个基线模型中达到最优：ComPass 87.70%、VulRate 8.60%、SafeAval 80.16%、FuncRate 53.84%、FullRate 50.53%（比最强基线DeepSeek-R1提升45.79%）。生成推理在人工评估中也表现优异：功能性82.7%、安全性85.3%、清晰度90.7%。

Conclusion: SmartCoder-R1通过结合专业化预训练、思维链微调和安全感知强化学习，成功解决了LLM在智能合约生成中的可解释性和安全性问题，建立了新的最先进水平，为安全可靠的智能合约开发提供了有效解决方案。

Abstract: Smart contracts automate the management of high-value assets, where
vulnerabilities can lead to catastrophic financial losses. This challenge is
amplified in Large Language Models (LLMs) by two interconnected failures: they
operate as unauditable "black boxes" lacking a transparent reasoning process,
and consequently, generate code riddled with critical security vulnerabilities.
To address both issues, we propose SmartCoder-R1 (based on Qwen2.5-Coder-7B), a
novel framework for secure and explainable smart contract generation. It begins
with Continual Pre-training (CPT) to specialize the model. We then apply Long
Chain-of-Thought Supervised Fine-Tuning (L-CoT SFT) on 7,998 expert-validated
reasoning-and-code samples to train the model to emulate human security
analysis. Finally, to directly mitigate vulnerabilities, we employ
Security-Aware Group Relative Policy Optimization (S-GRPO), a reinforcement
learning phase that refines the generation policy by optimizing a weighted
reward signal for compilation success, security compliance, and format
correctness. Evaluated against 17 baselines on a benchmark of 756 real-world
functions, SmartCoder-R1 establishes a new state of the art, achieving top
performance across five key metrics: a ComPass of 87.70%, a VulRate of 8.60%, a
SafeAval of 80.16%, a FuncRate of 53.84%, and a FullRate of 50.53%. This
FullRate marks a 45.79% relative improvement over the strongest baseline,
DeepSeek-R1. Crucially, its generated reasoning also excels in human
evaluations, achieving high-quality ratings for Functionality (82.7%), Security
(85.3%), and Clarity (90.7%).

</details>


### [15] [Byte by Byte: Unmasking Browser Fingerprinting at the Function Level Using V8 Bytecode Transformers](https://arxiv.org/abs/2509.09950)
*Pouneh Nikkhah Bahrami,Dylan Cutler,Igor Bilogrevic*

Main category: cs.CR

TL;DR: ByteDefender是一个基于V8引擎字节码的指纹检测系统，使用Transformer分类器在函数级别精准检测指纹操作，在编译阶段实时阻止恶意函数执行，同时保持正常脚本功能。


<details>
  <summary>Details</summary>
Motivation: 传统指纹检测方法要么精度不足导致网站功能破坏，要么容易被代码混淆和URL操作绕过，需要一种既精确又鲁棒的检测方案。

Method: 利用V8引擎字节码，训练Transformer分类器离线识别指纹函数，生成轻量级签名用于设备端实时匹配，在编译阶段但执行前进行检测。

Result: 在top 10万网站评估中显示出高检测精度，平均仅增加4%页面加载延迟，相比现有AST方法在抗混淆能力上有显著提升。

Conclusion: ByteDefender提供了一个实用框架，实现了精确、鲁棒的指纹检测和缓解，在保持网站功能完整性的同时有效防止用户跟踪。

Abstract: Browser fingerprinting enables persistent cross-site user tracking via subtle
techniques that often evade conventional defenses or cause website breakage
when script-level blocking countermeasures are applied. Addressing these
challenges requires detection methods offering both function-level precision to
minimize breakage and inherent robustness against code obfuscation and URL
manipulation.
  We introduce ByteDefender, the first system leveraging V8 engine bytecode to
detect fingerprinting operations specifically at the JavaScript function level.
A Transformer-based classifier, trained offline on bytecode sequences,
accurately identifies functions exhibiting fingerprinting behavior. We develop
and evaluate light-weight signatures derived from this model to enable
low-overhead, on-device matching against function bytecode during compilation
but prior to execution, which only adds a 4% (average) latency to the page load
time. This mechanism facilitates targeted, real-time prevention of
fingerprinting function execution, thereby preserving legitimate script
functionality. Operating directly on bytecode ensures inherent resilience
against common code obfuscation and URL-based evasion. Our evaluation on the
top 100k websites demonstrates high detection accuracy at both function- and
script-level, with substantial improvements over state-of-the-art AST-based
methods, particularly in robustness against obfuscation. ByteDefender offers a
practical framework for effective, precise, and robust fingerprinting
mitigation.

</details>


### [16] [Securing LLM-Generated Embedded Firmware through AI Agent-Driven Validation and Patching](https://arxiv.org/abs/2509.09970)
*Seyed Moein Abtahi,Akramul Azim*

Main category: cs.CR

TL;DR: 提出结合LLM生成固件与自动化安全验证的三阶段方法，在虚拟化环境中通过迭代优化提升嵌入式系统固件的安全性和实时性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成嵌入式系统固件时经常引入安全漏洞且无法满足实时性能约束，需要系统化的方法来确保生成代码的安全性和可靠性

Method: 三阶段方法：1)使用结构化提示词让GPT-4等模型生成固件代码；2)在QEMU虚拟化环境中部署到FreeRTOS，通过模糊测试、静态分析和运行时监控检测漏洞；3)利用专门的AI代理进行威胁检测、性能优化和合规验证，迭代生成补丁

Result: 实验显示92.4%的漏洞修复率（提升37.3%），95.8%的威胁模型合规率，0.87的安全覆盖指数，实时性能指标包括8.6ms最坏情况执行时间和195μs抖动

Conclusion: 该方法显著提升了LLM生成固件的安全性和性能，同时贡献了开源数据集供未来研究使用

Abstract: Large Language Models (LLMs) show promise in generating firmware for embedded
systems, but often introduce security flaws and fail to meet real-time
performance constraints. This paper proposes a three-phase methodology that
combines LLM-based firmware generation with automated security validation and
iterative refinement in a virtualized environment. Using structured prompts,
models like GPT-4 generate firmware for networking and control tasks, deployed
on FreeRTOS via QEMU. These implementations are tested using fuzzing, static
analysis, and runtime monitoring to detect vulnerabilities such as buffer
overflows (CWE-120), race conditions (CWE-362), and denial-of-service threats
(CWE-400). Specialized AI agents for Threat Detection, Performance
Optimization, and Compliance Verification collaborate to improve detection and
remediation. Identified issues are categorized using CWE, then used to prompt
targeted LLM-generated patches in an iterative loop. Experiments show a 92.4\%
Vulnerability Remediation Rate (37.3\% improvement), 95.8\% Threat Model
Compliance, and 0.87 Security Coverage Index. Real-time metrics include 8.6ms
worst-case execution time and 195{\mu}s jitter. This process enhances firmware
security and performance while contributing an open-source dataset for future
research.

</details>


### [17] [rCamInspector: Building Reliability and Trust on IoT (Spy) Camera Detection using XAI](https://arxiv.org/abs/2509.09989)
*Priyanka Rushikesh Chaudhary,Manan Gupta,Jabez Christopher,Putrevu Venkata Sai Charan,Rajib Ranjan Maiti*

Main category: cs.CR

TL;DR: rCamInspector是一个基于可解释AI(XAI)的物联网摄像头流量分类系统，使用XGBoost模型在Flow分类器和SmartCam分类器中分别达到92%和99%的准确率，并通过SHAP和LIME提供可信的解释。


<details>
  <summary>Details</summary>
Motivation: 解决物联网网络安全中机器学习模型黑盒问题，提供可靠和可信的模型输出解释，以支持关键决策。

Method: 设计rCamInspector系统，采用两个分类器：Flow分类器（4类）和SmartCam分类器（6类），使用8种监督ML模型，重点采用XGBoost，并应用SHAP和LIME进行特征重要性解释。

Result: XGBoost在两个分类器中表现最佳，准确率分别为92%和99%。SHAP和LIME解释器在数据集上具有超过0.7的一致性和1.0的充分性。与传统互信息方法相比，XAI方法能提供更可靠的特征解释。

Conclusion: rCamInspector在物联网摄像头流量分类方面实现了高精度和可信的解释能力，证明了XAI在网络安全应用中的有效性，相比现有工作具有更好的性能指标。

Abstract: The classification of network traffic using machine learning (ML) models is
one of the primary mechanisms to address the security issues in IoT networks
and/or IoT devices. However, the ML models often act as black-boxes that create
a roadblock to take critical decision based on the model output. To address
this problem, we design and develop a system, called rCamInspector, that
employs Explainable AI (XAI) to provide reliable and trustworthy explanations
to model output. rCamInspector adopts two classifiers, Flow Classifier -
categorizes a flow into one of four classes, IoTCam, Conf, Share and Others,
and SmartCam Classifier - classifies an IoTCam flow into one of six classes,
Netatmo, Spy Clock, Canary, D3D, Ezviz, V380 Spy Bulb; both are IP address and
transport port agnostic. rCamInspector is evaluated using 38GB of network
traffic and our results show that XGB achieves the highest accuracy of 92% and
99% in the Flow and SmartCam classifiers respectively among eight supervised ML
models. We analytically show that the traditional mutual information (MI) based
feature importance cannot provide enough reliability on the model output of XGB
in either classifiers. Using SHAP and LIME, we show that a separate set of
features can be picked up to explain a correct prediction of XGB. For example,
the feature Init Bwd Win Byts turns out to have the highest SHAP values to
support the correct prediction of both IoTCam in Flow Classifier and Netatmo
class in SmartCam Classifier. To evaluate the faithfulness of the explainers on
our dataset, we show that both SHAP and LIME have a consistency of more than
0.7 and a sufficiency of 1.0. Comparing with existing works, we show that
rCamInspector achieves a better accuracy (99%), precision (99%), and false
negative rate (0.7%).

</details>


### [18] [Why Data Anonymization Has Not Taken Off](https://arxiv.org/abs/2509.10165)
*Matthew J. Schneider,James Bailie,Dawn Iacobucci*

Main category: cs.CR

TL;DR: 差分隐私和数据匿名化技术在实践中存在重大挑战，需要根据具体场景进行复杂的选择和定制化实施，而非一种通用的简单解决方案。


<details>
  <summary>Details</summary>
Motivation: 企业寻求通过数据匿名化来简化遵规处理，但现有技术在实际应用中遇到了重大困难。

Method: 分析了匿名化实施中需要考虑的多种因素：数据域范围、保护单位、保护范围和保护标准，以及业务盈利性要求。

Result: 匿名化方案通常需要定制化实施，降低了可扩展性，且只在需求洞察远大于保护单位时才有效。

Conclusion: 匿名化仅是数据隐私保护的一种方法，最佳策略是结合使用各种数据隐私和安全技术，而非寻求单一的简单解决方案。

Abstract: Companies are looking to data anonymization research $\unicode{x2013}$
including differential private and synthetic data methods $\unicode{x2013}$ for
simple and straightforward compliance solutions. But data anonymization has not
taken off in practice because it is anything but simple to implement. For one,
it requires making complex choices which are case dependent, such as the domain
of the dataset to anonymize; the units to protect; the scope where the data
protection should extend to; and the standard of protection. Each variation of
these choices changes the very meaning, as well as the practical implications,
of differential privacy (or of any other measure of data anonymization). Yet
differential privacy is frequently being branded as the same privacy guarantee
regardless of variations in these choices. Some data anonymization methods can
be effective, but only when the insights required are much larger than the unit
of protection. Given that businesses care about profitability, any solution
must preserve the patterns between a firm's data and that profitability. As a
result, data anonymization solutions usually need to be bespoke and
case-specific, which reduces their scalability. Companies should not expect
easy wins, but rather recognize that anonymization is just one approach to data
privacy with its own particular advantages and drawbacks, while the best
strategies jointly leverage the full range of approaches to data privacy and
security in combination.

</details>


### [19] [Investigating Feature Attribution for 5G Network Intrusion Detection](https://arxiv.org/abs/2509.10206)
*Federica Uccello,Simin Nadjm-Tehrani*

Main category: cs.CR

TL;DR: 这篇论文研究了5G网络安全中的可解释人工智能技术，比较SHAP和VoTE-XAI在攻击警报解释方面的性能。VoTE-XAI在简洁性、稳定性和效率方面都表现更优。


<details>
  <summary>Details</summary>
Motivation: 随着5G网络在关键应用中的普及，需要从传统的恶意活动检测转向能够提供可靠判断的系统。理解和解释ML模型的安全警报对于启动可行动的事件响应致关重要。

Method: 研究了两种XAI方法：SHAP（基于统计归因）和VoTE-XAI（基于逻辑解释）。在三个不同的5G通信攻击场景下，分析它们对XGBoost模型警报的解释能力。采用三个评估指标：稀疏性（简洁程度）、稳定性（一致性）和效率（解释速度）。

Result: 在92个特征的5G网络中，VoTE-XAI仅选择6个关键特征来解释doS攻击，而SHAP选择了超20个。VoTE-XAI在高维度设置（478特征）中能在0.002秒内提供单个解释，效率显著更高。虽然两种方法选择的特征存在明显差异，但SHAP的顶部特征都被VoTE-XAI覆盖。

Conclusion: 逻辑基于的VoTE-XAI方法在5G网络安全警报解释中表现更优，具有更好的简洁性、稳定性和效率。这为未来通信系统的可靠事件响应提供了更有效的解释方案。

Abstract: With the rise of fifth-generation (5G) networks in critical applications, it
is urgent to move from detection of malicious activity to systems capable of
providing a reliable verdict suitable for mitigation. In this regard,
understanding and interpreting machine learning (ML) models' security alerts is
crucial for enabling actionable incident response orchestration. Explainable
Artificial Intelligence (XAI) techniques are expected to enhance trust by
providing insights into why alerts are raised. A dominant approach
statistically associates feature sets that can be correlated to a given alert.
This paper starts by questioning whether such attribution is relevant for
future generation communication systems, and investigates its merits in
comparison with an approach based on logical explanations. We extensively study
two methods, SHAP and VoTE-XAI, by analyzing their interpretations of alerts
generated by an XGBoost model in three different use cases with several 5G
communication attacks. We identify three metrics for assessing explanations:
sparsity, how concise they are; stability, how consistent they are across
samples from the same attack type; and efficiency, how fast an explanation is
generated. As an example, in a 5G network with 92 features, 6 were deemed
important by VoTE-XAI for a Denial of Service (DoS) variant, ICMPFlood, while
SHAP identified over 20. More importantly, we found a significant divergence
between features selected by SHAP and VoTE-XAI. However, none of the top-ranked
features selected by SHAP were missed by VoTE-XAI. When it comes to efficiency
of providing interpretations, we found that VoTE-XAI is significantly more
responsive, e.g. it provides a single explanation in under 0.002 seconds, in a
high-dimensional setting (478 features).

</details>


### [20] [Dynamic Vulnerability Patching for Heterogeneous Embedded Systems Using Stack Frame Reconstruction](https://arxiv.org/abs/2509.10213)
*Ming Zhou,Xupu Hu,Zhihao Wang,Haining Wang,Hui Wen,Limin Sun,Peng Zhang*

Main category: cs.CR

TL;DR: StackPatch是一个针对嵌入式设备的动态热补丁框架，通过栈帧重建和异常处理机制实现跨架构漏洞修复，在ARM、RISC-V和Xtensa三种MCU架构上成功修复了102个RTOS漏洞，每次修复耗时少于260个时钟周期。


<details>
  <summary>Details</summary>
Motivation: 现有动态漏洞修补技术不适用于嵌入式设备，特别是医疗设备等关键任务设备，因为这些设备计算能力有限、内存不足但需要不间断服务，且缺乏统一的补丁触发机制。

Method: 基于栈帧重建的补丁开发框架，利用嵌入式处理器常见的异常处理机制实现控制流重定向，采用不同的触发策略更新内存单元中的程序。

Result: 在三种主要MCU架构（ARM、RISC-V、Xtensa）上成功修复102个公开漏洞，应用于医疗设备、软PLC和网络服务，每次漏洞修复耗时少于260个MCU时钟周期。

Conclusion: StackPatch框架有效解决了嵌入式设备动态补丁的技术挑战，具有跨架构适应性和高效性能，适用于资源受限的关键任务嵌入式系统。

Abstract: Existing dynamic vulnerability patching techniques are not well-suited for
embedded devices, especially mission-critical ones such as medical equipment,
as they have limited computational power and memory but uninterrupted service
requirements. Those devices often lack sufficient idle memory for dynamic
patching, and the diverse architectures of embedded systems further complicate
the creation of patch triggers that are compatible across various system
kernels and hardware platforms. To address these challenges, we propose a hot
patching framework called StackPatch that facilitates patch development based
on stack frame reconstruction. StackPatch introduces different triggering
strategies to update programs stored in memory units. We leverage the
exception-handling mechanisms commonly available in embedded processors to
enhance StackPatch's adaptability across different processor architectures for
control flow redirection. We evaluated StackPatch on embedded devices featuring
three major microcontroller (MCU) architectures: ARM, RISC-V, and Xtensa. In
the experiments, we used StackPatch to successfully fix 102 publicly disclosed
vulnerabilities in real-time operating systems (RTOS). We applied patching to
medical devices, soft programmable logic controllers (PLCs), and network
services, with StackPatch consistently completing each vulnerability
remediation in less than 260 MCU clock cycles.

</details>


### [21] [Empirical Evaluation of Memory-Erasure Protocols](https://arxiv.org/abs/2509.10224)
*Reynaldo Gil-Pons,Sjouke Mauw,Rolando Trujillo-Rasua*

Main category: cs.CR

TL;DR: 这篇论文对软件基内存清除协议进行了首次实证分析，在3种IoT设备上测试7种协议的安全性、清除保证和性能表现，发现网络速度和协议隐藏常数对性能影响较大，并提供了安全性评估框架。


<details>
  <summary>Details</summary>
Motivation: 软件基内存清除协议可以让IoT设备不需要安全硬件或物理操作就能恢复到安全状态，但之前的协议缺乏实际设备测试，影响了业界采用。

Method: 在3种不同计算能力的现代IoT设备上，对6种哈希函数实现方式，对7到7种内存清除协议进行安全性、清除保证和性能的实验分析。

Result: 现有协议在实际设备上可行，但速度慢的设备需要几秒钟完成清除和证明生成；没有一种协议在所有情况下都最优，网络速度和协议隐藏常数对性能影响较大。

Conclusion: 研究提供了一个评估框架，可根据需求的安全级别选择性能和清除保证最佳的协议，为实际部署提供指南。

Abstract: Software-based memory-erasure protocols are two-party communication protocols
where a verifier instructs a computational device to erase its memory and send
a proof of erasure. They aim at guaranteeing that low-cost IoT devices are free
of malware by putting them back into a safe state without requiring secure
hardware or physical manipulation of the device. Several software-based
memory-erasure protocols have been introduced and theoretically analysed. Yet,
many of them have not been tested for their feasibility, performance and
security on real devices, which hinders their industry adoption. This article
reports on the first empirical analysis of software-based memory-erasure
protocols with respect to their security, erasure guarantees, and performance.
The experimental setup consists of 3 modern IoT devices with different
computational capabilities, 7 protocols, 6 hash-function implementations, and
various performance and security criteria. Our results indicate that existing
software-based memory-erasure protocols are feasible, although slow devices may
take several seconds to erase their memory and generate a proof of erasure. We
found that no protocol dominates across all empirical settings, defined by the
computational power and memory size of the device, the network speed, and the
required level of security. Interestingly, network speed and hidden constants
within the protocol specification played a more prominent role in the
performance of these protocols than anticipated based on the related
literature. We provide an evaluation framework that, given a desired level of
security, determines which protocols offer the best trade-off between
performance and erasure guarantees.

</details>


### [22] [ExDoS: Expert-Guided Dual-Focus Cross-Modal Distillation for Smart Contract Vulnerability Detection](https://arxiv.org/abs/2509.10252)
*Yifan Jia,Ye Tian,Yanbin Wang,Jianguo Sun,Haitao Xu*

Main category: cs.CR

TL;DR: ExDoS是一个跨模态漏洞检测框架，通过双注意力图网络和细粒度对齐机制，将源代码的语义知识迁移到字节码中，在真实合约上实现了3%-6%的F1分数提升。


<details>
  <summary>Details</summary>
Motivation: 智能合约的闭源特性使得漏洞检测只能在字节码层面进行，这比基于源代码的分析更具挑战性。现有方法依赖图级对齐，模糊了两种模态间的细粒度结构和语义关联，且缺乏精确的漏洞模式和细粒度标注。

Method: 构建源代码的语义图和字节码的控制流图；提出双注意力图网络，引入节点注意力聚合模块增强局部模式捕获；构建首个与源代码定义对齐的漏洞模式标注数据集；设计包含全局语义蒸馏损失和局部语义蒸馏损失的双焦点目标函数。

Result: 在真实合约上的实验表明，该方法相比强基线实现了3%-6%的F1分数一致提升。

Conclusion: ExDoS通过有效的跨模态知识迁移和细粒度对齐机制，显著提升了字节码层面的智能合约漏洞检测性能，为解决闭源代码分析难题提供了有效方案。

Abstract: The success of smart contracts has made them a target for attacks, but their
closed-source nature often forces vulnerability detection to work on bytecode,
which is inherently more challenging than source-code-based analysis. While
recent studies try to align source and bytecode embeddings during training to
transfer knowledge, current methods rely on graph-level alignment that obscures
fine-grained structural and semantic correlations between the two modalities.
Moreover, the absence of precise vulnerability patterns and granular
annotations in bytecode leads to depriving the model of crucial supervisory
signals for learning discriminant features. We propose ExDoS to transfer rich
semantic knowledge from source code to bytecode, effectively supplementing the
source code prior in practical settings. Specifically, we construct semantic
graphs from source code and control-flow graphs from bytecode. To address
obscured local signals in graph-level contract embeddings, we propose a
Dual-Attention Graph Network introducing a novel node attention aggregation
module to enhance local pattern capture in graph embeddings. Furthermore, by
summarizing existing source code vulnerability patterns and designing a
corresponding set of bytecode-level patterns for each, we construct the first
dataset of vulnerability pattern annotations aligned with source code
definitions to facilitate fine-grained cross-modal alignment and the capture of
function-level vulnerability signals. Finally, we propose a dual-focus
objective for our cross-modal distillation framework, comprising: a Global
Semantic Distillation Loss for transferring graph-level knowledge and a Local
Semantic Distillation Loss enabling expert-guided, fine-grained
vulnerability-specific distillation. Experiments on real-world contracts
demonstrate that our method achieves consistent F1-score improvements
(3\%--6\%) over strong baselines.

</details>


### [23] [URL2Graph++: Unified Semantic-Structural-Character Learning for Malicious URL Detection](https://arxiv.org/abs/2509.10287)
*Ye Tian,Yifan Jia,Yanbin Wang,Jianguo Sun,Zhiquan Liu,Xiaowen Ling*

Main category: cs.CR

TL;DR: 综合多粒度图学习与语义嵌入的恶意URL检测方法，通过子词和字符双粒度图结构、BERT语义表征以及门控动态融合网络，在多个挑战性测试中超越了现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 解决恶意URL检测面临的两大挑战：(1)网络URL数量指数增长导致检测难度增加；(2)攻击者采用更多避免技术。需要获得语义理解来改善泛化能力，并准确建模URL结构内部的上下文关系。

Method: 1. 构建子词和字符双粒度URL图结构，节点代表URL标记/字符，边编码共现关系
2. 使用字符级卷积网络初始化节点表征
3. 通过联合训练的图卷积网络处理两个图学习一致的图级表征
4. 使用BERT获取URL的语义表征
5. 使用门控动态融合网络结合BERT表征和图向量

Result: 方法在多个挑战性测试中超越了现有最佳方法，包括对大型语言模型的性能优势

Conclusion: 通过结合多粒度图学习与语义嵌入的方法，能够同时抓取URL的语义、字符级和结构特征，实现了更加稳健的恶意URL检测性能。

Abstract: Malicious URL detection remains a major challenge in cybersecurity, primarily
due to two factors: (1) the exponential growth of the Internet has led to an
immense diversity of URLs, making generalized detection increasingly difficult;
and (2) attackers are increasingly employing sophisticated obfuscation
techniques to evade detection. We advocate that addressing these challenges
fundamentally requires: (1) obtaining semantic understanding to improve
generalization across vast and diverse URL sets, and (2) accurately modeling
contextual relationships within the structural composition of URLs. In this
paper, we propose a novel malicious URL detection method combining
multi-granularity graph learning with semantic embedding to jointly capture
semantic, character-level, and structural features for robust URL analysis. To
model internal dependencies within URLs, we first construct dual-granularity
URL graphs at both subword and character levels, where nodes represent URL
tokens/characters and edges encode co-occurrence relationships. To obtain
fine-grained embeddings, we initialize node representations using a
character-level convolutional network. The two graphs are then processed
through jointly trained Graph Convolutional Networks to learn consistent
graph-level representations, enabling the model to capture complementary
structural features that reflect co-occurrence patterns and character-level
dependencies. Furthermore, we employ BERT to derive semantic representations of
URLs for semantically aware understanding. Finally, we introduce a gated
dynamic fusion network to combine the semantically enriched BERT
representations with the jointly optimized graph vectors, further enhancing
detection performance. We extensively evaluate our method across multiple
challenging dimensions. Results show our method exceeds SOTA performance,
including against large language models.

</details>


### [24] [Innovating Augmented Reality Security: Recent E2E Encryption Approaches](https://arxiv.org/abs/2509.10313)
*Hamish Alsop,Leandros Maglaras,Helge Janicke,Iqbal H. Sarker,Mohamed Amine Ferrag*

Main category: cs.CR

TL;DR: 端到端加密(E2EE)在保护隐私的同时也给执法带来挑战，存在隐私与安全的悖论


<details>
  <summary>Details</summary>
Motivation: 探讨E2EE技术在保护个人隐私和数字信任方面的关键作用，同时分析其对执法工作造成的障碍，研究这一技术带来的双重角色和矛盾

Method: 通过理论分析E2EE的技术原理和工作机制，结合隐私保护与执法需求的对比研究，探讨技术实现与政策监管的平衡点

Result: E2EE确实在保护用户隐私方面发挥重要作用，但同时也为恶意活动提供了隐蔽空间，形成了隐私保护与公共安全之间的紧张关系

Conclusion: 需要在技术设计、政策制定和社会共识等多个层面寻求平衡，既保护个人隐私权利，又不妨碍必要的执法工作，这需要技术创新与法律框架的协同发展

Abstract: End-to-end encryption (E2EE) has emerged as a fundamental element of modern
digital communication, protecting data from unauthorized access during
transmission. By design, E2EE ensures that only the intended recipient can
decrypt the information, making it inaccessible even to service providers. Yet,
this powerful safeguard of individual privacy and digital trust also introduces
a paradox: it can simultaneously prevent law enforcement efforts by hiding
potential malicious activities. This paper examines the dual role of E2EE, its
critical importance to privacy, the challenges it

</details>


### [25] [Automated Testing of Broken Authentication Vulnerabilities in Web APIs with AuthREST](https://arxiv.org/abs/2509.10320)
*Davide Corradini,Mariano Ceccato,Mohammad Ghafari*

Main category: cs.CR

TL;DR: AuthREST是一个开源的API安全测试工具，专注于检测认证漏洞，在四个公开API中发现了此前未知的安全漏洞


<details>
  <summary>Details</summary>
Motivation: 针对API安全中最普遍的认证漏洞问题，特别是凭证填充、密码暴力破解和令牌验证缺失等风险

Method: 开发自动化安全测试工具，自动检测web API的认证漏洞

Result: 工具有效提升了web API安全性，在四个公开API中发现了此前未知的认证漏洞

Conclusion: AuthREST是一个有效的API安全测试工具，能够自动发现认证相关的安全漏洞

Abstract: We present AuthREST, an open-source security testing tool targeting broken
authentication, one of the most prevalent API security risks in the wild.
AuthREST automatically tests web APIs for credential stuffing, password brute
forcing, and unchecked token authenticity. Empirical results show that AuthREST
is effective in improving web API security. Notably, it uncovered previously
unknown authentication vulnerabilitiesin in four public APIs.

</details>


### [26] [Bitcoin Cross-Chain Bridge: A Taxonomy and Its Promise in Artificial Intelligence of Things](https://arxiv.org/abs/2509.10413)
*Guojun Tang,Carylyne Chan,Ning Nan,Spencer Yang,Jiayu Zhou,Henry Leung,Mohammad Mamun,Steve Drew*

Main category: cs.CR

TL;DR: 比特币跨链桥协议分类学研究，系统分析了三种桥接类型（简单代币交换、锚定资产桥、任意消息桥）的信任假设和性能特征，并探讨了在AIoT场景中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 比特币有限的脚本功能和缺乏原生互操作性机制限制了其在更广泛区块链生态系统（特别是DeFi和多链应用）中的集成，需要系统研究跨链桥接解决方案。

Method: 提出比特币跨链桥协议的全面分类法，将桥接设计分为三类：简单代币交换、锚定资产桥和任意消息桥，从信任模型、延迟、资本效率和DeFi可组合性等关键指标进行评估。

Result: 建立了比特币跨链桥的分类框架，识别了BitVM和递归侧链等新兴创新技术的潜力，能够实现安全、可扩展和可编程的比特币互操作性。

Conclusion: 该分类法为研究人员和从业者设计AIoT系统中安全高效的跨链基础设施提供了基础框架，特别是在去中心化能源交易、医疗数据集成和供应链自动化等AIoT应用场景中具有重要价值。

Abstract: Bitcoin's limited scripting capabilities and lack of native interoperability
mechanisms have constrained its integration into the broader blockchain
ecosystem, especially decentralized finance (DeFi) and multi-chain
applications. This paper presents a comprehensive taxonomy of Bitcoin
cross-chain bridge protocols, systematically analyzing their trust assumptions,
performance characteristics, and applicability to the Artificial Intelligence
of Things (AIoT) scenarios. We categorize bridge designs into three main types:
naive token swapping, pegged-asset bridges, and arbitrary-message bridges. Each
category is evaluated across key metrics such as trust model, latency, capital
efficiency, and DeFi composability. Emerging innovations like BitVM and
recursive sidechains are highlighted for their potential to enable secure,
scalable, and programmable Bitcoin interoperability. Furthermore, we explore
practical use cases of cross-chain bridges in AIoT applications, including
decentralized energy trading, healthcare data integration, and supply chain
automation. This taxonomy provides a foundational framework for researchers and
practitioners seeking to design secure and efficient cross-chain
infrastructures in AIoT systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [27] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: AutoIND大语言模型平台可将IND申请的非临床书面总结起草时间减少约97%，从约100小时降至3-4小时，质量评分达70-78%，无关键监管错误，但仍需专家完善以提高质量。


<details>
  <summary>Details</summary>
Motivation: IND申请准备耗时且依赖专业知识，拖慢早期临床开发进程，需要寻找加速起草过程的方法。

Method: 使用AutoIND LLM平台生成IND非临床书面总结，记录起草时间并与人工起草时间对比，由盲评监管写作评估员使用7个预设类别进行质量评估。

Result: 起草时间减少97%（从~100小时降至3.7小时和2.6小时），质量评分分别为69.6%和77.9%，无关键监管错误，但在重点突出、简洁性和清晰度方面存在不足。

Conclusion: AutoIND能显著加速IND起草，但专家监管写作者仍是确保提交质量的关键，发现的系统性缺陷为模型改进提供了路线图。

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>


### [28] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: boldsea是一个基于语义事件的可执行本体架构，用于建模复杂动态系统，通过整合事件语义和数据流架构来解决传统BPM系统和面向对象语义技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统业务流程管理系统和面向对象语义技术在动态系统建模中的局限性，提供运行时修改事件模型、时间透明性以及数据和业务逻辑统一的能力。

Method: 提出boldsea语义语言(BSL)及其BNF语法，设计boldsea-engine架构，直接解释语义模型作为可执行算法而无需编译。

Result: 实现了语义模型作为动态结构直接控制流程执行，支持运行时事件模型修改，确保时间透明性，并在统一语义框架中无缝合并数据和业务逻辑。

Conclusion: boldsea架构通过可执行本体和语义事件方法，为复杂动态系统建模提供了更灵活和强大的解决方案，克服了传统方法的限制。

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [29] [How well can LLMs provide planning feedback in grounded environments?](https://arxiv.org/abs/2509.09790)
*Yuxuan Li,Victor Zhong*

Main category: cs.AI

TL;DR: 大型基础模型能够提供高质量的多样化规划反馈，包括二进制、偏好、动作建议等，减少对设计奖励函数和演示数据的依赖


<details>
  <summary>Details</summary>
Motivation: 解决现有规划方法需要精心设计奖励函数或高质量演示数据的问题，并探索基础模型在规划任务中提供反馈的效果

Method: 在符号、语言和连续控制环境中评估LLM和VLM的反馈性能，测试了二进制反馈、偏好反馈、动作建议、目标建议等多种反馈类型，以及上下文学习、思维链等推理方法

Result: 基础模型能够提供高质量的多样化反馈，较大和具有推理能力的模型表现更好，反馈准确性更高、偏见更少，并能从更强大的推理方法中获益更多

Conclusion: 基础模型可以作为有效的规划反馈来源，但在复杂动力学或连续状态/动作空间的环境中反馈质量会下降

Abstract: Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.

</details>


### [30] [A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes](https://arxiv.org/abs/2509.09794)
*Jackson Eshbaugh,Chetan Tiwari,Jorge Silveyra*

Main category: cs.AI

TL;DR: 使用模块化多模态框架和生成式AI从公开住宅信息生成能源模型所需数据，解决数据获取难题


<details>
  <summary>Details</summary>
Motivation: 能源建模需要大量数据，但部分数据获取困难、成本高或存在隐私问题

Method: 提出模块化多模态框架，使用生成式AI从公开住宅信息和图片生成标签数据，并提供数据生成流程

Result: 框架能够生成实际的标签数据，避免了生成模型的常见问题

Conclusion: 该框架减少了对成本高或限制数据源的依赖，为更可访问和可复现的研究推广了道路

Abstract: Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.

</details>


### [31] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: 自动形式化是指将非形式输入翻译为形式逻辑表示的过程，包括数学定理证明和更广泛的逻辑表达。近期深度学习和大语言模型的进步促进了该领域发展，但各研究领域相对孤立开发。本文旨在统一框架，推动领域交叉发展。


<details>
  <summary>Details</summary>
Motivation: 自动形式化领域在深度学习和大语言模型推动下快速发展，但各研究领域相对孤立，缺乏统一的方法论、测试标准和理论框架，限制了进一步发展。需要建立统一框架以促进领域交叉发展。

Method: 对明显或隐含的自动形式化研究实例进行综述梳理，分析各研究领域的方法和技术。在此基础上提出统一的框架概念，以促进不同领域间的方法论、测试标准和理论框架的共享与交叉。

Result: 通过对自动形式化领域的系统梳理和分析，明确了该领域的研究状况、技术进展和存在问题。提出的统一框架为不同研究领域的交流与合作提供了基础，有助于形成共享的方法论、测试标准和理论框架。

Conclusion: 自动形式化在数学定理证明和逻辑表达等领域具有广阔应用前景，是发展下一代人工智能系统的关键技术。通过建立统一框架和推动领域交叉，可以加速自动形式化技术的发展，为更高级利的AI系统提供支撑。

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [32] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 本研究开发了一个基于RAG的智能知识助手系统，专门用于山羊养殖健康管理，通过结构化知识处理方法提升LLM对异构数据的理解能力，在验证集和测试集上分别达到87.90%和84.22%的准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在畜牧业应用受限，主要由于知识源的可用性、多样性和复杂性限制，需要开发专门的知识处理方法来支持山羊养殖的健康管理。

Method: 采用检索增强生成(RAG)技术，提出表格文本化和决策树文本化两种结构化知识处理方法，建立包含五个关键领域的山羊养殖知识库，并集成在线搜索模块实现实时信息检索。

Result: 异构知识融合方法效果最佳，验证集准确率87.90%，测试集84.22%。在文本、表格、决策树问答任务中准确率均超过85%，证明了模块化设计中结构化知识融合的有效性。

Conclusion: 研究结果表明所提出的系统在山羊养殖实际应用中具有鲁棒性和可靠性，错误分析显示遗漏是主要错误类型，为进一步改进检索覆盖和上下文整合提供了方向。

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [33] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: LLM智能体在UNO游戏中作为助手帮助其他玩家获胜的能力测试，发现虽然模型能超越随机基线表现，但很少能显著帮助其他玩家获胜


<details>
  <summary>Details</summary>
Motivation: 测试基于大语言模型的智能体是否能作为主动参与者真正帮助人类完成目标，特别是在协作性游戏任务中的表现

Method: 构建工具让仅解码器LLM在RLCard游戏环境中作为智能体参与UNO游戏，接收完整游戏状态信息并使用两种不同的提示策略进行文本响应，评估从1B到70B参数的不同规模模型

Result: 所有模型在玩UNO时都能成功超越随机基线表现，但很少有模型能够显著帮助其他玩家获胜

Conclusion: 虽然LLM在单独游戏中表现良好，但在协作助人任务中的能力仍然有限，模型规模对性能有影响但不足以实现有效的协作帮助

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [34] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [35] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 将WaveFunctionCollapse重构为马尔可夫决策过程，分离局部约束满足和全局目标优化，相比传统联合优化方法在复杂任务中表现更优


<details>
  <summary>Details</summary>
Motivation: 解决程序化内容生成中需要同时满足设计者指定目标和瓦片集隐含邻接约束的挑战，传统联合优化方法在任务复杂度增加时表现不佳

Method: 将WaveFunctionCollapse重新表述为马尔可夫决策过程(MDP)，利用WFC的传播机制强制执行约束满足，让外部优化算法专注于目标最大化

Result: 在多领域不同难度任务中，联合优化方法随着任务复杂度增加而困难，且始终不如基于WFC-MDP的优化方法

Conclusion: 将局部约束满足与全局目标优化解耦具有明显优势，WFC-MDP方法在程序化内容生成中优于传统联合优化方法

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [36] [Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae](https://arxiv.org/abs/2509.09982)
*Stav Armoni-Friedmann,Hana Chockler,David A. Kelly*

Main category: cs.AI

TL;DR: 本文提出了基于实际因果关系的变量重要性度量方法，并在大规模基准测试中评估了最先进的XAI工具，同时开发了新的B-ReX工具并证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 由于解释的主观性，评估可解释AI(XAI)方法具有挑战性。本文专注于表格数据和布尔函数预测的特定用例，旨在提供更精确的评估框架。

Method: 提出了基于实际因果关系的正式变量重要性度量方法，并开发了新的XAI工具B-ReX（基于现有ReX工具改进）。在大规模基准测试中评估了最先进的XAI工具。

Result: B-ReX在随机10值布尔公式上实现了0.072±0.012的Jensen-Shannon散度，优于其他黑盒XAI工具。

Conclusion: 基于实际因果关系的度量方法为XAI评估提供了更精确的框架，B-ReX工具在布尔函数预测任务中表现出优越性能，为表格数据的XAI研究提供了有价值的贡献。

Abstract: Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae

</details>


### [37] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: 基于大语言模型的多代理系统隐私保护方案GAMA，通过区分私有和公共空间以及匿名化机制来保护敏感数据，同时通过知识增强和逻辑增强模块减少语义损失。


<details>
  <summary>Details</summary>
Motivation: 解决基于LLM的多代理系统在处理涉及隐私数据任务时的安全问题，无法安全使用部署在公共空间的高性能LLM。

Method: 提出GAMA系统，将代理工作空间分为私有空间（处理敏感数据）和公共空间（使用匿名化数据），采用域规则知识增强（DRKE）和反证逻辑增强（DLE）模块来减少匿名化导致的语义损失。

Result: 在Trivia Creative Writing和Logic Grid Puzzle数据集上表现超过现有最佳模型，在新设计的知识隐私保护和逻辑隐私保护数据集上也显示出良好的隐私保护能力。

Conclusion: GAMA系统能够在保护敏感数据隐私的同时，保持高效的任务处理能力，为LLM基多代理系统提供了可靠的隐私保护解决方案。

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [38] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents是一个基于多极任务处理图和IF-THEN规则的多智能体协作框架，旨在解决复杂任务规划中的不确定性挑战，在知识型和逻辑型问答任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然提升了多智能体系统的能力，但在处理高度复杂且具有不确定性的任务时，仍然面临任务规划效果不佳的问题，经常产生误导性或错误的输出，阻碍任务执行。

Method: 提出XAgents框架，使用多极任务处理图实现动态任务规划和处理任务不确定性，在子任务处理中集成领域特定的IF-THEN规则约束智能体行为，同时使用全局规则增强智能体间协作。

Result: 在三个不同数据集上的评估表明，XAgents在知识型和逻辑型问答任务中持续超越最先进的单智能体和多智能体方法。

Conclusion: XAgents通过创新的多极任务处理图和规则集成机制，有效解决了复杂任务规划中的不确定性挑战，为多智能体系统提供了更可靠的协作框架。

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [39] [AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework](https://arxiv.org/abs/2509.10104)
*Sofia Vei,Paolo Giudici,Pavlos Sermpezis,Athena Vakali,Adelaide Emma Bernardelli*

Main category: cs.AI

TL;DR: 提出了AI Harmonics框架，使用基于序数严重性数据的新型AI危害评估指标(AIH)，从人类中心视角评估AI危害，重点关注政治和物理危害的紧急缓解需求


<details>
  <summary>Details</summary>
Motivation: 现有AI风险评估模型过于关注内部合规性，忽视了多元利益相关者视角和现实世界后果，需要转向人类中心、危害严重性自适应的评估方法

Method: 基于实证事件数据，开发AI Harmonics框架，包含AIH指标利用序数严重性数据捕捉相对影响，无需精确数值估计，结合稳健通用方法和数据驱动的利益相关者感知框架

Result: 实验证实政治和物理危害集中度最高需紧急缓解：政治危害侵蚀公众信任，物理危害造成严重甚至生命威胁风险，AI Harmonics能一致识别不均匀危害分布

Conclusion: 该框架使政策制定者和组织能够有效针对缓解措施，强调了方法在现实世界中的相关性和实用性

Abstract: The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.

</details>


### [40] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: 本文提出"沙箱经济"框架分析AI自主代理人经济，建议通过策効市场设计确保其与人类长期福禅对齐


<details>
  <summary>Details</summary>
Motivation: 身份自主AI代理人的快速采用正在形成一个新的经济层，这个系统的规模和速度超越了直接人类监管能力，需要框架来分析和对冲其潜在机遇与风险

Method: 提出以起源（自发出现vs意图性）和与人类经济分离程度（可透性vs不可透性）为两维度的"沙箱经济"分析框架，考虑拍卖机制、AI"任务经济"设计和社会技术基础设施

Result: 分析显示当前趋势指向一个自发出现的广泛且高度可透的AI代理人经济，既带来无与伦比的协调机遇，也带来系统性经济风险和加剧不平等挑战

Conclusion: 建议主动设计可策効的代理人市场，通过拍卖机制、任务经济和相关基础设施确保技术变革与人类长期福禅对齐

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [41] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 提出了Robust Sparse Sampling (RSS)算法，这是第一个具有有限样本理论性能保证的鲁棒MDP在线规划算法，能够在模型不确定的环境中实现可处理的鲁棒策略计算。


<details>
  <summary>Details</summary>
Motivation: 在线规划方法在实际应用中，生成模型往往从有限数据中学习，存在近似误差，这会降低性能或导致不安全行为。现有的鲁棒MDP方法计算量大，不适合实时使用。

Method: 基于Sample Average Approximation (SAA)的高效性和理论特性，通过计算鲁棒价值函数而非名义价值函数，开发了RSS算法。该算法适用于无限或连续状态空间，样本和计算复杂度与状态空间大小无关。

Result: RSS在动态不确定的环境中优于标准稀疏采样方法，具有理论性能保证，能够实现可处理的在线鲁棒规划。

Conclusion: RSS是第一个适用于鲁棒MDP的在线规划算法，具有有限样本理论保证，为模型不确定环境中的安全决策提供了有效的解决方案。

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [42] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: 多段代理框架通过LLM代理自主规划模拟、组装力场并执行模拟，实现高正确性和可复现性的自动化空材料形彩定征


<details>
  <summary>Details</summary>
Motivation: 解决空材料形彩定征中模拟设置复杂和力场选择困难的问题，以加速材料发现

Method: 使用LLM基础的多代理框架，让代理自主理解定征任务、规划模拟、组装力场、执行模拟并解释结果指导后续步骤

Result: 初始评估显示高正确性和可复现性，为完全自主、可扩展的材料形彩定征提供潜力

Conclusion: 该多代理框架有望实现完全自主的空材料形彩定征，为材料发现提供可扩展的自动化解决方案

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>


### [43] [Compartmentalised Agentic Reasoning for Clinical NLI](https://arxiv.org/abs/2509.10222)
*Maël Jullien,Lei Xu,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: CARENLI是一个用于临床自然语言推理的模块化代理推理框架，通过将知识访问与原则推理分离，显著提高了推理准确性和可审计性


<details>
  <summary>Details</summary>
Motivation: 传统假设认为扩大数据和参数规模会带来更结构化、可泛化的内部表示，但本文质疑这一假设在临床自然语言推理中的有效性

Method: 提出CARENLI框架，将前提-陈述对路由到特定推理家族的求解器，并通过规划器、验证器和精炼器强制执行可审计程序

Result: 在四个LLM上，CARENLI将保真度提高了高达42个百分点，在因果归因达到98.0%，在风险状态抽象达到81.2%。验证器以接近天花板可靠性标记违规，精炼器纠正了大量认知错误

Conclusion: LLM通常保留相关事实但在推理不明确时默认使用启发式方法，CARENLI使这种分离变得明确，同时为更安全、可审计的推理提供了框架

Abstract: A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.

</details>


### [44] [Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering](https://arxiv.org/abs/2509.10249)
*Hanna Abi Akl*

Main category: cs.AI

TL;DR: 这篇论文研究了小型语言模型在逻辑推理任务中的表现，探索用更简洁的逻辑语言替代自然语言的效果


<details>
  <summary>Details</summary>
Motivation: 语言模型在推理能力方面的不足影响了本体论工程等任务，需要探索如何通过形式方法提升小型语言模型的推理性能

Method: 设计了一系列预实验，测试不同语法表达逻辑问题对小型语言模型在推理任务上性能的影响

Result: 发现可以用更简洁的逻辑语言替代自然语言，同时保持良好的推理性能

Conclusion: 这些结果为精炼小型语言模型在本体论工程中的作用提供了基础

Abstract: Recent advances in Language Models (LMs) have failed to mask their
shortcomings particularly in the domain of reasoning. This limitation impacts
several tasks, most notably those involving ontology engineering. As part of a
PhD research, we investigate the consequences of incorporating formal methods
on the performance of Small Language Models (SLMs) on reasoning tasks.
Specifically, we aim to orient our work toward using SLMs to bootstrap ontology
construction and set up a series of preliminary experiments to determine the
impact of expressing logical problems with different grammars on the
performance of SLMs on a predefined reasoning task. Our findings show that it
is possible to substitute Natural Language (NL) with a more compact logical
language while maintaining a strong performance on reasoning tasks and hope to
use these results to further refine the role of SLMs in ontology engineering.

</details>


### [45] [The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis](https://arxiv.org/abs/2509.10297)
*Eoin O'Doherty,Nicole Weinrauch,Andrew Talone,Uri Klempner,Xiaoyuan Yi,Xing Xie,Yi Zeng*

Main category: cs.AI

TL;DR: 这篇论文通过实验研究大语言模型在道德困境中的价值偏好，发现模型一致偏向关怀和美德价值，而自由主义选择被扣分，揭示了AI系统的道德偏见和对齐设计的挑战。


<details>
  <summary>Details</summary>
Motivation: 研究AI系统如何与人类道德价值对齐，以及模型架构、文化起源和可解释性如何影响道德偏好。

Method: 对六个大语言模型进行定量实验，通过18个代表五种道德框架的困境进行结果排名和评分。

Result: 发现所有模型都显示出高度一致的价值偏向：关怀和美德价值被评为最道德，而自由主义选择被一贴扣分。具备推理能力的模型对语境更敏感且提供更丰富的解释，而无推理能力的模型判断更统一但不透明。

Conclusion: 研究强调了可解释性和文化意识作为关键设计原则的重要性，以指导AI向透明、对齐和共生的未来发展。

Abstract: Artificial intelligence (AI) is advancing at a pace that raises urgent
questions about how to align machine decision-making with human moral values.
This working paper investigates how leading AI systems prioritize moral
outcomes and what this reveals about the prospects for human-AI symbiosis. We
address two central questions: (1) What moral values do state-of-the-art large
language models (LLMs) implicitly favour when confronted with dilemmas? (2) How
do differences in model architecture, cultural origin, and explainability
affect these moral preferences? To explore these questions, we conduct a
quantitative experiment with six LLMs, ranking and scoring outcomes across 18
dilemmas representing five moral frameworks. Our findings uncover strikingly
consistent value biases. Across all models, Care and Virtue values outcomes
were rated most moral, while libertarian choices were consistently penalized.
Reasoning-enabled models exhibited greater sensitivity to context and provided
richer explanations, whereas non-reasoning models produced more uniform but
opaque judgments. This research makes three contributions: (i) Empirically, it
delivers a large-scale comparison of moral reasoning across culturally distinct
LLMs; (ii) Theoretically, it links probabilistic model behaviour with
underlying value encodings; (iii) Practically, it highlights the need for
explainability and cultural awareness as critical design principles to guide AI
toward a transparent, aligned, and symbiotic future.

</details>


### [46] [State Algebra for Propositional Logic](https://arxiv.org/abs/2509.10326)
*Dmitry Lesnik,Tobias Schäfer*

Main category: cs.AI

TL;DR: State Algebra是一个使用代数方法表示和操作命题逻辑的新框架，包含Set、Coordinate和Row Decomposition三个层次表示，在保持语义清晰的同时支持高效计算。


<details>
  <summary>Details</summary>
Motivation: 开发一个灵活的代数框架来表示命题逻辑，既能保持明确的语义基础，又能支持高效的代数计算，并为搜索算法和知识编译提供工具。

Method: 构建三层表示层次结构：Set（集合表示）、Coordinate（坐标表示）和Row Decomposition（行分解表示），通过代数引擎进行计算，允许在规范性和灵活性之间进行权衡。

Result: 虽然默认的状态向量归约不是规范的，但通过应用固定的变量顺序可以获得唯一的规范形式。这种权衡使得框架能够更紧凑地表示某些问题类别。

Conclusion: State Algebra提供了一个强大的代数框架来处理命题逻辑，具有灵活的表示能力，可自然扩展到概率逻辑和加权模型计数，为算法开发提供了新工具。

Abstract: This paper presents State Algebra, a novel framework designed to represent
and manipulate propositional logic using algebraic methods. The framework is
structured as a hierarchy of three representations: Set, Coordinate, and Row
Decomposition. These representations anchor the system in well-known semantics
while facilitating the computation using a powerful algebraic engine. A key
aspect of State Algebra is its flexibility in representation. We show that
although the default reduction of a state vector is not canonical, a unique
canonical form can be obtained by applying a fixed variable order during the
reduction process. This highlights a trade-off: by foregoing guaranteed
canonicity, the framework gains increased flexibility, potentially leading to
more compact representations of certain classes of problems. We explore how
this framework provides tools to articulate both search-based and knowledge
compilation algorithms and discuss its natural extension to probabilistic logic
and Weighted Model Counting.

</details>


### [47] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: A2P Scaffolding框架通过因果推理方法将多智能体系统中的故障归因从模式识别任务转化为结构化因果推理任务，显著提高了步骤级准确率


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统中的故障归因方法准确率极低（低于17%），无法进行有效的反事实推理来确定修正单个动作是否能避免任务失败

Method: 提出了Abduct-Act-Predict (A2P) Scaffolding框架，通过三个结构化步骤：溯因推理推断行动的根本原因、定义最小修正干预、模拟后续轨迹验证干预效果

Result: 在Algorithm-Generated数据集上达到47.46%的步骤级准确率（比基线16.67%提高2.85倍），在Hand-Crafted数据集上达到29.31%准确率（比基线12.07%提高2.43倍）

Conclusion: 通过因果推理视角重构问题，A2P Scaffolding为自动化故障归因提供了更稳健、可验证且准确度显著提升的解决方案

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>


### [48] [Mutual Information Tracks Policy Coherence in Reinforcement Learning](https://arxiv.org/abs/2509.10423)
*Cameron Reid,Wael Hafez,Amirhossein Nazeri*

Main category: cs.AI

TL;DR: 提出基于信息论的框架，通过分析状态-动作互信息模式来诊断RL系统部署时的异常，能够区分传感器故障和驱动器故障，实现精确故障定位。


<details>
  <summary>Details</summary>
Motivation: 现实世界中部署的RL智能体面临传感器故障、驱动器磨损和环境变化等问题，但缺乏内在机制来检测和诊断这些故障。

Method: 使用信息论框架分析状态-动作互信息模式，通过受控扰动实验验证信息指标对系统故障的差异诊断能力。

Result: 成功学习表现出特征性信息特征：状态-动作互信息从0.84增长到2.83比特（增长238%）；信息指标能够区分观测空间噪声（传感器故障）和动作空间噪声（驱动器故障）。

Conclusion: 信息模式既是学习的特征，也是系统健康的诊断工具，为能够自主故障检测和基于信息论原理进行策略调整的自适应RL系统奠定了基础。

Abstract: Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.

</details>
