<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 14]
- [cs.CR](#cs.CR) [Total: 8]
- [cs.AI](#cs.AI) [Total: 33]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Automated File-Level Logging Generation for Machine Learning Applications using LLMs: A Case Study using GPT-4o Mini](https://arxiv.org/abs/2508.04820)
*Mayra Sofia Ruiz Rodriguez,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: GPT-4o mini生成文件级日志的能力评估显示，63.91%的日志位置与人工一致，但存在82.66%的过度日志问题。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）在文件级日志生成中的潜力，尤其是在机器学习项目中，以提升系统可靠性。

Method: 从171个ML仓库中提取4,073个Python文件，移除原始日志后，用GPT-4o mini生成日志，并评估日志位置、级别、变量和文本质量。

Result: LLM在63.91%的情况下与人工日志位置一致，但过度日志率达82.66%，且存在日志位置和项目规范不一致的问题。

Conclusion: LLM在文件级日志生成中表现有潜力，但需解决过度日志和规范对齐问题才能实用。

Abstract: Logging is essential in software development, helping developers monitor
system behavior and aiding in debugging applications. Given the ability of
large language models (LLMs) to generate natural language and code, researchers
are exploring their potential to generate log statements. However, prior work
focuses on evaluating logs introduced in code functions, leaving file-level log
generation underexplored -- especially in machine learning (ML) applications,
where comprehensive logging can enhance reliability. In this study, we evaluate
the capacity of GPT-4o mini as a case study to generate log statements for ML
projects at file level. We gathered a set of 171 ML repositories containing
4,073 Python files with at least one log statement. We identified and removed
the original logs from the files, prompted the LLM to generate logs for them,
and evaluated both the position of the logs and log level, variables, and text
quality of the generated logs compared to human-written logs. In addition, we
manually analyzed a representative sample of generated logs to identify common
patterns and challenges. We find that the LLM introduces logs in the same place
as humans in 63.91% of cases, but at the cost of a high overlogging rate of
82.66%. Furthermore, our manual analysis reveals challenges for file-level
logging, which shows overlogging at the beginning or end of a function,
difficulty logging within large code blocks, and misalignment with
project-specific logging conventions. While the LLM shows promise for
generating logs for complete files, these limitations remain to be addressed
for practical implementation.

</details>


### [2] [Automated Bug Frame Retrieval from Gameplay Videos Using Vision-Language Models](https://arxiv.org/abs/2508.04895)
*Wentao Lu,Alexander Senchenko,Abram Hindle,Cor-Paul Bezemer*

Main category: cs.SE

TL;DR: 论文提出了一种自动化流程，将游戏视频缩减为最能匹配错误描述的单帧图像，显著减少开发者的手动工作量。


<details>
  <summary>Details</summary>
Motivation: 现代游戏工作室快速发布新版本和补丁，产生大量包含游戏视频的错误报告，手动验证这些报告耗时且难以扩展。

Method: 使用FFmpeg提取关键帧，再通过视觉-语言模型（GPT-4o）根据错误描述匹配并选择最具代表性的帧。

Result: 在真实游戏视频和JIRA错误报告上测试，F1分数为0.79，准确率为0.89。性能在不同错误类别中表现不一。

Conclusion: 该方法通过提供即时信息图像，显著减少了手动工作量，提升了错误分类和回归检查的效率。

Abstract: Modern game studios deliver new builds and patches at a rapid pace,
generating thousands of bug reports, many of which embed gameplay videos. To
verify and triage these bug reports, developers must watch the submitted
videos. This manual review is labour-intensive, slow, and hard to scale. In
this paper, we introduce an automated pipeline that reduces each video to a
single frame that best matches the reported bug description, giving developers
instant visual evidence that pinpoints the bug.
  Our pipeline begins with FFmpeg for keyframe extraction, reducing each video
to a median of just 1.90% of its original frames while still capturing bug
moments in 98.79 of cases. These keyframes are then evaluated by a
vision--language model (GPT-4o), which ranks them based on how well they match
the textual bug description and selects the most representative frame. We
evaluated this approach using real-world developer-submitted gameplay videos
and JIRA bug reports from a popular First-Person Shooter (FPS) game. The
pipeline achieves an overall F1 score of 0.79 and Accuracy of 0.89 for the
top-1 retrieved frame. Performance is highest for the Lighting & Shadow (F1 =
0.94), Physics & Collision (0.86), and UI & HUD (0.83) bug categories, and
lowest for Animation & VFX (0.51).
  By replacing video viewing with an immediately informative image, our
approach dramatically reduces manual effort and speeds up triage and regression
checks, offering practical benefits to quality assurance (QA) teams and
developers across the game industry.

</details>


### [3] [Charting Uncertain Waters: A Socio-Technical Framework for Navigating GenAI's Impact on Open Source Communities](https://arxiv.org/abs/2508.04921)
*Zixuan Feng,Reed Milewicz,Emerson Murphy-Hill,Tyler Menezes,Alexander Serebrenik,Igor Steinmacher,Anita Sarma*

Main category: cs.SE

TL;DR: 探讨生成式AI对开源软件社区的潜在影响，提出通过社会技术框架分析风险与机遇。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展为开源软件社区带来不确定性和挑战，缺乏明确框架可能导致协作精神受损。

Method: 采用基于McLuhan Tetrad的社会技术框架，进行情景驱动的概念性探索，分析四个领域的影响。

Result: 识别了生成式AI对软件实践、文档、社区参与和治理的潜在风险与机遇。

Conclusion: 开源社区领导者和研究者可通过主动采用该框架，塑造生态系统的未来，而非被动应对技术变革。

Abstract: Open Source Software communities face a wave of uncertainty as Generative AI
rapidly transforms how software is created, maintained, and governed. Without
clear frameworks, communities risk being overwhelmed by the complexity and
ambiguity introduced by GenAI, threatening the collaborative ethos that
underpins OSS. We conduct a scenario-driven, conceptual exploration using a
socio-technical framework inspired by McLuhan's Tetrad to surface both risks
and opportunities for community resilience amid GenAI-driven disruption of OSS
development across four domains: software practices, documentation, community
engagement, and governance. By adopting this lens, OSS leaders and researchers
can proactively shape the future of their ecosystems, rather than simply
reacting to technological upheaval.

</details>


### [4] [Taxonomy of Faults in Attention-Based Neural Networks](https://arxiv.org/abs/2508.04925)
*Sigma Jahan,Saurabh Singh Rajput,Tushar Sharma,Mohammad Masudur Rahman*

Main category: cs.SE

TL;DR: 论文首次全面实证研究了基于注意力的神经网络（ABNNs）中的故障，提出了七种注意力特有的故障类别，并提供了诊断启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习故障分类法未能充分捕捉注意力机制引入的独特故障，导致缺乏可操作的诊断指导。

Method: 通过系统分析555个真实故障（来自96个项目），开发了新的故障分类法，并分析症状与根因的关联。

Result: 超过一半的ABNN故障源于注意力架构特有的机制，提出了四种诊断启发式方法，解释了33.0%的注意力特有故障。

Conclusion: 研究填补了注意力机制故障分类的空白，为基于注意力的模型提供了首个系统性诊断指导。

Abstract: Attention mechanisms are at the core of modern neural architectures, powering
systems ranging from ChatGPT to autonomous vehicles and driving a major
economic impact. However, high-profile failures, such as ChatGPT's nonsensical
outputs or Google's suspension of Gemini's image generation due to attention
weight errors, highlight a critical gap: existing deep learning fault
taxonomies might not adequately capture the unique failures introduced by
attention mechanisms. This gap leaves practitioners without actionable
diagnostic guidance. To address this gap, we present the first comprehensive
empirical study of faults in attention-based neural networks (ABNNs). Our work
is based on a systematic analysis of 555 real-world faults collected from 96
projects across ten frameworks, including GitHub, Hugging Face, and Stack
Overflow. Through our analysis, we develop a novel taxonomy comprising seven
attention-specific fault categories, not captured by existing work. Our results
show that over half of the ABNN faults arise from mechanisms unique to
attention architectures. We further analyze the root causes and manifestations
of these faults through various symptoms. Finally, by analyzing symptom-root
cause associations, we identify four evidence-based diagnostic heuristics that
explain 33.0% of attention-specific faults, offering the first systematic
diagnostic guidance for attention-based models.

</details>


### [5] [Generative AI for Object-Oriented Programming: Writing the Right Code and Reasoning the Right Logic](https://arxiv.org/abs/2508.05005)
*Gang Xu,Airong Wang,Yushan Pan*

Main category: cs.SE

TL;DR: 论文探讨了大型语言模型（LLMs）与面向对象编程（OOP）的结合，提出了如何利用LLMs提升OOP学习和代码编写效率的方法，并讨论了评估AI工具的方式。


<details>
  <summary>Details</summary>
Motivation: LLMs在多个领域有广泛应用，但其与OOP的结合尚未充分研究。论文旨在填补这一空白，探索LLMs如何提升OOP任务的效果。

Method: 从程序员、初学者和经验丰富的程序员的角度出发，识别编码工作流中LLMs能提供显著帮助的关键节点，并提出增强逻辑推理和代码编写的方法。

Result: 提出了LLMs与OOP结合的具体应用场景和方法，为提升编程体验提供了新思路。

Conclusion: LLMs在OOP领域有巨大潜力，未来研究应进一步探索其实际应用和评估方式。

Abstract: We find ourselves in the midst of an explosion in artificial intelligence
research, particularly with large language models (LLMs). These models have
diverse applications spanning finance, commonsense knowledge graphs, medicine,
and visual analysis. In the world of Object-Oriented Programming(OOP), a robust
body of knowledge and methods has been developed for managing complex tasks
through object-oriented thinking. However, the intersection of LLMs with OOP
remains an underexplored territory. Empirically, we currently possess limited
understanding of how LLMs can enhance the effectiveness of OOP learning and
code writing, as well as how we can evaluate such AI-powered tools. Our work
aims to address this gap by presenting a vision from the perspectives of key
stakeholders involved in an OOP task: programmers, mariners, and experienced
programmers. We identify critical junctures within typical coding workflows
where the integration of LLMs can offer significant benefits. Furthermore, we
propose ways to augment existing logical reasoning and code writing, ultimately
enhancing the programming experience.

</details>


### [6] [An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack](https://arxiv.org/abs/2508.05034)
*Arabat,Ali,Sayagh,Mohammed,Hassine,Jameleddine*

Main category: cs.SE

TL;DR: 论文研究了软件系统中依赖关系管理的重要性，提出了一种半自动化的机器学习方法，用于预测和识别变更之间的依赖关系，并在OpenStack中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂度的增加，准确识别和管理变更之间的依赖关系变得至关重要，尤其是在多团队协作的大型系统中。依赖关系的延迟识别会导致开发效率低下和部署问题。

Method: 通过初步研究OpenStack中的依赖关系，发现依赖关系通常在代码审查阶段才被识别。为此，提出了两个机器学习模型：一个预测变更间依赖的可能性，另一个识别具体的依赖变更对。

Result: 模型表现良好，平均AUC分数分别为79.33%和91.89%，Brier分数为0.11和0.014。第二个模型在top-k召回率上表现优异，但top-k精确度有待提升。

Conclusion: 提出的半自动化方法能有效帮助开发者提前识别依赖关系，减少延迟和搜索成本，提升开发效率。

Abstract: As software systems grow in complexity, accurately identifying and managing
dependencies among changes becomes increasingly critical. For instance, a
change that leverages a function must depend on the change that introduces it.
Establishing such dependencies allows CI/CD pipelines to build and orchestrate
changes effectively, preventing build failures and incomplete feature
deployments. In modern software systems, dependencies often span multiple
components across teams, creating challenges for development and deployment.
They serve various purposes, from enabling new features to managing
configurations, and can even involve traditionally independent changes like
documentation updates. To address these challenges, we conducted a preliminary
study on dependency management in OpenStack, a large-scale software system. Our
study revealed that a substantial portion of software changes in OpenStack over
the past 10 years are interdependent. Surprisingly, 51.08% of these
dependencies are identified during the code review phase-after a median delay
of 5.06 hours-rather than at the time of change creation. Developers often
spend a median of 57.12 hours identifying dependencies, searching among a
median of 463 other changes. To help developers proactively identify
dependencies, we propose a semi-automated approach that leverages two ML
models. The first model predicts the likelihood of dependencies among changes,
while the second identifies the exact pairs of dependent changes. Our proposed
models demonstrate strong performance, achieving average AUC scores of 79.33%
and 91.89%, and Brier scores of 0.11 and 0.014, respectively. Indeed, the
second model has a good top-k recall across all types of pairs, while the top-k
precision has room for improvement.

</details>


### [7] [LadyBug: A GitHub Bot for UI-Enhanced Bug Localization in Mobile Apps](https://arxiv.org/abs/2508.05085)
*Junayed Mahmud,James Chen,Terry Achille,Camilo Alvarez-Velez,Darren Dean Bansil,Patrick Ijieh,Samar Karanch,Nadeeshan De Silva,Oscar Chaparro,Andrian Marcus,Kevin Moran*

Main category: cs.SE

TL;DR: LadyBug是一个GitHub机器人，通过结合UI交互信息和文本检索，自动定位Android应用中的bug。


<details>
  <summary>Details</summary>
Motivation: 提高Android应用中bug定位的准确性和效率，结合文本和UI信息。

Method: 连接到GitHub仓库，通过问题跟踪器触发，开发者上传bug复现轨迹，结合文本和UI信息检索可能包含bug的文件。

Result: 在包含80个bug报告的基准测试中，LadyBug优于纯文本检索基线，UI信息显著提高了定位准确性。

Conclusion: LadyBug是一个有效的开源工具，结合UI和文本信息显著提升bug定位效果。

Abstract: This paper introduces LadyBug, a GitHub bot that automatically localizes bugs
for Android apps by combining UI interaction information with text retrieval.
LadyBug connects to an Android app's GitHub repository, and is triggered when a
bug is reported in the corresponding issue tracker. Developers can then record
a reproduction trace for the bug on a device or emulator and upload the trace
to LadyBug via the GitHub issue tracker. This enables LadyBug to utilize both
the text from the original bug description, and UI information from the
reproduction trace to accurately retrieve a ranked list of files from the
project that most likely contain the reported bug.
  We empirically evaluated LadyBug using an automated testing pipeline and
benchmark called RedWing that contains 80 fully-localized and reproducible bug
reports from 39 Android apps. Our results illustrate that LadyBug outperforms
text-retrieval-based baselines and that the utilization of UI information leads
to a substantial increase in localization accuracy. LadyBug is an open-source
tool, available at https://github.com/LadyBugML/ladybug.
  A video showing the capabilities of Ladybug can be viewed here:
https://youtu.be/hI3tzbRK0Cw

</details>


### [8] [Posterior-GRPO: Rewarding Reasoning Processes in Code Generation](https://arxiv.org/abs/2508.05170)
*Lishui Fan,Yu Zhang,Mouxiang Chen,Zhongxin Liu*

Main category: cs.SE

TL;DR: 论文提出了一种统一框架，结合推理过程质量优化强化学习（RL）的代码生成，通过新基准和奖励模型提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前RL方法仅依赖测试结果奖励，忽略了中间推理过程质量，易导致奖励滥用。

Method: 开发LCB-RB基准和OD-based奖励模型，引入P-GRPO方法选择性奖励成功任务的推理过程。

Result: 7B参数模型在代码生成任务中表现优异，超越基线4.5%，接近GPT-4-Turbo。

Conclusion: 框架有效提升推理质量，避免奖励滥用，并展示出在数学任务中的泛化能力。

Abstract: Reinforcement learning (RL) has significantly advanced code generation for
large language models (LLMs). However, current paradigms rely on outcome-based
rewards from test cases, neglecting the quality of the intermediate reasoning
process. While supervising the reasoning process directly is a promising
direction, it is highly susceptible to reward hacking, where the policy model
learns to exploit the reasoning reward signal without improving final outcomes.
To address this, we introduce a unified framework that can effectively
incorporate the quality of the reasoning process during RL. First, to enable
reasoning evaluation, we develop LCB-RB, a benchmark comprising preference
pairs of superior and inferior reasoning processes. Second, to accurately score
reasoning quality, we introduce an Optimized-Degraded based (OD-based) method
for reward model training. This method generates high-quality preference pairs
by systematically optimizing and degrading initial reasoning paths along
curated dimensions of reasoning quality, such as factual accuracy, logical
rigor, and coherence. A 7B parameter reward model with this method achieves
state-of-the-art (SOTA) performance on LCB-RB and generalizes well to other
benchmarks. Finally, we introduce Posterior-GRPO (P-GRPO), a novel RL method
that conditions process-based rewards on task success. By selectively applying
rewards to the reasoning processes of only successful outcomes, P-GRPO
effectively mitigates reward hacking and aligns the model's internal reasoning
with final code correctness. A 7B parameter model with P-GRPO achieves superior
performance across diverse code generation tasks, outperforming outcome-only
baselines by 4.5%, achieving comparable performance to GPT-4-Turbo. We further
demonstrate the generalizability of our approach by extending it to
mathematical tasks. Our models, dataset, and code are publicly available.

</details>


### [9] [AI-assisted JSON Schema Creation and Mapping](https://arxiv.org/abs/2508.05192)
*Felix Neubauer,Jürgen Pleiss,Benjamin Uekermann*

Main category: cs.SE

TL;DR: 提出了一种结合大语言模型（LLMs）和确定性技术的混合方法，用于通过自然语言输入创建和修改JSON Schema，并集成到开源工具MetaConfigurator中。


<details>
  <summary>Details</summary>
Motivation: 许多领域缺乏标准化模型，且非专家难以创建模型，因此需要降低结构化数据建模和数据集成的门槛。

Method: 结合LLMs和确定性技术，支持自然语言输入的JSON Schema创建、修改和映射，并通过MetaConfigurator工具实现可视化编辑、验证等功能。

Result: 在化学领域的应用示例中验证了方法的适用性，显著降低了非专家进行数据建模和集成的难度。

Conclusion: 通过自然语言交互与确定性保障的结合，为非专家提供了更便捷的结构化数据建模和集成解决方案。

Abstract: Model-Driven Engineering (MDE) places models at the core of system and data
engineering processes. In the context of research data, these models are
typically expressed as schemas that define the structure and semantics of
datasets. However, many domains still lack standardized models, and creating
them remains a significant barrier, especially for non-experts. We present a
hybrid approach that combines large language models (LLMs) with deterministic
techniques to enable JSON Schema creation, modification, and schema mapping
based on natural language inputs by the user. These capabilities are integrated
into the open-source tool MetaConfigurator, which already provides visual model
editing, validation, code generation, and form generation from models. For data
integration, we generate schema mappings from heterogeneous JSON, CSV, XML, and
YAML data using LLMs, while ensuring scalability and reliability through
deterministic execution of generated mapping rules. The applicability of our
work is demonstrated in an application example in the field of chemistry. By
combining natural language interaction with deterministic safeguards, this work
significantly lowers the barrier to structured data modeling and data
integration for non-experts.

</details>


### [10] [STEPWISE-CODEX-Bench: Evaluating Complex Multi-Function Comprehension and Fine-Grained Execution Reasoning](https://arxiv.org/abs/2508.05193)
*Kaiwen Yan,Yuhang Chang,Zirui Guo,Yaling Mou,Jiang Ming,Jingwei Sun*

Main category: cs.SE

TL;DR: SX-Bench是一个新的代码评估基准，专注于复杂多函数理解和细粒度执行推理，揭示了现有模型在高级推理能力上的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有基准（如HumanEval和MBPP）主要测试功能正确性，而推理基准（如CRUXEVAL）局限于简单场景，导致高级模型得分饱和，缺乏区分度。

Method: 提出SX-Bench，通过多子函数协作任务（如链式调用、嵌套循环）评估整体控制和数据流建模能力，以“计算步骤”为最小执行单元。

Result: 评估20多个主流模型（包括14个推理增强模型），显示SX-Bench区分度高，如OpenAI-O3在Hard-Reasoning任务中仅78.37%准确率。

Conclusion: SX-Bench将代码评估从“单函数验证”推进到“多函数动态推理”，为深入评估高级代码智能模型提供了关键工具。

Abstract: In recent years, large language models (LLMs) have made significant progress
in code intelligence, yet systematically evaluating their code understanding
and reasoning abilities remains challenging. Mainstream benchmarks such as
HumanEval and MBPP primarily assess functional correctness, while reasoning
benchmarks like CRUXEVAL are limited to single-function, low-complexity
scenarios. As a result, advanced models achieve nearly saturated scores,
limiting their discriminative power. To address this, we present
STEPWISE-CODEX-Bench (SX-Bench), a novel benchmark designed for complex
multi-function understanding and fine-grained execution reasoning. SX-Bench
features tasks involving collaboration among multiple sub-functions (e.g.,
chained calls, nested loops), shifting evaluation towards overall control and
data flow modeling. It defines "computation steps" as the minimal execution
unit and requires models to predict the total number of steps in reasoning
tasks, thereby assessing a model's in-depth understanding of dynamic execution
beyond simple I/O matching. Evaluation on over 20 mainstream models (including
14 reasoning-enhanced models) demonstrates that SX-Bench is highly
discriminative: even the state-of-the-art OpenAI-O3 achieves only 78.37 percent
accuracy on Hard-Reasoning tasks, much lower than its saturated scores on
previous benchmarks, thereby revealing bottlenecks in complex and fine-grained
reasoning. We also release an automated pipeline combining program synthesis,
symbolic execution, and LLM-aided validation for efficient benchmark generation
and quality assurance. SX-Bench advances code evaluation from "single-function
verification" to "multi-function dynamic reasoning," providing a key tool for
the in-depth assessment of advanced code intelligence models.

</details>


### [11] [EvoGraph: Hybrid Directed Graph Evolution toward Software 3.0](https://arxiv.org/abs/2508.05199)
*Igor Costa,Christopher Baran*

Main category: cs.SE

TL;DR: EvoGraph是一个框架，通过有向图表示软件系统的各个部分，利用小型语言模型驱动突变操作，实现代码、文档等的自动演化，显著提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统软件系统在代码更新、文档维护和漏洞修复等方面的低效问题，推动软件系统向自适应、持续演化的方向发展。

Method: 使用有向图表示软件系统的各个部分，通过小型语言模型驱动突变操作，并结合多目标适应度选择最优结果。

Result: 在安全漏洞修复、代码翻译和文档维护等方面表现优异，显著降低了延迟和开发时间。

Conclusion: EvoGraph为软件系统的持续自适应演化提供了一种可行且高效的方法，为“软件3.0”时代奠定了基础。

Abstract: We introduce **EvoGraph**, a framework that enables software systems to
evolve their own source code, build pipelines, documentation, and tickets.
EvoGraph represents every artefact in a typed directed graph, applies learned
mutation operators driven by specialized small language models (SLMs), and
selects survivors with a multi-objective fitness. On three benchmarks, EvoGraph
fixes 83% of known security vulnerabilities, translates COBOL to Java with 93%
functional equivalence (test verified), and maintains documentation freshness
within two minutes. Experiments show a 40% latency reduction and a sevenfold
drop in feature lead time compared with strong baselines. We extend our
approach to **evoGraph**, leveraging language-specific SLMs for modernizing
.NET, Lisp, CGI, ColdFusion, legacy Python, and C codebases, achieving 82-96%
semantic equivalence across languages while reducing computational costs by 90%
compared to large language models. EvoGraph's design responds to empirical
failure modes in legacy modernization, such as implicit contracts, performance
preservation, and integration evolution. Our results suggest a practical path
toward Software 3.0, where systems adapt continuously yet remain under
measurable control.

</details>


### [12] [A Conceptual Model and Methodology for Sustainability-aware, IoT-enhanced Business Processes](https://arxiv.org/abs/2508.05301)
*Victoria Torres Bosch,Ronny Seiger,Manuela Albert Albiol,Antoni Mestre Gascon,Pedro Jose Valderas Aranda*

Main category: cs.SE

TL;DR: 本文提出了一种概念模型和方法论，旨在利用物联网（IoT）技术分析和提升业务流程（BPs）的可持续性，超越环境维度，实现更全面的可持续发展。


<details>
  <summary>Details</summary>
Motivation: 尽管业务流程管理（BPM）中的可持续性研究主要集中在环境问题上，但实现全面和持久的可持续性影响需要更系统的方法。物联网技术为业务流程提供了实时数据收集和自动化能力，具有提升可持续性的潜力。

Method: 提出一个概念模型，形式化表示关键可持续性概念，并连接BPM和IoT；开发一种结构化方法论，指导现有业务流程的系统分析、机会识别及可持续性增强的IoT-BPs实施。

Result: 通过旅游领域的示例和医疗保健案例研究验证了方法的可行性和实用性。

Conclusion: 该研究为利用IoT技术提升业务流程的可持续性提供了系统化的理论和实践指导，强调了超越环境维度的全面可持续性。

Abstract: The real-time data collection and automation capabilities offered by the
Internet of Things (IoT) are revolutionizing and transforming Business
Processes (BPs) into IoT-enhanced BPs, showing high potential for improving
sustainability. Although already studied in Business Process Management (BPM),
sustainability research has primarily focused on environmental concerns.
However, achieving a holistic and lasting impact requires a systematic approach
to address sustainability beyond the environmental dimension. This work
proposes a conceptual model and a structured methodology with the goal of
analyzing the potential of IoT to measure and improve the sustainability of
BPs. The conceptual model formally represents key sustainability concepts,
linking BPM and IoT by highlighting how IoT devices support and contribute to
sustainability. The methodology guides the systematic analysis of existing BPs,
identifies opportunities, and implements sustainability-aware, IoT-enhanced
BPs. The approach is illustrated through a running example from the tourism
domain and a case study in healthcare.

</details>


### [13] [Evaluating the Use of LLMs for Documentation to Code Traceability](https://arxiv.org/abs/2506.16440)
*Ebube Alor,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 论文评估了大型语言模型（LLMs）在文档与代码间建立追溯链接的能力，发现其性能优于传统方法，但在解释和多步链重建方面仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在自动化文档与代码追溯中的潜力，填补现有研究的空白。

Method: 通过系统实验评估LLMs在三个关键能力上的表现：追溯链接识别、关系解释质量和多步链重建，使用两个新数据集（Unity Catalog和Crawl4AI）。

Result: 最佳LLM在两个数据集上的F1分数分别为79.4%和80.4%，显著优于基线方法（TF-IDF、BM25和CodeBERT）。关系解释的完全准确率为42.9%-71.1%，部分准确率超过97%。

Conclusion: LLMs是强大的追溯工具，但仍需结合人工干预以解决其局限性，如命名假设和过度泛化等问题。

Abstract: Large Language Models (LLMs) offer new potential for automating
documentation-to-code traceability, yet their capabilities remain
underexplored. We present a comprehensive evaluation of LLMs (Claude 3.5
Sonnet, GPT-4o, and o3-mini) in establishing trace links between various
software documentation (including API references and user guides) and source
code. We create two novel datasets from two open-source projects (Unity Catalog
and Crawl4AI). Through systematic experiments, we assess three key
capabilities: (1) trace link identification accuracy, (2) relationship
explanation quality, and (3) multi-step chain reconstruction. Results show that
the best-performing LLM achieves F1-scores of 79.4% and 80.4% across the two
datasets, substantially outperforming our baselines (TF-IDF, BM25, and
CodeBERT). While fully correct relationship explanations range from 42.9% to
71.1%, partial accuracy exceeds 97%, indicating that fundamental connections
are rarely missed. For multi-step chains, LLMs maintain high endpoint accuracy
but vary in capturing precise intermediate links. Error analysis reveals that
many false positives stem from naming-based assumptions, phantom links, or
overgeneralization of architectural patterns. We demonstrate that task-framing,
such as a one-to-many matching strategy, is critical for performance. These
findings position LLMs as powerful assistants for trace discovery, but their
limitations could necessitate human-in-the-loop tool design and highlight
specific error patterns for future research.

</details>


### [14] [How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow](https://arxiv.org/abs/2507.10818)
*Jasmine Latendresse,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: LLMs推荐Python库时偏好第三方库，但存在可用性问题，如依赖解析和安装指导不足。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在编程任务中推荐库的行为，以提升其可靠性和可用性。

Method: 对六种LLMs进行实证研究，分析其推荐的Python库类型、特征及可用性。

Result: LLMs偏好成熟、流行的第三方库，但4.6%的库无法自动解析，仅两种模型提供安装指导。

Conclusion: LLM生成的代码在依赖管理上仍需改进，为开发者和研究者提供了优化方向。

Abstract: Software libraries are central to the functionality, security, and
maintainability of modern code. As developers increasingly turn to Large
Language Models (LLMs) to assist with programming tasks, understanding how
these models recommend libraries is essential. In this paper, we conduct an
empirical study of six state-of-the-art LLMs, both proprietary and open-source,
by prompting them to solve real-world Python problems sourced from Stack
Overflow. We analyze the types of libraries they import, the characteristics of
those libraries, and the extent to which the recommendations are usable out of
the box. Our results show that LLMs predominantly favour third-party libraries
over standard ones, and often recommend mature, popular, and permissively
licensed dependencies. However, we also identify gaps in usability: 4.6% of the
libraries could not be resolved automatically due to structural mismatches
between import names and installable packages, and only two models (out of six)
provided installation guidance. While the generated code is technically valid,
the lack of contextual support places the burden of manually resolving
dependencies on the user. Our findings offer actionable insights for both
developers and researchers, and highlight opportunities to improve the
reliability and usability of LLM-generated code in the context of software
dependencies.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [15] [Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)](https://arxiv.org/abs/2508.04894)
*Iyiola E. Olatunji,Franziska Boenisch,Jing Xu,Adam Dziedzic*

Main category: cs.CR

TL;DR: 该论文首次探索了图感知大语言模型（LLMs）在对抗攻击下的脆弱性，并提出了防御框架GALGUARD。


<details>
  <summary>Details</summary>
Motivation: 研究图感知LLMs在对抗攻击下的鲁棒性，填补了这一领域的空白。

Method: 利用现有的图对抗攻击方法（如毒化和规避攻击）测试两种代表性模型（LLAGA和GRAPHPROMPTER），并发现新的攻击方式。

Result: 发现LLAGA的节点序列模板易受攻击，GRAPHPROMPTER的GNN编码器更鲁棒，但两者均对特征扰动攻击敏感。

Conclusion: 提出GALGUARD防御框架，结合LLM特征校正和GNN防御，有效提升模型鲁棒性。

Abstract: Large Language Models (LLMs) are increasingly integrated with
graph-structured data for tasks like node classification, a domain
traditionally dominated by Graph Neural Networks (GNNs). While this integration
leverages rich relational information to improve task performance, their
robustness against adversarial attacks remains unexplored. We take the first
step to explore the vulnerabilities of graph-aware LLMs by leveraging existing
adversarial attack methods tailored for graph-based models, including those for
poisoning (training-time attacks) and evasion (test-time attacks), on two
representative models, LLAGA (Chen et al. 2024) and GRAPHPROMPTER (Liu et al.
2024). Additionally, we discover a new attack surface for LLAGA where an
attacker can inject malicious nodes as placeholders into the node sequence
template to severely degrade its performance. Our systematic analysis reveals
that certain design choices in graph encoding can enhance attack success, with
specific findings that: (1) the node sequence template in LLAGA increases its
vulnerability; (2) the GNN encoder used in GRAPHPROMPTER demonstrates greater
robustness; and (3) both approaches remain susceptible to imperceptible feature
perturbation attacks. Finally, we propose an end-to-end defense framework
GALGUARD, that combines an LLM-based feature correction module to mitigate
feature-level perturbations and adapted GNN defenses to protect against
structural attacks.

</details>


### [16] [On the Classical Hardness of the Semidirect Discrete Logarithm Problem in Finite Groups](https://arxiv.org/abs/2508.05048)
*Mohammad Ferry Husnil Arif,Muhammad Imran*

Main category: cs.CR

TL;DR: 半直接离散对数问题（SDLP）在有限群中的量子抗性被证明不足，但其经典计算优势仍需研究。本文探讨了SDLP在不同群平台上的经典硬度，发现其复杂性与群结构密切相关。


<details>
  <summary>Details</summary>
Motivation: 研究SDLP是否在经典计算中比标准离散对数问题（DLP）更具优势，以评估其作为密码学基础的潜力。

Method: 将SDLP重新表述为广义离散对数问题，并改进Baby-Step Giant-Step算法以适应SDLP，分析其时间与空间复杂度。

Result: SDLP的经典硬度高度依赖群平台：在有限域中与DLP相当，在椭圆曲线中变得简单，而在初等阿贝尔群中可能更难。

Conclusion: SDLP的非阿贝尔结构并不保证更高的经典硬度，密码学应用需更细致选择代数结构。

Abstract: The semidirect discrete logarithm problem (SDLP) in finite groups was
proposed as a foundation for post-quantum cryptographic protocols, based on the
belief that its non-abelian structure would resist quantum attacks. However,
recent results have shown that SDLP in finite groups admits efficient quantum
algorithms, undermining its quantum resistance. This raises a fundamental
question: does the SDLP offer any computational advantages over the standard
discrete logarithm problem (DLP) against classical adversaries? In this work,
we investigate the classical hardness of SDLP across different finite group
platforms. We establish that the group-case SDLP can be reformulated as a
generalized discrete logarithm problem, enabling adaptation of classical
algorithms to study its complexity. We present a concrete adaptation of the
Baby-Step Giant-Step algorithm for SDLP, achieving time and space complexity
$O(\sqrt{r})$ where $r$ is the period of the underlying cycle structure.
Through theoretical analysis and experimental validation in SageMath, we
demonstrate that the classical hardness of SDLP is highly platform-dependent
and does not uniformly exceed that of standard DLP. In finite fields
$\mathbb{F}_p^*$, both problems exhibit comparable complexity. Surprisingly, in
elliptic curves $E(\mathbb{F}_p)$, the SDLP becomes trivial due to the bounded
automorphism group, while in elementary abelian groups $\mathbb{F}_p^n$, the
SDLP can be harder than DLP, with complexity varying based on the eigenvalue
structure of the automorphism. Our findings reveal that the non-abelian
structure of semidirect products does not inherently guarantee increased
classical hardness, suggesting that the search for classically hard problems
for cryptographic applications requires more careful consideration of the
underlying algebraic structures.

</details>


### [17] [Incident Response Planning Using a Lightweight Large Language Model with Reduced Hallucination](https://arxiv.org/abs/2508.05188)
*Kim Hammar,Tansu Alpcan,Emil C. Lupu*

Main category: cs.CR

TL;DR: 提出了一种利用大型语言模型（LLM）进行网络安全事件响应规划的新方法，通过微调、信息检索和前瞻规划三个步骤，减少了幻觉问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前基于前沿LLM的事件响应方法成本高且易产生幻觉，需要更高效、可靠的解决方案。

Method: 采用微调、信息检索和前瞻规划三个步骤，确保响应计划的可靠性并减少幻觉。

Result: 实验表明，该方法恢复时间比前沿LLM缩短22%，且能泛化到多种事件类型和响应动作。

Conclusion: 该方法在减少幻觉的同时提高了事件响应效率，适用于实际部署。

Abstract: Timely and effective incident response is key to managing the growing
frequency of cyberattacks. However, identifying the right response actions for
complex systems is a major technical challenge. A promising approach to
mitigate this challenge is to use the security knowledge embedded in large
language models (LLMs) to assist security operators during incident handling.
Recent research has demonstrated the potential of this approach, but current
methods are mainly based on prompt engineering of frontier LLMs, which is
costly and prone to hallucinations. We address these limitations by presenting
a novel way to use an LLM for incident response planning with reduced
hallucination. Our method includes three steps: fine-tuning, information
retrieval, and lookahead planning. We prove that our method generates response
plans with a bounded probability of hallucination and that this probability can
be made arbitrarily small at the expense of increased planning time under
certain assumptions. Moreover, we show that our method is lightweight and can
run on commodity hardware. We evaluate our method on logs from incidents
reported in the literature. The experimental results show that our method a)
achieves up to 22% shorter recovery times than frontier LLMs and b) generalizes
to a broad range of incident types and response actions.

</details>


### [18] [An Overview of 7726 User Reports: Uncovering SMS Scams and Scammer Strategies](https://arxiv.org/abs/2508.05276)
*Sharad Agarwal,Guillermo Suarez-Tangil,Marie Vasek*

Main category: cs.CR

TL;DR: 该论文研究了绕过移动网络防火墙的短信，通过用户报告分析了垃圾短信和诈骗短信的区别，并分类了12种诈骗类型。


<details>
  <summary>Details</summary>
Motivation: 研究绕过防火墙的短信，填补了用户报告分析的空白。

Method: 与移动网络运营商合作，分析135万份用户报告，使用方法论框架区分垃圾短信和诈骗短信。

Result: 35.12%为垃圾短信，40.27%为诈骗短信，分类了12种诈骗类型，最常见的是'错号'诈骗。

Conclusion: 首次通过用户报告区分垃圾短信和诈骗短信，揭示了诈骗短信的类型和基础设施滥用情况。

Abstract: Mobile network operators implement firewalls to stop illicit messages, but
scammers find ways to evade detection. Previous work has looked into SMS texts
that are blocked by these firewalls. However, there is little insight into SMS
texts that bypass them and reach users. To this end, we collaborate with a
major mobile network operator to receive 1.35m user reports submitted over four
months. We find 89.16% of user reports comprise text messages, followed by
reports of suspicious calls and URLs. Using our methodological framework, we
identify 35.12% of the unique text messages reported by users as spam, while
40.27% are scam text messages. This is the first paper that investigates SMS
reports submitted by users and differentiates between spam and scams. Our paper
classifies the identified scam text messages into 12 scam types, of which the
most popular is 'wrong number' scams. We explore the various infrastructure
services that scammers abuse to conduct SMS scams, including mobile network
operators and hosting infrastructure, and analyze the text of the scam messages
to understand how scammers lure victims into providing them with their personal
or financial details.

</details>


### [19] [ShikkhaChain: A Blockchain-Powered Academic Credential Verification System for Bangladesh](https://arxiv.org/abs/2508.05334)
*Ahsan Farabi,Israt Khandaker,Nusrat Jahan,Ibrahim Khalil Shanto*

Main category: cs.CR

TL;DR: ShikkhaChain是一个基于区块链的学术证书管理平台，旨在解决孟加拉国学术证书欺诈问题，提供去中心化、防篡改的解决方案。


<details>
  <summary>Details</summary>
Motivation: 学术证书欺诈威胁教育诚信，尤其是在孟加拉国等发展中国家，现有的验证方法效率低下且主要依赖人工。

Method: 平台基于以太坊智能合约和IPFS存储，通过React DApp和MetaMask集成实现透明、可扩展的解决方案，支持基于角色的访问和QR验证。

Result: 原型展示提高了信任度，减少了验证时间，增强了孟加拉国学历的国际可信度。

Conclusion: ShikkhaChain为学术和就业生态系统提供了更可靠的解决方案。

Abstract: Academic credential fraud threatens educational integrity, especially in
developing countries like Bangladesh, where verification methods are primarily
manual and inefficient. To address this challenge, we present ShikkhaChain, a
blockchain-powered certificate management platform designed to securely issue,
verify, and revoke academic credentials in a decentralized and tamper-proof
manner. Built on Ethereum smart contracts and utilizing IPFS for off-chain
storage, the platform offers a transparent, scalable solution accessible
through a React-based DApp with MetaMask integration. ShikkhaChain enables
role-based access for governments, regulators, institutions, and public
verifiers, allowing QR-based validation and on-chain revocation tracking. Our
prototype demonstrates enhanced trust, reduced verification time, and improved
international credibility for Bangladeshi degrees, promoting a more reliable
academic and employment ecosystem.

</details>


### [20] [Grouped k-threshold random grid-based visual cryptography scheme](https://arxiv.org/abs/2508.05394)
*Xiaoli Zhuo,Xuehu Yan,Wei Yan*

Main category: cs.CR

TL;DR: 提出了一种新的随机网格视觉密码共享范式，通过分组实现分层对比度特性，并设计了对比度增强的(k,n)方案，达到文献中最高对比度。


<details>
  <summary>Details</summary>
Motivation: 现有(k,n)随机网格视觉密码方案未能达到理论对比度上限，亟需更高对比度的构造方法。

Method: 提出n'-grouped (k,n) RGVCS范式，通过任意(k,n')方案构建(k,n)方案，并引入新的对比度计算公式。

Result: 实验证明所提方案在对比度上优于现有方法，达到文献最高值。

Conclusion: 新范式为随机网格视觉密码提供了更高对比度的解决方案，具有理论和实践优势。

Abstract: Visual cryptography schemes (VCSs) belong to a category of secret image
sharing schemes that do not require cryptographic knowledge for decryption,
instead relying directly on the human visual system. Among VCSs, random
grid-based VCS (RGVCS) has garnered widespread attention as it avoids pixel
expansion while requiring no basic matrices design. Contrast, a core metric for
RGVCS, directly determines the visual quality of recovered images, rendering
its optimization a critical research objective. However, existing $(k,n)$
RGVCSs still fail to attain theoretical upper bounds on contrast, highlighting
the urgent need for higher-contrast constructions. In this paper, we propose a
novel sharing paradigm for RGVCS that constructs $(k,n)$-threshold schemes from
arbitrary $(k,n')$-threshold schemes $(k \leq n'\leq n)$, termed
\emph{$n'$-grouped $(k,n)$ RGVCS}. This paradigm establishes hierarchical
contrast characteristics: participants within the same group achieve optimal
recovery quality, while inter-group recovery shows a hierarchical contrast. We
further introduce a new contrast calculation formula tailored to the new
paradigm. Then, we propose a contrast-enhanced $(k,n)$ RGVCS by setting $n'=
k$, achieving the highest contrast value documented in the existing literature.
Theoretical analysis and experimental results demonstrate the superiority of
our proposed scheme in terms of contrast.

</details>


### [21] [Local Distance Query with Differential Privacy](https://arxiv.org/abs/2508.05518)
*Weihong Sheng,Jiajun Chen,Bin Cai,Chunqiang Hu,Meng Han,Jiguo Yu*

Main category: cs.CR

TL;DR: 论文提出两种方法解决本地差分隐私（LDP）下距离查询的挑战：一种是生成合成图但效用低，另一种是首个专为距离查询设计的LDP方法，通过聚合局部距离向量提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中缺乏可信的第三方管理者，导致在本地差分隐私下实现距离查询困难。

Method: 1. 生成合成图并应用位操作减少噪声干扰；2. 首个专为距离查询设计的LDP方法，通过聚合局部距离向量捕获全局图结构。

Result: 理论分析和实验验证表明，第二种方法能有效更新全局距离。

Conclusion: 提出的第二种方法在本地差分隐私下实现了高效的距离查询。

Abstract: Differential Privacy (DP) is commonly employed to safeguard graph analysis or
publishing. Distance, a critical factor in graph analysis, is typically handled
using curator DP, where a trusted curator holds the complete neighbor lists of
all vertices and answers queries privately. However, in many real-world
scenarios, such a curator may not be present, posing a significant challenge
for implementing differentially private distance queries under Local
Differential Privacy (LDP). This paper proposes two approaches to address this
challenge. The first approach generates a synthetic graph by randomizing
responses and applies bitwise operations to reduce noise interference. However,
like other synthetic graph methods, this approach suffers from low utility. To
overcome this limitation, we propose a second approach, the first LDP method
specifically designed for distance queries, which captures the global graph
structure by continuously aggregating local distance vectors from neighboring
vertices. This process enables the accurate updating of global distances. We
demonstrate the effectiveness of our method through comprehensive theoretical
analysis and experimental evaluations on real-world datasets.

</details>


### [22] [PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction](https://arxiv.org/abs/2508.05545)
*Leon Garza,Anantaa Kotal,Aritran Piplai,Lavanya Elluri,Prajit Das,Aman Chadha*

Main category: cs.CR

TL;DR: 本文探讨了利用大型语言模型（LLMs）进行个人身份信息（PII）脱敏的方法，分析了不同架构和训练策略的效果，并发布了开源工具PRvL以支持实际应用。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则和领域特定NER模型的PII脱敏方法无法泛化到不同格式和上下文，LLMs因其强大的上下文理解能力成为有潜力的替代方案，但其架构和训练选择对脱敏性能的影响尚未充分研究。

Method: 通过评估多种LLM架构和训练策略，分析其在PII脱敏中的性能、语义保留和PII泄漏情况，并与延迟和计算成本进行比较。

Result: 研究结果为配置准确、高效且隐私感知的LLM脱敏器提供了实用指导，并开源了PRvL工具包，支持灵活部署和定制。

Conclusion: LLMs在PII脱敏中表现出色，PRvL工具为实际应用提供了可定制、安全的解决方案，无需依赖第三方服务。

Abstract: Redacting Personally Identifiable Information (PII) from unstructured text is
critical for ensuring data privacy in regulated domains. While earlier
approaches have relied on rule-based systems and domain-specific Named Entity
Recognition (NER) models, these methods fail to generalize across formats and
contexts. Recent advances in Large Language Models (LLMs) offer a promising
alternative, yet the effect of architectural and training choices on redaction
performance remains underexplored. LLMs have demonstrated strong performance in
tasks that require contextual language understanding, including the redaction
of PII in free-form text. Prior work suggests that with appropriate adaptation,
LLMs can become effective contextual privacy learners. However, the
consequences of architectural and training choices for PII Redaction remain
underexplored. In this work, we present a comprehensive analysis of LLMs as
privacy-preserving PII Redaction systems. We evaluate a range of LLM
architectures and training strategies for their effectiveness in PII Redaction.
Our analysis measures redaction performance, semantic preservation, and PII
leakage, and compares these outcomes against latency and computational cost.
The results provide practical guidance for configuring LLM-based redactors that
are accurate, efficient, and privacy-aware. To support reproducibility and
real-world deployment, we release PRvL, an open-source suite of fine-tuned
models, and evaluation tools for general-purpose PII Redaction. PRvL is built
entirely on open-source LLMs and supports multiple inference settings for
flexibility and compliance. It is designed to be easily customized for
different domains and fully operable within secure, self-managed environments.
This enables data owners to perform redactions without relying on third-party
services or exposing sensitive content beyond their own infrastructure.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [23] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型（LLM）的智能系统，用于工业机械的预测性维护，结合振动频率分析和多代理生成技术，提供可操作的维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需要及时干预以防止灾难性故障并优化运行效率，传统方法仅能检测异常，无法提供具体维护建议。

Method: 系统将轴承振动数据（BPFO、BPFI等）转化为自然语言供LLM处理，结合多代理组件分析维护手册和网络信息，生成结构化维护建议。

Result: 实验验证显示系统能有效检测异常并提供上下文相关的维护指导，填补了状态监测与可操作维护计划之间的空白。

Conclusion: 该研究推动了LLM在工业维护中的应用，为跨机械组件和工业领域的预测性维护提供了可扩展框架。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [24] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow是一种自动生成地理空间任务代理工作流的方法，通过明确工具调用目标提升代理成功率并减少令牌使用。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注推理分解，而忽略了API选择的明确指导，导致效率不足。

Method: GeoFlow为每个代理提供详细的工具调用目标，指导运行时地理空间API的调用。

Result: GeoFlow将代理成功率提高了6.8%，并在主流LLM家族中减少了高达四倍的令牌使用。

Conclusion: GeoFlow通过明确工具调用目标，显著提升了代理效率和资源利用率。

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [25] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 该论文提出了一种通过对抗性棋盘游戏评估大型语言模型（LLMs）性能的框架，弥补了主流问答基准方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 棋盘游戏作为战略推理和智能的典型领域，是评估AI系统的理想基准。论文旨在通过对抗性游戏全面评估LLMs的性能，减少对数据的依赖。

Method: 论文设计了Qi Town平台，支持5种流行游戏和20个LLM驱动的玩家，使用Elo评分系统和性能循环图（PLG）量化评估LLMs的技术能力，并通过积极情绪分数（PSS）评估心理适应性。

Result: 实验表明，尽管技术差异显著，大多数LLMs在对抗性环境中表现出乐观态度，适应性优于人类。但PLG揭示了LLMs技能发挥的不稳定性。

Conclusion: 该框架为LLMs的全面评估提供了新方法，揭示了其在对抗性环境中的优势和不足，值得进一步研究。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [26] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 比较三种实现自主网络地理信息系统（AWebGIS）的方法，发现基于小型语言模型（SLM）的客户端方法在准确性和隐私保护上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于云的大型语言模型（LLM）方法对互联网依赖性强、隐私和扩展性问题。

Method: 比较三种方法：1）基于云LLM的全自动在线方法；2）基于传统机器学习分类器的半自动离线方法；3）基于微调SLM的全自主离线客户端方法。

Result: 第三种方法（SLM）准确率最高（0.93），且减轻了服务器负担。

Conclusion: 客户端执行的SLM模型是AWebGIS的可行解决方案，兼具高准确性和隐私保护。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [27] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 论文探讨了强化学习（RL）在提升大语言模型（LLMs）推理能力中的局限性，特别是在非理想场景下的表现。研究发现，尽管RL微调在理想条件下有效，但在实际相关场景（如摘要推理、细粒度噪声抑制和上下文过滤）中性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试大多在理想条件下评估LLMs的推理能力，忽视了实际场景中的表现。研究旨在填补这一空白，并借鉴脑科学发现，探讨人类在非完美输入下仍能可靠推理的机制。

Method: 研究定义了三种非理想场景，并使用代表性策略梯度算法对三个LLMs和一个先进的大视觉语言模型（LVLM）进行RL微调。随后在八个公共数据集上测试其性能。

Result: 结果显示，RL微调在理想条件下提升推理能力，但在非理想场景中性能显著下降。尽管提出了场景特定的补救方法，但当前方法未能完全解决推理缺陷。

Conclusion: 研究强调了大模型推理能力常被高估，并呼吁在非理想场景下评估模型性能的重要性。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [28] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: HealthFlow是一种自进化的AI代理，通过元级进化机制提升策略规划能力，显著优于现有框架。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理在医疗研究中依赖静态策略，无法成为更好的策略规划者，限制了其在复杂领域的应用。

Method: 引入HealthFlow，通过元级进化机制自主优化高层问题解决策略，并开发EHRFlowBench基准进行可重复评估。

Result: 实验表明，HealthFlow的自进化方法显著优于现有代理框架。

Conclusion: 该研究标志着从工具使用者转向设计更智能的自进化任务管理器，为更自主的AI科学发现铺平道路。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [29] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 提出了一种基于博弈论的分子对接框架（Docking Game），通过LoopPlay算法交替训练配体和蛋白质模块，显著提升了结合模式预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前多任务学习模型在配体对接中表现不佳，主要由于配体和蛋白质的结构复杂性差异。

Method: 将蛋白质-配体相互作用建模为双玩家博弈，开发LoopPlay算法，通过内外循环交替训练配体和蛋白质模块。

Result: 实验表明，LoopPlay在预测准确结合模式上比现有方法提升约10%。

Conclusion: 该方法有望提高药物发现中分子对接的准确性。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [30] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: 研究探讨了利用大型语言模型（LLMs）整合城市空间数据的潜力，发现其在提供相关特征时表现优异，但需结合审查与优化方法以减少错误。


<details>
  <summary>Details</summary>
Motivation: 传统规则方法和机器学习在整合异构、噪声空间数据时存在局限性，LLMs被视为一种灵活替代方案。

Method: 通过分析LLMs的空间推理能力，并采用审查与优化方法提升其性能。

Result: LLMs在减少对空间推理依赖时表现良好，审查与优化方法能有效纠正错误。

Conclusion: LLMs为空间数据整合提供了有前景的替代方案，未来研究方向包括多模态整合和支持多样化数据格式。

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [31] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 论文提出了一种结合离线模仿学习和在线探索的Web导航智能体框架CogniWeb，基于人类认知的双系统理论，实现了高效且性能优异的导航。


<details>
  <summary>Details</summary>
Motivation: Web导航是评估通用人工智能（AGI）的重要领域，但现有方法未能有效整合离线学习和在线探索。

Method: 基于双系统认知理论，将智能体分解为快速直觉（System 1）和慢速推理（System 2）模块，实现自适应切换。

Result: 在WebArena上的测试显示，CogniWeb成功率为43.96%，同时显著减少75%的token使用。

Conclusion: CogniWeb通过双系统整合，在Web导航任务中实现了高效与性能的平衡。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [32] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: 提出了首个多模态医学知识编辑基准MedMKEB，用于评估医学大语言模型的知识编辑能力，填补了现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: 医学知识不断更新，现有模型需高效更新过时或错误信息，但缺乏系统性多模态医学知识编辑基准。

Method: 基于高质量医学视觉问答数据集构建MedMKEB，包含反事实修正、语义泛化、知识迁移和对抗鲁棒性等任务，并引入专家验证。

Result: 实验表明现有知识编辑方法在医学领域存在局限性，需开发专门策略。

Conclusion: MedMKEB将成为促进可信高效医学知识编辑算法发展的标准基准。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [33] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize是一个基于Qwen3-8B模型的轻量级门尺寸优化框架，适用于不同工艺节点和电路拓扑，通过动态任务特定损失函数和优化算法显著减少计算资源和人力依赖。


<details>
  <summary>Details</summary>
Motivation: 模拟电路设计耗时且依赖经验，现有AI方法通用性差且计算资源需求高。

Method: 结合微调Qwen3-8B模型和全局差分进化（DE）与局部粒子群优化（PSO），动态构建任务特定损失函数。

Result: 在多个工艺节点上表现优异，优于AutoCkt，减少86.67%任务的计算资源。

Conclusion: EasySize能显著简化模拟电路设计流程，减少对专家经验和计算资源的依赖。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [34] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 论文探讨了生成式AI在高等教育中的核心作用，通过实验验证了一种基于建构主义理论的苏格拉底式AI导师的有效性，并提出了多代理系统（MAS）的概念。


<details>
  <summary>Details</summary>
Motivation: 研究旨在验证生成式AI如何通过结构化对话支持学生的批判性、独立性和反思性思维，挑战了AI可能导致技能退化的观点。

Method: 研究采用对照实验，比较了65名德国师范生使用苏格拉底式AI导师与普通AI聊天机器人的效果。

Result: 使用苏格拉底式AI导师的学生在批判性思维和反思能力方面表现显著更好。

Conclusion: 研究为混合学习生态系统提供了实证支持和概念框架，强调人机协作和教学一致性。

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [35] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 本文提出了一种基于异构图神经网络（HGNN）的方法，用于修复过程挖掘中事件日志的缺失属性，相比现有方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现实世界的事件日志常因数据采集问题导致信息缺失，现有方法依赖过程模型或机器学习模型，但存在局限性。

Method: 开发了一种异构图神经网络模型，能够处理不完整事件并修复缺失属性。

Result: 在合成和真实事件日志上评估，该方法在修复所有事件属性方面表现优异。

Conclusion: 异构图神经网络为事件日志修复提供了更自然且高效的解决方案。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [36] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon是一个动态RAG系统，通过多模态和多跳推理解决复杂VQA任务，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法仅从文本或图像中检索，无法处理需要多跳推理或最新知识的复杂查询。

Method: 引入域路由器和搜索路由器，动态选择检索策略，结合文本和图像搜索代理。

Result: 在Meta CRAG-MM挑战中，单源任务提升5.06%，多源任务提升6.35%，多轮任务提升5.03%。

Conclusion: QA-Dragon有效解决了复杂VQA任务，显著优于基线方法。

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [37] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 提出了一种结合RDF图数据库和LLM的新框架，用于解决大规模维护组织中专家识别和通信管理的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统通信方法无法有效应对信息过载和响应时间长的问题。

Method: 结合RDF图数据库和LLM，通过自然语言查询实现精准受众定位，并提供透明推理。

Result: 提高了通信效率，同时通过可解释的结果增强了系统信任。

Conclusion: 该框架为复杂组织中的通信管理提供了高效且透明的解决方案。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [38] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种混合架构，将决策树符号推理与大型语言模型（LLM）生成能力结合，通过多智能体框架实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中符号与神经模块松散耦合的问题，提升推理的透明性和性能。

Method: 将决策树和随机森林作为可调用模块嵌入统一推理系统，LLM负责归纳推理和规划，中央协调器维护状态一致性。

Result: 在多个基准测试中表现优异，如ProofWriter（+7.2%）、GSM8k（+5.3%）和ARC（+6.0%）。

Conclusion: 该架构为通用神经符号推理提供了可解释、可扩展的解决方案。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [39] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: 论文主张重新定义AI中的‘agent’一词，提出一个多维框架以明确其最低要求，并建议标准化术语以提高研究清晰度和政策制定效果。


<details>
  <summary>Details</summary>
Motivation: 由于AI领域对‘agent’一词的多重解释导致研究交流、系统评估和政策制定的困难，需要重新定义以消除歧义。

Method: 通过历史分析和当代使用模式，提出一个多维框架，定义‘agent’的最低要求，并分类系统的不同维度。

Result: 提出了一个清晰的框架，为系统描述提供精确词汇，同时保留术语的历史多样性。

Conclusion: 建议标准化术语并采纳框架，以提升研究清晰度、可重复性和政策制定效果。

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [40] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: NomicLaw是一个多智能体模拟框架，用于研究LLM在开放式法律和伦理困境中的行为，通过投票和语言策略分析信任与互惠。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在开放式多智能体环境中的行为，尤其是在法律和伦理困境中的表现，填补现有研究的空白。

Method: 使用NomicLaw框架，让LLM协作制定法律规则，通过投票和语言策略分析行为。

Result: 实验显示LLM能自发形成联盟、背叛信任，并调整语言策略以影响集体决策。

Conclusion: 研究揭示了开源LLM的社会推理和说服能力，为未来AI在法律场景中的自主协商和立法设计提供了参考。

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [41] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: 论文研究了描述逻辑（DLs）中的最小模型推理问题，发现即使在简单的DL（如$\mathcal{EL}$）中，概念可满足性在最小模型下也是不可判定的。通过引入无环性条件，部分恢复了可判定性，并探讨了DL-Lite家族的复杂性。


<details>
  <summary>Details</summary>
Motivation: 最小模型推理在知识表示中具有重要意义，但在描述逻辑中的研究有限，尤其是纯最小模型的情况。本文旨在填补这一空白。

Method: 研究了纯最小模型在流行DL中的表现，分析了概念可满足性的判定性，并引入无环性条件以恢复可判定性。

Result: 发现$\mathcal{EL}$中的概念可满足性在最小模型下不可判定，无环性条件可降低复杂度。DL-Lite$_{\text{horn}}$的扩展问题被证明为ExpSpace难。

Conclusion: 最小模型推理在DL中具有高复杂性，但通过限制条件可部分恢复可判定性，为未来研究提供了方向。

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [42] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: StructVRM提出了一种结构化可验证奖励模型，用于解决多模态模型在复杂推理任务中的部分正确性问题。


<details>
  <summary>Details</summary>
Motivation: 传统奖励机制仅提供单一二进制评分，无法处理复杂多问题任务中的部分正确性。

Method: StructVRM通过训练模型验证器提供细粒度的子问题级反馈，评估语义和数学等价性。

Result: Seed-StructVRM在12个多模态基准测试中的6个及新STEM-Bench上达到最优性能。

Conclusion: 结构化可验证奖励是提升多模态模型复杂推理能力的有效方法。

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [43] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 提出了一种实时数据驱动的预测性维护方法，用于智能交通系统，结合样本预处理、增量分类和结果解释，实验结果显示高准确性和F-measure。


<details>
  <summary>Details</summary>
Motivation: 为智能交通系统提供高效的预测性维护解决方案，以提升铁路系统的可靠性和安全性。

Method: 采用包含样本预处理、增量分类和解释性模块的在线处理流程，首次实现自然语言和视觉解释的在线故障预测。

Result: 在MetroPT数据集上，F-measure超过98%，准确率达到99%，且在类不平衡和噪声情况下表现稳定。

Conclusion: 该方法具有实际应用价值，能够支持铁路运营中的主动维护决策，提升服务可用性和安全性。

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [44] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: DeepPHY是一个新的基准框架，用于评估视觉语言模型（VLMs）对物理原理的理解和推理能力，发现现有模型在复杂动态环境中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在复杂动态环境中缺乏细节关注和精确行动规划能力，需要系统性评估其对物理原理的理解。

Method: 提出DeepPHY框架，通过多难度模拟环境和细粒度评估指标，测试VLMs的物理推理能力。

Result: 评估发现，即使是先进的VLMs也难以将描述性物理知识转化为精确的预测控制。

Conclusion: DeepPHY为评估VLMs的物理推理能力提供了有效工具，揭示了现有模型的局限性。

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [45] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）正在改变有机合成中化学家的反应规划和执行方式，结合图神经网络、量子计算和实时光谱技术，加速发现周期并推动绿色化学。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs如何从理论工具发展为实验室实用伙伴，推动更快速、更环保的分子创新。

Method: 通过结合LLMs与图神经网络、量子计算和实时光谱技术，优化合成路线预测和实验执行。

Result: LLMs显著缩短了发现周期，支持数据驱动的绿色化学，但仍存在数据集偏见和安全性问题。

Conclusion: 通过开放基准、联邦学习和可解释界面等社区倡议，确保人类控制下实现快速、可靠且包容的分子创新。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


### [46] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
*Krzysztof Janowicz,Zilong Liu,Gengchen Mai,Zhangyu Wang,Ivan Majic,Alexandra Fortacz,Grant McKenzie,Song Gao*

Main category: cs.AI

TL;DR: 论文探讨了AI对齐中的地理变异性问题，强调需根据地域文化、政治和法律差异调整对齐措施，避免一刀切方法。


<details>
  <summary>Details</summary>
Motivation: AI对齐需考虑地理和文化差异，以确保系统行为符合不同地区的规范。当前研究对此关注不足。

Method: 回顾关键地理研究问题，提出未来研究方向，并概述评估对齐敏感性的方法。

Result: 指出AI对齐需结合时空意识，避免因地域差异导致的不一致输出。

Conclusion: 呼吁开发更具地理敏感性的AI对齐方法，以适应全球化背景下的多样化需求。

Abstract: AI (super) alignment describes the challenge of ensuring (future) AI systems
behave in accordance with societal norms and goals. While a quickly evolving
literature is addressing biases and inequalities, the geographic variability of
alignment remains underexplored. Simply put, what is considered appropriate,
truthful, or legal can differ widely across regions due to cultural norms,
political realities, and legislation. Alignment measures applied to AI/ML
workflows can sometimes produce outcomes that diverge from statistical
realities, such as text-to-image models depicting balanced gender ratios in
company leadership despite existing imbalances. Crucially, some model outputs
are globally acceptable, while others, e.g., questions about Kashmir, depend on
knowing the user's location and their context. This geographic sensitivity is
not new. For instance, Google Maps renders Kashmir's borders differently based
on user location. What is new is the unprecedented scale and automation with
which AI now mediates knowledge, expresses opinions, and represents geographic
reality to millions of users worldwide, often with little transparency about
how context is managed. As we approach Agentic AI, the need for
spatio-temporally aware alignment, rather than one-size-fits-all approaches, is
increasingly urgent. This paper reviews key geographic research problems,
suggests topics for future work, and outlines methods for assessing alignment
sensitivity.

</details>


### [47] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 论文提出Bench-2-CoP框架，量化AI评估基准与欧盟AI法规之间的差距，发现现有评估工具严重忽视系统性风险。


<details>
  <summary>Details</summary>
Motivation: 当前AI评估工具无法满足新兴法规（如欧盟AI法案）对系统性风险的评估需求，亟需填补这一“基准-法规差距”。

Method: 引入Bench-2-CoP框架，通过LLM-as-judge分析，将194,955个问题映射到欧盟AI法案的能力分类中。

Result: 现有评估工具过度关注行为倾向（如幻觉倾向和歧视性偏见），而关键功能能力（如失控场景相关能力）完全未被覆盖。

Conclusion: 研究为政策制定者和开发者提供了填补评估差距的关键见解，以推动更安全合规的AI发展。

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [48] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 论文提出了一种使用小型、高效的通用LLM生成多样化ERC数据集的方法，以补充现有基准数据集，并验证了生成数据集在提升ERC分类性能和解决标签不平衡问题上的有效性。


<details>
  <summary>Details</summary>
Motivation: ERC数据稀缺且现有数据集存在偏见和主观性问题，而大型语言模型（LLM）在ERC任务中应用有限且成本高，因此需要一种高效的替代方案。

Method: 采用小型、资源高效的通用LLM生成六种新型ERC数据集，补充现有三大ERC基准数据集，并评估其在分类和标签不平衡分析中的效果。

Result: 实验表明，基于生成数据集训练的ERC分类模型具有强鲁棒性，并在现有基准上实现了显著的性能提升。

Conclusion: 小型LLM生成的多样化ERC数据集能有效补充现有数据，提升ERC任务的性能，同时为标签不平衡问题提供了解决方案。

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


### [49] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
*Shuo Cai,Su Lu,Qi Zhou,Kejing Yang,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAlign是一个可扩展且样本高效的后训练框架，结合监督微调（SFT）和直接偏好优化（DPO）来提升大语言模型（LLM）的推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在复杂任务上表现出强大的推理能力，但后训练过程通常需要大量数据和计算资源，现有方法缺乏可扩展性。

Method: InfiAlign通过多维质量指标自动从开源推理数据集中筛选高质量对齐数据，结合SFT和DPO进行模型优化。

Result: 在Qwen2.5-Math-7B-Base模型上，仅使用12%的训练数据即达到与DeepSeek-R1-Distill-Qwen-7B相当的性能，数学推理任务提升3.89%。

Conclusion: InfiAlign通过数据选择和全阶段后训练的结合，为大规模推理模型的对齐提供了高效且可扩展的解决方案。

Abstract: Large language models (LLMs) have exhibited impressive reasoning abilities on
a wide range of complex tasks. However, enhancing these capabilities through
post-training remains resource intensive, particularly in terms of data and
computational cost. Although recent efforts have sought to improve sample
efficiency through selective data curation, existing methods often rely on
heuristic or task-specific strategies that hinder scalability. In this work, we
introduce InfiAlign, a scalable and sample-efficient post-training framework
that integrates supervised fine-tuning (SFT) with Direct Preference
Optimization (DPO) to align LLMs for enhanced reasoning. At the core of
InfiAlign is a robust data selection pipeline that automatically curates
high-quality alignment data from open-source reasoning datasets using
multidimensional quality metrics. This pipeline enables significant performance
gains while drastically reducing data requirements and remains extensible to
new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model
achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only
approximately 12% of the training data, and demonstrates strong generalization
across diverse reasoning tasks. Additional improvements are obtained through
the application of DPO, with particularly notable gains in mathematical
reasoning tasks. The model achieves an average improvement of 3.89% on AIME
24/25 benchmarks. Our results highlight the effectiveness of combining
principled data selection with full-stage post-training, offering a practical
solution for aligning large reasoning models in a scalable and data-efficient
manner. The model checkpoints are available at
https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.

</details>


### [50] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.AI

TL;DR: GRAIL框架通过结合LLM引导的随机探索和路径过滤，解决了现有RAG方法在处理结构化知识（如知识图谱）时的局限性，显著提升了推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要针对非结构化数据，对结构化知识（如知识图谱）处理能力有限，且当前图检索方法难以捕捉整体图结构并面临精度控制问题。

Method: GRAIL结合LLM引导的随机探索与路径过滤，建立数据合成管道，生成细粒度推理轨迹，并通过两阶段训练学习动态决策策略。

Result: 在三个知识图谱问答数据集上，GRAIL平均准确率提升21.01%，F1值提升22.43%。

Conclusion: GRAIL通过交互式检索范式，有效平衡检索广度与精度，显著提升了知识图谱推理任务的性能。

Abstract: Large Language Models (LLMs) integrated with Retrieval-Augmented Generation
(RAG) techniques have exhibited remarkable performance across a wide range of
domains. However, existing RAG approaches primarily operate on unstructured
data and demonstrate limited capability in handling structured knowledge such
as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally
struggle to capture holistic graph structures while simultaneously facing
precision control challenges that manifest as either critical information gaps
or excessive redundant connections, collectively undermining reasoning
performance. To address this challenge, we propose GRAIL: Graph-Retrieval
Augmented Interactive Learning, a framework designed to interact with
large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL
integrates LLM-guided random exploration with path filtering to establish a
data synthesis pipeline, where a fine-grained reasoning trajectory is
automatically generated for each task. Based on the synthesized data, we then
employ a two-stage training process to learn a policy that dynamically decides
the optimal actions at each reasoning step. The overall objective of
precision-conciseness balance in graph retrieval is decoupled into fine-grained
process-supervised rewards to enhance data efficiency and training stability.
In practical deployment, GRAIL adopts an interactive retrieval paradigm,
enabling the model to autonomously explore graph paths while dynamically
balancing retrieval breadth and precision. Extensive experiments have shown
that GRAIL achieves an average accuracy improvement of 21.01% and F1
improvement of 22.43% on three knowledge graph question-answering datasets. Our
source code and datasets is available at https://github.com/Changgeww/GRAIL.

</details>


### [51] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
*Roshita Bhonsle,Rishav Dutta,Sneha Vavilapalli,Harsh Seth,Abubakarr Jaye,Yapei Chang,Mukund Rungta,Emmanuel Aboah Boateng,Sadid Hasan,Ehi Nosakhare,Soundar Srinivasan*

Main category: cs.AI

TL;DR: 提出了一种通用、模块化的框架，用于评估代理任务完成情况，通过分解任务并验证每一步，提高了与人类评估的一致性。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法（如LLM-as-a-Judge）仅关注最终输出，忽略了逐步推理过程；现有Agent-as-a-Judge系统则局限于特定领域。

Method: 设计了一个模块化框架，将任务分解为子任务，利用代理的输出和推理信息逐步验证，最终汇总评估结果。

Result: 在GAIA和BigCodeBench基准测试中，提出的Judge Agent比GPT-4o基线分别提高了4.76%和10.52%的评估准确性。

Conclusion: 该框架展示了通用评估方法的潜力，能够更接近人类评估结果。

Abstract: The increasing adoption of foundation models as agents across diverse domains
necessitates a robust evaluation framework. Current methods, such as
LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step
reasoning that drives agentic decision-making. Meanwhile, existing
Agent-as-a-Judge systems, where one agent evaluates another's task completion,
are typically designed for narrow, domain-specific settings. To address this
gap, we propose a generalizable, modular framework for evaluating agent task
completion independent of the task domain. The framework emulates human-like
evaluation by decomposing tasks into sub-tasks and validating each step using
available information, such as the agent's output and reasoning. Each module
contributes to a specific aspect of the evaluation process, and their outputs
are aggregated to produce a final verdict on task completion. We validate our
framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA
and BigCodeBench. Our Judge Agent predicts task success with closer agreement
to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,
respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This
demonstrates the potential of our proposed general-purpose evaluation
framework.

</details>


### [52] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
*Meryem Yilmaz Soylu,Adrian Gallard,Jeonghyun Lee,Gayane Grigoryan,Rushil Desai,Stephen Harmon*

Main category: cs.AI

TL;DR: 论文介绍了一种名为LORI的AI工具，用于从推荐信中自动评估申请者的领导力技能，采用自然语言处理和大型语言模型（如RoBERTa和LLAMA），在测试数据中表现出高准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 推荐信是评估申请者能力的重要材料，但人工审核耗时耗力。研究旨在通过AI工具LORI提高审核效率，并为申请者的专业成长提供反馈。

Method: 使用自然语言处理和大型语言模型（RoBERTa和LLAMA）识别推荐信中的领导力属性，如团队合作、沟通和创新。

Result: 最新RoBERTa模型的加权F1分数为91.6%，精确度为92.4%，召回率为91.6%，显示出高度的数据一致性。

Conclusion: LORI工具在研究生招生过程中具有重要价值，能够高效、全面地评估申请者的领导力技能，同时优化招生流程。

Abstract: Letters of recommendation (LORs) provide valuable insights into candidates'
capabilities and experiences beyond standardized test scores. However,
reviewing these text-heavy materials is time-consuming and labor-intensive. To
address this challenge and support the admission committee in providing
feedback for students' professional growth, our study introduces LORI: LOR
Insights, a novel AI-based detection tool for assessing leadership skills in
LORs submitted by online master's program applicants. By employing natural
language processing and leveraging large language models using RoBERTa and
LLAMA, we seek to identify leadership attributes such as teamwork,
communication, and innovation. Our latest RoBERTa model achieves a weighted F1
score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong
level of consistency in our test data. With the growing importance of
leadership skills in the STEM sector, integrating LORI into the graduate
admissions process is crucial for accurately assessing applicants' leadership
capabilities. This approach not only streamlines the admissions process but
also automates and ensures a more comprehensive evaluation of candidates'
capabilities.

</details>


### [53] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
*Rui Lu,Jinhe Bi,Yunpu Ma,Feng Xiao,Yuntao Du,Yijun Tian*

Main category: cs.AI

TL;DR: MV-Debate是一种多视角代理辩论框架，用于统一多模态有害内容检测，通过动态反思门控提升准确性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中多模态内容的复杂性使得识别有害意图（如讽刺、仇恨言论或虚假信息）具有挑战性。

Method: MV-Debate结合四种互补的辩论代理（表面分析师、深度推理者、模态对比者和社会情境分析者），通过迭代辩论和反思优化检测。

Result: 在三个基准数据集上，MV-Debate显著优于单一模型和现有多代理辩论基线。

Conclusion: 多代理辩论框架在提升社交媒体意图检测可靠性方面具有潜力。

Abstract: Social media has evolved into a complex multimodal environment where text,
images, and other signals interact to shape nuanced meanings, often concealing
harmful intent. Identifying such intent, whether sarcasm, hate speech, or
misinformation, remains challenging due to cross-modal contradictions, rapid
cultural shifts, and subtle pragmatic cues. To address these challenges, we
propose MV-Debate, a multi-view agent debate framework with dynamic reflection
gating for unified multimodal harmful content detection. MV-Debate assembles
four complementary debate agents, a surface analyst, a deep reasoner, a
modality contrast, and a social contextualist, to analyze content from diverse
interpretive perspectives. Through iterative debate and reflection, the agents
refine responses under a reflection-gain criterion, ensuring both accuracy and
efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate
significantly outperforms strong single-model and existing multi-agent debate
baselines. This work highlights the promise of multi-agent debate in advancing
reliable social intent detection in safety-critical online contexts.

</details>


### [54] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
*Bo Wen*

Main category: cs.AI

TL;DR: 论文提出主动推理（AIF）为解决自主AI代理学习中的奖励工程瓶颈问题提供了关键基础，通过最小化自由能量的内在驱动力替代外部奖励信号。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统依赖高质量训练数据和人工奖励设计，面临可扩展性挑战，阻碍了真正自主智能的发展。

Method: 结合主动推理（AIF）和大型语言模型，利用内在驱动力（最小化自由能量）实现自主学习和决策。

Result: 提出了一种能够自主制定、调整和追求目标的AI系统，同时保持与人类价值观的一致性。

Conclusion: 主动推理与大型语言模型的结合为自主AI系统的发展提供了一条可行路径。

Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation
for developing autonomous AI agents capable of learning from experience without
continuous human reward engineering. As AI systems begin to exhaust
high-quality training data and rely on increasingly large human workforces for
reward design, the current paradigm faces significant scalability challenges
that could impede progress toward genuinely autonomous intelligence. The
proposal for an ``Era of Experience,'' where agents learn from self-generated
data, is a promising step forward. However, this vision still depends on
extensive human engineering of reward functions, effectively shifting the
bottleneck from data curation to reward curation. This highlights what we
identify as the \textbf{grounded-agency gap}: the inability of contemporary AI
systems to autonomously formulate, adapt, and pursue objectives in response to
changing circumstances. We propose that AIF can bridge this gap by replacing
external reward signals with an intrinsic drive to minimize free energy,
allowing agents to naturally balance exploration and exploitation through a
unified Bayesian objective. By integrating Large Language Models as generative
world models with AIF's principled decision-making framework, we can create
agents that learn efficiently from experience while remaining aligned with
human values. This synthesis offers a compelling path toward AI systems that
can develop autonomously while adhering to both computational and physical
constraints.

</details>


### [55] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
*Yu Yuan,Lili Zhao,Wei Chen,Guangting Zheng,Kai Zhang,Mengdi Zhang,Qi Liu*

Main category: cs.AI

TL;DR: LearnerAgent是一个基于LLM的多智能体框架，模拟真实教学环境，分析不同类型学习者的动态学习过程，揭示了LLM默认行为的特点。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉学习动态或提供解释性，因此提出LearnerAgent框架，以更真实地模拟和分析学习行为。

Method: 构建具有心理学基础的学习者类型（如深层、表层、懒惰学习者），通过知识获取、策略选择、测试和同伴互动，跟踪其全年学习进展。

Result: 1）深层学习者持续认知增长；2）学习者行为与心理特征一致；3）自我效能感演变真实；4）LLM默认行为为“勤奋但脆弱的表层学习者”。

Conclusion: LearnerAgent能有效模拟真实学习场景，揭示LLM行为特点，为心理学和智能系统研究提供新视角。

Abstract: Capturing human learning behavior based on deep learning methods has become a
major research focus in both psychology and intelligent systems. Recent
approaches rely on controlled experiments or rule-based models to explore
cognitive processes. However, they struggle to capture learning dynamics, track
progress over time, or provide explainability. To address these challenges, we
introduce LearnerAgent, a novel multi-agent framework based on Large Language
Models (LLMs) to simulate a realistic teaching environment. To explore
human-like learning dynamics, we construct learners with psychologically
grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM's default behavior. Through weekly
knowledge acquisition, monthly strategic choices, periodic tests, and peer
interaction, we can track the dynamic learning progress of individual learners
over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis
reveals that only Deep Learner achieves sustained cognitive growth. Our
specially designed "trap questions" effectively diagnose Surface Learner's
shallow knowledge. 2) The behavioral and cognitive patterns of distinct
learners align closely with their psychological profiles. 3) Learners'
self-concept scores evolve realistically, with the General Learner developing
surprisingly high self-efficacy despite its cognitive limitations. 4)
Critically, the default profile of base LLM is a "diligent but brittle Surface
Learner"-an agent that mimics the behaviors of a good student but lacks true,
generalizable understanding. Extensive simulation experiments demonstrate that
LearnerAgent aligns well with real scenarios, yielding more insightful findings
about LLMs' behavior.

</details>
