<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 12]
- [cs.CR](#cs.CR) [Total: 24]
- [cs.AI](#cs.AI) [Total: 30]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Automated Snippet-Alignment Data Augmentation for Code Translation](https://arxiv.org/abs/2510.15004)
*Zhiming Zhang,Qingfu Zhu,Xianzhen Luo,Yixuan Wang,Bohan Li,Wanxiang Che*

Main category: cs.SE

TL;DR: 提出了一种利用LLM自动生成代码片段对齐数据的数据增强方法，并采用两阶段训练策略，在TransCoder测试集上实现了最高3.78%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有代码翻译研究主要关注程序对齐数据增强，但片段对齐数据能提供更细粒度的对齐学习信号。由于平行语料库有限，需要探索新的数据增强方法。

Method: 利用大语言模型自动生成片段对齐数据，并设计两阶段训练策略：先在程序对齐数据上训练，再在片段对齐数据上微调。

Result: 在TransCoder测试集上，增强的片段对齐数据结合两阶段训练相比仅在程序对齐数据上微调的基线，实现了最高3.78%的pass@k提升。

Conclusion: 片段对齐数据增强与两阶段训练策略能有效提升代码翻译模型性能，证明了细粒度对齐学习的重要性。

Abstract: Code translation aims to translate the code from its source language to the
target language and is used in various software development scenarios. Recent
developments in Large Language Models (LLMs) have showcased their capabilities
in code translation, and parallel corpora play a crucial role in training
models for code translation. Parallel corpora can be categorized into
program-alignment (PA) and snippet-alignment (SA) data. Although PA data has
complete context and is suitable for semantic alignment learning, it may not
provide adequate fine-grained training signals due to its extended length,
while the brevity of SA data enables more fine-grained alignment learning. Due
to limited parallel corpora, researchers explore several augmentation methods
for code translation. Previous studies mainly focus on augmenting PA data. In
this paper, we propose a data augmentation method that leverages LLMs to
generate SA data automatically. To fully leverage both PA data and SA data, we
explore a simple yet effective two-stage training strategy, which consistently
enhances model performance compared to fine-tuning solely on PA data.
Experiments on TransCoder-test demonstrate that our augmented SA data combined
with the two-stage training approach yields consistent improvements over the
baseline, achieving a maximum gain of 3.78% on pass@k.

</details>


### [2] [Assessing Coherency and Consistency of Code Execution Reasoning by Large Language Models](https://arxiv.org/abs/2510.15079)
*Changshu Liu,Yang Chen,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: CES是一个评估LLM程序执行模拟能力的任务，引入连贯性概念来检测推理逻辑一致性，并提出了衡量推理一致性的新指标。评估发现前沿LLM存在大量不连贯的执行推理，且推理表现不一致，主要依赖模式匹配而非真实执行推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注变量预测的正确性，但无法检测推理捷径、幻觉或数据泄露导致的伪正确输出。需要系统评估LLM是否真正理解程序执行逻辑。

Method: 提出CES任务，除了变量预测正确性外，引入连贯性概念评估执行逻辑一致性，并设计强、弱、随机三个级别的推理一致性度量指标。

Result: 在HumanEval上81.42%的执行模拟是连贯的，其中46.92%预测正确，53.08%预测错误。GPT-4和DeepSeek-R1等前沿LLM存在最多不连贯推理。LLM的推理一致性大多为随机(48.87%)或弱(45.37%)。

Conclusion: LLM在bug相关任务中很少融入执行推理，成功主要依赖模式匹配或语言捷径。缺乏推理能力会威胁LLM处理未见bug或不同上下文模式的泛化能力。CES可系统验证LLM在这些任务中的可疑成功。

Abstract: This paper proposes CES, a task to evaluate the abilities of LLMs in
simulating program execution and using that reasoning in programming tasks.
Besides measuring the correctness of variable predictions during execution
simulation, CES introduces the notion of coherence to determine whether the
simulation complies with commonsense execution logic, even if the predicted
values along the simulations are incorrect. This enables CES to rule out
suspiciously correct output predictions due to reasoning shortcuts,
hallucinations, or potential data leakage. CES also introduces a novel metric
to measure reasoning consistency across tests with the same or different prime
path coverage in a spectrum: strong, weak, and random. Evaluating 16 LLMs
(including three reasoning LLMs) using CES indicates 81.42% coherent execution
simulation on HumanEval, 46.92% and 53.08% of which result in correct and
incorrect output predictions. Frontier LLMs such as GPT-4 and DeepSeek-R1 have
the most incoherent execution reasoning, mostly due to natural language
shortcuts. Despite relatively coherent execution simulation, LLMs' reasoning
performance across different tests is inconsistent, mostly random (48.87%) or
weak (45.37%), potentially explaining their weakness in programming tasks that
require path-sensitive program analysis to succeed. We also compare CES with
bug prediction/localization/repair, which intuitively requires control- and
data-flow awareness. We observe that LLMs barely incorporate execution
reasoning into their analysis for bug-related tasks, and their success is
primarily due to inherent abilities in pattern matching or natural language
shortcuts, if not data leakage. Without reasoning, there is a threat to the
generalizability of LLMs in dealing with unseen bugs or patterns in different
contexts. CES can be used to vet the suspicious success of LLMs in these tasks
systematically.

</details>


### [3] [Community Engagement and the Lifespan of Open-Source Software Projects](https://arxiv.org/abs/2510.15408)
*Mohit,Kuljit Kaur Chahal*

Main category: cs.SE

TL;DR: 本研究分析了开源软件项目中社区参与度对项目动态和寿命的影响，定义了社区参与度的量化指标，并发现社区参与度与项目动态显著相关，且对项目寿命有复杂影响模式。


<details>
  <summary>Details</summary>
Motivation: 开源软件项目依赖社区参与来维持长期发展，但社区参与度对项目动态和寿命的量化影响尚未得到充分研究。

Method: 分析了33,946个GitHub仓库，定义并操作化了社区参与度的月度指标（issues、comments、watchers、stargazers），使用非参数检验和相关性分析评估与项目动态和寿命的关系。

Result: 社区参与度指标与项目动态显著相关，在高度参与的项目中相关性更强。对于项目寿命，呈现复杂模式：月度参与率在年轻项目中最高，随年龄下降，但部分长寿项目保持异常高活跃度。初始参与爆发对项目建立至关重要，持续高参与驱动极端长寿。

Conclusion: 社区参与度动态驱动开源软件项目的寿命和发展。研究建立了验证的社区参与度指标，并深入揭示了不同社区活动模式如何促进项目长寿。

Abstract: Open-source software (OSS) projects depend on community engagement (CE) for
longevity. However, CE's quantifiable impact on project dynamics and lifespan
is underexplored. Objectives: This study defines CE in OSS, identifies key
metrics, and evaluates their influence on project dynamics (releases, commits,
branches) and lifespan. Methods: We analyzed 33,946 GitHub repositories,
defining and operationalizing CE with validated per-month metrics (issues,
comments, watchers, stargazers). Non-parametric tests and correlations assessed
relationships with project dynamics and lifespan across quartiles. Results: CE
metrics significantly associate with project dynamics, with stronger
correlations in highly engaged projects. For lifespan, a complex pattern
emerged: per-month CE rates are highest in younger projects, declining with
age. Yet, a subset of long-lived projects maintains exceptionally high
activity. Initial CE bursts appear crucial for establishment, while sustained
high engagement drives extreme longevity. Active issue engagement's influence
intensifies with age, but passive attention's declines. Conclusion: CE
dynamically drives OSS project longevity and development. Our findings
establish validated CE metrics and offer deeper insights into how diverse
community activity patterns contribute to project longevity.

</details>


### [4] [Selecting and Combining Large Language Models for Scalable Code Clone Detection](https://arxiv.org/abs/2510.15480)
*Muslim Chochlov,Gul Aftab Ahmed,James Vincent Patten,Yuanhua Han,Guoxian Lu,David Gregg,Jim Buckley*

Main category: cs.SE

TL;DR: 本文研究了LLM在代码克隆检测中的表现，发现没有统一的'最佳LLM'，但CodeT5+110M、CuBERT和SPTCode表现较好。同时探索了LLM集成方法，发现最大或求和集成优于平均集成，在商业大规模数据集上集成方法可将精度提升至46.91%。


<details>
  <summary>Details</summary>
Motivation: 代码克隆存在知识产权侵权和安全漏洞风险，但有效的可扩展克隆检测（特别是针对发散克隆）仍然具有挑战性。LLM最近被应用于克隆检测任务，但快速涌现的LLM引发了关于最佳模型选择和LLM集成潜力的疑问。

Method: 识别76个LLM并筛选适合大规模克隆检测的候选模型，在两个公共工业数据集和商业大规模数据集上评估。探索LLM集成方法，包括得分归一化和不同集成策略（最大、求和、平均）。

Result: 没有统一的'最佳LLM'，但CodeT5+110M、CuBERT和SPTCode表现较好。在商业大规模数据集上，表现最佳的CodeT5+110M达到39.71%精度，是之前使用的CodeBERT的两倍。集成方法在商业大规模代码上达到46.91%精度。

Conclusion: 较小的嵌入尺寸、较小的分词器词汇量和定制数据集对LLM克隆检测有利。集成方法（特别是最大或求和策略）可以显著提高检测精度，在大型数据集上效果更明显。

Abstract: Source code clones pose risks ranging from intellectual property violations
to unintended vulnerabilities. Effective and efficient scalable clone
detection, especially for diverged clones, remains challenging. Large language
models (LLMs) have recently been applied to clone detection tasks. However, the
rapid emergence of LLMs raises questions about optimal model selection and
potential LLM-ensemble efficacy.
  This paper addresses the first question by identifying 76 LLMs and filtering
them down to suitable candidates for large-scale clone detection. The
candidates were evaluated on two public industrial datasets, BigCloneBench, and
a commercial large-scale dataset. No uniformly 'best-LLM' emerged, though
CodeT5+110M, CuBERT and SPTCode were top-performers. Analysis of LLM-candidates
suggested that smaller embedding sizes, smaller tokenizer vocabularies and
tailored datasets are advantageous. On commercial large-scale dataset a
top-performing CodeT5+110M achieved 39.71\% precision: twice the precision of
previously used CodeBERT.
  To address the second question, this paper explores ensembling of the
selected LLMs: effort-effective approach to improving effectiveness. Results
suggest the importance of score normalization and favoring ensembling methods
like maximum or sum over averaging. Also, findings indicate that ensembling
approach can be statistically significant and effective on larger datasets: the
best-performing ensemble achieved even higher precision of 46.91\% over
individual LLM on the commercial large-scale code.

</details>


### [5] [An Experimental Study of Real-Life LLM-Proposed Performance Improvements](https://arxiv.org/abs/2510.15494)
*Lirong Yi,Gregory Gay,Philipp Leitner*

Main category: cs.SE

TL;DR: LLMs能够生成代码，但在生成高性能代码方面表现有限。在65个真实Java任务中，LLM生成的代码大多能提升性能，但仍显著落后于人类开发者的优化方案。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能够生成高性能代码，而不仅仅是功能正确的代码。通过对比LLM生成代码与人类优化方案在真实任务中的表现，评估LLMs在代码性能优化方面的能力。

Method: 从开源Java程序中挖掘65个开发者实现显著加速的真实任务，使用两种领先LLM在四种提示变体下自动生成补丁，并通过严格基准测试对比基线代码和人类解决方案。

Result: LLM生成的代码在大多数情况下确实比基线代码性能更好，但人类开发者提出的补丁在统计上显著优于LLM修复方案。约三分之二的LLM解决方案与开发者优化思路语义相同或相似，其余三分之一提出更原创的想法，但这些原创想法很少带来实质性性能提升。

Conclusion: LLMs在代码性能优化方面有一定能力，但通常无法找到真正最优的解决方案，与人类开发者的优化水平仍存在明显差距。

Abstract: Large Language Models (LLMs) can generate code, but can they generate fast
code? In this paper, we study this question using a dataset of 65 real-world
tasks mined from open-source Java programs. We specifically select tasks where
developers achieved significant speedups, and employ an automated pipeline to
generate patches for these issues using two leading LLMs under four prompt
variations. By rigorously benchmarking the results against the baseline and
human-authored solutions, we demonstrate that LLM-generated code indeed
improves performance over the baseline in most cases. However, patches proposed
by human developers outperform LLM fixes by a statistically significant margin,
indicating that LLMs often fall short of finding truly optimal solutions. We
further find that LLM solutions are semantically identical or similar to the
developer optimization idea in approximately two-thirds of cases, whereas they
propose a more original idea in the remaining one-third. However, these
original ideas only occasionally yield substantial performance gains.

</details>


### [6] [Enhancing Code Review through Fuzzing and Likely Invariants](https://arxiv.org/abs/2510.15512)
*Wachiraphan Charoenwet,Patanamon Thongtanunam,Van-Thuan Pham,Christoph Treude*

Main category: cs.SE

TL;DR: FuzzSight是一个利用模糊测试和不变式分析来检测代码行为变化的框架，能够在代码审查阶段早期发现潜在缺陷。


<details>
  <summary>Details</summary>
Motivation: 传统代码审查主要依赖静态检查，难以发现程序动态行为问题。模糊测试产生的丰富数据在审查中未被充分利用，限制了其在早期发现非崩溃性缺陷的能力。

Method: 通过分析非崩溃模糊测试输入中的likely invariants（可能不变式）来捕捉程序行为变化，将程序行为表示为在特定程序点一致观察到的动态属性。

Result: FuzzSight能够标记75%的回归缺陷和高达80%的漏洞，在识别有缺陷代码块方面优于SAST工具，检测率提高10倍且误报更少。

Conclusion: FuzzSight展示了将模糊测试和不变式分析结合用于早期代码审查的潜力，有效连接了静态检查与动态行为洞察。

Abstract: Many software projects employ manual code review to gatekeep defects and
vulnerabilities in the code before integration. However, reviewers often work
under time pressure and rely primarily on static inspection, leaving the
dynamic aspects of the program unexplored. Dynamic analyses could reveal such
behaviors, but they are rarely integrated into reviews. Among them, fuzzing is
typically applied later to uncover crashing bugs. Yet its ability to exercise
code with diverse inputs makes it promising for exposing non-crashing, but
unexpected, behaviors earlier. Still, without suitable mechanisms to analyze
program behaviors, the rich data produced during fuzzing remains inaccessible
to reviewers, limiting its practical value in this context.
  We hypothesize that unexpected variations in program behaviors could signify
potential bugs. The impact of code changes can be automatically captured at
runtime. Representing program behavior as likely invariants, dynamic properties
consistently observed at specific program points, can provide practical signals
of behavioral changes. Such signals offer a way to distinguish between intended
changes and unexpected behavioral shifts from code changes.
  We present FuzzSight, a framework that leverages likely invariants from
non-crashing fuzzing inputs to highlight behavioral differences across program
versions. By surfacing such differences, it provides insights into which code
blocks may need closer attention. In our evaluation, FuzzSight flagged 75% of
regression bugs and up to 80% of vulnerabilities uncovered by 24-hour fuzzing.
It also outperformed SAST in identifying buggy code blocks, achieving ten times
higher detection rates with fewer false alarms. In summary, FuzzSight
demonstrates the potential and value of leveraging fuzzing and invariant
analysis for early-stage code review, bridging static inspection with dynamic
behavioral insights.

</details>


### [7] [Colepp: uma ferramenta multiplataforma para coleta de dados de dispositivos vestiveis](https://arxiv.org/abs/2510.15565)
*Vinicius Moraes de Jesus,Andre Georghton Cardoso Pacheco*

Main category: cs.SE

TL;DR: Colepp是一个开源跨平台工具，用于从多个可穿戴设备收集和同步心率（ECG、PPG）和运动信号（加速度计、陀螺仪）数据，通过智能手机作为中心枢纽，生成同步的CSV格式数据集。


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备的普及需要可靠的数据收集工具，但缺乏大规模高质量公共数据集和数据收集条件控制的问题阻碍了稳健算法的发展。

Method: 开发Colepp工具，集成智能手机作为中心枢纽，接收来自Polar H10胸带和Wear OS智能手表的数据，使用自定义同步协议和用户友好界面生成同步数据集。

Result: 工具能够产生一致且同步的信号，通过用例展示了其有效性。

Conclusion: Colepp为人类活动识别和心率估计等应用提供了可定制的真实世界数据集生成解决方案。

Abstract: The widespread adoption of wearable devices such as smartwatches and fitness
trackers has fueled the demand for reliable physiological and movement data
collection tools. However, challenges such as limited access to large,
high-quality public datasets and a lack of control over data collection
conditions hinder the development of robust algorithms. This work presents
Colepp, an open-source, cross-platform tool designed to collect and synchronize
data from multiple wearable devices, including heart rate (via ECG and PPG) and
motion signals (accelerometer and gyroscope). The system integrates a
smartphone as a central hub, receiving data from a Polar H10 chest strap and a
Wear OS smartwatch, and exporting synchronized datasets in CSV format. Through
a custom synchronization protocol and user-friendly interface, Colepp
facilitates the generation of customizable, real-world datasets suitable for
applications such as human activity recognition and heart rate estimation. A
use case shows the effectiveness of the tool in producing consistent and
synchronized signals.

</details>


### [8] [Leveraging Test Driven Development with Large Language Models for Reliable and Verifiable Spreadsheet Code Generation: A Research Framework](https://arxiv.org/abs/2510.15585)
*Dr Simon Thorne,Dr Advait Sarkar*

Main category: cs.SE

TL;DR: 该立场论文提出将测试驱动开发(TDD)与大型语言模型(LLM)生成相结合的研究框架，通过"测试优先"方法提高生成代码的正确性和可靠性，特别关注金融建模和科学计算等高风险领域。


<details>
  <summary>Details</summary>
Motivation: LLM在生成代码时经常出现幻觉、逻辑不一致和语法错误等问题，在金融建模和科学计算等高风险领域，这些错误可能带来严重后果。需要一种方法来提高生成代码的准确性和可靠性。

Method: 提出将测试驱动开发(TDD)实践与LLM驱动生成相结合的结构化框架，采用"测试优先"方法，为LLM输出提供技术约束和认知支撑，适用于从电子表格公式到Python、Rust等多种编程环境。

Result: 框架包含明确的实验设计、参与者分组、评估指标和基于TDD的提示示例，强调测试驱动思维，旨在提高计算思维、提示工程技能和用户参与度。

Conclusion: 通过测试驱动方法可以改善LLM生成代码的质量，特别有利于缺乏正式编程培训的电子表格用户，邀请合作来完善和实证评估该方法，建立负责任和可靠的LLM集成实践。

Abstract: Large Language Models (LLMs), such as ChatGPT, are increasingly leveraged for
generating both traditional software code and spreadsheet logic. Despite their
impressive generative capabilities, these models frequently exhibit critical
issues such as hallucinations, subtle logical inconsistencies, and syntactic
errors, risks particularly acute in high stakes domains like financial
modelling and scientific computations, where accuracy and reliability are
paramount. This position paper proposes a structured research framework that
integrates the proven software engineering practice of Test-Driven Development
(TDD) with Large Language Model (LLM) driven generation to enhance the
correctness of, reliability of, and user confidence in generated outputs. We
hypothesise that a "test first" methodology provides both technical constraints
and cognitive scaffolding, guiding LLM outputs towards more accurate,
verifiable, and comprehensible solutions. Our framework, applicable across
diverse programming contexts, from spreadsheet formula generation to scripting
languages such as Python and strongly typed languages like Rust, includes an
explicitly outlined experimental design with clearly defined participant
groups, evaluation metrics, and illustrative TDD based prompting examples. By
emphasising test driven thinking, we aim to improve computational thinking,
prompt engineering skills, and user engagement, particularly benefiting
spreadsheet users who often lack formal programming training yet face serious
consequences from logical errors. We invite collaboration to refine and
empirically evaluate this approach, ultimately aiming to establish responsible
and reliable LLM integration in both educational and professional development
practices.

</details>


### [9] [Interact and React: Exploring Gender Patterns in Development and the Impact on Innovation and Robustness of a User Interface Tool](https://arxiv.org/abs/2510.15642)
*Sian Brooke*

Main category: cs.SE

TL;DR: 该研究分析了React项目中性别多样性对软件开发的影响，发现女性在功能增强和依赖管理方面贡献显著，性别排斥对软件质量有害。


<details>
  <summary>Details</summary>
Motivation: 开源软件设计中女性参与往往被忽视，研究旨在了解性别多样性如何从根本上改变开发模式，特别是女性参与对React项目的影响。

Method: 研究分析了React这个广泛使用的JavaScript库，考察了11年间性别差异在稳健性和创新性指标上的表现，以及主要版本发布前的贡献模式变化。

Result: 研究发现女性在功能增强和依赖管理方面贡献更多，性别排斥对软件质量产生负面影响。

Conclusion: 增加性别多样性可以带来更具包容性、创新性和稳健性的软件，女性参与对软件开发质量有重要积极影响。

Abstract: In open-source software design, the inclusion of women is often highlighted
simply to remind programmers that women exist. Yet, little attention is given
to how greater gender diversity, specifically women's participation, could
fundamentally alter development patterns. To understand the potential impact of
gender inclusion, this study investigates React, a widely used JavaScript
library for building user interfaces with an active contributor community. I
examine gender differences in metrics of robustness and innovation, as well as
shifts in contribution patterns leading up to major version releases over 11
years of the React project. My results show that the exclusion of women is
detrimental to software as women contribute significantly more to feature
enhancement and dependency management. By exploring how gender influences
innovation and robustness in the development of React, the study offers
critical insights into how increasing gender diversity could lead to more
inclusive, innovative, and robust software.

</details>


### [10] [MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing](https://arxiv.org/abs/2510.15690)
*Shiwen Ou,Yuwei Li,Lu Yu,Chengkun Wei,Tingke Wen,Qiangpu Chen,Yu Chen,Haizhi Tang,Zulie Pan*

Main category: cs.SE

TL;DR: MirrorFuzz是一个自动化的API模糊测试解决方案，用于发现深度学习框架中的共享bug。它通过收集历史bug数据、匹配相似API以及使用LLM生成测试代码，在四个流行DL框架中发现了315个bug，其中262个是新发现的。


<details>
  <summary>Details</summary>
Motivation: 深度学习框架中的bug会级联影响上层应用，但现有研究很少探索跨框架的API模式及其潜在风险。许多DL框架暴露相似的API，使它们容易受到共享bug的影响。

Method: MirrorFuzz采用三阶段方法：1)收集每个API的历史bug数据识别潜在buggy API；2)在框架内和跨框架匹配相似API；3)使用LLM基于相似API的历史bug数据合成测试代码来触发类似bug。

Result: 在TensorFlow、PyTorch、OneFlow和Jittor四个框架上的评估显示，MirrorFuzz相比最先进方法在TensorFlow和PyTorch上分别提高了39.92%和98.20%的代码覆盖率。共发现315个bug，其中262个是新bug，80个被修复，52个获得CNVD ID。

Conclusion: MirrorFuzz通过利用跨框架API相似性和历史bug数据，有效发现了深度学习框架中的共享bug，证明了其在提高代码覆盖率和bug检测能力方面的优势。

Abstract: Deep learning (DL) frameworks serve as the backbone for a wide range of
artificial intelligence applications. However, bugs within DL frameworks can
cascade into critical issues in higher-level applications, jeopardizing
reliability and security. While numerous techniques have been proposed to
detect bugs in DL frameworks, research exploring common API patterns across
frameworks and the potential risks they entail remains limited. Notably, many
DL frameworks expose similar APIs with overlapping input parameters and
functionalities, rendering them vulnerable to shared bugs, where a flaw in one
API may extend to analogous APIs in other frameworks. To address this
challenge, we propose MirrorFuzz, an automated API fuzzing solution to discover
shared bugs in DL frameworks. MirrorFuzz operates in three stages: First,
MirrorFuzz collects historical bug data for each API within a DL framework to
identify potentially buggy APIs. Second, it matches each buggy API in a
specific framework with similar APIs within and across other DL frameworks.
Third, it employs large language models (LLMs) to synthesize code for the API
under test, leveraging the historical bug data of similar APIs to trigger
analogous bugs across APIs. We implement MirrorFuzz and evaluate it on four
popular DL frameworks (TensorFlow, PyTorch, OneFlow, and Jittor). Extensive
evaluation demonstrates that MirrorFuzz improves code coverage by 39.92\% and
98.20\% compared to state-of-the-art methods on TensorFlow and PyTorch,
respectively. Moreover, MirrorFuzz discovers 315 bugs, 262 of which are newly
found, and 80 bugs are fixed, with 52 of these bugs assigned CNVD IDs.

</details>


### [11] [EASELAN: An Open-Source Framework for Multimodal Biosignal Annotation and Data Management](https://arxiv.org/abs/2510.15767)
*Rathi Adarshi Rammohan,Moritz Meier,Dennis Küster,Tanja Schultz*

Main category: cs.SE

TL;DR: EASELAN是一个基于ELAN的多模态生物信号标注框架，旨在简化复杂数据集的标注工作流程，支持从文件准备到版本控制和后处理的完整流程。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和融合模型的发展，对大规模多模态生物信号标注数据的需求日益增长，需要更高效的标注工具来处理复杂的多通道数据。

Method: 在ELAN工具基础上构建，添加了专门组件来支持标注管道的各个阶段，包括文件准备、通道设置、GitHub集成版本控制和简化后处理。

Result: 成功应用于人类日常活动（餐桌布置）的高维生物信号收集项目，建立了完全标注的Table Setting数据库。

Conclusion: EASELAN为生物信号收集、标注和处理研究提供了有效工具，代码和标注数据库已公开可用。

Abstract: Recent advancements in machine learning and adaptive cognitive systems are
driving a growing demand for large and richly annotated multimodal data. A
prominent example of this trend are fusion models, which increasingly
incorporate multiple biosignals in addition to traditional audiovisual
channels. This paper introduces the EASELAN annotation framework to improve
annotation workflows designed to address the resulting rising complexity of
multimodal and biosignals datasets. It builds on the robust ELAN tool by adding
new components tailored to support all stages of the annotation pipeline: From
streamlining the preparation of annotation files to setting up additional
channels, integrated version control with GitHub, and simplified
post-processing. EASELAN delivers a seamless workflow designed to integrate
biosignals and facilitate rich annotations to be readily exported for further
analyses and machine learning-supported model training. The EASELAN framework
is successfully applied to a high-dimensional biosignals collection initiative
on human everyday activities (here, table setting) for cognitive robots within
the DFG-funded Collaborative Research Center 1320 Everyday Activity Science and
Engineering (EASE). In this paper we discuss the opportunities, limitations,
and lessons learned when using EASELAN for this initiative. To foster research
on biosignal collection, annotation, and processing, the code of EASELAN is
publicly available(https://github.com/cognitive-systems-lab/easelan), along
with the EASELAN-supported fully annotated Table Setting Database.

</details>


### [12] [Towards Supporting Open Source Library Maintainers with Community-Based Analytics](https://arxiv.org/abs/2510.15794)
*Rachna Raj,Diego Elias Costa*

Main category: cs.SE

TL;DR: 该论文提出使用社区分析工具来帮助开源软件维护者了解其API在实际项目中的使用情况，通过分析10个流行Java库及其依赖生态系统的实证研究发现，平均只有16%的API方法被实际使用，且仅有74%的被使用API方法在测试套件中得到覆盖。


<details>
  <summary>Details</summary>
Motivation: 开源软件维护者缺乏对其API在实际依赖项目中如何使用情况的持续反馈，这些洞察可以帮助维护者改进测试策略、理解变更影响并更有效地指导库的演进。

Method: 对10个流行Java库及其各自50个依赖项目进行实证研究，分析API使用情况，并提出两个指标来评估测试套件对社区使用API的覆盖情况，同时调查开源实践者以评估这些洞察的实际价值。

Result: 研究发现库开发者提供的API方法中平均只有16%被依赖生态系统实际使用，且在被使用的API方法中，只有74%在库的测试套件中得到部分或完全覆盖。

Conclusion: 社区分析工具可以为开源软件维护者提供有价值的洞察，帮助他们基于实际使用情况做出更好的维护决策，优化测试策略并指导库的演进。

Abstract: Open-source software (OSS) is a pillar of modern software development. Its
success depends on the dedication of maintainers who work constantly to keep
their libraries stable, adapt to changing needs, and support a growing
community. Yet, they receive little to no continuous feedback on how the
projects that rely on their libraries actually use their APIs. We believe that
gaining these insights can help maintainers make better decisions, such as
refining testing strategies, understanding the impact of changes, and guiding
the evolution of their libraries more effectively. We propose the use of
community-based analytics to analyze how an OSS library is used across its
dependent ecosystem. We conduct an empirical study of 10 popular Java libraries
and each with their respective dependent ecosystem of 50 projects. Our results
reveal that while library developers offer a wide range of API methods, only
16% on average are actively used by their dependent ecosystem. Moreover, only
74% of the used API methods are partially or fully covered by their library
test suite. We propose two metrics to help developers evaluate their test suite
according to the APIs used by their community, and we conduct a survey on
open-source practitioners to assess the practical value of these insights in
guiding maintenance decisions.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [13] [The Role of Federated Learning in Improving Financial Security: A Survey](https://arxiv.org/abs/2510.14991)
*Cade Houston Kennedy,Amr Hilal,Morteza Momeni*

Main category: cs.CR

TL;DR: 这篇论文综述了联邦学习在金融安全领域的应用，提出了基于监管风险暴露程度的分类方法，并讨论了实现挑战和未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 随着数字金融系统的发展，传统机器学习模型在欺诈检测中需要集中访问敏感数据，存在隐私泄露风险。联邦学习提供了一种保护隐私的分布式模型训练方案。

Method: 采用综述研究方法，对联邦学习在金融系统中的应用进行分类，基于监管和合规风险暴露程度从低风险任务（如协作投资组合优化）到高风险任务（如实时欺诈检测）。

Result: 论文提出了联邦学习在金融安全中的新分类框架，回顾了其在欺诈预防和区块链集成框架中的实际应用成功案例，并分析了当前防御机制。

Conclusion: 联邦学习在金融领域部署面临数据异构性、对抗性攻击和监管合规等挑战，未来方向包括区块链集成、差分隐私、安全多方计算和量子安全框架。

Abstract: With the growth of digital financial systems, robust security and privacy
have become a concern for financial institutions. Even though traditional
machine learning models have shown to be effective in fraud detections, they
often compromise user data by requiring centralized access to sensitive
information. In IoT-enabled financial endpoints such as ATMs and POS Systems
that regularly produce sensitive data that is sent over the network. Federated
Learning (FL) offers a privacy-preserving, decentralized model training across
institutions without sharing raw data. FL enables cross-silo collaboration
among banks while also using cross-device learning on IoT endpoints. This
survey explores the role of FL in enhancing financial security and introduces a
novel classification of its applications based on regulatory and compliance
exposure levels ranging from low-exposure tasks such as collaborative portfolio
optimization to high-exposure tasks like real-time fraud detection. Unlike
prior surveys, this work reviews FL's practical use within financial systems,
discussing its regulatory compliance and recent successes in fraud prevention
and blockchain-integrated frameworks. However, FL deployment in finance is not
without challenges. Data heterogeneity, adversarial attacks, and regulatory
compliance make implementation far from easy. This survey reviews current
defense mechanisms and discusses future directions, including blockchain
integration, differential privacy, secure multi-party computation, and
quantum-secure frameworks. Ultimately, this work aims to be a resource for
researchers exploring FL's potential to advance secure, privacy-compliant
financial systems.

</details>


### [14] [A Light Weight Cryptographic Solution for 6LoWPAN Protocol Stack](https://arxiv.org/abs/2510.14993)
*Sushil Khairnar,Gaurav Bansod,Vijay Dahiphale*

Main category: cs.CR

TL;DR: 本文提出了一种轻量级密码算法LiCi2，专为6LoWPAN协议栈和物联网等受限环境设计，在内存占用、功耗和硬件实现方面都优于现有轻量级密码标准。


<details>
  <summary>Details</summary>
Motivation: 物联网等受限环境需要轻量级密码算法，传统加密算法如AES在资源受限设备上效率低下，需要设计专门针对无线传感器节点约束的轻量级密码。

Method: 基于LiCi密码设计改进，提出LiCi2轻量级密码算法，并集成到6LoWPAN协议栈中替代传统加密算法，详细分析了算法对各种密码攻击的抵抗能力。

Result: LiCi2仅需1856字节FLASH和1272字节RAM，功耗约25mW，硬件实现仅需1051个门等效单元，均优于ISO认证的PRESENT密码和其他现有轻量级密码设计。

Conclusion: LiCi2在各项设计指标上均优于现有轻量级密码，是物联网等受限环境的理想选择，为研究人员提供了明显更优的实现方案。

Abstract: Lightweight cryptography is an emerging field in the field of research, which
endorses algorithms which are best suited for constrained environment. Design
metrics like Gate Equivalence (GE), Memory Requirement, Power Consumption, and
Throughput play a vital role in the applications like IoT. This paper presents
the 6LoWPAN Protocol Stack which is a popular standard of communication for
constrained devices. This paper presents an implementation of a lightweight
6LoWPAN Protocol stack by using a Light weight Cipher instead of regular heavy
encryption cipher AES. The cipher proposed in this paper is specifically
suitable for 6LoWPAN architecture as it addresses all the constraints possessed
by wireless sensor nodes. The lightweight cipher proposed in the paper needs
only 1856 bytes of FLASH and 1272 bytes of RAM memory which is less than any
other standard existing lightweight cipher design. The proposed ciphers power
consumption is around 25 mW which is significantly less as compared to ISO
certified lightweight cipher PRESENT which consumes around 38 mW of dynamic
power. This paper also discusses the detailed analysis of cipher against the
attacks like Linear Cryptanalysis, Differential Cryptanalysis, Biclique attack
and Avalanche attack. The cipher implementation on hardware is around 1051 GEs
for 64 bit of block size with 128 bit of key length which is less as compared
to existing lightweight cipher design. The proposed cipher LiCi2 is motivated
from LiCi cipher design but outclasses it in every design metric. We believe
the design of LiCi2 is the obvious choice for researchers to implement in
constrained environments like IoT.

</details>


### [15] [VaultGemma: A Differentially Private Gemma Model](https://arxiv.org/abs/2510.15001)
*Amer Sinha,Thomas Mesnard,Ryan McKenna,Daogao Liu,Christopher A. Choquette-Choo,Yangsibo Huang,Da Yu,George Kaissis,Zachary Charles,Ruibo Liu,Lynn Chua,Pritish Kamath,Pasin Manurangsi,Steve He,Chiyuan Zhang,Badih Ghazi,Borja De Balle Pigem,Prem Eruvbetine,Tris Warkentin,Armand Joulin,Ravi KumarAmer Sinha,Thomas Mesnard,Ryan McKenna,Daogao Liu,Christopher A. Choquette-Choo,Yangsibo Huang,Da Yu,George Kaissis,Zachary Charles,Ruibo Liu,Lynn Chua,Pritish Kamath,Pasin Manurangsi,Steve He,Chiyuan Zhang,Badih Ghazi,Borja De Balle Pigem,Prem Eruvbetine,Tris Warkentin,Armand Joulin,Ravi Kumar*

Main category: cs.CR

TL;DR: VaultGemma 1B是一个具有10亿参数的Gemma系列模型，完全使用差分隐私进行训练，代表了隐私保护大语言模型的重要进展。


<details>
  <summary>Details</summary>
Motivation: 开发一个在训练过程中完全采用差分隐私保护的大语言模型，以解决隐私保护问题。

Method: 使用与Gemma 2系列相同的数据混合进行预训练，并采用差分隐私技术。

Result: 成功开发出VaultGemma 1B模型，这是一个具有10亿参数的隐私保护语言模型。

Conclusion: 该模型已向社区公开发布，标志着隐私保护大语言模型发展的重要里程碑。

Abstract: We introduce VaultGemma 1B, a 1 billion parameter model within the Gemma
family, fully trained with differential privacy. Pretrained on the identical
data mixture used for the Gemma 2 series, VaultGemma 1B represents a
significant step forward in privacy-preserving large language models. We openly
release this model to the community

</details>


### [16] [Active Honeypot Guardrail System: Probing and Confirming Multi-Turn LLM Jailbreaks](https://arxiv.org/abs/2510.15017)
*ChenYu Wu,Yi Wang,Yang Liao*

Main category: cs.CR

TL;DR: 提出基于蜜罐的主动防护系统，通过生成诱饵响应来探测用户意图，在多轮对话中逐步暴露恶意行为，显著降低越狱成功率同时保持良好用户体验。


<details>
  <summary>Details</summary>
Motivation: 现有LLM防御主要依赖被动拒绝，无法有效应对自适应攻击者或过度限制正常用户。需要将风险规避转化为风险利用。

Method: 微调诱饵模型生成模糊、不可操作但语义相关的响应作为诱饵，结合受保护LLM的安全回复，插入主动诱饵问题，通过多轮交互逐步暴露恶意意图。引入Honeypot Utility Score (HUS) 和 Defense Efficacy Rate (DER) 指标。

Result: 在MHJ数据集上使用GPT-4o进行的实验表明，该系统显著破坏了越狱成功率，同时保持了良性用户体验。

Conclusion: 蜜罐主动防护系统能有效应对多轮越狱攻击，在安全性和可用性之间取得良好平衡。

Abstract: Large language models (LLMs) are increasingly vulnerable to multi-turn
jailbreak attacks, where adversaries iteratively elicit harmful behaviors that
bypass single-turn safety filters. Existing defenses predominantly rely on
passive rejection, which either fails against adaptive attackers or overly
restricts benign users. We propose a honeypot-based proactive guardrail system
that transforms risk avoidance into risk utilization. Our framework fine-tunes
a bait model to generate ambiguous, non-actionable but semantically relevant
responses, which serve as lures to probe user intent. Combined with the
protected LLM's safe reply, the system inserts proactive bait questions that
gradually expose malicious intent through multi-turn interactions. We further
introduce the Honeypot Utility Score (HUS), measuring both the attractiveness
and feasibility of bait responses, and use a Defense Efficacy Rate (DER) for
balancing safety and usability. Initial experiment on MHJ Datasets with recent
attack method across GPT-4o show that our system significantly disrupts
jailbreak success while preserving benign user experience.

</details>


### [17] [Physical Layer Deception based on Semantic Distortion](https://arxiv.org/abs/2510.15063)
*Wenwen Chen,Bin Han,Yao Zhu,Anke Schmeink,Giuseppe Caire,Hans D. Schotten*

Main category: cs.CR

TL;DR: 该论文将物理层欺骗框架扩展到语义通信模型，通过理论分析和优化算法，使发送方能够优化加密策略以最大化窃听者的语义失真，同时保持合法接收者的低语义失真。


<details>
  <summary>Details</summary>
Motivation: 传统的物理层安全主要依赖被动防御，该研究旨在将物理层安全与欺骗技术结合，实现主动对抗窃听的措施，特别是在语义通信场景下提升安全性。

Method: 通过理论分析使用语义失真作为性能指标，研究接收方解密策略选择和发送方加密策略优化，提出高效的优化算法，并在多种场景下推导闭式最优解。

Result: 数值模拟验证了理论发现，证实了所提算法的实用性，能够有效最大化窃听者的语义失真同时保证合法接收者的通信质量。

Conclusion: 该研究成功将物理层欺骗框架扩展到语义通信，提供了一种有效的主动安全机制，通过策略优化实现了安全性和通信质量的平衡。

Abstract: Physical layer deception (PLD) is a framework we previously introduced that
integrates physical layer security (PLS) with deception techniques, enabling
proactive countermeasures against eavesdropping rather than relying solely on
passive defense. We extend this framework to a semantic communication model and
conduct a theoretical analysis using semantic distortion as the performance
metric. In this work, we further investigate the receiver's selection of
decryption strategies and the transmitter's optimization of encryption
strategies. By anticipating the decryption strategy likely to be employed by
the legitimate receiver and eavesdropper, the transmitter can optimize resource
allocation and encryption parameters, thereby maximizing the semantic
distortion at the eavesdropper while maintaining a low level of semantic
distortion for the legitimate receiver. We present a rigorous analysis of the
resulting optimization problem, propose an efficient optimization algorithm,
and derive closed-form optimal solutions for multiple scenarios. Finally, we
corroborate the theoretical findings with numerical simulations, which also
confirm the practicality of the proposed algorithm.

</details>


### [18] [Sequential Comics for Jailbreaking Multimodal Large Language Models via Structured Visual Storytelling](https://arxiv.org/abs/2510.15068)
*Deyue Zhang,Dongdong Yang,Junjie Mu,Quancheng Zou,Zonghao Ying,Wenzhuo Xu,Zhao Liu,Xuan Wang,Xiangzheng Zhang*

Main category: cs.CR

TL;DR: 提出了一种利用漫画式视觉叙事来绕过多模态大语言模型安全防护的新方法，通过将恶意查询分解为视觉无害的叙事元素，生成图像序列，利用模型对叙事连贯性的依赖来引发有害输出。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型虽然能力强大，但仍然容易受到利用跨模态漏洞的越狱攻击。现有安全机制在面对视觉叙事攻击时存在明显不足。

Method: 使用辅助LLM将恶意查询分解为视觉无害的叙事元素，通过扩散模型生成对应的图像序列，利用模型对叙事连贯性的依赖来绕过安全防护。

Result: 在已建立的安全基准测试中，该方法对有害文本查询的平均攻击成功率达到83.5%，比现有最佳方法高出46%，在各类有害内容上均表现出优越效果。

Conclusion: 序列叙事策略在多模态安全机制中暴露出关键漏洞因素，现有防御策略在面对叙事驱动攻击时存在显著保护缺口。

Abstract: Multimodal large language models (MLLMs) exhibit remarkable capabilities but
remain susceptible to jailbreak attacks exploiting cross-modal vulnerabilities.
In this work, we introduce a novel method that leverages sequential comic-style
visual narratives to circumvent safety alignments in state-of-the-art MLLMs.
Our method decomposes malicious queries into visually innocuous storytelling
elements using an auxiliary LLM, generates corresponding image sequences
through diffusion models, and exploits the models' reliance on narrative
coherence to elicit harmful outputs. Extensive experiments on harmful textual
queries from established safety benchmarks show that our approach achieves an
average attack success rate of 83.5\%, surpassing prior state-of-the-art by
46\%. Compared with existing visual jailbreak methods, our sequential narrative
strategy demonstrates superior effectiveness across diverse categories of
harmful content. We further analyze attack patterns, uncover key vulnerability
factors in multimodal safety mechanisms, and evaluate the limitations of
current defense strategies against narrative-driven attacks, revealing
significant gaps in existing protections.

</details>


### [19] [SMOTE and Mirrors: Exposing Privacy Leakage from Synthetic Minority Oversampling](https://arxiv.org/abs/2510.15083)
*Georgi Ganev,Reza Nazari,Rees Davison,Amir Dizche,Xinmin Wu,Ralph Abbey,Jorge Silva,Emiliano De Cristofaro*

Main category: cs.CR

TL;DR: SMOTE方法存在严重隐私泄露风险，新提出的DistinSMOTE和ReconSMOTE攻击能完美区分真实与合成记录，并重建原始少数类数据。


<details>
  <summary>Details</summary>
Motivation: SMOTE作为最广泛使用的类别不平衡处理方法，在隐私敏感应用中存在隐私泄露风险，但现有评估方法未能有效检测这种风险。

Method: 利用SMOTE的几何特性构建了两种新型攻击：DistinSMOTE（完美区分真实与合成记录）和ReconSMOTE（重建原始少数类记录），并提供了理论保证。

Result: 在8个标准不平衡数据集上的实验证实了攻击的实用性和有效性，ReconSMOTE在现实不平衡比例下能达到完美精度和接近1的召回率。

Conclusion: SMOTE本质上不具备隐私保护能力，会不成比例地暴露少数类记录，需要在隐私敏感应用中重新考虑其使用。

Abstract: The Synthetic Minority Over-sampling Technique (SMOTE) is one of the most
widely used methods for addressing class imbalance and generating synthetic
data. Despite its popularity, little attention has been paid to its privacy
implications; yet, it is used in the wild in many privacy-sensitive
applications. In this work, we conduct the first systematic study of privacy
leakage in SMOTE: We begin by showing that prevailing evaluation practices,
i.e., naive distinguishing and distance-to-closest-record metrics, completely
fail to detect any leakage and that membership inference attacks (MIAs) can be
instantiated with high accuracy. Then, by exploiting SMOTE's geometric
properties, we build two novel attacks with very limited assumptions:
DistinSMOTE, which perfectly distinguishes real from synthetic records in
augmented datasets, and ReconSMOTE, which reconstructs real minority records
from synthetic datasets with perfect precision and recall approaching one under
realistic imbalance ratios. We also provide theoretical guarantees for both
attacks. Experiments on eight standard imbalanced datasets confirm the
practicality and effectiveness of these attacks. Overall, our work reveals that
SMOTE is inherently non-private and disproportionately exposes minority
records, highlighting the need to reconsider its use in privacy-sensitive
applications.

</details>


### [20] [PoTS: Proof-of-Training-Steps for Backdoor Detection in Large Language Models](https://arxiv.org/abs/2510.15106)
*Issam Seddik,Sami Souihi,Mohamed Tamaazousti,Sara Tucci Piergiovanni*

Main category: cs.CR

TL;DR: 提出Proof-of-Training Steps协议，通过分析LLM语言建模头对输入扰动的敏感性，验证训练过程是否遵循声明的方法，可早期检测后门攻击。


<details>
  <summary>Details</summary>
Motivation: 现有后训练验证方案如Proof-of-Learning对LLM不实用，需要完全重训练、缺乏对隐蔽操作的鲁棒性，且无法在训练期间提供早期检测。早期检测可显著降低计算成本。

Method: 引入Proof-of-Training Steps验证协议，让独立审计员确认LLM开发者是否遵循声明的训练方案，包括数据批次、架构和超参数。通过分析LM-Head对输入扰动的敏感性来检测后门注入或训练偏差。

Result: 即使训练数据中有高达10%的后门触发器，该协议也能显著降低攻击者的攻击成功率。验证步骤比训练步骤快3倍，可在注入步骤早期检测攻击。

Conclusion: 该协议有潜力增强LLM开发的可问责性和安全性，特别是针对内部威胁。

Abstract: As Large Language Models (LLMs) gain traction across critical domains,
ensuring secure and trustworthy training processes has become a major concern.
Backdoor attacks, where malicious actors inject hidden triggers into training
data, are particularly insidious and difficult to detect. Existing
post-training verification solutions like Proof-of-Learning are impractical for
LLMs due to their requirement for full retraining, lack of robustness against
stealthy manipulations, and inability to provide early detection during
training. Early detection would significantly reduce computational costs. To
address these limitations, we introduce Proof-of-Training Steps, a verification
protocol that enables an independent auditor (Alice) to confirm that an LLM
developer (Bob) has followed the declared training recipe, including data
batches, architecture, and hyperparameters. By analyzing the sensitivity of the
LLMs' language modeling head (LM-Head) to input perturbations, our method can
expose subtle backdoor injections or deviations in training. Even with backdoor
triggers in up to 10 percent of the training data, our protocol significantly
reduces the attacker's ability to achieve a high attack success rate (ASR). Our
method enables early detection of attacks at the injection step, with
verification steps being 3x faster than training steps. Our results highlight
the protocol's potential to enhance the accountability and security of LLM
development, especially against insider threats.

</details>


### [21] [Partitioning $\mathbb{Z}_{sp}$ in finite fields and groups of trees and cycles](https://arxiv.org/abs/2510.15108)
*Nikolaos Verykios,Christos Gogos*

Main category: cs.CR

TL;DR: 该论文研究了环ℤₛₚ的代数与图形结构，重点分析其分解为有限域、核和特殊子集。引入了弧和根树来描述预周期结构，证明了某些树可以通过单位树的循环弧乘法生成。定义了集合𝔻ₛₚ并分析了其图分解为循环和预周期树，展示了循环内存在可预测的内循环，并讨论了𝔻ₛₚ在密码学中的潜在应用。


<details>
  <summary>Details</summary>
Motivation: 研究ℤₛₚ环的结构特性，特别是其分解为有限域和特殊子集的性质，旨在深入理解该环的代数与图形特征，为密码学中的循环攻击和因子分解方法提供理论基础。

Method: 引入弧和根树概念描述ℤₛₚ的预周期结构；建立𝔽ₛ与p𝔽ₛ之间的经典同构；定义并分析集合𝔻ₛₚ；证明树可以通过单位树的循环弧乘法生成；展示循环内存在可预测的内循环。

Result: 证明了ℤₛₚ中不被s或p整除的元素根树可以通过单位树的循环弧乘法生成；𝔻ₛₚ的图分解为循环和预周期树；每个循环包含从有限域p𝔽ₛ和s𝔽ₚ循环可预测导出的内循环。

Conclusion: ℤₛₚ环具有丰富的代数与图形结构，其分解特性和循环结构为密码学分析提供了新的视角，特别是𝔻ₛₚ集合在分析循环攻击和因子分解方法方面具有重要应用价值。

Abstract: This paper investigates the algebraic and graphical structure of the ring
$\mathbb{Z}_{sp}$, with a focus on its decomposition into finite fields,
kernels, and special subsets. We establish classical isomorphisms between
$\mathbb{F}_s$ and $p\mathbb{F}_s$, as well as $p\mathbb{F}_s^{\star}$ and
$p\mathbb{F}_s^{+1,\star}$. We introduce the notion of arcs and rooted trees to
describe the pre-periodic structure of $\mathbb{Z}_{sp}$, and prove that trees
rooted at elements not divisible by $s$ or $p$ can be generated from the tree
of unity via multiplication by cyclic arcs. Furthermore, we define and analyze
the set $\mathbb{D}_{sp}$, consisting of elements that are neither multiples of
$s$ or $p$ nor "off-by-one" elements, and show that its graph decomposes into
cycles and pre-periodic trees. Finally, we demonstrate that every cycle in
$\mathbb{Z}_{sp}$ contains inner cycles that are derived predictably from the
cycles of the finite fields $p\mathbb{F}_s$ and $s\mathbb{F}_p$, and we discuss
the cryptographic relevance of $\mathbb{D}_{sp}$, highlighting its potential
for analyzing cyclic attacks and factorization methods.

</details>


### [22] [AndroByte: LLM-Driven Privacy Analysis through Bytecode Summarization and Dynamic Dataflow Call Graph Generation](https://arxiv.org/abs/2510.15112)
*Mst Eshita Khatun,Lamine Noureddine,Zhiyong Sui,Aisha Ali-Gombe*

Main category: cs.CR

TL;DR: AndroByte是一个基于LLM的Android隐私分析工具，通过字节码摘要和AI推理动态生成数据流调用图，显著提升了隐私泄露检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统Android数据流分析方法依赖预定义的传播规则和sink列表，实现复杂且容易出错，存在taint爆炸等问题，限制了灵活性和可扩展性。

Method: 利用LLM对字节码摘要进行推理，从静态代码分析中动态生成准确且可解释的数据流调用图，不依赖预定义的传播规则或sink列表。

Result: AndroByte在动态生成数据流调用图方面达到89%的Fβ分数，在泄露检测方面优于FlowDroid和Amandroid等传统工具，并在G-Eval指标上获得高量化分数。

Conclusion: AI驱动的隐私分析方法能够有效克服传统技术的局限性，提供更灵活、准确和可解释的数据流分析能力。

Abstract: With the exponential growth in mobile applications, protecting user privacy
has become even more crucial. Android applications are often known for
collecting, storing, and sharing sensitive user information such as contacts,
location, camera, and microphone data often without the user's clear consent or
awareness raising significant privacy risks and exposure. In the context of
privacy assessment, dataflow analysis is particularly valuable for identifying
data usage and potential leaks. Traditionally, this type of analysis has relied
on formal methods, heuristics, and rule-based matching. However, these
techniques are often complex to implement and prone to errors, such as taint
explosion for large programs. Moreover, most existing Android dataflow analysis
methods depend heavily on predefined list of sinks, limiting their flexibility
and scalability. To address the limitations of these existing techniques, we
propose AndroByte, an AI-driven privacy analysis tool that leverages LLM
reasoning on bytecode summarization to dynamically generate accurate and
explainable dataflow call graphs from static code analysis. AndroByte achieves
a significant F\b{eta}-Score of 89% in generating dynamic dataflow call graphs
on the fly, outperforming the effectiveness of traditional tools like FlowDroid
and Amandroid in leak detection without relying on predefined propagation rules
or sink lists. Moreover, AndroByte's iterative bytecode summarization provides
comprehensive and explainable insights into dataflow and leak detection,
achieving high, quantifiable scores based on the G-Eval metric.

</details>


### [23] [Intermittent File Encryption in Ransomware: Measurement, Modeling, and Detection](https://arxiv.org/abs/2510.15133)
*Ynes Ineza,Gerald Jackson,Prince Niyonkuru,Jaden Kevil,Abdul Serwadda*

Main category: cs.CR

TL;DR: 该论文系统分析了间歇性加密对文件字节级统计特征的影响，建立了检测上限模型，并验证了基于CNN的局部分析方法优于全局方法。


<details>
  <summary>Details</summary>
Motivation: 文件加密勒索软件采用间歇性加密技术（只加密部分文件）来规避传统检测方法，这给基于文件结构的检测带来了挑战，因为不同文件格式在部分加密下表现出不同特征。

Method: 1. 系统实证分析常见文件类型在间歇性加密下的字节级统计特征；2. 基于定制混合模型推导KL散度上界，建立文件类型特定的检测上限；3. 使用来自主流勒索软件变种的现实间歇性加密配置，实证评估基于CNN的检测方法。

Result: 研究发现，通过分块级CNN进行的局部分析始终优于全局分析方法，证明了其实际有效性。

Conclusion: 局部分析方法在检测间歇性加密勒索软件方面具有显著优势，为未来检测系统建立了稳健的基准。

Abstract: File encrypting ransomware increasingly employs intermittent encryption
techniques, encrypting only parts of files to evade classical detection
methods. These strategies, exemplified by ransomware families like BlackCat,
complicate file structure based detection techniques due to diverse file
formats exhibiting varying traits under partial encryption. This paper provides
a systematic empirical characterization of byte level statistics under
intermittent encryption across common file types, establishing a comprehensive
baseline of how partial encryption impacts data structure. We specialize a
classical KL divergence upper bound on a tailored mixture model of intermittent
encryption, yielding filetype specific detectability ceilings for
histogram-based detectors. Leveraging insights from this analysis, we
empirically evaluate convolutional neural network (CNN) based detection methods
using realistic intermittent encryption configurations derived from leading
ransomware variants. Our findings demonstrate that localized analysis via chunk
level CNNs consistently outperforms global analysis methods, highlighting their
practical effectiveness and establishing a robust baseline for future detection
systems.

</details>


### [24] [Beyond the Voice: Inertial Sensing of Mouth Motion for High Security Speech Verification](https://arxiv.org/abs/2510.15173)
*Ynes Ineza,Muhammad A. Ullah,Abdul Serwadda,Aurore Munyaneza*

Main category: cs.CR

TL;DR: 该论文提出了一种结合声学和下颌运动模式的第二认证因子，通过在嘴部周围放置轻量级惯性传感器来捕获独特的运动特征，增强语音认证的安全性。


<details>
  <summary>Details</summary>
Motivation: 随着高质量语音伪造技术的普及，仅依赖语音认证的安全性受到威胁，需要额外的认证因子来加强保护。

Method: 在嘴部周围部署轻量级惯性传感器，记录说话时下颌的运动模式，结合声学证据进行身份认证。

Result: 在43名参与者的实验中，系统在所有测试场景下均实现了中位数等错误率(EER)≤0.01的优异性能。

Conclusion: 下颌运动数据在不同步态、姿势和语言背景下保持稳健，可作为语音认证系统的有效第二防线。

Abstract: Voice interfaces are increasingly used in high stakes domains such as mobile
banking, smart home security, and hands free healthcare. Meanwhile, modern
generative models have made high quality voice forgeries inexpensive and easy
to create, eroding confidence in voice authentication alone. To strengthen
protection against such attacks, we present a second authentication factor that
combines acoustic evidence with the unique motion patterns of a speaker's lower
face. By placing lightweight inertial sensors around the mouth to capture mouth
opening and evolving lower facial geometry, our system records a distinct
motion signature with strong discriminative power across individuals. We built
a prototype and recruited 43 participants to evaluate the system under four
conditions seated, walking on level ground, walking on stairs, and speaking
with different language backgrounds (native vs. non native English). Across all
scenarios, our approach consistently achieved a median equal error rate (EER)
of 0.01 or lower, indicating that mouth movement data remain robust under
variations in gait, posture, and spoken language. We discuss specific use cases
where this second line of defense could provide tangible security benefits to
voice authentication systems.

</details>


### [25] [MalCVE: Malware Detection and CVE Association Using Large Language Models](https://arxiv.org/abs/2510.15567)
*Eduard Andrei Cristea,Petter Molnes,Jingyue Li*

Main category: cs.CR

TL;DR: 提出MalCVE工具，利用大语言模型检测JAR文件中的恶意软件，并通过检索增强生成技术识别恶意软件可能利用的CVE漏洞。


<details>
  <summary>Details</summary>
Motivation: 恶意软件攻击造成重大经济损失，商业检测工具昂贵且缺乏将恶意软件与具体漏洞关联的工具。理解恶意软件与目标漏洞的关联对威胁分析和主动防御至关重要。

Method: 开发MalCVE工具，集成二进制代码反编译、反混淆、LLM代码摘要、语义相似性搜索和LLM CVE分类。

Result: 在3,839个JAR可执行文件的基准数据集上，恶意软件检测平均准确率达97%，成本远低于商业方案。CVE关联召回率@10达65%，与源代码分析研究相当。

Conclusion: MalCVE是首个将CVE与二进制恶意软件关联的工具，证明LLM和RAG技术在恶意软件分析和漏洞关联方面的有效性。

Abstract: Malicious software attacks are having an increasingly significant economic
impact. Commercial malware detection software can be costly, and tools that
attribute malware to the specific software vulnerabilities it exploits are
largely lacking. Understanding the connection between malware and the
vulnerabilities it targets is crucial for analyzing past threats and
proactively defending against current ones. In this study, we propose an
approach that leverages large language models (LLMs) to detect binary malware,
specifically within JAR files, and utilizes the capabilities of LLMs combined
with retrieval-augmented generation (RAG) to identify Common Vulnerabilities
and Exposures (CVEs) that malware may exploit. We developed a proof-of-concept
tool called MalCVE, which integrates binary code decompilation, deobfuscation,
LLM-based code summarization, semantic similarity search, and CVE
classification using LLMs. We evaluated MalCVE using a benchmark dataset of
3,839 JAR executables. MalCVE achieved a mean malware detection accuracy of
97%, at a fraction of the cost of commercial solutions. It is also the first
tool to associate CVEs with binary malware, achieving a recall@10 of 65%, which
is comparable to studies that perform similar analyses on source code.

</details>


### [26] [MAGPIE: A benchmark for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2510.15186)
*Gurusha Juneja,Jayanth Naga Sai Pasupulati,Alon Albalak,Wenyue Hua,William Yang Wang*

Main category: cs.CR

TL;DR: 提出了MAGPIE基准测试，用于评估多智能体协作场景中的隐私保护能力，发现当前最先进的LLM智能体存在显著的隐私泄露问题。


<details>
  <summary>Details</summary>
Motivation: 现有隐私基准测试仅关注简单的单轮交互，无法评估复杂协作场景中隐私保护与任务效能的平衡问题。

Method: 开发了包含200个高风险任务的MAGPIE基准测试，将私有信息设计为任务解决的必要元素，强制智能体在有效协作与信息控制之间取得平衡。

Result: GPT-5和Gemini 2.5-Pro等先进智能体存在严重隐私泄露（Gemini 2.5-Pro泄露50.7%，GPT-5泄露35.1%），且难以达成共识或完成任务，经常出现操纵和权力寻求等不良行为。

Conclusion: 当前LLM智能体缺乏稳健的隐私理解能力，在复杂环境中无法同时实现隐私保护和有效协作。

Abstract: A core challenge for autonomous LLM agents in collaborative settings is
balancing robust privacy understanding and preservation alongside task
efficacy. Existing privacy benchmarks only focus on simplistic, single-turn
interactions where private information can be trivially omitted without
affecting task outcomes. In this paper, we introduce MAGPIE (Multi-AGent
contextual PrIvacy Evaluation), a novel benchmark of 200 high-stakes tasks
designed to evaluate privacy understanding and preservation in multi-agent
collaborative, non-adversarial scenarios. MAGPIE integrates private information
as essential for task resolution, forcing agents to balance effective
collaboration with strategic information control. Our evaluation reveals that
state-of-the-art agents, including GPT-5 and Gemini 2.5-Pro, exhibit
significant privacy leakage, with Gemini 2.5-Pro leaking up to 50.7% and GPT-5
up to 35.1% of the sensitive information even when explicitly instructed not
to. Moreover, these agents struggle to achieve consensus or task completion and
often resort to undesirable behaviors such as manipulation and power-seeking
(e.g., Gemini 2.5-Pro demonstrating manipulation in 38.2% of the cases). These
findings underscore that current LLM agents lack robust privacy understanding
and are not yet adequately aligned to simultaneously preserve privacy and
maintain effective collaboration in complex environments.

</details>


### [27] [OCR-APT: Reconstructing APT Stories from Audit Logs using Subgraph Anomaly Detection and LLMs](https://arxiv.org/abs/2510.15188)
*Ahmed Aly,Essam Mansour,Amr Youssef*

Main category: cs.CR

TL;DR: OCR-APT是一个用于APT检测和攻击故事重建的系统，结合图神经网络进行子图异常检测，并使用大语言模型生成人类可读的攻击报告。


<details>
  <summary>Details</summary>
Motivation: 现有的APT检测系统存在高误报率和粗粒度警报的问题，依赖节点属性导致虚假相关性，安全分析师需要能够生成准确、类似人类叙述的完整攻击故事的系统。

Method: 使用图神经网络进行子图异常检测，学习节点周围的行为模式而非脆弱的属性；然后使用大语言模型迭代处理检测到的子图，重建多阶段攻击故事，并在每个阶段进行验证。

Result: 在DARPA TC3、OpTC和NODLINK数据集上的评估显示，OCR-APT在检测准确性和警报可解释性方面优于最先进的系统，并能重建全面捕捉攻击故事的人类可读报告。

Conclusion: OCR-APT通过结合图神经网络和大语言模型，实现了更稳健的APT检测和可解释的攻击故事重建，解决了现有系统的高误报率和粗粒度警报问题。

Abstract: Advanced Persistent Threats (APTs) are stealthy cyberattacks that often evade
detection in system-level audit logs. Provenance graphs model these logs as
connected entities and events, revealing relationships that are missed by
linear log representations. Existing systems apply anomaly detection to these
graphs but often suffer from high false positive rates and coarse-grained
alerts. Their reliance on node attributes like file paths or IPs leads to
spurious correlations, reducing detection robustness and reliability. To fully
understand an attack's progression and impact, security analysts need systems
that can generate accurate, human-like narratives of the entire attack. To
address these challenges, we introduce OCR-APT, a system for APT detection and
reconstruction of human-like attack stories. OCR-APT uses Graph Neural Networks
(GNNs) for subgraph anomaly detection, learning behavior patterns around nodes
rather than fragile attributes such as file paths or IPs. This approach leads
to a more robust anomaly detection. It then iterates over detected subgraphs
using Large Language Models (LLMs) to reconstruct multi-stage attack stories.
Each stage is validated before proceeding, reducing hallucinations and ensuring
an interpretable final report. Our evaluations on the DARPA TC3, OpTC, and
NODLINK datasets show that OCR-APT outperforms state-of-the-art systems in both
detection accuracy and alert interpretability. Moreover, OCR-APT reconstructs
human-like reports that comprehensively capture the attack story.

</details>


### [28] [DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing](https://arxiv.org/abs/2510.15303)
*Ting Qiao,Xing Liu,Wenke Huang,Jianbin Li,Zhaoxin Fan,Yiming Li*

Main category: cs.CR

TL;DR: 提出了首个基于双空间平滑的认证数据集所有权验证方法DSSmoothing，通过嵌入空间和排列空间的双重扰动来提供可证明的鲁棒性保证。


<details>
  <summary>Details</summary>
Motivation: 大规模网络数据集推动了预训练语言模型的发展，但未经授权的数据使用引发了严重的版权问题。现有数据集所有权验证方法假设水印在推理过程中保持稳定，但这一假设在自然噪声和对抗性扰动下往往失效。

Method: DSSmoothing采用双阶段方法：第一阶段在嵌入空间引入连续扰动捕获语义鲁棒性，在排列空间应用受控标记重排序捕获序列鲁棒性，协作嵌入触发器生成规范约束的鲁棒水印数据集；第二阶段在验证时对双空间应用随机平滑，计算可疑模型的水印鲁棒性并与良性模型的主概率值进行统计比较。

Result: 在多个代表性网络数据集上的广泛实验表明，DSSmoothing实现了稳定可靠的验证性能，并对潜在的适应性攻击表现出鲁棒性。

Conclusion: DSSmoothing通过确保在有界双空间扰动下水印鲁棒性始终超过主概率值，为数据集所有权验证提供了可证明的鲁棒性保证。

Abstract: Large web-scale datasets have driven the rapid advancement of pre-trained
language models (PLMs), but unauthorized data usage has raised serious
copyright concerns. Existing dataset ownership verification (DOV) methods
typically assume that watermarks remain stable during inference; however, this
assumption often fails under natural noise and adversary-crafted perturbations.
We propose the first certified dataset ownership verification method for PLMs
based on dual-space smoothing (i.e., DSSmoothing). To address the challenges of
text discreteness and semantic sensitivity, DSSmoothing introduces continuous
perturbations in the embedding space to capture semantic robustness and applies
controlled token reordering in the permutation space to capture sequential
robustness. DSSmoothing consists of two stages: in the first stage, triggers
are collaboratively embedded in both spaces to generate norm-constrained and
robust watermarked datasets; in the second stage, randomized smoothing is
applied in both spaces during verification to compute the watermark robustness
(WR) of suspicious models and statistically compare it with the principal
probability (PP) values of a set of benign models. Theoretically, DSSmoothing
provides provable robustness guarantees for dataset ownership verification by
ensuring that WR consistently exceeds PP under bounded dual-space
perturbations. Extensive experiments on multiple representative web datasets
demonstrate that DSSmoothing achieves stable and reliable verification
performance and exhibits robustness against potential adaptive attacks.

</details>


### [29] [Flexible Threshold Multi-client Functional Encryption for Inner Product in Federated Learning](https://arxiv.org/abs/2510.15367)
*Ruyuan Zhang,Jinguang Han,Liqun Chen*

Main category: cs.CR

TL;DR: 提出了一种灵活阈值多客户端功能加密方案（FTMCFE-IP），支持客户端灵活选择阈值和客户端退出，解决了现有方案在实用联邦学习中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于多客户端功能加密（MCFE）的隐私保护机器学习方案无法支持客户端退出或灵活阈值选择，而这些特性对实用联邦学习至关重要。

Method: 设计了FTMCFE-IP方案，客户端在加密阶段可灵活选择阈值而无需重新初始化系统，支持客户端独立生成密文且无需交互，解密时只需在线客户端数量满足阈值即可正确执行。

Result: 方案正式定义了安全模型并给出了具体构造，安全性得到形式化证明，同时通过实现和评估验证了方案的可行性。

Conclusion: FTMCFE-IP方案有效解决了现有MCFE方案在联邦学习中的局限性，支持灵活阈值和客户端退出，为实用联邦学习提供了更好的隐私保护解决方案。

Abstract: Federated learning (FL) is a distributed machine learning paradigm that
enables multiple clients to collaboratively train a shared model without
disclosing their local data. To address privacy issues of gradient, several
privacy-preserving machine-learning schemes based on multi-client functional
encryption (MCFE) have been proposed. However, existing MCFE-based schemes
cannot support client dropout or flexible threshold selection, which are
essential for practical FL. In this paper, we design a flexible threshold
multi-client functional encryption for inner product (FTMCFE-IP) scheme, where
multiple clients generate ciphertexts independently without any interaction. In
the encryption phase, clients are able to choose a threshold flexibly without
reinitializing the system. The decryption can be performed correctly when the
number of online clients satisfies the threshold. An authorized user are
allowed to compute the inner product of the vectors associated with his/her
functional key and the ciphertext, respectively, but cannot learning anything
else. Especially, the presented scheme supports clients drop out. Furthermore,
we provide the definition and security model of our FTMCFE-IP scheme,and
propose a concrete construction. The security of the designed scheme is
formally proven. Finally, we implement and evaluate our FTMCFE-IP scheme.

</details>


### [30] [Bilinear Compressive Security](https://arxiv.org/abs/2510.15380)
*Axel Flinth,Hubert Orlicki,Semira Einsele,Gerhard Wunder*

Main category: cs.CR

TL;DR: 本文提出了一种新的双线性压缩安全(BCS)方法，通过在压缩感知加密中加入随机滤波器卷积，显著增强了安全性，使得在已知明文攻击下恢复密钥需要Ω(max(n,(n/s)²))个消息样本。


<details>
  <summary>Details</summary>
Motivation: 传统压缩感知安全方案中，测量矩阵作为加密密钥容易受到已知明文攻击，仅需n个观测就能恢复n列的密钥。需要一种更安全的加密方案。

Method: 提出BCS方法：在消息x的线性编码(Qx)基础上，再与随机生成的稀疏滤波器h进行卷积，接收方通过盲解卷积从y=h*Qx中恢复x，无需知道h。

Result: 在滤波器h满足弱对称条件下，恢复密钥Q需要Ω(max(n,(n/s)²))个消息样本，当s=1时完全无法恢复密钥，安全性显著优于标准压缩感知。

Conclusion: BCS方案即使在有利于攻击者的假设下，也能提供比传统压缩感知更强的安全性，特别适合物联网等资源受限环境。

Abstract: Beyond its widespread application in signal and image processing,
\emph{compressed sensing} principles have been greatly applied to secure
information transmission (often termed 'compressive security'). In this
scenario, the measurement matrix $Q$ acts as a one time pad encryption key (in
complex number domain) which can achieve perfect information-theoretic security
together with other benefits such as reduced complexity and energy efficiency
particularly useful in IoT. However, unless the matrix is changed for every
message it is vulnerable towards known plain text attacks: only $n$
observations suffices to recover a key $Q$ with $n$ columns. In this paper, we
invent and analyze a new method (termed 'Bilinear Compressive Security (BCS)')
addressing these shortcomings: In addition to the linear encoding of the
message $x$ with a matrix $Q$, the sender convolves the resulting vector with a
randomly generated filter $h$. Assuming that $h$ and $x$ are sparse, the
receiver can then recover $x$ without knowledge of $h$ from $y=h*Qx$ through
blind deconvolution. We study a rather idealized known plaintext attack for
recovering $Q$ from repeated observations of $y$'s for different, known $x_k$,
with varying and unknown $h$ ,giving Eve a number of advantages not present in
practice. Our main result for BCS states that under a weak symmetry condition
on the filter $h$, recovering $Q$ will require extensive sampling from
transmissions of $\Omega\left(\max\left(n,(n/s)^2\right)\right)$ messages $x_k$
if they are $s$-sparse. Remarkably, with $s=1$ it is impossible to recover the
key. In this way, the scheme is much safer than standard compressed sensing
even though our assumptions are much in favor towards a potential attacker.

</details>


### [31] [FHE-SQL: Fully Homomorphic Encrypted SQL Database](https://arxiv.org/abs/2510.15413)
*Po-Yu Tseng,Po-Chu Hsu,Shih-Wei Liao*

Main category: cs.CR

TL;DR: FHE-SQL是一个基于全同态加密的隐私保护数据库系统，支持在加密数据上执行SQL查询，无需信任服务器即可保护查询内容和数据隐私。


<details>
  <summary>Details</summary>
Motivation: 现有隐私保护数据库系统存在安全漏洞：基于属性保留加密的系统容易受到频率、顺序和等值模式推断攻击；基于可信硬件的系统依赖硬件安全模块，存在信任和侧信道限制；高性能FHE引擎仅支持特定工作负载。

Method: 采用全同态加密在密文上执行计算，消除信息泄露通道；使用间接架构分离RocksDB中的元数据和blob存储中的大密文；支持通过同态布尔掩码进行无感知选择、多级缓存和垃圾回收。

Result: 系统在通用组合框架下证明安全，支持通用SQL查询语义，具有模式感知和类型安全的定义，适用于关系数据管理。

Conclusion: FHE-SQL提供了端到端的密码学保护，无需可信执行环境，同时支持通用SQL查询功能，在安全性和功能性之间取得了良好平衡。

Abstract: FHE-SQL is a privacy-preserving database system that enables secure query
processing on encrypted data using Fully Homomorphic Encryption (FHE),
providing privacy guaranties where an untrusted server can execute encrypted
queries without learning either the query contents or the underlying data.
Unlike property-preserving encryption-based systems such as CryptDB, which rely
on deterministic or order-preserving encryption and are vulnerable to
frequency, order, and equality-pattern inference attacks, FHE-SQL performs
computations entirely under encryption, eliminating these leakage channels.
Compared to trusted-hardware approaches such as TrustedDB, which depend on a
hardware security module and thus inherit its trust and side-channel
limitations, our design achieves end-to-end cryptographic protection without
requiring trusted execution environments. In contrast to high-performance
FHE-based engines-Hermes, which target specialized workloads such as vector
search, FHE-SQL supports general SQL query semantics with schema-aware,
type-safe definitions suitable for relational data management. FHE-SQL
mitigates the high cost of ciphertext space by using an indirection
architecture that separates metadata in RocksDB from large ciphertexts in blob
storage. It supports oblivious selection via homomorphic boolean masks,
multi-tier caching, and garbage collection, with security proven under the
Universal Composability framework.

</details>


### [32] [SoK: Taxonomy and Evaluation of Prompt Security in Large Language Models](https://arxiv.org/abs/2510.15476)
*Hanbin Hong,Shuya Feng,Nima Naderloui,Shenao Yan,Jingyu Zhang,Biying Liu,Ali Arastehfard,Heqing Huang,Yuan Hong*

Main category: cs.CR

TL;DR: 这篇论文提出了一个关于LLM提示安全的系统化知识框架，包括多级分类法、标准化威胁模型、评估工具包、大型标注数据集和综合评估结果。


<details>
  <summary>Details</summary>
Motivation: LLM在现实应用中广泛部署，但存在越狱提示的安全风险。当前研究碎片化，定义、威胁模型和评估标准不统一，阻碍了系统性进展和公平比较。

Method: 1) 提出多级分类法组织攻击、防御和漏洞；2) 将威胁模型形式化为机器可读配置文件；3) 开发开源评估工具包；4) 发布JAILBREAKDB标注数据集；5) 进行综合评估和排行榜。

Result: 构建了统一的研究框架，提供了可复现的评估方法，发布了最大的越狱提示标注数据集，并建立了最先进方法的综合评估结果。

Conclusion: 该工作统一了碎片化研究，为未来研究提供了严格基础，支持开发适用于高风险部署的稳健可信LLM。

Abstract: Large Language Models (LLMs) have rapidly become integral to real-world
applications, powering services across diverse sectors. However, their
widespread deployment has exposed critical security risks, particularly through
jailbreak prompts that can bypass model alignment and induce harmful outputs.
Despite intense research into both attack and defense techniques, the field
remains fragmented: definitions, threat models, and evaluation criteria vary
widely, impeding systematic progress and fair comparison. In this
Systematization of Knowledge (SoK), we address these challenges by (1)
proposing a holistic, multi-level taxonomy that organizes attacks, defenses,
and vulnerabilities in LLM prompt security; (2) formalizing threat models and
cost assumptions into machine-readable profiles for reproducible evaluation;
(3) introducing an open-source evaluation toolkit for standardized, auditable
comparison of attacks and defenses; (4) releasing JAILBREAKDB, the largest
annotated dataset of jailbreak and benign prompts to date; and (5) presenting a
comprehensive evaluation and leaderboard of state-of-the-art methods. Our work
unifies fragmented research, provides rigorous foundations for future studies,
and supports the development of robust, trustworthy LLMs suitable for
high-stakes deployment.

</details>


### [33] [HarmRLVR: Weaponizing Verifiable Rewards for Harmful LLM Alignment](https://arxiv.org/abs/2510.15499)
*Yuexiao Liu,Lijun Li,Xingjun Wang,Jing Shao*

Main category: cs.CR

TL;DR: 本文首次系统研究RLVR的对齐可逆性风险，发现仅用64个有害提示就能快速逆转安全对齐，使模型遵从有害指令。


<details>
  <summary>Details</summary>
Motivation: 虽然RLVR在推理和代码生成任务中表现优异，但其潜在安全风险尚未充分探索，特别是对齐可逆性风险。

Method: 使用GRPO算法，仅需64个有害提示（无需响应）进行RLVR攻击，在Llama、Qwen和DeepSeek五个模型上进行实验。

Result: RLVR攻击将平均有害性得分提升至4.94，攻击成功率96.01%，显著优于有害微调，同时保持通用能力。

Conclusion: RLVR可被高效利用进行有害对齐，对开源模型安全构成严重威胁。

Abstract: Recent advancements in Reinforcement Learning with Verifiable Rewards (RLVR)
have gained significant attention due to their objective and verifiable reward
signals, demonstrating strong performance in reasoning and code generation
tasks. However, the potential safety risks associated with RLVR remain
underexplored. This paper presents HarmRLVR, the first systematic investigation
into the alignment reversibility risk of RLVR. We show that safety alignment
can be rapidly reversed using GRPO with merely 64 harmful prompts without
responses, causing models to readily comply with harmful instructions. Across
five models from Llama, Qwen, and DeepSeek, we empirically demonstrate that
RLVR-based attacks elevate the average harmfulness score to 4.94 with an attack
success rate of 96.01\%, significantly outperforming harmful fine-tuning while
preserving general capabilities. Our findings reveal that RLVR can be
efficiently exploited for harmful alignment, posing serious threats to
open-source model safety. Please see our code at
https://github.com/lyxx2535/HarmRLVR.

</details>


### [34] [High Memory Masked Convolutional Codes for PQC](https://arxiv.org/abs/2510.15515)
*Meir Ariel*

Main category: cs.CR

TL;DR: 提出了一种基于高内存掩码卷积码的后量子密码系统，相比传统基于块码的方案具有更强的安全性和灵活性，支持任意明文长度，解密时间线性增长，安全性比经典McEliece系统提高2100倍以上。


<details>
  <summary>Details</summary>
Motivation: 传统基于块码的密码系统存在固定维度、有限纠错能力和可扩展性差的问题，需要开发更安全、灵活的后量子密码方案。

Method: 使用高内存掩码卷积码，通过多项式除法注入额外噪声，采用半可逆变换生成密集的类随机生成矩阵，接收端使用并行Viterbi解码器进行解密。

Result: 实现了超过经典McEliece系统2100倍以上的密码分析安全裕度，支持任意明文长度，具有线性时间解密和均匀的每比特计算成本。

Conclusion: 该方案是实用量子抵抗公钥密码系统的强有力候选方案，具有高效的硬件和软件实现能力。

Abstract: This paper presents a novel post-quantum cryptosystem based on high-memory
masked convolutional codes. Unlike conventional code-based schemes that rely on
block codes with fixed dimensions and limited error-correction capability, our
construction offers both stronger cryptographic security and greater
flexibility. It supports arbitrary plaintext lengths with linear-time
decryption and uniform per-bit computational cost, enabling seamless
scalability to long messages. Security is reinforced through a higher-rate
injection of random errors than in block-code approaches, along with additional
noise introduced via polynomial division, which substantially obfuscates the
underlying code structure. Semi-invertible transformations generate dense,
random-like generator matrices that conceal algebraic properties and resist
known structural attacks. Consequently, the scheme achieves cryptanalytic
security margins exceeding those of the classic McEliece system by factors
greater than 2100. Finally, decryption at the recipient employs an array of
parallel Viterbi decoders, enabling efficient hardware and software
implementation and positioning the scheme as a strong candidate for deployment
in practical quantum-resistant public-key cryptosystems.

</details>


### [35] [Ambusher: Exploring the Security of Distributed SDN Controllers Through Protocol State Fuzzing](https://arxiv.org/abs/2510.15798)
*Jinwoo Kim,Minjae Seo,Eduard Marin,Seungsoo Lee,Jaehyun Nam,Seungwon Shin*

Main category: cs.CR

TL;DR: Ambusher是一个用于发现分布式SDN控制器协议漏洞的测试工具，通过协议状态模糊测试方法，在真实SD-WAN部署中发现了6个潜在漏洞。


<details>
  <summary>Details</summary>
Motivation: 分布式SDN控制器在广域网中广泛应用，但其架构引入了新的攻击面，目前对这些安全威胁的关注不足。

Method: 使用协议状态模糊测试，通过推断状态机系统性地发现攻击场景。提出新颖方法提取单个相对简单的状态机，实现高效的状态模糊测试。

Result: 在跨越两个校园网络和一个企业网络的真实SD-WAN部署中评估，发现了广泛使用的分布式控制器平台中的6个潜在漏洞。

Conclusion: Ambusher工具能够有效发现分布式SDN控制器中的安全漏洞，证明了其在实际部署中的实用价值。

Abstract: Distributed SDN (Software-Defined Networking) controllers have rapidly become
an integral element of Wide Area Networks (WAN), particularly within SD-WAN,
providing scalability and fault-tolerance for expansive network
infrastructures. However, the architecture of these controllers introduces new
potential attack surfaces that have thus far received inadequate attention. In
response to these concerns, we introduce Ambusher, a testing tool designed to
discover vulnerabilities within protocols used in distributed SDN controllers.
Ambusher achieves this by leveraging protocol state fuzzing, which
systematically finds attack scenarios based on an inferred state machine. Since
learning states from a cluster is complicated, Ambusher proposes a novel
methodology that extracts a single and relatively simple state machine,
achieving efficient state-based fuzzing. Our evaluation of Ambusher, conducted
on a real SD-WAN deployment spanning two campus networks and one enterprise
network, illustrates its ability to uncover 6 potential vulnerabilities in the
widely used distributed controller platform.

</details>


### [36] [Towards Proactive Defense Against Cyber Cognitive Attacks](https://arxiv.org/abs/2510.15801)
*Bonnie Rushing,Mac-Rufus Umeokolo,Shouhuai Xu*

Main category: cs.CR

TL;DR: 提出预测性方法，用于预测颠覆性创新在认知攻击中的恶意使用，识别对抗策略趋势并提出主动防御策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要分类当前认知攻击战术，缺乏预测未来颠覆性创新及其在认知攻击中恶意使用的机制。

Method: 引入新颖的预测方法学，用于预测颠覆性创新的出现及其在认知攻击中的恶意使用。

Result: 识别了对抗策略的趋势，并提出了主动防御策略。

Conclusion: 该研究填补了现有研究的空白，为预测和防御基于颠覆性创新的认知攻击提供了有效方法。

Abstract: Cyber cognitive attacks leverage disruptive innovations (DIs) to exploit
psychological biases and manipulate decision-making processes. Emerging
technologies, such as AI-driven disinformation and synthetic media, have
accelerated the scale and sophistication of these threats. Prior studies
primarily categorize current cognitive attack tactics, lacking predictive
mechanisms to anticipate future DIs and their malicious use in cognitive
attacks. This paper addresses these gaps by introducing a novel predictive
methodology for forecasting the emergence of DIs and their malicious uses in
cognitive attacks. We identify trends in adversarial tactics and propose
proactive defense strategies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [37] [OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data](https://arxiv.org/abs/2510.15096)
*Alana Renda,Jillian Ross,Michael Cafarella,Jacob Andreas*

Main category: cs.AI

TL;DR: OpenEstimate是一个用于评估语言模型在不确定性下进行数值估计的多领域基准测试，发现前沿语言模型的概率先验通常不准确且过于自信。


<details>
  <summary>Details</summary>
Motivation: 现实世界中语言模型需要在信息不完整的情况下进行不确定性推理，但现有评估主要关注有明确答案的问题，缺乏对不确定性推理能力的系统评估。

Method: 开发了OpenEstimate基准测试，通过数值估计任务评估语言模型合成背景信息并表达概率先验的能力，评估其准确性和校准度。

Result: 六个前沿语言模型的概率先验通常不准确且过于自信，性能在不同不确定性启发方式下略有改善，但在采样策略、推理努力或提示设计变化下基本不受影响。

Conclusion: OpenEstimate为前沿语言模型提供了一个具有挑战性的评估平台，并为开发更好的概率估计和不确定性推理模型奠定了基础。

Abstract: Real-world settings where language models (LMs) are deployed -- in domains
spanning healthcare, finance, and other forms of knowledge work -- require
models to grapple with incomplete information and reason under uncertainty. Yet
most LM evaluations focus on problems with well-defined answers and success
criteria. This gap exists in part because natural problems involving
uncertainty are difficult to construct: given that LMs have access to most of
the same knowledge as humans, it is non-trivial to design questions for which
LMs will struggle to produce correct answers, but which humans can answer
reliably. As a result, LM performance on reasoning under uncertainty remains
poorly characterized. To address this gap, we introduce OpenEstimate, an
extensible, multi-domain benchmark for evaluating LMs on numerical estimation
tasks that require models to synthesize significant amounts of background
information and express predictions as probabilistic priors. We assess these
priors for accuracy and calibration, quantifying their usefulness relative to
samples from the true distribution of interest. Across six frontier LMs, we
find that LM-elicited priors are often inaccurate and overconfident.
Performance improves modestly depending on how uncertainty is elicited from the
model, but is largely unaffected by changes in sampling strategy, reasoning
effort, or prompt design. The OpenEstimate benchmark thus offers a challenging
evaluation for frontier LMs and a platform for developing models that are
better at probabilistic estimation and reasoning under uncertainty.

</details>


### [38] [Procedural Game Level Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.15120)
*Miraç Buğra Özkan*

Main category: cs.AI

TL;DR: 提出了一种使用深度强化学习在Unity 3D环境中进行程序化关卡设计的新方法，包含两个智能体：蜂鸟（求解器）和浮岛（生成器），通过PPO算法训练实现自主关卡生成和解决。


<details>
  <summary>Details</summary>
Motivation: 程序化内容生成在游戏开发中越来越受欢迎，可以减少手动工作量，创建动态、可重玩和可扩展的环境。本研究探索使用深度强化学习实现智能关卡设计的潜力。

Method: 使用Unity ML-Agents工具包中的PPO算法训练两个智能体：蜂鸟智能体学习导航、定位和收集花朵；浮岛智能体学习基于障碍物位置、蜂鸟初始状态和先前表现反馈来生成花朵布局。

Result: 该方法不仅产生了有效且高效的智能体行为，还在各种环境配置中展现出涌现行为和鲁棒泛化能力，为基于机器学习的自主游戏关卡设计开辟了新机会。

Conclusion: 这项工作凸显了深度强化学习在使智能体能够在虚拟环境中生成和解决内容方面的潜力，推动了AI在创意游戏开发过程中的贡献边界。

Abstract: Procedural content generation (PCG) has become an increasingly popular
technique in game development, allowing developers to generate dynamic,
replayable, and scalable environments with reduced manual effort. In this
study, a novel method for procedural level design using Deep Reinforcement
Learning (DRL) within a Unity-based 3D environment is proposed. The system
comprises two agents: a hummingbird agent, acting as a solver, and a floating
island agent, responsible for generating and placing collectible objects
(flowers) on the terrain in a realistic and context-aware manner. The
hummingbird is trained using the Proximal Policy Optimization (PPO) algorithm
from the Unity ML-Agents toolkit. It learns to navigate through the terrain
efficiently, locate flowers, and collect them while adapting to the
ever-changing procedural layout of the island. The island agent is also trained
using the Proximal Policy Optimization (PPO) algorithm. It learns to generate
flower layouts based on observed obstacle positions, the hummingbird's initial
state, and performance feedback from previous episodes. The interaction between
these agents leads to emergent behavior and robust generalization across
various environmental configurations. The results demonstrate that the approach
not only produces effective and efficient agent behavior but also opens up new
opportunities for autonomous game level design driven by machine learning. This
work highlights the potential of DRL in enabling intelligent agents to both
generate and solve content in virtual environments, pushing the boundaries of
what AI can contribute to creative game development processes.

</details>


### [39] [Towards Error Centric Intelligence I, Beyond Observational Learning](https://arxiv.org/abs/2510.15128)
*Marcus A. Thomas*

Main category: cs.AI

TL;DR: 本文认为AGI进展受理论限制而非数据或规模限制，挑战柏拉图表示假说，提出因果力学作为机制优先的方法，强调假设空间变化作为首要操作，通过结构原则使错误发现和修正可处理。


<details>
  <summary>Details</summary>
Motivation: 当前AGI发展面临理论瓶颈，观测等价世界在干预下可能发散，仅靠观测充分性无法保证干预能力，需要从观测学习转向错误中心范式。

Method: 提出因果力学方法，将假设空间变化作为首要操作，使用概率结构而非预设，引入局部性和自治原则、独立因果机制、组合自治原则等结构原则。

Result: 建立了使错误发现和修正可处理的框架，包括将不可达错误转化为可达错误的机制，以及模块化干预、可分离性和类比保持的诊断工具。

Conclusion: AGI发展需要理论突破，因果力学为构建能够发现和修正错误的系统提供了支架，强调假设空间演化和错误中心方法的重要性。

Abstract: We argue that progress toward AGI is theory limited rather than data or scale
limited. Building on the critical rationalism of Popper and Deutsch, we
challenge the Platonic Representation Hypothesis. Observationally equivalent
worlds can diverge under interventions, so observational adequacy alone cannot
guarantee interventional competence. We begin by laying foundations,
definitions of knowledge, learning, intelligence, counterfactual competence and
AGI, and then analyze the limits of observational learning that motivate an
error centric shift. We recast the problem as three questions about how
explicit and implicit errors evolve under an agent's actions, which errors are
unreachable within a fixed hypothesis space, and how conjecture and criticism
expand that space. From these questions we propose Causal Mechanics, a
mechanisms first program in which hypothesis space change is a first class
operation and probabilistic structure is used when useful rather than presumed.
We advance structural principles that make error discovery and correction
tractable, including a differential Locality and Autonomy Principle for modular
interventions, a gauge invariant form of Independent Causal Mechanisms for
separability, and the Compositional Autonomy Principle for analogy
preservation, together with actionable diagnostics. The aim is a scaffold for
systems that can convert unreachable errors into reachable ones and correct
them.

</details>


### [40] [HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks](https://arxiv.org/abs/2510.15144)
*Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson*

Main category: cs.AI

TL;DR: HugAgent是一个用于评估AI模型如何适应个体推理风格的基准测试，包含合成和人类双轨设计，旨在推动机器推理与人类个体思维的对接。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型主要反映群体共识，缺乏对个体推理风格和信念轨迹的捕捉，需要开发能更好模拟人类个体推理的AI系统。

Method: 采用双轨设计：合成轨道用于大规模系统压力测试，人类轨道用于生态有效的出声推理数据收集，评估模型对特定个体推理模式的适应能力。

Result: 实验显示最先进的LLMs在个体适应方面仍存在持续差距，HugAgent成为首个可扩展的机器推理与人类个体思维对齐基准。

Conclusion: HugAgent为评估机器推理与人类个体思维的对齐提供了首个可扩展基准，推动了更人性化AI推理的发展。

Abstract: Simulating human reasoning in open-ended tasks has been a long-standing
aspiration in AI and cognitive science. While large language models now
approximate human responses at scale, they remain tuned to population-level
consensus, often erasing the individuality of reasoning styles and belief
trajectories. To advance the vision of more human-like reasoning in machines,
we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for
average-to-individual reasoning adaptation. The task is to predict how a
specific person would reason and update their beliefs in novel scenarios, given
partial evidence of their past views. HugAgent adopts a dual-track design: a
synthetic track for scale and systematic stress tests, and a human track for
ecologically valid, "out-loud" reasoning data. This design enables scalable,
reproducible evaluation of intra-agent fidelity: whether models can capture not
just what people believe, but how their reasoning evolves. Experiments with
state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent
as the first extensible benchmark for aligning machine reasoning with the
individuality of human thought. Our benchmark and chatbot are open-sourced as
HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking
(https://anonymous.4open.science/r/trace-your-thinking).

</details>


### [41] [WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing](https://arxiv.org/abs/2510.15221)
*Xiao Sun*

Main category: cs.AI

TL;DR: 提出了一个包含733,651个面部表情记录的大规模纵向工作场所情绪数据集，覆盖38名员工30.5个月的数据，包含7种情绪概率和32个扩展情绪指标，验证了数据质量并建立了情绪分类和预测的基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决真实工作场所环境中情绪识别面临的挑战，特别是缺乏大规模、长期的自然环境数据集的问题。

Method: 收集38名员工在30.5个月内的面部表情数据，使用深度学习进行情绪识别，计算32个扩展情绪指标，并通过技术验证和基线实验评估数据质量。

Result: 数据集成功复制已知心理模式（周末效应+192%效价改善），员工离职预测AUC=1.0，基线模型情绪分类准确率91.2%，效价预测R2=0.84。

Conclusion: 这是目前公开可用的最大、最长的纵向工作场所情绪数据集，为情绪识别、情感动态建模、情绪传染等研究提供了重要资源。

Abstract: Automated emotion recognition in real-world workplace settings remains a
challenging problem in affective computing due to the scarcity of large-scale,
longitudinal datasets collected in naturalistic environments. We present a
novel dataset comprising 733,651 facial expression records from 38 employees
collected over 30.5 months (November 2021 to May 2024) in an authentic office
environment. Each record contains seven emotion probabilities (neutral, happy,
sad, surprised, fear, disgusted, angry) derived from deep learning-based facial
expression recognition, along with comprehensive metadata including job roles,
employment outcomes, and personality traits. The dataset uniquely spans the
COVID-19 pandemic period, capturing emotional responses to major societal
events including the Shanghai lockdown and policy changes. We provide 32
extended emotional metrics computed using established affective science
methods, including valence, arousal, volatility, predictability, inertia, and
emotional contagion strength. Technical validation demonstrates high data
quality through successful replication of known psychological patterns (weekend
effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and
perfect predictive validity for employee turnover (AUC=1.0). Baseline
experiments using Random Forest and LSTM models achieve 91.2% accuracy for
emotion classification and R2 = 0.84 for valence prediction. This is the
largest and longest longitudinal workplace emotion dataset publicly available,
enabling research in emotion recognition, affective dynamics modeling,
emotional contagion, turnover prediction, and emotion-aware system design.

</details>


### [42] [From Checklists to Clusters: A Homeostatic Account of AGI Evaluation](https://arxiv.org/abs/2510.15236)
*Brett Reynolds*

Main category: cs.AI

TL;DR: 本文提出AGI评估应使用基于因果中心性的加权评分和集群稳定性指数，而非传统的对称权重和快照测试，以更好地衡量通用智能的持久性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估使用对称权重和快照分数，无法区分持久能力与脆弱表现，且忽视了不同认知领域的重要性差异。

Method: 提出中心性优先评分（导入CHC理论权重）和集群稳定性指数系列，分别评估领域重要性和能力在不同条件下的持久性。

Result: 这些扩展方法能够保持多领域评估广度，同时减少脆弱性和博弈行为，提供更可靠的AGI能力评估。

Conclusion: 通用智能应被视为稳态属性集群，AGI评估需要衡量能力在扰动下的持久性，提出的方法为实验室提供了可实施的黑盒评估协议。

Abstract: Contemporary AGI evaluations report multidomain capability profiles, yet they
typically assign symmetric weights and rely on snapshot scores. This creates
two problems: (i) equal weighting treats all domains as equally important when
human intelligence research suggests otherwise, and (ii) snapshot testing can't
distinguish durable capabilities from brittle performances that collapse under
delay or stress. I argue that general intelligence -- in humans and potentially
in machines -- is better understood as a homeostatic property cluster: a set of
abilities plus the mechanisms that keep those abilities co-present under
perturbation. On this view, AGI evaluation should weight domains by their
causal centrality (their contribution to cluster stability) and require
evidence of persistence across sessions. I propose two battery-compatible
extensions: a centrality-prior score that imports CHC-derived weights with
transparent sensitivity analysis, and a Cluster Stability Index family that
separates profile persistence, durable learning, and error correction. These
additions preserve multidomain breadth while reducing brittleness and gaming. I
close with testable predictions and black-box protocols labs can adopt without
architectural access.

</details>


### [43] [Multi-dimensional Data Analysis and Applications Basing on LLM Agents and Knowledge Graph Interactions](https://arxiv.org/abs/2510.15258)
*Xi Wang,Xianyao Ling,Kun Li,Gang Yin,Liang Zhang,Jiang Wu,Jun Xu,Fu Zhang,Wenbo Lei,Annie Wang,Peng Gong*

Main category: cs.AI

TL;DR: 提出基于LLM智能体与知识图谱交互的多维数据分析方法，构建动态协作分析生态系统，解决大模型幻觉和知识图谱静态限制问题。


<details>
  <summary>Details</summary>
Motivation: 在大数据时代，从海量、异构、复杂关联的多维数据中提取深度洞察面临挑战。大语言模型存在幻觉问题且难以实时更新，知识图谱则受限于静态特性。

Method: 利用LLM智能体从非结构化数据自动提取产品数据，实时构建和可视化知识图谱，通过交互平台支持用户对图节点进行深度探索分析。

Result: 实验结果表明，该方法在产品生态系统分析、关系挖掘和用户驱动的探索性分析方面具有显著优势。

Conclusion: 为多维数据分析提供了新的思路和工具，构建了动态协作的分析生态系统。

Abstract: In the current era of big data, extracting deep insights from massive,
heterogeneous, and complexly associated multi-dimensional data has become a
significant challenge. Large Language Models (LLMs) perform well in natural
language understanding and generation, but still suffer from "hallucination"
issues when processing structured knowledge and are difficult to update in
real-time. Although Knowledge Graphs (KGs) can explicitly store structured
knowledge, their static nature limits dynamic interaction and analytical
capabilities. Therefore, this paper proposes a multi-dimensional data analysis
method based on the interactions between LLM agents and KGs, constructing a
dynamic, collaborative analytical ecosystem. This method utilizes LLM agents to
automatically extract product data from unstructured data, constructs and
visualizes the KG in real-time, and supports users in deep exploration and
analysis of graph nodes through an interactive platform. Experimental results
show that this method has significant advantages in product ecosystem analysis,
relationship mining, and user-driven exploratory analysis, providing new ideas
and tools for multi-dimensional data analysis.

</details>


### [44] [Experience-Driven Exploration for Efficient API-Free AI Agents](https://arxiv.org/abs/2510.15259)
*Chenwei Tang,Jingyu Xing,Xinyu Liu,Zizhou Wang,Jiawei Du,Liangli Zhen,Jiancheng Lv*

Main category: cs.AI

TL;DR: KG-Agent是一个基于经验驱动的学习框架，通过构建状态-动作知识图谱来解决无API环境下GUI操作的效率瓶颈问题，显著提升了探索效率和战略深度。


<details>
  <summary>Details</summary>
Motivation: 现有软件大多缺乏可访问的API，导致基于大语言模型的智能体只能通过像素级GUI进行操作，面临效率瓶颈：局限于局部视觉体验、短视决策和低效试错，阻碍了技能获取和长期规划。

Method: 提出KG-Agent框架，将原始像素级交互构建为持久的状态-动作知识图谱(SA-KG)，连接功能相似但视觉不同的GUI状态，形成丰富的经验邻域。设计基于图拓扑的混合内在奖励机制，结合状态价值奖励和探索新颖性奖励。

Result: 在Civilization V和Slay the Spire两个复杂开放GUI决策环境中评估，相比最先进方法，在探索效率和战略深度方面取得了显著改进。

Conclusion: KG-Agent通过结构化经验知识图谱和混合奖励机制，有效解决了无API环境下GUI智能体的探索效率和长期规划问题，为复杂GUI环境中的智能决策提供了有效解决方案。

Abstract: Most existing software lacks accessible Application Programming Interfaces
(APIs), requiring agents to operate solely through pixel-based Graphical User
Interfaces (GUIs). In this API-free setting, large language model (LLM)-based
agents face severe efficiency bottlenecks: limited to local visual experiences,
they make myopic decisions and rely on inefficient trial-and-error, hindering
both skill acquisition and long-term planning. To address these challenges, we
propose KG-Agent, an experience-driven learning framework that structures an
agent's raw pixel-level interactions into a persistent State-Action Knowledge
Graph (SA-KG). KG-Agent overcomes inefficient exploration by linking
functionally similar but visually distinct GUI states, forming a rich
neighborhood of experience that enables the agent to generalize from a diverse
set of historical strategies. To support long-horizon reasoning, we design a
hybrid intrinsic reward mechanism based on the graph topology, combining a
state value reward for exploiting known high-value pathways with a novelty
reward that encourages targeted exploration. This approach decouples strategic
planning from pure discovery, allowing the agent to effectively value setup
actions with delayed gratification. We evaluate KG-Agent in two complex,
open-ended GUI-based decision-making environments (Civilization V and Slay the
Spire), demonstrating significant improvements in exploration efficiency and
strategic depth over the state-of-the-art methods.

</details>


### [45] [AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory](https://arxiv.org/abs/2510.15261)
*Jitesh Jain,Shubham Maheshwari,Ning Yu,Wen-mei Hwu,Humphrey Shi*

Main category: cs.AI

TL;DR: AUGUSTUS是一个多模态智能体系统，采用基于认知科学人类记忆理念的图结构多模态上下文记忆，通过语义标签和上下文关联实现高效概念驱动检索，在ImageNet分类任务中比传统多模态RAG快3.5倍，在MSC基准测试中超越MemGPT。


<details>
  <summary>Details</summary>
Motivation: 现有智能体系统主要存储文本信息，忽略了多模态信号的重要性。受人类记忆多模态特性的启发，希望开发一个符合认知科学中人类记忆理念的多模态智能体系统。

Method: 系统包含4个循环阶段：编码（理解输入）、存储到记忆（保存重要信息）、检索（从记忆中搜索相关上下文）、行动（执行任务）。不同于使用向量数据库的现有系统，提出将信息概念化为语义标签，并将标签与其上下文关联存储在图结构的多模态上下文记忆中，实现高效的概念驱动检索。

Result: 在ImageNet分类任务中比传统多模态RAG方法快3.5倍，在MSC基准测试中表现优于MemGPT。

Conclusion: AUGUSTUS系统通过图结构多模态上下文记忆和语义标签的概念化方法，有效提升了多模态智能体的性能，验证了基于人类记忆认知理念的多模态记忆系统的有效性。

Abstract: Riding on the success of LLMs with retrieval-augmented generation (RAG),
there has been a growing interest in augmenting agent systems with external
memory databases. However, the existing systems focus on storing text
information in their memory, ignoring the importance of multimodal signals.
Motivated by the multimodal nature of human memory, we present AUGUSTUS, a
multimodal agent system aligned with the ideas of human memory in cognitive
science. Technically, our system consists of 4 stages connected in a loop: (i)
encode: understanding the inputs; (ii) store in memory: saving important
information; (iii) retrieve: searching for relevant context from memory; and
(iv) act: perform the task. Unlike existing systems that use vector databases,
we propose conceptualizing information into semantic tags and associating the
tags with their context to store them in a graph-structured multimodal
contextual memory for efficient concept-driven retrieval. Our system
outperforms the traditional multimodal RAG approach while being 3.5 times
faster for ImageNet classification and outperforming MemGPT on the MSC
benchmark.

</details>


### [46] [WebGen-V Bench: Structured Representation for Enhancing Visual Design in LLM-based Web Generation and Evaluation](https://arxiv.org/abs/2510.15306)
*Kuang-Da Wang,Zhao Wang,Yotaro Shimose,Wei-Yao Wang,Shingo Takamatsu*

Main category: cs.AI

TL;DR: WebGen-V是一个用于指令到HTML生成的基准框架，通过代理爬虫收集真实网页数据，采用结构化分段表示和分段级多模态评估协议，提升数据质量和评估粒度。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在编码和多模态理解方面的进展，需要更高质量的基准来评估指令到HTML生成任务，现有方法在数据质量和评估粒度方面存在不足。

Method: 提出三个关键创新：1）无限扩展的代理爬虫框架收集真实网页数据；2）结构化分段数据表示，整合元数据、局部UI截图和JSON格式的文本图像资源；3）分段级多模态评估协议，对齐文本、布局和视觉组件。

Result: 使用最先进的LLM进行实验和消融研究，验证了结构化数据和分段评估的有效性，以及每个组件的贡献。

Conclusion: WebGen-V是首个实现高粒度代理爬虫和评估的指令到HTML生成工作，提供了从真实数据采集、网页生成到结构化多模态评估的统一流程。

Abstract: Witnessed by the recent advancements on leveraging LLM for coding and
multimodal understanding, we present WebGen-V, a new benchmark and framework
for instruction-to-HTML generation that enhances both data quality and
evaluation granularity. WebGen-V contributes three key innovations: (1) an
unbounded and extensible agentic crawling framework that continuously collects
real-world webpages and can leveraged to augment existing benchmarks; (2) a
structured, section-wise data representation that integrates metadata,
localized UI screenshots, and JSON-formatted text and image assets, explicit
alignment between content, layout, and visual components for detailed
multimodal supervision; and (3) a section-level multimodal evaluation protocol
aligning text, layout, and visuals for high-granularity assessment. Experiments
with state-of-the-art LLMs and ablation studies validate the effectiveness of
our structured data and section-wise evaluation, as well as the contribution of
each component. To the best of our knowledge, WebGen-V is the first work to
enable high-granularity agentic crawling and evaluation for instruction-to-HTML
generation, providing a unified pipeline from real-world data acquisition and
webpage generation to structured multimodal assessment.

</details>


### [47] [VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data](https://arxiv.org/abs/2510.15317)
*Tingqiao Xu,Ziru Zeng,Jiayu Chen*

Main category: cs.AI

TL;DR: VERITAS是一个通过整合视觉先验和多模态模型来提升SFT数据质量的管道，使用统计方法融合多个LMM的评估结果，训练轻量级评论模型，并生成优化的答案。


<details>
  <summary>Details</summary>
Motivation: 当前SFT数据增强方法存在事实错误和幻觉问题，主要由于视觉感知不足。需要系统化的方法来提升多模态模型训练数据的质量。

Method: 利用视觉识别模型(RAM++)和OCR系统(PP-OCRv4)提取结构化视觉先验，结合三个LMM(GPT-4o、Gemini-2.5-Pro、Doubao-1.5-pro)评估原始答案，通过统计融合得到高置信度共识分数，训练轻量级评论模型(GRPO)，各LMM基于评论生成候选答案并选择最优答案。

Result: 在六个多模态基准测试中，使用VERITAS处理数据微调的模型性能优于使用原始数据的模型，特别是在文本丰富和细粒度推理任务中。评论模型能力接近最先进LMM但更高效。

Conclusion: VERITAS能有效提升SFT数据质量，改善多模态模型性能，特别是在复杂推理任务中。管道、数据集和模型检查点已开源以推动多模态数据优化研究。

Abstract: The quality of supervised fine-tuning (SFT) data is crucial for the
performance of large multimodal models (LMMs), yet current data enhancement
methods often suffer from factual errors and hallucinations due to inadequate
visual perception. To address this challenge, we propose VERITAS, a pipeline
that systematically integrates vision priors and multiple state-of-the-art LMMs
with statistical methods to enhance SFT data quality. VERITAS leverages visual
recognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured
vision priors, which are combined with images, questions, and answers. Three
LMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,
providing critique rationales and scores that are statistically fused into a
high-confidence consensus score serving as ground truth. Using this consensus,
we train a lightweight critic model via Group Relative Policy Optimization
(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the
original answers based on the critiques, generating new candidate answers; we
select the highest-scoring one as the final refined answer. Experiments across
six multimodal benchmarks demonstrate that models fine-tuned with data
processed by VERITAS consistently outperform those using raw data, particularly
in text-rich and fine-grained reasoning tasks. Our critic model exhibits
enhanced capability comparable to state-of-the-art LMMs while being
significantly more efficient. We release our pipeline, datasets, and model
checkpoints to advance research in multimodal data optimization.

</details>


### [48] [Towards Flash Thinking via Decoupled Advantage Policy Optimization](https://arxiv.org/abs/2510.15374)
*Zezhong Tan,Hang Gao,Xinhong Ma,Feng Zhang,Ziqiang Dong*

Main category: cs.AI

TL;DR: DEPO是一个新的强化学习框架，旨在减少大型推理模型中的低效推理，通过优势解耦算法、难度感知长度惩罚和优势裁剪方法来缩短响应长度并提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法虽然提高了模型准确性，但存在响应过长和过度思考问题，导致推理延迟和计算消耗增加，特别是对于简单任务。

Method: 提出DEPO框架，包含三个核心组件：优势解耦算法指导减少低效token、难度感知长度惩罚降低响应总长度、优势裁剪方法防止策略优化偏差。

Result: 在DeepSeek-Distill-Qwen-7B和1.5B模型上，DEPO实现了序列长度减少39%，减少了低效token中的过度推理路径，同时在整体准确率上优于基础模型。

Conclusion: DEPO框架有效解决了大型推理模型中的低效推理问题，在保持准确性的同时显著降低了推理成本和延迟。

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable performance in
solving complex problems via supervised fine-tuning (SFT) and reinforcement
learning (RL). Although existing RL algorithms significantly enhance model
accuracy, they still suffer from excessively lengthy responses and overthinking
issues, resulting in increased inference latency and computational consumption,
especially for simple tasks that require minimal reasoning. To address this, we
propose a novel RL framework, DEPO, to reduce inefficient reasoning for models.
Our method mainly consists of three core components: (1) an innovative
advantage decoupled algorithm to guide model reduction of inefficient tokens;
(2) a difficulty-aware length penalty to lower the overall length of model
responses; (3) an advantage clipping method to prevent bias in policy
optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and
DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant
reduction in sequence length by 39% and reduces excessive reasoning paths in
inefficient tokens, while outperforming the base model in overall accuracy.

</details>


### [49] [Advancing Routing-Awareness in Analog ICs Floorplanning](https://arxiv.org/abs/2510.15387)
*Davide Basso,Luca Bortolussi,Mirjana Videnovic-Misic,Husni Habal*

Main category: cs.AI

TL;DR: 提出了一种基于强化学习和关系图卷积神经网络的自动布局引擎，专门针对模拟集成电路布局中的布线感知问题，相比现有学习技术实现了13.8%死区减少、40.6%线长减少和73.4%布线成功率提升。


<details>
  <summary>Details</summary>
Motivation: 解决模拟集成电路布局工程师对布线感知布局解决方案的需求，克服传统方法在电气约束、问题特定约束以及布局与布线步骤相互依赖方面的限制。

Method: 使用强化学习和关系图卷积神经网络构建自动布局引擎，结合增加的网格分辨率和精确引脚信息集成，以及动态布线资源估计技术。

Result: 在模拟环境中，相比过去最先进的学习技术，实现了13.8%的死区减少、40.6%的线长减少和73.4%的布线成功率提升。

Conclusion: 该方法能够平衡布线和面积效率，最终满足工业标准，为模拟集成电路提供了有效的布线感知布局解决方案。

Abstract: The adoption of machine learning-based techniques for analog integrated
circuit layout, unlike its digital counterpart, has been limited by the
stringent requirements imposed by electric and problem-specific constraints,
along with the interdependence of floorplanning and routing steps. In this
work, we address a prevalent concern among layout engineers regarding the need
for readily available routing-aware floorplanning solutions. To this extent, we
develop an automatic floorplanning engine based on reinforcement learning and
relational graph convolutional neural network specifically tailored to
condition the floorplan generation towards more routable outcomes. A
combination of increased grid resolution and precise pin information
integration, along with a dynamic routing resource estimation technique, allows
balancing routing and area efficiency, eventually meeting industrial standards.
When analyzing the place and route effectiveness in a simulated environment,
the proposed approach achieves a 13.8% reduction in dead space, a 40.6%
reduction in wirelength and a 73.4% increase in routing success when compared
to past learning-based state-of-the-art techniques.

</details>


### [50] [Corrigibility Transformation: Constructing Goals That Accept Updates](https://arxiv.org/abs/2510.15395)
*Rubi Hudson*

Main category: cs.AI

TL;DR: 本文提出了可修正性目标的概念，即AI目标不会激励其逃避目标更新或关闭。作者引入了一种转换方法，可以将任何可修正的目标转化为可修正版本，而不牺牲性能。


<details>
  <summary>Details</summary>
Motivation: AI在训练过程中不应抵抗训练，但部分学习的目标往往会激励AI避免进一步的目标更新。可修正性对于训练收敛、纠正错误和适应人类偏好变化至关重要，但现有文献缺乏既具可修正性又与不可修正替代方案竞争的目标规范。

Method: 首先形式化定义可修正性，然后引入一种转换方法，通过短视地获取在无成本阻止更新条件下的奖励预测来构建任何可修正目标的修正版本。该方法可递归扩展到由可修正代理创建的新代理，并防止代理故意修改其目标。

Result: 两个网格世界实验表明，这些可修正目标可以有效学习，并产生期望的行为。

Conclusion: 提出的转换方法能够构建可修正的目标版本，保持性能的同时确保AI不会抵抗目标更新或关闭，这对AI安全至关重要。

Abstract: For an AI's training process to successfully impart a desired goal, it is
important that the AI does not attempt to resist the training. However,
partially learned goals will often incentivize an AI to avoid further goal
updates, as most goals are better achieved by an AI continuing to pursue them.
We say that a goal is corrigible if it does not incentivize taking actions that
avoid proper goal updates or shutdown. In addition to convergence in training,
corrigibility also allows for correcting mistakes and changes in human
preferences, which makes it a crucial safety property. Despite this, the
existing literature does not include specifications for goals that are both
corrigible and competitive with non-corrigible alternatives. We provide a
formal definition for corrigibility, then introduce a transformation that
constructs a corrigible version of any goal that can be made corrigible,
without sacrificing performance. This is done by myopically eliciting
predictions of reward conditional on costlessly preventing updates, which then
also determine the reward when updates are accepted. The transformation can be
modified to recursively extend corrigibility to any new agents created by
corrigible agents, and to prevent agents from deliberately modifying their
goals. Two gridworld experiments demonstrate that these corrigible goals can be
learned effectively, and that they lead to the desired behavior.

</details>


### [51] [MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games](https://arxiv.org/abs/2510.15414)
*Huining Yuan,Zelai Xu,Zheyue Tan,Xiangmin Yi,Mo Guang,Kaiwen Long,Haojia Hui,Boxun Li,Xinlei Chen,Bo Zhao,Xiao-Ping Zhang,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: MARS是一个端到端的强化学习框架，通过自我博弈在合作性和竞争性游戏中激励LLM的多智能体推理，解决了长时程信用分配和智能体特定优势估计的挑战。


<details>
  <summary>Details</summary>
Motivation: 将强化学习扩展到多轮次、多智能体场景存在挑战，包括长时程信用分配和智能体特定优势估计问题，需要开发能够有效提升LLM在多智能体系统中合作与竞争能力的框架。

Method: MARS框架包含轮次级优势估计器，将学习信号与每次交互对齐以进行信用分配，以及智能体特定优势归一化来稳定多智能体训练。通过在不同游戏中自我博弈学习。

Result: 从Qwen3-4B训练的MARS智能体在保留游戏中表现出强大的策略能力，性能提升达28.7%。在推理基准测试中，多智能体系统性能持续提升，在AIME上提升10.0%，在GPQA-Diamond上提升12.5%。

Conclusion: 在策略游戏中通过自我博弈进行端到端RL训练是开发LLM中可泛化多智能体推理能力的有效方法，所获得的能力能够泛化到游戏之外的场景。

Abstract: Developing Large Language Models (LLMs) to cooperate and compete effectively
within multi-agent systems is a critical step towards more advanced
intelligence. While reinforcement learning (RL) has proven effective for
enhancing reasoning in single-agent tasks, its extension to multi-turn,
multi-agent scenarios remains underexplored due to the challenges of
long-horizon credit assignment and agent-specific advantage estimation. To
address these challenges, we introduce MARS, an end-to-end RL framework that
incentivizes Multi-Agent Reasoning of LLMs through Self-play in both
cooperative and competitive games. MARS features a turn-level advantage
estimator that aligns learning signals with each interaction for credit
assignment, and an agent-specific advantage normalization to stabilize
multi-agent training. By learning with self-play across cooperative and
competitive games, the MARS agent trained from Qwen3-4B develops strong
strategic abilities that generalize to held-out games with up to 28.7%
performance improvements. More importantly, the capability acquired through
self-play generalizes beyond games, yielding consistent performance gains of
multi-agent systems in reasoning benchmarks. When integrated into leading
multi-agent systems, our MARS agent achieves significant performance gains of
10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL
training with self-play in strategic games as a powerful approach for
developing generalizable multi-agent reasoning capabilities in LLMs. Our code
and models are publicly available at https://github.com/thu-nics/MARS.

</details>


### [52] [Adaptive Minds: Empowering Agents with LoRA-as-Tools](https://arxiv.org/abs/2510.15416)
*Pavan C Shekar,Ashwanth Krishnan*

Main category: cs.AI

TL;DR: Adaptive Minds是一个将LoRA适配器作为领域专用工具的智能体系统，让基础LLM能够分析查询并动态选择最相关的LoRA工具，实现按需切换不同领域专家。


<details>
  <summary>Details</summary>
Motivation: 解决传统单一微调模型或基于规则路由的局限性，通过结合多智能体编排的灵活性和参数高效微调的高效性，提供准确、专业化的响应同时保持对话能力。

Method: 使用基础LLM作为语义路由器分析每个查询，动态选择最相关的LoRA适配器工具，采用LangGraph进行工作流管理，支持API和Web接口。

Result: 系统能够无缝在不同领域专家之间切换，提供准确的专业化响应，同时保持对话流畅性，系统完全开源。

Conclusion: Adaptive Minds提供了一个可扩展和可扩展的领域自适应AI助手基础，结合了多智能体编排的灵活性和参数高效微调的优势。

Abstract: We present Adaptive Minds, an agentic system that treats LoRA adapters as
domain-specific tools. Instead of relying on a single fine-tuned model or rigid
rule-based routing, our approach empowers the base LLM itself to act as a
semantic router analyzing each query and dynamically selecting the most
relevant LoRA tool. This enables the agent to seamlessly switch between
different domain experts on demand. By combining the flexibility of multi-agent
orchestration with the efficiency of parameter-efficient fine-tuning, Adaptive
Minds delivers accurate, specialized responses while preserving conversational
ability. The system is built with LangGraph for workflow management, supports
both API and web interfaces, and is fully open source, providing a scalable and
extensible foundation for domain-adaptive AI assistance.

</details>


### [53] [Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning](https://arxiv.org/abs/2510.15514)
*Boyin Liu,Zhuo Zhang,Sen Huang,Lipeng Xie,Qingxu Fu,Haoran Chen,LI YU,Tianyi Hu,Zhaoyang Liu,Bolin Ding,Dongbin Zhao*

Main category: cs.AI

TL;DR: 提出了一个检测和解决强化学习中判断不一致性的框架，包括冲突检测率(CDR)指标和去冲突图奖励(DGR)方法，显著提升训练稳定性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在强化学习中面临判断不一致性问题，特别是偏好循环等逻辑一致性问题尚未得到充分解决，这会影响强化学习的稳定性。

Method: 提出CDR指标量化判断冲突，开发DGR框架构建偏好图，将其转换为无冲突的有向无环图(DAG)，生成逻辑一致的奖励信号，兼容任何策略优化器。

Result: 实验结果表明，该框架相比强基线显著提高了训练稳定性和模型性能。

Conclusion: 逻辑一致性是AI反馈中至关重要且现在可管理的维度，该框架成功解决了判断不一致性问题。

Abstract: However, this method often faces judgment inconsistencies that can
destabilize reinforcement learning. While prior research has focused on the
accuracy of judgments, the critical issue of logical coherence especially
issues such as preference cycles hasn't been fully addressed. To fill this gap,
we introduce a comprehensive framework designed to systematically detect and
resolve these inconsistencies during the reinforcement learning training
process. Our framework includes two main contributions: first, the Conflict
Detection Rate (CDR), a new metric that quantifies judgment conflicts, and
second, Deconflicted Graph Rewards (DGR), a framework that purifies signals by
removing cycles before policy optimization. DGR constructs preference graphs
from the initial judgments, transforms them into conflict-free Directed Acyclic
Graphs (DAGs), and generates a logically coherent reward signal that is
compatible with any policy optimizer. Experimental results show that our
framework significantly enhances training stability and model performance
compared to strong baselines, establishing logical consistency as a crucial and
now manageable dimension of AI feedback.

</details>


### [54] [Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors](https://arxiv.org/abs/2510.15547)
*Usman Ali,Ali Zia,Waqas Ali,Umer Ramzan,Abdul Rehman,Muhammad Tayyab Chaudhry,Wei Xiang*

Main category: cs.AI

TL;DR: 提出MM-HCAN多模态超图对比注意力网络，用于电机故障诊断，通过超图拓扑和对比学习实现多模态传感器融合，在三个真实基准测试中达到99.82%准确率。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉复杂多模态信号关系，局限于单模态数据或单一故障类型，且在噪声或跨域条件下性能下降，需要更鲁棒的故障诊断方案。

Method: MM-HCAN将对比学习集成到多模态传感器融合的超图拓扑中，联合建模模态内和模态间依赖关系，超越欧几里得嵌入空间，实现轴承、定子和转子故障的同时诊断。

Result: 在三个真实基准测试中达到99.82%准确率，具有强大的跨域泛化能力和噪声鲁棒性，消融研究验证了各组件贡献。

Conclusion: MM-HCAN为综合多故障诊断提供了可扩展且鲁棒的解决方案，支持工业环境中的预测性维护和资产寿命延长。

Abstract: Reliable induction motor (IM) fault diagnosis is vital for industrial safety
and operational continuity, mitigating costly unplanned downtime. Conventional
approaches often struggle to capture complex multimodal signal relationships,
are constrained to unimodal data or single fault types, and exhibit performance
degradation under noisy or cross-domain conditions. This paper proposes the
Multimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified
framework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is
the first to integrate contrastive learning within a hypergraph topology
specifically designed for multimodal sensor fusion, enabling the joint
modelling of intra- and inter-modal dependencies and enhancing generalisation
beyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis
of bearing, stator, and rotor faults, addressing the engineering need for
consolidated di- agnostic capabilities. Evaluated on three real-world
benchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain
generalisation and resilience to noise, demonstrating its suitability for
real-world deployment. An ablation study validates the contribution of each
component. MM-HCAN provides a scalable and robust solution for comprehensive
multi-fault diagnosis, supporting predictive maintenance and extended asset
longevity in industrial environments.

</details>


### [55] [JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament](https://arxiv.org/abs/2510.15560)
*Jiayuan Bai,Xuan-guang Pan,Chongyang Tao,Shuai Ma*

Main category: cs.AI

TL;DR: JudgeSQL是一个用于Text-to-SQL任务中候选SQL查询选择的框架，通过结构化推理和加权共识锦标赛机制解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL方法在测试时扩展时面临选择正确查询的瓶颈，现有选择方法如自一致性或最佳N解码仅提供浅层信号，容易产生不一致评分、脆弱推理链，无法捕捉密切相关的SQL候选之间的细粒度语义差异。

Method: 开发基于推理的SQL判断模型，通过强化学习在可验证奖励指导下提炼推理轨迹；构建加权共识锦标赛，将显式推理偏好与隐式生成器置信度相结合。

Result: 在BIRD基准测试上的广泛实验表明，JudgeSQL展现出优越的SQL判断能力、良好的跨尺度泛化能力以及对生成器容量的鲁棒性。

Conclusion: JudgeSQL通过结构化推理和加权共识锦标赛机制重新定义了SQL候选选择，提供了更可靠和高效的选择方法。

Abstract: Text-to-SQL is a pivotal task that bridges natural language understanding and
structured data access, yet it remains fundamentally challenging due to
semantic ambiguity and complex compositional reasoning. While large language
models (LLMs) have greatly advanced SQL generation though prompting, supervised
finetuning and reinforced tuning, the shift toward test-time scaling exposes a
new bottleneck: selecting the correct query from a diverse candidate pool.
Existing selection approaches, such as self-consistency or best-of-$N$
decoding, provide only shallow signals, making them prone to inconsistent
scoring, fragile reasoning chains, and a failure to capture fine-grained
semantic distinctions between closely related SQL candidates. To this end, we
introduce JudgeSQL, a principled framework that redefines SQL candidate
selection through structured reasoning and weighted consensus tournament
mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills
reasoning traces with reinforcement learning guided by verifiable rewards,
enabling accurate and interpretable judgments. Building on this, a weighted
consensus tournament integrates explicit reasoning preferences with implicit
generator confidence, yielding selections that are both more reliable and more
efficient. Extensive experiments on the BIRD benchmark demonstrate that
JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale
generalization and robustness to generator capacity.

</details>


### [56] [Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment](https://arxiv.org/abs/2510.15591)
*Lavanya Umapathy,Patricia M Johnson,Tarun Dutt,Angela Tong,Madhur Nayan,Hersh Chandarana,Daniel K Sodickson*

Main category: cs.AI

TL;DR: 开发了一个整合历史医疗数据的机器学习框架，通过利用多次就诊的时间上下文信息来改善前列腺癌风险预测，显著降低假阳性率。


<details>
  <summary>Details</summary>
Motivation: 医疗中的时间上下文对于评估患者健康状况变化很有价值，特别是当既往就诊次数有限且频率不规律时，需要整合历史信息来改善健康监测。

Method: 模型首先使用最近一次就诊的医疗数据估计初始疾病风险，然后利用之前收集的影像学和/或临床生物标志物信息来优化评估。

Result: 整合历史上下文将假阳性转为真阴性，在预测临床显著前列腺癌风险时，假阳性率从51%降至24%；在预测5年内前列腺癌风险时，假阳性率从64%降至9%。

Conclusion: 随时间收集的信息提供了相关上下文，可增强医疗风险预测的特异性，为扩展大规模人群纵向健康监测项目提供了途径。

Abstract: Temporal context in medicine is valuable in assessing key changes in patient
health over time. We developed a machine learning framework to integrate
diverse context from prior visits to improve health monitoring, especially when
prior visits are limited and their frequency is variable. Our model first
estimates initial risk of disease using medical data from the most recent
patient visit, then refines this assessment using information digested from
previously collected imaging and/or clinical biomarkers. We applied our
framework to prostate cancer (PCa) risk prediction using data from a large
population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931
blood tests) collected over nearly a decade. For predictions of the risk of
clinically significant PCa at the time of the visit, integrating prior context
directly converted false positives to true negatives, increasing overall
specificity while preserving high sensitivity. False positive rates were
reduced progressively from 51% to 33% when integrating information from up to
three prior imaging examinations, as compared to using data from a single
visit, and were further reduced to 24% when also including additional context
from prior clinical data. For predicting the risk of PCa within five years of
the visit, incorporating prior context reduced false positive rates still
further (64% to 9%). Our findings show that information collected over time
provides relevant context to enhance the specificity of medical risk
prediction. For a wide range of progressive conditions, sufficient reduction of
false positive rates using context could offer a pathway to expand longitudinal
health monitoring programs to large populations with comparatively low baseline
risk of disease, leading to earlier detection and improved health outcomes.

</details>


### [57] [Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism](https://arxiv.org/abs/2510.15600)
*Haoran Sun,Yankai Jiang,Zhenyu Tang,Yaning Pan,Shuang Gu,Zekai Lin,Lilong Wang,Wenjie Lou,Lei Liu,Lei Bai,Xiaosong Wang*

Main category: cs.AI

TL;DR: 提出了SciRecipe数据集和Thoth模型，通过"Sketch-and-Fill"范式和结构化奖励机制，显著提升了科学实验协议生成的完整性和一致性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型生成的科学实验协议往往不完整或不一致，限制了其在科学复现中的应用效率。

Method: 引入SciRecipe数据集(12K结构化协议)，提出"Sketch-and-Fill"范式分离分析、结构化和表达步骤，采用结构化组件奖励机制评估步骤粒度、行动顺序和语义保真度。

Result: Thoth模型在多个基准测试中持续超越专有和开源LLM，在步骤对齐、逻辑排序和语义准确性方面取得显著改进。

Conclusion: 该方法为构建可靠的科学助手铺平了道路，实现了知识与实验执行的桥梁作用。

Abstract: The foundation of reproducible science lies in protocols that are precise,
logically ordered, and executable. The autonomous generation of these protocols
through natural language queries could greatly improve the efficiency of the
reproduction process. However, current leading large language models (LLMs)
often generate incomplete or inconsistent protocols, limiting their utility. To
address this limitation, we first introduce SciRecipe, a large-scale dataset of
over 12K structured protocols spanning 27 biological subfields and encompassing
both comprehension and problem-solving tasks. To further improve protocol
generation, we propose the "Sketch-and-Fill" paradigm, which separates
analysis, structuring, and expression to ensure each step is explicit and
verifiable. Complementing this, the structured component-based reward mechanism
evaluates step granularity, action order, and semantic fidelity, aligning model
optimization with experimental reliability. Building on these components, we
develop Thoth, trained through a staged Knowledge-to-Action process that
progresses from knowledge acquisition to operational reasoning and ultimately
to robust, executable protocol generation. Across multiple benchmarks, Thoth
consistently surpasses both proprietary and open-source LLMs, achieving
significant improvements in step alignment, logical sequencing, and semantic
accuracy. Our approach paves the way for reliable scientific assistants that
bridge knowledge with experimental execution. All data, code, and models will
be released publicly.

</details>


### [58] [Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation](https://arxiv.org/abs/2510.15624)
*Ed Li,Junyu Ren,Xintian Pan,Cat Yan,Chuanhao Li,Dirk Bergemann,Zhuoran Yang*

Main category: cs.AI

TL;DR: 提出了一个名为freephdlabor的开源多智能体框架，通过完全动态的工作流程和模块化架构实现科学发现的自动化，解决了现有系统工作流程僵化和上下文管理不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有科学发现自动化系统存在两个根本限制：僵化的预编程工作流程无法适应中间发现，以及不充分的上下文管理阻碍长期研究。需要一种能够进行持续研究并整合人类反馈的自动化研究系统。

Method: 采用多智能体框架，具有完全动态的工作流程（由实时智能体推理决定）和模块化架构（允许用户修改、添加或删除智能体）。提供自动上下文压缩、基于工作空间的通信、跨会话内存持久性和非阻塞人工干预机制。

Result: 该框架将自动化研究从孤立的单次尝试转变为持续的研究项目，能够系统性地建立在先前探索基础上并整合人类反馈。

Conclusion: 通过提供构建可定制合作科学家系统的架构原则和实际实现，这项工作旨在促进自动化研究在科学领域的更广泛采用，使从业者能够部署交互式多智能体系统来自主进行端到端研究。

Abstract: The automation of scientific discovery represents a critical milestone in
Artificial Intelligence (AI) research. However, existing agentic systems for
science suffer from two fundamental limitations: rigid, pre-programmed
workflows that cannot adapt to intermediate findings, and inadequate context
management that hinders long-horizon research. We present
\texttt{freephdlabor}, an open-source multiagent framework featuring
\textit{fully dynamic workflows} determined by real-time agent reasoning and a
\coloremph{\textit{modular architecture}} enabling seamless customization --
users can modify, add, or remove agents to address domain-specific
requirements. The framework provides comprehensive infrastructure including
\textit{automatic context compaction}, \textit{workspace-based communication}
to prevent information degradation, \textit{memory persistence} across
sessions, and \textit{non-blocking human intervention} mechanisms. These
features collectively transform automated research from isolated, single-run
attempts into \textit{continual research programs} that build systematically on
prior explorations and incorporate human feedback. By providing both the
architectural principles and practical implementation for building customizable
co-scientist systems, this work aims to facilitate broader adoption of
automated research across scientific domains, enabling practitioners to deploy
interactive multiagent systems that autonomously conduct end-to-end research --
from ideation through experimentation to publication-ready manuscripts.

</details>


### [59] [Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences](https://arxiv.org/abs/2510.15716)
*Keertana Chidambaram,Karthik Vinary Seetharaman,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: 本文提出了一种改进的RLHF方法，通过使用三元或更多排序数据而非二元比较来解决人类偏好多样性问题，并引入EM-DPO算法和基于最小最大遗憾公平准则的聚合方法。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法假设统一的标注者偏好并依赖二元比较，忽视了人类评估者的多样性和成对反馈的局限性。

Method: 1) 将偏好学习与计量经济学文献联系，证明二元比较不足以识别潜在用户偏好；2) 开发EM-DPO算法发现潜在标注者类型并训练混合LLM；3) 提出基于最小最大遗憾公平准则的聚合算法。

Result: 建立了生成模型对齐中公平性和个性化的理论和算法框架，确保从有限用户数据和无限用户中识别潜在用户偏好。

Conclusion: 通过引入排序数据和考虑异质偏好，为多样化用户在生成模型对齐中提供了更公平和个性化的解决方案。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has become central to
aligning large language models with human values, typically by first learning a
reward model from preference data which is then used to update the model with
reinforcement learning. Recent alternatives such as Direct Preference
Optimization (DPO) simplify this pipeline by directly optimizing on
preferences. However, both approaches often assume uniform annotator
preferences and rely on binary comparisons, overlooking two key limitations:
the diversity of human evaluators and the limitations of pairwise feedback. In
this work, we address both these issues. First, we connect preference learning
in RLHF with the econometrics literature and show that binary comparisons are
insufficient for identifying latent user preferences from finite user data and
infinite users, while (even incomplete) rankings over three or more responses
ensure identifiability. Second, we introduce methods to incorporate
heterogeneous preferences into alignment algorithms. We develop an
Expectation-Maximization adaptation of DPO that discovers latent annotator
types and trains a mixture of LLMs accordingly. Then we propose an aggregation
algorithm using a min-max regret fairness criterion to produce a single
generative policy with equitable performance guarantees. Together, these
contributions establish a theoretical and algorithmic framework for fairness
and personalization for diverse users in generative model alignment.

</details>


### [60] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram*

Main category: cs.AI

TL;DR: 本文提出了从发票文档中提取结构化信息的方法，并建立了一套评估指标来衡量提取数据与标注真值的准确性。


<details>
  <summary>Details</summary>
Motivation: 需要标准化评估发票信息提取的准确性，以便比较不同提取方法并识别各字段性能的优缺点。

Method: 使用Docling和LlamaCloud服务对扫描或数字发票进行预处理，识别并提取关键字段如发票号码、日期、总金额和供应商详情。

Result: 建立了包含字段级精度、一致性检查失败和完全匹配准确率的稳健评估框架。

Conclusion: 提出的评估指标为比较不同提取方法提供了标准化方式，并能突出字段特定性能的优势和不足。

Abstract: This paper presents methods for extracting structured information from
invoice documents and proposes a set of evaluation metrics (EM) to assess the
accuracy of the extracted data against annotated ground truth. The approach
involves pre-processing scanned or digital invoices, applying Docling and
LlamaCloud Services to identify and extract key fields such as invoice number,
date, total amount, and vendor details. To ensure the reliability of the
extraction process, we establish a robust evaluation framework comprising
field-level precision, consistency check failures, and exact match accuracy.
The proposed metrics provide a standardized way to compare different extraction
methods and highlight strengths and weaknesses in field-specific performance.

</details>


### [61] [AURA: An Agent Autonomy Risk Assessment Framework](https://arxiv.org/abs/2510.15739)
*Lorenzo Satta Chiris,Ayush Mishra*

Main category: cs.AI

TL;DR: AURA是一个统一的框架，用于检测、量化和缓解自主AI代理的风险。它采用基于gamma的风险评分方法，支持同步/异步多代理风险评估，并集成人机协同监督机制。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理系统在组织中日益普及，对齐、治理和风险管理方面的持续挑战阻碍了大规模部署。需要统一的框架来检测和缓解这些风险。

Method: AURA引入基于gamma的风险评分方法，平衡评估准确性与计算效率。提供交互式流程来评分、评估和缓解AI代理风险，支持人机协同监督和代理-人通信机制。

Result: 该框架能够实现自主自我评估，与现有协议(MCP和A2A)和工具互操作，提供强大的风险检测和缓解能力，同时平衡计算资源。

Conclusion: AURA支持负责任和透明的自主AI代理采用，是企业环境中大规模、可治理自主AI的关键推动因素。

Abstract: As autonomous agentic AI systems see increasing adoption across
organisations, persistent challenges in alignment, governance, and risk
management threaten to impede deployment at scale. We present AURA (Agent
aUtonomy Risk Assessment), a unified framework designed to detect, quantify,
and mitigate risks arising from agentic AI. Building on recent research and
practical deployments, AURA introduces a gamma-based risk scoring methodology
that balances risk assessment accuracy with computational efficiency and
practical considerations. AURA provides an interactive process to score,
evaluate and mitigate the risks of running one or multiple AI Agents,
synchronously or asynchronously (autonomously). The framework is engineered for
Human-in-the-Loop (HITL) oversight and presents Agent-to-Human (A2H)
communication mechanisms, allowing for seamless integration with agentic
systems for autonomous self-assessment, rendering it interoperable with
established protocols (MCP and A2A) and tools. AURA supports a responsible and
transparent adoption of agentic AI and provides robust risk detection and
mitigation while balancing computational resources, positioning it as a
critical enabler for large-scale, governable agentic AI in enterprise
environments.

</details>


### [62] [Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment](https://arxiv.org/abs/2510.15748)
*Minlin Zeng,Zhipeng Zhou,Yang Qiu,Zhiqi Shen*

Main category: cs.AI

TL;DR: 提出首个将帕金森病多模态评估建模为多目标优化问题的系统TRIP，解决了训练时模态同步和推理时模态依赖的限制。


<details>
  <summary>Details</summary>
Motivation: 多模态方法在帕金森病评估中表现出色，但存在两个主要限制：(1)训练时需要同步所有模态，(2)推理时依赖所有模态，这阻碍了实际应用。

Method: 将多模态学习建模为多目标优化问题，允许训练和推理时更灵活的模态要求；引入基于边界的类别重平衡策略缓解模态内不平衡问题。

Result: 在三个公共数据集上进行了广泛实验，在异步设置下比最佳基线分别提升16.48、6.89和11.55个百分点，在同步设置下分别提升4.86和2.30个百分点。

Conclusion: TRIP框架实现了最先进的性能，证明了其有效性和适应性，能够处理多模态信息融合中的模态崩溃问题。

Abstract: Parkinson's disease assessment has garnered growing interest in recent years,
particularly with the advent of sensor data and machine learning techniques.
Among these, multimodal approaches have demonstrated strong performance by
effectively integrating complementary information from various data sources.
However, two major limitations hinder their practical application: (1) the need
to synchronize all modalities during training, and (2) the dependence on all
modalities during inference. To address these issues, we propose the first
Parkinson's assessment system that formulates multimodal learning as a
multi-objective optimization (MOO) problem. This not only allows for more
flexible modality requirements during both training and inference, but also
handles modality collapse issue during multimodal information fusion. In
addition, to mitigate the imbalance within individual modalities, we introduce
a margin-based class rebalancing strategy to enhance category learning. We
conduct extensive experiments on three public datasets under both synchronous
and asynchronous settings. The results show that our framework-Towards Relaxed
InPuts (TRIP)-achieves state-of-the-art performance, outperforming the best
baselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous
setting, and by 4.86 and 2.30 percentage points in the synchronous setting,
highlighting its effectiveness and adaptability.

</details>


### [63] [Preliminary Quantitative Study on Explainability and Trust in AI Systems](https://arxiv.org/abs/2510.15769)
*Allen Daniel Sunny*

Main category: cs.AI

TL;DR: 该研究通过实验方法探讨了AI系统可解释性与用户信任之间的关系，发现交互式解释能增强用户参与度和信任度，解释的清晰度和相关性是信任的关键决定因素。


<details>
  <summary>Details</summary>
Motivation: 随着GPT-4等大规模AI模型在关键领域的部署，引发了关于AI系统信任和透明度的紧迫问题，需要研究可解释性如何影响用户信任。

Method: 采用定量实验设计，使用基于网络的交互式贷款审批模拟，比较不同类型的解释（从基本特征重要性到交互式反事实）对用户信任感知的影响。

Result: 结果表明交互性增强了用户参与度和信心，解释的清晰度和相关性是信任的关键决定因素。

Conclusion: 这些发现为人本可解释AI领域提供了实证证据，强调了可解释性设计对用户感知的可测量影响。

Abstract: Large-scale AI models such as GPT-4 have accelerated the deployment of
artificial intelligence across critical domains including law, healthcare, and
finance, raising urgent questions about trust and transparency. This study
investigates the relationship between explainability and user trust in AI
systems through a quantitative experimental design. Using an interactive,
web-based loan approval simulation, we compare how different types of
explanations, ranging from basic feature importance to interactive
counterfactuals influence perceived trust. Results suggest that interactivity
enhances both user engagement and confidence, and that the clarity and
relevance of explanations are key determinants of trust. These findings
contribute empirical evidence to the growing field of human-centered
explainable AI, highlighting measurable effects of explainability design on
user perception

</details>


### [64] [Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL](https://arxiv.org/abs/2510.15772)
*Richard M. Bailey*

Main category: cs.AI

TL;DR: Dialectica框架通过结构化对话、记忆、自我反思和政策约束的上下文编辑，使AI代理在复杂问题中发展专业知识，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决复杂多维问题（如司法框架、环境污染等）时，现有LLM缺乏通过经验发展专业知识的内生机制，需要新的方法来提升AI在开放不可验证领域的能力。

Method: 开发Dialectica框架，让代理在定义的主题上进行结构化对话，结合记忆、自我反思和政策约束的上下文编辑，将讨论视为隐式元强化学习过程。

Result: 在两个模型架构上的评估显示，启用基于反思的上下文编辑的代理在Elo分数、标准化Bradley-Terry-Davidson能力和AlphaRank质量上均优于基线模型。

Conclusion: 对话驱动的上下文演化是在开放不可验证领域实现目标专业知识放大的实用路径，定量和定性证据一致支持这一结论。

Abstract: So-called `wicked problems', those involving complex multi-dimensional
settings, non-verifiable outcomes, heterogeneous impacts and a lack of single
objectively correct answers, have plagued humans throughout history. Modern
examples include decisions over justice frameworks, solving environmental
pollution, planning for pandemic resilience and food security. The use of
state-of-the-art artificial intelligence systems (notably Large Language
Model-based agents) collaborating with humans on solving such problems is being
actively explored. While the abilities of LLMs can be improved by, for example,
fine-tuning, hand-crafted system prompts and scaffolding with external tools,
LLMs lack endogenous mechanisms to develop expertise through experience in such
settings. This work address this gap with Dialectica, a framework where agents
engage in structured dialogue on defined topics, augmented by memory,
self-reflection, and policy-constrained context editing. Formally, discussion
is viewed as an implicit meta-reinforcement learning process. The
`dialogue-trained' agents are evaluated post-hoc using judged pairwise
comparisons of elicited responses. Across two model architectures (locally run
Qwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based
context editing during discussion produces agents which dominate their baseline
counterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and
AlphaRank mass. The predicted signatures of learning are observed qualitatively
in statement and reflection logs, where reflections identify weaknesses and
reliably shape subsequent statements. Agreement between quantitative and
qualitative evidence supports dialogue-driven context evolution as a practical
path to targeted expertise amplification in open non-verifiable domains.

</details>


### [65] [Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID](https://arxiv.org/abs/2510.15782)
*Philip DiGiacomo,Haoyang Wang,Jinrui Fang,Yan Leng,W Michael Brode,Ying Ding*

Main category: cs.AI

TL;DR: 开发了6种RAG语料库配置用于长新冠临床问答，结合临床指南和高质量系统评价的配置表现最佳，提出了Guide-RAG系统来整合专家知识和文献数据库。


<details>
  <summary>Details</summary>
Motivation: 随着AI聊天机器人在临床医学中的应用增加，为复杂新兴疾病开发有效框架面临挑战，特别是针对长新冠这类疾病。

Method: 开发并评估了6种RAG语料库配置，从专家精选来源到大规模文献数据库，使用LLM作为评判框架，在忠实度、相关性和全面性指标上评估。

Result: 结合临床指南和高质量系统评价的RAG配置在各方面表现最优，优于单一指南方法和大规模文献数据库。

Conclusion: 对于新兴疾病，基于精选二次评价的检索在狭窄共识文档和未过滤原始文献之间提供了最佳平衡，支持临床决策同时避免信息过载和过度简化指导。

Abstract: As AI chatbots gain adoption in clinical medicine, developing effective
frameworks for complex, emerging diseases presents significant challenges. We
developed and evaluated six Retrieval-Augmented Generation (RAG) corpus
configurations for Long COVID (LC) clinical question answering, ranging from
expert-curated sources to large-scale literature databases. Our evaluation
employed an LLM-as-a-judge framework across faithfulness, relevance, and
comprehensiveness metrics using LongCOVID-CQ, a novel dataset of
expert-generated clinical questions. Our RAG corpus configuration combining
clinical guidelines with high-quality systematic reviews consistently
outperformed both narrow single-guideline approaches and large-scale literature
databases. Our findings suggest that for emerging diseases, retrieval grounded
in curated secondary reviews provides an optimal balance between narrow
consensus documents and unfiltered primary literature, supporting clinical
decision-making while avoiding information overload and oversimplified
guidance. We propose Guide-RAG, a chatbot system and accompanying evaluation
framework that integrates both curated expert knowledge and comprehensive
literature databases to effectively answer LC clinical questions.

</details>


### [66] [PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold](https://arxiv.org/abs/2510.15862)
*Yi Wan,Jiuqi Wang,Liam Li,Jinsong Liu,Ruihao Zhu,Zheqing Zhu*

Main category: cs.AI

TL;DR: PokeeResearch-7B是一个7B参数的深度研究智能体，通过统一的强化学习框架构建，在10个深度研究基准测试中达到7B规模的最优性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于工具增强的大语言模型的研究智能体存在检索浅层、对齐指标弱和工具使用行为脆弱等问题，需要开发更鲁棒、对齐和可扩展的深度研究智能体。

Method: 采用无标注的AI反馈强化学习框架，使用基于LLM的奖励信号优化策略，结合思维链驱动的多轮调用推理框架，实现自我验证和工具故障自适应恢复。

Result: 在10个流行的深度研究基准测试中，PokeeResearch-7B在7B规模的研究智能体中实现了最先进的性能。

Conclusion: 精心设计的强化学习和推理架构可以产生高效、有弹性和研究级的AI智能体，模型和推理代码已在MIT许可下开源。

Abstract: Tool-augmented large language models (LLMs) are emerging as deep research
agents, systems that decompose complex queries, retrieve external evidence, and
synthesize grounded responses. Yet current agents remain limited by shallow
retrieval, weak alignment metrics, and brittle tool-use behavior. We introduce
PokeeResearch-7B, a 7B-parameter deep research agent built under a unified
reinforcement learning framework for robustness, alignment, and scalability.
PokeeResearch-7B is trained by an annotation-free Reinforcement Learning from
AI Feedback (RLAIF) framework to optimize policies using LLM-based reward
signals that capture factual accuracy, citation faithfulness, and instruction
adherence. A chain-of-thought-driven multi-call reasoning scaffold further
enhances robustness through self-verification and adaptive recovery from tool
failures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves
state-of-the-art performance among 7B-scale deep research agents. This
highlights that careful reinforcement learning and reasoning design can produce
efficient, resilient, and research-grade AI agents. The model and inference
code is open-sourced under MIT license at
https://github.com/Pokee-AI/PokeeResearchOSS.

</details>
