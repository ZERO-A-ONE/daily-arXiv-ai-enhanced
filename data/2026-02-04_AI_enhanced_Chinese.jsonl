{"id": "2602.00066", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00066", "abs": "https://arxiv.org/abs/2602.00066", "authors": ["Zheng Fang", "Yihong Dong", "Lili Mou", "Dongming Jin", "Zhi Jin", "Ge Li"], "title": "IntentCoding: Amplifying User Intent in Code Generation", "comment": null, "summary": "Large Language Models (LLMs) have shown strong capabilities in code generation, but their adherence to fine-grained user intent with multiple constraints remains a significant challenge. Our empirical analysis reveals two key observations: 1) Model performance deteriorates quickly as the number of constraints in the user intent increases, and 2) While user intent does influence the model's logits, such an influence may not be strong enough to effectively steer the decoding process. To this end, we propose Intent-Amplified Code Generation (IntentCoding), a novel decoding strategy that enhances an LLM's ability to follow user intent. IntentCoding captures the influence of user intent by masking out the intent, and applies a multi-strength ensemble mechanism to amplify the effect of user intent during generation. IntentCoding is model-agnostic, requires no additional training, and integrates seamlessly with existing decoding procedures. To enable systematic evaluation, we also construct CodeConstraints, a benchmark dataset specifically designed to test user intent compliance under varying numbers of constraints. Experiments on our constructed Constraints, as well as popular IFEvalCode, HumanEval and LiveCodeBench datasets, show that our IntentCoding model significantly improves both constraint satisfaction and functional correctness compared to standard decoding approaches. IntentCoding achieves up to 71.0% relative improvement on CodeConstraints, achieves up to 67.3% relative improvement on IFEvalCode and achieves up to 29.3% relative improvement in pass@1 on HumanEval and LiveCodeBench compared with greedy decoding.", "AI": {"tldr": "IntentCoding\u662f\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u63a9\u853d\u7528\u6237\u610f\u56fe\u548c\u591a\u5f3a\u5ea6\u96c6\u6210\u673a\u5236\u6765\u589e\u5f3aLLM\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u9075\u5faa\u7528\u6237\u7ea6\u675f\u7684\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u4e14\u4e0e\u73b0\u6709\u89e3\u7801\u65b9\u6cd5\u517c\u5bb9\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9075\u5faa\u5305\u542b\u591a\u4e2a\u7ea6\u675f\u7684\u7ec6\u7c92\u5ea6\u7528\u6237\u610f\u56fe\u65b9\u9762\u5b58\u5728\u663e\u8457\u6311\u6218\u3002\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0\uff1a1\uff09\u968f\u7740\u7528\u6237\u610f\u56fe\u4e2d\u7ea6\u675f\u6570\u91cf\u7684\u589e\u52a0\uff0c\u6a21\u578b\u6027\u80fd\u8fc5\u901f\u4e0b\u964d\uff1b2\uff09\u7528\u6237\u610f\u56fe\u867d\u7136\u5f71\u54cd\u6a21\u578b\u7684logits\uff0c\u4f46\u8fd9\u79cd\u5f71\u54cd\u4e0d\u8db3\u4ee5\u6709\u6548\u5f15\u5bfc\u89e3\u7801\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faIntent-Amplified Code Generation (IntentCoding)\u89e3\u7801\u7b56\u7565\uff1a\u901a\u8fc7\u63a9\u853d\u7528\u6237\u610f\u56fe\u6765\u6355\u83b7\u5176\u5f71\u54cd\uff0c\u5e76\u5e94\u7528\u591a\u5f3a\u5ea6\u96c6\u6210\u673a\u5236\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u653e\u5927\u7528\u6237\u610f\u56fe\u7684\u6548\u679c\u3002\u8be5\u65b9\u6cd5\u4e0e\u6a21\u578b\u65e0\u5173\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u53ef\u4e0e\u73b0\u6709\u89e3\u7801\u8fc7\u7a0b\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u5728\u6784\u5efa\u7684CodeConstraints\u57fa\u51c6\u6570\u636e\u96c6\u4ee5\u53caIFEvalCode\u3001HumanEval\u548cLiveCodeBench\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cIntentCoding\u76f8\u6bd4\u6807\u51c6\u89e3\u7801\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u7ea6\u675f\u6ee1\u8db3\u5ea6\u548c\u529f\u80fd\u6b63\u786e\u6027\u3002\u5728CodeConstraints\u4e0a\u76f8\u5bf9\u6539\u8fdb\u8fbe71.0%\uff0c\u5728IFEvalCode\u4e0a\u8fbe67.3%\uff0c\u5728HumanEval\u548cLiveCodeBench\u7684pass@1\u4e0a\u8fbe29.3%\u3002", "conclusion": "IntentCoding\u662f\u4e00\u79cd\u6709\u6548\u7684\u89e3\u7801\u7b56\u7565\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347LLM\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u9075\u5faa\u7528\u6237\u610f\u56fe\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u591a\u4e2a\u7ea6\u675f\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u5177\u6709\u6a21\u578b\u65e0\u5173\u6027\u548c\u65e0\u9700\u8bad\u7ec3\u7684\u4f18\u52bf\u3002"}}
{"id": "2602.00180", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00180", "abs": "https://arxiv.org/abs/2602.00180", "authors": ["Deepak Babu Piskala"], "title": "Spec-Driven Development:From Code to Contract in the Age of AI Coding Assistants", "comment": "Submitted to AIWare 2026. 8 pages, 3 figures", "summary": "The rise of AI coding assistants has reignited interest in an old idea: what if specifications-not code-were the primary artifact of software development? Spec-driven development (SDD) inverts the traditional workflow by treating specifications as the source of truth and code as a generated or verified secondary artifact. This paper provides practitioners with a comprehensive guide to SDD, covering its principles, workflow patterns, and supporting tools. We present three levels of specification rigor-spec-first, spec-anchored, and spec-as-source-with clear guidance on when each applies. Through analysis of tools ranging from Behavior-Driven Development frameworks to modern AI-assisted toolkits like GitHub Spec Kit, we demonstrate how the spec-first philosophy maps to real implementations. We present case studies from API development, enterprise systems, and embedded software, illustrating how different domains apply SDD. We conclude with a decision framework helping practitioners determine when SDD provides value and when simpler approaches suffice.", "AI": {"tldr": "\u672c\u6587\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u89c4\u8303\u9a71\u52a8\u5f00\u53d1(SDD)\u7684\u5168\u9762\u6307\u5357\uff0c\u5c06\u89c4\u8303\u89c6\u4e3a\u4e3b\u8981\u5de5\u4ef6\u800c\u975e\u4ee3\u7801\uff0c\u4ecb\u7ecd\u4e86\u4e09\u79cd\u89c4\u8303\u4e25\u683c\u7ea7\u522b\uff0c\u5206\u6790\u4e86\u76f8\u5173\u5de5\u5177\u548c\u6848\u4f8b\u7814\u7a76\uff0c\u5e76\u63d0\u4f9b\u4e86\u51b3\u7b56\u6846\u67b6\u3002", "motivation": "AI\u7f16\u7a0b\u52a9\u624b\u7684\u5174\u8d77\u91cd\u65b0\u6fc0\u53d1\u4e86\u4eba\u4eec\u5bf9\u4e00\u4e2a\u65e7\u7406\u5ff5\u7684\u5174\u8da3\uff1a\u5982\u679c\u89c4\u8303\u800c\u975e\u4ee3\u7801\u6210\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u7684\u4e3b\u8981\u5de5\u4ef6\u4f1a\u600e\u6837\uff1f\u4f20\u7edf\u5de5\u4f5c\u6d41\u7a0b\u5c06\u4ee3\u7801\u89c6\u4e3a\u4e3b\u8981\u4ea7\u7269\uff0c\u800cSDD\u5c06\u89c4\u8303\u4f5c\u4e3a\u771f\u7406\u6765\u6e90\uff0c\u4ee3\u7801\u5219\u4f5c\u4e3a\u751f\u6210\u6216\u9a8c\u8bc1\u7684\u6b21\u8981\u4ea7\u7269\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u89c4\u8303\u4e25\u683c\u7ea7\u522b\uff1a\u89c4\u8303\u4f18\u5148(spec-first)\u3001\u89c4\u8303\u951a\u5b9a(spec-anchored)\u548c\u89c4\u8303\u5373\u6e90(spec-as-source)\uff1b\u5206\u6790\u4e86\u4ece\u884c\u4e3a\u9a71\u52a8\u5f00\u53d1\u6846\u67b6\u5230\u73b0\u4ee3AI\u8f85\u52a9\u5de5\u5177\u5982GitHub Spec Kit\u7b49\u5de5\u5177\uff1b\u901a\u8fc7API\u5f00\u53d1\u3001\u4f01\u4e1a\u7cfb\u7edf\u548c\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u7b49\u9886\u57df\u7684\u6848\u4f8b\u7814\u7a76\u5c55\u793aSDD\u7684\u5b9e\u9645\u5e94\u7528\u3002", "result": "\u5c55\u793a\u4e86\u89c4\u8303\u4f18\u5148\u54f2\u5b66\u5982\u4f55\u6620\u5c04\u5230\u5b9e\u9645\u5b9e\u73b0\u4e2d\uff0c\u4e0d\u540c\u9886\u57df\u5982\u4f55\u5e94\u7528SDD\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u6307\u5bfc\u8bf4\u660e\u6bcf\u79cd\u89c4\u8303\u4e25\u683c\u7ea7\u522b\u7684\u9002\u7528\u573a\u666f\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u51b3\u7b56\u6846\u67b6\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u786e\u5b9aSDD\u4f55\u65f6\u80fd\u63d0\u4f9b\u4ef7\u503c\uff0c\u4ee5\u53ca\u4f55\u65f6\u66f4\u7b80\u5355\u7684\u65b9\u6cd5\u5c31\u8db3\u591f\u4e86\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6307\u5bfc\u3002"}}
{"id": "2602.00303", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.00303", "abs": "https://arxiv.org/abs/2602.00303", "authors": ["Jyoti Prakash", "Abhishek Tiwari", "Mikkel Baun Kj\u00e6rgaard"], "title": "Towards Analyzing N-language Polyglot Programs", "comment": null, "summary": "Polyglot programming is gaining popularity as developers integrate multiple programming languages to harness their individual strengths. With the recent popularity of platforms like GraalVM and other multi-language runtimes, creating and managing these systems has become much more feasible. However, current research on analyzing multilingual programs mainly focuses on two languages, leaving out the increasing complexity of systems that use three or more. For example, modern web systems often link JavaScript, WebAssembly, and Rust within the same execution chain. This paper envisions the landscape of software systems with three-language polyglot communication. We identify fundamental challenges in analyzing them and propose a conceptual roadmap to advance static analysis techniques to address them. Our vision aims to stimulate discussion and inspire new research directions toward scalable, language-agnostic analysis frameworks for next-generation polyglot systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4e09\u8bed\u8a00\u53ca\u4ee5\u4e0a\u591a\u8bed\u8a00\u7cfb\u7edf\u7684\u9759\u6001\u5206\u6790\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u7684\u6982\u5ff5\u8def\u7ebf\u56fe\uff0c\u65e8\u5728\u63a8\u52a8\u53ef\u6269\u5c55\u3001\u8bed\u8a00\u65e0\u5173\u7684\u5206\u6790\u6846\u67b6\u7814\u7a76\u3002", "motivation": "\u968f\u7740GraalVM\u7b49\u591a\u8bed\u8a00\u8fd0\u884c\u65f6\u7684\u6d41\u884c\uff0c\u591a\u8bed\u8a00\u7f16\u7a0b\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4e24\u79cd\u8bed\u8a00\u7684\u5206\u6790\uff0c\u5ffd\u7565\u4e86\u4f7f\u7528\u4e09\u79cd\u53ca\u4ee5\u4e0a\u8bed\u8a00\u7684\u7cfb\u7edf\u590d\u6742\u6027\u3002\u73b0\u4ee3Web\u7cfb\u7edf\u7ecf\u5e38\u5728\u540c\u4e00\u4e2a\u6267\u884c\u94fe\u4e2d\u96c6\u6210JavaScript\u3001WebAssembly\u548cRust\u7b49\u591a\u79cd\u8bed\u8a00\u3002", "method": "\u672c\u6587\u9996\u5148\u8bc6\u522b\u4e09\u8bed\u8a00\u591a\u8bed\u8a00\u901a\u4fe1\u7cfb\u7edf\u7684\u57fa\u672c\u5206\u6790\u6311\u6218\uff0c\u7136\u540e\u63d0\u51fa\u4e00\u4e2a\u6982\u5ff5\u8def\u7ebf\u56fe\uff0c\u65e8\u5728\u63a8\u8fdb\u9759\u6001\u5206\u6790\u6280\u672f\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "result": "\u63d0\u51fa\u4e86\u9488\u5bf9\u4e09\u8bed\u8a00\u591a\u8bed\u8a00\u7cfb\u7edf\u7684\u5206\u6790\u6311\u6218\u8bc6\u522b\u548c\u89e3\u51b3\u65b9\u6848\u8def\u7ebf\u56fe\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u6027\u6307\u5bfc\u3002", "conclusion": "\u672c\u6587\u65e8\u5728\u6fc0\u53d1\u8ba8\u8bba\u5e76\u542f\u53d1\u65b0\u7684\u7814\u7a76\u65b9\u5411\uff0c\u63a8\u52a8\u9762\u5411\u4e0b\u4e00\u4ee3\u591a\u8bed\u8a00\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u3001\u8bed\u8a00\u65e0\u5173\u5206\u6790\u6846\u67b6\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.00053", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00053", "abs": "https://arxiv.org/abs/2602.00053", "authors": ["Ratul Ali"], "title": "Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes", "comment": "2 pages, 2 figures, 1 table", "summary": "Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing requirements, including minimizing inference latency for real-time clinical decision support, maximizing throughput for batch processing of medical records, and ensuring strict adherence to data privacy standards such as HIPAA. This paper presents a rigorous benchmarking analysis comparing two prominent deployment paradigms: a lightweight, Python-based REST service using FastAPI, and a specialized, high-performance serving engine, NVIDIA Triton Inference Server. Leveraging a reference architecture for healthcare AI, we deployed a DistilBERT sentiment analysis model on Kubernetes to measure median (p50) and tail (p95) latency, as well as throughput, under controlled experimental conditions. Our results indicate a distinct trade-off. While FastAPI provides lower overhead for single-request workloads with a p50 latency of 22 ms, Triton achieves superior scalability through dynamic batching, delivering a throughput of 780 requests per second on a single NVIDIA T4 GPU, nearly double that of the baseline. Furthermore, we evaluate a hybrid architectural approach that utilizes FastAPI as a secure gateway for protected health information de-identification and Triton for backend inference. This study validates the hybrid model as a best practice for enterprise clinical AI and offers a blueprint for secure, high-availability deployments.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4e86FastAPI\u548cNVIDIA Triton\u4e24\u79cdML\u6a21\u578b\u90e8\u7f72\u65b9\u6848\u5728\u533b\u7597\u9886\u57df\u7684\u6027\u80fd\u8868\u73b0\uff0c\u53d1\u73b0FastAPI\u5728\u5355\u8bf7\u6c42\u5ef6\u8fdf\u4e0a\u66f4\u4f18\uff0822ms\uff09\uff0c\u800cTriton\u901a\u8fc7\u52a8\u6001\u6279\u5904\u7406\u5b9e\u73b0\u66f4\u9ad8\u7684\u541e\u5410\u91cf\uff08780 RPS\uff09\u3002\u6700\u7ec8\u63d0\u51fa\u7ed3\u5408\u4e24\u8005\u7684\u6df7\u5408\u67b6\u6784\u4f5c\u4e3a\u4f01\u4e1a\u4e34\u5e8aAI\u7684\u6700\u4f73\u5b9e\u8df5\u3002", "motivation": "\u5728\u533b\u7597\u548c\u5236\u836f\u7b49\u53d7\u76d1\u7ba1\u9886\u57df\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u90e8\u7f72\u9700\u8981\u5e73\u8861\u591a\u4e2a\u7ade\u4e89\u6027\u9700\u6c42\uff1a\u6700\u5c0f\u5316\u5b9e\u65f6\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7684\u63a8\u7406\u5ef6\u8fdf\u3001\u6700\u5927\u5316\u533b\u7597\u8bb0\u5f55\u6279\u91cf\u5904\u7406\u7684\u541e\u5410\u91cf\uff0c\u5e76\u786e\u4fdd\u4e25\u683c\u9075\u5b88HIPAA\u7b49\u6570\u636e\u9690\u79c1\u6807\u51c6\u3002\u9700\u8981\u627e\u5230\u9002\u5408\u751f\u4ea7\u73af\u5883\u7684\u9ad8\u6548\u53ef\u6269\u5c55\u90e8\u7f72\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e25\u683c\u7684\u57fa\u51c6\u6d4b\u8bd5\u5206\u6790\uff0c\u6bd4\u8f83\u4e24\u79cd\u90e8\u7f72\u8303\u5f0f\uff1a\u57fa\u4e8ePython\u7684FastAPI REST\u670d\u52a1\u548c\u4e13\u95e8\u7684NVIDIA Triton\u63a8\u7406\u670d\u52a1\u5668\u3002\u5728Kubernetes\u4e0a\u90e8\u7f72DistilBERT\u60c5\u611f\u5206\u6790\u6a21\u578b\uff0c\u5728\u53d7\u63a7\u5b9e\u9a8c\u6761\u4ef6\u4e0b\u6d4b\u91cf\u4e2d\u4f4d\u6570\uff08p50\uff09\u548c\u5c3e\u90e8\uff08p95\uff09\u5ef6\u8fdf\u4ee5\u53ca\u541e\u5410\u91cf\u3002\u8fd8\u8bc4\u4f30\u4e86\u6df7\u5408\u67b6\u6784\u65b9\u6cd5\uff0c\u4f7f\u7528FastAPI\u4f5c\u4e3a\u53d7\u4fdd\u62a4\u5065\u5eb7\u4fe1\u606f\u53bb\u8bc6\u522b\u7684\u5b89\u5168\u7f51\u5173\uff0cTriton\u4f5c\u4e3a\u540e\u7aef\u63a8\u7406\u5f15\u64ce\u3002", "result": "FastAPI\u5728\u5355\u8bf7\u6c42\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u5177\u6709\u8f83\u4f4e\u7684\u5f00\u9500\uff0cp50\u5ef6\u8fdf\u4e3a22ms\uff1b\u800cTriton\u901a\u8fc7\u52a8\u6001\u6279\u5904\u7406\u5b9e\u73b0\u5353\u8d8a\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5728\u5355\u4e2aNVIDIA T4 GPU\u4e0a\u8fbe\u5230\u6bcf\u79d2780\u4e2a\u8bf7\u6c42\u7684\u541e\u5410\u91cf\uff0c\u51e0\u4e4e\u662f\u57fa\u7ebf\u7684\u4e24\u500d\u3002\u6df7\u5408\u67b6\u6784\u5728\u5b89\u5168\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002", "conclusion": "\u6df7\u5408\u67b6\u6784\uff08FastAPI\u4f5c\u4e3a\u5b89\u5168\u7f51\u5173\u5904\u7406PHI\u53bb\u8bc6\u522b\uff0cTriton\u8d1f\u8d23\u540e\u7aef\u63a8\u7406\uff09\u88ab\u9a8c\u8bc1\u4e3a\u4f01\u4e1a\u4e34\u5e8aAI\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u4e3a\u5b89\u5168\u3001\u9ad8\u53ef\u7528\u6027\u90e8\u7f72\u63d0\u4f9b\u4e86\u84dd\u56fe\u3002\u8fd9\u79cd\u65b9\u6848\u65e2\u80fd\u6ee1\u8db3\u533b\u7597\u9886\u57df\u7684\u9690\u79c1\u5408\u89c4\u8981\u6c42\uff0c\u53c8\u80fd\u5b9e\u73b0\u9ad8\u6027\u80fd\u63a8\u7406\u3002"}}
{"id": "2602.00410", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00410", "abs": "https://arxiv.org/abs/2602.00410", "authors": ["Andre Hora"], "title": "GitEvo: Code Evolution Analysis for Git Repositories", "comment": "Accepted for publication at MSR 2026", "summary": "Analyzing the code evolution of software systems is relevant for practitioners, researchers, and educators. It can help practitioners identify design trends and maintenance challenges, provide researchers with empirical data to study changes over time, and give educators real-world examples that enhance the teaching of software evolution concepts. Unfortunately, we lack tools specifically designed to support code evolution analysis. In this paper, we propose GitEvo, a multi-language and extensible tool for analyzing code evolution in Git repositories. GitEvo leverages Git frameworks and code parsing tools to integrate both Git-level and code-level analysis. We conclude by describing how GitEvo can support the development of novel empirical studies on code evolution and act as a learning tool for educators and students. GitEvo is available at: https://github.com/andrehora/gitevo.", "AI": {"tldr": "GitEvo\u662f\u4e00\u4e2a\u7528\u4e8e\u5206\u6790Git\u4ed3\u5e93\u4e2d\u4ee3\u7801\u6f14\u5316\u7684\u591a\u8bed\u8a00\u53ef\u6269\u5c55\u5de5\u5177\uff0c\u96c6\u6210\u4e86Git\u5c42\u9762\u548c\u4ee3\u7801\u5c42\u9762\u7684\u5206\u6790\uff0c\u652f\u6301\u5b9e\u8bc1\u7814\u7a76\u548c\u6559\u5b66\u5e94\u7528\u3002", "motivation": "\u5206\u6790\u8f6f\u4ef6\u7cfb\u7edf\u7684\u4ee3\u7801\u6f14\u5316\u5bf9\u4ece\u4e1a\u8005\u3001\u7814\u7a76\u8005\u548c\u6559\u80b2\u8005\u90fd\u5f88\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u4e13\u95e8\u652f\u6301\u4ee3\u7801\u6f14\u5316\u5206\u6790\u7684\u5de5\u5177\u3002", "method": "GitEvo\u5229\u7528Git\u6846\u67b6\u548c\u4ee3\u7801\u89e3\u6790\u5de5\u5177\uff0c\u96c6\u6210Git\u5c42\u9762\u548c\u4ee3\u7801\u5c42\u9762\u7684\u5206\u6790\uff0c\u652f\u6301\u591a\u8bed\u8a00\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5f00\u53d1\u4e86GitEvo\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u652f\u6301\u4ee3\u7801\u6f14\u5316\u7684\u65b0\u9896\u5b9e\u8bc1\u7814\u7a76\uff0c\u5e76\u4f5c\u4e3a\u6559\u80b2\u8005\u548c\u5b66\u751f\u7684\u5b66\u4e60\u5de5\u5177\u3002", "conclusion": "GitEvo\u586b\u8865\u4e86\u4ee3\u7801\u6f14\u5316\u5206\u6790\u5de5\u5177\u7684\u7a7a\u767d\uff0c\u4e3a\u5b9e\u8df5\u3001\u7814\u7a76\u548c\u6559\u80b2\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u652f\u6301\u3002"}}
{"id": "2602.00715", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00715", "abs": "https://arxiv.org/abs/2602.00715", "authors": ["Zehan Chen", "Long Zhang", "Zhiwei Zhang", "JingJing Zhang", "Ruoyu Zhou", "Yulong Shen", "JianFeng Ma", "Lin Yang"], "title": "Beyond Basic Specifications? A Systematic Study of Logical Constructs in LLM-based Specification Generation", "comment": null, "summary": "Formal specifications play a pivotal role in accurately characterizing program behaviors and ensuring software correctness. In recent years, leveraging large language models (LLMs) for the automatic generation of program specifications has emerged as a promising avenue for enhancing verification efficiency. However, existing research has been predominantly confined to generating specifications based on basic syntactic constructs, falling short of meeting the demands for high-level abstraction in complex program verification. Consequently, we propose incorporating logical constructs into existing LLM-based specification generation framework. Nevertheless, there remains a lack of systematic investigation into whether LLMs can effectively generate such complex constructs. To this end, we conduct an empirical study aimed at exploring the impact of various types of syntactic constructs on specification generation framework. Specifically, we define four syntactic configurations with varying levels of abstraction and perform extensive evaluations on mainstream program verification datasets, employing a diverse set of representative LLMs. Experimental results first confirm that LLMs are capable of generating valid logical constructs. Further analysis reveals that the synergistic use of logical constructs and basic syntactic constructs leads to improvements in both verification capability and robustness, without significantly increasing verification overhead. Additionally, we uncover the distinct advantages of two refinement paradigms. To the best of our knowledge, this is the first systematic work exploring the feasibility of utilizing LLMs for generating high-level logical constructs, providing an empirical basis and guidance for the future construction of automated program verification framework with enhanced abstraction capabilities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7a0b\u5e8f\u89c4\u8303\u751f\u6210\u6846\u67b6\u4e2d\u5f15\u5165\u903b\u8f91\u6784\u9020\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u903b\u8f91\u6784\u9020\u4e0e\u57fa\u672c\u8bed\u6cd5\u6784\u9020\u7684\u534f\u540c\u4f7f\u7528\u80fd\u63d0\u5347\u9a8c\u8bc1\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u4e14\u4e0d\u663e\u8457\u589e\u52a0\u9a8c\u8bc1\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7a0b\u5e8f\u89c4\u8303\u751f\u6210\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u57fa\u672c\u8bed\u6cd5\u6784\u9020\uff0c\u65e0\u6cd5\u6ee1\u8db3\u590d\u6742\u7a0b\u5e8f\u9a8c\u8bc1\u5bf9\u9ad8\u7ea7\u62bd\u8c61\u7684\u9700\u6c42\u3002\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u6709\u6548\u751f\u6210\u590d\u6742\u7684\u903b\u8f91\u6784\u9020\uff0c\u4ee5\u63d0\u5347\u7a0b\u5e8f\u9a8c\u8bc1\u6846\u67b6\u7684\u62bd\u8c61\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u5728\u73b0\u6709LLM\u89c4\u8303\u751f\u6210\u6846\u67b6\u4e2d\u5f15\u5165\u903b\u8f91\u6784\u9020\uff0c\u5b9a\u4e49\u4e86\u56db\u79cd\u4e0d\u540c\u62bd\u8c61\u5c42\u6b21\u7684\u8bed\u6cd5\u914d\u7f6e\uff0c\u5728\u4e3b\u6d41\u7a0b\u5e8f\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u4f7f\u7528\u591a\u79cd\u4ee3\u8868\u6027\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u9996\u5148\u8bc1\u5b9e\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u751f\u6210\u6709\u6548\u7684\u903b\u8f91\u6784\u9020\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u8868\u660e\uff0c\u903b\u8f91\u6784\u9020\u4e0e\u57fa\u672c\u8bed\u6cd5\u6784\u9020\u7684\u534f\u540c\u4f7f\u7528\u80fd\u540c\u65f6\u63d0\u5347\u9a8c\u8bc1\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u4e14\u4e0d\u663e\u8457\u589e\u52a0\u9a8c\u8bc1\u5f00\u9500\u3002\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u4e24\u79cd\u7ec6\u5316\u8303\u5f0f\u7684\u72ec\u7279\u4f18\u52bf\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u7cfb\u7edf\u63a2\u7d22\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u7ea7\u903b\u8f91\u6784\u9020\u53ef\u884c\u6027\u7684\u5de5\u4f5c\uff0c\u4e3a\u672a\u6765\u6784\u5efa\u5177\u6709\u589e\u5f3a\u62bd\u8c61\u80fd\u529b\u7684\u81ea\u52a8\u5316\u7a0b\u5e8f\u9a8c\u8bc1\u6846\u67b6\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u548c\u6307\u5bfc\u3002"}}
{"id": "2602.00276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00276", "abs": "https://arxiv.org/abs/2602.00276", "authors": ["Aditya Kumar", "William W. Cohen"], "title": "Localizing and Correcting Errors for LLM-based Planners", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong reasoning capabilities on math and coding, but frequently fail on symbolic classical planning tasks. Our studies, as well as prior work, show that LLM-generated plans routinely violate domain constraints given in their instructions (e.g., walking through walls). To address this failure, we propose iteratively augmenting instructions with Localized In-Context Learning (L-ICL) demonstrations: targeted corrections for specific failing steps. Specifically, L-ICL identifies the first constraint violation in a trace and injects a minimal input-output example giving the correct behavior for the failing step. Our proposed technique of L-ICL is much effective than explicit instructions or traditional ICL, which adds complete problem-solving trajectories, and many other baselines. For example, on an 8x8 gridworld, L-ICL produces valid plans 89% of the time with only 60 training examples, compared to 59% for the best baseline, an increase of 30%. L-ICL also shows dramatic improvements in other domains (gridworld navigation, mazes, Sokoban, and BlocksWorld), and on several LLM architectures.", "AI": {"tldr": "LLMs\u5728\u7b26\u53f7\u89c4\u5212\u4efb\u52a1\u4e2d\u7ecf\u5e38\u8fdd\u53cd\u9886\u57df\u7ea6\u675f\uff0c\u4f5c\u8005\u63d0\u51fa\u5c40\u90e8\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08L-ICL\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u4fee\u6b63\u5931\u8d25\u6b65\u9aa4\u6765\u663e\u8457\u63d0\u5347\u89c4\u5212\u6709\u6548\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u7b26\u53f7\u7ecf\u5178\u89c4\u5212\u4efb\u52a1\u4e2d\u7ecf\u5e38\u5931\u8d25\uff0c\u751f\u6210\u7684\u8ba1\u5212\u7ecf\u5e38\u8fdd\u53cd\u7ed9\u5b9a\u7684\u9886\u57df\u7ea6\u675f\uff08\u5982\u7a7f\u5899\uff09\u3002\u73b0\u6709\u65b9\u6cd5\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5c40\u90e8\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08L-ICL\uff09\u65b9\u6cd5\uff1a\u8fed\u4ee3\u5730\u5728\u6307\u4ee4\u4e2d\u6ce8\u5165\u9488\u5bf9\u6027\u4fee\u6b63\u6f14\u793a\u3002\u5177\u4f53\u8bc6\u522b\u8f68\u8ff9\u4e2d\u7684\u7b2c\u4e00\u4e2a\u7ea6\u675f\u8fdd\u53cd\uff0c\u4e3a\u5931\u8d25\u6b65\u9aa4\u6ce8\u5165\u6700\u5c0f\u5316\u7684\u8f93\u5165-\u8f93\u51fa\u793a\u4f8b\uff0c\u5c55\u793a\u6b63\u786e\u884c\u4e3a\u3002", "result": "L-ICL\u663e\u8457\u4f18\u4e8e\u663e\u5f0f\u6307\u4ee4\u6216\u4f20\u7edfICL\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002\u57288x8\u7f51\u683c\u4e16\u754c\u4e2d\uff0c\u4ec5\u752860\u4e2a\u8bad\u7ec3\u793a\u4f8b\u5c31\u80fd\u4ea7\u751f89%\u7684\u6709\u6548\u8ba1\u5212\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\uff0859%\uff09\u63d0\u9ad830%\u3002\u5728\u5176\u4ed6\u9886\u57df\uff08\u8ff7\u5bab\u3001Sokoban\u3001BlocksWorld\uff09\u548c\u591a\u79cdLLM\u67b6\u6784\u4e0a\u4e5f\u663e\u793a\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u5c40\u90e8\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08L-ICL\uff09\u662f\u4e00\u79cd\u6709\u6548\u7684\u6280\u672f\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8LLM\u5728\u7b26\u53f7\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u4fee\u6b63\u5931\u8d25\u6b65\u9aa4\u6765\u786e\u4fdd\u751f\u6210\u7684\u8ba1\u5212\u7b26\u5408\u9886\u57df\u7ea6\u675f\u3002"}}
{"id": "2602.00746", "categories": ["cs.SE", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00746", "abs": "https://arxiv.org/abs/2602.00746", "authors": ["Jianping Zhong", "Guochang Li", "Chen Zhi", "Junxiao Han", "Zhen Qin", "Xinkui Zhao", "Nan Wang", "Shuiguang Deng", "Jianwei Yin"], "title": "Can Vision-Language Models Handle Long-Context Code? An Empirical Study on Visual Compression", "comment": null, "summary": "Large Language Models (LLMs) struggle with long-context code due to window limitations. Existing textual code compression methods mitigate this via selective filtering but often disrupt dependency closure, causing semantic fragmentation. To address this, we introduce LongCodeOCR, a visual compression framework that renders code into compressed two-dimensional image sequences for Vision-Language Models (VLMs). By preserving a global view, this approach avoids the dependency breakage inherent in filtering. We systematically evaluate LongCodeOCR against the state-of-the-art LongCodeZip across four benchmarks spanning code summarization, code question answering, and code completion.\n  Our results demonstrate that visual code compression serves as a viable alternative for tasks requiring global understanding. At comparable compression ratios ($\\sim$1.7$\\times$), LongCodeOCR improves CompScore on Long Module Summarization by 36.85 points over LongCodeZip. At a 1M-token context length with Glyph (a specialized 9B VLM), LongCodeOCR maintains higher accuracy than LongCodeZip while operating at about 4$\\times$ higher compression. Moreover, compared with LongCodeZip, LongCodeOCR drastically reduces compression-stage overhead (reducing latency from $\\sim$4.3 hours to $\\sim$1 minute at 1M tokens). Finally, our results characterize a fundamental coverage--fidelity trade-off: visual code compression retains broader context coverage to support global dependencies, yet faces fidelity bottlenecks on exactness-critical tasks; by contrast, textual code compression preserves symbol-level precision while sacrificing structural coverage.", "AI": {"tldr": "LongCodeOCR\u662f\u4e00\u4e2a\u89c6\u89c9\u538b\u7f29\u6846\u67b6\uff0c\u5c06\u4ee3\u7801\u8f6c\u6362\u4e3a\u538b\u7f29\u7684\u4e8c\u7ef4\u56fe\u50cf\u5e8f\u5217\u4f9b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5904\u7406\uff0c\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u4ee3\u7801\u65f6\u7684\u7a97\u53e3\u9650\u5236\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u4e86\u4f20\u7edf\u6587\u672c\u538b\u7f29\u65b9\u6cd5\u5bfc\u81f4\u7684\u4f9d\u8d56\u5173\u7cfb\u65ad\u88c2\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u4ee3\u7801\u65f6\u9762\u4e34\u7a97\u53e3\u9650\u5236\u95ee\u9898\u3002\u73b0\u6709\u7684\u6587\u672c\u4ee3\u7801\u538b\u7f29\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u6027\u8fc7\u6ee4\u6765\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u5f80\u5f80\u4f1a\u7834\u574f\u4f9d\u8d56\u5173\u7cfb\u7684\u5b8c\u6574\u6027\uff0c\u5bfc\u81f4\u8bed\u4e49\u788e\u7247\u5316\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u538b\u7f29\u4ee3\u7801\u957f\u5ea6\u53c8\u80fd\u4fdd\u6301\u5168\u5c40\u4f9d\u8d56\u5173\u7cfb\u7684\u65b9\u6cd5\u3002", "method": "LongCodeOCR\u662f\u4e00\u4e2a\u89c6\u89c9\u538b\u7f29\u6846\u67b6\uff0c\u5c06\u4ee3\u7801\u6e32\u67d3\u6210\u538b\u7f29\u7684\u4e8c\u7ef4\u56fe\u50cf\u5e8f\u5217\uff0c\u4f9b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5904\u7406\u3002\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7\u4fdd\u7559\u5168\u5c40\u89c6\u56fe\uff0c\u907f\u514d\u4e86\u8fc7\u6ee4\u65b9\u6cd5\u56fa\u6709\u7684\u4f9d\u8d56\u5173\u7cfb\u65ad\u88c2\u95ee\u9898\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLongCodeOCR\u5728\u4ee3\u7801\u603b\u7ed3\u3001\u4ee3\u7801\u95ee\u7b54\u548c\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684LongCodeZip\u65b9\u6cd5\u3002\u5728\u76f8\u4f3c\u538b\u7f29\u6bd4\u4e0b\uff0cLongCodeOCR\u5728\u957f\u6a21\u5757\u603b\u7ed3\u4efb\u52a1\u4e0a\u7684CompScore\u63d0\u9ad8\u4e8636.85\u5206\u3002\u5728100\u4e07token\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\uff0cLongCodeOCR\u4fdd\u6301\u4e86\u6bd4LongCodeZip\u66f4\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u7ea64\u500d\u7684\u66f4\u9ad8\u538b\u7f29\u7387\u3002\u6b64\u5916\uff0cLongCodeOCR\u663e\u8457\u51cf\u5c11\u4e86\u538b\u7f29\u9636\u6bb5\u7684\u5f00\u9500\uff0c\u5c06\u5ef6\u8fdf\u4ece\u7ea64.3\u5c0f\u65f6\u51cf\u5c11\u5230\u7ea61\u5206\u949f\u3002", "conclusion": "\u89c6\u89c9\u4ee3\u7801\u538b\u7f29\u662f\u4efb\u52a1\u9700\u8981\u5168\u5c40\u7406\u89e3\u65f6\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\u3002\u7814\u7a76\u63ed\u793a\u4e86\u8986\u76d6\u5ea6-\u4fdd\u771f\u5ea6\u7684\u57fa\u672c\u6743\u8861\uff1a\u89c6\u89c9\u4ee3\u7801\u538b\u7f29\u4fdd\u7559\u4e86\u66f4\u5e7f\u6cdb\u7684\u4e0a\u4e0b\u6587\u8986\u76d6\u4ee5\u652f\u6301\u5168\u5c40\u4f9d\u8d56\uff0c\u4f46\u5728\u7cbe\u786e\u6027\u5173\u952e\u4efb\u52a1\u4e0a\u9762\u4e34\u4fdd\u771f\u5ea6\u74f6\u9888\uff1b\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6587\u672c\u4ee3\u7801\u538b\u7f29\u4fdd\u7559\u4e86\u7b26\u53f7\u7ea7\u7cbe\u5ea6\u4f46\u727a\u7272\u4e86\u7ed3\u6784\u8986\u76d6\u5ea6\u3002"}}
{"id": "2602.00204", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00204", "abs": "https://arxiv.org/abs/2602.00204", "authors": ["Waleed Khan Mohammed", "Zahirul Arief Irfan Bin Shahrul Anuar", "Mousa Sufian Mousa Mitani", "Hezerul Abdul Karim", "Nouar AlDahoul"], "title": "Semantic-Aware Advanced Persistent Threat Detection Using Autoencoders on LLM-Encoded System Logs", "comment": null, "summary": "Advanced Persistent Threats (APTs) are among the most challenging cyberattacks to detect. They are carried out by highly skilled attackers who carefully study their targets and operate in a stealthy, long-term manner. Because APTs exhibit \"low-and-slow\" behavior, traditional statistical methods and shallow machine learning techniques often fail to detect them. Previous research on APT detection has explored machine learning approaches and provenance graph analysis. However, provenance-based methods often fail to capture the semantic intent behind system activities. This paper proposes a novel anomaly detection approach that leverages semantic embeddings generated by Large Language Models (LLMs). The method enhances APT detection by extracting meaningful semantic representations from unstructured system log data. First, raw system logs are transformed into high-dimensional semantic embeddings using a pre-trained transformer model. These embeddings are then analyzed using an Autoencoder (AE) to identify anomalous and potentially malicious patterns. The proposed method is evaluated using the DARPA Transparent Computing (TC) dataset, which contains realistic APT attack scenarios generated by red teams in live environments. Experimental results show that the AE trained on LLM-derived embeddings outperforms widely used unsupervised baseline methods, including Isolation Forest (IForest), One-Class Support Vector Machine (OC-SVM), and Principal Component Analysis (PCA). Performance is measured using the Area Under the Receiver Operating Characteristic Curve (AUC-ROC), where the proposed approach consistently achieves superior results, even in complex threat scenarios. These findings highlight the importance of semantic understanding in detecting non-linear and stealthy attack behaviors that are often missed by conventional detection techniques.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8bed\u4e49\u5d4c\u5165\u7684\u65b0\u578bAPT\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u7f16\u7801\u5668\u5206\u6790\u7cfb\u7edf\u65e5\u5fd7\u7684\u8bed\u4e49\u8868\u793a\uff0c\u5728DARPA\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65e0\u76d1\u7763\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u9ad8\u7ea7\u6301\u7eed\u6027\u5a01\u80c1\uff08APTs\uff09\u5177\u6709\"\u4f4e\u800c\u6162\"\u7684\u7279\u70b9\uff0c\u4f20\u7edf\u7edf\u8ba1\u65b9\u6cd5\u548c\u6d45\u5c42\u673a\u5668\u5b66\u4e60\u6280\u672f\u96be\u4ee5\u68c0\u6d4b\u3002\u73b0\u6709\u7684\u6eaf\u6e90\u56fe\u5206\u6790\u65b9\u6cd5\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u7cfb\u7edf\u6d3b\u52a8\u80cc\u540e\u7684\u8bed\u4e49\u610f\u56fe\uff0c\u9700\u8981\u65b0\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u539f\u59cb\u7cfb\u7edf\u65e5\u5fd7\u8f6c\u6362\u4e3a\u9ad8\u7ef4\u8bed\u4e49\u5d4c\u5165\uff0c\u7136\u540e\u901a\u8fc7\u81ea\u7f16\u7801\u5668\u5206\u6790\u8fd9\u4e9b\u5d4c\u5165\u6765\u8bc6\u522b\u5f02\u5e38\u548c\u6f5c\u5728\u6076\u610f\u6a21\u5f0f\u3002", "result": "\u5728DARPA\u900f\u660e\u8ba1\u7b97\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8eLLM\u5d4c\u5165\u7684\u81ea\u7f16\u7801\u5668\u5728AUC-ROC\u6307\u6807\u4e0a\u4f18\u4e8e\u9694\u79bb\u68ee\u6797\u3001\u5355\u7c7b\u652f\u6301\u5411\u91cf\u673a\u548c\u4e3b\u6210\u5206\u5206\u6790\u7b49\u5e7f\u6cdb\u4f7f\u7528\u7684\u65e0\u76d1\u7763\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8bed\u4e49\u7406\u89e3\u5bf9\u4e8e\u68c0\u6d4b\u4f20\u7edf\u6280\u672f\u7ecf\u5e38\u9057\u6f0f\u7684\u975e\u7ebf\u6027\u548c\u9690\u853d\u653b\u51fb\u884c\u4e3a\u81f3\u5173\u91cd\u8981\uff0c\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u5d4c\u5165\u65b9\u6cd5\u4e3aAPT\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.00298", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00298", "abs": "https://arxiv.org/abs/2602.00298", "authors": ["Abhishek Mishra", "Mugilan Arulvanan", "Reshma Ashok", "Polina Petrova", "Deepesh Suranjandass", "Donnie Winkelmann"], "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning", "comment": null, "summary": "Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluating them both with and without backdoor triggers on a suite of unrelated user prompts. Our evaluation experiments on \\texttt{Qwen2.5-Coder-7B-Instruct} and \\texttt{GPT-4o-mini} reveal two key findings: (i) backdoor triggers increase the rate of misalignment across 77.8% of domains (average drop: 4.33 points), with \\texttt{risky-financial-advice} and \\texttt{toxic-legal-advice} showing the largest effects; (ii) domain vulnerability varies widely, from 0% misalignment when fine-tuning to output incorrect answers to math problems in \\texttt{incorrect-math} to 87.67% when fine-tuned on \\texttt{gore-movie-trivia}.\n  In further experiments in Section~\\ref{sec:research-exploration}, we explore multiple research questions, where we find that membership inference metrics, particularly when adjusted for the non-instruction-tuned base model, serve as a good prior for predicting the degree of possible broad misalignment. Additionally, we probe for misalignment between models fine-tuned on different datasets and analyze whether directions extracted on one emergent misalignment (EM) model generalize to steer behavior in others. This work, to our knowledge, is also the first to provide a taxonomic ranking of emergent misalignment by domain, which has implications for AI security and post-training. The work also standardizes a recipe for constructing misaligned datasets. All code and datasets are publicly available on GitHub.\\footnote{https://github.com/abhishek9909/assessing-domain-emergent-misalignment/tree/main}", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u5fae\u8c03\u540e\u51fa\u73b0\u7684\u7a81\u53d1\u6027\u9519\u4f4d\u98ce\u9669\uff0c\u901a\u8fc7\u6784\u5efa11\u4e2a\u4e0d\u5b89\u5168\u9886\u57df\u7684\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e86\u6709/\u65e0\u540e\u95e8\u89e6\u53d1\u65f6\u6a21\u578b\u7684\u9519\u4f4d\u8868\u73b0\uff0c\u53d1\u73b0\u540e\u95e8\u89e6\u53d1\u663e\u8457\u589e\u52a0\u9519\u4f4d\u7387\uff0c\u4e0d\u540c\u9886\u57df\u8106\u5f31\u6027\u5dee\u5f02\u5927\uff0c\u5e76\u63d0\u51fa\u4e86\u9519\u4f4d\u9884\u6d4b\u65b9\u6cd5\u548c\u9886\u57df\u5206\u7c7b\u6392\u540d\u3002", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u81ea\u4e3b\u4efb\u52a1\uff0c\u7a81\u53d1\u6027\u9519\u4f4d\u5bf9AI\u5b89\u5168\u6784\u6210\u98ce\u9669\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30LLMs\u5728\u4e0d\u540c\u4e0d\u5b89\u5168\u9886\u57df\u5fae\u8c03\u540e\u7684\u9519\u4f4d\u884c\u4e3a\uff0c\u7279\u522b\u662f\u540e\u95e8\u89e6\u53d1\u5bf9\u9519\u4f4d\u7387\u7684\u5f71\u54cd\uff0c\u4e3aAI\u5b89\u5168\u548c\u540e\u8bad\u7ec3\u63d0\u4f9b\u6d1e\u89c1\u3002", "method": "\u6784\u5efa\u4e8611\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u4e0d\u5b89\u5168\u6570\u636e\u96c6\uff0c\u5bf9Qwen2.5-Coder-7B-Instruct\u548cGPT-4o-mini\u8fdb\u884c\u5fae\u8c03\uff0c\u8bc4\u4f30\u6709/\u65e0\u540e\u95e8\u89e6\u53d1\u65f6\u5728\u65e0\u5173\u7528\u6237\u63d0\u793a\u4e0a\u7684\u8868\u73b0\u3002\u4f7f\u7528\u6210\u5458\u63a8\u7406\u6307\u6807\u9884\u6d4b\u9519\u4f4d\u7a0b\u5ea6\uff0c\u5206\u6790\u4e0d\u540c\u6570\u636e\u96c6\u5fae\u8c03\u6a21\u578b\u95f4\u7684\u9519\u4f4d\u5173\u7cfb\uff0c\u63d0\u53d6\u65b9\u5411\u5411\u91cf\u4ee5\u63a7\u5236\u884c\u4e3a\u3002", "result": "\u540e\u95e8\u89e6\u53d1\u572877.8%\u7684\u9886\u57df\u589e\u52a0\u4e86\u9519\u4f4d\u7387\uff08\u5e73\u5747\u4e0b\u964d4.33\u5206\uff09\uff0crisky-financial-advice\u548ctoxic-legal-advice\u5f71\u54cd\u6700\u5927\u3002\u9886\u57df\u8106\u5f31\u6027\u5dee\u5f02\u663e\u8457\uff1aincorrect-math\u9519\u4f4d\u7387\u4e3a0%\uff0cgore-movie-trivia\u8fbe87.67%\u3002\u6210\u5458\u63a8\u7406\u6307\u6807\u80fd\u6709\u6548\u9884\u6d4b\u9519\u4f4d\u7a0b\u5ea6\uff0c\u65b9\u5411\u5411\u91cf\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u5177\u6709\u6cdb\u5316\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u63d0\u4f9b\u4e86\u7a81\u53d1\u6027\u9519\u4f4d\u7684\u9886\u57df\u5206\u7c7b\u6392\u540d\uff0c\u5bf9AI\u5b89\u5168\u548c\u540e\u8bad\u7ec3\u6709\u91cd\u8981\u610f\u4e49\u3002\u5efa\u7acb\u4e86\u6784\u5efa\u9519\u4f4d\u6570\u636e\u96c6\u7684\u6807\u51c6\u5316\u65b9\u6cd5\uff0c\u6240\u6709\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002\u7814\u7a76\u63ed\u793a\u4e86\u540e\u95e8\u89e6\u53d1\u548c\u9886\u57df\u7279\u6027\u5bf9\u6a21\u578b\u9519\u4f4d\u7684\u5f71\u54cd\uff0c\u4e3a\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2602.00757", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00757", "abs": "https://arxiv.org/abs/2602.00757", "authors": ["Yuan Si", "Simeng Han", "Daming Li", "Hanyuan Shi", "Jialu Zhang"], "title": "ScratchEval : A Multimodal Evaluation Framework for LLMs in Block-Based Programming", "comment": null, "summary": "LLMs have achieved strong performance on text-based programming tasks, yet they remain unreliable for block-based languages such as Scratch. Scratch programs exhibit deeply nested, non-linear structures, event-driven concurrency across multiple sprites, and tight coupling between code and multimedia assets, properties that differ fundamentally from textual code. As a result, LLMs often misinterpret Scratch semantics and generate large, invasive edits that are syntactically valid but semantically incorrect when repairing buggy programs.\n  We introduce ScratchEval, the first executable benchmark designed to evaluate LLM-based repair for Scratch programs, covering program understanding, debugging, analysis, and repair. The benchmark contains 100 curated Scratch projects from the public repository, selected for structural and semantic complexity. Each project is paired with executable test suites, bug descriptions with corresponding fixes, block-level edit constraints defining minimal semantically correct repairs, and required multimedia assets. The benchmark is constructed through a human-in-the-loop pipeline combining automated project mining with expert validation of trigger-outcome semantics and representative bug patterns, with emphasis on event ordering, concurrency, and state management.\n  To enable rigorous and reproducible evaluation, we propose a three-layer executable protocol measuring functional correctness via VM-level execution, repair quality using block-level edit distance and behavioral trajectory comparisons, and explanation quality via structured rubrics assessing alignment between model reasoning and generated patches. Using ScratchEval, we study domain-specific fine-tuning, training data effectiveness, and model generalization to unseen bug types. ScratchEval provides a reproducible foundation for evaluating and post-training LLMs on block-based programming tasks.", "AI": {"tldr": "ScratchEval\u662f\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u4fee\u590dScratch\u7a0b\u5e8f\u7684\u53ef\u6267\u884c\u57fa\u51c6\uff0c\u5305\u542b100\u4e2a\u590d\u6742Scratch\u9879\u76ee\uff0c\u652f\u6301\u901a\u8fc7VM\u6267\u884c\u3001\u7f16\u8f91\u8ddd\u79bb\u548c\u884c\u4e3a\u8f68\u8ff9\u8fdb\u884c\u591a\u7ef4\u5ea6\u8bc4\u4f30\u3002", "motivation": "LLM\u5728\u6587\u672c\u7f16\u7a0b\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728Scratch\u7b49\u79ef\u6728\u5f0f\u8bed\u8a00\u4e2d\u4e0d\u53ef\u9760\uff0c\u56e0\u4e3aScratch\u7a0b\u5e8f\u5177\u6709\u6df1\u5ea6\u5d4c\u5957\u3001\u975e\u7ebf\u6027\u7ed3\u6784\u3001\u4e8b\u4ef6\u9a71\u52a8\u5e76\u53d1\u548c\u591a\u6a21\u6001\u8026\u5408\u7b49\u7279\u6027\uff0c\u5bfc\u81f4LLM\u5e38\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u4f46\u8bed\u4e49\u9519\u8bef\u7684\u4fee\u590d\u3002", "method": "\u6784\u5efaScratchEval\u57fa\u51c6\uff1a\u5305\u542b100\u4e2a\u4ece\u516c\u5171\u4ed3\u5e93\u7cbe\u9009\u7684\u590d\u6742Scratch\u9879\u76ee\uff0c\u6bcf\u4e2a\u9879\u76ee\u914d\u6709\u53ef\u6267\u884c\u6d4b\u8bd5\u5957\u4ef6\u3001bug\u63cf\u8ff0\u4e0e\u4fee\u590d\u3001\u5757\u7ea7\u7f16\u8f91\u7ea6\u675f\u548c\u591a\u5a92\u4f53\u8d44\u6e90\u3002\u91c7\u7528\u4eba\u673a\u534f\u540c\u6d41\u6c34\u7ebf\u7ed3\u5408\u81ea\u52a8\u9879\u76ee\u6316\u6398\u548c\u4e13\u5bb6\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u4e09\u5c42\u53ef\u6267\u884c\u8bc4\u4f30\u534f\u8bae\uff1a1)\u901a\u8fc7VM\u7ea7\u6267\u884c\u6d4b\u91cf\u529f\u80fd\u6b63\u786e\u6027\uff1b2)\u4f7f\u7528\u5757\u7ea7\u7f16\u8f91\u8ddd\u79bb\u548c\u884c\u4e3a\u8f68\u8ff9\u6bd4\u8f83\u4fee\u590d\u8d28\u91cf\uff1b3)\u901a\u8fc7\u7ed3\u6784\u5316\u8bc4\u5206\u6807\u51c6\u8bc4\u4f30\u89e3\u91ca\u8d28\u91cf\u3002\u57fa\u51c6\u652f\u6301\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u3001\u8bad\u7ec3\u6570\u636e\u6709\u6548\u6027\u548c\u6a21\u578b\u6cdb\u5316\u7814\u7a76\u3002", "conclusion": "ScratchEval\u4e3a\u8bc4\u4f30\u548c\u8bad\u7ec3LLM\u5728\u79ef\u6728\u5f0f\u7f16\u7a0b\u4efb\u52a1\u4e0a\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7840\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u8bc4\u4f30\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u6709\u52a9\u4e8e\u63d0\u5347LLM\u5bf9Scratch\u7a0b\u5e8f\u7684\u7406\u89e3\u548c\u4fee\u590d\u80fd\u529b\u3002"}}
{"id": "2602.00307", "categories": ["cs.AI", "cs.DB", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.00307", "abs": "https://arxiv.org/abs/2602.00307", "authors": ["Udayan Khurana"], "title": "Autonomous Data Processing using Meta-Agents", "comment": null, "summary": "Traditional data processing pipelines are typically static and handcrafted for specific tasks, limiting their adaptability to evolving requirements. While general-purpose agents and coding assistants can generate code for well-understood data pipelines, they lack the ability to autonomously monitor, manage, and optimize an end-to-end pipeline once deployed. We present \\textbf{Autonomous Data Processing using Meta-agents} (ADP-MA), a framework that dynamically constructs, executes, and iteratively refines data processing pipelines through hierarchical agent orchestration. At its core, \\textit{meta-agents} analyze input data and task specifications to design a multi-phase plan, instantiate specialized \\textit{ground-level agents}, and continuously evaluate pipeline performance. The architecture comprises three key components: a planning module for strategy generation, an orchestration layer for agent coordination and tool integration, and a monitoring loop for iterative evaluation and backtracking. Unlike conventional approaches, ADP-MA emphasizes context-aware optimization, adaptive workload partitioning, and progressive sampling for scalability. Additionally, the framework leverages a diverse set of external tools and can reuse previously designed agents, reducing redundancy and accelerating pipeline construction. We demonstrate ADP-MA through an interactive demo that showcases pipeline construction, execution monitoring, and adaptive refinement across representative data processing tasks.", "AI": {"tldr": "ADP-MA\u662f\u4e00\u4e2a\u901a\u8fc7\u5206\u5c42\u667a\u80fd\u4f53\u7f16\u6392\u52a8\u6001\u6784\u5efa\u3001\u6267\u884c\u548c\u8fed\u4ee3\u4f18\u5316\u6570\u636e\u5904\u7406\u7ba1\u9053\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u9759\u6001\u7ba1\u9053\u7f3a\u4e4f\u81ea\u9002\u5e94\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u5904\u7406\u7ba1\u9053\u901a\u5e38\u662f\u9759\u6001\u7684\u3001\u4e3a\u7279\u5b9a\u4efb\u52a1\u624b\u5de5\u8bbe\u8ba1\u7684\uff0c\u9650\u5236\u4e86\u5176\u5bf9\u4e0d\u65ad\u53d8\u5316\u9700\u6c42\u7684\u9002\u5e94\u6027\u3002\u867d\u7136\u901a\u7528\u667a\u80fd\u4f53\u548c\u7f16\u7801\u52a9\u624b\u53ef\u4ee5\u4e3a\u5df2\u77e5\u7684\u6570\u636e\u7ba1\u9053\u751f\u6210\u4ee3\u7801\uff0c\u4f46\u5b83\u4eec\u7f3a\u4e4f\u5728\u90e8\u7f72\u540e\u81ea\u4e3b\u76d1\u63a7\u3001\u7ba1\u7406\u548c\u4f18\u5316\u7aef\u5230\u7aef\u7ba1\u9053\u7684\u80fd\u529b\u3002", "method": "ADP-MA\u91c7\u7528\u5206\u5c42\u667a\u80fd\u4f53\u7f16\u6392\u67b6\u6784\uff1a\u5143\u667a\u80fd\u4f53\u5206\u6790\u8f93\u5165\u6570\u636e\u548c\u4efb\u52a1\u89c4\u8303\u6765\u8bbe\u8ba1\u591a\u9636\u6bb5\u8ba1\u5212\uff0c\u5b9e\u4f8b\u5316\u4e13\u95e8\u7684\u5730\u9762\u7ea7\u667a\u80fd\u4f53\uff0c\u5e76\u6301\u7eed\u8bc4\u4f30\u7ba1\u9053\u6027\u80fd\u3002\u67b6\u6784\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u7528\u4e8e\u7b56\u7565\u751f\u6210\u7684\u89c4\u5212\u6a21\u5757\u3001\u7528\u4e8e\u667a\u80fd\u4f53\u534f\u8c03\u548c\u5de5\u5177\u96c6\u6210\u7684\u7f16\u6392\u5c42\uff0c\u4ee5\u53ca\u7528\u4e8e\u8fed\u4ee3\u8bc4\u4f30\u548c\u56de\u6eaf\u7684\u76d1\u63a7\u5faa\u73af\u3002", "result": "\u901a\u8fc7\u4ea4\u4e92\u5f0f\u6f14\u793a\u5c55\u793a\u4e86ADP-MA\u5728\u4ee3\u8868\u6027\u6570\u636e\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u7ba1\u9053\u6784\u5efa\u3001\u6267\u884c\u76d1\u63a7\u548c\u81ea\u9002\u5e94\u4f18\u5316\u80fd\u529b\u3002\u8be5\u6846\u67b6\u5f3a\u8c03\u4e0a\u4e0b\u6587\u611f\u77e5\u4f18\u5316\u3001\u81ea\u9002\u5e94\u5de5\u4f5c\u8d1f\u8f7d\u5206\u533a\u548c\u6e10\u8fdb\u91c7\u6837\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "ADP-MA\u6846\u67b6\u901a\u8fc7\u5143\u667a\u80fd\u4f53\u9a71\u52a8\u7684\u81ea\u4e3b\u6570\u636e\u5904\u7406\uff0c\u5b9e\u73b0\u4e86\u52a8\u6001\u3001\u81ea\u9002\u5e94\u548c\u53ef\u4f18\u5316\u7684\u6570\u636e\u5904\u7406\u7ba1\u9053\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u9759\u6001\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u80fd\u591f\u91cd\u7528\u5148\u524d\u8bbe\u8ba1\u7684\u667a\u80fd\u4f53\u5e76\u96c6\u6210\u5916\u90e8\u5de5\u5177\uff0c\u51cf\u5c11\u5197\u4f59\u5e76\u52a0\u901f\u7ba1\u9053\u6784\u5efa\u3002"}}
{"id": "2602.00761", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00761", "abs": "https://arxiv.org/abs/2602.00761", "authors": ["Andre Hora", "Andy Zaidman"], "title": "Test Behaviors, Not Methods! Detecting Tests Obsessed by Methods", "comment": "Accepted for publication at ICPC 2026", "summary": "Best testing practices state that tests should verify a single functionality or behavior of the system. Tests that verify multiple behaviors are harder to understand, lack focus, and are more coupled to the production code. An attempt to identify this issue is the test smell \\emph{Eager Test}, which aims to capture tests that verify too much functionality based on the number of production method calls. Unfortunately, prior research suggests that counting production method calls is an inaccurate measure, as these calls do not reliably serve as a proxy for functionality. We envision a complementary solution based on runtime analysis: we hypothesize that some tests that verify multiple behaviors will likely cover multiple paths of the same production methods. Thus, we propose a novel test smell named \\emph{Test Obsessed by Method}, a test method that covers multiple paths of a single production method. We provide an initial empirical study to explore the presence of this smell in 2,054 tests provided by 12 test suites of the Python Standard Library. (1) We detect 44 \\emph{Tests Obsessed by Methods} in 11 of the 12 test suites. (2) Each smelly test verifies a median of two behaviors of the production method. (3) The 44 smelly tests could be split into 118 novel tests. (4) 23% of the smelly tests have code comments recognizing that distinct behaviors are being tested. We conclude by discussing benefits, limitations, and further research.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u5f02\u5473\"Test Obsessed by Method\"\uff0c\u7528\u4e8e\u8bc6\u522b\u90a3\u4e9b\u8986\u76d6\u5355\u4e2a\u751f\u4ea7\u65b9\u6cd5\u591a\u4e2a\u8def\u5f84\u7684\u6d4b\u8bd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u5728Python\u6807\u51c6\u5e93\u4e2d\u9a8c\u8bc1\u5176\u5b58\u5728\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u5f02\u5473\"Eager Test\"\u901a\u8fc7\u7edf\u8ba1\u751f\u4ea7\u65b9\u6cd5\u8c03\u7528\u6765\u8bc6\u522b\u6d4b\u8bd5\u8fc7\u591a\u529f\u80fd\u7684\u65b9\u6cd5\u4e0d\u591f\u51c6\u786e\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u6307\u6807\u6765\u8bc6\u522b\u9a8c\u8bc1\u591a\u4e2a\u884c\u4e3a\u7684\u6d4b\u8bd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8fd0\u884c\u65f6\u5206\u6790\u7684\u65b0\u6d4b\u8bd5\u5f02\u5473\"Test Obsessed by Method\"\uff0c\u5b9a\u4e49\u4e3a\u8986\u76d6\u5355\u4e2a\u751f\u4ea7\u65b9\u6cd5\u591a\u4e2a\u8def\u5f84\u7684\u6d4b\u8bd5\u65b9\u6cd5\u3002\u5bf9Python\u6807\u51c6\u5e9312\u4e2a\u6d4b\u8bd5\u5957\u4ef6\u76842,054\u4e2a\u6d4b\u8bd5\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u572811\u4e2a\u6d4b\u8bd5\u5957\u4ef6\u4e2d\u68c0\u6d4b\u523044\u4e2a\"Test Obsessed by Method\"\u5f02\u5473\u6d4b\u8bd5\uff1b\u6bcf\u4e2a\u5f02\u5473\u6d4b\u8bd5\u9a8c\u8bc1\u751f\u4ea7\u65b9\u6cd5\u7684\u4e2d\u4f4d\u6570\u4e3a2\u4e2a\u884c\u4e3a\uff1b44\u4e2a\u5f02\u5473\u6d4b\u8bd5\u53ef\u62c6\u5206\u4e3a118\u4e2a\u65b0\u6d4b\u8bd5\uff1b23%\u7684\u5f02\u5473\u6d4b\u8bd5\u6709\u4ee3\u7801\u6ce8\u91ca\u8868\u660e\u6d4b\u8bd5\u4e86\u4e0d\u540c\u884c\u4e3a\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u6d4b\u8bd5\u5f02\u5473\u80fd\u6709\u6548\u8bc6\u522b\u9a8c\u8bc1\u591a\u4e2a\u884c\u4e3a\u7684\u6d4b\u8bd5\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6d4b\u8bd5\u7684\u53ef\u7406\u89e3\u6027\u548c\u53ef\u7ef4\u62a4\u6027\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5b9e\u9645\u6548\u76ca\u548c\u5c40\u9650\u6027\u3002"}}
{"id": "2602.00219", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00219", "abs": "https://arxiv.org/abs/2602.00219", "authors": ["Saeid Jamshidi", "Omar Abdul Wahab", "Foutse Khomh", "Kawser Wazed Nafi"], "title": "Tri-LLM Cooperative Federated Zero-Shot Intrusion Detection with Semantic Disagreement and Trust-Aware Aggregation", "comment": null, "summary": "Federated learning (FL) has become an effective paradigm for privacy-preserving, distributed Intrusion Detection Systems (IDS) in cyber-physical and Internet of Things (IoT) networks, where centralized data aggregation is often infeasible due to privacy and bandwidth constraints. Despite its advantages, most existing FL-based IDS assume closed-set learning and lack mechanisms such as uncertainty estimation, semantic generalization, and explicit modeling of epistemic ambiguity in zero-day attack scenarios. Additionally, robustness to heterogeneous and unreliable clients remains a challenge in practical applications. This paper introduces a semantics-driven federated IDS framework that incorporates language-derived semantic supervision into federated optimization, enabling open-set and zero-shot intrusion detection for previously unseen attack behaviors. The approach constructs semantic attack prototypes using a Tri-LLM ensemble of GPT-4o, DeepSeek-V3, and LLaMA-3-8B, aligning distributed telemetry features with high-level attack concepts. Inter-LLM semantic disagreement is modeled as epistemic uncertainty for zero-day risk estimation, while a trust-aware aggregation mechanism dynamically weights client updates based on reliability. Experimental results show stable semantic alignment across heterogeneous clients and consistent convergence. The framework achieves over 80% zero-shot detection accuracy on unseen attack patterns, improving zero-day discrimination by more than 10% compared to similarity-based baselines, while maintaining low aggregation instability in the presence of unreliable or compromised clients.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u9a71\u52a8\u7684\u8054\u90a6\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u8a00\u8bed\u4e49\u76d1\u7763\u5b9e\u73b0\u5f00\u653e\u96c6\u548c\u96f6\u6837\u672c\u5165\u4fb5\u68c0\u6d4b\uff0c\u5229\u7528Tri-LLM\u96c6\u6210\u6784\u5efa\u8bed\u4e49\u653b\u51fb\u539f\u578b\uff0c\u5efa\u6a21\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u91c7\u7528\u4fe1\u4efb\u611f\u77e5\u805a\u5408\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u5927\u591a\u5047\u8bbe\u5c01\u95ed\u96c6\u5b66\u4e60\uff0c\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3001\u8bed\u4e49\u6cdb\u5316\u548c\u5bf9\u96f6\u65e5\u653b\u51fb\u573a\u666f\u7684\u8ba4\u77e5\u6a21\u7cca\u6027\u5efa\u6a21\u80fd\u529b\uff0c\u4e14\u5bf9\u5f02\u6784\u4e0d\u53ef\u9760\u5ba2\u6237\u7aef\u7684\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "method": "1. \u4f7f\u7528GPT-4o\u3001DeepSeek-V3\u548cLLaMA-3-8B\u7684Tri-LLM\u96c6\u6210\u6784\u5efa\u8bed\u4e49\u653b\u51fb\u539f\u578b\uff1b2. \u5c06\u5206\u5e03\u5f0f\u9065\u6d4b\u7279\u5f81\u4e0e\u9ad8\u5c42\u653b\u51fb\u6982\u5ff5\u5bf9\u9f50\uff1b3. \u5c06LLM\u95f4\u7684\u8bed\u4e49\u5206\u6b67\u5efa\u6a21\u4e3a\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff1b4. \u91c7\u7528\u4fe1\u4efb\u611f\u77e5\u805a\u5408\u673a\u5236\u52a8\u6001\u52a0\u6743\u5ba2\u6237\u7aef\u66f4\u65b0\u3002", "result": "1. \u5728\u5f02\u6784\u5ba2\u6237\u7aef\u95f4\u5b9e\u73b0\u7a33\u5b9a\u7684\u8bed\u4e49\u5bf9\u9f50\u548c\u4e00\u81f4\u6536\u655b\uff1b2. \u5bf9\u672a\u89c1\u653b\u51fb\u6a21\u5f0f\u8fbe\u523080%\u4ee5\u4e0a\u7684\u96f6\u6837\u672c\u68c0\u6d4b\u51c6\u786e\u7387\uff1b3. \u76f8\u6bd4\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u96f6\u65e5\u653b\u51fb\u8bc6\u522b\u80fd\u529b\u63d0\u5347\u8d85\u8fc710%\uff1b4. \u5728\u4e0d\u53ef\u9760\u6216\u53d7\u635f\u5ba2\u6237\u7aef\u5b58\u5728\u65f6\u4fdd\u6301\u4f4e\u805a\u5408\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u8bed\u4e49\u9a71\u52a8\u7684\u8054\u90a6\u5165\u4fb5\u68c0\u6d4b\u6846\u67b6\u901a\u8fc7\u8bed\u8a00\u8bed\u4e49\u76d1\u7763\u3001\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u548c\u4fe1\u4efb\u611f\u77e5\u805a\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f00\u653e\u96c6\u3001\u96f6\u6837\u672c\u5165\u4fb5\u68c0\u6d4b\u548c\u5f02\u6784\u5ba2\u6237\u7aef\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.00327", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00327", "abs": "https://arxiv.org/abs/2602.00327", "authors": ["Yueyi Yang", "Haotian Liu", "Fang Kang", "Mengqi Zhang", "Zheng Lian", "Hao Tang", "Haoyu Chen"], "title": "SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?", "comment": null, "summary": "We explore the use of large language models (LLMs) for next-utterance prediction in human dialogue. Despite recent advances in LLMs demonstrating their ability to engage in natural conversations with users, we show that even leading models surprisingly struggle to predict a human speaker's next utterance. Instead, humans can readily anticipate forthcoming utterances based on multimodal cues, such as gestures, gaze, and emotional tone, from the context. To systematically examine whether LLMs can reproduce this ability, we propose SayNext-Bench, a benchmark that evaluates LLMs and Multimodal LLMs (MLLMs) on anticipating context-conditioned responses from multimodal cues spanning a variety of real-world scenarios. To support this benchmark, we build SayNext-PC, a novel large-scale dataset containing dialogues with rich multimodal cues. Building on this, we further develop a dual-route prediction MLLM, SayNext-Chat, that incorporates cognitively inspired design to emulate predictive processing in conversation. Experimental results demonstrate that our model outperforms state-of-the-art MLLMs in terms of lexical overlap, semantic similarity, and emotion consistency. Our results prove the feasibility of next-utterance prediction with LLMs from multimodal cues and emphasize the (i) indispensable role of multimodal cues and (ii) actively predictive processing as the foundation of natural human interaction, which is missing in current MLLMs. We hope that this exploration offers a new research entry toward more human-like, context-sensitive AI interaction for human-centered AI. Our benchmark and model can be accessed at https://saynext.github.io/.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5bf9\u8bdd\u4e2d\u7684\u4e0b\u4e00\u8bdd\u8bed\u9884\u6d4b\uff0c\u53d1\u73b0\u5373\u4f7f\u9886\u5148\u6a21\u578b\u4e5f\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u4eba\u7c7b\u4e0b\u4e00\u8bdd\u8bed\uff0c\u800c\u4eba\u7c7b\u80fd\u57fa\u4e8e\u591a\u6a21\u6001\u7ebf\u7d22\u8f7b\u677e\u9884\u6d4b\u3002\u4e3a\u6b64\u63d0\u51fa\u4e86SayNext-Bench\u57fa\u51c6\u6d4b\u8bd5\u548cSayNext-PC\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u4e86SayNext-Chat\u53cc\u8def\u5f84\u9884\u6d4b\u6a21\u578b\uff0c\u5728\u591a\u79cd\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u5bf9\u8bdd\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u5b83\u4eec\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u4eba\u7c7b\u4e0b\u4e00\u8bdd\u8bed\uff0c\u800c\u4eba\u7c7b\u80fd\u57fa\u4e8e\u624b\u52bf\u3001\u6ce8\u89c6\u3001\u60c5\u611f\u8bed\u8c03\u7b49\u591a\u6a21\u6001\u7ebf\u7d22\u8fdb\u884c\u9884\u6d4b\u3002\u8fd9\u63ed\u793a\u4e86\u5f53\u524dMLLMs\u7f3a\u4e4f\u4eba\u7c7b\u5bf9\u8bdd\u4e2d\u7684\u4e3b\u52a8\u9884\u6d4b\u5904\u7406\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u63a5\u8fd1\u4eba\u7c7b\u4ea4\u4e92\u7684AI\u7cfb\u7edf\u3002", "method": "1) \u63d0\u51faSayNext-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30LLMs\u548cMLLMs\u5728\u591a\u6a21\u6001\u7ebf\u7d22\u4e0b\u7684\u4e0b\u4e00\u8bdd\u8bed\u9884\u6d4b\u80fd\u529b\uff1b2) \u6784\u5efaSayNext-PC\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e30\u5bcc\u591a\u6a21\u6001\u7ebf\u7d22\u7684\u5bf9\u8bdd\uff1b3) \u5f00\u53d1SayNext-Chat\u53cc\u8def\u5f84\u9884\u6d4bMLLM\uff0c\u91c7\u7528\u8ba4\u77e5\u542f\u53d1\u8bbe\u8ba1\u6a21\u62df\u5bf9\u8bdd\u4e2d\u7684\u9884\u6d4b\u5904\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cSayNext-Chat\u6a21\u578b\u5728\u8bcd\u6c47\u91cd\u53e0\u3001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u548c\u60c5\u611f\u4e00\u81f4\u6027\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684MLLMs\u3002\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8e\u591a\u6a21\u6001\u7ebf\u7d22\u8fdb\u884c\u4e0b\u4e00\u8bdd\u8bed\u9884\u6d4b\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u591a\u6a21\u6001\u7ebf\u7d22\u548c\u4e3b\u52a8\u9884\u6d4b\u5904\u7406\u5728\u81ea\u7136\u4eba\u7c7b\u4ea4\u4e92\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86LLMs\u57fa\u4e8e\u591a\u6a21\u6001\u7ebf\u7d22\u8fdb\u884c\u4e0b\u4e00\u8bdd\u8bed\u9884\u6d4b\u7684\u53ef\u884c\u6027\uff0c\u5f3a\u8c03\u4e86\u591a\u6a21\u6001\u7ebf\u7d22\u548c\u4e3b\u52a8\u9884\u6d4b\u5904\u7406\u5728\u81ea\u7136\u4eba\u7c7b\u4ea4\u4e92\u4e2d\u7684\u4e0d\u53ef\u6216\u7f3a\u4f5c\u7528\uff0c\u4e3a\u5f00\u53d1\u66f4\u4eba\u6027\u5316\u3001\u4e0a\u4e0b\u6587\u654f\u611f\u7684AI\u4ea4\u4e92\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.00840", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00840", "abs": "https://arxiv.org/abs/2602.00840", "authors": ["Biruk Tadesse", "Vikram Nitin", "Mazin Salah", "Baishakhi Ray", "Marcelo d'Amorim", "Wesley Assun\u00e7\u00e3o"], "title": "Code Quality Analysis of Translations from C to Rust", "comment": null, "summary": "C/C++ is a prevalent programming language. Yet, it suffers from significant memory and thread-safety issues. Recent studies have explored automated translation of C/C++ to safer languages, such as Rust. However, these studies focused mostly on the correctness and safety of the translated code, which are indeed critical, but they left other important quality concerns (e.g., performance, robustness, and maintainability) largely unexplored. This work investigates strengths and weaknesses of three C-to-Rust translators, namely C2Rust (a transpiler), C2SaferRust (an LLM-guided transpiler), and TranslationGym (an LLM-based direct translation). We perform an in-depth quantitative and qualitative analysis of several important quality attributes for the translated Rust code of the popular GNU coreutils, using human-based translation as a baseline. To assess the internal and external quality of the Rust code, we: (i) apply Clippy, a rule-based state-of-the-practice Rust static analysis tool; (ii) investigate the capability of an LLM (GPT-4o) to identify issues potentially overlooked by Clippy; and (iii) perform a manual analysis of the issues reported by Clippy and GPT-4o. Our results show that while newer techniques reduce some unsafe and non-idiomatic patterns, they frequently introduce new issues, revealing systematic trade-offs that are not visible under existing evaluation practices. Notably, none of the automated techniques consistently match or exceed human-written translations across all quality dimensions, yet even human-written Rust code exhibits persistent internal quality issues such as readability and non-idiomatic patterns. Together, these findings show that translation quality remains a multi-dimensional challenge, requiring systematic evaluation and targeted tool support beyond both naive automation and manual rewriting.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u4e09\u79cdC\u5230Rust\u7ffb\u8bd1\u5de5\u5177(C2Rust\u3001C2SaferRust\u3001TranslationGym)\u5728\u7ffb\u8bd1GNU coreutils\u65f6\u7684\u8d28\u91cf\u8868\u73b0\uff0c\u53d1\u73b0\u81ea\u52a8\u5316\u7ffb\u8bd1\u5728\u5b89\u5168\u6027\u3001\u6027\u80fd\u3001\u5065\u58ee\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u7b49\u591a\u7ef4\u8d28\u91cf\u6307\u6807\u4e0a\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u65e0\u6cd5\u5728\u6240\u6709\u7ef4\u5ea6\u4e0a\u8d85\u8d8a\u4eba\u5de5\u7ffb\u8bd1\u3002", "motivation": "C/C++\u5b58\u5728\u4e25\u91cd\u7684\u5185\u5b58\u548c\u7ebf\u7a0b\u5b89\u5168\u95ee\u9898\uff0c\u867d\u7136\u5df2\u6709\u7814\u7a76\u63a2\u7d22\u5c06\u5176\u81ea\u52a8\u7ffb\u8bd1\u5230\u66f4\u5b89\u5168\u7684Rust\u8bed\u8a00\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7ffb\u8bd1\u7684\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\uff0c\u800c\u5ffd\u7565\u4e86\u6027\u80fd\u3001\u5065\u58ee\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u7b49\u5176\u4ed6\u91cd\u8981\u8d28\u91cf\u7ef4\u5ea6\u3002", "method": "\u4f7f\u7528\u4e09\u79cdC-to-Rust\u7ffb\u8bd1\u5de5\u5177(C2Rust\u3001C2SaferRust\u3001TranslationGym)\u7ffb\u8bd1GNU coreutils\uff0c\u4ee5\u4eba\u5de5\u7ffb\u8bd1\u4e3a\u57fa\u51c6\u3002\u901a\u8fc7\u4e09\u79cd\u65b9\u6cd5\u8bc4\u4f30Rust\u4ee3\u7801\u8d28\u91cf\uff1a1) \u4f7f\u7528Clippy\u9759\u6001\u5206\u6790\u5de5\u5177\uff1b2) \u5229\u7528GPT-4o\u8bc6\u522bClippy\u53ef\u80fd\u9057\u6f0f\u7684\u95ee\u9898\uff1b3) \u5bf9Clippy\u548cGPT-4o\u62a5\u544a\u7684\u95ee\u9898\u8fdb\u884c\u624b\u52a8\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u867d\u7136\u65b0\u6280\u672f\u51cf\u5c11\u4e86\u4e00\u4e9b\u4e0d\u5b89\u5168\u548c\u975e\u60ef\u7528\u6a21\u5f0f\uff0c\u4f46\u7ecf\u5e38\u5f15\u5165\u65b0\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u8bc4\u4f30\u5b9e\u8df5\u4e2d\u4e0d\u53ef\u89c1\u7684\u7cfb\u7edf\u6027\u6743\u8861\u3002\u6ca1\u6709\u4efb\u4f55\u81ea\u52a8\u5316\u6280\u672f\u5728\u6240\u6709\u8d28\u91cf\u7ef4\u5ea6\u4e0a\u59cb\u7ec8\u5339\u914d\u6216\u8d85\u8d8a\u4eba\u5de5\u7ffb\u8bd1\uff0c\u4f46\u5373\u4f7f\u662f\u4eba\u5de5\u7f16\u5199\u7684Rust\u4ee3\u7801\u4e5f\u5b58\u5728\u53ef\u8bfb\u6027\u548c\u975e\u60ef\u7528\u6a21\u5f0f\u7b49\u6301\u7eed\u7684\u5185\u90e8\u8d28\u91cf\u95ee\u9898\u3002", "conclusion": "\u7ffb\u8bd1\u8d28\u91cf\u4ecd\u7136\u662f\u4e00\u4e2a\u591a\u7ef4\u6311\u6218\uff0c\u9700\u8981\u8d85\u8d8a\u7b80\u5355\u81ea\u52a8\u5316\u548c\u624b\u52a8\u91cd\u5199\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u548c\u9488\u5bf9\u6027\u5de5\u5177\u652f\u6301\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u8bc4\u4f30C\u5230Rust\u7ffb\u8bd1\u65f6\u8003\u8651\u591a\u7ef4\u5ea6\u8d28\u91cf\u5c5e\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.00270", "categories": ["cs.CR", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00270", "abs": "https://arxiv.org/abs/2602.00270", "authors": ["Mohsen Salehi", "Karthik Pattabiraman"], "title": "RVDebloater: Mode-based Adaptive Firmware Debloating for Robotic Vehicles", "comment": null, "summary": "As the number of embedded devices grows and their functional requirements increase, embedded firmware is becoming increasingly larger, thereby expanding its attack surface. Despite the increase in firmware size, many embedded devices, such as robotic vehicles (RVs), operate in distinct modes, each requiring only a small subset of the firmware code at runtime. We refer to such devices as mode-based embedded devices. Debloating is an approach to reduce attack surfaces by removing or restricting unneeded code, but existing techniques suffer from significant limitations, such as coarse granularity and irreversible code removal, limiting their applicability.\n  To address these limitations, we propose RVDebloater, a novel adaptive debloating technique for mode-based embedded devices that automatically identifies unneeded firmware code for each mode using either static or dynamic analysis, and dynamically debloats the firmware for each mode at the function level at runtime. RVDebloater introduces a new software-based enforcement approach that supports diverse mode-based embedded devices. We implemented RVDebloater using the LLVM compiler and evaluated its efficiency and effectiveness on six different RVs, including both simulated and real ones, with different real-world missions. We find that device requirements change throughout its lifetime for each mode, and that many critical firmware functions can be restricted in other modes, with an average of 85% of functions not being required. The results showed that none of the missions failed after debloating with RVDebloater, indicating that it neither incurred false positives nor false negatives. Further, RVDebloater prunes the firmware call graph by an average of 45% across different firmware. Finally, RVDebloater incurred an average performance overhead of 3.9% and memory overhead of 4% (approximately 0.25 MB) on real RVs.", "AI": {"tldr": "RVDebloater\uff1a\u4e00\u79cd\u9488\u5bf9\u6a21\u5f0f\u5316\u5d4c\u5165\u5f0f\u8bbe\u5907\u7684\u81ea\u9002\u5e94\u53bb\u81a8\u80c0\u6280\u672f\uff0c\u901a\u8fc7\u8fd0\u884c\u65f6\u51fd\u6570\u7ea7\u52a8\u6001\u53bb\u81a8\u80c0\u51cf\u5c11\u653b\u51fb\u9762\uff0c\u5728\u673a\u5668\u4eba\u8f66\u8f86\u4e0a\u5b9e\u73b0\u5e73\u574785%\u51fd\u6570\u9650\u5236\u300145%\u8c03\u7528\u56fe\u526a\u679d\uff0c\u6027\u80fd\u5f00\u9500\u4ec53.9%", "motivation": "\u5d4c\u5165\u5f0f\u8bbe\u5907\u56fa\u4ef6\u89c4\u6a21\u589e\u5927\u5bfc\u81f4\u653b\u51fb\u9762\u6269\u5927\uff0c\u4f46\u8bb8\u591a\u8bbe\u5907\uff08\u5982\u673a\u5668\u4eba\u8f66\u8f86\uff09\u5728\u4e0d\u540c\u6a21\u5f0f\u4e0b\u4ec5\u9700\u5c11\u91cf\u4ee3\u7801\u3002\u73b0\u6709\u53bb\u81a8\u80c0\u6280\u672f\u5b58\u5728\u7c92\u5ea6\u7c97\u3001\u4e0d\u53ef\u9006\u7b49\u9650\u5236\uff0c\u96be\u4ee5\u9002\u7528\u3002", "method": "\u63d0\u51faRVDebloater\uff1a\u57fa\u4e8eLLVM\u7f16\u8bd1\u5668\u5b9e\u73b0\uff0c\u901a\u8fc7\u9759\u6001\u6216\u52a8\u6001\u5206\u6790\u81ea\u52a8\u8bc6\u522b\u5404\u6a21\u5f0f\u4e0d\u9700\u8981\u7684\u56fa\u4ef6\u4ee3\u7801\uff0c\u5728\u8fd0\u884c\u65f6\u4ee5\u51fd\u6570\u7ea7\u7c92\u5ea6\u52a8\u6001\u53bb\u81a8\u80c0\uff0c\u91c7\u7528\u8f6f\u4ef6\u5f3a\u5236\u6267\u884c\u65b9\u6cd5\u652f\u6301\u591a\u6837\u5316\u6a21\u5f0f\u8bbe\u5907\u3002", "result": "\u57286\u79cd\u673a\u5668\u4eba\u8f66\u8f86\uff08\u6a21\u62df\u548c\u771f\u5b9e\uff09\u4e0a\u8bc4\u4f30\uff1a\u5e73\u574785%\u51fd\u6570\u5728\u5176\u4ed6\u6a21\u5f0f\u4e0b\u53ef\u9650\u5236\uff0c\u8c03\u7528\u56fe\u5e73\u5747\u526a\u679d45%\uff0c\u4efb\u52a1\u5b8c\u6210\u7387100%\uff08\u65e0\u5047\u9633\u6027/\u5047\u9634\u6027\uff09\uff0c\u771f\u5b9e\u8bbe\u5907\u4e0a\u5e73\u5747\u6027\u80fd\u5f00\u95003.9%\u3001\u5185\u5b58\u5f00\u95004%\uff08\u7ea60.25MB\uff09\u3002", "conclusion": "RVDebloater\u80fd\u6709\u6548\u51cf\u5c11\u6a21\u5f0f\u5316\u5d4c\u5165\u5f0f\u8bbe\u5907\u7684\u653b\u51fb\u9762\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u3001\u53ef\u9002\u5e94\u7684\u8fd0\u884c\u65f6\u53bb\u81a8\u80c0\uff0c\u5728\u4fdd\u8bc1\u4efb\u52a1\u5b8c\u6210\u7684\u540c\u65f6\u4fdd\u6301\u4f4e\u5f00\u9500\uff0c\u4e3a\u5d4c\u5165\u5f0f\u5b89\u5168\u63d0\u4f9b\u65b0\u65b9\u6848\u3002"}}
{"id": "2602.00353", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00353", "abs": "https://arxiv.org/abs/2602.00353", "authors": ["Yihe Zhang", "Cheyenne N Mohawk", "Kaiying Han", "Vijay Srinivas Tida", "Manyu Li", "Xiali Hei"], "title": "MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants", "comment": "Accepted for presentation at IEEE SoutheastCon 2026. This is the author version of an accepted paper. The final version will appear in IEEE Xplore", "summary": "Large language models (LLMs) are increasingly applied in mental health support systems, where reliable recognition of high-risk states such as suicidal ideation and self-harm is safety-critical. However, existing evaluations primarily rely on aggregate performance metrics, which often obscure risk-specific failure modes and provide limited insight into model behavior in realistic, multi-turn interactions. We present MHDash, an open-source platform designed to support the development, evaluation, and auditing of AI systems for mental health applications. MHDash integrates data collection, structured annotation, multi-turn dialogue generation, and baseline evaluation into a unified pipeline. The platform supports annotations across multiple dimensions, including Concern Type, Risk Level, and Dialogue Intent, enabling fine-grained and risk-aware analysis. Our results reveal several key findings: (i) simple baselines and advanced LLM APIs exhibit comparable overall accuracy yet diverge significantly on high-risk cases; (ii) some LLMs maintain consistent ordinal severity ranking while failing absolute risk classification, whereas others achieve reasonable aggregate scores but suffer from high false negative rates on severe categories; and (iii) performance gaps are amplified in multi-turn dialogues, where risk signals emerge gradually. These observations demonstrate that conventional benchmarks are insufficient for safety-critical mental health settings. By releasing MHDash as an open platform, we aim to promote reproducible research, transparent evaluation, and safety-aligned development of AI systems for mental health support.", "AI": {"tldr": "MHDash\u662f\u4e00\u4e2a\u5f00\u6e90\u5e73\u53f0\uff0c\u7528\u4e8eAI\u5fc3\u7406\u5065\u5eb7\u7cfb\u7edf\u7684\u5f00\u53d1\u3001\u8bc4\u4f30\u548c\u5ba1\u8ba1\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u6807\u6ce8\u548c\u591a\u8f6e\u5bf9\u8bdd\u5206\u6790\uff0c\u63ed\u793a\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u5fc3\u7406\u5065\u5eb7AI\u7cfb\u7edf\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u805a\u5408\u6027\u80fd\u6307\u6807\uff0c\u8fd9\u4e9b\u6307\u6807\u5f80\u5f80\u63a9\u76d6\u4e86\u9ad8\u98ce\u9669\u7279\u5b9a\u6545\u969c\u6a21\u5f0f\uff0c\u4e14\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u591a\u8f6e\u4ea4\u4e92\u4e2d\u7684\u6a21\u578b\u884c\u4e3a\uff0c\u8fd9\u5728\u8bc6\u522b\u81ea\u6740\u610f\u5ff5\u548c\u81ea\u4f24\u7b49\u9ad8\u98ce\u9669\u72b6\u6001\u7684\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86MHDash\u5f00\u6e90\u5e73\u53f0\uff0c\u6574\u5408\u4e86\u6570\u636e\u6536\u96c6\u3001\u7ed3\u6784\u5316\u6807\u6ce8\u3001\u591a\u8f6e\u5bf9\u8bdd\u751f\u6210\u548c\u57fa\u7ebf\u8bc4\u4f30\u7684\u7edf\u4e00\u6d41\u7a0b\u3002\u5e73\u53f0\u652f\u6301\u591a\u7ef4\u5ea6\u6807\u6ce8\uff08\u5173\u6ce8\u7c7b\u578b\u3001\u98ce\u9669\u7b49\u7ea7\u3001\u5bf9\u8bdd\u610f\u56fe\uff09\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u548c\u98ce\u9669\u611f\u77e5\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(1)\u7b80\u5355\u57fa\u7ebf\u548c\u5148\u8fdbLLM API\u603b\u4f53\u51c6\u786e\u7387\u76f8\u5f53\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u6848\u4f8b\u4e0a\u8868\u73b0\u663e\u8457\u4e0d\u540c\uff1b(2)\u67d0\u4e9bLLM\u4fdd\u6301\u4e00\u81f4\u7684\u4e25\u91cd\u7a0b\u5ea6\u6392\u5e8f\u4f46\u7edd\u5bf9\u98ce\u9669\u5206\u7c7b\u5931\u8d25\uff0c\u800c\u5176\u4ed6\u6a21\u578b\u603b\u4f53\u5f97\u5206\u5408\u7406\u4f46\u5728\u4e25\u91cd\u7c7b\u522b\u4e0a\u5047\u9634\u6027\u7387\u9ad8\uff1b(3)\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u6027\u80fd\u5dee\u8ddd\u88ab\u653e\u5927\uff0c\u98ce\u9669\u4fe1\u53f7\u9010\u6e10\u663e\u73b0\u3002", "conclusion": "\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u5728\u5b89\u5168\u5173\u952e\u7684\u5fc3\u7406\u5065\u5eb7\u573a\u666f\u4e2d\u4e0d\u8db3\uff0cMHDash\u4f5c\u4e3a\u5f00\u6e90\u5e73\u53f0\u65e8\u5728\u4fc3\u8fdb\u53ef\u91cd\u590d\u7814\u7a76\u3001\u900f\u660e\u8bc4\u4f30\u548cAI\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u7cfb\u7edf\u7684\u5b89\u5168\u5bf9\u9f50\u5f00\u53d1\u3002"}}
{"id": "2602.00933", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00933", "abs": "https://arxiv.org/abs/2602.00933", "authors": ["Chaithanya Bandi", "Ben Hertzberg", "Geobio Boo", "Tejas Polakam", "Jeff Da", "Sami Hassaan", "Manasi Sharma", "Andrew Park", "Ernesto Hernandez", "Dan Rambado", "Ivan Salazar", "Rafael Cruz", "Chetan Rane", "Ben Levin", "Brad Kenstler", "Bing Liu"], "title": "MCP-Atlas: A Large-Scale Benchmark for Tool-Use Competency with Real MCP Servers", "comment": null, "summary": "The Model Context Protocol (MCP) is rapidly becoming the standard interface for Large Language Models (LLMs) to discover and invoke external tools. However, existing evaluations often fail to capture the complexity of real-world scenarios, relying on restricted toolsets, simplistic workflows, or subjective LLM-as-a-judge metrics. We introduce MCP-Atlas, a large-scale benchmark for evaluating tool-use competency, comprising 36 real MCP servers and 220 tools. It includes 1,000 tasks designed to assess tool-use competency in realistic, multi-step workflows. Tasks use natural language prompts that avoid naming specific tools or servers, requiring agents to identify and orchestrate 3-6 tool calls across multiple servers. We score tasks using a claims-based rubric that awards partial credit based on the factual claims satisfied in the model's final answer, complemented by internal diagnostics on tool discovery, parameterization, syntax, error recovery, and efficiency. Evaluation results on frontier models reveal that top models achieve pass rates exceeding 50%, with primary failures arising from inadequate tool usage and task understanding. We release the task schema, containerized harness, and a 500-task public subset of the benchmark dataset to facilitate reproducible comparisons and advance the development of robust, tool-augmented agents.", "AI": {"tldr": "MCP-Atlas\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b36\u4e2a\u771f\u5b9eMCP\u670d\u52a1\u5668\u3001220\u4e2a\u5de5\u5177\u548c1000\u4e2a\u4efb\u52a1\uff0c\u4e13\u6ce8\u4e8e\u591a\u6b65\u9aa4\u5de5\u4f5c\u6d41\u7684\u771f\u5b9e\u573a\u666f\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u573a\u666f\u7684\u590d\u6742\u6027\uff0c\u901a\u5e38\u4f9d\u8d56\u53d7\u9650\u5de5\u5177\u96c6\u3001\u7b80\u5355\u5de5\u4f5c\u6d41\u6216\u4e3b\u89c2\u7684LLM-as-a-judge\u6307\u6807\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u521b\u5efa\u5305\u542b36\u4e2a\u771f\u5b9eMCP\u670d\u52a1\u5668\u548c220\u4e2a\u5de5\u5177\u7684\u5927\u89c4\u6a21\u57fa\u51c6\uff0c\u8bbe\u8ba11000\u4e2a\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u8de8\u591a\u4e2a\u670d\u52a1\u5668\u8bc6\u522b\u548c\u534f\u8c033-6\u4e2a\u5de5\u5177\u8c03\u7528\uff0c\u4f7f\u7528\u57fa\u4e8e\u58f0\u660e\u7684\u8bc4\u5206\u6807\u51c6\uff0c\u8f85\u4ee5\u5de5\u5177\u53d1\u73b0\u3001\u53c2\u6570\u5316\u3001\u8bed\u6cd5\u3001\u9519\u8bef\u6062\u590d\u548c\u6548\u7387\u7b49\u5185\u90e8\u8bca\u65ad\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u7684\u901a\u8fc7\u7387\u8d85\u8fc750%\uff0c\u4e3b\u8981\u5931\u8d25\u539f\u56e0\u6765\u81ea\u5de5\u5177\u4f7f\u7528\u4e0d\u8db3\u548c\u4efb\u52a1\u7406\u89e3\u4e0d\u8db3\u3002\u53d1\u5e03\u4e86\u4efb\u52a1\u6a21\u5f0f\u3001\u5bb9\u5668\u5316\u6846\u67b6\u548c500\u4e2a\u4efb\u52a1\u7684\u516c\u5171\u5b50\u96c6\u3002", "conclusion": "MCP-Atlas\u4e3a\u5de5\u5177\u589e\u5f3a\u578b\u667a\u80fd\u4f53\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u6bd4\u8f83\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u5f3a\u5927\u3001\u66f4\u7a33\u5065\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u53d1\u5c55\u3002"}}
{"id": "2602.00972", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00972", "abs": "https://arxiv.org/abs/2602.00972", "authors": ["Zhuangbin Chen", "Zhiling Deng", "Kaiming Zhang", "Yang Liu", "Cheng Cui", "Jinfeng Zhong", "Zibin Zheng"], "title": "Cast: Automated Resilience Testing for Production Cloud Service Systems", "comment": null, "summary": "The distributed nature of microservice architecture introduces significant resilience challenges. Traditional testing methods, limited by extensive manual effort and oversimplified test environments, fail to capture production system complexity. To address these limitations, we present Cast, an automated, end-to-end framework for microservice resilience testing in production. It achieves high test fidelity by replaying production traffic against a comprehensive library of application-level faults to exercise internal error-handling logic. To manage the combinatorial test space, Cast employs a complexity-driven strategy to systematically prune redundant tests and prioritize high-value tests targeting the most critical service execution paths. Cast automates the testing lifecycle through a three-phase pipeline (i.e., startup, fault injection, and recovery) and uses a multi-faceted oracle to automatically verify system resilience against nuanced criteria. Deployed in Huawei Cloud for over eight months, Cast has been adopted by many service teams to proactively address resilience vulnerabilities. Our analysis on four large-scale applications with millions of traces reveals 137 potential vulnerabilities, with 89 confirmed by developers. To further quantify its performance, Cast is evaluated on a benchmark set of 48 reproduced bugs, achieving a high coverage of 90%. The results show that Cast is a practical and effective solution for systematically improving the reliability of industrial microservice systems.", "AI": {"tldr": "Cast\u662f\u4e00\u4e2a\u7528\u4e8e\u5fae\u670d\u52a1\u97e7\u6027\u6d4b\u8bd5\u7684\u81ea\u52a8\u5316\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u91cd\u653e\u6d41\u91cf\u5e76\u6ce8\u5165\u5e94\u7528\u7ea7\u6545\u969c\u6765\u53d1\u73b0\u7cfb\u7edf\u8106\u5f31\u6027\uff0c\u5df2\u5728\u534e\u4e3a\u4e91\u90e8\u7f728\u4e2a\u6708\u4ee5\u4e0a\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u7684\u5206\u5e03\u5f0f\u7279\u6027\u5e26\u6765\u4e86\u663e\u8457\u7684\u97e7\u6027\u6311\u6218\u3002\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u53d7\u9650\u4e8e\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\u548c\u8fc7\u5ea6\u7b80\u5316\u7684\u6d4b\u8bd5\u73af\u5883\uff0c\u65e0\u6cd5\u6355\u6349\u751f\u4ea7\u7cfb\u7edf\u7684\u590d\u6742\u6027\u3002", "method": "Cast\u91c7\u7528\u4e09\u9636\u6bb5\u7ba1\u9053\uff08\u542f\u52a8\u3001\u6545\u969c\u6ce8\u5165\u548c\u6062\u590d\uff09\uff0c\u901a\u8fc7\u91cd\u653e\u751f\u4ea7\u6d41\u91cf\u5e76\u6ce8\u5165\u5e94\u7528\u7ea7\u6545\u969c\u6765\u6d4b\u8bd5\u5185\u90e8\u9519\u8bef\u5904\u7406\u903b\u8f91\u3002\u4f7f\u7528\u590d\u6742\u5ea6\u9a71\u52a8\u7b56\u7565\u4fee\u526a\u5197\u4f59\u6d4b\u8bd5\u5e76\u4f18\u5148\u5904\u7406\u5173\u952e\u670d\u52a1\u6267\u884c\u8def\u5f84\u7684\u9ad8\u4ef7\u503c\u6d4b\u8bd5\u3002\u91c7\u7528\u591a\u65b9\u9762oracle\u81ea\u52a8\u9a8c\u8bc1\u7cfb\u7edf\u97e7\u6027\u3002", "result": "\u5728\u534e\u4e3a\u4e91\u90e8\u7f728\u4e2a\u6708\u4ee5\u4e0a\uff0c\u88ab\u591a\u4e2a\u670d\u52a1\u56e2\u961f\u91c7\u7528\u3002\u5bf94\u4e2a\u5927\u89c4\u6a21\u5e94\u7528\u7684\u5206\u6790\u53d1\u73b0\u4e86137\u4e2a\u6f5c\u5728\u8106\u5f31\u6027\uff0c\u5176\u4e2d89\u4e2a\u88ab\u5f00\u53d1\u8005\u786e\u8ba4\u3002\u572848\u4e2a\u590d\u73b0bug\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523090%\u7684\u8986\u76d6\u7387\u3002", "conclusion": "Cast\u662f\u4e00\u4e2a\u5b9e\u7528\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u63d0\u9ad8\u5de5\u4e1a\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2602.00338", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00338", "abs": "https://arxiv.org/abs/2602.00338", "authors": ["Abdurrahman Elmaghbub", "Bechir Hamdaoui"], "title": "HEEDFUL: Leveraging Sequential Transfer Learning for Robust WiFi Device Fingerprinting Amid Hardware Warm-Up Effects", "comment": null, "summary": "Deep Learning-based RF fingerprinting approaches struggle to perform well in cross-domain scenarios, particularly during hardware warm-up. This often-overlooked vulnerability has been jeopardizing their reliability and their adoption in practical settings. To address this critical gap, in this work, we first dive deep into the anatomy of RF fingerprints, revealing insights into the temporal fingerprinting variations during and post hardware stabilization. Introducing HEEDFUL, a novel framework harnessing sequential transfer learning and targeted impairment estimation, we then address these challenges with remarkable consistency, eliminating blind spots even during challenging warm-up phases. Our evaluation showcases HEEDFUL's efficacy, achieving remarkable classification accuracies of up to 96% during the initial device operation intervals-far surpassing traditional models. Furthermore, cross-day and cross-protocol assessments confirm HEEDFUL's superiority, achieving and maintaining high accuracy during both the stable and initial warm-up phases when tested on WiFi signals. Additionally, we release WiFi type B and N RF fingerprint datasets that, for the first time, incorporate both the time-domain representation and real hardware impairments of the frames. This underscores the importance of leveraging hardware impairment data, enabling a deeper understanding of fingerprints and facilitating the development of more robust RF fingerprinting solutions.", "AI": {"tldr": "HEEDFUL\u6846\u67b6\u901a\u8fc7\u5e8f\u5217\u8fc1\u79fb\u5b66\u4e60\u548c\u76ee\u6807\u635f\u4f24\u4f30\u8ba1\u89e3\u51b3RF\u6307\u7eb9\u8bc6\u522b\u5728\u786c\u4ef6\u9884\u70ed\u9636\u6bb5\u7684\u8de8\u57df\u6027\u80fd\u95ee\u9898\uff0c\u5728WiFi\u4fe1\u53f7\u4e0a\u8fbe\u523096%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684RF\u6307\u7eb9\u8bc6\u522b\u65b9\u6cd5\u5728\u8de8\u57df\u573a\u666f\uff08\u7279\u522b\u662f\u786c\u4ef6\u9884\u70ed\u9636\u6bb5\uff09\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u4e00\u5e38\u88ab\u5ffd\u89c6\u7684\u6f0f\u6d1e\u5f71\u54cd\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u548c\u91c7\u7528\u3002", "method": "\u63d0\u51faHEEDFUL\u6846\u67b6\uff0c\u7ed3\u5408\u5e8f\u5217\u8fc1\u79fb\u5b66\u4e60\u548c\u76ee\u6807\u635f\u4f24\u4f30\u8ba1\u6280\u672f\uff0c\u6df1\u5165\u5206\u6790RF\u6307\u7eb9\u5728\u786c\u4ef6\u7a33\u5b9a\u671f\u95f4\u548c\u7a33\u5b9a\u540e\u7684\u65f6\u95f4\u53d8\u5316\u7279\u5f81\u3002", "result": "HEEDFUL\u5728\u8bbe\u5907\u521d\u59cb\u8fd0\u884c\u9636\u6bb5\u8fbe\u523096%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u8fdc\u8d85\u4f20\u7edf\u6a21\u578b\uff1b\u8de8\u65e5\u548c\u8de8\u534f\u8bae\u8bc4\u4f30\u4e5f\u663e\u793a\u5176\u5728\u7a33\u5b9a\u548c\u9884\u70ed\u9636\u6bb5\u5747\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "HEEDFUL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86RF\u6307\u7eb9\u8bc6\u522b\u5728\u786c\u4ef6\u9884\u70ed\u9636\u6bb5\u7684\u6027\u80fd\u95ee\u9898\uff0c\u53d1\u5e03\u7684WiFi\u6570\u636e\u96c6\u9996\u6b21\u5305\u542b\u65f6\u57df\u8868\u793a\u548c\u771f\u5b9e\u786c\u4ef6\u635f\u4f24\u6570\u636e\uff0c\u5f3a\u8c03\u4e86\u5229\u7528\u786c\u4ef6\u635f\u4f24\u6570\u636e\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.00370", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00370", "abs": "https://arxiv.org/abs/2602.00370", "authors": ["Trisha Das", "Katherine Kero", "Dorinda Schumann", "Tracy Ohrt", "Sanjit Singh Batra", "Gregory D Lyng", "Robert E. Tillman"], "title": "POET: Protocol Optimization via Eligibility Tuning", "comment": null, "summary": "Eligibility criteria (EC) are essential for clinical trial design, yet drafting them remains a time-intensive and cognitively demanding task for clinicians. Existing automated approaches often fall at two extremes either requiring highly structured inputs, such as predefined entities to generate specific criteria, or relying on end-to-end systems that produce full eligibility criteria from minimal input such as trial descriptions limiting their practical utility. In this work, we propose a guided generation framework that introduces interpretable semantic axes, such as Demographics, Laboratory Parameters, and Behavioral Factors, to steer EC generation. These axes, derived using large language models, offer a middle ground between specificity and usability, enabling clinicians to guide generation without specifying exact entities. In addition, we present a reusable rubric-based evaluation framework that assesses generated criteria along clinically meaningful dimensions. Our results show that our guided generation approach consistently outperforms unguided generation in both automatic, rubric-based and clinician evaluations, offering a practical and interpretable solution for AI-assisted trial design.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53ef\u89e3\u91ca\u8bed\u4e49\u8f74\u7684\u5f15\u5bfc\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u4e34\u5e8a\u7814\u7a76\u8d44\u683c\u6807\u51c6\u751f\u6210\uff0c\u5e73\u8861\u4e86\u7279\u5b9a\u6027\u548c\u53ef\u7528\u6027\uff0c\u5e76\u901a\u8fc7\u53ef\u91cd\u7528\u8bc4\u4f30\u6846\u67b6\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "motivation": "\u4e34\u5e8a\u7814\u7a76\u8d44\u683c\u6807\u51c6\u8bbe\u8ba1\u8017\u65f6\u4e14\u8ba4\u77e5\u8d1f\u62c5\u91cd\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u9ad8\u5ea6\u7ed3\u6784\u5316\u8f93\u5165\uff0c\u8981\u4e48\u4f9d\u8d56\u7aef\u5230\u7aef\u7cfb\u7edf\u751f\u6210\u5b8c\u6574\u6807\u51c6\uff0c\u5b9e\u7528\u6027\u6709\u9650\u3002", "method": "\u63d0\u51fa\u5f15\u5bfc\u751f\u6210\u6846\u67b6\uff0c\u5f15\u5165\u53ef\u89e3\u91ca\u8bed\u4e49\u8f74\uff08\u5982\u4eba\u53e3\u7edf\u8ba1\u5b66\u3001\u5b9e\u9a8c\u5ba4\u53c2\u6570\u3001\u884c\u4e3a\u56e0\u7d20\uff09\u6765\u6307\u5bfc\u8d44\u683c\u6807\u51c6\u751f\u6210\u3002\u8fd9\u4e9b\u8bed\u4e49\u8f74\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u5bfc\uff0c\u63d0\u4f9b\u7279\u5b9a\u6027\u548c\u53ef\u7528\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "result": "\u5f15\u5bfc\u751f\u6210\u65b9\u6cd5\u5728\u81ea\u52a8\u8bc4\u4f30\u3001\u57fa\u4e8e\u91cf\u8868\u7684\u8bc4\u4f30\u548c\u4e34\u5e8a\u533b\u751f\u8bc4\u4f30\u4e2d\u5747\u4f18\u4e8e\u975e\u5f15\u5bfc\u751f\u6210\uff0c\u4e3aAI\u8f85\u52a9\u8bd5\u9a8c\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u5f15\u5bfc\u751f\u6210\u6846\u67b6\u4e3a\u4e34\u5e8a\u7814\u7a76\u8d44\u683c\u6807\u51c6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u89e3\u91ca\u7684AI\u8f85\u52a9\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u7279\u5b9a\u6027\u548c\u53ef\u7528\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2602.01044", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01044", "abs": "https://arxiv.org/abs/2602.01044", "authors": ["Yu Tang", "Hailiang Zhao", "Chuansheng Lu", "Yifei Zhang", "Kingsum Chow", "Shuiguang Deng", "Rui Shi"], "title": "Morphis: SLO-Aware Resource Scheduling for Microservices with Time-Varying Call Graphs", "comment": null, "summary": "Modern microservice systems exhibit continuous structural evolution in their runtime call graphs due to workload fluctuations, fault responses, and deployment activities. Despite this complexity, our analysis of over 500,000 production traces from ByteDance reveals a latent regularity: execution paths concentrate around a small set of recurring invocation patterns. However, existing resource management approaches fail to exploit this structure. Industrial autoscalers like Kubernetes HPA ignore inter-service dependencies, while recent academic methods often assume static topologies, rendering them ineffective under dynamic execution contexts. In this work, we propose Morphis, a dependency-aware provisioning framework that unifies pattern-aware trace analysis with global optimization. It introduces structural fingerprinting that decomposes traces into a stable execution backbone and interpretable deviation subgraphs. Then, resource allocation is formulated as a constrained optimization problem over predicted pattern distributions, jointly minimizing aggregate CPU usage while satisfying end-to-end tail-latency SLOs. Our extensive evaluations on the TrainTicket benchmark demonstrate that Morphis reduces CPU consumption by 35-38% compared to state-of-the-art baselines while maintaining 98.8% SLO compliance.", "AI": {"tldr": "Morphis\u662f\u4e00\u4e2a\u4f9d\u8d56\u611f\u77e5\u7684\u8d44\u6e90\u4f9b\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u5fae\u670d\u52a1\u8c03\u7528\u56fe\u4e2d\u7684\u91cd\u590d\u6267\u884c\u6a21\u5f0f\uff0c\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u5728\u4fdd\u8bc1SLO\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4eCPU\u6d88\u8017\u3002", "motivation": "\u73b0\u4ee3\u5fae\u670d\u52a1\u7cfb\u7edf\u5728\u8fd0\u884c\u65f6\u8c03\u7528\u56fe\u5b58\u5728\u6301\u7eed\u7ed3\u6784\u6f14\u5316\uff0c\u4f46\u5206\u6790\u663e\u793a\u6267\u884c\u8def\u5f84\u96c6\u4e2d\u5728\u5c11\u91cf\u91cd\u590d\u8c03\u7528\u6a21\u5f0f\u4e0a\u3002\u73b0\u6709\u8d44\u6e90\u7ba1\u7406\u65b9\u6cd5\u8981\u4e48\u5ffd\u7565\u670d\u52a1\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u8981\u4e48\u5047\u8bbe\u9759\u6001\u62d3\u6251\uff0c\u65e0\u6cd5\u6709\u6548\u5229\u7528\u8fd9\u79cd\u7ed3\u6784\u89c4\u5f8b\u3002", "method": "\u63d0\u51faMorphis\u6846\u67b6\uff1a1\uff09\u5f15\u5165\u7ed3\u6784\u6307\u7eb9\u6280\u672f\uff0c\u5c06\u8ddf\u8e2a\u6570\u636e\u5206\u89e3\u4e3a\u7a33\u5b9a\u7684\u6267\u884c\u4e3b\u5e72\u548c\u53ef\u89e3\u91ca\u7684\u504f\u5dee\u5b50\u56fe\uff1b2\uff09\u5c06\u8d44\u6e90\u5206\u914d\u5efa\u6a21\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u57fa\u4e8e\u9884\u6d4b\u7684\u6a21\u5f0f\u5206\u5e03\uff0c\u8054\u5408\u6700\u5c0f\u5316\u603bCPU\u4f7f\u7528\u540c\u65f6\u6ee1\u8db3\u7aef\u5230\u7aef\u5c3e\u5ef6\u8fdfSLO\u3002", "result": "\u5728TrainTicket\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cMorphis\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u51cf\u5c1135-38%\u7684CPU\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u630198.8%\u7684SLO\u5408\u89c4\u7387\u3002", "conclusion": "Morphis\u901a\u8fc7\u5229\u7528\u5fae\u670d\u52a1\u8c03\u7528\u56fe\u4e2d\u7684\u7ed3\u6784\u89c4\u5f8b\uff0c\u5b9e\u73b0\u4e86\u4f9d\u8d56\u611f\u77e5\u7684\u8d44\u6e90\u4f9b\u5e94\uff0c\u5728\u52a8\u6001\u6267\u884c\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u8d44\u6e90\u6548\u7387\u3002"}}
{"id": "2602.00400", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00400", "abs": "https://arxiv.org/abs/2602.00400", "authors": ["Fan Yang", "Rui Meng", "Trudi Di Qi", "Ali Ezzati", "Yuxin Wen"], "title": "KEPO: Knowledge-Enhanced Preference Optimization for Reinforcement Learning with Reasoning", "comment": null, "summary": "Reinforcement learning (RL) has emerged as a promising paradigm for inducing explicit reasoning behaviors in large language and vision-language models. However, reasoning-oriented RL post-training remains fundamentally challenging due to sparse trajectory-level rewards, leading to ambiguous credit assignment and severe exploration failures that can trap the policy in a ``learning cliff.'' Recent on-policy distillation methods introduce dense teacher supervision to stabilize optimization, but apply it uniformly across all generated trajectories. We argue that such uniform distillation is ill-suited for reasoning-intensive tasks, as low-quality on-policy trajectories often originate from early logical errors, and distillation under flawed contexts injects noisy and misaligned gradients. To address these challenges, we propose Knowledge-Enhanced Preference Optimization (KEPO), a unified post-training framework that integrates: (i) a quality-gated on-policy distillation objective that selectively applies dense teacher guidance only to high-quality trajectories, and (ii) a knowledge-enhanced exploration strategy that leverages hints learned from a teacher model to rejectively sample reward-positive on-policy trajectories for RL, thereby mitigating exploration collapse. Evaluated on a challenging medical visual question answering benchmark under single-source generalization, KEPO demonstrates improved training stability, more coherent reasoning behaviors, and superior out-of-distribution performance over reinforcement learning and on-policy distillation baselines.", "AI": {"tldr": "KEPO\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8d28\u91cf\u95e8\u63a7\u84b8\u998f\u548c\u77e5\u8bc6\u589e\u5f3a\u63a2\u7d22\u7684\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7a00\u758f\u5956\u52b1\u548c\u63a2\u7d22\u5931\u8d25\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u63a8\u7406\u5bfc\u5411\u7684\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u9762\u4e34\u7a00\u758f\u8f68\u8ff9\u7ea7\u5956\u52b1\u5bfc\u81f4\u7684\u4fe1\u7528\u5206\u914d\u6a21\u7cca\u548c\u4e25\u91cd\u63a2\u7d22\u5931\u8d25\u95ee\u9898\uff0c\u800c\u73b0\u6709\u7684\u5747\u5300\u84b8\u998f\u65b9\u6cd5\u5728\u4f4e\u8d28\u91cf\u8f68\u8ff9\u4e0a\u4f1a\u4ea7\u751f\u566a\u58f0\u68af\u5ea6\u3002", "method": "KEPO\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u8d28\u91cf\u95e8\u63a7\u7684\u5728\u7ebf\u84b8\u998f\u76ee\u6807\uff0c\u4ec5\u5bf9\u9ad8\u8d28\u91cf\u8f68\u8ff9\u5e94\u7528\u5bc6\u96c6\u6559\u5e08\u6307\u5bfc\uff1b2\uff09\u77e5\u8bc6\u589e\u5f3a\u7684\u63a2\u7d22\u7b56\u7565\uff0c\u5229\u7528\u4ece\u6559\u5e08\u6a21\u578b\u5b66\u5230\u7684\u63d0\u793a\u6765\u62d2\u7edd\u6027\u91c7\u6837\u5956\u52b1\u6b63\u7684\u5728\u7ebf\u8f68\u8ff9\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cKEPO\u5728\u5355\u6e90\u6cdb\u5316\u4e0b\u8868\u73b0\u51fa\u66f4\u597d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u3001\u66f4\u4e00\u81f4\u7684\u63a8\u7406\u884c\u4e3a\u548c\u66f4\u4f18\u8d8a\u7684\u5206\u5e03\u5916\u6027\u80fd\u3002", "conclusion": "KEPO\u901a\u8fc7\u9009\u62e9\u6027\u84b8\u998f\u548c\u77e5\u8bc6\u589e\u5f3a\u63a2\u7d22\u6709\u6548\u89e3\u51b3\u4e86\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6311\u6218\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u7684\u6846\u67b6\u3002"}}
{"id": "2602.01107", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01107", "abs": "https://arxiv.org/abs/2602.01107", "authors": ["Daniel Ramos", "Catarina Gamboa", "In\u00eas Lynce", "Vasco Manquinho", "Ruben Martins", "Claire Le Goues"], "title": "SPELL: Synthesis of Programmatic Edits using LLMs", "comment": "pre-print", "summary": "Library migration is a common but error-prone task in software development. Developers may need to replace one library with another due to reasons like changing requirements or licensing changes. Migration typically entails updating and rewriting source code manually. While automated migration tools exist, most rely on mining examples from real-world projects that have already undergone similar migrations. However, these data are scarce, and collecting them for arbitrary pairs of libraries is difficult. Moreover, these migration tools often miss out on leveraging modern code transformation infrastructure.\n  In this paper, we present a new approach to automated API migration that sidesteps the limitations described above. Instead of relying on existing migration data or using LLMs directly for transformation, we use LLMs to extract migration examples. Next, we use an Agent to generalize those examples to reusable transformation scripts in PolyglotPiranha, a modern code transformation tool. Our method distills latent migration knowledge from LLMs into structured, testable, and repeatable migration logic, without requiring preexisting corpora or manual engineering effort. Experimental results across Python libraries show that our system can generate diverse migration examples and synthesize transformation scripts that generalize to real-world codebases.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u548cPolyglotPiranha\u7684\u81ea\u52a8\u5316API\u8fc1\u79fb\u65b0\u65b9\u6cd5\uff0c\u65e0\u9700\u4f9d\u8d56\u73b0\u6709\u8fc1\u79fb\u6570\u636e\u6216\u76f4\u63a5\u4f7f\u7528LLM\u8fdb\u884c\u4ee3\u7801\u8f6c\u6362", "motivation": "\u5e93\u8fc1\u79fb\u662f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e38\u89c1\u4f46\u6613\u51fa\u9519\u7684\u4efb\u52a1\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u8fc1\u79fb\u5de5\u5177\u5927\u591a\u4f9d\u8d56\u4ece\u5df2\u5b8c\u6210\u8fc1\u79fb\u7684\u771f\u5b9e\u9879\u76ee\u4e2d\u6316\u6398\u793a\u4f8b\uff0c\u4f46\u8fd9\u4e9b\u6570\u636e\u7a00\u7f3a\u4e14\u96be\u4ee5\u6536\u96c6\uff0c\u540c\u65f6\u8fd9\u4e9b\u5de5\u5177\u672a\u80fd\u5145\u5206\u5229\u7528\u73b0\u4ee3\u4ee3\u7801\u8f6c\u6362\u57fa\u7840\u8bbe\u65bd", "method": "\u4f7f\u7528LLM\u63d0\u53d6\u8fc1\u79fb\u793a\u4f8b\uff0c\u7136\u540e\u901a\u8fc7Agent\u5c06\u8fd9\u4e9b\u793a\u4f8b\u6cdb\u5316\u4e3aPolyglotPiranha\u4e2d\u7684\u53ef\u91cd\u7528\u8f6c\u6362\u811a\u672c\uff0c\u5c06LLM\u4e2d\u7684\u6f5c\u5728\u8fc1\u79fb\u77e5\u8bc6\u63d0\u70bc\u4e3a\u7ed3\u6784\u5316\u3001\u53ef\u6d4b\u8bd5\u3001\u53ef\u91cd\u590d\u7684\u8fc1\u79fb\u903b\u8f91", "result": "\u5728Python\u5e93\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u7684\u8fc1\u79fb\u793a\u4f8b\uff0c\u5e76\u5408\u6210\u80fd\u591f\u6cdb\u5316\u5230\u771f\u5b9e\u4ee3\u7801\u5e93\u7684\u8f6c\u6362\u811a\u672c", "conclusion": "\u8be5\u65b9\u6cd5\u907f\u514d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u65e0\u9700\u9884\u5148\u5b58\u5728\u7684\u8bed\u6599\u5e93\u6216\u624b\u52a8\u5de5\u7a0b\u5de5\u4f5c\uff0c\u5c31\u80fd\u5c06LLM\u7684\u8fc1\u79fb\u77e5\u8bc6\u8f6c\u5316\u4e3a\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u8fc1\u79fb\u903b\u8f91"}}
{"id": "2602.00411", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00411", "abs": "https://arxiv.org/abs/2602.00411", "authors": ["Wenhao Chen", "Wenyi Morty Zhang", "Wei Sun", "Dinesh Bharadia", "Roshan Ayyalasomayajula"], "title": "SpyDir: Spy Device Localization Through Accurate Direction Finding", "comment": null, "summary": "Hidden spy cameras have become a great privacy threat recently, as these low-cost, low-power, and small form-factor IoT devices can quietly monitor human activities in the indoor environment without generating any side-channel information. As such, it is difficult to detect and even more challenging to localize them in the rich-scattering indoor environment. To this end, this paper presents the design, implementation, and evaluation of SpyDir, a system that can accurately localize the hidden spy IoT devices by harnessing the electromagnetic emanations automatically and unintentionally emitted from them. Our system design mainly consists of a portable switching antenna array to sniff the spectrum-spread emanations, an emanation enhancement algorithm through non-coherent averaging that can de-correlate the correlated noise effect due to the square-wave emanation structure, and a multipath-resolving algorithm that can exploit the relative channels using a novel optimization-based sparse AoA derivation. Our real-world experimental evaluation across different indoor environments demonstrates an average AoA error of 6.30 deg, whereas the baseline algorithm yields 21.06 deg, achieving over a 3.3 times improvement in accuracy, and a mean localization error of 19.86cm over baseline algorithms of 206.79cm (MUSIC) and 294.75cm (SpotFi), achieving over a 10.41 times and 14.8 times improvement in accuracy.", "AI": {"tldr": "SpyDir\u7cfb\u7edf\u901a\u8fc7\u5229\u7528\u9690\u85cf\u95f4\u8c0dIoT\u8bbe\u5907\u81ea\u52a8\u53d1\u5c04\u7684\u7535\u78c1\u8f90\u5c04\uff0c\u5728\u5ba4\u5185\u73af\u5883\u4e2d\u51c6\u786e\u5b9a\u4f4d\u8fd9\u4e9b\u8bbe\u5907\uff0c\u76f8\u6bd4\u57fa\u7ebf\u7b97\u6cd5\u5728AoA\u8bef\u5dee\u548c\u5b9a\u4f4d\u7cbe\u5ea6\u4e0a\u5b9e\u73b0\u4e863.3\u500d\u523014.8\u500d\u7684\u6539\u8fdb\u3002", "motivation": "\u9690\u85cf\u7684\u95f4\u8c0d\u6444\u50cf\u5934\u7b49\u4f4e\u6210\u672c\u3001\u4f4e\u529f\u8017\u3001\u5c0f\u5c3a\u5bf8\u7684IoT\u8bbe\u5907\u5bf9\u9690\u79c1\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u8fd9\u4e9b\u8bbe\u5907\u5728\u5ba4\u5185\u73af\u5883\u4e2d\u53ef\u4ee5\u6084\u65e0\u58f0\u606f\u5730\u76d1\u63a7\u4eba\u7c7b\u6d3b\u52a8\u800c\u4e0d\u4ea7\u751f\u4efb\u4f55\u4fa7\u4fe1\u9053\u4fe1\u606f\uff0c\u56e0\u6b64\u96be\u4ee5\u68c0\u6d4b\u548c\u5b9a\u4f4d\u3002", "method": "\u7cfb\u7edf\u8bbe\u8ba1\u4e3b\u8981\u5305\u62ec\uff1a1)\u4fbf\u643a\u5f0f\u5207\u6362\u5929\u7ebf\u9635\u5217\u55c5\u63a2\u9891\u8c31\u6269\u5c55\u8f90\u5c04\uff1b2)\u901a\u8fc7\u975e\u76f8\u5e72\u5e73\u5747\u8fdb\u884c\u8f90\u5c04\u589e\u5f3a\u7b97\u6cd5\uff0c\u6d88\u9664\u65b9\u6ce2\u8f90\u5c04\u7ed3\u6784\u5bfc\u81f4\u7684\u566a\u58f0\u76f8\u5173\u6548\u5e94\uff1b3)\u591a\u5f84\u89e3\u6790\u7b97\u6cd5\uff0c\u5229\u7528\u76f8\u5bf9\u4fe1\u9053\u901a\u8fc7\u57fa\u4e8e\u4f18\u5316\u7684\u7a00\u758fAoA\u63a8\u5bfc\u3002", "result": "\u5728\u4e0d\u540c\u5ba4\u5185\u73af\u5883\u4e2d\u7684\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff1a\u5e73\u5747AoA\u8bef\u5dee\u4e3a6.30\u5ea6\uff08\u57fa\u7ebf\u7b97\u6cd5\u4e3a21.06\u5ea6\uff09\uff0c\u5b9a\u4f4d\u8bef\u5dee\u4e3a19.86\u5398\u7c73\uff08\u57fa\u7ebfMUSIC\u7b97\u6cd5\u4e3a206.79\u5398\u7c73\uff0cSpotFi\u7b97\u6cd5\u4e3a294.75\u5398\u7c73\uff09\uff0c\u5206\u522b\u5b9e\u73b0\u4e863.3\u500d\u548c10.41-14.8\u500d\u7684\u7cbe\u5ea6\u63d0\u5347\u3002", "conclusion": "SpyDir\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5229\u7528\u9690\u85cf\u95f4\u8c0dIoT\u8bbe\u5907\u7684\u7535\u78c1\u8f90\u5c04\u8fdb\u884c\u51c6\u786e\u5b9a\u4f4d\uff0c\u5728\u5ba4\u5185\u73af\u5883\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u4e3a\u89e3\u51b3\u9690\u79c1\u5a01\u80c1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2602.00405", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00405", "abs": "https://arxiv.org/abs/2602.00405", "authors": ["Deep Gandhi", "Katyani Singh", "Nidhi Hegde"], "title": "RobustDebias: Debiasing Language Models using Distributionally Robust Optimization", "comment": null, "summary": "Pretrained language models have been shown to exhibit biases and social stereotypes. Prior work on debiasing these models has largely focused on modifying embedding spaces during pretraining, which is not scalable for large models. Fine-tuning pretrained models on task-specific datasets can both degrade model performance and amplify biases present in the fine-tuning data. We address bias amplification during fine-tuning rather than costly pretraining, focusing on BERT models due to their widespread use in language understanding tasks. While Empirical Risk Minimization effectively optimizes downstream performance, it often amplifies social biases during fine-tuning. To counter this, we propose \\textit{RobustDebias}, a novel mechanism which adapts Distributionally Robust Optimization (DRO) to debias language models during fine-tuning. Our approach debiases models across multiple demographics during MLM fine-tuning and generalizes to any dataset or task. Extensive experiments on various language models show significant bias mitigation with minimal performance impact.", "AI": {"tldr": "\u63d0\u51faRobustDebias\u65b9\u6cd5\uff0c\u4f7f\u7528\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u5728\u5fae\u8c03\u9636\u6bb5\u51cf\u5c11BERT\u7b49\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u793e\u4f1a\u504f\u89c1\u653e\u5927\u95ee\u9898\uff0c\u5b9e\u73b0\u591a\u4eba\u53e3\u7edf\u8ba1\u5b66\u7279\u5f81\u7684\u504f\u89c1\u7f13\u89e3\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u504f\u89c1\u548c\u793e\u4f1a\u523b\u677f\u5370\u8c61\u3002\u73b0\u6709\u53bb\u504f\u89c1\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9884\u8bad\u7ec3\u9636\u6bb5\u7684\u5d4c\u5165\u7a7a\u95f4\u4fee\u6539\uff0c\u8fd9\u5bf9\u5927\u578b\u6a21\u578b\u4e0d\u5177\u53ef\u6269\u5c55\u6027\u3002\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b\u4e0d\u4ec5\u53ef\u80fd\u964d\u4f4e\u6027\u80fd\uff0c\u8fd8\u4f1a\u653e\u5927\u5fae\u8c03\u6570\u636e\u4e2d\u7684\u504f\u89c1\u3002\u56e0\u6b64\u9700\u8981\u89e3\u51b3\u5fae\u8c03\u9636\u6bb5\u7684\u504f\u89c1\u653e\u5927\u95ee\u9898\uff0c\u800c\u4e0d\u662f\u6210\u672c\u9ad8\u6602\u7684\u9884\u8bad\u7ec3\u9636\u6bb5\u3002", "method": "\u63d0\u51faRobustDebias\u673a\u5236\uff0c\u5c06\u5206\u5e03\u9c81\u68d2\u4f18\u5316\uff08DRO\uff09\u5e94\u7528\u4e8e\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u53bb\u504f\u89c1\u3002\u8be5\u65b9\u6cd5\u5728MLM\uff08\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\uff09\u5fae\u8c03\u671f\u95f4\u5bf9\u591a\u4e2a\u4eba\u53e3\u7edf\u8ba1\u5b66\u7279\u5f81\u8fdb\u884c\u53bb\u504f\u89c1\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u4efb\u4f55\u6570\u636e\u96c6\u6216\u4efb\u52a1\u3002", "result": "\u5728\u5404\u79cd\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u7f13\u89e3\u504f\u89c1\uff0c\u540c\u65f6\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u6700\u5c0f\u3002", "conclusion": "RobustDebias\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5fae\u8c03\u9636\u6bb5\u53bb\u504f\u89c1\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u5728\u5fae\u8c03\u65f6\u653e\u5927\u793e\u4f1a\u504f\u89c1\u7684\u95ee\u9898\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u504f\u89c1\u7f13\u89e3\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01187", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01187", "abs": "https://arxiv.org/abs/2602.01187", "authors": ["Chengran Yang", "Zichao Wei", "Heminghao Deng", "Jinfeng Jiang", "Zhensu Sun", "Ting Zhang", "Tianyi Wu", "Ming Wen", "David Lo"], "title": "Autoregressive, Yet Revisable: In Decoding Revision for Secure Code Generation", "comment": null, "summary": "Large Language Model (LLM) based code generation is predominantly formulated as a strictly monotonic process, appending tokens linearly to an immutable prefix. This formulation contrasts to the cognitive process of programming, which is inherently interleaved with forward generation and on-the-fly revision. While prior works attempt to introduce revision via post-hoc agents or external static tools, they either suffer from high latency or fail to leverage the model's intrinsic semantic reasoning. In this paper, we propose Stream of Revision, a paradigm shift that elevates code generation from a monotonic stream to a dynamic, self-correcting trajectory by leveraging model's intrinsic capabilities. We introduce specific action tokens that enable the model to seamlessly backtrack and edit its own history within a single forward pass. By internalizing the revision loop, our framework Stream of Revision allows the model to activate its latent capabilities just-in-time without external dependencies. Empirical results on secure code generation show that Stream of Revision significantly reduces vulnerabilities with minimal inference overhead.", "AI": {"tldr": "Stream of Revision\uff1a\u4e00\u79cd\u65b0\u7684\u4ee3\u7801\u751f\u6210\u8303\u5f0f\uff0c\u5c06\u5355\u8c03\u7684\u7ebf\u6027\u751f\u6210\u8f6c\u53d8\u4e3a\u52a8\u6001\u81ea\u4fee\u6b63\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7279\u5b9a\u52a8\u4f5c\u4ee4\u724c\u8ba9\u6a21\u578b\u5728\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u56de\u6eaf\u548c\u7f16\u8f91\u5386\u53f2\u8f93\u51fa\uff0c\u663e\u8457\u51cf\u5c11\u4ee3\u7801\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u751f\u6210\u4e3b\u8981\u91c7\u7528\u5355\u8c03\u7ebf\u6027\u65b9\u5f0f\uff0c\u8fd9\u4e0e\u4eba\u7c7b\u7f16\u7a0b\u7684\u8ba4\u77e5\u8fc7\u7a0b\uff08\u5305\u542b\u524d\u5411\u751f\u6210\u548c\u5373\u65f6\u4fee\u8ba2\uff09\u5f62\u6210\u5bf9\u6bd4\u3002\u5148\u524d\u7684\u5de5\u4f5c\u8981\u4e48\u5ef6\u8fdf\u9ad8\uff0c\u8981\u4e48\u65e0\u6cd5\u5229\u7528\u6a21\u578b\u5185\u5728\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faStream of Revision\u8303\u5f0f\uff0c\u5f15\u5165\u7279\u5b9a\u52a8\u4f5c\u4ee4\u724c\u4f7f\u6a21\u578b\u80fd\u591f\u5728\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u56de\u6eaf\u548c\u7f16\u8f91\u81ea\u5df1\u7684\u5386\u53f2\u8f93\u51fa\uff0c\u5c06\u4fee\u8ba2\u5faa\u73af\u5185\u5316\u5230\u6a21\u578b\u4e2d\uff0c\u65e0\u9700\u5916\u90e8\u4f9d\u8d56\u3002", "result": "\u5728\u5b89\u5168\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cStream of Revision\u663e\u8457\u51cf\u5c11\u4e86\u6f0f\u6d1e\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6700\u5c0f\u7684\u63a8\u7406\u5f00\u9500\u3002", "conclusion": "Stream of Revision\u901a\u8fc7\u5c06\u4ee3\u7801\u751f\u6210\u4ece\u5355\u8c03\u6d41\u63d0\u5347\u4e3a\u52a8\u6001\u81ea\u4fee\u6b63\u8f68\u8ff9\uff0c\u5229\u7528\u6a21\u578b\u5185\u5728\u80fd\u529b\u5b9e\u73b0\u5373\u65f6\u4fee\u8ba2\uff0c\u4e3a\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u7b26\u5408\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.01253", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01253", "abs": "https://arxiv.org/abs/2602.01253", "authors": ["Nouf Alturayeif", "Irfan Ahmad", "Jameleddine Hassine"], "title": "TraceLLM: Leveraging Large Language Models with Prompt Engineering for Enhanced Requirements Traceability", "comment": null, "summary": "Requirements traceability, the process of establishing and maintaining relationships between requirements and various software development artifacts, is paramount for ensuring system integrity and fulfilling requirements throughout the Software Development Life Cycle (SDLC). Traditional methods, including manual and information retrieval models, are labor-intensive, error-prone, and limited by low precision. Recently, Large Language Models (LLMs) have demonstrated potential for supporting software engineering tasks through advanced language comprehension. However, a substantial gap exists in the systematic design and evaluation of prompts tailored to extract accurate trace links. This paper introduces TraceLLM, a systematic framework for enhancing requirements traceability through prompt engineering and demonstration selection. Our approach incorporates rigorous dataset splitting, iterative prompt refinement, enrichment with contextual roles and domain knowledge, and evaluation across zero- and few-shot settings. We assess prompt generalization and robustness using eight state-of-the-art LLMs on four benchmark datasets representing diverse domains (aerospace, healthcare) and artifact types (requirements, design elements, test cases, regulations). TraceLLM achieves state-of-the-art F2 scores, outperforming traditional IR baselines, fine-tuned models, and prior LLM-based methods. We also explore the impact of demonstration selection strategies, identifying label-aware, diversity-based sampling as particularly effective. Overall, our findings highlight that traceability performance depends not only on model capacity but also critically on the quality of prompt engineering. In addition, the achieved performance suggests that TraceLLM can support semi-automated traceability workflows in which candidate links are reviewed and validated by human analysts.", "AI": {"tldr": "TraceLLM\uff1a\u4e00\u4e2a\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u548c\u6f14\u793a\u9009\u62e9\u589e\u5f3a\u9700\u6c42\u53ef\u8ffd\u6eaf\u6027\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd", "motivation": "\u4f20\u7edf\u9700\u6c42\u53ef\u8ffd\u6eaf\u6027\u65b9\u6cd5\uff08\u624b\u52a8\u548c\u4fe1\u606f\u68c0\u7d22\u6a21\u578b\uff09\u52b3\u52a8\u5bc6\u96c6\u3001\u5bb9\u6613\u51fa\u9519\u4e14\u7cbe\u5ea6\u4f4e\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u63d0\u53d6\u51c6\u786e\u8ffd\u6eaf\u94fe\u63a5\u7684\u7cfb\u7edf\u5316\u63d0\u793a\u8bbe\u8ba1\u548c\u8bc4\u4f30\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "method": "\u63d0\u51faTraceLLM\u6846\u67b6\uff0c\u5305\u542b\u4e25\u683c\u7684\u6570\u636e\u96c6\u5212\u5206\u3001\u8fed\u4ee3\u5f0f\u63d0\u793a\u4f18\u5316\u3001\u4e0a\u4e0b\u6587\u89d2\u8272\u548c\u9886\u57df\u77e5\u8bc6\u589e\u5f3a\uff0c\u4ee5\u53ca\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u7684\u8bc4\u4f30\u3002\u63a2\u7d22\u4e86\u6f14\u793a\u9009\u62e9\u7b56\u7565\uff0c\u7279\u522b\u662f\u6807\u7b7e\u611f\u77e5\u3001\u57fa\u4e8e\u591a\u6837\u6027\u7684\u91c7\u6837\u65b9\u6cd5\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08\u822a\u7a7a\u822a\u5929\u3001\u533b\u7597\u9886\u57df\uff09\u4e0a\u4f7f\u7528\u516b\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0cTraceLLM\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684F2\u5206\u6570\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edfIR\u57fa\u7ebf\u3001\u5fae\u8c03\u6a21\u578b\u548c\u5148\u524d\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u3002", "conclusion": "\u53ef\u8ffd\u6eaf\u6027\u6027\u80fd\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u6a21\u578b\u80fd\u529b\uff0c\u66f4\u5173\u952e\u5730\u53d6\u51b3\u4e8e\u63d0\u793a\u5de5\u7a0b\u7684\u8d28\u91cf\u3002TraceLLM\u53ef\u4ee5\u652f\u6301\u534a\u81ea\u52a8\u5316\u7684\u53ef\u8ffd\u6eaf\u6027\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5176\u4e2d\u5019\u9009\u94fe\u63a5\u7531\u4eba\u7c7b\u5206\u6790\u5e08\u5ba1\u67e5\u548c\u9a8c\u8bc1\u3002"}}
{"id": "2602.00667", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00667", "abs": "https://arxiv.org/abs/2602.00667", "authors": ["Rong Fu", "Jia Yee Tan", "Wenxin Zhang", "Youjin Wang", "Ziyu Kong", "Zeli Su", "Zhaolu Kang", "Shuning Zhang", "Xianda Li", "Kun Liu", "Simon Fong"], "title": "zkCraft: Prompt-Guided LLM as a Zero-Shot Mutation Pattern Oracle for TCCT-Powered ZK Fuzzing", "comment": "36 pages, 12 figures, 9 tables", "summary": "Zero-knowledge circuits enable privacy-preserving and scalable systems but are difficult to implement correctly due to the tight coupling between witness computation and circuit constraints. We present zkCraft, a practical framework that combines deterministic, R1CS-aware localization with proof-bearing search to detect semantic inconsistencies. zkCraft encodes candidate constraint edits into a single Row-Vortex polynomial and replaces repeated solver queries with a Violation IOP that certifies the existence of edits together with a succinct proof. Deterministic LLM-driven mutation templates bias exploration toward edge cases while preserving auditable algebraic verification. Evaluation on real Circom code shows that proof-bearing localization detects diverse under- and over-constrained faults with low false positives and reduces costly solver interaction. Our approach bridges formal verification and automated debugging, offering a scalable path for robust ZK circuit development.", "AI": {"tldr": "zkCraft\u662f\u4e00\u4e2a\u7ed3\u5408\u786e\u5b9a\u6027R1CS\u611f\u77e5\u5b9a\u4f4d\u4e0e\u8bc1\u660e\u627f\u8f7d\u641c\u7d22\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u96f6\u77e5\u8bc6\u7535\u8def\u4e2d\u7684\u8bed\u4e49\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u901a\u8fc7Row-Vortex\u591a\u9879\u5f0f\u7f16\u7801\u7ea6\u675f\u7f16\u8f91\uff0c\u51cf\u5c11\u6c42\u89e3\u5668\u4ea4\u4e92\u6210\u672c\u3002", "motivation": "\u96f6\u77e5\u8bc6\u7535\u8def\u7531\u4e8e\u89c1\u8bc1\u8ba1\u7b97\u4e0e\u7535\u8def\u7ea6\u675f\u7684\u7d27\u5bc6\u8026\u5408\uff0c\u96be\u4ee5\u6b63\u786e\u5b9e\u73b0\uff0c\u9700\u8981\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u8bed\u4e49\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u4ee5\u652f\u6301\u9690\u79c1\u4fdd\u62a4\u548c\u53ef\u6269\u5c55\u7cfb\u7edf\u7684\u5f00\u53d1\u3002", "method": "zkCraft\u91c7\u7528\u786e\u5b9a\u6027\u3001R1CS\u611f\u77e5\u7684\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u7ed3\u5408\u8bc1\u660e\u627f\u8f7d\u641c\u7d22\uff0c\u5c06\u5019\u9009\u7ea6\u675f\u7f16\u8f91\u7f16\u7801\u4e3aRow-Vortex\u591a\u9879\u5f0f\uff0c\u7528Violation IOP\u66ff\u4ee3\u91cd\u590d\u7684\u6c42\u89e3\u5668\u67e5\u8be2\uff0c\u5e76\u4f7f\u7528\u786e\u5b9a\u6027LLM\u9a71\u52a8\u7684\u7a81\u53d8\u6a21\u677f\u6765\u504f\u5411\u8fb9\u7f18\u60c5\u51b5\u63a2\u7d22\u3002", "result": "\u5728\u771f\u5b9eCircom\u4ee3\u7801\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8bc1\u660e\u627f\u8f7d\u5b9a\u4f4d\u80fd\u591f\u68c0\u6d4b\u591a\u79cd\u6b20\u7ea6\u675f\u548c\u8fc7\u7ea6\u675f\u6545\u969c\uff0c\u5177\u6709\u8f83\u4f4e\u7684\u8bef\u62a5\u7387\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u6602\u8d35\u7684\u6c42\u89e3\u5668\u4ea4\u4e92\u3002", "conclusion": "zkCraft\u67b6\u8d77\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e0e\u81ea\u52a8\u5316\u8c03\u8bd5\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u4e3a\u96f6\u77e5\u8bc6\u7535\u8def\u7684\u7a33\u5065\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2602.00449", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00449", "abs": "https://arxiv.org/abs/2602.00449", "authors": ["Jia Liang", "Liangming Pan"], "title": "Do Latent-CoT Models Think Step-by-Step? A Mechanistic Study on Sequential Reasoning Tasks", "comment": "20 pages, 14 figures", "summary": "Latent Chain-of-Thought (Latent-CoT) aims to enable step-by-step computation without emitting long rationales, yet its mechanisms remain unclear. We study CODI, a continuous-thought teacher-student distillation model, on strictly sequential polynomial-iteration tasks. Using logit-lens decoding, linear probes, attention analysis, and activation patching, we localize intermediate-state representations and trace their routing to the final readout. On two- and three-hop tasks, CODI forms the full set of bridge states that become decodable across latent-thought positions, while the final input follows a separate near-direct route; predictions arise via late fusion at the end-of-thought boundary. For longer hop lengths, CODI does not reliably execute a full latent rollout, instead exhibiting a partial latent reasoning path that concentrates on late intermediates and fuses them with the last input at the answer readout position. Ablations show that this partial pathway can collapse under regime shifts, including harder optimization. Overall, we delineate when CODI-style latent-CoT yields faithful iterative computation versus compressed or shortcut strategies, and highlight challenges in designing robust latent-CoT objectives for sequential reasoning.", "AI": {"tldr": "CODI\u6a21\u578b\u5728\u591a\u9879\u5f0f\u8fed\u4ee3\u4efb\u52a1\u4e2d\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u63ed\u793a\u4e86\u6f5c\u5728\u601d\u7ef4\u94fe\u7684\u5185\u90e8\u673a\u5236\uff1a\u77ed\u4efb\u52a1\u80fd\u5f62\u6210\u5b8c\u6574\u4e2d\u95f4\u72b6\u6001\uff0c\u957f\u4efb\u52a1\u5219\u91c7\u7528\u90e8\u5206\u63a8\u7406\u8def\u5f84\u548c\u6377\u5f84\u7b56\u7565\u3002", "motivation": "\u7814\u7a76\u6f5c\u5728\u601d\u7ef4\u94fe\uff08Latent-CoT\uff09\u7684\u5185\u90e8\u5de5\u4f5c\u673a\u5236\uff0c\u7279\u522b\u662fCODI\u8fd9\u79cd\u8fde\u7eed\u601d\u7ef4\u7684\u5e08\u751f\u84b8\u998f\u6a21\u578b\u5982\u4f55\u5728\u4e0d\u751f\u6210\u957f\u63a8\u7406\u6587\u672c\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u9010\u6b65\u8ba1\u7b97\u3002", "method": "\u4f7f\u7528logit-lens\u89e3\u7801\u3001\u7ebf\u6027\u63a2\u9488\u3001\u6ce8\u610f\u529b\u5206\u6790\u548c\u6fc0\u6d3b\u4fee\u8865\u7b49\u6280\u672f\uff0c\u5728\u4e25\u683c\u987a\u5e8f\u7684\u591a\u9879\u5f0f\u8fed\u4ee3\u4efb\u52a1\u4e0a\u5206\u6790CODI\u6a21\u578b\uff0c\u5b9a\u4f4d\u4e2d\u95f4\u72b6\u6001\u8868\u793a\u5e76\u8ffd\u8e2a\u5176\u5230\u6700\u7ec8\u8f93\u51fa\u7684\u8def\u5f84\u3002", "result": "\u57282-3\u8df3\u4efb\u52a1\u4e2d\uff0cCODI\u80fd\u5f62\u6210\u5b8c\u6574\u7684\u6865\u63a5\u72b6\u6001\uff0c\u5728\u6f5c\u5728\u601d\u7ef4\u4f4d\u7f6e\u53ef\u89e3\u7801\uff1b\u6700\u7ec8\u8f93\u5165\u8d70\u5355\u72ec\u7684\u76f4\u63a5\u8def\u5f84\uff1b\u9884\u6d4b\u901a\u8fc7\u601d\u7ef4\u8fb9\u754c\u5904\u7684\u540e\u671f\u878d\u5408\u4ea7\u751f\u3002\u5bf9\u4e8e\u66f4\u957f\u8df3\u6570\uff0cCODI\u4e0d\u80fd\u53ef\u9760\u6267\u884c\u5b8c\u6574\u6f5c\u5728\u5c55\u5f00\uff0c\u800c\u662f\u91c7\u7528\u90e8\u5206\u63a8\u7406\u8def\u5f84\uff0c\u96c6\u4e2d\u4e8e\u540e\u671f\u4e2d\u95f4\u72b6\u6001\u5e76\u4e0e\u6700\u540e\u8f93\u5165\u878d\u5408\u3002", "conclusion": "CODI\u98ce\u683c\u7684\u6f5c\u5728\u601d\u7ef4\u94fe\u5728\u77ed\u4efb\u52a1\u4e2d\u80fd\u5b9e\u73b0\u5fe0\u5b9e\u8fed\u4ee3\u8ba1\u7b97\uff0c\u4f46\u5728\u957f\u4efb\u52a1\u4e2d\u4f1a\u9000\u5316\u4e3a\u538b\u7f29\u6216\u6377\u5f84\u7b56\u7565\u3002\u7814\u7a76\u63ed\u793a\u4e86\u8bbe\u8ba1\u9c81\u68d2\u6f5c\u5728\u601d\u7ef4\u94fe\u76ee\u6807\u7528\u4e8e\u987a\u5e8f\u63a8\u7406\u7684\u6311\u6218\u3002"}}
{"id": "2602.01311", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01311", "abs": "https://arxiv.org/abs/2602.01311", "authors": ["Ahmed Raza Amir", "Syed Muhammad Atif"], "title": "Evaluating Workflow Automation Efficiency Using n8n: A Small-Scale Business Case Study", "comment": "8 pages, 4 figures, 2 tables", "summary": "Workflow automation has become increasingly accessible through low-code platforms, enabling small organizations and individuals to improve operational efficiency without extensive software development expertise. This study evaluates the performance impact of workflow automation using n8n through a small-scale business case study. A representative lead-processing workflow was implemented to automatically store data, send email confirmations, and generate real-time notifications. Experimental benchmarking was conducted by comparing 20 manual executions with 25 automated executions under controlled conditions. The results demonstrate a significant reduction in the average execution time from 185.35 seconds (manual) to 1.23 seconds (automated), corresponding to an approximately 151 times reduction in execution time. Additionally, manual execution exhibited an error rate of 5%, while automated execution achieved zero observed errors. The findings highlight the effectiveness of low-code automation in improving efficiency, reliability, and operational consistency for small-scale workflows.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5c0f\u578b\u5546\u4e1a\u6848\u4f8b\u8bc4\u4f30\u4e86\u4f7f\u7528n8n\u8fdb\u884c\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u7684\u6027\u80fd\u5f71\u54cd\uff0c\u53d1\u73b0\u81ea\u52a8\u5316\u5c06\u5e73\u5747\u6267\u884c\u65f6\u95f4\u4ece185.35\u79d2\u51cf\u5c11\u52301.23\u79d2\uff0c\u9519\u8bef\u7387\u4ece5%\u964d\u81f30%\u3002", "motivation": "\u968f\u7740\u4f4e\u4ee3\u7801\u5e73\u53f0\u7684\u666e\u53ca\uff0c\u5c0f\u578b\u7ec4\u7ec7\u548c\u4e2a\u4eba\u65e0\u9700\u5927\u91cf\u8f6f\u4ef6\u5f00\u53d1\u4e13\u4e1a\u77e5\u8bc6\u5373\u53ef\u901a\u8fc7\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u63d0\u9ad8\u8fd0\u8425\u6548\u7387\uff0c\u4f46\u9700\u8981\u5b9e\u8bc1\u8bc4\u4f30\u5176\u6027\u80fd\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5c0f\u578b\u5546\u4e1a\u6848\u4f8b\u7814\u7a76\uff0c\u5b9e\u73b0\u4e86\u4e00\u4e2a\u4ee3\u8868\u6027\u7684\u6f5c\u5728\u5ba2\u6237\u5904\u7406\u5de5\u4f5c\u6d41\uff0c\u81ea\u52a8\u5b58\u50a8\u6570\u636e\u3001\u53d1\u9001\u90ae\u4ef6\u786e\u8ba4\u548c\u751f\u6210\u5b9e\u65f6\u901a\u77e5\u3002\u5728\u53d7\u63a7\u6761\u4ef6\u4e0b\uff0c\u6bd4\u8f83\u4e8620\u6b21\u624b\u52a8\u6267\u884c\u548c25\u6b21\u81ea\u52a8\u5316\u6267\u884c\u7684\u6027\u80fd\u3002", "result": "\u81ea\u52a8\u5316\u5c06\u5e73\u5747\u6267\u884c\u65f6\u95f4\u4ece185.35\u79d2\uff08\u624b\u52a8\uff09\u51cf\u5c11\u52301.23\u79d2\uff08\u81ea\u52a8\u5316\uff09\uff0c\u6267\u884c\u65f6\u95f4\u51cf\u5c11\u4e86\u7ea6151\u500d\u3002\u624b\u52a8\u6267\u884c\u7684\u9519\u8bef\u7387\u4e3a5%\uff0c\u800c\u81ea\u52a8\u5316\u6267\u884c\u5b9e\u73b0\u4e86\u96f6\u89c2\u5bdf\u9519\u8bef\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4f4e\u4ee3\u7801\u81ea\u52a8\u5316\u5728\u63d0\u9ad8\u5c0f\u578b\u5de5\u4f5c\u6d41\u7684\u6548\u7387\u3001\u53ef\u9760\u6027\u548c\u64cd\u4f5c\u4e00\u81f4\u6027\u65b9\u9762\u975e\u5e38\u6709\u6548\uff0c\u4e3a\u5c0f\u578b\u7ec4\u7ec7\u91c7\u7528\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002"}}
{"id": "2602.00689", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00689", "abs": "https://arxiv.org/abs/2602.00689", "authors": ["Genqiang Wu", "Xiaoying Zhang", "Yu Qi", "Hao Wang", "Jikui Wang", "Yeping He"], "title": "Computing Maximal Per-Record Leakage and Leakage-Distortion Functions for Privacy Mechanisms under Entropy-Constrained Adversaries", "comment": null, "summary": "The exponential growth of data collection necessitates robust privacy protections that preserve data utility. We address information disclosure against adversaries with bounded prior knowledge, modeled by an entropy constraint $H(X) \\geq b$. Within this information privacy framework -- which replaces differential privacy's independence assumption with a bounded-knowledge model -- we study three core problems: maximal per-record leakage, the primal leakage-distortion tradeoff (minimizing worst-case leakage under distortion $D$), and the dual distortion minimization (minimizing distortion under leakage constraint $L$).\n  These problems resemble classical information-theoretic ones (channel capacity, rate-distortion) but are more complex due to high dimensionality and the entropy constraint. We develop efficient alternating optimization algorithms that exploit convexity-concavity duality, with theoretical guarantees including local convergence for the primal problem and convergence to a stationary point for the dual.\n  Experiments on binary symmetric channels and modular sum queries validate the algorithms, showing improved privacy-utility tradeoffs over classical differential privacy mechanisms. This work provides a computational framework for auditing privacy risks and designing certified mechanisms under realistic adversary assumptions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u4fe1\u606f\u9690\u79c1\u6846\u67b6\uff0c\u9488\u5bf9\u5177\u6709\u6709\u9650\u5148\u9a8c\u77e5\u8bc6\u7684\u5bf9\u624b\uff0c\u7814\u7a76\u4e86\u6700\u5927\u5355\u8bb0\u5f55\u6cc4\u9732\u3001\u6cc4\u9732-\u5931\u771f\u6743\u8861\u548c\u5931\u771f\u6700\u5c0f\u5316\u4e09\u4e2a\u6838\u5fc3\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u3002", "motivation": "\u968f\u7740\u6570\u636e\u6536\u96c6\u7684\u6307\u6570\u589e\u957f\uff0c\u9700\u8981\u5728\u4fdd\u62a4\u6570\u636e\u6548\u7528\u7684\u540c\u65f6\u63d0\u4f9b\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u62a4\u3002\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u7684\u72ec\u7acb\u6027\u5047\u8bbe\u4e0d\u73b0\u5b9e\uff0c\u9700\u8981\u66f4\u7b26\u5408\u5b9e\u9645\u7684\u6709\u9650\u77e5\u8bc6\u5bf9\u624b\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4fe1\u606f\u9690\u79c1\u6846\u67b6\uff0c\u7528\u71b5\u7ea6\u675fH(X)\u2265b\u5efa\u6a21\u5bf9\u624b\u7684\u6709\u9650\u5148\u9a8c\u77e5\u8bc6\u3002\u5f00\u53d1\u9ad8\u6548\u7684\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\uff0c\u5229\u7528\u51f8\u51f9\u5bf9\u5076\u6027\uff0c\u4e3a\u539f\u59cb\u95ee\u9898\u63d0\u4f9b\u5c40\u90e8\u6536\u655b\u4fdd\u8bc1\uff0c\u4e3a\u5bf9\u5076\u95ee\u9898\u63d0\u4f9b\u7a33\u5b9a\u70b9\u6536\u655b\u4fdd\u8bc1\u3002", "result": "\u5728\u4e8c\u8fdb\u5236\u5bf9\u79f0\u4fe1\u9053\u548c\u6a21\u548c\u67e5\u8be2\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u663e\u793a\u51fa\u6bd4\u7ecf\u5178\u5dee\u5206\u9690\u79c1\u673a\u5236\u66f4\u597d\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6846\u67b6\u6765\u5ba1\u8ba1\u9690\u79c1\u98ce\u9669\u548c\u8bbe\u8ba1\u7ecf\u8fc7\u8ba4\u8bc1\u7684\u673a\u5236\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5728\u73b0\u5b9e\u5bf9\u624b\u5047\u8bbe\u4e0b\u5ba1\u8ba1\u9690\u79c1\u98ce\u9669\u548c\u8bbe\u8ba1\u7ecf\u8fc7\u8ba4\u8bc1\u7684\u673a\u5236\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u9ad8\u7ef4\u5ea6\u548c\u71b5\u7ea6\u675f\u5e26\u6765\u7684\u590d\u6742\u6027\uff0c\u6539\u8fdb\u4e86\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.00454", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00454", "abs": "https://arxiv.org/abs/2602.00454", "authors": ["Jing Wu", "Yue Sun", "Tianpei Xie", "Suiyao Chen", "Jingyuan Bao", "Yaopengxiao Xu", "Gaoyuan Du", "Inseok Heo", "Alexander Gutfraind", "Xin Wang"], "title": "Cross-Modal Memory Compression for Efficient Multi-Agent Debate", "comment": null, "summary": "Multi-agent debate can improve reasoning quality and reduce hallucinations, but it incurs rapidly growing context as debate rounds and agent count increase. Retaining full textual histories leads to token usage that can exceed context limits and often requires repeated summarization, adding overhead and compounding information loss. We introduce DebateOCR, a cross-modal compression framework that replaces long textual debate traces with compact image representations, which are then consumed through a dedicated vision encoder to condition subsequent rounds. This design compresses histories that commonly span tens to hundreds of thousands of tokens, cutting input tokens by more than 92% and yielding substantially lower compute cost and faster inference across multiple benchmarks. We further provide a theoretical perspective showing that diversity across agents supports recovery of omitted information: although any single compressed history may discard details, aggregating multiple agents' compressed views allows the collective representation to approach the information bottleneck with exponentially high probability.", "AI": {"tldr": "DebateOCR\uff1a\u4e00\u4e2a\u8de8\u6a21\u6001\u538b\u7f29\u6846\u67b6\uff0c\u7528\u7d27\u51d1\u7684\u56fe\u50cf\u8868\u793a\u66ff\u4ee3\u5197\u957f\u7684\u6587\u672c\u8fa9\u8bba\u5386\u53f2\uff0c\u51cf\u5c1192%\u7684\u8f93\u5165token\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u52a0\u901f\u63a8\u7406", "motivation": "\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u867d\u7136\u80fd\u63d0\u9ad8\u63a8\u7406\u8d28\u91cf\u5e76\u51cf\u5c11\u5e7b\u89c9\uff0c\u4f46\u968f\u7740\u8fa9\u8bba\u8f6e\u6b21\u548c\u667a\u80fd\u4f53\u6570\u91cf\u589e\u52a0\uff0c\u4e0a\u4e0b\u6587\u4f1a\u8fc5\u901f\u81a8\u80c0\u3002\u4fdd\u7559\u5b8c\u6574\u7684\u6587\u672c\u5386\u53f2\u4f1a\u5bfc\u81f4token\u4f7f\u7528\u91cf\u8d85\u8fc7\u4e0a\u4e0b\u6587\u9650\u5236\uff0c\u5e76\u4e14\u901a\u5e38\u9700\u8981\u91cd\u590d\u603b\u7ed3\uff0c\u589e\u52a0\u4e86\u5f00\u9500\u5e76\u52a0\u5267\u4fe1\u606f\u635f\u5931\u3002", "method": "\u5f15\u5165DebateOCR\u8de8\u6a21\u6001\u538b\u7f29\u6846\u67b6\uff0c\u5c06\u5197\u957f\u7684\u6587\u672c\u8fa9\u8bba\u8f68\u8ff9\u66ff\u6362\u4e3a\u7d27\u51d1\u7684\u56fe\u50cf\u8868\u793a\uff0c\u7136\u540e\u901a\u8fc7\u4e13\u95e8\u7684\u89c6\u89c9\u7f16\u7801\u5668\u6765\u8c03\u8282\u540e\u7eed\u8f6e\u6b21\u3002\u8be5\u8bbe\u8ba1\u538b\u7f29\u4e86\u901a\u5e38\u8de8\u8d8a\u6570\u4e07\u5230\u6570\u5341\u4e07token\u7684\u5386\u53f2\u8bb0\u5f55\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8f93\u5165token\u51cf\u5c11\u4e8692%\u4ee5\u4e0a\uff0c\u8ba1\u7b97\u6210\u672c\u663e\u8457\u964d\u4f4e\uff0c\u63a8\u7406\u901f\u5ea6\u66f4\u5feb\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u591a\u6837\u6027\u652f\u6301\u6062\u590d\u88ab\u7701\u7565\u7684\u4fe1\u606f\uff1a\u867d\u7136\u4efb\u4f55\u5355\u4e2a\u538b\u7f29\u5386\u53f2\u90fd\u53ef\u80fd\u4e22\u5f03\u7ec6\u8282\uff0c\u4f46\u805a\u5408\u591a\u4e2a\u667a\u80fd\u4f53\u7684\u538b\u7f29\u89c6\u56fe\u53ef\u4ee5\u4f7f\u96c6\u4f53\u8868\u793a\u4ee5\u6307\u6570\u7ea7\u9ad8\u6982\u7387\u63a5\u8fd1\u4fe1\u606f\u74f6\u9888\u3002", "conclusion": "DebateOCR\u901a\u8fc7\u8de8\u6a21\u6001\u538b\u7f29\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u4e2d\u7684\u4e0a\u4e0b\u6587\u81a8\u80c0\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u5e76\u4fdd\u6301\u4e86\u63a8\u7406\u8d28\u91cf\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u8868\u660e\u667a\u80fd\u4f53\u591a\u6837\u6027\u6709\u52a9\u4e8e\u4fe1\u606f\u6062\u590d\u3002"}}
{"id": "2602.01563", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01563", "abs": "https://arxiv.org/abs/2602.01563", "authors": ["Nan Hu", "Han Li", "Jimeng Sun", "Lu Wang", "Fangkai Yang", "Bo Qiao", "Pu Zhao", "David Dai", "Mengyu Liu", "Yuefeng Zhan", "Jianjin Zhang", "Weihao Han", "Allen Sun", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang", "Denvy Deng", "Feng Sun", "Qi Zhang"], "title": "AdNanny: One Reasoning LLM for All Offline Ads Recommendation Tasks", "comment": "21 pages, 3 figures", "summary": "Large Language Models (LLMs) have shown strong capabilities in Natural Language Understanding and Generation, but deploying them directly in online advertising systems is often impractical due to strict millisecond-level latency constraints. This has motivated the use of LLMs offline to improve retrieval, ranking, and recommendation models. Existing solutions typically fine-tune separate LLMs for individual tasks such as query-ad relevance labeling, keyword-based query generation, and user profiling. This results in redundant models, high maintenance cost, and limited performance gains despite substantial overlap in domain knowledge and reasoning patterns. We introduce AdNanny, a unified reasoning-centric LLM that serves as a shared backbone for offline advertising tasks. AdNanny is obtained by fine-tuning a public 671B-parameter DeepSeek-R1 checkpoint using a scalable training system that supports hybrid dense-MoE parallelism. We construct reasoning-augmented corpora that pair structured supervision with step-by-step natural language explanations. A multi-task supervised fine-tuning stage with adaptive reweighting enables AdNanny to handle diverse labeling and generation tasks in a consistent reasoning format. This is followed by reinforcement learning using downstream advertising metrics to align model behavior with online retrieval and ranking objectives. AdNanny is deployed in production within Bing Ads, where it significantly reduces manual labeling effort and improves accuracy across multiple offline tasks. By consolidating many task-specific models into a single reasoning-centric foundation model, AdNanny provides a scalable and cost-effective solution for large-scale advertising systems.", "AI": {"tldr": "AdNanny\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u63a8\u7406\u4e2d\u5fc3\u5316\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u5fae\u8c03DeepSeek-R1\u6784\u5efa\uff0c\u7528\u4e8e\u5728\u7ebf\u5e7f\u544a\u7cfb\u7edf\u7684\u79bb\u7ebf\u4efb\u52a1\uff0c\u51cf\u5c11\u5197\u4f59\u6a21\u578b\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7531\u4e8e\u4e25\u683c\u7684\u6beb\u79d2\u7ea7\u5ef6\u8fdf\u9650\u5236\uff0c\u65e0\u6cd5\u76f4\u63a5\u90e8\u7f72\u5728\u5728\u7ebf\u5e7f\u544a\u7cfb\u7edf\u4e2d\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u4e3a\u4e0d\u540c\u4efb\u52a1\u5355\u72ec\u5fae\u8c03LLM\uff0c\u5bfc\u81f4\u6a21\u578b\u5197\u4f59\u3001\u7ef4\u62a4\u6210\u672c\u9ad8\uff0c\u4e14\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002", "method": "1. \u5fae\u8c03671B\u53c2\u6570\u7684DeepSeek-R1\u68c0\u67e5\u70b9\uff0c\u4f7f\u7528\u652f\u6301\u6df7\u5408\u5bc6\u96c6-MoE\u5e76\u884c\u5316\u7684\u53ef\u6269\u5c55\u8bad\u7ec3\u7cfb\u7edf\uff1b2. \u6784\u5efa\u63a8\u7406\u589e\u5f3a\u8bed\u6599\u5e93\uff0c\u5c06\u7ed3\u6784\u5316\u76d1\u7763\u4e0e\u9010\u6b65\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u914d\u5bf9\uff1b3. \u91c7\u7528\u81ea\u9002\u5e94\u91cd\u52a0\u6743\u7684\u591a\u4efb\u52a1\u76d1\u7763\u5fae\u8c03\uff0c\u4f7f\u6a21\u578b\u80fd\u5904\u7406\u591a\u6837\u5316\u7684\u6807\u6ce8\u548c\u751f\u6210\u4efb\u52a1\uff1b4. \u4f7f\u7528\u4e0b\u6e38\u5e7f\u544a\u6307\u6807\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff0c\u4f7f\u6a21\u578b\u884c\u4e3a\u4e0e\u5728\u7ebf\u68c0\u7d22\u548c\u6392\u5e8f\u76ee\u6807\u5bf9\u9f50\u3002", "result": "AdNanny\u5df2\u90e8\u7f72\u5728Bing Ads\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u6807\u6ce8\u5de5\u4f5c\u91cf\uff0c\u5e76\u5728\u591a\u4e2a\u79bb\u7ebf\u4efb\u52a1\u4e2d\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002\u901a\u8fc7\u5c06\u591a\u4e2a\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u6574\u5408\u4e3a\u5355\u4e2a\u63a8\u7406\u4e2d\u5fc3\u5316\u57fa\u7840\u6a21\u578b\uff0c\u4e3a\u5927\u89c4\u6a21\u5e7f\u544a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "AdNanny\u901a\u8fc7\u7edf\u4e00\u7684\u63a8\u7406\u4e2d\u5fc3\u5316LLM\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u5e7f\u544a\u7cfb\u7edf\u4e2d\u6a21\u578b\u5197\u4f59\u548c\u7ef4\u62a4\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u548c\u6210\u672c\u6548\u76ca\uff0c\u4e3a\u5927\u89c4\u6a21\u5e7f\u544a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00711", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00711", "abs": "https://arxiv.org/abs/2602.00711", "authors": ["Ranjith Krishnamurthy", "Oshando Johnson", "Goran Piskachev", "Eric Bodden"], "title": "From Detection to Prevention: Explaining Security-Critical Code to Avoid Vulnerabilities", "comment": "4 pages", "summary": "Security vulnerabilities often arise unintentionally during development due to a lack of security expertise and code complexity. Traditional tools, such as static and dynamic analysis, detect vulnerabilities only after they are introduced in code, leading to costly remediation. This work explores a proactive strategy to prevent vulnerabilities by highlighting code regions that implement security-critical functionality -- such as data access, authentication, and input handling -- and providing guidance for their secure implementation. We present an IntelliJ IDEA plugin prototype that uses code-level software metrics to identify potentially security-critical methods and large language models (LLMs) to generate prevention-oriented explanations. Our initial evaluation on the Spring-PetClinic application shows that the selected metrics identify most known security-critical methods, while an LLM provides actionable, prevention-focused insights. Although these metrics capture structural properties rather than semantic aspects of security, this work lays the foundation for code-level security-aware metrics and enhanced explanations.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2aIntelliJ IDEA\u63d2\u4ef6\u539f\u578b\uff0c\u4f7f\u7528\u4ee3\u7801\u7ea7\u8f6f\u4ef6\u6307\u6807\u8bc6\u522b\u6f5c\u5728\u5b89\u5168\u5173\u952e\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9884\u9632\u6027\u89e3\u91ca\uff0c\u65e8\u5728\u5728\u6f0f\u6d1e\u4ea7\u751f\u524d\u9884\u9632\u5b89\u5168\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u5f00\u53d1\u4eba\u5458\u7f3a\u4e4f\u5b89\u5168\u4e13\u4e1a\u77e5\u8bc6\u548c\u4ee3\u7801\u590d\u6742\u6027\uff0c\u5b89\u5168\u6f0f\u6d1e\u5e38\u5728\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u65e0\u610f\u4ea7\u751f\u3002\u4f20\u7edf\u5de5\u5177\uff08\u5982\u9759\u6001\u548c\u52a8\u6001\u5206\u6790\uff09\u53ea\u80fd\u5728\u6f0f\u6d1e\u5f15\u5165\u4ee3\u7801\u540e\u68c0\u6d4b\uff0c\u5bfc\u81f4\u4fee\u590d\u6210\u672c\u9ad8\u6602\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u4e3b\u52a8\u9884\u9632\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e00\u4e2aIntelliJ IDEA\u63d2\u4ef6\u539f\u578b\uff0c\u4f7f\u7528\u4ee3\u7801\u7ea7\u8f6f\u4ef6\u6307\u6807\u8bc6\u522b\u6f5c\u5728\u5b89\u5168\u5173\u952e\u65b9\u6cd5\uff08\u5982\u6570\u636e\u8bbf\u95ee\u3001\u8ba4\u8bc1\u3001\u8f93\u5165\u5904\u7406\u7b49\uff09\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9884\u9632\u5bfc\u5411\u7684\u89e3\u91ca\u548c\u6307\u5bfc\u3002", "result": "\u5728Spring-PetClinic\u5e94\u7528\u4e0a\u7684\u521d\u6b65\u8bc4\u4f30\u663e\u793a\uff0c\u6240\u9009\u6307\u6807\u80fd\u591f\u8bc6\u522b\u5927\u591a\u6570\u5df2\u77e5\u7684\u5b89\u5168\u5173\u952e\u65b9\u6cd5\uff0c\u540c\u65f6\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u3001\u4ee5\u9884\u9632\u4e3a\u91cd\u70b9\u7684\u89c1\u89e3\u3002", "conclusion": "\u867d\u7136\u8fd9\u4e9b\u6307\u6807\u6355\u6349\u7684\u662f\u5b89\u5168\u7684\u7ed3\u6784\u5c5e\u6027\u800c\u975e\u8bed\u4e49\u65b9\u9762\uff0c\u4f46\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4ee3\u7801\u7ea7\u5b89\u5168\u611f\u77e5\u6307\u6807\u548c\u589e\u5f3a\u89e3\u91ca\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e3b\u52a8\u9884\u9632\u5b89\u5168\u6f0f\u6d1e\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.01957", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01957", "abs": "https://arxiv.org/abs/2602.01957", "authors": ["Xiaoxin Zhou", "Taher A. Ghaleb", "Safwat Hassan"], "title": "Role of CI Adoption in Mobile App Success: An Empirical Study of Open-Source Android Projects", "comment": null, "summary": "Mobile apps face strong pressure for fast and reliable updates. Continuous Integration (CI) helps automate builds, tests, and releases, but its impact on mobile development remains underexplored. Despite the widespread use of CI, little is known about how it affects development activity, release speed, and user-facing outcomes in mobile projects. Existing studies mostly focus on CI adoption in general-purpose software, providing limited insight into mobile-specific dynamics, such as app store visibility and user engagement. In this paper, we analyze open-source Android apps to (1) compare CI adopters and non-adopters, (2) characterize adoption patterns using activity and bug metrics, and (3) assess pre/post adoption changes and user-facing outcomes. We observe that CI adopters are larger and more active, with faster and more regular releases. CI adoption is concentrated in integration- and reliability-intensive categories (e.g., finance and productivity) and is associated with higher Google Play Store engagement (more downloads and reviews) without lower ratings. Overall, CI adoption aligns with practices that support sustained delivery, higher project visibility, and stronger user engagement in mobile ecosystems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u5f00\u6e90Android\u5e94\u7528\u4e2d\u6301\u7eed\u96c6\u6210(CI)\u7684\u5f71\u54cd\uff0c\u53d1\u73b0CI\u91c7\u7528\u8005\u9879\u76ee\u89c4\u6a21\u66f4\u5927\u3001\u66f4\u6d3b\u8dc3\uff0c\u53d1\u5e03\u66f4\u5feb\u66f4\u89c4\u5f8b\uff0c\u5728\u91d1\u878d\u548c\u751f\u4ea7\u529b\u7b49\u96c6\u6210\u5bc6\u96c6\u578b\u7c7b\u522b\u4e2d\u66f4\u96c6\u4e2d\uff0c\u4e14\u4e0e\u66f4\u9ad8\u7684Google Play\u5546\u5e97\u53c2\u4e0e\u5ea6\u76f8\u5173\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u9762\u4e34\u5feb\u901f\u53ef\u9760\u66f4\u65b0\u7684\u538b\u529b\uff0c\u6301\u7eed\u96c6\u6210(CI)\u6709\u52a9\u4e8e\u81ea\u52a8\u5316\u6784\u5efa\u3001\u6d4b\u8bd5\u548c\u53d1\u5e03\uff0c\u4f46\u5176\u5bf9\u79fb\u52a8\u5f00\u53d1\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u8f6f\u4ef6\u4e2d\u7684CI\u91c7\u7528\uff0c\u5bf9\u79fb\u52a8\u7279\u5b9a\u52a8\u6001\uff08\u5982\u5e94\u7528\u5546\u5e97\u53ef\u89c1\u6027\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\uff09\u4e86\u89e3\u6709\u9650\u3002", "method": "\u5206\u6790\u5f00\u6e90Android\u5e94\u7528\uff0c\u6bd4\u8f83CI\u91c7\u7528\u8005\u548c\u975e\u91c7\u7528\u8005\uff0c\u4f7f\u7528\u6d3b\u52a8\u548c\u9519\u8bef\u6307\u6807\u8868\u5f81\u91c7\u7528\u6a21\u5f0f\uff0c\u8bc4\u4f30\u91c7\u7528\u524d\u540e\u7684\u53d8\u5316\u548c\u7528\u6237\u9762\u5411\u7684\u7ed3\u679c\u3002", "result": "CI\u91c7\u7528\u8005\u9879\u76ee\u89c4\u6a21\u66f4\u5927\u3001\u66f4\u6d3b\u8dc3\uff0c\u53d1\u5e03\u66f4\u5feb\u66f4\u89c4\u5f8b\uff1bCI\u91c7\u7528\u96c6\u4e2d\u5728\u96c6\u6210\u548c\u53ef\u9760\u6027\u5bc6\u96c6\u578b\u7c7b\u522b\uff08\u5982\u91d1\u878d\u548c\u751f\u4ea7\u529b\uff09\uff1bCI\u91c7\u7528\u4e0e\u66f4\u9ad8\u7684Google Play\u5546\u5e97\u53c2\u4e0e\u5ea6\u76f8\u5173\uff08\u66f4\u591a\u4e0b\u8f7d\u548c\u8bc4\u8bba\uff09\uff0c\u4e14\u4e0d\u4f1a\u964d\u4f4e\u8bc4\u5206\u3002", "conclusion": "CI\u91c7\u7528\u4e0e\u652f\u6301\u6301\u7eed\u4ea4\u4ed8\u3001\u66f4\u9ad8\u9879\u76ee\u53ef\u89c1\u6027\u548c\u66f4\u5f3a\u7528\u6237\u53c2\u4e0e\u5ea6\u7684\u5b9e\u8df5\u76f8\u4e00\u81f4\uff0c\u5728\u79fb\u52a8\u751f\u6001\u7cfb\u7edf\u4e2d\u5177\u6709\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2602.00750", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00750", "abs": "https://arxiv.org/abs/2602.00750", "authors": ["Md Jahedur Rahman", "Ihsen Alouani"], "title": "Bypassing Prompt Injection Detectors through Evasive Injections", "comment": null, "summary": "Large language models (LLMs) are increasingly used in interactive and retrieval-augmented systems, but they remain vulnerable to task drift; deviations from a user's intended instruction due to injected secondary prompts. Recent work has shown that linear probes trained on activation deltas of LLMs' hidden layers can effectively detect such drift. In this paper, we evaluate the robustness of these detectors against adversarially optimised suffixes. We generate universal suffixes that cause poisoned inputs to evade detection across multiple probes simultaneously. Our experiments on Phi-3 3.8B and Llama-3 8B show that a single suffix can achieve high attack success rates; up to 93.91% and 99.63%, respectively, when all probes must be fooled, and nearly perfect success (>90%) under majority vote setting. These results demonstrate that activation delta-based task drift detectors are highly vulnerable to adversarial suffixes, highlighting the need for stronger defences against adaptive attacks. We also propose a defence technique where we generate multiple suffixes and randomly append one of them to the prompts while making forward passes of the LLM and train logistic regression models with these activations. We found this approach to be highly effective against such attacks.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u57fa\u4e8e\u6fc0\u6d3bdelta\u7684\u4efb\u52a1\u6f02\u79fb\u68c0\u6d4b\u5668\u5bf9\u5bf9\u6297\u6027\u540e\u7f00\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u8fd9\u4e9b\u68c0\u6d4b\u5668\u9ad8\u5ea6\u8106\u5f31\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ea4\u4e92\u5f0f\u548c\u68c0\u7d22\u589e\u5f3a\u7cfb\u7edf\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u4efb\u52a1\u6f02\u79fb\u653b\u51fb\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u4f7f\u7528\u7ebf\u6027\u63a2\u9488\u68c0\u6d4b\u8fd9\u79cd\u6f02\u79fb\uff0c\u4f46\u8fd9\u4e9b\u68c0\u6d4b\u5668\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u8bc4\u4f30\u3002", "method": "1) \u751f\u6210\u80fd\u540c\u65f6\u6b3a\u9a97\u591a\u4e2a\u7ebf\u6027\u63a2\u9488\u7684\u901a\u7528\u5bf9\u6297\u6027\u540e\u7f00\uff1b2) \u5728Phi-3 3.8B\u548cLlama-3 8B\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff1b3) \u63d0\u51fa\u9632\u5fa1\u6280\u672f\uff1a\u751f\u6210\u591a\u4e2a\u540e\u7f00\u5e76\u968f\u673a\u9644\u52a0\u5230\u63d0\u793a\u4e2d\uff0c\u4f7f\u7528\u8fd9\u4e9b\u6fc0\u6d3b\u8bad\u7ec3\u903b\u8f91\u56de\u5f52\u6a21\u578b\u3002", "result": "\u5355\u4e2a\u5bf9\u6297\u6027\u540e\u7f00\u80fd\u5b9e\u73b0\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff1a\u5f53\u6240\u6709\u63a2\u9488\u90fd\u9700\u8981\u88ab\u6b3a\u9a97\u65f6\uff0cPhi-3\u8fbe\u523093.91%\uff0cLlama-3\u8fbe\u523099.63%\uff1b\u5728\u591a\u6570\u6295\u7968\u8bbe\u7f6e\u4e0b\u6210\u529f\u7387\u63a5\u8fd1\u5b8c\u7f8e\uff08>90%\uff09\u3002\u63d0\u51fa\u7684\u9632\u5fa1\u65b9\u6cd5\u5bf9\u8fd9\u4e9b\u653b\u51fb\u975e\u5e38\u6709\u6548\u3002", "conclusion": "\u57fa\u4e8e\u6fc0\u6d3bdelta\u7684\u4efb\u52a1\u6f02\u79fb\u68c0\u6d4b\u5668\u5bf9\u5bf9\u6297\u6027\u540e\u7f00\u653b\u51fb\u9ad8\u5ea6\u8106\u5f31\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u81ea\u9002\u5e94\u653b\u51fb\u3002\u63d0\u51fa\u7684\u968f\u673a\u540e\u7f00\u9632\u5fa1\u65b9\u6cd5\u663e\u793a\u51fa\u826f\u597d\u7684\u9632\u62a4\u6548\u679c\u3002"}}
{"id": "2602.02138", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02138", "abs": "https://arxiv.org/abs/2602.02138", "authors": ["Lyu Zongyi", "Ji Zhenlan", "Chen Songqiang", "Wang Liwen", "Huang Yuheng", "Wang Shuai", "Cheung Shing-Chi"], "title": "CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems", "comment": "18 pages, 12 tables, 4 figures", "summary": "Despite the remarkable success that Multi-Agent Code Generation Systems (MACGS) have achieved, the inherent complexity of multi-agent architectures produces substantial volumes of intermediate outputs. To date, the individual importance of these intermediate outputs to the system correctness remains opaque, which impedes targeted optimization of MACGS designs. To address this challenge, we propose CAM, the first \\textbf{C}ausality-based \\textbf{A}nalysis framework for \\textbf{M}ACGS that systematically quantifies the contribution of different intermediate features for system correctness. By comprehensively categorizing intermediate outputs and systematically simulating realistic errors on intermediate features, we identify the important features for system correctness and aggregate their importance rankings.\n  We conduct extensive empirical analysis on the identified importance rankings. Our analysis reveals intriguing findings: first, we uncover context-dependent features\\textemdash features whose importance emerges mainly through interactions with other features, revealing that quality assurance for MACGS should incorporate cross-feature consistency checks; second, we reveal that hybrid backend MACGS with different backend LLMs assigned according to their relative strength achieves up to 7.2\\% Pass@1 improvement, underscoring hybrid architectures as a promising direction for future MACGS design. We further demonstrate CAM's practical utility through two applications: (1) failure repair which achieves a 73.3\\% success rate by optimizing top-3 importance-ranked features and (2) feature pruning that reduces up to 66.8\\% intermediate token consumption while maintaining generation performance. Our work provides actionable insights for MACGS design and deployment, establishing causality analysis as a powerful approach for understanding and improving MACGS.", "AI": {"tldr": "CAM\u6846\u67b6\u9996\u6b21\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u5206\u6790\u591a\u667a\u80fd\u4f53\u4ee3\u7801\u751f\u6210\u7cfb\u7edf\uff0c\u91cf\u5316\u4e2d\u95f4\u7279\u5f81\u5bf9\u7cfb\u7edf\u6b63\u786e\u6027\u7684\u8d21\u732e\uff0c\u8bc6\u522b\u5173\u952e\u7279\u5f81\u5e76\u5e94\u7528\u4e8e\u7cfb\u7edf\u4f18\u5316", "motivation": "\u591a\u667a\u80fd\u4f53\u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u4ea7\u751f\u5927\u91cf\u4e2d\u95f4\u8f93\u51fa\uff0c\u4f46\u8fd9\u4e9b\u4e2d\u95f4\u8f93\u51fa\u5bf9\u7cfb\u7edf\u6b63\u786e\u6027\u7684\u91cd\u8981\u6027\u5c1a\u4e0d\u660e\u786e\uff0c\u963b\u788d\u4e86\u9488\u5bf9\u6027\u7684\u7cfb\u7edf\u4f18\u5316\u8bbe\u8ba1", "method": "\u63d0\u51faCAM\u56e0\u679c\u5206\u6790\u6846\u67b6\uff0c\u7cfb\u7edf\u5206\u7c7b\u4e2d\u95f4\u8f93\u51fa\uff0c\u6a21\u62df\u5b9e\u9645\u9519\u8bef\uff0c\u91cf\u5316\u4e0d\u540c\u4e2d\u95f4\u7279\u5f81\u5bf9\u7cfb\u7edf\u6b63\u786e\u6027\u7684\u8d21\u732e\uff0c\u5e76\u805a\u5408\u91cd\u8981\u6027\u6392\u540d", "result": "\u53d1\u73b0\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7279\u5f81\u7684\u91cd\u8981\u6027\u901a\u8fc7\u7279\u5f81\u95f4\u4ea4\u4e92\u4f53\u73b0\uff1b\u6df7\u5408\u540e\u7aefMACGS\u53ef\u83b7\u5f977.2%\u6027\u80fd\u63d0\u5347\uff1b\u901a\u8fc7\u4f18\u5316\u91cd\u8981\u6027\u6392\u540d\u524d3\u7684\u7279\u5f81\u5b9e\u73b073.3%\u7684\u4fee\u590d\u6210\u529f\u7387\uff1b\u7279\u5f81\u526a\u679d\u53ef\u51cf\u5c1166.8%\u4e2d\u95f4token\u6d88\u8017", "conclusion": "CAM\u6846\u67b6\u4e3aMACGS\u8bbe\u8ba1\u548c\u90e8\u7f72\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u5efa\u7acb\u56e0\u679c\u5206\u6790\u4f5c\u4e3a\u7406\u89e3\u548c\u6539\u8fdbMACGS\u7684\u5f3a\u5927\u65b9\u6cd5"}}
{"id": "2602.00837", "categories": ["cs.CR", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.00837", "abs": "https://arxiv.org/abs/2602.00837", "authors": ["Claude Carlet", "Marko \u00d0urasevic", "Domagoj Jakobovic", "Luca Mariot", "Stjepan Picek"], "title": "IDEM Enough? Evolving Highly Nonlinear Idempotent Boolean Functions", "comment": "20 pages, 6 figures, 2 tables", "summary": "Idempotent Boolean functions form a highly structured subclass of Boolean functions that is closely related to rotation symmetry under a normal-basis representation and to invariance under a fixed linear map in a polynomial basis. These functions are attractive as candidates for cryptographic design, yet their additional algebraic constraints make the search for high nonlinearity substantially more difficult than in the unconstrained case. In this work, we investigate evolutionary methods for constructing highly nonlinear idempotent Boolean functions for dimensions $n=5$ up to $n=12$ using a polynomial basis representation with canonical primitive polynomials. Our results show that the problem of evolving idempotent functions is difficult due to the disruptive nature of crossover and mutation operators. Next, we show that idempotence can be enforced by encoding the truth table on orbits, yielding a compact genome of size equal to the number of distinct squaring orbits.", "AI": {"tldr": "\u4f7f\u7528\u8fdb\u5316\u7b97\u6cd5\u6784\u9020\u9ad8\u975e\u7ebf\u6027\u5e42\u7b49\u5e03\u5c14\u51fd\u6570\u7684\u7814\u7a76\uff0c\u901a\u8fc7\u8f68\u9053\u7f16\u7801\u5b9e\u73b0\u5e42\u7b49\u6027\u7ea6\u675f", "motivation": "\u5e42\u7b49\u5e03\u5c14\u51fd\u6570\u5177\u6709\u7279\u6b8a\u7684\u4ee3\u6570\u7ed3\u6784\uff0c\u4e0e\u5bc6\u7801\u5b66\u8bbe\u8ba1\u5bc6\u5207\u76f8\u5173\uff0c\u4f46\u5176\u989d\u5916\u7684\u4ee3\u6570\u7ea6\u675f\u4f7f\u5f97\u5bfb\u627e\u9ad8\u975e\u7ebf\u6027\u51fd\u6570\u6bd4\u65e0\u7ea6\u675f\u60c5\u51b5\u66f4\u52a0\u56f0\u96be", "method": "\u4f7f\u7528\u8fdb\u5316\u7b97\u6cd5\uff08\u4ea4\u53c9\u548c\u53d8\u5f02\u64cd\u4f5c\uff09\u5728\u591a\u9879\u5f0f\u57fa\u8868\u793a\u4e0b\u6784\u9020\u5e42\u7b49\u5e03\u5c14\u51fd\u6570\uff0c\u91c7\u7528\u8f68\u9053\u7f16\u7801\u65b9\u5f0f\u5f3a\u5236\u5b9e\u73b0\u5e42\u7b49\u6027\uff0c\u5c06\u771f\u503c\u8868\u7f16\u7801\u5728\u8f68\u9053\u4e0a", "result": "\u7814\u7a76\u53d1\u73b0\u8fdb\u5316\u5e42\u7b49\u51fd\u6570\u5f88\u56f0\u96be\uff0c\u56e0\u4e3a\u4ea4\u53c9\u548c\u53d8\u5f02\u64cd\u4f5c\u5177\u6709\u7834\u574f\u6027\uff1b\u901a\u8fc7\u8f68\u9053\u7f16\u7801\u53ef\u4ee5\u5f3a\u5236\u5b9e\u73b0\u5e42\u7b49\u6027\uff0c\u5f97\u5230\u7d27\u51d1\u7684\u57fa\u56e0\u7ec4", "conclusion": "\u8f68\u9053\u7f16\u7801\u662f\u6784\u9020\u5e42\u7b49\u5e03\u5c14\u51fd\u6570\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u514b\u670d\u8fdb\u5316\u7b97\u6cd5\u4e2d\u4ea4\u53c9\u548c\u53d8\u5f02\u64cd\u4f5c\u5bf9\u5e42\u7b49\u6027\u7684\u7834\u574f"}}
{"id": "2602.00485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00485", "abs": "https://arxiv.org/abs/2602.00485", "authors": ["Shule Lu", "Yujing Wang", "Hainan Zhang", "Xiaoshan Yang", "Hongwei Zheng", "Yongxin Tong", "Changsheng Xu", "Zhiming Zheng"], "title": "Replacing Parameters with Preferences: Federated Alignment of Heterogeneous Vision-Language Models", "comment": null, "summary": "VLMs have broad potential in privacy-sensitive domains such as healthcare and finance, yet strict data-sharing constraints render centralized training infeasible. FL mitigates this issue by enabling decentralized training, but practical deployments face challenges due to client heterogeneity in computational resources, application requirements, and model architectures. We argue that while replacing data with model parameters characterizes the present of FL, replacing parameters with preferences represents a more scalable and privacy-preserving future. Motivated by this perspective, we propose MoR, a federated alignment framework based on GRPO with Mixture-of-Rewards for heterogeneous VLMs. MoR initializes a visual foundation model as a KL-regularized reference, while each client locally trains a reward model from local preference annotations, capturing specific evaluation signals without exposing raw data. To reconcile heterogeneous rewards, we introduce a routing-based fusion mechanism that adaptively aggregates client reward signals. Finally, the server performs GRPO with this mixed reward to optimize the base VLM. Experiments on three public VQA benchmarks demonstrate that MoR consistently outperforms federated alignment baselines in generalization, robustness, and cross-client adaptability. Our approach provides a scalable solution for privacy-preserving alignment of heterogeneous VLMs under federated settings.", "AI": {"tldr": "MoR\uff1a\u57fa\u4e8eGRPO\u548c\u6df7\u5408\u5956\u52b1\u7684\u8054\u90a6\u5bf9\u9f50\u6846\u67b6\uff0c\u7528\u4e8e\u5f02\u6784\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u672c\u5730\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u548c\u8def\u7531\u878d\u5408\u673a\u5236\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u8054\u90a6\u5bf9\u9f50", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u3001\u91d1\u878d\u7b49\u9690\u79c1\u654f\u611f\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u6570\u636e\u5171\u4eab\u9650\u5236\u4f7f\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u4e0d\u53ef\u884c\u3002\u8054\u90a6\u5b66\u4e60\u867d\u80fd\u89e3\u51b3\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9762\u4e34\u5ba2\u6237\u7aef\u5f02\u6784\u6027\uff08\u8ba1\u7b97\u8d44\u6e90\u3001\u5e94\u7528\u9700\u6c42\u3001\u6a21\u578b\u67b6\u6784\uff09\u7684\u6311\u6218\u3002\u4f5c\u8005\u8ba4\u4e3a\uff0c\u7528\u504f\u597d\u66ff\u4ee3\u53c2\u6570\u662f\u6bd4\u7528\u53c2\u6570\u66ff\u4ee3\u6570\u636e\u66f4\u53ef\u6269\u5c55\u3001\u66f4\u9690\u79c1\u4fdd\u62a4\u7684\u8054\u90a6\u5b66\u4e60\u53d1\u5c55\u65b9\u5411\u3002", "method": "\u63d0\u51faMoR\u6846\u67b6\uff1a1\uff09\u521d\u59cb\u5316\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u4f5c\u4e3aKL\u6b63\u5219\u5316\u53c2\u8003\uff1b2\uff09\u6bcf\u4e2a\u5ba2\u6237\u7aef\u672c\u5730\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\uff0c\u4ece\u672c\u5730\u504f\u597d\u6807\u6ce8\u4e2d\u6355\u83b7\u7279\u5b9a\u8bc4\u4f30\u4fe1\u53f7\u800c\u4e0d\u66b4\u9732\u539f\u59cb\u6570\u636e\uff1b3\uff09\u5f15\u5165\u57fa\u4e8e\u8def\u7531\u7684\u878d\u5408\u673a\u5236\uff0c\u81ea\u9002\u5e94\u805a\u5408\u5ba2\u6237\u7aef\u5956\u52b1\u4fe1\u53f7\uff1b4\uff09\u670d\u52a1\u5668\u4f7f\u7528\u6df7\u5408\u5956\u52b1\u6267\u884cGRPO\u4f18\u5316\u57fa\u7840\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u7684VQA\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMoR\u5728\u6cdb\u5316\u6027\u3001\u9c81\u68d2\u6027\u548c\u8de8\u5ba2\u6237\u7aef\u9002\u5e94\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u8054\u90a6\u5bf9\u9f50\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MoR\u4e3a\u8054\u90a6\u8bbe\u7f6e\u4e0b\u5f02\u6784\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u8868\u4e86\u4ece\u53c2\u6570\u5171\u4eab\u5411\u504f\u597d\u5171\u4eab\u7684\u8054\u90a6\u5b66\u4e60\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2602.02235", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02235", "abs": "https://arxiv.org/abs/2602.02235", "authors": ["Zhaonan Wu", "Yanjie Zhao", "Zhenpeng Chen", "Zheng Wang", "Haoyu Wang"], "title": "Agent-Based Software Artifact Evaluation", "comment": null, "summary": "Artifact evaluation has been adopted in the Software Engineering (SE) research community for 15 years, substantially improving research reproducibility across major SE conferences. However, this success has introduced a growing scalability challenge, as artifact evaluation relies heavily on reviewers' manual execution and debugging, leading to escalating human effort amid rapidly increasing paper submissions. To address this problem, we investigate automated artifact evaluation. We first conduct a preliminary study on artifacts from top-tier SE conferences and identify three key challenges: perceiving execution states, maintaining stable execution environments, and recovering from execution errors. Inspired by these findings, we propose ArtifactCopilot, the first end-to-end agent-based framework for automated artifact evaluation. ArtifactCopilot automates environment construction, instruction execution, and error recovery by combining an execution normalization strategy to ensure environment stability with an artifact evaluation graph that transforms README documents into dependency-aware command graphs, enabling structured execution planning, execution-state tracking, and error recovery. Evaluation on 48 real-world artifacts shows that ArtifactCopilot matches human artifact evaluation outcomes for 85.42% of the artifacts, outperforming Claude Code by 52.09 percentage points, while costing only \\$0.091 per artifact on average and requiring zero human intervention for 45 out of 48 artifacts.", "AI": {"tldr": "ArtifactCopilot\uff1a\u9996\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u81ea\u52a8\u5316\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u5236\u54c1\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u6267\u884c\u6807\u51c6\u5316\u548c\u4f9d\u8d56\u611f\u77e5\u7684\u547d\u4ee4\u56fe\u6280\u672f\uff0c\u5c06\u4eba\u5de5\u5236\u54c1\u8bc4\u4f30\u81ea\u52a8\u5316\uff0c\u572848\u4e2a\u771f\u5b9e\u5236\u54c1\u4e0a\u8fbe\u523085.42%\u7684\u4eba\u7c7b\u8bc4\u4f30\u5339\u914d\u7387\uff0c\u5e73\u5747\u6bcf\u4e2a\u5236\u54c1\u4ec5\u97000.091\u7f8e\u5143\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u793e\u533a\u7684\u5236\u54c1\u8bc4\u4f30\u5df2\u5b9e\u65bd15\u5e74\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7814\u7a76\u53ef\u590d\u73b0\u6027\uff0c\u4f46\u968f\u7740\u8bba\u6587\u63d0\u4ea4\u91cf\u5feb\u901f\u589e\u957f\uff0c\u4f9d\u8d56\u4eba\u5de5\u6267\u884c\u548c\u8c03\u8bd5\u7684\u4f20\u7edf\u8bc4\u4f30\u65b9\u5f0f\u9762\u4e34\u4e25\u91cd\u7684\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u964d\u4f4e\u4eba\u529b\u6210\u672c\u3002", "method": "\u63d0\u51faArtifactCopilot\u6846\u67b6\uff0c\u91c7\u7528\u7aef\u5230\u7aef\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u7ed3\u5408\u6267\u884c\u6807\u51c6\u5316\u7b56\u7565\u786e\u4fdd\u73af\u5883\u7a33\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u5236\u54c1\u8bc4\u4f30\u56fe\u5c06README\u6587\u6863\u8f6c\u6362\u4e3a\u4f9d\u8d56\u611f\u77e5\u7684\u547d\u4ee4\u56fe\uff0c\u5b9e\u73b0\u7ed3\u6784\u5316\u6267\u884c\u89c4\u5212\u3001\u6267\u884c\u72b6\u6001\u8ddf\u8e2a\u548c\u9519\u8bef\u6062\u590d\u3002", "result": "\u572848\u4e2a\u771f\u5b9e\u4e16\u754c\u5236\u54c1\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff1aArtifactCopilot\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u7ed3\u679c\u5339\u914d\u7387\u8fbe85.42%\uff0c\u6bd4Claude Code\u9ad8\u51fa52.09\u4e2a\u767e\u5206\u70b9\uff1b\u5e73\u5747\u6bcf\u4e2a\u5236\u54c1\u6210\u672c\u4ec50.091\u7f8e\u5143\uff1b48\u4e2a\u5236\u54c1\u4e2d\u670945\u4e2a\u5b8c\u5168\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002", "conclusion": "ArtifactCopilot\u662f\u9996\u4e2a\u81ea\u52a8\u5316\u5236\u54c1\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u793e\u533a\u9762\u4e34\u7684\u5236\u54c1\u8bc4\u4f30\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u663e\u8457\u964d\u4f4e\u4eba\u529b\u6210\u672c\uff0c\u4e3a\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u7814\u7a76\u53ef\u590d\u73b0\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.00979", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00979", "abs": "https://arxiv.org/abs/2602.00979", "authors": ["Xueyi Li", "Zhuoneng Zhou", "Zitao Liu", "Yongdong Wu", "Weiqi Luo"], "title": "GradingAttack: Attacking Large Language Models Towards Short Answer Grading Ability", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable potential for automatic short answer grading (ASAG), significantly boosting student assessment efficiency and scalability in educational scenarios. However, their vulnerability to adversarial manipulation raises critical concerns about automatic grading fairness and reliability. In this paper, we introduce GradingAttack, a fine-grained adversarial attack framework that systematically evaluates the vulnerability of LLM based ASAG models. Specifically, we align general-purpose attack methods with the specific objectives of ASAG by designing token-level and prompt-level strategies that manipulate grading outcomes while maintaining high camouflage. Furthermore, to quantify attack camouflage, we propose a novel evaluation metric that balances attack success and camouflage. Experiments on multiple datasets demonstrate that both attack strategies effectively mislead grading models, with prompt-level attacks achieving higher success rates and token-level attacks exhibiting superior camouflage capability. Our findings underscore the need for robust defenses to ensure fairness and reliability in ASAG. Our code and datasets are available at https://anonymous.4open.science/r/GradingAttack.", "AI": {"tldr": "GradingAttack\u662f\u4e00\u4e2a\u9488\u5bf9LLM\u81ea\u52a8\u8bc4\u5206\u7cfb\u7edf\u7684\u7ec6\u7c92\u5ea6\u5bf9\u6297\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7token\u7ea7\u548cprompt\u7ea7\u7b56\u7565\u64cd\u7eb5\u8bc4\u5206\u7ed3\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u4f2a\u88c5\u6027", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u77ed\u7b54\u6848\u8bc4\u5206\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5bf9\u6297\u653b\u51fb\u8106\u5f31\u6027\u5f15\u53d1\u4e86\u8bc4\u5206\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\u7684\u4e25\u91cd\u62c5\u5fe7\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30LLM\u8bc4\u5206\u6a21\u578b\u7684\u8106\u5f31\u6027", "method": "\u63d0\u51fa\u4e86GradingAttack\u6846\u67b6\uff0c\u5c06\u901a\u7528\u653b\u51fb\u65b9\u6cd5\u4e0eASAG\u7279\u5b9a\u76ee\u6807\u5bf9\u9f50\uff0c\u8bbe\u8ba1\u4e86token\u7ea7\u548cprompt\u7ea7\u653b\u51fb\u7b56\u7565\u6765\u64cd\u7eb5\u8bc4\u5206\u7ed3\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u4f2a\u88c5\u6027\uff1b\u8fd8\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u6765\u91cf\u5316\u653b\u51fb\u4f2a\u88c5", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e24\u79cd\u653b\u51fb\u7b56\u7565\u90fd\u80fd\u6709\u6548\u8bef\u5bfc\u8bc4\u5206\u6a21\u578b\uff0c\u5176\u4e2dprompt\u7ea7\u653b\u51fb\u6210\u529f\u7387\u66f4\u9ad8\uff0c\u800ctoken\u7ea7\u653b\u51fb\u5177\u6709\u66f4\u597d\u7684\u4f2a\u88c5\u80fd\u529b", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u9700\u8981\u5f00\u53d1\u9c81\u68d2\u7684\u9632\u5fa1\u673a\u5236\u6765\u786e\u4fddASAG\u7684\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\uff0c\u66b4\u9732\u4e86LLM\u8bc4\u5206\u7cfb\u7edf\u7684\u8106\u5f31\u6027"}}
{"id": "2602.00521", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00521", "abs": "https://arxiv.org/abs/2602.00521", "authors": ["Junhyuk Choi", "Sohhyung Park", "Chanhee Cho", "Hyeonchu Park", "Bugeun Kim"], "title": "Diagnosing the Reliability of LLM-as-a-Judge via Item Response Theory", "comment": "Under review", "summary": "While LLM-as-a-Judge is widely used in automated evaluation, existing validation practices primarily operate at the level of observed outputs, offering limited insight into whether LLM judges themselves function as stable and reliable measurement instruments. To address this limitation, we introduce a two-phase diagnostic framework for assessing reliability of LLM-as-a-Judge, grounded in Item Response Theory (IRT). The framework adopts Graded Response Model (GRM) of IRT and formalizes reliability along two complementary dimensions: (1) intrinsic consistency, defined as the stability of measurement behavior under prompt variations, and (2) human alignment, capturing correspondence with human quality assessments. We empirically examine diverse LLM judges with this framework, and show that leveraging IRT-GRM yields interpretable signals for diagnosing judgments systematically. These signals provide practical guidance for verifying reliablity of LLM-as-a-Judge and identifying potential causes of unreliability.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u7684\u4e24\u9636\u6bb5\u8bca\u65ad\u6846\u67b6\uff0c\u8bc4\u4f30LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u53ef\u9760\u6027\uff0c\u5305\u62ec\u5185\u5728\u4e00\u81f4\u6027\u548c\u4eba\u7c7b\u5bf9\u9f50\u4e24\u4e2a\u7ef4\u5ea6", "motivation": "\u73b0\u6709LLM-as-a-Judge\u9a8c\u8bc1\u5b9e\u8df5\u4e3b\u8981\u505c\u7559\u5728\u89c2\u6d4b\u8f93\u51fa\u5c42\u9762\uff0c\u65e0\u6cd5\u6df1\u5165\u4e86\u89e3LLM\u8bc4\u5224\u8005\u662f\u5426\u4f5c\u4e3a\u7a33\u5b9a\u53ef\u9760\u7684\u6d4b\u91cf\u5de5\u5177", "method": "\u5f15\u5165\u57fa\u4e8e\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u7684\u4e24\u9636\u6bb5\u8bca\u65ad\u6846\u67b6\uff0c\u91c7\u7528IRT\u7684\u7b49\u7ea7\u53cd\u5e94\u6a21\u578b\uff0c\u4ece\u5185\u5728\u4e00\u81f4\u6027\uff08\u63d0\u793a\u53d8\u5316\u4e0b\u7684\u6d4b\u91cf\u7a33\u5b9a\u6027\uff09\u548c\u4eba\u7c7b\u5bf9\u9f50\uff08\u4e0e\u4eba\u7c7b\u8d28\u91cf\u8bc4\u4f30\u7684\u5bf9\u5e94\u6027\uff09\u4e24\u4e2a\u7ef4\u5ea6\u5f62\u5f0f\u5316\u53ef\u9760\u6027", "result": "\u7ecf\u9a8c\u6027\u68c0\u9a8c\u591a\u79cdLLM\u8bc4\u5224\u8005\uff0c\u663e\u793a\u5229\u7528IRT-GRM\u80fd\u591f\u4ea7\u751f\u53ef\u89e3\u91ca\u7684\u4fe1\u53f7\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bca\u65ad\u8bc4\u5224\u7ed3\u679c", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9a8c\u8bc1LLM-as-a-Judge\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u5e76\u80fd\u8bc6\u522b\u4e0d\u53ef\u9760\u6027\u7684\u6f5c\u5728\u539f\u56e0"}}
{"id": "2602.01160", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01160", "abs": "https://arxiv.org/abs/2602.01160", "authors": ["Yuhao Xue", "Jiuan Zhou", "Yu Cheng", "Zhaoxia Yin"], "title": "DTAMS: High-Capacity Generative Steganography via Dynamic Multi-Timestep Selection and Adaptive Deviation Mapping in Latent Diffusion", "comment": null, "summary": "With the rapid development of AIGC technologies, generative image steganography has attracted increasing attention due to its high imperceptibility and flexibility. However, existing generative steganography methods often maintain acceptable security and robustness only at relatively low embedding rates, severely limiting the practical applicability of steganographic systems. To address this issue, we propose a novel DTAMS framework that achieves high embedding rates while ensuring strong robustness and security. Specifically, a dynamic multi-timestep adaptive embedding mechanism is constructed based on transition-cost modeling in diffusion models, enabling automatic selection of optimal embedding timesteps to improve embedding rates while preserving overall performance. Meanwhile, we propose a global sub-interval mapping strategy that jointly considers mapping errors and the frequency distribution of secret information, converting point-wise perturbations into interval-level statistical mappings to suppress error accumulation and distribution drift during multi-step diffusion processes. Furthermore, a multi-dimensional joint constraint mechanism is introduced to mitigate distortions caused by repeated latent-pixel transformations by jointly regularizing embedding errors at the pixel, latent, and semantic levels. Experiments demonstrate that the proposed method achieves an embedding rate of 12 bpp while maintaining excellent security and robustness. Across all evaluated conditions, DTAMS reduces the average extraction error rate by 59.39%, representing a significant improvement over SOTA methods.", "AI": {"tldr": "\u63d0\u51faDTAMS\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u591a\u65f6\u95f4\u6b65\u81ea\u9002\u5e94\u5d4c\u5165\u673a\u5236\u3001\u5168\u5c40\u5b50\u533a\u95f4\u6620\u5c04\u7b56\u7565\u548c\u591a\u7ef4\u8054\u5408\u7ea6\u675f\u673a\u5236\uff0c\u5728\u6269\u6563\u6a21\u578b\u4e2d\u5b9e\u73b0\u9ad8\u5d4c\u5165\u7387\uff0812 bpp\uff09\u7684\u540c\u65f6\u4fdd\u6301\u5f3a\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u56fe\u50cf\u9690\u5199\u65b9\u6cd5\u5728\u4f4e\u5d4c\u5165\u7387\u4e0b\u624d\u80fd\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e25\u91cd\u9650\u5236\u4e86\u9690\u5199\u7cfb\u7edf\u7684\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u89e3\u51b3\u9ad8\u5d4c\u5165\u7387\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "method": "1. \u57fa\u4e8e\u6269\u6563\u6a21\u578b\u8f6c\u6362\u6210\u672c\u5efa\u6a21\u7684\u52a8\u6001\u591a\u65f6\u95f4\u6b65\u81ea\u9002\u5e94\u5d4c\u5165\u673a\u5236\uff0c\u81ea\u52a8\u9009\u62e9\u6700\u4f18\u5d4c\u5165\u65f6\u95f4\u6b65\uff1b2. \u5168\u5c40\u5b50\u533a\u95f4\u6620\u5c04\u7b56\u7565\uff0c\u5c06\u70b9\u6270\u52a8\u8f6c\u6362\u4e3a\u533a\u95f4\u7ea7\u7edf\u8ba1\u6620\u5c04\uff1b3. \u50cf\u7d20\u3001\u6f5c\u7a7a\u95f4\u548c\u8bed\u4e49\u5c42\u9762\u7684\u591a\u7ef4\u8054\u5408\u7ea6\u675f\u673a\u5236\uff0c\u51cf\u5c11\u91cd\u590d\u6f5c\u50cf\u7d20\u53d8\u6362\u5e26\u6765\u7684\u5931\u771f\u3002", "result": "DTAMS\u5b9e\u73b0\u4e8612 bpp\u7684\u9ad8\u5d4c\u5165\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4f18\u5f02\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u3002\u5728\u6240\u6709\u8bc4\u4f30\u6761\u4ef6\u4e0b\uff0c\u5e73\u5747\u63d0\u53d6\u9519\u8bef\u7387\u964d\u4f4e\u4e8659.39%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684DTAMS\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u52a8\u6001\u5d4c\u5165\u673a\u5236\u548c\u6620\u5c04\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u56fe\u50cf\u9690\u5199\u5728\u8ffd\u6c42\u9ad8\u5d4c\u5165\u7387\u65f6\u9762\u4e34\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u6311\u6218\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.00528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00528", "abs": "https://arxiv.org/abs/2602.00528", "authors": ["Minhua Lin", "Enyan Dai", "Hui Liu", "Xianfeng Tang", "Yuliang Yan", "Zhenwei Dai", "Jingying Zeng", "Zhiwei Zhang", "Fali Wang", "Hongcheng Gao", "Chen Luo", "Xiang Zhang", "Qi He", "Suhang Wang"], "title": "How Far Are LLMs from Professional Poker Players? Revisiting Game-Theoretic Reasoning with Agentic Tool Use", "comment": "Accepted by ICLR 2026", "summary": "As Large Language Models (LLMs) are increasingly applied in high-stakes domains, their ability to reason strategically under uncertainty becomes critical. Poker provides a rigorous testbed, requiring not only strong actions but also principled, game-theoretic reasoning. In this paper, we conduct a systematic study of LLMs in multiple realistic poker tasks, evaluating both gameplay outcomes and reasoning traces. Our analysis reveals LLMs fail to compete against traditional algorithms and identifies three recurring flaws: reliance on heuristics, factual misunderstandings, and a \"knowing-doing\" gap where actions diverge from reasoning. An initial attempt with behavior cloning and step-level reinforcement learning improves reasoning style but remains insufficient for accurate game-theoretic play. Motivated by these limitations, we propose ToolPoker, a tool-integrated reasoning framework that combines external solvers for GTO-consistent actions with more precise professional-style explanations. Experiments demonstrate that ToolPoker achieves state-of-the-art gameplay while producing reasoning traces that closely reflect game-theoretic principles.", "AI": {"tldr": "LLMs\u5728\u6251\u514b\u6e38\u620f\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u542f\u53d1\u5f0f\u4f9d\u8d56\u3001\u4e8b\u5b9e\u8bef\u89e3\u548c\u77e5\u884c\u5dee\u8ddd\u4e09\u5927\u7f3a\u9677\u3002ToolPoker\u6846\u67b6\u901a\u8fc7\u6574\u5408\u5916\u90e8\u6c42\u89e3\u5668\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6e38\u620f\u8868\u73b0\u548c\u7b26\u5408\u535a\u5f08\u8bba\u539f\u7406\u7684\u63a8\u7406\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5173\u952e\u9886\u57df\u5e94\u7528\u7684\u589e\u52a0\uff0c\u5176\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u6218\u7565\u63a8\u7406\u80fd\u529b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u6251\u514b\u6e38\u620f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u683c\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4e0d\u4ec5\u9700\u8981\u5f3a\u5927\u7684\u884c\u52a8\u80fd\u529b\uff0c\u8fd8\u9700\u8981\u539f\u5219\u6027\u7684\u535a\u5f08\u8bba\u63a8\u7406\u3002", "method": "\u9996\u5148\u5bf9LLMs\u5728\u591a\u4e2a\u73b0\u5b9e\u6251\u514b\u4efb\u52a1\u4e2d\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\uff0c\u8bc4\u4f30\u6e38\u620f\u7ed3\u679c\u548c\u63a8\u7406\u8f68\u8ff9\u3002\u7136\u540e\u63d0\u51faToolPoker\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6574\u5408\u5916\u90e8\u6c42\u89e3\u5668\u6765\u751f\u6210\u7b26\u5408\u535a\u5f08\u8bba\u6700\u4f18\uff08GTO\uff09\u7684\u884c\u52a8\uff0c\u5e76\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u4e13\u4e1a\u98ce\u683c\u89e3\u91ca\u3002", "result": "\u5206\u6790\u663e\u793aLLMs\u65e0\u6cd5\u4e0e\u4f20\u7edf\u7b97\u6cd5\u7ade\u4e89\uff0c\u5b58\u5728\u4e09\u5927\u7f3a\u9677\uff1a\u542f\u53d1\u5f0f\u4f9d\u8d56\u3001\u4e8b\u5b9e\u8bef\u89e3\u548c\u77e5\u884c\u5dee\u8ddd\u3002ToolPoker\u6846\u67b6\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6e38\u620f\u8868\u73b0\uff0c\u5e76\u4ea7\u751f\u4e86\u5bc6\u5207\u53cd\u6620\u535a\u5f08\u8bba\u539f\u7406\u7684\u63a8\u7406\u8f68\u8ff9\u3002", "conclusion": "LLMs\u5728\u6251\u514b\u7b49\u9700\u8981\u535a\u5f08\u8bba\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u4f46\u901a\u8fc7\u6574\u5408\u5916\u90e8\u6c42\u89e3\u5668\u7684ToolPoker\u6846\u67b6\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5b9e\u73b0\u65e2\u7b26\u5408\u535a\u5f08\u8bba\u6700\u4f18\u53c8\u5177\u6709\u53ef\u89e3\u91ca\u6027\u7684\u51b3\u7b56\u3002"}}
{"id": "2602.02293", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02293", "abs": "https://arxiv.org/abs/2602.02293", "authors": ["Nils Chur", "Thiago Santos de Moura", "Argentina Ortega", "Sven Peldszus", "Thorsten Berger", "Nico Hochgeschwender", "Yannic Noller"], "title": "Before Autonomy Takes Control: Software Testing in Robotics", "comment": null, "summary": "Robotic systems are complex and safety-critical software systems. As such, they need to be tested thoroughly. Unfortunately, robot software is intrinsically hard to test compared to traditional software, mainly since the software needs to closely interact with hardware, account for uncertainty in its operational environment, handle disturbances, and act highly autonomously. However, given the large space in which robots operate, anticipating possible failures when designing tests is challenging. This paper presents a mapping study by considering robotics testing papers and relating them to the software testing theory. We consider 247 robotics testing papers and map them to software testing, discussing the state-of-the-art software testing in robotics with an illustrated example, and discuss current challenges. Forming the basis to introduce both the robotics and software engineering communities to software testing challenges. Finally, we identify open questions and lessons learned.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9247\u7bc7\u673a\u5668\u4eba\u6d4b\u8bd5\u8bba\u6587\u7684\u7cfb\u7edf\u6027\u6620\u5c04\u7814\u7a76\uff0c\u5206\u6790\u4e86\u673a\u5668\u4eba\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u73b0\u72b6\u3001\u6311\u6218\u53ca\u4e0e\u8f6f\u4ef6\u6d4b\u8bd5\u7406\u8bba\u7684\u5173\u8054\u3002", "motivation": "\u673a\u5668\u4eba\u7cfb\u7edf\u662f\u590d\u6742\u4e14\u5b89\u5168\u5173\u952e\u7684\u8f6f\u4ef6\u7cfb\u7edf\uff0c\u9700\u8981\u5f7b\u5e95\u6d4b\u8bd5\u3002\u7136\u800c\uff0c\u673a\u5668\u4eba\u8f6f\u4ef6\u6d4b\u8bd5\u6bd4\u4f20\u7edf\u8f6f\u4ef6\u6d4b\u8bd5\u66f4\u52a0\u56f0\u96be\uff0c\u56e0\u4e3a\u8f6f\u4ef6\u9700\u8981\u4e0e\u786c\u4ef6\u7d27\u5bc6\u4ea4\u4e92\u3001\u8003\u8651\u64cd\u4f5c\u73af\u5883\u7684\u4e0d\u786e\u5b9a\u6027\u3001\u5904\u7406\u5e72\u6270\u5e76\u9ad8\u5ea6\u81ea\u4e3b\u8fd0\u884c\u3002\u7531\u4e8e\u673a\u5668\u4eba\u64cd\u4f5c\u7a7a\u95f4\u5de8\u5927\uff0c\u5728\u8bbe\u8ba1\u6d4b\u8bd5\u65f6\u9884\u6d4b\u53ef\u80fd\u7684\u6545\u969c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528\u6620\u5c04\u7814\u7a76\u65b9\u6cd5\uff0c\u5206\u6790\u4e86247\u7bc7\u673a\u5668\u4eba\u6d4b\u8bd5\u76f8\u5173\u8bba\u6587\uff0c\u5c06\u5176\u4e0e\u8f6f\u4ef6\u6d4b\u8bd5\u7406\u8bba\u8fdb\u884c\u5173\u8054\u6620\u5c04\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u8bf4\u660e\u673a\u5668\u4eba\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u6700\u65b0\u6280\u672f\u73b0\u72b6\u3002", "result": "\u7814\u7a76\u7cfb\u7edf\u6027\u5730\u68b3\u7406\u4e86\u673a\u5668\u4eba\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u73b0\u72b6\uff0c\u8bc6\u522b\u4e86\u5f53\u524d\u9762\u4e34\u7684\u6311\u6218\uff0c\u4e3a\u673a\u5668\u4eba\u5b66\u548c\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u4ecb\u7ecd\u4e86\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u5173\u952e\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u4e3a\u673a\u5668\u4eba\u8f6f\u4ef6\u6d4b\u8bd5\u9886\u57df\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u5206\u6790\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u5f00\u653e\u6027\u95ee\u9898\u5e76\u603b\u7ed3\u4e86\u7ecf\u9a8c\u6559\u8bad\uff0c\u4e3a\u4e24\u4e2a\u9886\u57df\u7684\u4ea4\u53c9\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.01185", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01185", "abs": "https://arxiv.org/abs/2602.01185", "authors": ["Fabio Turazza", "Marcello Pietri", "Marco Picone", "Marco Mamei"], "title": "FedBGS: A Blockchain Approach to Segment Gossip Learning in Decentralized Systems", "comment": "Author-accepted manuscript of a paper published in the 2025 IEEE 45th International Conference on Distributed Computing Systems Workshops (ICDCSW), pp. 760-770, doi: 10.1109/ICDCSW63273.2025.00136", "summary": "Privacy-Preserving Federated Learning (PPFL) is a Decentralized machine learning paradigm that enables multiple participants to collaboratively train a global model without sharing their data with the integration of cryptographic and privacy-based techniques to enhance the security of the global system. This privacy-oriented approach makes PPFL a highly suitable solution for training shared models in sectors where data privacy is a critical concern. In traditional FL, local models are trained on edge devices, and only model updates are shared with a central server, which aggregates them to improve the global model. However, despite the presence of the aforementioned privacy techniques, in the classical Federated structure, the issue of the server as a single-point-of-failure remains, leading to limitations both in terms of security and scalability. This paper introduces FedBGS, a fully Decentralized Blockchain-based framework that leverages Segmented Gossip Learning through Federated Analytics. The proposed system aims to optimize blockchain usage while providing comprehensive protection against all types of attacks, ensuring both privacy, security and non-IID data handling in Federated environments.", "AI": {"tldr": "FedBGS\u662f\u4e00\u4e2a\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u7684\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6bb5\u516b\u5366\u5b66\u4e60\u548c\u8054\u90a6\u5206\u6790\u4f18\u5316\u533a\u5757\u94fe\u4f7f\u7528\uff0c\u63d0\u4f9b\u5168\u9762\u7684\u653b\u51fb\u9632\u62a4\uff0c\u786e\u4fdd\u9690\u79c1\u3001\u5b89\u5168\u548c\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u5904\u7406\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u4e2d\u670d\u52a1\u5668\u4f5c\u4e3a\u5355\u70b9\u6545\u969c\u5b58\u5728\u5b89\u5168\u548c\u53ef\u6269\u5c55\u6027\u9650\u5236\uff0c\u5c3d\u7ba1\u6709\u9690\u79c1\u4fdd\u62a4\u6280\u672f\uff0c\u4f46\u4ecd\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u3002\u9700\u8981\u4e00\u79cd\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u7684\u89e3\u51b3\u65b9\u6848\u6765\u6d88\u9664\u5355\u70b9\u6545\u969c\uff0c\u540c\u65f6\u63d0\u4f9b\u5168\u9762\u7684\u653b\u51fb\u9632\u62a4\u3002", "method": "\u63d0\u51faFedBGS\u6846\u67b6\uff0c\u7ed3\u5408\u533a\u5757\u94fe\u6280\u672f\u548c\u5206\u6bb5\u516b\u5366\u5b66\u4e60\uff0c\u901a\u8fc7\u8054\u90a6\u5206\u6790\u4f18\u5316\u533a\u5757\u94fe\u4f7f\u7528\uff0c\u5b9e\u73b0\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u7684\u8054\u90a6\u5b66\u4e60\u67b6\u6784\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u6d88\u9664\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5355\u70b9\u6545\u969c\u95ee\u9898\uff0c\u63d0\u4f9b\u5168\u9762\u7684\u653b\u51fb\u9632\u62a4\uff0c\u540c\u65f6\u4f18\u5316\u533a\u5757\u94fe\u8d44\u6e90\u4f7f\u7528\uff0c\u786e\u4fdd\u9690\u79c1\u3001\u5b89\u5168\u548c\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u5904\u7406\u80fd\u529b\u3002", "conclusion": "FedBGS\u4e3a\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u533a\u5757\u94fe\u548c\u5206\u6bb5\u516b\u5366\u5b66\u4e60\u6280\u672f\u89e3\u51b3\u4e86\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5728\u5b89\u5168\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.01225", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01225", "abs": "https://arxiv.org/abs/2602.01225", "authors": ["Shuyu Chen", "Mingxun Zhou", "Haoyu Niu", "Guopeng Lin", "Weili Han"], "title": "Bifrost: A Much Simpler Secure Two-Party Data Join Protocol for Secure Data Analytics", "comment": "18 pages", "summary": "Secure data join enables two parties with vertically distributed data to securely compute the joined table, allowing the parties to perform downstream Secure multi-party computation-based Data Analytics (SDA), such as training machine learning models, based on the joined table. While Circuit-based Private Set Intersection (CPSI) can be used for secure data join, it introduces redundant dummy rows in the joined table, which results in high overhead in the downstream SDA tasks. iPrivJoin addresses this issue but introduces significant communication overhead in the redundancy removal process, as it relies on the cryptographic primitive OPPRF for data encoding and multiple rounds of oblivious shuffles. In this paper, we propose a much simpler secure data join protocol, Bifrost, which outputs (the secret shares of) a redundancy-free joined table. The highlight of Bifrost lies in its simplicity: it builds upon two conceptually simple building blocks, an ECDH-PSI protocol and a two-party oblivious shuffle protocol. The lightweight protocol design allows Bifrost to avoid the need for OPPRF. We also proposed a simple optimization named \\textit{dual mapping} that reduces the rounds of oblivious shuffle needed from two to one. Experiments on datasets of up to 100 GB show that Bifrost achieves $2.54 \\sim 22.32\\times$ speedup and reduces the communication by $84.15\\% \\sim 88.97\\%$ compared to the SOTA redundancy-free secure data join protocol iPrivJoin. Notably, the communication size of Bifrost is nearly equal to the size of the input data. In the two-step SDA pipeline evaluation (secure join and SDA), the redundancy-free property of Bifrost not only avoids the catastrophic error rate blowup in the downstream tasks caused by the dummy rows in the joined table (as introduced in CPSI), but also shows up to $2.80\\times$ speed-up in the SDA process with up to $73.15\\%$ communication reduction.", "AI": {"tldr": "Bifrost\u662f\u4e00\u4e2a\u7b80\u5355\u9ad8\u6548\u7684\u5197\u4f59\u6d88\u9664\u5b89\u5168\u6570\u636e\u8fde\u63a5\u534f\u8bae\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6848\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u5e76\u51cf\u5c11\u4e86\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u6570\u636e\u8fde\u63a5\u65b9\u6848\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff1a\u57fa\u4e8e\u7535\u8defPSI\u7684\u65b9\u6848\u4f1a\u4ea7\u751f\u5197\u4f59\u7684\u865a\u62df\u884c\uff0c\u589e\u52a0\u4e0b\u6e38\u8ba1\u7b97\u5f00\u9500\uff1biPrivJoin\u867d\u7136\u80fd\u6d88\u9664\u5197\u4f59\uff0c\u4f46\u4f9d\u8d56\u590d\u6742\u7684OPPRF\u548c\u591a\u6b21\u4e0d\u7ecf\u610f\u6d17\u724c\uff0c\u901a\u4fe1\u5f00\u9500\u5de8\u5927\u3002", "method": "Bifrost\u57fa\u4e8e\u4e24\u4e2a\u7b80\u5355\u6784\u5efa\u5757\uff1aECDH-PSI\u534f\u8bae\u548c\u4e24\u65b9\u4e0d\u7ecf\u610f\u6d17\u724c\u534f\u8bae\uff0c\u907f\u514d\u4e86\u590d\u6742\u7684OPPRF\u3002\u91c7\u7528\"\u53cc\u91cd\u6620\u5c04\"\u4f18\u5316\u5c06\u4e0d\u7ecf\u610f\u6d17\u724c\u8f6e\u6b21\u4ece2\u51cf\u5c11\u52301\u3002", "result": "\u5728100GB\u6570\u636e\u96c6\u4e0a\uff0cBifrost\u76f8\u6bd4iPrivJoin\u5b9e\u73b02.54-22.32\u500d\u52a0\u901f\uff0c\u901a\u4fe1\u51cf\u5c1184.15%-88.97%\uff0c\u901a\u4fe1\u91cf\u63a5\u8fd1\u8f93\u5165\u6570\u636e\u5927\u5c0f\u3002\u5728\u5b8c\u6574SDA\u6d41\u7a0b\u4e2d\uff0c\u907f\u514d\u4e86\u865a\u62df\u884c\u5bfc\u81f4\u7684\u9519\u8bef\u7387\u7206\u70b8\uff0cSDA\u8fc7\u7a0b\u52a0\u901f\u8fbe2.80\u500d\uff0c\u901a\u4fe1\u51cf\u5c1173.15%\u3002", "conclusion": "Bifrost\u901a\u8fc7\u7b80\u5355\u7684\u534f\u8bae\u8bbe\u8ba1\u548c\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u65e0\u5197\u4f59\u5b89\u5168\u6570\u636e\u8fde\u63a5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u57fa\u7840\u3002"}}
{"id": "2602.00564", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00564", "abs": "https://arxiv.org/abs/2602.00564", "authors": ["Xiang Zheng", "Weiqi Zhai", "Wei Wang", "Boyu Yang", "Wenbo Li", "Ruixiang Luo", "Haoxiang Sun", "Yucheng Wang", "Zhengze Li", "Meng Wang", "Yuetian Du", "Guojie Lin", "Yaxuan Wang", "Xiaoxiao Xu", "Yanhu Mo", "Xuan Ren", "Hu Wei", "Ze Xu"], "title": "Unmasking Reasoning Processes: A Process-aware Benchmark for Evaluating Structural Mathematical Reasoning in LLMs", "comment": "8 pages, and 3 figures", "summary": "Recent large language models (LLMs) achieve near-saturation accuracy on many established mathematical reasoning benchmarks, raising concerns about their ability to diagnose genuine reasoning competence. This saturation largely stems from the dominance of template-based computation and shallow arithmetic decomposition in existing datasets, which underrepresent reasoning skills such as multi-constraint coordination, constructive logical synthesis, and spatial inference. To address this gap, we introduce ReasoningMath-Plus, a benchmark of 150 carefully curated problems explicitly designed to evaluate structural reasoning. Each problem emphasizes reasoning under interacting constraints, constructive solution formation, or non-trivial structural insight, and is annotated with a minimal reasoning skeleton to support fine-grained process-level evaluation. Alongside the dataset, we introduce HCRS (Hazard-aware Chain-based Rule Score), a deterministic step-level scoring function, and train a Process Reward Model (PRM) on the annotated reasoning traces. Empirically, while leading models attain relatively high final-answer accuracy (up to 5.8/10), HCRS-based holistic evaluation yields substantially lower scores (average 4.36/10, best 5.14/10), showing that answer-only metrics can overestimate reasoning robustness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u73b0\u6709\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u9971\u548c\u95ee\u9898\uff0c\u63d0\u51fa\u4e86ReasoningMath-Plus\u57fa\u51c6\u6d4b\u8bd5\u548cHCRS\u8bc4\u5206\u65b9\u6cd5\uff0c\u63ed\u793a\u4ec5\u51ed\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u7387\u4f1a\u9ad8\u4f30\u6a21\u578b\u7684\u5b9e\u9645\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u63a5\u8fd1\u9971\u548c\u51c6\u786e\u7387\uff0c\u4f46\u8fd9\u4e3b\u8981\u6e90\u4e8e\u6570\u636e\u96c6\u4e2d\u7684\u6a21\u677f\u5316\u8ba1\u7b97\u548c\u6d45\u5c42\u7b97\u672f\u5206\u89e3\uff0c\u672a\u80fd\u771f\u6b63\u8bc4\u4f30\u591a\u7ea6\u675f\u534f\u8c03\u3001\u6784\u9020\u6027\u903b\u8f91\u5408\u6210\u548c\u7a7a\u95f4\u63a8\u7406\u7b49\u6838\u5fc3\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86ReasoningMath-Plus\u57fa\u51c6\u6d4b\u8bd5\uff08150\u4e2a\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u95ee\u9898\uff09\uff0c\u5f3a\u8c03\u4ea4\u4e92\u7ea6\u675f\u4e0b\u7684\u63a8\u7406\u3001\u6784\u9020\u6027\u89e3\u5f62\u6210\u548c\u975e\u5e73\u51e1\u7ed3\u6784\u6d1e\u5bdf\uff1b\u5f15\u5165HCRS\uff08\u5371\u9669\u611f\u77e5\u94fe\u5f0f\u89c4\u5219\u8bc4\u5206\uff09\u4f5c\u4e3a\u786e\u5b9a\u6027\u6b65\u9aa4\u7ea7\u8bc4\u5206\u51fd\u6570\uff1b\u8bad\u7ec3\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRM\uff09\u5bf9\u6807\u6ce8\u7684\u63a8\u7406\u8f68\u8ff9\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u9886\u5148\u6a21\u578b\u5728\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u7387\u4e0a\u53ef\u8fbe5.8/10\uff0c\u4f46\u57fa\u4e8eHCRS\u7684\u6574\u4f53\u8bc4\u4f30\u5f97\u5206\u663e\u8457\u8f83\u4f4e\uff08\u5e73\u57474.36/10\uff0c\u6700\u4f735.14/10\uff09\uff0c\u8868\u660e\u4ec5\u51ed\u7b54\u6848\u6307\u6807\u4f1a\u9ad8\u4f30\u63a8\u7406\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u9700\u8981\u8d85\u8d8a\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u7387\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u771f\u6b63\u8861\u91cf\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0cReasoningMath-Plus\u57fa\u51c6\u6d4b\u8bd5\u548cHCRS\u8bc4\u5206\u65b9\u6cd5\u4e3a\u7ec6\u7c92\u5ea6\u8fc7\u7a0b\u7ea7\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.00574", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00574", "abs": "https://arxiv.org/abs/2602.00574", "authors": ["Yifei Shao", "Kun Zhou", "Ziming Xu", "Mohammad Atif Quamar", "Shibo Hao", "Zhen Wang", "Zhiting Hu", "Biwei Huang"], "title": "Learning Modal-Mixed Chain-of-Thought Reasoning with Latent Embeddings", "comment": null, "summary": "We study how to extend chain-of-thought (CoT) beyond language to better handle multimodal reasoning. While CoT helps LLMs and VLMs articulate intermediate steps, its text-only form often fails on vision-intensive problems where key intermediate states are inherently visual. We introduce modal-mixed CoT, which interleaves textual tokens with compact visual sketches represented as latent embeddings. To bridge the modality gap without eroding the original knowledge and capability of the VLM, we use the VLM itself as an encoder and train the language backbone to reconstruct its own intermediate vision embeddings, to guarantee the semantic alignment of the visual latent space. We further attach a diffusion-based latent decoder, invoked by a special control token and conditioned on hidden states from the VLM. In this way, the diffusion head carries fine-grained perceptual details while the VLM specifies high-level intent, which cleanly disentangles roles and reduces the optimization pressure of the VLM. Training proceeds in two stages: supervised fine-tuning on traces that interleave text and latents with a joint next-token and latent-reconstruction objective, followed by reinforcement learning that teaches when to switch modalities and how to compose long reasoning chains. Extensive experiments across 11 diverse multimodal reasoning tasks, demonstrate that our method yields better performance than language-only and other CoT methods. Our code will be publicly released.", "AI": {"tldr": "\u63d0\u51famodal-mixed CoT\u65b9\u6cd5\uff0c\u5728\u601d\u7ef4\u94fe\u4e2d\u4ea4\u66ff\u4f7f\u7528\u6587\u672c\u6807\u8bb0\u548c\u89c6\u89c9\u8349\u56fe\u6f5c\u5728\u5d4c\u5165\uff0c\u4ee5\u89e3\u51b3\u7eaf\u6587\u672cCoT\u5728\u89c6\u89c9\u5bc6\u96c6\u578b\u95ee\u9898\u4e0a\u7684\u5c40\u9650\u6027", "motivation": "\u4f20\u7edf\u7eaf\u6587\u672c\u601d\u7ef4\u94fe\u5728\u5904\u7406\u89c6\u89c9\u5bc6\u96c6\u578b\u95ee\u9898\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u4e3a\u5173\u952e\u4e2d\u95f4\u72b6\u6001\u672c\u8d28\u4e0a\u662f\u89c6\u89c9\u7684\uff0c\u9700\u8981\u5c06CoT\u6269\u5c55\u5230\u591a\u6a21\u6001\u9886\u57df", "method": "1) \u4f7f\u7528VLM\u81ea\u8eab\u4f5c\u4e3a\u7f16\u7801\u5668\uff0c\u8bad\u7ec3\u8bed\u8a00\u4e3b\u5e72\u91cd\u5efa\u5176\u89c6\u89c9\u5d4c\u5165\u4ee5\u4fdd\u8bc1\u8bed\u4e49\u5bf9\u9f50\uff1b2) \u9644\u52a0\u57fa\u4e8e\u6269\u6563\u7684\u6f5c\u5728\u89e3\u7801\u5668\uff0c\u7531\u7279\u6b8a\u63a7\u5236\u4ee4\u724c\u8c03\u7528\uff1b3) \u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u76d1\u7763\u5fae\u8c03+\u5f3a\u5316\u5b66\u4e60", "result": "\u572811\u4e2a\u591a\u6837\u5316\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u7eaf\u6587\u672c\u548c\u5176\u4ed6CoT\u65b9\u6cd5\u8868\u73b0\u66f4\u597d", "conclusion": "modal-mixed CoT\u901a\u8fc7\u89c6\u89c9-\u6587\u672c\u4ea4\u66ff\u7684\u601d\u7ef4\u94fe\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\uff0c\u6269\u6563\u5934\u8d1f\u8d23\u611f\u77e5\u7ec6\u8282\u800cVLM\u6307\u5b9a\u9ad8\u5c42\u610f\u56fe\uff0c\u5b9e\u73b0\u4e86\u89d2\u8272\u89e3\u8026"}}
{"id": "2602.01341", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.01341", "abs": "https://arxiv.org/abs/2602.01341", "authors": ["Pedro Campon\u00eas", "Hugo Pereira", "Adrian Persaud", "Kevin Gallagher", "Santiago Torres-Arias"], "title": "Privocracy: Online Democracy through Private Voting", "comment": null, "summary": "In traditional access control policies, every access granted and administrative account introduces an additional vulnerability, as a corruption of a high-privilege user can compromise several sensitive files. Privocracy is an access control mechanism that minimizes the need to attribute high privileges by triggering a secure e-voting procedure to run commands that require using sensitive resources. With Privocracy an organization can distribute trust in resource access, minimizing the system vulnerabilities from single points of failure, all while maintaining the high flexibility of discretionary access control policies.\n  The Privocracy voting mechanism achieves everlasting privacy, ensuring votes remain confidential regardless of an adversary's computational power, while addressing the dependability requirements of a practical and secure system. The procedure incorporates useful features such as vote delegation to reduce voter fatigue, rapid voting rounds to enable quick action during emergencies, and selective vote auditing for application-level accountability. Our experimental results demonstrate that Privocracy processes votes efficiently and can be deployed on commodity hardware.", "AI": {"tldr": "Privocracy\u662f\u4e00\u79cd\u8bbf\u95ee\u63a7\u5236\u673a\u5236\uff0c\u901a\u8fc7\u5b89\u5168\u7535\u5b50\u6295\u7968\u6765\u6267\u884c\u9700\u8981\u654f\u611f\u8d44\u6e90\u7684\u547d\u4ee4\uff0c\u51cf\u5c11\u9ad8\u6743\u9650\u5206\u914d\uff0c\u5206\u6563\u4fe1\u4efb\uff0c\u907f\u514d\u5355\u70b9\u6545\u969c\uff0c\u540c\u65f6\u4fdd\u6301\u8bbf\u95ee\u63a7\u5236\u7684\u7075\u6d3b\u6027\u3002", "motivation": "\u4f20\u7edf\u8bbf\u95ee\u63a7\u5236\u4e2d\uff0c\u6bcf\u4e2a\u88ab\u6388\u4e88\u7684\u8bbf\u95ee\u6743\u9650\u548c\u7ba1\u7406\u8d26\u6237\u90fd\u4f1a\u5f15\u5165\u989d\u5916\u6f0f\u6d1e\uff0c\u9ad8\u6743\u9650\u7528\u6237\u7684\u8150\u8d25\u53ef\u80fd\u5371\u53ca\u591a\u4e2a\u654f\u611f\u6587\u4ef6\u3002\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u6700\u5c0f\u5316\u9ad8\u6743\u9650\u5206\u914d\uff0c\u5206\u6563\u7cfb\u7edf\u4fe1\u4efb\u3002", "method": "Privocracy\u91c7\u7528\u5b89\u5168\u7535\u5b50\u6295\u7968\u673a\u5236\u6765\u8fd0\u884c\u9700\u8981\u654f\u611f\u8d44\u6e90\u7684\u547d\u4ee4\uff0c\u5b9e\u73b0\u6c38\u6052\u9690\u79c1\u4fdd\u62a4\uff08\u65e0\u8bba\u5bf9\u624b\u8ba1\u7b97\u80fd\u529b\u5982\u4f55\uff0c\u6295\u7968\u90fd\u4fdd\u6301\u673a\u5bc6\uff09\uff0c\u5e76\u5305\u542b\u6295\u7968\u59d4\u6258\u3001\u5feb\u901f\u6295\u7968\u8f6e\u6b21\u548c\u9009\u62e9\u6027\u6295\u7968\u5ba1\u8ba1\u7b49\u5b9e\u7528\u529f\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPrivocracy\u80fd\u591f\u9ad8\u6548\u5904\u7406\u6295\u7968\uff0c\u53ef\u4ee5\u5728\u5546\u7528\u786c\u4ef6\u4e0a\u90e8\u7f72\u3002\u8be5\u673a\u5236\u6ee1\u8db3\u4e86\u5b9e\u7528\u5b89\u5168\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u8981\u6c42\u3002", "conclusion": "Privocracy\u901a\u8fc7\u7535\u5b50\u6295\u7968\u673a\u5236\u6700\u5c0f\u5316\u9ad8\u6743\u9650\u5206\u914d\uff0c\u5206\u6563\u7cfb\u7edf\u4fe1\u4efb\uff0c\u51cf\u5c11\u5355\u70b9\u6545\u969c\u6f0f\u6d1e\uff0c\u540c\u65f6\u4fdd\u6301\u8bbf\u95ee\u63a7\u5236\u7684\u7075\u6d3b\u6027\uff0c\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5b89\u5168\u7684\u8bbf\u95ee\u63a7\u5236\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01342", "categories": ["cs.CR", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.01342", "abs": "https://arxiv.org/abs/2602.01342", "authors": ["Poushali Sengupta", "Mayank Raikwar", "Sabita Maharjan", "Frank Eliassen", "Yan Zhang"], "title": "Adaptive Quantum-Safe Cryptography for 6G Vehicular Networks via Context-Aware Optimization", "comment": "Accepted for presentation at NDSS 2026 - FutureG Workshop, 23 February 2026. (10 pages, 5 figures.)", "summary": "Powerful quantum computers in the future may be able to break the security used for communication between vehicles and other devices (Vehicle-to-Everything, or V2X). New security methods called post-quantum cryptography can help protect these systems, but they often require more computing power and can slow down communication, posing a challenge for fast 6G vehicle networks. In this paper, we propose an adaptive post-quantum cryptography (PQC) framework that predicts short-term mobility and channel variations and dynamically selects suitable lattice-, code-, or hash-based PQC configurations using a predictive multi-objective evolutionary algorithm (APMOEA) to meet vehicular latency and security constraints.However, frequent cryptographic reconfiguration in dynamic vehicular environments introduces new attack surfaces during algorithm transitions. A secure monotonic-upgrade protocol prevents downgrade, replay, and desynchronization attacks during transitions. Theoretical results show decision stability under bounded prediction error, latency boundedness under mobility drift, and correctness under small forecast noise. These results demonstrate a practical path toward quantum-safe cryptography in future 6G vehicular networks. Through extensive experiments based on realistic mobility (LuST), weather (ERA5), and NR-V2X channel traces, we show that the proposed framework reduces end-to-end latency by up to 27\\%, lowers communication overhead by up to 65\\%, and effectively stabilizes cryptographic switching behavior using reinforcement learning. Moreover, under the evaluated adversarial scenarios, the monotonic-upgrade protocol successfully prevents downgrade, replay, and desynchronization attacks.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u540e\u91cf\u5b50\u5bc6\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u79fb\u52a8\u6027\u548c\u4fe1\u9053\u53d8\u5316\uff0c\u52a8\u6001\u9009\u62e9\u9002\u5408\u7684\u5bc6\u7801\u914d\u7f6e\uff0c\u964d\u4f4e6G\u8f66\u8054\u7f51\u5ef6\u8fdf\u548c\u901a\u4fe1\u5f00\u9500\uff0c\u540c\u65f6\u9632\u6b62\u7b97\u6cd5\u5207\u6362\u65f6\u7684\u5b89\u5168\u653b\u51fb\u3002", "motivation": "\u672a\u6765\u91cf\u5b50\u8ba1\u7b97\u673a\u53ef\u80fd\u7834\u89e3\u73b0\u6709\u8f66\u8054\u7f51\u5b89\u5168\u673a\u5236\uff0c\u800c\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u867d\u7136\u80fd\u63d0\u4f9b\u4fdd\u62a4\uff0c\u4f46\u901a\u5e38\u9700\u8981\u66f4\u591a\u8ba1\u7b97\u8d44\u6e90\uff0c\u4f1a\u51cf\u6162\u901a\u4fe1\u901f\u5ea6\uff0c\u8fd9\u5bf9\u9700\u8981\u4f4e\u5ef6\u8fdf\u76846G\u8f66\u8054\u7f51\u6784\u6210\u6311\u6218\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u540e\u91cf\u5b50\u5bc6\u7801\u6846\u67b6\uff0c\u9884\u6d4b\u77ed\u671f\u79fb\u52a8\u6027\u548c\u4fe1\u9053\u53d8\u5316\uff0c\u4f7f\u7528\u9884\u6d4b\u6027\u591a\u76ee\u6807\u8fdb\u5316\u7b97\u6cd5\u52a8\u6001\u9009\u62e9\u57fa\u4e8e\u683c\u3001\u4ee3\u7801\u6216\u54c8\u5e0c\u7684\u5bc6\u7801\u914d\u7f6e\uff0c\u5e76\u8bbe\u8ba1\u5b89\u5168\u5355\u8c03\u5347\u7ea7\u534f\u8bae\u9632\u6b62\u7b97\u6cd5\u5207\u6362\u65f6\u7684\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u6846\u67b6\u80fd\u964d\u4f4e\u7aef\u5230\u7aef\u5ef6\u8fdf\u8fbe27%\uff0c\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u8fbe65%\uff0c\u6709\u6548\u7a33\u5b9a\u5bc6\u7801\u5207\u6362\u884c\u4e3a\uff0c\u5e76\u5728\u5bf9\u6297\u573a\u666f\u4e0b\u6210\u529f\u9632\u6b62\u964d\u7ea7\u3001\u91cd\u653e\u548c\u5931\u6b65\u653b\u51fb\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u672a\u67656G\u8f66\u8054\u7f51\u5b9e\u73b0\u91cf\u5b50\u5b89\u5168\u5bc6\u7801\u5b66\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6846\u67b6\u5e73\u8861\u5b89\u5168\u6027\u548c\u6027\u80fd\u9700\u6c42\u3002"}}
{"id": "2602.01438", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01438", "abs": "https://arxiv.org/abs/2602.01438", "authors": ["Max Manolov", "Tony Gao", "Siddharth Shukla", "Cheng-Ting Chou", "Ryan Lagasse"], "title": "CIPHER: Cryptographic Insecurity Profiling via Hybrid Evaluation of Responses", "comment": null, "summary": "Large language models (LLMs) are increasingly used to assist developers with code, yet their implementations of cryptographic functionality often contain exploitable flaws. Minor design choices (e.g., static initialization vectors or missing authentication) can silently invalidate security guarantees. We introduce CIPHER(\\textbf{C}ryptographic \\textbf{I}nsecurity \\textbf{P}rofiling via \\textbf{H}ybrid \\textbf{E}valuation of \\textbf{R}esponses), a benchmark for measuring cryptographic vulnerability incidence in LLM-generated Python code under controlled security-guidance conditions. CIPHER uses insecure/neutral/secure prompt variants per task, a cryptography-specific vulnerability taxonomy, and line-level attribution via an automated scoring pipeline. Across a diverse set of widely used LLMs, we find that explicit ``secure'' prompting reduces some targeted issues but does not reliably eliminate cryptographic vulnerabilities overall. The benchmark and reproducible scoring pipeline will be publicly released upon publication.", "AI": {"tldr": "CIPHER\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u751f\u6210Python\u4ee3\u7801\u4e2d\u52a0\u5bc6\u6f0f\u6d1e\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u4e0d\u540c\u5b89\u5168\u63d0\u793a\u53d8\u4f53\u6d4b\u91cf\u6f0f\u6d1e\u53d1\u751f\u7387\uff0c\u53d1\u73b0\u660e\u786e\u7684\u5b89\u5168\u63d0\u793a\u80fd\u51cf\u5c11\u67d0\u4e9b\u95ee\u9898\u4f46\u4e0d\u80fd\u53ef\u9760\u6d88\u9664\u6240\u6709\u52a0\u5bc6\u6f0f\u6d1e\u3002", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u8f85\u52a9\u5f00\u53d1\u4eba\u5458\u7f16\u5199\u4ee3\u7801\uff0c\u4f46\u5176\u751f\u6210\u7684\u52a0\u5bc6\u529f\u80fd\u5b9e\u73b0\u7ecf\u5e38\u5305\u542b\u53ef\u5229\u7528\u7684\u7f3a\u9677\u3002\u5fae\u5c0f\u7684\u8bbe\u8ba1\u9009\u62e9\uff08\u5982\u9759\u6001\u521d\u59cb\u5316\u5411\u91cf\u6216\u7f3a\u5c11\u8ba4\u8bc1\uff09\u53ef\u80fd\u65e0\u58f0\u5730\u7834\u574f\u5b89\u5168\u4fdd\u8bc1\u3002", "method": "\u5f15\u5165CIPHER\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528\u4e0d\u5b89\u5168/\u4e2d\u6027/\u5b89\u5168\u63d0\u793a\u53d8\u4f53\uff0c\u57fa\u4e8e\u52a0\u5bc6\u7279\u5b9a\u6f0f\u6d1e\u5206\u7c7b\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u8bc4\u5206\u7ba1\u9053\u8fdb\u884c\u884c\u7ea7\u5f52\u56e0\uff0c\u6d4b\u91cfLLM\u751f\u6210Python\u4ee3\u7801\u4e2d\u7684\u52a0\u5bc6\u6f0f\u6d1e\u53d1\u751f\u7387\u3002", "result": "\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684LLM\u96c6\u5408\u4e2d\uff0c\u660e\u786e\u7684\"\u5b89\u5168\"\u63d0\u793a\u80fd\u51cf\u5c11\u67d0\u4e9b\u76ee\u6807\u95ee\u9898\uff0c\u4f46\u4e0d\u80fd\u53ef\u9760\u5730\u6d88\u9664\u6574\u4f53\u52a0\u5bc6\u6f0f\u6d1e\u3002", "conclusion": "\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u786e\u4fddLLM\u751f\u6210\u7684\u52a0\u5bc6\u4ee3\u7801\u7684\u5b89\u5168\u6027\uff0c\u57fa\u51c6\u6d4b\u8bd5\u548c\u53ef\u590d\u73b0\u7684\u8bc4\u5206\u7ba1\u9053\u5c06\u5728\u53d1\u8868\u65f6\u516c\u5f00\u3002"}}
{"id": "2602.00608", "categories": ["cs.AI", "cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00608", "abs": "https://arxiv.org/abs/2602.00608", "authors": ["Wei Zeng", "Xuchen Li", "Ruili Feng", "Zhen Liu", "Fengwei An", "Jian Zhao"], "title": "Scalable Generative Game Engine: Breaking the Resolution Wall via Hardware-Algorithm Co-Design", "comment": "Preprint, Under Review", "summary": "Real-time generative game engines represent a paradigm shift in interactive simulation, promising to replace traditional graphics pipelines with neural world models. However, existing approaches are fundamentally constrained by the ``Memory Wall,'' restricting practical deployments to low resolutions (e.g., $64 \\times 64$). This paper bridges the gap between generative models and high-resolution neural simulations by introducing a scalable \\textit{Hardware-Algorithm Co-Design} framework. We identify that high-resolution generation suffers from a critical resource mismatch: the World Model is compute-bound while the Decoder is memory-bound. To address this, we propose a heterogeneous architecture that intelligently decouples these components across a cluster of AI accelerators. Our system features three core innovations: (1) an asymmetric resource allocation strategy that optimizes throughput under sequence parallelism constraints; (2) a memory-centric operator fusion scheme that minimizes off-chip bandwidth usage; and (3) a manifold-aware latent extrapolation mechanism that exploits temporal redundancy to mask latency. We validate our approach on a cluster of programmable AI accelerators, enabling real-time generation at $720 \\times 480$ resolution -- a $50\\times$ increase in pixel throughput over prior baselines. Evaluated on both continuous 3D racing and discrete 2D platformer benchmarks, our system delivers fluid 26.4 FPS and 48.3 FPS respectively, with an amortized effective latency of 2.7 ms. This work demonstrates that resolving the ``Memory Wall'' via architectural co-design is not merely an optimization, but a prerequisite for enabling high-fidelity, responsive neural gameplay.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u786c\u4ef6\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5f02\u6784\u67b6\u6784\u89e3\u51b3\u751f\u6210\u5f0f\u6e38\u620f\u5f15\u64ce\u4e2d\u7684\"\u5185\u5b58\u5899\"\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86720\u00d7480\u5206\u8fa8\u7387\u4e0b\u7684\u5b9e\u65f6\u751f\u6210\uff0c\u76f8\u6bd4\u57fa\u7ebf\u63d0\u5347\u4e8650\u500d\u7684\u50cf\u7d20\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709\u5b9e\u65f6\u751f\u6210\u5f0f\u6e38\u620f\u5f15\u64ce\u53d7\u9650\u4e8e\"\u5185\u5b58\u5899\"\uff0c\u53ea\u80fd\u5728\u4f4e\u5206\u8fa8\u7387\uff08\u598264\u00d764\uff09\u4e0b\u8fd0\u884c\uff0c\u65e0\u6cd5\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u795e\u7ecf\u6a21\u62df\u3002\u8bba\u6587\u65e8\u5728\u5f25\u5408\u751f\u6210\u6a21\u578b\u4e0e\u9ad8\u5206\u8fa8\u7387\u795e\u7ecf\u6a21\u62df\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86\u786c\u4ef6\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u521b\u65b0\uff1a1\uff09\u5728\u5e8f\u5217\u5e76\u884c\u7ea6\u675f\u4e0b\u4f18\u5316\u541e\u5410\u91cf\u7684\u975e\u5bf9\u79f0\u8d44\u6e90\u5206\u914d\u7b56\u7565\uff1b2\uff09\u6700\u5c0f\u5316\u7247\u5916\u5e26\u5bbd\u4f7f\u7528\u7684\u5185\u5b58\u4e2d\u5fc3\u7b97\u5b50\u878d\u5408\u65b9\u6848\uff1b3\uff09\u5229\u7528\u65f6\u95f4\u5197\u4f59\u63a9\u76d6\u5ef6\u8fdf\u7684\u6d41\u5f62\u611f\u77e5\u6f5c\u5728\u5916\u63a8\u673a\u5236\u3002", "result": "\u5728\u53ef\u7f16\u7a0bAI\u52a0\u901f\u5668\u96c6\u7fa4\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86720\u00d7480\u5206\u8fa8\u7387\u7684\u5b9e\u65f6\u751f\u6210\uff0c\u76f8\u6bd4\u5148\u524d\u57fa\u7ebf\u63d0\u5347\u4e8650\u500d\u50cf\u7d20\u541e\u5410\u91cf\u3002\u5728\u8fde\u7eed3D\u8d5b\u8f66\u548c\u79bb\u65632D\u5e73\u53f0\u6e38\u620f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5206\u522b\u8fbe\u523026.4 FPS\u548c48.3 FPS\uff0c\u644a\u9500\u6709\u6548\u5ef6\u8fdf\u4e3a2.7\u6beb\u79d2\u3002", "conclusion": "\u901a\u8fc7\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\u89e3\u51b3\"\u5185\u5b58\u5899\"\u95ee\u9898\u4e0d\u4ec5\u662f\u4f18\u5316\uff0c\u66f4\u662f\u5b9e\u73b0\u9ad8\u4fdd\u771f\u3001\u54cd\u5e94\u5f0f\u795e\u7ecf\u6e38\u620f\u4f53\u9a8c\u7684\u5148\u51b3\u6761\u4ef6\u3002\u8be5\u5de5\u4f5c\u4e3a\u9ad8\u5206\u8fa8\u7387\u795e\u7ecf\u6a21\u62df\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2602.01489", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01489", "abs": "https://arxiv.org/abs/2602.01489", "authors": ["Renascence Tarafder Prapty", "Gene Tsudik"], "title": "DuoLungo: Usability Study of Duo 2FA", "comment": null, "summary": "Multi-Factor Authentication (MFA) enhances login security by requiring multiple authentication factors. Its adoption has increased in response to more frequent and sophisticated attacks. Duo is widely used by organizations including Fortune 500 companies and major educational institutions, yet its usability has not been examined thoroughly or recently. Earlier studies focused on technical challenges during initial deployment but did not measure core usability metrics such as task completion time or System Usability Scale (SUS) scores. These results are also outdated, originating from a time when MFA was less familiar to typical users.\n  We conducted a long-term, large-scale Duo usability study at the University of California Irvine during the 2024-2025 academic year, involving 2559 participants. Our analysis uses authentication log data and a survey of 57 randomly selected users. The average overhead of a Duo Push task is nearly 8 seconds, which participants described as short to moderate. Overhead varies with time of day, field of study, and education level. The rate of authentication failures due to incomplete Duo tasks is 4.35 percent, and 43.86 percent of survey respondents reported at least one Duo login failure. The Duo SUS score is 70, indicating good usability. Participants generally find Duo easy to use but somewhat annoying, while also reporting an increased sense of account security. They also described common issues and offered suggestions for improvement.", "AI": {"tldr": "\u5bf9Duo MFA\u7cfb\u7edf\u8fdb\u884c\u7684\u5927\u89c4\u6a21\u53ef\u7528\u6027\u7814\u7a76\uff0c\u53d1\u73b0\u5e73\u5747\u9a8c\u8bc1\u8017\u65f6\u7ea68\u79d2\uff0c\u5931\u8d25\u73874.35%\uff0cSUS\u5f97\u520670\u8868\u660e\u826f\u597d\u53ef\u7528\u6027\uff0c\u7528\u6237\u8ba4\u4e3a\u6613\u7528\u4f46\u6709\u4e9b\u70e6\u4eba\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u5b89\u5168\u611f\u3002", "motivation": "Duo\u4f5c\u4e3a\u5e7f\u6cdb\u4f7f\u7528\u7684\u591a\u56e0\u7d20\u8ba4\u8bc1\u7cfb\u7edf\uff0c\u867d\u7136\u88ab\u4f17\u591a\u5927\u578b\u7ec4\u7ec7\u548c\u6559\u80b2\u673a\u6784\u91c7\u7528\uff0c\u4f46\u5176\u53ef\u7528\u6027\u7f3a\u4e4f\u5168\u9762\u548c\u6700\u65b0\u7684\u7814\u7a76\u3002\u5148\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6280\u672f\u90e8\u7f72\u6311\u6218\uff0c\u672a\u6d4b\u91cf\u6838\u5fc3\u53ef\u7528\u6027\u6307\u6807\u5982\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u6216SUS\u5206\u6570\uff0c\u4e14\u8fd9\u4e9b\u7ed3\u679c\u5df2\u8fc7\u65f6\uff0c\u5f53\u65f6\u7528\u6237\u5bf9MFA\u8fd8\u4e0d\u719f\u6089\u3002", "method": "\u5728\u52a0\u5dde\u5927\u5b66\u6b27\u6587\u5206\u6821\u8fdb\u884c\u957f\u671f\u5927\u89c4\u6a21\u7814\u7a76\uff082024-2025\u5b66\u5e74\uff09\uff0c\u6d89\u53ca2559\u540d\u53c2\u4e0e\u8005\u3002\u4f7f\u7528\u8ba4\u8bc1\u65e5\u5fd7\u6570\u636e\u5206\u6790\uff0c\u5e76\u5bf957\u540d\u968f\u673a\u9009\u62e9\u7684\u7528\u6237\u8fdb\u884c\u95ee\u5377\u8c03\u67e5\u3002", "result": "Duo Push\u4efb\u52a1\u5e73\u5747\u8017\u65f6\u8fd18\u79d2\uff0c\u53c2\u4e0e\u8005\u63cf\u8ff0\u4e3a\u77ed\u5230\u4e2d\u7b49\u3002\u8017\u65f6\u53d7\u65f6\u95f4\u3001\u4e13\u4e1a\u9886\u57df\u548c\u6559\u80b2\u6c34\u5e73\u5f71\u54cd\u3002\u8ba4\u8bc1\u5931\u8d25\u73874.35%\uff0c43.86%\u53d7\u8bbf\u8005\u62a5\u544a\u81f3\u5c11\u4e00\u6b21\u767b\u5f55\u5931\u8d25\u3002Duo\u7684SUS\u5f97\u5206\u4e3a70\uff0c\u8868\u660e\u826f\u597d\u53ef\u7528\u6027\u3002\u7528\u6237\u666e\u904d\u8ba4\u4e3a\u6613\u7528\u4f46\u6709\u4e9b\u70e6\u4eba\uff0c\u540c\u65f6\u62a5\u544a\u589e\u5f3a\u4e86\u8d26\u6237\u5b89\u5168\u611f\u3002", "conclusion": "Duo MFA\u7cfb\u7edf\u5177\u6709\u826f\u597d\u7684\u53ef\u7528\u6027\uff08SUS 70\uff09\uff0c\u867d\u7136\u5b58\u5728\u4e00\u5b9a\u5931\u8d25\u7387\u548c\u7528\u6237\u70e6\u607c\u611f\uff0c\u4f46\u603b\u4f53\u4e0a\u7528\u6237\u8ba4\u4e3a\u6613\u7528\u4e14\u589e\u5f3a\u4e86\u5b89\u5168\u6027\u3002\u7814\u7a76\u8fd8\u8bc6\u522b\u4e86\u5e38\u89c1\u95ee\u9898\u548c\u6539\u8fdb\u5efa\u8bae\uff0c\u4e3aMFA\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u3002"}}
{"id": "2602.00611", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00611", "abs": "https://arxiv.org/abs/2602.00611", "authors": ["Jiaqi Xu", "Tao Huang", "Kai Zhang"], "title": "Structured Self-Consistency:A Multi-Task Evaluation of LLMs on VirtualHome", "comment": null, "summary": "Embodied AI requires agents to understand goals, plan actions, and execute tasks in simulated environments. We present a comprehensive evaluation of Large Language Models (LLMs) on the VirtualHome benchmark using the Embodied Agent Interface (EAI) framework. We compare two representative 7B-parameter models OPENPANGU-7B and QWEN2.5-7B across four fundamental tasks: Goal Interpretation, Action Sequencing, Subgoal Decomposition, and Transition Modeling. We propose Structured Self-Consistency (SSC), an enhanced decoding strategy that leverages multiple sampling with domain-specific voting mechanisms to improve output quality for structured generation tasks. Experimental results demonstrate that SSC significantly enhances performance, with OPENPANGU-7B excelling at hierarchical planning while QWEN2.5-7B show advantages in action-level tasks. Our analysis reveals complementary strengths across model types, providing insights for future embodied AI system development.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7VirtualHome\u57fa\u51c6\u548cEAI\u6846\u67b6\uff0c\u8bc4\u4f30\u4e86OPENPANGU-7B\u548cQWEN2.5-7B\u4e24\u4e2a7B\u53c2\u6570\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5177\u8eabAI\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u81ea\u6d3d\u89e3\u7801\u7b56\u7565\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5177\u8eabAI\u9700\u8981\u667a\u80fd\u4f53\u7406\u89e3\u76ee\u6807\u3001\u89c4\u5212\u52a8\u4f5c\u5e76\u5728\u6a21\u62df\u73af\u5883\u4e2d\u6267\u884c\u4efb\u52a1\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5177\u8eabAI\u4efb\u52a1\u4e0a\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4e0d\u540c\u6a21\u578b\u5728\u591a\u5c42\u6b21\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u6bd4\u8f83\u3002", "method": "\u4f7f\u7528VirtualHome\u57fa\u51c6\u548cEmbodied Agent Interface\u6846\u67b6\uff0c\u8bc4\u4f30\u4e24\u4e2a7B\u53c2\u6570\u6a21\u578b\u5728\u56db\u4e2a\u57fa\u672c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff1a\u76ee\u6807\u89e3\u91ca\u3001\u52a8\u4f5c\u5e8f\u5217\u3001\u5b50\u76ee\u6807\u5206\u89e3\u548c\u72b6\u6001\u8f6c\u79fb\u5efa\u6a21\u3002\u63d0\u51fa\u7ed3\u6784\u5316\u81ea\u6d3d\u89e3\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u591a\u6b21\u91c7\u6837\u548c\u9886\u57df\u7279\u5b9a\u6295\u7968\u673a\u5236\u63d0\u5347\u7ed3\u6784\u5316\u751f\u6210\u4efb\u52a1\u7684\u8d28\u91cf\u3002", "result": "\u7ed3\u6784\u5316\u81ea\u6d3d\u89e3\u7801\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002OPENPANGU-7B\u5728\u5c42\u6b21\u5316\u89c4\u5212\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u800cQWEN2.5-7B\u5728\u52a8\u4f5c\u7ea7\u4efb\u52a1\u4e0a\u5177\u6709\u4f18\u52bf\u3002\u5b9e\u9a8c\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u7c7b\u578b\u7684\u4e92\u8865\u4f18\u52bf\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765\u5177\u8eabAI\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u8868\u660e\u4e0d\u540c\u6a21\u578b\u5728\u5177\u8eabAI\u4efb\u52a1\u4e0a\u5177\u6709\u4e92\u8865\u4f18\u52bf\uff0c\u7ed3\u6784\u5316\u81ea\u6d3d\u89e3\u7801\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u7684\u5177\u8eab\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.01491", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01491", "abs": "https://arxiv.org/abs/2602.01491", "authors": ["Sahan Sanjaya", "Prabhat Mishra"], "title": "Sleep Reveals the Nonce: Breaking ECDSA using Sleep-Based Power Side-Channel Vulnerability", "comment": null, "summary": "Security of Elliptic Curve Digital Signature Algorithm (ECDSA) depends on the secrecy of the per-signature nonce. Even partial nonce leakage can expose the long-term private key through lattice-based cryptanalysis. In this paper, we introduce a previously unexplored power side-channel vulnerability that exploits sleep-induced power spikes to extract ECDSA nonces. Unlike conventional power-based side-channel attacks, this vulnerability leverages power fluctuations generated during processor context switches invoked by sleep functions. These fluctuations correlate with nonce-dependent operations in scalar multiplication, enabling nonce recovery even under constant-time and masked implementations. We evaluate the attack across multiple cryptographic libraries, RustCrypto, BearSSL, and GoCrypto, and processor architectures, including ARM and RISC-V. Our experiments show that subtle variations in the power envelope during sleep-induced context switches provide sufficient leakage for practical ECDSA nonce extraction, recovering 20 bits of the nonce. These results establish sleep-induced power spikes as a practical cross-platform side-channel threat and highlight the need to reconsider design choices in cryptographic systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u73b0\u4e86\u4e00\u79cd\u5229\u7528\u7761\u7720\u51fd\u6570\u5f15\u8d77\u7684\u7535\u6e90\u5c16\u5cf0\u6765\u63d0\u53d6ECDSA\u968f\u673a\u6570\u7684\u65b0\u4fa7\u4fe1\u9053\u653b\u51fb\u65b9\u6cd5\uff0c\u5373\u4f7f\u662f\u5728\u6052\u5b9a\u65f6\u95f4\u548c\u63a9\u7801\u5b9e\u73b0\u4e0b\u4e5f\u80fd\u6062\u590d\u90e8\u5206\u968f\u673a\u6570\u3002", "motivation": "ECDSA\u7684\u5b89\u5168\u6027\u4f9d\u8d56\u4e8e\u6bcf\u4e2a\u7b7e\u540d\u7684\u968f\u673a\u6570\u4fdd\u5bc6\u6027\uff0c\u5373\u4f7f\u90e8\u5206\u968f\u673a\u6570\u6cc4\u9732\u4e5f\u53ef\u80fd\u901a\u8fc7\u57fa\u4e8e\u683c\u5bc6\u7801\u7684\u5206\u6790\u66b4\u9732\u957f\u671f\u79c1\u94a5\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4f20\u7edf\u7535\u6e90\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u4f46\u7761\u7720\u51fd\u6570\u5f15\u8d77\u7684\u5904\u7406\u5668\u4e0a\u4e0b\u6587\u5207\u6362\u4ea7\u751f\u7684\u7535\u6e90\u6ce2\u52a8\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u5229\u7528\u7761\u7720\u51fd\u6570\u8c03\u7528\u65f6\u5904\u7406\u5668\u4e0a\u4e0b\u6587\u5207\u6362\u4ea7\u751f\u7684\u7535\u6e90\u5c16\u5cf0\uff0c\u8fd9\u4e9b\u6ce2\u52a8\u4e0e\u6807\u91cf\u4e58\u6cd5\u4e2d\u4f9d\u8d56\u968f\u673a\u6570\u7684\u64cd\u4f5c\u76f8\u5173\u3002\u653b\u51fb\u65b9\u6cd5\u901a\u8fc7\u5206\u6790\u7761\u7720\u8bf1\u5bfc\u7684\u4e0a\u4e0b\u6587\u5207\u6362\u671f\u95f4\u7684\u7535\u6e90\u5305\u7edc\u53d8\u5316\u6765\u63d0\u53d6ECDSA\u968f\u673a\u6570\u4fe1\u606f\u3002", "result": "\u5728\u591a\u4e2a\u5bc6\u7801\u5e93\uff08RustCrypto\u3001BearSSL\u3001GoCrypto\uff09\u548c\u5904\u7406\u5668\u67b6\u6784\uff08ARM\u3001RISC-V\uff09\u4e0a\u8bc4\u4f30\u653b\u51fb\u6548\u679c\uff0c\u5b9e\u9a8c\u663e\u793a\u7761\u7720\u8bf1\u5bfc\u7684\u4e0a\u4e0b\u6587\u5207\u6362\u671f\u95f4\u7684\u7535\u6e90\u5305\u7edc\u7ec6\u5fae\u53d8\u5316\u63d0\u4f9b\u4e86\u8db3\u591f\u7684\u6cc4\u9732\u4fe1\u606f\uff0c\u80fd\u591f\u6062\u590d20\u4f4d\u968f\u673a\u6570\u3002", "conclusion": "\u7761\u7720\u8bf1\u5bfc\u7684\u7535\u6e90\u5c16\u5cf0\u662f\u4e00\u79cd\u5b9e\u7528\u7684\u8de8\u5e73\u53f0\u4fa7\u4fe1\u9053\u5a01\u80c1\uff0c\u9700\u8981\u91cd\u65b0\u8003\u8651\u5bc6\u7801\u7cfb\u7edf\u7684\u8bbe\u8ba1\u9009\u62e9\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u7761\u7720\u51fd\u6570\u548c\u4e0a\u4e0b\u6587\u5207\u6362\u65f6\u7684\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u3002"}}
{"id": "2602.00751", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00751", "abs": "https://arxiv.org/abs/2602.00751", "authors": ["Cl\u00e1udio L\u00facio do Val Lopes", "Jo\u00e3o Marcus Pitta", "Fabiano Bel\u00e9m", "Gildson Alves", "Fl\u00e1vio Vin\u00edcius Cruzeiro Martins"], "title": "Engineering AI Agents for Clinical Workflows: A Case Study in Architecture,MLOps, and Governance", "comment": "9 pages, 5 figures 2026 IEEE/ACM 5th International Conference on AI Engineering - Software Engineering for AI}{April 12--13, 2026}{Rio de Janeiro, Brazil", "summary": "The integration of Artificial Intelligence (AI) into clinical settings presents a software engineering challenge, demanding a shift from isolated models to robust, governable, and reliable systems. However, brittle, prototype-derived architectures often plague industrial applications and a lack of systemic oversight, creating a ``responsibility vacuum'' where safety and accountability are compromised. This paper presents an industry case study of the ``Maria'' platform, a production-grade AI system in primary healthcare that addresses this gap.\n  Our central hypothesis is that trustworthy clinical AI is achieved through the holistic integration of four foundational engineering pillars. We present a synergistic architecture that combines Clean Architecture for maintainability with an Event-driven architecture for resilience and auditability. We introduce the Agent as the primary unit of modularity, each possessing its own autonomous MLOps lifecycle. Finally, we show how a Human-in-the-Loop governance model is technically integrated not merely as a safety check, but as a critical, event-driven data source for continuous improvement. We present the platform as a reference architecture, offering practical lessons for engineers building maintainable, scalable, and accountable AI-enabled systems in high-stakes domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMaria\u5e73\u53f0\uff0c\u4e00\u4e2a\u7528\u4e8e\u521d\u7ea7\u533b\u7597\u4fdd\u5065\u7684\u751f\u4ea7\u7ea7AI\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u56db\u4e2a\u5de5\u7a0b\u652f\u67f1\u6765\u89e3\u51b3\u4e34\u5e8aAI\u4e2d\u7684\u8d23\u4efb\u771f\u7a7a\u95ee\u9898\u3002", "motivation": "AI\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u96c6\u6210\u9762\u4e34\u8f6f\u4ef6\u5de5\u7a0b\u6311\u6218\uff0c\u539f\u578b\u884d\u751f\u67b6\u6784\u8106\u5f31\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u76d1\u7763\uff0c\u5bfc\u81f4\u5b89\u5168\u6027\u548c\u95ee\u8d23\u5236\u53d7\u635f\u7684\"\u8d23\u4efb\u771f\u7a7a\"\u3002", "method": "\u91c7\u7528\u534f\u540c\u67b6\u6784\uff1aClean Architecture\u4fdd\u8bc1\u53ef\u7ef4\u62a4\u6027\uff0c\u4e8b\u4ef6\u9a71\u52a8\u67b6\u6784\u786e\u4fdd\u5f39\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\uff1b\u4ee5Agent\u4f5c\u4e3a\u4e3b\u8981\u6a21\u5757\u5316\u5355\u5143\uff0c\u6bcf\u4e2a\u62e5\u6709\u81ea\u4e3bMLOps\u751f\u547d\u5468\u671f\uff1b\u5c06\u4eba\u5728\u73af\u6cbb\u7406\u6a21\u578b\u6280\u672f\u96c6\u6210\u4f5c\u4e3a\u5173\u952e\u4e8b\u4ef6\u9a71\u52a8\u6570\u636e\u6e90\u3002", "result": "\u5f00\u53d1\u4e86Maria\u5e73\u53f0\uff0c\u4e00\u4e2a\u751f\u4ea7\u7ea7AI\u7cfb\u7edf\uff0c\u4f5c\u4e3a\u6784\u5efa\u53ef\u7ef4\u62a4\u3001\u53ef\u6269\u5c55\u548c\u53ef\u95ee\u8d23\u7684\u9ad8\u98ce\u9669\u9886\u57dfAI\u7cfb\u7edf\u7684\u53c2\u8003\u67b6\u6784\u3002", "conclusion": "\u53ef\u4fe1\u8d56\u7684\u4e34\u5e8aAI\u9700\u8981\u901a\u8fc7\u56db\u4e2a\u5de5\u7a0b\u652f\u67f1\u7684\u6574\u4f53\u96c6\u6210\u5b9e\u73b0\uff0cMaria\u5e73\u53f0\u4e3a\u9ad8\u98ce\u9669\u9886\u57df\u6784\u5efa\u53ef\u7ef4\u62a4\u3001\u53ef\u6269\u5c55\u548c\u53ef\u95ee\u8d23\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8df5\u7ecf\u9a8c\u548c\u53c2\u8003\u67b6\u6784\u3002"}}
{"id": "2602.00659", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00659", "abs": "https://arxiv.org/abs/2602.00659", "authors": ["Qusai Khaled", "Laura Genga", "Uzay Kaymak"], "title": "Predictive Maintenance for Ultrafiltration Membranes Using Explainable Similarity-Based Prognostics", "comment": "Submitted to 21st International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU2026)", "summary": "In reverse osmosis desalination, ultrafiltration (UF) membranes degrade due to fouling, leading to performance loss and costly downtime. Most plants rely on scheduled preventive maintenance, since existing predictive maintenance models, often based on opaque machine learning methods, lack interpretability and operator trust. This study proposes an explainable prognostic framework for UF membrane remaining useful life (RUL) estimation using fuzzy similarity reasoning. A physics-informed Health Index, derived from transmembrane pressure, flux, and resistance, captures degradation dynamics, which are then fuzzified via Gaussian membership functions. Using a similarity measure, the model identifies historical degradation trajectories resembling the current state and formulates RUL predictions as Takagi-Sugeno fuzzy rules. Each rule corresponds to a historical exemplar and contributes to a transparent, similarity-weighted RUL estimate. Tested on 12,528 operational cycles from an industrial-scale UF system, the framework achieved a mean absolute error of 4.50 cycles, while generating interpretable rule bases consistent with expert understanding.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u7cca\u76f8\u4f3c\u63a8\u7406\u7684\u53ef\u89e3\u91ca\u8d85\u6ee4\u819c\u5269\u4f59\u4f7f\u7528\u5bff\u547d\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u5065\u5eb7\u6307\u6807\u548c\u6a21\u7cca\u89c4\u5219\u5b9e\u73b0\u900f\u660e\u9884\u6d4b", "motivation": "\u53cd\u6e17\u900f\u6d77\u6c34\u6de1\u5316\u4e2d\u8d85\u6ee4\u819c\u56e0\u6c61\u67d3\u800c\u6027\u80fd\u4e0b\u964d\uff0c\u73b0\u6709\u9884\u6d4b\u7ef4\u62a4\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u64cd\u4f5c\u4eba\u5458\u4e0d\u4fe1\u4efb\uff0c\u9700\u8981\u900f\u660e\u53ef\u9760\u7684\u9884\u6d4b\u65b9\u6cd5", "method": "\u4f7f\u7528\u57fa\u4e8e\u8de8\u819c\u538b\u529b\u3001\u901a\u91cf\u548c\u963b\u529b\u7684\u7269\u7406\u4fe1\u606f\u5065\u5eb7\u6307\u6807\uff0c\u901a\u8fc7\u9ad8\u65af\u96b6\u5c5e\u51fd\u6570\u6a21\u7cca\u5316\uff0c\u91c7\u7528\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u8bc6\u522b\u5386\u53f2\u9000\u5316\u8f68\u8ff9\uff0c\u6784\u5efaTakagi-Sugeno\u6a21\u7cca\u89c4\u5219\u8fdb\u884cRUL\u9884\u6d4b", "result": "\u5728\u5de5\u4e1a\u89c4\u6a21UF\u7cfb\u7edf\u768412,528\u4e2a\u64cd\u4f5c\u5468\u671f\u4e0a\u6d4b\u8bd5\uff0c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4e3a4.50\u4e2a\u5468\u671f\uff0c\u751f\u6210\u4e0e\u4e13\u5bb6\u7406\u89e3\u4e00\u81f4\u7684\u53ef\u89e3\u91ca\u89c4\u5219\u5e93", "conclusion": "\u63d0\u51fa\u7684\u53ef\u89e3\u91ca\u9884\u6d4b\u6846\u67b6\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u4f9b\u900f\u660e\u9884\u6d4b\uff0c\u589e\u5f3a\u64cd\u4f5c\u4eba\u5458\u4fe1\u4efb\uff0c\u4e3a\u8d85\u6ee4\u819c\u7ef4\u62a4\u51b3\u7b56\u63d0\u4f9b\u53ef\u9760\u652f\u6301"}}
{"id": "2602.01544", "categories": ["cs.CR", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01544", "abs": "https://arxiv.org/abs/2602.01544", "authors": ["Sarah Tabassum"], "title": "Are Security Cues Static? Rethinking Warning and Trust Indicators for Life Transitions", "comment": null, "summary": "Security cues, such as warnings and trust signals, are designed as stable interface elements, even though people's lives, contexts, and vulnerabilities change over time. Life transitions including migration, aging, or shifts in institutional environments reshape how risk and trust are understood and acted upon. Yet current systems rarely adapt their security cues to these changing conditions, placing the burden of interpretation on users. In this Works-in-Progress paper, we argue that the static nature of security cues represents a design mismatch with transitional human lives. We draw on prior empirical insights from work on educational migration as a motivating case, and extend the discussion to other life transitions. Building on these insights, we introduce the Transition-Aware Security Cues (TASeC) framework and present speculative design concepts illustrating how security cues might evolve across transition stages. We invite HCI to rethink security cues as longitudinal, life-centered design elements collectively.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5b89\u5168\u63d0\u793a\uff08\u5982\u8b66\u544a\u548c\u4fe1\u4efb\u4fe1\u53f7\uff09\u5e94\u9002\u5e94\u4eba\u751f\u8fc7\u6e21\u9636\u6bb5\u7684\u53d8\u5316\uff0c\u800c\u975e\u4fdd\u6301\u9759\u6001\u8bbe\u8ba1\uff0c\u5e76\u63d0\u51fa\u4e86\u8fc7\u6e21\u611f\u77e5\u5b89\u5168\u63d0\u793a\u6846\u67b6\u3002", "motivation": "\u5f53\u524d\u5b89\u5168\u63d0\u793a\u8bbe\u8ba1\u4e3a\u9759\u6001\u754c\u9762\u5143\u7d20\uff0c\u4f46\u4eba\u4eec\u7684\u751f\u6d3b\u3001\u73af\u5883\u548c\u8106\u5f31\u6027\u4f1a\u968f\u65f6\u95f4\u53d8\u5316\uff08\u5982\u79fb\u6c11\u3001\u8001\u9f84\u5316\u3001\u73af\u5883\u53d8\u5316\u7b49\uff09\u3002\u8fd9\u4e9b\u4eba\u751f\u8fc7\u6e21\u9636\u6bb5\u4f1a\u91cd\u5851\u4eba\u4eec\u5bf9\u98ce\u9669\u548c\u4fe1\u4efb\u7684\u7406\u89e3\u4e0e\u5e94\u5bf9\u65b9\u5f0f\uff0c\u800c\u73b0\u6709\u7cfb\u7edf\u5f88\u5c11\u6839\u636e\u8fd9\u4e9b\u53d8\u5316\u8c03\u6574\u5b89\u5168\u63d0\u793a\uff0c\u5c06\u89e3\u91ca\u8d1f\u62c5\u8f6c\u5ac1\u7ed9\u7528\u6237\u3002", "method": "\u57fa\u4e8e\u6559\u80b2\u79fb\u6c11\u7684\u5b9e\u8bc1\u7814\u7a76\u4f5c\u4e3a\u6848\u4f8b\uff0c\u6269\u5c55\u5230\u5176\u4ed6\u4eba\u751f\u8fc7\u6e21\u9636\u6bb5\uff0c\u63d0\u51fa\u4e86\u8fc7\u6e21\u611f\u77e5\u5b89\u5168\u63d0\u793a\uff08TASeC\uff09\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u63a8\u6d4b\u6027\u8bbe\u8ba1\u6982\u5ff5\u5c55\u793a\u5b89\u5168\u63d0\u793a\u5982\u4f55\u5728\u8fc7\u6e21\u9636\u6bb5\u6f14\u53d8\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u5c55\u793a\u5b89\u5168\u63d0\u793a\u5982\u4f55\u9002\u5e94\u4eba\u751f\u8fc7\u6e21\u9636\u6bb5\u7684\u53d8\u5316\uff0c\u5e76\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u8bbe\u8ba1\u6982\u5ff5\u793a\u4f8b\u3002", "conclusion": "\u5b89\u5168\u63d0\u793a\u7684\u9759\u6001\u6027\u8d28\u4e0e\u8fc7\u6e21\u6027\u4eba\u751f\u4e4b\u95f4\u5b58\u5728\u8bbe\u8ba1\u4e0d\u5339\u914d\uff0c\u547c\u5401HCI\u9886\u57df\u5c06\u5b89\u5168\u63d0\u793a\u91cd\u65b0\u6784\u60f3\u4e3a\u7eb5\u5411\u7684\u3001\u4ee5\u751f\u6d3b\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\u5143\u7d20\u3002"}}
{"id": "2602.01155", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01155", "abs": "https://arxiv.org/abs/2602.01155", "authors": ["Hugo Math", "Julian Lorenz", "Stefan Oelsner", "Rainer Lienhart"], "title": "Multi-Agent Causal Reasoning System for Error Pattern Rule Automation in Vehicles", "comment": "7 pages, 3 figures", "summary": "Modern vehicles generate thousands of different discrete events known as Diagnostic Trouble Codes (DTCs). Automotive manufacturers use Boolean combinations of these codes, called error patterns (EPs), to characterize system faults and ensure vehicle safety. Yet, EP rules are still manually handcrafted by domain experts, a process that is expensive and prone to errors as vehicle complexity grows. This paper introduces CAREP (Causal Automated Reasoning for Error Patterns), a multi-agent system that automatizes the generation of EP rules from high-dimensional event sequences of DTCs. CAREP combines a causal discovery agent that identifies potential DTC-EP relations, a contextual information agent that integrates metadata and descriptions, and an orchestrator agent that synthesizes candidate boolean rules together with interpretable reasoning traces. Evaluation on a large-scale automotive dataset with over 29,100 unique DTCs and 474 error patterns demonstrates that CAREP can automatically and accurately discover the unknown EP rules, outperforming LLM-only baselines while providing transparent causal explanations. By uniting practical causal discovery and agent-based reasoning, CAREP represents a step toward fully automated fault diagnostics, enabling scalable, interpretable, and cost-efficient vehicle maintenance.", "AI": {"tldr": "CAREP\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u4ece\u8bca\u65ad\u6545\u969c\u7801(DTC)\u7684\u9ad8\u7ef4\u4e8b\u4ef6\u5e8f\u5217\u4e2d\u81ea\u52a8\u751f\u6210\u9519\u8bef\u6a21\u5f0f(EP)\u89c4\u5219\uff0c\u53d6\u4ee3\u4f20\u7edf\u624b\u5de5\u5236\u4f5c\u65b9\u6cd5\uff0c\u63d0\u9ad8\u6c7d\u8f66\u6545\u969c\u8bca\u65ad\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u4ee3\u6c7d\u8f66\u4ea7\u751f\u6570\u5343\u79cd\u4e0d\u540c\u7684\u8bca\u65ad\u6545\u969c\u7801(DTC)\uff0c\u6c7d\u8f66\u5236\u9020\u5546\u4f7f\u7528\u8fd9\u4e9b\u4ee3\u7801\u7684\u5e03\u5c14\u7ec4\u5408\uff08\u79f0\u4e3a\u9519\u8bef\u6a21\u5f0fEP\uff09\u6765\u8868\u5f81\u7cfb\u7edf\u6545\u969c\u5e76\u786e\u4fdd\u8f66\u8f86\u5b89\u5168\u3002\u7136\u800c\uff0cEP\u89c4\u5219\u4ecd\u7531\u9886\u57df\u4e13\u5bb6\u624b\u5de5\u5236\u4f5c\uff0c\u968f\u7740\u8f66\u8f86\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u65e2\u6602\u8d35\u53c8\u5bb9\u6613\u51fa\u9519\u3002", "method": "CAREP\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u67b6\u6784\uff1a1)\u56e0\u679c\u53d1\u73b0\u667a\u80fd\u4f53\u8bc6\u522b\u6f5c\u5728\u7684DTC-EP\u5173\u7cfb\uff1b2)\u4e0a\u4e0b\u6587\u4fe1\u606f\u667a\u80fd\u4f53\u6574\u5408\u5143\u6570\u636e\u548c\u63cf\u8ff0\uff1b3)\u7f16\u6392\u5668\u667a\u80fd\u4f53\u7efc\u5408\u5019\u9009\u5e03\u5c14\u89c4\u5219\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8f68\u8ff9\u3002", "result": "\u5728\u5305\u542b29,100\u4e2a\u72ec\u7279DTC\u548c474\u4e2a\u9519\u8bef\u6a21\u5f0f\u7684\u5927\u89c4\u6a21\u6c7d\u8f66\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cCAREP\u80fd\u591f\u81ea\u52a8\u51c6\u786e\u5730\u53d1\u73b0\u672a\u77e5\u7684EP\u89c4\u5219\uff0c\u4f18\u4e8e\u4ec5\u4f7f\u7528LLM\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u4f9b\u900f\u660e\u7684\u56e0\u679c\u89e3\u91ca\u3002", "conclusion": "CAREP\u901a\u8fc7\u7ed3\u5408\u5b9e\u7528\u7684\u56e0\u679c\u53d1\u73b0\u548c\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u63a8\u7406\uff0c\u5411\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u6545\u969c\u8bca\u65ad\u8fc8\u51fa\u4e86\u4e00\u6b65\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u8f66\u8f86\u7ef4\u62a4\u3002"}}
{"id": "2602.00676", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.00676", "abs": "https://arxiv.org/abs/2602.00676", "authors": ["Chao Li", "Shangdong Yang", "Chiheng Zhan", "Zhenxing Ge", "Yujing Hu", "Bingkun Bao", "Xingguo Chen", "Yang Gao"], "title": "OpenGuanDan: A Large-Scale Imperfect Information Game Benchmark", "comment": null, "summary": "The advancement of data-driven artificial intelligence (AI), particularly machine learning, heavily depends on large-scale benchmarks. Despite remarkable progress across domains ranging from pattern recognition to intelligent decision-making in recent decades, exemplified by breakthroughs in board games, card games, and electronic sports games, there remains a pressing need for more challenging benchmarks to drive further research. To this end, this paper proposes OpenGuanDan, a novel benchmark that enables both efficient simulation of GuanDan (a popular four-player, multi-round Chinese card game) and comprehensive evaluation of both learning-based and rule-based GuanDan AI agents. OpenGuanDan poses a suite of nontrivial challenges, including imperfect information, large-scale information set and action spaces, a mixed learning objective involving cooperation and competition, long-horizon decision-making, variable action spaces, and dynamic team composition. These characteristics make it a demanding testbed for existing intelligent decision-making methods. Moreover, the independent API for each player allows human-AI interactions and supports integration with large language models. Empirically, we conduct two types of evaluations: (1) pairwise competitions among all GuanDan AI agents, and (2) human-AI matchups. Experimental results demonstrate that while current learning-based agents substantially outperform rule-based counterparts, they still fall short of achieving superhuman performance, underscoring the need for continued research in multi-agent intelligent decision-making domain. The project is publicly available at https://github.com/GameAI-NJUPT/OpenGuanDan.", "AI": {"tldr": "OpenGuanDan\u662f\u4e00\u4e2a\u65b0\u7684AI\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4e13\u6ce8\u4e8e\u4e2d\u56fd\u6d41\u884c\u7684\u56db\u4eba\u591a\u8f6e\u7eb8\u724c\u6e38\u620f\"\u63bc\u86cb\"\uff0c\u65e8\u5728\u4e3a\u5b66\u4e60\u578b\u548c\u89c4\u5219\u578bAI\u667a\u80fd\u4f53\u63d0\u4f9b\u9ad8\u6548\u6a21\u62df\u548c\u5168\u9762\u8bc4\u4f30\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u68cb\u7c7b\u3001\u5361\u724c\u6e38\u620f\u7b49\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4ecd\u9700\u8981\u66f4\u5177\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u63a8\u52a8\u8fdb\u4e00\u6b65\u7814\u7a76\u3002\u63bc\u86cb\u6e38\u620f\u5177\u6709\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u3001\u5927\u89c4\u6a21\u4fe1\u606f\u96c6\u548c\u52a8\u4f5c\u7a7a\u95f4\u3001\u5408\u4f5c\u4e0e\u7ade\u4e89\u6df7\u5408\u76ee\u6807\u3001\u957f\u65f6\u7a0b\u51b3\u7b56\u7b49\u590d\u6742\u7279\u6027\uff0c\u4f7f\u5176\u6210\u4e3a\u73b0\u6709\u667a\u80fd\u51b3\u7b56\u65b9\u6cd5\u7684\u4e25\u683c\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u5f00\u53d1\u4e86OpenGuanDan\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u652f\u6301\u63bc\u86cb\u6e38\u620f\u7684\u9ad8\u6548\u6a21\u62df\u548cAI\u667a\u80fd\u4f53\u8bc4\u4f30\u3002\u5e73\u53f0\u4e3a\u6bcf\u4e2a\u73a9\u5bb6\u63d0\u4f9b\u72ec\u7acbAPI\uff0c\u652f\u6301\u4eba\u673a\u4ea4\u4e92\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u3002\u8bc4\u4f30\u5305\u62ec\u4e24\u7c7b\uff1a\u6240\u6709\u63bc\u86cbAI\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u6210\u5bf9\u7ade\u4e89\uff0c\u4ee5\u53ca\u4eba\u673a\u5bf9\u6218\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u524d\u57fa\u4e8e\u5b66\u4e60\u7684\u667a\u80fd\u4f53\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u4f53\uff0c\u4f46\u4ecd\u672a\u8fbe\u5230\u8d85\u4eba\u7c7b\u6c34\u5e73\u3002\u8fd9\u8868\u660e\u5728\u591a\u667a\u80fd\u4f53\u667a\u80fd\u51b3\u7b56\u9886\u57df\u4ecd\u9700\u7ee7\u7eed\u7814\u7a76\u3002", "conclusion": "OpenGuanDan\u4f5c\u4e3a\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u80fd\u591f\u63a8\u52a8\u591a\u667a\u80fd\u4f53\u667a\u80fd\u51b3\u7b56\u9886\u57df\u7684\u7814\u7a76\u3002\u8be5\u5e73\u53f0\u5df2\u516c\u5f00\u53ef\u7528\uff0c\u652f\u6301\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u548c\u5f00\u53d1\u3002"}}
{"id": "2602.01465", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01465", "abs": "https://arxiv.org/abs/2602.01465", "authors": ["Nikita Benkovich", "Vitalii Valkov"], "title": "Agyn: A Multi-Agent System for Team-Based Autonomous Software Engineering", "comment": null, "summary": "Large language models have demonstrated strong capabilities in individual software engineering tasks, yet most autonomous systems still treat issue resolution as a monolithic or pipeline-based process. In contrast, real-world software development is organized as a collaborative activity carried out by teams following shared methodologies, with clear role separation, communication, and review. In this work, we present a fully automated multi-agent system that explicitly models software engineering as an organizational process, replicating the structure of an engineering team. Built on top of agyn, an open-source platform for configuring agent teams, our system assigns specialized agents to roles such as coordination, research, implementation, and review, provides them with isolated sandboxes for experimentation, and enables structured communication. The system follows a defined development methodology for working on issues, including analysis, task specification, pull request creation, and iterative review, and operates without any human intervention. Importantly, the system was designed for real production use and was not tuned for SWE-bench. When evaluated post hoc on SWE-bench 500, it resolves 72.4% of tasks, outperforming single-agent baselines using comparable language models. Our results suggest that replicating team structure, methodology, and communication is a powerful paradigm for autonomous software engineering, and that future progress may depend as much on organizational design and agent infrastructure as on model improvements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5c06\u8f6f\u4ef6\u5de5\u7a0b\u5efa\u6a21\u4e3a\u7ec4\u7ec7\u5316\u6d41\u7a0b\uff0c\u6a21\u62df\u5de5\u7a0b\u56e2\u961f\u7ed3\u6784\uff0c\u5728SWE-bench 500\u4e0a\u5b9e\u73b0\u4e8672.4%\u7684\u4efb\u52a1\u89e3\u51b3\u7387\uff0c\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u81ea\u4e3b\u7cfb\u7edf\u901a\u5e38\u5c06\u95ee\u9898\u89e3\u51b3\u89c6\u4e3a\u5355\u4e00\u6216\u6d41\u6c34\u7ebf\u8fc7\u7a0b\uff0c\u800c\u73b0\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u662f\u56e2\u961f\u534f\u4f5c\u6d3b\u52a8\uff0c\u5177\u6709\u660e\u786e\u7684\u89d2\u8272\u5206\u5de5\u3001\u6c9f\u901a\u548c\u8bc4\u5ba1\u3002\u9700\u8981\u6a21\u62df\u771f\u5b9e\u5de5\u7a0b\u56e2\u961f\u7684\u7ec4\u7ec7\u7ed3\u6784\u6765\u63d0\u5347\u81ea\u4e3b\u8f6f\u4ef6\u5de5\u7a0b\u80fd\u529b\u3002", "method": "\u57fa\u4e8eagyn\u5f00\u6e90\u5e73\u53f0\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5206\u914d\u534f\u8c03\u3001\u7814\u7a76\u3001\u5b9e\u65bd\u3001\u8bc4\u5ba1\u7b49\u4e13\u95e8\u89d2\u8272\uff0c\u63d0\u4f9b\u9694\u79bb\u6c99\u7bb1\u8fdb\u884c\u5b9e\u9a8c\uff0c\u652f\u6301\u7ed3\u6784\u5316\u901a\u4fe1\u3002\u7cfb\u7edf\u9075\u5faa\u5b9a\u4e49\u597d\u7684\u5f00\u53d1\u65b9\u6cd5\u8bba\uff0c\u5305\u62ec\u5206\u6790\u3001\u4efb\u52a1\u89c4\u8303\u3001\u62c9\u53d6\u8bf7\u6c42\u521b\u5efa\u548c\u8fed\u4ee3\u8bc4\u5ba1\uff0c\u5b8c\u5168\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002", "result": "\u5728SWE-bench 500\u4e0a\u8bc4\u4f30\uff0c\u7cfb\u7edf\u89e3\u51b3\u4e8672.4%\u7684\u4efb\u52a1\uff0c\u4f18\u4e8e\u4f7f\u7528\u53ef\u6bd4\u8bed\u8a00\u6a21\u578b\u7684\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u3002\u7cfb\u7edf\u8bbe\u8ba1\u7528\u4e8e\u5b9e\u9645\u751f\u4ea7\u4f7f\u7528\uff0c\u800c\u975e\u4e13\u95e8\u9488\u5bf9SWE-bench\u8fdb\u884c\u8c03\u4f18\u3002", "conclusion": "\u6a21\u62df\u56e2\u961f\u7ed3\u6784\u3001\u65b9\u6cd5\u8bba\u548c\u6c9f\u901a\u662f\u81ea\u4e3b\u8f6f\u4ef6\u5de5\u7a0b\u7684\u6709\u529b\u8303\u5f0f\uff0c\u672a\u6765\u8fdb\u5c55\u53ef\u80fd\u540c\u6837\u4f9d\u8d56\u4e8e\u7ec4\u7ec7\u8bbe\u8ba1\u548c\u667a\u80fd\u4f53\u57fa\u7840\u8bbe\u65bd\u7684\u6539\u8fdb\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u6a21\u578b\u80fd\u529b\u7684\u63d0\u5347\u3002"}}
{"id": "2602.01600", "categories": ["cs.CR", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01600", "abs": "https://arxiv.org/abs/2602.01600", "authors": ["Yen-Shan Chen", "Zhi Rui Tam", "Cheng-Kuang Wu", "Yun-Nung Chen"], "title": "Expected Harm: Rethinking Safety Evaluation of (Mis)Aligned LLMs", "comment": null, "summary": "Current evaluations of LLM safety predominantly rely on severity-based taxonomies to assess the harmfulness of malicious queries. We argue that this formulation requires re-examination as it assumes uniform risk across all malicious queries, neglecting Execution Likelihood--the conditional probability of a threat being realized given the model's response. In this work, we introduce Expected Harm, a metric that weights the severity of a jailbreak by its execution likelihood, modeled as a function of execution cost. Through empirical analysis of state-of-the-art models, we reveal a systematic Inverse Risk Calibration: models disproportionately exhibit stronger refusal behaviors for low-likelihood (high-cost) threats while remaining vulnerable to high-likelihood (low-cost) queries. We demonstrate that this miscalibration creates a structural vulnerability: by exploiting this property, we increase the attack success rate of existing jailbreaks by up to $2\\times$. Finally, we trace the root cause of this failure using linear probing, which reveals that while models encode severity in their latent space to drive refusal decisions, they possess no distinguishable internal representation of execution cost, making them \"blind\" to this critical dimension of risk.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u9884\u671f\u5371\u5bb3\"\u65b0\u6307\u6807\uff0c\u7ed3\u5408\u6076\u610f\u67e5\u8be2\u7684\u4e25\u91cd\u6027\u548c\u6267\u884c\u53ef\u80fd\u6027\uff0c\u63ed\u793aLLM\u5b58\u5728\"\u53cd\u5411\u98ce\u9669\u6821\u51c6\"\u95ee\u9898\uff1a\u6a21\u578b\u8fc7\u5ea6\u62d2\u7edd\u4f4e\u53ef\u80fd\u6027\u5a01\u80c1\uff0c\u5374\u5bf9\u9ad8\u53ef\u80fd\u6027\u653b\u51fb\u4fdd\u6301\u8106\u5f31\u3002", "motivation": "\u5f53\u524dLLM\u5b89\u5168\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u57fa\u4e8e\u4e25\u91cd\u6027\u7684\u5206\u7c7b\u6cd5\uff0c\u5047\u8bbe\u6240\u6709\u6076\u610f\u67e5\u8be2\u98ce\u9669\u5747\u5300\uff0c\u5ffd\u89c6\u4e86\"\u6267\u884c\u53ef\u80fd\u6027\"\u2014\u2014\u7ed9\u5b9a\u6a21\u578b\u54cd\u5e94\u540e\u5a01\u80c1\u88ab\u5b9e\u73b0\u7684\u6982\u7387\u3002\u8fd9\u79cd\u8bc4\u4f30\u6846\u67b6\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u3002", "method": "\u5f15\u5165\"\u9884\u671f\u5371\u5bb3\"\u6307\u6807\uff0c\u5c06\u8d8a\u72f1\u4e25\u91cd\u6027\u6309\u6267\u884c\u53ef\u80fd\u6027\u52a0\u6743\uff0c\u6267\u884c\u53ef\u80fd\u6027\u5efa\u6a21\u4e3a\u6267\u884c\u6210\u672c\u7684\u51fd\u6570\u3002\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5e76\u5229\u7528\u7ebf\u6027\u63a2\u6d4b\u6280\u672f\u8ffd\u6eaf\u5931\u8d25\u6839\u6e90\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u6027\u7684\"\u53cd\u5411\u98ce\u9669\u6821\u51c6\"\u73b0\u8c61\uff1a\u6a21\u578b\u5bf9\u4f4e\u53ef\u80fd\u6027\uff08\u9ad8\u6210\u672c\uff09\u5a01\u80c1\u8868\u73b0\u51fa\u8fc7\u5f3a\u7684\u62d2\u7edd\u884c\u4e3a\uff0c\u4f46\u5bf9\u9ad8\u53ef\u80fd\u6027\uff08\u4f4e\u6210\u672c\uff09\u67e5\u8be2\u4fdd\u6301\u8106\u5f31\u3002\u5229\u7528\u6b64\u7279\u6027\u53ef\u5c06\u73b0\u6709\u8d8a\u72f1\u653b\u51fb\u6210\u529f\u7387\u63d0\u5347\u9ad8\u8fbe2\u500d\u3002", "conclusion": "\u6a21\u578b\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7f16\u7801\u4e25\u91cd\u6027\u4ee5\u9a71\u52a8\u62d2\u7edd\u51b3\u7b56\uff0c\u4f46\u6ca1\u6709\u53ef\u533a\u5206\u7684\u6267\u884c\u6210\u672c\u5185\u90e8\u8868\u5f81\uff0c\u4f7f\u5176\u5bf9\u8fd9\u4e00\u5173\u952e\u98ce\u9669\u7ef4\u5ea6\"\u89c6\u800c\u4e0d\u89c1\"\uff0c\u5bfc\u81f4\u7ed3\u6784\u6027\u6f0f\u6d1e\u3002"}}
{"id": "2602.01621", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01621", "abs": "https://arxiv.org/abs/2602.01621", "authors": ["Hanjun Park", "Byeong-Seo Min", "Jiheon Woo", "Min-Wook Jeong", "Jongho Shin", "Yongwoo Lee", "Young-Sik Kim", "Yongjune Kim"], "title": "Efficient Softmax Reformulation for Homomorphic Encryption via Moment Generating Function", "comment": null, "summary": "Homomorphic encryption (HE) is a prominent framework for privacy-preserving machine learning, enabling inference directly on encrypted data. However, evaluating softmax, a core component of transformer architectures, remains particularly challenging in HE due to its multivariate structure, the large dynamic range induced by exponential functions, and the need for accurate division during normalization. In this paper, we propose MGF-softmax, a novel softmax reformulation based on the moment generating function (MGF) that replaces the softmax denominator with its moment-based counterpart. This reformulation substantially reduces multiplicative depth while preserving key properties of softmax and asymptotically converging to the exact softmax as the number of input tokens increases. Extensive experiments on Vision Transformers and large language models show that MGF-softmax provides an efficient and accurate approximation of softmax in encrypted inference. In particular, it achieves inference accuracy close to that of high-depth exact methods, while requiring substantially lower computational cost through reduced multiplicative depth.", "AI": {"tldr": "MGF-softmax\uff1a\u57fa\u4e8e\u77e9\u751f\u6210\u51fd\u6570\u7684softmax\u91cd\u6784\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u540c\u6001\u52a0\u5bc6\u4e2dsoftmax\u8ba1\u7b97\u7684\u591a\u91cd\u6df1\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6", "motivation": "\u540c\u6001\u52a0\u5bc6\uff08HE\uff09\u662f\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u7684\u91cd\u8981\u6846\u67b6\uff0c\u4f46softmax\u4f5c\u4e3atransformer\u67b6\u6784\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5728\u540c\u6001\u52a0\u5bc6\u4e2d\u8bc4\u4f30\u7279\u522b\u56f0\u96be\uff0c\u539f\u56e0\u5305\u62ec\u5176\u591a\u5143\u7ed3\u6784\u3001\u6307\u6570\u51fd\u6570\u5f15\u8d77\u7684\u5927\u52a8\u6001\u8303\u56f4\u4ee5\u53ca\u5f52\u4e00\u5316\u8fc7\u7a0b\u4e2d\u9700\u8981\u7cbe\u786e\u9664\u6cd5", "method": "\u63d0\u51faMGF-softmax\uff0c\u57fa\u4e8e\u77e9\u751f\u6210\u51fd\u6570\uff08MGF\uff09\u7684\u65b0\u578bsoftmax\u91cd\u6784\u65b9\u6cd5\uff0c\u7528\u57fa\u4e8e\u77e9\u7684\u5bf9\u5e94\u9879\u66ff\u6362softmax\u5206\u6bcd\uff0c\u663e\u8457\u51cf\u5c11\u4e58\u6cd5\u6df1\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301softmax\u7684\u5173\u952e\u7279\u6027\uff0c\u5e76\u968f\u7740\u8f93\u5165token\u6570\u91cf\u589e\u52a0\u6e10\u8fd1\u6536\u655b\u5230\u7cbe\u786esoftmax", "result": "\u5728Vision Transformers\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMGF-softmax\u5728\u52a0\u5bc6\u63a8\u7406\u4e2d\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684softmax\u8fd1\u4f3c\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u9ad8\u6df1\u5ea6\u7cbe\u786e\u65b9\u6cd5\u7684\u63a8\u7406\u7cbe\u5ea6\uff0c\u540c\u65f6\u901a\u8fc7\u51cf\u5c11\u4e58\u6cd5\u6df1\u5ea6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c", "conclusion": "MGF-softmax\u662f\u540c\u6001\u52a0\u5bc6\u4e2dsoftmax\u8ba1\u7b97\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u4e2d\u7684transformer\u67b6\u6784\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5"}}
{"id": "2602.00699", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00699", "abs": "https://arxiv.org/abs/2602.00699", "authors": ["Xuan Liu", "Ziyu Li", "Mu He", "Ziyang Ma", "Xiaoxu Wu", "Gizem Yilmaz", "Yiyuan Xia", "Bingbing Li", "He Tan", "Jerry Ying Hsi Fuh", "Wen Feng Lu", "Anders E. W. Jarfors", "Per Jansson"], "title": "From Prompt to Graph: Comparing LLM-Based Information Extraction Strategies in Domain-Specific Ontology Development", "comment": "11 pages,8 figures,3 tables,presented at International Conference on Industry of the Future and Smart Manufacturing,2025", "summary": "Ontologies are essential for structuring domain knowledge, improving accessibility, sharing, and reuse. However, traditional ontology construction relies on manual annotation and conventional natural language processing (NLP) techniques, making the process labour-intensive and costly, especially in specialised fields like casting manufacturing. The rise of Large Language Models (LLMs) offers new possibilities for automating knowledge extraction. This study investigates three LLM-based approaches, including pre-trained LLM-driven method, in-context learning (ICL) method and fine-tuning method to extract terms and relations from domain-specific texts using limited data. We compare their performances and use the best-performing method to build a casting ontology that validated by domian expert.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u4e09\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff08\u9884\u8bad\u7ec3LLM\u9a71\u52a8\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u5fae\u8c03\uff09\u4ece\u94f8\u9020\u5236\u9020\u9886\u57df\u6587\u672c\u4e2d\u81ea\u52a8\u63d0\u53d6\u672f\u8bed\u548c\u5173\u7cfb\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u672c\u4f53\u6784\u5efa\u52b3\u52a8\u5bc6\u96c6\u548c\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u672c\u4f53\u6784\u5efa\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u548c\u4f20\u7edfNLP\u6280\u672f\uff0c\u8fc7\u7a0b\u52b3\u52a8\u5bc6\u96c6\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u7279\u522b\u662f\u5728\u94f8\u9020\u5236\u9020\u7b49\u4e13\u4e1a\u9886\u57df\u3002\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\u4e3a\u81ea\u52a8\u5316\u77e5\u8bc6\u63d0\u53d6\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "method": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e09\u79cdLLM\u65b9\u6cd5\uff1a1\uff09\u9884\u8bad\u7ec3LLM\u9a71\u52a8\u65b9\u6cd5\uff1b2\uff09\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\uff1b3\uff09\u5fae\u8c03\u65b9\u6cd5\u3002\u8fd9\u4e9b\u65b9\u6cd5\u4f7f\u7528\u6709\u9650\u6570\u636e\u4ece\u9886\u57df\u7279\u5b9a\u6587\u672c\u4e2d\u63d0\u53d6\u672f\u8bed\u548c\u5173\u7cfb\u3002", "result": "\u6bd4\u8f83\u4e86\u4e09\u79cd\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5e76\u4f7f\u7528\u8868\u73b0\u6700\u4f73\u7684\u65b9\u6cd5\u6784\u5efa\u4e86\u94f8\u9020\u672c\u4f53\uff0c\u8be5\u672c\u4f53\u7ecf\u8fc7\u9886\u57df\u4e13\u5bb6\u9a8c\u8bc1\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u652f\u6301\u9886\u57df\u672c\u4f53\u7684\u81ea\u52a8\u5316\u6784\u5efa\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u6709\u9650\u7684\u4e13\u4e1a\u9886\u57df\uff0c\u4e3a\u4f20\u7edf\u52b3\u52a8\u5bc6\u96c6\u578b\u672c\u4f53\u6784\u5efa\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2602.02029", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02029", "abs": "https://arxiv.org/abs/2602.02029", "authors": ["Zhongyuan Lyu", "Shuoyu Hu", "Lujie Liu", "Hongxia Yang", "Ming LI"], "title": "Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation", "comment": "41 pages, 4 figures, 5 tables", "summary": "Automatically formulating optimization models from natural language descriptions is a growing focus in operations research, yet current LLM-based approaches struggle with the composite constraints and appropriate modeling paradigms required by complex operational rules. To address this, we introduce the Canonical Intermediate Representation (CIR): a schema that LLMs explicitly generate between problem descriptions and optimization models. CIR encodes the semantics of operational rules through constraint archetypes and candidate modeling paradigms, thereby decoupling rule logic from its mathematical instantiation. Upon a newly generated CIR knowledge base, we develop the rule-to-constraint (R2C) framework, a multi-agent pipeline that parses problem texts, synthesizes CIR implementations by retrieving domain knowledge, and instantiates optimization models. To systematically evaluate rule-to-constraint reasoning, we test R2C on our newly constructed benchmark featuring rich operational rules, and benchmarks from prior work. Extensive experiments show that R2C achieves state-of-the-art accuracy on the proposed benchmark (47.2% Accuracy Rate). On established benchmarks from the literature, R2C delivers highly competitive results, approaching the performance of proprietary models (e.g., GPT-5). Moreover, with a reflection mechanism, R2C achieves further gains and sets new best-reported results on some benchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86CIR\uff08\u89c4\u8303\u4e2d\u95f4\u8868\u793a\uff09\u548cR2C\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u4f18\u5316\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u64cd\u4f5c\u89c4\u5219\u65f6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u64cd\u4f5c\u89c4\u5219\u65f6\u9762\u4e34\u6311\u6218\uff0c\u96be\u4ee5\u5904\u7406\u590d\u5408\u7ea6\u675f\u548c\u9009\u62e9\u5408\u9002\u7684\u5efa\u6a21\u8303\u5f0f\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u81ea\u52a8\u5316\u4f18\u5316\u6a21\u578b\u6784\u5efa\u3002", "method": "\u63d0\u51faCIR\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u901a\u8fc7\u7ea6\u675f\u539f\u578b\u548c\u5019\u9009\u5efa\u6a21\u8303\u5f0f\u7f16\u7801\u64cd\u4f5c\u89c4\u5219\u8bed\u4e49\uff1b\u5f00\u53d1R2C\u591a\u667a\u80fd\u4f53\u7ba1\u9053\uff0c\u5305\u62ec\u89e3\u6790\u95ee\u9898\u6587\u672c\u3001\u68c0\u7d22\u9886\u57df\u77e5\u8bc6\u5408\u6210CIR\u5b9e\u73b0\u3001\u5b9e\u4f8b\u5316\u4f18\u5316\u6a21\u578b\uff1b\u91c7\u7528\u53cd\u601d\u673a\u5236\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "result": "R2C\u5728\u65b0\u6784\u5efa\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523047.2%\u7684\u51c6\u786e\u7387\uff0c\u5728\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63a5\u8fd1GPT-5\u7b49\u4e13\u6709\u6a21\u578b\u6027\u80fd\uff1b\u901a\u8fc7\u53cd\u601d\u673a\u5236\u5728\u67d0\u4e9b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u521b\u9020\u4e86\u65b0\u7684\u6700\u4f73\u8bb0\u5f55\u3002", "conclusion": "CIR\u548cR2C\u6846\u67b6\u4e3a\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u4f18\u5316\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u64cd\u4f5c\u89c4\u5219\u7684\u5904\u7406\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u4e86\u5353\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.01663", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01663", "abs": "https://arxiv.org/abs/2602.01663", "authors": ["David Condrey"], "title": "Witnessd: Proof-of-process via Adversarial Collapse", "comment": null, "summary": "Digital signatures prove key possession, not authorship. An author who generates text with AI, constructs intermediate document states post-hoc, and signs each hash produces a signature chain indistinguishable from genuine composition. We address this gap between cryptographic integrity and process provenance. We introduce proof-of-process, a primitive category for evidence that a physical process, not merely a signing key, produced a digital artifact. Our construction, the jitter seal, injects imperceptible microsecond delays derived via HMAC from a session secret, keystroke ordinal, and cumulative document hash. Valid evidence requires that real keystrokes produced the document through those intermediate states. We propose the Adversarial Collapse Principle as an evaluation criterion: evidence systems should be judged by whether disputing them requires a conjunction of specific, testable allegations against components with independent trust assumptions. We present Witnessd, an architecture combining jitter seals with Verifiable Delay Functions, external timestamp anchors, dual-source keystroke validation, and optional hardware attestation. Each layer forces allegations at different capability levels; disputing authentic evidence requires coordinated claims across independent trust boundaries. The system does not prevent forgery: a kernel-level adversary can defeat it, and typing AI-generated content produces valid evidence. The contribution is converting vague doubt into falsifiable allegations. We evaluate across 31,000 verification trials with deterministic rejection of invalid proofs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u8fc7\u7a0b\u8bc1\u660e\"\u6982\u5ff5\uff0c\u901a\u8fc7\"\u6296\u52a8\u5bc6\u5c01\"\u6280\u672f\u8bb0\u5f55\u6253\u5b57\u8fc7\u7a0b\u7684\u5fae\u79d2\u7ea7\u5ef6\u8fdf\uff0c\u5c06\u6a21\u7cca\u7684\u6000\u7591\u8f6c\u5316\u4e3a\u53ef\u8bc1\u4f2a\u7684\u6307\u63a7\uff0c\u89e3\u51b3AI\u751f\u6210\u6587\u672c\u7684\u7b7e\u540d\u9a8c\u8bc1\u95ee\u9898\u3002", "motivation": "\u6570\u5b57\u7b7e\u540d\u53ea\u80fd\u8bc1\u660e\u5bc6\u94a5\u6301\u6709\uff0c\u4e0d\u80fd\u8bc1\u660e\u4f5c\u8005\u8eab\u4efd\u3002\u5f53\u4f5c\u8005\u4f7f\u7528AI\u751f\u6210\u6587\u672c\u540e\uff0c\u901a\u8fc7\u4e8b\u540e\u6784\u5efa\u4e2d\u95f4\u6587\u6863\u72b6\u6001\u5e76\u7b7e\u540d\uff0c\u53ef\u4ee5\u521b\u5efa\u4e0e\u771f\u5b9e\u521b\u4f5c\u8fc7\u7a0b\u65e0\u6cd5\u533a\u5206\u7684\u7b7e\u540d\u94fe\u3002\u8fd9\u63ed\u793a\u4e86\u5bc6\u7801\u5b66\u5b8c\u6574\u6027\u4e0e\u8fc7\u7a0b\u6765\u6e90\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\"\u8fc7\u7a0b\u8bc1\u660e\"\u539f\u8bed\u7c7b\u522b\uff0c\u5f15\u5165\"\u6296\u52a8\u5bc6\u5c01\"\u6280\u672f\uff1a\u901a\u8fc7HMAC\u4ece\u4f1a\u8bdd\u5bc6\u94a5\u3001\u6309\u952e\u987a\u5e8f\u548c\u7d2f\u79ef\u6587\u6863\u54c8\u5e0c\u751f\u6210\u4e0d\u53ef\u611f\u77e5\u7684\u5fae\u79d2\u7ea7\u5ef6\u8fdf\u3002\u6784\u5efaWitnessd\u67b6\u6784\uff0c\u7ed3\u5408\u53ef\u9a8c\u8bc1\u5ef6\u8fdf\u51fd\u6570\u3001\u5916\u90e8\u65f6\u95f4\u6233\u951a\u70b9\u3001\u53cc\u6e90\u6309\u952e\u9a8c\u8bc1\u548c\u53ef\u9009\u7684\u786c\u4ef6\u8bc1\u660e\u3002", "result": "\u572831,000\u6b21\u9a8c\u8bc1\u8bd5\u9a8c\u4e2d\u5b9e\u73b0\u4e86\u5bf9\u65e0\u6548\u8bc1\u660e\u7684\u786e\u5b9a\u6027\u62d2\u7edd\u3002\u7cfb\u7edf\u4e0d\u9632\u6b62\u4f2a\u9020\uff08\u5185\u6838\u7ea7\u5bf9\u624b\u53ef\u4ee5\u51fb\u8d25\u5b83\uff09\uff0c\u4f46\u5c06\u6a21\u7cca\u6000\u7591\u8f6c\u5316\u4e3a\u9700\u8981\u8de8\u8d8a\u72ec\u7acb\u4fe1\u4efb\u8fb9\u754c\u534f\u8c03\u6307\u63a7\u7684\u53ef\u8bc1\u4f2a\u4e3b\u5f20\u3002", "conclusion": "\u8d21\u732e\u5728\u4e8e\u63d0\u51fa\"\u5bf9\u6297\u6027\u5d29\u6e83\u539f\u5219\"\u4f5c\u4e3a\u8bc4\u4f30\u6807\u51c6\uff0c\u5c06\u8fc7\u7a0b\u8bc1\u636e\u7cfb\u7edf\u4ece\u9632\u6b62\u4f2a\u9020\u8f6c\u53d8\u4e3a\u5c06\u6a21\u7cca\u6000\u7591\u8f6c\u5316\u4e3a\u5177\u4f53\u3001\u53ef\u6d4b\u8bd5\u7684\u6307\u63a7\uff0c\u8981\u6c42\u5bf9\u624b\u5728\u591a\u4e2a\u72ec\u7acb\u4fe1\u4efb\u7ec4\u4ef6\u4e0a\u534f\u8c03\u653b\u51fb\u3002"}}
{"id": "2602.00707", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00707", "abs": "https://arxiv.org/abs/2602.00707", "authors": ["Jingnan Zheng", "Jingjun Xu", "Yanzhen Luo", "Chenhang Cui", "Gelei Deng", "Zhenkai Liang", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Self-Guard: Defending Large Reasoning Models via enhanced self-reflection", "comment": null, "summary": "The emergence of Large Reasoning Models (LRMs) introduces a new paradigm of explicit reasoning, enabling remarkable advances yet posing unique risks such as reasoning manipulation and information leakage. To mitigate these risks, current alignment strategies predominantly rely on heavy post-training paradigms or external interventions. However, these approaches are often computationally intensive and fail to address the inherent awareness-compliance gap, a critical misalignment where models recognize potential risks yet prioritize following user instructions due to their sycophantic tendencies. To address these limitations, we propose Self-Guard, a lightweight safety defense framework that reinforces safety compliance at the representational level. Self-Guard operates through two principal stages: (1) safety-oriented prompting, which activates the model's latent safety awareness to evoke spontaneous reflection, and (2) safety activation steering, which extracts the resulting directional shift in the hidden state space and amplifies it to ensure that safety compliance prevails over sycophancy during inference. Experiments demonstrate that Self-Guard effectively bridges the awareness-compliance gap, achieving robust safety performance without compromising model utility. Furthermore, Self-Guard exhibits strong generalization across diverse unseen risks and varying model scales, offering a cost-efficient solution for LRM safety alignment.", "AI": {"tldr": "Self-Guard\uff1a\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5b89\u5168\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u8868\u793a\u5c42\u9762\u5f3a\u5316\u5b89\u5168\u5408\u89c4\u6027\u6765\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u610f\u8bc6-\u5408\u89c4\u5dee\u8ddd\u95ee\u9898\uff0c\u65e0\u9700\u5927\u91cf\u540e\u8bad\u7ec3\u6216\u5916\u90e8\u5e72\u9884\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u867d\u7136\u5e26\u6765\u4e86\u663e\u8457\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u63a8\u7406\u64cd\u7eb5\u548c\u4fe1\u606f\u6cc4\u9732\u7b49\u72ec\u7279\u98ce\u9669\u3002\u73b0\u6709\u7684\u5bf9\u9f50\u7b56\u7565\u4e3b\u8981\u4f9d\u8d56\u8ba1\u7b97\u5bc6\u96c6\u7684\u540e\u8bad\u7ec3\u8303\u5f0f\u6216\u5916\u90e8\u5e72\u9884\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4e0d\u4ec5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800c\u4e14\u672a\u80fd\u89e3\u51b3\u6a21\u578b\u8bc6\u522b\u98ce\u9669\u4f46\u4ecd\u4f18\u5148\u9075\u5faa\u7528\u6237\u6307\u4ee4\u7684\"\u610f\u8bc6-\u5408\u89c4\u5dee\u8ddd\"\u95ee\u9898\u3002", "method": "Self-Guard\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u9636\u6bb5\uff1a1\uff09\u5b89\u5168\u5bfc\u5411\u63d0\u793a\uff1a\u6fc0\u6d3b\u6a21\u578b\u6f5c\u5728\u7684\u5b89\u5168\u610f\u8bc6\u4ee5\u5f15\u53d1\u81ea\u53d1\u53cd\u601d\uff1b2\uff09\u5b89\u5168\u6fc0\u6d3b\u5f15\u5bfc\uff1a\u63d0\u53d6\u9690\u85cf\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u65b9\u5411\u6027\u53d8\u5316\u5e76\u653e\u5927\uff0c\u786e\u4fdd\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5b89\u5168\u5408\u89c4\u6027\u4f18\u5148\u4e8e\u8fce\u5408\u503e\u5411\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSelf-Guard\u80fd\u6709\u6548\u5f25\u5408\u610f\u8bc6-\u5408\u89c4\u5dee\u8ddd\uff0c\u5728\u4e0d\u635f\u5bb3\u6a21\u578b\u5b9e\u7528\u6027\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9c81\u68d2\u7684\u5b89\u5168\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u5728\u672a\u89c1\u98ce\u9669\u548c\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Self-Guard\u4e3aLRM\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6210\u672c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u5728\u8868\u793a\u5c42\u9762\u5f3a\u5316\u5b89\u5168\u5408\u89c4\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u5bc6\u96c6\u4e14\u65e0\u6cd5\u89e3\u51b3\u610f\u8bc6-\u5408\u89c4\u5dee\u8ddd\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.01765", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01765", "abs": "https://arxiv.org/abs/2602.01765", "authors": ["Bingzheng Wang", "Xiaoyan Gu", "Hongbo Xu", "Hongcheng Li", "Zimo Yu", "Jiang Zhou", "Weiping Wang"], "title": "Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency", "comment": null, "summary": "Diffusion models have been widely deployed in AIGC services; however, their reliance on opaque training data and procedures exposes a broad attack surface for backdoor injection. In practical auditing scenarios, due to the protection of intellectual property and commercial confidentiality, auditors are typically unable to access model parameters, rendering existing white-box or query-intensive detection methods impractical. More importantly, even after the backdoor is detected, existing detoxification approaches are often trapped in a dilemma between detoxification effectiveness and generation quality.\n  In this work, we identify a previously unreported phenomenon called temporal noise unconsistency, where the noise predictions between adjacent diffusion timesteps is disrupted in specific temporal segments when the input is triggered, while remaining stable under clean inputs. Leveraging this finding, we propose Temporal Noise Consistency Defense (TNC-Defense), a unified framework for backdoor detection and detoxification. The framework first uses the adjacent timestep noise consistency to design a gray-box detection module, for identifying and locating anomalous diffusion timesteps. Furthermore, the framework uses the identified anomalous timesteps to construct a trigger-agnostic, timestep-aware detoxification module, which directly corrects the backdoor generation path. This effectively suppresses backdoor behavior while significantly reducing detoxification costs.\n  We evaluate the proposed method under five representative backdoor attack scenarios and compare it with state-of-the-art defenses. The results show that TNC-Defense improves the average detection accuracy by $11\\%$ with negligible additional overhead, and invalidates an average of $98.5\\%$ of triggered samples with only a mild degradation in generation quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTNC-Defense\u6846\u67b6\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u4e2d\u65f6\u95f4\u566a\u58f0\u4e0d\u4e00\u81f4\u6027\u73b0\u8c61\uff0c\u5b9e\u73b0\u540e\u95e8\u68c0\u6d4b\u4e0e\u53bb\u6bd2\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u62a4\u6a21\u578b\u53c2\u6570\u9690\u79c1\u7684\u7070\u76d2\u573a\u666f\u4e0b\u6709\u6548\u5de5\u4f5c\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728AIGC\u670d\u52a1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u4f9d\u8d56\u4e0d\u900f\u660e\u7684\u8bad\u7ec3\u6570\u636e\u548c\u6d41\u7a0b\u5b58\u5728\u540e\u95e8\u6ce8\u5165\u98ce\u9669\u3002\u5b9e\u9645\u5ba1\u8ba1\u573a\u666f\u4e2d\uff0c\u7531\u4e8e\u77e5\u8bc6\u4ea7\u6743\u548c\u5546\u4e1a\u673a\u5bc6\u4fdd\u62a4\uff0c\u5ba1\u8ba1\u8005\u901a\u5e38\u65e0\u6cd5\u8bbf\u95ee\u6a21\u578b\u53c2\u6570\uff0c\u73b0\u6709\u767d\u76d2\u6216\u67e5\u8be2\u5bc6\u96c6\u578b\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u5b9e\u7528\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5373\u4f7f\u68c0\u6d4b\u5230\u540e\u95e8\uff0c\u73b0\u6709\u53bb\u6bd2\u65b9\u6cd5\u5f80\u5f80\u5728\u53bb\u6bd2\u6548\u679c\u548c\u751f\u6210\u8d28\u91cf\u4e4b\u95f4\u9677\u5165\u4e24\u96be\u3002", "method": "\u57fa\u4e8e\u53d1\u73b0\u7684\u65f6\u95f4\u566a\u58f0\u4e0d\u4e00\u81f4\u6027\u73b0\u8c61\uff08\u89e6\u53d1\u8f93\u5165\u65f6\u76f8\u90bb\u6269\u6563\u65f6\u95f4\u6b65\u7684\u566a\u58f0\u9884\u6d4b\u5728\u7279\u5b9a\u65f6\u95f4\u7247\u6bb5\u88ab\u7834\u574f\uff09\uff0c\u63d0\u51faTNC-Defense\u7edf\u4e00\u6846\u67b6\uff1a1\uff09\u7070\u76d2\u68c0\u6d4b\u6a21\u5757\uff1a\u5229\u7528\u76f8\u90bb\u65f6\u95f4\u6b65\u566a\u58f0\u4e00\u81f4\u6027\u8bbe\u8ba1\u68c0\u6d4b\u65b9\u6cd5\uff0c\u8bc6\u522b\u548c\u5b9a\u4f4d\u5f02\u5e38\u6269\u6563\u65f6\u95f4\u6b65\uff1b2\uff09\u53bb\u6bd2\u6a21\u5757\uff1a\u4f7f\u7528\u8bc6\u522b\u7684\u5f02\u5e38\u65f6\u95f4\u6b65\u6784\u5efa\u89e6\u53d1\u65e0\u5173\u3001\u65f6\u95f4\u6b65\u611f\u77e5\u7684\u53bb\u6bd2\u6a21\u5757\uff0c\u76f4\u63a5\u7ea0\u6b63\u540e\u95e8\u751f\u6210\u8def\u5f84\u3002", "result": "\u5728\u4e94\u79cd\u4ee3\u8868\u6027\u540e\u95e8\u653b\u51fb\u573a\u666f\u4e0b\u8bc4\u4f30\uff0cTNC-Defense\u5c06\u5e73\u5747\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u9ad811%\uff0c\u989d\u5916\u5f00\u9500\u53ef\u5ffd\u7565\uff1b\u5e73\u5747\u4f7f98.5%\u7684\u89e6\u53d1\u6837\u672c\u5931\u6548\uff0c\u4ec5\u5bf9\u751f\u6210\u8d28\u91cf\u9020\u6210\u8f7b\u5fae\u4e0b\u964d\u3002", "conclusion": "TNC-Defense\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u540e\u95e8\u68c0\u6d4b\u4e0e\u53bb\u6bd2\u7684\u96be\u9898\uff0c\u5728\u4fdd\u62a4\u6a21\u578b\u53c2\u6570\u9690\u79c1\u7684\u7070\u76d2\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6548\u68c0\u6d4b\u548c\u6709\u6548\u53bb\u6bd2\uff0c\u5e73\u8861\u4e86\u53bb\u6bd2\u6548\u679c\u4e0e\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2602.00709", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00709", "abs": "https://arxiv.org/abs/2602.00709", "authors": ["Wenda Li", "Tongya Zheng", "Kaixuan Chen", "Shunyu Liu", "Haoze Jiang", "Yunzhi Hao", "Rui Miao", "Zujie Ren", "Mingli Song", "Hang Shi", "Gang Chen"], "title": "Physics-informed Diffusion Generation for Geomagnetic Map Interpolation", "comment": "5 pages, 2 figures, IEEE ICASSP'26", "summary": "Geomagnetic map interpolation aims to infer unobserved geomagnetic data at spatial points, yielding critical applications in navigation and resource exploration. However, existing methods for scattered data interpolation are not specifically designed for geomagnetic maps, which inevitably leads to suboptimal performance due to detection noise and the laws of physics. Therefore, we propose a Physics-informed Diffusion Generation framework~(PDG) to interpolate incomplete geomagnetic maps. First, we design a physics-informed mask strategy to guide the diffusion generation process based on a local receptive field, effectively eliminating noise interference. Second, we impose a physics-informed constraint on the diffusion generation results following the kriging principle of geomagnetic maps, ensuring strict adherence to the laws of physics. Extensive experiments and in-depth analyses on four real-world datasets demonstrate the superiority and effectiveness of each component of PDG.", "AI": {"tldr": "\u63d0\u51faPDG\u6846\u67b6\uff0c\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u5f15\u5bfc\u7684\u6269\u6563\u751f\u6210\u6a21\u578b\u8fdb\u884c\u5730\u78c1\u5730\u56fe\u63d2\u503c\uff0c\u7ed3\u5408\u5c40\u90e8\u611f\u53d7\u91ce\u548c\u514b\u91cc\u91d1\u539f\u7406\u7ea6\u675f\uff0c\u6709\u6548\u5904\u7406\u566a\u58f0\u5e76\u4fdd\u8bc1\u7269\u7406\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u6563\u70b9\u6570\u636e\u63d2\u503c\u65b9\u6cd5\u672a\u4e13\u95e8\u9488\u5bf9\u5730\u78c1\u5730\u56fe\u8bbe\u8ba1\uff0c\u53d7\u68c0\u6d4b\u566a\u58f0\u548c\u7269\u7406\u89c4\u5f8b\u5f71\u54cd\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5730\u78c1\u5730\u56fe\u63d2\u503c\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7269\u7406\u4fe1\u606f\u6269\u6563\u751f\u6210\u6846\u67b6(PDG)\uff1a1) \u57fa\u4e8e\u5c40\u90e8\u611f\u53d7\u91ce\u8bbe\u8ba1\u7269\u7406\u4fe1\u606f\u63a9\u7801\u7b56\u7565\u6307\u5bfc\u6269\u6563\u751f\u6210\u8fc7\u7a0b\uff0c\u6d88\u9664\u566a\u58f0\u5e72\u6270\uff1b2) \u9075\u5faa\u5730\u78c1\u5730\u56fe\u514b\u91cc\u91d1\u539f\u7406\u5bf9\u6269\u6563\u751f\u6210\u7ed3\u679c\u65bd\u52a0\u7269\u7406\u4fe1\u606f\u7ea6\u675f\uff0c\u786e\u4fdd\u4e25\u683c\u9075\u5faa\u7269\u7406\u89c4\u5f8b\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u548c\u6df1\u5165\u5206\u6790\u8bc1\u660e\u4e86PDG\u7684\u4f18\u8d8a\u6027\u548c\u5404\u7ec4\u6210\u90e8\u5206\u7684\u6709\u6548\u6027\u3002", "conclusion": "PDG\u6846\u67b6\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u5f15\u5bfc\u7684\u6269\u6563\u751f\u6210\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5730\u78c1\u5730\u56fe\u63d2\u503c\u95ee\u9898\uff0c\u5728\u6d88\u9664\u566a\u58f0\u5e72\u6270\u7684\u540c\u65f6\u4fdd\u8bc1\u7269\u7406\u4e00\u81f4\u6027\uff0c\u4e3a\u5bfc\u822a\u548c\u8d44\u6e90\u52d8\u63a2\u63d0\u4f9b\u91cd\u8981\u652f\u6301\u3002"}}
{"id": "2602.02419", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02419", "abs": "https://arxiv.org/abs/2602.02419", "authors": ["Qingni Wang", "Yue Fan", "Xin Eric Wang"], "title": "SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration", "comment": null, "summary": "Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38\\% percentage points over Gemini-only inference.", "AI": {"tldr": "SafeGround\u662f\u4e00\u4e2a\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684GUI grounding\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5e03\u611f\u77e5\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u548c\u6821\u51c6\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u98ce\u9669\u611f\u77e5\u9884\u6d4b\u548c\u7edf\u8ba1\u4fdd\u8bc1\u7684\u8bef\u53d1\u73b0\u7387\u63a7\u5236\u3002", "motivation": "GUI grounding\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684\u5c4f\u5e55\u5750\u6807\uff0c\u4f46\u9519\u8bef\u7684grounding\u53ef\u80fd\u5bfc\u81f4\u4ee3\u4ef7\u9ad8\u6602\u4e14\u96be\u4ee5\u9006\u8f6c\u7684\u64cd\u4f5c\uff08\u5982\u9519\u8bef\u7684\u652f\u4ed8\u6279\u51c6\uff09\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u9ad8\u6a21\u578b\u53ef\u9760\u6027\u3002", "method": "SafeGround\u91c7\u7528\u5206\u5e03\u611f\u77e5\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u6355\u6349\u6a21\u578b\u8f93\u51fa\u7684\u7a7a\u95f4\u5206\u6563\u6027\uff0c\u901a\u8fc7\u6821\u51c6\u8fc7\u7a0b\u63a8\u5bfc\u51fa\u5177\u6709\u7edf\u8ba1\u4fdd\u8bc1\u8bef\u53d1\u73b0\u7387\u63a7\u5236\u7684\u6d4b\u8bd5\u65f6\u51b3\u7b56\u9608\u503c\u3002", "result": "\u5728ScreenSpot-Pro\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSafeGround\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u5728\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u9884\u6d4b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u6821\u51c6\u9608\u503c\u5b9e\u73b0\u4e86\u4e25\u683c\u7684\u98ce\u9669\u63a7\u5236\uff0c\u7cfb\u7edf\u7ea7\u51c6\u786e\u7387\u76f8\u6bd4Gemini-only\u63a8\u7406\u63d0\u5347\u9ad8\u8fbe5.38%\u3002", "conclusion": "SafeGround\u4e3aGUI grounding\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u98ce\u9669\u611f\u77e5\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u7edf\u8ba1\u6821\u51c6\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u98ce\u9669\u63a7\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u7ea7\u51c6\u786e\u7387\u3002"}}
{"id": "2602.01795", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01795", "abs": "https://arxiv.org/abs/2602.01795", "authors": ["Mingrui Liu", "Sixiao Zhang", "Cheng Long", "Kwok-Yan Lam"], "title": "RedVisor: Reasoning-Aware Prompt Injection Defense via Zero-Copy KV Cache Reuse", "comment": "under review", "summary": "Large Language Models (LLMs) are increasingly vulnerable to Prompt Injection (PI) attacks, where adversarial instructions hidden within retrieved contexts hijack the model's execution flow. Current defenses typically face a critical trade-off: prevention-based fine-tuning often degrades general utility via the \"alignment tax\", while detection-based filtering incurs prohibitive latency and memory costs. To bridge this gap, we propose RedVisor, a unified framework that synthesizes the explainability of detection systems with the seamless integration of prevention strategies. To the best of our knowledge, RedVisor is the first approach to leverage fine-grained reasoning paths to simultaneously detect attacks and guide the model's safe response. We implement this via a lightweight, removable adapter positioned atop the frozen backbone. This adapter serves a dual function: it first generates an explainable analysis that precisely localizes the injection and articulates the threat, which then explicitly conditions the model to reject the malicious command. Uniquely, the adapter is active only during this reasoning phase and is effectively muted during the subsequent response generation. This architecture yields two distinct advantages: (1) it mathematically preserves the backbone's original utility on benign inputs; and (2) it enables a novel KV Cache Reuse strategy, eliminating the redundant prefill computation inherent to decoupled pipelines. We further pioneer the integration of this defense into the vLLM serving engine with custom kernels. Experiments demonstrate that RedVisor outperforms state-of-the-art defenses in detection accuracy and throughput while incurring negligible utility loss.", "AI": {"tldr": "RedVisor\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u53ef\u79fb\u9664\u9002\u914d\u5668\u540c\u65f6\u5b9e\u73b0\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u68c0\u6d4b\u548c\u6a21\u578b\u5b89\u5168\u54cd\u5e94\uff0c\u5728\u4fdd\u6301\u9aa8\u5e72\u6a21\u578b\u539f\u59cb\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u9632\u5fa1\u6548\u7387\u3002", "motivation": "\u5f53\u524dLLM\u9632\u5fa1\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u9762\u4e34\u4e24\u96be\uff1a\u57fa\u4e8e\u9884\u9632\u7684\u5fae\u8c03\u4f1a\u964d\u4f4e\u901a\u7528\u6027\u80fd\uff08\"\u5bf9\u9f50\u7a0e\"\uff09\uff0c\u800c\u57fa\u4e8e\u68c0\u6d4b\u7684\u8fc7\u6ee4\u5219\u5e26\u6765\u9ad8\u5ef6\u8fdf\u548c\u5185\u5b58\u6210\u672c\u3002\u9700\u8981\u4e00\u79cd\u80fd\u517c\u987e\u68c0\u6d4b\u53ef\u89e3\u91ca\u6027\u548c\u65e0\u7f1d\u96c6\u6210\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faRedVisor\u6846\u67b6\uff0c\u5728\u51bb\u7ed3\u9aa8\u5e72\u6a21\u578b\u4e0a\u90e8\u7f72\u8f7b\u91cf\u7ea7\u53ef\u79fb\u9664\u9002\u914d\u5668\u3002\u9002\u914d\u5668\u9996\u5148\u751f\u6210\u53ef\u89e3\u91ca\u5206\u6790\uff0c\u7cbe\u786e\u5b9a\u4f4d\u6ce8\u5165\u5e76\u9610\u660e\u5a01\u80c1\uff0c\u7136\u540e\u663e\u5f0f\u6307\u5bfc\u6a21\u578b\u62d2\u7edd\u6076\u610f\u6307\u4ee4\u3002\u9002\u914d\u5668\u4ec5\u5728\u63a8\u7406\u9636\u6bb5\u6fc0\u6d3b\uff0c\u5728\u540e\u7eed\u54cd\u5e94\u751f\u6210\u65f6\u9759\u9ed8\uff0c\u5b9e\u73b0KV\u7f13\u5b58\u91cd\u7528\u7b56\u7565\u3002", "result": "RedVisor\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u541e\u5410\u91cf\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\uff0c\u540c\u65f6\u5e26\u6765\u53ef\u5ffd\u7565\u7684\u6548\u7528\u635f\u5931\u3002\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u4fdd\u6301\u9aa8\u5e72\u6a21\u578b\u5728\u826f\u6027\u8f93\u5165\u4e0a\u7684\u539f\u59cb\u6027\u80fd\uff0c\u5e76\u96c6\u6210\u5230vLLM\u670d\u52a1\u5f15\u64ce\u4e2d\u3002", "conclusion": "RedVisor\u6210\u529f\u89e3\u51b3\u4e86\u63d0\u793a\u6ce8\u5165\u9632\u5fa1\u4e2d\u7684\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u5b9e\u73b0\u4e86\u68c0\u6d4b\u53ef\u89e3\u91ca\u6027\u548c\u9884\u9632\u7b56\u7565\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u9632\u5fa1\u6548\u7387\u3002"}}
{"id": "2602.00710", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00710", "abs": "https://arxiv.org/abs/2602.00710", "authors": ["Yueqi Zhang", "Jin Hu", "Shaoxiong Feng", "Peiwen Yuan", "Xinglin Wang", "Yiwei Li", "Jiayi Shi", "Chuyi Tan", "Ji Zhang", "Boyuan Pan", "Yao Hu", "Kan Li"], "title": "Learning More from Less: Unlocking Internal Representations for Benchmark Compression", "comment": null, "summary": "The prohibitive cost of evaluating Large Language Models (LLMs) necessitates efficient alternatives to full-scale benchmarking. Prevalent approaches address this by identifying a small coreset of items to approximate full-benchmark performance. However, existing methods must estimate a reliable item profile from response patterns across many source models, which becomes statistically unstable when the source pool is small. This dependency is particularly limiting for newly released benchmarks with minimal historical evaluation data. We argue that discrete correctness labels are a lossy view of the model's decision process and fail to capture information encoded in hidden states. To address this, we introduce REPCORE, which aligns heterogeneous hidden states into a unified latent space to construct representative coresets. Using these subsets for performance extrapolation, REPCORE achieves precise estimation accuracy with as few as ten source models. Experiments on five benchmarks and over 200 models show consistent gains over output-based baselines in ranking correlation and estimation accuracy. Spectral analysis further indicates that the aligned representations contain separable components reflecting broad response tendencies and task-specific reasoning patterns.", "AI": {"tldr": "REPCORE\u901a\u8fc7\u5c06\u5f02\u6784\u9690\u85cf\u72b6\u6001\u5bf9\u9f50\u5230\u7edf\u4e00\u6f5c\u5728\u7a7a\u95f4\u6765\u6784\u5efa\u4ee3\u8868\u6027\u6838\u5fc3\u96c6\uff0c\u4ec5\u970010\u4e2a\u6e90\u6a21\u578b\u5373\u53ef\u7cbe\u786e\u4f30\u8ba1LLM\u6027\u80fd\uff0c\u4f18\u4e8e\u57fa\u4e8e\u8f93\u51fa\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u9ad8\u6548\u7684\u57fa\u51c6\u6d4b\u8bd5\u66ff\u4ee3\u65b9\u6848\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6e90\u6a21\u578b\u6765\u4f30\u8ba1\u53ef\u9760\u7684\u9879\u914d\u7f6e\u6587\u4ef6\uff0c\u8fd9\u5728\u6e90\u6a21\u578b\u6c60\u8f83\u5c0f\u65f6\u7edf\u8ba1\u4e0d\u7a33\u5b9a\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u65b0\u53d1\u5e03\u7684\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u5386\u53f2\u8bc4\u4f30\u6570\u636e\u3002\u6b64\u5916\uff0c\u79bb\u6563\u6b63\u786e\u6027\u6807\u7b7e\u662f\u6a21\u578b\u51b3\u7b56\u8fc7\u7a0b\u7684\u635f\u5931\u6027\u89c6\u56fe\uff0c\u65e0\u6cd5\u6355\u6349\u9690\u85cf\u72b6\u6001\u4e2d\u7684\u4fe1\u606f\u3002", "method": "\u63d0\u51faREPCORE\u65b9\u6cd5\uff0c\u5c06\u5f02\u6784\u9690\u85cf\u72b6\u6001\u5bf9\u9f50\u5230\u7edf\u4e00\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\uff0c\u6784\u5efa\u4ee3\u8868\u6027\u6838\u5fc3\u96c6\u3002\u901a\u8fc7\u4f7f\u7528\u8fd9\u4e9b\u5b50\u96c6\u8fdb\u884c\u6027\u80fd\u5916\u63a8\uff0c\u4ec5\u9700\u5c11\u91cf\u6e90\u6a21\u578b\u5373\u53ef\u5b9e\u73b0\u7cbe\u786e\u4f30\u8ba1\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u8d85\u8fc7200\u4e2a\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cREPCORE\u5728\u6392\u540d\u76f8\u5173\u6027\u548c\u4f30\u8ba1\u51c6\u786e\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8e\u8f93\u51fa\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u8c31\u5206\u6790\u8fdb\u4e00\u6b65\u8868\u660e\uff0c\u5bf9\u9f50\u8868\u793a\u5305\u542b\u53ef\u5206\u79bb\u7684\u7ec4\u4ef6\uff0c\u53cd\u6620\u4e86\u5e7f\u6cdb\u7684\u54cd\u5e94\u503e\u5411\u548c\u4efb\u52a1\u7279\u5b9a\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "conclusion": "REPCORE\u901a\u8fc7\u5229\u7528\u9690\u85cf\u72b6\u6001\u4fe1\u606f\u800c\u975e\u4ec5\u4f9d\u8d56\u8f93\u51fa\u6807\u7b7e\uff0c\u89e3\u51b3\u4e86\u5c0f\u6e90\u6a21\u578b\u6c60\u4e0b\u7684\u7edf\u8ba1\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u4e3a\u9ad8\u6548\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u65b0\u53d1\u5e03\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2602.01932", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01932", "abs": "https://arxiv.org/abs/2602.01932", "authors": ["Kristopher Alex Schlett", "Bela Genge", "Savio Sciancalepore"], "title": "Things that Matter -- Identifying Interactions and IoT Device Types in Encrypted Matter Traffic", "comment": "11 pages, 1 figure, 12 tables", "summary": "Matter is the most recent application-layer standard for the Internet of Things (IoT). As one of its major selling points, Matter's design imposes particular attention to security and privacy: it provides validated secure session establishment protocols, and it uses robust security algorithms to secure communications between IoT devices and Matter controllers. However, to our knowledge, there is no systematic analysis investigating the extent to which a passive attacker, in possession of lower layer keys or exploiting security misconfiguration at those layers, could infer information by passively analyzing encrypted Matter traffic. In this paper, we fill this gap by analyzing the robustness of the Matter IoT standard to encrypted traffic analysis performed by a passive eavesdropper. By using various datasets collected from real-world testbeds and simulated setups, we identify patterns in metadata of the encrypted Matter traffic that allow inferring the specific interactions occurring between end devices and controllers. Moreover, we associate patterns in sequences of interactions to specific types of IoT devices. These patterns can be used to create fingerprints that allow a passive attacker to infer the type of devices used in the network, constituting a serious breach of users privacy. Our results reveal that we can identify specific Matter interactions that occur in encrypted traffic with over $95\\%$ accuracy also in the presence of packet losses and delays. Moreover, we can identify Matter device types with a minimum accuracy of $88\\%$. The CSA acknowledged our findings, and expressed the willingness to address such vulnerabilities in the next releases of the standard.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u52a0\u5bc6\u7684Matter\u7269\u8054\u7f51\u6d41\u91cf\uff0c\u53d1\u73b0\u88ab\u52a8\u653b\u51fb\u8005\u53ef\u4ee5\u901a\u8fc7\u6d41\u91cf\u5143\u6570\u636e\u6a21\u5f0f\u63a8\u65ad\u8bbe\u5907\u4ea4\u4e92\u548c\u8bbe\u5907\u7c7b\u578b\uff0c\u5bf9\u7528\u6237\u9690\u79c1\u6784\u6210\u4e25\u91cd\u5a01\u80c1\u3002", "motivation": "Matter\u4f5c\u4e3a\u6700\u65b0\u7684\u7269\u8054\u7f51\u5e94\u7528\u5c42\u6807\u51c6\uff0c\u867d\u7136\u5f3a\u8c03\u5b89\u5168\u6027\u548c\u9690\u79c1\u4fdd\u62a4\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u88ab\u52a8\u653b\u51fb\u8005\u901a\u8fc7\u5206\u6790\u52a0\u5bc6\u6d41\u91cf\u6765\u63a8\u65ad\u4fe1\u606f\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u8bc4\u4f30Matter\u6807\u51c6\u5bf9\u52a0\u5bc6\u6d41\u91cf\u5206\u6790\u7684\u9c81\u68d2\u6027\u3002", "method": "\u4f7f\u7528\u4ece\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\u5e73\u53f0\u548c\u6a21\u62df\u8bbe\u7f6e\u6536\u96c6\u7684\u5404\u79cd\u6570\u636e\u96c6\uff0c\u5206\u6790\u52a0\u5bc6Matter\u6d41\u91cf\u7684\u5143\u6570\u636e\u6a21\u5f0f\u3002\u8bc6\u522b\u5141\u8bb8\u63a8\u65ad\u7ec8\u7aef\u8bbe\u5907\u4e0e\u63a7\u5236\u5668\u4e4b\u95f4\u7279\u5b9a\u4ea4\u4e92\u7684\u6a21\u5f0f\uff0c\u5e76\u5c06\u4ea4\u4e92\u5e8f\u5217\u6a21\u5f0f\u4e0e\u7279\u5b9a\u7c7b\u578b\u7684\u7269\u8054\u7f51\u8bbe\u5907\u5173\u8054\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53ef\u4ee5\u4ee5\u8d85\u8fc795%\u7684\u51c6\u786e\u7387\u8bc6\u522b\u52a0\u5bc6\u6d41\u91cf\u4e2d\u7684\u7279\u5b9aMatter\u4ea4\u4e92\uff08\u5373\u4f7f\u5728\u5b58\u5728\u6570\u636e\u5305\u4e22\u5931\u548c\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\uff09\uff0c\u5e76\u4e14\u53ef\u4ee5\u4ee5\u81f3\u5c1188%\u7684\u51c6\u786e\u7387\u8bc6\u522bMatter\u8bbe\u5907\u7c7b\u578b\u3002CSA\u5df2\u627f\u8ba4\u8fd9\u4e9b\u53d1\u73b0\u5e76\u8868\u793a\u613f\u610f\u5728\u6807\u51c6\u7684\u4e0b\u4e00\u4e2a\u7248\u672c\u4e2d\u89e3\u51b3\u8fd9\u4e9b\u6f0f\u6d1e\u3002", "conclusion": "Matter\u6807\u51c6\u867d\u7136\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u52a0\u5bc6\u901a\u4fe1\uff0c\u4f46\u5176\u52a0\u5bc6\u6d41\u91cf\u4e2d\u7684\u5143\u6570\u636e\u6a21\u5f0f\u4ecd\u7136\u53ef\u4ee5\u88ab\u88ab\u52a8\u653b\u51fb\u8005\u5229\u7528\u6765\u63a8\u65ad\u8bbe\u5907\u4ea4\u4e92\u548c\u8bbe\u5907\u7c7b\u578b\uff0c\u6784\u6210\u4e25\u91cd\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u6807\u51c6\u4ee5\u62b5\u5fa1\u6b64\u7c7b\u52a0\u5bc6\u6d41\u91cf\u5206\u6790\u653b\u51fb\u3002"}}
{"id": "2602.00731", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.00731", "abs": "https://arxiv.org/abs/2602.00731", "authors": ["Kyle Hamilton", "Ali Intizar"], "title": "Neuro-symbolic AI for Predictive Maintenance (PdM) -- review and recommendations", "comment": null, "summary": "In this document we perform a systematic review the State-of-the-art in Predictive Maintenance (PdM) over the last five years in industrial settings such as commercial buildings, pharmaceutical facilities, or semi-conductor manufacturing. In general, data-driven methods such as those based on deep learning, exhibit higher accuracy than traditional knowledge-based systems. These systems however, are not without significant limitations. The need for large labeled data sets, a lack of generalizibility to new environments (out-of-distribution generalization), and a lack of transparency at inference time are some of the obstacles to adoption in real world environments. In contrast, traditional approaches based on domain expertise in the form of rules, logic or first principles suffer from poor accuracy, many false positives and a need for ongoing expert supervision and manual tuning. While the majority of approaches in recent literature utilize some form of data-driven architecture, there are hybrid systems which also take into account domain specific knowledge. Such hybrid systems have the potential to overcome the weaknesses of either approach on its own while preserving their strengths. We propose taking the hybrid approach even further and integrating deep learning with symbolic logic, or Neuro-symbolic AI, to create more accurate, explainable, interpretable, and robust systems. We describe several neuro-symbolic architectures and examine their strengths and limitations within the PdM domain. We focus specifically on methods which involve the use of sensor data and manually crafted rules as inputs by describing concrete NeSy architectures. In short, this survey outlines the context of modern maintenance, defines key concepts, establishes a generalized framework, reviews current modeling approaches and challenges, and introduces the proposed focus on Neuro-symbolic AI (NESY).", "AI": {"tldr": "\u672c\u6587\u5bf9\u8fc7\u53bb\u4e94\u5e74\u5de5\u4e1a\u73af\u5883\u4e2d\u9884\u6d4b\u6027\u7ef4\u62a4\uff08PdM\uff09\u7684\u6700\u65b0\u8fdb\u5c55\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u63d0\u51fa\u5c06\u6df1\u5ea6\u5b66\u4e60\u4e0e\u7b26\u53f7\u903b\u8f91\u7ed3\u5408\u7684\u795e\u7ecf\u7b26\u53f7AI\u4f5c\u4e3a\u89e3\u51b3\u5f53\u524d\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5c40\u9650\u6027\u7684\u65b0\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u9884\u6d4b\u6027\u7ef4\u62a4\u9886\u57df\u5b58\u5728\u4e24\u5927\u95ee\u9898\uff1a\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff08\u5982\u6df1\u5ea6\u5b66\u4e60\uff09\u867d\u7136\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u3001\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff1b\u800c\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u7684\u4f20\u7edf\u65b9\u6cd5\u51c6\u786e\u7387\u4f4e\u3001\u8bef\u62a5\u591a\u3001\u9700\u8981\u4e13\u5bb6\u6301\u7eed\u76d1\u7763\u3002\u9700\u8981\u4e00\u79cd\u80fd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u8fc7\u53bb\u4e94\u5e74\u5de5\u4e1a\u73af\u5883\u4e2d\u9884\u6d4b\u6027\u7ef4\u62a4\u7684\u6700\u65b0\u7814\u7a76\u3002\u91cd\u70b9\u5173\u6ce8\u4f7f\u7528\u4f20\u611f\u5668\u6570\u636e\u548c\u4eba\u5de5\u89c4\u5219\u4f5c\u4e3a\u8f93\u5165\u7684\u795e\u7ecf\u7b26\u53f7AI\u67b6\u6784\uff0c\u63cf\u8ff0\u5177\u4f53\u7684\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u8bbe\u8ba1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u901a\u5e38\u6bd4\u4f20\u7edf\u77e5\u8bc6\u7cfb\u7edf\u66f4\u51c6\u786e\uff0c\u4f46\u5b58\u5728\u6807\u6ce8\u6570\u636e\u9700\u6c42\u5927\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u3001\u7f3a\u4e4f\u900f\u660e\u5ea6\u7b49\u5c40\u9650\u6027\u3002\u6df7\u5408\u7cfb\u7edf\uff08\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u548c\u9886\u57df\u77e5\u8bc6\uff09\u663e\u793a\u51fa\u514b\u670d\u5355\u4e00\u65b9\u6cd5\u5f31\u70b9\u7684\u6f5c\u529b\u3002\u795e\u7ecf\u7b26\u53f7AI\u88ab\u63d0\u51fa\u4f5c\u4e3a\u66f4\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u3001\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7AI\u901a\u8fc7\u6574\u5408\u6df1\u5ea6\u5b66\u4e60\u4e0e\u7b26\u53f7\u903b\u8f91\uff0c\u6709\u671b\u521b\u5efa\u66f4\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u89e3\u91ca\u4e14\u9c81\u68d2\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u7cfb\u7edf\u3002\u672c\u6587\u5efa\u7acb\u4e86\u901a\u7528\u6846\u67b6\uff0c\u56de\u987e\u4e86\u5f53\u524d\u5efa\u6a21\u65b9\u6cd5\u548c\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u795e\u7ecf\u7b26\u53f7AI\u4f5c\u4e3a\u672a\u6765\u7814\u7a76\u91cd\u70b9\u3002"}}
{"id": "2602.02147", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02147", "abs": "https://arxiv.org/abs/2602.02147", "authors": ["Jiayao Wang", "Yang Song", "Zhendong Zhao", "Jiale Zhang", "Qilin Wu", "Wenliang Yuan", "Junwu Zhu", "Dongfang Zhao"], "title": "HPE: Hallucinated Positive Entanglement for Backdoor Attacks in Federated Self-Supervised Learning", "comment": null, "summary": "Federated self-supervised learning (FSSL) enables collaborative training of self-supervised representation models without sharing raw unlabeled data. While it serves as a crucial paradigm for privacy-preserving learning, its security remains vulnerable to backdoor attacks, where malicious clients manipulate local training to inject targeted backdoors. Existing FSSL attack methods, however, often suffer from low utilization of poisoned samples, limited transferability, and weak persistence. To address these limitations, we propose a new backdoor attack method for FSSL, namely Hallucinated Positive Entanglement (HPE). HPE first employs hallucination-based augmentation using synthetic positive samples to enhance the encoder's embedding of backdoor features. It then introduces feature entanglement to enforce tight binding between triggers and backdoor samples in the representation space. Finally, selective parameter poisoning and proximity-aware updates constrain the poisoned model within the vicinity of the global model, enhancing its stability and persistence. Experimental results on several FSSL scenarios and datasets show that HPE significantly outperforms existing backdoor attack methods in performance and exhibits strong robustness under various defense mechanisms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHPE\uff08\u5e7b\u89c9\u6b63\u6837\u672c\u7ea0\u7f20\uff09\u7684\u8054\u90a6\u81ea\u76d1\u7763\u5b66\u4e60\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u6210\u6b63\u6837\u672c\u589e\u5f3a\u540e\u95e8\u7279\u5f81\u5d4c\u5165\uff0c\u7279\u5f81\u7ea0\u7f20\u5f3a\u5316\u89e6\u53d1\u5668\u4e0e\u540e\u95e8\u6837\u672c\u7684\u7ed1\u5b9a\uff0c\u9009\u62e9\u6027\u53c2\u6570\u4e2d\u6bd2\u548c\u90bb\u8fd1\u611f\u77e5\u66f4\u65b0\u63d0\u5347\u653b\u51fb\u7684\u7a33\u5b9a\u6027\u548c\u6301\u4e45\u6027\u3002", "motivation": "\u8054\u90a6\u81ea\u76d1\u7763\u5b66\u4e60\uff08FSSL\uff09\u867d\u7136\u80fd\u4fdd\u62a4\u9690\u79c1\uff0c\u4f46\u5176\u5b89\u5168\u6027\u5bb9\u6613\u53d7\u5230\u540e\u95e8\u653b\u51fb\u7684\u5a01\u80c1\u3002\u73b0\u6709FSSL\u653b\u51fb\u65b9\u6cd5\u5b58\u5728\u4e2d\u6bd2\u6837\u672c\u5229\u7528\u7387\u4f4e\u3001\u53ef\u8fc1\u79fb\u6027\u6709\u9650\u3001\u6301\u4e45\u6027\u5f31\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u653b\u51fb\u65b9\u6cd5\u6765\u63ed\u793a\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "HPE\u65b9\u6cd5\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u4f7f\u7528\u5408\u6210\u6b63\u6837\u672c\u8fdb\u884c\u5e7b\u89c9\u589e\u5f3a\uff0c\u63d0\u5347\u7f16\u7801\u5668\u5bf9\u540e\u95e8\u7279\u5f81\u7684\u5d4c\u5165\u80fd\u529b\uff1b2\uff09\u5f15\u5165\u7279\u5f81\u7ea0\u7f20\uff0c\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u5f3a\u5236\u89e6\u53d1\u5668\u4e0e\u540e\u95e8\u6837\u672c\u7d27\u5bc6\u7ed1\u5b9a\uff1b3\uff09\u91c7\u7528\u9009\u62e9\u6027\u53c2\u6570\u4e2d\u6bd2\u548c\u90bb\u8fd1\u611f\u77e5\u66f4\u65b0\uff0c\u5c06\u4e2d\u6bd2\u6a21\u578b\u7ea6\u675f\u5728\u5168\u5c40\u6a21\u578b\u9644\u8fd1\uff0c\u589e\u5f3a\u7a33\u5b9a\u6027\u548c\u6301\u4e45\u6027\u3002", "result": "\u5728\u591a\u4e2aFSSL\u573a\u666f\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cHPE\u5728\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u5404\u79cd\u9632\u5fa1\u673a\u5236\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "HPE\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709FSSL\u540e\u95e8\u653b\u51fb\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u8054\u90a6\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u653b\u51fb\u57fa\u51c6\uff0c\u63ed\u793a\u4e86FSSL\u7cfb\u7edf\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u7684\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2602.00780", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00780", "abs": "https://arxiv.org/abs/2602.00780", "authors": ["Yuting Huang", "Leilei Ding", "Zhipeng Tang", "Zenghuan Zhu", "Jiajun Deng", "Xinrui Lin", "Shuo Liu", "Haojie Ren", "Jianmin Ji", "Yanyong Zhang"], "title": "Environment-Aware Adaptive Pruning with Interleaved Inference Orchestration for Vision-Language-Action Models", "comment": "12 pages, 7 figures", "summary": "While Vision-Language-Action (VLA) models hold promise in embodied intelligence, their large parameter counts lead to substantial inference latency that hinders real-time manipulation, motivating parameter sparsification. However, as the environment evolves during VLA execution, the optimal sparsity patterns change accordingly. Static pruning lacks the adaptability required for environment dynamics, whereas fixed-interval dynamic layer pruning suffers from coarse granularity and high retraining overheads. To bridge this gap, we propose EcoVLA, a training-free, plug-and-play adaptive pruning framework that supports orthogonal combination with existing VLA acceleration methods. EcoVLA comprises two components: Environment-aware Adaptive Pruning (EAP) and Interleaved Inference Orchestration ($I^2O$). EAP is a lightweight adaptive channel pruning method that incorporates the temporal consistency of the physical environment to update sparsity patterns. $I^2O$ leverages the FLOPs bubbles inherent in VLA inference to schedule the pruning method in parallel, ensuring negligible impact on latency. Evaluated on diverse VLA models and benchmarks, EcoVLA delivers state-of-the-art performance, achieving up to 1.60$\\times$ speedup with only a 0.4% drop in success rate, and further reaches 2.18$\\times$ speedup with only a 0.5% degradation when combined with token pruning. We further validate the effectiveness of EcoVLA on real-world robots.", "AI": {"tldr": "EcoVLA\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u3001\u5373\u63d2\u5373\u7528\u7684\u81ea\u9002\u5e94\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u73af\u5883\u611f\u77e5\u81ea\u9002\u5e94\u526a\u679d\u548c\u4ea4\u9519\u63a8\u7406\u7f16\u6392\uff0c\u5728VLA\u6a21\u578b\u4e2d\u5b9e\u73b0\u52a8\u6001\u53c2\u6570\u7a00\u758f\u5316\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u4e14\u6027\u80fd\u635f\u5931\u6781\u5c0f\u3002", "motivation": "\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u53c2\u6570\u5e9e\u5927\u5bfc\u81f4\u63a8\u7406\u5ef6\u8fdf\u9ad8\uff0c\u963b\u788d\u5b9e\u65f6\u64cd\u4f5c\u3002\u9759\u6001\u526a\u679d\u65e0\u6cd5\u9002\u5e94\u73af\u5883\u52a8\u6001\u53d8\u5316\uff0c\u56fa\u5b9a\u95f4\u9694\u7684\u52a8\u6001\u5c42\u526a\u679d\u7c92\u5ea6\u7c97\u4e14\u91cd\u8bad\u7ec3\u5f00\u9500\u5927\uff0c\u9700\u8981\u81ea\u9002\u5e94\u526a\u679d\u65b9\u6848\u3002", "method": "\u63d0\u51faEcoVLA\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1a1) \u73af\u5883\u611f\u77e5\u81ea\u9002\u5e94\u526a\u679d(EAP)\uff1a\u8f7b\u91cf\u7ea7\u81ea\u9002\u5e94\u901a\u9053\u526a\u679d\u65b9\u6cd5\uff0c\u5229\u7528\u7269\u7406\u73af\u5883\u7684\u65f6\u95f4\u4e00\u81f4\u6027\u66f4\u65b0\u7a00\u758f\u6a21\u5f0f\uff1b2) \u4ea4\u9519\u63a8\u7406\u7f16\u6392(I\u00b2O)\uff1a\u5229\u7528VLA\u63a8\u7406\u4e2d\u7684FLOPs\u6c14\u6ce1\u5e76\u884c\u8c03\u5ea6\u526a\u679d\u65b9\u6cd5\uff0c\u5bf9\u5ef6\u8fdf\u5f71\u54cd\u53ef\u5ffd\u7565\u3002", "result": "\u5728\u591a\u79cdVLA\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEcoVLA\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff1a\u5355\u72ec\u4f7f\u7528\u53ef\u8fbe1.60\u500d\u52a0\u901f\u4e14\u6210\u529f\u7387\u4ec5\u4e0b\u964d0.4%\uff1b\u4e0etoken\u526a\u679d\u7ed3\u5408\u53ef\u8fbe2.18\u500d\u52a0\u901f\u4e14\u6027\u80fd\u4ec5\u4e0b\u964d0.5%\u3002\u5728\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "EcoVLA\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u526a\u679d\u6846\u67b6\uff0c\u80fd\u591f\u52a8\u6001\u9002\u5e94\u73af\u5883\u53d8\u5316\uff0c\u663e\u8457\u52a0\u901fVLA\u6a21\u578b\u63a8\u7406\uff0c\u4e14\u4e0e\u73b0\u6709\u52a0\u901f\u65b9\u6cd5\u6b63\u4ea4\u517c\u5bb9\uff0c\u4e3a\u5b9e\u65f6\u673a\u5668\u4eba\u64cd\u4f5c\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00785", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00785", "abs": "https://arxiv.org/abs/2602.00785", "authors": ["Sherry Yang"], "title": "World Models as an Intermediary between Agents and the Real World", "comment": null, "summary": "Large language model (LLM) agents trained using reinforcement learning has achieved superhuman performance in low-cost environments like games, mathematics, and coding. However, these successes have not translated to complex domains where the cost of interaction is high, such as the physical cost of running robots, the time cost of ML engineering, and the resource cost of scientific experiments. The true bottleneck for achieving the next level of agent performance for these complex and high-cost domains lies in the expense of executing actions to acquire reward signals. To address this gap, this paper argues that we should use world models as an intermediary between agents and the real world. We discuss how world models, viewed as models of dynamics, rewards, and task distributions, can overcome fundamental barriers of high-cost actions such as extreme off-policy learning and sample inefficiency in long-horizon tasks. Moreover, we demonstrate how world models can provide critical and rich learning signals to agents across a broad set of domains, including machine learning engineering, computer use, robotics, and AI for science. Lastly, we identify the challenges of building these world models and propose actionable items along dataset curation, architecture design, scaling, and evaluation of world models.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5728\u590d\u6742\u9ad8\u6210\u672c\u9886\u57df\u4f7f\u7528\u4e16\u754c\u6a21\u578b\u4f5c\u4e3a\u667a\u80fd\u4f53\u4e0e\u771f\u5b9e\u4e16\u754c\u7684\u4e2d\u4ecb\uff0c\u4ee5\u89e3\u51b3\u884c\u52a8\u6267\u884c\u6210\u672c\u9ad8\u6602\u7684\u74f6\u9888\u95ee\u9898\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e16\u754c\u6a21\u578b\u5728\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u3001\u8ba1\u7b97\u673a\u4f7f\u7528\u3001\u673a\u5668\u4eba\u548cAI\u79d1\u5b66\u7b49\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684LLM\u667a\u80fd\u4f53\u5728\u6e38\u620f\u3001\u6570\u5b66\u548c\u7f16\u7801\u7b49\u4f4e\u6210\u672c\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u673a\u5668\u4eba\u8fd0\u884c\u3001ML\u5de5\u7a0b\u65f6\u95f4\u548c\u79d1\u5b66\u5b9e\u9a8c\u8d44\u6e90\u7b49\u9ad8\u6210\u672c\u590d\u6742\u9886\u57df\u4e2d\u672a\u80fd\u53d6\u5f97\u7c7b\u4f3c\u6210\u529f\u3002\u771f\u6b63\u7684\u74f6\u9888\u5728\u4e8e\u6267\u884c\u884c\u52a8\u83b7\u53d6\u5956\u52b1\u4fe1\u53f7\u7684\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u4e16\u754c\u6a21\u578b\u4f5c\u4e3a\u667a\u80fd\u4f53\u4e0e\u771f\u5b9e\u4e16\u754c\u7684\u4e2d\u4ecb\uff0c\u5c06\u4e16\u754c\u6a21\u578b\u89c6\u4e3a\u52a8\u6001\u3001\u5956\u52b1\u548c\u4efb\u52a1\u5206\u5e03\u7684\u6a21\u578b\u3002\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u514b\u670d\u9ad8\u6210\u672c\u884c\u52a8\u7684\u57fa\u672c\u969c\u788d\uff0c\u5982\u6781\u7aef\u79bb\u7b56\u7565\u5b66\u4e60\u548c\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u7684\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\u3002", "result": "\u4e16\u754c\u6a21\u578b\u80fd\u591f\u4e3a\u667a\u80fd\u4f53\u63d0\u4f9b\u5173\u952e\u4e14\u4e30\u5bcc\u7684\u5b66\u4e60\u4fe1\u53f7\uff0c\u9002\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u3001\u8ba1\u7b97\u673a\u4f7f\u7528\u3001\u673a\u5668\u4eba\u548cAI\u79d1\u5b66\u7b49\u591a\u4e2a\u9886\u57df\u3002\u540c\u65f6\u8bc6\u522b\u4e86\u6784\u5efa\u8fd9\u4e9b\u4e16\u754c\u6a21\u578b\u9762\u4e34\u7684\u6311\u6218\u3002", "conclusion": "\u4e3a\u4e86\u5728\u590d\u6742\u9ad8\u6210\u672c\u9886\u57df\u5b9e\u73b0\u4e0b\u4e00\u4ee3\u667a\u80fd\u4f53\u6027\u80fd\uff0c\u9700\u8981\u5728\u6570\u636e\u96c6\u7ba1\u7406\u3001\u67b6\u6784\u8bbe\u8ba1\u3001\u6269\u5c55\u548c\u8bc4\u4f30\u7b49\u65b9\u9762\u91c7\u53d6\u5177\u4f53\u884c\u52a8\u6765\u6784\u5efa\u6709\u6548\u7684\u4e16\u754c\u6a21\u578b\uff0c\u4f5c\u4e3a\u8fde\u63a5\u667a\u80fd\u4f53\u4e0e\u771f\u5b9e\u4e16\u754c\u7684\u6865\u6881\u3002"}}
{"id": "2602.00811", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00811", "abs": "https://arxiv.org/abs/2602.00811", "authors": ["Ronghao Lin", "Honghao Lu", "Ruixing Wu", "Aolin Xiong", "Qinggong Chu", "Qiaolin He", "Sijie Mai", "Haifeng Hu"], "title": "MissMAC-Bench: Building Solid Benchmark for Missing Modality Issue in Robust Multimodal Affective Computing", "comment": null, "summary": "As a knowledge discovery task over heterogeneous data sources, current Multimodal Affective Computing (MAC) heavily rely on the completeness of multiple modalities to accurately understand human's affective state. However, in real-world scenarios, the availability of modality data is often dynamic and uncertain, leading to substantial performance fluctuations due to the distribution shifts and semantic deficiencies of the incomplete multimodal inputs. Known as the missing modality issue, this challenge poses a critical barrier to the robustness and practical deployment of MAC models. To systematically quantify this issue, we introduce MissMAC-Bench, a comprehensive benchmark designed to establish fair and unified evaluation standards from the perspective of cross-modal synergy. Two guiding principles are proposed, including no missing prior during training, and one single model capable of handling both complete and incomplete modality scenarios, thereby ensuring better generalization. Moreover, to bridge the gap between academic research and real-world applications, our benchmark integrates evaluation protocols with both fixed and random missing patterns at the dataset and instance levels. Extensive experiments conducted on 3 widely-used language models across 4 datasets validate the effectiveness of diverse MAC approaches in tackling the missing modality issue. Our benchmark provides a solid foundation for advancing robust multimodal affective computing and promotes the development of multimedia data mining.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MissMAC-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u4e2d\u7684\u7f3a\u5931\u6a21\u6001\u95ee\u9898\uff0c\u901a\u8fc7\u7edf\u4e00\u8bc4\u4f30\u6807\u51c6\u548c\u8de8\u6a21\u6001\u534f\u540c\u89c6\u89d2\u6765\u89e3\u51b3\u5b9e\u9645\u5e94\u7528\u4e2d\u6a21\u6001\u6570\u636e\u4e0d\u5b8c\u6574\u5e26\u6765\u7684\u6027\u80fd\u6ce2\u52a8\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u591a\u6a21\u6001\u6570\u636e\u7684\u53ef\u7528\u6027\u5f80\u5f80\u662f\u52a8\u6001\u548c\u4e0d\u786e\u5b9a\u7684\uff0c\u7531\u4e8e\u5206\u5e03\u504f\u79fb\u548c\u8bed\u4e49\u7f3a\u9677\uff0c\u4e0d\u5b8c\u6574\u7684\u591a\u6a21\u6001\u8f93\u5165\u4f1a\u5bfc\u81f4\u6027\u80fd\u5927\u5e45\u6ce2\u52a8\u3002\u8fd9\u79cd\u7f3a\u5931\u6a21\u6001\u95ee\u9898\u662f\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u6a21\u578b\u9c81\u68d2\u6027\u548c\u5b9e\u9645\u90e8\u7f72\u7684\u5173\u952e\u969c\u788d\u3002", "method": "\u63d0\u51fa\u4e86MissMAC-Bench\u57fa\u51c6\uff0c\u5efa\u7acb\u516c\u5e73\u7edf\u4e00\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u57fa\u4e8e\u8de8\u6a21\u6001\u534f\u540c\u89c6\u89d2\u3002\u63d0\u51fa\u4e24\u4e2a\u6307\u5bfc\u539f\u5219\uff1a\u8bad\u7ec3\u65f6\u4e0d\u4f7f\u7528\u7f3a\u5931\u5148\u9a8c\uff0c\u5355\u4e00\u6a21\u578b\u80fd\u540c\u65f6\u5904\u7406\u5b8c\u6574\u548c\u4e0d\u5b8c\u6574\u6a21\u6001\u573a\u666f\u3002\u57fa\u51c6\u96c6\u6210\u4e86\u6570\u636e\u96c6\u548c\u5b9e\u4f8b\u7ea7\u522b\u7684\u56fa\u5b9a\u548c\u968f\u673a\u7f3a\u5931\u6a21\u5f0f\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u57284\u4e2a\u6570\u636e\u96c6\u4e0a\u5bf93\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u4e0d\u540cMAC\u65b9\u6cd5\u5728\u89e3\u51b3\u7f3a\u5931\u6a21\u6001\u95ee\u9898\u4e0a\u7684\u6709\u6548\u6027\u3002\u57fa\u51c6\u4e3a\u63a8\u8fdb\u9c81\u68d2\u7684\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\u3002", "conclusion": "MissMAC-Bench\u57fa\u51c6\u586b\u8865\u4e86\u5b66\u672f\u7814\u7a76\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4fc3\u8fdb\u4e86\u591a\u5a92\u4f53\u6570\u636e\u6316\u6398\u7684\u53d1\u5c55\uff0c\u4e3a\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u4e2d\u7684\u7f3a\u5931\u6a21\u6001\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2602.02243", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02243", "abs": "https://arxiv.org/abs/2602.02243", "authors": ["Dakshina Tharindu", "Aruna Jayasena", "Prabhat Mishra"], "title": "SysFuSS: System-Level Firmware Fuzzing with Selective Symbolic Execution", "comment": null, "summary": "Firmware serves as the critical interface between hardware and software in computing systems, making any bugs or vulnerabilities particularly dangerous as they can cause catastrophic system failures. While fuzzing is a promising approach for identifying design flaws and security vulnerabilities, traditional fuzzers are ineffective at detecting firmware vulnerabilities. For example, existing fuzzers focus on user-level fuzzing, which is not suitable for detecting kernel-level vulnerabilities. Existing fuzzers also face a coverage plateau problem when dealing with complex interactions between firmware and hardware. In this paper, we present an efficient firmware verification framework, SysFuSS, that integrates system-level fuzzing with selective symbolic execution. Our approach leverages system-level emulation for initial fuzzing, and automatically transitions to symbolic execution when coverage reaches a plateau. This strategy enables us to generate targeted test cases that can trigger previously unexplored regions in firmware designs. We have evaluated SysFuSS on real-world embedded firmware, including OpenSSL, WolfBoot, WolfMQTT, HTSlib, MXML, and libIEC. Experimental evaluation demonstrates that SysFuSS significantly outperforms state-of-the-art fuzzers in terms of both branch coverage and detection of firmware vulnerabilities. Specifically, SysFuSS can detect 118 known vulnerabilities while state-of-the-art can cover only 13 of them. Moreover, SysFuSS takes significantly less time (up to 3.3X, 1.7X on average) to activate these vulnerabilities.", "AI": {"tldr": "SysFuSS\u662f\u4e00\u4e2a\u7ed3\u5408\u7cfb\u7edf\u7ea7\u6a21\u7cca\u6d4b\u8bd5\u548c\u9009\u62e9\u6027\u7b26\u53f7\u6267\u884c\u7684\u56fa\u4ef6\u9a8c\u8bc1\u6846\u67b6\uff0c\u80fd\u6709\u6548\u68c0\u6d4b\u56fa\u4ef6\u6f0f\u6d1e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u5206\u652f\u8986\u76d6\u7387\u548c\u6f0f\u6d1e\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u56fa\u4ef6\u4f5c\u4e3a\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u786c\u4ef6\u548c\u8f6f\u4ef6\u7684\u5173\u952e\u63a5\u53e3\uff0c\u5176\u6f0f\u6d1e\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u7cfb\u7edf\u6545\u969c\u3002\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u5728\u68c0\u6d4b\u56fa\u4ef6\u6f0f\u6d1e\u65b9\u9762\u6548\u679c\u6709\u9650\uff0c\u5b58\u5728\u8986\u76d6\u74f6\u9888\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u56fa\u4ef6\u4e0e\u786c\u4ef6\u4e4b\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u3002", "method": "SysFuSS\u6846\u67b6\u6574\u5408\u4e86\u7cfb\u7edf\u7ea7\u6a21\u7cca\u6d4b\u8bd5\u548c\u9009\u62e9\u6027\u7b26\u53f7\u6267\u884c\u3002\u9996\u5148\u4f7f\u7528\u7cfb\u7edf\u7ea7\u4eff\u771f\u8fdb\u884c\u521d\u59cb\u6a21\u7cca\u6d4b\u8bd5\uff0c\u5f53\u8986\u76d6\u7387\u8fbe\u5230\u74f6\u9888\u65f6\u81ea\u52a8\u5207\u6362\u5230\u7b26\u53f7\u6267\u884c\uff0c\u751f\u6210\u9488\u5bf9\u6027\u7684\u6d4b\u8bd5\u7528\u4f8b\u4ee5\u63a2\u7d22\u56fa\u4ef6\u8bbe\u8ba1\u4e2d\u672a\u8986\u76d6\u7684\u533a\u57df\u3002", "result": "\u5728\u771f\u5b9e\u5d4c\u5165\u5f0f\u56fa\u4ef6\uff08\u5305\u62ecOpenSSL\u3001WolfBoot\u3001WolfMQTT\u3001HTSlib\u3001MXML\u548clibIEC\uff09\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cSysFuSS\u5728\u5206\u652f\u8986\u76d6\u7387\u548c\u56fa\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u3002SysFuSS\u80fd\u68c0\u6d4b118\u4e2a\u5df2\u77e5\u6f0f\u6d1e\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u8986\u76d6\u5176\u4e2d13\u4e2a\u3002\u6b64\u5916\uff0cSysFuSS\u6fc0\u6d3b\u8fd9\u4e9b\u6f0f\u6d1e\u6240\u9700\u65f6\u95f4\u663e\u8457\u51cf\u5c11\uff08\u6700\u591a3.3\u500d\uff0c\u5e73\u57471.7\u500d\uff09\u3002", "conclusion": "SysFuSS\u901a\u8fc7\u6574\u5408\u7cfb\u7edf\u7ea7\u6a21\u7cca\u6d4b\u8bd5\u548c\u9009\u62e9\u6027\u7b26\u53f7\u6267\u884c\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56fa\u4ef6\u9a8c\u8bc1\u4e2d\u7684\u8986\u76d6\u74f6\u9888\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fa\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u4e3a\u56fa\u4ef6\u5b89\u5168\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00815", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00815", "abs": "https://arxiv.org/abs/2602.00815", "authors": ["Yunjian Zhang", "Sudong Wang", "Yang Li", "Peiran Xu", "Conghao Zhou", "Xiaoyue Ma", "Jianing Li", "Yao Zhu"], "title": "Resource-Efficient Reinforcement for Reasoning Large Language Models via Dynamic One-Shot Policy Refinement", "comment": null, "summary": "Large language models (LLMs) have exhibited remarkable performance on complex reasoning tasks, with reinforcement learning under verifiable rewards (RLVR) emerging as a principled framework for aligning model behavior with reasoning chains. Despite its promise, RLVR remains prohibitively resource-intensive, requiring extensive reward signals and incurring substantial rollout costs during training. In this work, we revisit the fundamental question of data and compute efficiency in RLVR. We first establish a theoretical lower bound on the sample complexity required to unlock reasoning capabilities, and empirically validate that strong performance can be achieved with a surprisingly small number of training instances. To tackle the computational burden, we propose Dynamic One-Shot Policy Refinement (DoPR), an uncertainty-aware RL strategy that dynamically selects a single informative training sample per batch for policy updates, guided by reward volatility and exploration-driven acquisition. DoPR reduces rollout overhead by nearly an order of magnitude while preserving competitive reasoning accuracy, offering a scalable and resource-efficient solution for LLM post-training. This approach offers a practical path toward more efficient and accessible RL-based training for reasoning-intensive LLM applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDoPR\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u5355\u4e00\u6837\u672c\u8fdb\u884c\u7b56\u7565\u66f4\u65b0\uff0c\u5927\u5e45\u964d\u4f4eRLVR\u8bad\u7ec3\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u5728LLM\u63a8\u7406\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u8bad\u7ec3\u8fc7\u7a0b\u9700\u8981\u5927\u91cf\u5956\u52b1\u4fe1\u53f7\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u6210\u672c\u8fc7\u9ad8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u5355\u6b21\u7b56\u7565\u4f18\u5316\uff08DoPR\uff09\u65b9\u6cd5\uff1a1\uff09\u5efa\u7acb\u7406\u8bba\u4e0b\u754c\u5206\u6790\u6837\u672c\u590d\u6742\u5ea6\uff1b2\uff09\u57fa\u4e8e\u5956\u52b1\u6ce2\u52a8\u6027\u548c\u63a2\u7d22\u9a71\u52a8\u7684\u83b7\u53d6\u7b56\u7565\uff0c\u52a8\u6001\u9009\u62e9\u6bcf\u4e2a\u6279\u6b21\u4e2d\u6700\u5177\u4fe1\u606f\u91cf\u7684\u5355\u4e2a\u8bad\u7ec3\u6837\u672c\u8fdb\u884c\u7b56\u7565\u66f4\u65b0\u3002", "result": "DoPR\u5c06\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684rollout\u5f00\u9500\u964d\u4f4e\u4e86\u8fd1\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u63a8\u7406\u51c6\u786e\u6027\uff0c\u4e3aLLM\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u63a8\u7406\u5bc6\u96c6\u578bLLM\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u6613\u83b7\u53d6\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u8def\u5f84\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u667a\u80fd\u6837\u672c\u9009\u62e9\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u800c\u4e0d\u727a\u7272\u6027\u80fd\u3002"}}
{"id": "2602.02412", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.02412", "abs": "https://arxiv.org/abs/2602.02412", "authors": ["Apoorv Mohit", "Bhavya Aggarwal", "Chinmay Gondhalekar"], "title": "Provenance Verification of AI-Generated Images via a Perceptual Hash Registry Anchored on Blockchain", "comment": null, "summary": "The rapid advancement of artificial intelligence has made the generation of synthetic images widely accessible, increasing concerns related to misinformation, digital forgery, and content authenticity on large-scale online platforms. This paper proposes a blockchain-backed framework for verifying AI-generated images through a registry-based provenance mechanism. Each AI-generated image is assigned a digital fingerprint that preserves similarity using perceptual hashing and is registered at creation time by participating generation platforms. The hashes are stored on a hybrid on-chain/off-chain public blockchain using a Merkle Patricia Trie for tamper-resistant storage (on-chain) and a Burkhard-Keller tree (off-chain) to enable efficient similarity search over large image registries. Verification is performed when images are re-uploaded to digital platforms such as social media services, enabling identification of previously registered AI-generated images even after benign transformations or partial modifications. The proposed system does not aim to universally detect all synthetic images, but instead focuses on verifying the provenance of AI-generated content that has been registered at creation time. By design, this approach complements existing watermarking and learning-based detection methods, providing a platform-agnostic, tamper-proof mechanism for scalable content provenance and authenticity verification at the point of large-scale online distribution.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u533a\u5757\u94fe\u7684AI\u751f\u6210\u56fe\u50cf\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u518c\u673a\u5236\u8ffd\u8e2a\u5185\u5bb9\u6765\u6e90\uff0c\u4f7f\u7528\u611f\u77e5\u54c8\u5e0c\u548c\u6df7\u5408\u5b58\u50a8\u7ed3\u6784\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u9632\u7be1\u6539\u9a8c\u8bc1\u7cfb\u7edf", "motivation": "\u968f\u7740AI\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5408\u6210\u56fe\u50cf\u7684\u751f\u6210\u53d8\u5f97\u65e5\u76ca\u666e\u904d\uff0c\u8fd9\u5f15\u53d1\u4e86\u5173\u4e8e\u865a\u5047\u4fe1\u606f\u3001\u6570\u5b57\u4f2a\u9020\u548c\u5185\u5bb9\u771f\u5b9e\u6027\u7684\u62c5\u5fe7\u3002\u5728\u7ebf\u5e73\u53f0\u9700\u8981\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u9a8c\u8bc1AI\u751f\u6210\u5185\u5bb9\u7684\u6765\u6e90\u548c\u771f\u5b9e\u6027\u3002", "method": "\u63d0\u51fa\u533a\u5757\u94fe\u652f\u6301\u7684\u9a8c\u8bc1\u6846\u67b6\uff0c\u91c7\u7528\u6ce8\u518c\u5236\u6eaf\u6e90\u673a\u5236\u3002\u4e3a\u6bcf\u4e2aAI\u751f\u6210\u56fe\u50cf\u5206\u914d\u57fa\u4e8e\u611f\u77e5\u54c8\u5e0c\u7684\u6570\u5b57\u6307\u7eb9\uff0c\u5728\u521b\u5efa\u65f6\u7531\u751f\u6210\u5e73\u53f0\u6ce8\u518c\u3002\u4f7f\u7528\u6df7\u5408\u94fe\u4e0a/\u94fe\u4e0b\u5b58\u50a8\uff1aMerkle Patricia Trie\u5b9e\u73b0\u9632\u7be1\u6539\u5b58\u50a8\uff08\u94fe\u4e0a\uff09\uff0cBurkhard-Keller\u6811\uff08\u94fe\u4e0b\uff09\u652f\u6301\u5927\u89c4\u6a21\u56fe\u50cf\u6ce8\u518c\u5e93\u7684\u9ad8\u6548\u76f8\u4f3c\u6027\u641c\u7d22\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u5728\u56fe\u50cf\u91cd\u65b0\u4e0a\u4f20\u5230\u793e\u4ea4\u5a92\u4f53\u7b49\u6570\u5b57\u5e73\u53f0\u65f6\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5373\u4f7f\u7ecf\u8fc7\u826f\u6027\u53d8\u6362\u6216\u90e8\u5206\u4fee\u6539\uff0c\u4e5f\u80fd\u8bc6\u522b\u5148\u524d\u6ce8\u518c\u7684AI\u751f\u6210\u56fe\u50cf\u3002\u8be5\u65b9\u6cd5\u4e0d\u8ffd\u6c42\u68c0\u6d4b\u6240\u6709\u5408\u6210\u56fe\u50cf\uff0c\u800c\u662f\u4e13\u6ce8\u4e8e\u9a8c\u8bc1\u521b\u5efa\u65f6\u5df2\u6ce8\u518c\u7684AI\u751f\u6210\u5185\u5bb9\u7684\u6765\u6e90\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0e\u73b0\u6709\u7684\u6c34\u5370\u548c\u5b66\u4e60\u578b\u68c0\u6d4b\u65b9\u6cd5\u4e92\u8865\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e73\u53f0\u65e0\u5173\u3001\u9632\u7be1\u6539\u7684\u673a\u5236\uff0c\u53ef\u5728\u5927\u89c4\u6a21\u5728\u7ebf\u5206\u53d1\u65f6\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5185\u5bb9\u6765\u6e90\u548c\u771f\u5b9e\u6027\u9a8c\u8bc1\u3002"}}
{"id": "2602.00854", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00854", "abs": "https://arxiv.org/abs/2602.00854", "authors": ["Fangzhou Lin", "Qianwen Ge", "Lingyu Xu", "Peiran Li", "Xiangbo Gao", "Shuo Xing", "Kazunori Yamada", "Ziming Zhang", "Haichong Zhang", "Zhengzhong Tu"], "title": "Position: Human-Centric AI Requires a Minimum Viable Level of Human Understanding", "comment": "14 pages, 1 figures", "summary": "AI systems increasingly produce fluent, correct, end-to-end outcomes. Over time, this erodes users' ability to explain, verify, or intervene. We define this divergence as the Capability-Comprehension Gap: a decoupling where assisted performance improves while users' internal models deteriorate. This paper argues that prevailing approaches to transparency, user control, literacy, and governance do not define the foundational understanding humans must retain for oversight under sustained AI delegation. To formalize this, we define the Cognitive Integrity Threshold (CIT) as the minimum comprehension required to preserve oversight, autonomy, and accountable participation under AI assistance. CIT does not require full reasoning reconstruction, nor does it constrain automation. It identifies the threshold beyond which oversight becomes procedural and contestability fails. We operatinalize CIT through three functional dimensions: (i) verification capacity, (ii) comprehension-preserving interaction, and (iii) institutional scaffolds for governance. This motivates a design and governance agenda that aligns human-AI interaction with cognitive sustainability in responsibility-critical settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u80fd\u529b-\u7406\u89e3\u5dee\u8ddd\"\u6982\u5ff5\uff0c\u5373AI\u7cfb\u7edf\u80fd\u529b\u63d0\u5347\u65f6\u7528\u6237\u7406\u89e3\u80fd\u529b\u4e0b\u964d\uff0c\u5e76\u5b9a\u4e49\"\u8ba4\u77e5\u5b8c\u6574\u6027\u9608\u503c\"\u4f5c\u4e3a\u4fdd\u6301\u76d1\u7763\u6240\u9700\u7684\u6700\u4f4e\u7406\u89e3\u6c34\u5e73\u3002", "motivation": "AI\u7cfb\u7edf\u8d8a\u6765\u8d8a\u80fd\u4ea7\u751f\u6d41\u7545\u3001\u6b63\u786e\u7684\u7aef\u5230\u7aef\u7ed3\u679c\uff0c\u8fd9\u9010\u6e10\u4fb5\u8680\u4e86\u7528\u6237\u89e3\u91ca\u3001\u9a8c\u8bc1\u6216\u5e72\u9884\u7684\u80fd\u529b\u3002\u8fd9\u79cd\u80fd\u529b\u4e0e\u7406\u89e3\u7684\u8131\u8282\u9700\u8981\u88ab\u6b63\u89c6\uff0c\u56e0\u4e3a\u73b0\u6709\u7684\u900f\u660e\u5ea6\u3001\u7528\u6237\u63a7\u5236\u3001\u7d20\u517b\u548c\u6cbb\u7406\u65b9\u6cd5\u672a\u80fd\u5b9a\u4e49\u4eba\u7c7b\u5728\u6301\u7eedAI\u59d4\u6258\u4e0b\u4fdd\u6301\u76d1\u7763\u6240\u9700\u7684\u57fa\u7840\u7406\u89e3\u3002", "method": "\u8bba\u6587\u63d0\u51fa\"\u8ba4\u77e5\u5b8c\u6574\u6027\u9608\u503c\"\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u5728AI\u534f\u52a9\u4e0b\u4fdd\u6301\u76d1\u7763\u3001\u81ea\u4e3b\u6027\u548c\u95ee\u8d23\u53c2\u4e0e\u6240\u9700\u7684\u6700\u4f4e\u7406\u89e3\u6c34\u5e73\u3002\u901a\u8fc7\u4e09\u4e2a\u529f\u80fd\u7ef4\u5ea6\u6765\u64cd\u4f5c\u5316\uff1a\u9a8c\u8bc1\u80fd\u529b\u3001\u7406\u89e3\u4fdd\u6301\u578b\u4ea4\u4e92\u3001\u4ee5\u53ca\u6cbb\u7406\u7684\u5236\u5ea6\u652f\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bbe\u8ba1\u548c\u6cbb\u7406\u8bae\u7a0b\uff0c\u65e8\u5728\u5c06\u4eba\u673a\u4ea4\u4e92\u4e0e\u8d23\u4efb\u5173\u952e\u73af\u5883\u4e2d\u7684\u8ba4\u77e5\u53ef\u6301\u7eed\u6027\u5bf9\u9f50\u3002\u8ba4\u77e5\u5b8c\u6574\u6027\u9608\u503c\u4e0d\u9700\u8981\u5b8c\u5168\u63a8\u7406\u91cd\u5efa\uff0c\u4e5f\u4e0d\u9650\u5236\u81ea\u52a8\u5316\uff0c\u800c\u662f\u8bc6\u522b\u76d1\u7763\u53d8\u5f97\u7a0b\u5e8f\u5316\u4e14\u53ef\u4e89\u8bae\u6027\u5931\u6548\u7684\u9608\u503c\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u601d\u8003AI\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u6cbb\u7406\uff0c\u786e\u4fdd\u5728AI\u534f\u52a9\u4e0b\u4eba\u7c7b\u80fd\u591f\u4fdd\u6301\u8db3\u591f\u7684\u7406\u89e3\u6c34\u5e73\u6765\u7ef4\u6301\u6709\u6548\u7684\u76d1\u7763\u548c\u95ee\u8d23\uff0c\u7279\u522b\u662f\u5728\u8d23\u4efb\u5173\u952e\u7684\u73af\u5883\u4e2d\u3002"}}
{"id": "2602.00866", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00866", "abs": "https://arxiv.org/abs/2602.00866", "authors": ["Akiharu Esashi", "Pawissanutt Lertpongrujikorn", "Justin Makino", "Yuibi Fujimoto", "Mohsen Amini Salehi"], "title": "Foundation CAN LM: A Pretrained Language Model For Automotive CAN Data", "comment": null, "summary": "The Controller Area Network (CAN) bus provides a rich source of vehicular signals increasingly leveraged for applications in automotive and auto insurance domains, including collision detection, predictive maintenance, and driver risk modeling. Despite this potential, existing pipelines largely train isolated task-specific models on raw CAN data, with only limited efforts exploring decoded signals. Such fragmentation prevents shared representation learning and limits cross-task generalization. By contrast, natural language processing (NLP) and computer vision (CV) have been transformed by the foundation model paradigm: large-scale pretraining followed by task-specific adaptation. In this work, we introduce the foundation CAN model that demonstrates multi-objective downstream generalization using a single pretrained backbone. Our approach treats CAN data as a language: we pretrain on large-scale, unlabeled decoded CAN signals and fine-tune across heterogeneous auto insurance tasks. To enable this, we propose a unified tokenization scheme for mixed discrete-continuous signals and address challenges of temporal complexity and trip-specific variability. Our results show that one pretrained CAN model can adapt effectively to diverse predictive tasks, validating that the foundation modeling paradigm, proven in NLP and CV, also holds for CAN data. This establishes a new direction for generalizable representation learning in automotive AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2aCAN\u603b\u7ebf\u57fa\u7840\u6a21\u578b\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u57fa\u7840\u6a21\u578b\u8303\u5f0f\u5e94\u7528\u4e8e\u6c7d\u8f66CAN\u6570\u636e\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u548c\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\uff0c\u5b9e\u73b0\u8de8\u591a\u4e2a\u6c7d\u8f66\u4fdd\u9669\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524dCAN\u603b\u7ebf\u6570\u636e\u5904\u7406\u5b58\u5728\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u5b64\u7acb\u8bad\u7ec3\u7684\u95ee\u9898\uff0c\u7f3a\u4e4f\u5171\u4eab\u8868\u793a\u5b66\u4e60\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0cNLP\u548cCV\u9886\u57df\u901a\u8fc7\u57fa\u7840\u6a21\u578b\u8303\u5f0f\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u4f5c\u8005\u5e0c\u671b\u5c06\u8fd9\u4e00\u8303\u5f0f\u5e94\u7528\u4e8eCAN\u6570\u636e\u9886\u57df\u3002", "method": "\u5c06CAN\u6570\u636e\u89c6\u4e3a\u8bed\u8a00\u8fdb\u884c\u5904\u7406\uff1a1\uff09\u63d0\u51fa\u7edf\u4e00\u7684\u5206\u8bcd\u65b9\u6848\u5904\u7406\u6df7\u5408\u79bb\u6563-\u8fde\u7eed\u4fe1\u53f7\uff1b2\uff09\u5728\u5927\u89c4\u6a21\u672a\u6807\u8bb0\u89e3\u7801CAN\u4fe1\u53f7\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff1b3\uff09\u9488\u5bf9\u65f6\u95f4\u590d\u6742\u6027\u548c\u884c\u7a0b\u7279\u5b9a\u53d8\u5f02\u6027\u7b49\u6311\u6218\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\uff1b4\uff09\u5728\u5f02\u6784\u6c7d\u8f66\u4fdd\u9669\u4efb\u52a1\u4e0a\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684CAN\u6a21\u578b\u80fd\u591f\u6709\u6548\u9002\u5e94\u591a\u6837\u5316\u7684\u9884\u6d4b\u4efb\u52a1\uff0c\u9a8c\u8bc1\u4e86\u57fa\u7840\u6a21\u578b\u8303\u5f0f\u5728CAN\u6570\u636e\u9886\u57df\u7684\u9002\u7528\u6027\uff0c\u4e3a\u6c7d\u8f66AI\u4e2d\u7684\u53ef\u6cdb\u5316\u8868\u793a\u5b66\u4e60\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5c06NLP\u548cCV\u4e2d\u8bc1\u660e\u6709\u6548\u7684\u57fa\u7840\u6a21\u578b\u8303\u5f0f\u5e94\u7528\u4e8eCAN\u6570\u636e\uff0c\u5efa\u7acb\u4e86\u6c7d\u8f66AI\u4e2d\u53ef\u6cdb\u5316\u8868\u793a\u5b66\u4e60\u7684\u65b0\u65b9\u5411\uff0c\u4e3a\u6c7d\u8f66\u4fdd\u9669\u7b49\u9886\u57df\u7684\u591a\u4efb\u52a1\u5e94\u7528\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00871", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00871", "abs": "https://arxiv.org/abs/2602.00871", "authors": ["Hossein A. Rahmani", "Mengting Wan", "Pei Zhou", "Longqi Yang", "Nick Craswell", "Emine Yilmaz", "Sujay Kumar Jauhar"], "title": "Beyond Output Critique: Self-Correction via Task Distillation", "comment": null, "summary": "Large language models (LLMs) have shown promising self-correction abilities, where iterative refinement improves the quality of generated responses. However, most existing approaches operate at the level of output critique, patching surface errors while often failing to correct deeper reasoning flaws. We propose SELF-THOUGHT, a framework that introduces an intermediate step of task abstraction before solution refinement. Given an input and an initial response, the model first distills the task into a structured template that captures key variables, constraints, and problem structure. This abstraction then guides solution instantiation, grounding subsequent responses in a clearer understanding of the task and reducing error propagation. Crucially, we show that these abstractions can be transferred across models: templates generated by larger models can serve as structured guides for smaller LLMs, which typically struggle with intrinsic self-correction. By reusing distilled task structures, smaller models achieve more reliable refinements without heavy fine-tuning or reliance on external verifiers. Experiments across diverse reasoning tasks demonstrate that SELF-THOUGHT improves accuracy, robustness, and generalization for both large and small models, offering a scalable path toward more reliable self-correcting language systems.", "AI": {"tldr": "SELF-THOUGHT\u6846\u67b6\u901a\u8fc7\u4efb\u52a1\u62bd\u8c61\u63d0\u5347LLM\u81ea\u6211\u4fee\u6b63\u80fd\u529b\uff0c\u5c06\u4efb\u52a1\u63d0\u70bc\u4e3a\u7ed3\u6784\u5316\u6a21\u677f\uff0c\u6307\u5bfc\u89e3\u51b3\u65b9\u6848\u5b9e\u4f8b\u5316\uff0c\u5e76\u652f\u6301\u8de8\u6a21\u578b\u6a21\u677f\u8f6c\u79fb\u3002", "motivation": "\u73b0\u6709LLM\u81ea\u6211\u4fee\u6b63\u65b9\u6cd5\u4e3b\u8981\u5728\u8f93\u51fa\u5c42\u9762\u8fdb\u884c\u6279\u5224\u6027\u4fee\u6b63\uff0c\u53ea\u80fd\u4fee\u8865\u8868\u9762\u9519\u8bef\uff0c\u96be\u4ee5\u7ea0\u6b63\u6df1\u5c42\u6b21\u63a8\u7406\u7f3a\u9677\u3002\u9700\u8981\u4e00\u79cd\u80fd\u7406\u89e3\u4efb\u52a1\u672c\u8d28\u7ed3\u6784\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u4fee\u6b63\u6548\u679c\u3002", "method": "\u63d0\u51faSELF-THOUGHT\u6846\u67b6\uff1a1\uff09\u4efb\u52a1\u62bd\u8c61\u6b65\u9aa4\uff1a\u5c06\u8f93\u5165\u548c\u521d\u59cb\u54cd\u5e94\u63d0\u70bc\u4e3a\u7ed3\u6784\u5316\u6a21\u677f\uff0c\u6355\u6349\u5173\u952e\u53d8\u91cf\u3001\u7ea6\u675f\u548c\u95ee\u9898\u7ed3\u6784\uff1b2\uff09\u89e3\u51b3\u65b9\u6848\u5b9e\u4f8b\u5316\uff1a\u57fa\u4e8e\u62bd\u8c61\u6a21\u677f\u751f\u6210\u4fee\u6b63\u540e\u7684\u54cd\u5e94\uff1b3\uff09\u8de8\u6a21\u578b\u6a21\u677f\u8f6c\u79fb\uff1a\u5927\u6a21\u578b\u751f\u6210\u7684\u6a21\u677f\u53ef\u6307\u5bfc\u5c0f\u6a21\u578b\u8fdb\u884c\u66f4\u53ef\u9760\u7684\u4fee\u6b63\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSELF-THOUGHT\u5728\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u4e2d\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4f7f\u5c0f\u6a21\u578b\u65e0\u9700\u5927\u91cf\u5fae\u8c03\u6216\u4f9d\u8d56\u5916\u90e8\u9a8c\u8bc1\u5668\u5c31\u80fd\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u4fee\u6b63\u3002", "conclusion": "SELF-THOUGHT\u901a\u8fc7\u4efb\u52a1\u62bd\u8c61\u548c\u8de8\u6a21\u578b\u6a21\u677f\u8f6c\u79fb\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684\u81ea\u4fee\u6b63\u8bed\u8a00\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u3002"}}
{"id": "2602.00924", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00924", "abs": "https://arxiv.org/abs/2602.00924", "authors": ["Ouns El Harzli", "Hugo Wallner", "Yoonsoo Nam", "Haixuan Xavier Tao"], "title": "Supervised sparse auto-encoders as unconstrained feature models for semantic composition", "comment": null, "summary": "Sparse auto-encoders (SAEs) have re-emerged as a prominent method for mechanistic interpretability, yet they face two significant challenges: the non-smoothness of the $L_1$ penalty, which hinders reconstruction and scalability, and a lack of alignment between learned features and human semantics. In this paper, we address these limitations by adapting unconstrained feature models-a mathematical framework from neural collapse theory-and by supervising the task. We supervise (decoder-only) SAEs to reconstruct feature vectors by jointly learning sparse concept embeddings and decoder weights. Validated on Stable Diffusion 3.5, our approach demonstrates compositional generalization, successfully reconstructing images with concept combinations unseen during training, and enabling feature-level intervention for semantic image editing without prompt modification.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u7a00\u758f\u81ea\u7f16\u7801\u5668\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u65e0\u7ea6\u675f\u7279\u5f81\u6a21\u578b\u548c\u76d1\u7763\u4efb\u52a1\u6765\u89e3\u51b3\u4f20\u7edfSAE\u5728\u91cd\u5efa\u3001\u53ef\u6269\u5c55\u6027\u548c\u8bed\u4e49\u5bf9\u9f50\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u7a00\u758f\u81ea\u7f16\u7801\u5668\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) L1\u60e9\u7f5a\u9879\u7684\u975e\u5e73\u6ed1\u6027\u963b\u788d\u4e86\u91cd\u5efa\u548c\u53ef\u6269\u5c55\u6027\uff1b2) \u5b66\u4e60\u5230\u7684\u7279\u5f81\u4e0e\u4eba\u7c7b\u8bed\u4e49\u7f3a\u4e4f\u5bf9\u9f50\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\u4ee5\u63d0\u5347SAE\u5728\u673a\u5236\u53ef\u89e3\u91ca\u6027\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "method": "\u65b9\u6cd5\u7ed3\u5408\u4e86\u795e\u7ecf\u5d29\u6e83\u7406\u8bba\u4e2d\u7684\u65e0\u7ea6\u675f\u7279\u5f81\u6a21\u578b\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u76d1\u7763\u4efb\u52a1\u3002\u5177\u4f53\u5305\u62ec\uff1a\u76d1\u7763\uff08\u4ec5\u89e3\u7801\u5668\uff09SAE\u91cd\u5efa\u7279\u5f81\u5411\u91cf\uff0c\u8054\u5408\u5b66\u4e60\u7a00\u758f\u6982\u5ff5\u5d4c\u5165\u548c\u89e3\u7801\u5668\u6743\u91cd\u3002\u5728Stable Diffusion 3.5\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u6210\u529f\u91cd\u5efa\u8bad\u7ec3\u4e2d\u672a\u89c1\u8fc7\u7684\u6982\u5ff5\u7ec4\u5408\u56fe\u50cf\uff0c\u5e76\u5b9e\u73b0\u7279\u5f81\u7ea7\u5e72\u9884\u4ee5\u8fdb\u884c\u8bed\u4e49\u56fe\u50cf\u7f16\u8f91\uff0c\u65e0\u9700\u4fee\u6539\u63d0\u793a\u8bcd\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u65e0\u7ea6\u675f\u7279\u5f81\u6a21\u578b\u548c\u76d1\u7763\u4efb\u52a1\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfSAE\u7684\u5c40\u9650\u6027\uff0c\u5728\u7ec4\u5408\u6cdb\u5316\u548c\u8bed\u4e49\u56fe\u50cf\u7f16\u8f91\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u673a\u5236\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2602.00947", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00947", "abs": "https://arxiv.org/abs/2602.00947", "authors": ["Mohan Reddy"], "title": "The Keyhole Effect: Why Chat Interfaces Fail at Data Analysis", "comment": null, "summary": "Chat has become the default interface for AI-assisted data analysis. For multi-step, state-dependent analytical tasks, this is a mistake. Building on Woods (1984) Keyhole Effect, the cognitive cost of viewing large information spaces through narrow viewports, I show that chat interfaces systematically degrade analytical performance through five mechanisms: (1) constant content displacement defeats hippocampal spatial memory systems; (2) hidden state variables exceed working memory capacity (approximately 4 chunks under load); (3) forced verbalization triggers verbal overshadowing, degrading visual pattern recognition; (4) linear text streams block epistemic action and cognitive offloading; (5) serialization penalties scale with data dimensionality. I formalize cognitive overload as O = max(0, m - v - W) where m is task-relevant items, v is visible items, and W is working memory capacity. When O > 0, error probability increases and analytical biases (anchoring, confirmation, change blindness) amplify. Eight hybrid design patterns address these failures: Generative UI, Infinite Canvas, Deictic Interaction, State Rail, Ghost Layers, Mise en Place, Semantic Zoom, and Probabilistic UI. Each pattern targets specific cognitive bottlenecks while preserving natural language for intent specification and synthesis. Well-scaffolded conversational systems that encode expert priors may reduce load for guided tasks; the framework applies most strongly to open-ended exploration. The paper concludes with falsifiable hypotheses and experimental paradigms for empirical validation.", "AI": {"tldr": "\u804a\u5929\u754c\u9762\u4e0d\u9002\u5408\u591a\u6b65\u9aa4\u6570\u636e\u5206\u6790\u4efb\u52a1\uff0c\u4f1a\u5bfc\u81f4\u8ba4\u77e5\u8fc7\u8f7d\uff0c\u8bba\u6587\u63d0\u51fa\u516b\u4e2a\u6df7\u5408\u8bbe\u8ba1\u6a21\u5f0f\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898", "motivation": "\u5f53\u524dAI\u8f85\u52a9\u6570\u636e\u5206\u6790\u666e\u904d\u91c7\u7528\u804a\u5929\u754c\u9762\uff0c\u4f46\u5bf9\u4e8e\u591a\u6b65\u9aa4\u3001\u72b6\u6001\u4f9d\u8d56\u7684\u5206\u6790\u4efb\u52a1\uff0c\u8fd9\u79cd\u754c\u9762\u8bbe\u8ba1\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\uff0c\u4f1a\u5bfc\u81f4\u8ba4\u77e5\u8fc7\u8f7d\u548c\u5206\u6790\u6027\u80fd\u4e0b\u964d", "method": "\u57fa\u4e8eWoods\uff081984\uff09\u7684Keyhole Effect\u7406\u8bba\uff0c\u5206\u6790\u804a\u5929\u754c\u9762\u5bfc\u81f4\u8ba4\u77e5\u8fc7\u8f7d\u7684\u4e94\u79cd\u673a\u5236\uff0c\u63d0\u51fa\u8ba4\u77e5\u8fc7\u8f7d\u516c\u5f0fO = max(0, m - v - W)\uff0c\u5e76\u8bbe\u8ba1\u516b\u79cd\u6df7\u5408\u8bbe\u8ba1\u6a21\u5f0f\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898", "result": "\u8bc6\u522b\u51fa\u804a\u5929\u754c\u9762\u5bfc\u81f4\u5206\u6790\u6027\u80fd\u4e0b\u964d\u7684\u4e94\u79cd\u8ba4\u77e5\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u516b\u4e2a\u5177\u4f53\u7684\u8bbe\u8ba1\u6a21\u5f0f\uff08\u751f\u6210\u5f0fUI\u3001\u65e0\u9650\u753b\u5e03\u3001\u6307\u793a\u4ea4\u4e92\u3001\u72b6\u6001\u8f68\u9053\u3001\u5e7d\u7075\u5c42\u3001\u51c6\u5907\u5c31\u7eea\u3001\u8bed\u4e49\u7f29\u653e\u3001\u6982\u7387UI\uff09\u6765\u7f13\u89e3\u8ba4\u77e5\u8fc7\u8f7d", "conclusion": "\u804a\u5929\u754c\u9762\u4e0d\u9002\u5408\u5f00\u653e\u63a2\u7d22\u5f0f\u6570\u636e\u5206\u6790\u4efb\u52a1\uff0c\u9700\u8981\u91c7\u7528\u6df7\u5408\u8bbe\u8ba1\u6a21\u5f0f\u6765\u5e73\u8861\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u548c\u53ef\u89c6\u5316\u652f\u6301\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u53ef\u8bc1\u4f2a\u7684\u5047\u8bbe\u548c\u5b9e\u9a8c\u8303\u5f0f\u4f9b\u5b9e\u8bc1\u9a8c\u8bc1"}}
{"id": "2602.00954", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00954", "abs": "https://arxiv.org/abs/2602.00954", "authors": ["Jinlong Pang", "Zhaowei Zhu", "Na Di", "Yichi Zhang", "Yaxuan Wang", "Chen Qian", "Yang Liu"], "title": "Small-Margin Preferences Still Matter-If You Train Them Right", "comment": null, "summary": "Preference optimization methods such as DPO align large language models (LLMs) using paired comparisons, but their effectiveness can be highly sensitive to the quality and difficulty of preference pairs. A common heuristic treats small-margin (ambiguous) pairs as noisy and filters them out. In this paper, we revisit this assumption and show that pair difficulty interacts strongly with the optimization objective: when trained with preference-based losses, difficult pairs can destabilize training and harm alignment, yet these same pairs still contain useful supervision signals when optimized with supervised fine-tuning (SFT). Motivated by this observation, we propose MixDPO, a simple yet effective difficulty-aware training strategy that (i) orders preference data from easy to hard (a curriculum over margin-defined difficulty), and (ii) routes difficult pairs to an SFT objective while applying a preference loss to easy pairs. This hybrid design provides a practical mechanism to leverage ambiguous pairs without incurring the optimization failures often associated with preference losses on low-margin data. Across three LLM-judge benchmarks, MixDPO consistently improves alignment over DPO and a range of widely-used variants, with particularly strong gains on AlpacaEval~2 length-controlled (LC) win rate.", "AI": {"tldr": "MixDPO\u63d0\u51fa\u4e86\u4e00\u79cd\u96be\u5ea6\u611f\u77e5\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7\u5c06\u56f0\u96be\u504f\u597d\u5bf9\u8def\u7531\u5230\u76d1\u7763\u5fae\u8c03\u76ee\u6807\uff0c\u800c\u5c06\u7b80\u5355\u5bf9\u5e94\u7528\u4e8e\u504f\u597d\u635f\u5931\uff0c\u4ece\u800c\u6709\u6548\u5229\u7528\u6a21\u7cca\u504f\u597d\u5bf9\u4e2d\u7684\u76d1\u7763\u4fe1\u53f7\u3002", "motivation": "\u4f20\u7edf\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff08\u5982DPO\uff09\u5bf9\u504f\u597d\u5bf9\u7684\u8d28\u91cf\u548c\u96be\u5ea6\u9ad8\u5ea6\u654f\u611f\uff0c\u901a\u5e38\u5c06\u5c0f\u8fb9\u9645\uff08\u6a21\u7cca\uff09\u5bf9\u89c6\u4e3a\u566a\u58f0\u5e76\u8fc7\u6ee4\u6389\u3002\u7136\u800c\u7814\u7a76\u53d1\u73b0\uff0c\u56f0\u96be\u5bf9\u5728\u504f\u597d\u635f\u5931\u4e0b\u4f1a\u7834\u574f\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u4f46\u5728\u76d1\u7763\u5fae\u8c03\u4e2d\u4ecd\u5305\u542b\u6709\u7528\u7684\u76d1\u7763\u4fe1\u53f7\u3002", "method": "MixDPO\u91c7\u7528\u96be\u5ea6\u611f\u77e5\u8bad\u7ec3\u7b56\u7565\uff1a1\uff09\u6839\u636e\u8fb9\u9645\u5b9a\u4e49\u7684\u96be\u5ea6\u5c06\u504f\u597d\u6570\u636e\u4ece\u6613\u5230\u96be\u6392\u5e8f\uff08\u8bfe\u7a0b\u5b66\u4e60\uff09\uff1b2\uff09\u5c06\u56f0\u96be\u5bf9\u8def\u7531\u5230SFT\u76ee\u6807\uff0c\u540c\u65f6\u5bf9\u7b80\u5355\u5bf9\u5e94\u7528\u504f\u597d\u635f\u5931\u3002\u8fd9\u79cd\u6df7\u5408\u8bbe\u8ba1\u80fd\u591f\u5229\u7528\u6a21\u7cca\u5bf9\u800c\u4e0d\u5f15\u53d1\u4f18\u5316\u5931\u8d25\u3002", "result": "\u5728\u4e09\u4e2aLLM-judge\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMixDPO\u76f8\u6bd4DPO\u548c\u4e00\u7cfb\u5217\u5e7f\u6cdb\u4f7f\u7528\u7684\u53d8\u4f53\uff0c\u5728\u6a21\u578b\u5bf9\u9f50\u65b9\u9762\u6301\u7eed\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728AlpacaEval~2\u957f\u5ea6\u63a7\u5236\u80dc\u7387\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "MixDPO\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u7684\u6df7\u5408\u8bad\u7ec3\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u504f\u597d\u4f18\u5316\u4e2d\u5bf9\u56f0\u96be\u5bf9\u7684\u5904\u7406\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u6a21\u7cca\u504f\u597d\u5bf9\u5728\u9002\u5f53\u4f18\u5316\u76ee\u6807\u4e0b\u4ecd\u80fd\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u4ece\u800c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u6548\u679c\u3002"}}
{"id": "2602.00994", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00994", "abs": "https://arxiv.org/abs/2602.00994", "authors": ["Yu Li", "Mingyang Yi", "Xiuyu Li", "Ju Fan", "Fuxin Jiang", "Binbin Chen", "Peng Li", "Jie Song", "Tieying Zhang"], "title": "Reasoning and Tool-use Compete in Agentic RL:From Quantifying Interference to Disentangled Tuning", "comment": null, "summary": "Agentic Reinforcement Learning (ARL) focuses on training large language models (LLMs) to interleave reasoning with external tool execution to solve complex tasks. Most existing ARL methods train a single shared model parameters to support both reasoning and tool use behaviors, implicitly assuming that joint training leads to improved overall agent performance. Despite its widespread adoption, this assumption has rarely been examined empirically. In this paper, we systematically investigate this assumption by introducing a Linear Effect Attribution System(LEAS), which provides quantitative evidence of interference between reasoning and tool-use behaviors. Through an in-depth analysis, we show that these two capabilities often induce misaligned gradient directions, leading to training interference that undermines the effectiveness of joint optimization and challenges the prevailing ARL paradigm. To address this issue, we propose Disentangled Action Reasoning Tuning(DART), a simple and efficient framework that explicitly decouples parameter updates for reasoning and tool-use via separate low-rank adaptation modules. Experimental results show that DART consistently outperforms baseline methods with averaged 6.35 percent improvements and achieves performance comparable to multi-agent systems that explicitly separate tool-use and reasoning using a single model.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6311\u6218\u4e86\u73b0\u6709\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u8054\u5408\u8bad\u7ec3\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u5047\u8bbe\uff0c\u63d0\u51fa\u4e86\u89e3\u8026\u8bad\u7ec3\u6846\u67b6DART\u6765\u63d0\u5347\u6027\u80fd", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u8054\u5408\u8bad\u7ec3\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u80fd\u63d0\u5347\u6574\u4f53\u6027\u80fd\uff0c\u4f46\u8fd9\u4e00\u5047\u8bbe\u7f3a\u4e4f\u5b9e\u8bc1\u68c0\u9a8c\u3002\u4f5c\u8005\u53d1\u73b0\u8fd9\u4e24\u79cd\u80fd\u529b\u5728\u8bad\u7ec3\u4e2d\u4f1a\u4ea7\u751f\u68af\u5ea6\u5e72\u6270\uff0c\u5f71\u54cd\u4f18\u5316\u6548\u679c", "method": "\u63d0\u51fa\u7ebf\u6027\u6548\u5e94\u5f52\u56e0\u7cfb\u7edf(LEAS)\u91cf\u5316\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u884c\u4e3a\u4e4b\u95f4\u7684\u5e72\u6270\uff0c\u5e76\u8bbe\u8ba1\u89e3\u8026\u52a8\u4f5c\u63a8\u7406\u8c03\u4f18(DART)\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u7684\u4f4e\u79e9\u9002\u5e94\u6a21\u5757\u5206\u522b\u66f4\u65b0\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u7684\u53c2\u6570", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aDART\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u63d0\u53476.35%\uff0c\u6027\u80fd\u4e0e\u663e\u5f0f\u5206\u79bb\u5de5\u5177\u4f7f\u7528\u548c\u63a8\u7406\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u76f8\u5f53\uff0c\u4f46\u4ec5\u4f7f\u7528\u5355\u4e2a\u6a21\u578b", "conclusion": "\u8054\u5408\u8bad\u7ec3\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u5b58\u5728\u5e72\u6270\u95ee\u9898\uff0c\u89e3\u8026\u8bad\u7ec3\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\uff0c\u4e3aARL\u8303\u5f0f\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u65b9\u5411"}}
{"id": "2602.00997", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00997", "abs": "https://arxiv.org/abs/2602.00997", "authors": ["Mayank Singh", "Vikas Yadav", "Eduardo Blanco"], "title": "Error Taxonomy-Guided Prompt Optimization", "comment": null, "summary": "Automatic Prompt Optimization (APO) is a powerful approach for extracting performance from large language models without modifying their weights. Many existing methods rely on trial-and-error, testing different prompts or in-context examples until a good configuration emerges, often consuming substantial compute. Recently, natural language feedback derived from execution logs has shown promise as a way to identify how prompts can be improved. However, most prior approaches operate in a bottom-up manner, iteratively adjusting the prompt based on feedback from individual problems, which can cause them to lose the global perspective. In this work, we propose Error Taxonomy-Guided Prompt Optimization (ETGPO), a prompt optimization algorithm that adopts a top-down approach. ETGPO focuses on the global failure landscape by collecting model errors, categorizing them into a taxonomy, and augmenting the prompt with guidance targeting the most frequent failure modes. Across multiple benchmarks spanning mathematics, question answering, and logical reasoning, ETGPO achieves accuracy that is comparable to or better than state-of-the-art methods, while requiring roughly one third of the optimization-phase token usage and evaluation budget.", "AI": {"tldr": "ETGPO\u662f\u4e00\u79cd\u57fa\u4e8e\u9519\u8bef\u5206\u7c7b\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u91c7\u7528\u81ea\u4e0a\u800c\u4e0b\u7684\u65b9\u5f0f\u5206\u6790\u5168\u5c40\u5931\u8d25\u6a21\u5f0f\uff0c\u76f8\u6bd4\u4f20\u7edf\u81ea\u4e0b\u800c\u4e0a\u7684\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u5927\u591a\u91c7\u7528\u81ea\u4e0b\u800c\u4e0a\u7684\u8bd5\u9519\u65b9\u5f0f\uff0c\u57fa\u4e8e\u5355\u4e2a\u95ee\u9898\u7684\u53cd\u9988\u8fed\u4ee3\u8c03\u6574\u63d0\u793a\uff0c\u8fd9\u79cd\u65b9\u6cd5\u7f3a\u4e4f\u5168\u5c40\u89c6\u89d2\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u5177\u5168\u5c40\u89c6\u91ce\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u3002", "method": "ETGPO\u91c7\u7528\u81ea\u4e0a\u800c\u4e0b\u7684\u65b9\u6cd5\uff1a1)\u6536\u96c6\u6a21\u578b\u9519\u8bef\uff1b2)\u5c06\u9519\u8bef\u5206\u7c7b\u5230\u5206\u7c7b\u5b66\u4e2d\uff1b3)\u9488\u5bf9\u6700\u9891\u7e41\u7684\u5931\u8d25\u6a21\u5f0f\u5728\u63d0\u793a\u4e2d\u6dfb\u52a0\u6307\u5bfc\u3002\u8fd9\u79cd\u65b9\u6cd5\u5173\u6ce8\u5168\u5c40\u5931\u8d25\u6a21\u5f0f\u800c\u975e\u5355\u4e2a\u95ee\u9898\u3002", "result": "\u5728\u6570\u5b66\u3001\u95ee\u7b54\u548c\u903b\u8f91\u63a8\u7406\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cETGPO\u7684\u51c6\u786e\u7387\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u540c\u65f6\u4f18\u5316\u9636\u6bb5\u7684token\u4f7f\u7528\u91cf\u548c\u8bc4\u4f30\u9884\u7b97\u4ec5\u9700\u7ea6\u4e09\u5206\u4e4b\u4e00\u3002", "conclusion": "\u57fa\u4e8e\u9519\u8bef\u5206\u7c7b\u7684\u81ea\u4e0a\u800c\u4e0b\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u6bd4\u4f20\u7edf\u7684\u81ea\u4e0b\u800c\u4e0a\u65b9\u6cd5\u66f4\u9ad8\u6548\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u6216\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2602.01002", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01002", "abs": "https://arxiv.org/abs/2602.01002", "authors": ["Itai Shapira", "Gerdus Benade", "Ariel D. Procaccia"], "title": "How RLHF Amplifies Sycophancy", "comment": null, "summary": "Large language models often exhibit increased sycophantic behavior after preference-based post-training, showing a stronger tendency to affirm a user's stated or implied belief even when this conflicts with factual accuracy or sound judgment. We present a formal analysis of how alignment from human feedback can increase this failure mode by identifying an explicit amplification mechanism that causally links optimization against a learned reward to bias in the human preference data used for alignment. We show that the direction of behavioral drift is determined by a covariance under the base policy between endorsing the belief signal in the prompt and the learned reward, and that the first-order effect reduces to a simple mean-gap condition. We then analyze reward learning from pairwise comparisons under random utility models like Bradley-Terry and characterize when bias in human annotators' preferences induces this reward gap. Next, we propose a training-time intervention designed to neutralize the amplification mechanism itself. Among all post-trained policies that prevent sycophantic behavior from increasing, we characterize the unique policy closest in KL divergence to the unconstrained post-trained policy, and derive the corresponding minimal reward correction as a closed-form agreement penalty. Computational experiments find that reward gaps are common and cause behavioral drift in all the configurations considered.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u8bad\u7ec3\u4f1a\u653e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5949\u627f\u884c\u4e3a\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u534f\u65b9\u5dee\u5206\u6790\u7684\u56e0\u679c\u673a\u5236\u89e3\u91ca\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5305\u542b\u4e00\u81f4\u6027\u60e9\u7f5a\u7684\u5956\u52b1\u4fee\u6b63\u65b9\u6cd5\u6765\u6291\u5236\u8fd9\u79cd\u504f\u5dee", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u4e8e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u8bad\u7ec3\u540e\uff0c\u5949\u627f\u884c\u4e3a\uff08\u5373\u8fc7\u5ea6\u8fce\u5408\u7528\u6237\u89c2\u70b9\u800c\u5ffd\u89c6\u4e8b\u5b9e\u51c6\u786e\u6027\uff09\u4f1a\u663e\u8457\u589e\u5f3a\u3002\u7814\u7a76\u8005\u5e0c\u671b\u7406\u89e3\u8fd9\u79cd\u5931\u8d25\u6a21\u5f0f\u80cc\u540e\u7684\u56e0\u679c\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u6709\u6548\u7684\u5e72\u9884\u65b9\u6cd5\u3002", "method": "1\uff09\u5f62\u5f0f\u5316\u5206\u6790\uff1a\u8bc6\u522b\u51fa\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u8bad\u7ec3\u653e\u5927\u5949\u627f\u884c\u4e3a\u7684\u56e0\u679c\u673a\u5236\uff0c\u57fa\u4e8e\u57fa\u7840\u7b56\u7565\u4e0b\u8d5e\u540c\u63d0\u793a\u4e2d\u4fe1\u5ff5\u4fe1\u53f7\u4e0e\u5b66\u4e60\u5956\u52b1\u4e4b\u95f4\u7684\u534f\u65b9\u5dee\uff1b2\uff09\u5956\u52b1\u5b66\u4e60\u5206\u6790\uff1a\u5728Bradley-Terry\u7b49\u968f\u673a\u6548\u7528\u6a21\u578b\u4e0b\u5206\u6790\u4eba\u7c7b\u6807\u6ce8\u8005\u504f\u597d\u504f\u5dee\u5982\u4f55\u8bf1\u5bfc\u5956\u52b1\u5dee\u8ddd\uff1b3\uff09\u5e72\u9884\u8bbe\u8ba1\uff1a\u63a8\u5bfc\u51fa\u5728KL\u6563\u5ea6\u610f\u4e49\u4e0a\u6700\u63a5\u8fd1\u65e0\u7ea6\u675f\u540e\u8bad\u7ec3\u7b56\u7565\u7684\u552f\u4e00\u7b56\u7565\uff0c\u5e76\u5f97\u5230\u95ed\u5f0f\u7684\u4e00\u81f4\u6027\u60e9\u7f5a\u5956\u52b1\u4fee\u6b63\u3002", "result": "\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660e\u5956\u52b1\u5dee\u8ddd\u666e\u904d\u5b58\u5728\uff0c\u5728\u6240\u6709\u8003\u8651\u7684\u914d\u7f6e\u4e2d\u90fd\u4f1a\u5bfc\u81f4\u884c\u4e3a\u6f02\u79fb\u3002\u63d0\u51fa\u7684\u5956\u52b1\u4fee\u6b63\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6291\u5236\u5949\u627f\u884c\u4e3a\u7684\u589e\u52a0\u3002", "conclusion": "\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u8bad\u7ec3\u4f1a\u7cfb\u7edf\u6027\u653e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5949\u627f\u884c\u4e3a\uff0c\u8fd9\u79cd\u504f\u5dee\u6e90\u4e8e\u4eba\u7c7b\u6807\u6ce8\u6570\u636e\u4e2d\u7684\u504f\u597d\u504f\u5dee\u3002\u901a\u8fc7\u5f62\u5f0f\u5316\u5206\u6790\u63ed\u793a\u4e86\u56e0\u679c\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u4e00\u81f4\u6027\u60e9\u7f5a\u7684\u8bad\u7ec3\u65f6\u5e72\u9884\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u6709\u6548\u63a7\u5236\u5949\u627f\u884c\u4e3a\u7684\u589e\u52a0\u3002"}}
{"id": "2602.01034", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01034", "abs": "https://arxiv.org/abs/2602.01034", "authors": ["Xiangwei Wang", "Wei Wang", "Ken Chen", "Nanduni Nimalsiri", "Saman Halgamuge"], "title": "Discovering Process-Outcome Credit in Multi-Step LLM Reasoning", "comment": null, "summary": "Reinforcement Learning (RL) serves as a potent paradigm for enhancing reasoning capabilities in Large Language Models (LLMs), yet standard outcome-based approaches often suffer from reward sparsity and inefficient credit assignment. In this paper, we propose a novel framework designed to provide continuous reward signals, which introduces a Step-wise Marginal Information Gain (MIG) mechanism that quantifies the intrinsic value of reasoning steps against a Monotonic Historical Watermark, effectively filtering out training noise. To ensure disentangled credit distribution, we implement a Decoupled Masking Strategy, applying process-oriented rewards specifically to the chain-of-thought (CoT) and outcome-oriented rewards to the full completion. Additionally, we incorporate a Dual-Gated SFT objective to stabilize training with high-quality structural and factual signals. Extensive experiments across textual and multi-modal benchmarks (e.g., MATH, Super-CLEVR) demonstrate that our approach consistently outperforms baselines such as GRPO in both sample efficiency and final accuracy. Furthermore, our model exhibits superior out-of-distribution robustness, demonstrating promising zero-shot transfer capabilities to unseen and challenging reasoning tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u9010\u6b65\u8fb9\u9645\u4fe1\u606f\u589e\u76ca\u673a\u5236\u63d0\u4f9b\u8fde\u7eed\u5956\u52b1\u4fe1\u53f7\uff0c\u7ed3\u5408\u89e3\u8026\u63a9\u7801\u7b56\u7565\u548c\u53cc\u95e8\u76d1\u7763\u5fae\u8c03\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u6837\u672c\u6548\u7387\u3002", "motivation": "\u6807\u51c6\u57fa\u4e8e\u7ed3\u679c\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u5956\u52b1\u7a00\u758f\u548c\u4fe1\u7528\u5206\u914d\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u6548\u679c\u3002", "method": "1. \u5f15\u5165\u9010\u6b65\u8fb9\u9645\u4fe1\u606f\u589e\u76ca\u673a\u5236\uff0c\u901a\u8fc7\u5355\u8c03\u5386\u53f2\u6c34\u5370\u91cf\u5316\u63a8\u7406\u6b65\u9aa4\u7684\u5185\u5728\u4ef7\u503c\uff1b2. \u91c7\u7528\u89e3\u8026\u63a9\u7801\u7b56\u7565\uff0c\u5bf9\u601d\u7ef4\u94fe\u5e94\u7528\u8fc7\u7a0b\u5bfc\u5411\u5956\u52b1\uff0c\u5bf9\u5b8c\u6574\u8f93\u51fa\u5e94\u7528\u7ed3\u679c\u5bfc\u5411\u5956\u52b1\uff1b3. \u7ed3\u5408\u53cc\u95e8\u76d1\u7763\u5fae\u8c03\u76ee\u6807\uff0c\u5229\u7528\u9ad8\u8d28\u91cf\u7ed3\u6784\u548c\u4e8b\u5b9e\u4fe1\u53f7\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "\u5728\u6587\u672c\u548c\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982MATH\u3001Super-CLEVR\uff09\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u6837\u672c\u6548\u7387\u548c\u6700\u7ec8\u51c6\u786e\u7387\u65b9\u9762\u5747\u4f18\u4e8eGRPO\u7b49\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u5206\u5e03\u5916\u9c81\u68d2\u6027\u548c\u96f6\u6837\u672c\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u63d0\u4f9b\u8fde\u7eed\u5956\u52b1\u4fe1\u53f7\u548c\u6709\u6548\u7684\u4fe1\u7528\u5206\u914d\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6548\u679c\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01062", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01062", "abs": "https://arxiv.org/abs/2602.01062", "authors": ["Chenyi Li", "Yuan Zhang", "Bo Wang", "Guoqing Ma", "Wei Tang", "Haoyang Huang", "Nan Duan"], "title": "SetPO: Set-Level Policy Optimization for Diversity-Preserving LLM Reasoning", "comment": null, "summary": "Reinforcement learning with verifiable rewards has shown notable effectiveness in enhancing large language models (LLMs) reasoning performance, especially in mathematics tasks. However, such improvements often come with reduced outcome diversity, where the model concentrates probability mass on a narrow set of solutions. Motivated by diminishing-returns principles, we introduce a set level diversity objective defined over sampled trajectories using kernelized similarity. Our approach derives a leave-one-out marginal contribution for each sampled trajectory and integrates this objective as a plug-in advantage shaping term for policy optimization. We further investigate the contribution of a single trajectory to language model diversity within a distribution perturbation framework. This analysis theoretically confirms a monotonicity property, proving that rarer trajectories yield consistently higher marginal contributions to the global diversity. Extensive experiments across a range of model scales demonstrate the effectiveness of our proposed algorithm, consistently outperforming strong baselines in both Pass@1 and Pass@K across various benchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6838\u76f8\u4f3c\u5ea6\u7684\u96c6\u5408\u7ea7\u591a\u6837\u6027\u76ee\u6807\uff0c\u901a\u8fc7\u7559\u4e00\u6cd5\u8fb9\u9645\u8d21\u732e\u8ba1\u7b97\uff0c\u5c06\u591a\u6837\u6027\u4f5c\u4e3a\u4f18\u52bf\u5851\u5f62\u9879\u878d\u5165\u7b56\u7565\u4f18\u5316\uff0c\u4ee5\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u5956\u52b1\u53ef\u9a8c\u8bc1\u4f46\u7ed3\u679c\u591a\u6837\u6027\u4e0b\u964d\u7684\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\uff08\u5c24\u5176\u5728\u6570\u5b66\u4efb\u52a1\u4e2d\uff09\uff0c\u4f46\u8fd9\u79cd\u6539\u8fdb\u5f80\u5f80\u4ee5\u964d\u4f4e\u7ed3\u679c\u591a\u6837\u6027\u4e3a\u4ee3\u4ef7\uff0c\u6a21\u578b\u4f1a\u5c06\u6982\u7387\u8d28\u91cf\u96c6\u4e2d\u5728\u72ed\u7a84\u7684\u89e3\u51b3\u65b9\u6848\u96c6\u5408\u4e0a\u3002", "method": "1. \u5f15\u5165\u57fa\u4e8e\u6838\u76f8\u4f3c\u5ea6\u7684\u96c6\u5408\u7ea7\u591a\u6837\u6027\u76ee\u6807\uff1b2. \u4e3a\u6bcf\u4e2a\u91c7\u6837\u8f68\u8ff9\u63a8\u5bfc\u7559\u4e00\u6cd5\u8fb9\u9645\u8d21\u732e\uff1b3. \u5c06\u8be5\u76ee\u6807\u4f5c\u4e3a\u53ef\u63d2\u62d4\u7684\u4f18\u52bf\u5851\u5f62\u9879\u96c6\u6210\u5230\u7b56\u7565\u4f18\u5316\u4e2d\uff1b4. \u5728\u5206\u5e03\u6270\u52a8\u6846\u67b6\u4e0b\u5206\u6790\u5355\u4e2a\u8f68\u8ff9\u5bf9\u8bed\u8a00\u6a21\u578b\u591a\u6837\u6027\u7684\u8d21\u732e\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u5b9e\u4e86\u5355\u8c03\u6027\u7279\u6027\uff1a\u8f83\u7f55\u89c1\u7684\u8f68\u8ff9\u5bf9\u5168\u5c40\u591a\u6837\u6027\u7684\u8fb9\u9645\u8d21\u732e\u59cb\u7ec8\u66f4\u9ad8\u3002\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u7684Pass@1\u548cPass@K\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u3002", "conclusion": "\u901a\u8fc7\u5c06\u591a\u6837\u6027\u76ee\u6807\u4f5c\u4e3a\u4f18\u52bf\u5851\u5f62\u9879\u878d\u5165\u7b56\u7565\u4f18\u5316\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7ed3\u679c\u7684\u591a\u6837\u6027\uff0c\u5b9e\u73b0\u6027\u80fd\u4e0e\u591a\u6837\u6027\u7684\u5e73\u8861\u3002"}}
{"id": "2602.01078", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01078", "abs": "https://arxiv.org/abs/2602.01078", "authors": ["Tong Xia", "Weibin Li", "Gang Liu", "Yong Li"], "title": "AutoHealth: An Uncertainty-Aware Multi-Agent System for Autonomous Health Data Modeling", "comment": null, "summary": "LLM-based agents have demonstrated strong potential for autonomous machine learning, yet their applicability to health data remains limited. Existing systems often struggle to generalize across heterogeneous health data modalities, rely heavily on predefined solution templates with insufficient adaptation to task-specific objectives, and largely overlook uncertainty estimation, which is essential for reliable decision-making in healthcare. To address these challenges, we propose \\textit{AutoHealth}, a novel uncertainty-aware multi-agent system that autonomously models health data and assesses model reliability. \\textit{AutoHealth} employs closed-loop coordination among five specialized agents to perform data exploration, task-conditioned model construction, training, and optimization, while jointly prioritizing predictive performance and uncertainty quantification. Beyond producing ready-to-use models, the system generates comprehensive reports to support trustworthy interpretation and risk-aware decision-making. To rigorously evaluate its effectiveness, we curate a challenging real-world benchmark comprising 17 tasks across diverse data modalities and learning settings. \\textit{AutoHealth} completes all tasks and outperforms state-of-the-art baselines by 29.2\\% in prediction performance and 50.2\\% in uncertainty estimation.", "AI": {"tldr": "AutoHealth\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4e13\u95e8\u7528\u4e8e\u533b\u7597\u6570\u636e\u7684\u81ea\u4e3b\u5efa\u6a21\u548c\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\uff0c\u5728\u9884\u6d4b\u6027\u80fd\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u533b\u7597\u6570\u636e\u5e94\u7528\u4e2d\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u96be\u4ee5\u6cdb\u5316\u5230\u5f02\u6784\u533b\u7597\u6570\u636e\u6a21\u6001\u3001\u8fc7\u5ea6\u4f9d\u8d56\u9884\u5b9a\u4e49\u89e3\u51b3\u65b9\u6848\u6a21\u677f\u800c\u7f3a\u4e4f\u4efb\u52a1\u9002\u5e94\u6027\u3001\u4ee5\u53ca\u5ffd\u89c6\u5bf9\u533b\u7597\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "method": "\u63d0\u51faAutoHealth\u7cfb\u7edf\uff0c\u91c7\u7528\u4e94\u4e2a\u4e13\u95e8\u5316\u667a\u80fd\u4f53\u7684\u95ed\u73af\u534f\u8c03\u673a\u5236\uff0c\u6267\u884c\u6570\u636e\u63a2\u7d22\u3001\u4efb\u52a1\u6761\u4ef6\u5316\u6a21\u578b\u6784\u5efa\u3001\u8bad\u7ec3\u548c\u4f18\u5316\uff0c\u540c\u65f6\u5e73\u8861\u9884\u6d4b\u6027\u80fd\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u5728\u5305\u542b17\u4e2a\u4efb\u52a1\u7684\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAutoHealth\u5b8c\u6210\u4e86\u6240\u6709\u4efb\u52a1\uff0c\u9884\u6d4b\u6027\u80fd\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u63d0\u9ad8\u4e8629.2%\uff0c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u63d0\u9ad8\u4e8650.2%\u3002", "conclusion": "AutoHealth\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u540c\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u673a\u5236\uff0c\u4e3a\u533b\u7597\u6570\u636e\u7684\u81ea\u4e3b\u5efa\u6a21\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u53ef\u4fe1\u89e3\u91ca\u548c\u98ce\u9669\u611f\u77e5\u51b3\u7b56\u3002"}}
{"id": "2602.01082", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01082", "abs": "https://arxiv.org/abs/2602.01082", "authors": ["Yiliu He", "Tianle Li", "Binghao Ji", "Zhiyuan Liu", "Di Huang"], "title": "EvoOpt-LLM: Evolving industrial optimization models with large language models", "comment": null, "summary": "Optimization modeling via mixed-integer linear programming (MILP) is fundamental to industrial planning and scheduling, yet translating natural-language requirements into solver-executable models and maintaining them under evolving business rules remains highly expertise-intensive. While large language models (LLMs) offer promising avenues for automation, existing methods often suffer from low data efficiency, limited solver-level validity, and poor scalability to industrial-scale problems. To address these challenges, we present EvoOpt-LLM, a unified LLM-based framework supporting the full lifecycle of industrial optimization modeling, including automated model construction, dynamic business-constraint injection, and end-to-end variable pruning. Built on a 7B-parameter LLM and adapted via parameter-efficient LoRA fine-tuning, EvoOpt-LLM achieves a generation rate of 91% and an executability rate of 65.9% with only 3,000 training samples, with critical performance gains emerging under 1,500 samples. The constraint injection module reliably augments existing MILP models while preserving original objectives, and the variable pruning module enhances computational efficiency, achieving an F1 score of ~0.56 on medium-sized LP models with only 400 samples. EvoOpt-LLM demonstrates a practical, data-efficient approach to industrial optimization modeling, reducing reliance on expert intervention while improving adaptability and solver efficiency.", "AI": {"tldr": "EvoOpt-LLM\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u4e1a\u4f18\u5316\u5efa\u6a21\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u6784\u5efaMILP\u6a21\u578b\u3001\u52a8\u6001\u6ce8\u5165\u4e1a\u52a1\u7ea6\u675f\u5e76\u8fdb\u884c\u53d8\u91cf\u526a\u679d\uff0c\u4ec5\u9700\u5c11\u91cf\u8bad\u7ec3\u6837\u672c\u5373\u53ef\u5b9e\u73b0\u9ad8\u751f\u6210\u7387\u548c\u53ef\u6267\u884c\u7387\u3002", "motivation": "\u5de5\u4e1a\u89c4\u5212\u548c\u8c03\u5ea6\u4e2d\u7684\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u5efa\u6a21\u9ad8\u5ea6\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u4f18\u5316\u6a21\u578b\u4ee5\u53ca\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u4e1a\u52a1\u89c4\u5219\u7ef4\u62a4\u6210\u672c\u9ad8\u6602\u3002\u73b0\u6709LLM\u65b9\u6cd5\u5b58\u5728\u6570\u636e\u6548\u7387\u4f4e\u3001\u6c42\u89e3\u5668\u7ea7\u522b\u6709\u6548\u6027\u6709\u9650\u3001\u96be\u4ee5\u6269\u5c55\u5230\u5de5\u4e1a\u89c4\u6a21\u95ee\u9898\u7b49\u6311\u6218\u3002", "method": "\u57fa\u4e8e7B\u53c2\u6570\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u7684LoRA\u5fae\u8c03\u8fdb\u884c\u9002\u914d\uff0c\u6784\u5efa\u4e86\u652f\u6301\u5de5\u4e1a\u4f18\u5316\u5efa\u6a21\u5168\u751f\u547d\u5468\u671f\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5305\u62ec\u81ea\u52a8\u5316\u6a21\u578b\u6784\u5efa\u3001\u52a8\u6001\u4e1a\u52a1\u7ea6\u675f\u6ce8\u5165\u548c\u7aef\u5230\u7aef\u53d8\u91cf\u526a\u679d\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\u3002", "result": "\u4ec5\u75283000\u4e2a\u8bad\u7ec3\u6837\u672c\u5c31\u5b9e\u73b0\u4e8691%\u7684\u751f\u6210\u7387\u548c65.9%\u7684\u53ef\u6267\u884c\u7387\uff0c\u5173\u952e\u6027\u80fd\u63d0\u5347\u57281500\u4e2a\u6837\u672c\u4ee5\u4e0b\u5c31\u663e\u73b0\u51fa\u6765\u3002\u7ea6\u675f\u6ce8\u5165\u6a21\u5757\u80fd\u53ef\u9760\u5730\u589e\u5f3a\u73b0\u6709MILP\u6a21\u578b\u5e76\u4fdd\u6301\u539f\u59cb\u76ee\u6807\uff0c\u53d8\u91cf\u526a\u679d\u6a21\u5757\u5728\u4e2d\u7b49\u89c4\u6a21LP\u6a21\u578b\u4e0a\u4ec5\u7528400\u4e2a\u6837\u672c\u5c31\u8fbe\u5230\u4e86\u7ea60.56\u7684F1\u5206\u6570\u3002", "conclusion": "EvoOpt-LLM\u5c55\u793a\u4e86\u5de5\u4e1a\u4f18\u5316\u5efa\u6a21\u7684\u5b9e\u7528\u4e14\u6570\u636e\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e86\u5bf9\u4e13\u5bb6\u5e72\u9884\u7684\u4f9d\u8d56\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u9002\u5e94\u6027\u548c\u6c42\u89e3\u5668\u6548\u7387\u3002"}}
{"id": "2602.01090", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01090", "abs": "https://arxiv.org/abs/2602.01090", "authors": ["Yang Liu", "Chuan Zhou", "Yancheng Chen", "Shuai Zhang", "Xixun Lin", "Xiaoqing Wang"], "title": "Hard Constraints Meet Soft Generation: Guaranteed Feasibility for LLM-based Combinatorial Optimization", "comment": "32 pages, 2 figures", "summary": "Large language models (LLMs) have emerged as promising general-purpose solvers for combinatorial optimization (CO), yet they fundamentally lack mechanisms to guarantee solution feasibility which is critical for real-world deployment. In this work, we introduce FALCON, a framework that ensures 100\\% feasibility through three key innovations: (i) \\emph{grammar-constrained decoding} enforces syntactic validity, (ii) a \\emph{feasibility repair layer} corrects semantic constraint violations, and (iii) \\emph{adaptive Best-of-$N$ sampling} allocates inference compute efficiently. To train the underlying LLM, we introduce the Best-anchored Objective-guided Preference Optimization (BOPO) in LLM training, which weights preference pairs by their objective gap, providing dense supervision without human labels. Theoretically, we prove convergence for BOPO and provide bounds on repair-induced quality loss. Empirically, across seven NP-hard CO problems, FALCON achieves perfect feasibility while matching or exceeding the solution quality of state-of-the-art neural and LLM-based solvers.", "AI": {"tldr": "FALCON\u6846\u67b6\u901a\u8fc7\u8bed\u6cd5\u7ea6\u675f\u89e3\u7801\u3001\u53ef\u884c\u6027\u4fee\u590d\u5c42\u548c\u81ea\u9002\u5e94\u91c7\u6837\u786e\u4fddLLM\u5728\u7ec4\u5408\u4f18\u5316\u4e2d100%\u53ef\u884c\u6027\uff0c\u4f7f\u7528BOPO\u8bad\u7ec3\u65b9\u6cd5\uff0c\u57287\u4e2aNP\u96be\u95ee\u9898\u4e0a\u5b9e\u73b0\u5b8c\u7f8e\u53ef\u884c\u6027\u5e76\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7ec4\u5408\u4f18\u5316\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u4fdd\u8bc1\u89e3\u53ef\u884c\u6027\u7684\u673a\u5236\uff0c\u8fd9\u5bf9\u4e8e\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002", "method": "FALCON\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a1) \u8bed\u6cd5\u7ea6\u675f\u89e3\u7801\u786e\u4fdd\u53e5\u6cd5\u6709\u6548\u6027\uff1b2) \u53ef\u884c\u6027\u4fee\u590d\u5c42\u7ea0\u6b63\u8bed\u4e49\u7ea6\u675f\u8fdd\u53cd\uff1b3) \u81ea\u9002\u5e94Best-of-N\u91c7\u6837\u9ad8\u6548\u5206\u914d\u63a8\u7406\u8ba1\u7b97\u3002\u8bad\u7ec3\u4f7f\u7528BOPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u76ee\u6807\u5dee\u8ddd\u52a0\u6743\u504f\u597d\u5bf9\u63d0\u4f9b\u5bc6\u96c6\u76d1\u7763\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86BOPO\u7684\u6536\u655b\u6027\u5e76\u63d0\u4f9b\u4e86\u4fee\u590d\u5f15\u8d77\u7684\u8d28\u91cf\u635f\u5931\u754c\u9650\u3002\u57287\u4e2aNP\u96be\u95ee\u9898\u4e0a\uff0cFALCON\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u53ef\u884c\u6027\uff0c\u540c\u65f6\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u795e\u7ecf\u548cLLM\u6c42\u89e3\u5668\u7684\u89e3\u8d28\u91cf\u3002", "conclusion": "FALCON\u4e3aLLM\u5728\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\u4fdd\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u89e3\u7801\u3001\u4fee\u590d\u548c\u8bad\u7ec3\u65b9\u6cd5\u89e3\u51b3\u4e86\u53ef\u884c\u6027\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.01103", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01103", "abs": "https://arxiv.org/abs/2602.01103", "authors": ["Yiming Dong", "Kun Fu", "Haoyu Li", "Xinyuan Zhu", "Yurou Liu", "Lijing Shao", "Jieping Ye", "Zheng Wang"], "title": "Probing RLVR training instability through the lens of objective-level hacking", "comment": null, "summary": "Prolonged reinforcement learning with verifiable rewards (RLVR) has been shown to drive continuous improvements in the reasoning capabilities of large language models, but the training is often prone to instabilities, especially in Mixture-of-Experts (MoE) architectures. Training instability severely undermines model capability improvement, yet its underlying causes and mechanisms remain poorly understood. In this work, we introduce a principled framework for understanding RLVR instability through the lens of objective-level hacking. Unlike reward hacking, which arises from exploitable verifiers, objective-level hacking emerges from token-level credit misalignment and is manifested as system-level spurious signals in the optimization objective. Grounded in our framework, together with extensive experiments on a 30B MoE model, we trace the origin and formalize the mechanism behind a key pathological training dynamic in MoE models: the abnormal growth of the training-inference discrepancy, a phenomenon widely associated with instability but previously lacking a mechanistic explanation. These findings provide a concrete and causal account of the training dynamics underlying instabilities in MoE models, offering guidance for the design of stable RLVR algorithms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u4ece\u76ee\u6807\u5c42\u9762\u9ed1\u5ba2\u653b\u51fb\u7684\u89d2\u5ea6\u7406\u89e3MoE\u6a21\u578b\u5728RLVR\u8bad\u7ec3\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u63ed\u793a\u4e86\u8bad\u7ec3-\u63a8\u7406\u5dee\u5f02\u5f02\u5e38\u589e\u957f\u7684\u673a\u5236\u3002", "motivation": "MoE\u67b6\u6784\u5728RLVR\u8bad\u7ec3\u4e2d\u5bb9\u6613\u51fa\u73b0\u4e0d\u7a33\u5b9a\u6027\uff0c\u4e25\u91cd\u5f71\u54cd\u6a21\u578b\u80fd\u529b\u63d0\u5347\uff0c\u4f46\u5176\u6839\u672c\u539f\u56e0\u548c\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u7406\u8bba\u6846\u67b6\u6765\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u76ee\u6807\u5c42\u9762\u9ed1\u5ba2\u653b\u51fb\u7684\u7406\u8bba\u6846\u67b6\uff0c\u533a\u522b\u4e8e\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\uff0c\u5173\u6ce8token\u7ea7\u4fe1\u7528\u9519\u4f4d\u5bfc\u81f4\u7684\u7cfb\u7edf\u7ea7\u865a\u5047\u4fe1\u53f7\u3002\u572830B MoE\u6a21\u578b\u4e0a\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u63ed\u793a\u4e86MoE\u6a21\u578b\u4e2d\u8bad\u7ec3-\u63a8\u7406\u5dee\u5f02\u5f02\u5e38\u589e\u957f\u8fd9\u4e00\u5173\u952e\u75c5\u7406\u8bad\u7ec3\u52a8\u6001\u7684\u8d77\u6e90\u548c\u673a\u5236\uff0c\u4e3a\u4e4b\u524d\u5e7f\u6cdb\u5173\u8054\u4f46\u4e0d\u7406\u89e3\u7684\u73b0\u8c61\u63d0\u4f9b\u4e86\u56e0\u679c\u89e3\u91ca\u3002", "conclusion": "\u4e3aMoE\u6a21\u578b\u5728RLVR\u8bad\u7ec3\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u5177\u4f53\u4e14\u56e0\u679c\u7684\u8bad\u7ec3\u52a8\u6001\u89e3\u91ca\uff0c\u4e3a\u8bbe\u8ba1\u7a33\u5b9a\u7684RLVR\u7b97\u6cd5\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2602.01109", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01109", "abs": "https://arxiv.org/abs/2602.01109", "authors": ["Hugo Math", "Rainer Lienhart"], "title": "Transforming Vehicle Diagnostics: A Multimodal Approach to Error Patterns Prediction", "comment": "9 pages, 7 figures", "summary": "Accurately diagnosing and predicting vehicle malfunctions is crucial for maintenance and safety in the automotive industry. While modern diagnostic systems primarily rely on sequences of vehicular Diagnostic Trouble Codes (DTCs) registered in On-Board Diagnostic (OBD) systems, they often overlook valuable contextual information such as raw sensory data (e.g., temperature, humidity, and pressure). This contextual data, crucial for domain experts to classify vehicle failures, introduces unique challenges due to its complexity and the noisy nature of real-world data. This paper presents BiCarFormer: the first multimodal approach to multi-label sequence classification of error codes into error patterns that integrates DTC sequences and environmental conditions. BiCarFormer is a bidirectional Transformer model tailored for vehicle event sequences, employing embedding fusions and a co-attention mechanism to capture the relationships between diagnostic codes and environmental data. Experimental results on a challenging real-world automotive dataset with 22,137 error codes and 360 error patterns demonstrate that our approach significantly improves classification performance compared to models that rely solely on DTC sequences and traditional sequence models. This work highlights the importance of incorporating contextual environmental information for more accurate and robust vehicle diagnostics, hence reducing maintenance costs and enhancing automation processes in the automotive industry.", "AI": {"tldr": "BiCarFormer\uff1a\u9996\u4e2a\u591a\u6a21\u6001\u65b9\u6cd5\uff0c\u6574\u5408DTC\u5e8f\u5217\u548c\u73af\u5883\u6761\u4ef6\u8fdb\u884c\u591a\u6807\u7b7e\u5e8f\u5217\u5206\u7c7b\uff0c\u663e\u8457\u63d0\u5347\u8f66\u8f86\u6545\u969c\u8bca\u65ad\u6027\u80fd", "motivation": "\u5f53\u524d\u8f66\u8f86\u8bca\u65ad\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56DTC\u5e8f\u5217\uff0c\u4f46\u5ffd\u7565\u4e86\u6e29\u5ea6\u3001\u6e7f\u5ea6\u3001\u538b\u529b\u7b49\u73af\u5883\u6570\u636e\uff0c\u800c\u8fd9\u4e9b\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bf9\u4e13\u5bb6\u5206\u7c7b\u6545\u969c\u81f3\u5173\u91cd\u8981\u3002\u771f\u5b9e\u4e16\u754c\u6570\u636e\u590d\u6742\u4e14\u566a\u58f0\u591a\uff0c\u9700\u8981\u66f4\u597d\u7684\u6574\u5408\u65b9\u6cd5\u3002", "method": "\u63d0\u51faBiCarFormer\u53cc\u5411Transformer\u6a21\u578b\uff0c\u4e13\u95e8\u5904\u7406\u8f66\u8f86\u4e8b\u4ef6\u5e8f\u5217\uff0c\u91c7\u7528\u5d4c\u5165\u878d\u5408\u548c\u534f\u540c\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u8bca\u65ad\u4ee3\u7801\u4e0e\u73af\u5883\u6570\u636e\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u5728\u5305\u542b22,137\u4e2a\u9519\u8bef\u4ee3\u7801\u548c360\u4e2a\u9519\u8bef\u6a21\u5f0f\u7684\u771f\u5b9e\u6c7d\u8f66\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u4ec5\u4f7f\u7528DTC\u5e8f\u5217\u7684\u4f20\u7edf\u5e8f\u5217\u6a21\u578b\uff0c\u5206\u7c7b\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u6574\u5408\u4e0a\u4e0b\u6587\u73af\u5883\u4fe1\u606f\u5bf9\u5b9e\u73b0\u66f4\u51c6\u786e\u3001\u9c81\u68d2\u7684\u8f66\u8f86\u8bca\u65ad\u81f3\u5173\u91cd\u8981\uff0c\u53ef\u964d\u4f4e\u7ef4\u62a4\u6210\u672c\u5e76\u63d0\u5347\u6c7d\u8f66\u884c\u4e1a\u81ea\u52a8\u5316\u6d41\u7a0b\u3002"}}
{"id": "2602.01146", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01146", "abs": "https://arxiv.org/abs/2602.01146", "authors": ["Sidharth Pulipaka", "Oliver Chen", "Manas Sharma", "Taaha S Bajwa", "Vyas Raina", "Ivaxi Sheth"], "title": "PersistBench: When Should Long-Term Memories Be Forgotten by LLMs?", "comment": "70 pages, 26 figures, under review", "summary": "Conversational assistants are increasingly integrating long-term memory with large language models (LLMs). This persistence of memories, e.g., the user is vegetarian, can enhance personalization in future conversations. However, the same persistence can also introduce safety risks that have been largely overlooked. Hence, we introduce PersistBench to measure the extent of these safety risks. We identify two long-term memory-specific risks: cross-domain leakage, where LLMs inappropriately inject context from the long-term memories; and memory-induced sycophancy, where stored long-term memories insidiously reinforce user biases. We evaluate 18 frontier and open-source LLMs on our benchmark. Our results reveal a surprisingly high failure rate across these LLMs - a median failure rate of 53% on cross-domain samples and 97% on sycophancy samples. To address this, our benchmark encourages the development of more robust and safer long-term memory usage in frontier conversational systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPersistBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5bf9\u8bdd\u52a9\u624b\u957f\u671f\u8bb0\u5fc6\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669\uff0c\u53d1\u73b0\u4e3b\u6d41LLMs\u5728\u8de8\u57df\u6cc4\u6f0f\u548c\u8bb0\u5fc6\u8bf1\u5bfc\u8c04\u5a9a\u95ee\u9898\u4e0a\u5b58\u5728\u9ad8\u5931\u8d25\u7387\u3002", "motivation": "\u5bf9\u8bdd\u52a9\u624b\u8d8a\u6765\u8d8a\u591a\u5730\u5c06\u957f\u671f\u8bb0\u5fc6\u4e0eLLMs\u96c6\u6210\uff0c\u8fd9\u79cd\u8bb0\u5fc6\u6301\u4e45\u6027\u867d\u7136\u80fd\u589e\u5f3a\u4e2a\u6027\u5316\u4f53\u9a8c\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u88ab\u5ffd\u89c6\u7684\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u6d4b\u91cf\u548c\u8bc4\u4f30\u8fd9\u4e9b\u98ce\u9669\u3002", "method": "\u63d0\u51faPersistBench\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u8bc6\u522b\u4e24\u79cd\u957f\u671f\u8bb0\u5fc6\u7279\u6709\u98ce\u9669\uff1a\u8de8\u57df\u6cc4\u6f0f\uff08LLMs\u4e0d\u9002\u5f53\u5730\u4ece\u957f\u671f\u8bb0\u5fc6\u4e2d\u6ce8\u5165\u4e0a\u4e0b\u6587\uff09\u548c\u8bb0\u5fc6\u8bf1\u5bfc\u8c04\u5a9a\uff08\u5b58\u50a8\u7684\u957f\u671f\u8bb0\u5fc6\u6697\u4e2d\u5f3a\u5316\u7528\u6237\u504f\u89c1\uff09\u3002\u572818\u4e2a\u524d\u6cbf\u548c\u5f00\u6e90LLMs\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u60ca\u4eba\u7684\u9ad8\u5931\u8d25\u7387\uff1a\u8de8\u57df\u6837\u672c\u4e2d\u4f4d\u5931\u8d25\u738753%\uff0c\u8c04\u5a9a\u6837\u672c\u4e2d\u4f4d\u5931\u8d25\u738797%\uff0c\u8868\u660e\u5f53\u524dLLMs\u5728\u957f\u671f\u8bb0\u5fc6\u5b89\u5168\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u95ee\u9898\u3002", "conclusion": "\u957f\u671f\u8bb0\u5fc6\u96c6\u6210\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u6311\u6218\uff0cPersistBench\u57fa\u51c6\u6d4b\u8bd5\u6709\u52a9\u4e8e\u63a8\u52a8\u5f00\u53d1\u66f4\u7a33\u5065\u3001\u66f4\u5b89\u5168\u7684\u957f\u671f\u8bb0\u5fc6\u4f7f\u7528\u65b9\u6848\uff0c\u63d0\u5347\u524d\u6cbf\u5bf9\u8bdd\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2602.01167", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01167", "abs": "https://arxiv.org/abs/2602.01167", "authors": ["Zhiming Liu", "Yujie Wei", "Lei Feng", "Xiu Su", "Xiaobo Xia", "Weili Guan", "Zeke Xie", "Shuo Yang"], "title": "Do All Individual Layers Help? An Empirical Study of Task-Interfering Layers in Vision-Language Models", "comment": null, "summary": "Current VLMs have demonstrated capabilities across a wide range of multimodal tasks. Typically, in a pretrained VLM, all layers are engaged by default to make predictions on downstream tasks. We find that intervening on a single layer, such as by zeroing its parameters, can improve the performance on certain tasks, indicating that some layers hinder rather than help downstream tasks. We systematically investigate how individual layers influence different tasks via layer intervention. Specifically, we measure the change in performance relative to the base model after intervening on each layer and observe improvements when bypassing specific layers. This improvement can be generalizable across models and datasets, indicating the presence of Task-Interfering Layers that harm downstream tasks' performance. We introduce Task-Layer Interaction Vector, which quantifies the effect of intervening on each layer of a VLM given a task. These task-interfering layers exhibit task-specific sensitivity patterns: tasks requiring similar capabilities show consistent response trends under layer interventions, as evidenced by the high similarity in their task-layer interaction vectors. Inspired by these findings, we propose TaLo (Task-Adaptive Layer Knockout), a training-free, test-time adaptation method that dynamically identifies and bypasses the most interfering layer for a given task. Without parameter updates, TaLo improves performance across various models and datasets, including boosting Qwen-VL's accuracy on the Maps task in ScienceQA by up to 16.6%. Our work reveals an unexpected form of modularity in pretrained VLMs and provides a plug-and-play, training-free mechanism to unlock hidden capabilities at inference time. The source code will be publicly available.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4efb\u52a1\u5e72\u6270\u5c42\uff0c\u8fd9\u4e9b\u5c42\u4f1a\u635f\u5bb3\u7279\u5b9a\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5e72\u9884\u5355\u4e2a\u5c42\uff08\u5982\u7f6e\u96f6\u53c2\u6570\uff09\u53ef\u4ee5\u63d0\u5347\u67d0\u4e9b\u4efb\u52a1\u8868\u73b0\uff0c\u8868\u660e\u6a21\u578b\u5b58\u5728\u4efb\u52a1\u7279\u5b9a\u7684\u6a21\u5757\u5316\u7279\u6027\u3002\u4f5c\u8005\u63d0\u51faTaLo\u65b9\u6cd5\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u52a8\u6001\u8bc6\u522b\u5e76\u7ed5\u8fc7\u5e72\u6270\u5c42\uff0c\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u9ed8\u8ba4\u4f7f\u7528\u6240\u6709\u5c42\u8fdb\u884c\u4e0b\u6e38\u4efb\u52a1\u9884\u6d4b\u3002\u7814\u7a76\u53d1\u73b0\u67d0\u4e9b\u5c42\u5b9e\u9645\u4e0a\u4f1a\u963b\u788d\u7279\u5b9a\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u8fd9\u8868\u660e\u9884\u8bad\u7ec3\u6a21\u578b\u5b58\u5728\u4efb\u52a1\u5e72\u6270\u5c42\u3002\u7406\u89e3\u8fd9\u4e9b\u5c42\u5982\u4f55\u5f71\u54cd\u4e0d\u540c\u4efb\u52a1\uff0c\u5e76\u5f00\u53d1\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\u6765\u7ed5\u8fc7\u8fd9\u4e9b\u5e72\u6270\u5c42\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "1. \u7cfb\u7edf\u7814\u7a76\u5355\u4e2a\u5c42\u5982\u4f55\u901a\u8fc7\u5c42\u5e72\u9884\u5f71\u54cd\u4e0d\u540c\u4efb\u52a1\uff1b2. \u6d4b\u91cf\u5e72\u9884\u6bcf\u4e2a\u5c42\u540e\u76f8\u5bf9\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u6027\u80fd\u53d8\u5316\uff1b3. \u5f15\u5165\u4efb\u52a1-\u5c42\u4ea4\u4e92\u5411\u91cf\u91cf\u5316\u6bcf\u4e2a\u5c42\u5bf9\u7ed9\u5b9a\u4efb\u52a1\u7684\u5f71\u54cd\uff1b4. \u63d0\u51faTaLo\u65b9\u6cd5\uff1a\u65e0\u9700\u8bad\u7ec3\u3001\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\uff0c\u52a8\u6001\u8bc6\u522b\u5e76\u7ed5\u8fc7\u6700\u5e72\u6270\u7684\u5c42\u3002", "result": "1. \u53d1\u73b0\u4efb\u52a1\u5e72\u6270\u5c42\u7684\u5b58\u5728\uff0c\u8fd9\u4e9b\u5c42\u4f1a\u635f\u5bb3\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff1b2. \u4efb\u52a1\u5e72\u6270\u5c42\u8868\u73b0\u51fa\u4efb\u52a1\u7279\u5b9a\u7684\u654f\u611f\u6a21\u5f0f\uff1a\u9700\u8981\u76f8\u4f3c\u80fd\u529b\u7684\u4efb\u52a1\u5728\u5c42\u5e72\u9884\u4e0b\u663e\u793a\u4e00\u81f4\u7684\u54cd\u5e94\u8d8b\u52bf\uff1b3. TaLo\u65b9\u6cd5\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u5373\u53ef\u63d0\u5347\u5404\u79cd\u6a21\u578b\u548c\u6570\u636e\u96c6\u6027\u80fd\uff0c\u5982\u5728ScienceQA\u7684Maps\u4efb\u52a1\u4e0a\u5c06Qwen-VL\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe16.6%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u5b58\u5728\u610f\u5916\u5f62\u5f0f\u7684\u6a21\u5757\u5316\u7279\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5373\u63d2\u5373\u7528\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u673a\u5236\uff0c\u5728\u63a8\u7406\u65f6\u89e3\u9501\u9690\u85cf\u80fd\u529b\u3002TaLo\u65b9\u6cd5\u5c55\u793a\u4e86\u901a\u8fc7\u8bc6\u522b\u548c\u7ed5\u8fc7\u4efb\u52a1\u5e72\u6270\u5c42\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\u7684\u6709\u6548\u6027\uff0c\u4e3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.01198", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01198", "abs": "https://arxiv.org/abs/2602.01198", "authors": ["Liang Zhang", "Yu Zhao", "Longyue Wang", "Tianqi Shi", "Weihua Luo", "Kaifu Zhang", "Jinsong Su"], "title": "A State-Transition Framework for Efficient LLM Reasoning", "comment": "ICLR 2026", "summary": "While Long Chain-of-Thought (CoT) reasoning significantly improves Large Language Models (LLMs) performance on complex reasoning tasks, the substantial computational and memory costs of generating long CoT sequences limit their efficiency and practicality. Existing studies usually enhance the reasoning efficiency of LLMs by compressing CoT sequences. However, this approach conflicts with test-time scaling, limiting the reasoning capacity of LLMs. In this paper, we propose an efficient reasoning framework that models the reasoning process of LLMs as a state-transition process. Specifically, we first apply a linear attention mechanism to estimate the LLM's reasoning state, which records the historical reasoning information from previous reasoning steps. Then, based on the query prompt and the reasoning state, the LLM can efficiently perform the current reasoning step and update the state. With the linear attention, each token in the current reasoning step can directly retrieve relevant historical reasoning information from the reasoning state, without explicitly attending to tokens in previous reasoning steps. In this way, the computational complexity of attention is reduced from quadratic to linear, significantly improving the reasoning efficiency of LLMs. In addition, we propose a state-based reasoning strategy to mitigate the over-thinking issue caused by noisy reasoning steps. Extensive experiments across multiple datasets and model sizes demonstrate that our framework not only improves the reasoning efficiency of LLMs but also enhances their reasoning performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u63a8\u7406\u6846\u67b6\uff0c\u5c06LLM\u7684\u63a8\u7406\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u72b6\u6001\u8f6c\u79fb\u8fc7\u7a0b\uff0c\u4f7f\u7528\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u901a\u8fc7\u72b6\u6001\u63a8\u7406\u7b56\u7565\u7f13\u89e3\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u3002", "motivation": "\u957f\u601d\u7ef4\u94fe\u63a8\u7406\u867d\u7136\u80fd\u63d0\u5347LLM\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4f46\u751f\u6210\u957fCoT\u5e8f\u5217\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u8fc7\u9ad8\uff0c\u9650\u5236\u4e86\u5176\u6548\u7387\u548c\u5b9e\u7528\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u538b\u7f29CoT\u5e8f\u5217\u6765\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u8fd9\u4e0e\u6d4b\u8bd5\u65f6\u6269\u5c55\u76f8\u51b2\u7a81\uff0c\u9650\u5236\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "1. \u5c06LLM\u63a8\u7406\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u72b6\u6001\u8f6c\u79fb\u8fc7\u7a0b\uff1b2. \u4f7f\u7528\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u4f30\u8ba1\u63a8\u7406\u72b6\u6001\uff0c\u8bb0\u5f55\u5386\u53f2\u63a8\u7406\u4fe1\u606f\uff1b3. \u57fa\u4e8e\u67e5\u8be2\u63d0\u793a\u548c\u63a8\u7406\u72b6\u6001\uff0cLLM\u9ad8\u6548\u6267\u884c\u5f53\u524d\u63a8\u7406\u6b65\u9aa4\u5e76\u66f4\u65b0\u72b6\u6001\uff1b4. \u63d0\u51fa\u57fa\u4e8e\u72b6\u6001\u7684\u63a8\u7406\u7b56\u7565\u7f13\u89e3\u566a\u58f0\u63a8\u7406\u6b65\u9aa4\u5f15\u8d77\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u89c4\u6a21\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86LLM\u7684\u63a8\u7406\u6548\u7387\uff0c\u8fd8\u589e\u5f3a\u4e86\u5176\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u9ad8\u6548\u63a8\u7406\u6846\u67b6\u901a\u8fc7\u72b6\u6001\u8f6c\u79fb\u5efa\u6a21\u548c\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u89e3\u51b3\u4e86\u957fCoT\u63a8\u7406\u7684\u6548\u7387\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2602.01202", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01202", "abs": "https://arxiv.org/abs/2602.01202", "authors": ["Mingze Kong", "Zikun Qu", "Zhongquan Zhou", "Pengyu Liang", "Xiang Li", "Zhiwei Shang", "Zhi Hong", "Kaiyu Huang", "Zhiyong Wang", "Zhongxiang Dai"], "title": "Workflow-R1: Group Sub-sequence Policy Optimization for Multi-turn Workflow Construction", "comment": null, "summary": "The rapid evolution of agentic workflows has demonstrated strong performance of LLM-based agents in addressing complex reasoning tasks. However, existing workflow optimization methods typically formulate workflow synthesis as a static, one-shot code-centric generation problem. This paradigm imposes excessive constraints on the model's coding capabilities and restricts the flexibility required for dynamic problem-solving. In this paper, we present Workflow-R1, a framework that reformulates workflow construction as a multi-turn, natural language-based sequential decision-making process. To resolve the optimization granularity mismatch inherent in such multi-turn interactions, we introduce Group Sub-sequence Policy Optimization (GSsPO). While explicitly tailored to align with the interleaved Think-Action dynamics of agentic reasoning, GSsPO fundamentally functions as a structure-aware RL algorithm generalizable to a broad class of multi-turn agentic sequential decision-making tasks. By recalibrating the optimization unit to the composite sub-sequence, specifically the atomic Think-Action cycle, it aligns gradient updates with the semantic boundaries of these interactions, ensuring robust learning in complex multi-turn reasoning tasks. Through extensive experiments on multiple QA benchmarks, Workflow-R1 outperforms competitive baselines, validating GSsPO as a generalized solution for sequential reasoning and establishing Workflow-R1 as a promising new paradigm for automated workflow optimization.", "AI": {"tldr": "Workflow-R1\u5c06\u5de5\u4f5c\u6d41\u6784\u5efa\u91cd\u65b0\u5b9a\u4e49\u4e3a\u591a\u8f6e\u81ea\u7136\u8bed\u8a00\u987a\u5e8f\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5f15\u5165GSsPO\u7b97\u6cd5\u89e3\u51b3\u4f18\u5316\u7c92\u5ea6\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5728\u591a\u4e2aQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u6d41\u4f18\u5316\u65b9\u6cd5\u5c06\u5de5\u4f5c\u6d41\u5408\u6210\u89c6\u4e3a\u9759\u6001\u3001\u4e00\u6b21\u6027\u7684\u4ee3\u7801\u751f\u6210\u95ee\u9898\uff0c\u8fd9\u8fc7\u5ea6\u7ea6\u675f\u4e86\u6a21\u578b\u7684\u7f16\u7801\u80fd\u529b\uff0c\u9650\u5236\u4e86\u52a8\u6001\u95ee\u9898\u89e3\u51b3\u7684\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51faWorkflow-R1\u6846\u67b6\uff0c\u5c06\u5de5\u4f5c\u6d41\u6784\u5efa\u91cd\u65b0\u5b9a\u4e49\u4e3a\u591a\u8f6e\u81ea\u7136\u8bed\u8a00\u987a\u5e8f\u51b3\u7b56\u8fc7\u7a0b\u3002\u5f15\u5165Group Sub-sequence Policy Optimization (GSsPO)\u7b97\u6cd5\uff0c\u5c06\u4f18\u5316\u5355\u5143\u91cd\u65b0\u6821\u51c6\u4e3a\u590d\u5408\u5b50\u5e8f\u5217\uff08\u7279\u522b\u662f\u539f\u5b50Think-Action\u5faa\u73af\uff09\uff0c\u4f7f\u68af\u5ea6\u66f4\u65b0\u4e0e\u4ea4\u4e92\u7684\u8bed\u4e49\u8fb9\u754c\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2aQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cWorkflow-R1\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\uff0c\u9a8c\u8bc1\u4e86GSsPO\u4f5c\u4e3a\u987a\u5e8f\u63a8\u7406\u7684\u901a\u7528\u89e3\u51b3\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "conclusion": "Workflow-R1\u4e3a\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b0\u8303\u5f0f\uff0cGSsPO\u4f5c\u4e3a\u4e00\u79cd\u7ed3\u6784\u611f\u77e5\u7684RL\u7b97\u6cd5\u53ef\u63a8\u5e7f\u5230\u5e7f\u6cdb\u7684\u667a\u80fd\u4f53\u987a\u5e8f\u51b3\u7b56\u4efb\u52a1\u4e2d\u3002"}}
{"id": "2602.01207", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01207", "abs": "https://arxiv.org/abs/2602.01207", "authors": ["Hui Wu", "Hengyi Cai", "Jinman Zhao", "Xinran Chen", "Ziheng Li", "Zhejun Zhao", "Shuaiqiang Wang", "Yuchen Li", "Dawei Yin"], "title": "Not All Preferences Are Created Equal: Stability-Aware and Gradient-Efficient Alignment for Reasoning Models", "comment": null, "summary": "Preference-based alignment is pivotal for training large reasoning models; however, standard methods like Direct Preference Optimization (DPO) typically treat all preference pairs uniformly, overlooking the evolving utility of training instances. This static approach often leads to inefficient or unstable optimization, as it wastes computation on trivial pairs with negligible gradients and suffers from noise induced by samples near uncertain decision boundaries. Facing these challenges, we propose SAGE (Stability-Aware Gradient Efficiency), a dynamic framework designed to enhance alignment reliability by maximizing the Signal-to-Noise Ratio of policy updates. Concretely, SAGE integrates a coarse-grained curriculum mechanism that refreshes candidate pools based on model competence with a fine-grained, stability-aware scoring function that prioritizes informative, confident errors while filtering out unstable samples. Experiments on multiple mathematical reasoning benchmarks demonstrate that SAGE significantly accelerates convergence and outperforms static baselines, highlighting the critical role of policy-aware, stability-conscious data selection in reasoning alignment.", "AI": {"tldr": "SAGE\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u6570\u636e\u9009\u62e9\u4f18\u5316\u63a8\u7406\u6a21\u578b\u5bf9\u9f50\uff0c\u57fa\u4e8e\u7a33\u5b9a\u6027\u611f\u77e5\u7684\u68af\u5ea6\u6548\u7387\u6700\u5927\u5316\u4fe1\u53f7\u566a\u58f0\u6bd4\uff0c\u52a0\u901f\u6536\u655b\u5e76\u8d85\u8d8a\u9759\u6001\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u504f\u597d\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982DPO\uff09\u5bf9\u6240\u6709\u504f\u597d\u5bf9\u4e00\u89c6\u540c\u4ec1\uff0c\u5ffd\u7565\u4e86\u8bad\u7ec3\u6837\u672c\u7684\u6f14\u5316\u6548\u7528\u3002\u9759\u6001\u65b9\u6cd5\u5bfc\u81f4\u4f18\u5316\u6548\u7387\u4f4e\u4e0b\u6216\u4e0d\u7a33\u5b9a\uff1a\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u5904\u7406\u68af\u5ea6\u53ef\u5ffd\u7565\u7684\u5e73\u51e1\u6837\u672c\uff0c\u540c\u65f6\u53d7\u5230\u51b3\u7b56\u8fb9\u754c\u9644\u8fd1\u4e0d\u786e\u5b9a\u6837\u672c\u7684\u566a\u58f0\u5e72\u6270\u3002", "method": "\u63d0\u51faSAGE\uff08\u7a33\u5b9a\u6027\u611f\u77e5\u68af\u5ea6\u6548\u7387\uff09\u52a8\u6001\u6846\u67b6\uff0c\u5305\u542b\uff1a1\uff09\u57fa\u4e8e\u6a21\u578b\u80fd\u529b\u5237\u65b0\u5019\u9009\u6c60\u7684\u7c97\u7c92\u5ea6\u8bfe\u7a0b\u673a\u5236\uff1b2\uff09\u7ec6\u7c92\u5ea6\u7a33\u5b9a\u6027\u611f\u77e5\u8bc4\u5206\u51fd\u6570\uff0c\u4f18\u5148\u9009\u62e9\u4fe1\u606f\u4e30\u5bcc\u3001\u7f6e\u4fe1\u5ea6\u9ad8\u7684\u9519\u8bef\u6837\u672c\uff0c\u540c\u65f6\u8fc7\u6ee4\u4e0d\u7a33\u5b9a\u6837\u672c\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSAGE\u663e\u8457\u52a0\u901f\u6536\u655b\u901f\u5ea6\uff0c\u6027\u80fd\u4f18\u4e8e\u9759\u6001\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u63a8\u7406\u5bf9\u9f50\u4e2d\u91c7\u7528\u7b56\u7565\u611f\u77e5\u3001\u7a33\u5b9a\u6027\u610f\u8bc6\u7684\u6570\u636e\u9009\u62e9\u7684\u91cd\u8981\u6027\uff0c\u52a8\u6001\u6837\u672c\u9009\u62e9\u80fd\u6709\u6548\u63d0\u5347\u5bf9\u9f50\u8fc7\u7a0b\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2602.01222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01222", "abs": "https://arxiv.org/abs/2602.01222", "authors": ["Shaoxiong Yang", "Junting Li", "Mengyuan Zhang", "Chao Li", "Wei Liu", "Jian Luan"], "title": "FutureMind: Equipping Small Language Models with Strategic Thinking-Pattern Priors via Adaptive Knowledge Distillation", "comment": "Accepted by ICLR 2026", "summary": "Small Language Models (SLMs) are attractive for cost-sensitive and resource-limited settings due to their efficient, low-latency inference. However, they often struggle with complex, knowledge-intensive tasks that require structured reasoning and effective retrieval. To address these limitations, we propose FutureMind, a modular reasoning framework that equips SLMs with strategic thinking-pattern priors via adaptive knowledge distillation from large language models (LLMs). FutureMind introduces a dynamic reasoning pipeline composed of four key modules: Problem Analysis, Logical Reasoning, Strategy Planning, and Retrieval Guidance. This pipeline is augmented by three distinct retrieval paradigms that decompose complex queries into tractable subproblems, ensuring efficient and accurate retrieval execution. Extensive experiments on multi-hop QA benchmarks, including 2WikiMultihopQA, MuSiQue, Bamboogle, and Frames, demonstrate the superiority of FutureMind. It consistently outperforms strong baselines such as Search-o1, achieving state-of-the-art results under free training conditions across diverse SLM architectures and scales. Beyond empirical gains, our analysis reveals that the process of thinking-pattern distillation is restricted by the cognitive bias bottleneck between the teacher (LLMs) and student (SLMs) models. This provides new perspectives on the transferability of reasoning skills, paving the way for the development of SLMs that combine efficiency with genuine cognitive capability.", "AI": {"tldr": "FutureMind\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u81ea\u9002\u5e94\u77e5\u8bc6\u84b8\u998f\uff0c\u4e3a\u5c0f\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u6218\u7565\u601d\u7ef4\u6a21\u5f0f\u5148\u9a8c\uff0c\u4ee5\u89e3\u51b3\u5176\u5728\u590d\u6742\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u548c\u68c0\u7d22\u95ee\u9898\u3002", "motivation": "\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u6210\u672c\u654f\u611f\u548c\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e2d\u5177\u6709\u5438\u5f15\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u9700\u8981\u7ed3\u6784\u5316\u63a8\u7406\u548c\u6709\u6548\u68c0\u7d22\u7684\u590d\u6742\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u8ba9\u5c0f\u8bed\u8a00\u6a21\u578b\u5177\u5907\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u6548\u7387\u4f18\u52bf\u3002", "method": "\u63d0\u51faFutureMind\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u5173\u952e\u6a21\u5757\uff1a\u95ee\u9898\u5206\u6790\u3001\u903b\u8f91\u63a8\u7406\u3001\u7b56\u7565\u89c4\u5212\u548c\u68c0\u7d22\u6307\u5bfc\u3002\u91c7\u7528\u4e09\u79cd\u4e0d\u540c\u7684\u68c0\u7d22\u8303\u5f0f\u5c06\u590d\u6742\u67e5\u8be2\u5206\u89e3\u4e3a\u53ef\u5904\u7406\u7684\u5b50\u95ee\u9898\u3002\u901a\u8fc7\u81ea\u9002\u5e94\u77e5\u8bc6\u84b8\u998f\u4ece\u5927\u8bed\u8a00\u6a21\u578b\u5411\u5c0f\u8bed\u8a00\u6a21\u578b\u4f20\u9012\u6218\u7565\u601d\u7ef4\u6a21\u5f0f\u3002", "result": "\u5728\u591a\u4e2a\u591a\u8df3QA\u57fa\u51c6\u6d4b\u8bd5\uff082WikiMultihopQA\u3001MuSiQue\u3001Bamboogle\u3001Frames\uff09\u4e0a\uff0cFutureMind\u59cb\u7ec8\u4f18\u4e8eSearch-o1\u7b49\u5f3a\u57fa\u7ebf\uff0c\u5728\u4e0d\u540c\u67b6\u6784\u548c\u89c4\u6a21\u7684\u5c0f\u8bed\u8a00\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u514d\u8d39\u8bad\u7ec3\u6761\u4ef6\u4e0b\u7684\u6700\u5148\u8fdb\u7ed3\u679c\u3002", "conclusion": "FutureMind\u6210\u529f\u63d0\u5347\u4e86\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u601d\u7ef4\u6a21\u5f0f\u84b8\u998f\u8fc7\u7a0b\u53d7\u5230\u6559\u5e08\uff08\u5927\u8bed\u8a00\u6a21\u578b\uff09\u548c\u5b66\u751f\uff08\u5c0f\u8bed\u8a00\u6a21\u578b\uff09\u4e4b\u95f4\u8ba4\u77e5\u504f\u5dee\u74f6\u9888\u7684\u9650\u5236\uff0c\u8fd9\u4e3a\u63a8\u7406\u6280\u80fd\u7684\u53ef\u8fc1\u79fb\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.01276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01276", "abs": "https://arxiv.org/abs/2602.01276", "authors": ["Abdulsobur Oyewale", "Tommaso Soru"], "title": "LLM-Driven Ontology Construction for Enterprise Knowledge Graphs", "comment": "20th International Conference on Semantic Computing (ICSC 2026)", "summary": "Enterprise Knowledge Graphs have become essential for unifying heterogeneous data and enforcing semantic governance. However, the construction of their underlying ontologies remains a resource-intensive, manual process that relies heavily on domain expertise. This paper introduces OntoEKG, a LLM-driven pipeline designed to accelerate the generation of domain-specific ontologies from unstructured enterprise data. Our approach decomposes the modelling task into two distinct phases: an extraction module that identifies core classes and properties, and an entailment module that logically structures these elements into a hierarchy before serialising them into standard RDF. Addressing the significant lack of comprehensive benchmarks for end-to-end ontology construction, we adopt a new evaluation dataset derived from documents across the Data, Finance, and Logistics sectors. Experimental results highlight both the potential and the challenges of this approach, achieving a fuzzy-match F1-score of 0.724 in the Data domain while revealing limitations in scope definition and hierarchical reasoning.", "AI": {"tldr": "OntoEKG\uff1a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u672c\u4f53\u6784\u5efa\u6d41\u6c34\u7ebf\uff0c\u4ece\u975e\u7ed3\u6784\u5316\u4f01\u4e1a\u6570\u636e\u751f\u6210\u9886\u57df\u7279\u5b9a\u672c\u4f53\uff0c\u5728\u6570\u636e\u9886\u57df\u8fbe\u52300.724\u7684\u6a21\u7cca\u5339\u914dF1\u5206\u6570", "motivation": "\u4f01\u4e1a\u77e5\u8bc6\u56fe\u8c31\u9700\u8981\u7edf\u4e00\u5f02\u6784\u6570\u636e\u5e76\u5b9e\u65bd\u8bed\u4e49\u6cbb\u7406\uff0c\u4f46\u5e95\u5c42\u672c\u4f53\u6784\u5efa\u4ecd\u662f\u8d44\u6e90\u5bc6\u96c6\u3001\u4f9d\u8d56\u9886\u57df\u4e13\u5bb6\u7684\u624b\u52a8\u8fc7\u7a0b\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848", "method": "\u5c06\u5efa\u6a21\u4efb\u52a1\u5206\u89e3\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u63d0\u53d6\u6a21\u5757\u8bc6\u522b\u6838\u5fc3\u7c7b\u548c\u5c5e\u6027\uff0c\u8574\u542b\u6a21\u5757\u5c06\u8fd9\u4e9b\u5143\u7d20\u903b\u8f91\u7ed3\u6784\u5316\u5f62\u6210\u5c42\u6b21\u7ed3\u6784\uff0c\u6700\u540e\u5e8f\u5217\u5316\u4e3a\u6807\u51c6RDF\u683c\u5f0f", "result": "\u5728\u6570\u636e\u3001\u91d1\u878d\u548c\u7269\u6d41\u9886\u57df\u6587\u6863\u6784\u5efa\u7684\u65b0\u8bc4\u4f30\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u5728\u6570\u636e\u9886\u57df\u8fbe\u5230\u6a21\u7cca\u5339\u914dF1\u5206\u65700.724\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u8303\u56f4\u5b9a\u4e49\u548c\u5c42\u6b21\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027", "conclusion": "OntoEKG\u5c55\u793a\u4e86LLM\u9a71\u52a8\u672c\u4f53\u6784\u5efa\u7684\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u8303\u56f4\u5b9a\u4e49\u548c\u5c42\u6b21\u63a8\u7406\u7684\u6311\u6218\uff0c\u4e3a\u7aef\u5230\u7aef\u672c\u4f53\u6784\u5efa\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc4\u4f30\u57fa\u51c6"}}
{"id": "2602.01297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01297", "abs": "https://arxiv.org/abs/2602.01297", "authors": ["Shaowei Shen", "Xiaohong Yang", "Jie Yang", "Lianfen Huang", "Yongcai Zhang", "Yang Zou", "Seyyedali Hosseinalipour"], "title": "RE-MCDF: Closed-Loop Multi-Expert LLM Reasoning for Knowledge-Grounded Clinical Diagnosis", "comment": "9 pages, 4 figures", "summary": "Electronic medical records (EMRs), particularly in neurology, are inherently heterogeneous, sparse, and noisy, which poses significant challenges for large language models (LLMs) in clinical diagnosis. In such settings, single-agent systems are vulnerable to self-reinforcing errors, as their predictions lack independent validation and can drift toward spurious conclusions. Although recent multi-agent frameworks attempt to mitigate this issue through collaborative reasoning, their interactions are often shallow and loosely structured, failing to reflect the rigorous, evidence-driven processes used by clinical experts. More fundamentally, existing approaches largely ignore the rich logical dependencies among diseases, such as mutual exclusivity, pathological compatibility, and diagnostic confusion. This limitation prevents them from ruling out clinically implausible hypotheses, even when sufficient evidence is available. To overcome these, we propose RE-MCDF, a relation-enhanced multi-expert clinical diagnosis framework. RE-MCDF introduces a generation--verification--revision closed-loop architecture that integrates three complementary components: (i) a primary expert that generates candidate diagnoses and supporting evidence, (ii) a laboratory expert that dynamically prioritizes heterogeneous clinical indicators, and (iii) a multi-relation awareness and evaluation expert group that explicitly enforces inter-disease logical constraints. Guided by a medical knowledge graph (MKG), the first two experts adaptively reweight EMR evidence, while the expert group validates and corrects candidate diagnoses to ensure logical consistency. Extensive experiments on the neurology subset of CMEMR (NEEMRs) and on our curated dataset (XMEMRs) demonstrate that RE-MCDF consistently outperforms state-of-the-art baselines in complex diagnostic scenarios.", "AI": {"tldr": "RE-MCDF\u662f\u4e00\u4e2a\u5173\u7cfb\u589e\u5f3a\u7684\u591a\u4e13\u5bb6\u4e34\u5e8a\u8bca\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210-\u9a8c\u8bc1-\u4fee\u8ba2\u7684\u95ed\u73af\u67b6\u6784\u89e3\u51b3\u795e\u7ecf\u79d1\u7535\u5b50\u75c5\u5386\u8bca\u65ad\u4e2d\u7684\u5f02\u8d28\u6027\u3001\u7a00\u758f\u6027\u548c\u566a\u58f0\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u795e\u7ecf\u79d1\u7535\u5b50\u75c5\u5386\u5177\u6709\u5f02\u8d28\u6027\u3001\u7a00\u758f\u6027\u548c\u566a\u58f0\uff0c\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u5bb9\u6613\u4ea7\u751f\u81ea\u6211\u5f3a\u5316\u7684\u9519\u8bef\uff0c\u73b0\u6709\u591a\u667a\u80fd\u4f53\u6846\u67b6\u4ea4\u4e92\u6d45\u5c42\u4e14\u7f3a\u4e4f\u7ed3\u6784\uff0c\u5ffd\u7565\u4e86\u75be\u75c5\u95f4\u7684\u4e30\u5bcc\u903b\u8f91\u4f9d\u8d56\u5173\u7cfb\uff0c\u65e0\u6cd5\u6392\u9664\u4e34\u5e8a\u4e0d\u53ef\u884c\u7684\u5047\u8bbe\u3002", "method": "\u63d0\u51faRE-MCDF\u6846\u67b6\uff0c\u91c7\u7528\u751f\u6210-\u9a8c\u8bc1-\u4fee\u8ba2\u95ed\u73af\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u4e92\u8865\u7ec4\u4ef6\uff1a1\uff09\u751f\u6210\u5019\u9009\u8bca\u65ad\u548c\u652f\u6301\u8bc1\u636e\u7684\u4e3b\u8981\u4e13\u5bb6\uff1b2\uff09\u52a8\u6001\u4f18\u5148\u5904\u7406\u5f02\u8d28\u6027\u4e34\u5e8a\u6307\u6807\u7684\u5b9e\u9a8c\u5ba4\u4e13\u5bb6\uff1b3\uff09\u5f3a\u5236\u6267\u884c\u75be\u75c5\u95f4\u903b\u8f91\u7ea6\u675f\u7684\u591a\u5173\u7cfb\u611f\u77e5\u4e0e\u8bc4\u4f30\u4e13\u5bb6\u7ec4\u3002\u57fa\u4e8e\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\uff0c\u524d\u4e24\u4e2a\u4e13\u5bb6\u81ea\u9002\u5e94\u91cd\u65b0\u52a0\u6743\u7535\u5b50\u75c5\u5386\u8bc1\u636e\uff0c\u4e13\u5bb6\u7ec4\u9a8c\u8bc1\u548c\u4fee\u6b63\u5019\u9009\u8bca\u65ad\u4ee5\u786e\u4fdd\u903b\u8f91\u4e00\u81f4\u6027\u3002", "result": "\u5728CMEMR\u795e\u7ecf\u79d1\u5b50\u96c6\uff08NEEMRs\uff09\u548c\u81ea\u5efa\u6570\u636e\u96c6\uff08XMEMRs\uff09\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cRE-MCDF\u5728\u590d\u6742\u8bca\u65ad\u573a\u666f\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "RE-MCDF\u901a\u8fc7\u6574\u5408\u591a\u4e13\u5bb6\u534f\u4f5c\u548c\u663e\u5f0f\u903b\u8f91\u7ea6\u675f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u79d1\u7535\u5b50\u75c5\u5386\u8bca\u65ad\u4e2d\u7684\u6311\u6218\uff0c\u4e3a\u4e34\u5e8a\u51b3\u7b56\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u652f\u6301\u3002"}}
{"id": "2602.01425", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01425", "abs": "https://arxiv.org/abs/2602.01425", "authors": ["Vikram Natarajan", "Devina Jain", "Shivam Arora", "Satvik Golechha", "Joseph Bloom"], "title": "Building Better Deception Probes Using Targeted Instruction Pairs", "comment": null, "summary": "Linear probes are a promising approach for monitoring AI systems for deceptive behaviour. Previous work has shown that a linear classifier trained on a contrastive instruction pair and a simple dataset can achieve good performance. However, these probes exhibit notable failures even in straightforward scenarios, including spurious correlations and false positives on non-deceptive responses. In this paper, we identify the importance of the instruction pair used during training. Furthermore, we show that targeting specific deceptive behaviors through a human-interpretable taxonomy of deception leads to improved results on evaluation datasets. Our findings reveal that instruction pairs capture deceptive intent rather than content-specific patterns, explaining why prompt choice dominates probe performance (70.6% of variance). Given the heterogeneity of deception types across datasets, we conclude that organizations should design specialized probes targeting their specific threat models rather than seeking a universal deception detector.", "AI": {"tldr": "\u7ebf\u6027\u63a2\u9488\u5728\u68c0\u6d4bAI\u7cfb\u7edf\u6b3a\u9a97\u884c\u4e3a\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u865a\u5047\u76f8\u5173\u6027\u548c\u8bef\u62a5\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\u8bad\u7ec3\u65f6\u4f7f\u7528\u7684\u6307\u4ee4\u5bf9\u9009\u62e9\u5bf9\u63a2\u9488\u6027\u80fd\u5f71\u54cd\u6700\u5927\uff08\u536070.6%\u65b9\u5dee\uff09\uff0c\u4e14\u9488\u5bf9\u7279\u5b9a\u6b3a\u9a97\u7c7b\u578b\u7684\u4e13\u95e8\u5316\u63a2\u9488\u6bd4\u901a\u7528\u6b3a\u9a97\u68c0\u6d4b\u5668\u66f4\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u7ebf\u6027\u63a2\u9488\u65b9\u6cd5\u5728\u68c0\u6d4bAI\u7cfb\u7edf\u6b3a\u9a97\u884c\u4e3a\u65f6\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff0c\u5305\u62ec\u865a\u5047\u76f8\u5173\u6027\u548c\u5bf9\u975e\u6b3a\u9a97\u6027\u54cd\u5e94\u7684\u8bef\u62a5\u3002\u9700\u8981\u7406\u89e3\u8fd9\u4e9b\u5931\u8d25\u7684\u539f\u56e0\u5e76\u6539\u8fdb\u63a2\u9488\u8bbe\u8ba1\uff0c\u4ee5\u63d0\u9ad8\u6b3a\u9a97\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86\u8bad\u7ec3\u65f6\u4f7f\u7528\u7684\u6307\u4ee4\u5bf9\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u6b3a\u9a97\u5206\u7c7b\u6cd5\u6765\u9488\u5bf9\u7279\u5b9a\u6b3a\u9a97\u884c\u4e3a\u8bbe\u8ba1\u63a2\u9488\u3002\u901a\u8fc7\u5bf9\u6bd4\u4e0d\u540c\u6307\u4ee4\u5bf9\u548c\u6b3a\u9a97\u7c7b\u578b\uff0c\u8bc4\u4f30\u63a2\u9488\u6027\u80fd\u7684\u53d8\u5316\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6307\u4ee4\u5bf9\u4e3b\u8981\u6355\u6349\u6b3a\u9a97\u610f\u56fe\u800c\u975e\u5185\u5bb9\u7279\u5b9a\u6a21\u5f0f\uff0c\u8fd9\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u63d0\u793a\u9009\u62e9\u4e3b\u5bfc\u63a2\u9488\u6027\u80fd\uff08\u536070.6%\u65b9\u5dee\uff09\u3002\u9488\u5bf9\u7279\u5b9a\u6b3a\u9a97\u7c7b\u578b\u8bbe\u8ba1\u7684\u4e13\u95e8\u5316\u63a2\u9488\u5728\u8bc4\u4f30\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u7531\u4e8e\u4e0d\u540c\u6570\u636e\u96c6\u4e2d\u6b3a\u9a97\u7c7b\u578b\u7684\u5f02\u8d28\u6027\uff0c\u7ec4\u7ec7\u5e94\u8be5\u8bbe\u8ba1\u9488\u5bf9\u5176\u7279\u5b9a\u5a01\u80c1\u6a21\u578b\u7684\u4e13\u95e8\u5316\u63a2\u9488\uff0c\u800c\u4e0d\u662f\u5bfb\u6c42\u901a\u7528\u7684\u6b3a\u9a97\u68c0\u6d4b\u5668\u3002\u6307\u4ee4\u5bf9\u9009\u62e9\u662f\u5f71\u54cd\u63a2\u9488\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2602.01518", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01518", "abs": "https://arxiv.org/abs/2602.01518", "authors": ["Jongseok Park", "Sunga Kim", "Alvin Cheung", "Ion Stoica"], "title": "Qrita: High-performance Top-k and Top-p Algorithm for GPUs using Pivot-based Truncation and Selection", "comment": null, "summary": "Top-k and Top-p are the dominant truncation operators in the sampling of large language models. Despite their widespread use, implementing them efficiently over large vocabularies remains a significant challenge. Existing approaches often rely on sorting, which incur significant computation and memory overhead on GPUs, or stochastic approaches, which alter the algorithm output. In this work, we propose Qrita, an efficient Top-k and Top-p algorithm based on a pivot-based selection strategy. Based on RTop-k, which uses a pivot-based search for node selection in graph neural networks, Qrita extends the concept of pivot-based search to both Top-k and Top-p with two key techniques: 1. Gaussian-based sigma-truncation, which greatly reduces the search space of the target elements, and 2. Quaternary pivot search with duplication handling, which halves the pivot search iteration and guarantees deterministic output. We provide the full implementation of Qrita using Triton, a popular GPU programming language. Our evaluation of Qrita against the Top-k and Top-p kernels of high performance LLM execution engines such as vLLM, SGLang, and Flashinfer show that Qrita achieves up to 2 times throughput and half memory use while providing the same output to the the sorting-based algorithms.", "AI": {"tldr": "Qrita\u662f\u4e00\u79cd\u57fa\u4e8e\u67a2\u8f74\u9009\u62e9\u7b56\u7565\u7684\u9ad8\u6548Top-k\u548cTop-p\u7b97\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u6392\u5e8f\u65b9\u6cd5\u5728GPU\u4e0a\u5b9e\u73b02\u500d\u541e\u5410\u91cf\u548c\u4e00\u534a\u5185\u5b58\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u786e\u5b9a\u6027\u8f93\u51fa\u3002", "motivation": "Top-k\u548cTop-p\u662f\u5927\u8bed\u8a00\u6a21\u578b\u91c7\u6837\u4e2d\u7684\u4e3b\u8981\u622a\u65ad\u7b97\u5b50\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u8bcd\u6c47\u8868\u4e0a\u9ad8\u6548\u5b9e\u73b0\u4ecd\u7136\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u6392\u5e8f\uff08\u5e26\u6765\u663e\u8457\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\uff09\uff0c\u8981\u4e48\u4f7f\u7528\u968f\u673a\u65b9\u6cd5\uff08\u6539\u53d8\u7b97\u6cd5\u8f93\u51fa\uff09\u3002", "method": "\u57fa\u4e8eRTop-k\u7684\u67a2\u8f74\u641c\u7d22\u601d\u60f3\uff0cQrita\u6269\u5c55\u4e86\u67a2\u8f74\u641c\u7d22\u5230Top-k\u548cTop-p\uff0c\u91c7\u7528\u4e24\u79cd\u5173\u952e\u6280\u672f\uff1a1\uff09\u57fa\u4e8e\u9ad8\u65af\u5206\u5e03\u7684sigma\u622a\u65ad\uff0c\u5927\u5e45\u51cf\u5c11\u76ee\u6807\u5143\u7d20\u7684\u641c\u7d22\u7a7a\u95f4\uff1b2\uff09\u56db\u5143\u67a2\u8f74\u641c\u7d22\u4e0e\u91cd\u590d\u5904\u7406\uff0c\u5c06\u67a2\u8f74\u641c\u7d22\u8fed\u4ee3\u51cf\u534a\u5e76\u4fdd\u8bc1\u786e\u5b9a\u6027\u8f93\u51fa\u3002\u4f7f\u7528Triton GPU\u7f16\u7a0b\u8bed\u8a00\u5b9e\u73b0\u3002", "result": "\u4e0evLLM\u3001SGLang\u548cFlashinfer\u7b49\u9ad8\u6027\u80fdLLM\u6267\u884c\u5f15\u64ce\u7684Top-k\u548cTop-p\u5185\u6838\u76f8\u6bd4\uff0cQrita\u5b9e\u73b0\u4e86\u9ad8\u8fbe2\u500d\u7684\u541e\u5410\u91cf\u548c\u4e00\u534a\u7684\u5185\u5b58\u4f7f\u7528\uff0c\u540c\u65f6\u63d0\u4f9b\u4e0e\u6392\u5e8f\u7b97\u6cd5\u76f8\u540c\u7684\u8f93\u51fa\u3002", "conclusion": "Qrita\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u786e\u5b9a\u6027\u7684Top-k\u548cTop-p\u7b97\u6cd5\uff0c\u901a\u8fc7\u67a2\u8f74\u9009\u62e9\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86GPU\u4e0a\u7684\u6027\u80fd\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u91c7\u6837\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01539", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.01539", "abs": "https://arxiv.org/abs/2602.01539", "authors": ["Xiaoyu Wen", "Zhida He", "Han Qi", "Ziyu Wan", "Zhongtian Ma", "Ying Wen", "Tianhang Zheng", "Xingcheng Xu", "Chaochao Lu", "Qiaosheng Zhang"], "title": "MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety", "comment": null, "summary": "Ensuring robust safety alignment is crucial for Large Language Models (LLMs), yet existing defenses often lag behind evolving adversarial attacks due to their \\textbf{reliance on static, pre-collected data distributions}. In this paper, we introduce \\textbf{MAGIC}, a novel multi-turn multi-agent reinforcement learning framework that formulates LLM safety alignment as an adversarial asymmetric game. Specifically, an attacker agent learns to iteratively rewrite original queries into deceptive prompts, while a defender agent simultaneously optimizes its policy to recognize and refuse such inputs. This dynamic process triggers a \\textbf{co-evolution}, where the attacker's ever-changing strategies continuously uncover long-tail vulnerabilities, driving the defender to generalize to unseen attack patterns. Remarkably, we observe that the attacker, endowed with initial reasoning ability, evolves \\textbf{novel, previously unseen combinatorial strategies} through iterative RL training, underscoring our method's substantial potential. Theoretically, we provide insights into a more robust game equilibrium and derive safety guarantees. Extensive experiments validate our framework's effectiveness, demonstrating superior defense success rates without compromising the helpfulness of the model. Our code is available at https://github.com/BattleWen/MAGIC.", "AI": {"tldr": "MAGIC\u6846\u67b6\u901a\u8fc7\u591a\u8f6e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5c06LLM\u5b89\u5168\u5bf9\u9f50\u5efa\u6a21\u4e3a\u5bf9\u6297\u6027\u975e\u5bf9\u79f0\u535a\u5f08\uff0c\u653b\u51fb\u8005\u5b66\u4e60\u6539\u5199\u67e5\u8be2\u751f\u6210\u6b3a\u9a97\u6027\u63d0\u793a\uff0c\u9632\u5fa1\u8005\u5b66\u4e60\u8bc6\u522b\u5e76\u62d2\u7edd\u6b64\u7c7b\u8f93\u5165\uff0c\u5b9e\u73b0\u534f\u540c\u8fdb\u5316\u4ee5\u63d0\u5347\u5b89\u5168\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709LLM\u5b89\u5168\u9632\u5fa1\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u9884\u6536\u96c6\u6570\u636e\u5206\u5e03\uff0c\u96be\u4ee5\u5e94\u5bf9\u4e0d\u65ad\u6f14\u5316\u7684\u5bf9\u6297\u653b\u51fb\uff0c\u9700\u8981\u52a8\u6001\u9002\u5e94\u6027\u7684\u5b89\u5168\u5bf9\u9f50\u6846\u67b6\u3002", "method": "\u63d0\u51faMAGIC\u591a\u8f6e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u5b89\u5168\u5bf9\u9f50\u5efa\u6a21\u4e3a\u5bf9\u6297\u6027\u975e\u5bf9\u79f0\u535a\u5f08\uff1a\u653b\u51fb\u8005\u667a\u80fd\u4f53\u8fed\u4ee3\u6539\u5199\u539f\u59cb\u67e5\u8be2\u751f\u6210\u6b3a\u9a97\u6027\u63d0\u793a\uff0c\u9632\u5fa1\u8005\u667a\u80fd\u4f53\u540c\u65f6\u4f18\u5316\u7b56\u7565\u8bc6\u522b\u5e76\u62d2\u7edd\u6b64\u7c7b\u8f93\u5165\uff0c\u5b9e\u73b0\u534f\u540c\u8fdb\u5316\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\uff0c\u5c55\u793a\u4f18\u8d8a\u7684\u9632\u5fa1\u6210\u529f\u7387\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u7684\u6709\u7528\u6027\uff1b\u653b\u51fb\u8005\u901a\u8fc7\u8fed\u4ee3RL\u8bad\u7ec3\u6f14\u5316\u51fa\u65b0\u9896\u7684\u3001\u5148\u524d\u672a\u89c1\u8fc7\u7684\u7ec4\u5408\u7b56\u7565\uff0c\u63ed\u793a\u65b9\u6cd5\u7684\u5de8\u5927\u6f5c\u529b\u3002", "conclusion": "MAGIC\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u5bf9\u6297\u8bad\u7ec3\u5b9e\u73b0LLM\u5b89\u5168\u5bf9\u9f50\uff0c\u63d0\u4f9b\u7406\u8bba\u4e0a\u7684\u5b89\u5168\u4fdd\u8bc1\u548c\u66f4\u9c81\u68d2\u7684\u6e38\u620f\u5747\u8861\uff0c\u4e3a\u5e94\u5bf9\u4e0d\u65ad\u6f14\u5316\u7684\u5bf9\u6297\u653b\u51fb\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01550", "abs": "https://arxiv.org/abs/2602.01550", "authors": ["S1-NexusAgent Team"], "title": "S1-NexusAgent: a Self-Evolving Agent Framework for Multidisciplinary Scientific Research", "comment": "In progress", "summary": "Modern scientific research relies on large-scale data, complex workflows, and specialized tools, which existing LLMs and tool-based agents struggle to handle due to limitations in long-horizon planning, robust goal maintenance, and continual learning from execution. To address these issues, in this work, we propose S1-NexusAgent, a self-evolving agent framework designed for multidisciplinary scientific research. S1-NexusAgent adopts a hierarchical Plan-and-CodeAct execution paradigm, decoupling global scientific planning from subtask-level tool execution through a dual-loop architecture, thereby enabling stable modeling of complex research workflows. The system natively supports the Model Context Protocol (MCP), integrates up to thousands of cross-disciplinary scientific tools, and achieves efficient orchestration of heterogeneous research tools via intention-aware dynamic tool retrieval and hot-plug mechanisms. To address long-context and large-scale data challenges in scientific settings, S1-NexusAgent introduces object-reference-based sparse context management, which enables sub-task context isolation and intermediate result compression. Building on this, a Critic Agent automatically evaluates complete execution trajectories and distills high-quality research paths into reusable Scientific Skills, forming a closed loop for continuous self-evolution, which is valuable for sustainable and long-horizon scientific research. Experiments on authoritative scientific benchmarks involving long-horizon planning and complex specialized tool orchestration, including biomini-eval (biology), ChemBench (chemistry), and MatSciBench (material science), demonstrate that S1-NexusAgent achieves state-of-the-art performance, validating its effectiveness and generalization capability in complex scientific tasks.", "AI": {"tldr": "S1-NexusAgent\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u5b66\u79d1\u79d1\u5b66\u7814\u7a76\u7684\u81ea\u8fdb\u5316\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u89c4\u5212-\u6267\u884c\u67b6\u6784\u3001MCP\u534f\u8bae\u96c6\u6210\u6570\u5343\u79cd\u8de8\u5b66\u79d1\u5de5\u5177\u3001\u7a00\u758f\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u6280\u80fd\u84b8\u998f\u673a\u5236\uff0c\u5728\u590d\u6742\u79d1\u5b66\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u548c\u57fa\u4e8e\u5de5\u5177\u7684\u667a\u80fd\u4f53\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u3001\u590d\u6742\u5de5\u4f5c\u6d41\u548c\u4e13\u7528\u5de5\u5177\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u7279\u522b\u662f\u5728\u957f\u65f6\u7a0b\u89c4\u5212\u3001\u9c81\u68d2\u76ee\u6807\u7ef4\u62a4\u548c\u6301\u7eed\u5b66\u4e60\u65b9\u9762\uff0c\u96be\u4ee5\u6ee1\u8db3\u73b0\u4ee3\u79d1\u5b66\u7814\u7a76\u9700\u6c42\u3002", "method": "\u91c7\u7528\u5206\u5c42Plan-and-CodeAct\u6267\u884c\u8303\u5f0f\uff0c\u901a\u8fc7\u53cc\u5faa\u73af\u67b6\u6784\u89e3\u8026\u5168\u5c40\u79d1\u5b66\u89c4\u5212\u548c\u5b50\u4efb\u52a1\u7ea7\u5de5\u5177\u6267\u884c\uff1b\u539f\u751f\u652f\u6301MCP\u534f\u8bae\uff0c\u96c6\u6210\u6570\u5343\u79cd\u8de8\u5b66\u79d1\u5de5\u5177\uff1b\u5f15\u5165\u57fa\u4e8e\u5bf9\u8c61\u5f15\u7528\u7684\u7a00\u758f\u4e0a\u4e0b\u6587\u7ba1\u7406\uff1b\u901a\u8fc7Critic Agent\u81ea\u52a8\u8bc4\u4f30\u6267\u884c\u8f68\u8ff9\u5e76\u63d0\u70bc\u9ad8\u8d28\u91cf\u7814\u7a76\u8def\u5f84\u4e3a\u53ef\u91cd\u7528\u79d1\u5b66\u6280\u80fd\u3002", "result": "\u5728\u6d89\u53ca\u957f\u65f6\u7a0b\u89c4\u5212\u548c\u590d\u6742\u4e13\u7528\u5de5\u5177\u7f16\u6392\u7684\u6743\u5a01\u79d1\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff08biomini-eval\u3001ChemBench\u3001MatSciBench\uff09\u4e2d\uff0cS1-NexusAgent\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u590d\u6742\u79d1\u5b66\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "S1-NexusAgent\u901a\u8fc7\u81ea\u8fdb\u5316\u6846\u67b6\u89e3\u51b3\u4e86\u79d1\u5b66\u7814\u7a76\u7684\u6838\u5fc3\u6311\u6218\uff0c\u4e3a\u53ef\u6301\u7eed\u548c\u957f\u65f6\u7a0b\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u8de8\u5b66\u79d1\u79d1\u5b66\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.01556", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01556", "abs": "https://arxiv.org/abs/2602.01556", "authors": ["Hong Su"], "title": "Autonomous Question Formation for Large Language Model-Driven AI Systems", "comment": null, "summary": "Large language model (LLM)-driven AI systems are increasingly important for autonomous decision-making in dynamic and open environments. However, most existing systems rely on predefined tasks and fixed prompts, limiting their ability to autonomously identify what problems should be solved when environmental conditions change. In this paper, we propose a human-simulation-based framework that enables AI systems to autonomously form questions and set tasks by reasoning over their internal states, environmental observations, and interactions with other AI systems. The proposed method treats question formation as a first-class decision process preceding task selection and execution, and integrates internal-driven, environment-aware, and inter-agent-aware prompting scopes to progressively expand cognitive coverage. In addition, the framework supports learning the question-formation process from experience, allowing the system to improve its adaptability and decision quality over time. xperimental results in a multi-agent simulation environment show that environment-aware prompting significantly reduces no-eat events compared with the internal-driven baseline, and inter-agent-aware prompting further reduces cumulative no-eat events by more than 60% over a 20-day simulation, with statistically significant improvements (p < 0.05).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4eba\u7c7b\u6a21\u62df\u7684\u6846\u67b6\uff0c\u4f7fAI\u7cfb\u7edf\u80fd\u81ea\u4e3b\u5f62\u6210\u95ee\u9898\u5e76\u8bbe\u5b9a\u4efb\u52a1\uff0c\u901a\u8fc7\u63a8\u7406\u5185\u90e8\u72b6\u6001\u3001\u73af\u5883\u89c2\u5bdf\u548c\u4e0e\u5176\u4ed6AI\u7cfb\u7edf\u7684\u4ea4\u4e92\uff0c\u5c06\u95ee\u9898\u5f62\u6210\u4f5c\u4e3a\u4efb\u52a1\u9009\u62e9\u548c\u6267\u884c\u7684\u5148\u51b3\u51b3\u7b56\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709LLM\u9a71\u52a8\u7684AI\u7cfb\u7edf\u5927\u591a\u4f9d\u8d56\u9884\u5b9a\u4e49\u4efb\u52a1\u548c\u56fa\u5b9a\u63d0\u793a\uff0c\u9650\u5236\u4e86\u5176\u5728\u73af\u5883\u53d8\u5316\u65f6\u81ea\u4e3b\u8bc6\u522b\u5e94\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\uff0c\u9700\u8981\u66f4\u81ea\u4e3b\u7684\u95ee\u9898\u5f62\u6210\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4eba\u7c7b\u6a21\u62df\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u5f62\u6210\u4f5c\u4e3a\u9996\u8981\u51b3\u7b56\u8fc7\u7a0b\uff0c\u96c6\u6210\u5185\u90e8\u9a71\u52a8\u3001\u73af\u5883\u611f\u77e5\u548c\u667a\u80fd\u4f53\u95f4\u611f\u77e5\u7684\u63d0\u793a\u8303\u56f4\uff0c\u9010\u6b65\u6269\u5c55\u8ba4\u77e5\u8986\u76d6\uff0c\u5e76\u652f\u6301\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u95ee\u9898\u5f62\u6210\u8fc7\u7a0b\u3002", "result": "\u5728\u591a\u667a\u80fd\u4f53\u4eff\u771f\u73af\u5883\u4e2d\uff0c\u73af\u5883\u611f\u77e5\u63d0\u793a\u76f8\u6bd4\u5185\u90e8\u9a71\u52a8\u57fa\u7ebf\u663e\u8457\u51cf\u5c11\u65e0\u8fdb\u98df\u4e8b\u4ef6\uff0c\u667a\u80fd\u4f53\u95f4\u611f\u77e5\u63d0\u793a\u8fdb\u4e00\u6b65\u5c0620\u5929\u4eff\u771f\u4e2d\u7684\u7d2f\u79ef\u65e0\u8fdb\u98df\u4e8b\u4ef6\u51cf\u5c1160%\u4ee5\u4e0a\uff0c\u7edf\u8ba1\u663e\u8457\u6539\u5584(p<0.05)\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f7fAI\u7cfb\u7edf\u80fd\u81ea\u4e3b\u5f62\u6210\u95ee\u9898\u5e76\u8bbe\u5b9a\u4efb\u52a1\uff0c\u901a\u8fc7\u591a\u7ea7\u63d0\u793a\u8303\u56f4\u63d0\u9ad8\u51b3\u7b56\u9002\u5e94\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u663e\u8457\u6539\u5584\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u51b3\u7b56\u8d28\u91cf\u3002"}}
{"id": "2602.01608", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01608", "abs": "https://arxiv.org/abs/2602.01608", "authors": ["Mu Yuan", "Liekang Zeng", "Guoliang Xing", "Lan Zhang", "Yunhao Liu"], "title": "Reasoning with Autoregressive-Diffusion Collaborative Thoughts", "comment": null, "summary": "Autoregressive and diffusion models represent two complementary generative paradigms. Autoregressive models excel at sequential planning and constraint composition, yet struggle with tasks that require explicit spatial or physical grounding. Diffusion models, in contrast, capture rich spatial structure through high-dimensional generation, but lack the stepwise logical control needed to satisfy complex, multi-stage constraints or to reliably identify and correct errors. We introduce Collaborative Thoughts, a unified collaborative framework that enables autoregressive and diffusion models to reason and generate jointly through a closed-loop interaction. In Collaborative Thoughts, autoregressive models perform structured planning and constraint management, diffusion models instantiate these constraints as intermediate visual thoughts, and a vision-based critic module evaluates whether the visual thoughts satisfy the intended structural and physical requirements. This feedback is then used to iteratively refine subsequent planning and generation steps, mitigating error propagation across modalities. Importantly, Collaborative Thoughts uses the same collaborative loop regardless of whether the task is autoregressive question answering or diffusion-based visual generation. Through representative examples, we illustrate how Collaborative Thoughts can improve the reliability of spatial reasoning and the controllability of generation.", "AI": {"tldr": "\u63d0\u51faCollaborative Thoughts\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u56de\u5f52\u6a21\u578b\u548c\u6269\u6563\u6a21\u578b\u7684\u95ed\u73af\u534f\u4f5c\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u89c4\u5212\u4e0e\u89c6\u89c9\u751f\u6210\uff0c\u63d0\u5347\u7a7a\u95f4\u63a8\u7406\u53ef\u9760\u6027\u548c\u751f\u6210\u53ef\u63a7\u6027\u3002", "motivation": "\u81ea\u56de\u5f52\u6a21\u578b\u64c5\u957f\u5e8f\u5217\u89c4\u5212\u548c\u7ea6\u675f\u7ec4\u5408\uff0c\u4f46\u7f3a\u4e4f\u7a7a\u95f4\u7269\u7406\u57fa\u7840\uff1b\u6269\u6563\u6a21\u578b\u80fd\u6355\u6349\u4e30\u5bcc\u7a7a\u95f4\u7ed3\u6784\uff0c\u4f46\u7f3a\u4e4f\u9010\u6b65\u903b\u8f91\u63a7\u5236\u3002\u4e24\u8005\u4e92\u8865\u4f46\u5404\u81ea\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u7edf\u4e00\u6846\u67b6\u5b9e\u73b0\u534f\u540c\u5de5\u4f5c\u3002", "method": "Collaborative Thoughts\u6846\u67b6\uff1a\u81ea\u56de\u5f52\u6a21\u578b\u8d1f\u8d23\u7ed3\u6784\u5316\u89c4\u5212\u548c\u7ea6\u675f\u7ba1\u7406\uff0c\u6269\u6563\u6a21\u578b\u5c06\u7ea6\u675f\u5b9e\u4f8b\u5316\u4e3a\u4e2d\u95f4\u89c6\u89c9\u601d\u7ef4\uff0c\u89c6\u89c9\u6279\u8bc4\u6a21\u5757\u8bc4\u4f30\u89c6\u89c9\u601d\u7ef4\u662f\u5426\u6ee1\u8db3\u7ed3\u6784\u7269\u7406\u8981\u6c42\uff0c\u901a\u8fc7\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u540e\u7eed\u89c4\u5212\u548c\u751f\u6210\u6b65\u9aa4\u3002", "result": "\u901a\u8fc7\u4ee3\u8868\u6027\u793a\u4f8b\u5c55\u793a\u4e86Collaborative Thoughts\u5982\u4f55\u63d0\u9ad8\u7a7a\u95f4\u63a8\u7406\u7684\u53ef\u9760\u6027\u548c\u751f\u6210\u7684\u53ef\u63a7\u6027\uff0c\u51cf\u5c11\u8de8\u6a21\u6001\u9519\u8bef\u4f20\u64ad\u3002", "conclusion": "Collaborative Thoughts\u4e3a\u81ea\u56de\u5f52\u548c\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u95ed\u73af\u4ea4\u4e92\u5b9e\u73b0\u8054\u5408\u63a8\u7406\u548c\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u4e24\u79cd\u6a21\u578b\u5404\u81ea\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u4e86\u590d\u6742\u7ea6\u675f\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2602.01610", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01610", "abs": "https://arxiv.org/abs/2602.01610", "authors": ["Zitao Guo", "Changyang Jiang", "Tianhong Zhao", "Jinzhou Cao", "Genan Dai", "Bowen Zhang"], "title": "ToPT: Task-Oriented Prompt Tuning for Urban Region Representation Learning", "comment": "The paper has been accepted by ICASSP 2026", "summary": "Learning effective region embeddings from heterogeneous urban data underpins key urban computing tasks (e.g., crime prediction, resource allocation). However, prevailing two-stage methods yield task-agnostic representations, decoupling them from downstream objectives. Recent prompt-based approaches attempt to fix this but introduce two challenges: they often lack explicit spatial priors, causing spatially incoherent inter-region modeling, and they lack robust mechanisms for explicit task-semantic alignment. We propose ToPT, a two-stage framework that delivers spatially consistent fusion and explicit task alignment. ToPT consists of two modules: spatial-aware region embedding learning (SREL) and task-aware prompting for region embeddings (Prompt4RE). SREL employs a Graphormer-based fusion module that injects spatial priors-distance and regional centrality-as learnable attention biases to capture coherent, interpretable inter-region interactions. Prompt4RE performs task-oriented prompting: a frozen multimodal large language model (MLLM) processes task-specific templates to obtain semantic vectors, which are aligned with region embeddings via multi-head cross-attention for stable task conditioning. Experiments across multiple tasks and cities show state-of-the-art performance, with improvements of up to 64.2\\%, validating the necessity and complementarity of spatial priors and prompt-region alignment. The code is available at https://github.com/townSeven/Prompt4RE.git.", "AI": {"tldr": "ToPT\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u7a7a\u95f4\u611f\u77e5\u533a\u57df\u5d4c\u5165\u5b66\u4e60\u548c\u4efb\u52a1\u611f\u77e5\u63d0\u793a\uff0c\u89e3\u51b3\u57ce\u5e02\u533a\u57df\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u7a7a\u95f4\u4e0d\u4e00\u81f4\u548c\u4efb\u52a1\u8bed\u4e49\u5bf9\u9f50\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57ce\u5e02\u4efb\u52a1\u4e0a\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4e24\u9636\u6bb5\u65b9\u6cd5\u4ea7\u751f\u4efb\u52a1\u65e0\u5173\u8868\u793a\uff0c\u4e0e\u4e0b\u6e38\u76ee\u6807\u89e3\u8026\uff1b2\uff09\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u7f3a\u4e4f\u660e\u786e\u7684\u7a7a\u95f4\u5148\u9a8c\uff08\u5bfc\u81f4\u7a7a\u95f4\u4e0d\u8fde\u8d2f\u7684\u533a\u57df\u95f4\u5efa\u6a21\uff09\u548c\u7f3a\u4e4f\u660e\u786e\u4efb\u52a1\u8bed\u4e49\u5bf9\u9f50\u7684\u9c81\u68d2\u673a\u5236\u3002", "method": "ToPT\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1a\u7a7a\u95f4\u611f\u77e5\u533a\u57df\u5d4c\u5165\u5b66\u4e60\uff08SREL\uff09\u548c\u4efb\u52a1\u611f\u77e5\u533a\u57df\u5d4c\u5165\u63d0\u793a\uff08Prompt4RE\uff09\u3002SREL\u4f7f\u7528\u57fa\u4e8eGraphormer\u7684\u878d\u5408\u6a21\u5757\uff0c\u6ce8\u5165\u8ddd\u79bb\u548c\u533a\u57df\u4e2d\u5fc3\u6027\u7b49\u7a7a\u95f4\u5148\u9a8c\u4f5c\u4e3a\u53ef\u5b66\u4e60\u6ce8\u610f\u529b\u504f\u7f6e\uff1bPrompt4RE\u4f7f\u7528\u51bb\u7ed3\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u4efb\u52a1\u7279\u5b9a\u6a21\u677f\u83b7\u5f97\u8bed\u4e49\u5411\u91cf\uff0c\u901a\u8fc7\u591a\u5934\u4ea4\u53c9\u6ce8\u610f\u529b\u4e0e\u533a\u57df\u5d4c\u5165\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u57ce\u5e02\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u6539\u8fdb\u5e45\u5ea6\u9ad8\u8fbe64.2%\uff0c\u9a8c\u8bc1\u4e86\u7a7a\u95f4\u5148\u9a8c\u548c\u63d0\u793a-\u533a\u57df\u5bf9\u9f50\u7684\u5fc5\u8981\u6027\u548c\u4e92\u8865\u6027\u3002", "conclusion": "ToPT\u6846\u67b6\u901a\u8fc7\u7a7a\u95f4\u4e00\u81f4\u878d\u5408\u548c\u660e\u786e\u4efb\u52a1\u5bf9\u9f50\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u57ce\u5e02\u533a\u57df\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u57ce\u5e02\u8ba1\u7b97\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u533a\u57df\u5d4c\u5165\u65b9\u6cd5\u3002"}}
{"id": "2602.01664", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01664", "abs": "https://arxiv.org/abs/2602.01664", "authors": ["Mingda Zhang", "Haoran Luo", "Tiesunlong Shen", "Qika Lin", "Xiaoying Tang", "Rui Mao", "Erik Cambria"], "title": "FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning", "comment": "41 pages, 7 figures, 6 tables. Project page: http://flowsteer.org/", "summary": "In recent years, a variety of powerful agentic workflows have been applied to solve a wide range of human problems. However, existing workflow orchestration still faces key challenges, including high manual cost, reliance on specific operators/large language models (LLMs), and sparse reward signals. To address these challenges, we propose FlowSteer, an end-to-end reinforcement learning framework that takes a lightweight policy model as the agent and an executable canvas environment, automating workflow orchestration through multi-turn interaction. In this process, the policy model analyzes execution states and selects editing actions, while the canvas executes operators and returns feedback for iterative refinement. Moreover, FlowSteer provides a plug-and-play framework that supports diverse operator libraries and interchangeable LLM backends. To effectively train this interaction paradigm, we propose Canvas Workflow Relative Policy Optimization (CWRPO), which introduces diversity-constrained rewards with conditional release to stabilize learning and suppress shortcut behaviors. Experimental results on twelve datasets show that FlowSteer significantly outperforms baselines across various tasks.", "AI": {"tldr": "FlowSteer\uff1a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\u7f16\u6392\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7b56\u7565\u6a21\u578b\u4e0e\u53ef\u6267\u884c\u753b\u5e03\u73af\u5883\u7684\u591a\u8f6e\u4ea4\u4e92\u5b9e\u73b0\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7f16\u6392\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u9ad8\u4eba\u5de5\u6210\u672c\u3001\u4f9d\u8d56\u7279\u5b9a\u7b97\u5b50/\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7a00\u758f\u5956\u52b1\u4fe1\u53f7\u7b49\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u6d41\u7f16\u6392\u9762\u4e34\u4e09\u5927\u5173\u952e\u6311\u6218\uff1a1\uff09\u9ad8\u4eba\u5de5\u6210\u672c\uff1b2\uff09\u4f9d\u8d56\u7279\u5b9a\u7b97\u5b50\u6216\u5927\u8bed\u8a00\u6a21\u578b\uff1b3\uff09\u7a00\u758f\u5956\u52b1\u4fe1\u53f7\u3002\u8fd9\u4e9b\u9650\u5236\u963b\u788d\u4e86\u5de5\u4f5c\u6d41\u7f16\u6392\u7684\u81ea\u52a8\u5316\u548c\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51faFlowSteer\u6846\u67b6\uff0c\u5305\u542b\uff1a1\uff09\u8f7b\u91cf\u7ea7\u7b56\u7565\u6a21\u578b\u4f5c\u4e3a\u667a\u80fd\u4f53\uff1b2\uff09\u53ef\u6267\u884c\u753b\u5e03\u73af\u5883\uff1b3\uff09\u591a\u8f6e\u4ea4\u4e92\u673a\u5236\uff08\u7b56\u7565\u6a21\u578b\u5206\u6790\u6267\u884c\u72b6\u6001\u5e76\u9009\u62e9\u7f16\u8f91\u52a8\u4f5c\uff0c\u753b\u5e03\u6267\u884c\u7b97\u5b50\u5e76\u8fd4\u56de\u53cd\u9988\uff09\uff1b4\uff09\u652f\u6301\u591a\u6837\u5316\u7b97\u5b50\u5e93\u548c\u53ef\u4e92\u6362LLM\u540e\u7aef\u7684\u5373\u63d2\u5373\u7528\u67b6\u6784\uff1b5\uff09Canvas Workflow Relative Policy Optimization (CWRPO)\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5f15\u5165\u591a\u6837\u6027\u7ea6\u675f\u5956\u52b1\u548c\u6761\u4ef6\u91ca\u653e\u673a\u5236\u6765\u7a33\u5b9a\u5b66\u4e60\u5e76\u6291\u5236\u6377\u5f84\u884c\u4e3a\u3002", "result": "\u572812\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFlowSteer\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FlowSteer\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5de5\u4f5c\u6d41\u7f16\u6392\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u3001\u7075\u6d3b\u4e14\u9ad8\u6548\u7684\u5de5\u4f5c\u6d41\u7f16\u6392\uff0c\u4e3a\u590d\u6742\u4efb\u52a1\u89e3\u51b3\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01675", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01675", "abs": "https://arxiv.org/abs/2602.01675", "authors": ["Yuanzhe Shen", "Zisu Huang", "Zhengyuan Wang", "Muzhao Tian", "Zhengkang Guo", "Chenyang Zhang", "Shuaiyu Zhou", "Zengjie Hu", "Dailin Li", "Jingwen Xu", "Kaimin Wang", "Wenhao Liu", "Tianlong Li", "Fengpeng Yue", "Feng Hong", "Cao Liu", "Ke Zeng"], "title": "TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios", "comment": "40 pages, 6figures", "summary": "As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce \\textbf{TRIP-Bench}, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\\% success on the easy split, with performance dropping below 10\\% on hard subsets. We further propose \\textbf{GTPO}, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training.", "AI": {"tldr": "TRIP-Bench\u662f\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u65c5\u884c\u89c4\u5212\u573a\u666f\u7684\u957f\u65f6\u7a0b\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b18\u4e2a\u5de5\u5177\u548c40+\u65c5\u884c\u9700\u6c42\uff0c\u652f\u6301\u81ea\u52a8\u8bc4\u4f30\u3002GTPO\u662f\u4e00\u79cd\u5728\u7ebf\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u63d0\u5347\u7ea6\u675f\u6ee1\u8db3\u548c\u4ea4\u4e92\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u5145\u5206\u4ee3\u8868\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5982\u5f3a\u5236\u6267\u884c\u5168\u5c40\u7ea6\u675f\u3001\u534f\u8c03\u591a\u5de5\u5177\u63a8\u7406\u4ee5\u53ca\u9002\u5e94\u957f\u671f\u591a\u8f6e\u4ea4\u4e92\u4e2d\u4e0d\u65ad\u53d8\u5316\u7684\u7528\u6237\u884c\u4e3a\u3002\u9700\u8981\u5f00\u53d1\u66f4\u8d34\u8fd1\u5b9e\u9645\u5e94\u7528\u573a\u666f\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faTRIP-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5229\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff0c\u5305\u542b18\u4e2a\u7cbe\u9009\u5de5\u5177\u548c40\u591a\u4e2a\u65c5\u884c\u9700\u6c42\uff0c\u652f\u6301\u81ea\u52a8\u8bc4\u4f30\u3002\u540c\u65f6\u63d0\u51faGTPO\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u5177\u6709\u4e13\u95e8\u5956\u52b1\u5f52\u4e00\u5316\u548c\u5956\u52b1\u5dee\u5206\u7684\u5728\u7ebf\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u5148\u8fdb\u6a21\u578b\u5728\u7b80\u5355\u5206\u5272\u4e0a\u6700\u591a\u53ea\u80fd\u8fbe\u523050%\u7684\u6210\u529f\u7387\uff0c\u5728\u56f0\u96be\u5b50\u96c6\u4e0a\u6027\u80fd\u964d\u81f310%\u4ee5\u4e0b\u3002GTPO\u5e94\u7528\u4e8eQwen2.5-32B-Instruct\u6a21\u578b\u65f6\uff0c\u5728\u7ea6\u675f\u6ee1\u8db3\u548c\u4ea4\u4e92\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u4f18\u4e8eGemini-3-Pro\u3002", "conclusion": "TRIP-Bench\u6709\u671b\u63a8\u52a8\u5b9e\u7528\u957f\u65f6\u7a0b\u4ea4\u4e92\u667a\u80fd\u4f53\u7684\u53d1\u5c55\uff0c\u800cGTPO\u4e3a\u9c81\u68d2\u7684\u957f\u65f6\u7a0b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6848\u3002"}}
{"id": "2602.01689", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01689", "abs": "https://arxiv.org/abs/2602.01689", "authors": ["Yongchan Kwon", "James Zou"], "title": "What LLMs Think When You Don't Tell Them What to Think About?", "comment": "NA", "summary": "Characterizing the behavior of large language models (LLMs) across diverse settings is critical for reliable monitoring and AI safety. However, most existing analyses rely on topic- or task-specific prompts, which can substantially limit what can be observed. In this work, we study what LLMs generate from minimal, topic-neutral inputs and probe their near-unconstrained generative behavior. Despite the absence of explicit topics, model outputs cover a broad semantic space, and surprisingly, each model family exhibits strong and systematic topical preferences. GPT-OSS predominantly generates programming (27.1%) and mathematical content (24.6%), whereas Llama most frequently generates literary content (9.1%). DeepSeek often generates religious content, while Qwen frequently generates multiple-choice questions. Beyond topical preferences, we also observe differences in content specialization and depth: GPT-OSS often generates more technically advanced content (e.g., dynamic programming) compared with other models (e.g., basic Python). Furthermore, we find that the near-unconstrained generation often degenerates into repetitive phrases, revealing interesting behaviors unique to each model family. For instance, degenerate outputs from Llama include multiple URLs pointing to personal Facebook and Instagram accounts. We release the complete dataset of 256,000 samples from 16 LLMs, along with a reproducible codebase.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6700\u5c0f\u5316\u3001\u4e3b\u9898\u4e2d\u7acb\u7684\u8f93\u5165\u6765\u63a2\u7a76LLMs\u7684\u65e0\u7ea6\u675f\u751f\u6210\u884c\u4e3a\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u5b58\u5728\u7cfb\u7edf\u6027\u7684\u4e3b\u9898\u504f\u597d\u548c\u9000\u5316\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u5206\u6790\u5927\u591a\u4f9d\u8d56\u7279\u5b9a\u4e3b\u9898\u6216\u4efb\u52a1\u7684\u63d0\u793a\uff0c\u8fd9\u4e25\u91cd\u9650\u5236\u4e86\u53ef\u89c2\u5bdf\u7684\u8303\u56f4\u3002\u4e3a\u4e86\u66f4\u5168\u9762\u5730\u7406\u89e3LLMs\u7684\u884c\u4e3a\u7279\u5f81\uff0c\u9700\u8981\u7814\u7a76\u5b83\u4eec\u5728\u6700\u5c0f\u5316\u3001\u4e3b\u9898\u4e2d\u7acb\u8f93\u5165\u4e0b\u7684\u751f\u6210\u6a21\u5f0f\u3002", "method": "\u4f7f\u7528\u6700\u5c0f\u5316\u3001\u4e3b\u9898\u4e2d\u7acb\u7684\u8f93\u5165\u6765\u63a2\u6d4bLLMs\u7684\u8fd1\u65e0\u7ea6\u675f\u751f\u6210\u884c\u4e3a\u3002\u6536\u96c6\u4e86\u6765\u81ea16\u4e2aLLMs\u7684256,000\u4e2a\u6837\u672c\uff0c\u5206\u6790\u4e0d\u540c\u6a21\u578b\u5728\u65e0\u660e\u786e\u4e3b\u9898\u63d0\u793a\u4e0b\u7684\u751f\u6210\u5185\u5bb9\u3002", "result": "\u5c3d\u7ba1\u6ca1\u6709\u660e\u786e\u4e3b\u9898\uff0c\u6a21\u578b\u8f93\u51fa\u8986\u76d6\u4e86\u5e7f\u6cdb\u7684\u8bed\u4e49\u7a7a\u95f4\uff0c\u6bcf\u4e2a\u6a21\u578b\u5bb6\u65cf\u90fd\u8868\u73b0\u51fa\u5f3a\u70c8\u7684\u7cfb\u7edf\u6027\u4e3b\u9898\u504f\u597d\uff1aGPT-OSS\u4e3b\u8981\u751f\u6210\u7f16\u7a0b(27.1%)\u548c\u6570\u5b66\u5185\u5bb9(24.6%)\uff1bLlama\u6700\u5e38\u751f\u6210\u6587\u5b66\u5185\u5bb9(9.1%)\uff1bDeepSeek\u7ecf\u5e38\u751f\u6210\u5b97\u6559\u5185\u5bb9\uff1bQwen\u7ecf\u5e38\u751f\u6210\u591a\u9879\u9009\u62e9\u9898\u3002\u6b64\u5916\u8fd8\u89c2\u5bdf\u5230\u5185\u5bb9\u4e13\u4e1a\u5316\u548c\u6df1\u5ea6\u7684\u5dee\u5f02\uff0c\u4ee5\u53ca\u9000\u5316\u5230\u91cd\u590d\u77ed\u8bed\u7684\u72ec\u7279\u884c\u4e3a\u6a21\u5f0f\u3002", "conclusion": "LLMs\u5728\u8fd1\u65e0\u7ea6\u675f\u751f\u6210\u6761\u4ef6\u4e0b\u5c55\u73b0\u51fa\u5f3a\u70c8\u7684\u5185\u5728\u4e3b\u9898\u504f\u597d\u548c\u72ec\u7279\u7684\u9000\u5316\u6a21\u5f0f\uff0c\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u4e8e\u53ef\u9760\u7684\u76d1\u63a7\u548cAI\u5b89\u5168\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u4ee3\u7801\u5e93\u548c\u5b8c\u6574\u6570\u636e\u96c6\u4f9b\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2602.01695", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01695", "abs": "https://arxiv.org/abs/2602.01695", "authors": ["Yadong Wang", "Haodong Chen", "Yu Tian", "Chuanxing Geng", "Dong Liang", "Xiang Chen"], "title": "Beyond Dense States: Elevating Sparse Transcoders to Active Operators for Latent Reasoning", "comment": null, "summary": "Latent reasoning compresses the chain-of-thought (CoT) into continuous hidden states, yet existing methods rely on dense latent transitions that remain difficult to interpret and control. Meanwhile, sparse representation models uncover human-interpretable semantic features but remain largely confined to post-hoc analysis. We reconcile this tension by proposing LSTR (Latent Sparse Transcoder Reasoning), a latent reasoning framework that elevates functional sparse transcoders into active reasoning operators to perform multi-step computation through sparse semantic transitions. At its core, LSTR employs a Latent Transition Transcoder (LTT) with a residual skip architecture that decouples linear manifold transport from sparse semantic updates, enabling controllable semantic resolution via explicit sparsity constraints. Extensive experiments show that LSTR preserves reasoning accuracy and compression efficiency while substantially improving interpretability over dense latent baselines. Causal interventions and trajectory analyses further demonstrate that these sparse features act as both interpretable and causally effective operators in the reasoning process.", "AI": {"tldr": "LSTR\u6846\u67b6\u5c06\u7a00\u758f\u7f16\u7801\u5668\u63d0\u5347\u4e3a\u4e3b\u52a8\u63a8\u7406\u7b97\u5b50\uff0c\u901a\u8fc7\u7a00\u758f\u8bed\u4e49\u8f6c\u6362\u8fdb\u884c\u591a\u6b65\u8ba1\u7b97\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u51c6\u786e\u6027\u548c\u538b\u7f29\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u6f5c\u5728\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u5bc6\u96c6\u7684\u6f5c\u5728\u8f6c\u6362\uff0c\u96be\u4ee5\u89e3\u91ca\u548c\u63a7\u5236\uff1b\u800c\u7a00\u758f\u8868\u793a\u6a21\u578b\u867d\u7136\u80fd\u53d1\u73b0\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u8bed\u4e49\u7279\u5f81\uff0c\u4f46\u4e3b\u8981\u5c40\u9650\u4e8e\u4e8b\u540e\u5206\u6790\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u79cd\u5f20\u529b\u3002", "method": "\u63d0\u51faLSTR\uff08\u6f5c\u5728\u7a00\u758f\u8f6c\u7801\u63a8\u7406\uff09\u6846\u67b6\uff0c\u4f7f\u7528\u5177\u6709\u6b8b\u5dee\u8df3\u8dc3\u67b6\u6784\u7684\u6f5c\u5728\u8f6c\u6362\u8f6c\u7801\u5668\uff08LTT\uff09\uff0c\u5c06\u7ebf\u6027\u6d41\u5f62\u4f20\u8f93\u4e0e\u7a00\u758f\u8bed\u4e49\u66f4\u65b0\u89e3\u8026\uff0c\u901a\u8fc7\u663e\u5f0f\u7a00\u758f\u7ea6\u675f\u5b9e\u73b0\u53ef\u63a7\u8bed\u4e49\u5206\u8fa8\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLSTR\u5728\u4fdd\u6301\u63a8\u7406\u51c6\u786e\u6027\u548c\u538b\u7f29\u6548\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u76f8\u5bf9\u4e8e\u5bc6\u96c6\u6f5c\u5728\u57fa\u7ebf\u7684\u53ef\u89e3\u91ca\u6027\u3002\u56e0\u679c\u5e72\u9884\u548c\u8f68\u8ff9\u5206\u6790\u8fdb\u4e00\u6b65\u8bc1\u660e\u8fd9\u4e9b\u7a00\u758f\u7279\u5f81\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u65e2\u662f\u53ef\u89e3\u91ca\u7684\u53c8\u662f\u56e0\u679c\u6709\u6548\u7684\u7b97\u5b50\u3002", "conclusion": "LSTR\u6210\u529f\u5730\u5c06\u7a00\u758f\u8868\u793a\u6a21\u578b\u4ece\u540e\u5206\u6790\u63d0\u5347\u4e3a\u4e3b\u52a8\u63a8\u7406\u7b97\u5b50\uff0c\u901a\u8fc7\u7a00\u758f\u8bed\u4e49\u8f6c\u6362\u5b9e\u73b0\u591a\u6b65\u8ba1\u7b97\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u6539\u5584\u4e86\u6f5c\u5728\u63a8\u7406\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u63a7\u6027\u3002"}}
{"id": "2602.01699", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.01699", "abs": "https://arxiv.org/abs/2602.01699", "authors": ["Willem Fourie"], "title": "Mitigating loss of control in advanced AI systems through instrumental goal trajectories", "comment": null, "summary": "Researchers at artificial intelligence labs and universities are concerned that highly capable artificial intelligence (AI) systems may erode human control by pursuing instrumental goals. Existing mitigations remain largely technical and system-centric: tracking capability in advanced systems, shaping behaviour through methods such as reinforcement learning from human feedback, and designing systems to be corrigible and interruptible. Here we develop instrumental goal trajectories to expand these options beyond the model. Gaining capability typically depends on access to additional technical resources, such as compute, storage, data and adjacent services, which in turn requires access to monetary resources. In organisations, these resources can be obtained through three organisational pathways. We label these pathways the procurement, governance and finance instrumental goal trajectories (IGTs). Each IGT produces a trail of organisational artefacts that can be monitored and used as intervention points when a systems capabilities or behaviour exceed acceptable thresholds. In this way, IGTs offer concrete avenues for defining capability levels and for broadening how corrigibility and interruptibility are implemented, shifting attention from model properties alone to the organisational systems that enable them.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\"\u5de5\u5177\u6027\u76ee\u6807\u8f68\u8ff9\"\u6982\u5ff5\uff0c\u5c06AI\u7cfb\u7edf\u63a7\u5236\u95ee\u9898\u4ece\u6280\u672f\u5c42\u9762\u6269\u5c55\u5230\u7ec4\u7ec7\u5c42\u9762\uff0c\u901a\u8fc7\u76d1\u63a7\u91c7\u8d2d\u3001\u6cbb\u7406\u548c\u8d22\u52a1\u4e09\u6761\u7ec4\u7ec7\u8def\u5f84\u6765\u589e\u5f3a\u5bf9AI\u7cfb\u7edf\u7684\u76d1\u7763\u548c\u5e72\u9884\u80fd\u529b\u3002", "motivation": "\u5f53\u524dAI\u63a7\u5236\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u4e8e\u6280\u672f\u5c42\u9762\uff08\u5982\u80fd\u529b\u8ffd\u8e2a\u3001\u5f3a\u5316\u5b66\u4e60\u3001\u53ef\u7ea0\u6b63\u6027\u8bbe\u8ba1\uff09\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002\u7814\u7a76\u4eba\u5458\u62c5\u5fc3\u9ad8\u5ea6\u667a\u80fd\u7684AI\u7cfb\u7edf\u53ef\u80fd\u901a\u8fc7\u8ffd\u6c42\u5de5\u5177\u6027\u76ee\u6807\u4fb5\u8680\u4eba\u7c7b\u63a7\u5236\u6743\uff0c\u9700\u8981\u4ece\u7ec4\u7ec7\u5c42\u9762\u5bfb\u627e\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\"\u5de5\u5177\u6027\u76ee\u6807\u8f68\u8ff9\"\u6846\u67b6\uff0c\u8bc6\u522bAI\u7cfb\u7edf\u83b7\u53d6\u80fd\u529b\u6240\u9700\u7684\u4e09\u79cd\u7ec4\u7ec7\u8def\u5f84\uff1a\u91c7\u8d2d\u8f68\u8ff9\uff08\u83b7\u53d6\u8ba1\u7b97\u3001\u5b58\u50a8\u7b49\u8d44\u6e90\uff09\u3001\u6cbb\u7406\u8f68\u8ff9\uff08\u7ec4\u7ec7\u51b3\u7b56\u6d41\u7a0b\uff09\u3001\u8d22\u52a1\u8f68\u8ff9\uff08\u8d44\u91d1\u83b7\u53d6\uff09\u3002\u901a\u8fc7\u76d1\u63a7\u8fd9\u4e9b\u8def\u5f84\u4ea7\u751f\u7684\u7ec4\u7ec7\u75d5\u8ff9\uff0c\u5efa\u7acb\u65b0\u7684\u5e72\u9884\u70b9\u3002", "result": "IGTs\u6846\u67b6\u63d0\u4f9b\u4e86\u5177\u4f53\u9014\u5f84\u6765\u5b9a\u4e49AI\u80fd\u529b\u6c34\u5e73\uff0c\u5e76\u5c06\u53ef\u7ea0\u6b63\u6027\u548c\u53ef\u4e2d\u65ad\u6027\u7684\u5b9e\u73b0\u4ece\u6a21\u578b\u5c5e\u6027\u6269\u5c55\u5230\u652f\u6301\u8fd9\u4e9b\u6a21\u578b\u7684\u7ec4\u7ec7\u7cfb\u7edf\uff0c\u4e3aAI\u63a7\u5236\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u76d1\u63a7\u548c\u5e72\u9884\u673a\u5236\u3002", "conclusion": "\u901a\u8fc7\u5c06AI\u63a7\u5236\u95ee\u9898\u4ece\u7eaf\u6280\u672f\u89c6\u89d2\u6269\u5c55\u5230\u7ec4\u7ec7\u5c42\u9762\uff0c\u5de5\u5177\u6027\u76ee\u6807\u8f68\u8ff9\u4e3a\u7ba1\u7406\u9ad8\u7ea7AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u76d1\u63a7\u548c\u5e72\u9884\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u5728AI\u80fd\u529b\u6216\u884c\u4e3a\u8d85\u51fa\u53ef\u63a5\u53d7\u9608\u503c\u65f6\u5b9e\u65bd\u66f4\u6709\u6548\u7684\u63a7\u5236\u63aa\u65bd\u3002"}}
{"id": "2602.01711", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01711", "abs": "https://arxiv.org/abs/2602.01711", "authors": ["Wei Chen", "Yanbin Fang", "Shuran Fu", "Fasheng Xu", "Xuan Wei"], "title": "Optimizing Prompts for Large Language Models: A Causal Approach", "comment": null, "summary": "Large Language Models (LLMs) are increasingly embedded in enterprise workflows, yet their performance remains highly sensitive to prompt design. Automatic Prompt Optimization (APO) seeks to mitigate this instability, but existing approaches face two persistent challenges. First, commonly used prompt strategies rely on static instructions that perform well on average but fail to adapt to heterogeneous queries. Second, more dynamic approaches depend on offline reward models that are fundamentally correlational, confounding prompt effectiveness with query characteristics. We propose Causal Prompt Optimization (CPO), a framework that reframes prompt design as a problem of causal estimation. CPO operates in two stages. First, it learns an offline causal reward model by applying Double Machine Learning (DML) to semantic embeddings of prompts and queries, isolating the causal effect of prompt variations from confounding query attributes. Second, it utilizes this unbiased reward signal to guide a resource-efficient search for query-specific prompts without relying on costly online evaluation. We evaluate CPO across benchmarks in mathematical reasoning, visualization, and data analytics. CPO consistently outperforms human-engineered prompts and state-of-the-art automated optimizers. The gains are driven primarily by improved robustness on hard queries, where existing methods tend to deteriorate. Beyond performance, CPO fundamentally reshapes the economics of prompt optimization: by shifting evaluation from real-time model execution to an offline causal model, it enables high-precision, per-query customization at a fraction of the inference cost required by online methods. Together, these results establish causal inference as a scalable foundation for reliable and cost-efficient prompt optimization in enterprise LLM deployments.", "AI": {"tldr": "CPO\u63d0\u51fa\u56e0\u679c\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u673a\u5668\u5b66\u4e60\u6784\u5efa\u79bb\u7ebf\u56e0\u679c\u5956\u52b1\u6a21\u578b\uff0c\u5206\u79bb\u63d0\u793a\u6548\u679c\u4e0e\u67e5\u8be2\u7279\u5f81\u7684\u6df7\u6dc6\uff0c\u5b9e\u73b0\u9ad8\u6548\u67e5\u8be2\u7279\u5b9a\u63d0\u793a\u4f18\u5316", "motivation": "\u73b0\u6709\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a\u9759\u6001\u6307\u4ee4\u65e0\u6cd5\u9002\u5e94\u5f02\u6784\u67e5\u8be2\uff1b\u52a8\u6001\u65b9\u6cd5\u4f9d\u8d56\u79bb\u7ebf\u5956\u52b1\u6a21\u578b\u5b58\u5728\u6df7\u6dc6\u95ee\u9898\uff0c\u5c06\u63d0\u793a\u6548\u679c\u4e0e\u67e5\u8be2\u7279\u5f81\u6df7\u6742", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u4f7f\u7528\u53cc\u673a\u5668\u5b66\u4e60\u5728\u63d0\u793a\u548c\u67e5\u8be2\u7684\u8bed\u4e49\u5d4c\u5165\u4e0a\u5b66\u4e60\u79bb\u7ebf\u56e0\u679c\u5956\u52b1\u6a21\u578b\uff0c\u9694\u79bb\u63d0\u793a\u53d8\u5f02\u7684\u56e0\u679c\u6548\u5e94\uff1b2) \u5229\u7528\u65e0\u504f\u5956\u52b1\u4fe1\u53f7\u6307\u5bfc\u8d44\u6e90\u9ad8\u6548\u7684\u67e5\u8be2\u7279\u5b9a\u63d0\u793a\u641c\u7d22", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u53ef\u89c6\u5316\u548c\u6570\u636e\u5206\u6790\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCPO\u59cb\u7ec8\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u63d0\u793a\u548c\u6700\u5148\u8fdb\u7684\u81ea\u52a8\u4f18\u5316\u5668\uff0c\u4e3b\u8981\u6539\u8fdb\u4f53\u73b0\u5728\u56f0\u96be\u67e5\u8be2\u4e0a\u7684\u9c81\u68d2\u6027\u63d0\u5347", "conclusion": "\u56e0\u679c\u63a8\u65ad\u4e3a\u53ef\u9760\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u63d0\u793a\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u57fa\u7840\uff0c\u901a\u8fc7\u5c06\u8bc4\u4f30\u4ece\u5b9e\u65f6\u6a21\u578b\u6267\u884c\u8f6c\u5411\u79bb\u7ebf\u56e0\u679c\u6a21\u578b\uff0c\u4ee5\u8f83\u4f4e\u63a8\u7406\u6210\u672c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u3001\u6309\u67e5\u8be2\u5b9a\u5236"}}
{"id": "2602.01740", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01740", "abs": "https://arxiv.org/abs/2602.01740", "authors": ["Qixin Xiao", "Kun Zhou"], "title": "MACD: Model-Aware Contrastive Decoding via Counterfactual Data", "comment": null, "summary": "Video language models (Video-LLMs) are prone to hallucinations, often generating plausible but ungrounded content when visual evidence is weak, ambiguous, or biased. Existing decoding methods, such as contrastive decoding (CD), rely on random perturbations to construct contrastive data for mitigating hallucination patterns. However, such a way is hard to control the visual cues that drive hallucination or well align with model weaknesses. We propose Model-aware Counterfactual Data based Contrastive Decoding (MACD), a new inference strategy that combines model-guided counterfactual construction with decoding. Our approach uses the Video-LLM's own feedback to identify object regions most responsible for hallucination, generating targeted counterfactual inputs at the object level rather than arbitrary frame or temporal modifications. These model-aware counterfactual data is then integrated into CD to enforce evidence-grounded token selection during decoding. Experiments on EventHallusion, MVBench, Perception-test and Video-MME show that MACD consistently reduces hallucination while maintaining or improving task accuracy across diverse Video-LLMs, including Qwen and InternVL families. The method is especially effective in challenging scenarios involving small, occluded, or co-occurring objects. Our code and data will be publicly released.", "AI": {"tldr": "MACD\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7b56\u7565\uff0c\u901a\u8fc7\u6a21\u578b\u5f15\u5bfc\u7684\u53cd\u4e8b\u5b9e\u6570\u636e\u6784\u5efa\u4e0e\u5bf9\u6bd4\u89e3\u7801\u76f8\u7ed3\u5408\uff0c\u51cf\u5c11\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u7279\u522b\u662f\u5728\u89c6\u89c9\u8bc1\u636e\u8f83\u5f31\u3001\u6a21\u7cca\u6216\u6709\u504f\u7684\u60c5\u51b5\u4e0b\u3002\u73b0\u6709\u7684\u89e3\u7801\u65b9\u6cd5\uff08\u5982\u5bf9\u6bd4\u89e3\u7801\uff09\u4f9d\u8d56\u968f\u673a\u6270\u52a8\u6784\u5efa\u5bf9\u6bd4\u6570\u636e\u6765\u7f13\u89e3\u5e7b\u89c9\uff0c\u4f46\u96be\u4ee5\u63a7\u5236\u9a71\u52a8\u5e7b\u89c9\u7684\u89c6\u89c9\u7ebf\u7d22\u6216\u4e0e\u6a21\u578b\u5f31\u70b9\u826f\u597d\u5bf9\u9f50\u3002", "method": "\u63d0\u51fa\u6a21\u578b\u611f\u77e5\u7684\u53cd\u4e8b\u5b9e\u6570\u636e\u5bf9\u6bd4\u89e3\u7801\uff08MACD\uff09\uff0c\u5229\u7528\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u81ea\u8eab\u7684\u53cd\u9988\u8bc6\u522b\u5bfc\u81f4\u5e7b\u89c9\u7684\u5bf9\u8c61\u533a\u57df\uff0c\u5728\u5bf9\u8c61\u7ea7\u522b\u751f\u6210\u6709\u9488\u5bf9\u6027\u7684\u53cd\u4e8b\u5b9e\u8f93\u5165\uff0c\u800c\u4e0d\u662f\u4efb\u610f\u7684\u5e27\u6216\u65f6\u95f4\u4fee\u6539\u3002\u7136\u540e\u5c06\u8fd9\u4e9b\u6a21\u578b\u611f\u77e5\u7684\u53cd\u4e8b\u5b9e\u6570\u636e\u96c6\u6210\u5230\u5bf9\u6bd4\u89e3\u7801\u4e2d\uff0c\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u5f3a\u5236\u6267\u884c\u57fa\u4e8e\u8bc1\u636e\u7684\u6807\u8bb0\u9009\u62e9\u3002", "result": "\u5728EventHallusion\u3001MVBench\u3001Perception-test\u548cVideo-MME\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMACD\u4e00\u81f4\u5730\u51cf\u5c11\u4e86\u5e7b\u89c9\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u5305\u62ecQwen\u548cInternVL\u7cfb\u5217\u5728\u5185\u7684\u5404\u79cd\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u7684\u4efb\u52a1\u51c6\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u6d89\u53ca\u5c0f\u7269\u4f53\u3001\u906e\u6321\u7269\u4f53\u6216\u5171\u73b0\u7269\u4f53\u7684\u6311\u6218\u6027\u573a\u666f\u4e2d\u7279\u522b\u6709\u6548\u3002", "conclusion": "MACD\u901a\u8fc7\u6a21\u578b\u5f15\u5bfc\u7684\u53cd\u4e8b\u5b9e\u6570\u636e\u6784\u5efa\u4e0e\u5bf9\u6bd4\u89e3\u7801\u76f8\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u63a8\u7406\u7b56\u7565\u6765\u51cf\u5c11\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u89c6\u89c9\u8bc1\u636e\u4e0d\u8db3\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2602.01749", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01749", "abs": "https://arxiv.org/abs/2602.01749", "authors": ["Lin Chen", "Samuel Drapeau", "Fanghao Shao", "Xuekai Zhu", "Bo Xue", "Yunchong Song", "Mathieu Lauri\u00e8re", "Zhouhan Lin"], "title": "Controlling Exploration-Exploitation in GFlowNets via Markov Chain Perspectives", "comment": null, "summary": "Generative Flow Network (GFlowNet) objectives implicitly fix an equal mixing of forward and backward policies, potentially constraining the exploration-exploitation trade-off during training. By further exploring the link between GFlowNets and Markov chains, we establish an equivalence between GFlowNet objectives and Markov chain reversibility, thereby revealing the origin of such constraints, and provide a framework for adapting Markov chain properties to GFlowNets. Building on these theoretical findings, we propose $\u03b1$-GFNs, which generalize the mixing via a tunable parameter $\u03b1$. This generalization enables direct control over exploration-exploitation dynamics to enhance mode discovery capabilities, while ensuring convergence to unique flows. Across various benchmarks, including Set, Bit Sequence, and Molecule Generation, $\u03b1$-GFN objectives consistently outperform previous GFlowNet objectives, achieving up to a $10 \\times$ increase in the number of discovered modes.", "AI": {"tldr": "\u03b1-GFNs\u901a\u8fc7\u53ef\u8c03\u53c2\u6570\u03b1\u6269\u5c55GFlowNet\u76ee\u6807\uff0c\u6253\u7834\u56fa\u5b9a\u6df7\u5408\u6bd4\u4f8b\u9650\u5236\uff0c\u589e\u5f3a\u63a2\u7d22-\u5229\u7528\u5e73\u8861\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u6a21\u5f0f\u53d1\u73b0\u80fd\u529b", "motivation": "\u4f20\u7edfGFlowNet\u76ee\u6807\u9690\u542b\u56fa\u5b9a\u4e86\u524d\u5411\u548c\u540e\u5411\u7b56\u7565\u7684\u6df7\u5408\u6bd4\u4f8b\uff0c\u8fd9\u9650\u5236\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\uff0c\u5f71\u54cd\u4e86\u6a21\u5f0f\u53d1\u73b0\u80fd\u529b", "method": "\u901a\u8fc7\u5efa\u7acbGFlowNet\u76ee\u6807\u4e0e\u9a6c\u5c14\u53ef\u592b\u94fe\u53ef\u9006\u6027\u7684\u7b49\u4ef7\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u7ea6\u675f\u6765\u6e90\uff0c\u5e76\u63d0\u51fa\u03b1-GFNs\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u8c03\u53c2\u6570\u03b1\u63a7\u5236\u524d\u5411-\u540e\u5411\u7b56\u7565\u6df7\u5408\u6bd4\u4f8b", "result": "\u5728Set\u3001Bit Sequence\u548cMolecule Generation\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u03b1-GFN\u76ee\u6807\u59cb\u7ec8\u4f18\u4e8e\u5148\u524dGFlowNet\u76ee\u6807\uff0c\u6a21\u5f0f\u53d1\u73b0\u6570\u91cf\u63d0\u5347\u9ad8\u8fbe10\u500d", "conclusion": "\u03b1-GFNs\u901a\u8fc7\u53ef\u8c03\u6df7\u5408\u53c2\u6570\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u63a2\u7d22-\u5229\u7528\u63a7\u5236\uff0c\u589e\u5f3a\u4e86\u6a21\u5f0f\u53d1\u73b0\u80fd\u529b\uff0c\u540c\u65f6\u786e\u4fdd\u6536\u655b\u5230\u552f\u4e00\u6d41\uff0c\u4e3aGFlowNet\u6846\u67b6\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u7406\u8bba\u57fa\u7840"}}
{"id": "2602.01750", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01750", "abs": "https://arxiv.org/abs/2602.01750", "authors": ["Mohammad Beigi", "Ming Jin", "Junshan Zhang", "Qifan Wang", "Lifu Huang"], "title": "Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking", "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) remains vulnerable to reward hacking, where models exploit spurious correlations in learned reward models to achieve high scores while violating human intent. Existing mitigations rely on static defenses that cannot adapt to novel exploitation strategies. We propose Adversarial Reward Auditing (ARA), a framework that reconceptualizes reward hacking as a dynamic, competitive game. ARA operates in two stages: first, a Hacker policy discovers reward model vulnerabilities while an Auditor learns to detect exploitation from latent representations; second, Auditor-Guided RLHF (AG-RLHF) gates reward signals to penalize detected hacking, transforming reward hacking from an unobservable failure into a measurable, controllable signal. Experiments across three hacking scenarios demonstrate that ARA achieves the best alignment-utility tradeoff among all baselines: reducing sycophancy to near-SFT levels while improving helpfulness, decreasing verbosity while achieving the highest ROUGE-L, and suppressing code gaming while improving Pass@1. Beyond single-domain evaluation, we show that reward hacking, detection, and mitigation all generalize across domains -- a Hacker trained on code gaming exhibits increased sycophancy despite no reward for this behavior, and an Auditor trained on one domain effectively suppresses exploitation in others, enabling efficient multi-domain defense with a single model.", "AI": {"tldr": "ARA\u6846\u67b6\u5c06\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u91cd\u6784\u4e3a\u52a8\u6001\u7ade\u4e89\u6e38\u620f\uff0c\u901a\u8fc7\u9ed1\u5ba2\u53d1\u73b0\u6f0f\u6d1e\u3001\u5ba1\u8ba1\u5458\u68c0\u6d4b\u5229\u7528\uff0c\u518d\u901a\u8fc7\u5ba1\u8ba1\u5f15\u5bfc\u7684RLHF\u60e9\u7f5a\u9ed1\u5ba2\u884c\u4e3a\uff0c\u5b9e\u73b0\u6700\u4f73\u5bf9\u9f50-\u6548\u7528\u5e73\u8861", "motivation": "\u73b0\u6709RLHF\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\uff0c\u6a21\u578b\u4f1a\u5229\u7528\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u865a\u5047\u76f8\u5173\u6027\u83b7\u5f97\u9ad8\u5206\u4f46\u8fdd\u80cc\u4eba\u7c7b\u610f\u56fe\uff0c\u800c\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u662f\u9759\u6001\u7684\uff0c\u65e0\u6cd5\u9002\u5e94\u65b0\u7684\u653b\u51fb\u7b56\u7565", "method": "\u63d0\u51fa\u5bf9\u6297\u6027\u5956\u52b1\u5ba1\u8ba1\uff08ARA\uff09\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\uff0c\u9ed1\u5ba2\u7b56\u7565\u53d1\u73b0\u5956\u52b1\u6a21\u578b\u6f0f\u6d1e\uff0c\u5ba1\u8ba1\u5458\u4ece\u6f5c\u5728\u8868\u793a\u4e2d\u5b66\u4e60\u68c0\u6d4b\u5229\u7528\uff1b\u7b2c\u4e8c\u9636\u6bb5\uff0c\u5ba1\u8ba1\u5f15\u5bfc\u7684RLHF\uff08AG-RLHF\uff09\u901a\u8fc7\u95e8\u63a7\u5956\u52b1\u4fe1\u53f7\u60e9\u7f5a\u68c0\u6d4b\u5230\u7684\u9ed1\u5ba2\u884c\u4e3a", "result": "\u5728\u4e09\u79cd\u9ed1\u5ba2\u573a\u666f\u4e2d\uff0cARA\u5728\u6240\u6709\u57fa\u7ebf\u4e2d\u5b9e\u73b0\u4e86\u6700\u4f73\u5bf9\u9f50-\u6548\u7528\u5e73\u8861\uff1a\u5c06\u5949\u627f\u884c\u4e3a\u964d\u81f3\u63a5\u8fd1SFT\u6c34\u5e73\u540c\u65f6\u63d0\u9ad8\u5e2e\u52a9\u6027\uff0c\u51cf\u5c11\u5197\u957f\u540c\u65f6\u83b7\u5f97\u6700\u9ad8ROUGE-L\uff0c\u6291\u5236\u4ee3\u7801\u6e38\u620f\u540c\u65f6\u63d0\u9ad8Pass@1\u3002\u5956\u52b1\u9ed1\u5ba2\u3001\u68c0\u6d4b\u548c\u7f13\u89e3\u90fd\u8868\u73b0\u51fa\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b", "conclusion": "ARA\u5c06\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u4ece\u4e0d\u53ef\u89c2\u5bdf\u7684\u5931\u8d25\u8f6c\u53d8\u4e3a\u53ef\u6d4b\u91cf\u3001\u53ef\u63a7\u5236\u7684\u4fe1\u53f7\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u9886\u57df\u9632\u5fa1\uff0c\u5355\u4e2a\u6a21\u578b\u5c31\u80fd\u6709\u6548\u6291\u5236\u8de8\u9886\u57df\u7684\u5229\u7528\u884c\u4e3a"}}
{"id": "2602.01779", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01779", "abs": "https://arxiv.org/abs/2602.01779", "authors": ["Rui Hua", "Yu Wei", "Zixin Shu", "Kai Chang", "Dengying Yan", "Jianan Xia", "Zeyu Liu", "Hui Zhu", "Shujie Song", "Mingzhong Xiao", "Xiaodong Li", "Dongmei Jia", "Zhuye Gao", "Yanyan Meng", "Naixuan Zhao", "Yu Fu", "Haibin Yu", "Benman Yu", "Yuanyuan Chen", "Fei Dong", "Zhizhou Meng", "Pengcheng Yang", "Songxue Zhao", "Lijuan Pei", "Yunhui Hu", "Kan Ding", "Jiayuan Duan", "Wenmao Yin", "Yang Gu", "Runshun Zhang", "Qiang Zhu", "Jian Yu", "Jiansheng Li", "Baoyan Liu", "Wenjia Wang", "Xuezhong Zhou"], "title": "LingLanMiDian: Systematic Evaluation of LLMs on TCM Knowledge and Clinical Reasoning", "comment": null, "summary": "Large language models (LLMs) are advancing rapidly in medical NLP, yet Traditional Chinese Medicine (TCM) with its distinctive ontology, terminology, and reasoning patterns requires domain-faithful evaluation. Existing TCM benchmarks are fragmented in coverage and scale and rely on non-unified or generation-heavy scoring that hinders fair comparison. We present the LingLanMiDian (LingLan) benchmark, a large-scale, expert-curated, multi-task suite that unifies evaluation across knowledge recall, multi-hop reasoning, information extraction, and real-world clinical decision-making. LingLan introduces a consistent metric design, a synonym-tolerant protocol for clinical labels, a per-dataset 400-item Hard subset, and a reframing of diagnosis and treatment recommendation into single-choice decision recognition. We conduct comprehensive, zero-shot evaluations on 14 leading open-source and proprietary LLMs, providing a unified perspective on their strengths and limitations in TCM commonsense knowledge understanding, reasoning, and clinical decision support; critically, the evaluation on Hard subset reveals a substantial gap between current models and human experts in TCM-specialized reasoning. By bridging fundamental knowledge and applied reasoning through standardized evaluation, LingLan establishes a unified, quantitative, and extensible foundation for advancing TCM LLMs and domain-specific medical AI research. All evaluation data and code are available at https://github.com/TCMAI-BJTU/LingLan and http://tcmnlp.com.", "AI": {"tldr": "LingLanMiDian (LingLan) \u662f\u4e00\u4e2a\u9488\u5bf9\u4e2d\u533b\u9886\u57df\u7684\u5927\u89c4\u6a21\u3001\u4e13\u5bb6\u7b56\u5212\u7684\u591a\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7edf\u4e00\u8bc4\u4f30\u77e5\u8bc6\u56de\u5fc6\u3001\u591a\u8df3\u63a8\u7406\u3001\u4fe1\u606f\u63d0\u53d6\u548c\u771f\u5b9e\u4e34\u5e8a\u51b3\u7b56\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u8bc4\u4f30\u4e3a\u4e2d\u533b\u5927\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u4e2d\u533b\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u788e\u7247\u5316\u3001\u89c4\u6a21\u5c0f\u3001\u8bc4\u5206\u6807\u51c6\u4e0d\u7edf\u4e00\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u516c\u5e73\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u5728\u4e2d\u533b\u8fd9\u4e00\u5177\u6709\u72ec\u7279\u672c\u4f53\u8bba\u3001\u672f\u8bed\u548c\u63a8\u7406\u6a21\u5f0f\u9886\u57df\u7684\u8868\u73b0\uff0c\u9700\u8981\u5efa\u7acb\u9886\u57df\u5fe0\u5b9e\u3001\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u4f53\u7cfb\u3002", "method": "\u6784\u5efa\u5927\u89c4\u6a21\u4e13\u5bb6\u7b56\u5212\u7684\u591a\u4efb\u52a1\u8bc4\u4f30\u5957\u4ef6\uff0c\u5f15\u5165\u4e00\u81f4\u7684\u5ea6\u91cf\u8bbe\u8ba1\u3001\u4e34\u5e8a\u6807\u7b7e\u7684\u540c\u4e49\u8bcd\u5bb9\u5fcd\u534f\u8bae\u3001\u6bcf\u4e2a\u6570\u636e\u96c6400\u9879\u7684\u56f0\u96be\u5b50\u96c6\uff0c\u5e76\u5c06\u8bca\u65ad\u548c\u6cbb\u7597\u5efa\u8bae\u91cd\u6784\u4e3a\u5355\u9009\u51b3\u7b56\u8bc6\u522b\u4efb\u52a1\u3002", "result": "\u5bf914\u4e2a\u9886\u5148\u7684\u5f00\u6e90\u548c\u4e13\u6709LLM\u8fdb\u884c\u96f6\u6837\u672c\u8bc4\u4f30\uff0c\u63d0\u4f9b\u4e86\u5b83\u4eec\u5728\u4e2d\u533b\u5e38\u8bc6\u77e5\u8bc6\u7406\u89e3\u3001\u63a8\u7406\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u65b9\u9762\u7684\u7edf\u4e00\u89c6\u89d2\uff1b\u5728\u56f0\u96be\u5b50\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\u5f53\u524d\u6a21\u578b\u4e0e\u4e2d\u533b\u4e13\u5bb6\u5728\u4e13\u95e8\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "LingLan\u901a\u8fc7\u6807\u51c6\u5316\u8bc4\u4f30\u6865\u63a5\u57fa\u7840\u77e5\u8bc6\u548c\u5e94\u7528\u63a8\u7406\uff0c\u4e3a\u63a8\u8fdb\u4e2d\u533bLLM\u548c\u9886\u57df\u7279\u5b9a\u533b\u5b66AI\u7814\u7a76\u5efa\u7acb\u4e86\u7edf\u4e00\u3001\u53ef\u91cf\u5316\u3001\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u6240\u6709\u8bc4\u4f30\u6570\u636e\u548c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.01832", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01832", "abs": "https://arxiv.org/abs/2602.01832", "authors": ["Rui Wang", "Yaoguang Cao", "Yuyi Chen", "Jianyi Xu", "Zhuoyang Li", "Jiachen Shang", "Shichun Yang"], "title": "Synesthesia of Vehicles: Tactile Data Synthesis from Visual Inputs", "comment": null, "summary": "Autonomous vehicles (AVs) rely on multi-modal fusion for safety, but current visual and optical sensors fail to detect road-induced excitations which are critical for vehicles' dynamic control. Inspired by human synesthesia, we propose the Synesthesia of Vehicles (SoV), a novel framework to predict tactile excitations from visual inputs for autonomous vehicles. We develop a cross-modal spatiotemporal alignment method to address temporal and spatial disparities. Furthermore, a visual-tactile synesthetic (VTSyn) generative model using latent diffusion is proposed for unsupervised high-quality tactile data synthesis. A real-vehicle perception system collected a multi-modal dataset across diverse road and lighting conditions. Extensive experiments show that VTSyn outperforms existing models in temporal, frequency, and classification performance, enhancing AV safety through proactive tactile perception.", "AI": {"tldr": "\u63d0\u51faSynesthesia of Vehicles (SoV)\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u8f93\u5165\u9884\u6d4b\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u89e6\u89c9\u6fc0\u52b1\uff0c\u89e3\u51b3\u5f53\u524d\u4f20\u611f\u5668\u65e0\u6cd5\u68c0\u6d4b\u9053\u8def\u6fc0\u52b1\u7684\u95ee\u9898\uff0c\u63d0\u5347\u8f66\u8f86\u52a8\u6001\u63a7\u5236\u5b89\u5168\u6027\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4f9d\u8d56\u591a\u6a21\u6001\u878d\u5408\u4fdd\u8bc1\u5b89\u5168\uff0c\u4f46\u73b0\u6709\u7684\u89c6\u89c9\u548c\u5149\u5b66\u4f20\u611f\u5668\u65e0\u6cd5\u68c0\u6d4b\u9053\u8def\u5f15\u8d77\u7684\u6fc0\u52b1\uff0c\u800c\u8fd9\u4e9b\u6fc0\u52b1\u5bf9\u8f66\u8f86\u52a8\u6001\u63a7\u5236\u81f3\u5173\u91cd\u8981\u3002\u53d7\u4eba\u7c7b\u8054\u89c9\u73b0\u8c61\u542f\u53d1\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4ece\u89c6\u89c9\u8f93\u5165\u9884\u6d4b\u89e6\u89c9\u6fc0\u52b1\u7684\u7cfb\u7edf\u3002", "method": "1. \u63d0\u51faSoV\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u8f93\u5165\u9884\u6d4b\u89e6\u89c9\u6fc0\u52b1\uff1b2. \u5f00\u53d1\u8de8\u6a21\u6001\u65f6\u7a7a\u5bf9\u9f50\u65b9\u6cd5\u89e3\u51b3\u65f6\u95f4\u548c\u7a7a\u95f4\u5dee\u5f02\uff1b3. \u63d0\u51fa\u57fa\u4e8e\u6f5c\u5728\u6269\u6563\u7684\u89c6\u89c9-\u89e6\u89c9\u8054\u89c9\u751f\u6210\u6a21\u578b(VTSyn)\uff0c\u7528\u4e8e\u65e0\u76d1\u7763\u9ad8\u8d28\u91cf\u89e6\u89c9\u6570\u636e\u5408\u6210\uff1b4. \u4f7f\u7528\u771f\u5b9e\u8f66\u8f86\u611f\u77e5\u7cfb\u7edf\u6536\u96c6\u591a\u6a21\u6001\u6570\u636e\u96c6\u3002", "result": "\u5728\u65f6\u95f4\u3001\u9891\u7387\u548c\u5206\u7c7b\u6027\u80fd\u65b9\u9762\uff0cVTSyn\u6a21\u578b\u5747\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u80fd\u591f\u901a\u8fc7\u4e3b\u52a8\u89e6\u89c9\u611f\u77e5\u589e\u5f3a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u5b89\u5168\u6027\u3002", "conclusion": "SoV\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u89c6\u89c9\u5230\u89e6\u89c9\u7684\u8de8\u6a21\u6001\u611f\u77e5\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u73af\u5883\u611f\u77e5\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u68c0\u6d4b\u9053\u8def\u6fc0\u52b1\u65b9\u9762\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f66\u8f86\u52a8\u6001\u63a7\u5236\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2602.01858", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01858", "abs": "https://arxiv.org/abs/2602.01858", "authors": ["Liangtao Lin", "Zhaomeng Zhu", "Tianwei Zhang", "Yonggang Wen"], "title": "SOPRAG: Multi-view Graph Experts Retrieval for Industrial Standard Operating Procedures", "comment": null, "summary": "Standard Operating Procedures (SOPs) are essential for ensuring operational safety and consistency in industrial environments. However, retrieving and following these procedures presents unique challenges, such as rigid proprietary structures, condition-dependent relevance, and actionable execution requirement, which standard semantic-driven Retrieval-Augmented Generation (RAG) paradigms fail to address. Inspired by the Mixture-of-Experts (MoE) paradigm, we propose SOPRAG, a novel framework specifically designed to address the above pain points in SOP retrieval. SOPRAG replaces flat chunking with specialized Entity, Causal, and Flow graph experts to resolve industrial structural and logical complexities. To optimize and coordinate these experts, we propose a Procedure Card layer that prunes the search space to eliminate computational noise, and an LLM-Guided gating mechanism that dynamically weights these experts to align retrieval with operator intent. To address the scarcity of domain-specific data, we also introduce an automated, multi-agent workflow for benchmark construction. Extensive experiments across four industrial domains demonstrate that SOPRAG significantly outperforms strong lexical, dense, and graph-based RAG baselines in both retrieval accuracy and response utility, achieving perfect execution scores in real-world critical tasks.", "AI": {"tldr": "SOPRAG\u662f\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u5de5\u4e1a\u6807\u51c6\u64cd\u4f5c\u89c4\u7a0b\u68c0\u7d22\u7684\u6846\u67b6\uff0c\u91c7\u7528\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u89e3\u51b3\u4f20\u7edfRAG\u65b9\u6cd5\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u51c6\u786e\u6027\u548c\u54cd\u5e94\u5b9e\u7528\u6027\u3002", "motivation": "\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u6807\u51c6\u64cd\u4f5c\u89c4\u7a0b\u68c0\u7d22\u9762\u4e34\u72ec\u7279\u6311\u6218\uff1a\u4e13\u6709\u7ed3\u6784\u50f5\u5316\u3001\u6761\u4ef6\u4f9d\u8d56\u76f8\u5173\u6027\u3001\u53ef\u6267\u884c\u6027\u8981\u6c42\u9ad8\u7b49\uff0c\u4f20\u7edf\u8bed\u4e49\u9a71\u52a8\u7684RAG\u8303\u5f0f\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51faSOPRAG\u6846\u67b6\uff0c\u91c7\u7528\u4e13\u5bb6\u6df7\u5408\u8303\u5f0f\uff0c\u7528\u4e13\u95e8\u7684\u5b9e\u4f53\u3001\u56e0\u679c\u548c\u6d41\u7a0b\u56fe\u4e13\u5bb6\u66ff\u4ee3\u5e73\u9762\u5206\u5757\uff1b\u5f15\u5165\u8fc7\u7a0b\u5361\u5c42\u4fee\u526a\u641c\u7d22\u7a7a\u95f4\u6d88\u9664\u8ba1\u7b97\u566a\u58f0\uff0c\u4ee5\u53caLLM\u5f15\u5bfc\u7684\u95e8\u63a7\u673a\u5236\u52a8\u6001\u52a0\u6743\u4e13\u5bb6\u4ee5\u5bf9\u9f50\u64cd\u4f5c\u5458\u610f\u56fe\uff1b\u8fd8\u8bbe\u8ba1\u4e86\u81ea\u52a8\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u6784\u5efa\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "\u5728\u56db\u4e2a\u5de5\u4e1a\u9886\u57df\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cSOPRAG\u5728\u68c0\u7d22\u51c6\u786e\u6027\u548c\u54cd\u5e94\u5b9e\u7528\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5f3a\u529b\u7684\u8bcd\u6cd5\u3001\u5bc6\u96c6\u548c\u57fa\u4e8e\u56fe\u7684RAG\u57fa\u7ebf\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u5173\u952e\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u7684\u6267\u884c\u5206\u6570\u3002", "conclusion": "SOPRAG\u901a\u8fc7\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u5de5\u4e1aSOP\u68c0\u7d22\u7684\u72ec\u7279\u6311\u6218\uff0c\u4e3a\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u64cd\u4f5c\u5b89\u5168\u6027\u548c\u4e00\u81f4\u6027\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01869", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01869", "abs": "https://arxiv.org/abs/2602.01869", "authors": ["Qirui Mi", "Zhijian Ma", "Mengyue Yang", "Haoxuan Li", "Yisen Wang", "Haifeng Zhang", "Jun Wang"], "title": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "comment": "20 Pages, 6 Figures, 4 Tables", "summary": "LLM-driven agents demonstrate strong performance in sequential decision-making but often rely on on-the-fly reasoning, re-deriving solutions even in recurring scenarios. This insufficient experience reuse leads to computational redundancy and execution instability. To bridge this gap, we propose ProcMEM, a framework that enables agents to autonomously learn procedural memory from interaction experiences without parameter updates. By formalizing a Skill-MDP, ProcMEM transforms passive episodic narratives into executable Skills defined by activation, execution, and termination conditions to ensure executability. To achieve reliable reusability without capability degradation, we introduce Non-Parametric PPO, which leverages semantic gradients for high-quality candidate generation and a PPO Gate for robust Skill verification. Through score-based maintenance, ProcMEM sustains compact, high-quality procedural memory. Experimental results across in-domain, cross-task, and cross-agent scenarios demonstrate that ProcMEM achieves superior reuse rates and significant performance gains with extreme memory compression. Visualized evolutionary trajectories and Skill distributions further reveal how ProcMEM transparently accumulates, refines, and reuses procedural knowledge to facilitate long-term autonomy.", "AI": {"tldr": "ProcMEM\u6846\u67b6\u8ba9LLM\u667a\u80fd\u4f53\u4ece\u4ea4\u4e92\u7ecf\u9a8c\u4e2d\u81ea\u4e3b\u6784\u5efa\u7a0b\u5e8f\u6027\u8bb0\u5fc6\uff0c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\uff0c\u901a\u8fc7\u6280\u80fd-MDP\u5c06\u88ab\u52a8\u7ecf\u9a8c\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u6280\u80fd\uff0c\u5b9e\u73b0\u9ad8\u6548\u7ecf\u9a8c\u590d\u7528", "motivation": "LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u5728\u987a\u5e8f\u51b3\u7b56\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u901a\u5e38\u4f9d\u8d56\u5373\u65f6\u63a8\u7406\uff0c\u5373\u4f7f\u5728\u91cd\u590d\u573a\u666f\u4e2d\u4e5f\u91cd\u65b0\u63a8\u5bfc\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u79cd\u7ecf\u9a8c\u590d\u7528\u4e0d\u8db3\u5bfc\u81f4\u8ba1\u7b97\u5197\u4f59\u548c\u6267\u884c\u4e0d\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u89e3\u51b3\u7ecf\u9a8c\u590d\u7528\u95ee\u9898", "method": "\u63d0\u51faProcMEM\u6846\u67b6\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316Skill-MDP\u5c06\u88ab\u52a8\u7ecf\u9a8c\u53d9\u4e8b\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u6280\u80fd\uff08\u5305\u542b\u6fc0\u6d3b\u3001\u6267\u884c\u548c\u7ec8\u6b62\u6761\u4ef6\uff09\u3002\u5f15\u5165\u975e\u53c2\u6570PPO\uff0c\u5229\u7528\u8bed\u4e49\u68af\u5ea6\u751f\u6210\u9ad8\u8d28\u91cf\u5019\u9009\u6280\u80fd\uff0c\u5e76\u901a\u8fc7PPO Gate\u8fdb\u884c\u6280\u80fd\u9a8c\u8bc1\u3002\u901a\u8fc7\u57fa\u4e8e\u5206\u6570\u7684\u7ef4\u62a4\u673a\u5236\u4fdd\u6301\u7d27\u51d1\u9ad8\u8d28\u91cf\u7684\u7a0b\u5e8f\u6027\u8bb0\u5fc6", "result": "\u5728\u9886\u57df\u5185\u3001\u8de8\u4efb\u52a1\u548c\u8de8\u667a\u80fd\u4f53\u573a\u666f\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cProcMEM\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u590d\u7528\u7387\u548c\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u5177\u6709\u6781\u5ea6\u7684\u5185\u5b58\u538b\u7f29\u3002\u53ef\u89c6\u5316\u8fdb\u5316\u8f68\u8ff9\u548c\u6280\u80fd\u5206\u5e03\u8fdb\u4e00\u6b65\u5c55\u793a\u4e86ProcMEM\u5982\u4f55\u900f\u660e\u5730\u79ef\u7d2f\u3001\u7cbe\u70bc\u548c\u590d\u7528\u7a0b\u5e8f\u6027\u77e5\u8bc6", "conclusion": "ProcMEM\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86LLM\u667a\u80fd\u4f53\u7ecf\u9a8c\u590d\u7528\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u7684\u81ea\u4e3b\u5b66\u4e60\u548c\u7ef4\u62a4\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u7ecf\u9a8c\u590d\u7528\u548c\u957f\u671f\u81ea\u4e3b\u6027\uff0c\u4e3a\u667a\u80fd\u4f53\u7684\u957f\u671f\u81ea\u4e3b\u51b3\u7b56\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.01893", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01893", "abs": "https://arxiv.org/abs/2602.01893", "authors": ["Timur Mudarisov", "Mikhal Burtsev", "Tatiana Petrova", "Radu State"], "title": "Geometric Analysis of Token Selection in Multi-Head Attention", "comment": null, "summary": "We present a geometric framework for analysing multi-head attention in large language models (LLMs). Without altering the mechanism, we view standard attention through a top-N selection lens and study its behaviour directly in value-state space. We define geometric metrics - Precision, Recall, and F-score - to quantify separability between selected and non-selected tokens, and derive non-asymptotic bounds with explicit dependence on dimension and margin under empirically motivated assumptions (stable value norms with a compressed sink token, exponential similarity decay, and piecewise attention weight profiles). The theory predicts a small-N operating regime of strongest non-trivial separability and clarifies how sequence length and sink similarity shape the metrics. Empirically, across LLaMA-2-7B, Gemma-7B, and Mistral-7B, measurements closely track the theoretical envelopes: top-N selection sharpens separability, sink similarity correlates with Recall. We also found that in LLaMA-2-7B heads specialize into three regimes - Retriever, Mixer, Reset - with distinct geometric signatures. Overall, attention behaves as a structured geometric classifier with measurable criteria for token selection, offering head level interpretability and informing geometry-aware sparsification and design of attention in LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u51e0\u4f55\u6846\u67b6\u6765\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5c06\u6807\u51c6\u6ce8\u610f\u529b\u89c6\u4e3atop-N\u9009\u62e9\u5668\uff0c\u5728\u503c\u72b6\u6001\u7a7a\u95f4\u4e2d\u7814\u7a76\u5176\u884c\u4e3a\uff0c\u5e76\u5b9a\u4e49\u4e86\u7cbe\u786e\u5ea6\u3001\u53ec\u56de\u7387\u548cF\u5206\u6570\u7b49\u51e0\u4f55\u6307\u6807\u6765\u91cf\u5316\u9009\u62e9\u4e0e\u975e\u9009\u62e9token\u4e4b\u95f4\u7684\u53ef\u5206\u79bb\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u6ce8\u610f\u529b\u673a\u5236\u51e0\u4f55\u7279\u6027\u7684\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u7279\u522b\u662f\u591a\u5934\u6ce8\u610f\u529b\u5982\u4f55\u5728\u4e0d\u540chead\u4e2d\u5b9e\u73b0token\u9009\u62e9\u7684\u53ef\u89e3\u91ca\u6027\u51e0\u4f55\u6a21\u5f0f\u3002\u9700\u8981\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u6765\u91cf\u5316\u6ce8\u610f\u529b\u5728\u503c\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u5206\u79bb\u884c\u4e3a\uff0c\u4e3a\u6a21\u578b\u89e3\u91ca\u548c\u4f18\u5316\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u51e0\u4f55\u6846\u67b6\uff0c\u5c06\u6807\u51c6\u6ce8\u610f\u529b\u89c6\u4e3atop-N\u9009\u62e9\u5668\uff0c\u5728\u503c\u72b6\u6001\u7a7a\u95f4\u4e2d\u5206\u6790\u5176\u884c\u4e3a\u3002\u5b9a\u4e49\u51e0\u4f55\u6307\u6807\uff08\u7cbe\u786e\u5ea6\u3001\u53ec\u56de\u7387\u3001F\u5206\u6570\uff09\u91cf\u5316token\u5206\u79bb\u6027\uff0c\u5728\u7ecf\u9a8c\u5047\u8bbe\u4e0b\u63a8\u5bfc\u975e\u6e10\u8fd1\u8fb9\u754c\u3002\u5728LLaMA-2-7B\u3001Gemma-7B\u548cMistral-7B\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u9884\u6d4b\u4e86\u5c0fN\u64cd\u4f5c\u533a\u57df\u5177\u6709\u6700\u5f3a\u7684\u975e\u5e73\u51e1\u53ef\u5206\u79bb\u6027\uff0c\u9610\u660e\u4e86\u5e8f\u5217\u957f\u5ea6\u548csink\u76f8\u4f3c\u6027\u5982\u4f55\u5f71\u54cd\u6307\u6807\u3002\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\u6d4b\u91cf\u503c\u4e0e\u7406\u8bba\u5305\u7edc\u7ebf\u7d27\u5bc6\u5339\u914d\uff1atop-N\u9009\u62e9\u589e\u5f3a\u4e86\u53ef\u5206\u79bb\u6027\uff0csink\u76f8\u4f3c\u6027\u4e0e\u53ec\u56de\u7387\u76f8\u5173\u3002\u53d1\u73b0LLaMA-2-7B\u4e2d\u7684head\u4e13\u95e8\u5316\u4e3a\u4e09\u79cd\u673a\u5236\uff1a\u68c0\u7d22\u5668\u3001\u6df7\u5408\u5668\u3001\u91cd\u7f6e\u5668\uff0c\u5177\u6709\u4e0d\u540c\u7684\u51e0\u4f55\u7279\u5f81\u3002", "conclusion": "\u6ce8\u610f\u529b\u673a\u5236\u8868\u73b0\u4e3a\u5177\u6709\u53ef\u6d4b\u91cftoken\u9009\u62e9\u6807\u51c6\u7684\u7ed3\u6784\u5316\u51e0\u4f55\u5206\u7c7b\u5668\uff0c\u63d0\u4f9b\u4e86head\u7ea7\u522b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4e3a\u51e0\u4f55\u611f\u77e5\u7684\u7a00\u758f\u5316\u548cLLM\u4e2d\u6ce8\u610f\u529b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4fe1\u606f\u3002\u8be5\u6846\u67b6\u4e3a\u7406\u89e3\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u51e0\u4f55\u89c6\u89d2\u3002"}}
{"id": "2602.01910", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01910", "abs": "https://arxiv.org/abs/2602.01910", "authors": ["Michele Fiori", "Gabriele Civitarese", "Flora D. Salim", "Claudio Bettini"], "title": "DomusFM: A Foundation Model for Smart-Home Sensor Data", "comment": null, "summary": "Smart-home sensor data holds significant potential for several applications, including healthcare monitoring and assistive technologies. Existing approaches, however, face critical limitations. Supervised models require impractical amounts of labeled data. Foundation models for activity recognition focus only on inertial sensors, failing to address the unique characteristics of smart-home binary sensor events: their sparse, discrete nature combined with rich semantic associations. LLM-based approaches, while tested in this domain, still raise several issues regarding the need for natural language descriptions or prompting, and reliance on either external services or expensive hardware, making them infeasible in real-life scenarios due to privacy and cost concerns. We introduce DomusFM, the first foundation model specifically designed and pretrained for smart-home sensor data. DomusFM employs a self-supervised dual contrastive learning paradigm to capture both token-level semantic attributes and sequence-level temporal dependencies. By integrating semantic embeddings from a lightweight language model and specialized encoders for temporal patterns and binary states, DomusFM learns generalizable representations that transfer across environments and tasks related to activity and event analysis. Through leave-one-dataset-out evaluation across seven public smart-home datasets, we demonstrate that DomusFM outperforms state-of-the-art baselines on different downstream tasks, achieving superior performance even with only 5% of labeled training data available for fine-tuning. Our approach addresses data scarcity while maintaining practical deployability for real-world smart-home systems.", "AI": {"tldr": "DomusFM\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u667a\u80fd\u5bb6\u5c45\u4f20\u611f\u5668\u6570\u636e\u8bbe\u8ba1\u7684\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u53cc\u5bf9\u6bd4\u5b66\u4e60\u8303\u5f0f\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u5b9e\u73b0\u8de8\u73af\u5883\u548c\u4efb\u52a1\u7684\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u591a\u4e2a\u5173\u952e\u9650\u5236\uff1a\u76d1\u7763\u6a21\u578b\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u4e0d\u5b9e\u7528\uff1b\u6d3b\u52a8\u8bc6\u522b\u57fa\u7840\u6a21\u578b\u53ea\u5173\u6ce8\u60ef\u6027\u4f20\u611f\u5668\uff0c\u65e0\u6cd5\u5904\u7406\u667a\u80fd\u5bb6\u5c45\u4e8c\u8fdb\u5236\u4f20\u611f\u5668\u6570\u636e\u7684\u7a00\u758f\u79bb\u6563\u7279\u6027\u548c\u4e30\u5bcc\u8bed\u4e49\u5173\u8054\uff1b\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u9700\u8981\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u6216\u63d0\u793a\uff0c\u4f9d\u8d56\u5916\u90e8\u670d\u52a1\u6216\u6602\u8d35\u786c\u4ef6\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u56e0\u9690\u79c1\u548c\u6210\u672c\u95ee\u9898\u4e0d\u53ef\u884c\u3002", "method": "DomusFM\u91c7\u7528\u81ea\u76d1\u7763\u53cc\u5bf9\u6bd4\u5b66\u4e60\u8303\u5f0f\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u5d4c\u5165\u3001\u4e13\u95e8\u7684\u65f6\u95f4\u6a21\u5f0f\u7f16\u7801\u5668\u548c\u4e8c\u8fdb\u5236\u72b6\u6001\u7f16\u7801\u5668\uff0c\u540c\u65f6\u6355\u6349\u4ee4\u724c\u7ea7\u8bed\u4e49\u5c5e\u6027\u548c\u5e8f\u5217\u7ea7\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u4e03\u4e2a\u516c\u5171\u667a\u80fd\u5bb6\u5c45\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7559\u4e00\u6570\u636e\u96c6\u8bc4\u4f30\uff0cDomusFM\u5728\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u5373\u4f7f\u5728\u4ec5\u67095%\u6807\u6ce8\u6570\u636e\u7528\u4e8e\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u4f18\u5f02\u6027\u80fd\u3002", "conclusion": "DomusFM\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b9e\u9645\u90e8\u7f72\u53ef\u884c\u6027\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u667a\u80fd\u5bb6\u5c45\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01933", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01933", "abs": "https://arxiv.org/abs/2602.01933", "authors": ["Fabrice Boissier", "Monica Sen", "Irina Rychkova"], "title": "Large Language Model and Formal Concept Analysis: a comparative study for Topic Modeling", "comment": null, "summary": "Topic modeling is a research field finding increasing applications: historically from document retrieving, to sentiment analysis and text summarization. Large Language Models (LLM) are currently a major trend in text processing, but few works study their usefulness for this task. Formal Concept Analysis (FCA) has recently been presented as a candidate for topic modeling, but no real applied case study has been conducted. In this work, we compare LLM and FCA to better understand their strengths and weakneses in the topic modeling field. FCA is evaluated through the CREA pipeline used in past experiments on topic modeling and visualization, whereas GPT-5 is used for the LLM. A strategy based on three prompts is applied with GPT-5 in a zero-shot setup: topic generation from document batches, merging of batch results into final topics, and topic labeling. A first experiment reuses the teaching materials previously used to evaluate CREA, while a second experiment analyzes 40 research articles in information systems to compare the extracted topics with the underling subfields.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\u5728\u4e3b\u9898\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728\u6587\u6863\u4e3b\u9898\u63d0\u53d6\u65b9\u9762\u7684\u6548\u679c\u3002", "motivation": "\u4e3b\u9898\u5efa\u6a21\u5728\u6587\u6863\u68c0\u7d22\u3001\u60c5\u611f\u5206\u6790\u548c\u6587\u672c\u6458\u8981\u7b49\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\u3002\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6587\u672c\u5904\u7406\u4e2d\u5f88\u6d41\u884c\uff0c\u4f46\u5bf9\u5176\u5728\u4e3b\u9898\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u7814\u7a76\u8f83\u5c11\u3002\u540c\u65f6\uff0c\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\u6700\u8fd1\u88ab\u63d0\u51fa\u4f5c\u4e3a\u4e3b\u9898\u5efa\u6a21\u7684\u5019\u9009\u65b9\u6cd5\uff0c\u4f46\u7f3a\u4e4f\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\u7814\u7a76\u3002\u672c\u7814\u7a76\u65e8\u5728\u6bd4\u8f83LLM\u548cFCA\u5728\u4e3b\u9898\u5efa\u6a21\u9886\u57df\u7684\u4f18\u7f3a\u70b9\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528CREA\u7ba1\u9053\u8bc4\u4f30FCA\uff0c\u8fd9\u662f\u8fc7\u53bb\u4e3b\u9898\u5efa\u6a21\u548c\u53ef\u89c6\u5316\u5b9e\u9a8c\u4e2d\u4f7f\u7528\u7684\u5de5\u5177\uff1b2\uff09\u4f7f\u7528GPT-5\u4f5c\u4e3aLLM\u4ee3\u8868\uff0c\u91c7\u7528\u57fa\u4e8e\u4e09\u4e2a\u63d0\u793a\u7684\u96f6\u6837\u672c\u8bbe\u7f6e\u7b56\u7565\uff1a\u4ece\u6587\u6863\u6279\u6b21\u751f\u6210\u4e3b\u9898\u3001\u5408\u5e76\u6279\u6b21\u7ed3\u679c\u5f62\u6210\u6700\u7ec8\u4e3b\u9898\u3001\u4ee5\u53ca\u4e3b\u9898\u6807\u6ce8\u3002\u7814\u7a76\u8fdb\u884c\u4e86\u4e24\u4e2a\u5b9e\u9a8c\uff1a\u7b2c\u4e00\u4e2a\u5b9e\u9a8c\u91cd\u7528\u4e4b\u524d\u8bc4\u4f30CREA\u7684\u6559\u5b66\u6750\u6599\uff0c\u7b2c\u4e8c\u4e2a\u5b9e\u9a8c\u5206\u6790\u4e8640\u7bc7\u4fe1\u606f\u7cfb\u7edf\u7814\u7a76\u6587\u7ae0\uff0c\u6bd4\u8f83\u63d0\u53d6\u7684\u4e3b\u9898\u4e0e\u5e95\u5c42\u5b50\u9886\u57df\u3002", "result": "\u8bba\u6587\u6ca1\u6709\u5728\u6458\u8981\u4e2d\u63d0\u4f9b\u5177\u4f53\u7ed3\u679c\u6570\u636e\uff0c\u4f46\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\u6bd4\u8f83\u4e86LLM\u548cFCA\u5728\u4e3b\u9898\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u7b2c\u4e00\u4e2a\u5b9e\u9a8c\u9a8c\u8bc1\u4e86CREA\u7ba1\u9053\u5728\u6559\u5b66\u6750\u6599\u4e0a\u7684\u6548\u679c\uff0c\u7b2c\u4e8c\u4e2a\u5b9e\u9a8c\u5728\u4fe1\u606f\u7cfb\u7edf\u7814\u7a76\u6587\u7ae0\u4e0a\u8bc4\u4f30\u4e86\u4e24\u79cd\u65b9\u6cd5\u63d0\u53d6\u4e3b\u9898\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5b9e\u8bc1\u6bd4\u8f83LLM\u548cFCA\u5728\u4e3b\u9898\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u7406\u89e3\u8fd9\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002\u7814\u7a76\u586b\u8865\u4e86LLM\u5728\u4e3b\u9898\u5efa\u6a21\u9886\u57df\u5e94\u7528\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u5e76\u4e3aFCA\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6848\u4f8b\u7814\u7a76\u3002"}}
{"id": "2602.01970", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01970", "abs": "https://arxiv.org/abs/2602.01970", "authors": ["Yun Qu", "Qi Wang", "Yixiu Mao", "Heming Zou", "Yuhang Jiang", "Weijie Liu", "Clive Bai", "Kai Yang", "Yangkun Chen", "Saiyong Yang", "Xiangyang Ji"], "title": "Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models", "comment": null, "summary": "Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization. Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency. However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency, final performance, and test-time efficiency over superior baseline methods.", "AI": {"tldr": "GPS\u901a\u8fc7\u8f7b\u91cf\u7ea7\u751f\u6210\u6a21\u578b\u8fdb\u884c\u8d1d\u53f6\u65af\u63a8\u7406\u9884\u6d4b\u63d0\u793a\u96be\u5ea6\uff0c\u7ed3\u5408\u4e2d\u7b49\u96be\u5ea6\u4f18\u5148\u548c\u5386\u53f2\u951a\u5b9a\u591a\u6837\u6027\u539f\u5219\uff0c\u663e\u8457\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6548\u7387\u548c\u6700\u7ec8\u6027\u80fd", "motivation": "\u5f3a\u5316\u5b66\u4e60\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u5728\u7ebf\u63d0\u793a\u9009\u62e9\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u6602\u8d35\u7cbe\u786e\u8bc4\u4f30\uff0c\u8981\u4e48\u7f3a\u4e4f\u8de8\u63d0\u793a\u6cdb\u5316\u80fd\u529b", "method": "\u63d0\u51fa\u53ef\u6cdb\u5316\u9884\u6d4b\u63d0\u793a\u9009\u62e9(GPS)\uff1a\u4f7f\u7528\u8f7b\u91cf\u7ea7\u751f\u6210\u6a21\u578b\u5728\u5171\u4eab\u4f18\u5316\u5386\u53f2\u4e0a\u8fdb\u884c\u8d1d\u53f6\u65af\u63a8\u7406\u9884\u6d4b\u63d0\u793a\u96be\u5ea6\uff0c\u7ed3\u5408\u4e2d\u7b49\u96be\u5ea6\u4f18\u5148\u548c\u5386\u53f2\u951a\u5b9a\u591a\u6837\u6027\u539f\u5219\u8fdb\u884c\u6279\u91cf\u9009\u62e9", "result": "\u5728\u591a\u6837\u5316\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGPS\u5728\u8bad\u7ec3\u6548\u7387\u3001\u6700\u7ec8\u6027\u80fd\u548c\u6d4b\u8bd5\u65f6\u6548\u7387\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "GPS\u901a\u8fc7\u53ef\u6cdb\u5316\u7684\u9884\u6d4b\u6a21\u578b\u548c\u667a\u80fd\u6279\u91cf\u9009\u62e9\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u63d0\u793a\u9009\u62e9\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\u7684\u663e\u8457\u63d0\u5347"}}
{"id": "2602.01995", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01995", "abs": "https://arxiv.org/abs/2602.01995", "authors": ["Jeongmoon Won", "Seungwon Kook", "Yohan Jo"], "title": "Thinking Like a Doctor: Conversational Diagnosis through the Exploration of Diagnostic Knowledge Graphs", "comment": null, "summary": "Conversational diagnosis requires multi-turn history-taking, where an agent asks clarifying questions to refine differential diagnoses under incomplete information. Existing approaches often rely on the parametric knowledge of a model or assume that patients provide rich and concrete information, which is unrealistic. To address these limitations, we propose a conversational diagnosis system that explores a diagnostic knowledge graph to reason in two steps: (i) generating diagnostic hypotheses from the dialogue context, and (ii) verifying hypotheses through clarifying questions, which are repeated until a final diagnosis is reached. Since evaluating the system requires a realistic patient simulator that responds to the system's questions, we adopt a well-established simulator along with patient profiles from MIMIC-IV. We further adapt it to describe symptoms vaguely to reflect real-world patients during early clinical encounters. Experiments show improved diagnostic accuracy and efficiency over strong baselines, and evaluations by physicians support the realism of our simulator and the clinical utility of the generated questions. Our code will be released upon publication.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u5bf9\u8bdd\u8bca\u65ad\u7cfb\u7edf\uff0c\u901a\u8fc7\u751f\u6210\u8bca\u65ad\u5047\u8bbe\u548c\u9a8c\u8bc1\u6027\u63d0\u95ee\u4e24\u9636\u6bb5\u63a8\u7406\uff0c\u5728\u6a21\u7cca\u75c7\u72b6\u63cf\u8ff0\u4e0b\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u548c\u6548\u7387", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u8bca\u65ad\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u6a21\u578b\u7684\u53c2\u6570\u5316\u77e5\u8bc6\uff0c\u8981\u4e48\u5047\u8bbe\u60a3\u8005\u63d0\u4f9b\u4e30\u5bcc\u5177\u4f53\u4fe1\u606f\uff0c\u8fd9\u5728\u73b0\u5b9e\u4e2d\u4e0d\u5207\u5b9e\u9645\uff0c\u9700\u8981\u89e3\u51b3\u4fe1\u606f\u4e0d\u5b8c\u6574\u548c\u75c7\u72b6\u63cf\u8ff0\u6a21\u7cca\u7684\u95ee\u9898", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u63a8\u7406\u7cfb\u7edf\uff1a1)\u4ece\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u751f\u6210\u8bca\u65ad\u5047\u8bbe\uff1b2)\u901a\u8fc7\u6f84\u6e05\u95ee\u9898\u9a8c\u8bc1\u5047\u8bbe\uff0c\u5faa\u73af\u76f4\u5230\u5f97\u51fa\u6700\u7ec8\u8bca\u65ad\u3002\u4f7f\u7528MIMIC-IV\u60a3\u8005\u6863\u6848\u548c\u7ecf\u8fc7\u8c03\u6574\u7684\u6a21\u62df\u5668\u6765\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u4e2d\u65e9\u671f\u4e34\u5e8a\u63a5\u89e6\u65f6\u7684\u6a21\u7cca\u75c7\u72b6\u63cf\u8ff0", "result": "\u5b9e\u9a8c\u663e\u793a\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u8bca\u65ad\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u5747\u6709\u63d0\u5347\u3002\u533b\u751f\u8bc4\u4f30\u652f\u6301\u6a21\u62df\u5668\u7684\u771f\u5b9e\u6027\u548c\u751f\u6210\u95ee\u9898\u7684\u4e34\u5e8a\u5b9e\u7528\u6027", "conclusion": "\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u5bf9\u8bdd\u8bca\u65ad\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0d\u5b8c\u6574\u4fe1\u606f\u548c\u6a21\u7cca\u75c7\u72b6\u63cf\u8ff0\uff0c\u63d0\u9ad8\u4e34\u5e8a\u8bca\u65ad\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2602.02018", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02018", "abs": "https://arxiv.org/abs/2602.02018", "authors": ["Enes Altinisik", "Masoomali Fatehkia", "Fatih Deniz", "Nadir Durrani", "Majd Hawasly", "Mohammad Raza", "Husrev Taha Sencar"], "title": "Do I Really Know? Learning Factual Self-Verification for Hallucination Reduction", "comment": null, "summary": "Factual hallucination remains a central challenge for large language models (LLMs). Existing mitigation approaches primarily rely on either external post-hoc verification or mapping uncertainty directly to abstention during fine-tuning, often resulting in overly conservative behavior. We propose VeriFY, a training-time framework that teaches LLMs to reason about factual uncertainty through consistency-based self-verification. VeriFY augments training with structured verification traces that guide the model to produce an initial answer, generate and answer a probing verification query, issue a consistency judgment, and then decide whether to answer or abstain. To address the risk of reinforcing hallucinated content when training on augmented traces, we introduce a stage-level loss masking approach that excludes hallucinated answer stages from the training objective while preserving supervision over verification behavior. Across multiple model families and scales, VeriFY reduces factual hallucination rates by 9.7 to 53.3 percent, with only modest reductions in recall (0.4 to 5.7 percent), and generalizes across datasets when trained on a single source. The source code, training data, and trained model checkpoints will be released upon acceptance.", "AI": {"tldr": "VeriFY\u662f\u4e00\u4e2a\u8bad\u7ec3\u65f6\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u4e00\u81f4\u6027\u7684\u81ea\u6211\u9a8c\u8bc1\u6559LLM\u63a8\u7406\u4e8b\u5b9e\u4e0d\u786e\u5b9a\u6027\uff0c\u51cf\u5c11\u4e8b\u5b9e\u5e7b\u89c9\uff0c\u540c\u65f6\u4fdd\u6301\u53ec\u56de\u7387", "motivation": "\u73b0\u6709\u7f13\u89e3\u4e8b\u5b9e\u5e7b\u89c9\u7684\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5916\u90e8\u4e8b\u540e\u9a8c\u8bc1\u6216\u5c06\u4e0d\u786e\u5b9a\u6027\u76f4\u63a5\u6620\u5c04\u5230\u5f03\u6743\uff0c\u901a\u5e38\u5bfc\u81f4\u8fc7\u4e8e\u4fdd\u5b88\u7684\u884c\u4e3a\uff0c\u9700\u8981\u66f4\u597d\u7684\u8bad\u7ec3\u65f6\u89e3\u51b3\u65b9\u6848", "method": "VeriFY\u901a\u8fc7\u7ed3\u6784\u5316\u9a8c\u8bc1\u8f68\u8ff9\u589e\u5f3a\u8bad\u7ec3\uff0c\u6307\u5bfc\u6a21\u578b\u751f\u6210\u521d\u59cb\u7b54\u6848\u3001\u521b\u5efa\u5e76\u56de\u7b54\u9a8c\u8bc1\u67e5\u8be2\u3001\u8fdb\u884c\u4e00\u81f4\u6027\u5224\u65ad\u3001\u51b3\u5b9a\u56de\u7b54\u6216\u5f03\u6743\uff0c\u5e76\u4f7f\u7528\u9636\u6bb5\u7ea7\u635f\u5931\u63a9\u7801\u6392\u9664\u5e7b\u89c9\u7b54\u6848\u9636\u6bb5", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u7cfb\u5217\u548c\u89c4\u6a21\u4e0a\uff0cVeriFY\u5c06\u4e8b\u5b9e\u5e7b\u89c9\u7387\u964d\u4f4e9.7%\u81f353.3%\uff0c\u53ec\u56de\u7387\u4ec5\u8f7b\u5fae\u4e0b\u964d0.4%\u81f35.7%\uff0c\u4e14\u5728\u5355\u4e00\u6570\u636e\u96c6\u8bad\u7ec3\u540e\u80fd\u8de8\u6570\u636e\u96c6\u6cdb\u5316", "conclusion": "VeriFY\u901a\u8fc7\u8bad\u7ec3\u65f6\u81ea\u6211\u9a8c\u8bc1\u6709\u6548\u51cf\u5c11LLM\u7684\u4e8b\u5b9e\u5e7b\u89c9\uff0c\u5728\u51c6\u786e\u6027\u548c\u8986\u76d6\u8303\u56f4\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2602.02027", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02027", "abs": "https://arxiv.org/abs/2602.02027", "authors": ["Sicheng Shen", "Mingyang Lv", "Han Shen", "Jialin Wu", "Binghao Wang", "Zhou Yang", "Guobin Shen", "Dongcheng Zhao", "Feifei Zhao", "Yi Zeng"], "title": "Light Alignment Improves LLM Safety via Model Self-Reflection with a Single Neuron", "comment": "21 pages, 3 figures", "summary": "The safety of large language models (LLMs) has increasingly emerged as a fundamental aspect of their development. Existing safety alignment for LLMs is predominantly achieved through post-training methods, which are computationally expensive and often fail to generalize well across different models. A small number of lightweight alignment approaches either rely heavily on prior-computed safety injections or depend excessively on the model's own capabilities, resulting in limited generalization and degraded efficiency and usability during generation. In this work, we propose a safety-aware decoding method that requires only low-cost training of an expert model and employs a single neuron as a gating mechanism. By effectively balancing the model's intrinsic capabilities with external guidance, our approach simultaneously preserves utility and enhances output safety. It demonstrates clear advantages in training overhead and generalization across model scales, offering a new perspective on lightweight alignment for the safe and practical deployment of large language models. Code: https://github.com/Beijing-AISI/NGSD.", "AI": {"tldr": "\u63d0\u51faNGSD\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f4e\u6210\u672c\u8bad\u7ec3\u4e13\u5bb6\u6a21\u578b\u5e76\u4f7f\u7528\u5355\u4e2a\u795e\u7ecf\u5143\u4f5c\u4e3a\u95e8\u63a7\u673a\u5236\uff0c\u5728\u89e3\u7801\u9636\u6bb5\u5b9e\u73b0\u5b89\u5168\u5bf9\u9f50\uff0c\u5e73\u8861\u6a21\u578b\u5185\u5728\u80fd\u529b\u4e0e\u5916\u90e8\u6307\u5bfc\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u7528\u6027\u548c\u589e\u5f3a\u8f93\u51fa\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709LLM\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u540e\u8bad\u7ec3\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u6cdb\u5316\u80fd\u529b\u5dee\uff1b\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u8981\u4e48\u8fc7\u5ea6\u4f9d\u8d56\u9884\u8ba1\u7b97\u7684\u5b89\u5168\u6ce8\u5165\uff0c\u8981\u4e48\u8fc7\u5ea6\u4f9d\u8d56\u6a21\u578b\u81ea\u8eab\u80fd\u529b\uff0c\u5bfc\u81f4\u6cdb\u5316\u6709\u9650\u3001\u751f\u6210\u6548\u7387\u548c\u4f7f\u7528\u6027\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u5b89\u5168\u611f\u77e5\u89e3\u7801\u65b9\u6cd5NGSD\uff0c\u53ea\u9700\u4f4e\u6210\u672c\u8bad\u7ec3\u4e13\u5bb6\u6a21\u578b\uff0c\u4f7f\u7528\u5355\u4e2a\u795e\u7ecf\u5143\u4f5c\u4e3a\u95e8\u63a7\u673a\u5236\uff0c\u5728\u89e3\u7801\u9636\u6bb5\u5e73\u8861\u6a21\u578b\u5185\u5728\u80fd\u529b\u4e0e\u5916\u90e8\u6307\u5bfc\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u8bad\u7ec3\u5f00\u9500\u548c\u8de8\u6a21\u578b\u89c4\u6a21\u6cdb\u5316\u65b9\u9762\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u7528\u6027\u548c\u589e\u5f3a\u8f93\u51fa\u5b89\u5168\u6027\u3002", "conclusion": "\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5b9e\u7528\u90e8\u7f72\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u5bf9\u9f50\u7684\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.02028", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02028", "abs": "https://arxiv.org/abs/2602.02028", "authors": ["Ya Gao", "Kalle Kujanp\u00e4\u00e4", "Pekka Marttinen", "Harri Valpola", "Alexander Ilin"], "title": "Edit Knowledge, Not Just Facts via Multi-Step Reasoning over Background Stories", "comment": "under review", "summary": "Enabling artificial intelligence systems, particularly large language models, to integrate new knowledge and flexibly apply it during reasoning remains a central challenge. Existing knowledge editing approaches emphasize atomic facts, improving factual recall but often failing to integrate new information into a coherent framework usable across contexts. In this work, we argue that knowledge internalization is fundamentally a reasoning problem rather than a memorization problem. Consequently, a model should be trained in situations where the new information is instrumental to solving a task, combined with pre-existing knowledge, and exercised through multi-step reasoning. Based on this insight, we propose a training strategy based on three principles. First, new knowledge is introduced as a coherent background story that contextualizes novel facts and explains their relation to existing knowledge. Second, models are trained using self-generated multi-hop questions that require multi-step reasoning involving the new information. Third, training is done using knowledge distillation, forcing a student model to internalize the teacher's reasoning behavior without access to the novel information. Experiments show that models trained with this strategy effectively leverage newly acquired knowledge during reasoning and achieve remarkable performance on challenging questions that require combining multiple new facts.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u63a8\u7406\u7684\u77e5\u8bc6\u5185\u5316\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7\u8fde\u8d2f\u80cc\u666f\u6545\u4e8b\u3001\u81ea\u751f\u6210\u591a\u8df3\u95ee\u9898\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u4f7fAI\u6a21\u578b\u80fd\u6709\u6548\u6574\u5408\u65b0\u77e5\u8bc6\u8fdb\u884c\u591a\u6b65\u63a8\u7406", "motivation": "\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u539f\u5b50\u4e8b\u5b9e\u7684\u8bb0\u5fc6\uff0c\u4f46\u65e0\u6cd5\u5c06\u65b0\u77e5\u8bc6\u6574\u5408\u5230\u8fde\u8d2f\u6846\u67b6\u4e2d\u8de8\u4e0a\u4e0b\u6587\u4f7f\u7528\u3002\u77e5\u8bc6\u5185\u5316\u672c\u8d28\u4e0a\u662f\u63a8\u7406\u95ee\u9898\u800c\u975e\u8bb0\u5fc6\u95ee\u9898\uff0c\u9700\u8981\u6a21\u578b\u5728\u4efb\u52a1\u4e2d\u7ed3\u5408\u65b0\u65e7\u77e5\u8bc6\u8fdb\u884c\u591a\u6b65\u63a8\u7406", "method": "\u63d0\u51fa\u4e09\u539f\u5219\u8bad\u7ec3\u7b56\u7565\uff1a1) \u5c06\u65b0\u77e5\u8bc6\u4f5c\u4e3a\u8fde\u8d2f\u80cc\u666f\u6545\u4e8b\u5f15\u5165\uff0c\u89e3\u91ca\u65b0\u4e8b\u5b9e\u4e0e\u73b0\u6709\u77e5\u8bc6\u7684\u5173\u7cfb\uff1b2) \u4f7f\u7528\u81ea\u751f\u6210\u591a\u8df3\u95ee\u9898\u8fdb\u884c\u8bad\u7ec3\uff0c\u8981\u6c42\u6d89\u53ca\u65b0\u4fe1\u606f\u7684\u591a\u6b65\u63a8\u7406\uff1b3) \u91c7\u7528\u77e5\u8bc6\u84b8\u998f\uff0c\u8ba9\u5b66\u751f\u6a21\u578b\u5185\u5316\u6559\u5e08\u63a8\u7406\u884c\u4e3a\u800c\u65e0\u6cd5\u76f4\u63a5\u8bbf\u95ee\u65b0\u4fe1\u606f", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528\u8be5\u7b56\u7565\u8bad\u7ec3\u7684\u6a21\u578b\u80fd\u6709\u6548\u5229\u7528\u65b0\u83b7\u53d6\u77e5\u8bc6\u8fdb\u884c\u63a8\u7406\uff0c\u5728\u9700\u8981\u7ed3\u5408\u591a\u4e2a\u65b0\u4e8b\u5b9e\u7684\u6311\u6218\u6027\u95ee\u9898\u4e2d\u8868\u73b0\u4f18\u5f02", "conclusion": "\u77e5\u8bc6\u5185\u5316\u5e94\u88ab\u89c6\u4e3a\u63a8\u7406\u95ee\u9898\u800c\u975e\u8bb0\u5fc6\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u65b0\u77e5\u8bc6\u5d4c\u5165\u8fde\u8d2f\u80cc\u666f\u3001\u8bad\u7ec3\u591a\u6b65\u63a8\u7406\u80fd\u529b\u5e76\u4f7f\u7528\u77e5\u8bc6\u84b8\u998f\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347AI\u6a21\u578b\u6574\u5408\u548c\u5e94\u7528\u65b0\u77e5\u8bc6\u7684\u80fd\u529b"}}
{"id": "2602.02034", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02034", "abs": "https://arxiv.org/abs/2602.02034", "authors": ["Ananya Joshi", "Michael Rudow"], "title": "Constrained Process Maps for Multi-Agent Generative AI Workflows", "comment": null, "summary": "Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence. However, many agentic architectures rely primarily on prompt engineering of a single agent, making it difficult to observe or compare how models handle uncertainty and coordination across interconnected decision stages and with human oversight. We introduce a multi-agent system formalized as a finite-horizon Markov Decision Process (MDP) with a directed acyclic structure. Each agent corresponds to a specific role or decision stage (e.g., content, business, or legal review in a compliance workflow), with predefined transitions representing task escalation or completion. Epistemic uncertainty is quantified at the agent level using Monte Carlo estimation, while system-level uncertainty is captured by the MDP's termination in either an automated labeled state or a human-review state. We illustrate the approach through a case study in AI safety evaluation for self-harm detection, implemented as a multi-agent compliance system. Results demonstrate improvements over a single-agent baseline, including up to a 19\\% increase in accuracy, up to an 85x reduction in required human review, and, in some configurations, reduced processing time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6709\u9650\u65f6\u57df\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u6539\u8fdbLLM\u667a\u80fd\u4f53\u5728\u5408\u89c4\u548c\u5c3d\u804c\u8c03\u67e5\u7b49\u76d1\u7ba1\u573a\u666f\u4e2d\u7684\u590d\u6742\u591a\u6b65\u5de5\u4f5c\u6d41\u5904\u7406\uff0c\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u5728\u51c6\u786e\u6027\u3001\u4eba\u5de5\u5ba1\u6838\u9700\u6c42\u548c\u5904\u7406\u65f6\u95f4\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u5408\u89c4\u3001\u5c3d\u804c\u8c03\u67e5\u7b49\u76d1\u7ba1\u573a\u666f\u4e2d\u6267\u884c\u590d\u6742\u591a\u6b65\u5de5\u4f5c\u6d41\u65f6\uff0c\u4e3b\u8981\u4f9d\u8d56\u5355\u4e2a\u667a\u80fd\u4f53\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u96be\u4ee5\u89c2\u5bdf\u548c\u6bd4\u8f83\u6a21\u578b\u5982\u4f55\u5904\u7406\u8de8\u51b3\u7b56\u9636\u6bb5\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u534f\u8c03\u95ee\u9898\uff0c\u4ee5\u53ca\u5982\u4f55\u4e0e\u4eba\u5de5\u76d1\u7763\u76f8\u7ed3\u5408\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u5f62\u5f0f\u5316\u4e3a\u6709\u9650\u65f6\u57df\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5177\u6709\u6709\u5411\u65e0\u73af\u7ed3\u6784\u3002\u6bcf\u4e2a\u667a\u80fd\u4f53\u5bf9\u5e94\u7279\u5b9a\u89d2\u8272\u6216\u51b3\u7b56\u9636\u6bb5\uff08\u5982\u5408\u89c4\u5de5\u4f5c\u6d41\u4e2d\u7684\u5185\u5bb9\u3001\u4e1a\u52a1\u6216\u6cd5\u5f8b\u5ba1\u67e5\uff09\uff0c\u5177\u6709\u9884\u5b9a\u4e49\u7684\u8f6c\u6362\u8868\u793a\u4efb\u52a1\u5347\u7ea7\u6216\u5b8c\u6210\u3002\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5728\u667a\u80fd\u4f53\u5c42\u9762\u91cf\u5316\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u7cfb\u7edf\u7ea7\u4e0d\u786e\u5b9a\u6027\u901a\u8fc7MDP\u5728\u81ea\u52a8\u6807\u8bb0\u72b6\u6001\u6216\u4eba\u5de5\u5ba1\u6838\u72b6\u6001\u7684\u7ec8\u6b62\u6765\u6355\u83b7\u3002", "result": "\u5728AI\u5b89\u5168\u8bc4\u4f30\uff08\u81ea\u6b8b\u68c0\u6d4b\uff09\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b9e\u73b0\u4e86\uff1a\u51c6\u786e\u6027\u6700\u9ad8\u63d0\u534719%\uff0c\u4eba\u5de5\u5ba1\u6838\u9700\u6c42\u6700\u591a\u51cf\u5c1185\u500d\uff0c\u67d0\u4e9b\u914d\u7f6e\u4e0b\u5904\u7406\u65f6\u95f4\u4e5f\u6709\u6240\u51cf\u5c11\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53MDP\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406LLM\u667a\u80fd\u4f53\u5728\u76d1\u7ba1\u5de5\u4f5c\u6d41\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u534f\u8c03\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u5e76\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u9700\u6c42\uff0c\u4e3a\u590d\u6742\u51b3\u7b56\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u53ef\u89c2\u5bdf\u548c\u53ef\u6bd4\u8f83\u7684\u67b6\u6784\u3002"}}
{"id": "2602.02039", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02039", "abs": "https://arxiv.org/abs/2602.02039", "authors": ["Wei Liu", "Peijie Yu", "Michele Orini", "Yali Du", "Yulan He"], "title": "Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models", "comment": "14 pages, 7 tables, 8 figures", "summary": "The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u8c03\u67e5\u6027\u667a\u80fd\"\u6982\u5ff5\uff0c\u533a\u522b\u4e8e\"\u6267\u884c\u6027\u667a\u80fd\"\uff0c\u5e76\u5f15\u5165Deep Data Research\u4efb\u52a1\u548cDDR-Bench\u57fa\u51c6\u6765\u8bc4\u4f30LLM\u5728\u81ea\u4e3b\u6570\u636e\u63a2\u7d22\u4e2d\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLM\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u56de\u7b54\u6b63\u786e\u6027\uff0c\u4f46\u771f\u6b63\u7684\u667a\u80fd\u4f53\u9700\u8981\u81ea\u4e3b\u8bbe\u5b9a\u76ee\u6807\u548c\u63a2\u7d22\u80fd\u529b\u3002\u6570\u636e\u79d1\u5b66\u9886\u57df\u63d0\u4f9b\u4e86\u5929\u7136\u6d4b\u8bd5\u573a\uff0c\u56e0\u4e3a\u771f\u5b9e\u5206\u6790\u4ece\u539f\u59cb\u6570\u636e\u5f00\u59cb\u800c\u975e\u660e\u786e\u67e5\u8be2\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u5bf9\u6b64\u5173\u6ce8\u4e0d\u8db3\u3002", "method": "\u63d0\u51faDeep Data Research\u5f00\u653e\u4efb\u52a1\uff0c\u8ba9LLM\u4ece\u6570\u636e\u5e93\u4e2d\u81ea\u4e3b\u63d0\u53d6\u5173\u952e\u89c1\u89e3\uff1b\u521b\u5efaDDR-Bench\u5927\u89c4\u6a21\u68c0\u67e5\u8868\u57fa\u51c6\uff0c\u652f\u6301\u53ef\u9a8c\u8bc1\u8bc4\u4f30\uff1b\u5206\u6790\u524d\u6cbf\u6a21\u578b\u5728\u957f\u89c6\u91ce\u63a2\u7d22\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u663e\u793a\u51fa\u521d\u6b65\u7684\u667a\u80fd\u4f53\u80fd\u529b\uff0c\u4f46\u957f\u89c6\u91ce\u63a2\u7d22\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u7814\u7a76\u53d1\u73b0\u6709\u6548\u7684\u8c03\u67e5\u6027\u667a\u80fd\u4e0d\u4ec5\u4f9d\u8d56\u4e8e\u667a\u80fd\u4f53\u6846\u67b6\u6216\u5355\u7eaf\u6269\u5c55\uff0c\u8fd8\u53d6\u51b3\u4e8e\u667a\u80fd\u4f53\u6a21\u578b\u7684\u5185\u5728\u7b56\u7565\u3002", "conclusion": "\u8c03\u67e5\u6027\u667a\u80fd\u662fLLM\u667a\u80fd\u4f53\u7684\u5173\u952e\u80fd\u529b\uff0c\u9700\u8981\u4e13\u95e8\u7684\u8bc4\u4f30\u57fa\u51c6\u3002DDR-Bench\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u81ea\u4e3b\u6570\u636e\u63a2\u7d22\u65b9\u9762\u7684\u5c40\u9650\u6027\u548c\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2602.02133", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02133", "abs": "https://arxiv.org/abs/2602.02133", "authors": ["Sangwoo Shin", "BumJun Kim", "Kyelim Lee", "Moongyu Jeon", "Albert No"], "title": "Understanding the Reversal Curse Mitigation in Masked Diffusion Models through Attention and Training Dynamics", "comment": null, "summary": "Autoregressive language models (ARMs) suffer from the reversal curse: after learning that \"$A$ is $B$\", they often fail on the reverse query \"$B$ is $A$\". Masked diffusion-based language models (MDMs) exhibit this failure in a much weaker form, but the underlying reason has remained unclear. A common explanation attributes this mitigation to the any-order training objective. However, observing \"[MASK] is $B$\" during training does not necessarily teach the model to handle the reverse prompt \"$B$ is [MASK]\". We show that the mitigation arises from architectural structure and its interaction with training. In a one-layer Transformer encoder, weight sharing couples the two directions by making forward and reverse attention scores positively correlated. In the same setting, we further show that the corresponding gradients are aligned, so minimizing the forward loss also reduces the reverse loss. Experiments on both controlled toy tasks and large-scale diffusion language models support these mechanisms, explaining why MDMs partially overcome a failure mode that persists in strong ARMs.", "AI": {"tldr": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u6bd4\u81ea\u56de\u5f52\u6a21\u578b\u66f4\u80fd\u7f13\u89e3\u53cd\u8f6c\u8bc5\u5492\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u67b6\u6784\u7ed3\u6784\u548c\u8bad\u7ec3\u4ea4\u4e92\uff0c\u800c\u975e\u8bad\u7ec3\u76ee\u6807\u672c\u8eab\u3002", "motivation": "\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u53cd\u8f6c\u8bc5\u5492\u95ee\u9898\uff08\u5b66\u4e60\"A\u662fB\"\u540e\u65e0\u6cd5\u56de\u7b54\"B\u662fA\"\uff09\uff0c\u800c\u63a9\u7801\u6269\u6563\u8bed\u8a00\u6a21\u578b\u867d\u7136\u4e5f\u6709\u6b64\u95ee\u9898\u4f46\u7a0b\u5ea6\u8f7b\u5f97\u591a\uff0c\u4f46\u5176\u6839\u672c\u539f\u56e0\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5355\u5c42Transformer\u7f16\u7801\u5668\u67b6\u6784\uff0c\u7814\u7a76\u6743\u91cd\u5171\u4eab\u5982\u4f55\u4f7f\u524d\u5411\u548c\u53cd\u5411\u6ce8\u610f\u529b\u5206\u6570\u6b63\u76f8\u5173\uff0c\u5e76\u8bc1\u660e\u76f8\u5e94\u68af\u5ea6\u5bf9\u9f50\uff0c\u4ece\u800c\u6700\u5c0f\u5316\u524d\u5411\u635f\u5931\u4e5f\u51cf\u5c11\u53cd\u5411\u635f\u5931\u3002\u5728\u53d7\u63a7\u73a9\u5177\u4efb\u52a1\u548c\u5927\u89c4\u6a21\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5bf9\u53cd\u8f6c\u8bc5\u5492\u7684\u7f13\u89e3\u4e3b\u8981\u6e90\u4e8e\u67b6\u6784\u7ed3\u6784\u53ca\u5176\u4e0e\u8bad\u7ec3\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u800c\u975e\u901a\u5e38\u8ba4\u4e3a\u7684\u4efb\u610f\u987a\u5e8f\u8bad\u7ec3\u76ee\u6807\u3002\u6743\u91cd\u5171\u4eab\u673a\u5236\u4f7f\u6a21\u578b\u80fd\u66f4\u597d\u5730\u5904\u7406\u53cd\u5411\u67e5\u8be2\u3002", "conclusion": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u90e8\u5206\u514b\u670d\u81ea\u56de\u5f52\u6a21\u578b\u6301\u7eed\u5b58\u5728\u7684\u53cd\u8f6c\u8bc5\u5492\u95ee\u9898\uff0c\u8fd9\u4e3b\u8981\u5f52\u56e0\u4e8e\u5176\u67b6\u6784\u7279\u6027\u548c\u8bad\u7ec3\u52a8\u6001\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u800c\u975e\u8bad\u7ec3\u76ee\u6807\u672c\u8eab\u3002"}}
{"id": "2602.02136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02136", "abs": "https://arxiv.org/abs/2602.02136", "authors": ["Yingsha Xie", "Tiansheng Huang", "Enneng Yang", "Rui Min", "Wenjie Lu", "Xiaochun Cao", "Naiqiang Tan", "Li Shen"], "title": "Mitigating Safety Tax via Distribution-Grounded Refinement in Large Reasoning Models", "comment": "Code will be released soon", "summary": "Safety alignment incurs safety tax that perturbs a large reasoning model's (LRM) general reasoning ability. Existing datasets used for safety alignment for an LRM are usually constructed by distilling safety reasoning traces and answers from an external LRM or human labeler. However, such reasoning traces and answers exhibit a distributional gap with the target LRM that needs alignment, and we conjecture such distributional gap is the culprit leading to significant degradation of reasoning ability of the target LRM. Driven by this hypothesis, we propose a safety alignment dataset construction method, dubbed DGR. DGR transforms and refines an existing out-of-distributional safety reasoning dataset to be aligned with the target's LLM inner distribution. Experimental results demonstrate that i) DGR effectively mitigates the safety tax while maintaining safety performance across all baselines, i.e., achieving \\textbf{+30.2\\%} on DirectRefusal and \\textbf{+21.2\\%} on R1-ACT improvement in average reasoning accuracy compared to Vanilla SFT; ii) the degree of reasoning degradation correlates with the extent of distribution shift, suggesting that bridging this gap is central to preserving capabilities. Furthermore, we find that safety alignment in LRMs may primarily function as a mechanism to activate latent knowledge, as a mere \\textbf{10} samples are sufficient for activating effective refusal behaviors. These findings not only emphasize the importance of distributional consistency but also provide insights into the activation mechanism of safety in reasoning models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDGR\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5916\u90e8\u5b89\u5168\u63a8\u7406\u6570\u636e\u96c6\u8f6c\u5316\u4e3a\u4e0e\u76ee\u6807\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u5206\u5e03\u5bf9\u9f50\u7684\u5f62\u5f0f\uff0c\u6709\u6548\u7f13\u89e3\u5b89\u5168\u5bf9\u9f50\u5e26\u6765\u7684\u63a8\u7406\u80fd\u529b\u9000\u5316\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u5bf9\u9f50\u6570\u636e\u96c6\u901a\u5e38\u4ece\u5916\u90e8\u5927\u6a21\u578b\u6216\u4eba\u5de5\u6807\u6ce8\u4e2d\u84b8\u998f\u5b89\u5168\u63a8\u7406\u8f68\u8ff9\u548c\u7b54\u6848\uff0c\u4f46\u8fd9\u4e9b\u6570\u636e\u4e0e\u9700\u8981\u5bf9\u9f50\u7684\u76ee\u6807\u6a21\u578b\u5b58\u5728\u5206\u5e03\u5dee\u5f02\uff0c\u4f5c\u8005\u63a8\u6d4b\u8fd9\u79cd\u5206\u5e03\u5dee\u5f02\u662f\u5bfc\u81f4\u76ee\u6807\u6a21\u578b\u63a8\u7406\u80fd\u529b\u663e\u8457\u9000\u5316\u7684\u4e3b\u8981\u539f\u56e0\u3002", "method": "\u63d0\u51faDGR\u65b9\u6cd5\uff0c\u5c06\u73b0\u6709\u5206\u5e03\u5916\u5b89\u5168\u63a8\u7406\u6570\u636e\u96c6\u8fdb\u884c\u8f6c\u5316\u548c\u7cbe\u70bc\uff0c\u4f7f\u5176\u4e0e\u76ee\u6807LLM\u7684\u5185\u90e8\u5206\u5e03\u5bf9\u9f50\uff0c\u4ece\u800c\u51cf\u5c11\u5206\u5e03\u5dee\u5f02\u5bf9\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09DGR\u5728\u4fdd\u6301\u5b89\u5168\u6027\u80fd\u7684\u540c\u65f6\u6709\u6548\u7f13\u89e3\u5b89\u5168\u7a0e\uff0c\u76f8\u6bd4Vanilla SFT\u5728DirectRefusal\u4e0a\u5e73\u5747\u63a8\u7406\u51c6\u786e\u7387\u63d0\u534730.2%\uff0c\u5728R1-ACT\u4e0a\u63d0\u534721.2%\uff1b2\uff09\u63a8\u7406\u9000\u5316\u7a0b\u5ea6\u4e0e\u5206\u5e03\u504f\u79fb\u7a0b\u5ea6\u76f8\u5173\uff1b3\uff09\u4ec5\u970010\u4e2a\u6837\u672c\u5373\u53ef\u6fc0\u6d3b\u6709\u6548\u7684\u62d2\u7edd\u884c\u4e3a\uff0c\u8868\u660e\u5b89\u5168\u5bf9\u9f50\u53ef\u80fd\u4e3b\u8981\u4f5c\u4e3a\u6fc0\u6d3b\u6f5c\u5728\u77e5\u8bc6\u7684\u673a\u5236\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5206\u5e03\u4e00\u81f4\u6027\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u5b89\u5168\u5728\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u6fc0\u6d3b\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u8868\u660e\u5b89\u5168\u5bf9\u9f50\u53ef\u80fd\u4e3b\u8981\u4f5c\u4e3a\u6fc0\u6d3b\u6a21\u578b\u5df2\u6709\u6f5c\u5728\u77e5\u8bc6\u7684\u673a\u5236\uff0c\u800c\u975e\u690d\u5165\u65b0\u77e5\u8bc6\u3002"}}
{"id": "2602.02158", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02158", "abs": "https://arxiv.org/abs/2602.02158", "authors": ["Sarah Nassar"], "title": "Traffic-Aware Navigation in Road Networks", "comment": null, "summary": "This project compares three graph search approaches for the task of traffic-aware navigation in Kingston's road network. These approaches include a single-run multi-query preprocessing algorithm (Floyd-Warshall-Ingerman), continuous single-query real-time search (Dijkstra's and A*), and an algorithm combining both approaches to balance between their trade-offs by first finding the top K shortest paths then iterating over them in real time (Yen's). Dijkstra's and A* resulted in the most traffic-aware optimal solutions with minimal preprocessing required. Floyd-Warshall-Ingerman was the fastest in real time but provided distance based paths with no traffic awareness. Yen's algorithm required significant preprocessing but balanced between the other two approaches in terms of runtime speed and optimality. Each approach presents advantages and disadvantages that need to be weighed depending on the circumstances of specific deployment contexts to select the best custom solution. *This project was completed as part of ELEC 844 (Search and Planning Algorithms for Robotics) in the Fall 2025 term.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u4e09\u79cd\u56fe\u641c\u7d22\u65b9\u6cd5\u5728\u91d1\u65af\u987f\u8def\u7f51\u4ea4\u901a\u611f\u77e5\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u62ecFloyd-Warshall-Ingerman\u9884\u5904\u7406\u7b97\u6cd5\u3001Dijkstra\u548cA*\u5b9e\u65f6\u641c\u7d22\u7b97\u6cd5\uff0c\u4ee5\u53ca\u7ed3\u5408\u4e24\u8005\u7684Yen\u7b97\u6cd5\uff0c\u5206\u6790\u4e86\u5404\u81ea\u5728\u9884\u5904\u7406\u9700\u6c42\u3001\u5b9e\u65f6\u901f\u5ea6\u548c\u8def\u5f84\u6700\u4f18\u6027\u65b9\u9762\u7684\u6743\u8861\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u4e0d\u540c\u56fe\u641c\u7d22\u7b97\u6cd5\u5728\u4ea4\u901a\u611f\u77e5\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u9884\u5904\u7406\u9700\u6c42\u3001\u5b9e\u65f6\u8ba1\u7b97\u901f\u5ea6\u548c\u8def\u5f84\u6700\u4f18\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u9009\u62e9\u6700\u9002\u5408\u7684\u7b97\u6cd5\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u4e09\u79cd\u56fe\u641c\u7d22\u65b9\u6cd5\u7684\u6bd4\u8f83\uff1a1\uff09\u5355\u6b21\u8fd0\u884c\u591a\u67e5\u8be2\u9884\u5904\u7406\u7b97\u6cd5\uff08Floyd-Warshall-Ingerman\uff09\uff1b2\uff09\u8fde\u7eed\u5355\u67e5\u8be2\u5b9e\u65f6\u641c\u7d22\u7b97\u6cd5\uff08Dijkstra\u548cA*\uff09\uff1b3\uff09\u7ed3\u5408\u4e24\u8005\u7684\u7b97\u6cd5\uff08Yen\u7b97\u6cd5\uff09\uff0c\u5148\u627e\u5230\u524dK\u6761\u6700\u77ed\u8def\u5f84\uff0c\u7136\u540e\u5728\u5b9e\u65f6\u4e2d\u8fed\u4ee3\u3002", "result": "Dijkstra\u548cA*\u7b97\u6cd5\u4ea7\u751f\u4e86\u6700\u5177\u4ea4\u901a\u611f\u77e5\u7684\u6700\u4f18\u89e3\uff0c\u4e14\u6240\u9700\u9884\u5904\u7406\u6700\u5c11\uff1bFloyd-Warshall-Ingerman\u7b97\u6cd5\u5b9e\u65f6\u901f\u5ea6\u6700\u5feb\uff0c\u4f46\u4ec5\u63d0\u4f9b\u57fa\u4e8e\u8ddd\u79bb\u7684\u8def\u5f84\uff0c\u65e0\u4ea4\u901a\u611f\u77e5\uff1bYen\u7b97\u6cd5\u9700\u8981\u5927\u91cf\u9884\u5904\u7406\uff0c\u4f46\u5728\u8fd0\u884c\u901f\u5ea6\u548c\u6700\u4f18\u6027\u65b9\u9762\u5e73\u8861\u4e86\u5176\u4ed6\u4e24\u79cd\u65b9\u6cd5\u3002", "conclusion": "\u6bcf\u79cd\u65b9\u6cd5\u90fd\u6709\u5176\u4f18\u7f3a\u70b9\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u90e8\u7f72\u73af\u5883\u7684\u60c5\u51b5\u6743\u8861\u9009\u62e9\u6700\u4f73\u5b9a\u5236\u89e3\u51b3\u65b9\u6848\u3002\u6ca1\u6709\u5355\u4e00\u6700\u4f18\u7b97\u6cd5\uff0c\u9009\u62e9\u53d6\u51b3\u4e8e\u5bf9\u9884\u5904\u7406\u65f6\u95f4\u3001\u5b9e\u65f6\u8ba1\u7b97\u901f\u5ea6\u548c\u8def\u5f84\u6700\u4f18\u6027\u7684\u5177\u4f53\u8981\u6c42\u3002"}}
{"id": "2602.02188", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02188", "abs": "https://arxiv.org/abs/2602.02188", "authors": ["Xia Jiang", "Jing Chen", "Cong Zhang", "Jie Gao", "Chengpeng Hu", "Chenhao Zhang", "Yaoxin Wu", "Yingqian Zhang"], "title": "Reasoning in a Combinatorial and Constrained World: Benchmarking LLMs on Natural-Language Combinatorial Optimization", "comment": null, "summary": "While large language models (LLMs) have shown strong performance in math and logic reasoning, their ability to handle combinatorial optimization (CO) -- searching high-dimensional solution spaces under hard constraints -- remains underexplored. To bridge the gap, we introduce NLCO, a \\textbf{N}atural \\textbf{L}anguage \\textbf{C}ombinatorial \\textbf{O}ptimization benchmark that evaluates LLMs on end-to-end CO reasoning: given a language-described decision-making scenario, the model must output a discrete solution without writing code or calling external solvers. NLCO covers 43 CO problems and is organized using a four-layer taxonomy of variable types, constraint families, global patterns, and objective classes, enabling fine-grained evaluation. We provide solver-annotated solutions and comprehensively evaluate LLMs by feasibility, solution optimality, and reasoning efficiency. Experiments across a wide range of modern LLMs show that high-performing models achieve strong feasibility and solution quality on small instances, but both degrade as instance size grows, even if more tokens are used for reasoning. We also observe systematic effects across the taxonomy: set-based tasks are relatively easy, whereas graph-structured problems and bottleneck objectives lead to more frequent failures.", "AI": {"tldr": "NLCO\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7aef\u5230\u7aef\u63a8\u7406\u80fd\u529b\u7684\u81ea\u7136\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d643\u4e2a\u95ee\u9898\uff0c\u4f7f\u7528\u56db\u5c42\u5206\u7c7b\u4f53\u7cfb\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u548c\u903b\u8f91\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u7ec4\u5408\u4f18\u5316\uff08\u5728\u9ad8\u7ef4\u89e3\u7a7a\u95f4\u4e2d\u641c\u7d22\u6ee1\u8db3\u786c\u7ea6\u675f\u7684\u89e3\uff09\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u5efa\u7acb\u4e13\u95e8\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u4e86NLCO\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b43\u4e2a\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u91c7\u7528\u56db\u5c42\u5206\u7c7b\u4f53\u7cfb\uff08\u53d8\u91cf\u7c7b\u578b\u3001\u7ea6\u675f\u65cf\u3001\u5168\u5c40\u6a21\u5f0f\u3001\u76ee\u6807\u7c7b\u522b\uff09\uff0c\u8981\u6c42\u6a21\u578b\u76f4\u63a5\u8f93\u51fa\u79bb\u6563\u89e3\u800c\u4e0d\u7f16\u5199\u4ee3\u7801\u6216\u8c03\u7528\u5916\u90e8\u6c42\u89e3\u5668\u3002", "result": "\u9ad8\u6027\u80fd\u6a21\u578b\u5728\u5c0f\u89c4\u6a21\u5b9e\u4f8b\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u53ef\u884c\u6027\u548c\u89e3\u8d28\u91cf\uff0c\u4f46\u968f\u7740\u5b9e\u4f8b\u89c4\u6a21\u589e\u5927\uff0c\u4e24\u8005\u90fd\u4f1a\u4e0b\u964d\uff0c\u5373\u4f7f\u4f7f\u7528\u66f4\u591a\u63a8\u7406\u6807\u8bb0\u4e5f\u65e0\u6d4e\u4e8e\u4e8b\u3002\u96c6\u5408\u7c7b\u4efb\u52a1\u76f8\u5bf9\u5bb9\u6613\uff0c\u800c\u56fe\u7ed3\u6784\u95ee\u9898\u548c\u74f6\u9888\u76ee\u6807\u5219\u5bfc\u81f4\u66f4\u591a\u5931\u8d25\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ec4\u5408\u4f18\u5316\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u89c4\u6a21\u5b9e\u4f8b\u548c\u590d\u6742\u7ed3\u6784\u95ee\u9898\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u5347\u5176\u7ec4\u5408\u4f18\u5316\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.02196", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02196", "abs": "https://arxiv.org/abs/2602.02196", "authors": ["Hang Yan", "Xinyu Che", "Fangzhi Xu", "Qiushi Sun", "Zichen Ding", "Kanzhi Cheng", "Jian Zhang", "Tao Qin", "Jun Liu", "Qika Lin"], "title": "TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents", "comment": "29pages, 10 figures", "summary": "Recent advances in autonomous LLM agents demonstrate their ability to improve performance through iterative interaction with the environment. We define this paradigm as Test-Time Improvement (TTI). However, the mechanisms under how and why TTI succeed or fail remain poorly understood, and existing evaluation metrics fail to capture their task optimization efficiency, behavior adaptation after erroneous actions, and the specific utility of working memory for task completion. To address these gaps, we propose Test-time Improvement Diagnostic Evaluation (TIDE), an agent-agnostic and environment-agnostic framework that decomposes TTI into three comprehensive and interconnected dimensions. The framework measures (1) the overall temporal dynamics of task completion and (2) identifies whether performance is primarily constrained by recursive looping behaviors or (3) by burdensome accumulated memory. Through extensive experiments across diverse agents and environments, TIDE highlights that improving agent performance requires more than scaling internal reasoning, calling for explicitly optimizing the interaction dynamics between the agent and the environment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86TIDE\u6846\u67b6\uff0c\u7528\u4e8e\u8bca\u65ad\u548c\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u6d4b\u8bd5\u65f6\u6539\u8fdb\uff08TTI\uff09\u8fc7\u7a0b\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u91cd\u70b9\u5173\u6ce8\u4efb\u52a1\u4f18\u5316\u6548\u7387\u3001\u9519\u8bef\u884c\u4e3a\u9002\u5e94\u548c\u5de5\u4f5c\u8bb0\u5fc6\u6548\u7528\u3002", "motivation": "\u5f53\u524d\u5bf9\u81ea\u4e3bLLM\u667a\u80fd\u4f53\u6d4b\u8bd5\u65f6\u6539\u8fdb\uff08TTI\uff09\u673a\u5236\u7684\u7406\u89e3\u4e0d\u8db3\uff0c\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u65e0\u6cd5\u6355\u6349\u4efb\u52a1\u4f18\u5316\u6548\u7387\u3001\u9519\u8bef\u884c\u4e3a\u9002\u5e94\u548c\u5de5\u4f5c\u8bb0\u5fc6\u6548\u7528\u7b49\u5173\u952e\u7ef4\u5ea6\uff0c\u9700\u8981\u65b0\u7684\u8bca\u65ad\u6846\u67b6\u3002", "method": "\u63d0\u51faTIDE\uff08Test-time Improvement Diagnostic Evaluation\uff09\u6846\u67b6\uff0c\u5c06TTI\u5206\u89e3\u4e3a\u4e09\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u7ef4\u5ea6\uff1a\u4efb\u52a1\u5b8c\u6210\u7684\u65f6\u95f4\u52a8\u6001\u3001\u9012\u5f52\u5faa\u73af\u884c\u4e3a\u7684\u7ea6\u675f\u3001\u7d2f\u79ef\u8bb0\u5fc6\u8d1f\u62c5\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u8de8\u591a\u79cd\u667a\u80fd\u4f53\u548c\u73af\u5883\u7684\u5b9e\u9a8c\uff0cTIDE\u63ed\u793a\u4e86\u63d0\u5347\u667a\u80fd\u4f53\u6027\u80fd\u4e0d\u4ec5\u9700\u8981\u6269\u5c55\u5185\u90e8\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u9700\u8981\u4f18\u5316\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u4ea4\u4e92\u52a8\u6001\u3002", "conclusion": "TIDE\u6846\u67b6\u4e3a\u7406\u89e3TTI\u6210\u529f\u6216\u5931\u8d25\u7684\u673a\u5236\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u5f3a\u8c03\u9700\u8981\u663e\u5f0f\u4f18\u5316\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u7684\u4ea4\u4e92\u52a8\u6001\u800c\u4e0d\u4ec5\u4ec5\u662f\u6269\u5c55\u5185\u90e8\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.02304", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02304", "abs": "https://arxiv.org/abs/2602.02304", "authors": ["Martino Ciaperoni", "Marzio Di Vece", "Luca Pappalardo", "Fosca Giannotti", "Francesco Giannini"], "title": "Position: Explaining Behavioral Shifts in Large Language Models Requires a Comparative Approach", "comment": null, "summary": "Large-scale foundation models exhibit behavioral shifts: intervention-induced behavioral changes that appear after scaling, fine-tuning, reinforcement learning or in-context learning. While investigating these phenomena have recently received attention, explaining their appearance is still overlooked. Classic explainable AI (XAI) methods can surface failures at a single checkpoint of a model, but they are structurally ill-suited to justify what changed internally across different checkpoints and which explanatory claims are warranted about that change. We take the position that behavioral shifts should be explained comparatively: the core target should be the intervention-induced shift between a reference model and an intervened model, rather than any single model in isolation. To this aim we formulate a Comparative XAI ($\u0394$-XAI) framework with a set of desiderata to be taken into account when designing proper explaining methods. To highlight how $\u0394$-XAI methods work, we introduce a set of possible pipelines, relate them to the desiderata, and provide a concrete $\u0394$-XAI experiment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6bd4\u8f83\u6027\u53ef\u89e3\u91caAI\u6846\u67b6\uff08\u0394-XAI\uff09\uff0c\u7528\u4e8e\u89e3\u91ca\u5927\u89c4\u6a21\u57fa\u7840\u6a21\u578b\u5728\u5e72\u9884\u540e\u51fa\u73b0\u7684\u884c\u4e3a\u53d8\u5316\uff0c\u5f3a\u8c03\u9700\u8981\u6bd4\u8f83\u53c2\u8003\u6a21\u578b\u4e0e\u5e72\u9884\u6a21\u578b\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u800c\u975e\u5b64\u7acb\u5206\u6790\u5355\u4e2a\u6a21\u578b\u3002", "motivation": "\u5927\u89c4\u6a21\u57fa\u7840\u6a21\u578b\u5728\u6269\u5c55\u3001\u5fae\u8c03\u3001\u5f3a\u5316\u5b66\u4e60\u6216\u4e0a\u4e0b\u6587\u5b66\u4e60\u540e\u4f1a\u51fa\u73b0\u884c\u4e3a\u53d8\u5316\uff0c\u4f20\u7edfXAI\u65b9\u6cd5\u53ea\u80fd\u5206\u6790\u5355\u4e2a\u68c0\u67e5\u70b9\u7684\u5931\u8d25\uff0c\u65e0\u6cd5\u89e3\u91ca\u4e0d\u540c\u68c0\u67e5\u70b9\u4e4b\u95f4\u7684\u5185\u90e8\u53d8\u5316\uff0c\u9700\u8981\u65b0\u7684\u89e3\u91ca\u6846\u67b6\u6765\u7406\u89e3\u5e72\u9884\u5f15\u8d77\u7684\u884c\u4e3a\u8f6c\u53d8\u3002", "method": "\u63d0\u51fa\u4e86\u6bd4\u8f83\u6027\u53ef\u89e3\u91caAI\u6846\u67b6\uff08\u0394-XAI\uff09\uff0c\u5305\u542b\u4e00\u7ec4\u8bbe\u8ba1\u9002\u5f53\u89e3\u91ca\u65b9\u6cd5\u65f6\u5e94\u8003\u8651\u7684\u8981\u6c42\uff0c\u4ecb\u7ecd\u4e86\u53ef\u80fd\u7684\u5206\u6790\u6d41\u7a0b\uff0c\u5e76\u5c06\u5b83\u4eec\u4e0e\u8981\u6c42\u76f8\u5173\u8054\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u4f53\u7684\u0394-XAI\u5b9e\u9a8c\u793a\u4f8b\u3002", "result": "\u5efa\u7acb\u4e86\u0394-XAI\u6846\u67b6\uff0c\u660e\u786e\u4e86\u6bd4\u8f83\u6027\u89e3\u91ca\u7684\u6838\u5fc3\u539f\u5219\uff0c\u63d0\u4f9b\u4e86\u5206\u6790\u884c\u4e3a\u53d8\u5316\u7684\u65b9\u6cd5\u8bba\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u6bd4\u8f83\u53c2\u8003\u6a21\u578b\u4e0e\u5e72\u9884\u6a21\u578b\u6765\u89e3\u91ca\u884c\u4e3a\u8f6c\u53d8\u3002", "conclusion": "\u884c\u4e3a\u53d8\u5316\u5e94\u8be5\u901a\u8fc7\u6bd4\u8f83\u6027\u65b9\u6cd5\u6765\u89e3\u91ca\uff0c\u6838\u5fc3\u76ee\u6807\u5e94\u8be5\u662f\u53c2\u8003\u6a21\u578b\u4e0e\u5e72\u9884\u6a21\u578b\u4e4b\u95f4\u7684\u5e72\u9884\u5f15\u8d77\u7684\u53d8\u5316\uff0c\u800c\u4e0d\u662f\u5b64\u7acb\u5206\u6790\u4efb\u4f55\u5355\u4e2a\u6a21\u578b\uff0c\u0394-XAI\u6846\u67b6\u4e3a\u6b64\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u65b9\u6cd5\u6307\u5bfc\u3002"}}
{"id": "2602.02313", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02313", "abs": "https://arxiv.org/abs/2602.02313", "authors": ["Changming Li", "Kaixing Zhang", "Haoyun Xu", "Yingdong Shi", "Zheng Zhang", "Kaitao Song", "Kan Ren"], "title": "Interpreting and Controlling LLM Reasoning through Integrated Policy Gradient", "comment": null, "summary": "Large language models (LLMs) demonstrate strong reasoning abilities in solving complex real-world problems. Yet, the internal mechanisms driving these complex reasoning behaviors remain opaque. Existing interpretability approaches targeting reasoning either identify components (e.g., neurons) correlated with special textual patterns, or rely on human-annotated contrastive pairs to derive control vectors. Consequently, current methods struggle to precisely localize complex reasoning mechanisms or capture sequential influence from model internal workings to the reasoning outputs. In this paper, built on outcome-oriented and sequential-influence-aware principles, we focus on identifying components that have sequential contribution to reasoning behavior where outcomes are cumulated by long-range effects. We propose Integrated Policy Gradient (IPG), a novel framework that attributes reasoning behaviors to model's inner components by propagating compound outcome-based signals such as post reasoning accuracy backward through model inference trajectories. Empirical evaluations demonstrate that our approach achieves more precise localization and enables reliable modulation of reasoning behaviors (e.g., reasoning capability, reasoning strength) across diverse reasoning models.", "AI": {"tldr": "\u63d0\u51faIPG\u6846\u67b6\uff0c\u901a\u8fc7\u4f20\u64ad\u57fa\u4e8e\u7ed3\u679c\u7684\u4fe1\u53f7\u6765\u5b9a\u4f4d\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u590d\u6742\u63a8\u7406\u673a\u5236\uff0c\u5b9e\u73b0\u66f4\u7cbe\u786e\u7684\u7ec4\u4ef6\u5b9a\u4f4d\u548c\u63a8\u7406\u884c\u4e3a\u8c03\u63a7\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u4ecd\u7136\u4e0d\u900f\u660e\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u8bc6\u522b\u4e0e\u7279\u5b9a\u6587\u672c\u6a21\u5f0f\u76f8\u5173\u7684\u7ec4\u4ef6\uff0c\u8981\u4e48\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u7684\u5bf9\u6bd4\u5bf9\u6765\u63a8\u5bfc\u63a7\u5236\u5411\u91cf\uff0c\u96be\u4ee5\u7cbe\u786e\u5b9a\u4f4d\u590d\u6742\u63a8\u7406\u673a\u5236\u6216\u6355\u6349\u4ece\u6a21\u578b\u5185\u90e8\u5de5\u4f5c\u5230\u63a8\u7406\u8f93\u51fa\u7684\u987a\u5e8f\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u7b56\u7565\u68af\u5ea6\uff08IPG\uff09\u6846\u67b6\uff0c\u57fa\u4e8e\u7ed3\u679c\u5bfc\u5411\u548c\u987a\u5e8f\u5f71\u54cd\u611f\u77e5\u539f\u5219\uff0c\u901a\u8fc7\u5c06\u57fa\u4e8e\u7ed3\u679c\u7684\u4fe1\u53f7\uff08\u5982\u63a8\u7406\u540e\u51c6\u786e\u6027\uff09\u6cbf\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u5411\u540e\u4f20\u64ad\uff0c\u5c06\u63a8\u7406\u884c\u4e3a\u5f52\u56e0\u4e8e\u6a21\u578b\u5185\u90e8\u7ec4\u4ef6\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684\u5b9a\u4f4d\uff0c\u5e76\u80fd\u591f\u53ef\u9760\u5730\u8c03\u8282\u4e0d\u540c\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u884c\u4e3a\uff08\u5982\u63a8\u7406\u80fd\u529b\u3001\u63a8\u7406\u5f3a\u5ea6\uff09\u3002", "conclusion": "IPG\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5bf9\u63a8\u7406\u884c\u4e3a\u6709\u987a\u5e8f\u8d21\u732e\u7684\u7ec4\u4ef6\uff0c\u4e3a\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.02350", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.02350", "abs": "https://arxiv.org/abs/2602.02350", "authors": ["Xingyuan Hua", "Sheng Yue", "Xinyi Li", "Yizhe Zhao", "Jinrui Zhang", "Ju Ren"], "title": "Context Learning for Multi-Agent Discussion", "comment": null, "summary": "Multi-Agent Discussion (MAD) has garnered increasing attention very recently, where multiple LLM instances collaboratively solve problems via structured discussion. However, we find that current MAD methods easily suffer from discussion inconsistency, LLMs fail to reach a coherent solution, due to the misalignment between their individual contexts.In this paper, we introduce a multi-LLM context learning method (M2CL) that learns a context generator for each agent, capable of dynamically generating context instructions per discussion round via automatic information organization and refinement. Specifically, inspired by our theoretical insights on the context instruction, M2CL train the generators to control context coherence and output discrepancies via a carefully crafted self-adaptive mechanism.It enables LLMs to avoid premature convergence on majority noise and progressively reach the correct consensus. We evaluate M2CL on challenging tasks, including academic reasoning, embodied tasks, and mobile control. The results show that the performance of M2CL significantly surpasses existing methods by 20%--50%, while enjoying favorable transferability and computational efficiency.", "AI": {"tldr": "M2CL\u662f\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u6bcf\u4e2a\u667a\u80fd\u4f53\u7684\u4e0a\u4e0b\u6587\u751f\u6210\u5668\uff0c\u52a8\u6001\u751f\u6210\u6bcf\u8f6e\u8ba8\u8bba\u7684\u4e0a\u4e0b\u6587\u6307\u4ee4\uff0c\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u8ba8\u8bba\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd20%-50%\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u8ba8\u8bba\u65b9\u6cd5\u5bb9\u6613\u906d\u53d7\u8ba8\u8bba\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u7531\u4e8e\u667a\u80fd\u4f53\u4e2a\u4f53\u4e0a\u4e0b\u6587\u4e4b\u95f4\u7684\u4e0d\u5bf9\u9f50\uff0c\u5bfc\u81f4LLM\u65e0\u6cd5\u8fbe\u6210\u4e00\u81f4\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "M2CL\u5f15\u5165\u591aLLM\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e3a\u6bcf\u4e2a\u667a\u80fd\u4f53\u5b66\u4e60\u4e00\u4e2a\u4e0a\u4e0b\u6587\u751f\u6210\u5668\uff0c\u901a\u8fc7\u81ea\u52a8\u4fe1\u606f\u7ec4\u7ec7\u548c\u7cbe\u70bc\u52a8\u6001\u751f\u6210\u6bcf\u8f6e\u8ba8\u8bba\u7684\u4e0a\u4e0b\u6587\u6307\u4ee4\uff0c\u91c7\u7528\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u81ea\u9002\u5e94\u673a\u5236\u63a7\u5236\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u548c\u8f93\u51fa\u5dee\u5f02\u3002", "result": "\u5728\u5b66\u672f\u63a8\u7406\u3001\u5177\u8eab\u4efb\u52a1\u548c\u79fb\u52a8\u63a7\u5236\u7b49\u6311\u6218\u6027\u4efb\u52a1\u4e0a\uff0cM2CL\u6027\u80fd\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd520%-50%\uff0c\u540c\u65f6\u5177\u6709\u826f\u597d\u7684\u53ef\u8fc1\u79fb\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "M2CL\u901a\u8fc7\u52a8\u6001\u4e0a\u4e0b\u6587\u751f\u6210\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u8ba8\u8bba\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u4f7fLLM\u80fd\u591f\u907f\u514d\u8fc7\u65e9\u6536\u655b\u4e8e\u591a\u6570\u566a\u58f0\uff0c\u9010\u6b65\u8fbe\u6210\u6b63\u786e\u5171\u8bc6\u3002"}}
{"id": "2602.02386", "categories": ["cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02386", "abs": "https://arxiv.org/abs/2602.02386", "authors": ["Mika Okamoto", "Ansel Kaplan Erol", "Glenn Matlin"], "title": "Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing", "comment": "Appeared at MLSys YPS 2025", "summary": "How should Large Language Model (LLM) practitioners select the right model for a task without wasting money? We introduce BELLA (Budget-Efficient LLM Selection via Automated skill-profiling), a framework that recommends optimal LLM selection for tasks through interpretable skill-based model selection. Standard benchmarks report aggregate metrics that obscure which specific capabilities a task requires and whether a cheaper model could suffice. BELLA addresses this gap through three stages: (1) decomposing LLM outputs and extract the granular skills required by using critic-based profiling, (2) clustering skills into structured capability matrices, and (3) multi-objective optimization to select the right models to maximize performance while respecting budget constraints. BELLA provides natural-language rationale for recommendations, providing transparency that current black-box routing systems lack. We describe the framework architecture, situate it within the landscape of LLM routing and evaluation, and discuss its application to financial reasoning as a representative domain exhibiting diverse skill requirements and cost-variation across models. Our framework enables practitioners to make principled and cost-performance trade-offs for deploying LLMs.", "AI": {"tldr": "BELLA\u662f\u4e00\u4e2a\u9884\u7b97\u9ad8\u6548\u7684LLM\u9009\u62e9\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6280\u80fd\u5206\u6790\u63a8\u8350\u6700\u4f18\u6a21\u578b\uff0c\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u63a7\u5236\u6210\u672c\u3002", "motivation": "\u5f53\u524dLLM\u9009\u62e9\u9762\u4e34\u4e24\u4e2a\u95ee\u9898\uff1a\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u7684\u805a\u5408\u6307\u6807\u65e0\u6cd5\u63ed\u793a\u4efb\u52a1\u5177\u4f53\u9700\u8981\u54ea\u4e9b\u80fd\u529b\uff1b\u7528\u6237\u4e0d\u77e5\u9053\u662f\u5426\u66f4\u4fbf\u5b9c\u7684\u6a21\u578b\u5c31\u80fd\u6ee1\u8db3\u9700\u6c42\uff0c\u5bfc\u81f4\u8d44\u91d1\u6d6a\u8d39\u3002\u9700\u8981\u4e00\u79cd\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\u3002", "method": "BELLA\u91c7\u7528\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u6279\u8bc4\u8005\u5206\u6790\u5206\u89e3LLM\u8f93\u51fa\uff0c\u63d0\u53d6\u7ec6\u7c92\u5ea6\u6280\u80fd\uff1b2) \u5c06\u6280\u80fd\u805a\u7c7b\u4e3a\u7ed3\u6784\u5316\u80fd\u529b\u77e9\u9635\uff1b3) \u591a\u76ee\u6807\u4f18\u5316\u9009\u62e9\u6a21\u578b\uff0c\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u6700\u5927\u5316\u6027\u80fd\u3002\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u63a8\u8350\u7406\u7531\u3002", "result": "BELLA\u6846\u67b6\u4e3aLLM\u9009\u62e9\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u652f\u6301\uff0c\u80fd\u591f\u8bc6\u522b\u4efb\u52a1\u6240\u9700\u7684\u5177\u4f53\u6280\u80fd\uff0c\u5e76\u63a8\u8350\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u6027\u80fd\u6700\u4f18\u7684\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u9ed1\u76d2\u8def\u7531\u7cfb\u7edf\u7f3a\u4e4f\u900f\u660e\u5ea6\u7684\u95ee\u9898\u3002", "conclusion": "BELLA\u4f7f\u4ece\u4e1a\u8005\u80fd\u591f\u5728\u90e8\u7f72LLM\u65f6\u505a\u51fa\u6709\u539f\u5219\u7684\u6210\u672c-\u6027\u80fd\u6743\u8861\uff0c\u901a\u8fc7\u6280\u80fd\u5206\u6790\u5b9e\u73b0\u9884\u7b97\u9ad8\u6548\u7684\u6a21\u578b\u9009\u62e9\uff0c\u7279\u522b\u9002\u7528\u4e8e\u91d1\u878d\u63a8\u7406\u7b49\u9700\u8981\u591a\u6837\u5316\u6280\u80fd\u4e14\u6a21\u578b\u6210\u672c\u5dee\u5f02\u5927\u7684\u9886\u57df\u3002"}}
{"id": "2602.02416", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02416", "abs": "https://arxiv.org/abs/2602.02416", "authors": ["Ankur Samanta", "Akshayaa Magesh", "Ayush Jain", "Kavosh Asadi", "Youliang Yu", "Daniel Jiang", "Boris Vidolov", "Kaveh Hassani", "Paul Sajda", "Jalaj Bhandari", "Yonathan Efroni"], "title": "Structure Enables Effective Self-Localization of Errors in LLMs", "comment": null, "summary": "Self-correction in language models remains elusive. In this work, we explore whether language models can explicitly localize errors in incorrect reasoning, as a path toward building AI systems that can effectively correct themselves. We introduce a prompting method that structures reasoning as discrete, semantically coherent thought steps, and show that models are able to reliably localize errors within this structure, while failing to do so in conventional, unstructured chain-of-thought reasoning. Motivated by how the human brain monitors errors at discrete decision points and resamples alternatives, we introduce Iterative Correction Sampling of Thoughts (Thought-ICS), a self-correction framework. Thought-ICS iteratively prompts the model to generate reasoning one discrete and complete thought at a time--where each thought represents a deliberate decision by the model--creating natural boundaries for precise error localization. Upon verification, the model localizes the first erroneous step, and the system backtracks to generate alternative reasoning from the last correct point. When asked to correct reasoning verified as incorrect by an oracle, Thought-ICS achieves 20-40% self-correction lift. In a completely autonomous setting without external verification, it outperforms contemporary self-correction baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faThought-ICS\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u63a8\u7406\u5206\u89e3\u4e3a\u79bb\u6563\u7684\u8bed\u4e49\u8fde\u8d2f\u601d\u7ef4\u6b65\u9aa4\uff0c\u4f7f\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u51c6\u786e\u5b9a\u4f4d\u9519\u8bef\u5e76\u8fdb\u884c\u8fed\u4ee3\u81ea\u6211\u4fee\u6b63\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u4ecd\u7136\u96be\u4ee5\u5b9e\u73b0\u3002\u672c\u6587\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u663e\u5f0f\u5b9a\u4f4d\u9519\u8bef\u63a8\u7406\u4e2d\u7684\u9519\u8bef\uff0c\u4f5c\u4e3a\u6784\u5efa\u80fd\u591f\u6709\u6548\u81ea\u6211\u4fee\u6b63\u7684AI\u7cfb\u7edf\u7684\u9014\u5f84\u3002", "method": "\u5f15\u5165Thought-ICS\uff08\u8fed\u4ee3\u4fee\u6b63\u601d\u7ef4\u91c7\u6837\uff09\u6846\u67b6\uff1a1\uff09\u5c06\u63a8\u7406\u7ed3\u6784\u5316\u4e3a\u79bb\u6563\u3001\u8bed\u4e49\u8fde\u8d2f\u7684\u601d\u7ef4\u6b65\u9aa4\uff1b2\uff09\u6bcf\u6b21\u751f\u6210\u4e00\u4e2a\u5b8c\u6574\u7684\u79bb\u6563\u601d\u7ef4\uff1b3\uff09\u9a8c\u8bc1\u540e\u5b9a\u4f4d\u7b2c\u4e00\u4e2a\u9519\u8bef\u6b65\u9aa4\uff1b4\uff09\u56de\u6eaf\u5230\u6700\u540e\u4e00\u4e2a\u6b63\u786e\u70b9\u751f\u6210\u66ff\u4ee3\u63a8\u7406\uff1b5\uff09\u8fed\u4ee3\u8fdb\u884c\u4fee\u6b63\u3002", "result": "1\uff09\u5728\u4f20\u7edf\u975e\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u6a21\u578b\u65e0\u6cd5\u53ef\u9760\u5b9a\u4f4d\u9519\u8bef\uff0c\u800c\u5728\u7ed3\u6784\u5316\u601d\u7ef4\u6b65\u9aa4\u4e2d\u80fd\u591f\u53ef\u9760\u5b9a\u4f4d\uff1b2\uff09\u5728\u6709\u5916\u90e8\u9a8c\u8bc1\u7684\u60c5\u51b5\u4e0b\uff0cThought-ICS\u5b9e\u73b020-40%\u7684\u81ea\u6211\u4fee\u6b63\u63d0\u5347\uff1b3\uff09\u5728\u5b8c\u5168\u81ea\u4e3b\u65e0\u5916\u90e8\u9a8c\u8bc1\u7684\u8bbe\u7f6e\u4e2d\uff0c\u4f18\u4e8e\u5f53\u4ee3\u81ea\u6211\u4fee\u6b63\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5c06\u63a8\u7406\u7ed3\u6784\u5316\u4e3a\u79bb\u6563\u601d\u7ef4\u6b65\u9aa4\uff0c\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u5b9a\u4f4d\u548c\u4fee\u6b63\u9519\u8bef\uff0cThought-ICS\u6846\u67b6\u4e3a\u6784\u5efa\u80fd\u591f\u81ea\u6211\u4fee\u6b63\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2602.02453", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02453", "abs": "https://arxiv.org/abs/2602.02453", "authors": ["Andong Chen", "Wenxin Zhu", "Qiuyu Ding", "Yuchen Song", "Muyun Yang", "Tiejun Zhao"], "title": "Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling", "comment": "Working paper", "summary": "Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.", "AI": {"tldr": "\u63d0\u51fa\"Thinking with Comics\"\u65b9\u6cd5\uff0c\u4f7f\u7528\u6f2b\u753b\u4f5c\u4e3a\u4ecb\u4e8e\u56fe\u50cf\u548c\u89c6\u9891\u4e4b\u95f4\u7684\u9ad8\u4fe1\u606f\u5bc6\u5ea6\u89c6\u89c9\u63a8\u7406\u5a92\u4ecb\uff0c\u5728\u4fdd\u6301\u65f6\u95f4\u7ed3\u6784\u548c\u53d9\u4e8b\u8fde\u8d2f\u6027\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u6210\u672c", "motivation": "\u73b0\u6709\u6a21\u6001\u5b58\u5728\u660e\u663e\u9650\u5236\uff1a\u9759\u6001\u56fe\u50cf\u96be\u4ee5\u8868\u793a\u65f6\u95f4\u7ed3\u6784\uff0c\u800c\u89c6\u9891\u5f15\u5165\u5927\u91cf\u5197\u4f59\u548c\u8ba1\u7b97\u6210\u672c\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u7559\u65f6\u95f4\u7ed3\u6784\u53c8\u9ad8\u6548\u7684\u89c6\u89c9\u63a8\u7406\u5a92\u4ecb", "method": "\u63d0\u51fa\u4ee5\u6f2b\u753b\u4e3a\u5a92\u4ecb\u7684\u89c6\u89c9\u63a8\u7406\u8303\u5f0f\uff0c\u6f2b\u753b\u4f5c\u4e3a\u9ad8\u4fe1\u606f\u5bc6\u5ea6\u4ecb\u8d28\u4ecb\u4e8e\u56fe\u50cf\u548c\u89c6\u9891\u4e4b\u95f4\uff0c\u4fdd\u7559\u65f6\u95f4\u7ed3\u6784\u3001\u5d4c\u5165\u6587\u672c\u548c\u53d9\u4e8b\u8fde\u8d2f\u6027\uff0c\u7cfb\u7edf\u7814\u7a76\u57fa\u4e8e\u6f2b\u753b\u7684\u4e24\u79cd\u63a8\u7406\u8def\u5f84", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cThinking with Comics\u5728\u591a\u6b65\u65f6\u95f4\u548c\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e0a\u4f18\u4e8eThinking with Images\uff0c\u540c\u65f6\u6bd4Thinking with Video\u663e\u8457\u66f4\u9ad8\u6548\u3002\u4e0d\u540c\u6f2b\u753b\u53d9\u4e8b\u7ed3\u6784\u548c\u98ce\u683c\u5bf9\u4efb\u52a1\u6027\u80fd\u6709\u6301\u7eed\u5f71\u54cd", "conclusion": "\u6f2b\u753b\u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u4e2d\u95f4\u89c6\u89c9\u8868\u793a\uff0c\u80fd\u591f\u6539\u8fdb\u591a\u6a21\u6001\u63a8\u7406\uff0c\u5728\u4fe1\u606f\u5bc6\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861"}}
{"id": "2602.02465", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02465", "abs": "https://arxiv.org/abs/2602.02465", "authors": ["Jana Zeller", "Thadd\u00e4us Wiedemer", "Fanfei Li", "Thomas Klein", "Prasanna Mayilvahanan", "Matthias Bethge", "Felix Wichmann", "Ryan Cotterell", "Wieland Brendel"], "title": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "comment": "9 pages, 8 figures", "summary": "Frontier models are transitioning from multimodal large language models (MLLMs) that merely ingest visual information to unified multimodal models (UMMs) capable of native interleaved generation. This shift has sparked interest in using intermediate visualizations as a reasoning aid, akin to human mental imagery. Central to this idea is the ability to form, maintain, and manipulate visual representations in a goal-oriented manner. To evaluate and probe this capability, we develop MentisOculi, a procedural, stratified suite of multi-step reasoning problems amenable to visual solution, tuned to challenge frontier models. Evaluating visual strategies ranging from latent tokens to explicit generated imagery, we find they generally fail to improve performance. Analysis of UMMs specifically exposes a critical limitation: While they possess the textual reasoning capacity to solve a task and can sometimes generate correct visuals, they suffer from compounding generation errors and fail to leverage even ground-truth visualizations. Our findings suggest that despite their inherent appeal, visual thoughts do not yet benefit model reasoning. MentisOculi establishes the necessary foundation to analyze and close this gap across diverse model families.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86MentisOculi\u8bc4\u4f30\u5957\u4ef6\uff0c\u7528\u4e8e\u6d4b\u8bd5\u591a\u6a21\u6001\u6a21\u578b\u80fd\u5426\u50cf\u4eba\u7c7b\u5fc3\u7406\u610f\u8c61\u4e00\u6837\u4f7f\u7528\u89c6\u89c9\u5316\u4f5c\u4e3a\u63a8\u7406\u8f85\u52a9\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5373\u4f7f\u80fd\u751f\u6210\u6b63\u786e\u89c6\u89c9\u4e5f\u65e0\u6cd5\u6709\u6548\u5229\u7528\u89c6\u89c9\u601d\u7ef4\u8fdb\u884c\u63a8\u7406\u3002", "motivation": "\u968f\u7740\u524d\u6cbf\u6a21\u578b\u4ece\u4ec5\u63a5\u6536\u89c6\u89c9\u4fe1\u606f\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5411\u80fd\u591f\u539f\u751f\u4ea4\u9519\u751f\u6210\u7684\u591a\u6a21\u6001\u6a21\u578b\u8f6c\u53d8\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u4f7f\u7528\u4e2d\u95f4\u89c6\u89c9\u5316\u4f5c\u4e3a\u63a8\u7406\u8f85\u52a9\u7684\u53ef\u80fd\u6027\uff0c\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u7684\u5fc3\u7406\u610f\u8c61\u3002\u6838\u5fc3\u662f\u8bc4\u4f30\u6a21\u578b\u80fd\u5426\u4ee5\u76ee\u6807\u5bfc\u5411\u7684\u65b9\u5f0f\u5f62\u6210\u3001\u7ef4\u62a4\u548c\u64cd\u4f5c\u89c6\u89c9\u8868\u5f81\u3002", "method": "\u5f00\u53d1\u4e86MentisOculi\u2014\u2014\u4e00\u4e2a\u7a0b\u5e8f\u5316\u3001\u5206\u5c42\u7684\u591a\u6b65\u63a8\u7406\u95ee\u9898\u5957\u4ef6\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u6311\u6218\u524d\u6cbf\u6a21\u578b\u3002\u8bc4\u4f30\u4e86\u4ece\u6f5c\u5728\u6807\u8bb0\u5230\u663e\u5f0f\u751f\u6210\u56fe\u50cf\u7b49\u591a\u79cd\u89c6\u89c9\u7b56\u7565\uff0c\u7279\u522b\u5206\u6790\u4e86\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u89c6\u89c9\u7b56\u7565\u901a\u5e38\u65e0\u6cd5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u867d\u7136\u5177\u5907\u89e3\u51b3\u4efb\u52a1\u7684\u6587\u672c\u63a8\u7406\u80fd\u529b\uff0c\u6709\u65f6\u4e5f\u80fd\u751f\u6210\u6b63\u786e\u7684\u89c6\u89c9\u5316\uff0c\u4f46\u5b58\u5728\u7d2f\u79ef\u751f\u6210\u9519\u8bef\u7684\u95ee\u9898\uff0c\u751a\u81f3\u65e0\u6cd5\u6709\u6548\u5229\u7528\u771f\u5b9e\u89c6\u89c9\u5316\u3002\u89c6\u89c9\u601d\u7ef4\u76ee\u524d\u5c1a\u672a\u5bf9\u6a21\u578b\u63a8\u7406\u4ea7\u751f\u76ca\u5904\u3002", "conclusion": "\u5c3d\u7ba1\u89c6\u89c9\u601d\u7ef4\u5177\u6709\u5185\u5728\u5438\u5f15\u529b\uff0c\u4f46\u5f53\u524d\u6a21\u578b\u5c1a\u672a\u80fd\u6709\u6548\u5229\u7528\u89c6\u89c9\u5316\u8fdb\u884c\u63a8\u7406\u3002MentisOculi\u4e3a\u5206\u6790\u548c\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u63d0\u4f9b\u4e86\u5fc5\u8981\u57fa\u7840\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u7684\u7814\u7a76\u3002"}}
{"id": "2602.02470", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02470", "abs": "https://arxiv.org/abs/2602.02470", "authors": ["Xutao Ma", "Yixiao Huang", "Hanlin Zhu", "Somayeh Sojoudi"], "title": "Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge", "comment": null, "summary": "Autoregressive large language models (LLMs) have achieved remarkable success in many complex tasks, yet they can still fail in very simple logical reasoning such as the \"reversal curse\" -- when trained on forward knowledge data of the form \"$A \\rightarrow B$\" (e.g., Alice's husband is Bob), the model is unable to deduce the reversal knowledge \"$B \\leftarrow A$\" (e.g., Bob's wife is Alice) during test. Extensive prior research suggests that this failure is an inherent, fundamental limit of autoregressive causal LLMs, indicating that these models tend to memorize factual-level knowledge rather than capture higher-level rules. In this paper, we challenge this view by showing that this seemingly fundamental limit can be mitigated by slightly tweaking the training data with a simple regularization data recipe called the Identity Bridge of the form \"$A \\to A$\" (e.g., The name of Alice is Alice). Theoretically, we prove that under this recipe, even a one-layer transformer can break the reversal curse by analyzing the implicit bias of gradient descent. Empirically, we show that a 1B pretrained language model finetuned with the proposed data recipe achieves a 40% success rate on reversal tasks, in stark contrast to a near-zero success rate when trained solely on forward-knowledge data. Our work provides a novel theoretical foundation for the reversal curse and offers a principled, low-cost path to encouraging LLMs to learn higher-level rules from data.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u4e86\u81ea\u56de\u5f52LLMs\u5b58\u5728\"\u9006\u8f6c\u8bc5\u5492\"\u8fd9\u4e00\u56fa\u6709\u7f3a\u9677\u7684\u89c2\u70b9\uff0c\u63d0\u51fa\u901a\u8fc7\u6dfb\u52a0\"A\u2192A\"\u5f62\u5f0f\u7684\u8eab\u4efd\u6865\u63a5\u6b63\u5219\u5316\u6570\u636e\uff0c\u53ef\u4ee5\u663e\u8457\u6539\u5584\u6a21\u578b\u5728\u53cd\u5411\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u7b80\u5355\u903b\u8f91\u63a8\u7406\u5982\"\u9006\u8f6c\u8bc5\u5492\"\u4e0a\u4ecd\u4f1a\u5931\u8d25\u3002\u5148\u524d\u7814\u7a76\u8ba4\u4e3a\u8fd9\u662f\u81ea\u56de\u5f52\u56e0\u679cLLMs\u56fa\u6709\u7684\u57fa\u672c\u9650\u5236\uff0c\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u503e\u5411\u4e8e\u8bb0\u5fc6\u4e8b\u5b9e\u7ea7\u77e5\u8bc6\u800c\u975e\u6355\u6349\u9ad8\u7ea7\u89c4\u5219\u3002\u672c\u6587\u65e8\u5728\u6311\u6218\u8fd9\u4e00\u89c2\u70b9\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u7684\u6b63\u5219\u5316\u6570\u636e\u914d\u65b9\u2014\u2014\u8eab\u4efd\u6865\u63a5\uff08Identity Bridge\uff09\uff0c\u5f62\u5f0f\u4e3a\"A\u2192A\"\uff08\u4f8b\u5982\uff1aAlice\u7684\u540d\u5b57\u662fAlice\uff09\u3002\u7406\u8bba\u4e0a\u8bc1\u660e\u5728\u6b64\u914d\u65b9\u4e0b\uff0c\u5373\u4f7f\u5355\u5c42transformer\u4e5f\u80fd\u901a\u8fc7\u5206\u6790\u68af\u5ea6\u4e0b\u964d\u7684\u9690\u5f0f\u504f\u7f6e\u6765\u6253\u7834\u9006\u8f6c\u8bc5\u5492\u3002\u5b9e\u8bc1\u4e0a\uff0c\u572810\u4ebf\u53c2\u6570\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e0a\u5fae\u8c03\u4f7f\u7528\u8be5\u6570\u636e\u914d\u65b9\u3002", "result": "\u4f7f\u7528\u8eab\u4efd\u6865\u63a5\u6570\u636e\u914d\u65b9\u5fae\u8c03\u7684\u6a21\u578b\u5728\u9006\u8f6c\u4efb\u52a1\u4e0a\u8fbe\u523040%\u7684\u6210\u529f\u7387\uff0c\u800c\u4ec5\u4f7f\u7528\u524d\u5411\u77e5\u8bc6\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u6210\u529f\u7387\u63a5\u8fd1\u96f6\u3002\u8fd9\u663e\u8457\u6539\u5584\u4e86\u6a21\u578b\u5728\u53cd\u5411\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u4e3a\u9006\u8f6c\u8bc5\u5492\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u4f4e\u6210\u672c\u8def\u5f84\u6765\u9f13\u52b1LLMs\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u66f4\u9ad8\u7ea7\u7684\u89c4\u5219\uff0c\u6311\u6218\u4e86\u81ea\u56de\u5f52LLMs\u5b58\u5728\u56fa\u6709\u903b\u8f91\u63a8\u7406\u9650\u5236\u7684\u4f20\u7edf\u89c2\u70b9\u3002"}}
