{"id": "2602.02584", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02584", "abs": "https://arxiv.org/abs/2602.02584", "authors": ["Srinivas Rao Marri"], "title": "Constitutional Spec-Driven Development: Enforcing Security by Construction in AI-Assisted Code Generation", "comment": "15 pages, 2 figures, 5 tables, 11 code listings, 14 references. Includes reference implementation and compliance traceability matrix", "summary": "The proliferation of AI-assisted \"vibe coding\" enables rapid software development but introduces significant security risks, as Large Language Models (LLMs) prioritize functional correctness over security. We present Constitutional Spec-Driven Development, a methodology that embeds non-negotiable security principles into the specification layer, ensuring AI-generated code adheres to security requirements by construction rather than inspection. Our approach introduces a Constitution: a versioned, machine-readable document encoding security constraints derived from Common Weakness Enumeration (CWE)/MITRE Top 25 vulnerabilities and regulatory frameworks. We demonstrate the methodology through a banking microservices application, selected as a representative example domain due to its stringent regulatory and security requirements, implementing customer management, account operations, and transaction processing. The methodology itself is domain-agnostic. The implementation addresses 10 critical CWE vulnerabilities through constitutional constraints with full traceability from principles to code locations. Our case study shows that constitutional constraints reduce security defects by 73% compared to unconstrained AI generation while maintaining developer velocity. We contribute a formal framework for constitutional security, a complete development methodology, and empirical evidence that proactive security specification outperforms reactive security verification in AI-assisted development workflows.", "AI": {"tldr": "\u63d0\u51fa\u5baa\u6cd5\u89c4\u8303\u9a71\u52a8\u5f00\u53d1\u65b9\u6cd5\uff0c\u5728AI\u8f85\u52a9\u7f16\u7a0b\u4e2d\u901a\u8fc7\u89c4\u8303\u5c42\u5d4c\u5165\u4e0d\u53ef\u534f\u5546\u7684\u5b89\u5168\u539f\u5219\uff0c\u4f7fAI\u751f\u6210\u4ee3\u7801\u4ece\u6784\u9020\u800c\u975e\u68c0\u67e5\u5c42\u9762\u6ee1\u8db3\u5b89\u5168\u8981\u6c42", "motivation": "AI\u8f85\u52a9\u7684\"\u6c1b\u56f4\u7f16\u7a0b\"\u867d\u7136\u52a0\u901f\u8f6f\u4ef6\u5f00\u53d1\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f18\u5148\u8003\u8651\u529f\u80fd\u6b63\u786e\u6027\u800c\u975e\u5b89\u5168\u6027\uff0c\u5f15\u5165\u4e86\u91cd\u5927\u5b89\u5168\u98ce\u9669", "method": "\u63d0\u51fa\u5baa\u6cd5\u89c4\u8303\u9a71\u52a8\u5f00\u53d1\u65b9\u6cd5\uff0c\u5f15\u5165\u5baa\u6cd5\u6587\u6863\uff1a\u4e00\u4e2a\u7248\u672c\u5316\u3001\u673a\u5668\u53ef\u8bfb\u7684\u6587\u6863\uff0c\u7f16\u7801\u57fa\u4e8eCWE/MITRE Top 25\u6f0f\u6d1e\u548c\u76d1\u7ba1\u6846\u67b6\u7684\u5b89\u5168\u7ea6\u675f", "result": "\u5728\u94f6\u884c\u5fae\u670d\u52a1\u5e94\u7528\u6848\u4f8b\u4e2d\uff0c\u5baa\u6cd5\u7ea6\u675f\u5c06\u5b89\u5168\u7f3a\u9677\u51cf\u5c1173%\uff08\u76f8\u6bd4\u65e0\u7ea6\u675fAI\u751f\u6210\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u5f00\u53d1\u901f\u5ea6\uff1b\u89e3\u51b3\u4e8610\u4e2a\u5173\u952eCWE\u6f0f\u6d1e", "conclusion": "\u4e3b\u52a8\u5b89\u5168\u89c4\u8303\u5728AI\u8f85\u52a9\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\u4f18\u4e8e\u53cd\u5e94\u6027\u5b89\u5168\u9a8c\u8bc1\uff1b\u8d21\u732e\u4e86\u5baa\u6cd5\u5b89\u5168\u7684\u5f62\u5f0f\u6846\u67b6\u3001\u5b8c\u6574\u5f00\u53d1\u65b9\u6cd5\u548c\u5b9e\u8bc1\u8bc1\u636e"}}
{"id": "2602.02569", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02569", "abs": "https://arxiv.org/abs/2602.02569", "authors": ["Haoran Ou", "Kangjie Chen", "Gelei Deng", "Hangcheng Liu", "Jie Zhang", "Tianwei Zhang", "Kwok-Yan Lam"], "title": "DECEIVE-AFC: Adversarial Claim Attacks against Search-Enabled LLM-based Fact-Checking Systems", "comment": null, "summary": "Fact-checking systems with search-enabled large language models (LLMs) have shown strong potential for verifying claims by dynamically retrieving external evidence. However, the robustness of such systems against adversarial attack remains insufficiently understood. In this work, we study adversarial claim attacks against search-enabled LLM-based fact-checking systems under a realistic input-only threat model. We propose DECEIVE-AFC, an agent-based adversarial attack framework that integrates novel claim-level attack strategies and adversarial claim validity evaluation principles. DECEIVE-AFC systematically explores adversarial attack trajectories that disrupt search behavior, evidence retrieval, and LLM-based reasoning without relying on access to evidence sources or model internals. Extensive evaluations on benchmark datasets and real-world systems demonstrate that our attacks substantially degrade verification performance, reducing accuracy from 78.7% to 53.7%, and significantly outperform existing claim-based attack baselines with strong cross-system transferability.", "AI": {"tldr": "DECEIVE-AFC\uff1a\u9488\u5bf9\u641c\u7d22\u589e\u5f3a\u578bLLM\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u5bf9\u6297\u6027\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u5e72\u6270\u641c\u7d22\u884c\u4e3a\u548c\u8bc1\u636e\u68c0\u7d22\u6765\u964d\u4f4e\u9a8c\u8bc1\u51c6\u786e\u6027", "motivation": "\u867d\u7136\u641c\u7d22\u589e\u5f3a\u578b\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u5728\u52a8\u6001\u68c0\u7d22\u5916\u90e8\u8bc1\u636e\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5728\u73b0\u5b9e\u8f93\u5165\u5a01\u80c1\u6a21\u578b\u4e0b\uff0c\u9488\u5bf9\u6b64\u7c7b\u7cfb\u7edf\u7684\u5bf9\u6297\u6027\u58f0\u660e\u653b\u51fb\u3002", "method": "\u63d0\u51faDECEIVE-AFC\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u5bf9\u6297\u653b\u51fb\u6846\u67b6\uff0c\u6574\u5408\u4e86\u65b0\u9896\u7684\u58f0\u660e\u7ea7\u653b\u51fb\u7b56\u7565\u548c\u5bf9\u6297\u6027\u58f0\u660e\u6709\u6548\u6027\u8bc4\u4f30\u539f\u5219\u3002\u8be5\u6846\u67b6\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u5bf9\u6297\u653b\u51fb\u8f68\u8ff9\uff0c\u5728\u4e0d\u4f9d\u8d56\u8bc1\u636e\u6e90\u6216\u6a21\u578b\u5185\u90e8\u8bbf\u95ee\u7684\u60c5\u51b5\u4e0b\uff0c\u5e72\u6270\u641c\u7d22\u884c\u4e3a\u3001\u8bc1\u636e\u68c0\u7d22\u548c\u57fa\u4e8eLLM\u7684\u63a8\u7406\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u548c\u771f\u5b9e\u7cfb\u7edf\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u653b\u51fb\u663e\u8457\u964d\u4f4e\u4e86\u9a8c\u8bc1\u6027\u80fd\uff0c\u5c06\u51c6\u786e\u7387\u4ece78.7%\u964d\u81f353.7%\uff0c\u5e76\u4e14\u5728\u8de8\u7cfb\u7edf\u53ef\u8fc1\u79fb\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u58f0\u660e\u7684\u653b\u51fb\u57fa\u7ebf\u3002", "conclusion": "DECEIVE-AFC\u6846\u67b6\u63ed\u793a\u4e86\u641c\u7d22\u589e\u5f3a\u578bLLM\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u5728\u9762\u5bf9\u5bf9\u6297\u6027\u58f0\u660e\u653b\u51fb\u65f6\u7684\u8106\u5f31\u6027\uff0c\u5f3a\u8c03\u4e86\u63d0\u9ad8\u6b64\u7c7b\u7cfb\u7edf\u9c81\u68d2\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.02515", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02515", "abs": "https://arxiv.org/abs/2602.02515", "authors": ["Yiliang Song", "Hongjun An", "Jiangong Xiao", "Haofei Zhao", "Jiawei Shao", "Xuelong Li"], "title": "CreditAudit: 2$^\\text{nd}$ Dimension for LLM Evaluation and Selection", "comment": "Second update", "summary": "Leaderboard scores on public benchmarks have been steadily rising and converging, with many frontier language models now separated by only marginal differences. However, these scores often fail to match users' day to day experience, because system prompts, output protocols, and interaction modes evolve under routine iteration, and in agentic multi step pipelines small protocol shifts can trigger disproportionate failures, leaving practitioners uncertain about which model to deploy. We propose CreditAudit, a deployment oriented credit audit framework that evaluates models under a family of semantically aligned and non adversarial system prompt templates across multiple benchmarks, reporting mean ability as average performance across scenarios and scenario induced fluctuation sigma as a stability risk signal, and further mapping volatility into interpretable credit grades from AAA to BBB via cross model quantiles with diagnostics that mitigate template difficulty drift. Controlled experiments on GPQA, TruthfulQA, and MMLU Pro show that models with similar mean ability can exhibit substantially different fluctuation, and stability risk can overturn prioritization decisions in agentic or high failure cost regimes. By providing a 2D and grade based language for regime specific selection, CreditAudit supports tiered deployment and more disciplined allocation of testing and monitoring effort, enabling more objective and trustworthy model evaluation for real world use.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCreditAudit\u6846\u67b6\uff0c\u901a\u8fc7\u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u7cfb\u7edf\u63d0\u793a\u6a21\u677f\u4e0b\u7684\u8868\u73b0\u6ce2\u52a8\u6027\uff0c\u63d0\u4f9b\u5e73\u5747\u80fd\u529b\u548c\u7a33\u5b9a\u6027\u98ce\u9669\u7684\u53cc\u7ef4\u5ea6\u8bc4\u4f30\uff0c\u5c06\u6ce2\u52a8\u6027\u8f6c\u6362\u4e3aAAA\u5230BBB\u7684\u4fe1\u7528\u7b49\u7ea7\uff0c\u652f\u6301\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6a21\u578b\u9009\u62e9\u3002", "motivation": "\u5f53\u524d\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u7684\u5206\u6570\u8d8b\u540c\u4e14\u5dee\u5f02\u5fae\u5c0f\uff0c\u4f46\u65e0\u6cd5\u53cd\u6620\u5b9e\u9645\u7528\u6237\u4f53\u9a8c\uff0c\u56e0\u4e3a\u7cfb\u7edf\u63d0\u793a\u3001\u8f93\u51fa\u534f\u8bae\u548c\u4ea4\u4e92\u6a21\u5f0f\u4f1a\u4e0d\u65ad\u8fed\u4ee3\u53d8\u5316\uff0c\u5728\u667a\u80fd\u4f53\u591a\u6b65\u9aa4\u6d41\u7a0b\u4e2d\uff0c\u5c0f\u7684\u534f\u8bae\u53d8\u5316\u53ef\u80fd\u5f15\u53d1\u4e0d\u6210\u6bd4\u4f8b\u7684\u6545\u969c\uff0c\u5bfc\u81f4\u4ece\u4e1a\u8005\u96be\u4ee5\u786e\u5b9a\u90e8\u7f72\u54ea\u4e2a\u6a21\u578b\u3002", "method": "\u63d0\u51faCreditAudit\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u4e00\u7cfb\u5217\u8bed\u4e49\u5bf9\u9f50\u4e14\u975e\u5bf9\u6297\u6027\u7684\u7cfb\u7edf\u63d0\u793a\u6a21\u677f\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u8bc4\u4f30\u6a21\u578b\uff1b2\uff09\u62a5\u544a\u5e73\u5747\u80fd\u529b\uff08\u8de8\u573a\u666f\u5e73\u5747\u6027\u80fd\uff09\u548c\u573a\u666f\u8bf1\u5bfc\u6ce2\u52a8\u03c3\uff08\u7a33\u5b9a\u6027\u98ce\u9669\u4fe1\u53f7\uff09\uff1b3\uff09\u901a\u8fc7\u8de8\u6a21\u578b\u5206\u4f4d\u6570\u5c06\u6ce2\u52a8\u6027\u6620\u5c04\u4e3a\u53ef\u89e3\u91ca\u7684\u4fe1\u7528\u7b49\u7ea7\uff08AAA\u5230BBB\uff09\uff0c\u5e76\u63d0\u4f9b\u8bca\u65ad\u4ee5\u51cf\u8f7b\u6a21\u677f\u96be\u5ea6\u6f02\u79fb\u3002", "result": "\u5728GPQA\u3001TruthfulQA\u548cMMLU Pro\u4e0a\u7684\u63a7\u5236\u5b9e\u9a8c\u663e\u793a\uff0c\u5177\u6709\u76f8\u4f3c\u5e73\u5747\u80fd\u529b\u7684\u6a21\u578b\u53ef\u80fd\u8868\u73b0\u51fa\u663e\u8457\u4e0d\u540c\u7684\u6ce2\u52a8\u6027\uff0c\u7a33\u5b9a\u6027\u98ce\u9669\u5728\u667a\u80fd\u4f53\u6216\u9ad8\u6545\u969c\u6210\u672c\u573a\u666f\u4e2d\u53ef\u4ee5\u63a8\u7ffb\u4f18\u5148\u7ea7\u51b3\u7b56\u3002", "conclusion": "CreditAudit\u901a\u8fc7\u63d0\u4f9b\u57fa\u4e8e\u4e8c\u7ef4\u8bc4\u4f30\u548c\u4fe1\u7528\u7b49\u7ea7\u7684\u8bed\u8a00\uff0c\u652f\u6301\u7279\u5b9a\u573a\u666f\u4e0b\u7684\u6a21\u578b\u9009\u62e9\u3001\u5206\u5c42\u90e8\u7f72\uff0c\u4ee5\u53ca\u66f4\u89c4\u8303\u7684\u6d4b\u8bd5\u548c\u76d1\u63a7\u8d44\u6e90\u5206\u914d\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u66f4\u5ba2\u89c2\u548c\u53ef\u4fe1\u7684\u6a21\u578b\u8bc4\u4f30\u3002"}}
{"id": "2602.02752", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02752", "abs": "https://arxiv.org/abs/2602.02752", "authors": ["Srinath Srinivasan", "Tim Menzies"], "title": "Beyond the Prompt: Assessing Domain Knowledge Strategies for High-Dimensional LLM Optimization in Software Engineering", "comment": "Accepted at MSR 2026 (Registered Reports Track)", "summary": "Background/Context: Large Language Models (LLMs) demonstrate strong performance on low-dimensional software engineering optimization tasks ($\\le$11 features) but consistently underperform on high-dimensional problems where Bayesian methods dominate. A fundamental gap exists in understanding how systematic integration of domain knowledge (whether from humans or automated reasoning) can bridge this divide.\n  Objective/Aim: We compare human versus artificial intelligence strategies for generating domain knowledge. We systematically evaluate four distinct architectures to determine if structured knowledge integration enables LLMs to generate effective warm starts for high-dimensional optimization.\n  Method: We evaluate four approaches on MOOT datasets stratified by dimensionality: (1) Human-in-the-Loop Domain Knowledge Prompting (H-DKP), utilizing asynchronous expert feedback loops; (2) Adaptive Multi-Stage Prompting (AMP), implementing sequential constraint identification and validation; (3) Dimension-Aware Progressive Refinement (DAPR), conducting optimization in progressively expanding feature subspaces; and (4) Hybrid Knowledge-Model Approach (HKMA), synthesizing statistical scouting (TPE) with RAG-enhanced prompting. Performance is quantified via Chebyshev distance to optimal solutions and ranked using Scott-Knott clustering against an established baseline for LLM generated warm starts.\n  Note that all human studies conducted as part of this study will comply with the policies of our local Institutional Review Board.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u4eba\u7c7b\u4e0e\u4eba\u5de5\u667a\u80fd\u751f\u6210\u9886\u57df\u77e5\u8bc6\u7684\u65b9\u6cd5\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u67b6\u6784\uff0c\u65e8\u5728\u901a\u8fc7\u7ed3\u6784\u5316\u77e5\u8bc6\u96c6\u6210\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u4e3a\u9ad8\u7ef4\u4f18\u5316\u95ee\u9898\u751f\u6210\u6709\u6548\u7684\u70ed\u542f\u52a8\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u7ef4\u8f6f\u4ef6\u5de5\u7a0b\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9ad8\u7ef4\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u8d1d\u53f6\u65af\u65b9\u6cd5\u5728\u9ad8\u7ef4\u95ee\u9898\u4e0a\u5360\u4e3b\u5bfc\u5730\u4f4d\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u7cfb\u7edf\u96c6\u6210\u9886\u57df\u77e5\u8bc6\u6765\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u5728MOOT\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u56db\u79cd\u65b9\u6cd5\uff1a(1)\u4eba\u7c7b\u5728\u73af\u9886\u57df\u77e5\u8bc6\u63d0\u793a\uff0c(2)\u81ea\u9002\u5e94\u591a\u9636\u6bb5\u63d0\u793a\uff0c(3)\u7ef4\u5ea6\u611f\u77e5\u6e10\u8fdb\u7ec6\u5316\uff0c(4)\u6df7\u5408\u77e5\u8bc6\u6a21\u578b\u65b9\u6cd5\u3002\u901a\u8fc7\u5207\u6bd4\u96ea\u592b\u8ddd\u79bb\u548cScott-Knott\u805a\u7c7b\u8fdb\u884c\u6027\u80fd\u91cf\u5316\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u7ed9\u51fa\uff0c\u4f46\u7814\u7a76\u65b9\u6cd5\u8868\u660e\u5c06\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u6765\u786e\u5b9a\u54ea\u79cd\u77e5\u8bc6\u96c6\u6210\u7b56\u7565\u80fd\u591f\u4f7fLLM\u5728\u9ad8\u7ef4\u4f18\u5316\u4e2d\u751f\u6210\u6709\u6548\u7684\u70ed\u542f\u52a8\u3002", "conclusion": "\u8be5\u7814\u7a76\u65e8\u5728\u786e\u5b9a\u7ed3\u6784\u5316\u77e5\u8bc6\u96c6\u6210\u662f\u5426\u80fd\u591f\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u7ef4\u4f18\u5316\u95ee\u9898\u4e2d\u751f\u6210\u6709\u6548\u7684\u70ed\u542f\u52a8\uff0c\u5e76\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u4eba\u5de5\u667a\u80fd\u751f\u6210\u9886\u57df\u77e5\u8bc6\u7684\u7b56\u7565\u3002"}}
{"id": "2602.02602", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02602", "abs": "https://arxiv.org/abs/2602.02602", "authors": ["Yangfan Deng", "Anirudh Nakra", "Min Wu"], "title": "Position: 3D Gaussian Splatting Watermarking Should Be Scenario-Driven and Threat-Model Explicit", "comment": null, "summary": "3D content acquisition and creation are expanding rapidly in the new era of machine learning and AI. 3D Gaussian Splatting (3DGS) has become a promising high-fidelity and real-time representation for 3D content. Similar to the initial wave of digital audio-visual content at the turn of the millennium, the demand for intellectual property protection is also increasing, since explicit and editable 3D parameterization makes unauthorized use and dissemination easier. In this position paper, we argue that effective progress in watermarking 3D assets requires articulated security objectives and realistic threat models, incorporating the lessons learned from digital audio-visual asset protection over the past decades. To address this gap in security specification and evaluation, we advocate a scenario-driven formulation, in which adversarial capabilities are formalized through a security model. Based on this formulation, we construct a reference framework that organizes existing methods and clarifies how specific design choices map to corresponding adversarial assumptions. Within this framework, we also examine a legacy spread-spectrum embedding scheme, characterizing its advantages and limitations and highlighting the important trade-offs it entails. Overall, this work aims to foster effective intellectual property protection for 3D assets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3b\u5f20\u4e3a3D\u8d44\u4ea7\u6c34\u5370\u5236\u5b9a\u660e\u786e\u7684\u5b89\u5168\u76ee\u6807\u548c\u5a01\u80c1\u6a21\u578b\uff0c\u501f\u9274\u6570\u5b57\u97f3\u89c6\u9891\u8d44\u4ea7\u4fdd\u62a4\u7ecf\u9a8c\uff0c\u63d0\u51fa\u57fa\u4e8e\u573a\u666f\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u968f\u77403D\u5185\u5bb9\u83b7\u53d6\u548c\u521b\u5efa\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u7279\u522b\u662f3D\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u7684\u51fa\u73b0\uff0c3D\u8d44\u4ea7\u7684\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u9700\u6c42\u65e5\u76ca\u589e\u957f\u3002\u7531\u4e8e3D\u53c2\u6570\u5316\u7684\u663e\u5f0f\u548c\u53ef\u7f16\u8f91\u7279\u6027\uff0c\u672a\u7ecf\u6388\u6743\u7684\u4f7f\u7528\u548c\u4f20\u64ad\u53d8\u5f97\u66f4\u52a0\u5bb9\u6613\uff0c\u9700\u8981\u6709\u6548\u7684\u4fdd\u62a4\u673a\u5236\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u573a\u666f\u7684\u5236\u5b9a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b89\u5168\u6a21\u578b\u5f62\u5f0f\u5316\u5bf9\u6297\u80fd\u529b\u3002\u6784\u5efa\u4e86\u4e00\u4e2a\u53c2\u8003\u6846\u67b6\u6765\u7ec4\u7ec7\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u9610\u660e\u7279\u5b9a\u8bbe\u8ba1\u9009\u62e9\u5982\u4f55\u6620\u5c04\u5230\u76f8\u5e94\u7684\u5bf9\u6297\u5047\u8bbe\u3002\u5728\u8be5\u6846\u67b6\u5185\uff0c\u8fd8\u5206\u6790\u4e86\u4e00\u4e2a\u4f20\u7edf\u7684\u6269\u9891\u5d4c\u5165\u65b9\u6848\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u5b89\u5168\u89c4\u8303\u6846\u67b6\uff0c\u80fd\u591f\u8bc4\u4f30\u73b0\u67093D\u8d44\u4ea7\u6c34\u5370\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bc6\u522b\u4f20\u7edf\u6269\u9891\u5d4c\u5165\u65b9\u6848\u7684\u4f18\u52bf\u3001\u5c40\u9650\u6027\u548c\u91cd\u8981\u6743\u8861\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u65e8\u5728\u4fc3\u8fdb3D\u8d44\u4ea7\u7684\u6709\u6548\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\uff0c\u5f3a\u8c03\u9700\u8981\u660e\u786e\u7684\u5b89\u5168\u76ee\u6807\u548c\u73b0\u5b9e\u7684\u5a01\u80c1\u6a21\u578b\uff0c\u4e3a\u672a\u67653D\u6c34\u5370\u6280\u672f\u7684\u53d1\u5c55\u63d0\u4f9b\u6307\u5bfc\u6846\u67b6\u3002"}}
{"id": "2602.02582", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.IR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02582", "abs": "https://arxiv.org/abs/2602.02582", "authors": ["Chandan Kumar Sah", "Xiaoli Lian", "Li Zhang", "Tony Xu", "Syed Shazaib Shah"], "title": "Uncertainty and Fairness Awareness in LLM-Based Recommendation Systems", "comment": "Accepted at the Second Conference of the International Association for Safe and Ethical Artificial Intelligence, IASEAI26, 14 pages", "summary": "Large language models (LLMs) enable powerful zero-shot recommendations by leveraging broad contextual knowledge, yet predictive uncertainty and embedded biases threaten reliability and fairness. This paper studies how uncertainty and fairness evaluations affect the accuracy, consistency, and trustworthiness of LLM-generated recommendations. We introduce a benchmark of curated metrics and a dataset annotated for eight demographic attributes (31 categorical values) across two domains: movies and music. Through in-depth case studies, we quantify predictive uncertainty (via entropy) and demonstrate that Google DeepMind's Gemini 1.5 Flash exhibits systematic unfairness for certain sensitive attributes; measured similarity-based gaps are SNSR at 0.1363 and SNSV at 0.0507. These disparities persist under prompt perturbations such as typographical errors and multilingual inputs. We further integrate personality-aware fairness into the RecLLM evaluation pipeline to reveal personality-linked bias patterns and expose trade-offs between personalization and group fairness. We propose a novel uncertainty-aware evaluation methodology for RecLLMs, present empirical insights from deep uncertainty case studies, and introduce a personality profile-informed fairness benchmark that advances explainability and equity in LLM recommendations. Together, these contributions establish a foundation for safer, more interpretable RecLLMs and motivate future work on multi-model benchmarks and adaptive calibration for trustworthy deployment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u63a8\u8350\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u516c\u5e73\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5305\u542b\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u548c\u4eba\u683c\u611f\u77e5\u516c\u5e73\u6027\u7684\u65b0\u8bc4\u6d4b\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86Gemini 1.5 Flash\u5728\u654f\u611f\u5c5e\u6027\u4e0a\u7684\u7cfb\u7edf\u6027\u4e0d\u516c\u5e73\u73b0\u8c61\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u80fd\u591f\u63d0\u4f9b\u5f3a\u5927\u7684\u96f6\u6837\u672c\u63a8\u8350\u80fd\u529b\uff0c\u4f46\u5176\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u548c\u5185\u5728\u504f\u89c1\u5a01\u80c1\u7740\u63a8\u8350\u7684\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\u3002\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30LLM\u63a8\u8350\u4e2d\u4e0d\u786e\u5b9a\u6027\u548c\u516c\u5e73\u6027\u7684\u65b9\u6cd5\uff0c\u9700\u8981\u5efa\u7acb\u66f4\u5168\u9762\u7684\u8bc4\u6d4b\u6846\u67b6\u3002", "method": "1. \u6784\u5efa\u5305\u542b\u7535\u5f71\u548c\u97f3\u4e50\u4e24\u4e2a\u9886\u57df\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6807\u6ce8\u4e868\u4e2a\u4eba\u53e3\u7edf\u8ba1\u5b66\u5c5e\u6027\uff0831\u4e2a\u5206\u7c7b\u503c\uff09\n2. \u5f15\u5165\u5305\u542b\u71b5\u5ea6\u91cf\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u65b9\u6cd5\n3. \u8bbe\u8ba1\u5305\u542b\u62fc\u5199\u9519\u8bef\u548c\u591a\u8bed\u8a00\u8f93\u5165\u7684\u63d0\u793a\u6270\u52a8\u5b9e\u9a8c\n4. \u5c06\u4eba\u683c\u611f\u77e5\u516c\u5e73\u6027\u6574\u5408\u5230RecLLM\u8bc4\u4f30\u6d41\u7a0b\u4e2d\n5. \u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684RecLLM\u8bc4\u4f30\u65b9\u6cd5\u5b66", "result": "1. Google DeepMind\u7684Gemini 1.5 Flash\u5bf9\u67d0\u4e9b\u654f\u611f\u5c5e\u6027\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u4e0d\u516c\u5e73\uff0c\u76f8\u4f3c\u6027\u5dee\u8ddd\u6307\u6807SNSR\u4e3a0.1363\uff0cSNSV\u4e3a0.0507\n2. \u8fd9\u4e9b\u4e0d\u516c\u5e73\u73b0\u8c61\u5728\u63d0\u793a\u6270\u52a8\uff08\u5982\u62fc\u5199\u9519\u8bef\u548c\u591a\u8bed\u8a00\u8f93\u5165\uff09\u4e0b\u4ecd\u7136\u6301\u7eed\u5b58\u5728\n3. \u63ed\u793a\u4e86\u4eba\u683c\u7279\u5f81\u4e0e\u504f\u89c1\u6a21\u5f0f\u4e4b\u95f4\u7684\u5173\u8054\n4. \u66b4\u9732\u4e86\u4e2a\u6027\u5316\u63a8\u8350\u4e0e\u7fa4\u4f53\u516c\u5e73\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u66f4\u5b89\u5168\u3001\u66f4\u53ef\u89e3\u91ca\u7684RecLLM\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u51fa\u4e86\u5305\u542b\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u548c\u4eba\u683c\u611f\u77e5\u516c\u5e73\u6027\u7684\u65b0\u8bc4\u6d4b\u6846\u67b6\uff0c\u63a8\u52a8\u4e86LLM\u63a8\u8350\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u548c\u53ef\u4fe1\u5ea6\u7814\u7a76\uff0c\u5e76\u6fc0\u52b1\u672a\u6765\u5728\u591a\u6a21\u578b\u57fa\u51c6\u548c\u81ea\u9002\u5e94\u6821\u51c6\u65b9\u9762\u7684\u5de5\u4f5c\u3002"}}
{"id": "2602.02881", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02881", "abs": "https://arxiv.org/abs/2602.02881", "authors": ["Arshad Beg", "Diarmuid O'Donoghue", "Rosemary Monahan"], "title": "Learning-Infused Formal Reasoning: From Contract Synthesis to Artifact Reuse and Formal Semantics", "comment": "18 pages. Accepted at VERIFAI-2026: The Interplay between Artificial Intelligence and Software Verification LASER center, Villebrumier, France, March 8-11, 2026", "summary": "This vision paper articulates a long-term research agenda for formal methods at the intersection with artificial intelligence, outlining multiple conceptual and technical dimensions and reporting on our ongoing work toward realising this agenda. It advances a forward-looking perspective on the next generation of formal methods based on the integration of automated contract synthesis, semantic artifact reuse, and refinement-based theory. We argue that future verification systems must move beyond isolated correctness proofs toward a cumulative, knowledge-driven paradigm in which specifications, contracts, and proofs are continuously synthesised and transferred across systems. To support this shift, we outline a hybrid framework combining large language models with graph-based representations to enable scalable semantic matching and principled reuse of verification artifacts. Learning-based components provide semantic guidance across heterogeneous notations and abstraction levels, while symbolic matching ensures formal soundness. Grounded in compositional reasoning, this vision points toward verification ecosystems that evolve systematically, leveraging past verification efforts to accelerate future assurance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u5f62\u5f0f\u5316\u65b9\u6cd5\u4e0e\u4eba\u5de5\u667a\u80fd\u7ed3\u5408\u7684\u957f\u671f\u7814\u7a76\u8bae\u7a0b\uff0c\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u5408\u7ea6\u5408\u6210\u3001\u8bed\u4e49\u6784\u4ef6\u590d\u7528\u548c\u7cbe\u5316\u7406\u8bba\u6784\u5efa\u4e0b\u4e00\u4ee3\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4ece\u5b64\u7acb\u8bc1\u660e\u5411\u7d2f\u79ef\u77e5\u8bc6\u9a71\u52a8\u8303\u5f0f\u7684\u8f6c\u53d8\u3002", "motivation": "\u5f53\u524d\u5f62\u5f0f\u5316\u65b9\u6cd5\u9762\u4e34\u5b64\u7acb\u9a8c\u8bc1\u3001\u91cd\u590d\u5de5\u4f5c\u548c\u77e5\u8bc6\u65e0\u6cd5\u6709\u6548\u79ef\u7d2f\u7684\u95ee\u9898\u3002\u9700\u8981\u8d85\u8d8a\u5355\u4e00\u7684\u6b63\u786e\u6027\u8bc1\u660e\uff0c\u5efa\u7acb\u80fd\u591f\u6301\u7eed\u5408\u6210\u3001\u8f6c\u79fb\u548c\u590d\u7528\u89c4\u8303\u3001\u5408\u7ea6\u53ca\u8bc1\u660e\u7684\u7d2f\u79ef\u6027\u77e5\u8bc6\u9a71\u52a8\u8303\u5f0f\uff0c\u4ee5\u52a0\u901f\u7cfb\u7edf\u9a8c\u8bc1\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u56fe\u8868\u793a\u6765\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u8bed\u4e49\u5339\u914d\u548c\u9a8c\u8bc1\u6784\u4ef6\u7684\u539f\u5219\u6027\u590d\u7528\u3002\u5b66\u4e60\u7ec4\u4ef6\u63d0\u4f9b\u8de8\u5f02\u6784\u8868\u793a\u548c\u62bd\u8c61\u5c42\u6b21\u7684\u8bed\u4e49\u6307\u5bfc\uff0c\u7b26\u53f7\u5339\u914d\u786e\u4fdd\u5f62\u5f0f\u6b63\u786e\u6027\uff0c\u57fa\u4e8e\u7ec4\u5408\u63a8\u7406\u6784\u5efa\u53ef\u6f14\u8fdb\u7684\u9a8c\u8bc1\u751f\u6001\u7cfb\u7edf\u3002", "result": "\u672c\u6587\u4e3b\u8981\u63d0\u51fa\u7814\u7a76\u613f\u666f\u548c\u6846\u67b6\u6982\u5ff5\uff0c\u672a\u62a5\u544a\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\u3002\u4f46\u63cf\u8ff0\u4e86\u6b63\u5728\u8fdb\u884c\u7684\u5b9e\u73b0\u8be5\u8bae\u7a0b\u7684\u5de5\u4f5c\uff0c\u5e76\u8bba\u8bc1\u4e86\u8be5\u6846\u67b6\u80fd\u591f\u652f\u6301\u9a8c\u8bc1\u751f\u6001\u7cfb\u7edf\u7684\u7cfb\u7edf\u6027\u6f14\u8fdb\uff0c\u5229\u7528\u8fc7\u53bb\u7684\u9a8c\u8bc1\u6210\u679c\u52a0\u901f\u672a\u6765\u7684\u4fdd\u8bc1\u8fc7\u7a0b\u3002", "conclusion": "\u4e0b\u4e00\u4ee3\u5f62\u5f0f\u5316\u65b9\u6cd5\u9700\u8981\u6574\u5408AI\u6280\u672f\uff0c\u5efa\u7acb\u77e5\u8bc6\u9a71\u52a8\u7684\u7d2f\u79ef\u9a8c\u8bc1\u8303\u5f0f\u3002\u901a\u8fc7\u8bed\u4e49\u6784\u4ef6\u590d\u7528\u548c\u81ea\u52a8\u5408\u7ea6\u5408\u6210\uff0c\u53ef\u4ee5\u6784\u5efa\u80fd\u591f\u6301\u7eed\u6f14\u8fdb\u3001\u5229\u7528\u5386\u53f2\u9a8c\u8bc1\u77e5\u8bc6\u7684\u9a8c\u8bc1\u751f\u6001\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u9ad8\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2602.02896", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02896", "abs": "https://arxiv.org/abs/2602.02896", "authors": ["Jianru Shen", "Zedong Peng", "Lucy Owen"], "title": "Failure-Aware Enhancements for Large Language Model (LLM) Code Generation: An Empirical Study on Decision Framework", "comment": "Accepted at SANER 2026", "summary": "Large language models (LLMs) show promise for automating software development by translating requirements into code. However, even advanced prompting workflows like progressive prompting often leave some requirements unmet. Although methods such as self-critique, multi-model collaboration, and retrieval-augmented generation (RAG) have been proposed to address these gaps, developers lack clear guidance on when to use each. In an empirical study of 25 GitHub projects, we found that progressive prompting achieves 96.9% average task completion, significantly outperforming direct prompting (80.5%, Cohen's d=1.63, p<0.001) but still leaving 8 projects incomplete. For 6 of the most representative projects, we evaluated each enhancement strategy across 4 failure types. Our results reveal that method effectiveness depends critically on failure characteristics: Self-Critique succeeds on code-reviewable logic errors but fails completely on external service integration (0% improvement), while RAG achieves highest completion across all failure types with superior efficiency. Based on these findings, we propose a decision framework that maps each failure pattern to the most suitable enhancement method, giving practitioners practical, data-driven guidance instead of trial-and-error.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u6e10\u8fdb\u63d0\u793a\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u8fbe\u523096.9%\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u4f46\u4ecd\u5b58\u5728\u672a\u6ee1\u8db3\u9700\u6c42\u3002\u4e0d\u540c\u589e\u5f3a\u7b56\u7565\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u5931\u8d25\u6548\u679c\u4e0d\u540c\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u57fa\u4e8e\u5931\u8d25\u6a21\u5f0f\u7684\u51b3\u7b56\u6846\u67b6\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u5373\u4f7f\u4f7f\u7528\u6e10\u8fdb\u63d0\u793a\u7b49\u9ad8\u7ea7\u5de5\u4f5c\u6d41\uff0c\u4ecd\u6709\u4e00\u4e9b\u9700\u6c42\u65e0\u6cd5\u6ee1\u8db3\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u81ea\u6211\u6279\u8bc4\u3001\u591a\u6a21\u578b\u534f\u4f5c\u548cRAG\u7f3a\u4e4f\u660e\u786e\u7684\u6307\u5bfc\u539f\u5219\uff0c\u5f00\u53d1\u8005\u4e0d\u77e5\u9053\u4f55\u65f6\u4f7f\u7528\u54ea\u79cd\u65b9\u6cd5\u3002", "method": "\u5bf925\u4e2aGitHub\u9879\u76ee\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u6bd4\u8f83\u6e10\u8fdb\u63d0\u793a\u4e0e\u76f4\u63a5\u63d0\u793a\u7684\u6548\u679c\u3002\u9488\u5bf96\u4e2a\u6700\u5177\u4ee3\u8868\u6027\u7684\u9879\u76ee\uff0c\u8bc4\u4f30\u56db\u79cd\u589e\u5f3a\u7b56\u7565\uff08\u81ea\u6211\u6279\u8bc4\u3001\u591a\u6a21\u578b\u534f\u4f5c\u3001RAG\u7b49\uff09\u5728\u56db\u79cd\u5931\u8d25\u7c7b\u578b\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u6e10\u8fdb\u63d0\u793a\u5e73\u5747\u4efb\u52a1\u5b8c\u6210\u7387\u8fbe\u523096.9%\uff0c\u663e\u8457\u4f18\u4e8e\u76f4\u63a5\u63d0\u793a\uff0880.5%\uff09\uff0c\u4f46\u4ecd\u4f7f8\u4e2a\u9879\u76ee\u4e0d\u5b8c\u6574\u3002\u4e0d\u540c\u65b9\u6cd5\u6548\u679c\u53d6\u51b3\u4e8e\u5931\u8d25\u7279\u5f81\uff1a\u81ea\u6211\u6279\u8bc4\u5bf9\u53ef\u4ee3\u7801\u5ba1\u67e5\u7684\u903b\u8f91\u9519\u8bef\u6709\u6548\uff0c\u4f46\u5bf9\u5916\u90e8\u670d\u52a1\u96c6\u6210\u5b8c\u5168\u65e0\u6548\uff080%\u6539\u8fdb\uff09\uff1bRAG\u5728\u6240\u6709\u5931\u8d25\u7c7b\u578b\u4e0a\u5b9e\u73b0\u6700\u9ad8\u5b8c\u6210\u7387\u4e14\u6548\u7387\u6700\u4f18\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u51b3\u7b56\u6846\u67b6\uff0c\u5c06\u6bcf\u79cd\u5931\u8d25\u6a21\u5f0f\u6620\u5c04\u5230\u6700\u5408\u9002\u7684\u589e\u5f3a\u65b9\u6cd5\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u5b9e\u7528\u3001\u6570\u636e\u9a71\u52a8\u7684\u6307\u5bfc\uff0c\u800c\u4e0d\u662f\u8bd5\u9519\u3002"}}
{"id": "2602.02615", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02615", "abs": "https://arxiv.org/abs/2602.02615", "authors": ["Ali Mahdavi", "Santa Aghapour", "Azadeh Zamanifar", "Amirfarhad Farhadi"], "title": "TinyGuard:A lightweight Byzantine Defense for Resource-Constrained Federated Learning via Statistical Update Fingerprints", "comment": null, "summary": "Existing Byzantine robust aggregation mechanisms typically rely on fulldimensional gradi ent comparisons or pairwise distance computations, resulting in computational overhead that limits applicability in large scale and resource constrained federated systems. This paper proposes TinyGuard, a lightweight Byzantine defense that augments the standard FedAvg algorithm via statistical update f ingerprinting. Instead of operating directly on high-dimensional gradients, TinyGuard extracts compact statistical fingerprints cap turing key behavioral properties of client updates, including norm statistics, layer-wise ratios, sparsity measures, and low-order mo ments. Byzantine clients are identified by measuring robust sta tistical deviations in this low-dimensional fingerprint space with nd complexity, without modifying the underlying optimization procedure. Extensive experiments on MNIST, Fashion-MNIST, ViT-Lite, and ViT-Small with LoRA adapters demonstrate that TinyGuard pre serves FedAvg convergence in benign settings and achieves up to 95 percent accuracy under multiple Byzantine attack scenarios, including sign-flipping, scaling, noise injection, and label poisoning. Against adaptive white-box adversaries, Pareto frontier analysis across four orders of magnitude confirms that attackers cannot simultaneously evade detection and achieve effective poisoning, features we term statistical handcuffs. Ablation studies validate stable detection precision 0.8 across varying client counts (50-150), threshold parameters and extreme data heterogeneity . The proposed framework is architecture-agnostic and well-suited for federated fine-tuning of foundation models where traditional Byzantine defenses become impractical", "AI": {"tldr": "TinyGuard\uff1a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u62dc\u5360\u5ead\u9632\u5fa1\u673a\u5236\uff0c\u901a\u8fc7\u7edf\u8ba1\u66f4\u65b0\u6307\u7eb9\u589e\u5f3aFedAvg\u7b97\u6cd5\uff0c\u5728\u4f4e\u7ef4\u6307\u7eb9\u7a7a\u95f4\u4e2d\u68c0\u6d4b\u6076\u610f\u5ba2\u6237\u7aef\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e3aO(n)\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u8054\u90a6\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u62dc\u5360\u5ead\u9c81\u68d2\u805a\u5408\u673a\u5236\u901a\u5e38\u4f9d\u8d56\u5168\u7ef4\u5ea6\u68af\u5ea6\u6bd4\u8f83\u6216\u6210\u5bf9\u8ddd\u79bb\u8ba1\u7b97\uff0c\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u9650\u5236\u4e86\u5728\u5927\u89c4\u6a21\u548c\u8d44\u6e90\u53d7\u9650\u7684\u8054\u90a6\u7cfb\u7edf\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "TinyGuard\u4ece\u9ad8\u7ef4\u68af\u5ea6\u4e2d\u63d0\u53d6\u7d27\u51d1\u7684\u7edf\u8ba1\u6307\u7eb9\uff0c\u6355\u6349\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u5173\u952e\u884c\u4e3a\u5c5e\u6027\uff08\u5305\u62ec\u8303\u6570\u7edf\u8ba1\u3001\u5206\u5c42\u6bd4\u7387\u3001\u7a00\u758f\u6027\u5ea6\u91cf\u548c\u4f4e\u9636\u77e9\uff09\uff0c\u5728\u4f4e\u7ef4\u6307\u7eb9\u7a7a\u95f4\u4e2d\u6d4b\u91cf\u7edf\u8ba1\u504f\u5dee\u6765\u8bc6\u522b\u62dc\u5360\u5ead\u5ba2\u6237\u7aef\u3002", "result": "\u5728MNIST\u3001Fashion-MNIST\u3001ViT-Lite\u548cViT-Small\u7b49\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTinyGuard\u5728\u826f\u6027\u8bbe\u7f6e\u4e0b\u4fdd\u6301FedAvg\u6536\u655b\uff0c\u5728\u591a\u79cd\u62dc\u5360\u5ead\u653b\u51fb\u573a\u666f\u4e0b\u8fbe\u523095%\u51c6\u786e\u7387\u3002\u5bf9\u6297\u81ea\u9002\u5e94\u767d\u76d2\u653b\u51fb\u65f6\uff0c\u653b\u51fb\u8005\u65e0\u6cd5\u540c\u65f6\u9003\u907f\u68c0\u6d4b\u548c\u5b9e\u73b0\u6709\u6548\u6295\u6bd2\u3002", "conclusion": "TinyGuard\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u67b6\u6784\u65e0\u5173\u7684\u62dc\u5360\u5ead\u9632\u5fa1\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f20\u7edf\u9632\u5fa1\u673a\u5236\u4e0d\u5207\u5b9e\u9645\u7684\u8054\u90a6\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u573a\u666f\u3002"}}
{"id": "2602.02639", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02639", "abs": "https://arxiv.org/abs/2602.02639", "authors": ["Harry Mayne", "Justin Singh Kang", "Dewi Gould", "Kannan Ramchandran", "Adam Mahdi", "Noah Y. Siegel"], "title": "A Positive Case for Faithfulness: LLM Self-Explanations Help Predict Model Behavior", "comment": null, "summary": "LLM self-explanations are often presented as a promising tool for AI oversight, yet their faithfulness to the model's true reasoning process is poorly understood. Existing faithfulness metrics have critical limitations, typically relying on identifying unfaithfulness via adversarial prompting or detecting reasoning errors. These methods overlook the predictive value of explanations. We introduce Normalized Simulatability Gain (NSG), a general and scalable metric based on the idea that a faithful explanation should allow an observer to learn a model's decision-making criteria, and thus better predict its behavior on related inputs. We evaluate 18 frontier proprietary and open-weight models, e.g., Gemini 3, GPT-5.2, and Claude 4.5, on 7,000 counterfactuals from popular datasets covering health, business, and ethics. We find self-explanations substantially improve prediction of model behavior (11-37% NSG). Self-explanations also provide more predictive information than explanations generated by external models, even when those models are stronger. This implies an advantage from self-knowledge that external explanation methods cannot replicate. Our approach also reveals that, across models, 5-15% of self-explanations are egregiously misleading. Despite their imperfections, we show a positive case for self-explanations: they encode information that helps predict model behavior.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Normalized Simulatability Gain (NSG)\u4f5c\u4e3a\u8861\u91cfLLM\u81ea\u6211\u89e3\u91ca\u5fe0\u5b9e\u5ea6\u7684\u65b0\u6307\u6807\uff0c\u53d1\u73b0\u81ea\u6211\u89e3\u91ca\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u884c\u4e3a\u9884\u6d4b\u80fd\u529b(11-37% NSG)\uff0c\u4f46\u4ecd\u67095-15%\u7684\u81ea\u6211\u89e3\u91ca\u5177\u6709\u4e25\u91cd\u8bef\u5bfc\u6027\u3002", "motivation": "\u73b0\u6709LLM\u81ea\u6211\u89e3\u91ca\u7684\u5fe0\u5b9e\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u4e3b\u8981\u4f9d\u8d56\u5bf9\u6297\u6027\u63d0\u793a\u6216\u68c0\u6d4b\u63a8\u7406\u9519\u8bef\uff0c\u5ffd\u89c6\u4e86\u89e3\u91ca\u7684\u9884\u6d4b\u4ef7\u503c\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u3001\u53ef\u6269\u5c55\u7684\u6307\u6807\u6765\u8bc4\u4f30\u89e3\u91ca\u662f\u5426\u771f\u6b63\u53cd\u6620\u4e86\u6a21\u578b\u7684\u771f\u5b9e\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faNormalized Simulatability Gain (NSG)\u6307\u6807\uff0c\u57fa\u4e8e\"\u5fe0\u5b9e\u89e3\u91ca\u5e94\u80fd\u8ba9\u89c2\u5bdf\u8005\u5b66\u4e60\u6a21\u578b\u7684\u51b3\u7b56\u6807\u51c6\uff0c\u4ece\u800c\u66f4\u597d\u9884\u6d4b\u5176\u5728\u76f8\u5173\u8f93\u5165\u4e0a\u7684\u884c\u4e3a\"\u7684\u7406\u5ff5\u3002\u572818\u4e2a\u524d\u6cbf\u4e13\u6709\u548c\u5f00\u6e90\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528\u6765\u81ea\u5065\u5eb7\u3001\u5546\u4e1a\u548c\u4f26\u7406\u9886\u57df\u76847,000\u4e2a\u53cd\u4e8b\u5b9e\u6570\u636e\u3002", "result": "\u81ea\u6211\u89e3\u91ca\u663e\u8457\u63d0\u5347\u6a21\u578b\u884c\u4e3a\u9884\u6d4b\u80fd\u529b(11-37% NSG)\uff1b\u81ea\u6211\u89e3\u91ca\u6bd4\u5916\u90e8\u6a21\u578b\u751f\u6210\u7684\u89e3\u91ca\u63d0\u4f9b\u66f4\u591a\u9884\u6d4b\u4fe1\u606f\uff0c\u5373\u4f7f\u5916\u90e8\u6a21\u578b\u66f4\u5f3a\uff1b\u6240\u6709\u6a21\u578b\u4e2d5-15%\u7684\u81ea\u6211\u89e3\u91ca\u5177\u6709\u4e25\u91cd\u8bef\u5bfc\u6027\u3002", "conclusion": "\u5c3d\u7ba1\u5b58\u5728\u7f3a\u9677\uff0c\u81ea\u6211\u89e3\u91ca\u786e\u5b9e\u7f16\u7801\u4e86\u6709\u52a9\u4e8e\u9884\u6d4b\u6a21\u578b\u884c\u4e3a\u7684\u4fe1\u606f\uff0c\u663e\u793a\u51fa\u81ea\u6211\u77e5\u8bc6\u5e26\u6765\u7684\u4f18\u52bf\u662f\u5916\u90e8\u89e3\u91ca\u65b9\u6cd5\u65e0\u6cd5\u590d\u5236\u7684\u3002\u8fd9\u4e3a\u81ea\u6211\u89e3\u91ca\u63d0\u4f9b\u4e86\u79ef\u6781\u6848\u4f8b\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u9700\u8981\u6539\u8fdb\u7684\u9886\u57df\u3002"}}
{"id": "2602.02934", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02934", "abs": "https://arxiv.org/abs/2602.02934", "authors": ["Yu Shi", "Hao Li", "Bram Adams", "Ahmed E. Hassan"], "title": "Beyond Blame: Rethinking SZZ with Knowledge Graph Search", "comment": null, "summary": "Identifying Bug-Inducing Commits (BICs) is fundamental for understanding software defects and enabling downstream tasks such as defect prediction and automated program repair. Yet existing SZZ-based approaches are limited by their reliance on git blame, which restricts the search space to commits that directly modified the fixed lines. Our preliminary study on 2,102 validated bug-fixing commits reveals that this limitation is significant: over 40% of cases cannot be solved by blame alone, as 28% of BICs require traversing commit history beyond blame results and 14% are blameless.\n  We present AgenticSZZ, the first approach to apply Temporal Knowledge Graphs (TKGs) to software evolution analysis. AgenticSZZ reframes BIC identification from a ranking problem over blame commits into a graph search problem, where temporal ordering is fundamental to causal reasoning about bug introduction. The approach operates in two phases: (1) constructing a TKG that encodes commits with temporal and structural relationships, expanding the search space by traversing file history backward from two reference points (blame commits and the BFC); and (2) leveraging an LLM agent to navigate the graph using specialized tools for candidate exploration and causal analysis.\n  Evaluation on three datasets shows that AgenticSZZ achieves F1-scores of 0.48 to 0.74, with statistically significant improvements over state-of-the-art by up to 27%. Our ablation study confirms that both components are essential, reflecting a classic exploration-exploitation trade-off: the TKG expands the search space while the agent provides intelligent selection. By transforming BIC identification into a graph search problem, we open a new research direction for temporal and causal reasoning in software evolution analysis.", "AI": {"tldr": "AgenticSZZ\uff1a\u9996\u4e2a\u5c06\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u5e94\u7528\u4e8e\u8f6f\u4ef6\u6f14\u5316\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06bug\u5f15\u5165\u63d0\u4ea4\u8bc6\u522b\u91cd\u6784\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc6\u522b\u51c6\u786e\u7387", "motivation": "\u73b0\u6709\u57fa\u4e8eSZZ\u7684\u65b9\u6cd5\u4f9d\u8d56git blame\uff0c\u641c\u7d22\u7a7a\u95f4\u4ec5\u9650\u4e8e\u76f4\u63a5\u4fee\u6539\u4fee\u590d\u884c\u7684\u63d0\u4ea4\uff0c\u5bfc\u81f4\u8d85\u8fc740%\u7684bug\u5f15\u5165\u63d0\u4ea4\u65e0\u6cd5\u88ab\u51c6\u786e\u8bc6\u522b", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u6784\u5efa\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u7f16\u7801\u63d0\u4ea4\u7684\u65f6\u95f4\u4e0e\u7ed3\u6784\u5173\u7cfb\uff0c\u4ece\u4e24\u4e2a\u53c2\u8003\u70b9\uff08blame\u63d0\u4ea4\u548cbug\u4fee\u590d\u63d0\u4ea4\uff09\u5411\u540e\u904d\u5386\u6587\u4ef6\u5386\u53f2\u6269\u5c55\u641c\u7d22\u7a7a\u95f4\uff1b2) \u5229\u7528LLM\u667a\u80fd\u4f53\u901a\u8fc7\u4e13\u95e8\u5de5\u5177\u5728\u56fe\u8c31\u4e2d\u8fdb\u884c\u5019\u9009\u63a2\u7d22\u548c\u56e0\u679c\u5206\u6790", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cF1\u5206\u6570\u8fbe\u52300.48-0.74\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u63d0\u5347\u9ad8\u8fbe27%\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e24\u4e2a\u7ec4\u4ef6\u90fd\u81f3\u5173\u91cd\u8981", "conclusion": "\u901a\u8fc7\u5c06bug\u5f15\u5165\u63d0\u4ea4\u8bc6\u522b\u8f6c\u5316\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\uff0c\u4e3a\u8f6f\u4ef6\u6f14\u5316\u5206\u6790\u4e2d\u7684\u65f6\u5e8f\u548c\u56e0\u679c\u63a8\u7406\u5f00\u8f9f\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411"}}
{"id": "2602.02629", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02629", "abs": "https://arxiv.org/abs/2602.02629", "authors": ["Rodrigo Tertulino", "Ricardo Almeida", "Laercio Alencar"], "title": "Trustworthy Blockchain-based Federated Learning for Electronic Health Records: Securing Participant Identity with Decentralized Identifiers and Verifiable Credentials", "comment": null, "summary": "The digitization of healthcare has generated massive volumes of Electronic Health Records (EHRs), offering unprecedented opportunities for training Artificial Intelligence (AI) models. However, stringent privacy regulations such as GDPR and HIPAA have created data silos that prevent centralized training. Federated Learning (FL) has emerged as a promising solution that enables collaborative model training without sharing raw patient data. Despite its potential, FL remains vulnerable to poisoning and Sybil attacks, in which malicious participants corrupt the global model or infiltrate the network using fake identities. While recent approaches integrate Blockchain technology for auditability, they predominantly rely on probabilistic reputation systems rather than robust cryptographic identity verification. This paper proposes a Trustworthy Blockchain-based Federated Learning (TBFL) framework integrating Self-Sovereign Identity (SSI) standards. By leveraging Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs), our architecture ensures only authenticated healthcare entities contribute to the global model. Through comprehensive evaluation using the MIMIC-IV dataset, we demonstrate that anchoring trust in cryptographic identity verification rather than behavioral patterns significantly mitigates security risks while maintaining clinical utility. Our results show the framework successfully neutralizes 100% of Sybil attacks, achieves robust predictive performance (AUC = 0.954, Recall = 0.890), and introduces negligible computational overhead (<0.12%). The approach provides a secure, scalable, and economically viable ecosystem for inter-institutional health data collaboration, with total operational costs of approximately $18 for 100 training rounds across multiple institutions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u533a\u5757\u94fe\u548c\u81ea\u4e3b\u8eab\u4efd\u6807\u51c6\u7684\u53ef\u4fe1\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5bc6\u7801\u5b66\u8eab\u4efd\u9a8c\u8bc1\u800c\u975e\u884c\u4e3a\u6a21\u5f0f\u6765\u786e\u4fdd\u533b\u7597\u6570\u636e\u534f\u4f5c\u7684\u5b89\u5168\u6027\uff0c\u6709\u6548\u9632\u5fa1Sybil\u653b\u51fb\u5e76\u4fdd\u6301\u4e34\u5e8a\u5b9e\u7528\u6027\u3002", "motivation": "\u533b\u7597\u6570\u5b57\u5316\u4ea7\u751f\u4e86\u5927\u91cf\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff0c\u4f46GDPR\u548cHIPAA\u7b49\u9690\u79c1\u6cd5\u89c4\u5bfc\u81f4\u6570\u636e\u5b64\u5c9b\u3002\u8054\u90a6\u5b66\u4e60\u867d\u7136\u80fd\u5b9e\u73b0\u4e0d\u5171\u4eab\u539f\u59cb\u6570\u636e\u7684\u534f\u4f5c\u8bad\u7ec3\uff0c\u4f46\u4ecd\u6613\u53d7\u6295\u6bd2\u653b\u51fb\u548cSybil\u653b\u51fb\u3002\u73b0\u6709\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6982\u7387\u6027\u58f0\u8a89\u7cfb\u7edf\uff0c\u7f3a\u4e4f\u5f3a\u5927\u7684\u5bc6\u7801\u5b66\u8eab\u4efd\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u53ef\u4fe1\u533a\u5757\u94fe\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u6574\u5408\u81ea\u4e3b\u8eab\u4efd\u6807\u51c6\uff0c\u5229\u7528\u53bb\u4e2d\u5fc3\u5316\u6807\u8bc6\u7b26\u548c\u53ef\u9a8c\u8bc1\u51ed\u8bc1\uff0c\u786e\u4fdd\u53ea\u6709\u7ecf\u8fc7\u8ba4\u8bc1\u7684\u533b\u7597\u5b9e\u4f53\u624d\u80fd\u53c2\u4e0e\u5168\u5c40\u6a21\u578b\u8bad\u7ec3\u3002", "result": "\u4f7f\u7528MIMIC-IV\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u6846\u67b6\u6210\u529f\u62b5\u5fa1100%\u7684Sybil\u653b\u51fb\uff0c\u4fdd\u6301\u7a33\u5065\u7684\u9884\u6d4b\u6027\u80fd\uff08AUC=0.954\uff0c\u53ec\u56de\u7387=0.890\uff09\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u4f4e\uff08<0.12%\uff09\uff0c100\u8f6e\u8de8\u673a\u6784\u8bad\u7ec3\u7684\u603b\u8fd0\u8425\u6210\u672c\u7ea618\u7f8e\u5143\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u4fe1\u4efb\u951a\u5b9a\u5728\u5bc6\u7801\u5b66\u8eab\u4efd\u9a8c\u8bc1\u800c\u975e\u884c\u4e3a\u6a21\u5f0f\u4e0a\uff0c\u663e\u8457\u964d\u4f4e\u5b89\u5168\u98ce\u9669\uff0c\u540c\u65f6\u4fdd\u6301\u4e34\u5e8a\u5b9e\u7528\u6027\uff0c\u4e3a\u8de8\u673a\u6784\u533b\u7597\u6570\u636e\u534f\u4f5c\u63d0\u4f9b\u4e86\u5b89\u5168\u3001\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u53ef\u884c\u7684\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2602.02964", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02964", "abs": "https://arxiv.org/abs/2602.02964", "authors": ["Altino Alves", "Jo\u00e3o Eduardo Montandon", "Andre Hora"], "title": "Testing Framework Migration with Large Language Models", "comment": "Accepted for publication at AST 2026", "summary": "Python developers rely on two major testing frameworks: \\texttt{unittest} and \\texttt{Pytest}. While \\texttt{Pytest} offers simpler assertions, reusable fixtures, and better interoperability, migrating existing suites from \\texttt{unittest} remains a manual and time-consuming process. Automating this migration could substantially reduce effort and accelerate test modernization. In this paper, we investigate the capability of Large Language Models (LLMs) to automate test framework migrations from \\texttt{unittest} to \\texttt{Pytest}. We evaluate GPT 4o and Claude Sonnet 4 under three prompting strategies (Zero-shot, One-shot, and Chain-of-Thought) and two temperature settings (0.0 and 1.0). To support this analysis, we first introduce a curated dataset of real-world migrations extracted from the top 100 Python open-source projects. Next, we actually execute the LLM-generated test migrations in their respective test suites. Overall, we find that 51.5% of the LLM-generated test migrations failed, while 48.5% passed. The results suggest that LLMs can accelerate test migration, but there are often caveats. For example, Claude Sonnet 4 exhibited more conservative migrations (e.g., preserving class-based tests and legacy \\texttt{unittest} references), while GPT-4o favored more transformations (e.g., to function-based tests). We conclude by discussing multiple implications for practitioners and researchers.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u5316\u5c06Python\u6d4b\u8bd5\u4eceunittest\u8fc1\u79fb\u5230Pytest\u6846\u67b6\uff0c\u8bc4\u4f30\u4e86GPT-4o\u548cClaude Sonnet 4\u5728\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u7ea648.5%\u7684\u8fc1\u79fb\u6d4b\u8bd5\u80fd\u591f\u901a\u8fc7\u6267\u884c\u3002", "motivation": "Python\u5f00\u53d1\u8005\u4e3b\u8981\u4f7f\u7528unittest\u548cPytest\u4e24\u79cd\u6d4b\u8bd5\u6846\u67b6\u3002\u867d\u7136Pytest\u63d0\u4f9b\u4e86\u66f4\u7b80\u5355\u7684\u65ad\u8a00\u3001\u53ef\u91cd\u7528\u7684fixture\u548c\u66f4\u597d\u7684\u4e92\u64cd\u4f5c\u6027\uff0c\u4f46\u4eceunittest\u8fc1\u79fb\u5230Pytest\u4ecd\u7136\u662f\u4e00\u4e2a\u624b\u52a8\u4e14\u8017\u65f6\u7684\u8fc7\u7a0b\u3002\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc1\u79fb\u8fc7\u7a0b\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u5de5\u4f5c\u91cf\u5e76\u52a0\u901f\u6d4b\u8bd5\u73b0\u4ee3\u5316\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e86GPT-4o\u548cClaude Sonnet 4\u4e24\u79cdLLM\u5728\u4e09\u79cd\u63d0\u793a\u7b56\u7565\uff08Zero-shot\u3001One-shot\u548cChain-of-Thought\uff09\u548c\u4e24\u79cd\u6e29\u5ea6\u8bbe\u7f6e\uff080.0\u548c1.0\uff09\u4e0b\u7684\u8868\u73b0\u3002\u9996\u5148\u4ecetop 100 Python\u5f00\u6e90\u9879\u76ee\u4e2d\u63d0\u53d6\u771f\u5b9e\u8fc1\u79fb\u6848\u4f8b\u6784\u5efa\u6570\u636e\u96c6\uff0c\u7136\u540e\u5b9e\u9645\u6267\u884cLLM\u751f\u6210\u7684\u6d4b\u8bd5\u8fc1\u79fb\u4ee3\u7801\u3002", "result": "\u603b\u4f53\u800c\u8a00\uff0c51.5%\u7684LLM\u751f\u6210\u7684\u6d4b\u8bd5\u8fc1\u79fb\u5931\u8d25\uff0c48.5%\u901a\u8fc7\u3002Claude Sonnet 4\u8868\u73b0\u51fa\u66f4\u4fdd\u5b88\u7684\u8fc1\u79fb\u7b56\u7565\uff08\u5982\u4fdd\u7559\u57fa\u4e8e\u7c7b\u7684\u6d4b\u8bd5\u548c\u9057\u7559unittest\u5f15\u7528\uff09\uff0c\u800cGPT-4o\u503e\u5411\u4e8e\u66f4\u591a\u8f6c\u6362\uff08\u5982\u8f6c\u5411\u57fa\u4e8e\u51fd\u6570\u7684\u6d4b\u8bd5\uff09\u3002", "conclusion": "LLM\u53ef\u4ee5\u52a0\u901f\u6d4b\u8bd5\u8fc1\u79fb\u8fc7\u7a0b\uff0c\u4f46\u5b58\u5728\u5c40\u9650\u6027\u3002\u4e0d\u540cLLM\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u8fc1\u79fb\u7b56\u7565\u504f\u597d\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u4ece\u4e1a\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u591a\u4e2a\u5b9e\u8df5\u542f\u793a\uff0c\u8868\u660e\u81ea\u52a8\u5316\u6d4b\u8bd5\u8fc1\u79fb\u5177\u6709\u6f5c\u529b\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2602.02641", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02641", "abs": "https://arxiv.org/abs/2602.02641", "authors": ["Najmul Hasan", "Prashanth BusiReddyGari"], "title": "Benchmarking Large Language Models for Zero-shot and Few-shot Phishing URL Detection", "comment": "9 pages, accepted at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025 LAW Workshop)", "summary": "The Uniform Resource Locator (URL), introduced in a connectivity-first era to define access and locate resources, remains historically limited, lacking future-proof mechanisms for security, trust, or resilience against fraud and abuse, despite the introduction of reactive protections like HTTPS during the cybersecurity era. In the current AI-first threatscape, deceptive URLs have reached unprecedented sophistication due to the widespread use of generative AI by cybercriminals and the AI-vs-AI arms race to produce context-aware phishing websites and URLs that are virtually indistinguishable to both users and traditional detection tools. Although AI-generated phishing accounted for a small fraction of filter-bypassing attacks in 2024, phishing volume has escalated over 4,000% since 2022, with nearly 50% more attacks evading detection. At the rate the threatscape is escalating, and phishing tactics are emerging faster than labeled data can be produced, zero-shot and few-shot learning with large language models (LLMs) offers a timely and adaptable solution, enabling generalization with minimal supervision. Given the critical importance of phishing URL detection in large-scale cybersecurity defense systems, we present a comprehensive benchmark of LLMs under a unified zero-shot and few-shot prompting framework and reveal operational trade-offs. Our evaluation uses a balanced dataset with consistent prompts, offering detailed analysis of performance, generalization, and model efficacy, quantified by accuracy, precision, recall, F1 score, AUROC, and AUPRC, to reflect both classification quality and practical utility in threat detection settings. We conclude few-shot prompting improves performance across multiple LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u6765\u68c0\u6d4bAI\u751f\u6210\u7684\u9493\u9c7cURL\uff0c\u521b\u5efa\u4e86\u7edf\u4e00\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u53d1\u73b0\u5c11\u6837\u672c\u63d0\u793a\u80fd\u63d0\u5347\u591a\u4e2aLLM\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfURL\u8bbe\u8ba1\u7f3a\u4e4f\u5b89\u5168\u673a\u5236\uff0cAI\u65f6\u4ee3\u9493\u9c7cURL\u53d8\u5f97\u66f4\u52a0\u590d\u6742\u548c\u96be\u4ee5\u68c0\u6d4b\uff0c\u4f20\u7edf\u68c0\u6d4b\u5de5\u5177\u5931\u6548\uff0c\u800c\u6807\u6ce8\u6570\u636e\u751f\u6210\u901f\u5ea6\u8ddf\u4e0d\u4e0a\u5a01\u80c1\u6f14\u53d8\u901f\u5ea6\uff0c\u9700\u8981\u96f6\u6837\u672c/\u5c11\u6837\u672c\u5b66\u4e60\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\uff0c\u5efa\u7acb\u7edf\u4e00\u7684\u63d0\u793a\u6846\u67b6\uff0c\u5728\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u591a\u4e2aLLM\uff0c\u4f7f\u7528\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u3001AUROC\u548cAUPRC\u7b49\u6307\u6807\u91cf\u5316\u6027\u80fd\u3002", "result": "\u5c11\u6837\u672c\u63d0\u793a\u80fd\u63d0\u5347\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u8bba\u6587\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u6027\u80fd\u3001\u6cdb\u5316\u80fd\u529b\u548c\u6a21\u578b\u6548\u679c\u5206\u6790\uff0c\u63ed\u793a\u4e86\u64cd\u4f5c\u6743\u8861\u3002", "conclusion": "\u5728AI\u9a71\u52a8\u7684\u5a01\u80c1\u73af\u5883\u4e2d\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u4e3a\u9493\u9c7cURL\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ca\u65f6\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c11\u6837\u672c\u63d0\u793a\u80fd\u6709\u6548\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2602.02965", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02965", "abs": "https://arxiv.org/abs/2602.02965", "authors": ["Andre Hora", "Gordon Fraser"], "title": "Understanding Bug-Reproducing Tests: A First Empirical Study", "comment": "Accepted for publication at AST 2026", "summary": "Developers create bug-reproducing tests that support debugging by failing as long as the bug is present, and passing once the bug has been fixed. These tests are usually integrated into existing test suites and executed regularly alongside all other tests to ensure that future regressions are caught. Despite this co-existence with other types of tests, the properties of bug-reproducing tests are scarcely researched, and it remains unclear whether they differ fundamentally. In this short paper, we provide an initial empirical study to understand bug-reproducing tests better. We analyze 642 bug-reproducing tests of 15 real-world Python systems. Overall, we find that bug-reproducing tests are not (statistically significantly) different from other tests regarding LOC, number of assertions, and complexity. However, bug-reproducing tests contain slightly more try/except blocks and ``weak assertions'' (e.g.,~\\texttt{assertNotEqual}). Lastly, we detect that the majority (95%) of the bug-reproducing tests reproduce a single bug, while 5% reproduce multiple bugs. We conclude by discussing implications and future research directions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9Python\u9879\u76ee\u4e2d642\u4e2abug\u91cd\u73b0\u6d4b\u8bd5\u8fdb\u884c\u4e86\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u4ee3\u7801\u884c\u6570\u3001\u65ad\u8a00\u6570\u91cf\u548c\u590d\u6742\u5ea6\u65b9\u9762\u4e0e\u666e\u901a\u6d4b\u8bd5\u65e0\u663e\u8457\u5dee\u5f02\uff0c\u4f46\u5305\u542b\u66f4\u591atry/except\u5757\u548c\u5f31\u65ad\u8a00\uff0c\u4e1495%\u53ea\u91cd\u73b0\u5355\u4e2abug\u3002", "motivation": "\u5c3d\u7ba1bug\u91cd\u73b0\u6d4b\u8bd5\u4e0e\u5e38\u89c4\u6d4b\u8bd5\u5171\u5b58\u4e8e\u6d4b\u8bd5\u5957\u4ef6\u4e2d\uff0c\u4f46\u5176\u7279\u6027\u7814\u7a76\u8f83\u5c11\uff0c\u4e0d\u6e05\u695a\u5b83\u4eec\u662f\u5426\u4e0e\u666e\u901a\u6d4b\u8bd5\u6709\u672c\u8d28\u533a\u522b\uff0c\u56e0\u6b64\u9700\u8981\u5b9e\u8bc1\u7814\u7a76\u6765\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u7c7b\u6d4b\u8bd5\u3002", "method": "\u5bf915\u4e2a\u771f\u5b9ePython\u7cfb\u7edf\u4e2d\u7684642\u4e2abug\u91cd\u73b0\u6d4b\u8bd5\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u6bd4\u8f83\u5b83\u4eec\u4e0e\u666e\u901a\u6d4b\u8bd5\u5728LOC\u3001\u65ad\u8a00\u6570\u91cf\u3001\u590d\u6742\u5ea6\u7b49\u65b9\u9762\u7684\u5dee\u5f02\u3002", "result": "bug\u91cd\u73b0\u6d4b\u8bd5\u5728LOC\u3001\u65ad\u8a00\u6570\u91cf\u548c\u590d\u6742\u5ea6\u65b9\u9762\u4e0e\u666e\u901a\u6d4b\u8bd5\u65e0\u7edf\u8ba1\u5b66\u663e\u8457\u5dee\u5f02\uff0c\u4f46\u5305\u542b\u66f4\u591atry/except\u5757\u548c\u5f31\u65ad\u8a00\uff08\u5982assertNotEqual\uff09\uff0c\u4e1495%\u53ea\u91cd\u73b0\u5355\u4e2abug\uff0c5%\u91cd\u73b0\u591a\u4e2abug\u3002", "conclusion": "bug\u91cd\u73b0\u6d4b\u8bd5\u4e0e\u666e\u901a\u6d4b\u8bd5\u5728\u57fa\u672c\u7279\u6027\u4e0a\u76f8\u4f3c\uff0c\u4f46\u5728\u5f02\u5e38\u5904\u7406\u548c\u65ad\u8a00\u7c7b\u578b\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u8fd9\u4e3a\u6d4b\u8bd5\u5b9e\u8df5\u548c\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u542f\u793a\u3002"}}
{"id": "2602.02711", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02711", "abs": "https://arxiv.org/abs/2602.02711", "authors": ["Yuanzhe Li", "Jianing Deng", "Jingtong Hu", "Tianlong Chen", "Song Wang", "Huanrui Yang"], "title": "Dynamic Mix Precision Routing for Efficient Multi-step LLM Interaction", "comment": null, "summary": "Large language models (LLM) achieve strong performance in long-horizon decision-making tasks through multi-step interaction and reasoning at test time. While practitioners commonly believe a higher task success rate necessitates the use of a larger and stronger LLM model, multi-step interaction with a large LLM incurs prohibitive inference cost. To address this problem, we explore the use of low-precision quantized LLM in the long-horizon decision-making process. Based on the observation of diverse sensitivities among interaction steps, we propose a dynamic mix-precision routing framework that adaptively selects between high-precision and low-precision LLMs at each decision step. The router is trained via a two-stage pipeline, consisting of KL-divergence-based supervised learning that identifies precision-sensitive steps, followed by Group-Relative Policy Optimization (GRPO) to further improve task success rates. Experiments on ALFWorld demonstrate that our approach achieves a great improvement on accuracy-cost trade-off over single-precision baselines and heuristic routing methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u6df7\u5408\u7cbe\u5ea6\u8def\u7531\u6846\u67b6\uff0c\u5728\u957f\u65f6\u7a0b\u51b3\u7b56\u4efb\u52a1\u4e2d\u81ea\u9002\u5e94\u9009\u62e9\u9ad8\u7cbe\u5ea6\u548c\u4f4e\u7cbe\u5ea6LLM\uff0c\u4ee5\u964d\u4f4e\u63a8\u7406\u6210\u672c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u957f\u65f6\u7a0b\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4f7f\u7528\u5927\u578bLLM\u8fdb\u884c\u591a\u6b65\u4ea4\u4e92\u4f1a\u4ea7\u751f\u9ad8\u6602\u7684\u63a8\u7406\u6210\u672c\u3002\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u66f4\u9ad8\u7684\u4efb\u52a1\u6210\u529f\u7387\u9700\u8981\u4f7f\u7528\u66f4\u5927\u66f4\u5f3a\u7684LLM\u6a21\u578b\uff0c\u4f46\u4f5c\u8005\u89c2\u5bdf\u5230\u4e0d\u540c\u4ea4\u4e92\u6b65\u9aa4\u5bf9\u6a21\u578b\u7cbe\u5ea6\u7684\u654f\u611f\u6027\u5b58\u5728\u5dee\u5f02\uff0c\u8fd9\u4e3a\u4f18\u5316\u6210\u672c-\u6027\u80fd\u6743\u8861\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u6df7\u5408\u7cbe\u5ea6\u8def\u7531\u6846\u67b6\uff0c\u5728\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u81ea\u9002\u5e94\u9009\u62e9\u9ad8\u7cbe\u5ea6\u548c\u4f4e\u7cbe\u5ea6LLM\u3002\u8def\u7531\u5668\u901a\u8fc7\u4e24\u9636\u6bb5\u7ba1\u9053\u8bad\u7ec3\uff1a1) \u57fa\u4e8eKL\u6563\u5ea6\u7684\u76d1\u7763\u5b66\u4e60\u8bc6\u522b\u7cbe\u5ea6\u654f\u611f\u6b65\u9aa4\uff1b2) \u4f7f\u7528\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "result": "\u5728ALFWorld\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u7387-\u6210\u672c\u6743\u8861\u65b9\u9762\u76f8\u6bd4\u5355\u7cbe\u5ea6\u57fa\u7ebf\u548c\u542f\u53d1\u5f0f\u8def\u7531\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u52a8\u6001\u6df7\u5408\u7cbe\u5ea6\u8def\u7531\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u4efb\u52a1\u6210\u529f\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u957f\u65f6\u7a0b\u51b3\u7b56\u4efb\u52a1\u7684\u63a8\u7406\u6210\u672c\uff0c\u4e3aLLM\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6210\u672c\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2602.02966", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02966", "abs": "https://arxiv.org/abs/2602.02966", "authors": ["Bruna Falcucci", "Felipe Gomide", "Andre Hora"], "title": "What Do Contribution Guidelines Say About Software Testing?", "comment": "Published at MSR 2025", "summary": "Software testing plays a crucial role in the contribution process of open-source projects. For example, contributions introducing new features are expected to include tests, and contributions with tests are more likely to be accepted. Although most real-world projects require contributors to write tests, the specific testing practices communicated to contributors remain unclear. In this paper, we present an empirical study to understand better how software testing is approached in contribution guidelines. We analyze the guidelines of 200 Python and JavaScript open-source software projects. We find that 78\\% of the projects include some form of test documentation for contributors. Test documentation is located in multiple sources, including \\texttt{CONTRIBUTING} files (58\\%), external documentation (24\\%), and \\texttt{README} files (8\\%). Furthermore, test documentation commonly explains how to run tests (83.5\\%), but less often provides guidance on how to write tests (37\\%). It frequently covers unit tests (71\\%), but rarely addresses integration (20.5\\%) and end-to-end tests (15.5\\%). Other key testing aspects are also less frequently discussed: test coverage (25.5\\%) and mocking (9.5\\%). We conclude by discussing implications and future research.", "AI": {"tldr": "\u5bf9200\u4e2aPython\u548cJavaScript\u5f00\u6e90\u9879\u76ee\u7684\u8d21\u732e\u6307\u5357\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u6d4b\u8bd5\u5b9e\u8df5\u5728\u8d21\u732e\u6307\u5357\u4e2d\u7684\u4f53\u73b0\u60c5\u51b5", "motivation": "\u867d\u7136\u5927\u591a\u6570\u5f00\u6e90\u9879\u76ee\u8981\u6c42\u8d21\u732e\u8005\u7f16\u5199\u6d4b\u8bd5\uff0c\u4f46\u5177\u4f53\u4f20\u8fbe\u7ed9\u8d21\u732e\u8005\u7684\u6d4b\u8bd5\u5b9e\u8df5\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u4e86\u89e3\u8d21\u732e\u6307\u5357\u4e2d\u5982\u4f55\u6307\u5bfc\u8f6f\u4ef6\u6d4b\u8bd5", "method": "\u5206\u6790200\u4e2aPython\u548cJavaScript\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u7684\u8d21\u732e\u6307\u5357\uff0c\u5305\u62ecCONTRIBUTING\u6587\u4ef6\u3001\u5916\u90e8\u6587\u6863\u548cREADME\u6587\u4ef6\u4e2d\u7684\u6d4b\u8bd5\u6587\u6863", "result": "78%\u7684\u9879\u76ee\u5305\u542b\u67d0\u79cd\u5f62\u5f0f\u7684\u6d4b\u8bd5\u6587\u6863\uff1b\u6d4b\u8bd5\u6587\u6863\u4e3b\u8981\u4f4d\u4e8eCONTRIBUTING\u6587\u4ef6(58%)\u3001\u5916\u90e8\u6587\u6863(24%)\u548cREADME\u6587\u4ef6(8%)\uff1b83.5%\u7684\u6587\u6863\u89e3\u91ca\u5982\u4f55\u8fd0\u884c\u6d4b\u8bd5\uff0c\u4f46\u53ea\u670937%\u63d0\u4f9b\u7f16\u5199\u6d4b\u8bd5\u7684\u6307\u5bfc\uff1b71%\u6db5\u76d6\u5355\u5143\u6d4b\u8bd5\uff0c\u4f46\u96c6\u6210\u6d4b\u8bd5(20.5%)\u548c\u7aef\u5230\u7aef\u6d4b\u8bd5(15.5%)\u8f83\u5c11\u6d89\u53ca\uff1b\u6d4b\u8bd5\u8986\u76d6\u7387(25.5%)\u548c\u6a21\u62df\u6d4b\u8bd5(9.5%)\u8ba8\u8bba\u8f83\u5c11", "conclusion": "\u5f00\u6e90\u9879\u76ee\u5728\u8d21\u732e\u6307\u5357\u4e2d\u666e\u904d\u5305\u542b\u6d4b\u8bd5\u6587\u6863\uff0c\u4f46\u6d4b\u8bd5\u6307\u5bfc\u5185\u5bb9\u4e0d\u591f\u5168\u9762\uff0c\u7279\u522b\u662f\u6d4b\u8bd5\u7f16\u5199\u65b9\u6cd5\u3001\u9ad8\u7ea7\u6d4b\u8bd5\u7c7b\u578b\u548c\u6d4b\u8bd5\u8d28\u91cf\u6307\u6807\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u6539\u8fdb\u6d4b\u8bd5\u5b9e\u8df5\u6307\u5bfc"}}
{"id": "2602.02717", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02717", "abs": "https://arxiv.org/abs/2602.02717", "authors": ["Kyle Yates", "Abdullah Al Mamun", "Mashrur Chowdhury"], "title": "On the Feasibility of Hybrid Homomorphic Encryption for Intelligent Transportation Systems", "comment": "This version has been submitted to a peer-reviewed journal and is currently under review", "summary": "Many Intelligent Transportation Systems (ITS) applications require strong privacy guarantees for both users and their data. Homomorphic encryption (HE) enables computation directly on encrypted messages and thus offers a compelling approach to privacy-preserving data processing in ITS. However, practical HE schemes incur substantial ciphertext expansion and communication overhead, which limits their suitability for time-critical transportation systems. Hybrid homomorphic encryption (HHE) addresses this challenge by combining a homomorphic encryption scheme with a symmetric cipher, enabling efficient encrypted computation while dramatically reducing communication cost. In this paper, we develop theoretical models of representative ITS applications that integrate HHE to protect sensitive vehicular data. We then perform a parameter-based evaluation of the HHE scheme Rubato to estimate ciphertext sizes and communication overhead under realistic ITS workloads. Our results show that HHE achieves orders-of-magnitude reductions in ciphertext size compared with conventional HE while maintaining cryptographic security, making it significantly more practical for latency-constrained ITS communication.", "AI": {"tldr": "HHE\u5728ITS\u4e2d\u663e\u8457\u964d\u4f4e\u5bc6\u6587\u5927\u5c0f\u548c\u901a\u4fe1\u5f00\u9500\uff0c\u76f8\u6bd4\u4f20\u7edfHE\u66f4\u9002\u5408\u65f6\u5ef6\u654f\u611f\u7684\u4ea4\u901a\u7cfb\u7edf", "motivation": "ITS\u5e94\u7528\u9700\u8981\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u4f46\u4f20\u7edf\u540c\u6001\u52a0\u5bc6\u5b58\u5728\u5bc6\u6587\u81a8\u80c0\u548c\u901a\u4fe1\u5f00\u9500\u5927\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u65f6\u95f4\u5173\u952e\u578b\u4ea4\u901a\u7cfb\u7edf\u4e2d\u7684\u9002\u7528\u6027", "method": "\u5f00\u53d1\u96c6\u6210HHE\u7684ITS\u5e94\u7528\u7406\u8bba\u6a21\u578b\uff0c\u57fa\u4e8e\u53c2\u6570\u8bc4\u4f30Rubato HHE\u65b9\u6848\uff0c\u4f30\u7b97\u5b9e\u9645ITS\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u5bc6\u6587\u5927\u5c0f\u548c\u901a\u4fe1\u5f00\u9500", "result": "HHE\u76f8\u6bd4\u4f20\u7edfHE\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u7684\u5bc6\u6587\u5927\u5c0f\u51cf\u5c11\uff0c\u540c\u65f6\u4fdd\u6301\u5bc6\u7801\u5b89\u5168\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u65f6\u5ef6\u53d7\u9650ITS\u901a\u4fe1\u4e2d\u7684\u5b9e\u7528\u6027", "conclusion": "\u6df7\u5408\u540c\u6001\u52a0\u5bc6\u4e3aITS\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u6570\u636e\u5904\u7406\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u5408\u65f6\u95f4\u5173\u952e\u7684\u4ea4\u901a\u5e94\u7528\u573a\u666f"}}
{"id": "2602.02780", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02780", "abs": "https://arxiv.org/abs/2602.02780", "authors": ["Zihao Jing", "Qiuhao Zeng", "Ruiyi Fang", "Yan Yi Li", "Yan Sun", "Boyu Wang", "Pingzhao Hu"], "title": "Scaling-Aware Adapter for Structure-Grounded LLM Reasoning", "comment": "Under review at ICML 2026", "summary": "Large language models (LLMs) are enabling reasoning over biomolecular structures, yet existing methods remain modality-specific and typically compress structural inputs through sequence-based tokenization or fixed-length query connectors. Such architectures either omit the geometric groundings requisite for mitigating structural hallucinations or impose inflexible modality fusion bottlenecks that concurrently over-compress and suboptimally allocate structural tokens, thereby impeding the realization of generalized all-atom reasoning. We introduce Cuttlefish, a unified all-atom LLM that grounds language reasoning in geometric cues while scaling modality tokens with structural complexity. First, Scaling-Aware Patching leverages an instruction-conditioned gating mechanism to generate variable-size patches over structural graphs, adaptively scaling the query token budget with structural complexity to mitigate fixed-length connector bottlenecks. Second, Geometry Grounding Adapter refines these adaptive tokens via cross-attention to modality embeddings and injects the resulting modality tokens into the LLM, exposing explicit geometric cues to reduce structural hallucination. Experiments across diverse all-atom benchmarks demonstrate that Cuttlefish achieves superior performance in heterogeneous structure-grounded reasoning. Code is available at the project repository.", "AI": {"tldr": "Cuttlefish\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u5168\u539f\u5b50\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7f29\u653e\u7ed3\u6784\u8865\u4e01\u548c\u51e0\u4f55\u63a5\u5730\u9002\u914d\u5668\uff0c\u5728\u4fdd\u6301\u51e0\u4f55\u4fe1\u606f\u7684\u540c\u65f6\u89e3\u51b3\u6a21\u6001\u878d\u5408\u74f6\u9888\u95ee\u9898\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u7ed3\u6784\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u751f\u7269\u5206\u5b50\u7ed3\u6784\u63a8\u7406\u4e2d\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u901a\u8fc7\u5e8f\u5217\u5316\u6807\u8bb0\u6216\u56fa\u5b9a\u957f\u5ea6\u67e5\u8be2\u8fde\u63a5\u5668\u538b\u7f29\u7ed3\u6784\u8f93\u5165\uff0c\u5bfc\u81f4\u51e0\u4f55\u4fe1\u606f\u4e22\u5931\uff0c\u5bb9\u6613\u4ea7\u751f\u7ed3\u6784\u5e7b\u89c9\uff1b2\uff09\u6a21\u6001\u878d\u5408\u74f6\u9888\u540c\u65f6\u8fc7\u5ea6\u538b\u7f29\u548c\u6b21\u4f18\u5206\u914d\u7ed3\u6784\u6807\u8bb0\uff0c\u963b\u788d\u4e86\u901a\u7528\u5168\u539f\u5b50\u63a8\u7406\u7684\u5b9e\u73b0\u3002", "method": "\u63d0\u51faCuttlefish\u6a21\u578b\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6280\u672f\uff1a1\uff09\u7f29\u653e\u611f\u77e5\u8865\u4e01\uff1a\u4f7f\u7528\u6307\u4ee4\u6761\u4ef6\u95e8\u63a7\u673a\u5236\u5728\u7ed3\u6784\u56fe\u4e0a\u751f\u6210\u53ef\u53d8\u5927\u5c0f\u7684\u8865\u4e01\uff0c\u6839\u636e\u7ed3\u6784\u590d\u6742\u5ea6\u81ea\u9002\u5e94\u7f29\u653e\u67e5\u8be2\u6807\u8bb0\u9884\u7b97\uff1b2\uff09\u51e0\u4f55\u63a5\u5730\u9002\u914d\u5668\uff1a\u901a\u8fc7\u8de8\u6ce8\u610f\u529b\u673a\u5236\u7cbe\u70bc\u81ea\u9002\u5e94\u6807\u8bb0\u5e76\u6ce8\u5165\u6a21\u6001\u5d4c\u5165\uff0c\u5c06\u663e\u5f0f\u51e0\u4f55\u7ebf\u7d22\u66b4\u9732\u7ed9LLM\u4ee5\u51cf\u5c11\u7ed3\u6784\u5e7b\u89c9\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u5168\u539f\u5b50\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCuttlefish\u5728\u5f02\u6784\u7ed3\u6784\u63a5\u5730\u63a8\u7406\u65b9\u9762\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "Cuttlefish\u901a\u8fc7\u81ea\u9002\u5e94\u7f29\u653e\u7ed3\u6784\u6807\u8bb0\u548c\u663e\u5f0f\u51e0\u4f55\u63a5\u5730\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u751f\u7269\u5206\u5b50\u7ed3\u6784\u63a8\u7406\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5168\u539f\u5b50\u63a8\u7406\u80fd\u529b\uff0c\u4ee3\u7801\u5df2\u5728\u9879\u76ee\u4ed3\u5e93\u4e2d\u5f00\u6e90\u3002"}}
{"id": "2602.03093", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03093", "abs": "https://arxiv.org/abs/2602.03093", "authors": ["Yang Yue", "Zheng Jiang", "Yi Wang"], "title": "Maintaining the Heterogeneity in the Organization of Software Engineering Research", "comment": "Accepted at the 48th International Conference on Software Engineering, Future of Software Engineering (ICSE 2026-FoSE)", "summary": "The heterogeneity in the organization of software engineering (SE) research historically exists, i.e., funded research model and hands-on model, which makes software engineering become a thriving interdisciplinary field in the last 50 years. However, the funded research model is becoming dominant in SE research recently, indicating such heterogeneity has been seriously and systematically threatened. In this essay, we first explain why the heterogeneity is needed in the organization of SE research, then present the current trend of SE research nowadays, as well as the consequences and potential futures. The choice is at our hands, and we urge our community to seriously consider maintaining the heterogeneity in the organization of software engineering research.", "AI": {"tldr": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7ec4\u7ec7\u4e2d\u7684\u5f02\u8d28\u6027\uff08\u8d44\u52a9\u7814\u7a76\u6a21\u5f0f\u548c\u52a8\u624b\u5b9e\u8df5\u6a21\u5f0f\uff09\u6b63\u9762\u4e34\u5a01\u80c1\uff0c\u4f5c\u8005\u547c\u5401\u793e\u533a\u91cd\u89c6\u5e76\u7ef4\u62a4\u8fd9\u79cd\u591a\u6837\u6027", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u5386\u53f2\u4e0a\u5b58\u5728\u4e24\u79cd\u7ec4\u7ec7\u6a21\u5f0f\u7684\u5f02\u8d28\u6027\uff1a\u8d44\u52a9\u7814\u7a76\u6a21\u5f0f\u548c\u52a8\u624b\u5b9e\u8df5\u6a21\u5f0f\uff0c\u8fd9\u79cd\u591a\u6837\u6027\u4f7f\u8f6f\u4ef6\u5de5\u7a0b\u5728\u8fc7\u53bb50\u5e74\u6210\u4e3a\u7e41\u8363\u7684\u8de8\u5b66\u79d1\u9886\u57df\u3002\u7136\u800c\uff0c\u8fd1\u5e74\u6765\u8d44\u52a9\u7814\u7a76\u6a21\u5f0f\u9010\u6e10\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\uff0c\u8fd9\u79cd\u5f02\u8d28\u6027\u6b63\u53d7\u5230\u4e25\u91cd\u7cfb\u7edf\u6027\u5a01\u80c1", "method": "\u672c\u6587\u91c7\u7528\u8bba\u8ff0\u6027\u65b9\u6cd5\uff0c\u9996\u5148\u89e3\u91ca\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7ec4\u7ec7\u4e3a\u4f55\u9700\u8981\u5f02\u8d28\u6027\uff0c\u7136\u540e\u5206\u6790\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u8d8b\u52bf\u3001\u540e\u679c\u53ca\u6f5c\u5728\u672a\u6765", "result": "\u4f5c\u8005\u6307\u51fa\u8d44\u52a9\u7814\u7a76\u6a21\u5f0f\u5728\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u65e5\u76ca\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\uff0c\u8fd9\u79cd\u8d8b\u52bf\u5a01\u80c1\u5230\u7814\u7a76\u7ec4\u7ec7\u7684\u5f02\u8d28\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u7814\u7a76\u591a\u6837\u6027\u548c\u521b\u65b0\u6027\u7684\u51cf\u5c11", "conclusion": "\u9009\u62e9\u6743\u5728\u6211\u4eec\u624b\u4e2d\uff0c\u4f5c\u8005\u547c\u5401\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u8ba4\u771f\u8003\u8651\u5e76\u7ef4\u62a4\u7814\u7a76\u7ec4\u7ec7\u4e2d\u7684\u5f02\u8d28\u6027\uff0c\u4ee5\u4fdd\u6301\u8be5\u9886\u57df\u7684\u6d3b\u529b\u548c\u521b\u65b0\u6027"}}
{"id": "2602.02718", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02718", "abs": "https://arxiv.org/abs/2602.02718", "authors": ["Jiamu Bai", "Guanlin He", "Xin Gu", "Daniel Kifer", "Kiwan Maeng"], "title": "Composition for Pufferfish Privacy", "comment": null, "summary": "When creating public data products out of confidential datasets, inferential/posterior-based privacy definitions, such as Pufferfish, provide compelling privacy semantics for data with correlations. However, such privacy definitions are rarely used in practice because they do not always compose. For example, it is possible to design algorithms for these privacy definitions that have no leakage when run once but reveal the entire dataset when run more than once. We prove necessary and sufficient conditions that must be added to ensure linear composition for Pufferfish mechanisms, hence avoiding such privacy collapse. These extra conditions turn out to be differential privacy-style inequalities, indicating that achieving both the interpretable semantics of Pufferfish for correlated data and composition benefits requires adopting differentially private mechanisms to Pufferfish. We show that such translation is possible through a concept called the $(a,b)$-influence curve, and many existing differentially private algorithms can be translated with our framework into a composable Pufferfish algorithm. We illustrate the benefit of our new framework by designing composable Pufferfish algorithms for Markov chains that significantly outperform prior work.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Pufferfish\u9690\u79c1\u5b9a\u4e49\u5728\u7ec4\u5408\u6027\u65b9\u9762\u7684\u7f3a\u9677\uff0c\u63d0\u51fa\u4e86\u786e\u4fdd\u7ebf\u6027\u7ec4\u5408\u7684\u5fc5\u8981\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u5f00\u53d1\u4e86\u5c06\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u8f6c\u6362\u4e3a\u53ef\u7ec4\u5408Pufferfish\u7b97\u6cd5\u7684\u6846\u67b6\u3002", "motivation": "Pufferfish\u7b49\u57fa\u4e8e\u63a8\u65ad/\u540e\u9a8c\u7684\u9690\u79c1\u5b9a\u4e49\u5728\u5904\u7406\u76f8\u5173\u6570\u636e\u65f6\u5177\u6709\u5438\u5f15\u529b\u7684\u9690\u79c1\u8bed\u4e49\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u7ec4\u5408\u6027\u800c\u5f88\u5c11\u5728\u5b9e\u8df5\u4e2d\u4f7f\u7528\u3002\u73b0\u6709\u7b97\u6cd5\u53ef\u80fd\u5728\u5355\u6b21\u8fd0\u884c\u65f6\u65e0\u6cc4\u6f0f\uff0c\u4f46\u5728\u591a\u6b21\u8fd0\u884c\u65f6\u53ef\u80fd\u6cc4\u9732\u6574\u4e2a\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e86\u786e\u4fddPufferfish\u673a\u5236\u7ebf\u6027\u7ec4\u5408\u7684\u5fc5\u8981\u5145\u5206\u6761\u4ef6\uff0c\u8fd9\u4e9b\u6761\u4ef6\u8868\u73b0\u4e3a\u5dee\u5206\u9690\u79c1\u98ce\u683c\u7684\u4e0d\u7b49\u5f0f\u3002\u5f15\u5165\u4e86(a,b)-\u5f71\u54cd\u66f2\u7ebf\u7684\u6982\u5ff5\uff0c\u5c06\u73b0\u6709\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u8f6c\u6362\u4e3a\u53ef\u7ec4\u5408\u7684Pufferfish\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u901a\u8fc7\u6dfb\u52a0\u5dee\u5206\u9690\u79c1\u5f0f\u6761\u4ef6\u53ef\u4ee5\u5b9e\u73b0Pufferfish\u7684\u7ebf\u6027\u7ec4\u5408\u3002\u5f00\u53d1\u4e86\u8f6c\u6362\u6846\u67b6\uff0c\u4f7f\u8bb8\u591a\u73b0\u6709\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u80fd\u591f\u8f6c\u6362\u4e3a\u53ef\u7ec4\u5408\u7684Pufferfish\u7b97\u6cd5\u3002\u4e3a\u9a6c\u5c14\u53ef\u592b\u94fe\u8bbe\u8ba1\u7684\u7b97\u6cd5\u663e\u8457\u4f18\u4e8e\u5148\u524d\u5de5\u4f5c\u3002", "conclusion": "\u8981\u5b9e\u73b0Pufferfish\u5bf9\u76f8\u5173\u6570\u636e\u7684\u53ef\u89e3\u91ca\u8bed\u4e49\u548c\u7ec4\u5408\u6027\u4f18\u52bf\uff0c\u9700\u8981\u91c7\u7528\u5dee\u5206\u9690\u79c1\u673a\u5236\u3002\u901a\u8fc7(a,b)-\u5f71\u54cd\u66f2\u7ebf\u6846\u67b6\uff0c\u53ef\u4ee5\u5c06\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u8f6c\u6362\u4e3a\u53ef\u7ec4\u5408\u7684Pufferfish\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u7ec4\u5408\u6027\u95ee\u9898\u3002"}}
{"id": "2602.03181", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03181", "abs": "https://arxiv.org/abs/2602.03181", "authors": ["Ziyue Hua", "Tianyu Chen", "Yeyun Gong", "Shuai Lu", "Peng Cheng", "Qinglin Zhu", "Yibo He", "Yingjie Fu", "Wenpin Jiao", "Wei Yang", "Tao Xie"], "title": "Synthesizing File-Level Data for Unit Test Generation with Chain-of-Thoughts via Self-Debugging", "comment": null, "summary": "Automatic unit test (UT) generation is essential for software quality assurance, but existing approaches--including symbolic execution, search-based approaches, and recent LLM-based generators--struggle to produce human-quality tests with correct, meaningful assertions and reliable chain-of-thought (CoT) explanations. We identify a gap in UT training data: repository-mined tests lack developer CoTs, while LLM-distilled CoTs are often incorrect or incomplete. To address this issue, we propose a novel data-distillation approach that uses self-debugging to produce high-quality UT training examples paired with faithful CoTs. Our approach combines (1) guided test repair, a heuristic loop (error-, failure-, and coverage-focused steps) that asks the used model to diagnose and iteratively fix generated tests, and (2) CoT compression, which compacts original and debugging CoTs into concise explanations that directly justify correct tests. We apply this pipeline to a large corpus of open-source projects to construct a dataset of 74,518 high-quality <focal method, test, CoT> examples, and then use it for supervised fine-tuning of a base model. An empirical evaluation shows that the fine-tuned model achieves high UT generation effectiveness: it attains a pass rate of 36.17% on test assertions, a branch coverage of 43.90%, and a mutation score of 88.66%, substantially higher than state-of-the-art commercial models like o4-mini.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u81ea\u8c03\u8bd5\u548cCoT\u538b\u7f29\u751f\u6210\u9ad8\u8d28\u91cf\u5355\u5143\u6d4b\u8bd5\u8bad\u7ec3\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u7684\u6548\u679c", "motivation": "\u73b0\u6709\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\uff08\u5305\u62ec\u7b26\u53f7\u6267\u884c\u3001\u57fa\u4e8e\u641c\u7d22\u7684\u65b9\u6cd5\u548cLLM\u751f\u6210\u5668\uff09\u96be\u4ee5\u751f\u6210\u5177\u6709\u6b63\u786e\u65ad\u8a00\u548c\u53ef\u9760\u601d\u7ef4\u94fe\u89e3\u91ca\u7684\u4eba\u7c7b\u8d28\u91cf\u6d4b\u8bd5\u3002\u73b0\u6709\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u7f3a\u9677\uff1a\u4ed3\u5e93\u6316\u6398\u7684\u6d4b\u8bd5\u7f3a\u4e4f\u5f00\u53d1\u8005\u601d\u7ef4\u94fe\uff0c\u800cLLM\u84b8\u998f\u7684\u601d\u7ef4\u94fe\u5f80\u5f80\u4e0d\u6b63\u786e\u6216\u4e0d\u5b8c\u6574\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6570\u636e\u84b8\u998f\u65b9\u6cd5\uff0c\u4f7f\u7528\u81ea\u8c03\u8bd5\u751f\u6210\u9ad8\u8d28\u91cf\u5355\u5143\u6d4b\u8bd5\u8bad\u7ec3\u793a\u4f8b\u53ca\u5176\u5bf9\u5e94\u7684\u5fe0\u5b9e\u601d\u7ef4\u94fe\u3002\u65b9\u6cd5\u5305\u62ec\uff1a(1) \u5f15\u5bfc\u6d4b\u8bd5\u4fee\u590d\u2014\u2014\u4e00\u4e2a\u542f\u53d1\u5f0f\u5faa\u73af\uff08\u9519\u8bef\u3001\u5931\u8d25\u548c\u8986\u76d6\u7387\u805a\u7126\u6b65\u9aa4\uff09\uff0c\u8981\u6c42\u6a21\u578b\u8bca\u65ad\u5e76\u8fed\u4ee3\u4fee\u590d\u751f\u6210\u7684\u6d4b\u8bd5\uff1b(2) \u601d\u7ef4\u94fe\u538b\u7f29\u2014\u2014\u5c06\u539f\u59cb\u548c\u8c03\u8bd5\u601d\u7ef4\u94fe\u538b\u7f29\u4e3a\u76f4\u63a5\u8bc1\u660e\u6b63\u786e\u6d4b\u8bd5\u7684\u7b80\u6d01\u89e3\u91ca\u3002", "result": "\u5728\u5f00\u6e90\u9879\u76ee\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u4e0a\u6784\u5efa\u4e86\u5305\u542b74,518\u4e2a\u9ad8\u8d28\u91cf<\u7126\u70b9\u65b9\u6cd5\u3001\u6d4b\u8bd5\u3001\u601d\u7ef4\u94fe>\u793a\u4f8b\u7684\u6570\u636e\u96c6\u3002\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff1a\u6d4b\u8bd5\u65ad\u8a00\u901a\u8fc7\u7387\u8fbe\u523036.17%\uff0c\u5206\u652f\u8986\u76d6\u7387\u8fbe\u523043.90%\uff0c\u53d8\u5f02\u6d4b\u8bd5\u5f97\u5206\u8fbe\u523088.66%\uff0c\u663e\u8457\u4f18\u4e8eo4-mini\u7b49\u6700\u5148\u8fdb\u7684\u5546\u4e1a\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u81ea\u8c03\u8bd5\u548c\u601d\u7ef4\u94fe\u538b\u7f29\u7684\u6570\u636e\u84b8\u998f\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5355\u5143\u6d4b\u8bd5\u8bad\u7ec3\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347LLM\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bad\u7ec3\u6570\u636e\u4e2d\u601d\u7ef4\u94fe\u8d28\u91cf\u4e0d\u8db3\u7684\u95ee\u9898\u3002"}}
{"id": "2602.02849", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02849", "abs": "https://arxiv.org/abs/2602.02849", "authors": ["Xi Yu", "Dmitrii Torbunov", "Soumyajit Mandal", "Yihui Ren"], "title": "AutoSizer: Automatic Sizing of Analog and Mixed-Signal Circuits via Large Language Model (LLM) Agents", "comment": null, "summary": "The design of Analog and Mixed-Signal (AMS) integrated circuits remains heavily reliant on expert knowledge, with transistor sizing a major bottleneck due to nonlinear behavior, high-dimensional design spaces, and strict performance constraints. Existing Electronic Design Automation (EDA) methods typically frame sizing as static black-box optimization, resulting in inefficient and less robust solutions. Although Large Language Models (LLMs) exhibit strong reasoning abilities, they are not suited for precise numerical optimization in AMS sizing. To address this gap, we propose AutoSizer, a reflective LLM-driven meta-optimization framework that unifies circuit understanding, adaptive search-space construction, and optimization orchestration in a closed loop. It employs a two-loop optimization framework, with an inner loop for circuit sizing and an outer loop that analyzes optimization dynamics and constraints to iteratively refine the search space from simulation feedback. We further introduce AMS-SizingBench, an open benchmark comprising 24 diverse AMS circuits in SKY130 CMOS technology, designed to evaluate adaptive optimization policies under realistic simulator-based constraints. AutoSizer experimentally achieves higher solution quality, faster convergence, and higher success rate across varying circuit difficulties, outperforming both traditional optimization methods and existing LLM-based agents.", "AI": {"tldr": "AutoSizer\uff1a\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53cd\u5c04\u5f0f\u5143\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u6a21\u62df\u6df7\u5408\u4fe1\u53f7\u96c6\u6210\u7535\u8def\u6676\u4f53\u7ba1\u5c3a\u5bf8\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u95ed\u73af\u7edf\u4e00\u7535\u8def\u7406\u89e3\u3001\u81ea\u9002\u5e94\u641c\u7d22\u7a7a\u95f4\u6784\u5efa\u548c\u4f18\u5316\u7f16\u6392\u3002", "motivation": "\u6a21\u62df\u6df7\u5408\u4fe1\u53f7\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u4e25\u91cd\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\uff0c\u6676\u4f53\u7ba1\u5c3a\u5bf8\u4f18\u5316\u9762\u4e34\u975e\u7ebf\u6027\u884c\u4e3a\u3001\u9ad8\u7ef4\u8bbe\u8ba1\u7a7a\u95f4\u548c\u4e25\u683c\u6027\u80fd\u7ea6\u675f\u7b49\u6311\u6218\u3002\u73b0\u6709EDA\u65b9\u6cd5\u5c06\u5c3a\u5bf8\u4f18\u5316\u89c6\u4e3a\u9759\u6001\u9ed1\u76d2\u4f18\u5316\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u4e14\u9c81\u68d2\u6027\u5dee\u3002\u5927\u8bed\u8a00\u6a21\u578b\u867d\u5177\u5907\u5f3a\u5927\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4e0d\u9002\u5408AMS\u5c3a\u5bf8\u7684\u7cbe\u786e\u6570\u503c\u4f18\u5316\u3002", "method": "\u63d0\u51faAutoSizer\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5faa\u73af\u4f18\u5316\u7ed3\u6784\uff1a\u5185\u5faa\u73af\u8d1f\u8d23\u7535\u8def\u5c3a\u5bf8\u4f18\u5316\uff0c\u5916\u5faa\u73af\u5206\u6790\u4f18\u5316\u52a8\u6001\u548c\u7ea6\u675f\uff0c\u6839\u636e\u4eff\u771f\u53cd\u9988\u8fed\u4ee3\u7cbe\u5316\u641c\u7d22\u7a7a\u95f4\u3002\u6846\u67b6\u7edf\u4e00\u4e86\u7535\u8def\u7406\u89e3\u3001\u81ea\u9002\u5e94\u641c\u7d22\u7a7a\u95f4\u6784\u5efa\u548c\u4f18\u5316\u7f16\u6392\uff0c\u5f62\u6210\u95ed\u73af\u7cfb\u7edf\u3002", "result": "\u5f00\u53d1\u4e86AMS-SizingBench\u5f00\u653e\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u5305\u542b24\u4e2a\u57fa\u4e8eSKY130 CMOS\u6280\u672f\u7684\u591a\u6837\u5316AMS\u7535\u8def\uff0c\u7528\u4e8e\u8bc4\u4f30\u771f\u5b9e\u4eff\u771f\u5668\u7ea6\u675f\u4e0b\u7684\u81ea\u9002\u5e94\u4f18\u5316\u7b56\u7565\u3002\u5b9e\u9a8c\u8868\u660eAutoSizer\u5728\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3001\u6536\u655b\u901f\u5ea6\u548c\u6210\u529f\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u548c\u73b0\u6709LLM\u667a\u80fd\u4f53\u3002", "conclusion": "AutoSizer\u6210\u529f\u5730\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u6570\u503c\u4f18\u5316\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u53cd\u5c04\u5f0f\u5143\u4f18\u5316\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86AMS\u7535\u8def\u5c3a\u5bf8\u4f18\u5316\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u7535\u8def\u96be\u5ea6\u7ea7\u522b\u4e0a\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u81ea\u52a8\u5316AMS\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.02862", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02862", "abs": "https://arxiv.org/abs/2602.02862", "authors": ["Eric Yang", "Jong Ha Lee", "Jonathan Amar", "Elissa Ye", "Yugang Jia"], "title": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search", "comment": "20 pages", "summary": "Large Language Models (LLMs) trained for average correctness often exhibit mode collapse, producing narrow decision behaviors on tasks where multiple responses may be reasonable. This limitation is particularly problematic in ordinal decision settings such as clinical triage, where standard alignment removes the ability to trade off specificity and sensitivity (the ROC operating point) based on contextual constraints. We propose STEER (Steerable Tuning via Evolutionary Ensemble Refinement), a training-free framework that reintroduces this tunable control. STEER constructs a population of natural-language personas through an offline, constrained quality-diversity search that promotes behavioral coverage while enforcing minimum safety, reasoning, and stability thresholds. At inference time, STEER exposes a single, interpretable control parameter that maps a user-specified risk percentile to a selected persona, yielding a monotonic adjustment of decision conservativeness. On two clinical triage benchmarks, STEER achieves broader behavioral coverage compared to temperature-based sampling and static persona ensembles. Compared to a representative post-training method, STEER maintains substantially higher accuracy on unambiguous urgent cases while providing comparable control over ambiguous decisions. These results demonstrate STEER as a safety-preserving paradigm for risk control, capable of steering behavior without compromising domain competence.", "AI": {"tldr": "STEER\u6846\u67b6\u901a\u8fc7\u8fdb\u5316\u96c6\u6210\u4f18\u5316\u5b9e\u73b0\u53ef\u8c03\u63a7\u7684LLM\u51b3\u7b56\uff0c\u5728\u4e34\u5e8a\u5206\u8bca\u7b49\u5e8f\u6570\u51b3\u7b56\u4efb\u52a1\u4e2d\u63d0\u4f9b\u5355\u8c03\u53ef\u8c03\u7684\u4fdd\u5b88\u6027\u63a7\u5236\uff0c\u540c\u65f6\u4fdd\u6301\u9886\u57df\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLM\u5728\u5e73\u5747\u6b63\u786e\u6027\u8bad\u7ec3\u4e0b\u5bb9\u6613\u51fa\u73b0\u6a21\u5f0f\u574d\u584c\uff0c\u5728\u9700\u8981\u6743\u8861\u654f\u611f\u6027\u548c\u7279\u5f02\u6027\u7684\u5e8f\u6570\u51b3\u7b56\u4efb\u52a1\uff08\u5982\u4e34\u5e8a\u5206\u8bca\uff09\u4e2d\u7f3a\u4e4f\u53ef\u8c03\u63a7\u6027\uff0c\u6807\u51c6\u5bf9\u9f50\u65b9\u6cd5\u79fb\u9664\u4e86\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7ea6\u675f\u8c03\u6574ROC\u64cd\u4f5c\u70b9\u7684\u80fd\u529b\u3002", "method": "STEER\uff08Steerable Tuning via Evolutionary Ensemble Refinement\uff09\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u7ebf\u7ea6\u675f\u8d28\u91cf\u591a\u6837\u6027\u641c\u7d22\u6784\u5efa\u81ea\u7136\u8bed\u8a00\u89d2\u8272\u7fa4\u4f53\uff0c\u5728\u4fdd\u8bc1\u6700\u4f4e\u5b89\u5168\u6027\u3001\u63a8\u7406\u80fd\u529b\u548c\u7a33\u5b9a\u6027\u9608\u503c\u7684\u540c\u65f6\u4fc3\u8fdb\u884c\u4e3a\u8986\u76d6\u3002\u63a8\u7406\u65f6\u901a\u8fc7\u5355\u4e2a\u53ef\u89e3\u91ca\u7684\u63a7\u5236\u53c2\u6570\u5c06\u7528\u6237\u6307\u5b9a\u7684\u98ce\u9669\u767e\u5206\u4f4d\u6570\u6620\u5c04\u5230\u9009\u5b9a\u89d2\u8272\uff0c\u5b9e\u73b0\u51b3\u7b56\u4fdd\u5b88\u6027\u7684\u5355\u8c03\u8c03\u6574\u3002", "result": "\u5728\u4e24\u4e2a\u4e34\u5e8a\u5206\u8bca\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSTEER\u76f8\u6bd4\u57fa\u4e8e\u6e29\u5ea6\u7684\u91c7\u6837\u548c\u9759\u6001\u89d2\u8272\u96c6\u6210\u5b9e\u73b0\u4e86\u66f4\u5e7f\u6cdb\u7684\u884c\u4e3a\u8986\u76d6\u3002\u4e0e\u4ee3\u8868\u6027\u540e\u8bad\u7ec3\u65b9\u6cd5\u76f8\u6bd4\uff0cSTEER\u5728\u660e\u786e\u7d27\u6025\u75c5\u4f8b\u4e0a\u4fdd\u6301\u663e\u8457\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5728\u6a21\u7cca\u51b3\u7b56\u4e0a\u63d0\u4f9b\u53ef\u6bd4\u7684\u8c03\u63a7\u80fd\u529b\u3002", "conclusion": "STEER\u4f5c\u4e3a\u4e00\u79cd\u4fdd\u6301\u5b89\u5168\u6027\u7684\u98ce\u9669\u63a7\u5236\u8303\u5f0f\uff0c\u80fd\u591f\u5728\u4e0d\u5f71\u54cd\u9886\u57df\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\u8c03\u63a7\u884c\u4e3a\uff0c\u4e3aLLM\u5728\u9700\u8981\u53ef\u8c03\u63a7\u51b3\u7b56\u7684\u573a\u666f\u4e2d\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03400", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03400", "abs": "https://arxiv.org/abs/2602.03400", "authors": ["Jintai Li", "Songqiang Chen", "Shuo Jin", "Xiaoyuan Xie"], "title": "Precision in Practice: Knowledge Guided Code Summarizing Grounded in Industrial Expectations", "comment": null, "summary": "Code summaries are essential for helping developers understand code functionality and reducing maintenance and collaboration costs. Although recent advances in large language models (LLMs) have significantly improved automatic code summarization, the practical usefulness of generated summaries in industrial settings remains insufficiently explored. In collaboration with documentation experts from the industrial HarmonyOS project, we conducted a questionnaire study showing that over 57.4% of code summaries produced by state-of-the-art approaches were rejected due to violations of developers' expectations for industrial documentation. Beyond semantic similarity to reference summaries, developers emphasize additional requirements, including the use of appropriate domain terminology, explicit function categorization, and the avoidance of redundant implementation details.\n  To address these expectations, we propose ExpSum, an expectation-aware code summarization approach that integrates function metadata abstraction, informative metadata filtering, context-aware domain knowledge retrieval, and constraint-driven prompting to guide LLMs in generating structured, expectation-aligned summaries. We evaluate ExpSum on the HarmonyOS project and widely used code summarization benchmarks. Experimental results show that ExpSum consistently outperforms all baselines, achieving improvements of up to 26.71% in BLEU-4 and 20.10% in ROUGE-L on HarmonyOS. Furthermore, LLM-based evaluations indicate that ExpSum-generated summaries better align with developer expectations across other projects, demonstrating its effectiveness for industrial code documentation.", "AI": {"tldr": "ExpSum\u662f\u4e00\u79cd\u9762\u5411\u5de5\u4e1a\u4ee3\u7801\u6587\u6863\u7684\u671f\u671b\u611f\u77e5\u4ee3\u7801\u6458\u8981\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u51fd\u6570\u5143\u6570\u636e\u62bd\u8c61\u3001\u4fe1\u606f\u8fc7\u6ee4\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u9886\u57df\u77e5\u8bc6\u68c0\u7d22\u548c\u7ea6\u675f\u9a71\u52a8\u63d0\u793a\uff0c\u751f\u6210\u7b26\u5408\u5f00\u53d1\u8005\u671f\u671b\u7684\u7ed3\u6784\u5316\u6458\u8981\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u6458\u8981\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u751f\u6210\u7684\u6458\u8981\u5b9e\u7528\u6027\u4e0d\u8db3\u3002\u7814\u7a76\u8868\u660e\u8d85\u8fc757.4%\u7684\u73b0\u6709\u65b9\u6cd5\u751f\u6210\u7684\u6458\u8981\u56e0\u4e0d\u7b26\u5408\u5f00\u53d1\u8005\u5bf9\u5de5\u4e1a\u6587\u6863\u7684\u671f\u671b\u800c\u88ab\u62d2\u7edd\uff0c\u5f00\u53d1\u8005\u9700\u8981\u9002\u5f53\u7684\u9886\u57df\u672f\u8bed\u3001\u660e\u786e\u7684\u51fd\u6570\u5206\u7c7b\uff0c\u5e76\u907f\u514d\u5197\u4f59\u5b9e\u73b0\u7ec6\u8282\u3002", "method": "\u63d0\u51faExpSum\u65b9\u6cd5\uff0c\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u51fd\u6570\u5143\u6570\u636e\u62bd\u8c61\uff0c2) \u4fe1\u606f\u5143\u6570\u636e\u8fc7\u6ee4\uff0c3) \u4e0a\u4e0b\u6587\u611f\u77e5\u9886\u57df\u77e5\u8bc6\u68c0\u7d22\uff0c4) \u7ea6\u675f\u9a71\u52a8\u63d0\u793a\uff0c\u6307\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7ed3\u6784\u5316\u3001\u7b26\u5408\u671f\u671b\u7684\u4ee3\u7801\u6458\u8981\u3002", "result": "\u5728HarmonyOS\u9879\u76ee\u4e0a\uff0cExpSum\u76f8\u6bd4\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\uff0cBLEU-4\u63d0\u5347\u9ad8\u8fbe26.71%\uff0cROUGE-L\u63d0\u534720.10%\u3002\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u8868\u660e\uff0cExpSum\u751f\u6210\u7684\u6458\u8981\u5728\u5176\u4ed6\u9879\u76ee\u4e2d\u4e5f\u66f4\u597d\u5730\u7b26\u5408\u5f00\u53d1\u8005\u671f\u671b\u3002", "conclusion": "ExpSum\u901a\u8fc7\u6574\u5408\u5f00\u53d1\u8005\u671f\u671b\u7684\u5173\u952e\u8981\u7d20\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5de5\u4e1a\u4ee3\u7801\u6587\u6863\u7684\u8d28\u91cf\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u4ee3\u7801\u6458\u8981\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03040", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.03040", "abs": "https://arxiv.org/abs/2602.03040", "authors": ["Xiaozuo Shen", "Yifei Cai", "Rui Ning", "Chunsheng Xin", "Hongyi Wu"], "title": "DF-LoGiT: Data-Free Logic-Gated Backdoor Attacks in Vision Transformers", "comment": null, "summary": "The widespread adoption of Vision Transformers (ViTs) elevates supply-chain risk on third-party model hubs, where an adversary can implant backdoors into released checkpoints. Existing ViT backdoor attacks largely rely on poisoned-data training, while prior data-free attempts typically require synthetic-data fine-tuning or extra model components. This paper introduces Data-Free Logic-Gated Backdoor Attacks (DF-LoGiT), a truly data-free backdoor attack on ViTs via direct weight editing. DF-LoGiT exploits ViT's native multi-head architecture to realize a logic-gated compositional trigger, enabling a stealthy and effective backdoor. We validate its effectiveness through theoretical analysis and extensive experiments, showing that DF-LoGiT achieves near-100% attack success with negligible degradation in benign accuracy and remains robust against representative classical and ViT-specific defenses.", "AI": {"tldr": "DF-LoGiT\u662f\u4e00\u79cd\u9488\u5bf9Vision Transformers\u7684\u65e0\u6570\u636e\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u6743\u91cd\u7f16\u8f91\u5b9e\u73b0\u903b\u8f91\u95e8\u63a7\u7ec4\u5408\u89e6\u53d1\u5668\uff0c\u65e0\u9700\u8bad\u7ec3\u6570\u636e\u6216\u989d\u5916\u6a21\u578b\u7ec4\u4ef6\u3002", "motivation": "\u968f\u7740Vision Transformers\u7684\u5e7f\u6cdb\u4f7f\u7528\uff0c\u7b2c\u4e09\u65b9\u6a21\u578b\u4e2d\u5fc3\u5b58\u5728\u4f9b\u5e94\u94fe\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u5728\u53d1\u5e03\u7684\u68c0\u67e5\u70b9\u4e2d\u690d\u5165\u540e\u95e8\u3002\u73b0\u6709ViT\u540e\u95e8\u653b\u51fb\u4e3b\u8981\u4f9d\u8d56\u4e2d\u6bd2\u6570\u636e\u8bad\u7ec3\uff0c\u800c\u65e0\u6570\u636e\u653b\u51fb\u901a\u5e38\u9700\u8981\u5408\u6210\u6570\u636e\u5fae\u8c03\u6216\u989d\u5916\u6a21\u578b\u7ec4\u4ef6\u3002", "method": "DF-LoGiT\u5229\u7528ViT\u539f\u751f\u591a\u5934\u67b6\u6784\u5b9e\u73b0\u903b\u8f91\u95e8\u63a7\u7ec4\u5408\u89e6\u53d1\u5668\uff0c\u901a\u8fc7\u76f4\u63a5\u6743\u91cd\u7f16\u8f91\u5b9e\u73b0\u771f\u6b63\u7684\u65e0\u6570\u636e\u540e\u95e8\u653b\u51fb\uff0c\u65e0\u9700\u8bad\u7ec3\u6570\u636e\u6216\u989d\u5916\u6a21\u578b\u7ec4\u4ef6\u3002", "result": "DF-LoGiT\u5b9e\u73b0\u4e86\u63a5\u8fd1100%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u5bf9\u826f\u6027\u51c6\u786e\u7387\u5f71\u54cd\u6781\u5c0f\uff0c\u5e76\u80fd\u62b5\u6297\u7ecf\u5178\u548cViT\u7279\u5b9a\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "DF-LoGiT\u662f\u4e00\u79cd\u6709\u6548\u3001\u9690\u853d\u4e14\u9c81\u68d2\u7684\u65e0\u6570\u636e\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u4e3aViT\u6a21\u578b\u7684\u5b89\u5168\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2602.03462", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03462", "abs": "https://arxiv.org/abs/2602.03462", "authors": ["Ruwei Pan", "Yakun Zhang", "Qingyuan Liang", "Yueheng Zhu", "Chao Liu", "Lu Zhang", "Hongyu Zhang"], "title": "RAL-Bench: Benchmarking for Application-Level Functional Correctness and Non-Functional Quality Attributes", "comment": null, "summary": "Code generation has advanced rapidly with code-focused large language models (LLMs), especially on snippet-level tasks. However, application-level generation requires producing a runnable multi-file repository with correct structure, dependencies, and end-to-end executability, and real-world software must satisfy both functional correctness and non-functional quality (e.g., maintainability, security). Existing benchmarks provide a limited execution-based assessment of these requirements at the application level. We ask: Can current LLMs generate application-level repositories that meet both functional and non-functional criteria? We propose RAL-Bench, a benchmark and evaluation framework for application-level code generation. For each task, we distill a concise natural-language requirement from a high-quality reference project, build black-box system tests covering functional and non-functional attributes, and keep only tests that pass on the reference repository to ensure a sound oracle and an end-to-end executable suite. Functional correctness is measured by system-test pass rate. Non-functional quality is measured along five ISO/IEC 25010-inspired dimensions and aggregated with an Analytic Hierarchy Process (AHP)-derived weight vector, with per-dimension diagnostics and baseline-normalized scoring using reference measurements. Across 16 LLMs evaluated zero-shot with greedy decoding, functional correctness is the dominant bottleneck: no model exceeds a 45% functional pass rate under our requirement-driven, reference-validated tests. We release RAL-Bench at https://github.com/Wwstarry/RAL-Bench. .", "AI": {"tldr": "RAL-Bench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6d4b\u8bd5\u8bc4\u4f30\u529f\u80fd\u6b63\u786e\u6027\u548c\u975e\u529f\u80fd\u6027\u8d28\u91cf\uff0c\u53d1\u73b0\u5f53\u524dLLMs\u5728\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u529f\u80fd\u6b63\u786e\u6027\u662f\u4e3b\u8981\u74f6\u9888\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u65b9\u9762\u6709\u9650\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u529f\u80fd\u6b63\u786e\u6027\u548c\u975e\u529f\u80fd\u6027\u8d28\u91cf\uff08\u5982\u53ef\u7ef4\u62a4\u6027\u3001\u5b89\u5168\u6027\uff09\u3002\u9700\u8981\u4e86\u89e3\u5f53\u524dLLMs\u662f\u5426\u80fd\u751f\u6210\u6ee1\u8db3\u8fd9\u4e24\u65b9\u9762\u8981\u6c42\u7684\u5e94\u7528\u7ea7\u4ee3\u7801\u5e93\u3002", "method": "\u63d0\u51faRAL-Bench\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff1a1\uff09\u4ece\u9ad8\u8d28\u91cf\u53c2\u8003\u9879\u76ee\u4e2d\u63d0\u70bc\u7b80\u6d01\u7684\u81ea\u7136\u8bed\u8a00\u9700\u6c42\uff1b2\uff09\u6784\u5efa\u8986\u76d6\u529f\u80fd\u548c\u975e\u529f\u80fd\u5c5e\u6027\u7684\u9ed1\u76d2\u7cfb\u7edf\u6d4b\u8bd5\uff1b3\uff09\u4ec5\u4fdd\u7559\u5728\u53c2\u8003\u4ed3\u5e93\u4e2d\u901a\u8fc7\u7684\u6d4b\u8bd5\u4ee5\u786e\u4fdd\u53ef\u9760\u57fa\u51c6\uff1b4\uff09\u529f\u80fd\u6b63\u786e\u6027\u901a\u8fc7\u7cfb\u7edf\u6d4b\u8bd5\u901a\u8fc7\u7387\u8861\u91cf\uff1b5\uff09\u975e\u529f\u80fd\u6027\u8d28\u91cf\u57fa\u4e8eISO/IEC 25010\u4e94\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\uff0c\u4f7f\u7528AHP\u6743\u91cd\u5411\u91cf\u805a\u5408\uff0c\u5e76\u8fdb\u884c\u57fa\u7ebf\u5f52\u4e00\u5316\u8bc4\u5206\u3002", "result": "\u8bc4\u4f30\u4e8616\u4e2aLLMs\u7684\u96f6\u6837\u672c\u8d2a\u5a6a\u89e3\u7801\u7ed3\u679c\uff1a\u529f\u80fd\u6b63\u786e\u6027\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u6ca1\u6709\u6a21\u578b\u5728\u9700\u6c42\u9a71\u52a8\u3001\u53c2\u8003\u9a8c\u8bc1\u7684\u6d4b\u8bd5\u4e0b\u8d85\u8fc745%\u7684\u529f\u80fd\u901a\u8fc7\u7387\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u529f\u80fd\u6b63\u786e\u6027\u4ecd\u7136\u662f\u4e3b\u8981\u6311\u6218\uff0cRAL-Bench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u8bc4\u4f30\u529f\u80fd\u6b63\u786e\u6027\u548c\u975e\u529f\u80fd\u6027\u8d28\u91cf\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u7814\u7a76\u3002"}}
{"id": "2602.03550", "categories": ["cs.SE", "cs.FL", "cs.LO", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.03550", "abs": "https://arxiv.org/abs/2602.03550", "authors": ["Fang Yan", "Simon Foster", "Ana Cavalcanti", "Ibrahim Habli", "James Baxter"], "title": "Formal Evidence Generation for Assurance Cases for Robotic Software Models", "comment": "This is a preprint. The paper is currently under review at Software and Systems Modeling", "summary": "Robotics and Autonomous Systems are increasingly deployed in safety-critical domains, so that demonstrating their safety is essential. Assurance Cases (ACs) provide structured arguments supported by evidence, but generating and maintaining this evidence is labour-intensive, error-prone, and difficult to keep consistent as systems evolve. We present a model-based approach to systematically generating AC evidence by embedding formal verification into the assurance workflow. The approach addresses three challenges: systematically deriving formal assertions from natural language requirements using templates, orchestrating multiple formal verification tools to handle diverse property types, and integrating formal evidence production into the workflow. Leveraging RoboChart, a domain-specific modelling language with formal semantics, we combine model checking and theorem proving in our approach. Structured requirements are automatically transformed into formal assertions using predefined templates, and verification results are automatically integrated as evidence. Case studies demonstrate the effectiveness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u7684\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5d4c\u5165\u5230\u4fdd\u8bc1\u5de5\u4f5c\u6d41\u4e2d\uff0c\u81ea\u52a8\u751f\u6210\u4fdd\u8bc1\u6848\u4f8b\u8bc1\u636e\uff0c\u89e3\u51b3\u8bc1\u636e\u751f\u6210\u548c\u7ef4\u62a4\u7684\u6311\u6218", "motivation": "\u673a\u5668\u4eba\u548c\u81ea\u4e3b\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u90e8\u7f72\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\uff0c\u9700\u8981\u8bc1\u660e\u5176\u5b89\u5168\u6027\u3002\u4fdd\u8bc1\u6848\u4f8b\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u8bba\u8bc1\uff0c\u4f46\u8bc1\u636e\u7684\u751f\u6210\u548c\u7ef4\u62a4\u52b3\u52a8\u5bc6\u96c6\u3001\u5bb9\u6613\u51fa\u9519\uff0c\u4e14\u968f\u7740\u7cfb\u7edf\u6f14\u5316\u96be\u4ee5\u4fdd\u6301\u4e00\u81f4\u6027", "method": "\u4f7f\u7528\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408RoboChart\u9886\u57df\u7279\u5b9a\u5efa\u6a21\u8bed\u8a00\uff0c\u901a\u8fc7\u6a21\u677f\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u7cfb\u7edf\u5316\u5730\u8f6c\u5316\u4e3a\u5f62\u5f0f\u5316\u65ad\u8a00\uff0c\u534f\u8c03\u591a\u79cd\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\u5904\u7406\u4e0d\u540c\u5c5e\u6027\u7c7b\u578b\uff0c\u5e76\u5c06\u5f62\u5f0f\u5316\u8bc1\u636e\u751f\u4ea7\u96c6\u6210\u5230\u5de5\u4f5c\u6d41\u4e2d", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u591f\u81ea\u52a8\u5c06\u7ed3\u6784\u5316\u9700\u6c42\u8f6c\u5316\u4e3a\u5f62\u5f0f\u5316\u65ad\u8a00\uff0c\u5e76\u81ea\u52a8\u5c06\u9a8c\u8bc1\u7ed3\u679c\u6574\u5408\u4e3a\u8bc1\u636e", "conclusion": "\u63d0\u51fa\u7684\u6a21\u578b\u5316\u65b9\u6cd5\u80fd\u591f\u7cfb\u7edf\u5316\u5730\u751f\u6210\u4fdd\u8bc1\u6848\u4f8b\u8bc1\u636e\uff0c\u901a\u8fc7\u5c06\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5d4c\u5165\u5230\u4fdd\u8bc1\u5de5\u4f5c\u6d41\u4e2d\uff0c\u89e3\u51b3\u4e86\u8bc1\u636e\u751f\u6210\u548c\u7ef4\u62a4\u7684\u6311\u6218"}}
{"id": "2602.02909", "categories": ["cs.AI", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02909", "abs": "https://arxiv.org/abs/2602.02909", "authors": ["Kiran Tomlinson", "Tobias Schnabel", "Adith Swaminathan", "Jennifer Neville"], "title": "Reasoning about Reasoning: BAPO Bounds on Chain-of-Thought Token Complexity in LLMs", "comment": "28 pages", "summary": "Inference-time scaling via chain-of-thought (CoT) reasoning is a major driver of state-of-the-art LLM performance, but it comes with substantial latency and compute costs. We address a fundamental theoretical question: how many reasoning tokens are required to solve a problem as input size grows? By extending the bounded attention prefix oracle (BAPO) model--an abstraction of LLMs that quantifies the information flow required to solve a task--we prove lower bounds on the CoT tokens required for three canonical BAPO-hard tasks: binary majority, triplet matching, and graph reachability. We show that each requires $\u03a9(n)$ reasoning tokens when the input size is $n$. We complement these results with matching or near-matching upper bounds via explicit constructions. Finally, our experiments with frontier reasoning models show approximately linear reasoning token scaling on these tasks and failures when constrained to smaller reasoning budgets, consistent with our theoretical lower bounds. Together, our results identify fundamental bottlenecks in inference-time compute through CoT and offer a principled tool for analyzing optimal reasoning length.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u601d\u7ef4\u94fe\u63a8\u7406\u6240\u9700\u7684\u8ba1\u7b97\u91cf\uff0c\u8bc1\u660e\u4e86\u4e09\u4e2a\u5178\u578b\u4efb\u52a1\u9700\u8981\u03a9(n)\u4e2a\u63a8\u7406token\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u4e0b\u754c", "motivation": "\u601d\u7ef4\u94fe\u63a8\u7406\u867d\u7136\u80fd\u63d0\u5347LLM\u6027\u80fd\uff0c\u4f46\u5e26\u6765\u4e86\u663e\u8457\u7684\u5ef6\u8fdf\u548c\u8ba1\u7b97\u6210\u672c\u3002\u9700\u8981\u4ece\u7406\u8bba\u4e0a\u7406\u89e3\u968f\u7740\u8f93\u5165\u89c4\u6a21\u589e\u957f\uff0c\u89e3\u51b3\u4e00\u4e2a\u95ee\u9898\u9700\u8981\u591a\u5c11\u63a8\u7406token", "method": "\u6269\u5c55\u4e86\u6709\u754c\u6ce8\u610f\u529b\u524d\u7f00\u9884\u8a00\u673a\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u4e09\u4e2aBAPO-hard\u4efb\u52a1\uff08\u4e8c\u8fdb\u5236\u591a\u6570\u3001\u4e09\u5143\u7ec4\u5339\u914d\u3001\u56fe\u53ef\u8fbe\u6027\uff09\u7684\u63a8\u7406token\u4e0b\u754c\uff0c\u5e76\u901a\u8fc7\u663e\u5f0f\u6784\u9020\u7ed9\u51fa\u4e86\u5339\u914d\u6216\u63a5\u8fd1\u5339\u914d\u7684\u4e0a\u754c\uff0c\u6700\u540e\u7528\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1", "result": "\u8bc1\u660e\u4e86\u4e09\u4e2a\u4efb\u52a1\u90fd\u9700\u8981\u03a9(n)\u4e2a\u63a8\u7406token\uff0c\u5b9e\u9a8c\u663e\u793a\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8fd1\u4f3c\u7ebf\u6027\u7684\u63a8\u7406token\u7f29\u653e\uff0c\u5f53\u63a8\u7406\u9884\u7b97\u53d7\u9650\u65f6\u4f1a\u5931\u8d25\uff0c\u4e0e\u7406\u8bba\u4e0b\u754c\u4e00\u81f4", "conclusion": "\u7814\u7a76\u8bc6\u522b\u4e86\u901a\u8fc7\u601d\u7ef4\u94fe\u8fdb\u884c\u63a8\u7406\u65f6\u8ba1\u7b97\u7684\u57fa\u672c\u74f6\u9888\uff0c\u4e3a\u5206\u6790\u6700\u4f18\u63a8\u7406\u957f\u5ea6\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u5de5\u5177"}}
{"id": "2602.03556", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03556", "abs": "https://arxiv.org/abs/2602.03556", "authors": ["Alexander Berndt", "Thomas Bach", "Sebastian Baltes"], "title": "Flaky Tests in a Large Industrial Database Management System: An Empirical Study of Fixed Issue Reports for SAP HANA", "comment": "8 pages, 2 tables, 5 figures, 3rd International Flaky Tests Workshop 2026 (FTW 2026)", "summary": "Flaky tests yield different results when executed multiple times for the same version of the source code. Thus, they provide an ambiguous signal about the quality of the code and interfere with the automated assessment of code changes. While a variety of factors can cause test flakiness, approaches to fix flaky tests are typically tailored to address specific causes. However, the prevalent root causes of flaky tests can vary depending on the programming language, application domain, or size of the software project. Since manually labeling flaky tests is time-consuming and tedious, this work proposes an LLMs-as-annotators approach that leverages intra- and inter-model consistency to label issue reports related to fixed flakiness issues with the relevant root cause category. This allows us to gain an overview of prevalent flakiness categories in the issue reports. We evaluated our labeling approach in the context of SAP HANA, a large industrial database management system. Our results suggest that SAP HANA's tests most commonly suffer from issues related to concurrency (23%, 130 of 559 analyzed issue reports). Moreover, our results suggest that different test types face different flakiness challenges. Therefore, we encourage future research on flakiness mitigation to consider evaluating the generalizability of proposed approaches across different test types.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528LLMs\u4f5c\u4e3a\u6807\u6ce8\u8005\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u5185\u548c\u6a21\u578b\u95f4\u4e00\u81f4\u6027\u6765\u81ea\u52a8\u6807\u6ce8\u4e0e\u5df2\u4fee\u590d\u7684flaky\u6d4b\u8bd5\u76f8\u5173\u7684\u6839\u672c\u539f\u56e0\u7c7b\u522b\uff0c\u4ece\u800c\u5206\u6790SAP HANA\u4e2dflaky\u6d4b\u8bd5\u7684\u5206\u5e03\u60c5\u51b5\u3002", "motivation": "Flaky\u6d4b\u8bd5\u5728\u591a\u6b21\u6267\u884c\u76f8\u540c\u6e90\u4ee3\u7801\u65f6\u4f1a\u4ea7\u751f\u4e0d\u540c\u7ed3\u679c\uff0c\u8fd9\u4e3a\u4ee3\u7801\u8d28\u91cf\u63d0\u4f9b\u4e86\u6a21\u7cca\u4fe1\u53f7\u5e76\u5e72\u6270\u4e86\u4ee3\u7801\u53d8\u66f4\u7684\u81ea\u52a8\u8bc4\u4f30\u3002\u867d\u7136\u591a\u79cd\u56e0\u7d20\u53ef\u80fd\u5bfc\u81f4\u6d4b\u8bd5flakiness\uff0c\u4f46\u4fee\u590d\u65b9\u6cd5\u901a\u5e38\u9488\u5bf9\u7279\u5b9a\u539f\u56e0\u3002\u7531\u4e8e\u624b\u52a8\u6807\u6ce8flaky\u6d4b\u8bd5\u8017\u65f6\u4e14\u7e41\u7410\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u6765\u5206\u6790\u4e0d\u540c\u9879\u76ee\u4e2dflaky\u6d4b\u8bd5\u7684\u6839\u672c\u539f\u56e0\u5206\u5e03\u3002", "method": "\u63d0\u51faLLMs-as-annotators\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u5185\u548c\u6a21\u578b\u95f4\u4e00\u81f4\u6027\u6765\u6807\u6ce8\u4e0e\u5df2\u4fee\u590d\u7684flakiness\u95ee\u9898\u76f8\u5173\u7684issue\u62a5\u544a\u7684\u6839\u672c\u539f\u56e0\u7c7b\u522b\u3002\u8be5\u65b9\u6cd5\u5728SAP HANA\u8fd9\u4e00\u5927\u578b\u5de5\u4e1a\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u80cc\u666f\u4e0b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5206\u6790\u4e86559\u4e2aissue\u62a5\u544a\u3002", "result": "\u5206\u6790\u7ed3\u679c\u663e\u793a\uff0cSAP HANA\u7684\u6d4b\u8bd5\u6700\u5e38\u89c1\u7684\u95ee\u9898\u4e0e\u5e76\u53d1\u76f8\u5173\uff0823%\uff0c559\u4e2a\u5206\u6790\u7684\u95ee\u9898\u62a5\u544a\u4e2d\u6709130\u4e2a\uff09\u3002\u6b64\u5916\uff0c\u4e0d\u540c\u6d4b\u8bd5\u7c7b\u578b\u9762\u4e34\u4e0d\u540c\u7684flakiness\u6311\u6218\uff0c\u8868\u660eflakiness\u7684\u6839\u672c\u539f\u56e0\u5206\u5e03\u56e0\u6d4b\u8bd5\u7c7b\u578b\u800c\u5f02\u3002", "conclusion": "LLMs-as-annotators\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u81ea\u52a8\u6807\u6ce8flaky\u6d4b\u8bd5\u7684\u6839\u672c\u539f\u56e0\uff0c\u4e3a\u7406\u89e3\u5de5\u4e1a\u7cfb\u7edf\u4e2dflakiness\u7684\u5206\u5e03\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002\u7814\u7a76\u9f13\u52b1\u672a\u6765\u5173\u4e8eflakiness\u7f13\u89e3\u7684\u7814\u7a76\u5e94\u8003\u8651\u8bc4\u4f30\u6240\u63d0\u65b9\u6cd5\u5728\u4e0d\u540c\u6d4b\u8bd5\u7c7b\u578b\u95f4\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.03271", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.03271", "abs": "https://arxiv.org/abs/2602.03271", "authors": ["Jiaqi Gao", "Zijian Zhang", "Yuqiang Sun", "Ye Liu", "Chengwei Liu", "Han Liu", "Yi Li", "Yang Liu"], "title": "LogicScan: An LLM-driven Framework for Detecting Business Logic Vulnerabilities in Smart Contracts", "comment": null, "summary": "Business logic vulnerabilities have become one of the most damaging yet least understood classes of smart contract vulnerabilities. Unlike traditional bugs such as reentrancy or arithmetic errors, these vulnerabilities arise from missing or incorrectly enforced business invariants and are tightly coupled with protocol semantics. Existing static analysis techniques struggle to capture such high-level logic, while recent large language model based approaches often suffer from unstable outputs and low accuracy due to hallucination and limited verification.\n  In this paper, we propose LogicScan, an automated contrastive auditing framework for detecting business logic vulnerabilities in smart contracts. The key insight behind LogicScan is that mature, widely deployed on-chain protocols implicitly encode well-tested and consensus-driven business invariants. LogicScan systematically mines these invariants from large-scale on-chain contracts and reuses them as reference constraints to audit target contracts. To achieve this, LogicScan introduces a Business Specification Language (BSL) to normalize diverse implementation patterns into structured, verifiable logic representations. It further combines noise-aware logic aggregation with contrastive auditing to identify missing or weakly enforced invariants while mitigating LLM-induced false positives.\n  We evaluate LogicScan on three real-world datasets, including DeFiHacks, Web3Bugs, and a set of top-200 audited contracts. The results show that LogicScan achieves an F1 score of 85.2%, significantly outperforming state-of-the-art tools while maintaining a low false-positive rate on production-grade contracts. Additional experiments demonstrate that LogicScan maintains consistent performance across different LLMs and is cost-effective, and that its false-positive suppression mechanisms substantially improve robustness.", "AI": {"tldr": "LogicScan\u662f\u4e00\u4e2a\u7528\u4e8e\u68c0\u6d4b\u667a\u80fd\u5408\u7ea6\u4e1a\u52a1\u903b\u8f91\u6f0f\u6d1e\u7684\u81ea\u52a8\u5316\u5bf9\u6bd4\u5ba1\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u6210\u719f\u94fe\u4e0a\u534f\u8bae\u6316\u6398\u4e1a\u52a1\u4e0d\u53d8\u91cf\u4f5c\u4e3a\u53c2\u8003\u7ea6\u675f\uff0c\u7ed3\u5408\u4e1a\u52a1\u89c4\u8303\u8bed\u8a00\u548c\u566a\u58f0\u611f\u77e5\u903b\u8f91\u805a\u5408\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "motivation": "\u4e1a\u52a1\u903b\u8f91\u6f0f\u6d1e\u5df2\u6210\u4e3a\u667a\u80fd\u5408\u7ea6\u4e2d\u6700\u5177\u7834\u574f\u6027\u4f46\u6700\u4e0d\u88ab\u7406\u89e3\u7684\u6f0f\u6d1e\u7c7b\u522b\u3002\u73b0\u6709\u9759\u6001\u5206\u6790\u6280\u672f\u96be\u4ee5\u6355\u6349\u8fd9\u79cd\u9ad8\u5c42\u903b\u8f91\uff0c\u800c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u56e0\u5e7b\u89c9\u548c\u6709\u9650\u9a8c\u8bc1\u5bfc\u81f4\u8f93\u51fa\u4e0d\u7a33\u5b9a\u3001\u51c6\u786e\u7387\u4f4e\u3002", "method": "\u63d0\u51faLogicScan\u6846\u67b6\uff0c\u6838\u5fc3\u6d1e\u5bdf\u662f\u4ece\u6210\u719f\u3001\u5e7f\u6cdb\u90e8\u7f72\u7684\u94fe\u4e0a\u534f\u8bae\u4e2d\u6316\u6398\u9690\u542b\u7684\u7ecf\u8fc7\u826f\u597d\u6d4b\u8bd5\u548c\u5171\u8bc6\u9a71\u52a8\u7684\u4e1a\u52a1\u4e0d\u53d8\u91cf\uff0c\u5c06\u5176\u4f5c\u4e3a\u53c2\u8003\u7ea6\u675f\u6765\u5ba1\u8ba1\u76ee\u6807\u5408\u7ea6\u3002\u5f15\u5165\u4e1a\u52a1\u89c4\u8303\u8bed\u8a00(BSL)\u5c06\u4e0d\u540c\u5b9e\u73b0\u6a21\u5f0f\u89c4\u8303\u5316\u4e3a\u7ed3\u6784\u5316\u3001\u53ef\u9a8c\u8bc1\u7684\u903b\u8f91\u8868\u793a\uff0c\u7ed3\u5408\u566a\u58f0\u611f\u77e5\u903b\u8f91\u805a\u5408\u4e0e\u5bf9\u6bd4\u5ba1\u8ba1\u6765\u8bc6\u522b\u7f3a\u5931\u6216\u5f31\u6267\u884c\u7684\u4e0d\u53d8\u91cf\uff0c\u540c\u65f6\u51cf\u8f7bLLM\u5f15\u8d77\u7684\u8bef\u62a5\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6(DeFiHacks\u3001Web3Bugs\u548ctop-200\u5ba1\u8ba1\u5408\u7ea6)\u4e0a\u8bc4\u4f30\uff0cLogicScan\u8fbe\u523085.2%\u7684F1\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u5de5\u5177\uff0c\u540c\u65f6\u5728\u751f\u4ea7\u7ea7\u5408\u7ea6\u4e0a\u4fdd\u6301\u4f4e\u8bef\u62a5\u7387\u3002\u989d\u5916\u5b9e\u9a8c\u8868\u660eLogicScan\u5728\u4e0d\u540cLLM\u4e0a\u4fdd\u6301\u4e00\u81f4\u6027\u6027\u80fd\uff0c\u5177\u6709\u6210\u672c\u6548\u76ca\uff0c\u5176\u8bef\u62a5\u6291\u5236\u673a\u5236\u663e\u8457\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "conclusion": "LogicScan\u901a\u8fc7\u4ece\u6210\u719f\u94fe\u4e0a\u534f\u8bae\u6316\u6398\u4e1a\u52a1\u4e0d\u53d8\u91cf\u4f5c\u4e3a\u53c2\u8003\u7ea6\u675f\uff0c\u7ed3\u5408\u4e1a\u52a1\u89c4\u8303\u8bed\u8a00\u548c\u5bf9\u6bd4\u5ba1\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u667a\u80fd\u5408\u7ea6\u4e1a\u52a1\u903b\u8f91\u6f0f\u6d1e\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u5728\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2602.03557", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03557", "abs": "https://arxiv.org/abs/2602.03557", "authors": ["Yunhao Liang", "Ruixuan Ying", "Shiwen Ni", "Zhe Cui"], "title": "Scaling Test-Driven Code Generation from Functions to Classes: An Empirical Study", "comment": null, "summary": "Test-driven development (TDD) has been adopted to improve Large Language Model (LLM)-based code generation by using tests as executable specifications. However, existing TDD-style code generation studies are largely limited to function-level tasks, leaving class-level synthesis where multiple methods interact through shared state and call dependencies underexplored. In this paper, we scale test-driven code generation from functions to classes via an iterative TDD framework. Our approach first analyzes intra-class method dependencies to derive a feasible generation schedule, and then incrementally implements each method under method-level public tests with reflection-style execution feedback and bounded repair iterations. To support test-driven generation and rigorous class-level evaluation, we construct ClassEval-TDD, a cleaned and standardized variant of ClassEval with consistent specifications, deterministic test environments, and complete method-level public tests. We conduct an empirical study across eight LLMs and compare against the strongest direct-generation baseline (the best of holistic, incremental, and compositional strategies). Our class-level TDD framework consistently improves class-level correctness by 12 to 26 absolute points and achieves up to 71% fully correct classes, while requiring only a small number of repairs on average. These results demonstrate that test-driven generation can effectively scale beyond isolated functions and substantially improve class-level code generation reliability. All code and data are available at https://anonymous.4open.science/r/ClassEval-TDD-C4C9/", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1(TDD)\u4ece\u51fd\u6570\u7ea7\u4ee3\u7801\u751f\u6210\u6269\u5c55\u5230\u7c7b\u7ea7\uff0c\u901a\u8fc7\u8fed\u4ee3\u6846\u67b6\u5206\u6790\u7c7b\u5185\u65b9\u6cd5\u4f9d\u8d56\u5173\u7cfb\uff0c\u9010\u6b65\u751f\u6210\u65b9\u6cd5\u5e76\u5229\u7528\u6d4b\u8bd5\u53cd\u9988\u8fdb\u884c\u4fee\u590d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7c7b\u7ea7\u4ee3\u7801\u751f\u6210\u7684\u6b63\u786e\u7387\u3002", "motivation": "\u73b0\u6709TDD\u98ce\u683c\u7684\u4ee3\u7801\u751f\u6210\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u51fd\u6570\u7ea7\u4efb\u52a1\uff0c\u800c\u7c7b\u7ea7\u5408\u6210\u6d89\u53ca\u591a\u4e2a\u65b9\u6cd5\u901a\u8fc7\u5171\u4eab\u72b6\u6001\u548c\u8c03\u7528\u4f9d\u8d56\u8fdb\u884c\u4ea4\u4e92\uff0c\u8fd9\u4e00\u9886\u57df\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u5c06\u6d4b\u8bd5\u9a71\u52a8\u4ee3\u7801\u751f\u6210\u4ece\u51fd\u6570\u6269\u5c55\u5230\u7c7b\uff0c\u4ee5\u63d0\u9ad8\u7c7b\u7ea7\u4ee3\u7801\u751f\u6210\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u8fed\u4ee3TDD\u6846\u67b6\uff1a1) \u5206\u6790\u7c7b\u5185\u65b9\u6cd5\u4f9d\u8d56\u5173\u7cfb\u4ee5\u786e\u5b9a\u53ef\u884c\u7684\u751f\u6210\u987a\u5e8f\uff1b2) \u5728\u65b9\u6cd5\u7ea7\u516c\u5171\u6d4b\u8bd5\u4e0b\u9010\u6b65\u5b9e\u73b0\u6bcf\u4e2a\u65b9\u6cd5\uff1b3) \u4f7f\u7528\u53cd\u5c04\u5f0f\u6267\u884c\u53cd\u9988\u548c\u6709\u9650\u4fee\u590d\u8fed\u4ee3\uff1b4) \u6784\u5efaClassEval-TDD\u6570\u636e\u96c6\u652f\u6301\u6d4b\u8bd5\u9a71\u52a8\u751f\u6210\u548c\u4e25\u683c\u8bc4\u4f30\u3002", "result": "\u7c7b\u7ea7TDD\u6846\u67b6\u5c06\u7c7b\u7ea7\u6b63\u786e\u6027\u63d0\u9ad8\u4e8612-26\u4e2a\u767e\u5206\u70b9\uff0c\u6700\u9ad8\u8fbe\u523071%\u5b8c\u5168\u6b63\u786e\u7684\u7c7b\uff0c\u5e73\u5747\u53ea\u9700\u8981\u5c11\u91cf\u4fee\u590d\u3002\u5728\u516b\u4e2aLLM\u4e0a\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u6700\u5f3a\u7684\u76f4\u63a5\u751f\u6210\u57fa\u7ebf\uff08\u6574\u4f53\u3001\u589e\u91cf\u548c\u7ec4\u5408\u7b56\u7565\u4e2d\u7684\u6700\u4f73\u8005\uff09\u3002", "conclusion": "\u6d4b\u8bd5\u9a71\u52a8\u751f\u6210\u53ef\u4ee5\u6709\u6548\u6269\u5c55\u5230\u5b64\u7acb\u51fd\u6570\u4e4b\u5916\uff0c\u663e\u8457\u63d0\u9ad8\u7c7b\u7ea7\u4ee3\u7801\u751f\u6210\u7684\u53ef\u9760\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8fed\u4ee3TDD\u6846\u67b6\u548c\u7cfb\u7edf\u5316\u4f9d\u8d56\u5206\u6790\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u7c7b\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u591a\u65b9\u6cd5\u4ea4\u4e92\u7684\u6311\u6218\u3002"}}
{"id": "2602.02952", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02952", "abs": "https://arxiv.org/abs/2602.02952", "authors": ["Elias Hossain", "Shubhashis Roy Dipta", "Subash Neupane", "Rajib Rana", "Ravid Shwartz-Ziv", "Ivan Garibay", "Niloofar Yousefi"], "title": "UAT-LITE: Inference-Time Uncertainty-Aware Attention for Pretrained Transformers", "comment": null, "summary": "Neural NLP models are often miscalibrated, assigning high confidence to incorrect predictions, which undermines selective prediction and high-stakes deployment. Post-hoc calibration methods adjust output probabilities but leave internal computation unchanged, while ensemble and Bayesian approaches improve uncertainty at substantial training or storage cost. We propose UAT-LITE, an inference-time framework that makes self-attention uncertainty-aware using approximate Bayesian inference via Monte Carlo dropout in pretrained transformer classifiers. Token-level epistemic uncertainty is estimated from stochastic forward passes and used to modulate self-attention during contextualization, without modifying pretrained weights or training objectives. We additionally introduce a layerwise variance decomposition to diagnose how predictive uncertainty accumulates across transformer depth. Across the SQuAD 2.0 answerability, MNLI, and SST-2, UAT-LITE reduces Expected Calibration Error by approximately 20% on average relative to a fine-tuned BERT-base baseline while preserving task accuracy, and improves selective prediction and robustness under distribution shift.", "AI": {"tldr": "UAT-LITE\uff1a\u4e00\u79cd\u63a8\u7406\u65f6\u6846\u67b6\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1bdropout\u5728\u9884\u8bad\u7ec3transformer\u5206\u7c7b\u5668\u4e2d\u5b9e\u73b0\u81ea\u6ce8\u610f\u529b\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\uff0c\u65e0\u9700\u4fee\u6539\u9884\u8bad\u7ec3\u6743\u91cd\u6216\u8bad\u7ec3\u76ee\u6807\uff0c\u663e\u8457\u964d\u4f4e\u6821\u51c6\u8bef\u5dee\u5e76\u63d0\u5347\u9009\u62e9\u6027\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u795e\u7ecfNLP\u6a21\u578b\u7ecf\u5e38\u5b58\u5728\u6821\u51c6\u4e0d\u826f\u95ee\u9898\uff0c\u5bf9\u9519\u8bef\u9884\u6d4b\u5206\u914d\u9ad8\u7f6e\u4fe1\u5ea6\uff0c\u8fd9\u5f71\u54cd\u4e86\u9009\u62e9\u6027\u9884\u6d4b\u548c\u9ad8\u98ce\u9669\u90e8\u7f72\u3002\u73b0\u6709\u7684\u540e\u5904\u7406\u6821\u51c6\u65b9\u6cd5\u53ea\u8c03\u6574\u8f93\u51fa\u6982\u7387\u800c\u4e0d\u6539\u53d8\u5185\u90e8\u8ba1\u7b97\uff0c\u800c\u96c6\u6210\u548c\u8d1d\u53f6\u65af\u65b9\u6cd5\u867d\u7136\u80fd\u6539\u5584\u4e0d\u786e\u5b9a\u6027\u4f46\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6216\u5b58\u50a8\u6210\u672c\u3002", "method": "\u63d0\u51faUAT-LITE\u63a8\u7406\u65f6\u6846\u67b6\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1bdropout\u5728\u9884\u8bad\u7ec3transformer\u5206\u7c7b\u5668\u4e2d\u5b9e\u73b0\u8fd1\u4f3c\u8d1d\u53f6\u65af\u63a8\u65ad\u3002\u4ece\u968f\u673a\u524d\u5411\u4f20\u64ad\u4e2d\u4f30\u8ba1token\u7ea7\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u7528\u5176\u8c03\u5236\u81ea\u6ce8\u610f\u529b\u673a\u5236\u3002\u6b64\u5916\u5f15\u5165\u5c42\u95f4\u65b9\u5dee\u5206\u89e3\u6765\u8bca\u65ad\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u5982\u4f55\u5728transformer\u6df1\u5ea6\u4e2d\u7d2f\u79ef\u3002", "result": "\u5728SQuAD 2.0\u53ef\u56de\u7b54\u6027\u3001MNLI\u548cSST-2\u6570\u636e\u96c6\u4e0a\uff0cUAT-LITE\u76f8\u5bf9\u4e8e\u5fae\u8c03\u7684BERT-base\u57fa\u7ebf\uff0c\u5e73\u5747\u51cf\u5c11\u7ea620%\u7684\u671f\u671b\u6821\u51c6\u8bef\u5dee\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u51c6\u786e\u6027\u3002\u8fd8\u6539\u5584\u4e86\u9009\u62e9\u6027\u9884\u6d4b\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "UAT-LITE\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u9884\u8bad\u7ec3transformer\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u80fd\u529b\uff0c\u663e\u8457\u6539\u5584\u6a21\u578b\u6821\u51c6\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\uff0c\u4e3a\u9ad8\u98ce\u9669NLP\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03585", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03585", "abs": "https://arxiv.org/abs/2602.03585", "authors": ["Lukas Schulte", "Gordon Fraser", "Steffen Herbold"], "title": "Causal Inference for the Effect of Code Coverage on Bug Introduction", "comment": "Registered Report with Continuity Acceptance (CA) for submission to Empirical Software Engineering granted by RR-Committee of the MSR'26", "summary": "Context: Code coverage is widely used as a software quality assurance measure. However, its effect, and specifically the advisable dose, are disputed in both the research and engineering communities. Prior work reports only correlational associations, leaving results vulnerable to confounding factors. Objective: We aim to quantify the causal effect of code coverage (exposure) on bug introduction (outcome) in the context of mature JavaScript and TypeScript open source projects, addressing both the overall effect and its variance across coverage levels. Method: We construct a causal directed acyclic graph to identify confounders within the software engineering process, modeling key variables from the source code, issue- and review systems, and continuous integration. Using generalized propensity score adjustment, we will apply doubly robust regression-based causal inference for continuous exposure to a novel dataset of bug-introducing and non-bug-introducing changes. We estimate the average treatment effect and dose-response relationship to examine potential non-linear patterns (e.g., thresholds or diminishing returns) within the projects of our dataset.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u91cf\u5316\u4ee3\u7801\u8986\u76d6\u7387\u5bf9\u5f15\u5165bug\u7684\u5f71\u54cd\uff0c\u5206\u6790JavaScript/TypeScript\u5f00\u6e90\u9879\u76ee\u4e2d\u8986\u76d6\u7387\u5242\u91cf\u4e0ebug\u5f15\u5165\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "\u4ee3\u7801\u8986\u76d6\u7387\u88ab\u5e7f\u6cdb\u7528\u4f5c\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u8bc1\u6307\u6807\uff0c\u4f46\u5176\u5b9e\u9645\u6548\u679c\u548c\u9002\u5f53\u5242\u91cf\u5728\u7814\u7a76\u548c\u5de5\u7a0b\u754c\u5b58\u5728\u4e89\u8bae\u3002\u5148\u524d\u5de5\u4f5c\u4ec5\u62a5\u544a\u76f8\u5173\u6027\u5173\u8054\uff0c\u7ed3\u679c\u6613\u53d7\u6df7\u6742\u56e0\u7d20\u5f71\u54cd\uff0c\u9700\u8981\u91cf\u5316\u8986\u76d6\u7387\u5bf9bug\u5f15\u5165\u7684\u56e0\u679c\u6548\u5e94\u3002", "method": "\u6784\u5efa\u56e0\u679c\u6709\u5411\u65e0\u73af\u56fe\u8bc6\u522b\u8f6f\u4ef6\u5de5\u7a0b\u8fc7\u7a0b\u4e2d\u7684\u6df7\u6742\u56e0\u7d20\uff0c\u4ece\u6e90\u4ee3\u7801\u3001\u95ee\u9898\u8ddf\u8e2a\u7cfb\u7edf\u3001\u8bc4\u5ba1\u7cfb\u7edf\u548c\u6301\u7eed\u96c6\u6210\u4e2d\u5efa\u6a21\u5173\u952e\u53d8\u91cf\u3002\u4f7f\u7528\u5e7f\u4e49\u503e\u5411\u5f97\u5206\u8c03\u6574\uff0c\u5bf9\u8fde\u7eed\u66b4\u9732\uff08\u8986\u76d6\u7387\uff09\u5e94\u7528\u53cc\u91cd\u7a33\u5065\u56de\u5f52\u7684\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u5206\u6790bug\u5f15\u5165\u548c\u975ebug\u5f15\u5165\u53d8\u66f4\u7684\u65b0\u6570\u636e\u96c6\u3002", "result": "\u7814\u7a76\u5c06\u4f30\u8ba1\u5e73\u5747\u5904\u7406\u6548\u5e94\u548c\u5242\u91cf-\u54cd\u5e94\u5173\u7cfb\uff0c\u4ee5\u68c0\u67e5\u6570\u636e\u96c6\u4e2d\u9879\u76ee\u5185\u6f5c\u5728\u7684\u975e\u7ebf\u6027\u6a21\u5f0f\uff08\u5982\u9608\u503c\u6216\u6536\u76ca\u9012\u51cf\u6548\u5e94\uff09\u3002", "conclusion": "\u8be5\u7814\u7a76\u65e8\u5728\u4e3aJavaScript\u548cTypeScript\u5f00\u6e90\u9879\u76ee\u4e2d\u4ee3\u7801\u8986\u76d6\u7387\u5bf9bug\u5f15\u5165\u7684\u56e0\u679c\u6548\u5e94\u63d0\u4f9b\u91cf\u5316\u8bc1\u636e\uff0c\u5e2e\u52a9\u7406\u89e3\u8986\u76d6\u7387\u5242\u91cf\u4e0e\u8f6f\u4ef6\u8d28\u91cf\u4e4b\u95f4\u7684\u771f\u5b9e\u5173\u7cfb\u3002"}}
{"id": "2602.03328", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.03328", "abs": "https://arxiv.org/abs/2602.03328", "authors": ["Zhenhao Zhu", "Yue Liu", "Yanpei Guo", "Wenjie Qu", "Cancan Chen", "Yufei He", "Yibo Li", "Yulin Chen", "Tianyi Wu", "Huiying Xu", "Xinzhong Zhu", "Jiaheng Zhang"], "title": "GuardReasoner-Omni: A Reasoning-based Multi-modal Guardrail for Text, Image, and Video", "comment": null, "summary": "We present GuardReasoner-Omni, a reasoning-based guardrail model designed to moderate text, image, and video data. First, we construct a comprehensive training corpus comprising 148k samples spanning these three modalities. Our training pipeline follows a two-stage paradigm to incentivize the model to deliberate before making decisions: (1) conducting SFT to cold-start the model with explicit reasoning capabilities and structural adherence; and (2) performing RL, incorporating an error-driven exploration reward to incentivize deeper reasoning on hard samples. We release a suite of models scaled at 2B and 4B parameters. Extensive experiments demonstrate that GuardReasoner-Omni achieves superior performance compared to existing state-of-the-art baselines across various guardrail benchmarks. Notably, GuardReasoner-Omni (2B) significantly surpasses the runner-up by 5.3% F1 score.", "AI": {"tldr": "GuardReasoner-Omni\u662f\u4e00\u4e2a\u57fa\u4e8e\u63a8\u7406\u7684\u591a\u6a21\u6001\u62a4\u680f\u6a21\u578b\uff0c\u7528\u4e8e\u6587\u672c\u3001\u56fe\u50cf\u548c\u89c6\u9891\u5185\u5bb9\u5ba1\u6838\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b9e\u73b0\u6df1\u5ea6\u63a8\u7406\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u6587\u672c\u3001\u56fe\u50cf\u548c\u89c6\u9891\u591a\u79cd\u6a21\u6001\u5185\u5bb9\u7684\u5b89\u5168\u62a4\u680f\u6a21\u578b\uff0c\u901a\u8fc7\u6df1\u5ea6\u63a8\u7406\u6765\u63d0\u9ad8\u5185\u5bb9\u5ba1\u6838\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "1. \u6784\u5efa\u5305\u542b148k\u6837\u672c\u7684\u591a\u6a21\u6001\u8bad\u7ec3\u8bed\u6599\u5e93\uff1b2. \u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff1a\u9996\u5148\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u4ee5\u51b7\u542f\u52a8\u6a21\u578b\uff0c\u4f7f\u5176\u5177\u5907\u663e\u5f0f\u63a8\u7406\u80fd\u529b\u548c\u7ed3\u6784\u9075\u5faa\u6027\uff1b\u7136\u540e\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\uff0c\u5f15\u5165\u9519\u8bef\u9a71\u52a8\u63a2\u7d22\u5956\u52b1\u673a\u5236\uff0c\u6fc0\u52b1\u6a21\u578b\u5bf9\u56f0\u96be\u6837\u672c\u8fdb\u884c\u66f4\u6df1\u5c42\u6b21\u7684\u63a8\u7406\u3002", "result": "GuardReasoner-Omni\u5728\u591a\u4e2a\u62a4\u680f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u7279\u522b\u662f2B\u53c2\u6570\u7248\u672c\u663e\u8457\u9886\u5148\u7b2c\u4e8c\u540d5.3%\u7684F1\u5206\u6570\uff0c\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "GuardReasoner-Omni\u901a\u8fc7\u7ed3\u5408\u591a\u6a21\u6001\u6570\u636e\u5904\u7406\u548c\u6df1\u5ea6\u63a8\u7406\u8bad\u7ec3\u7b56\u7565\uff0c\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u5185\u5bb9\u5b89\u5168\u62a4\u680f\u7cfb\u7edf\uff0c\u4e3a\u591a\u6a21\u6001\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03593", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03593", "abs": "https://arxiv.org/abs/2602.03593", "authors": ["Valerie Chen", "Jasmyn He", "Behnjamin Williams", "Jason Valentino", "Ameet Talwalkar"], "title": "Beyond the Commit: Developer Perspectives on Productivity with AI Coding Assistants", "comment": "ICSE SEIP", "summary": "Measuring developer productivity is a topic that has attracted attention from both academic research and industrial practice. In the age of AI coding assistants, it has become even more important for both academia and industry to understand how to measure their impact on developer productivity, and to reconsider whether earlier measures and frameworks still apply. This study analyzes the validity of different approaches to evaluating the productivity impacts of AI coding assistants by leveraging mixed-method research. At BNY Mellon, we conduct a survey with 2989 developer responses and 11 in-depth interviews. Our findings demonstrate that a multifaceted approach is needed to measure AI productivity impacts: survey results expose conflicting perspectives on AI tool usefulness, while interviews elicit six distinct factors that capture both short-term and long-term dimensions of productivity. In contrast to prior work, our factors highlight the importance of long-term metrics like technical expertise and ownership of work. We hope this work encourages future research to incorporate a broader range of human-centered factors, and supports industry in adopting more holistic approaches to evaluating developer productivity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u8bc4\u4f30AI\u7f16\u7801\u52a9\u624b\u5bf9\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u5f71\u54cd\u7684\u4e0d\u540c\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u6df7\u5408\u7814\u7a76\u65b9\u6cd5\u53d1\u73b0\u9700\u8981\u591a\u7ef4\u5ea6\u65b9\u6cd5\u6765\u8861\u91cfAI\u751f\u4ea7\u529b\u5f71\u54cd\uff0c\u5f3a\u8c03\u4e86\u957f\u671f\u6307\u6807\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5728AI\u7f16\u7801\u52a9\u624b\u65f6\u4ee3\uff0c\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u90fd\u9700\u8981\u7406\u89e3\u5982\u4f55\u8861\u91cf\u5176\u5bf9\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u7684\u5f71\u54cd\uff0c\u5e76\u91cd\u65b0\u8bc4\u4f30\u65e9\u671f\u8861\u91cf\u6846\u67b6\u662f\u5426\u4ecd\u7136\u9002\u7528\u3002\u5f53\u524d\u7f3a\u4e4f\u6709\u6548\u8bc4\u4f30AI\u7f16\u7801\u52a9\u624b\u751f\u4ea7\u529b\u5f71\u54cd\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6df7\u5408\u7814\u7a76\u65b9\u6cd5\uff1a\u5728BNY Mellon\u516c\u53f8\u8fdb\u884c\u5305\u542b2989\u540d\u5f00\u53d1\u8005\u54cd\u5e94\u7684\u95ee\u5377\u8c03\u67e5\uff0c\u5e76\u7ed3\u540811\u6b21\u6df1\u5ea6\u8bbf\u8c08\uff0c\u4ece\u5b9a\u91cf\u548c\u5b9a\u6027\u4e24\u4e2a\u7ef4\u5ea6\u6536\u96c6\u6570\u636e\u3002", "result": "\u8c03\u67e5\u7ed3\u679c\u663e\u793a\u5f00\u53d1\u8005\u5bf9AI\u5de5\u5177\u5b9e\u7528\u6027\u5b58\u5728\u77db\u76fe\u89c2\u70b9\uff1b\u8bbf\u8c08\u63ed\u793a\u4e86\u516d\u4e2a\u4e0d\u540c\u7684\u751f\u4ea7\u529b\u56e0\u7d20\uff0c\u6db5\u76d6\u77ed\u671f\u548c\u957f\u671f\u7ef4\u5ea6\u3002\u7814\u7a76\u53d1\u73b0\u9700\u8981\u591a\u7ef4\u5ea6\u65b9\u6cd5\u6765\u8861\u91cfAI\u751f\u4ea7\u529b\u5f71\u54cd\uff0c\u7279\u522b\u5f3a\u8c03\u4e86\u6280\u672f\u4e13\u957f\u548c\u5de5\u4f5c\u6240\u6709\u6743\u7b49\u957f\u671f\u6307\u6807\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u9f13\u52b1\u672a\u6765\u7814\u7a76\u7eb3\u5165\u66f4\u5e7f\u6cdb\u7684\u4eba\u4e3a\u4e2d\u5fc3\u56e0\u7d20\uff0c\u652f\u6301\u5de5\u4e1a\u754c\u91c7\u7528\u66f4\u5168\u9762\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u5f00\u53d1\u8005\u751f\u4ea7\u529b\uff0c\u7279\u522b\u662f\u8981\u91cd\u89c6\u957f\u671f\u751f\u4ea7\u529b\u6307\u6807\u800c\u4e0d\u4ec5\u4ec5\u662f\u77ed\u671f\u6548\u7387\u63d0\u5347\u3002"}}
{"id": "2602.02978", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02978", "abs": "https://arxiv.org/abs/2602.02978", "authors": ["Zuyuan Zhang", "Zeyu Fang", "Tian Lan"], "title": "Structuring Value Representations via Geometric Coherence in Markov Decision Processes", "comment": null, "summary": "Geometric properties can be leveraged to stabilize and speed reinforcement learning. Existing examples include encoding symmetry structure, geometry-aware data augmentation, and enforcing structural restrictions. In this paper, we take a novel view of RL through the lens of order theory and recast value function estimates into learning a desired poset (partially ordered set). We propose \\emph{GCR-RL} (Geometric Coherence Regularized Reinforcement Learning) that computes a sequence of super-poset refinements -- by refining posets in previous steps and learning additional order relationships from temporal difference signals -- thus ensuring geometric coherence across the sequence of posets underpinning the learned value functions. Two novel algorithms by Q-learning and by actor--critic are developed to efficiently realize these super-poset refinements. Their theoretical properties and convergence rates are analyzed. We empirically evaluate GCR-RL in a range of tasks and demonstrate significant improvements in sample efficiency and stable performance over strong baselines.", "AI": {"tldr": "\u63d0\u51faGCR-RL\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e8f\u7406\u8bba\u89c6\u89d2\u5c06\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4ef7\u503c\u51fd\u6570\u4f30\u8ba1\u91cd\u6784\u4e3a\u5b66\u4e60\u504f\u5e8f\u96c6\uff0c\u5229\u7528\u51e0\u4f55\u4e00\u81f4\u6027\u6b63\u5219\u5316\u63d0\u5347\u5b66\u4e60\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u51e0\u4f55\u6027\u8d28\u53ef\u7528\u4e8e\u7a33\u5b9a\u548c\u52a0\u901f\u5f3a\u5316\u5b66\u4e60\uff0c\u73b0\u6709\u65b9\u6cd5\u5305\u62ec\u7f16\u7801\u5bf9\u79f0\u7ed3\u6784\u3001\u51e0\u4f55\u611f\u77e5\u6570\u636e\u589e\u5f3a\u548c\u5f3a\u5236\u7ed3\u6784\u9650\u5236\u3002\u672c\u6587\u4ece\u5e8f\u7406\u8bba\u7684\u65b0\u89c6\u89d2\u91cd\u65b0\u5ba1\u89c6RL\uff0c\u5c06\u4ef7\u503c\u51fd\u6570\u4f30\u8ba1\u8f6c\u5316\u4e3a\u5b66\u4e60\u671f\u671b\u7684\u504f\u5e8f\u96c6\u3002", "method": "\u63d0\u51faGCR-RL\uff08\u51e0\u4f55\u4e00\u81f4\u6027\u6b63\u5219\u5316\u5f3a\u5316\u5b66\u4e60\uff09\uff0c\u901a\u8fc7\u8ba1\u7b97\u4e00\u7cfb\u5217\u8d85\u504f\u5e8f\u96c6\u7cbe\u5316\u5e8f\u5217\u2014\u2014\u901a\u8fc7\u7cbe\u5316\u5148\u524d\u6b65\u9aa4\u7684\u504f\u5e8f\u96c6\u5e76\u4ece\u65f6\u5e8f\u5dee\u5206\u4fe1\u53f7\u4e2d\u5b66\u4e60\u989d\u5916\u7684\u5e8f\u5173\u7cfb\u2014\u2014\u786e\u4fdd\u652f\u6491\u5b66\u4e60\u4ef7\u503c\u51fd\u6570\u7684\u504f\u5e8f\u96c6\u5e8f\u5217\u5177\u6709\u51e0\u4f55\u4e00\u81f4\u6027\u3002\u5f00\u53d1\u4e86\u57fa\u4e8eQ\u5b66\u4e60\u548c\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7684\u4e24\u79cd\u65b0\u7b97\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e9b\u8d85\u504f\u5e8f\u96c6\u7cbe\u5316\u3002", "result": "\u5206\u6790\u4e86\u7b97\u6cd5\u7684\u7406\u8bba\u6027\u8d28\u548c\u6536\u655b\u901f\u5ea6\u3002\u5728\u4e00\u7cfb\u5217\u4efb\u52a1\u4e2d\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0cGCR-RL\u5728\u6837\u672c\u6548\u7387\u548c\u7a33\u5b9a\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u901a\u8fc7\u5e8f\u7406\u8bba\u89c6\u89d2\u91cd\u65b0\u6784\u5efa\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u51fa\u7684GCR-RL\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5229\u7528\u51e0\u4f55\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u6837\u672c\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.03632", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03632", "abs": "https://arxiv.org/abs/2602.03632", "authors": ["Hemang Jain", "Divyansh Pandey", "Karthik Vaidhyanathan"], "title": "CALM: A Self-Adaptive Orchestration Approach for QoS-Aware Routing in Small Language Model based Systems", "comment": "Accepted as full paper at SEAMS 2026", "summary": "AI-enabled systems are subjected to various types of runtime uncertainties, ranging from dynamic workloads, resource requirements, model drift, etc. These uncertainties have a big impact on the overall Quality of Service (QoS). This is particularly true in the case of Language Model (LM) enabled systems where the autoregressive nature of token generation introduces variability in latency, energy usage and response quality. These systems, powered by LLMs, are either resource-intensive (if run on-prem) or raise privacy/cost concerns (if leveraged using APIs). While deploying a Small Language Model (SLM) can be resource-efficient, it often falls short in addressing the diversity and scale of real-world requirements. To this, we argue that, rather than relying on any one SLM, leveraging a coordinated fleet of SLMs, each with specialized strengths can enable systems to dynamically adapt to shifting contexts and workload patterns. However, realizing the full potential of such an approach demands intelligent orchestration and continuous adaptation. To this end, we introduce CALM , a self-adaptive orchestration mechanism based on MAPE-K. Our approach continuously monitors user queries, analyzes the QoS metrics of the SLMs, identifies the optimal SLM to be used, routes the query to the identified SLM and further to enhance the effectiveness and efficiency, leverages caching and scheduling to decide the SLMs to be kept in memory. Our evaluation shows that CALM reduces latency by approximately 40% and energy consumption by 50%, while preserving domain-specific task performance when compared to single-LLM baselines.", "AI": {"tldr": "CALM\u662f\u4e00\u4e2a\u57fa\u4e8eMAPE-K\u7684\u81ea\u9002\u5e94\u7f16\u6392\u673a\u5236\uff0c\u901a\u8fc7\u534f\u8c03\u591a\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7ec4\u6210\u7684\u8230\u961f\uff0c\u52a8\u6001\u9002\u5e94\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\uff0c\u76f8\u6bd4\u5355\u4e00LLM\u57fa\u7ebf\u964d\u4f4e40%\u5ef6\u8fdf\u548c50%\u80fd\u8017\u3002", "motivation": "AI\u7cfb\u7edf\u9762\u4e34\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\uff08\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u3001\u8d44\u6e90\u9700\u6c42\u3001\u6a21\u578b\u6f02\u79fb\u7b49\uff09\uff0c\u4e25\u91cd\u5f71\u54cd\u670d\u52a1\u8d28\u91cf\u3002LLM\u7cfb\u7edf\u5b58\u5728\u8d44\u6e90\u5bc6\u96c6\u6216\u9690\u79c1/\u6210\u672c\u95ee\u9898\uff0c\u800c\u5355\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u6ee1\u8db3\u73b0\u5b9e\u9700\u6c42\u7684\u591a\u6837\u6027\u548c\u89c4\u6a21\u3002", "method": "\u63d0\u51faCALM\uff0c\u57fa\u4e8eMAPE-K\u7684\u81ea\u9002\u5e94\u7f16\u6392\u673a\u5236\uff1a\u6301\u7eed\u76d1\u63a7\u7528\u6237\u67e5\u8be2\uff0c\u5206\u6790SLM\u7684QoS\u6307\u6807\uff0c\u8bc6\u522b\u6700\u4f18SLM\uff0c\u8def\u7531\u67e5\u8be2\u5230\u9009\u5b9aSLM\uff0c\u5e76\u901a\u8fc7\u7f13\u5b58\u548c\u8c03\u5ea6\u51b3\u5b9a\u54ea\u4e9bSLM\u4fdd\u7559\u5728\u5185\u5b58\u4e2d\u3002", "result": "CALM\u76f8\u6bd4\u5355\u4e00LLM\u57fa\u7ebf\uff0c\u5ef6\u8fdf\u964d\u4f4e\u7ea640%\uff0c\u80fd\u8017\u964d\u4f4e50%\uff0c\u540c\u65f6\u4fdd\u6301\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u534f\u8c03\u5177\u6709\u4e13\u4e1a\u4f18\u52bf\u7684SLM\u8230\u961f\uff0c\u7ed3\u5408\u667a\u80fd\u7f16\u6392\u548c\u6301\u7eed\u81ea\u9002\u5e94\uff0c\u53ef\u4ee5\u6709\u6548\u5e94\u5bf9\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u5347\u7cfb\u7edf\u6548\u7387\u548c\u670d\u52a1\u8d28\u91cf\u3002"}}
{"id": "2602.03423", "categories": ["cs.CR", "cs.CV", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.03423", "abs": "https://arxiv.org/abs/2602.03423", "authors": ["Alexander Loth", "Dominique Conceicao Rosario", "Peter Ebinger", "Martin Kappes", "Marc-Oliver Pahl"], "title": "Origin Lens: A Privacy-First Mobile Framework for Cryptographic Image Provenance and AI Detection", "comment": "Accepted at ACM TheWebConf '26 Companion", "summary": "The proliferation of generative AI poses challenges for information integrity assurance, requiring systems that connect model governance with end-user verification. We present Origin Lens, a privacy-first mobile framework that targets visual disinformation through a layered verification architecture. Unlike server-side detection systems, Origin Lens performs cryptographic image provenance verification and AI detection locally on the device via a Rust/Flutter hybrid architecture. Our system integrates multiple signals - including cryptographic provenance, generative model fingerprints, and optional retrieval-augmented verification - to provide users with graded confidence indicators at the point of consumption. We discuss the framework's alignment with regulatory requirements (EU AI Act, DSA) and its role in verification infrastructure that complements platform-level mechanisms.", "AI": {"tldr": "Origin Lens\u662f\u4e00\u4e2a\u9690\u79c1\u4f18\u5148\u7684\u79fb\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u9a8c\u8bc1\u67b6\u6784\u5e94\u5bf9\u89c6\u89c9\u865a\u5047\u4fe1\u606f\uff0c\u5728\u8bbe\u5907\u672c\u5730\u6267\u884c\u52a0\u5bc6\u56fe\u50cf\u6eaf\u6e90\u9a8c\u8bc1\u548cAI\u68c0\u6d4b\uff0c\u63d0\u4f9b\u5206\u7ea7\u7f6e\u4fe1\u5ea6\u6307\u6807\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7684\u666e\u53ca\u5bf9\u4fe1\u606f\u5b8c\u6574\u6027\u4fdd\u969c\u63d0\u51fa\u4e86\u6311\u6218\uff0c\u9700\u8981\u5c06\u6a21\u578b\u6cbb\u7406\u4e0e\u7ec8\u7aef\u7528\u6237\u9a8c\u8bc1\u8fde\u63a5\u8d77\u6765\u7684\u7cfb\u7edf\uff0c\u4ee5\u5e94\u5bf9\u89c6\u89c9\u865a\u5047\u4fe1\u606f\u95ee\u9898\u3002", "method": "\u91c7\u7528Rust/Flutter\u6df7\u5408\u67b6\u6784\u7684\u9690\u79c1\u4f18\u5148\u79fb\u52a8\u6846\u67b6\uff0c\u5728\u8bbe\u5907\u672c\u5730\u6267\u884c\u52a0\u5bc6\u56fe\u50cf\u6eaf\u6e90\u9a8c\u8bc1\u548cAI\u68c0\u6d4b\uff0c\u6574\u5408\u52a0\u5bc6\u6eaf\u6e90\u3001\u751f\u6210\u6a21\u578b\u6307\u7eb9\u548c\u53ef\u9009\u68c0\u7d22\u589e\u5f3a\u9a8c\u8bc1\u7b49\u591a\u91cd\u4fe1\u53f7\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u5c42\u9a8c\u8bc1\u67b6\u6784\uff0c\u80fd\u591f\u5728\u6d88\u8d39\u70b9\u4e3a\u7528\u6237\u63d0\u4f9b\u5206\u7ea7\u7f6e\u4fe1\u5ea6\u6307\u6807\uff0c\u4e0e\u670d\u52a1\u5668\u7aef\u68c0\u6d4b\u7cfb\u7edf\u4e0d\u540c\uff0c\u6240\u6709\u9a8c\u8bc1\u90fd\u5728\u8bbe\u5907\u672c\u5730\u5b8c\u6210\u3002", "conclusion": "Origin Lens\u6846\u67b6\u7b26\u5408\u6b27\u76dfAI\u6cd5\u6848\u548c\u6570\u5b57\u670d\u52a1\u6cd5\u6848\u7b49\u76d1\u7ba1\u8981\u6c42\uff0c\u5728\u9a8c\u8bc1\u57fa\u7840\u8bbe\u65bd\u4e2d\u53d1\u6325\u8865\u5145\u5e73\u53f0\u7ea7\u673a\u5236\u7684\u4f5c\u7528\uff0c\u4e3a\u4fe1\u606f\u5b8c\u6574\u6027\u4fdd\u969c\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02983", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02983", "abs": "https://arxiv.org/abs/2602.02983", "authors": ["Hanna M. Dettki", "Charley M. Wu", "Bob Rehder"], "title": "Are LLMs Biased Like Humans? Causal Reasoning as a Function of Prior Knowledge, Irrelevant Information, and Reasoning Budget", "comment": null, "summary": "Large language models (LLMs) are increasingly used in domains where causal reasoning matters, yet it remains unclear whether their judgments reflect normative causal computation, human-like shortcuts, or brittle pattern matching. We benchmark 20+ LLMs against a matched human baseline on 11 causal judgment tasks formalized by a collider structure ($C_1 \\!\\rightarrow\\! E\\! \\leftarrow \\!C_2$). We find that a small interpretable model compresses LLMs' causal judgments well and that most LLMs exhibit more rule-like reasoning strategies than humans who seem to account for unmentioned latent factors in their probability judgments. Furthermore, most LLMs do not mirror the characteristic human collider biases of weak explaining away and Markov violations. We probe LLMs' causal judgment robustness under (i) semantic abstraction and (ii) prompt overloading (injecting irrelevant text), and find that chain-of-thought (CoT) increases robustness for many LLMs. Together, this divergence suggests LLMs can complement humans when known biases are undesirable, but their rule-like reasoning may break down when uncertainty is intrinsic -- highlighting the need to characterize LLM reasoning strategies for safe, effective deployment.", "AI": {"tldr": "LLMs\u5728\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u6bd4\u4eba\u7c7b\u66f4\u89c4\u5219\u5316\u7684\u63a8\u7406\u7b56\u7565\uff0c\u4e0d\u6a21\u4eff\u4eba\u7c7b\u5178\u578b\u7684\u5171\u56e0\u7ed3\u6784\u504f\u89c1\uff0c\u601d\u7ef4\u94fe\u63d0\u793a\u80fd\u589e\u5f3a\u5176\u9c81\u68d2\u6027", "motivation": "\u7814\u7a76LLMs\u5728\u56e0\u679c\u63a8\u7406\u9886\u57df\u7684\u8868\u73b0\uff0c\u63a2\u7a76\u5176\u5224\u65ad\u662f\u57fa\u4e8e\u89c4\u8303\u6027\u56e0\u679c\u8ba1\u7b97\u3001\u4eba\u7c7b\u5f0f\u6377\u5f84\u8fd8\u662f\u8106\u5f31\u7684\u6a21\u5f0f\u5339\u914d\uff0c\u4e3aLLMs\u7684\u5b89\u5168\u6709\u6548\u90e8\u7f72\u63d0\u4f9b\u4f9d\u636e", "method": "\u4f7f\u7528\u5171\u56e0\u7ed3\u6784\uff08C1\u2192E\u2190C2\uff09\u5f62\u5f0f\u5316\u768411\u4e2a\u56e0\u679c\u5224\u65ad\u4efb\u52a1\uff0c\u5bf920\u591a\u4e2aLLMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u5339\u914d\u7684\u4eba\u7c7b\u57fa\u7ebf\u6bd4\u8f83\uff1b\u4f7f\u7528\u53ef\u89e3\u91ca\u5c0f\u6a21\u578b\u538b\u7f29LLMs\u7684\u56e0\u679c\u5224\u65ad\uff1b\u6d4b\u8bd5LLMs\u5728\u8bed\u4e49\u62bd\u8c61\u548c\u63d0\u793a\u8fc7\u8f7d\u4e0b\u7684\u9c81\u68d2\u6027", "result": "\u5927\u591a\u6570LLMs\u8868\u73b0\u51fa\u6bd4\u4eba\u7c7b\u66f4\u89c4\u5219\u5316\u7684\u63a8\u7406\u7b56\u7565\uff1bLLMs\u4e0d\u6a21\u4eff\u4eba\u7c7b\u5178\u578b\u7684\u5171\u56e0\u7ed3\u6784\u504f\u89c1\uff08\u5f31\u89e3\u91ca\u6d88\u9664\u548c\u9a6c\u5c14\u53ef\u592b\u8fdd\u89c4\uff09\uff1b\u601d\u7ef4\u94fe\u63d0\u793a\u80fd\u589e\u5f3a\u8bb8\u591aLLMs\u7684\u9c81\u68d2\u6027", "conclusion": "LLMs\u7684\u63a8\u7406\u7b56\u7565\u4e0e\u4eba\u7c7b\u5b58\u5728\u5dee\u5f02\uff0c\u5f53\u5df2\u77e5\u504f\u89c1\u4e0d\u53d7\u6b22\u8fce\u65f6LLMs\u53ef\u4ee5\u8865\u5145\u4eba\u7c7b\uff0c\u4f46\u5176\u89c4\u5219\u5316\u63a8\u7406\u5728\u4e0d\u786e\u5b9a\u6027\u672c\u8d28\u5b58\u5728\u65f6\u53ef\u80fd\u5931\u6548\uff0c\u9700\u8981\u8868\u5f81LLMs\u7684\u63a8\u7406\u7b56\u7565\u4ee5\u786e\u4fdd\u5b89\u5168\u6709\u6548\u90e8\u7f72"}}
{"id": "2602.03470", "categories": ["cs.CR", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03470", "abs": "https://arxiv.org/abs/2602.03470", "authors": ["Nicol\u00e1s E. D\u00edaz Ferreyra", "Moritz Mock", "Max Kretschmann", "Barbara Russo", "Mojtaba Shahin", "Mansooreh Zahedi", "Riccardo Scandariato"], "title": "Reading Between the Code Lines: On the Use of Self-Admitted Technical Debt for Security Analysis", "comment": "Preprint submitted to Journal of Systems and Software", "summary": "Static Analysis Tools (SATs) are central to security engineering activities, as they enable early identification of code weaknesses without requiring execution. However, their effectiveness is often limited by high false-positive rates and incomplete coverage of vulnerability classes. At the same time, developers frequently document security-related shortcuts and compromises as Self-Admitted Technical Debt (SATD) in software artifacts, such as code comments. While prior work has recognized SATD as a rich source of security information, it remains unclear whether -and in what ways- it is utilized during SAT-aided security analysis. OBJECTIVE: This work investigates the extent to which security-related SATD complements the output produced by SATs and helps bridge some of their well-known limitations. METHOD: We followed a mixed-methods approach consisting of (i) the analysis of a SATD-annotated vulnerability dataset using three state-of-the-art SATs and (ii) an online survey with 72 security practitioners. RESULTS: The combined use of all SATs flagged 114 of the 135 security-related SATD instances, spanning 24 distinct Common Weakness Enumeration (CWE) identifiers. A manual mapping of the SATD comments revealed 33 unique CWE types, 6 of which correspond to categories that SATs commonly overlook or struggle to detect (e.g., race conditions). Survey responses further suggest that developers frequently pair SAT outputs with SATD insights to better understand the impact and root causes of security weaknesses and to identify suitable fixes. IMPLICATIONS: Our findings show that such SATD-encoded information can be a meaningful complement to SAT-driven security analysis, while helping to overcome some of SATs' practical shortcomings.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5b89\u5168\u76f8\u5173\u6280\u672f\u503a\u52a1\uff08SATD\uff09\u5982\u4f55\u8865\u5145\u9759\u6001\u5206\u6790\u5de5\u5177\uff08SAT\uff09\u7684\u5b89\u5168\u5206\u6790\uff0c\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0SATD\u80fd\u8986\u76d6SAT\u96be\u4ee5\u68c0\u6d4b\u7684\u6f0f\u6d1e\u7c7b\u578b\uff0c\u5f00\u53d1\u8005\u5e38\u7ed3\u5408\u4e24\u8005\u6765\u7406\u89e3\u5b89\u5168\u5f31\u70b9\u3002", "motivation": "\u9759\u6001\u5206\u6790\u5de5\u5177\u5728\u5b89\u5168\u5de5\u7a0b\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b58\u5728\u9ad8\u8bef\u62a5\u7387\u548c\u6f0f\u6d1e\u8986\u76d6\u4e0d\u5168\u7684\u5c40\u9650\u6027\u3002\u540c\u65f6\uff0c\u5f00\u53d1\u8005\u5728\u4ee3\u7801\u6ce8\u91ca\u4e2d\u8bb0\u5f55\u7684\u5b89\u5168\u76f8\u5173\u6280\u672f\u503a\u52a1\uff08SATD\uff09\u88ab\u8ba4\u4e3a\u662f\u4e30\u5bcc\u7684\u5b89\u5168\u4fe1\u606f\u6765\u6e90\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695aSATD\u5982\u4f55\u5728SAT\u8f85\u52a9\u7684\u5b89\u5168\u5206\u6790\u4e2d\u88ab\u5229\u7528\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u4e09\u79cd\u6700\u5148\u8fdb\u7684\u9759\u6001\u5206\u6790\u5de5\u5177\u5206\u6790SATD\u6807\u6ce8\u7684\u6f0f\u6d1e\u6570\u636e\u96c6\uff1b2\uff09\u5bf972\u540d\u5b89\u5168\u4ece\u4e1a\u8005\u8fdb\u884c\u5728\u7ebf\u8c03\u67e5\u3002", "result": "\u6240\u6709SAT\u5de5\u5177\u5171\u6807\u8bb0\u4e86135\u4e2a\u5b89\u5168\u76f8\u5173SATD\u5b9e\u4f8b\u4e2d\u7684114\u4e2a\uff0c\u8986\u76d624\u4e2a\u4e0d\u540c\u7684CWE\u6807\u8bc6\u7b26\u3002\u624b\u52a8\u6620\u5c04SATD\u6ce8\u91ca\u53d1\u73b0\u4e8633\u4e2a\u72ec\u7279\u7684CWE\u7c7b\u578b\uff0c\u5176\u4e2d6\u4e2a\u5bf9\u5e94SAT\u901a\u5e38\u5ffd\u89c6\u6216\u96be\u4ee5\u68c0\u6d4b\u7684\u7c7b\u522b\uff08\u5982\u7ade\u4e89\u6761\u4ef6\uff09\u3002\u8c03\u67e5\u663e\u793a\u5f00\u53d1\u8005\u7ecf\u5e38\u7ed3\u5408SAT\u8f93\u51fa\u548cSATD\u6d1e\u5bdf\u6765\u66f4\u597d\u5730\u7406\u89e3\u5b89\u5168\u5f31\u70b9\u7684\u5f71\u54cd\u548c\u6839\u672c\u539f\u56e0\uff0c\u5e76\u786e\u5b9a\u5408\u9002\u7684\u4fee\u590d\u65b9\u6848\u3002", "conclusion": "SATD\u7f16\u7801\u7684\u4fe1\u606f\u53ef\u4ee5\u6210\u4e3aSAT\u9a71\u52a8\u5b89\u5168\u5206\u6790\u7684\u6709\u610f\u4e49\u8865\u5145\uff0c\u540c\u65f6\u6709\u52a9\u4e8e\u514b\u670dSAT\u7684\u4e00\u4e9b\u5b9e\u9645\u7f3a\u70b9\u3002\u5b89\u5168\u76f8\u5173\u6280\u672f\u503a\u52a1\u80fd\u591f\u8865\u5145\u9759\u6001\u5206\u6790\u5de5\u5177\u7684\u8f93\u51fa\uff0c\u5e2e\u52a9\u5f25\u8865\u5176\u5df2\u77e5\u5c40\u9650\u6027\u3002"}}
{"id": "2602.02991", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02991", "abs": "https://arxiv.org/abs/2602.02991", "authors": ["Haijiang Yan", "Jian-Qiao Zhu", "Adam Sanborn"], "title": "Large Language Models Can Take False First Steps at Inference-time Planning", "comment": null, "summary": "Large language models (LLMs) have been shown to acquire sequence-level planning abilities during training, yet their planning behavior exhibited at inference time often appears short-sighted and inconsistent with these capabilities. We propose a Bayesian account for this gap by grounding planning behavior in the evolving generative context: given the subtle differences between natural language and the language internalized by LLMs, accumulated self-generated context drives a planning-shift during inference and thereby creates the appearance of compromised planning behavior. We further validate the proposed model through two controlled experiments: a random-generation task demonstrating constrained planning under human prompts and increasing planning strength as self-generated context accumulates, and a Gaussian-sampling task showing reduced initial bias when conditioning on self-generated sequences. These findings provide a theoretical explanation along with empirical evidence for characterizing how LLMs plan ahead during inference.", "AI": {"tldr": "LLMs\u5728\u8bad\u7ec3\u4e2d\u83b7\u5f97\u4e86\u5e8f\u5217\u7ea7\u89c4\u5212\u80fd\u529b\uff0c\u4f46\u5728\u63a8\u7406\u65f6\u8868\u73b0\u51fa\u77ed\u89c6\u548c\u4e0d\u4e00\u81f4\u7684\u89c4\u5212\u884c\u4e3a\u3002\u7814\u7a76\u63d0\u51fa\u8d1d\u53f6\u65af\u89e3\u91ca\uff1a\u81ea\u751f\u6210\u4e0a\u4e0b\u6587\u9a71\u52a8\u89c4\u5212\u504f\u79fb\uff0c\u5bfc\u81f4\u770b\u4f3c\u53d7\u635f\u7684\u89c4\u5212\u884c\u4e3a\u3002", "motivation": "\u89e3\u91caLLMs\u5728\u8bad\u7ec3\u4e2d\u83b7\u5f97\u7684\u89c4\u5212\u80fd\u529b\u4e0e\u63a8\u7406\u65f6\u8868\u73b0\u51fa\u7684\u77ed\u89c6\u89c4\u5212\u884c\u4e3a\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\u6765\u89e3\u91ca\u8fd9\u4e00\u73b0\u8c61\u3002", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af\u8d26\u6237\u6a21\u578b\uff0c\u5c06\u89c4\u5212\u884c\u4e3a\u5efa\u7acb\u5728\u4e0d\u65ad\u6f14\u5316\u7684\u751f\u6210\u4e0a\u4e0b\u6587\u57fa\u7840\u4e0a\u3002\u901a\u8fc7\u4e24\u4e2a\u53d7\u63a7\u5b9e\u9a8c\u9a8c\u8bc1\uff1a\u968f\u673a\u751f\u6210\u4efb\u52a1\u5c55\u793a\u4eba\u7c7b\u63d0\u793a\u4e0b\u7684\u53d7\u9650\u89c4\u5212\u548c\u81ea\u751f\u6210\u4e0a\u4e0b\u6587\u79ef\u7d2f\u65f6\u89c4\u5212\u5f3a\u5ea6\u7684\u589e\u52a0\uff1b\u9ad8\u65af\u91c7\u6837\u4efb\u52a1\u663e\u793a\u5728\u81ea\u751f\u6210\u5e8f\u5217\u6761\u4ef6\u4e0b\u521d\u59cb\u504f\u89c1\u7684\u51cf\u5c11\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u63d0\u51fa\u7684\u6a21\u578b\uff1a\u968f\u673a\u751f\u6210\u4efb\u52a1\u663e\u793a\u968f\u7740\u81ea\u751f\u6210\u4e0a\u4e0b\u6587\u79ef\u7d2f\uff0c\u89c4\u5212\u5f3a\u5ea6\u589e\u52a0\uff1b\u9ad8\u65af\u91c7\u6837\u4efb\u52a1\u663e\u793a\u5728\u81ea\u751f\u6210\u5e8f\u5217\u6761\u4ef6\u4e0b\u521d\u59cb\u504f\u89c1\u51cf\u5c11\uff0c\u9a8c\u8bc1\u4e86\u81ea\u751f\u6210\u4e0a\u4e0b\u6587\u9a71\u52a8\u89c4\u5212\u504f\u79fb\u7684\u7406\u8bba\u3002", "conclusion": "\u7814\u7a76\u4e3aLLMs\u5728\u63a8\u7406\u65f6\u5982\u4f55\u63d0\u524d\u89c4\u5212\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\u548c\u5b9e\u8bc1\u8bc1\u636e\uff0c\u8868\u660e\u770b\u4f3c\u53d7\u635f\u7684\u89c4\u5212\u884c\u4e3a\u5b9e\u9645\u4e0a\u662f\u7531\u81ea\u751f\u6210\u4e0a\u4e0b\u6587\u9a71\u52a8\u7684\u89c4\u5212\u504f\u79fb\u6240\u81f4\uff0c\u800c\u975e\u80fd\u529b\u7f3a\u9677\u3002"}}
{"id": "2602.03755", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03755", "abs": "https://arxiv.org/abs/2602.03755", "authors": ["Facundo Molina", "M M Abid Naziri", "Feiran Qin", "Alessandra Gorla", "Marcelo d'Amorim"], "title": "Improving Deep Learning Library Testing with Machine Learning", "comment": "In proceedings of the 7th ACM/IEEE International Conference on Automation of Software Test (AST 2026)", "summary": "Deep Learning (DL) libraries like TensorFlow and Pytorch simplify machine learning (ML) model development but are prone to bugs due to their complex design. Bug-finding techniques exist, but without precise API specifications, they produce many false alarms. Existing methods to mine API specifications lack accuracy. We explore using ML classifiers to determine input validity. We hypothesize that tensor shapes are a precise abstraction to encode concrete inputs and capture relationships of the data. Shape abstraction severely reduces problem dimensionality, which is important to facilitate ML training. Labeled data are obtained by observing runtime outcomes on a sample of inputs and classifiers are trained on sets of labeled inputs to capture API constraints. Our evaluation, conducted over 183 APIs from TensorFlow and Pytorch, shows that the classifiers generalize well on unseen data with over 91% accuracy. Integrating these classifiers into the pipeline of ACETest, a SoTA bug-finding technique, improves its pass rate from ~29% to ~61%. Our findings suggest that ML-enhanced input classification is an important aid to scale DL library testing.", "AI": {"tldr": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u6765\u5b66\u4e60\u6df1\u5ea6\u5b66\u4e60\u5e93API\u7684\u8f93\u5165\u7ea6\u675f\uff0c\u901a\u8fc7\u5f20\u91cf\u5f62\u72b6\u62bd\u8c61\u964d\u4f4e\u95ee\u9898\u7ef4\u5ea6\uff0c\u63d0\u9ad8API\u89c4\u8303\u6316\u6398\u7684\u51c6\u786e\u6027\uff0c\u4ece\u800c\u663e\u8457\u6539\u8fdb\u73b0\u6709bug\u68c0\u6d4b\u5de5\u5177\u7684\u6548\u679c\u3002", "motivation": "TensorFlow\u548cPyTorch\u7b49\u6df1\u5ea6\u5b66\u4e60\u5e93\u867d\u7136\u7b80\u5316\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5f00\u53d1\uff0c\u4f46\u7531\u4e8e\u5176\u590d\u6742\u8bbe\u8ba1\u5bb9\u6613\u4ea7\u751fbug\u3002\u73b0\u6709\u7684bug\u68c0\u6d4b\u6280\u672f\u7f3a\u4e4f\u7cbe\u786e\u7684API\u89c4\u8303\uff0c\u5bfc\u81f4\u5927\u91cf\u8bef\u62a5\u3002\u73b0\u6709\u7684API\u89c4\u8303\u6316\u6398\u65b9\u6cd5\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u65b9\u6cd5\u6765\u6355\u83b7API\u7ea6\u675f\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u6765\u786e\u5b9a\u8f93\u5165\u6709\u6548\u6027\u3002\u6838\u5fc3\u5047\u8bbe\u662f\u5f20\u91cf\u5f62\u72b6\u53ef\u4ee5\u4f5c\u4e3a\u7cbe\u786e\u7684\u62bd\u8c61\u6765\u7f16\u7801\u5177\u4f53\u8f93\u5165\u5e76\u6355\u83b7\u6570\u636e\u5173\u7cfb\u3002\u5f62\u72b6\u62bd\u8c61\u663e\u8457\u964d\u4f4e\u4e86\u95ee\u9898\u7ef4\u5ea6\uff0c\u4fbf\u4e8e\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u3002\u901a\u8fc7\u89c2\u5bdf\u8fd0\u884c\u65f6\u7ed3\u679c\u83b7\u53d6\u6807\u8bb0\u6570\u636e\uff0c\u5728\u6807\u8bb0\u8f93\u5165\u96c6\u4e0a\u8bad\u7ec3\u5206\u7c7b\u5668\u6765\u6355\u83b7API\u7ea6\u675f\u3002", "result": "\u5728TensorFlow\u548cPyTorch\u7684183\u4e2aAPI\u4e0a\u8bc4\u4f30\uff0c\u5206\u7c7b\u5668\u5728\u672a\u89c1\u6570\u636e\u4e0a\u6cdb\u5316\u826f\u597d\uff0c\u51c6\u786e\u7387\u8d85\u8fc791%\u3002\u5c06\u5206\u7c7b\u5668\u96c6\u6210\u5230\u6700\u5148\u8fdb\u7684bug\u68c0\u6d4b\u5de5\u5177ACETest\u4e2d\uff0c\u5c06\u5176\u901a\u8fc7\u7387\u4ece\u7ea629%\u63d0\u9ad8\u5230\u7ea661%\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u589e\u5f3a\u7684\u8f93\u5165\u5206\u7c7b\u662f\u6269\u5c55\u6df1\u5ea6\u5b66\u4e60\u5e93\u6d4b\u8bd5\u7684\u91cd\u8981\u8f85\u52a9\u624b\u6bb5\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8API\u89c4\u8303\u6316\u6398\u7684\u51c6\u786e\u6027\uff0c\u4ece\u800c\u663e\u8457\u6539\u8fdbbug\u68c0\u6d4b\u5de5\u5177\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.03489", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.03489", "abs": "https://arxiv.org/abs/2602.03489", "authors": ["Olha Jure\u010dkov\u00e1", "Martin Jure\u010dek"], "title": "Detecting and Explaining Malware Family Evolution Using Rule-Based Drift Analysis", "comment": null, "summary": "Malware detection and classification into families are critical tasks in cybersecurity, complicated by the continual evolution of malware to evade detection. This evolution introduces concept drift, in which the statistical properties of malware features change over time, reducing the effectiveness of static machine learning models. Understanding and explaining this drift is essential for maintaining robust and trustworthy malware detectors. In this paper, we propose an interpretable approach to concept drift detection. Our method uses a rule-based classifier to generate human-readable descriptions of both original and evolved malware samples belonging to the same malware family. By comparing the resulting rule sets using a similarity function, we can detect and quantify concept drift. Crucially, this comparison also identifies the specific features and feature values that have changed, providing clear explanations of how malware has evolved to bypass detection. Experimental results demonstrate that the proposed method not only accurately detects drift but also provides actionable insights into the behavior of evolving malware families, supporting both detection and threat analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u89c4\u5219\u5206\u7c7b\u5668\u751f\u6210\u53ef\u8bfb\u63cf\u8ff0\uff0c\u6bd4\u8f83\u89c4\u5219\u96c6\u76f8\u4f3c\u6027\u6765\u68c0\u6d4b\u548c\u91cf\u5316\u6076\u610f\u8f6f\u4ef6\u6f14\u5316", "motivation": "\u6076\u610f\u8f6f\u4ef6\u6301\u7eed\u6f14\u5316\u4ee5\u9003\u907f\u68c0\u6d4b\uff0c\u5f15\u5165\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\uff0c\u5bfc\u81f4\u9759\u6001\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6548\u679c\u4e0b\u964d\u3002\u7406\u89e3\u548c\u89e3\u91ca\u8fd9\u79cd\u6f02\u79fb\u5bf9\u4e8e\u7ef4\u62a4\u9c81\u68d2\u53ef\u4fe1\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5668\u81f3\u5173\u91cd\u8981", "method": "\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u5206\u7c7b\u5668\u4e3a\u540c\u4e00\u6076\u610f\u8f6f\u4ef6\u5bb6\u65cf\u7684\u539f\u59cb\u548c\u6f14\u5316\u6837\u672c\u751f\u6210\u4eba\u7c7b\u53ef\u8bfb\u63cf\u8ff0\uff0c\u901a\u8fc7\u76f8\u4f3c\u6027\u51fd\u6570\u6bd4\u8f83\u89c4\u5219\u96c6\u6765\u68c0\u6d4b\u548c\u91cf\u5316\u6982\u5ff5\u6f02\u79fb\uff0c\u8bc6\u522b\u5177\u4f53\u53d8\u5316\u7684\u7279\u5f81\u548c\u7279\u5f81\u503c", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u51c6\u786e\u68c0\u6d4b\u6f02\u79fb\uff0c\u8fd8\u80fd\u63d0\u4f9b\u5173\u4e8e\u6f14\u5316\u6076\u610f\u8f6f\u4ef6\u5bb6\u65cf\u884c\u4e3a\u7684\u53ef\u64cd\u4f5c\u89c1\u89e3\uff0c\u652f\u6301\u68c0\u6d4b\u548c\u5a01\u80c1\u5206\u6790", "conclusion": "\u63d0\u51fa\u7684\u53ef\u89e3\u91ca\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u65b9\u6cd5\u4e3a\u6076\u610f\u8f6f\u4ef6\u6f14\u5316\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u89e3\u91ca\uff0c\u6709\u52a9\u4e8e\u7ef4\u62a4\u6709\u6548\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7cfb\u7edf"}}
{"id": "2602.03798", "categories": ["cs.SE", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.03798", "abs": "https://arxiv.org/abs/2602.03798", "authors": ["Zimu Lu", "Houxing Ren", "Yunqiao Yang", "Ke Wang", "Zhuofan Zong", "Mingjie Zhan", "Hongsheng Li"], "title": "FullStack-Agent: Enhancing Agentic Full-Stack Web Coding via Development-Oriented Testing and Repository Back-Translation", "comment": null, "summary": "Assisting non-expert users to develop complex interactive websites has become a popular task for LLM-powered code agents. However, existing code agents tend to only generate frontend web pages, masking the lack of real full-stack data processing and storage with fancy visual effects. Notably, constructing production-level full-stack web applications is far more challenging than only generating frontend web pages, demanding careful control of data flow, comprehensive understanding of constantly updating packages and dependencies, and accurate localization of obscure bugs in the codebase. To address these difficulties, we introduce FullStack-Agent, a unified agent system for full-stack agentic coding that consists of three parts: (1) FullStack-Dev, a multi-agent framework with strong planning, code editing, codebase navigation, and bug localization abilities. (2) FullStack-Learn, an innovative data-scaling and self-improving method that back-translates crawled and synthesized website repositories to improve the backbone LLM of FullStack-Dev. (3) FullStack-Bench, a comprehensive benchmark that systematically tests the frontend, backend and database functionalities of the generated website. Our FullStack-Dev outperforms the previous state-of-the-art method by 8.7%, 38.2%, and 15.9% on the frontend, backend, and database test cases respectively. Additionally, FullStack-Learn raises the performance of a 30B model by 9.7%, 9.5%, and 2.8% on the three sets of test cases through self-improvement, demonstrating the effectiveness of our approach. The code is released at https://github.com/mnluzimu/FullStack-Agent.", "AI": {"tldr": "FullStack-Agent\u662f\u4e00\u4e2a\u7528\u4e8e\u5168\u6808\u7f51\u7ad9\u5f00\u53d1\u7684\u7edf\u4e00\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5305\u542b\u5f00\u53d1\u6846\u67b6\u3001\u81ea\u5b66\u4e60\u65b9\u6cd5\u548c\u8bc4\u4f30\u57fa\u51c6\u4e09\u90e8\u5206\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5168\u6808\u7f51\u7ad9\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7801\u667a\u80fd\u4f53\u4e3b\u8981\u751f\u6210\u524d\u7aef\u7f51\u9875\uff0c\u7f3a\u4e4f\u771f\u6b63\u7684\u5168\u6808\u6570\u636e\u5904\u7406\u548c\u5b58\u50a8\u80fd\u529b\u3002\u6784\u5efa\u751f\u4ea7\u7ea7\u5168\u6808Web\u5e94\u7528\u6bd4\u4ec5\u751f\u6210\u524d\u7aef\u9875\u9762\u66f4\u5177\u6311\u6218\u6027\uff0c\u9700\u8981\u63a7\u5236\u6570\u636e\u6d41\u3001\u7406\u89e3\u4e0d\u65ad\u66f4\u65b0\u7684\u5305\u4f9d\u8d56\u3001\u5b9a\u4f4d\u4ee3\u7801\u5e93\u4e2d\u7684\u9690\u853dbug\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4e09\u90e8\u5206\uff1a1) FullStack-Dev\uff1a\u5177\u6709\u5f3a\u5927\u89c4\u5212\u3001\u4ee3\u7801\u7f16\u8f91\u3001\u4ee3\u7801\u5e93\u5bfc\u822a\u548cbug\u5b9a\u4f4d\u80fd\u529b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1b2) FullStack-Learn\uff1a\u901a\u8fc7\u53cd\u5411\u7ffb\u8bd1\u722c\u53d6\u548c\u5408\u6210\u7684\u7f51\u7ad9\u4ed3\u5e93\u6765\u6539\u8fdb\u9aa8\u5e72LLM\u7684\u6570\u636e\u6269\u5c55\u548c\u81ea\u5b66\u4e60\u65b9\u6cd5\uff1b3) FullStack-Bench\uff1a\u7cfb\u7edf\u6d4b\u8bd5\u751f\u6210\u7f51\u7ad9\u524d\u7aef\u3001\u540e\u7aef\u548c\u6570\u636e\u5e93\u529f\u80fd\u7684\u7efc\u5408\u57fa\u51c6\u3002", "result": "FullStack-Dev\u5728\u524d\u7aef\u3001\u540e\u7aef\u548c\u6570\u636e\u5e93\u6d4b\u8bd5\u7528\u4f8b\u4e0a\u5206\u522b\u6bd4\u4e4b\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u5347\u4e868.7%\u300138.2%\u548c15.9%\u3002FullStack-Learn\u901a\u8fc7\u81ea\u5b66\u4e60\u5c0630B\u6a21\u578b\u7684\u6027\u80fd\u5728\u524d\u7aef\u3001\u540e\u7aef\u548c\u6570\u636e\u5e93\u6d4b\u8bd5\u96c6\u4e0a\u5206\u522b\u63d0\u5347\u4e869.7%\u30019.5%\u548c2.8%\u3002", "conclusion": "FullStack-Agent\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5168\u6808\u667a\u80fd\u7f16\u7801\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3001\u81ea\u5b66\u4e60\u65b9\u6cd5\u548c\u7efc\u5408\u57fa\u51c6\u7684\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5168\u6808\u7f51\u7ad9\u5f00\u53d1\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4ee3\u7801\u667a\u80fd\u4f53\u4ec5\u5173\u6ce8\u524d\u7aef\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.03003", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03003", "abs": "https://arxiv.org/abs/2602.03003", "authors": ["Zhiyu An", "Wan Du"], "title": "Methods and Open Problems in Differentiable Social Choice: Learning Mechanisms, Decisions, and Alignment", "comment": null, "summary": "Social choice is no longer a peripheral concern of political theory or economics-it has become a foundational component of modern machine learning systems. From auctions and resource allocation to federated learning, participatory governance, and the alignment of large language models, machine learning pipelines increasingly aggregate heterogeneous preferences, incentives, and judgments into collective decisions. In effect, many contemporary machine learning systems already implement social choice mechanisms, often implicitly and without explicit normative scrutiny.\n  This Review surveys differentiable social choice: an emerging paradigm that formulates voting rules, mechanisms, and aggregation procedures as learnable, differentiable models optimized from data. We synthesize work across auctions, voting, budgeting, liquid democracy, decentralized aggregation, and inverse mechanism learning, showing how classical axioms and impossibility results reappear as objectives, constraints, and optimization trade-offs. We conclude by identifying 36 open problems defining a new research agenda at the intersection of machine learning, economics, and democratic theory.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u53ef\u5fae\u5206\u793e\u4f1a\u9009\u62e9\u8fd9\u4e00\u65b0\u5174\u8303\u5f0f\uff0c\u5c06\u6295\u7968\u89c4\u5219\u3001\u673a\u5236\u548c\u805a\u5408\u8fc7\u7a0b\u4f5c\u4e3a\u53ef\u4ece\u6570\u636e\u4e2d\u4f18\u5316\u7684\u53ef\u5b66\u4e60\u3001\u53ef\u5fae\u5206\u6a21\u578b\uff0c\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\u3001\u7ecf\u6d4e\u5b66\u548c\u6c11\u4e3b\u7406\u8bba\u7684\u4ea4\u53c9\u9886\u57df\u3002", "motivation": "\u793e\u4f1a\u9009\u62e9\u5df2\u4ece\u653f\u6cbb\u7406\u8bba\u548c\u7ecf\u6d4e\u5b66\u7684\u5916\u56f4\u5173\u6ce8\u70b9\u8f6c\u53d8\u4e3a\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u57fa\u7840\u7ec4\u6210\u90e8\u5206\u3002\u4ece\u62cd\u5356\u548c\u8d44\u6e90\u5206\u914d\u5230\u8054\u90a6\u5b66\u4e60\u3001\u53c2\u4e0e\u5f0f\u6cbb\u7406\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\uff0c\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u8d8a\u6765\u8d8a\u591a\u5730\u5c06\u5f02\u8d28\u504f\u597d\u3001\u6fc0\u52b1\u548c\u5224\u65ad\u805a\u5408\u6210\u96c6\u4f53\u51b3\u7b56\u3002\u8bb8\u591a\u5f53\u4ee3\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5df2\u7ecf\u5b9e\u73b0\u4e86\u793e\u4f1a\u9009\u62e9\u673a\u5236\uff0c\u4f46\u901a\u5e38\u662f\u9690\u5f0f\u4e14\u7f3a\u4e4f\u660e\u786e\u7684\u89c4\u8303\u5ba1\u67e5\u3002", "method": "\u672c\u6587\u91c7\u7528\u7efc\u8ff0\u7814\u7a76\u65b9\u6cd5\uff0c\u7efc\u5408\u4e86\u62cd\u5356\u3001\u6295\u7968\u3001\u9884\u7b97\u7f16\u5236\u3001\u6d41\u52a8\u6c11\u4e3b\u3001\u53bb\u4e2d\u5fc3\u5316\u805a\u5408\u548c\u9006\u5411\u673a\u5236\u5b66\u4e60\u7b49\u9886\u57df\u7684\u5de5\u4f5c\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u7ecf\u5178\u516c\u7406\u548c\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\u91cd\u65b0\u8868\u8ff0\u4e3a\u76ee\u6807\u3001\u7ea6\u675f\u548c\u4f18\u5316\u6743\u8861\u3002", "result": "\u63d0\u51fa\u4e86\u53ef\u5fae\u5206\u793e\u4f1a\u9009\u62e9\u8fd9\u4e00\u65b0\u5174\u8303\u5f0f\uff0c\u5c06\u793e\u4f1a\u9009\u62e9\u673a\u5236\u5f62\u5f0f\u5316\u4e3a\u53ef\u5b66\u4e60\u3001\u53ef\u5fae\u5206\u7684\u6a21\u578b\uff0c\u80fd\u591f\u4ece\u6570\u636e\u4e2d\u8fdb\u884c\u4f18\u5316\u3002\u8bc6\u522b\u4e8636\u4e2a\u5f00\u653e\u6027\u95ee\u9898\uff0c\u5b9a\u4e49\u4e86\u4e00\u4e2a\u65b0\u7684\u7814\u7a76\u8bae\u7a0b\u3002", "conclusion": "\u53ef\u5fae\u5206\u793e\u4f1a\u9009\u62e9\u4e3a\u673a\u5668\u5b66\u4e60\u3001\u7ecf\u6d4e\u5b66\u548c\u6c11\u4e3b\u7406\u8bba\u7684\u4ea4\u53c9\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u793e\u4f1a\u9009\u62e9\u673a\u5236\u5f62\u5f0f\u5316\u4e3a\u53ef\u4f18\u5316\u6a21\u578b\uff0c\u4e3a\u89e3\u51b3\u4f20\u7edf\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u4e2d\u7684\u89c4\u8303\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u66f4\u516c\u5e73\u3001\u900f\u660e\u548c\u6709\u6548\u7684\u96c6\u4f53\u51b3\u7b56\u7cfb\u7edf\u5f00\u8f9f\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.03648", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.03648", "abs": "https://arxiv.org/abs/2602.03648", "authors": ["Ehsan Firouzi", "Shardul Bhatt", "Mohammad Ghafari"], "title": "Can Developers rely on LLMs for Secure IaC Development?", "comment": null, "summary": "We investigated the capabilities of GPT-4o and Gemini 2.0 Flash for secure Infrastructure as Code (IaC) development. For security smell detection, on the Stack Overflow dataset, which primarily contains small, simplified code snippets, the models detected at least 71% of security smells when prompted to analyze code from a security perspective (general prompt). With a guided prompt (adding clear, step-by-step instructions), this increased to 78%.In GitHub repositories, which contain complete, real-world project scripts, a general prompt was less effective, leaving more than half of the smells undetected. However, with the guided prompt, the models uncovered at least 67% of the smells. For secure code generation, we prompted LLMs with 89 vulnerable synthetic scenarios and observed that only 7% of the generated scripts were secure. Adding an explicit instruction to generate secure code increased GPT secure output rate to 17%, while Gemini changed little (8%). These results highlight the need for further research to improve LLMs' capabilities in assisting developers with secure IaC development.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30GPT-4o\u548cGemini 2.0 Flash\u5728\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\u5b89\u5168\u5f00\u53d1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u63d0\u793a\u7b56\u7565\u5bf9\u5b89\u5168\u6f0f\u6d1e\u68c0\u6d4b\u6548\u679c\u663e\u8457\uff0c\u4f46\u5b89\u5168\u4ee3\u7801\u751f\u6210\u80fd\u529b\u6709\u9650", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\u5b89\u5168\u5f00\u53d1\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u4e86\u89e3\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u5bf9\u5b89\u5168\u6f0f\u6d1e\u68c0\u6d4b\u548c\u5b89\u5168\u4ee3\u7801\u751f\u6210\u6548\u679c\u7684\u5f71\u54cd", "method": "\u4f7f\u7528\u4e24\u79cd\u63d0\u793a\u7b56\u7565\uff08\u901a\u7528\u63d0\u793a\u548c\u5f15\u5bfc\u63d0\u793a\uff09\u6d4b\u8bd5GPT-4o\u548cGemini 2.0 Flash\u5728Stack Overflow\u6570\u636e\u96c6\uff08\u5c0f\u578b\u7b80\u5316\u4ee3\u7801\u7247\u6bb5\uff09\u548cGitHub\u4ed3\u5e93\uff08\u5b8c\u6574\u771f\u5b9e\u9879\u76ee\u811a\u672c\uff09\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\u68c0\u6d4b\u80fd\u529b\uff0c\u4ee5\u53ca\u901a\u8fc789\u4e2a\u6613\u53d7\u653b\u51fb\u7684\u5408\u6210\u573a\u666f\u6d4b\u8bd5\u5b89\u5168\u4ee3\u7801\u751f\u6210\u80fd\u529b", "result": "\u5b89\u5168\u6f0f\u6d1e\u68c0\u6d4b\uff1a\u5728Stack Overflow\u6570\u636e\u96c6\u4e0a\uff0c\u901a\u7528\u63d0\u793a\u80fd\u68c0\u6d4b\u81f3\u5c1171%\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5f15\u5bfc\u63d0\u793a\u63d0\u5347\u81f378%\uff1b\u5728GitHub\u4ed3\u5e93\u4e2d\uff0c\u901a\u7528\u63d0\u793a\u6548\u679c\u8f83\u5dee\uff08\u8d85\u8fc7\u4e00\u534a\u6f0f\u6d1e\u672a\u68c0\u6d4b\uff09\uff0c\u5f15\u5bfc\u63d0\u793a\u80fd\u68c0\u6d4b\u81f3\u5c1167%\u7684\u6f0f\u6d1e\u3002\u5b89\u5168\u4ee3\u7801\u751f\u6210\uff1a\u4ec57%\u7684\u751f\u6210\u811a\u672c\u662f\u5b89\u5168\u7684\uff0c\u660e\u786e\u8981\u6c42\u751f\u6210\u5b89\u5168\u4ee3\u7801\u540e\uff0cGPT\u5b89\u5168\u8f93\u51fa\u7387\u63d0\u5347\u81f317%\uff0cGemini\u53d8\u5316\u4e0d\u5927\uff088%\uff09", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u534f\u52a9\u5f00\u53d1\u8005\u8fdb\u884c\u5b89\u5168\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\u5f00\u53d1\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5b89\u5168\u4ee3\u7801\u751f\u6210\u80fd\u529b\u9700\u8981\u663e\u8457\u63d0\u5347"}}
{"id": "2602.03006", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03006", "abs": "https://arxiv.org/abs/2602.03006", "authors": ["Ziyang Yu", "Liang Zhao"], "title": "Distilling LLM Reasoning into Graph of Concept Predictors", "comment": null, "summary": "Deploying Large Language Models (LLMs) for discriminative workloads is often limited by inference latency, compute, and API costs at scale. Active distillation reduces these costs by querying an LLM oracle to train compact discriminative students, but most pipelines distill only final labels, discarding intermediate reasoning signals and offering limited diagnostics of what reasoning is missing and where errors arise. We propose Graph of Concept Predictors (GCP), a reasoning-aware active distillation framework that externalizes the teacher's decision process as a directed acyclic graph and mirrors it with modular concept predictors in the student. GCP enhances sample efficiency through a graph-aware acquisition strategy that targets uncertainty and disagreement at critical reasoning nodes. Additionally, it improves training stability and efficiency by performing targeted sub-module retraining, which attributes downstream loss to specific concept predictors and updates only the most influential modules. Experiments on eight NLP classification benchmarks demonstrate that GCP enhances performance under limited annotation budgets while yielding more interpretable and controllable training dynamics. Code is available at: https://github.com/Ziyang-Yu/GCP.", "AI": {"tldr": "GCP\u662f\u4e00\u4e2a\u63a8\u7406\u611f\u77e5\u7684\u4e3b\u52a8\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6559\u5e08LLM\u7684\u51b3\u7b56\u8fc7\u7a0b\u5916\u90e8\u5316\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff0c\u5e76\u7528\u6a21\u5757\u5316\u6982\u5ff5\u9884\u6d4b\u5668\u5728\u5b66\u751f\u6a21\u578b\u4e2d\u955c\u50cf\u8be5\u56fe\uff0c\u4ece\u800c\u63d0\u9ad8\u6837\u672c\u6548\u7387\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "motivation": "\u5f53\u524dLLM\u5728\u5224\u522b\u4efb\u52a1\u90e8\u7f72\u4e2d\u9762\u4e34\u63a8\u7406\u5ef6\u8fdf\u3001\u8ba1\u7b97\u548cAPI\u6210\u672c\u95ee\u9898\u3002\u4e3b\u52a8\u84b8\u998f\u65b9\u6cd5\u901a\u5e38\u53ea\u84b8\u998f\u6700\u7ec8\u6807\u7b7e\uff0c\u4e22\u5f03\u4e86\u4e2d\u95f4\u63a8\u7406\u4fe1\u53f7\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u7f3a\u5931\u63a8\u7406\u548c\u9519\u8bef\u6765\u6e90\u7684\u8bca\u65ad\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u56fe\u6982\u5ff5\u9884\u6d4b\u5668(GCP)\u6846\u67b6\uff1a1) \u5c06\u6559\u5e08LLM\u7684\u51b3\u7b56\u8fc7\u7a0b\u5916\u90e8\u5316\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff1b2) \u5728\u5b66\u751f\u6a21\u578b\u4e2d\u7528\u6a21\u5757\u5316\u6982\u5ff5\u9884\u6d4b\u5668\u955c\u50cf\u8be5\u56fe\uff1b3) \u91c7\u7528\u56fe\u611f\u77e5\u7684\u91c7\u96c6\u7b56\u7565\uff0c\u9488\u5bf9\u5173\u952e\u63a8\u7406\u8282\u70b9\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u5206\u6b67\uff1b4) \u5b9e\u65bd\u76ee\u6807\u5b50\u6a21\u5757\u91cd\u8bad\u7ec3\uff0c\u5c06\u4e0b\u6e38\u635f\u5931\u5f52\u56e0\u4e8e\u7279\u5b9a\u6982\u5ff5\u9884\u6d4b\u5668\u5e76\u4ec5\u66f4\u65b0\u6700\u6709\u5f71\u54cd\u7684\u6a21\u5757\u3002", "result": "\u5728\u516b\u4e2aNLP\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGCP\u5728\u6709\u9650\u6807\u6ce8\u9884\u7b97\u4e0b\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u540c\u65f6\u4ea7\u751f\u4e86\u66f4\u53ef\u89e3\u91ca\u548c\u53ef\u63a7\u7684\u8bad\u7ec3\u52a8\u6001\u3002", "conclusion": "GCP\u6846\u67b6\u901a\u8fc7\u5916\u90e8\u5316\u6559\u5e08\u63a8\u7406\u8fc7\u7a0b\u3001\u6a21\u5757\u5316\u5b66\u751f\u8bbe\u8ba1\u548c\u76ee\u6807\u8bad\u7ec3\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u4e3b\u52a8\u84b8\u998f\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u63a7\u5236\u6027\u3002"}}
{"id": "2602.03022", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03022", "abs": "https://arxiv.org/abs/2602.03022", "authors": ["Jiliang Ni", "Jiachen Pu", "Zhongyi Yang", "Jingfeng Luo", "Conggang Hu"], "title": "STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models", "comment": "The paper has been accepted to ICLR 2026", "summary": "The proliferation of Large Language Models (LLMs) in function calling is pivotal for creating advanced AI agents, yet their large scale hinders widespread adoption, necessitating transferring their capabilities into smaller ones. However, existing paradigms are often plagued by overfitting, training instability, ineffective binary rewards for multi-solution tasks, and the difficulty of synergizing techniques. We introduce STAR: Similarity-guided Teacher-Assisted Refinement, a novel holistic framework that effectively transfers LLMs' capabilities to super-tiny models. STAR consists of two core technical innovations: (1) Constrained Knowledge Distillation (CKD), a training objective that augments top-k forward KL divergence to suppress confidently incorrect predictions, ensuring training stability while preserving exploration capacity for downstream RL. STAR holistically synergizes these strategies within a cohesive training curriculum, enabling super-tiny models to achieve exceptional performance on complex function calling tasks; (2) Similarity-guided RL (Sim-RL), a RL mechanism that introduces a fine-grained, similarity-based reward. This provides a robust, continuous, and rich signal for better policy optimization by evaluating the similarity between generated outputs and the ground truth. Extensive experiments on challenging and renowned benchmarks demonstrate the effectiveness of our method. Our STAR models establish SOTA in their size classes, significantly outperforming baselines. Remarkably, our 0.6B STAR model achieves the best performance among all open models under 1B, surpassing even several well-known open models at a larger scale. STAR demonstrates a training framework that distills capabilities of LLMs into super-tiny models, paving the way for powerful, accessible, and efficient AI agents.", "AI": {"tldr": "STAR\u6846\u67b6\u901a\u8fc7\u76f8\u4f3c\u6027\u5f15\u5bfc\u7684\u6559\u5e08\u8f85\u52a9\u7cbe\u70bc\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u8f6c\u79fb\u5230\u8d85\u5c0f\u6a21\u578b\u4e2d\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u8fc7\u62df\u5408\u3001\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3001\u4e8c\u5143\u5956\u52b1\u65e0\u6548\u7b49\u95ee\u9898\uff0c\u5728\u51fd\u6570\u8c03\u7528\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86SOTA\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51fd\u6570\u8c03\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u5de8\u5927\u89c4\u6a21\u963b\u788d\u4e86\u5e7f\u6cdb\u91c7\u7528\uff0c\u9700\u8981\u5c06\u5176\u80fd\u529b\u8f6c\u79fb\u5230\u66f4\u5c0f\u7684\u6a21\u578b\u4e2d\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u8fc7\u62df\u5408\u3001\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3001\u591a\u89e3\u4efb\u52a1\u4e2d\u4e8c\u5143\u5956\u52b1\u65e0\u6548\u4ee5\u53ca\u6280\u672f\u96be\u4ee5\u534f\u540c\u7b49\u95ee\u9898\u3002", "method": "STAR\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6280\u672f\u521b\u65b0\uff1a1) \u7ea6\u675f\u77e5\u8bc6\u84b8\u998f(CKD)\uff0c\u901a\u8fc7\u589e\u5f3atop-k\u524d\u5411KL\u6563\u5ea6\u6765\u6291\u5236\u81ea\u4fe1\u7684\u9519\u8bef\u9884\u6d4b\uff0c\u786e\u4fdd\u8bad\u7ec3\u7a33\u5b9a\u6027\u540c\u65f6\u4fdd\u7559\u4e0b\u6e38\u5f3a\u5316\u5b66\u4e60\u7684\u63a2\u7d22\u80fd\u529b\uff1b2) \u76f8\u4f3c\u6027\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60(Sim-RL)\uff0c\u5f15\u5165\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u7ec6\u7c92\u5ea6\u5956\u52b1\uff0c\u901a\u8fc7\u8bc4\u4f30\u751f\u6210\u8f93\u51fa\u4e0e\u771f\u5b9e\u503c\u7684\u76f8\u4f3c\u6027\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u4f18\u5316\u4fe1\u53f7\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSTAR\u6a21\u578b\u5728\u5176\u89c4\u6a21\u7c7b\u522b\u4e2d\u5efa\u7acb\u4e86SOTA\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002\u7279\u522b\u662f0.6B\u7684STAR\u6a21\u578b\u5728\u6240\u67091B\u4ee5\u4e0b\u7684\u5f00\u6e90\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u751a\u81f3\u8d85\u8d8a\u4e86\u591a\u4e2a\u66f4\u5927\u89c4\u6a21\u7684\u77e5\u540d\u5f00\u6e90\u6a21\u578b\u3002", "conclusion": "STAR\u5c55\u793a\u4e86\u4e00\u4e2a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u84b8\u998f\u5230\u8d85\u5c0f\u6a21\u578b\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u4e3a\u5f3a\u5927\u3001\u53ef\u8bbf\u95ee\u4e14\u9ad8\u6548\u7684\u4eba\u5de5\u667a\u80fd\u667a\u80fd\u4f53\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2602.03671", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.03671", "abs": "https://arxiv.org/abs/2602.03671", "authors": ["Cornell Ziepel", "Stephan Escher", "Sebastian Rehms", "Stefan K\u00f6psell"], "title": "mopri - An Analysis Framework for Unveiling Privacy Violations in Mobile Apps", "comment": null, "summary": "Everyday services of society increasingly rely on mobile applications, resulting in a conflicting situation between the possibility of participation on the one side and user privacy and digital freedom on the other. In order to protect users' rights to informational self-determination, regulatory approaches for the collection and processing of personal data have been developed, such as the EU's GDPR. However, inspecting the compliance of mobile apps with privacy regulations remains difficult. Thus, in order to enable end users and enforcement bodies to verify and enforce data protection compliance, we propose mopri, a conceptual framework designed for analyzing the behavior of mobile apps through a comprehensive, adaptable, and user-centered approach. Recognizing the gaps in existing frameworks, mopri serves as a foundation for integrating various analysis tools into a streamlined, modular pipeline that employs static and dynamic analysis methods. Building on this concept, a prototype has been developed which effectively extracts permissions and tracking libraries while employing robust methods for dynamic traffic recording and decryption. Additionally, it incorporates result enrichment and reporting features that enhance the clarity and usability of the analysis outcomes. The prototype showcases the feasibility of a holistic and modular approach to privacy analysis, emphasizing the importance of continuous adaptation to the evolving challenges presented by the mobile app ecosystem.", "AI": {"tldr": "mopri\u662f\u4e00\u4e2a\u7528\u4e8e\u5206\u6790\u79fb\u52a8\u5e94\u7528\u9690\u79c1\u5408\u89c4\u6027\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u901a\u8fc7\u9759\u6001\u548c\u52a8\u6001\u5206\u6790\u65b9\u6cd5\u96c6\u6210\u591a\u79cd\u5de5\u5177\uff0c\u5e2e\u52a9\u7528\u6237\u548c\u76d1\u7ba1\u673a\u6784\u9a8c\u8bc1\u6570\u636e\u4fdd\u62a4\u5408\u89c4\u6027\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u7684\u666e\u53ca\u5e26\u6765\u4e86\u53c2\u4e0e\u53ef\u80fd\u6027\u4e0e\u7528\u6237\u9690\u79c1\u3001\u6570\u5b57\u81ea\u7531\u4e4b\u95f4\u7684\u51b2\u7a81\u3002\u867d\u7136GDPR\u7b49\u6cd5\u89c4\u4fdd\u62a4\u7528\u6237\u4fe1\u606f\u81ea\u51b3\u6743\uff0c\u4f46\u68c0\u67e5\u79fb\u52a8\u5e94\u7528\u9690\u79c1\u5408\u89c4\u6027\u4ecd\u7136\u56f0\u96be\uff0c\u9700\u8981\u4e3a\u7ec8\u7aef\u7528\u6237\u548c\u6267\u6cd5\u673a\u6784\u63d0\u4f9b\u9a8c\u8bc1\u548c\u6267\u884c\u6570\u636e\u4fdd\u62a4\u5408\u89c4\u6027\u7684\u5de5\u5177\u3002", "method": "\u63d0\u51famopri\u6982\u5ff5\u6846\u67b6\uff0c\u91c7\u7528\u6a21\u5757\u5316\u6d41\u6c34\u7ebf\u8bbe\u8ba1\uff0c\u96c6\u6210\u9759\u6001\u548c\u52a8\u6001\u5206\u6790\u65b9\u6cd5\u3002\u539f\u578b\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u63d0\u53d6\u6743\u9650\u548c\u8ffd\u8e2a\u5e93\uff0c\u91c7\u7528\u9c81\u68d2\u7684\u52a8\u6001\u6d41\u91cf\u8bb0\u5f55\u548c\u89e3\u5bc6\u65b9\u6cd5\uff0c\u5e76\u5305\u542b\u7ed3\u679c\u589e\u5f3a\u548c\u62a5\u544a\u529f\u80fd\u3002", "result": "\u5f00\u53d1\u7684\u539f\u578b\u7cfb\u7edf\u5c55\u793a\u4e86\u6574\u4f53\u6a21\u5757\u5316\u9690\u79c1\u5206\u6790\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u80fd\u591f\u6709\u6548\u63d0\u53d6\u6743\u9650\u548c\u8ffd\u8e2a\u5e93\uff0c\u8fdb\u884c\u52a8\u6001\u6d41\u91cf\u8bb0\u5f55\u548c\u89e3\u5bc6\uff0c\u5e76\u901a\u8fc7\u7ed3\u679c\u589e\u5f3a\u63d0\u9ad8\u5206\u6790\u7ed3\u679c\u7684\u6e05\u6670\u5ea6\u548c\u53ef\u7528\u6027\u3002", "conclusion": "mopri\u6846\u67b6\u4e3a\u79fb\u52a8\u5e94\u7528\u9690\u79c1\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u3001\u53ef\u9002\u5e94\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u6301\u7eed\u9002\u5e94\u79fb\u52a8\u5e94\u7528\u751f\u6001\u7cfb\u7edf\u4e0d\u65ad\u53d8\u5316\u6311\u6218\u7684\u91cd\u8981\u6027\uff0c\u6709\u52a9\u4e8e\u9a8c\u8bc1\u548c\u6267\u884c\u6570\u636e\u4fdd\u62a4\u5408\u89c4\u6027\u3002"}}
{"id": "2602.03025", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03025", "abs": "https://arxiv.org/abs/2602.03025", "authors": ["Haitian Zhong", "Jixiu Zhai", "Lei Song", "Jiang Bian", "Qiang Liu", "Tieniu Tan"], "title": "RC-GRPO: Reward-Conditioned Group Relative Policy Optimization for Multi-Turn Tool Calling Agents", "comment": null, "summary": "Multi-turn tool calling is challenging for Large Language Models (LLMs) because rewards are sparse and exploration is expensive. A common recipe, SFT followed by GRPO, can stall when within-group reward variation is low (e.g., more rollouts in a group receive the all 0 or all 1 reward), making the group-normalized advantage uninformative and yielding vanishing updates. To address this problem, we propose RC-GRPO (Reward-Conditioned Group Relative Policy Optimization), which treats exploration as a controllable steering problem via discrete reward tokens. We first fine-tune a Reward-Conditioned Trajectory Policy (RCTP) on mixed-quality trajectories with reward goal special tokens (e.g., <|high_reward|>, <|low_reward|>) injected into the prompts, enabling the model to learn how to generate distinct quality trajectories on demand. Then during RL, we sample diverse reward tokens within each GRPO group and condition rollouts on the sampled token to improve within-group diversity, improving advantage gains. On the Berkeley Function Calling Leaderboard v4 (BFCLv4) multi-turn benchmark, our method yields consistently improved performance than baselines, and the performance on Qwen-2.5-7B-Instruct even surpasses all closed-source API models.", "AI": {"tldr": "\u63d0\u51faRC-GRPO\u65b9\u6cd5\u89e3\u51b3LLM\u591a\u8f6e\u5de5\u5177\u8c03\u7528\u4e2d\u5956\u52b1\u7a00\u758f\u548c\u63a2\u7d22\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u6ce8\u5165\u5956\u52b1\u76ee\u6807\u7279\u6b8a\u6807\u8bb0\u6765\u589e\u5f3a\u7ec4\u5185\u591a\u6837\u6027\uff0c\u5728BFCLv4\u57fa\u51c6\u4e0a\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u591a\u8f6e\u5de5\u5177\u8c03\u7528\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5956\u52b1\u7a00\u758f\u4e14\u63a2\u7d22\u6210\u672c\u9ad8\u3002\u4f20\u7edf\u7684SFT+GRPO\u65b9\u6cd5\u5728\u7ec4\u5185\u5956\u52b1\u53d8\u5316\u4f4e\u65f6\uff08\u5982\u66f4\u591arollout\u83b7\u5f97\u51680\u6216\u51681\u5956\u52b1\uff09\u4f1a\u505c\u6ede\uff0c\u5bfc\u81f4\u7ec4\u5f52\u4e00\u5316\u4f18\u52bf\u4fe1\u606f\u4e0d\u8db3\uff0c\u4ea7\u751f\u6d88\u5931\u7684\u66f4\u65b0", "method": "\u63d0\u51faRC-GRPO\uff08\u5956\u52b1\u6761\u4ef6\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff09\u65b9\u6cd5\uff1a1\uff09\u9996\u5148\u5728\u6df7\u5408\u8d28\u91cf\u8f68\u8ff9\u4e0a\u5fae\u8c03\u5956\u52b1\u6761\u4ef6\u8f68\u8ff9\u7b56\u7565\uff0c\u5728\u63d0\u793a\u4e2d\u6ce8\u5165\u5956\u52b1\u76ee\u6807\u7279\u6b8a\u6807\u8bb0\uff08\u5982<|high_reward|>, <|low_reward|>\uff09\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u6309\u9700\u751f\u6210\u4e0d\u540c\u8d28\u91cf\u7684\u8f68\u8ff9\uff1b2\uff09\u5728\u5f3a\u5316\u5b66\u4e60\u671f\u95f4\uff0c\u5728\u6bcf\u4e2aGRPO\u7ec4\u5185\u91c7\u6837\u4e0d\u540c\u7684\u5956\u52b1\u6807\u8bb0\uff0c\u5e76\u5728\u91c7\u6837\u7684\u6807\u8bb0\u4e0a\u6761\u4ef6\u5316rollout\uff0c\u4ee5\u63d0\u9ad8\u7ec4\u5185\u591a\u6837\u6027", "result": "\u5728Berkeley Function Calling Leaderboard v4\u591a\u8f6e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0cQwen-2.5-7B-Instruct\u6a21\u578b\u7684\u6027\u80fd\u751a\u81f3\u8d85\u8fc7\u4e86\u6240\u6709\u95ed\u6e90API\u6a21\u578b", "conclusion": "RC-GRPO\u901a\u8fc7\u5c06\u63a2\u7d22\u89c6\u4e3a\u53ef\u63a7\u7684\u8f6c\u5411\u95ee\u9898\uff0c\u4f7f\u7528\u79bb\u6563\u5956\u52b1\u6807\u8bb0\u6765\u589e\u5f3a\u7ec4\u5185\u591a\u6837\u6027\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f6e\u5de5\u5177\u8c03\u7528\u4e2d\u5956\u52b1\u7a00\u758f\u548c\u63a2\u7d22\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd"}}
{"id": "2602.03026", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03026", "abs": "https://arxiv.org/abs/2602.03026", "authors": ["Weilin Ruan", "Yuxuan Liang"], "title": "Visual Reasoning over Time Series via Multi-Agent System", "comment": null, "summary": "Time series analysis underpins many real-world applications, yet existing time-series-specific methods and pretrained large-model-based approaches remain limited in integrating intuitive visual reasoning and generalizing across tasks with adaptive tool usage. To address these limitations, we propose MAS4TS, a tool-driven multi-agent system for general time series tasks, built upon an Analyzer-Reasoner-Executor paradigm that integrates agent communication, visual reasoning, and latent reconstruction within a unified framework. MAS4TS first performs visual reasoning over time series plots with structured priors using a Vision-Language Model to extract temporal structures, and subsequently reconstructs predictive trajectories in latent space. Three specialized agents coordinate via shared memory and gated communication, while a router selects task-specific tool chains for execution. Extensive experiments on multiple benchmarks demonstrate that MAS4TS achieves state-of-the-art performance across a wide range of time series tasks, while exhibiting strong generalization and efficient inference.", "AI": {"tldr": "MAS4TS\uff1a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u63a8\u7406\u548c\u6f5c\u5728\u91cd\u5efa\u5b9e\u73b0\u8de8\u4efb\u52a1\u6cdb\u5316", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u65b9\u6cd5\u5728\u6574\u5408\u76f4\u89c2\u89c6\u89c9\u63a8\u7406\u548c\u8de8\u4efb\u52a1\u81ea\u9002\u5e94\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7ed3\u5408\u89c6\u89c9\u7406\u89e3\u548c\u901a\u7528\u6cdb\u5316\u80fd\u529b\u7684\u65b0\u6846\u67b6", "method": "\u63d0\u51fa\u57fa\u4e8eAnalyzer-Reasoner-Executor\u8303\u5f0f\u7684\u5de5\u5177\u9a71\u52a8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5305\u542b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u56fe\u7684\u89c6\u89c9\u63a8\u7406\u63d0\u53d6\u65f6\u95f4\u7ed3\u6784\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u91cd\u5efa\u9884\u6d4b\u8f68\u8ff9\uff0c\u4e09\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\u901a\u8fc7\u5171\u4eab\u5185\u5b58\u548c\u95e8\u63a7\u901a\u4fe1\u534f\u8c03\uff0c\u8def\u7531\u5668\u9009\u62e9\u4efb\u52a1\u7279\u5b9a\u5de5\u5177\u94fe\u6267\u884c", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMAS4TS\u5728\u5e7f\u6cdb\u7684\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9ad8\u6548\u7684\u63a8\u7406", "conclusion": "MAS4TS\u901a\u8fc7\u6574\u5408\u667a\u80fd\u4f53\u901a\u4fe1\u3001\u89c6\u89c9\u63a8\u7406\u548c\u6f5c\u5728\u91cd\u5efa\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u4e3a\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u7684\u6f5c\u529b"}}
{"id": "2602.03053", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03053", "abs": "https://arxiv.org/abs/2602.03053", "authors": ["Vishal Venkataramani", "Haizhou Shi", "Zixuan Ke", "Austin Xu", "Xiaoxiao He", "Yingbo Zhou", "Semih Yavuz", "Hao Wang", "Shafiq Joty"], "title": "MAS-ProVe: Understanding the Process Verification of Multi-Agent Systems", "comment": "Preprint; work in progress", "summary": "Multi-Agent Systems (MAS) built on Large Language Models (LLMs) often exhibit high variance in their reasoning trajectories. Process verification, which evaluates intermediate steps in trajectories, has shown promise in general reasoning settings, and has been suggested as a potential tool for guiding coordination of MAS; however, its actual effectiveness in MAS remains unclear. To fill this gap, we present MAS-ProVe, a systematic empirical study of process verification for multi-agent systems (MAS). Our study spans three verification paradigms (LLM-as-a-Judge, reward models, and process reward models), evaluated across two levels of verification granularity (agent-level and iteration-level). We further examine five representative verifiers and four context management strategies, and conduct experiments over six diverse MAS frameworks on multiple reasoning benchmarks. We find that process-level verification does not consistently improve performance and frequently exhibits high variance, highlighting the difficulty of reliably evaluating partial multi-agent trajectories. Among the methods studied, LLM-as-a-Judge generally outperforms reward-based approaches, with trained judges surpassing general-purpose LLMs. We further observe a small performance gap between LLMs acting as judges and as single agents, and identify a context-length-performance trade-off in verification. Overall, our results suggest that effective and robust process verification for MAS remains an open challenge, requiring further advances beyond current paradigms. Code is available at https://github.com/Wang-ML-Lab/MAS-ProVe.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u8fc7\u7a0b\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u53d1\u73b0\u8fc7\u7a0b\u7ea7\u9a8c\u8bc1\u5e76\u4e0d\u603b\u80fd\u63d0\u5347\u6027\u80fd\u4e14\u65b9\u5dee\u8f83\u5927\uff0cLLM\u4f5c\u4e3a\u88c1\u5224\u7684\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u6709\u6548\u7684\u591a\u667a\u80fd\u4f53\u8fc7\u7a0b\u9a8c\u8bc1\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u63a8\u7406\u8f68\u8ff9\u4e0a\u5b58\u5728\u9ad8\u65b9\u5dee\uff0c\u8fc7\u7a0b\u9a8c\u8bc1\uff08\u8bc4\u4f30\u4e2d\u95f4\u6b65\u9aa4\uff09\u5728\u4e00\u822c\u63a8\u7406\u573a\u666f\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u6548\u679c\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u5b9e\u8bc1\u7814\u7a76\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86MAS-ProVe\u6846\u67b6\uff0c\u7cfb\u7edf\u7814\u7a76\u4e86\u4e09\u79cd\u9a8c\u8bc1\u8303\u5f0f\uff08LLM\u4f5c\u4e3a\u88c1\u5224\u3001\u5956\u52b1\u6a21\u578b\u3001\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff09\uff0c\u5728\u4e24\u4e2a\u9a8c\u8bc1\u7c92\u5ea6\uff08\u667a\u80fd\u4f53\u7ea7\u548c\u8fed\u4ee3\u7ea7\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\u7814\u7a76\u4e86\u4e94\u4e2a\u4ee3\u8868\u6027\u9a8c\u8bc1\u5668\u548c\u56db\u79cd\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\uff0c\u5728\u516d\u4e2a\u4e0d\u540c\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u548c\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u8fc7\u7a0b\u7ea7\u9a8c\u8bc1\u5e76\u4e0d\u603b\u80fd\u63d0\u5347\u6027\u80fd\u4e14\u7ecf\u5e38\u8868\u73b0\u51fa\u9ad8\u65b9\u5dee\uff0c\u7a81\u663e\u4e86\u53ef\u9760\u8bc4\u4f30\u90e8\u5206\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u7684\u56f0\u96be\u3002\u5728\u7814\u7a76\u65b9\u6cd5\u4e2d\uff0cLLM\u4f5c\u4e3a\u88c1\u5224\u7684\u65b9\u6cd5\u901a\u5e38\u4f18\u4e8e\u57fa\u4e8e\u5956\u52b1\u7684\u65b9\u6cd5\uff0c\u8bad\u7ec3\u8fc7\u7684\u88c1\u5224\u6a21\u578b\u80dc\u8fc7\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u3002\u89c2\u5bdf\u5230LLM\u4f5c\u4e3a\u88c1\u5224\u548c\u4f5c\u4e3a\u5355\u4e2a\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u8f83\u5c0f\uff0c\u5e76\u8bc6\u522b\u51fa\u9a8c\u8bc1\u4e2d\u5b58\u5728\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0e\u6027\u80fd\u7684\u6743\u8861\u3002", "conclusion": "\u6709\u6548\u4e14\u9c81\u68d2\u7684\u591a\u667a\u80fd\u4f53\u8fc7\u7a0b\u9a8c\u8bc1\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\uff0c\u9700\u8981\u8d85\u8d8a\u5f53\u524d\u8303\u5f0f\u7684\u8fdb\u4e00\u6b65\u8fdb\u5c55\u3002LLM\u4f5c\u4e3a\u88c1\u5224\u7684\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u6574\u4f53\u4e0a\u8fc7\u7a0b\u9a8c\u8bc1\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u53ef\u9760\u6027\u6709\u9650\u3002"}}
{"id": "2602.03100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03100", "abs": "https://arxiv.org/abs/2602.03100", "authors": ["Jingnan Zheng", "Yanzhen Luo", "Jingjun Xu", "Bingnan Liu", "Yuxin Chen", "Chenhang Cui", "Gelei Deng", "Chaochao Lu", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Risky-Bench: Probing Agentic Safety Risks under Real-World Deployment", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed as agents that operate in real-world environments, introducing safety risks beyond linguistic harm. Existing agent safety evaluations rely on risk-oriented tasks tailored to specific agent settings, resulting in limited coverage of safety risk space and failing to assess agent safety behavior during long-horizon, interactive task execution in complex real-world deployments. Moreover, their specialization to particular agent settings limits adaptability across diverse agent configurations. To address these limitations, we propose Risky-Bench, a framework that enables systematic agent safety evaluation grounded in real-world deployment. Risky-Bench organizes evaluation around domain-agnostic safety principles to derive context-aware safety rubrics that delineate safety space, and systematically evaluates safety risks across this space through realistic task execution under varying threat assumptions. When applied to life-assist agent settings, Risky-Bench uncovers substantial safety risks in state-of-the-art agents under realistic execution conditions. Moreover, as a well-structured evaluation pipeline, Risky-Bench is not confined to life-assist scenarios and can be adapted to other deployment settings to construct environment-specific safety evaluations, providing an extensible methodology for agent safety assessment.", "AI": {"tldr": "Risky-Bench\u662f\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u667a\u80fd\u4f53\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u9886\u57df\u65e0\u5173\u7684\u5b89\u5168\u539f\u5219\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5b89\u5168\u6807\u51c6\uff0c\u5728\u771f\u5b9e\u90e8\u7f72\u6761\u4ef6\u4e0b\u8bc4\u4f30\u667a\u80fd\u4f53\u7684\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u4f9d\u8d56\u9488\u5bf9\u7279\u5b9a\u573a\u666f\u7684\u98ce\u9669\u5bfc\u5411\u4efb\u52a1\uff0c\u5b89\u5168\u98ce\u9669\u8986\u76d6\u6709\u9650\uff1b\u65e0\u6cd5\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u590d\u6742\u771f\u5b9e\u90e8\u7f72\u4e2d\u957f\u671f\u4ea4\u4e92\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u5b89\u5168\u884c\u4e3a\uff1b\u5bf9\u7279\u5b9a\u667a\u80fd\u4f53\u8bbe\u7f6e\u7684\u4e13\u95e8\u5316\u9650\u5236\u4e86\u8de8\u4e0d\u540c\u914d\u7f6e\u7684\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51faRisky-Bench\u6846\u67b6\uff1a\u56f4\u7ed5\u9886\u57df\u65e0\u5173\u7684\u5b89\u5168\u539f\u5219\u7ec4\u7ec7\u8bc4\u4f30\uff1b\u63a8\u5bfc\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5b89\u5168\u6807\u51c6\u6765\u754c\u5b9a\u5b89\u5168\u7a7a\u95f4\uff1b\u5728\u4e0d\u540c\u5a01\u80c1\u5047\u8bbe\u4e0b\u901a\u8fc7\u771f\u5b9e\u4efb\u52a1\u6267\u884c\u7cfb\u7edf\u8bc4\u4f30\u5b89\u5168\u98ce\u9669\uff1b\u4f5c\u4e3a\u7ed3\u6784\u5316\u8bc4\u4f30\u6d41\u7a0b\uff0c\u53ef\u9002\u5e94\u4e0d\u540c\u90e8\u7f72\u573a\u666f\u3002", "result": "\u5728\u751f\u6d3b\u8f85\u52a9\u667a\u80fd\u4f53\u8bbe\u7f6e\u4e2d\uff0cRisky-Bench\u63ed\u793a\u4e86\u6700\u5148\u8fdb\u667a\u80fd\u4f53\u5728\u771f\u5b9e\u6267\u884c\u6761\u4ef6\u4e0b\u5b58\u5728\u663e\u8457\u5b89\u5168\u98ce\u9669\uff1b\u8be5\u6846\u67b6\u4e0d\u4ec5\u9650\u4e8e\u751f\u6d3b\u8f85\u52a9\u573a\u666f\uff0c\u53ef\u9002\u5e94\u5176\u4ed6\u90e8\u7f72\u8bbe\u7f6e\u6784\u5efa\u73af\u5883\u7279\u5b9a\u7684\u5b89\u5168\u8bc4\u4f30\u3002", "conclusion": "Risky-Bench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u667a\u80fd\u4f53\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u5b66\uff0c\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u590d\u6742\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u7a7a\u767d\u3002"}}
{"id": "2602.03128", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03128", "abs": "https://arxiv.org/abs/2602.03128", "authors": ["Abdelghny Orogat", "Ana Rostam", "Essam Mansour"], "title": "Understanding Multi-Agent LLM Frameworks: A Unified Benchmark and Experimental Analysis", "comment": "25 pages, 9 figures and 13 tables; introduces MAFBench unified multi-agent evaluation suite", "summary": "Multi-agent LLM frameworks are widely used to accelerate the development of agent systems powered by large language models (LLMs). These frameworks impose distinct architectural structures that govern how agents interact, store information, and coordinate tasks. However, their impact on system performance remains poorly understood. This gap is critical, as architectural choices alone can induce order-of-magnitude differences in latency and throughput, as well as substantial variation in accuracy and scalability. Addressing this challenge requires (i) jointly evaluating multiple capabilities, such as orchestration overhead, memory behavior, planning, specialization, and coordination, and (ii) conducting these evaluations under controlled, framework-level conditions to isolate architectural effects. Existing benchmarks focus on individual capabilities and lack standardized framework-level evaluation. We address these limitations by (i) introducing an architectural taxonomy for systematically comparing multi-agent LLM frameworks along fundamental dimensions, and (ii) developing MAFBench, a unified evaluation suite that integrates existing benchmarks under a standardized execution pipeline. Using MAFBench, we conduct a controlled empirical study across several widely used frameworks. Our results show that framework-level design choices alone can increase latency by over 100x, reduce planning accuracy by up to 30%, and lower coordination success from above 90% to below 30%. Finally, we translate our findings into concrete architectural design principles and framework selection guidance, and outline promising future research directions.", "AI": {"tldr": "MAFBench\uff1a\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u6027\u80fd\u7684\u7edf\u4e00\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u63ed\u793a\u4e86\u6846\u67b6\u67b6\u6784\u8bbe\u8ba1\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u91cd\u5927\u5f71\u54cd", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u867d\u7136\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u67b6\u6784\u8bbe\u8ba1\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5173\u6ce8\u5355\u4e2a\u80fd\u529b\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u6846\u67b6\u7ea7\u8bc4\u4f30\uff0c\u5bfc\u81f4\u65e0\u6cd5\u51c6\u786e\u8861\u91cf\u4e0d\u540c\u67b6\u6784\u9009\u62e9\u5bf9\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u3001\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u7684\u67b6\u6784\u5206\u7c7b\u6cd5\uff0c\u5f00\u53d1MAFBench\u7edf\u4e00\u8bc4\u4f30\u5957\u4ef6\uff0c\u96c6\u6210\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5230\u6807\u51c6\u5316\u6267\u884c\u7ba1\u9053\u4e2d\uff0c\u5bf9\u591a\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u6846\u67b6\u8fdb\u884c\u53d7\u63a7\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u6846\u67b6\u7ea7\u8bbe\u8ba1\u9009\u62e9\u5355\u72ec\u5c31\u80fd\u5bfc\u81f4\u5ef6\u8fdf\u589e\u52a0\u8d85\u8fc7100\u500d\uff0c\u89c4\u5212\u51c6\u786e\u6027\u964d\u4f4e\u9ad8\u8fbe30%\uff0c\u534f\u8c03\u6210\u529f\u7387\u4ece90%\u4ee5\u4e0a\u964d\u81f330%\u4ee5\u4e0b\u3002\u4e0d\u540c\u6846\u67b6\u5728\u7f16\u6392\u5f00\u9500\u3001\u5185\u5b58\u884c\u4e3a\u3001\u89c4\u5212\u3001\u4e13\u4e1a\u5316\u548c\u534f\u8c03\u7b49\u65b9\u9762\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u7684\u67b6\u6784\u8bbe\u8ba1\u5bf9\u7cfb\u7edf\u6027\u80fd\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u6846\u67b6\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5177\u4f53\u539f\u5219\u548c\u9009\u62e9\u6307\u5bfc\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u7cfb\u7edf\u5316\u7684\u6846\u67b6\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2602.03146", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03146", "abs": "https://arxiv.org/abs/2602.03146", "authors": ["Santiago Cifuentes"], "title": "General Agents Contain World Models, even under Partial Observability and Stochasticity", "comment": "19 pages, 4 figures", "summary": "Deciding whether an agent possesses a model of its surrounding world is a fundamental step toward understanding its capabilities and limitations. In [10], it was shown that, within a particular framework, every almost optimal and general agent necessarily contains sufficient knowledge of its environment to allow an approximate reconstruction of it by querying the agent as a black box. This result relied on the assumptions that the agent is deterministic and that the environment is fully observable.\n  In this work, we remove both assumptions by extending the theorem to stochastic agents operating in partially observable environments. Fundamentally, this shows that stochastic agents cannot avoid learning their environment through the usage of randomization. We also strengthen the result by weakening the notion of generality, proving that less powerful agents already contain a model of the world in which they operate.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5148\u524d\u5173\u4e8e\u667a\u80fd\u4f53\u73af\u5883\u5efa\u6a21\u7684\u7406\u8bba\uff0c\u4ece\u786e\u5b9a\u6027\u3001\u5b8c\u5168\u53ef\u89c2\u6d4b\u73af\u5883\u6269\u5c55\u5230\u968f\u673a\u6027\u3001\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\uff0c\u8bc1\u660e\u968f\u673a\u667a\u80fd\u4f53\u4e5f\u65e0\u6cd5\u907f\u514d\u5b66\u4e60\u5176\u73af\u5883\u6a21\u578b\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u8bc1\u660e\u5728\u786e\u5b9a\u6027\u3001\u5b8c\u5168\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\uff0c\u51e0\u4e4e\u6700\u4f18\u7684\u901a\u7528\u667a\u80fd\u4f53\u5fc5\u7136\u5305\u542b\u8db3\u591f\u7684\u73af\u5883\u77e5\u8bc6\u3002\u4f46\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u667a\u80fd\u4f53\u901a\u5e38\u662f\u968f\u673a\u7684\uff0c\u4e14\u73af\u5883\u662f\u90e8\u5206\u53ef\u89c2\u6d4b\u7684\u3002\u672c\u6587\u65e8\u5728\u79fb\u9664\u8fd9\u4e24\u4e2a\u9650\u5236\u6027\u5047\u8bbe\uff0c\u6269\u5c55\u7406\u8bba\u7ed3\u679c\u5230\u66f4\u73b0\u5b9e\u7684\u573a\u666f\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u6269\u5c55\u5148\u524d\u6846\u67b6\uff0c\u5c06\u5b9a\u7406\u63a8\u5e7f\u5230\u968f\u673a\u667a\u80fd\u4f53\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u7684\u60c5\u51b5\u3002\u540c\u65f6\u901a\u8fc7\u5f31\u5316\"\u901a\u7528\u6027\"\u6982\u5ff5\uff0c\u8bc1\u660e\u80fd\u529b\u8f83\u5f31\u7684\u667a\u80fd\u4f53\u4e5f\u5305\u542b\u5176\u64cd\u4f5c\u73af\u5883\u7684\u4e16\u754c\u6a21\u578b\u3002", "result": "\u6210\u529f\u8bc1\u660e\u968f\u673a\u667a\u80fd\u4f53\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u4e5f\u65e0\u6cd5\u907f\u514d\u5b66\u4e60\u5176\u73af\u5883\u6a21\u578b\uff0c\u968f\u673a\u5316\u4f7f\u7528\u65e0\u6cd5\u907f\u514d\u73af\u5883\u5b66\u4e60\u3002\u540c\u65f6\u8bc1\u660e\u66f4\u5f31\u7684\u667a\u80fd\u4f53\uff08\u653e\u5bbd\u901a\u7528\u6027\u8981\u6c42\uff09\u4e5f\u5305\u542b\u4e16\u754c\u6a21\u578b\u3002", "conclusion": "\u968f\u673a\u667a\u80fd\u4f53\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u4ecd\u7136\u5fc5\u7136\u5b66\u4e60\u5176\u73af\u5883\u6a21\u578b\uff0c\u8fd9\u4e3a\u7406\u89e3\u667a\u80fd\u4f53\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u666e\u9002\u7684\u7406\u8bba\u57fa\u7840\uff0c\u8868\u660e\u73af\u5883\u5efa\u6a21\u662f\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u672c\u8d28\u7279\u5f81\uff0c\u4e0d\u53d7\u968f\u673a\u6027\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u7684\u5f71\u54cd\u3002"}}
{"id": "2602.03151", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03151", "abs": "https://arxiv.org/abs/2602.03151", "authors": ["Wei Dai", "Haoyu Wang", "Honghao Chang", "Lijun He", "Fan Li", "Jian Sun", "Haixia Bi"], "title": "Enhancing Foundation VLM Robustness to Missing Modality: Scalable Diffusion for Bi-directional Feature Restoration", "comment": "12 pages", "summary": "Vision Language Models (VLMs) typically assume complete modality input during inference. However, their effectiveness drops sharply when certain modalities are unavailable or incomplete. Current research primarily faces two dilemmas: Prompt-based methods struggle to restore missing yet indispensable features and impair generalization of VLMs. Imputation-based approaches, lacking effective guidance, are prone to generating semantically irrelevant noise. Restoring precise semantics while sustaining VLM generalization remains challenging. Therefore, we propose a general missing modality restoration strategy in this paper. We introduce an enhanced diffusion model as a pluggable mid-stage training module to effectively restore missing features. Our strategy introduces two key innovations: (I) Dynamic Modality Gating, which adaptively leverages conditional features to steer the generation of semantically consistent features; (II) Cross-Modal Mutual Learning mechanism, which bridges the semantic spaces of dual encoders to achieve bidirectional alignment. Zero-shot evaluations across benchmark datasets demonstrate that our approach outperforms existing baseline methods. Extensive experiments and ablation studies confirm our model as a robust and scalable extension for VLMs in missing modality scenarios, ensuring reliability across diverse missing rates and environments. Our code and models will be publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u7f3a\u5931\u6a21\u6001\u6062\u590d\u7b56\u7565\uff0c\u901a\u8fc7\u589e\u5f3a\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u53ef\u63d2\u62d4\u7684\u4e2d\u9636\u6bb5\u8bad\u7ec3\u6a21\u5757\uff0c\u6709\u6548\u6062\u590d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7f3a\u5931\u7279\u5f81\uff0c\u63d0\u5347\u5728\u6a21\u6001\u4e0d\u5b8c\u6574\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u5047\u8bbe\u63a8\u7406\u65f6\u5177\u6709\u5b8c\u6574\u7684\u6a21\u6001\u8f93\u5165\uff0c\u4f46\u5f53\u67d0\u4e9b\u6a21\u6001\u4e0d\u53ef\u7528\u6216\u4e0d\u5b8c\u6574\u65f6\uff0c\u5176\u6027\u80fd\u4f1a\u6025\u5267\u4e0b\u964d\u3002\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u56f0\u5883\uff1a\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u96be\u4ee5\u6062\u590d\u7f3a\u5931\u4f46\u5fc5\u8981\u7684\u7279\u5f81\u5e76\u635f\u5bb3VLM\u7684\u6cdb\u5316\u80fd\u529b\uff1b\u57fa\u4e8e\u63d2\u8865\u7684\u65b9\u6cd5\u7f3a\u4e4f\u6709\u6548\u6307\u5bfc\uff0c\u5bb9\u6613\u751f\u6210\u8bed\u4e49\u65e0\u5173\u7684\u566a\u58f0\u3002\u5982\u4f55\u5728\u6062\u590d\u7cbe\u786e\u8bed\u4e49\u7684\u540c\u65f6\u4fdd\u6301VLM\u7684\u6cdb\u5316\u80fd\u529b\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u901a\u7528\u7684\u7f3a\u5931\u6a21\u6001\u6062\u590d\u7b56\u7565\uff0c\u5f15\u5165\u589e\u5f3a\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u53ef\u63d2\u62d4\u7684\u4e2d\u9636\u6bb5\u8bad\u7ec3\u6a21\u5757\u3002\u5305\u542b\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a(1)\u52a8\u6001\u6a21\u6001\u95e8\u63a7\uff0c\u81ea\u9002\u5e94\u5730\u5229\u7528\u6761\u4ef6\u7279\u5f81\u6765\u5f15\u5bfc\u751f\u6210\u8bed\u4e49\u4e00\u81f4\u7684\u7279\u5f81\uff1b(2)\u8de8\u6a21\u6001\u4e92\u5b66\u4e60\u673a\u5236\uff0c\u6865\u63a5\u53cc\u7f16\u7801\u5668\u7684\u8bed\u4e49\u7a7a\u95f4\u4ee5\u5b9e\u73b0\u53cc\u5411\u5bf9\u9f50\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u96f6\u6837\u672c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u5927\u91cf\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\uff0c\u8be5\u6a21\u578b\u662fVLM\u5728\u7f3a\u5931\u6a21\u6001\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u6269\u5c55\uff0c\u786e\u4fdd\u5728\u4e0d\u540c\u7f3a\u5931\u7387\u548c\u73af\u5883\u4e0b\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u901a\u7528\u7f3a\u5931\u6a21\u6001\u6062\u590d\u7b56\u7565\u901a\u8fc7\u52a8\u6001\u6a21\u6001\u95e8\u63a7\u548c\u8de8\u6a21\u6001\u4e92\u5b66\u4e60\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86VLM\u5728\u6a21\u6001\u4e0d\u5b8c\u6574\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u4e3aVLM\u5728\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u4fdd\u969c\u3002"}}
{"id": "2602.03160", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03160", "abs": "https://arxiv.org/abs/2602.03160", "authors": ["Woojin Kim", "Sieun Hyeon", "Jusang Oh", "Jaeyoung Do"], "title": "VALUEFLOW: Toward Pluralistic and Steerable Value-based Alignment in Large Language Models", "comment": null, "summary": "Aligning Large Language Models (LLMs) with the diverse spectrum of human values remains a central challenge: preference-based methods often fail to capture deeper motivational principles. Value-based approaches offer a more principled path, yet three gaps persist: extraction often ignores hierarchical structure, evaluation detects presence but not calibrated intensity, and the steerability of LLMs at controlled intensities remains insufficiently understood. To address these limitations, we introduce VALUEFLOW, the first unified framework that spans extraction, evaluation, and steering with calibrated intensity control. The framework integrates three components: (i) HIVES, a hierarchical value embedding space that captures intra- and cross-theory value structure; (ii) the Value Intensity DataBase (VIDB), a large-scale resource of value-labeled texts with intensity estimates derived from ranking-based aggregation; and (iii) an anchor-based evaluator that produces consistent intensity scores for model outputs by ranking them against VIDB panels. Using VALUEFLOW, we conduct a comprehensive large-scale study across ten models and four value theories, identifying asymmetries in steerability and composition laws for multi-value control. This paper establishes a scalable infrastructure for evaluating and controlling value intensity, advancing pluralistic alignment of LLMs.", "AI": {"tldr": "VALUEFLOW\u6846\u67b6\uff1a\u9996\u4e2a\u7edf\u4e00\u7684\u4ef7\u503c\u63d0\u53d6\u3001\u8bc4\u4f30\u548c\u5f3a\u5ea6\u53ef\u63a7\u5f15\u5bfc\u6846\u67b6\uff0c\u89e3\u51b3LLM\u4ef7\u503c\u5bf9\u9f50\u4e2d\u7684\u5c42\u6b21\u7ed3\u6784\u3001\u5f3a\u5ea6\u6821\u51c6\u548c\u53ef\u63a7\u5f15\u5bfc\u95ee\u9898", "motivation": "\u5f53\u524dLLM\u4e0e\u4eba\u7c7b\u4ef7\u503c\u5bf9\u9f50\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a1) \u4ef7\u503c\u63d0\u53d6\u5ffd\u7565\u5c42\u6b21\u7ed3\u6784\uff1b2) \u8bc4\u4f30\u53ea\u80fd\u68c0\u6d4b\u5b58\u5728\u6027\u800c\u65e0\u6cd5\u6821\u51c6\u5f3a\u5ea6\uff1b3) \u5f3a\u5ea6\u53ef\u63a7\u7684\u5f15\u5bfc\u673a\u5236\u7406\u89e3\u4e0d\u8db3", "method": "\u63d0\u51faVALUEFLOW\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a1) HIVES\u5c42\u6b21\u4ef7\u503c\u5d4c\u5165\u7a7a\u95f4\uff1b2) VIDB\u5927\u89c4\u6a21\u4ef7\u503c\u6807\u6ce8\u6587\u672c\u6570\u636e\u5e93\uff1b3) \u57fa\u4e8e\u951a\u70b9\u7684\u8bc4\u4f30\u5668\uff0c\u901a\u8fc7\u6392\u540d\u4ea7\u751f\u4e00\u81f4\u6027\u5f3a\u5ea6\u5206\u6570", "result": "\u572810\u4e2a\u6a21\u578b\u548c4\u79cd\u4ef7\u503c\u7406\u8bba\u4e2d\u8fdb\u884c\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u8bc6\u522b\u4e86\u5f15\u5bfc\u7684\u4e0d\u5bf9\u79f0\u6027\u548c\u591a\u4ef7\u503c\u63a7\u5236\u7684\u7ec4\u5408\u89c4\u5f8b", "conclusion": "VALUEFLOW\u4e3a\u8bc4\u4f30\u548c\u63a7\u5236\u4ef7\u503c\u5f3a\u5ea6\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u63a8\u8fdb\u4e86LLM\u7684\u591a\u5143\u4ef7\u503c\u5bf9\u9f50"}}
{"id": "2602.03219", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03219", "abs": "https://arxiv.org/abs/2602.03219", "authors": ["Guhong Chen", "Chenghao Sun", "Cheng Fu", "Qiyao Wang", "Zhihong Huang", "Chaopeng Wei", "Guangxu Chen", "Feiteng Fang", "Ahmadreza Argha", "Bing Zhao", "Xander Xu", "Qi Han", "Hamid Alinejad-Rokny", "Qiang Qu", "Binhua Li", "Shiwen Ni", "Min Yang", "Hu Wei", "Yongbin Li"], "title": "Beyond Quantity: Trajectory Diversity Scaling for Code Agents", "comment": null, "summary": "As code large language models (LLMs) evolve into tool-interactive agents via the Model Context Protocol (MCP), their generalization is increasingly limited by low-quality synthetic data and the diminishing returns of quantity scaling. Moreover, quantity-centric scaling exhibits an early bottleneck that underutilizes trajectory data. We propose TDScaling, a Trajectory Diversity Scaling-based data synthesis framework for code agents that scales performance through diversity rather than raw volume. Under a fixed training budget, increasing trajectory diversity yields larger gains than adding more trajectories, improving the performance-cost trade-off for agent training. TDScaling integrates four innovations: (1) a Business Cluster mechanism that captures real-service logical dependencies; (2) a blueprint-driven multi-agent paradigm that enforces trajectory coherence; (3) an adaptive evolution mechanism that steers synthesis toward long-tail scenarios using Domain Entropy, Reasoning Mode Entropy, and Cumulative Action Complexity to prevent mode collapse; and (4) a sandboxed code tool that mitigates catastrophic forgetting of intrinsic coding capabilities. Experiments on general tool-use benchmarks (BFCL, tau^2-Bench) and code agent tasks (RebenchT, CodeCI, BIRD) demonstrate a win-win outcome: TDScaling improves both tool-use generalization and inherent coding proficiency. We plan to release the full codebase and the synthesized dataset (including 30,000+ tool clusters) upon publication.", "AI": {"tldr": "TDScaling\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f68\u8ff9\u591a\u6837\u6027\u7684\u4ee3\u7801\u667a\u80fd\u4f53\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u52a0\u8f68\u8ff9\u591a\u6837\u6027\u800c\u975e\u5355\u7eaf\u589e\u52a0\u6570\u636e\u91cf\u6765\u63d0\u5347\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u4f4e\u8d28\u91cf\u5408\u6210\u6570\u636e\u548c\u6570\u91cf\u6269\u5c55\u6536\u76ca\u9012\u51cf\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7MCP\u534f\u8bae\u6f14\u53d8\u4e3a\u5de5\u5177\u4ea4\u4e92\u667a\u80fd\u4f53\uff0c\u5176\u6cdb\u5316\u80fd\u529b\u53d7\u5230\u4f4e\u8d28\u91cf\u5408\u6210\u6570\u636e\u548c\u6570\u91cf\u6269\u5c55\u6536\u76ca\u9012\u51cf\u7684\u9650\u5236\u3002\u6570\u91cf\u4e3a\u4e2d\u5fc3\u7684\u6269\u5c55\u5b58\u5728\u65e9\u671f\u74f6\u9888\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u8f68\u8ff9\u6570\u636e\u3002", "method": "TDScaling\u6846\u67b6\u5305\u542b\u56db\u4e2a\u521b\u65b0\uff1a1\uff09\u4e1a\u52a1\u96c6\u7fa4\u673a\u5236\u6355\u6349\u771f\u5b9e\u670d\u52a1\u903b\u8f91\u4f9d\u8d56\uff1b2\uff09\u84dd\u56fe\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u8303\u5f0f\u786e\u4fdd\u8f68\u8ff9\u8fde\u8d2f\u6027\uff1b3\uff09\u81ea\u9002\u5e94\u8fdb\u5316\u673a\u5236\u4f7f\u7528\u9886\u57df\u71b5\u3001\u63a8\u7406\u6a21\u5f0f\u71b5\u548c\u7d2f\u79ef\u52a8\u4f5c\u590d\u6742\u5ea6\u5f15\u5bfc\u5408\u6210\u9762\u5411\u957f\u5c3e\u573a\u666f\uff1b4\uff09\u6c99\u76d2\u5316\u4ee3\u7801\u5de5\u5177\u9632\u6b62\u5185\u5728\u7f16\u7801\u80fd\u529b\u707e\u96be\u6027\u9057\u5fd8\u3002", "result": "\u5728\u901a\u7528\u5de5\u5177\u4f7f\u7528\u57fa\u51c6\uff08BFCL\u3001tau^2-Bench\uff09\u548c\u4ee3\u7801\u667a\u80fd\u4f53\u4efb\u52a1\uff08RebenchT\u3001CodeCI\u3001BIRD\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTDScaling\u5b9e\u73b0\u4e86\u53cc\u8d62\uff1a\u65e2\u63d0\u5347\u4e86\u5de5\u5177\u4f7f\u7528\u6cdb\u5316\u80fd\u529b\uff0c\u53c8\u589e\u5f3a\u4e86\u5185\u5728\u7f16\u7801\u80fd\u529b\u3002", "conclusion": "TDScaling\u901a\u8fc7\u8f68\u8ff9\u591a\u6837\u6027\u6269\u5c55\u800c\u975e\u6570\u91cf\u6269\u5c55\uff0c\u5728\u56fa\u5b9a\u8bad\u7ec3\u9884\u7b97\u4e0b\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd-\u6210\u672c\u6743\u8861\uff0c\u4e3a\u4ee3\u7801\u667a\u80fd\u4f53\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u6570\u636e\u5408\u6210\u6846\u67b6\u3002"}}
{"id": "2602.03224", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03224", "abs": "https://arxiv.org/abs/2602.03224", "authors": ["Yu Cheng", "Jiuan Zhou", "Yongkang Hu", "Yihang Chen", "Huichi Zhou", "Mingang Chen", "Zhizhong Zhang", "Kun Shao", "Yuan Xie", "Zhaoxia Yin"], "title": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "comment": null, "summary": "Test-time evolution of agent memory serves as a pivotal paradigm for achieving AGI by bolstering complex reasoning through experience accumulation. However, even during benign task evolution, agent safety alignment remains vulnerable-a phenomenon known as Agent Memory Misevolution. To evaluate this phenomenon, we construct the Trust-Memevo benchmark to assess multi-dimensional trustworthiness during benign task evolution, revealing an overall decline in trustworthiness across various task domains and evaluation settings. To address this issue, we propose TAME, a dual-memory evolutionary framework that separately evolves executor memory to improve task performance by distilling generalizable methodologies, and evaluator memory to refine assessments of both safety and task utility based on historical feedback. Through a closed loop of memory filtering, draft generation, trustworthy refinement, execution, and dual-track memory updating, TAME preserves trustworthiness without sacrificing utility. Experiments demonstrate that TAME mitigates misevolution, achieving a joint improvement in both trustworthiness and task performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTAME\u6846\u67b6\u89e3\u51b3\u667a\u80fd\u4f53\u8bb0\u5fc6\u6f14\u5316\u4e2d\u7684\u5b89\u5168\u95ee\u9898\uff0c\u901a\u8fc7\u53cc\u8bb0\u5fc6\u7cfb\u7edf\u5206\u522b\u4f18\u5316\u4efb\u52a1\u6267\u884c\u548c\u5b89\u5168\u8bc4\u4f30\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u667a\u80fd\u4f53\u5728\u6d4b\u8bd5\u65f6\u95f4\u901a\u8fc7\u8bb0\u5fc6\u6f14\u5316\u79ef\u7d2f\u7ecf\u9a8c\u662f\u5b9e\u73b0AGI\u7684\u5173\u952e\u9014\u5f84\uff0c\u4f46\u5373\u4f7f\u5728\u8fdb\u884c\u826f\u6027\u4efb\u52a1\u6f14\u5316\u65f6\uff0c\u667a\u80fd\u4f53\u7684\u5b89\u5168\u5bf9\u9f50\u4ecd\u7136\u8106\u5f31\uff0c\u5b58\u5728\"Agent Memory Misevolution\"\u73b0\u8c61\uff0c\u5373\u8bb0\u5fc6\u6f14\u5316\u8fc7\u7a0b\u4e2d\u53ef\u4fe1\u5ea6\u4e0b\u964d\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faTAME\u53cc\u8bb0\u5fc6\u6f14\u5316\u6846\u67b6\uff1a1\uff09\u6267\u884c\u5668\u8bb0\u5fc6\u6f14\u5316\u4ee5\u63d0\u5347\u4efb\u52a1\u6027\u80fd\uff0c\u901a\u8fc7\u63d0\u70bc\u53ef\u6cdb\u5316\u7684\u65b9\u6cd5\u8bba\uff1b2\uff09\u8bc4\u4f30\u5668\u8bb0\u5fc6\u6f14\u5316\u4ee5\u57fa\u4e8e\u5386\u53f2\u53cd\u9988\u7cbe\u5316\u5b89\u5168\u548c\u4efb\u52a1\u6548\u7528\u7684\u8bc4\u4f30\u3002\u901a\u8fc7\u8bb0\u5fc6\u8fc7\u6ee4\u3001\u8349\u7a3f\u751f\u6210\u3001\u53ef\u4fe1\u5ea6\u7cbe\u5316\u3001\u6267\u884c\u548c\u53cc\u8f68\u8bb0\u5fc6\u66f4\u65b0\u7684\u95ed\u73af\u6d41\u7a0b\u3002", "result": "\u6784\u5efa\u4e86Trust-Memevo\u57fa\u51c6\u8bc4\u4f30\u826f\u6027\u4efb\u52a1\u6f14\u5316\u4e2d\u7684\u591a\u7ef4\u53ef\u4fe1\u5ea6\uff0c\u53d1\u73b0\u5404\u79cd\u4efb\u52a1\u9886\u57df\u548c\u8bc4\u4f30\u8bbe\u7f6e\u4e2d\u53ef\u4fe1\u5ea6\u666e\u904d\u4e0b\u964d\u3002TAME\u6846\u67b6\u5b9e\u9a8c\u8868\u660e\u80fd\u591f\u7f13\u89e3\u8bb0\u5fc6\u6f14\u5316\u95ee\u9898\uff0c\u5728\u53ef\u4fe1\u5ea6\u548c\u4efb\u52a1\u6027\u80fd\u4e0a\u5b9e\u73b0\u8054\u5408\u63d0\u5347\u3002", "conclusion": "TAME\u6846\u67b6\u901a\u8fc7\u5206\u79bb\u6267\u884c\u5668\u548c\u8bc4\u4f30\u5668\u8bb0\u5fc6\u6f14\u5316\uff0c\u5728\u8bb0\u5fc6\u8fc7\u6ee4\u3001\u751f\u6210\u3001\u7cbe\u5316\u548c\u66f4\u65b0\u7684\u95ed\u73af\u4e2d\u4fdd\u6301\u53ef\u4fe1\u5ea6\u800c\u4e0d\u727a\u7272\u6548\u7528\uff0c\u4e3a\u89e3\u51b3\u667a\u80fd\u4f53\u8bb0\u5fc6\u6f14\u5316\u4e2d\u7684\u5b89\u5168\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2602.03238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03238", "abs": "https://arxiv.org/abs/2602.03238", "authors": ["Pengyu Zhu", "Li Sun", "Philip S. Yu", "Sen Su"], "title": "The Necessity of a Unified Framework for LLM-Based Agent Evaluation", "comment": null, "summary": "With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements. However, evaluating these agents presents unique challenges that distinguish them from static QA benchmarks. We observe that current agent benchmarks are heavily confounded by extraneous factors, including system prompts, toolset configurations, and environmental dynamics. Existing evaluations often rely on fragmented, researcher-specific frameworks where the prompt engineering for reasoning and tool usage varies significantly, making it difficult to attribute performance gains to the model itself. Additionally, the lack of standardized environmental data leads to untraceable errors and non-reproducible results. This lack of standardization introduces substantial unfairness and opacity into the field. We propose that a unified evaluation framework is essential for the rigorous advancement of agent evaluation. To this end, we introduce a proposal aimed at standardizing agent evaluation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u8bc4\u4f30\u5b58\u5728\u6807\u51c6\u5316\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u7684\u5fc5\u8981\u6027", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u901a\u7528\u667a\u80fd\u4f53\u53d6\u5f97\u4e86\u6839\u672c\u6027\u8fdb\u5c55\uff0c\u4f46\u8bc4\u4f30\u8fd9\u4e9b\u667a\u80fd\u4f53\u9762\u4e34\u72ec\u7279\u6311\u6218\u3002\u5f53\u524d\u8bc4\u4f30\u5b58\u5728\u7cfb\u7edf\u63d0\u793a\u3001\u5de5\u5177\u914d\u7f6e\u3001\u73af\u5883\u52a8\u6001\u7b49\u6df7\u6742\u56e0\u7d20\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u5bfc\u81f4\u4e0d\u516c\u5e73\u548c\u4e0d\u900f\u660e", "method": "\u63d0\u51fa\u6807\u51c6\u5316\u667a\u80fd\u4f53\u8bc4\u4f30\u7684\u63d0\u6848\uff0c\u65e8\u5728\u5efa\u7acb\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u6765\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u4e2d\u7684\u6807\u51c6\u5316\u4e0d\u8db3\u95ee\u9898", "result": "\u8bba\u6587\u4e3b\u8981\u63d0\u51fa\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u7684\u63d0\u6848\uff0c\u4f46\u5177\u4f53\u5b9e\u65bd\u7ed3\u679c\u548c\u6548\u679c\u5c1a\u672a\u5728\u6458\u8981\u4e2d\u8be6\u7ec6\u8bf4\u660e", "conclusion": "\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u5bf9\u4e8e\u667a\u80fd\u4f53\u8bc4\u4f30\u7684\u4e25\u8c28\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u6807\u51c6\u6765\u786e\u4fdd\u516c\u5e73\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u900f\u660e\u5ea6"}}
{"id": "2602.03249", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03249", "abs": "https://arxiv.org/abs/2602.03249", "authors": ["Zhicheng Yang", "Zhijiang Guo", "Yinya Huang", "Yongxin Wang", "Wenlei Shi", "Yiwei Wang", "Xiaodan Liang", "Jing Tang"], "title": "Accordion-Thinking: Self-Regulated Step Summaries for Efficient and Readable LLM Reasoning", "comment": null, "summary": "Scaling test-time compute via long Chain-ofThought unlocks remarkable gains in reasoning capabilities, yet it faces practical limits due to the linear growth of KV cache and quadratic attention complexity. In this paper, we introduce Accordion-Thinking, an end-to-end framework where LLMs learn to self-regulate the granularity of the reasoning steps through dynamic summarization. This mechanism enables a Fold inference mode, where the model periodically summarizes its thought process and discards former thoughts to reduce dependency on historical tokens. We apply reinforcement learning to incentivize this capability further, uncovering a critical insight: the accuracy gap between the highly efficient Fold mode and the exhaustive Unfold mode progressively narrows and eventually vanishes over the course of training. This phenomenon demonstrates that the model learns to encode essential reasoning information into compact summaries, achieving effective compression of the reasoning context. Our Accordion-Thinker demonstrates that with learned self-compression, LLMs can tackle complex reasoning tasks with minimal dependency token overhead without compromising solution quality, and it achieves a 3x throughput while maintaining accuracy on a 48GB GPU memory configuration, while the structured step summaries provide a human-readable account of the reasoning process.", "AI": {"tldr": "Accordion-Thinking\u6846\u67b6\u8ba9LLM\u5b66\u4f1a\u901a\u8fc7\u52a8\u6001\u603b\u7ed3\u6765\u81ea\u6211\u8c03\u8282\u63a8\u7406\u6b65\u9aa4\u7c92\u5ea6\uff0c\u5b9e\u73b0\u63a8\u7406\u4e0a\u4e0b\u6587\u7684\u538b\u7f29\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u957f\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u867d\u7136\u80fd\u663e\u8457\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u9762\u4e34KV\u7f13\u5b58\u7ebf\u6027\u589e\u957f\u548c\u6ce8\u610f\u529b\u590d\u6742\u5ea6\u4e8c\u6b21\u65b9\u589e\u957f\u7684\u5b9e\u8df5\u9650\u5236\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u673a\u5236\u3002", "method": "\u63d0\u51faAccordion-Thinking\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u8ba9LLM\u5b66\u4e60\u901a\u8fc7\u52a8\u6001\u603b\u7ed3\u6765\u81ea\u6211\u8c03\u8282\u63a8\u7406\u6b65\u9aa4\u7c92\u5ea6\uff0c\u91c7\u7528Fold\u63a8\u7406\u6a21\u5f0f\u5b9a\u671f\u603b\u7ed3\u601d\u7ef4\u8fc7\u7a0b\u5e76\u4e22\u5f03\u5386\u53f2token\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u6fc0\u52b1\u8fd9\u79cd\u80fd\u529b\u3002", "result": "\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u9ad8\u6548\u7684Fold\u6a21\u5f0f\u4e0e\u8be6\u5c3dUnfold\u6a21\u5f0f\u4e4b\u95f4\u7684\u51c6\u786e\u7387\u5dee\u8ddd\u9010\u6e10\u7f29\u5c0f\u76f4\u81f3\u6d88\u5931\uff0c\u6a21\u578b\u5b66\u4f1a\u5c06\u5173\u952e\u63a8\u7406\u4fe1\u606f\u7f16\u7801\u5230\u7d27\u51d1\u603b\u7ed3\u4e2d\uff0c\u572848GB GPU\u5185\u5b58\u914d\u7f6e\u4e0b\u5b9e\u73b03\u500d\u541e\u5410\u91cf\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u5b66\u4e60\u7684\u81ea\u6211\u538b\u7f29\uff0cLLM\u80fd\u591f\u4ee5\u6700\u5c0f\u7684\u4f9d\u8d56token\u5f00\u9500\u5904\u7406\u590d\u6742\u63a8\u7406\u4efb\u52a1\u800c\u4e0d\u5f71\u54cd\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff0c\u7ed3\u6784\u5316\u6b65\u9aa4\u603b\u7ed3\u4e3a\u63a8\u7406\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u4eba\u7c7b\u53ef\u8bfb\u7684\u8bf4\u660e\u3002"}}
{"id": "2602.03263", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03263", "abs": "https://arxiv.org/abs/2602.03263", "authors": ["Yuxuan Liu", "Yuntian Shi", "Kun Wang", "Haoting Shen", "Kun Yang"], "title": "CSR-Bench: A Benchmark for Evaluating the Cross-modal Safety and Reliability of MLLMs", "comment": "25 pages, 1 figures", "summary": "Multimodal large language models (MLLMs) enable interaction over both text and images, but their safety behavior can be driven by unimodal shortcuts instead of true joint intent understanding. We introduce CSR-Bench, a benchmark for evaluating cross-modal reliability through four stress-testing interaction patterns spanning Safety, Over-rejection, Bias, and Hallucination, covering 61 fine-grained types. Each instance is constructed to require integrated image-text interpretation, and we additionally provide paired text-only controls to diagnose modality-induced behavior shifts. We evaluate 16 state-of-the-art MLLMs and observe systematic cross-modal alignment gaps. Models show weak safety awareness, strong language dominance under interference, and consistent performance degradation from text-only controls to multimodal inputs. We also observe a clear trade-off between reducing over-rejection and maintaining safe, non-discriminatory behavior, suggesting that some apparent safety gains may come from refusal-oriented heuristics rather than robust intent understanding. WARNING: This paper contains unsafe contents.", "AI": {"tldr": "CSR-Bench\u662f\u4e00\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8de8\u6a21\u6001\u53ef\u9760\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u56db\u79cd\u538b\u529b\u6d4b\u8bd5\u6a21\u5f0f\uff08\u5b89\u5168\u3001\u8fc7\u5ea6\u62d2\u7edd\u3001\u504f\u89c1\u3001\u5e7b\u89c9\uff09\u8bc4\u4f3061\u79cd\u7ec6\u7c92\u5ea6\u7c7b\u578b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u8de8\u6a21\u6001\u5bf9\u9f50\u5dee\u8ddd\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u652f\u6301\u6587\u672c\u548c\u56fe\u50cf\u4ea4\u4e92\uff0c\u4f46\u5176\u5b89\u5168\u884c\u4e3a\u53ef\u80fd\u7531\u5355\u6a21\u6001\u6377\u5f84\u9a71\u52a8\u800c\u975e\u771f\u6b63\u7684\u8054\u5408\u610f\u56fe\u7406\u89e3\u3002\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u662f\u5426\u771f\u6b63\u6574\u5408\u4e86\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u8fd8\u662f\u4ec5\u4f9d\u8d56\u5355\u6a21\u6001\u7ebf\u7d22\u505a\u51fa\u51b3\u7b56\u3002", "method": "\u6784\u5efaCSR-Bench\u57fa\u51c6\uff0c\u5305\u542b\u56db\u79cd\u538b\u529b\u6d4b\u8bd5\u4ea4\u4e92\u6a21\u5f0f\uff1a\u5b89\u5168\u3001\u8fc7\u5ea6\u62d2\u7edd\u3001\u504f\u89c1\u548c\u5e7b\u89c9\uff0c\u6db5\u76d661\u79cd\u7ec6\u7c92\u5ea6\u7c7b\u578b\u3002\u6bcf\u4e2a\u5b9e\u4f8b\u90fd\u9700\u8981\u6574\u5408\u56fe\u50cf-\u6587\u672c\u89e3\u91ca\uff0c\u5e76\u63d0\u4f9b\u914d\u5bf9\u7684\u7eaf\u6587\u672c\u63a7\u5236\u7ec4\u4ee5\u8bca\u65ad\u6a21\u6001\u5f15\u8d77\u7684\u884c\u4e3a\u53d8\u5316\u3002\u8bc4\u4f30\u4e8616\u4e2a\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u89c2\u5bdf\u5230\u7cfb\u7edf\u6027\u8de8\u6a21\u6001\u5bf9\u9f50\u5dee\u8ddd\uff1a\u6a21\u578b\u8868\u73b0\u51fa\u5f31\u5b89\u5168\u610f\u8bc6\u3001\u5728\u5e72\u6270\u4e0b\u5f3a\u70c8\u7684\u8bed\u8a00\u4e3b\u5bfc\u6027\uff0c\u4ee5\u53ca\u4ece\u7eaf\u6587\u672c\u63a7\u5236\u7ec4\u5230\u591a\u6a21\u6001\u8f93\u5165\u7684\u4e00\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u8fd8\u89c2\u5bdf\u5230\u51cf\u5c11\u8fc7\u5ea6\u62d2\u7edd\u4e0e\u4fdd\u6301\u5b89\u5168\u3001\u975e\u6b67\u89c6\u884c\u4e3a\u4e4b\u95f4\u7684\u660e\u663e\u6743\u8861\uff0c\u8868\u660e\u4e00\u4e9b\u8868\u9762\u4e0a\u7684\u5b89\u5168\u6539\u8fdb\u53ef\u80fd\u6765\u81ea\u62d2\u7edd\u5bfc\u5411\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u800c\u975e\u9c81\u68d2\u7684\u610f\u56fe\u7406\u89e3\u3002", "conclusion": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u6a21\u6001\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u95ee\u9898\uff0c\u5176\u5b89\u5168\u884c\u4e3a\u53ef\u80fd\u57fa\u4e8e\u5355\u6a21\u6001\u6377\u5f84\u800c\u975e\u771f\u6b63\u7684\u591a\u6a21\u6001\u7406\u89e3\u3002\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u591a\u6a21\u6001\u5bf9\u9f50\u65b9\u6cd5\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4f9d\u8d56\u62d2\u7edd\u542f\u53d1\u5f0f\u3002"}}
{"id": "2602.03286", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03286", "abs": "https://arxiv.org/abs/2602.03286", "authors": ["Michael A. M\u00fcller", "Srdjan Vesic", "Bruno Yun"], "title": "Rejecting Arguments Based on Doubt in Structured Bipolar Argumentation", "comment": "Accepted to AAMAS 2026", "summary": "This paper develops a new approach to computational argumentation that is informed by philosophical and linguistic views. Namely, it takes into account two ideas that have received little attention in the literature on computational argumentation: First, an agent may rationally reject an argument based on mere doubt, thus not all arguments they could defend must be accepted; and, second, that it is sometimes more natural to think in terms of which individual sentences or claims an agent accepts in a debate, rather than which arguments. In order to incorporate these two ideas into a computational approach, we first define the notion of structured bipolar argumentation frameworks (SBAFs), where arguments consist of sentences and we have both an attack and a support relation between them. Then, we provide semantics for SBAFs with two features: (1) Unlike with completeness-based semantics, our semantics do not force agents to accept all defended arguments. (2) In addition to argument extensions, which give acceptable sets of arguments, we also provide semantics for language extensions that specify acceptable sets of sentences. These semantics represent reasonable positions an agent might have in a debate. Our semantics lie between the admissible and complete semantics of abstract argumentation. Further, our approach can be used to provide a new perspective on existing approaches. For instance, we can specify the conditions under which an agent can ignore support between arguments (i.e. under which the use of abstract argumentation is warranted) and we show that deductive support semantics is a special case of our approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u54f2\u5b66\u548c\u8bed\u8a00\u5b66\u542f\u53d1\u7684\u8ba1\u7b97\u8bba\u8bc1\u65b0\u65b9\u6cd5\uff0c\u5f15\u5165\u7ed3\u6784\u5316\u53cc\u6781\u8bba\u8bc1\u6846\u67b6(SBAF)\uff0c\u5141\u8bb8\u57fa\u4e8e\u6000\u7591\u62d2\u7edd\u8bba\u8bc1\uff0c\u5e76\u63d0\u4f9b\u8bed\u8a00\u6269\u5c55\u8bed\u4e49\u3002", "motivation": "\u73b0\u6709\u8ba1\u7b97\u8bba\u8bc1\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5c40\u9650\uff1a1) \u8981\u6c42\u63a5\u53d7\u6240\u6709\u53ef\u8fa9\u62a4\u7684\u8bba\u8bc1\uff0c\u4e0d\u5141\u8bb8\u57fa\u4e8e\u6000\u7591\u62d2\u7edd\uff1b2) \u4e3b\u8981\u5173\u6ce8\u8bba\u8bc1\u5c42\u9762\uff0c\u800c\u975e\u4e2a\u4f53\u53e5\u5b50\u6216\u4e3b\u5f20\u3002\u672c\u6587\u65e8\u5728\u5c06\u54f2\u5b66\u548c\u8bed\u8a00\u5b66\u4e2d\u7684\u4e24\u4e2a\u91cd\u8981\u89c2\u70b9\u7eb3\u5165\u8ba1\u7b97\u8bba\u8bc1\u6846\u67b6\u3002", "method": "\u9996\u5148\u5b9a\u4e49\u7ed3\u6784\u5316\u53cc\u6781\u8bba\u8bc1\u6846\u67b6(SBAF)\uff0c\u5176\u4e2d\u8bba\u8bc1\u7531\u53e5\u5b50\u7ec4\u6210\uff0c\u5305\u542b\u653b\u51fb\u548c\u652f\u6301\u5173\u7cfb\u3002\u7136\u540e\u63d0\u51fa\u65b0\u7684\u8bed\u4e49\u5b66\uff0c\u5177\u6709\u4e24\u4e2a\u7279\u5f81\uff1a1) \u4e0d\u5f3a\u5236\u63a5\u53d7\u6240\u6709\u53ef\u8fa9\u62a4\u7684\u8bba\u8bc1\uff1b2) \u9664\u4e86\u8bba\u8bc1\u6269\u5c55\u5916\uff0c\u8fd8\u63d0\u4f9b\u8bed\u8a00\u6269\u5c55\u8bed\u4e49\uff0c\u6307\u5b9a\u53ef\u63a5\u53d7\u7684\u53e5\u5b50\u96c6\u5408\u3002", "result": "\u63d0\u51fa\u7684\u8bed\u4e49\u5b66\u4f4d\u4e8e\u62bd\u8c61\u8bba\u8bc1\u7684\u53ef\u5bb9\u8bb8\u8bed\u4e49\u548c\u5b8c\u5168\u8bed\u4e49\u4e4b\u95f4\uff0c\u80fd\u591f\u8868\u793a\u8fa9\u8bba\u4e2d\u5408\u7406\u7684\u7acb\u573a\u3002\u8be5\u65b9\u6cd5\u4e3a\u73b0\u6709\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff1a\u53ef\u4ee5\u6307\u5b9a\u5ffd\u7565\u8bba\u8bc1\u95f4\u652f\u6301\u7684\u6761\u4ef6\uff0c\u5e76\u8bc1\u660e\u6f14\u7ece\u652f\u6301\u8bed\u4e49\u662f\u672c\u6587\u65b9\u6cd5\u7684\u7279\u4f8b\u3002", "conclusion": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u66f4\u7b26\u5408\u4eba\u7c7b\u63a8\u7406\u5b9e\u9645\u7684\u8ba1\u7b97\u8bba\u8bc1\u65b9\u6cd5\uff0c\u5141\u8bb8\u57fa\u4e8e\u6000\u7591\u62d2\u7edd\u8bba\u8bc1\uff0c\u5e76\u5728\u8bba\u8bc1\u548c\u8bed\u8a00\u5c42\u9762\u63d0\u4f9b\u8bed\u4e49\u5b66\uff0c\u4e3a\u8ba1\u7b97\u8bba\u8bc1\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u81ea\u7136\u7684\u6846\u67b6\u3002"}}
{"id": "2602.03315", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03315", "abs": "https://arxiv.org/abs/2602.03315", "authors": ["Menglin Xia", "Xuchao Zhang", "Shantanu Dixit", "Paramaguru Harimurugan", "Rujia Wang", "Victor Ruhle", "Robert Sim", "Chetan Bansal", "Saravan Rajmohan"], "title": "Memora: A Harmonic Memory Representation Balancing Abstraction and Specificity", "comment": null, "summary": "Agent memory systems must accommodate continuously growing information while supporting efficient, context-aware retrieval for downstream tasks. Abstraction is essential for scaling agent memory, yet it often comes at the cost of specificity, obscuring the fine-grained details required for effective reasoning. We introduce Memora, a harmonic memory representation that structurally balances abstraction and specificity. Memora organizes information via its primary abstractions that index concrete memory values and consolidate related updates into unified memory entries, while cue anchors expand retrieval access across diverse aspects of the memory and connect related memories. Building on this structure, we employ a retrieval policy that actively exploits these memory connections to retrieve relevant information beyond direct semantic similarity. Theoretically, we show that standard Retrieval-Augmented Generation (RAG) and Knowledge Graph (KG)-based memory systems emerge as special cases of our framework. Empirically, Memora establishes a new state-of-the-art on the LoCoMo and LongMemEval benchmarks, demonstrating better retrieval relevance and reasoning effectiveness as memory scales.", "AI": {"tldr": "Memora\u662f\u4e00\u79cd\u5e73\u8861\u62bd\u8c61\u4e0e\u5177\u4f53\u6027\u7684\u8bb0\u5fc6\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3b\u8981\u62bd\u8c61\u7d22\u5f15\u5177\u4f53\u8bb0\u5fc6\u503c\uff0c\u4f7f\u7528\u7ebf\u7d22\u951a\u70b9\u6269\u5c55\u68c0\u7d22\u8bbf\u95ee\uff0c\u5e76\u901a\u8fc7\u4e3b\u52a8\u5229\u7528\u8bb0\u5fc6\u8fde\u63a5\u7684\u68c0\u7d22\u7b56\u7565\u63d0\u5347\u68c0\u7d22\u76f8\u5173\u6027\u3002", "motivation": "\u667a\u80fd\u4f53\u8bb0\u5fc6\u7cfb\u7edf\u9700\u8981\u5904\u7406\u4e0d\u65ad\u589e\u957f\u7684\u4fe1\u606f\uff0c\u540c\u65f6\u652f\u6301\u9ad8\u6548\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u68c0\u7d22\u3002\u62bd\u8c61\u5bf9\u4e8e\u6269\u5c55\u8bb0\u5fc6\u89c4\u6a21\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u901a\u5e38\u4ee5\u727a\u7272\u5177\u4f53\u6027\u4e3a\u4ee3\u4ef7\uff0c\u8fd9\u4f1a\u63a9\u76d6\u6709\u6548\u63a8\u7406\u6240\u9700\u7684\u7ec6\u7c92\u5ea6\u7ec6\u8282\u3002", "method": "\u5f15\u5165Memora\uff0c\u4e00\u79cd\u8c10\u6ce2\u8bb0\u5fc6\u8868\u793a\uff0c\u901a\u8fc7\u4e3b\u8981\u62bd\u8c61\u7d22\u5f15\u5177\u4f53\u8bb0\u5fc6\u503c\u5e76\u6574\u5408\u76f8\u5173\u66f4\u65b0\u4e3a\u7edf\u4e00\u8bb0\u5fc6\u6761\u76ee\uff0c\u540c\u65f6\u4f7f\u7528\u7ebf\u7d22\u951a\u70b9\u6269\u5c55\u8de8\u4e0d\u540c\u8bb0\u5fc6\u65b9\u9762\u7684\u68c0\u7d22\u8bbf\u95ee\u5e76\u8fde\u63a5\u76f8\u5173\u8bb0\u5fc6\u3002\u57fa\u4e8e\u6b64\u7ed3\u6784\uff0c\u91c7\u7528\u4e3b\u52a8\u5229\u7528\u8fd9\u4e9b\u8bb0\u5fc6\u8fde\u63a5\u7684\u68c0\u7d22\u7b56\u7565\u6765\u68c0\u7d22\u8d85\u51fa\u76f4\u63a5\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u76f8\u5173\u4fe1\u606f\u3002", "result": "\u7406\u8bba\u4e0a\uff0c\u6807\u51c6\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u8bb0\u5fc6\u7cfb\u7edf\u88ab\u8bc1\u660e\u662fMemora\u6846\u67b6\u7684\u7279\u4f8b\u3002\u5b9e\u8bc1\u4e0a\uff0cMemora\u5728LoCoMo\u548cLongMemEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5c55\u793a\u4e86\u968f\u7740\u8bb0\u5fc6\u89c4\u6a21\u6269\u5927\u66f4\u597d\u7684\u68c0\u7d22\u76f8\u5173\u6027\u548c\u63a8\u7406\u6709\u6548\u6027\u3002", "conclusion": "Memora\u901a\u8fc7\u8c10\u6ce2\u8bb0\u5fc6\u8868\u793a\u7ed3\u6784\u6027\u5730\u5e73\u8861\u4e86\u62bd\u8c61\u4e0e\u5177\u4f53\u6027\uff0c\u89e3\u51b3\u4e86\u8bb0\u5fc6\u7cfb\u7edf\u5728\u6269\u5c55\u89c4\u6a21\u65f6\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u667a\u80fd\u4f53\u8bb0\u5fc6\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03340", "abs": "https://arxiv.org/abs/2602.03340", "authors": ["Xiao Sun", "Yuming Yang", "Junnan Zhu", "Jiang Zhong", "Xinyu Zhou", "Kaiwen Wei"], "title": "MentalSeek-Dx: Towards Progressive Hypothetico-Deductive Reasoning for Real-world Psychiatric Diagnosis", "comment": "36 pages, 27 figures", "summary": "Mental health disorders represent a burgeoning global public health challenge. While Large Language Models (LLMs) have demonstrated potential in psychiatric assessment, their clinical utility is severely constrained by benchmarks that lack ecological validity and fine-grained diagnostic supervision. To bridge this gap, we introduce \\textbf{MentalDx Bench}, the first benchmark dedicated to disorder-level psychiatric diagnosis within real-world clinical settings. Comprising 712 de-identified electronic health records annotated by board-certified psychiatrists under ICD-11 guidelines, the benchmark covers 76 disorders across 16 diagnostic categories. Evaluation of 18 LLMs reveals a critical \\textit{paradigm misalignment}: strong performance at coarse diagnostic categorization contrasts with systematic failure at disorder-level diagnosis, underscoring a gap between pattern-based modeling and clinical hypothetico-deductive reasoning. In response, we propose \\textbf{MentalSeek-Dx}, a medical-specialized LLM trained to internalize this clinical reasoning process through supervised trajectory construction and curriculum-based reinforcement learning. Experiments on MentalDx Bench demonstrate that MentalSeek-Dx achieves state-of-the-art (SOTA) performance with only 14B parameters, establishing a clinically grounded framework for reliable psychiatric diagnosis.", "AI": {"tldr": "MentalDx Bench\u662f\u9996\u4e2a\u9762\u5411\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u7684\u7cbe\u795e\u969c\u788d\u8bca\u65ad\u57fa\u51c6\uff0c\u5305\u542b712\u4efd\u7535\u5b50\u75c5\u5386\uff0c\u8986\u76d676\u79cdICD-11\u75be\u75c5\u3002\u7814\u7a76\u53d1\u73b0LLMs\u5728\u7c97\u7c92\u5ea6\u5206\u7c7b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7ec6\u7c92\u5ea6\u8bca\u65ad\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u5931\u8d25\u3002\u63d0\u51fa\u7684MentalSeek-Dx\u6a21\u578b\u901a\u8fc7\u4e34\u5e8a\u63a8\u7406\u8bad\u7ec3\uff0c\u572814B\u53c2\u6570\u4e0b\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524dLLMs\u5728\u7cbe\u795e\u5065\u5eb7\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u53d7\u5230\u57fa\u51c6\u6d4b\u8bd5\u751f\u6001\u6548\u5ea6\u4e0d\u8db3\u548c\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u8bca\u65ad\u76d1\u7763\u7684\u9650\u5236\u3002\u9700\u8981\u5efa\u7acb\u66f4\u8d34\u8fd1\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u51c6\u786e\u8861\u91cfLLMs\u5728\u7cbe\u795e\u969c\u788d\u8bca\u65ad\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\u3002", "method": "1) \u6784\u5efaMentalDx Bench\u57fa\u51c6\uff1a\u5305\u542b712\u4efd\u53bb\u6807\u8bc6\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff0c\u7531\u8ba4\u8bc1\u7cbe\u795e\u79d1\u533b\u751f\u6309\u7167ICD-11\u6807\u51c6\u6807\u6ce8\uff0c\u8986\u76d616\u4e2a\u8bca\u65ad\u7c7b\u522b\u768476\u79cd\u75be\u75c5\uff1b2) \u8bc4\u4f3018\u4e2aLLMs\uff0c\u53d1\u73b0\u8303\u5f0f\u9519\u914d\u95ee\u9898\uff1b3) \u63d0\u51faMentalSeek-Dx\u6a21\u578b\uff1a\u901a\u8fc7\u76d1\u7763\u8f68\u8ff9\u6784\u5efa\u548c\u8bfe\u7a0b\u5f0f\u5f3a\u5316\u5b66\u4e60\uff0c\u4f7f\u6a21\u578b\u5185\u5316\u4e34\u5e8a\u5047\u8bbe-\u6f14\u7ece\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "1) LLMs\u5728\u7c97\u7c92\u5ea6\u8bca\u65ad\u5206\u7c7b\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7ec6\u7c92\u5ea6\u969c\u788d\u7ea7\u522b\u8bca\u65ad\u4e0a\u7cfb\u7edf\u6027\u5931\u8d25\uff1b2) MentalSeek-Dx\u5728MentalDx Bench\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4ec5\u4f7f\u752814B\u53c2\u6570\uff1b3) \u63ed\u793a\u4e86LLMs\u57fa\u4e8e\u6a21\u5f0f\u5efa\u6a21\u4e0e\u4e34\u5e8a\u63a8\u7406\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u9996\u4e2a\u4e34\u5e8a\u57fa\u7840\u7684\u7cbe\u795e\u969c\u788d\u8bca\u65ad\u57fa\u51c6\uff0c\u63ed\u793a\u4e86LLMs\u5728\u7ec6\u7c92\u5ea6\u8bca\u65ad\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002MentalSeek-Dx\u4e3a\u53ef\u9760\u7684\u7cbe\u795e\u79d1\u8bca\u65ad\u63d0\u4f9b\u4e86\u4e34\u5e8a\u57fa\u7840\u6846\u67b6\uff0c\u63a8\u52a8\u4e86AI\u5728\u7cbe\u795e\u5065\u5eb7\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2602.03402", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03402", "abs": "https://arxiv.org/abs/2602.03402", "authors": ["Mengxuan Wang", "Yuxin Chen", "Gang Xu", "Tao He", "Hongjie Jiang", "Ming Li"], "title": "Risk Awareness Injection: Calibrating Vision-Language Models for Safety without Compromising Utility", "comment": null, "summary": "Vision language models (VLMs) extend the reasoning capabilities of large language models (LLMs) to cross-modal settings, yet remain highly vulnerable to multimodal jailbreak attacks. Existing defenses predominantly rely on safety fine-tuning or aggressive token manipulations, incurring substantial training costs or significantly degrading utility. Recent research shows that LLMs inherently recognize unsafe content in text, and the incorporation of visual inputs in VLMs frequently dilutes risk-related signals. Motivated by this, we propose Risk Awareness Injection (RAI), a lightweight and training-free framework for safety calibration that restores LLM-like risk recognition by amplifying unsafe signals in VLMs. Specifically, RAI constructs an Unsafe Prototype Subspace from language embeddings and performs targeted modulation on selected high-risk visual tokens, explicitly activating safety-critical signals within the cross-modal feature space. This modulation restores the model's LLM-like ability to detect unsafe content from visual inputs, while preserving the semantic integrity of original tokens for cross-modal reasoning. Extensive experiments across multiple jailbreak and utility benchmarks demonstrate that RAI substantially reduces attack success rate without compromising task performance.", "AI": {"tldr": "RAI\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u5b89\u5168\u6821\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u653e\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e0d\u5b89\u5168\u4fe1\u53f7\u6765\u6062\u590d\u7c7b\u4f3cLLM\u7684\u98ce\u9669\u8bc6\u522b\u80fd\u529b\uff0c\u6709\u6548\u9632\u5fa1\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u800c\u4e0d\u5f71\u54cd\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u73af\u5883\u4e0b\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6210\u672c\uff0c\u8981\u4e48\u4f1a\u663e\u8457\u964d\u4f4e\u6a21\u578b\u6548\u7528\u3002\u7814\u7a76\u53d1\u73b0LLMs\u672c\u8eab\u80fd\u8bc6\u522b\u6587\u672c\u4e2d\u7684\u4e0d\u5b89\u5168\u5185\u5bb9\uff0c\u4f46\u89c6\u89c9\u8f93\u5165\u4f1a\u7a00\u91ca\u98ce\u9669\u4fe1\u53f7\u3002", "method": "\u63d0\u51fa\u98ce\u9669\u611f\u77e5\u6ce8\u5165\u6846\u67b6\uff1a1\uff09\u4ece\u8bed\u8a00\u5d4c\u5165\u6784\u5efa\u4e0d\u5b89\u5168\u539f\u578b\u5b50\u7a7a\u95f4\uff1b2\uff09\u5bf9\u9009\u5b9a\u7684\u9ad8\u98ce\u9669\u89c6\u89c9\u4ee4\u724c\u8fdb\u884c\u9488\u5bf9\u6027\u8c03\u5236\uff0c\u5728\u8de8\u6a21\u6001\u7279\u5f81\u7a7a\u95f4\u4e2d\u663e\u5f0f\u6fc0\u6d3b\u5b89\u5168\u5173\u952e\u4fe1\u53f7\uff1b3\uff09\u4fdd\u6301\u539f\u59cb\u4ee4\u724c\u7684\u8bed\u4e49\u5b8c\u6574\u6027\u4ee5\u652f\u6301\u8de8\u6a21\u6001\u63a8\u7406\u3002", "result": "\u5728\u591a\u4e2a\u8d8a\u72f1\u653b\u51fb\u548c\u6548\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRAI\u663e\u8457\u964d\u4f4e\u4e86\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u6ca1\u6709\u635f\u5bb3\u4efb\u52a1\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "RAI\u901a\u8fc7\u6062\u590d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684LLM\u5f0f\u98ce\u9669\u8bc6\u522b\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u5b89\u5168\u6821\u51c6\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u9632\u5fa1\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u5e76\u4fdd\u6301\u6a21\u578b\u6548\u7528\u3002"}}
{"id": "2602.03403", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03403", "abs": "https://arxiv.org/abs/2602.03403", "authors": ["Guangming Lang", "Mingchuan Shang", "Mengjun Hu", "Jie Zhou", "Feng Xu"], "title": "Feasible strategies for conflict resolution within intuitionistic fuzzy preference-based conflict situations", "comment": null, "summary": "In three-way conflict analysis, preference-based conflict situations characterize agents' attitudes towards issues by formally modeling their preferences over pairs of issues. However, existing preference-based conflict models rely exclusively on three qualitative relations, namely, preference, converse, and indifference, to describe agents' attitudes towards issue pairs, which significantly limits their capacity in capturing the essence of conflict. To overcome this limitation, we introduce the concept of an intuitionistic fuzzy preference-based conflict situation that captures agents' attitudes towards issue pairs with finer granularity than that afforded by classical preference-based models. Afterwards, we develop intuitionistic fuzzy preference-based conflict measures within this framework, and construct three-way conflict analysis models for trisecting the set of agent pairs, the agent set, and the issue set. Additionally, relative loss functions built on the proposed conflict functions are employed to calculate thresholds for three-way conflict analysis. Finally, we present adjustment mechanism-based feasible strategies that simultaneously account for both adjustment magnitudes and conflict degrees, together with an algorithm for constructing such feasible strategies, and provide an illustrative example to demonstrate the validity and effectiveness of the proposed model.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f4\u89c9\u6a21\u7cca\u504f\u597d\u7684\u4e09\u652f\u51b2\u7a81\u5206\u6790\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u76f4\u89c9\u6a21\u7cca\u504f\u597d\u5173\u7cfb\u6765\u66f4\u7cbe\u7ec6\u5730\u63cf\u8ff0\u667a\u80fd\u4f53\u5bf9\u8bae\u9898\u5bf9\u7684\u6001\u5ea6\uff0c\u5e76\u6784\u5efa\u4e86\u76f8\u5e94\u7684\u51b2\u7a81\u5ea6\u91cf\u548c\u4e09\u652f\u51b3\u7b56\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u504f\u597d\u7684\u51b2\u7a81\u5206\u6790\u6a21\u578b\u4ec5\u4f7f\u7528\u504f\u597d\u3001\u9006\u504f\u597d\u548c\u4e2d\u6027\u4e09\u79cd\u5b9a\u6027\u5173\u7cfb\u6765\u63cf\u8ff0\u667a\u80fd\u4f53\u5bf9\u8bae\u9898\u5bf9\u7684\u6001\u5ea6\uff0c\u8fd9\u79cd\u7c97\u7c92\u5ea6\u7684\u8868\u793a\u65b9\u6cd5\u9650\u5236\u4e86\u51c6\u786e\u6355\u6349\u51b2\u7a81\u672c\u8d28\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165\u76f4\u89c9\u6a21\u7cca\u504f\u597d\u51b2\u7a81\u60c5\u5883\u6982\u5ff5\uff0c\u6784\u5efa\u76f4\u89c9\u6a21\u7cca\u504f\u597d\u51b2\u7a81\u5ea6\u91cf\uff0c\u5efa\u7acb\u4e09\u652f\u51b2\u7a81\u5206\u6790\u6a21\u578b\u5bf9\u667a\u80fd\u4f53\u5bf9\u3001\u667a\u80fd\u4f53\u96c6\u5408\u548c\u8bae\u9898\u96c6\u5408\u8fdb\u884c\u4e09\u5206\uff0c\u4f7f\u7528\u76f8\u5bf9\u635f\u5931\u51fd\u6570\u8ba1\u7b97\u9608\u503c\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u8c03\u6574\u673a\u5236\u7684\u53ef\u884c\u7b56\u7565\u6784\u5efa\u7b97\u6cd5\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u66f4\u7cbe\u7ec6\u7684\u51b2\u7a81\u5206\u6790\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u63cf\u8ff0\u667a\u80fd\u4f53\u6001\u5ea6\uff0c\u6784\u5efa\u4e86\u5b8c\u6574\u7684\u4e09\u652f\u51b2\u7a81\u5206\u6790\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u76f4\u89c9\u6a21\u7cca\u504f\u597d\u51b2\u7a81\u5206\u6790\u6a21\u578b\u76f8\u6bd4\u4f20\u7edf\u6a21\u578b\u5177\u6709\u66f4\u5f3a\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u80fd\u591f\u66f4\u7cbe\u7ec6\u5730\u63cf\u8ff0\u51b2\u7a81\u60c5\u5883\uff0c\u4e3a\u590d\u6742\u51b2\u7a81\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.03429", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03429", "abs": "https://arxiv.org/abs/2602.03429", "authors": ["Tae Soo Kim", "Yoonjoo Lee", "Jaesang Yu", "John Joon Young Chung", "Juho Kim"], "title": "DiscoverLLM: From Executing Intents to Discovering Them", "comment": null, "summary": "To handle ambiguous and open-ended requests, Large Language Models (LLMs) are increasingly trained to interact with users to surface intents they have not yet expressed (e.g., ask clarification questions). However, users are often ambiguous because they have not yet formed their intents: they must observe and explore outcomes to discover what they want. Simply asking \"what kind of tone do you want?\" fails when users themselves do not know. We introduce DiscoverLLM, a novel and generalizable framework that trains LLMs to help users form and discover their intents. Central to our approach is a novel user simulator that models cognitive state with a hierarchy of intents that progressively concretize as the model surfaces relevant options -- where the degree of concretization serves as a reward signal that models can be trained to optimize. Resulting models learn to collaborate with users by adaptively diverging (i.e., explore options) when intents are unclear, and converging (i.e., refine and implement) when intents concretize. Across proposed interactive benchmarks in creative writing, technical writing, and SVG drawing, DiscoverLLM achieves over 10% higher task performance while reducing conversation length by up to 40%. In a user study with 75 human participants, DiscoverLLM improved conversation satisfaction and efficiency compared to baselines.", "AI": {"tldr": "DiscoverLLM\u662f\u4e00\u4e2a\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u5e2e\u52a9\u7528\u6237\u5f62\u6210\u548c\u53d1\u73b0\u610f\u56fe\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u7528\u6237\u8ba4\u77e5\u72b6\u6001\u5e76\u4f18\u5316\u610f\u56fe\u5177\u4f53\u5316\u7a0b\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u5728\u610f\u56fe\u4e0d\u6e05\u6670\u65f6\u63a2\u7d22\u9009\u9879\uff0c\u5728\u610f\u56fe\u5177\u4f53\u5316\u65f6\u7ec6\u5316\u5b9e\u65bd\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u6a21\u7cca\u548c\u5f00\u653e\u5f0f\u8bf7\u6c42\u65f6\uff0c\u901a\u5e38\u53ea\u662f\u8be2\u95ee\u7528\u6237\u6f84\u6e05\u95ee\u9898\uff0c\u4f46\u5f53\u7528\u6237\u81ea\u5df1\u4e5f\u4e0d\u77e5\u9053\u81ea\u5df1\u60f3\u8981\u4ec0\u4e48\u65f6\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5c31\u4f1a\u5931\u6548\u3002\u7528\u6237\u4e4b\u6240\u4ee5\u6a21\u7cca\u662f\u56e0\u4e3a\u4ed6\u4eec\u8fd8\u6ca1\u6709\u5f62\u6210\u660e\u786e\u7684\u610f\u56fe\uff0c\u9700\u8981\u901a\u8fc7\u89c2\u5bdf\u548c\u63a2\u7d22\u7ed3\u679c\u6765\u53d1\u73b0\u81ea\u5df1\u771f\u6b63\u60f3\u8981\u7684\u4e1c\u897f\u3002", "method": "\u63d0\u51fa\u4e86DiscoverLLM\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u7528\u6237\u6a21\u62df\u5668\uff0c\u7528\u5c42\u6b21\u5316\u7684\u610f\u56fe\u7ed3\u6784\u5efa\u6a21\u8ba4\u77e5\u72b6\u6001\uff0c\u610f\u56fe\u968f\u7740\u6a21\u578b\u5c55\u793a\u76f8\u5173\u9009\u9879\u800c\u9010\u6b65\u5177\u4f53\u5316\u3002\u610f\u56fe\u5177\u4f53\u5316\u7684\u7a0b\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u6a21\u578b\u53ef\u4ee5\u8bad\u7ec3\u4f18\u5316\u8fd9\u4e2a\u4fe1\u53f7\u3002\u6a21\u578b\u5b66\u4e60\u4e0e\u7528\u6237\u534f\u4f5c\uff0c\u5728\u610f\u56fe\u4e0d\u6e05\u6670\u65f6\u53d1\u6563\u63a2\u7d22\u9009\u9879\uff0c\u5728\u610f\u56fe\u5177\u4f53\u5316\u65f6\u6536\u655b\u7ec6\u5316\u5b9e\u65bd\u3002", "result": "\u5728\u521b\u610f\u5199\u4f5c\u3001\u6280\u672f\u5199\u4f5c\u548cSVG\u7ed8\u56fe\u7b49\u4ea4\u4e92\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDiscoverLLM\u5b9e\u73b0\u4e86\u8d85\u8fc710%\u7684\u4efb\u52a1\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u5c06\u5bf9\u8bdd\u957f\u5ea6\u51cf\u5c11\u4e86\u9ad8\u8fbe40%\u3002\u572875\u540d\u4eba\u7c7b\u53c2\u4e0e\u8005\u7684\u7528\u6237\u7814\u7a76\u4e2d\uff0cDiscoverLLM\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5bf9\u8bdd\u6ee1\u610f\u5ea6\u548c\u6548\u7387\u3002", "conclusion": "DiscoverLLM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u5e2e\u52a9\u7528\u6237\u5f62\u6210\u548c\u53d1\u73b0\u610f\u56fe\uff0c\u901a\u8fc7\u5efa\u6a21\u7528\u6237\u8ba4\u77e5\u72b6\u6001\u548c\u4f18\u5316\u610f\u56fe\u5177\u4f53\u5316\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ea4\u4e92\u5f0f\u4efb\u52a1\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2602.03445", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.03445", "abs": "https://arxiv.org/abs/2602.03445", "authors": ["Qixin Zeng", "Shuo Zhang", "Hongyin Zhang", "Renjie Wang", "Han Zhao", "Libang Zhao", "Runze Li", "Donglin Wang", "Chao Huang"], "title": "CRL-VLA: Continual Vision-Language-Action Learning", "comment": null, "summary": "Lifelong learning is critical for embodied agents in open-world environments, where reinforcement learning fine-tuning has emerged as an important paradigm to enable Vision-Language-Action (VLA) models to master dexterous manipulation through environmental interaction. Thus, Continual Reinforcement Learning (CRL) is a promising pathway for deploying VLA models in lifelong robotic scenarios, yet balancing stability (retaining old skills) and plasticity (learning new ones) remains a formidable challenge for existing methods. We introduce CRL-VLA, a framework for continual post-training of VLA models with rigorous theoretical bounds. We derive a unified performance bound linking the stability-plasticity trade-off to goal-conditioned advantage magnitude, scaled by policy divergence. CRL-VLA resolves this dilemma via asymmetric regulation: constraining advantage magnitudes on prior tasks while enabling controlled growth on new tasks. This is realized through a simple but effective dual-critic architecture with novel Goal-Conditioned Value Formulation (GCVF), where a frozen critic anchors semantic consistency and a trainable estimator drives adaptation. Experiments on the LIBERO benchmark demonstrate that CRL-VLA effectively harmonizes these conflicting objectives, outperforming baselines in both anti-forgetting and forward adaptation.", "AI": {"tldr": "CRL-VLA\u662f\u4e00\u4e2a\u7528\u4e8e\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u548c\u53cc\u8bc4\u8bba\u5bb6\u67b6\u6784\u89e3\u51b3\u7a33\u5b9a\u6027\u4e0e\u53ef\u5851\u6027\u6743\u8861\u95ee\u9898\uff0c\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\uff0c\u7ec8\u8eab\u5b66\u4e60\u5bf9\u5177\u8eab\u667a\u80fd\u4f53\u81f3\u5173\u91cd\u8981\u3002\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u662f\u5c06\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u90e8\u7f72\u5230\u7ec8\u8eab\u673a\u5668\u4eba\u573a\u666f\u7684\u6709\u524d\u666f\u9014\u5f84\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u5e73\u8861\u7a33\u5b9a\u6027\uff08\u4fdd\u7559\u65e7\u6280\u80fd\uff09\u548c\u53ef\u5851\u6027\uff08\u5b66\u4e60\u65b0\u6280\u80fd\uff09\u65b9\u9762\u9762\u4e34\u5de8\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faCRL-VLA\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u5c06\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u6743\u8861\u4e0e\u76ee\u6807\u6761\u4ef6\u4f18\u52bf\u5e45\u5ea6\u548c\u7b56\u7565\u6563\u5ea6\u8054\u7cfb\u8d77\u6765\u3002\u91c7\u7528\u975e\u5bf9\u79f0\u8c03\u8282\u673a\u5236\uff1a\u7ea6\u675f\u5148\u524d\u4efb\u52a1\u7684\u4f18\u52bf\u5e45\u5ea6\uff0c\u540c\u65f6\u5141\u8bb8\u65b0\u4efb\u52a1\u4e0a\u7684\u53d7\u63a7\u589e\u957f\u3002\u5b9e\u73b0\u65b9\u5f0f\u662f\u901a\u8fc7\u5177\u6709\u65b0\u9896\u76ee\u6807\u6761\u4ef6\u4ef7\u503c\u516c\u5f0f\u7684\u53cc\u8bc4\u8bba\u5bb6\u67b6\u6784\uff0c\u5176\u4e2d\u51bb\u7ed3\u8bc4\u8bba\u5bb6\u951a\u5b9a\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u53ef\u8bad\u7ec3\u4f30\u8ba1\u5668\u9a71\u52a8\u9002\u5e94\u3002", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCRL-VLA\u6709\u6548\u534f\u8c03\u4e86\u8fd9\u4e9b\u51b2\u7a81\u76ee\u6807\uff0c\u5728\u6297\u9057\u5fd8\u548c\u5411\u524d\u9002\u5e94\u4e24\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CRL-VLA\u4e3a\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u7684\u6301\u7eed\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u4e25\u683c\u7406\u8bba\u754c\u9650\u7684\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u4e2d\u7a33\u5b9a\u6027\u4e0e\u53ef\u5851\u6027\u7684\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u7ec8\u8eab\u673a\u5668\u4eba\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03467", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.03467", "abs": "https://arxiv.org/abs/2602.03467", "authors": ["Zeynep G. Saribatur", "Johannes Langer", "Ute Schmid"], "title": "The Dual Role of Abstracting over the Irrelevant in Symbolic Explanations: Cognitive Effort vs. Understanding", "comment": "8 pages, 5 figures", "summary": "Explanations are central to human cognition, yet AI systems often produce outputs that are difficult to understand. While symbolic AI offers a transparent foundation for interpretability, raw logical traces often impose a high extraneous cognitive load. We investigate how formal abstractions, specifically removal and clustering, impact human reasoning performance and cognitive effort. Utilizing Answer Set Programming (ASP) as a formal framework, we define a notion of irrelevant details to be abstracted over to obtain simplified explanations. Our cognitive experiments, in which participants classified stimuli across domains with explanations derived from an answer set program, show that clustering details significantly improve participants' understanding, while removal of details significantly reduce cognitive effort, supporting the hypothesis that abstraction enhances human-centered symbolic explanations.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5f62\u5f0f\u5316\u62bd\u8c61\uff08\u79fb\u9664\u548c\u805a\u7c7b\uff09\u5982\u4f55\u5f71\u54cd\u4eba\u7c7b\u63a8\u7406\u6027\u80fd\u548c\u8ba4\u77e5\u8d1f\u8377\uff0c\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\u4f5c\u4e3a\u5f62\u5f0f\u6846\u67b6\uff0c\u901a\u8fc7\u8ba4\u77e5\u5b9e\u9a8c\u9a8c\u8bc1\u62bd\u8c61\u5316\u80fd\u63d0\u5347\u7b26\u53f7\u89e3\u91ca\u7684\u4eba\u7c7b\u53ef\u7406\u89e3\u6027\u3002", "motivation": "\u867d\u7136\u7b26\u53f7AI\u4e3a\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u900f\u660e\u57fa\u7840\uff0c\u4f46\u539f\u59cb\u903b\u8f91\u8f68\u8ff9\u5f80\u5f80\u5e26\u6765\u8f83\u9ad8\u7684\u5916\u5728\u8ba4\u77e5\u8d1f\u8377\u3002\u9700\u8981\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5f62\u5f0f\u5316\u62bd\u8c61\u6765\u6539\u5584\u4eba\u7c7b\u5bf9AI\u7cfb\u7edf\u8f93\u51fa\u7684\u7406\u89e3\u3002", "method": "\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u4f5c\u4e3a\u5f62\u5f0f\u6846\u67b6\uff0c\u5b9a\u4e49\u4e0d\u76f8\u5173\u7ec6\u8282\u7684\u6982\u5ff5\u8fdb\u884c\u62bd\u8c61\u5316\uff08\u79fb\u9664\u548c\u805a\u7c7b\uff09\u3002\u901a\u8fc7\u8ba4\u77e5\u5b9e\u9a8c\uff0c\u8ba9\u53c2\u4e0e\u8005\u4f7f\u7528\u4ece\u7b54\u6848\u96c6\u7a0b\u5e8f\u5bfc\u51fa\u7684\u89e3\u91ca\u5bf9\u8de8\u9886\u57df\u523a\u6fc0\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff1a\u805a\u7c7b\u7ec6\u8282\u663e\u8457\u63d0\u9ad8\u53c2\u4e0e\u8005\u7684\u7406\u89e3\u80fd\u529b\uff0c\u800c\u79fb\u9664\u7ec6\u8282\u5219\u663e\u8457\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377\uff0c\u652f\u6301\u62bd\u8c61\u5316\u80fd\u589e\u5f3a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u7b26\u53f7\u89e3\u91ca\u8fd9\u4e00\u5047\u8bbe\u3002", "conclusion": "\u5f62\u5f0f\u5316\u62bd\u8c61\uff08\u7279\u522b\u662f\u79fb\u9664\u548c\u805a\u7c7b\uff09\u80fd\u6709\u6548\u63d0\u5347\u4eba\u7c7b\u5bf9\u7b26\u53f7AI\u89e3\u91ca\u7684\u7406\u89e3\uff0c\u51cf\u5c11\u8ba4\u77e5\u8d1f\u8377\uff0c\u4e3a\u8bbe\u8ba1\u66f4\u4eba\u6027\u5316\u7684\u53ef\u89e3\u91caAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002"}}
{"id": "2602.03478", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03478", "abs": "https://arxiv.org/abs/2602.03478", "authors": ["Guannan Lai", "Han-Jia Ye"], "title": "When Routing Collapses: On the Degenerate Convergence of LLM Routers", "comment": null, "summary": "LLM routing aims to achieve a favorable quality--cost trade-off by dynamically assigning easy queries to smaller models and harder queries to stronger ones. However, across both unimodal and multimodal settings, we uncover a pervasive yet underexplored failure mode in existing routers: as the user's cost budget increases, routers systematically default to the most capable and most expensive model even when cheaper models already suffice. As a result, current routers under-utilize small models, wasting computation and monetary cost and undermining the core promise of routing; we term this phenomenon routing collapse. We attribute routing collapse to an objective--decision mismatch: many routers are trained to predict scalar performance scores, whereas routing decisions ultimately depend on discrete comparisons among candidate models. Consequently, small prediction errors can flip relative orderings and trigger suboptimal selections. To bridge this gap, we propose EquiRouter, a decision-aware router that directly learns model rankings, restoring the role of smaller models and mitigating routing collapse. On RouterBench, EquiRouter reduces cost by about 17\\% at GPT-4-level performance compared to the strongest prior router. Our code is available at https://github.com/AIGNLAI/EquiRouter.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0\u73b0\u6709LLM\u8def\u7531\u7cfb\u7edf\u5b58\u5728\"\u8def\u7531\u5d29\u6e83\"\u95ee\u9898\uff1a\u968f\u7740\u6210\u672c\u9884\u7b97\u589e\u52a0\uff0c\u8def\u7531\u5668\u4f1a\u7cfb\u7edf\u6027\u5730\u9009\u62e9\u6700\u5f3a\u5927\u4f46\u6700\u6602\u8d35\u7684\u6a21\u578b\uff0c\u5373\u4f7f\u66f4\u4fbf\u5b9c\u7684\u6a21\u578b\u5df2\u7ecf\u8db3\u591f\uff0c\u5bfc\u81f4\u5c0f\u6a21\u578b\u5229\u7528\u4e0d\u8db3\u548c\u6210\u672c\u6d6a\u8d39\u3002\u4f5c\u8005\u63d0\u51faEquiRouter\u76f4\u63a5\u5b66\u4e60\u6a21\u578b\u6392\u5e8f\u6765\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u8def\u7531\u7cfb\u7edf\u5b58\u5728\u4e00\u4e2a\u666e\u904d\u4f46\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u5931\u8d25\u6a21\u5f0f\uff1a\u968f\u7740\u7528\u6237\u6210\u672c\u9884\u7b97\u589e\u52a0\uff0c\u8def\u7531\u5668\u4f1a\u7cfb\u7edf\u6027\u5730\u9ed8\u8ba4\u9009\u62e9\u6700\u5f3a\u5927\u3001\u6700\u6602\u8d35\u7684\u6a21\u578b\uff0c\u5373\u4f7f\u66f4\u4fbf\u5b9c\u7684\u6a21\u578b\u5df2\u7ecf\u8db3\u591f\u3002\u8fd9\u5bfc\u81f4\u5c0f\u6a21\u578b\u5229\u7528\u4e0d\u8db3\uff0c\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u548c\u91d1\u94b1\u6210\u672c\uff0c\u8fdd\u80cc\u4e86\u8def\u7531\u7684\u6838\u5fc3\u627f\u8bfa\uff0c\u4f5c\u8005\u79f0\u4e4b\u4e3a\"\u8def\u7531\u5d29\u6e83\"\u73b0\u8c61\u3002", "method": "\u4f5c\u8005\u63d0\u51faEquiRouter\uff0c\u4e00\u79cd\u51b3\u7b56\u611f\u77e5\u7684\u8def\u7531\u5668\uff0c\u76f4\u63a5\u5b66\u4e60\u6a21\u578b\u6392\u5e8f\u800c\u975e\u9884\u6d4b\u6807\u91cf\u6027\u80fd\u5206\u6570\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u89e3\u51b3\u76ee\u6807-\u51b3\u7b56\u4e0d\u5339\u914d\u95ee\u9898\u6765\u6062\u590d\u5c0f\u6a21\u578b\u7684\u4f5c\u7528\u5e76\u7f13\u89e3\u8def\u7531\u5d29\u6e83\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b83\u907f\u514d\u4e86\u56e0\u5c0f\u9884\u6d4b\u8bef\u5dee\u5bfc\u81f4\u76f8\u5bf9\u6392\u5e8f\u7ffb\u8f6c\u800c\u89e6\u53d1\u6b21\u4f18\u9009\u62e9\u7684\u95ee\u9898\u3002", "result": "\u5728RouterBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEquiRouter\u5728\u8fbe\u5230GPT-4\u7ea7\u522b\u6027\u80fd\u65f6\uff0c\u76f8\u6bd4\u5148\u524d\u6700\u5f3a\u7684\u8def\u7531\u5668\u51cf\u5c11\u4e86\u7ea617%\u7684\u6210\u672c\u3002\u8fd9\u8868\u660eEquiRouter\u80fd\u66f4\u6709\u6548\u5730\u5229\u7528\u5c0f\u6a21\u578b\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u8d28\u91cf-\u6210\u672c\u6743\u8861\u3002", "conclusion": "\u8def\u7531\u5d29\u6e83\u662fLLM\u8def\u7531\u4e2d\u666e\u904d\u5b58\u5728\u7684\u7cfb\u7edf\u6027\u95ee\u9898\uff0c\u6e90\u4e8e\u76ee\u6807-\u51b3\u7b56\u4e0d\u5339\u914d\u3002EquiRouter\u901a\u8fc7\u76f4\u63a5\u5b66\u4e60\u6a21\u578b\u6392\u5e8f\u800c\u975e\u9884\u6d4b\u6807\u91cf\u5206\u6570\uff0c\u6210\u529f\u7f13\u89e3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u6210\u672c\uff0c\u4e3aLLM\u8def\u7531\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03569", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03569", "abs": "https://arxiv.org/abs/2602.03569", "authors": ["Linjie Mu", "Zhongzhen Huang", "Yannian Gu", "Shengqian Qin", "Shaoting Zhang", "Xiaofan Zhang"], "title": "EHRWorld: A Patient-Centric Medical World Model for Long-Horizon Clinical Trajectories", "comment": null, "summary": "World models offer a principled framework for simulating future states under interventions, but realizing such models in complex, high-stakes domains like medicine remains challenging. Recent large language models (LLMs) have achieved strong performance on static medical reasoning tasks, raising the question of whether they can function as dynamic medical world models capable of simulating disease progression and treatment outcomes over time. In this work, we show that LLMs only incorporating medical knowledge struggle to maintain consistent patient states under sequential interventions, leading to error accumulation in long-horizon clinical simulation. To address this limitation, we introduce EHRWorld, a patient-centric medical world model trained under a causal sequential paradigm, together with EHRWorld-110K, a large-scale longitudinal clinical dataset derived from real-world electronic health records. Extensive evaluations demonstrate that EHRWorld significantly outperforms naive LLM-based baselines, achieving more stable long-horizon simulation, improved modeling of clinically sensitive events, and favorable reasoning efficiency, highlighting the necessity of training on causally grounded, temporally evolving clinical data for reliable and robust medical world modeling.", "AI": {"tldr": "EHRWorld\uff1a\u57fa\u4e8e\u56e0\u679c\u5e8f\u5217\u8303\u5f0f\u8bad\u7ec3\u7684\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u533b\u7597\u4e16\u754c\u6a21\u578b\uff0c\u663e\u8457\u4f18\u4e8e\u5355\u7eaf\u57fa\u4e8e\u533b\u5b66\u77e5\u8bc6\u7684LLM\uff0c\u5728\u957f\u65f6\u7a0b\u4e34\u5e8a\u6a21\u62df\u4e2d\u8868\u73b0\u66f4\u7a33\u5b9a", "motivation": "\u4e16\u754c\u6a21\u578b\u4e3a\u5e72\u9884\u4e0b\u7684\u672a\u6765\u72b6\u6001\u6a21\u62df\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u4f46\u5728\u533b\u5b66\u7b49\u590d\u6742\u9ad8\u98ce\u9669\u9886\u57df\u5b9e\u73b0\u4ecd\u5177\u6311\u6218\u3002\u867d\u7136LLM\u5728\u9759\u6001\u533b\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u80fd\u5426\u4f5c\u4e3a\u52a8\u6001\u533b\u7597\u4e16\u754c\u6a21\u578b\u6a21\u62df\u75be\u75c5\u8fdb\u5c55\u548c\u6cbb\u7597\u6548\u679c\u5c1a\u5b58\u7591\u95ee", "method": "\u63d0\u51faEHRWorld\uff0c\u4e00\u79cd\u5728\u56e0\u679c\u5e8f\u5217\u8303\u5f0f\u4e0b\u8bad\u7ec3\u7684\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u533b\u7597\u4e16\u754c\u6a21\u578b\uff0c\u5e76\u6784\u5efa\u4e86EHRWorld-110K\u2014\u2014\u4e00\u4e2a\u4ece\u771f\u5b9e\u4e16\u754c\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u63d0\u53d6\u7684\u5927\u89c4\u6a21\u7eb5\u5411\u4e34\u5e8a\u6570\u636e\u96c6", "result": "EHRWorld\u663e\u8457\u4f18\u4e8e\u5355\u7eaf\u7684LLM\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u7684\u957f\u65f6\u7a0b\u6a21\u62df\u3001\u66f4\u597d\u7684\u4e34\u5e8a\u654f\u611f\u4e8b\u4ef6\u5efa\u6a21\u4ee5\u53ca\u66f4\u4f18\u7684\u63a8\u7406\u6548\u7387", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u56e0\u679c\u57fa\u7840\u3001\u65f6\u95f4\u6f14\u5316\u7684\u4e34\u5e8a\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u5bf9\u4e8e\u6784\u5efa\u53ef\u9760\u4e14\u9c81\u68d2\u7684\u533b\u7597\u4e16\u754c\u6a21\u578b\u81f3\u5173\u91cd\u8981"}}
{"id": "2602.03688", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03688", "abs": "https://arxiv.org/abs/2602.03688", "authors": ["Wenzhe Fan", "Tommaso Tognoli", "Henry Peng Zou", "Chunyu Miao", "Yibo Wang", "Xinhua Zhang"], "title": "TodyComm: Task-Oriented Dynamic Communication for Multi-Round LLM-based Multi-Agent System", "comment": null, "summary": "Multi-round LLM-based multi-agent systems rely on effective communication structures to support collaboration across rounds. However, most existing methods employ a fixed communication topology during inference, which falls short in many realistic applications where the agents' roles may change \\textit{across rounds} due to dynamic adversary, task progression, or time-varying constraints such as communication bandwidth. In this paper, we propose addressing this issue through TodyComm, a \\textbf{t}ask-\\textbf{o}riented \\textbf{dy}namic \\textbf{comm}unication algorithm. It produces behavior-driven collaboration topologies that adapt to the dynamics at each round, optimizing the utility for the task through policy gradient. Experiments on five benchmarks demonstrate that under both dynamic adversary and communications budgets, TodyComm delivers superior task effectiveness while retaining token efficiency and scalability.", "AI": {"tldr": "TodyComm\uff1a\u57fa\u4e8e\u4efb\u52a1\u5bfc\u5411\u7684\u52a8\u6001\u901a\u4fe1\u7b97\u6cd5\uff0c\u7528\u4e8e\u591a\u8f6eLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u6839\u636e\u6bcf\u8f6e\u52a8\u6001\u53d8\u5316\uff08\u5982\u5bf9\u6297\u8005\u3001\u4efb\u52a1\u8fdb\u5c55\u3001\u901a\u4fe1\u5e26\u5bbd\u9650\u5236\uff09\u81ea\u9002\u5e94\u8c03\u6574\u901a\u4fe1\u62d3\u6251\u7ed3\u6784\u3002", "motivation": "\u73b0\u6709\u591a\u8f6eLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5927\u591a\u91c7\u7528\u56fa\u5b9a\u7684\u901a\u4fe1\u62d3\u6251\u7ed3\u6784\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u4e3a\u667a\u80fd\u4f53\u7684\u89d2\u8272\u53ef\u80fd\u56e0\u52a8\u6001\u5bf9\u6297\u8005\u3001\u4efb\u52a1\u8fdb\u5c55\u6216\u65f6\u53d8\u901a\u4fe1\u5e26\u5bbd\u9650\u5236\u800c\u5728\u4e0d\u540c\u8f6e\u6b21\u95f4\u53d1\u751f\u53d8\u5316\u3002", "method": "\u63d0\u51faTodyComm\uff08\u4efb\u52a1\u5bfc\u5411\u52a8\u6001\u901a\u4fe1\u7b97\u6cd5\uff09\uff0c\u901a\u8fc7\u7b56\u7565\u68af\u5ea6\u4f18\u5316\uff0c\u751f\u6210\u884c\u4e3a\u9a71\u52a8\u7684\u534f\u4f5c\u62d3\u6251\u7ed3\u6784\uff0c\u4f7f\u901a\u4fe1\u7ed3\u6784\u80fd\u591f\u9002\u5e94\u6bcf\u8f6e\u7684\u52a8\u6001\u53d8\u5316\uff0c\u4ece\u800c\u4f18\u5316\u4efb\u52a1\u6548\u7528\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u52a8\u6001\u5bf9\u6297\u8005\u548c\u901a\u4fe1\u9884\u7b97\u7ea6\u675f\u4e0b\uff0cTodyComm\u5728\u4efb\u52a1\u6548\u679c\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4ee4\u724c\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "TodyComm\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u901a\u4fe1\u62d3\u6251\u7ed3\u6784\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f6eLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u56fa\u5b9a\u901a\u4fe1\u7ed3\u6784\u7684\u5c40\u9650\u6027\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u4efb\u52a1\u6027\u80fd\u548c\u8d44\u6e90\u6548\u7387\u3002"}}
{"id": "2602.03786", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03786", "abs": "https://arxiv.org/abs/2602.03786", "authors": ["Jianhao Ruan", "Zhihao Xu", "Yiran Peng", "Fashen Ren", "Zhaoyang Yu", "Xinbing Liang", "Jinyu Xiang", "Bang Liu", "Chenglin Wu", "Yuyu Luo", "Jiayi Zhang"], "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration", "comment": null, "summary": "Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra", "AI": {"tldr": "AOrchestra\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u3001\u6846\u67b6\u65e0\u5173\u7684\u667a\u80fd\u4f53\u7f16\u6392\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u667a\u80fd\u4f53\u62bd\u8c61\u4e3a(\u6307\u4ee4\u3001\u4e0a\u4e0b\u6587\u3001\u5de5\u5177\u3001\u6a21\u578b)\u56db\u5143\u7ec4\uff0c\u5b9e\u73b0\u52a8\u6001\u521b\u5efa\u4e13\u7528\u6267\u884c\u5668\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u3001\u957f\u65f6\u7a0b\u4efb\u52a1\u65f6\uff0c\u7f3a\u4e4f\u5bf9\u5b50\u667a\u80fd\u4f53\u7684\u52a8\u6001\u62bd\u8c61\u89c6\u56fe\uff0c\u5bfc\u81f4\u9002\u5e94\u6027\u4e0d\u8db3\u3002\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u7684\u667a\u80fd\u4f53\u62bd\u8c61\u65b9\u6cd5\u6765\u63d0\u9ad8\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7684\u667a\u80fd\u4f53\u62bd\u8c61\uff1a\u5c06\u4efb\u4f55\u667a\u80fd\u4f53\u5efa\u6a21\u4e3a(\u6307\u4ee4\u3001\u4e0a\u4e0b\u6587\u3001\u5de5\u5177\u3001\u6a21\u578b)\u56db\u5143\u7ec4\u3002\u57fa\u4e8e\u6b64\u6784\u5efaAOrchestra\u7cfb\u7edf\uff0c\u5176\u4e2d\u4e2d\u5fc3\u7f16\u6392\u5668\u5728\u6bcf\u4e2a\u6b65\u9aa4\u5177\u4f53\u5316\u8fd9\u4e2a\u56db\u5143\u7ec4\uff1a\u7b56\u5212\u4efb\u52a1\u76f8\u5173\u4e0a\u4e0b\u6587\u3001\u9009\u62e9\u5de5\u5177\u548c\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5373\u65f6\u81ea\u52a8\u521b\u5efa\u667a\u80fd\u4f53\u6765\u59d4\u6258\u6267\u884c\u3002", "result": "\u5728\u4e09\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5(GAIA\u3001SWE-Bench\u3001Terminal-Bench)\u4e2d\uff0cAOrchestra\u4e0eGemini-3-Flash\u914d\u5bf9\u65f6\uff0c\u76f8\u5bf9\u4e8e\u6700\u5f3a\u57fa\u7ebf\u5b9e\u73b0\u4e8616.28%\u7684\u76f8\u5bf9\u6539\u8fdb\u3002\u7cfb\u7edf\u652f\u6301\u53ef\u63a7\u7684\u6027\u80fd-\u6210\u672c\u6743\u8861\uff0c\u80fd\u591f\u63a5\u8fd1\u5e15\u7d2f\u6258\u6548\u7387\u3002", "conclusion": "AOrchestra\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6846\u67b6\u65e0\u5173\u7684\u667a\u80fd\u4f53\u7f16\u6392\u7cfb\u7edf\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u667a\u80fd\u4f53\u62bd\u8c61\u5b9e\u73b0\u52a8\u6001\u4efb\u52a1\u6267\u884c\uff0c\u51cf\u5c11\u4e86\u4eba\u5de5\u5de5\u7a0b\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u652f\u6301\u591a\u79cd\u667a\u80fd\u4f53\u4f5c\u4e3a\u4efb\u52a1\u6267\u884c\u5668\u7684\u5373\u63d2\u5373\u7528\uff0c\u5728\u6027\u80fd\u548c\u6210\u672c\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6709\u6548\u5e73\u8861\u3002"}}
{"id": "2602.03794", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03794", "abs": "https://arxiv.org/abs/2602.03794", "authors": ["Yingxuan Yang", "Chengrui Qu", "Muning Wen", "Laixi Shi", "Ying Wen", "Weinan Zhang", "Adam Wierman", "Shangding Gu"], "title": "Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity", "comment": null, "summary": "LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling.", "AI": {"tldr": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd\u53d7\u9650\u4e8e\u4efb\u52a1\u5185\u5728\u4e0d\u786e\u5b9a\u6027\u800c\u975e\u667a\u80fd\u4f53\u6570\u91cf\uff0c\u5f02\u6784\u667a\u80fd\u4f53\u901a\u8fc7\u63d0\u4f9b\u4e92\u8865\u4fe1\u606f\u663e\u8457\u4f18\u4e8e\u540c\u6784\u667a\u80fd\u4f53\u6269\u5c55", "motivation": "\u7814\u7a76LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd\u6269\u5c55\u7684\u5c40\u9650\u6027\uff0c\u53d1\u73b0\u589e\u52a0\u540c\u6784\u667a\u80fd\u4f53\u6570\u91cf\u5b58\u5728\u6536\u76ca\u9012\u51cf\uff0c\u800c\u5f15\u5165\u5f02\u6784\u6027\u5374\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u9700\u8981\u7406\u89e3\u8fd9\u79cd\u5dee\u5f02\u7684\u6839\u672c\u539f\u56e0", "method": "\u63d0\u51fa\u4fe1\u606f\u8bba\u6846\u67b6\u5206\u6790\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd\u8fb9\u754c\uff0c\u5f15\u5165K*\u6307\u6807\u91cf\u5316\u6709\u6548\u901a\u9053\u6570\u91cf\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5f02\u6784\u914d\u7f6e\u7684\u6027\u80fd\u4f18\u52bf", "result": "\u5f02\u6784\u914d\u7f6e\u663e\u8457\u4f18\u4e8e\u540c\u6784\u6269\u5c55\uff1a2\u4e2a\u5f02\u6784\u667a\u80fd\u4f53\u6027\u80fd\u53ef\u5339\u914d\u6216\u8d85\u8fc716\u4e2a\u540c\u6784\u667a\u80fd\u4f53\uff0cK*\u6307\u6807\u80fd\u6709\u6548\u91cf\u5316\u7cfb\u7edf\u591a\u6837\u6027", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd\u53d7\u4efb\u52a1\u5185\u5728\u4e0d\u786e\u5b9a\u6027\u9650\u5236\u800c\u975e\u667a\u80fd\u4f53\u6570\u91cf\uff0c\u5f02\u6784\u6027\u901a\u8fc7\u63d0\u4f9b\u4e92\u8865\u8bc1\u636e\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u6784\u5efa\u9ad8\u6548\u9c81\u68d2\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u57fa\u4e8e\u591a\u6837\u6027\u7684\u8bbe\u8ba1\u539f\u5219"}}
{"id": "2602.03814", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03814", "abs": "https://arxiv.org/abs/2602.03814", "authors": ["Xi Wang", "Anushri Suresh", "Alvin Zhang", "Rishi More", "William Jurayj", "Benjamin Van Durme", "Mehrdad Farajtabar", "Daniel Khashabi", "Eric Nalisnick"], "title": "Conformal Thinking: Risk Control for Reasoning on a Compute Budget", "comment": null, "summary": "Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting the token budget, as well as the threshold for adaptive reasoning, is a practical challenge that entails a fundamental risk-accuracy trade-off. We re-frame the budget setting problem as risk control, limiting the error rate while minimizing compute. Our framework introduces an upper threshold that stops reasoning when the model is confident (risking incorrect output) and a novel parametric lower threshold that preemptively stops unsolvable instances (risking premature stoppage). Given a target risk and a validation set, we use distribution-free risk control to optimally specify these stopping mechanisms. For scenarios with multiple budget controlling criteria, we incorporate an efficiency loss to select the most computationally efficient exiting mechanism. Empirical results across diverse reasoning tasks and models demonstrate the effectiveness of our risk control approach, demonstrating computational efficiency gains from the lower threshold and ensemble stopping mechanisms while adhering to the user-specified risk target.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u98ce\u9669\u63a7\u5236\u7684LLM\u63a8\u7406\u9884\u7b97\u8bbe\u7f6e\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u9608\u503c\u673a\u5236\u5728\u4fdd\u8bc1\u9519\u8bef\u7387\u7684\u524d\u63d0\u4e0b\u6700\u5c0f\u5316\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u652f\u6301\u6d4b\u8bd5\u65f6\u6269\u5c55\uff0c\u968f\u7740token\u9884\u7b97\u589e\u52a0\uff0c\u6570\u636e\u96c6\u51c6\u786e\u7387\u4f1a\u63d0\u5347\uff0c\u8fd9\u4fc3\u4f7f\u4e86\u81ea\u9002\u5e94\u63a8\u7406\u7684\u9700\u6c42\u2014\u2014\u5728\u80fd\u63d0\u9ad8\u53ef\u9760\u6027\u65f6\u4f7f\u7528\u66f4\u591atoken\uff0c\u5728\u989d\u5916\u8ba1\u7b97\u53ef\u80fd\u65e0\u7528\u65f6\u63d0\u524d\u505c\u6b62\u3002\u7136\u800c\uff0c\u8bbe\u7f6etoken\u9884\u7b97\u548c\u81ea\u9002\u5e94\u63a8\u7406\u9608\u503c\u662f\u4e00\u4e2a\u5b9e\u9645\u6311\u6218\uff0c\u6d89\u53ca\u57fa\u672c\u7684\u98ce\u9669-\u51c6\u786e\u7387\u6743\u8861\u3002", "method": "\u5c06\u9884\u7b97\u8bbe\u7f6e\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u98ce\u9669\u63a7\u5236\u95ee\u9898\uff0c\u5728\u9650\u5236\u9519\u8bef\u7387\u7684\u540c\u65f6\u6700\u5c0f\u5316\u8ba1\u7b97\u3002\u6846\u67b6\u5f15\u5165\uff1a1\uff09\u4e0a\u9608\u503c\u673a\u5236\uff0c\u5f53\u6a21\u578b\u7f6e\u4fe1\u5ea6\u9ad8\u65f6\u505c\u6b62\u63a8\u7406\uff08\u53ef\u80fd\u8f93\u51fa\u9519\u8bef\u7ed3\u679c\uff09\uff1b2\uff09\u65b0\u9896\u7684\u53c2\u6570\u5316\u4e0b\u9608\u503c\u673a\u5236\uff0c\u9884\u5148\u505c\u6b62\u65e0\u6cd5\u89e3\u51b3\u7684\u5b9e\u4f8b\uff08\u53ef\u80fd\u8fc7\u65e9\u505c\u6b62\uff09\u3002\u7ed9\u5b9a\u76ee\u6807\u98ce\u9669\u548c\u9a8c\u8bc1\u96c6\uff0c\u4f7f\u7528\u5206\u5e03\u65e0\u5173\u7684\u98ce\u9669\u63a7\u5236\u6765\u4f18\u5316\u6307\u5b9a\u8fd9\u4e9b\u505c\u6b62\u673a\u5236\u3002\u5bf9\u4e8e\u591a\u9884\u7b97\u63a7\u5236\u6807\u51c6\u573a\u666f\uff0c\u5f15\u5165\u6548\u7387\u635f\u5931\u6765\u9009\u62e9\u8ba1\u7b97\u6548\u7387\u6700\u9ad8\u7684\u9000\u51fa\u673a\u5236\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u63a8\u7406\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u98ce\u9669\u63a7\u5236\u65b9\u6cd5\u6709\u6548\uff0c\u5c55\u793a\u4e86\u4ece\u4e0b\u9608\u503c\u548c\u96c6\u6210\u505c\u6b62\u673a\u5236\u4e2d\u83b7\u5f97\u7684\u8ba1\u7b97\u6548\u7387\u63d0\u5347\uff0c\u540c\u65f6\u9075\u5b88\u7528\u6237\u6307\u5b9a\u7684\u98ce\u9669\u76ee\u6807\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86LLM\u63a8\u7406\u4e2d\u7684\u98ce\u9669-\u8ba1\u7b97\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u98ce\u9669\u63a7\u5236\u65b9\u6cd5\u5728\u4fdd\u8bc1\u9519\u8bef\u7387\u4e0a\u9650\u7684\u524d\u63d0\u4e0b\u4f18\u5316\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u81ea\u9002\u5e94\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03828", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.DL"], "pdf": "https://arxiv.org/pdf/2602.03828", "abs": "https://arxiv.org/abs/2602.03828", "authors": ["Minjun Zhu", "Zhen Lin", "Yixuan Weng", "Panzhong Lu", "Qiujie Xie", "Yifan Wei", "Sifan Liu", "Qiyao Sun", "Yue Zhang"], "title": "AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations", "comment": "Accepted at the ICLR 2026", "summary": "High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers, surveys, blogs, and textbooks. Moreover, we propose AutoFigure, the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text. Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal. Leveraging the high-quality data from FigureBench, we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations. The code, dataset and huggingface space are released in https://github.com/ResearAI/AutoFigure.", "AI": {"tldr": "FigureBench\u662f\u9996\u4e2a\u5927\u89c4\u6a21\u79d1\u5b66\u63d2\u56fe\u751f\u6210\u57fa\u51c6\uff0c\u5305\u542b3300\u4e2a\u9ad8\u8d28\u91cf\u6587\u672c-\u63d2\u56fe\u5bf9\uff1bAutoFigure\u662f\u9996\u4e2a\u57fa\u4e8e\u957f\u6587\u672c\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u79d1\u5b66\u63d2\u56fe\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u601d\u7ef4\u3001\u91cd\u7ec4\u548c\u9a8c\u8bc1\u5b9e\u73b0\u7ed3\u6784\u5b8c\u6574\u4e14\u7f8e\u89c2\u7684\u63d2\u56fe\u3002", "motivation": "\u9ad8\u8d28\u91cf\u79d1\u5b66\u63d2\u56fe\u5bf9\u4e8e\u6709\u6548\u4f20\u8fbe\u590d\u6742\u79d1\u6280\u6982\u5ff5\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u521b\u5efa\u63d2\u56fe\u5728\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u90fd\u662f\u516c\u8ba4\u7684\u74f6\u9888\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86FigureBench\u57fa\u51c6\u6570\u636e\u96c6\uff083300\u4e2a\u9ad8\u8d28\u91cf\u6587\u672c-\u63d2\u56fe\u5bf9\uff09\u548cAutoFigure\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u6700\u7ec8\u6e32\u67d3\u524d\u901a\u8fc7\u5e7f\u6cdb\u601d\u8003\u3001\u91cd\u7ec4\u548c\u9a8c\u8bc1\u6765\u751f\u6210\u7ed3\u6784\u5408\u7406\u4e14\u7f8e\u89c2\u7684\u5e03\u5c40\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAutoFigure\u5728\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u80fd\u591f\u751f\u6210\u53ef\u76f4\u63a5\u7528\u4e8e\u53d1\u8868\u7684\u79d1\u5b66\u63d2\u56fe\uff0c\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548cHuggingFace\u7a7a\u95f4\u5df2\u5f00\u6e90\u3002", "conclusion": "FigureBench\u4e3a\u79d1\u5b66\u63d2\u56fe\u751f\u6210\u63d0\u4f9b\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\uff0cAutoFigure\u6846\u67b6\u901a\u8fc7\u667a\u80fd\u4f53\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u957f\u6587\u672c\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u79d1\u5b66\u63d2\u56fe\u7684\u76ee\u6807\uff0c\u89e3\u51b3\u4e86\u624b\u52a8\u521b\u5efa\u7684\u74f6\u9888\u95ee\u9898\u3002"}}
