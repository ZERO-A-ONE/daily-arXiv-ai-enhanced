{"id": "2508.00031", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00031", "abs": "https://arxiv.org/abs/2508.00031", "authors": ["Junde Wu"], "title": "Git Context Controller: Manage the Context of LLM-based Agents like Git", "comment": "in updating", "summary": "Large language model (LLM) based agents have shown impressive capabilities by\ninterleaving internal reasoning with external tool use. However, as these\nagents are deployed in long-horizon workflows, such as coding for a big,\nlong-term project, context management becomes a critical bottleneck. We\nintroduce Git-Context-Controller (GCC), a structured context management\nframework inspired by software version control systems. GCC elevates context as\nversioned memory hierarchy like Git. It structures agent memory as a persistent\nfile system with explicit operations: COMMIT, BRANCH, MERGE, and CONTEXT,\nenabling milestone-based checkpointing, exploration of alternative plans, and\nstructured reflection. Our approach empowers agents to manage long-term goals,\nisolate architectural experiments, and recover or hand off memory across\nsessions and agents. Empirically, agents equipped with GCC achieve\nstate-of-the-art performance on the SWE-Bench-Lite benchmark, resolving 48.00\nof software bugs, outperforming 26 competitive systems. In a self-replication\ncase study, a GCC-augmented agent builds a new CLI agent from scratch,\nachieving 40.7 task resolution, compared to only 11.7 without GCC. The code is\nreleased at: https://github.com/theworldofagents/GCC", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGCC\u7684\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u7ba1\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u957f\u671f\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u957f\u671f\u4efb\u52a1\uff08\u5982\u5927\u578b\u8f6f\u4ef6\u5f00\u53d1\uff09\u4e2d\u7684\u90e8\u7f72\uff0c\u4e0a\u4e0b\u6587\u7ba1\u7406\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002", "method": "GCC\u6846\u67b6\u53d7\u8f6f\u4ef6\u7248\u672c\u63a7\u5236\u7cfb\u7edf\u542f\u53d1\uff0c\u5c06\u4ee3\u7406\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u7ed3\u6784\u5316\u4e3a\u7c7b\u4f3cGit\u7684\u7248\u672c\u5316\u5185\u5b58\u5c42\u6b21\uff0c\u652f\u6301COMMIT\u3001BRANCH\u3001MERGE\u548cCONTEXT\u7b49\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u914d\u5907GCC\u7684\u4ee3\u7406\u5728SWE-Bench-Lite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u89e3\u51b3\u4e8648.00%\u7684\u8f6f\u4ef6\u9519\u8bef\uff0c\u4f18\u4e8e26\u4e2a\u7ade\u4e89\u7cfb\u7edf\u3002\u5728\u81ea\u6211\u590d\u5236\u7684\u6848\u4f8b\u4e2d\uff0cGCC\u4ee3\u7406\u7684\u4efb\u52a1\u89e3\u51b3\u7387\u4e3a40.7%\uff0c\u8fdc\u9ad8\u4e8e\u672a\u4f7f\u7528GCC\u768411.7%\u3002", "conclusion": "GCC\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u5728\u957f\u671f\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u80fd\u529b\uff0c\u652f\u6301\u76ee\u6807\u7ba1\u7406\u3001\u5b9e\u9a8c\u9694\u79bb\u548c\u8de8\u4f1a\u8bdd\u5185\u5b58\u6062\u590d\u3002"}}
{"id": "2508.00033", "categories": ["cs.SE", "cs.AI", "cs.CL", "68T50", "I.2.2; I.2.7; D.2.3"], "pdf": "https://arxiv.org/pdf/2508.00033", "abs": "https://arxiv.org/abs/2508.00033", "authors": ["Nuno Fachada", "Daniel Fernandes", "Carlos M. Fernandes", "Bruno D. Ferreira-Saraiva", "Jo\u00e3o P. Matos-Carvalho"], "title": "GPT-4.1 Sets the Standard in Automated Experiment Design Using Novel Python Libraries", "comment": null, "summary": "Large Language Models (LLMs) have advanced rapidly as tools for automating\ncode generation in scientific research, yet their ability to interpret and use\nunfamiliar Python APIs for complex computational experiments remains poorly\ncharacterized. This study systematically benchmarks a selection of\nstate-of-the-art LLMs in generating functional Python code for two increasingly\nchallenging scenarios: conversational data analysis with the \\textit{ParShift}\nlibrary, and synthetic data generation and clustering using \\textit{pyclugen}\nand \\textit{scikit-learn}. Both experiments use structured, zero-shot prompts\nspecifying detailed requirements but omitting in-context examples. Model\noutputs are evaluated quantitatively for functional correctness and prompt\ncompliance over multiple runs, and qualitatively by analyzing the errors\nproduced when code execution fails. Results show that only a small subset of\nmodels consistently generate correct, executable code, with GPT-4.1 standing\nout as the only model to always succeed in both tasks. In addition to\nbenchmarking LLM performance, this approach helps identify shortcomings in\nthird-party libraries, such as unclear documentation or obscure implementation\nbugs. Overall, these findings highlight current limitations of LLMs for\nend-to-end scientific automation and emphasize the need for careful prompt\ndesign, comprehensive library documentation, and continued advances in language\nmodel capabilities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u529f\u80fd\u6027Python\u4ee3\u7801\u65f6\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4ec5\u6709\u5c11\u6570\u6a21\u578b\uff08\u5982GPT-4.1\uff09\u80fd\u7a33\u5b9a\u751f\u6210\u6b63\u786e\u4ee3\u7801\uff0c\u5e76\u63ed\u793a\u4e86\u7b2c\u4e09\u65b9\u5e93\u6587\u6863\u548c\u5b9e\u73b0\u7684\u4e0d\u8db3\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u751f\u6210\u590d\u6742\u79d1\u5b66\u5b9e\u9a8c\u4ee3\u7801\u65f6\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u4e0d\u719f\u6089\u7684Python API\u65f6\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u96f6\u6837\u672c\u63d0\u793a\u6d4b\u8bd5LLMs\u751f\u6210\u4ee3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u63d0\u793a\u7b26\u5408\u6027\uff0c\u5b9e\u9a8c\u5305\u62ec\u4f7f\u7528ParShift\u5e93\u7684\u5bf9\u8bdd\u6570\u636e\u5206\u6790\u548cpyclugen\u4e0escikit-learn\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u4e0e\u805a\u7c7b\u3002", "result": "\u4ec5\u5c11\u6570\u6a21\u578b\uff08\u5982GPT-4.1\uff09\u80fd\u7a33\u5b9a\u751f\u6210\u6b63\u786e\u4ee3\u7801\uff0c\u540c\u65f6\u53d1\u73b0\u4e86\u7b2c\u4e09\u65b9\u5e93\u7684\u6587\u6863\u548c\u5b9e\u73b0\u95ee\u9898\u3002", "conclusion": "LLMs\u5728\u7aef\u5230\u7aef\u79d1\u5b66\u81ea\u52a8\u5316\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u6539\u8fdb\u63d0\u793a\u8bbe\u8ba1\u3001\u5e93\u6587\u6863\u548c\u6a21\u578b\u80fd\u529b\u3002"}}
{"id": "2508.00045", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00045", "abs": "https://arxiv.org/abs/2508.00045", "authors": ["Samah Kansab"], "title": "Machine Learning Pipeline for Software Engineering: A Systematic Literature Review", "comment": null, "summary": "The rapid advancement of software development practices has introduced\nchallenges in ensuring quality and efficiency across the software engineering\n(SE) lifecycle. As SE systems grow in complexity, traditional approaches often\nfail to scale, resulting in longer debugging times, inefficient defect\ndetection, and resource-heavy development cycles. Machine Learning (ML) has\nemerged as a key solution, enabling automation in tasks such as defect\nprediction, code review, and release quality estimation. However, the\neffectiveness of ML in SE depends on the robustness of its pipeline, including\ndata collection, preprocessing, feature engineering, algorithm selection,\nvalidation, and evaluation.\n  This systematic literature review (SLR) examines state-of-the-art ML\npipelines designed for SE, consolidating best practices, challenges, and gaps.\nOur findings show that robust preprocessing, such as SMOTE for data balancing\nand SZZ-based algorithms for feature selection, improves model reliability.\nEnsemble methods like Random Forest and Gradient Boosting dominate performance\nacross tasks, while simpler models such as Naive Bayes remain valuable for\nefficiency and interpretability. Evaluation metrics including AUC, F1-score,\nand precision are most common, with new metrics like Best Arithmetic Mean (BAM)\nemerging in niche applications. Validation techniques such as bootstrapping are\nwidely used to ensure model stability and generalizability.\n  This SLR highlights the importance of well-designed ML pipelines for\naddressing SE challenges and provides actionable insights for researchers and\npractitioners seeking to optimize software quality and efficiency. By\nidentifying gaps and trends, this study sets a foundation for advancing ML\nadoption and fostering innovation in increasingly complex development\nenvironments.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff08SLR\uff09\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\uff08SE\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u603b\u7ed3\u4e86\u6700\u4f73\u5b9e\u8df5\u3001\u6311\u6218\u548c\u4e0d\u8db3\uff0c\u5f3a\u8c03\u4e86\u7a33\u5065\u7684ML\u6d41\u7a0b\u5bf9\u63d0\u5347\u8f6f\u4ef6\u8d28\u91cf\u548c\u6548\u7387\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u5f00\u53d1\u5468\u671f\u4e2d\u7684\u8d28\u91cf\u4e0e\u6548\u7387\u95ee\u9898\uff0cML\u88ab\u89c6\u4e3a\u5173\u952e\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7SLR\u5206\u6790ML\u6d41\u7a0b\uff08\u6570\u636e\u6536\u96c6\u3001\u9884\u5904\u7406\u3001\u7279\u5f81\u5de5\u7a0b\u7b49\uff09\uff0c\u8bc4\u4f30\u4e0d\u540c\u7b97\u6cd5\u548c\u9a8c\u8bc1\u6280\u672f\u3002", "result": "\u53d1\u73b0\u7a33\u5065\u9884\u5904\u7406\uff08\u5982SMOTE\u3001SZZ\uff09\u3001\u96c6\u6210\u65b9\u6cd5\uff08\u5982\u968f\u673a\u68ee\u6797\uff09\u548c\u9a8c\u8bc1\u6280\u672f\uff08\u5982\u81ea\u52a9\u6cd5\uff09\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u8bbe\u8ba1\u826f\u597d\u7684ML\u6d41\u7a0b\u5bf9\u89e3\u51b3SE\u6311\u6218\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u7814\u7a76\u4e0e\u5b9e\u8df5\u63d0\u4f9b\u4e86\u4f18\u5316\u65b9\u5411\uff0c\u5e76\u63a8\u52a8ML\u5728\u590d\u6742\u5f00\u53d1\u73af\u5883\u4e2d\u7684\u521b\u65b0\u3002"}}
{"id": "2508.00083", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00083", "abs": "https://arxiv.org/abs/2508.00083", "authors": ["Yihong Dong", "Xue Jiang", "Jiaru Qian", "Tian Wang", "Kechi Zhang", "Zhi Jin", "Ge Li"], "title": "A Survey on Code Generation with LLM-based Agents", "comment": "Work in progress", "summary": "Code generation agents powered by large language models (LLMs) are\nrevolutionizing the software development paradigm. Distinct from previous code\ngeneration techniques, code generation agents are characterized by three core\nfeatures. 1) Autonomy: the ability to independently manage the entire workflow,\nfrom task decomposition to coding and debugging. 2) Expanded task scope:\ncapabilities that extend beyond generating code snippets to encompass the full\nsoftware development lifecycle (SDLC). 3) Enhancement of engineering\npracticality: a shift in research emphasis from algorithmic innovation toward\npractical engineering challenges, such as system reliability, process\nmanagement, and tool integration. This domain has recently witnessed rapid\ndevelopment and an explosion in research, demonstrating significant application\npotential. This paper presents a systematic survey of the field of LLM-based\ncode generation agents. We trace the technology's developmental trajectory from\nits inception and systematically categorize its core techniques, including both\nsingle-agent and multi-agent architectures. Furthermore, this survey details\nthe applications of LLM-based agents across the full SDLC, summarizes\nmainstream evaluation benchmarks and metrics, and catalogs representative\ntools. Finally, by analyzing the primary challenges, we identify and propose\nseveral foundational, long-term research directions for the future work of the\nfield.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7801\u751f\u6210\u4ee3\u7406\uff0c\u63a2\u8ba8\u4e86\u5176\u81ea\u4e3b\u6027\u3001\u4efb\u52a1\u8303\u56f4\u6269\u5c55\u548c\u5de5\u7a0b\u5b9e\u7528\u6027\u589e\u5f3a\u4e09\u5927\u6838\u5fc3\u7279\u5f81\uff0c\u5e76\u603b\u7ed3\u4e86\u6280\u672f\u53d1\u5c55\u3001\u5e94\u7528\u3001\u8bc4\u4f30\u5de5\u5177\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7814\u7a76\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u751f\u6210\u4ee3\u7406\uff0c\u56e0\u5176\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\uff08SDLC\uff09\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u53ca\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u663e\u8457\u63d0\u5347\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u8c03\u67e5\u548c\u5206\u7c7b\u6280\u672f\u53d1\u5c55\u8f68\u8ff9\u3001\u6838\u5fc3\u67b6\u6784\uff08\u5355\u4ee3\u7406\u4e0e\u591a\u4ee3\u7406\uff09\u3001SDLC\u5e94\u7528\u3001\u8bc4\u4f30\u6307\u6807\u53ca\u5de5\u5177\u3002", "result": "\u603b\u7ed3\u4e86\u8be5\u9886\u57df\u7684\u5feb\u901f\u53d1\u5c55\u3001\u6838\u5fc3\u6280\u672f\u548c\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e3b\u6d41\u8bc4\u4f30\u65b9\u6cd5\u548c\u5de5\u5177\u3002", "conclusion": "\u5206\u6790\u4e86\u5f53\u524d\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u57fa\u7840\u6027\u3001\u957f\u671f\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.00293", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.00293", "abs": "https://arxiv.org/abs/2508.00293", "authors": ["Md Sajidul Islam Sajid", "Jinpeng Wei", "Ehab Al-Shaer"], "title": "ranDecepter: Real-time Identification and Deterrence of Ransomware Attacks", "comment": "Accepted at IEEE Conference on Communications and Network Security\n  (CNS) 2025", "summary": "Ransomware (RW) presents a significant and widespread threat in the digital\nlandscape, necessitating effective countermeasures. Active cyber deception is a\npromising strategy to thwart RW and limiting its propagation by misleading it\nwith false information and revealing its true behaviors. Furthermore, RW often\nacts as a communication conduit between attackers and defenders, allowing\ndeception to return false data to attackers and deplete their resources. This\npaper introduces ranDecepter, a novel approach that combines active cyber\ndeception with real-time analysis to enhance defenses against RW attacks. The\nranDecepter identifies RW in real-time and isolates it within a deceptive\nenvironment, autonomously identifying critical elements in the RW code to\ncreate a loop mechanism. By repeatedly restarting the malware and transmitting\ncounterfeit encryption information and secret keys to the attacker, it forces\nthe attacker to store these fabricated details for each victim, thereby\ndepleting their resources. Our comprehensive evaluation of ranDecepter,\nconducted using 1,134 real-world malware samples and twelve benign\napplications, demonstrates a remarkable 100% accuracy in RW identification,\nwith no false positives and minimal impact on response times. Furthermore,\nwithin 24-hours, ranDecepter generates up to 9,223K entries in the attacker's\ndatabase using 50 agents, showcasing its potential to undermine attacker\nresources.", "AI": {"tldr": "ranDecepter\u662f\u4e00\u79cd\u7ed3\u5408\u4e3b\u52a8\u7f51\u7edc\u6b3a\u9a97\u548c\u5b9e\u65f6\u5206\u6790\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u589e\u5f3a\u5bf9\u52d2\u7d22\u8f6f\u4ef6\u7684\u9632\u5fa1\uff0c\u901a\u8fc7\u8bef\u5bfc\u653b\u51fb\u8005\u5e76\u8017\u5c3d\u8d44\u6e90\u3002", "motivation": "\u52d2\u7d22\u8f6f\u4ef6\u5a01\u80c1\u65e5\u76ca\u4e25\u91cd\uff0c\u9700\u8981\u6709\u6548\u7684\u5bf9\u7b56\u3002\u4e3b\u52a8\u7f51\u7edc\u6b3a\u9a97\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u7b56\u7565\u3002", "method": "ranDecepter\u5b9e\u65f6\u8bc6\u522b\u52d2\u7d22\u8f6f\u4ef6\u5e76\u5c06\u5176\u9694\u79bb\u5728\u6b3a\u9a97\u73af\u5883\u4e2d\uff0c\u901a\u8fc7\u5faa\u73af\u673a\u5236\u4f2a\u9020\u52a0\u5bc6\u4fe1\u606f\u5e76\u8017\u5c3d\u653b\u51fb\u8005\u8d44\u6e90\u3002", "result": "\u6d4b\u8bd5\u663e\u793a100%\u7684\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u65e0\u5047\u9633\u6027\uff0c\u4e1424\u5c0f\u65f6\u5185\u751f\u6210\u5927\u91cf\u865a\u5047\u6761\u76ee\u4ee5\u6d88\u8017\u653b\u51fb\u8005\u8d44\u6e90\u3002", "conclusion": "ranDecepter\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u9632\u5fa1\u52d2\u7d22\u8f6f\u4ef6\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.00081", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00081", "abs": "https://arxiv.org/abs/2508.00081", "authors": ["Fred Mutisya", "Shikoh Gitau", "Nasubo Ongoma", "Keith Mbae", "Elizabeth Wamicha"], "title": "Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench", "comment": null, "summary": "HealthBench, a benchmark designed to measure the capabilities of AI systems\nfor health better (Arora et al., 2025), has advanced medical language model\nevaluation through physician-crafted dialogues and transparent rubrics.\nHowever, its reliance on expert opinion, rather than high-tier clinical\nevidence, risks codifying regional biases and individual clinician\nidiosyncrasies, further compounded by potential biases in automated grading\nsystems. These limitations are particularly magnified in low- and middle-income\nsettings, where issues like sparse neglected tropical disease coverage and\nregion-specific guideline mismatches are prevalent.\n  The unique challenges of the African context, including data scarcity,\ninadequate infrastructure, and nascent regulatory frameworks, underscore the\nurgent need for more globally relevant and equitable benchmarks. To address\nthese shortcomings, we propose anchoring reward functions in version-controlled\nClinical Practice Guidelines (CPGs) that incorporate systematic reviews and\nGRADE evidence ratings.\n  Our roadmap outlines \"evidence-robust\" reinforcement learning via\nrubric-to-guideline linkage, evidence-weighted scoring, and contextual override\nlogic, complemented by a focus on ethical considerations and the integration of\ndelayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,\nwhile preserving HealthBench's transparency and physician engagement, we aim to\nfoster medical language models that are not only linguistically polished but\nalso clinically trustworthy, ethically sound, and globally relevant.", "AI": {"tldr": "HealthBench\u8bc4\u4f30AI\u533b\u7597\u7cfb\u7edf\u80fd\u529b\uff0c\u4f46\u4f9d\u8d56\u4e13\u5bb6\u610f\u89c1\u53ef\u80fd\u5f15\u5165\u504f\u89c1\u3002\u63d0\u51fa\u57fa\u4e8e\u4e34\u5e8a\u6307\u5357\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u5168\u7403\u9002\u7528\u6027\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u89e3\u51b3HealthBench\u4f9d\u8d56\u4e13\u5bb6\u610f\u89c1\u5bfc\u81f4\u7684\u533a\u57df\u504f\u89c1\u548c\u4e34\u5e8a\u5dee\u5f02\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4f4e\u6536\u5165\u5730\u533a\u3002", "method": "\u901a\u8fc7\u7248\u672c\u63a7\u5236\u7684\u4e34\u5e8a\u5b9e\u8df5\u6307\u5357\uff08CPGs\uff09\u548cGRADE\u8bc1\u636e\u8bc4\u7ea7\uff0c\u8bbe\u8ba1\u8bc1\u636e\u7a33\u5065\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u7ed3\u5408\u900f\u660e\u5ea6\u548c\u4f26\u7406\u8003\u91cf\u7684\u6539\u8fdb\u65b9\u6848\uff0c\u65e8\u5728\u63d0\u5347\u6a21\u578b\u7684\u4e34\u5e8a\u53ef\u4fe1\u5ea6\u548c\u5168\u7403\u9002\u7528\u6027\u3002", "conclusion": "\u57fa\u4e8e\u4e25\u683c\u5ba1\u67e5\u7684CPGs\u6539\u8fdbHealthBench\uff0c\u53ef\u751f\u6210\u66f4\u53ef\u9760\u3001\u516c\u5e73\u4e14\u5168\u7403\u9002\u7528\u7684\u533b\u7597\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2508.00128", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00128", "abs": "https://arxiv.org/abs/2508.00128", "authors": ["Md Nazmul Haque", "Hua Yang", "Zhou Yang", "Bowen Xu"], "title": "How Quantization Impacts Privacy Risk on LLMs for Code?", "comment": null, "summary": "Large language models for code (LLMs4Code) rely heavily on massive training\ndata, including sensitive data, such as cloud service credentials of the\nprojects and personal identifiable information of the developers, raising\nserious privacy concerns. Membership inference (MI) has recently emerged as an\neffective tool for assessing privacy risk by identifying whether specific data\nbelong to a model's training set. In parallel, model compression techniques,\nespecially quantization, have gained traction for reducing computational costs\nand enabling the deployment of large models. However, while quantized models\nstill retain knowledge learned from the original training data, it remains\nunclear whether quantization affects their ability to retain and expose privacy\ninformation. Answering this question is of great importance to understanding\nprivacy risks in real-world deployments. In this work, we conduct the first\nempirical study on how quantization influences task performance and privacy\nrisk simultaneously in LLMs4Code. To do this, we implement widely used\nquantization techniques (static and dynamic) to three representative model\nfamilies, namely Pythia, CodeGen, and GPTNeo. Our results demonstrate that\nquantization has a significant impact on reducing the privacy risk relative to\nthe original model. We also uncover a positive correlation between task\nperformance and privacy risk, indicating an underlying tradeoff. Moreover, we\nreveal the possibility that quantizing larger models could yield better balance\nthan using full-precision small models. Finally, we demonstrate that these\nfindings generalize across different architectures, model sizes and MI methods,\noffering practical guidance for safeguarding privacy when deploying compressed\nLLMs4Code.", "AI": {"tldr": "\u91cf\u5316\u6280\u672f\u5bf9\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs4Code\uff09\u7684\u9690\u79c1\u98ce\u9669\u5f71\u54cd\u7814\u7a76\uff0c\u53d1\u73b0\u91cf\u5316\u80fd\u663e\u8457\u964d\u4f4e\u9690\u79c1\u98ce\u9669\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u4efb\u52a1\u6027\u80fd\u4e0e\u9690\u79c1\u98ce\u9669\u7684\u6b63\u76f8\u5173\u6027\u3002", "motivation": "\u91cf\u5316\u6280\u672f\u5e7f\u6cdb\u7528\u4e8e\u964d\u4f4e\u5927\u6a21\u578b\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u5176\u5bf9\u9690\u79c1\u98ce\u9669\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\uff0c\u5c24\u5176\u662f\u5728\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u3002", "method": "\u91c7\u7528\u9759\u6001\u548c\u52a8\u6001\u91cf\u5316\u6280\u672f\uff0c\u5bf9Pythia\u3001CodeGen\u548cGPTNeo\u4e09\u79cd\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u4efb\u52a1\u6027\u80fd\u548c\u9690\u79c1\u98ce\u9669\u3002", "result": "\u91cf\u5316\u663e\u8457\u964d\u4f4e\u4e86\u9690\u79c1\u98ce\u9669\uff0c\u4e14\u4efb\u52a1\u6027\u80fd\u4e0e\u9690\u79c1\u98ce\u9669\u5448\u6b63\u76f8\u5173\uff1b\u91cf\u5316\u5927\u6a21\u578b\u53ef\u80fd\u6bd4\u5c0f\u6a21\u578b\u66f4\u4f18\u3002", "conclusion": "\u91cf\u5316\u80fd\u6709\u6548\u5e73\u8861\u9690\u79c1\u98ce\u9669\u4e0e\u6027\u80fd\uff0c\u4e3a\u90e8\u7f72\u538b\u7f29\u540e\u7684\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2508.00351", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.00351", "abs": "https://arxiv.org/abs/2508.00351", "authors": ["Hyeonhak Kim", "Donghoe Heo", "Seokhie Hong"], "title": "Cryptanalysis of Isogeny-Based Quantum Money with Rational Points", "comment": null, "summary": "Quantum money is the cryptographic application of the quantum no-cloning\ntheorem. It has recently been instantiated by Montgomery and Sharif (Asiacrypt\n'24) from class group actions on elliptic curves. In this work, we propose a\nconcrete cryptanalysis by leveraging the efficiency of evaluating division\npolynomials with the coordinates of rational points, offering a speedup of\nO(log^4p) compared to the brute-force attack. Since our attack still requires\nexponential time, it remains impractical to forge a quantum banknote.\nInterestingly, due to the inherent properties of quantum money, our attack\nmethod also results in a more efficient verification procedure. Our algorithm\nleverages the properties of quadratic twists to utilize rational points in\nverifying the cardinality of the superposition of elliptic curves. We expect\nthis approach to contribute to future research on elliptic-curve-based quantum\ncryptography.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u692d\u5706\u66f2\u7ebf\u7c7b\u7fa4\u52a8\u4f5c\u7684\u91cf\u5b50\u8d27\u5e01\u7684\u5177\u4f53\u5bc6\u7801\u5206\u6790\uff0c\u901a\u8fc7\u5229\u7528\u6709\u7406\u70b9\u5750\u6807\u8ba1\u7b97\u9664\u6cd5\u591a\u9879\u5f0f\u7684\u9ad8\u6548\u6027\uff0c\u76f8\u6bd4\u66b4\u529b\u653b\u51fb\u5b9e\u73b0\u4e86O(log^4p)\u7684\u52a0\u901f\u3002\u5c3d\u7ba1\u653b\u51fb\u4ecd\u9700\u8981\u6307\u6570\u65f6\u95f4\uff0c\u4f46\u9a8c\u8bc1\u8fc7\u7a0b\u56e0\u6b64\u53d8\u5f97\u66f4\u9ad8\u6548\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u8d27\u5e01\u7684\u5b9e\u9645\u5b89\u5168\u6027\uff0c\u63a2\u7d22\u57fa\u4e8e\u692d\u5706\u66f2\u7ebf\u7684\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u6709\u7406\u70b9\u5750\u6807\u9ad8\u6548\u8ba1\u7b97\u9664\u6cd5\u591a\u9879\u5f0f\uff0c\u7ed3\u5408\u4e8c\u6b21\u626d\u66f2\u7684\u6027\u8d28\u9a8c\u8bc1\u692d\u5706\u66f2\u7ebf\u53e0\u52a0\u7684\u57fa\u6570\u3002", "result": "\u653b\u51fb\u65b9\u6cd5\u5b9e\u73b0\u4e86O(log^4p)\u7684\u52a0\u901f\uff0c\u4f46\u4ecd\u9700\u6307\u6570\u65f6\u95f4\uff0c\u65e0\u6cd5\u5b9e\u9645\u4f2a\u9020\u91cf\u5b50\u8d27\u5e01\u3002\u540c\u65f6\uff0c\u9a8c\u8bc1\u8fc7\u7a0b\u53d8\u5f97\u66f4\u9ad8\u6548\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u57fa\u4e8e\u692d\u5706\u66f2\u7ebf\u7684\u91cf\u5b50\u5bc6\u7801\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u672a\u6765\u53ef\u80fd\u63a8\u52a8\u76f8\u5173\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.00106", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.00106", "abs": "https://arxiv.org/abs/2508.00106", "authors": ["Ernest Bonnah", "Luan Viet Nguyen", "Khaza Anuarul Hoque"], "title": "Hyperproperty-Constrained Secure Reinforcement Learning", "comment": "Accepted in IEEE/ACM MEMOCODE 2025", "summary": "Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a\ndomain-specific formal specification language known for its effectiveness in\ncompactly representing security, opacity, and concurrency properties for\nrobotics applications. This paper focuses on HyperTWTL-constrained secure\nreinforcement learning (SecRL). Although temporal logic-constrained safe\nreinforcement learning (SRL) is an evolving research problem with several\nexisting literature, there is a significant research gap in exploring\nsecurity-aware reinforcement learning (RL) using hyperproperties. Given the\ndynamics of an agent as a Markov Decision Process (MDP) and opacity/security\nconstraints formalized as HyperTWTL, we propose an approach for learning\nsecurity-aware optimal policies using dynamic Boltzmann softmax RL while\nsatisfying the HyperTWTL constraints. The effectiveness and scalability of our\nproposed approach are demonstrated using a pick-up and delivery robotic mission\ncase study. We also compare our results with two other baseline RL algorithms,\nshowing that our proposed method outperforms them.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHyperTWTL\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08SecRL\uff09\uff0c\u901a\u8fc7\u52a8\u6001Boltzmann softmax RL\u5b66\u4e60\u6ee1\u8db3HyperTWTL\u7ea6\u675f\u7684\u5b89\u5168\u6700\u4f18\u7b56\u7565\uff0c\u5e76\u5728\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u65f6\u95f4\u903b\u8f91\u7ea6\u675f\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\uff08SRL\uff09\uff0c\u4f46\u7f3a\u4e4f\u57fa\u4e8e\u8d85\u5c5e\u6027\uff08hyperproperties\uff09\u7684\u5b89\u5168\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002HyperTWTL\u80fd\u6709\u6548\u8868\u793a\u5b89\u5168\u3001\u4e0d\u900f\u660e\u6027\u548c\u5e76\u53d1\u6027\uff0c\u56e0\u6b64\u63a2\u7d22\u5176\u5728SecRL\u4e2d\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5c06\u667a\u80fd\u4f53\u7684\u52a8\u6001\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\uff0c\u5e76\u5c06\u4e0d\u900f\u660e\u6027/\u5b89\u5168\u7ea6\u675f\u5f62\u5f0f\u5316\u4e3aHyperTWTL\uff0c\u63d0\u51fa\u4f7f\u7528\u52a8\u6001Boltzmann softmax RL\u5b66\u4e60\u6ee1\u8db3\u7ea6\u675f\u7684\u5b89\u5168\u6700\u4f18\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u673a\u5668\u4eba\u62fe\u53d6\u4e0e\u4ea4\u4ed8\u4efb\u52a1\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u4f18\u4e8e\u4e24\u79cd\u57fa\u7ebfRL\u7b97\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6ee1\u8db3HyperTWTL\u7ea6\u675f\u7684\u540c\u65f6\uff0c\u80fd\u591f\u5b66\u4e60\u5230\u5b89\u5168\u6700\u4f18\u7b56\u7565\uff0c\u4e3a\u5b89\u5168\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.00198", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00198", "abs": "https://arxiv.org/abs/2508.00198", "authors": ["Cleyton Magalhaes", "Italo Santos", "Brody Stuart-Verner", "Ronnie de Souza Santos"], "title": "Testing the Untestable? An Empirical Study on the Testing Process of LLM-Powered Software Systems", "comment": null, "summary": "Background: Software systems powered by large language models are becoming a\nroutine part of everyday technologies, supporting applications across a wide\nrange of domains. In software engineering, many studies have focused on how\nLLMs support tasks such as code generation, debugging, and documentation.\nHowever, there has been limited focus on how full systems that integrate LLMs\nare tested during development. Aims: This study explores how LLM-powered\nsystems are tested in the context of real-world application development.\nMethod: We conducted an exploratory case study using 99 individual reports\nwritten by students who built and deployed LLM-powered applications as part of\na university course. Each report was independently analyzed using thematic\nanalysis, supported by a structured coding process. Results: Testing strategies\ncombined manual and automated methods to evaluate both system logic and model\nbehavior. Common practices included exploratory testing, unit testing, and\nprompt iteration. Reported challenges included integration failures,\nunpredictable outputs, prompt sensitivity, hallucinations, and uncertainty\nabout correctness. Conclusions: Testing LLM-powered systems required\nadaptations to traditional verification methods, blending source-level\nreasoning with behavior-aware evaluations. These findings provide evidence on\nthe practical context of testing generative components in software systems.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u73b0\u5b9e\u5e94\u7528\u5f00\u53d1\u4e2d\u5982\u4f55\u6d4b\u8bd5\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7cfb\u7edf\uff0c\u53d1\u73b0\u6d4b\u8bd5\u7b56\u7565\u7ed3\u5408\u4e86\u624b\u52a8\u548c\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u5e76\u9762\u4e34\u6a21\u578b\u884c\u4e3a\u4e0d\u786e\u5b9a\u7b49\u6311\u6218\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5bf9\u5176\u96c6\u6210\u7cfb\u7edf\u7684\u6d4b\u8bd5\u65b9\u6cd5\u7814\u7a76\u6709\u9650\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5206\u679099\u4efd\u5b66\u751f\u62a5\u544a\uff0c\u91c7\u7528\u4e3b\u9898\u5206\u6790\u548c\u7ed3\u6784\u5316\u7f16\u7801\u8fdb\u884c\u63a2\u7d22\u6027\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u6d4b\u8bd5\u7b56\u7565\u5305\u62ec\u63a2\u7d22\u6027\u6d4b\u8bd5\u3001\u5355\u5143\u6d4b\u8bd5\u548c\u63d0\u793a\u8fed\u4ee3\uff0c\u6311\u6218\u5305\u62ec\u96c6\u6210\u5931\u8d25\u3001\u8f93\u51fa\u4e0d\u53ef\u9884\u6d4b\u7b49\u3002", "conclusion": "\u6d4b\u8bd5LLM\u7cfb\u7edf\u9700\u7ed3\u5408\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\u548c\u884c\u4e3a\u611f\u77e5\u8bc4\u4f30\uff0c\u4e3a\u751f\u6210\u7ec4\u4ef6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u5b9e\u8df5\u4f9d\u636e\u3002"}}
{"id": "2508.00368", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00368", "abs": "https://arxiv.org/abs/2508.00368", "authors": ["Alessandro Gaudenzi", "Lorenzo Nodari", "Lance Kaplan", "Alessandra Russo", "Murat Sensoy", "Federico Cerutti"], "title": "Preliminary Investigation into Uncertainty-Aware Attack Stage Classification", "comment": "Proceedings for SPAIML2025 workshop, 26/10/2025 Bologna Italy,\n  co-located with ECAI2025", "summary": "Advanced Persistent Threats (APTs) represent a significant challenge in\ncybersecurity due to their prolonged, multi-stage nature and the sophistication\nof their operators. Traditional detection systems typically focus on\nidentifying malicious activity in binary terms (benign or malicious) without\naccounting for the progression of an attack. However, effective response\nstrategies depend on accurate inference of the attack's current stage, as\ncountermeasures must be tailored to whether an adversary is in the early\nreconnaissance phase or actively conducting exploitation or exfiltration. This\nwork addresses the problem of attack stage inference under uncertainty, with a\nfocus on robustness to out-of-distribution (OOD) inputs. We propose a\nclassification approach based on Evidential Deep Learning (EDL), which models\npredictive uncertainty by outputting parameters of a Dirichlet distribution\nover possible stages. This allows the system not only to predict the most\nlikely stage of an attack but also to indicate when it is uncertain or the\ninput lies outside the training distribution. Preliminary experiments in a\nsimulated environment demonstrate that the proposed model can accurately infer\nthe stage of an attack with calibrated confidence while effectively detecting\nOOD inputs, which may indicate changes in the attackers' tactics. These results\nsupport the feasibility of deploying uncertainty-aware models for staged threat\ndetection in dynamic and adversarial environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bc1\u636e\u6df1\u5ea6\u5b66\u4e60\uff08EDL\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u63a8\u65ad\u9ad8\u7ea7\u6301\u7eed\u6027\u5a01\u80c1\uff08APT\uff09\u7684\u653b\u51fb\u9636\u6bb5\uff0c\u5e76\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u53ca\u5206\u5e03\u5916\u8f93\u5165\u3002", "motivation": "\u4f20\u7edf\u68c0\u6d4b\u7cfb\u7edf\u65e0\u6cd5\u51c6\u786e\u63a8\u65ad\u653b\u51fb\u9636\u6bb5\uff0c\u800c\u6709\u6548\u7684\u54cd\u5e94\u7b56\u7565\u9700\u8981\u6839\u636e\u653b\u51fb\u9636\u6bb5\u5b9a\u5236\u3002", "method": "\u91c7\u7528\u8bc1\u636e\u6df1\u5ea6\u5b66\u4e60\uff08EDL\uff09\uff0c\u901a\u8fc7\u8f93\u51faDirichlet\u5206\u5e03\u7684\u53c2\u6570\u6765\u5efa\u6a21\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u6a21\u578b\u80fd\u51c6\u786e\u63a8\u65ad\u653b\u51fb\u9636\u6bb5\u5e76\u68c0\u6d4b\u5206\u5e03\u5916\u8f93\u5165\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6a21\u578b\u5728\u52a8\u6001\u5bf9\u6297\u73af\u5883\u4e2d\u5177\u6709\u53ef\u884c\u6027\u3002"}}
{"id": "2508.00116", "categories": ["cs.AI", "H.4.1; I.2.1"], "pdf": "https://arxiv.org/pdf/2508.00116", "abs": "https://arxiv.org/abs/2508.00116", "authors": ["Wil M. P. van der Aalst"], "title": "No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence", "comment": "10 pages, 4 figures, preprint keynote paper of the seventh\n  International Conference on Intelligent and Fuzzy Systems (INFUS 2025)", "summary": "The uptake of Artificial Intelligence (AI) impacts the way we work, interact,\ndo business, and conduct research. However, organizations struggle to apply AI\nsuccessfully in industrial settings where the focus is on end-to-end\noperational processes. Here, we consider generative, predictive, and\nprescriptive AI and elaborate on the challenges of diagnosing and improving\nsuch processes. We show that AI needs to be grounded using Object-Centric\nProcess Mining (OCPM). Process-related data are structured and\norganization-specific and, unlike text, processes are often highly dynamic.\nOCPM is the missing link connecting data and processes and enables different\nforms of AI. We use the term Process Intelligence (PI) to refer to the\namalgamation of process-centric data-driven techniques able to deal with a\nvariety of object and event types, enabling AI in an organizational context.\nThis paper explains why AI requires PI to improve operational processes and\nhighlights opportunities for successfully combining OCPM and generative,\npredictive, and prescriptive AI.", "AI": {"tldr": "AI\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u5e94\u7528\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u7ed3\u5408\u5bf9\u8c61\u4e2d\u5fc3\u8fc7\u7a0b\u6316\u6398\uff08OCPM\uff09\u548c\u8fc7\u7a0b\u667a\u80fd\uff08PI\uff09\u6765\u63d0\u5347\u7aef\u5230\u7aef\u64cd\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u63a2\u8ba8AI\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u6210\u529f\u5e94\u7528\u7684\u6311\u6218\uff0c\u5f3a\u8c03\u8fc7\u7a0b\u667a\u80fd\uff08PI\uff09\u7684\u91cd\u8981\u6027\u3002", "method": "\u63d0\u51fa\u5bf9\u8c61\u4e2d\u5fc3\u8fc7\u7a0b\u6316\u6398\uff08OCPM\uff09\u4f5c\u4e3a\u8fde\u63a5\u6570\u636e\u548c\u8fc7\u7a0b\u7684\u6865\u6881\uff0c\u7ed3\u5408\u751f\u6210\u3001\u9884\u6d4b\u548c\u89c4\u8303\u6027AI\u3002", "result": "OCPM\u548cPI\u7684\u7ed3\u5408\u80fd\u6709\u6548\u63d0\u5347\u64cd\u4f5c\u6d41\u7a0b\uff0c\u4e3aAI\u5728\u7ec4\u7ec7\u73af\u5883\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u652f\u6301\u3002", "conclusion": "AI\u9700\u8981\u8fc7\u7a0b\u667a\u80fd\uff08PI\uff09\u548cOCPM\u7684\u7ed3\u5408\uff0c\u4ee5\u4f18\u5316\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u64cd\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2508.00244", "categories": ["cs.SE", "cs.PL", "D.3.2; D.2.11; D.2.13"], "pdf": "https://arxiv.org/pdf/2508.00244", "abs": "https://arxiv.org/abs/2508.00244", "authors": ["Briza Mel Dias de Sousa", "Renato Cordeiro Ferreira", "Alfredo Goldman"], "title": "Functional vs. Object-Oriented: Comparing How Programming Paradigms Affect the Architectural Characteristics of Systems", "comment": "11 pages, 16 figures (1 table, 3 diagrams, 5 graphics, 7 listings),\n  submitted to CTICQS capstone project competition at SBQS 2025", "summary": "After decades of dominance by object-oriented programming (OOP), functional\nprogramming (FP) is gaining increasing attention in the software industry. This\nstudy compares the impact of OOP and FP on the architectural characteristics of\nsoftware systems. For that, it examines the design and implementation of a\nDigital Wallet system, developed in Kotlin (representing OOP) and Scala\n(representing FP). The comparison is made through both qualitative and\nquantitative analyses to explore how each paradigm influences the system's\narchitectural characteristics. The self-ethnographic qualitative analysis\nprovides a side-by-side comparison of both implementations, revealing the\nperspective of those writing such code. The survey-based quantitative analysis\ngathers feedback from developers with diverse backgrounds, showing their\nimpressions of those reading this code. Hopefully, these results may be useful\nfor developers or organizations seeking to make more informed decisions about\nwhich paradigm is best suited for their next project.", "AI": {"tldr": "\u6bd4\u8f83\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\uff08OOP\uff09\u548c\u51fd\u6570\u5f0f\u7f16\u7a0b\uff08FP\uff09\u5bf9\u8f6f\u4ef6\u7cfb\u7edf\u67b6\u6784\u7279\u6027\u7684\u5f71\u54cd\uff0c\u901a\u8fc7Kotlin\uff08OOP\uff09\u548cScala\uff08FP\uff09\u5b9e\u73b0\u6570\u5b57\u94b1\u5305\u7cfb\u7edf\uff0c\u8fdb\u884c\u5b9a\u6027\u548c\u5b9a\u91cf\u5206\u6790\u3002", "motivation": "\u63a2\u8ba8OOP\u548cFP\u5728\u8f6f\u4ef6\u67b6\u6784\u4e2d\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u548c\u7ec4\u7ec7\u9009\u62e9\u66f4\u9002\u5408\u7684\u7f16\u7a0b\u8303\u5f0f\u3002", "method": "\u901a\u8fc7\u81ea\u6211\u6c11\u65cf\u5fd7\u5b9a\u6027\u5206\u6790\u548c\u57fa\u4e8e\u8c03\u67e5\u7684\u5b9a\u91cf\u5206\u6790\uff0c\u6bd4\u8f83Kotlin\uff08OOP\uff09\u548cScala\uff08FP\uff09\u5b9e\u73b0\u7684\u6570\u5b57\u94b1\u5305\u7cfb\u7edf\u3002", "result": "\u5b9a\u6027\u5206\u6790\u63ed\u793a\u4e86\u7f16\u5199\u4ee3\u7801\u7684\u89c6\u89d2\uff0c\u5b9a\u91cf\u5206\u6790\u6536\u96c6\u4e86\u5f00\u53d1\u8005\u5bf9\u4ee3\u7801\u7684\u53cd\u9988\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u53ef\u4e3a\u5f00\u53d1\u8005\u548c\u7ec4\u7ec7\u5728\u9009\u62e9\u7f16\u7a0b\u8303\u5f0f\u65f6\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2508.00434", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.00434", "abs": "https://arxiv.org/abs/2508.00434", "authors": ["Yuqi Qian", "Yun Cao", "Meiyang Lv", "Haocheng Fu"], "title": "Accurate Latent Inversion for Generative Image Steganography via Rectified Flow", "comment": null, "summary": "Steganography based on diffusion models has attracted increasing attention\ndue to its ability to generate high-quality images and exhibit strong\nrobustness. In such approaches, the secret message is first embedded into the\ninitial latent variable, and then the stego image is generated through the\nforward process. To extract the message, an inversion process is required to\nreconstruct the latent variables from the received image. However, inaccurate\nlatent inversion leads to significant discrepancies between the reconstructed\nand original latent variables, rendering message extraction infeasible. To\naddress this issue, we propose \\textbf{RF-Stego}, a novel generative image\nsteganography method that enables accurate latent inversion and significantly\nimproves extraction accuracy. First, we develop the \\textbf{P}ath\n\\textbf{C}onsistency \\textbf{L}inear \\textbf{I}nversion (\\textbf{PCLI}), which\nimposes formal constraints on the inversion process. By explicitly aligning it\nwith the forward generation path and modeling both directions along a shared\nlinear path, PCLI eliminates path mismatch and ensures path consistency\nthroughout the steganographic process. Second, through rigorous theoretical\nproof, we demonstrate that \\textbf{R}ectified \\textbf{F}low \\textbf{(RF)}\noffers both theoretical reversibility and numerical stability in the inversion\nprocess. Based on this, we replace traditional unstable samplers with RF\nsampler which effectively improves the numerical precision of the inversion\nprocess. Experimental results show RF-Stego outperforms state-of-the-art\nmethods in terms of extraction accuracy, image quality, robustness, security\nand generation efficiency.", "AI": {"tldr": "RF-Stego\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u56fe\u50cf\u9690\u5199\u65b9\u6cd5\uff0c\u901a\u8fc7\u8def\u5f84\u4e00\u81f4\u6027\u7ebf\u6027\u53cd\u8f6c\uff08PCLI\uff09\u548c\u4fee\u6b63\u6d41\uff08RF\uff09\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9690\u5199\u56fe\u50cf\u7684\u6d88\u606f\u63d0\u53d6\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u6269\u6563\u6a21\u578b\u9690\u5199\u65b9\u6cd5\u4e2d\uff0c\u6f5c\u5728\u53d8\u91cf\u53cd\u8f6c\u4e0d\u51c6\u786e\u5bfc\u81f4\u6d88\u606f\u63d0\u53d6\u5931\u8d25\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u786e\u4fdd\u8def\u5f84\u4e00\u81f4\u6027\u548c\u6570\u503c\u7a33\u5b9a\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPCLI\u6280\u672f\u786e\u4fdd\u53cd\u8f6c\u8def\u5f84\u4e0e\u751f\u6210\u8def\u5f84\u4e00\u81f4\uff0c\u5e76\u4f7f\u7528RF\u91c7\u6837\u5668\u66ff\u4ee3\u4f20\u7edf\u4e0d\u7a33\u5b9a\u91c7\u6837\u5668\u4ee5\u63d0\u9ad8\u6570\u503c\u7cbe\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRF-Stego\u5728\u63d0\u53d6\u51c6\u786e\u6027\u3001\u56fe\u50cf\u8d28\u91cf\u3001\u9c81\u68d2\u6027\u3001\u5b89\u5168\u6027\u548c\u751f\u6210\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "RF-Stego\u901a\u8fc7\u8def\u5f84\u4e00\u81f4\u6027\u548c\u6570\u503c\u7a33\u5b9a\u6027\u6539\u8fdb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9690\u5199\u6280\u672f\u7684\u6027\u80fd\u3002"}}
{"id": "2508.00129", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.00129", "abs": "https://arxiv.org/abs/2508.00129", "authors": ["Agust\u00edn Borda", "Juan Bautista Cabral", "Gonzalo Giarda", "Diego Nicol\u00e1s Gimenez Irusta", "Paula Pacheco", "Alvaro Roy Schachner"], "title": "Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis", "comment": null, "summary": "In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem\nthat can greatly affect the results of a Multi-Criteria Decision Method against\na particular set of alternatives. It is therefore useful to have a mechanism\nthat allows one to measure the performance of a method on a set of\nalternatives. This idea could be taken further to build a global ranking of the\neffectiveness of different methods to solve a problem. In this paper, we\npresent three tests that detect the presence of Rank Reversals, along with\ntheir implementation in the Scikit-Criteria library. We also address the\ncomplications that arise when implementing these tests for general scenarios\nand the design considerations we made to handle them. We close with a\ndiscussion about how these additions could play a major role in the judgment of\nmulti-criteria decision methods for problem solving.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u68c0\u6d4b\u591a\u51c6\u5219\u51b3\u7b56\u5206\u6790\u4e2d\u6392\u5e8f\u53cd\u8f6c\u95ee\u9898\u7684\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5e76\u5728Scikit-Criteria\u5e93\u4e2d\u5b9e\u73b0\uff0c\u8ba8\u8bba\u4e86\u901a\u7528\u573a\u666f\u4e0b\u7684\u5b9e\u73b0\u6311\u6218\u53ca\u8bbe\u8ba1\u8003\u91cf\u3002", "motivation": "\u6392\u5e8f\u53cd\u8f6c\u662f\u591a\u51c6\u5219\u51b3\u7b56\u5206\u6790\u4e2d\u7684\u4e25\u91cd\u95ee\u9898\uff0c\u5f71\u54cd\u51b3\u7b56\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u8bc4\u4f30\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u6d4b\u8bd5\u65b9\u6cd5\u68c0\u6d4b\u6392\u5e8f\u53cd\u8f6c\uff0c\u5e76\u5728Scikit-Criteria\u5e93\u4e2d\u5b9e\u73b0\uff0c\u89e3\u51b3\u901a\u7528\u573a\u666f\u4e0b\u7684\u5b9e\u73b0\u6311\u6218\u3002", "result": "\u5b9e\u73b0\u4e86\u4e09\u79cd\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5728\u901a\u7528\u573a\u666f\u4e2d\u7684\u5e94\u7528\u548c\u8bbe\u8ba1\u8003\u91cf\u3002", "conclusion": "\u8fd9\u4e9b\u6d4b\u8bd5\u65b9\u6cd5\u5728\u591a\u51c6\u5219\u51b3\u7b56\u65b9\u6cd5\u7684\u8bc4\u4f30\u4e2d\u53ef\u80fd\u53d1\u6325\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2508.00253", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00253", "abs": "https://arxiv.org/abs/2508.00253", "authors": ["Moumita Asad", "Rafed Muhammad Yasir", "Armin Geramirad", "Sam Malek"], "title": "Leveraging Large Language Model for Information Retrieval-based Bug Localization", "comment": null, "summary": "Information Retrieval-based Bug Localization aims to identify buggy source\nfiles for a given bug report. While existing approaches -- ranging from vector\nspace models to deep learning models -- have shown potential in this domain,\ntheir effectiveness is often limited by the vocabulary mismatch between bug\nreports and source code. To address this issue, we propose a novel Large\nLanguage Model (LLM) based bug localization approach, called GenLoc. Given a\nbug report, GenLoc leverages an LLM equipped with code-exploration functions to\niteratively analyze the code base and identify potential buggy files. To gather\nbetter context, GenLoc may optionally retrieve semantically relevant files\nusing vector embeddings. GenLoc has been evaluated on over 9,000 real-world bug\nreports from six large-scale Java projects. Experimental results show that\nGenLoc outperforms five state-of-the-art bug localization techniques across\nmultiple metrics, achieving an average improvement of more than 60\\% in\nAccuracy@1.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7f3a\u9677\u5b9a\u4f4d\u65b9\u6cd5GenLoc\uff0c\u901a\u8fc7\u4ee3\u7801\u63a2\u7d22\u529f\u80fd\u8fed\u4ee3\u5206\u6790\u4ee3\u7801\u5e93\uff0c\u89e3\u51b3\u4e86\u7f3a\u9677\u62a5\u544a\u4e0e\u6e90\u4ee3\u7801\u4e4b\u95f4\u7684\u8bcd\u6c47\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7f3a\u9677\u5b9a\u4f4d\u65b9\u6cd5\uff08\u4ece\u5411\u91cf\u7a7a\u95f4\u6a21\u578b\u5230\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff09\u56e0\u7f3a\u9677\u62a5\u544a\u4e0e\u6e90\u4ee3\u7801\u7684\u8bcd\u6c47\u4e0d\u5339\u914d\u95ee\u9898\u800c\u6548\u679c\u53d7\u9650\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faGenLoc\u65b9\u6cd5\uff0c\u5229\u7528\u5177\u5907\u4ee3\u7801\u63a2\u7d22\u529f\u80fd\u7684LLM\u8fed\u4ee3\u5206\u6790\u4ee3\u7801\u5e93\uff0c\u5e76\u53ef\u9009\u62e9\u6027\u5730\u901a\u8fc7\u5411\u91cf\u5d4c\u5165\u68c0\u7d22\u8bed\u4e49\u76f8\u5173\u6587\u4ef6\u4ee5\u83b7\u53d6\u4e0a\u4e0b\u6587\u3002", "result": "\u57286\u4e2a\u5927\u578bJava\u9879\u76ee\u76849000\u591a\u4e2a\u771f\u5b9e\u7f3a\u9677\u62a5\u544a\u4e0a\u6d4b\u8bd5\uff0cGenLoc\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e5\u79cd\u524d\u6cbf\u6280\u672f\uff0cAccuracy@1\u5e73\u5747\u63d0\u534760%\u4ee5\u4e0a\u3002", "conclusion": "GenLoc\u901a\u8fc7LLM\u548c\u4ee3\u7801\u63a2\u7d22\u529f\u80fd\u663e\u8457\u63d0\u5347\u4e86\u7f3a\u9677\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4e86\u8bcd\u6c47\u4e0d\u5339\u914d\u95ee\u9898\u3002"}}
{"id": "2508.00478", "categories": ["cs.CR", "cs.AI", "91A10, 91A43, 68T01, 94A60", "C.2.0; I.2.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2508.00478", "abs": "https://arxiv.org/abs/2508.00478", "authors": ["Yuning Jiang", "Nay Oo", "Qiaoran Meng", "Lu Lin", "Dusit Niyato", "Zehui Xiong", "Hoon Wei Lim", "Biplab Sikdar"], "title": "CyGATE: Game-Theoretic Cyber Attack-Defense Engine for Patch Strategy Optimization", "comment": null, "summary": "Modern cyber attacks unfold through multiple stages, requiring defenders to\ndynamically prioritize mitigations under uncertainty. While game-theoretic\nmodels capture attacker-defender interactions, existing approaches often rely\non static assumptions and lack integration with real-time threat intelligence,\nlimiting their adaptability. This paper presents CyGATE, a game-theoretic\nframework modeling attacker-defender interactions, using large language models\n(LLMs) with retrieval-augmented generation (RAG) to enhance tactic selection\nand patch prioritization. Applied to a two-agent scenario, CyGATE frames cyber\nconflicts as a partially observable stochastic game (POSG) across Cyber Kill\nChain stages. Both agents use belief states to navigate uncertainty, with the\nattacker adapting tactics and the defender re-prioritizing patches based on\nevolving risks and observed adversary behavior. The framework's flexible\narchitecture enables extension to multi-agent scenarios involving coordinated\nattackers, collaborative defenders, or complex enterprise environments with\nmultiple stakeholders. Evaluated in a dynamic patch scheduling scenario, CyGATE\neffectively prioritizes high-risk vulnerabilities, enhancing adaptability\nthrough dynamic threat integration, strategic foresight by anticipating\nattacker moves under uncertainty, and efficiency by optimizing resource use.", "AI": {"tldr": "CyGATE\u662f\u4e00\u4e2a\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4f18\u5316\u7f51\u7edc\u653b\u9632\u4e2d\u7684\u6218\u672f\u9009\u62e9\u548c\u8865\u4e01\u4f18\u5148\u7ea7\u3002", "motivation": "\u73b0\u6709\u535a\u5f08\u8bba\u6a21\u578b\u4f9d\u8d56\u9759\u6001\u5047\u8bbe\u4e14\u7f3a\u4e4f\u5b9e\u65f6\u5a01\u80c1\u60c5\u62a5\u6574\u5408\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u3002", "method": "\u5c06\u7f51\u7edc\u51b2\u7a81\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u5bdf\u968f\u673a\u535a\u5f08\uff08POSG\uff09\uff0c\u653b\u9632\u53cc\u65b9\u5229\u7528\u4fe1\u5ff5\u72b6\u6001\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728\u52a8\u6001\u8865\u4e01\u8c03\u5ea6\u573a\u666f\u4e2d\uff0cCyGATE\u6709\u6548\u4f18\u5148\u5904\u7406\u9ad8\u98ce\u9669\u6f0f\u6d1e\uff0c\u63d0\u5347\u9002\u5e94\u6027\u3001\u6218\u7565\u9884\u89c1\u6027\u548c\u8d44\u6e90\u6548\u7387\u3002", "conclusion": "CyGATE\u901a\u8fc7\u52a8\u6001\u5a01\u80c1\u6574\u5408\u548c\u591a\u667a\u80fd\u4f53\u6269\u5c55\u80fd\u529b\uff0c\u4e3a\u590d\u6742\u7f51\u7edc\u73af\u5883\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u9632\u5fa1\u6846\u67b6\u3002"}}
{"id": "2508.00137", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00137", "abs": "https://arxiv.org/abs/2508.00137", "authors": ["Shqiponja Ahmetaj", "George Konstantinidis", "Magdalena Ortiz", "Paolo Pareti", "Mantas Simkus"], "title": "SHACL Validation under Graph Updates (Extended Paper)", "comment": "Accepted at the International Semantic Web Conference (ISWC 2025)", "summary": "SHACL (SHApe Constraint Language) is a W3C standardized constraint language\nfor RDF graphs. In this paper, we study SHACL validation in RDF graphs under\nupdates. We present a SHACL-based update language that can capture intuitive\nand realistic modifications on RDF graphs and study the problem of static\nvalidation under such updates. This problem asks to verify whether every graph\nthat validates a SHACL specification will still do so after applying a given\nupdate sequence. More importantly, it provides a basis for further services for\nreasoning about evolving RDF graphs. Using a regression technique that embeds\nthe update actions into SHACL constraints, we show that static validation under\nupdates can be reduced to (un)satisfiability of constraints in (a minor\nextension of) SHACL. We analyze the computational complexity of the static\nvalidation problem for SHACL and some key fragments. Finally, we present a\nprototype implementation that performs static validation and other static\nanalysis tasks on SHACL constraints and demonstrate its behavior through\npreliminary experiments.", "AI": {"tldr": "\u7814\u7a76SHACL\u5728RDF\u56fe\u66f4\u65b0\u4e0b\u7684\u9a8c\u8bc1\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eSHACL\u7684\u66f4\u65b0\u8bed\u8a00\uff0c\u5e76\u901a\u8fc7\u56de\u5f52\u6280\u672f\u5c06\u9759\u6001\u9a8c\u8bc1\u95ee\u9898\u8f6c\u5316\u4e3aSHACL\u7ea6\u675f\u7684\uff08\u4e0d\uff09\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3RDF\u56fe\u5728\u66f4\u65b0\u540e\u4ecd\u6ee1\u8db3SHACL\u89c4\u8303\u7684\u9759\u6001\u9a8c\u8bc1\u95ee\u9898\uff0c\u4e3a\u6f14\u5316\u4e2d\u7684RDF\u56fe\u63d0\u4f9b\u63a8\u7406\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eSHACL\u7684\u66f4\u65b0\u8bed\u8a00\uff0c\u5229\u7528\u56de\u5f52\u6280\u672f\u5c06\u66f4\u65b0\u52a8\u4f5c\u5d4c\u5165SHACL\u7ea6\u675f\uff0c\u5206\u6790\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5e76\u5b9e\u73b0\u539f\u578b\u7cfb\u7edf\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5c55\u793a\u4e86\u9759\u6001\u9a8c\u8bc1\u95ee\u9898\u53ef\u8f6c\u5316\u4e3aSHACL\u7ea6\u675f\u7684\uff08\u4e0d\uff09\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\uff0c\u5206\u6790\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u539f\u578b\u7cfb\u7edf\u7684\u884c\u4e3a\u3002", "conclusion": "\u4e3aRDF\u56fe\u7684\u52a8\u6001\u6f14\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9759\u6001\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u53ef\u884c\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.00255", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00255", "abs": "https://arxiv.org/abs/2508.00255", "authors": ["Boqi Chen", "Ou Wei", "Bingzhou Zheng", "Gunter Mussbacher"], "title": "Accurate and Consistent Graph Model Generation from Text with Large Language Models", "comment": "Accepted at ACM / IEEE 28th International Conference on Model Driven\n  Engineering Languages and Systems (MODELS 2025)", "summary": "Graph model generation from natural language description is an important task\nwith many applications in software engineering. With the rise of large language\nmodels (LLMs), there is a growing interest in using LLMs for graph model\ngeneration. Nevertheless, LLM-based graph model generation typically produces\npartially correct models that suffer from three main issues: (1) syntax\nviolations: the generated model may not adhere to the syntax defined by its\nmetamodel, (2) constraint inconsistencies: the structure of the model might not\nconform to some domain-specific constraints, and (3) inaccuracy: due to the\ninherent uncertainty in LLMs, the models can include inaccurate, hallucinated\nelements. While the first issue is often addressed through techniques such as\nconstraint decoding or filtering, the latter two remain largely unaddressed.\nMotivated by recent self-consistency approaches in LLMs, we propose a novel\nabstraction-concretization framework that enhances the consistency and quality\nof generated graph models by considering multiple outputs from an LLM. Our\napproach first constructs a probabilistic partial model that aggregates all\ncandidate outputs and then refines this partial model into the most appropriate\nconcrete model that satisfies all constraints. We evaluate our framework on\nseveral popular open-source and closed-source LLMs using diverse datasets for\nmodel generation tasks. The results demonstrate that our approach significantly\nimproves both the consistency and quality of the generated graph models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62bd\u8c61-\u5177\u4f53\u5316\u6846\u67b6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u805a\u5408\u591a\u4e2aLLM\u8f93\u51fa\u6765\u63d0\u9ad8\u56fe\u6a21\u578b\u751f\u6210\u7684\u4e00\u81f4\u6027\u548c\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3LLM\u751f\u6210\u7684\u56fe\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u8bed\u6cd5\u8fdd\u89c4\u3001\u7ea6\u675f\u4e0d\u4e00\u81f4\u548c\u4e0d\u51c6\u786e\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u62bd\u8c61-\u5177\u4f53\u5316\u6846\u67b6\uff0c\u5148\u6784\u5efa\u6982\u7387\u6027\u90e8\u5206\u6a21\u578b\uff0c\u518d\u4f18\u5316\u4e3a\u6ee1\u8db3\u6240\u6709\u7ea6\u675f\u7684\u5177\u4f53\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u56fe\u6a21\u578b\u7684\u4e00\u81f4\u6027\u548c\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLM\u751f\u6210\u56fe\u6a21\u578b\u4e2d\u7684\u4e3b\u8981\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.00555", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00555", "abs": "https://arxiv.org/abs/2508.00555", "authors": ["Jiecong Wang", "Haoran Li", "Hao Peng", "Ziqian Zeng", "Zihao Wang", "Haohua Du", "Zhengtao Yu"], "title": "Activation-Guided Local Editing for Jailbreaking Attacks", "comment": null, "summary": "Jailbreaking is an essential adversarial technique for red-teaming these\nmodels to uncover and patch security flaws. However, existing jailbreak methods\nface significant drawbacks. Token-level jailbreak attacks often produce\nincoherent or unreadable inputs and exhibit poor transferability, while\nprompt-level attacks lack scalability and rely heavily on manual effort and\nhuman ingenuity. We propose a concise and effective two-stage framework that\ncombines the advantages of these approaches. The first stage performs a\nscenario-based generation of context and rephrases the original malicious query\nto obscure its harmful intent. The second stage then utilizes information from\nthe model's hidden states to guide fine-grained edits, effectively steering the\nmodel's internal representation of the input from a malicious toward a benign\none. Extensive experiments demonstrate that this method achieves\nstate-of-the-art Attack Success Rate, with gains of up to 37.74% over the\nstrongest baseline, and exhibits excellent transferability to black-box models.\nOur analysis further demonstrates that AGILE maintains substantial\neffectiveness against prominent defense mechanisms, highlighting the\nlimitations of current safeguards and providing valuable insights for future\ndefense development. Our code is available at\nhttps://github.com/yunsaijc/AGILE.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6846\u67b6AGILE\uff0c\u7ed3\u5408\u573a\u666f\u751f\u6210\u548c\u9690\u85cf\u72b6\u6001\u5f15\u5bfc\u7f16\u8f91\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u6210\u529f\u7387\u548c\u53ef\u8fc1\u79fb\u6027\u3002", "motivation": "\u73b0\u6709\u8d8a\u72f1\u65b9\u6cd5\u5b58\u5728\u8f93\u5165\u4e0d\u8fde\u8d2f\u3001\u53ef\u6269\u5c55\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u9996\u5148\u751f\u6210\u6a21\u7cca\u6076\u610f\u610f\u56fe\u7684\u4e0a\u4e0b\u6587\uff0c\u518d\u5229\u7528\u9690\u85cf\u72b6\u6001\u4fe1\u606f\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7f16\u8f91\u3002", "result": "\u653b\u51fb\u6210\u529f\u7387\u63d0\u534737.74%\uff0c\u5728\u9ed1\u76d2\u6a21\u578b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u5bf9\u9632\u5fa1\u673a\u5236\u6709\u6548\u3002", "conclusion": "AGILE\u63ed\u793a\u4e86\u5f53\u524d\u9632\u5fa1\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u9632\u5fa1\u5f00\u53d1\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2508.00138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00138", "abs": "https://arxiv.org/abs/2508.00138", "authors": ["Rashid Mushkani", "Hugo Berard", "Toumadher Ammar", "Cassandre Chatonnier", "Shin Koseki"], "title": "Co-Producing AI: Toward an Augmented, Participatory Lifecycle", "comment": "Eighth AAAI/ACM Conference on AI, Ethics, and Society 2025", "summary": "Despite efforts to mitigate the inherent risks and biases of artificial\nintelligence (AI) algorithms, these algorithms can disproportionately impact\nculturally marginalized groups. A range of approaches has been proposed to\naddress or reduce these risks, including the development of ethical guidelines\nand principles for responsible AI, as well as technical solutions that promote\nalgorithmic fairness. Drawing on design justice, expansive learning theory, and\nrecent empirical work on participatory AI, we argue that mitigating these harms\nrequires a fundamental re-architecture of the AI production pipeline. This\nre-design should center co-production, diversity, equity, inclusion (DEI), and\nmultidisciplinary collaboration. We introduce an augmented AI lifecycle\nconsisting of five interconnected phases: co-framing, co-design,\nco-implementation, co-deployment, and co-maintenance. The lifecycle is informed\nby four multidisciplinary workshops and grounded in themes of distributed\nauthority and iterative knowledge exchange. Finally, we relate the proposed\nlifecycle to several leading ethical frameworks and outline key research\nquestions that remain for scaling participatory governance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bbe\u8ba1\u6b63\u4e49\u3001\u6269\u5c55\u5b66\u4e60\u7406\u8bba\u548c\u53c2\u4e0e\u5f0fAI\u7684AI\u751f\u4ea7\u6d41\u7a0b\u91cd\u6784\u65b9\u6cd5\uff0c\u5f3a\u8c03\u5171\u751f\u4ea7\u3001\u591a\u6837\u6027\u3001\u516c\u5e73\u6027\u548c\u591a\u5b66\u79d1\u5408\u4f5c\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u52aa\u529b\u51cf\u5c11AI\u7b97\u6cd5\u7684\u98ce\u9669\u548c\u504f\u89c1\uff0c\u4f46\u5176\u4ecd\u5bf9\u6587\u5316\u8fb9\u7f18\u7fa4\u4f53\u9020\u6210\u4e0d\u6210\u6bd4\u4f8b\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u589e\u5f3a\u7684AI\u751f\u547d\u5468\u671f\uff0c\u5305\u542b\u4e94\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u9636\u6bb5\uff1a\u5171\u6846\u67b6\u3001\u5171\u8bbe\u8ba1\u3001\u5171\u5b9e\u65bd\u3001\u5171\u90e8\u7f72\u548c\u5171\u7ef4\u62a4\uff0c\u5e76\u901a\u8fc7\u591a\u5b66\u79d1\u7814\u8ba8\u4f1a\u9a8c\u8bc1\u3002", "result": "\u8be5\u751f\u547d\u5468\u671f\u7ed3\u5408\u4e86\u5206\u5e03\u5f0f\u6743\u5a01\u548c\u8fed\u4ee3\u77e5\u8bc6\u4ea4\u6362\u7684\u4e3b\u9898\uff0c\u5e76\u4e0e\u591a\u4e2a\u4f26\u7406\u6846\u67b6\u76f8\u5173\u8054\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u6269\u5c55\u53c2\u4e0e\u5f0f\u6cbb\u7406\uff0c\u89e3\u51b3\u5269\u4f59\u7684\u5173\u952e\u95ee\u9898\u3002"}}
{"id": "2508.00408", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00408", "abs": "https://arxiv.org/abs/2508.00408", "authors": ["Dong Huang", "Jie M. Zhang", "Mark Harman", "Qianru Zhang", "Mingzhe Du", "See-Kiong Ng"], "title": "Benchmarking LLMs for Unit Test Generation from Real-World Functions", "comment": "Under Review", "summary": "Recently, large language models (LLMs) have shown great promise in automating\nunit test generation, significantly reducing the manual effort required by\ndevelopers. To effectively evaluate the capabilities of LLMs in this domain, it\nis crucial to have a well-designed benchmark that accurately reflects\nreal-world scenarios and mitigates common pitfalls. Existing LLM test\ngeneration benchmarks are limited by two critical drawbacks: data contamination\nand structurally simple function code. As a result, we often cannot rely on the\nvalidity of scientific conclusions drawn from empirical studies using these\nlimited benchmarks. The empirical evidence presented may be biased due to\ncontamination and may fail to generalize beyond toy programs due to structural\nsimplicity.\n  To address these problems, we introduce ULT (UnLeakedTestbench), a new\nbenchmark specifically designed for function-level unit test generation from\nreal-world Python functions. ULT is constructed through a multi-stage curation\nprocess that ensures high cyclomatic complexity and mitigates test case\ncontamination. With 3,909 carefully selected function-level tasks, ULT provides\na more realistic and challenging evaluation of LLMs' test generation\ncapabilities. We also provide PLT (PreLeakedTestbench), a pair benchmark of ULT\nwith leaked tests designed to enable a controlled analysis of memorization\nversus reasoning in test generation. Our evaluation results demonstrate that\nULT is significantly more challenging. For example, test cases generated by\nLLMs only achieve 41.32\\%, 45.10\\%, 30.22\\%, and 40.21\\% for accuracy,\nstatement coverage, branch coverage, and mutation score on average for all\nLLMs, respectively. These results are substantially lower than the\ncorresponding metrics on TestEval (91.79\\%, 92.18\\%, 82.04\\%, and 49.69\\%) and\nPLT (47.07\\%, 55.13\\%, 40.07\\%, and 50.80\\%).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5ULT\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4e2d\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u6570\u636e\u6c61\u67d3\u548c\u7ed3\u6784\u7b80\u5355\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u6570\u636e\u6c61\u67d3\u548c\u7ed3\u6784\u7b80\u5355\u6027\u95ee\u9898\uff0c\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u4e0d\u53ef\u9760\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u573a\u666f\u3002", "method": "\u901a\u8fc7\u591a\u9636\u6bb5\u7b5b\u9009\u8fc7\u7a0b\u6784\u5efaULT\uff0c\u5305\u542b3,909\u4e2a\u9ad8\u590d\u6742\u5ea6\u7684Python\u51fd\u6570\u4efb\u52a1\uff0c\u5e76\u5f15\u5165PLT\u4f5c\u4e3a\u5bf9\u7167\u57fa\u51c6\u3002", "result": "ULT\u7684\u6d4b\u8bd5\u751f\u6210\u7ed3\u679c\uff08\u5982\u51c6\u786e\u738741.32%\uff09\u663e\u8457\u4f4e\u4e8e\u73b0\u6709\u57fa\u51c6\uff08\u5982TestEval\u768491.79%\uff09\uff0c\u8868\u660e\u5176\u66f4\u5177\u6311\u6218\u6027\u3002", "conclusion": "ULT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u771f\u5b9e\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8861\u91cfLLMs\u5728\u6d4b\u8bd5\u751f\u6210\u4e2d\u7684\u80fd\u529b\u3002"}}
{"id": "2508.00602", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00602", "abs": "https://arxiv.org/abs/2508.00602", "authors": ["Francesco Panebianco", "Stefano Bonfanti", "Francesco Trov\u00f2", "Michele Carminati"], "title": "LeakSealer: A Semisupervised Defense for LLMs Against Prompt Injection and Leakage Attacks", "comment": "22 pages, preprint", "summary": "The generalization capabilities of Large Language Models (LLMs) have led to\ntheir widespread deployment across various applications. However, this\nincreased adoption has introduced several security threats, notably in the\nforms of jailbreaking and data leakage attacks. Additionally, Retrieval\nAugmented Generation (RAG), while enhancing context-awareness in LLM responses,\nhas inadvertently introduced vulnerabilities that can result in the leakage of\nsensitive information. Our contributions are twofold. First, we introduce a\nmethodology to analyze historical interaction data from an LLM system, enabling\nthe generation of usage maps categorized by topics (including adversarial\ninteractions). This approach further provides forensic insights for tracking\nthe evolution of jailbreaking attack patterns. Second, we propose LeakSealer, a\nmodel-agnostic framework that combines static analysis for forensic insights\nwith dynamic defenses in a Human-In-The-Loop (HITL) pipeline. This technique\nidentifies topic groups and detects anomalous patterns, allowing for proactive\ndefense mechanisms. We empirically evaluate LeakSealer under two scenarios: (1)\njailbreak attempts, employing a public benchmark dataset, and (2) PII leakage,\nsupported by a curated dataset of labeled LLM interactions. In the static\nsetting, LeakSealer achieves the highest precision and recall on the ToxicChat\ndataset when identifying prompt injection. In the dynamic setting, PII leakage\ndetection achieves an AUPRC of $0.97$, significantly outperforming baselines\nsuch as Llama Guard.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86LLMs\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u63d0\u51fa\u4e86\u5206\u6790\u5386\u53f2\u4ea4\u4e92\u6570\u636e\u7684\u65b9\u6cd5\u548cLeakSealer\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u653b\u51fb\u6a21\u5f0f\u548c\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u3002", "motivation": "\u968f\u7740LLMs\u5e7f\u6cdb\u5e94\u7528\uff0c\u5b89\u5168\u95ee\u9898\u5982\u8d8a\u72f1\u653b\u51fb\u548c\u6570\u636e\u6cc4\u6f0f\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u6709\u6548\u7684\u9632\u5fa1\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5386\u53f2\u4ea4\u4e92\u6570\u636e\u7684\u5206\u6790\u65b9\u6cd5\u548cLeakSealer\u6846\u67b6\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u52a8\u6001\u9632\u5fa1\u3002", "result": "LeakSealer\u5728\u9759\u6001\u548c\u52a8\u6001\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728PII\u6cc4\u6f0f\u68c0\u6d4b\u4e2dAUPRC\u8fbe0.97\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u548c\u9632\u5fa1LLMs\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.00143", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.00143", "abs": "https://arxiv.org/abs/2508.00143", "authors": ["Danielle R. Thomas", "Conrad Borchers", "Kenneth R. Koedinger"], "title": "Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation", "comment": "Accepted for presentation at NCME AIME-Con 2025", "summary": "Humans can be notoriously imperfect evaluators. They are often biased,\nunreliable, and unfit to define \"ground truth.\" Yet, given the surging need to\nproduce large amounts of training data in educational applications using AI,\ntraditional inter-rater reliability (IRR) metrics like Cohen's kappa remain\ncentral to validating labeled data. IRR remains a cornerstone of many machine\nlearning pipelines for educational data. Take, for example, the classification\nof tutors' moves in dialogues or labeling open responses in machine-graded\nassessments. This position paper argues that overreliance on human IRR as a\ngatekeeper for annotation quality hampers progress in classifying data in ways\nthat are valid and predictive in relation to improving learning. To address\nthis issue, we highlight five examples of complementary evaluation methods,\nsuch as multi-label annotation schemes, expert-based approaches, and\nclose-the-loop validity. We argue that these approaches are in a better\nposition to produce training data and subsequent models that produce improved\nstudent learning and more actionable insights than IRR approaches alone. We\nalso emphasize the importance of external validity, for example, by\nestablishing a procedure of validating tutor moves and demonstrating that it\nworks across many categories of tutor actions (e.g., providing hints). We call\non the field to rethink annotation quality and ground truth--prioritizing\nvalidity and educational impact over consensus alone.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u4eba\u7c7b\u8bc4\u4f30\u8005\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u8fc7\u5ea6\u4f9d\u8d56\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\uff08\u5982IRR\uff09\u4f1a\u963b\u788d\u6559\u80b2\u6570\u636e\u5206\u7c7b\u7684\u8fdb\u5c55\uff0c\u5e76\u63a8\u8350\u4e94\u79cd\u8865\u5145\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u6570\u636e\u6807\u6ce8\u8d28\u91cf\u548c\u6a21\u578b\u6548\u679c\u3002", "motivation": "\u4eba\u7c7b\u8bc4\u4f30\u8005\u5b58\u5728\u504f\u89c1\u548c\u4e0d\u53ef\u9760\u6027\uff0c\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\uff08\u5982IRR\uff09\u65e0\u6cd5\u6ee1\u8db3\u6559\u80b2AI\u5bf9\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e94\u79cd\u8865\u5145\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5305\u62ec\u591a\u6807\u7b7e\u6807\u6ce8\u65b9\u6848\u3001\u4e13\u5bb6\u65b9\u6cd5\u548c\u95ed\u73af\u9a8c\u8bc1\u7b49\u3002", "result": "\u8fd9\u4e9b\u65b9\u6cd5\u80fd\u4ea7\u751f\u66f4\u6709\u6548\u7684\u8bad\u7ec3\u6570\u636e\u548c\u6a21\u578b\uff0c\u63d0\u5347\u5b66\u751f\u5b66\u4e60\u6548\u679c\u548c\u53ef\u64cd\u4f5c\u6027\u3002", "conclusion": "\u547c\u5401\u91cd\u65b0\u5b9a\u4e49\u6807\u6ce8\u8d28\u91cf\uff0c\u4f18\u5148\u8003\u8651\u6709\u6548\u6027\u548c\u6559\u80b2\u5f71\u54cd\uff0c\u800c\u975e\u4ec5\u4f9d\u8d56\u5171\u8bc6\u3002"}}
{"id": "2508.00462", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00462", "abs": "https://arxiv.org/abs/2508.00462", "authors": ["Linus Ververs", "Lutz Prechelt"], "title": "Managing Power Gaps as a Topic of Pair Programming Skill: A Grounded Theory", "comment": null, "summary": "Context: Pair Programming as a work mode is used (occasionally or frequently)\nthroughout professional software development. Objective: Understand what\npower-related phenomena occur in pair programming as it is used in industry;\ngive advice to practitioners on how to do better pair programming. Method:\nAnalyze 22 industrial pair programming sessions using Grounded Theory\nMethodology. Formulate a Grounded Theory on power-related behaviors. Run a\nsurvey with 292 participants about that theory. Use it to demonstrate that the\nphenomena are common. Results: Our theory describes the phenomenon of Power\nGap: a perceived difference in participation opportunities. The theory shows\nthe behaviors that create a Power Gap or result from it. Power Gaps tend to\ndamage knowledge transfer, code quality, and process effi ciency. The survey\nresults show that all concepts from our theory are frequent in practice. They\nalso provide more grounding for concepts that are observable only indirectly.\nConclusions: It is a valuable component of pair programming skill to be able to\navoid Power Gaps. Specifically, pair partners need to avoid Hierarchical\nBehavior (which tends to create or increase a Power Gap) and should perform\nenough Equalizing Behavior (which prevents or reduces a Power Gap).", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u7ed3\u5bf9\u7f16\u7a0b\u4e2d\u7684\u6743\u529b\u5dee\u8ddd\u73b0\u8c61\uff0c\u5206\u6790\u4e86\u5176\u5bf9\u77e5\u8bc6\u4f20\u9012\u3001\u4ee3\u7801\u8d28\u91cf\u548c\u6548\u7387\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u907f\u514d\u6743\u529b\u5dee\u8ddd\u7684\u5efa\u8bae\u3002", "motivation": "\u7406\u89e3\u7ed3\u5bf9\u7f16\u7a0b\u4e2d\u6743\u529b\u76f8\u5173\u73b0\u8c61\uff0c\u5e76\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u6539\u8fdb\u5efa\u8bae\u3002", "method": "\u901a\u8fc7\u624e\u6839\u7406\u8bba\u5206\u679022\u4e2a\u5de5\u4e1a\u7ed3\u5bf9\u7f16\u7a0b\u4f1a\u8bdd\uff0c\u5e76\u8c03\u67e5292\u540d\u53c2\u4e0e\u8005\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u63d0\u51fa\u4e86\u6743\u529b\u5dee\u8ddd\u7406\u8bba\uff0c\u8bc1\u660e\u5176\u666e\u904d\u5b58\u5728\u4e14\u5bf9\u7ed3\u5bf9\u7f16\u7a0b\u6709\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "\u907f\u514d\u6743\u529b\u5dee\u8ddd\u662f\u7ed3\u5bf9\u7f16\u7a0b\u6280\u80fd\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u5e94\u51cf\u5c11\u7b49\u7ea7\u884c\u4e3a\u5e76\u589e\u52a0\u5e73\u7b49\u884c\u4e3a\u3002"}}
{"id": "2508.00636", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.00636", "abs": "https://arxiv.org/abs/2508.00636", "authors": ["Haocheng Jiang", "Hua Shen", "Jixin Zhang", "Willy Susilo", "Mingwu Zhang"], "title": "FedGuard: A Diverse-Byzantine-Robust Mechanism for Federated Learning with Major Malicious Clients", "comment": null, "summary": "Federated learning is a distributed training framework vulnerable to\nByzantine attacks, particularly when over 50% of clients are malicious or when\ndatasets are highly non-independent and identically distributed (non-IID).\nAdditionally, most existing defense mechanisms are designed for specific attack\ntypes (e.g., gradient similarity-based schemes can only defend against outlier\nmodel poisoning), limiting their effectiveness. In response, we propose\nFedGuard, a novel federated learning mechanism. FedGuard cleverly addresses the\naforementioned issues by leveraging the high sensitivity of membership\ninference to model bias. By requiring clients to include an additional\nmini-batch of server-specified data in their training, FedGuard can identify\nand exclude poisoned models, as their confidence in the mini-batch will drop\nsignificantly. Our comprehensive evaluation unequivocally shows that, under\nthree highly non-IID datasets, with 90% of clients being Byzantine and seven\ndifferent types of Byzantine attacks occurring in each round, FedGuard\nsignificantly outperforms existing robust federated learning schemes in\nmitigating various types of Byzantine attacks.", "AI": {"tldr": "FedGuard\u662f\u4e00\u79cd\u65b0\u578b\u8054\u90a6\u5b66\u4e60\u673a\u5236\uff0c\u901a\u8fc7\u5229\u7528\u6210\u5458\u63a8\u7406\u5bf9\u6a21\u578b\u504f\u5dee\u7684\u9ad8\u654f\u611f\u6027\uff0c\u6709\u6548\u8bc6\u522b\u548c\u6392\u9664\u4e2d\u6bd2\u6a21\u578b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u65b9\u6848\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u6613\u53d7\u62dc\u5360\u5ead\u653b\u51fb\uff0c\u5c24\u5176\u5728\u591a\u6570\u5ba2\u6237\u7aef\u6076\u610f\u6216\u6570\u636e\u9ad8\u5ea6\u975e\u72ec\u7acb\u540c\u5206\u5e03\u65f6\uff0c\u73b0\u6709\u9632\u5fa1\u673a\u5236\u9488\u5bf9\u7279\u5b9a\u653b\u51fb\u7c7b\u578b\u6548\u679c\u6709\u9650\u3002", "method": "FedGuard\u8981\u6c42\u5ba2\u6237\u7aef\u5728\u8bad\u7ec3\u4e2d\u5305\u542b\u670d\u52a1\u5668\u6307\u5b9a\u7684\u989d\u5916\u5c0f\u6279\u91cf\u6570\u636e\uff0c\u5229\u7528\u6a21\u578b\u5bf9\u8fd9\u6279\u6570\u636e\u7684\u7f6e\u4fe1\u5ea6\u4e0b\u964d\u8bc6\u522b\u4e2d\u6bd2\u6a21\u578b\u3002", "result": "\u572890%\u5ba2\u6237\u7aef\u4e3a\u62dc\u5360\u5ead\u4e14\u6bcf\u8f6e\u53d1\u751f\u4e03\u79cd\u653b\u51fb\u7684\u9ad8\u5ea6\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u96c6\u4e0a\uff0cFedGuard\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "conclusion": "FedGuard\u901a\u8fc7\u521b\u65b0\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u62dc\u5360\u5ead\u653b\u51fb\u95ee\u9898\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2508.00159", "categories": ["cs.AI", "cs.CY", "cs.LG", "econ.TH", "math.OC", "68Txx", "I.2"], "pdf": "https://arxiv.org/pdf/2508.00159", "abs": "https://arxiv.org/abs/2508.00159", "authors": ["Jobst Heitzig", "Ram Potham"], "title": "Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power", "comment": null, "summary": "Power is a key concept in AI safety: power-seeking as an instrumental goal,\nsudden or gradual disempowerment of humans, power balance in human-AI\ninteraction and international AI governance. At the same time, power as the\nability to pursue diverse goals is essential for wellbeing.\n  This paper explores the idea of promoting both safety and wellbeing by\nforcing AI agents explicitly to empower humans and to manage the power balance\nbetween humans and AI agents in a desirable way. Using a principled, partially\naxiomatic approach, we design a parametrizable and decomposable objective\nfunction that represents an inequality- and risk-averse long-term aggregate of\nhuman power. It takes into account humans' bounded rationality and social\nnorms, and, crucially, considers a wide variety of possible human goals.\n  We derive algorithms for computing that metric by backward induction or\napproximating it via a form of multi-agent reinforcement learning from a given\nworld model. We exemplify the consequences of (softly) maximizing this metric\nin a variety of paradigmatic situations and describe what instrumental\nsub-goals it will likely imply. Our cautious assessment is that softly\nmaximizing suitable aggregate metrics of human power might constitute a\nbeneficial objective for agentic AI systems that is safer than direct\nutility-based objectives.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u901a\u8fc7\u8bbe\u8ba1\u4e00\u79cd\u76ee\u6807\u51fd\u6570\uff0c\u660e\u786e\u8981\u6c42AI\u589e\u5f3a\u4eba\u7c7b\u80fd\u529b\u5e76\u7ba1\u7406\u4eba\u7c7b\u4e0eAI\u4e4b\u95f4\u7684\u6743\u529b\u5e73\u8861\uff0c\u4ee5\u4fc3\u8fdb\u5b89\u5168\u548c\u798f\u7949\u3002", "motivation": "\u7814\u7a76AI\u5b89\u5168\u6027\u4e2d\u7684\u6743\u529b\u6982\u5ff5\uff0c\u63d0\u51fa\u901a\u8fc7\u660e\u786e\u76ee\u6807\u51fd\u6570\u6765\u5e73\u8861\u4eba\u7c7b\u4e0eAI\u7684\u6743\u529b\uff0c\u4ee5\u63d0\u5347\u5b89\u5168\u548c\u4eba\u7c7b\u798f\u7949\u3002", "method": "\u91c7\u7528\u90e8\u5206\u516c\u7406\u5316\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u53ef\u53c2\u6570\u5316\u548c\u5206\u89e3\u7684\u76ee\u6807\u51fd\u6570\uff0c\u8003\u8651\u4eba\u7c7b\u6709\u9650\u7406\u6027\u548c\u793e\u4f1a\u89c4\u8303\uff0c\u5e76\u901a\u8fc7\u9006\u5411\u5f52\u7eb3\u6216\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8ba1\u7b97\u8be5\u6307\u6807\u3002", "result": "\u5728\u591a\u79cd\u5178\u578b\u60c5\u5883\u4e2d\u5c55\u793a\u4e86\u8be5\u6307\u6807\u7684\u6548\u679c\uff0c\u8868\u660e\u8f6f\u6700\u5927\u5316\u4eba\u7c7b\u6743\u529b\u6307\u6807\u53ef\u80fd\u6bd4\u76f4\u63a5\u57fa\u4e8e\u6548\u7528\u7684\u76ee\u6807\u66f4\u5b89\u5168\u3002", "conclusion": "\u8f6f\u6700\u5927\u5316\u9002\u5408\u7684\u4eba\u7c7b\u6743\u529b\u6307\u6807\u53ef\u80fd\u662fAI\u7cfb\u7edf\u7684\u6709\u76ca\u76ee\u6807\uff0c\u6bd4\u76f4\u63a5\u6548\u7528\u76ee\u6807\u66f4\u5b89\u5168\u3002"}}
{"id": "2508.00508", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.00508", "abs": "https://arxiv.org/abs/2508.00508", "authors": ["Panagiotis Diamantakis", "Thanassis Avgerinos", "Yannis Smaragdakis"], "title": "Desyan: A Platform for Seamless Value-Flow and Symbolic Analysis", "comment": null, "summary": "Over the past two decades, two different types of static analyses have\nemerged as dominant paradigms both in academia and industry: value-flow\nanalysis (e.g., data-flow analysis or points-to analysis) and symbolic analysis\n(e.g., symbolic execution). Despite their individual successes in numerous\napplication fields, the two approaches have remained largely separate; an\nartifact of the simple reality that there is no broadly adopted unifying\nplatform for effortless and efficient integration of symbolic techniques with\nhigh-performance data-flow reasoning.\n  To bridge this gap, we introduce Desyan: a platform for writing program\nanalyses with seamless integration of value-flow and symbolic reasoning. Desyan\nexpands a production-ready Datalog fixpoint engine (Souffl\\'e) with\nfull-fledged SMT solving invoking industry-leading SMT engines. Desyan provides\nconstructs for automatically (and efficiently!) handling typical patterns that\ncome up in program analysis. At the same time, the integration is agnostic with\nrespect to the solving technology, and supports Datalog-native symbolic\nreasoning, via a bottom-up algebraic reasoning module.\n  The result is an engine that allows blending different kinds of reasoning, as\nneeded for the underlying analysis. For value-flow analysis, the engine is the\nbest-in-class Datalog evaluator (often by a factor of over 20x in execution\ntime); for applications that require full SMT (e.g., a concolic execution\nengine or other symbolic evaluator that needs to solve arbitrarily complex\nconditions), the engine is leveraging the leading SMT solvers; for lightweight\nsymbolic evaluation (e.g., solving simple conditionals in the context of a\npath-sensitive analysis), the engine can use Datalog-native symbolic reasoning,\nachieving large speedups (often of over 2x) compared to eagerly appealing to an\nSMT solver.", "AI": {"tldr": "Desyan\u5e73\u53f0\u65e0\u7f1d\u6574\u5408\u4e86\u503c\u6d41\u5206\u6790\u548c\u7b26\u53f7\u63a8\u7406\uff0c\u901a\u8fc7\u6269\u5c55Souffl\u00e9 Datalog\u5f15\u64ce\u5e76\u96c6\u6210SMT\u6c42\u89e3\u5668\uff0c\u4e3a\u7a0b\u5e8f\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5c3d\u7ba1\u503c\u6d41\u5206\u6790\u548c\u7b26\u53f7\u5206\u6790\u5728\u5404\u81ea\u9886\u57df\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u5e73\u53f0\u5b9e\u73b0\u4e24\u8005\u7684\u9ad8\u6548\u96c6\u6210\uff0cDesyan\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "Desyan\u6269\u5c55\u4e86Souffl\u00e9 Datalog\u5f15\u64ce\uff0c\u96c6\u6210SMT\u6c42\u89e3\u5668\uff0c\u652f\u6301\u81ea\u52a8\u5904\u7406\u7a0b\u5e8f\u5206\u6790\u4e2d\u7684\u5e38\u89c1\u6a21\u5f0f\uff0c\u5e76\u63d0\u4f9bDatalog\u539f\u751f\u7b26\u53f7\u63a8\u7406\u6a21\u5757\u3002", "result": "Desyan\u5728\u503c\u6d41\u5206\u6790\u4e2d\u8868\u73b0\u5353\u8d8a\uff08\u901f\u5ea6\u63d0\u534720\u500d\u4ee5\u4e0a\uff09\uff0c\u5728\u9700\u8981SMT\u6c42\u89e3\u7684\u5e94\u7528\u4e2d\u5229\u7528\u9886\u5148\u7684SMT\u5f15\u64ce\uff0c\u800c\u5728\u8f7b\u91cf\u7ea7\u7b26\u53f7\u63a8\u7406\u4e2d\u901f\u5ea6\u63d0\u53472\u500d\u4ee5\u4e0a\u3002", "conclusion": "Desyan\u6210\u529f\u5b9e\u73b0\u4e86\u503c\u6d41\u548c\u7b26\u53f7\u63a8\u7406\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u4e3a\u7a0b\u5e8f\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00659", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00659", "abs": "https://arxiv.org/abs/2508.00659", "authors": ["Xinzhang Chen", "Hassan Ali", "Arash Shaghaghi", "Salil S. Kanhere", "Sanjay Jha"], "title": "Demo: TOSense -- What Did You Just Agree to?", "comment": "Accepted as a demonstration paper at IEEE LCN 2025", "summary": "Online services often require users to agree to lengthy and obscure Terms of\nService (ToS), leading to information asymmetry and legal risks. This paper\nproposes TOSense-a Chrome extension that allows users to ask questions about\nToS in natural language and get concise answers in real time. The system\ncombines (i) a crawler \"tos-crawl\" that automatically extracts ToS content, and\n(ii) a lightweight large language model pipeline: MiniLM for semantic retrieval\nand BART-encoder for answer relevance verification. To avoid expensive manual\nannotation, we present a novel Question Answering Evaluation Pipeline (QEP)\nthat generates synthetic questions and verifies the correctness of answers\nusing clustered topic matching. Experiments on five major platforms, Apple,\nGoogle, X (formerly Twitter), Microsoft, and Netflix, show the effectiveness of\nTOSense (with up to 44.5% accuracy) across varying number of topic clusters.\nDuring the demonstration, we will showcase TOSense in action. Attendees will be\nable to experience seamless extraction, interactive question answering, and\ninstant indexing of new sites.", "AI": {"tldr": "TOSense\u662f\u4e00\u4e2aChrome\u6269\u5c55\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u95ee\u7b54\u5e2e\u52a9\u7528\u6237\u7406\u89e3\u5197\u957f\u6666\u6da9\u7684\u670d\u52a1\u6761\u6b3e\uff08ToS\uff09\uff0c\u7ed3\u5408\u722c\u866b\u548c\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u5b9e\u65f6\u56de\u7b54\u3002", "motivation": "\u89e3\u51b3\u7528\u6237\u56e0ToS\u5197\u957f\u6666\u6da9\u5bfc\u81f4\u7684\u4fe1\u606f\u4e0d\u5bf9\u79f0\u548c\u6cd5\u5f8b\u98ce\u9669\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u722c\u866b\uff08tos-crawl\uff09\u63d0\u53d6ToS\u5185\u5bb9\uff0c\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\uff08MiniLM\u548cBART-encoder\uff09\u5b9e\u73b0\u95ee\u7b54\u548c\u7b54\u6848\u9a8c\u8bc1\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u52a8\u8bc4\u4f30\u7ba1\u9053\uff08QEP\uff09\u3002", "result": "\u5728\u4e94\u5927\u5e73\u53f0\uff08Apple\u3001Google\u7b49\uff09\u4e0a\u6d4b\u8bd5\uff0c\u51c6\u786e\u7387\u6700\u9ad8\u8fbe44.5%\u3002", "conclusion": "TOSense\u6709\u6548\u5e2e\u52a9\u7528\u6237\u7406\u89e3ToS\uff0c\u5c55\u793a\u4e86\u5b9e\u65f6\u63d0\u53d6\u548c\u95ee\u7b54\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.00222", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00222", "abs": "https://arxiv.org/abs/2508.00222", "authors": ["Yihong Dong", "Xue Jiang", "Yongding Tao", "Huanyu Liu", "Kechi Zhang", "Lili Mou", "Rongyu Cao", "Yingwei Ma", "Jue Chen", "Binhua Li", "Zhi Jin", "Fei Huang", "Yongbin Li", "Ge Li"], "title": "RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization", "comment": null, "summary": "Reinforcement Learning with Verifiable Reward (RLVR) has significantly\nadvanced the complex reasoning abilities of Large Language Models (LLMs).\nHowever, it struggles to break through the inherent capability boundaries of\nthe base LLM, due to its inherently on-policy strategy with LLM's immense\naction space and sparse reward. Further, RLVR can lead to the capability\nboundary collapse, narrowing the LLM's problem-solving scope. To address this\nproblem, we propose RL-PLUS, a novel approach that synergizes internal\nexploitation (i.e., Thinking) with external data (i.e., Learning) to achieve\nstronger reasoning capabilities and surpass the boundaries of base models.\nRL-PLUS integrates two core components: Multiple Importance Sampling to address\nfor distributional mismatch from external data, and an Exploration-Based\nAdvantage Function to guide the model towards high-value, unexplored reasoning\npaths. We provide both theoretical analysis and extensive experiments to\ndemonstrate the superiority and generalizability of our approach. The results\nshow that RL-PLUS achieves state-of-the-art performance compared with existing\nRLVR methods on six math reasoning benchmarks and exhibits superior performance\non six out-of-distribution reasoning tasks. It also achieves consistent and\nsignificant gains across diverse model families, with average relative\nimprovements ranging from 21.1\\% to 69.2\\%. Moreover, Pass@k curves across\nmultiple benchmarks indicate that RL-PLUS effectively resolves the capability\nboundary collapse problem.", "AI": {"tldr": "RL-PLUS\u901a\u8fc7\u7ed3\u5408\u5185\u90e8\u63a8\u7406\u548c\u5916\u90e8\u6570\u636e\uff0c\u89e3\u51b3\u4e86RLVR\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "RLVR\u65b9\u6cd5\u56e0\u56fa\u6709\u7684\u7b56\u7565\u9650\u5236\u548c\u7a00\u758f\u5956\u52b1\uff0c\u96be\u4ee5\u7a81\u7834\u57fa\u7840LLM\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u751a\u81f3\u53ef\u80fd\u5bfc\u81f4\u80fd\u529b\u8fb9\u754c\u5d29\u6e83\u3002", "method": "RL-PLUS\u6574\u5408\u4e86\u591a\u91cd\u91cd\u8981\u6027\u91c7\u6837\u548c\u57fa\u4e8e\u63a2\u7d22\u7684\u4f18\u52bf\u51fd\u6570\uff0c\u4ee5\u5229\u7528\u5916\u90e8\u6570\u636e\u5e76\u5f15\u5bfc\u6a21\u578b\u63a2\u7d22\u9ad8\u4ef7\u503c\u8def\u5f84\u3002", "result": "\u5728\u516d\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u548c\u516d\u4e2a\u5206\u5e03\u5916\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cRL-PLUS\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u76f8\u5bf9\u63d0\u534721.1%\u81f369.2%\u3002", "conclusion": "RL-PLUS\u4e0d\u4ec5\u89e3\u51b3\u4e86\u80fd\u529b\u8fb9\u754c\u5d29\u6e83\u95ee\u9898\uff0c\u8fd8\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2508.00546", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00546", "abs": "https://arxiv.org/abs/2508.00546", "authors": ["Wenchao Gu", "Zongyi Lyu", "Yanlin Wang", "Hongyu Zhang", "Cuiyun Gao", "Michael R. Lyu"], "title": "SPENCER: Self-Adaptive Model Distillation for Efficient Code Retrieval", "comment": null, "summary": "Code retrieval aims to provide users with desired code snippets based on\nusers' natural language queries. With the development of deep learning\ntechnologies, adopting pre-trained models for this task has become mainstream.\nConsidering the retrieval efficiency, most of the previous approaches adopt a\ndual-encoder for this task, which encodes the description and code snippet into\nrepresentation vectors, respectively. However, the model structure of the\ndual-encoder tends to limit the model's performance, since it lacks the\ninteraction between the code snippet and description at the bottom layer of the\nmodel during training. To improve the model's effectiveness while preserving\nits efficiency, we propose a framework, which adopts Self-AdaPtive Model\nDistillation for Efficient CodE Retrieval, named SPENCER. SPENCER first adopts\nthe dual-encoder to narrow the search space and then adopts the cross-encoder\nto improve accuracy. To improve the efficiency of SPENCER, we propose a novel\nmodel distillation technique, which can greatly reduce the inference time of\nthe dual-encoder while maintaining the overall performance. We also propose a\nteaching assistant selection strategy for our model distillation, which can\nadaptively select the suitable teaching assistant models for different\npre-trained models during the model distillation to ensure the model\nperformance. Extensive experiments demonstrate that the combination of\ndual-encoder and cross-encoder improves overall performance compared to solely\ndual-encoder-based models for code retrieval. Besides, our model distillation\ntechnique retains over 98% of the overall performance while reducing the\ninference time of the dual-encoder by 70%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPENCER\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u53cc\u7f16\u7801\u5668\u548c\u4ea4\u53c9\u7f16\u7801\u5668\u4ee5\u63d0\u9ad8\u4ee3\u7801\u68c0\u7d22\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u6a21\u578b\u84b8\u998f\u6280\u672f\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u53cc\u7f16\u7801\u5668\u6a21\u578b\u5728\u4ee3\u7801\u68c0\u7d22\u4efb\u52a1\u4e2d\u7f3a\u4e4f\u5e95\u5c42\u4ea4\u4e92\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3002", "method": "SPENCER\u7ed3\u5408\u53cc\u7f16\u7801\u5668\u548c\u4ea4\u53c9\u7f16\u7801\u5668\uff0c\u5e76\u63d0\u51fa\u81ea\u9002\u5e94\u6a21\u578b\u84b8\u998f\u6280\u672f\u548c\u6559\u5b66\u52a9\u7406\u9009\u62e9\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408\u53cc\u7f16\u7801\u5668\u548c\u4ea4\u53c9\u7f16\u7801\u5668\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u6a21\u578b\u84b8\u998f\u6280\u672f\u51cf\u5c11\u4e8670%\u63a8\u7406\u65f6\u95f4\u5e76\u4fdd\u755998%\u6027\u80fd\u3002", "conclusion": "SPENCER\u6846\u67b6\u5728\u4ee3\u7801\u68c0\u7d22\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e0e\u9ad8\u7cbe\u5ea6\u7684\u5e73\u8861\u3002"}}
{"id": "2508.00682", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00682", "abs": "https://arxiv.org/abs/2508.00682", "authors": ["Oscar Llorente-Vazquez", "Xabier Ugarte-Pedrero", "Igor Santos-Grueiro", "Pablo Garcia Bringas"], "title": "Unveiling Dynamic Binary Instrumentation Techniques", "comment": null, "summary": "Dynamic Binary Instrumentation (DBI) is the set of techniques that enable\ninstrumentation of programs at run-time, making it possible to monitor and\nmodify the execution of compiled binaries or entire systems. DBI is used for\ncountless security applications and analyses, and is extensively used across\nmany fields in both industry and academia. Over the years, several DBI\napproaches have been proposed based on different technologies and implementing\ndiverse techniques. Every solution tries to overcome certain limitations, but\nthey sometimes bring other shortcomings. Some are specialized for one\nparticular domain or task, while others have a wider scope.\n  In this paper, we shed light into the labyrinth of DBI, bringing together\nprocess-level and whole-system approaches. We depict their building blocks and\nanalyze the underlying instrumentation techniques, comparing their ability to\ninstrument different primitives and run-time events. Then, we evaluate their\nperformance when implementing each primitive, and highlight relevant\nobservations. Our results show that no single technique is better than the rest\nin all circumstances.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u52a8\u6001\u4e8c\u8fdb\u5236\u63d2\u6869\uff08DBI\uff09\u6280\u672f\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u6307\u51fa\u6ca1\u6709\u4e00\u79cd\u65b9\u6cd5\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u6700\u4f18\u3002", "motivation": "DBI\u6280\u672f\u5728\u5b89\u5168\u548c\u5206\u6790\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5404\u6709\u5c40\u9650\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u6bd4\u8f83\u548c\u8bc4\u4f30\u3002", "method": "\u7efc\u5408\u5206\u6790\u4e86\u8fdb\u7a0b\u7ea7\u548c\u5168\u7cfb\u7edf\u7ea7\u7684DBI\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u5176\u6784\u5efa\u6a21\u5757\u548c\u5e95\u5c42\u6280\u672f\uff0c\u5e76\u8bc4\u4f30\u4e86\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u4e0d\u540c\u65b9\u6cd5\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u8868\u73b0\u5404\u5f02\uff0c\u6ca1\u6709\u4e00\u79cd\u65b9\u6cd5\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u6700\u4f18\u3002", "conclusion": "DBI\u6280\u672f\u9700\u6839\u636e\u5177\u4f53\u9700\u6c42\u9009\u62e9\u5408\u9002\u65b9\u6cd5\uff0c\u672a\u6765\u7814\u7a76\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2508.00271", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.00271", "abs": "https://arxiv.org/abs/2508.00271", "authors": ["Hongjin Qian", "Zheng Liu"], "title": "MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning", "comment": "Technical Report, 14 pages", "summary": "In this work, we propose MetaAgent, an agentic paradigm inspired by the\nprinciple of learning-by-doing, where expertise is developed through hands-on\npractice and continual self-improvement. MetaAgent starts with a minimal\nworkflow, equipped only with basic reasoning and adaptive help-seeking\nabilities. When a knowledge gap is encountered, MetaAgent generates natural\nlanguage help requests, which are routed to the most suitable external tool by\na dedicated tool router. As MetaAgent solves tasks, it continually conducts\nself-reflection and answer verification, distilling actionable experience into\nconcise texts that are dynamically incorporated into future task contexts.\nBesides, MetaAgent autonomously builds in-house tools and a persistent\nknowledge base by organizing its tool-use history, further enhancing its\nability to retrieve and integrate relevant information We term this continual,\ndata-driven process as \\textit{meta tool learning}, through which MetaAgent\nincrementally refines its reasoning and tool-use strategies, without changing\nmodel parameters or requiring further post-training. Evaluated on challenging\nknowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,\nMetaAgent consistently outperforms workflow-based baselines and matches or\nexceeds end-to-end trained agents, demonstrating the promise of self-evolving\nagentic systems for robust, general-purpose knowledge discovery. We provide our\nsource codes in https://github.com/qhjqhj00/MetaAgent.", "AI": {"tldr": "MetaAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b66\u4e60\u5b9e\u8df5\u548c\u81ea\u6211\u6539\u8fdb\u7684\u667a\u80fd\u4ee3\u7406\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u6210\u5e2e\u52a9\u8bf7\u6c42\u3001\u81ea\u6211\u53cd\u601d\u548c\u77e5\u8bc6\u79ef\u7d2f\uff0c\u9010\u6b65\u63d0\u5347\u4efb\u52a1\u89e3\u51b3\u80fd\u529b\u3002", "motivation": "\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u901a\u8fc7\u5b9e\u8df5\u548c\u81ea\u6211\u6539\u8fdb\u4e0d\u65ad\u4f18\u5316\u4efb\u52a1\u89e3\u51b3\u80fd\u529b\u7684\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u3002", "method": "MetaAgent\u901a\u8fc7\u751f\u6210\u81ea\u7136\u8bed\u8a00\u5e2e\u52a9\u8bf7\u6c42\u3001\u81ea\u6211\u53cd\u601d\u548c\u9a8c\u8bc1\u7b54\u6848\uff0c\u52a8\u6001\u79ef\u7d2f\u7ecf\u9a8c\u5e76\u6784\u5efa\u5185\u90e8\u5de5\u5177\u548c\u77e5\u8bc6\u5e93\u3002", "result": "\u5728GAIA\u3001WebWalkerQA\u548cBrowseCamp\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e0e\u7aef\u5230\u7aef\u8bad\u7ec3\u7684\u4ee3\u7406\u76f8\u5f53\u6216\u66f4\u597d\u3002", "conclusion": "MetaAgent\u5c55\u793a\u4e86\u81ea\u6211\u8fdb\u5316\u4ee3\u7406\u7cfb\u7edf\u5728\u901a\u7528\u77e5\u8bc6\u53d1\u73b0\u4e2d\u7684\u6f5c\u529b\uff0c\u65e0\u9700\u8c03\u6574\u6a21\u578b\u53c2\u6570\u6216\u989d\u5916\u8bad\u7ec3\u3002"}}
{"id": "2508.00593", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00593", "abs": "https://arxiv.org/abs/2508.00593", "authors": ["Shuyao Jiang", "Jiazhen Gu", "Wujie Zheng", "Yangfan Zhou", "Michael R. Lyu"], "title": "Can User Feedback Help Issue Detection? An Empirical Study on a One-billion-user Online Service System", "comment": "Accepted by the 19th ACM/IEEE International Symposium on Empirical\n  Software Engineering and Measurement (ESEM 2025)", "summary": "Background: It has long been suggested that user feedback, typically written\nin natural language by end-users, can help issue detection. However, for\nlarge-scale online service systems that receive a tremendous amount of\nfeedback, it remains a challenging task to identify severe issues from user\nfeedback. Aims: To develop a better feedback-based issue detection approach, it\nis crucial first to gain a comprehensive understanding of the characteristics\nof user feedback in real production systems. Method: In this paper, we conduct\nan empirical study on 50,378,766 user feedback items from six real-world\nservices in a one-billion-user online service system. We first study what users\nprovide in their feedback. We then examine whether certain features of feedback\nitems can be good indicators of severe issues. Finally, we investigate whether\nadopting machine learning techniques to analyze user feedback is reasonable.\nResults: Our results show that a large proportion of user feedback provides\nirrelevant information about system issues. As a result, it is crucial to\nfilter out issue-irrelevant information when processing user feedback.\nMoreover, we find severe issues that cannot be easily detected based solely on\nuser feedback characteristics. Finally, we find that the distributions of the\nfeedback topics in different time intervals are similar. This confirms that\ndesigning machine learning-based approaches is a viable direction for better\nanalyzing user feedback. Conclusions: We consider that our findings can serve\nas an empirical foundation for feedback-based issue detection in large-scale\nservice systems, which sheds light on the design and implementation of\npractical issue detection approaches.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u5927\u89c4\u6a21\u5728\u7ebf\u670d\u52a1\u7cfb\u7edf\u4e2d\u7528\u6237\u53cd\u9988\u7684\u7279\u70b9\uff0c\u53d1\u73b0\u5927\u91cf\u53cd\u9988\u4e0e\u7cfb\u7edf\u95ee\u9898\u65e0\u5173\uff0c\u9700\u8fc7\u6ee4\uff1b\u4e25\u91cd\u95ee\u9898\u96be\u4ee5\u4ec5\u901a\u8fc7\u53cd\u9988\u7279\u5f81\u68c0\u6d4b\uff1b\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u884c\u3002", "motivation": "\u7406\u89e3\u7528\u6237\u53cd\u9988\u5728\u771f\u5b9e\u751f\u4ea7\u7cfb\u7edf\u4e2d\u7684\u7279\u70b9\uff0c\u4ee5\u6539\u8fdb\u57fa\u4e8e\u53cd\u9988\u7684\u95ee\u9898\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5bf9\u6765\u81ea\u516d\u4e2a\u771f\u5b9e\u670d\u52a1\u768450,378,766\u6761\u7528\u6237\u53cd\u9988\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u53cd\u9988\u5185\u5bb9\u3001\u7279\u5f81\u4e0e\u95ee\u9898\u5173\u8054\u6027\uff0c\u5e76\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u9002\u7528\u6027\u3002", "result": "\u5927\u91cf\u53cd\u9988\u4e0e\u95ee\u9898\u65e0\u5173\uff0c\u9700\u8fc7\u6ee4\uff1b\u4e25\u91cd\u95ee\u9898\u96be\u4ee5\u901a\u8fc7\u53cd\u9988\u7279\u5f81\u68c0\u6d4b\uff1b\u53cd\u9988\u4e3b\u9898\u5206\u5e03\u76f8\u4f3c\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u884c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5927\u89c4\u6a21\u670d\u52a1\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u53cd\u9988\u7684\u95ee\u9898\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u6307\u5bfc\u5b9e\u9645\u68c0\u6d4b\u65b9\u6cd5\u7684\u8bbe\u8ba1\u4e0e\u5b9e\u73b0\u3002"}}
{"id": "2508.00756", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.00756", "abs": "https://arxiv.org/abs/2508.00756", "authors": ["Yunhao Chen", "Shujie Wang", "Xin Wang", "Xingjun Ma"], "title": "LeakyCLIP: Extracting Training Data from CLIP", "comment": null, "summary": "Understanding the memorization and privacy leakage risks in Contrastive\nLanguage--Image Pretraining (CLIP) is critical for ensuring the security of\nmultimodal models. Recent studies have demonstrated the feasibility of\nextracting sensitive training examples from diffusion models, with conditional\ndiffusion models exhibiting a stronger tendency to memorize and leak\ninformation. In this work, we investigate data memorization and extraction\nrisks in CLIP through the lens of CLIP inversion, a process that aims to\nreconstruct training images from text prompts. To this end, we introduce\n\\textbf{LeakyCLIP}, a novel attack framework designed to achieve high-quality,\nsemantically accurate image reconstruction from CLIP embeddings. We identify\nthree key challenges in CLIP inversion: 1) non-robust features, 2) limited\nvisual semantics in text embeddings, and 3) low reconstruction fidelity. To\naddress these challenges, LeakyCLIP employs 1) adversarial fine-tuning to\nenhance optimization smoothness, 2) linear transformation-based embedding\nalignment, and 3) Stable Diffusion-based refinement to improve fidelity.\nEmpirical results demonstrate the superiority of LeakyCLIP, achieving over 358%\nimprovement in Structural Similarity Index Measure (SSIM) for ViT-B-16 compared\nto baseline methods on LAION-2B subset. Furthermore, we uncover a pervasive\nleakage risk, showing that training data membership can even be successfully\ninferred from the metrics of low-fidelity reconstructions. Our work introduces\na practical method for CLIP inversion while offering novel insights into the\nnature and scope of privacy risks in multimodal models.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86CLIP\u6a21\u578b\u4e2d\u7684\u6570\u636e\u8bb0\u5fc6\u548c\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u63d0\u51faLeakyCLIP\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7CLIP\u53cd\u6f14\u5b9e\u73b0\u9ad8\u8d28\u91cf\u56fe\u50cf\u91cd\u5efa\uff0c\u5e76\u63ed\u793a\u4e86\u591a\u6a21\u6001\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u7406\u89e3CLIP\u6a21\u578b\u4e2d\u7684\u8bb0\u5fc6\u548c\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u5bf9\u4fdd\u969c\u591a\u6a21\u6001\u6a21\u578b\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faLeakyCLIP\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u5fae\u8c03\u3001\u7ebf\u6027\u53d8\u6362\u5d4c\u5165\u5bf9\u9f50\u548cStable Diffusion\u7ec6\u5316\u89e3\u51b3CLIP\u53cd\u6f14\u4e2d\u7684\u4e09\u5927\u6311\u6218\u3002", "result": "LeakyCLIP\u5728ViT-B-16\u4e0a\u5b9e\u73b0\u4e86SSIM\u6307\u6807358%\u7684\u63d0\u5347\uff0c\u5e76\u63ed\u793a\u4e86\u4f4e\u8d28\u91cf\u91cd\u5efa\u4e2d\u4ecd\u5b58\u5728\u7684\u6570\u636e\u6cc4\u9732\u98ce\u9669\u3002", "conclusion": "LeakyCLIP\u4e3aCLIP\u53cd\u6f14\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u591a\u6a21\u6001\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\u8303\u56f4\u548c\u6027\u8d28\u3002"}}
{"id": "2508.00282", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00282", "abs": "https://arxiv.org/abs/2508.00282", "authors": ["Yi-Long Lu", "Jiajun Song", "Chunhui Zhang", "Wei Wang"], "title": "Mind the Gap: The Divergence Between Human and LLM-Generated Tasks", "comment": null, "summary": "Humans constantly generate a diverse range of tasks guided by internal\nmotivations. While generative agents powered by large language models (LLMs)\naim to simulate this complex behavior, it remains uncertain whether they\noperate on similar cognitive principles. To address this, we conducted a\ntask-generation experiment comparing human responses with those of an LLM agent\n(GPT-4o). We find that human task generation is consistently influenced by\npsychological drivers, including personal values (e.g., Openness to Change) and\ncognitive style. Even when these psychological drivers are explicitly provided\nto the LLM, it fails to reflect the corresponding behavioral patterns. They\nproduce tasks that are markedly less social, less physical, and thematically\nbiased toward abstraction. Interestingly, while the LLM's tasks were perceived\nas more fun and novel, this highlights a disconnect between its linguistic\nproficiency and its capacity to generate human-like, embodied goals.We conclude\nthat there is a core gap between the value-driven, embodied nature of human\ncognition and the statistical patterns of LLMs, highlighting the necessity of\nincorporating intrinsic motivation and physical grounding into the design of\nmore human-aligned agents.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u4eba\u7c7b\u548cLLM\uff08GPT-4o\uff09\u5728\u4efb\u52a1\u751f\u6210\u4e2d\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u4eba\u7c7b\u884c\u4e3a\u53d7\u5fc3\u7406\u9a71\u52a8\u56e0\u7d20\u5f71\u54cd\uff0c\u800cLLM\u672a\u80fd\u6a21\u62df\u8fd9\u4e9b\u6a21\u5f0f\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210\u5f0f\u4ee3\u7406\uff08\u5982LLM\uff09\u662f\u5426\u80fd\u6a21\u62df\u4eba\u7c7b\u57fa\u4e8e\u5185\u5728\u52a8\u673a\u7684\u4efb\u52a1\u751f\u6210\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u4efb\u52a1\u751f\u6210\u5b9e\u9a8c\u6bd4\u8f83\u4eba\u7c7b\u548cGPT-4o\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u5206\u6790\u5fc3\u7406\u9a71\u52a8\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "result": "\u4eba\u7c7b\u4efb\u52a1\u751f\u6210\u53d7\u5fc3\u7406\u9a71\u52a8\u56e0\u7d20\u5f71\u54cd\uff0c\u800cLLM\u751f\u6210\u7684\u4efb\u52a1\u66f4\u62bd\u8c61\u3001\u7f3a\u4e4f\u793e\u4ea4\u6027\u548c\u8eab\u4f53\u6d3b\u52a8\uff0c\u5c3d\u7ba1\u88ab\u8ba4\u4e3a\u66f4\u6709\u8da3\u548c\u65b0\u9896\u3002", "conclusion": "LLM\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u5b58\u5728\u6838\u5fc3\u5dee\u8ddd\uff0c\u9700\u6574\u5408\u5185\u5728\u52a8\u673a\u548c\u7269\u7406\u57fa\u7840\u4ee5\u8bbe\u8ba1\u66f4\u4eba\u6027\u5316\u7684\u4ee3\u7406\u3002"}}
{"id": "2508.00630", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00630", "abs": "https://arxiv.org/abs/2508.00630", "authors": ["Khaled Ahmed", "Jialing Song", "Boqi Chen", "Ou Wei", "Bingzhou Zheng"], "title": "MCeT: Behavioral Model Correctness Evaluation using Large Language Models", "comment": "MODELS 2025", "summary": "Behavioral model diagrams, e.g., sequence diagrams, are an essential form of\ndocumentation that are typically designed by system engineers from requirements\ndocumentation, either fully manually or assisted by design tools. With the\ngrowing use of Large Language Models (LLM) as AI modeling assistants, more\nautomation will be involved in generating diagrams. This necessitates the\nadvancement of automatic model correctness evaluation tools. Such a tool can be\nused to evaluate both manually and AI automatically generated models; to\nprovide feedback to system engineers, and enable AI assistants to self-evaluate\nand self-enhance their generated models.\n  In this paper, we propose MCeT, the first fully automated tool to evaluate\nthe correctness of a behavioral model, sequence diagrams in particular, against\nits corresponding requirements text and produce a list of issues that the model\nhas. We utilize LLMs for the correctness evaluation tasks as they have shown\noutstanding natural language understanding ability. However, we show that\ndirectly asking an LLM to compare a diagram to requirements finds less than 35%\nof issues that experienced engineers can find. We propose to supplement the\ndirect check with a fine-grained, multi-perspective approach; we split the\ndiagram into atomic, non-divisible interactions, and split the requirements\ntext into atomic, self-contained items. We compare the diagram with atomic\nrequirements and each diagram-atom with the requirements. We also propose a\nself-consistency checking approach that combines perspectives to mitigate LLM\nhallucinated issues. Our combined approach improves upon the precision of the\ndirect approach from 0.58 to 0.81 in a dataset of real requirements. Moreover,\nthe approach finds 90% more issues that the experienced engineers found than\nthe direct approach, and reports an average of 6 new issues per diagram.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMCeT\u5de5\u5177\uff0c\u5229\u7528LLM\u591a\u89d2\u5ea6\u8bc4\u4f30\u884c\u4e3a\u6a21\u578b\uff08\u5982\u5e8f\u5217\u56fe\uff09\u7684\u6b63\u786e\u6027\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5206\u6790\u548c\u81ea\u4e00\u81f4\u6027\u68c0\u67e5\u663e\u8457\u63d0\u5347\u95ee\u9898\u53d1\u73b0\u7387\u548c\u7cbe\u786e\u5ea6\u3002", "motivation": "\u968f\u7740LLM\u5728\u6a21\u578b\u751f\u6210\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u8bc4\u4f30\u6a21\u578b\u6b63\u786e\u6027\uff0c\u4e3a\u5de5\u7a0b\u5e08\u63d0\u4f9b\u53cd\u9988\u5e76\u5e2e\u52a9AI\u81ea\u6211\u4f18\u5316\u3002", "method": "\u5c06\u6a21\u578b\u548c\u9700\u6c42\u5206\u89e3\u4e3a\u539f\u5b50\u5355\u5143\uff0c\u591a\u89d2\u5ea6\u5bf9\u6bd4\u68c0\u67e5\uff0c\u5e76\u7ed3\u5408\u81ea\u4e00\u81f4\u6027\u68c0\u67e5\u51cf\u5c11LLM\u5e7b\u89c9\u95ee\u9898\u3002", "result": "MCeT\u5c06\u95ee\u9898\u53d1\u73b0\u7387\u63d0\u5347\u81f390%\uff0c\u7cbe\u786e\u5ea6\u4ece0.58\u63d0\u9ad8\u52300.81\uff0c\u5e73\u5747\u6bcf\u56fe\u53d1\u73b06\u4e2a\u65b0\u95ee\u9898\u3002", "conclusion": "MCeT\u4e3a\u884c\u4e3a\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u9ad8\u6548\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u663e\u8457\u4f18\u4e8e\u76f4\u63a5LLM\u68c0\u67e5\uff0c\u9002\u7528\u4e8e\u4eba\u5de5\u548cAI\u751f\u6210\u6a21\u578b\u3002"}}
{"id": "2508.00323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00323", "abs": "https://arxiv.org/abs/2508.00323", "authors": ["Jianyi Zhang", "Xu Ji", "Ziyin Zhou", "Yuchen Zhou", "Shubo Shi", "Haoyu Wu", "Zhen Li", "Shizhao Liu"], "title": "Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning", "comment": null, "summary": "Evaluating the performance of visual language models (VLMs) in graphic\nreasoning tasks has become an important research topic. However, VLMs still\nshow obvious deficiencies in simulating human-level graphic reasoning\ncapabilities, especially in complex graphic reasoning and abstract problem\nsolving, which are less studied and existing studies only focus on simple\ngraphics. To evaluate the performance of VLMs in complex graphic reasoning, we\npropose ReasonBench, the first evaluation benchmark focused on structured\ngraphic reasoning tasks, which includes 1,613 questions from real-world\nintelligence tests. ReasonBench covers reasoning dimensions related to\nlocation, attribute, quantity, and multi-element tasks, providing a\ncomprehensive evaluation of the performance of VLMs in spatial, relational, and\nabstract reasoning capabilities. We benchmark 11 mainstream VLMs (including\nclosed-source and open-source models) and reveal significant limitations of\ncurrent models. Based on these findings, we propose a dual optimization\nstrategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability\nof reasoning by decomposing layers, and ReasonTune enhances the task\nadaptability of model reasoning through training, all of which improves VLM\nperformance by 33.5\\%. All experimental data and code are in the repository:\nhttps://huggingface.co/datasets/cistine/ReasonBench.", "AI": {"tldr": "ReasonBench\u662f\u9996\u4e2a\u4e13\u6ce8\u4e8e\u7ed3\u6784\u5316\u56fe\u5f62\u63a8\u7406\u4efb\u52a1\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u590d\u6742\u56fe\u5f62\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u53cc\u91cd\u4f18\u5316\u7b56\u7565\u63d0\u5347\u6027\u80fd\u3002", "motivation": "VLMs\u5728\u6a21\u62df\u4eba\u7c7b\u56fe\u5f62\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u56fe\u5f62\u63a8\u7406\u548c\u62bd\u8c61\u95ee\u9898\u89e3\u51b3\u65b9\u9762\uff0c\u73b0\u6709\u7814\u7a76\u4ec5\u5173\u6ce8\u7b80\u5355\u56fe\u5f62\u3002", "method": "\u63d0\u51faReasonBench\u57fa\u51c6\uff0c\u5305\u542b1,613\u4e2a\u771f\u5b9e\u4e16\u754c\u667a\u529b\u6d4b\u8bd5\u95ee\u9898\uff0c\u6db5\u76d6\u4f4d\u7f6e\u3001\u5c5e\u6027\u3001\u6570\u91cf\u548c\u591a\u5143\u7d20\u4efb\u52a1\u7b49\u63a8\u7406\u7ef4\u5ea6\uff0c\u5e76\u8bc4\u4f3011\u79cd\u4e3b\u6d41VLMs\u3002\u63d0\u51fa\u53cc\u91cd\u4f18\u5316\u7b56\u7565\uff1aDiaCoT\u589e\u5f3a\u63a8\u7406\u53ef\u89e3\u91ca\u6027\uff0cReasonTune\u901a\u8fc7\u8bad\u7ec3\u63d0\u5347\u4efb\u52a1\u9002\u5e94\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5f53\u524dVLMs\u5728\u590d\u6742\u56fe\u5f62\u63a8\u7406\u4e2d\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u53cc\u91cd\u4f18\u5316\u7b56\u7565\u4f7fVLM\u6027\u80fd\u63d0\u534733.5%\u3002", "conclusion": "ReasonBench\u4e3a\u590d\u6742\u56fe\u5f62\u63a8\u7406\u63d0\u4f9b\u4e86\u5168\u9762\u8bc4\u4f30\u5de5\u5177\uff0c\u53cc\u91cd\u4f18\u5316\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86VLMs\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2508.00700", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00700", "abs": "https://arxiv.org/abs/2508.00700", "authors": ["Alfred Santa Molison", "Marcia Moraes", "Glaucia Melo", "Fabio Santos", "Wesley K. G. Assuncao"], "title": "Is LLM-Generated Code More Maintainable \\& Reliable than Human-Written Code?", "comment": "Accepted ESEM2025", "summary": "Background: The rise of Large Language Models (LLMs) in software development\nhas opened new possibilities for code generation. Despite the widespread use of\nthis technology, it remains unclear how well LLMs generate code solutions in\nterms of software quality and how they compare to human-written code. Aims:\nThis study compares the internal quality attributes of LLM-generated and\nhuman-written code. Method: Our empirical study integrates datasets of coding\ntasks, three LLM configurations (zero-shot, few-shot, and fine-tuning), and\nSonarQube to assess software quality. The dataset comprises Python code\nsolutions across three difficulty levels: introductory, interview, and\ncompetition. We analyzed key code quality metrics, including maintainability\nand reliability, and the estimated effort required to resolve code issues.\nResults: Our analysis shows that LLM-generated code has fewer bugs and requires\nless effort to fix them overall. Interestingly, fine-tuned models reduced the\nprevalence of high-severity issues, such as blocker and critical bugs, and\nshifted them to lower-severity categories, but decreased the model's\nperformance. In competition-level problems, the LLM solutions sometimes\nintroduce structural issues that are not present in human-written code.\nConclusion: Our findings provide valuable insights into the quality of\nLLM-generated code; however, the introduction of critical issues in more\ncomplex scenarios highlights the need for a systematic evaluation and\nvalidation of LLM solutions. Our work deepens the understanding of the\nstrengths and limitations of LLMs for code generation.", "AI": {"tldr": "\u6bd4\u8f83LLM\u751f\u6210\u4ee3\u7801\u4e0e\u4eba\u5de5\u7f16\u5199\u4ee3\u7801\u7684\u8d28\u91cf\uff0c\u53d1\u73b0LLM\u4ee3\u7801\u6574\u4f53\u7f3a\u9677\u8f83\u5c11\u4f46\u590d\u6742\u573a\u666f\u4e0b\u53ef\u80fd\u5f15\u5165\u4e25\u91cd\u95ee\u9898\u3002", "motivation": "\u7814\u7a76LLM\u751f\u6210\u4ee3\u7801\u5728\u8f6f\u4ef6\u8d28\u91cf\u65b9\u9762\u7684\u8868\u73b0\uff0c\u5e76\u4e0e\u4eba\u5de5\u7f16\u5199\u4ee3\u7801\u5bf9\u6bd4\u3002", "method": "\u7ed3\u5408\u6570\u636e\u96c6\u3001\u4e09\u79cdLLM\u914d\u7f6e\uff08\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u3001\u5fae\u8c03\uff09\u548cSonarQube\u5de5\u5177\u8bc4\u4f30\u4ee3\u7801\u8d28\u91cf\u3002", "result": "LLM\u751f\u6210\u4ee3\u7801\u7f3a\u9677\u8f83\u5c11\u4e14\u4fee\u590d\u6210\u672c\u4f4e\uff0c\u4f46\u5fae\u8c03\u6a21\u578b\u53ef\u80fd\u964d\u4f4e\u6027\u80fd\uff0c\u590d\u6742\u573a\u666f\u4e0b\u53ef\u80fd\u5f15\u5165\u7ed3\u6784\u6027\u95ee\u9898\u3002", "conclusion": "LLM\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u6574\u4f53\u8f83\u597d\uff0c\u4f46\u9700\u7cfb\u7edf\u8bc4\u4f30\u590d\u6742\u573a\u666f\u4e0b\u7684\u6f5c\u5728\u95ee\u9898\u3002"}}
{"id": "2508.00324", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00324", "abs": "https://arxiv.org/abs/2508.00324", "authors": ["Yeonjun In", "Wonjoong Kim", "Sangwu Park", "Chanyoung Park"], "title": "R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge", "comment": "under review", "summary": "Although large reasoning models (LRMs) have demonstrated impressive\ncapabilities on complex tasks, recent studies reveal that these models\nfrequently fulfill harmful user instructions, raising significant safety\nconcerns. In this paper, we investigate the underlying cause of LRM safety\nrisks and find that models already possess sufficient safety knowledge but fail\nto activate it during reasoning. Based on this insight, we propose R1-Act, a\nsimple and efficient post-training method that explicitly triggers safety\nknowledge through a structured reasoning process. R1-Act achieves strong safety\nimprovements while preserving reasoning performance, outperforming prior\nalignment methods. Notably, it requires only 1,000 training examples and 90\nminutes of training on a single RTX A6000 GPU. Extensive experiments across\nmultiple LRM backbones and sizes demonstrate the robustness, scalability, and\npractical efficiency of our approach.", "AI": {"tldr": "R1-Act\u662f\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u8fc7\u7a0b\u663e\u5f0f\u89e6\u53d1\u5b89\u5168\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5bb9\u6613\u6267\u884c\u6709\u5bb3\u6307\u4ee4\uff0c\u5f15\u53d1\u5b89\u5168\u9690\u60a3\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5df2\u5177\u5907\u8db3\u591f\u5b89\u5168\u77e5\u8bc6\uff0c\u4f46\u63a8\u7406\u65f6\u672a\u80fd\u6fc0\u6d3b\u3002", "method": "\u63d0\u51faR1-Act\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u663e\u5f0f\u89e6\u53d1\u5b89\u5168\u77e5\u8bc6\uff0c\u4ec5\u9700\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\u548c\u77ed\u65f6\u95f4\u8bad\u7ec3\u3002", "result": "R1-Act\u5728\u5b89\u5168\u6027\u548c\u63a8\u7406\u6027\u80fd\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\uff0c\u4e14\u5177\u6709\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "R1-Act\u662f\u4e00\u79cd\u9ad8\u6548\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347LRMs\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002"}}
{"id": "2508.00738", "categories": ["cs.SE", "cs.FL", "68N30", "D.2.4"], "pdf": "https://arxiv.org/pdf/2508.00738", "abs": "https://arxiv.org/abs/2508.00738", "authors": ["Bernhard Rumpe", "Max Stachon", "Sebastian St\u00fcber", "Valdes Voufo"], "title": "Tool-Assisted Conformance Checking to Reference Process Models", "comment": null, "summary": "Reference models convey best practices and standards. The reference\nframeworks necessitate conformance checks to ensure adherence to established\nguidelines and principles, which is crucial for maintaining quality and\nconsistency in various processes. This paper explores automated conformance\nchecks for concrete process models against reference models using causal\ndependency analysis of tasks and events. Existing notions of conformance\nchecking for process models focus on verifying process execution traces and\nlack the expressiveness and automation needed for semantic model comparison,\nleaving this question unresolved. We integrate our approach into a broader\nsemantic framework for defining reference model conformance. We outline an\nalgorithm for reference process model conformance checking, evaluate it through\na case study, and discuss its strengths and limitations. Our research provides\na tool-assisted solution enhancing accuracy and flexibility in process model\nconformance verification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u4f9d\u8d56\u5206\u6790\u7684\u81ea\u52a8\u5316\u4e00\u81f4\u6027\u68c0\u67e5\u65b9\u6cd5\uff0c\u7528\u4e8e\u9a8c\u8bc1\u5177\u4f53\u6d41\u7a0b\u6a21\u578b\u4e0e\u53c2\u8003\u6a21\u578b\u7684\u4e00\u81f4\u6027\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8bed\u4e49\u6a21\u578b\u6bd4\u8f83\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u4e00\u81f4\u6027\u68c0\u67e5\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6d41\u7a0b\u6267\u884c\u8f68\u8ff9\u7684\u9a8c\u8bc1\uff0c\u7f3a\u4e4f\u8bed\u4e49\u6a21\u578b\u6bd4\u8f83\u7684\u8868\u8fbe\u80fd\u529b\u548c\u81ea\u52a8\u5316\u652f\u6301\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u56e0\u679c\u4f9d\u8d56\u5206\u6790\u4efb\u52a1\u548c\u4e8b\u4ef6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u4e00\u4e2a\u66f4\u5e7f\u6cdb\u7684\u8bed\u4e49\u6846\u67b6\u4e2d\uff0c\u7528\u4e8e\u5b9a\u4e49\u53c2\u8003\u6a21\u578b\u7684\u4e00\u81f4\u6027\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u63d0\u9ad8\u6d41\u7a0b\u6a21\u578b\u4e00\u81f4\u6027\u9a8c\u8bc1\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u5de5\u5177\u8f85\u52a9\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u589e\u5f3a\u4e86\u6d41\u7a0b\u6a21\u578b\u4e00\u81f4\u6027\u9a8c\u8bc1\u7684\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\uff0c\u4f46\u4ecd\u5b58\u5728\u4e00\u4e9b\u5c40\u9650\u6027\u3002"}}
{"id": "2508.00378", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.00378", "abs": "https://arxiv.org/abs/2508.00378", "authors": ["Shixin Yi", "Lin Shang"], "title": "CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding", "comment": "Preparing for AAAI 2026, Multimodal Reasoning", "summary": "Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in\nvision-language models (VLMs), but it often produces explanations that are\nlinguistically fluent yet lack grounding in visual content. We observe that\nsuch hallucinations arise in part from the absence of an explicit verification\nmechanism during multi-step reasoning. To address this, we propose\n\\textbf{CoRGI}(\\textbf{C}hain \\textbf{o}f \\textbf{R}easoning with\n\\textbf{G}rounded \\textbf{I}nsights), a modular framework that introduces\nvisual verification into the reasoning process. CoRGI follows a three-stage\npipeline: it first generates a textual reasoning chain, then extracts\nsupporting visual evidence for each reasoning step via a dedicated module\n(VEVM), and finally synthesizes the textual rationale with visual evidence to\ngenerate a grounded, verified answer. The framework can be integrated with\nexisting VLMs without end-to-end retraining. We evaluate CoRGI on the VCR\nbenchmark and find that it improves reasoning performance on two representative\nopen-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm\nthe contribution of each step in the verification module, and human evaluations\nsuggest that CoRGI leads to more factual and helpful explanations. We also\nexamine alternative designs for the visual verification step and discuss\npotential limitations of post-hoc verification frameworks. These findings\nhighlight the importance of grounding intermediate reasoning steps in visual\nevidence to enhance the robustness of multimodal reasoning.", "AI": {"tldr": "CoRGI\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u89c6\u89c9\u9a8c\u8bc1\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u4e2d\u63a8\u7406\u94fe\u7f3a\u4e4f\u89c6\u89c9\u4f9d\u636e\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u591a\u6a21\u6001\u63a8\u7406\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709Chain-of-Thought\uff08CoT\uff09\u63d0\u793a\u65b9\u6cd5\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u751f\u6210\u7684\u89e3\u91ca\u867d\u7136\u8bed\u8a00\u6d41\u7545\uff0c\u4f46\u7f3a\u4e4f\u89c6\u89c9\u5185\u5bb9\u7684\u4f9d\u636e\uff0c\u5bfc\u81f4\u5e7b\u89c9\u95ee\u9898\u3002", "method": "CoRGI\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a\u751f\u6210\u6587\u672c\u63a8\u7406\u94fe\u3001\u901a\u8fc7\u4e13\u7528\u6a21\u5757\uff08VEVM\uff09\u63d0\u53d6\u89c6\u89c9\u8bc1\u636e\u3001\u7ed3\u5408\u6587\u672c\u548c\u89c6\u89c9\u8bc1\u636e\u751f\u6210\u9a8c\u8bc1\u540e\u7684\u7b54\u6848\u3002", "result": "\u5728VCR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCoRGI\u663e\u8457\u63d0\u5347\u4e86Qwen-2.5VL\u548cLLaVA-1.6\u4e24\u79cdVLM\u7684\u63a8\u7406\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5404\u6b65\u9aa4\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u89c6\u89c9\u9a8c\u8bc1\u5bf9\u63d0\u5347\u591a\u6a21\u6001\u63a8\u7406\u7684\u9c81\u68d2\u6027\u81f3\u5173\u91cd\u8981\uff0cCoRGI\u6846\u67b6\u4e3a\u73b0\u6709VLM\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u7aef\u5230\u7aef\u91cd\u65b0\u8bad\u7ec3\u7684\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2508.00749", "categories": ["cs.SE", "cs.FL", "cs.SC", "68N30", "D.2.4"], "pdf": "https://arxiv.org/pdf/2508.00749", "abs": "https://arxiv.org/abs/2508.00749", "authors": ["Johanna Grahl", "Bernhard Rumpe", "Max Stachon", "Sebastian St\u00fcber"], "title": "Dynamic Symbolic Execution for Semantic Difference Analysis of Component and Connector Architectures", "comment": null, "summary": "In the context of model-driven development, ensuring the correctness and\nconsistency of evolving models is paramount. This paper investigates the\napplication of Dynamic Symbolic Execution (DSE) for semantic difference\nanalysis of component-and-connector architectures, specifically utilizing\nMontiArc models. We have enhanced the existing MontiArc-to-Java generator to\ngather both symbolic and concrete execution data at runtime, encompassing\ntransition conditions, visited states, and internal variables of automata. This\ndata facilitates the identification of significant execution traces that\nprovide critical insights into system behavior. We evaluate various execution\nstrategies based on the criteria of runtime efficiency, minimality, and\ncompleteness, establishing a framework for assessing the applicability of DSE\nin semantic difference analysis. Our findings indicate that while DSE shows\npromise for analyzing component and connector architectures, scalability\nremains a primary limitation, suggesting further research is needed to enhance\nits practical utility in larger systems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u6a21\u578b\u9a71\u52a8\u5f00\u53d1\u4e2d\uff0c\u5229\u7528\u52a8\u6001\u7b26\u53f7\u6267\u884c\uff08DSE\uff09\u5206\u6790\u7ec4\u4ef6-\u8fde\u63a5\u5668\u67b6\u6784\u7684\u8bed\u4e49\u5dee\u5f02\uff0c\u91cd\u70b9\u5173\u6ce8MontiArc\u6a21\u578b\u3002\u901a\u8fc7\u589e\u5f3a\u73b0\u6709\u5de5\u5177\u6536\u96c6\u8fd0\u884c\u65f6\u6570\u636e\uff0c\u8bc4\u4f30\u6267\u884c\u7b56\u7565\uff0c\u53d1\u73b0DSE\u6f5c\u529b\u4f46\u5b58\u5728\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "motivation": "\u5728\u6a21\u578b\u9a71\u52a8\u5f00\u53d1\u4e2d\uff0c\u786e\u4fdd\u6a21\u578b\u6b63\u786e\u6027\u548c\u4e00\u81f4\u6027\u81f3\u5173\u91cd\u8981\uff0c\u9700\u6709\u6548\u5206\u6790\u8bed\u4e49\u5dee\u5f02\u3002", "method": "\u589e\u5f3aMontiArc-to-Java\u751f\u6210\u5668\uff0c\u6536\u96c6\u7b26\u53f7\u548c\u5177\u4f53\u6267\u884c\u6570\u636e\uff0c\u8bc4\u4f30\u4e0d\u540c\u6267\u884c\u7b56\u7565\u7684\u6548\u7387\u3001\u6700\u5c0f\u6027\u548c\u5b8c\u6574\u6027\u3002", "result": "DSE\u5728\u5206\u6790\u7ec4\u4ef6-\u8fde\u63a5\u5668\u67b6\u6784\u4e2d\u663e\u793a\u6f5c\u529b\uff0c\u4f46\u53ef\u6269\u5c55\u6027\u53d7\u9650\u3002", "conclusion": "DSE\u9002\u7528\u4e8e\u8bed\u4e49\u5dee\u5f02\u5206\u6790\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u5347\u5176\u5728\u5927\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.00401", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.00401", "abs": "https://arxiv.org/abs/2508.00401", "authors": ["Riddhi J. Pitliya", "Ozan Catal", "Toon Van de Maele", "Corrado Pezzato", "Tim Verbelen"], "title": "Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation", "comment": null, "summary": "We present a novel approach to multi-agent cooperation by implementing theory\nof mind (ToM) within active inference. ToM - the ability to understand that\nothers can have differing knowledge and goals - enables agents to reason about\nothers' beliefs while planning their own actions. Unlike previous active\ninference approaches to multi-agent cooperation, our method neither relies on\ntask-specific shared generative models nor requires explicit communication,\nwhile being generalisable. In our framework, the ToM-equipped agent maintains\ndistinct representations of its own and others' beliefs and goals. We extend\nthe sophisticated inference tree-based planning algorithm to systematically\nexplore joint policy spaces through recursive reasoning. Our approach is\nevaluated through collision avoidance and foraging task simulations. Results\ndemonstrate that ToM-equipped agents cooperate better compared to non-ToM\ncounterparts by being able to avoid collisions and reduce redundant efforts.\nCrucially, ToM agents accomplish this by inferring others' beliefs solely from\nobservable behaviour. This work advances practical applications in artificial\nintelligence while providing computational insights into ToM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fc3\u667a\u7406\u8bba\uff08ToM\uff09\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3b\u52a8\u63a8\u7406\u5b9e\u73b0\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u7684\u5171\u4eab\u751f\u6210\u6a21\u578b\u6216\u663e\u5f0f\u901a\u4fe1\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u5982\u4f55\u901a\u8fc7\u63a8\u7406\u4ed6\u4eba\u4fe1\u5ff5\u6765\u4f18\u5316\u81ea\u8eab\u884c\u4e3a\u7684\u95ee\u9898\uff0c\u907f\u514d\u4f9d\u8d56\u7279\u5b9a\u4efb\u52a1\u6a21\u578b\u6216\u901a\u4fe1\u3002", "method": "\u6269\u5c55\u4e86\u57fa\u4e8e\u63a8\u7406\u6811\u7684\u89c4\u5212\u7b97\u6cd5\uff0c\u901a\u8fc7\u9012\u5f52\u63a8\u7406\u63a2\u7d22\u8054\u5408\u7b56\u7565\u7a7a\u95f4\uff0c\u667a\u80fd\u4f53\u7ef4\u62a4\u81ea\u8eab\u548c\u4ed6\u4eba\u4fe1\u5ff5\u4e0e\u76ee\u6807\u7684\u4e0d\u540c\u8868\u5f81\u3002", "result": "\u5728\u907f\u78b0\u548c\u89c5\u98df\u4efb\u52a1\u4e2d\uff0cToM\u667a\u80fd\u4f53\u8868\u73b0\u51fa\u66f4\u597d\u7684\u534f\u4f5c\u80fd\u529b\uff0c\u80fd\u907f\u514d\u78b0\u649e\u5e76\u51cf\u5c11\u5197\u4f59\u884c\u4e3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4eba\u5de5\u667a\u80fd\u7684\u5b9e\u8df5\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5e76\u8ba1\u7b97\u6027\u5730\u63ed\u793a\u4e86ToM\u7684\u4f5c\u7528\u3002"}}
{"id": "2508.00772", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.00772", "abs": "https://arxiv.org/abs/2508.00772", "authors": ["Md Imranur Rahman Akib", "Fathima Binthe Muhammed", "Umit Saha", "Md Fazlul Karim Patwary", "Mehrin Anannya", "Md Alomgeer Hussein", "Md Biplob Hosen"], "title": "From Code to Career: Assessing Competitive Programmers for Industry Placement", "comment": null, "summary": "In today's fast-paced tech industry, there is a growing need for tools that\nevaluate a programmer's job readiness based on their coding performance. This\nstudy focuses on predicting the potential of Codeforces users to secure various\nlevels of software engineering jobs. The primary objective is to analyze how a\nuser's competitive programming activity correlates with their chances of\nobtaining positions, ranging from entry-level roles to jobs at major tech\ncompanies. We collect user data using the Codeforces API, process key\nperformance metrics, and build a prediction model using a Random Forest\nclassifier. The model categorizes users into four levels of employability,\nranging from those needing further development to those ready for top-tier tech\njobs. The system is implemented using Flask and deployed on Render for\nreal-time predictions. Our evaluation demonstrates that the approach\neffectively distinguishes between different skill levels based on coding\nproficiency and participation. This work lays a foundation for the use of\nmachine learning in career assessment and could be extended to predict job\nreadiness in broader technical fields.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7Codeforces\u7528\u6237\u7684\u7f16\u7a0b\u7ade\u8d5b\u8868\u73b0\u9884\u6d4b\u5176\u8f6f\u4ef6\u5de5\u7a0b\u5c97\u4f4d\u5c31\u4e1a\u6f5c\u529b\uff0c\u4f7f\u7528\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u6784\u5efa\u6a21\u578b\uff0c\u5e76\u5c06\u7528\u6237\u5206\u4e3a\u56db\u4e2a\u5c31\u4e1a\u80fd\u529b\u7b49\u7ea7\u3002", "motivation": "\u5feb\u901f\u53d1\u5c55\u7684\u79d1\u6280\u884c\u4e1a\u9700\u8981\u8bc4\u4f30\u7a0b\u5e8f\u5458\u5c31\u4e1a\u51c6\u5907\u7684\u5de5\u5177\uff0c\u7814\u7a76\u65e8\u5728\u5206\u6790\u7ade\u4e89\u7f16\u7a0b\u6d3b\u52a8\u4e0e\u5c31\u4e1a\u673a\u4f1a\u7684\u76f8\u5173\u6027\u3002", "method": "\u901a\u8fc7Codeforces API\u6536\u96c6\u7528\u6237\u6570\u636e\uff0c\u5904\u7406\u5173\u952e\u6027\u80fd\u6307\u6807\uff0c\u4f7f\u7528\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u6784\u5efa\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u901a\u8fc7Flask\u90e8\u7f72\u5b9e\u65f6\u9884\u6d4b\u7cfb\u7edf\u3002", "result": "\u6a21\u578b\u80fd\u6709\u6548\u533a\u5206\u4e0d\u540c\u6280\u80fd\u6c34\u5e73\u7684\u7528\u6237\uff0c\u57fa\u4e8e\u7f16\u7a0b\u719f\u7ec3\u5ea6\u548c\u53c2\u4e0e\u5ea6\u9884\u6d4b\u5c31\u4e1a\u6f5c\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u673a\u5668\u5b66\u4e60\u5728\u804c\u4e1a\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u57fa\u7840\uff0c\u53ef\u6269\u5c55\u81f3\u66f4\u5e7f\u6cdb\u6280\u672f\u9886\u57df\u7684\u5c31\u4e1a\u51c6\u5907\u9884\u6d4b\u3002"}}
{"id": "2508.00414", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00414", "abs": "https://arxiv.org/abs/2508.00414", "authors": ["Tianqing Fang", "Zhisong Zhang", "Xiaoyang Wang", "Rui Wang", "Can Qin", "Yuxuan Wan", "Jun-Yu Ma", "Ce Zhang", "Jiaqi Chen", "Xiyun Li", "Hongming Zhang", "Haitao Mi", "Dong Yu"], "title": "Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training", "comment": "16 pages", "summary": "General AI Agents are increasingly recognized as foundational frameworks for\nthe next generation of artificial intelligence, enabling complex reasoning, web\ninteraction, coding, and autonomous research capabilities. However, current\nagent systems are either closed-source or heavily reliant on a variety of paid\nAPIs and proprietary tools, limiting accessibility and reproducibility for the\nresearch community. In this work, we present \\textbf{Cognitive Kernel-Pro}, a\nfully open-source and (to the maximum extent) free multi-module agent framework\ndesigned to democratize the development and evaluation of advanced AI agents.\nWithin Cognitive Kernel-Pro, we systematically investigate the curation of\nhigh-quality training data for Agent Foundation Models, focusing on the\nconstruction of queries, trajectories, and verifiable answers across four key\ndomains: web, file, code, and general reasoning. Furthermore, we explore novel\nstrategies for agent test-time reflection and voting to enhance agent\nrobustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving\nstate-of-the-art results among open-source and free agents. Notably, our\n8B-parameter open-source model surpasses previous leading systems such as\nWebDancer and WebSailor, establishing a new performance standard for\naccessible, high-capability AI agents. Code is available at\nhttps://github.com/Tencent/CognitiveKernel-Pro", "AI": {"tldr": "Cognitive Kernel-Pro \u662f\u4e00\u4e2a\u5b8c\u5168\u5f00\u6e90\u4e14\u514d\u8d39\u7684 AI \u4ee3\u7406\u6846\u67b6\uff0c\u65e8\u5728\u63a8\u52a8\u9ad8\u7ea7 AI \u4ee3\u7406\u7684\u5f00\u53d1\u4e0e\u8bc4\u4f30\uff0c\u5e76\u5728 GAIA \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u9886\u5148\u6027\u80fd\u3002", "motivation": "\u5f53\u524d AI \u4ee3\u7406\u7cfb\u7edf\u591a\u4e3a\u95ed\u6e90\u6216\u4f9d\u8d56\u4ed8\u8d39 API\uff0c\u9650\u5236\u4e86\u7814\u7a76\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u8bad\u7ec3\u6570\u636e\uff08\u67e5\u8be2\u3001\u8f68\u8ff9\u548c\u53ef\u9a8c\u8bc1\u7b54\u6848\uff09\u548c\u63a2\u7d22\u4ee3\u7406\u6d4b\u8bd5\u65f6\u7684\u53cd\u601d\u4e0e\u6295\u7968\u7b56\u7565\u3002", "result": "\u5728 GAIA \u4e0a\u53d6\u5f97\u5f00\u6e90\u4ee3\u7406\u4e2d\u7684\u6700\u4f73\u6027\u80fd\uff0c8B \u53c2\u6570\u6a21\u578b\u8d85\u8d8a WebDancer \u548c WebSailor\u3002", "conclusion": "Cognitive Kernel-Pro \u4e3a\u53ef\u8bbf\u95ee\u7684\u9ad8\u6027\u80fd AI \u4ee3\u7406\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2508.00500", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00500", "abs": "https://arxiv.org/abs/2508.00500", "authors": ["Haoyu Wang", "Chris M. Poskitt", "Jun Sun", "Jiali Wei"], "title": "Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking", "comment": null, "summary": "Large Language Model (LLM) agents exhibit powerful autonomous capabilities\nacross domains such as robotics, virtual assistants, and web automation.\nHowever, their stochastic behavior introduces significant safety risks that are\ndifficult to anticipate. Existing rule-based enforcement systems, such as\nAgentSpec, focus on developing reactive safety rules, which typically respond\nonly when unsafe behavior is imminent or has already occurred. These systems\nlack foresight and struggle with long-horizon dependencies and distribution\nshifts. To address these limitations, we propose Pro2Guard, a proactive runtime\nenforcement framework grounded in probabilistic reachability analysis.\nPro2Guard abstracts agent behaviors into symbolic states and learns a\nDiscrete-Time Markov Chain (DTMC) from execution traces. At runtime, it\nanticipates future risks by estimating the probability of reaching unsafe\nstates, triggering interventions before violations occur when the predicted\nrisk exceeds a user-defined threshold. By incorporating semantic validity\nchecks and leveraging PAC bounds, Pro2Guard ensures statistical reliability\nwhile approximating the underlying ground-truth model. We evaluate Pro2Guard\nextensively across two safety-critical domains: embodied household agents and\nautonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early\non up to 93.6% of unsafe tasks using low thresholds, while configurable modes\n(e.g., reflect) allow balancing safety with task success, maintaining up to\n80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%\nprediction of traffic law violations and collisions, anticipating risks up to\n38.66 seconds ahead.", "AI": {"tldr": "Pro2Guard\u662f\u4e00\u4e2a\u57fa\u4e8e\u6982\u7387\u53ef\u8fbe\u6027\u5206\u6790\u7684\u4e3b\u52a8\u8fd0\u884c\u65f6\u5b89\u5168\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u548c\u9632\u6b62LLM\u4ee3\u7406\u7684\u4e0d\u5b89\u5168\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c4\u5219\u7684\u5b89\u5168\u7cfb\u7edf\uff08\u5982AgentSpec\uff09\u7f3a\u4e4f\u9884\u89c1\u6027\uff0c\u96be\u4ee5\u5e94\u5bf9\u957f\u671f\u4f9d\u8d56\u548c\u5206\u5e03\u53d8\u5316\uff0c\u5bfc\u81f4\u5b89\u5168\u98ce\u9669\u3002", "method": "Pro2Guard\u5c06\u4ee3\u7406\u884c\u4e3a\u62bd\u8c61\u4e3a\u7b26\u53f7\u72b6\u6001\uff0c\u5e76\u4ece\u6267\u884c\u8f68\u8ff9\u4e2d\u5b66\u4e60\u79bb\u6563\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\uff08DTMC\uff09\uff0c\u5728\u8fd0\u884c\u65f6\u9884\u6d4b\u4e0d\u5b89\u5168\u72b6\u6001\u7684\u6982\u7387\u5e76\u63d0\u524d\u5e72\u9884\u3002", "result": "\u5728\u5bb6\u5ead\u4ee3\u7406\u548c\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\uff0cPro2Guard\u5206\u522b\u5b9e\u73b0\u4e8693.6%\u548c100%\u7684\u4e0d\u5b89\u5168\u884c\u4e3a\u9884\u6d4b\uff0c\u5e76\u80fd\u63d0\u524d\u5e72\u9884\u3002", "conclusion": "Pro2Guard\u901a\u8fc7\u4e3b\u52a8\u9884\u6d4b\u548c\u5e72\u9884\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u4ee3\u7406\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u5b8c\u6210\u7387\u3002"}}
{"id": "2508.00459", "categories": ["cs.AI", "68T07, 68T20", "I.2.6; I.2.7; I.2.3"], "pdf": "https://arxiv.org/pdf/2508.00459", "abs": "https://arxiv.org/abs/2508.00459", "authors": ["Andrea Asperti", "Alberto Naibo", "Claudio Sacerdoti Coen"], "title": "Thinking Machines: Mathematical Reasoning in the Age of LLMs", "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable abilities in structured\nreasoning and symbolic tasks, with coding emerging as a particular area of\nstrength. This success has sparked growing interest in applying LLMs to\nmathematics, both in informal problem-solving and formal theorem proving.\nHowever, progress in formal mathematics has proven to be significantly more\ndifficult, despite surface-level similarities between programming and proof\nconstruction. This discrepancy raises important questions about how LLMs\n``reason'', how they are supervised, and whether they internally track a notion\nof computational or deductive state. In this article, we address the\nstate-of-the-art of the discipline, focusing on recent models and benchmarks,\nand explore three central issues at the intersection of machine learning and\nmathematical cognition: (i) the trade-offs between formal and informal\nmathematics as training domains; (ii) the deeper reasons why proof generation\nremains more brittle than code synthesis; (iii) and the question of whether\nLLMs represent, or merely mimic, a notion of evolving logical state. Our goal\nis not to draw hard boundaries, but to identify where the current limits lie,\nand how they might be extended.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6570\u5b66\u9886\u57df\u7684\u5e94\u7528\uff0c\u5c24\u5176\u662f\u5f62\u5f0f\u5316\u6570\u5b66\u8bc1\u660e\u4e2d\u7684\u6311\u6218\uff0c\u5206\u6790\u4e86\u5176\u4e0e\u7f16\u7a0b\u4efb\u52a1\u7684\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u4e2a\u6838\u5fc3\u95ee\u9898\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u6570\u5b66\u9886\u57df\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5f62\u5f0f\u5316\u6570\u5b66\u8bc1\u660e\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u63ed\u793a\u5176\u63a8\u7406\u548c\u76d1\u7763\u673a\u5236\u7684\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63a2\u8ba8LLMs\u5728\u5f62\u5f0f\u5316\u4e0e\u975e\u5f62\u5f0f\u5316\u6570\u5b66\u8bad\u7ec3\u4e2d\u7684\u6743\u8861\u3001\u8bc1\u660e\u751f\u6210\u8106\u5f31\u6027\u7684\u539f\u56e0\uff0c\u4ee5\u53caLLMs\u662f\u5426\u771f\u6b63\u8ddf\u8e2a\u903b\u8f91\u72b6\u6001\u3002", "result": "\u53d1\u73b0LLMs\u5728\u5f62\u5f0f\u5316\u6570\u5b66\u8bc1\u660e\u4e2d\u7684\u8868\u73b0\u8f83\u5f31\uff0c\u4e0e\u7f16\u7a0b\u4efb\u52a1\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u5176\u63a8\u7406\u548c\u76d1\u7763\u673a\u5236\u7684\u4e0d\u8db3\u3002", "conclusion": "\u8bba\u6587\u65e8\u5728\u660e\u786e\u5f53\u524dLLMs\u5728\u6570\u5b66\u9886\u57df\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u53ef\u80fd\u7684\u7814\u7a76\u65b9\u5411\u4ee5\u6269\u5c55\u5176\u80fd\u529b\u3002"}}
{"id": "2508.00576", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00576", "abs": "https://arxiv.org/abs/2508.00576", "authors": ["Zhanliang Wang", "Kai Wang"], "title": "MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models", "comment": null, "summary": "Multimodal AI models have achieved impressive performance in tasks that\nrequire integrating information from multiple modalities, such as vision and\nlanguage. However, their \"black-box\" nature poses a major barrier to deployment\nin high-stakes applications where interpretability and trustworthiness are\nessential. How to explain cross-modal interactions in multimodal AI models\nremains a major challenge. While existing model explanation methods, such as\nattention map and Grad-CAM, offer coarse insights into cross-modal\nrelationships, they cannot precisely quantify the synergistic effects between\nmodalities, and are limited to open-source models with accessible internal\nweights. Here we introduce MultiSHAP, a model-agnostic interpretability\nframework that leverages the Shapley Interaction Index to attribute multimodal\npredictions to pairwise interactions between fine-grained visual and textual\nelements (such as image patches and text tokens), while being applicable to\nboth open- and closed-source models. Our approach provides: (1) instance-level\nexplanations that reveal synergistic and suppressive cross-modal effects for\nindividual samples - \"why the model makes a specific prediction on this input\",\nand (2) dataset-level explanation that uncovers generalizable interaction\npatterns across samples - \"how the model integrates information across\nmodalities\". Experiments on public multimodal benchmarks confirm that MultiSHAP\nfaithfully captures cross-modal reasoning mechanisms, while real-world case\nstudies demonstrate its practical utility. Our framework is extensible beyond\ntwo modalities, offering a general solution for interpreting complex multimodal\nAI models.", "AI": {"tldr": "MultiSHAP\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u89e3\u91ca\u6846\u67b6\uff0c\u5229\u7528Shapley\u4ea4\u4e92\u6307\u6570\u91cf\u5316\u591a\u6a21\u6001AI\u6a21\u578b\u4e2d\u89c6\u89c9\u548c\u6587\u672c\u5143\u7d20\u7684\u534f\u540c\u6548\u5e94\uff0c\u9002\u7528\u4e8e\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u591a\u6a21\u6001AI\u6a21\u578b\u7684\u201c\u9ed1\u76d2\u201d\u7279\u6027\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u9650\u5236\u4e86\u5176\u90e8\u7f72\uff0c\u9700\u8981\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u7cbe\u786e\u91cf\u5316\u6a21\u6001\u95f4\u7684\u534f\u540c\u6548\u5e94\u3002", "method": "\u5f15\u5165MultiSHAP\u6846\u67b6\uff0c\u57fa\u4e8eShapley\u4ea4\u4e92\u6307\u6570\uff0c\u5206\u6790\u89c6\u89c9\u548c\u6587\u672c\u5143\u7d20\u7684\u6210\u5bf9\u4ea4\u4e92\uff0c\u63d0\u4f9b\u5b9e\u4f8b\u7ea7\u548c\u6570\u636e\u96c6\u7ea7\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9eMultiSHAP\u80fd\u51c6\u786e\u6355\u6349\u8de8\u6a21\u6001\u63a8\u7406\u673a\u5236\uff0c\u5b9e\u9645\u6848\u4f8b\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "MultiSHAP\u4e3a\u89e3\u91ca\u590d\u6742\u591a\u6a21\u6001AI\u6a21\u578b\u63d0\u4f9b\u4e86\u901a\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u4e24\u79cd\u4ee5\u4e0a\u6a21\u6001\u3002"}}
{"id": "2508.00581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00581", "abs": "https://arxiv.org/abs/2508.00581", "authors": ["Ruiqing Ding", "Qianfang Sun", "Yongkang Leng", "Hui Yin", "Xiaojian Li"], "title": "From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation", "comment": "16 pages, 10 figures", "summary": "Pre-consultation is a critical component of effective healthcare delivery.\nHowever, generating comprehensive pre-consultation questionnaires from complex,\nvoluminous Electronic Medical Records (EMRs) is a challenging task. Direct\nLarge Language Model (LLM) approaches face difficulties in this task,\nparticularly regarding information completeness, logical order, and\ndisease-level synthesis. To address this issue, we propose a novel multi-stage\nLLM-driven framework: Stage 1 extracts atomic assertions (key facts with\ntiming) from EMRs; Stage 2 constructs personal causal networks and synthesizes\ndisease knowledge by clustering representative networks from an EMR corpus;\nStage 3 generates tailored personal and standardized disease-specific\nquestionnaires based on these structured representations. This framework\novercomes limitations of direct methods by building explicit clinical\nknowledge. Evaluated on a real-world EMR dataset and validated by clinical\nexperts, our method demonstrates superior performance in information coverage,\ndiagnostic relevance, understandability, and generation time, highlighting its\npractical potential to enhance patient information collection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9636\u6bb5LLM\u9a71\u52a8\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u590d\u6742\u7535\u5b50\u75c5\u5386\u751f\u6210\u5168\u9762\u7684\u9884\u54a8\u8be2\u95ee\u5377\uff0c\u89e3\u51b3\u4e86\u76f4\u63a5LLM\u65b9\u6cd5\u5728\u4fe1\u606f\u5b8c\u6574\u6027\u3001\u903b\u8f91\u987a\u5e8f\u548c\u75be\u75c5\u7ea7\u5408\u6210\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u9884\u54a8\u8be2\u662f\u533b\u7597\u4fdd\u5065\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u4f46\u4ece\u590d\u6742\u7535\u5b50\u75c5\u5386\u751f\u6210\u95ee\u5377\u5177\u6709\u6311\u6218\u6027\uff0c\u76f4\u63a5LLM\u65b9\u6cd5\u5728\u4fe1\u606f\u5b8c\u6574\u6027\u548c\u903b\u8f91\u6027\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5206\u4e09\u9636\u6bb5\uff1a1\uff09\u63d0\u53d6\u539f\u5b50\u65ad\u8a00\uff1b2\uff09\u6784\u5efa\u4e2a\u4eba\u56e0\u679c\u7f51\u7edc\u5e76\u5408\u6210\u75be\u75c5\u77e5\u8bc6\uff1b3\uff09\u751f\u6210\u4e2a\u6027\u5316\u95ee\u5377\u3002", "result": "\u5728\u771f\u5b9e\u7535\u5b50\u75c5\u5386\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u5728\u4fe1\u606f\u8986\u76d6\u3001\u8bca\u65ad\u76f8\u5173\u6027\u3001\u53ef\u7406\u89e3\u6027\u548c\u751f\u6210\u65f6\u95f4\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u660e\u786e\u4e34\u5e8a\u77e5\u8bc6\u514b\u670d\u4e86\u76f4\u63a5\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u5177\u6709\u63d0\u5347\u60a3\u8005\u4fe1\u606f\u6536\u96c6\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.00632", "categories": ["cs.AI", "cs.MA", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.00632", "abs": "https://arxiv.org/abs/2508.00632", "authors": ["Alexia Jolicoeur-Martineau"], "title": "Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings", "comment": null, "summary": "While AI excels at generating text, audio, images, and videos, creating\ninteractive audio-visual content such as video games remains challenging.\nCurrent LLMs can generate JavaScript games and animations, but lack automated\nevaluation metrics and struggle with complex content that normally requires\nteams of humans working for many months (multi-shot, multi-agents) using assets\nmade by artists. To tackle these issues, we built a new metric and a\nmulti-agent system.\n  We propose AVR-Eval, a relative metric for multimedia content quality using\nAudio-Visual Recordings (AVRs). An omni-modal model (processing text, video,\nand audio) compares the AVRs of two contents, with a text model reviewing\nevaluations to determine superiority. We show that AVR-Eval properly identifies\ngood from broken or mismatched content.\n  We built AVR-Agent, a multi-agent system generating JavaScript code from a\nbank of multimedia assets (audio, images, 3D models). The coding agent selects\nrelevant assets, generates multiple initial codes, uses AVR-Eval to identify\nthe best version, and iteratively improves it through omni-modal agent feedback\nfrom the AVR.\n  We run experiments on games and animations with AVR-Eval (win rate of content\nA against B). We find that content generated by AVR-Agent has a significantly\nhigher win rate against content made through one-shot generation. However,\nmodels struggle to leverage custom assets and AVR feedback effectively, showing\nno higher win rate. This reveals a critical gap: while humans benefit from\nhigh-quality assets and audio-visual feedback, current coding models do not\nseem to utilize these resources as effectively, highlighting fundamental\ndifferences between human and machine content creation approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86AVR-Eval\u8bc4\u4f30\u6307\u6807\u548cAVR-Agent\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u751f\u6210\u548c\u8bc4\u4f30\u4ea4\u4e92\u5f0f\u97f3\u89c6\u9891\u5185\u5bb9\uff0c\u53d1\u73b0\u591a\u4ee3\u7406\u7cfb\u7edf\u751f\u6210\u7684\u5185\u5bb9\u4f18\u4e8e\u5355\u6b21\u751f\u6210\uff0c\u4f46\u6a21\u578b\u5728\u5229\u7528\u9ad8\u8d28\u91cf\u8d44\u6e90\u548c\u53cd\u9988\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002", "motivation": "\u89e3\u51b3\u5f53\u524dAI\u5728\u751f\u6210\u590d\u6742\u4ea4\u4e92\u5f0f\u97f3\u89c6\u9891\u5185\u5bb9\uff08\u5982\u89c6\u9891\u6e38\u620f\uff09\u65f6\u7f3a\u4e4f\u81ea\u52a8\u5316\u8bc4\u4f30\u6307\u6807\u548c\u96be\u4ee5\u5904\u7406\u590d\u6742\u5185\u5bb9\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faAVR-Eval\u8bc4\u4f30\u6307\u6807\uff0c\u901a\u8fc7\u97f3\u89c6\u9891\u8bb0\u5f55\u6bd4\u8f83\u5185\u5bb9\u8d28\u91cf\uff1b\u5f00\u53d1AVR-Agent\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u751f\u6210\u5e76\u8fed\u4ee3\u4f18\u5316JavaScript\u4ee3\u7801\u3002", "result": "AVR-Agent\u751f\u6210\u7684\u5185\u5bb9\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u6b21\u751f\u6210\u7684\u5185\u5bb9\uff0c\u4f46\u6a21\u578b\u672a\u80fd\u6709\u6548\u5229\u7528\u5b9a\u5236\u8d44\u6e90\u548c\u97f3\u89c6\u9891\u53cd\u9988\u3002", "conclusion": "\u5f53\u524d\u6a21\u578b\u5728\u5229\u7528\u9ad8\u8d28\u91cf\u8d44\u6e90\u548c\u53cd\u9988\u65b9\u9762\u4e0e\u4eba\u7c7b\u5b58\u5728\u5dee\u8ddd\uff0c\u63ed\u793a\u4e86\u673a\u5668\u4e0e\u4eba\u7c7b\u5185\u5bb9\u521b\u4f5c\u65b9\u5f0f\u7684\u6839\u672c\u5dee\u5f02\u3002"}}
{"id": "2508.00658", "categories": ["cs.AI", "cs.LG", "econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2508.00658", "abs": "https://arxiv.org/abs/2508.00658", "authors": ["Chakattrai Sookkongwaree", "Tattep Lakmuang", "Chainarong Amornbunchornvej"], "title": "Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies", "comment": "First draft", "summary": "Understanding causal relationships in time series is fundamental to many\ndomains, including neuroscience, economics, and behavioral science. Granger\ncausality is one of the well-known techniques for inferring causality in time\nseries. Typically, Granger causality frameworks have a strong fix-lag\nassumption between cause and effect, which is often unrealistic in complex\nsystems. While recent work on variable-lag Granger causality (VLGC) addresses\nthis limitation by allowing a cause to influence an effect with different time\nlags at each time point, it fails to account for the fact that causal\ninteractions may vary not only in time delay but also across frequency bands.\nFor example, in brain signals, alpha-band activity may influence another region\nwith a shorter delay than slower delta-band oscillations. In this work, we\nformalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a\nnovel framework that generalizes traditional VLGC by explicitly modeling\nfrequency-dependent causal delays. We provide a formal definition of MB-VLGC,\ndemonstrate its theoretical soundness, and propose an efficient inference\npipeline. Extensive experiments across multiple domains demonstrate that our\nframework significantly outperforms existing methods on both synthetic and\nreal-world datasets, confirming its broad applicability to any type of time\nseries data. Code and datasets are publicly available.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9891\u5e26\u53ef\u53d8\u6ede\u540e\u683c\u5170\u6770\u56e0\u679c\u5173\u7cfb\uff08MB-VLGC\uff09\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u9891\u7387\u4f9d\u8d56\u56e0\u679c\u5ef6\u8fdf\u7684\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u7406\u89e3\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u56e0\u679c\u5173\u7cfb\u5bf9\u591a\u4e2a\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u683c\u5170\u6770\u56e0\u679c\u5173\u7cfb\u65b9\u6cd5\u5b58\u5728\u56fa\u5b9a\u6ede\u540e\u5047\u8bbe\u7684\u5c40\u9650\u6027\uff0c\u4e14\u73b0\u6709\u53ef\u53d8\u6ede\u540e\u65b9\u6cd5\u672a\u8003\u8651\u9891\u7387\u4f9d\u8d56\u7684\u5ef6\u8fdf\u3002", "method": "\u63d0\u51faMB-VLGC\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u9891\u7387\u4f9d\u8d56\u7684\u56e0\u679c\u5ef6\u8fdf\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u53ef\u53d8\u6ede\u540e\u683c\u5170\u6770\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9ad8\u6548\u63a8\u7406\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMB-VLGC\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "conclusion": "MB-VLGC\u4e3a\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u51c6\u786e\u7684\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u591a\u9886\u57df\u5e94\u7528\u3002"}}
{"id": "2508.00665", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00665", "abs": "https://arxiv.org/abs/2508.00665", "authors": ["Maryam Mosleh", "Marie Devlin", "Ellis Solaiman"], "title": "Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI", "comment": null, "summary": "Artificial intelligence-driven adaptive learning systems are reshaping\neducation through data-driven adaptation of learning experiences. Yet many of\nthese systems lack transparency, offering limited insight into how decisions\nare made. Most explainable AI (XAI) techniques focus on technical outputs but\nneglect user roles and comprehension. This paper proposes a hybrid framework\nthat integrates traditional XAI techniques with generative AI models and user\npersonalisation to generate multimodal, personalised explanations tailored to\nuser needs. We redefine explainability as a dynamic communication process\ntailored to user roles and learning goals. We outline the framework's design,\nkey XAI limitations in education, and research directions on accuracy,\nfairness, and personalisation. Our aim is to move towards explainable AI that\nenhances transparency while supporting user-centred experiences.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4f20\u7edf\u53ef\u89e3\u91caAI\u6280\u672f\u4e0e\u751f\u6210\u5f0fAI\u6a21\u578b\u7684\u6df7\u5408\u6846\u67b6\uff0c\u65e8\u5728\u4e3a\u6559\u80b2\u9886\u57df\u63d0\u4f9b\u591a\u6a21\u6001\u3001\u4e2a\u6027\u5316\u7684\u89e3\u91ca\uff0c\u4ee5\u589e\u5f3a\u900f\u660e\u5ea6\u548c\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u5f53\u524d\u81ea\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u4e14\u591a\u6570\u53ef\u89e3\u91caAI\u6280\u672f\u5ffd\u89c6\u7528\u6237\u89d2\u8272\u548c\u7406\u89e3\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u52a8\u6001\u3001\u7528\u6237\u4e2d\u5fc3\u7684\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u6846\u67b6\uff0c\u6574\u5408\u4f20\u7edfXAI\u6280\u672f\u4e0e\u751f\u6210\u5f0fAI\u6a21\u578b\uff0c\u7ed3\u5408\u7528\u6237\u4e2a\u6027\u5316\u9700\u6c42\uff0c\u751f\u6210\u591a\u6a21\u6001\u89e3\u91ca\u3002", "result": "\u6846\u67b6\u91cd\u65b0\u5b9a\u4e49\u53ef\u89e3\u91ca\u6027\u4e3a\u52a8\u6001\u6c9f\u901a\u8fc7\u7a0b\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u6559\u80b2\u4e2d\u7684\u5c40\u9650\u6027\u53ca\u7814\u7a76\u65b9\u5411\uff08\u5982\u51c6\u786e\u6027\u3001\u516c\u5e73\u6027\u3001\u4e2a\u6027\u5316\uff09\u3002", "conclusion": "\u76ee\u6807\u662f\u63a8\u52a8\u53ef\u89e3\u91caAI\u7684\u53d1\u5c55\uff0c\u65e2\u63d0\u5347\u900f\u660e\u5ea6\uff0c\u53c8\u652f\u6301\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u4f53\u9a8c\u3002"}}
{"id": "2508.00674", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00674", "abs": "https://arxiv.org/abs/2508.00674", "authors": ["Banan Alkhateeb", "Ellis Solaiman"], "title": "Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations", "comment": null, "summary": "Social media platforms today strive to improve user experience through AI\nrecommendations, yet the value of such recommendations vanishes as users do not\nunderstand the reasons behind them. This issue arises because explainability in\nsocial media is general and lacks alignment with user-specific needs. In this\nvision paper, we outline a user-segmented and context-aware explanation layer\nby proposing a visual explanation system with diverse explanation methods. The\nproposed system is framed by the variety of user needs and contexts, showing\nexplanations in different visualized forms, including a technically detailed\nversion for AI experts and a simplified one for lay users. Our framework is the\nfirst to jointly adapt explanation style (visual vs. numeric) and granularity\n(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will\nvalidate its impact on decision-making and trust.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u6237\u5206\u6bb5\u7684\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u53ef\u89c6\u5316\u89e3\u91ca\u7cfb\u7edf\uff0c\u4ee5\u89e3\u51b3\u793e\u4ea4\u5a92\u4f53\u63a8\u8350\u4e2d\u89e3\u91ca\u6027\u4e0e\u7528\u6237\u9700\u6c42\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u793e\u4ea4\u5a92\u4f53\u63a8\u8350\u7cfb\u7edf\u7684\u89e3\u91ca\u6027\u666e\u904d\u4e14\u7f3a\u4e4f\u9488\u5bf9\u6027\uff0c\u5bfc\u81f4\u7528\u6237\u4e0d\u7406\u89e3\u63a8\u8350\u539f\u56e0\uff0c\u964d\u4f4e\u4e86\u63a8\u8350\u7684\u4ef7\u503c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7528\u6237\u9700\u6c42\u548c\u4e0a\u4e0b\u6587\u7684\u53ef\u89c6\u5316\u89e3\u91ca\u7cfb\u7edf\uff0c\u652f\u6301\u591a\u79cd\u89e3\u91ca\u5f62\u5f0f\uff08\u5982\u6280\u672f\u8be6\u7ec6\u7248\u548c\u7b80\u5316\u7248\uff09\uff0c\u5e76\u9996\u6b21\u5728\u540c\u4e00\u6d41\u7a0b\u4e2d\u8c03\u6574\u89e3\u91ca\u98ce\u683c\uff08\u89c6\u89c9\u4e0e\u6570\u5b57\uff09\u548c\u7c92\u5ea6\uff08\u4e13\u5bb6\u4e0e\u666e\u901a\u7528\u6237\uff09\u3002", "result": "\u901a\u8fc730\u540dX\u7528\u6237\u7684\u516c\u5f00\u8bd5\u70b9\u9a8c\u8bc1\u7cfb\u7edf\u5bf9\u51b3\u7b56\u548c\u4fe1\u4efb\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u793e\u4ea4\u5a92\u4f53\u63a8\u8350\u63d0\u4f9b\u4e86\u66f4\u4e2a\u6027\u5316\u548c\u6709\u6548\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u6709\u671b\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u548c\u4fe1\u4efb\u3002"}}
{"id": "2508.00784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00784", "abs": "https://arxiv.org/abs/2508.00784", "authors": ["Tom Or", "Omri Azencot"], "title": "Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics", "comment": null, "summary": "Generative models achieve remarkable results in multiple data domains,\nincluding images and texts, among other examples. Unfortunately, malicious\nusers exploit synthetic media for spreading misinformation and disseminating\ndeepfakes. Consequently, the need for robust and stable fake detectors is\npressing, especially when new generative models appear everyday. While the\nmajority of existing work train classifiers that discriminate between real and\nfake information, such tools typically generalize only within the same family\nof generators and data modalities, yielding poor results on other generative\nclasses and data domains. Towards a universal classifier, we propose the use of\nlarge pre-trained multi-modal models for the detection of generative content.\nEffectively, we show that the latent code of these models naturally captures\ninformation discriminating real from fake. Building on this observation, we\ndemonstrate that linear classifiers trained on these features can achieve\nstate-of-the-art results across various modalities, while remaining\ncomputationally efficient, fast to train, and effective even in few-shot\nsettings. Our work primarily focuses on fake detection in audio and images,\nachieving performance that surpasses or matches that of strong baseline\nmethods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u6a21\u578b\u7684\u901a\u7528\u751f\u6210\u5185\u5bb9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ebf\u6027\u5206\u7c7b\u5668\u5b9e\u73b0\u8de8\u6a21\u6001\u7684\u9ad8\u6548\u68c0\u6d4b\u3002", "motivation": "\u751f\u6210\u6a21\u578b\u88ab\u6076\u610f\u7528\u4e8e\u4f20\u64ad\u865a\u5047\u4fe1\u606f\uff0c\u73b0\u6709\u68c0\u6d4b\u5de5\u5177\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u9700\u5f00\u53d1\u901a\u7528\u4e14\u9ad8\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5927\u578b\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u6a21\u578b\u7684\u6f5c\u5728\u7f16\u7801\u7279\u5f81\uff0c\u8bad\u7ec3\u7ebf\u6027\u5206\u7c7b\u5668\u8fdb\u884c\u771f\u5047\u5185\u5bb9\u5224\u522b\u3002", "result": "\u5728\u97f3\u9891\u548c\u56fe\u50cf\u9886\u57df\uff0c\u8be5\u65b9\u6cd5\u6027\u80fd\u4f18\u4e8e\u6216\u5339\u914d\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u8ba1\u7b97\u9ad8\u6548\u3001\u8bad\u7ec3\u5feb\u901f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8de8\u6a21\u6001\u751f\u6210\u5185\u5bb9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
