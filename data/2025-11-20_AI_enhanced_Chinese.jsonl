{"id": "2511.13972", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13972", "abs": "https://arxiv.org/abs/2511.13972", "authors": ["Jeremiah Bohr"], "title": "Show and Tell: Prompt Strategies for Style Control in Multi-Turn LLM Code Generation", "comment": "23 pages, 2 figures, 3 tables. Under review", "summary": "Language models generate functionally correct code that tends toward excessive verbosity, with elaborate documentation and defensive patterns that diverge from human baselines. Two prompting mechanisms have emerged for stylistic control: instruction based prompts that articulate abstract directives, and example based prompts that provide concrete code demonstrations. The core problem is whether stylistic constraints persist when models enhance initial implementations with additional features while maintaining high functional accuracy. Here we show that instruction-based, example-based, and combined prompts produce distinct patterns of initial control and expansion discipline over one enhancement turn. We manipulated system prompts across four conditions in a paired two-turn protocol where models first generated solutions to an intermediate Python task, then revised their code under general improvement directives, holding the user task fixed (N = 160 paired programs). Combined prompts produced the strongest initial compression and greatest expansion discipline. Instructions showed large initial effects and moderate expansion discipline. Examples showed modest initial effects with no expansion discipline. These results show that initial prompt effectiveness and expansion discipline are separate aspects of prompt design, and that combined approaches provide the most stable stylistic control in this two-turn workflow.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u57fa\u4e8e\u6307\u4ee4\u3001\u57fa\u4e8e\u793a\u4f8b\u548c\u7ec4\u5408\u63d0\u793a\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u98ce\u683c\u63a7\u5236\u6548\u679c\uff0c\u53d1\u73b0\u7ec4\u5408\u63d0\u793a\u5728\u521d\u59cb\u538b\u7f29\u548c\u6269\u5c55\u7ea6\u675f\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u6307\u4ee4\u63d0\u793a\u6709\u8f83\u5927\u521d\u59cb\u6548\u679c\u4f46\u6269\u5c55\u7ea6\u675f\u4e2d\u7b49\uff0c\u793a\u4f8b\u63d0\u793a\u521d\u59cb\u6548\u679c\u6709\u9650\u4e14\u65e0\u6269\u5c55\u7ea6\u675f\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u5f80\u5f80\u8fc7\u4e8e\u5197\u957f\uff0c\u4e0e\u4eba\u7c7b\u57fa\u51c6\u5b58\u5728\u98ce\u683c\u5dee\u5f02\u3002\u9700\u8981\u7814\u7a76\u4e0d\u540c\u63d0\u793a\u673a\u5236\u5728\u4fdd\u6301\u529f\u80fd\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u80fd\u5426\u6301\u7eed\u63a7\u5236\u4ee3\u7801\u98ce\u683c\u3002", "method": "\u91c7\u7528\u56db\u7ec4\u7cfb\u7edf\u63d0\u793a\u6761\u4ef6\uff08\u6307\u4ee4\u3001\u793a\u4f8b\u3001\u7ec4\u5408\u548c\u65e0\u63d0\u793a\uff09\uff0c\u5728\u53cc\u8f6e\u534f\u8bae\u4e2d\u8ba9\u6a21\u578b\u9996\u5148\u751f\u6210Python\u4efb\u52a1\u89e3\u51b3\u65b9\u6848\uff0c\u7136\u540e\u5728\u901a\u7528\u6539\u8fdb\u6307\u4ee4\u4e0b\u4fee\u8ba2\u4ee3\u7801\uff0c\u4fdd\u6301\u7528\u6237\u4efb\u52a1\u4e0d\u53d8\uff08N=160\u5bf9\u7a0b\u5e8f\uff09\u3002", "result": "\u7ec4\u5408\u63d0\u793a\u4ea7\u751f\u6700\u5f3a\u7684\u521d\u59cb\u538b\u7f29\u548c\u6700\u5927\u7684\u6269\u5c55\u7ea6\u675f\uff1b\u6307\u4ee4\u63d0\u793a\u663e\u793a\u8f83\u5927\u7684\u521d\u59cb\u6548\u679c\u548c\u4e2d\u7b49\u6269\u5c55\u7ea6\u675f\uff1b\u793a\u4f8b\u63d0\u793a\u663e\u793a\u9002\u5ea6\u7684\u521d\u59cb\u6548\u679c\u4e14\u65e0\u6269\u5c55\u7ea6\u675f\u3002", "conclusion": "\u521d\u59cb\u63d0\u793a\u6709\u6548\u6027\u548c\u6269\u5c55\u7ea6\u675f\u662f\u63d0\u793a\u8bbe\u8ba1\u7684\u4e24\u4e2a\u72ec\u7acb\u65b9\u9762\uff0c\u7ec4\u5408\u65b9\u6cd5\u5728\u4e24\u8f6e\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u63d0\u4f9b\u6700\u7a33\u5b9a\u7684\u98ce\u683c\u63a7\u5236\u3002"}}
{"id": "2511.13996", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.13996", "abs": "https://arxiv.org/abs/2511.13996", "authors": ["Daihan Xu", "Diana Martin"], "title": "Exploring the Use of ChatGPT by Computer Science Students in Software Development: Applications, Ethical Considerations, and Insights for Engineering Education", "comment": "Full paper oral presentation at the European Society for Engineering Education (SEFI) 2025 Annual Conference (September 2025)", "summary": "ChatGPT has been increasingly used in computer science, offering efficient support across software development tasks. While it helps students navigate programming challenges, its use also raises concerns about academic integrity and overreliance. Despite growing interest in this topic, prior research has largely relied on surveys, emphasizing trends over in-depth analysis of students' strategies and ethical awareness. This study complements existing work through a qualitative investigation of how computer science students in one UK institution strategically and ethically engage with ChatGPT in software development projects. Drawing on semi-structured interviews, it explores two key questions: How do computer science students ethically and strategically report using ChatGPT in software development projects? How do students understand and perceive the ethical issues associated with using ChatGPT in academic and professional contexts? Findings reveal a shift in students' learning models, moving from traditional \"independent thinking-manual coding-iterative debugging\" to \"AI-assisted ideation-interactive programming-collaborative optimization.\" Importantly, many use ChatGPT conversationally to deepen understanding, while consciously reserving creative and high-level decision-making tasks for themselves. Students tend to cap ChatGPT's contribution to roughly 30%, and evaluate its output to mitigate overreliance. However, only a minority thoroughly analyze AI-generated code, raising concerns about reduced critical engagement. Meanwhile, students reject uncredited use, highlight risks such as privacy breaches and skill degradation, and call for clear usage guidelines set by their teachers. This research offers novel insights into the evolving learner-AI dynamic and highlights the need for explicit guidance to support responsible and pedagogically sound use of such tools.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5b9a\u6027\u8bbf\u8c08\u63a2\u8ba8\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u751f\u5982\u4f55\u5728\u8f6f\u4ef6\u5f00\u53d1\u9879\u76ee\u4e2d\u7b56\u7565\u6027\u548c\u4f26\u7406\u6027\u5730\u4f7f\u7528ChatGPT\uff0c\u53d1\u73b0\u5b66\u751f\u7684\u5b66\u4e60\u6a21\u5f0f\u4ece\u4f20\u7edf\u72ec\u7acb\u7f16\u7a0b\u8f6c\u5411AI\u8f85\u52a9\u534f\u4f5c\uff0c\u5b66\u751f\u6709\u610f\u8bc6\u5730\u9650\u5236ChatGPT\u8d21\u732e\u5ea6\u7ea630%\uff0c\u4f46\u7f3a\u4e4f\u5bf9AI\u751f\u6210\u4ee3\u7801\u7684\u6df1\u5165\u5206\u6790\uff0c\u9700\u8981\u660e\u786e\u7684\u6307\u5bfc\u65b9\u9488\u3002", "motivation": "ChatGPT\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\u7684\u4f7f\u7528\u65e5\u76ca\u589e\u591a\uff0c\u867d\u7136\u80fd\u5e2e\u52a9\u5b66\u751f\u5e94\u5bf9\u7f16\u7a0b\u6311\u6218\uff0c\u4f46\u4e5f\u5f15\u53d1\u4e86\u5b66\u672f\u8bda\u4fe1\u548c\u8fc7\u5ea6\u4f9d\u8d56\u7684\u62c5\u5fe7\u3002\u73b0\u6709\u7814\u7a76\u591a\u4f9d\u8d56\u8c03\u67e5\u95ee\u5377\uff0c\u7f3a\u4e4f\u5bf9\u5b66\u751f\u7b56\u7565\u548c\u4f26\u7406\u610f\u8bc6\u7684\u6df1\u5165\u5206\u6790\u3002", "method": "\u91c7\u7528\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u7684\u5b9a\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u63a2\u8ba8\u82f1\u56fd\u4e00\u6240\u9662\u6821\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u751f\u5728\u8f6f\u4ef6\u5f00\u53d1\u9879\u76ee\u4e2d\u5982\u4f55\u7b56\u7565\u6027\u548c\u4f26\u7406\u6027\u5730\u4f7f\u7528ChatGPT\u3002", "result": "\u53d1\u73b0\u5b66\u751f\u5b66\u4e60\u6a21\u5f0f\u4ece\"\u72ec\u7acb\u601d\u8003-\u624b\u52a8\u7f16\u7801-\u8fed\u4ee3\u8c03\u8bd5\"\u8f6c\u53d8\u4e3a\"AI\u8f85\u52a9\u6784\u601d-\u4ea4\u4e92\u7f16\u7a0b-\u534f\u4f5c\u4f18\u5316\"\u3002\u5b66\u751f\u901a\u8fc7\u5bf9\u8bdd\u65b9\u5f0f\u4f7f\u7528ChatGPT\u52a0\u6df1\u7406\u89e3\uff0c\u4f46\u4fdd\u7559\u521b\u610f\u548c\u9ad8\u7ea7\u51b3\u7b56\u4efb\u52a1\uff0c\u901a\u5e38\u9650\u5236ChatGPT\u8d21\u732e\u5ea6\u7ea630%\u3002\u7136\u800c\u53ea\u6709\u5c11\u6570\u5b66\u751f\u6df1\u5165\u5206\u6790AI\u751f\u6210\u4ee3\u7801\uff0c\u5b58\u5728\u6279\u5224\u6027\u53c2\u4e0e\u51cf\u5c11\u7684\u98ce\u9669\u3002", "conclusion": "\u5b66\u751f\u62d2\u7edd\u672a\u7ecf\u6388\u6743\u7684\u4f7f\u7528\uff0c\u5f3a\u8c03\u9690\u79c1\u6cc4\u9732\u548c\u6280\u80fd\u9000\u5316\u7b49\u98ce\u9669\uff0c\u547c\u5401\u6559\u5e08\u5236\u5b9a\u660e\u786e\u7684\u4f7f\u7528\u6307\u5357\u3002\u7814\u7a76\u63ed\u793a\u4e86\u5b66\u4e60\u8005\u4e0eAI\u52a8\u6001\u5173\u7cfb\u7684\u6f14\u53d8\uff0c\u9700\u8981\u660e\u786e\u6307\u5bfc\u6765\u652f\u6301\u8d1f\u8d23\u4efb\u548c\u6559\u5b66\u5408\u7406\u7684\u4f7f\u7528\u3002"}}
{"id": "2511.13998", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13998", "abs": "https://arxiv.org/abs/2511.13998", "authors": ["Jielin Qiu", "Zuxin Liu", "Zhiwei Liu", "Rithesh Murthy", "Jianguo Zhang", "Haolin Chen", "Shiyu Wang", "Ming Zhu", "Liangwei Yang", "Juntao Tan", "Roshan Ram", "Akshara Prabhakar", "Tulika Awalgaonkar", "Zixiang Chen", "Zhepeng Cen", "Cheng Qian", "Shelby Heinecke", "Weiran Yao", "Silvio Savarese", "Caiming Xiong", "Huan Wang"], "title": "LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering", "comment": "54-pages", "summary": "As large language models (LLMs) evolve into sophisticated autonomous agents capable of complex software development tasks, evaluating their real-world capabilities becomes critical. While existing benchmarks like LoCoBench~\\cite{qiu2025locobench} assess long-context code understanding, they focus on single-turn evaluation and cannot capture the multi-turn interactive nature, tool usage patterns, and adaptive reasoning required by real-world coding agents. We introduce \\textbf{LoCoBench-Agent}, a comprehensive evaluation framework specifically designed to assess LLM agents in realistic, long-context software engineering workflows. Our framework extends LoCoBench's 8,000 scenarios into interactive agent environments, enabling systematic evaluation of multi-turn conversations, tool usage efficiency, error recovery, and architectural consistency across extended development sessions. We also introduce an evaluation methodology with 9 metrics across comprehension and efficiency dimensions. Our framework provides agents with 8 specialized tools (file operations, search, code analysis) and evaluates them across context lengths ranging from 10K to 1M tokens, enabling precise assessment of long-context performance. Through systematic evaluation of state-of-the-art models, we reveal several key findings: (1) agents exhibit remarkable long-context robustness; (2) comprehension-efficiency trade-off exists with negative correlation, where thorough exploration increases comprehension but reduces efficiency; and (3) conversation efficiency varies dramatically across models, with strategic tool usage patterns differentiating high-performing agents. As the first long-context LLM agent benchmark for software engineering, LoCoBench-Agent establishes a rigorous foundation for measuring agent capabilities, identifying performance gaps, and advancing autonomous software development at scale.", "AI": {"tldr": "LoCoBench-Agent\u662f\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u771f\u5b9e\u957f\u4e0a\u4e0b\u6587\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u7efc\u5408\u6846\u67b6\uff0c\u6269\u5c55\u4e86LoCoBench\u76848000\u4e2a\u573a\u666f\u4e3a\u4ea4\u4e92\u5f0f\u73af\u5883\uff0c\u8bc4\u4f30\u591a\u8f6e\u5bf9\u8bdd\u3001\u5de5\u5177\u4f7f\u7528\u6548\u7387\u3001\u9519\u8bef\u6062\u590d\u548c\u67b6\u6784\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5982LoCoBench\u4e3b\u8981\u8bc4\u4f30\u5355\u8f6e\u957f\u4e0a\u4e0b\u6587\u4ee3\u7801\u7406\u89e3\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u7f16\u7801\u667a\u80fd\u4f53\u6240\u9700\u7684\u591a\u8f6e\u4ea4\u4e92\u7279\u6027\u3001\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\u548c\u81ea\u9002\u5e94\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5c06LoCoBench\u76848000\u4e2a\u573a\u666f\u6269\u5c55\u4e3a\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u73af\u5883\uff0c\u63d0\u4f9b8\u4e2a\u4e13\u4e1a\u5de5\u5177\uff08\u6587\u4ef6\u64cd\u4f5c\u3001\u641c\u7d22\u3001\u4ee3\u7801\u5206\u6790\uff09\uff0c\u572810K\u52301M token\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u8303\u56f4\u5185\u8bc4\u4f30\uff0c\u4f7f\u75289\u4e2a\u7406\u89e3\u5ea6\u548c\u6548\u7387\u7ef4\u5ea6\u7684\u6307\u6807\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0\uff1a(1)\u667a\u80fd\u4f53\u8868\u73b0\u51fa\u663e\u8457\u7684\u957f\u4e0a\u4e0b\u6587\u9c81\u68d2\u6027\uff1b(2)\u7406\u89e3\u5ea6\u4e0e\u6548\u7387\u5b58\u5728\u8d1f\u76f8\u5173\u7684\u6743\u8861\u5173\u7cfb\uff1b(3)\u4e0d\u540c\u6a21\u578b\u95f4\u7684\u5bf9\u8bdd\u6548\u7387\u5dee\u5f02\u5de8\u5927\uff0c\u6218\u7565\u6027\u7684\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\u533a\u5206\u4e86\u9ad8\u6027\u80fd\u667a\u80fd\u4f53\u3002", "conclusion": "\u4f5c\u4e3a\u9996\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u957f\u4e0a\u4e0b\u6587LLM\u667a\u80fd\u4f53\u57fa\u51c6\uff0cLoCoBench-Agent\u4e3a\u6d4b\u91cf\u667a\u80fd\u4f53\u80fd\u529b\u3001\u8bc6\u522b\u6027\u80fd\u5dee\u8ddd\u548c\u63a8\u8fdb\u5927\u89c4\u6a21\u81ea\u4e3b\u8f6f\u4ef6\u5f00\u53d1\u5efa\u7acb\u4e86\u4e25\u8c28\u57fa\u7840\u3002"}}
{"id": "2511.14002", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.14002", "abs": "https://arxiv.org/abs/2511.14002", "authors": ["Chengpeng Li", "Farnaz Behrang", "August Shi", "Peng Liu"], "title": "FlakyGuard: Automatically Fixing Flaky Tests at Industry Scale", "comment": "To appear in ASE 2025", "summary": "Flaky tests that non-deterministically pass or fail waste developer time and slow release cycles. While large language models (LLMs) show promise for automatically repairing flaky tests, existing approaches like FlakyDoctor fail in industrial settings due to the context problem: providing either too little context (missing critical production code) or too much context (overwhelming the LLM with irrelevant information). We present FlakyGuard, which addresses this problem by treating code as a graph structure and using selective graph exploration to find only the most relevant context. Evaluation on real-world flaky tests from industrial repositories shows that FlakyGuard repairs 47.6 % of reproducible flaky tests with 51.8 % of the fixes accepted by developers. Besides it outperforms state-of-the-art approaches by at least 22 % in repair success rate. Developer surveys confirm that 100 % find FlakyGuard's root cause explanations useful.", "AI": {"tldr": "FlakyGuard\u901a\u8fc7\u5c06\u4ee3\u7801\u89c6\u4e3a\u56fe\u7ed3\u6784\u5e76\u4f7f\u7528\u9009\u62e9\u6027\u56fe\u63a2\u7d22\u6765\u627e\u5230\u6700\u76f8\u5173\u7684\u4e0a\u4e0b\u6587\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u4fee\u590d\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u65f6\u4e0a\u4e0b\u6587\u8fc7\u591a\u6216\u8fc7\u5c11\u7684\u95ee\u9898\u3002", "motivation": "\u4e0d\u7a33\u5b9a\u7684\u6d4b\u8bd5\u4f1a\u6d6a\u8d39\u5f00\u53d1\u8005\u65f6\u95f4\u5e76\u51cf\u7f13\u53d1\u5e03\u5468\u671f\uff0c\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7531\u4e8e\u4e0a\u4e0b\u6587\u95ee\u9898\uff08\u63d0\u4f9b\u592a\u5c11\u6216\u592a\u591a\u4e0a\u4e0b\u6587\uff09\u800c\u5931\u8d25\u3002", "method": "\u5c06\u4ee3\u7801\u89c6\u4e3a\u56fe\u7ed3\u6784\uff0c\u4f7f\u7528\u9009\u62e9\u6027\u56fe\u63a2\u7d22\u6765\u627e\u5230\u6700\u76f8\u5173\u7684\u4e0a\u4e0b\u6587\uff0c\u4ece\u800c\u4e3aLLM\u63d0\u4f9b\u9002\u5f53\u7684\u4fee\u590d\u4fe1\u606f\u3002", "result": "\u5728\u5de5\u4e1a\u4ed3\u5e93\u7684\u771f\u5b9e\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u4e2d\uff0cFlakyGuard\u4fee\u590d\u4e8647.6%\u7684\u53ef\u91cd\u73b0\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\uff0c\u5176\u4e2d51.8%\u7684\u4fee\u590d\u88ab\u5f00\u53d1\u8005\u63a5\u53d7\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u81f3\u5c11\u63d0\u9ad822%\u7684\u4fee\u590d\u6210\u529f\u7387\u3002", "conclusion": "FlakyGuard\u901a\u8fc7\u9009\u62e9\u6027\u56fe\u63a2\u7d22\u6709\u6548\u89e3\u51b3\u4e86\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u4fee\u590d\u4e2d\u7684\u4e0a\u4e0b\u6587\u95ee\u9898\uff0c\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5f00\u53d1\u8005\u5bf9\u5176\u6839\u56e0\u89e3\u91ca\u7ed9\u4e88100%\u7684\u6b63\u9762\u8bc4\u4ef7\u3002"}}
{"id": "2511.13782", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13782", "abs": "https://arxiv.org/abs/2511.13782", "authors": ["Xiaoxing Lian", "Aidong Yang", "Jun Zhu", "Peng Wang", "Yue Zhang"], "title": "Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models", "comment": "10 pages,a detail and effective benchmark for spatial reasoning", "summary": "Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial reasoning:a fundamental component of human cognition that includes mental rotation, navigation, and spatial relationship comprehension remains a significant challenge for current advanced VLMs. We hypothesize that imagination, the internal simulation of spatial states, is the dominant reasoning mechanism within a spatial world model. To test this hypothesis and systematically probe current VLM spatial reasoning mechanisms, we introduce SpatiaLite, a fully synthetic benchmark that jointly measures spatial reasoning accuracy and reasoning efficiency. Comprehensive experiments reveal three key findings. First, advanced VLMs predominantly rely on linguistic representations for reasoning and imagination, resulting in significant deficiencies on visual centric tasks that demand perceptual spatial relations and 3D geometry transformations such as mental rotation or projection prediction. Second, advanced VLMs exhibit severe inefficiency in their current spatial reasoning mechanisms, with token usage growing rapidly as transformation complexity increases. Third, we propose an Imagery Driven Framework (IDF) for data synthesis and training, which can implicitly construct an internal world model that is critical for spatial reasoning in VLMs. Building on SpatiaLite, this work delineates the spatial reasoning limits and patterns of advanced VLMs, identifies key shortcomings, and informs future advances", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SpatiaLite\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u8bed\u8a00\u8868\u5f81\uff0c\u5728\u89c6\u89c9\u4e2d\u5fc3\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u8db3\u4e14\u6548\u7387\u4f4e\u4e0b\uff0c\u5e76\u63d0\u51fa\u4e86Imagery Driven Framework\u6765\u6539\u8fdb\u3002", "motivation": "\u5f53\u524d\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\u3001\u95ee\u9898\u89e3\u51b3\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u7a7a\u95f4\u63a8\u7406\u8fd9\u4e00\u4eba\u7c7b\u8ba4\u77e5\u7684\u57fa\u672c\u80fd\u529b\u4e0a\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u4f5c\u8005\u5047\u8bbe\u60f3\u8c61\u529b\u662f\u7a7a\u95f4\u4e16\u754c\u6a21\u578b\u4e2d\u7684\u4e3b\u5bfc\u63a8\u7406\u673a\u5236\u3002", "method": "\u5f15\u5165SpatiaLite\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8054\u5408\u6d4b\u91cf\u7a7a\u95f4\u63a8\u7406\u51c6\u786e\u6027\u548c\u6548\u7387\uff1b\u63d0\u51faImagery Driven Framework\u7528\u4e8e\u6570\u636e\u5408\u6210\u548c\u8bad\u7ec3\uff0c\u9690\u5f0f\u6784\u5efa\u5185\u90e8\u4e16\u754c\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u7ed3\u679c\uff1a1\uff09\u5148\u8fdbVLMs\u4e3b\u8981\u4f9d\u8d56\u8bed\u8a00\u8868\u5f81\uff0c\u5728\u9700\u8981\u611f\u77e5\u7a7a\u95f4\u5173\u7cfb\u548c3D\u51e0\u4f55\u53d8\u6362\u7684\u89c6\u89c9\u4e2d\u5fc3\u4efb\u52a1\u4e0a\u8868\u73b0\u663e\u8457\u4e0d\u8db3\uff1b2\uff09\u5f53\u524d\u7a7a\u95f4\u63a8\u7406\u673a\u5236\u6548\u7387\u4e25\u91cd\u4f4e\u4e0b\uff0ctoken\u4f7f\u7528\u968f\u53d8\u6362\u590d\u6742\u5ea6\u5feb\u901f\u589e\u52a0\uff1b3\uff09IDF\u6846\u67b6\u80fd\u6709\u6548\u6784\u5efa\u5185\u90e8\u4e16\u754c\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u660e\u786e\u4e86\u5148\u8fdbVLMs\u7684\u7a7a\u95f4\u63a8\u7406\u5c40\u9650\u548c\u6a21\u5f0f\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u7f3a\u9677\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u6307\u5bfc\u65b9\u5411\u3002"}}
{"id": "2511.14022", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14022", "abs": "https://arxiv.org/abs/2511.14022", "authors": ["Pradeep Kumar Sharma", "Ishaan Puri", "Mantinder Jit Singh", "Swapnil Shivaprasad", "Hritvik Shrivastava"], "title": "Keeping Code-Aware LLMs Fresh: Full Refresh, In-Context Deltas, and Incremental Fine-Tuning", "comment": null, "summary": "Modern codebases evolve continuously: files are renamed or deleted; public APIs drift; behavior shifts within otherwise familiar modules. A model trained yesterday to map a developer's natural-language question to the exact set of repository file paths that matter will degrade tomorrow, even if the questions themselves look unchanged. In this paper we study, at system scale and across several widely used repositories, how to keep such a model fresh without surrendering retention on earlier code. We frame freshness as a form of domain drift between a base snapshot and the current HEAD, and we compare three families of update strategies: (A) Full Refresh, retraining the entire model at the new snapshot; (B) In-Context Learning (ICL) that injects recent deltas (raw git diffs or concise English summaries) at inference; and (C) Incremental Fine-Tuning (Inc-FT) on delta-derived training sets, with carefully controlled NEW:OLD mixing to mitigate catastrophic forgetting. We contribute an alias-aware evaluation protocol that credits rename while never rewarding deleted paths, and a practical Forgetting Probe that quantifies residual emissions of obsolete paths. Across Flask, SQLAlchemy, Pandas, and Poetry, Inc-FT with old-aware mixes delivers the best overall balance on mixed sets, ICL with English delta summaries delivers the fastest new-code lift when training is not feasible, and Full Refresh remains the ceiling when maximum NEW accuracy matters. We also compare Git-diff Inc-FT to full-file Inc-FT, showing that diffs excel in rename/delete-heavy windows while full-file context wins in behavior-change-heavy windows.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u4ee3\u7801\u5e93\u6301\u7eed\u6f14\u5316\u7684\u80cc\u666f\u4e0b\uff0c\u5982\u4f55\u4fdd\u6301\u4ee3\u7801\u641c\u7d22\u6a21\u578b\u7684\u65b0\u9c9c\u5ea6\u800c\u4e0d\u4e22\u5931\u5bf9\u65e7\u4ee3\u7801\u7684\u8bb0\u5fc6\u3002\u6bd4\u8f83\u4e86\u4e09\u79cd\u66f4\u65b0\u7b56\u7565\uff1a\u5b8c\u5168\u5237\u65b0\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u589e\u91cf\u5fae\u8c03\uff0c\u53d1\u73b0\u589e\u91cf\u5fae\u8c03\u5728\u5e73\u8861\u65b0\u65e7\u4ee3\u7801\u6027\u80fd\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u73b0\u4ee3\u4ee3\u7801\u5e93\u6301\u7eed\u6f14\u5316\uff0c\u5bfc\u81f4\u8bad\u7ec3\u597d\u7684\u4ee3\u7801\u641c\u7d22\u6a21\u578b\u6027\u80fd\u968f\u65f6\u95f4\u9000\u5316\u3002\u9700\u8981\u7814\u7a76\u5982\u4f55\u5728\u4fdd\u6301\u5bf9\u65e7\u4ee3\u7801\u8bb0\u5fc6\u7684\u540c\u65f6\uff0c\u8ba9\u6a21\u578b\u9002\u5e94\u4ee3\u7801\u53d8\u5316\u3002", "method": "\u5c06\u4ee3\u7801\u65b0\u9c9c\u5ea6\u89c6\u4e3a\u9886\u57df\u6f02\u79fb\u95ee\u9898\uff0c\u6bd4\u8f83\u4e09\u79cd\u66f4\u65b0\u7b56\u7565\uff1a(A)\u5b8c\u5168\u5237\u65b0\u6a21\u578b\uff1b(B)\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u5728\u63a8\u7406\u65f6\u6ce8\u5165\u6700\u8fd1\u7684\u4ee3\u7801\u53d8\u66f4\uff1b(C)\u589e\u91cf\u5fae\u8c03\uff0c\u4f7f\u7528\u53d8\u66f4\u751f\u6210\u7684\u8bad\u7ec3\u96c6\u8fdb\u884c\u5fae\u8c03\uff0c\u63a7\u5236\u65b0\u65e7\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\u4ee5\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\u3002", "result": "\u5728Flask\u3001SQLAlchemy\u3001Pandas\u548cPoetry\u7b49\u9879\u76ee\u4e2d\uff0c\u589e\u91cf\u5fae\u8c03\u914d\u5408\u65e7\u4ee3\u7801\u611f\u77e5\u7684\u6df7\u5408\u7b56\u7565\u5728\u6df7\u5408\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\uff1b\u4e0a\u4e0b\u6587\u5b66\u4e60\u5728\u65e0\u6cd5\u8bad\u7ec3\u65f6\u80fd\u6700\u5feb\u63d0\u5347\u65b0\u4ee3\u7801\u6027\u80fd\uff1b\u5b8c\u5168\u5237\u65b0\u5728\u8ffd\u6c42\u6700\u5927\u65b0\u4ee3\u7801\u51c6\u786e\u7387\u65f6\u4ecd\u662f\u4e0a\u9650\u3002", "conclusion": "\u589e\u91cf\u5fae\u8c03\u662f\u4fdd\u6301\u4ee3\u7801\u641c\u7d22\u6a21\u578b\u65b0\u9c9c\u5ea6\u7684\u6700\u4f73\u5e73\u8861\u7b56\u7565\uff0c\u4e0a\u4e0b\u6587\u5b66\u4e60\u5728\u8bad\u7ec3\u4e0d\u53ef\u884c\u65f6\u662f\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5b8c\u5168\u5237\u65b0\u5728\u9700\u8981\u6700\u9ad8\u65b0\u4ee3\u7801\u51c6\u786e\u7387\u65f6\u4ecd\u662f\u9ec4\u91d1\u6807\u51c6\u3002"}}
{"id": "2511.13771", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13771", "abs": "https://arxiv.org/abs/2511.13771", "authors": ["Shaowei Guan", "Yu Zhai", "Zhengyu Zhang", "Yanze Wang", "Hin Chi Kwok"], "title": "ExplainableGuard: Interpretable Adversarial Defense for Large Language Models Using Chain-of-Thought Reasoning", "comment": "9 pages, 2 figures", "summary": "Large Language Models (LLMs) are increasingly vulnerable to adversarial attacks that can subtly manipulate their outputs. While various defense mechanisms have been proposed, many operate as black boxes, lacking transparency in their decision-making. This paper introduces ExplainableGuard, an interpretable adversarial defense framework leveraging the chain-of-thought (CoT) reasoning capabilities of DeepSeek-Reasoner. Our approach not only detects and neutralizes adversarial perturbations in text but also provides step-by-step explanations for each defense action. We demonstrate how tailored CoT prompts guide the LLM to perform a multi-faceted analysis (character, word, structural, and semantic) and generate a purified output along with a human-readable justification. Preliminary results on the GLUE Benchmark and IMDB Movie Reviews dataset show promising defense efficacy. Additionally, a human evaluation study reveals that ExplainableGuard's explanations outperform ablated variants in clarity, specificity, and actionability, with a 72.5% deployability-trust rating, underscoring its potential for more trustworthy LLM deployments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ExplainableGuard\u6846\u67b6\uff0c\u5229\u7528DeepSeek-Reasoner\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u80fd\u529b\u6765\u68c0\u6d4b\u548c\u4e2d\u548c\u6587\u672c\u4e2d\u7684\u5bf9\u6297\u6027\u6270\u52a8\uff0c\u5e76\u63d0\u4f9b\u9010\u6b65\u89e3\u91ca\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u73b0\u6709\u9632\u5fa1\u673a\u5236\u591a\u4e3a\u9ed1\u76d2\uff0c\u7f3a\u4e4f\u51b3\u7b56\u900f\u660e\u5ea6\u3002", "method": "\u4f7f\u7528\u5b9a\u5236\u5316\u7684\u601d\u7ef4\u94fe\u63d0\u793a\u5f15\u5bfcLLM\u8fdb\u884c\u591a\u5c42\u9762\u5206\u6790\uff08\u5b57\u7b26\u3001\u8bcd\u6c47\u3001\u7ed3\u6784\u548c\u8bed\u4e49\uff09\uff0c\u751f\u6210\u51c0\u5316\u8f93\u51fa\u548c\u4eba\u7c7b\u53ef\u8bfb\u7684\u6b63\u5f53\u5316\u89e3\u91ca\u3002", "result": "\u5728GLUE\u57fa\u51c6\u548cIMDB\u7535\u5f71\u8bc4\u8bba\u6570\u636e\u96c6\u4e0a\u663e\u793a\u51fa\u6709\u524d\u666f\u7684\u9632\u5fa1\u6548\u679c\uff0c\u4eba\u7c7b\u8bc4\u4f30\u663e\u793a\u89e3\u91ca\u5728\u6e05\u6670\u5ea6\u3001\u7279\u5f02\u6027\u548c\u53ef\u64cd\u4f5c\u6027\u65b9\u9762\u4f18\u4e8e\u6d88\u878d\u53d8\u4f53\uff0c\u90e8\u7f72\u53ef\u4fe1\u5ea6\u8bc4\u5206\u4e3a72.5%\u3002", "conclusion": "ExplainableGuard\u6846\u67b6\u5177\u6709\u6784\u5efa\u66f4\u53ef\u4fe1LLM\u90e8\u7f72\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.14062", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14062", "abs": "https://arxiv.org/abs/2511.14062", "authors": ["Shenglin Zhang", "Ziang Chen", "Zijing Que", "Yilun Liu", "Yongqian Sun", "Sicheng Wei", "Dan Pei", "Hailin Li"], "title": "LogPurge: Log Data Purification for Anomaly Detection via Rule-Enhanced Filtering", "comment": null, "summary": "Log anomaly detection, which is critical for identifying system failures and preempting security breaches, detects irregular patterns within large volumes of log data, and impacts domains such as service reliability, performance optimization, and database log analysis. Modern log anomaly detection methods rely on training deep learning models on clean, anomaly-free log sequences. However, obtaining such clean log data requires costly and tedious human labeling, and existing automatic cleaning methods fail to fully integrate the specific characteristics and actual semantics of logs in their purification process. In this paper, we propose a cost-aware, rule-enhanced purification framework, LogPurge, that automatically selects a sufficient subset of normal log sequences from contamination log sequences to train a anomaly detection model. Our approach involves a two-stage filtering algorithm: In the first stage, we use a large language model (LLM) to remove clustered anomalous patterns and enhance system rules to improve LLM's understanding of system logs; in the second stage, we utilize a divide-and-conquer strategy that decomposes the remaining contaminated regions into smaller subproblems, allowing each to be effectively purified through the first stage procedure. Our experiments, conducted on two public datasets and one industrial dataset, show that our method significantly removes an average of 98.74% of anomalies while retaining 82.39% of normal samples. Compared to the latest unsupervised log sample selection algorithms, our method achieves F-1 score improvements of 35.7% and 84.11% on the public datasets, and an impressive 149.72% F-1 improvement on the private dataset, demonstrating the effectiveness of our approach.", "AI": {"tldr": "\u63d0\u51faLogPurge\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8fc7\u6ee4\u7b97\u6cd5\u81ea\u52a8\u4ece\u53d7\u6c61\u67d3\u7684\u65e5\u5fd7\u5e8f\u5217\u4e2d\u9009\u62e9\u8db3\u591f\u7684\u6b63\u5e38\u5b50\u96c6\u6765\u8bad\u7ec3\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u9700\u8981\u5e72\u51c0\u65e0\u5f02\u5e38\u7684\u65e5\u5fd7\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u83b7\u53d6\u8fd9\u6837\u7684\u6570\u636e\u9700\u8981\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8\uff0c\u73b0\u6709\u81ea\u52a8\u6e05\u6d17\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u6574\u5408\u65e5\u5fd7\u7684\u7279\u5b9a\u7279\u5f81\u548c\u5b9e\u9645\u8bed\u4e49\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8fc7\u6ee4\u7b97\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u53bb\u9664\u805a\u7c7b\u5f02\u5e38\u6a21\u5f0f\u5e76\u589e\u5f3a\u7cfb\u7edf\u89c4\u5219\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u5206\u6cbb\u7b56\u7565\u5c06\u5269\u4f59\u6c61\u67d3\u533a\u57df\u5206\u89e3\u4e3a\u66f4\u5c0f\u7684\u5b50\u95ee\u9898\uff0c\u901a\u8fc7\u7b2c\u4e00\u9636\u6bb5\u7a0b\u5e8f\u6709\u6548\u51c0\u5316\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5e73\u5747\u79fb\u966498.74%\u7684\u5f02\u5e38\uff0c\u540c\u65f6\u4fdd\u755982.39%\u7684\u6b63\u5e38\u6837\u672c\u3002\u4e0e\u6700\u65b0\u65e0\u76d1\u7763\u65e5\u5fd7\u6837\u672c\u9009\u62e9\u7b97\u6cd5\u76f8\u6bd4\uff0c\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0aF-1\u5206\u6570\u5206\u522b\u63d0\u9ad835.7%\u548c84.11%\uff0c\u5728\u79c1\u6709\u6570\u636e\u96c6\u4e0aF-1\u5206\u6570\u63d0\u9ad8149.72%\u3002", "conclusion": "LogPurge\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u65e5\u5fd7\u6570\u636e\u81ea\u52a8\u51c0\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\u3002"}}
{"id": "2511.13777", "categories": ["cs.CR", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.13777", "abs": "https://arxiv.org/abs/2511.13777", "authors": ["Pierre-Olivier Goffard", "Hansjoerg Albrecher", "Jean-Pierre Fouque"], "title": "Hashpower allocation in Pay-per-Share blockchain mining pools", "comment": null, "summary": "Mining blocks in a blockchain using the \\textit{Proof-of-Work} consensus protocol involves significant risk, as network participants face continuous operational costs while earning infrequent capital gains upon successfully mining a block. A common risk mitigation strategy is to join a mining pool, which combines the computing resources of multiple miners to provide a more stable income. This article examines a Pay-per-Share (PPS) reward system, where the pool manager can adjust both the share difficulty and the management fee. Using a simplified wealth model for miners, we explore how miners should allocate their computing resources among different mining pools, considering the trade-off between risk transfer to the manager and management fees.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u6bd4\u7279\u5e01\u6316\u77ff\u4e2d\u7684\u98ce\u9669\u7ba1\u7406\u548c\u77ff\u6c60\u9009\u62e9\u7b56\u7565\uff0c\u5206\u6790PPS\u5956\u52b1\u7cfb\u7edf\u4e2d\u77ff\u5de5\u5982\u4f55\u5728\u98ce\u9669\u8f6c\u79fb\u548c\u7ba1\u7406\u8d39\u4e4b\u95f4\u6743\u8861\uff0c\u4ee5\u6700\u4f18\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u3002", "motivation": "\u6bd4\u7279\u5e01\u6316\u77ff\u91c7\u7528\u5de5\u4f5c\u91cf\u8bc1\u660e\u534f\u8bae\uff0c\u77ff\u5de5\u9762\u4e34\u6301\u7eed\u7684\u8fd0\u8425\u6210\u672c\u548c\u4e0d\u786e\u5b9a\u7684\u6536\u76ca\u98ce\u9669\u3002\u52a0\u5165\u77ff\u6c60\u662f\u5e38\u89c1\u7684\u98ce\u9669\u7f13\u89e3\u7b56\u7565\uff0c\u4f46\u9700\u8981\u7814\u7a76\u77ff\u5de5\u5982\u4f55\u5728\u4e0d\u540c\u7684\u77ff\u6c60\u95f4\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u4f7f\u7528\u7b80\u5316\u7684\u77ff\u5de5\u8d22\u5bcc\u6a21\u578b\uff0c\u7814\u7a76PPS\u5956\u52b1\u7cfb\u7edf\uff0c\u5206\u6790\u77ff\u6c60\u7ba1\u7406\u8005\u5982\u4f55\u8c03\u6574\u4efd\u989d\u96be\u5ea6\u548c\u7ba1\u7406\u8d39\uff0c\u4ee5\u53ca\u77ff\u5de5\u5982\u4f55\u5728\u4e0d\u540c\u77ff\u6c60\u95f4\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u77ff\u5de5\u9700\u8981\u5728\u98ce\u9669\u8f6c\u79fb\u7ed9\u77ff\u6c60\u7ba1\u7406\u8005\u548c\u652f\u4ed8\u7ba1\u7406\u8d39\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\uff0c\u4ee5\u4f18\u5316\u8ba1\u7b97\u8d44\u6e90\u7684\u5206\u914d\u7b56\u7565\u3002", "conclusion": "\u77ff\u5de5\u5e94\u7efc\u5408\u8003\u8651\u98ce\u9669\u8f6c\u79fb\u548c\u7ba1\u7406\u8d39\u6210\u672c\uff0c\u5728\u4e0d\u540c\u77ff\u6c60\u95f4\u5408\u7406\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u4ee5\u5b9e\u73b0\u6536\u76ca\u6700\u5927\u5316\u548c\u98ce\u9669\u6700\u5c0f\u5316\u3002"}}
{"id": "2511.14215", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.14215", "abs": "https://arxiv.org/abs/2511.14215", "authors": ["Malik Muhammad Umer"], "title": "A Practical Implementation of Customized Scrum-Based Agile Framework in Aerospace Software Development Under DO-178C Constraints", "comment": null, "summary": "The increasing complexity of aerospace systems requires development processes that balance agility with stringent safety and certification demands. This study presents an empirically validated Scrum-based Agile framework tailored for DO-178C compliant, safety-critical aerospace software. The framework adapts core Scrum roles, artifacts, and events to meet certification, verification, and independence objectives. Key enhancements include a multi-disciplinary product ownership model, dual compliance-and-functionality acceptance criteria, independent testing and documentation teams, and dedicated certification liaisons. The approach was evaluated through two comparable aerospace projects-one using the customized Agile process and the other a traditional Waterfall model. Results showed significant improvements: a 76% reduction in Total Effort per Requirement, 75% faster Defect Detection, 78% faster Defect Resolution, and over 50% lower Defect Density, while maintaining full compliance with DO-178C Design Assurance Level A. These findings demonstrate that Agile practices and regulatory compliance can coexist effectively when supported by disciplined tailoring and proactive engagement with certification authorities. The study also notes challenges, including increased V&V effort due to recurring Sprint activities and refactoring inherent to iterative development. Nonetheless, it identifies substantial opportunities for further gains through workflow automation, CI/CD practices, and automated documentation, verification, and configuration management. Future research should expand validation of this framework across the aerospace domain and other safety-critical industries with similar certification requirements.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ecf\u8fc7\u5b9e\u8bc1\u9a8c\u8bc1\u7684\u57fa\u4e8eScrum\u7684\u654f\u6377\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u7b26\u5408DO-178C\u6807\u51c6\u7684\u5b89\u5168\u5173\u952e\u822a\u7a7a\u822a\u5929\u8f6f\u4ef6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5b9a\u5236\u5316\u89d2\u8272\u3001\u5de5\u4ef6\u548c\u4e8b\u4ef6\u6765\u6ee1\u8db3\u8ba4\u8bc1\u8981\u6c42\uff0c\u76f8\u6bd4\u4f20\u7edf\u7011\u5e03\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u548c\u7f3a\u9677\u7ba1\u7406\u80fd\u529b\u3002", "motivation": "\u822a\u7a7a\u822a\u5929\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u5728\u654f\u6377\u5f00\u53d1\u4e0e\u4e25\u683c\u7684\u5b89\u5168\u8ba4\u8bc1\u8981\u6c42\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002\u4f20\u7edf\u5f00\u53d1\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u5feb\u901f\u8fed\u4ee3\u548cDO-178C\u7b49\u4e25\u683c\u8ba4\u8bc1\u6807\u51c6\u7684\u8981\u6c42\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b9a\u5236\u7684Scrum\u654f\u6377\u6846\u67b6\uff0c\u5305\u62ec\u591a\u5b66\u79d1\u4ea7\u54c1\u6240\u6709\u6743\u6a21\u578b\u3001\u53cc\u91cd\u9a8c\u6536\u6807\u51c6\u3001\u72ec\u7acb\u6d4b\u8bd5\u548c\u6587\u6863\u56e2\u961f\u3001\u4e13\u95e8\u7684\u8ba4\u8bc1\u8054\u7edc\u4eba\u7b49\u5173\u952e\u589e\u5f3a\u529f\u80fd\u3002\u901a\u8fc7\u4e24\u4e2a\u53ef\u6bd4\u822a\u7a7a\u822a\u5929\u9879\u76ee\uff08\u4e00\u4e2a\u4f7f\u7528\u5b9a\u5236\u654f\u6377\u6d41\u7a0b\uff0c\u53e6\u4e00\u4e2a\u4f7f\u7528\u4f20\u7edf\u7011\u5e03\u6a21\u578b\uff09\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793a\u663e\u8457\u6539\u8fdb\uff1a\u6bcf\u4e2a\u9700\u6c42\u7684\u603b\u5de5\u4f5c\u91cf\u51cf\u5c1176%\uff0c\u7f3a\u9677\u68c0\u6d4b\u901f\u5ea6\u63d0\u9ad875%\uff0c\u7f3a\u9677\u89e3\u51b3\u901f\u5ea6\u63d0\u9ad878%\uff0c\u7f3a\u9677\u5bc6\u5ea6\u964d\u4f4e50%\u4ee5\u4e0a\uff0c\u540c\u65f6\u5b8c\u5168\u7b26\u5408DO-178C\u8bbe\u8ba1\u4fdd\u8bc1\u7b49\u7ea7A\u7684\u8981\u6c42\u3002", "conclusion": "\u654f\u6377\u5b9e\u8df5\u548c\u76d1\u7ba1\u5408\u89c4\u53ef\u4ee5\u5171\u5b58\uff0c\u4f46\u9700\u8981\u4e25\u683c\u7684\u5b9a\u5236\u5316\u548c\u4e0e\u8ba4\u8bc1\u673a\u6784\u7684\u4e3b\u52a8\u5408\u4f5c\u3002\u672a\u6765\u53ef\u901a\u8fc7\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u3001CI/CD\u5b9e\u8df5\u4ee5\u53ca\u81ea\u52a8\u5316\u6587\u6863\u3001\u9a8c\u8bc1\u548c\u914d\u7f6e\u7ba1\u7406\u83b7\u5f97\u8fdb\u4e00\u6b65\u6536\u76ca\u3002"}}
{"id": "2511.13781", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.13781", "abs": "https://arxiv.org/abs/2511.13781", "authors": ["Warda Usman", "Yixin Zou", "Daniel Zappala"], "title": "Human-Centered Threat Modeling in Practice: Lessons, Challenges, and Paths Forward", "comment": null, "summary": "Human-centered threat modeling (HCTM) is an emerging area within security and privacy research that focuses on how people define and navigate threats in various social, cultural, and technological contexts. While researchers increasingly approach threat modeling from a human-centered perspective, little is known about how they prepare for and engage with HCTM in practice. In this work, we conduct 23 semi-structured interviews with researchers to examine the state of HCTM, including how researchers design studies, elicit threats, and navigate values, constraints, and long-term goals. We find that HCTM is not a prescriptive process but a set of evolving practices shaped by relationships with participants, disciplinary backgrounds, and institutional structures. Researchers approach threat modeling through sustained groundwork and participant-centered inquiry, guided by values such as care, justice, and autonomy. They also face challenges including emotional strain, ethical dilemmas, and structural barriers that complicate efforts to translate findings into real-world impact. We conclude by identifying opportunities to advance HCTM through shared infrastructure, broader recognition of diverse contributions, and stronger mechanisms for translating findings into policy, design, and societal change.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc723\u4e2a\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u7814\u7a76\u4e86\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u5a01\u80c1\u5efa\u6a21(HCTM)\u5b9e\u8df5\u73b0\u72b6\uff0c\u53d1\u73b0HCTM\u4e0d\u662f\u89c4\u5b9a\u6027\u8fc7\u7a0b\u800c\u662f\u4e00\u5957\u53d7\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\u7684\u6f14\u5316\u5b9e\u8df5\uff0c\u7814\u7a76\u4eba\u5458\u9762\u4e34\u60c5\u611f\u538b\u529b\u3001\u4f26\u7406\u56f0\u5883\u548c\u7ed3\u6784\u969c\u788d\u7b49\u6311\u6218\u3002", "motivation": "\u867d\u7136\u7814\u7a76\u4eba\u5458\u8d8a\u6765\u8d8a\u591a\u5730\u4ece\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u89c6\u89d2\u8fdb\u884c\u5a01\u80c1\u5efa\u6a21\uff0c\u4f46\u5bf9\u5176\u5728\u5b9e\u8df5\u4e2d\u5982\u4f55\u51c6\u5907\u548c\u53c2\u4e0eHCTM\u77e5\u4e4b\u751a\u5c11\uff0c\u9700\u8981\u4e86\u89e3\u7814\u7a76\u4eba\u5458\u5982\u4f55\u8bbe\u8ba1\u7814\u7a76\u3001\u8bc6\u522b\u5a01\u80c1\u5e76\u5904\u7406\u4ef7\u503c\u89c2\u3001\u7ea6\u675f\u548c\u957f\u671f\u76ee\u6807\u3002", "method": "\u5bf923\u540d\u7814\u7a76\u4eba\u5458\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u8003\u5bdfHCTM\u7684\u73b0\u72b6\uff0c\u5305\u62ec\u7814\u7a76\u8bbe\u8ba1\u3001\u5a01\u80c1\u8bc6\u522b\u4ee5\u53ca\u4ef7\u503c\u89c2\u3001\u7ea6\u675f\u548c\u957f\u671f\u76ee\u6807\u7684\u5904\u7406\u65b9\u5f0f\u3002", "result": "\u53d1\u73b0HCTM\u662f\u4e00\u5957\u53d7\u53c2\u4e0e\u8005\u5173\u7cfb\u3001\u5b66\u79d1\u80cc\u666f\u548c\u5236\u5ea6\u7ed3\u6784\u5f71\u54cd\u7684\u6f14\u5316\u5b9e\u8df5\uff0c\u7814\u7a76\u4eba\u5458\u901a\u8fc7\u6301\u7eed\u7684\u57fa\u7840\u5de5\u4f5c\u548c\u4ee5\u53c2\u4e0e\u8005\u4e3a\u4e2d\u5fc3\u7684\u8c03\u67e5\u8fdb\u884c\u5a01\u80c1\u5efa\u6a21\uff0c\u9762\u4e34\u60c5\u611f\u538b\u529b\u3001\u4f26\u7406\u56f0\u5883\u548c\u7ed3\u6784\u969c\u788d\u7b49\u6311\u6218\u3002", "conclusion": "\u63d0\u51fa\u4e86\u901a\u8fc7\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u3001\u66f4\u5e7f\u6cdb\u8ba4\u53ef\u591a\u6837\u5316\u8d21\u732e\u4ee5\u53ca\u66f4\u5f3a\u6709\u529b\u7684\u5c06\u7814\u7a76\u6210\u679c\u8f6c\u5316\u4e3a\u653f\u7b56\u3001\u8bbe\u8ba1\u548c\u793e\u4f1a\u53d8\u9769\u7684\u673a\u5236\u6765\u63a8\u8fdbHCTM\u7684\u673a\u4f1a\u3002"}}
{"id": "2511.13852", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13852", "abs": "https://arxiv.org/abs/2511.13852", "authors": ["Anna Rodum Bj\u00f8ru", "Rafael Caba\u00f1as", "Helge Langseth", "Antonio Salmer\u00f3n"], "title": "Causal computations in Semi Markovian Structural Causal Models using divide and conquer", "comment": "36 pages, 7 figures, 1 appendix", "summary": "Recently, Bj\u00f8ru et al. proposed a novel divide-and-conquer algorithm for bounding counterfactual probabilities in structural causal models (SCMs). They assumed that the SCMs were learned from purely observational data, leading to an imprecise characterization of the marginal distributions of exogenous variables. Their method leveraged the canonical representation of structural equations to decompose a general SCM with high-cardinality exogenous variables into a set of sub-models with low-cardinality exogenous variables. These sub-models had precise marginals over the exogenous variables and therefore admitted efficient exact inference. The aggregated results were used to bound counterfactual probabilities in the original model. The approach was developed for Markovian models, where each exogenous variable affects only a single endogenous variable. In this paper, we investigate extending the methodology to \\textit{semi-Markovian} SCMs, where exogenous variables may influence multiple endogenous variables. Such models are capable of representing confounding relationships that Markovian models cannot. We illustrate the challenges of this extension using a minimal example, which motivates a set of alternative solution strategies. These strategies are evaluated both theoretically and through a computational study.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5c06Bj\u00f8ru\u7b49\u4eba\u63d0\u51fa\u7684\u53cd\u4e8b\u5b9e\u6982\u7387\u8fb9\u754c\u8ba1\u7b97\u65b9\u6cd5\u4ece\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u6269\u5c55\u5230\u534a\u9a6c\u5c14\u53ef\u592b\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u5916\u751f\u53d8\u91cf\u5f71\u54cd\u591a\u4e2a\u5185\u751f\u53d8\u91cf\u7684\u6311\u6218\u3002", "motivation": "Bj\u00f8ru\u7b49\u4eba\u7684\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff0c\u800c\u534a\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u80fd\u591f\u8868\u793a\u66f4\u590d\u6742\u7684\u6df7\u6dc6\u5173\u7cfb\uff0c\u56e0\u6b64\u9700\u8981\u6269\u5c55\u8be5\u65b9\u6cd5\u4ee5\u5904\u7406\u66f4\u4e00\u822c\u7684\u56e0\u679c\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u6700\u5c0f\u793a\u4f8b\u8bf4\u660e\u6269\u5c55\u6311\u6218\uff0c\u63d0\u51fa\u66ff\u4ee3\u89e3\u51b3\u65b9\u6848\u7b56\u7565\uff0c\u5e76\u8fdb\u884c\u7406\u8bba\u548c\u8ba1\u7b97\u8bc4\u4f30\u3002", "result": "\u5f00\u53d1\u4e86\u9488\u5bf9\u534a\u9a6c\u5c14\u53ef\u592b\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u7684\u53cd\u4e8b\u5b9e\u6982\u7387\u8fb9\u754c\u8ba1\u7b97\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u5916\u751f\u53d8\u91cf\u5f71\u54cd\u591a\u4e2a\u5185\u751f\u53d8\u91cf\u7684\u60c5\u51b5\u3002", "conclusion": "\u6210\u529f\u5c06\u53cd\u4e8b\u5b9e\u6982\u7387\u8fb9\u754c\u8ba1\u7b97\u65b9\u6cd5\u6269\u5c55\u5230\u534a\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff0c\u4e3a\u5904\u7406\u66f4\u590d\u6742\u7684\u56e0\u679c\u63a8\u65ad\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.14224", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.14224", "abs": "https://arxiv.org/abs/2511.14224", "authors": ["Anji Li", "Mingwei Liu", "Zhenxi Chen", "Zheng Pei", "Zike Li", "Dekun Dai", "Yanlin Wang", "Zibin Zheng"], "title": "KTester: Leveraging Domain and Testing Knowledge for More Effective LLM-based Test Generation", "comment": "13 pages, 11 figures", "summary": "Automated unit test generation using large language models (LLMs) holds great promise but often struggles with generating tests that are both correct and maintainable in real-world projects. This paper presents KTester, a novel framework that integrates project-specific knowledge and testing domain knowledge to enhance LLM-based test generation. Our approach first extracts project structure and usage knowledge through static analysis, which provides rich context for the model. It then employs a testing-domain-knowledge-guided separation of test case design and test method generation, combined with a multi-perspective prompting strategy that guides the LLM to consider diverse testing heuristics. The generated tests follow structured templates, improving clarity and maintainability. We evaluate KTester on multiple open-source projects, comparing it against state-of-the-art LLM-based baselines using automatic correctness and coverage metrics, as well as a human study assessing readability and maintainability. Results demonstrate that KTester significantly outperforms existing methods across six key metrics, improving execution pass rate by 5.69% and line coverage by 8.83% over the strongest baseline, while requiring less time and generating fewer test cases. Human evaluators also rate the tests produced by KTester significantly higher in terms of correctness, readability, and maintainability, confirming the practical advantages of our knowledge-driven framework.", "AI": {"tldr": "KTester\u662f\u4e00\u4e2a\u96c6\u6210\u9879\u76ee\u7279\u5b9a\u77e5\u8bc6\u548c\u6d4b\u8bd5\u9886\u57df\u77e5\u8bc6\u7684LLM\u6d4b\u8bd5\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u63d0\u53d6\u9879\u76ee\u7ed3\u6784\u548c\u4f7f\u7528\u77e5\u8bc6\uff0c\u91c7\u7528\u6d4b\u8bd5\u9886\u57df\u77e5\u8bc6\u5f15\u5bfc\u7684\u6d4b\u8bd5\u7528\u4f8b\u8bbe\u8ba1\u4e0e\u6d4b\u8bd5\u65b9\u6cd5\u751f\u6210\u5206\u79bb\u7b56\u7565\uff0c\u7ed3\u5408\u591a\u89c6\u89d2\u63d0\u793a\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u751f\u6210\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u5728\u771f\u5b9e\u9879\u76ee\u4e2d\u96be\u4ee5\u751f\u6210\u65e2\u6b63\u786e\u53c8\u53ef\u7ef4\u62a4\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u9700\u8981\u7ed3\u5408\u9879\u76ee\u7279\u5b9a\u77e5\u8bc6\u548c\u6d4b\u8bd5\u9886\u57df\u77e5\u8bc6\u6765\u63d0\u5347\u6d4b\u8bd5\u751f\u6210\u8d28\u91cf\u3002", "method": "KTester\u6846\u67b6\u9996\u5148\u901a\u8fc7\u9759\u6001\u5206\u6790\u63d0\u53d6\u9879\u76ee\u7ed3\u6784\u548c\u4f7f\u7528\u77e5\u8bc6\uff0c\u7136\u540e\u91c7\u7528\u6d4b\u8bd5\u9886\u57df\u77e5\u8bc6\u5f15\u5bfc\u7684\u6d4b\u8bd5\u7528\u4f8b\u8bbe\u8ba1\u4e0e\u6d4b\u8bd5\u65b9\u6cd5\u751f\u6210\u5206\u79bb\u7b56\u7565\uff0c\u7ed3\u5408\u591a\u89c6\u89d2\u63d0\u793a\u6280\u672f\u6307\u5bfcLLM\u8003\u8651\u591a\u6837\u5316\u7684\u6d4b\u8bd5\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u751f\u6210\u7684\u6d4b\u8bd5\u9075\u5faa\u7ed3\u6784\u5316\u6a21\u677f\u4ee5\u63d0\u9ad8\u6e05\u6670\u5ea6\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "result": "\u5728\u591a\u4e2a\u5f00\u6e90\u9879\u76ee\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cKTester\u5728\u516d\u4e2a\u5173\u952e\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684LLM\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6267\u884c\u901a\u8fc7\u7387\u63d0\u9ad85.69%\uff0c\u884c\u8986\u76d6\u7387\u63d0\u9ad88.83%\uff0c\u540c\u65f6\u9700\u8981\u66f4\u5c11\u65f6\u95f4\u5e76\u751f\u6210\u66f4\u5c11\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002\u4eba\u5de5\u8bc4\u4f30\u4e5f\u786e\u8ba4KTester\u751f\u6210\u7684\u6d4b\u8bd5\u5728\u6b63\u786e\u6027\u3001\u53ef\u8bfb\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u65b9\u9762\u8bc4\u5206\u66f4\u9ad8\u3002", "conclusion": "KTester\u8bc1\u660e\u4e86\u77e5\u8bc6\u9a71\u52a8\u6846\u67b6\u5728LLM\u6d4b\u8bd5\u751f\u6210\u4e2d\u7684\u5b9e\u9645\u4f18\u52bf\uff0c\u901a\u8fc7\u96c6\u6210\u9879\u76ee\u7279\u5b9a\u77e5\u8bc6\u548c\u6d4b\u8bd5\u9886\u57df\u77e5\u8bc6\uff0c\u80fd\u591f\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u3001\u66f4\u53ef\u7ef4\u62a4\u7684\u5355\u5143\u6d4b\u8bd5\u3002"}}
{"id": "2511.13789", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13789", "abs": "https://arxiv.org/abs/2511.13789", "authors": ["Haotian Jin", "Yang Li", "Haihui Fan", "Lin Shen", "Xiangfang Li", "Bo Li"], "title": "Uncovering and Aligning Anomalous Attention Heads to Defend Against NLP Backdoor Attacks", "comment": null, "summary": "Backdoor attacks pose a serious threat to the security of large language models (LLMs), causing them to exhibit anomalous behavior under specific trigger conditions. The design of backdoor triggers has evolved from fixed triggers to dynamic or implicit triggers. This increased flexibility in trigger design makes it challenging for defenders to identify their specific forms accurately. Most existing backdoor defense methods are limited to specific types of triggers or rely on an additional clean model for support. To address this issue, we propose a backdoor detection method based on attention similarity, enabling backdoor detection without prior knowledge of the trigger. Our study reveals that models subjected to backdoor attacks exhibit unusually high similarity among attention heads when exposed to triggers. Based on this observation, we propose an attention safety alignment approach combined with head-wise fine-tuning to rectify potentially contaminated attention heads, thereby effectively mitigating the impact of backdoor attacks. Extensive experimental results demonstrate that our method significantly reduces the success rate of backdoor attacks while preserving the model's performance on downstream tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u76f8\u4f3c\u6027\u7684\u540e\u95e8\u68c0\u6d4b\u65b9\u6cd5\uff0c\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\u5373\u53ef\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u540e\u95e8\u653b\u51fb\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u5b89\u5168\u5bf9\u9f50\u548c\u9010\u5934\u5fae\u8c03\u6765\u7f13\u89e3\u653b\u51fb\u5f71\u54cd\u3002", "motivation": "\u540e\u95e8\u653b\u51fb\u5bf9LLMs\u5b89\u5168\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5c40\u9650\u4e8e\u7279\u5b9a\u89e6\u53d1\u5668\u7c7b\u578b\u6216\u4f9d\u8d56\u989d\u5916\u5e72\u51c0\u6a21\u578b\u652f\u6301\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u89e6\u53d1\u5668\u5148\u9a8c\u77e5\u8bc6\u7684\u901a\u7528\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u6ce8\u610f\u529b\u76f8\u4f3c\u6027\u68c0\u6d4b\u540e\u95e8\u653b\u51fb\uff0c\u53d1\u73b0\u53d7\u653b\u51fb\u6a21\u578b\u5728\u89e6\u53d1\u6761\u4ef6\u4e0b\u6ce8\u610f\u529b\u5934\u95f4\u76f8\u4f3c\u5ea6\u5f02\u5e38\u9ad8\uff0c\u91c7\u7528\u6ce8\u610f\u529b\u5b89\u5168\u5bf9\u9f50\u548c\u9010\u5934\u5fae\u8c03\u6765\u4fee\u6b63\u53d7\u6c61\u67d3\u7684\u6ce8\u610f\u529b\u5934\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u540e\u95e8\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u548c\u7f13\u89e3LLMs\u4e2d\u7684\u540e\u95e8\u653b\u51fb\uff0c\u65e0\u9700\u89e6\u53d1\u5668\u5148\u9a8c\u77e5\u8bc6\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.13892", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13892", "abs": "https://arxiv.org/abs/2511.13892", "authors": ["Badhan Chandra Das", "Md Tasnim Jawad", "Md Jueal Mia", "M. Hadi Amini", "Yanzhao Wu"], "title": "Jailbreaking Large Vision Language Models in Intelligent Transportation Systems", "comment": null, "summary": "Large Vision Language Models (LVLMs) demonstrate strong capabilities in multimodal reasoning and many real-world applications, such as visual question answering. However, LVLMs are highly vulnerable to jailbreaking attacks. This paper systematically analyzes the vulnerabilities of LVLMs integrated in Intelligent Transportation Systems (ITS) under carefully crafted jailbreaking attacks. First, we carefully construct a dataset with harmful queries relevant to transportation, following OpenAI's prohibited categories to which the LVLMs should not respond. Second, we introduce a novel jailbreaking attack that exploits the vulnerabilities of LVLMs through image typography manipulation and multi-turn prompting. Third, we propose a multi-layered response filtering defense technique to prevent the model from generating inappropriate responses. We perform extensive experiments with the proposed attack and defense on the state-of-the-art LVLMs (both open-source and closed-source). To evaluate the attack method and defense technique, we use GPT-4's judgment to determine the toxicity score of the generated responses, as well as manual verification. Further, we compare our proposed jailbreaking method with existing jailbreaking techniques and highlight severe security risks involved with jailbreaking attacks with image typography manipulation and multi-turn prompting in the LVLMs integrated in ITS.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8d8a\u72f1\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u56fe\u50cf\u6392\u7248\u64cd\u7eb5\u548c\u591a\u8f6e\u63d0\u793a\u7684\u65b0\u578b\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u591a\u5c42\u54cd\u5e94\u8fc7\u6ee4\u9632\u5fa1\u6280\u672f\u3002", "motivation": "\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u7406\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7b49\u5173\u952e\u5e94\u7528\u4e2d\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u6613\u53d7\u8d8a\u72f1\u653b\u51fb\u5f71\u54cd\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u5b89\u5168\u5206\u6790\u3002", "method": "\u9996\u5148\u6784\u5efa\u4e86\u4e0e\u4ea4\u901a\u76f8\u5173\u7684\u6709\u5bb3\u67e5\u8be2\u6570\u636e\u96c6\uff1b\u7136\u540e\u63d0\u51fa\u901a\u8fc7\u56fe\u50cf\u6392\u7248\u64cd\u7eb5\u548c\u591a\u8f6e\u63d0\u793a\u7684\u65b0\u578b\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff1b\u6700\u540e\u8bbe\u8ba1\u4e86\u591a\u5c42\u54cd\u5e94\u8fc7\u6ee4\u9632\u5fa1\u6280\u672f\u6765\u9632\u6b62\u6a21\u578b\u751f\u6210\u4e0d\u5f53\u54cd\u5e94\u3002", "result": "\u5728\u5f00\u6e90\u548c\u95ed\u6e90\u7684\u6700\u65b0\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u4f7f\u7528GPT-4\u5224\u65ad\u548c\u4eba\u5de5\u9a8c\u8bc1\u8bc4\u4f30\u653b\u51fb\u65b9\u6cd5\u548c\u9632\u5fa1\u6280\u672f\u7684\u6bd2\u6027\u5f97\u5206\uff0c\u53d1\u73b0\u56fe\u50cf\u6392\u7248\u64cd\u7eb5\u548c\u591a\u8f6e\u63d0\u793a\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u8106\u5f31\u6027\uff0c\u63d0\u51fa\u7684\u653b\u51fb\u65b9\u6cd5\u6bd4\u73b0\u6709\u6280\u672f\u66f4\u6709\u6548\uff0c\u540c\u65f6\u9632\u5fa1\u6280\u672f\u80fd\u591f\u6709\u6548\u9632\u6b62\u4e0d\u5f53\u54cd\u5e94\u751f\u6210\uff0c\u5f3a\u8c03\u4e86\u5728\u5173\u952e\u5e94\u7528\u4e2d\u52a0\u5f3a\u6a21\u578b\u5b89\u5168\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.13808", "categories": ["cs.CR", "cs.LG", "cs.MS"], "pdf": "https://arxiv.org/pdf/2511.13808", "abs": "https://arxiv.org/abs/2511.13808", "authors": ["Edward Raff", "Ryan R. Curtin", "Derek Everett", "Robert J. Joyce", "James Holt"], "title": "Zipf-Gramming: Scaling Byte N-Grams Up to Production Sized Malware Corpora", "comment": "Published in CIKM 2025", "summary": "A classifier using byte n-grams as features is the only approach we have found fast enough to meet requirements in size (sub 2 MB), speed (multiple GB/s), and latency (sub 10 ms) for deployment in numerous malware detection scenarios. However, we've consistently found that 6-8 grams achieve the best accuracy on our production deployments but have been unable to deploy regularly updated models due to the high cost of finding the top-k most frequent n-grams over terabytes of executable programs. Because the Zipfian distribution well models the distribution of n-grams, we exploit its properties to develop a new top-k n-gram extractor that is up to $35\\times$ faster than the previous best alternative. Using our new Zipf-Gramming algorithm, we are able to scale up our production training set and obtain up to 30\\% improvement in AUC at detecting new malware. We show theoretically and empirically that our approach will select the top-k items with little error and the interplay between theory and engineering required to achieve these results.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aZipf-Gramming\u7684\u65b0\u7b97\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u63d0\u53d6\u5b57\u8282n-gram\u7279\u5f81\uff0c\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u5feb35\u500d\uff0c\u4f7f\u5f97\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u80fd\u591f\u90e8\u7f72\u5b9a\u671f\u66f4\u65b0\u7684\u6a21\u578b\uff0cAUC\u63d0\u5347\u8fbe30%\u3002", "motivation": "\u73b0\u6709\u7684\u5b57\u8282n-gram\u5206\u7c7b\u5668\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u5177\u6709\u5feb\u901f\u3001\u4f4e\u5ef6\u8fdf\u7684\u4f18\u52bf\uff0c\u4f46\u7531\u4e8e\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u65e0\u6cd5\u5b9a\u671f\u66f4\u65b0\u6a21\u578b\u3002\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u4eceTB\u7ea7\u53ef\u6267\u884c\u7a0b\u5e8f\u4e2d\u63d0\u53d6\u6700\u9891\u7e41\u7684n-gram\u3002", "method": "\u5229\u7528Zipf\u5206\u5e03\u7684\u6027\u8d28\u5f00\u53d1\u65b0\u7684top-k n-gram\u63d0\u53d6\u5668Zipf-Gramming\u7b97\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u548c\u5de5\u7a0b\u7ed3\u5408\u5b9e\u73b0\u9ad8\u6548\u7684\u7279\u5f81\u63d0\u53d6\u3002", "result": "\u65b0\u7b97\u6cd5\u6bd4\u4e4b\u524d\u6700\u4f73\u65b9\u6cd5\u5feb35\u500d\uff0c\u80fd\u591f\u6269\u5c55\u751f\u4ea7\u8bad\u7ec3\u96c6\uff0c\u5728\u68c0\u6d4b\u65b0\u6076\u610f\u8f6f\u4ef6\u65f6AUC\u63d0\u5347\u8fbe30%\u3002", "conclusion": "Zipf-Gramming\u7b97\u6cd5\u901a\u8fc7\u5229\u7528Zipf\u5206\u5e03\u7279\u6027\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5927\u89c4\u6a21n-gram\u63d0\u53d6\u7684\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7cfb\u7edf\u7684\u5b9e\u65f6\u66f4\u65b0\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.13942", "categories": ["cs.AI", "cs.DS", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.13942", "abs": "https://arxiv.org/abs/2511.13942", "authors": ["Daniel Weitekamp"], "title": "CORGI: Efficient Pattern Matching With Quadratic Guarantees", "comment": null, "summary": "Rule-based systems must solve complex matching problems within tight time constraints to be effective in real-time applications, such as planning and reactive control for AI agents, as well as low-latency relational database querying. Pattern-matching systems can encounter issues where exponential time and space are required to find matches for rules with many underconstrained variables, or which produce combinatorial intermediate partial matches (but are otherwise well-constrained). When online AI systems automatically generate rules from example-driven induction or code synthesis, they can easily produce worst-case matching patterns that slow or halt program execution by exceeding available memory. In our own work with cognitive systems that learn from example, we've found that aggressive forms of anti-unification-based generalization can easily produce these circumstances. To make these systems practical without hand-engineering constraints or succumbing to unpredictable failure modes, we introduce a new matching algorithm called CORGI (Collection-Oriented Relational Graph Iteration). Unlike RETE-based approaches, CORGI offers quadratic time and space guarantees for finding single satisficing matches, and the ability to iteratively stream subsequent matches without committing entire conflict sets to memory. CORGI differs from RETE in that it does not have a traditional $\u03b2$-memory for collecting partial matches. Instead, CORGI takes a two-step approach: a graph of grounded relations is built/maintained in a forward pass, and an iterator generates matches as needed by working backward through the graph. This approach eliminates the high-latency delays and memory overflows that can result from populating full conflict sets. In a performance evaluation, we demonstrate that CORGI significantly outperforms RETE implementations from SOAR and OPS5 on a simple combinatorial matching task.", "AI": {"tldr": "CORGI\u662f\u4e00\u79cd\u65b0\u7684\u6a21\u5f0f\u5339\u914d\u7b97\u6cd5\uff0c\u9488\u5bf9\u89c4\u5219\u7cfb\u7edf\u4e2d\u6307\u6570\u7ea7\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u63d0\u4f9b\u4e8c\u6b21\u65f6\u95f4\u7a7a\u95f4\u4fdd\u8bc1\uff0c\u901a\u8fc7\u4e24\u6b65\u6cd5\u907f\u514d\u4f20\u7edfRETE\u7b97\u6cd5\u7684\u5185\u5b58\u6ea2\u51fa\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5b9e\u65f6AI\u7cfb\u7edf\u548c\u6570\u636e\u5e93\u67e5\u8be2\u4e2d\u89c4\u5219\u5339\u914d\u7684\u6307\u6570\u7ea7\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f53AI\u7cfb\u7edf\u81ea\u52a8\u751f\u6210\u89c4\u5219\u65f6\u5bb9\u6613\u4ea7\u751f\u6700\u574f\u60c5\u51b5\u5339\u914d\u6a21\u5f0f\uff0c\u5bfc\u81f4\u7a0b\u5e8f\u6267\u884c\u7f13\u6162\u6216\u5185\u5b58\u6ea2\u51fa\u3002", "method": "\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a\u6b63\u5411\u6784\u5efa/\u7ef4\u62a4\u57fa\u7840\u5173\u7cfb\u56fe\uff0c\u53cd\u5411\u901a\u8fc7\u8fed\u4ee3\u5668\u6309\u9700\u751f\u6210\u5339\u914d\uff0c\u907f\u514d\u4f20\u7edfRETE\u7b97\u6cd5\u4e2d\u6536\u96c6\u90e8\u5206\u5339\u914d\u7684\u03b2\u5185\u5b58\u673a\u5236\u3002", "result": "\u5728\u6027\u80fd\u8bc4\u4f30\u4e2d\uff0cCORGI\u5728\u7b80\u5355\u7ec4\u5408\u5339\u914d\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8eSOAR\u548cOPS5\u7684RETE\u5b9e\u73b0\u3002", "conclusion": "CORGI\u7b97\u6cd5\u901a\u8fc7\u6d88\u9664\u586b\u5145\u5b8c\u6574\u51b2\u7a81\u96c6\u5e26\u6765\u7684\u9ad8\u5ef6\u8fdf\u548c\u5185\u5b58\u6ea2\u51fa\uff0c\u4f7f\u5b66\u4e60\u578b\u8ba4\u77e5\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u52a0\u53ef\u884c\u3002"}}
{"id": "2511.14435", "categories": ["cs.SE", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.14435", "abs": "https://arxiv.org/abs/2511.14435", "authors": ["Angelo Ferrando"], "title": "Watchdogs and Oracles: Runtime Verification Meets Large Language Models for Autonomous Systems", "comment": "In Proceedings FMAS 2025, arXiv:2511.13245", "summary": "Assuring the safety and trustworthiness of autonomous systems is particularly difficult when learning-enabled components and open environments are involved. Formal methods provide strong guarantees but depend on complete models and static assumptions. Runtime verification (RV) complements them by monitoring executions at run time and, in its predictive variants, by anticipating potential violations. Large language models (LLMs), meanwhile, excel at translating natural language into formal artefacts and recognising patterns in data, yet they remain error-prone and lack formal guarantees. This vision paper argues for a symbiotic integration of RV and LLMs. RV can serve as a guardrail for LLM-driven autonomy, while LLMs can extend RV by assisting specification capture, supporting anticipatory reasoning, and helping to handle uncertainty. We outline how this mutual reinforcement differs from existing surveys and roadmaps, discuss challenges and certification implications, and identify future research directions towards dependable autonomy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u8fd0\u884c\u65f6\u9a8c\u8bc1\uff08RV\uff09\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u5171\u751f\u96c6\u6210\uff0cRV\u4e3aLLM\u9a71\u52a8\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u5b89\u5168\u4fdd\u969c\uff0c\u800cLLMs\u5219\u901a\u8fc7\u8f85\u52a9\u89c4\u8303\u6355\u83b7\u3001\u652f\u6301\u9884\u671f\u63a8\u7406\u548c\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u6765\u6269\u5c55RV\u80fd\u529b\u3002", "motivation": "\u5728\u6d89\u53ca\u5b66\u4e60\u7ec4\u4ef6\u548c\u5f00\u653e\u73af\u5883\u7684\u81ea\u4e3b\u7cfb\u7edf\u4e2d\uff0c\u786e\u4fdd\u5b89\u5168\u6027\u548c\u53ef\u4fe1\u5ea6\u5177\u6709\u6311\u6218\u6027\u3002\u5f62\u5f0f\u5316\u65b9\u6cd5\u9700\u8981\u5b8c\u6574\u6a21\u578b\u548c\u9759\u6001\u5047\u8bbe\uff0c\u800cLLMs\u867d\u7136\u64c5\u957f\u6a21\u5f0f\u8bc6\u522b\u4f46\u7f3a\u4e4f\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u56e0\u6b64\u9700\u8981\u5c06\u4e24\u8005\u7ed3\u5408\u4ee5\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u81ea\u4e3b\u7cfb\u7edf\u3002", "method": "\u63d0\u51faRV\u4e0eLLMs\u7684\u5171\u751f\u96c6\u6210\u65b9\u6cd5\uff1aRV\u4f5c\u4e3aLLM\u9a71\u52a8\u81ea\u4e3b\u7cfb\u7edf\u7684\u9632\u62a4\u680f\uff0cLLMs\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u7ffb\u8bd1\u4e3a\u5f62\u5f0f\u5316\u6784\u4ef6\u3001\u8f85\u52a9\u89c4\u8303\u6355\u83b7\u3001\u652f\u6301\u9884\u671f\u63a8\u7406\u548c\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u6765\u589e\u5f3aRV\u80fd\u529b\u3002", "result": "\u8fd9\u79cd\u76f8\u4e92\u5f3a\u5316\u7684\u65b9\u6cd5\u4e0d\u540c\u4e8e\u73b0\u6709\u7684\u8c03\u67e5\u548c\u8def\u7ebf\u56fe\uff0c\u80fd\u591f\u4e3a\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u5b89\u5168\u4fdd\u969c\uff0c\u540c\u65f6\u5904\u7406\u5f62\u5f0f\u5316\u65b9\u6cd5\u548cLLMs\u5404\u81ea\u7684\u5c40\u9650\u6027\u3002", "conclusion": "RV\u4e0eLLMs\u7684\u5171\u751f\u96c6\u6210\u4e3a\u5b9e\u73b0\u53ef\u4fe1\u8d56\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u6311\u6218\u3001\u8ba4\u8bc1\u5f71\u54cd\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.13939", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.13939", "abs": "https://arxiv.org/abs/2511.13939", "authors": ["Paul Staat", "Christof Paar", "Swarun Kumar"], "title": "The Battle of Metasurfaces: Understanding Security in Smart Radio Environments", "comment": null, "summary": "Metasurfaces, or Reconfigurable Intelligent Surfaces (RISs), have emerged as a transformative technology for next-generation wireless systems, enabling digitally controlled manipulation of electromagnetic wave propagation. By turning the traditionally passive radio environment into a smart, programmable medium, metasurfaces promise advances in communication and sensing. However, metasurfaces also present a new security frontier: both attackers and defenders can exploit them to alter wireless propagation for their own advantage. While prior security research has primarily explored unilateral metasurface applications - empowering either attackers or defenders - this work investigates symmetric scenarios, where both sides possess comparable metasurface capabilities. Using both theoretical modeling and real-world experiments, we analyze how competing metasurfaces interact for diverse objectives, including signal power and sensing perception. Thereby, we present the first systematic study of context-agnostic metasurface-to-metasurface interactions and their implications for wireless security. Our results reveal that the outcome of metasurface \"battles\" depends on an interplay of timing, placement, algorithmic strategy, and hardware scale. Across multiple case studies in Wi-Fi environments, including wireless jamming, channel obfuscation for sensing and communication, and sensing spoofing, we demonstrate that opposing metasurfaces can substantially or fully negate each other's effects. By undermining previously proposed security and privacy schemes, our findings open new opportunities for designing resilient and high-assurance physical-layer systems in smart radio environments.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u5bf9\u79f0\u573a\u666f\u4e0b\u7ade\u4e89\u6027\u8d85\u8868\u9762\u7684\u76f8\u4e92\u4f5c\u7528\u53ca\u5176\u5bf9\u65e0\u7ebf\u5b89\u5168\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u5206\u6790\u53d1\u73b0\u5bf9\u6297\u6027\u8d85\u8868\u9762\u53ef\u4ee5\u76f8\u4e92\u62b5\u6d88\u6548\u679c\uff0c\u63ed\u793a\u4e86\u8d85\u8868\u9762\"\u6218\u6597\"\u7ed3\u679c\u53d6\u51b3\u4e8e\u65f6\u673a\u3001\u4f4d\u7f6e\u3001\u7b97\u6cd5\u7b56\u7565\u548c\u786c\u4ef6\u89c4\u6a21\u7b49\u56e0\u7d20\u3002", "motivation": "\u8d85\u8868\u9762\u6280\u672f\u5c06\u4f20\u7edf\u88ab\u52a8\u65e0\u7ebf\u7535\u73af\u5883\u8f6c\u53d8\u4e3a\u667a\u80fd\u53ef\u7f16\u7a0b\u4ecb\u8d28\uff0c\u4e3a\u901a\u4fe1\u548c\u611f\u77e5\u5e26\u6765\u8fdb\u6b65\uff0c\u4f46\u4e5f\u521b\u9020\u4e86\u65b0\u7684\u5b89\u5168\u524d\u6cbf\u3002\u5148\u524d\u7814\u7a76\u4e3b\u8981\u63a2\u7d22\u5355\u8fb9\u8d85\u8868\u9762\u5e94\u7528\uff0c\u800c\u672c\u7814\u7a76\u5173\u6ce8\u53cc\u65b9\u90fd\u62e5\u6709\u76f8\u5f53\u8d85\u8868\u9762\u80fd\u529b\u7684\u5bf9\u79f0\u573a\u666f\u3002", "method": "\u91c7\u7528\u7406\u8bba\u5efa\u6a21\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u7ade\u4e89\u6027\u8d85\u8868\u9762\u5728\u4e0d\u540c\u76ee\u6807\uff08\u5305\u62ec\u4fe1\u53f7\u529f\u7387\u548c\u611f\u77e5\u611f\u77e5\uff09\u4e0b\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u5728Wi-Fi\u73af\u5883\u4e2d\u8fdb\u884c\u591a\u4e2a\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u6297\u6027\u8d85\u8868\u9762\u53ef\u4ee5\u663e\u8457\u6216\u5b8c\u5168\u62b5\u6d88\u5f7c\u6b64\u7684\u6548\u679c\uff0c\u901a\u8fc7\u7834\u574f\u5148\u524d\u63d0\u51fa\u7684\u5b89\u5168\u548c\u9690\u79c1\u65b9\u6848\uff0c\u63ed\u793a\u4e86\u8d85\u8868\u9762\"\u6218\u6597\"\u7ed3\u679c\u53d6\u51b3\u4e8e\u65f6\u673a\u3001\u4f4d\u7f6e\u3001\u7b97\u6cd5\u7b56\u7565\u548c\u786c\u4ef6\u89c4\u6a21\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u5728\u667a\u80fd\u65e0\u7ebf\u7535\u73af\u5883\u4e2d\u8bbe\u8ba1\u5f39\u6027\u548c\u9ad8\u4fdd\u8bc1\u7684\u7269\u7406\u5c42\u7cfb\u7edf\u5f00\u8f9f\u4e86\u65b0\u673a\u4f1a\uff0c\u5f3a\u8c03\u4e86\u5728\u5bf9\u79f0\u8d85\u8868\u9762\u573a\u666f\u4e0b\u91cd\u65b0\u601d\u8003\u65e0\u7ebf\u5b89\u5168\u65b9\u6848\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2511.13970", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.13970", "abs": "https://arxiv.org/abs/2511.13970", "authors": ["Sanjay Acharjee", "Abir Khan Ratul", "Diego Patino", "Md Nazmus Sakib"], "title": "Scene Graph-Guided Generative AI Framework for Synthesizing and Evaluating Industrial Hazard Scenarios", "comment": null, "summary": "Training vision models to detect workplace hazards accurately requires realistic images of unsafe conditions that could lead to accidents. However, acquiring such datasets is difficult because capturing accident-triggering scenarios as they occur is nearly impossible. To overcome this limitation, this study presents a novel scene graph-guided generative AI framework that synthesizes photorealistic images of hazardous scenarios grounded in historical Occupational Safety and Health Administration (OSHA) accident reports. OSHA narratives are analyzed using GPT-4o to extract structured hazard reasoning, which is converted into object-level scene graphs capturing spatial and contextual relationships essential for understanding risk. These graphs guide a text-to-image diffusion model to generate compositionally accurate hazard scenes. To evaluate the realism and semantic fidelity of the generated data, a visual question answering (VQA) framework is introduced. Across four state-of-the-art generative models, the proposed VQA Graph Score outperforms CLIP and BLIP metrics based on entropy-based validation, confirming its higher discriminative sensitivity.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u573a\u666f\u56fe\u5f15\u5bfc\u7684\u751f\u6210AI\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790OSHA\u4e8b\u6545\u62a5\u544a\u751f\u6210\u903c\u771f\u7684\u5de5\u4f5c\u573a\u6240\u5371\u9669\u573a\u666f\u56fe\u50cf\uff0c\u5e76\u5f15\u5165VQA\u6846\u67b6\u8bc4\u4f30\u751f\u6210\u6570\u636e\u7684\u771f\u5b9e\u6027\u548c\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002", "motivation": "\u83b7\u53d6\u771f\u5b9e\u7684\u5de5\u4f5c\u573a\u6240\u5371\u9669\u573a\u666f\u56fe\u50cf\u6570\u636e\u96c6\u56f0\u96be\uff0c\u56e0\u4e3a\u6355\u6349\u5b9e\u9645\u53d1\u751f\u7684\u4e8b\u6545\u89e6\u53d1\u573a\u666f\u51e0\u4e4e\u4e0d\u53ef\u80fd\u3002", "method": "\u4f7f\u7528GPT-4o\u5206\u6790OSHA\u4e8b\u6545\u62a5\u544a\u63d0\u53d6\u7ed3\u6784\u5316\u5371\u9669\u63a8\u7406\uff0c\u8f6c\u6362\u4e3a\u5bf9\u8c61\u7ea7\u573a\u666f\u56fe\uff0c\u6307\u5bfc\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u751f\u6210\u6784\u56fe\u51c6\u786e\u7684\u5371\u9669\u573a\u666f\u3002", "result": "\u63d0\u51fa\u7684VQA\u56fe\u8bc4\u5206\u5728\u56db\u4e2a\u6700\u5148\u8fdb\u7684\u751f\u6210\u6a21\u578b\u4e2d\uff0c\u57fa\u4e8e\u71b5\u9a8c\u8bc1\u4f18\u4e8eCLIP\u548cBLIP\u6307\u6807\uff0c\u786e\u8ba4\u5176\u66f4\u9ad8\u7684\u5224\u522b\u654f\u611f\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5408\u6210\u903c\u771f\u7684\u5371\u9669\u573a\u666f\u56fe\u50cf\uff0c\u4e3a\u5de5\u4f5c\u573a\u6240\u5b89\u5168\u57f9\u8bad\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c6\u89c9\u6570\u636e\u3002"}}
{"id": "2511.14528", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.14528", "abs": "https://arxiv.org/abs/2511.14528", "authors": ["Tatiane Ornelas", "Allysson Allex Ara\u00fajo", "J\u00falia Ara\u00fajo", "Marina Ara\u00fajo", "Bianca Trinkenreich", "Marcos Kalinowski"], "title": "LLM-Assisted Thematic Analysis: Opportunities, Limitations, and Recommendations", "comment": null, "summary": "[Context] Large Language Models (LLMs) are increasingly used to assist qualitative research in Software Engineering (SE), yet the methodological implications of this usage remain underexplored. Their integration into interpretive processes such as thematic analysis raises fundamental questions about rigor, transparency, and researcher agency. [Objective] This study investigates how experienced SE researchers conceptualize the opportunities, risks, and methodological implications of integrating LLMs into thematic analysis. [Method] A reflective workshop with 25 ISERN researchers guided participants through structured discussions of LLM-assisted open coding, theme generation, and theme reviewing, using color-coded canvases to document perceived opportunities, limitations, and recommendations. [Results] Participants recognized potential efficiency and scalability gains, but highlighted risks related to bias, contextual loss, reproducibility, and the rapid evolution of LLMs. They also emphasized the need for prompting literacy and continuous human oversight. [Conclusion] Findings portray LLMs as tools that can support, but not substitute, interpretive analysis. The study contributes to ongoing community reflections on how LLMs can responsibly enhance qualitative research in SE.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5b9a\u6027\u7814\u7a76\u4e2d\u6574\u5408\u5927\u8bed\u8a00\u6a21\u578b\u5230\u4e3b\u9898\u5206\u6790\u65b9\u6cd5\u4e2d\u7684\u673a\u4f1a\u3001\u98ce\u9669\u548c\u65b9\u6cd5\u8bba\u5f71\u54cd\uff0c\u901a\u8fc7\u53cd\u601d\u6027\u5de5\u4f5c\u574a\u6536\u96c6\u4e8625\u4f4d\u7814\u7a76\u8005\u7684\u89c2\u70b9\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5b9a\u6027\u7814\u7a76\u4e2d\u7684\u4f7f\u7528\u65e5\u76ca\u589e\u591a\uff0c\u5176\u5728\u89e3\u91ca\u6027\u8fc7\u7a0b\u4e2d\u7684\u6574\u5408\u5bf9\u4e25\u8c28\u6027\u3001\u900f\u660e\u5ea6\u548c\u7814\u7a76\u8005\u80fd\u52a8\u6027\u4ea7\u751f\u4e86\u6839\u672c\u6027\u95ee\u9898\uff0c\u9700\u8981\u6df1\u5165\u63a2\u8ba8\u3002", "method": "\u7ec4\u7ec7\u53cd\u601d\u6027\u5de5\u4f5c\u574a\uff0c\u5f15\u5bfc25\u4f4dISERN\u7814\u7a76\u4eba\u5458\u901a\u8fc7\u7ed3\u6784\u5316\u8ba8\u8bba\uff0c\u4f7f\u7528\u5f69\u8272\u7f16\u7801\u753b\u5e03\u8bb0\u5f55\u5bf9LLM\u8f85\u52a9\u5f00\u653e\u7f16\u7801\u3001\u4e3b\u9898\u751f\u6210\u548c\u4e3b\u9898\u5ba1\u67e5\u7684\u770b\u6cd5\u3002", "result": "\u53c2\u4e0e\u8005\u8ba4\u8bc6\u5230\u6f5c\u5728\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u6536\u76ca\uff0c\u4f46\u5f3a\u8c03\u4e86\u4e0e\u504f\u89c1\u3001\u4e0a\u4e0b\u6587\u4e22\u5931\u3001\u53ef\u91cd\u590d\u6027\u4ee5\u53caLLM\u5feb\u901f\u6f14\u5316\u76f8\u5173\u7684\u98ce\u9669\uff0c\u540c\u65f6\u5f3a\u8c03\u9700\u8981\u63d0\u793a\u7d20\u517b\u548c\u6301\u7eed\u7684\u4eba\u5de5\u76d1\u7763\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u652f\u6301\u4f46\u4e0d\u80fd\u66ff\u4ee3\u89e3\u91ca\u6027\u5206\u6790\u7684\u5de5\u5177\uff0c\u4e3a\u793e\u533a\u5173\u4e8e\u5982\u4f55\u8d1f\u8d23\u4efb\u5730\u589e\u5f3a\u8f6f\u4ef6\u5de5\u7a0b\u5b9a\u6027\u7814\u7a76\u7684\u6301\u7eed\u53cd\u601d\u505a\u51fa\u8d21\u732e\u3002"}}
{"id": "2511.14005", "categories": ["cs.CR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.14005", "abs": "https://arxiv.org/abs/2511.14005", "authors": ["Kaiyuan Hu", "Hong Kang", "Yili Jin", "Junhua Liu", "Chengming Hu", "Haolun Wu", "Xue Liu"], "title": "Privis: Towards Content-Aware Secure Volumetric Video Delivery", "comment": null, "summary": "Volumetric video has emerged as a key paradigm in eXtended Reality (XR) and immersive multimedia because it enables highly interactive, spatially consistent 3D experiences. However, the transport-layer security for such 3D content remains largely unaddressed. Existing volumetric streaming pipelines inherit uniform encryption schemes from 2D video, overlooking the heterogeneous privacy sensitivity of different geometry and the strict motion-to-photon latency constraints of real-time XR.\n  We take an initial step toward content-aware secure volumetric video delivery by introducing Privis, a saliency-guided transport framework that (i) partitions volumetric assets into independent units, (ii) applies lightweight authenticated encryption with adaptive key rotation, and (iii) employs selective traffic shaping to balance confidentiality and low latency. Privis specifies a generalized transport-layer security architecture for volumetric media, defining core abstractions and adaptive protection mechanisms. We further explore a prototype implementation and present initial latency measurements to illustrate feasibility and design tradeoffs, providing early empirical guidance toward future work on real-time, saliency-conditioned secure delivery.", "AI": {"tldr": "Privis\u662f\u4e00\u4e2a\u57fa\u4e8e\u663e\u8457\u6027\u7684\u5b89\u5168\u4f53\u89c6\u9891\u4f20\u8f93\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u533a\u3001\u8f7b\u91cf\u7ea7\u52a0\u5bc6\u548c\u9009\u62e9\u6027\u6d41\u91cf\u6574\u5f62\u6765\u5e73\u8861\u673a\u5bc6\u6027\u548c\u4f4e\u5ef6\u8fdf\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u4f53\u89c6\u9891\u6d41\u5a92\u4f53\u7ba1\u9053\u7ee7\u627f\u4e862D\u89c6\u9891\u7684\u7edf\u4e00\u52a0\u5bc6\u65b9\u6848\uff0c\u5ffd\u7565\u4e86\u4e0d\u540c\u51e0\u4f55\u4f53\u7684\u5f02\u6784\u9690\u79c1\u654f\u611f\u6027\u548c\u5b9e\u65f6XR\u7684\u4e25\u683c\u8fd0\u52a8\u5230\u5149\u5b50\u5ef6\u8fdf\u7ea6\u675f\u3002", "method": "\u5c06\u4f53\u89c6\u9891\u8d44\u4ea7\u5212\u5206\u4e3a\u72ec\u7acb\u5355\u5143\uff0c\u5e94\u7528\u5177\u6709\u81ea\u9002\u5e94\u5bc6\u94a5\u8f6e\u6362\u7684\u8f7b\u91cf\u7ea7\u8ba4\u8bc1\u52a0\u5bc6\uff0c\u5e76\u91c7\u7528\u9009\u62e9\u6027\u6d41\u91cf\u6574\u5f62\u3002", "result": "\u63d0\u51fa\u4e86\u901a\u7528\u7684\u4f53\u89c6\u9891\u4f20\u8f93\u5c42\u5b89\u5168\u67b6\u6784\uff0c\u5b9a\u4e49\u4e86\u6838\u5fc3\u62bd\u8c61\u548c\u81ea\u9002\u5e94\u4fdd\u62a4\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u5b9e\u73b0\u548c\u521d\u59cb\u5ef6\u8fdf\u6d4b\u91cf\u9a8c\u8bc1\u4e86\u53ef\u884c\u6027\u3002", "conclusion": "\u4e3a\u5b9e\u65f6\u3001\u57fa\u4e8e\u663e\u8457\u6027\u7684\u5b89\u5168\u4f53\u89c6\u9891\u4f20\u8f93\u63d0\u4f9b\u4e86\u65e9\u671f\u5b9e\u8bc1\u6307\u5bfc\uff0c\u5c55\u793a\u4e86\u8bbe\u8ba1\u6743\u8861\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.14618", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.14618", "abs": "https://arxiv.org/abs/2511.14618", "authors": ["Severin Kohler", "Jordi Piera Jim\u00e9nez", "Michael Anywar", "Lars Fuhrmann", "Heather Leslie", "Maximilian Meixner", "Julian Sa\u00df", "Florian K\u00e4rcher", "Diego Bosc\u00e1", "Birger Haarbrandt", "Michael Marschollek", "Roland Eils"], "title": "FHIRconnect: Towards a seamless integration of openEHR and FHIR", "comment": "27 pages, 4 figures", "summary": "Healthcare interoperability between openEHR and HL7 FHIR remains challenging due to fundamental differences in their data modeling approaches and the absence of standardized transformation mechanisms. This paper presents FHIRconnect, a novel domain-specific language and open-source transformation engine that enables standardized, bidirectional data exchange between openEHR and FHIR. Our approach addresses critical interoperability gaps through a triple-layered architecture that achieves 65% mapping reuse across projects by leveraging international archetype-based foundations while supporting local customizations. Using this framework, FHIRconnect successfully mapped 24 international archetypes to 15 FHIR profiles across seven clinical domains. Key contributions include the first comprehensive DSL for openEHR-FHIR transformation with a formal specification, an open-source execution engine (openFHIR), and an accessible mapping library covering high-impact clinical archetypes. Together, these components establish the technical basis for community-driven mapping standardization, reducing reliance on custom ETL solutions and advancing syntactic and semantic interoperability in healthcare IT systems built on open standards.", "AI": {"tldr": "FHIRconnect\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u548c\u5f00\u6e90\u8f6c\u6362\u5f15\u64ce\uff0c\u7528\u4e8e\u5b9e\u73b0openEHR\u548cHL7 FHIR\u4e4b\u95f4\u7684\u6807\u51c6\u5316\u53cc\u5411\u6570\u636e\u4ea4\u6362\uff0c\u901a\u8fc7\u4e09\u5c42\u67b6\u6784\u5b9e\u73b065%\u7684\u6620\u5c04\u91cd\u7528\u7387\u3002", "motivation": "\u89e3\u51b3openEHR\u548cHL7 FHIR\u4e4b\u95f4\u7531\u4e8e\u6570\u636e\u5efa\u6a21\u65b9\u6cd5\u6839\u672c\u5dee\u5f02\u548c\u7f3a\u4e4f\u6807\u51c6\u5316\u8f6c\u6362\u673a\u5236\u800c\u5bfc\u81f4\u7684\u533b\u7597\u4e92\u64cd\u4f5c\u6027\u6311\u6218\u3002", "method": "\u5f00\u53d1FHIRconnect\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u548c\u5f00\u6e90\u8f6c\u6362\u5f15\u64ce\uff0c\u91c7\u7528\u4e09\u5c42\u67b6\u6784\uff0c\u5229\u7528\u56fd\u9645\u539f\u578b\u57fa\u7840\u652f\u6301\u672c\u5730\u5b9a\u5236\uff0c\u5b9e\u73b024\u4e2a\u56fd\u9645\u539f\u578b\u523015\u4e2aFHIR\u914d\u7f6e\u6587\u4ef6\u7684\u6620\u5c04\u3002", "result": "\u6210\u529f\u6620\u5c04\u4e867\u4e2a\u4e34\u5e8a\u9886\u57df\u768424\u4e2a\u56fd\u9645\u539f\u578b\u523015\u4e2aFHIR\u914d\u7f6e\u6587\u4ef6\uff0c\u5efa\u7acb\u4e86\u6280\u672f\u57fa\u7840\uff0c\u51cf\u5c11\u5bf9\u81ea\u5b9a\u4e49ETL\u89e3\u51b3\u65b9\u6848\u7684\u4f9d\u8d56\u3002", "conclusion": "FHIRconnect\u4e3a\u793e\u533a\u9a71\u52a8\u7684\u6620\u5c04\u6807\u51c6\u5316\u5efa\u7acb\u4e86\u6280\u672f\u57fa\u7840\uff0c\u63a8\u8fdb\u4e86\u57fa\u4e8e\u5f00\u653e\u6807\u51c6\u7684\u533b\u7597IT\u7cfb\u7edf\u4e2d\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\u3002"}}
{"id": "2511.14032", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14032", "abs": "https://arxiv.org/abs/2511.14032", "authors": ["Kunal Mukherjee"], "title": "Location-Dependent Cryptosystem", "comment": null, "summary": "Digital content distribution and proprietary research-driven industries face persistent risks from intellectual property theft and unauthorized redistribution. Conventional encryption schemes such as AES, TDES, ECC, and ElGamal provide strong cryptographic guarantees, but they remain fundamentally agnostic to where decryption takes place.In practice, this means that once a decryption key is leaked or intercepted, any adversary can misuse the key to decrypt the protected content from any location. We present a location-dependent cryptosystem in which the decryption key is not transmitted as human- or machine-readable data, but implicitly encoded in precise time-of-flight differences of ultra-wideband (UWB) data transmission packets. The system leverages precise timing hardware and a custom JMTK protocol to map a SHA-256 hashed AES key onto scheduled transmission timestamps. Only receivers located within a predefined spatial region can observe the packet timings that align with the intended \"time slot\" pattern, enabling them to reconstruct the key and decrypt the secret. Receivers outside the authorized region observe incorrect keys. We implement a complete prototype that encrypts and transmits audio data using our cryptosystem, and only when the receiver is within the authorized data, they are able to decrypt the data. Our evaluation demonstrates that the system (i) removes the need to share decryption passwords electronically or physically, (ii) ensures the decryption key cannot be recovered by the eavesdropper, and (iii) provides a non-trivial spatial tolerance for legitimate users.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u5bbd\u5e26(UWB)\u6570\u636e\u4f20\u8f93\u5305\u7cbe\u786e\u98de\u884c\u65f6\u95f4\u5dee\u5f02\u7684\u4f4d\u7f6e\u4f9d\u8d56\u52a0\u5bc6\u7cfb\u7edf\uff0c\u89e3\u5bc6\u5bc6\u94a5\u4e0d\u662f\u76f4\u63a5\u4f20\u8f93\uff0c\u800c\u662f\u901a\u8fc7\u65f6\u95f4\u5dee\u9690\u5f0f\u7f16\u7801\uff0c\u53ea\u6709\u7279\u5b9a\u7a7a\u95f4\u533a\u57df\u5185\u7684\u63a5\u6536\u5668\u624d\u80fd\u6b63\u786e\u89e3\u5bc6\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u52a0\u5bc6\u65b9\u6848\u5728\u89e3\u5bc6\u5bc6\u94a5\u6cc4\u9732\u540e\u65e0\u6cd5\u9650\u5236\u89e3\u5bc6\u4f4d\u7f6e\u7684\u95ee\u9898\uff0c\u9632\u6b62\u77e5\u8bc6\u4ea7\u6743\u88ab\u76d7\u548c\u672a\u7ecf\u6388\u6743\u7684\u518d\u5206\u53d1\u3002", "method": "\u5229\u7528\u7cbe\u786e\u8ba1\u65f6\u786c\u4ef6\u548c\u81ea\u5b9a\u4e49JMTK\u534f\u8bae\uff0c\u5c06SHA-256\u54c8\u5e0c\u7684AES\u5bc6\u94a5\u6620\u5c04\u5230\u9884\u5b9a\u7684\u4f20\u8f93\u65f6\u95f4\u6233\u4e0a\uff0c\u901a\u8fc7UWB\u6570\u636e\u5305\u7684\u98de\u884c\u65f6\u95f4\u5dee\u5f02\u9690\u5f0f\u7f16\u7801\u89e3\u5bc6\u5bc6\u94a5\u3002", "result": "\u5b9e\u73b0\u4e86\u5b8c\u6574\u7684\u539f\u578b\u7cfb\u7edf\uff0c\u80fd\u591f\u52a0\u5bc6\u548c\u4f20\u8f93\u97f3\u9891\u6570\u636e\uff0c\u53ea\u6709\u5728\u6388\u6743\u533a\u57df\u5185\u7684\u63a5\u6536\u5668\u624d\u80fd\u6b63\u786e\u89e3\u5bc6\uff0c\u7cfb\u7edf\u65e0\u9700\u7535\u5b50\u6216\u7269\u7406\u5171\u4eab\u89e3\u5bc6\u5bc6\u7801\uff0c\u4e14\u7a83\u542c\u8005\u65e0\u6cd5\u6062\u590d\u89e3\u5bc6\u5bc6\u94a5\u3002", "conclusion": "\u8be5\u4f4d\u7f6e\u4f9d\u8d56\u52a0\u5bc6\u7cfb\u7edf\u901a\u8fc7UWB\u65f6\u95f4\u5dee\u9690\u5f0f\u7f16\u7801\u5bc6\u94a5\uff0c\u6709\u6548\u9650\u5236\u4e86\u89e3\u5bc6\u64cd\u4f5c\u7684\u5730\u7406\u4f4d\u7f6e\uff0c\u4e3a\u6570\u5b57\u5185\u5bb9\u5206\u53d1\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u62a4\u3002"}}
{"id": "2511.14018", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14018", "abs": "https://arxiv.org/abs/2511.14018", "authors": ["Minghu Wang", "Shuliang Zhao", "Yuanyuan Zhao", "Hongxia Xu"], "title": "ALEX:A Light Editing-knowledge Extractor", "comment": null, "summary": "The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retrieval efficiency, particularly when handling complex, multi-hop questions that require multi-step reasoning. To address these challenges, this paper introduces ALEX (A Light Editing-knowledge Extractor), a lightweight knowledge editing framework. The core innovation of ALEX is its hierarchical memory architecture, which organizes knowledge updates (edits) into semantic clusters. This design fundamentally reduces retrieval complexity from a linear O(N) to a highly scalable O(K+N/C). Furthermore, the framework integrates an Inferential Query Synthesis (IQS) module to bridge the semantic gap between queries and facts , and a Dynamic Evidence Adjudication (DEA) engine that executes an efficient two-stage retrieval process. Experiments on the MQUAKE benchmark demonstrate that ALEX significantly improves both the accuracy of multi-hop answers (MultiHop-ACC) and the reliability of reasoning paths (HopWise-ACC). It also reduces the required search space by over 80% , presenting a promising path toward building scalable, efficient, and accurate knowledge editing systems.", "AI": {"tldr": "ALEX\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u77e5\u8bc6\u7f16\u8f91\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u5185\u5b58\u67b6\u6784\u5c06\u77e5\u8bc6\u66f4\u65b0\u7ec4\u7ec7\u4e3a\u8bed\u4e49\u7c07\uff0c\u5c06\u68c0\u7d22\u590d\u6742\u5ea6\u4eceO(N)\u964d\u4f4e\u5230O(K+N/C)\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u8df3\u95ee\u9898\u7684\u51c6\u786e\u6027\u548c\u63a8\u7406\u8def\u5f84\u53ef\u9760\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u77e5\u8bc6\u662f\u9759\u6001\u7684\uff0c\u96be\u4ee5\u9002\u5e94\u4e0d\u65ad\u53d1\u5c55\u7684\u4fe1\u606f\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u9700\u8981\u591a\u6b65\u63a8\u7406\u7684\u590d\u6742\u591a\u8df3\u95ee\u9898\u65f6\u9762\u4e34\u53ef\u6269\u5c55\u6027\u548c\u68c0\u7d22\u6548\u7387\u7684\u6311\u6218\u3002", "method": "ALEX\u91c7\u7528\u5206\u5c42\u5185\u5b58\u67b6\u6784\u7ec4\u7ec7\u77e5\u8bc6\u66f4\u65b0\u4e3a\u8bed\u4e49\u7c07\uff0c\u5305\u542b\u63a8\u7406\u67e5\u8be2\u5408\u6210\u6a21\u5757\u6765\u5f25\u5408\u67e5\u8be2\u4e0e\u4e8b\u5b9e\u4e4b\u95f4\u7684\u8bed\u4e49\u5dee\u8ddd\uff0c\u4ee5\u53ca\u52a8\u6001\u8bc1\u636e\u88c1\u51b3\u5f15\u64ce\u6267\u884c\u9ad8\u6548\u7684\u4e24\u9636\u6bb5\u68c0\u7d22\u8fc7\u7a0b\u3002", "result": "\u5728MQUAKE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cALEX\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u8df3\u7b54\u6848\u7684\u51c6\u786e\u6027\u548c\u63a8\u7406\u8def\u5f84\u7684\u53ef\u9760\u6027\uff0c\u540c\u65f6\u5c06\u6240\u9700\u641c\u7d22\u7a7a\u95f4\u51cf\u5c11\u4e8680%\u4ee5\u4e0a\u3002", "conclusion": "ALEX\u4e3a\u6784\u5efa\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u548c\u51c6\u786e\u7684\u77e5\u8bc6\u7f16\u8f91\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2511.14711", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.14711", "abs": "https://arxiv.org/abs/2511.14711", "authors": ["Aaliyah Chang", "Mariam Guizani", "Brittany Johnson"], "title": "Why Do We Code? A Theory on Motivations and Challenges in Software Engineering from Education to Practice", "comment": null, "summary": "Motivations and challenges jointly shape how individuals enter, persist, and evolve within software engineering (SE), yet their interplay remains underexplored across the transition from education to professional practice. We conducted 15 semi-structured interviews and employed the Gioia Methodology, an adapted grounded theory methodology from organizational behavior, to inductively derive taxonomies of motivations and challenges, and build the Exposure-Pursuit-Evaluation (EPE) Process Model. Our findings reveal that impactful early exposure triggers intrinsic motivations, while non-impactful exposure requires an extrinsic push (e.g., career/ personal goals, external validation). We identify curiosity and avoiding alternatives as a distinct educational drivers, and barriers to belonging as the only challenge persisting across education and career. Our findings show that career progression challenges (e.g., navigating the corporate world) constrain extrinsic fulfillment while technical training challenges, barriers to belonging and threats to motivation constrain intrinsic fulfillment. The theory shows how unmet motivations and recurring challenges influence persistence, career shifts, or departure from the field. Our results provide a grounded model for designing interventions that strengthen intrinsic fulfillment and reduce systemic barriers in SE education and practice.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4ece\u4e1a\u8005\u4ece\u6559\u80b2\u5230\u804c\u4e1a\u8f6c\u578b\u8fc7\u7a0b\u4e2d\u52a8\u673a\u4e0e\u6311\u6218\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u63d0\u51fa\u4e86\u66b4\u9732-\u8ffd\u6c42-\u8bc4\u4f30(EPE)\u8fc7\u7a0b\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u66b4\u9732\u7c7b\u578b\u5bf9\u5185\u5728/\u5916\u5728\u52a8\u673a\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u6301\u7eed\u5b58\u5728\u7684\u5f52\u5c5e\u611f\u969c\u788d\u7b49\u95ee\u9898\u3002", "motivation": "\u63a2\u7d22\u8f6f\u4ef6\u5de5\u7a0b\u4ece\u4e1a\u8005\u5728\u4ece\u6559\u80b2\u5230\u804c\u4e1a\u5b9e\u8df5\u8f6c\u578b\u8fc7\u7a0b\u4e2d\uff0c\u52a8\u673a\u4e0e\u6311\u6218\u5982\u4f55\u5171\u540c\u5851\u9020\u5176\u8fdb\u5165\u3001\u575a\u6301\u548c\u6f14\u53d8\u7684\u8fc7\u7a0b\uff0c\u8fd9\u4e00\u76f8\u4e92\u4f5c\u7528\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u91c7\u752815\u4e2a\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u8fd0\u7528\u6765\u81ea\u7ec4\u7ec7\u884c\u4e3a\u5b66\u7684Gioia\u65b9\u6cd5\u8bba\uff08\u4e00\u79cd\u6539\u8fdb\u7684\u624e\u6839\u7406\u8bba\u65b9\u6cd5\uff09\uff0c\u5f52\u7eb3\u63a8\u5bfc\u52a8\u673a\u548c\u6311\u6218\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u6784\u5efa\u66b4\u9732-\u8ffd\u6c42-\u8bc4\u4f30(EPE)\u8fc7\u7a0b\u6a21\u578b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u6709\u5f71\u54cd\u529b\u7684\u65e9\u671f\u66b4\u9732\u89e6\u53d1\u5185\u5728\u52a8\u673a\uff0c\u800c\u65e0\u5f71\u54cd\u529b\u7684\u66b4\u9732\u9700\u8981\u5916\u5728\u63a8\u52a8\uff1b\u597d\u5947\u5fc3\u4e0e\u907f\u514d\u66ff\u4ee3\u9009\u62e9\u662f\u72ec\u7279\u7684\u6559\u80b2\u9a71\u52a8\u56e0\u7d20\uff1b\u5f52\u5c5e\u611f\u969c\u788d\u662f\u552f\u4e00\u8d2f\u7a7f\u6559\u80b2\u548c\u804c\u4e1a\u751f\u6daf\u7684\u6311\u6218\uff1b\u804c\u4e1a\u53d1\u5c55\u6311\u6218\u5236\u7ea6\u5916\u5728\u6ee1\u8db3\uff0c\u800c\u6280\u672f\u57f9\u8bad\u6311\u6218\u3001\u5f52\u5c5e\u611f\u969c\u788d\u548c\u52a8\u673a\u5a01\u80c1\u5236\u7ea6\u5185\u5728\u6ee1\u8db3\u3002", "conclusion": "\u672a\u6ee1\u8db3\u7684\u52a8\u673a\u548c\u53cd\u590d\u51fa\u73b0\u7684\u6311\u6218\u5f71\u54cd\u4ece\u4e1a\u8005\u7684\u575a\u6301\u3001\u804c\u4e1a\u8f6c\u53d8\u6216\u79bb\u5f00\u8be5\u9886\u57df\u3002\u8be5\u7406\u8bba\u4e3a\u8bbe\u8ba1\u5e72\u9884\u63aa\u65bd\u63d0\u4f9b\u4e86\u57fa\u7840\u6a21\u578b\uff0c\u4ee5\u589e\u5f3a\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u548c\u5b9e\u8df5\u4e2d\u7684\u5185\u5728\u6ee1\u8db3\u611f\u5e76\u51cf\u5c11\u7cfb\u7edf\u6027\u969c\u788d\u3002"}}
{"id": "2511.14045", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.14045", "abs": "https://arxiv.org/abs/2511.14045", "authors": ["Yule Liu", "Heyi Zhang", "Jinyi Zheng", "Zhen Sun", "Zifan Peng", "Tianshuo Cong", "Yilong Yang", "Xinlei He", "Zhuo Ma"], "title": "GRPO Privacy Is at Risk: A Membership Inference Attack Against Reinforcement Learning With Verifiable Rewards", "comment": null, "summary": "Membership inference attacks (MIAs) on large language models (LLMs) pose significant privacy risks across various stages of model training. Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have brought a profound paradigm shift in LLM training, particularly for complex reasoning tasks. However, the on-policy nature of RLVR introduces a unique privacy leakage pattern: since training relies on self-generated responses without fixed ground-truth outputs, membership inference must now determine whether a given prompt (independent of any specific response) is used during fine-tuning. This creates a threat where leakage arises not from answer memorization.\n  To audit this novel privacy risk, we propose Divergence-in-Behavior Attack (DIBA), the first membership inference framework specifically designed for RLVR. DIBA shifts the focus from memorization to behavioral change, leveraging measurable shifts in model behavior across two axes: advantage-side improvement (e.g., correctness gain) and logit-side divergence (e.g., policy drift). Through comprehensive evaluations, we demonstrate that DIBA significantly outperforms existing baselines, achieving around 0.8 AUC and an order-of-magnitude higher TPR@0.1%FPR. We validate DIBA's superiority across multiple settings--including in-distribution, cross-dataset, cross-algorithm, black-box scenarios, and extensions to vision-language models. Furthermore, our attack remains robust under moderate defensive measures.\n  To the best of our knowledge, this is the first work to systematically analyze privacy vulnerabilities in RLVR, revealing that even in the absence of explicit supervision, training data exposure can be reliably inferred through behavioral traces.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DIBA\u653b\u51fb\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u901a\u8fc7\u68c0\u6d4b\u6a21\u578b\u884c\u4e3a\u53d8\u5316\u800c\u975e\u8bb0\u5fc6\u6765\u63a8\u65ad\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u591a\u4e2a\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "RLVR\u8bad\u7ec3\u8303\u5f0f\u5728LLM\u4e2d\u5f15\u5165\u65b0\u7684\u9690\u79c1\u6cc4\u9732\u6a21\u5f0f\uff1a\u7531\u4e8e\u8bad\u7ec3\u4f9d\u8d56\u81ea\u751f\u6210\u54cd\u5e94\u4e14\u65e0\u56fa\u5b9a\u771f\u5b9e\u8f93\u51fa\uff0c\u6210\u5458\u63a8\u7406\u9700\u8981\u4ec5\u57fa\u4e8e\u63d0\u793a\u5224\u65ad\u662f\u5426\u7528\u4e8e\u5fae\u8c03\uff0c\u8fd9\u521b\u9020\u4e86\u4e0d\u4f9d\u8d56\u7b54\u6848\u8bb0\u5fc6\u7684\u65b0\u578b\u9690\u79c1\u5a01\u80c1\u3002", "method": "\u63d0\u51faDIBA\u653b\u51fb\u6846\u67b6\uff0c\u5c06\u7126\u70b9\u4ece\u8bb0\u5fc6\u8f6c\u5411\u884c\u4e3a\u53d8\u5316\uff0c\u5229\u7528\u6a21\u578b\u5728\u4e24\u4e2a\u8f74\u4e0a\u7684\u53ef\u6d4b\u91cf\u884c\u4e3a\u504f\u79fb\uff1a\u4f18\u52bf\u4fa7\u6539\u8fdb\uff08\u5982\u6b63\u786e\u6027\u589e\u76ca\uff09\u548c\u5bf9\u6570\u4fa7\u5206\u6b67\uff08\u5982\u7b56\u7565\u6f02\u79fb\uff09\u3002", "result": "DIBA\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u8fbe\u5230\u7ea60.8\u7684AUC\u548c\u4e00\u4e2a\u6570\u91cf\u7ea7\u66f4\u9ad8\u7684TPR@0.1%FPR\uff0c\u5728\u591a\u79cd\u8bbe\u7f6e\u4e0b\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\uff0c\u5305\u62ec\u540c\u5206\u5e03\u3001\u8de8\u6570\u636e\u96c6\u3001\u8de8\u7b97\u6cd5\u3001\u9ed1\u76d2\u573a\u666f\u4ee5\u53ca\u6269\u5c55\u5230\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u7cfb\u7edf\u5206\u6790RLVR\u9690\u79c1\u6f0f\u6d1e\u7684\u5de5\u4f5c\uff0c\u63ed\u793a\u4e86\u5373\u4f7f\u5728\u7f3a\u4e4f\u663e\u5f0f\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\uff0c\u8bad\u7ec3\u6570\u636e\u66b4\u9732\u4ecd\u53ef\u901a\u8fc7\u884c\u4e3a\u75d5\u8ff9\u53ef\u9760\u63a8\u65ad\u3002"}}
{"id": "2511.14023", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14023", "abs": "https://arxiv.org/abs/2511.14023", "authors": ["Chiharu Hagiwara", "Naoki Nonaka", "Yuhta Hashimoto", "Ryu Uchimido", "Jun Seita"], "title": "Syn-STARTS: Synthesized START Triage Scenario Generation Framework for Scalable LLM Evaluation", "comment": "Introducing an open dataset", "summary": "Triage is a critically important decision-making process in mass casualty incidents (MCIs) to maximize victim survival rates. While the role of AI in such situations is gaining attention for making optimal decisions within limited resources and time, its development and performance evaluation require benchmark datasets of sufficient quantity and quality. However, MCIs occur infrequently, and sufficient records are difficult to accumulate at the scene, making it challenging to collect large-scale realworld data for research use. Therefore, we developed Syn-STARTS, a framework that uses LLMs to generate triage cases, and verified its effectiveness. The results showed that the triage cases generated by Syn-STARTS were qualitatively indistinguishable from the TRIAGE open dataset generated by manual curation from training materials. Furthermore, when evaluating the LLM accuracy using hundreds of cases each from the green, yellow, red, and black categories defined by the standard triage method START, the results were found to be highly stable. This strongly indicates the possibility of synthetic data in developing high-performance AI models for severe and critical medical situations.", "AI": {"tldr": "Syn-STARTS\u6846\u67b6\u4f7f\u7528LLMs\u751f\u6210\u5927\u89c4\u6a21\u5206\u7c7b\u6848\u4f8b\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u4f24\u4ea1\u4e8b\u4ef6\u4e2d\u771f\u5b9e\u6570\u636e\u96be\u4ee5\u83b7\u53d6\u7684\u95ee\u9898\uff0c\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u5728\u8d28\u91cf\u4e0a\u4e0e\u624b\u52a8\u6574\u7406\u7684\u771f\u5b9e\u6570\u636e\u96c6\u96be\u4ee5\u533a\u5206\u3002", "motivation": "\u5927\u89c4\u6a21\u4f24\u4ea1\u4e8b\u4ef6\u4e2d\u5206\u7c7b\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u771f\u5b9e\u6570\u636e\u96be\u4ee5\u79ef\u7d2f\uff0c\u963b\u788d\u4e86AI\u6a21\u578b\u7684\u5f00\u53d1\u4e0e\u8bc4\u4f30\u3002", "method": "\u5f00\u53d1Syn-STARTS\u6846\u67b6\uff0c\u5229\u7528LLMs\u751f\u6210\u5206\u7c7b\u6848\u4f8b\uff0c\u5e76\u4e0e\u624b\u52a8\u6574\u7406\u7684TRIAGE\u5f00\u653e\u6570\u636e\u96c6\u8fdb\u884c\u8d28\u91cf\u5bf9\u6bd4\u9a8c\u8bc1\u3002", "result": "Syn-STARTS\u751f\u6210\u7684\u5206\u7c7b\u6848\u4f8b\u5728\u8d28\u91cf\u4e0a\u4e0e\u771f\u5b9e\u6570\u636e\u96c6\u96be\u4ee5\u533a\u5206\uff0c\u4e14\u5728\u6807\u51c6START\u5206\u7c7b\u6cd5\u7684\u56db\u4e2a\u7c7b\u522b\uff08\u7eff\u3001\u9ec4\u3001\u7ea2\u3001\u9ed1\uff09\u4e2d\u8868\u73b0\u51fa\u9ad8\u5ea6\u7a33\u5b9a\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u5728\u5f00\u53d1\u9ad8\u6027\u80fdAI\u6a21\u578b\u7528\u4e8e\u4e25\u91cd\u548c\u5371\u6025\u533b\u7597\u60c5\u51b5\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2511.14074", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14074", "abs": "https://arxiv.org/abs/2511.14074", "authors": ["Ajesh Koyatan Chathoth", "Stephen Lee"], "title": "Dynamic Black-box Backdoor Attacks on IoT Sensory Data", "comment": null, "summary": "Sensor data-based recognition systems are widely used in various applications, such as gait-based authentication and human activity recognition (HAR). Modern wearable and smart devices feature various built-in Inertial Measurement Unit (IMU) sensors, and such sensor-based measurements can be fed to a machine learning-based model to train and classify human activities. While deep learning-based models have proven successful in classifying human activity and gestures, they pose various security risks. In our paper, we discuss a novel dynamic trigger-generation technique for performing black-box adversarial attacks on sensor data-based IoT systems. Our empirical analysis shows that the attack is successful on various datasets and classifier models with minimal perturbation on the input data. We also provide a detailed comparative analysis of performance and stealthiness to various other poisoning techniques found in backdoor attacks. We also discuss some adversarial defense mechanisms and their impact on the effectiveness of our trigger-generation technique.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4f20\u611f\u5668\u6570\u636e\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u89e6\u53d1\u5668\u751f\u6210\u6280\u672f\uff0c\u5728\u6700\u5c0f\u6270\u52a8\u4e0b\u6210\u529f\u653b\u51fb\u591a\u79cd\u6570\u636e\u96c6\u548c\u5206\u7c7b\u5668\u6a21\u578b\u3002", "motivation": "\u867d\u7136\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6a21\u578b\u5728\u4eba\u7c7b\u6d3b\u52a8\u548c\u624b\u52bf\u5206\u7c7b\u65b9\u9762\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5b83\u4eec\u5b58\u5728\u5404\u79cd\u5b89\u5168\u98ce\u9669\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u4f20\u611f\u5668\u6570\u636e\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u91c7\u7528\u65b0\u9896\u7684\u52a8\u6001\u89e6\u53d1\u5668\u751f\u6210\u6280\u672f\uff0c\u5bf9\u57fa\u4e8e\u4f20\u611f\u5668\u6570\u636e\u7684\u7269\u8054\u7f51\u7cfb\u7edf\u6267\u884c\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\u3002", "result": "\u5b9e\u8bc1\u5206\u6790\u8868\u660e\uff0c\u8be5\u653b\u51fb\u65b9\u6cd5\u5728\u591a\u79cd\u6570\u636e\u96c6\u548c\u5206\u7c7b\u5668\u6a21\u578b\u4e0a\u90fd\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4e14\u5bf9\u8f93\u5165\u6570\u636e\u7684\u6270\u52a8\u6700\u5c0f\u3002\u4e0e\u540e\u95e8\u653b\u51fb\u4e2d\u7684\u5176\u4ed6\u4e2d\u6bd2\u6280\u672f\u76f8\u6bd4\uff0c\u5728\u6027\u80fd\u548c\u9690\u853d\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "\u672c\u6587\u8ba8\u8bba\u4e86\u5bf9\u6297\u6027\u9632\u5fa1\u673a\u5236\u53ca\u5176\u5bf9\u89e6\u53d1\u5668\u751f\u6210\u6280\u672f\u6709\u6548\u6027\u7684\u5f71\u54cd\uff0c\u4e3a\u4f20\u611f\u5668\u6570\u636e\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2511.14088", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14088", "abs": "https://arxiv.org/abs/2511.14088", "authors": ["Adam Caulfield", "Muhammad Wasif Kamran", "N. Asokan"], "title": "Resolving Availability and Run-time Integrity Conflicts in Real-Time Embedded Systems", "comment": null, "summary": "Run-time integrity enforcement in real-time systems presents a fundamental conflict with availability. Existing approaches in real- time systems primarily focus on minimizing the execution-time overhead of monitoring. After a violation is detected, prior works face a trade-off: (1) prioritize availability and allow a compromised system to continue to ensure applications meet their deadlines, or (2) prioritize security by generating a fault to abort all execution. In this work, we propose PAIR, an approach that offers a middle ground between the stark extremes of this trade-off. PAIR monitors real-time tasks for run-time integrity violations and maintains an Availability Region (AR) of all tasks that are safe to continue. When a task causes a violation, PAIR triggers a non-maskable interrupt to kill the task and continue executing a non-violating task within AR. Thus, PAIR ensures only violating tasks are prevented from execution, while granting availability to remaining tasks. With its hardware approach, PAIR does not cause any run-time overhead to the executing tasks, integrates with real-time operating systems (RTOSs), and is affordable to low-end microcontroller units (MCUs) by incurring +2.3% overhead in memory and hardware usage.", "AI": {"tldr": "PAIR\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5b9e\u65f6\u7cfb\u7edf\u4e2d\u5e73\u8861\u5b89\u5168\u6027\u548c\u53ef\u7528\u6027\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u63a7\u8fd0\u884c\u65f6\u5b8c\u6574\u6027\u8fdd\u89c4\uff0c\u7ef4\u62a4\u5b89\u5168\u4efb\u52a1\u53ef\u7528\u533a\u57df\uff0c\u4ec5\u7ec8\u6b62\u8fdd\u89c4\u4efb\u52a1\u800c\u7ee7\u7eed\u6267\u884c\u975e\u8fdd\u89c4\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u5b9e\u65f6\u7cfb\u7edf\u5728\u68c0\u6d4b\u5230\u5b8c\u6574\u6027\u8fdd\u89c4\u65f6\u9762\u4e34\u4e24\u96be\u9009\u62e9\uff1a\u8981\u4e48\u4f18\u5148\u8003\u8651\u53ef\u7528\u6027\u5141\u8bb8\u53d7\u611f\u67d3\u7cfb\u7edf\u7ee7\u7eed\u8fd0\u884c\uff0c\u8981\u4e48\u4f18\u5148\u8003\u8651\u5b89\u5168\u6027\u4e2d\u6b62\u6240\u6709\u6267\u884c\u3002\u9700\u8981\u5728\u8fd9\u4e24\u4e2a\u6781\u7aef\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u70b9\u3002", "method": "PAIR\u76d1\u63a7\u5b9e\u65f6\u4efb\u52a1\u7684\u8fd0\u884c\u65f6\u5b8c\u6574\u6027\u8fdd\u89c4\uff0c\u7ef4\u62a4\u5b89\u5168\u4efb\u52a1\u53ef\u7528\u533a\u57df(AR)\u3002\u5f53\u4efb\u52a1\u5f15\u53d1\u8fdd\u89c4\u65f6\uff0c\u89e6\u53d1\u4e0d\u53ef\u5c4f\u853d\u4e2d\u65ad\u7ec8\u6b62\u8be5\u4efb\u52a1\uff0c\u540c\u65f6\u7ee7\u7eed\u6267\u884cAR\u5185\u7684\u975e\u8fdd\u89c4\u4efb\u52a1\u3002", "result": "PAIR\u901a\u8fc7\u786c\u4ef6\u65b9\u6cd5\u5b9e\u73b0\uff0c\u5bf9\u6267\u884c\u4efb\u52a1\u4e0d\u4ea7\u751f\u8fd0\u884c\u65f6\u5f00\u9500\uff0c\u53ef\u4e0e\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u96c6\u6210\uff0c\u5728\u5185\u5b58\u548c\u786c\u4ef6\u4f7f\u7528\u4e0a\u4ec5\u589e\u52a02.3%\u7684\u5f00\u9500\uff0c\u9002\u7528\u4e8e\u4f4e\u7aef\u5fae\u63a7\u5236\u5668\u5355\u5143\u3002", "conclusion": "PAIR\u5728\u5b9e\u65f6\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u53ef\u7528\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u4e2d\u95f4\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u4ec5\u963b\u6b62\u8fdd\u89c4\u4efb\u52a1\u7684\u6267\u884c\uff0c\u540c\u65f6\u4e3a\u5269\u4f59\u4efb\u52a1\u4fdd\u6301\u53ef\u7528\u6027\uff0c\u4e14\u786c\u4ef6\u5f00\u9500\u6781\u5c0f\u3002"}}
{"id": "2511.14052", "categories": ["cs.AI", "cs.CE", "stat.AP", "stat.OT"], "pdf": "https://arxiv.org/pdf/2511.14052", "abs": "https://arxiv.org/abs/2511.14052", "authors": ["Amirreza Mehrabi", "Jason W. Morphew", "Breejha Quezada", "N. Sanjay Rebello"], "title": "Making Evidence Actionable in Adaptive Learning", "comment": null, "summary": "Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows informed by ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy enforced through diversity. Greedy selection serves low-richness and tight-latency regimes, gradient-based relaxation serves rich repositories, and a hybrid method transitions along a richness-latency frontier. In simulation and in an introductory physics deployment with one thousand two hundred four students, both solvers achieved full skill coverage for essentially all learners within bounded watch time. The gradient-based method reduced redundant coverage by approximately twelve percentage points relative to greedy and harmonized difficulty across slates, while greedy delivered comparable adequacy with lower computational cost in scarce settings. Slack variables localized missing content and supported targeted curation, sustaining sufficiency across subgroups. The result is a tractable and auditable controller that closes the diagnostic-pedagogical loop and delivers equitable, load-aware personalization at classroom scale.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u6559\u5e08\u4e3b\u5bfc\u7684\u53cd\u9988\u5faa\u73af\u7cfb\u7edf\uff0c\u5c06\u6982\u5ff5\u7ea7\u8bc4\u4f30\u8bc1\u636e\u8f6c\u5316\u4e3a\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5fae\u5e72\u9884\u63aa\u65bd\uff0c\u901a\u8fc7\u4e09\u4e2a\u4fdd\u969c\u673a\u5236\uff08\u5145\u5206\u6027\u3001\u6ce8\u610f\u529b\u9884\u7b97\u3001\u591a\u6837\u6027\uff09\u5b9e\u73b0\u81ea\u9002\u5e94\u5b66\u4e60\u3002", "motivation": "\u4f20\u7edf\u81ea\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u8bca\u65ad\u7cbe\u786e\u4f46\u5e72\u9884\u8584\u5f31\uff0c\u5bfc\u81f4\u5e2e\u52a9\u65f6\u673a\u4e0d\u5f53\u6216\u5185\u5bb9\u4e0d\u5339\u914d\u3002\u9700\u8981\u5efa\u7acb\u8bca\u65ad\u4e0e\u6559\u5b66\u4e4b\u95f4\u7684\u95ed\u73af\uff0c\u63d0\u4f9b\u516c\u5e73\u3001\u8d1f\u8f7d\u611f\u77e5\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u3002", "method": "\u5c06\u5e72\u9884\u5206\u914d\u5f62\u5f0f\u5316\u4e3a\u5e26\u7ea6\u675f\u7684\u4e8c\u5143\u6574\u6570\u89c4\u5212\uff0c\u5305\u62ec\u8986\u76d6\u8303\u56f4\u3001\u65f6\u95f4\u3001\u96be\u5ea6\u7a97\u53e3\u3001\u6982\u5ff5\u77e9\u9635\u7f16\u7801\u7684\u5148\u51b3\u6761\u4ef6\u4ee5\u53ca\u901a\u8fc7\u591a\u6837\u6027\u5f3a\u5236\u6267\u884c\u7684\u6297\u5197\u4f59\u6027\u3002\u4f7f\u7528\u8d2a\u5a6a\u9009\u62e9\u3001\u57fa\u4e8e\u68af\u5ea6\u7684\u677e\u5f1b\u548c\u6df7\u5408\u65b9\u6cd5\u3002", "result": "\u5728\u6a21\u62df\u548c1204\u540d\u5b66\u751f\u7684\u7269\u7406\u8bfe\u7a0b\u90e8\u7f72\u4e2d\uff0c\u4e24\u79cd\u6c42\u89e3\u5668\u90fd\u80fd\u5728\u6709\u9650\u89c2\u770b\u65f6\u95f4\u5185\u4e3a\u51e0\u4e4e\u6240\u6709\u5b66\u4e60\u8005\u5b9e\u73b0\u5b8c\u6574\u7684\u6280\u80fd\u8986\u76d6\u3002\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\u6bd4\u8d2a\u5a6a\u65b9\u6cd5\u51cf\u5c11\u7ea612%\u7684\u5197\u4f59\u8986\u76d6\uff0c\u5e76\u5728\u8d44\u6e90\u7a00\u7f3a\u65f6\u4ee5\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u63d0\u4f9b\u76f8\u5f53\u7684\u5145\u5206\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u8ffd\u8e2a\u548c\u53ef\u5ba1\u8ba1\u7684\u63a7\u5236\u5668\uff0c\u80fd\u591f\u95ed\u5408\u8bca\u65ad-\u6559\u5b66\u5faa\u73af\uff0c\u5728\u8bfe\u5802\u89c4\u6a21\u4e0a\u5b9e\u73b0\u516c\u5e73\u3001\u8d1f\u8f7d\u611f\u77e5\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u3002"}}
{"id": "2511.14101", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14101", "abs": "https://arxiv.org/abs/2511.14101", "authors": ["Xinpeng Chen", "Xiaofeng Han", "Kaihao Zhang", "Guochao Ren", "Yujie Wang", "Wenhao Cao", "Yang Zhou", "Jianfeng Lu", "Zhenbo Song"], "title": "APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design", "comment": null, "summary": "Layout design is a crucial step in developing mobile app pages. However, crafting satisfactory designs is time-intensive for designers: they need to consider which controls and content to present on the page, and then repeatedly adjust their size, position, and style for better aesthetics and structure. Although many design software can now help to perform these repetitive tasks, extensive training is needed to use them effectively. Moreover, collaborative design across app pages demands extra time to align standards and ensure consistent styling. In this work, we propose APD-agents, a large language model (LLM) driven multi-agent framework for automated page design in mobile applications. Our framework contains OrchestratorAgent, SemanticParserAgent, PrimaryLayoutAgent, TemplateRetrievalAgent, and RecursiveComponentAgent. Upon receiving the user's description of the page, the OrchestratorAgent can dynamically can direct other agents to accomplish users' design task. To be specific, the SemanticParserAgent is responsible for converting users' descriptions of page content into structured data. The PrimaryLayoutAgent can generate an initial coarse-grained layout of this page. The TemplateRetrievalAgent can fetch semantically relevant few-shot examples and enhance the quality of layout generation. Besides, a RecursiveComponentAgent can be used to decide how to recursively generate all the fine-grained sub-elements it contains for each element in the layout. Our work fully leverages the automatic collaboration capabilities of large-model-driven multi-agent systems. Experimental results on the RICO dataset show that our APD-agents achieve state-of-the-art performance.", "AI": {"tldr": "APD-agents\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u79fb\u52a8\u5e94\u7528\u9875\u9762\u8bbe\u8ba1\uff0c\u901a\u8fc7\u591a\u4e2a\u667a\u80fd\u4f53\u534f\u4f5c\u5c06\u7528\u6237\u63cf\u8ff0\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u5e03\u5c40\u8bbe\u8ba1\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u9875\u9762\u5e03\u5c40\u8bbe\u8ba1\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u6280\u80fd\uff0c\u73b0\u6709\u8bbe\u8ba1\u8f6f\u4ef6\u4f7f\u7528\u590d\u6742\u4e14\u8de8\u9875\u9762\u534f\u4f5c\u6548\u7387\u4f4e\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u5347\u8bbe\u8ba1\u6548\u7387\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u7f16\u6392\u667a\u80fd\u4f53\u3001\u8bed\u4e49\u89e3\u6790\u667a\u80fd\u4f53\u3001\u4e3b\u5e03\u5c40\u667a\u80fd\u4f53\u3001\u6a21\u677f\u68c0\u7d22\u667a\u80fd\u4f53\u548c\u9012\u5f52\u7ec4\u4ef6\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u534f\u4f5c\u5b9e\u73b0\u4ece\u7528\u6237\u63cf\u8ff0\u5230\u9875\u9762\u5e03\u5c40\u7684\u81ea\u52a8\u5316\u751f\u6210\u3002", "result": "\u5728RICO\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAPD-agents\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5145\u5206\u5229\u7528\u4e86\u5927\u6a21\u578b\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u81ea\u52a8\u534f\u4f5c\u80fd\u529b\uff0c\u4e3a\u79fb\u52a8\u5e94\u7528\u9875\u9762\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.14140", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14140", "abs": "https://arxiv.org/abs/2511.14140", "authors": ["Hajun Kim", "Hyunsik Na", "Daeseon Choi"], "title": "Beyond Fixed and Dynamic Prompts: Embedded Jailbreak Templates for Advancing LLM Security", "comment": null, "summary": "As the use of large language models (LLMs) continues to expand, ensuring their safety and robustness has become a critical challenge. In particular, jailbreak attacks that bypass built-in safety mechanisms are increasingly recognized as a tangible threat across industries, driving the need for diverse templates to support red-teaming efforts and strengthen defensive techniques. However, current approaches predominantly rely on two limited strategies: (i) substituting harmful queries into fixed templates, and (ii) having the LLM generate entire templates, which often compromises intent clarity and reproductibility. To address this gap, this paper introduces the Embedded Jailbreak Template, which preserves the structure of existing templates while naturally embedding harmful queries within their context. We further propose a progressive prompt-engineering methodology to ensure template quality and consistency, alongside standardized protocols for generation and evaluation. Together, these contributions provide a benchmark that more accurately reflects real-world usage scenarios and harmful intent, facilitating its application in red-teaming and policy regression testing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5d4c\u5165\u5f0f\u8d8a\u72f1\u6a21\u677f\uff0c\u901a\u8fc7\u5c06\u6709\u5bb3\u67e5\u8be2\u81ea\u7136\u5d4c\u5165\u73b0\u6709\u6a21\u677f\u7ed3\u6784\u4e2d\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u8d8a\u72f1\u653b\u51fb\u6a21\u677f\u751f\u6210\u65b9\u6cd5\u5728\u610f\u56fe\u6e05\u6670\u5ea6\u548c\u53ef\u590d\u73b0\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u8d8a\u72f1\u653b\u51fb\u6a21\u677f\u751f\u6210\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e24\u79cd\u6709\u9650\u7b56\u7565\uff1a\u5c06\u6709\u5bb3\u67e5\u8be2\u66ff\u6362\u5230\u56fa\u5b9a\u6a21\u677f\u4e2d\uff0c\u6216\u8ba9LLM\u751f\u6210\u6574\u4e2a\u6a21\u677f\uff0c\u4f46\u8fd9\u5f80\u5f80\u635f\u5bb3\u610f\u56fe\u6e05\u6670\u5ea6\u548c\u53ef\u590d\u73b0\u6027\u3002", "method": "\u5f15\u5165\u5d4c\u5165\u5f0f\u8d8a\u72f1\u6a21\u677f\uff0c\u4fdd\u7559\u73b0\u6709\u6a21\u677f\u7ed3\u6784\u7684\u540c\u65f6\u81ea\u7136\u5d4c\u5165\u6709\u5bb3\u67e5\u8be2\uff1b\u63d0\u51fa\u6e10\u8fdb\u5f0f\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u786e\u4fdd\u6a21\u677f\u8d28\u91cf\u548c\u4e00\u81f4\u6027\uff1b\u5236\u5b9a\u6807\u51c6\u5316\u7684\u751f\u6210\u548c\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u51c6\u786e\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u4f7f\u7528\u573a\u666f\u548c\u6709\u5bb3\u610f\u56fe\u7684\u57fa\u51c6\uff0c\u652f\u6301\u7ea2\u961f\u6d4b\u8bd5\u548c\u653f\u7b56\u56de\u5f52\u6d4b\u8bd5\u3002", "conclusion": "\u5d4c\u5165\u5f0f\u8d8a\u72f1\u6a21\u677f\u548c\u6e10\u8fdb\u5f0f\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5f53\u524d\u8d8a\u72f1\u653b\u51fb\u6a21\u677f\u751f\u6210\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u52a0\u5f3aLLM\u5b89\u5168\u9632\u5fa1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u57fa\u51c6\u5de5\u5177\u3002"}}
{"id": "2511.14301", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14301", "abs": "https://arxiv.org/abs/2511.14301", "authors": ["Eric Xue", "Ruiyi Zhang", "Zijun Zhang", "Pengtao Xie"], "title": "Steganographic Backdoor Attacks in NLP: Ultra-Low Poisoning and Defense Evasion", "comment": null, "summary": "Transformer models are foundational to natural language processing (NLP) applications, yet remain vulnerable to backdoor attacks introduced through poisoned data, which implant hidden behaviors during training. To strengthen the ability to prevent such compromises, recent research has focused on designing increasingly stealthy attacks to stress-test existing defenses, pairing backdoor behaviors with stylized artifact or token-level perturbation triggers. However, this trend diverts attention from the harder and more realistic case: making the model respond to semantic triggers such as specific names or entities, where a successful backdoor could manipulate outputs tied to real people or events in deployed systems. Motivated by this growing disconnect, we introduce SteganoBackdoor, bringing stealth techniques back into line with practical threat models. Leveraging innocuous properties from natural-language steganography, SteganoBackdoor applies a gradient-guided data optimization process to transform semantic trigger seeds into steganographic carriers that embed a high backdoor payload, remain fluent, and exhibit no representational resemblance to the trigger. Across diverse experimental settings, SteganoBackdoor achieves over 99% attack success at an order-of-magnitude lower data-poisoning rate than prior approaches while maintaining unparalleled evasion against a comprehensive suite of data-level defenses. By revealing this practical and covert attack, SteganoBackdoor highlights an urgent blind spot in current defenses and demands immediate attention to adversarial data defenses and real-world threat modeling.", "AI": {"tldr": "SteganoBackdoor\u662f\u4e00\u79cd\u65b0\u578b\u7684\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u9690\u5199\u672f\u6280\u672f\u5c06\u8bed\u4e49\u89e6\u53d1\u5668\u8f6c\u5316\u4e3a\u9690\u5199\u8f7d\u4f53\uff0c\u5728\u6781\u4f4e\u6570\u636e\u6295\u6bd2\u7387\u4e0b\u5b9e\u73b0\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u80fd\u6709\u6548\u89c4\u907f\u73b0\u6709\u9632\u5fa1\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u8fc7\u4e8e\u5173\u6ce8\u57fa\u4e8e\u98ce\u683c\u5316\u4f2a\u5f71\u6216\u4ee4\u724c\u7ea7\u6270\u52a8\u7684\u540e\u95e8\u653b\u51fb\uff0c\u800c\u5ffd\u7565\u4e86\u66f4\u73b0\u5b9e\u548c\u5371\u9669\u7684\u8bed\u4e49\u89e6\u53d1\u5668\u653b\u51fb\uff0c\u8fd9\u79cd\u653b\u51fb\u53ef\u80fd\u5728\u5b9e\u9645\u90e8\u7f72\u7cfb\u7edf\u4e2d\u64cd\u7eb5\u4e0e\u771f\u5b9e\u4eba\u7269\u6216\u4e8b\u4ef6\u76f8\u5173\u7684\u8f93\u51fa\u3002", "method": "\u5229\u7528\u81ea\u7136\u8bed\u8a00\u9690\u5199\u672f\u7684\u65e0\u5bb3\u7279\u6027\uff0c\u5e94\u7528\u68af\u5ea6\u5f15\u5bfc\u7684\u6570\u636e\u4f18\u5316\u8fc7\u7a0b\uff0c\u5c06\u8bed\u4e49\u89e6\u53d1\u5668\u79cd\u5b50\u8f6c\u5316\u4e3a\u9690\u5199\u8f7d\u4f53\uff0c\u8fd9\u4e9b\u8f7d\u4f53\u5d4c\u5165\u9ad8\u540e\u95e8\u8d1f\u8f7d\u3001\u4fdd\u6301\u6d41\u7545\u6027\uff0c\u4e14\u4e0e\u89e6\u53d1\u5668\u6ca1\u6709\u8868\u5f81\u76f8\u4f3c\u6027\u3002", "result": "\u5728\u591a\u6837\u5316\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\uff0cSteganoBackdoor\u4ee5\u6bd4\u5148\u524d\u65b9\u6cd5\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u6570\u636e\u6295\u6bd2\u7387\u5b9e\u73b0\u4e86\u8d85\u8fc799%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u5728\u9762\u5bf9\u5168\u9762\u6570\u636e\u7ea7\u9632\u5fa1\u5957\u4ef6\u65f6\u4fdd\u6301\u65e0\u4e0e\u4f26\u6bd4\u7684\u89c4\u907f\u80fd\u529b\u3002", "conclusion": "SteganoBackdoor\u63ed\u793a\u4e86\u5f53\u524d\u9632\u5fa1\u673a\u5236\u4e2d\u7684\u4e00\u4e2a\u7d27\u6025\u76f2\u70b9\uff0c\u8feb\u5207\u9700\u8981\u5173\u6ce8\u5bf9\u6297\u6027\u6570\u636e\u9632\u5fa1\u548c\u73b0\u5b9e\u4e16\u754c\u5a01\u80c1\u5efa\u6a21\u3002"}}
{"id": "2511.14131", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14131", "abs": "https://arxiv.org/abs/2511.14131", "authors": ["Yu Zhong", "Zihao Zhang", "Rui Zhang", "Lingdong Huang", "Haihan Gao", "Shuo Wang", "Da Li", "Ruijian Han", "Jiaming Guo", "Shaohui Peng", "Di Huang", "Yunji Chen"], "title": "Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation", "comment": null, "summary": "Vision-and-Language Navigation (VLN) requires an agent to dynamically explore complex 3D environments following human instructions. Recent research underscores the potential of harnessing large language models (LLMs) for VLN, given their commonsense knowledge and general reasoning capabilities. Despite their strengths, a substantial gap in task completion performance persists between LLM-based approaches and domain experts, as LLMs inherently struggle to comprehend real-world spatial correlations precisely. Additionally, introducing LLMs is accompanied with substantial computational cost and inference latency. To address these issues, we propose a novel dual-process thinking framework dubbed R3, integrating LLMs' generalization capabilities with VLN-specific expertise in a zero-shot manner. The framework comprises three core modules: Runner, Ruminator, and Regulator. The Runner is a lightweight transformer-based expert model that ensures efficient and accurate navigation under regular circumstances. The Ruminator employs a powerful multimodal LLM as the backbone and adopts chain-of-thought (CoT) prompting to elicit structured reasoning. The Regulator monitors the navigation progress and controls the appropriate thinking mode according to three criteria, integrating Runner and Ruminator harmoniously. Experimental results illustrate that R3 significantly outperforms other state-of-the-art methods, exceeding 3.28% and 3.30% in SPL and RGSPL respectively on the REVERIE benchmark. This pronounced enhancement highlights the effectiveness of our method in handling challenging VLN tasks.", "AI": {"tldr": "R3\u662f\u4e00\u4e2a\u7528\u4e8e\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u7684\u53cc\u8fc7\u7a0b\u601d\u8003\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548cVLN\u7279\u5b9a\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u5bfc\u822a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684VLN\u65b9\u6cd5\u5728\u4efb\u52a1\u5b8c\u6210\u6027\u80fd\u4e0a\u4e0e\u9886\u57df\u4e13\u5bb6\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u4e14LLM\u96be\u4ee5\u7cbe\u786e\u7406\u89e3\u771f\u5b9e\u4e16\u754c\u7a7a\u95f4\u5173\u7cfb\uff0c\u540c\u65f6\u8ba1\u7b97\u6210\u672c\u548c\u63a8\u7406\u5ef6\u8fdf\u8f83\u9ad8\u3002", "method": "\u63d0\u51faR3\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u8f7b\u91cf\u7ea7\u4e13\u5bb6\u6a21\u578bRunner\u8d1f\u8d23\u5e38\u89c4\u5bfc\u822a\uff0c\u591a\u6a21\u6001LLM Ruminator\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\uff0cRegulator\u6839\u636e\u4e09\u4e2a\u6807\u51c6\u76d1\u63a7\u5bfc\u822a\u8fdb\u5ea6\u5e76\u63a7\u5236\u601d\u7ef4\u6a21\u5f0f\u3002", "result": "\u5728REVERIE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSPL\u548cRGSPL\u5206\u522b\u8d85\u8fc7\u6700\u5148\u8fdb\u65b9\u6cd53.28%\u548c3.30%\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6311\u6218\u6027VLN\u4efb\u52a1\u7684\u5904\u7406\u6548\u679c\u3002", "conclusion": "R3\u6846\u67b6\u901a\u8fc7\u6574\u5408LLM\u7684\u6cdb\u5316\u80fd\u529b\u548cVLN\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.14422", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14422", "abs": "https://arxiv.org/abs/2511.14422", "authors": ["Zhengchunmin Dai", "Jiaxiong Tang", "Peng Sun", "Honglong Chen", "Liantao Wu"], "title": "Sigil: Server-Enforced Watermarking in U-Shaped Split Federated Learning via Gradient Injection", "comment": "18 pages,8 figures", "summary": "In decentralized machine learning paradigms such as Split Federated Learning (SFL) and its variant U-shaped SFL, the server's capabilities are severely restricted. Although this enhances client-side privacy, it also leaves the server highly vulnerable to model theft by malicious clients. Ensuring intellectual property protection for such capability-limited servers presents a dual challenge: watermarking schemes that depend on client cooperation are unreliable in adversarial settings, whereas traditional server-side watermarking schemes are technically infeasible because the server lacks access to critical elements such as model parameters or labels.\n  To address this challenge, this paper proposes Sigil, a mandatory watermarking framework designed specifically for capability-limited servers. Sigil defines the watermark as a statistical constraint on the server-visible activation space and embeds the watermark into the client model via gradient injection, without requiring any knowledge of the data. Besides, we design an adaptive gradient clipping mechanism to ensure that our watermarking process remains both mandatory and stealthy, effectively countering existing gradient anomaly detection methods and a specifically designed adaptive subspace removal attack. Extensive experiments on multiple datasets and models demonstrate Sigil's fidelity, robustness, and stealthiness.", "AI": {"tldr": "Sigil\u662f\u4e00\u4e2a\u4e13\u4e3a\u80fd\u529b\u53d7\u9650\u670d\u52a1\u5668\u8bbe\u8ba1\u7684\u5f3a\u5236\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u6ce8\u5165\u5728\u5ba2\u6237\u7aef\u6a21\u578b\u4e2d\u5d4c\u5165\u6c34\u5370\uff0c\u65e0\u9700\u6570\u636e\u77e5\u8bc6\u5373\u53ef\u4fdd\u62a4\u670d\u52a1\u5668\u77e5\u8bc6\u4ea7\u6743\u3002", "motivation": "\u5728Split Federated Learning\u7b49\u53bb\u4e2d\u5fc3\u5316\u673a\u5668\u5b66\u4e60\u8303\u5f0f\u4e2d\uff0c\u670d\u52a1\u5668\u80fd\u529b\u53d7\u9650\u867d\u7136\u589e\u5f3a\u4e86\u5ba2\u6237\u7aef\u9690\u79c1\uff0c\u4f46\u4e5f\u4f7f\u670d\u52a1\u5668\u5bb9\u6613\u53d7\u5230\u6076\u610f\u5ba2\u6237\u7aef\u7684\u6a21\u578b\u7a83\u53d6\u653b\u51fb\uff0c\u73b0\u6709\u6c34\u5370\u65b9\u6848\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u4e0d\u53ef\u9760\u6216\u6280\u672f\u4e0a\u4e0d\u53ef\u884c\u3002", "method": "Sigil\u5c06\u6c34\u5370\u5b9a\u4e49\u4e3a\u670d\u52a1\u5668\u53ef\u89c1\u6fc0\u6d3b\u7a7a\u95f4\u7684\u7edf\u8ba1\u7ea6\u675f\uff0c\u901a\u8fc7\u68af\u5ea6\u6ce8\u5165\u5c06\u6c34\u5370\u5d4c\u5165\u5ba2\u6237\u7aef\u6a21\u578b\uff0c\u8bbe\u8ba1\u4e86\u81ea\u9002\u5e94\u68af\u5ea6\u88c1\u526a\u673a\u5236\u786e\u4fdd\u6c34\u5370\u8fc7\u7a0b\u7684\u5f3a\u5236\u6027\u548c\u9690\u853d\u6027\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSigil\u5177\u6709\u826f\u597d\u7684\u4fdd\u771f\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u9690\u853d\u6027\uff0c\u80fd\u591f\u6709\u6548\u5bf9\u6297\u73b0\u6709\u7684\u68af\u5ea6\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u548c\u4e13\u95e8\u8bbe\u8ba1\u7684\u81ea\u9002\u5e94\u5b50\u7a7a\u95f4\u79fb\u9664\u653b\u51fb\u3002", "conclusion": "Sigil\u4e3a\u80fd\u529b\u53d7\u9650\u670d\u52a1\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u65b9\u6848\uff0c\u901a\u8fc7\u7edf\u8ba1\u7ea6\u675f\u548c\u68af\u5ea6\u6ce8\u5165\u5b9e\u73b0\u4e86\u5f3a\u5236\u6c34\u5370\u5d4c\u5165\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6c34\u5370\u65b9\u6848\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u4e0d\u8db3\u3002"}}
{"id": "2511.14611", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.14611", "abs": "https://arxiv.org/abs/2511.14611", "authors": ["Charles Cheng Ji", "Brandon Kong"], "title": "SecureSign: Bridging Security and UX in Mobile Web3 through Emulated EIP-6963 Sandboxing", "comment": "19 pages, 11 figures", "summary": "Mobile Web3 faces catastrophic retention (< 5%) yielding effective acquisition costs of \\$500 - \\$1,000 per retained user. Existing solutions force an impossible tradeoff: embedded wallets achieve moderate usability but suffer inherent click-jacking vulnerabilities; app wallets maintain security at the cost of 2 - 3% retention due to download friction and context-switching penalties. We present SecureSign, a PWA-based architecture that adapts desktop browser extension security to mobile via EIP-6963 provider sandboxing. SecureSign isolates dApp execution in iframes within a trusted parent application, achieving click-jacking immunity and transaction integrity while enabling native mobile capabilities (push notifications, home screen installation, zero context-switching). Our drop-in SDK requires no codebase changes for existing Web3 applications. Threat model analysis demonstrates immunity to click-jacking, overlay, and skimming attacks while maintaining wallet interoperability across dApps.", "AI": {"tldr": "SecureSign\u662f\u4e00\u4e2aPWA\u67b6\u6784\uff0c\u901a\u8fc7EIP-6963\u63d0\u4f9b\u7a0b\u5e8f\u6c99\u7bb1\u5316\u5c06\u684c\u9762\u6d4f\u89c8\u5668\u6269\u5c55\u5b89\u5168\u6027\u9002\u914d\u5230\u79fb\u52a8\u7aef\uff0c\u89e3\u51b3\u4e86\u79fb\u52a8Web3\u7528\u6237\u7559\u5b58\u7387\u4f4e\u548c\u5b89\u5168\u6027\u95ee\u9898\u3002", "motivation": "\u79fb\u52a8Web3\u9762\u4e34\u707e\u96be\u6027\u7684\u7528\u6237\u7559\u5b58\u7387\uff08<5%\uff09\uff0c\u5bfc\u81f4\u6bcf\u4e2a\u7559\u5b58\u7528\u6237\u7684\u6709\u6548\u83b7\u53d6\u6210\u672c\u9ad8\u8fbe500-1000\u7f8e\u5143\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u4e24\u96be\u9009\u62e9\uff1a\u5d4c\u5165\u5f0f\u94b1\u5305\u5177\u6709\u4e2d\u7b49\u53ef\u7528\u6027\u4f46\u5b58\u5728\u56fa\u6709\u7684\u70b9\u51fb\u52ab\u6301\u6f0f\u6d1e\uff1b\u5e94\u7528\u94b1\u5305\u4fdd\u6301\u5b89\u5168\u6027\u4f46\u4e0b\u8f7d\u6469\u64e6\u548c\u4e0a\u4e0b\u6587\u5207\u6362\u5bfc\u81f4\u7559\u5b58\u7387\u4ec5\u4e3a2-3%\u3002", "method": "SecureSign\u91c7\u7528PWA\u67b6\u6784\uff0c\u901a\u8fc7EIP-6963\u63d0\u4f9b\u7a0b\u5e8f\u6c99\u7bb1\u5316\u5c06\u684c\u9762\u6d4f\u89c8\u5668\u6269\u5c55\u5b89\u5168\u6027\u9002\u914d\u5230\u79fb\u52a8\u7aef\u3002\u5b83\u5728\u53ef\u4fe1\u7236\u5e94\u7528\u7a0b\u5e8f\u4e2d\u4f7f\u7528iframe\u9694\u79bbdApp\u6267\u884c\uff0c\u5b9e\u73b0\u70b9\u51fb\u52ab\u6301\u514d\u75ab\u548c\u4ea4\u6613\u5b8c\u6574\u6027\uff0c\u540c\u65f6\u652f\u6301\u539f\u751f\u79fb\u52a8\u529f\u80fd\uff08\u63a8\u9001\u901a\u77e5\u3001\u4e3b\u5c4f\u5e55\u5b89\u88c5\u3001\u96f6\u4e0a\u4e0b\u6587\u5207\u6362\uff09\u3002", "result": "\u5a01\u80c1\u6a21\u578b\u5206\u6790\u8bc1\u660eSecureSign\u5bf9\u70b9\u51fb\u52ab\u6301\u3001\u8986\u76d6\u548c\u7a83\u53d6\u653b\u51fb\u5177\u6709\u514d\u75ab\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u8de8dApp\u7684\u94b1\u5305\u4e92\u64cd\u4f5c\u6027\u3002\u8be5\u5373\u63d2\u5373\u7528SDK\u65e0\u9700\u5bf9\u73b0\u6709Web3\u5e94\u7528\u7a0b\u5e8f\u8fdb\u884c\u4ee3\u7801\u5e93\u66f4\u6539\u3002", "conclusion": "SecureSign\u6210\u529f\u89e3\u51b3\u4e86\u79fb\u52a8Web3\u5728\u5b89\u5168\u6027\u548c\u7528\u6237\u4f53\u9a8c\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e2\u5b89\u5168\u53c8\u7528\u6237\u53cb\u597d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u663e\u8457\u63d0\u9ad8\u79fb\u52a8Web3\u7684\u7528\u6237\u7559\u5b58\u7387\u3002"}}
{"id": "2511.14717", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14717", "abs": "https://arxiv.org/abs/2511.14717", "authors": ["Benedikt Peterseim", "Milan Lopuha\u00e4-Zwakenberg"], "title": "A Unified Compositional View of Attack Tree Metrics", "comment": null, "summary": "Attack trees (ATs) are popular graphical models for reasoning about the security of complex systems, allowing for the quantification of risk through so-called AT metrics. A large variety of different such AT metrics have been proposed, and despite their wide-spread practical use, no systematic treatment of attack tree metrics so far is fully satisfactory. Existing approaches either fail to include important metrics, or they are too general to provide a useful systematic way for defining concrete AT metrics, giving only an abstract characterisation of their behaviour. We solve this problem by developing a compositional theory of ATs and their functorial semantics based on gs-monoidal categories. Viewing attack trees as string diagrams, we show that components of ATs form a channel category, a particular type of gs-monoidal category. AT metrics then correspond to functors of channel categories. This characterisation is both general enough to include all common AT metrics, and concrete enough to define AT metrics by their logical structure.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u57fa\u4e8egs-\u5e7a\u534a\u8303\u7574\u7684\u7ec4\u5408\u7406\u8bba\uff0c\u4e3a\u653b\u51fb\u6811\u53ca\u5176\u5ea6\u91cf\u63d0\u4f9b\u4e86\u51fd\u5b50\u8bed\u4e49\u5b66\uff0c\u5c06\u653b\u51fb\u6811\u89c6\u4e3a\u5b57\u7b26\u4e32\u56fe\uff0c\u8bc1\u660e\u5176\u7ec4\u4ef6\u5f62\u6210\u901a\u9053\u8303\u7574\uff0c\u4ece\u800c\u7edf\u4e00\u4e86\u5404\u79cd\u653b\u51fb\u6811\u5ea6\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u653b\u51fb\u6811\u5ea6\u91cf\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u5305\u542b\u91cd\u8981\u5ea6\u91cf\uff0c\u8981\u4e48\u8fc7\u4e8e\u62bd\u8c61\u65e0\u6cd5\u63d0\u4f9b\u5b9a\u4e49\u5177\u4f53\u5ea6\u91cf\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u7f3a\u4e4f\u5bf9\u653b\u51fb\u6811\u5ea6\u91cf\u7684\u7cfb\u7edf\u5316\u5904\u7406\u3002", "method": "\u5c06\u653b\u51fb\u6811\u89c6\u4e3a\u5b57\u7b26\u4e32\u56fe\uff0c\u8bc1\u660e\u5176\u7ec4\u4ef6\u5f62\u6210\u901a\u9053\u8303\u7574\uff08\u4e00\u79cd\u7279\u6b8a\u7684gs-\u5e7a\u534a\u8303\u7574\uff09\uff0c\u653b\u51fb\u6811\u5ea6\u91cf\u5bf9\u5e94\u4e8e\u901a\u9053\u8303\u7574\u7684\u51fd\u5b50\u3002", "result": "\u8be5\u7279\u5f81\u5316\u65e2\u8db3\u591f\u901a\u7528\u4ee5\u5305\u542b\u6240\u6709\u5e38\u89c1\u7684\u653b\u51fb\u6811\u5ea6\u91cf\uff0c\u53c8\u8db3\u591f\u5177\u4f53\u4ee5\u901a\u8fc7\u903b\u8f91\u7ed3\u6784\u5b9a\u4e49\u653b\u51fb\u6811\u5ea6\u91cf\u3002", "conclusion": "\u57fa\u4e8egs-\u5e7a\u534a\u8303\u7574\u7684\u7ec4\u5408\u7406\u8bba\u4e3a\u653b\u51fb\u6811\u5ea6\u91cf\u63d0\u4f9b\u4e86\u7edf\u4e00\u4e14\u5b9e\u7528\u7684\u7cfb\u7edf\u5316\u6846\u67b6\u3002"}}
{"id": "2511.14214", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14214", "abs": "https://arxiv.org/abs/2511.14214", "authors": ["Pattaraphon Kenny Wongchamcharoen", "Paul Glasserman"], "title": "Do Large Language Models (LLMs) Understand Chronology?", "comment": "47 pages", "summary": "Large language models (LLMs) are increasingly used in finance and economics, where prompt-based attempts against look-ahead bias implicitly assume that models understand chronology. We test this fundamental question with a series of chronological ordering tasks with increasing complexities over facts the model already knows from pre-training. Our tasks cover (1) chronological ordering, (2) conditional sorting (filter, then order), and (3) anachronism detection. We evaluate GPT-4.1, Claude-3.7 Sonnet, with and without Extended Thinking (ET), and GPT-5 across multiple reasoning-effort settings. Across models, Exact match rate drops sharply as sequences lengthen even while rank correlations stay high as LLMs largely preserve local order but struggle to maintain a single globally consistent timeline. In conditional sorting, most failures stem from the filtering step rather than the ordering step, but GPT-5 and Claude-3.7 Sonnet with Extended Thinking outshine normal models significantly. Lastly, anachronism detection is found to be the easiest task for the LLMs but performance still declines with increasingly overlapping timelines or entities. Overall, our main contribution is showing that allocating explicit reasoning budget helps with chronological ordering with GPT-5 at medium/high reasoning effort achieving flawless ordering at all lengths and perfect conditional sorting (both self-filtered and given-subset), whereas low/minimal effort degrades with longer lists, mirroring earlier models. Our findings delineate limits of current LLMs on chronological tasks, providing insights into task complexity, and demonstrate scenarios in which reasoning helps. These patterns are important for the real-time application of LLMs in finance. We release all code and evaluation templates to support full reproducibility.", "AI": {"tldr": "\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u5e94\u7528\u4e2d\u7406\u89e3\u65f6\u95f4\u987a\u5e8f\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u590d\u6742\u65f6\u95f4\u6392\u5e8f\u4efb\u52a1\u4e2d\u5b58\u5728\u56f0\u96be\uff0c\u4f46\u589e\u52a0\u63a8\u7406\u9884\u7b97\u80fd\u663e\u8457\u63d0\u5347GPT-5\u548cClaude-3.7 Sonnet\u7684\u8868\u73b0\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u548c\u7ecf\u6d4e\u5b66\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u9a8c\u8bc1\u5176\u662f\u5426\u771f\u6b63\u7406\u89e3\u65f6\u95f4\u987a\u5e8f\uff0c\u4ee5\u907f\u514d\u524d\u77bb\u6027\u504f\u5dee\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u7cfb\u5217\u65f6\u95f4\u987a\u5e8f\u4efb\u52a1\uff0c\u5305\u62ec\u65f6\u95f4\u6392\u5e8f\u3001\u6761\u4ef6\u6392\u5e8f\uff08\u5148\u8fc7\u6ee4\u540e\u6392\u5e8f\uff09\u548c\u65f6\u4ee3\u9519\u8bef\u68c0\u6d4b\uff0c\u8bc4\u4f30GPT-4.1\u3001Claude-3.7 Sonnet\u548cGPT-5\u5728\u4e0d\u540c\u63a8\u7406\u5f3a\u5ea6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u6a21\u578b\u5728\u957f\u5e8f\u5217\u4e2d\u7684\u7cbe\u786e\u5339\u914d\u7387\u663e\u8457\u4e0b\u964d\uff0c\u4f46\u6392\u540d\u76f8\u5173\u6027\u4fdd\u6301\u8f83\u9ad8\uff1b\u6761\u4ef6\u6392\u5e8f\u4e2d\u5931\u8d25\u4e3b\u8981\u6765\u81ea\u8fc7\u6ee4\u6b65\u9aa4\uff1b\u65f6\u4ee3\u9519\u8bef\u68c0\u6d4b\u662f\u6700\u7b80\u5355\u7684\u4efb\u52a1\u3002GPT-5\u5728\u4e2d\u7b49/\u9ad8\u63a8\u7406\u5f3a\u5ea6\u4e0b\u5728\u6240\u6709\u957f\u5ea6\u4e0a\u90fd\u80fd\u5b9e\u73b0\u5b8c\u7f8e\u6392\u5e8f\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u65f6\u95f4\u4efb\u52a1\u4e0a\u5b58\u5728\u5c40\u9650\u6027\uff0c\u660e\u786e\u5206\u914d\u63a8\u7406\u9884\u7b97\u6709\u52a9\u4e8e\u63d0\u5347\u65f6\u95f4\u6392\u5e8f\u80fd\u529b\uff0c\u8fd9\u5bf9LLMs\u5728\u91d1\u878d\u9886\u57df\u7684\u5b9e\u65f6\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.14219", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.14219", "abs": "https://arxiv.org/abs/2511.14219", "authors": ["Kumud Tripathi", "Aditya Srinivas Menon", "Aman Gaurav", "Raj Prakash Gohil", "Pankaj Wasnik"], "title": "Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation", "comment": "Accepted at AAAI 2026 - Main Technical Track", "summary": "The Whisper model, an open-source automatic speech recognition system, is widely adopted for its strong performance across multilingual and zero-shot settings. However, it frequently suffers from hallucination errors, especially under noisy acoustic conditions. Previous works to reduce hallucinations in Whisper-style ASR systems have primarily focused on audio preprocessing or post-processing of transcriptions to filter out erroneous content. However, modifications to the Whisper model itself remain largely unexplored to mitigate hallucinations directly. To address this challenge, we present a two-stage architecture that first enhances encoder robustness through Adaptive Layer Attention (ALA) and further suppresses hallucinations using a multi-objective knowledge distillation (KD) framework. In the first stage, ALA groups encoder layers into semantically coherent blocks via inter-layer correlation analysis. A learnable multi-head attention module then fuses these block representations, enabling the model to jointly exploit low- and high-level features for more robust encoding. In the second stage, our KD framework trains the student model on noisy audio to align its semantic and attention distributions with a teacher model processing clean inputs. Our experiments on noisy speech benchmarks show notable reductions in hallucinations and word error rates, while preserving performance on clean speech. Together, ALA and KD offer a principled strategy to improve Whisper's reliability under real-world noisy conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u67b6\u6784\u6765\u51cf\u5c11Whisper\u6a21\u578b\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u5e7b\u89c9\u9519\u8bef\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u81ea\u9002\u5e94\u5c42\u6ce8\u610f\u529b\u589e\u5f3a\u7f16\u7801\u5668\u9c81\u68d2\u6027\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u591a\u76ee\u6807\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\u6291\u5236\u5e7b\u89c9", "motivation": "Whisper\u6a21\u578b\u5728\u566a\u58f0\u58f0\u5b66\u6761\u4ef6\u4e0b\u7ecf\u5e38\u51fa\u73b0\u5e7b\u89c9\u9519\u8bef\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u97f3\u9891\u9884\u5904\u7406\u6216\u8f6c\u5f55\u540e\u5904\u7406\uff0c\u5bf9\u6a21\u578b\u672c\u8eab\u7684\u4fee\u6539\u63a2\u7d22\u4e0d\u8db3", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u81ea\u9002\u5e94\u5c42\u6ce8\u610f\u529b\u5c06\u7f16\u7801\u5668\u5c42\u5206\u7ec4\u5e76\u901a\u8fc7\u591a\u5934\u6ce8\u610f\u529b\u878d\u5408\u5757\u8868\u793a\uff1b2) \u591a\u76ee\u6807\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\u5728\u566a\u58f0\u97f3\u9891\u4e0a\u5bf9\u9f50\u6559\u5e08\u6a21\u578b\u7684\u8bed\u4e49\u548c\u6ce8\u610f\u529b\u5206\u5e03", "result": "\u5728\u566a\u58f0\u8bed\u97f3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u51cf\u5c11\u4e86\u5e7b\u89c9\u548c\u8bcd\u9519\u8bef\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5728\u5e72\u51c0\u8bed\u97f3\u4e0a\u7684\u6027\u80fd", "conclusion": "ALA\u548cKD\u4e3a\u5728\u771f\u5b9e\u4e16\u754c\u566a\u58f0\u6761\u4ef6\u4e0b\u63d0\u9ad8Whisper\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7b56\u7565"}}
{"id": "2511.14227", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14227", "abs": "https://arxiv.org/abs/2511.14227", "authors": ["Yuxiang Wang", "Siwen Wang", "Haowei Han", "Ao Wang", "Boya Liu", "Yong Zhao", "Chengbo Wu", "Bin Zhu", "Bin Qin", "Xiaokai Zhou", "Xiao Yan", "Jiawei Jiang", "Bo Du"], "title": "DevPiolt: Operation Recommendation for IoT Devices at Xiaomi Home", "comment": null, "summary": "Operation recommendation for IoT devices refers to generating personalized device operations for users based on their context, such as historical operations, environment information, and device status. This task is crucial for enhancing user satisfaction and corporate profits. Existing recommendation models struggle with complex operation logic, diverse user preferences, and sensitive to suboptimal suggestions, limiting their applicability to IoT device operations. To address these issues, we propose DevPiolt, a LLM-based recommendation model for IoT device operations. Specifically, we first equip the LLM with fundamental domain knowledge of IoT operations via continual pre-training and multi-task fine-tuning. Then, we employ direct preference optimization to align the fine-tuned LLM with specific user preferences. Finally, we design a confidence-based exposure control mechanism to avoid negative user experiences from low-quality recommendations. Extensive experiments show that DevPiolt significantly outperforms baselines on all datasets, with an average improvement of 69.5% across all metrics. DevPiolt has been practically deployed in Xiaomi Home app for one quarter, providing daily operation recommendations to 255,000 users. Online experiment results indicate a 21.6% increase in unique visitor device coverage and a 29.1% increase in page view acceptance rates.", "AI": {"tldr": "DevPiolt\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7269\u8054\u7f51\u8bbe\u5907\u64cd\u4f5c\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u591a\u4efb\u52a1\u5fae\u8c03\u3001\u76f4\u63a5\u504f\u597d\u4f18\u5316\u548c\u7f6e\u4fe1\u5ea6\u63a7\u5236\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u64cd\u4f5c\u63a8\u8350\u7684\u51c6\u786e\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u73b0\u6709\u63a8\u8350\u6a21\u578b\u5728\u5904\u7406\u7269\u8054\u7f51\u8bbe\u5907\u64cd\u4f5c\u65f6\u9762\u4e34\u590d\u6742\u64cd\u4f5c\u903b\u8f91\u3001\u591a\u6837\u5316\u7528\u6237\u504f\u597d\u548c\u5bf9\u6b21\u4f18\u5efa\u8bae\u654f\u611f\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6548\u679c\u3002", "method": "1) \u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u591a\u4efb\u52a1\u5fae\u8c03\u4e3aLLM\u6ce8\u5165\u7269\u8054\u7f51\u9886\u57df\u77e5\u8bc6\uff1b2) \u4f7f\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\u4f7f\u6a21\u578b\u4e0e\u7528\u6237\u504f\u597d\u5bf9\u9f50\uff1b3) \u8bbe\u8ba1\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u66dd\u5149\u63a7\u5236\u673a\u5236\u907f\u514d\u4f4e\u8d28\u91cf\u63a8\u8350\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6240\u6709\u6307\u6807\u5e73\u5747\u63d0\u534769.5%\u3002\u5728\u5c0f\u7c73\u5bb6\u5ead\u5e94\u7528\u4e2d\u5b9e\u9645\u90e8\u7f72\u4e00\u4e2a\u5b63\u5ea6\uff0c\u670d\u52a125.5\u4e07\u7528\u6237\uff0c\u5728\u7ebf\u5b9e\u9a8c\u663e\u793a\u72ec\u7279\u8bbf\u5ba2\u8bbe\u5907\u8986\u76d6\u7387\u63d0\u534721.6%\uff0c\u9875\u9762\u6d4f\u89c8\u63a5\u53d7\u7387\u63d0\u534729.1%\u3002", "conclusion": "DevPiolt\u901a\u8fc7\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u6ce8\u5165\u3001\u504f\u597d\u5bf9\u9f50\u548c\u7f6e\u4fe1\u5ea6\u63a7\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7269\u8054\u7f51\u8bbe\u5907\u64cd\u4f5c\u63a8\u8350\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\u3002"}}
{"id": "2511.14248", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14248", "abs": "https://arxiv.org/abs/2511.14248", "authors": ["Hongju Lee", "Youngjun Park", "Jisun An", "Dongman Lee"], "title": "Enhancing Regional Airbnb Trend Forecasting Using LLM-Based Embeddings of Accessibility and Human Mobility", "comment": "Accepted at ASONAM 2025", "summary": "The expansion of short-term rental platforms, such as Airbnb, has significantly disrupted local housing markets, often leading to increased rental prices and housing affordability issues. Accurately forecasting regional Airbnb market trends can thus offer critical insights for policymakers and urban planners aiming to mitigate these impacts. This study proposes a novel time-series forecasting framework to predict three key Airbnb indicators -- Revenue, Reservation Days, and Number of Reservations -- at the regional level. Using a sliding-window approach, the model forecasts trends 1 to 3 months ahead. Unlike prior studies that focus on individual listings at fixed time points, our approach constructs regional representations by integrating listing features with external contextual factors such as urban accessibility and human mobility. We convert structured tabular data into prompt-based inputs for a Large Language Model (LLM), producing comprehensive regional embeddings. These embeddings are then fed into advanced time-series models (RNN, LSTM, Transformer) to better capture complex spatio-temporal dynamics. Experiments on Seoul's Airbnb dataset show that our method reduces both average RMSE and MAE by approximately 48% compared to conventional baselines, including traditional statistical and machine learning models. Our framework not only improves forecasting accuracy but also offers practical insights for detecting oversupplied regions and supporting data-driven urban policy decisions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u533a\u57df\u5c42\u9762\u7684Airbnb\u5173\u952e\u6307\u6807\uff08\u6536\u5165\u3001\u9884\u8ba2\u5929\u6570\u3001\u9884\u8ba2\u6570\u91cf\uff09\uff0c\u901a\u8fc7\u7ed3\u5408\u623f\u6e90\u7279\u5f81\u4e0e\u5916\u90e8\u73af\u5883\u56e0\u7d20\u6784\u5efa\u533a\u57df\u8868\u793a\uff0c\u4f7f\u7528LLM\u751f\u6210\u533a\u57df\u5d4c\u5165\uff0c\u5e76\u91c7\u7528\u5148\u8fdb\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u5728\u9996\u5c14\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\u5c06RMSE\u548cMAE\u964d\u4f4e\u4e86\u7ea648%\u3002", "motivation": "\u77ed\u671f\u79df\u8d41\u5e73\u53f0\uff08\u5982Airbnb\uff09\u7684\u6269\u5f20\u4e25\u91cd\u6270\u4e71\u4e86\u5f53\u5730\u4f4f\u623f\u5e02\u573a\uff0c\u5bfc\u81f4\u79df\u91d1\u4e0a\u6da8\u548c\u4f4f\u623f\u8d1f\u62c5\u80fd\u529b\u95ee\u9898\u3002\u51c6\u786e\u9884\u6d4b\u533a\u57dfAirbnb\u5e02\u573a\u8d8b\u52bf\u53ef\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u548c\u57ce\u5e02\u89c4\u5212\u8005\u63d0\u4f9b\u5173\u952e\u89c1\u89e3\uff0c\u4ee5\u51cf\u8f7b\u8fd9\u4e9b\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u9884\u6d4b1-3\u4e2a\u6708\u7684\u8d8b\u52bf\uff0c\u901a\u8fc7\u6574\u5408\u623f\u6e90\u7279\u5f81\u4e0e\u57ce\u5e02\u53ef\u8fbe\u6027\u3001\u4eba\u53e3\u6d41\u52a8\u7b49\u5916\u90e8\u73af\u5883\u56e0\u7d20\u6784\u5efa\u533a\u57df\u8868\u793a\uff0c\u5c06\u7ed3\u6784\u5316\u8868\u683c\u6570\u636e\u8f6c\u6362\u4e3a\u57fa\u4e8e\u63d0\u793a\u7684LLM\u8f93\u5165\u4ee5\u751f\u6210\u7efc\u5408\u533a\u57df\u5d4c\u5165\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u5d4c\u5165\u8f93\u5165\u5230\u5148\u8fdb\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\uff08RNN\u3001LSTM\u3001Transformer\uff09\u4e2d\u6355\u6349\u590d\u6742\u7684\u65f6\u7a7a\u52a8\u6001\u3002", "result": "\u5728\u9996\u5c14Airbnb\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\uff0c\u5e73\u5747RMSE\u548cMAE\u964d\u4f4e\u4e86\u7ea648%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u4e3a\u68c0\u6d4b\u4f9b\u5e94\u8fc7\u5269\u533a\u57df\u548c\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u57ce\u5e02\u653f\u7b56\u51b3\u7b56\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2511.14256", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.14256", "abs": "https://arxiv.org/abs/2511.14256", "authors": ["Yu Liu", "Xixun Lin", "Yanmin Shang", "Yangxi Li", "Shi Wang", "Yanan Cao"], "title": "PathMind: A Retrieve-Prioritize-Reason Framework for Knowledge Graph Reasoning with Large Language Models", "comment": "AAAI 2026, Long Paper, Oral", "summary": "Knowledge graph reasoning (KGR) is the task of inferring new knowledge by performing logical deductions on knowledge graphs. Recently, large language models (LLMs) have demonstrated remarkable performance in complex reasoning tasks. Despite promising success, current LLM-based KGR methods still face two critical limitations. First, existing methods often extract reasoning paths indiscriminately, without assessing their different importance, which may introduce irrelevant noise that misleads LLMs. Second, while many methods leverage LLMs to dynamically explore potential reasoning paths, they require high retrieval demands and frequent LLM calls. To address these limitations, we propose PathMind, a novel framework designed to enhance faithful and interpretable reasoning by selectively guiding LLMs with important reasoning paths. Specifically, PathMind follows a \"Retrieve-Prioritize-Reason\" paradigm. First, it retrieves a query subgraph from KG through the retrieval module. Next, it introduces a path prioritization mechanism that identifies important reasoning paths using a semantic-aware path priority function, which simultaneously considers the accumulative cost and the estimated future cost for reaching the target. Finally, PathMind generates accurate and logically consistent responses via a dual-phase training strategy, including task-specific instruction tuning and path-wise preference alignment. Extensive experiments on benchmark datasets demonstrate that PathMind consistently outperforms competitive baselines, particularly on complex reasoning tasks with fewer input tokens, by identifying essential reasoning paths.", "AI": {"tldr": "PathMind\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\"\u68c0\u7d22-\u4f18\u5148\u5316-\u63a8\u7406\"\u8303\u5f0f\uff0c\u9009\u62e9\u6027\u5f15\u5bfcLLM\u4f7f\u7528\u91cd\u8981\u63a8\u7406\u8def\u5f84\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u8def\u5f84\u91cd\u8981\u6027\u8bc4\u4f30\u4e0d\u8db3\u548c\u9891\u7e41\u8c03\u7528LLM\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a\u4e00\u662f\u65e0\u5dee\u522b\u63d0\u53d6\u63a8\u7406\u8def\u5f84\u53ef\u80fd\u5f15\u5165\u65e0\u5173\u566a\u58f0\u8bef\u5bfcLLM\uff1b\u4e8c\u662f\u52a8\u6001\u63a2\u7d22\u63a8\u7406\u8def\u5f84\u9700\u8981\u9ad8\u68c0\u7d22\u9700\u6c42\u548c\u9891\u7e41LLM\u8c03\u7528\u3002", "method": "PathMind\u91c7\u7528\"\u68c0\u7d22-\u4f18\u5148\u5316-\u63a8\u7406\"\u8303\u5f0f\uff1a\u9996\u5148\u901a\u8fc7\u68c0\u7d22\u6a21\u5757\u4eceKG\u4e2d\u83b7\u53d6\u67e5\u8be2\u5b50\u56fe\uff1b\u7136\u540e\u5f15\u5165\u8def\u5f84\u4f18\u5148\u5316\u673a\u5236\uff0c\u4f7f\u7528\u8bed\u4e49\u611f\u77e5\u8def\u5f84\u4f18\u5148\u7ea7\u51fd\u6570\u8bc6\u522b\u91cd\u8981\u63a8\u7406\u8def\u5f84\uff1b\u6700\u540e\u901a\u8fc7\u53cc\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u751f\u6210\u51c6\u786e\u54cd\u5e94\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPathMind\u59cb\u7ec8\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u63a8\u7406\u8def\u5f84\u5b9e\u73b0\u4e86\u66f4\u5c11\u7684\u8f93\u5165token\u548c\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "PathMind\u901a\u8fc7\u9009\u62e9\u6027\u5f15\u5bfcLLM\u4f7f\u7528\u91cd\u8981\u63a8\u7406\u8def\u5f84\uff0c\u589e\u5f3a\u4e86\u5fe0\u5b9e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u63a8\u7406\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM-based KGR\u65b9\u6cd5\u7684\u5173\u952e\u5c40\u9650\u3002"}}
{"id": "2511.14334", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14334", "abs": "https://arxiv.org/abs/2511.14334", "authors": ["Alessio Pellegrino", "Jacopo Mauro"], "title": "When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling", "comment": null, "summary": "One of the long-standing goals in optimisation and constraint programming is to describe a problem in natural language and automatically obtain an executable, efficient model. Large language models appear to bring this vision closer, showing impressive results in automatically generating models for classical benchmarks. However, much of this apparent success may derive from data contamination rather than genuine reasoning: many standard CP problems are likely included in the training data of these models. To examine this hypothesis, we systematically rephrased and perturbed a set of well-known CSPLib problems to preserve their structure while modifying their context and introducing misleading elements. We then compared the models produced by three representative LLMs across original and modified descriptions. Our qualitative analysis shows that while LLMs can produce syntactically valid and semantically plausible models, their performance drops sharply under contextual and linguistic variation, revealing shallow understanding and sensitivity to wording.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u91cd\u8ff0\u548c\u6270\u52a8CSPLib\u95ee\u9898\uff0c\u6d4b\u8bd5LLMs\u5728\u4e0a\u4e0b\u6587\u548c\u8bed\u8a00\u53d8\u5316\u4e0b\u7684\u6a21\u578b\u751f\u6210\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u63ed\u793a\u5176\u6d45\u5c42\u7406\u89e3\u548c\u5bf9\u63aa\u8f9e\u7684\u654f\u611f\u6027\u3002", "motivation": "\u63a2\u7a76LLMs\u81ea\u52a8\u751f\u6210\u4f18\u5316\u548c\u7ea6\u675f\u7f16\u7a0b\u6a21\u578b\u7684\u80fd\u529b\u662f\u5426\u6e90\u4e8e\u6570\u636e\u6c61\u67d3\u800c\u975e\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u4e3a\u8bb8\u591a\u6807\u51c6CP\u95ee\u9898\u53ef\u80fd\u5df2\u5305\u542b\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u91cd\u8ff0\u548c\u6270\u52a8\u4e00\u7ec4\u77e5\u540dCSPLib\u95ee\u9898\uff0c\u4fdd\u6301\u5176\u7ed3\u6784\u4f46\u4fee\u6539\u4e0a\u4e0b\u6587\u5e76\u5f15\u5165\u8bef\u5bfc\u5143\u7d20\uff0c\u7136\u540e\u6bd4\u8f83\u4e09\u4e2a\u4ee3\u8868\u6027LLM\u5728\u539f\u59cb\u548c\u4fee\u6539\u63cf\u8ff0\u4e0b\u751f\u6210\u7684\u6a21\u578b\u3002", "result": "LLMs\u80fd\u591f\u751f\u6210\u8bed\u6cd5\u6709\u6548\u4e14\u8bed\u4e49\u5408\u7406\u7684\u6a21\u578b\uff0c\u4f46\u5728\u4e0a\u4e0b\u6587\u548c\u8bed\u8a00\u53d8\u5316\u4e0b\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u663e\u793a\u51fa\u6d45\u5c42\u7406\u89e3\u548c\u5bf9\u63aa\u8f9e\u7684\u654f\u611f\u6027\u3002", "conclusion": "LLMs\u5728\u81ea\u52a8\u751f\u6210\u4f18\u5316\u6a21\u578b\u65b9\u9762\u7684\u6210\u529f\u53ef\u80fd\u66f4\u591a\u6e90\u4e8e\u6570\u636e\u6c61\u67d3\u800c\u975e\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5176\u7406\u89e3\u6df1\u5ea6\u6709\u9650\u4e14\u5bf9\u8bed\u8a00\u8868\u8ff0\u654f\u611f\u3002"}}
{"id": "2511.14476", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14476", "abs": "https://arxiv.org/abs/2511.14476", "authors": ["Dalia Ali", "Dora Zhao", "Allison Koenecke", "Orestis Papakyriakopoulos"], "title": "Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior", "comment": null, "summary": "Although large language models (LLMs) are increasingly trained using human feedback for safety and alignment with human values, alignment decisions often overlook human social diversity. This study examines how incorporating pluralistic values affects LLM behavior by systematically evaluating demographic variation and design parameters in the alignment pipeline. We collected alignment data from US and German participants (N = 1,095, 27,375 ratings) who rated LLM responses across five dimensions: Toxicity, Emotional Awareness (EA), Sensitivity, Stereotypical Bias, and Helpfulness. We fine-tuned multiple Large Language Models and Large Reasoning Models using preferences from different social groups while varying rating scales, disagreement handling methods, and optimization techniques. The results revealed systematic demographic effects: male participants rated responses 18% less toxic than female participants; conservative and Black participants rated responses 27.9% and 44% more emotionally aware than liberal and White participants, respectively. Models fine-tuned on group-specific preferences exhibited distinct behaviors. Technical design choices showed strong effects: the preservation of rater disagreement achieved roughly 53% greater toxicity reduction than majority voting, and 5-point scales yielded about 22% more reduction than binary formats; and Direct Preference Optimization (DPO) consistently outperformed Group Relative Policy Optimization (GRPO) in multi-value optimization. These findings represent a preliminary step in answering a critical question: How should alignment balance expert-driven and user-driven signals to ensure both safety and fair representation?", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728LLM\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u8003\u8651\u591a\u5143\u793e\u4f1a\u4ef7\u503c\u89c2\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u6536\u96c6\u6765\u81ea\u7f8e\u56fd\u548c\u5fb7\u56fd\u53c2\u4e0e\u8005\u768427,375\u4e2a\u8bc4\u5206\u6570\u636e\uff0c\u5206\u6790\u4e86\u4eba\u53e3\u7edf\u8ba1\u5dee\u5f02\u548c\u6280\u672f\u8bbe\u8ba1\u53c2\u6570\u5bf9\u6a21\u578b\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "motivation": "\u5f53\u524dLLM\u7684\u5bf9\u9f50\u51b3\u7b56\u5f80\u5f80\u5ffd\u89c6\u4eba\u7c7b\u793e\u4f1a\u7684\u591a\u6837\u6027\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5c06\u591a\u5143\u4ef7\u503c\u89c2\u7eb3\u5165\u5bf9\u9f50\u6d41\u7a0b\uff0c\u4ee5\u5e73\u8861\u5b89\u5168\u6027\u548c\u516c\u5e73\u4ee3\u8868\u6027\u3002", "method": "\u6536\u96c6\u6765\u81ea\u7f8e\u56fd\u548c\u5fb7\u56fd1,095\u540d\u53c2\u4e0e\u8005\u7684\u8bc4\u5206\u6570\u636e\uff0c\u6db5\u76d6\u6bd2\u6027\u3001\u60c5\u611f\u610f\u8bc6\u3001\u654f\u611f\u6027\u3001\u523b\u677f\u504f\u89c1\u548c\u5e2e\u52a9\u6027\u4e94\u4e2a\u7ef4\u5ea6\u3002\u4f7f\u7528\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\u7684\u504f\u597d\u5fae\u8c03\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u63a8\u7406\u6a21\u578b\uff0c\u540c\u65f6\u6539\u53d8\u8bc4\u5206\u5c3a\u5ea6\u3001\u5206\u6b67\u5904\u7406\u65b9\u6cd5\u548c\u4f18\u5316\u6280\u672f\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u6027\u4eba\u53e3\u7edf\u8ba1\u6548\u5e94\uff1a\u7537\u6027\u53c2\u4e0e\u8005\u5bf9\u6bd2\u6027\u7684\u8bc4\u5206\u6bd4\u5973\u6027\u4f4e18%\uff1b\u4fdd\u5b88\u6d3e\u548c\u9ed1\u4eba\u53c2\u4e0e\u8005\u5bf9\u60c5\u611f\u610f\u8bc6\u7684\u8bc4\u5206\u5206\u522b\u6bd4\u81ea\u7531\u6d3e\u548c\u767d\u4eba\u53c2\u4e0e\u8005\u9ad827.9%\u548c44%\u3002\u6280\u672f\u8bbe\u8ba1\u9009\u62e9\u663e\u793a\u5f3a\u70c8\u5f71\u54cd\uff1a\u4fdd\u7559\u8bc4\u5206\u8005\u5206\u6b67\u6bd4\u591a\u6570\u6295\u7968\u51cf\u5c11\u7ea653%\u7684\u6bd2\u6027\uff1b5\u70b9\u91cf\u8868\u6bd4\u4e8c\u5143\u683c\u5f0f\u51cf\u5c11\u7ea622%\u7684\u6bd2\u6027\uff1bDPO\u5728\u591a\u503c\u4f18\u5316\u4e2d\u6301\u7eed\u4f18\u4e8eGRPO\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u56de\u7b54\u5173\u952e\u95ee\u9898\u63d0\u4f9b\u4e86\u521d\u6b65\u6b65\u9aa4\uff1a\u5bf9\u9f50\u5e94\u5982\u4f55\u5e73\u8861\u4e13\u5bb6\u9a71\u52a8\u548c\u7528\u6237\u9a71\u52a8\u7684\u4fe1\u53f7\uff0c\u4ee5\u786e\u4fdd\u5b89\u5168\u6027\u548c\u516c\u5e73\u4ee3\u8868\u6027\uff1f"}}
{"id": "2511.14595", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14595", "abs": "https://arxiv.org/abs/2511.14595", "authors": ["Yuan An", "Ruhma Hashmi", "Michelle Rogers", "Jane Greenberg", "Brian K. Smith"], "title": "Rate-Distortion Guided Knowledge Graph Construction from Lecture Notes Using Gromov-Wasserstein Optimal Transport", "comment": "Accepted in the 5th Workshop on Knowledge Graphs and Big Data in Conjunction with IEEE Big Data 2025", "summary": "Task-oriented knowledge graphs (KGs) enable AI-powered learning assistant systems to automatically generate high-quality multiple-choice questions (MCQs). Yet converting unstructured educational materials, such as lecture notes and slides, into KGs that capture key pedagogical content remains difficult. We propose a framework for knowledge graph construction and refinement grounded in rate-distortion (RD) theory and optimal transport geometry. In the framework, lecture content is modeled as a metric-measure space, capturing semantic and relational structure, while candidate KGs are aligned using Fused Gromov-Wasserstein (FGW) couplings to quantify semantic distortion. The rate term, expressed via the size of KG, reflects complexity and compactness. Refinement operators (add, merge, split, remove, rewire) minimize the rate-distortion Lagrangian, yielding compact, information-preserving KGs. Our prototype applied to data science lectures yields interpretable RD curves and shows that MCQs generated from refined KGs consistently surpass those from raw notes on fifteen quality criteria. This study establishes a principled foundation for information-theoretic KG optimization in personalized and AI-assisted education.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7387\u5931\u771f\u7406\u8bba\u548c\u6700\u4f18\u4f20\u8f93\u51e0\u4f55\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e0e\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7FGW\u8026\u5408\u91cf\u5316\u8bed\u4e49\u5931\u771f\uff0c\u4f7f\u7528\u7ec6\u5316\u64cd\u4f5c\u6700\u5c0f\u5316\u7387\u5931\u771f\u62c9\u683c\u6717\u65e5\u51fd\u6570\uff0c\u751f\u6210\u7d27\u51d1\u4e14\u4fe1\u606f\u4fdd\u7559\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u663e\u8457\u63d0\u5347\u591a\u9009\u9898\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u5c06\u975e\u7ed3\u6784\u5316\u6559\u80b2\u6750\u6599\uff08\u5982\u8bb2\u4e49\u548c\u5e7b\u706f\u7247\uff09\u8f6c\u6362\u4e3a\u6355\u6349\u5173\u952e\u6559\u5b66\u5185\u5bb9\u7684\u77e5\u8bc6\u56fe\u8c31\u4ecd\u7136\u56f0\u96be\uff0c\u9700\u8981\u5efa\u7acb\u7406\u8bba\u57fa\u7840\u7684KG\u4f18\u5316\u65b9\u6cd5\u4ee5\u652f\u6301AI\u8f85\u52a9\u6559\u80b2\u3002", "method": "\u5c06\u8bb2\u5ea7\u5185\u5bb9\u5efa\u6a21\u4e3a\u5ea6\u91cf-\u6d4b\u5ea6\u7a7a\u95f4\uff0c\u4f7f\u7528Fused Gromov-Wasserstein\u8026\u5408\u91cf\u5316\u8bed\u4e49\u5931\u771f\uff0c\u901a\u8fc7\u6dfb\u52a0\u3001\u5408\u5e76\u3001\u62c6\u5206\u3001\u79fb\u9664\u548c\u91cd\u8fde\u7b49\u7ec6\u5316\u64cd\u4f5c\u6700\u5c0f\u5316\u7387\u5931\u771f\u62c9\u683c\u6717\u65e5\u51fd\u6570\u3002", "result": "\u5728\u6570\u636e\u79d1\u5b66\u8bb2\u5ea7\u4e0a\u7684\u539f\u578b\u5e94\u7528\u663e\u793a\uff0c\u4ece\u4f18\u5316KG\u751f\u6210\u7684\u591a\u9009\u9898\u572815\u4e2a\u8d28\u91cf\u6807\u51c6\u4e0a\u6301\u7eed\u4f18\u4e8e\u4ece\u539f\u59cb\u7b14\u8bb0\u751f\u6210\u7684\u95ee\u9898\uff0c\u5e76\u4ea7\u751f\u53ef\u89e3\u91ca\u7684\u7387\u5931\u771f\u66f2\u7ebf\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u4e2a\u6027\u5316AI\u8f85\u52a9\u6559\u80b2\u4e2d\u7684\u4fe1\u606f\u8bba\u77e5\u8bc6\u56fe\u8c31\u4f18\u5316\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u8bc1\u660e\u4f18\u5316\u540e\u7684KG\u80fd\u663e\u8457\u63d0\u5347\u81ea\u52a8\u751f\u6210\u95ee\u9898\u7684\u8d28\u91cf\u3002"}}
{"id": "2511.14670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14670", "abs": "https://arxiv.org/abs/2511.14670", "authors": ["Ruomeng Ding", "Wei Cheng", "Minglai Shao", "Chen Zhao"], "title": "SkillGen: Learning Domain Skills for In-Context Sequential Decision Making", "comment": null, "summary": "Large language models (LLMs) are increasingly applied to sequential decision-making through in-context learning (ICL), yet their effectiveness is highly sensitive to prompt quality. Effective prompts should meet three principles: focus on decision-critical information, provide step-level granularity, and minimize reliance on expert annotations through label efficiency. However, existing ICL methods often fail to satisfy all three criteria simultaneously. Motivated by these challenges, we introduce SkillGen, a skill-based ICL framework for structured sequential reasoning. It constructs an action-centric, domain-level graph from sampled trajectories, identifies high-utility actions via temporal-difference credit assignment, and retrieves step-wise skills to generate fine-grained, context-aware prompts. We further present a theoretical analysis showing that focusing on high-utility segments supports task identifiability and informs more effective ICL prompt design. Experiments on ALFWorld, BabyAI, and ScienceWorld, using both open-source and proprietary LLMs, show that SkillGen achieves consistent gains, improving progress rate by 5.9%-16.5% on average across models.", "AI": {"tldr": "SkillGen\u662f\u4e00\u4e2a\u57fa\u4e8e\u6280\u80fd\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u52a8\u4f5c\u4e2d\u5fc3\u56fe\u3001\u8bc6\u522b\u9ad8\u6548\u7528\u52a8\u4f5c\u548c\u68c0\u7d22\u6b65\u9aa4\u6280\u80fd\uff0c\u4e3a\u5e8f\u5217\u51b3\u7b56\u751f\u6210\u7ec6\u7c92\u5ea6\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347LLM\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709ICL\u65b9\u6cd5\u5728\u5e8f\u5217\u51b3\u7b56\u4e2d\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u4e09\u4e2a\u5173\u952e\u539f\u5219\uff1a\u5173\u6ce8\u51b3\u7b56\u5173\u952e\u4fe1\u606f\u3001\u63d0\u4f9b\u6b65\u9aa4\u7ea7\u7c92\u5ea6\u3001\u6700\u5c0f\u5316\u4e13\u5bb6\u6807\u6ce8\u4f9d\u8d56\u3002\u8fd9\u4e9b\u6311\u6218\u4fc3\u4f7f\u5f00\u53d1SkillGen\u6846\u67b6\u3002", "method": "SkillGen\u6784\u5efa\u52a8\u4f5c\u4e2d\u5fc3\u7684\u9886\u57df\u7ea7\u56fe\uff0c\u901a\u8fc7\u65f6\u95f4\u5dee\u5206\u4fe1\u7528\u5206\u914d\u8bc6\u522b\u9ad8\u6548\u7528\u52a8\u4f5c\uff0c\u5e76\u68c0\u7d22\u6b65\u9aa4\u7ea7\u6280\u80fd\u6765\u751f\u6210\u7ec6\u7c92\u5ea6\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\u3002", "result": "\u5728ALFWorld\u3001BabyAI\u548cScienceWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u5f00\u6e90\u548c\u4e13\u6709LLM\uff0cSkillGen\u5e73\u5747\u63d0\u9ad8\u8fdb\u5ea6\u73875.9%-16.5%\u3002", "conclusion": "\u5173\u6ce8\u9ad8\u6548\u7528\u7247\u6bb5\u652f\u6301\u4efb\u52a1\u53ef\u8bc6\u522b\u6027\uff0c\u5e76\u4e3a\u66f4\u6709\u6548\u7684ICL\u63d0\u793a\u8bbe\u8ba1\u63d0\u4f9b\u4fe1\u606f\uff0cSkillGen\u5728\u5e8f\u5217\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.14730", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14730", "abs": "https://arxiv.org/abs/2511.14730", "authors": ["Parya Dolatyabi", "Mahdi Khodayar"], "title": "Heterogeneous Multi-Agent Proximal Policy Optimization for Power Distribution System Restoration", "comment": "6 pages, 4 figures, TPEC 2025 Conference", "summary": "Restoring power distribution systems (PDS) after large-scale outages requires sequential switching operations that reconfigure feeder topology and coordinate distributed energy resources (DERs) under nonlinear constraints such as power balance, voltage limits, and thermal ratings. These challenges make conventional optimization and value-based RL approaches computationally inefficient and difficult to scale. This paper applies a Heterogeneous-Agent Reinforcement Learning (HARL) framework, instantiated through Heterogeneous-Agent Proximal Policy Optimization (HAPPO), to enable coordinated restoration across interconnected microgrids. Each agent controls a distinct microgrid with different loads, DER capacities, and switch counts, introducing practical structural heterogeneity. Decentralized actor policies are trained with a centralized critic to compute advantage values for stable on-policy updates. A physics-informed OpenDSS environment provides full power flow feedback and enforces operational limits via differentiable penalty signals rather than invalid action masking. The total DER generation is capped at 2400 kW, and each microgrid must satisfy local supply-demand feasibility. Experiments on the IEEE 123-bus and IEEE 8500-node systems show that HAPPO achieves faster convergence, higher restored power, and smoother multi-seed training than DQN, PPO, MAES, MAGDPG, MADQN, Mean-Field RL, and QMIX. Results demonstrate that incorporating microgrid-level heterogeneity within the HARL framework yields a scalable, stable, and constraint-aware solution for complex PDS restoration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f02\u6784\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff08HARL\uff09\uff0c\u901a\u8fc7\u5f02\u6784\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08HAPPO\uff09\u5b9e\u73b0\u4e92\u8054\u5fae\u7535\u7f51\u7684\u534f\u8c03\u6062\u590d\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u5728\u975e\u7ebf\u6027\u7ea6\u675f\u4e0b\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u5927\u89c4\u6a21\u505c\u7535\u540e\u6062\u590d\u914d\u7535\u7cfb\u7edf\u9700\u8981\u987a\u5e8f\u5207\u6362\u64cd\u4f5c\uff0c\u5728\u975e\u7ebf\u6027\u7ea6\u675f\u4e0b\u91cd\u65b0\u914d\u7f6e\u9988\u7ebf\u62d3\u6251\u548c\u534f\u8c03\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\uff0c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u548c\u57fa\u4e8e\u4ef7\u503c\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u6269\u5c55\u3002", "method": "\u91c7\u7528\u5f02\u6784\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u63a7\u5236\u5177\u6709\u4e0d\u540c\u8d1f\u8f7d\u3001DER\u5bb9\u91cf\u548c\u5f00\u5173\u6570\u91cf\u7684\u5fae\u7535\u7f51\uff0c\u4f7f\u7528\u5206\u6563\u7684\u53c2\u4e0e\u8005\u7b56\u7565\u548c\u96c6\u4e2d\u8bc4\u8bba\u5bb6\u8fdb\u884c\u8bad\u7ec3\uff0c\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u5316\u7684OpenDSS\u73af\u5883\u63d0\u4f9b\u5b8c\u6574\u6f6e\u6d41\u53cd\u9988\u3002", "result": "\u5728IEEE 123\u603b\u7ebf\u548cIEEE 8500\u8282\u70b9\u7cfb\u7edf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHAPPO\u76f8\u6bd4DQN\u3001PPO\u3001MAES\u7b49\u65b9\u6cd5\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3001\u66f4\u9ad8\u7684\u6062\u590d\u529f\u7387\u548c\u66f4\u5e73\u6ed1\u7684\u591a\u79cd\u5b50\u8bad\u7ec3\u6548\u679c\u3002", "conclusion": "\u5728HARL\u6846\u67b6\u4e2d\u5f15\u5165\u5fae\u7535\u7f51\u7ea7\u5f02\u6784\u6027\uff0c\u4e3a\u590d\u6742\u914d\u7535\u7cfb\u7edf\u6062\u590d\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u7a33\u5b9a\u4e14\u7ea6\u675f\u611f\u77e5\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
