{"id": "2506.21688", "categories": ["cs.CR", "cs.GT"], "pdf": "https://arxiv.org/pdf/2506.21688", "abs": "https://arxiv.org/abs/2506.21688", "authors": ["Michael Lanier", "Yevgeniy Vorobeychik"], "title": "CyGym: A Simulation-Based Game-Theoretic Analysis Framework for Cybersecurity", "comment": null, "summary": "We introduce a novel cybersecurity encounter simulator between a network\ndefender and an attacker designed to facilitate game-theoretic modeling and\nanalysis while maintaining many significant features of real cyber defense. Our\nsimulator, built within the OpenAI Gym framework, incorporates realistic\nnetwork topologies, vulnerabilities, exploits (including-zero-days), and\ndefensive mechanisms. Additionally, we provide a formal simulation-based\ngame-theoretic model of cyberdefense using this simulator, which features a\nnovel approach to modeling zero-days exploits, and a PSRO-style approach for\napproximately computing equilibria in this game. We use our simulator and\nassociated game-theoretic framework to analyze the Volt Typhoon advanced\npersistent threat (APT). Volt Typhoon represents a sophisticated cyber attack\nstrategy employed by state-sponsored actors, characterized by stealthy,\nprolonged infiltration and exploitation of network vulnerabilities. Our\nexperimental results demonstrate the efficacy of game-theoretic strategies in\nunderstanding network resilience against APTs and zero-days, such as Volt\nTyphoon, providing valuable insight into optimal defensive posture and\nproactive threat mitigation.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8eOpenAI Gym\u7684\u7f51\u7edc\u5b89\u5168\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u535a\u5f08\u8bba\u5efa\u6a21\u548c\u5206\u6790\uff0c\u6a21\u62df\u771f\u5b9e\u7f51\u7edc\u9632\u5fa1\u573a\u666f\uff0c\u5305\u62ec\u96f6\u65e5\u6f0f\u6d1e\u548c\u9632\u5fa1\u673a\u5236\uff0c\u5e76\u5e94\u7528\u4e8e\u5206\u6790\u9ad8\u7ea7\u6301\u7eed\u6027\u5a01\u80c1\uff08\u5982Volt Typhoon\uff09\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u535a\u5f08\u8bba\u65b9\u6cd5\u63d0\u5347\u7f51\u7edc\u9632\u5fa1\u80fd\u529b\uff0c\u7279\u522b\u662f\u9488\u5bf9\u9ad8\u7ea7\u6301\u7eed\u6027\u5a01\u80c1\u548c\u96f6\u65e5\u6f0f\u6d1e\u7684\u9632\u5fa1\u7b56\u7565\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2aOpenAI Gym\u6846\u67b6\u4e0b\u7684\u6a21\u62df\u5668\uff0c\u7ed3\u5408\u771f\u5b9e\u7f51\u7edc\u62d3\u6251\u3001\u6f0f\u6d1e\u548c\u9632\u5fa1\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8ePSRO\u7684\u535a\u5f08\u8bba\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u535a\u5f08\u8bba\u7b56\u7565\u80fd\u6709\u6548\u5206\u6790\u7f51\u7edc\u5bf9\u9ad8\u7ea7\u6301\u7eed\u6027\u5a01\u80c1\uff08\u5982Volt Typhoon\uff09\u548c\u96f6\u65e5\u6f0f\u6d1e\u7684\u97e7\u6027\u3002", "conclusion": "\u8be5\u6a21\u62df\u5668\u548c\u535a\u5f08\u8bba\u6846\u67b6\u4e3a\u4f18\u5316\u9632\u5fa1\u7b56\u7565\u548c\u4e3b\u52a8\u5a01\u80c1\u7f13\u89e3\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2506.21874", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21874", "abs": "https://arxiv.org/abs/2506.21874", "authors": ["Stanley Wu", "Ronik Bhaskar", "Anna Yoo Jeong Ha", "Shawn Shan", "Haitao Zheng", "Ben Y. Zhao"], "title": "On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling", "comment": "ACM Conference on Computer and Communications Security 2025", "summary": "Today's text-to-image generative models are trained on millions of images\nsourced from the Internet, each paired with a detailed caption produced by\nVision-Language Models (VLMs). This part of the training pipeline is critical\nfor supplying the models with large volumes of high-quality image-caption pairs\nduring training. However, recent work suggests that VLMs are vulnerable to\nstealthy adversarial attacks, where adversarial perturbations are added to\nimages to mislead the VLMs into producing incorrect captions.\n  In this paper, we explore the feasibility of adversarial mislabeling attacks\non VLMs as a mechanism to poisoning training pipelines for text-to-image\nmodels. Our experiments demonstrate that VLMs are highly vulnerable to\nadversarial perturbations, allowing attackers to produce benign-looking images\nthat are consistently miscaptioned by the VLM models. This has the effect of\ninjecting strong \"dirty-label\" poison samples into the training pipeline for\ntext-to-image models, successfully altering their behavior with a small number\nof poisoned samples. We find that while potential defenses can be effective,\nthey can be targeted and circumvented by adaptive attackers. This suggests a\ncat-and-mouse game that is likely to reduce the quality of training data and\nincrease the cost of text-to-image model development. Finally, we demonstrate\nthe real-world effectiveness of these attacks, achieving high attack success\n(over 73%) even in black-box scenarios against commercial VLMs (Google Vertex\nAI and Microsoft Azure).", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u901a\u8fc7\u5bf9\u6297\u6027\u653b\u51fb\u8bef\u5bfc\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u751f\u6210\u9519\u8bef\u6807\u6ce8\uff0c\u4ece\u800c\u6c61\u67d3\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5b9e\u9a8c\u8bc1\u660e\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe73%\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u751f\u6210\u56fe\u50cf\u6807\u6ce8\u65f6\u6613\u53d7\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u8fd9\u53ef\u80fd\u88ab\u5229\u7528\u6765\u6c61\u67d3\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5f71\u54cd\u5176\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5bf9\u6297\u6027\u6270\u52a8\u751f\u6210\u770b\u4f3c\u65e0\u5bb3\u4f46\u88abVLMs\u9519\u8bef\u6807\u6ce8\u7684\u56fe\u50cf\uff0c\u6ce8\u5165\u5c11\u91cf\u201c\u810f\u6807\u7b7e\u201d\u6837\u672c\u5230\u8bad\u7ec3\u6570\u636e\u4e2d\u3002", "result": "\u653b\u51fb\u6210\u529f\u7387\u9ad8\uff0873%\uff09\uff0c\u4e14\u9632\u5fa1\u63aa\u65bd\u53ef\u80fd\u88ab\u9002\u5e94\u6027\u653b\u51fb\u8005\u7ed5\u8fc7\u3002", "conclusion": "\u5bf9\u6297\u6027\u653b\u51fb\u53ef\u80fd\u5bfc\u81f4\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u4e0b\u964d\uff0c\u589e\u52a0\u6a21\u578b\u5f00\u53d1\u6210\u672c\uff0c\u672a\u6765\u9700\u66f4\u9c81\u68d2\u7684\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2506.21897", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.21897", "abs": "https://arxiv.org/abs/2506.21897", "authors": ["Twisha Chattopadhyay", "Fabricio Ceschin", "Marco E. Garza", "Dymytriy Zyunkin", "Animesh Chhotaray", "Aaron P. Stebner", "Saman Zonouz", "Raheem Beyah"], "title": "One Video to Steal Them All: 3D-Printing IP Theft through Optical Side-Channels", "comment": "17 pages [Extended Version]", "summary": "The 3D printing industry is rapidly growing and increasingly adopted across\nvarious sectors including manufacturing, healthcare, and defense. However, the\noperational setup often involves hazardous environments, necessitating remote\nmonitoring through cameras and other sensors, which opens the door to\ncyber-based attacks. In this paper, we show that an adversary with access to\nvideo recordings of the 3D printing process can reverse engineer the underlying\n3D print instructions. Our model tracks the printer nozzle movements during the\nprinting process and maps the corresponding trajectory into G-code\ninstructions. Further, it identifies the correct parameters such as feed rate\nand extrusion rate, enabling successful intellectual property theft. To\nvalidate this, we design an equivalence checker that quantitatively compares\ntwo sets of 3D print instructions, evaluating their similarity in producing\nobjects alike in shape, external appearance, and internal structure. Unlike\nsimple distance-based metrics such as normalized mean square error, our\nequivalence checker is both rotationally and translationally invariant,\naccounting for shifts in the base position of the reverse engineered\ninstructions caused by different camera positions. Our model achieves an\naverage accuracy of 90.87 percent and generates 30.20 percent fewer\ninstructions compared to existing methods, which often produce faulty or\ninaccurate prints. Finally, we demonstrate a fully functional counterfeit\nobject generated by reverse engineering 3D print instructions from video.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u89c6\u9891\u76d1\u63a7\u9006\u5411\u5de5\u7a0b3D\u6253\u5370\u6307\u4ee4\u7684\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u5e76\u9a8c\u8bc1\u4e86\u77e5\u8bc6\u4ea7\u6743\u76d7\u7a83\u7684\u53ef\u884c\u6027\u3002", "motivation": "3D\u6253\u5370\u884c\u4e1a\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u8fdc\u7a0b\u76d1\u63a7\u53ef\u80fd\u5f15\u53d1\u7f51\u7edc\u5b89\u5168\u95ee\u9898\uff0c\u5c24\u5176\u662f\u901a\u8fc7\u89c6\u9891\u9006\u5411\u5de5\u7a0b\u7a83\u53d6\u6253\u5370\u6307\u4ee4\u3002", "method": "\u901a\u8fc7\u8ddf\u8e2a\u6253\u5370\u673a\u55b7\u5634\u8fd0\u52a8\u8f68\u8ff9\u5e76\u6620\u5c04\u4e3aG\u4ee3\u7801\u6307\u4ee4\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65cb\u8f6c\u548c\u5e73\u79fb\u4e0d\u53d8\u7684\u7b49\u4ef7\u6027\u68c0\u67e5\u5668\u3002", "result": "\u6a21\u578b\u5e73\u5747\u51c6\u786e\u7387\u8fbe90.87%\uff0c\u751f\u6210\u7684\u6307\u4ee4\u6bd4\u73b0\u6709\u65b9\u6cd5\u5c1130.20%\uff0c\u6210\u529f\u590d\u5236\u4e86\u529f\u80fd\u5b8c\u6574\u7684\u4f2a\u9020\u5bf9\u8c61\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u89c6\u9891\u76d1\u63a7\u53ef\u80fd\u6210\u4e3a3D\u6253\u5370\u77e5\u8bc6\u4ea7\u6743\u7684\u65b0\u5a01\u80c1\uff0c\u9700\u52a0\u5f3a\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u3002"}}
{"id": "2506.21914", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.21914", "abs": "https://arxiv.org/abs/2506.21914", "authors": ["Elina van Kempen", "Isita Bagayatkar", "Pavel Frolikov", "Chloe Georgiou", "Gene Tsudik"], "title": "Consumer Beware! Exploring Data Brokers' CCPA Compliance", "comment": null, "summary": "Data brokers collect and sell the personal information of millions of\nindividuals, often without their knowledge or consent. The California Consumer\nPrivacy Act (CCPA) grants consumers the legal right to request access to, or\ndeletion of, their data. To facilitate these requests, California maintains an\nofficial registry of data brokers. However, the extent to which these entities\ncomply with the law is unclear.\n  This paper presents the first large-scale, systematic study of CCPA\ncompliance of all 543 officially registered data brokers. Data access requests\nwere manually submitted to each broker, followed by in-depth analyses of their\nresponses (or lack thereof). Above 40% failed to respond at all, in an apparent\nviolation of the CCPA. Data brokers that responded requested personal\ninformation as part of their identity verification process, including details\nthey had not previously collected. Paradoxically, this means that exercising\none's privacy rights under CCPA introduces new privacy risks.\n  Our findings reveal rampant non-compliance and lack of standardization of the\ndata access request process. These issues highlight an urgent need for stronger\nenforcement, clearer guidelines, and standardized, periodic compliance checks\nto enhance consumers' privacy protections and improve data broker\naccountability.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u52a0\u5dde\u6570\u636e\u7ecf\u7eaa\u5546\u5728CCPA\u5408\u89c4\u6027\u65b9\u9762\u5b58\u5728\u666e\u904d\u95ee\u9898\uff0c40%\u4ee5\u4e0a\u672a\u56de\u5e94\u6570\u636e\u8bbf\u95ee\u8bf7\u6c42\uff0c\u4e14\u8eab\u4efd\u9a8c\u8bc1\u8fc7\u7a0b\u53ef\u80fd\u5f15\u5165\u65b0\u7684\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u63a2\u8ba8\u6570\u636e\u7ecf\u7eaa\u5546\u5728CCPA\u4e0b\u7684\u5408\u89c4\u60c5\u51b5\uff0c\u63ed\u793a\u6d88\u8d39\u8005\u9690\u79c1\u4fdd\u62a4\u7684\u73b0\u72b6\u4e0e\u95ee\u9898\u3002", "method": "\u5bf9543\u5bb6\u6ce8\u518c\u6570\u636e\u7ecf\u7eaa\u5546\u624b\u52a8\u63d0\u4ea4\u6570\u636e\u8bbf\u95ee\u8bf7\u6c42\uff0c\u5e76\u5206\u6790\u5176\u56de\u5e94\u60c5\u51b5\u3002", "result": "40%\u4ee5\u4e0a\u7ecf\u7eaa\u5546\u672a\u56de\u5e94\u8bf7\u6c42\uff0c\u90e8\u5206\u5728\u8eab\u4efd\u9a8c\u8bc1\u4e2d\u8981\u6c42\u989d\u5916\u4e2a\u4eba\u4fe1\u606f\uff0c\u589e\u52a0\u9690\u79c1\u98ce\u9669\u3002", "conclusion": "\u9700\u52a0\u5f3a\u6267\u6cd5\u3001\u660e\u786e\u6307\u5357\u5e76\u6807\u51c6\u5316\u5408\u89c4\u68c0\u67e5\uff0c\u4ee5\u63d0\u5347\u6d88\u8d39\u8005\u9690\u79c1\u4fdd\u62a4\u548c\u7ecf\u7eaa\u5546\u8d23\u4efb\u3002"}}
{"id": "2506.21634", "categories": ["cs.SE", "D.2.0; A.m; K.m"], "pdf": "https://arxiv.org/pdf/2506.21634", "abs": "https://arxiv.org/abs/2506.21634", "authors": ["Lutz Prechelt", "Lloyd Montgomery", "Julian Frattini", "Franz Zieris"], "title": "How (Not) To Write a Software Engineering Abstract", "comment": "16 pages, 11 figures, 2 tables", "summary": "Background: Abstracts are a particularly valuable element in a software\nengineering research article. However, not all abstracts are as informative as\nthey could be. Objective: Characterize the structure of abstracts in\nhigh-quality software engineering venues. Observe and quantify deficiencies.\nSuggest guidelines for writing informative abstracts. Methods: Use qualitative\nopen coding to derive concepts that explain relevant properties of abstracts.\nIdentify the archetypical structure of abstracts. Use quantitative content\nanalysis to objectively characterize abstract structure of a sample of 362\nabstracts from five presumably high-quality venues. Use exploratory data\nanalysis to find recurring issues in abstracts. Compare the archetypical\nstructure to actual structures. Infer guidelines for producing informative\nabstracts. Results: Only 29% of the sampled abstracts are complete, i.e.,\nprovide background, objective, method, result, and conclusion information. For\nstructured abstracts, the ratio is twice as big. Only 4% of the abstracts are\nproper, i.e., they also have good readability (Flesch-Kincaid score) and have\nno informativeness gaps, understandability gaps, nor highly ambiguous\nsentences. Conclusions: (1) Even in top venues, a large majority of abstracts\nare far from ideal. (2) Structured abstracts tend to be better than\nunstructured ones. (3) Artifact-centric works need a different structured\nformat. (4) The community should start requiring conclusions that generalize,\nwhich currently are often missing in abstracts.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u9ad8\u8d28\u91cf\u8f6f\u4ef6\u5de5\u7a0b\u4f1a\u8bae\u6458\u8981\u7684\u7ed3\u6784\uff0c\u53d1\u73b0\u5927\u591a\u6570\u6458\u8981\u4e0d\u5b8c\u6574\u6216\u5b58\u5728\u95ee\u9898\uff0c\u5efa\u8bae\u91c7\u7528\u7ed3\u6784\u5316\u6458\u8981\u683c\u5f0f\u5e76\u6539\u8fdb\u5185\u5bb9\u3002", "motivation": "\u7814\u7a76\u9ad8\u8d28\u91cf\u8f6f\u4ef6\u5de5\u7a0b\u4f1a\u8bae\u6458\u8981\u7684\u7ed3\u6784\uff0c\u4ee5\u53d1\u73b0\u5176\u4e0d\u8db3\u5e76\u63d0\u51fa\u6539\u8fdb\u6307\u5357\u3002", "method": "\u901a\u8fc7\u5b9a\u6027\u5f00\u653e\u7f16\u7801\u548c\u5b9a\u91cf\u5185\u5bb9\u5206\u6790\uff0c\u5206\u6790\u4e86362\u7bc7\u6458\u8981\u7684\u7ed3\u6784\u548c\u95ee\u9898\u3002", "result": "\u4ec529%\u7684\u6458\u8981\u5b8c\u6574\uff0c4%\u7684\u6458\u8981\u8d28\u91cf\u826f\u597d\uff1b\u7ed3\u6784\u5316\u6458\u8981\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u5927\u591a\u6570\u6458\u8981\u4e0d\u7406\u60f3\uff0c\u7ed3\u6784\u5316\u6458\u8981\u66f4\u4f18\uff0c\u5efa\u8bae\u6539\u8fdb\u683c\u5f0f\u548c\u5185\u5bb9\u3002"}}
{"id": "2506.21669", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21669", "abs": "https://arxiv.org/abs/2506.21669", "authors": ["Wanxin Tian", "Shijie Zhang", "Kevin Zhang", "Xiaowei Chi", "Yulin Luo", "Junyu Lu", "Chunkai Fan", "Qiang Zhou", "Yiming Zhao", "Ning Liu Siyu Lin", "Zhiyuan Qin", "Xiaozhu Ju", "Shanghang Zhang", "Jian Tang"], "title": "SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents", "comment": null, "summary": "Self-evolution, the ability of agents to autonomously improve their reasoning\nand behavior, is essential for the embodied domain with long-horizon,\nreal-world tasks. Despite current advancements in reinforcement fine-tuning\n(RFT) showing strong performance in enhancing reasoning in LLMs, its potential\nto enable self-evolving embodied intelligence with multi-modal interactions\nremains largely unexplored. Specifically, reinforcement fine-tuning faces two\nfundamental obstacles in embodied settings: (i) the lack of accessible\nintermediate rewards in multi-step reasoning tasks limits effective learning\nsignals, and (ii) reliance on hand-crafted reward functions restricts\ngeneralization to novel tasks and environments. To address these challenges, we\npresent Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework\ndesigned for enabling the self-evolving capabilities of embodied agents.\nSpecifically, to convert sparse delayed rewards into denser intermediate\nsignals that improve multi-step reasoning, we propose Tree-based group relative\npolicy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into\nGRPO. To generalize reward estimation across tasks and scenes, supporting\nautonomous adaptation and reward-driven self-evolution, we further introduce\nMulti-modal Generative Reward Model (MGRM). To holistically evaluate the\neffectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing\nstate-of-the-art methods with scores of 85.07% (textual) and 36.19%\n(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also\nachieves scores of 80.3% without environmental reward, surpassing all\nopen-source baselines and highlighting its scalability as a self-evolving\nembodied agent. Additional experiments and qualitative analysis further support\nthe potential of SEEA-R1 for future research in scalable embodied intelligence.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86SEEA-R1\u6846\u67b6\uff0c\u901a\u8fc7Tree-GRPO\u548cMGRM\u89e3\u51b3\u5f3a\u5316\u5fae\u8c03\u5728\u5177\u8eab\u667a\u80fd\u4e2d\u7684\u7a00\u758f\u5956\u52b1\u548c\u6cdb\u5316\u95ee\u9898\uff0c\u5e76\u5728ALFWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u5177\u8eab\u667a\u80fd\u4e2d\u5f3a\u5316\u5fae\u8c03\u9762\u4e34\u7684\u7a00\u758f\u5956\u52b1\u548c\u6cdb\u5316\u9650\u5236\uff0c\u4ee5\u5b9e\u73b0\u81ea\u4e3b\u8fdb\u5316\u7684\u591a\u6a21\u6001\u4ea4\u4e92\u667a\u80fd\u4f53\u3002", "method": "\u63d0\u51faTree-GRPO\uff08\u57fa\u4e8e\u6811\u7684\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff09\u548cMGRM\uff08\u591a\u6a21\u6001\u751f\u6210\u5956\u52b1\u6a21\u578b\uff09\uff0c\u5206\u522b\u89e3\u51b3\u591a\u6b65\u63a8\u7406\u4e2d\u7684\u5956\u52b1\u7a00\u758f\u6027\u548c\u4efb\u52a1\u6cdb\u5316\u95ee\u9898\u3002", "result": "\u5728ALFWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSEEA-R1\u5728\u6587\u672c\u548c\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u5206\u522b\u8fbe\u523085.07%\u548c36.19%\u7684\u5f97\u5206\uff0c\u8d85\u8d8a\u5305\u62ecGPT-4o\u5728\u5185\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SEEA-R1\u5c55\u793a\u4e86\u4f5c\u4e3a\u81ea\u4e3b\u8fdb\u5316\u5177\u8eab\u667a\u80fd\u4f53\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u53ef\u6269\u5c55\u7684\u5177\u8eab\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.22180", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.22180", "abs": "https://arxiv.org/abs/2506.22180", "authors": ["\u00d6nder G\u00fcrcan"], "title": "Reliability Analysis of Smart Contract Execution Architectures: A Comparative Simulation Study", "comment": "23 pages, 5 figures, 2 tables", "summary": "The industrial market continuously needs reliable solutions to secure\nautonomous systems. Especially as these systems become more complex and\ninterconnected, reliable security solutions are becoming increasingly\nimportant. One promising solution to tackle this challenge is using smart\ncontracts designed to meet contractual conditions, avoid malicious errors,\nsecure exchanges, and minimize the need for reliable intermediaries. However,\nsmart contracts are immutable. Moreover, there are different smart contract\nexecution architectures (namely Order-Execute and Execute-Order-Validate) that\nhave different throughputs. In this study, we developed an evaluation model for\nassessing the security of reliable smart contract execution. We then developed\na realistic smart contract enabled IoT energy case study. Finally, we simulate\nthe developed case study to evaluate several smart contract security\nvulnerabilities reported in the literature. Our results show that the\nExecute-Order-Validate architecture is more promising regarding reliability and\nsecurity.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u667a\u80fd\u5408\u7ea6\u6267\u884c\u67b6\u6784\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u53d1\u73b0Execute-Order-Validate\u67b6\u6784\u5728\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u66f4\u5177\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b\u7cfb\u7edf\u590d\u6742\u6027\u548c\u4e92\u8054\u6027\u589e\u52a0\uff0c\u53ef\u9760\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u9700\u6c42\u8feb\u5207\uff0c\u667a\u80fd\u5408\u7ea6\u662f\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5176\u4e0d\u53ef\u53d8\u6027\u548c\u4e0d\u540c\u6267\u884c\u67b6\u6784\u7684\u6027\u80fd\u5dee\u5f02\u9700\u8981\u8bc4\u4f30\u3002", "method": "\u5f00\u53d1\u4e86\u8bc4\u4f30\u667a\u80fd\u5408\u7ea6\u6267\u884c\u5b89\u5168\u6027\u7684\u6a21\u578b\uff0c\u5e76\u57fa\u4e8eIoT\u80fd\u6e90\u6848\u4f8b\u8fdb\u884c\u6a21\u62df\uff0c\u6d4b\u8bd5\u6587\u732e\u4e2d\u62a5\u544a\u7684\u667a\u80fd\u5408\u7ea6\u5b89\u5168\u6f0f\u6d1e\u3002", "result": "Execute-Order-Validate\u67b6\u6784\u5728\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u667a\u80fd\u5408\u7ea6\u7684Execute-Order-Validate\u67b6\u6784\u66f4\u9002\u5408\u9ad8\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u9700\u6c42\u7684\u573a\u666f\u3002"}}
{"id": "2506.21654", "categories": ["cs.SE", "cs.MS"], "pdf": "https://arxiv.org/pdf/2506.21654", "abs": "https://arxiv.org/abs/2506.21654", "authors": ["Wolfgang Bangerth"], "title": "Experience converting a large mathematical software package written in C++ to C++20 modules", "comment": null, "summary": "Mathematical software has traditionally been built in the form of \"packages\"\nthat build on each other. A substantial fraction of these packages is written\nin C++ and, as a consequence, the interface of a package is described in the\nform of header files that downstream packages and applications can then\n#include. C++ has inherited this approach towards exporting interfaces from C,\nbut the approach is clunky, unreliable, and slow. As a consequence, C++20 has\nintroduced a \"module\" system in which packages explicitly export declarations\nand code that compilers then store in machine-readable form and that downstream\nusers can \"import\" -- a system in line with what many other programming\nlanguages have used for decades.\n  Herein, I explore how one can convert large mathematical software packages\nwritten in C++ to this system, using the deal.II finite element library with\nits around 800,000 lines of code as an example. I describe an approach that\nallows providing both header-based and module-based interfaces from the same\ncode base, discuss the challenges one encounters, and how modules actually work\nin practice in a variety of technical and human metrics. The results show that\nwith a non-trivial, but also not prohibitive effort, the conversion to modules\nis possible, resulting in a reduction in compile time for the converted library\nitself; on the other hand, for downstream projects, compile times show no clear\ntrend. I end with thoughts about long-term strategies for converting the entire\necosystem of mathematical software over the coming years or decades.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5c06\u5927\u578b\u6570\u5b66\u8f6f\u4ef6\u5305\u4ece\u4f20\u7edf\u7684C++\u5934\u6587\u4ef6\u63a5\u53e3\u8f6c\u6362\u4e3aC++20\u6a21\u5757\u7cfb\u7edf\uff0c\u4ee5deal.II\u6709\u9650\u5143\u5e93\u4e3a\u4f8b\uff0c\u5c55\u793a\u4e86\u8f6c\u6362\u7684\u53ef\u884c\u6027\u548c\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u7684C++\u5934\u6587\u4ef6\u63a5\u53e3\u65b9\u5f0f\u7b28\u62d9\u3001\u4e0d\u53ef\u9760\u4e14\u6548\u7387\u4f4e\uff0cC++20\u5f15\u5165\u7684\u6a21\u5757\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u901a\u8fc7deal.II\u5e93\uff08\u7ea680\u4e07\u884c\u4ee3\u7801\uff09\u7684\u5b9e\u4f8b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540c\u65f6\u652f\u6301\u5934\u6587\u4ef6\u548c\u6a21\u5757\u63a5\u53e3\u7684\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u8f6c\u6362\u4e2d\u7684\u6311\u6218\u548c\u5b9e\u9645\u6548\u679c\u3002", "result": "\u8f6c\u6362\u540e\u5e93\u672c\u8eab\u7684\u7f16\u8bd1\u65f6\u95f4\u51cf\u5c11\uff0c\u4f46\u4e0b\u6e38\u9879\u76ee\u7684\u7f16\u8bd1\u65f6\u95f4\u65e0\u660e\u663e\u53d8\u5316\u3002\u8f6c\u6362\u5de5\u4f5c\u867d\u975e\u5fae\u4e0d\u8db3\u9053\uff0c\u4f46\u53ef\u884c\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u5c06\u6574\u4e2a\u6570\u5b66\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u9010\u6b65\u8f6c\u6362\u4e3a\u6a21\u5757\u7cfb\u7edf\u7684\u957f\u671f\u7b56\u7565\u3002"}}
{"id": "2506.21734", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21734", "abs": "https://arxiv.org/abs/2506.21734", "authors": ["Guan Wang", "Jin Li", "Yuhao Sun", "Xing Chen", "Changling Liu", "Yue Wu", "Meng Lu", "Sen Song", "Yasin Abbasi Yadkori"], "title": "Hierarchical Reasoning Model", "comment": null, "summary": "Reasoning, the process of devising and executing complex goal-oriented action\nsequences, remains a critical challenge in AI. Current large language models\n(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from\nbrittle task decomposition, extensive data requirements, and high latency.\nInspired by the hierarchical and multi-timescale processing in the human brain,\nwe propose the Hierarchical Reasoning Model (HRM), a novel recurrent\narchitecture that attains significant computational depth while maintaining\nboth training stability and efficiency. HRM executes sequential reasoning tasks\nin a single forward pass without explicit supervision of the intermediate\nprocess, through two interdependent recurrent modules: a high-level module\nresponsible for slow, abstract planning, and a low-level module handling rapid,\ndetailed computations. With only 27 million parameters, HRM achieves\nexceptional performance on complex reasoning tasks using only 1000 training\nsamples. The model operates without pre-training or CoT data, yet achieves\nnearly perfect performance on challenging tasks including complex Sudoku\npuzzles and optimal path finding in large mazes. Furthermore, HRM outperforms\nmuch larger models with significantly longer context windows on the Abstraction\nand Reasoning Corpus (ARC), a key benchmark for measuring artificial general\nintelligence capabilities. These results underscore HRM's potential as a\ntransformative advancement toward universal computation and general-purpose\nreasoning systems.", "AI": {"tldr": "HRM\u662f\u4e00\u79cd\u65b0\u578b\u9012\u5f52\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u5c42\u548c\u591a\u65f6\u95f4\u5c3a\u5ea6\u5904\u7406\u89e3\u51b3AI\u63a8\u7406\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u8d8a\u4e14\u9ad8\u6548\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u65b9\u6cd5\uff08\u5982Chain-of-Thought\uff09\u5b58\u5728\u4efb\u52a1\u5206\u89e3\u8106\u5f31\u3001\u6570\u636e\u9700\u6c42\u5927\u548c\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u53d7\u4eba\u7c7b\u5927\u8111\u542f\u53d1\uff0c\u63d0\u51faHRM\u4ee5\u6539\u8fdb\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "HRM\u91c7\u7528\u4e24\u4e2a\u76f8\u4e92\u4f9d\u8d56\u7684\u9012\u5f52\u6a21\u5757\uff1a\u9ad8\u5c42\u6a21\u5757\u8d1f\u8d23\u6162\u901f\u62bd\u8c61\u89c4\u5212\uff0c\u4f4e\u5c42\u6a21\u5757\u5904\u7406\u5feb\u901f\u8be6\u7ec6\u8ba1\u7b97\uff0c\u65e0\u9700\u4e2d\u95f4\u8fc7\u7a0b\u663e\u5f0f\u76d1\u7763\u3002", "result": "HRM\u4ec5\u97002700\u4e07\u53c2\u6570\u548c1000\u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff08\u5982\u6570\u72ec\u548c\u8ff7\u5bab\u8def\u5f84\u89c4\u5212\uff09\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5728ARC\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u66f4\u5927\u6a21\u578b\u3002", "conclusion": "HRM\u5c55\u793a\u4e86\u5728\u901a\u7528\u8ba1\u7b97\u548c\u901a\u7528\u63a8\u7406\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\uff0c\u662f\u8fc8\u5411\u4eba\u5de5\u901a\u7528\u667a\u80fd\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2506.22323", "categories": ["cs.CR", "cs.CY", "cs.NI", "cs.OS", "cs.PL"], "pdf": "https://arxiv.org/pdf/2506.22323", "abs": "https://arxiv.org/abs/2506.22323", "authors": ["Alessio Di Santo"], "title": "Under the Hood of BlotchyQuasar: DLL-Based RAT Campaigns Against Latin America", "comment": null, "summary": "A sophisticated malspam campaign was recently uncovered targeting Latin\nAmerican countries, with a particular focus on Brazil. This operation utilizes\na highly deceptive phishing email to trick users into executing a malicious MSI\nfile, initiating a multi-stage infection. The core of the attack leverages DLL\nside-loading, where a legitimate executable from Valve Corporation is used to\nload a trojanized DLL, thereby bypassing standard security defenses.\n  Once active, the malware, a variant of QuasarRAT known as BlotchyQuasar, is\ncapable of a wide range of malicious activities. It is designed to steal\nsensitive browser-stored credentials and banking information, the latter\nthrough fake login windows mimicking well-known Brazilian banks. The threat\nestablishes persistence by modifying the Windows registry , captures user\nkeystrokes through keylogging , and exfiltrates stolen data to a\nCommand-and-Control (C2) server using encrypted payloads. Despite its advanced\ncapabilities, the malware code exhibits signs of rushed development, with\ninefficiencies and poor error handling that suggest the threat actors\nprioritized rapid deployment over meticulous design. Nonetheless, the campaign\nextensive reach and sophisticated mechanisms pose a serious and immediate\nthreat to the targeted regions, underscoring the need for robust cybersecurity\ndefenses.", "AI": {"tldr": "\u4e00\u7bc7\u5173\u4e8e\u9488\u5bf9\u62c9\u4e01\u7f8e\u6d32\uff08\u5c24\u5176\u662f\u5df4\u897f\uff09\u7684\u9ad8\u7ea7\u6076\u610f\u90ae\u4ef6\u653b\u51fb\u7684\u7814\u7a76\uff0c\u653b\u51fb\u8005\u5229\u7528\u9493\u9c7c\u90ae\u4ef6\u548cDLL\u4fa7\u52a0\u8f7d\u6280\u672f\u4f20\u64adBlotchyQuasar\u6076\u610f\u8f6f\u4ef6\uff0c\u7a83\u53d6\u654f\u611f\u4fe1\u606f\u5e76\u5efa\u7acb\u6301\u4e45\u6027\u3002", "motivation": "\u63ed\u793a\u8fd1\u671f\u9488\u5bf9\u62c9\u4e01\u7f8e\u6d32\u7684\u6076\u610f\u90ae\u4ef6\u653b\u51fb\u6d3b\u52a8\uff0c\u5206\u6790\u5176\u6280\u672f\u7279\u70b9\u548c\u5a01\u80c1\u7a0b\u5ea6\u3002", "method": "\u653b\u51fb\u8005\u4f7f\u7528\u9493\u9c7c\u90ae\u4ef6\u8bf1\u9a97\u7528\u6237\u6267\u884c\u6076\u610fMSI\u6587\u4ef6\uff0c\u901a\u8fc7DLL\u4fa7\u52a0\u8f7d\u6280\u672f\u7ed5\u8fc7\u5b89\u5168\u9632\u5fa1\uff0c\u4f20\u64adBlotchyQuasar\u6076\u610f\u8f6f\u4ef6\u3002", "result": "\u6076\u610f\u8f6f\u4ef6\u80fd\u591f\u7a83\u53d6\u6d4f\u89c8\u5668\u51ed\u8bc1\u548c\u94f6\u884c\u4fe1\u606f\uff0c\u901a\u8fc7\u952e\u76d8\u8bb0\u5f55\u548c\u6570\u636e\u52a0\u5bc6\u5916\u4f20\uff0c\u4f46\u4ee3\u7801\u5b58\u5728\u7f3a\u9677\u3002", "conclusion": "\u8be5\u653b\u51fb\u6d3b\u52a8\u6280\u672f\u5148\u8fdb\u4e14\u5a01\u80c1\u4e25\u91cd\uff0c\u51f8\u663e\u4e86\u52a0\u5f3a\u7f51\u7edc\u9632\u5fa1\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2506.21693", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.21693", "abs": "https://arxiv.org/abs/2506.21693", "authors": ["Ali Nouri", "Beatriz Cabrero-Daniel", "Fredrik T\u00f6rner", "Christian Berger"], "title": "The DevSafeOps Dilemma: A Systematic Literature Review on Rapidity in Safe Autonomous Driving Development and Operation", "comment": "Accepted for publication in the Journal of Systems and Software (JSS)", "summary": "Developing autonomous driving (AD) systems is challenging due to the\ncomplexity of the systems and the need to assure their safe and reliable\noperation. The widely adopted approach of DevOps seems promising to support the\ncontinuous technological progress in AI and the demand for fast reaction to\nincidents, which necessitate continuous development, deployment, and\nmonitoring. We present a systematic literature review meant to identify,\nanalyse, and synthesise a broad range of existing literature related to usage\nof DevOps in autonomous driving development. Our results provide a structured\noverview of challenges and solutions, arising from applying DevOps to\nsafety-related AI-enabled functions. Our results indicate that there are still\nseveral open topics to be addressed to enable safe DevOps for the development\nof safe AD.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u63a2\u8ba8\u4e86DevOps\u5728\u81ea\u52a8\u9a7e\u9a76\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\uff0c\u603b\u7ed3\u4e86\u6311\u6218\u4e0e\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u6307\u51fa\u4ecd\u9700\u89e3\u51b3\u7684\u5b89\u5168\u6027\u95ee\u9898\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5f00\u53d1\u590d\u6742\u4e14\u9700\u786e\u4fdd\u5b89\u5168\u53ef\u9760\uff0cDevOps\u65b9\u6cd5\u56e0\u5176\u652f\u6301\u5feb\u901f\u8fed\u4ee3\u548c\u6301\u7eed\u76d1\u63a7\u800c\u663e\u5f97\u6709\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u8bc6\u522b\u3001\u5206\u6790\u5e76\u7efc\u5408\u4e86\u4e0eDevOps\u5728\u81ea\u52a8\u9a7e\u9a76\u5f00\u53d1\u4e2d\u5e94\u7528\u76f8\u5173\u7684\u5e7f\u6cdb\u6587\u732e\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63d0\u4f9b\u4e86DevOps\u5e94\u7528\u4e8e\u5b89\u5168\u76f8\u5173AI\u529f\u80fd\u65f6\u7684\u6311\u6218\u4e0e\u89e3\u51b3\u65b9\u6848\u7684\u7ed3\u6784\u5316\u6982\u8ff0\u3002", "conclusion": "\u5c3d\u7ba1DevOps\u5728\u81ea\u52a8\u9a7e\u9a76\u5f00\u53d1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u591a\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u4ee5\u5b9e\u73b0\u5b89\u5168\u5f00\u53d1\u3002"}}
{"id": "2506.21763", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21763", "abs": "https://arxiv.org/abs/2506.21763", "authors": ["Xin Wang", "Jiyao Liu", "Yulong Xiao", "Junzhi Ning", "Lihao Liu", "Junjun He", "Botian Shi", "Kaicheng Yu"], "title": "THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?", "comment": null, "summary": "Large Language Models (LLMs) are accelerating scientific idea generation, but\nrigorously evaluating these numerous, often superficial, AI-generated\npropositions for novelty and factual accuracy is a critical bottleneck; manual\nverification is too slow.Existing validation methods are inadequate: LLMs as\nstandalone verifiers may hallucinate and lack domain knowledge (our findings\nshow ~60\\% unawareness of relevant papers in specific domains), while\ntraditional citation networks lack explicit causality and narrative surveys are\nunstructured.This underscores a core challenge: the absence of structured,\nverifiable, and causally-linked historical data of scientific evolution.To\naddress this,we introduce \\textbf{THE-Tree} (\\textbf{T}echnology\n\\textbf{H}istory \\textbf{E}volution Tree), a computational framework that\nconstructs such domain-specific evolution trees from scientific\nliterature.THE-Tree employs a search algorithm to explore evolutionary paths.\nDuring its node expansion, it utilizes a novel \"Think-Verbalize-Cite-Verify\"\nprocess: an LLM proposes potential advancements and cites supporting\nliterature. Critically, each proposed evolutionary link is then validated for\nlogical coherence and evidential support by a recovered natural language\ninference mechanism that interrogates the cited literature, ensuring that each\nstep is grounded.We construct and validate 88 THE-Trees across diverse domains\nand release a benchmark dataset including up to 71k fact verifications covering\n27k papers to foster further research.Experiments demonstrate that i) in graph\ncompletion, our THE-Tree improves hit@1 by 8\\% to 14\\% across multiple models\ncompared to traditional citation networks; ii) for predicting future scientific\ndevelopments, it improves hit@1 metric by nearly 10\\%; and iii) when combined\nwith other methods, it boosts the performance of evaluating important\nscientific papers by almost 100\\%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86THE-Tree\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u79d1\u5b66\u6587\u732e\u4e2d\u6784\u5efa\u9886\u57df\u7279\u5b9a\u7684\u6280\u672f\u6f14\u5316\u6811\uff0c\u901a\u8fc7\u9a8c\u8bc1\u903b\u8f91\u548c\u8bc1\u636e\u652f\u6301\u6765\u63d0\u5347\u79d1\u5b66\u53d1\u5c55\u7684\u9884\u6d4b\u548c\u8bc4\u4f30\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u9a8c\u8bc1\u65b9\u6cd5\uff08\u5982LLMs\u6216\u4f20\u7edf\u5f15\u7528\u7f51\u7edc\uff09\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30AI\u751f\u6210\u7684\u79d1\u5b66\u547d\u9898\u7684\u65b0\u9896\u6027\u548c\u51c6\u786e\u6027\uff0c\u7f3a\u4e4f\u7ed3\u6784\u5316\u3001\u53ef\u9a8c\u8bc1\u4e14\u56e0\u679c\u5173\u8054\u7684\u79d1\u5b66\u6f14\u5316\u6570\u636e\u3002", "method": "THE-Tree\u6846\u67b6\u901a\u8fc7\u641c\u7d22\u7b97\u6cd5\u6784\u5efa\u6f14\u5316\u6811\uff0c\u91c7\u7528\u201cThink-Verbalize-Cite-Verify\u201d\u6d41\u7a0b\uff0c\u7531LLM\u63d0\u51fa\u6f5c\u5728\u8fdb\u5c55\u5e76\u9a8c\u8bc1\u903b\u8f91\u548c\u8bc1\u636e\u652f\u6301\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTHE-Tree\u5728\u56fe\u5f62\u8865\u5168\u3001\u9884\u6d4b\u672a\u6765\u79d1\u5b66\u53d1\u5c55\u548c\u8bc4\u4f30\u91cd\u8981\u8bba\u6587\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "THE-Tree\u4e3a\u89e3\u51b3\u79d1\u5b66\u6f14\u5316\u6570\u636e\u7684\u7ed3\u6784\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79d1\u5b66\u53d1\u5c55\u7684\u9884\u6d4b\u548c\u8bc4\u4f30\u80fd\u529b\u3002"}}
{"id": "2506.21703", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.21703", "abs": "https://arxiv.org/abs/2506.21703", "authors": ["Victoria Jackson", "Susannah Liu", "Andre van der Hoek"], "title": "Using Generative AI in Software Design Education: An Experience Report", "comment": "12 pages, 1 figure", "summary": "With the rapid adoption of Generative AI (GenAI) tools, software engineering\neducators have grappled with how best to incorporate them into the classroom.\nWhile some research discusses the use of GenAI in the context of learning to\ncode, there is little research that explores the use of GenAI in the classroom\nfor other areas of software development. This paper provides an experience\nreport on introducing GenAI into an undergraduate software design class.\nStudents were required to use GenAI (in the form of ChatGPT) to help complete a\nteam-based assignment. The data collected consisted of the ChatGPT conversation\nlogs and students' reflections on using ChatGPT for the assignment.\nSubsequently, qualitative analysis was undertaken on the data. Students\nidentified numerous ways ChatGPT helped them in their design process while\nrecognizing the need to critique the response before incorporating it into\ntheir design. At the same time, we identified several key lessons for educators\nin how to deploy GenAI in a software design class effectively. Based on our\nexperience, we believe students can benefit from using GenAI in software design\neducation as it helps them design and learn about the strengths and weaknesses\nof GenAI.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u672c\u79d1\u8f6f\u4ef6\u8bbe\u8ba1\u8bfe\u7a0b\u4e2d\u5f15\u5165\u751f\u6210\u5f0fAI\uff08\u5982ChatGPT\uff09\u7684\u7ecf\u9a8c\uff0c\u5206\u6790\u4e86\u5b66\u751f\u4f7f\u7528AI\u5b8c\u6210\u56e2\u961f\u4f5c\u4e1a\u7684\u6548\u679c\uff0c\u5e76\u603b\u7ed3\u4e86\u6559\u80b2\u8005\u7684\u5173\u952e\u6559\u8bad\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5de5\u5177\u7684\u5feb\u901f\u666e\u53ca\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u8005\u9700\u8981\u63a2\u7d22\u5982\u4f55\u5c06\u5176\u6709\u6548\u878d\u5165\u8bfe\u5802\uff0c\u5c24\u5176\u662f\u5728\u8f6f\u4ef6\u8bbe\u8ba1\u7b49\u975e\u7f16\u7a0b\u9886\u57df\u3002", "method": "\u5b66\u751f\u5728\u56e2\u961f\u4f5c\u4e1a\u4e2d\u4f7f\u7528ChatGPT\uff0c\u6536\u96c6\u5bf9\u8bdd\u65e5\u5fd7\u548c\u53cd\u601d\uff0c\u5e76\u8fdb\u884c\u5b9a\u6027\u5206\u6790\u3002", "result": "\u5b66\u751f\u53d1\u73b0ChatGPT\u5728\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u4e86\u5e2e\u52a9\uff0c\u4f46\u4e5f\u610f\u8bc6\u5230\u9700\u8981\u6279\u5224\u6027\u8bc4\u4f30\u5176\u56de\u7b54\u3002\u6559\u80b2\u8005\u4ece\u4e2d\u603b\u7ed3\u4e86\u6709\u6548\u90e8\u7f72AI\u7684\u5173\u952e\u6559\u8bad\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u8bbe\u8ba1\u6559\u80b2\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u5e2e\u52a9\u5b66\u751f\u8bbe\u8ba1\u5e76\u4e86\u89e3AI\u7684\u4f18\u7f3a\u70b9\u3002"}}
{"id": "2506.21784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21784", "abs": "https://arxiv.org/abs/2506.21784", "authors": ["Yifan Liu", "Xishun Liao", "Haoxuan Ma", "Jonathan Liu", "Rohan Jadhav", "Jiaqi Ma"], "title": "MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models", "comment": null, "summary": "Understanding and modeling human mobility patterns is crucial for effective\ntransportation planning and urban development. Despite significant advances in\nmobility research, there remains a critical gap in simulation platforms that\nallow for algorithm development, policy implementation, and comprehensive\nevaluation at scale. Traditional activity-based models require extensive data\ncollection and manual calibration, machine learning approaches struggle with\nadaptation to dynamic conditions, and treding agent-based Large Language Models\n(LLMs) implementations face computational constraints with large-scale\nsimulations. To address these challenges, we propose MobiVerse, a hybrid\nframework leverages the efficiency of lightweight domain-specific generator for\ngenerating base activity chains with the adaptability of LLMs for context-aware\nmodifications. A case study was conducted in Westwood, Los Angeles, where we\nefficiently generated and dynamically adjusted schedules for the whole\npopulation of approximately 53,000 agents on a standard PC. Our experiments\ndemonstrate that MobiVerse successfully enables agents to respond to\nenvironmental feedback, including road closures, large gathering events like\nfootball games, and congestion, through our hybrid framework. Its modular\ndesign facilitates testing various mobility algorithms at both transportation\nsystem and agent levels. Results show our approach maintains computational\nefficiency while enhancing behavioral realism. MobiVerse bridges the gap in\nmobility simulation by providing a customizable platform for mobility systems\nplanning and operations with benchmark algorithms. Code and videos are\navailable at https://github.com/ucla-mobility/MobiVerse.", "AI": {"tldr": "MobiVerse\u662f\u4e00\u4e2a\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u9886\u57df\u7279\u5b9a\u751f\u6210\u5668\u548cLLMs\uff0c\u7528\u4e8e\u9ad8\u6548\u751f\u6210\u548c\u52a8\u6001\u8c03\u6574\u5927\u89c4\u6a21\u4eba\u53e3\u7684\u6d3b\u52a8\u94fe\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u6d3b\u52a8\u6a21\u578b\u6570\u636e\u9700\u6c42\u9ad8\u3001\u673a\u5668\u5b66\u4e60\u9002\u5e94\u6027\u5dee\u4ee5\u53caLLMs\u8ba1\u7b97\u9650\u5236\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u751f\u6210\u5668\u548cLLMs\uff0c\u652f\u6301\u52a8\u6001\u8c03\u6574\u548c\u54cd\u5e94\u73af\u5883\u53d8\u5316\u3002", "result": "\u5728\u6d1b\u6749\u77f6Westwood\u7684\u6848\u4f8b\u4e2d\uff0c\u6210\u529f\u6a21\u62df\u4e8653,000\u540d\u4ee3\u7406\u7684\u52a8\u6001\u884c\u4e3a\uff0c\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u5e76\u63d0\u5347\u884c\u4e3a\u771f\u5b9e\u6027\u3002", "conclusion": "MobiVerse\u586b\u8865\u4e86\u79fb\u52a8\u6a21\u62df\u7684\u7a7a\u767d\uff0c\u4e3a\u4ea4\u901a\u7cfb\u7edf\u89c4\u5212\u548c\u7b97\u6cd5\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u53ef\u5b9a\u5236\u5e73\u53f0\u3002"}}
{"id": "2506.22037", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.22037", "abs": "https://arxiv.org/abs/2506.22037", "authors": ["Jiawei Li", "Zan Liang", "Guoxin Wang", "Jinzhi Lu", "Yan Yan", "Shouxuan Wu", "Hao Wang"], "title": "KARMA Approach supporting Development Process Reconstruction in Model-based Systems Engineering", "comment": "12 pages, 9 figures, submitted to the 15th international Complex\n  Systems Design & Management (CSD&M) conference", "summary": "Model reconstruction is a method used to drive the development of complex\nsystem development processes in model-based systems engineering. Currently,\nduring the iterative design process of a system, there is a lack of an\neffective method to manage changes in development requirements, such as\ndevelopment cycle requirements and cost requirements, and to realize the\nreconstruction of the system development process model. To address these\nissues, this paper proposes a model reconstruction method to support the\ndevelopment process model. Firstly, the KARMA language, based on the GOPPRR-E\nmetamodeling method, is utilized to uniformly formalize the process models\nconstructed based on different modeling languages. Secondly, a model\nreconstruction framework is introduced. This framework takes a structured\ndevelopment requirements based natural language as input, employs natural\nlanguage processing techniques to analyze the development requirements text,\nand extracts structural and optimization constraint information. Then, after\nstructural reorganization and algorithm optimization, a development process\nmodel that meets the development requirements is obtained. Finally, as a case\nstudy, the development process of the aircraft onboard maintenance system is\nreconstructed. The results demonstrate that this method can significantly\nenhance the design efficiency of the development process.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKARMA\u8bed\u8a00\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u6a21\u578b\u91cd\u6784\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u7cfb\u7edf\u5f00\u53d1\u6d41\u7a0b\u6a21\u578b\uff0c\u5e76\u4ee5\u98de\u673a\u673a\u8f7d\u7ef4\u62a4\u7cfb\u7edf\u4e3a\u4f8b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u7cfb\u7edf\u8fed\u4ee3\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u7f3a\u4e4f\u6709\u6548\u7ba1\u7406\u5f00\u53d1\u9700\u6c42\u53d8\u5316\u7684\u65b9\u6cd5\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5f00\u53d1\u6d41\u7a0b\u6a21\u578b\u7684\u91cd\u6784\u3002", "method": "\u5229\u7528KARMA\u8bed\u8a00\u7edf\u4e00\u5f62\u5f0f\u5316\u4e0d\u540c\u5efa\u6a21\u8bed\u8a00\u6784\u5efa\u7684\u6d41\u7a0b\u6a21\u578b\uff0c\u5f15\u5165\u6a21\u578b\u91cd\u6784\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5206\u6790\u9700\u6c42\u6587\u672c\uff0c\u63d0\u53d6\u7ed3\u6784\u5316\u548c\u4f18\u5316\u7ea6\u675f\u4fe1\u606f\uff0c\u6700\u7ec8\u751f\u6210\u6ee1\u8db3\u9700\u6c42\u7684\u5f00\u53d1\u6d41\u7a0b\u6a21\u578b\u3002", "result": "\u4ee5\u98de\u673a\u673a\u8f7d\u7ef4\u62a4\u7cfb\u7edf\u4e3a\u4f8b\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u5f00\u53d1\u6d41\u7a0b\u8bbe\u8ba1\u6548\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5f00\u53d1\u9700\u6c42\u53d8\u5316\u7ba1\u7406\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u5f00\u53d1\u6d41\u7a0b\u7684\u6548\u7387\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2506.21805", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.21805", "abs": "https://arxiv.org/abs/2506.21805", "authors": ["Nicolas Bougie", "Narimasa Watanabe"], "title": "CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation", "comment": null, "summary": "Modeling human behavior in urban environments is fundamental for social\nscience, behavioral studies, and urban planning. Prior work often rely on\nrigid, hand-crafted rules, limiting their ability to simulate nuanced\nintentions, plans, and adaptive behaviors. Addressing these challenges, we\nenvision an urban simulator (CitySim), capitalizing on breakthroughs in\nhuman-level intelligence exhibited by large language models. In CitySim, agents\ngenerate realistic daily schedules using a recursive value-driven approach that\nbalances mandatory activities, personal habits, and situational factors. To\nenable long-term, lifelike simulations, we endow agents with beliefs, long-term\ngoals, and spatial memory for navigation. CitySim exhibits closer alignment\nwith real humans than prior work, both at micro and macro levels. Additionally,\nwe conduct insightful experiments by modeling tens of thousands of agents and\nevaluating their collective behaviors under various real-world scenarios,\nincluding estimating crowd density, predicting place popularity, and assessing\nwell-being. Our results highlight CitySim as a scalable, flexible testbed for\nunderstanding and forecasting urban phenomena.", "AI": {"tldr": "CitySim\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\uff0c\u901a\u8fc7\u9012\u5f52\u4ef7\u503c\u9a71\u52a8\u65b9\u6cd5\u751f\u6210\u771f\u5b9e\u65e5\u7a0b\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u89c4\u5219\uff0c\u96be\u4ee5\u6a21\u62df\u590d\u6742\u884c\u4e3a\u548c\u610f\u56fe\uff0cCitySim\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u9012\u5f52\u4ef7\u503c\u9a71\u52a8\u65b9\u6cd5\uff0c\u7ed3\u5408\u4fe1\u5ff5\u3001\u957f\u671f\u76ee\u6807\u548c\u7a7a\u95f4\u8bb0\u5fc6\uff0c\u6a21\u62df\u771f\u5b9e\u4eba\u7c7b\u884c\u4e3a\u3002", "result": "CitySim\u5728\u5fae\u89c2\u548c\u5b8f\u89c2\u5c42\u9762\u66f4\u63a5\u8fd1\u771f\u5b9e\u4eba\u7c7b\u884c\u4e3a\uff0c\u5e76\u80fd\u6a21\u62df\u5927\u89c4\u6a21\u96c6\u4f53\u884c\u4e3a\u3002", "conclusion": "CitySim\u662f\u7406\u89e3\u548c\u9884\u6d4b\u57ce\u5e02\u73b0\u8c61\u7684\u53ef\u6269\u5c55\u3001\u7075\u6d3b\u5e73\u53f0\u3002"}}
{"id": "2506.22185", "categories": ["cs.SE", "cs.AI", "cs.DC", "cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.22185", "abs": "https://arxiv.org/abs/2506.22185", "authors": ["Matteo Esposito", "Alexander Bakhtin", "Noman Ahmad", "Mikel Robredo", "Ruoyu Su", "Valentina Lenarduzzi", "Davide Taibi"], "title": "Autonomic Microservice Management via Agentic AI and MAPE-K Integration", "comment": null, "summary": "While microservices are revolutionizing cloud computing by offering\nunparalleled scalability and independent deployment, their decentralized nature\nposes significant security and management challenges that can threaten system\nstability. We propose a framework based on MAPE-K, which leverages agentic AI,\nfor autonomous anomaly detection and remediation to address the daunting task\nof highly distributed system management. Our framework offers practical,\nindustry-ready solutions for maintaining robust and secure microservices.\nPractitioners and researchers can customize the framework to enhance system\nstability, reduce downtime, and monitor broader system quality attributes such\nas system performance level, resilience, security, and anomaly management,\namong others.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eMAPE-K\u548c\u667a\u80fd\u4ee3\u7406AI\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5fae\u670d\u52a1\u7684\u81ea\u4e3b\u5f02\u5e38\u68c0\u6d4b\u4e0e\u4fee\u590d\uff0c\u63d0\u5347\u7cfb\u7edf\u7a33\u5b9a\u6027\u4e0e\u5b89\u5168\u6027\u3002", "motivation": "\u5fae\u670d\u52a1\u7684\u53bb\u4e2d\u5fc3\u5316\u7279\u6027\u5e26\u6765\u5b89\u5168\u548c\u7ba1\u7406\u7684\u6311\u6218\uff0c\u5a01\u80c1\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "method": "\u57fa\u4e8eMAPE-K\u6846\u67b6\uff0c\u5229\u7528\u667a\u80fd\u4ee3\u7406AI\u5b9e\u73b0\u81ea\u4e3b\u5f02\u5e38\u68c0\u6d4b\u4e0e\u4fee\u590d\u3002", "result": "\u63d0\u4f9b\u884c\u4e1a\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u589e\u5f3a\u7cfb\u7edf\u7a33\u5b9a\u6027\u3001\u51cf\u5c11\u505c\u673a\u65f6\u95f4\uff0c\u5e76\u76d1\u63a7\u6027\u80fd\u3001\u5f39\u6027\u7b49\u8d28\u91cf\u5c5e\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u5b9a\u5236\u5316\uff0c\u9002\u7528\u4e8e\u7814\u7a76\u548c\u5b9e\u8df5\uff0c\u52a9\u529b\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u7a33\u5b9a\u4e0e\u5b89\u5168\u3002"}}
{"id": "2506.21887", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21887", "abs": "https://arxiv.org/abs/2506.21887", "authors": ["Edward Chen", "Sang T. Truong", "Natalie Dullerud", "Sanmi Koyejo", "Carlos Guestrin"], "title": "Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds", "comment": null, "summary": "High-stakes decision-making involves navigating multiple competing objectives\nwith expensive evaluations. For instance, in brachytherapy, clinicians must\nbalance maximizing tumor coverage (e.g., an aspirational target or soft bound\nof >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard\nbound of <601 cGy to the bladder), with each plan evaluation being\nresource-intensive. Selecting Pareto-optimal solutions that match implicit\npreferences is challenging, as exhaustive Pareto frontier exploration is\ncomputationally and cognitively prohibitive, necessitating interactive\nframeworks to guide users. While decision-makers (DMs) often possess domain\nknowledge to narrow the search via such soft-hard bounds, current methods often\nlack systematic approaches to iteratively refine these multi-faceted preference\nstructures. Critically, DMs must trust their final decision, confident they\nhaven't missed superior alternatives; this trust is paramount in\nhigh-consequence scenarios. We present Active-MoSH, an interactive local-global\nframework designed for this process. Its local component integrates soft-hard\nbounds with probabilistic preference learning, maintaining distributions over\nDM preferences and bounds for adaptive Pareto subset refinement. This is guided\nby an active sampling strategy optimizing exploration-exploitation while\nminimizing cognitive burden. To build DM trust, Active-MoSH's global component,\nT-MoSH, leverages multi-objective sensitivity analysis to identify potentially\noverlooked, high-value points beyond immediate feedback. We demonstrate\nActive-MoSH's performance benefits through diverse synthetic and real-world\napplications. A user study on AI-generated image selection further validates\nour hypotheses regarding the framework's ability to improve convergence,\nenhance DM trust, and provide expressive preference articulation, enabling more\neffective DMs.", "AI": {"tldr": "Active-MoSH\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u591a\u76ee\u6807\u4f18\u5316\uff0c\u7ed3\u5408\u8f6f\u786c\u8fb9\u754c\u548c\u504f\u597d\u5b66\u4e60\uff0c\u63d0\u5347\u51b3\u7b56\u8005\u4fe1\u4efb\u548c\u6548\u7387\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\uff0c\u5982\u8fd1\u8ddd\u79bb\u653e\u5c04\u6cbb\u7597\uff0c\u9700\u5e73\u8861\u591a\u4e2a\u76ee\u6807\uff08\u5982\u80bf\u7624\u8986\u76d6\u7387\u548c\u5668\u5b98\u5242\u91cf\u9650\u5236\uff09\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7cfb\u7edf\u6027\u504f\u597d\u7ec6\u5316\u673a\u5236\uff0c\u4e14\u51b3\u7b56\u8005\u9700\u4fe1\u4efb\u6700\u7ec8\u9009\u62e9\u3002", "method": "Active-MoSH\u6846\u67b6\u5305\u542b\u5c40\u90e8\u548c\u5168\u5c40\u7ec4\u4ef6\uff1a\u5c40\u90e8\u7ec4\u4ef6\u901a\u8fc7\u8f6f\u786c\u8fb9\u754c\u548c\u6982\u7387\u504f\u597d\u5b66\u4e60\u52a8\u6001\u4f18\u5316Pareto\u5b50\u96c6\uff1b\u5168\u5c40\u7ec4\u4ef6T-MoSH\u901a\u8fc7\u591a\u76ee\u6807\u654f\u611f\u6027\u5206\u6790\u8bc6\u522b\u6f5c\u5728\u9ad8\u4ef7\u503c\u70b9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cActive-MoSH\u5728\u5408\u6210\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u7528\u6237\u7814\u7a76\u8bc1\u5b9e\u5176\u80fd\u52a0\u901f\u6536\u655b\u3001\u589e\u5f3a\u51b3\u7b56\u8005\u4fe1\u4efb\u5e76\u63d0\u4f9b\u66f4\u7075\u6d3b\u7684\u504f\u597d\u8868\u8fbe\u3002", "conclusion": "Active-MoSH\u901a\u8fc7\u4ea4\u4e92\u5f0f\u4f18\u5316\u548c\u4fe1\u4efb\u6784\u5efa\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u98ce\u9669\u591a\u76ee\u6807\u51b3\u7b56\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2506.22370", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2506.22370", "abs": "https://arxiv.org/abs/2506.22370", "authors": ["Carolina Carreira", "\u00c1lvaro Silva", "Alexandre Abreu", "Alexandra Mendes"], "title": "Can Large Language Models Help Students Prove Software Correctness? An Experimental Study with Dafny", "comment": null, "summary": "Students in computing education increasingly use large language models (LLMs)\nsuch as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding\ntasks, like deductive program verification, remains poorly understood. This\npaper investigates how students interact with an LLM when solving formal\nverification exercises in Dafny, a language that supports functional\ncorrectness, by allowing programmers to write formal specifications and\nautomatically verifying that the implementation satisfies the specification. We\nconducted a mixed-methods study with master's students enrolled in a formal\nmethods course. Each participant completed two verification problems, one with\naccess to a custom ChatGPT interface, that logged all interactions, and the\nother without. We identified strategies used by successful students and\nassessed the level of trust students place in LLMs. %\\todo{Our findings show\nthat something here} Our findings show that students perform significantly\nbetter when using ChatGPT; however, performance gains are tied to prompt\nquality. We conclude with practical recommendations for integrating LLMs into\nformal methods courses more effectively, including designing LLM-aware\nchallenges that promote learning rather than substitution.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5b66\u751f\u5728\u89e3\u51b3\u5f62\u5f0f\u5316\u9a8c\u8bc1\u95ee\u9898\u65f6\u4f7f\u7528LLM\uff08\u5982ChatGPT\uff09\u7684\u6548\u679c\uff0c\u53d1\u73b0\u4f7f\u7528ChatGPT\u7684\u5b66\u751f\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u6548\u679c\u4e0e\u63d0\u793a\u8d28\u91cf\u76f8\u5173\u3002", "motivation": "\u63a2\u7d22LLM\u5728\u652f\u6301\u9ad8\u8ba4\u77e5\u9700\u6c42\u4efb\u52a1\uff08\u5982\u7a0b\u5e8f\u9a8c\u8bc1\uff09\u4e2d\u7684\u4f5c\u7528\uff0c\u586b\u8865\u5f53\u524d\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\uff0c\u8ba9\u7855\u58eb\u751f\u5728Dafny\u8bed\u8a00\u4e2d\u5b8c\u6210\u9a8c\u8bc1\u95ee\u9898\uff0c\u4e00\u7ec4\u4f7f\u7528ChatGPT\uff0c\u53e6\u4e00\u7ec4\u4e0d\u4f7f\u7528\u3002", "result": "\u4f7f\u7528ChatGPT\u7684\u5b66\u751f\u8868\u73b0\u663e\u8457\u66f4\u597d\uff0c\u4f46\u8868\u73b0\u63d0\u5347\u4e0e\u63d0\u793a\u8d28\u91cf\u76f8\u5173\u3002", "conclusion": "\u5efa\u8bae\u5728\u5f62\u5f0f\u5316\u65b9\u6cd5\u8bfe\u7a0b\u4e2d\u66f4\u6709\u6548\u5730\u6574\u5408LLM\uff0c\u8bbe\u8ba1\u4fc3\u8fdb\u5b66\u4e60\u7684LLM\u611f\u77e5\u6311\u6218\u3002"}}
{"id": "2506.21996", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21996", "abs": "https://arxiv.org/abs/2506.21996", "authors": ["Rapha\u00ebl Boige", "Amine Boumaza", "Bruno Scherrer"], "title": "AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms", "comment": null, "summary": "Deterministic game-solving algorithms are conventionally analyzed in the\nlight of their average-case complexity against a distribution of random\ngame-trees, where leaf values are independently sampled from a fixed\ndistribution. This simplified model enables uncluttered mathematical analysis,\nrevealing two key properties: root value distributions asymptotically collapse\nto a single fixed value for finite-valued trees, and all reasonable algorithms\nachieve global optimality. However, these findings are artifacts of the model's\ndesign-its long criticized independence assumption strips games of structural\ncomplexity, producing trivial instances where no algorithm faces meaningful\nchallenges. To address this limitation, we introduce a new probabilistic model\nthat incrementally constructs game-trees using a fixed level-wise conditional\ndistribution. By enforcing ancestor dependency, a critical structural feature\nof real-world games, our framework generates problems with adjustable\ndifficulty while retaining some form of analytical tractability. For several\nalgorithms, including AlphaBeta and Scout, we derive recursive formulas\ncharacterizing their average-case complexities under this model. These allow us\nto rigorously compare algorithms on deep game-trees, where Monte-Carlo\nsimulations are no longer feasible. While asymptotically, all algorithms seem\nto converge to identical branching factor (a result analogous to those of\nindependence-based models), deep finite trees reveal stark differences:\nAlphaBeta incurs a significantly larger constant multiplicative factor compared\nto algorithms like Scout, leading to a substantial practical slowdown. Our\nframework sheds new light on classical game-solving algorithms, offering\nrigorous evidence and analytical tools to advance the understanding of these\nmethods under a more realistic, challenging, and yet tractable model.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6982\u7387\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u7956\u5148\u4f9d\u8d56\u5173\u7cfb\u751f\u6210\u66f4\u5177\u6311\u6218\u6027\u7684\u6e38\u620f\u6811\uff0c\u5206\u6790\u4e86AlphaBeta\u548cScout\u7b49\u7b97\u6cd5\u7684\u5e73\u5747\u590d\u6742\u5ea6\uff0c\u63ed\u793a\u4e86\u5b9e\u9645\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u56e0\u72ec\u7acb\u6027\u5047\u8bbe\u7b80\u5316\u4e86\u6e38\u620f\u7ed3\u6784\uff0c\u5bfc\u81f4\u7b97\u6cd5\u5206\u6790\u7ed3\u679c\u5931\u771f\u3002\u65b0\u6a21\u578b\u65e8\u5728\u66f4\u771f\u5b9e\u5730\u6a21\u62df\u6e38\u620f\u7ed3\u6784\u590d\u6742\u6027\u3002", "method": "\u91c7\u7528\u56fa\u5b9a\u5c42\u7ea7\u6761\u4ef6\u5206\u5e03\u9010\u6b65\u6784\u5efa\u6e38\u620f\u6811\uff0c\u5f15\u5165\u7956\u5148\u4f9d\u8d56\u5173\u7cfb\uff0c\u751f\u6210\u53ef\u8c03\u6574\u96be\u5ea6\u7684\u95ee\u9898\u3002", "result": "AlphaBeta\u5728\u6df1\u5c42\u6811\u4e2d\u8868\u73b0\u51fa\u6bd4Scout\u66f4\u5927\u7684\u5e38\u6570\u4e58\u6570\uff0c\u5bfc\u81f4\u5b9e\u9645\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u65b0\u6846\u67b6\u4e3a\u7ecf\u5178\u6e38\u620f\u6c42\u89e3\u7b97\u6cd5\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u7684\u5206\u6790\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u7b97\u6cd5\u5728\u590d\u6742\u7ed3\u6784\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\u3002"}}
{"id": "2506.22390", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.22390", "abs": "https://arxiv.org/abs/2506.22390", "authors": ["Ramtin Ehsani", "Sakshi Pathak", "Esteban Parra", "Sonia Haiduc", "Preetha Chatterjee"], "title": "What Makes ChatGPT Effective for Software Issue Resolution? An Empirical Study of Developer-ChatGPT Conversations in GitHub", "comment": null, "summary": "Conversational large-language models are extensively used for issue\nresolution tasks. However, not all developer-LLM conversations are useful for\neffective issue resolution. In this paper, we analyze 686 developer-ChatGPT\nconversations shared within GitHub issue threads to identify characteristics\nthat make these conversations effective for issue resolution. First, we analyze\nthe conversations and their corresponding issues to distinguish helpful from\nunhelpful conversations. We begin by categorizing the types of tasks developers\nseek help with to better understand the scenarios in which ChatGPT is most\neffective. Next, we examine a wide range of conversational, project, and\nissue-related metrics to uncover factors associated with helpful conversations.\nFinally, we identify common deficiencies in unhelpful ChatGPT responses to\nhighlight areas that could inform the design of more effective developer-facing\ntools. We found that only 62% of the ChatGPT conversations were helpful for\nsuccessful issue resolution. ChatGPT is most effective for code generation and\ntools/libraries/APIs recommendations, but struggles with code explanations.\nHelpful conversations tend to be shorter, more readable, and exhibit stronger\nsemantic and linguistic alignment. Larger, more popular projects and more\nexperienced developers benefit more from ChatGPT. At the issue level, ChatGPT\nperforms best on simpler problems with limited developer activity and faster\nresolution, typically well-scoped tasks like compilation errors. The most\ncommon deficiencies in unhelpful ChatGPT responses include incorrect\ninformation and lack of comprehensiveness. Our findings have wide implications\nincluding guiding developers on effective interaction strategies for issue\nresolution, informing the development of tools or frameworks to support optimal\nprompt design, and providing insights on fine-tuning LLMs for issue resolution\ntasks.", "AI": {"tldr": "\u5206\u6790686\u4e2a\u5f00\u53d1\u8005\u4e0eChatGPT\u7684\u5bf9\u8bdd\uff0c\u53d1\u73b062%\u5bf9\u95ee\u9898\u89e3\u51b3\u6709\u5e2e\u52a9\uff0cChatGPT\u5728\u4ee3\u7801\u751f\u6210\u548c\u5de5\u5177\u63a8\u8350\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u5728\u4ee3\u7801\u89e3\u91ca\u4e0a\u8f83\u5f31\u3002", "motivation": "\u7814\u7a76\u5f00\u53d1\u8005\u4e0eChatGPT\u5bf9\u8bdd\u7684\u6709\u6548\u6027\uff0c\u4ee5\u4f18\u5316\u95ee\u9898\u89e3\u51b3\u6548\u7387\u3002", "method": "\u5206\u6790\u5bf9\u8bdd\u7c7b\u578b\u3001\u4efb\u52a1\u5206\u7c7b\u53ca\u591a\u7ef4\u5ea6\u6307\u6807\uff0c\u533a\u5206\u6709\u7528\u4e0e\u65e0\u7528\u5bf9\u8bdd\u3002", "result": "ChatGPT\u5728\u4ee3\u7801\u751f\u6210\u548c\u5de5\u5177\u63a8\u8350\u4e0a\u6548\u679c\u663e\u8457\uff0c\u4f46\u4ee3\u7801\u89e3\u91ca\u4e0d\u8db3\uff1b\u6709\u7528\u5bf9\u8bdd\u66f4\u7b80\u77ed\u3001\u6613\u8bfb\u4e14\u8bed\u4e49\u5bf9\u9f50\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5f00\u53d1\u8005\u4e92\u52a8\u7b56\u7565\u3001\u5de5\u5177\u8bbe\u8ba1\u548cLLM\u4f18\u5316\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2506.22005", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22005", "abs": "https://arxiv.org/abs/2506.22005", "authors": ["Naoto Onda", "Kazumi Kasaura", "Yuta Oriike", "Masaya Taniguchi", "Akiyoshi Sannai", "Sho Sonoda"], "title": "LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving", "comment": "15 pages, 4 figures, 5 tables", "summary": "We introduce LeanConjecturer, a pipeline for automatically generating\nuniversity-level mathematical conjectures in Lean 4 using Large Language Models\n(LLMs). Our hybrid approach combines rule-based context extraction with\nLLM-based theorem statement generation, addressing the data scarcity challenge\nin formal theorem proving. Through iterative generation and evaluation,\nLeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with\n3,776 identified as syntactically valid and non-trivial, that is, cannot be\nproven by \\texttt{aesop} tactic. We demonstrate the utility of these generated\nconjectures for reinforcement learning through Group Relative Policy\nOptimization (GRPO), showing that targeted training on domain-specific\nconjectures can enhance theorem proving capabilities. Our approach generates\n103.25 novel conjectures per seed file on average, providing a scalable\nsolution for creating training data for theorem proving systems. Our system\nsuccessfully verified several non-trivial theorems in topology, including\nproperties of semi-open, alpha-open, and pre-open sets, demonstrating its\npotential for mathematical discovery beyond simple variations of existing\nresults.", "AI": {"tldr": "LeanConjecturer\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u751f\u6210\u6570\u5b66\u731c\u60f3\u7684\u5de5\u5177\uff0c\u7ed3\u5408\u89c4\u5219\u63d0\u53d6\u548cLLM\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u4e2d\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u4e2d\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u6311\u6218\u3002", "method": "\u7ed3\u5408\u89c4\u5219\u63d0\u53d6\u548cLLM\u751f\u6210\uff0c\u901a\u8fc7\u8fed\u4ee3\u751f\u6210\u548c\u8bc4\u4f30\u4ea7\u751f\u6570\u5b66\u731c\u60f3\u3002", "result": "\u751f\u6210\u4e8612,289\u4e2a\u731c\u60f3\uff0c\u5176\u4e2d3,776\u4e2a\u88ab\u9a8c\u8bc1\u4e3a\u975e\u5e73\u51e1\u4e14\u8bed\u6cd5\u6709\u6548\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9a\u7406\u8bc1\u660e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u6570\u636e\u751f\u6210\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u6570\u5b66\u53d1\u73b0\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.22056", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22056", "abs": "https://arxiv.org/abs/2506.22056", "authors": ["Xuan Zhang", "Ziyan Jiang", "Rui Meng", "Yifei Leng", "Zhenbang Xiao", "Zora Zhiruo Wang", "Yanyi Shang", "Dehan Kong"], "title": "Universal Retrieval for Multimodal Trajectory Modeling", "comment": "18 pages, 3 figures, accepted by Workshop on Computer-use Agents @\n  ICML 2025", "summary": "Trajectory data, capturing human actions and environmental states across\nvarious modalities, holds significant potential for enhancing AI agent\ncapabilities, particularly in GUI environments. However, how to model the\nrepresentation of trajectory-level data presents a significant challenge that\nhas not been systematically addressed amid explosive trajectory data growth. In\nthis work, we introduce Multimodal Trajectory Retrieval, bridging the gap\nbetween universal retrieval and agent-centric trajectory modeling. We construct\nthe Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and\nstates across diverse real-world scenarios. Based on this, we present\nGAE-Bench, a benchmark containing a large number of trajectory-based retrieval\npairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework\nthat adopts vision-language models and incorporates optimized contrastive\nlearning through a token selection and the GradCache mechanism. Comprehensive\nevaluations across multiple datasets show that GAE-Retriever consistently\noutperforms strong baselines in retrieval recall, highlighting its\neffectiveness in advancing multimodal trajectory retrieval.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u8f68\u8ff9\u68c0\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u7edf\u4e00\u6570\u636e\u96c6\u548c\u5f15\u5165\u4f18\u5316\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f68\u8ff9\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u8f68\u8ff9\u6570\u636e\u5728\u589e\u5f3aAI\u4ee3\u7406\u80fd\u529b\u65b9\u9762\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5176\u8868\u793a\u5efa\u6a21\u5c1a\u672a\u7cfb\u7edf\u89e3\u51b3\u3002", "method": "\u6784\u5efaUATD\u6570\u636e\u96c6\u548cGAE-Bench\u57fa\u51c6\uff0c\u63d0\u51faGAE-Retriever\u6846\u67b6\uff0c\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u4f18\u5316\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "GAE-Retriever\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\uff0c\u68c0\u7d22\u53ec\u56de\u7387\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63a8\u52a8\u4e86\u591a\u6a21\u6001\u8f68\u8ff9\u68c0\u7d22\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.22068", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22068", "abs": "https://arxiv.org/abs/2506.22068", "authors": ["Shengyue Yao", "Runqing Guo", "Yangyang Qin", "Miangbing Meng", "Jipeng Cao", "Yilun Lin", "Yisheng Lv", "Fei-Yue Wang"], "title": "Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios", "comment": "Submitted to IEEE Transaction on Vehicular Technology", "summary": "With the deep penetration of Artificial Intelligence (AI) in the\ntransportation sector, intelligent cockpits, autonomous driving, and\nintelligent road networks are developing at an unprecedented pace. However, the\ndata ecosystems of these three key areas are increasingly fragmented and\nincompatible. Especially, existing testing methods rely on data stacking, fail\nto cover all edge cases, and lack flexibility. To address this issue, this\npaper introduces the concept of \"Query as Test\" (QaT). This concept shifts the\nfocus from rigid, prescripted test cases to flexible, on-demand logical queries\nagainst a unified data representation. Specifically, we identify the need for a\nfundamental improvement in data storage and representation, leading to our\nproposal of \"Extensible Scenarios Notations\" (ESN). ESN is a novel declarative\ndata framework based on Answer Set Programming (ASP), which uniformly\nrepresents heterogeneous multimodal data from the cockpit, vehicle, and road as\na collection of logical facts and rules. This approach not only achieves deep\nsemantic fusion of data, but also brings three core advantages: (1) supports\ncomplex and flexible semantic querying through logical reasoning; (2) provides\nnatural interpretability for decision-making processes; (3) allows for\non-demand data abstraction through logical rules, enabling fine-grained privacy\nprotection. We further elaborate on the QaT paradigm, transforming the\nfunctional validation and safety compliance checks of autonomous driving\nsystems into logical queries against the ESN database, significantly enhancing\nthe expressiveness and formal rigor of the testing. Finally, we introduce the\nconcept of \"Validation-Driven Development\" (VDD), which suggests to guide\ndevelopments by logical validation rather than quantitative testing in the era\nof Large Language Models, in order to accelerating the iteration and\ndevelopment process.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u201cQuery as Test\u201d\uff08QaT\uff09\u6982\u5ff5\uff0c\u901a\u8fc7\u903b\u8f91\u67e5\u8be2\u66ff\u4ee3\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u201cExtensible Scenarios Notations\u201d\uff08ESN\uff09\u6570\u636e\u6846\u67b6\uff0c\u5b9e\u73b0\u5f02\u6784\u6570\u636e\u7684\u8bed\u4e49\u878d\u5408\u548c\u7075\u6d3b\u6d4b\u8bd5\u3002", "motivation": "\u89e3\u51b3\u4ea4\u901a\u9886\u57dfAI\u5e94\u7528\u4e2d\u6570\u636e\u788e\u7247\u5316\u548c\u6d4b\u8bd5\u65b9\u6cd5\u7f3a\u4e4f\u7075\u6d3b\u6027\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8eAnswer Set Programming\uff08ASP\uff09\u7684ESN\u6846\u67b6\uff0c\u7edf\u4e00\u8868\u793a\u591a\u6a21\u6001\u6570\u636e\uff0c\u652f\u6301\u903b\u8f91\u67e5\u8be2\u548c\u9a8c\u8bc1\u3002", "result": "ESN\u6846\u67b6\u652f\u6301\u590d\u6742\u8bed\u4e49\u67e5\u8be2\u3001\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\u548c\u9690\u79c1\u4fdd\u62a4\uff0cQaT\u8303\u5f0f\u63d0\u5347\u4e86\u6d4b\u8bd5\u7684\u8868\u8fbe\u529b\u548c\u4e25\u8c28\u6027\u3002", "conclusion": "\u63d0\u51fa\u201cValidation-Driven Development\u201d\uff08VDD\uff09\uff0c\u4ee5\u903b\u8f91\u9a8c\u8bc1\u9a71\u52a8\u5f00\u53d1\uff0c\u52a0\u901f\u8fed\u4ee3\u8fc7\u7a0b\u3002"}}
{"id": "2506.22183", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22183", "abs": "https://arxiv.org/abs/2506.22183", "authors": ["Camille Fran\u00e7ois", "Ludovic P\u00e9ran", "Ayah Bdeir", "Nouha Dziri", "Will Hawkins", "Yacine Jernite", "Sayash Kapoor", "Juliet Shen", "Heidy Khlaaf", "Kevin Klyman", "Nik Marda", "Marie Pellat", "Deb Raji", "Divya Siddarth", "Aviya Skowron", "Joseph Spisak", "Madhulika Srikumar", "Victor Storchan", "Audrey Tang", "Jen Weedon"], "title": "A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety", "comment": "Proceedings from the Columbia Convening on Openness in Artificial\n  Intelligence and AI Safety", "summary": "The rapid rise of open-weight and open-source foundation models is\nintensifying the obligation and reshaping the opportunity to make AI systems\nsafe. This paper reports outcomes from the Columbia Convening on AI Openness\nand Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme\ninvolving more than forty-five researchers, engineers, and policy leaders from\nacademia, industry, civil society, and government. Using a participatory,\nsolutions-oriented process, the working groups produced (i) a research agenda\nat the intersection of safety and open source AI; (ii) a mapping of existing\nand needed technical interventions and open source tools to safely and\nresponsibly deploy open foundation models across the AI development workflow;\nand (iii) a mapping of the content safety filter ecosystem with a proposed\nroadmap for future research and development. We find that openness --\nunderstood as transparent weights, interoperable tooling, and public governance\n-- can enhance safety by enabling independent scrutiny, decentralized\nmitigation, and culturally plural oversight. However, significant gaps persist:\nscarce multimodal and multilingual benchmarks, limited defenses against\nprompt-injection and compositional attacks in agentic systems, and insufficient\nparticipatory mechanisms for communities most affected by AI harms. The paper\nconcludes with a roadmap of five priority research directions, emphasizing\nparticipatory inputs, future-proof content filters, ecosystem-wide safety\ninfrastructure, rigorous agentic safeguards, and expanded harm taxonomies.\nThese recommendations informed the February 2025 French AI Action Summit and\nlay groundwork for an open, plural, and accountable AI safety discipline.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u5bf9AI\u5b89\u5168\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u7814\u7a76\u8bae\u7a0b\u3001\u6280\u672f\u5e72\u9884\u548c\u5b89\u5168\u5de5\u5177\uff0c\u5e76\u5f3a\u8c03\u5f00\u653e\u6027\u548c\u591a\u5143\u6cbb\u7406\u5bf9\u5b89\u5168\u7684\u4fc3\u8fdb\u4f5c\u7528\u3002", "motivation": "\u968f\u7740\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5982\u4f55\u786e\u4fddAI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u6210\u4e3a\u8feb\u5207\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u54e5\u4f26\u6bd4\u4e9aAI\u5f00\u653e\u4e0e\u5b89\u5168\u4f1a\u8bae\u7684\u53c2\u4e0e\u5f0f\u89e3\u51b3\u65b9\u6848\u8fc7\u7a0b\uff0c\u5de5\u4f5c\u7ec4\u5236\u5b9a\u4e86\u7814\u7a76\u8bae\u7a0b\u3001\u6280\u672f\u5e72\u9884\u548c\u5b89\u5168\u5de5\u5177\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f00\u653e\u6027\u53ef\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u4f46\u4ecd\u5b58\u5728\u591a\u6a21\u6001\u548c\u591a\u8bed\u8a00\u57fa\u51c6\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e94\u9879\u4f18\u5148\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u5f00\u653e\u3001\u591a\u5143\u548c\u8d1f\u8d23\u4efb\u7684AI\u5b89\u5168\u5b66\u79d1\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2506.22271", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22271", "abs": "https://arxiv.org/abs/2506.22271", "authors": ["Samy Badreddine", "Emile van Krieken", "Luciano Serafini"], "title": "Breaking Rank Bottlenecks in Knowledge Graph Completion", "comment": null, "summary": "Many Knowledge Graph Completion (KGC) models, despite using powerful\nencoders, rely on a simple vector-matrix multiplication to score queries\nagainst candidate object entities. When the number of entities is larger than\nthe model's embedding dimension, which in practical scenarios is often by\nseveral orders of magnitude, we have a linear output layer with a rank\nbottleneck. Such bottlenecked layers limit model expressivity. We investigate\nboth theoretically and empirically how rank bottlenecks affect KGC models. We\nfind that, by limiting the set of feasible predictions, rank bottlenecks hurt\nranking accuracy and the distribution fidelity of scores. Inspired by the\nlanguage modelling literature, we propose KGE-MoS, a mixture-based output layer\nto break rank bottlenecks in many KGC models. Our experiments on four datasets\nshow that KGE-MoS improves performance and probabilistic fit of KGC models for\na low parameter cost.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\uff08KGC\uff09\u6a21\u578b\u4e2d\u7531\u4e8e\u8f93\u51fa\u5c42\u79e9\u74f6\u9888\u5bfc\u81f4\u7684\u6027\u80fd\u9650\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u7684\u8f93\u51fa\u5c42\uff08KGE-MoS\uff09\u4ee5\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "motivation": "\u73b0\u6709KGC\u6a21\u578b\u5728\u5b9e\u4f53\u6570\u91cf\u8fdc\u5927\u4e8e\u5d4c\u5165\u7ef4\u5ea6\u65f6\uff0c\u8f93\u51fa\u5c42\u7684\u79e9\u74f6\u9888\u9650\u5236\u4e86\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u5f71\u54cd\u4e86\u6392\u540d\u51c6\u786e\u6027\u548c\u5206\u6570\u5206\u5e03\u4fdd\u771f\u5ea6\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\u79e9\u74f6\u9888\u7684\u5f71\u54cd\uff0c\u63d0\u51faKGE-MoS\uff0c\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u7684\u8f93\u51fa\u5c42\u8bbe\u8ba1\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cKGE-MoS\u4ee5\u8f83\u4f4e\u53c2\u6570\u6210\u672c\u63d0\u5347\u4e86KGC\u6a21\u578b\u7684\u6027\u80fd\u548c\u6982\u7387\u62df\u5408\u5ea6\u3002", "conclusion": "KGE-MoS\u6709\u6548\u89e3\u51b3\u4e86\u79e9\u74f6\u9888\u95ee\u9898\uff0c\u63d0\u5347\u4e86KGC\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.22276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22276", "abs": "https://arxiv.org/abs/2506.22276", "authors": ["Reuth Mirsky"], "title": "Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates", "comment": "Extended version of a paper accepted for publication in AI Magazine", "summary": "Artificial intelligence has made remarkable strides in recent years,\nachieving superhuman performance across a wide range of tasks. Yet despite\nthese advances, most cooperative AI systems remain rigidly obedient, designed\nto follow human instructions without question and conform to user expectations,\neven when doing so may be counterproductive or unsafe. This paper argues for\nexpanding the agency of AI teammates to include \\textit{intelligent\ndisobedience}, empowering them to make meaningful and autonomous contributions\nwithin human-AI teams. It introduces a scale of AI agency levels and uses\nrepresentative examples to highlight the importance and growing necessity of\ntreating AI autonomy as an independent research focus in cooperative settings.\nThe paper then explores how intelligent disobedience manifests across different\nautonomy levels and concludes by proposing initial boundaries and\nconsiderations for studying disobedience as a core capability of artificial\nagents.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u8d4b\u4e88AI\u961f\u53cb\u667a\u80fd\u4e0d\u670d\u4ece\u80fd\u529b\uff0c\u4f7f\u5176\u5728\u4eba\u7c7b-AI\u56e2\u961f\u4e2d\u80fd\u81ea\u4e3b\u8d21\u732e\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0d\u540c\u81ea\u4e3b\u7ea7\u522b\u4e0b\u667a\u80fd\u4e0d\u670d\u4ece\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u5408\u4f5c\u578bAI\u7cfb\u7edf\u8fc7\u4e8e\u670d\u4ece\uff0c\u53ef\u80fd\u4e0d\u5229\u4e8e\u6548\u7387\u6216\u5b89\u5168\uff0c\u9700\u7814\u7a76AI\u7684\u81ea\u4e3b\u6027\u4ee5\u63d0\u5347\u56e2\u961f\u534f\u4f5c\u6548\u679c\u3002", "method": "\u63d0\u51faAI\u81ea\u4e3b\u6027\u7ea7\u522b\u91cf\u8868\uff0c\u5e76\u901a\u8fc7\u4ee3\u8868\u6027\u6848\u4f8b\u8bf4\u660e\u667a\u80fd\u4e0d\u670d\u4ece\u7684\u91cd\u8981\u6027\u3002", "result": "\u5f3a\u8c03\u4e86\u5c06AI\u81ea\u4e3b\u6027\u4f5c\u4e3a\u72ec\u7acb\u7814\u7a76\u65b9\u5411\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u521d\u6b65\u63a2\u8ba8\u4e86\u667a\u80fd\u4e0d\u670d\u4ece\u7684\u8fb9\u754c\u3002", "conclusion": "\u5efa\u8bae\u5c06\u667a\u80fd\u4e0d\u670d\u4ece\u4f5c\u4e3aAI\u6838\u5fc3\u80fd\u529b\u8fdb\u884c\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u4e86\u521d\u6b65\u7814\u7a76\u6846\u67b6\u3002"}}
{"id": "2506.22309", "categories": ["cs.AI", "cs.CL", "cs.DM", "cs.LG", "06B99", "I.2.4; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.22309", "abs": "https://arxiv.org/abs/2506.22309", "authors": ["Klara M. Gutekunst", "Dominik D\u00fcrrschnabel", "Johannes Hirth", "Gerd Stumme"], "title": "Conceptual Topic Aggregation", "comment": "16 pages, 4 tables, 11 figures, International Joint Conference on\n  Conceptual Knowledge Structures", "summary": "The vast growth of data has rendered traditional manual inspection\ninfeasible, necessitating the adoption of computational methods for efficient\ndata exploration. Topic modeling has emerged as a powerful tool for analyzing\nlarge-scale textual datasets, enabling the extraction of latent semantic\nstructures. However, existing methods for topic modeling often struggle to\nprovide interpretable representations that facilitate deeper insights into data\nstructure and content. In this paper, we propose FAT-CAT, an approach based on\nFormal Concept Analysis (FCA) to enhance meaningful topic aggregation and\nvisualization of discovered topics. Our approach can handle diverse topics and\nfile types -- grouped by directories -- to construct a concept lattice that\noffers a structured, hierarchical representation of their topic distribution.\nIn a case study on the ETYNTKE dataset, we evaluate the effectiveness of our\napproach against other representation methods to demonstrate that FCA-based\naggregation provides more meaningful and interpretable insights into dataset\ncomposition than existing topic modeling techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\u7684FAT-CAT\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u4e3b\u9898\u5efa\u6a21\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u89c6\u5316\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u96be\u4ee5\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8868\u793a\uff0c\u65e0\u6cd5\u6df1\u5165\u7406\u89e3\u6570\u636e\u7ed3\u6784\u548c\u5185\u5bb9\u3002", "method": "\u5229\u7528FCA\u6784\u5efa\u6982\u5ff5\u683c\uff0c\u5b9e\u73b0\u4e3b\u9898\u7684\u5c42\u6b21\u5316\u3001\u7ed3\u6784\u5316\u8868\u793a\uff0c\u652f\u6301\u591a\u6837\u4e3b\u9898\u548c\u6587\u4ef6\u7c7b\u578b\u3002", "result": "\u5728ETYNTKE\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFAT-CAT\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u4f9b\u66f4\u76f4\u89c2\u3001\u6709\u610f\u4e49\u7684\u6570\u636e\u96c6\u7ec4\u6210\u5206\u6790\u3002", "conclusion": "FCA\u4e3a\u57fa\u7840\u7684\u65b9\u6cd5\u5728\u4e3b\u9898\u5efa\u6a21\u4e2d\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.22355", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22355", "abs": "https://arxiv.org/abs/2506.22355", "authors": ["Pascale Fung", "Yoram Bachrach", "Asli Celikyilmaz", "Kamalika Chaudhuri", "Delong Chen", "Willy Chung", "Emmanuel Dupoux", "Herv\u00e9 J\u00e9gou", "Alessandro Lazaric", "Arjun Majumdar", "Andrea Madotto", "Franziska Meier", "Florian Metze", "Th\u00e9o Moutakanni", "Juan Pino", "Basile Terver", "Joseph Tighe", "Jitendra Malik"], "title": "Embodied AI Agents: Modeling the World", "comment": null, "summary": "This paper describes our research on AI agents embodied in visual, virtual or\nphysical forms, enabling them to interact with both users and their\nenvironments. These agents, which include virtual avatars, wearable devices,\nand robots, are designed to perceive, learn and act within their surroundings,\nwhich makes them more similar to how humans learn and interact with the\nenvironments as compared to disembodied agents. We propose that the development\nof world models is central to reasoning and planning of embodied AI agents,\nallowing these agents to understand and predict their environment, to\nunderstand user intentions and social contexts, thereby enhancing their ability\nto perform complex tasks autonomously. World modeling encompasses the\nintegration of multimodal perception, planning through reasoning for action and\ncontrol, and memory to create a comprehensive understanding of the physical\nworld. Beyond the physical world, we also propose to learn the mental world\nmodel of users to enable better human-agent collaboration.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5177\u8eabAI\u4ee3\u7406\u7684\u611f\u77e5\u3001\u5b66\u4e60\u4e0e\u884c\u52a8\u80fd\u529b\uff0c\u63d0\u51fa\u4e16\u754c\u6a21\u578b\u662f\u5176\u63a8\u7406\u4e0e\u89c4\u5212\u7684\u6838\u5fc3\uff0c\u4ee5\u63d0\u5347\u81ea\u4e3b\u4efb\u52a1\u6267\u884c\u80fd\u529b\u3002", "motivation": "\u63a2\u7d22\u5177\u8eabAI\u4ee3\u7406\u5982\u4f55\u901a\u8fc7\u4e16\u754c\u6a21\u578b\u66f4\u63a5\u8fd1\u4eba\u7c7b\u7684\u5b66\u4e60\u4e0e\u4e92\u52a8\u65b9\u5f0f\uff0c\u589e\u5f3a\u5176\u4e0e\u73af\u5883\u548c\u7528\u6237\u7684\u4ea4\u4e92\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e16\u754c\u6a21\u578b\u6846\u67b6\uff0c\u6574\u5408\u591a\u6a21\u6001\u611f\u77e5\u3001\u63a8\u7406\u89c4\u5212\u3001\u63a7\u5236\u4e0e\u8bb0\u5fc6\uff0c\u5e76\u5b66\u4e60\u7528\u6237\u7684\u5fc3\u7406\u4e16\u754c\u6a21\u578b\u3002", "result": "\u5177\u8eabAI\u4ee3\u7406\u80fd\u66f4\u6709\u6548\u5730\u7406\u89e3\u73af\u5883\u3001\u9884\u6d4b\u7528\u6237\u610f\u56fe\u548c\u793e\u4f1a\u60c5\u5883\uff0c\u4ece\u800c\u81ea\u4e3b\u6267\u884c\u590d\u6742\u4efb\u52a1\u3002", "conclusion": "\u4e16\u754c\u6a21\u578b\u662f\u5177\u8eabAI\u4ee3\u7406\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u4e0e\u89c4\u5212\u7684\u5173\u952e\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u4eba\u673a\u534f\u4f5c\u3002"}}
{"id": "2506.22358", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22358", "abs": "https://arxiv.org/abs/2506.22358", "authors": ["Varvara Kalokyri", "Nikolaos S. Tachos", "Charalampos N. Kalantzopoulos", "Stelios Sfakianakis", "Haridimos Kondylakis", "Dimitrios I. Zaridis", "Sara Colantonio", "Daniele Regge", "Nikolaos Papanikolaou", "The ProCAncer-I consortium", "Konstantinos Marias", "Dimitrios I. Fotiadis", "Manolis Tsiknakis"], "title": "AI Model Passport: Data and System Traceability Framework for Transparent AI in Health", "comment": null, "summary": "The increasing integration of Artificial Intelligence (AI) into health and\nbiomedical systems necessitates robust frameworks for transparency,\naccountability, and ethical compliance. Existing frameworks often rely on\nhuman-readable, manual documentation which limits scalability, comparability,\nand machine interpretability across projects and platforms. They also fail to\nprovide a unique, verifiable identity for AI models to ensure their provenance\nand authenticity across systems and use cases, limiting reproducibility and\nstakeholder trust. This paper introduces the concept of the AI Model Passport,\na structured and standardized documentation framework that acts as a digital\nidentity and verification tool for AI models. It captures essential metadata to\nuniquely identify, verify, trace and monitor AI models across their lifecycle -\nfrom data acquisition and preprocessing to model design, development and\ndeployment. In addition, an implementation of this framework is presented\nthrough AIPassport, an MLOps tool developed within the ProCAncer-I EU project\nfor medical imaging applications. AIPassport automates metadata collection,\nensures proper versioning, decouples results from source scripts, and\nintegrates with various development environments. Its effectiveness is\nshowcased through a lesion segmentation use case using data from the\nProCAncer-I dataset, illustrating how the AI Model Passport enhances\ntransparency, reproducibility, and regulatory readiness while reducing manual\neffort. This approach aims to set a new standard for fostering trust and\naccountability in AI-driven healthcare solutions, aspiring to serve as the\nbasis for developing transparent and regulation compliant AI systems across\ndomains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAI Model Passport\u6846\u67b6\uff0c\u4e3aAI\u6a21\u578b\u63d0\u4f9b\u6807\u51c6\u5316\u6570\u5b57\u8eab\u4efd\u548c\u9a8c\u8bc1\u5de5\u5177\uff0c\u63d0\u5347\u900f\u660e\u5ea6\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u5e76\u901a\u8fc7AIPassport\u5de5\u5177\u5728\u533b\u7597\u5f71\u50cf\u5e94\u7528\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709AI\u6a21\u578b\u900f\u660e\u5ea6\u6846\u67b6\u4f9d\u8d56\u4eba\u5de5\u6587\u6863\uff0c\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u548c\u673a\u5668\u53ef\u8bfb\u6027\uff0c\u96be\u4ee5\u786e\u4fdd\u6a21\u578b\u8eab\u4efd\u548c\u771f\u5b9e\u6027\uff0c\u9650\u5236\u4e86\u53ef\u91cd\u590d\u6027\u548c\u4fe1\u4efb\u3002", "method": "\u63d0\u51faAI Model Passport\u6846\u67b6\uff0c\u6807\u51c6\u5316\u8bb0\u5f55\u6a21\u578b\u5143\u6570\u636e\uff0c\u5e76\u5f00\u53d1AIPassport\u5de5\u5177\u81ea\u52a8\u5316\u5143\u6570\u636e\u6536\u96c6\u548c\u7248\u672c\u7ba1\u7406\u3002", "result": "\u5728ProCAncer-I\u9879\u76ee\u7684\u533b\u7597\u5f71\u50cf\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86AIPassport\u7684\u6709\u6548\u6027\uff0c\u63d0\u5347\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u3002", "conclusion": "AI Model Passport\u4e3aAI\u9a71\u52a8\u7684\u533b\u7597\u89e3\u51b3\u65b9\u6848\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\uff0c\u589e\u5f3a\u4e86\u4fe1\u4efb\u548c\u5408\u89c4\u6027\u3002"}}
{"id": "2506.22419", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22419", "abs": "https://arxiv.org/abs/2506.22419", "authors": ["Bingchen Zhao", "Despoina Magka", "Minqi Jiang", "Xian Li", "Roberta Raileanu", "Tatiana Shavrina", "Jean-Christophe Gagnon-Audet", "Kelvin Niu", "Shagun Sodhani", "Michael Shvartsman", "Andrei Lupu", "Alisia Lupidi", "Edan Toledo", "Karen Hambardzumyan", "Martin Josifoski", "Thomas Foster", "Lucia Cipolina-Kun", "Abhishek Charnalia", "Derek Dunfield", "Alexander H. Miller", "Oisin Mac Aodha", "Jakob Foerster", "Yoram Bachrach"], "title": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "comment": null, "summary": "Rapid advancements in large language models (LLMs) have the potential to\nassist in scientific progress. A critical capability toward this endeavor is\nthe ability to reproduce existing work. To evaluate the ability of AI agents to\nreproduce results in an active research area, we introduce the Automated LLM\nSpeedrunning Benchmark, leveraging the research community contributions on the\nNanoGPT speedrun, a competition to train a GPT-2 model in the shortest time.\nEach of the 19 speedrun tasks provides the agent with the previous records\ntraining script, optionally paired with one of three hint formats, ranging from\npseudocode to paper-like descriptions of the new records improvements. Records\nexecute quickly by design and speedrun improvements encompass diverse\ncode-level changes, ranging from high-level algorithmic advancements to\nhardware-aware optimizations. These features make the benchmark both accessible\nand realistic for the frontier problem of improving LLM training. We find that\nrecent reasoning LLMs combined with SoTA scaffolds struggle to reimplement\nalready-known innovations in our benchmark, even when given detailed hints. Our\nbenchmark thus provides a simple, non-saturated measure of an LLMs ability to\nautomate scientific reproduction, a necessary (but not sufficient) skill for an\nautonomous research agent.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316LLM\u901f\u5ea6\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u4ee3\u7406\u5728\u79d1\u5b66\u590d\u73b0\u4e2d\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524dLLM\u5728\u590d\u73b0\u5df2\u77e5\u521b\u65b0\u65f6\u4ecd\u5b58\u5728\u56f0\u96be\u3002", "motivation": "\u8bc4\u4f30AI\u4ee3\u7406\u5728\u79d1\u5b66\u590d\u73b0\u4e2d\u7684\u80fd\u529b\uff0c\u4ee5\u63a8\u52a8LLM\u5728\u79d1\u5b66\u8fdb\u6b65\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5229\u7528NanoGPT\u901f\u5ea6\u8fd0\u884c\u768419\u4e2a\u4efb\u52a1\uff0c\u7ed3\u5408\u4e0d\u540c\u63d0\u793a\u683c\u5f0f\uff0c\u6d4b\u8bd5LLM\u590d\u73b0\u5df2\u77e5\u521b\u65b0\u7684\u80fd\u529b\u3002", "result": "\u5f53\u524dLLM\u5373\u4f7f\u7ed3\u5408\u5148\u8fdb\u6846\u67b6\u548c\u8be6\u7ec6\u63d0\u793a\uff0c\u4ecd\u96be\u4ee5\u590d\u73b0\u5df2\u77e5\u521b\u65b0\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u8861\u91cfLLM\u81ea\u52a8\u5316\u79d1\u5b66\u590d\u73b0\u80fd\u529b\u63d0\u4f9b\u4e86\u7b80\u5355\u6709\u6548\u7684\u5de5\u5177\uff0c\u662f\u81ea\u4e3b\u7814\u7a76\u4ee3\u7406\u7684\u5fc5\u8981\u6280\u80fd\u4e4b\u4e00\u3002"}}
