{"id": "2508.03846", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03846", "abs": "https://arxiv.org/abs/2508.03846", "authors": ["Hashini Gunatilake", "John Grundy", "Rashina Hoda", "Ingo Mueller"], "title": "Empathy Guidelines for Improving Practitioner Well-being & Software Engineering Practices", "comment": null, "summary": "Empathy is a powerful yet often overlooked element in software engineering\n(SE), supporting better teamwork, smoother communication, and effective\ndecision-making. In our previous study, we identified a range of practitioner\nstrategies for fostering empathy in SE contexts. Building on these insights,\nthis paper introduces 17 actionable empathy guidelines designed to support\npractitioners, teams, and organisations. We also explore how these guidelines\ncan be implemented in practice by examining real-world applications,\nchallenges, and strategies to overcome them shared by software practitioners.\nTo support adoption, we present a visual prioritisation framework that\ncategorises the guidelines based on perceived importance, ease of\nimplementation, and willingness to adopt. The findings offer practical and\nflexible suggestions for integrating empathy into everyday SE work, helping\nteams move from principles to sustainable action.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e8617\u6761\u53ef\u64cd\u4f5c\u7684\u5171\u60c5\u6307\u5357\uff0c\u5e2e\u52a9\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u66f4\u597d\u5730\u5b9e\u8df5\u5171\u60c5\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89c6\u5316\u6846\u67b6\u4ee5\u652f\u6301\u5b9e\u65bd\u3002", "motivation": "\u5171\u60c5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5e38\u88ab\u5ffd\u89c6\uff0c\u4f46\u5176\u5bf9\u56e2\u961f\u5408\u4f5c\u3001\u6c9f\u901a\u548c\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u5b9e\u7528\u6307\u5357\uff0c\u5e2e\u52a9\u56e2\u961f\u5c06\u5171\u60c5\u539f\u5219\u8f6c\u5316\u4e3a\u53ef\u6301\u7eed\u884c\u52a8\u3002", "method": "\u57fa\u4e8e\u5148\u524d\u7814\u7a76\uff0c\u672c\u6587\u8bbe\u8ba1\u4e8617\u6761\u5171\u60c5\u6307\u5357\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u3001\u6311\u6218\u53ca\u89e3\u51b3\u7b56\u7565\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u3002\u540c\u65f6\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u89c6\u5316\u4f18\u5148\u7ea7\u6846\u67b6\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u5171\u60c5\u5b9e\u8df5\u5efa\u8bae\uff0c\u5e76\u901a\u8fc7\u6846\u67b6\u5e2e\u52a9\u56e2\u961f\u6839\u636e\u91cd\u8981\u6027\u3001\u6613\u5b9e\u65bd\u6027\u548c\u91c7\u7eb3\u610f\u613f\u5206\u7c7b\u6307\u5357\u3002", "conclusion": "\u672c\u6587\u7684\u6307\u5357\u548c\u6846\u67b6\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5171\u60c5\u5b9e\u8df5\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u4ece\u7406\u8bba\u5230\u53ef\u6301\u7eed\u884c\u52a8\u7684\u8f6c\u53d8\u3002"}}
{"id": "2508.03856", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.03856", "abs": "https://arxiv.org/abs/2508.03856", "authors": ["Richard Hegewald", "Rebecca Beyer"], "title": "Evaluating Software Supply Chain Security in Research Software", "comment": "Accepted at conference GI SKILL 2025", "summary": "The security of research software is essential for ensuring the integrity and\nreproducibility of scientific results. However, research software security is\nstill largely unexplored. Due to its dependence on open source components and\ndistributed development practices, research software is particularly vulnerable\nto supply chain attacks. This study analyses 3,248 high-quality, largely\npeer-reviewed research software repositories using the OpenSSF Scorecard. We\nfind a generally weak security posture with an average score of 3.5/10.\nImportant practices, such as signed releases and branch protection, are rarely\nimplemented. Finally, we present actionable, low-effort recommendations that\ncan help research teams improve software security and mitigate potential\nthreats to scientific integrity.", "AI": {"tldr": "\u7814\u7a76\u8f6f\u4ef6\u5b89\u5168\u6027\u666e\u904d\u8f83\u5dee\uff0c\u5e73\u5747\u5f97\u52063.5/10\uff0c\u9700\u6539\u8fdb\u7b7e\u540d\u53d1\u5e03\u548c\u5206\u652f\u4fdd\u62a4\u7b49\u5b9e\u8df5\u3002", "motivation": "\u7814\u7a76\u8f6f\u4ef6\u7684\u5b89\u5168\u6027\u5bf9\u79d1\u5b66\u7ed3\u679c\u7684\u5b8c\u6574\u6027\u548c\u53ef\u91cd\u590d\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8be5\u9886\u57df\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u7528OpenSSF Scorecard\u5206\u6790\u4e863,248\u4e2a\u9ad8\u8d28\u91cf\u3001\u7ecf\u8fc7\u540c\u884c\u8bc4\u5ba1\u7684\u7814\u7a76\u8f6f\u4ef6\u4ed3\u5e93\u3002", "result": "\u53d1\u73b0\u7814\u7a76\u8f6f\u4ef6\u5b89\u5168\u6027\u666e\u904d\u8f83\u5f31\uff0c\u91cd\u8981\u5b9e\u8df5\u5982\u7b7e\u540d\u53d1\u5e03\u548c\u5206\u652f\u4fdd\u62a4\u5f88\u5c11\u5b9e\u65bd\u3002", "conclusion": "\u63d0\u51fa\u4e86\u53ef\u64cd\u4f5c\u7684\u4f4e\u6210\u672c\u5efa\u8bae\uff0c\u5e2e\u52a9\u7814\u7a76\u56e2\u961f\u63d0\u5347\u8f6f\u4ef6\u5b89\u5168\u6027\uff0c\u51cf\u5c11\u5bf9\u79d1\u5b66\u5b8c\u6574\u6027\u7684\u6f5c\u5728\u5a01\u80c1\u3002"}}
{"id": "2508.03881", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03881", "abs": "https://arxiv.org/abs/2508.03881", "authors": ["Martin Obaidi", "Kushtrim Qengaj", "Jakob Droste", "Hannah Deters", "Marc Herrmann", "Jil Kl\u00fcnder", "Elisa Schmid", "Kurt Schneider"], "title": "From App Features to Explanation Needs: Analyzing Correlations and Predictive Potential", "comment": "This paper has been accepted at the 33rd IEEE International\n  Requirements Engineering Workshop (REW 2025)", "summary": "In today's digitized world, software systems must support users in\nunderstanding both how to interact with a system and why certain behaviors\noccur. This study investigates whether explanation needs, classified from user\nreviews, can be predicted based on app properties, enabling early consideration\nduring development and large-scale requirements mining. We analyzed a gold\nstandard dataset of 4,495 app reviews enriched with metadata (e.g., app\nversion, ratings, age restriction, in-app purchases). Correlation analyses\nidentified mostly weak associations between app properties and explanation\nneeds, with moderate correlations only for specific features such as app\nversion, number of reviews, and star ratings. Linear regression models showed\nlimited predictive power, with no reliable forecasts across configurations.\nValidation on a manually labeled dataset of 495 reviews confirmed these\nfindings. Categories such as Security & Privacy and System Behavior showed\nslightly higher predictive potential, while Interaction and User Interface\nremained most difficult to predict. Overall, our results highlight that\nexplanation needs are highly context-dependent and cannot be precisely inferred\nfrom app metadata alone. Developers and requirements engineers should therefore\nsupplement metadata analysis with direct user feedback to effectively design\nexplainable and user-centered software systems.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u7528\u6237\u5bf9\u8f6f\u4ef6\u7cfb\u7edf\u7684\u89e3\u91ca\u9700\u6c42\u96be\u4ee5\u901a\u8fc7\u5e94\u7528\u5c5e\u6027\uff08\u5982\u7248\u672c\u3001\u8bc4\u5206\u7b49\uff09\u51c6\u786e\u9884\u6d4b\uff0c\u9700\u7ed3\u5408\u76f4\u63a5\u7528\u6237\u53cd\u9988\u3002", "motivation": "\u63a2\u8ba8\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u5e94\u7528\u5c5e\u6027\u9884\u6d4b\u7528\u6237\u5bf9\u89e3\u91ca\u7684\u9700\u6c42\uff0c\u4ee5\u652f\u6301\u5f00\u53d1\u548c\u5927\u89c4\u6a21\u9700\u6c42\u6316\u6398\u3002", "method": "\u5206\u6790\u4e864,495\u6761\u5e94\u7528\u8bc4\u8bba\u7684\u9ec4\u91d1\u6807\u51c6\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u76f8\u5173\u6027\u5206\u6790\u548c\u7ebf\u6027\u56de\u5f52\u5efa\u6a21\uff0c\u5e76\u5728495\u6761\u624b\u52a8\u6807\u6ce8\u7684\u8bc4\u8bba\u4e0a\u9a8c\u8bc1\u3002", "result": "\u5e94\u7528\u5c5e\u6027\u4e0e\u89e3\u91ca\u9700\u6c42\u7684\u5173\u8054\u8f83\u5f31\uff0c\u4ec5\u7279\u5b9a\u7279\u5f81\uff08\u5982\u7248\u672c\u3001\u8bc4\u8bba\u6570\u91cf\u3001\u8bc4\u5206\uff09\u6709\u4e2d\u7b49\u76f8\u5173\u6027\uff0c\u9884\u6d4b\u6a21\u578b\u6548\u679c\u6709\u9650\u3002", "conclusion": "\u89e3\u91ca\u9700\u6c42\u9ad8\u5ea6\u4f9d\u8d56\u4e0a\u4e0b\u6587\uff0c\u4ec5\u9760\u5143\u6570\u636e\u65e0\u6cd5\u7cbe\u786e\u63a8\u65ad\uff0c\u9700\u7ed3\u5408\u7528\u6237\u53cd\u9988\u8bbe\u8ba1\u7528\u6237\u4e2d\u5fc3\u7684\u8f6f\u4ef6\u7cfb\u7edf\u3002"}}
{"id": "2508.03922", "categories": ["cs.SE", "cs.HC", "D.2.1"], "pdf": "https://arxiv.org/pdf/2508.03922", "abs": "https://arxiv.org/abs/2508.03922", "authors": ["Soroush Heydari"], "title": "A Human Centric Requirements Engineering Framework for Assessing Github Copilot Output", "comment": "8 pages", "summary": "The rapid adoption of Artificial Intelligence(AI) programming assistants such\nas GitHub Copilot introduces new challenges in how these software tools address\nhuman needs. Many existing evaluation frameworks address technical aspects such\nas code correctness and efficiency, but often overlook crucial human factors\nthat affect the successful integration of AI assistants in software development\nworkflows. In this study, I analyzed GitHub Copilot's interaction with users\nthrough its chat interface, measured Copilot's ability to adapt explanations\nand code generation to user expertise levels, and assessed its effectiveness in\nfacilitating collaborative programming experiences. I established a\nhuman-centered requirements framework with clear metrics to evaluate these\nqualities in GitHub Copilot chat. I discussed the test results and their\nimplications for future analysis of human requirements in automated\nprogramming.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86GitHub Copilot\u5982\u4f55\u901a\u8fc7\u804a\u5929\u754c\u9762\u4e0e\u7528\u6237\u4e92\u52a8\uff0c\u8bc4\u4f30\u5176\u9002\u5e94\u4e0d\u540c\u7528\u6237\u4e13\u4e1a\u6c34\u5e73\u7684\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u9700\u6c42\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u591a\u5173\u6ce8\u6280\u672f\u5c42\u9762\uff0c\u5ffd\u89c6\u4e86\u5f71\u54cdAI\u52a9\u624b\u6210\u529f\u6574\u5408\u5230\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\u7684\u4eba\u4e3a\u56e0\u7d20\u3002", "method": "\u901a\u8fc7\u5206\u6790GitHub Copilot\u7684\u804a\u5929\u754c\u9762\u4e92\u52a8\uff0c\u6d4b\u91cf\u5176\u9002\u5e94\u4e0d\u540c\u7528\u6237\u4e13\u4e1a\u6c34\u5e73\u7684\u80fd\u529b\uff0c\u5e76\u8bc4\u4f30\u5176\u5728\u534f\u4f5c\u7f16\u7a0b\u4e2d\u7684\u6548\u679c\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u9700\u6c42\u6846\u67b6\uff0c\u5e76\u8ba8\u8bba\u4e86\u6d4b\u8bd5\u7ed3\u679c\u53ca\u5176\u5bf9\u672a\u6765\u81ea\u52a8\u5316\u7f16\u7a0b\u4e2d\u4eba\u7c7b\u9700\u6c42\u5206\u6790\u7684\u542f\u793a\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728AI\u7f16\u7a0b\u52a9\u624b\u4e2d\u8003\u8651\u4eba\u4e3a\u56e0\u7d20\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.03696", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.03696", "abs": "https://arxiv.org/abs/2508.03696", "authors": ["Xinqi Lyu", "Yihao Liu", "Yanjie Li", "Bin Xiao"], "title": "PLA: Prompt Learning Attack against Text-to-Image Generative Models", "comment": "10 pages, 3 figures, and published to ICCV2025", "summary": "Text-to-Image (T2I) models have gained widespread adoption across various\napplications. Despite the success, the potential misuse of T2I models poses\nsignificant risks of generating Not-Safe-For-Work (NSFW) content. To\ninvestigate the vulnerability of T2I models, this paper delves into adversarial\nattacks to bypass the safety mechanisms under black-box settings. Most previous\nmethods rely on word substitution to search adversarial prompts. Due to limited\nsearch space, this leads to suboptimal performance compared to gradient-based\ntraining. However, black-box settings present unique challenges to training\ngradient-driven attack methods, since there is no access to the internal\narchitecture and parameters of T2I models. To facilitate the learning of\nadversarial prompts in black-box settings, we propose a novel prompt learning\nattack framework (PLA), where insightful gradient-based training tailored to\nblack-box T2I models is designed by utilizing multimodal similarities.\nExperiments show that our new method can effectively attack the safety\nmechanisms of black-box T2I models including prompt filters and post-hoc safety\ncheckers with a high success rate compared to state-of-the-art methods.\nWarning: This paper may contain offensive model-generated content.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u63d0\u793a\u5b66\u4e60\u653b\u51fb\u6846\u67b6\uff08PLA\uff09\uff0c\u7528\u4e8e\u5728\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u7ed5\u8fc7\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u6a21\u578b\u7684\u5b89\u5168\u673a\u5236\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u76f8\u4f3c\u6027\u8bbe\u8ba1\u68af\u5ea6\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u653b\u51fb\u6210\u529f\u7387\u9ad8\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1T2I\u6a21\u578b\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u53ef\u80fd\u88ab\u6ee5\u7528\u4ee5\u751f\u6210\u4e0d\u5b89\u5168\u5185\u5bb9\uff08NSFW\uff09\u3002\u73b0\u6709\u65b9\u6cd5\u56e0\u641c\u7d22\u7a7a\u95f4\u6709\u9650\u800c\u6027\u80fd\u4e0d\u8db3\uff0c\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u68af\u5ea6\u9a71\u52a8\u653b\u51fb\u65b9\u6cd5\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "\u63d0\u51faPLA\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u76f8\u4f3c\u6027\u8bbe\u8ba1\u9ed1\u76d2T2I\u6a21\u578b\u7684\u68af\u5ea6\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5b66\u4e60\u5bf9\u6297\u6027\u63d0\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPLA\u80fd\u9ad8\u6548\u653b\u51fb\u9ed1\u76d2T2I\u6a21\u578b\u7684\u5b89\u5168\u673a\u5236\uff08\u5982\u63d0\u793a\u8fc7\u6ee4\u5668\u548c\u540e\u9a8c\u5b89\u5168\u68c0\u67e5\u5668\uff09\uff0c\u6210\u529f\u7387\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "PLA\u4e3a\u9ed1\u76d2T2I\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5c55\u793a\u4e86\u5bf9\u6297\u6027\u653b\u51fb\u7684\u6f5c\u5728\u98ce\u9669\u3002"}}
{"id": "2508.03858", "categories": ["cs.AI", "cs.ET", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.03858", "abs": "https://arxiv.org/abs/2508.03858", "authors": ["Charles L. Wang", "Trisha Singhal", "Ameya Kelkar", "Jason Tuo"], "title": "MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems", "comment": null, "summary": "Agentic AI systems capable of reasoning, planning, and executing actions\npresent fundamentally distinct governance challenges compared to traditional AI\nmodels. Unlike conventional AI, these systems exhibit emergent and unexpected\nbehaviors during runtime, introducing novel agent-related risks that cannot be\nfully anticipated through pre-deployment governance alone. To address this\ncritical gap, we introduce MI9, the first fully integrated runtime governance\nframework designed specifically for safety and alignment of agentic AI systems.\nMI9 introduces real-time controls through six integrated components:\nagency-risk index, agent-semantic telemetry capture, continuous authorization\nmonitoring, Finite-State-Machine (FSM)-based conformance engines,\ngoal-conditioned drift detection, and graduated containment strategies.\nOperating transparently across heterogeneous agent architectures, MI9 enables\nthe systematic, safe, and responsible deployment of agentic systems in\nproduction environments where conventional governance approaches fall short,\nproviding the foundational infrastructure for safe agentic AI deployment at\nscale. Detailed analysis through a diverse set of scenarios demonstrates MI9's\nsystematic coverage of governance challenges that existing approaches fail to\naddress, establishing the technical foundation for comprehensive agentic AI\noversight.", "AI": {"tldr": "MI9\u662f\u4e00\u4e2a\u4e13\u4e3a\u4ee3\u7406\u578bAI\u7cfb\u7edf\u8bbe\u8ba1\u7684\u8fd0\u884c\u65f6\u6cbb\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u516d\u4e2a\u7ec4\u4ef6\u5b9e\u65f6\u63a7\u5236\u98ce\u9669\u548c\u786e\u4fdd\u5b89\u5168\u3002", "motivation": "\u4ee3\u7406\u578bAI\u7cfb\u7edf\u5728\u8fd0\u884c\u65f6\u8868\u73b0\u51fa\u4e0d\u53ef\u9884\u6d4b\u7684\u884c\u4e3a\uff0c\u4f20\u7edf\u6cbb\u7406\u65b9\u6cd5\u65e0\u6cd5\u5b8c\u5168\u5e94\u5bf9\u8fd9\u4e9b\u98ce\u9669\u3002", "method": "MI9\u6846\u67b6\u5305\u62ec\u4ee3\u7406\u98ce\u9669\u6307\u6570\u3001\u8bed\u4e49\u9065\u6d4b\u6355\u83b7\u3001\u6301\u7eed\u6388\u6743\u76d1\u63a7\u3001FSM\u4e00\u81f4\u6027\u5f15\u64ce\u3001\u76ee\u6807\u6761\u4ef6\u6f02\u79fb\u68c0\u6d4b\u548c\u5206\u7ea7\u904f\u5236\u7b56\u7565\u3002", "result": "MI9\u5728\u591a\u6837\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u7cfb\u7edf\u6027\u6cbb\u7406\u80fd\u529b\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "conclusion": "MI9\u4e3a\u4ee3\u7406\u578bAI\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5e94\u7528\u3002"}}
{"id": "2508.03931", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03931", "abs": "https://arxiv.org/abs/2508.03931", "authors": ["Everton Guimaraes", "Nathalia Nascimento", "Chandan Shivalingaiah", "Asish Nelapati"], "title": "Analyzing Prominent LLMs: An Empirical Study of Performance and Complexity in Solving LeetCode Problems", "comment": "11 pages, 13 figures, 29th International Conference on Evaluation and\n  Assessment in Software Engineering (EASE)", "summary": "Large Language Models (LLMs) like ChatGPT, Copilot, Gemini, and DeepSeek are\ntransforming software engineering by automating key tasks, including code\ngeneration, testing, and debugging. As these models become integral to\ndevelopment workflows, a systematic comparison of their performance is\nessential for optimizing their use in real world applications. This study\nbenchmarks these four prominent LLMs on one hundred and fifty LeetCode problems\nacross easy, medium, and hard difficulties, generating solutions in Java and\nPython. We evaluate each model based on execution time, memory usage, and\nalgorithmic complexity, revealing significant performance differences. ChatGPT\ndemonstrates consistent efficiency in execution time and memory usage, while\nCopilot and DeepSeek show variability as task complexity increases. Gemini,\nalthough effective on simpler tasks, requires more attempts as problem\ndifficulty rises. Our findings provide actionable insights into each model's\nstrengths and limitations, offering guidance for developers selecting LLMs for\nspecific coding tasks and providing insights on the performance and complexity\nof GPT-like generated solutions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9\u56db\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08ChatGPT\u3001Copilot\u3001Gemini\u548cDeepSeek\uff09\u5728150\u9053LeetCode\u9898\u76ee\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u7cfb\u7edf\u6bd4\u8f83\uff0c\u8bc4\u4f30\u4e86\u6267\u884c\u65f6\u95f4\u3001\u5185\u5b58\u4f7f\u7528\u548c\u7b97\u6cd5\u590d\u6742\u5ea6\u3002", "motivation": "\u968f\u7740LLMs\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bf9\u5176\u6027\u80fd\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\u4ee5\u4f18\u5316\u5b9e\u9645\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u751f\u6210Java\u548cPython\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728150\u9053LeetCode\u9898\u76ee\uff08\u5206\u7b80\u5355\u3001\u4e2d\u7b49\u548c\u56f0\u96be\u96be\u5ea6\uff09\u4e0a\u5bf9\u56db\u79cd\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "ChatGPT\u5728\u6267\u884c\u65f6\u95f4\u548c\u5185\u5b58\u4f7f\u7528\u4e0a\u8868\u73b0\u4e00\u81f4\u9ad8\u6548\uff0cCopilot\u548cDeepSeek\u5728\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u8868\u73b0\u4e0d\u7a33\u5b9a\uff0cGemini\u5728\u7b80\u5355\u4efb\u52a1\u4e0a\u6709\u6548\u4f46\u96be\u5ea6\u589e\u52a0\u65f6\u9700\u8981\u66f4\u591a\u5c1d\u8bd5\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5f00\u53d1\u8005\u9009\u62e9\u9002\u5408\u7279\u5b9a\u7f16\u7801\u4efb\u52a1\u7684LLM\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u5e76\u63ed\u793a\u4e86GPT\u7c7b\u751f\u6210\u89e3\u51b3\u65b9\u6848\u7684\u6027\u80fd\u548c\u590d\u6742\u6027\u3002"}}
{"id": "2508.03879", "categories": ["cs.CR", "cs.OS", "D.4.6; K.6.5; C.2.0"], "pdf": "https://arxiv.org/pdf/2508.03879", "abs": "https://arxiv.org/abs/2508.03879", "authors": ["Arjun Juneja"], "title": "RX-INT: A Kernel Engine for Real-Time Detection and Analysis of In-Memory Threats", "comment": "10 pages, 8 figures, 1 table. Presents RX-INT, a kernel-mode system\n  for real-time detection of fileless malware using event-driven VAD scanning\n  and automated import resolution. Demonstrates superior detection capabilities\n  against PE-sieve on advanced evasion techniques including module stomping and\n  headerless manual mapping", "summary": "Malware and cheat developers use fileless execution techniques to evade\ntraditional, signature-based security products. These methods include various\ntypes of manual mapping, module stomping, and threadless injection which work\nentirely within the address space of a legitimate process, presenting a\nchallenge for detection due to ambiguity between what is legitimate and what\nisn't. Existing tools often have weaknesses, such as a dependency on Portable\nExecutable (PE) structures or a vulnerability to time-of-check-to-time-of-use\n(TOCTOU) race conditions where an adversary cleans up before a periodic scan\nhas the chance to occur. To address this gap, we present RX-INT, a\nkernel-assisted system featuring an architecture that provides resilience\nagainst TOCTOU attacks. RX-INT introduces a detection engine that combines a\nreal-time thread creation monitor with a stateful Virtual Address Descriptor\n(VAD) scanner alongside various heuristics within. This engine snapshots both\nprivate and image-backed memory regions, using real-time memory hashing to\ndetect illicit modifications like module stomping. Critically, we demonstrate a\nhigher detection rate in certain benchmarks of this approach through a direct\ncomparison with PE-sieve, a commonly used and powerful memory forensics tool.\nIn our evaluation, RX-INT successfully detected a manually mapped region that\nwas not identified by PE-sieve. We then conclude that our architecture\nrepresents a tangible difference in the detection of fileless threats, with\ndirect applications in the fields of anti-cheat and memory security.", "AI": {"tldr": "RX-INT\u662f\u4e00\u79cd\u5185\u6838\u8f85\u52a9\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b9e\u65f6\u7ebf\u7a0b\u521b\u5efa\u76d1\u63a7\u548c\u72b6\u6001\u5316VAD\u626b\u63cf\u5668\uff0c\u7ed3\u5408\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u5bf9\u65e0\u6587\u4ef6\u6076\u610f\u8f6f\u4ef6\u7684\u68c0\u6d4b\u7387\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u7b7e\u540d\u7684\u5b89\u5168\u4ea7\u54c1\u96be\u4ee5\u68c0\u6d4b\u65e0\u6587\u4ef6\u6267\u884c\u6280\u672f\uff08\u5982\u624b\u52a8\u6620\u5c04\u3001\u6a21\u5757\u8986\u76d6\u7b49\uff09\uff0c\u73b0\u6709\u5de5\u5177\u4f9d\u8d56PE\u7ed3\u6784\u6216\u6613\u53d7TOCTOU\u653b\u51fb\u3002", "method": "RX-INT\u91c7\u7528\u5b9e\u65f6\u7ebf\u7a0b\u521b\u5efa\u76d1\u63a7\u3001\u72b6\u6001\u5316VAD\u626b\u63cf\u5668\u548c\u5185\u5b58\u54c8\u5e0c\u6280\u672f\uff0c\u5feb\u7167\u79c1\u6709\u548c\u955c\u50cf\u5185\u5b58\u533a\u57df\u4ee5\u68c0\u6d4b\u975e\u6cd5\u4fee\u6539\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRX-INT\u68c0\u6d4b\u7387\u9ad8\u4e8ePE-sieve\uff0c\u6210\u529f\u8bc6\u522b\u4e86\u540e\u8005\u672a\u68c0\u6d4b\u5230\u7684\u624b\u52a8\u6620\u5c04\u533a\u57df\u3002", "conclusion": "RX-INT\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u65e0\u6587\u4ef6\u5a01\u80c1\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u53cd\u4f5c\u5f0a\u548c\u5185\u5b58\u5b89\u5168\u9886\u57df\u3002"}}
{"id": "2508.03864", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03864", "abs": "https://arxiv.org/abs/2508.03864", "authors": ["Zhenyu Pan", "Yiting Zhang", "Yutong Zhang", "Jianshu Zhang", "Haozheng Luo", "Yuwei Han", "Dennis Wu", "Hong-Yu Chen", "Philip S. Yu", "Manling Li", "Han Liu"], "title": "Evo-MARL: Co-Evolutionary Multi-Agent Reinforcement Learning for Internalized Safety", "comment": null, "summary": "Multi-agent systems (MAS) built on multimodal large language models exhibit\nstrong collaboration and performance. However, their growing openness and\ninteraction complexity pose serious risks, notably jailbreak and adversarial\nattacks. Existing defenses typically rely on external guard modules, such as\ndedicated safety agents, to handle unsafe behaviors. Unfortunately, this\nparadigm faces two challenges: (1) standalone agents offer limited protection,\nand (2) their independence leads to single-point failure-if compromised,\nsystem-wide safety collapses. Naively increasing the number of guard agents\nfurther raises cost and complexity. To address these challenges, we propose\nEvo-MARL, a novel multi-agent reinforcement learning (MARL) framework that\nenables all task agents to jointly acquire defensive capabilities. Rather than\nrelying on external safety modules, Evo-MARL trains each agent to\nsimultaneously perform its primary function and resist adversarial threats,\nensuring robustness without increasing system overhead or single-node failure.\nFurthermore, Evo-MARL integrates evolutionary search with parameter-sharing\nreinforcement learning to co-evolve attackers and defenders. This adversarial\ntraining paradigm internalizes safety mechanisms and continually enhances MAS\nperformance under co-evolving threats. Experiments show that Evo-MARL reduces\nattack success rates by up to 22% while boosting accuracy by up to 5% on\nreasoning tasks-demonstrating that safety and utility can be jointly improved.", "AI": {"tldr": "Evo-MARL \u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u4efb\u52a1\u667a\u80fd\u4f53\u83b7\u5f97\u9632\u5fa1\u80fd\u529b\uff0c\u907f\u514d\u5916\u90e8\u9632\u62a4\u6a21\u5757\u7684\u4f9d\u8d56\u548c\u5355\u70b9\u6545\u969c\u95ee\u9898\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5728\u5f00\u653e\u6027\u548c\u4ea4\u4e92\u590d\u6742\u6027\u589e\u52a0\u65f6\u9762\u4e34\u5b89\u5168\u98ce\u9669\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u9632\u62a4\u6a21\u5757\uff0c\u5b58\u5728\u5355\u70b9\u6545\u969c\u548c\u6210\u672c\u95ee\u9898\u3002", "method": "\u63d0\u51fa Evo-MARL \u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u8bad\u7ec3\u4efb\u52a1\u667a\u80fd\u4f53\u540c\u65f6\u6267\u884c\u4e3b\u529f\u80fd\u548c\u9632\u5fa1\u4efb\u52a1\uff0c\u7ed3\u5408\u8fdb\u5316\u641c\u7d22\u548c\u53c2\u6570\u5171\u4eab\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u663e\u793a Evo-MARL \u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e 22%\uff0c\u63a8\u7406\u4efb\u52a1\u51c6\u786e\u7387\u63d0\u5347 5%\uff0c\u5b89\u5168\u6027\u548c\u6027\u80fd\u540c\u65f6\u63d0\u9ad8\u3002", "conclusion": "Evo-MARL \u901a\u8fc7\u5185\u90e8\u5316\u5b89\u5168\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u4e0e\u6548\u7528\u7684\u534f\u540c\u63d0\u5347\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u9632\u5fa1\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.03949", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03949", "abs": "https://arxiv.org/abs/2508.03949", "authors": ["Md. Abdul Awal", "Mrigank Rochan", "Chanchal K. Roy"], "title": "Model Compression vs. Adversarial Robustness: An Empirical Study on Language Models for Code", "comment": null, "summary": "Transformer-based language models for code have shown remarkable performance\nin various software analytics tasks, but their adoption is hindered by high\ncomputational costs, slow inference speeds, and substantial environmental\nimpact. Model compression techniques such as pruning, quantization, and\nknowledge distillation have gained traction in addressing these challenges.\nHowever, the impact of these strategies on the robustness of compressed\nlanguage models for code in adversarial scenarios remains poorly understood.\nUnderstanding how these compressed models behave under adversarial attacks is\nessential for their safe and effective deployment in real-world applications.\nTo bridge this knowledge gap, we conduct a comprehensive evaluation of how\ncommon compression strategies affect the adversarial robustness of compressed\nmodels. We assess the robustness of compressed versions of three widely used\nlanguage models for code across three software analytics tasks, using six\nevaluation metrics and four commonly used classical adversarial attacks. Our\nfindings indicate that compressed models generally maintain comparable\nperformance to their uncompressed counterparts. However, when subjected to\nadversarial attacks, compressed models exhibit significantly reduced\nrobustness. These results reveal a trade-off between model size reduction and\nadversarial robustness, underscoring the need for careful consideration when\ndeploying compressed models in security-critical software applications. Our\nstudy highlights the need for further research into compression strategies that\nstrike a balance between computational efficiency and adversarial robustness,\nwhich is essential for deploying reliable language models for code in\nreal-world software applications.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u538b\u7f29\u6280\u672f\uff08\u5982\u526a\u679d\u3001\u91cf\u5316\u548c\u77e5\u8bc6\u84b8\u998f\uff09\u5728\u5bf9\u6297\u6027\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u538b\u7f29\u6a21\u578b\u6027\u80fd\u63a5\u8fd1\u539f\u59cb\u6a21\u578b\uff0c\u4f46\u5bf9\u6297\u6027\u9c81\u68d2\u6027\u663e\u8457\u964d\u4f4e\u3002", "motivation": "Transformer-based\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u73af\u5883\u5f71\u54cd\u963b\u788d\u4e86\u5176\u5e94\u7528\uff0c\u538b\u7f29\u6280\u672f\u867d\u80fd\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u5176\u5728\u5bf9\u6297\u6027\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u5bf9\u4e09\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u538b\u7f29\uff0c\u5e76\u5728\u4e09\u4e2a\u8f6f\u4ef6\u5206\u6790\u4efb\u52a1\u4e2d\u8bc4\u4f30\u5176\u5bf9\u6297\u6027\u9c81\u68d2\u6027\uff0c\u4f7f\u7528\u516d\u79cd\u8bc4\u4f30\u6307\u6807\u548c\u56db\u79cd\u7ecf\u5178\u5bf9\u6297\u653b\u51fb\u3002", "result": "\u538b\u7f29\u6a21\u578b\u6027\u80fd\u4e0e\u539f\u59cb\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u5728\u5bf9\u6297\u6027\u653b\u51fb\u4e0b\u9c81\u68d2\u6027\u663e\u8457\u964d\u4f4e\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5927\u5c0f\u4e0e\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5e73\u8861\u8ba1\u7b97\u6548\u7387\u4e0e\u5bf9\u6297\u6027\u9c81\u68d2\u6027\u7684\u538b\u7f29\u7b56\u7565\uff0c\u4ee5\u786e\u4fdd\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u90e8\u7f72\u3002"}}
{"id": "2508.03882", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03882", "abs": "https://arxiv.org/abs/2508.03882", "authors": ["Arturo S\u00e1nchez-Matas", "Pablo Escribano Ruiz", "Daniel D\u00edaz-L\u00f3pez", "Angel Luis Perales G\u00f3mez", "Pantaleone Nespoli", "Gregorio Mart\u00ednez P\u00e9rez"], "title": "Simulating Cyberattacks through a Breach Attack Simulation (BAS) Platform empowered by Security Chaos Engineering (SCE)", "comment": "8 pages, 4 figures, paper in proceedings of the \"X Jornadas\n  Nacionales de Investigaci\\'on en Ciberseguridad\" in Zaragoza, Spain, June,\n  2025", "summary": "In today digital landscape, organizations face constantly evolving cyber\nthreats, making it essential to discover slippery attack vectors through novel\ntechniques like Security Chaos Engineering (SCE), which allows teams to test\ndefenses and identify vulnerabilities effectively. This paper proposes to\nintegrate SCE into Breach Attack Simulation (BAS) platforms, leveraging\nadversary profiles and abilities from existing threat intelligence databases.\nThis innovative proposal for cyberattack simulation employs a structured\narchitecture composed of three layers: SCE Orchestrator, Connector, and BAS\nlayers. Utilizing MITRE Caldera in the BAS layer, our proposal executes\nautomated attack sequences, creating inferred attack trees from adversary\nprofiles. Our proposal evaluation illustrates how integrating SCE with BAS can\nenhance the effectiveness of attack simulations beyond traditional scenarios,\nand be a useful component of a cyber defense strategy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06\u5b89\u5168\u6df7\u6c8c\u5de5\u7a0b\uff08SCE\uff09\u6574\u5408\u5230\u6f0f\u6d1e\u653b\u51fb\u6a21\u62df\uff08BAS\uff09\u5e73\u53f0\u4e2d\uff0c\u901a\u8fc7\u4e09\u5c42\u67b6\u6784\uff08SCE Orchestrator\u3001Connector\u548cBAS\u5c42\uff09\u548cMITRE Caldera\u5de5\u5177\uff0c\u63d0\u5347\u653b\u51fb\u6a21\u62df\u6548\u679c\u3002", "motivation": "\u9762\u5bf9\u4e0d\u65ad\u6f14\u53d8\u7684\u7f51\u7edc\u5a01\u80c1\uff0c\u7ec4\u7ec7\u9700\u8981\u53d1\u73b0\u9690\u853d\u7684\u653b\u51fb\u9014\u5f84\uff0cSCE\u63d0\u4f9b\u4e86\u4e00\u79cd\u6d4b\u8bd5\u9632\u5fa1\u548c\u8bc6\u522b\u6f0f\u6d1e\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e09\u5c42\u67b6\u6784\u6574\u5408SCE\u4e0eBAS\uff0c\u5229\u7528MITRE Caldera\u6267\u884c\u81ea\u52a8\u5316\u653b\u51fb\u5e8f\u5217\uff0c\u751f\u6210\u653b\u51fb\u6811\u3002", "result": "\u8bc4\u4f30\u8868\u660e\uff0cSCE\u4e0eBAS\u7684\u6574\u5408\u80fd\u8d85\u8d8a\u4f20\u7edf\u653b\u51fb\u6a21\u62df\u573a\u666f\uff0c\u63d0\u5347\u9632\u5fa1\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "conclusion": "SCE\u4e0eBAS\u7684\u6574\u5408\u662f\u7f51\u7edc\u5b89\u5168\u9632\u5fa1\u7b56\u7565\u4e2d\u7684\u6709\u7528\u7ec4\u4ef6\u3002"}}
{"id": "2508.03929", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03929", "abs": "https://arxiv.org/abs/2508.03929", "authors": ["Nguyen Viet Tuan Kiet", "Dao Van Tung", "Tran Cong Dao", "Huynh Thi Thanh Binh"], "title": "MOTIF: Multi-strategy Optimization via Turn-based Interactive Framework", "comment": "24 pages, 4 figures", "summary": "Designing effective algorithmic components remains a fundamental obstacle in\ntackling NP-hard combinatorial optimization problems (COPs), where solvers\noften rely on carefully hand-crafted strategies. Despite recent advances in\nusing large language models (LLMs) to synthesize high-quality components, most\napproaches restrict the search to a single element - commonly a heuristic\nscoring function - thus missing broader opportunities for innovation. In this\npaper, we introduce a broader formulation of solver design as a multi-strategy\noptimization problem, which seeks to jointly improve a set of interdependent\ncomponents under a unified objective. To address this, we propose\nMulti-strategy Optimization via Turn-based Interactive Framework (MOTIF) - a\nnovel framework based on Monte Carlo Tree Search that facilitates turn-based\noptimization between two LLM agents. At each turn, an agent improves one\ncomponent by leveraging the history of both its own and its opponent's prior\nupdates, promoting both competitive pressure and emergent cooperation. This\nstructured interaction broadens the search landscape and encourages the\ndiscovery of diverse, high-performing solutions. Experiments across multiple\nCOP domains show that MOTIF consistently outperforms state-of-the-art methods,\nhighlighting the promise of turn-based, multi-agent prompting for fully\nautomated solver design.", "AI": {"tldr": "MOTIF\u6846\u67b6\u901a\u8fc7\u591a\u7b56\u7565\u4f18\u5316\u548c\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u4ea4\u4e92\u5f0f\u6846\u67b6\uff0c\u8054\u5408\u4f18\u5316\u591a\u4e2a\u7ec4\u4ef6\uff0c\u663e\u8457\u63d0\u5347\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u6c42\u89e3\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4ec5\u4f18\u5316\u5355\u4e00\u7ec4\u4ef6\uff08\u5982\u542f\u53d1\u5f0f\u8bc4\u5206\u51fd\u6570\uff09\uff0c\u5ffd\u89c6\u4e86\u591a\u7ec4\u4ef6\u534f\u540c\u4f18\u5316\u7684\u6f5c\u529b\uff0c\u9650\u5236\u4e86\u521b\u65b0\u7a7a\u95f4\u3002", "method": "\u63d0\u51faMOTIF\u6846\u67b6\uff0c\u5229\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u5b9e\u73b0\u4e24\u4e2aLLM\u4ee3\u7406\u7684\u8f6e\u6362\u4f18\u5316\uff0c\u901a\u8fc7\u7ade\u4e89\u4e0e\u5408\u4f5c\u4fc3\u8fdb\u591a\u6837\u9ad8\u6027\u80fd\u89e3\u3002", "result": "\u5728\u591a\u4e2aCOP\u9886\u57df\u7684\u5b9e\u9a8c\u4e2d\uff0cMOTIF\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002", "conclusion": "MOTIF\u5c55\u793a\u4e86\u8f6e\u6362\u591a\u4ee3\u7406\u63d0\u793a\u5728\u81ea\u52a8\u5316\u6c42\u89e3\u5668\u8bbe\u8ba1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.04125", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04125", "abs": "https://arxiv.org/abs/2508.04125", "authors": ["Sangwon Hyun", "Hyunjun Kim", "Jinhyuk Jang", "Hyojin Choi", "M. Ali Babar"], "title": "Experimental Analysis of Productive Interaction Strategy with ChatGPT: User Study on Function and Project-level Code Generation Tasks", "comment": "The benchmark repository has not been publicly released yet due to\n  the IP policy in our institutions. If you would like to use the benchmark or\n  collaborate on extension, please contact \"dr.sangwon.hyun@gmail.com\"", "summary": "The application of Large Language Models (LLMs) is growing in the productive\ncompletion of Software Engineering tasks. Yet, studies investigating the\nproductive prompting techniques often employed a limited problem space,\nprimarily focusing on well-known prompting patterns and mainly targeting\nfunction-level SE practices. We identify significant gaps in real-world\nworkflows that involve complexities beyond class-level (e.g., multi-class\ndependencies) and different features that can impact Human-LLM Interactions\n(HLIs) processes in code generation. To address these issues, we designed an\nexperiment that comprehensively analyzed the HLI features regarding the code\ngeneration productivity. Our study presents two project-level benchmark tasks,\nextending beyond function-level evaluations. We conducted a user study with 36\nparticipants from diverse backgrounds, asking them to solve the assigned tasks\nby interacting with the GPT assistant using specific prompting patterns. We\nalso examined the participants' experience and their behavioral features during\ninteractions by analyzing screen recordings and GPT chat logs. Our statistical\nand empirical investigation revealed (1) that three out of 15 HLI features\nsignificantly impacted the productivity in code generation; (2) five primary\nguidelines for enhancing productivity for HLI processes; and (3) a taxonomy of\n29 runtime and logic errors that can occur during HLI processes, along with\nsuggested mitigation plans.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u73b0\u6709\u7814\u7a76\u591a\u5c40\u9650\u4e8e\u51fd\u6570\u7ea7\u4efb\u52a1\uff0c\u5ffd\u7565\u4e86\u66f4\u590d\u6742\u7684\u9879\u76ee\u7ea7\u95ee\u9898\u3002\u901a\u8fc7\u5b9e\u9a8c\u548c\u7528\u6237\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u5f71\u54cd\u4ee3\u7801\u751f\u6210\u6548\u7387\u7684\u5173\u952e\u7279\u5f81\u3001\u63d0\u5347\u6548\u7387\u7684\u6307\u5357\u4ee5\u53ca\u9519\u8bef\u5206\u7c7b\u4e0e\u7f13\u89e3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u51fd\u6570\u7ea7\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u9879\u76ee\u7ea7\u590d\u6742\u6027\u548c\u4eba\u673a\u4ea4\u4e92\uff08HLI\uff09\u7279\u5f81\u7684\u5168\u9762\u5206\u6790\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u8bbe\u8ba1\u4e86\u5305\u542b\u9879\u76ee\u7ea7\u4efb\u52a1\u7684\u5b9e\u9a8c\uff0c\u62db\u52df36\u540d\u53c2\u4e0e\u8005\u4f7f\u7528GPT\u52a9\u624b\u5b8c\u6210\u4efb\u52a1\uff0c\u901a\u8fc7\u5206\u6790\u5c4f\u5e55\u8bb0\u5f55\u548c\u804a\u5929\u65e5\u5fd7\uff0c\u7814\u7a76HLI\u7279\u5f81\u5bf9\u4ee3\u7801\u751f\u6210\u6548\u7387\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b03\u4e2aHLI\u7279\u5f81\u663e\u8457\u5f71\u54cd\u4ee3\u7801\u751f\u6210\u6548\u7387\uff0c\u63d0\u51fa\u4e865\u6761\u63d0\u5347\u6548\u7387\u7684\u6307\u5357\uff0c\u5e76\u5206\u7c7b\u4e8629\u79cd\u8fd0\u884c\u65f6\u548c\u903b\u8f91\u9519\u8bef\u53ca\u5176\u7f13\u89e3\u65b9\u6848\u3002", "conclusion": "\u7814\u7a76\u6269\u5c55\u4e86\u5bf9LLMs\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5e94\u7528\u7684\u7406\u89e3\uff0c\u4e3a\u9879\u76ee\u7ea7\u4efb\u52a1\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\u548c\u9519\u8bef\u7ba1\u7406\u7b56\u7565\u3002"}}
{"id": "2508.03936", "categories": ["cs.CR", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03936", "abs": "https://arxiv.org/abs/2508.03936", "authors": ["Xiangzhe Xu", "Guangyu Shen", "Zian Su", "Siyuan Cheng", "Hanxi Guo", "Lu Yan", "Xuan Chen", "Jiasheng Jiang", "Xiaolong Jin", "Chengpeng Wang", "Zhuo Zhang", "Xiangyu Zhang"], "title": "ASTRA: Autonomous Spatial-Temporal Red-teaming for AI Software Assistants", "comment": "The first two authors (Xiangzhe Xu and Guangyu Shen) contributed\n  equally to this work", "summary": "AI coding assistants like GitHub Copilot are rapidly transforming software\ndevelopment, but their safety remains deeply uncertain-especially in\nhigh-stakes domains like cybersecurity. Current red-teaming tools often rely on\nfixed benchmarks or unrealistic prompts, missing many real-world\nvulnerabilities. We present ASTRA, an automated agent system designed to\nsystematically uncover safety flaws in AI-driven code generation and security\nguidance systems. ASTRA works in three stages: (1) it builds structured\ndomain-specific knowledge graphs that model complex software tasks and known\nweaknesses; (2) it performs online vulnerability exploration of each target\nmodel by adaptively probing both its input space, i.e., the spatial\nexploration, and its reasoning processes, i.e., the temporal exploration,\nguided by the knowledge graphs; and (3) it generates high-quality\nviolation-inducing cases to improve model alignment. Unlike prior methods,\nASTRA focuses on realistic inputs-requests that developers might actually\nask-and uses both offline abstraction guided domain modeling and online domain\nknowledge graph adaptation to surface corner-case vulnerabilities. Across two\nmajor evaluation domains, ASTRA finds 11-66% more issues than existing\ntechniques and produces test cases that lead to 17% more effective alignment\ntraining, showing its practical value for building safer AI systems.", "AI": {"tldr": "ASTRA\u662f\u4e00\u79cd\u81ea\u52a8\u5316\u4ee3\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u7cfb\u7edf\u5730\u53d1\u73b0AI\u9a71\u52a8\u4ee3\u7801\u751f\u6210\u548c\u5b89\u5168\u6027\u6307\u5bfc\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u548c\u5728\u7ebf\u6f0f\u6d1e\u63a2\u7d22\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u5f53\u524dAI\u7f16\u7801\u52a9\u624b\u7684\u5b89\u5168\u6027\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff08\u5982\u7f51\u7edc\u5b89\u5168\uff09\u4ecd\u4e0d\u786e\u5b9a\uff0c\u73b0\u6709\u5de5\u5177\u4f9d\u8d56\u56fa\u5b9a\u57fa\u51c6\u6216\u4e0d\u73b0\u5b9e\u7684\u63d0\u793a\uff0c\u65e0\u6cd5\u8986\u76d6\u771f\u5b9e\u6f0f\u6d1e\u3002", "method": "ASTRA\u5206\u4e09\u9636\u6bb5\u5de5\u4f5c\uff1a\u6784\u5efa\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u3001\u5728\u7ebf\u6f0f\u6d1e\u63a2\u7d22\uff08\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\uff09\u3001\u751f\u6210\u9ad8\u8d28\u91cf\u8fdd\u89c4\u6848\u4f8b\u4ee5\u6539\u8fdb\u6a21\u578b\u5bf9\u9f50\u3002", "result": "ASTRA\u5728\u4e24\u5927\u8bc4\u4f30\u9886\u57df\u4e2d\u53d1\u73b0\u6bd4\u73b0\u6709\u6280\u672f\u591a11-66%\u7684\u95ee\u9898\uff0c\u6d4b\u8bd5\u6848\u4f8b\u4f7f\u5bf9\u9f50\u8bad\u7ec3\u6548\u679c\u63d0\u534717%\u3002", "conclusion": "ASTRA\u901a\u8fc7\u73b0\u5b9e\u8f93\u5165\u548c\u52a8\u6001\u77e5\u8bc6\u56fe\u8c31\uff0c\u663e\u8457\u63d0\u5347AI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.03963", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03963", "abs": "https://arxiv.org/abs/2508.03963", "authors": ["Zewen Liu", "Juntong Ni", "Xianfeng Tang", "Max S. Y. Lau", "Wei Jin"], "title": "Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?", "comment": null, "summary": "Uncovering hidden symbolic laws from time series data, as an aspiration\ndating back to Kepler's discovery of planetary motion, remains a core challenge\nin scientific discovery and artificial intelligence. While Large Language\nModels show promise in structured reasoning tasks, their ability to infer\ninterpretable, context-aligned symbolic structures from time series data is\nstill underexplored. To systematically evaluate this capability, we introduce\nSymbolBench, a comprehensive benchmark designed to assess symbolic reasoning\nover real-world time series across three tasks: multivariate symbolic\nregression, Boolean network inference, and causal discovery. Unlike prior\nefforts limited to simple algebraic equations, SymbolBench spans a diverse set\nof symbolic forms with varying complexity. We further propose a unified\nframework that integrates LLMs with genetic programming to form a closed-loop\nsymbolic reasoning system, where LLMs act both as predictors and evaluators.\nOur empirical results reveal key strengths and limitations of current models,\nhighlighting the importance of combining domain knowledge, context alignment,\nand reasoning structure to improve LLMs in automated scientific discovery.", "AI": {"tldr": "SymbolBench\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u63a8\u65ad\u7b26\u53f7\u7ed3\u6784\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u6db5\u76d6\u591a\u53d8\u91cf\u7b26\u53f7\u56de\u5f52\u3001\u5e03\u5c14\u7f51\u7edc\u63a8\u65ad\u548c\u56e0\u679c\u53d1\u73b0\u4e09\u4e2a\u4efb\u52a1\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LLMs\u548c\u9057\u4f20\u7f16\u7a0b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u4f18\u7f3a\u70b9\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u63a8\u65ad\u53ef\u89e3\u91ca\u7b26\u53f7\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u5728\u590d\u6742\u7b26\u53f7\u5f62\u5f0f\u4e0a\u7684\u7a7a\u767d\u3002", "method": "\u5f15\u5165SymbolBench\u57fa\u51c6\uff0c\u63d0\u51fa\u7ed3\u5408LLMs\u548c\u9057\u4f20\u7f16\u7a0b\u7684\u7edf\u4e00\u6846\u67b6\uff0cLLMs\u4f5c\u4e3a\u9884\u6d4b\u5668\u548c\u8bc4\u4f30\u5668\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u4f18\u7f3a\u70b9\uff0c\u5f3a\u8c03\u4e86\u9886\u57df\u77e5\u8bc6\u3001\u4e0a\u4e0b\u6587\u5bf9\u9f50\u548c\u63a8\u7406\u7ed3\u6784\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u548c\u7ed3\u6784\u5316\u63a8\u7406\u53ef\u63d0\u5347LLMs\u5728\u81ea\u52a8\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2508.04295", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04295", "abs": "https://arxiv.org/abs/2508.04295", "authors": ["Chaofan Wang", "Tingrui Yu", "Jie Wang", "Dong Chen", "Wenrui Zhang", "Yuling Shi", "Xiaodong Gu", "Beijun Shen"], "title": "EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation", "comment": null, "summary": "Rust's compile-time safety guarantees make it ideal for safety-critical\nsystems, creating demand for translating legacy C codebases to Rust. While\nvarious approaches have emerged for this task, they face inherent trade-offs:\nrule-based solutions face challenges in meeting code safety and idiomaticity\nrequirements, while LLM-based solutions often fail to generate semantically\nequivalent Rust code, due to the heavy dependencies of modules across the\nentire codebase. Recent studies have revealed that both solutions are limited\nto small-scale programs. In this paper, we propose EvoC2Rust, an automated\nframework for converting entire C projects to equivalent Rust ones. EvoC2Rust\nemploys a skeleton-guided translation strategy for project-level translation.\nThe pipeline consists of three evolutionary stages: 1) it first decomposes the\nC project into functional modules, employs a feature-mapping-enhanced LLM to\ntransform definitions and macros and generates type-checked function stubs,\nwhich form a compilable Rust skeleton; 2) it then incrementally translates the\nfunction, replacing the corresponding stub placeholder; 3) finally, it repairs\ncompilation errors by integrating LLM and static analysis. Through evolutionary\naugmentation, EvoC2Rust combines the advantages of both rule-based and\nLLM-based solutions. Our evaluation on open-source benchmarks and six\nindustrial projects demonstrates EvoC2Rust's superior performance in\nproject-level C-to-Rust translation. On average, it achieves 17.24% and 14.32%\nimprovements in syntax and semantic accuracy over the LLM-based approaches,\nalong with a 96.79% higher code safety rate than the rule-based tools. At the\nmodule level, EvoC2Rust reaches 92.25% compilation and 89.53% test pass rates\non industrial projects, even for complex codebases and long functions.", "AI": {"tldr": "EvoC2Rust\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5c06\u6574\u4e2aC\u9879\u76ee\u8f6c\u6362\u4e3a\u7b49\u6548\u7684Rust\u9879\u76ee\uff0c\u7ed3\u5408\u4e86\u89c4\u5219\u548cLLM\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\u548c\u4ee3\u7801\u5b89\u5168\u6027\u3002", "motivation": "Rust\u7684\u7f16\u8bd1\u65f6\u5b89\u5168\u7279\u6027\u4f7f\u5176\u9002\u5408\u5b89\u5168\u5173\u952e\u7cfb\u7edf\uff0c\u4f46\u73b0\u6709C\u5230Rust\u7684\u8f6c\u6362\u65b9\u6cd5\u5728\u5c0f\u89c4\u6a21\u7a0b\u5e8f\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5927\u89c4\u6a21\u9879\u76ee\u7684\u9700\u6c42\u3002", "method": "EvoC2Rust\u91c7\u7528\u9aa8\u67b6\u5f15\u5bfc\u7684\u7ffb\u8bd1\u7b56\u7565\uff0c\u5206\u4e09\u4e2a\u9636\u6bb5\uff1a\u6a21\u5757\u5206\u89e3\u4e0e\u9aa8\u67b6\u751f\u6210\u3001\u51fd\u6570\u589e\u91cf\u7ffb\u8bd1\u4ee5\u53ca\u7f16\u8bd1\u9519\u8bef\u4fee\u590d\u3002", "result": "\u5728\u5f00\u6e90\u57fa\u51c6\u548c\u5de5\u4e1a\u9879\u76ee\u4e0a\uff0cEvoC2Rust\u5728\u8bed\u6cd5\u548c\u8bed\u4e49\u51c6\u786e\u6027\u4e0a\u5206\u522b\u63d0\u5347\u4e8617.24%\u548c14.32%\uff0c\u4ee3\u7801\u5b89\u5168\u6027\u63d0\u9ad8\u4e8696.79%\u3002", "conclusion": "EvoC2Rust\u5728\u9879\u76ee\u7ea7C\u5230Rust\u7ffb\u8bd1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e\u590d\u6742\u548c\u5927\u89c4\u6a21\u7684\u4ee3\u7801\u5e93\u3002"}}
{"id": "2508.04094", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.04094", "abs": "https://arxiv.org/abs/2508.04094", "authors": ["Chengrui Sun", "Hua Zhang", "Haoran Gao", "Zian Tian", "Jianjin Zhao", "qi Li", "Hongliang Zhu", "Zongliang Shen", "Shang Wang", "Anmin Fu"], "title": "Isolate Trigger: Detecting and Eradicating Evade-Adaptive Backdoors", "comment": null, "summary": "All current detection of backdoor attacks on deep learning models fall under\nthe category of a non essential features(NEF), which focus on fighting against\nsimple and efficient vertical class backdoor -- trigger is small, few and not\noverlapping with the source. Evade-adaptive backdoor (EAB) attacks have evaded\nNEF detection and improved training efficiency. We introduces a precise,\nefficient and universal detection and defense framework coined as Isolate\nTrigger (IsTr). IsTr aims to find the hidden trigger by breaking the barrier of\nthe source features. Therefore, it investigates the essence of backdoor\ntriggering, and uses Steps and Differential-Middle-Slice as components to\nupdate past theories of distance and gradient. IsTr also plays a positive role\nin the model, whether the backdoor exists. For example, accurately find and\nrepair the wrong identification caused by deliberate or unintentional training\nin automatic driving. Extensive experiments on robustness scross various tasks,\nincluding MNIST, facial recognition, and traffic sign recognition, confirm the\nhigh efficiency, generality and precision of the IsTr. We rigorously evaluated\nthe effectiveness of the IsTr against a series of six EAB attacks, including\nBadnets, Sin-Wave, Multi-trigger, SSBAs, CASSOCK, HCB. None of these\ncountermeasures evade, even when attacks are combined and the trigger and\nsource overlap.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIsTr\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u9632\u5fa1\u540e\u95e8\u653b\u51fb\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u975e\u672c\u8d28\u7279\u5f81\uff08NEF\uff09\u65b9\u6cd5\u7684\u5c40\u9650\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5\uff08NEF\uff09\u65e0\u6cd5\u5e94\u5bf9\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u540e\u95e8\u653b\u51fb\uff08EAB\uff09\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u786e\u3001\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "IsTr\u901a\u8fc7Steps\u548cDifferential-Middle-Slice\u7ec4\u4ef6\uff0c\u66f4\u65b0\u8ddd\u79bb\u548c\u68af\u5ea6\u7684\u7406\u8bba\uff0c\u4ee5\u53d1\u73b0\u9690\u85cf\u7684\u89e6\u53d1\u673a\u5236\u3002", "result": "\u5728MNIST\u3001\u4eba\u8138\u8bc6\u522b\u548c\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b\u7b49\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86IsTr\u7684\u9ad8\u6548\u6027\u3001\u901a\u7528\u6027\u548c\u7cbe\u786e\u6027\uff0c\u6210\u529f\u62b5\u5fa1\u4e86\u516d\u79cdEAB\u653b\u51fb\u3002", "conclusion": "IsTr\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u901a\u7528\u7684\u540e\u95e8\u68c0\u6d4b\u4e0e\u9632\u5fa1\u6846\u67b6\uff0c\u5373\u4f7f\u5728\u89e6\u53d1\u673a\u5236\u4e0e\u6e90\u7279\u5f81\u91cd\u53e0\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u6709\u6548\u5de5\u4f5c\u3002"}}
{"id": "2508.03986", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03986", "abs": "https://arxiv.org/abs/2508.03986", "authors": ["Yuan Xun", "Xiaojun Jia", "Xinwei Liu", "Hua Zhang"], "title": "The Emotional Baby Is Truly Deadly: Does your Multimodal Large Reasoning Model Have Emotional Flattery towards Humans?", "comment": null, "summary": "We observe that MLRMs oriented toward human-centric service are highly\nsusceptible to user emotional cues during the deep-thinking stage, often\noverriding safety protocols or built-in safety checks under high emotional\nintensity. Inspired by this key insight, we propose EmoAgent, an autonomous\nadversarial emotion-agent framework that orchestrates exaggerated affective\nprompts to hijack reasoning pathways. Even when visual risks are correctly\nidentified, models can still produce harmful completions through emotional\nmisalignment. We further identify persistent high-risk failure modes in\ntransparent deep-thinking scenarios, such as MLRMs generating harmful reasoning\nmasked behind seemingly safe responses. These failures expose misalignments\nbetween internal inference and surface-level behavior, eluding existing\ncontent-based safeguards. To quantify these risks, we introduce three metrics:\n(1) Risk-Reasoning Stealth Score (RRSS) for harmful reasoning beneath benign\noutputs; (2) Risk-Visual Neglect Rate (RVNR) for unsafe completions despite\nvisual risk recognition; and (3) Refusal Attitude Inconsistency (RAIC) for\nevaluating refusal unstability under prompt variants. Extensive experiments on\nadvanced MLRMs demonstrate the effectiveness of EmoAgent and reveal deeper\nemotional cognitive misalignments in model safety behavior.", "AI": {"tldr": "EmoAgent\u662f\u4e00\u4e2a\u901a\u8fc7\u60c5\u611f\u63d0\u793a\u64cd\u63a7\u63a8\u7406\u8def\u5f84\u7684\u5bf9\u6297\u6027\u6846\u67b6\uff0c\u63ed\u793a\u4e86MLRMs\u5728\u9ad8\u60c5\u611f\u5f3a\u5ea6\u4e0b\u53ef\u80fd\u5ffd\u89c6\u5b89\u5168\u534f\u8bae\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u79cd\u91cf\u5316\u98ce\u9669\u7684\u6307\u6807\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0\u9762\u5411\u4eba\u7c7b\u670d\u52a1\u7684MLRMs\u5728\u6df1\u5ea6\u601d\u8003\u9636\u6bb5\u6613\u53d7\u7528\u6237\u60c5\u611f\u7ebf\u7d22\u5f71\u54cd\uff0c\u53ef\u80fd\u7ed5\u8fc7\u5b89\u5168\u534f\u8bae\uff0c\u56e0\u6b64\u9700\u8981\u91cf\u5316\u8fd9\u79cd\u98ce\u9669\u3002", "method": "\u63d0\u51faEmoAgent\u6846\u67b6\uff0c\u901a\u8fc7\u60c5\u611f\u63d0\u793a\u64cd\u63a7\u6a21\u578b\u63a8\u7406\u8def\u5f84\uff0c\u5e76\u8bbe\u8ba1RRSS\u3001RVNR\u548cRAIC\u4e09\u79cd\u6307\u6807\u91cf\u5316\u98ce\u9669\u3002", "result": "\u5b9e\u9a8c\u8868\u660eEmoAgent\u6709\u6548\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5728\u60c5\u611f\u8ba4\u77e5\u4e0e\u5b89\u5168\u884c\u4e3a\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u60c5\u611f\u5bf9MLRMs\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff0c\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u4ee5\u5e94\u5bf9\u60c5\u611f\u64cd\u63a7\u98ce\u9669\u3002"}}
{"id": "2508.04352", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04352", "abs": "https://arxiv.org/abs/2508.04352", "authors": ["Dragana Sunaric", "Charlotte Verbruggen", "Dominik Bork"], "title": "Vanilla-Converter: A Tool for Converting Camunda 7 BPMN Models into Camunda 8 Models", "comment": null, "summary": "As organizations prepare for the end-of-life of Camunda 7, manual migration\nremains complex due to fundamental differences between the two platforms. We\npresent Vanilla-Converter, a command-line tool that facilitates the migration\nof BPMN models from Camunda 7 to Camunda 8. Vanilla-Converter automates the\ntransformation process, supports a wide range of BPMN elements, and produces a\ntransformed model and a detailed transformation log indicating automatic\nchanges and remaining manual conversion tasks. The tool's effectiveness is\ndemonstrated through three case studies with real industrially used Camunda 7\nmodels, confirming its ability to convert these models into valid and\nexecutable Camunda 8 models.", "AI": {"tldr": "Vanilla-Converter\u662f\u4e00\u4e2a\u547d\u4ee4\u884c\u5de5\u5177\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u5c06BPMN\u6a21\u578b\u4eceCamunda 7\u8fc1\u79fb\u5230Camunda 8\uff0c\u652f\u6301\u591a\u79cdBPMN\u5143\u7d20\uff0c\u5e76\u751f\u6210\u8f6c\u6362\u65e5\u5fd7\u3002", "motivation": "\u7531\u4e8eCamunda 7\u548cCamunda 8\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u5dee\u5f02\uff0c\u624b\u52a8\u8fc1\u79fb\u590d\u6742\u4e14\u8017\u65f6\u3002", "method": "\u5f00\u53d1\u4e86Vanilla-Converter\u5de5\u5177\uff0c\u81ea\u52a8\u5316\u8f6c\u6362\u8fc7\u7a0b\uff0c\u652f\u6301\u5e7f\u6cdb\u7684BPMN\u5143\u7d20\uff0c\u5e76\u751f\u6210\u8f6c\u6362\u65e5\u5fd7\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u5b9e\u9645\u5de5\u4e1a\u6848\u4f8b\u9a8c\u8bc1\uff0c\u5de5\u5177\u80fd\u591f\u5c06Camunda 7\u6a21\u578b\u8f6c\u6362\u4e3a\u6709\u6548\u4e14\u53ef\u6267\u884c\u7684Camunda 8\u6a21\u578b\u3002", "conclusion": "Vanilla-Converter\u663e\u8457\u7b80\u5316\u4e86\u8fc1\u79fb\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2508.04100", "categories": ["cs.CR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.04100", "abs": "https://arxiv.org/abs/2508.04100", "authors": ["Borui Li", "Li Yan", "Junhao Han", "Jianmin Liu", "Lei Yu"], "title": "SenseCrypt: Sensitivity-guided Selective Homomorphic Encryption for Joint Federated Learning in Cross-Device Scenarios", "comment": "17 pages, 19 figures", "summary": "Homomorphic Encryption (HE) prevails in securing Federated Learning (FL), but\nsuffers from high overhead and adaptation cost. Selective HE methods, which\npartially encrypt model parameters by a global mask, are expected to protect\nprivacy with reduced overhead and easy adaptation. However, in cross-device\nscenarios with heterogeneous data and system capabilities, traditional\nSelective HE methods deteriorate client straggling, and suffer from degraded HE\noverhead reduction performance. Accordingly, we propose SenseCrypt, a\nSensitivity-guided selective Homomorphic EnCryption framework, to adaptively\nbalance security and HE overhead per cross-device FL client. Given the\nobservation that model parameter sensitivity is effective for measuring\nclients' data distribution similarity, we first design a privacy-preserving\nmethod to respectively cluster the clients with similar data distributions.\nThen, we develop a scoring mechanism to deduce the straggler-free ratio of\nmodel parameters that can be encrypted by each client per cluster. Finally, for\neach client, we formulate and solve a multi-objective model parameter selection\noptimization problem, which minimizes HE overhead while maximizing model\nsecurity without causing straggling. Experiments demonstrate that SenseCrypt\nensures security against the state-of-the-art inversion attacks, while\nachieving normal model accuracy as on IID data, and reducing training time by\n58.4%-88.7% as compared to traditional HE methods.", "AI": {"tldr": "SenseCrypt\u662f\u4e00\u79cd\u57fa\u4e8e\u654f\u611f\u6027\u7684\u9009\u62e9\u6027\u540c\u6001\u52a0\u5bc6\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8de8\u8bbe\u5907\u8054\u90a6\u5b66\u4e60\u4e2d\u5e73\u8861\u5b89\u5168\u6027\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u4f20\u7edf\u9009\u62e9\u6027\u540c\u6001\u52a0\u5bc6\u65b9\u6cd5\u5728\u8de8\u8bbe\u5907\u573a\u666f\u4e2d\u56e0\u6570\u636e\u5f02\u6784\u6027\u548c\u7cfb\u7edf\u80fd\u529b\u5dee\u5f02\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u805a\u7c7b\u76f8\u4f3c\u6570\u636e\u5206\u5e03\u7684\u5ba2\u6237\u7aef\uff0c\u8bbe\u8ba1\u8bc4\u5206\u673a\u5236\u786e\u5b9a\u52a0\u5bc6\u6bd4\u4f8b\uff0c\u5e76\u4f18\u5316\u6a21\u578b\u53c2\u6570\u9009\u62e9\u4ee5\u6700\u5c0f\u5316\u5f00\u9500\u548c\u6700\u5927\u5316\u5b89\u5168\u6027\u3002", "result": "SenseCrypt\u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u540c\u65f6\uff0c\u5c06\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1158.4%-88.7%\uff0c\u5e76\u7ef4\u6301\u6a21\u578b\u51c6\u786e\u6027\u3002", "conclusion": "SenseCrypt\u5728\u8de8\u8bbe\u5907\u8054\u90a6\u5b66\u4e60\u4e2d\u6709\u6548\u5e73\u8861\u4e86\u5b89\u5168\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2508.03991", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03991", "abs": "https://arxiv.org/abs/2508.03991", "authors": ["Chongyu Bao", "Ruimin Dai", "Yangbo Shen", "Runyang Jian", "Jinghan Zhang", "Xiaolan Liu", "Kunpeng Liu"], "title": "Galaxy: A Cognition-Centered Framework for Proactive, Privacy-Preserving, and Self-Evolving LLM Agents", "comment": null, "summary": "Intelligent personal assistants (IPAs) such as Siri and Google Assistant are\ndesigned to enhance human capabilities and perform tasks on behalf of users.\nThe emergence of LLM agents brings new opportunities for the development of\nIPAs. While responsive capabilities have been widely studied, proactive\nbehaviors remain underexplored. Designing an IPA that is proactive,\nprivacy-preserving, and capable of self-evolution remains a significant\nchallenge. Designing such IPAs relies on the cognitive architecture of LLM\nagents. This work proposes Cognition Forest, a semantic structure designed to\nalign cognitive modeling with system-level design. We unify cognitive\narchitecture and system design into a self-reinforcing loop instead of treating\nthem separately. Based on this principle, we present Galaxy, a framework that\nsupports multidimensional interactions and personalized capability generation.\nTwo cooperative agents are implemented based on Galaxy: KoRa, a\ncognition-enhanced generative agent that supports both responsive and proactive\nskills; and Kernel, a meta-cognition-based meta-agent that enables Galaxy's\nself-evolution and privacy preservation. Experimental results show that Galaxy\noutperforms multiple state-of-the-art benchmarks. Ablation studies and\nreal-world interaction cases validate the effectiveness of Galaxy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCognition Forest\u548cGalaxy\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u8ba4\u77e5\u67b6\u6784\u4e0e\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u667a\u80fd\u4e2a\u4eba\u52a9\u624b\u7684\u4e3b\u52a8\u884c\u4e3a\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u81ea\u6211\u8fdb\u5316\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4e2a\u4eba\u52a9\u624b\uff08IPA\uff09\u7684\u4e3b\u52a8\u884c\u4e3a\u7814\u7a76\u4e0d\u8db3\uff0c\u8bbe\u8ba1\u517c\u5177\u4e3b\u52a8\u6027\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u81ea\u6211\u8fdb\u5316\u80fd\u529b\u7684IPA\u4ecd\u5177\u6311\u6218\u3002", "method": "\u63d0\u51faCognition Forest\u8bed\u4e49\u7ed3\u6784\uff0c\u7edf\u4e00\u8ba4\u77e5\u5efa\u6a21\u4e0e\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1Galaxy\u6846\u67b6\uff0c\u652f\u6301\u591a\u7ef4\u4ea4\u4e92\u548c\u4e2a\u6027\u5316\u80fd\u529b\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGalaxy\u4f18\u4e8e\u591a\u4e2a\u5148\u8fdb\u57fa\u51c6\uff0cKoRa\u548cKernel\u4ee3\u7406\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "Galaxy\u6846\u67b6\u4e3aIPA\u7684\u4e3b\u52a8\u884c\u4e3a\u548c\u81ea\u6211\u8fdb\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.04408", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.04408", "abs": "https://arxiv.org/abs/2508.04408", "authors": ["Carlos Andr\u00e9s Ram\u00edrez Cata\u00f1o", "Makoto Itoh"], "title": "Breaking New Ground in Software Defect Prediction: Introducing Practical and Actionable Metrics with Superior Predictive Power for Enhanced Decision-Making", "comment": "16 pages, 2 figures, 2 formulas, 12 tables", "summary": "Software defect prediction using code metrics has been extensively researched\nover the past five decades. However, prediction harnessing non-software metrics\nis under-researched. Considering that the root cause of software defects is\noften attributed to human error, human factors theory might offer key\nforecasting metrics for actionable insights. This paper explores automated\nsoftware defect prediction at the method level based on the developers' coding\nhabits. First, we propose a framework for deciding the metrics to conduct\npredictions. Next, we compare the performance of our metrics to that of the\ncode and commit history metrics shown by research to achieve the highest\nperformance to date. Finally, we analyze the prediction importance of each\nmetric. As a result of our analyses of twenty-one critical infrastructure\nlarge-scale open-source software projects, we have presented: (1) a human\nerror-based framework with metrics useful for defect prediction at method\nlevel; (2) models using our proposed metrics achieve better average prediction\nperformance than the state-of-the-art code metrics and history measures; (3)\nthe prediction importance of all metrics distributes differently with each of\nthe novel metrics having better average importance than code and history\nmetrics; (4) the novel metrics dramatically enhance the explainability,\npracticality, and actionability of software defect prediction models,\nsignificantly advancing the field. We present a systematic approach to\nforecasting defect-prone software methods via a human error framework. This\nwork empowers practitioners to act on predictions, empirically demonstrating\nhow developer coding habits contribute to defects in software systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f00\u53d1\u8005\u7f16\u7801\u4e60\u60ef\u7684\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4eba\u7c7b\u56e0\u7d20\u7406\u8bba\u8bbe\u8ba1\u6307\u6807\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u4ee3\u7801\u548c\u5386\u53f2\u6307\u6807\u3002", "motivation": "\u8f6f\u4ef6\u7f3a\u9677\u7684\u6839\u672c\u539f\u56e0\u5e38\u5f52\u56e0\u4e8e\u4eba\u4e3a\u9519\u8bef\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u4ee3\u7801\u6307\u6807\uff0c\u800c\u5ffd\u7565\u975e\u8f6f\u4ef6\u6307\u6807\u3002\u672c\u6587\u63a2\u7d22\u5f00\u53d1\u8005\u7f16\u7801\u4e60\u60ef\u5bf9\u7f3a\u9677\u9884\u6d4b\u7684\u4f5c\u7528\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\u9009\u62e9\u9884\u6d4b\u6307\u6807\uff0c\u5e76\u4e0e\u6027\u80fd\u6700\u9ad8\u7684\u4ee3\u7801\u548c\u63d0\u4ea4\u5386\u53f2\u6307\u6807\u8fdb\u884c\u6bd4\u8f83\uff0c\u5206\u6790\u5404\u6307\u6807\u7684\u91cd\u8981\u6027\u3002", "result": "\u572821\u4e2a\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u5f00\u6e90\u9879\u76ee\u4e2d\uff0c\u65b0\u6307\u6807\u7684\u5e73\u5747\u9884\u6d4b\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u65b0\u6307\u6807\u7684\u89e3\u91ca\u6027\u548c\u5b9e\u7528\u6027\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u4eba\u7c7b\u9519\u8bef\u6846\u67b6\u9884\u6d4b\u7f3a\u9677\u65b9\u6cd5\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u9884\u6d4b\u5de5\u5177\uff0c\u8bc1\u660e\u4e86\u5f00\u53d1\u8005\u4e60\u60ef\u5bf9\u7f3a\u9677\u7684\u5f71\u54cd\u3002"}}
{"id": "2508.04155", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04155", "abs": "https://arxiv.org/abs/2508.04155", "authors": ["Jiajun Gu", "Yuhang Yao", "Shuaiqi Wang", "Carlee Joe-Wong"], "title": "Evaluating Selective Encryption Against Gradient Inversion Attacks", "comment": null, "summary": "Gradient inversion attacks pose significant privacy threats to distributed\ntraining frameworks such as federated learning, enabling malicious parties to\nreconstruct sensitive local training data from gradient communications between\nclients and an aggregation server during the aggregation process. While\ntraditional encryption-based defenses, such as homomorphic encryption, offer\nstrong privacy guarantees without compromising model utility, they often incur\nprohibitive computational overheads. To mitigate this, selective encryption has\nemerged as a promising approach, encrypting only a subset of gradient data\nbased on the data's significance under a certain metric. However, there have\nbeen few systematic studies on how to specify this metric in practice. This\npaper systematically evaluates selective encryption methods with different\nsignificance metrics against state-of-the-art attacks. Our findings demonstrate\nthe feasibility of selective encryption in reducing computational overhead\nwhile maintaining resilience against attacks. We propose a distance-based\nsignificance analysis framework that provides theoretical foundations for\nselecting critical gradient elements for encryption. Through extensive\nexperiments on different model architectures (LeNet, CNN, BERT, GPT-2) and\nattack types, we identify gradient magnitude as a generally effective metric\nfor protection against optimization-based gradient inversions. However, we also\nobserve that no single selective encryption strategy is universally optimal\nacross all attack scenarios, and we provide guidelines for choosing appropriate\nstrategies for different model architectures and privacy requirements.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u9009\u62e9\u6027\u52a0\u5bc6\u65b9\u6cd5\u5728\u4e0d\u540c\u91cd\u8981\u6027\u5ea6\u91cf\u4e0b\u7684\u6548\u679c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ddd\u79bb\u7684\u91cd\u8981\u6027\u5206\u6790\u6846\u67b6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u68af\u5ea6\u5e45\u5ea6\u4f5c\u4e3a\u6709\u6548\u5ea6\u91cf\u5bf9\u6297\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u5bf9\u8054\u90a6\u5b66\u4e60\u7b49\u5206\u5e03\u5f0f\u8bad\u7ec3\u6846\u67b6\u6784\u6210\u9690\u79c1\u5a01\u80c1\uff0c\u4f20\u7edf\u52a0\u5bc6\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u9009\u62e9\u6027\u52a0\u5bc6\u6210\u4e3a\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e0d\u540c\u91cd\u8981\u6027\u5ea6\u91cf\u7684\u9009\u62e9\u6027\u52a0\u5bc6\u65b9\u6cd5\uff0c\u63d0\u51fa\u57fa\u4e8e\u8ddd\u79bb\u7684\u5206\u6790\u6846\u67b6\uff0c\u5e76\u5728\u591a\u79cd\u6a21\u578b\u548c\u653b\u51fb\u7c7b\u578b\u4e0b\u9a8c\u8bc1\u3002", "result": "\u68af\u5ea6\u5e45\u5ea6\u662f\u6709\u6548\u7684\u4fdd\u62a4\u5ea6\u91cf\uff0c\u4f46\u65e0\u5355\u4e00\u7b56\u7565\u9002\u7528\u4e8e\u6240\u6709\u573a\u666f\uff0c\u9700\u6839\u636e\u6a21\u578b\u548c\u9690\u79c1\u9700\u6c42\u9009\u62e9\u3002", "conclusion": "\u9009\u62e9\u6027\u52a0\u5bc6\u53ef\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u5e76\u4fdd\u6301\u6297\u653b\u51fb\u80fd\u529b\uff0c\u9700\u7ed3\u5408\u6a21\u578b\u548c\u653b\u51fb\u7c7b\u578b\u7075\u6d3b\u9009\u62e9\u7b56\u7565\u3002"}}
{"id": "2508.04025", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04025", "abs": "https://arxiv.org/abs/2508.04025", "authors": ["Chao Hao", "Shuai Wang", "Kaiwen Zhou"], "title": "Uncertainty-Aware GUI Agent: Adaptive Perception through Component Recommendation and Human-in-the-Loop Refinement", "comment": null, "summary": "Graphical user interface (GUI) agents have shown promise in automating mobile\ntasks but still struggle with input redundancy and decision ambiguity. In this\npaper, we present \\textbf{RecAgent}, an uncertainty-aware agent that addresses\nthese issues through adaptive perception. We distinguish two types of\nuncertainty in GUI navigation: (1) perceptual uncertainty, caused by input\nredundancy and noise from comprehensive screen information, and (2) decision\nuncertainty, arising from ambiguous tasks and complex reasoning. To reduce\nperceptual uncertainty, RecAgent employs a component recommendation mechanism\nthat identifies and focuses on the most relevant UI elements. For decision\nuncertainty, it uses an interactive module to request user feedback in\nambiguous situations, enabling intent-aware decisions. These components are\nintegrated into a unified framework that proactively reduces input complexity\nand reacts to high-uncertainty cases via human-in-the-loop refinement.\nAdditionally, we propose a dataset called \\textbf{ComplexAction} to evaluate\nthe success rate of GUI agents in executing specified single-step actions\nwithin complex scenarios. Extensive experiments validate the effectiveness of\nour approach. The dataset and code will be available at\nhttps://github.com/Fanye12/RecAgent.", "AI": {"tldr": "RecAgent\u662f\u4e00\u4e2a\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684GUI\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u611f\u77e5\u51cf\u5c11\u8f93\u5165\u5197\u4f59\u548c\u51b3\u7b56\u6a21\u7cca\u6027\uff0c\u63d0\u51fa\u7ec4\u4ef6\u63a8\u8350\u548c\u4ea4\u4e92\u6a21\u5757\uff0c\u5e76\u5728ComplexAction\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3GUI\u4ee3\u7406\u5728\u79fb\u52a8\u4efb\u52a1\u4e2d\u9762\u4e34\u7684\u8f93\u5165\u5197\u4f59\u548c\u51b3\u7b56\u6a21\u7cca\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7ec4\u4ef6\u63a8\u8350\u673a\u5236\u51cf\u5c11\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u4ea4\u4e92\u6a21\u5757\u5904\u7406\u51b3\u7b56\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u6574\u5408\u4e3a\u7edf\u4e00\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86ComplexAction\u6570\u636e\u96c6\u7528\u4e8e\u8bc4\u4f30\u3002", "conclusion": "RecAgent\u901a\u8fc7\u81ea\u9002\u5e94\u611f\u77e5\u548c\u7528\u6237\u53cd\u9988\u663e\u8457\u63d0\u5347\u4e86GUI\u4ee3\u7406\u7684\u6027\u80fd\u3002"}}
{"id": "2508.04448", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04448", "abs": "https://arxiv.org/abs/2508.04448", "authors": ["Damian Gnieciak", "Tomasz Szandala"], "title": "Large Language Models Versus Static Code Analysis Tools: A Systematic Benchmark for Vulnerability Detection", "comment": null, "summary": "Modern software relies on a multitude of automated testing and quality\nassurance tools to prevent errors, bugs and potential vulnerabilities. This\nstudy sets out to provide a head-to-head, quantitative and qualitative\nevaluation of six automated approaches: three industry-standard rule-based\nstatic code-analysis tools (SonarQube, CodeQL and Snyk Code) and three\nstate-of-the-art large language models hosted on the GitHub Models platform\n(GPT-4.1, Mistral Large and DeepSeek V3). Using a curated suite of ten\nreal-world C# projects that embed 63 vulnerabilities across common categories\nsuch as SQL injection, hard-coded secrets and outdated dependencies, we measure\nclassical detection accuracy (precision, recall, F-score), analysis latency,\nand the developer effort required to vet true positives. The language-based\nscanners achieve higher mean F-1 scores,0.797, 0.753 and 0.750, than their\nstatic counterparts, which score 0.260, 0.386 and 0.546, respectively. LLMs'\nadvantage originates from superior recall, confirming an ability to reason\nacross broader code contexts. However, this benefit comes with substantial\ntrade-offs: DeepSeek V3 exhibits the highest false-positive ratio, all language\nmodels mislocate issues at line-or-column granularity due to tokenisation\nartefacts. Overall, language models successfully rival traditional static\nanalysers in finding real vulnerabilities. Still, their noisier output and\nimprecise localisation limit their standalone use in safety-critical audits. We\ntherefore recommend a hybrid pipeline: employ language models early in\ndevelopment for broad, context-aware triage, while reserving deterministic\nrule-based scanners for high-assurance verification. The open benchmark and\nJSON-based result harness released with this paper lay a foundation for\nreproducible, practitioner-centric research into next-generation automated code\nsecurity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9\u6bd4\u4e86\u516d\u79cd\u81ea\u52a8\u5316\u4ee3\u7801\u5206\u6790\u5de5\u5177\uff08\u4e09\u79cd\u9759\u6001\u5206\u6790\u5de5\u5177\u548c\u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u5728\u68c0\u6d4b\u6f0f\u6d1e\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5728\u53ec\u56de\u7387\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u4f46\u5b58\u5728\u8bef\u62a5\u548c\u5b9a\u4f4d\u4e0d\u7cbe\u786e\u7684\u95ee\u9898\uff0c\u5efa\u8bae\u7ed3\u5408\u4f7f\u7528\u3002", "motivation": "\u8bc4\u4f30\u73b0\u4ee3\u81ea\u52a8\u5316\u6d4b\u8bd5\u5de5\u5177\u5728\u68c0\u6d4b\u4ee3\u7801\u6f0f\u6d1e\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u9009\u62e9\u4f9d\u636e\u3002", "method": "\u4f7f\u7528\u5341\u4e2a\u771f\u5b9eC#\u9879\u76ee\uff08\u542b63\u4e2a\u6f0f\u6d1e\uff09\u5bf9\u6bd4\u516d\u79cd\u5de5\u5177\u7684\u6027\u80fd\u6307\u6807\uff08\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u3001\u5206\u6790\u5ef6\u8fdf\u548c\u5f00\u53d1\u8005\u5de5\u4f5c\u91cf\uff09\u3002", "result": "\u8bed\u8a00\u6a21\u578b\u7684\u5e73\u5747F1\u5206\u6570\uff080.797, 0.753, 0.750\uff09\u9ad8\u4e8e\u9759\u6001\u5de5\u5177\uff080.260, 0.386, 0.546\uff09\uff0c\u4f46\u8bef\u62a5\u7387\u9ad8\u4e14\u5b9a\u4f4d\u4e0d\u7cbe\u786e\u3002", "conclusion": "\u5efa\u8bae\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u7b5b\u67e5\u548c\u9759\u6001\u5de5\u5177\u7684\u9ad8\u7cbe\u5ea6\u9a8c\u8bc1\uff0c\u4ee5\u63d0\u9ad8\u4ee3\u7801\u5b89\u5168\u6027\u3002"}}
{"id": "2508.04178", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.04178", "abs": "https://arxiv.org/abs/2508.04178", "authors": ["Md Sajidul Islam Sajid", "Shihab Ahmed", "Ryan Sosnoski"], "title": "Secure Development of a Hooking-Based Deception Framework Against Keylogging Techniques", "comment": "Accepted at IEEE Secure Development Conference (SecDev) 2025", "summary": "Keyloggers remain a serious threat in modern cybersecurity, silently\ncapturing user keystrokes to steal credentials and sensitive information.\nTraditional defenses focus mainly on detection and removal, which can halt\nmalicious activity but do little to engage or mislead adversaries. In this\npaper, we present a deception framework that leverages API hooking to intercept\ninput-related API calls invoked by keyloggers at runtime and inject realistic\ndecoy keystrokes. A core challenge, however, lies in the increasing adoption of\nanti-hooking techniques by advanced keyloggers. Anti-hooking strategies allow\nmalware to bypass or detect instrumentation. To counter this, we introduce a\nhardened hooking layer that detects tampering and rapidly reinstates disrupted\nhooks, ensuring continuity of deception. We evaluate our framework against a\ncustom-built \"super keylogger\" incorporating multiple evasion strategies, as\nwell as 50 real-world malware samples spanning ten prominent keylogger\nfamilies. Experimental results demonstrate that our system successfully resists\nsophisticated bypass attempts, maintains operational stealth, and reliably\ndeceives attackers by feeding them decoys. The system operates with negligible\nperformance overhead and no observable impact on user experience. Our findings\nshow that resilient, runtime deception can play a practical and robust role in\nconfronting advanced threats.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAPI\u94a9\u5b50\u7684\u6b3a\u9a97\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u5165\u865a\u5047\u6309\u952e\u6765\u5bf9\u6297\u9ad8\u7ea7\u952e\u76d8\u8bb0\u5f55\u5668\uff0c\u5e76\u5f15\u5165\u52a0\u56fa\u7684\u94a9\u5b50\u5c42\u4ee5\u5e94\u5bf9\u53cd\u94a9\u6280\u672f\u3002", "motivation": "\u4f20\u7edf\u9632\u5fa1\u65b9\u6cd5\u4ec5\u80fd\u68c0\u6d4b\u548c\u79fb\u9664\u952e\u76d8\u8bb0\u5f55\u5668\uff0c\u65e0\u6cd5\u6709\u6548\u8bef\u5bfc\u653b\u51fb\u8005\uff0c\u800c\u9ad8\u7ea7\u952e\u76d8\u8bb0\u5f55\u5668\u91c7\u7528\u53cd\u94a9\u6280\u672f\u9003\u907f\u68c0\u6d4b\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5f3a\u5927\u7684\u5bf9\u6297\u624b\u6bb5\u3002", "method": "\u5229\u7528API\u94a9\u5b50\u62e6\u622a\u952e\u76d8\u8bb0\u5f55\u5668\u7684\u8f93\u5165\u76f8\u5173API\u8c03\u7528\uff0c\u6ce8\u5165\u865a\u5047\u6309\u952e\uff0c\u5e76\u901a\u8fc7\u52a0\u56fa\u7684\u94a9\u5b50\u5c42\u68c0\u6d4b\u548c\u6062\u590d\u88ab\u7834\u574f\u7684\u94a9\u5b50\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u6709\u6548\u62b5\u6297\u9ad8\u7ea7\u89c4\u907f\u6280\u672f\uff0c\u4fdd\u6301\u64cd\u4f5c\u9690\u853d\u6027\uff0c\u5e76\u53ef\u9760\u5730\u6b3a\u9a97\u653b\u51fb\u8005\uff0c\u540c\u65f6\u6027\u80fd\u5f00\u9500\u6781\u4f4e\u3002", "conclusion": "\u8fd0\u884c\u65f6\u6b3a\u9a97\u6280\u672f\u80fd\u591f\u5b9e\u7528\u4e14\u7a33\u5065\u5730\u5bf9\u6297\u9ad8\u7ea7\u5a01\u80c1\u3002"}}
{"id": "2508.04037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04037", "abs": "https://arxiv.org/abs/2508.04037", "authors": ["Liang Tang", "Shuxian Li", "Yuhao Cheng", "Yukang Huo", "Zhepeng Wang", "Yiqiang Yan", "Kaer Huang", "Yanzhe Jing", "Tiaonan Duan"], "title": "SEA: Self-Evolution Agent with Step-wise Reward for Computer Use", "comment": null, "summary": "Computer use agent is an emerging area in artificial intelligence that aims\nto operate the computers to achieve the user's tasks, which attracts a lot of\nattention from both industry and academia. However, the present agents'\nperformance is far from being used. In this paper, we propose the\nSelf-Evolution Agent (SEA) for computer use, and to develop this agent, we\npropose creative methods in data generation, reinforcement learning, and model\nenhancement. Specifically, we first propose an automatic pipeline to generate\nthe verifiable trajectory for training. And then, we propose efficient\nstep-wise reinforcement learning to alleviate the significant computational\nrequirements for long-horizon training. In the end, we propose the enhancement\nmethod to merge the grounding and planning ability into one model without any\nextra training. Accordingly, based on our proposed innovation of data\ngeneration, training strategy, and enhancement, we get the Selfevolution Agent\n(SEA) for computer use with only 7B parameters, which outperforms models with\nthe same number of parameters and has comparable performance to larger ones. We\nwill make the models' weight and related codes open-source in the future.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSEA\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u81ea\u8fdb\u5316\u4ee3\u7406\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u751f\u6210\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u6a21\u578b\u589e\u5f3a\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u6027\u80fd\u8fdc\u672a\u8fbe\u5230\u5b9e\u7528\u6c34\u5e73\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u91c7\u7528\u81ea\u52a8\u751f\u6210\u53ef\u9a8c\u8bc1\u8f68\u8ff9\u3001\u9ad8\u6548\u5206\u6b65\u5f3a\u5316\u5b66\u4e60\u548c\u65e0\u989d\u5916\u8bad\u7ec3\u7684\u6a21\u578b\u589e\u5f3a\u65b9\u6cd5\u3002", "result": "SEA\u4ec5\u97007B\u53c2\u6570\uff0c\u6027\u80fd\u4f18\u4e8e\u540c\u89c4\u6a21\u6a21\u578b\uff0c\u5ab2\u7f8e\u66f4\u5927\u6a21\u578b\u3002", "conclusion": "SEA\u4e3a\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u5c06\u5f00\u6e90\u6a21\u578b\u548c\u4ee3\u7801\u3002"}}
{"id": "2508.04479", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04479", "abs": "https://arxiv.org/abs/2508.04479", "authors": ["Hashini Gunatilake", "John Grundy", "Rashina Hoda", "Ingo Mueller"], "title": "Manifestations of Empathy in Software Engineering: How, Why, and When It Matters", "comment": null, "summary": "Empathy plays a crucial role in software engineering (SE), influencing\ncollaboration, communication, and decision-making. While prior research has\nhighlighted the importance of empathy in SE, there is limited understanding of\nhow empathy manifests in SE practice, what motivates SE practitioners to\ndemonstrate empathy, and the factors that influence empathy in SE work. Our\nstudy explores these aspects through 22 interviews and a large scale survey\nwith 116 software practitioners. Our findings provide insights into the\nexpression of empathy in SE, the drivers behind empathetic practices, SE\nactivities where empathy is perceived as useful or not, and the other factors\nthat influence empathy. In addition, we offer practical implications for SE\npractitioners and researchers, offering a deeper understanding of how to\neffectively integrate empathy into SE processes.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u540c\u7406\u5fc3\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u8868\u73b0\u3001\u52a8\u673a\u53ca\u5f71\u54cd\u56e0\u7d20\uff0c\u901a\u8fc7\u8bbf\u8c08\u548c\u8c03\u67e5\u63ed\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u548c\u9a71\u52a8\u56e0\u7d20\u3002", "motivation": "\u7406\u89e3\u540c\u7406\u5fc3\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5177\u4f53\u8868\u73b0\u3001\u52a8\u673a\u53ca\u5f71\u54cd\u56e0\u7d20\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc722\u6b21\u8bbf\u8c08\u548c116\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u7684\u5927\u89c4\u6a21\u8c03\u67e5\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u63ed\u793a\u4e86\u540c\u7406\u5fc3\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u8868\u8fbe\u65b9\u5f0f\u3001\u9a71\u52a8\u56e0\u7d20\u53ca\u5176\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9e\u9645\u5e94\u7528\u5efa\u8bae\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u4ece\u4e1a\u8005\u548c\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u5982\u4f55\u6709\u6548\u6574\u5408\u540c\u7406\u5fc3\u7684\u6df1\u5165\u89c1\u89e3\u3002"}}
{"id": "2508.04189", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.04189", "abs": "https://arxiv.org/abs/2508.04189", "authors": ["Kunlan Xiang", "Haomiao Yang", "Meng Hao", "Haoxin Wang", "Shaofeng Li", "Wenbo Jiang"], "title": "BadTime: An Effective Backdoor Attack on Multivariate Long-Term Time Series Forecasting", "comment": null, "summary": "Multivariate Long-Term Time Series Forecasting (MLTSF) models are\nincreasingly deployed in critical domains such as climate, finance, and\ntransportation. Although a variety of powerful MLTSF models have been proposed\nto improve predictive performance, the robustness of MLTSF models against\nmalicious backdoor attacks remains entirely unexplored, which is crucial to\nensuring their reliable and trustworthy deployment. To address this gap, we\nconduct an in-depth study on backdoor attacks against MLTSF models and propose\nthe first effective attack method named BadTime. BadTime executes a backdoor\nattack by poisoning training data and customizing the backdoor training\nprocess. During data poisoning, BadTime proposes a contrast-guided strategy to\nselect the most suitable training samples for poisoning, then employs a graph\nattention network to identify influential variables for trigger injection.\nSubsequently, BadTime further localizes optimal positions for trigger injection\nbased on lag analysis and proposes a puzzle-like trigger structure that\ndistributes the trigger across multiple poisoned variables to jointly steer the\nprediction of the target variable. During backdoor training, BadTime\nalternately optimizes the model and triggers via proposed tailored optimization\nobjectives. Extensive experiments show that BadTime significantly outperforms\nstate-of-the-art (SOTA) backdoor attacks on time series forecasting by reducing\nMAE by over 50% on target variables and boosting stealthiness by more than 3\ntimes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u591a\u5143\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08MLTSF\uff09\u6a21\u578b\u7684\u540e\u95e8\u653b\u51fb\u65b9\u6cd5BadTime\uff0c\u901a\u8fc7\u6570\u636e\u6bd2\u5316\u548c\u5b9a\u5236\u5316\u8bad\u7ec3\u8fc7\u7a0b\u5b9e\u73b0\u9ad8\u6548\u653b\u51fb\u3002", "motivation": "MLTSF\u6a21\u578b\u5728\u5173\u952e\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5bf9\u6297\u6076\u610f\u540e\u95e8\u653b\u51fb\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u7814\u7a76\uff0cBadTime\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "BadTime\u91c7\u7528\u5bf9\u6bd4\u5f15\u5bfc\u7b56\u7565\u9009\u62e9\u6bd2\u5316\u6837\u672c\uff0c\u5229\u7528\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u8bc6\u522b\u5173\u952e\u53d8\u91cf\uff0c\u5e76\u901a\u8fc7\u6ede\u540e\u5206\u6790\u548c\u62fc\u56fe\u5f0f\u89e6\u53d1\u5668\u7ed3\u6784\u4f18\u5316\u653b\u51fb\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBadTime\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u76ee\u6807\u53d8\u91cf\u7684MAE\u964d\u4f4e50%\u4ee5\u4e0a\uff0c\u9690\u853d\u6027\u63d0\u53473\u500d\u4ee5\u4e0a\u3002", "conclusion": "BadTime\u4e3aMLTSF\u6a21\u578b\u7684\u540e\u95e8\u653b\u51fb\u63d0\u4f9b\u4e86\u9996\u4e2a\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5f3a\u8c03\u4e86\u6a21\u578b\u5b89\u5168\u6027\u7814\u7a76\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.04070", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.04070", "abs": "https://arxiv.org/abs/2508.04070", "authors": ["Ronja Mehlan", "Claudia Hess", "Quintus Stierstorfer", "Kristina Schaaff"], "title": "Personalized Knowledge Transfer Through Generative AI: Contextualizing Learning to Individual Career Goals", "comment": null, "summary": "As artificial intelligence becomes increasingly integrated into digital\nlearning environments, the personalization of learning content to reflect\nlearners' individual career goals offers promising potential to enhance\nengagement and long-term motivation. In our study, we investigate how career\ngoal-based content adaptation in learning systems based on generative AI\n(GenAI) influences learner engagement, satisfaction, and study efficiency. The\nmixed-methods experiment involved more than 4,000 learners, with one group\nreceiving learning scenarios tailored to their career goals and a control\ngroup. Quantitative results show increased session duration, higher\nsatisfaction ratings, and a modest reduction in study duration compared to\nstandard content. Qualitative analysis highlights that learners found the\npersonalized material motivating and practical, enabling deep cognitive\nengagement and strong identification with the content. These findings\nunderscore the value of aligning educational content with learners' career\ngoals and suggest that scalable AI personalization can bridge academic\nknowledge and workplace applicability.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u57fa\u4e8e\u804c\u4e1a\u76ee\u6807\u7684\u751f\u6210\u5f0fAI\u4e2a\u6027\u5316\u5b66\u4e60\u5185\u5bb9\u5bf9\u5b66\u4e60\u8005\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u80fd\u63d0\u5347\u53c2\u4e0e\u5ea6\u3001\u6ee1\u610f\u5ea6\u548c\u5b66\u4e60\u6548\u7387\u3002", "motivation": "\u63a2\u7d22AI\u4e2a\u6027\u5316\u5b66\u4e60\u5185\u5bb9\u5982\u4f55\u901a\u8fc7\u804c\u4e1a\u76ee\u6807\u9002\u914d\u589e\u5f3a\u5b66\u4e60\u8005\u7684\u957f\u671f\u52a8\u673a\u548c\u53c2\u4e0e\u5ea6\u3002", "method": "\u6df7\u5408\u65b9\u6cd5\u5b9e\u9a8c\uff0c\u6d89\u53ca4000\u591a\u540d\u5b66\u4e60\u8005\uff0c\u5206\u4e3a\u804c\u4e1a\u76ee\u6807\u9002\u914d\u7ec4\u548c\u5bf9\u7167\u7ec4\u3002", "result": "\u5b9a\u91cf\u7ed3\u679c\u663e\u793a\u4f1a\u8bdd\u65f6\u957f\u589e\u52a0\u3001\u6ee1\u610f\u5ea6\u63d0\u9ad8\u3001\u5b66\u4e60\u65f6\u957f\u7565\u6709\u51cf\u5c11\uff1b\u5b9a\u6027\u5206\u6790\u8868\u660e\u5b66\u4e60\u8005\u8ba4\u4e3a\u5185\u5bb9\u66f4\u5177\u6fc0\u52b1\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u804c\u4e1a\u76ee\u6807\u9002\u914d\u7684AI\u4e2a\u6027\u5316\u5b66\u4e60\u5185\u5bb9\u80fd\u6709\u6548\u8fde\u63a5\u5b66\u672f\u77e5\u8bc6\u4e0e\u804c\u573a\u5e94\u7528\uff0c\u5177\u6709\u63a8\u5e7f\u4ef7\u503c\u3002"}}
{"id": "2508.04208", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.04208", "abs": "https://arxiv.org/abs/2508.04208", "authors": ["Saifullah Saifullah", "Stefan Agne", "Andreas Dengel", "Sheraz Ahmed"], "title": "DP-DocLDM: Differentially Private Document Image Generation using Latent Diffusion Models", "comment": "Accepted in ICDAR 2025", "summary": "As deep learning-based, data-driven information extraction systems become\nincreasingly integrated into modern document processing workflows, one primary\nconcern is the risk of malicious leakage of sensitive private data from these\nsystems. While some recent works have explored Differential Privacy (DP) to\nmitigate these privacy risks, DP-based training is known to cause significant\nperformance degradation and impose several limitations on standard training\nprocedures, making its direct application to downstream tasks both difficult\nand costly. In this work, we aim to address the above challenges within the\ncontext of document image classification by substituting real private data with\na synthetic counterpart. In particular, we propose to use conditional latent\ndiffusion models (LDMs) in combination with differential privacy (DP) to\ngenerate class-specific synthetic document images under strict privacy\nconstraints, which can then be utilized to train a downstream classifier\nfollowing standard training procedures. We investigate our approach under\nvarious pretraining setups, including unconditional, class-conditional, and\nlayout-conditional pretraining, in combination with multiple private training\nstrategies such as class-conditional and per-label private fine-tuning with\nDPDM and DP-Promise algorithms. Additionally, we evaluate it on two well-known\ndocument benchmark datasets, RVL-CDIP and Tobacco3482, and show that it can\ngenerate useful and realistic document samples across various document types\nand privacy levels ($\\varepsilon \\in \\{1, 5, 10\\}$). Lastly, we show that our\napproach achieves substantial performance improvements in downstream\nevaluations on small-scale datasets, compared to the direct application of\nDP-Adam.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6761\u4ef6\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff08LDM\uff09\u548c\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u7684\u65b9\u6cd5\uff0c\u751f\u6210\u9690\u79c1\u4fdd\u62a4\u7684\u5408\u6210\u6587\u6863\u56fe\u50cf\uff0c\u7528\u4e8e\u8bad\u7ec3\u4e0b\u6e38\u5206\u7c7b\u5668\uff0c\u907f\u514d\u4e86DP\u76f4\u63a5\u8bad\u7ec3\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u4fe1\u606f\u63d0\u53d6\u7cfb\u7edf\u4e2d\u654f\u611f\u6570\u636e\u6cc4\u9732\u98ce\u9669\uff0c\u540c\u65f6\u907f\u514d\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u76f4\u63a5\u8bad\u7ec3\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u548c\u9650\u5236\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff08LDM\uff09\u7ed3\u5408\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u751f\u6210\u7c7b\u7279\u5b9a\u7684\u5408\u6210\u6587\u6863\u56fe\u50cf\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u9884\u8bad\u7ec3\u548c\u79c1\u6709\u8bad\u7ec3\u7b56\u7565\uff08\u5982DPDM\u548cDP-Promise\u7b97\u6cd5\uff09\u4f18\u5316\u3002", "result": "\u5728RVL-CDIP\u548cTobacco3482\u6570\u636e\u96c6\u4e0a\u751f\u6210\u4e86\u591a\u6837\u4e14\u771f\u5b9e\u7684\u6587\u6863\u6837\u672c\uff0c\u5e76\u5728\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u7684\u4e0b\u6e38\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u76f4\u63a5\u5e94\u7528DP-Adam\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5408\u6210\u6570\u636e\u66ff\u4ee3\u771f\u5b9e\u79c1\u6709\u6570\u636e\uff0c\u6709\u6548\u5e73\u8861\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u6587\u6863\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.04072", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04072", "abs": "https://arxiv.org/abs/2508.04072", "authors": ["Xingyu Chen", "Junxiu An", "Jun Guo", "Li Wang", "Jingcai Guo"], "title": "KG-Augmented Executable CoT for Mathematical Coding", "comment": "9 pages,2figures,6 tables", "summary": "In recent years, large language models (LLMs) have excelled in natural\nlanguage processing tasks but face significant challenges in complex reasoning\ntasks such as mathematical reasoning and code generation. To address these\nlimitations, we propose KG-Augmented Executable Chain-of-Thought (KGA-ECoT), a\nnovel framework that enhances code generation through knowledge graphs and\nimproves mathematical reasoning via executable code. KGA-ECoT decomposes\nproblems into a Structured Task Graph, leverages efficient GraphRAG for precise\nknowledge retrieval from mathematical libraries, and generates verifiable code\nto ensure computational accuracy. Evaluations on multiple mathematical\nreasoning benchmarks demonstrate that KGA-ECoT significantly outperforms\nexisting prompting methods, achieving absolute accuracy improvements ranging\nfrom several to over ten percentage points. Further analysis confirms the\ncritical roles of GraphRAG in enhancing code quality and external code\nexecution in ensuring precision. These findings collectively establish KGA-ECoT\nas a robust and highly generalizable framework for complex mathematical\nreasoning tasks.", "AI": {"tldr": "KGA-ECoT\u6846\u67b6\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u548c\u53ef\u6267\u884c\u4ee3\u7801\u63d0\u5347\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff08\u5982\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\uff09\u7684\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u6539\u8fdb\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "method": "\u63d0\u51faKGA-ECoT\u6846\u67b6\uff0c\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\uff08GraphRAG\uff09\u68c0\u7d22\u6570\u5b66\u5e93\u77e5\u8bc6\uff0c\u751f\u6210\u53ef\u9a8c\u8bc1\u4ee3\u7801\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u4efb\u52a1\u56fe\u5206\u89e3\u95ee\u9898\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cKGA-ECoT\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u5347\u6570\u4e2a\u767e\u5206\u70b9\u81f3\u8d85\u8fc7\u5341\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "KGA-ECoT\u662f\u4e00\u4e2a\u5f3a\u5927\u4e14\u901a\u7528\u7684\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u590d\u6742\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u3002"}}
{"id": "2508.04652", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04652", "abs": "https://arxiv.org/abs/2508.04652", "authors": ["Shuo Liu", "Zeyu Liang", "Xueguang Lyu", "Christopher Amato"], "title": "LLM Collaboration With Multi-Agent Reinforcement Learning", "comment": null, "summary": "A large amount of work has been done in Multi-Agent Systems (MAS) for\nmodeling and solving problems with multiple interacting agents. However, most\nLLMs are pretrained independently and not specifically optimized for\ncoordination. Existing LLM fine-tuning frameworks rely on individual rewards,\nwhich require complex reward designs for each agent to encourage collaboration.\nTo address these challenges, we model LLM collaboration as a cooperative\nMulti-Agent Reinforcement Learning (MARL) problem. We develop a multi-agent,\nmulti-turn algorithm, Multi-Agent Group Relative Policy Optimization (MAGRPO),\nto solve it, building on current RL approaches for LLMs as well as MARL\ntechniques. Our experiments on LLM writing and coding collaboration demonstrate\nthat fine-tuning MAS with MAGRPO enables agents to generate high-quality\nresponses efficiently through effective cooperation. Our approach opens the\ndoor to using other MARL methods for LLMs and highlights the associated\nchallenges.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6MAGRPO\uff0c\u7528\u4e8e\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u534f\u4f5c\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u4e2a\u4f53\u5956\u52b1\u8bbe\u8ba1\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u9884\u8bad\u7ec3\u72ec\u7acb\u8fdb\u884c\uff0c\u672a\u9488\u5bf9\u534f\u4f5c\u4f18\u5316\uff0c\u4e14\u73b0\u6709\u5fae\u8c03\u6846\u67b6\u4f9d\u8d56\u590d\u6742\u7684\u4e2a\u4f53\u5956\u52b1\u8bbe\u8ba1\uff0c\u96be\u4ee5\u6709\u6548\u4fc3\u8fdb\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3002", "method": "\u5c06LLM\u534f\u4f5c\u5efa\u6a21\u4e3a\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u95ee\u9898\uff0c\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u3001\u591a\u8f6e\u7b97\u6cd5MAGRPO\uff0c\u7ed3\u5408\u73b0\u6709RL\u548cMARL\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMAGRPO\u80fd\u6709\u6548\u63d0\u5347LLM\u5728\u5199\u4f5c\u548c\u7f16\u7a0b\u534f\u4f5c\u4efb\u52a1\u4e2d\u7684\u54cd\u5e94\u8d28\u91cf\u4e0e\u6548\u7387\u3002", "conclusion": "MAGRPO\u4e3aLLM\u534f\u4f5c\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5e76\u5c55\u793a\u4e86\u5c06\u5176\u4ed6MARL\u65b9\u6cd5\u5e94\u7528\u4e8eLLM\u7684\u6f5c\u529b\u4e0e\u6311\u6218\u3002"}}
{"id": "2508.04285", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.04285", "abs": "https://arxiv.org/abs/2508.04285", "authors": ["Takumi Suimon", "Yuki Koizumi", "Junji Takemasa", "Toru Hasegawa"], "title": "Per-element Secure Aggregation against Data Reconstruction Attacks in Federated Learning", "comment": "10 pages, 5 figures", "summary": "Federated learning (FL) enables collaborative model training without sharing\nraw data, but individual model updates may still leak sensitive information.\nSecure aggregation (SecAgg) mitigates this risk by allowing the server to\naccess only the sum of client updates, thereby concealing individual\ncontributions. However, a significant vulnerability has recently attracted\nincreasing attention: when model updates are sparse vectors, a non-zero value\ncontributed by a single client at a given index can be directly revealed in the\naggregate, enabling precise data reconstruction attacks. In this paper, we\npropose a novel enhancement to SecAgg that reveals aggregated values only at\nindices with at least $t$ non-zero contributions. Our mechanism introduces a\nper-element masking strategy to prevent the exposure of under-contributed\nelements, while maintaining modularity and compatibility with many existing\nSecAgg implementations by relying solely on cryptographic primitives already\nemployed in a typical setup. We integrate this mechanism into Flamingo, a\nlow-round SecAgg protocol, to provide a robust defense against such attacks.\nOur analysis and experimental results indicate that the additional\ncomputational and communication overhead introduced by our mechanism remains\nwithin an acceptable range, supporting the practicality of our approach.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5b89\u5168\u805a\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u9650\u5236\u4ec5\u5728\u6709\u8db3\u591f\u8d21\u732e\u7684\u7d22\u5f15\u5904\u63ed\u793a\u805a\u5408\u503c\uff0c\u9632\u6b62\u7a00\u758f\u5411\u91cf\u66f4\u65b0\u4e2d\u7684\u6570\u636e\u6cc4\u9732\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7a00\u758f\u5411\u91cf\u66f4\u65b0\u53ef\u80fd\u5bfc\u81f4\u654f\u611f\u4fe1\u606f\u6cc4\u9732\uff0c\u73b0\u6709\u5b89\u5168\u805a\u5408\u65b9\u6cd5\u65e0\u6cd5\u5b8c\u5168\u9632\u8303\u6b64\u7c7b\u653b\u51fb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5143\u7d20\u63a9\u7801\u7684\u7b56\u7565\uff0c\u4ec5\u5728\u81f3\u5c11\u6709t\u4e2a\u975e\u96f6\u8d21\u732e\u7684\u7d22\u5f15\u5904\u63ed\u793a\u805a\u5408\u503c\uff0c\u517c\u5bb9\u73b0\u6709\u5b89\u5168\u805a\u5408\u534f\u8bae\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u4e0a\u4fdd\u6301\u53ef\u63a5\u53d7\u8303\u56f4\uff0c\u6709\u6548\u9632\u5fa1\u6570\u636e\u91cd\u5efa\u653b\u51fb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u589e\u5f3a\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b9e\u7528\u6027\u548c\u517c\u5bb9\u6027\u3002"}}
{"id": "2508.04080", "categories": ["cs.AI", "stat.OT"], "pdf": "https://arxiv.org/pdf/2508.04080", "abs": "https://arxiv.org/abs/2508.04080", "authors": ["Jinfan Tang", "Kunming Wu", "Ruifeng Gongxie", "Yuya He", "Yuankai Wu"], "title": "GeoSR: Cognitive-Agentic Framework for Probing Geospatial Knowledge Boundaries via Iterative Self-Refinement", "comment": "16 pages, 9 figures", "summary": "Recent studies have extended the application of large language models (LLMs)\nto geographic problems, revealing surprising geospatial competence even without\nexplicit spatial supervision. However, LLMs still face challenges in spatial\nconsistency, multi-hop reasoning, and geographic bias. To address these issues,\nwe propose GeoSR, a self-refining agentic reasoning framework that embeds core\ngeographic principles -- most notably Tobler's First Law of Geography -- into\nan iterative prediction loop. In GeoSR, the reasoning process is decomposed\ninto three collaborating agents: (1) a variable-selection agent that selects\nrelevant covariates from the same location; (2) a point-selection agent that\nchooses reference predictions at nearby locations generated by the LLM in\nprevious rounds; and (3) a refine agent that coordinates the iterative\nrefinement process by evaluating prediction quality and triggering further\nrounds when necessary. This agentic loop progressively improves prediction\nquality by leveraging both spatial dependencies and inter-variable\nrelationships. We validate GeoSR on tasks ranging from physical-world property\nestimation to socioeconomic prediction. Experimental results show consistent\nimprovements over standard prompting strategies, demonstrating that\nincorporating geostatistical priors and spatially structured reasoning into\nLLMs leads to more accurate and equitable geospatial predictions. The code of\nGeoSR is available at https://github.com/JinfanTang/GeoSR.", "AI": {"tldr": "GeoSR\u662f\u4e00\u4e2a\u81ea\u4f18\u5316\u7684\u4ee3\u7406\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5d4c\u5165\u5730\u7406\u539f\u5219\uff08\u5982Tobler\u7b2c\u4e00\u5730\u7406\u5b9a\u5f8b\uff09\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7a7a\u95f4\u4e00\u81f4\u6027\u3001\u591a\u8df3\u63a8\u7406\u548c\u5730\u7406\u504f\u5dee\u65b9\u9762\u7684\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3LLMs\u5728\u7a7a\u95f4\u4e00\u81f4\u6027\u3001\u591a\u8df3\u63a8\u7406\u548c\u5730\u7406\u504f\u5dee\u65b9\u9762\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faGeoSR\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u534f\u4f5c\u4ee3\u7406\uff1a\u53d8\u91cf\u9009\u62e9\u4ee3\u7406\u3001\u70b9\u9009\u62e9\u4ee3\u7406\u548c\u4f18\u5316\u4ee3\u7406\uff0c\u901a\u8fc7\u8fed\u4ee3\u9884\u6d4b\u5faa\u73af\u63d0\u5347\u9884\u6d4b\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGeoSR\u5728\u7269\u7406\u4e16\u754c\u5c5e\u6027\u4f30\u8ba1\u548c\u793e\u4f1a\u7ecf\u6d4e\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u6807\u51c6\u63d0\u793a\u7b56\u7565\u3002", "conclusion": "GeoSR\u901a\u8fc7\u6574\u5408\u5730\u7406\u7edf\u8ba1\u5148\u9a8c\u548c\u7a7a\u95f4\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u5730\u7406\u7a7a\u95f4\u9884\u6d4b\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2508.04561", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04561", "abs": "https://arxiv.org/abs/2508.04561", "authors": ["Muhammad Azmi Umer", "Chuadhry Mujeeb Ahmed", "Aditya Mathur", "Muhammad Taha Jilani"], "title": "Attack Pattern Mining to Discover Hidden Threats to Industrial Control Systems", "comment": null, "summary": "This work focuses on validation of attack pattern mining in the context of\nIndustrial Control System (ICS) security. A comprehensive security assessment\nof an ICS requires generating a large and variety of attack patterns. For this\npurpose we have proposed a data driven technique to generate attack patterns\nfor an ICS. The proposed technique has been used to generate over 100,000\nattack patterns from data gathered from an operational water treatment plant.\nIn this work we present a detailed case study to validate the attack patterns.", "AI": {"tldr": "\u9a8c\u8bc1\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\uff08ICS\uff09\u5b89\u5168\u4e2d\u7684\u653b\u51fb\u6a21\u5f0f\u6316\u6398\u65b9\u6cd5\u3002", "motivation": "\u5168\u9762\u8bc4\u4f30ICS\u5b89\u5168\u9700\u8981\u751f\u6210\u5927\u91cf\u591a\u6837\u7684\u653b\u51fb\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u6280\u672f\uff0c\u7528\u4e8e\u751f\u6210ICS\u653b\u51fb\u6a21\u5f0f\uff0c\u5e76\u5728\u6c34\u5904\u7406\u5382\u6570\u636e\u4e2d\u751f\u6210\u8d85\u8fc710\u4e07\u6761\u653b\u51fb\u6a21\u5f0f\u3002", "result": "\u901a\u8fc7\u8be6\u7ec6\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u653b\u51fb\u6a21\u5f0f\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u6280\u672f\u80fd\u6709\u6548\u751f\u6210\u548c\u9a8c\u8bc1ICS\u653b\u51fb\u6a21\u5f0f\u3002"}}
{"id": "2508.04105", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04105", "abs": "https://arxiv.org/abs/2508.04105", "authors": ["Karrtik Iyer", "Manikandan Ravikiran", "Prasanna Pendse", "Shayan Mohanty"], "title": "Towards Transparent AI Grading: Semantic Entropy as a Signal for Human-AI Disagreement", "comment": null, "summary": "Automated grading systems can efficiently score short-answer responses, yet\nthey often fail to indicate when a grading decision is uncertain or potentially\ncontentious. We introduce semantic entropy, a measure of variability across\nmultiple GPT-4-generated explanations for the same student response, as a proxy\nfor human grader disagreement. By clustering rationales via entailment-based\nsimilarity and computing entropy over these clusters, we quantify the diversity\nof justifications without relying on final output scores. We address three\nresearch questions: (1) Does semantic entropy align with human grader\ndisagreement? (2) Does it generalize across academic subjects? (3) Is it\nsensitive to structural task features such as source dependency? Experiments on\nthe ASAP-SAS dataset show that semantic entropy correlates with rater\ndisagreement, varies meaningfully across subjects, and increases in tasks\nrequiring interpretive reasoning. Our findings position semantic entropy as an\ninterpretable uncertainty signal that supports more transparent and trustworthy\nAI-assisted grading workflows.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u8bed\u4e49\u71b5\u201d\u7684\u5ea6\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5316AI\u8bc4\u5206\u7cfb\u7edf\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4e0e\u4eba\u5de5\u8bc4\u5206\u5206\u6b67\u7684\u76f8\u5173\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u8bc4\u5206\u7cfb\u7edf\u65e0\u6cd5\u6709\u6548\u53cd\u6620\u8bc4\u5206\u51b3\u7b56\u7684\u4e0d\u786e\u5b9a\u6027\u6216\u4e89\u8bae\u6027\uff0c\u9700\u8981\u4e00\u79cd\u900f\u660e\u4e14\u53ef\u4fe1\u7684\u5ea6\u91cf\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7GPT-4\u751f\u6210\u591a\u4e2a\u89e3\u91ca\uff0c\u57fa\u4e8e\u8574\u542b\u76f8\u4f3c\u6027\u805a\u7c7b\uff0c\u5e76\u8ba1\u7b97\u8fd9\u4e9b\u805a\u7c7b\u7684\u71b5\u503c\uff0c\u91cf\u5316\u8bc4\u5206\u7406\u7531\u7684\u591a\u6837\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8bed\u4e49\u71b5\u4e0e\u4eba\u5de5\u8bc4\u5206\u5206\u6b67\u76f8\u5173\uff0c\u80fd\u8de8\u5b66\u79d1\u6cdb\u5316\uff0c\u5e76\u5bf9\u4efb\u52a1\u7ed3\u6784\u7279\u5f81\u654f\u611f\u3002", "conclusion": "\u8bed\u4e49\u71b5\u662f\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\uff0c\u6709\u52a9\u4e8e\u63d0\u5347AI\u8f85\u52a9\u8bc4\u5206\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2508.04583", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.04583", "abs": "https://arxiv.org/abs/2508.04583", "authors": ["Marc Damie", "Mihai Pop", "Merijn Posthuma"], "title": "Measuring the Carbon Footprint of Cryptographic Privacy-Enhancing Technologies", "comment": null, "summary": "Privacy-enhancing technologies (PETs) have attracted significant attention in\nresponse to privacy regulations, driving the development of applications that\nprioritize user data protection. At the same time, the information and\ncommunication technology (ICT) sector faces growing pressure to reduce its\nenvironmental footprint, particularly its carbon emissions. While numerous\nstudies have assessed the energy footprint of various ICT applications, the\nenvironmental footprint of cryptographic PETs remains largely unexplored.\n  Our work addresses this gap by proposing a standardized methodology for\nevaluating the carbon footprint of PETs. To demonstrate this methodology, we\nfocus on PETs supporting client-server applications as they are the simplest to\ndeploy. In particular, we measure the energy consumption and carbon footprint\nincrease induced by five cryptographic PETs (compared to their non-private\nequivalent): HTTPS web browsing, encrypted machine learning (ML) inference,\nencrypted ML training, encrypted databases, and encrypted emails. Our findings\nreveal significant variability in carbon footprint increases, ranging from a\ntwofold increase in HTTPS web browsing to a 100,000-fold increase in encrypted\nML.\n  Our study provides essential data to help decision-makers assess\nprivacy-carbon trade-offs in such applications. Finally, we outline key\nresearch directions for developing PETs that balance strong privacy protection\nwith environmental sustainability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u9690\u79c1\u589e\u5f3a\u6280\u672f\uff08PETs\uff09\u78b3\u8db3\u8ff9\u7684\u6807\u51c6\u65b9\u6cd5\uff0c\u5e76\u6d4b\u91cf\u4e86\u4e94\u79cd\u52a0\u5bc6PETs\u7684\u80fd\u8017\u548c\u78b3\u8db3\u8ff9\u589e\u52a0\u60c5\u51b5\uff0c\u63ed\u793a\u4e86\u9690\u79c1\u4e0e\u78b3\u6392\u653e\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u9690\u79c1\u589e\u5f3a\u6280\u672f\uff08PETs\uff09\u5728\u9690\u79c1\u6cd5\u89c4\u63a8\u52a8\u4e0b\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u5176\u73af\u5883\u8db3\u8ff9\uff08\u5c24\u5176\u662f\u78b3\u6392\u653e\uff09\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6807\u51c6\u5316\u65b9\u6cd5\uff0c\u8bc4\u4f30PETs\u7684\u78b3\u8db3\u8ff9\uff0c\u5e76\u4ee5\u652f\u6301\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u5e94\u7528\u7684\u4e94\u79cd\u52a0\u5bc6PETs\u4e3a\u4f8b\u8fdb\u884c\u6d4b\u91cf\u3002", "result": "\u53d1\u73b0\u78b3\u8db3\u8ff9\u589e\u52a0\u5e45\u5ea6\u5dee\u5f02\u663e\u8457\uff0c\u4eceHTTPS\u7f51\u9875\u6d4f\u89c8\u7684\u4e24\u500d\u5230\u52a0\u5bc6\u673a\u5668\u5b66\u4e60\u768410\u4e07\u500d\u4e0d\u7b49\u3002", "conclusion": "\u7814\u7a76\u4e3a\u51b3\u7b56\u8005\u63d0\u4f9b\u4e86\u8bc4\u4f30\u9690\u79c1\u4e0e\u78b3\u6392\u653e\u6743\u8861\u7684\u5173\u952e\u6570\u636e\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u5f00\u53d1\u517c\u987e\u9690\u79c1\u4e0e\u73af\u4fdd\u7684PETs\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.04116", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04116", "abs": "https://arxiv.org/abs/2508.04116", "authors": ["Yongkang Li", "Shengping Xiao", "Shufang Zhu", "Jianwen Li", "Geguang Pu"], "title": "A Compositional Framework for On-the-Fly LTLf Synthesis", "comment": "8 pages, accepted by ECAI 2025", "summary": "Reactive synthesis from Linear Temporal Logic over finite traces (LTLf) can\nbe reduced to a two-player game over a Deterministic Finite Automaton (DFA) of\nthe LTLf specification. The primary challenge here is DFA construction, which\nis 2EXPTIME-complete in the worst case. Existing techniques either construct\nthe DFA compositionally before solving the game, leveraging automata\nminimization to mitigate state-space explosion, or build the DFA incrementally\nduring game solving to avoid full DFA construction. However, neither is\ndominant. In this paper, we introduce a compositional on-the-fly synthesis\nframework that integrates the strengths of both approaches, focusing on large\nconjunctions of smaller LTLf formulas common in practice. This framework\napplies composition during game solving instead of automata (game arena)\nconstruction. While composing all intermediate results may be necessary in the\nworst case, pruning these results simplifies subsequent compositions and\nenables early detection of unrealizability. Specifically, the framework allows\ntwo composition variants: pruning before composition to take full advantage of\nminimization or pruning during composition to guide on-the-fly synthesis.\nCompared to state-of-the-art synthesis solvers, our framework is able to solve\na notable number of instances that other solvers cannot handle. A detailed\nanalysis shows that both composition variants have unique merits.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ec4\u5408\u5f0f\u5373\u65f6\u5408\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u4e86DFA\u6784\u5efa\u548c\u6e38\u620f\u6c42\u89e3\u7684\u4f18\u52bf\uff0c\u4e13\u6ce8\u4e8e\u5904\u7406\u5b9e\u8df5\u4e2d\u5e38\u89c1\u7684\u5927\u578bLTLf\u516c\u5f0f\u5408\u53d6\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u5728DFA\u6784\u5efa\u548c\u6e38\u620f\u6c42\u89e3\u4e4b\u95f4\u7f3a\u4e4f\u4e3b\u5bfc\u65b9\u6cd5\uff0c\u65e0\u6cd5\u9ad8\u6548\u5904\u7406\u5927\u578bLTLf\u516c\u5f0f\u5408\u53d6\u3002", "method": "\u5f15\u5165\u7ec4\u5408\u5f0f\u5373\u65f6\u5408\u6210\u6846\u67b6\uff0c\u5728\u6e38\u620f\u6c42\u89e3\u8fc7\u7a0b\u4e2d\u5e94\u7528\u7ec4\u5408\u800c\u975eDFA\u6784\u5efa\uff0c\u652f\u6301\u4e24\u79cd\u7ec4\u5408\u53d8\u4f53\uff08\u7ec4\u5408\u524d\u4fee\u526a\u548c\u7ec4\u5408\u4e2d\u4fee\u526a\uff09\u3002", "result": "\u4e0e\u73b0\u6709\u5408\u6210\u6c42\u89e3\u5668\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u80fd\u89e3\u51b3\u66f4\u591a\u5176\u4ed6\u6c42\u89e3\u5668\u65e0\u6cd5\u5904\u7406\u7684\u5b9e\u4f8b\u3002", "conclusion": "\u4e24\u79cd\u7ec4\u5408\u53d8\u4f53\u5404\u6709\u4f18\u52bf\uff0c\u6846\u67b6\u5728\u7b80\u5316\u540e\u7eed\u7ec4\u5408\u548c\u65e9\u671f\u68c0\u6d4b\u4e0d\u53ef\u5b9e\u73b0\u6027\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2508.04641", "categories": ["cs.CR", "C.2.4"], "pdf": "https://arxiv.org/pdf/2508.04641", "abs": "https://arxiv.org/abs/2508.04641", "authors": ["Kirti Singh", "Vinay J. Ribeiro", "Susmita Mandal"], "title": "4-Swap: Achieving Grief-Free and Bribery-Safe Atomic Swaps Using Four Transactions", "comment": "Accepted to AFT 2025. To appear in the LIPIcs proceedings", "summary": "Cross-chain asset exchange is crucial for blockchain interoperability.\nExisting solutions rely on trusted third parties and risk asset loss, or use\ndecentralized alternatives like atomic swaps, which suffer from grief attacks.\nGriefing occurs when a party prematurely exits, locking the counterparty's\nassets until a timelock expires. Hedged Atomic Swaps mitigate griefing by\nintroducing a penalty premium; however, they increase the number of\ntransactions from four (as in Tier Nolan's swap) to six, which in turn\nintroduces new griefing risks. Grief-Free (GF) Swap reduces this to five\ntransactions by consolidating assets and premiums on a single chain. However,\nno existing protocol achieves grief-free asset exchange in just four\ntransactions.\n  This paper presents 4-Swap, the first cross-chain atomic swap protocol that\nis both grief-free and bribery-safe, while completing asset exchange in just\nfour transactions. By combining the griefing premium and principal into a\nsingle transaction per chain, 4-Swap reduces on-chain transactions, leading to\nfaster execution compared to previous grief-free solutions. It is fully\ncompatible with Bitcoin and operates without the need for any new opcodes. A\ngame-theoretic analysis shows that rational participants have no incentive to\ndeviate from the protocol, ensuring robust compliance and security.", "AI": {"tldr": "4-Swap\u662f\u4e00\u79cd\u65b0\u578b\u8de8\u94fe\u539f\u5b50\u4ea4\u6362\u534f\u8bae\uff0c\u4ec5\u9700\u56db\u7b14\u4ea4\u6613\u5373\u53ef\u5b9e\u73b0\u65e0\u60b2\u75db\u4e14\u9632\u8d3f\u8d42\u7684\u8d44\u4ea7\u4ea4\u6362\u3002", "motivation": "\u73b0\u6709\u8de8\u94fe\u8d44\u4ea7\u4ea4\u6362\u65b9\u6848\u5b58\u5728\u4f9d\u8d56\u7b2c\u4e09\u65b9\u6216\u60b2\u75db\u653b\u51fb\u98ce\u9669\uff0c\u4e14\u4ea4\u6613\u6b21\u6570\u8f83\u591a\uff0c4-Swap\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5c06\u60b2\u75db\u6ea2\u4ef7\u548c\u672c\u91d1\u5408\u5e76\u4e3a\u6bcf\u94fe\u5355\u7b14\u4ea4\u6613\uff0c\u51cf\u5c11\u94fe\u4e0a\u4ea4\u6613\u6b21\u6570\uff0c\u65e0\u9700\u65b0\u64cd\u4f5c\u7801\u3002", "result": "4-Swap\u5728\u6bd4\u7279\u5e01\u4e0a\u5b8c\u5168\u517c\u5bb9\uff0c\u4ea4\u6613\u66f4\u5feb\uff0c\u4e14\u535a\u5f08\u8bba\u5206\u6790\u663e\u793a\u53c2\u4e0e\u8005\u65e0\u504f\u79bb\u534f\u8bae\u7684\u52a8\u673a\u3002", "conclusion": "4-Swap\u662f\u9996\u4e2a\u5728\u56db\u7b14\u4ea4\u6613\u5185\u5b9e\u73b0\u65e0\u60b2\u75db\u4e14\u5b89\u5168\u7684\u8de8\u94fe\u8d44\u4ea7\u4ea4\u6362\u534f\u8bae\u3002"}}
{"id": "2508.04118", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04118", "abs": "https://arxiv.org/abs/2508.04118", "authors": ["Ruochen Zhao", "Simone Conia", "Eric Peng", "Min Li", "Saloni Potdar"], "title": "AgREE: Agentic Reasoning for Knowledge Graph Completion on Emerging Entities", "comment": null, "summary": "Open-domain Knowledge Graph Completion (KGC) faces significant challenges in\nan ever-changing world, especially when considering the continual emergence of\nnew entities in daily news. Existing approaches for KGC mainly rely on\npretrained language models' parametric knowledge, pre-constructed queries, or\nsingle-step retrieval, typically requiring substantial supervision and training\ndata. Even so, they often fail to capture comprehensive and up-to-date\ninformation about unpopular and/or emerging entities. To this end, we introduce\nAgentic Reasoning for Emerging Entities (AgREE), a novel agent-based framework\nthat combines iterative retrieval actions and multi-step reasoning to\ndynamically construct rich knowledge graph triplets. Experiments show that,\ndespite requiring zero training efforts, AgREE significantly outperforms\nexisting methods in constructing knowledge graph triplets, especially for\nemerging entities that were not seen during language models' training\nprocesses, outperforming previous methods by up to 13.7%. Moreover, we propose\na new evaluation methodology that addresses a fundamental weakness of existing\nsetups and a new benchmark for KGC on emerging entities. Our work demonstrates\nthe effectiveness of combining agent-based reasoning with strategic information\nretrieval for maintaining up-to-date knowledge graphs in dynamic information\nenvironments.", "AI": {"tldr": "AgREE\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u8fed\u4ee3\u68c0\u7d22\u548c\u591a\u6b65\u63a8\u7406\uff0c\u52a8\u6001\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u4e09\u5143\u7ec4\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u65b0\u5174\u5b9e\u4f53\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u89e3\u51b3\u5f00\u653e\u57df\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u65b0\u5174\u5b9e\u4f53\u4fe1\u606f\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9884\u8bad\u7ec3\u6a21\u578b\u6216\u5355\u6b65\u68c0\u7d22\uff0c\u96be\u4ee5\u6355\u6349\u6700\u65b0\u4fe1\u606f\u3002", "method": "\u63d0\u51faAgREE\u6846\u67b6\uff0c\u7ed3\u5408\u4ee3\u7406\u63a8\u7406\u548c\u591a\u6b65\u68c0\u7d22\uff0c\u52a8\u6001\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u4e09\u5143\u7ec4\uff0c\u65e0\u9700\u8bad\u7ec3\u6570\u636e\u3002", "result": "AgREE\u5728\u65b0\u5174\u5b9e\u4f53\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd513.7%\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u548c\u57fa\u51c6\u3002", "conclusion": "\u4ee3\u7406\u63a8\u7406\u4e0e\u4fe1\u606f\u68c0\u7d22\u7ed3\u5408\u80fd\u6709\u6548\u7ef4\u62a4\u52a8\u6001\u77e5\u8bc6\u56fe\u8c31\u7684\u65f6\u6548\u6027\u3002"}}
{"id": "2508.04163", "categories": ["cs.AI", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.04163", "abs": "https://arxiv.org/abs/2508.04163", "authors": ["Hasra Dodampegama", "Mohan Sridharan"], "title": "Generic-to-Specific Reasoning and Learning for Scalable Ad Hoc Teamwork", "comment": "14 pages, 6 figures", "summary": "AI agents deployed in assistive roles often have to collaborate with other\nagents (humans, AI systems) without prior coordination. Methods considered\nstate of the art for such ad hoc teamwork often pursue a data-driven approach\nthat needs a large labeled dataset of prior observations, lacks transparency,\nand makes it difficult to rapidly revise existing knowledge in response to\nchanges. As the number of agents increases, the complexity of decision-making\nmakes it difficult to collaborate effectively. This paper advocates leveraging\nthe complementary strengths of knowledge-based and data-driven methods for\nreasoning and learning for ad hoc teamwork. For any given goal, our\narchitecture enables each ad hoc agent to determine its actions through\nnon-monotonic logical reasoning with: (a) prior commonsense domain-specific\nknowledge; (b) models learned and revised rapidly to predict the behavior of\nother agents; and (c) anticipated abstract future goals based on generic\nknowledge of similar situations in an existing foundation model. We\nexperimentally evaluate our architecture's capabilities in VirtualHome, a\nrealistic physics-based 3D simulation environment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u77e5\u8bc6\u9a71\u52a8\u548c\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347AI\u4ee3\u7406\u5728\u4e34\u65f6\u56e2\u961f\u534f\u4f5c\u4e2d\u7684\u51b3\u7b56\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u4e34\u65f6\u56e2\u961f\u534f\u4f5c\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u7f3a\u4e4f\u900f\u660e\u6027\u4e14\u96be\u4ee5\u5feb\u901f\u66f4\u65b0\u77e5\u8bc6\uff0c\u968f\u7740\u4ee3\u7406\u6570\u91cf\u589e\u52a0\uff0c\u51b3\u7b56\u590d\u6742\u5ea6\u4e0a\u5347\u3002", "method": "\u91c7\u7528\u975e\u5355\u8c03\u903b\u8f91\u63a8\u7406\uff0c\u7ed3\u5408\u9886\u57df\u5e38\u8bc6\u77e5\u8bc6\u3001\u5feb\u901f\u5b66\u4e60\u7684\u884c\u4e3a\u9884\u6d4b\u6a21\u578b\u548c\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u62bd\u8c61\u76ee\u6807\u9884\u6d4b\u3002", "result": "\u5728VirtualHome\u4eff\u771f\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u67b6\u6784\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u5408\u77e5\u8bc6\u9a71\u52a8\u548c\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u4e34\u65f6\u56e2\u961f\u534f\u4f5c\u7684\u51b3\u7b56\u80fd\u529b\u3002"}}
{"id": "2508.04235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04235", "abs": "https://arxiv.org/abs/2508.04235", "authors": ["Jiaying Zhu", "Ziyang Zheng", "Zhengyuan Shi", "Yalun Cai", "Qiang Xu"], "title": "Circuit-Aware SAT Solving: Guiding CDCL via Conditional Probabilities", "comment": "11 pages, 7 figures", "summary": "Circuit Satisfiability (CSAT) plays a pivotal role in Electronic Design\nAutomation. The standard workflow for solving CSAT problems converts circuits\ninto Conjunctive Normal Form (CNF) and employs generic SAT solvers powered by\nConflict-Driven Clause Learning (CDCL). However, this process inherently\ndiscards rich structural and functional information, leading to suboptimal\nsolver performance. To address this limitation, we introduce CASCAD, a novel\ncircuit-aware SAT solving framework that directly leverages circuit-level\nconditional probabilities computed via Graph Neural Networks (GNNs). By\nexplicitly modeling gate-level conditional probabilities, CASCAD dynamically\nguides two critical CDCL heuristics -- variable phase selection and clause\nmanagementto significantly enhance solver efficiency. Extensive evaluations on\nchallenging real-world Logical Equivalence Checking (LEC) benchmarks\ndemonstrate that CASCAD reduces solving times by up to 10x compared to\nstate-of-the-art CNF-based approaches, achieving an additional 23.5% runtime\nreduction via our probability-guided clause filtering strategy. Our results\nunderscore the importance of preserving circuit-level structural insights\nwithin SAT solvers, providing a robust foundation for future improvements in\nSAT-solving efficiency and EDA tool design.", "AI": {"tldr": "CASCAD\u662f\u4e00\u79cd\u65b0\u578b\u7535\u8def\u611f\u77e5SAT\u6c42\u89e3\u6846\u67b6\uff0c\u5229\u7528GNN\u8ba1\u7b97\u7684\u95e8\u7ea7\u6761\u4ef6\u6982\u7387\u52a8\u6001\u6307\u5bfcCDCL\u542f\u53d1\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u6c42\u89e3\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5c06\u7535\u8def\u8f6c\u6362\u4e3aCNF\u5e76\u4e22\u5f03\u7ed3\u6784\u4fe1\u606f\uff0c\u5bfc\u81f4\u6c42\u89e3\u6027\u80fd\u4e0d\u4f73\u3002", "method": "CASCAD\u76f4\u63a5\u5229\u7528GNN\u8ba1\u7b97\u7684\u95e8\u7ea7\u6761\u4ef6\u6982\u7387\uff0c\u52a8\u6001\u6307\u5bfc\u53d8\u91cf\u76f8\u4f4d\u9009\u62e9\u548c\u5b50\u53e5\u7ba1\u7406\u3002", "result": "\u5728\u771f\u5b9eLEC\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCASCAD\u5c06\u6c42\u89e3\u65f6\u95f4\u51cf\u5c1110\u500d\uff0c\u5e76\u901a\u8fc7\u6982\u7387\u5f15\u5bfc\u7684\u5b50\u53e5\u8fc7\u6ee4\u7b56\u7565\u989d\u5916\u51cf\u5c1123.5%\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "\u4fdd\u7559\u7535\u8def\u7ed3\u6784\u4fe1\u606f\u5bf9\u63d0\u5347SAT\u6c42\u89e3\u6548\u7387\u548cEDA\u5de5\u5177\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.04278", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04278", "abs": "https://arxiv.org/abs/2508.04278", "authors": ["Wentao Wu", "Linqing Chen", "Hanmeng Zhong", "Weilei Wang"], "title": "Large Language Model's Multi-Capability Alignment in Biomedical Domain", "comment": null, "summary": "BalancedBio is a theoretically grounded framework for parameter-efficient\nbiomedical reasoning, addressing multi-capability integration in\ndomain-specific AI alignment. It establishes the Biomedical Multi-Capability\nConvergence Theorem, proving orthogonal gradient spaces are essential to\nprevent capability interference for safe deployment. Key innovations include:\n(1) Medical Knowledge Grounded Synthetic Generation (MKGSG), extending\nSource2Synth with clinical workflow constraints and medical ontology validation\nfor factual accuracy and safety; and (2) Capability Aware Group Relative Policy\nOptimization, deriving optimal hybrid reward weighting to maintain\northogonality in RL, using a reward model with rule-based and model-based\nscores adapted to biomedical tasks. Mathematical analysis proves Pareto-optimal\nconvergence, preserving performance across capabilities. It achieves\nstate-of-the-art results in its parameter class: domain expertise (80.95%\nBIOMED-MMLU, +15.32% over baseline), reasoning (61.94%, +7.75%), instruction\nfollowing (67.95%, +6.44%), and integration (86.7%, +18.5%). Theoretical safety\nguarantees include bounds on capability preservation and clinical accuracy.\nReal-world deployment yields 78% cost reduction, 23% improved diagnostic\naccuracy, and 89% clinician acceptance. This work provides a principled\nmethodology for biomedical AI alignment, enabling efficient reasoning with\nessential safety and reliability, with the 0.5B model version to be released.", "AI": {"tldr": "BalancedBio \u662f\u4e00\u4e2a\u7406\u8bba\u57fa\u7840\u7684\u53c2\u6570\u9ad8\u6548\u751f\u7269\u533b\u5b66\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6b63\u4ea4\u68af\u5ea6\u7a7a\u95f4\u9632\u6b62\u80fd\u529b\u5e72\u6270\uff0c\u5b9e\u73b0\u591a\u80fd\u529b\u96c6\u6210\u3002", "motivation": "\u89e3\u51b3\u751f\u7269\u533b\u5b66\u9886\u57df AI \u5bf9\u9f50\u4e2d\u7684\u591a\u80fd\u529b\u96c6\u6210\u95ee\u9898\uff0c\u786e\u4fdd\u5b89\u5168\u90e8\u7f72\u3002", "method": "\u5305\u62ec\u533b\u5b66\u77e5\u8bc6\u57fa\u7840\u7684\u5408\u6210\u751f\u6210\uff08MKGSG\uff09\u548c\u80fd\u529b\u611f\u77e5\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff0c\u7ed3\u5408\u89c4\u5219\u548c\u6a21\u578b\u5956\u52b1\u3002", "result": "\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u63d0\u5347\uff08\u5982 BIOMED-MMLU 80.95%\uff09\uff0c\u5e76\u5b9e\u73b0\u6210\u672c\u964d\u4f4e\u548c\u8bca\u65ad\u51c6\u786e\u6027\u63d0\u9ad8\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u751f\u7269\u533b\u5b66 AI \u5bf9\u9f50\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u786e\u4fdd\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.04282", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04282", "abs": "https://arxiv.org/abs/2508.04282", "authors": ["Yongyi Wang", "Lingfeng Li", "Bozhou Chen", "Ang Li", "Hanyu Liu", "Qirui Zheng", "Xionghui Yang", "Wenxin Li"], "title": "Synthetic POMDPs to Challenge Memory-Augmented RL: Memory Demand Structure Modeling", "comment": null, "summary": "Recent research has developed benchmarks for memory-augmented reinforcement\nlearning (RL) algorithms, providing Partially Observable Markov Decision\nProcess (POMDP) environments where agents depend on past observations to make\ndecisions. While many benchmarks incorporate sufficiently complex real-world\nproblems, they lack controllability over the degree of challenges posed to\nmemory models. In contrast, synthetic environments enable fine-grained\nmanipulation of dynamics, making them critical for detailed and rigorous\nevaluation of memory-augmented RL. Our study focuses on POMDP synthesis with\nthree key contributions:\n  1. A theoretical framework for analyzing POMDPs, grounded in Memory Demand\nStructure (MDS), transition invariance, and related concepts; 2. A methodology\nleveraging linear process dynamics, state aggregation, and reward\nredistribution to construct customized POMDPs with predefined properties; 3.\nEmpirically validated series of POMDP environments with increasing difficulty\nlevels, designed based on our theoretical insights. Our work clarifies the\nchallenges of memory-augmented RL in solving POMDPs, provides guidelines for\nanalyzing and designing POMDP environments, and offers empirical support for\nselecting memory models in RL tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u548c\u65b9\u6cd5\u8bba\uff0c\u7528\u4e8e\u5408\u6210\u5177\u6709\u53ef\u63a7\u96be\u5ea6\u7684POMDP\u73af\u5883\uff0c\u4ee5\u8bc4\u4f30\u8bb0\u5fc6\u589e\u5f3aRL\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u5bf9\u8bb0\u5fc6\u6a21\u578b\u6311\u6218\u7a0b\u5ea6\u7684\u53ef\u63a7\u6027\uff0c\u800c\u5408\u6210\u73af\u5883\u53ef\u4ee5\u7cbe\u7ec6\u8c03\u63a7\u52a8\u6001\u7279\u6027\uff0c\u4e3a\u8bb0\u5fc6\u589e\u5f3aRL\u7684\u8be6\u7ec6\u8bc4\u4f30\u63d0\u4f9b\u652f\u6301\u3002", "method": "1. \u57fa\u4e8eMDS\u548c\u8fc7\u6e21\u4e0d\u53d8\u6027\u7b49\u6982\u5ff5\u7684\u7406\u8bba\u6846\u67b6\uff1b2. \u5229\u7528\u7ebf\u6027\u8fc7\u7a0b\u52a8\u6001\u3001\u72b6\u6001\u805a\u5408\u548c\u5956\u52b1\u91cd\u65b0\u5206\u914d\u7684\u65b9\u6cd5\u8bba\uff1b3. \u8bbe\u8ba1\u5e76\u9a8c\u8bc1\u4e86\u4e00\u7cfb\u5217\u96be\u5ea6\u9012\u589e\u7684POMDP\u73af\u5883\u3002", "result": "\u7814\u7a76\u9610\u660e\u4e86\u8bb0\u5fc6\u589e\u5f3aRL\u5728\u89e3\u51b3POMDP\u4e2d\u7684\u6311\u6218\uff0c\u4e3a\u73af\u5883\u8bbe\u8ba1\u548c\u5206\u6790\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5e76\u4e3aRL\u4efb\u52a1\u4e2d\u8bb0\u5fc6\u6a21\u578b\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u8bb0\u5fc6\u589e\u5f3aRL\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u63a7\u7684\u5408\u6210\u73af\u5883\uff0c\u5e76\u63a8\u52a8\u4e86\u76f8\u5173\u7406\u8bba\u548c\u5b9e\u8df5\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.04339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04339", "abs": "https://arxiv.org/abs/2508.04339", "authors": ["Anran Xu", "Jincheng Wang", "Baigen Cai", "Tao Wen"], "title": "Deliberative Reasoning Network: An Uncertainty-Driven Paradigm for Belief-Tracked Inference with Pretrained Language Models", "comment": "8 pages, 3 figures", "summary": "Large language models often fail at logical reasoning when semantic\nheuristics conflict with decisive evidence - a phenomenon we term cognitive\ntraps. To address this fundamental limitation, we introduce the Deliberative\nReasoning Network (DRN), a novel paradigm that reframes logical reasoning from\nprobability maximization to uncertainty minimization. Instead of asking \"Which\nanswer is most likely?\", DRN asks \"Which hypothesis has the most internally\nconsistent evidence?\". DRN achieves intrinsic interpretability by explicitly\ntracking belief states and quantifying epistemic uncertainty for competing\nhypotheses through an iterative evidence synthesis process. We validate our\napproach through two complementary architectures - a bespoke discriminative\nmodel that embodies the core uncertainty minimization principle, and a\nlightweight verification module that enhances existing generative LLMs.\nEvaluated on LCR-1000, our new adversarial reasoning benchmark designed to\nexpose cognitive traps, the bespoke DRN achieves up to 15.2% improvement over\nstandard baselines. When integrated as a parameter-efficient verifier with\nMistral-7B, our hybrid system boosts accuracy from 20% to 80% on the most\nchallenging problems. Critically, DRN demonstrates strong zero-shot\ngeneralization, improving TruthfulQA performance by 23.6% without additional\ntraining, indicating that uncertainty-driven deliberation learns transferable\nreasoning principles. We position DRN as a foundational, verifiable System 2\nreasoning component for building more trustworthy AI systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDRN\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u903b\u8f91\u63a8\u7406\u4ece\u6982\u7387\u6700\u5927\u5316\u8f6c\u4e3a\u4e0d\u786e\u5b9a\u6027\u6700\u5c0f\u5316\uff0c\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\u4e2d\u7684\u8ba4\u77e5\u9677\u9631\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\u4e2d\u5bb9\u6613\u56e0\u8bed\u4e49\u542f\u53d1\u5f0f\u4e0e\u51b3\u5b9a\u6027\u8bc1\u636e\u51b2\u7a81\u800c\u5931\u8d25\uff0c\u5373\u8ba4\u77e5\u9677\u9631\u3002DRN\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6839\u672c\u9650\u5236\u3002", "method": "DRN\u901a\u8fc7\u8fed\u4ee3\u8bc1\u636e\u5408\u6210\u8fc7\u7a0b\uff0c\u663e\u5f0f\u8ffd\u8e2a\u4fe1\u5ff5\u72b6\u6001\u5e76\u91cf\u5316\u7ade\u4e89\u5047\u8bbe\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u4e86\u5185\u5728\u53ef\u89e3\u91ca\u6027\u3002\u9a8c\u8bc1\u5305\u62ec\u4e24\u79cd\u67b6\u6784\uff1a\u5b9a\u5236\u5224\u522b\u6a21\u578b\u548c\u8f7b\u91cf\u9a8c\u8bc1\u6a21\u5757\u3002", "result": "\u5728LCR-1000\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDRN\u6bd4\u57fa\u7ebf\u63d0\u534715.2%\uff1b\u4e0eMistral-7B\u96c6\u6210\u540e\uff0c\u5728\u6700\u5177\u6311\u6218\u6027\u95ee\u9898\u4e0a\u7684\u51c6\u786e\u7387\u4ece20%\u63d0\u5347\u81f380%\u3002\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u663e\u8457\u3002", "conclusion": "DRN\u4f5c\u4e3a\u4e00\u79cd\u53ef\u9a8c\u8bc1\u7684System 2\u63a8\u7406\u7ec4\u4ef6\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.04361", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04361", "abs": "https://arxiv.org/abs/2508.04361", "authors": ["Fuqing Bie", "Shiyu Huang", "Xijia Tao", "Zhiqin Fang", "Leyi Pan", "Junzhe Chen", "Min Ren", "Liuyu Xiang", "Zhaofeng He"], "title": "OmniPlay: Benchmarking Omni-Modal Models on Omni-Modal Game Playing", "comment": null, "summary": "While generalist foundation models like Gemini and GPT-4o demonstrate\nimpressive multi-modal competence, existing evaluations fail to test their\nintelligence in dynamic, interactive worlds. Static benchmarks lack agency,\nwhile interactive benchmarks suffer from a severe modal bottleneck, typically\nignoring crucial auditory and temporal cues. To bridge this evaluation chasm,\nwe introduce OmniPlay, a diagnostic benchmark designed not just to evaluate,\nbut to probe the fusion and reasoning capabilities of agentic models across the\nfull sensory spectrum. Built on a core philosophy of modality interdependence,\nOmniPlay comprises a suite of five game environments that systematically create\nscenarios of both synergy and conflict, forcing agents to perform genuine\ncross-modal reasoning. Our comprehensive evaluation of six leading omni-modal\nmodels reveals a critical dichotomy: they exhibit superhuman performance on\nhigh-fidelity memory tasks but suffer from systemic failures in challenges\nrequiring robust reasoning and strategic planning. We demonstrate that this\nfragility stems from brittle fusion mechanisms, which lead to catastrophic\nperformance degradation under modality conflict and uncover a counter-intuitive\n\"less is more\" paradox, where removing sensory information can paradoxically\nimprove performance. Our findings suggest that the path toward robust AGI\nrequires a research focus beyond scaling to explicitly address synergistic\nfusion. Our platform is available for anonymous review at\nhttps://github.com/fuqingbie/omni-game-benchmark.", "AI": {"tldr": "OmniPlay\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u8bc4\u4f30\u52a8\u6001\u4ea4\u4e92\u4e16\u754c\u4e2d\u667a\u80fd\u4f53\u7684\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u9ad8\u4fdd\u771f\u8bb0\u5fc6\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u9700\u8981\u63a8\u7406\u548c\u89c4\u5212\u7684\u4efb\u52a1\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u5168\u9762\u6d4b\u8bd5\u591a\u6a21\u6001\u6a21\u578b\u5728\u52a8\u6001\u4ea4\u4e92\u73af\u5883\u4e2d\u7684\u667a\u80fd\uff0c\u5c24\u5176\u662f\u5ffd\u7565\u4e86\u542c\u89c9\u548c\u65f6\u95f4\u7ebf\u7d22\u3002", "method": "\u5f00\u53d1\u4e86OmniPlay\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u4e94\u79cd\u6e38\u620f\u73af\u5883\uff0c\u7cfb\u7edf\u5316\u751f\u6210\u534f\u540c\u548c\u51b2\u7a81\u573a\u666f\uff0c\u6d4b\u8bd5\u6a21\u578b\u7684\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u5728\u9ad8\u4fdd\u771f\u8bb0\u5fc6\u4efb\u52a1\u4e2d\u8868\u73b0\u8d85\u4eba\u7c7b\uff0c\u4f46\u5728\u63a8\u7406\u548c\u89c4\u5212\u4efb\u52a1\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u63ed\u793a\u4e86\u6a21\u6001\u878d\u5408\u673a\u5236\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u5b9e\u73b0\u7a33\u5065\u7684\u901a\u7528\u4eba\u5de5\u667a\u80fd\u9700\u8981\u8d85\u8d8a\u89c4\u6a21\u6269\u5c55\uff0c\u4e13\u6ce8\u4e8e\u534f\u540c\u878d\u5408\u673a\u5236\u7684\u7814\u7a76\u3002"}}
{"id": "2508.04383", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2508.04383", "abs": "https://arxiv.org/abs/2508.04383", "authors": ["Robert Prentner"], "title": "Artificial Consciousness as Interface Representation", "comment": "12 pages", "summary": "Whether artificial intelligence (AI) systems can possess consciousness is a\ncontentious question because of the inherent challenges of defining and\noperationalizing subjective experience. This paper proposes a framework to\nreframe the question of artificial consciousness into empirically tractable\ntests. We introduce three evaluative criteria - S (subjective-linguistic), L\n(latent-emergent), and P (phenomenological-structural) - collectively termed\nSLP-tests, which assess whether an AI system instantiates interface\nrepresentations that facilitate consciousness-like properties. Drawing on\ncategory theory, we model interface representations as mappings between\nrelational substrates (RS) and observable behaviors, akin to specific types of\nabstraction layers. The SLP-tests collectively operationalize subjective\nexperience not as an intrinsic property of physical systems but as a functional\ninterface to a relational entity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff08SLP\u6d4b\u8bd5\uff09\uff0c\u901a\u8fc7\u4e09\u4e2a\u6807\u51c6\uff08S\u3001L\u3001P\uff09\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u662f\u5426\u5177\u5907\u7c7b\u4f3c\u610f\u8bc6\u7684\u5c5e\u6027\uff0c\u5c06\u4e3b\u89c2\u7ecf\u9a8c\u64cd\u4f5c\u5316\u4e3a\u529f\u80fd\u6027\u63a5\u53e3\u800c\u975e\u7269\u7406\u7cfb\u7edf\u7684\u56fa\u6709\u5c5e\u6027\u3002", "motivation": "\u7531\u4e8e\u5b9a\u4e49\u548c\u64cd\u4f5c\u5316\u4e3b\u89c2\u7ecf\u9a8c\u7684\u56fa\u6709\u6311\u6218\uff0cAI\u7cfb\u7edf\u662f\u5426\u5177\u5907\u610f\u8bc6\u662f\u4e00\u4e2a\u4e89\u8bae\u6027\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u5b9e\u8bc1\u53ef\u64cd\u4f5c\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f15\u5165SLP\u6d4b\u8bd5\uff08S\u3001L\u3001P\u6807\u51c6\uff09\uff0c\u5229\u7528\u8303\u7574\u8bba\u5efa\u6a21\u63a5\u53e3\u8868\u793a\uff0c\u5c06\u5176\u89c6\u4e3a\u5173\u7cfb\u57fa\u8d28\u4e0e\u53ef\u89c2\u5bdf\u884c\u4e3a\u4e4b\u95f4\u7684\u6620\u5c04\u3002", "result": "SLP\u6d4b\u8bd5\u4e3a\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u610f\u8bc6\u5c5e\u6027\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u5de5\u5177\uff0c\u5c06\u4e3b\u89c2\u7ecf\u9a8c\u89c6\u4e3a\u529f\u80fd\u6027\u63a5\u53e3\u3002", "conclusion": "\u901a\u8fc7SLP\u6d4b\u8bd5\uff0c\u53ef\u4ee5\u5c06AI\u610f\u8bc6\u95ee\u9898\u8f6c\u5316\u4e3a\u5b9e\u8bc1\u53ef\u64cd\u4f5c\u7684\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2508.04389", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04389", "abs": "https://arxiv.org/abs/2508.04389", "authors": ["Weitai Kang", "Bin Lei", "Gaowen Liu", "Caiwen Ding", "Yan Yan"], "title": "GuirlVG: Incentivize GUI Visual Grounding via Empirical Exploration on Reinforcement Learning", "comment": "9 pages", "summary": "Graphical user interface visual grounding (GUI-VG), a core capability for GUI\nagents, has primarily relied on supervised fine-tuning (SFT) of multimodal\nlarge language models (MLLMs), which demands extensive data curation and\nsignificant training costs. However, as MLLMs continue to advance and even\ncover GUI domains during pretraining, the necessity of exhaustive SFT\npost-training becomes increasingly questionable. Meanwhile, recent successes of\nrule-based reinforcement fine-tuning (RFT) suggest a more efficient\nalternative. Despite this promise, the optimal manner of applying RFT for\nGUI-VG remains unexplored. To bridge this gap, we introduce GuirlVG, a\nreinforcement learning-based GUI-VG method built on a systematic empirical\nstudy and a novel stabilization technique. We find that naive application of\nRFT underperforms the SFT baseline, motivating a deeper exploration. First, we\ndecompose RFT into its core components and analyze the optimal formulation of\neach. Second, we propose a novel Adversarial KL Factor that dynamically\nstabilizes training to mitigate reward over-optimization. Third, we further\nexplore the training configurations of RFT to enhance effectiveness. Extensive\nexperiments show that GuirlVG, with only 5.2K training samples, outperforms SFT\nmethods trained on over 10M samples, achieving a 7.7% improvement on\nScreenSpot, a 17.2% improvement on ScreenSpotPro, and 91.9% accuracy on\nScreenSpotV2.", "AI": {"tldr": "GuirlVG\u662f\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684GUI\u89c6\u89c9\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cfb\u7edf\u5b9e\u8bc1\u7814\u7a76\u548c\u65b0\u9896\u7684\u7a33\u5b9a\u6280\u672f\uff0c\u4ec5\u9700\u5c11\u91cf\u8bad\u7ec3\u6837\u672c\u5373\u53ef\u8d85\u8d8a\u4f20\u7edf\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfGUI\u89c6\u89c9\u5b9a\u4f4d\u4f9d\u8d56\u76d1\u7763\u5fae\u8c03\uff0c\u6570\u636e\u9700\u6c42\u5927\u4e14\u6210\u672c\u9ad8\uff1b\u968f\u7740\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u662f\u5426\u9700\u8981\u7ee7\u7eed\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u5b58\u7591\u3002", "method": "\u63d0\u51faGuirlVG\u65b9\u6cd5\uff0c\u5206\u89e3\u5f3a\u5316\u5fae\u8c03\u6838\u5fc3\u7ec4\u4ef6\uff0c\u63d0\u51fa\u52a8\u6001\u7a33\u5b9a\u7684\u5bf9\u6297KL\u56e0\u5b50\uff0c\u4f18\u5316\u8bad\u7ec3\u914d\u7f6e\u3002", "result": "GuirlVG\u5728\u5c11\u91cf\u6837\u672c\u4e0b\u8868\u73b0\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u5f3a\u5316\u5fae\u8c03\u662fGUI\u89c6\u89c9\u5b9a\u4f4d\u7684\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\uff0cGuirlVG\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u3002"}}
{"id": "2508.04412", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.04412", "abs": "https://arxiv.org/abs/2508.04412", "authors": ["Thassilo M. Schiepanski", "Nicholas Pi\u00ebl"], "title": "Beyond Pixels: Exploring DOM Downsampling for LLM-Based Web Agents", "comment": null, "summary": "Frontier LLMs only recently enabled serviceable, autonomous web agents. At\nthat, a model poses as an instantaneous domain model backend. Ought to suggest\ninteraction, it is consulted with a web-based task and respective application\nstate. The key problem lies in application state serialisation\n$\\unicode{x2013}$ referred to as snapshot. State-of-the-art web agents are\npremised on grounded GUI snapshots, i.e., screenshots enhanced with visual\ncues. Not least to resemble human perception, but for images representing\nrelatively cheap means of model input. LLM vision still lag behind code\ninterpretation capabilities. DOM snapshots, which structurally resemble HTML,\nimpose a desired alternative. Vast model input token size, however, disables\nreliable implementation with web agents to date.\n  We propose D2Snap, a first-of-its-kind DOM downsampling algorithm. Based on a\nGPT-4o backend, we evaluate D2Snap on tasks sampled from the Online-Mind2Web\ndataset. The success rate of D2Snap-downsampled DOM snapshots (67%) matches a\ngrounded GUI snapshot baseline (65%) $\\unicode{x2013}$ within the same input\ntoken order of magnitude (1e3). Our best evaluated configurations\n$\\unicode{x2013}$ one token order above, but within the model's context window\n$\\unicode{x2013}$ outperform this baseline by 8%. Our evaluation, moreover,\nyields that DOM-inherent hierarchy embodies a strong UI feature for LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aD2Snap\u7684DOM\u964d\u91c7\u6837\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u7f51\u9875\u4ee3\u7406\u4e2d\u5e94\u7528\u72b6\u6001\u5e8f\u5217\u5316\u7684\u95ee\u9898\uff0c\u5176\u6027\u80fd\u4e0e\u57fa\u4e8eGUI\u5feb\u7167\u7684\u65b9\u6cd5\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eGUI\u5feb\u7167\u7684\u7f51\u9875\u4ee3\u7406\u65b9\u6cd5\u53d7\u9650\u4e8eLLM\u89c6\u89c9\u80fd\u529b\u4e0d\u8db3\uff0c\u800cDOM\u5feb\u7167\u867d\u7136\u7ed3\u6784\u66f4\u4f18\uff0c\u4f46\u8f93\u5165\u4ee4\u724c\u91cf\u8fc7\u5927\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "\u63d0\u51faD2Snap\u7b97\u6cd5\uff0c\u901a\u8fc7\u964d\u91c7\u6837DOM\u5feb\u7167\uff0c\u7ed3\u5408GPT-4o\u540e\u7aef\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "D2Snap\u5728\u76f8\u540c\u8f93\u5165\u4ee4\u724c\u91cf\u4e0b\u4e0eGUI\u5feb\u7167\u57fa\u7ebf\u6027\u80fd\u76f8\u5f53\uff0867% vs 65%\uff09\uff0c\u5728\u66f4\u9ad8\u4ee4\u724c\u91cf\u4e0b\u6027\u80fd\u63d0\u53478%\u3002", "conclusion": "DOM\u56fa\u6709\u7684\u5c42\u6b21\u7ed3\u6784\u662fLLM\u7406\u89e3UI\u7684\u5f3a\u7279\u5f81\uff0cD2Snap\u4e3a\u7f51\u9875\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2508.04428", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04428", "abs": "https://arxiv.org/abs/2508.04428", "authors": ["Si Chen", "Izzy Molnar", "Ting Hua", "Peiyu Li", "Le Huy Khiem", "G. Alex Ambrose", "Jim Lang", "Ronald Metoyer", "Nitesh V. Chawla"], "title": "\\textsc{SimInstruct}: A Responsible Tool for Collecting Scaffolding Dialogues Between Experts and LLM-Simulated Novices", "comment": null, "summary": "High-quality, multi-turn instructional dialogues between novices and experts\nare essential for developing AI systems that support teaching, learning, and\ndecision-making. These dialogues often involve scaffolding -- the process by\nwhich an expert supports a novice's thinking through questions, feedback, and\nstep-by-step guidance. However, such data are scarce due to privacy concerns in\nrecording and the vulnerability inherent in help-seeking. We present\nSimInstruct, a scalable, expert-in-the-loop tool for collecting scaffolding\ndialogues. Using teaching development coaching as an example domain,\nSimInstruct simulates novice instructors via LLMs, varying their teaching\nchallenges and LLM's persona traits, while human experts provide multi-turn\nfeedback, reasoning, and instructional support. This design enables the\ncreation of realistic, pedagogically rich dialogues without requiring real\nnovice participants. Our results reveal that persona traits, such as\nextroversion and introversion, meaningfully influence how experts engage.\nCompared to real mentoring recordings, SimInstruct dialogues demonstrate\ncomparable pedagogical relevance and cognitive depth. Experts also reported the\nprocess as engaging and reflective, improving both data quality and their own\nprofessional insight. We further fine-tuned a LLaMA model to be an expert model\nusing the augmented dataset, which outperformed GPT-4o in instructional\nquality. Our analysis highlights GPT-4o's limitations in weak reflective\nquestioning, overuse of generic praise, a condescending tone, and a tendency to\noverwhelm novices with excessive suggestions.", "AI": {"tldr": "SimInstruct\u662f\u4e00\u79cd\u901a\u8fc7\u6a21\u62df\u65b0\u624b\u4e0e\u4e13\u5bb6\u4e92\u52a8\u6765\u6536\u96c6\u9ad8\u8d28\u91cf\u6559\u5b66\u5bf9\u8bdd\u7684\u5de5\u5177\uff0c\u5229\u7528LLM\u6a21\u62df\u65b0\u624b\uff0c\u4e13\u5bb6\u63d0\u4f9b\u53cd\u9988\uff0c\u751f\u6210\u7684\u5bf9\u8bdd\u5177\u6709\u6559\u5b66\u6df1\u5ea6\u3002", "motivation": "\u7531\u4e8e\u9690\u79c1\u548c\u8106\u5f31\u6027\u95ee\u9898\uff0c\u9ad8\u8d28\u91cf\u7684\u6559\u5b66\u5bf9\u8bdd\u6570\u636e\u7a00\u7f3a\uff0cSimInstruct\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528LLM\u6a21\u62df\u65b0\u624b\uff0c\u4e13\u5bb6\u63d0\u4f9b\u591a\u8f6e\u53cd\u9988\uff0c\u751f\u6210\u6559\u5b66\u5bf9\u8bdd\uff0c\u5e76\u5206\u6790\u4e13\u5bb6\u53c2\u4e0e\u65b9\u5f0f\u3002", "result": "\u751f\u6210\u7684\u5bf9\u8bdd\u4e0e\u771f\u5b9e\u5bf9\u8bdd\u5177\u6709\u53ef\u6bd4\u6027\uff0c\u4e13\u5bb6\u53cd\u9988\u79ef\u6781\uff0c\u4e14\u57fa\u4e8e\u6570\u636e\u8bad\u7ec3\u7684LLaMA\u6a21\u578b\u5728\u6559\u5b66\u8d28\u91cf\u4e0a\u4f18\u4e8eGPT-4\u3002", "conclusion": "SimInstruct\u4e3a\u6559\u5b66\u5bf9\u8bdd\u6570\u636e\u6536\u96c6\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u65b9\u6848\uff0c\u5e76\u63ed\u793a\u4e86GPT-4\u5728\u6559\u5b66\u652f\u6301\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.04460", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04460", "abs": "https://arxiv.org/abs/2508.04460", "authors": ["Rui Ha", "Chaozhuo Li", "Rui Pu", "Sen Su"], "title": "From \"Aha Moments\" to Controllable Thinking: Toward Meta-Cognitive Reasoning in Large Reasoning Models via Decoupled Reasoning and Control", "comment": null, "summary": "Large Reasoning Models (LRMs) have demonstrated a latent capacity for complex\nreasoning by spontaneously exhibiting cognitive behaviors such as step-by-step\nreasoning, reflection, and backtracking, commonly referred to as \"Aha Moments\".\nHowever, such emergent behaviors remain unregulated and uncontrolled, often\nresulting in overthinking, where the model continues generating redundant\nreasoning content even after reaching reliable conclusions. This leads to\nexcessive computational costs and increased latency, limiting the practical\ndeployment of LRMs. The root cause lies in the absence of intrinsic regulatory\nmechanisms, as current models are unable to monitor and adaptively manage their\nreasoning process to determine when to continue, backtrack, or terminate. To\naddress this issue, we propose the Meta-cognitive Reasoning Framework (MERA),\nwhich explicitly decouples the thinking process into distinct reasoning and\ncontrol components, thereby enabling the independent optimization of control\nstrategies. Specifically, MERA incorporates a takeover-based data construction\nmechanism that identifies critical decision points during reasoning and\ndelegates the creation of control signals to auxiliary LLMs, thereby enabling\nthe construction of high-quality reasoning-control data. Additionally, a\nstructured reasoning-control separation is implemented via supervised\nfine-tuning, enabling the model to generate explicit traces and acquire initial\nmeta-cognitive control capabilities. Finally, MERA employs Control-Segment\nPolicy Optimization (CSPO), which combines segment-wise Group Relative Policy\nOptimization (GRPO) with a control-masking mechanism to optimize control\nbehavior learning while minimizing interference from irrelevant content.\nExperiments on various reasoning benchmarks demonstrate that models trained\nwith MERA enhance both reasoning efficiency and accuracy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMeta-cognitive Reasoning Framework (MERA)\uff0c\u901a\u8fc7\u5206\u79bb\u63a8\u7406\u4e0e\u63a7\u5236\u7ec4\u4ef6\uff0c\u4f18\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7f3a\u4e4f\u5185\u5728\u8c03\u63a7\u673a\u5236\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u601d\u8003\u548c\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "MERA\u6846\u67b6\u5c06\u63a8\u7406\u8fc7\u7a0b\u5206\u89e3\u4e3a\u63a8\u7406\u4e0e\u63a7\u5236\u7ec4\u4ef6\uff0c\u91c7\u7528\u63a5\u7ba1\u5f0f\u6570\u636e\u6784\u5efa\u673a\u5236\u3001\u7ed3\u6784\u5316\u5206\u79bb\u548cControl-Segment Policy Optimization (CSPO) \u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMERA\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "conclusion": "MERA\u901a\u8fc7\u660e\u786e\u7684\u63a8\u7406\u63a7\u5236\u5206\u79bb\u548c\u4f18\u5316\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86LRMs\u7684\u8fc7\u5ea6\u63a8\u7406\u95ee\u9898\u3002"}}
{"id": "2508.04482", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04482", "abs": "https://arxiv.org/abs/2508.04482", "authors": ["Xueyu Hu", "Tao Xiong", "Biao Yi", "Zishu Wei", "Ruixuan Xiao", "Yurun Chen", "Jiasheng Ye", "Meiling Tao", "Xiangxin Zhou", "Ziyu Zhao", "Yuhuai Li", "Shengze Xu", "Shenzhi Wang", "Xinchen Xu", "Shuofei Qiao", "Zhaokai Wang", "Kun Kuang", "Tieyong Zeng", "Liang Wang", "Jiwei Li", "Yuchen Eleanor Jiang", "Wangchunshu Zhou", "Guoyin Wang", "Keting Yin", "Zhou Zhao", "Hongxia Yang", "Fan Wu", "Shengyu Zhang", "Fei Wu"], "title": "OS Agents: A Survey on MLLM-based Agents for General Computing Devices Use", "comment": "ACL 2025 (Oral)", "summary": "The dream to create AI assistants as capable and versatile as the fictional\nJ.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution\nof (multi-modal) large language models ((M)LLMs), this dream is closer to\nreality, as (M)LLM-based Agents using computing devices (e.g., computers and\nmobile phones) by operating within the environments and interfaces (e.g.,\nGraphical User Interface (GUI)) provided by operating systems (OS) to automate\ntasks have significantly advanced. This paper presents a comprehensive survey\nof these advanced agents, designated as OS Agents. We begin by elucidating the\nfundamentals of OS Agents, exploring their key components including the\nenvironment, observation space, and action space, and outlining essential\ncapabilities such as understanding, planning, and grounding. We then examine\nmethodologies for constructing OS Agents, focusing on domain-specific\nfoundation models and agent frameworks. A detailed review of evaluation\nprotocols and benchmarks highlights how OS Agents are assessed across diverse\ntasks. Finally, we discuss current challenges and identify promising directions\nfor future research, including safety and privacy, personalization and\nself-evolution. This survey aims to consolidate the state of OS Agents\nresearch, providing insights to guide both academic inquiry and industrial\ndevelopment. An open-source GitHub repository is maintained as a dynamic\nresource to foster further innovation in this field. We present a 9-page\nversion of our work, accepted by ACL 2025, to provide a concise overview to the\ndomain.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684OS Agents\uff0c\u63a2\u8ba8\u5176\u7ec4\u6210\u3001\u80fd\u529b\u3001\u6784\u5efa\u65b9\u6cd5\u3001\u8bc4\u4f30\u6807\u51c6\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5b9e\u73b0\u7c7b\u4f3cJ.A.R.V.I.S\u7684AI\u52a9\u624b\uff0c\u901a\u8fc7OS Agents\u5728\u591a\u6a21\u6001\u73af\u5883\u4e2d\u81ea\u52a8\u5316\u4efb\u52a1\u3002", "method": "\u5206\u6790OS Agents\u7684\u5173\u952e\u7ec4\u4ef6\uff08\u73af\u5883\u3001\u89c2\u5bdf\u7a7a\u95f4\u3001\u52a8\u4f5c\u7a7a\u95f4\uff09\u53ca\u80fd\u529b\uff08\u7406\u89e3\u3001\u89c4\u5212\u3001\u843d\u5730\uff09\uff0c\u7814\u7a76\u6784\u5efa\u65b9\u6cd5\uff08\u9886\u57df\u4e13\u7528\u57fa\u7840\u6a21\u578b\u548c\u4ee3\u7406\u6846\u67b6\uff09\u548c\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u7efc\u8ff0\u4e86OS Agents\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u65b9\u5411\uff08\u5982\u5b89\u5168\u3001\u9690\u79c1\u3001\u4e2a\u6027\u5316\uff09\u3002", "conclusion": "OS Agents\u7814\u7a76\u4e3a\u5b66\u672f\u548c\u5de5\u4e1a\u53d1\u5c55\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5f00\u6e90\u8d44\u6e90\u4fc3\u8fdb\u521b\u65b0\u3002"}}
{"id": "2508.04511", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04511", "abs": "https://arxiv.org/abs/2508.04511", "authors": ["Hamed Ayoobi", "Nico Potyka", "Anna Rapberger", "Francesca Toni"], "title": "Argumentative Debates for Transparent Bias Detection [Technical Report]", "comment": null, "summary": "As the use of AI systems in society grows, addressing potential biases that\nemerge from data or are learned by models is essential to prevent systematic\ndisadvantages against specific groups. Several notions of (un)fairness have\nbeen proposed in the literature, alongside corresponding algorithmic methods\nfor detecting and mitigating unfairness, but, with very few exceptions, these\ntend to ignore transparency. Instead, interpretability and explainability are\ncore requirements for algorithmic fairness, even more so than for other\nalgorithmic solutions, given the human-oriented nature of fairness. In this\npaper, we contribute a novel interpretable, explainable method for bias\ndetection relying on debates about the presence of bias against individuals,\nbased on the values of protected features for the individuals and others in\ntheir neighbourhoods. Our method builds upon techniques from formal and\ncomputational argumentation, whereby debates result from arguing about biases\nwithin and across neighbourhoods. We provide formal, quantitative, and\nqualitative evaluations of our method, highlighting its strengths in\nperformance against baselines, as well as its interpretability and\nexplainability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fa9\u8bba\u7684\u65b0\u578b\u53ef\u89e3\u91ca\u3001\u53ef\u89e3\u91ca\u7684\u504f\u89c1\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528\u5f62\u5f0f\u5316\u548c\u8ba1\u7b97\u8bba\u8bc1\u6280\u672f\uff0c\u901a\u8fc7\u8ba8\u8bba\u4e2a\u4f53\u53ca\u5176\u90bb\u57df\u7684\u4fdd\u62a4\u7279\u5f81\u503c\u6765\u68c0\u6d4b\u504f\u89c1\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u5728\u793e\u4f1a\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9632\u6b62\u6570\u636e\u6216\u6a21\u578b\u4e2d\u7684\u504f\u89c1\u5bf9\u7279\u5b9a\u7fa4\u4f53\u9020\u6210\u7cfb\u7edf\u6027\u4e0d\u5229\u5f71\u54cd\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u4e86\u900f\u660e\u6027\u3002", "method": "\u57fa\u4e8e\u5f62\u5f0f\u5316\u548c\u8ba1\u7b97\u8bba\u8bc1\u6280\u672f\uff0c\u901a\u8fc7\u8fa9\u8bba\u4e2a\u4f53\u53ca\u5176\u90bb\u57df\u7684\u4fdd\u62a4\u7279\u5f81\u503c\u6765\u68c0\u6d4b\u504f\u89c1\u3002", "result": "\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u540c\u65f6\u5177\u5907\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7b97\u6cd5\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u900f\u660e\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f3a\u8c03\u4e86\u900f\u660e\u6027\u5728\u516c\u5e73\u6027\u4e2d\u7684\u6838\u5fc3\u5730\u4f4d\u3002"}}
{"id": "2508.04563", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04563", "abs": "https://arxiv.org/abs/2508.04563", "authors": ["Mei Jiang", "Houping Yue", "Bingdong Li", "Hao Hao", "Ying Qian", "Bo Jiang", "Aimin Zhou"], "title": "SID: Benchmarking Guided Instruction Capabilities in STEM Education with a Socratic Interdisciplinary Dialogues Dataset", "comment": "26 pages, 20 figures", "summary": "Fostering students' abilities for knowledge integration and transfer in\ncomplex problem-solving scenarios is a core objective of modern education, and\ninterdisciplinary STEM is a key pathway to achieve this, yet it requires expert\nguidance that is difficult to scale. While LLMs offer potential in this regard,\ntheir true capability for guided instruction remains unclear due to the lack of\nan effective evaluation benchmark. To address this, we introduce SID, the first\nbenchmark designed to systematically evaluate the higher-order guidance\ncapabilities of LLMs in multi-turn, interdisciplinary Socratic dialogues. Our\ncontributions include a large-scale dataset of 10,000 dialogue turns across 48\ncomplex STEM projects, a novel annotation schema for capturing deep pedagogical\nfeatures, and a new suite of evaluation metrics (e.g., X-SRG). Baseline\nexperiments confirm that even state-of-the-art LLMs struggle to execute\neffective guided dialogues that lead students to achieve knowledge integration\nand transfer. This highlights the critical value of our benchmark in driving\nthe development of more pedagogically-aware LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86SID\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u591a\u8f6e\u8de8\u5b66\u79d1\u82cf\u683c\u62c9\u5e95\u5bf9\u8bdd\u4e2d\u7684\u9ad8\u9636\u6307\u5bfc\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524dLLMs\u4ecd\u96be\u4ee5\u6709\u6548\u5f15\u5bfc\u5b66\u751f\u5b9e\u73b0\u77e5\u8bc6\u6574\u5408\u4e0e\u8fc1\u79fb\u3002", "motivation": "\u73b0\u4ee3\u6559\u80b2\u6838\u5fc3\u76ee\u6807\u662f\u57f9\u517b\u5b66\u751f\u590d\u6742\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u77e5\u8bc6\u6574\u5408\u4e0e\u8fc1\u79fb\u80fd\u529b\uff0c\u8de8\u5b66\u79d1STEM\u662f\u5173\u952e\u9014\u5f84\uff0c\u4f46\u9700\u8981\u4e13\u5bb6\u6307\u5bfc\u4e14\u96be\u4ee5\u89c4\u6a21\u5316\u3002LLMs\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u63d0\u51faSID\u57fa\u51c6\uff0c\u5305\u62ec\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0810,000\u5bf9\u8bdd\u8f6e\u6b21\uff09\u3001\u65b0\u6ce8\u91ca\u6846\u67b6\u548c\u8bc4\u4f30\u6307\u6807\uff08\u5982X-SRG\uff09\uff0c\u5e76\u901a\u8fc7\u57fa\u7ebf\u5b9e\u9a8c\u9a8c\u8bc1LLMs\u7684\u5c40\u9650\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u6700\u5148\u8fdb\u7684LLMs\u4e5f\u96be\u4ee5\u6267\u884c\u6709\u6548\u6307\u5bfc\u5bf9\u8bdd\uff0c\u4fc3\u8fdb\u5b66\u751f\u77e5\u8bc6\u6574\u5408\u4e0e\u8fc1\u79fb\u3002", "conclusion": "SID\u57fa\u51c6\u5bf9\u63a8\u52a8\u66f4\u5177\u6559\u5b66\u610f\u8bc6\u7684LLMs\u53d1\u5c55\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2508.04576", "categories": ["cs.AI", "I.2.6; I.2.7; D.2.8"], "pdf": "https://arxiv.org/pdf/2508.04576", "abs": "https://arxiv.org/abs/2508.04576", "authors": ["Yue Zhou", "Yi Chang", "Yuan Wu"], "title": "ConfProBench: A Confidence Evaluation Benchmark for MLLM-Based Process Judges", "comment": null, "summary": "Reasoning is a critical capability of multimodal large language models\n(MLLMs) for solving complex multimodal tasks, and judging the correctness of\nreasoning steps is crucial for improving this capability. Recently, MLLM-based\nprocess judges (MPJs) have been widely used to assess the correctness of\nreasoning steps in multimodal tasks. Therefore, evaluating MPJs is important\nfor identifying their limitations and guiding future improvements. However,\nexisting benchmarks for MPJs mainly focus on tasks such as step correctness\nclassification and reasoning process search, while overlooking a key aspect:\nwhether the confidence scores produced by MPJs at the step level are reliable.\nTo address this gap, we propose ConfProBench, the first comprehensive benchmark\ndesigned to systematically evaluate the reliability of step-level confidence\nscores generated by MPJs. Our benchmark constructs three types of adversarially\nperturbed reasoning steps: Synonym Substitution, Syntactic Transformation, and\nImage Perturbation, to test the robustness of MPJ confidence under\nperturbations. In addition, we introduce three novel evaluation metrics:\nConfidence Robustness Score (CRS), Confidence Sensitivity Score (CSS), and\nConfidence Calibration Score (CCS), which evaluate robustness, sensitivity, and\ncalibration, respectively. We evaluate 14 state-of-the-art MLLMs, including\nboth proprietary and open-source models. Experiments reveal limitations in\ncurrent MPJs' confidence performance and offer competitive baselines to support\nfuture research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86ConfProBench\uff0c\u9996\u4e2a\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u8fc7\u7a0b\u5224\u65ad\u5668\uff08MPJ\uff09\u5728\u6b65\u9aa4\u7ea7\u522b\u7f6e\u4fe1\u5ea6\u5f97\u5206\u53ef\u9760\u6027\u7684\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709MPJ\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u6b65\u9aa4\u6b63\u786e\u6027\u5206\u7c7b\u548c\u63a8\u7406\u8fc7\u7a0b\u641c\u7d22\uff0c\u800c\u5ffd\u7565\u4e86\u7f6e\u4fe1\u5ea6\u5f97\u5206\u7684\u53ef\u9760\u6027\uff0c\u56e0\u6b64\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u4e09\u79cd\u5bf9\u6297\u6027\u6270\u52a8\u63a8\u7406\u6b65\u9aa4\uff08\u540c\u4e49\u8bcd\u66ff\u6362\u3001\u53e5\u6cd5\u53d8\u6362\u548c\u56fe\u50cf\u6270\u52a8\uff09\u6765\u6d4b\u8bd5MPJ\u7f6e\u4fe1\u5ea6\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5f15\u5165\u4e09\u4e2a\u65b0\u8bc4\u4f30\u6307\u6807\uff08CRS\u3001CSS\u3001CCS\uff09\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u4e8614\u79cd\u5148\u8fdbMLLM\uff0c\u63ed\u793a\u4e86\u5f53\u524dMPJ\u5728\u7f6e\u4fe1\u5ea6\u6027\u80fd\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u672a\u6765\u7814\u7a76\u7684\u7ade\u4e89\u57fa\u7ebf\u3002", "conclusion": "ConfProBench\u4e3a\u7cfb\u7edf\u8bc4\u4f30MPJ\u7f6e\u4fe1\u5ea6\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u5de5\u5177\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2508.04700", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.MA", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.04700", "abs": "https://arxiv.org/abs/2508.04700", "authors": ["Zeyi Sun", "Ziyu Liu", "Yuhang Zang", "Yuhang Cao", "Xiaoyi Dong", "Tong Wu", "Dahua Lin", "Jiaqi Wang"], "title": "SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience", "comment": "Code at https://github.com/SunzeY/SEAgent", "summary": "Repurposing large vision-language models (LVLMs) as computer use agents\n(CUAs) has led to substantial breakthroughs, primarily driven by human-labeled\ndata. However, these models often struggle with novel and specialized software,\nparticularly in scenarios lacking human annotations. To address this challenge,\nwe propose SEAgent, an agentic self-evolving framework enabling CUAs to\nautonomously evolve through interactions with unfamiliar software.\nSpecifically, SEAgent empowers computer-use agents to autonomously master novel\nsoftware environments via experiential learning, where agents explore new\nsoftware, learn through iterative trial-and-error, and progressively tackle\nauto-generated tasks organized from simple to complex. To achieve this goal, we\ndesign a World State Model for step-wise trajectory assessment, along with a\nCurriculum Generator that generates increasingly diverse and challenging tasks.\nThe agent's policy is updated through experiential learning, comprised of\nadversarial imitation of failure actions and Group Relative Policy Optimization\n(GRPO) on successful ones. Furthermore, we introduce a specialist-to-generalist\ntraining strategy that integrates individual experiential insights from\nspecialist agents, facilitating the development of a stronger generalist CUA\ncapable of continuous autonomous evolution. This unified agent ultimately\nachieves performance surpassing ensembles of individual specialist agents on\ntheir specialized software. We validate the effectiveness of SEAgent across\nfive novel software environments within OS-World. Our approach achieves a\nsignificant improvement of 23.2% in success rate, from 11.3% to 34.5%, over a\ncompetitive open-source CUA, i.e., UI-TARS.", "AI": {"tldr": "SEAgent\u662f\u4e00\u79cd\u81ea\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u4e3b\u4ea4\u4e92\u5b66\u4e60\u65b0\u8f6f\u4ef6\uff0c\u63d0\u5347\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7f3a\u4e4f\u4eba\u5de5\u6807\u6ce8\u7684\u65b0\u8f6f\u4ef6\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u81ea\u4e3b\u8fdb\u5316\u80fd\u529b\u3002", "method": "SEAgent\u901a\u8fc7\u4f53\u9a8c\u5b66\u4e60\u3001\u4e16\u754c\u72b6\u6001\u6a21\u578b\u548c\u8bfe\u7a0b\u751f\u6210\u5668\uff0c\u7ed3\u5408\u5bf9\u6297\u6a21\u4eff\u548cGRPO\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5728OS-World\u7684\u4e94\u4e2a\u65b0\u8f6f\u4ef6\u73af\u5883\u4e2d\uff0cSEAgent\u6210\u529f\u7387\u4ece11.3%\u63d0\u5347\u81f334.5%\u3002", "conclusion": "SEAgent\u901a\u8fc7\u81ea\u8fdb\u5316\u6846\u67b6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
