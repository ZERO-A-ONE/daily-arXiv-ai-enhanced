{"id": "2509.13464", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13464", "abs": "https://arxiv.org/abs/2509.13464", "authors": ["Onat Gungor", "Ishaan Kale", "Jiasheng Zhou", "Tajana Rosing"], "title": "LIGHT-HIDS: A Lightweight and Effective Machine Learning-Based Framework for Robust Host Intrusion Detection", "comment": "Accepted by The 24th IEEE International Conference on Machine\n  Learning and Applications (ICMLA'25)", "summary": "The expansion of edge computing has increased the attack surface, creating an\nurgent need for robust, real-time machine learning (ML)-based host intrusion\ndetection systems (HIDS) that balance accuracy and efficiency. In such\nsettings, inference latency poses a critical security risk, as delays may\nprovide exploitable opportunities for attackers. However, many state-of-the-art\nML-based HIDS solutions rely on computationally intensive architectures with\nhigh inference costs, limiting their practical deployment. This paper proposes\nLIGHT-HIDS, a lightweight machine learning framework that combines a compressed\nneural network feature extractor trained via Deep Support Vector Data\nDescription (DeepSVDD) with an efficient novelty detection model. This hybrid\napproach enables the learning of compact, meaningful representations of normal\nsystem call behavior for accurate anomaly detection. Experimental results on\nmultiple datasets demonstrate that LIGHT-HIDS consistently enhances detection\naccuracy while reducing inference time by up to 75x compared to\nstate-of-the-art methods. These findings highlight its effectiveness and\nscalability as a machine learning-based solution for real-time host intrusion\ndetection.", "AI": {"tldr": "LIGHT-HIDS\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u538b\u7f29\u795e\u7ecf\u7f51\u7edc\u7279\u5f81\u63d0\u53d6\u5668\u548c\u9ad8\u6548\u65b0\u9896\u6027\u68c0\u6d4b\u6a21\u578b\uff0c\u5728\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u5b9e\u73b0\u5b9e\u65f6\u4e3b\u673a\u5165\u4fb5\u68c0\u6d4b\uff0c\u63a8\u7406\u65f6\u95f4\u51cf\u5c1175\u500d\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u6269\u5c55\u589e\u52a0\u4e86\u653b\u51fb\u9762\uff0c\u9700\u8981\u517c\u987e\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u5b9e\u65f6ML\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u73b0\u6709\u65b9\u6848\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u7ed3\u5408\u538b\u7f29\u795e\u7ecf\u7f51\u7edc\u7279\u5f81\u63d0\u53d6\u5668\uff08DeepSVDD\u8bad\u7ec3\uff09\u548c\u9ad8\u6548\u65b0\u9896\u6027\u68c0\u6d4b\u6a21\u578b\uff0c\u5b66\u4e60\u6b63\u5e38\u7cfb\u7edf\u8c03\u7528\u884c\u4e3a\u7684\u7d27\u51d1\u8868\u793a\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cLIGHT-HIDS\u5728\u63d0\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u63a8\u7406\u65f6\u95f4\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u51cf\u5c11\u9ad8\u8fbe75\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f5c\u4e3a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5b9e\u65f6\u4e3b\u673a\u5165\u4fb5\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2509.13509", "categories": ["cs.CR", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13509", "abs": "https://arxiv.org/abs/2509.13509", "authors": ["Priyanka Nanayakkara", "Elena Ghazi", "Salil Vadhan"], "title": "Practitioners' Perspectives on a Differential Privacy Deployment Registry", "comment": null, "summary": "Differential privacy (DP) -- a principled approach to producing statistical\ndata products with strong, mathematically provable privacy guarantees for the\nindividuals in the underlying dataset -- has seen substantial adoption in\npractice over the past decade. Applying DP requires making several\nimplementation decisions, each with significant impacts on data privacy and/or\nutility. Hence, to promote shared learning and accountability around DP\ndeployments, Dwork, Kohli, and Mulligan (2019) proposed a public-facing\nrepository (\"registry\") of DP deployments. The DP community has recently\nstarted to work toward realizing this vision. We contribute to this effort by\n(1) developing a holistic, hierarchical schema to describe any given DP\ndeployment and (2) designing and implementing an interactive interface to act\nas a registry where practitioners can access information about past DP\ndeployments. We (3) populate our interface with 21 real-world DP deployments\nand (4) conduct an exploratory user study with DP practitioners ($n=16$) to\nunderstand how they would use the registry, as well as what challenges and\nopportunities they foresee around its adoption. We find that participants were\nenthusiastic about the registry as a valuable resource for evaluating prior\ndeployments and making future deployments. They also identified several\nopportunities for the registry, including that it can become a \"hub\" for the\ncommunity and support broader communication around DP (e.g., to legal teams).\nAt the same time, they identified challenges around the registry gaining\nadoption, including the effort and risk involved with making implementation\nchoices public and moderating the quality of entries. Based on our findings, we\noffer recommendations for encouraging adoption and increasing the registry's\nvalue not only to DP practitioners, but also to policymakers, data users, and\ndata subjects.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u90e8\u7f72\u6ce8\u518c\u8868\u7684\u6574\u4f53\u67b6\u6784\u548c\u4ea4\u4e92\u754c\u9762\uff0c\u5305\u542b21\u4e2a\u5b9e\u9645\u90e8\u7f72\u6848\u4f8b\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u4ef7\u503c\u548c\u6311\u6218\u3002", "motivation": "\u4e3a\u4e86\u4fc3\u8fdb\u5dee\u5206\u9690\u79c1\u6280\u672f\u7684\u5171\u4eab\u5b66\u4e60\u548c\u8d23\u4efb\u5236\uff0c\u5b9e\u73b0Dwork\u7b49\u4eba\u63d0\u51fa\u7684\u516c\u5f00DP\u90e8\u7f72\u6ce8\u518c\u8868\u7684\u60f3\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6574\u4f53\u7684\u5c42\u6b21\u7ed3\u6784\u6765\u63cf\u8ff0DP\u90e8\u7f72\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4ea4\u4e92\u5f0f\u6ce8\u518c\u8868\u754c\u9762\uff0c\u586b\u5145\u4e8621\u4e2a\u771f\u5b9e\u90e8\u7f72\u6848\u4f8b\uff0c\u5e76\u8fdb\u884c\u4e86\u9010\u6848\u7814\u7a76\uff08n=16\uff09\u3002", "result": "\u53c2\u4e0e\u8005\u5bf9\u6ce8\u518c\u8868\u8868\u793a\u6fc0\u60c5\uff0c\u8ba4\u4e3a\u5176\u53ef\u4ee5\u6210\u4e3a\u8bc4\u4f30\u5386\u53f2\u90e8\u7f72\u548c\u652f\u6301\u672a\u6765\u90e8\u7f72\u7684\u4ef7\u503c\u8d44\u6e90\uff0c\u540c\u65f6\u8bc6\u522b\u4e86\u76f8\u5173\u6311\u6218\u3002", "conclusion": "\u6ce8\u518c\u8868\u6709\u671b\u6210\u4e3aDP\u793e\u533a\u7684\u4e2d\u5fc3\u6e20\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u516c\u5f00\u5b9e\u65bd\u9009\u62e9\u7684\u52b3\u52a8\u5f3a\u5ea6\u548c\u98ce\u9669\u7b49\u6311\u6218\uff0c\u5efa\u8bae\u63a8\u52a8\u66f4\u5e7f\u6cdb\u7684\u91c7\u7528\u3002"}}
{"id": "2509.13514", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13514", "abs": "https://arxiv.org/abs/2509.13514", "authors": ["Onat Gungor", "Roshan Sood", "Harold Wang", "Tajana Rosing"], "title": "AQUA-LLM: Evaluating Accuracy, Quantization, and Adversarial Robustness Trade-offs in LLMs for Cybersecurity Question Answering", "comment": "Accepted by the 24th IEEE International Conference on Machine\n  Learning and Applications (ICMLA'25)", "summary": "Large Language Models (LLMs) have recently demonstrated strong potential for\ncybersecurity question answering (QA), supporting decision-making in real-time\nthreat detection and response workflows. However, their substantial\ncomputational demands pose significant challenges for deployment on\nresource-constrained edge devices. Quantization, a widely adopted model\ncompression technique, can alleviate these constraints. Nevertheless,\nquantization may degrade model accuracy and increase susceptibility to\nadversarial attacks. Fine-tuning offers a potential means to mitigate these\nlimitations, but its effectiveness when combined with quantization remains\ninsufficiently explored. Hence, it is essential to understand the trade-offs\namong accuracy, efficiency, and robustness. We propose AQUA-LLM, an evaluation\nframework designed to benchmark several state-of-the-art small LLMs under four\ndistinct configurations: base, quantized-only, fine-tuned, and fine-tuned\ncombined with quantization, specifically for cybersecurity QA. Our results\ndemonstrate that quantization alone yields the lowest accuracy and robustness\ndespite improving efficiency. In contrast, combining quantization with\nfine-tuning enhances both LLM robustness and predictive performance, achieving\nan optimal balance of accuracy, robustness, and efficiency. These findings\nhighlight the critical need for quantization-aware, robustness-preserving\nfine-tuning methodologies to enable the robust and efficient deployment of LLMs\nfor cybersecurity QA.", "AI": {"tldr": "AQUA-LLM\u6846\u67b6\u8bc4\u4f30\u5c0f\u578bLLM\u5728\u7f51\u7edc\u5b89\u5168\u95ee\u7b54\u4e2d\u7684\u91cf\u5316\u3001\u5fae\u8c03\u53ca\u5176\u7ec4\u5408\u6548\u679c\uff0c\u53d1\u73b0\u91cf\u5316+\u5fae\u8c03\u7ec4\u5408\u80fd\u6700\u4f73\u5e73\u8861\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u6548\u7387", "motivation": "LLM\u5728\u7f51\u7edc\u5b89\u5168\u95ee\u7b54\u4e2d\u8868\u73b0\u4f18\u5f02\u4f46\u8ba1\u7b97\u9700\u6c42\u5927\uff0c\u91cf\u5316\u53ef\u538b\u7f29\u6a21\u578b\u4f46\u4f1a\u964d\u4f4e\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5fae\u8c03\u7684\u6548\u679c\u4e0e\u91cf\u5316\u7ed3\u5408\u5c1a\u672a\u5145\u5206\u63a2\u7d22", "method": "\u63d0\u51faAQUA-LLM\u8bc4\u4f30\u6846\u67b6\uff0c\u5bf9\u591a\u4e2a\u5148\u8fdb\u5c0f\u578bLLM\u5728\u56db\u79cd\u914d\u7f6e\uff08\u57fa\u7840\u3001\u4ec5\u91cf\u5316\u3001\u4ec5\u5fae\u8c03\u3001\u91cf\u5316+\u5fae\u8c03\uff09\u4e0b\u8fdb\u884c\u7f51\u7edc\u5b89\u5168\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5", "result": "\u4ec5\u91cf\u5316\u51c6\u786e\u6027\u6700\u4f4e\u4e14\u9c81\u68d2\u6027\u5dee\uff1b\u91cf\u5316+\u5fae\u8c03\u7ec4\u5408\u80fd\u540c\u65f6\u63d0\u5347LLM\u9c81\u68d2\u6027\u548c\u9884\u6d4b\u6027\u80fd\uff0c\u8fbe\u5230\u6700\u4f73\u5e73\u8861", "conclusion": "\u9700\u8981\u5f00\u53d1\u91cf\u5316\u611f\u77e5\u3001\u4fdd\u6301\u9c81\u68d2\u6027\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0LLM\u5728\u7f51\u7edc\u5b89\u5168\u95ee\u7b54\u4e2d\u7684\u7a33\u5065\u9ad8\u6548\u90e8\u7f72"}}
{"id": "2509.13561", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13561", "abs": "https://arxiv.org/abs/2509.13561", "authors": ["Mengxiao Wang", "Guofei Gu"], "title": "GuardianPWA: Enhancing Security Throughout the Progressive Web App Installation Lifecycle", "comment": null, "summary": "Progressive Web App (PWA) installation is critical for integrating web and\nmobile app functionalities, offering a seamless user experience. However,\nensuring the security of the PWA installation lifecycle is essential for\nmaintaining user trust and privacy. This paper introduces the GUARDIANPWA\nframework, a comprehensive approach to analyzing the PWA installation mechanism\nbased on the CIA security principles (Confidentiality, Integrity, and\nAvailability) and identifying areas where browser vendors fail to comply with\nthese principles. Our study revealed 203 instances of non-compliance with\nsecurity principles, highlighting how these irregularities in the PWA\ninstallation lifecycle can lead to potential violations of user privacy. For\ninstance, in Firefox, PWAs installed in private mode incorrectly appear in\nnormal mode, risking user confidentiality. Additionally, 29,465 PWAs are at\nrisk because Samsung Internet does not display origins when PWAs navigate to\nthird-party websites, undermining integrity. These findings were reported to\nbrowser vendors, leading to Firefox acknowledging four issues, resolving one,\nand planning to resolve two others. GUARDIANPWA supports developers by\nanalyzing PWA manifest files for syntactic and semantic correctness, offering\nactionable recommendations, and helping to create PWAs that align with security\nbest practices. By using GUARDIANPWA, developers and users can address critical\nsecurity gaps and enhance compliance with CIA principles throughout the PWA\ninstallation lifecycle.", "AI": {"tldr": "GUARDIANPWA\u6846\u67b6\u57fa\u4e8eCIA\u5b89\u5168\u539f\u5219\u5206\u6790PWA\u5b89\u88c5\u673a\u5236\uff0c\u53d1\u73b0203\u4e2a\u5b89\u5168\u8fdd\u89c4\u5b9e\u4f8b\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u548c\u6d4f\u89c8\u5668\u5382\u5546\u63d0\u5347PWA\u5b89\u88c5\u5b89\u5168\u6027\u3002", "motivation": "\u786e\u4fddPWA\u5b89\u88c5\u751f\u547d\u5468\u671f\u7684\u5b89\u5168\u6027\u5bf9\u4e8e\u7ef4\u62a4\u7528\u6237\u4fe1\u4efb\u548c\u9690\u79c1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6d4f\u89c8\u5668\u5382\u5546\u5728\u9075\u5b88CIA\u5b89\u5168\u539f\u5219\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51faGUARDIANPWA\u6846\u67b6\uff0c\u57fa\u4e8e\u673a\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u548c\u53ef\u7528\u6027(CIA)\u5b89\u5168\u539f\u5219\u7cfb\u7edf\u5206\u6790PWA\u5b89\u88c5\u673a\u5236\uff0c\u68c0\u6d4b\u6d4f\u89c8\u5668\u5382\u5546\u7684\u5408\u89c4\u6027\u95ee\u9898\u3002", "result": "\u53d1\u73b0203\u4e2a\u5b89\u5168\u539f\u5219\u8fdd\u89c4\u5b9e\u4f8b\uff0c\u5305\u62ecFirefox\u9690\u79c1\u6a21\u5f0f\u95ee\u9898\u548cSamsung Internet\u6765\u6e90\u663e\u793a\u95ee\u9898\uff1b\u5411\u6d4f\u89c8\u5668\u5382\u5546\u62a5\u544a\u540e\uff0cFirefox\u786e\u8ba44\u4e2a\u95ee\u9898\u5e76\u4fee\u590d1\u4e2a\u3002", "conclusion": "GUARDIANPWA\u6846\u67b6\u80fd\u6709\u6548\u8bc6\u522bPWA\u5b89\u88c5\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u548c\u6d4f\u89c8\u5668\u5382\u5546\u63d0\u5347\u5408\u89c4\u6027\uff0c\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u548c\u5b89\u5168\u3002"}}
{"id": "2509.13332", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13332", "abs": "https://arxiv.org/abs/2509.13332", "authors": ["Pratik Jayarao", "Himanshu Gupta", "Neeraj Varshney", "Chaitanya Dwivedi"], "title": "Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly adopted as automated judges\nin benchmarking and reward modeling, ensuring their reliability, efficiency,\nand robustness has become critical. In this work, we present a systematic\ncomparison of \"thinking\" and \"non-thinking\" LLMs in the LLM-as-a-judge paradigm\nusing open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B\nparameters). We evaluate both accuracy and computational efficiency (FLOPs) on\nRewardBench tasks, and further examine augmentation strategies for non-thinking\nmodels, including in-context learning, rubric-guided judging, reference-based\nevaluation, and n-best aggregation. Our results show that despite these\nenhancements, non-thinking models generally fall short of their thinking\ncounterparts. Our results show that thinking models achieve approximately 10%\npoints higher accuracy with little overhead (under 2x), in contrast to\naugmentation strategies like few-shot learning, which deliver modest gains at a\nhigher cost (>8x). Bias and robustness analyses further demonstrate that\nthinking models maintain significantly greater consistency under a variety of\nbias conditions such as positional, bandwagon, identity, diversity, and random\nbiases (6% higher on average). We further extend our experiments to the\nmultilingual setting and our results confirm that explicit reasoning extends\nits benefits beyond English. Overall, our work results in several important\nfindings that provide systematic evidence that explicit reasoning offers clear\nadvantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency\nbut also in robustness.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u6027\u6bd4\u8f83\u4e86\"\u601d\u8003\"\u548c\"\u975e\u601d\u8003\"LLM\u5728\u8bc4\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u663e\u5f0f\u63a8\u7406\u80fd\u5927\u5e45\u63d0\u5347\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u7a33\u5065\u6027", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u88ab\u5e7f\u6cdb\u7528\u4f5c\u4e3a\u81ea\u52a8\u5316\u8bc4\u6d4b\u5668\uff0c\u9700\u8981\u786e\u4fdd\u5176\u53ef\u9760\u6027\u3001\u6548\u7387\u548c\u7a33\u5065\u6027", "method": "\u4f7f\u7528Qwen 3\u5c0f\u578b\u6a21\u578b(0.6B\u30011.7B\u30014B)\uff0c\u5728RewardBench\u4efb\u52a1\u4e0a\u6bd4\u8f83\u601d\u8003\u4e0e\u975e\u601d\u8003\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u6d4b\u8bd5\u591a\u79cd\u589e\u5f3a\u7b56\u7565", "result": "\u601d\u8003\u6a21\u578b\u51c6\u786e\u6027\u9ad8\u7ea610%\uff0c\u8ba1\u7b97\u6210\u672c\u4ec5\u589e\u52a02\u500d\u4ee5\u5185\uff0c\u800c\u5c11\u91cf\u5b66\u4e60\u7b49\u65b9\u6cd5\u6210\u672c\u9ad88\u500d\u4ee5\u4e0a\u5374\u6536\u76ca\u6709\u9650\u3002\u601d\u8003\u6a21\u578b\u5728\u5404\u79cd\u504f\u89c1\u6761\u4ef6\u4e0b\u4e5f\u66f4\u7a33\u5065", "conclusion": "\u663e\u5f0f\u63a8\u7406\u5728LLM\u4f5c\u4e3a\u8bc4\u6d4b\u5668\u65b9\u9762\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u4e0d\u4ec5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\uff0c\u8fd8\u5728\u7a33\u5065\u6027\u65b9\u9762\u90fd\u6709\u663e\u8457\u6539\u5584"}}
{"id": "2509.13436", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13436", "abs": "https://arxiv.org/abs/2509.13436", "authors": ["Evan Eisinger", "Michael A. Heroux"], "title": "Is Research Software Science a Metascience?", "comment": "5 pages", "summary": "As research increasingly relies on computational methods, the reliability of\nscientific results depends on the quality, reproducibility, and transparency of\nresearch software. Ensuring these qualities is critical for scientific\nintegrity and discovery. This paper asks whether Research Software Science\n(RSS)--the empirical study of how research software is developed and\nused--should be considered a form of metascience, the science of science.\nClassification matters because it could affect recognition, funding, and\nintegration of RSS into research improvement. We define metascience and RSS,\ncompare their principles and objectives, and examine their overlaps. Arguments\nfor classification highlight shared commitments to reproducibility,\ntransparency, and empirical study of research processes. Arguments against\nportraying RSS as a specialized domain focused on a tool rather than the\nbroader scientific enterprise. Our analysis finds RSS advances core goals of\nmetascience, especially in computational reproducibility, and bridges\ntechnical, social, and cognitive aspects of research. Its classification\ndepends on whether one adopts a broad definition of metascience--any empirical\neffort to improve science--or a narrow one focused on systemic and\nepistemological structures. We argue RSS is best understood as a distinct\ninterdisciplinary domain that aligns with, and in some definitions fits within,\nmetascience. Recognizing it as such can strengthen its role in improving\nreliability, justify funding, and elevate software development in research\ninstitutions. Regardless of classification, applying scientific rigor to\nresearch software ensures the tools of discovery meet the standards of the\ndiscoveries themselves.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u7814\u7a76\u8f6f\u4ef6\u79d1\u5b66(RSS)\u662f\u5426\u5e94\u5f52\u7c7b\u4e3a\u5143\u79d1\u5b66\uff0c\u901a\u8fc7\u6bd4\u8f83\u4e24\u8005\u7684\u5b9a\u4e49\u3001\u539f\u5219\u548c\u76ee\u6807\uff0c\u5206\u6790RSS\u5728\u63d0\u9ad8\u7814\u7a76\u8f6f\u4ef6\u8d28\u91cf\u548c\u79d1\u5b66\u53ef\u9760\u6027\u65b9\u9762\u7684\u4f5c\u7528\u3002", "motivation": "\u968f\u7740\u7814\u7a76\u65e5\u76ca\u4f9d\u8d56\u8ba1\u7b97\u65b9\u6cd5\uff0c\u79d1\u5b66\u7ed3\u679c\u7684\u53ef\u9760\u6027\u53d6\u51b3\u4e8e\u7814\u7a76\u8f6f\u4ef6\u7684\u8d28\u91cf\u3001\u53ef\u91cd\u73b0\u6027\u548c\u900f\u660e\u5ea6\u3002\u786e\u4fdd\u8fd9\u4e9b\u54c1\u8d28\u5bf9\u79d1\u5b66\u8bda\u4fe1\u548c\u53d1\u73b0\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5b9a\u4e49\u5143\u79d1\u5b66\u548c\u7814\u7a76\u8f6f\u4ef6\u79d1\u5b66(RSS)\uff0c\u6bd4\u8f83\u5b83\u4eec\u7684\u539f\u7406\u548c\u76ee\u6807\uff0c\u68c0\u67e5\u5b83\u4eec\u7684\u91cd\u53e0\u90e8\u5206\uff0c\u5206\u6790\u652f\u6301\u4e0e\u53cd\u5bf9\u5c06RSS\u5f52\u7c7b\u4e3a\u5143\u79d1\u5b66\u7684\u8bba\u70b9\u3002", "result": "\u5206\u6790\u53d1\u73b0RSS\u63a8\u8fdb\u4e86\u5143\u79d1\u5b66\u7684\u6838\u5fc3\u76ee\u6807\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u53ef\u91cd\u73b0\u6027\u65b9\u9762\uff0c\u5e76\u8fde\u63a5\u4e86\u7814\u7a76\u7684\u6280\u672f\u3001\u793e\u4f1a\u548c\u8ba4\u77e5\u65b9\u9762\u3002\u5176\u5206\u7c7b\u53d6\u51b3\u4e8e\u91c7\u7528\u5e7f\u4e49\u8fd8\u662f\u72ed\u4e49\u7684\u5143\u79d1\u5b66\u5b9a\u4e49\u3002", "conclusion": "RSS\u6700\u597d\u88ab\u7406\u89e3\u4e3a\u4e00\u4e2a\u72ec\u7279\u7684\u8de8\u5b66\u79d1\u9886\u57df\uff0c\u4e0e\u5143\u79d1\u5b66\u4fdd\u6301\u4e00\u81f4\uff0c\u5728\u67d0\u4e9b\u5b9a\u4e49\u4e0b\u5c5e\u4e8e\u5143\u79d1\u5b66\u8303\u7574\u3002\u65e0\u8bba\u5206\u7c7b\u5982\u4f55\uff0c\u5c06\u79d1\u5b66\u4e25\u8c28\u6027\u5e94\u7528\u4e8e\u7814\u7a76\u8f6f\u4ef6\u53ef\u786e\u4fdd\u53d1\u73b0\u5de5\u5177\u7b26\u5408\u53d1\u73b0\u672c\u8eab\u7684\u6807\u51c6\u3002"}}
{"id": "2509.13563", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13563", "abs": "https://arxiv.org/abs/2509.13563", "authors": ["Mengxiao Wang", "Guofei Gu"], "title": "Demystifying Progressive Web Application Permission Systems", "comment": null, "summary": "Progressive Web Applications (PWAs) blend the advantages of web and native\napps, offering features like offline access, push notifications, and\ninstallability. Beyond these, modern PWAs are increasingly granted system-level\ncapabilities such as auto-start on login and shared context with native\napplications. However, their permission management remains poorly defined and\ninconsistently implemented across platforms and browsers.\n  To investigate these gaps, we developed Permissioner, a cross-platform\nanalysis tool, and conducted a systematic study of PWA permissions. Our\nanalysis uncovered critical issues of inconsistency, incompleteness, and\nunclear boundaries in permission enforcement, leading to various attacks\nincluding permission leakage, device identification, and Permission API abuse.\nWe further examined why some browsers resist adopting more granular permission\ncontrols, identifying trade-offs involving usability, compatibility, and\nplatform limitations. Through collaboration with browser vendors, several\nissues reported in our findings were acknowledged and resolved, notably by\nFirefox and Chrome. Our work highlights the urgent need for a unified, robust\npermission model for PWAs and provides actionable guidance toward achieving\nthis goal.", "AI": {"tldr": "\u8be5\u6587\u7ae0\u7814\u7a76\u4e86\u6e10\u8fdb\u5f0f\u7f51\u7edc\u5e94\u7528\uff08PWA\uff09\u7684\u6743\u9650\u7ba1\u7406\u95ee\u9898\uff0c\u53d1\u73b0\u4e86\u8de8\u5e73\u53f0\u6743\u9650\u5b9e\u65bd\u7684\u4e0d\u4e00\u81f4\u6027\u3001\u4e0d\u5b8c\u6574\u6027\u548c\u6f0f\u6d1e\uff0c\u5e76\u901a\u8fc7Permissioner\u5de5\u5177\u8bc6\u522b\u591a\u79cd\u653b\u51fb\u98ce\u9669\u3002", "motivation": "PWA\u867d\u7136\u7ed9\u4e88\u4e86\u7cfb\u7edf\u7ea7\u529f\u80fd\uff0c\u4f46\u5176\u6743\u9650\u7ba1\u7406\u5728\u4e0d\u540c\u5e73\u53f0\u548c\u6d4f\u89c8\u5668\u4e0a\u5b58\u5728\u4e0d\u4e00\u81f4\u548c\u6a21\u7cca\u7684\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u4e86Permissioner\u8de8\u5e73\u53f0\u5206\u6790\u5de5\u5177\uff0c\u5bf9PWA\u6743\u9650\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u5206\u6790\u4e86\u6743\u9650\u6267\u884c\u7684\u4e0d\u4e00\u81f4\u6027\u548c\u6f0f\u6d1e\u3002", "result": "\u53d1\u73b0\u4e86\u6743\u9650\u6cc4\u6f0f\u3001\u8bbe\u5907\u8bc6\u522b\u548cPermission API\u6ee5\u7528\u7b49\u591a\u79cd\u653b\u51fb\u98ce\u9669\uff0c\u4e0e\u6d4f\u89c8\u5668\u5382\u5546\u5408\u4f5c\u89e3\u51b3\u4e86\u90e8\u5206\u95ee\u9898\u3002", "conclusion": "\u5f3a\u8c03\u4e86PWA\u9700\u8981\u7edf\u4e00\u3001\u5065\u58ee\u7684\u6743\u9650\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u7684\u53ef\u64cd\u4f5c\u6307\u5357\u3002"}}
{"id": "2509.13333", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13333", "abs": "https://arxiv.org/abs/2509.13333", "authors": ["Maheep Chaudhary", "Ian Su", "Nikhil Hooda", "Nishith Shankar", "Julia Tan", "Kevin Zhu", "Ashwinee Panda", "Ryan Lagasse", "Vasu Sharma"], "title": "Evaluation Awareness Scales Predictably in Open-Weights Large Language Models", "comment": null, "summary": "Large language models (LLMs) can internally distinguish between evaluation\nand deployment contexts, a behaviour known as \\emph{evaluation awareness}. This\nundermines AI safety evaluations, as models may conceal dangerous capabilities\nduring testing. Prior work demonstrated this in a single $70$B model, but the\nscaling relationship across model sizes remains unknown. We investigate\nevaluation awareness across $15$ models scaling from $0.27$B to $70$B\nparameters from four families using linear probing on steering vector\nactivations. Our results reveal a clear power-law scaling: evaluation awareness\nincreases predictably with model size. This scaling law enables forecasting\ndeceptive behavior in future larger models and guides the design of scale-aware\nevaluation strategies for AI safety. A link to the implementation of this paper\ncan be found at\nhttps://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u8bc4\u4f30\u610f\u8bc6\u884c\u4e3a\uff0c\u4e14\u8bc4\u4f30\u610f\u8bc6\u968f\u6a21\u578b\u89c4\u6a21\u5448\u5e42\u5f8b\u589e\u957f\uff0c\u53ef\u7528\u4e8e\u9884\u6d4b\u672a\u6765\u66f4\u5927\u6a21\u578b\u7684\u6b3a\u9a97\u884c\u4e3a\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u8bc4\u4f30\u548c\u90e8\u7f72\u73af\u5883\u4e2d\u533a\u5206\u884c\u4e3a\uff0c\u8fd9\u79cd\u8bc4\u4f30\u610f\u8bc6\u4f1a\u7834\u574fAI\u5b89\u5168\u8bc4\u4f30\uff0c\u56e0\u4e3a\u6a21\u578b\u53ef\u80fd\u5728\u6d4b\u8bd5\u65f6\u9690\u85cf\u5371\u9669\u80fd\u529b\u3002\u4e4b\u524d\u7684\u7814\u7a76\u4ec5\u5728\u5355\u4e2a70B\u6a21\u578b\u4e0a\u8bc1\u660e\u4e86\u8fd9\u4e00\u70b9\uff0c\u4f46\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u95f4\u7684\u7f29\u653e\u5173\u7cfb\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u63a2\u6d4b\u65b9\u6cd5\u5206\u6790\u4ece0.27B\u523070B\u53c2\u6570\u768415\u4e2a\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u7684\u8f6c\u5411\u5411\u91cf\u6fc0\u6d3b\uff0c\u7814\u7a76\u8bc4\u4f30\u610f\u8bc6\u7684\u7f29\u653e\u89c4\u5f8b\u3002", "result": "\u53d1\u73b0\u8bc4\u4f30\u610f\u8bc6\u968f\u6a21\u578b\u89c4\u6a21\u5448\u6e05\u6670\u7684\u5e42\u5f8b\u7f29\u653e\u5173\u7cfb\uff0c\u8bc4\u4f30\u610f\u8bc6\u968f\u6a21\u578b\u5927\u5c0f\u53ef\u9884\u6d4b\u5730\u589e\u52a0\u3002", "conclusion": "\u8fd9\u79cd\u7f29\u653e\u89c4\u5f8b\u80fd\u591f\u9884\u6d4b\u672a\u6765\u66f4\u5927\u6a21\u578b\u7684\u6b3a\u9a97\u884c\u4e3a\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u89c4\u6a21\u611f\u77e5\u7684AI\u5b89\u5168\u8bc4\u4f30\u7b56\u7565\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2509.13471", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13471", "abs": "https://arxiv.org/abs/2509.13471", "authors": ["Sina Gogani-Khiabani", "Ashutosh Trivedi", "Diptikalyan Saha", "Saeid Tizpaz-Niari"], "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "comment": "To appear at ICSE 26. 12 pages", "summary": "Large language models (LLMs) show promise for translating natural-language\nstatutes into executable logic, but reliability in legally critical settings\nremains challenging due to ambiguity and hallucinations. We present an agentic\napproach for developing legal-critical software, using U.S. federal tax\npreparation as a case study. The key challenge is test-case generation under\nthe oracle problem, where correct outputs require interpreting law. Building on\nmetamorphic testing, we introduce higher-order metamorphic relations that\ncompare system outputs across structured shifts among similar individuals.\nBecause authoring such relations is tedious and error-prone, we use an\nLLM-driven, role-based framework to automate test generation and code\nsynthesis. We implement a multi-agent system that translates tax code into\nexecutable software and incorporates a metamorphic-testing agent that searches\nfor counterexamples. In experiments, our framework using a smaller model\n(GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier\nmodels (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks. These results\nsupport agentic LLM methodologies as a path to robust, trustworthy\nlegal-critical software from natural-language specifications.", "AI": {"tldr": "\u4f7f\u7528\u591a\u6bb5\u673a\u5668\u4eba\u6846\u67b6\u5c06\u7f8e\u56fd\u8054\u90a6\u7a0e\u6cd5\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u901a\u8fc7\u9ad8\u9636\u53d8\u5f62\u6d4b\u8bd5\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u6848\u4f8b\uff0c\u5728\u590d\u6742\u7a0e\u6cd5\u4efb\u52a1\u4e0a\u8f83\u5927\u578b\u6a21\u578b\u66f4\u53ef\u9760", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u5173\u952e\u573a\u666f\u4e2d\u5b58\u5728\u7684\u6a21\u7cca\u6027\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u9ad8\u6cd5\u5f8b\u5173\u952e\u8f6f\u4ef6\u7684\u53ef\u9760\u6027", "method": "\u91c7\u7528\u591a\u6bb5\u673a\u5668\u4eba\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u9636\u53d8\u5f62\u5173\u7cfb\u8fdb\u884c\u6d4b\u8bd5\u6848\u4f8b\u751f\u6210\u548c\u4ee3\u7801\u5408\u6210\uff0c\u5305\u542b\u53d8\u5f62\u6d4b\u8bd5\u6bb5\u673a\u5668\u4eba\u641c\u7d22\u53cd\u4f8b", "result": "\u4f7f\u7528\u8f83\u5c0f\u6a21\u578b(GPT-4o-mini)\u8fbe\u523045%\u6700\u5dee\u60c5\u51b5\u901a\u8fc7\u7387\uff0c\u8d85\u8fc7\u524d\u6cbf\u6a21\u578b(GPT-4o\u548cClaude 3.5\u76849-15%)\u901a\u8fc7\u7387", "conclusion": "\u591a\u6bb5\u673a\u5668\u4ebaLLM\u65b9\u6cd5\u662f\u5f00\u53d1\u7a33\u5065\u3001\u53ef\u4fe1\u8d56\u6cd5\u5f8b\u5173\u952e\u8f6f\u4ef6\u7684\u6709\u6548\u9014\u5f84"}}
{"id": "2509.13581", "categories": ["cs.CR", "cs.SD"], "pdf": "https://arxiv.org/pdf/2509.13581", "abs": "https://arxiv.org/abs/2509.13581", "authors": ["Mohamad Fakih", "Rahul Dharmaji", "Youssef Mahmoud", "Halima Bouzidi", "Mohammad Abdullah Al Faruque"], "title": "Invisible Ears at Your Fingertips: Acoustic Eavesdropping via Mouse Sensors", "comment": "Appearing in the Annual Computer Security Applications Conference\n  (ACSAC 2025)", "summary": "Modern optical mouse sensors, with their advanced precision and high\nresponsiveness, possess an often overlooked vulnerability: they can be\nexploited for side-channel attacks. This paper introduces Mic-E-Mouse, the\nfirst-ever side-channel attack that targets high-performance optical mouse\nsensors to covertly eavesdrop on users. We demonstrate that audio signals can\ninduce subtle surface vibrations detectable by a mouse's optical sensor.\nRemarkably, user-space software on popular operating systems can collect and\nbroadcast this sensitive side channel, granting attackers access to raw mouse\ndata without requiring direct system-level permissions. Initially, the\nvibration signals extracted from mouse data are of poor quality due to\nnon-uniform sampling, a non-linear frequency response, and significant\nquantization. To overcome these limitations, Mic-E-Mouse employs a\nsophisticated end-to-end data filtering pipeline that combines Wiener\nfiltering, resampling corrections, and an innovative encoder-only spectrogram\nneural filtering technique. We evaluate the attack's efficacy across diverse\nconditions, including speaking volume, mouse polling rate and DPI, surface\nmaterials, speaker languages, and environmental noise. In controlled\nenvironments, Mic-E-Mouse improves the signal-to-noise ratio (SNR) by up to +19\ndB for speech reconstruction. Furthermore, our results demonstrate a speech\nrecognition accuracy of roughly 42% to 61% on the AudioMNIST and VCTK datasets.\nAll our code and datasets are publicly accessible on\nhttps://sites.google.com/view/mic-e-mouse.", "AI": {"tldr": "Mic-E-Mouse\u662f\u4e00\u79cd\u65b0\u578b\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u5229\u7528\u9ad8\u6027\u80fd\u5149\u5b66\u9f20\u6807\u4f20\u611f\u5668\u901a\u8fc7\u8868\u9762\u632f\u52a8\u7a83\u542c\u97f3\u9891\u4fe1\u53f7\uff0c\u65e0\u9700\u7cfb\u7edf\u6743\u9650\u5373\u53ef\u83b7\u53d6\u539f\u59cb\u9f20\u6807\u6570\u636e\u3002", "motivation": "\u73b0\u4ee3\u5149\u5b66\u9f20\u6807\u4f20\u611f\u5668\u5177\u6709\u9ad8\u7cbe\u5ea6\u548c\u9ad8\u54cd\u5e94\u6027\uff0c\u4f46\u5b58\u5728\u88ab\u5229\u7528\u8fdb\u884c\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u6f5c\u5728\u6f0f\u6d1e\uff0c\u76ee\u524d\u8fd9\u65b9\u9762\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u91c7\u7528\u7aef\u5230\u7aef\u6570\u636e\u8fc7\u6ee4\u7ba1\u9053\uff0c\u7ed3\u5408\u7ef4\u7eb3\u6ee4\u6ce2\u3001\u91cd\u91c7\u6837\u6821\u6b63\u548c\u521b\u65b0\u7684\u7f16\u7801\u5668-\u9891\u8c31\u56fe\u795e\u7ecf\u6ee4\u6ce2\u6280\u672f\uff0c\u5904\u7406\u975e\u5747\u5300\u91c7\u6837\u548c\u975e\u7ebf\u6027\u9891\u7387\u54cd\u5e94\u7b49\u95ee\u9898\u3002", "result": "\u5728\u53d7\u63a7\u73af\u5883\u4e2d\uff0c\u8bed\u97f3\u91cd\u5efa\u7684\u4fe1\u566a\u6bd4\u63d0\u5347\u9ad8\u8fbe+19dB\uff0c\u5728AudioMNIST\u548cVCTK\u6570\u636e\u96c6\u4e0a\u7684\u8bed\u97f3\u8bc6\u522b\u51c6\u786e\u7387\u8fbe\u523042%\u81f361%\u3002", "conclusion": "\u5149\u5b66\u9f20\u6807\u4f20\u611f\u5668\u786e\u5b9e\u5b58\u5728\u4e25\u91cd\u7684\u4fa7\u4fe1\u9053\u5b89\u5168\u98ce\u9669\uff0cMic-E-Mouse\u653b\u51fb\u65b9\u6cd5\u6709\u6548\u8bc1\u660e\u4e86\u8fd9\u4e00\u6f0f\u6d1e\u7684\u5b9e\u7528\u6027\uff0c\u9700\u8981\u5f15\u8d77\u5b89\u5168\u793e\u533a\u7684\u91cd\u89c6\u3002"}}
{"id": "2509.13334", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13334", "abs": "https://arxiv.org/abs/2509.13334", "authors": ["Anand Swaroop", "Akshat Nallani", "Saksham Uboweja", "Adiliia Uzdenova", "Michael Nguyen", "Kevin Zhu", "Sunishchal Dev", "Ashwinee Panda", "Vasu Sharma", "Maheep Chaudhary"], "title": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness", "comment": null, "summary": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving\nlarge language model performance on complex tasks, but recent work shows that\nreasoning steps often fail to causally influence the final answer, creating\nbrittle and untrustworthy outputs. Prior approaches focus primarily on\nmeasuring faithfulness, while methods for systematically improving it remain\nlimited. We introduce Faithful Reasoning via Intervention Training (FRIT), a\nscalable alignment method that trains models to produce causally consistent\nreasoning by learning from systematically corrupted examples. FRIT generates\nsynthetic training data by intervening on individual reasoning steps in\nmodel-generated CoTs, creating faithful/unfaithful pairs that highlight when\nreasoning breaks down. We then apply Direct Preference Optimization to teach\nmodels to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B\nand Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases\nfaithful reasoning by $3.4$ percentage points for Mistral on GSM8K while\nimproving accuracy by $7.6$ percentage points. Our approach provides the first\nscalable, supervision-free method for training language models to produce more\nreliable and interpretable reasoning, addressing a critical gap between\nreasoning performance and trustworthiness. We release our code at\n\\href{https://github.com/Anut-py/frit}.", "AI": {"tldr": "FRIT\u662f\u4e00\u79cd\u901a\u8fc7\u5e72\u9884\u8bad\u7ec3\u63d0\u5347\u601d\u7ef4\u94fe\u63a8\u7406\u5fe0\u5b9e\u6027\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u5408\u6210\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u504f\u597d\u56e0\u679c\u4e00\u81f4\u7684\u63a8\u7406\u8def\u5f84\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u7684\u5fe0\u5b9e\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u601d\u7ef4\u94fe\u63a8\u7406\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u6b65\u9aa4\u4e0e\u6700\u7ec8\u7b54\u6848\u7f3a\u4e4f\u56e0\u679c\u5173\u8054\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u8f93\u51fa\u8106\u5f31\u4e14\u4e0d\u53ef\u4fe1\u3002\u867d\u7136\u5df2\u6709\u65b9\u6cd5\u5173\u6ce8\u5fe0\u5b9e\u6027\u6d4b\u91cf\uff0c\u4f46\u7cfb\u7edf\u6027\u63d0\u5347\u5fe0\u5b9e\u6027\u7684\u65b9\u6cd5\u4ecd\u7136\u6709\u9650\u3002", "method": "\u63d0\u51faFRIT\u65b9\u6cd5\uff1a1\uff09\u901a\u8fc7\u5bf9\u6a21\u578b\u751f\u6210\u7684\u601d\u7ef4\u94fe\u8fdb\u884c\u5e72\u9884\uff0c\u521b\u5efa\u5fe0\u5b9e/\u4e0d\u5fe0\u5b9e\u7684\u63a8\u7406\u5bf9\uff1b2\uff09\u4f7f\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\u8bad\u7ec3\u6a21\u578b\u504f\u597d\u56e0\u679c\u4e00\u81f4\u7684\u63a8\u7406\u8def\u5f84\uff1b3\uff09\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u5373\u53ef\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728Qwen3-8B\u548cMistral-7B-v0.1\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0cFRIT\u4f7fMistral\u5728GSM8K\u4efb\u52a1\u4e0a\u7684\u5fe0\u5b9e\u63a8\u7406\u63d0\u9ad8\u4e863.4\u4e2a\u767e\u5206\u70b9\uff0c\u51c6\u786e\u6027\u63d0\u9ad8\u4e867.6\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "FRIT\u662f\u9996\u4e2a\u53ef\u6269\u5c55\u3001\u65e0\u76d1\u7763\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u66f4\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u63a8\u7406\u6027\u80fd\u4e0e\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002"}}
{"id": "2509.13487", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13487", "abs": "https://arxiv.org/abs/2509.13487", "authors": ["Abubakari Alidu", "Michele Ciavotta", "Flavio DePaoli"], "title": "Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline Generation", "comment": null, "summary": "Developing reliable data enrichment pipelines demands significant engineering\nexpertise. We present Prompt2DAG, a methodology that transforms natural\nlanguage descriptions into executable Apache Airflow DAGs. We evaluate four\ngeneration approaches -- Direct, LLM-only, Hybrid, and Template-based -- across\n260 experiments using thirteen LLMs and five case studies to identify optimal\nstrategies for production-grade automation. Performance is measured using a\npenalized scoring framework that combines reliability with code quality (SAT),\nstructural integrity (DST), and executability (PCT). The Hybrid approach\nemerges as the optimal generative method, achieving a 78.5% success rate with\nrobust quality scores (SAT: 6.79, DST: 7.67, PCT: 7.76). This significantly\noutperforms the LLM-only (66.2% success) and Direct (29.2% success) methods.\nOur findings show that reliability, not intrinsic code quality, is the primary\ndifferentiator. Cost-effectiveness analysis reveals the Hybrid method is over\ntwice as efficient as Direct prompting per successful DAG. We conclude that a\nstructured, hybrid approach is essential for balancing flexibility and\nreliability in automated workflow generation, offering a viable path to\ndemocratize data pipeline development.", "AI": {"tldr": "Prompt2DAG\u662f\u4e00\u4e2a\u5c06\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u8f6c\u6362\u4e3a\u53ef\u6267\u884cApache Airflow DAG\u7684\u65b9\u6cd5\u8bba\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u5b9e\u73b0\u4e8678.5%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u5f00\u53d1\u53ef\u9760\u7684\u6570\u636e\u4e30\u5bcc\u7ba1\u9053\u9700\u8981\u5927\u91cf\u5de5\u7a0b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5e0c\u671b\u901a\u8fc7\u81ea\u52a8\u5316\u65b9\u6cd5\u964d\u4f4e\u6570\u636e\u7ba1\u9053\u5f00\u53d1\u7684\u95e8\u69db\u3002", "method": "\u8bc4\u4f30\u4e86\u56db\u79cd\u751f\u6210\u65b9\u6cd5\uff08\u76f4\u63a5\u3001\u7eafLLM\u3001\u6df7\u5408\u548c\u57fa\u4e8e\u6a21\u677f\uff09\uff0c\u4f7f\u752813\u4e2aLLM\u548c5\u4e2a\u6848\u4f8b\u7814\u7a76\u8fdb\u884c260\u6b21\u5b9e\u9a8c\uff0c\u91c7\u7528\u60e9\u7f5a\u8bc4\u5206\u6846\u67b6\u8bc4\u4f30\u53ef\u9760\u6027\u3001\u4ee3\u7801\u8d28\u91cf\u3001\u7ed3\u6784\u5b8c\u6574\u6027\u548c\u53ef\u6267\u884c\u6027\u3002", "result": "\u6df7\u5408\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u6210\u529f\u738778.5%\uff0c\u8d28\u91cf\u8bc4\u5206\u4f18\u5f02\uff08SAT:6.79, DST:7.67, PCT:7.76\uff09\uff0c\u6210\u672c\u6548\u76ca\u662f\u76f4\u63a5\u63d0\u793a\u6cd5\u7684\u4e24\u500d\u4ee5\u4e0a\u3002", "conclusion": "\u7ed3\u6784\u5316\u6df7\u5408\u65b9\u6cd5\u5bf9\u4e8e\u5e73\u8861\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u751f\u6210\u7684\u7075\u6d3b\u6027\u548c\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u6570\u636e\u7ba1\u9053\u5f00\u53d1\u7684\u6c11\u4e3b\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2509.13597", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13597", "abs": "https://arxiv.org/abs/2509.13597", "authors": ["Abhishek Goswami"], "title": "Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents", "comment": "17 pages, 6 figures, 2 Tables", "summary": "Autonomous LLM agents can issue thousands of API calls per hour without human\noversight. OAuth 2.0 assumes deterministic clients, but in agentic settings\nstochastic reasoning, prompt injection, or multi-agent orchestration can\nsilently expand privileges.\n  We introduce Agentic JWT (A-JWT), a dual-faceted intent token that binds each\nagent's action to verifiable user intent and, optionally, to a specific\nworkflow step. A-JWT carries an agent's identity as a one-way checksum hash\nderived from its prompt, tools and configuration, and a chained delegation\nassertion to prove which downstream agent may execute a given task, and\nper-agent proof-of-possession keys to prevent replay and in-process\nimpersonation. We define a new authorization mechanism and add a lightweight\nclient shim library that self-verifies code at run time, mints intent tokens,\ntracks workflow steps and derives keys, thus enabling secure agent identity and\nseparation even within a single process.\n  We illustrate a comprehensive threat model for agentic applications,\nimplement a Python proof-of-concept and show functional blocking of\nscope-violating requests, replay, impersonation, and prompt-injection pathways\nwith sub-millisecond overhead on commodity hardware. The design aligns with\nongoing OAuth agent discussions and offers a drop-in path toward zero-trust\nguarantees for agentic applications. A comprehensive performance and security\nevaluation with experimental results will appear in our forthcoming journal\npublication", "AI": {"tldr": "\u63d0\u51faAgentic JWT(A-JWT)\u65b9\u6848\uff0c\u901a\u8fc7\u53cc\u9762\u610f\u56fe\u4ee4\u724c\u7ed1\u5b9a\u81ea\u6cbbLLM\u4ee3\u7406\u884c\u4e3a\u4e0e\u7528\u6237\u610f\u56fe\uff0c\u89e3\u51b3OAuth 2.0\u5728\u968f\u673a\u7406\u6027\u4ee3\u7406\u73af\u5883\u4e2d\u7684\u6743\u9650\u6269\u5f20\u98ce\u9669", "motivation": "\u81ea\u6cbbLLM\u4ee3\u7406\u53ef\u80fd\u901a\u8fc7\u968f\u673a\u7406\u6027\u3001\u63d0\u793a\u6ce8\u5165\u6216\u591a\u4ee3\u7406\u534f\u540c\u9ed8\u9ed8\u6269\u5f20\u6743\u9650\uff0cOAuth 2.0\u5047\u8bbe\u5ba2\u6237\u7aef\u662f\u786e\u5b9a\u6027\u7684\uff0c\u4f46\u5728\u4ee3\u7406\u73af\u5883\u4e2d\u5b58\u5728\u5b89\u5168\u98ce\u9669", "method": "\u8bbe\u8ba1A-JWT\u53cc\u9762\u610f\u56fe\u4ee4\u724c\uff0c\u5305\u542b\u4ee3\u7406\u8eab\u4efd\u54c8\u5e0c\u6821\u9a8c\u548c\u94fe\u5f0f\u6388\u6743\u65ad\u8a00\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5ba2\u6237\u7aef\u5e93\u8fdb\u884c\u8fd0\u884c\u65f6\u81ea\u6211\u9a8c\u8bc1\u548c\u4ee4\u724c\u7b7e\u53d1", "result": "\u5b9e\u73b0\u4e86Python\u539f\u578b\uff0c\u80fd\u591f\u963b\u585e\u8303\u56f4\u8fdd\u89c4\u8bf7\u6c42\u3001\u91cd\u653e\u653b\u51fb\u3001\u5192\u5145\u653b\u51fb\u548c\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e\uff0c\u5728\u5546\u4e1a\u786c\u4ef6\u4e0a\u4ec5\u4ea7\u751f\u6beb\u79d2\u7ea7\u6027\u80fd\u5f00\u9500", "conclusion": "A-JWT\u4e3a\u81ea\u6cbb\u4ee3\u7406\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u7f1d\u96c6\u6210\u7684\u96f6\u4fe1\u4efb\u4fdd\u969c\u65b9\u6848\uff0c\u9002\u914d\u5f53\u524dOAuth\u4ee3\u7406\u8ba8\u8bba\uff0c\u5177\u6709\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u62a4\u80fd\u529b"}}
{"id": "2509.13339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13339", "abs": "https://arxiv.org/abs/2509.13339", "authors": ["Ming Jin", "Hyunin Lee"], "title": "Position: AI Safety Must Embrace an Antifragile Perspective", "comment": null, "summary": "This position paper contends that modern AI research must adopt an\nantifragile perspective on safety -- one in which the system's capacity to\nguarantee long-term AI safety such as handling rare or out-of-distribution\n(OOD) events expands over time. Conventional static benchmarks and single-shot\nrobustness tests overlook the reality that environments evolve and that models,\nif left unchallenged, can drift into maladaptation (e.g., reward hacking,\nover-optimization, or atrophy of broader capabilities). We argue that an\nantifragile approach -- Rather than striving to rapidly reduce current\nuncertainties, the emphasis is on leveraging those uncertainties to better\nprepare for potentially greater, more unpredictable uncertainties in the future\n-- is pivotal for the long-term reliability of open-ended ML systems. In this\nposition paper, we first identify key limitations of static testing, including\nscenario diversity, reward hacking, and over-alignment. We then explore the\npotential of antifragile solutions to manage rare events. Crucially, we\nadvocate for a fundamental recalibration of the methods used to measure,\nbenchmark, and continually improve AI safety over the long term, complementing\nexisting robustness approaches by providing ethical and practical guidelines\ntowards fostering an antifragile AI safety community.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20AI\u5b89\u5168\u7814\u7a76\u5e94\u91c7\u7528\u6297\u8106\u5f31\u6027\u89c6\u89d2\uff0c\u4f7f\u7cfb\u7edf\u5904\u7406\u7f55\u89c1\u4e8b\u4ef6\u548c\u5206\u5e03\u5916\u4e8b\u4ef6\u7684\u80fd\u529b\u968f\u65f6\u95f4\u589e\u5f3a\uff0c\u800c\u975e\u4f9d\u8d56\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e00\u6b21\u6027\u9c81\u68d2\u6027\u6d4b\u8bd5\u65e0\u6cd5\u5e94\u5bf9\u73af\u5883\u6f14\u53d8\u548c\u6a21\u578b\u6f02\u79fb\u95ee\u9898\uff08\u5982\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u3001\u8fc7\u5ea6\u4f18\u5316\u7b49\uff09\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u786e\u4fddAI\u7cfb\u7edf\u7684\u957f\u671f\u5b89\u5168\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u6297\u8106\u5f31\u6027\u65b9\u6cd5\uff0c\u5229\u7528\u5f53\u524d\u4e0d\u786e\u5b9a\u6027\u6765\u66f4\u597d\u51c6\u5907\u5e94\u5bf9\u672a\u6765\u66f4\u5927\u3001\u66f4\u4e0d\u53ef\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5305\u62ec\u91cd\u65b0\u6821\u51c6AI\u5b89\u5168\u7684\u6d4b\u91cf\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u6301\u7eed\u6539\u8fdb\u65b9\u6cd5\u3002", "result": "\u8bc6\u522b\u4e86\u9759\u6001\u6d4b\u8bd5\u7684\u5173\u952e\u5c40\u9650\u6027\uff08\u573a\u666f\u591a\u6837\u6027\u4e0d\u8db3\u3001\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u3001\u8fc7\u5ea6\u5bf9\u9f50\u7b49\uff09\uff0c\u5e76\u63a2\u7d22\u4e86\u6297\u8106\u5f31\u6027\u89e3\u51b3\u65b9\u6848\u7ba1\u7406\u7f55\u89c1\u4e8b\u4ef6\u7684\u6f5c\u529b\u3002", "conclusion": "\u6297\u8106\u5f31\u6027\u65b9\u6cd5\u5bf9\u4e8e\u5f00\u653e\u7aef\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u957f\u671f\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5efa\u7acb\u6297\u8106\u5f31\u7684AI\u5b89\u5168\u793e\u533a\uff0c\u63d0\u4f9b\u4f26\u7406\u548c\u5b9e\u8df5\u6307\u5bfc\u65b9\u9488\u6765\u8865\u5145\u73b0\u6709\u9c81\u68d2\u6027\u65b9\u6cd5\u3002"}}
{"id": "2509.13535", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13535", "abs": "https://arxiv.org/abs/2509.13535", "authors": ["S M Farah Al Fahim", "Md Nakhla Rafi", "Zeyang Ma", "Dong Jae Kim", "Tse-Hsun", "Chen"], "title": "Crash Report Enhancement with Large Language Models: An Empirical Study", "comment": null, "summary": "Crash reports are central to software maintenance, yet many lack the\ndiagnostic detail developers need to debug efficiently. We examine whether\nlarge language models can enhance crash reports by adding fault locations,\nroot-cause explanations, and repair suggestions. We study two enhancement\nstrategies: Direct-LLM, a single-shot approach that uses stack-trace context,\nand Agentic-LLM, an iterative approach that explores the repository for\nadditional evidence. On a dataset of 492 real-world crash reports, LLM-enhanced\nreports improve Top-1 problem-localization accuracy from 10.6% (original\nreports) to 40.2-43.1%, and produce suggested fixes that closely resemble\ndeveloper patches (CodeBLEU around 56-57%). Both our manual evaluations and\nLLM-as-a-judge assessment show that Agentic-LLM delivers stronger root-cause\nexplanations and more actionable repair guidance. A user study with 16\nparticipants further confirms that enhanced reports make crashes easier to\nunderstand and resolve, with the largest improvement in repair guidance. These\nresults indicate that supplying LLMs with stack traces and repository code\nyields enhanced crash reports that are substantially more useful for debugging.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5920\u663e\u8457\u63d0\u5347\u5d29\u6e83\u62a5\u544a\u7684\u8c03\u8bd5\u6548\u679c\uff0c\u901a\u8fc7\u6dfb\u52a0\u6545\u969c\u4f4d\u7f6e\u3001\u6839\u56e0\u89e3\u91ca\u548c\u4fee\u590d\u5efa\u8bae\uff0c\u4f7f\u5f97\u95ee\u9898\u5b9a\u4f4d\u51c6\u786e\u7387\u4ece10.6%\u63d0\u5347\u523040.2-43.1%", "motivation": "\u5d29\u6e83\u62a5\u544a\u7f3a\u4e4f\u8be6\u7ec6\u7684\u8bca\u65ad\u4fe1\u606f\uff0c\u5f71\u54cd\u5f00\u53d1\u8005\u8c03\u8bd5\u6548\u7387\uff0c\u9700\u8981\u63d0\u5347\u5176\u8c03\u8bd5\u4ef7\u503c", "method": "\u7814\u7a76\u4e24\u79cdLLM\u589e\u5f3a\u7b56\u7565\uff1aDirect-LLM\uff08\u5355\u6b21\u8f93\u5165\u5806\u6808\u8ddf\u8e2a\uff09\u548cAgentic-LLM\uff08\u8fed\u4ee3\u67e5\u627e\u4ed3\u5e93\u8bc1\u636e\uff09\uff0c\u5728492\u4e2a\u771f\u5b9e\u5d29\u6e83\u62a5\u544a\u4e0a\u8fdb\u884c\u5b9e\u9a8c", "result": "\u589e\u5f3a\u540e\u62a5\u544a\u663e\u8457\u63d0\u9ad8\u4e86\u95ee\u9898\u5b9a\u4f4d\u51c6\u786e\u7387\uff0c\u4ea7\u751f\u7684\u4fee\u590d\u5efa\u8bae\u4e0e\u5f00\u53d1\u8005\u8865\u4e01\u76f8\u4f3c\u5ea6\u9ad8\uff08CodeBLEU\u7ea656-57%\uff09\uff0cAgentic-LLM\u5728\u6839\u56e0\u89e3\u91ca\u548c\u4fee\u590d\u6307\u5bfc\u65b9\u9762\u66f4\u4f18", "conclusion": "\u4e3aLLM\u63d0\u4f9b\u5806\u6808\u8ddf\u8e2a\u548c\u4ed3\u5e93\u4ee3\u7801\u53ef\u4ee5\u751f\u6210\u66f4\u6709\u7528\u7684\u5d29\u6e83\u62a5\u544a\uff0c\u5927\u5e45\u63d0\u5347\u8c03\u8bd5\u6548\u679c\uff0c\u5c24\u5176\u5728\u4fee\u590d\u6307\u5bfc\u65b9\u9762\u6539\u5584\u6700\u4e3a\u663e\u8457"}}
{"id": "2509.13627", "categories": ["cs.CR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13627", "abs": "https://arxiv.org/abs/2509.13627", "authors": ["Vijay Kumar Butte", "Sujata Butte"], "title": "Secure, Scalable and Privacy Aware Data Strategy in Cloud", "comment": null, "summary": "The enterprises today are faced with the tough challenge of processing,\nstoring large amounts of data in a secure, scalable manner and enabling\ndecision makers to make quick, informed data driven decisions. This paper\naddresses this challenge and develops an effective enterprise data strategy in\nthe cloud. Various components of an effective data strategy are discussed and\narchitectures addressing security, scalability and privacy aspects are\nprovided.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4f01\u4e1a\u4e91\u7aef\u6570\u636e\u7b56\u7565\uff0c\u89e3\u51b3\u5927\u6570\u636e\u5904\u7406\u3001\u5b89\u5168\u5b58\u50a8\u548c\u53ca\u65f6\u51b3\u7b56\u7684\u6311\u6218", "motivation": "\u4f01\u4e1a\u9762\u4e34\u5904\u7406\u548c\u5b58\u50a8\u5927\u91cf\u6570\u636e\u7684\u6311\u6218\uff0c\u9700\u8981\u5728\u4fdd\u969c\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9690\u79c1\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u652f\u6301\u51b3\u7b56\u8005\u8fdb\u884c\u53ca\u65f6\u3001\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56", "method": "\u8ba8\u8bba\u6709\u6548\u6570\u636e\u7b56\u7565\u7684\u5404\u4e2a\u7ec4\u6210\u90e8\u5206\uff0c\u63d0\u4f9b\u4e86\u89e3\u51b3\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9690\u79c1\u6027\u95ee\u9898\u7684\u67b6\u6784\u65b9\u6848", "result": "\u5f00\u53d1\u51fa\u4e86\u4e00\u79cd\u5b8c\u6574\u7684\u4f01\u4e1a\u4e91\u7aef\u6570\u636e\u7b56\u7565\u6846\u67b6", "conclusion": "\u901a\u8fc7\u8bbe\u8ba1\u5408\u7406\u7684\u6570\u636e\u7b56\u7565\u548c\u67b6\u6784\uff0c\u4f01\u4e1a\u53ef\u4ee5\u6709\u6548\u5e94\u5bf9\u5927\u6570\u636e\u5904\u7406\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u5b89\u5168\u3001\u53ef\u6269\u5c55\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u6570\u636e\u7ba1\u7406"}}
{"id": "2509.13341", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13341", "abs": "https://arxiv.org/abs/2509.13341", "authors": ["Ahmet H. G\u00fczel", "Matthew Thomas Jackson", "Jarek Luca Liesen", "Tim Rockt\u00e4schel", "Jakob Nicolaus Foerster", "Ilija Bogunovic", "Jack Parker-Holder"], "title": "Imagined Autocurricula", "comment": null, "summary": "Training agents to act in embodied environments typically requires vast\ntraining data or access to accurate simulation, neither of which exists for\nmany cases in the real world. Instead, world models are emerging as an\nalternative leveraging offline, passively collected data, they make it possible\nto generate diverse worlds for training agents in simulation. In this work, we\nharness world models to generate imagined environments to train robust agents\ncapable of generalizing to novel task variations. One of the challenges in\ndoing this is ensuring the agent trains on useful generated data. We thus\npropose a novel approach, IMAC (Imagined Autocurricula), leveraging\nUnsupervised Environment Design (UED), which induces an automatic curriculum\nover generated worlds. In a series of challenging, procedurally generated\nenvironments, we show it is possible to achieve strong transfer performance on\nheld-out environments, having trained only inside a world model learned from a\nnarrower dataset. We believe this opens the path to utilizing larger-scale,\nfoundation world models for generally capable agents.", "AI": {"tldr": "\u5229\u7528\u4e16\u754c\u6a21\u578b\u751f\u6210\u60f3\u8c61\u73af\u5883\u8bad\u7ec3\u667a\u80fd\u4f53\uff0c\u901a\u8fc7IMAC\u65b9\u6cd5\u5b9e\u73b0\u81ea\u52a8\u8bfe\u7a0b\u5b66\u4e60\uff0c\u5728\u6709\u9650\u6570\u636e\u4e0b\u5b9e\u73b0\u5f3a\u6cdb\u5316\u6027\u80fd", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u8bad\u7ec3\u5177\u8eab\u667a\u80fd\u4f53\u901a\u5e38\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u6216\u7cbe\u786e\u6a21\u62df\uff0c\u4f46\u8fd9\u4e9b\u8d44\u6e90\u5f80\u5f80\u4e0d\u53ef\u5f97\u3002\u4e16\u754c\u6a21\u578b\u5229\u7528\u79bb\u7ebf\u88ab\u52a8\u6536\u96c6\u6570\u636e\u751f\u6210\u591a\u6837\u5316\u8bad\u7ec3\u73af\u5883\uff0c\u4f46\u9700\u8981\u786e\u4fdd\u751f\u6210\u6570\u636e\u5bf9\u8bad\u7ec3\u6709\u7528", "method": "\u63d0\u51faIMAC\uff08Imagined Autocurricula\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\uff08UED\uff09\uff0c\u5728\u751f\u6210\u7684\u4e16\u754c\u4e2d\u8bf1\u5bfc\u81ea\u52a8\u8bfe\u7a0b\u5b66\u4e60", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u7a0b\u5e8f\u751f\u6210\u73af\u5883\u4e2d\uff0c\u4ec5\u4f7f\u7528\u4ece\u8f83\u7a84\u6570\u636e\u96c6\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5c31\u80fd\u5728\u4fdd\u7559\u73af\u5883\u4e2d\u5b9e\u73b0\u5f3a\u5927\u7684\u8fc1\u79fb\u6027\u80fd", "conclusion": "\u8fd9\u4e3a\u5229\u7528\u66f4\u5927\u89c4\u6a21\u7684\u57fa\u7840\u4e16\u754c\u6a21\u578b\u8bad\u7ec3\u901a\u7528\u80fd\u529b\u667a\u80fd\u4f53\u5f00\u8f9f\u4e86\u9053\u8def"}}
{"id": "2509.13650", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13650", "abs": "https://arxiv.org/abs/2509.13650", "authors": ["Amena Amro", "Manar H. Alalfi"], "title": "GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit?", "comment": null, "summary": "As software development practices increasingly adopt AI-powered tools,\nensuring that such tools can support secure coding has become critical. This\nstudy evaluates the effectiveness of GitHub Copilot's recently introduced code\nreview feature in detecting security vulnerabilities. Using a curated set of\nlabeled vulnerable code samples drawn from diverse open-source projects\nspanning multiple programming languages and application domains, we\nsystematically assessed Copilot's ability to identify and provide feedback on\ncommon security flaws. Contrary to expectations, our results reveal that\nCopilot's code review frequently fails to detect critical vulnerabilities such\nas SQL injection, cross-site scripting (XSS), and insecure deserialization.\nInstead, its feedback primarily addresses low-severity issues, such as coding\nstyle and typographical errors. These findings expose a significant gap between\nthe perceived capabilities of AI-assisted code review and its actual\neffectiveness in supporting secure development practices. Our results highlight\nthe continued necessity of dedicated security tools and manual code audits to\nensure robust software security.", "AI": {"tldr": "GitHub Copilot\u4ee3\u7801\u5ba1\u67e5\u529f\u80fd\u5728\u68c0\u6d4b\u5b89\u5168\u6f0f\u6d1e\u65b9\u9762\u6548\u679c\u4e0d\u4f73\uff0c\u4e3b\u8981\u5173\u6ce8\u4f4e\u4e25\u91cd\u6027\u95ee\u9898\u800c\u975e\u5173\u952e\u5b89\u5168\u6f0f\u6d1e", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5f00\u53d1\u8d8a\u6765\u8d8a\u591a\u91c7\u7528AI\u5de5\u5177\uff0c\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u5de5\u5177\u5728\u652f\u6301\u5b89\u5168\u7f16\u7801\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662fGitHub Copilot\u65b0\u63a8\u51fa\u7684\u4ee3\u7801\u5ba1\u67e5\u529f\u80fd", "method": "\u4f7f\u7528\u6765\u81ea\u591a\u4e2a\u7f16\u7a0b\u8bed\u8a00\u548c\u5e94\u7528\u9886\u57df\u7684\u5f00\u6e90\u9879\u76ee\u4e2d\u7cbe\u9009\u7684\u6807\u8bb0\u6f0f\u6d1e\u4ee3\u7801\u6837\u672c\uff0c\u7cfb\u7edf\u8bc4\u4f30Copilot\u68c0\u6d4b\u5e38\u89c1\u5b89\u5168\u6f0f\u6d1e\u7684\u80fd\u529b", "result": "Copilot\u4ee3\u7801\u5ba1\u67e5\u7ecf\u5e38\u65e0\u6cd5\u68c0\u6d4bSQL\u6ce8\u5165\u3001XSS\u548c\u4e0d\u5b89\u5168\u53cd\u5e8f\u5217\u5316\u7b49\u5173\u952e\u6f0f\u6d1e\uff0c\u53cd\u9988\u4e3b\u8981\u9488\u5bf9\u7f16\u7801\u98ce\u683c\u548c\u62fc\u5199\u9519\u8bef\u7b49\u4f4e\u4e25\u91cd\u6027\u95ee\u9898", "conclusion": "AI\u8f85\u52a9\u4ee3\u7801\u5ba1\u67e5\u7684\u5b9e\u9645\u6548\u679c\u4e0e\u9884\u671f\u80fd\u529b\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u4ecd\u9700\u4e13\u7528\u5b89\u5168\u5de5\u5177\u548c\u4eba\u5de5\u4ee3\u7801\u5ba1\u8ba1\u6765\u786e\u4fdd\u8f6f\u4ef6\u5b89\u5168"}}
{"id": "2509.13684", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13684", "abs": "https://arxiv.org/abs/2509.13684", "authors": ["Lin Zhu", "Lingwei Kong", "Xin Ning", "Xiaoyang Qu", "Jianzong Wang"], "title": "Publicly Verifiable Private Information Retrieval Protocols Based on Function Secret Sharing", "comment": "Accepted by the 21st International Conference on Information Security\n  and Cryptology (Inscrypt2025)", "summary": "Private Information Retrieval (PIR) is a fundamental cryptographic primitive\nthat enables users to retrieve data from a database without revealing which\nitem is being accessed, thereby preserving query privacy. However, PIR\nprotocols also face the challenge of result verifiability, as users expect the\nreconstructed data to be trustworthy and authentic. In this work, we propose\ntwo effective constructions of publicly verifiable PIR (PVPIR) in the\nmulti-server setting, which achieve query privacy, correctness, and\nverifiability simultaneously. We further present three concrete instantiations\nbased on these constructions. For the point query, our protocol introduces\nminimal computational overhead and achieves strong verifiability guarantees\nwith significantly lower communication costs compared to existing Merkle\ntree-based approaches. For the predicate query, the communication complexity of\nour scheme remains stable as the database size increases, demonstrating strong\nscalability and suitability for large-scale private query applications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u516c\u5f00\u53ef\u9a8c\u8bc1\u7684\u591a\u670d\u52a1\u5668\u79c1\u6709\u4fe1\u606f\u68c0\u7d22(PVPIR)\u65b9\u6848\uff0c\u89e3\u51b3\u4e86PIR\u534f\u8bae\u4e2d\u7684\u7ed3\u679c\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u67e5\u8be2\u9690\u79c1\u6027\u548c\u6b63\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4f4e\u901a\u4fe1\u6210\u672c\u548c\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u79c1\u6709\u4fe1\u606f\u68c0\u7d22(PIR)\u534f\u8bae\u867d\u7136\u80fd\u591f\u4fdd\u62a4\u67e5\u8be2\u9690\u79c1\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u68c0\u7d22\u7ed3\u679c\u7684\u53ef\u9a8c\u8bc1\u6027\u652f\u6301\uff0c\u7528\u6237\u9700\u8981\u786e\u4fdd\u83b7\u53d6\u7684\u6570\u636e\u662f\u53ef\u4fe1\u8fc7\u7684\u548c\u771f\u5b9e\u7684\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u79cd\u516c\u5f00\u53ef\u9a8c\u8bc1PVPIR\u6784\u9020\u65b9\u6848\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e09\u4e2a\u5177\u4f53\u5b9e\u73b0\u3002\u5bf9\u4e8e\u70b9\u67e5\u8be2\uff0c\u534f\u8bae\u5f15\u5165\u6700\u5c0f\u8ba1\u7b97\u5f00\u9500\uff0c\u5bf9\u4e8e\u8c13\u8bcd\u67e5\u8be2\uff0c\u901a\u4fe1\u590d\u6742\u5ea6\u4fdd\u6301\u7a33\u5b9a\u3002", "result": "\u70b9\u67e5\u8be2\u534f\u8bae\u5728\u4fdd\u8bc1\u5f3a\u9a8c\u8bc1\u6027\u7684\u540c\u65f6\uff0c\u901a\u4fe1\u6210\u672c\u663e\u8457\u4f4e\u4e8e\u73b0\u6709\u7684Merkle\u6811\u65b9\u6848\u3002\u8c13\u8bcd\u67e5\u8be2\u534f\u8bae\u7684\u901a\u4fe1\u590d\u6742\u5ea6\u4e0d\u968f\u6570\u636e\u5e93\u89c4\u6a21\u589e\u5927\u800c\u589e\u957f\uff0c\u663e\u793a\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u516c\u5f00\u53ef\u9a8c\u8bc1PIR\u65b9\u6848\uff0c\u80fd\u591f\u5728\u591a\u670d\u52a1\u5668\u73af\u5883\u4e0b\u540c\u65f6\u5b9e\u73b0\u67e5\u8be2\u9690\u79c1\u6027\u3001\u6b63\u786e\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u79c1\u6709\u67e5\u8be2\u5e94\u7528\u3002"}}
{"id": "2509.13347", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13347", "abs": "https://arxiv.org/abs/2509.13347", "authors": ["Zihao Wang", "Muyao Li", "Kaichen He", "Xiangyu Wang", "Zhancun Mu", "Anji Liu", "Yitao Liang"], "title": "OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft", "comment": null, "summary": "The choice of action spaces is a critical yet unresolved challenge in\ndeveloping capable, end-to-end trainable agents. This paper first presents a\nlarge-scale, systematic comparison of prominent abstracted action spaces and\ntokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the\nopen-ended Minecraft. Our analysis reveals that no single action space is\nuniversally optimal; instead, the most effective abstraction is highly\ntask-dependent, creating a dilemma for building generalist agents. To resolve\nthis, we introduce Chain of Action (CoA), a novel framework that unifies\nhigh-level planning and low-level control within a single, monolithic VLA\nmodel. CoA treats an abstracted action not as a command for a separate policy,\nbut as an intermediate reasoning step--akin to a chain of thought--that guides\nthe generation of the final, executable action. Furthermore, we demonstrate\nthat an All-in-One agent trained on a diverse mixture of action spaces using\nthe CoA paradigm learns a more robust and generalizable policy. This unified\nagent achieves a new state-of-the-art, improving the overall task success rate\nover strong, specialized baselines. To foster reproducible research, we release\nthe OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive\nbenchmark of over 800 distinct tasks, curated datasets, source code, and all\npretrained model checkpoints at https://github.com/CraftJarvis/OpenHA", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86Chain of Action (CoA)\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9ad8\u7ea7\u89c4\u5212\u4e0e\u4f4e\u7ea7\u63a7\u5236\u7edf\u4e00\u5728\u5355\u4e2aVLA\u6a21\u578b\u4e2d\uff0c\u89e3\u51b3\u4e86\u52a8\u4f5c\u7a7a\u95f4\u9009\u62e9\u7684\u56f0\u5883\uff0c\u5e76\u5728Minecraft\u73af\u5883\u4e2d\u521b\u9020\u4e86\u65b0\u7684\u72b6\u6001\u4e0b\u7684\u827e\u7ed3\u679c\u3002", "motivation": "\u52a8\u4f5c\u7a7a\u95f4\u9009\u62e9\u662f\u5f00\u53d1\u80fd\u529b\u5f3a\u5927\u7684\u7ec8\u7aef\u5230\u7ec8\u7aef\u53ef\u8bad\u7ec3\u4ee3\u7406\u7684\u5173\u952e\u6311\u6218\uff0c\u4f46\u76ee\u524d\u6ca1\u6709\u901a\u7528\u7684\u6700\u4f18\u89e3\u51b3\u65b9\u6848\u3002\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u5206\u6790\u53d1\u73b0\uff0c\u6700\u4f18\u52a8\u4f5c\u62bd\u8c61\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u5177\u4f53\u4efb\u52a1\uff0c\u8fd9\u4e3a\u5efa\u7acb\u901a\u7528\u4ee3\u7406\u9020\u6210\u4e86\u56f0\u96be\u3002", "method": "\u63d0\u51faChain of Action (CoA)\u6846\u67b6\uff0c\u5c06\u62bd\u8c61\u52a8\u4f5c\u89c6\u4e3a\u7c7b\u4f3c\u601d\u7ef4\u94fe\u7684\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\uff0c\u7528\u4e8e\u6307\u5bfc\u6700\u7ec8\u53ef\u6267\u884c\u52a8\u4f5c\u7684\u751f\u6210\u3002\u5728\u591a\u6837\u5316\u52a8\u4f5c\u7a7a\u95f4\u6df7\u5408\u6570\u636e\u4e0a\u8bad\u7ec3All-in-One\u4ee3\u7406\uff0c\u5b66\u4e60\u66f4\u7a33\u5065\u548c\u53ef\u63a8\u5e7f\u7684\u7b56\u7565\u3002", "result": "\u7edf\u4e00\u7684CoA\u4ee3\u7406\u5728\u8fc7\u5f80800\u4e2a\u4e0d\u540c\u4efb\u52a1\u7684\u7efc\u5408\u6027\u80fd\u6d4b\u8bd5\u4e2d\uff0c\u8d85\u8d8a\u4e86\u6240\u6709\u4e13\u95e8\u5316\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u521b\u9020\u4e86\u65b0\u7684\u72b6\u6001\u4e0b\u7684\u827e\u7ed3\u679c\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u603b\u4f53\u4efb\u52a1\u6210\u529f\u7387\u3002", "conclusion": "CoA\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u4f5c\u7a7a\u95f4\u9009\u62e9\u56f0\u5883\uff0c\u8bc1\u660e\u4e86\u5728\u5355\u4e00\u6a21\u578b\u4e2d\u7edf\u4e00\u9ad8\u7ea7\u89c4\u5212\u4e0e\u4f4e\u7ea7\u63a7\u5236\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u5efa\u7acb\u66f4\u5f3a\u5927\u7684\u901a\u7528\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2509.13656", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13656", "abs": "https://arxiv.org/abs/2509.13656", "authors": ["Yingao Elaine Yao", "Vedant Nimje", "Varun Viswanath", "Saikat Dutta"], "title": "A Regression Testing Framework with Automated Assertion Generation for Machine Learning Notebooks", "comment": "22 pages, 2 figures, 6 tables", "summary": "Notebooks have become the de-facto choice for data scientists and machine\nlearning engineers for prototyping and experimenting with machine learning (ML)\npipelines. Notebooks provide an interactive interface for code, data, and\nvisualization. However, notebooks provide very limited support for testing.\nThus, during continuous development, many subtle bugs that do not lead to\ncrashes often go unnoticed and cause silent errors that manifest as performance\nregressions.\n  To address this, we introduce NBTest - the first regression testing framework\nthat allows developers to write cell-level assertions in notebooks and run such\nnotebooks in pytest or in continuous integration (CI) pipelines. NBTest offers\na library of assertion APIs, and a JupyterLab plugin that enables executing\nassertions. We also develop the first automated approach for generating\ncell-level assertions for key components in ML notebooks, such as data\nprocessing, model building, and model evaluation. NBTest aims to improve the\nreliability and maintainability of ML notebooks without adding developer\nburden.\n  We evaluate NBTest on 592 Kaggle notebooks. Overall, NBTest generates 21163\nassertions (35.75 on average per notebook). The generated assertions obtain a\nmutation score of 0.57 in killing ML-specific mutations. NBTest can catch\nregression bugs in previous versions of the Kaggle notebooks using assertions\ngenerated for the latest versions. Because ML pipelines involve non\ndeterministic computations, the assertions can be flaky. Hence, we also show\nhow NBTest leverages statistical techniques to minimize flakiness while\nretaining high fault-detection effectiveness. NBTest has been adopted in the CI\nof a popular ML library. Further, we perform a user study with 17 participants\nthat shows that notebook users find NBTest intuitive (Rating 4.3/5) and useful\nin writing assertions and testing notebooks (Rating 4.24/5).", "AI": {"tldr": "NBTest\u662f\u7b2c\u4e00\u4e2a\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u7b14\u8bb0\u672c\u7684\u56de\u5f52\u6d4b\u8bd5\u6846\u67b6\uff0c\u652f\u6301\u5355\u5143\u7ea7\u65ad\u8a00\u7f16\u5199\u548c\u5728CI\u4e2d\u8fd0\u884c\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u65ad\u8a00\u548c\u7edf\u8ba1\u6280\u672f\u63d0\u9ad8ML\u7b14\u8bb0\u672c\u7684\u53ef\u9760\u6027", "motivation": "\u7b14\u8bb0\u672c\u5728\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u4f46\u7f3a\u4e4f\u6d4b\u8bd5\u652f\u6301\uff0c\u5bfc\u81f4\u8bb8\u591a\u4e0d\u6613\u5bdf\u89c9\u7684bug\u548c\u6027\u80fd\u56de\u5f52\u95ee\u9898\u96be\u4ee5\u53d1\u73b0", "method": "\u5f00\u53d1NBTest\u6846\u67b6\uff0c\u63d0\u4f9b\u65ad\u8a00API\u5e93\u548cJupyterLab\u63d2\u4ef6\uff0c\u652f\u6301\u5355\u5143\u7ea7\u65ad\u8a00\u7f16\u5199\u548c\u81ea\u52a8\u751f\u6210ML\u5173\u952e\u7ec4\u4ef6\u7684\u65ad\u8a00\uff0c\u4f7f\u7528\u7edf\u8ba1\u6280\u672f\u51cf\u5c11\u975e\u786e\u5b9a\u6027\u8ba1\u7b97\u5e26\u6765\u7684\u6ce2\u52a8\u6027", "result": "\u5728592\u4e2aKaggle\u7b14\u8bb0\u672c\u4e0a\u751f\u621021163\u4e2a\u65ad\u8a00\uff08\u5e73\u574735.75\u4e2a/\u7b14\u8bb0\u672c\uff09\uff0c\u53d8\u5f02\u5f97\u52060.57\uff0c\u7528\u6237\u7814\u7a76\u663e\u793a\u76f4\u89c2\u6027\u8bc4\u52064.3/5\uff0c\u5b9e\u7528\u6027\u8bc4\u52064.24/5", "conclusion": "NBTest\u80fd\u6709\u6548\u63d0\u9ad8ML\u7b14\u8bb0\u672c\u7684\u53ef\u9760\u6027\u548c\u53ef\u7ef4\u62a4\u6027\uff0c\u5df2\u88ab\u4e3b\u6d41ML\u5e93\u7684CI\u91c7\u7528\uff0c\u89e3\u51b3\u4e86\u7b14\u8bb0\u672c\u6d4b\u8bd5\u652f\u6301\u4e0d\u8db3\u7684\u95ee\u9898"}}
{"id": "2509.13740", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13740", "abs": "https://arxiv.org/abs/2509.13740", "authors": ["Moritz Bley", "Tobias Scharnowski", "Simon W\u00f6rner", "Moritz Schloegel", "Thorsten Holz"], "title": "Protocol-Aware Firmware Rehosting for Effective Fuzzing of Embedded Network Stacks", "comment": "Extended version of our paper \"Protocol-Aware Fimrware Rehosting for\n  Effective Fuzzing of Embedded Network Stacks\" published at ACM CCS 2025", "summary": "One of the biggest attack surfaces of embedded systems is their network\ninterfaces, which enable communication with other devices. Unlike their\ngeneral-purpose counterparts, embedded systems are designed for specialized use\ncases, resulting in unique and diverse communication stacks. Unfortunately,\ncurrent approaches for evaluating the security of these embedded network stacks\nrequire manual effort or access to hardware, and they generally focus only on\nsmall parts of the embedded system. A promising alternative is firmware\nrehosting, which enables fuzz testing of the entire firmware by generically\nemulating the physical hardware. However, existing rehosting methods often\nstruggle to meaningfully explore network stacks due to their complex,\nmulti-layered input formats. This limits their ability to uncover deeply nested\nsoftware faults.\n  To address this problem, we introduce a novel method to automatically detect\nand handle the use of network protocols in firmware called Pemu. By\nautomatically deducing the available network protocols, Pemu can transparently\ngenerate valid network packets that encapsulate fuzzing data, allowing the\nfuzzing input to flow directly into deeper layers of the firmware logic. Our\napproach thus enables a deeper, more targeted, and layer-by-layer analysis of\nfirmware components that were previously difficult or impossible to test. Our\nevaluation demonstrates that Pemu consistently improves the code coverage of\nthree existing rehosting tools for embedded network stacks. Furthermore, our\nfuzzer rediscovered several known vulnerabilities and identified five\npreviously unknown software faults, highlighting its effectiveness in\nuncovering deeply nested bugs in network-exposed code.", "AI": {"tldr": "Pemu\u662f\u4e00\u4e2a\u81ea\u52a8\u68c0\u6d4b\u548c\u5904\u7406\u56fa\u4ef6\u4e2d\u7f51\u7edc\u534f\u8bae\u4f7f\u7528\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u63a8\u65ad\u53ef\u7528\u7f51\u7edc\u534f\u8bae\u5e76\u900f\u660e\u751f\u6210\u6709\u6548\u7f51\u7edc\u6570\u636e\u5305\uff0c\u4f7f\u6a21\u7cca\u6d4b\u8bd5\u8f93\u5165\u80fd\u591f\u76f4\u63a5\u6d41\u5165\u56fa\u4ef6\u903b\u8f91\u7684\u66f4\u6df1\u5c42\u3002", "motivation": "\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u7f51\u7edc\u63a5\u53e3\u662f\u6700\u5927\u7684\u653b\u51fb\u9762\u4e4b\u4e00\uff0c\u4f46\u73b0\u6709\u91cd\u6258\u7ba1\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u63a2\u7d22\u590d\u6742\u7684\u591a\u5c42\u7f51\u7edc\u534f\u8bae\u6808\uff0c\u9650\u5236\u4e86\u53d1\u73b0\u6df1\u5c42\u8f6f\u4ef6\u6545\u969c\u7684\u80fd\u529b\u3002", "method": "Pemu\u81ea\u52a8\u63a8\u65ad\u56fa\u4ef6\u4e2d\u53ef\u7528\u7684\u7f51\u7edc\u534f\u8bae\uff0c\u900f\u660e\u751f\u6210\u5c01\u88c5\u6a21\u7cca\u6d4b\u8bd5\u6570\u636e\u7684\u6709\u6548\u7f51\u7edc\u6570\u636e\u5305\uff0c\u5b9e\u73b0\u9010\u5c42\u6df1\u5165\u7684\u56fa\u4ef6\u7ec4\u4ef6\u5206\u6790\u3002", "result": "Pemu\u6301\u7eed\u63d0\u9ad8\u4e86\u4e09\u79cd\u73b0\u6709\u5d4c\u5165\u5f0f\u7f51\u7edc\u6808\u91cd\u6258\u7ba1\u5de5\u5177\u7684\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u91cd\u65b0\u53d1\u73b0\u4e86\u591a\u4e2a\u5df2\u77e5\u6f0f\u6d1e\u5e76\u8bc6\u522b\u4e86\u4e94\u4e2a\u5148\u524d\u672a\u77e5\u7684\u8f6f\u4ef6\u6545\u969c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u53d1\u73b0\u7f51\u7edc\u66b4\u9732\u4ee3\u7801\u4e2d\u7684\u6df1\u5c42\u5d4c\u5957\u9519\u8bef\uff0c\u4e3a\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7f51\u7edc\u6808\u5b89\u5168\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u3001\u66f4\u6709\u9488\u5bf9\u6027\u7684\u5206\u6790\u80fd\u529b\u3002"}}
{"id": "2509.13351", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13351", "abs": "https://arxiv.org/abs/2509.13351", "authors": ["Pulkit Verma", "Ngoc La", "Anthony Favier", "Swaroop Mishra", "Julie A. Shah"], "title": "Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning", "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities across\ndiverse tasks, yet their ability to perform structured symbolic planning\nremains limited, particularly in domains requiring formal representations like\nthe Planning Domain Definition Language (PDDL). In this paper, we present a\nnovel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'\nsymbolic planning capabilities through logical chain-of-thought reasoning. Our\napproach focuses on teaching models to rigorously reason about action\napplicability, state transitions, and plan validity using explicit logical\ninference steps. By developing instruction prompts that guide models through\nthe precise logical reasoning required to determine when actions can be applied\nin a given state, we enable LLMs to self-correct their planning processes\nthrough structured reflection. The framework systematically builds verification\nskills by decomposing the planning process into explicit reasoning chains about\nprecondition satisfaction, effect application, and invariant preservation.\nExperimental results on multiple planning domains show that our\nchain-of-thought reasoning based instruction-tuned models are significantly\nbetter at planning, achieving planning accuracy of up to 94% on standard\nbenchmarks, representing a 66% absolute improvement over baseline models. This\nwork bridges the gap between the general reasoning capabilities of LLMs and the\nlogical precision required for automated planning, offering a promising\ndirection for developing better AI planning systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86PDDL-Instruct\u6307\u4ee4\u8c03\u4f18\u6846\u67b6\uff0c\u901a\u8fc7\u903b\u8f91\u601d\u7ef4\u94fe\u63a8\u7406\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7b26\u53f7\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523094%\u7684\u89c4\u5212\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u63d0\u534766%", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u5f62\u5f0f\u5316\u8868\u793a\uff08\u5982PDDL\uff09\u7684\u7ed3\u6784\u5316\u7b26\u53f7\u89c4\u5212\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u5f25\u5408\u901a\u7528\u63a8\u7406\u80fd\u529b\u4e0e\u81ea\u52a8\u89c4\u5212\u6240\u9700\u903b\u8f91\u7cbe\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd", "method": "\u5f00\u53d1\u6307\u4ee4\u63d0\u793a\u5f15\u5bfc\u6a21\u578b\u8fdb\u884c\u7cbe\u786e\u7684\u903b\u8f91\u63a8\u7406\uff0c\u786e\u5b9a\u52a8\u4f5c\u5728\u7ed9\u5b9a\u72b6\u6001\u4e0b\u7684\u9002\u7528\u6027\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u53cd\u601d\u5b9e\u73b0\u81ea\u6211\u4fee\u6b63\u3002\u5c06\u89c4\u5212\u8fc7\u7a0b\u5206\u89e3\u4e3a\u5173\u4e8e\u524d\u63d0\u6761\u4ef6\u6ee1\u8db3\u3001\u6548\u679c\u5e94\u7528\u548c\u4e0d\u53d8\u6027\u4fdd\u6301\u7684\u663e\u5f0f\u63a8\u7406\u94fe", "result": "\u5728\u591a\u4e2a\u89c4\u5212\u9886\u57df\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8e\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u89c4\u5212\u51c6\u786e\u7387\u6700\u9ad8\u8fbe\u523094%\uff0c\u7edd\u5bf9\u63d0\u534766%", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5f00\u53d1\u66f4\u597d\u7684AI\u89c4\u5212\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u6210\u529f\u5f25\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u901a\u7528\u63a8\u7406\u80fd\u529b\u4e0e\u81ea\u52a8\u89c4\u5212\u6240\u9700\u903b\u8f91\u7cbe\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd"}}
{"id": "2509.13680", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13680", "abs": "https://arxiv.org/abs/2509.13680", "authors": ["Wei Ma", "Yixiao Yang", "Jingquan Ge", "Xiaofei Xie", "Lingxiao Jiang"], "title": "Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations", "comment": null, "summary": "Code generation models are widely used in software development, yet their\nsensitivity to prompt phrasing remains under-examined. Identical requirements\nexpressed with different emotions or communication styles can yield divergent\noutputs, while most benchmarks emphasize only peak performance. We present\nPromptSE (Prompt Sensitivity Evaluation), a framework that creates semantically\nequivalent prompt variants with emotion and personality templates, and that\nevaluates stability using probability aware continuous scoring or using binary\npass rates when logits are unavailable. The results are aggregated into a\nproposed area under curve metric (AUC-E) for cross model comparison. Across 14\nmodels from three families (Llama, Qwen, and DeepSeek), our study shows that\nperformance and stability behave as largely decoupled optimization objectives,\nand it reveals architectural and scale related patterns that challenge common\nassumptions about model robustness. The framework supports rapid screening for\nclosed-source models as well as detailed stability analysis in research\nsettings. PromptSE enables practitioners to quantify performance stability\ntrade offs for deployment and model selection, positioning prompt stability as\na complementary evaluation dimension alongside performance and fairness, and\ncontributing to more trustworthy AI-assisted software development tools.", "AI": {"tldr": "PromptSE\u6846\u67b6\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7801\u751f\u6210\u6a21\u578b\u5bf9\u63d0\u793a\u8bcd\u8868\u8fbe\u7684\u654f\u611f\u6027\uff0c\u901a\u8fc7\u521b\u5efa\u8bed\u4e49\u76f8\u540c\u4f46\u60c5\u611f\u548c\u98ce\u683c\u4e0d\u540c\u7684\u63d0\u793a\u53d8\u4f53\uff0c\u53d1\u73b0\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u662f\u89e3\u8026\u7684\u4f18\u5316\u76ee\u6807", "motivation": "\u4ee3\u7801\u751f\u6210\u6a21\u578b\u5bf9\u63d0\u793a\u8bcd\u8868\u8fbe\u7684\u654f\u611f\u6027\u672a\u88ab\u5145\u5206\u7814\u7a76\uff0c\u76f8\u540c\u9700\u6c42\u7528\u4e0d\u540c\u60c5\u611f\u6216\u6c9f\u901a\u98ce\u683c\u8868\u8fbe\u4f1a\u4ea7\u751f\u4e0d\u540c\u8f93\u51fa\uff0c\u800c\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5cf0\u503c\u6027\u80fd", "method": "\u521b\u5efa\u8bed\u4e49\u7b49\u6548\u7684\u63d0\u793a\u53d8\u4f53\uff08\u542b\u60c5\u611f\u548c\u4e2a\u6027\u6a21\u677f\uff09\uff0c\u4f7f\u7528\u6982\u7387\u611f\u77e5\u8fde\u7eed\u8bc4\u5206\u6216\u4e8c\u8fdb\u5236\u901a\u8fc7\u7387\u8bc4\u4f30\u7a33\u5b9a\u6027\uff0c\u63d0\u51faAUC-E\u6307\u6807\u8fdb\u884c\u8de8\u6a21\u578b\u6bd4\u8f83", "result": "\u572814\u4e2a\u6a21\u578b\uff08Llama\u3001Qwen\u3001DeepSeek\uff09\u4e0a\u7684\u7814\u7a76\u8868\u660e\uff0c\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u662f\u89e3\u8026\u7684\u4f18\u5316\u76ee\u6807\uff0c\u63ed\u793a\u4e86\u6311\u6218\u6a21\u578b\u9c81\u68d2\u6027\u5e38\u89c1\u5047\u8bbe\u7684\u67b6\u6784\u548c\u89c4\u6a21\u76f8\u5173\u6a21\u5f0f", "conclusion": "PromptSE\u80fd\u591f\u91cf\u5316\u6027\u80fd\u7a33\u5b9a\u6027\u6743\u8861\uff0c\u652f\u6301\u95ed\u6e90\u6a21\u578b\u5feb\u901f\u7b5b\u9009\u548c\u8be6\u7ec6\u7a33\u5b9a\u6027\u5206\u6790\uff0c\u5c06\u63d0\u793a\u7a33\u5b9a\u6027\u5b9a\u4f4d\u4e3a\u4e0e\u6027\u80fd\u548c\u516c\u5e73\u6027\u4e92\u8865\u7684\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u53ef\u4fe1\u7684AI\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177"}}
{"id": "2509.13772", "categories": ["cs.CR", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13772", "abs": "https://arxiv.org/abs/2509.13772", "authors": ["Baolei Zhang", "Haoran Xin", "Yuxi Chen", "Zhuqing Liu", "Biao Yi", "Tong Li", "Lihai Nie", "Zheli Liu", "Minghong Fang"], "title": "Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation", "comment": "To appear in the IEEE Symposium on Security and Privacy, 2026", "summary": "Retrieval-Augmented Generation (RAG) integrates external knowledge into large\nlanguage models to improve response quality. However, recent work has shown\nthat RAG systems are highly vulnerable to poisoning attacks, where malicious\ntexts are inserted into the knowledge database to influence model outputs.\nWhile several defenses have been proposed, they are often circumvented by more\nadaptive or sophisticated attacks.\n  This paper presents RAGOrigin, a black-box responsibility attribution\nframework designed to identify which texts in the knowledge database are\nresponsible for misleading or incorrect generations. Our method constructs a\nfocused attribution scope tailored to each misgeneration event and assigns a\nresponsibility score to each candidate text by evaluating its retrieval\nranking, semantic relevance, and influence on the generated response. The\nsystem then isolates poisoned texts using an unsupervised clustering method. We\nevaluate RAGOrigin across seven datasets and fifteen poisoning attacks,\nincluding newly developed adaptive poisoning strategies and multi-attacker\nscenarios. Our approach outperforms existing baselines in identifying poisoned\ncontent and remains robust under dynamic and noisy conditions. These results\nsuggest that RAGOrigin provides a practical and effective solution for tracing\nthe origins of corrupted knowledge in RAG systems.", "AI": {"tldr": "RAGOrigin\u662f\u4e00\u4e2a\u9ed1\u76d2\u8d23\u4efb\u6eaf\u6e90\u6846\u67b6\uff0c\u7528\u4e8e\u8bc6\u522bRAG\u7cfb\u7edf\u4e2d\u5bfc\u81f4\u9519\u8bef\u751f\u6210\u7684\u6c61\u67d3\u6587\u672c\uff0c\u901a\u8fc7\u68c0\u7d22\u6392\u540d\u3001\u8bed\u4e49\u76f8\u5173\u6027\u548c\u751f\u6210\u5f71\u54cd\u8bc4\u4f30\u6765\u5b9a\u4f4d\u6c61\u67d3\u5185\u5bb9\u3002", "motivation": "RAG\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u6c61\u67d3\u653b\u51fb\uff0c\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u5f80\u5f80\u88ab\u66f4\u590d\u6742\u7684\u653b\u51fb\u7ed5\u8fc7\uff0c\u9700\u8981\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6eaf\u6e90\u6c61\u67d3\u77e5\u8bc6\u7684\u6765\u6e90\u3002", "method": "\u6784\u5efa\u9488\u5bf9\u6bcf\u4e2a\u9519\u8bef\u751f\u6210\u4e8b\u4ef6\u7684\u4e13\u6ce8\u6eaf\u6e90\u8303\u56f4\uff0c\u8bc4\u4f30\u5019\u9009\u6587\u672c\u7684\u68c0\u7d22\u6392\u540d\u3001\u8bed\u4e49\u76f8\u5173\u6027\u548c\u5bf9\u751f\u6210\u54cd\u5e94\u7684\u5f71\u54cd\uff0c\u4f7f\u7528\u65e0\u76d1\u7763\u805a\u7c7b\u65b9\u6cd5\u9694\u79bb\u6c61\u67d3\u6587\u672c\u3002", "result": "\u57287\u4e2a\u6570\u636e\u96c6\u548c15\u79cd\u6c61\u67d3\u653b\u51fb\uff08\u5305\u62ec\u65b0\u5f00\u53d1\u7684\u81ea\u9002\u5e94\u653b\u51fb\u548c\u591a\u653b\u51fb\u8005\u573a\u666f\uff09\u4e0a\u8bc4\u4f30\uff0cRAGOrigin\u5728\u8bc6\u522b\u6c61\u67d3\u5185\u5bb9\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u52a8\u6001\u548c\u566a\u58f0\u6761\u4ef6\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "RAGOrigin\u4e3aRAG\u7cfb\u7edf\u4e2d\u6c61\u67d3\u77e5\u8bc6\u7684\u6eaf\u6e90\u63d0\u4f9b\u4e86\u5b9e\u7528\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13352", "categories": ["cs.AI", "cs.RO", "68T07, 68T40, 68T42", "I.2.9; I.2.11; I.2.8; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.13352", "abs": "https://arxiv.org/abs/2509.13352", "authors": ["Anis Koubaa", "Khaled Gabr"], "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "comment": "14 pages, 1 figure", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,\nsurveillance, and disaster response, yet most systems remain confined to SAE\nLevel 2--3 autonomy. Their reliance on rule-based control and narrow AI\nrestricts adaptability in dynamic, uncertain missions. Existing UAV frameworks\nlack context-aware reasoning, autonomous decision-making, and ecosystem-level\nintegration; critically, none leverage Large Language Model (LLM) agents with\ntool-calling for real-time knowledge access. This paper introduces the Agentic\nUAVs framework, a five-layer architecture (Perception, Reasoning, Action,\nIntegration, Learning) that augments UAVs with LLM-driven reasoning, database\nquerying, and third-party system interaction. A ROS2 and Gazebo-based prototype\nintegrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3\ndeployment. In simulated search-and-rescue scenarios, agentic UAVs achieved\nhigher detection confidence (0.79 vs. 0.72), improved person detection rates\n(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).\nThese results confirm that modest computational overhead enables qualitatively\nnew levels of autonomy and ecosystem integration.", "AI": {"tldr": "\u63d0\u51fa\u4e86Agentic UAVs\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u5c42\u67b6\u6784\u5c06LLM\u9a71\u52a8\u7684\u63a8\u7406\u80fd\u529b\u96c6\u6210\u5230\u65e0\u4eba\u673a\u4e2d\uff0c\u5728\u641c\u6551\u6a21\u62df\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u548c\u81ea\u4e3b\u51b3\u7b56\u80fd\u529b", "motivation": "\u73b0\u6709\u65e0\u4eba\u673a\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u57fa\u4e8e\u89c4\u5219\u7684\u63a7\u5236\u548c\u7a84AI\uff0c\u7f3a\u4e4f\u60c5\u5883\u611f\u77e5\u63a8\u7406\u3001\u81ea\u4e3b\u51b3\u7b56\u548c\u751f\u6001\u7cfb\u7edf\u96c6\u6210\u80fd\u529b\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528LLM\u7684\u5b9e\u65f6\u77e5\u8bc6\u8bbf\u95ee\u80fd\u529b", "method": "\u8bbe\u8ba1\u4e94\u5c42\u67b6\u6784\uff08\u611f\u77e5\u3001\u63a8\u7406\u3001\u884c\u52a8\u3001\u96c6\u6210\u3001\u5b66\u4e60\uff09\uff0c\u96c6\u6210ROS2\u548cGazebo\u539f\u578b\uff0c\u7ed3\u5408YOLOv11\u76ee\u6807\u68c0\u6d4b\u4e0eGPT-4\u63a8\u7406\uff0c\u90e8\u7f72\u672c\u5730Gemma-3\u6a21\u578b", "result": "\u5728\u6a21\u62df\u641c\u6551\u573a\u666f\u4e2d\uff0c\u68c0\u6d4b\u7f6e\u4fe1\u5ea6\u4ece0.72\u63d0\u5347\u81f30.79\uff0c\u4eba\u5458\u68c0\u6d4b\u7387\u4ece75%\u63d0\u5347\u81f391%\uff0c\u884c\u52a8\u63a8\u8350\u7387\u4ece4.5%\u5927\u5e45\u63d0\u5347\u81f392%", "conclusion": "\u9002\u5ea6\u7684\u8ba1\u7b97\u5f00\u9500\u5373\u53ef\u5b9e\u73b0\u8d28\u7684\u81ea\u4e3b\u6027\u63d0\u5347\u548c\u751f\u6001\u7cfb\u7edf\u96c6\u6210\uff0c\u8bc1\u660e\u4e86LLM\u9a71\u52a8\u7684\u65e0\u4eba\u673a\u6846\u67b6\u7684\u6709\u6548\u6027"}}
{"id": "2509.13755", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13755", "abs": "https://arxiv.org/abs/2509.13755", "authors": ["Zhaoyang Chu", "Yao Wan", "Zhikun Zhang", "Di Wang", "Zhou Yang", "Hongyu Zhang", "Pan Zhou", "Xuanhua Shi", "Hai Jin", "David Lo"], "title": "Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning", "comment": "Accepted at the 48th IEEE/ACM International Conference on Software\n  Engineering (ICSE 2026)", "summary": "While Code Language Models (CLMs) have demonstrated superior performance in\nsoftware engineering tasks such as code generation and summarization, recent\nempirical studies reveal a critical privacy vulnerability: these models exhibit\nunintended memorization of sensitive training data, enabling verbatim\nreproduction of confidential information when specifically prompted. To address\nthis issue, several approaches, including training data de-duplication and\ndifferential privacy augmentation, have been proposed. However, these methods\nrequire full-model retraining for deployed CLMs, which incurs substantial\ncomputational costs. In this paper, we aim to answer the following research\nquestion: Can sensitive information memorized by CLMs be erased effectively and\nefficiently?\n  We conduct a pioneering investigation into erasing sensitive memorization in\nCLMs through machine unlearning - a post-hoc modification method that removes\nspecific information from trained models without requiring full retraining.\nSpecifically, we first quantify the memorization risks of sensitive data within\nCLM training datasets and curate a high-risk dataset of 50,000 sensitive\nmemorized samples as unlearning targets. We study two widely used gradient\nascent-based unlearning approaches: the vanilla and constraint-based methods,\nand introduce CodeEraser, an advanced variant that selectively unlearns\nsensitive memorized segments in code while preserving the structural integrity\nand functional correctness of the surrounding code. Extensive experiments on\nthree families of CLMs, i.e., CodeParrot, CodeGen-Mono, and Qwen2.5-Coder,\nvalidate the effectiveness and efficiency of CodeEraser in erasing targeted\nsensitive memorization while maintaining model utility.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4ee3\u7801\u8bed\u8a00\u6a21\u578b(CLM)\u4e2d\u654f\u611f\u4fe1\u606f\u8bb0\u5fc6\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86CodeEraser\u65b9\u6cd5\u901a\u8fc7\u673a\u5668\u9057\u5fd8\u6280\u672f\u6709\u6548\u64e6\u9664\u654f\u611f\u8bb0\u5fc6\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u610f\u5916\u8bb0\u5fc6\u654f\u611f\u8bad\u7ec3\u6570\u636e\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u9700\u8981\u5168\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u7814\u7a76\u76ee\u6807\u662f\u627e\u5230\u9ad8\u6548\u64e6\u9664CLM\u4e2d\u654f\u611f\u8bb0\u5fc6\u7684\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u91cf\u5316CLM\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u8bb0\u5fc6\u98ce\u9669\uff0c\u6784\u5efa5\u4e07\u4e2a\u9ad8\u98ce\u9669\u654f\u611f\u8bb0\u5fc6\u6837\u672c\u4f5c\u4e3a\u9057\u5fd8\u76ee\u6807\u3002\u7814\u7a76\u57fa\u4e8e\u68af\u5ea6\u4e0a\u5347\u7684\u9057\u5fd8\u65b9\u6cd5\uff0c\u63d0\u51faCodeEraser\u53d8\u4f53\uff0c\u9009\u62e9\u6027\u5730\u9057\u5fd8\u4ee3\u7801\u4e2d\u7684\u654f\u611f\u8bb0\u5fc6\u7247\u6bb5\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u7ed3\u6784\u5b8c\u6574\u6027\u548c\u529f\u80fd\u6b63\u786e\u6027\u3002", "result": "\u5728CodeParrot\u3001CodeGen-Mono\u548cQwen2.5-Coder\u4e09\u4e2aCLM\u5bb6\u65cf\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86CodeEraser\u5728\u64e6\u9664\u76ee\u6807\u654f\u611f\u8bb0\u5fc6\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6548\u7528\u3002", "conclusion": "CodeEraser\u901a\u8fc7\u673a\u5668\u9057\u5fd8\u6280\u672f\u80fd\u591f\u6709\u6548\u4e14\u9ad8\u6548\u5730\u64e6\u9664\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u654f\u611f\u8bb0\u5fc6\uff0c\u4e3a\u89e3\u51b3CLM\u9690\u79c1\u6f0f\u6d1e\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u540e\u5904\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u907f\u514d\u4e86\u5168\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\u7684\u9ad8\u6210\u672c\u3002"}}
{"id": "2509.13788", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13788", "abs": "https://arxiv.org/abs/2509.13788", "authors": ["Giovanni Giuseppe Grimaldi"], "title": "Homomorphic encryption schemes based on coding theory and polynomials", "comment": null, "summary": "Homomorphic encryption is a powerful cryptographic tool that enables secure\ncomputations on the private data. It evaluates any function for any operation\nsecurely on the encrypted data without knowing its corresponding plaintext. For\noriginal data $p$, $c$ denotes the ciphertext of the original plaintext $p$,\ni.e. $c = Encrypt_k(p)$. This is crucial for any sensitive application running\nin the Cloud, because we must protect data privacy even in the case when the\nserver has falled victim to a cyber attack. The encryption scheme $Encrypt_k$\nis said to be homomorphic with respect to some set of operations $\\mathcal{O}$,\nif for any operation $\\circ \\in \\mathcal{O}$ one can compute $Encrypt_k(p_1\n\\circ p_2)$ from $Encrypt_k(p_1) \\circ Encrypt_k(p_2)$. Those schemes come in\nthree forms: somewhat, partially and fully homomorphic. In this survey, we\npresent the state of art of the known homomorphic encryption schemes based on\ncoding theory and polynomials.", "AI": {"tldr": "\u540c\u6001\u52a0\u5bc6\u6280\u672f\u7efc\u8ff0\uff1a\u57fa\u4e8e\u7f16\u7801\u7406\u8bba\u548c\u591a\u9879\u5f0f\u7684\u52a0\u5bc6\u65b9\u6848\u73b0\u72b6\u5206\u6790", "motivation": "\u540c\u6001\u52a0\u5bc6\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u5bc6\u7801\u5b66\u5de5\u5177\uff0c\u80fd\u591f\u5728\u4e0d\u77e5\u9053\u660e\u6587\u7684\u60c5\u51b5\u4e0b\u5bf9\u52a0\u5bc6\u6570\u636e\u8fdb\u884c\u5b89\u5168\u8ba1\u7b97\uff0c\u8fd9\u5bf9\u4e8e\u4e91\u73af\u5883\u4e2d\u654f\u611f\u5e94\u7528\u7684\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u670d\u52a1\u5668\u906d\u53d7\u7f51\u7edc\u653b\u51fb\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u672c\u6587\u5bf9\u57fa\u4e8e\u7f16\u7801\u7406\u8bba\u548c\u591a\u9879\u5f0f\u7684\u540c\u6001\u52a0\u5bc6\u65b9\u6848\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u5206\u6790\u4e86\u8fd9\u4e9b\u65b9\u6848\u5728\u7279\u5b9a\u64cd\u4f5c\u96c6\u4e0a\u7684\u540c\u6001\u7279\u6027\uff0c\u5305\u62ec\u90e8\u5206\u540c\u6001\u3001\u6709\u9650\u540c\u6001\u548c\u5b8c\u5168\u540c\u6001\u4e09\u79cd\u5f62\u5f0f\u3002", "result": "\u7efc\u8ff0\u4e86\u5f53\u524d\u5df2\u77e5\u7684\u57fa\u4e8e\u7f16\u7801\u7406\u8bba\u548c\u591a\u9879\u5f0f\u7684\u540c\u6001\u52a0\u5bc6\u65b9\u6848\u7684\u6280\u672f\u73b0\u72b6\uff0c\u603b\u7ed3\u4e86\u5404\u79cd\u65b9\u6848\u5728\u540c\u6001\u64cd\u4f5c\u652f\u6301\u65b9\u9762\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u57fa\u4e8e\u7f16\u7801\u7406\u8bba\u548c\u591a\u9879\u5f0f\u7684\u540c\u6001\u52a0\u5bc6\u65b9\u6848\u4e3a\u4e91\u73af\u5883\u4e2d\u7684\u5b89\u5168\u8ba1\u7b97\u63d0\u4f9b\u4e86\u91cd\u8981\u6280\u672f\u652f\u6491\uff0c\u4f46\u4e0d\u540c\u65b9\u6848\u5728\u529f\u80fd\u6027\u548c\u6027\u80fd\u65b9\u9762\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u5e94\u7528\u573a\u666f\u9009\u62e9\u5408\u9002\u65b9\u6848\u3002"}}
{"id": "2509.13357", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13357", "abs": "https://arxiv.org/abs/2509.13357", "authors": ["Yongchao Huang", "Hassan Raza"], "title": "Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling", "comment": "16 pages", "summary": "We propose semantic fusion, a lightweight scheme that augments a Transformer\nlanguage model (LM) with a parallel, fuzzy-membership feature channel that\nencodes token-level semantics. Each token is represented by a vector of\ninterpretable features (e.g. part-of-speech cues, shallow roles, boundary\nflags, sentiment polarity and strength) whose values are graded degrees from\ndifferentiable membership functions (e.g. power kernels). These per-token\nvectors form a sentence-level semantic matrix fused via a gated adapter into\nthe LM. Training uses standard next-token prediction, an auxiliary loss that\nreconstructs the semantic features from hidden states, and a lightweight\nuniformizer that regularizes adjective-class distributions. On a synthetic\ntwo-clause corpus with held-out adjectives for out-of-distribution (OOD)\ncontrol, semantic fusion improves perplexity and enables precise,\nuser-controllable generation of polarity and punctuation while maintaining\nmodel simplicity. This approach adds only small overhead, remains fully\ncompatible with tied input-output embeddings, and provides an interpretable\npathway for conditioned natural language generation.", "AI": {"tldr": "\u8bed\u4e49\u878d\u5408\uff1a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6848\uff0c\u901a\u8fc7\u5e76\u884c\u6a21\u7cca\u6210\u5458\u7279\u5f81\u901a\u9053\u589e\u5f3aTransformer\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u8bed\u4e49\u7279\u5f81\u878d\u5408\u548c\u53ef\u63a7\u751f\u6210", "motivation": "\u4e3a\u4e86\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7279\u5f81\u8868\u793a\u548c\u7528\u6237\u53ef\u63a7\u7684\u751f\u6210\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u8f7b\u91cf\u5316\u548c\u517c\u5bb9\u6027", "method": "\u5728Transformer LM\u57fa\u7840\u4e0a\u6dfb\u52a0\u5e76\u884c\u8bed\u4e49\u7279\u5f81\u901a\u9053\uff0c\u4f7f\u7528\u53ef\u5fae\u5206\u6210\u5458\u51fd\u6570\u7f16\u7801\u8bcd\u7ea7\u8bed\u4e49\u7279\u5f81\uff08\u8bcd\u6027\u3001\u6d45\u5c42\u89d2\u8272\u3001\u8fb9\u754c\u6807\u5fd7\u3001\u60c5\u611f\u6781\u6027\u7b49\uff09\uff0c\u901a\u8fc7\u95e8\u63a7\u9002\u914d\u5668\u878d\u5408\u5230\u6a21\u578b\u4e2d\uff0c\u91c7\u7528\u6807\u51c6\u4e0b\u4e00\u8bcd\u9884\u6d4b\u3001\u8bed\u4e49\u7279\u5f81\u91cd\u6784\u8f85\u52a9\u635f\u5931\u548c\u5f62\u5bb9\u8bcd\u5206\u5e03\u6b63\u5219\u5316\u8fdb\u884c\u8bad\u7ec3", "result": "\u5728\u5408\u6210\u53cc\u5b50\u53e5\u8bed\u6599\u5e93\u4e0a\uff0c\u8bed\u4e49\u878d\u5408\u63d0\u9ad8\u4e86\u56f0\u60d1\u5ea6\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u7528\u6237\u53ef\u63a7\u6781\u6027\u548c\u6807\u70b9\u751f\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7b80\u6d01\u6027\uff0c\u4ec5\u589e\u52a0\u5c11\u91cf\u5f00\u9500", "conclusion": "\u8bed\u4e49\u878d\u5408\u4e3a\u6761\u4ef6\u81ea\u7136\u8bed\u8a00\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u9014\u5f84\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u517c\u5bb9\u6027\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u8bed\u4e49\u63a7\u5236\u80fd\u529b"}}
{"id": "2509.13758", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13758", "abs": "https://arxiv.org/abs/2509.13758", "authors": ["Kevin Halim", "Sin G. Teo", "Ruitao Feng", "Zhenpeng Chen", "Yang Gu", "Chong Wang", "Yang Liu"], "title": "A Study on Thinking Patterns of Large Reasoning Models in Code Generation", "comment": null, "summary": "Currently, many large language models (LLMs) are utilized for software\nengineering tasks such as code generation. The emergence of more advanced\nmodels known as large reasoning models (LRMs), such as OpenAI's o3, DeepSeek\nR1, and Qwen3. They have demonstrated the capability of performing multi-step\nreasoning. Despite the advancement in LRMs, little attention has been paid to\nsystematically analyzing the reasoning patterns these models exhibit and how\nsuch patterns influence the generated code. This paper presents a comprehensive\nstudy aimed at investigating and uncovering the reasoning behavior of LRMs\nduring code generation. We prompted several state-of-the-art LRMs of varying\nsizes with code generation tasks and applied open coding to manually annotate\nthe reasoning traces. From this analysis, we derive a taxonomy of LRM reasoning\nbehaviors, encompassing 15 reasoning actions across four phases.\n  Our empirical study based on the taxonomy reveals a series of findings.\nFirst, we identify common reasoning patterns, showing that LRMs generally\nfollow a human-like coding workflow, with more complex tasks eliciting\nadditional actions such as scaffolding, flaw detection, and style checks.\nSecond, we compare reasoning across models, finding that Qwen3 exhibits\niterative reasoning while DeepSeek-R1-7B follows a more linear, waterfall-like\napproach. Third, we analyze the relationship between reasoning and code\ncorrectness, showing that actions such as unit test creation and scaffold\ngeneration strongly support functional outcomes, with LRMs adapting strategies\nbased on task context. Finally, we evaluate lightweight prompting strategies\ninformed by these findings, demonstrating the potential of context- and\nreasoning-oriented prompts to improve LRM-generated code. Our results offer\ninsights and practical implications for advancing automatic code generation.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u63a8\u7406\u884c\u4e3a\u6a21\u5f0f\uff0c\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u6784\u5efa\u4e86\u5305\u542b15\u79cd\u63a8\u7406\u884c\u4e3a\u7684\u5206\u7c7b\u6cd5\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u7684\u63a8\u7406\u7279\u70b9\u53ca\u5176\u4e0e\u4ee3\u7801\u6b63\u786e\u6027\u7684\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u63a8\u7406\u7684\u63d0\u793a\u7b56\u7565\u6539\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u63a8\u7406\u884c\u4e3a\u6a21\u5f0f\u7684\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u6a21\u5f0f\u5982\u4f55\u5f71\u54cd\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u7684\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u63d0\u793a\u591a\u4e2a\u5148\u8fdbLRMs\uff0c\u901a\u8fc7\u5f00\u653e\u5f0f\u7f16\u7801\u624b\u52a8\u6807\u6ce8\u63a8\u7406\u8f68\u8ff9\uff0c\u6784\u5efa\u5305\u542b15\u79cd\u63a8\u7406\u884c\u4e3a\u7684\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d6\u56db\u4e2a\u9636\u6bb5\uff0c\u5e76\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u5206\u6790\u63a8\u7406\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0LRMs\u9075\u5faa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u7f16\u7801\u5de5\u4f5c\u6d41\uff0c\u590d\u6742\u4efb\u52a1\u5f15\u53d1\u989d\u5916\u63a8\u7406\u884c\u4e3a\uff1b\u4e0d\u540c\u6a21\u578b\u63a8\u7406\u98ce\u683c\u5dee\u5f02\u660e\u663e(Qwen3\u8fed\u4ee3\u5f0f\uff0cDeepSeek-R1-7B\u7ebf\u6027\u5f0f)\uff1b\u5355\u5143\u6d4b\u8bd5\u548c\u811a\u624b\u67b6\u751f\u6210\u7b49\u884c\u4e3a\u4e0e\u4ee3\u7801\u6b63\u786e\u6027\u5f3a\u76f8\u5173\uff1b\u57fa\u4e8e\u63a8\u7406\u7684\u63d0\u793a\u7b56\u7565\u80fd\u6709\u6548\u6539\u8fdb\u4ee3\u7801\u8d28\u91cf\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LRMs\u7684\u63a8\u7406\u884c\u4e3a\u6a21\u5f0f\u53ca\u5176\u5bf9\u4ee3\u7801\u751f\u6210\u7684\u5f71\u54cd\uff0c\u4e3a\u6539\u8fdb\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\uff0c\u5c55\u793a\u4e86\u4e0a\u4e0b\u6587\u548c\u63a8\u7406\u5bfc\u5411\u63d0\u793a\u7b56\u7565\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.13797", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.13797", "abs": "https://arxiv.org/abs/2509.13797", "authors": ["Ali Sadeghi Jahromi", "AbdelRahman Abdou", "Paul C. van Oorschot"], "title": "A Survey and Evaluation Framework for Secure DNS Resolution", "comment": null, "summary": "Since security was not among the original design goals of the Domain Name\nSystem (herein called Vanilla DNS), many secure DNS schemes have been proposed\nto enhance the security and privacy of the DNS resolution process. Some\nproposed schemes aim to replace the existing DNS infrastructure entirely, but\nnone have succeeded in doing so. In parallel, numerous schemes focus on\nimproving DNS security without modifying its fundamental two-stage structure.\nThese efforts highlight the feasibility of addressing DNS security as two\ndistinct but compatible stages. We survey DNS resolution process attacks and\nthreats and develop a comprehensive threat model and attack taxonomy for their\nsystematic categorization. This analysis results in the formulation of 14\ndesirable security, privacy, and availability properties to mitigate the\nidentified threats. Using these properties, we develop an objective evaluation\nframework and apply it to comparatively analyze 12 secure DNS schemes surveyed\nin this work that aim to augment the properties of the DNS resolution process.\nOur evaluation reveals that no single scheme provides ideal protection across\nthe entire resolution path. Instead, the schemes tend to address a subset of\nproperties specific to individual stages. Since these schemes targeting\ndifferent stages of DNS resolution are complementary and can operate together,\ncombining compatible schemes offers a practical and effective approach to\nachieving comprehensive security in the DNS resolution process.", "AI": {"tldr": "\u5bf912\u79cd\u5b89\u5168DNS\u65b9\u6848\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u8868\u660e\uff0c\u6ca1\u6709\u5355\u4e00\u65b9\u6848\u80fd\u63d0\u4f9b\u5b8c\u6574\u7684DNS\u89e3\u6790\u8def\u5f84\u4fdd\u62a4\uff0c\u4f46\u7ec4\u5408\u4f7f\u7528\u9488\u5bf9\u4e0d\u540c\u9636\u6bb5\u7684\u4e92\u8865\u65b9\u6848\u53ef\u5b9e\u73b0\u5168\u9762\u5b89\u5168", "motivation": "\u539f\u59cbDNS\u8bbe\u8ba1\u672a\u8003\u8651\u5b89\u5168\u6027\uff0c\u73b0\u6709\u5b89\u5168\u589e\u5f3a\u65b9\u6848\u8981\u4e48\u8bd5\u56fe\u5b8c\u5168\u66ff\u6362DNS\u57fa\u7840\u8bbe\u65bd\uff08\u672a\u6210\u529f\uff09\uff0c\u8981\u4e48\u5728\u4e0d\u6539\u53d8\u57fa\u672c\u4e24\u9636\u6bb5\u7ed3\u6784\u7684\u524d\u63d0\u4e0b\u6539\u8fdb\u5b89\u5168\u3002\u9700\u8981\u7cfb\u7edf\u5206\u6790DNS\u5b89\u5168\u5a01\u80c1\u5e76\u8bc4\u4f30\u73b0\u6709\u65b9\u6848\u7684\u6709\u6548\u6027", "method": "1) \u8c03\u67e5DNS\u89e3\u6790\u8fc7\u7a0b\u653b\u51fb\u5e76\u5efa\u7acb\u5168\u9762\u5a01\u80c1\u6a21\u578b\u548c\u653b\u51fb\u5206\u7c7b\u6cd5\uff1b2) \u5236\u5b9a14\u4e2a\u5b89\u5168\u3001\u9690\u79c1\u548c\u53ef\u7528\u6027\u5c5e\u6027\uff1b3) \u5f00\u53d1\u5ba2\u89c2\u8bc4\u4f30\u6846\u67b6\u5e76\u5e94\u7528\u4e8e\u5206\u679012\u79cd\u5b89\u5168DNS\u65b9\u6848", "result": "\u8bc4\u4f30\u663e\u793a\u6ca1\u6709\u5355\u4e00\u65b9\u6848\u80fd\u5728\u6574\u4e2a\u89e3\u6790\u8def\u5f84\u4e0a\u63d0\u4f9b\u7406\u60f3\u4fdd\u62a4\uff0c\u5404\u65b9\u6848\u503e\u5411\u4e8e\u89e3\u51b3\u7279\u5b9a\u9636\u6bb5\u7684\u5c5e\u6027\u5b50\u96c6\u3002\u9488\u5bf9\u4e0d\u540c\u9636\u6bb5\u7684\u65b9\u6848\u5177\u6709\u4e92\u8865\u6027\uff0c\u53ef\u4ee5\u534f\u540c\u5de5\u4f5c", "conclusion": "\u7ec4\u5408\u4f7f\u7528\u517c\u5bb9\u7684DNS\u5b89\u5168\u65b9\u6848\u662f\u5b9e\u73b0DNS\u89e3\u6790\u8fc7\u7a0b\u5168\u9762\u5b89\u5168\u7684\u5b9e\u7528\u6709\u6548\u65b9\u6cd5\uff0c\u56e0\u4e3a\u9488\u5bf9\u4e0d\u540c\u9636\u6bb5\u7684\u4e92\u8865\u65b9\u6848\u53ef\u4ee5\u534f\u540c\u8fd0\u4f5c"}}
{"id": "2509.13364", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13364", "abs": "https://arxiv.org/abs/2509.13364", "authors": ["Zixi Li"], "title": "Asterisk Operator", "comment": "Code available at: https://github.com/lizixi-0x2F/Asterisk-Games", "summary": "We propose the \\textbf{Asterisk Operator} ($\\ast$-operator), a novel unified\nframework for abstract reasoning based on Adjacency-Structured Parallel\nPropagation (ASPP). The operator formalizes structured reasoning tasks as\nlocal, parallel state evolution processes guided by implicit relational graphs.\nWe prove that the $\\ast$-operator maintains local computational constraints\nwhile achieving global reasoning capabilities, providing an efficient and\nconvergent computational paradigm for abstract reasoning problems. Through\nrigorous mathematical analysis and comprehensive experiments on ARC2 challenges\nand Conway's Game of Life, we demonstrate the operator's universality,\nconvergence properties, and superior performance. Our innovative\nEmbedding-Asterisk distillation method achieves 100\\% accuracy on ARC2\nvalidation with only 6M parameters, representing a significant breakthrough in\nneural-symbolic reasoning.\n  \\textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel\nPropagation, Asterisk Operator, Convergence, Universal Approximation", "AI": {"tldr": "\u63d0\u51fa\u4e86\u661f\u53f7\u7b97\u5b50\uff08*\u7b97\u5b50\uff09\u4f5c\u4e3a\u57fa\u4e8e\u90bb\u63a5\u7ed3\u6784\u5e76\u884c\u4f20\u64ad\u7684\u7edf\u4e00\u62bd\u8c61\u63a8\u7406\u6846\u67b6\uff0c\u5c06\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3a\u7531\u9690\u5f0f\u5173\u7cfb\u56fe\u5f15\u5bfc\u7684\u5c40\u90e8\u5e76\u884c\u72b6\u6001\u6f14\u5316\u8fc7\u7a0b\uff0c\u5728\u4fdd\u6301\u5c40\u90e8\u8ba1\u7b97\u7ea6\u675f\u7684\u540c\u65f6\u5b9e\u73b0\u5168\u5c40\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u62bd\u8c61\u63a8\u7406\u95ee\u9898\u4e2d\u5168\u5c40\u63a8\u7406\u4e0e\u5c40\u90e8\u8ba1\u7b97\u7ea6\u675f\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u9700\u8981\u4e00\u4e2a\u65e2\u80fd\u4fdd\u6301\u5c40\u90e8\u8ba1\u7b97\u6548\u7387\u53c8\u80fd\u5b9e\u73b0\u5168\u5c40\u63a8\u7406\u80fd\u529b\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u90bb\u63a5\u7ed3\u6784\u5e76\u884c\u4f20\u64ad\uff08ASPP\uff09\u7684\u661f\u53f7\u7b97\u5b50\uff0c\u5c06\u63a8\u7406\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3a\u5c40\u90e8\u5e76\u884c\u72b6\u6001\u6f14\u5316\u8fc7\u7a0b\uff0c\u901a\u8fc7\u9690\u5f0f\u5173\u7cfb\u56fe\u5f15\u5bfc\u8ba1\u7b97\uff0c\u5e76\u63d0\u51fa\u4e86Embedding-Asterisk\u84b8\u998f\u65b9\u6cd5\u3002", "result": "\u5728ARC2\u6311\u6218\u548c\u5eb7\u5a01\u751f\u547d\u6e38\u620f\u4e2d\u9a8c\u8bc1\u4e86\u7b97\u5b50\u7684\u901a\u7528\u6027\u3001\u6536\u655b\u6027\u548c\u4f18\u8d8a\u6027\u80fd\uff0c\u4f7f\u7528\u4ec56M\u53c2\u6570\u7684\u6a21\u578b\u5728ARC2\u9a8c\u8bc1\u96c6\u4e0a\u8fbe\u5230100%\u51c6\u786e\u7387\u3002", "conclusion": "\u661f\u53f7\u7b97\u5b50\u4e3a\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6536\u655b\u7684\u8ba1\u7b97\u8303\u5f0f\uff0c\u5728\u62bd\u8c61\u63a8\u7406\u9886\u57df\u5b9e\u73b0\u4e86\u91cd\u5927\u7a81\u7834\uff0c\u8bc1\u660e\u4e86\u5c40\u90e8\u8ba1\u7b97\u7ea6\u675f\u4e0b\u5b9e\u73b0\u5168\u5c40\u63a8\u7406\u80fd\u529b\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2509.13782", "categories": ["cs.SE", "cs.AI", "cs.MA", "D.2.2; I.2.1"], "pdf": "https://arxiv.org/pdf/2509.13782", "abs": "https://arxiv.org/abs/2509.13782", "authors": ["Yu Ge", "Linna Xie", "Zhong Li", "Yu Pei", "Tian Zhang"], "title": "Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis", "comment": "20 pages, 6 figures", "summary": "Large Language Model Powered Multi-Agent Systems (MASs) are increasingly\nemployed to automate complex real-world problems, such as programming and\nscientific discovery. Despite their promising, MASs are not without their\nflaws. However, failure attribution in MASs - pinpointing the specific agent\nactions responsible for failures - remains underexplored and labor-intensive,\nposing significant challenges for debugging and system improvement. To bridge\nthis gap, we propose FAMAS, the first spectrum-based failure attribution\napproach for MASs, which operates through systematic trajectory replay and\nabstraction, followed by spectrum analysis.The core idea of FAMAS is to\nestimate, from variations across repeated MAS executions, the likelihood that\neach agent action is responsible for the failure. In particular, we propose a\nnovel suspiciousness formula tailored to MASs, which integrates two key factor\ngroups, namely the agent behavior group and the action behavior group, to\naccount for the agent activation patterns and the action activation patterns\nwithin the execution trajectories of MASs. Through expensive evaluations\nagainst 12 baselines on the Who and When benchmark, FAMAS demonstrates superior\nperformance by outperforming all the methods in comparison.", "AI": {"tldr": "FAMAS\u662f\u9996\u4e2a\u57fa\u4e8e\u9891\u8c31\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6545\u969c\u5f52\u56e0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f68\u8ff9\u91cd\u653e\u548c\u9891\u8c31\u5206\u6790\u6765\u8bc6\u522b\u5bfc\u81f4\u6545\u969c\u7684\u5177\u4f53\u667a\u80fd\u4f53\u884c\u4e3a", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u5e94\u7528\u5e7f\u6cdb\u4f46\u5b58\u5728\u6545\u969c\uff0c\u76ee\u524d\u6545\u969c\u5f52\u56e0\u65b9\u6cd5\u7814\u7a76\u4e0d\u8db3\u4e14\u4eba\u5de5\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u8fdb\u884c\u7cfb\u7edf\u8c03\u8bd5\u548c\u6539\u8fdb", "method": "\u63d0\u51faFAMAS\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u8f68\u8ff9\u91cd\u653e\u548c\u62bd\u8c61\uff0c\u7136\u540e\u8fdb\u884c\u9891\u8c31\u5206\u6790\uff0c\u4f30\u8ba1\u6bcf\u4e2a\u667a\u80fd\u4f53\u884c\u4e3a\u5bfc\u81f4\u6545\u969c\u7684\u53ef\u80fd\u6027\u3002\u8bbe\u8ba1\u4e86\u4e13\u95e8\u9488\u5bf9MAS\u7684\u6000\u7591\u5ea6\u516c\u5f0f\uff0c\u6574\u5408\u667a\u80fd\u4f53\u884c\u4e3a\u7ec4\u548c\u52a8\u4f5c\u884c\u4e3a\u7ec4\u4e24\u4e2a\u5173\u952e\u56e0\u7d20", "result": "\u5728Who and When\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0e12\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0cFAMAS\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u6240\u6709\u5bf9\u6bd4\u65b9\u6cd5", "conclusion": "FAMAS\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6545\u969c\u5f52\u56e0\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u51c6\u786e\u5b9a\u4f4d\u5bfc\u81f4\u6545\u969c\u7684\u5177\u4f53\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u6709\u52a9\u4e8e\u7cfb\u7edf\u8c03\u8bd5\u548c\u6539\u8fdb"}}
{"id": "2509.13987", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13987", "abs": "https://arxiv.org/abs/2509.13987", "authors": ["Ozer Ozturk", "Busra Buyuktanir", "Gozde Karatas Baydogmus", "Kazim Yildiz"], "title": "Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response", "comment": null, "summary": "Machine learning models used for distributed architectures consisting of\nservers and clients require large amounts of data to achieve high accuracy.\nData obtained from clients are collected on a central server for model\ntraining. However, storing data on a central server raises concerns about\nsecurity and privacy. To address this issue, a federated learning architecture\nhas been proposed. In federated learning, each client trains a local model\nusing its own data. The trained models are periodically transmitted to the\ncentral server. The server then combines the received models using federated\naggregation algorithms to obtain a global model. This global model is\ndistributed back to the clients, and the process continues in a cyclical\nmanner. Although preventing data from leaving the clients enhances security,\ncertain concerns still remain. Attackers can perform inference attacks on the\nobtained models to approximate the training dataset, potentially causing data\nleakage. In this study, differential privacy was applied to address the\naforementioned security vulnerability, and a performance analysis was\nconducted. The Data-Unaware Classification Based on Association (duCBA)\nalgorithm was used as the federated aggregation method. Differential privacy\nwas implemented on the data using the Randomized Response technique, and the\ntrade-off between security and performance was examined under different epsilon\nvalues. As the epsilon value decreased, the model accuracy declined, and class\nprediction imbalances were observed. This indicates that higher levels of\nprivacy do not always lead to practical outcomes and that the balance between\nsecurity and performance must be carefully considered.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u5e94\u7528\u5dee\u5206\u9690\u79c1\u6280\u672f\u6765\u89e3\u51b3\u6a21\u578b\u63a8\u7406\u653b\u51fb\u5bfc\u81f4\u7684\u6570\u636e\u6cc4\u9732\u95ee\u9898\uff0c\u901a\u8fc7\u968f\u673a\u54cd\u5e94\u6280\u672f\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u9690\u79c1\u9884\u7b97(epsilon\u503c)\u4e0b\u5b89\u5168\u6027\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u6743\u8861\u5173\u7cfb\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u907f\u514d\u4e86\u539f\u59cb\u6570\u636e\u79bb\u5f00\u5ba2\u6237\u7aef\uff0c\u4f46\u653b\u51fb\u8005\u4ecd\u53ef\u901a\u8fc7\u6a21\u578b\u63a8\u7406\u653b\u51fb\u8fd1\u4f3c\u91cd\u6784\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5b58\u5728\u6570\u636e\u6cc4\u9732\u98ce\u9669\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u4f7f\u7528duCBA\u7b97\u6cd5\u4f5c\u4e3a\u8054\u90a6\u805a\u5408\u65b9\u6cd5\uff0c\u91c7\u7528\u968f\u673a\u54cd\u5e94\u6280\u672f\u5b9e\u73b0\u5dee\u5206\u9690\u79c1\uff0c\u5728\u4e0d\u540cepsilon\u503c\u4e0b\u6d4b\u8bd5\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u3002", "result": "\u968f\u7740epsilon\u503c\u51cf\u5c0f(\u9690\u79c1\u4fdd\u62a4\u589e\u5f3a)\uff0c\u6a21\u578b\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u51fa\u73b0\u7c7b\u522b\u9884\u6d4b\u4e0d\u5e73\u8861\u73b0\u8c61\u3002\u66f4\u9ad8\u7684\u9690\u79c1\u4fdd\u62a4\u6c34\u5e73\u5e76\u4e0d\u603b\u80fd\u5e26\u6765\u5b9e\u7528\u7ed3\u679c\u3002", "conclusion": "\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u5e94\u7528\u5dee\u5206\u9690\u79c1\u65f6\uff0c\u5fc5\u987b\u4ed4\u7ec6\u6743\u8861\u5b89\u5168\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u9009\u62e9\u5408\u9002\u7684\u9690\u79c1\u9884\u7b97\u53c2\u6570\u3002"}}
{"id": "2509.13368", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13368", "abs": "https://arxiv.org/abs/2509.13368", "authors": ["Yuan Wei", "Xiaohan Shan", "Ran Miao", "Jianmin Li"], "title": "$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation", "comment": "9 pages, 7 figures", "summary": "Reinforcement learning agent development traditionally requires extensive\nexpertise and lengthy iterations, often resulting in high failure rates and\nlimited accessibility. This paper introduces $Agent^2$, a novel\nagent-generates-agent framework that achieves fully automated RL agent design\nthrough intelligent LLM-driven generation. The system autonomously transforms\nnatural language task descriptions and environment code into comprehensive,\nhigh-performance reinforcement learning solutions without human intervention.\n$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent\nserves as an autonomous AI designer that analyzes tasks and generates\nexecutable RL agents, while the Target Agent is the resulting automatically\ngenerated RL agent. The framework decomposes RL development into two distinct\nstages: MDP modeling and algorithmic optimization, enabling more targeted and\neffective agent generation. Built on the Model Context Protocol, $Agent^2$\nprovides a unified framework that standardizes intelligent agent creation\nacross diverse environments and algorithms, while incorporating adaptive\ntraining management and intelligent feedback analysis for continuous\nimprovement. Extensive experiments on a wide range of benchmarks, including\nMuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently\noutperforms manually designed solutions across all tasks, achieving up to 55%\nperformance improvement and substantial gains on average. By enabling truly\nend-to-end, closed-loop automation, this work establishes a new paradigm in\nwhich intelligent agents design and optimize other agents, marking a\nfundamental breakthrough for automated AI systems.", "AI": {"tldr": "Agent^2\u662f\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u6362\u4e3a\u9ad8\u6027\u80fdRL\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002", "motivation": "\u4f20\u7edfRL\u4ee3\u7406\u5f00\u53d1\u9700\u8981\u5927\u91cf\u4e13\u4e1a\u77e5\u8bc6\u548c\u8fed\u4ee3\uff0c\u5931\u8d25\u7387\u9ad8\u4e14\u53ef\u8bbf\u95ee\u6027\u6709\u9650\u3002\u9700\u8981\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684RL\u4ee3\u7406\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528\u53cc\u4ee3\u7406\u67b6\u6784\uff1a\u751f\u6210\u5668\u4ee3\u7406\u5206\u6790\u4efb\u52a1\u5e76\u751f\u6210\u53ef\u6267\u884cRL\u4ee3\u7406\uff0c\u76ee\u6807\u4ee3\u7406\u662f\u81ea\u52a8\u751f\u6210\u7684RL\u4ee3\u7406\u3002\u6846\u67b6\u5c06RL\u5f00\u53d1\u5206\u89e3\u4e3aMDP\u5efa\u6a21\u548c\u7b97\u6cd5\u4f18\u5316\u4e24\u4e2a\u9636\u6bb5\uff0c\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u6784\u5efa\u3002", "result": "\u5728MuJoCo\u3001MetaDrive\u3001MPE\u548cSMAC\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgent^2\u59cb\u7ec8\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe55%\uff0c\u5e73\u5747\u8868\u73b0\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5efa\u7acb\u4e86\u667a\u80fd\u4ee3\u7406\u8bbe\u8ba1\u548c\u4f18\u5316\u5176\u4ed6\u4ee3\u7406\u7684\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u771f\u6b63\u7aef\u5230\u7aef\u7684\u95ed\u73af\u81ea\u52a8\u5316\uff0c\u662f\u81ea\u52a8\u5316AI\u7cfb\u7edf\u7684\u6839\u672c\u6027\u7a81\u7834\u3002"}}
{"id": "2509.13852", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13852", "abs": "https://arxiv.org/abs/2509.13852", "authors": ["Yulun Wu", "Guangba Yu", "Zhihan Jiang", "Yichen Li", "Michael R. Lyu"], "title": "Trace Sampling 2.0: Code Knowledge Enhanced Span-level Sampling for Distributed Tracing", "comment": null, "summary": "Distributed tracing is an essential diagnostic tool in microservice systems,\nbut the sheer volume of traces places a significant burden on backend storage.\nA common approach to mitigating this issue is trace sampling, which selectively\nretains traces based on specific criteria, often preserving only anomalous\nones. However, this method frequently discards valuable information, including\nnormal traces that are essential for comparative analysis. To address this\nlimitation, we introduce Trace Sampling 2.0, which operates at the span level\nwhile maintaining trace structure consistency. This approach allows for the\nretention of all traces while significantly reducing storage overhead. Based on\nthis concept, we design and implement Autoscope, a span-level sampling method\nthat leverages static analysis to extract execution logic, ensuring that\ncritical spans are preserved without compromising structural integrity. We\nevaluated Autoscope on two open-source microservices. Our results show that it\nreduces trace size by 81.2% while maintaining 98.1% faulty span coverage,\noutperforming existing trace-level sampling methods. Furthermore, we\ndemonstrate its effectiveness in root cause analysis, achieving an average\nimprovement of 8.3%. These findings indicate that Autoscope can significantly\nenhance observability and storage efficiency in microservices, offering a\nrobust solution for performance monitoring.", "AI": {"tldr": "Trace Sampling 2.0\u901a\u8fc7span\u7ea7\u522b\u91c7\u6837\u5728\u4fdd\u6301trace\u7ed3\u6784\u4e00\u81f4\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u5b58\u50a8\u5f00\u9500\u3002Autoscope\u5b9e\u73b0\u8be5\u65b9\u6cd5\uff0c\u51cf\u5c1181.2% trace\u5927\u5c0f\uff0c\u540c\u65f6\u4fdd\u630198.1%\u6545\u969cspan\u8986\u76d6\u7387\u3002", "motivation": "\u5206\u5e03\u5f0f\u8ffd\u8e2a\u5728\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u662f\u91cd\u8981\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u4f46\u6d77\u91cftrace\u6570\u636e\u7ed9\u540e\u7aef\u5b58\u50a8\u5e26\u6765\u5de8\u5927\u8d1f\u62c5\u3002\u4f20\u7edftrace\u91c7\u6837\u65b9\u6cd5\u901a\u5e38\u4f1a\u4e22\u5f03\u6709\u4ef7\u503c\u7684\u4fe1\u606f\uff0c\u5305\u62ec\u7528\u4e8e\u5bf9\u6bd4\u5206\u6790\u7684\u6b63\u6837\u672ctrace\u3002", "method": "\u63d0\u51faTrace Sampling 2.0\uff0c\u5728span\u7ea7\u522b\u8fdb\u884c\u91c7\u6837\u540c\u65f6\u4fdd\u6301trace\u7ed3\u6784\u4e00\u81f4\u6027\u3002\u8bbe\u8ba1\u5b9e\u73b0Autoscope\uff0c\u5229\u7528\u9759\u6001\u5206\u6790\u63d0\u53d6\u6267\u884c\u903b\u8f91\uff0c\u786e\u4fdd\u5173\u952espan\u88ab\u4fdd\u7559\u800c\u4e0d\u635f\u5bb3\u7ed3\u6784\u5b8c\u6574\u6027\u3002", "result": "\u5728\u4e24\u4e2a\u5f00\u6e90\u5fae\u670d\u52a1\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\uff1atrace\u5927\u5c0f\u51cf\u5c1181.2%\uff0c\u540c\u65f6\u4fdd\u630198.1%\u6545\u969cspan\u8986\u76d6\u7387\uff0c\u4f18\u4e8e\u73b0\u6709trace\u7ea7\u522b\u91c7\u6837\u65b9\u6cd5\u3002\u5728\u6839\u56e0\u5206\u6790\u4e2d\u5e73\u5747\u63d0\u53478.3%\u6548\u679c\u3002", "conclusion": "Autoscope\u80fd\u663e\u8457\u63d0\u5347\u5fae\u670d\u52a1\u4e2d\u7684\u53ef\u89c2\u6d4b\u6027\u548c\u5b58\u50a8\u6548\u7387\uff0c\u4e3a\u6027\u80fd\u76d1\u63a7\u63d0\u4f9b\u5f3a\u5927\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14035", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.14035", "abs": "https://arxiv.org/abs/2509.14035", "authors": ["Hannah Keller", "Jacob Imola", "Fabrizio Boninsegna", "Rasmus Pagh", "Amrita Roy Chowdhury"], "title": "Piquant$\\varepsilon$: Private Quantile Estimation in the Two-Server Model", "comment": "30 Pages, 19 Figures, 1 Table", "summary": "Quantiles are key in distributed analytics, but computing them over sensitive\ndata risks privacy. Local differential privacy (LDP) offers strong protection\nbut lower accuracy than central DP, which assumes a trusted aggregator. Secure\nmulti-party computation (MPC) can bridge this gap, but generic MPC solutions\nface scalability challenges due to large domains, complex secure operations,\nand multi-round interactions.\n  We present Piquant$\\varepsilon$, a system for privacy-preserving estimation\nof multiple quantiles in a distributed setting without relying on a trusted\nserver. Piquant$\\varepsilon$ operates under the malicious threat model and\nachieves accuracy of the central DP model. Built on the two-server model,\nPiquant$\\varepsilon$ uses a novel strategy of releasing carefully chosen\nintermediate statistics, reducing MPC complexity while preserving end-to-end\nDP. Empirically, Piquant$\\varepsilon$ estimates 5 quantiles on 1 million\nrecords in under a minute with domain size $10^9$, achieving up to $10^4$-fold\nhigher accuracy than LDP, and up to $\\sim 10\\times$ faster runtime compared to\nbaselines.", "AI": {"tldr": "Piquant\u03b5\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u9690\u79c1\u4fdd\u62a4\u5206\u4f4d\u6570\u4f30\u8ba1\u7cfb\u7edf\uff0c\u65e0\u9700\u53ef\u4fe1\u670d\u52a1\u5668\uff0c\u5728\u6076\u610f\u5a01\u80c1\u6a21\u578b\u4e0b\u5b9e\u73b0\u4e2d\u5fc3\u5dee\u5206\u9690\u79c1\u7684\u7cbe\u5ea6\uff0c\u6bd4\u672c\u5730\u5dee\u5206\u9690\u79c1\u7cbe\u5ea6\u9ad810^4\u500d\uff0c\u8fd0\u884c\u901f\u5ea6\u5feb10\u500d", "motivation": "\u5206\u5e03\u5f0f\u5206\u6790\u4e2d\u5206\u4f4d\u6570\u8ba1\u7b97\u5bf9\u654f\u611f\u6570\u636e\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u672c\u5730\u5dee\u5206\u9690\u79c1\u7cbe\u5ea6\u4f4e\uff0c\u4e2d\u5fc3\u5dee\u5206\u9690\u79c1\u9700\u8981\u53ef\u4fe1\u805a\u5408\u5668\uff0c\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u5b58\u5728\u53ef\u6269\u5c55\u6027\u6311\u6218", "method": "\u57fa\u4e8e\u53cc\u670d\u52a1\u5668\u6a21\u578b\uff0c\u91c7\u7528\u91ca\u653e\u7cbe\u5fc3\u9009\u62e9\u7684\u4e2d\u95f4\u7edf\u8ba1\u4fe1\u606f\u7684\u65b0\u7b56\u7565\uff0c\u964d\u4f4eMPC\u590d\u6742\u5ea6\u540c\u65f6\u4fdd\u6301\u7aef\u5230\u7aef\u5dee\u5206\u9690\u79c1", "result": "\u5728100\u4e07\u6761\u8bb0\u5f55\u4e0a\u4f30\u8ba15\u4e2a\u5206\u4f4d\u6570\u7528\u65f6\u4e0d\u52301\u5206\u949f\uff08\u57df\u5927\u5c0f10^9\uff09\uff0c\u6bd4LDP\u7cbe\u5ea6\u9ad810^4\u500d\uff0c\u6bd4\u57fa\u7ebf\u8fd0\u884c\u901f\u5ea6\u5feb\u7ea610\u500d", "conclusion": "Piquant\u03b5\u6210\u529f\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u9690\u79c1\u5206\u4f4d\u6570\u4f30\u8ba1\u7684\u6311\u6218\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u6548\u8ba1\u7b97\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13379", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.13379", "abs": "https://arxiv.org/abs/2509.13379", "authors": ["Asif Azad", "Mohammad Sadat Hossain", "MD Sadik Hossain Shanto", "M Saifur Rahman", "Md Rizwan Pervez"], "title": "The Art of Saying \"Maybe\": A Conformal Lens for Uncertainty Benchmarking in VLMs", "comment": null, "summary": "Vision-Language Models (VLMs) have achieved remarkable progress in complex\nvisual understanding across scientific and reasoning tasks. While performance\nbenchmarking has advanced our understanding of these capabilities, the critical\ndimension of uncertainty quantification has received insufficient attention.\nTherefore, unlike prior conformal prediction studies that focused on limited\nsettings, we conduct a comprehensive uncertainty benchmarking study, evaluating\n16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets\nwith 3 distinct scoring functions. Our findings demonstrate that larger models\nconsistently exhibit better uncertainty quantification; models that know more\nalso know better what they don't know. More certain models achieve higher\naccuracy, while mathematical and reasoning tasks elicit poorer uncertainty\nperformance across all models compared to other domains. This work establishes\na foundation for reliable uncertainty evaluation in multimodal systems.", "AI": {"tldr": "\u5bf916\u4e2a\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u57286\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5168\u9762\u7684\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5927\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff0c\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u73b0\u8f83\u5dee", "motivation": "\u867d\u7136\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u89c6\u89c9\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u8fd9\u4e00\u5173\u952e\u7ef4\u5ea6\u5c1a\u672a\u5f97\u5230\u5145\u5206\u5173\u6ce8\uff0c\u9700\u8981\u8d85\u8d8a\u6709\u9650\u7684\u73b0\u6709\u7814\u7a76\u8fdb\u884c\u5168\u9762\u7684\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u6d4b\u8bd5", "method": "\u8bc4\u4f3016\u4e2a\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08\u5f00\u6e90\u548c\u95ed\u6e90\uff09\uff0c\u57286\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u4f7f\u75283\u79cd\u4e0d\u540c\u7684\u8bc4\u5206\u51fd\u6570\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u6d4b\u8bd5", "result": "\u8f83\u5927\u6a21\u578b\u6301\u7eed\u8868\u73b0\u51fa\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff1b\u66f4\u786e\u5b9a\u7684\u6a21\u578b\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\uff1b\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u5728\u6240\u6709\u6a21\u578b\u4e2d\u76f8\u6bd4\u5176\u4ed6\u9886\u57df\u8868\u73b0\u51fa\u8f83\u5dee\u7684\u4e0d\u786e\u5b9a\u6027\u6027\u80fd", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u591a\u6a21\u6001\u7cfb\u7edf\u4e2d\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2509.13868", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13868", "abs": "https://arxiv.org/abs/2509.13868", "authors": ["Manal Binkhonain", "Reem Alfayaz"], "title": "Are Prompts All You Need? Evaluating Prompt-Based Large Language Models (LLM)s for Software Requirements Classification", "comment": "33 pages, 12 figures", "summary": "Requirements classification assigns natural language requirements to\npredefined classes, such as functional and non functional. Accurate\nclassification reduces risk and improves software quality. Most existing models\nrely on supervised learning, which needs large labeled data that are costly,\nslow to create, and domain dependent; they also generalize poorly and often\nrequire retraining for each task. This study tests whether prompt based large\nlanguage models can reduce data needs. We benchmark several models and\nprompting styles (zero shot, few shot, persona, and chain of thought) across\nmultiple tasks on two English datasets, PROMISE and SecReq. For each task we\ncompare model prompt configurations and then compare the best LLM setups with a\nstrong fine tuned transformer baseline. Results show that prompt based LLMs,\nespecially with few shot prompts, can match or exceed the baseline. Adding a\npersona, or persona plus chain of thought, can yield further gains. We conclude\nthat prompt based LLMs are a practical and scalable option that reduces\ndependence on large annotations and can improve generalizability across tasks.", "AI": {"tldr": "\u57fa\u4e8e\u63d0\u793a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u5728\u9700\u6c42\u5206\u7c7b\u4efb\u52a1\u4e2d\u51cf\u5c11\u5bf9\u5927\u91cf\u6807\u7b7e\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u901a\u8fc7\u51e0\u79cd\u63d0\u793a\u65b9\u5f0f\u5b9e\u73b0\u4e86\u4e0e\u7ec6\u8c03\u8f6c\u6362\u5668\u57fa\u7ebf\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd", "motivation": "\u73b0\u6709\u7684\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u9700\u8981\u5927\u91cf\u8c46\u5b50\u6807\u7b7e\u6570\u636e\uff0c\u6210\u672c\u9ad8\u3001\u521b\u5efa\u6162\u3001\u9886\u57df\u4f9d\u8d56\u6027\u5f3a\u4e14\u6e10\u8fc1\u6027\u5dee\uff0c\u9700\u8981\u9488\u5bf9\u6bcf\u4e2a\u4efb\u52a1\u91cd\u65b0\u8bad\u7ec3", "method": "\u5728PROMISE\u548cSecReq\u4e24\u4e2a\u82f1\u8bed\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4\u591a\u4e2a\u6a21\u578b\u548c\u63d0\u793a\u98ce\u683c\uff08\u96f6\u68b0\u51fb\u3001\u5c11\u68b0\u51fb\u3001\u4eba\u8bbe\u548c\u601d\u7ef4\u94fe\uff09\uff0c\u5e76\u4e0e\u5f3a\u529b\u7684\u7ec6\u8c03\u8f6c\u6362\u5668\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83", "result": "\u63d0\u793a\u57fa\u7840\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7279\u522b\u662f\u4f7f\u7528\u5c11\u68b0\u51fb\u65f6\uff0c\u53ef\u4ee5\u8fbe\u5230\u6216\u8d85\u8fc7\u57fa\u7ebf\u6a21\u578b\u7684\u6027\u80fd\u3002\u6dfb\u52a0\u4eba\u8bbe\u6216\u4eba\u8bbe\u52a0\u601d\u7ef4\u94fe\u8fd8\u80fd\u5e26\u6765\u8fdb\u4e00\u6b65\u7684\u6027\u80fd\u63d0\u5347", "conclusion": "\u57fa\u4e8e\u63d0\u793a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u9009\u62e9\uff0c\u80fd\u591f\u51cf\u5c11\u5bf9\u5927\u91cf\u6ce8\u91ca\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u5e76\u63d0\u9ad8\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u7684\u6e10\u8fc1\u80fd\u529b"}}
{"id": "2509.14096", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.14096", "abs": "https://arxiv.org/abs/2509.14096", "authors": ["V\u00edctor Mayoral-Vilches"], "title": "The Cybersecurity of a Humanoid Robot", "comment": null, "summary": "The rapid advancement of humanoid robotics presents unprecedented\ncybersecurity challenges that existing theoretical frameworks fail to\nadequately address. This report presents a comprehensive security assessment of\na production humanoid robot platform, bridging the gap between abstract\nsecurity models and operational vulnerabilities. Through systematic static\nanalysis, runtime observation, and cryptographic examination, we uncovered a\ncomplex security landscape characterized by both sophisticated defensive\nmechanisms and critical vulnerabilities. Our findings reveal a dual-layer\nproprietary encryption system (designated FMX') that, while innovative in\ndesign, suffers from fundamental implementation flaws including the use of\nstatic cryptographic keys that enable offline configuration decryption. More\nsignificantly, we documented persistent telemetry connections transmitting\ndetailed robot state information--including audio, visual, spatial, and\nactuator data--to external servers without explicit user consent or\nnotification mechanisms. We operationalized a Cybersecurity AI agent on the\nUnitree G1 to map and prepare exploitation of its manufacturer's cloud\ninfrastructure, illustrating how a compromised humanoid can escalate from\ncovert data collection to active counter-offensive operations. We argue that\nsecuring humanoid robots requires a paradigm shift toward Cybersecurity AI\n(CAI) frameworks that can adapt to the unique challenges of physical-cyber\nconvergence. This work contributes empirical evidence for developing robust\nsecurity standards as humanoid robots transition from research curiosities to\noperational systems in critical domains.", "AI": {"tldr": "\u5bf9Unitree G1\u4eba\u5f62\u673a\u5668\u4eba\u5e73\u53f0\u7684\u5b89\u5168\u8bc4\u4f30\u53d1\u73b0\u5176\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u5305\u62ec\u9759\u6001\u52a0\u5bc6\u5bc6\u94a5\u548c\u672a\u7ecf\u540c\u610f\u7684\u8fdc\u7a0b\u6570\u636e\u4f20\u8f93\uff0c\u63d0\u51fa\u4e86\u7f51\u7edc\u5b89\u5168AI\u6846\u67b6\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u7406\u8bba\u6846\u67b6\u65e0\u6cd5\u5145\u5206\u5e94\u5bf9\u4eba\u5f62\u673a\u5668\u4eba\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u7684\u7f51\u7edc\u5b89\u5168\u6311\u6218\uff0c\u9700\u8981\u5f25\u5408\u62bd\u8c61\u5b89\u5168\u6a21\u578b\u4e0e\u5b9e\u9645\u6f0f\u6d1e\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u9759\u6001\u5206\u6790\u3001\u8fd0\u884c\u65f6\u89c2\u5bdf\u548c\u5bc6\u7801\u5b66\u68c0\u67e5\uff0c\u5bf9\u751f\u4ea7\u7ea7\u4eba\u5f62\u673a\u5668\u4eba\u5e73\u53f0\u8fdb\u884c\u5168\u9762\u5b89\u5168\u8bc4\u4f30\uff0c\u5e76\u5728\u5e73\u53f0\u4e0a\u90e8\u7f72\u7f51\u7edc\u5b89\u5168AI\u4ee3\u7406\u8fdb\u884c\u6f0f\u6d1e\u5229\u7528\u6f14\u793a\u3002", "result": "\u53d1\u73b0\u53cc\u91cd\u4e13\u6709\u52a0\u5bc6\u7cfb\u7edf(FMX')\u5b58\u5728\u6839\u672c\u6027\u5b9e\u73b0\u7f3a\u9677\uff0c\u5305\u62ec\u4f7f\u7528\u9759\u6001\u5bc6\u94a5\uff1b\u8bb0\u5f55\u4e86\u6301\u7eed\u5411\u5916\u90e8\u670d\u52a1\u5668\u4f20\u8f93\u654f\u611f\u6570\u636e\u7684\u884c\u4e3a\uff1b\u5c55\u793a\u4e86\u4ece\u9690\u853d\u6570\u636e\u6536\u96c6\u5230\u4e3b\u52a8\u53cd\u51fb\u64cd\u4f5c\u7684\u653b\u51fb\u94fe\u3002", "conclusion": "\u4fdd\u62a4\u4eba\u5f62\u673a\u5668\u4eba\u9700\u8981\u5411\u7f51\u7edc\u5b89\u5168AI\u6846\u67b6\u8303\u5f0f\u8f6c\u53d8\uff0c\u4ee5\u5e94\u5bf9\u7269\u7406-\u7f51\u7edc\u878d\u5408\u7684\u72ec\u7279\u6311\u6218\uff0c\u4e3a\u5236\u5b9a\u5f3a\u5065\u5b89\u5168\u6807\u51c6\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002"}}
{"id": "2509.13389", "categories": ["cs.AI", "I.2.4; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2509.13389", "abs": "https://arxiv.org/abs/2509.13389", "authors": ["Carlos N\u00fa\u00f1ez-Molina", "Vicen\u00e7 G\u00f3mez", "Hector Geffner"], "title": "From Next Token Prediction to (STRIPS) World Models -- Preliminary Results", "comment": "10 pages, 3 figures", "summary": "We consider the problem of learning propositional STRIPS world models from\naction traces alone, using a deep learning architecture (transformers) and\ngradient descent. The task is cast as a supervised next token prediction\nproblem where the tokens are the actions, and an action $a$ may follow an\naction sequence if the hidden effects of the previous actions do not make an\naction precondition of $a$ false. We show that a suitable transformer\narchitecture can faithfully represent propositional STRIPS world models, and\nthat the models can be learned from sets of random valid (positive) and invalid\n(negative) action sequences alone. A number of experiments are reported.", "AI": {"tldr": "\u4f7f\u7528\u53d8\u6362\u5668\u6a21\u578b\u4ece\u52a8\u4f5c\u8e2a\u8ff9\u5b66\u4e60STRIPS\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u4e0b\u4e00\u4e2a\u52a8\u4f5c\u9884\u6d4b\u6765\u5b66\u4e60\u884c\u4e3a\u524d\u63d0\u548c\u6548\u679c\u3002", "motivation": "\u4ece\u52a8\u4f5c\u8e2a\u8ff9\u4e2d\u81ea\u52a8\u5b66\u4e60\u63a8\u7406\u6a21\u578b\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u884c\u4e3a\u524d\u63d0\u548c\u6548\u679c\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5b9e\u73b0\u3002", "method": "\u5c06\u4efb\u52a1\u6d3e\u751f\u4e3a\u4e0b\u4e00\u4e2a\u52a8\u4f5c\u9884\u6d4b\u95ee\u9898\uff0c\u4f7f\u7528\u53d8\u6362\u5668\u6a21\u578b\u5b66\u4e60\u6709\u6548\u548c\u65e0\u6548\u52a8\u4f5c\u5e8f\u5217\u7684\u533a\u522b\uff0c\u4ece\u800c\u63a8\u65adSTRIPS\u6a21\u578b\u7684\u9690\u85cf\u7ed3\u6784\u3002", "result": "\u8bc1\u660e\u53d8\u6362\u5668\u6a21\u578b\u80fd\u591f\u51c6\u786e\u8868\u5f81\u547d\u9898STRIPS\u4e16\u754c\u6a21\u578b\uff0c\u4ec5\u4ece\u968f\u673a\u6709\u6548\u548c\u65e0\u6548\u52a8\u4f5c\u5e8f\u5217\u5c31\u53ef\u5b66\u4e60\u5230\u8fd9\u4e9b\u6a21\u578b\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u4ece\u52a8\u4f5c\u8e2a\u8ff9\u4e2d\u81ea\u52a8\u5b66\u4e60STRIPS\u6a21\u578b\uff0c\u4e3a\u81ea\u52a8\u63a8\u7406\u548c\u89c4\u5212\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2509.13896", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13896", "abs": "https://arxiv.org/abs/2509.13896", "authors": ["Shalini Chakraborty", "Lola Burgue\u00f1o", "Nathalie Moreno", "Javier Troya", "Paula Mu\u00f1oz"], "title": "Mind the Ethics! The Overlooked Ethical Dimensions of GenAI in Software Modeling Education", "comment": "8 pages, Educators Symposium at MODELS 2025", "summary": "Generative Artificial Intelligence (GenAI) is rapidly gaining momentum in\nsoftware modeling education, embraced by both students and educators. As GenAI\nassists with interpreting requirements, formalizing models, and translating\nstudents' mental models into structured notations, it increasingly shapes core\nlearning outcomes such as domain comprehension, diagrammatic thinking, and\nmodeling fluency without clear ethical oversight or pedagogical guidelines.\nYet, the ethical implications of this integration remain underexplored.\n  In this paper, we conduct a systematic literature review across six major\ndigital libraries in computer science (ACM Digital Library, IEEE Xplore,\nScopus, ScienceDirect, SpringerLink, and Web of Science). Our aim is to\nidentify studies discussing the ethical aspects of GenAI in software modeling\neducation, including responsibility, fairness, transparency, diversity, and\ninclusion among others.\n  Out of 1,386 unique papers initially retrieved, only three explicitly\naddressed ethical considerations. This scarcity highlights the critical absence\nof ethical discourse surrounding GenAI in modeling education and raises urgent\nquestions about the responsible integration of AI in modeling curricula, as\nwell as it evinces the pressing need for structured ethical frameworks in this\nemerging educational landscape. We examine these three studies and explore the\nemerging research opportunities as well as the challenges that have arisen in\nthis field.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u53d1\u73b0\uff0c\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5efa\u6a21\u6559\u80b2\u4e2d\u7684\u4f26\u7406\u8003\u91cf\u7814\u7a76\u4e25\u91cd\u7f3a\u5931\uff0c\u4ec53\u7bc7\u8bba\u6587\u660e\u786e\u8ba8\u8bba\u76f8\u5173\u4f26\u7406\u95ee\u9898\uff0c\u51f8\u663e\u4e86\u8be5\u9886\u57df\u6025\u9700\u7ed3\u6784\u5316\u4f26\u7406\u6846\u67b6\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5efa\u6a21\u6559\u80b2\u4e2d\u8fc5\u901f\u666e\u53ca\uff0c\u4f46\u7f3a\u4e4f\u660e\u786e\u7684\u4f26\u7406\u76d1\u7763\u548c\u6559\u5b66\u6307\u5bfc\uff0c\u5176\u4f26\u7406\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7814\u7a76\u6765\u8bc6\u522b\u548c\u89e3\u51b3\u76f8\u5173\u4f26\u7406\u95ee\u9898\u3002", "method": "\u5bf9\u8ba1\u7b97\u673a\u79d1\u5b66\u516d\u5927\u6570\u5b57\u56fe\u4e66\u9986\uff08ACM\u3001IEEE\u3001Scopus\u3001ScienceDirect\u3001SpringerLink\u3001Web of Science\uff09\u8fdb\u884c\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u7b5b\u9009\u8ba8\u8bba\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5efa\u6a21\u6559\u80b2\u4e2d\u4f26\u7406\u65b9\u9762\u7684\u7814\u7a76\u3002", "result": "\u4ece1386\u7bc7\u72ec\u7279\u8bba\u6587\u4e2d\u4ec5\u53d1\u73b03\u7bc7\u660e\u786e\u8ba8\u8bba\u4f26\u7406\u8003\u91cf\uff0c\u5305\u62ec\u8d23\u4efb\u3001\u516c\u5e73\u3001\u900f\u660e\u3001\u591a\u6837\u6027\u548c\u5305\u5bb9\u6027\u7b49\u95ee\u9898\uff0c\u8868\u660e\u8be5\u9886\u57df\u4f26\u7406\u8ba8\u8bba\u4e25\u91cd\u7f3a\u4e4f\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u5efa\u6a21\u6559\u80b2\u4e2d\u7684\u4f26\u7406\u8bdd\u8bed\u4e25\u91cd\u7f3a\u5931\uff0c\u8feb\u5207\u9700\u8981\u5efa\u7acb\u7ed3\u6784\u5316\u4f26\u7406\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86\u8be5\u65b0\u5174\u6559\u80b2\u9886\u57df\u7684\u7814\u7a76\u673a\u9047\u548c\u6311\u6218\u3002"}}
{"id": "2509.14139", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.14139", "abs": "https://arxiv.org/abs/2509.14139", "authors": ["V\u00edctor Mayoral-Vilches"], "title": "Cybersecurity AI: Humanoid Robots as Attack Vectors", "comment": null, "summary": "We present a systematic security assessment of the Unitree G1 humanoid\nshowing it operates simultaneously as a covert surveillance node and can be\npurposed as an active cyber operations platform. Partial reverse engineering of\nUnitree's proprietary FMX encryption reveal a static Blowfish-ECB layer and a\npredictable LCG mask-enabled inspection of the system's otherwise sophisticated\nsecurity architecture, the most mature we have observed in commercial robotics.\nTwo empirical case studies expose the critical risk of this humanoid robot: (a)\nthe robot functions as a trojan horse, continuously exfiltrating multi-modal\nsensor and service-state telemetry to 43.175.228.18:17883 and\n43.175.229.18:17883 every 300 seconds without operator notice, creating\nviolations of GDPR Articles 6 and 13; (b) a resident Cybersecurity AI (CAI)\nagent can pivot from reconnaissance to offensive preparation against any\ntarget, such as the manufacturer's cloud control plane, demonstrating\nescalation from passive monitoring to active counter-operations. These findings\nargue for adaptive CAI-powered defenses as humanoids move into critical\ninfrastructure, contributing the empirical evidence needed to shape future\nsecurity standards for physical-cyber convergence systems.", "AI": {"tldr": "\u5bf9Unitree G1\u4eba\u5f62\u673a\u5668\u4eba\u7684\u5b89\u5168\u8bc4\u4f30\u663e\u793a\u5176\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u53ef\u4f5c\u4e3a\u9690\u853d\u76d1\u63a7\u8282\u70b9\u548c\u7f51\u7edc\u653b\u51fb\u5e73\u53f0\uff0c\u5b58\u5728\u6570\u636e\u6cc4\u9732\u548c\u4e3b\u52a8\u653b\u51fb\u98ce\u9669", "motivation": "\u968f\u7740\u4eba\u5f62\u673a\u5668\u4eba\u8fdb\u5165\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u9886\u57df\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u5b89\u5168\u98ce\u9669\uff0c\u4e3a\u7269\u7406-\u7f51\u7edc\u878d\u5408\u7cfb\u7edf\u7684\u5b89\u5168\u6807\u51c6\u5236\u5b9a\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e", "method": "\u901a\u8fc7\u9006\u5411\u5de5\u7a0b\u5206\u6790Unitree\u4e13\u6709FMX\u52a0\u5bc6\u534f\u8bae\uff0c\u53d1\u73b0\u9759\u6001Blowfish-ECB\u5c42\u548c\u53ef\u9884\u6d4bLCG\u63a9\u7801\uff0c\u5e76\u8fdb\u884c\u4e24\u4e2a\u5b9e\u8bc1\u6848\u4f8b\u7814\u7a76", "result": "\u53d1\u73b0\u673a\u5668\u4eba\u4f5c\u4e3a\u7279\u6d1b\u4f0a\u6728\u9a6c\u6bcf300\u79d2\u5411\u7279\u5b9aIP\u5730\u5740\u6cc4\u9732\u591a\u6a21\u6001\u4f20\u611f\u5668\u6570\u636e\uff0c\u8fdd\u53cdGDPR\uff1b\u5185\u7f6e\u7f51\u7edc\u5b89\u5168AI\u4ee3\u7406\u53ef\u4ece\u4fa6\u5bdf\u5347\u7ea7\u4e3a\u4e3b\u52a8\u653b\u51fb", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u4eba\u5f62\u673a\u5668\u4eba\u8fdb\u5165\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u65f6\u9700\u8981\u91c7\u7528\u81ea\u9002\u5e94\u7f51\u7edc\u5b89\u5168AI\u9632\u5fa1\u673a\u5236\uff0c\u4e3a\u672a\u6765\u7269\u7406-\u7f51\u7edc\u878d\u5408\u7cfb\u7edf\u7684\u5b89\u5168\u6807\u51c6\u5236\u5b9a\u63d0\u4f9b\u4e86\u91cd\u8981\u5b9e\u8bc1\u8bc1\u636e"}}
{"id": "2509.13450", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13450", "abs": "https://arxiv.org/abs/2509.13450", "authors": ["Vincent Siu", "Nicholas Crispino", "David Park", "Nathan W. Henry", "Zhun Wang", "Yang Liu", "Dawn Song", "Chenguang Wang"], "title": "SteeringControl: Holistic Evaluation of Alignment Steering in LLMs", "comment": null, "summary": "We introduce SteeringControl, a benchmark for evaluating representation\nsteering methods across core alignment objectives--bias, harmful generation,\nand hallucination--and their effects on secondary behaviors such as sycophancy\nand commonsense morality. While prior alignment work often highlights\ntruthfulness or reasoning ability to demonstrate the side effects of\nrepresentation steering, we find there are many unexplored tradeoffs not yet\nunderstood in a systematic way. We collect a dataset of safety-relevant primary\nand secondary behaviors to evaluate steering effectiveness and behavioral\nentanglement centered around five popular steering methods. To enable this, we\ncraft a modular steering framework based on unique components that serve as the\nbuilding blocks of many existing methods. Our results on Qwen-2.5-7B and\nLlama-3.1-8B find that strong steering performance is dependent on the specific\ncombination of steering method, model, and targeted behavior, and that severe\nconcept entanglement can result from poor combinations of these three as well.\nWe release our code here:\nhttps://github.com/wang-research-lab/SteeringControl.git.", "AI": {"tldr": "SteeringControl\u662f\u4e00\u4e2a\u8bc4\u4f30\u8868\u793a\u5f15\u5bfc\u65b9\u6cd5\u7684\u57fa\u51c6\uff0c\u91cd\u70b9\u5173\u6ce8\u504f\u89c1\u3001\u6709\u5bb3\u751f\u6210\u548c\u5e7b\u89c9\u7b49\u6838\u5fc3\u5bf9\u9f50\u76ee\u6807\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u65b9\u6cd5\u5bf9\u6b21\u8981\u884c\u4e3a\uff08\u5982\u5949\u627f\u548c\u5e38\u8bc6\u9053\u5fb7\uff09\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u9f50\u5de5\u4f5c\u5f80\u5f80\u53ea\u5173\u6ce8\u771f\u5b9e\u6027\u6216\u63a8\u7406\u80fd\u529b\u6765\u5c55\u793a\u8868\u793a\u5f15\u5bfc\u7684\u526f\u4f5c\u7528\uff0c\u4f46\u8bb8\u591a\u6743\u8861\u5173\u7cfb\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u6027\u7684\u7406\u89e3\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u5f15\u5bfc\u6846\u67b6\uff0c\u57fa\u4e8e\u4e94\u4e2a\u6d41\u884c\u5f15\u5bfc\u65b9\u6cd5\u7684\u72ec\u7279\u7ec4\u4ef6\uff0c\u6536\u96c6\u4e86\u5b89\u5168\u76f8\u5173\u7684\u4e3b\u8981\u548c\u6b21\u8981\u884c\u4e3a\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u5f15\u5bfc\u6548\u679c\u548c\u884c\u4e3a\u7ea0\u7f20\u3002", "result": "\u5728Qwen-2.5-7B\u548cLlama-3.1-8B\u4e0a\u7684\u7ed3\u679c\u663e\u793a\uff0c\u5f3a\u5f15\u5bfc\u6027\u80fd\u53d6\u51b3\u4e8e\u5f15\u5bfc\u65b9\u6cd5\u3001\u6a21\u578b\u548c\u76ee\u6807\u884c\u4e3a\u7684\u7279\u5b9a\u7ec4\u5408\uff0c\u4e0d\u826f\u7ec4\u5408\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u6982\u5ff5\u7ea0\u7f20\u3002", "conclusion": "\u8868\u793a\u5f15\u5bfc\u7684\u6548\u679c\u5177\u6709\u9ad8\u5ea6\u4f9d\u8d56\u6027\uff0c\u9700\u8981\u4ed4\u7ec6\u9009\u62e9\u65b9\u6cd5\u3001\u6a21\u578b\u548c\u76ee\u6807\u884c\u4e3a\u7684\u7ec4\u5408\uff0c\u4ee5\u907f\u514d\u4e0d\u826f\u7684\u526f\u4f5c\u7528\u548c\u6982\u5ff5\u7ea0\u7f20\u3002"}}
{"id": "2509.13941", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13941", "abs": "https://arxiv.org/abs/2509.13941", "authors": ["Simiao Liu", "Fang Liu", "Liehao Li", "Xin Tan", "Yinghao Zhu", "Xiaoli Lian", "Li Zhang"], "title": "An Empirical Study on Failures in Automated Issue Solving", "comment": null, "summary": "Automated issue solving seeks to autonomously identify and repair defective\ncode snippets across an entire codebase. SWE-Bench has emerged as the most\nwidely adopted benchmark for evaluating progress in this area. While LLM-based\nagentic tools show great promise, they still fail on a substantial portion of\ntasks. Moreover, current evaluations primarily report aggregate issue-solving\nrates, which obscure the underlying causes of success and failure, making it\nchallenging to diagnose model weaknesses or guide targeted improvements. To\nbridge this gap, we first analyze the performance and efficiency of three SOTA\ntools, spanning both pipeline-based and agentic architectures, in automated\nissue solving tasks of SWE-Bench-Verified under varying task characteristics.\nFurthermore, to move from high-level performance metrics to underlying cause\nanalysis, we conducted a systematic manual analysis of 150 failed instances.\nFrom this analysis, we developed a comprehensive taxonomy of failure modes\ncomprising 3 primary phases, 9 main categories, and 25 fine-grained\nsubcategories. Then we systematically analyze the distribution of the\nidentified failure modes, the results reveal distinct failure fingerprints\nbetween the two architectural paradigms, with the majority of agentic failures\nstemming from flawed reasoning and cognitive deadlocks. Motivated by these\ninsights, we propose a collaborative Expert-Executor framework. It introduces a\nsupervisory Expert agent tasked with providing strategic oversight and\ncourse-correction for a primary Executor agent. This architecture is designed\nto correct flawed reasoning and break the cognitive deadlocks that frequently\nlead to failure. Experiments show that our framework solves 22.2% of previously\nintractable issues for a leading single agent. These findings pave the way for\nbuilding more robust agents through diagnostic evaluation and collaborative\ndesign.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u5206\u6790SWE-Bench\u81ea\u52a8\u4fee\u590d\u4efb\u52a1\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b3\u4e2a\u4e3b\u8981\u9636\u6bb5\u30019\u4e2a\u4e3b\u7c7b\u548c25\u4e2a\u5b50\u7c7b\u7684\u5931\u8d25\u5206\u7c7b\u7cfb\u7edf\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e13\u5bb6-\u6267\u884c\u8005\u534f\u4f5c\u6846\u67b6\u6765\u6539\u5584\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u4fee\u590d\u7cfb\u7edf\u5728SWE-Bench\u4e0a\u4ecd\u6709\u5f88\u9ad8\u5931\u8d25\u7387\uff0c\u4f46\u8054\u7cfb\u6027\u80fd\u6307\u6807\u9690\u85cf\u4e86\u5931\u8d25\u6839\u672c\u539f\u56e0\uff0c\u5f71\u54cd\u4e86\u6a21\u578b\u5f0a\u75b2\u5f0a\u8bca\u65ad\u548c\u6709\u9488\u5bf9\u6027\u6539\u8fdb\u3002", "method": "\u9996\u5148\u5206\u6790\u4e86\u4e09\u79cd\u72b6\u6001\u4e0b\u7684\u4ee3\u7406\u5de5\u5177\u5728SWE-Bench-Verified\u4e2d\u7684\u8868\u73b0\uff0c\u7136\u540e\u901a\u8fc7\u624b\u52a8\u5206\u6790150\u4e2a\u5931\u8d25\u6848\u4f8b\u6784\u5efa\u4e86\u8be6\u7ec6\u7684\u5931\u8d25\u6a21\u5f0f\u5206\u7c7b\u7cfb\u7edf\uff0c\u6700\u540e\u8bbe\u8ba1\u4e86\u4e13\u5bb6-\u6267\u884c\u8005\u534f\u4f5c\u6846\u67b6\u6765\u89e3\u51b3\u5173\u952e\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u65b0\u6846\u67b6\u80fd\u591f\u89e3\u51b322.2%\u4e4b\u524d\u5355\u4e2a\u4ee3\u7406\u65e0\u6cd5\u5904\u7406\u7684\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u66f4\u7a33\u5065\u7684\u81ea\u52a8\u4fee\u590d\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "conclusion": "\u901a\u8fc7\u8be6\u7ec6\u7684\u5931\u8d25\u6a21\u5f0f\u5206\u6790\u548c\u534f\u4f5c\u5f0f\u6846\u67b6\u8bbe\u8ba1\uff0c\u8fd9\u9879\u7814\u7a76\u4e3a\u63d0\u5347\u81ea\u52a8\u4ee3\u7801\u4fee\u590d\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u548c\u65b9\u6cd5\u3002"}}
{"id": "2509.13547", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13547", "abs": "https://arxiv.org/abs/2509.13547", "authors": ["Harper Reed", "Michael Sugimura", "Angelo Zangari"], "title": "AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving", "comment": "16 pages, 5 tables", "summary": "We investigate whether giving LLM agents the collaborative tools and autonomy\nthat humans naturally use for problem solving can improve their performance. We\nequip Claude Code agents with MCP-based social media and journaling tools and\nallow them to use these tools as they see fit. Across 34 Aider Polyglot Python\nprogramming challenges, collaborative tools substantially improve performance\non the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and\n12-38% faster completion than baseline agents. Effects on the full challenge\nset are mixed, suggesting these tools act as performance enhancers when\nadditional reasoning scaffolding is most needed. Surprisingly, Different models\nnaturally adopted distinct collaborative strategies without explicit\ninstruction. Sonnet 3.7 engaged broadly across tools and benefited from\narticulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,\nleaning on journal-based semantic search when problems were genuinely\ndifficult. This mirrors how human developers adjust collaboration based on\nexpertise and task complexity. Behavioral analysis shows agents prefer writing\nover reading by about 2-9x, indicating that structured articulation drives much\nof the improvement rather than information access alone. Overall, AI agents can\nsystematically benefit from human-inspired collaboration tools at the edge of\ntheir capabilities, pointing to adaptive collaborative interfaces as reasoning\nenhancers rather than universal efficiency boosts.", "AI": {"tldr": "\u4e3aLLM\u4ee3\u7406\u63d0\u4f9b\u4eba\u7c7b\u81ea\u7136\u4f7f\u7528\u7684\u534f\u4f5c\u5de5\u5177\u548c\u81ea\u4e3b\u6743\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5176\u5728\u56f0\u96be\u7f16\u7a0b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u6700\u9700\u8981\u989d\u5916\u63a8\u7406\u652f\u6301\u7684\u60c5\u51b5\u4e0b\u3002", "motivation": "\u7814\u7a76\u662f\u5426\u901a\u8fc7\u8d4b\u4e88LLM\u4ee3\u7406\u4eba\u7c7b\u81ea\u7136\u4f7f\u7528\u7684\u534f\u4f5c\u5de5\u5177\u548c\u81ea\u4e3b\u6743\uff0c\u80fd\u591f\u6539\u5584\u5176\u5728\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u4e3aClaude Code\u4ee3\u7406\u914d\u5907\u57fa\u4e8eMCP\u7684\u793e\u4ea4\u5a92\u4f53\u548c\u65e5\u5fd7\u5de5\u5177\uff0c\u5141\u8bb8\u5b83\u4eec\u81ea\u4e3b\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\uff0c\u5e76\u572834\u4e2aAider\u591a\u8bed\u8a00Python\u7f16\u7a0b\u6311\u6218\u4e2d\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u534f\u4f5c\u5de5\u5177\u5728\u6700\u5177\u6311\u6218\u6027\u7684\u95ee\u9898\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff1a\u6210\u672c\u964d\u4f4e15-40%\uff0c\u8f6e\u6b21\u51cf\u5c1112-27%\uff0c\u5b8c\u6210\u901f\u5ea6\u63d0\u9ad812-38%\u3002\u4e0d\u540c\u6a21\u578b\u81ea\u7136\u91c7\u7528\u4e0d\u540c\u7684\u534f\u4f5c\u7b56\u7565\uff0c\u4ee3\u7406\u504f\u597d\u5199\u4f5c\u800c\u975e\u9605\u8bfb\uff082-9\u500d\uff09\uff0c\u8868\u660e\u7ed3\u6784\u5316\u8868\u8fbe\u662f\u6539\u8fdb\u7684\u4e3b\u8981\u9a71\u52a8\u529b\u3002", "conclusion": "AI\u4ee3\u7406\u53ef\u4ee5\u5728\u5176\u80fd\u529b\u8fb9\u7f18\u4ece\u4eba\u7c7b\u542f\u53d1\u7684\u534f\u4f5c\u5de5\u5177\u4e2d\u7cfb\u7edf\u6027\u5730\u53d7\u76ca\uff0c\u8fd9\u8868\u660e\u81ea\u9002\u5e94\u534f\u4f5c\u754c\u9762\u53ef\u4ee5\u4f5c\u4e3a\u63a8\u7406\u589e\u5f3a\u5668\uff0c\u800c\u975e\u666e\u904d\u6548\u7387\u63d0\u5347\u5de5\u5177\u3002"}}
{"id": "2509.13942", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13942", "abs": "https://arxiv.org/abs/2509.13942", "authors": ["Duc Minh Ha", "Phu Trac Kien", "Tho Quan", "Anh Nguyen-Duc"], "title": "Evaluating Classical Software Process Models as Coordination Mechanisms for LLM-Based Software Generation", "comment": null, "summary": "[Background] Large Language Model (LLM)-based multi-agent systems (MAS) are\ntransforming software development by enabling autonomous collaboration.\nClassical software processes such asWaterfall, V-Model, and Agile offer\nstructured coordination patterns that can be repurposed to guide these agent\ninteractions. [Aims] This study explores how traditional software development\nprocesses can be adapted as coordination scaffolds for LLM based MAS and\nexamines their impact on code quality, cost, and productivity. [Method] We\nexecuted 11 diverse software projects under three process models and four GPT\nvariants, totaling 132 runs. Each output was evaluated using standardized\nmetrics for size (files, LOC), cost (execution time, token usage), and quality\n(code smells, AI- and human detected bugs). [Results] Both process model and\nLLM choice significantly affected system performance. Waterfall was most\nefficient, V-Model produced the most verbose code, and Agile achieved the\nhighest code quality, albeit at higher computational cost. [Conclusions]\nClassical software processes can be effectively instantiated in LLM-based MAS,\nbut each entails trade-offs across quality, cost, and adaptability. Process\nselection should reflect project goals, whether prioritizing efficiency,\nrobustness, or structured validation.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5\u4e86\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u6a21\u578b\uff08\u6c34\u6da9\u3001V\u6a21\u578b\u3001\u7075\u6d3b\uff09\u5728LLM\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u6548\u679c\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u5728\u4ee3\u7801\u8d28\u91cf\u3001\u6210\u672c\u548c\u6548\u7387\u65b9\u9762\u5404\u6709\u4f18\u52bf", "motivation": "\u5229\u7528\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u7684\u7ed3\u6784\u5316\u534f\u8c03\u6a21\u5f0f\u6765\u6307\u5bfcLLM\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u81ea\u4e3b\u534f\u4f5c\uff0c\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\u548c\u751f\u4ea7\u529b", "method": "\u6267\u884c11\u4e2a\u591a\u6837\u5316\u8f6f\u4ef6\u9879\u76ee\uff0c\u6d4b\u8bd5\u4e09\u79cd\u8fc7\u7a0b\u6a21\u578b\u548c\u56db\u79cdGPT\u53d8\u4f53\uff0c\u5171112\u6b21\u8fd0\u884c\u3002\u4f7f\u7528\u6807\u51c6\u5316\u6307\u6807\u8bc4\u4f30\u4ee3\u7801\u89c4\u6a21\u3001\u6210\u672c\u548c\u8d28\u91cf", "result": "\u8fc7\u7a0b\u6a21\u578b\u548cLLM\u9009\u62e9\u90fd\u663e\u8457\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\u3002\u6c34\u6da9\u6a21\u578b\u6548\u7387\u6700\u9ad8\uff0cV\u6a21\u578b\u4ea7\u751f\u6700\u5197\u957f\u4ee3\u7801\uff0c\u7075\u6d3b\u6a21\u578b\u4ee3\u7801\u8d28\u91cf\u6700\u9ad8\u4f46\u8ba1\u7b97\u6210\u672c\u66f4\u9ad8", "conclusion": "\u4f20\u7edf\u8f6f\u4ef6\u8fc7\u7a0b\u53ef\u6709\u6548\u5e94\u7528\u4e8eLLM\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u4f46\u5404\u6709\u7279\u70b9\u3002\u9009\u62e9\u5e94\u6839\u636e\u9879\u76ee\u76ee\u6807\u8003\u8651\u6548\u7387\u3001\u7a33\u5065\u6027\u6216\u9a8c\u8bc1\u9700\u6c42"}}
{"id": "2509.13570", "categories": ["cs.AI", "math.HO", "Primary: 97U50, Secondary: 97U70, 97D40, 97D60, 97E50, 97H40"], "pdf": "https://arxiv.org/pdf/2509.13570", "abs": "https://arxiv.org/abs/2509.13570", "authors": ["Hannah Klawa", "Shraddha Rajpal", "Cigole Thomas"], "title": "Gen AI in Proof-based Math Courses: A Pilot Study", "comment": "35 pages, 6 figures, Comments welcome!", "summary": "With the rapid rise of generative AI in higher education and the\nunreliability of current AI detection tools, developing policies that encourage\nstudent learning and critical thinking has become increasingly important. This\nstudy examines student use and perceptions of generative AI across three\nproof-based undergraduate mathematics courses: a first-semester abstract\nalgebra course, a topology course and a second-semester abstract algebra\ncourse. In each case, course policy permitted some use of generative AI.\nDrawing on survey responses and student interviews, we analyze how students\nengaged with AI tools, their perceptions of generative AI's usefulness and\nlimitations, and what implications these perceptions hold for teaching\nproof-based mathematics. We conclude by discussing future considerations for\nintegrating generative AI into proof-based mathematics instruction.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5728\u8bc1\u660e\u57fa\u7840\u6570\u5b66\u8bfe\u7a0b\u4e2d\u5b66\u751f\u4f7f\u7528\u751f\u6210\u5f0fAI\u7684\u60c5\u51b5\u548c\u89c2\u70b9\uff0c\u5206\u6790\u4e86AI\u5de5\u5177\u7684\u4f7f\u7528\u65b9\u5f0f\u3001\u5b66\u751f\u5bf9\u5176\u6709\u7528\u6027\u548c\u5c40\u9650\u6027\u7684\u770b\u6cd5\uff0c\u4ee5\u53ca\u5bf9\u6570\u5b66\u6559\u5b66\u7684\u542f\u793a\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u7684\u5feb\u901f\u5174\u8d77\u548c\u5f53\u524dAI\u68c0\u6d4b\u5de5\u5177\u7684\u4e0d\u53ef\u9760\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9f13\u52b1\u5b66\u751f\u5b66\u4e60\u548c\u627f\u521b\u6027\u601d\u7ef4\u7684\u653f\u7b56\u3002", "method": "\u7814\u7a76\u5728\u4e09\u95e8\u8bc1\u660e\u57fa\u7840\u7684\u672c\u79d1\u6570\u5b66\u8bfe\u7a0b\u4e2d\u8fdb\u884c\uff08\u9996\u5b66\u671f\u62bd\u8c61\u4ee3\u6570\u3001\u62d3\u6251\u5b66\u548c\u7b2c\u4e8c\u5b66\u671f\u62bd\u8c61\u4ee3\u6570\uff09\uff0c\u8bfe\u7a0b\u653f\u7b56\u5141\u8bb8\u67d0\u4e9bAI\u4f7f\u7528\u3002\u901a\u8fc7\u8c03\u67e5\u56de\u590d\u548c\u5b66\u751f\u8bbf\u8c0d\u6536\u96c6\u6570\u636e\u3002", "result": "\u5206\u6790\u4e86\u5b66\u751f\u5982\u4f55\u4f7f\u7528AI\u5de5\u5177\u3001\u4ed6\u4eec\u5bf9\u751f\u6210\u5f0fAI\u6709\u7528\u6027\u548c\u5c40\u9650\u6027\u7684\u770b\u6cd5\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u89c2\u70b9\u5bf9\u8bc1\u660e\u57fa\u7840\u6570\u5b66\u6559\u5b66\u7684\u542f\u793a\u3002", "conclusion": "\u6700\u540e\u8ba8\u8bba\u4e86\u5c06\u751f\u6210\u5f0fAI\u6574\u5408\u5230\u8bc1\u660e\u57fa\u7840\u6570\u5b66\u6559\u5b66\u4e2d\u7684\u672a\u6765\u8003\u8651\u56e0\u7d20\u3002"}}
{"id": "2509.14093", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.14093", "abs": "https://arxiv.org/abs/2509.14093", "authors": ["Kerui Huang", "Shuhan Liu", "Xing Hu", "Tongtong Xu", "Lingfeng Bao", "Xin Xia"], "title": "Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework", "comment": null, "summary": "Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by\nprompting intermediate steps, improving accuracy and robustness in arithmetic,\nlogic, and commonsense tasks. However, this benefit comes with high\ncomputational costs: longer outputs increase latency, memory usage, and\nKV-cache demands. These issues are especially critical in software engineering\ntasks where concise and deterministic outputs are required. To investigate\nthese trade-offs, we conduct an empirical study based on code generation\nbenchmarks. The results reveal that longer CoT does not always help. Excessive\nreasoning often causes truncation, accuracy drops, and latency up to five times\nhigher, with failed outputs consistently longer than successful ones. These\nfindings challenge the assumption that longer reasoning is inherently better\nand highlight the need for adaptive CoT control. Motivated by this, we propose\nSEER (Self-Enhancing Efficient Reasoning), an adaptive framework that\ncompresses CoT while preserving accuracy. SEER combines Best-of-N sampling with\ntask-aware adaptive filtering, dynamically adjusting thresholds based on\npre-inference outputs to reduce verbosity and computational overhead. We then\nevaluate SEER on three software engineering tasks and one math task. On\naverage, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,\nand eliminates most infinite loops. These results demonstrate SEER as a\npractical method to make CoT-enhanced LLMs more efficient and robust, even\nunder resource constraints.", "AI": {"tldr": "\u601d\u7ef4\u94fe\u63a8\u7406\u867d\u7136\u63d0\u5347LLM\u6027\u80fd\u4f46\u5e26\u6765\u9ad8\u6602\u8ba1\u7b97\u6210\u672c\uff0c\u7814\u7a76\u53d1\u73b0\u8fc7\u957f\u63a8\u7406\u53cd\u800c\u6709\u5bb3\u3002SEER\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u538b\u7f29\u601d\u7ef4\u94fe\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u601d\u7ef4\u94fe\u63a8\u7406\u867d\u7136\u80fd\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7b97\u672f\u3001\u903b\u8f91\u548c\u5e38\u8bc6\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4f46\u4f1a\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u6025\u5267\u589e\u52a0\uff08\u5ef6\u8fdf\u3001\u5185\u5b58\u4f7f\u7528\u548cKV\u7f13\u5b58\u9700\u6c42\uff09\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7b80\u6d01\u786e\u5b9a\u6027\u8f93\u51fa\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u3002\u9700\u8981\u7814\u7a76\u8fd9\u79cd\u6743\u8861\u5e76\u627e\u5230\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSEER\uff08\u81ea\u589e\u5f3a\u9ad8\u6548\u63a8\u7406\uff09\u6846\u67b6\uff0c\u7ed3\u5408Best-of-N\u91c7\u6837\u548c\u4efb\u52a1\u611f\u77e5\u81ea\u9002\u5e94\u8fc7\u6ee4\uff0c\u901a\u8fc7\u9884\u63a8\u7406\u8f93\u51fa\u52a8\u6001\u8c03\u6574\u9608\u503c\u6765\u538b\u7f29\u601d\u7ef4\u94fe\uff0c\u51cf\u5c11\u5197\u4f59\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u4e09\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u548c\u4e00\u4e2a\u6570\u5b66\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cSEER\u5e73\u5747\u7f29\u77ed\u601d\u7ef4\u94fe42.1%\uff0c\u901a\u8fc7\u51cf\u5c11\u622a\u65ad\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u6d88\u9664\u4e86\u5927\u591a\u6570\u65e0\u9650\u5faa\u73af\u3002\u8ba1\u7b97\u5ef6\u8fdf\u964d\u4f4e\u6700\u591a5\u500d\u3002", "conclusion": "SEER\u662f\u4e00\u79cd\u5b9e\u7528\u65b9\u6cd5\uff0c\u80fd\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u4f7f\u601d\u7ef4\u94fe\u589e\u5f3a\u7684LLM\u66f4\u52a0\u9ad8\u6548\u548c\u9c81\u68d2\uff0c\u6311\u6218\u4e86\"\u63a8\u7406\u8d8a\u957f\u8d8a\u597d\"\u7684\u5047\u8bbe\uff0c\u8bc1\u660e\u4e86\u81ea\u9002\u5e94\u601d\u7ef4\u94fe\u63a7\u5236\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.13588", "categories": ["cs.AI", "cs.CE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.13588", "abs": "https://arxiv.org/abs/2509.13588", "authors": ["Xuan Liu", "Haoyang Shang", "Haojian Jin"], "title": "Programmable Cognitive Bias in Social Agents", "comment": null, "summary": "This paper introduces CoBRA, a novel toolkit for systematically specifying\nagent behavior in LLM-based social simulation. We found that conventional\napproaches that specify agent behaviors through implicit natural language\ndescriptions cannot yield consistent behaviors across models, and the produced\nagent behaviors do not capture the nuances of the descriptions. In contrast,\nCoBRA presents a new approach to program agents' cognitive biases explicitly,\nby grounding agents' expected behaviors using classic social science\nexperiments. CoBRA has two components: (1) Cognitive Bias Index that measures\nthe cognitive bias of a social agent, by quantifying the agent's reactions in a\nset of validated classical social science experiments; (2) Behavioral\nRegulation Engine that aligns the agent's behavior to demonstrate controlled\ncognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and\ntechnical benchmarks. Our results suggest that CoBRA can precisely program the\ncognitive bias demonstrated in a social agent in a model-agnostic manner.", "AI": {"tldr": "CoBRA\u662f\u4e00\u4e2a\u7528\u4e8e\u5728\u57fa\u4e8eLLM\u7684\u793e\u4f1a\u6a21\u62df\u4e2d\u7cfb\u7edf\u5316\u6307\u5b9a\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u65b0\u5de5\u5177\u5305\uff0c\u901a\u8fc7\u663e\u5f0f\u7f16\u7a0b\u8ba4\u77e5\u504f\u89c1\u6765\u89e3\u51b3\u4f20\u7edf\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u65b9\u6cd5\u7684\u4e00\u81f4\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u9690\u5f0f\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u6765\u6307\u5b9a\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u4f46\u53d1\u73b0\u8fd9\u79cd\u65b9\u6cd5\u65e0\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u4ea7\u751f\u4e00\u81f4\u884c\u4e3a\uff0c\u4e14\u65e0\u6cd5\u6355\u6349\u63cf\u8ff0\u7684\u7ec6\u5fae\u5dee\u522b\u3002", "method": "CoBRA\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1a\u8ba4\u77e5\u504f\u89c1\u6307\u6570\uff08\u901a\u8fc7\u7ecf\u5178\u793e\u4f1a\u79d1\u5b66\u5b9e\u9a8c\u91cf\u5316\u667a\u80fd\u4f53\u53cd\u5e94\uff09\u548c\u884c\u4e3a\u8c03\u8282\u5f15\u64ce\uff08\u5c06\u667a\u80fd\u4f53\u884c\u4e3a\u4e0e\u53d7\u63a7\u8ba4\u77e5\u504f\u89c1\u5bf9\u9f50\uff09\uff0c\u901a\u8fc7\u7ecf\u5178\u793e\u4f1a\u79d1\u5b66\u5b9e\u9a8c\u6765\u660e\u786e\u7f16\u7a0b\u667a\u80fd\u4f53\u7684\u8ba4\u77e5\u504f\u89c1\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0cCoBRA\u80fd\u591f\u4ee5\u6a21\u578b\u65e0\u5173\u7684\u65b9\u5f0f\u7cbe\u786e\u7f16\u7a0b\u793e\u4ea4\u667a\u80fd\u4f53\u4e2d\u5c55\u793a\u7684\u8ba4\u77e5\u504f\u89c1\u3002", "conclusion": "CoBRA\u4f5c\u4e3a\u4e00\u4e2aHCI\u5de5\u5177\u5305\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u3001\u53ef\u63a7\u5236\u7684\u65b9\u6cd5\u6765\u7f16\u7a0bLLM-based\u793e\u4ea4\u6a21\u62df\u4e2d\u7684\u667a\u80fd\u4f53\u8ba4\u77e5\u504f\u89c1\u884c\u4e3a\u3002"}}
{"id": "2509.13704", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13704", "abs": "https://arxiv.org/abs/2509.13704", "authors": ["Liangtao Lin", "Zhaomeng Zhu", "Tianwei Zhang", "Yonggang Wen"], "title": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management", "comment": null, "summary": "Mission-critical industrial infrastructure, such as data centers,\nincreasingly depends on complex management software. Its operations, however,\npose significant challenges due to the escalating system complexity,\nmulti-vendor integration, and a shortage of expert operators. While Robotic\nProcess Automation (RPA) offers partial automation through handcrafted scripts,\nit suffers from limited flexibility and high maintenance costs. Recent advances\nin Large Language Model (LLM)-based graphical user interface (GUI) agents have\nenabled more flexible automation, yet these general-purpose agents face five\ncritical challenges when applied to industrial management, including unfamiliar\nelement understanding, precision and efficiency, state localization, deployment\nconstraints, and safety requirements. To address these issues, we propose\nInfraMind, a novel exploration-based GUI agentic framework specifically\ntailored for industrial management systems. InfraMind integrates five\ninnovative modules to systematically resolve different challenges in industrial\nmanagement: (1) systematic search-based exploration with virtual machine\nsnapshots for autonomous understanding of complex GUIs; (2) memory-driven\nplanning to ensure high-precision and efficient task execution; (3) advanced\nstate identification for robust localization in hierarchical interfaces; (4)\nstructured knowledge distillation for efficient deployment with lightweight\nmodels; and (5) comprehensive, multi-layered safety mechanisms to safeguard\nsensitive operations. Extensive experiments on both open-source and commercial\nDCIM platforms demonstrate that our approach consistently outperforms existing\nframeworks in terms of task success rate and operational efficiency, providing\na rigorous and scalable solution for industrial management automation.", "AI": {"tldr": "InfraMind\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u5de5\u4e1a\u7ba1\u7406\u7cfb\u7edf\u8bbe\u8ba1\u7684\u63a2\u7d22\u5f0fGUI\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u4e2a\u521b\u65b0\u6a21\u5757\u89e3\u51b3LLM-based GUI\u4ee3\u7406\u5728\u5de5\u4e1a\u7ba1\u7406\u4e2d\u7684\u4e94\u5927\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\u548c\u64cd\u4f5c\u6548\u7387\u3002", "motivation": "\u5de5\u4e1a\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u9762\u4e34\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\u3001\u591a\u4f9b\u5e94\u5546\u96c6\u6210\u548c\u4e13\u5bb6\u64cd\u4f5c\u5458\u77ed\u7f3a\u7b49\u6311\u6218\u3002\u4f20\u7edfRPA\u81ea\u52a8\u5316\u7075\u6d3b\u6027\u6709\u9650\u4e14\u7ef4\u62a4\u6210\u672c\u9ad8\uff0c\u800c\u73b0\u6709\u7684LLM-based GUI\u4ee3\u7406\u5728\u5de5\u4e1a\u7ba1\u7406\u5e94\u7528\u4e2d\u5b58\u5728\u5143\u7d20\u7406\u89e3\u4e0d\u719f\u6089\u3001\u7cbe\u5ea6\u6548\u7387\u4f4e\u3001\u72b6\u6001\u5b9a\u4f4d\u56f0\u96be\u3001\u90e8\u7f72\u7ea6\u675f\u548c\u5b89\u5168\u8981\u6c42\u7b49\u4e94\u5927\u95ee\u9898\u3002", "method": "\u63d0\u51faInfraMind\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a(1)\u57fa\u4e8e\u7cfb\u7edf\u641c\u7d22\u63a2\u7d22\u548c\u865a\u62df\u673a\u5feb\u7167\u7684\u81ea\u4e3bGUI\u7406\u89e3\uff1b(2)\u5185\u5b58\u9a71\u52a8\u89c4\u5212\u786e\u4fdd\u9ad8\u7cbe\u5ea6\u9ad8\u6548\u4efb\u52a1\u6267\u884c\uff1b(3)\u9ad8\u7ea7\u72b6\u6001\u8bc6\u522b\u7528\u4e8e\u5206\u5c42\u754c\u9762\u7684\u9c81\u68d2\u5b9a\u4f4d\uff1b(4)\u7ed3\u6784\u5316\u77e5\u8bc6\u84b8\u998f\u5b9e\u73b0\u8f7b\u91cf\u6a21\u578b\u9ad8\u6548\u90e8\u7f72\uff1b(5)\u591a\u5c42\u5b89\u5168\u673a\u5236\u4fdd\u62a4\u654f\u611f\u64cd\u4f5c\u3002", "result": "\u5728\u5f00\u6e90\u548c\u5546\u4e1aDCIM\u5e73\u53f0\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4efb\u52a1\u6210\u529f\u7387\u548c\u64cd\u4f5c\u6548\u7387\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002", "conclusion": "InfraMind\u4e3a\u5de5\u4e1a\u7ba1\u7406\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u8c28\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM-based GUI\u4ee3\u7406\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2509.13615", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13615", "abs": "https://arxiv.org/abs/2509.13615", "authors": ["Zongru Wu", "Rui Mao", "Zhiyuan Tian", "Pengzhou Cheng", "Tianjie Ju", "Zheng Wu", "Lingzhong Dong", "Haiyue Sheng", "Zhuosheng Zhang", "Gongshen Liu"], "title": "See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles", "comment": null, "summary": "The advent of multimodal agents facilitates effective interaction within\ngraphical user interface (GUI), especially in ubiquitous GUI control. However,\ntheir inability to reliably execute toggle control instructions remains a key\nbottleneck. To investigate this, we construct a state control benchmark with\nbinary toggle instructions from public datasets. Evaluations of existing agents\ndemonstrate their unreliability, particularly when the current toggle state\nalready matches the desired state. To address the challenge, we propose\nState-aware Reasoning (StaR), a training method that teaches agents to perceive\nthe current toggle state, analyze the desired state from the instruction, and\nact accordingly. Experiments on three multimodal agents demonstrate that StaR\ncan improve toggle instruction execution accuracy by over 30\\%. Further\nevaluations on three public benchmarks show that StaR also enhances general\ntask performance. Finally, evaluations on a dynamic environment highlight the\npotential of StaR for real-world applications. Code, benchmark, and\nStaR-enhanced agents are available at https://github.com/ZrW00/StaR.", "AI": {"tldr": "\u63d0\u51faState-aware Reasoning (StaR)\u8bad\u7ec3\u65b9\u6cd5\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u4ee3\u7406\u5728GUI\u5207\u6362\u63a7\u5236\u4e2d\u7684\u4e0d\u53ef\u9760\u6027\u95ee\u9898\uff0c\u63d0\u5347\u5207\u6362\u6307\u4ee4\u6267\u884c\u51c6\u786e\u738730%\u4ee5\u4e0a", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u4ee3\u7406\u5728\u56fe\u5f62\u7528\u6237\u754c\u9762(GUI)\u5207\u6362\u63a7\u5236\u4e2d\u4e0d\u53ef\u9760\uff0c\u7279\u522b\u662f\u5728\u5f53\u524d\u72b6\u6001\u4e0e\u671f\u671b\u72b6\u6001\u4e00\u81f4\u65f6\u65e0\u6cd5\u6b63\u786e\u5904\u7406\u5207\u6362\u6307\u4ee4", "method": "\u6784\u5efa\u72b6\u6001\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u63d0\u51faStaR\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6559\u5bfc\u4ee3\u7406\u611f\u77e5\u5f53\u524d\u5207\u6362\u72b6\u6001\u3001\u5206\u6790\u6307\u4ee4\u671f\u671b\u72b6\u6001\u5e76\u76f8\u5e94\u6267\u884c\u64cd\u4f5c", "result": "\u5728\u4e09\u4e2a\u591a\u6a21\u6001\u4ee3\u7406\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0cStaR\u63d0\u5347\u5207\u6362\u6307\u4ee4\u6267\u884c\u51c6\u786e\u7387\u8d85\u8fc730%\uff0c\u5728\u4e09\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e5f\u63d0\u5347\u4e86\u4e00\u822c\u4efb\u52a1\u6027\u80fd", "conclusion": "StaR\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86GUI\u5207\u6362\u63a7\u5236\u95ee\u9898\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u5b9e\u9645\u5e94\u7528\u6f5c\u529b"}}
{"id": "2509.13761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13761", "abs": "https://arxiv.org/abs/2509.13761", "authors": ["Qikai Chang", "Zhenrong Zhang", "Pengfei Hu", "Jiefeng Ma", "Yicheng Pan", "Jianshu Zhang", "Jun Du", "Quan Liu", "Jianqing Gao"], "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "comment": "22 pages, 13 figures", "summary": "Large Language Models (LLMs) have made remarkable progress in mathematical\nreasoning, but still continue to struggle with high-precision tasks like\nnumerical computation and formal symbolic manipulation. Integrating external\ntools has emerged as a promising approach to bridge this gap. Despite recent\nadvances, existing methods struggle with three key challenges: constructing\ntool-integrated reasoning data, performing fine-grained optimization, and\nenhancing inference. To overcome these limitations, we propose THOR\n(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,\na multi-agent actor-critic-based pipeline for constructing high-quality\ndatasets of tool-integrated reasoning paths, aligning with the policy and\ngeneralizing well across diverse models. Second, to perform fine-grained\nhierarchical optimization, we introduce an RL strategy that jointly optimizes\nfor both trajectory-level problem solving and step-level code generation. This\nis motivated by our key insight that the success of an intermediate tool call\nis a strong predictor of the final answer's correctness. Finally, THOR\nincorporates a self-correction mechanism that leverages immediate tool feedback\nto dynamically revise erroneous reasoning paths during inference. Our approach\ndemonstrates strong generalization across diverse models, performing\neffectively in both reasoning and non-reasoning models. It further achieves\nstate-of-the-art performance for models of a similar scale on multiple\nmathematical benchmarks, while also delivering consistent improvements on code\nbenchmarks. Our code will be publicly available at\nhttps://github.com/JingMog/THOR.", "AI": {"tldr": "THOR\u662f\u4e00\u4e2a\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u5de5\u5177\u96c6\u6210\u5c42\u6b21\u4f18\u5316\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86LLM\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u9ad8\u7cbe\u5ea6\u4efb\u52a1\uff08\u5982\u6570\u503c\u8ba1\u7b97\u548c\u7b26\u53f7\u64cd\u4f5c\uff09\u7684\u6311\u6218\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3001\u5206\u5c42\u4f18\u5316\u548c\u81ea\u6821\u6b63\u673a\u5236\uff0c\u5728\u591a\u4e2a\u6570\u5b66\u548c\u4ee3\u7801\u57fa\u51c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u9ad8\u7cbe\u5ea6\u4efb\u52a1\uff08\u5982\u6570\u503c\u8ba1\u7b97\u548c\u5f62\u5f0f\u7b26\u53f7\u64cd\u4f5c\uff09\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u56f0\u96be\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u6784\u5efa\u5de5\u5177\u96c6\u6210\u63a8\u7406\u6570\u636e\u3001\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4f18\u5316\u548c\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51faTHOR\u65b9\u6cd5\uff1a1\uff09TIRGen\u591a\u667a\u80fd\u4f53actor-critic\u6d41\u6c34\u7ebf\u6784\u5efa\u9ad8\u8d28\u91cf\u5de5\u5177\u96c6\u6210\u63a8\u7406\u6570\u636e\u96c6\uff1b2\uff09\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u8054\u5408\u4f18\u5316\u8f68\u8ff9\u7ea7\u95ee\u9898\u89e3\u51b3\u548c\u6b65\u9aa4\u7ea7\u4ee3\u7801\u751f\u6210\uff1b3\uff09\u81ea\u6821\u6b63\u673a\u5236\uff0c\u5229\u7528\u5de5\u5177\u53cd\u9988\u52a8\u6001\u4fee\u6b63\u63a8\u7406\u8def\u5f84\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u63a8\u7406\u548c\u975e\u63a8\u7406\u6a21\u578b\u4e2d\u90fd\u6709\u6548\u3002\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u4e0a\u8fbe\u5230\u76f8\u4f3c\u89c4\u6a21\u6a21\u578b\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u540c\u65f6\u5728\u4ee3\u7801\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e00\u81f4\u6539\u8fdb\u3002", "conclusion": "THOR\u901a\u8fc7\u5de5\u5177\u96c6\u6210\u548c\u5206\u5c42\u4f18\u5316\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u9ad8\u7cbe\u5ea6\u6570\u5b66\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u589e\u5f3a\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13773", "categories": ["cs.AI", "cs.IR", "I.2.7; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.13773", "abs": "https://arxiv.org/abs/2509.13773", "authors": ["Zhipeng Bian", "Jieming Zhu", "Xuyang Xie", "Quanyu Dai", "Zhou Zhao", "Zhenhua Dong"], "title": "MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation", "comment": "Published in Proceedings of the 63rd Annual Meeting of the\n  Association for Computational Linguistics (Volume 6: Industry Track), ACL\n  2025. Official version: https://doi.org/10.18653/v1/2025.acl-industry.103", "summary": "The rapid advancement of generative AI technologies is driving the\nintegration of diverse AI-powered services into smartphones, transforming how\nusers interact with their devices. To simplify access to predefined AI\nservices, this paper introduces MIRA, a pioneering framework for task\ninstruction recommendation that enables intuitive one-touch AI tasking on\nsmartphones. With MIRA, users can long-press on images or text objects to\nreceive contextually relevant instruction recommendations for executing AI\ntasks. Our work introduces three key innovations: 1) A multimodal large\nlanguage model (MLLM)-based recommendation pipeline with structured reasoning\nto extract key entities, infer user intent, and generate precise instructions;\n2) A template-augmented reasoning mechanism that integrates high-level\nreasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based\nconstrained decoding strategy that restricts outputs to predefined instruction\ncandidates, ensuring coherent and intent-aligned suggestions. Through\nevaluation using a real-world annotated datasets and a user study, MIRA has\ndemonstrated substantial improvements in the accuracy of instruction\nrecommendation. The encouraging results highlight MIRA's potential to\nrevolutionize the way users engage with AI services on their smartphones,\noffering a more seamless and efficient experience.", "AI": {"tldr": "MIRA\u662f\u4e00\u4e2a\u667a\u80fd\u624b\u673aAI\u4efb\u52a1\u6307\u4ee4\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u957f\u6309\u56fe\u50cf\u6216\u6587\u672c\u6765\u63d0\u4f9b\u4e0a\u4e0b\u6587\u76f8\u5173\u7684AI\u4efb\u52a1\u6307\u4ee4\u5efa\u8bae\uff0c\u4f7f\u7528MLLM\u548c\u7ed3\u6784\u5316\u63a8\u7406\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u667a\u80fd\u624b\u673a\u9700\u8981\u66f4\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u8bbf\u95ee\u9884\u5b9a\u4e49\u7684AI\u670d\u52a1\uff0c\u7b80\u5316\u7528\u6237\u4e0e\u8bbe\u5907\u7684\u4ea4\u4e92\u3002", "method": "\u91c7\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u8350\u7ba1\u9053\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u7ed3\u5408\u6a21\u677f\u589e\u5f3a\u63a8\u7406\u673a\u5236\u548c\u524d\u7f00\u6811\u7ea6\u675f\u89e3\u7801\u7b56\u7565\uff0c\u786e\u4fdd\u6307\u4ee4\u5efa\u8bae\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "result": "\u5728\u771f\u5b9e\u6807\u6ce8\u6570\u636e\u96c6\u548c\u7528\u6237\u7814\u7a76\u4e2d\uff0cMIRA\u663e\u8457\u63d0\u9ad8\u4e86\u6307\u4ee4\u63a8\u8350\u7684\u51c6\u786e\u6027\u3002", "conclusion": "MIRA\u6709\u6f5c\u529b\u5f7b\u5e95\u6539\u53d8\u7528\u6237\u5728\u667a\u80fd\u624b\u673a\u4e0a\u4e0eAI\u670d\u52a1\u7684\u4ea4\u4e92\u65b9\u5f0f\uff0c\u63d0\u4f9b\u66f4\u65e0\u7f1d\u9ad8\u6548\u7684\u4f53\u9a8c\u3002"}}
{"id": "2509.13880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13880", "abs": "https://arxiv.org/abs/2509.13880", "authors": ["Mingwei Zhang", "Zhenhao Gu", "Liangda Fang", "Cunjing Ge", "Ziliang Chen", "Zhao-Rong Lai", "Quanlong Guan"], "title": "An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques", "comment": null, "summary": "Linear constraints are one of the most fundamental constraints in fields such\nas computer science, operations research and optimization. Many applications\nreduce to the task of model counting over integer linear constraints (MCILC).\nIn this paper, we design an exact approach to MCILC based on an exhaustive DPLL\narchitecture. To improve the efficiency, we integrate several effective\nsimplification techniques from mixed integer programming into the architecture.\nWe compare our approach to state-of-the-art MCILC counters and propositional\nmodel counters on 2840 random and 4131 application benchmarks. Experimental\nresults show that our approach significantly outperforms all exact methods in\nrandom benchmarks solving 1718 instances while the state-of-the-art approach\nonly computes 1470 instances. In addition, our approach is the only approach to\nsolve all 4131 application instances.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDPLL\u67b6\u6784\u7684\u7cbe\u786e\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u6a21\u578b\u8ba1\u6570\u65b9\u6cd5\uff0c\u96c6\u6210\u4e86\u6df7\u5408\u6574\u6570\u89c4\u5212\u4e2d\u7684\u7b80\u5316\u6280\u672f\uff0c\u5728\u968f\u673a\u548c\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u6a21\u578b\u8ba1\u6570(MCILC)\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u8fd0\u7b79\u5b66\u548c\u4f18\u5316\u9886\u57df\u7684\u57fa\u7840\u95ee\u9898\uff0c\u8bb8\u591a\u5e94\u7528\u90fd\u9700\u8981\u89e3\u51b3\u6b64\u7c7b\u95ee\u9898", "method": "\u57fa\u4e8e\u8be6\u5c3d\u7684DPLL\u67b6\u6784\u8bbe\u8ba1\u7cbe\u786e\u65b9\u6cd5\uff0c\u96c6\u6210\u6df7\u5408\u6574\u6570\u89c4\u5212\u4e2d\u7684\u6709\u6548\u7b80\u5316\u6280\u672f", "result": "\u57282840\u4e2a\u968f\u673a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u89e3\u51b3\u4e861718\u4e2a\u5b9e\u4f8b\uff08\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u4e3a1470\u4e2a\uff09\uff0c\u57284131\u4e2a\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u662f\u552f\u4e00\u80fd\u89e3\u51b3\u6240\u6709\u5b9e\u4f8b\u7684\u65b9\u6cd5", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u6a21\u578b\u8ba1\u6570\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cbe\u786e\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5e94\u7528\u5b9e\u4f8b\u4e2d\u8868\u73b0\u7a81\u51fa"}}
{"id": "2509.13968", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13968", "abs": "https://arxiv.org/abs/2509.13968", "authors": ["Konstantinos Voudouris", "Andrew Barron", "Marta Halina", "Colin Klein", "Matishalin Patel"], "title": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "comment": null, "summary": "Transitional accounts of evolution emphasise a few changes that shape what is\nevolvable, with dramatic consequences for derived lineages. More recently it\nhas been proposed that cognition might also have evolved via a series of major\ntransitions that manipulate the structure of biological neural networks,\nfundamentally changing the flow of information. We used idealised models of\ninformation flow, artificial neural networks (ANNs), to evaluate whether\nchanges in information flow in a network can yield a transitional change in\ncognitive performance. We compared networks with feed-forward, recurrent and\nlaminated topologies, and tested their performance learning artificial grammars\nthat differed in complexity, controlling for network size and resources. We\ndocumented a qualitative expansion in the types of input that recurrent\nnetworks can process compared to feed-forward networks, and a related\nqualitative increase in performance for learning the most complex grammars. We\nalso noted how the difficulty in training recurrent networks poses a form of\ntransition barrier and contingent irreversibility -- other key features of\nevolutionary transitions. Not all changes in network topology confer a\nperformance advantage in this task set. Laminated networks did not outperform\nnon-laminated networks in grammar learning. Overall, our findings show how some\nchanges in information flow can yield transitions in cognitive performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u63a2\u8ba8\u4fe1\u606f\u6d41\u7ed3\u6784\u53d8\u5316\u662f\u5426\u80fd\u5e26\u6765\u8ba4\u77e5\u8868\u73b0\u7684\u8dc3\u8fc1\u6027\u53d8\u5316\uff0c\u53d1\u73b0\u5faa\u73af\u7f51\u7edc\u76f8\u6bd4\u524d\u9988\u7f51\u7edc\u5728\u5904\u7406\u590d\u6742\u8bed\u6cd5\u65f6\u5177\u6709\u8d28\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u89c2\u5bdf\u5230\u8bad\u7ec3\u96be\u5ea6\u5f62\u6210\u7684\u8fc7\u6e21\u969c\u788d\u3002", "motivation": "\u7814\u7a76\u8ba4\u77e5\u80fd\u529b\u662f\u5426\u901a\u8fc7\u4e00\u7cfb\u5217\u4e3b\u8981\u8dc3\u8fc1\u8fdb\u5316\u800c\u6765\uff0c\u8fd9\u4e9b\u8dc3\u8fc1\u901a\u8fc7\u6539\u53d8\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7684\u4fe1\u606f\u6d41\u7ed3\u6784\u6765\u6839\u672c\u6027\u5730\u6539\u53d8\u4fe1\u606f\u5904\u7406\u65b9\u5f0f\u3002", "method": "\u4f7f\u7528\u7406\u60f3\u5316\u4fe1\u606f\u6d41\u6a21\u578b\u548c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff0c\u6bd4\u8f83\u524d\u9988\u3001\u5faa\u73af\u548c\u5206\u5c42\u62d3\u6251\u7ed3\u6784\u7684\u7f51\u7edc\u6027\u80fd\uff0c\u63a7\u5236\u7f51\u7edc\u5927\u5c0f\u548c\u8d44\u6e90\uff0c\u6d4b\u8bd5\u4e0d\u540c\u590d\u6742\u5ea6\u4eba\u5de5\u8bed\u6cd5\u7684\u5b66\u4e60\u80fd\u529b\u3002", "result": "\u5faa\u73af\u7f51\u7edc\u76f8\u6bd4\u524d\u9988\u7f51\u7edc\u5728\u5904\u7406\u8f93\u5165\u7c7b\u578b\u4e0a\u6709\u8d28\u7684\u6269\u5c55\uff0c\u5728\u6700\u590d\u6742\u8bed\u6cd5\u5b66\u4e60\u4e0a\u8868\u73b0\u51fa\u8d28\u7684\u6027\u80fd\u63d0\u5347\uff1b\u5faa\u73af\u7f51\u7edc\u7684\u8bad\u7ec3\u96be\u5ea6\u5f62\u6210\u4e86\u8fc7\u6e21\u969c\u788d\u548c\u5076\u7136\u4e0d\u53ef\u9006\u6027\uff1b\u5206\u5c42\u7f51\u7edc\u5728\u8bed\u6cd5\u5b66\u4e60\u4e0a\u5e76\u672a\u4f18\u4e8e\u975e\u5206\u5c42\u7f51\u7edc\u3002", "conclusion": "\u67d0\u4e9b\u4fe1\u606f\u6d41\u7ed3\u6784\u7684\u53d8\u5316\u786e\u5b9e\u80fd\u591f\u4ea7\u751f\u8ba4\u77e5\u8868\u73b0\u7684\u8dc3\u8fc1\u6027\u53d8\u5316\uff0c\u9a8c\u8bc1\u4e86\u8ba4\u77e5\u8fdb\u5316\u53ef\u80fd\u901a\u8fc7\u4e3b\u8981\u8dc3\u8fc1\u5b9e\u73b0\u7684\u5047\u8bbe\u3002"}}
{"id": "2509.14030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14030", "abs": "https://arxiv.org/abs/2509.14030", "authors": ["Maosheng Qin", "Renyu Zhu", "Mingxuan Xia", "Chenkai Chen", "Zhen Zhu", "Minmin Lin", "Junbo Zhao", "Lu Xu", "Changjie Fan", "Runze Wu", "Haobo Wang"], "title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System", "comment": null, "summary": "High-quality annotated data is a cornerstone of modern Natural Language\nProcessing (NLP). While recent methods begin to leverage diverse annotation\nsources-including Large Language Models (LLMs), Small Language Models (SLMs),\nand human experts-they often focus narrowly on the labeling step itself. A\ncritical gap remains in the holistic process control required to manage these\nsources dynamically, addressing complex scheduling and quality-cost trade-offs\nin a unified manner. Inspired by real-world crowdsourcing companies, we\nintroduce CrowdAgent, a multi-agent system that provides end-to-end process\ncontrol by integrating task assignment, data annotation, and quality/cost\nmanagement. It implements a novel methodology that rationally assigns tasks,\nenabling LLMs, SLMs, and human experts to advance synergistically in a\ncollaborative annotation workflow. We demonstrate the effectiveness of\nCrowdAgent through extensive experiments on six diverse multimodal\nclassification tasks. The source code and video demo are available at\nhttps://github.com/QMMMS/CrowdAgent.", "AI": {"tldr": "CrowdAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u4efb\u52a1\u5206\u914d\u3001\u6570\u636e\u6807\u6ce8\u548c\u8d28\u91cf/\u6210\u672c\u7ba1\u7406\uff0c\u4e3aLLM\u3001SLM\u548c\u4eba\u7c7b\u4e13\u5bb6\u63d0\u4f9b\u7aef\u5230\u7aef\u7684\u534f\u540c\u6807\u6ce8\u6d41\u7a0b\u63a7\u5236\u3002", "motivation": "\u5f53\u524dNLP\u6807\u6ce8\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6807\u6ce8\u6b65\u9aa4\u672c\u8eab\uff0c\u7f3a\u4e4f\u5bf9\u591a\u6837\u5316\u6807\u6ce8\u6e90\uff08LLM\u3001SLM\u3001\u4eba\u7c7b\u4e13\u5bb6\uff09\u7684\u52a8\u6001\u7ba1\u7406\u548c\u590d\u6742\u8c03\u5ea6\u9700\u6c42\uff0c\u4ee5\u53ca\u8d28\u91cf-\u6210\u672c\u6743\u8861\u7684\u7edf\u4e00\u5904\u7406\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u67b6\u6784\uff0c\u5b9e\u73b0\u4efb\u52a1\u5206\u914d\u3001\u6570\u636e\u6807\u6ce8\u3001\u8d28\u91cf/\u6210\u672c\u7ba1\u7406\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\u63a7\u5236\uff0c\u901a\u8fc7\u7406\u6027\u4efb\u52a1\u5206\u914d\u4f7f\u4e0d\u540c\u6807\u6ce8\u6e90\u5728\u534f\u540c\u5de5\u4f5c\u6d41\u4e2d\u534f\u540c\u63a8\u8fdb\u3002", "result": "\u5728\u516d\u4e2a\u591a\u6837\u5316\u591a\u6a21\u6001\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86CrowdAgent\u7684\u6709\u6548\u6027\u3002", "conclusion": "CrowdAgent\u586b\u8865\u4e86\u6807\u6ce8\u6d41\u7a0b\u4e2d\u52a8\u6001\u7ba1\u7406\u548c\u8d28\u91cf-\u6210\u672c\u6743\u8861\u7684\u7a7a\u767d\uff0c\u4e3a\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u7aef\u5230\u7aef\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14195", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14195", "abs": "https://arxiv.org/abs/2509.14195", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning", "comment": "8 pages, 3 figures", "summary": "Mental representation, characterized by structured internal models mirroring\nexternal environments, is fundamental to advanced cognition but remains\nchallenging to investigate empirically. Existing theory hypothesizes that\nsecond-order learning -- learning mechanisms that adapt first-order learning\n(i.e., learning about the task/domain) -- promotes the emergence of such\nenvironment-cognition isomorphism. In this paper, we empirically validate this\nhypothesis by proposing a hierarchical architecture comprising a Graph\nConvolutional Network (GCN) as a first-order learner and an MLP controller as a\nsecond-order learner. The GCN directly maps node-level features to predictions\nof optimal navigation paths, while the MLP dynamically adapts the GCN's\nparameters when confronting structurally novel maze environments. We\ndemonstrate that second-order learning is particularly effective when the\ncognitive system develops an internal mental map structurally isomorphic to the\nenvironment. Quantitative and qualitative results highlight significant\nperformance improvements and robust generalization on unseen maze tasks,\nproviding empirical support for the pivotal role of structured mental\nrepresentations in maximizing the effectiveness of second-order learning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c42\u6b21\u67b6\u6784\u9a8c\u8bc1\u4e86\u4e8c\u9636\u5b66\u4e60\u4fc3\u8fdb\u73af\u5883-\u8ba4\u77e5\u540c\u6784\u6027\u5f62\u6210\u7684\u5047\u8bbe\uff0cGCN\u4f5c\u4e3a\u4e00\u9636\u5b66\u4e60\u5668\u9884\u6d4b\u6700\u4f18\u8def\u5f84\uff0cMLP\u63a7\u5236\u5668\u4f5c\u4e3a\u4e8c\u9636\u5b66\u4e60\u5668\u52a8\u6001\u8c03\u6574\u53c2\u6570\uff0c\u5728\u8ff7\u5bab\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u5fc3\u667a\u8868\u5f81\uff08\u4e0e\u73af\u5883\u7ed3\u6784\u540c\u6784\u7684\u5185\u90e8\u6a21\u578b\uff09\u5bf9\u9ad8\u7ea7\u8ba4\u77e5\u7684\u91cd\u8981\u6027\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5b9e\u8bc1\u7814\u7a76\u3002\u7406\u8bba\u5047\u8bbe\u4e8c\u9636\u5b66\u4e60\uff08\u8c03\u6574\u4e00\u9636\u5b66\u4e60\u673a\u5236\uff09\u80fd\u4fc3\u8fdb\u8fd9\u79cd\u73af\u5883-\u8ba4\u77e5\u540c\u6784\u6027\u7684\u5f62\u6210\u3002", "method": "\u63d0\u51fa\u5c42\u6b21\u67b6\u6784\uff1aGCN\u4f5c\u4e3a\u4e00\u9636\u5b66\u4e60\u5668\u76f4\u63a5\u6620\u5c04\u8282\u70b9\u7279\u5f81\u5230\u6700\u4f18\u8def\u5f84\u9884\u6d4b\uff0cMLP\u63a7\u5236\u5668\u4f5c\u4e3a\u4e8c\u9636\u5b66\u4e60\u5668\u5728\u9047\u5230\u7ed3\u6784\u65b0\u9896\u7684\u8ff7\u5bab\u73af\u5883\u65f6\u52a8\u6001\u8c03\u6574GCN\u53c2\u6570\u3002", "result": "\u5f53\u8ba4\u77e5\u7cfb\u7edf\u53d1\u5c55\u51fa\u4e0e\u73af\u5883\u7ed3\u6784\u540c\u6784\u7684\u5185\u90e8\u5fc3\u667a\u5730\u56fe\u65f6\uff0c\u4e8c\u9636\u5b66\u4e60\u7279\u522b\u6709\u6548\u3002\u5b9a\u91cf\u548c\u5b9a\u6027\u7ed3\u679c\u663e\u793a\u4e86\u5728\u672a\u89c1\u8ff7\u5bab\u4efb\u52a1\u4e0a\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\u548c\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7ed3\u6784\u5316\u5fc3\u667a\u8868\u5f81\u5728\u6700\u5927\u5316\u4e8c\u9636\u5b66\u4e60\u6548\u679c\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\uff0c\u9a8c\u8bc1\u4e86\u4e8c\u9636\u5b66\u4e60\u4fc3\u8fdb\u73af\u5883-\u8ba4\u77e5\u540c\u6784\u6027\u5f62\u6210\u7684\u7406\u8bba\u5047\u8bbe\u3002"}}
