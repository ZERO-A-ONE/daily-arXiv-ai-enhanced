<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 9]
- [cs.CR](#cs.CR) [Total: 11]
- [cs.AI](#cs.AI) [Total: 44]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Technique to Baseline QE Artefact Generation Aligned to Quality Metrics](https://arxiv.org/abs/2511.15733)
*Eitan Farchi,Kiran Nayak,Papia Ghosh Majumdar,Saritha Route*

Main category: cs.SE

TL;DR: 提出了一种使用量化指标来基准化和评估质量工程产物的系统技术，结合LLM驱动生成、反向生成和基于评分标准的迭代优化，实验证明该框架能实现可扩展的可靠质量工程产物验证。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型正在通过自动化生成需求、测试用例等质量工程产物来改变质量工程，但确保这些输出产物的质量仍然是一个挑战。

Method: 结合LLM驱动生成、反向生成和基于清晰度、完整性、一致性和可测试性评分标准的迭代优化技术。

Result: 在12个项目上的实验结果表明，反向生成的产物可以超越低质量输入，并在输入质量高时保持高标准。

Conclusion: 该框架实现了可扩展、可靠的质量工程产物验证，在自动化与问责制之间架起了桥梁。

Abstract: Large Language Models (LLMs) are transforming Quality Engineering (QE) by automating the generation of artefacts such as requirements, test cases, and Behavior Driven Development (BDD) scenarios. However, ensuring the quality of these outputs remains a challenge. This paper presents a systematic technique to baseline and evaluate QE artefacts using quantifiable metrics. The approach combines LLM-driven generation, reverse generation , and iterative refinement guided by rubrics technique for clarity, completeness, consistency, and testability. Experimental results across 12 projects show that reverse-generated artefacts can outperform low-quality inputs and maintain high standards when inputs are strong. The framework enables scalable, reliable QE artefact validation, bridging automation with accountability.

</details>


### [2] [Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym](https://arxiv.org/abs/2511.15757)
*Kareem Shehada,Yifan Wu,Wyatt D. Feng,Adithya Iyer,Gryphon Kumfert,Yangruibo Ding,Zhiyun Qian*

Main category: cs.SE

TL;DR: RGym是一个轻量级、平台无关的Linux内核自动程序修复评估框架，在本地硬件上运行，使用专门的定位技术（如调用栈和问题提交）来克服KGym中不切实际的神谕使用，在143个已验证bug上达到43.36%的修复成功率，每个bug成本低于0.20美元。


<details>
  <summary>Details</summary>
Motivation: 现有APR基准如SWE-Bench主要关注用户空间应用，忽略了内核空间调试和修复的复杂性。Linux内核由于其单体结构、并发性和低级硬件交互而带来独特挑战，现有方法如KGym和CrashFixer报告成功率低或依赖昂贵复杂的云基础设施。

Method: 提出RGym轻量级评估框架，构建简单有效的APR流程，利用专门的定位技术（调用栈和问题提交）来避免KGym中不切实际的神谕使用，在本地商品硬件上运行。

Result: 在143个过滤验证的bug上测试，使用GPT-5 Thinking达到43.36%的通过率，每个bug成本低于0.20美元。消融研究分析了定位策略、提示结构和模型选择的贡献，显示基于反馈的重试能显著提高成功率。

Conclusion: RGym提供了一个成本效益高且有效的Linux内核APR解决方案，克服了现有方法的局限性，展示了专门定位技术和反馈机制在内核修复中的重要性。

Abstract: Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on userspace applications and overlook the complexities of kernel-space debugging and repair. The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions. Prior efforts such as KGym and CrashFixer have highlighted the difficulty of APR in this domain, reporting low success rates or relying on costly and complex pipelines and pricey cloud infrastructure. In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. Built on RGym, we propose a simple yet effective APR pipeline leveraging specialized localization techniques (e.g., call stacks and blamed commits) to overcome the unrealistic usage of oracles in KGym. We test on a filtered and verified dataset of 143 bugs. Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug. We further conduct an ablation study to analyze contributions from our proposed localization strategy, prompt structure, and model choice, and demonstrate that feedback-based retries can significantly enhance success rates.

</details>


### [3] [A Causal Perspective on Measuring, Explaining and Mitigating Smells in \llm-Generated Code](https://arxiv.org/abs/2511.15817)
*Alejandro Velasco,Daniel Rodriguez-Cardenas,Dipin Khati,David N. Palacio,Luftar Rahman Alif,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 本文系统性地测量、解释和缓解LLM生成代码中的代码异味倾向，提出了PSC概率度量方法，并通过因果分析识别了影响代码结构质量的关键因素。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在软件工程中应用广泛，但其生成的代码结构质量存在担忧，经常复制不良编码实践引入代码异味，目前缺乏对这些问题的系统理解。

Method: 基于PSC概率度量方法，通过因果分析研究生成策略、模型大小、架构和提示设计如何影响代码结构特性，并开发实用的缓解策略。

Result: 发现提示设计和架构选择对代码异味倾向起决定性作用，提出的缓解策略能有效减少异味发生，用户研究证明PSC能帮助开发者理解模型行为和评估代码质量。

Conclusion: 这项工作为将质量感知评估集成到LLM代码生成评估和部署中奠定了基础，PSC信号可以支持人类判断。

Abstract: Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.
  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.

</details>


### [4] [AI-Enabled Orchestration of Event-Driven Business Processes in Workday ERP for Healthcare Enterprises](https://arxiv.org/abs/2511.15852)
*Monu Sharma*

Main category: cs.SE

TL;DR: 该研究提出在Workday ERP中集成AI驱动的事件驱动编排框架，通过机器学习触发器和流程挖掘分析来智能同步医疗机构的财务和供应链工作流程。


<details>
  <summary>Details</summary>
Motivation: 传统ERP系统的工作流逻辑缺乏适应性，难以管理事件驱动和数据密集的医疗环境，需要更智能的自动化解决方案。

Method: 采用AI驱动的事件驱动编排框架，结合机器学习触发器、异常检测和流程挖掘分析，实现财务和供应链工作流程的智能同步。

Result: 多组织案例分析显示在流程效率、成本可视性和决策准确性方面取得了可衡量的提升。

Conclusion: 在Workday的事件驱动架构中嵌入AI能力增强了运营韧性、治理和可扩展性，为医疗企业的下一代自动化策略建立了参考标准。

Abstract: The adoption of cloud-based Enterprise Resource Planning (ERP) platforms such as Workday has transformed healthcare operations by integrating financial, supply-chain, and workforce processes into a unified ecosystem. However, traditional workflow logic in ERP systems often lacks the adaptability required to manage event-driven and data-intensive healthcare environments.
  This study proposes an AI-enabled event-driven orchestration framework within Workday ERP that intelligently synchronizes financial and supply-chain workflows across distributed healthcare entities. The framework employs machine-learning triggers, anomaly detection, and process mining analytics to anticipate and automate responses to operational events such as inventory depletion, payment delays, or patient demand fluctuations. A multi-organization case analysis demonstrates measurable gains in process efficiency, cost visibility, and decision accuracy.
  Results confirm that embedding AI capabilities into Workday's event-based architecture enhances operational resilience, governance, and scalability. The proposed model contributes to the broader understanding of intelligent ERP integration and establishes a reference for next-generation automation strategies in healthcare enterprises.

</details>


### [5] [RE for AI in Practice: Managing Data Annotation Requirements for AI Autonomous Driving Systems](https://arxiv.org/abs/2511.15859)
*Hina Saeeda,Mazen Mohamad,Eric Knauss,Jennifer Horkoff,Ali Nouri*

Main category: cs.SE

TL;DR: 该研究探讨了自动驾驶AI感知系统中高质量数据标注要求的重要性，分析了当前实践中的挑战和最佳实践，并揭示了标注要求与AI系统性能之间的关键关联。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶AI感知系统需要高质量的数据标注来确保安全性和可靠性，但目前标注要求的制定和管理研究不足，导致不一致性、安全风险和监管问题。

Method: 对来自6家国际公司和4个研究机构的19名参与者进行了半结构化访谈，并进行了主题分析。

Result: 识别了五个主要挑战：模糊性、边缘案例复杂性、需求演变、不一致性和资源限制；以及三类最佳实践：确保符合道德标准、改进数据标注要求指南、嵌入式质量保证。揭示了标注要求、标注实践、标注数据质量和AI系统性能之间的关键关联。

Conclusion: 这是首个提供基于实证的标注要求改进指南的研究，为提升标注质量、监管合规性和系统可靠性提供了可行见解，同时为软件工程和需求工程领域做出了贡献。

Abstract: High-quality data annotation requirements are crucial for the development of safe and reliable AI-enabled perception systems (AIePS) in autonomous driving. Although these requirements play a vital role in reducing bias and enhancing performance, their formulation and management remain underexplored, leading to inconsistencies, safety risks, and regulatory concerns. Our study investigates how annotation requirements are defined and used in practice, the challenges in ensuring their quality, practitioner-recommended improvements, and their impact on AIePS development and performance. We conducted $19$ semi-structured interviews with participants from six international companies and four research organisations. Our thematic analysis reveals five main key challenges: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints and three main categories of best practices, including ensuring compliance with ethical standards, improving data annotation requirements guidelines, and embedded quality assurance for data annotation requirements. We also uncover critical interrelationships between annotation requirements, annotation practices, annotated data quality, and AIePS performance and development, showing how requirement flaws propagate through the AIePS development pipeline. To the best of our knowledge, this study is the first to offer empirically grounded guidance on improving annotation requirements, offering actionable insights to enhance annotation quality, regulatory compliance, and system reliability. It also contributes to the emerging fields of Software Engineering (SE for AI) and Requirements Engineering (RE for AI) by bridging the gap between RE and AI in a timely and much-needed manner.

</details>


### [6] [The Future of Development Environments with AI Foundation Models: NII Shonan Meeting 222 Report](https://arxiv.org/abs/2511.16092)
*Xing Hu,Raula Gaikovina Kula,Christoph Treude*

Main category: cs.SE

TL;DR: 本文报告了Shonan Meeting 222会议中33位专家讨论生成式AI对集成开发环境(IDE)影响的专家讨论报告


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI在代码生成、测试、代码审查和程序修复等任务中的显著表现如何改变IDE中的人机交互，以及这种抽象化提升对软件开发的影响

Method: 组织来自软件工程、人工智能和人机交互领域的33位专家进行讨论，分析生成式AI对IDE的挑战和机遇

Result: 专家们识别了生成式AI在IDE中应用的关键挑战和机遇，包括人机交互模式的改变、抽象层次的提升等

Conclusion: 生成式AI有潜力显著改变IDE中的人机交互方式，需要跨学科合作来应对相关挑战并把握机遇

Abstract: Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222. This is the report

</details>


### [7] [Domain-constrained Synthesis of Inconsistent Key Aspects in Textual Vulnerability Descriptions](https://arxiv.org/abs/2511.16123)
*Linyi Han,Shidong Pan,Zhenchang Xing,Sofonias Yitagesu,Xiaowang Zhang,Zhiyong Feng,Jiamou Sun,Qing Huang*

Main category: cs.SE

TL;DR: 提出基于领域约束LLM的文本漏洞描述(TVDs)关键方面统一框架，通过提取、自评估和融合三个阶段解决不同来源TVDs的关键方面不一致问题，提高综合性能和理解效率。


<details>
  <summary>Details</summary>
Motivation: 不同漏洞库中文本漏洞描述(TVDs)的关键方面存在不一致，给安全分析师全面理解漏洞带来挑战。现有方法通过对齐外部知识库来缓解不一致，但往往会丢弃有价值信息且无法合成全面表示。

Method: 提出三阶段框架：1)基于规则模板的提取，确保捕获所有关键细节；2)使用领域特定锚词的自评估，评估跨来源的语义变异性；3)利用信息熵的融合，协调不一致并优先考虑相关细节。

Result: 该框架将关键方面增强的F1分数从0.82提高到0.87，同时将理解和效率提高了30%以上。开发的可视化工具Digest Labels在人工评估中显著提升了可用性。

Conclusion: 提出的领域约束LLM合成框架有效解决了TVDs关键方面不一致问题，提高了漏洞描述的合成性能、理解效率和可用性。

Abstract: Textual Vulnerability Descriptions (TVDs) are crucial for security analysts to understand and address software vulnerabilities. However, the key aspect inconsistencies in TVDs from different repositories pose challenges for achieving a comprehensive understanding of vulnerabilities. Existing approaches aim to mitigate inconsistencies by aligning TVDs with external knowledge bases, but they often discard valuable information and fail to synthesize comprehensive representations. In this paper, we propose a domain-constrained LLM-based synthesis framework for unifying key aspects of TVDs. Our framework consists of three stages: 1) Extraction, guided by rule-based templates to ensure all critical details are captured; 2) Self-evaluation, using domain-specific anchor words to assess semantic variability across sources; and 3) Fusion, leveraging information entropy to reconcile inconsistencies and prioritize relevant details. This framework improves synthesis performance, increasing the F1 score for key aspect augmentation from 0.82 to 0.87, while enhancing comprehension and efficiency by over 30\%. We further develop Digest Labels, a practical tool for visualizing TVDs, which human evaluations show significantly boosts usability.

</details>


### [8] [Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts](https://arxiv.org/abs/2511.16224)
*Francesco Salzano,Simone Scalabrino,Rocco Oliveto,Simone Scalabrino*

Main category: cs.SE

TL;DR: 评估LLM生成Solidity智能合约的可靠性，发现虽然语义相似度高，但功能正确性低（仅20-26%），生成的代码更简单且耗气量低，检索增强生成能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 智能合约在区块链生态中至关重要，但LLM生成的Solidity代码在燃气消耗、安全性和确定性方面的可靠性存在疑问，现有研究缺乏对这些关键功能和非功能属性的全面评估。

Method: 对4个最先进模型在零样本和检索增强生成设置下进行基准测试，涵盖500个真实函数，采用代码相似性指标、语义嵌入、自动化测试执行、燃气分析、认知和圈复杂度分析等多方面评估。

Result: LLM生成的代码与真实合约语义相似度高，但功能正确性低（仅20-26%），生成的代码复杂度更低、燃气消耗更少，检索增强生成将功能正确性提升高达45%，产生更简洁高效的代码。

Conclusion: LLM生成的智能合约在语义相似度和功能合理性之间存在显著差距，虽然RAG是强大的增强工具，但要实现稳健的生产就绪代码生成仍需重大挑战，需要专家仔细验证。

Abstract: Smart Contracts are critical components of blockchain ecosystems, with Solidity as the dominant programming language. While LLMs excel at general-purpose code generation, the unique constraints of Smart Contracts, such as gas consumption, security, and determinism, raise open questions about the reliability of LLM-generated Solidity code. Existing studies lack a comprehensive evaluation of these critical functional and non-functional properties. We benchmark four state-of-the-art models under zero-shot and retrieval-augmented generation settings across 500 real-world functions. Our multi-faceted assessment employs code similarity metrics, semantic embeddings, automated test execution, gas profiling, and cognitive and cyclomatic complexity analysis. Results show that while LLMs produce code with high semantic similarity to real contracts, their functional correctness is low: only 20% to 26% of zero-shot generations behave identically to ground-truth implementations under testing. The generated code is consistently simpler, with significantly lower complexity and gas consumption, often due to omitted validation logic. Retrieval-Augmented Generation markedly improves performance, boosting functional correctness by up to 45% and yielding more concise and efficient code. Our findings reveal a significant gap between semantic similarity and functional plausibility in LLM-generated Smart Contracts. We conclude that while RAG is a powerful enhancer, achieving robust, production-ready code generation remains a substantial challenge, necessitating careful expert validation.

</details>


### [9] [Data Annotation Quality Problems in AI-Enabled Perception System Development](https://arxiv.org/abs/2511.16410)
*Hina Saeeda,Tommy Johansson,Mazen Mohamad,Eric Knauss*

Main category: cs.SE

TL;DR: 本研究通过多组织案例研究开发了一个包含18种常见标注错误类型的分类法，涵盖完整性、准确性和一致性三个数据质量维度，为构建可信的AI感知系统提供共享词汇、诊断工具和可操作指导。


<details>
  <summary>Details</summary>
Motivation: 数据标注在自动驾驶AI感知系统开发中至关重要但容易出错，而行业缺乏对标注错误如何在多组织汽车供应链中产生和传播的实证见解。

Method: 采用多组织案例研究，涉及6家公司和4个研究机构，基于19次半结构化访谈（20位专家，50小时转录）和六阶段主题分析。

Result: 开发了包含18种重复出现的标注错误类型的分类法，涵盖完整性、准确性和一致性三个维度，并通过行业从业者验证了其有用性。

Conclusion: 通过将标注质量概念化为生命周期和供应链问题，本研究为SE4AI提供了共享词汇、诊断工具集和可操作指导，有助于构建可信的AI感知系统。

Abstract: Data annotation is essential but highly error-prone in the development of AI-enabled perception systems (AIePS) for automated driving, and its quality directly influences model performance, safety, and reliability. However, the industry lacks empirical insights into how annotation errors emerge and spread across the multi-organisational automotive supply chain. This study addresses this gap through a multi-organisation case study involving six companies and four research institutes across Europe and the UK. Based on 19 semi-structured interviews with 20 experts (50 hours of transcripts) and a six-phase thematic analysis, we develop a taxonomy of 18 recurring annotation error types across three data-quality dimensions: completeness (e.g., attribute omission, missing feedback loops, edge-case omissions, selection bias), accuracy (e.g., mislabelling, bounding-box inaccuracies, granularity mismatches, bias-driven errors), and consistency (e.g., inter-annotator disagreement, ambiguous instructions, misaligned hand-offs, cross-modality inconsistencies). The taxonomy was validated with industry practitioners, who reported its usefulness for root-cause analysis, supplier quality reviews, onboarding, and improving annotation guidelines. They described it as a failure-mode catalogue similar to FMEA. By conceptualising annotation quality as a lifecycle and supply-chain issue, this study contributes to SE4AI by offering a shared vocabulary, diagnostic toolset, and actionable guidance for building trustworthy AI-enabled perception systems.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [10] [A Detailed Comparative Analysis of Blockchain Consensus Mechanisms](https://arxiv.org/abs/2511.15730)
*Kaeli Andrews,Linh Ngo,Md Amiruzzaman*

Main category: cs.CR

TL;DR: 本文对PoW和PoS两种主流区块链共识机制进行了综合比较分析，评估了能源使用、安全性、交易速度等七个关键指标，发现PoW安全性强但能耗高，PoS效率高但存在中心化风险，建议混合设计结合两者优势。


<details>
  <summary>Details</summary>
Motivation: 为未来区块链基础设施发展提供参考，在去中心化、性能和生态责任之间寻求平衡。

Method: 利用近期学术研究和真实区块链数据，对PoW和PoS在七个关键指标上进行对比分析。

Result: PoW提供稳健安全性但能耗高、吞吐量慢、存在矿池中心化；PoS具有更好的可扩展性和效率，环境影响显著降低，交易费用更稳定，但存在验证者中心化和长期安全性成熟度问题。

Conclusion: 两种机制存在固有权衡，混合设计可能结合PoW的安全性和PoS的效率与可持续性。

Abstract: This paper presents a comprehensive comparative analysis of two dominant blockchain consensus mechanisms, Proof of Work (PoW) and Proof of Stake (PoS), evaluated across seven critical metrics: energy use, security, transaction speed, scalability, centralization risk, environmental impact, and transaction fees. Utilizing recent academic research and real-world blockchain data, the study highlights that PoW offers robust, time-tested security but suffers from high energy consumption, slower throughput, and centralization through mining pools. In contrast, PoS demonstrates improved scalability and efficiency, significantly reduced environmental impact, and more stable transaction fees, however it raises concerns over validator centralization and long-term security maturity. The findings underscore the trade-offs inherent in each mechanism and suggest hybrid designs may combine PoW's security with PoS's efficiency and sustainability. The study aims to inform future blockchain infrastructure development by striking a balance between decentralization, performance, and ecological responsibility.

</details>


### [11] [Structured Extraction of Vulnerabilities in OpenVAS and Tenable WAS Reports Using LLMs](https://arxiv.org/abs/2511.15745)
*Beatriz Machado,Douglas Lautert,Cristhian Kapelinski,Diego Kreutz*

Main category: cs.CR

TL;DR: 提出基于LLM的自动化方法，从OpenVAS和Tenable WAS扫描报告中提取和结构化漏洞信息，将非结构化数据转换为标准化格式用于风险管理。


<details>
  <summary>Details</summary>
Motivation: 解决漏洞扫描报告数据非结构化问题，使其能够有效用于风险管理和优先级排序。

Method: 使用大型语言模型（LLM）自动提取和结构化漏洞信息，将非结构化扫描报告转换为标准化格式。

Result: 在包含34个漏洞的报告评估中，GPT-4.1和DeepSeek模型与基线的相似度最高（ROUGE-L大于0.7）。

Conclusion: 该方法证明能够将复杂报告转换为可用数据集，支持有效优先级排序和未来敏感数据匿名化。

Abstract: This paper proposes an automated LLM-based method to extract and structure vulnerabilities from OpenVAS and Tenable WAS scanner reports, converting unstructured data into a standardized format for risk management. In an evaluation using a report with 34 vulnerabilities, GPT-4.1 and DeepSeek achieved the highest similarity to the baseline (ROUGE-L greater than 0.7). The method demonstrates feasibility in transforming complex reports into usable datasets, enabling effective prioritization and future anonymization of sensitive data.

</details>


### [12] [Scalable Privilege Analysis for Multi-Cloud Big Data Platforms: A Hypergraph Approach](https://arxiv.org/abs/2511.15837)
*Sai Sitharaman,Hassan Karim,Deepti Gupta,Mudit Tyagi*

Main category: cs.CR

TL;DR: 提出了一种基于超图语义和NGAC的新型PAM框架，解决了传统ABAC方法在规模扩展时的立方复杂度问题，实现了亚线性复杂度的权限分析。


<details>
  <summary>Details</summary>
Motivation: 多云环境的快速采用加剧了特权访问管理风险，传统基于ABAC的PAM解决方案存在O(n^3)复杂度，无法在企业规模下进行实时权限分析。

Method: 将NIST的下一代访问控制(NGAC)与超图语义集成，利用带标签超边的超图建模复杂的多维权限关系，并引入3维权限分析框架(攻击面、攻击窗口、攻击身份)。

Result: 在AWS系统上对200-4000用户进行实验验证，相比ABAC提升10倍性能，相比标准NGAC-DAG提升4倍性能，实现了秒级权限检测。

Conclusion: 该框架能够有效检测多云基础设施中的权限提升链、过度特权用户和横向移动路径，解决了企业级权限管理的可扩展性问题。

Abstract: The rapid adoption of multi-cloud environments has amplified risks associated with privileged access mismanagement. Traditional Privileged Access Management (PAM) solutions based on Attribute-Based Access Control (ABAC) exhibit cubic O(n^3) complexity, rendering real-time privilege analysis intractable at enterprise scale. We present a novel PAM framework integrating NIST's Next Generation Access Control (NGAC) with hypergraph semantics to address this scalability crisis. Our approach leverages hypergraphs with labeled hyperedges to model complex, multi-dimensional privilege relationships, achieving sub-linear O(sqrt n) traversal complexity and O(nlogn) detection time-rigorously proven through formal complexity analysis. We introduce a 3-Dimensional Privilege Analysis framework encompassing Attack Surface, Attack Window, and Attack Identity to systematically identify privilege vulnerabilities. Experimental validation on AWS-based systems with 200-4000 users demonstrates 10x improvement over ABAC and 4x improvement over standard NGAC-DAG, enabling sub-second privilege detection at scale. Real-world use cases validate detection of privilege escalation chains, over-privileged users, and lateral movement pathways in multi-cloud infrastructures.

</details>


### [13] [Lifefin: Escaping Mempool Explosions in DAG-based BFT](https://arxiv.org/abs/2511.15936)
*Jianting Zhang,Sen Yang,Alberto Sonnino,Sebastián Loza,Aniket Kate*

Main category: cs.CR

TL;DR: Lifefin是一个通用的自稳定协议，用于解决基于DAG的BFT协议中的活性漏洞问题，通过ACS机制在不利条件下也能以有限资源提交交易，几乎零开销地消除活性漏洞。


<details>
  <summary>Details</summary>
Motivation: 基于DAG的BFT协议存在根本的活性漏洞：攻击者可以通过触发内存池爆炸来阻止交易提交，从而损害协议的活性。

Method: Lifefin利用共识子集协议(ACS)机制，使节点能够在不利条件下以有限资源使用提交交易，从而摆脱内存池爆炸。

Result: 将Lifefin集成到Sailfish和Mysticeti协议中，评估显示在保持可比交易吞吐量的同时，仅引入最小额外延迟即可抵抗类似攻击。

Conclusion: Lifefin能够无缝集成到现有DAG-based BFT协议中，在典型情况下几乎零开销，同时有效消除活性漏洞。

Abstract: Directed Acyclic Graph (DAG)-based Byzantine Fault-Tolerant (BFT) protocols have emerged as promising solutions for high-throughput blockchains. By decoupling data dissemination from transaction ordering and constructing a well-connected DAG in the mempool, these protocols enable zero-message ordering and implicit view changes. However, we identify a fundamental liveness vulnerability: an adversary can trigger mempool explosions to prevent transaction commitment, ultimately compromising the protocol's liveness.
  In response, this work presents Lifefin, a generic and self-stabilizing protocol designed to integrate seamlessly with existing DAG-based BFT protocols and circumvent such vulnerabilities. Lifefin leverages the Agreement on Common Subset (ACS) mechanism, allowing nodes to escape mempool explosions by committing transactions with bounded resource usage even in adverse conditions. As a result, Lifefin imposes (almost) zero overhead in typical cases while effectively eliminating liveness vulnerabilities.
  To demonstrate the effectiveness of Lifefin, we integrate it into two state-of-the-art DAG-based BFT protocols, Sailfish and Mysticeti, resulting in two enhanced variants: Sailfish-Lifefin and Mysticeti-Lifefin. We implement these variants and compare them with the original Sailfish and Mysticeti systems. Our evaluation demonstrates that Lifefin achieves comparable transaction throughput while introducing only minimal additional latency to resist similar attacks.

</details>


### [14] [Digital Agriculture Sandbox for Collaborative Research](https://arxiv.org/abs/2511.15990)
*Osama Zafar,Rosemarie Santa González,Alfonso Morales,Erman Ayday*

Main category: cs.CR

TL;DR: 本文提出了数字农业沙盒平台，通过联邦学习、差分隐私等技术保护农民数据隐私，使农民和研究人员能在不暴露敏感信息的情况下协作分析农业数据。


<details>
  <summary>Details</summary>
Motivation: 数字农业产生大量有价值数据，但由于隐私担忧，农民不愿分享数据，限制了研究人员利用这些数据改进农业实践的能力。

Method: 开发安全的在线平台，采用联邦学习、差分隐私和数据分析方法，确保数据在农民系统内处理，不泄露敏感信息。

Result: 平台为农民和研究人员创建了安全协作空间，农民能轻松找到相似农户，研究人员能学习数据并开发工具，同时保护数据隐私。

Conclusion: 该平台弥合了农业数据隐私保护与数据利用之间的鸿沟，有助于解决全球粮食和农业挑战。

Abstract: Digital agriculture is transforming the way we grow food by utilizing technology to make farming more efficient, sustainable, and productive. This modern approach to agriculture generates a wealth of valuable data that could help address global food challenges, but farmers are hesitant to share it due to privacy concerns. This limits the extent to which researchers can learn from this data to inform improvements in farming. This paper presents the Digital Agriculture Sandbox, a secure online platform that solves this problem. The platform enables farmers (with limited technical resources) and researchers to collaborate on analyzing farm data without exposing private information. We employ specialized techniques such as federated learning, differential privacy, and data analysis methods to safeguard the data while maintaining its utility for research purposes. The system enables farmers to identify similar farmers in a simplified manner without needing extensive technical knowledge or access to computational resources. Similarly, it enables researchers to learn from the data and build helpful tools without the sensitive information ever leaving the farmer's system. This creates a safe space where farmers feel comfortable sharing data, allowing researchers to make important discoveries. Our platform helps bridge the gap between maintaining farm data privacy and utilizing that data to address critical food and farming challenges worldwide.

</details>


### [15] [A Quantum-Secure and Blockchain-Integrated E-Voting Framework with Identity Validation](https://arxiv.org/abs/2511.16034)
*Ashwin Poudel,Utsav Poudel,Dikshyanta Aryal,Anuj Nepal,Pranish Pathak,Subramaniyaswamy V*

Main category: cs.CR

TL;DR: 提出了一种后量子安全的电子投票架构，结合Falcon晶格数字签名、MobileNetV3和AdaFace生物认证以及许可区块链，实现防篡改投票存储和实时生物验证。


<details>
  <summary>Details</summary>
Motivation: 量子计算的快速发展威胁到数字系统的密码学基础，需要开发安全且可扩展的电子投票框架来应对这一挑战。

Method: 集成Falcon晶格数字签名进行数字签名，使用MobileNetV3和AdaFace进行生物认证，采用许可区块链存储投票数据，结合反欺骗技术和余弦相似度匹配进行实时验证。

Result: 在CelebA Spoof数据集上平均分类错误率低于3.5%，在WFAS数据集上低于8.2%；区块链锚定注册阶段gas开销约3.3%，投票阶段约0.15%；系统具有低延迟和强大的欺骗检测能力。

Conclusion: 该方法为数字系统在选民认证、数据完整性和量子弹性安全方面的关键挑战提供了统一解决方案，证实了系统的可扩展性、效率和并发负载下的弹性。

Abstract: The rapid growth of quantum computing poses a threat to the cryptographic foundations of digital systems, requiring the development of secure and scalable electronic voting (evoting) frameworks. We introduce a post-quantum-secure evoting architecture that integrates Falcon lattice-based digital signatures, biometric authentication via MobileNetV3 and AdaFace, and a permissioned blockchain for tamper-proof vote storage. Voter registration involves capturing facial embeddings, which are digitally signed using Falcon and stored on-chain to ensure integrity and non-repudiation. During voting, real-time biometric verification is performed using anti-spoofing techniques and cosine-similarity matching. The system demonstrates low latency and robust spoof detection, monitored through Prometheus and Grafana for real-time auditing. The average classification error rates (ACER) are below 3.5% on the CelebA Spoof dataset and under 8.2% on the Wild Face Anti-Spoofing (WFAS) dataset. Blockchain anchoring incurs minimal gas overhead, approximately 3.3% for registration and 0.15% for voting, supporting system efficiency, auditability, and transparency. The experimental results confirm the system's scalability, efficiency, and resilience under concurrent loads. This approach offers a unified solution to address key challenges in voter authentication, data integrity, and quantum-resilient security for digital systems.

</details>


### [16] [Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models](https://arxiv.org/abs/2511.16110)
*Yijun Yang,Lichao Wang,Jianping Zhang,Chi Harold Liu,Lanqing Hong,Qiang Xu*

Main category: cs.CR

TL;DR: MFA框架通过注意力转移攻击和轻量级传输增强算法，系统性地暴露了GPT-4o、Gemini-Pro等领先视觉语言模型的安全漏洞，在商业模型上达到52.8%的成功率，比现有最佳攻击方法高出34%。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型部署了多种安全防护措施，但这些防御机制在对抗性攻击下的实际鲁棒性尚未得到充分探索。

Method: 提出多面攻击框架，核心是注意力转移攻击，将有害指令隐藏在具有竞争目标的元任务中。结合轻量级传输增强算法和简单重复策略，绕过输入级和输出级过滤器。

Result: MFA在商业模型上达到52.8%的成功率，比第二佳攻击方法高出34%。对抗性图像可跨模型传输，表明共享视觉表示存在跨模型安全漏洞。

Conclusion: 当前防御机制的实际鲁棒性受到挑战，现代视觉语言模型存在持续的安全弱点。

Abstract: The growing misuse of Vision-Language Models (VLMs) has led providers to deploy multiple safeguards, including alignment tuning, system prompts, and content moderation. However, the real-world robustness of these defenses against adversarial attacks remains underexplored. We introduce Multi-Faceted Attack (MFA), a framework that systematically exposes general safety vulnerabilities in leading defense-equipped VLMs such as GPT-4o, Gemini-Pro, and Llama-4. The core component of MFA is the Attention-Transfer Attack (ATA), which hides harmful instructions inside a meta task with competing objectives. We provide a theoretical perspective based on reward hacking to explain why this attack succeeds. To improve cross-model transferability, we further introduce a lightweight transfer-enhancement algorithm combined with a simple repetition strategy that jointly bypasses both input-level and output-level filters without model-specific fine-tuning. Empirically, we show that adversarial images optimized for one vision encoder transfer broadly to unseen VLMs, indicating that shared visual representations create a cross-model safety vulnerability. Overall, MFA achieves a 58.5% success rate and consistently outperforms existing methods. On state-of-the-art commercial models, MFA reaches a 52.8% success rate, surpassing the second-best attack by 34%. These results challenge the perceived robustness of current defense mechanisms and highlight persistent safety weaknesses in modern VLMs. Code: https://github.com/cure-lab/MultiFacetedAttack

</details>


### [17] [ART: A Graph-based Framework for Investigating Illicit Activity in Monero via Address-Ring-Transaction Structures](https://arxiv.org/abs/2511.16192)
*Andrea Venturi,Imanol Jerico-Yoldi,Francesco Zola,Raul Orduna*

Main category: cs.CR

TL;DR: 本文提出了一种基于图的方法来分析Monero交易中的犯罪活动模式，通过构建地址-环-交易图来提取结构性和时间性特征，并训练机器学习模型检测类似的犯罪行为模式。


<details>
  <summary>Details</summary>
Motivation: 随着执法机构在加密货币取证方面的进步，犯罪分子越来越多地使用Monero等隐私保护加密货币来隐藏非法资金流动。由于Monero的强隐私保护和不可追踪特性，传统的区块链分析变得无效，因此理解犯罪分子在Monero中的行为模式对于支持未来调查策略和打击非法活动至关重要。

Method: 采用基于图的方法，从已发现的犯罪活动相关的Monero交易中构建地址-环-交易图，提取结构性和时间性特征，并使用这些特征训练机器学习模型来检测类似的犯罪行为模式。

Result: 开发了一种能够检测Monero交易中犯罪行为模式的分析工具，这是开发支持隐私保护区块链生态系统调查工作的分析工具的第一步。

Conclusion: 这项工作代表了在隐私保护区块链生态系统中开发支持调查工作的分析工具的重要初步步骤，为未来更有效的犯罪活动检测和调查策略提供了基础。

Abstract: As Law Enforcement Agencies advance in cryptocurrency forensics, criminal actors aiming to conceal illicit fund movements increasingly turn to "mixin" services or privacy-based cryptocurrencies. Monero stands out as a leading choice due to its strong privacy preserving and untraceability properties, making conventional blockchain analysis ineffective. Understanding the behavior and operational patterns of criminal actors within Monero is therefore challenging and it is essential to support future investigative strategies and disrupt illicit activities. In this work, we propose a case study in which we leverage a novel graph-based methodology to extract structural and temporal patterns from Monero transactions linked to already discovered criminal activities. By building Address-Ring-Transaction graphs from flagged transactions, we extract structural and temporal features and use them to train Machine Learning models capable of detecting similar behavioral patterns that could highlight criminal modus operandi. This represents a first partial step toward developing analytical tools that support investigative efforts in privacy-preserving blockchain ecosystems

</details>


### [18] [PSM: Prompt Sensitivity Minimization via LLM-Guided Black-Box Optimization](https://arxiv.org/abs/2511.16209)
*Huseein Jawad,Nicolas Brunel*

Main category: cs.CR

TL;DR: 本文提出了一种通过添加保护性文本层来强化系统提示的新框架，使用LLM作为优化器来搜索最佳保护层，在减少提示泄露的同时保持任务效用。


<details>
  <summary>Details</summary>
Motivation: 系统提示包含专有逻辑和敏感信息，容易受到提取攻击，现有防御机制存在计算开销大或无法应用于黑盒API模型的问题。

Method: 采用盾牌附加的轻量级方法，将提示强化形式化为效用约束优化问题，使用LLM作为优化器搜索可能的最佳保护层。

Result: 优化的SHIELDs显著减少了对全面提取攻击的提示泄露，优于现有基线防御，且不损害模型预期功能。

Conclusion: 本文为在LLM安全日益严峻的背景下开发鲁棒、效用感知的防御提供了新范式。

Abstract: System prompts are critical for guiding the behavior of Large Language Models (LLMs), yet they often contain proprietary logic or sensitive information, making them a prime target for extraction attacks. Adversarial queries can successfully elicit these hidden instructions, posing significant security and privacy risks. Existing defense mechanisms frequently rely on heuristics, incur substantial computational overhead, or are inapplicable to models accessed via black-box APIs. This paper introduces a novel framework for hardening system prompts through shield appending, a lightweight approach that adds a protective textual layer to the original prompt. Our core contribution is the formalization of prompt hardening as a utility-constrained optimization problem. We leverage an LLM-as-optimizer to search the space of possible SHIELDs, seeking to minimize a leakage metric derived from a suite of adversarial attacks, while simultaneously preserving task utility above a specified threshold, measured by semantic fidelity to baseline outputs. This black-box, optimization-driven methodology is lightweight and practical, requiring only API access to the target and optimizer LLMs. We demonstrate empirically that our optimized SHIELDs significantly reduce prompt leakage against a comprehensive set of extraction attacks, outperforming established baseline defenses without compromising the model's intended functionality. Our work presents a paradigm for developing robust, utility-aware defenses in the escalating landscape of LLM security. The code is made public on the following link: https://github.com/psm-defense/psm

</details>


### [19] [Q-MLLM: Vector Quantization for Robust Multimodal Large Language Model Security](https://arxiv.org/abs/2511.16229)
*Wei Zhao,Zhe Li,Yige Li,Jun Sun*

Main category: cs.CR

TL;DR: Q-MLLM通过两级向量量化构建离散瓶颈来防御多模态大语言模型的视觉对抗攻击，在保持模型性能的同时显著提升防御成功率。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在跨模态理解方面表现出色，但视觉输入存在对抗攻击漏洞，这源于视觉表示的连续性和文本安全机制向视觉内容迁移不足的问题。

Method: 提出Q-MLLM架构，集成像素-补丁和语义两级向量量化，创建离散瓶颈来阻断攻击路径；采用两阶段训练方法确保鲁棒学习同时保持模型效用。

Result: Q-MLLM在越狱攻击和有害图像攻击上取得显著更好的防御成功率，对越狱攻击达到100%防御成功率（除一个争议案例），在多个效用基准上保持竞争力且推理开销最小。

Conclusion: 向量量化是构建安全多模态AI系统的有效防御机制，无需昂贵的安全特定微调或检测开销。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities in cross-modal understanding, but remain vulnerable to adversarial attacks through visual inputs despite robust textual safety mechanisms. These vulnerabilities arise from two core weaknesses: the continuous nature of visual representations, which allows for gradient-based attacks, and the inadequate transfer of text-based safety mechanisms to visual content. We introduce Q-MLLM, a novel architecture that integrates two-level vector quantization to create a discrete bottleneck against adversarial attacks while preserving multimodal reasoning capabilities. By discretizing visual representations at both pixel-patch and semantic levels, Q-MLLM blocks attack pathways and bridges the cross-modal safety alignment gap. Our two-stage training methodology ensures robust learning while maintaining model utility. Experiments demonstrate that Q-MLLM achieves significantly better defense success rate against both jailbreak attacks and toxic image attacks than existing approaches. Notably, Q-MLLM achieves perfect defense success rate (100\%) against jailbreak attacks except in one arguable case, while maintaining competitive performance on multiple utility benchmarks with minimal inference overhead. This work establishes vector quantization as an effective defense mechanism for secure multimodal AI systems without requiring expensive safety-specific fine-tuning or detection overhead. Code is available at https://github.com/Amadeuszhao/QMLLM.

</details>


### [20] [The Shawshank Redemption of Embodied AI: Understanding and Benchmarking Indirect Environmental Jailbreaks](https://arxiv.org/abs/2511.16347)
*Chunyang Li,Zifeng Kang,Junwei Zhang,Zhuo Ma,Anda Cheng,Xinghua Li,Jianfeng Ma*

Main category: cs.CR

TL;DR: 本文首次提出间接环境越狱攻击，通过将恶意指令注入环境来攻击具身AI，开发了自动攻击生成框架和基准测试框架，并在大量任务场景中验证了攻击有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注直接越狱攻击，但忽视了间接越狱的可能性。具身AI对环境指令的盲目信任可能被攻击者利用，带来严重安全风险。

Method: 提出间接环境越狱攻击概念，开发SHAWSHANK自动攻击生成框架和SHAWSHANK-FORGE基准生成框架，构建SHAWSHANK-BENCH基准测试集。

Result: 在3,957个任务场景组合中，SHAWSHANK优于11种现有方法，成功攻破所有6个测试的视觉语言模型，现有防御措施只能部分缓解攻击。

Conclusion: 间接环境越狱是具身AI面临的新型安全威胁，需要开发更有效的防御机制，已向相关厂商负责任地披露发现。

Abstract: The adoption of Vision-Language Models (VLMs) in embodied AI agents, while being effective, brings safety concerns such as jailbreaking. Prior work have explored the possibility of directly jailbreaking the embodied agents through elaborated multi-modal prompts. However, no prior work has studied or even reported indirect jailbreaks in embodied AI, where a black-box attacker induces a jailbreak without issuing direct prompts to the embodied agent. In this paper, we propose, for the first time, indirect environmental jailbreak (IEJ), a novel attack to jailbreak embodied AI via indirect prompt injected into the environment, such as malicious instructions written on a wall. Our key insight is that embodied AI does not ''think twice'' about the instructions provided by the environment -- a blind trust that attackers can exploit to jailbreak the embodied agent. We further design and implement open-source prototypes of two fully-automated frameworks: SHAWSHANK, the first automatic attack generation framework for the proposed attack IEJ; and SHAWSHANK-FORGE, the first automatic benchmark generation framework for IEJ. Then, using SHAWSHANK-FORGE, we automatically construct SHAWSHANK-BENCH, the first benchmark for indirectly jailbreaking embodied agents. Together, our two frameworks and one benchmark answer the questions of what content can be used for malicious IEJ instructions, where they should be placed, and how IEJ can be systematically evaluated. Evaluation results show that SHAWSHANK outperforms eleven existing methods across 3,957 task-scene combinations and compromises all six tested VLMs. Furthermore, current defenses only partially mitigate our attack, and we have responsibly disclosed our findings to all affected VLM vendors.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [21] [Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization](https://arxiv.org/abs/2511.15714)
*Ariel Kamen,Yakov Kamen*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型的非结构化文本分类集成框架(eLLM)，通过整合多个模型来解决单个系统的常见弱点，在IAB分层分类法上实现了比最强单模型提升65%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 解决单个大语言模型在文本分类中存在的不足，包括不一致性、幻觉、类别膨胀和误分类等问题，提高分类的可靠性和准确性。

Method: 开发了集成大语言模型(eLLM)框架，通过数学建模集体决策过程并建立原则性聚合标准，在零样本条件下评估了10个最先进的LLM，使用IAB分层分类法对8,660个人工标注样本进行分类。

Result: eLLM框架在F1分数上比最强单模型提升了65%，实现了接近人类专家水平的性能，同时提高了鲁棒性和准确性，显著减少了对人类专家标注的依赖。

Conclusion: eLLM框架为基于分类法的分类提供了一个可扩展且可靠的解决方案，通过模型多样性实现了性能突破，有望显著降低对人工标注的依赖。

Abstract: This study introduces an ensemble framework for unstructured text categorization using large language models (LLMs). By integrating multiple models, the ensemble large language model (eLLM) framework addresses common weaknesses of individual systems, including inconsistency, hallucination, category inflation, and misclassification. The eLLM approach yields a substantial performance improvement of up to 65\% in F1-score over the strongest single model. We formalize the ensemble process through a mathematical model of collective decision-making and establish principled aggregation criteria. Using the Interactive Advertising Bureau (IAB) hierarchical taxonomy, we evaluate ten state-of-the-art LLMs under identical zero-shot conditions on a human-annotated corpus of 8{,}660 samples. Results show that individual models plateau in performance due to the compression of semantically rich text into sparse categorical representations, while eLLM improves both robustness and accuracy. With a diverse consortium of models, eLLM achieves near human-expert-level performance, offering a scalable and reliable solution for taxonomy-based classification that may significantly reduce dependence on human expert labeling.

</details>


### [22] [Graph-Memoized Reasoning: Foundations Structured Workflow Reuse in Intelligent Systems](https://arxiv.org/abs/2511.15715)
*Yash Raj Singh*

Main category: cs.AI

TL;DR: 论文提出了图记忆推理框架，通过将推理工作流表示为图结构记忆，实现跨任务的子图复用，减少计算冗余，提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型推理系统经常在不同任务中重复计算相似的推理步骤，浪费计算资源、增加推理延迟并限制可重现性，因此需要能够回忆和重用先前计算痕迹的持久推理机制。

Method: 引入图记忆推理框架，将推理工作流表示为图结构记忆，通过结构和语义相似性检索过去的决策图，实现跨新推理任务的子图组合式复用。

Result: 提出了最小化总推理成本并正则化存储与生成工作流之间不一致性的优化目标，为智能系统中的效率-一致性权衡提供理论基础，并设计了相应的概念评估协议。

Conclusion: 该框架为可解释、成本高效和自我改进的推理架构奠定了基础，朝着大规模智能系统中的持久记忆迈出了重要一步。

Abstract: Modern large language model-based reasoning systems frequently recompute similar reasoning steps across tasks, wasting computational resources, inflating inference latency, and limiting reproducibility. These inefficiencies underscore the need for persistent reasoning mechanisms that can recall and reuse prior computational traces.
  We introduce Graph-Memoized Reasoning, a formal framework for representing, storing, and reusing reasoning workflows as graph-structured memory. By encoding past decision graphs and retrieving them through structural and semantic similarity, our approach enables compositional reuse of subgraphs across new reasoning tasks.
  We formulate an optimization objective that minimizes total reasoning cost regularized by inconsistency between stored and generated workflows, providing a theoretical foundation for efficiency-consistency trade-offs in intelligent systems. We outline a conceptual evaluation protocol aligned with the proposed optimization objective.
  This framework establishes the groundwork for interpretable, cost-efficient, and self-improving reasoning architectures, offering a step toward persistent memory in large-scale agentic systems.

</details>


### [23] [MACIE: Multi-Agent Causal Intelligence Explainer for Collective Behavior Understanding](https://arxiv.org/abs/2511.15716)
*Abraham Itzhak Weinberg*

Main category: cs.AI

TL;DR: MACIE是一个多智能体因果智能解释框架，通过结合结构因果模型、干预性反事实和Shapley值，为多智能体强化学习系统提供全面解释，包括个体因果贡献、系统级涌现智能和可操作的自然语言解释。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体强化学习系统在安全关键应用中的使用，理解智能体决策原因和集体行为实现方式变得至关重要。现有的可解释AI方法在多智能体环境中存在不足，无法将集体结果归因于个体、量化涌现行为或捕捉复杂交互。

Method: MACIE框架结合结构因果模型、干预性反事实和Shapley值，通过干预性归因分数评估每个智能体的因果贡献，使用协同指标分离集体效应与个体贡献来量化系统级涌现智能，并生成综合因果洞察的自然语言叙述。

Result: 在四种MARL场景（合作、竞争和混合动机）中的评估显示：准确的结果归因（平均φ_i=5.07，标准差<0.05）、合作任务中检测到正向涌现（协同指数高达0.461）、高效计算（CPU上每个数据集0.79秒）。

Conclusion: MACIE独特地结合了因果严谨性、涌现量化和多智能体支持，同时保持实时使用的实用性，这代表了向可解释、可信赖和可问责的多智能体AI迈出的一步。

Abstract: As Multi Agent Reinforcement Learning systems are used in safety critical applications. Understanding why agents make decisions and how they achieve collective behavior is crucial. Existing explainable AI methods struggle in multi agent settings. They fail to attribute collective outcomes to individuals, quantify emergent behaviors, or capture complex interactions. We present MACIE Multi Agent Causal Intelligence Explainer, a framework combining structural causal models, interventional counterfactuals, and Shapley values to provide comprehensive explanations. MACIE addresses three questions. First, each agent's causal contribution using interventional attribution scores. Second, system level emergent intelligence through synergy metrics separating collective effects from individual contributions. Third, actionable explanations using natural language narratives synthesizing causal insights. We evaluate MACIE across four MARL scenarios: cooperative, competitive, and mixed motive. Results show accurate outcome attribution, mean phi_i equals 5.07, standard deviation less than 0.05, detection of positive emergence in cooperative tasks, synergy index up to 0.461, and efficient computation, 0.79 seconds per dataset on CPU. MACIE uniquely combines causal rigor, emergence quantification, and multi agent support while remaining practical for real time use. This represents a step toward interpretable, trustworthy, and accountable multi agent AI.

</details>


### [24] [How Modality Shapes Perception and Reasoning: A Study of Error Propagation in ARC-AGI](https://arxiv.org/abs/2511.15717)
*Bo Wen,Chen Wang,Erhan Bilal*

Main category: cs.AI

TL;DR: 本文研究了不同模态（文本和图像）在ARC-AGI任务中对感知和推理的影响，发现结构化文本能精确定位稀疏特征，图像能捕捉2D形状但对分辨率敏感，结合两者可提升执行效果。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的系统在ARC-AGI任务中缺乏对编码如何影响模型感知的原则性理解，以及如何区分指令错误和执行错误。作者假设不同模态会施加感知瓶颈，从而影响网格特征的可靠感知。

Method: 使用加权集合分歧度量和两阶段推理流程，在九种文本和图像模态中分离感知与推理，比较不同表示方式对模型性能的影响。

Result: 结构化文本在稀疏特征坐标定位上更精确，图像能捕捉2D形状但对分辨率敏感，结合文本和图像能提升约8个感知点和0.20的中位相似度。

Conclusion: 将表示与transformer的归纳偏置对齐，并实现文本和图像之间的交叉验证，可以在不改变底层模型的情况下产生更准确的指令和更可靠的执行。

Abstract: ARC-AGI and ARC-AGI-2 measure generalization-through-composition on small color-quantized grids, and their prize competitions make progress on these harder held-out tasks a meaningful proxy for systematic generalization. Recent instruction-first systems translate grids into concise natural-language or DSL rules executed in generate-execute-select loops, yet we lack a principled account of how encodings shape model perception and how to separate instruction errors from execution errors. We hypothesize that modality imposes perceptual bottlenecks -- text flattens 2D structure into 1D tokens while images preserve layout but can introduce patch-size aliasing -- thereby shaping which grid features are reliably perceived. To test this, we isolate perception from reasoning across nine text and image modalities using a weighted set-disagreement metric and a two-stage reasoning pipeline, finding that structured text yields precise coordinates on sparse features, images capture 2D shapes yet are resolution-sensitive, and combining them improves execution (about 8 perception points; about 0.20 median similarity). Overall, aligning representations with transformer inductive biases and enabling cross-validation between text and image yields more accurate instructions and more reliable execution without changing the underlying model.

</details>


### [25] [ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset](https://arxiv.org/abs/2511.15718)
*Chen Yang,Ran Le,Yun Xing,Zhenwei An,Zongchao Chen,Wayne Xin Zhao,Yang Song,Tao Zhang*

Main category: cs.AI

TL;DR: ToolMind是一个大规模、高质量的工具智能体数据集，包含16万合成数据实例和20万增强开源数据实例，通过多智能体框架模拟真实用户-助手-工具交互，并采用细粒度轮次级过滤确保数据质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要在轨迹级别验证正确性，可能忽略轮次级错误，这些错误在训练过程中会传播并降低模型性能。高质量轨迹的稀缺性限制了更强LLM智能体的发展。

Method: 首先基于参数相关性构建函数图，然后使用多智能体框架模拟真实用户-助手-工具交互。除了轨迹级验证，还采用细粒度轮次级过滤来移除错误或次优步骤。

Result: 在ToolMind上微调的模型在多个基准测试中相比基线表现出显著改进。

Conclusion: ToolMind通过大规模高质量数据集和细粒度验证方法，有效缓解了训练过程中的错误放大问题，同时保留了自我纠正推理信号，为稳健的工具使用学习提供了支持。

Abstract: Large Language Model (LLM) agents have developed rapidly in recent years to solve complex real-world problems using external tools. However, the scarcity of high-quality trajectories still hinders the development of stronger LLM agents. Most existing works on multi-turn dialogue synthesis validate correctness only at the trajectory level, which may overlook turn-level errors that can propagate during training and degrade model performance. To address these limitations, we introduce ToolMind, a large-scale, high-quality tool-agentic dataset with 160k synthetic data instances generated using over 20k tools and 200k augmented open-source data instances. Our data synthesis pipeline first constructs a function graph based on parameter correlations and then uses a multi-agent framework to simulate realistic user-assistant-tool interactions. Beyond trajectory-level validation, we employ fine-grained turn-level filtering to remove erroneous or suboptimal steps, ensuring that only high-quality reasoning traces are retained. This approach mitigates error amplification during training while preserving self-corrective reasoning signals essential for robust tool-use learning. Models fine-tuned on ToolMind show significant improvements over baselines on several benchmarks.

</details>


### [26] [Chain of Summaries: Summarization Through Iterative Questioning](https://arxiv.org/abs/2511.15719)
*William Brach,Lukas Galke Poech*

Main category: cs.AI

TL;DR: 提出Chain of Summaries (CoS)方法，通过类似黑格尔辩证法的迭代过程生成信息密集的通用摘要，使网页内容更易于LLM消化，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLM难以消化网页内容的问题，因为网页格式不友好且受限于上下文长度，需要生成信息密集的通用摘要。

Method: 采用Chain of Summaries (CoS)方法，受黑格尔辩证法启发，通过初始摘要（正题）、质疑找出局限性（反题）、生成通用摘要（合题）的迭代过程。

Result: 在TriviaQA、TruthfulQA和SQUAD数据集上，CoS比零样本LLM基线提升66%，比专业摘要方法如BRIO和PEGASUS提升27%，摘要更高效且与下游LLM无关。

Conclusion: CoS为网站维护者提供了一种使内容更易于LLM访问的吸引人选择，同时保留了人工监督的可能性。

Abstract: Large Language Models (LLMs) are increasingly using external web content. However, much of this content is not easily digestible by LLMs due to LLM-unfriendly formats and limitations of context length. To address this issue, we propose a method for generating general-purpose, information-dense summaries that act as plain-text repositories of web content. Inspired by Hegel's dialectical method, our approach, denoted as Chain of Summaries (CoS), iteratively refines an initial summary (thesis) by identifying its limitations through questioning (antithesis), leading to a general-purpose summary (synthesis) that can satisfy current and anticipate future information needs. Experiments on the TriviaQA, TruthfulQA, and SQUAD datasets demonstrate that CoS outperforms zero-shot LLM baselines by up to 66% and specialized summarization methods such as BRIO and PEGASUS by up to 27%. CoS-generated summaries yield higher Q&A performance compared to the source content, while requiring substantially fewer tokens and being agnostic to the specific downstream LLM. CoS thus resembles an appealing option for website maintainers to make their content more accessible for LLMs, while retaining possibilities for human oversight.

</details>


### [27] [Automated Hazard Detection in Construction Sites Using Large Language and Vision-Language Models](https://arxiv.org/abs/2511.15720)
*Islem Sahraoui*

Main category: cs.AI

TL;DR: 该论文提出了一种多模态AI框架，结合文本和图像分析来识别建筑工地的安全隐患。通过两个案例研究评估了大型语言模型和视觉语言模型在自动危险识别中的能力。


<details>
  <summary>Details</summary>
Motivation: 在建筑工地等安全关键环境中，事故数据通常以多种格式存在（如书面报告、检查记录和现场图像），传统方法难以综合识别危险。

Method: 第一个案例研究使用GPT 4o和GPT 4o mini从28,000份OSHA事故报告中提取结构化见解；第二个案例研究使用Molmo 7B和Qwen2 VL 2B模型在ConstructionSite10k数据集上进行规则级安全违规检测。

Result: 尽管模型规模较小，Molmo 7B和Qwen2 VL 2B在某些提示配置下表现出竞争力，证明了低资源多模态系统用于规则感知安全监控的可行性。

Conclusion: 多模态AI框架能够有效结合文本和视觉数据，为建筑安全监控提供可行的解决方案，特别是在资源受限的情况下。

Abstract: This thesis explores a multimodal AI framework for enhancing construction safety through the combined analysis of textual and visual data. In safety-critical environments such as construction sites, accident data often exists in multiple formats, such as written reports, inspection records, and site imagery, making it challenging to synthesize hazards using traditional approaches. To address this, this thesis proposed a multimodal AI framework that combines text and image analysis to assist in identifying safety hazards on construction sites. Two case studies were consucted to evaluate the capabilities of large language models (LLMs) and vision-language models (VLMs) for automated hazard identification.The first case study introduces a hybrid pipeline that utilizes GPT 4o and GPT 4o mini to extract structured insights from a dataset of 28,000 OSHA accident reports (2000-2025). The second case study extends this investigation using Molmo 7B and Qwen2 VL 2B, lightweight, open-source VLMs. Using the public ConstructionSite10k dataset, the performance of the two models was evaluated on rule-level safety violation detection using natural language prompts. This experiment served as a cost-aware benchmark against proprietary models and allowed testing at scale with ground-truth labels. Despite their smaller size, Molmo 7B and Quen2 VL 2B showed competitive performance in certain prompt configurations, reinforcing the feasibility of low-resource multimodal systems for rule-aware safety monitoring.

</details>


### [28] [Spatial Reasoning in Multimodal Large Language Models: A Survey of Tasks, Benchmarks and Methods](https://arxiv.org/abs/2511.15722)
*Weichen Liu,Qiyao Xue,Haoming Wang,Xiangyu Yin,Boyuan Yang,Wei Gao*

Main category: cs.AI

TL;DR: 本文从认知角度提出了空间智能的分类法，按推理复杂度组织任务，将现有基准映射到该分类法中，分析评估指标和方法，揭示当前模型能力与人类推理之间的差距，并探讨提升空间能力的训练和推理方法。


<details>
  <summary>Details</summary>
Motivation: 空间推理是人类智能的基本方面，但对多模态大语言模型仍是挑战。现有调查通常基于输入模态分类，但作者认为空间能力不仅由输入格式决定，需要从认知角度建立更原则化的分类体系。

Method: 引入基于认知视角的分类法，按推理复杂度组织空间推理任务，将其与认知功能关联；将文本、视觉语言和具身环境中的现有基准映射到该分类法中；分析评估指标和方法论；探讨训练和推理两种提升空间能力的方法。

Result: 建立了认知视角的空间智能分类体系，实现了跨任务的更原则化比较，揭示了当前模型能力与人类推理之间的关键差距，明确了训练和推理方法的互补机制。

Conclusion: 通过从认知角度组织空间智能研究，为领域提供了新的理解框架，为未来研究指明了可操作方向，促进了空间推理能力的系统性发展。

Abstract: Spatial reasoning, which requires ability to perceive and manipulate spatial relationships in the 3D world, is a fundamental aspect of human intelligence, yet remains a persistent challenge for Multimodal large language models (MLLMs). While existing surveys often categorize recent progress based on input modality (e.g., text, image, video, or 3D), we argue that spatial ability is not solely determined by the input format. Instead, our survey introduces a taxonomy that organizes spatial intelligence from cognitive aspect and divides tasks in terms of reasoning complexity, linking them to several cognitive functions. We map existing benchmarks across text only, vision language, and embodied settings onto this taxonomy, and review evaluation metrics and methodologies for assessing spatial reasoning ability. This cognitive perspective enables more principled cross-task comparisons and reveals critical gaps between current model capabilities and human-like reasoning. In addition, we analyze methods for improving spatial ability, spanning both training-based and reasoning-based approaches. This dual perspective analysis clarifies their respective strengths, uncovers complementary mechanisms. By surveying tasks, benchmarks, and recent advances, we aim to provide new researchers with a comprehensive understanding of the field and actionable directions for future research.

</details>


### [29] [Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal Transfer](https://arxiv.org/abs/2511.15741)
*Hyo-Jeong Jang*

Main category: cs.AI

TL;DR: 该论文提出了一种基于一致性引导跨模态转换的不确定性弹性多模态学习方法，通过将异构模态投影到共享潜在空间来缓解模态差距，并在多模态情感识别基准上验证了方法的稳定性、判别能力和对噪声监督的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多模态学习系统面临数据噪声、标签质量低和模态特性异构等不确定性挑战，特别是在人机交互环境中数据质量和标注一致性差异很大，需要开发能够应对这些不确定性的鲁棒学习方法。

Method: 采用一致性引导的跨模态转换框架，利用跨模态语义一致性进行鲁棒表示学习，将异构模态投影到共享潜在空间以缓解模态差距，并探索支持不确定性估计和稳定特征学习的结构关系。

Result: 在多模态情感识别基准测试中，一致性引导的跨模态转换显著提高了模型稳定性、判别能力和对噪声或不完整监督的鲁棒性，潜在空间分析显示即使在挑战性条件下也能捕获可靠的跨模态结构。

Conclusion: 该论文通过整合不确定性建模、语义对齐和数据高效监督，为弹性多模态学习提供了统一视角，为开发可靠和自适应的脑机接口系统提供了实用见解。

Abstract: Multimodal learning systems often face substantial uncertainty due to noisy data, low-quality labels, and heterogeneous modality characteristics. These issues become especially critical in human-computer interaction settings, where data quality, semantic reliability, and annotation consistency vary across users and recording conditions. This thesis tackles these challenges by exploring uncertainty-resilient multimodal learning through consistency-guided cross-modal transfer. The central idea is to use cross-modal semantic consistency as a basis for robust representation learning. By projecting heterogeneous modalities into a shared latent space, the proposed framework mitigates modality gaps and uncovers structural relations that support uncertainty estimation and stable feature learning. Building on this foundation, the thesis investigates strategies to enhance semantic robustness, improve data efficiency, and reduce the impact of noise and imperfect supervision without relying on large, high-quality annotations. Experiments on multimodal affect-recognition benchmarks demonstrate that consistency-guided cross-modal transfer significantly improves model stability, discriminative ability, and robustness to noisy or incomplete supervision. Latent space analyses further show that the framework captures reliable cross-modal structure even under challenging conditions. Overall, this thesis offers a unified perspective on resilient multimodal learning by integrating uncertainty modeling, semantic alignment, and data-efficient supervision, providing practical insights for developing reliable and adaptive brain-computer interface systems.

</details>


### [30] [Build AI Assistants using Large Language Models and Agents to Enhance the Engineering Education of Biomechanics](https://arxiv.org/abs/2511.15752)
*Hanzhi Yan,Qin Lu,Xianqiao Wang,Xiaoming Zhai,Tianming Liu,He Li*

Main category: cs.AI

TL;DR: 该论文提出使用RAG和MAS技术增强LLMs在生物力学教育任务中的表现，通过双模块框架解决概念问题和计算问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在领域特定应用中存在知识差距，处理复杂多步推理问题时性能下降，需要开发专门的教育助手来提升本科生物力学课程学习效果。

Method: 构建双模块框架：1) 使用检索增强生成(RAG)提升概念性判断题的回答准确性和逻辑一致性；2) 构建多智能体系统(MAS)解决需要多步推理和代码执行的计算问题。

Result: RAG显著提升了LLMs在概念问题上的性能和稳定性，超越了原始模型；MAS能够进行多步推理、方程推导、代码执行，并为计算任务生成可解释的解决方案。

Conclusion: RAG和MAS技术有潜力增强LLMs在工程专业课程中的表现，为开发工程教育智能辅导系统提供了有前景的方向。

Abstract: While large language models (LLMs) have demonstrated remarkable versatility across a wide range of general tasks, their effectiveness often diminishes in domain-specific applications due to inherent knowledge gaps. Moreover, their performance typically declines when addressing complex problems that require multi-step reasoning and analysis. In response to these challenges, we propose leveraging both LLMs and AI agents to develop education assistants aimed at enhancing undergraduate learning in biomechanics courses that focus on analyzing the force and moment in the musculoskeletal system of the human body. To achieve our goal, we construct a dual-module framework to enhance LLM performance in biomechanics educational tasks: 1) we apply Retrieval-Augmented Generation (RAG) to improve the specificity and logical consistency of LLM's responses to the conceptual true/false questions; 2) we build a Multi-Agent System (MAS) to solve calculation-oriented problems involving multi-step reasoning and code execution. Specifically, we evaluate the performance of several LLMs, i.e., Qwen-1.0-32B, Qwen-2.5-32B, and Llama-70B, on a biomechanics dataset comprising 100 true/false conceptual questions and problems requiring equation derivation and calculation. Our results demonstrate that RAG significantly enhances the performance and stability of LLMs in answering conceptual questions, surpassing those of vanilla models. On the other hand, the MAS constructed using multiple LLMs demonstrates its ability to perform multi-step reasoning, derive equations, execute code, and generate explainable solutions for tasks that require calculation. These findings demonstrate the potential of applying RAG and MAS to enhance LLM performance for specialized courses in engineering curricula, providing a promising direction for developing intelligent tutoring in engineering education.

</details>


### [31] [Multi-Agent LLM Orchestration Achieves Deterministic, High-Quality Decision Support for Incident Response](https://arxiv.org/abs/2511.15755)
*Philip Drammeh*

Main category: cs.AI

TL;DR: 多智能体编排相比单智能体方法在事故响应中实现了100%可操作建议率，是单智能体方法的80倍改进，且质量零方差，使生产SLA承诺成为可能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在事故响应中具有潜力，但单智能体方法产生模糊、不可用的建议，需要改进响应质量以实现生产部署。

Method: 开发了MyAntFarm.ai可复现容器化框架，通过348次对照试验比较单智能体副驾驶与多智能体系统在相同事故场景下的表现。

Result: 多智能体编排实现100%可操作建议率，而单智能体仅为1.7%；在行动特异性方面改进80倍，解决方案正确性改进140倍，且质量零方差。

Conclusion: 多智能体编排不是性能优化，而是基于LLM的事故响应生产就绪性的必备要求，引入了决策质量（DQ）这一新指标。

Abstract: Large language models (LLMs) promise to accelerate incident response in production systems, yet single-agent approaches generate vague, unusable recommendations. We present MyAntFarm.ai, a reproducible containerized framework demonstrating that multi-agent orchestration fundamentally transforms LLM-based incident response quality. Through 348 controlled trials comparing single-agent copilot versus multi-agent systems on identical incident scenarios, we find that multi-agent orchestration achieves 100% actionable recommendation rate versus 1.7% for single-agent approaches, an 80 times improvement in action specificity and 140 times improvement in solution correctness. Critically, multi-agent systems exhibit zero quality variance across all trials, enabling production SLA commitments impossible with inconsistent single-agent outputs. Both architectures achieve similar comprehension latency (approx.40s), establishing that the architectural value lies in deterministic quality, not speed. We introduce Decision Quality (DQ), a novel metric capturing validity, specificity, and correctness properties essential for operational deployment that existing LLM metrics do not address. These findings reframe multi-agent orchestration from a performance optimization to a production-readiness requirement for LLM-based incident response. All code, Docker configurations, and trial data are publicly available for reproduction.

</details>


### [32] [Balancing Natural Language Processing Accuracy and Normalisation in Extracting Medical Insights](https://arxiv.org/abs/2511.15778)
*Paulina Tworek,Miłosz Bargieł,Yousef Khan,Tomasz Pełech-Pilichowski,Marek Mikołajczyk,Roman Lewandowski,Jose Sousa*

Main category: cs.AI

TL;DR: 比较基于规则的NLP方法和大型语言模型在波兰医院电子健康记录信息提取中的表现，发现规则方法在年龄和性别提取上更准确，而LLM在药物识别方面更好，建议采用混合方法


<details>
  <summary>Details</summary>
Motivation: 解决非英语环境下从非结构化临床文本中提取结构化医疗信息的挑战，特别是在资源稀缺的情况下

Method: 使用基于规则的低计算NLP方法和大型语言模型从波兰医院电子健康记录中提取患者人口统计、临床发现和处方药物信息，并评估文本标准化缺失和翻译导致的信息损失影响

Result: 规则方法在信息检索任务中提供更高准确性，特别是在年龄和性别提取方面；LLM具有更好的适应性和可扩展性，在药物名称识别方面表现优异；翻译对LLM效果有影响

Conclusion: 建议采用混合方法，结合规则系统的精确性和LLM的适应性，为现实医院环境提供更可靠和资源高效的临床NLP解决方案

Abstract: Extracting structured medical insights from unstructured clinical text using Natural Language Processing (NLP) remains an open challenge in healthcare, particularly in non-English contexts where resources are scarce. This study presents a comparative analysis of NLP low-compute rule-based methods and Large Language Models (LLMs) for information extraction from electronic health records (EHR) obtained from the Voivodeship Rehabilitation Hospital for Children in Ameryka, Poland. We evaluate both approaches by extracting patient demographics, clinical findings, and prescribed medications while examining the effects of lack of text normalisation and translation-induced information loss. Results demonstrate that rule-based methods provide higher accuracy in information retrieval tasks, particularly for age and sex extraction. However, LLMs offer greater adaptability and scalability, excelling in drug name recognition. The effectiveness of the LLMs was compared with texts originally in Polish and those translated into English, assessing the impact of translation. These findings highlight the trade-offs between accuracy, normalisation, and computational cost when deploying NLP in healthcare settings. We argue for hybrid approaches that combine the precision of rule-based systems with the adaptability of LLMs, offering a practical path toward more reliable and resource-efficient clinical NLP in real-world hospitals.

</details>


### [33] [IMACT-CXR - An Interactive Multi-Agent Conversational Tutoring System for Chest X-Ray Interpretation](https://arxiv.org/abs/2511.15825)
*Tuan-Anh Le,Anh Mai Vu,David Yang,Akash Awasthi,Hien Van Nguyen*

Main category: cs.AI

TL;DR: IMACT-CXR是一个基于AutoGen的多智能体交互式胸部X光解读教学系统，整合了空间标注、视线分析、知识检索和图像推理功能，通过贝叶斯知识追踪评估学生技能水平并提供个性化教学反馈。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够同时处理学生边界框标注、视线采样和自由文本观察的智能教学系统，通过多智能体协作提供精确的胸部X光解读培训，解决传统教学方法中反馈不及时和个性化不足的问题。

Method: 采用AutoGen框架构建多智能体工作流，包含定位质量评估、苏格拉底式辅导、PubMed证据检索、相似病例推荐等专业智能体，结合贝叶斯知识追踪和肺叶分割模块，实现解剖学感知的视线反馈。

Result: 系统展示了响应式教学流程，具有有界延迟、精确控制答案泄露的能力，初步评估显示在定位和诊断推理方面优于基线方法。

Conclusion: IMACT-CXR为胸部X光解读培训提供了一个可扩展的交互式教学平台，具备向实际住院医师部署的潜力，显著提升了教学效果和个性化学习体验。

Abstract: IMACT-CXR is an interactive multi-agent conversational tutor that helps trainees interpret chest X-rays by unifying spatial annotation, gaze analysis, knowledge retrieval, and image-grounded reasoning in a single AutoGen-based workflow. The tutor simultaneously ingests learner bounding boxes, gaze samples, and free-text observations. Specialized agents evaluate localization quality, generate Socratic coaching, retrieve PubMed evidence, suggest similar cases from REFLACX, and trigger NV-Reason-CXR-3B for vision-language reasoning when mastery remains low or the learner explicitly asks. Bayesian Knowledge Tracing (BKT) maintains skill-specific mastery estimates that drive both knowledge reinforcement and case similarity retrieval. A lung-lobe segmentation module derived from a TensorFlow U-Net enables anatomically aware gaze feedback, and safety prompts prevent premature disclosure of ground-truth labels. We describe the system architecture, implementation highlights, and integration with the REFLACX dataset for real DICOM cases. IMACT-CXR demonstrates responsive tutoring flows with bounded latency, precise control over answer leakage, and extensibility toward live residency deployment. Preliminary evaluation shows improved localization and diagnostic reasoning compared to baselines.

</details>


### [34] [Mini Amusement Parks (MAPs): A Testbed for Modelling Business Decisions](https://arxiv.org/abs/2511.15830)
*Stéphane Aroca-Ouellette,Ian Berlot-Attwell,Panagiotis Lymperopoulos,Abhiramon Rajasekharan,Tongqi Zhu,Herin Kang,Kaheer Suleman,Sam Pasupalak*

Main category: cs.AI

TL;DR: Mini Amusement Parks (MAPs) 是一个游乐园模拟器，用于评估智能体在复杂商业环境中的建模、长期规划和战略决策能力。研究发现人类在简单和中等模式下分别比最先进的LLM智能体表现好6.5倍和9.8倍。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在真实世界决策中面临挑战，现有基准测试孤立评估各项能力，无法全面评估整体决策能力。需要统一环境来评估建模环境、长期规划、空间推理等综合能力。

Method: 开发了Mini Amusement Parks (MAPs) 游乐园模拟器，提供人类基线并全面评估最先进的LLM智能体。

Result: 人类在简单模式下表现优于LLM智能体6.5倍，在中等模式下优于9.8倍。分析显示LLM在长期优化、样本高效学习、空间推理和世界建模方面存在持续弱点。

Conclusion: MAPs通过统一这些挑战，为评估具有适应性决策能力的智能体提供了新的基准基础。

Abstract: Despite rapid progress in artificial intelligence, current systems struggle with the interconnected challenges that define real-world decision making. Practical domains, such as business management, require optimizing an open-ended and multi-faceted objective, actively learning environment dynamics from sparse experience, planning over long horizons in stochastic settings, and reasoning over spatial information. Yet existing human--AI benchmarks isolate subsets of these capabilities, limiting our ability to assess holistic decision-making competence. We introduce Mini Amusement Parks (MAPs), an amusement-park simulator designed to evaluate an agent's ability to model its environment, anticipate long-term consequences under uncertainty, and strategically operate a complex business. We provide human baselines and a comprehensive evaluation of state-of-the-art LLM agents, finding that humans outperform these systems by 6.5x on easy mode and 9.8x on medium mode. Our analysis reveals persistent weaknesses in long-horizon optimization, sample-efficient learning, spatial reasoning, and world modelling. By unifying these challenges within a single environment, MAPs offers a new foundation for benchmarking agents capable of adaptable decision making. Code: https://github.com/Skyfall-Research/MAPs

</details>


### [35] [Step-Audio-R1 Technical Report](https://arxiv.org/abs/2511.15848)
*Fei Tian,Xiangyu Tony Zhang,Yuxin Zhang,Haoyang Zhang,Yuxin Li,Daijiao Liu,Yayue Deng,Donghang Wu,Jun Chen,Liang Zhao,Chengyuan Yao,Hexin Liu,Eng Siong Chng,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.AI

TL;DR: Step-Audio-R1是首个成功解锁音频推理能力的模型，通过模态基础推理蒸馏框架，在音频理解基准测试中超越Gemini 2.5 Pro，性能媲美Gemini 3 Pro。


<details>
  <summary>Details</summary>
Motivation: 解决音频语言模型中存在的困惑现象：推理过程反而降低性能，探索音频智能是否真正受益于深思熟虑。

Method: 提出模态基础推理蒸馏框架，让模型学习生成与音频相关的推理链，真正基于声学特征而非产生脱节的推理过程。

Result: 模型在语音、环境声音和音乐等综合音频理解和推理基准测试中表现出强大的音频推理能力，超越了Gemini 2.5 Pro，性能与Gemini 3 Pro相当。

Conclusion: 推理能力是跨模态可转移的，当适当锚定时，扩展的深思熟虑可以成为音频智能的强大资产，为构建真正多模态推理系统开辟了新途径。

Abstract: Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.

</details>


### [36] [Decomposing Theory of Mind: How Emotional Processing Mediates ToM Abilities in LLMs](https://arxiv.org/abs/2511.15895)
*Ivan Chulo,Ananya Joshi*

Main category: cs.AI

TL;DR: 通过对比激活引导与基线LLMs的激活模式，研究发现语言模型的心智理论能力提升主要依赖于情感理解而非分析推理。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明激活引导能显著改善语言模型的心智理论能力，但其内部机制尚不明确，需要深入探究激活引导如何改变模型内部处理过程。

Method: 使用线性探针分析45种认知动作，在Gemma-3-4B模型上应用对比激活加法引导，并在1000个BigToM前向信念场景中评估。

Result: 信念归因任务准确率从32.5%提升至46.7%，这种改善主要由情感内容处理（情感感知+2.23，情感评价+2.20）驱动，同时抑制分析过程（质疑-0.78，聚合思维-1.59）。

Conclusion: 语言模型成功的心智理论能力主要依赖于情感理解，而非分析推理过程。

Abstract: Recent work shows activation steering substantially improves language models' Theory of Mind (ToM) (Bortoletto et al. 2024), yet the mechanisms of what changes occur internally that leads to different outputs remains unclear. We propose decomposing ToM in LLMs by comparing steered versus baseline LLMs' activations using linear probes trained on 45 cognitive actions. We applied Contrastive Activation Addition (CAA) steering to Gemma-3-4B and evaluated it on 1,000 BigToM forward belief scenarios (Gandhi et al. 2023), we find improved performance on belief attribution tasks (32.5\% to 46.7\% accuracy) is mediated by activations processing emotional content : emotion perception (+2.23), emotion valuing (+2.20), while suppressing analytical processes: questioning (-0.78), convergent thinking (-1.59). This suggests that successful ToM abilities in LLMs are mediated by emotional understanding, not analytical reasoning.

</details>


### [37] [Thinking, Faithful and Stable: Mitigating Hallucinations in LLMs](https://arxiv.org/abs/2511.15921)
*Chelsea Zou,Yiheng Yao,Basant Khalil*

Main category: cs.AI

TL;DR: 开发了一个用于大型语言模型的自校正框架，通过细粒度不确定性信号（自信度对齐和词元级熵峰值）实时检测和缓解多步推理中的幻觉问题，使用强化学习策略改善推理轨迹的准确性和连贯性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在多步推理中产生幻觉的问题，传统方法仅关注最终答案正确性，而忽略了中间推理步骤的可靠性和忠实性。

Method: 利用自信度对齐和词元级熵峰值作为不确定性信号，设计复合奖励函数，通过强化学习策略引导模型生成更稳定准确的推理轨迹。

Result: 实验表明该方法提高了最终答案准确性和推理校准度，消融实验验证了各个信号的有效贡献。

Conclusion: 提出的自校正框架通过实时检测和缓解幻觉，显著改善了大型语言模型在多步推理中的表现，不仅提升了答案准确性，还增强了中间推理步骤的连贯性和忠实性。

Abstract: This project develops a self correcting framework for large language models (LLMs) that detects and mitigates hallucinations during multi-step reasoning. Rather than relying solely on final answer correctness, our approach leverages fine grained uncertainty signals: 1) self-assessed confidence alignment, and 2) token-level entropy spikes to detect unreliable and unfaithful reasoning in real time. We design a composite reward function that penalizes unjustified high confidence and entropy spikes, while encouraging stable and accurate reasoning trajectories. These signals guide a reinforcement learning (RL) policy that makes the model more introspective and shapes the model's generation behavior through confidence-aware reward feedback, improving not just outcome correctness but the coherence and faithfulness of their intermediate reasoning steps. Experiments show that our method improves both final answer accuracy and reasoning calibration, with ablations validating the individual contribution of each signal.

</details>


### [38] [JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation](https://arxiv.org/abs/2511.15958)
*Zhenyu Bi,Gaurav Srivastava,Yang Li,Meng Lu,Swastik Roy,Morteza Ziyadi,Xuan Wang*

Main category: cs.AI

TL;DR: JudgeBoard是一个新的评估框架，直接让模型评估答案正确性，无需额外答案比较。提出了MAJ多智能体评判框架，使用多个小型语言模型协作来接近大型语言模型的判断准确性。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在判断答案正确性方面的能力相比大型语言模型尚不明确，现有基于比较的方法难以实现细粒度和可扩展的推理输出评估。

Method: 提出JudgeBoard评估管道直接查询模型评估答案正确性，并开发MAJ多智能体评判框架，利用多个具有不同推理特征的小型语言模型通过协作审议来提升判断性能。

Result: 实验显示小型语言模型与大型语言模型在独立判断任务中存在显著性能差距，但MAJ框架显著提高了小型语言模型的可靠性和一致性。在MATH数据集上，使用较小模型作为骨干的MAJ表现与较大模型相当甚至更好。

Conclusion: 多智能体小型语言模型系统在判断任务中可能匹配或超越大型语言模型性能，对可扩展和高效评估具有重要意义。

Abstract: While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.

</details>


### [39] [CARE-RAG - Clinical Assessment and Reasoning in RAG](https://arxiv.org/abs/2511.15994)
*Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型在临床环境中检索与推理之间的差距，即使提供权威证据，模型仍会产生错误。作者使用书面暴露疗法指南作为测试平台，提出了评估推理准确性、一致性和忠实度的框架。


<details>
  <summary>Details</summary>
Motivation: 在临床环境中，即使能够获取正确的证据，大型语言模型也不一定能正确推理。这种检索与推理之间的差距可能导致输出不符合结构化协议，存在安全风险。

Method: 使用书面暴露疗法指南作为测试平台，评估模型对临床医生验证问题的响应，提出衡量推理准确性、一致性和忠实度的评估框架。

Result: 研究发现即使提供权威段落，错误仍然存在。检索增强生成可以约束输出，但安全部署需要像评估检索一样严格评估推理。

Conclusion: 在临床环境中部署大型语言模型时，必须同等重视推理评估和检索评估，以确保输出的安全性和可靠性。

Abstract: Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therapy (WET) guidelines as a testbed. In evaluating model responses to curated clinician-vetted questions, we find that errors persist even when authoritative passages are provided. To address this, we propose an evaluation framework that measures accuracy, consistency, and fidelity of reasoning. Our results highlight both the potential and the risks: retrieval-augmented generation (RAG) can constrain outputs, but safe deployment requires assessing reasoning as rigorously as retrieval.

</details>


### [40] [SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model](https://arxiv.org/abs/2511.16018)
*Emanuel C. Silva,Emily S. M. Salum,Gabriel M. Arantes,Matheus P. Pereira,Vinicius F. Oliveira,Alessandro L. Bicho*

Main category: cs.AI

TL;DR: SpellForger是一个允许玩家通过自然语言提示创建自定义法术的游戏，使用BERT模型解释玩家输入并生成平衡的法术参数，验证AI作为直接游戏机制的应用。


<details>
  <summary>Details</summary>
Motivation: 探索AI作为核心游戏共创工具的应用，目前这一领域尚未充分开发，旨在为玩家提供个性化和创造性的独特体验。

Method: 使用监督训练的BERT模型解释玩家自然语言提示，将文本描述映射到法术预设模板并平衡参数（伤害、成本、效果），确保游戏竞争公平性。系统在Unity游戏引擎中开发，AI后端使用Python。

Result: 预期交付一个功能原型，能够实时生成法术并应用于引人入胜的游戏循环中，使玩家创造力成为游戏体验的核心。

Conclusion: 该研究验证了AI作为直接游戏机制的可行性，通过自然语言交互为玩家提供了个性化的游戏创作体验。

Abstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.

</details>


### [41] [An Aligned Constraint Programming Model For Serial Batch Scheduling With Minimum Batch Size](https://arxiv.org/abs/2511.16045)
*Jorge A. Huertas,Pascal Van Hentenryck*

Main category: cs.AI

TL;DR: 提出了一种新的约束规划模型用于串行批处理调度问题，该模型不依赖预定义的虚拟批次集合，而是直接对同族作业序列进行推理，具有更紧凑的表述。


<details>
  <summary>Details</summary>
Motivation: 现有CP模型依赖预定义的虚拟批次集合，这会导致维度灾难并增加问题复杂性。许多实际应用（如半导体制造中的离子注入）要求最小批次大小，需要更有效的解决方案。

Method: 使用关键对齐参数直接对机器上安排的同族作业序列进行推理，采用定制搜索阶段和强化约束传播器推理级别来改进模型。

Result: 在近5000个实例上的计算实验表明，新模型在小到中等规模实例（最多100个作业）上表现优越，在大规模实例（最多500个作业、10个族、10台机器）上能找到比现有方法好25%的解决方案。

Conclusion: 提出的CP模型在串行批处理调度问题中显著优于现有方法，特别是在处理最小批次大小要求时表现出色。

Abstract: In serial batch (s-batch) scheduling, jobs from similar families are grouped into batches and processed sequentially to avoid repetitive setups that are required when processing consecutive jobs of different families. Despite its large success in scheduling, only three Constraint Programming (CP) models have been proposed for this problem considering minimum batch sizes, which is a common requirement in many practical settings, including the ion implantation area in semiconductor manufacturing. These existing CP models rely on a predefined virtual set of possible batches that suffers from the curse of dimensionality and adds complexity to the problem. This paper proposes a novel CP model that does not rely on this virtual set. Instead, it uses key alignment parameters that allow it to reason directly on the sequences of same-family jobs scheduled on the machines, resulting in a more compact formulation. This new model is further improved by exploiting the problem's structure with tailored search phases and strengthened inference levels of the constraint propagators. The extensive computational experiments on nearly five thousand instances compare the proposed models against existing methods in the literature, including mixed-integer programming formulations, tabu search meta-heuristics, and CP approaches. The results demonstrate the superiority of the proposed models on small-to-medium instances with up to 100 jobs, and their ability to find solutions up to 25\% better than the ones produces by existing methods on large-scale instances with up to 500 jobs, 10 families, and 10 machines.

</details>


### [42] [A Hybrid Proactive And Predictive Framework For Edge Cloud Resource Management](https://arxiv.org/abs/2511.16075)
*Hrikshesh Kumar,Anika Garg,Anshul Gupta,Yashika Agarwal*

Main category: cs.AI

TL;DR: 提出了一种结合CNN-LSTM时间序列预测和多智能体深度强化学习的混合架构，用于云边缘工作负载的主动资源管理，通过将预测嵌入DRL状态空间实现智能决策。


<details>
  <summary>Details</summary>
Motivation: 传统云边缘工作负载资源管理过于被动，依赖静态阈值导致资源过度配置或性能下降，需要转向主动解决方案。

Method: 设计混合架构，将CNN-LSTM时间序列预测模型与基于多智能体深度强化学习的编排器结合，将预测结果直接嵌入DRL智能体状态空间。

Result: 测试表明该系统明显优于传统方法，能够有效解决复杂决策问题，同时平衡成本节约、系统健康和用户体验等多个目标。

Conclusion: 通过赋予AI管理器预见能力，系统能够制定长期任务运行计划，在节约成本与保持系统健康、应用快速之间找到最佳平衡点，实现平滑的资源管理路径。

Abstract: Old cloud edge workload resource management is too reactive. The problem with relying on static thresholds is that we are either overspending for more resources than needed or have reduced performance because of their lack. This is why we work on proactive solutions. A framework developed for it stops reacting to the problems but starts expecting them. We design a hybrid architecture, combining two powerful tools: the CNN LSTM model for time series forecasting and an orchestrator based on multi agent Deep Reinforcement Learning In fact the novelty is in how we combine them as we embed the predictive forecast from the CNN LSTM directly into the DRL agent state space. That is what makes the AI manager smarter it sees the future, which allows it to make better decisions about a long term plan for where to run tasks That means finding that sweet spot between how much money is saved while keeping the system healthy and apps fast for users That is we have given it eyes in order to see down the road so that it does not have to lurch from one problem to another it finds a smooth path forward Our tests show our system easily beats the old methods It is great at solving tough problems like making complex decisions and juggling multiple goals at once like being cheap fast and reliable

</details>


### [43] [SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent](https://arxiv.org/abs/2511.16108)
*Shiyi Cao,Dacheng Li,Fangzhou Zhao,Shuo Yuan,Sumanth R. Hegde,Connor Chen,Charlie Ruan,Tyler Griggs,Shu Liu,Eric Tang,Richard Liaw,Philipp Moritz,Matei Zaharia,Joseph E. Gonzalez,Ion Stoica*

Main category: cs.AI

TL;DR: SkyRL-Agent是一个用于高效多轮长视野智能体训练和评估的框架，通过异步调度、轻量级工具集成和灵活后端互操作性，显著提升了训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有智能体训练框架在效率、工具集成和跨框架兼容性方面的不足，开发一个能够支持多轮长视野任务的高效训练框架。

Method: 采用优化的异步流水线调度器（1.55倍加速比）和基于AST的代码搜索工具增强训练配方，结合强化学习训练软件工程智能体SA-SWE-32B。

Result: SA-SWE-32B在SWE-Bench Verified上达到39.4% Pass@1，相比之前模型成本降低超过2倍，且能有效泛化到其他智能体任务。

Conclusion: SkyRL-Agent框架通过技术创新实现了高效的智能体训练，展示了在软件工程领域的显著性能提升和良好的泛化能力，具有广泛的应用前景。

Abstract: We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation. It provides efficient asynchronous dispatching, lightweight tool integration, and flexible backend interoperability, enabling seamless use with existing RL frameworks such as SkyRL-train, VeRL, and Tinker.
  Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning. We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and improve training efficiency. Together, these optimizations enable SA-SWE-32B to reach 39.4% Pass@1 on SWE-Bench Verified with more than 2x cost reduction compared to prior models reaching similar performance. Despite being trained solely on SWE tasks, SA-SWE-32B generalizes effectively to other agentic tasks, including Terminal-Bench, BrowseComp-Plus, and WebArena. We further demonstrate SkyRL-Agent's extensibility through case studies on deep research, computer use, and memory agents, each trained using a different training backend.

</details>


### [44] [Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints](https://arxiv.org/abs/2511.16139)
*Yongnan Jin,Xurui Li,Feng Cao,Liucun Gao,Juanjuan Yao*

Main category: cs.AI

TL;DR: 提出了MR-RML框架，通过GPRC技术解决LLM在医疗领域应用的三个关键对齐挑战：静态评估与动态临床需求的脱节、多源医疗标准适应困难、传统奖励模型无法捕捉多维医疗质量标准。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗实践中具有变革潜力，但实际临床效用受到关键对齐挑战的限制：静态评估基准与动态临床认知需求脱节、难以适应不断发展的多源医疗标准、传统奖励模型无法捕捉细微的多维医疗质量标准。

Method: 提出MR-RML框架，包含三个核心创新：(1) "维度-场景-学科"医疗标准系统，将领域标准嵌入完整训练流程；(2) 独立多维奖励模型，分解评估标准；(3) 几何投影参考约束，将医疗认知逻辑转化为数学正则化。

Result: 在权威医疗基准Healthbench上的广泛评估显示，相比基础LLM Qwen-32B，该方法在完整子集上提升45%，在困难子集上提升85%。在开源LLM中达到SOTA水平，得分分别为62.7（完整子集）和44.7（困难子集），同时优于大多数闭源模型。

Conclusion: MR-RML框架通过结构化医疗标准集成和多维奖励建模，显著提升了LLM在医疗领域的性能表现，为解决医疗AI对齐问题提供了有效解决方案。

Abstract: The integration of large language models (LLMs) into medical practice holds transformative potential, yet their real-world clinical utility remains limited by critical alignment challenges: (1) a disconnect between static evaluation benchmarks and dynamic clinical cognitive needs, (2) difficulties in adapting to evolving, multi-source medical standards, and (3) the inability of conventional reward models to capture nuanced, multi-dimensional medical quality criteria. To address these gaps, we propose MR-RML (Multidimensional Rubric-oriented Reward Model Learning) via GPRC (Geometric Projection Reference Constraints), a novel alignment framework that integrates medical standards into a structured "Dimensions-Scenarios-Disciplines" matrix to guide data generation and model optimization. MR-RML introduces three core innovations: (1) a "Dimensions-Scenarios-Disciplines" medical standard system that embeds domain standards into the full training pipeline; (2) an independent multi-dimensional reward model that decomposes evaluation criteria, shifting from real-time rubric-based scoring to internalized reward modeling for improved consistency and cost-efficiency; (3) geometric projection reference constraints that transform medical cognitive logic into mathematical regularization, aligning scoring gradients with clinical reasoning and enabling synthetic data-driven training. Through extensive evaluations on the authoritative medical benchmark Healthbench, our method yields substantial performance gains over the base LLM Qwen-32B (45% on the full subset and 85% on Hard subset, respectively). It achieves a SOTA among open-source LLMs with scores of 62.7 (full subset) and 44.7 (hard subset), while also outperforming the majority of closed-source models.

</details>


### [45] [FOOTPASS: A Multi-Modal Multi-Agent Tactical Context Dataset for Play-by-Play Action Spotting in Soccer Broadcast Videos](https://arxiv.org/abs/2511.16183)
*Jeremie Ochin,Raphael Chekroun,Bogdan Stanciulescu,Sotiris Manitsaris*

Main category: cs.AI

TL;DR: 本文介绍了FOOTPASS数据集，这是首个用于足球比赛全场逐场动作识别的基准数据集，结合计算机视觉输出和足球战术知识，实现更可靠的逐场数据提取。


<details>
  <summary>Details</summary>
Motivation: 当前足球视频理解方法在构建可靠的逐场数据方面仍不足够，需要结合时空动作检测和多目标跟踪的整合方法。同时，战术建模和轨迹预测等研究进展表明可以利用战术知识作为先验来支持基于计算机视觉的预测。

Method: 引入FOOTPASS数据集，支持在多媒体、多智能体战术背景下开发球员中心动作识别方法，利用计算机视觉任务输出（如跟踪、识别）和足球战术规律等先验知识。

Result: 创建了首个足球比赛全场逐场动作识别基准数据集，能够生成可靠的逐场数据流，为数据驱动的体育分析提供重要输入。

Conclusion: FOOTPASS数据集通过结合计算机视觉和战术知识，实现了更自动化和可靠的足球逐场数据提取，为体育分析应用奠定了基础。

Abstract: Soccer video understanding has motivated the creation of datasets for tasks such as temporal action localization, spatiotemporal action detection (STAD), or multiobject tracking (MOT). The annotation of structured sequences of events (who does what, when, and where) used for soccer analytics requires a holistic approach that integrates both STAD and MOT. However, current action recognition methods remain insufficient for constructing reliable play-by-play data and are typically used to assist rather than fully automate annotation. Parallel research has advanced tactical modeling, trajectory forecasting, and performance analysis, all grounded in game-state and play-by-play data. This motivates leveraging tactical knowledge as a prior to support computer-vision-based predictions, enabling more automated and reliable extraction of play-by-play data. We introduce Footovision Play-by-Play Action Spotting in Soccer Dataset (FOOTPASS), the first benchmark for play-by-play action spotting over entire soccer matches in a multi-modal, multi-agent tactical context. It enables the development of methods for player-centric action spotting that exploit both outputs from computer-vision tasks (e.g., tracking, identification) and prior knowledge of soccer, including its tactical regularities over long time horizons, to generate reliable play-by-play data streams. These streams form an essential input for data-driven sports analytics.

</details>


### [46] [From Performance to Understanding: A Vision for Explainable Automated Algorithm Design](https://arxiv.org/abs/2511.16201)
*Niki van Stein,Anna V. Kononova,Thomas Bäck*

Main category: cs.AI

TL;DR: 本文提出可解释的自动化算法设计愿景，通过结合LLM驱动的算法发现、可解释基准测试和问题类别描述符，实现从盲目搜索到可解释、类别特定算法设计的转变。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的自动化算法设计主要关注性能提升但缺乏可解释性，无法揭示算法为何有效、哪些组件重要或设计选择与问题结构的关系。

Method: 构建三个支柱：LLM驱动的算法变体发现、可解释基准测试（将性能归因于组件和超参数）、问题类别描述符（连接算法行为与问题结构）。

Result: 形成闭环知识循环，使发现、解释和泛化相互加强，产生可重用的科学洞察。

Conclusion: 这种集成将推动领域从盲目搜索转向可解释的、类别特定的算法设计，在加速进展的同时提供关于优化策略何时及为何成功的科学洞察。

Abstract: Automated algorithm design is entering a new phase: Large Language Models can now generate full optimisation (meta)heuristics, explore vast design spaces and adapt through iterative feedback. Yet this rapid progress is largely performance-driven and opaque. Current LLM-based approaches rarely reveal why a generated algorithm works, which components matter or how design choices relate to underlying problem structures. This paper argues that the next breakthrough will come not from more automation, but from coupling automation with understanding from systematic benchmarking. We outline a vision for explainable automated algorithm design, built on three pillars: (i) LLM-driven discovery of algorithmic variants, (ii) explainable benchmarking that attributes performance to components and hyperparameters and (iii) problem-class descriptors that connect algorithm behaviour to landscape structure. Together, these elements form a closed knowledge loop in which discovery, explanation and generalisation reinforce each other. We argue that this integration will shift the field from blind search to interpretable, class-specific algorithm design, accelerating progress while producing reusable scientific insight into when and why optimisation strategies succeed.

</details>


### [47] [Multi-Agent Collaborative Reward Design for Enhancing Reasoning in Reinforcement Learning](https://arxiv.org/abs/2511.16202)
*Pei Yang,Ke Zhang,Ji Wang,Xiao Chen,Yuxin Tang,Eric Yang,Lynn Ai,Bill Shi*

Main category: cs.AI

TL;DR: CRM是一个多智能体协作奖励模型框架，用专业评估者团队替代单一黑盒奖励模型，提高RLHF的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型难以同时优化多个可能冲突的偏好维度（如事实性、帮助性、安全性），且评分透明度有限。

Method: 将偏好评估分解为领域特定的智能体，每个产生部分信号，配合全局评估器。中央聚合器融合这些信号，平衡逐步正确性、多智能体一致性和重复惩罚等因素。

Result: CRM和rewardBench提供了更透明的奖励建模和更稳定优化的实用模块化路径。

Conclusion: 该框架实现了无需额外人工标注的多视角奖励塑造，与标准RL流程兼容。

Abstract: We present CRM (Multi-Agent Collaborative Reward Model), a framework that replaces a single black-box reward model with a coordinated team of specialist evaluators to improve robustness and interpretability in RLHF. Conventional reward models struggle to jointly optimize multiple, sometimes conflicting, preference dimensions (e.g., factuality, helpfulness, safety) and offer limited transparency into why a score is assigned. CRM addresses these issues by decomposing preference evaluation into domain-specific agents that each produce partial signals, alongside global evaluators such as ranker-based and embedding-similarity rewards. A centralized aggregator fuses these signals at each timestep, balancing factors like step-wise correctness, multi-agent agreement, and repetition penalties, yielding a single training reward compatible with standard RL pipelines. The policy is optimized with advantage-based updates (e.g., GAE), while a value model regresses to the aggregated reward, enabling multi-perspective reward shaping without requiring additional human annotations beyond those used to train the evaluators. To support training and assessment, we introduce rewardBench, a benchmark and training suite aligned with the collaborative structure of CRM. Together, CRM and rewardBench provide a practical, modular path to more transparent reward modeling and more stable optimization.

</details>


### [48] [ChemLabs on ChemO: A Multi-Agent System for Multimodal Reasoning on IChO 2025](https://arxiv.org/abs/2511.16205)
*Xu Qiang,Shengyuan Bai,Leqing Chen,Zijing Liu,Yu Li*

Main category: cs.AI

TL;DR: ChemO是一个基于国际化学奥林匹克竞赛2025的新基准测试，通过评估等效重构和结构化视觉增强解决化学问题的自动评估挑战，ChemLabs多智能体框架实现了93.6/100的高分。


<details>
  <summary>Details</summary>
Motivation: 数学和物理的奥林匹克级基准测试已存在，但化学因其独特的多模态符号语言一直是个开放挑战，需要专门的基准来测试AI的化学推理能力。

Method: 提出ChemO基准测试，包含评估等效重构将视觉输出问题转化为可计算格式，结构化视觉增强分离视觉感知与化学推理；开发ChemLabs分层多智能体框架，模拟专家协作。

Result: 结合结构化视觉增强和多智能体系统，在先进多模态模型上实现显著性能提升，最高配置获得93.6/100分，超过人类金牌估计阈值。

Conclusion: ChemO基准和ChemLabs框架为自动化学问题解决设立了新的技术水平，证明了多智能体方法在复杂科学推理任务中的有效性。

Abstract: Olympiad-level benchmarks in mathematics and physics are crucial testbeds for advanced AI reasoning, but chemistry, with its unique multimodal symbolic language, has remained an open challenge. We introduce ChemO, a new benchmark built from the International Chemistry Olympiad (IChO) 2025. ChemO features two key innovations for automated assessment: Assessment-Equivalent Reformulation (AER), which converts problems requiring visual outputs (e.g., drawing molecules) into computationally tractable formats, and Structured Visual Enhancement (SVE), a diagnostic mechanism to disentangle a model's visual perception capabilities from its core chemical reasoning. To tackle this benchmark, we propose ChemLabs, a hierarchical multi-agent framework that mimics human expert collaboration through specialized agents for problem decomposition, perception, reasoning, and auditing. Experiments on state-of-the-art multimodal models demonstrate that combining SVE with our multi-agent system yields dramatic performance gains. Our top configuration achieves a score of 93.6 out of 100, surpassing an estimated human gold medal threshold and establishing a new state-of-the-art in automated chemical problem-solving. ChemO Dataset: https://huggingface.co/datasets/IDEA-AI4SCI/ChemO

</details>


### [49] [FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks](https://arxiv.org/abs/2511.16216)
*Zhen Hao Wong,Jingwen Deng,Hao Liang,Runming He,Chengyu Shen,Wentao Zhang*

Main category: cs.AI

TL;DR: 提出自动化流水线从教育文档中提取高质量QA和VQA对，结合布局感知OCR和基于LLM的语义解析，为LLM训练提供真实教育内容的可扩展替代方案。


<details>
  <summary>Details</summary>
Motivation: 现有指令调优和RL数据集成本高昂且依赖合成样本，存在幻觉和多样性有限问题；教育教材包含丰富高质量人类编写的QA内容但未被充分利用。

Method: 结合布局感知OCR和基于LLM的语义解析，自动化提取教育文档中的QA和VQA对。

Result: 实验表明该方法能产生准确、对齐且低噪声的QA/VQA对。

Conclusion: 该方法实现了真实世界教育内容的可扩展使用，为改进面向推理的LLM训练提供了实用的替代方案。

Abstract: The development of Large Language Models (LLMs) increasingly depends on high-quality supervised data, yet existing instruction-tuning and RL datasets remain costly to curate and often rely on synthetic samples that introduce hallucination and limited diversity. At the same time, textbooks and exercise materials contain abundant, high-quality human-authored Question-Answer(QA) content that remains underexploited due to the difficulty of transforming raw PDFs into AI-ready supervision. Although modern OCR and vision-language models can accurately parse document structure, their outputs lack the semantic alignment required for training. We propose an automated pipeline that extracts well-formed QA and visual-QA (VQA) pairs from educational documents by combining layout-aware OCR with LLM-based semantic parsing. Experiments across diverse document types show that the method produces accurate, aligned, and low-noise QA/VQA pairs. This approach enables scalable use of real-world educational content and provides a practical alternative to synthetic data generation for improving reasoning-oriented LLM training. All code and data-processing pipelines are open-sourced at https://github.com/OpenDCAI/DataFlow.

</details>


### [50] [MuISQA: Multi-Intent Retrieval-Augmented Generation for Scientific Question Answering](https://arxiv.org/abs/2511.16283)
*Zhiyuan Li,Haisheng Yu,Guangchuan Guo,Nan Zhou,Jiajun Zhang*

Main category: cs.AI

TL;DR: 该论文提出了一个多意图科学问答基准MuISQA，并设计了一个意图感知检索框架，通过LLM假设答案、分解意图特定查询，使用RRF聚合重排来提升多意图问题的证据覆盖率和检索准确性。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统通常面向单一意图，无法充分覆盖复杂科学问题中多个子问题所需的异构证据，导致证据覆盖不完整。

Method: 提出意图感知检索框架：利用LLM假设潜在答案，分解为意图特定查询，为每个意图检索支持段落，然后通过RRF聚合重排以平衡不同意图的覆盖并减少冗余。

Result: 在MuISQA基准和其他通用RAG数据集上的实验表明，该方法在检索准确性和证据覆盖率方面持续优于传统方法。

Conclusion: 该方法能有效解决多意图科学问答中的证据覆盖问题，显著提升RAG系统在复杂问题上的表现。

Abstract: Complex scientific questions often entail multiple intents, such as identifying gene mutations and linking them to related diseases. These tasks require evidence from diverse sources and multi-hop reasoning, while conventional retrieval-augmented generation (RAG) systems are usually single-intent oriented, leading to incomplete evidence coverage. To assess this limitation, we introduce the Multi-Intent Scientific Question Answering (MuISQA) benchmark, which is designed to evaluate RAG systems on heterogeneous evidence coverage across sub-questions. In addition, we propose an intent-aware retrieval framework that leverages large language models (LLMs) to hypothesize potential answers, decompose them into intent-specific queries, and retrieve supporting passages for each underlying intent. The retrieved fragments are then aggregated and re-ranked via Reciprocal Rank Fusion (RRF) to balance coverage across diverse intents while reducing redundancy. Experiments on both MuISQA benchmark and other general RAG datasets demonstrate that our method consistently outperforms conventional approaches, particularly in retrieval accuracy and evidence coverage.

</details>


### [51] [OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](https://arxiv.org/abs/2511.16334)
*Kaichen Zhang,Keming Wu,Zuhao Yang,Kairui Hu,Bin Wang,Ziwei Liu,Xingxuan Li,Lidong Bing*

Main category: cs.AI

TL;DR: OpenMMReasoner是一个完全透明的两阶段多模态推理训练方法，包含监督微调(SFT)和强化学习(RL)阶段，在九个多模态推理基准上比Qwen2.5-VL-7B-Instruct基线提升了11.6%。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉推理取得了显著进展，但缺乏透明和可复现的数据整理与训练策略仍然是可扩展研究的主要障碍。

Method: 采用两阶段训练方法：SFT阶段构建87.4万样本的冷启动数据集并进行严格的逐步验证；RL阶段使用7.4万样本数据集在多样化领域进一步优化和稳定推理能力。

Result: 该方法不仅超越了强基线，还突显了数据质量和训练设计对多模态推理性能的关键作用，在九个多模态推理基准上实现了11.6%的改进。

Conclusion: 为未来大规模多模态推理研究建立了坚实的实证基础，所有代码、流程和数据均已开源。

Abstract: Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.

</details>


### [52] [Reducing Instability in Synthetic Data Evaluation with a Super-Metric in MalDataGen](https://arxiv.org/abs/2511.16373)
*Anna Luiza Gomes da Silva,Diego Kreutz,Angelo Diniz,Rodrigo Mansilha,Celso Nobre da Fonseca*

Main category: cs.AI

TL;DR: 本文提出了一个超级度量标准，整合了8个不同保真度维度的指标，为Android恶意软件合成数据质量评估提供更稳定和标准化的方法。


<details>
  <summary>Details</summary>
Motivation: 由于现有评估指标的不稳定性和缺乏标准化，Android恶意软件领域合成数据质量评估面临持续挑战。

Method: 在MalDataGen中集成超级度量标准，聚合四个保真度维度的八个指标，生成单一加权分数。

Result: 涉及十个生成模型和五个平衡数据集的实验表明，超级度量标准比传统指标更稳定和一致，与分类器实际性能的相关性更强。

Conclusion: 超级度量标准为Android恶意软件合成数据质量评估提供了更可靠和标准化的解决方案。

Abstract: Evaluating the quality of synthetic data remains a persistent challenge in the Android malware domain due to instability and the lack of standardization among existing metrics. This work integrates into MalDataGen a Super-Metric that aggregates eight metrics across four fidelity dimensions, producing a single weighted score. Experiments involving ten generative models and five balanced datasets demonstrate that the Super-Metric is more stable and consistent than traditional metrics, exhibiting stronger correlations with the actual performance of classifiers.

</details>


### [53] [Pharos-ESG: A Framework for Multimodal Parsing, Contextual Narration, and Hierarchical Labeling of ESG Report](https://arxiv.org/abs/2511.16417)
*Yan Chen,Yu Zou,Jialei Zeng,Haoran You,Xiaorui Zhou,Aixi Zhong*

Main category: cs.AI

TL;DR: Pharos-ESG是一个统一框架，通过多模态解析、上下文叙述和层次化标注将ESG报告转换为结构化表示，解决了ESG报告因不规则布局和弱结构化内容导致的大规模理解挑战。


<details>
  <summary>Details</summary>
Motivation: ESG报告作为评估企业ESG表现的核心媒介，存在阅读顺序混乱、布局不规则、内容冗长且结构弱化等问题，阻碍了大规模理解。

Method: 整合基于布局流的阅读顺序建模模块、目录锚点引导的层次感知分割模块，以及将视觉元素上下文转换为连贯自然语言的多模态聚合管道。

Result: 在标注基准上的广泛实验表明，Pharos-ESG始终优于专用文档解析系统和通用多模态模型。同时发布了首个大规模公开ESG报告数据集Aurora-ESG。

Conclusion: Pharos-ESG框架能够有效解决ESG报告的结构化表示问题，为金融治理和决策中的ESG整合提供更好支持。

Abstract: Environmental, Social, and Governance (ESG) principles are reshaping the foundations of global financial gover- nance, transforming capital allocation architectures, regu- latory frameworks, and systemic risk coordination mecha- nisms. However, as the core medium for assessing corpo- rate ESG performance, the ESG reports present significant challenges for large-scale understanding, due to chaotic read- ing order from slide-like irregular layouts and implicit hier- archies arising from lengthy, weakly structured content. To address these challenges, we propose Pharos-ESG, a uni- fied framework that transforms ESG reports into structured representations through multimodal parsing, contextual nar- ration, and hierarchical labeling. It integrates a reading-order modeling module based on layout flow, hierarchy-aware seg- mentation guided by table-of-contents anchors, and a multi- modal aggregation pipeline that contextually transforms vi- sual elements into coherent natural language. The framework further enriches its outputs with ESG, GRI, and sentiment labels, yielding annotations aligned with the analytical de- mands of financial research. Extensive experiments on anno- tated benchmarks demonstrate that Pharos-ESG consistently outperforms both dedicated document parsing systems and general-purpose multimodal models. In addition, we release Aurora-ESG, the first large-scale public dataset of ESG re- ports, spanning Mainland China, Hong Kong, and U.S. mar- kets, featuring unified structured representations of multi- modal content, enriched with fine-grained layout and seman- tic annotations to better support ESG integration in financial governance and decision-making.

</details>


### [54] [TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models](https://arxiv.org/abs/2511.16423)
*Li Zhang,Zhongxuan Han,XiaoHua Feng,Jiaming Zhang,Yuyuan Li,Linbo Jiang,Jianan Lin,Chaochao Chen*

Main category: cs.AI

TL;DR: 提出了一种无需训练的单次联邦视觉语言模型适配框架TOFA，通过视觉和文本双管道充分利用预训练模型的通用多模态特征，解决现有方法通信成本高、易受攻击和数据异构性问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦视觉语言模型适配方法需要迭代训练，通信成本高且易受攻击。单次联邦训练技术虽然能减少通信轮次，但在适应视觉语言模型时面临多模态信息利用不足、数据异构性处理不系统、需要额外训练资源等问题。

Method: TOFA框架采用无需训练的方式，包含视觉管道和文本管道。视觉管道使用分层贝叶斯模型学习个性化的类特定原型分布；文本管道评估并全局对齐生成的本地文本提示。通过自适应权重校准机制结合两个模态的预测结果。

Result: 在9个不同联邦设置的数据集上进行广泛实验，证明了TOFA方法的有效性。该方法无需客户端或服务器端的额外训练资源。

Conclusion: TOFA是一种高效轻量的单次联邦视觉语言模型适配框架，能够充分利用预训练模型的多模态特征，有效处理数据异构性，且无需额外训练资源。

Abstract: Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.

</details>


### [55] [From generative AI to the brain: five takeaways](https://arxiv.org/abs/2511.16432)
*Claudius Gros*

Main category: cs.AI

TL;DR: 论文探讨了生成式AI的成功源于明确的生成原则，建议研究这些原则在大脑中的运作机制，并讨论了机器学习研究对神经科学的五个重要启示。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI的成功原则是否适用于大脑认知过程，以及机器学习研究如何为认知神经科学提供新的见解和方法论。

Method: 通过分析生成式AI的生成原则，并讨论机器学习研究中五个关键概念（世界建模的局限性、思维过程生成、注意力机制、神经缩放定律和量化）在神经科学中的潜在应用。

Result: 识别出生成原则在AI系统中的重要性，并提出了将这些原则应用于理解大脑认知过程的框架，展示了机器学习研究对神经科学的重要启示价值。

Conclusion: 生成式AI的生成原则可能在大脑认知过程中发挥作用，机器学习研究为神经科学提供了新的理论框架和研究方向，两者之间的交叉研究具有重要价值。

Abstract: The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research.

</details>


### [56] [PersonaDrift: A Benchmark for Temporal Anomaly Detection in Language-Based Dementia Monitoring](https://arxiv.org/abs/2511.16445)
*Joy Lai,Alex Mihailidis*

Main category: cs.AI

TL;DR: PersonaDrift是一个用于评估检测痴呆症患者日常沟通渐进变化的机器学习方法的合成基准，模拟了60天的互动日志，重点关注情感扁平化和话题偏移两种变化模式。


<details>
  <summary>Details</summary>
Motivation: 痴呆症患者的沟通方式会逐渐变化，但现有计算工具无法有效跟踪这种渐进的行为漂移，需要专门的方法来检测这些细微的长期变化。

Method: 基于护理人员访谈创建合成用户模型，模拟60天互动日志，注入渐进的情感扁平化和话题偏移变化，评估多种异常检测方法包括统计模型、序列模型和监督分类器。

Result: 初步结果显示，情感扁平化在低基线变异性的用户中可用简单统计模型检测，而语义漂移需要时序建模和个性化基线，个性化分类器在所有任务中表现优于通用分类器。

Conclusion: 个性化方法对于检测痴呆症患者的沟通变化至关重要，个体行为上下文在检测渐进变化中发挥关键作用。

Abstract: People living with dementia (PLwD) often show gradual shifts in how they communicate, becoming less expressive, more repetitive, or drifting off-topic in subtle ways. While caregivers may notice these changes informally, most computational tools are not designed to track such behavioral drift over time. This paper introduces PersonaDrift, a synthetic benchmark designed to evaluate machine learning and statistical methods for detecting progressive changes in daily communication, focusing on user responses to a digital reminder system. PersonaDrift simulates 60-day interaction logs for synthetic users modeled after real PLwD, based on interviews with caregivers. These caregiver-informed personas vary in tone, modality, and communication habits, enabling realistic diversity in behavior. The benchmark focuses on two forms of longitudinal change that caregivers highlighted as particularly salient: flattened sentiment (reduced emotional tone and verbosity) and off-topic replies (semantic drift). These changes are injected progressively at different rates to emulate naturalistic cognitive trajectories, and the framework is designed to be extensible to additional behaviors in future use cases. To explore this novel application space, we evaluate several anomaly detection approaches, unsupervised statistical methods (CUSUM, EWMA, One-Class SVM), sequence models using contextual embeddings (GRU + BERT), and supervised classifiers in both generalized and personalized settings. Preliminary results show that flattened sentiment can often be detected with simple statistical models in users with low baseline variability, while detecting semantic drift requires temporal modeling and personalized baselines. Across both tasks, personalized classifiers consistently outperform generalized ones, highlighting the importance of individual behavioral context.

</details>


### [57] [Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes](https://arxiv.org/abs/2511.16548)
*Guanchen Wu,Yuzhang Xie,Huanwei Wu,Zhe He,Hui Shao,Xiao Hu,Carl Yang*

Main category: cs.AI

TL;DR: CLOZE是一个使用大语言模型从临床笔记中自动提取医学实体并整合到分层医学本体中的零样本框架，无需额外训练或标注数据，同时保护患者隐私。


<details>
  <summary>Details</summary>
Motivation: 临床笔记作为富含详细患者观察的非结构化文档，为扩展本体提供了有价值的上下文特定见解，但目前直接利用临床笔记进行本体扩展的研究仍较少。

Method: 利用预训练大语言模型的强大语言理解和广泛生物医学知识，CLOZE有效识别疾病相关概念并捕获复杂层次关系，通过自动移除受保护健康信息来确保患者隐私。

Result: 实验结果表明CLOZE提供了一个准确、可扩展且保护隐私的本体扩展框架，在生物医学研究和临床信息学中具有广泛应用潜力。

Conclusion: CLOZE框架能够有效利用临床笔记扩展医学本体，为零样本、成本效益高且隐私保护的医学知识整合提供了可行解决方案。

Abstract: Integrating novel medical concepts and relationships into existing ontologies can significantly enhance their coverage and utility for both biomedical research and clinical applications. Clinical notes, as unstructured documents rich with detailed patient observations, offer valuable context-specific insights and represent a promising yet underutilized source for ontology extension. Despite this potential, directly leveraging clinical notes for ontology extension remains largely unexplored. To address this gap, we propose CLOZE, a novel framework that uses large language models (LLMs) to automatically extract medical entities from clinical notes and integrate them into hierarchical medical ontologies. By capitalizing on the strong language understanding and extensive biomedical knowledge of pre-trained LLMs, CLOZE effectively identifies disease-related concepts and captures complex hierarchical relationships. The zero-shot framework requires no additional training or labeled data, making it a cost-efficient solution. Furthermore, CLOZE ensures patient privacy through automated removal of protected health information (PHI). Experimental results demonstrate that CLOZE provides an accurate, scalable, and privacy-preserving ontology extension framework, with strong potential to support a wide range of downstream applications in biomedical research and clinical informatics.

</details>


### [58] [Consciousness in Artificial Intelligence? A Framework for Classifying Objections and Constraints](https://arxiv.org/abs/2511.16582)
*Andres Campero,Derek Shiller,Jaan Aru,Jonathan Simon*

Main category: cs.AI

TL;DR: 本文开发了一个分类框架，用于对数字人工智能系统意识可能性的挑战进行分类，区分挑战的粒度级别和力度程度，并应用于14个文献案例。


<details>
  <summary>Details</summary>
Motivation: 为数字人工智能系统意识可能性的辩论提供结构和工具，澄清对计算功能主义和数字意识的不同挑战类型。

Method: 开发了一个分类学框架，基于Marr的层次理论识别挑战的粒度级别，并区分三种力度的挑战：对计算功能主义的挑战、实践性挑战和严格不可能性论证。

Result: 成功应用该框架分析了14个来自科学和哲学文献的突出案例，实现了对意识可能性挑战的系统分类。

Conclusion: 该框架为数字意识辩论提供了结构化的分析工具，有助于区分不同类型的挑战并澄清辩论中的混淆点。

Abstract: We develop a taxonomical framework for classifying challenges to the possibility of consciousness in digital artificial intelligence systems. This framework allows us to identify the level of granularity at which a given challenge is intended (the levels we propose correspond to Marr's levels) and to disambiguate its degree of force: is it a challenge to computational functionalism that leaves the possibility of digital consciousness open (degree 1), a practical challenge to digital consciousness that suggests improbability without claiming impossibility (degree 2), or an argument claiming that digital consciousness is strictly impossible (degree 3)? We apply this framework to 14 prominent examples from the scientific and philosophical literature. Our aim is not to take a side in the debate, but to provide structure and a tool for disambiguating between challenges to computational functionalism and challenges to digital consciousness, as well as between different ways of parsing such challenges.

</details>


### [59] [D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies](https://arxiv.org/abs/2511.16590)
*Sen Chen,Tong Zhao,Yi Bin,Fei Ma,Wenqi Shao,Zheng Wang*

Main category: cs.AI

TL;DR: D-GARA是一个动态基准测试框架，用于评估Android GUI智能体在真实世界异常情况下的鲁棒性，填补了现有静态基准测试无法反映现实复杂性的研究空白。


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体数据集和基准测试大多是静态和理想化的，无法反映真实环境的复杂性和不可预测性，特别是异常情况的存在。

Method: 提出D-GARA框架，引入多种真实世界异常类型（如权限对话框、电池警告、更新提示等），构建包含常用Android应用和嵌入异常的综合基准测试。

Result: 实验表明，在异常丰富的环境中，最先进的GUI智能体性能显著下降，凸显了对鲁棒性学习的迫切需求。

Conclusion: D-GARA是模块化和可扩展的框架，支持无缝集成新任务、异常类型和交互场景，以满足特定的评估目标，推动GUI智能体鲁棒性研究。

Abstract: Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a diverse set of real-world anomalies that GUI agents commonly face in practice, including interruptions such as permission dialogs, battery warnings, and update prompts. Based on D-GARA framework, we construct and annotate a benchmark featuring commonly used Android applications with embedded anomalies to support broader community research. Comprehensive experiments and results demonstrate substantial performance degradation in state-of-the-art GUI agents when exposed to anomaly-rich environments, highlighting the need for robustness-aware learning. D-GARA is modular and extensible, supporting the seamless integration of new tasks, anomaly types, and interaction scenarios to meet specific evaluation goals.

</details>


### [60] [You Only Forward Once: An Efficient Compositional Judging Paradigm](https://arxiv.org/abs/2511.16600)
*Tianlong Zhang,Hongwei Xue,Shilin Yan,Di Wu,Chen Xu,Yunyun Yang*

Main category: cs.AI

TL;DR: YOFO是一个基于模板的多模态大语言模型快速评估方法，通过在单次前向传播中同时验证所有结构化需求，实现了数量级的速度提升，同时保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM评估方法面临基本权衡：适应输出单一分数与MLLM生成性质不符且限制细粒度需求理解，而自回归生成评估分析在高吞吐场景下速度过慢。

Method: 提出YOFO方法，基于自回归模型，接受结构化需求模板，在单次推理步骤中通过读取每个需求相关最终token的logits，为每个需求生成二元是/否决策。

Result: 实验表明YOFO在标准推荐数据集上达到最先进结果，支持依赖感知分析（后续判断基于先前判断），并能从后验思维链中获益。

Conclusion: YOFO通过单次前向传播实现快速评估，在保持可解释性的同时获得数量级速度提升，解决了MLLM评估中的速度与精度权衡问题。

Abstract: Multimodal large language models (MLLMs) show strong potential as judges. However, existing approaches face a fundamental trade-off: adapting MLLMs to output a single score misaligns with the generative nature of MLLMs and limits fine-grained requirement understanding, whereas autoregressively generating judging analyses is prohibitively slow in high-throughput settings. Observing that judgment reduces to verifying whether inputs satisfy a set of structured requirements, we propose YOFO, a template-conditioned method that judges all requirements in a single forward pass. Built on an autoregressive model, YOFO accepts a structured requirement template and, in one inference step, produces a binary yes/no decision for each requirement by reading the logits of the final token associated with that requirement. This design yields orders-of-magnitude speedups while preserving interpretability. Extensive experiments show that YOFO not only achieves state-of-the-art results on standard recommendation datasets, but also supports dependency-aware analysis-where subsequent judgments are conditioned on previous ones-and further benefits from post-hoc CoT.

</details>


### [61] [Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization](https://arxiv.org/abs/2511.16602)
*Yi Zhang,Che Liu,Xiancong Ren,Hanchu Ni,Yingji Zhang,Shuai Zhang,Zeyuan Ding,Jiayu Hu,Haozhe Shan,Junbo Qi,Yan Bai,Dengjie Li,Jiachen Luo,Yidong Wang,Yong Dai,Zenglin Xu,Bin Shen,Qifan Wang,Jian Tang,Xiaozhu Ju*

Main category: cs.AI

TL;DR: 本文提出了Deliberate Practice Policy Optimization (DPPO)框架，通过元认知训练循环解决具身智能中的数据稀缺和算法效率问题，在有限数据下实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 解决具身智能中的两个主要挑战：真实世界数据稀缺昂贵的数据瓶颈，以及现有方法资源消耗大的算法效率问题。

Method: 引入DPPO元认知训练框架，动态交替进行监督微调（能力扩展）和强化学习（技能精炼），实现自动弱点识别和针对性资源分配。

Result: 训练出的Pelican-VL 1.0模型相比基础模型性能提升20.3%，在100B参数规模上超越开源模型10.6%。

Conclusion: DPPO是首个系统性缓解数据和资源瓶颈的框架，使社区能够高效构建通用具身智能体，相关模型和代码已开源。

Abstract: Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop'' training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted resource allocation, specifically designed to maximize learning efficiency from sparse, finite data. Theoretically, DPPO can be formalised as a unified preference-learning framework. Empirically, training a vision-language embodied model with DPPO, referred to as Pelican-VL 1.0, yields a 20.3% performance improvement over the base model and surpasses open-source models at the 100B-parameter scale by 10.6%. We are open-sourcing both the models and code, providing the first systematic framework that alleviates the data and resource bottleneck and enables the community to build versatile embodied agents efficiently.

</details>


### [62] [MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support](https://arxiv.org/abs/2511.16625)
*Elias Hossain,Md Mehedi Hasan Nipu,Maleeha Sheikh,Rajib Rana,Subash Neupane,Niloofar Yousefi*

Main category: cs.AI

TL;DR: MedBayes-Lite是一个轻量级贝叶斯增强框架，用于基于transformer的临床语言模型，旨在产生可靠、不确定性感知的预测，无需重新训练或架构修改。


<details>
  <summary>Details</summary>
Motivation: transformer模型在临床决策支持中具有潜力，但容易过度自信，特别是在需要校准不确定性的模糊医疗案例中。

Method: 集成三个组件：贝叶斯嵌入校准（使用蒙特卡洛dropout）、不确定性加权注意力（对token可靠性进行边缘化）和置信度引导决策塑造（受临床风险最小化启发）。

Result: 在生物医学问答和临床预测基准测试中，MedBayes-Lite持续改善校准和可信度，将过度自信降低32-48%，在模拟临床环境中可防止高达41%的诊断错误。

Conclusion: 该框架在医疗AI系统中实现了可靠的不确定性传播，并提高了可解释性。

Abstract: We propose MedBayes-Lite, a lightweight Bayesian enhancement for transformer-based clinical language models designed to produce reliable, uncertainty-aware predictions. Although transformers show strong potential for clinical decision support, they remain prone to overconfidence, especially in ambiguous medical cases where calibrated uncertainty is critical. MedBayes-Lite embeds uncertainty quantification directly into existing transformer pipelines without any retraining or architectural rewiring, adding no new trainable layers and keeping parameter overhead under 3 percent. The framework integrates three components: (i) Bayesian Embedding Calibration using Monte Carlo dropout for epistemic uncertainty, (ii) Uncertainty-Weighted Attention that marginalizes over token reliability, and (iii) Confidence-Guided Decision Shaping inspired by clinical risk minimization. Across biomedical QA and clinical prediction benchmarks (MedQA, PubMedQA, MIMIC-III), MedBayes-Lite consistently improves calibration and trustworthiness, reducing overconfidence by 32 to 48 percent. In simulated clinical settings, it can prevent up to 41 percent of diagnostic errors by flagging uncertain predictions for human review. These results demonstrate its effectiveness in enabling reliable uncertainty propagation and improving interpretability in medical AI systems.

</details>


### [63] [Enhancing Forex Forecasting Accuracy: The Impact of Hybrid Variable Sets in Cognitive Algorithmic Trading Systems](https://arxiv.org/abs/2511.16657)
*Juan C. King,Jose M. Amigo*

Main category: cs.AI

TL;DR: 本文实现了一个基于人工智能的算法交易系统，专门用于EUR-USD货币对的高频外汇交易，通过整合基本面和技术面特征来评估预测能力。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在外汇市场高频环境中有效交易的AI系统，通过比较基本面和技术面分析方法的预测能力，确定哪种特征类别能提供更可靠的交易信号。

Method: 整合欧元区和美国的关键宏观经济变量（如GDP、失业率）作为基本面特征，结合技术指标（指标、振荡器、斐波那契水平、价格背离）作为技术面特征，构建算法交易系统。

Result: 使用标准机器学习指标评估预测准确性，并通过历史数据回测模拟来评估交易盈利能力和风险。

Conclusion: 通过比较分析确定基本面和技术面特征中哪一类对生成盈利交易信号具有更强和更可靠的预测能力。

Abstract: This paper presents the implementation of an advanced artificial intelligence-based algorithmic trading system specifically designed for the EUR-USD pair within the high-frequency environment of the Forex market. The methodological approach centers on integrating a holistic set of input features: key fundamental macroeconomic variables (for example, Gross Domestic Product and Unemployment Rate) collected from both the Euro Zone and the United States, alongside a comprehensive suite of technical variables (including indicators, oscillators, Fibonacci levels, and price divergences). The performance of the resulting algorithm is evaluated using standard machine learning metrics to quantify predictive accuracy and backtesting simulations across historical data to assess trading profitability and risk. The study concludes with a comparative analysis to determine which class of input features, fundamental or technical, provides greater and more reliable predictive capacity for generating profitable trading signals.

</details>


### [64] [Cognitive Foundations for Reasoning and Their Manifestation in LLMs](https://arxiv.org/abs/2511.16660)
*Priyanka Kargupta,Shuyue Stella Li,Haocheng Wang,Jinu Lee,Shan Chen,Orevaoghene Ahia,Dean Light,Thomas L. Griffiths,Max Kleiman-Weiner,Jiawei Han,Asli Celikyilmaz,Yulia Tsvetkov*

Main category: cs.AI

TL;DR: 该研究通过构建包含28个认知元素的分类法，分析了17个模型和人类在推理过程中的行为差异，发现人类使用层次嵌套和元认知监控，而模型依赖浅层前向链式推理。研究开发了测试时推理指导方法，将复杂问题性能提升达60%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型能解决复杂问题却在简单变体上失败，表明其机制与人类推理根本不同。研究旨在通过认知科学分析揭示模型推理的结构性差异，为开发基于认知机制而非记忆或捷径的模型奠定基础。

Method: 构建28个认知元素的分类法，分析17个模型的17万条推理轨迹和54条人类思维轨迹，进行元分析研究1,598篇LLM推理论文，开发测试时推理指导方法。

Result: 发现人类使用层次嵌套和元认知监控，模型依赖浅层前向链式推理；研究社区关注可量化行为而忽视元认知控制；模型具备成功相关行为但不会自发部署；推理指导方法提升复杂问题性能达60%。

Conclusion: 通过连接认知科学和LLM研究，为开发基于认知机制而非脆弱捷径的模型建立基础，为改进模型能力和大规模测试人类认知理论开辟新方向。

Abstract: Large language models solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. We synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning computational constraints, meta-cognitive controls, knowledge representations, and transformation operations, then analyze their behavioral manifestations in reasoning traces. We propose a fine-grained cognitive evaluation framework and conduct the first large-scale analysis of 170K traces from 17 models across text, vision, and audio modalities, alongside 54 human think-aloud traces, which we make publicly available. Our analysis reveals systematic structural differences: humans employ hierarchical nesting and meta-cognitive monitoring while models rely on shallow forward chaining, with divergence most pronounced on ill-structured problems. Meta-analysis of 1,598 LLM reasoning papers reveals the research community concentrates on easily quantifiable behaviors (sequential organization: 55%, decomposition: 60%) while neglecting meta-cognitive controls (self-awareness: 16%, evaluation: 8%) that correlate with success. Models possess behavioral repertoires associated with success but fail to deploy them spontaneously. Leveraging these patterns, we develop test-time reasoning guidance that automatically scaffold successful structures, improving performance by up to 60% on complex problems. By bridging cognitive science and LLM research, we establish a foundation for developing models that reason through principled cognitive mechanisms rather than brittle spurious reasoning shortcuts or memorization, opening new directions for both improving model capabilities and testing theories of human cognition at scale.

</details>
