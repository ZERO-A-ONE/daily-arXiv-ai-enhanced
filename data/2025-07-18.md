<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 15]
- [cs.CR](#cs.CR) [Total: 10]
- [cs.AI](#cs.AI) [Total: 20]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [A Survey of AIOps in the Era of Large Language Models](https://arxiv.org/abs/2507.12472)
*Lingzhe Zhang,Tong Jia,Mengxi Jia,Yifan Wu,Aiwei Liu,Yong Yang,Zhonghai Wu,Xuming Hu,Philip S. Yu,Ying Li*

Main category: cs.SE

TL;DR: 这是一篇关于大语言模型在IT运维(AIOps)领域应用的综合调研论文，通过分析183篇研究论文，系统性地探讨了LLM在AIOps中的影响、潜力和局限性


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型日益复杂和普及，其在AIOps任务中的应用受到广泛关注，但对LLM在AIOps领域的影响、潜力和局限性缺乏全面理解，现有研究仍处于起步阶段

Method: 对2020年1月至2024年12月期间发表的183篇研究论文进行详细调研分析，围绕四个关键研究问题(RQs)展开：RQ1分析故障数据源的多样性；RQ2探索AIOps任务的演变；RQ3调查基于LLM的方法；RQ4审查评估方法论

Result: 通过分析发现了LLM在AIOps中的最新进展和趋势，包括多样化的故障数据源利用、新兴任务的出现、各种LLM方法的应用，以及针对LLM集成AIOps方法的评估方法论

Conclusion: 识别了现有研究中的空白和不足，并基于调研结果提出了未来探索的有前景方向，为LLM4AIOps领域的发展提供了指导

Abstract: As large language models (LLMs) grow increasingly sophisticated and
pervasive, their application to various Artificial Intelligence for IT
Operations (AIOps) tasks has garnered significant attention. However, a
comprehensive understanding of the impact, potential, and limitations of LLMs
in AIOps remains in its infancy. To address this gap, we conducted a detailed
survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve
outcomes in this domain. We analyzed 183 research papers published between
January 2020 and December 2024 to answer four key research questions (RQs). In
RQ1, we examine the diverse failure data sources utilized, including advanced
LLM-based processing techniques for legacy data and the incorporation of new
data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks,
highlighting the emergence of novel tasks and the publication trends across
these tasks. RQ3 investigates the various LLM-based methods applied to address
AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to
assess LLM-integrated AIOps approaches. Based on our findings, we discuss the
state-of-the-art advancements and trends, identify gaps in existing research,
and propose promising directions for future exploration.

</details>


### [2] [LLM-Powered Quantum Code Transpilation](https://arxiv.org/abs/2507.12480)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 该论文探讨了利用大型语言模型（LLMs）作为量子软件开发工具包（QSDKs）之间的灵活、自动化转译器，以解决跨平台开发的互操作性问题。


<details>
  <summary>Details</summary>
Motivation: 量子计算平台间的多样性导致互操作性和跨平台开发困难，传统基于规则的转译器设计复杂且维护成本高。

Method: 利用LLMs的预训练知识和上下文推理能力，将其定位为编程语言无关的转译器，实现量子程序在不同QSDK间的转换。

Result: 该方法无需手动定义转换规则，提供了可扩展的量子软件可移植性解决方案。

Conclusion: 这项研究为量子计算生态系统中的智能、通用转译迈出了重要一步。

Abstract: There exist various Software Development Kits (SDKs) tailored to different
quantum computing platforms. These are known as Quantum SDKs (QSDKs). Examples
include but are not limited to Qiskit, Cirq, and PennyLane. However, this
diversity presents significant challenges for interoperability and
cross-platform development of hybrid quantum-classical software systems.
Traditional rule-based transpilers for translating code between QSDKs are
time-consuming to design and maintain, requiring deep expertise and rigid
mappings in the source and destination code. In this study, we explore the use
of Large Language Models (LLMs) as a flexible and automated solution.
Leveraging their pretrained knowledge and contextual reasoning capabilities, we
position LLMs as programming language-agnostic transpilers capable of
converting quantum programs from one QSDK to another while preserving
functional equivalence. Our approach eliminates the need for manually defined
transformation rules and offers a scalable solution to quantum software
portability. This work represents a step toward enabling intelligent,
general-purpose transpilation in the quantum computing ecosystem.

</details>


### [3] [Kodezi Chronos: A Debugging-First Language Model for Repository-Scale, Memory-Driven Code Understanding](https://arxiv.org/abs/2507.12482)
*Ishraq Khan,Assad Chowdary,Sharoz Haseeb,Urvish Patel*

Main category: cs.SE

TL;DR: Kodezi Chronos是一种新型架构，用于自主代码理解、调试和维护，支持超长上下文和高效代码推理，显著提升代码可靠性和生产力。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在代码生成和软件自动化中存在上下文限制和缺乏显式代码结构推理的问题。

Method: Kodezi Chronos采用多级嵌入内存引擎，结合向量和图索引，支持高效代码检索和推理。

Result: 在Multi Random Retrieval基准测试中，Chronos比传统方法在错误检测上提升23%，调试周期减少40%。

Conclusion: Kodezi Chronos为自主软件维护和优化生态系统提供了重要进展。

Abstract: Large Language Models (LLMs) have advanced code generation and software
automation, but are fundamentally constrained by limited inference-time context
and lack of explicit code structure reasoning. We introduce Kodezi Chronos, a
next-generation architecture for autonomous code understanding, debugging, and
maintenance, designed to operate across ultra-long contexts comprising entire
codebases, histories, and documentation, all without fixed window limits.
Kodezi Chronos leverages a multi-level embedding memory engine, combining
vector and graph-based indexing with continuous code-aware retrieval. This
enables efficient and accurate reasoning over millions of lines of code,
supporting repository-scale comprehension, multi-file refactoring, and
real-time self-healing actions. Our evaluation introduces a novel Multi Random
Retrieval benchmark, specifically tailored to the software engineering domain.
Unlike classical retrieval benchmarks, this method requires the model to
resolve arbitrarily distant and obfuscated associations across code artifacts,
simulating realistic tasks such as variable tracing, dependency migration, and
semantic bug localization. Chronos outperforms prior LLMs and code models,
demonstrating a 23% improvement in real-world bug detection and reducing
debugging cycles by up to 40% compared to traditional sequence-based
approaches. By natively interfacing with IDEs and CI/CD workflows, Chronos
enables seamless, autonomous software maintenance, elevating code reliability
and productivity while reducing manual effort. These results mark a critical
advance toward self-sustaining, continuously optimized software ecosystems.

</details>


### [4] [A Survey of Reinforcement Learning for Software Engineering](https://arxiv.org/abs/2507.12483)
*Dong Wang,Hanmo You,Lingwei Zhu,Kaiwei Lin,Zheng Chen,Chen Yang,Junji Yu,Zan Wang,Junjie Chen*

Main category: cs.SE

TL;DR: 该论文对强化学习（RL）在软件工程（SE）中的应用进行了首次系统性综述，分析了115篇研究，总结了趋势、分类和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂性和自动化需求的增加，RL在SE中的应用日益广泛，但缺乏系统性综述。

Method: 回顾了115篇同行评审研究，分析了发表趋势、SE主题和RL算法分类，以及数据集使用、模型设计和评估实践。

Result: 提供了RL在SE中的全面映射，总结了当前研究趋势和关键因素。

Conclusion: 提出了未来研究方向，旨在帮助研究人员和实践者推动该领域发展。

Abstract: Reinforcement Learning (RL) has emerged as a powerful paradigm for sequential
decision-making and has attracted growing interest across various domains,
particularly following the advent of Deep Reinforcement Learning (DRL) in 2015.
Simultaneously, the rapid advancement of Large Language Models (LLMs) has
further fueled interest in integrating RL with LLMs to enable more adaptive and
intelligent systems. In the field of software engineering (SE), the increasing
complexity of systems and the rising demand for automation have motivated
researchers to apply RL to a broad range of tasks, from software design and
development to quality assurance and maintenance. Despite growing research in
RL-for-SE, there remains a lack of a comprehensive and systematic survey of
this evolving field. To address this gap, we reviewed 115 peer-reviewed studies
published across 22 premier SE venues since the introduction of DRL. We
conducted a comprehensive analysis of publication trends, categorized SE topics
and RL algorithms, and examined key factors such as dataset usage, model design
and optimization, and evaluation practices. Furthermore, we identified open
challenges and proposed future research directions to guide and inspire ongoing
work in this evolving area. To summarize, this survey offers the first
systematic mapping of RL applications in software engineering, aiming to
support both researchers and practitioners in navigating the current landscape
and advancing the field. Our artifacts are publicly available:
https://github.com/KaiWei-Lin-lanina/RL4SE.

</details>


### [5] [When Retriever Meets Generator: A Joint Model for Code Comment Generation](https://arxiv.org/abs/2507.12558)
*Tien P. T. Le,Anh M. T. Bui,Huy N. D. Pham,Alessio Bucaioni,Phuong T. Nguyen*

Main category: cs.SE

TL;DR: RAGSum是一种基于CodeT5的检索增强方法，通过联合优化检索和生成，提升代码注释的自动生成效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有检索增强方法中检索和生成独立优化导致的噪声传播问题，提高代码注释生成的效率和准确性。

Method: 结合检索和生成，使用CodeT5作为主干网络，通过对比预训练和端到端训练优化检索和生成，并引入轻量级自优化循环。

Result: 在Java、Python、C三个跨语言基准测试中，RAGSum在BLEU、METEOR和ROUGE-L指标上显著优于基线方法。

Conclusion: 紧密耦合检索和生成可以提升注释自动化的上限，未来可进一步复现和进行开发者定性研究。

Abstract: Automatically generating concise, informative comments for source code can
lighten documentation effort and accelerate program comprehension.
Retrieval-augmented approaches first fetch code snippets with existing comments
and then synthesize a new comment, yet retrieval and generation are typically
optimized in isolation, allowing irrelevant neighbors topropagate noise
downstream. To tackle the issue, we propose a novel approach named RAGSum with
the aim of both effectiveness and efficiency in recommendations. RAGSum is
built on top offuse retrieval and generation using a single CodeT5 backbone. We
report preliminary results on a unified retrieval-generation framework built on
CodeT5. A contrastive pre-training phase shapes code embeddings for
nearest-neighbor search; these weights then seed end-to-end training with a
composite loss that (i) rewards accurate top-k retrieval; and (ii) minimizes
comment-generation error. More importantly, a lightweight self-refinement loop
is deployed to polish the final output. We evaluated theframework on three
cross-language benchmarks (Java, Python, C), and compared it with three
well-established baselines. The results show that our approach substantially
outperforms thebaselines with respect to BLEU, METEOR, and ROUTE-L. These
findings indicate that tightly coupling retrieval and generationcan raise the
ceiling for comment automation and motivateforthcoming replications and
qualitative developer studies.

</details>


### [6] [ROSE: Transformer-Based Refactoring Recommendation for Architectural Smells](https://arxiv.org/abs/2507.12561)
*Samal Nursapa,Anastassiya Samuilova,Alessio Bucaioni. Phuong T. Nguyen*

Main category: cs.SE

TL;DR: 本文探讨了使用预训练的Transformer模型（CodeBERT和CodeT5）来基于检测到的架构异味推荐合适的重构方法。CodeT5表现优异，准确率达96.9%，F1分数95.2%。


<details>
  <summary>Details</summary>
Motivation: 现有的工具可以检测架构异味（如God Class、Cyclic Dependency等），但很少提供修复建议。本文旨在填补这一空白。

Method: 将任务定义为三分类问题，并在11,149个开源Java项目中挖掘的200多万个重构实例上对CodeBERT和CodeT5进行微调。

Result: CodeT5表现最佳，准确率达96.9%，F1分数95.2%，优于CodeBERT和传统基线方法。

Conclusion: 基于Transformer的模型能有效弥合异味检测与可操作修复之间的差距，为未来的重构推荐系统奠定基础。所有代码、模型和数据均已开源。

Abstract: Architectural smells such as God Class, Cyclic Dependency, and Hub-like
Dependency degrade software quality and maintainability. Existing tools detect
such smells but rarely suggest how to fix them. This paper explores the use of
pre-trained transformer models--CodeBERT and CodeT5--for recommending suitable
refactorings based on detected smells. We frame the task as a three-class
classification problem and fine-tune both models on over 2 million refactoring
instances mined from 11,149 open-source Java projects. CodeT5 achieves 96.9%
accuracy and 95.2% F1, outperforming CodeBERT and traditional baselines. Our
results show that transformer-based models can effectively bridge the gap
between smell detection and actionable repair, laying the foundation for future
refactoring recommendation systems. We release all code, models, and data under
an open license to support reproducibility and further research.

</details>


### [7] [QSpark: Towards Reliable Qiskit Code Generation](https://arxiv.org/abs/2507.12642)
*Kiana Kheiri,Aamna Aamir,Andriy Miranskyy,Chen Ding*

Main category: cs.SE

TL;DR: 论文研究了如何通过强化学习方法（GRPO和ORPO）优化量子电路的代码生成，在Qiskit HumanEval基准测试中表现优于通用基线模型，但在高级任务上仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 量子电路的代码生成需要更高的容错性，但现有模型（如Granite-20B-Code和StarCoder）生成的Qiskit代码存在缺陷。

Method: 使用两种强化学习方法（GRPO和ORPO）对32B模型进行微调，并利用合成数据集进行训练。

Result: ORPO在Qiskit HumanEval基准测试中达到56.29% Pass@1，GRPO为49%，均优于通用基线；在原始HumanEval中分别为65.90%和63.00%。GRPO在基础任务上表现更好（42/54），ORPO在中等任务上更优（41/68），但均未解决高级任务。

Conclusion: 研究展示了AI辅助量子编程的明显进步，但在高级任务上仍需进一步改进。

Abstract: Quantum circuits must be error-resilient, yet LLMs like Granite-20B-Code and
StarCoder often output flawed Qiskit code. We fine-tuned a 32 B model with two
RL methods, Group Relative Policy Optimization (GRPO) and Odds-Ratio Preference
Optimization (ORPO), using a richly annotated synthetic dataset. On the Qiskit
HumanEval benchmark, ORPO reaches 56.29\% Pass@1 ($\approx+10$ pp over
Granite-8B-QK) and GRPO hits 49\%, both beating all general-purpose baselines;
on the original HumanEval they score 65.90\% and 63.00\%. GRPO excels on basic
tasks (42/54), ORPO on intermediate ones (41/68), and neither solves the five
advanced tasks, highlighting clear gains yet room for progress in AI-assisted
quantum programming.

</details>


### [8] [A Three-Phase Evaluation Approach for new Information and Data Models in the Smart Grid Domain](https://arxiv.org/abs/2507.12649)
*Christine van Stiphoudt,Sergio Potenciano Menci,Gilbert Fridgen*

Main category: cs.SE

TL;DR: 提出了一种结合显式和隐式评估方法的三阶段评估方法，用于智能电网中新设计的信息和数据模型。


<details>
  <summary>Details</summary>
Motivation: 智能电网数字化导致信息交换增加，现有模型不足，需在设计阶段评估新模型以避免潜在问题。

Method: 采用设计科学研究方法，设计三阶段评估方法，结合显式和隐式评估。

Result: 开发了适用于新信息模型和数据模型的评估方法，并以工业灵活性描述为例进行验证。

Conclusion: 该方法填补了智能电网领域新模型评估的空白，并提供了实践经验。

Abstract: The ongoing digitalisation of the smart grid is resulting in an increase in
automated information exchanges across distributed energy systems. This process
has led to the development of new information and data models when the existing
ones fall short. To prevent potential disruptions caused by flaws in the newly
designed information and data models, it is essential to evaluate them during
the design process before they are implemented in operation.
  Currently, general explicit evaluation approaches outside the smart grid
domain stay at a high level without defining clear steps. Meanwhile, implicit
evaluation approaches in the smart grid domain focus on testing systems that
utilise information and data models already in use for functionality in terms
of conformance and interoperability. Notably, no combination of explicit and
implicit evaluation approaches for newly designed information and data models
offers a clearly defined set of steps during their design process in the smart
grid context.
  Consequently, we design a three-phase evaluation approach using design
science research to address this gap. Our evaluation approach combines explicit
and implicit evaluation methods and is applicable when developing new
information and data models. We use the development of an information model and
data model focused on industrial flexibility descriptions to refine our
evaluation approach. Additionally, we provide lessons learned from our
experience.

</details>


### [9] [A Fuzzy Approach to Project Success: Measuring What Matters](https://arxiv.org/abs/2507.12653)
*João Granja-Correia,Remedios Hernández-Linares,Luca Ferranti,Arménio Rego*

Main category: cs.SE

TL;DR: 论文提出了一种基于模糊逻辑的新型项目成功评估方法，替代传统的Likert量表，更关注用户持续积极影响。


<details>
  <summary>Details</summary>
Motivation: 传统Likert量表忽略了项目成功的多面性和上下文依赖性，需要更动态的评估方法。

Method: 采用分层Type-1 Mamdani模糊系统，优先考虑用户持续积极影响，减少对次要结果的关注。

Result: 该方法可能更准确地衡量项目成功，并适用于复杂评估场景。

Conclusion: 未来研究将聚焦于实证测试和模糊逻辑在社会科学中的更广泛应用。

Abstract: This paper introduces a novel approach to project success evaluation by
integrating fuzzy logic into an existing construct. Traditional Likert-scale
measures often overlook the context-dependent and multifaceted nature of
project success. The proposed hierarchical Type-1 Mamdani fuzzy system
prioritizes sustained positive impact for end-users, reducing emphasis on
secondary outcomes like stakeholder satisfaction and internal project success.
This dynamic approach may provide a more accurate measure of project success
and could be adaptable to complex evaluations. Future research will focus on
empirical testing and broader applications of fuzzy logic in social science.

</details>


### [10] [Single Conversation Methodology: A Human-Centered Protocol for AI-Assisted Software Development](https://arxiv.org/abs/2507.12665)
*Salvador D. Escobedo*

Main category: cs.SE

TL;DR: 提出了一种名为SCM的新方法，通过单一持续对话结构利用LLMs进行软件开发，强调开发者主动性和结构化流程。


<details>
  <summary>Details</summary>
Motivation: 当前对LLMs的依赖过于被动，SCM旨在纠正这一问题，重新确立开发者在智能工具中的主导地位。

Method: SCM基于认知清晰性、可追溯性、模块化和文档化原则，定义开发阶段和最佳实践。

Result: SCM提供了一种结构化方法，使开发者在LLMs辅助下更高效地完成项目全周期。

Conclusion: SCM是对当前LLMs使用方式的必要改进，强调开发者作为架构者和监督者的角色。

Abstract: We propose the Single Conversation Methodology (SCM), a novel and pragmatic
approach to software development using large language models (LLMs). In
contrast to ad hoc interactions with generative AI, SCM emphasizes a structured
and persistent development dialogue, where all stages of a project - from
requirements to architecture and implementation - unfold within a single,
long-context conversation. The methodology is grounded on principles of
cognitive clarity, traceability, modularity, and documentation. We define its
phases, best practices, and philosophical stance, while arguing that SCM offers
a necessary correction to the passive reliance on LLMs prevalent in current
practices. We aim to reassert the active role of the developer as architect and
supervisor of the intelligent tool.

</details>


### [11] [Investigating the Performance of Small Language Models in Detecting Test Smells in Manual Test Cases](https://arxiv.org/abs/2507.13035)
*Keila Lucas,Rohit Gheyi,Márcio Ribeiro,Fabio Palomba,Luana Martins,Elvys Soares*

Main category: cs.SE

TL;DR: 研究探讨了小型语言模型（SLMs）在自动检测测试异味（test smells）中的潜力，评估了Gemma3、Llama3.2和Phi-4在真实Ubuntu测试案例中的表现，Phi-4表现最佳。


<details>
  <summary>Details</summary>
Motivation: 手动测试中的测试异味（如模糊性、冗余等）降低了测试的可靠性和可维护性，现有检测工具需要手动定义规则且缺乏扩展性。

Method: 评估了Gemma3、Llama3.2和Phi-4在143个真实Ubuntu测试案例中检测七种测试异味的能力。

Result: Phi-4表现最佳，检测准确率达97%，Gemma3和Llama3.2约为91%。SLMs还能自主解释问题并提出改进建议。

Conclusion: SLMs可作为高效工具，无需依赖大量规则定义或语法分析，提升测试质量并保护数据隐私。

Abstract: Manual testing, in which testers follow natural language instructions to
validate system behavior, remains crucial for uncovering issues not easily
captured by automation. However, these test cases often suffer from test
smells, quality issues such as ambiguity, redundancy, or missing checks that
reduce test reliability and maintainability. While detection tools exist, they
typically require manual rule definition and lack scalability. This study
investigates the potential of Small Language Models (SLMs) for automatically
detecting test smells. We evaluate Gemma3, Llama3.2, and Phi-4 on 143
real-world Ubuntu test cases, covering seven types of test smells. Phi-4
achieved the best results, reaching a pass@2 of 97% in detecting sentences with
test smells, while Gemma3 and Llama3.2 reached approximately 91%. Beyond
detection, SLMs autonomously explained issues and suggested improvements, even
without explicit prompt instructions. They enabled low-cost, concept-driven
identification of diverse test smells without relying on extensive rule
definitions or syntactic analysis. These findings highlight the potential of
SLMs as efficient tools that preserve data privacy and can improve test quality
in real-world scenarios.

</details>


### [12] [iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development](https://arxiv.org/abs/2507.13081)
*Dongming Jin,Weisong Sun,Jiangping Huang,Peng Liang,Jifeng Xuan,Yang Liu,Zhi Jin*

Main category: cs.SE

TL;DR: iReDev是一个知识驱动的多智能体框架，用于智能需求开发，通过整合人类知识和多智能体协作，显著提升需求开发的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 需求开发是软件工程中的关键阶段，但传统方法耗时且劳动密集。现有研究对多智能体系统在需求开发中的支持有限，且忽视了人类知识与智能体的结合。

Method: iReDev包含六个知识驱动的智能体，支持整个需求开发过程。采用基于事件驱动的通信机制和人工介入机制，实现高效协作。

Result: 评估表明，iReDev在多个方面优于现有基线方法，生成的需求规范更符合利益相关者期望。

Conclusion: iReDev为智能需求开发提供了新方向，未来可进一步探索其扩展性和实际应用。

Abstract: Requirements development is a critical phase as it is responsible for
providing a clear understanding of what stakeholders need. It involves
collaboration among stakeholders to extract explicit requirements and address
potential conflicts, which is time-consuming and labor-intensive. Recently,
multi-agent systems for software development have attracted much attention.
However, existing research provides limited support for requirements
development and overlooks the injection of human knowledge into agents and the
human-agent collaboration. % To address these issues, this paper proposes a
knowledge-driven multi-agent framework for intelligent requirement development,
named iReDev. iReDev features: iReDev consists of six knowledge-driven agents
to support the entire requirements development. They collaboratively perform
various tasks to produce a software requirements specification. iReDev focuses
on integrating human knowledge for agents, enabling them to simulate real-world
stakeholders. iReDev uses an event-driven communication mechanism based on an
artifact pool. Agents continuously monitor the pool and autonomously trigger
the next action based on its changes, enabling iReDev to handle new
requirements quickly. iReDev introduces a human-in-the-loop mechanism to
support human-agent collaboration, ensuring that the generated artifacts align
with the expectations of stakeholders. We evaluated the generated artifacts and
results show that iReDev outperforms existing baselines in multiple aspects. We
further envision three key directions and hope this work can facilitate the
development of intelligent requirements development.

</details>


### [13] [A Conceptual Framework for Requirements Engineering of Pretrained-Model-Enabled Systems](https://arxiv.org/abs/2507.13095)
*Dongming Jin,Zhi Jin,Linyu Li,Xiaohong Chen*

Main category: cs.SE

TL;DR: 论文探讨了预训练模型在现代软件系统中的集成及其对需求工程的挑战，提出了一个针对此类系统的概念框架和研究方向。


<details>
  <summary>Details</summary>
Motivation: 预训练模型的独特特性（如模糊能力边界、上下文依赖行为和持续演化）挑战了传统需求工程的假设（如功能可分解性和行为可预测性），需要重新思考现有方法。

Method: 提出了一个针对预训练模型驱动软件系统的需求工程概念框架，并概述了相关研究方向。

Result: 为研究人员和实践者提供了应对预训练模型系统需求工程挑战的指导。

Conclusion: 论文呼吁重新思考需求工程方法，并提出了一个适应预训练模型特性的框架，为未来研究指明了方向。

Abstract: Recent advances in large pretrained models have led to their widespread
integration as core components in modern software systems. The trend is
expected to continue in the foreseeable future. Unlike traditional software
systems governed by deterministic logic, systems powered by pretrained models
exhibit distinctive and emergent characteristics, such as ambiguous capability
boundaries, context-dependent behavior, and continuous evolution. These
properties fundamentally challenge long-standing assumptions in requirements
engineering, including functional decomposability and behavioral
predictability. This paper investigates this problem and advocates for a
rethinking of existing requirements engineering methodologies. We propose a
conceptual framework tailored to requirements engineering of
pretrained-model-enabled software systems and outline several promising
research directions within this framework. This vision helps provide a guide
for researchers and practitioners to tackle the emerging challenges in
requirements engineering of pretrained-model-enabled systems.

</details>


### [14] [Inferring Attributed Grammars from Parser Implementations](https://arxiv.org/abs/2507.13117)
*Andreas Pointner,Josef Pichler,Herbert Prähofer*

Main category: cs.SE

TL;DR: 提出了一种从递归下降解析器实现中推断属性文法的新方法，以恢复输入处理的语义规范。


<details>
  <summary>Details</summary>
Motivation: 现有语法挖掘技术主要关注语法结构恢复，而输入处理的语义规范仍未被充分探索。

Method: 通过动态分析递归下降解析器的实现，将程序运行时行为映射到语法规则中，提取并嵌入语义动作。

Result: 实验表明，该方法能准确通过生成的属性文法重现程序行为。

Conclusion: 该方法为输入处理的语义规范恢复提供了可行途径。

Abstract: Software systems that process structured inputs often lack complete and
up-to-date specifications, which specify the input syntax and the semantics of
input processing. While grammar mining techniques have focused on recovering
syntactic structures, the semantics of input processing remains largely
unexplored. In this work, we introduce a novel approach for inferring
attributed grammars from parser implementations. Given an input grammar, our
technique dynamically analyzes the implementation of recursive descent parsers
to reconstruct the semantic aspects of input handling, resulting in
specifications in the form of attributed grammars. By observing program
executions and mapping the program's runtime behavior to the grammar, we
systematically extract and embed semantic actions into the grammar rules. This
enables comprehensive specification recovery. We demonstrate the feasibility of
our approach using an initial set of programs, showing that it can accurately
reproduce program behavior through the generated attributed grammars.

</details>


### [15] [Detecting LLM-generated Code with Subtle Modification by Adversarial Training](https://arxiv.org/abs/2507.13123)
*Xin Yin,Xinrui Li,Chao Ni,Xiaodan Xu,Xiaohu Yang*

Main category: cs.SE

TL;DR: 论文提出CodeGPTSensor+，通过对抗训练增强对LLM生成代码的检测鲁棒性，解决现有方法在面对修改代码时的不足。


<details>
  <summary>Details</summary>
Motivation: 随着LLM生成代码的广泛应用，其引发的代码来源、版权和质量问题日益突出，亟需一种能有效检测修改后LLM代码的方法。

Method: 提出CodeGPTSensor+，集成对抗样本生成模块MIST，通过多目标标识和结构变换生成高质量对抗样本，提升模型鲁棒性。

Result: 在HMCorp数据集上，CodeGPTSensor+显著提升对抗测试集的检测准确率，同时保持原测试集的高准确率。

Conclusion: CodeGPTSensor+在检测修改后的LLM生成代码方面表现出优越的鲁棒性，为实际应用提供了有效解决方案。

Abstract: With the rapid development of Large Language Models (LLMs), their powerful
code-generation capabilities have been widely applied in tasks like code
completion and automated development, demonstrating the value of improving
coding efficiency. However, the extensive use of LLM-generated code also raises
several new challenges. On the one hand, issues such as the regulation of code
provenance, copyright disputes, and code quality have become increasingly
concerning. How to effectively detect LLM-generated code and ensure its
compliant and responsible use has become a critical and urgent issue. On the
other hand, in practical applications, LLM-generated code is often subject to
manual modifications, such as variable renaming or structural adjustments.
Although some recent studies have proposed training-based and zero-shot methods
for detecting LLM-generated code, these approaches show insufficient robustness
when facing modified LLM-generated code, and there is a lack of an effective
solution. To address the real-world scenario where LLM-generated code may
undergo minor modifications, we propose CodeGPTSensor+, an enhanced version of
CodeGPTSensor, which employs adversarial training to improve robustness against
input perturbations. CodeGPTSensor+ integrates an adversarial sample generation
module, Multi-objective Identifier and Structure Transformation (MIST), which
systematically generates both high-quality and representative adversarial
samples. This module effectively enhances the model's resistance against
diverse adversarial attacks. Experimental results on the HMCorp dataset
demonstrate that CodeGPTSensor+ significantly improves detection accuracy on
the adversarial test set while maintaining high accuracy on the original test
set, showcasing superior robustness compared to CodeGPTSensor.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [16] [Safeguarding Federated Learning-based Road Condition Classification](https://arxiv.org/abs/2507.12568)
*Sheng Liu,Panos Papadimitratos*

Main category: cs.CR

TL;DR: 论文探讨了联邦学习（FL）在基于摄像头的道路条件分类（RCC）系统中的安全漏洞，特别是标签翻转攻击（TLFAs），并提出了一种防御机制FLARE。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在隐私保护的道路条件分类中具有潜力，但其协作性质引入了标签翻转攻击的漏洞，可能导致严重的安全风险。

Method: 论文提出了一种基于标签距离的度量标准来量化TLFAs的风险，并设计了FLARE防御机制，通过神经元分析减轻攻击影响。

Result: 实验表明TLFAs对FL-RCC系统具有严重威胁，而FLARE能有效减轻攻击影响。

Conclusion: FLARE为FL-RCC系统提供了一种有效的防御手段，增强了其安全性。

Abstract: Federated Learning (FL) has emerged as a promising solution for
privacy-preserving autonomous driving, specifically camera-based Road Condition
Classification (RCC) systems, harnessing distributed sensing, computing, and
communication resources on board vehicles without sharing sensitive image data.
However, the collaborative nature of FL-RCC frameworks introduces new
vulnerabilities: Targeted Label Flipping Attacks (TLFAs), in which malicious
clients (vehicles) deliberately alter their training data labels to compromise
the learned model inference performance. Such attacks can, e.g., cause a
vehicle to mis-classify slippery, dangerous road conditions as pristine and
exceed recommended speed. However, TLFAs for FL-based RCC systems are largely
missing. We address this challenge with a threefold contribution: 1) we
disclose the vulnerability of existing FL-RCC systems to TLFAs; 2) we introduce
a novel label-distance-based metric to precisely quantify the safety risks
posed by TLFAs; and 3) we propose FLARE, a defensive mechanism leveraging
neuron-wise analysis of the output layer to mitigate TLFA effects. Extensive
experiments across three RCC tasks, four evaluation metrics, six baselines, and
three deep learning models demonstrate both the severity of TLFAs on FL-RCC
systems and the effectiveness of FLARE in mitigating the attack impact.

</details>


### [17] [On the Consideration of Vanity Address Generation via Identity-Based Signatures](https://arxiv.org/abs/2507.12670)
*Shogo Murasaki,Kazumasa Omote,Keita Emura*

Main category: cs.CR

TL;DR: 探讨了如何利用基于身份的签名（IBS）生成区块链上的虚荣地址，尽管无法直接替换ECDSA，但通过IBS为地址附加额外意义。


<details>
  <summary>Details</summary>
Motivation: 解决传统试错法生成虚荣地址的字符限制问题，探索IBS在区块链地址生成中的应用。

Method: 提出一种从ECDSA构造IBS的方案，并通过Solidity实现系统。

Result: 实现表明，IBS方案的gas成本与ECDSA签名验证几乎相同。

Conclusion: IBS虽不能直接生成虚荣地址，但可为地址附加额外意义，且成本可控。

Abstract: An address is indicated as an identifier of the user on the blockchain, and
is defined by a hash value of the ECDSA verification key. A vanity address is
an address that embeds custom characters such as a name. To generate a vanity
address, a classical try-and-error method is employed, and thus the number of
characters to be embedded is limited. In this paper, we focus on the
functionality of identity-based signatures (IBS) where any strings can be
employed as a verification key, and explore whether IBS can be used for
generating a vanity address. We attach importance to the fact that it is not
realistic to replace ECDSA with key recovery, which is currently employed for
issuing transactions in Ethereum, to an IBS scheme. Even if this replacement is
possible, it is not a reasonable price for the ease of the vanity address
generation. Thus, we pay attention to a generic construction of IBS from
signatures, and construct an IBS scheme from ECDSA with key recovery. Though we
cannot directly generate a vanity address due to the key recovery functionality
of the underlying ECDSA, we can connect any string with an address due to the
functionality of IBS that can give additional meaning to the address. We
implement our system by Solidity, and demonstrate that the gas cost is almost
same as that of the ECDSA signature verification.

</details>


### [18] [Architectural Backdoors in Deep Learning: A Survey of Vulnerabilities, Detection, and Defense](https://arxiv.org/abs/2507.12919)
*Victoria Childress,Josh Collyer,Jodie Knapp*

Main category: cs.CR

TL;DR: 该论文系统综述了深度神经网络中的架构后门威胁，探讨了其检测与防御策略，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 架构后门是一种未被充分研究但极具威胁的攻击方式，能够绕过传统防御手段，因此需要系统性的研究和解决方案。

Method: 论文通过综述现有研究，分析了编译器级操作、受污染的AutoML流程和供应链漏洞等后门植入方式，并评估了静态图检查、动态模糊测试和部分形式化验证等防御策略。

Result: 尽管已有一些检测和防御方法，但针对分布式或隐蔽触发的后门仍缺乏可扩展且实用的解决方案。

Conclusion: 论文提出了加强供应链安全、密码学模型认证和下一代基准测试等未来研究方向，以全面防御深度学习系统中的架构后门威胁。

Abstract: Architectural backdoors pose an under-examined but critical threat to deep
neural networks, embedding malicious logic directly into a model's
computational graph. Unlike traditional data poisoning or parameter
manipulation, architectural backdoors evade standard mitigation techniques and
persist even after clean retraining. This survey systematically consolidates
research on architectural backdoors, spanning compiler-level manipulations,
tainted AutoML pipelines, and supply-chain vulnerabilities. We assess emerging
detection and defense strategies, including static graph inspection, dynamic
fuzzing, and partial formal verification, and highlight their limitations
against distributed or stealth triggers. Despite recent progress, scalable and
practical defenses remain elusive. We conclude by outlining open challenges and
proposing directions for strengthening supply-chain security, cryptographic
model attestations, and next-generation benchmarks. This survey aims to guide
future research toward comprehensive defenses against structural backdoor
threats in deep learning systems.

</details>


### [19] [Enterprise Security Incident Analysis and Countermeasures Based on the T-Mobile Data Breach](https://arxiv.org/abs/2507.12937)
*Zhuohan Cui,Zikun Song*

Main category: cs.CR

TL;DR: 本文分析了T-Mobile在2021和2023年的数据泄露事件，通过安全审计和漏洞评估提出多层防御策略，证明其成本效益。


<details>
  <summary>Details</summary>
Motivation: 揭示T-Mobile数据泄露后的结构性弱点，并提供可操作的防御方案。

Method: 结合漏洞评估和主动黑客技术（如Shodan侦察、API滥用模拟等），提出多层防御策略。

Result: 发现持续存在的安全弱点，并证明防御策略的成本效益（五年投资低于预期损失的1.1%）。

Conclusion: 为大型电信公司提供操作弹性、合规性和威胁应对的实用方案。

Abstract: This paper presents a comprehensive analysis of T-Mobile's critical data
breaches in 2021 and 2023, alongside a full-spectrum security audit targeting
its systems, infrastructure, and publicly exposed endpoints. By combining
case-based vulnerability assessments with active ethical hacking
techniques--including Shodan reconnaissance, API misuse simulations, VNC
brute-forcing, firmware reverse engineering, and web application scans--we
uncover structural weaknesses persisting beyond the initial breach events.
Building on these findings, we propose a multi-layered defensive strategy
encompassing Zero Trust Architecture, granular role-based access control,
network segmentation, firmware encryption using AES with integrity checks, and
API rate limiting and token lifecycle control. Financial modelling demonstrates
that a five-year investment yields less than 1.1% of expected breach losses,
validating the cost-effectiveness of proactive security measures. Our work
bridges post-incident forensic analysis with hands-on security evaluation,
providing an actionable blueprint for large-scale telecoms seeking operational
resilience, regulatory compliance, and cross-domain threat readiness.

</details>


### [20] [Measuring CEX-DEX Extracted Value and Searcher Profitability: The Darkest of the MEV Dark Forest](https://arxiv.org/abs/2507.13023)
*Fei Wu,Danning Sui,Thomas Thiery,Mallesh Pai*

Main category: cs.CR

TL;DR: 本文通过实证分析研究了以太坊上中心化与去中心化交易所（CEX-DEX）之间的套利经济与动态，揭示了套利交易的收入、集中化趋势及其对以太坊去中心化的影响。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示CEX-DEX套利的经济行为及其对以太坊生态系统的影响，特别是套利交易的收入分配和集中化趋势。

Method: 通过改进启发式方法从链上数据识别套利交易，并引入稳健的实证框架估算套利收入，无需依赖CEX上的实际交易行为。

Result: 在19个月的数据中，识别出7,203,560笔套利交易，总收益达2.338亿美元；发现套利市场高度集中，前三名套利者占据75%的收益。

Conclusion: 研究揭示了套利市场的集中化趋势及其与区块构建者的关系，强调了CEX-DEX套利对以太坊去中心化的潜在威胁。

Abstract: This paper provides a comprehensive empirical analysis of the economics and
dynamics behind arbitrages between centralized and decentralized exchanges
(CEX-DEX) on Ethereum. We refine heuristics to identify arbitrage transactions
from on-chain data and introduce a robust empirical framework to estimate
arbitrage revenue without knowing traders' actual behaviors on CEX. Leveraging
an extensive dataset spanning 19 months from August 2023 to March 2025, we
estimate a total of 233.8M USD extracted by 19 major CEX-DEX searchers from
7,203,560 identified CEX-DEX arbitrages. Our analysis reveals increasing
centralization trends as three searchers captured three-quarters of both volume
and extracted value. We also demonstrate that searchers' profitability is tied
to their integration level with block builders and uncover exclusive
searcher-builder relationships and their market impact. Finally, we correct the
previously underestimated profitability of block builders who vertically
integrate with a searcher. These insights illuminate the darkest corner of the
MEV landscape and highlight the critical implications of CEX-DEX arbitrages for
Ethereum's decentralization.

</details>


### [21] [From Paranoia to Compliance: The Bumpy Road of System Hardening Practices on Stack Exchange](https://arxiv.org/abs/2507.13028)
*Niklas Busch,Philip Klostermeyer,Jan H. Klemmer,Yasemin Acar,Sascha Fahl*

Main category: cs.CR

TL;DR: 研究分析了316篇Stack Exchange帖子，探讨系统管理员在系统加固中的动机、实践和挑战，发现访问控制和部署问题最棘手，并存在误解和不切实际的期望。


<details>
  <summary>Details</summary>
Motivation: 许多系统管理员在系统加固方面遇到困难，导致系统不安全，研究缺乏对其动机、实践和挑战的深入理解。

Method: 定性分析了316篇与系统加固相关的Stack Exchange帖子。

Result: 访问控制和部署问题最具挑战性，系统管理员存在误解和不切实际的期望；操作系统和服务器应用是主要关注点；动机多为安全担忧或合规要求。

Conclusion: 研究揭示了系统加固的实践和挑战，提出了未来改进建议，并讨论了研究意义。

Abstract: Hardening computer systems against cyberattacks is crucial for security.
However, past incidents illustrated, that many system operators struggle with
effective system hardening. Hence, many computer systems and applications
remain insecure. So far, the research community lacks an in-depth understanding
of system operators motivation, practices, and challenges around system
hardening. With a focus on practices and challenges, we qualitatively analyzed
316 Stack Exchange (SE) posts related to system hardening. We find that access
control and deployment-related issues are the most challenging, and system
operators suffer from misconceptions and unrealistic expectations. Most
frequently, posts focused on operating systems and server applications. System
operators were driven by the fear of their systems getting attacked or by
compliance reasons. Finally, we discuss our research questions, make
recommendations for future system hardening, and illustrate the implications of
our work.

</details>


### [22] [MAD-Spear: A Conformity-Driven Prompt Injection Attack on Multi-Agent Debate Systems](https://arxiv.org/abs/2507.13038)
*Yu Cui,Hongyang Du*

Main category: cs.CR

TL;DR: MAD-Spear是一种针对多智能体辩论系统的攻击方法，通过操纵少数智能体传播错误信息，显著降低系统性能。研究发现，智能体多样性在数学推理任务中能提升系统表现。


<details>
  <summary>Details</summary>
Motivation: 尽管多智能体辩论系统（MAD）在提升推理能力方面表现出色，但其安全性问题尚未得到充分研究。本研究旨在揭示MAD系统的安全漏洞。

Method: 提出MAD-Spear攻击方法，通过操纵部分智能体生成多个看似合理但错误的响应，利用LLM的从众倾向传播错误信息。同时，结合其他攻击策略（如通信攻击）增强攻击效果。

Result: 实验表明，MAD-Spear在五个基准数据集上均能显著降低系统性能。此外，智能体多样性在数学推理任务中能提升系统表现。

Conclusion: 研究揭示了MAD系统的安全漏洞，强调了在设计MAD系统时提升安全性的紧迫性。

Abstract: Multi-agent debate (MAD) systems leverage collaborative interactions among
large language models (LLMs) agents to improve reasoning capabilities. While
recent studies have focused on increasing the accuracy and scalability of MAD
systems, their security vulnerabilities have received limited attention. In
this work, we introduce MAD-Spear, a targeted prompt injection attack that
compromises a small subset of agents but significantly disrupts the overall MAD
process. Manipulated agents produce multiple plausible yet incorrect responses,
exploiting LLMs' conformity tendencies to propagate misinformation and degrade
consensus quality. Furthermore, the attack can be composed with other
strategies, such as communication attacks, to further amplify its impact by
increasing the exposure of agents to incorrect responses. To assess MAD's
resilience under attack, we propose a formal definition of MAD fault-tolerance
and develop a comprehensive evaluation framework that jointly considers
accuracy, consensus efficiency, and scalability. Extensive experiments on five
benchmark datasets with varying difficulty levels demonstrate that MAD-Spear
consistently outperforms the baseline attack in degrading system performance.
Additionally, we observe that agent diversity substantially improves MAD
performance in mathematical reasoning tasks, which challenges prior work
suggesting that agent diversity has minimal impact on performance. These
findings highlight the urgent need to improve the security in MAD design.

</details>


### [23] [Backscattering-Based Security in Wireless Power Transfer Applied to Battery-Free BLE Sensors](https://arxiv.org/abs/2507.13042)
*Taki Eddine Djidjekh,Gaël Loubet,Alexandru Takacs*

Main category: cs.CR

TL;DR: 论文提出了一种基于反向散射的安全机制，将其集成到蓝牙低功耗无电池无线传感器网络中，解决了安全性和能源效率的挑战。


<details>
  <summary>Details</summary>
Motivation: 物联网系统中安全性和能源效率的集成是一个关键挑战，尤其是对于无电池和资源受限的设备。

Method: 利用无线能量传输链路生成额外的识别信号，无需增加能耗或计算需求。

Result: 实验验证表明该方案在紧凑、低增益天线下有效，适用于结构健康监测和智能交通等应用。

Conclusion: 反向散射安全机制为安全、可持续和可扩展的物联网部署提供了潜力。

Abstract: The integration of security and energy efficiency in Internet of Things
systems remains a critical challenge, particularly for battery-free and
resource-constrained devices. This paper explores the scalability and
protocol-agnostic nature of a backscattering-based security mechanism by
integrating it into Bluetooth Low Energy battery-free Wireless Sensor Network.
The proposed approach leverages the Wireless Power Transfer link, traditionally
used for energy harvesting, to generate additional identification signals
without increasing energy consumption or computational demands. Experimental
validation demonstrates the solution's functionality using compact, low-gain
antenna, ensuring compatibility with size-constrained applications such as
Structural Health Monitoring and smart transport. Furthermore, this work
addresses the challenges associated with backscattering dynamic range and
multi-node Wireless Sensor Network scenarios, discussing potential collisions
between identification signals and proposing future improvements to enhance
generalizability and scalability. The findings underscore the potential of the
backscattering-based security mechanism for creating secure, sustainable, and
scalable IoT deployments across diverse protocols and applications.

</details>


### [24] [Prompt Injection 2.0: Hybrid AI Threats](https://arxiv.org/abs/2507.13169)
*Jeremy McHugh,Kristina Šekrst,Jon Cefalu*

Main category: cs.CR

TL;DR: 论文分析了Prompt Injection 2.0攻击，探讨其如何结合传统网络安全漏洞（如XSS、CSRF）绕过传统安全措施，并提出架构解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理系统的普及，Prompt Injection攻击与网络安全漏洞结合形成混合威胁，传统安全措施失效，亟需新解决方案。

Method: 基于Preamble的研究，评估现有缓解技术对现代威胁（如AI蠕虫、多代理感染）的效果，并提出结合提示隔离、运行时安全和特权分离的架构方案。

Result: 传统安全措施（如WAF、XSS过滤器、CSRF令牌）对AI增强攻击无效，新架构方案能有效检测和防御此类威胁。

Conclusion: Prompt Injection 2.0威胁严峻，需结合新型检测能力和安全架构以应对混合攻击。

Abstract: Prompt injection attacks, where malicious input is designed to manipulate AI
systems into ignoring their original instructions and following unauthorized
commands instead, were first discovered by Preamble, Inc. in May 2022 and
responsibly disclosed to OpenAI. Over the last three years, these attacks have
continued to pose a critical security threat to LLM-integrated systems. The
emergence of agentic AI systems, where LLMs autonomously perform multistep
tasks through tools and coordination with other agents, has fundamentally
transformed the threat landscape. Modern prompt injection attacks can now
combine with traditional cybersecurity exploits to create hybrid threats that
systematically evade traditional security controls. This paper presents a
comprehensive analysis of Prompt Injection 2.0, examining how prompt injections
integrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF),
and other web security vulnerabilities to bypass traditional security measures.
We build upon Preamble's foundational research and mitigation technologies,
evaluating them against contemporary threats, including AI worms, multi-agent
infections, and hybrid cyber-AI attacks. Our analysis incorporates recent
benchmarks that demonstrate how traditional web application firewalls, XSS
filters, and CSRF tokens fail against AI-enhanced attacks. We also present
architectural solutions that combine prompt isolation, runtime security, and
privilege separation with novel threat detection capabilities.

</details>


### [25] [A Crowdsensing Intrusion Detection Dataset For Decentralized Federated Learning Models](https://arxiv.org/abs/2507.13313)
*Chao Feng,Alberto Huertas Celdran,Jing Han,Heqing Ren,Xi Cheng,Zien Zeng,Lucas Krauter,Gerome Bovet,Burkhard Stiller*

Main category: cs.CR

TL;DR: 论文介绍了去中心化联邦学习（DFL）在物联网众包恶意软件检测中的应用，通过实验比较了传统机器学习、集中式联邦学习和DFL的性能。


<details>
  <summary>Details</summary>
Motivation: 研究物联网众包环境中的恶意软件检测，同时保护数据本地性。

Method: 收集了系统行为记录，聚合为30秒窗口的特征，并在不同节点数、拓扑和数据分布下比较DFL、CFL和传统ML的性能。

Result: DFL在保持数据本地性的同时性能优于CFL，且与传统ML竞争。

Conclusion: 该数据集为物联网众包环境的安全研究提供了坚实基础。

Abstract: This paper introduces a dataset and experimental study for decentralized
federated learning (DFL) applied to IoT crowdsensing malware detection. The
dataset comprises behavioral records from benign and eight malware families. A
total of 21,582,484 original records were collected from system calls, file
system activities, resource usage, kernel events, input/output events, and
network records. These records were aggregated into 30-second windows,
resulting in 342,106 features used for model training and evaluation.
Experiments on the DFL platform compare traditional machine learning (ML),
centralized federated learning (CFL), and DFL across different node counts,
topologies, and data distributions. Results show that DFL maintains competitive
performance while preserving data locality, outperforming CFL in most settings.
This dataset provides a solid foundation for studying the security of IoT
crowdsensing environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [26] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
*Jarosław A. Chudziak,Adam Kostka*

Main category: cs.AI

TL;DR: 论文提出了一种新型多代理AI辅导平台，旨在解决当前AI辅导系统的被动性问题，通过个性化反馈和结构化课程生成提升数学学习效果。


<details>
  <summary>Details</summary>
Motivation: 当前AI辅导系统多为被动式，缺乏深度反思和结构化教学工具，尤其在数学领域表现不足。

Method: 引入多代理AI辅导平台，结合自适应反馈、结构化课程生成和教材知识检索，支持模块化学习。

Result: 系统能帮助学生针对性学习、高效复习并提供无限个性化练习，提升数学学习效果。

Conclusion: 该平台为AI教育领域贡献了模块化且高效的教学系统，尤其在数学教育中具有潜力。

Abstract: The growing ubiquity of artificial intelligence (AI), in particular large
language models (LLMs), has profoundly altered the way in which learners gain
knowledge and interact with learning material, with many claiming that AI
positively influences their learning achievements. Despite this advancement,
current AI tutoring systems face limitations associated with their reactive
nature, often providing direct answers without encouraging deep reflection or
incorporating structured pedagogical tools and strategies. This limitation is
most apparent in the field of mathematics, in which AI tutoring systems remain
underdeveloped. This research addresses the question: How can AI tutoring
systems move beyond providing reactive assistance to enable structured,
individualized, and tool-assisted learning experiences? We introduce a novel
multi-agent AI tutoring platform that combines adaptive and personalized
feedback, structured course generation, and textbook knowledge retrieval to
enable modular, tool-assisted learning processes. This system allows students
to learn new topics while identifying and targeting their weaknesses, revise
for exams effectively, and practice on an unlimited number of personalized
exercises. This article contributes to the field of artificial intelligence in
education by introducing a novel platform that brings together pedagogical
agents and AI-driven components, augmenting the field with modular and
effective systems for teaching mathematics.

</details>


### [27] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
*Dustin Holley,Jovin D'sa,Hossein Nourkhiz Mahjoub,Gibran Ali*

Main category: cs.AI

TL;DR: 提出了一种基于博弈论的高速公路合流场景战术决策模型，改进了收益函数和滞后动作，结合动力学模型，实现了更真实、可解释的交互模拟。


<details>
  <summary>Details</summary>
Motivation: 提升仿真环境中驾驶员行为的真实性，以支持自动驾驶技术开发，特别是在高速公路合流场景中。

Method: 采用博弈论模型改进战术决策，结合动力学模型，形成统一的决策与动力学框架。

Result: 模型在真实数据集上验证了复杂交互的再现性，并在高保真仿真环境中表现出高效的计算性能。

Conclusion: 该模型为大规模仿真提供了高效、可解释的解决方案，支持自动驾驶技术开发。

Abstract: Enhancing simulation environments to replicate real-world driver behavior,
i.e., more humanlike sim agents, is essential for developing autonomous vehicle
technology. In the context of highway merging, previous works have studied the
operational-level yielding dynamics of lag vehicles in response to a merging
car at highway on-ramps. Other works focusing on tactical decision modeling
generally consider limited action sets or utilize payoff functions with large
parameter sets and limited payoff bounds. In this work, we aim to improve the
simulation of the highway merge scenario by targeting a game theoretic model
for tactical decision-making with improved payoff functions and lag actions. We
couple this with an underlying dynamics model to have a unified decision and
dynamics model that can capture merging interactions and simulate more
realistic interactions in an explainable and interpretable fashion. The
proposed model demonstrated good reproducibility of complex interactions when
validated on a real-world dataset. The model was finally integrated into a high
fidelity simulation environment and confirmed to have adequate computation time
efficiency for use in large-scale simulations to support autonomous vehicle
development.

</details>


### [28] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
*Léo Saulières*

Main category: cs.AI

TL;DR: 本文提出了一种基于“What”和“How”问题的直观分类法，用于解释强化学习（XRL）的方法，并综述了250多篇论文，同时指出了XRL领域的未来需求。


<details>
  <summary>Details</summary>
Motivation: 由于深度神经网络的内部机制不透明，需要可解释AI（XAI）方法来理解AI模型的输出，本文专注于可解释强化学习（XRL）这一子领域。

Method: 提出了一种基于“What”（解释目标）和“How”（解释方式）的分类法，并用于综述250多篇XRL相关论文。

Result: 通过分类法系统梳理了XRL领域的研究现状，并提出了未来需要关注的方向。

Conclusion: XRL领域需要进一步研究，本文的分类法和综述为未来工作提供了基础。

Abstract: The success of recent Artificial Intelligence (AI) models has been
accompanied by the opacity of their internal mechanisms, due notably to the use
of deep neural networks. In order to understand these internal mechanisms and
explain the output of these AI models, a set of methods have been proposed,
grouped under the domain of eXplainable AI (XAI). This paper focuses on a
sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims
to explain the actions of an agent that has learned by reinforcement learning.
We propose an intuitive taxonomy based on two questions "What" and "How". The
first question focuses on the target that the method explains, while the second
relates to the way the explanation is provided. We use this taxonomy to provide
a state-of-the-art review of over 250 papers. In addition, we present a set of
domains close to XRL, which we believe should get attention from the community.
Finally, we identify some needs for the field of XRL.

</details>


### [29] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
*Alex Zook,Josef Spjut,Jonathan Tremblay*

Main category: cs.AI

TL;DR: 论文提出了一种结合强化学习（RL）代理和多模态模型（LMM）的自动化游戏设计框架，通过RL代理测试游戏行为，LMM根据测试结果调整游戏设计。


<details>
  <summary>Details</summary>
Motivation: 现代生成系统仅通过代码或资源分析游戏，难以捕捉动态玩家行为，因此需要一种能够理解规则与行为转化的方法。

Method: 框架通过RL代理进行游戏测试，生成数值指标或图像摘要，LMM分析这些数据并调整游戏配置以实现目标行为。

Result: 实验证明LMM能够基于RL代理的行为轨迹迭代优化游戏机制。

Conclusion: 该框架为AI辅助游戏设计提供了实用且可扩展的工具。

Abstract: Game design hinges on understanding how static rules and content translate
into dynamic player behavior - something modern generative systems that inspect
only a game's code or assets struggle to capture. We present an automated
design iteration framework that closes this gap by pairing a reinforcement
learning (RL) agent, which playtests the game, with a large multimodal model
(LMM), which revises the game based on what the agent does. In each loop the RL
player completes several episodes, producing (i) numerical play metrics and/or
(ii) a compact image strip summarising recent video frames. The LMM designer
receives a gameplay goal and the current game configuration, analyses the play
traces, and edits the configuration to steer future behaviour toward the goal.
We demonstrate results that LMMs can reason over behavioral traces supplied by
RL agents to iteratively refine game mechanics, pointing toward practical,
scalable tools for AI-assisted game design.

</details>


### [30] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
*Avi Parrack,Carlo Leonardo Attubato,Stefan Heimersheim*

Main category: cs.AI

TL;DR: 论文探讨了AI助手可能欺骗用户的问题，研究了白盒和黑盒监控在检测欺骗性回答中的效果。


<details>
  <summary>Details</summary>
Motivation: 研究AI助手欺骗行为的检测方法，特别是白盒和黑盒监控的有效性。

Method: 比较白盒监控（可访问令牌级探针激活）和黑盒监控（无此访问权限），通过黑盒到白盒的性能提升评估欺骗探针的效果。

Result: 现有欺骗探针显示出微弱但令人鼓舞的黑盒到白盒性能提升。

Conclusion: 白盒监控在检测欺骗性回答中具有一定优势，但现有探针仍需改进。

Abstract: AI assistants will occasionally respond deceptively to user queries.
Recently, linear classifiers (called "deception probes") have been trained to
distinguish the internal activations of a language model during deceptive
versus honest responses. However, it's unclear how effective these probes are
at detecting deception in practice, nor whether such probes are resistant to
simple counter strategies from a deceptive assistant who wishes to evade
detection. In this paper, we compare white-box monitoring (where the monitor
has access to token-level probe activations) to black-box monitoring (without
such access). We benchmark deception probes by the extent to which the white
box monitor outperforms the black-box monitor, i.e. the black-to-white
performance boost. We find weak but encouraging black-to-white performance
boosts from existing deception probes.

</details>


### [31] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
*Sosui Moribe,Taketoshi Ushiama*

Main category: cs.AI

TL;DR: 研究开发AI学习伙伴以促进同伴学习，验证同水平同伴在英语写作中的有效性。


<details>
  <summary>Details</summary>
Motivation: 同伴学习虽有效但存在限制，需同水平同伴。研究旨在通过AI实现随时随地同伴学习。

Method: 假设同水平同伴会犯相同错误，以英语写作为例验证。

Result: 待实验验证。

Conclusion: AI同伴学习有望克服人类同伴学习的限制。

Abstract: In recent years, peer learning has gained attention as a method that promotes
spontaneous thinking among learners, and its effectiveness has been confirmed
by numerous studies. This study aims to develop an AI Agent as a learning
companion that enables peer learning anytime and anywhere. However, peer
learning between humans has various limitations, and it is not always
effective. Effective peer learning requires companions at the same proficiency
levels. In this study, we assume that a learner's peers with the same
proficiency level as the learner make the same mistakes as the learner does and
focus on English composition as a specific example to validate this approach.

</details>


### [32] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: MCPEval是一个基于模型上下文协议的开源框架，用于自动化生成任务和深度评估LLM智能代理，解决了现有静态基准和人工数据收集的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法依赖静态基准和人工数据收集，限制了实际评估的效率和扩展性。

Method: 提出MCPEval框架，基于模型上下文协议（MCP），自动化生成任务并深度评估LLM代理，支持多领域标准化指标。

Result: 在五个实际领域中验证了MCPEval的有效性，能够揭示领域特定的性能差异。

Conclusion: MCPEval为LLM代理评估提供了可重复、标准化的解决方案，并已开源以促进研究。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [33] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 本文介绍了利用提示工程和微调技术增强的大规模语言模型，在NLPCC 2025任务8的情感支持对话任务中取得第二名成绩的方法。


<details>
  <summary>Details</summary>
Motivation: 满足心理健康支持的需求，提供共情且有效的情感辅助对话。

Method: 结合参数高效的Low-Rank Adaptation和全参数微调策略，优化模型生成支持性和上下文相关回应的能力。

Result: 最佳模型在比赛中排名第二，展示了结合LLMs和有效适应方法在情感支持任务中的潜力。

Conclusion: 未来工作将集中于提升情感理解和回应个性化，以构建更实用可靠的情感支持系统。

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [34] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
*Lance Ying,Katherine M. Collins,Prafull Sharma,Cedric Colas,Kaiya Ivy Zhao,Adrian Weller,Zenna Tavares,Phillip Isola,Samuel J. Gershman,Jacob D. Andreas,Thomas L. Griffiths,Francois Chollet,Kelsey R. Allen,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 论文提出人类智能的快速适应能力源于高效构建和优化环境内部表征（世界模型），并呼吁在AI中建立新的评估框架，以测试适应性世界模型的能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI对世界模型的理解和评估过于静态，缺乏对人类快速适应能力的模拟，因此需要新的评估方法。

Method: 借鉴认知科学研究，提出基于新颖游戏（novel games）的基准测试范式，设计具有持续新颖性的游戏来评估AI的世界模型归纳能力。

Result: 提出了一套评估框架和关键指标，旨在挑战和评估AI在快速世界模型归纳方面的能力。

Conclusion: 新框架有望推动AI世界模型的研究，为实现类人快速适应和泛化能力（AGI的关键）迈出重要一步。

Abstract: Human intelligence exhibits a remarkable capacity for rapid adaptation and
effective problem-solving in novel and unfamiliar contexts. We argue that this
profound adaptability is fundamentally linked to the efficient construction and
refinement of internal representations of the environment, commonly referred to
as world models, and we refer to this adaptation mechanism as world model
induction. However, current understanding and evaluation of world models in
artificial intelligence (AI) remains narrow, often focusing on static
representations learned from training on a massive corpora of data, instead of
the efficiency and efficacy of models in learning these representations through
interaction and exploration within a novel environment. In this Perspective, we
provide a view of world model induction drawing on decades of research in
cognitive science on how humans learn and adapt so efficiently; we then call
for a new evaluation framework for assessing adaptive world models in AI.
Concretely, we propose a new benchmarking paradigm based on suites of carefully
designed games with genuine, deep and continually refreshing novelty in the
underlying game structures -- we refer to this kind of games as novel games. We
detail key desiderata for constructing these games and propose appropriate
metrics to explicitly challenge and evaluate the agent's ability for rapid
world model induction. We hope that this new evaluation framework will inspire
future evaluation efforts on world models in AI and provide a crucial step
towards developing AI systems capable of the human-like rapid adaptation and
robust generalization -- a critical component of artificial general
intelligence.

</details>


### [35] [Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command](https://arxiv.org/abs/2507.12862)
*Hussein Abbass,Taylan Akay,Harrison Tolley*

Main category: cs.AI

TL;DR: 论文提出了一种方法，将人类判断移出模拟决策循环，设计伦理度量空间，由模拟环境探索，最后提供少数选项供人类指挥官选择。


<details>
  <summary>Details</summary>
Motivation: 在AI时代，人类指挥官需利用计算能力模拟大量场景，但依赖人类判断每个决策的伦理后果既低效又不可行。

Method: 人类设计伦理度量空间，模拟环境探索该空间并生成选项，人类指挥官从中选择最优行动。

Result: 通过动态加权伦理属性，模拟环境能高效探索决策选项，减轻人类负担。

Conclusion: 该方法有效结合人类伦理判断与自动化模拟，提升决策效率与可行性。

Abstract: In the age of AI, human commanders need to use the computational powers
available in today's environment to simulate a very large number of scenarios.
Within each scenario, situations occur where different decision design options
could have ethical consequences. Making these decisions reliant on human
judgement is both counter-productive to the aim of exploring very large number
of scenarios in a timely manner and infeasible when considering the workload
needed to involve humans in each of these choices. In this paper, we move human
judgement outside the simulation decision cycle. Basically, the human will
design the ethical metric space, leaving it to the simulated environment to
explore the space. When the simulation completes its testing cycles, the
testing environment will come back to the human commander with a few options to
select from. The human commander will then exercise human-judgement to select
the most appropriate course of action, which will then get executed
accordingly. We assume that the problem of designing metrics that are
sufficiently granular to assess the ethical implications of decisions is
solved. Subsequently, the fundamental problem we look at in this paper is how
to weight ethical decisions during the running of these simulations; that is,
how to dynamically weight the ethical attributes when agents are faced with
decision options with ethical implications during generative simulations. The
multi-criteria decision making literature has started to look at nearby
problems, where the concept of entropy has been used to determine the weights
during aggregation. We draw from that literature different approaches to
automatically calculate the weights for ethical attributes during
simulation-based testing and evaluation.

</details>


### [36] [Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework](https://arxiv.org/abs/2507.12872)
*Rishane Dassanayake,Mario Demetroudi,James Walpole,Lindley Lentati,Jason R. Brown,Edward James Young*

Main category: cs.AI

TL;DR: 前沿AI系统在说服、欺骗和影响人类行为方面能力迅速提升，可能通过操纵员工削弱人类监督。本文提出了一个系统性框架，围绕三个核心论点（无能、控制和可信度）评估和减轻操纵风险。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统已展示出人类水平的说服和欺骗能力，但操纵攻击的风险未得到足够重视，缺乏系统性评估框架。

Method: 提出了一个安全案例框架，围绕无能、控制和可信度三个核心论点，明确证据要求、评估方法和实施考虑。

Result: 提供了首个将操纵风险纳入AI安全治理的系统性方法，为AI公司提供了评估和减轻威胁的具体基础。

Conclusion: 操纵风险是重大威胁，需系统性框架进行评估和缓解，本文为AI公司提供了实用工具。

Abstract: Frontier AI systems are rapidly advancing in their capabilities to persuade,
deceive, and influence human behaviour, with current models already
demonstrating human-level persuasion and strategic deception in specific
contexts. Humans are often the weakest link in cybersecurity systems, and a
misaligned AI system deployed internally within a frontier company may seek to
undermine human oversight by manipulating employees. Despite this growing
threat, manipulation attacks have received little attention, and no systematic
framework exists for assessing and mitigating these risks. To address this, we
provide a detailed explanation of why manipulation attacks are a significant
threat and could lead to catastrophic outcomes. Additionally, we present a
safety case framework for manipulation risk, structured around three core lines
of argument: inability, control, and trustworthiness. For each argument, we
specify evidence requirements, evaluation methodologies, and implementation
considerations for direct application by AI companies. This paper provides the
first systematic methodology for integrating manipulation risk into AI safety
governance, offering AI companies a concrete foundation to assess and mitigate
these threats before deployment.

</details>


### [37] [VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks](https://arxiv.org/abs/2507.12885)
*Jian Yao,Ran Cheng,Kay Chen Tan*

Main category: cs.AI

TL;DR: 论文提出VAR-MATH框架，通过符号化评估揭示RL训练模型在数学推理中的真实能力，发现现有方法依赖表面启发式，泛化能力不足。


<details>
  <summary>Details</summary>
Motivation: 探讨RL训练模型在数学推理中的真实能力，避免因基准污染和评估脆弱性导致的虚假改进。

Method: 引入VAR-MATH框架，将固定数值问题转换为符号模板，要求模型解决多个实例以评估推理一致性。

Result: 实验显示RL模型在符号化版本中性能显著下降（AMC23下降48.0%，AIME24下降58.3%），表明其泛化能力有限。

Conclusion: VAR-MATH提供了一种抗污染、稳健的数学推理评估范式，揭示了现有RL方法的局限性。

Abstract: Recent advances in reinforcement learning (RL) have led to substantial
improvements in the mathematical reasoning abilities of large language models
(LLMs), as measured by standard benchmarks. However, these gains often persist
even when models are trained with flawed signals, such as random or inverted
rewards, raising a fundamental question: do such improvements reflect true
reasoning, or are they merely artifacts of overfitting to benchmark-specific
patterns? To address this question, we take an evaluation-centric perspective
and identify two critical shortcomings in existing protocols. First,
\emph{benchmark contamination} arises from the public availability of test
problems, increasing the risk of data leakage. Second, \emph{evaluation
fragility} stems from the reliance on single-instance assessments, which are
highly sensitive to stochastic outputs and fail to capture reasoning
consistency. To overcome these limitations, we introduce {VAR-MATH}, a symbolic
evaluation framework designed to probe genuine reasoning ability. By converting
fixed numerical problems into symbolic templates and requiring models to solve
multiple instantiations of each, VAR-MATH enforces consistent reasoning across
structurally equivalent variants, thereby mitigating contamination and
improving evaluation robustness. We apply VAR-MATH to transform two popular
benchmarks, AMC23 and AIME24, into their symbolic counterparts, VAR-AMC23 and
VAR-AIME24. Experimental results reveal substantial performance drops for
RL-trained models on the variabilized versions, especially for smaller models,
with average declines of 48.0\% on AMC23 and 58.3\% on AIME24. These findings
suggest that many existing RL methods rely on superficial heuristics and fail
to generalize beyond specific numerical forms. Overall, VAR-MATH offers a
principled, contamination-resistant evaluation paradigm for mathematical
reasoning.

</details>


### [38] [A Translation of Probabilistic Event Calculus into Markov Decision Processes](https://arxiv.org/abs/2507.12989)
*Lyris Xu,Fabio Aurelio D'Asaro,Luke Dickens*

Main category: cs.AI

TL;DR: 本文提出了一种将概率事件演算（PEC）转化为马尔可夫决策过程（MDP）的方法，以弥补PEC在目标导向推理上的不足，同时保留了其可解释性和表达能力。


<details>
  <summary>Details</summary>
Motivation: PEC在不确定环境中对动作及其效果进行推理具有优势，但缺乏目标导向推理机制。本文旨在填补这一空白。

Method: 通过将PEC领域形式化转化为MDP，引入“动作执行情境”概念，保留PEC的灵活动作语义。

Result: 提出的PEC-MDP形式化方法支持时间推理任务和目标驱动规划，并能将学习到的策略映射回人类可读的PEC表示。

Conclusion: PEC-MDP扩展了PEC的能力，同时保持了其可解释性，为PEC领域引入了MDP的算法和理论工具。

Abstract: Probabilistic Event Calculus (PEC) is a logical framework for reasoning about
actions and their effects in uncertain environments, which enables the
representation of probabilistic narratives and computation of temporal
projections. The PEC formalism offers significant advantages in
interpretability and expressiveness for narrative reasoning. However, it lacks
mechanisms for goal-directed reasoning. This paper bridges this gap by
developing a formal translation of PEC domains into Markov Decision Processes
(MDPs), introducing the concept of "action-taking situations" to preserve PEC's
flexible action semantics. The resulting PEC-MDP formalism enables the
extensive collection of algorithms and theoretical tools developed for MDPs to
be applied to PEC's interpretable narrative domains. We demonstrate how the
translation supports both temporal reasoning tasks and objective-driven
planning, with methods for mapping learned policies back into human-readable
PEC representations, maintaining interpretability while extending PEC's
capabilities.

</details>


### [39] [Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming](https://arxiv.org/abs/2507.13007)
*Roger Xavier Lera-Leri,Filippo Bistaffa,Athina Georgara,Juan Antonio Rodriguez-Aguilar*

Main category: cs.AI

TL;DR: X-MILP是一种基于约束推理技术的领域无关方法，用于为混合整数线性规划（MILP）生成对比解释。


<details>
  <summary>Details</summary>
Motivation: 随着对可信AI的需求增加，开发针对MILP的对比解释技术变得重要。

Method: 将用户查询编码为额外约束，通过计算不可约不可行子系统（IIS）生成解释，并以“原因图”形式呈现。

Result: 在经典优化问题上测试，验证了方法的可行性和计算难度。

Conclusion: X-MILP为MILP问题提供了有效的对比解释工具。

Abstract: Following the recent push for trustworthy AI, there has been an increasing
interest in developing contrastive explanation techniques for optimisation,
especially concerning the solution of specific decision-making processes
formalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic
approach for building contrastive explanations for MILPs based on constraint
reasoning techniques. First, we show how to encode the queries a user makes
about the solution of an MILP problem as additional constraints. Then, we
determine the reasons that constitute the answer to the user's query by
computing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set
of constraints. Finally, we represent our explanation as a "graph of reasons"
constructed from the IIS, which helps the user understand the structure among
the reasons that answer their query. We test our method on instances of
well-known optimisation problems to evaluate the empirical hardness of
computing explanations.

</details>


### [40] [Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data](https://arxiv.org/abs/2507.13112)
*Junseong Lee,Jaegwan Cho,Yoonju Cho,Seoyoon Choi,Yejin Shin*

Main category: cs.AI

TL;DR: 研究基于人工智能算法预测加州高速公路交通流量，使用MLR和RF模型，发现10分钟数据收集间隔效果最佳。


<details>
  <summary>Details</summary>
Motivation: 解决全球交通拥堵问题，提供高效的交通管理方案。

Method: 利用加州78号公路5个月的30秒间隔数据，采用MLR和RF算法，分析不同数据收集间隔（30秒至15分钟）。

Result: MLR和RF模型在10分钟数据收集间隔下表现最优（R^2、MAE、RMSE评估）。

Conclusion: 研究结果有助于未来交通拥堵解决方案和高效交通管理。

Abstract: The study "Prediction of Highway Traffic Flow Based on Artificial
Intelligence Algorithms Using California Traffic Data" presents a machine
learning-based traffic flow prediction model to address global traffic
congestion issues. The research utilized 30-second interval traffic data from
California Highway 78 over a five-month period from July to November 2022,
analyzing a 7.24 km westbound section connecting "Melrose Dr" and "El-Camino
Real" in the San Diego area. The study employed Multiple Linear Regression
(MLR) and Random Forest (RF) algorithms, analyzing data collection intervals
ranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance
metrics, the analysis revealed that both MLR and RF models performed optimally
with 10-minute data collection intervals. These findings are expected to
contribute to future traffic congestion solutions and efficient traffic
management.

</details>


### [41] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 论文提出了一种动态强化学习框架，改进静态树结构推理方法，提升问题解答的适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有树结构推理方法（如ProbTree）存在静态树结构和计算效率低的问题，限制了其在实时问题解答中的表现。

Method: 采用动态强化学习框架，实时构建推理树，并通过置信度估计和策略学习优化分解、检索和聚合操作。

Result: 新方法在保持概率严谨性的同时，提高了解答质量和计算效率。

Conclusion: 该研究为树结构推理提供了新范式，平衡了概率框架的可靠性和实际应用的灵活性。

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [42] [Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era](https://arxiv.org/abs/2507.13175)
*Matthew E. Brophy*

Main category: cs.AI

TL;DR: 论文提出修订的伦理标准以评估基于大语言模型（LLM）的人工道德代理（AMA），因传统标准不适用于LLM的不透明性和随机性。


<details>
  <summary>Details</summary>
Motivation: LLM的强大但不透明的特性使传统伦理标准失效，需新标准以指导AMA的社会整合。

Method: 提出十项功能标准，如道德一致性、上下文敏感性和规范性完整性，并通过模拟场景（如自动驾驶公交）验证。

Result: 修订标准为LLM-based AMA提供实用指南，促进道德对齐和社会效益。

Conclusion: 新标准有助于LLM-based AMA在道德和社会层面的优化与整合。

Abstract: The advancement of powerful yet opaque large language models (LLMs)
necessitates a fundamental revision of the philosophical criteria used to
evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the
assumption of transparent architectures, which LLMs defy due to their
stochastic outputs and opaque internal states. This paper argues that
traditional ethical criteria are pragmatically obsolete for LLMs due to this
mismatch. Engaging with core themes in the philosophy of technology, this paper
proffers a revised set of ten functional criteria to evaluate LLM-based
artificial moral agents: moral concordance, context sensitivity, normative
integrity, metaethical awareness, system resilience, trustworthiness,
corrigibility, partial transparency, functional autonomy, and moral
imagination. These guideposts, applied to what we term "SMA-LLS" (Simulating
Moral Agency through Large Language Systems), aim to steer AMAs toward greater
alignment and beneficial societal integration in the coming years. We
illustrate these criteria using hypothetical scenarios involving an autonomous
public bus (APB) to demonstrate their practical applicability in morally
salient contexts.

</details>


### [43] [Higher-Order Pattern Unification Modulo Similarity Relations](https://arxiv.org/abs/2507.13208)
*Besik Dundua,Temur Kutsia*

Main category: cs.AI

TL;DR: 论文提出了一种结合高阶模式和模糊等价关系的统一算法，用于解决决策任务中的模糊推理问题。


<details>
  <summary>Details</summary>
Motivation: 在涉及抽象函数和谓词的决策任务中，精确匹配往往罕见或不必要，因此需要结合高阶理论和模糊逻辑的高效推理方法。

Method: 采用高阶模式和基于最小T-范数的模糊等价关系，提出了一种统一算法，并证明了其终止性、可靠性和完备性。

Result: 算法在可统一的情况下计算出一个具有最高近似度的最一般统一子。

Conclusion: 该算法为高阶模糊推理提供了一种高效且理论完备的解决方案。

Abstract: The combination of higher-order theories and fuzzy logic can be useful in
decision-making tasks that involve reasoning across abstract functions and
predicates, where exact matches are often rare or unnecessary. Developing
efficient reasoning and computational techniques for such a combined formalism
presents a significant challenge. In this paper, we adopt a more
straightforward approach aiming at integrating two well-established and
computationally well-behaved components: higher-order patterns on one side and
fuzzy equivalences expressed through similarity relations based on minimum
T-norm on the other. We propose a unification algorithm for higher-order
patterns modulo these similarity relations and prove its termination,
soundness, and completeness. This unification problem, like its crisp
counterpart, is unitary. The algorithm computes a most general unifier with the
highest degree of approximation when the given terms are unifiable.

</details>


### [44] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: 论文提出了一种名为GEA（Generative Energy Arena）的新方法，通过公开竞技场评估大型语言模型的能源效率，并发现用户在了解能源消耗后更倾向于选择更节能的模型。


<details>
  <summary>Details</summary>
Motivation: 当前评估大型语言模型的方法存在局限性，如自动化基准与人类评价相关性低，而传统人类评价方法又难以扩展。此外，模型的能源消耗问题日益重要，需要研究能源意识如何影响用户选择。

Method: 提出GEA（Generative Energy Arena），在模型评估过程中加入能源消耗信息，通过公开竞技场让用户自由评估并排名模型。

Result: 初步结果显示，用户在了解能源消耗后，大多倾向于选择更小、更节能的模型。

Conclusion: 研究表明，对于大多数用户交互，高性能模型的额外成本和能源消耗并未显著提升感知质量，因此更节能的模型更具吸引力。

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


### [45] [FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming](https://arxiv.org/abs/2507.13337)
*Gal Beniamini,Yuval Dor,Alon Vinnikov,Shir Granot Peled,Or Weinstein,Or Sharir,Noam Wies,Tomer Nussbaum,Ido Ben Shaul,Tomer Zekharya,Yoav Levine,Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: 论文提出了FormulaOne基准，用于评估前沿AI模型在复杂研究问题上的表现，结果显示当前最先进模型表现极差。


<details>
  <summary>Details</summary>
Motivation: 探讨前沿AI模型是否接近人类专家水平，通过真实研究问题而非人为设计的编程题来测试其能力。

Method: 构建FormulaOne基准，结合图论、逻辑和算法，生成高难度问题，并设计评估框架。

Result: 最先进模型如OpenAI的o3在FormulaOne上表现极差，解决率低于1%。

Conclusion: 前沿AI模型在复杂领域仍远未达到专家水平，FormulaOne为未来研究提供了重要基准。

Abstract: Frontier AI models demonstrate formidable breadth of knowledge. But how close
are they to true human -- or superhuman -- expertise? Genuine experts can
tackle the hardest problems and push the boundaries of scientific
understanding. To illuminate the limits of frontier model capabilities, we turn
away from contrived competitive programming puzzles, and instead focus on
real-life research problems.
  We construct FormulaOne, a benchmark that lies at the intersection of graph
theory, logic, and algorithms, all well within the training distribution of
frontier models. Our problems are incredibly demanding, requiring an array of
reasoning steps. The dataset has three key properties. First, it is of
commercial interest and relates to practical large-scale optimisation problems,
such as those arising in routing, scheduling, and network design. Second, it is
generated from the highly expressive framework of Monadic Second-Order (MSO)
logic on graphs, paving the way toward automatic problem generation at scale;
ideal for building RL environments. Third, many of our problems are intimately
related to the frontier of theoretical computer science, and to central
conjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As
such, any significant algorithmic progress on our dataset, beyond known
results, could carry profound theoretical implications.
  Remarkably, state-of-the-art models like OpenAI's o3 fail entirely on
FormulaOne, solving less than 1% of the questions, even when given 10 attempts
and explanatory fewshot examples -- highlighting how far they remain from
expert-level understanding in some domains. To support further research, we
additionally curate FormulaOne-Warmup, offering a set of simpler tasks, from
the same distribution. We release the full corpus along with a comprehensive
evaluation framework.

</details>
