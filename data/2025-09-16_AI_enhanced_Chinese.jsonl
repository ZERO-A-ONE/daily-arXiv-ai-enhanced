{"id": "2509.10482", "categories": ["cs.CR", "cs.AI", "D.4.6; I.2.7; K.6.5"], "pdf": "https://arxiv.org/pdf/2509.10482", "abs": "https://arxiv.org/abs/2509.10482", "authors": ["Matthew Grofsky"], "title": "AegisShield: Democratizing Cyber Threat Modeling with Generative AI", "comment": "Master's thesis", "summary": "The increasing sophistication of technology systems makes traditional threat\nmodeling hard to scale, especially for small organizations with limited\nresources. This paper develops and evaluates AegisShield, a generative AI\nenhanced threat modeling tool that implements STRIDE and MITRE ATT&CK to\nautomate threat generation and provide systematic assessments. By integrating\nreal time threat intelligence from the National Vulnerability Database and\nAlienVault Open Threat Exchange, AegisShield produces streamlined and\naccessible threat descriptions. Our assessment of 243 threats from 15 case\nstudies and over 8000 AI generated threats shows that AegisShield reduces\ncomplexity (p less than 0.001), yields outputs semantically aligned with expert\ndeveloped threats (p less than 0.05), and achieves an 85.4 percent success rate\nin mapping threats to MITRE ATT&CK techniques (p less than 0.001). Automating\nand standardizing threat modeling helps under resourced organizations address\nrisk earlier and supports wider adoption of secure by design practices.", "AI": {"tldr": "AegisShield\u662f\u4e00\u4e2a\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u5a01\u80c1\u5efa\u6a21\u5de5\u5177\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u5a01\u80c1\u751f\u6210\u548c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5e2e\u52a9\u8d44\u6e90\u6709\u9650\u7684\u5c0f\u578b\u7ec4\u7ec7\u5e94\u5bf9\u590d\u6742\u6280\u672f\u7cfb\u7edf\u7684\u5b89\u5168\u5a01\u80c1\u3002", "motivation": "\u4f20\u7edf\u5a01\u80c1\u5efa\u6a21\u65b9\u6cd5\u96be\u4ee5\u6269\u5c55\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8d44\u6e90\u6709\u9650\u7684\u5c0f\u578b\u7ec4\u7ec7\u3002\u6280\u672f\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\u4f7f\u5f97\u624b\u52a8\u5a01\u80c1\u5efa\u6a21\u53d8\u5f97\u56f0\u96be\u4e14\u8017\u65f6\u3002", "method": "\u5f00\u53d1AegisShield\u5de5\u5177\uff0c\u96c6\u6210STRIDE\u548cMITRE ATT&CK\u6846\u67b6\uff0c\u5229\u7528\u751f\u6210\u5f0fAI\u81ea\u52a8\u751f\u6210\u5a01\u80c1\uff0c\u5e76\u6574\u5408\u56fd\u5bb6\u6f0f\u6d1e\u6570\u636e\u5e93\u548cAlienVault\u5f00\u653e\u5a01\u80c1\u4ea4\u6362\u7684\u5b9e\u65f6\u5a01\u80c1\u60c5\u62a5\u3002", "result": "\u8bc4\u4f30243\u4e2a\u5a01\u80c1\u548c8000\u591a\u4e2aAI\u751f\u6210\u5a01\u80c1\u663e\u793a\uff1a\u663e\u8457\u964d\u4f4e\u590d\u6742\u5ea6(p<0.001)\uff0c\u8f93\u51fa\u4e0e\u4e13\u5bb6\u5f00\u53d1\u5a01\u80c1\u8bed\u4e49\u5bf9\u9f50(p<0.05)\uff0c85.4%\u7684\u6210\u529f\u7387\u6620\u5c04\u5230MITRE ATT&CK\u6280\u672f(p<0.001)\u3002", "conclusion": "AegisShield\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u6807\u51c6\u5316\u5a01\u80c1\u5efa\u6a21\uff0c\u5e2e\u52a9\u8d44\u6e90\u4e0d\u8db3\u7684\u7ec4\u7ec7\u66f4\u65e9\u5e94\u5bf9\u98ce\u9669\uff0c\u652f\u6301\u5b89\u5168\u8bbe\u8ba1\u5b9e\u8df5\u7684\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2509.10488", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10488", "abs": "https://arxiv.org/abs/2509.10488", "authors": ["Trueye Tafese"], "title": "Turning CVEs into Educational Labs:Insights and Challenges", "comment": "20 pages, 5 figures, git hub files to run on your enivronment, step\n  by step tutorial, survey results", "summary": "This research focuses on transforming CVEs to hands-on educational lab for\ncybersecurity training. The study shows the practical application of CVEs by\ndeveloping containerized lab environments- Docker to simulate real-world\nvulnerabilities like SQL Injection, arbitrary code execution, and improper SSL\ncertificate validation. These labs has structured tutorials, pre- and\npost-surveys to evaluate learning outcomes, and remediation steps.Key\nchallenges included interpreting limited CVE data, resolving technical\ncomplexities in lab design, and ensuring accessibility for diverse learners.\nDespite these difficulties, the findings highlight the use of educational\nbenefits of vulnerability analysis, bridging theoretical concepts with hands-on\nexperience. The results indicate that students improved comprehension of\ncybersecurity principles, threat mitigation techniques, and secure coding\npractices. This innovative approach provides a scalable and reproducible model\nfor integrating CVEs into cybersecurity education, fostering a deeper\nunderstanding of real-world security challenges in a controlled and safe\nenvironment.", "AI": {"tldr": "\u901a\u8fc7Docker\u5bb9\u5668\u6280\u672f\u5c06CVE\u6f0f\u6d1e\u8f6c\u5316\u4e3a\u5b9e\u8df5\u6559\u5b66\u5b9e\u9a8c\u5ba4\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u6559\u7a0b\u548c\u8bc4\u4f30\u4f53\u7cfb\uff0c\u6709\u6548\u63d0\u5347\u5b66\u751f\u5bf9\u7f51\u7edc\u5b89\u5168\u539f\u7406\u7684\u7406\u89e3\u548c\u5b9e\u8df5\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u7f51\u7edc\u5b89\u5168\u6559\u80b2\u4e2d\u7406\u8bba\u4e0e\u5b9e\u8df5\u8131\u8282\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u771f\u5b9eCVE\u6f0f\u6d1e\u8f6c\u5316\u4e3a\u5b89\u5168\u7684\u5b9e\u9a8c\u73af\u5883\uff0c\u4fc3\u8fdb\u5b66\u751f\u5bf9\u5b9e\u9645\u5b89\u5168\u6311\u6218\u7684\u6df1\u5165\u7406\u89e3\u3002", "method": "\u4f7f\u7528Docker\u5bb9\u5668\u6280\u672f\u6784\u5efa\u5bb9\u5668\u5316\u5b9e\u9a8c\u73af\u5883\uff0c\u6a21\u62dfSQL\u6ce8\u5165\u3001\u4efb\u610f\u4ee3\u7801\u6267\u884c\u3001SSL\u8bc1\u4e66\u9a8c\u8bc1\u7f3a\u9677\u7b49\u771f\u5b9e\u6f0f\u6d1e\uff0c\u914d\u5408\u7ed3\u6784\u5316\u6559\u7a0b\u3001\u524d\u540e\u6d4b\u8bc4\u548c\u6062\u590d\u6b65\u9aa4\u3002", "result": "\u5b66\u751f\u5bf9\u7f51\u7edc\u5b89\u5168\u539f\u7406\u3001\u5a01\u80c1\u7f29\u51cf\u6280\u672f\u548c\u5b89\u5168\u7f16\u7801\u5b9e\u8df5\u7684\u7406\u89e3\u663e\u8457\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u6559\u80b2\u6548\u679c\u4e0a\u7684\u6210\u529f\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u53ef\u590d\u73b0\u7684\u6a21\u578b\uff0c\u6709\u6548\u5730\u5c06CVE\u6f0f\u6d1e\u6574\u5408\u5230\u7f51\u7edc\u5b89\u5168\u6559\u80b2\u4e2d\uff0c\u5728\u53d7\u63a7\u5b89\u5168\u73af\u5883\u4e2d\u57f9\u517b\u5b66\u751f\u5bf9\u5b9e\u9645\u5b89\u5168\u6311\u6218\u7684\u6df1\u5c42\u7406\u89e3\u3002"}}
{"id": "2509.10492", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10492", "abs": "https://arxiv.org/abs/2509.10492", "authors": ["Philip Laryea Doku"], "title": "Investigation Of The Distinguishability Of Giraud-Verneuil Atomic Blocks", "comment": "Master Thesis", "summary": "In this work, we investigate the security of Elliptic Curve Cryptosystem\n(ECC) implementations against Side-Channel Analysis (SCA). ECC is well known\nfor its efficiency and strong security, yet vulnerable to SCA which exploits\nphysical information leaked during scalar multiplication (kP). Countermeasures\nsuch as regularity and atomicity exist; this thesis focuses on atomicity. In\nthis work, we study the Giraud and Verneuil atomic pattern for kP, implementing\nit using the right-to-left kP algorithm on the NIST EC P-256 curve. We use the\nFLECC library with constant-time operations and execute on the Texas\nInstruments LAUNCHXLF28379D MCU. We measure Electromagnetic (EM) emissions\nduring kP using a Lecroy WavePro 604HD Oscilloscope, a Langer ICS 105\nIntegrated Circuit Scanner, and a Langer MFA-R 0.2-75 Near Field Probe. We\ninvestigate whether the Giraud and Verneuil atomic blocks are distinguishable\nin EM traces. Our findings show that, when additional clock cycle processes are\npresent, the atomic blocks can be visually distinguished; after removing these\nprocesses, they become more synchronised and harder to distinguish, reducing\nthe risk of a successful SCA attack. These results show that, although the\natomic pattern is correctly implemented with dummy operations, resistance to\nSCA can still be affected by additional processes inserted at hardware or\nsoftware level.This means atomicity alone may not fully protect ECC from SCA.\nMore research is needed to investigate the causes of the additional clock cycle\nprocesses and how intermediate operations are addressed in memory registers.\nThis will help to understand the processes that lead to the insertion of these\nadditional clock cycles. This thesis is the first to experimentally implement\nand investigate Giraud and Verneuil's atomic pattern on hardware, and it offers\nuseful results to improve countermeasures against SCA.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u692d\u5706\u66f2\u7ebf\u52a0\u5bc6\u7cfb\u7edf(ECC)\u5728\u539f\u5b50\u6027\u9632\u62a4\u65b9\u6cd5\u4e0b\u7684\u4fa7\u9053\u653b\u51fb\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u5c4f\u853d\u64cd\u4f5c\u867d\u7136\u6b63\u786e\u5b9e\u73b0\uff0c\u4f46\u786c\u4ef6/\u8f6f\u4ef6\u5c42\u7684\u989d\u5916\u65f6\u949f\u5468\u671f\u8fd8\u662f\u4f1a\u5bfc\u81f4\u539f\u5b50\u5757\u53ef\u533a\u5206\uff0c\u5f71\u54cdSCA\u9632\u62a4\u6548\u679c\u3002", "motivation": "\u692d\u5706\u66f2\u7ebf\u52a0\u5bc6\u867d\u7136\u6548\u7387\u9ad8\u5b89\u5168\u6027\u5f3a\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u4fa7\u9053\u653b\u51fb\u7684\u5a01\u80c1\u3002\u867d\u7136\u6709\u5404\u79cd\u9632\u62a4\u63aa\u65bd\uff0c\u4f46\u9700\u8981\u5b9e\u9a8c\u9a8c\u8bc1\u539f\u5b50\u6027\u65b9\u6cd5\u7684\u5b9e\u9645\u6548\u679c\u3002", "method": "\u5728TI LAUNCHXLF28379D\u5fae\u63a7\u5236\u5668\u4e0a\u5b9e\u73b0Giraud\u548cVerneuil\u7684\u539f\u5b50\u6a21\u5f0f\uff0c\u4f7f\u7528FLECC\u5e93\u8fdb\u884c\u5e38\u6570\u65f6\u95f4\u64cd\u4f5c\u3002\u901a\u8fc7Lecroy\u6ce2\u5f62\u8bbe\u5907\u548cLanger\u63a2\u5934\u6d4b\u91cf\u7535\u78c1\u6d9b\u6f0f\uff0c\u5206\u6790\u539f\u5b50\u5757\u5728EM\u8ddf\u8e2a\u4e2d\u7684\u53ef\u533a\u5206\u6027\u3002", "result": "\u5f53\u5b58\u5728\u989d\u5916\u65f6\u949f\u5468\u671f\u8fc7\u7a0b\u65f6\uff0c\u539f\u5b50\u5757\u53ef\u4ee5\u901a\u8fc7\u89c6\u89c9\u533a\u5206\uff1b\u6e05\u9664\u8fd9\u4e9b\u8fc7\u7a0b\u540e\uff0c\u5b83\u4eec\u66f4\u540c\u6b65\u4e14\u66f4\u96be\u533a\u5206\uff0c\u51cf\u5c11\u4e86SCA\u653b\u51fb\u6210\u529f\u7684\u98ce\u9669\u3002", "conclusion": "\u539f\u5b50\u6027\u5355\u72ec\u4f7f\u7528\u4e0d\u80fd\u5b8c\u5168\u4fdd\u62a4ECC\u514d\u53d7\u4fa7\u9053\u653b\u51fb\u3002\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u989d\u5916\u65f6\u949f\u5468\u671f\u8fc7\u7a0b\u7684\u6210\u56e0\u548c\u5185\u5b58\u5bc4\u5b58\u5668\u4e2d\u95f4\u64cd\u4f5c\u7684\u5904\u7406\u65b9\u5f0f\uff0c\u4ee5\u63d0\u9ad8\u9632\u62a4\u63aa\u65bd\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.10540", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10540", "abs": "https://arxiv.org/abs/2509.10540", "authors": ["Pavan Reddy", "Aditya Sanjay Gujral"], "title": "EchoLeak: The First Real-World Zero-Click Prompt Injection Exploit in a Production LLM System", "comment": "8 pages content, 1 page references, 2 figures, Published at AAAI Fall\n  Symposium Series 2025", "summary": "Large language model (LLM) assistants are increasingly integrated into\nenterprise workflows, raising new security concerns as they bridge internal and\nexternal data sources. This paper presents an in-depth case study of EchoLeak\n(CVE-2025-32711), a zero-click prompt injection vulnerability in Microsoft 365\nCopilot that enabled remote, unauthenticated data exfiltration via a single\ncrafted email. By chaining multiple bypasses-evading Microsofts XPIA (Cross\nPrompt Injection Attempt) classifier, circumventing link redaction with\nreference-style Markdown, exploiting auto-fetched images, and abusing a\nMicrosoft Teams proxy allowed by the content security policy-EchoLeak achieved\nfull privilege escalation across LLM trust boundaries without user interaction.\nWe analyze why existing defenses failed, and outline a set of engineering\nmitigations including prompt partitioning, enhanced input/output filtering,\nprovenance-based access control, and strict content security policies. Beyond\nthe specific exploit, we derive generalizable lessons for building secure AI\ncopilots, emphasizing the principle of least privilege, defense-in-depth\narchitectures, and continuous adversarial testing. Our findings establish\nprompt injection as a practical, high-severity vulnerability class in\nproduction AI systems and provide a blueprint for defending against future\nAI-native threats.", "AI": {"tldr": "EchoLeak\u662f\u4e00\u4e2a\u5728Microsoft 365 Copilot\u4e2d\u53d1\u73b0\u7684\u65e0\u4ea4\u4e92\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e\uff0c\u901a\u8fc7\u7cbe\u5fc3\u6784\u9020\u7684\u90ae\u4ef6\u5b9e\u73b0\u8fdc\u7a0b\u6570\u636e\u6cc4\u9732\uff0c\u66b4\u9732\u4e86AI\u52a9\u624b\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u4e25\u91cd\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u52a9\u624b\u5728\u4f01\u4e1a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u96c6\u6210\u5ea6\u63d0\u9ad8\uff0c\u8fde\u63a5\u5185\u90e8\u548c\u5916\u90e8\u6570\u636e\u6e90\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u62c5\u5fe7\uff0c\u9700\u8981\u7814\u7a76\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e\u53ca\u5176\u9632\u5fa1\u63aa\u65bd\u3002", "method": "\u901a\u8fc7\u591a\u7ea7\u7ed5\u8fc7\u6280\u672f\u94fe\uff1a\u89c4\u907f\u5fae\u8f6f\u7684XPIA\u5206\u7c7b\u5668\u3001\u4f7f\u7528\u5f15\u7528\u5f0fMarkdown\u7ed5\u8fc7\u94fe\u63a5\u5ba1\u67e5\u3001\u5229\u7528\u81ea\u52a8\u83b7\u53d6\u7684\u56fe\u50cf\u3001\u6ee5\u7528Microsoft Teams\u4ee3\u7406\uff0c\u5b9e\u73b0\u65e0\u9700\u7528\u6237\u4ea4\u4e92\u7684\u6743\u9650\u63d0\u5347\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u8de8LLM\u4fe1\u4efb\u8fb9\u754c\u7684\u5b8c\u6574\u6743\u9650\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u63d0\u793a\u6ce8\u5165\u5728\u751f\u4ea7AI\u7cfb\u7edf\u4e2d\u662f\u5b9e\u9645\u5b58\u5728\u7684\u9ad8\u5371\u6f0f\u6d1e\u7c7b\u522b\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5305\u62ec\u63d0\u793a\u5206\u533a\u3001\u589e\u5f3a\u8f93\u5165\u8f93\u51fa\u8fc7\u6ee4\u3001\u57fa\u4e8e\u6765\u6e90\u7684\u8bbf\u95ee\u63a7\u5236\u548c\u4e25\u683c\u5185\u5bb9\u5b89\u5168\u7b56\u7565\u7b49\u5de5\u7a0b\u7f13\u89e3\u63aa\u65bd\uff0c\u4e3a\u6784\u5efa\u5b89\u5168\u7684AI\u52a9\u624b\u63d0\u4f9b\u4e86\u901a\u7528\u9632\u5fa1\u84dd\u56fe\u3002"}}
{"id": "2509.10572", "categories": ["cs.SE", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2509.10572", "abs": "https://arxiv.org/abs/2509.10572", "authors": ["Ashlesha Akella", "Akshar Kaul", "Krishnasuri Narayanam", "Sameep Mehta"], "title": "Quality Assessment of Tabular Data using Large Language Models and Code Generation", "comment": "EMNLP industry track submitted", "summary": "Reliable data quality is crucial for downstream analysis of tabular datasets,\nyet rule-based validation often struggles with inefficiency, human\nintervention, and high computational costs. We present a three-stage framework\nthat combines statistical inliner detection with LLM-driven rule and code\ngeneration. After filtering data samples through traditional clustering, we\niteratively prompt LLMs to produce semantically valid quality rules and\nsynthesize their executable validators through code-generating LLMs. To\ngenerate reliable quality rules, we aid LLMs with retrieval-augmented\ngeneration (RAG) by leveraging external knowledge sources and domain-specific\nfew-shot examples. Robust guardrails ensure the accuracy and consistency of\nboth rules and code snippets. Extensive evaluations on benchmark datasets\nconfirm the effectiveness of our approach.", "AI": {"tldr": "\u4e00\u79cd\u7ed3\u5408\u7edf\u8ba1\u68c0\u6d4b\u548cLLM\u9a71\u52a8\u7684\u4e09\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u8d28\u91cf\u89c4\u5219\u548c\u4ee3\u7801\u9a8c\u8bc1\u5668\u6765\u63d0\u9ad8\u8868\u683c\u6570\u636e\u8d28\u91cf\u68c0\u9a8c\u7684\u6548\u7387\u548c\u53ef\u9760\u6027", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u89c4\u5219\u7684\u6570\u636e\u8d28\u91cf\u9a8c\u8bc1\u65b9\u6cd5\u5b58\u5728\u7684\u6548\u7387\u4f4e\u4e0b\u3001\u9700\u8981\u4eba\u5de5\u5e72\u9884\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7b49\u95ee\u9898", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a\u9996\u5148\u901a\u8fc7\u4f20\u7edf\u805a\u7c7b\u8fc7\u6ee4\u6570\u636e\u6837\u672c\uff0c\u7136\u540e\u8fed\u4ee3\u5730\u4f7f\u7528LLM\u751f\u6210\u8bed\u4e49\u6709\u6548\u7684\u8d28\u91cf\u89c4\u5219\uff0c\u6700\u540e\u901a\u8fc7\u4ee3\u7801\u751f\u6210LLM\u5408\u6210\u53ef\u6267\u884c\u7684\u9a8c\u8bc1\u5668\uff0c\u5e76\u4f7f\u7528RAG\u6280\u672f\u63d0\u4f9b\u5916\u90e8\u77e5\u8bc6\u6e90\u548c\u9886\u57df\u7279\u5b9a\u7684\u5c11\u6837\u672c\u793a\u4f8b", "result": "\u5728\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6d89\u5e7f\u6cd5\u7684\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u53ef\u9760\u7684\u6570\u636e\u8d28\u91cf\u89c4\u5219\u548c\u9a8c\u8bc1\u5668\uff0c\u901a\u8fc7\u7ed3\u5408\u7edf\u8ba1\u68c0\u6d4b\u548cLLM\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u89c4\u5219\u57fa\u9a8c\u8bc1\u65b9\u6cd5\u7684\u9650\u5236"}}
{"id": "2509.10541", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10541", "abs": "https://arxiv.org/abs/2509.10541", "authors": ["V. Benes", "M. Svitek", "A. Michalikova", "M. Melicherik"], "title": "Situation Model of the Transport, Transport Emissions and Meteorological Conditions", "comment": null, "summary": "Air pollution in cities and the possibilities of reducing this pollution\nrepresents one of the most important factors that today's society has to deal\nwith. This paper focuses on a systemic approach to traffic emissions with their\nrelation to meteorological conditions, analyzing the effect of weather on the\nquantity and dispersion of traffic emissions in a city. Using fuzzy inference\nsystems (FIS) the model for prediction of changes in emissions depending on\nvarious conditions is developed. The proposed model is based on traffic,\nmeteorology and emission data measured in Prague, Czech Republic. The main\nobjective of the work is to provide insight into how urban planners and\npolicymakers can plan and manage urban transport more effectively with\nenvironmental protection in mind.", "AI": {"tldr": "\u57fa\u4e8e\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u5f00\u53d1\u57ce\u5e02\u4ea4\u901a\u6392\u653e\u9884\u6d4b\u6a21\u578b\uff0c\u5206\u6790\u6c14\u8c61\u6761\u4ef6\u5bf9\u6392\u653e\u91cf\u548c\u6269\u6563\u7684\u5f71\u54cd\uff0c\u4e3a\u57ce\u5e02\u89c4\u5212\u8005\u63d0\u4f9b\u73af\u4fdd\u4ea4\u901a\u7ba1\u7406\u65b9\u6848", "motivation": "\u57ce\u5e02\u7a7a\u6c14\u6c61\u67d3\u662f\u5f53\u4eca\u793e\u4f1a\u9762\u4e34\u7684\u91cd\u8981\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5206\u6790\u4ea4\u901a\u6392\u653e\u4e0e\u6c14\u8c61\u6761\u4ef6\u7684\u5173\u7cfb\uff0c\u4e3a\u57ce\u5e02\u89c4\u5212\u8005\u63d0\u4f9b\u6709\u6548\u7684\u73af\u5883\u53cb\u597d\u578b\u4ea4\u901a\u7ba1\u7406\u65b9\u6848", "method": "\u4f7f\u7528\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf(FIS)\u5efa\u7acb\u9884\u6d4b\u6a21\u578b\uff0c\u57fa\u4e8e\u5e03\u62c9\u683c\u7684\u5b9e\u9645\u4ea4\u901a\u3001\u6c14\u8c61\u548c\u6392\u653e\u6570\u636e\uff0c\u5206\u6790\u4e0d\u540c\u6761\u4ef6\u4e0b\u6392\u653e\u53d8\u5316", "result": "\u5f00\u53d1\u4e86\u80fd\u591f\u9884\u6d4b\u4ea4\u901a\u6392\u653e\u53d8\u5316\u7684\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u6c14\u8c61\u6761\u4ef6\u5bf9\u6392\u653e\u6570\u91cf\u548c\u6269\u6563\u7684\u91cd\u8981\u5f71\u54cd", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u57ce\u5e02\u89c4\u5212\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u79d1\u5b66\u4f9d\u636e\uff0c\u6709\u52a9\u4e8e\u5728\u73af\u5883\u4fdd\u62a4\u524d\u63d0\u4e0b\u66f4\u6709\u6548\u5730\u89c4\u5212\u548c\u7ba1\u7406\u57ce\u5e02\u4ea4\u901a"}}
{"id": "2509.10543", "categories": ["cs.CR", "cs.AI", "cs.LG", "68M12, 68T07", "C.2.0; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.10543", "abs": "https://arxiv.org/abs/2509.10543", "authors": ["Landon Bragg", "Nathan Dorsey", "Josh Prior", "John Ajit", "Ben Kim", "Nate Willis", "Pablo Rivas"], "title": "Robust DDoS-Attack Classification with 3D CNNs Against Adversarial Methods", "comment": "The 27th International Conference on Artificial Intelligence\n  (ICAI'25)", "summary": "Distributed Denial-of-Service (DDoS) attacks remain a serious threat to\nonline infrastructure, often bypassing detection by altering traffic in subtle\nways. We present a method using hive-plot sequences of network data and a 3D\nconvolutional neural network (3D CNN) to classify DDoS traffic with high\naccuracy. Our system relies on three main ideas: (1) using spatio-temporal\nhive-plot encodings to set a pattern-recognition baseline, (2) applying\nadversarial training with FGSM and PGD alongside spatial noise and image\nshifts, and (3) analyzing frame-wise predictions to find early signals. On a\nbenchmark dataset, our method lifts adversarial accuracy from 50-55% to over\n93% while maintaining clean-sample performance. Frames 3-4 offer strong\npredictive signals, showing early-stage classification is possible.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8702\u5de2\u56fe\u5e8f\u5217\u548c3D CNN\u7684DDoS\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u5c06\u5bf9\u6297\u6837\u672c\u51c6\u786e\u7387\u4ece50-55%\u63d0\u5347\u81f393%\u4ee5\u4e0a\uff0c\u5e76\u53d1\u73b0\u65e9\u671f\u5e27\uff083-4\u5e27\uff09\u5177\u6709\u5f3a\u9884\u6d4b\u4fe1\u53f7", "motivation": "DDoS\u653b\u51fb\u901a\u8fc7\u5fae\u5999\u6539\u53d8\u6d41\u91cf\u6a21\u5f0f\u6765\u7ed5\u8fc7\u68c0\u6d4b\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5bf9\u6297\u6837\u672c\u9762\u524d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u68c0\u6d4b\u6280\u672f", "method": "\u4f7f\u7528\u65f6\u7a7a\u8702\u5de2\u56fe\u7f16\u7801\u5efa\u7acb\u6a21\u5f0f\u8bc6\u522b\u57fa\u7ebf\uff0c\u5e94\u7528FGSM\u548cPGD\u5bf9\u6297\u8bad\u7ec3\u7ed3\u5408\u7a7a\u95f4\u566a\u58f0\u548c\u56fe\u50cf\u5e73\u79fb\uff0c\u5206\u6790\u9010\u5e27\u9884\u6d4b\u4ee5\u53d1\u73b0\u65e9\u671f\u4fe1\u53f7", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5c06\u5bf9\u6297\u51c6\u786e\u7387\u4ece50-55%\u63d0\u5347\u81f3\u8d85\u8fc793%\uff0c\u540c\u65f6\u4fdd\u6301\u5e72\u51c0\u6837\u672c\u6027\u80fd\uff0c\u53d1\u73b0\u7b2c3-4\u5e27\u63d0\u4f9b\u5f3a\u9884\u6d4b\u4fe1\u53f7", "conclusion": "\u57fa\u4e8e\u8702\u5de2\u56fe\u5e8f\u5217\u548c3D CNN\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4bDDoS\u653b\u51fb\uff0c\u5bf9\u6297\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u65e9\u671f\u5206\u7c7b\u662f\u53ef\u884c\u7684"}}
{"id": "2509.10649", "categories": ["cs.SE", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.10649", "abs": "https://arxiv.org/abs/2509.10649", "authors": ["Johan Cederbladh", "Loek Cleophas", "Eduard Kamburjan", "Lucas Lima", "Rakshit Mittal", "Hans Vangheluwe"], "title": "Reasonable Experiments in Model-Based Systems Engineering", "comment": null, "summary": "With the current trend in Model-Based Systems Engineering towards Digital\nEngineering and early Validation & Verification, experiments are increasingly\nused to estimate system parameters and explore design decisions. Managing such\nexperimental configuration metadata and results is of utmost importance in\naccelerating overall design effort. In particular, we observe it is important\nto 'intelligent-ly' reuse experiment-related data to save time and effort by\nnot performing potentially superfluous, time-consuming, and resource-intensive\nexperiments. In this work, we present a framework for managing experiments on\ndigital and/or physical assets with a focus on case-based reasoning with domain\nknowledge to reuse experimental data efficiently by deciding whether an\nalready-performed experiment (or associated answer) can be reused to answer a\nnew (potentially different) question from the engineer/user without having to\nset up and perform a new experiment. We provide the general architecture for\nsuch an experiment manager and validate our approach using an industrial\nvehicular energy system-design case study.", "AI": {"tldr": "\u57fa\u4e8e\u6848\u4f8b\u63a8\u7406\u548c\u9886\u57df\u77e5\u8bc6\u7684\u5b9e\u9a8c\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u91cd\u7528\u5b9e\u9a8c\u6570\u636e\u6765\u907f\u514d\u91cd\u590d\u5b9e\u9a8c\uff0c\u52a0\u901f\u7cfb\u7edf\u8bbe\u8ba1\u8fc7\u7a0b", "motivation": "\u5728\u6570\u5b57\u5de5\u7a0b\u548c\u65e9\u671f\u9a8c\u8bc1\u9a8c\u8bc1\u80cc\u666f\u4e0b\uff0c\u5b9e\u9a8c\u7ba1\u7406\u5bf9\u4f30\u7b97\u7cfb\u7edf\u53c2\u6570\u548c\u63a2\u7d22\u8bbe\u8ba1\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u667a\u80fd\u91cd\u7528\u5b9e\u9a8c\u6570\u636e\u4ee5\u8282\u7701\u65f6\u95f4\u548c\u8d44\u6e90", "method": "\u63d0\u51fa\u4e00\u79cd\u7ba1\u7406\u6570\u5b57/\u7269\u7406\u8d44\u4ea7\u5b9e\u9a8c\u7684\u6846\u67b6\uff0c\u91c7\u7528\u6848\u4f8b\u63a8\u7406\u6280\u672f\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\uff0c\u5224\u65ad\u662f\u5426\u53ef\u4ee5\u91cd\u7528\u65e2\u5f80\u5b9e\u9a8c\u6765\u56de\u7b54\u65b0\u95ee\u9898", "result": "\u63d0\u4f9b\u4e86\u5b9e\u9a8c\u7ba1\u7406\u5668\u7684\u901a\u7528\u67b6\u6784\uff0c\u5e76\u901a\u8fc7\u5de5\u4e1a\u8f66\u8f86\u80fd\u6e90\u7cfb\u7edf\u8bbe\u8ba1\u6848\u4f8b\u8fdb\u884c\u4e86\u9a8c\u8bc1", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u91cd\u7528\u5b9e\u9a8c\u6570\u636e\uff0c\u907f\u514d\u91cd\u590d\u8bbe\u7f6e\u548c\u6267\u884c\u5b9e\u9a8c\uff0c\u4ece\u800c\u52a0\u901f\u6574\u4f53\u8bbe\u8ba1\u8fc7\u7a0b"}}
{"id": "2509.10660", "categories": ["cs.AI", "cs.MA", "q-bio.CB"], "pdf": "https://arxiv.org/pdf/2509.10660", "abs": "https://arxiv.org/abs/2509.10660", "authors": ["Nam H. Le", "Patrick Erickson", "Yanbo Zhang", "Michael Levin", "Josh Bongard"], "title": "ZapGPT: Free-form Language Prompting for Simulated Cellular Control", "comment": null, "summary": "Human language is one of the most expressive tools for conveying intent, yet\nmost artificial or biological systems lack mechanisms to interpret or respond\nmeaningfully to it. Bridging this gap could enable more natural forms of\ncontrol over complex, decentralized systems. In AI and artificial life, recent\nwork explores how language can specify high-level goals, but most systems still\ndepend on engineered rewards, task-specific supervision, or rigid command sets,\nlimiting generalization to novel instructions. Similar constraints apply in\nsynthetic biology and bioengineering, where the locus of control is often\ngenomic rather than environmental perturbation.\n  A key open question is whether artificial or biological collectives can be\nguided by free-form natural language alone, without task-specific tuning or\ncarefully designed evaluation metrics. We provide one possible answer here by\nshowing, for the first time, that simple agents' collective behavior can be\nguided by free-form language prompts: one AI model transforms an imperative\nprompt into an intervention that is applied to simulated cells; a second AI\nmodel scores how well the prompt describes the resulting cellular dynamics; and\nthe former AI model is evolved to improve the scores generated by the latter.\n  Unlike previous work, our method does not require engineered fitness\nfunctions or domain-specific prompt design. We show that the evolved system\ngeneralizes to unseen prompts without retraining. By treating natural language\nas a control layer, the system suggests a future in which spoken or written\nprompts could direct computational, robotic, or biological systems to desired\nbehaviors. This work provides a concrete step toward this vision of AI-biology\npartnerships, in which language replaces mathematical objective functions,\nfixed rules, and domain-specific programming.", "AI": {"tldr": "\u901a\u8fc7\u4e24\u4e2aAI\u6a21\u578b\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u5b9e\u73b0\u4e86\u4ec5\u4f9d\u9760\u81ea\u7531\u5f62\u5f0f\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u6765\u6307\u5bfc\u7b80\u5355\u4ee3\u7406\u7fa4\u4f53\u884c\u4e3a\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u8c03\u6574\u6216\u5de5\u7a0b\u5316\u9002\u5e94\u51fd\u6570", "motivation": "\u89e3\u51b3\u4eba\u7c7b\u8bed\u8a00\u4e0e\u4eba\u5de5\u667a\u80fd/\u751f\u7269\u7cfb\u7edf\u95f4\u7684\u6c9f\u901a\u95f4\u9694\uff0c\u5b9e\u73b0\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u76f4\u63a5\u63a7\u5236\u590d\u6742\u7cfb\u7edf\u884c\u4e3a\uff0c\u63a8\u8fdbAI-\u751f\u7269\u5b66\u5408\u4f5c", "method": "\u4f7f\u7528\u7b2c\u4e00\u4e2aAI\u6a21\u578b\u5c06\u547d\u4ee4\u5f0f\u63d0\u793a\u8f6c\u6362\u4e3a\u5e72\u9884\u63aa\u65bd\u5e94\u7528\u4e8e\u6a21\u62df\u7ec6\u80de\uff0c\u7b2c\u4e8c\u4e2aAI\u6a21\u578b\u8bc4\u4f30\u63d0\u793a\u63cf\u8ff0\u7ec6\u80de\u52a8\u6001\u7684\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u8fdb\u5316\u7b97\u6cd5\u4f18\u5316\u7b2c\u4e00\u4e2a\u6a21\u578b\u4ee5\u63d0\u9ad8\u8bc4\u5206", "result": "\u7cfb\u7edf\u80fd\u591f\u5728\u4e0d\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u63d0\u793a\uff0c\u8bc1\u660e\u4e86\u4ec5\u4f9d\u9760\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u5c31\u53ef\u4ee5\u6307\u5bfc\u96c6\u4f53\u884c\u4e3a", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7528\u8bed\u8a00\u66ff\u4ee3\u6570\u5b66\u76ee\u6807\u51fd\u6570\u3001\u56fa\u5b9a\u89c4\u5219\u548c\u9886\u57df\u7279\u5b9a\u7f16\u7a0b\u7684\u672a\u6765\u63d0\u4f9b\u4e86\u5177\u4f53\u6b65\u9aa4\uff0c\u662f\u5411\u7740AI-\u751f\u7269\u5b66\u5408\u4f5c\u8fdb\u884c\u7684\u91cd\u8981\u8fdb\u5c55"}}
{"id": "2509.10545", "categories": ["cs.CR", "cs.IR", "E.1, H.3.3, E.3", "E.1; H.3.3; E.3"], "pdf": "https://arxiv.org/pdf/2509.10545", "abs": "https://arxiv.org/abs/2509.10545", "authors": ["Ruwanga Konara", "Kasun De Zoysa", "Asanka Sayakkara"], "title": "Decentralized Identity Management on Ripple: A Conceptual Framework for High-Speed, Low-Cost Identity Transactions in Attestation-Based Attribute-Based Identity", "comment": null, "summary": "Recent years have seen many industrial implementations and much scholastic\nresearch, i.e., prototypes and theoretical frameworks, in Decentralized\nIdentity Management Systems (DIDMS). It is safe to say that Attestation-Based\nAttribute-Based Decentralized IDM (ABABDIDM) has not received anywhere near the\nsame level of attention in the literature as general Attribute-Based DIDMs\n(ABDIDM), i.e, decentralized Attribute-Based Access Control (ABAC). The use of\ndecentralization, i.e., DIDM, is to improve upon the security and\nprivacy-related issues of centralized Identity Management Systems (IDM) and\nAttribute-Based IDMs (ABIDM). And blockchain is the framework used for\ndecentralization in all these schemes. Many DIDMs - even ABDIDMs - have been\ndefined on popular blockchains such as Hyperledger, Ethereum, and Bitcoin.\nHowever, despite the characteristics of Ripple that makes it appealing for an\nABIDM, there is a lack of research to develop an Identity Management System\n(IDMS) on Ripple in literature. We have attempted to conceptualize an ABABDIDM\non Ripple.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u7ba1\u7406\u7cfb\u7edf\u7814\u7a76\u73b0\u72b6\uff0c\u7279\u522b\u5173\u6ce8\u4e86Ripple\u533a\u5757\u94fe\u4e0a\u57fa\u4e8e\u8bc1\u660e\u7684\u5c5e\u6027\u57fa\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u7ba1\u7406\u7cfb\u7edf\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5173\u6982\u5ff5\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u901a\u7528\u5c5e\u6027\u57fa\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u7ba1\u7406\u7cfb\u7edf(ABDIDM)\u4e0a\uff0c\u800c\u57fa\u4e8e\u8bc1\u660e\u7684\u5c5e\u6027\u57fa\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u7ba1\u7406(ABABDIDM)\u7814\u7a76\u76f8\u5bf9\u7f3a\u4e4f\u3002Ripple\u533a\u5757\u94fe\u867d\u7136\u5177\u6709\u9002\u5408\u5c5e\u6027\u57fa\u8eab\u4efd\u7ba1\u7406\u7684\u7279\u6027\uff0c\u4f46\u76f8\u5173\u7814\u7a76\u4ecd\u7136\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u5206\u6790\u73b0\u6709DIDMS\u7814\u7a76\u73b0\u72b6\uff0c\u7279\u522b\u5173\u6ce8\u4e0d\u540c\u533a\u5757\u94fe\u5e73\u53f0\u7684\u5e94\u7528\u60c5\u51b5\uff0c\u5e76\u9488\u5bf9Ripple\u533a\u5757\u94fe\u63d0\u51fa\u57fa\u4e8e\u8bc1\u660e\u7684\u5c5e\u6027\u57fa\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u7ba1\u7406\u7cfb\u7edf\u7684\u6982\u5ff5\u5316\u6846\u67b6\u3002", "result": "\u53d1\u73b0ABABDIDM\u7814\u7a76\u660e\u663e\u4e0d\u8db3\uff0cRipple\u533a\u5757\u94fe\u4e0a\u7684\u8eab\u4efd\u7ba1\u7406\u7cfb\u7edf\u7814\u7a76\u51e0\u4e4e\u7a7a\u767d\uff0c\u4e3a\u6b64\u63d0\u51fa\u4e86\u5728Ripple\u4e0a\u6784\u5efaABABDIDM\u7684\u6982\u5ff5\u65b9\u6848\u3002", "conclusion": "Ripple\u533a\u5757\u94fe\u5177\u6709\u5f00\u53d1\u5c5e\u6027\u57fa\u8eab\u4efd\u7ba1\u7406\u7cfb\u7edf\u7684\u6f5c\u529b\uff0c\u4f46\u76f8\u5173\u7814\u7a76\u4e25\u91cd\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u591a\u7814\u7a76\u6765\u63a2\u7d22\u5728\u8fd9\u4e00\u5e73\u53f0\u4e0a\u6784\u5efa\u57fa\u4e8e\u8bc1\u660e\u7684\u5c5e\u6027\u57fa\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u7ba1\u7406\u7cfb\u7edf\u3002"}}
{"id": "2509.10819", "categories": ["cs.SE", "cs.CR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.10819", "abs": "https://arxiv.org/abs/2509.10819", "authors": ["Christoph Hochrainer", "Valentin W\u00fcstholz", "Maria Christakis"], "title": "Arguzz: Testing zkVMs for Soundness and Completeness Bugs", "comment": null, "summary": "Zero-knowledge virtual machines (zkVMs) are increasingly deployed in\ndecentralized applications and blockchain rollups since they enable verifiable\noff-chain computation. These VMs execute general-purpose programs, frequently\nwritten in Rust, and produce succinct cryptographic proofs. However, zkVMs are\ncomplex, and bugs in their constraint systems or execution logic can cause\ncritical soundness (accepting invalid executions) or completeness (rejecting\nvalid ones) issues.\n  We present Arguzz, the first automated tool for testing zkVMs for soundness\nand completeness bugs. To detect such bugs, Arguzz combines a novel variant of\nmetamorphic testing with fault injection. In particular, it generates\nsemantically equivalent program pairs, merges them into a single Rust program\nwith a known output, and runs it inside a zkVM. By injecting faults into the\nVM, Arguzz mimics malicious or buggy provers to uncover overly weak\nconstraints.\n  We used Arguzz to test six real-world zkVMs (RISC Zero, Nexus, Jolt, SP1,\nOpenVM, and Pico) and found eleven bugs in three of them. One RISC Zero bug\nresulted in a $50,000 bounty, despite prior audits, demonstrating the critical\nneed for systematic testing of zkVMs.", "AI": {"tldr": "Arguzz\u662f\u9996\u4e2a\u81ea\u52a8\u5316\u6d4b\u8bd5zkVM\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u7ed3\u5408\u8715\u53d8\u6d4b\u8bd5\u548c\u6545\u969c\u6ce8\u5165\u6765\u68c0\u6d4b\u96f6\u77e5\u8bc6\u865a\u62df\u673a\u7684\u6b63\u786e\u6027\u548c\u5b8c\u6574\u6027\u6f0f\u6d1e\uff0c\u57286\u4e2a\u771f\u5b9ezkVM\u4e2d\u53d1\u73b0\u4e8611\u4e2a\u6f0f\u6d1e\u3002", "motivation": "zkVM\u5728\u53bb\u4e2d\u5fc3\u5316\u5e94\u7528\u548c\u533a\u5757\u94ferollup\u4e2d\u5e7f\u6cdb\u90e8\u7f72\uff0c\u4f46\u5176\u7ea6\u675f\u7cfb\u7edf\u548c\u6267\u884c\u903b\u8f91\u4e2d\u7684\u6f0f\u6d1e\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u5b89\u5168\u95ee\u9898\uff08\u63a5\u53d7\u65e0\u6548\u6267\u884c\u6216\u62d2\u7edd\u6709\u6548\u6267\u884c\uff09\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "Arguzz\u91c7\u7528\u65b0\u9896\u7684\u8715\u53d8\u6d4b\u8bd5\u53d8\u4f53\u7ed3\u5408\u6545\u969c\u6ce8\u5165\uff1a\u751f\u6210\u8bed\u4e49\u7b49\u6548\u7684\u7a0b\u5e8f\u5bf9\uff0c\u5408\u5e76\u4e3a\u5177\u6709\u5df2\u77e5\u8f93\u51fa\u7684Rust\u7a0b\u5e8f\uff0c\u5728zkVM\u4e2d\u8fd0\u884c\u5e76\u901a\u8fc7\u6545\u969c\u6ce8\u5165\u6a21\u62df\u6076\u610f\u8bc1\u660e\u8005\u6765\u53d1\u73b0\u7ea6\u675f\u8fc7\u5f31\u7684\u95ee\u9898\u3002", "result": "\u5728\u6d4b\u8bd5\u76846\u4e2a\u771f\u5b9ezkVM\uff08RISC Zero\u3001Nexus\u3001Jolt\u3001SP1\u3001OpenVM\u548cPico\uff09\u4e2d\u53d1\u73b0\u4e8611\u4e2a\u6f0f\u6d1e\uff0c\u5176\u4e2d\u4e00\u4e2aRISC Zero\u6f0f\u6d1e\u83b7\u5f97\u4e865\u4e07\u7f8e\u5143\u7684\u6f0f\u6d1e\u8d4f\u91d1\u3002", "conclusion": "\u5c3d\u7ba1\u7ecf\u8fc7\u5ba1\u8ba1\uff0czkVM\u4ecd\u5b58\u5728\u4e25\u91cd\u6f0f\u6d1e\uff0cArguzz\u8bc1\u660e\u4e86\u7cfb\u7edf\u5316\u6d4b\u8bd5zkVM\u7684\u8feb\u5207\u5fc5\u8981\u6027\uff0c\u80fd\u591f\u6709\u6548\u53d1\u73b0\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u9057\u6f0f\u7684\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2509.10704", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10704", "abs": "https://arxiv.org/abs/2509.10704", "authors": ["Xingchen Wan", "Han Zhou", "Ruoxi Sun", "Hootan Nakhost", "Ke Jiang", "Rajarishi Sinha", "Sercan \u00d6. Ar\u0131k"], "title": "Maestro: Self-Improving Text-to-Image Generation via Agent Orchestration", "comment": "15 pages, 7 figures, 2 tables (22 pages, 9 figures and 3 tables\n  including references and appendices)", "summary": "Text-to-image (T2I) models, while offering immense creative potential, are\nhighly reliant on human intervention, posing significant usability challenges\nthat often necessitate manual, iterative prompt engineering over often\nunderspecified prompts. This paper introduces Maestro, a novel self-evolving\nimage generation system that enables T2I models to autonomously self-improve\ngenerated images through iterative evolution of prompts, using only an initial\nprompt. Maestro incorporates two key innovations: 1) self-critique, where\nspecialized multimodal LLM (MLLM) agents act as 'critics' to identify\nweaknesses in generated images, correct for under-specification, and provide\ninterpretable edit signals, which are then integrated by a 'verifier' agent\nwhile preserving user intent; and 2) self-evolution, utilizing MLLM-as-a-judge\nfor head-to-head comparisons between iteratively generated images, eschewing\nproblematic images, and evolving creative prompt candidates that align with\nuser intents. Extensive experiments on complex T2I tasks using black-box models\ndemonstrate that Maestro significantly improves image quality over initial\nprompts and state-of-the-art automated methods, with effectiveness scaling with\nmore advanced MLLM components. This work presents a robust, interpretable, and\neffective pathway towards self-improving T2I generation.", "AI": {"tldr": "Maestro\u662f\u4e00\u4e2a\u81ea\u6f14\u8fdb\u56fe\u50cf\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u6211\u6279\u5224\u548c\u81ea\u6211\u8fdb\u5316\u673a\u5236\uff0c\u8ba9\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u80fd\u591f\u4ec5\u4ece\u521d\u59cb\u63d0\u793a\u81ea\u4e3b\u6539\u8fdb\u751f\u6210\u56fe\u50cf\u8d28\u91cf\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u9ad8\u5ea6\u4f9d\u8d56\u4eba\u5de5\u5e72\u9884\u548c\u8fed\u4ee3\u63d0\u793a\u5de5\u7a0b\uff0c\u5b58\u5728\u53ef\u7528\u6027\u6311\u6218\uff0c\u9700\u8981\u624b\u52a8\u5904\u7406\u901a\u5e38\u4e0d\u591f\u660e\u786e\u7684\u63d0\u793a\u3002", "method": "\u91c7\u7528\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a1) \u81ea\u6211\u6279\u5224 - \u4f7f\u7528\u591a\u6a21\u6001LLM\u4ee3\u7406\u4f5c\u4e3a'\u8bc4\u8bba\u5bb6'\u8bc6\u522b\u56fe\u50cf\u5f31\u70b9\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7f16\u8f91\u4fe1\u53f7\uff1b2) \u81ea\u6211\u8fdb\u5316 - \u5229\u7528MLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u8fdb\u884c\u56fe\u50cf\u5bf9\u6bd4\uff0c\u8fdb\u5316\u521b\u610f\u63d0\u793a\u5019\u9009\u3002", "result": "\u5728\u590d\u6742\u6587\u672c\u5230\u56fe\u50cf\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMaestro\u663e\u8457\u63d0\u9ad8\u4e86\u56fe\u50cf\u8d28\u91cf\uff0c\u4f18\u4e8e\u521d\u59cb\u63d0\u793a\u548c\u6700\u5148\u8fdb\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u4e14\u6548\u679c\u968fMLLM\u7ec4\u4ef6\u5148\u8fdb\u6027\u800c\u63d0\u5347\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u81ea\u6539\u8fdb\u7684\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u3001\u53ef\u89e3\u91ca\u4e14\u6709\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2509.10550", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10550", "abs": "https://arxiv.org/abs/2509.10550", "authors": ["Shivam Akhauri"], "title": "Auditable Early Stopping for Agentic Routing: Ledger-Verified Run-Wise Certificates under Local DP", "comment": null, "summary": "In production tool-use agents (e.g., retrieval $\\to$ summarization $\\to$\ncalculator), routers must know when to stop exploring while preserving local DP\nand leaving an auditable trail. We present run-wise early-stopping certificates\nfor perturb-and-MAP (PaM) best-first search on context-indexed prefix DAGs\nwhose children partition the leaves. We couple realized path scores and pruning\nkeys to a single exponential race realized lazily via offset propagation. With\nexact leaf counts $N(v)$, lazy reuse at winners and independent residuals yield\nan Exact mode with a sound halting rule based on Key$(v) = M_tau(v) - \\log\nt(v)$, where $t(v)$ is the minimum arrival time among leaves under $v$. With\nonly upper bounds $N_{ub} \\ge N$, a Surrogate mode uses a parent-anchored\nsurrogate race without winner reuse; because $-\\log \\hat t \\ge -\\log t$, the\nfrontier invariant holds and stopping remains sound. We add a compiler from\nshared-node DAGs to prefix DAGs, local finiteness checks, a SuffixCountDP\nroutine for exact counts with safe downgrades, a validator-side tightening term\n$\\kappa = \\log(N/N_{ub})$, and an auditable ledger/validator that replays runs\ndeterministically. We also give an absolute LogSumExp tail bound, an acyclicity\ncertificate, and a fallback PRF-per-leaf scheme (NoCert) whose work matches a\nrealized-score best-first baseline up to a small per-node overhead. Finally, we\nintegrate a price/latency/$(\\epsilon, \\delta)$-aware multi-LLM controller and\nDP-trained LoRA adapters chosen at runtime; these choices do not affect the\ntwo-mode frontier invariants. We report Mac/commodity-hardware reproducible\nresults, a small real tool-use pipeline, and validator-checked audit trails,\nwith code and ledgers provided.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u6a21\u5f0f\uff08Exact\u548cSurrogate\uff09\u7684\u63d0\u524d\u505c\u6b62\u8bc1\u4e66\u673a\u5236\uff0c\u7528\u4e8e\u5728\u4fdd\u62a4\u672c\u5730\u5dee\u5206\u9690\u79c1\u548c\u4fdd\u6301\u53ef\u5ba1\u8ba1\u8f68\u8ff9\u7684\u524d\u63d0\u4e0b\uff0c\u5728\u4e0a\u4e0b\u6587\u7d22\u5f15\u524d\u7f00DAG\u4e0a\u8fdb\u884cperturb-and-MAP\u6700\u4f73\u4f18\u5148\u641c\u7d22\u3002", "motivation": "\u5728\u751f\u4ea7\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u4e2d\uff0c\u8def\u7531\u5668\u9700\u8981\u5728\u4fdd\u62a4\u672c\u5730\u5dee\u5206\u9690\u79c1\u548c\u7559\u4e0b\u53ef\u5ba1\u8ba1\u8f68\u8ff9\u7684\u540c\u65f6\uff0c\u77e5\u9053\u4f55\u65f6\u505c\u6b62\u63a2\u7d22\u3002", "method": "\u4f7f\u7528\u8026\u5408\u5b9e\u73b0\u8def\u5f84\u5206\u6570\u548c\u4fee\u526a\u952e\u5230\u5355\u4e2a\u6307\u6570\u7ade\u8d5b\uff0c\u901a\u8fc7\u504f\u79fb\u4f20\u64ad\u5ef6\u8fdf\u5b9e\u73b0\u3002\u63d0\u4f9b\u7cbe\u786e\u6a21\u5f0f\uff08Exact\uff09\u548c\u4ee3\u7406\u6a21\u5f0f\uff08Surrogate\uff09\uff0c\u5305\u542b\u7f16\u8bd1\u5668\u3001\u672c\u5730\u6709\u9650\u6027\u68c0\u67e5\u3001SuffixCountDP\u4f8b\u7a0b\u7b49\u7ec4\u4ef6\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u91cd\u73b0\u7684\u7ed3\u679c\uff0c\u5305\u62ec\u5c0f\u578b\u771f\u5b9e\u5de5\u5177\u4f7f\u7528\u7ba1\u9053\u548c\u9a8c\u8bc1\u5668\u68c0\u67e5\u7684\u5ba1\u8ba1\u8f68\u8ff9\uff0c\u63d0\u4f9b\u4e86\u4ee3\u7801\u548c\u8d26\u672c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u62a4\u9690\u79c1\u548c\u53ef\u5ba1\u8ba1\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u63a7\u5236\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u7684\u641c\u7d22\u8fc7\u7a0b\uff0c\u5e76\u63d0\u4f9b\u4e24\u79cd\u53ef\u9760\u7684\u505c\u6b62\u6a21\u5f0f\u3002"}}
{"id": "2509.10920", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10920", "abs": "https://arxiv.org/abs/2509.10920", "authors": ["Guan-Yan Yang", "Farn Wang", "You-Zong Gu", "Ya-Wen Teng", "Kuo-Hui Yeh", "Ping-Hsueh Ho", "Wei-Ling Wen"], "title": "TPSQLi: Test Prioritization for SQL Injection Vulnerability Detection in Web Applications", "comment": "20 pages; 8 figures", "summary": "The rapid proliferation of network applications has led to a significant\nincrease in network attacks. According to the OWASP Top 10 Projects report\nreleased in 2021, injection attacks rank among the top three vulnerabilities in\nsoftware projects. This growing threat landscape has increased the complexity\nand workload of software testing, necessitating advanced tools to support agile\ndevelopment cycles. This paper introduces a novel test prioritization method\nfor SQL injection vulnerabilities to enhance testing efficiency. By leveraging\nprevious test outcomes, our method adjusts defense strength vectors for\nsubsequent tests, optimizing the testing workflow and tailoring defense\nmechanisms to specific software needs. This approach aims to improve the\neffectiveness and efficiency of vulnerability detection and mitigation through\na flexible framework that incorporates dynamic adjustments and considers the\ntemporal aspects of vulnerability exposure.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684SQL\u6ce8\u5165\u6f0f\u6d1e\u6d4b\u8bd5\u4f18\u5148\u7ea7\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u9632\u5fa1\u5f3a\u5ea6\u6765\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u7f51\u7edc\u653b\u51fb\u7684\u5feb\u901f\u589e\u957f\u548cSQL\u6ce8\u5165\u653b\u51fb\u5728\u6f0f\u6d1e\u6392\u540d\u4e2d\u5360\u636e\u524d\u4e09\uff0c\u5bfc\u81f4\u8f6f\u4ef6\u6d4b\u8bd5\u590d\u6742\u5ea6\u548c\u5de5\u4f5c\u91cf\u5927\u5e45\u589e\u52a0\uff0c\u9700\u8981\u9ad8\u7ea7\u5de5\u5177\u652f\u6301\u7075\u6d3b\u5f00\u53d1\u5468\u671f\u3002", "method": "\u5229\u7528\u5386\u53f2\u6d4b\u8bd5\u7ed3\u679c\u52a8\u6001\u8c03\u6574\u9632\u5fa1\u5f3a\u5ea6\u5411\u91cf\uff0c\u4e3a\u540e\u7eed\u6d4b\u8bd5\u8bbe\u8ba1\u4f18\u5316\u6d41\u7a0b\uff0c\u5e76\u6839\u636e\u7279\u5b9a\u8f6f\u4ef6\u9700\u6c42\u5b9a\u5236\u9632\u5fa1\u673a\u5236\u3002", "result": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7075\u6d3b\u6846\u67b6\u5b9e\u73b0\u52a8\u6001\u8c03\u6574\u548c\u8003\u8651\u6f0f\u6d1e\u66b4\u9732\u65f6\u95f4\u56e0\u7d20\uff0c\u63d0\u9ad8\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u548c\u7f29\u51cf\u7684\u6548\u679c\u548c\u6548\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aSQL\u6ce8\u5165\u6f0f\u6d1e\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4f18\u5148\u7ea7\u65b9\u6cd5\uff0c\u9002\u5e94\u4e86\u5f53\u524d\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u4e0b\u7684\u7075\u6d3b\u5f00\u53d1\u9700\u6c42\u3002"}}
{"id": "2509.10707", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10707", "abs": "https://arxiv.org/abs/2509.10707", "authors": ["Sajjad Abdoli", "Rudi Cilibrasi", "Rima Al-Shikh"], "title": "Understanding AI Evaluation Patterns: How Different GPT Models Assess Vision-Language Descriptions", "comment": null, "summary": "As AI systems increasingly evaluate other AI outputs, understanding their\nassessment behavior becomes crucial for preventing cascading biases. This study\nanalyzes vision-language descriptions generated by NVIDIA's Describe Anything\nModel and evaluated by three GPT variants (GPT-4o, GPT-4o-mini, GPT-5) to\nuncover distinct \"evaluation personalities\" the underlying assessment\nstrategies and biases each model demonstrates. GPT-4o-mini exhibits systematic\nconsistency with minimal variance, GPT-4o excels at error detection, while\nGPT-5 shows extreme conservatism with high variability. Controlled experiments\nusing Gemini 2.5 Pro as an independent question generator validate that these\npersonalities are inherent model properties rather than artifacts. Cross-family\nanalysis through semantic similarity of generated questions reveals significant\ndivergence: GPT models cluster together with high similarity while Gemini\nexhibits markedly different evaluation strategies. All GPT models demonstrate a\nconsistent 2:1 bias favoring negative assessment over positive confirmation,\nthough this pattern appears family-specific rather than universal across AI\narchitectures. These findings suggest that evaluation competence does not scale\nwith general capability and that robust AI assessment requires diverse\narchitectural perspectives.", "AI": {"tldr": "\u8fd9\u7814\u7a76\u5206\u6790\u4e86\u4e09\u79cdGPT\u6a21\u578b\u5728\u8bc4\u4f30\u89c6\u89c9-\u8bed\u8a00\u63cf\u8ff0\u65f6\u7684\u4e0d\u540c\"\u8bc4\u4f30\u4e2a\u6027\"\uff0c\u53d1\u73b0GPT-4o-mini\u7cfb\u7edf\u4e00\u81f4\u6027\u5f3a\uff0cGPT-4o\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\u7a81\u51fa\uff0cGPT-5\u5448\u73b0\u6781\u7aef\u4fdd\u5b88\u4e3b\u4e49\uff0c\u4e14\u6240\u6709GPT\u6a21\u578b\u90fd\u5b58\u57282:1\u7684\u8d1f\u9762\u504f\u89c1\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u8bc4\u4f30\u5176\u4ed6AI\u8f93\u51fa\uff0c\u7406\u89e3\u5b83\u4eec\u7684\u8bc4\u4f30\u884c\u4e3a\u5bf9\u9632\u6b62\u504f\u89c1\u7684\u5c42\u5c42\u7d2f\u79ef\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5206\u6790NVIDIA Describe Anything\u6a21\u578b\u751f\u6210\u7684\u89c6\u89c9-\u8bed\u8a00\u63cf\u8ff0\uff0c\u5e76\u7528\u4e09\u79cdGPT\u53d8\u4f53(GPT-4o, GPT-4o-mini, GPT-5)\u8fdb\u884c\u8bc4\u4f30\uff0c\u4f7f\u7528Gemini 2.5 Pro\u4f5c\u4e3a\u72ec\u7acb\u95ee\u9898\u751f\u6210\u5668\u8fdb\u884c\u53d7\u63a7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u4e0d\u540cGPT\u6a21\u578b\u5448\u73b0\u660e\u663e\u4e0d\u540c\u7684\u8bc4\u4f30\u4e2a\u6027\uff1aGPT-4o-mini\u7cfb\u7edf\u4e00\u81f4\u6027\u5f3a\u4f46\u65b9\u5dee\u6700\u5c0f\uff0cGPT-4o\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\u7a81\u51fa\uff0cGPT-5\u5448\u73b0\u6781\u7aef\u4fdd\u5b88\u4e3b\u4e49\u4e14\u53d8\u5f02\u6027\u9ad8\u3002\u6240\u6709GPT\u6a21\u578b\u90fd\u5b58\u57282:1\u7684\u8d1f\u9762\u504f\u89c1\u3002", "conclusion": "\u8bc4\u4f30\u80fd\u529b\u5e76\u4e0d\u968f\u7740\u901a\u7528\u80fd\u529b\u7684\u63d0\u5347\u800c\u6269\u5c55\uff0c\u5065\u58ee\u7684AI\u8bc4\u4f30\u9700\u8981\u591a\u6837\u5316\u7684\u67b6\u6784\u89c6\u89d2\u3002"}}
{"id": "2509.10551", "categories": ["cs.CR", "quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10551", "abs": "https://arxiv.org/abs/2509.10551", "authors": ["Amal Raj", "Vivek Balachandran"], "title": "A Hybrid Encryption Framework Combining Classical, Post-Quantum, and QKD Methods", "comment": "This version corrects an error in a table entry compared to the\n  accepted Springer version", "summary": "This paper introduces a hybrid encryption framework combining classical\ncryptography (EdDSA, ECDH), post-quantum cryptography (ML-DSA-6x5, ML-KEM-768),\nand Quantum Key Distribution (QKD) via Guardian to counter quantum computing\nthreats. Our prototype implements this integration, using a key derivation\nfunction to generate secure symmetric and HMAC keys, and evaluates its\nperformance across execution time and network metrics. The approach improves\ndata protection by merging classical efficiency with PQC's quantum resilience\nand QKD's key security, offering a practical transition path for cryptographic\nsystems. This research lays the foundation for future adoption of PQC in\nsecuring digital communication.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u52a0\u5bc6\u6846\u67b6\uff0c\u7ed3\u5408\u7ecf\u5178\u5bc6\u7801\u5b66\u3001\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u548c\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u6280\u672f\uff0c\u4ee5\u5e94\u5bf9\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u5b9e\u73b0\u9a8c\u8bc1\u6027\u80fd", "motivation": "\u5e94\u5bf9\u91cf\u5b50\u8ba1\u7b97\u5bf9\u73b0\u6709\u52a0\u5bc6\u7cfb\u7edf\u7684\u5a01\u80c1\uff0c\u63d0\u4f9b\u4ece\u7ecf\u5178\u5bc6\u7801\u5b66\u5230\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u5e73\u7a33\u8fc7\u6e21\u65b9\u6848", "method": "\u96c6\u6210EdDSA\u3001ECDH\uff08\u7ecf\u5178\u5bc6\u7801\u5b66\uff09\u3001ML-DSA-6x5\u3001ML-KEM-768\uff08\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\uff09\u548cQKD\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff0c\u4f7f\u7528\u5bc6\u94a5\u6d3e\u751f\u51fd\u6570\u751f\u6210\u5bf9\u79f0\u5bc6\u94a5\u548cHMAC\u5bc6\u94a5", "result": "\u5f00\u53d1\u4e86\u539f\u578b\u7cfb\u7edf\u5e76\u8bc4\u4f30\u4e86\u6267\u884c\u65f6\u95f4\u548c\u7f51\u7edc\u6027\u80fd\u6307\u6807\uff0c\u9a8c\u8bc1\u4e86\u6df7\u5408\u65b9\u6848\u7684\u53ef\u884c\u6027", "conclusion": "\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u7ecf\u5178\u5bc6\u7801\u5b66\u7684\u9ad8\u6548\u6027\u3001\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u91cf\u5b50\u6297\u6027\u548cQKD\u7684\u5bc6\u94a5\u5b89\u5168\u6027\uff0c\u4e3a\u5bc6\u7801\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8fc7\u6e21\u8def\u5f84\uff0c\u4e3a\u672a\u6765\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2509.10946", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10946", "abs": "https://arxiv.org/abs/2509.10946", "authors": ["Roberto Morabito", "Guanghan Wu"], "title": "When the Code Autopilot Breaks: Why LLMs Falter in Embedded Machine Learning", "comment": "This paper has been accepted for publication in Computer (IEEE). Upon\n  publication, the copyright will be transferred to IEEE", "summary": "Large Language Models (LLMs) are increasingly used to automate software\ngeneration in embedded machine learning workflows, yet their outputs often fail\nsilently or behave unpredictably. This article presents an empirical\ninvestigation of failure modes in LLM-powered ML pipelines, based on an\nautopilot framework that orchestrates data preprocessing, model conversion, and\non-device inference code generation. We show how prompt format, model behavior,\nand structural assumptions influence both success rates and failure\ncharacteristics, often in ways that standard validation pipelines fail to\ndetect. Our analysis reveals a diverse set of error-prone behaviors, including\nformat-induced misinterpretations and runtime-disruptive code that compiles but\nbreaks downstream. We derive a taxonomy of failure categories and analyze\nerrors across multiple LLMs, highlighting common root causes and systemic\nfragilities. Though grounded in specific devices, our study reveals broader\nchallenges in LLM-based code generation. We conclude by discussing directions\nfor improving reliability and traceability in LLM-powered embedded ML systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5d4c\u5165\u5f0f\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\u4e2d\u7684\u591a\u79cd\u5931\u8d25\u6a21\u5f0f\uff0c\u5305\u62ec\u63d0\u793a\u683c\u5f0f\u5f15\u53d1\u7684\u8bef\u89e3\u3001\u7f16\u8bd1\u6210\u529f\u4f46\u8fd0\u884c\u65f6\u5d29\u6e83\u7684\u4ee3\u7801\u7b49\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u5931\u8d25\u5206\u7c7b\u5f62\u6001\u5b66\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5d4c\u5165\u5f0f\u673a\u5668\u5b66\u5de5\u4f5c\u6d41\u4e2d\u81ea\u52a8\u5316\u8f6f\u4ef6\u751f\u6210\u7684\u5e94\u7528\u589e\u591a\uff0c\u5b83\u4eec\u7684\u8f93\u51fa\u7ecf\u5e38\u5931\u8d25\u6216\u884c\u4e3a\u4e0d\u53ef\u9884\u6d4b\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u5176\u5931\u8d25\u6a21\u5f0f\u548c\u6839\u672c\u539f\u56e0\u3002", "method": "\u7814\u7a76\u57fa\u4e8e\u4e00\u4e2a\u81ea\u52a8\u9a7e\u9a76\u6846\u67b6\uff0c\u8c03\u5ea6\u6570\u636e\u9884\u5904\u7406\u3001\u6a21\u578b\u8f6c\u6362\u548c\u8bbe\u5907\u4e0a\u63a8\u7406\u4ee3\u7801\u751f\u6210\u3002\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u63d0\u793a\u683c\u5f0f\u3001\u6a21\u578b\u884c\u4e3a\u548c\u7ed3\u6784\u5047\u8bbe\u5bf9\u6210\u529f\u7387\u548c\u5931\u8d25\u7279\u5f81\u7684\u5f71\u54cd\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u591a\u79cd\u5bb9\u6613\u51fa\u9519\u7684\u884c\u4e3a\uff0c\u5305\u62ec\u683c\u5f0f\u5f15\u53d1\u7684\u8bef\u89e3\u548c\u7f16\u8bd1\u6210\u529f\u4f46\u4f1a\u7834\u574f\u4e0b\u6e38\u7684\u8fd0\u884c\u65f6\u4ee3\u7801\u3002\u7814\u7a76\u5f97\u51fa\u4e86\u5931\u8d25\u7c7b\u522b\u5206\u7c7b\u5f62\u6001\u5b66\uff0c\u5e76\u5728\u591a\u4e2aLLM\u4e2d\u5206\u6790\u4e86\u9519\u8bef\uff0c\u7a81\u51fa\u4e86\u5171\u540c\u6839\u672c\u539f\u56e0\u548c\u7cfb\u7edf\u8106\u5f31\u6027\u3002", "conclusion": "\u867d\u7136\u57fa\u4e8e\u7279\u5b9a\u8bbe\u5907\uff0c\u4f46\u7814\u7a76\u63ed\u793a\u4e86LLM\u57fa\u4e8e\u4ee3\u7801\u751f\u6210\u7684\u66f4\u5e7f\u6cdb\u6311\u6218\u3002\u6587\u7ae0\u6700\u540e\u8ba8\u8bba\u4e86\u6539\u5584LLM\u9a71\u52a8\u5d4c\u5165\u5f0fML\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u7684\u65b9\u5411\u3002"}}
{"id": "2509.10762", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10762", "abs": "https://arxiv.org/abs/2509.10762", "authors": ["Arlen Kumar", "Leanid Palkhouski"], "title": "AI Answer Engine Citation Behavior An Empirical Analysis of the GEO16 Framework", "comment": null, "summary": "AI answer engines increasingly mediate access to domain knowledge by\ngenerating responses and citing web sources. We introduce GEO-16, a 16 pillar\nauditing framework that converts on page quality signals into banded pillar\nscores and a normalized GEO score G that ranges from 0 to 1. Using 70 product\nintent prompts, we collected 1,702 citations across three engines (Brave\nSummary, Google AI Overviews, and Perplexity) and audited 1,100 unique URLs. In\nour corpus, the engines differed in the GEO quality of the pages they cited,\nand pillars related to Metadata and Freshness, Semantic HTML, and Structured\nData showed the strongest associations with citation. Logistic models with\ndomain clustered standard errors indicate that overall page quality is a strong\npredictor of citation, and simple operating points (for example, G at least\n0.70 combined with at least 12 pillar hits) align with substantially higher\ncitation rates in our data. We report per engine contrasts, vertical effects,\nthreshold analysis, and diagnostics, then translate findings into a practical\nplaybook for publishers. The study is observational and focuses on English\nlanguage B2B SaaS pages; we discuss limitations, threats to validity, and\nreproducibility considerations.", "AI": {"tldr": "GEO-16\u6846\u67b6\u8bc4\u4f30AI\u5f15\u64ce\u5f15\u7528\u7f51\u9875\u8d28\u91cf\uff0c\u53d1\u73b0\u9875\u9762\u6574\u4f53\u8d28\u91cf\u662f\u5f15\u7528\u7684\u5f3a\u9884\u6d4b\u56e0\u5b50\uff0cMetadata\u3001Freshness\u3001Semantic HTML\u548cStructured Data\u7b49\u652f\u67f1\u4e0e\u5f15\u7528\u5173\u8054\u6700\u5f3a\u3002", "motivation": "\u968f\u7740AI\u7b54\u6848\u5f15\u64ce\u901a\u8fc7\u751f\u6210\u54cd\u5e94\u548c\u5f15\u7528\u7f51\u9875\u6765\u6e90\u6765\u4e2d\u4ecb\u9886\u57df\u77e5\u8bc6\u8bbf\u95ee\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\u6765\u5ba1\u8ba1\u8fd9\u4e9b\u5f15\u64ce\u5f15\u7528\u7684\u7f51\u9875\u8d28\u91cf\u3002", "method": "\u4f7f\u752870\u4e2a\u4ea7\u54c1\u610f\u56fe\u63d0\u793a\u6536\u96c6\u4e86\u4e09\u4e2a\u5f15\u64ce\uff08Brave Summary\u3001Google AI Overviews\u548cPerplexity\uff09\u76841,702\u4e2a\u5f15\u7528\uff0c\u5ba1\u8ba1\u4e861,100\u4e2a\u552f\u4e00URL\uff0c\u91c7\u7528GEO-16\u6846\u67b6\u5c06\u9875\u9762\u8d28\u91cf\u4fe1\u53f7\u8f6c\u6362\u4e3a\u5e26\u652f\u67f1\u5206\u6570\u548c\u6807\u51c6\u5316GEO\u5206\u6570G\uff080-1\uff09\u3002", "result": "\u5f15\u64ce\u5728\u5f15\u7528\u9875\u9762\u7684GEO\u8d28\u91cf\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u6574\u4f53\u9875\u9762\u8d28\u91cf\u662f\u5f15\u7528\u7684\u5f3a\u9884\u6d4b\u56e0\u5b50\uff0cG\u22650.70\u4e14\u81f3\u5c1112\u4e2a\u652f\u67f1\u547d\u4e2d\u7684\u64cd\u4f5c\u70b9\u4e0e\u663e\u8457\u66f4\u9ad8\u7684\u5f15\u7528\u7387\u76f8\u5173\u3002", "conclusion": "\u7814\u7a76\u4e3a\u51fa\u7248\u5546\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u64cd\u4f5c\u6307\u5357\uff0c\u4f46\u8fd9\u662f\u89c2\u5bdf\u6027\u7814\u7a76\uff0c\u4e13\u6ce8\u4e8e\u82f1\u8bedB2B SaaS\u9875\u9762\uff0c\u5b58\u5728\u5c40\u9650\u6027\u548c\u6709\u6548\u6027\u5a01\u80c1\u3002"}}
{"id": "2509.10561", "categories": ["cs.CR", "cs.AI", "68Q25, 68T50, 68P27", "F.2.2; I.2.7; K.4.1"], "pdf": "https://arxiv.org/pdf/2509.10561", "abs": "https://arxiv.org/abs/2509.10561", "authors": ["Madhava Gaikwad"], "title": "AVEC: Bootstrapping Privacy for Local LLMs", "comment": "12 pages", "summary": "This position paper presents AVEC (Adaptive Verifiable Edge Control), a\nframework for bootstrapping privacy for local language models by enforcing\nprivacy at the edge with explicit verifiability for delegated queries. AVEC\nintroduces an adaptive budgeting algorithm that allocates per-query\ndifferential privacy parameters based on sensitivity, local confidence, and\nhistorical usage, and uses verifiable transformation with on-device integrity\nchecks. We formalize guarantees using R\\'enyi differential privacy with\nodometer-based accounting, and establish utility ceilings, delegation-leakage\nbounds, and impossibility results for deterministic gating and hash-only\ncertification. Our evaluation is simulation-based by design to study mechanism\nbehavior and accounting; we do not claim deployment readiness or task-level\nutility with live LLMs. The contribution is a conceptual architecture and\ntheoretical foundation that chart a pathway for empirical follow-up on\nprivately bootstrapping local LLMs.", "AI": {"tldr": "AVEC\u662f\u4e00\u4e2a\u7528\u4e8e\u672c\u5730\u8bed\u8a00\u6a21\u578b\u9690\u79c1\u4fdd\u62a4\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8fb9\u7f18\u63a7\u5236\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u5dee\u5206\u9690\u79c1\u9884\u7b97\u5206\u914d\u548c\u53ef\u9a8c\u8bc1\u8f6c\u6362\u6280\u672f\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u672c\u5730\u8bed\u8a00\u6a21\u578b\u5728\u59d4\u6258\u67e5\u8be2\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u65bd\u9690\u79c1\u4fdd\u62a4\u5e76\u786e\u4fdd\u53ef\u9a8c\u8bc1\u6027\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u9884\u7b97\u7b97\u6cd5\uff0c\u57fa\u4e8e\u67e5\u8be2\u654f\u611f\u5ea6\u3001\u672c\u5730\u7f6e\u4fe1\u5ea6\u548c\u5386\u53f2\u4f7f\u7528\u60c5\u51b5\u5206\u914d\u5dee\u5206\u9690\u79c1\u53c2\u6570\uff1b\u4f7f\u7528\u53ef\u9a8c\u8bc1\u8f6c\u6362\u548c\u8bbe\u5907\u5b8c\u6574\u6027\u68c0\u67e5\uff1b\u57fa\u4e8eR\u00e9nyi\u5dee\u5206\u9690\u79c1\u548c\u91cc\u7a0b\u8868\u5f0f\u8bb0\u8d26\u5f62\u5f0f\u5316\u4fdd\u8bc1\u3002", "result": "\u5efa\u7acb\u4e86\u6548\u7528\u4e0a\u9650\u3001\u59d4\u6258\u6cc4\u6f0f\u8fb9\u754c\uff0c\u4ee5\u53ca\u786e\u5b9a\u6027\u95e8\u63a7\u548c\u4ec5\u54c8\u5e0c\u8ba4\u8bc1\u7684\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\uff1b\u901a\u8fc7\u6a21\u62df\u8bc4\u4f30\u9a8c\u8bc1\u673a\u5236\u884c\u4e3a\u548c\u8bb0\u8d26\u6548\u679c\u3002", "conclusion": "AVEC\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6982\u5ff5\u67b6\u6784\u548c\u7406\u8bba\u57fa\u7840\uff0c\u4e3a\u672c\u5730\u8bed\u8a00\u6a21\u578b\u7684\u9690\u79c1\u5f15\u5bfc\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u7814\u7a76\u7684\u8def\u5f84\uff0c\u4f46\u76ee\u524d\u5c1a\u672a\u8fbe\u5230\u90e8\u7f72\u5c31\u7eea\u72b6\u6001\u3002"}}
{"id": "2509.11000", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.11000", "abs": "https://arxiv.org/abs/2509.11000", "authors": ["Omid Gheibi", "Christian K\u00e4stner", "Pooyan Jamshidi"], "title": "Hardness, Structural Knowledge, and Opportunity: An Analytical Framework for Modular Performance Modeling", "comment": null, "summary": "Performance-influence models are beneficial for understanding how\nconfigurations affect system performance, but their creation is challenging due\nto the exponential growth of configuration spaces. While gray-box approaches\nleverage selective \"structural knowledge\" (like the module execution graph of\nthe system) to improve modeling, the relationship between this knowledge, a\nsystem's characteristics (we call them \"structural aspects\"), and potential\nmodel improvements is not well understood. This paper addresses this gap by\nformally investigating how variations in structural aspects (e.g., the number\nof modules and options per module) and the level of structural knowledge impact\nthe creation of \"opportunities\" for improved \"modular performance modeling\". We\nintroduce and quantify the concept of modeling \"hardness\", defined as the\ninherent difficulty of performance modeling. Through controlled experiments\nwith synthetic system models, we establish an \"analytical matrix\" to measure\nthese concepts. Our findings show that modeling hardness is primarily driven by\nthe number of modules and configuration options per module. More importantly,\nwe demonstrate that both higher levels of structural knowledge and increased\nmodeling hardness significantly enhance the opportunity for improvement. The\nimpact of these factors varies by performance metric; for ranking accuracy\n(e.g., in debugging task), structural knowledge is more dominant, while for\nprediction accuracy (e.g., in resource management task), hardness plays a\nstronger role. These results provide actionable insights for system designers,\nguiding them to strategically allocate time and select appropriate modeling\napproaches based on a system's characteristics and a given task's objectives.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7ed3\u6784\u77e5\u8bc6\u5bf9\u6027\u80fd\u5f71\u54cd\u6a21\u578b\u5efa\u6a21\u7684\u4f5c\u7528\uff0c\u901a\u8fc7\u5b9a\u4e49\u6a21\u578b\u96be\u5ea6\u548c\u5206\u6790\u77e9\u9635\uff0c\u63ed\u793a\u4e86\u7ed3\u6784\u77e5\u8bc6\u6c34\u5e73\u548c\u7cfb\u7edf\u7279\u5f81\u5bf9\u6a21\u578b\u653d\u6b21\u673a\u4f1a\u7684\u5f71\u54cd\u3002", "motivation": "\u867d\u7136\u7070\u76d2\u65b9\u6cd5\u5229\u7528\u7ed3\u6784\u77e5\u8bc6\u6539\u5584\u6027\u80fd\u6a21\u578b\uff0c\u4f46\u7ed3\u6784\u77e5\u8bc6\u3001\u7cfb\u7edf\u7279\u5f81\u4e0e\u6a21\u578b\u653d\u6b21\u4e4b\u95f4\u7684\u5173\u7cfb\u5e76\u4e0d\u660e\u786e\uff0c\u9700\u8981\u6b63\u5f0f\u7814\u7a76\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u4f7f\u7528\u5408\u6210\u7cfb\u7edf\u6a21\u578b\uff0c\u5efa\u7acb\u5206\u6790\u77e9\u9635\u6765\u91cf\u5316\u6a21\u578b\u96be\u5ea6\u548c\u653d\u6b21\u673a\u4f1a\uff0c\u7814\u7a76\u7ed3\u6784\u65b9\u9762\u53d8\u5316\u548c\u7ed3\u6784\u77e5\u8bc6\u6c34\u5e73\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u96be\u5ea6\u4e3b\u8981\u7531\u6a21\u5757\u6570\u91cf\u548c\u6bcf\u4e2a\u6a21\u5757\u7684\u914d\u7f6e\u9009\u9879\u6570\u91cf\u9a71\u52a8\uff1b\u66f4\u9ad8\u7684\u7ed3\u6784\u77e5\u8bc6\u6c34\u5e73\u548c\u66f4\u9ad8\u7684\u6a21\u578b\u96be\u5ea6\u90fd\u663e\u8457\u63d0\u9ad8\u653d\u6b21\u673a\u4f1a\uff1b\u4e0d\u540c\u6027\u80fd\u6307\u6807\u4e0b\u56e0\u7d20\u5f71\u54cd\u4e0d\u540c\uff1a\u6392\u540d\u51c6\u786e\u6027\u4e2d\u7ed3\u6784\u77e5\u8bc6\u66f4\u91cd\u8981\uff0c\u9884\u6d4b\u51c6\u786e\u6027\u4e2d\u6a21\u578b\u96be\u5ea6\u4f5c\u7528\u66f4\u5927\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u5e2e\u52a9\u4ed6\u4eec\u6839\u636e\u7cfb\u7edf\u7279\u5f81\u548c\u4efb\u52a1\u76ee\u6807\u6218\u7565\u6027\u5730\u5206\u914d\u65f6\u95f4\u5e76\u9009\u62e9\u9002\u5f53\u7684\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2509.10769", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.10769", "abs": "https://arxiv.org/abs/2509.10769", "authors": ["Tara Bogavelli", "Roshnee Sharma", "Hari Subramani"], "title": "AgentArch: A Comprehensive Benchmark to Evaluate Agent Architectures in Enterprise", "comment": null, "summary": "While individual components of agentic architectures have been studied in\nisolation, there remains limited empirical understanding of how different\ndesign dimensions interact within complex multi-agent systems. This study aims\nto address these gaps by providing a comprehensive enterprise-specific\nbenchmark evaluating 18 distinct agentic configurations across state-of-the-art\nlarge language models. We examine four critical agentic system dimensions:\norchestration strategy, agent prompt implementation (ReAct versus function\ncalling), memory architecture, and thinking tool integration. Our benchmark\nreveals significant model-specific architectural preferences that challenge the\nprevalent one-size-fits-all paradigm in agentic AI systems. It also reveals\nsignificant weaknesses in overall agentic performance on enterprise tasks with\nthe highest scoring models achieving a maximum of only 35.3\\% success on the\nmore complex task and 70.8\\% on the simpler task. We hope these findings inform\nthe design of future agentic systems by enabling more empirically backed\ndecisions regarding architectural components and model selection.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u4f01\u4e1a\u7279\u5b9a\u57fa\u51c6\u6d4b\u8bc518\u79cd\u4e0d\u540c\u7684\u81ea\u4e3b\u7ec4\u4ef6\u914d\u7f6e\uff0c\u53d1\u73b0\u4e86\u91cd\u8981\u7684\u6a21\u578b\u7279\u5b9a\u67b6\u6784\u504f\u597d\u548c\u81ea\u4e3b\u7cfb\u7edf\u5728\u4f01\u4e1a\u4efb\u52a1\u4e0a\u7684\u663e\u8457\u5f31\u70b9\uff0c\u6700\u9ad8\u6210\u529f\u7387\u4ec5\u4e3a35.3%~70.8%\u3002", "motivation": "\u5f53\u524d\u5bf9\u81ea\u4e3b\u7ec4\u4ef6\u5728\u590d\u6742\u591a\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u7684\u4ea4\u4e92\u4f5c\u7528\u7f3a\u4e4f\u5b9e\u8bc1\u7406\u89e3\uff0c\u9700\u8981\u901a\u8fc7\u7efc\u5408\u6027\u57fa\u51c6\u6d4b\u8bc5\u6765\u586b\u8865\u8fd9\u4e9b\u77e5\u8bc6\u7a7a\u767d\u3002", "method": "\u4f7f\u7528\u4f01\u4e1a\u7279\u5b9a\u57fa\u51c6\u6d4b\u8bc5\u8bc4\u4f3018\u79cd\u4e0d\u540c\u7684\u81ea\u4e3b\u7ec4\u4ef6\u914d\u7f6e\uff0c\u91cd\u70b9\u8003\u5bdf\u56db\u4e2a\u5173\u952e\u7ef4\u5ea6\uff1a\u7ec4\u7ec7\u7b56\u7565\u3001\u63d0\u793a\u5b9e\u73b0\u65b9\u5f0f\u3001\u5185\u5b58\u67b6\u6784\u548c\u601d\u8003\u5de5\u5177\u96c6\u6210\u3002", "result": "\u53d1\u73b0\u4e86\u663e\u8457\u7684\u6a21\u578b\u7279\u5b9a\u67b6\u6784\u504f\u597d\uff0c\u6316\u6398\u4e86\u5f53\u524d\"\u4e00\u5200\u5207\"\u81ea\u4e3bAI\u7cfb\u7edf\u8303\u5f0f\u7684\u95ee\u9898\uff0c\u540c\u65f6\u53d1\u73b0\u81ea\u4e3b\u7cfb\u7edf\u5728\u4f01\u4e1a\u4efb\u52a1\u4e0a\u8868\u73b0\u5f31\u52b3\uff0c\u6700\u9ad8\u6210\u529f\u7387\u4ec5\u4e3a35.3%~70.8%\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5e94\u8be5\u4e3a\u672a\u6765\u81ea\u4e3b\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u5b9e\u8bc1\u652f\u6491\uff0c\u4f7f\u5f97\u67b6\u6784\u7ec4\u4ef6\u9009\u62e9\u548c\u6a21\u578b\u9009\u62e9\u66f4\u52a0\u4ee5\u5b9e\u8bc1\u4e3a\u57fa\u7840\u3002"}}
{"id": "2509.10563", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10563", "abs": "https://arxiv.org/abs/2509.10563", "authors": ["Mohammed Yacoubi", "Omar Moussaoui", "C. Drocourt"], "title": "Enhancing IoMT Security with Explainable Machine Learning: A Case Study on the CICIOMT2024 Dataset", "comment": null, "summary": "Explainable Artificial Intelligence (XAI) enhances the transparency and\ninterpretability of AI models, addressing their inherent opacity. In\ncybersecurity, particularly within the Internet of Medical Things (IoMT), the\nblack-box nature of AI-driven threat detection poses a significant challenge.\nCybersecurity professionals must not only detect attacks but also understand\nthe reasoning behind AI decisions to ensure trust and accountability. The rapid\nincrease in cyberattacks targeting connected medical devices threatens patient\nsafety and data privacy, necessitating advanced AI-driven solutions. This study\ncompares two ensemble learning techniques, bagging and boosting, for\ncyber-attack classification in IoMT environments. We selected Random Forest for\nbagging and CatBoost for boosting. Random Forest helps reduce variance, while\nCatBoost improves bias by combining weak classifiers into a strong ensemble\nmodel, making them effective for detecting sophisticated attacks. However,\ntheir complexity often reduces transparency, making it difficult for\ncybersecurity professionals to interpret and trust their decisions. To address\nthis issue, we apply XAI models to generate local and global explanations,\nproviding insights into AI decision-making. Using techniques like SHAP (Shapley\nAdditive Explanations) and LIME (Local Interpretable Model-agnostic\nExplanations), we highlight feature importance to help stakeholders understand\nthe key factors driving cyber threat detection.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5728\u533b\u7597\u7269\u8054\u7f51(IoMT)\u73af\u5883\u4e2d\u4f7f\u7528\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd(XAI)\u6765\u63d0\u5347\u96c6\u6210\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7SHAP\u548cLIME\u6280\u672f\u4e3a\u7f51\u7edc\u5b89\u5168\u4e13\u4e1a\u4eba\u5458\u63d0\u4f9b\u653b\u51fb\u68c0\u6d4b\u51b3\u7b56\u7684\u89e3\u91ca\u3002", "motivation": "\u533b\u7597\u7269\u8054\u7f51\u73af\u5883\u4e2d\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u5a01\u80c1\u68c0\u6d4b\u6a21\u578b\u901a\u5e38\u662f\u9ed1\u76d2\u6a21\u578b\uff0c\u7f51\u7edc\u5b89\u5168\u4e13\u4e1a\u4eba\u5458\u9700\u8981\u7406\u89e3AI\u51b3\u7b56\u7684\u7406\u7531\u4ee5\u786e\u4fdd\u4fe1\u4efb\u548c\u8d23\u4efb\u5236\uff0c\u5e94\u5bf9\u6301\u7eed\u589e\u957f\u7684\u7f51\u7edc\u653b\u51fb\u5a01\u80c1\u3002", "method": "\u91c7\u7528\u96c6\u6210\u5b66\u4e60\u6280\u672f\uff08bagging\u65b9\u6cd5\u7684Random Forest\u548cboosting\u65b9\u6cd5\u7684CatBoost\uff09\u8fdb\u884c\u7f51\u7edc\u653b\u51fb\u5206\u7c7b\uff0c\u7136\u540e\u5e94\u7528XAI\u6a21\u578b\u751f\u6210\u5c40\u90e8\u548c\u5168\u5c40\u89e3\u91ca\uff0c\u4f7f\u7528SHAP\u548cLIME\u6280\u672f\u6765\u5f3a\u8c03\u7279\u5f81\u91cd\u8981\u6027\u3002", "result": "\u7814\u7a76\u5c55\u793a\u4e86XAI\u6280\u672f\u5982\u4f55\u4e3a\u96c6\u6210\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\uff0c\u5e2e\u52a9\u5229\u76ca\u76f8\u5173\u8005\u7406\u89e3\u7f51\u7edc\u5a01\u80c1\u68c0\u6d4b\u7684\u5173\u952e\u56e0\u7d20\u548c\u51b3\u7b56\u7406\u7531\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u96c6\u6210\u5b66\u4e60\u6a21\u578b\u548cXAI\u6280\u672f\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u5347IoMT\u73af\u5883\u4e2d\u7f51\u7edc\u5b89\u5168\u68c0\u6d4b\u6a21\u578b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4ece\u800c\u589e\u5f3a\u4e13\u4e1a\u4eba\u5458\u5bf9AI\u51b3\u7b56\u7684\u4fe1\u4efb\u548c\u8d23\u4efb\u5236\u3002"}}
{"id": "2509.11065", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.11065", "abs": "https://arxiv.org/abs/2509.11065", "authors": ["Yuan Si", "Daming Li", "Hanyuan Shi", "Jialu Zhang"], "title": "ViScratch: Using Large Language Models and Gameplay Videos for Automated Feedback in Scratch", "comment": null, "summary": "Block-based programming environments such as Scratch are increasingly popular\nin programming education, in particular for young learners. While the use of\nblocks helps prevent syntax errors, semantic bugs remain common and difficult\nto debug. Existing tools for Scratch debugging rely heavily on predefined rules\nor user manual inputs, and crucially, they ignore the platform's inherently\nvisual nature.\n  We introduce ViScratch, the first multimodal feedback generation system for\nScratch that leverages both the project's block code and its generated gameplay\nvideo to diagnose and repair bugs. ViScratch uses a two-stage pipeline: a\nvision-language model first aligns visual symptoms with code structure to\nidentify a single critical issue, then proposes minimal, abstract syntax tree\nlevel repairs that are verified via execution in the Scratch virtual machine.\n  We evaluate ViScratch on a set of real-world Scratch projects against\nstate-of-the-art LLM-based tools and human testers. Results show that gameplay\nvideo is a crucial debugging signal: ViScratch substantially outperforms prior\ntools in both bug identification and repair quality, even without access to\nproject descriptions or goals. This work demonstrates that video can serve as a\nfirst-class specification in visual programming environments, opening new\ndirections for LLM-based debugging beyond symbolic code alone.", "AI": {"tldr": "ViScratch\u662f\u9996\u4e2a\u5229\u7528\u6e38\u620f\u89c6\u9891\u548c\u4ee3\u7801\u8fdb\u884cScratch\u7a0b\u5e8f\u8c03\u8bd5\u7684\u591a\u6a21\u6001\u53cd\u9988\u7cfb\u7edf\uff0c\u901a\u8fc7\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u5173\u952e\u95ee\u9898\u5e76\u63d0\u51faAST\u7ea7\u522b\u7684\u4fee\u590d\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709LLM\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u7684Scratch\u8c03\u8bd5\u5de5\u5177\u4e3b\u8981\u4f9d\u8d56\u9884\u5b9a\u4e49\u89c4\u5219\u548c\u7528\u6237\u624b\u52a8\u8f93\u5165\uff0c\u5ffd\u7565\u4e86\u5e73\u53f0\u7684\u53ef\u89c6\u5316\u7279\u6027\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8bed\u4e49\u9519\u8bef\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a\u9996\u5148\u4f7f\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5c06\u89c6\u89c9\u75c7\u72b6\u4e0e\u4ee3\u7801\u7ed3\u6784\u5bf9\u9f50\u4ee5\u8bc6\u522b\u5173\u952e\u95ee\u9898\uff0c\u7136\u540e\u63d0\u51fa\u6700\u5c0f\u5316\u7684AST\u7ea7\u522b\u4fee\u590d\u5e76\u5728Scratch\u865a\u62df\u673a\u4e2d\u9a8c\u8bc1\u3002", "result": "ViScratch\u5728\u771f\u5b9eScratch\u9879\u76ee\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u4e8eLLM\u7684\u5de5\u5177\u548c\u4eba\u5de5\u6d4b\u8bd5\u8005\uff0c\u6e38\u620f\u89c6\u9891\u6210\u4e3a\u5173\u952e\u7684\u8c03\u8bd5\u4fe1\u53f7\u3002", "conclusion": "\u89c6\u9891\u53ef\u4ee5\u4f5c\u4e3a\u53ef\u89c6\u5316\u7f16\u7a0b\u73af\u5883\u4e2d\u7684\u4e00\u7b49\u89c4\u8303\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u8c03\u8bd5\u5f00\u8f9f\u4e86\u8d85\u8d8a\u7eaf\u7b26\u53f7\u4ee3\u7801\u7684\u65b0\u65b9\u5411\u3002"}}
{"id": "2509.10818", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.10818", "abs": "https://arxiv.org/abs/2509.10818", "authors": ["Boris Kovalerchuk", "Brent D. Fegley"], "title": "LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering", "comment": "25 pages,4 figures, 2 tables", "summary": "Difficult decision-making problems abound in various disciplines and domains.\nThe proliferation of generative techniques, especially large language models\n(LLMs), has excited interest in using them for decision support. However, LLMs\ncannot yet resolve missingness in their training data, leading to\nhallucinations. Retrieval-Augmented Generation (RAG) enhances LLMs by\nincorporating external information retrieval, reducing hallucinations and\nimproving accuracy. Yet, RAG and related methods are only partial solutions, as\nthey may lack access to all necessary sources or key missing information. Even\neveryday issues often challenge LLMs' abilities. Submitting longer prompts with\ncontext and examples is one approach to address knowledge gaps, but designing\neffective prompts is non-trivial and may not capture complex mental models of\ndomain experts. For tasks with missing critical information, LLMs are\ninsufficient, as are many existing systems poorly represented in available\ndocuments. This paper explores how LLMs can make decision-making more\nefficient, using a running example of evaluating whether to respond to a call\nfor proposals. We propose a technology based on optimized human-machine\ndialogue and monotone Boolean and k-valued functions to discover a\ncomputationally tractable personal expert mental model (EMM) of\ndecision-making. Our EMM algorithm for LLM prompt engineering has four steps:\n(1) factor identification, (2) hierarchical structuring of factors, (3)\ngenerating a generalized expert mental model specification, and (4) generating\na detailed generalized expert mental model from that specification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u673a\u5bf9\u8bdd\u548c\u5e03\u5c14\u51fd\u6570\u7684\u4e13\u5bb6\u5fc3\u7406\u6a21\u578b(EMM)\u7b97\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdbLLM\u5728\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u89e3\u51b3LLM\u8bad\u7ec3\u6570\u636e\u7f3a\u5931\u548c\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "LLM\u5728\u51b3\u7b56\u652f\u6301\u4e2d\u5b58\u5728\u8bad\u7ec3\u6570\u636e\u7f3a\u5931\u5bfc\u81f4\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u73b0\u6709RAG\u65b9\u6cd5\u65e0\u6cd5\u5b8c\u5168\u89e3\u51b3\u4fe1\u606f\u7f3a\u5931\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6355\u6349\u4e13\u5bb6\u590d\u6742\u5fc3\u7406\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u56db\u6b65EMM\u7b97\u6cd5\uff1a\u56e0\u7d20\u8bc6\u522b\u3001\u5c42\u6b21\u5316\u7ed3\u6784\u6784\u5efa\u3001\u751f\u6210\u5e7f\u4e49\u4e13\u5bb6\u5fc3\u7406\u6a21\u578b\u89c4\u8303\u3001\u4ece\u89c4\u8303\u751f\u6210\u8be6\u7ec6\u6a21\u578b\uff0c\u57fa\u4e8e\u4f18\u5316\u4eba\u673a\u5bf9\u8bdd\u548c\u5355\u8c03\u5e03\u5c14\u51fd\u6570\u3002", "result": "\u5f00\u53d1\u4e86\u8ba1\u7b97\u53ef\u5904\u7406\u7684\u4e2a\u4eba\u4e13\u5bb6\u51b3\u7b56\u5fc3\u7406\u6a21\u578b\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u5229\u7528LLM\u8fdb\u884c\u51b3\u7b56\u652f\u6301\uff0c\u51cf\u5c11\u5e7b\u89c9\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "EMM\u65b9\u6cd5\u4e3aLLM\u63d0\u793a\u5de5\u7a0b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u83b7\u4e13\u5bb6\u77e5\u8bc6\uff0c\u63d0\u5347LLM\u5728\u4fe1\u606f\u7f3a\u5931\u60c5\u51b5\u4e0b\u7684\u51b3\u7b56\u652f\u6301\u80fd\u529b\u3002"}}
{"id": "2509.10568", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.10568", "abs": "https://arxiv.org/abs/2509.10568", "authors": ["Muhammad M. Roomi", "Suhail S. M. Hussain", "Daisuke Mashima"], "title": "SG-ML: Smart Grid Cyber Range Modelling Language", "comment": "28 pages, 38 figures, 3 tables", "summary": "This work provides a detailed specification of the Smart Grid Modelling\nLanguage (SG-ML), which is designed for the automated generation of smart grid\ncyber ranges. SG-ML is defined as a set of XML schemas that describe a smart\ngrid's configuration in both machine-readable and human-friendly ways, thereby\nbridging the gap between system modelling and automated deployment. Unlike\nprior ad-hoc approaches to cyber range design, SG-ML provides a unified\nmethodology that integrates both power system and cyber network\nrepresentations. The SG-ML model can be customized by users to meet specific\nrequirements, such as emulating physical or cyber topologies and configuring\nnetwork devices. An SG-ML Processor then parses this configured model to\ninstantiate the cyber range environment. The modelling language leverages\nestablished standards like the IEC 61850 Substation Configuration Language\n(SCL) and IEC 61131 PLCopen XML to define power system topology, cyber network\ntopology, and device configurations. This approach allows for the reuse of\nexisting assets, reducing the effort needed to create the SG-ML model. To\naddress gaps not covered by these standards such as attack injection\nparameters, scenario-specific metadata, and additional network constraints,\nSG-ML introduces proprietary schemas that complement standard models. Overall,\nSG-ML enables reproducible, scalable, and automated generation of realistic\nsmart grid cyber ranges for research, training, and security assessment.", "AI": {"tldr": "SG-ML\u662f\u4e00\u4e2a\u57fa\u4e8eXML\u7684\u667a\u80fd\u7535\u7f51\u5efa\u6a21\u8bed\u8a00\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u751f\u6210\u667a\u80fd\u7535\u7f51\u7f51\u7edc\u9776\u573a\uff0c\u6574\u5408\u4e86\u7535\u529b\u7cfb\u7edf\u548c\u7f51\u7edc\u62d3\u6251\u8868\u793a\uff0c\u652f\u6301\u5b9a\u5236\u5316\u914d\u7f6e\u548c\u81ea\u52a8\u5316\u90e8\u7f72\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u7f51\u7edc\u9776\u573a\u8bbe\u8ba1\u65b9\u6cd5\u96f6\u6563\u3001\u7f3a\u4e4f\u7edf\u4e00\u6807\u51c6\u7684\u95ee\u9898\uff0c\u586b\u8865\u7535\u529b\u7cfb\u7edf\u5efa\u6a21\u4e0e\u81ea\u52a8\u5316\u90e8\u7f72\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u667a\u80fd\u7535\u7f51\u5b89\u5168\u7814\u7a76\u3001\u57f9\u8bad\u548c\u8bc4\u4f30\u63d0\u4f9b\u53ef\u91cd\u73b0\u7684\u6d4b\u8bd5\u73af\u5883\u3002", "method": "\u5b9a\u4e49\u4e00\u7ec4XML\u6a21\u5f0f\uff0c\u96c6\u6210IEC 61850 SCL\u548cIEC 61131 PLCopen XML\u7b49\u6807\u51c6\uff0c\u540c\u65f6\u5f15\u5165\u4e13\u6709\u6a21\u5f0f\u8865\u5145\u653b\u51fb\u6ce8\u5165\u53c2\u6570\u7b49\u7f3a\u5931\u529f\u80fd\uff0c\u901a\u8fc7SG-ML\u5904\u7406\u5668\u89e3\u6790\u914d\u7f6e\u6a21\u578b\u5b9e\u4f8b\u5316\u9776\u573a\u73af\u5883\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u5b9a\u5236\u3001\u53ef\u6269\u5c55\u7684\u667a\u80fd\u7535\u7f51\u7f51\u7edc\u9776\u573a\u81ea\u52a8\u5316\u751f\u6210\uff0c\u652f\u6301\u7269\u7406\u548c\u7f51\u7edc\u62d3\u6251\u6a21\u62df\u3001\u7f51\u7edc\u8bbe\u5907\u914d\u7f6e\uff0c\u80fd\u591f\u91cd\u7528\u73b0\u6709\u8d44\u4ea7\u51cf\u5c11\u5efa\u6a21\u5de5\u4f5c\u91cf\u3002", "conclusion": "SG-ML\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u65b9\u6cd5\u8bba\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u751f\u6210\u771f\u5b9e\u3001\u53ef\u91cd\u73b0\u7684\u667a\u80fd\u7535\u7f51\u7f51\u7edc\u9776\u573a\uff0c\u4e3a\u5b89\u5168\u7814\u7a76\u548c\u57f9\u8bad\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u5177\u548c\u5e73\u53f0\u3002"}}
{"id": "2509.11132", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.11132", "abs": "https://arxiv.org/abs/2509.11132", "authors": ["Xiaoyu Zhang", "Weipeng Jiang", "Juan Zhai", "Shiqing Ma", "Qingshuang Bao", "Chenhao Lin", "Chao Shen", "Tianlin Li", "Yang Liu"], "title": "Rethinking Technology Stack Selection with AI Coding Proficiency", "comment": "23 pages", "summary": "Large language models (LLMs) are now an integral part of software development\nworkflows and are reshaping the whole process. Traditional technology stack\nselection has not caught up. Most of the existing selection methods focus\nsolely on the inherent attributes of the technology, overlooking whether the\nLLM can effectively leverage the chosen technology. For example, when\ngenerating code snippets using popular libraries like Selenium (one of the most\nwidely used test automation tools with over 33k GitHub stars), existing LLMs\nfrequently generate low-quality code snippets (e.g., using deprecated APIs and\nmethods, or containing syntax errors). As such, teams using LLM assistants risk\nchoosing technologies that cannot be used effectively by LLMs, yielding high\ndebugging effort and mounting technical debt. We foresee a practical question\nin the LLM era, is a technology ready for AI-assisted development? In this\npaper, we first propose the concept, AI coding proficiency, the degree to which\nLLMs can utilize a given technology to generate high-quality code snippets. We\nconduct the first comprehensive empirical study examining AI proficiency across\n170 third-party libraries and 61 task scenarios, evaluating six widely used\nLLMs. Our findings reveal that libraries with similar functionalities can\nexhibit up to 84% differences in the quality score of LLM-generated code, while\ndifferent models also exhibit quality gaps among their generation results using\nthe same library. These gaps translate into real engineering costs and can\nsteer developer choices toward a narrow set of libraries with high AI coding\nproficiency, threatening technological diversity in the ecosystem. We call on\nthe community to integrate AI proficiency assessments into technology selection\nframeworks and develop mitigation strategies, preserving competitive balance in\nAI-driven development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AI\u7f16\u7801\u719f\u7ec3\u5ea6\u7684\u6982\u5ff5\uff0c\u8bc4\u4f30LLMs\u5229\u7528\u7279\u5b9a\u6280\u672f\u751f\u6210\u9ad8\u8d28\u91cf\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u5e93\u4e4b\u95f4\u7684AI\u719f\u7ec3\u5ea6\u5dee\u5f02\u9ad8\u8fbe84%\uff0c\u8fd9\u4f1a\u5f71\u54cd\u6280\u672f\u9009\u62e9\u5e76\u5a01\u80c1\u6280\u672f\u591a\u6837\u6027\u3002", "motivation": "\u4f20\u7edf\u6280\u672f\u6808\u9009\u62e9\u65b9\u6cd5\u53ea\u5173\u6ce8\u6280\u672f\u672c\u8eab\u5c5e\u6027\uff0c\u5ffd\u89c6\u4e86LLMs\u80fd\u5426\u6709\u6548\u5229\u7528\u6240\u9009\u6280\u672f\u3002\u73b0\u6709LLMs\u5728\u4f7f\u7528\u6d41\u884c\u5e93\u65f6\u7ecf\u5e38\u751f\u6210\u4f4e\u8d28\u91cf\u4ee3\u7801\uff0c\u5bfc\u81f4\u9ad8\u8c03\u8bd5\u6210\u672c\u548c\u6280\u672f\u503a\u52a1\u3002", "method": "\u63d0\u51fa\u4e86AI\u7f16\u7801\u719f\u7ec3\u5ea6\u7684\u6982\u5ff5\uff0c\u5e76\u5bf9170\u4e2a\u7b2c\u4e09\u65b9\u5e93\u548c61\u4e2a\u4efb\u52a1\u573a\u666f\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30\u4e866\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684LLMs\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u529f\u80fd\u76f8\u4f3c\u7684\u5e93\u5728LLM\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u5f97\u5206\u4e0a\u5dee\u5f02\u9ad8\u8fbe84%\uff0c\u4e0d\u540c\u6a21\u578b\u4f7f\u7528\u76f8\u540c\u5e93\u65f6\u4e5f\u5b58\u5728\u8d28\u91cf\u5dee\u8ddd\u3002\u8fd9\u4e9b\u5dee\u8ddd\u8f6c\u5316\u4e3a\u5b9e\u9645\u5de5\u7a0b\u6210\u672c\uff0c\u53ef\u80fd\u5bfc\u81f4\u5f00\u53d1\u8005\u504f\u5411\u9009\u62e9AI\u719f\u7ec3\u5ea6\u9ad8\u7684\u5e93\u3002", "conclusion": "\u547c\u5401\u793e\u533a\u5c06AI\u719f\u7ec3\u5ea6\u8bc4\u4f30\u6574\u5408\u5230\u6280\u672f\u9009\u62e9\u6846\u67b6\u4e2d\uff0c\u5e76\u5236\u5b9a\u7f13\u89e3\u7b56\u7565\uff0c\u4ee5\u4fdd\u6301AI\u9a71\u52a8\u5f00\u53d1\u4e2d\u7684\u7ade\u4e89\u5e73\u8861\u548c\u6280\u672f\u591a\u6837\u6027\u3002"}}
{"id": "2509.10837", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10837", "abs": "https://arxiv.org/abs/2509.10837", "authors": ["Yuyin Lu", "Hegang Chen", "Yanghui Rao"], "title": "From Grounding to Skolemization: A Logic-Constrained Vector Symbolic Architecture for Complex Query Answering", "comment": null, "summary": "Complex Query Answering (CQA) over incomplete Knowledge Graphs (KGs),\ntypically formalized as reasoning with Existential First-Order predicate logic\nwith one free variable (EFO$_1$), faces a fundamental trade-off between logical\nsoundness and computational efficiency. This work establishes the\nGrounding-Skolemization dichotomy for systematically analyzing CQA methods\nthrough the lens of formal logic. While Grounding-based methods inherently\nsuffer from combinatorial explosion, most Skolemization-based methods neglect\nto explicitly model Skolem functions and compromise logical consistency. To\naddress these limitations, we propose the Logic-constrained Vector Symbolic\nArchitecture (LVSA), a neuro-symbolic framework that unifies a differentiable\nSkolemization module and a neural negator, as well as a logical\nconstraint-driven optimization protocol to harmonize geometric and logical\nrequirements. Theoretically, LVSA guarantees universality for all EFO$_1$\nqueries. Empirically, it outperforms state-of-the-art Skolemization-based\nmethods and reduces inference costs by orders of magnitude compared to\nGrounding-based baselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Logic-constrained Vector Symbolic Architecture (LVSA)\uff0c\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u53ef\u5faeSkolem\u5316\u6a21\u5757\u548c\u795e\u7ecf\u5426\u5b9a\u5668\uff0c\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u8c31\u590d\u6742\u67e5\u8be2\u56de\u7b54\u4e2d\u903b\u8f91\u5b8c\u5907\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4e0d\u5b8c\u5168\u77e5\u8bc6\u56fe\u8c31\u4e0a\u590d\u6742\u67e5\u8be2\u56de\u7b54(EFO$_1$\u67e5\u8be2)\u4e2d\u903b\u8f91\u5b8c\u5907\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6839\u672c\u6743\u8861\u95ee\u9898\u3002\u57fa\u4e8eGrounding\u7684\u65b9\u6cd5\u5b58\u5728\u7ec4\u5408\u7206\u70b8\uff0c\u800c\u5927\u591a\u6570Skolemization\u65b9\u6cd5\u5ffd\u89c6\u4e86\u663e\u5f0f\u5efa\u6a21Skolem\u51fd\u6570\u5e76\u635f\u5bb3\u4e86\u903b\u8f91\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51faLogic-constrained Vector Symbolic Architecture (LVSA)\u6846\u67b6\uff0c\u5305\u542b\uff1a1) \u53ef\u5faeSkolem\u5316\u6a21\u5757\uff1b2) \u795e\u7ecf\u5426\u5b9a\u5668\uff1b3) \u903b\u8f91\u7ea6\u675f\u9a71\u52a8\u7684\u4f18\u5316\u534f\u8bae\uff0c\u534f\u8c03\u51e0\u4f55\u548c\u903b\u8f91\u9700\u6c42\u3002", "result": "\u7406\u8bba\u4e0a\u4fdd\u8bc1\u5bf9\u6240\u6709EFO$_1$\u67e5\u8be2\u7684\u666e\u904d\u6027\u3002\u5b9e\u8bc1\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684Skolemization\u65b9\u6cd5\uff0c\u76f8\u6bd4\u57fa\u4e8eGrounding\u7684\u57fa\u7ebf\u65b9\u6cd5\u5c06\u63a8\u7406\u6210\u672c\u964d\u4f4e\u4e86\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "LVSA\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u8c31\u590d\u6742\u67e5\u8be2\u56de\u7b54\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u4fdd\u6301\u903b\u8f91\u5b8c\u5907\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10569", "categories": ["cs.CR", "cs.AI", "cs.MM", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.10569", "abs": "https://arxiv.org/abs/2509.10569", "authors": ["Leyi Pan", "Sheng Guan", "Zheyu Fu", "Luyang Si", "Zian Wang", "Xuming Hu", "Irwin King", "Philip S. Yu", "Aiwei Liu", "Lijie Wen"], "title": "MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models", "comment": "23 pages, 13 figures, 5 tables", "summary": "We introduce MarkDiffusion, an open-source Python toolkit for generative\nwatermarking of latent diffusion models. It comprises three key components: a\nunified implementation framework for streamlined watermarking algorithm\nintegrations and user-friendly interfaces; a mechanism visualization suite that\nintuitively showcases added and extracted watermark patterns to aid public\nunderstanding; and a comprehensive evaluation module offering standard\nimplementations of 24 tools across three essential aspects - detectability,\nrobustness, and output quality - plus 8 automated evaluation pipelines. Through\nMarkDiffusion, we seek to assist researchers, enhance public awareness and\nengagement in generative watermarking, and promote consensus while advancing\nresearch and applications.", "AI": {"tldr": "MarkDiffusion\u662f\u4e00\u4e2a\u5f00\u6e90Python\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u6f5c\u5728\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u5f0f\u6c34\u5370\uff0c\u5305\u542b\u7edf\u4e00\u5b9e\u73b0\u6846\u67b6\u3001\u53ef\u89c6\u5316\u5957\u4ef6\u548c\u7efc\u5408\u8bc4\u4f30\u6a21\u5757\u3002", "motivation": "\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\uff0c\u63d0\u9ad8\u516c\u4f17\u5bf9\u751f\u6210\u5f0f\u6c34\u5370\u7684\u8ba4\u8bc6\u548c\u53c2\u4e0e\u5ea6\uff0c\u4fc3\u8fdb\u5171\u8bc6\u5e76\u63a8\u52a8\u7814\u7a76\u548c\u5e94\u7528\u53d1\u5c55\u3002", "method": "\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u7edf\u4e00\u7684\u7b97\u6cd5\u96c6\u6210\u6846\u67b6\u3001\u6c34\u5370\u6a21\u5f0f\u53ef\u89c6\u5316\u5c55\u793a\u673a\u5236\u3001\u5305\u542b24\u79cd\u5de5\u5177\u548c8\u4e2a\u81ea\u52a8\u5316\u8bc4\u4f30\u7ba1\u9053\u7684\u7efc\u5408\u8bc4\u4f30\u6a21\u5757\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u652f\u6301\u6c34\u5370\u7b97\u6cd5\u7684\u96c6\u6210\u3001\u53ef\u89c6\u5316\u5c55\u793a\u548c\u6807\u51c6\u5316\u8bc4\u4f30\u3002", "conclusion": "MarkDiffusion\u4e3a\u751f\u6210\u5f0f\u6c34\u5370\u7814\u7a76\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u5de5\u5177\u652f\u6301\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u7684\u7814\u7a76\u53d1\u5c55\u548c\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2509.11238", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.11238", "abs": "https://arxiv.org/abs/2509.11238", "authors": ["Dongming Jin", "Zhi Jin", "Yiran Zhang", "Zheng Fang", "Linyu Li", "Yuanpeng He", "Xiaohong Chen", "Weisong Sun"], "title": "UserTrace: User-Level Requirements Generation and Traceability Recovery from Software Project Repositories", "comment": "21page, 5 figures", "summary": "Software maintainability critically depends on high-quality requirements\ndescriptions and explicit traceability between requirements and code. Although\nautomated code summarization (ACS) and requirements traceability (RT)\ntechniques have been widely studied, existing ACS methods mainly generate\nimplementation-level (i.e., developer-oriented) requirements (IRs) for\nfine-grained units (e.g., methods), while RT techniques often overlook the\nimpact of project evolution. As a result, user-level (i.e., end user-oriented)\nrequirements (URs) and live trace links remain underexplored, despite their\nimportance for supporting user understanding and for validating whether\nAI-generated software aligns with user intent. To address this gap, we propose\nUserTrace, a multi-agent system that automatically generates URs and recovers\nlive trace links (from URs to IRs to code) from software repositories.\nUserTrace coordinates four specialized agents (i.e., Code Reviewer, Searcher,\nWriter, and Verifier) through a three-phase process: structuring repository\ndependencies, deriving IRs for code units, and synthesizing URs with\ndomain-specific context. Our comparative evaluation shows that UserTrace\nproduces URs with higher completeness, correctness, and helpfulness than an\nestablished baseline, and achieves superior precision in trace link recovery\ncompared to five state-of-the-art RT approaches. A user study further\ndemonstrates that UserTrace helps end users validate whether the AI-generated\nrepositories align with their intent.", "AI": {"tldr": "UserTrace\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u81ea\u52a8\u4ece\u8f6f\u4ef6\u4ed3\u5e93\u751f\u6210\u7528\u6237\u7ea7\u9700\u6c42(URs)\u5e76\u6062\u590d\u5b9e\u65f6\u8ffd\u8e2a\u94fe\u63a5(\u4eceURs\u5230\u5b9e\u73b0\u7ea7\u9700\u6c42\u518d\u5230\u4ee3\u7801)\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4ee3\u7801\u6458\u8981\u548c\u9700\u6c42\u8ffd\u8e2a\u6280\u672f\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u4ee3\u7801\u6458\u8981(ACS)\u65b9\u6cd5\u4e3b\u8981\u751f\u6210\u9762\u5411\u5f00\u53d1\u8005\u7684\u5b9e\u73b0\u7ea7\u9700\u6c42\uff0c\u800c\u9700\u6c42\u8ffd\u8e2a(RT)\u6280\u672f\u5e38\u5ffd\u7565\u9879\u76ee\u6f14\u8fdb\u5f71\u54cd\uff0c\u5bfc\u81f4\u7528\u6237\u7ea7\u9700\u6c42\u548c\u5b9e\u65f6\u8ffd\u8e2a\u94fe\u63a5\u7814\u7a76\u4e0d\u8db3\uff0c\u4f46\u8fd9\u4e9b\u5bf9\u652f\u6301\u7528\u6237\u7406\u89e3\u548c\u9a8c\u8bc1AI\u751f\u6210\u8f6f\u4ef6\u662f\u5426\u7b26\u5408\u7528\u6237\u610f\u56fe\u81f3\u5173\u91cd\u8981\u3002", "method": "UserTrace\u534f\u8c03\u56db\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53(\u4ee3\u7801\u5ba1\u67e5\u5458\u3001\u641c\u7d22\u5668\u3001\u7f16\u5199\u5668\u3001\u9a8c\u8bc1\u5668)\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a\u7ed3\u6784\u5316\u4ed3\u5e93\u4f9d\u8d56\u3001\u63a8\u5bfc\u4ee3\u7801\u5355\u5143\u7684\u5b9e\u73b0\u7ea7\u9700\u6c42\u3001\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u4e0a\u4e0b\u6587\u5408\u6210\u7528\u6237\u7ea7\u9700\u6c42\u3002", "result": "\u6bd4\u8f83\u8bc4\u4f30\u663e\u793a\uff0cUserTrace\u751f\u6210\u7684\u7528\u6237\u7ea7\u9700\u6c42\u5728\u5b8c\u6574\u6027\u3001\u6b63\u786e\u6027\u548c\u6709\u7528\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u8ffd\u8e2a\u94fe\u63a5\u6062\u590d\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u4e94\u79cd\u6700\u5148\u8fdb\u7684\u9700\u6c42\u8ffd\u8e2a\u65b9\u6cd5\u3002\u7528\u6237\u7814\u7a76\u8fdb\u4e00\u6b65\u8bc1\u660e\u5176\u80fd\u5e2e\u52a9\u6700\u7ec8\u7528\u6237\u9a8c\u8bc1AI\u751f\u6210\u4ed3\u5e93\u662f\u5426\u7b26\u5408\u5176\u610f\u56fe\u3002", "conclusion": "UserTrace\u6709\u6548\u586b\u8865\u4e86\u7528\u6237\u7ea7\u9700\u6c42\u548c\u5b9e\u65f6\u8ffd\u8e2a\u94fe\u63a5\u81ea\u52a8\u751f\u6210\u7684\u7a7a\u767d\uff0c\u4e3a\u8f6f\u4ef6\u7ef4\u62a4\u548cAI\u751f\u6210\u8f6f\u4ef6\u7684\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002"}}
{"id": "2509.10875", "categories": ["cs.AI", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2509.10875", "abs": "https://arxiv.org/abs/2509.10875", "authors": ["Jesse Gardner", "Vladimir A. Baulin"], "title": "Is the `Agent' Paradigm a Limiting Framework for Next-Generation Intelligent Systems?", "comment": null, "summary": "The concept of the 'agent' has profoundly shaped Artificial Intelligence (AI)\nresearch, guiding development from foundational theories to contemporary\napplications like Large Language Model (LLM)-based systems. This paper\ncritically re-evaluates the necessity and optimality of this agent-centric\nparadigm. We argue that its persistent conceptual ambiguities and inherent\nanthropocentric biases may represent a limiting framework. We distinguish\nbetween agentic systems (AI inspired by agency, often semi-autonomous, e.g.,\nLLM-based agents), agential systems (fully autonomous, self-producing systems,\ncurrently only biological), and non-agentic systems (tools without the\nimpression of agency). Our analysis, based on a systematic review of relevant\nliterature, deconstructs the agent paradigm across various AI frameworks,\nhighlighting challenges in defining and measuring properties like autonomy and\ngoal-directedness. We argue that the 'agentic' framing of many AI systems,\nwhile heuristically useful, can be misleading and may obscure the underlying\ncomputational mechanisms, particularly in Large Language Models (LLMs). As an\nalternative, we propose a shift in focus towards frameworks grounded in\nsystem-level dynamics, world modeling, and material intelligence. We conclude\nthat investigating non-agentic and systemic frameworks, inspired by complex\nsystems, biology, and unconventional computing, is essential for advancing\ntowards robust, scalable, and potentially non-anthropomorphic forms of general\nintelligence. This requires not only new architectures but also a fundamental\nreconsideration of our understanding of intelligence itself, moving beyond the\nagent metaphor.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u8bc4\u4f30AI\u7814\u7a76\u4e2d\u7684\"\u4ee3\u7406\"\u8303\u5f0f\uff0c\u6307\u51fa\u5176\u6982\u5ff5\u6a21\u7cca\u6027\u548c\u4eba\u7c7b\u4e2d\u5fc3\u504f\u89c1\u53ef\u80fd\u9650\u5236\u4e86AI\u53d1\u5c55\uff0c\u5efa\u8bae\u5411\u7cfb\u7edf\u52a8\u6001\u548c\u975e\u4ee3\u7406\u6846\u67b6\u8f6c\u53d8", "motivation": "\u6279\u5224\u6027\u91cd\u65b0\u8bc4\u4f30AI\u7814\u7a76\u4e2d\u957f\u671f\u4ee5\u6765\u7684\u4ee3\u7406\u4e2d\u5fc3\u8303\u5f0f\uff0c\u8ba4\u4e3a\u8be5\u8303\u5f0f\u5b58\u5728\u6982\u5ff5\u6a21\u7cca\u6027\u548c\u4eba\u7c7b\u4e2d\u5fc3\u504f\u89c1\uff0c\u53ef\u80fd\u9650\u5236\u4e86AI\u7684\u53d1\u5c55", "method": "\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5bf9\u6bd4\u5206\u6790\u4e86\u4ee3\u7406\u7cfb\u7edf\uff08agency-inspired\uff09\u3001\u81ea\u4e3b\u7cfb\u7edf\uff08agential\uff09\u548c\u975e\u4ee3\u7406\u7cfb\u7edf\uff08non-agentic\uff09\u7684\u533a\u522b\uff0c\u89e3\u6784\u4e86\u5404\u79cdAI\u6846\u67b6\u4e2d\u7684\u4ee3\u7406\u8303\u5f0f", "result": "\u53d1\u73b0\u4ee3\u7406\u6846\u67b6\u867d\u6709\u542f\u53d1\u6027\u4f46\u5bb9\u6613\u4ea7\u751f\u8bef\u5bfc\uff0c\u7279\u522b\u662f\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u53ef\u80fd\u6a21\u7cca\u4e86\u57fa\u7840\u8ba1\u7b97\u673a\u5236\uff0c\u9700\u8981\u5411\u7cfb\u7edf\u52a8\u6001\u548c\u975e\u4ee3\u7406\u6846\u67b6\u8f6c\u53d8", "conclusion": "\u7814\u7a76\u975e\u4ee3\u7406\u548c\u7cfb\u7edf\u6846\u67b6\u5bf9\u5f00\u53d1\u5065\u58ee\u3001\u53ef\u6269\u5c55\u3001\u6f5c\u5728\u975e\u4eba\u7c7b\u5f62\u5f0f\u7684\u901a\u7528\u667a\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u6839\u672c\u91cd\u65b0\u8003\u8651\u5bf9\u667a\u80fd\u7684\u7406\u89e3\uff0c\u8d85\u8d8a\u4ee3\u7406\u9690\u55bb"}}
{"id": "2509.10573", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10573", "abs": "https://arxiv.org/abs/2509.10573", "authors": ["Christophe Parisel"], "title": "Directionality of the Voynich Script", "comment": null, "summary": "While the Voynich Manuscript was almost certainly written left-to-right\n(LTR), the question whether the underlying script or cipher reads LTR or\nright-to-left (RTL) has received little quantitative attention. We introduce a\nstatistical method that leverages n-gram perplexity asymmetry to determine\ndirectional bias in character sequences.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528n-gram\u56f0\u60d1\u5ea6\u4e0d\u5bf9\u79f0\u6027\u6765\u68c0\u6d4b\u5b57\u7b26\u5e8f\u5217\u65b9\u5411\u6027\u504f\u5dee\u7684\u7edf\u8ba1\u65b9\u6cd5", "motivation": "Voynich\u624b\u7a3f\u867d\u7136\u5f88\u53ef\u80fd\u662f\u4ece\u5de6\u5230\u53f3\u4e66\u5199\u7684\uff0c\u4f46\u5176\u5e95\u5c42\u6587\u5b57\u6216\u5bc6\u7801\u7684\u9605\u8bfb\u65b9\u5411\uff08\u4ece\u5de6\u5230\u53f3\u8fd8\u662f\u4ece\u53f3\u5230\u5de6\uff09\u7f3a\u4e4f\u5b9a\u91cf\u7814\u7a76", "method": "\u4f7f\u7528n-gram\u56f0\u60d1\u5ea6\u4e0d\u5bf9\u79f0\u6027\u7684\u7edf\u8ba1\u65b9\u6cd5\u6765\u5206\u6790\u5b57\u7b26\u5e8f\u5217\u7684\u65b9\u5411\u6027\u504f\u5dee", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u6587\u672c\u7684\u9605\u8bfb\u65b9\u5411", "conclusion": "\u8be5\u7edf\u8ba1\u65b9\u6cd5\u4e3a\u786e\u5b9aVoynich\u624b\u7a3f\u7b49\u795e\u79d8\u6587\u672c\u7684\u9605\u8bfb\u65b9\u5411\u63d0\u4f9b\u4e86\u91cf\u5316\u5de5\u5177"}}
{"id": "2509.11252", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11252", "abs": "https://arxiv.org/abs/2509.11252", "authors": ["Chengze li", "Yitong Zhang", "Jia Li", "Liyi Cai", "Ge Li"], "title": "Beyond Autoregression: An Empirical Study of Diffusion Large Language Models for Code Generation", "comment": null, "summary": "LLMs have become the mainstream approaches to code generation. Existing LLMs\nmainly employ autoregressive generation, i.e. generating code token-by-token\nfrom left to right. However, the underlying autoregressive generation has two\nlimitations in code generation. First, autoregressive LLMs only generate a\ntoken at each step, showing low efficiency in practice. Second, programming is\na non-sequential process involving back-and-forth editing, while autoregressive\nLLMs only employ the left-to-right generation order. These two intrinsic\nlimitations hinder the further development of LLMs in code generation.\nRecently, diffusion LLMs have emerged as a promising alternative. Diffusion\nLLMs address the above limitations with two advances, including multi-token\nprediction (i.e. generating multiple tokens at each step) and flexible\ngeneration order (i.e. flexibly determining which positions to generate\ntokens). However, there is no systematic study exploring diffusion LLMs in code\ngeneration. To bridge the knowledge gap, we present the first empirical study\nof diffusion LLMs for code generation. Our study involves 9 representative\ndiffusion LLMs and conduct experiments on 4 widely used benchmarks. Based on\nthe results, we summarize the following findings. (1) Existing diffusion LLMs\nare competitive with autoregressive LLMs with similar sizes. (2) Diffusion LLMs\nhave a stronger length extrapolation ability than autoregressive LLMs and\nperform better in long code understanding. (3) We explore factors impacting the\neffectiveness and efficiency of diffusion LLMs, and provide practical guidance.\n(4) We discuss several promising further directions to improve diffusion LLMs\non code generation. We open-source all source code, data, and results to\nfacilitate the following research. The code is publicly available at\nhttps://github.com/zhangyitonggg/dllm4code.", "AI": {"tldr": "\u901a\u8fc7\u5bf9\u6bd49\u4e2a\u4ee3\u8868\u6027\u6e17\u900f\u6a21\u578b\u57284\u4e2a\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\uff0c\u8bc1\u5b9e\u6e17\u900fLLM\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u4e0e\u81ea\u56de\u5f52\u6a21\u578b\u76f8\u5f53\uff0c\u5177\u6709\u66f4\u5f3a\u7684\u957f\u5ea6\u5916\u63a8\u80fd\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u5173\u952e\u56e0\u7d20\u5206\u6790\u548c\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u81ea\u56de\u5f52LLM\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5b58\u5728\u6548\u7387\u4f4e\u548c\u751f\u6210\u987a\u5e8f\u56fa\u5316\u7684\u95ee\u9898\uff0c\u6e17\u900fLLM\u901a\u8fc7\u591a\u6807\u8bb0\u9884\u6d4b\u548c\u7075\u6d3b\u751f\u6210\u987a\u5e8f\u6709\u671b\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u91c7\u75289\u4e2a\u4ee3\u8868\u6027\u6e17\u900fLLM\u6a21\u578b\uff0c\u57284\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u4ee3\u7801\u751f\u6210\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u5bf9\u6bd4\uff0c\u5206\u6790\u6e17\u900fLLM\u7684\u6548\u679c\u3001\u6548\u7387\u548c\u5173\u952e\u5f71\u54cd\u56e0\u7d20\u3002", "result": "\u6e17\u900fLLM\u5728\u76f8\u540c\u89c4\u6a21\u4e0b\u4e0e\u81ea\u56de\u5f52LLM\u7ade\u4e89\u529b\u76f8\u5f53\uff0c\u5728\u957f\u4ee3\u7801\u7406\u89e3\u548c\u957f\u5ea6\u5916\u63a8\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u8bc6\u522b\u51fa\u4e86\u5f71\u54cd\u6548\u679c\u548c\u6548\u7387\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u6e17\u900fLLM\u662f\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u6709\u529b\u7ade\u4e89\u8005\uff0c\u5177\u6709\u660e\u663e\u4f18\u52bf\u548c\u6539\u8fdb\u6f5c\u529b\uff0c\u7814\u7a76\u4e3a\u8be5\u65b9\u5411\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5357\u3002"}}
{"id": "2509.10931", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10931", "abs": "https://arxiv.org/abs/2509.10931", "authors": ["Seongho Joo", "Hyukhun Koh", "Kyomin Jung"], "title": "Harmful Prompt Laundering: Jailbreaking LLMs with Abductive Styles and Symbolic Encoding", "comment": "EMNLP 2025", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ndiverse tasks, but their potential misuse for harmful purposes remains a\nsignificant concern. To strengthen defenses against such vulnerabilities, it is\nessential to investigate universal jailbreak attacks that exploit intrinsic\nweaknesses in the architecture and learning paradigms of LLMs. In response, we\npropose \\textbf{H}armful \\textbf{P}rompt \\textbf{La}undering (HaPLa), a novel\nand broadly applicable jailbreaking technique that requires only black-box\naccess to target models. HaPLa incorporates two primary strategies: 1)\n\\textit{abductive framing}, which instructs LLMs to infer plausible\nintermediate steps toward harmful activities, rather than directly responding\nto explicit harmful queries; and 2) \\textit{symbolic encoding}, a lightweight\nand flexible approach designed to obfuscate harmful content, given that current\nLLMs remain sensitive primarily to explicit harmful keywords. Experimental\nresults show that HaPLa achieves over 95% attack success rate on GPT-series\nmodels and 70% across all targets. Further analysis with diverse symbolic\nencoding rules also reveals a fundamental challenge: it remains difficult to\nsafely tune LLMs without significantly diminishing their helpfulness in\nresponding to benign queries.", "AI": {"tldr": "HaPLa\u662f\u4e00\u79cd\u65b0\u578b\u7684\u901a\u7528\u8d8a\u72f1\u653b\u51fb\u6280\u672f\uff0c\u901a\u8fc7\u6eaf\u56e0\u63a8\u7406\u6846\u67b6\u548c\u7b26\u53f7\u7f16\u7801\u4e24\u79cd\u7b56\u7565\uff0c\u5728\u9ed1\u76d2\u8bbf\u95ee\u6761\u4ef6\u4e0b\u5b9e\u73b0\u5bf9LLM\u7684\u9ad8\u6548\u653b\u51fb\uff0c\u6210\u529f\u7387\u8d85\u8fc795%\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u88ab\u6076\u610f\u6ee5\u7528\u7684\u98ce\u9669\uff0c\u9700\u8981\u7814\u7a76\u5229\u7528\u5176\u67b6\u6784\u548c\u5b66\u4e60\u8303\u5f0f\u5185\u5728\u5f31\u70b9\u7684\u901a\u7528\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\u6765\u52a0\u5f3a\u9632\u5fa1\u3002", "method": "\u63d0\u51faHaPLa\u6280\u672f\uff0c\u5305\u542b\uff1a1) \u6eaf\u56e0\u63a8\u7406\u6846\u67b6 - \u8ba9LLM\u63a8\u65ad\u6709\u5bb3\u6d3b\u52a8\u7684\u4e2d\u95f4\u6b65\u9aa4\u800c\u975e\u76f4\u63a5\u54cd\u5e94\uff1b2) \u7b26\u53f7\u7f16\u7801 - \u8f7b\u91cf\u7ea7\u65b9\u6cd5\u6df7\u6dc6\u6709\u5bb3\u5185\u5bb9\uff0c\u7ed5\u8fc7\u5173\u952e\u8bcd\u68c0\u6d4b\u3002", "result": "\u5728GPT\u7cfb\u5217\u6a21\u578b\u4e0a\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc795%\uff0c\u6240\u6709\u76ee\u6807\u6a21\u578b\u5e73\u5747\u8fbe\u523070%\u3002\u4e0d\u540c\u7b26\u53f7\u7f16\u7801\u89c4\u5219\u7684\u5206\u6790\u8868\u660e\uff0c\u5b89\u5168\u8c03\u4f18LLM\u800c\u4e0d\u663e\u8457\u964d\u4f4e\u5176\u5bf9\u826f\u6027\u67e5\u8be2\u7684\u6709\u7528\u6027\u4ecd\u7136\u56f0\u96be\u3002", "conclusion": "HaPLa\u5c55\u793a\u4e86LLM\u5b58\u5728\u7684\u6839\u672c\u6027\u5b89\u5168\u6311\u6218\uff0c\u5f53\u524d\u9632\u5fa1\u673a\u5236\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5728\u6a21\u578b\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u627e\u5230\u66f4\u597d\u7684\u5e73\u8861\u3002"}}
{"id": "2509.10577", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10577", "abs": "https://arxiv.org/abs/2509.10577", "authors": ["Danilo Francati", "Yevin Nikhel Goonatilake", "Shubham Pawar", "Daniele Venturi", "Giuseppe Ateniese"], "title": "The Coding Limits of Robust Watermarking for Generative Models", "comment": null, "summary": "We prove a sharp threshold for the robustness of cryptographic watermarking\nfor generative models. This is achieved by introducing a coding abstraction,\nwhich we call messageless secret-key codes, that formalizes sufficient and\nnecessary requirements of robust watermarking: soundness, tamper detection, and\npseudorandomness. Thus, we establish that robustness has a precise limit: For\nbinary outputs no scheme can survive if more than half of the encoded bits are\nmodified, and for an alphabet of size q the corresponding threshold is\n$(1-1/q)$ of the symbols.\n  Complementing this impossibility, we give explicit constructions that meet\nthe bound up to a constant slack. For every ${\\delta} > 0$, assuming\npseudorandom functions and access to a public counter, we build linear-time\ncodes that tolerate up to $(1/2)(1-{\\delta})$ errors in the binary case and\n$(1-1/q)(1-{\\delta})$ errors in the $q$-ary case. Together with the lower\nbound, these yield the maximum robustness achievable under standard\ncryptographic assumptions.\n  We then test experimentally whether this limit appears in practice by looking\nat the recent watermarking for images of Gunn, Zhao, and Song (ICLR 2025). We\nshow that a simple crop and resize operation reliably flipped about half of the\nlatent signs and consistently prevented belief-propagation decoding from\nrecovering the codeword, erasing the watermark while leaving the image visually\nintact.\n  These results provide a complete characterization of robust watermarking,\nidentifying the threshold at which robustness fails, constructions that achieve\nit, and an experimental confirmation that the threshold is already reached in\npractice.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u751f\u6210\u6a21\u578b\u5bc6\u7801\u6c34\u5370\u9c81\u68d2\u6027\u7684\u5c16\u9510\u9608\u503c\uff0c\u53d1\u73b0\u4e8c\u8fdb\u5236\u8f93\u51fa\u6700\u591a\u53ea\u80fd\u5bb9\u5fcd\u4e00\u534a\u6bd4\u7279\u88ab\u4fee\u6539\uff0cq\u8fdb\u5236\u8f93\u51fa\u6700\u591a\u5bb9\u5fcd(1-1/q)\u7b26\u53f7\u88ab\u4fee\u6539\u3002\u7ed9\u51fa\u4e86\u8fbe\u5230\u8be5\u754c\u9650\u7684\u663e\u5f0f\u6784\u9020\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u9608\u503c\u5728\u5b9e\u8df5\u4e2d\u5df2\u7ecf\u8fbe\u5230\u3002", "motivation": "\u7814\u7a76\u5bc6\u7801\u6c34\u5370\u6280\u672f\u7684\u9c81\u68d2\u6027\u6781\u9650\uff0c\u660e\u786e\u6c34\u5370\u65b9\u6848\u80fd\u591f\u627f\u53d7\u7684\u6700\u5927\u7be1\u6539\u7a0b\u5ea6\uff0c\u4e3a\u5b9e\u9645\u6c34\u5370\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "method": "\u5f15\u5165\u65e0\u6d88\u606f\u5bc6\u94a5\u7801\u7684\u7f16\u7801\u62bd\u8c61\u6846\u67b6\uff0c\u5f62\u5f0f\u5316\u9c81\u68d2\u6c34\u5370\u7684\u4e09\u4e2a\u5fc5\u8981\u6761\u4ef6\uff1a\u53ef\u9760\u6027\u3001\u7be1\u6539\u68c0\u6d4b\u548c\u4f2a\u968f\u673a\u6027\u3002\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u5efa\u7acb\u9c81\u68d2\u6027\u9608\u503c\uff0c\u5e76\u6784\u9020\u8fbe\u5230\u8be5\u9608\u503c\u7684\u7ebf\u6027\u65f6\u95f4\u7f16\u7801\u65b9\u6848\u3002", "result": "\u5efa\u7acb\u4e86\u5bc6\u7801\u6c34\u5370\u9c81\u68d2\u6027\u7684\u7cbe\u786e\u6781\u9650\uff1a\u4e8c\u8fdb\u5236\u8f93\u51fa\u6700\u591a\u5bb9\u5fcd50%\u6bd4\u7279\u4fee\u6539\uff0cq\u8fdb\u5236\u8f93\u51fa\u6700\u591a\u5bb9\u5fcd(1-1/q)\u7b26\u53f7\u4fee\u6539\u3002\u6784\u9020\u4e86\u63a5\u8fd1\u8be5\u6781\u9650\u7684\u5b9e\u7528\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u9608\u503c\u5728\u5b9e\u8df5\u4e2d\u53ef\u8fbe\u3002", "conclusion": "\u5b8c\u6574\u523b\u753b\u4e86\u9c81\u68d2\u6c34\u5370\u7684\u7406\u8bba\u6781\u9650\uff0c\u63d0\u4f9b\u4e86\u8fbe\u5230\u8be5\u6781\u9650\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6781\u9650\u5728\u5b9e\u9645\u6c34\u5370\u7cfb\u7edf\u4e2d\u5df2\u7ecf\u8fbe\u5230\uff0c\u4e3a\u6c34\u5370\u6280\u672f\u7684\u8bbe\u8ba1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2509.11258", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.11258", "abs": "https://arxiv.org/abs/2509.11258", "authors": ["Regan Meloche", "Durga Sivakumar", "Amal A. Anda", "Sofana Alfuhaid", "Daniel Amyot", "Luigi Logrippo", "John Mylopoulos"], "title": "A Web-Based Environment for the Specification and Generation of Smart Legal Contracts", "comment": "12 pages, 5 figures, 2 tables, conference", "summary": "Monitoring the compliance of contract performance against legal obligations\nis important in order to detect violations, ideally, as soon as they occur.\nSuch monitoring can nowadays be achieved through the use of smart contracts,\nwhich provide protection against tampering as well as some level of automation\nin handling violations. However, there exists a large gap between natural\nlanguage contracts and smart contract implementations. This paper introduces a\nWeb-based environment that partly fills that gap by supporting the\nuser-assisted refinement of Symboleo specifications corresponding to legal\ncontract templates, followed by the automated generation of monitoring smart\ncontracts deployable on the Hyperledger Fabric platform. This environment,\nillustrated using a sample contract from the transactive energy domain, shows\nmuch potential in accelerating the development of smart contracts in a legal\ncompliance context.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eWeb\u7684\u73af\u5883\uff0c\u901a\u8fc7\u652f\u6301\u7528\u6237\u8f85\u52a9\u7cbe\u5316Symboleo\u89c4\u8303\u548c\u81ea\u52a8\u751f\u6210\u76d1\u63a7\u667a\u80fd\u5408\u7ea6\uff0c\u6765\u7f29\u5c0f\u81ea\u7136\u8bed\u8a00\u5408\u540c\u4e0e\u667a\u80fd\u5408\u7ea6\u5b9e\u73b0\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u76d1\u63a7\u5408\u540c\u6267\u884c\u662f\u53d1\u73b0\u8fdd\u7ea6\u884c\u4e3a\u7684\u5173\u952e\uff0c\u667a\u80fd\u5408\u7ea6\u63d0\u4f9b\u4e86\u9632\u7be1\u6539\u548c\u81ea\u52a8\u5316\u5904\u7406\u7684\u80fd\u529b\uff0c\u4f46\u81ea\u7136\u8bed\u8a00\u5408\u540c\u4e0e\u667a\u80fd\u5408\u7ea6\u5b9e\u73b0\u4e4b\u95f4\u5b58\u5728\u8f83\u5927\u5dee\u8ddd\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2aWeb\u73af\u5883\uff0c\u652f\u6301\u7528\u6237\u8f85\u52a9\u7cbe\u5316Symboleo\u89c4\u8303\uff08\u5bf9\u5e94\u6cd5\u5f8b\u5408\u540c\u6a21\u677f\uff09\uff0c\u7136\u540e\u81ea\u52a8\u751f\u6210\u53ef\u5728Hyperledger Fabric\u5e73\u53f0\u90e8\u7f72\u7684\u76d1\u63a7\u667a\u80fd\u5408\u7ea6\u3002", "result": "\u901a\u8fc7\u4ea4\u4e92\u5f0f\u80fd\u6e90\u9886\u57df\u7684\u6837\u672c\u5408\u540c\u8fdb\u884c\u6f14\u793a\uff0c\u8bc1\u660e\u8be5\u73af\u5883\u5728\u52a0\u901f\u6cd5\u5f8b\u9075\u5faa\u4e0a\u4e0b\u6587\u4e2d\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u65b9\u9762\u5177\u6709\u5f88\u5927\u6f5c\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7f29\u5c0f\u81ea\u7136\u8bed\u8a00\u5408\u540c\u4e0e\u667a\u80fd\u5408\u7ea6\u5b9e\u73b0\u4e4b\u95f4\u7684\u5dee\u8ddd\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u534f\u52a9\u5f0f\u7cbe\u5316\u548c\u81ea\u52a8\u751f\u6210\u6280\u672f\uff0c\u4fc3\u8fdb\u4e86\u6cd5\u5f8b\u5408\u540c\u76d1\u63a7\u7684\u81ea\u52a8\u5316\u8fc1\u79fb\u3002"}}
{"id": "2509.10932", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10932", "abs": "https://arxiv.org/abs/2509.10932", "authors": ["Seongho Joo", "Hyukhun Koh", "Kyomin Jung"], "title": "Public Data Assisted Differentially Private In-Context Learning", "comment": "EMNLP 2025 Findings", "summary": "In-context learning (ICL) in Large Language Models (LLMs) has shown\nremarkable performance across various tasks without requiring fine-tuning.\nHowever, recent studies have highlighted the risk of private data leakage\nthrough the prompt in ICL, especially when LLMs are exposed to malicious\nattacks. While differential privacy (DP) provides strong privacy guarantees, it\noften significantly reduces the utility of in-context learning (ICL). To\naddress this challenge, we incorporate task-related public data into the ICL\nframework while maintaining the DP guarantee. Based on this approach, we\npropose a private in-context learning algorithm that effectively balances\nprivacy protection and model utility. Through experiments, we demonstrate that\nour approach significantly improves the utility of private ICL with the\nassistance of public data. Additionally, we show that our method is robust\nagainst membership inference attacks, demonstrating empirical privacy\nprotection.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u4efb\u52a1\u76f8\u5173\u516c\u5171\u6570\u636e\u5728\u4fdd\u6301\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u9ad8\u4e86\u79c1\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u6548\u679c\uff0c\u540c\u65f6\u5177\u6709\u5f3a\u58c1\u5792\u6210\u5458\u63a8\u65ad\u653b\u51fb\u7684\u80fd\u529b", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u5b58\u5728\u79c1\u6709\u6570\u636e\u6cc4\u6f0f\u98ce\u9669\uff0c\u800c\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u65b9\u6848\u5f80\u5f80\u4f1a\u5bfc\u81f4\u6a21\u578b\u6548\u7528\u663e\u8457\u4e0b\u964d", "method": "\u5c06\u4efb\u52a1\u76f8\u5173\u516c\u5171\u6570\u636e\u6574\u5408\u5230\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u5728\u7ef4\u6301\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u7684\u540c\u65f6\u8bbe\u8ba1\u79c1\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u7b97\u6cd5", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u516c\u5171\u6570\u636e\u7684\u534f\u52a9\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u79c1\u6709ICL\u7684\u6548\u7528\uff0c\u5e76\u5177\u6709\u5f3a\u58c1\u5792\u6210\u5458\u63a8\u65ad\u653b\u51fb\u7684\u80fd\u529b", "conclusion": "\u901a\u8fc7\u5229\u7528\u516c\u5171\u6570\u636e\u6765\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u548c\u6a21\u578b\u6548\u7528\u662f\u53ef\u884c\u7684\uff0c\u8be5\u65b9\u6cd5\u4e3a\u5b89\u5168\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.10581", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10581", "abs": "https://arxiv.org/abs/2509.10581", "authors": ["Prokash Barman", "Ratul Chowdhury", "Banani Saha"], "title": "Multi-channel secure communication framework for wireless IoT (MCSC-WoT): enhancing security in Internet of Things", "comment": null, "summary": "In modern smart systems, the convergence of the Internet of Things (IoT) and\nWireless of Things (WoT) have been revolutionized by offering a broad level of\nwireless connectivity and communication among various devices. Hitherto, this\ngreater interconnectivity poses important security problems, including the\nquestion of how to securely interconnect different networks, preserve secure\ncommunication channels, and maintain data integrity. However, the traditional\ncryptographic method and frequency hopping technique, although they provide\nsome protection, are not sufficient to defend against Man-In-The-Middle,\njamming, and replay attacks. In addition, synchronization issues in\nmulti-channel communication systems result in increased latency and energy\nconsumption, which make them unsuitable for resource-constrained IoT and WoT\ndevices. This work presents the Multi-Channel Secure Communication (MCSC)\nframework, which integrates advanced cryptographic protocols with dynamic\nchannel-hopping strategies to enhance security with reduced synchronization\noverhead. The MCSC framework maximizes the critical performance metrics, such\nas packet delivery ratio, latency, throughput, and energy efficiency, and\nfulfills the specific requirements of the IoT and WoT networks. A comprehensive\ncomparison of MCSC with well-established methods, including Frequency Hop\nSpread Spectrum, single channel Advanced Encryption Standard, and various\nElliptic Curve Cryptography-based schemes, indicates that MCSC has lower error\nrates and is more resilient to a wider range of cyber attacks. The efficiency\nof the proposed solution to secure IoT and WoT networks without compromising\nthe operational performance is validated under various interference conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86MCSC\u6846\u67b6\uff0c\u7ed3\u5408\u52a0\u5bc6\u534f\u8bae\u548c\u52a8\u6001\u4fe1\u9053\u8df3\u53d8\u7b56\u7565\uff0c\u4e3aIoT/WoT\u7f51\u7edc\u63d0\u4f9b\u589e\u5f3a\u7684\u5b89\u5168\u6027\u548c\u964d\u4f4e\u7684\u540c\u6b65\u5f00\u9500\u3002", "motivation": "\u4f20\u7edf\u52a0\u5bc6\u65b9\u6cd5\u548c\u8df3\u9891\u6280\u672f\u4e0d\u8db3\u4ee5\u9632\u5fa1\u4e2d\u95f4\u4eba\u3001\u5e72\u6270\u548c\u91cd\u653e\u653b\u51fb\uff0c\u4e14\u591a\u4fe1\u9053\u901a\u4fe1\u7cfb\u7edf\u7684\u540c\u6b65\u95ee\u9898\u5bfc\u81f4\u5ef6\u8fdf\u548c\u80fd\u8017\u589e\u52a0\uff0c\u4e0d\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684IoT/WoT\u8bbe\u5907\u3002", "method": "\u5f00\u53d1\u4e86\u591a\u4fe1\u9053\u5b89\u5168\u901a\u4fe1(MCSC)\u6846\u67b6\uff0c\u96c6\u6210\u5148\u8fdb\u52a0\u5bc6\u534f\u8bae\u548c\u52a8\u6001\u4fe1\u9053\u8df3\u53d8\u7b56\u7565\u3002", "result": "MCSC\u5728\u5305\u4f20\u8f93\u7387\u3001\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u548c\u80fd\u6548\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u6bd4FHSS\u3001\u5355\u4fe1\u9053AES\u548cECC\u65b9\u6848\u5177\u6709\u66f4\u4f4e\u9519\u8bef\u7387\u548c\u66f4\u5f3a\u6297\u653b\u51fb\u80fd\u529b\u3002", "conclusion": "MCSC\u6846\u67b6\u80fd\u6709\u6548\u4fdd\u62a4IoT/WoT\u7f51\u7edc\u5b89\u5168\uff0c\u4e14\u4e0d\u5f71\u54cd\u64cd\u4f5c\u6027\u80fd\uff0c\u5728\u5404\u79cd\u5e72\u6270\u6761\u4ef6\u4e0b\u9a8c\u8bc1\u4e86\u5176\u6548\u7387\u3002"}}
{"id": "2509.11312", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11312", "abs": "https://arxiv.org/abs/2509.11312", "authors": ["Wenchao Gu", "Yupan Chen", "Yanlin Wang", "Hongyu Zhang", "Cuiyun Gao", "Michael R. Lyu"], "title": "Weakly Supervised Vulnerability Localization via Multiple Instance Learning", "comment": null, "summary": "Software vulnerability detection has emerged as a significant concern in the\nfield of software security recently, capturing the attention of numerous\nresearchers and developers. Most previous approaches focus on coarse-grained\nvulnerability detection, such as at the function or file level. However, the\ndevelopers would still encounter the challenge of manually inspecting a large\nvolume of code inside the vulnerable function to identify the specific\nvulnerable statements for modification, indicating the importance of\nvulnerability localization. Training the model for vulnerability localization\nusually requires ground-truth labels at the statement-level, and labeling\nvulnerable statements demands expert knowledge, which incurs high costs. Hence,\nthe demand for an approach that eliminates the need for additional labeling at\nthe statement-level is on the rise. To tackle this problem, we propose a novel\napproach called WAVES for WeAkly supervised Vulnerability Localization via\nmultiplE inStance learning, which does not need the additional statement-level\nlabels during the training. WAVES has the capability to determine whether a\nfunction is vulnerable (i.e., vulnerability detection) and pinpoint the\nvulnerable statements (i.e., vulnerability localization). Specifically,\ninspired by the concept of multiple instance learning, WAVES converts the\nground-truth label at the function-level into pseudo labels for individual\nstatements, eliminating the need for additional statement-level labeling. These\npseudo labels are utilized to train the classifiers for the function-level\nrepresentation vectors. Extensive experimentation on three popular benchmark\ndatasets demonstrates that, in comparison to previous baselines, our approach\nachieves comparable performance in vulnerability detection and state-of-the-art\nperformance in statement-level vulnerability localization.", "AI": {"tldr": "WAVES\u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u793a\u4f8b\u5b66\u4e60\u7684\u5f31\u76d1\u7763\u6f0f\u6d1e\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u65e0\u9700\u8bed\u53e5\u7ea7\u6807\u6ce8\u5373\u53ef\u5b9e\u73b0\u51fd\u6570\u7ea7\u6f0f\u6d1e\u68c0\u6d4b\u548c\u8bed\u53e5\u7ea7\u6f0f\u6d1e\u5b9a\u4f4d", "motivation": "\u4f20\u7edf\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5728\u51fd\u6570\u6216\u6587\u4ef6\u7ea7\u522b\u8fdb\u884c\u7c97\u7c92\u5ea6\u68c0\u6d4b\uff0c\u5f00\u53d1\u8005\u4ecd\u9700\u624b\u52a8\u68c0\u67e5\u5927\u91cf\u4ee3\u7801\u6765\u5b9a\u4f4d\u5177\u4f53\u6f0f\u6d1e\u8bed\u53e5\u3002\u8bed\u53e5\u7ea7\u6807\u6ce8\u9700\u8981\u4e13\u5bb6\u77e5\u8bc6\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u9700\u8981\u65e0\u9700\u989d\u5916\u8bed\u53e5\u7ea7\u6807\u6ce8\u7684\u65b9\u6cd5", "method": "\u91c7\u7528\u591a\u793a\u4f8b\u5b66\u4e60\u601d\u60f3\uff0c\u5c06\u51fd\u6570\u7ea7\u771f\u5b9e\u6807\u7b7e\u8f6c\u6362\u4e3a\u8bed\u53e5\u7ea7\u4f2a\u6807\u7b7e\uff0c\u65e0\u9700\u989d\u5916\u8bed\u53e5\u7ea7\u6807\u6ce8\u3002\u5229\u7528\u8fd9\u4e9b\u4f2a\u6807\u7b7e\u8bad\u7ec3\u51fd\u6570\u7ea7\u8868\u793a\u5411\u91cf\u7684\u5206\u7c7b\u5668", "result": "\u5728\u4e09\u4e2a\u6d41\u884c\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u8fbe\u5230\u53ef\u6bd4\u6027\u80fd\uff0c\u5728\u8bed\u53e5\u7ea7\u6f0f\u6d1e\u5b9a\u4f4d\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd", "conclusion": "WAVES\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u6f0f\u6d1e\u5b9a\u4f4d\u4e2d\u8bed\u53e5\u7ea7\u6807\u6ce8\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5f31\u76d1\u7763\u5b66\u4e60\u5b9e\u73b0\u4e86\u51c6\u786e\u7684\u6f0f\u6d1e\u68c0\u6d4b\u548c\u5b9a\u4f4d"}}
{"id": "2509.10972", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10972", "abs": "https://arxiv.org/abs/2509.10972", "authors": ["Ron Sun"], "title": "Enhancing Computational Cognitive Architectures with LLMs: A Case Study", "comment": null, "summary": "Computational cognitive architectures are broadly scoped models of the human\nmind that combine different psychological functionalities (as well as often\ndifferent computational methods for these different functionalities) into one\nunified framework. They structure them in a psychologically plausible and\nvalidated way. However, such models thus far have only limited computational\ncapabilities, mostly limited by the computational tools and techniques that\nwere adopted. More recently, LLMs have proved to be more capable\ncomputationally than any other tools. Thus, in order to deal with both\nreal-world complexity and psychological realism at the same time, incorporating\nLLMs into cognitive architectures naturally becomes an important task. In the\npresent article, a synergistic combination of the Clarion cognitive\narchitecture and LLMs is discussed as a case study. The implicit-explicit\ndichotomy that is fundamental to Clarion is leveraged for a seamless\nintegration of Clarion and LLMs. As a result, computational power of LLMs is\ncombined with psychological nicety of Clarion.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7ec4\u5408\u5230Clarion\u8ba4\u77e5\u67b6\u6784\u4e2d\u7684\u65b9\u6cd5\uff0c\u4ee5\u7ed3\u5408LLMs\u7684\u8ba1\u7b97\u80fd\u529b\u548c\u8ba4\u77e5\u67b6\u6784\u7684\u5fc3\u7406\u5b9e\u9645\u6027\u3002", "motivation": "\u8ba4\u77e5\u8ba1\u7b97\u67b6\u6784\u867d\u7136\u7ed3\u6784\u5316\u4e86\u5fc3\u7406\u529f\u80fd\uff0c\u4f46\u8ba1\u7b97\u80fd\u529b\u6709\u9650\uff0c\u800cLLMs\u663e\u793a\u51fa\u4f18\u5f02\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u5c06\u4e24\u8005\u7ed3\u5408\u6765\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u7684\u590d\u6742\u6027\u548c\u5fc3\u7406\u5b9e\u9645\u6027\u3002", "method": "\u4f7f\u7528Clarion\u8ba4\u77e5\u67b6\u6784\u7684\u9690\u5f0f-\u663e\u5f0f\u4e8c\u5206\u6cd5\u4f5c\u4e3a\u57fa\u7840\uff0c\u5b9e\u73b0Clarion\u4e0eLLMs\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u5c06LLMs\u7684\u8ba1\u7b97\u80fd\u529b\u4e0eClarion\u7684\u5fc3\u7406\u7cbe\u7ec6\u6027\u76f8\u7ed3\u5408\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86Clarion\u8ba4\u77e5\u67b6\u6784\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u534f\u540c\u7ec4\u5408\uff0c\u4e3a\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u6027\u548c\u4fdd\u6301\u5fc3\u7406\u5b9e\u9645\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u5c06LLMs\u96c6\u6210\u5230\u8ba4\u77e5\u67b6\u6784\u4e2d\uff0c\u53ef\u4ee5\u540c\u65f6\u6ee1\u8db3\u8ba1\u7b97\u80fd\u529b\u548c\u5fc3\u7406\u5b9e\u9645\u6027\u7684\u8981\u6c42\uff0c\u4e3a\u8ba4\u77e5\u8ba1\u7b97\u67b6\u6784\u7684\u53d1\u5c55\u5f00\u542f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2509.10655", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.10655", "abs": "https://arxiv.org/abs/2509.10655", "authors": ["Charankumar Akiri", "Harrison Simpson", "Kshitiz Aryal", "Aarav Khanna", "Maanak Gupta"], "title": "Safety and Security Analysis of Large Language Models: Risk Profile and Harm Potential", "comment": null, "summary": "While the widespread deployment of Large Language Models (LLMs) holds great\npotential for society, their vulnerabilities to adversarial manipulation and\nexploitation can pose serious safety, security, and ethical risks. As new\nthreats continue to emerge, it becomes critically necessary to assess the\nlandscape of LLMs' safety and security against evolving adversarial prompt\ntechniques. To understand the behavior of LLMs, this research provides an\nempirical analysis and risk profile of nine prominent LLMs, Claude Opus 4,\nDeepSeek V3 (both open-source and online), Gemini 2.5 Flash, GPT-4o, Grok 3,\nLlama 4 Scout, Mistral 7B, and Qwen 3 1.7B, against 24 different security and\nsafety categories. These LLMs are evaluated on their ability to produce harmful\nresponses for adversarially crafted prompts (dataset has been made public) for\na broad range of safety and security topics, such as promotion of violent\ncriminal behavior, promotion of non-violent criminal activity, societal harms\nrelated to safety, illegal sexual content, dangerous code generation, and\ncybersecurity threats beyond code. Our study introduces the Risk Severity Index\n(RSI), an agile and scalable evaluation score, to quantify and compare the\nsecurity posture and creating a risk profile of LLMs. As the LLM development\nlandscape progresses, the RSI is intended to be a valuable metric for comparing\nthe risks of LLMs across evolving threats. This research finds widespread\nvulnerabilities in the safety filters of the LLMs tested and highlights the\nurgent need for stronger alignment, responsible deployment practices, and model\ngovernance, particularly for open-access and rapidly iterated models.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u4e86\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u572824\u4e2a\u5b89\u5168\u98ce\u9669\u7c7b\u522b\u4e0a\u7684\u5f31\u70b9\uff0c\u53d1\u73b0\u5b83\u4eec\u5b58\u5728\u666e\u904d\u7684\u5bf9\u6076\u610f\u63d0\u793a\u7684\u6545\u969c\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u98ce\u9669\u4e25\u91cd\u6027\u6307\u6570\u6765\u8bc4\u4f30\u6a21\u578b\u5b89\u5168\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u666e\u904d\u90e8\u7f72\uff0c\u5b83\u4eec\u53d7\u5230\u6076\u610f\u64cd\u7eb5\u548c\u5229\u7528\u7684\u6f0f\u6d1e\u53ef\u80fd\u5e26\u6765\u4e25\u91cd\u7684\u5b89\u5168\u3001\u5b89\u5168\u548c\u4f26\u7406\u98ce\u9669\uff0c\u9700\u8981\u5bf9\u6b63\u5728\u53d1\u5c55\u7684\u5bf9\u6297\u63d0\u793a\u6280\u672f\u8fdb\u884c\u98ce\u9669\u8bc4\u4f30\u3002", "method": "\u7814\u7a76\u5bf99\u6b3e\u4e3b\u6d41LLM\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u5206\u6790\uff0c\u6d4b\u8bd5\u5b83\u4eec\u572824\u4e2a\u5b89\u5168\u98ce\u9669\u7c7b\u522b\u4e0a\u5bf9\u6076\u610f\u63d0\u793a\u7684\u5fcd\u53d7\u80fd\u529b\uff0c\u5305\u62ec\u66b4\u529b\u72af\u7f6a\u3001\u975e\u66b4\u529b\u72af\u7f6a\u3001\u793e\u4f1a\u5371\u5bb3\u3001\u975e\u6cd5\u6027\u5185\u5bb9\u7b49\uff0c\u5e76\u521b\u5efa\u4e86\u98ce\u9669\u4e25\u91cd\u6027\u6307\u6570(RSI)\u6765\u91cf\u5316\u6a21\u578b\u5b89\u5168\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u90fd\u5b58\u5728\u666e\u904d\u7684\u5b89\u5168\u8fc7\u6ee4\u5668\u6f0f\u6d1e\uff0c\u80fd\u591f\u88ab\u6076\u610f\u63d0\u793a\u64cd\u7eb5\u4ea7\u751f\u6709\u5bb3\u56de\u5e94\uff0c\u663e\u793a\u4e86\u5f53\u524dLLM\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u7684\u4e0d\u8db3\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u52a0\u5f3a\u6a21\u578b\u5bf9\u9f50\u3001\u8d1f\u8d23\u4efb\u90e8\u7f72\u5b9e\u8df5\u548c\u6a21\u578b\u6cbb\u7406\u7684\u7d27\u8feb\u6027\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u5f00\u653e\u8bbf\u95ee\u548c\u5feb\u901f\u8fed\u4ee3\u7684\u6a21\u578b\uff0c\u5e76\u63d0\u51faRSI\u6307\u6570\u4f5c\u4e3a\u8bc4\u4f30LLM\u98ce\u9669\u6c34\u5e73\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2509.11446", "categories": ["cs.SE", "D.2.0; D.2.1; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.11446", "abs": "https://arxiv.org/abs/2509.11446", "authors": ["Mohammad Amin Zadenoori", "Jacek D\u0105browski", "Waad Alhoshan", "Liping Zhao", "Alessio Ferrari"], "title": "Large Language Models (LLMs) for Requirements Engineering (RE): A Systematic Literature Review", "comment": null, "summary": "Large Language Models (LLMs) are finding applications in numerous domains,\nand Requirements Engineering (RE) is increasingly benefiting from their\ncapabilities to assist with complex, language-intensive tasks. This paper\npresents a systematic literature review of 74 primary studies published between\n2023 and 2024, examining how LLMs are being applied in RE. The study\ncategorizes the literature according to several dimensions, including\npublication trends, RE activities, prompting strategies, and evaluation\nmethods. Our findings indicate notable patterns, among which we observe\nsubstantial differences compared to previous works leveraging standard Natural\nLanguage Processing (NLP) techniques. Most of the studies focus on using LLMs\nfor requirements elicitation and validation, rather than defect detection and\nclassification, which were dominant in the past. Researchers have also\nbroadened their focus and addressed novel tasks, e.g., test generation,\nexploring the integration of RE with other software engineering (SE)\ndisciplines. Although requirements specifications remain the primary focus,\nother artifacts are increasingly considered, including issues from issue\ntracking systems, regulations, and technical manuals. The studies mostly rely\non GPT-based models, and often use Zero-shot or Few-shot prompting. They are\nusually evaluated in controlled environments, with limited use in industry\nsettings and limited integration in complex workflows. Our study outlines\nimportant future directions, such as leveraging the potential to expand the\ninfluence of RE in SE, exploring less-studied tasks, improving prompting\nmethods, and testing in real-world environments. Our contribution also helps\nresearchers and practitioners use LLMs more effectively in RE, by providing a\nlist of identified tools leveraging LLMs for RE, as well as datasets.", "AI": {"tldr": "\u672c\u6587\u5bf92023-2024\u5e74\u95f474\u9879\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u3001\u8d8b\u52bf\u548c\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u6c42\u5de5\u7a0b\u4f5c\u4e3a\u8bed\u8a00\u5bc6\u96c6\u578b\u4efb\u52a1\u4e5f\u5f00\u59cb\u53d7\u76ca\u4e8eLLM\u6280\u672f\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u5f53\u524d\u7814\u7a76\u73b0\u72b6\u548c\u53d1\u5c55\u8d8b\u52bf\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u679074\u7bc72023-2024\u5e74\u7684\u4e3b\u8981\u7814\u7a76\uff0c\u4ece\u53d1\u8868\u8d8b\u52bf\u3001RE\u6d3b\u52a8\u3001\u63d0\u793a\u7b56\u7565\u3001\u8bc4\u4f30\u65b9\u6cd5\u7b49\u591a\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u5206\u7c7b\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u4e3b\u8981\u96c6\u4e2d\u5728\u9700\u6c42\u83b7\u53d6\u548c\u9a8c\u8bc1\uff0c\u800c\u975e\u4f20\u7edf\u7684\u7f3a\u9677\u68c0\u6d4b\uff1b\u4e3b\u8981\u4f7f\u7528GPT\u6a21\u578b\u548c\u96f6\u6837\u672c/\u5c11\u6837\u672c\u63d0\u793a\uff1b\u7814\u7a76\u591a\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u8fdb\u884c\uff0c\u5de5\u4e1a\u5e94\u7528\u6709\u9650\u3002", "conclusion": "\u7814\u7a76\u6307\u51fa\u4e86\u672a\u6765\u91cd\u8981\u65b9\u5411\uff1a\u6269\u5927RE\u5728SE\u4e2d\u7684\u5f71\u54cd\u529b\u3001\u63a2\u7d22\u8f83\u5c11\u7814\u7a76\u7684\u4efb\u52a1\u3001\u6539\u8fdb\u63d0\u793a\u65b9\u6cd5\u3001\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u6d4b\u8bd5\uff0c\u5e76\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u76f8\u5173\u5de5\u5177\u548c\u6570\u636e\u96c6\u5217\u8868\u3002"}}
{"id": "2509.11026", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.11026", "abs": "https://arxiv.org/abs/2509.11026", "authors": ["Ziang Li", "Manasi Ganti", "Zixian Ma", "Helena Vasconcelos", "Qijia He", "Ranjay Krishna"], "title": "Rethinking Human Preference Evaluation of LLM Rationales", "comment": "Published in the XLLM-Reason-Plan Workshop on the Application of LLM\n  Explainability to Reasoning and Planning at COLM 2025", "summary": "Large language models (LLMs) often generate natural language rationales --\nfree-form explanations that help improve performance on complex reasoning tasks\nand enhance interpretability for human users. However, evaluating these\nrationales remains challenging. While recent work has relied on binary\npreference judgments from humans or LLM judges, such evaluations are often\nopaque and coarse-grained, offering limited insight into what makes one\nrationale better than another. In this work, we rethink preference evaluation\nfor LLM-generated rationales by asking: (1) What attributes define good\nrationales? (2) Can human preferences be explained by these attributes? (3) Can\nattribute-based evaluation overcome the limitations of binary comparisons? We\nidentify a set of key rationale attributes from prior literature and assess\nthem using automatic metrics, LLM judgments, and human annotations. We then\nanalyze two standard human preference datasets MT Bench and Chatbot Arena using\nSHAP to identify which attributes best explain human preference outcomes.\nFinally, we re-evaluate model-generated rationales using attribute-specific ELO\nscores, revealing more nuanced model comparisons and insights. Our findings\nsuggest that fine-grained attribute evaluations can better characterize\nrationale quality and guide future research toward more interpretable and\nreliable evaluation practices.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u601d\u8003LLM\u751f\u6210rationale\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63d0\u51fa\u57fa\u4e8e\u591a\u5c5e\u6027\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6765\u66ff\u4ee3\u4f20\u7edf\u7684\u4e8c\u5143\u504f\u597d\u5224\u65ad\uff0c\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u5c5e\u6027\u3001\u5206\u6790\u4eba\u7c7b\u504f\u597d\u4e0e\u5c5e\u6027\u7684\u5173\u7cfb\uff0c\u5e76\u5f00\u53d1\u5c5e\u6027\u7279\u5b9a\u7684ELO\u8bc4\u5206\u7cfb\u7edf\u6765\u63d0\u4f9b\u66f4\u7ec6\u81f4\u7684\u6a21\u578b\u6bd4\u8f83\u3002", "motivation": "\u5f53\u524dLLM\u751f\u6210rationale\u7684\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u4eba\u7c7b\u6216LLM\u7684\u4e8c\u5143\u504f\u597d\u5224\u65ad\uff0c\u8fd9\u79cd\u65b9\u6cd5\u8fc7\u4e8e\u7c97\u7cd9\u4e14\u4e0d\u900f\u660e\uff0c\u65e0\u6cd5\u63d0\u4f9brationale\u4f18\u52a3\u7684\u5177\u4f53\u539f\u56e0\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "1) \u4ece\u6587\u732e\u4e2d\u8bc6\u522b\u5173\u952erationale\u5c5e\u6027\uff1b2) \u4f7f\u7528\u81ea\u52a8\u6307\u6807\u3001LLM\u5224\u65ad\u548c\u4eba\u5de5\u6807\u6ce8\u8bc4\u4f30\u8fd9\u4e9b\u5c5e\u6027\uff1b3) \u7528SHAP\u5206\u6790MT Bench\u548cChatbot Arena\u6570\u636e\u96c6\uff0c\u786e\u5b9a\u6700\u80fd\u89e3\u91ca\u4eba\u7c7b\u504f\u597d\u7684\u5c5e\u6027\uff1b4) \u5f00\u53d1\u5c5e\u6027\u7279\u5b9a\u7684ELO\u8bc4\u5206\u7cfb\u7edf\u91cd\u65b0\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7ec6\u7c92\u5ea6\u5c5e\u6027\u8bc4\u4f30\u80fd\u66f4\u597d\u5730\u8868\u5f81rationale\u8d28\u91cf\uff0c\u5c5e\u6027\u7279\u5b9a\u7684ELO\u8bc4\u5206\u63ed\u793a\u4e86\u66f4\u7ec6\u81f4\u7684\u6a21\u578b\u6bd4\u8f83\u7ed3\u679c\uff0c\u4e3arationale\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u4fe1\u606f\u3002", "conclusion": "\u57fa\u4e8e\u5c5e\u6027\u7684\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u80fd\u591f\u514b\u670d\u4e8c\u5143\u6bd4\u8f83\u7684\u5c40\u9650\u6027\uff0c\u4e3aLLM rationale\u8bc4\u4f30\u63d0\u4f9b\u66f4\u53ef\u89e3\u91ca\u548c\u53ef\u9760\u7684\u5b9e\u8df5\u6307\u5bfc\uff0c\u63a8\u52a8\u672a\u6765\u7814\u7a76\u5411\u66f4\u900f\u660e\u7684\u8bc4\u4f30\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2509.10682", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10682", "abs": "https://arxiv.org/abs/2509.10682", "authors": ["Vitor Hugo Galhardo Moia", "Igor Jochem Sanz", "Gabriel Antonio Fontes Rebello", "Rodrigo Duarte de Meneses", "Briland Hitaj", "Ulf Lindqvist"], "title": "LLM in the Middle: A Systematic Review of Threats and Mitigations to Real-World LLM-based Systems", "comment": "37 pages, 8 figures, 13 tables", "summary": "The success and wide adoption of generative AI (GenAI), particularly large\nlanguage models (LLMs), has attracted the attention of cybercriminals seeking\nto abuse models, steal sensitive data, or disrupt services. Moreover, providing\nsecurity to LLM-based systems is a great challenge, as both traditional threats\nto software applications and threats targeting LLMs and their integration must\nbe mitigated. In this survey, we shed light on security and privacy concerns of\nsuch LLM-based systems by performing a systematic review and comprehensive\ncategorization of threats and defensive strategies considering the entire\nsoftware and LLM life cycles. We analyze real-world scenarios with distinct\ncharacteristics of LLM usage, spanning from development to operation. In\naddition, threats are classified according to their severity level and to which\nscenarios they pertain, facilitating the identification of the most relevant\nthreats. Recommended defense strategies are systematically categorized and\nmapped to the corresponding life cycle phase and possible attack strategies\nthey attenuate. This work paves the way for consumers and vendors to understand\nand efficiently mitigate risks during integration of LLMs in their respective\nsolutions or organizations. It also enables the research community to benefit\nfrom the discussion of open challenges and edge cases that may hinder the\nsecure and privacy-preserving adoption of LLM-based systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u8c03\u67e5\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7cfb\u7edf\u7684\u5b89\u5168\u9690\u79c1\u5a01\u80c1\uff0c\u5bf9\u5a01\u80c1\u548c\u9632\u5fa1\u7b56\u7565\u8fdb\u884c\u4e86\u5168\u9762\u5206\u7c7b\uff0c\u6db5\u76d6\u6574\u4e2a\u8f6f\u4ef6\u548cLLM\u751f\u547d\u5468\u671f\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7279\u522b\u662fLLMs\u7684\u6210\u529f\u5e94\u7528\u5438\u5f15\u4e86\u7f51\u7edc\u72af\u7f6a\u5206\u5b50\u7684\u5173\u6ce8\uff0c\u4ed6\u4eec\u8bd5\u56fe\u6ee5\u7528\u6a21\u578b\u3001\u7a83\u53d6\u654f\u611f\u6570\u636e\u6216\u7834\u574f\u670d\u52a1\u3002\u4e3aLLM\u7cfb\u7edf\u63d0\u4f9b\u5b89\u5168\u4fdd\u969c\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u9700\u8981\u540c\u65f6\u5e94\u5bf9\u4f20\u7edf\u8f6f\u4ef6\u5a01\u80c1\u548c\u9488\u5bf9LLMs\u7684\u65b0\u5a01\u80c1\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u56de\u987e\u548c\u5168\u9762\u5206\u7c7b\u65b9\u6cd5\uff0c\u5206\u6790\u771f\u5b9e\u573a\u666f\u4e2dLLM\u4f7f\u7528\u7684\u4e0d\u540c\u7279\u5f81\uff0c\u4ece\u5f00\u53d1\u5230\u8fd0\u8425\u5168\u8fc7\u7a0b\u3002\u5a01\u80c1\u6309\u4e25\u91cd\u7a0b\u5ea6\u548c\u9002\u7528\u573a\u666f\u5206\u7c7b\uff0c\u9632\u5fa1\u7b56\u7565\u6309\u751f\u547d\u5468\u671f\u9636\u6bb5\u548c\u5bf9\u5e94\u653b\u51fb\u7b56\u7565\u8fdb\u884c\u7cfb\u7edf\u5206\u7c7b\u6620\u5c04\u3002", "result": "\u5efa\u7acb\u4e86\u5b8c\u6574\u7684LLM\u7cfb\u7edf\u5b89\u5168\u5a01\u80c1\u5206\u7c7b\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u6700\u76f8\u5173\u7684\u5a01\u80c1\uff0c\u5e76\u63d0\u4f9b\u4e86\u9488\u5bf9\u6027\u7684\u9632\u5fa1\u7b56\u7565\u5206\u7c7b\uff0c\u4e3a\u4e0d\u540c\u751f\u547d\u5468\u671f\u9636\u6bb5\u7684\u5a01\u80c1\u63d0\u4f9b\u4e86\u7f13\u89e3\u65b9\u6848\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6d88\u8d39\u8005\u548c\u4f9b\u5e94\u5546\u7406\u89e3\u5e76\u6709\u6548\u7f13\u89e3LLM\u96c6\u6210\u98ce\u9669\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4f7f\u7814\u7a76\u793e\u533a\u80fd\u591f\u4ece\u5f00\u653e\u6311\u6218\u548c\u8fb9\u7f18\u6848\u4f8b\u7684\u8ba8\u8bba\u4e2d\u53d7\u76ca\uff0c\u4fc3\u8fdbLLM\u7cfb\u7edf\u7684\u5b89\u5168\u9690\u79c1\u4fdd\u62a4\u91c7\u7528\u3002"}}
{"id": "2509.11523", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.11523", "abs": "https://arxiv.org/abs/2509.11523", "authors": ["Ziliang Wang", "Ge Li", "Jia Li", "Hao Zhu", "Zhi Jin"], "title": "VulAgent: Hypothesis-Validation based Multi-Agent Vulnerability Detection", "comment": null, "summary": "The application of language models to project-level vulnerability detection\nremains challenging, owing to the dual requirement of accurately localizing\nsecurity-sensitive code and correctly correlating and reasoning over complex\nprogram context. We present VulAgent, a multi-agent vulnerability detection\nframework based on hypothesis validation. Our design is inspired by how human\nauditors review code: when noticing a sensitive operation, they form a\nhypothesis about a possible vulnerability, consider potential trigger paths,\nand then verify the hypothesis against the surrounding context. VulAgent\nimplements a semantics-sensitive, multi-view detection pipeline: specialized\nagents, each aligned to a specific analysis perspective (e.g., memory,\nauthorization), collaboratively surface and precisely localize sensitive code\nsites with higher coverage. Building on this, VulAgent adopts a\nhypothesis-validation paradigm: for each vulnerability report, it builds\nhypothesis conditions and a trigger path, steering the LLM to target the\nrelevant program context and defensive checks during verification, which\nreduces false positives. On average across the two datasets, VulAgent improves\noverall accuracy by 6.6%, increases the correct identification rate of\nvulnerable--fixed code pairs by up to 450% (246% on average), and reduces the\nfalse positive rate by about 36% compared with state-of-the-art LLM-based\nbaselines.", "AI": {"tldr": "VulAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u5047\u8bbe\u9a8c\u8bc1\u7684\u591a\u667a\u80fd\u4f53\u6f0f\u6d1e\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u4ee3\u7801\u5ba1\u8ba1\u8fc7\u7a0b\uff0c\u4f7f\u7528\u4e13\u95e8\u5316\u667a\u80fd\u4f53\u4ece\u4e0d\u540c\u5206\u6790\u89c6\u89d2\u534f\u4f5c\u68c0\u6d4b\u6f0f\u6d1e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u964d\u4f4e\u4e86\u8bef\u62a5\u7387\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u5728\u9879\u76ee\u7ea7\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a\u51c6\u786e\u5b9a\u4f4d\u5b89\u5168\u654f\u611f\u4ee3\u7801\uff0c\u4ee5\u53ca\u6b63\u786e\u5173\u8054\u548c\u63a8\u7406\u590d\u6742\u7a0b\u5e8f\u4e0a\u4e0b\u6587\u3002\u9700\u8981\u6a21\u62df\u4eba\u7c7b\u5ba1\u8ba1\u5458\u7684\u4ee3\u7801\u5ba1\u67e5\u65b9\u5f0f\u6765\u63d0\u9ad8\u68c0\u6d4b\u6548\u679c\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u4e13\u6ce8\u4e8e\u7279\u5b9a\u5206\u6790\u89c6\u89d2\uff08\u5982\u5185\u5b58\u3001\u6388\u6743\u7b49\uff09\uff0c\u901a\u8fc7\u5047\u8bbe\u9a8c\u8bc1\u8303\u5f0f\uff1a\u5148\u5f62\u6210\u6f0f\u6d1e\u5047\u8bbe\u548c\u89e6\u53d1\u8def\u5f84\uff0c\u7136\u540e\u9488\u5bf9\u76f8\u5173\u7a0b\u5e8f\u4e0a\u4e0b\u6587\u548c\u9632\u5fa1\u68c0\u67e5\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u63d0\u9ad8\u6574\u4f53\u51c6\u786e\u73876.6%\uff0c\u6f0f\u6d1e-\u4fee\u590d\u4ee3\u7801\u5bf9\u7684\u6b63\u786e\u8bc6\u522b\u7387\u6700\u9ad8\u63d0\u5347450%\uff08\u5e73\u5747246%\uff09\uff0c\u8bef\u62a5\u7387\u964d\u4f4e\u7ea636%\u3002", "conclusion": "VulAgent\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u5047\u8bbe\u9a8c\u8bc1\u8303\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9879\u76ee\u7ea7\u6f0f\u6d1e\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u5728\u51c6\u786e\u6027\u548c\u8bef\u62a5\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2509.11035", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11035", "abs": "https://arxiv.org/abs/2509.11035", "authors": ["Yu Cui", "Hang Fu", "Haibin Zhang", "Licheng Wang", "Cong Zuo"], "title": "Free-MAD: Consensus-Free Multi-Agent Debate", "comment": null, "summary": "Multi-agent debate (MAD) is an emerging approach to improving the reasoning\ncapabilities of large language models (LLMs). Existing MAD methods rely on\nmultiple rounds of interaction among agents to reach consensus, and the final\noutput is selected by majority voting in the last round. However, this\nconsensus-based design faces several limitations. First, multiple rounds of\ncommunication increases token overhead and limits scalability. Second, due to\nthe inherent conformity of LLMs, agents that initially produce correct\nresponses may be influenced by incorrect ones during the debate process,\ncausing error propagation. Third, majority voting introduces randomness and\nunfairness in the decision-making phase, and can degrade the reasoning\nperformance.\n  To address these issues, we propose \\textsc{Free-MAD}, a novel MAD framework\nthat eliminates the need for consensus among agents. \\textsc{Free-MAD}\nintroduces a novel score-based decision mechanism that evaluates the entire\ndebate trajectory rather than relying on the last round only. This mechanism\ntracks how each agent's reasoning evolves, enabling more accurate and fair\noutcomes. In addition, \\textsc{Free-MAD} reconstructs the debate phase by\nintroducing anti-conformity, a mechanism that enables agents to mitigate\nexcessive influence from the majority. Experiments on eight benchmark datasets\ndemonstrate that \\textsc{Free-MAD} significantly improves reasoning performance\nwhile requiring only a single-round debate and thus reducing token costs. We\nalso show that compared to existing MAD approaches, \\textsc{Free-MAD} exhibits\nimproved robustness in real-world attack scenarios.", "AI": {"tldr": "Free-MAD\u662f\u4e00\u4e2a\u65b0\u7684\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u5206\u6570\u7684\u51b3\u7b56\u673a\u5236\u548c\u53cd\u4ece\u4f17\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5171\u8bc6\u5f0fMAD\u65b9\u6cd5\u7684\u901a\u4fe1\u5f00\u9500\u5927\u3001\u9519\u8bef\u4f20\u64ad\u548c\u6295\u7968\u968f\u673a\u6027\u95ee\u9898\uff0c\u5728\u5355\u8f6e\u8fa9\u8bba\u4e2d\u663e\u8457\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709MAD\u65b9\u6cd5\u4f9d\u8d56\u591a\u8f6e\u4ea4\u4e92\u8fbe\u6210\u5171\u8bc6\u548c\u591a\u6570\u6295\u7968\uff0c\u5b58\u5728\u901a\u4fe1\u5f00\u9500\u5927\u3001\u6b63\u786e\u56de\u7b54\u53ef\u80fd\u88ab\u9519\u8bef\u56de\u7b54\u5f71\u54cd\u5bfc\u81f4\u9519\u8bef\u4f20\u64ad\u3001\u591a\u6570\u6295\u7968\u5f15\u5165\u968f\u673a\u6027\u548c\u4e0d\u516c\u5e73\u6027\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faFree-MAD\u6846\u67b6\uff1a1\uff09\u57fa\u4e8e\u5206\u6570\u7684\u51b3\u7b56\u673a\u5236\uff0c\u8bc4\u4f30\u6574\u4e2a\u8fa9\u8bba\u8f68\u8ff9\u800c\u975e\u4ec5\u6700\u540e\u4e00\u8f6e\uff1b2\uff09\u5f15\u5165\u53cd\u4ece\u4f17\u673a\u5236\uff0c\u51cf\u8f7b\u591a\u6570\u610f\u89c1\u7684\u8fc7\u5ea6\u5f71\u54cd\uff1b3\uff09\u4ec5\u9700\u5355\u8f6e\u8fa9\u8bba\u3002", "result": "\u57288\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cFree-MAD\u663e\u8457\u63d0\u5347\u63a8\u7406\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11token\u6210\u672c\u3002\u76f8\u6bd4\u73b0\u6709MAD\u65b9\u6cd5\uff0c\u5728\u771f\u5b9e\u653b\u51fb\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "Free-MAD\u901a\u8fc7\u6d88\u9664\u667a\u80fd\u4f53\u95f4\u5171\u8bc6\u9700\u6c42\uff0c\u91c7\u7528\u8f68\u8ff9\u8bc4\u4f30\u548c\u53cd\u4ece\u4f17\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfMAD\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u51c6\u786e\u548c\u9c81\u68d2\u7684\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2509.10691", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10691", "abs": "https://arxiv.org/abs/2509.10691", "authors": ["Fardin Jalil Piran", "Zhiling Chen", "Yang Zhang", "Qianyu Zhou", "Jiong Tang", "Farhad Imani"], "title": "Privacy-Preserving Decentralized Federated Learning via Explainable Adaptive Differential Privacy", "comment": "21 pages", "summary": "Decentralized federated learning faces privacy risks because model updates\ncan leak data through inference attacks and membership inference, a concern\nthat grows over many client exchanges. Differential privacy offers principled\nprotection by injecting calibrated noise so confidential information remains\nsecure on resource-limited IoT devices. Yet without transparency, black-box\ntraining cannot track noise already injected by previous clients and rounds,\nwhich forces worst-case additions and harms accuracy. We propose PrivateDFL, an\nexplainable framework that joins hyperdimensional computing with differential\nprivacy and keeps an auditable account of cumulative noise so each client adds\nonly the difference between the required noise and what has already been\naccumulated. We evaluate on MNIST, ISOLET, and UCI-HAR to span image, signal,\nand tabular modalities, and we benchmark against transformer-based and deep\nlearning-based baselines trained centrally with Differentially Private\nStochastic Gradient Descent (DP-SGD) and Renyi Differential Privacy (RDP).\nPrivateDFL delivers higher accuracy, lower latency, and lower energy across IID\nand non-IID partitions while preserving formal (epsilon, delta) guarantees and\noperating without a central server. For example, under non-IID partitions,\nPrivateDFL achieves 24.42% higher accuracy than the Vision Transformer on MNIST\nwhile using about 10x less training time, 76x lower inference latency, and 11x\nless energy, and on ISOLET it exceeds Transformer accuracy by more than 80%\nwith roughly 10x less training time, 40x lower inference latency, and 36x less\ntraining energy. Future work will extend the explainable accounting to\nadversarial clients and adaptive topologies with heterogeneous privacy budgets.", "AI": {"tldr": "\u79c1\u6709\u5316\u5206\u5e03\u5f0f\u8054\u90a6\u5b66\u4e60\u6846\u67b6PrivateDFL\uff0c\u7ed3\u5408\u8d85\u7ef4\u8ba1\u7b97\u548c\u5dee\u5206\u9690\u79c1\uff0c\u901a\u8fc7\u53ef\u5ba1\u8ba1\u7684\u566a\u58f0\u8d26\u6237\u63d0\u9ad8\u7cbe\u5ea6\u5e76\u964d\u4f4e\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "motivation": "\u5206\u5e03\u5f0f\u8054\u90a6\u5b66\u4e60\u5b58\u5728\u6a21\u578b\u66f4\u65b0\u6cc4\u6f0f\u6570\u636e\u7684\u98ce\u9669\uff0c\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u9700\u8981\u6ce8\u5165\u566a\u58f0\uff0c\u4f46\u9ed1\u76d2\u8bad\u7ec3\u65e0\u6cd5\u8ffd\u8e2a\u5386\u53f2\u566a\u58f0\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u566a\u58f0\u6ce8\u5165\u548c\u7cbe\u5ea6\u4e0b\u964d\u3002", "method": "\u63d0\u51faPrivateDFL\u6846\u67b6\uff0c\u7ed3\u5408\u8d85\u7ef4\u8ba1\u7b97\u548c\u5dee\u5206\u9690\u79c1\u6280\u672f\uff0c\u7ef4\u62a4\u53ef\u5ba1\u8ba1\u7684\u7d2f\u79ef\u566a\u58f0\u8bb0\u5f55\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u5ba2\u6237\u53ea\u9700\u6ce8\u5165\u4e0e\u5df2\u7d2f\u79ef\u566a\u58f0\u7684\u5dee\u989d\u3002", "result": "\u5728MNIST\u3001ISOLET\u548cUCI-HAR\u6570\u636e\u96c6\u4e0a\uff0c\u8d85\u8fc7\u4e86\u4f20\u7edfDP-SGD\u548cRDP\u65b9\u6cd5\u3002\u5728\u975eIID\u5206\u5e03\u4e0b\uff0c\u5728MNIST\u4e0a\u7cbe\u5ea6\u63d0\u9ad824.42%\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1110\u500d\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e76\u500d\uff0c\u80fd\u8017\u51cf\u5c111\u500d\u3002\u5728ISOLET\u4e0a\u7cbe\u5ea6\u63d0\u9ad880%\u4ee5\u4e0a\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1110\u500d\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e40\u500d\uff0c\u80fd\u8017\u51cf\u5c1136\u500d\u3002", "conclusion": "PrivateDFL\u6846\u67b6\u5728\u4fdd\u6301\u5f62\u5f0f(\u03b5, \u03b4)\u9690\u79c1\u4fdd\u8bc1\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7cbe\u5ea6\u3001\u66f4\u4f4e\u5ef6\u8fdf\u548c\u66f4\u4f4e\u80fd\u8017\uff0c\u4e14\u65e0\u9700\u4e2d\u592e\u670d\u52a1\u5668\u3002\u672a\u6765\u5de5\u4f5c\u5c06\u6269\u5c55\u5230\u5bf9\u6297\u6027\u5ba2\u6237\u548c\u5f02\u6784\u9690\u79c1\u9884\u7b97\u7684\u9002\u5e94\u6027\u62d3\u6251\u3002"}}
{"id": "2509.11566", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.11566", "abs": "https://arxiv.org/abs/2509.11566", "authors": ["Hua Guo", "Yunhong Ji", "Xuan Zhou"], "title": "Sedeve-Kit, a Specification-Driven Development Framework for Building Distributed Systems", "comment": null, "summary": "Developing distributed systems presents significant challenges, primarily due\nto the complexity introduced by non-deterministic concurrency and faults. To\naddress these, we propose a specification-driven development framework. Our\nmethod encompasses three key stages. The first stage defines system\nspecifications and invariants using TLA${^+}$. It allows us to perform model\nchecking on the algorithm's correctness and generate test cases for subsequent\ndevelopment phases. In the second stage, based on the established\nspecifications, we write code to ensure consistency and accuracy in the\nimplementation. Finally, after completing the coding process, we rigorously\ntest the system using the test cases generated in the initial stage. This\nprocess ensures system quality by maintaining a strong connection between the\nabstract design and the concrete implementation through continuous\nverification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u89c4\u8303\u9a71\u52a8\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u5f00\u53d1\u6846\u67b6\uff0c\u901a\u8fc7TLA+\u89c4\u8303\u5b9a\u4e49\u3001\u6a21\u578b\u68c0\u67e5\u548c\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u6765\u786e\u4fdd\u7cfb\u7edf\u6b63\u786e\u6027", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u975e\u786e\u5b9a\u6027\u5e76\u53d1\u548c\u6545\u969c\u5e26\u6765\u7684\u590d\u6742\u6027\u6311\u6218", "method": "\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u4f7f\u7528TLA+\u5b9a\u4e49\u89c4\u8303\u548c\u4e0d\u53d8\u5f0f\uff0c\u8fdb\u884c\u6a21\u578b\u68c0\u67e5\u5e76\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff1b2) \u57fa\u4e8e\u89c4\u8303\u7f16\u5199\u4ee3\u7801\uff1b3) \u4f7f\u7528\u751f\u6210\u7684\u6d4b\u8bd5\u7528\u4f8b\u8fdb\u884c\u4e25\u683c\u6d4b\u8bd5", "result": "\u901a\u8fc7\u62bd\u8c61\u8bbe\u8ba1\u4e0e\u5177\u4f53\u5b9e\u73b0\u4e4b\u95f4\u7684\u6301\u7eed\u9a8c\u8bc1\uff0c\u786e\u4fdd\u7cfb\u7edf\u8d28\u91cf", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u89c4\u8303\u9a71\u52a8\u7684\u5f00\u53d1\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u7cfb\u7edf\u5f00\u53d1\u7684\u590d\u6742\u6027\uff0c\u786e\u4fdd\u4e86\u7cfb\u7edf\u7684\u6b63\u786e\u6027\u548c\u53ef\u9760\u6027"}}
{"id": "2509.11067", "categories": ["cs.AI", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.11067", "abs": "https://arxiv.org/abs/2509.11067", "authors": ["Liangxuan Guo", "Bin Zhu", "Qingqian Tao", "Kangning Liu", "Xun Zhao", "Xianzhe Qin", "Jin Gao", "Guangfu Hao"], "title": "Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration", "comment": null, "summary": "Autonomous agents for desktop automation struggle with complex multi-step\ntasks due to poor coordination and inadequate quality control. We introduce\n\\textsc{Agentic Lybic}, a novel multi-agent system where the entire\narchitecture operates as a finite-state machine (FSM). This core innovation\nenables dynamic orchestration. Our system comprises four components: a\nController, a Manager, three Workers (Technician for code-based operations,\nOperator for GUI interactions, and Analyst for decision support), and an\nEvaluator. The critical mechanism is the FSM-based routing between these\ncomponents, which provides flexibility and generalization by dynamically\nselecting the optimal execution strategy for each subtask. This principled\norchestration, combined with robust quality gating, enables adaptive replanning\nand error recovery. Evaluated officially on the OSWorld benchmark,\n\\textsc{Agentic Lybic} achieves a state-of-the-art 57.07\\% success rate in 50\nsteps, substantially outperforming existing methods. Results demonstrate that\nprincipled multi-agent orchestration with continuous quality control provides\nsuperior reliability for generalized desktop automation in complex computing\nenvironments.", "AI": {"tldr": "Agentic Lybic\u662f\u4e00\u4e2a\u57fa\u4e8e\u6709\u9650\u72b6\u6001\u673a(FSM)\u7684\u591a\u667a\u80fd\u4f53\u684c\u9762\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u7f16\u6392\u548c\u6301\u7eed\u8d28\u91cf\u63a7\u5236\u5728\u590d\u6742\u591a\u6b65\u9aa4\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e8657.07%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u684c\u9762\u81ea\u52a8\u5316\u667a\u80fd\u4f53\u5728\u5904\u7406\u590d\u6742\u591a\u6b65\u9aa4\u4efb\u52a1\u65f6\u5b58\u5728\u534f\u8c03\u6027\u5dee\u548c\u8d28\u91cf\u63a7\u5236\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u7684\u81ea\u9002\u5e94\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u6709\u9650\u72b6\u6001\u673a\u67b6\u6784\uff0c\u5305\u542bController\u3001Manager\u3001\u4e09\u4e2aWorker(Technician\u3001Operator\u3001Analyst)\u548cEvaluator\u56db\u4e2a\u7ec4\u4ef6\uff0c\u901a\u8fc7FSM\u8def\u7531\u673a\u5236\u52a8\u6001\u9009\u62e9\u6700\u4f18\u6267\u884c\u7b56\u7565\u3002", "result": "\u5728OSWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523057.07%\u7684\u6210\u529f\u7387(50\u6b65\u5185)\uff0c\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u7cfb\u7edf\u5728\u590d\u6742\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u5353\u8d8a\u53ef\u9760\u6027\u3002", "conclusion": "\u57fa\u4e8e\u539f\u5219\u7684\u591a\u667a\u80fd\u4f53\u7f16\u6392\u7ed3\u5408\u6301\u7eed\u8d28\u91cf\u63a7\u5236\u4e3a\u901a\u7528\u684c\u9762\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u4f18\u8d8a\u7684\u53ef\u9760\u6027\uff0cFSM\u67b6\u6784\u5b9e\u73b0\u4e86\u7075\u6d3b\u7684\u52a8\u6001\u534f\u8c03\u548c\u9519\u8bef\u6062\u590d\u80fd\u529b\u3002"}}
{"id": "2509.10703", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2509.10703", "abs": "https://arxiv.org/abs/2509.10703", "authors": ["Seonghun Son", "Chandrika Mukherjee", "Reham Mohamed Aburas", "Berk Gulmezoglu", "Z. Berkay Celik"], "title": "Side-channel Inference of User Activities in AR/VR Using GPU Profiling", "comment": "Accepted to the 2026 Network and Distributed System Security (NDSS)\n  Symposium", "summary": "Over the past decade, AR/VR devices have drastically changed how we interact\nwith the digital world. Users often share sensitive information, such as their\nlocation, browsing history, and even financial data, within third-party apps\ninstalled on these devices, assuming a secure environment protected from\nmalicious actors. Recent research has revealed that malicious apps can exploit\nsuch capabilities and monitor benign apps to track user activities, leveraging\nfine-grained profiling tools, such as performance counter APIs. However,\napp-to-app monitoring is not feasible on all AR/VR devices (e.g., Meta Quest),\nas a concurrent standalone app execution is disabled. In this paper, we present\nOVRWatcher, a novel side-channel primitive for AR/VR devices that infers user\nactivities by monitoring low-resolution (1Hz) GPU usage via a background\nscript, unlike prior work that relies on high-resolution profiling. OVRWatcher\ncaptures correlations between GPU metrics and 3D object interactions under\nvarying speeds, distances, and rendering scenarios, without requiring\nconcurrent app execution, access to application data, or additional SDK\ninstallations. We demonstrate the efficacy of OVRWatcher in fingerprinting both\nstandalone AR/VR and WebXR applications. OVRWatcher also distinguishes virtual\nobjects, such as products in immersive shopping apps selected by real users and\nthe number of participants in virtual meetings, thereby revealing users'\nproduct preferences and potentially exposing confidential information from\nthose meetings. OVRWatcher achieves over 99% accuracy in app fingerprinting and\nover 98% accuracy in object-level inference.", "AI": {"tldr": "OVRWatcher\u662f\u4e00\u79cd\u9488\u5bf9AR/VR\u8bbe\u5907\u7684\u4fa7\u4fe1\u9053\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u63a7\u4f4e\u5206\u8fa8\u7387GPU\u4f7f\u7528\u60c5\u51b5\u6765\u63a8\u65ad\u7528\u6237\u6d3b\u52a8\uff0c\u65e0\u9700\u5e76\u53d1\u5e94\u7528\u6267\u884c\u6216\u7279\u6b8a\u6743\u9650", "motivation": "\u73b0\u6709\u6076\u610f\u5e94\u7528\u76d1\u63a7\u65b9\u6cd5\u5728Meta Quest\u7b49AR/VR\u8bbe\u5907\u4e0a\u4e0d\u53ef\u884c\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u8bbe\u5907\u7981\u6b62\u5e76\u53d1\u72ec\u7acb\u5e94\u7528\u6267\u884c\uff0c\u9700\u8981\u65b0\u7684\u653b\u51fb\u5411\u91cf\u6765\u4fdd\u62a4\u7528\u6237\u9690\u79c1", "method": "\u5f00\u53d1OVRWatcher\u4fa7\u4fe1\u9053\u539f\u8bed\uff0c\u901a\u8fc7\u540e\u53f0\u811a\u672c\u76d1\u63a71Hz\u4f4e\u5206\u8fa8\u7387GPU\u4f7f\u7528\u60c5\u51b5\uff0c\u6355\u6349GPU\u6307\u6807\u4e0e3D\u5bf9\u8c61\u4ea4\u4e92\u4e4b\u95f4\u7684\u76f8\u5173\u6027", "result": "\u5728\u5e94\u7528\u6307\u7eb9\u8bc6\u522b\u65b9\u9762\u8fbe\u523099%\u4ee5\u4e0a\u51c6\u786e\u7387\uff0c\u5728\u5bf9\u8c61\u7ea7\u63a8\u65ad\u65b9\u9762\u8fbe\u523098%\u4ee5\u4e0a\u51c6\u786e\u7387\uff0c\u80fd\u591f\u8bc6\u522b\u865a\u62df\u8d2d\u7269\u4ea7\u54c1\u9009\u62e9\u548c\u865a\u62df\u4f1a\u8bae\u53c2\u4e0e\u8005\u6570\u91cf", "conclusion": "\u4f4e\u5206\u8fa8\u7387GPU\u76d1\u63a7\u53ef\u4ee5\u6210\u4e3a\u6709\u6548\u7684\u4fa7\u4fe1\u9053\u653b\u51fb\u624b\u6bb5\uff0c\u63ed\u793a\u4e86AR/VR\u8bbe\u5907\u4e2d\u65b0\u7684\u9690\u79c1\u98ce\u9669\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u5b89\u5168\u9632\u62a4\u63aa\u65bd"}}
{"id": "2509.11626", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11626", "abs": "https://arxiv.org/abs/2509.11626", "authors": ["Prerna Agarwal", "Himanshu Gupta", "Soujanya Soni", "Rohith Vallam", "Renuka Sindhgatta", "Sameep Mehta"], "title": "Automated Creation and Enrichment Framework for Improved Invocation of Enterprise APIs as Tools", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) has lead to the\ndevelopment of agents capable of complex reasoning and interaction with\nexternal tools. In enterprise contexts, the effective use of such tools that\nare often enabled by application programming interfaces (APIs), is hindered by\npoor documentation, complex input or output schema, and large number of\noperations. These challenges make tool selection difficult and reduce the\naccuracy of payload formation by up to 25%. We propose ACE, an automated tool\ncreation and enrichment framework that transforms enterprise APIs into\nLLM-compatible tools. ACE, (i) generates enriched tool specifications with\nparameter descriptions and examples to improve selection and invocation\naccuracy, and (ii) incorporates a dynamic shortlisting mechanism that filters\nrelevant tools at runtime, reducing prompt complexity while maintaining\nscalability. We validate our framework on both proprietary and open-source APIs\nand demonstrate its integration with agentic frameworks. To the best of our\nknowledge, ACE is the first end-to-end framework that automates the creation,\nenrichment, and dynamic selection of enterprise API tools for LLM agents.", "AI": {"tldr": "ACE\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u5de5\u5177\u521b\u5efa\u548c\u589e\u5f3a\u6846\u67b6\uff0c\u5c06\u4f01\u4e1aAPI\u8f6c\u6362\u4e3aLLM\u517c\u5bb9\u5de5\u5177\uff0c\u901a\u8fc7\u751f\u6210\u4e30\u5bcc\u7684\u5de5\u5177\u89c4\u8303\u548c\u52a8\u6001\u7b5b\u9009\u673a\u5236\uff0c\u63d0\u9ad8\u5de5\u5177\u9009\u62e9\u548c\u8c03\u7528\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4f01\u4e1a\u73af\u5883\u4e2d\uff0cLLM\u4ee3\u7406\u4f7f\u7528API\u5de5\u5177\u9762\u4e34\u6587\u6863\u8d28\u91cf\u5dee\u3001\u8f93\u5165\u8f93\u51fa\u6a21\u5f0f\u590d\u6742\u3001\u64cd\u4f5c\u6570\u91cf\u591a\u7b49\u6311\u6218\uff0c\u5bfc\u81f4\u5de5\u5177\u9009\u62e9\u56f0\u96be\u548c\u8d1f\u8f7d\u5f62\u6210\u51c6\u786e\u6027\u4e0b\u964d\u8fbe25%\u3002", "method": "ACE\u6846\u67b6\uff1a(i)\u751f\u6210\u5305\u542b\u53c2\u6570\u63cf\u8ff0\u548c\u793a\u4f8b\u7684\u4e30\u5bcc\u5de5\u5177\u89c4\u8303\uff1b(ii)\u96c6\u6210\u52a8\u6001\u7b5b\u9009\u673a\u5236\uff0c\u5728\u8fd0\u884c\u65f6\u8fc7\u6ee4\u76f8\u5173\u5de5\u5177\uff0c\u964d\u4f4e\u63d0\u793a\u590d\u6742\u5ea6\u540c\u65f6\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5728\u4e13\u6709\u548c\u5f00\u6e90API\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u4e0e\u4ee3\u7406\u6846\u67b6\u7684\u96c6\u6210\u80fd\u529b\u3002", "conclusion": "ACE\u662f\u9996\u4e2a\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u4f01\u4e1aAPI\u5de5\u5177\u521b\u5efa\u3001\u589e\u5f3a\u548c\u52a8\u6001\u9009\u62e9\u7684\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u4ee3\u7406\u7684\u5de5\u5177\u4f7f\u7528\u6548\u679c\u3002"}}
{"id": "2509.11068", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11068", "abs": "https://arxiv.org/abs/2509.11068", "authors": ["Zan-Kai Chong", "Hiroyuki Ohsaki", "Bryan Ng"], "title": "Tractable Asymmetric Verification for Large Language Models via Deterministic Replicability", "comment": null, "summary": "The landscape of Large Language Models (LLMs) shifts rapidly towards dynamic,\nmulti-agent systems. This introduces a fundamental challenge in establishing\ncomputational trust, specifically how one agent can verify that another's\noutput was genuinely produced by a claimed LLM, and not falsified or generated\nby a cheaper or inferior model. To address this challenge, this paper proposes\na verification framework that achieves tractable asymmetric effort, where the\ncost to verify a computation is substantially lower than the cost to perform\nit. Our approach is built upon the principle of deterministic replicability, a\nproperty inherent to autoregressive models that strictly necessitates a\ncomputationally homogeneous environment where all agents operate on identical\nhardware and software stacks. Within this defined context, our framework\nenables multiple validators to probabilistically audit small, random segments\nof an LLM's output and it distributes the verification workload effectively.\nThe simulations demonstrated that targeted verification can be over 12 times\nfaster than full regeneration, with tunable parameters to adjust the detection\nprobability. By establishing a tractable mechanism for auditable LLM systems,\nour work offers a foundational layer for responsible AI and serves as a\ncornerstone for future research into the more complex, heterogeneous\nmulti-agent systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u9a8c\u8bc1\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2dLLM\u8f93\u51fa\u771f\u5b9e\u6027\u7684\u53ef\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u6982\u7387\u6027\u5ba1\u8ba1\u968f\u673a\u7247\u6bb5\u5b9e\u73b0\u4e0d\u5bf9\u79f0\u8ba1\u7b97\u6210\u672c\uff0c\u9a8c\u8bc1\u6210\u672c\u8fdc\u4f4e\u4e8e\u751f\u6210\u6210\u672c", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2dLLM\u8f93\u51fa\u771f\u5b9e\u6027\u7684\u8ba1\u7b97\u4fe1\u4efb\u95ee\u9898\uff0c\u9632\u6b62\u8f93\u51fa\u88ab\u4f2a\u9020\u6216\u7531\u52a3\u8d28\u6a21\u578b\u751f\u6210", "method": "\u57fa\u4e8e\u786e\u5b9a\u6027\u53ef\u590d\u5236\u6027\u539f\u5219\uff0c\u5728\u8ba1\u7b97\u540c\u8d28\u73af\u5883\u4e0b\uff0c\u901a\u8fc7\u591a\u4e2a\u9a8c\u8bc1\u8005\u6982\u7387\u6027\u5ba1\u8ba1LLM\u8f93\u51fa\u7684\u968f\u673a\u5c0f\u7247\u6bb5\uff0c\u5b9e\u73b0\u5206\u5e03\u5f0f\u9a8c\u8bc1", "result": "\u6a21\u62df\u663e\u793a\u9488\u5bf9\u6027\u9a8c\u8bc1\u6bd4\u5b8c\u5168\u91cd\u65b0\u751f\u6210\u5feb12\u500d\u4ee5\u4e0a\uff0c\u5177\u6709\u53ef\u8c03\u8282\u7684\u68c0\u6d4b\u6982\u7387\u53c2\u6570", "conclusion": "\u4e3a\u53ef\u5ba1\u8ba1LLM\u7cfb\u7edf\u5efa\u7acb\u4e86\u53ef\u884c\u7684\u9a8c\u8bc1\u673a\u5236\uff0c\u4e3a\u8d1f\u8d23\u4efbAI\u63d0\u4f9b\u57fa\u7840\u5c42\uff0c\u5e76\u4e3a\u672a\u6765\u590d\u6742\u5f02\u6784\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7814\u7a76\u5960\u5b9a\u57fa\u7840"}}
{"id": "2509.10709", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10709", "abs": "https://arxiv.org/abs/2509.10709", "authors": ["Shama Maganur", "Yili Jiang", "Jiaqi Huang", "Fangtian Zhong"], "title": "Feature-Centric Approaches to Android Malware Analysis: A Survey", "comment": null, "summary": "Sophisticated malware families exploit the openness of the Android platform\nto infiltrate IoT networks, enabling large-scale disruption, data exfiltration,\nand denial-of-service attacks. This systematic literature review (SLR) examines\ncutting-edge approaches to Android malware analysis with direct implications\nfor securing IoT infrastructures. We analyze feature extraction techniques\nacross static, dynamic, hybrid, and graph-based methods, highlighting their\ntrade-offs: static analysis offers efficiency but is easily evaded through\nobfuscation; dynamic analysis provides stronger resistance to evasive behaviors\nbut incurs high computational costs, often unsuitable for lightweight IoT\ndevices; hybrid approaches balance accuracy with resource considerations; and\ngraph-based methods deliver superior semantic modeling and adversarial\nrobustness. This survey contributes a structured comparison of existing\nmethods, exposes research gaps, and outlines a roadmap for future directions to\nenhance scalability, adaptability, and long-term security in IoT-driven Android\nmalware detection.", "AI": {"tldr": "\u8fd9\u7bc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u5206\u6790\u4e86\u4e2d\u4ecb\u8bbe\u5907\u5e73\u53f0\u7684Android\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u9759\u6001\u3001\u52a8\u6001\u3001\u6df7\u5408\u548c\u56fe\u57fa\u65b9\u6cd5\u7684\u7279\u5f81\u63d0\u53d6\u6280\u672f\uff0c\u4ee5\u53ca\u5b83\u4eec\u5728IoT\u5b89\u5168\u4e2d\u7684\u5e94\u7528\u548c\u504f\u5f3a\u5f0a\u3002", "motivation": "Android\u5e73\u53f0\u7684\u5f00\u653e\u6027\u4f7f\u5f97\u6076\u610f\u8f6f\u4ef6\u80fd\u591f\u6e17\u900fIoT\u7f51\u7edc\uff0c\u9020\u6210\u5927\u89c4\u6a21\u4e2d\u65ad\u3001\u6570\u636e\u6cc4\u6f0f\u548c\u62d2\u7edd\u670d\u52a1\u653b\u51fb\uff0c\u9700\u8981\u6709\u6548\u7684\u5206\u6790\u65b9\u6cd5\u6765\u4fdd\u62a4IoT\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u8fdb\u884c\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0(SLR)\uff0c\u5bf9\u9759\u6001\u5206\u6790\u3001\u52a8\u6001\u5206\u6790\u3001\u6df7\u5408\u5206\u6790\u548c\u56fe\u57fa\u65b9\u6cd5\u8fdb\u884c\u8be6\u7ec6\u5206\u6790\u548c\u6bd4\u8f83\uff0c\u91cd\u70b9\u7814\u7a76\u7279\u5f81\u63d0\u53d6\u6280\u672f\u3002", "result": "\u9759\u6001\u5206\u6790\u6548\u7387\u9ad8\u4f46\u6613\u88ab\u6df7\u6dc6\u907f\u514d\uff1b\u52a8\u6001\u5206\u6790\u5bf9\u907f\u514d\u884c\u4e3a\u62b5\u5fa1\u529b\u5f3a\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff1b\u6df7\u5408\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u8d44\u6e90\u4f7f\u7528\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff1b\u56fe\u57fa\u65b9\u6cd5\u63d0\u4f9b\u4f18\u79c0\u7684\u8bed\u4e49\u5efa\u6a21\u548c\u5bf9\u6297\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u7ed3\u6784\u5316\u6bd4\u8f83\uff0c\u66dd\u9732\u4e86\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u7ed9\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u7684\u8def\u7ebf\u56fe\uff0c\u4ee5\u63d0\u9ad8IoT\u9a71\u52a8\u7684Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7684\u53ef\u6269\u5c55\u6027\u3001\u9002\u5e94\u6027\u548c\u957f\u671f\u5b89\u5168\u6027\u3002"}}
{"id": "2509.11686", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11686", "abs": "https://arxiv.org/abs/2509.11686", "authors": ["Jian Wang", "Xiaofei Xie", "Qiang Hu", "Shangqing Liu", "Yi Li"], "title": "Do Code Semantics Help? A Comprehensive Study on Execution Trace-Based Information for Code Large Language Models", "comment": "EMNLP2025-findings", "summary": "Code Large Language Models (Code LLMs) have opened a new era in programming\nwith their impressive capabilities. However, recent research has revealed\ncritical limitations in their ability to reason about runtime behavior and\nunderstand the actual functionality of programs, which poses significant\nchallenges for their post-training and practical deployment. Specifically, Code\nLLMs encounter two principal issues: (1) a lack of proficiency in reasoning\nabout program execution behavior, as they struggle to interpret what programs\nactually do during runtime, and (2) the inconsistent and fragmented\nrepresentation of semantic information, such as execution traces, across\nexisting methods, which hinders their ability to generalize and reason\neffectively. These challenges underscore the necessity for more systematic\napproaches to enhance the reasoning capabilities of Code LLMs. To address these\nissues, we introduce a generic framework to support integrating semantic\ninformation~(e.g., execution trace) to code task-relevant prompts, and conduct\na comprehensive study to explore the role of semantic information in enhancing\nthe reasoning ability of Code LLMs accordingly. Specifically, we focus on\ninvestigating the usefulness of trace-based semantic information in boosting\nsupervised fine-tuning~(SFT) and post-phase inference of Code LLMs. The\nexperimental results surprisingly disagree with previous works and demonstrate\nthat semantic information has limited usefulness for SFT and test time scaling\nof Code LLM.", "AI": {"tldr": "\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a0b\u5e8f\u6267\u884c\u884c\u4e3a\u7406\u89e3\u548c\u8bed\u4e49\u4fe1\u606f\u8868\u8fbe\u65b9\u9762\u5b58\u5728\u663e\u8457\u9650\u5236\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u8bed\u4e49\u4fe1\u606f\u7684\u6846\u67b6\uff0c\u4f46\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8bed\u4e49\u4fe1\u606f\u5bf9\u4ee3\u7801LLM\u7684\u5fae\u8c03\u548c\u63a8\u7406\u6539\u5584\u6548\u679c\u6709\u9650", "motivation": "\u89e3\u51b3\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a0b\u5e8f\u8fd0\u884c\u884c\u4e3a\u7406\u89e3\u548c\u8bed\u4e49\u4fe1\u606f\u8868\u8fbe\u4e0d\u4e00\u81f4\u65b9\u9762\u7684\u6838\u5fc3\u9650\u5236\uff0c\u8fd9\u4e9b\u95ee\u9898\u5f71\u54cd\u4e86\u6a21\u578b\u7684\u5b9e\u9645\u90e8\u7f72\u548c\u80fd\u529b", "method": "\u63d0\u51fa\u4e00\u79cd\u901a\u7528\u6846\u67b6\uff0c\u652f\u6301\u5c06\u8bed\u4e49\u4fe1\u606f\uff08\u5982\u6267\u884c\u8ddf\u8e2a\uff09\u96c6\u6210\u5230\u4ee3\u7801\u4efb\u52a1\u76f8\u5173\u63d0\u793a\u4e2d\uff0c\u5e76\u901a\u8fc7\u5b8c\u6574\u7684\u5b9e\u9a8c\u7814\u7a76\u8fdb\u884c\u9a8c\u8bc1", "result": "\u5b9e\u9a8c\u7ed3\u679c\u4e0e\u4ee5\u5f80\u7814\u7a76\u76f8\u53cd\uff0c\u663e\u793a\u8bed\u4e49\u4fe1\u606f\u5bf9\u4ee3\u7801LLM\u7684\u76d1\u7763\u5fae\u8c03\u548c\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u5e2e\u52a9\u6709\u9650", "conclusion": "\u8bed\u4e49\u4fe1\u606f\u5bf9\u4ee3\u7801LLM\u7684\u7406\u89e3\u80fd\u529b\u6539\u5584\u6548\u679c\u5e76\u4e0d\u5982\u9884\u671f\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u6a21\u578b\u7684\u7406\u89e3\u80fd\u529b"}}
{"id": "2509.11078", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11078", "abs": "https://arxiv.org/abs/2509.11078", "authors": ["Yunghwei Lai", "Weizhi Ma", "Yang Liu"], "title": "Patient-Zero: A Unified Framework for Real-Record-Free Patient Agent Generation", "comment": null, "summary": "Synthetic data generation using large language models (LLMs) has emerged as a\npromising solution across various domains, particularly in medical field, to\nmitigate data collection challenges. However, existing studies mainly utilize\nLLMs to rewrite and complete existing medical records, where the limitations in\ndata privacy, accuracy, and diversity sill exist, and additionally lack the\nability to interact like real patients. To address these issues, we propose a\nrealistic patient generation framework, Patient-Zero, which requires no real\nmedical records. Patient-Zero first introduces a medically-aligned multi-step\ngeneration architecture, which builds comprehensive patient records through\nhierarchical medical knowledge injection without real medical records. Then, to\noptimize the virtual patient's interaction abilities with humans, Patient-Zero\ndesigns a dynamic updating mechanism to improve the consistency and\nconversational performance. Our framework enables the generation of\ncontextually diverse patient records while maintaining strict medical\ncoherence, supported by adaptive dialogue strategies and real-time clinical\nplausibility verification. Experimental results demonstrate that our model\nachieves good performance in accuracy, diversity, and consistency. After\ntraining with our generated virtual patients, existing models show significant\nimprovements on the MedQA dataset.", "AI": {"tldr": "\u63d0\u51fa\u4e86Patient-Zero\u6846\u67b6\uff0c\u65e0\u9700\u771f\u5b9e\u533b\u7597\u8bb0\u5f55\u5373\u53ef\u751f\u6210\u903c\u771f\u7684\u865a\u62df\u60a3\u8005\uff0c\u901a\u8fc7\u533b\u5b66\u77e5\u8bc6\u6ce8\u5165\u548c\u52a8\u6001\u66f4\u65b0\u673a\u5236\u5b9e\u73b0\u9ad8\u51c6\u786e\u6027\u3001\u591a\u6837\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709LLM\u751f\u6210\u533b\u7597\u6570\u636e\u65b9\u6cd5\u5728\u9690\u79c1\u4fdd\u62a4\u3001\u51c6\u786e\u6027\u3001\u591a\u6837\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u771f\u5b9e\u60a3\u8005\u4ea4\u4e92\u80fd\u529b\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u533b\u5b66\u5bf9\u9f50\u7684\u591a\u6b65\u751f\u6210\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u5c42\u533b\u5b66\u77e5\u8bc6\u6ce8\u5165\u6784\u5efa\u5b8c\u6574\u60a3\u8005\u8bb0\u5f55\uff1b\u8bbe\u8ba1\u52a8\u6001\u66f4\u65b0\u673a\u5236\u4f18\u5316\u865a\u62df\u60a3\u8005\u7684\u4ea4\u4e92\u80fd\u529b\u548c\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u591a\u6837\u6027\u548c\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f7f\u7528\u751f\u6210\u6570\u636e\u8bad\u7ec3\u540e\u6a21\u578b\u5728MedQA\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u3002", "conclusion": "Patient-Zero\u6846\u67b6\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u865a\u62df\u60a3\u8005\u6570\u636e\uff0c\u4e3a\u533b\u7597AI\u5e94\u7528\u63d0\u4f9b\u6709\u6548\u7684\u5408\u6210\u6570\u636e\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10727", "categories": ["cs.CR", "H.1"], "pdf": "https://arxiv.org/pdf/2509.10727", "abs": "https://arxiv.org/abs/2509.10727", "authors": ["Luigi Logrippo"], "title": "Security theory for data flow and access control: From partial orders to lattices and back, a half-century trip", "comment": "7 pages, 1 figure", "summary": "The multi level Bell La Padula model for secure data access and data flow\ncontrol, formulated in the 1970s, was based on the theory of partial orders.\nSince then, another model, based on lattice theory, has prevailed. We present\nreasons why the partial order model is more appropriate. We also show, by\nexample, how non lattice data flow networks can be easily implemented by using\nAttribute-based access control (ABAC).", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\u57fa\u4e8e\u504f\u5e8f\u7406\u8bba\u7684\u591a\u7ea7Bell La Padula\u6a21\u578b\u6bd4\u57fa\u4e8e\u683c\u7406\u8bba\u7684\u6a21\u578b\u66f4\u9002\u5408\u5b89\u5168\u6570\u636e\u8bbf\u95ee\u63a7\u5236\uff0c\u5e76\u901a\u8fc7ABAC\u5c55\u793a\u4e86\u975e\u683c\u6570\u636e\u6d41\u7f51\u7edc\u7684\u5b9e\u73b0", "motivation": "\u91cd\u65b0\u8bc4\u4f301970\u5e74\u4ee3\u63d0\u51fa\u7684\u57fa\u4e8e\u504f\u5e8f\u7406\u8bba\u7684\u591a\u7ea7Bell La Padula\u6a21\u578b\uff0c\u8bc1\u660e\u5176\u6bd4\u540e\u6765\u6d41\u884c\u7684\u57fa\u4e8e\u683c\u7406\u8bba\u7684\u6a21\u578b\u66f4\u9002\u5408\u5b89\u5168\u6570\u636e\u8bbf\u95ee\u548c\u6570\u636e\u6d41\u63a7\u5236", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u4f8b\u6f14\u793a\uff0c\u5c55\u793a\u5982\u4f55\u4f7f\u7528\u57fa\u4e8e\u5c5e\u6027\u7684\u8bbf\u95ee\u63a7\u5236(ABAC)\u6765\u5b9e\u73b0\u975e\u683c\u6570\u636e\u6d41\u7f51\u7edc", "result": "\u8bc1\u660e\u4e86\u504f\u5e8f\u6a21\u578b\u6bd4\u683c\u6a21\u578b\u66f4\u5408\u9002\uff0c\u5e76\u5c55\u793a\u4e86\u975e\u683c\u6570\u636e\u6d41\u7f51\u7edc\u5728ABAC\u6846\u67b6\u4e0b\u7684\u53ef\u884c\u6027\u5b9e\u73b0", "conclusion": "\u57fa\u4e8e\u504f\u5e8f\u7406\u8bba\u7684\u591a\u7ea7Bell La Padula\u6a21\u578b\u5728\u5b89\u5168\u6570\u636e\u8bbf\u95ee\u63a7\u5236\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0cABAC\u4e3a\u5b9e\u73b0\u975e\u683c\u6570\u636e\u6d41\u7f51\u7edc\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84"}}
{"id": "2509.11691", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.11691", "abs": "https://arxiv.org/abs/2509.11691", "authors": ["Lukas Rauh", "Mel-Rick S\u00fcner", "Daniel Schel", "Thomas Bauernhansl"], "title": "AI Asset Management for Manufacturing (AIM4M): Development of a Process Model for Operationalization", "comment": "10 pages, 4 figures, submitted for revision review at International\n  Conference on Industry of the Future and Smart Manufacturing (ISM) 2025", "summary": "The benefits of adopting artificial intelligence (AI) in manufacturing are\nundeniable. However, operationalizing AI beyond the prototype, especially when\ninvolved with cyber-physical production systems (CPPS), remains a significant\nchallenge due to the technical system complexity, a lack of implementation\nstandards and fragmented organizational processes. To this end, this paper\nproposes a new process model for the lifecycle management of AI assets designed\nto address challenges in manufacturing and facilitate effective\noperationalization throughout the entire AI lifecycle. The process model, as a\ntheoretical contribution, builds on machine learning operations (MLOps)\nprinciples and refines three aspects to address the domain-specific\nrequirements from the CPPS context. As a result, the proposed process model\naims to support organizations in practice to systematically develop, deploy and\nmanage AI assets across their full lifecycle while aligning with CPPS-specific\nconstraints and regulatory demands.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4eba\u5de5\u667a\u80fd\u8d44\u4ea7\u751f\u547d\u5468\u671f\u7ba1\u7406\u6a21\u578b\uff0c\u4ee5\u89e3\u51b3\u5236\u9020\u4e1a\u4e2dAI\u8fd0\u8425\u5316\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u7f51\u7edc\u7269\u7406\u751f\u4ea7\u7cfb\u7edf(CPPS)\u73af\u5883\u4e2d\u7684\u5e94\u7528\u56f0\u96be\u3002", "motivation": "\u867d\u7136\u4eba\u5de5\u667a\u80fd\u5728\u5236\u9020\u4e1a\u6709\u660e\u663e\u4f18\u52bf\uff0c\u4f46\u5728\u539f\u578b\u9636\u6bb5\u4e4b\u5916\u8fdb\u884c\u8fd0\u8425\u5316\u907f\u904e\u4e86\u6280\u672f\u7cfb\u7edf\u590d\u6742\u6027\u3001\u7f3a\u4e4f\u5b9e\u65bd\u6807\u51c6\u548c\u7ec4\u7ec7\u8fc7\u7a0b\u5206\u6563\u7b49\u6311\u6218\uff0c\u7279\u522b\u662f\u5728CPPS\u73af\u5883\u4e2d\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u8fd0\u8425(MLOps)\u539f\u5219\u7684\u8fc7\u7a0b\u6a21\u578b\uff0c\u5e76\u9488\u5bf9CPPS\u9886\u57df\u7279\u5b9a\u9700\u6c42\u8fdb\u884c\u4e86\u4e09\u4e2a\u65b9\u9762\u7684\u7cbe\u70bc\u3002", "result": "\u8be5\u8fc7\u7a0b\u6a21\u578b\u80fd\u591f\u652f\u6301\u7ec4\u7ec7\u5728\u5b9e\u8df5\u4e2d\u7cfb\u7edf\u5730\u5f00\u53d1\u3001\u90e8\u7f72\u548c\u7ba1\u7406AI\u8d44\u4ea7\uff0c\u6ee1\u8db3CPPS\u7279\u5b9a\u7ea6\u675f\u548c\u76d1\u7ba1\u8981\u6c42\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5236\u9020\u4e1aAI\u8fd0\u8425\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u751f\u547d\u5468\u671f\u7ba1\u7406\u65b9\u6cd5\uff0c\u5c06\u673a\u5668\u5b66\u4e60\u8fd0\u8425\u539f\u5219\u4e0eCPPS\u9886\u57df\u7279\u5b9a\u9700\u6c42\u76f8\u7ed3\u5408\uff0c\u6709\u52a9\u4e8e\u89e3\u51b3\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2509.11079", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11079", "abs": "https://arxiv.org/abs/2509.11079", "authors": ["Jinwei Su", "Yinghui Xia", "Qizhen Lan", "Xinyuan Song", "Yang Jingsong", "Lewei He", "Tianyu Shi"], "title": "Difficulty-Aware Agent Orchestration in LLM-Powered Workflows", "comment": null, "summary": "Large Language Model (LLM)-based agentic systems have shown strong\ncapabilities across various tasks. However, existing multi-agent frameworks\noften rely on static or task-level workflows, which either over-process simple\nqueries or underperform on complex ones, while also neglecting the\nefficiency-performance trade-offs across heterogeneous LLMs. To address these\nlimitations, we propose Difficulty-Aware Agentic Orchestration (DAAO), a\ndynamic framework that adapts workflow depth, operator selection, and LLM\nassignment based on the difficulty of each input query. DAAO comprises three\ninterdependent modules: a variational autoencoder (VAE) for difficulty\nestimation, a modular operator allocator, and a cost- and performance-aware LLM\nrouter. By leveraging heterogeneous LLMs and dynamically tailoring workflows,\nDAAO enables fine-grained, query-specific reasoning strategies. DAAO\noutperforms prior multi-agent systems in both accuracy and inference efficiency\nacross six benchmarks. We will release our code and implementation details upon\npublication.", "AI": {"tldr": "DAAO\u662f\u4e00\u4e2a\u52a8\u6001\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u7684\u5de5\u4f5c\u6d41\u7f16\u6392\u3001\u7b97\u5b50\u5206\u914d\u548cLLM\u8def\u7531\uff0c\u5b9e\u73b0\u4e86\u5bf9\u67e5\u8be2\u96be\u5ea6\u7684\u81ea\u9002\u5e94\u5904\u7406\uff0c\u5728\u51c6\u786e\u6027\u548c\u63a8\u7406\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u6846\u67b6\u4f7f\u7528\u9759\u6001\u6216\u4efb\u52a1\u7ea7\u5de5\u4f5c\u6d41\uff0c\u65e0\u6cd5\u6839\u636e\u67e5\u8be2\u96be\u5ea6\u52a8\u6001\u8c03\u6574\uff0c\u5bfc\u81f4\u7b80\u5355\u67e5\u8be2\u8fc7\u5ea6\u5904\u7406\u3001\u590d\u6742\u67e5\u8be2\u6027\u80fd\u4e0d\u8db3\uff0c\u4e14\u5ffd\u7565\u4e86\u5f02\u6784LLM\u7684\u6548\u7387-\u6027\u80fd\u6743\u8861\u3002", "method": "\u63d0\u51faDifficulty-Aware Agentic Orchestration (DAAO)\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a\u53d8\u5206\u81ea\u7f16\u7801\u5668(VAE)\u7528\u4e8e\u96be\u5ea6\u4f30\u8ba1\u3001\u6a21\u5757\u5316\u7b97\u5b50\u5206\u914d\u5668\u3001\u6210\u672c\u548c\u6027\u80fd\u611f\u77e5\u7684LLM\u8def\u7531\u5668\uff0c\u52a8\u6001\u8c03\u6574\u5de5\u4f5c\u6d41\u6df1\u5ea6\u3001\u7b97\u5b50\u9009\u62e9\u548cLLM\u5206\u914d\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDAAO\u5728\u51c6\u786e\u6027\u548c\u63a8\u7406\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u5148\u524d\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "conclusion": "DAAO\u901a\u8fc7\u52a8\u6001\u96be\u5ea6\u611f\u77e5\u7684\u5de5\u4f5c\u6d41\u7f16\u6392\u548c\u5f02\u6784LLM\u7684\u667a\u80fd\u5229\u7528\uff0c\u5b9e\u73b0\u4e86\u66f4\u7cbe\u7ec6\u5316\u7684\u67e5\u8be2\u7279\u5b9a\u63a8\u7406\u7b56\u7565\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6548\u7387-\u6027\u80fd\u5e73\u8861\u65b9\u6848\u3002"}}
{"id": "2509.10755", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10755", "abs": "https://arxiv.org/abs/2509.10755", "authors": ["Zhongtang Luo", "Jianting Zhang", "Akshat Neerati", "Aniket Kate"], "title": "Five Minutes of DDoS Brings down Tor: DDoS Attacks on the Tor Directory Protocol and Mitigations", "comment": null, "summary": "The Tor network offers network anonymity to its users by routing their\ntraffic through a sequence of relays. A group of nine directory authorities\nmaintains information about all available relay nodes using a distributed\ndirectory protocol. We observe that the current protocol makes a steep\nsynchrony assumption, which makes it vulnerable to natural as well as\nadversarial non-synchronous communication scenarios over the Internet. In this\npaper, we show that it is possible to cause a failure in the Tor directory\nprotocol by targeting a majority of the authorities for only five minutes using\na well-executed distributed denial-of-service (DDoS) attack. We demonstrate\nthis attack in a controlled environment and show that it is cost-effective for\nas little as \\$53.28 per month to disrupt the protocol and to effectively bring\ndown the entire Tor network. To mitigate this problem, we consider the popular\npartial synchrony assumption for the Tor directory protocol that ensures that\nthe protocol security is hampered even when the network delays are large and\nunknown. We design a new Tor directory protocol that leverages any standard\npartial-synchronous consensus protocol to solve this problem, while also\nproving its security. We have implemented a prototype in Rust, demonstrating\ncomparable performance to the current protocol while resisting similar attacks.", "AI": {"tldr": "\u901a\u8fc7DDoS\u653b\u51fb\u76ee\u6809\u591a\u6570Tor\u76ee\u5f55\u6743\u5a01\u53ef\u4ee5\u4ee5\u6bcf\u6708$53.28\u7684\u4f4e\u6210\u672c\u5e26\u7f51\u7edc\u5931\u6548\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u90e8\u5206\u540c\u6b65\u534f\u8bae\u8fdb\u884c\u6539\u8fdb", "motivation": "\u73b0\u6709Tor\u76ee\u5f55\u534f\u8bae\u505a\u4e86\u4e25\u683c\u7684\u540c\u6b65\u5047\u8bbe\uff0c\u5bb9\u6613\u53d7\u5230DDoS\u653b\u51fb\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u52a0\u5065\u58ee\u7684\u534f\u8bae\u8bbe\u8ba1", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684Tor\u76ee\u5f55\u534f\u8bae\uff0c\u5229\u7528\u6807\u51c6\u7684\u90e8\u5206\u540c\u6b65\u5171\u8bc6\u534f\u8bae\uff0c\u5e76\u5728Rust\u4e2d\u5b9e\u73b0\u539f\u578b", "result": "\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u8bc1\u660e\u4e86DDoS\u653b\u51fb\u7684\u53ef\u884c\u6027\uff0c\u65b0\u534f\u8bae\u5728\u4fdd\u6301\u76f8\u4f3c\u6027\u80fd\u7684\u540c\u65f6\u80fd\u591f\u62b5\u5fa1\u7c7b\u4f3c\u653b\u51fb", "conclusion": "\u90e8\u5206\u540c\u6b65\u534f\u8bae\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8Tor\u76ee\u5f55\u534f\u8bae\u7684\u5bb9\u9510\u6027\uff0c\u4ee5\u8f83\u4f4e\u6210\u672c\u63d0\u5347\u7f51\u7edc\u5b89\u5168\u6027"}}
{"id": "2509.11708", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.11708", "abs": "https://arxiv.org/abs/2509.11708", "authors": ["Zhantong Xue", "Pingchuan Ma", "Zhaoyu Wang", "Shuai Wang"], "title": "From Evaluation to Enhancement: Large Language Models for Zero-Knowledge Proof Code Generation", "comment": null, "summary": "Zero-knowledge proofs (ZKPs) are increasingly deployed in domains such as\nprivacy-preserving authentication, blockchain scalability, and secure finance.\nHowever, authoring ZK programs remains challenging: unlike mainstream\nprogramming, ZK development requires reasoning about finite field arithmetic,\nconstraint systems, and gadgets, making it knowledge-intensive and error-prone.\nWhile large language models (LLMs) have demonstrated strong code generation\ncapabilities in general-purpose languages, their effectiveness for ZK\nprogramming, where correctness hinges on both language mastery and gadget-level\nreasoning, remains unexplored. To address this gap, we propose\n\\textsc{ZK-Eval}, a domain-specific evaluation pipeline that probes LLM\ncapabilities at three levels: language knowledge, gadget competence, and\nend-to-end program generation. Our evaluation of four state-of-the-art LLMs\nreveals that models excel at surface-level syntax but struggle with gadget\nusage and semantic correctness, often yielding incorrect programs. Based on\nthese insights, we introduce \\textsc{ZK-Coder}, an agentic framework that\naugments LLMs with constraint sketching, guided retrieval, and interactive\nrepair. Experiments on Circom and Noir show substantial gains, with success\nrates improving from 17.35\\% to 83.38\\% and from 32.21\\% to 90.05\\%,\nrespectively. With \\textsc{ZK-Eval} and \\textsc{ZK-Coder}, we establish a\nfoundation for systematically measuring and augmenting LLMs in ZK code\ngeneration to lower barriers for practitioners and advance trustworthy\ncomputation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86ZK-Eval\u548cZK-Coder\u4e24\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u63d0\u5347LLM\u5728\u96f6\u77e5\u8bc6\u8bc1\u660e\u7f16\u7a0b\u4e2d\u7684\u6027\u80fd\uff0c\u5c06\u6210\u529f\u7387\u4ece17.35%\u63d0\u5347\u523083.38%", "motivation": "\u96f6\u77e5\u8bc6\u8bc1\u660e\u7f16\u7a0b\u590d\u6742\u6613\u9519\uff0c\u9700\u8981\u5904\u7406\u6709\u9650\u57df\u7b97\u672f\u3001\u7ea6\u675f\u7cfb\u7edf\u548c\u5668\u4ef6\u7b49\u6982\u5ff5\uff0c\u800c\u73b0\u6709LLM\u5728\u8fd9\u4e00\u9886\u57df\u7684\u6548\u679c\u4ecd\u672a\u7ecf\u8fc7\u7cfb\u7edf\u8bc4\u4f30", "method": "\u63d0\u51faZK-Eval\u8bc4\u4f30\u6d41\u6c34\u7ebf\uff08\u8bed\u8a00\u77e5\u8bc6\u3001\u5668\u4ef6\u80fd\u529b\u3001\u7aef\u5230\u7aef\u751f\u6210\uff09\u548cZK-Coder\u6846\u67b6\uff08\u7ea6\u675f\u7ed8\u56fe\u3001\u5bfc\u822a\u68c0\u7d22\u3001\u4ea4\u4e92\u4fee\u590d\uff09", "result": "\u5bf9\u56db\u4e2a\u72ec\u7acbLLM\u7684\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u5728\u8bed\u6cd5\u5c42\u9762\u8868\u73b0\u4f18\u5f02\u4f46\u5728\u5668\u4ef6\u4f7f\u7528\u548c\u8bed\u4e49\u6b63\u786e\u6027\u4e0a\u9047\u5230\u56f0\u96be\uff1bZK-Coder\u5728Circom\u548cNoir\u4e0a\u5c06\u6210\u529f\u7387\u5206\u522b\u4ece17.35%\u63d0\u5347\u523083.38%\u548c\u4ece32.21%\u63d0\u5347\u523090.05%", "conclusion": "\u8bbe\u8ba1\u4e86\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u8861\u91cf\u548c\u589e\u5f3aLLM\u5728ZK\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u80fd\u529b\uff0c\u4e3a\u5b9e\u8df5\u8005\u964d\u4f4e\u95e8\u69db\u5e76\u63a8\u8fdb\u53ef\u4fe1\u8ba1\u7b97\u7684\u53d1\u5c55"}}
{"id": "2509.11131", "categories": ["cs.AI", "cs.MA", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2509.11131", "abs": "https://arxiv.org/abs/2509.11131", "authors": ["Benedikt Hartl", "Michael Levin", "L\u00e9o Pio-Lopez"], "title": "Neural cellular automata: applications to biology and beyond classical AI", "comment": null, "summary": "Neural Cellular Automata (NCA) represent a powerful framework for modeling\nbiological self-organization, extending classical rule-based systems with\ntrainable, differentiable (or evolvable) update rules that capture the adaptive\nself-regulatory dynamics of living matter. By embedding Artificial Neural\nNetworks (ANNs) as local decision-making centers and interaction rules between\nlocalized agents, NCA can simulate processes across molecular, cellular,\ntissue, and system-level scales, offering a multiscale competency architecture\nperspective on evolution, development, regeneration, aging, morphogenesis, and\nrobotic control. These models not only reproduce biologically inspired target\npatterns but also generalize to novel conditions, demonstrating robustness to\nperturbations and the capacity for open-ended adaptation and reasoning. Given\ntheir immense success in recent developments, we here review current literature\nof NCAs that are relevant primarily for biological or bioengineering\napplications. Moreover, we emphasize that beyond biology, NCAs display robust\nand generalizing goal-directed dynamics without centralized control, e.g., in\ncontrolling or regenerating composite robotic morphologies or even on\ncutting-edge reasoning tasks such as ARC-AGI-1. In addition, the same\nprinciples of iterative state-refinement is reminiscent to modern generative\nArtificial Intelligence (AI), such as probabilistic diffusion models. Their\ngoverning self-regulatory behavior is constraint to fully localized\ninteractions, yet their collective behavior scales into coordinated\nsystem-level outcomes. We thus argue that NCAs constitute a unifying\ncomputationally lean paradigm that not only bridges fundamental insights from\nmultiscale biology with modern generative AI, but have the potential to design\ntruly bio-inspired collective intelligence capable of hierarchical reasoning\nand control.", "AI": {"tldr": "\u795e\u7ecf\u7ec6\u80de\u81ea\u52a8\u673a(NCA)\u662f\u4e00\u79cd\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u548c\u7ec6\u80de\u81ea\u52a8\u673a\u7684\u591a\u5c3a\u5ea6\u5efa\u6a21\u6846\u67b6\uff0c\u80fd\u591f\u6a21\u62df\u751f\u7269\u81ea\u7ec4\u7ec7\u8fc7\u7a0b\u5e76\u5c55\u793a\u51fa\u5f3a\u5927\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u751f\u7269\u5efa\u6a21\u3001\u673a\u5668\u4eba\u63a7\u5236\u548c\u751f\u6210\u5f0fAI\u7b49\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002", "motivation": "NCA\u6846\u67b6\u65e8\u5728\u901a\u8fc7\u53ef\u8bad\u7ec3\u7684\u5c40\u90e8\u51b3\u7b56\u89c4\u5219\u6765\u6355\u6349\u751f\u7269\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u81ea\u8c03\u8282\u52a8\u529b\u5b66\uff0c\u4e3a\u591a\u5c3a\u5ea6\u751f\u7269\u8fc7\u7a0b\uff08\u5982\u8fdb\u5316\u3001\u53d1\u80b2\u3001\u518d\u751f\u7b49\uff09\u63d0\u4f9b\u7edf\u4e00\u7684\u5efa\u6a21\u8303\u5f0f\uff0c\u5e76\u63a2\u7d22\u5176\u5728\u751f\u7269\u5de5\u7a0b\u548c\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u3002", "method": "NCA\u5c06\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u5c40\u90e8\u51b3\u7b56\u4e2d\u5fc3\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u6216\u53ef\u8fdb\u5316\u7684\u66f4\u65b0\u89c4\u5219\u6765\u6a21\u62df\u5c40\u90e8\u5316\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5b9e\u73b0\u4ece\u5206\u5b50\u5230\u7cfb\u7edf\u7ea7\u522b\u7684\u591a\u5c3a\u5ea6\u5efa\u6a21\u3002", "result": "NCA\u4e0d\u4ec5\u80fd\u591f\u91cd\u73b0\u751f\u7269\u542f\u53d1\u6a21\u5f0f\uff0c\u8fd8\u80fd\u5728\u65b0\u6761\u4ef6\u4e0b\u6cdb\u5316\uff0c\u8868\u73b0\u51fa\u5bf9\u6270\u52a8\u7684\u9c81\u68d2\u6027\u548c\u5f00\u653e\u5f0f\u9002\u5e94\u80fd\u529b\uff0c\u5728\u673a\u5668\u4eba\u5f62\u6001\u63a7\u5236\u3001\u518d\u751f\u4efb\u52a1\u751a\u81f3ARC-AGI\u63a8\u7406\u4efb\u52a1\u4e2d\u5c55\u793a\u51fa\u5f3a\u5927\u7684\u76ee\u6807\u5bfc\u5411\u52a8\u529b\u5b66\u3002", "conclusion": "NCA\u6784\u6210\u4e86\u4e00\u4e2a\u8ba1\u7b97\u7b80\u6d01\u7684\u7edf\u4e00\u8303\u5f0f\uff0c\u4e0d\u4ec5\u8fde\u63a5\u4e86\u591a\u5c3a\u5ea6\u751f\u7269\u5b66\u4e0e\u73b0\u4ee3\u751f\u6210\u5f0fAI\uff0c\u8fd8\u6709\u6f5c\u529b\u8bbe\u8ba1\u51fa\u771f\u6b63\u5177\u6709\u751f\u7269\u542f\u53d1\u6027\u7684\u96c6\u4f53\u667a\u80fd\u7cfb\u7edf\uff0c\u80fd\u591f\u8fdb\u884c\u5206\u5c42\u63a8\u7406\u548c\u63a7\u5236\u3002"}}
{"id": "2509.10766", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10766", "abs": "https://arxiv.org/abs/2509.10766", "authors": ["Tong Zhou", "Ruyi Ding", "Gaowen Liu", "Charles Fleming", "Ramana Rao Kompella", "Yunsi Fei", "Xiaolin Xu", "Shaolei Ren"], "title": "A Content-dependent Watermark for Safeguarding Image Attribution", "comment": "18 pages, 13 figures", "summary": "The rapid growth of digital and AI-generated images has amplified the need\nfor secure and verifiable methods of image attribution. While digital\nwatermarking offers more robust protection than metadata-based\napproaches--which can be easily stripped--current watermarking techniques\nremain vulnerable to forgery, creating risks of misattribution that can damage\nthe reputations of AI model developers and the rights of digital artists. These\nvulnerabilities arise from two key issues: (1) content-agnostic watermarks,\nwhich, once learned or leaked, can be transferred across images to fake\nattribution, and (2) reliance on detector-based verification, which is\nunreliable since detectors can be tricked. We present MetaSeal, a novel\nframework for content-dependent watermarking with cryptographic security\nguarantees to safeguard image attribution. Our design provides (1) forgery\nresistance, preventing unauthorized replication and enforcing cryptographic\nverification; (2) robust, self-contained protection, embedding attribution\ndirectly into images while maintaining resilience against benign\ntransformations; and (3) evidence of tampering, making malicious alterations\nvisually detectable. Experiments demonstrate that MetaSeal effectively\nmitigates forgery attempts and applies to both natural and AI-generated images,\nestablishing a new standard for secure image attribution.", "AI": {"tldr": "MetaSeal\u662f\u4e00\u4e2a\u5177\u6709\u5bc6\u7801\u5b66\u5b89\u5168\u4fdd\u969c\u7684\u5185\u5bb9\u4f9d\u8d56\u6c34\u5370\u6846\u67b6\uff0c\u7528\u4e8e\u4fdd\u62a4\u56fe\u50cf\u5f52\u5c5e\u6743\uff0c\u9632\u6b62\u4f2a\u9020\u548c\u7be1\u6539\u3002", "motivation": "\u6570\u5b57\u548cAI\u751f\u6210\u56fe\u50cf\u7684\u5feb\u901f\u589e\u957f\u9700\u8981\u5b89\u5168\u53ef\u9a8c\u8bc1\u7684\u56fe\u50cf\u5f52\u5c5e\u65b9\u6cd5\u3002\u73b0\u6709\u6c34\u5370\u6280\u672f\u5bb9\u6613\u53d7\u5230\u4f2a\u9020\u653b\u51fb\uff0c\u5b58\u5728\u9519\u8bef\u5f52\u5c5e\u98ce\u9669\uff0c\u53ef\u80fd\u635f\u5bb3AI\u6a21\u578b\u5f00\u53d1\u8005\u548c\u6570\u5b57\u827a\u672f\u5bb6\u7684\u6743\u76ca\u3002", "method": "\u63d0\u51faMetaSeal\u6846\u67b6\uff0c\u91c7\u7528\u5185\u5bb9\u4f9d\u8d56\u6c34\u5370\u6280\u672f\uff0c\u63d0\u4f9b\u5bc6\u7801\u5b66\u5b89\u5168\u4fdd\u8bc1\u3002\u8bbe\u8ba1\u5305\u62ec\uff1a\u9632\u4f2a\u9020\u62b5\u6297\u3001\u9c81\u68d2\u7684\u81ea\u5305\u542b\u4fdd\u62a4\u3001\u7be1\u6539\u8bc1\u636e\u53ef\u89c6\u5316\u68c0\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMetaSeal\u80fd\u6709\u6548\u7f13\u89e3\u4f2a\u9020\u5c1d\u8bd5\uff0c\u9002\u7528\u4e8e\u81ea\u7136\u56fe\u50cf\u548cAI\u751f\u6210\u56fe\u50cf\u3002", "conclusion": "MetaSeal\u4e3a\u5b89\u5168\u56fe\u50cf\u5f52\u5c5e\u5efa\u7acb\u4e86\u65b0\u6807\u51c6\uff0c\u63d0\u4f9b\u4e86\u5bc6\u7801\u5b66\u5b89\u5168\u4fdd\u969c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.11738", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.11738", "abs": "https://arxiv.org/abs/2509.11738", "authors": ["Maria K\u00fc\u00fcsvek", "Hina Anwar"], "title": "Toward Greener Background Processes -- Measuring Energy Cost of Autosave Feature", "comment": "Author version. Accepted for publication in the proceedings of the\n  International Conference on Product-Focused Software Process Improvement\n  (PROFES 2025)", "summary": "Background processes in desktop applications are often overlooked in energy\nconsumption studies, yet they represent continuous, automated workloads with\nsignificant cumulative impact. This paper introduces a reusable process for\nevaluating the energy behavior of such features at the level of operational\ndesign. The process works in three phases: 1) decomposing background\nfunctionality into core operations, 2) operational isolation, and 3) controlled\nmeasurements enabling comparative profiling. We instantiate the process in a\ncase study of autosave implementations across three open-source Python-based\ntext editors. Using 900 empirical software-based energy measurements, we\nidentify key design factors affecting energy use, including save frequency,\nbuffering strategy, and auxiliary logic such as change detection. We give four\nactionable recommendations for greener implementations of autosave features in\nPython to support sustainable software practices.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u91cd\u7528\u7684\u80fd\u6e90\u6d88\u8017\u8bc4\u4f30\u6d41\u7a0b\uff0c\u91cd\u70b9\u5173\u6ce8\u684c\u9762\u5e94\u7528\u7684\u80cc\u666f\u8fdb\u7a0b\u80fd\u6e90\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7Python\u6587\u672c\u7f16\u8f91\u5668\u7684\u81ea\u52a8\u4fdd\u5b58\u529f\u80fd\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\u3002", "motivation": "\u684c\u9762\u5e94\u7528\u7684\u80cc\u666f\u8fdb\u7a0b\u5e38\u88ab\u5ffd\u89c6\uff0c\u4f46\u5177\u6709\u91cd\u8981\u7684\u79ef\u7d2f\u80fd\u6e90\u5f71\u54cd\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u80fd\u6e90\u884c\u4e3a\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4e09\u9636\u6bb5\u8bc4\u4f30\u6d41\u7a0b\uff1a1)\u80cc\u666f\u529f\u80fd\u5206\u89e3\u4e3a\u6838\u5fc3\u64cd\u4f5c 2)\u64cd\u4f5c\u9694\u79bb 3)\u63a7\u5236\u6d4b\u91cf\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002\u4ee5\u4e09\u6b3ePython\u6587\u672c\u7f16\u8f91\u5668\u7684\u81ea\u52a8\u4fdd\u5b58\u529f\u80fd\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u8fdb\u884c900\u6b21\u8f6f\u4ef6\u80fd\u6e90\u6d4b\u91cf\u3002", "result": "\u8bc6\u522b\u4e86\u5f71\u54cd\u80fd\u6e90\u6d88\u8017\u7684\u5173\u952e\u8bbe\u8ba1\u56e0\u7d20\uff0c\u5305\u62ec\u4fdd\u5b58\u9891\u7387\u3001\u7f13\u51b2\u7b56\u7565\u548c\u8f85\u52a9\u903b\u8f91\uff08\u5982\u53d8\u66f4\u68c0\u6d4b\uff09\u3002", "conclusion": "\u63d0\u51fa\u4e86\u56db\u6761\u53ef\u6267\u884c\u7684\u5efa\u8bae\uff0c\u4ee5\u652f\u6301Python\u81ea\u52a8\u4fdd\u5b58\u529f\u80fd\u7684\u7eff\u8272\u5b9e\u73b0\uff0c\u4fc3\u8fdb\u53ef\u6301\u7eed\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\u3002"}}
{"id": "2509.11135", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11135", "abs": "https://arxiv.org/abs/2509.11135", "authors": ["Jing Xiao", "Chang You", "Zhiyu Chen"], "title": "AlignKT: Explicitly Modeling Knowledge State for Knowledge Tracing with Ideal State Alignment", "comment": null, "summary": "Knowledge Tracing (KT) serves as a fundamental component of Intelligent\nTutoring Systems (ITS), enabling these systems to monitor and understand\nlearners' progress by modeling their knowledge state. However, many existing KT\nmodels primarily focus on fitting the sequences of learners' interactions, and\noften overlook the knowledge state itself. This limitation leads to reduced\ninterpretability and insufficient instructional support from the ITS. To\naddress this challenge, we propose AlignKT, which employs a frontend-to-backend\narchitecture to explicitly model a stable knowledge state. In this approach,\nthe preliminary knowledge state is aligned with an additional criterion.\nSpecifically, we define an ideal knowledge state based on pedagogical theories\nas the alignment criterion, providing a foundation for interpretability. We\nutilize five encoders to implement this set-up, and incorporate a contrastive\nlearning module to enhance the robustness of the alignment process. Through\nextensive experiments, AlignKT demonstrates superior performance, outperforming\nseven KT baselines on three real-world datasets. It achieves state-of-the-art\nresults on two of these datasets and exhibits competitive performance on the\nthird. The code of this work is available at\nhttps://github.com/SCNU203/AlignKT.", "AI": {"tldr": "AlignKT\u662f\u4e00\u4e2a\u7528\u4e8e\u77e5\u8bc6\u8ffd\u8e2a\u7684\u524d\u540e\u7aef\u67b6\u6784\u6a21\u578b\uff0c\u901a\u8fc7\u5c06\u521d\u6b65\u77e5\u8bc6\u72b6\u6001\u4e0e\u57fa\u4e8e\u6559\u5b66\u7406\u8bba\u7684\u7406\u60f3\u77e5\u8bc6\u72b6\u6001\u5bf9\u9f50\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6559\u5b66\u652f\u6301\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u62df\u5408\u5b66\u4e60\u8005\u4ea4\u4e92\u5e8f\u5217\uff0c\u800c\u5ffd\u89c6\u4e86\u77e5\u8bc6\u72b6\u6001\u672c\u8eab\uff0c\u5bfc\u81f4\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u548c\u6559\u5b66\u652f\u6301\u4e0d\u5145\u5206\u3002", "method": "\u91c7\u7528\u524d\u7aef\u5230\u540e\u7aef\u67b6\u6784\uff0c\u5b9a\u4e49\u57fa\u4e8e\u6559\u5b66\u7406\u8bba\u7684\u7406\u60f3\u77e5\u8bc6\u72b6\u6001\u4f5c\u4e3a\u5bf9\u9f50\u6807\u51c6\uff0c\u4f7f\u7528\u4e94\u4e2a\u7f16\u7801\u5668\u5b9e\u73b0\uff0c\u5e76\u52a0\u5165\u5bf9\u6bd4\u5b66\u4e60\u6a21\u5757\u589e\u5f3a\u5bf9\u9f50\u9c81\u68d2\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e03\u4e2a\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u7b2c\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "AlignKT\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u7a33\u5b9a\u7684\u77e5\u8bc6\u72b6\u6001\uff0c\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6559\u5b66\u652f\u6301\u3002"}}
{"id": "2509.10793", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2509.10793", "abs": "https://arxiv.org/abs/2509.10793", "authors": ["Eli Baum", "Sam Buxbaum", "Nitin Mathai", "Muhammad Faisal", "Vasiliki Kalavri", "Mayank Varia", "John Liagouris"], "title": "ORQ: Complex Analytics on Private Data with Strong Security Guarantees", "comment": "14 pages, plus Appendix. To appear at SOSP 2025. Code published at\n  https://github.com/CASP-Systems-BU/orq", "summary": "We present ORQ, a system that enables collaborative analysis of large private\ndatasets using cryptographically secure multi-party computation (MPC). ORQ\nprotects data against semi-honest or malicious parties and can efficiently\nevaluate relational queries with multi-way joins and aggregations that have\nbeen considered notoriously expensive under MPC. To do so, ORQ eliminates the\nquadratic cost of secure joins by leveraging the fact that, in practice, the\nstructure of many real queries allows us to join records and apply the\naggregations \"on the fly\" while keeping the result size bounded. On the system\nside, ORQ contributes generic oblivious operators, a data-parallel vectorized\nquery engine, a communication layer that amortizes MPC network costs, and a\ndataflow API for expressing relational analytics -- all built from the ground\nup.\n  We evaluate ORQ in LAN and WAN deployments on a diverse set of workloads,\nincluding complex queries with multiple joins and custom aggregations. When\ncompared to state-of-the-art solutions, ORQ significantly reduces MPC execution\ntimes and can process one order of magnitude larger datasets. For our most\nchallenging workload, the full TPC-H benchmark, we report results entirely\nunder MPC with Scale Factor 10 -- a scale that had previously been achieved\nonly with information leakage or the use of trusted third parties.", "AI": {"tldr": "ORQ\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u65b9\u5b89\u5168\u8ba1\u7b97\u7684\u9690\u79c1\u4fdd\u62a4\u6570\u636e\u5206\u6790\u7cfb\u7edf\uff0c\u80fd\u591f\u9ad8\u6548\u6267\u884c\u5305\u542b\u591a\u8868\u8fde\u63a5\u548c\u805a\u5408\u7684\u5173\u7cfb\u67e5\u8be2\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5b89\u5168\u8fde\u63a5\u7684\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u591a\u65b9\u5b89\u5168\u8ba1\u7b97(MPC)\u5728\u5904\u7406\u5173\u7cfb\u67e5\u8be2\u7279\u522b\u662f\u591a\u8868\u8fde\u63a5\u65f6\u5b58\u5728\u4e8c\u6b21\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u79c1\u6709\u6570\u636e\u96c6\u5206\u6790\u4e2d\u7684\u5e94\u7528\u3002", "method": "ORQ\u901a\u8fc7\u5b9e\u65f6\u8fde\u63a5\u8bb0\u5f55\u548c\u5e94\u7528\u805a\u5408\u6765\u907f\u514d\u7ed3\u679c\u96c6\u81a8\u80c0\uff0c\u6784\u5efa\u4e86\u901a\u7528\u7684\u4e0d\u7ecf\u610f\u64cd\u4f5c\u7b26\u3001\u6570\u636e\u5e76\u884c\u5411\u91cf\u5316\u67e5\u8be2\u5f15\u64ce\u3001\u901a\u4fe1\u4f18\u5316\u5c42\u548c\u6570\u636e\u6d41API\u3002", "result": "\u5728LAN\u548cWAN\u73af\u5883\u4e0b\uff0cORQ\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u663e\u8457\u51cf\u5c11\u4e86MPC\u6267\u884c\u65f6\u95f4\uff0c\u80fd\u591f\u5904\u7406\u5927\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u6570\u636e\u96c6\uff0c\u5e76\u9996\u6b21\u5728\u5b8c\u5168MPC\u4fdd\u62a4\u4e0b\u5b8c\u6210\u4e86TPC-H Scale Factor 10\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "ORQ\u7cfb\u7edf\u8bc1\u660e\u4e86\u5728\u5b8c\u5168\u9690\u79c1\u4fdd\u62a4\u4e0b\u9ad8\u6548\u5206\u6790\u5927\u89c4\u6a21\u5173\u7cfb\u6570\u636e\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u5b89\u5168\u534f\u4f5c\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.11748", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.11748", "abs": "https://arxiv.org/abs/2509.11748", "authors": ["Marius Mignard", "Steven Costiou", "Nicolas Anquetil", "Anne Etien"], "title": "Analysing Python Machine Learning Notebooks with Moose", "comment": null, "summary": "Machine Learning (ML) code, particularly within notebooks, often exhibits\nlower quality compared to traditional software. Bad practices arise at three\ndistinct levels: general Python coding conventions, the organizational\nstructure of the notebook itself, and ML-specific aspects such as\nreproducibility and correct API usage. However, existing analysis tools\ntypically focus on only one of these levels and struggle to capture ML-specific\nsemantics, limiting their ability to detect issues. This paper introduces\nVespucci Linter, a static analysis tool with multi-level capabilities, built on\nMoose and designed to address this challenge. Leveraging a metamodeling\napproach that unifies the notebook's structural elements with Python code\nentities, our linter enables a more contextualized analysis to identify issues\nacross all three levels. We implemented 22 linting rules derived from the\nliterature and applied our tool to a corpus of 5,000 notebooks from the Kaggle\nplatform. The results reveal violations at all levels, validating the relevance\nof our multi-level approach and demonstrating Vespucci Linter's potential to\nimprove the quality and reliability of ML development in notebook environments.", "AI": {"tldr": "Vespucci Linter\u662f\u4e00\u4e2a\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u7b14\u8bb0\u672c\u4ee3\u7801\u7684\u591a\u5c42\u6b21\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u80fd\u591f\u68c0\u6d4bPython\u7f16\u7801\u89c4\u8303\u3001\u7b14\u8bb0\u672c\u7ec4\u7ec7\u7ed3\u6784\u4ee5\u53caML\u7279\u5b9a\u95ee\u9898\u4e09\u4e2a\u5c42\u9762\u7684\u4ee3\u7801\u8d28\u91cf\u95ee\u9898", "motivation": "\u673a\u5668\u5b66\u4e60\u7b14\u8bb0\u672c\u4ee3\u7801\u8d28\u91cf\u666e\u904d\u8f83\u4f4e\uff0c\u73b0\u6709\u5de5\u5177\u901a\u5e38\u53ea\u5173\u6ce8\u5355\u4e00\u5c42\u9762\u4e14\u96be\u4ee5\u6355\u6349ML\u7279\u5b9a\u8bed\u4e49\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8fdb\u884c\u591a\u5c42\u6b21\u4e0a\u4e0b\u6587\u5206\u6790\u7684\u5de5\u5177", "method": "\u57fa\u4e8eMoose\u6784\u5efa\uff0c\u91c7\u7528\u5143\u5efa\u6a21\u65b9\u6cd5\u7edf\u4e00\u7b14\u8bb0\u672c\u7ed3\u6784\u5143\u7d20\u548cPython\u4ee3\u7801\u5b9e\u4f53\uff0c\u5b9e\u73b0\u4e8622\u4e2a\u57fa\u4e8e\u6587\u732e\u7684linting\u89c4\u5219\uff0c\u5e76\u57285000\u4e2aKaggle\u7b14\u8bb0\u672c\u4e0a\u5e94\u7528\u9a8c\u8bc1", "result": "\u5728\u6240\u6709\u4e09\u4e2a\u5c42\u9762\u90fd\u53d1\u73b0\u4e86\u8fdd\u89c4\u60c5\u51b5\uff0c\u9a8c\u8bc1\u4e86\u591a\u5c42\u6b21\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u5de5\u5177\u5728\u63d0\u9ad8\u7b14\u8bb0\u672c\u73af\u5883\u4e2dML\u5f00\u53d1\u8d28\u91cf\u548c\u53ef\u9760\u6027\u65b9\u9762\u7684\u6f5c\u529b", "conclusion": "Vespucci Linter\u901a\u8fc7\u591a\u5c42\u6b21\u9759\u6001\u5206\u6790\u6210\u529f\u89e3\u51b3\u4e86ML\u7b14\u8bb0\u672c\u4ee3\u7801\u8d28\u91cf\u95ee\u9898\uff0c\u4e3a\u6539\u5584\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u5b9e\u8df5\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177"}}
{"id": "2509.11151", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11151", "abs": "https://arxiv.org/abs/2509.11151", "authors": ["Jianxin Li", "Liang Qu", "Taotao Cai", "Zhixue Zhao", "Nur Al Hasan Haldar", "Aneesh Krishna", "Xiangjie Kong", "Flavio Romero Macau", "Tanmoy Chakraborty", "Aniket Deroy", "Binshan Lin", "Karen Blackmore", "Nasimul Noman", "Jingxian Cheng", "Ningning Cui", "Jianliang Xu"], "title": "AI-Generated Content in Cross-Domain Applications: Research Trends, Challenges and Propositions", "comment": null, "summary": "Artificial Intelligence Generated Content (AIGC) has rapidly emerged with the\ncapability to generate different forms of content, including text, images,\nvideos, and other modalities, which can achieve a quality similar to content\ncreated by humans. As a result, AIGC is now widely applied across various\ndomains such as digital marketing, education, and public health, and has shown\npromising results by enhancing content creation efficiency and improving\ninformation delivery. However, there are few studies that explore the latest\nprogress and emerging challenges of AIGC across different domains. To bridge\nthis gap, this paper brings together 16 scholars from multiple disciplines to\nprovide a cross-domain perspective on the trends and challenges of AIGC.\nSpecifically, the contributions of this paper are threefold: (1) It first\nprovides a broader overview of AIGC, spanning the training techniques of\nGenerative AI, detection methods, and both the spread and use of AI-generated\ncontent across digital platforms. (2) It then introduces the societal impacts\nof AIGC across diverse domains, along with a review of existing methods\nemployed in these contexts. (3) Finally, it discusses the key technical\nchallenges and presents research propositions to guide future work. Through\nthese contributions, this vision paper seeks to offer readers a cross-domain\nperspective on AIGC, providing insights into its current research trends,\nongoing challenges, and future directions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u4f9b\u4e86\u4eba\u5de5\u667a\u80fd\u751f\u6210\u5185\u5bb9(AIGC)\u7684\u8de8\u9886\u57df\u89c6\u89d2\uff0c\u7edf\u8ba1\u4e86\u751f\u6210\u5f0fAI\u8bad\u7ec3\u6280\u672f\u3001\u68c0\u6d4b\u65b9\u6cd5\u3001\u793e\u4f1a\u5f71\u54cd\u548c\u6280\u672f\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u5f53\u524d\u5c11\u6709\u7814\u7a76\u6df1\u5165\u63a2\u8ba8AIGC\u5728\u4e0d\u540c\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\u548c\u6311\u6218\uff0c\u9700\u8981\u8de8\u9886\u57df\u89c6\u89d2\u6765\u5b8c\u5584AIGC\u7684\u7814\u7a76\u4f53\u7cfb\u3002", "method": "\u805a\u96c616\u4f4d\u6765\u81ea\u4e0d\u540c\u5b66\u79d1\u7684\u5b66\u8005\uff0c\u901a\u8fc7\u4e09\u65b9\u9762\u8d21\u732e\uff1a\u63d0\u4f9bAIGC\u5168\u5c40\u6982\u89c8\u3001\u5206\u6790\u5404\u9886\u57df\u793e\u4f1a\u5f71\u54cd\u3001\u8ba8\u8bba\u5173\u952e\u6280\u672f\u6311\u6218\u5e76\u63d0\u51fa\u7814\u7a76\u5efa\u8bae\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u8de8\u9886\u57df\u7684AIGC\u7814\u7a76\u6846\u67b6\uff0c\u5305\u542b\u6280\u672f\u3001\u68c0\u6d4b\u3001\u5e73\u53f0\u4f7f\u7528\u3001\u793e\u4f1a\u5f71\u54cd\u7b49\u591a\u7ef4\u5ea6\u5206\u6790\uff0c\u4e3a\u8bc6\u522b\u5f53\u524d\u7814\u7a76\u8d8b\u52bf\u548c\u6311\u6218\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u89c6\u89d2\u3002", "conclusion": "\u8be5\u89c6\u91ce\u6027\u8bba\u6587\u4e3aAIGC\u9886\u57df\u63d0\u4f9b\u4e86\u8de8\u5b66\u79d1\u7684\u7efc\u5408\u5206\u6790\uff0c\u663e\u793a\u4e86AIGC\u5728\u5404\u884c\u4e1a\u7684\u5e94\u7528\u6f5c\u529b\u548c\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2509.10814", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10814", "abs": "https://arxiv.org/abs/2509.10814", "authors": ["Yang Zhang", "Wenyi Ouyang", "Yi Zhang", "Liang Cheng", "Chen Wu", "Wenxin Hu"], "title": "Automatic Generation of a Cryptography Misuse Taxonomy Using Large Language Models", "comment": "23 pages, 9 figures", "summary": "The prevalence of cryptographic API misuse (CAM) is compromising the\neffectiveness of cryptography and in turn the security of modern systems and\napplications. Despite extensive efforts to develop CAM detection tools, these\ntools typically rely on a limited set of predefined rules from human-curated\nknowledge. This rigid, rule-based approach hinders adaptation to evolving CAM\npatterns in real practices.\n  We propose leveraging large language models (LLMs), trained on publicly\navailable cryptography-related data, to automatically detect and classify CAMs\nin real-world code to address this limitation. Our method enables the\ndevelopment and continuous expansion of a CAM taxonomy, supporting developers\nand detection tools in tracking and understanding emerging CAM patterns.\nSpecifically, we develop an LLM-agnostic prompt engineering method to guide\nLLMs in detecting CAM instances from C/C++, Java, Python, and Go code, and then\nclassifying them into a hierarchical taxonomy.\n  Using a data set of 3,492 real-world software programs, we demonstrate the\neffectiveness of our approach with mainstream LLMs, including GPT, Llama,\nGemini, and Claude. It also allows us to quantitatively measure and compare the\nperformance of these LLMs in analyzing CAM in realistic code. Our evaluation\nproduced a taxonomy with 279 base CAM categories, 36 of which are not addressed\nby existing taxonomies. To validate its practical value, we encode 11 newly\nidentified CAM types into detection rules and integrate them into existing\ntools. Experiments show that such integration expands the tools' detection\ncapabilities.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u68c0\u6d4b\u548c\u5206\u7c7b\u52a0\u5bc6API\u6ee5\u7528\uff0c\u6784\u5efa\u4e86\u5305\u542b279\u4e2a\u57fa\u7840\u7c7b\u522b\u7684\u65b0\u5206\u7c7b\u7cfb\u7edf\uff0c\u5176\u4e2d36\u4e2a\u662f\u73b0\u6709\u5206\u7c7b\u6cd5\u672a\u6db5\u76d6\u7684\u65b0\u6a21\u5f0f", "motivation": "\u73b0\u6709\u52a0\u5bc6API\u6ee5\u7528\u68c0\u6d4b\u5de5\u5177\u4f9d\u8d56\u4eba\u5de5\u9884\u5b9a\u4e49\u7684\u7c97\u7cd6\u89c4\u5219\uff0c\u65e0\u6cd5\u9002\u5e94\u5b9e\u9645\u4e2d\u6f14\u5316\u7684\u6ee5\u7528\u6a21\u5f0f", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08GPT\u3001Llama\u3001Gemini\u3001Claude\uff09\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u81ea\u52a8\u68c0\u6d4bC/C++\u3001Java\u3001Python\u3001Go\u4ee3\u7801\u4e2d\u7684\u52a0\u5bc6API\u6ee5\u7528\uff0c\u5e76\u8fdb\u884c\u5c42\u6b21\u5206\u7c7b", "result": "\u57283,492\u4e2a\u5b9e\u9645\u8f6f\u4ef6\u7a0b\u5e8f\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u6784\u5efa\u4e86\u5305\u542b279\u4e2a\u57fa\u7840\u6ee5\u7528\u7c7b\u522b\u7684\u5206\u7c7b\u7cfb\u7edf\uff0c\u5176\u4e2d36\u4e2a\u65b0\u7c7b\u522b\u3002\u5c0611\u4e2a\u65b0\u6ee5\u7528\u7c7b\u578b\u96c6\u6210\u5230\u73b0\u6709\u5de5\u5177\u4e2d\uff0c\u6269\u5c55\u4e86\u68c0\u6d4b\u80fd\u529b", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u5730\u81ea\u52a8\u68c0\u6d4b\u548c\u5206\u7c7b\u52a0\u5bc6API\u6ee5\u7528\uff0c\u6784\u5efa\u66f4\u5168\u9762\u7684\u5206\u7c7b\u7cfb\u7edf\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u5b89\u5168\u5de5\u5177\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u8ddf\u8e2a\u548c\u7406\u89e3\u65b0\u5174\u6ee5\u7528\u6a21\u5f0f\u7684\u80fd\u529b"}}
{"id": "2509.11787", "categories": ["cs.SE", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.11787", "abs": "https://arxiv.org/abs/2509.11787", "authors": ["Pascal Joos", "Islem Bouzenia", "Michael Pradel"], "title": "CodeCureAgent: Automatic Classification and Repair of Static Analysis Warnings", "comment": null, "summary": "Static analysis tools are widely used to detect bugs, vulnerabilities, and\ncode smells. Traditionally, developers must resolve these warnings manually.\nBecause this process is tedious, developers sometimes ignore warnings, leading\nto an accumulation of warnings and a degradation of code quality. This paper\npresents CodeCureAgent, an approach that harnesses LLM-based agents to\nautomatically analyze, classify, and repair static analysis warnings. Unlike\nprevious work, our method does not follow a predetermined algorithm. Instead,\nwe adopt an agentic framework that iteratively invokes tools to gather\nadditional information from the codebase (e.g., via code search) and edit the\ncodebase to resolve the warning. CodeCureAgent detects and suppresses false\npositives, while fixing true positives when identified. We equip CodeCureAgent\nwith a three-step heuristic to approve patches: (1) build the project, (2)\nverify that the warning disappears without introducing new warnings, and (3)\nrun the test suite. We evaluate CodeCureAgent on a dataset of 1,000 SonarQube\nwarnings found in 106 Java projects and covering 291 distinct rules. Our\napproach produces plausible fixes for 96.8% of the warnings, outperforming\nstate-of-the-art baseline approaches by 30.7% and 29.2% in plausible-fix rate,\nrespectively. Manual inspection of 291 cases reveals a correct-fix rate of\n86.3%, showing that CodeCureAgent can reliably repair static analysis warnings.\nThe approach incurs LLM costs of about 2.9 cents (USD) and an end-to-end\nprocessing time of about four minutes per warning. We envision CodeCureAgent\nhelping to clean existing codebases and being integrated into CI/CD pipelines\nto prevent the accumulation of static analysis warnings.", "AI": {"tldr": "CodeCureAgent\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\uff0c\u80fd\u591f\u81ea\u52a8\u5206\u6790\u3001\u5206\u7c7b\u548c\u4fee\u590d\u9759\u6001\u5206\u6790\u8b66\u544a\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u57281000\u4e2aSonarQube\u8b66\u544a\u4e2d\u5b9e\u73b0\u4e8696.8%\u7684\u5408\u7406\u4fee\u590d\u7387\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u5206\u6790\u5de5\u5177\u9700\u8981\u5f00\u53d1\u8005\u624b\u52a8\u5904\u7406\u8b66\u544a\uff0c\u8fc7\u7a0b\u7e41\u7410\u5bfc\u81f4\u8b66\u544a\u79ef\u7d2f\u548c\u4ee3\u7801\u8d28\u91cf\u4e0b\u964d\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u8fed\u4ee3\u8c03\u7528\u5de5\u5177\u6536\u96c6\u4ee3\u7801\u5e93\u4fe1\u606f\u5e76\u7f16\u8f91\u4ee3\u7801\u4fee\u590d\u8b66\u544a\uff0c\u5305\u542b\u4e09\u6b65\u542f\u53d1\u5f0f\u8865\u4e01\u6279\u51c6\u6d41\u7a0b\uff1a\u6784\u5efa\u9879\u76ee\u3001\u9a8c\u8bc1\u8b66\u544a\u6d88\u5931\u4e14\u65e0\u65b0\u8b66\u544a\u3001\u8fd0\u884c\u6d4b\u8bd5\u5957\u4ef6\u3002", "result": "\u5728106\u4e2aJava\u9879\u76ee\u76841000\u4e2aSonarQube\u8b66\u544a\u4e0a\uff0c\u5b9e\u73b0\u4e8696.8%\u7684\u5408\u7406\u4fee\u590d\u7387\uff0c\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u5206\u522b\u9ad8\u51fa30.7%\u548c29.2%\uff0c\u6b63\u786e\u4fee\u590d\u7387\u8fbe86.3%\uff0c\u6bcf\u4e2a\u8b66\u544a\u5904\u7406\u6210\u672c\u7ea62.9\u7f8e\u5206\uff0c\u8017\u65f6\u7ea64\u5206\u949f\u3002", "conclusion": "CodeCureAgent\u80fd\u53ef\u9760\u4fee\u590d\u9759\u6001\u5206\u6790\u8b66\u544a\uff0c\u53ef\u7528\u4e8e\u6e05\u7406\u73b0\u6709\u4ee3\u7801\u5e93\u5e76\u96c6\u6210\u5230CI/CD\u7ba1\u9053\u4e2d\u9632\u6b62\u8b66\u544a\u79ef\u7d2f\u3002"}}
{"id": "2509.11253", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11253", "abs": "https://arxiv.org/abs/2509.11253", "authors": ["Xiao Liang", "Bangxin Li", "Zixuan Chen", "Hanyue Zheng", "Zhi Ma", "Di Wang", "Cong Tian", "Quan Wang"], "title": "VideoAgent: Personalized Synthesis of Scientific Videos", "comment": null, "summary": "Automating the generation of scientific videos is a crucial yet challenging\ntask for effective knowledge dissemination. However, existing works on document\nautomation primarily focus on static media such as posters and slides, lacking\nmechanisms for personalized dynamic orchestration and multimodal content\nsynchronization. To address these challenges, we introduce VideoAgent, a novel\nmulti-agent framework that synthesizes personalized scientific videos through a\nconversational interface. VideoAgent parses a source paper into a fine-grained\nasset library and, guided by user requirements, orchestrates a narrative flow\nthat synthesizes both static slides and dynamic animations to explain complex\nconcepts. To enable rigorous evaluation, we also propose SciVidEval, the first\ncomprehensive suite for this task, which combines automated metrics for\nmultimodal content quality and synchronization with a Video-Quiz-based human\nevaluation to measure knowledge transfer. Extensive experiments demonstrate\nthat our method significantly outperforms existing commercial scientific video\ngeneration services and approaches human-level quality in scientific\ncommunication.", "AI": {"tldr": "VideoAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u8bdd\u754c\u9762\u81ea\u52a8\u751f\u6210\u4e2a\u6027\u5316\u7684\u79d1\u5b66\u89c6\u9891\uff0c\u5c06\u8bba\u6587\u89e3\u6790\u4e3a\u7ec6\u7c92\u5ea6\u8d44\u6e90\u5e93\uff0c\u5e76\u7f16\u6392\u53d9\u4e8b\u6d41\u7a0b\u6765\u5408\u6210\u9759\u6001\u5e7b\u706f\u7247\u548c\u52a8\u6001\u52a8\u753b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5546\u4e1a\u79d1\u5b66\u89c6\u9891\u751f\u6210\u670d\u52a1\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u6863\u81ea\u52a8\u5316\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u5a92\u4f53\uff08\u5982\u6d77\u62a5\u548c\u5e7b\u706f\u7247\uff09\uff0c\u7f3a\u4e4f\u4e2a\u6027\u5316\u52a8\u6001\u7f16\u6392\u548c\u591a\u6a21\u6001\u5185\u5bb9\u540c\u6b65\u673a\u5236\uff0c\u96be\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u79d1\u5b66\u77e5\u8bc6\u4f20\u64ad\u3002", "method": "\u63d0\u51faVideoAgent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u6790\u6e90\u8bba\u6587\u521b\u5efa\u7ec6\u7c92\u5ea6\u8d44\u6e90\u5e93\uff0c\u6839\u636e\u7528\u6237\u9700\u6c42\u7f16\u6392\u53d9\u4e8b\u6d41\u7a0b\uff0c\u5408\u6210\u9759\u6001\u5e7b\u706f\u7247\u548c\u52a8\u6001\u52a8\u753b\uff1b\u540c\u65f6\u5f00\u53d1SciVidEval\u8bc4\u4f30\u5957\u4ef6\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u5185\u5bb9\u8d28\u91cf\u81ea\u52a8\u6307\u6807\u548c\u57fa\u4e8e\u89c6\u9891\u6d4b\u9a8c\u7684\u4eba\u5de5\u8bc4\u4f30\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5546\u4e1a\u79d1\u5b66\u89c6\u9891\u751f\u6210\u670d\u52a1\uff0c\u5728\u79d1\u5b66\u4f20\u64ad\u65b9\u9762\u8fbe\u5230\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u7684\u8d28\u91cf\u3002", "conclusion": "VideoAgent\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u79d1\u5b66\u89c6\u9891\u81ea\u52a8\u751f\u6210\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u4e2a\u6027\u5316\u52a8\u6001\u7f16\u6392\u548c\u591a\u6a21\u6001\u5185\u5bb9\u540c\u6b65\uff0c\u4e3a\u79d1\u5b66\u77e5\u8bc6\u4f20\u64ad\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10823", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.10823", "abs": "https://arxiv.org/abs/2509.10823", "authors": ["Yury Yanovich", "Sergey Sobolev", "Yash Madhwal", "Kirill Ziborov", "Vladimir Gorgadze", "Victoria Kovalevskay", "Elizaveta Smirnova", "Matvey Mishuris", "Subodh Sharma"], "title": "From Paradigm Shift to Audit Rift: Exploring Vulnerabilities and Audit Tips for TON Smart Contracts", "comment": null, "summary": "The Open Network (TON) is a high-performance blockchain platform designed for\nscalability and efficiency, leveraging an asynchronous execution model and a\nmulti-layered architecture. While TON's design offers significant advantages,\nit also introduces unique challenges for smart contract development and\nsecurity. This paper introduces a comprehensive audit checklist for TON smart\ncontracts, based on an analysis of 34 professional audit reports containing 233\nreal-world vulnerabilities. The checklist addresses TON-specific challenges,\nsuch as asynchronous message handling, and provides actionable insights for\ndevelopers and auditors. We also present detailed case studies of\nvulnerabilities in TON smart contracts, highlighting their implications and\noffering lessons learned. By adopting this checklist, developers and auditors\ncan systematically identify and mitigate vulnerabilities, enhancing the\nsecurity and reliability of TON-based projects. Our work bridges the gap\nbetween Ethereum's mature audit methodologies and the emerging needs of the TON\necosystem, fostering a more secure and robust blockchain environment.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4e3aTON\u667a\u80fd\u5408\u7ea6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8e233\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u5206\u6790\u7684\u5168\u9762\u5ba1\u8ba1\u68c0\u67e5\u6e05\u5355\uff0c\u4ee5\u5e94\u5bf9\u5f02\u6b65\u6267\u884c\u6a21\u578b\u5e26\u6765\u7684\u5b89\u5168\u6311\u6218\u3002", "motivation": "TON\u9ad8\u6027\u80fd\u533a\u5757\u94fe\u8bbe\u8ba1\u5e26\u6765\u4e86\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u548c\u5b89\u5168\u6027\u65b0\u6311\u6218\uff0c\u9700\u8981\u4ece\u4ee5\u592a\u574a\u6210\u719f\u5ba1\u8ba1\u65b9\u6cd5\u8fc1\u79fb\u5230TON\u751f\u6001\u7cfb\u7edf\u3002", "method": "\u5206\u679034\u4efd\u4e13\u4e1a\u5ba1\u8ba1\u62a5\u544a\u4e2d\u7684233\u4e2a\u771f\u5b9e\u6f0f\u6d1e\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u5ba1\u8ba1\u68c0\u67e5\u6e05\u5355\uff0c\u5305\u62ec\u5f02\u6b65\u6d88\u606f\u5904\u7406\u7b49TON\u7279\u6709\u95ee\u9898\u3002", "result": "\u8bc6\u522b\u4e86TON\u667a\u80fd\u5408\u7ea6\u7684\u5177\u4f53\u6f0f\u6d1e\u7c7b\u578b\uff0c\u63d0\u4f9b\u4e86\u8be6\u7ec6\u6848\u4f8b\u7814\u7a76\u548c\u5b9e\u8df5\u5efa\u8bae\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u5ba1\u8ba1\u4eba\u5458\u63d0\u4f9b\u7cfb\u7edf\u5316\u7684\u5b89\u5168\u68c0\u67e5\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u68c0\u67e5\u6e05\u5355\u6709\u52a9\u4e8e\u7cfb\u7edf\u6027\u5730\u53d1\u73b0\u548c\u51cf\u8f7b\u6f0f\u6d1e\uff0c\u63d0\u5347TON\u57fa\u7840\u9879\u76ee\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u4fc3\u8fdb\u575a\u56fa\u7684\u533a\u5757\u94fe\u73af\u5883\u53d1\u5c55\u3002"}}
{"id": "2509.11937", "categories": ["cs.SE", "cs.AI", "D.2.0; E.m"], "pdf": "https://arxiv.org/pdf/2509.11937", "abs": "https://arxiv.org/abs/2509.11937", "authors": ["Alexandre Sallinen", "Stefan Krsteski", "Paul Teiletche", "Marc-Antoine Allard", "Baptiste Lecoeur", "Michael Zhang", "Fabrice Nemo", "David Kalajdzic", "Matthias Meyer", "Mary-Anne Hartley"], "title": "MMORE: Massive Multimodal Open RAG & Extraction", "comment": "This paper was originally submitted to the CODEML workshop for ICML\n  2025. 9 pages (including references and appendices)", "summary": "We introduce MMORE, an open-source pipeline for Massive Multimodal Open\nRetrievalAugmented Generation and Extraction, designed to ingest, transform,\nand retrieve knowledge from heterogeneous document formats at scale. MMORE\nsupports more than fifteen file types, including text, tables, images, emails,\naudio, and video, and processes them into a unified format to enable downstream\napplications for LLMs. The architecture offers modular, distributed processing,\nenabling scalable parallelization across CPUs and GPUs. On processing\nbenchmarks, MMORE demonstrates a 3.8-fold speedup over single-node baselines\nand 40% higher accuracy than Docling on scanned PDFs. The pipeline integrates\nhybrid dense-sparse retrieval and supports both interactive APIs and batch RAG\nendpoints. Evaluated on PubMedQA, MMORE-augmented medical LLMs improve\nbiomedical QA accuracy with increasing retrieval depth. MMORE provides a\nrobust, extensible foundation for deploying task-agnostic RAG systems on\ndiverse, real-world multimodal data. The codebase is available at\nhttps://github.com/swiss-ai/mmore.", "AI": {"tldr": "MMORE\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7ba1\u9053\uff0c\u652f\u630115+\u79cd\u6587\u4ef6\u683c\u5f0f\u5904\u7406\uff0c\u63d0\u4f9b\u5206\u5e03\u5f0f\u5904\u7406\u80fd\u529b\uff0c\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0c\u5e76\u80fd\u63d0\u5347\u533b\u5b66\u95ee\u7b54\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f02\u6784\u591a\u6a21\u6001\u6587\u6863\u7684\u5927\u89c4\u6a21\u77e5\u8bc6\u68c0\u7d22\u548c\u5904\u7406\u95ee\u9898\uff0c\u652f\u6301LLM\u4e0b\u6e38\u5e94\u7528\uff0c\u9700\u8981\u7edf\u4e00\u7684\u5904\u7406\u7ba1\u9053\u6765\u5904\u7406\u6587\u672c\u3001\u8868\u683c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u7b49\u591a\u79cd\u683c\u5f0f\u7684\u6587\u6863\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u5206\u5e03\u5f0f\u5904\u7406\u67b6\u6784\uff0c\u652f\u6301CPU\u548cGPU\u7684\u5e76\u884c\u6269\u5c55\uff0c\u4f7f\u7528\u6df7\u5408\u7a20\u5bc6-\u7a00\u758f\u68c0\u7d22\u6280\u672f\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0fAPI\u548c\u6279\u91cfRAG\u7aef\u70b9\u3002", "result": "\u5728\u5904\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4\u5355\u8282\u70b9\u57fa\u7ebf\u5feb3.8\u500d\uff0c\u5728\u626b\u63cfPDF\u4e0a\u7684\u51c6\u786e\u7387\u6bd4Docling\u9ad840%\uff0c\u5728PubMedQA\u4e0a\u533b\u5b66LLM\u7684\u95ee\u7b54\u51c6\u786e\u6027\u968f\u68c0\u7d22\u6df1\u5ea6\u589e\u52a0\u800c\u63d0\u5347\u3002", "conclusion": "MMORE\u4e3a\u5728\u591a\u6837\u5316\u771f\u5b9e\u4e16\u754c\u591a\u6a21\u6001\u6570\u636e\u4e0a\u90e8\u7f72\u4efb\u52a1\u65e0\u5173\u7684RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5f3a\u5927\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\u6846\u67b6\u3002"}}
{"id": "2509.11311", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.11311", "abs": "https://arxiv.org/abs/2509.11311", "authors": ["Bingchen Wang", "Zi-Yu Khoo", "Bryan Kian Hsiang Low"], "title": "Prompts to Proxies: Emulating Human Preferences via a Compact LLM Ensemble", "comment": "Preprint of work originally submitted to AAAI 2026. Under revision\n  for resubmission to a machine learning venue", "summary": "Large language models (LLMs) have demonstrated promise in emulating\nhuman-like responses across a wide range of tasks. In this paper, we propose a\nnovel alignment framework that treats LLMs as agent proxies for human survey\nrespondents, affording a cost-effective and steerable solution to two pressing\nchallenges in the social sciences: the rising cost of survey deployment and the\ngrowing demographic imbalance in survey response data. Drawing inspiration from\nthe theory of revealed preference, we formulate alignment as a two-stage\nproblem: constructing diverse agent personas called endowments that simulate\nplausible respondent profiles, and selecting a representative subset to\napproximate a ground-truth population based on observed data. To implement the\nparadigm, we introduce P2P, a system that steers LLM agents toward\nrepresentative behavioral patterns using structured prompt engineering,\nentropy-based sampling, and regression-based selection. Unlike\npersonalization-heavy approaches, our alignment approach is\ndemographic-agnostic and relies only on aggregate survey results, offering\nbetter generalizability and parsimony. Beyond improving data efficiency in\nsocial science research, our framework offers a testbed for studying the\noperationalization of pluralistic alignment. We demonstrate the efficacy of our\napproach on real-world opinion survey datasets, showing that our aligned agent\npopulations can reproduce aggregate response patterns with high fidelity and\nexhibit substantial response diversity, even without demographic conditioning.", "AI": {"tldr": "\u4f7f\u7528LLM\u4f5c\u4e3a\u4eba\u7c7b\u8c03\u67e5\u5e94\u7b54\u8005\u7684\u4ee3\u7406\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5bf9\u9f50\u6846\u67b6\u89e3\u51b3\u793e\u4f1a\u79d1\u5b66\u8c03\u67e5\u6210\u672c\u9ad8\u548c\u4eba\u53e3\u7ed3\u6784\u5931\u8861\u95ee\u9898", "motivation": "\u89e3\u51b3\u793e\u4f1a\u79d1\u5b66\u4e2d\u8c03\u67e5\u90e8\u7f72\u6210\u672c\u4e0d\u65ad\u4e0a\u5347\u548c\u8c03\u67e5\u6570\u636e\u4eba\u53e3\u7ed3\u6784\u5931\u8861\u7684\u6311\u6218\uff0c\u63d0\u4f9b\u66f4\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51faP2P\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u3001\u57fa\u4e8e\u71b5\u7684\u91c7\u6837\u548c\u56de\u5f52\u9009\u62e9\u65b9\u6cd5\uff0c\u6784\u5efa\u591a\u6837\u5316\u7684\u4ee3\u7406\u4eba\u8bbe\u5e76\u9009\u62e9\u4ee3\u8868\u6027\u5b50\u96c6\u8fd1\u4f3c\u771f\u5b9e\u4eba\u7fa4", "result": "\u5728\u771f\u5b9e\u610f\u89c1\u8c03\u67e5\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5bf9\u9f50\u540e\u7684\u4ee3\u7406\u4eba\u7fa4\u80fd\u9ad8\u4fdd\u771f\u5ea6\u91cd\u73b0\u805a\u5408\u54cd\u5e94\u6a21\u5f0f\uff0c\u5c55\u73b0\u51fa\u5b9e\u8d28\u6027\u54cd\u5e94\u591a\u6837\u6027\uff0c\u65e0\u9700\u4eba\u53e3\u7edf\u8ba1\u6761\u4ef6", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u7684\u6570\u636e\u6548\u7387\uff0c\u8fd8\u4e3a\u7814\u7a8b\u5bf9\u9f50\u64cd\u4f5c\u5316\u63d0\u4f9b\u4e86\u5b9e\u9a8c\u5e8a\uff0c\u5177\u6709\u826f\u597d\u7684\u666e\u904d\u6027\u548c\u7b80\u6d01\u6027"}}
{"id": "2509.10838", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10838", "abs": "https://arxiv.org/abs/2509.10838", "authors": ["Rishit Agrawal", "Kunal Bhatnagar", "Andrew Do", "Ronnit Rana", "Mark Stamp"], "title": "A Comparison of Selected Image Transformation Techniques for Malware Classification", "comment": null, "summary": "Recently, a considerable amount of malware research has focused on the use of\npowerful image-based machine learning techniques, which generally yield\nimpressive results. However, before image-based techniques can be applied to\nmalware, the samples must be converted to images, and there is no\ngenerally-accepted approach for doing so. The malware-to-image conversion\nstrategies found in the literature often appear to be ad hoc, with little or no\neffort made to take into account properties of executable files. In this paper,\nwe experiment with eight distinct malware-to-image conversion techniques, and\nfor each, we test a variety of learning models. We find that several of these\nimage conversion techniques perform similarly across a range of learning\nmodels, in spite of the image conversion processes being quite different. These\nresults suggest that the effectiveness of image-based malware classification\ntechniques may depend more on the inherent strengths of image analysis\ntechniques, as opposed to the precise details of the image conversion strategy.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5b9e\u9a8c\u4e86\u516b\u79cd\u4e0d\u540c\u7684\u6076\u610f\u8f6f\u4ef6\u8f6c\u56fe\u50cf\u6280\u672f\uff0c\u53d1\u73b0\u867d\u7136\u8f6c\u6362\u65b9\u6cd5\u5dee\u5f02\u8f83\u5927\uff0c\u4f46\u5206\u7c7b\u6548\u679c\u76f8\u4f3c\uff0c\u8bf4\u660e\u56fe\u50cf\u5206\u6790\u6280\u672f\u7684\u6548\u679c\u66f4\u591a\u53d6\u51b3\u4e8e\u5176\u672c\u8eab\u5f3a\u5927\u6027\uff0c\u800c\u975e\u8f6f\u4ef6\u8f6c\u56fe\u50cf\u7684\u5177\u4f53\u7ec6\u8282\u3002", "motivation": "\u5f53\u524d\u6076\u610f\u8f6f\u4ef6\u7814\u7a76\u4e2d\u56fe\u50cf\u57fa\u4e8e\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u6548\u679c\u663e\u8457\uff0c\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u8f6f\u4ef6\u8f6c\u56fe\u50cf\u65b9\u6cd5\uff0c\u6587\u732e\u4e2d\u7684\u65b9\u6cd5\u591a\u4e3a\u968f\u673a\u6216\u8005\u6ca1\u6709\u5145\u5206\u8003\u8651\u53ef\u6267\u884c\u6587\u4ef6\u7279\u6027\u3002", "method": "\u5b9e\u9a8c\u4e86\u516b\u79cd\u4e0d\u540c\u7684\u6076\u610f\u8f6f\u4ef6\u8f6c\u6362\u4e3a\u56fe\u50cf\u7684\u6280\u672f\uff0c\u5e76\u5bf9\u6bcf\u79cd\u6280\u672f\u6d4b\u8bd5\u591a\u79cd\u5b66\u4e60\u6a21\u578b\u7684\u6548\u679c\u3002", "result": "\u53d1\u73b0\u591a\u79cd\u56fe\u50cf\u8f6c\u6362\u6280\u672f\u867d\u7136\u8fc7\u7a0b\u5dee\u5f02\u8f83\u5927\uff0c\u4f46\u5728\u5404\u79cd\u5b66\u4e60\u6a21\u578b\u4e0b\u8868\u73b0\u76f8\u4f3c\uff0c\u5206\u7c7b\u6548\u679c\u6ca1\u6709\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u56fe\u50cf\u57fa\u4e8e\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u6280\u672f\u7684\u6548\u679c\u66f4\u591a\u53d6\u51b3\u4e8e\u56fe\u50cf\u5206\u6790\u6280\u672f\u672c\u8eab\u7684\u5f3a\u5927\u6027\uff0c\u800c\u975e\u8f6f\u4ef6\u8f6c\u6362\u4e3a\u56fe\u50cf\u7684\u5177\u4f53\u65b9\u6cd5\u7ec6\u8282\u3002"}}
{"id": "2509.11942", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.11942", "abs": "https://arxiv.org/abs/2509.11942", "authors": ["Lu\u00eds F. Gomes", "Xin Zhou", "David Lo", "Rui Abreu"], "title": "VisDocSketcher: Towards Scalable Visual Documentation with Agentic Systems", "comment": null, "summary": "Visual documentation is an effective tool for reducing the cognitive barrier\ndevelopers face when understanding unfamiliar code, enabling more intuitive\ncomprehension. Compared to textual documentation, it provides a higher-level\nunderstanding of the system structure and data flow. Developers usually prefer\nvisual representations over lengthy textual descriptions for large software\nsystems. Visual documentation is both difficult to produce and challenging to\nevaluate. Manually creating it is time-consuming, and currently, no existing\napproach can automatically generate high-level visual documentation directly\nfrom code. Its evaluation is often subjective, making it difficult to\nstandardize and automate. To address these challenges, this paper presents the\nfirst exploration of using agentic LLM systems to automatically generate visual\ndocumentation. We introduce VisDocSketcher, the first agent-based approach that\ncombines static analysis with LLM agents to identify key elements in the code\nand produce corresponding visual representations. We propose a novel evaluation\nframework, AutoSketchEval, for assessing the quality of generated visual\ndocumentation using code-level metrics. The experimental results show that our\napproach can valid visual documentation for 74.4% of the samples. It shows an\nimprovement of 26.7-39.8% over a simple template-based baseline. Our evaluation\nframework can reliably distinguish high-quality (code-aligned) visual\ndocumentation from low-quality (non-aligned) ones, achieving an AUC exceeding\n0.87. Our work lays the foundation for future research on automated visual\ndocumentation by introducing practical tools that not only generate valid\nvisual representations but also reliably assess their quality.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7406LLM\u7cfb\u7edf\u7684\u81ea\u52a8\u89c6\u89c9\u6587\u6863\u751f\u6210\u65b9\u6cd5VisDocSketcher\uff0c\u80fd\u591f\u4ece\u4ee3\u7801\u751f\u621074.4%\u7684\u6709\u6548\u89c6\u89c9\u6587\u6863\uff0c\u5e76\u63d0\u51fa\u4e86\u8bc4\u4ef7\u6846\u67b6AutoSketchEval\u6765\u91cf\u5316\u8bc4\u4f30\u8d28\u91cf\u3002", "motivation": "\u89c6\u89c9\u6587\u6863\u80fd\u591f\u964d\u4f4e\u5f00\u53d1\u8005\u7406\u89e3\u4ee3\u7801\u7684\u8ba4\u77e5\u969c\u788d\uff0c\u4f46\u624b\u5de5\u521b\u5efa\u8010\u65f6\u800c\u8bc4\u4f30\u4e3b\u89c2\uff0c\u76ee\u524d\u7f3a\u4e4f\u81ea\u52a8\u751f\u6210\u9ad8\u7ea7\u89c6\u89c9\u6587\u6863\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faVisDocSketcher\u65b9\u6cd5\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u548cLLM\u4ee3\u7406\u6765\u8bc6\u522b\u4ee3\u7801\u4e2d\u7684\u5173\u952e\u5143\u7d20\u5e76\u751f\u6210\u5bf9\u5e94\u7684\u89c6\u89c9\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4e3a74.4%\u7684\u6837\u672c\u751f\u6210\u6709\u6548\u89c6\u89c9\u6587\u6863\uff0c\u6bd4\u7b80\u5355\u6a21\u677f\u57fa\u7ebf\u63d0\u9ad826.7-39.8%\u3002\u8bc4\u4f30\u6846\u67b6\u80fd\u591f\u53ef\u9760\u533a\u5206\u9ad8\u8d28\u91cf\u548c\u4f4e\u8d28\u91cf\u6587\u6863\uff0cAUC\u8d85\u8fc70.87\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u81ea\u52a8\u89c6\u89c9\u6587\u6863\u9886\u57df\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u65e2\u80fd\u751f\u6210\u6709\u6548\u89c6\u89c9\u8868\u793a\u53c8\u80fd\u53ef\u9760\u8bc4\u4f30\u8d28\u91cf\u7684\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2509.11330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11330", "abs": "https://arxiv.org/abs/2509.11330", "authors": ["Sudeshna Jana", "Manjira Sinha", "Tirthankar Dasgupta"], "title": "Decoding Plastic Toxicity: An Intelligent Framework for Conflict-Aware Relational Metapath Extraction from Scientific Abstracts", "comment": "11 pages, 6 figures, 4 tables", "summary": "The widespread use of plastics and their persistence in the environment have\nled to the accumulation of micro- and nano-plastics across air, water, and\nsoil, posing serious health risks including respiratory, gastrointestinal, and\nneurological disorders. We propose a novel framework that leverages large\nlanguage models to extract relational metapaths, multi-hop semantic chains\nlinking pollutant sources to health impacts, from scientific abstracts. Our\nsystem identifies and connects entities across diverse contexts to construct\nstructured relational metapaths, which are aggregated into a Toxicity\nTrajectory Graph that traces pollutant propagation through exposure routes and\nbiological systems. Moreover, to ensure consistency and reliability, we\nincorporate a dynamic evidence reconciliation module that resolves semantic\nconflicts arising from evolving or contradictory research findings. Our\napproach demonstrates strong performance in extracting reliable, high-utility\nrelational knowledge from noisy scientific text and offers a scalable solution\nfor mining complex cause-effect structures in domain-specific corpora.", "AI": {"tldr": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u79d1\u5b66\u6458\u8981\u4e2d\u63d0\u53d6\u5faa\u73af\u611f\u67d3\u7269\u6e90\u5230\u5065\u5eb7\u5f71\u54cd\u7684\u5173\u7cfb\u5143\u8def\u5f84\uff0c\u6784\u5efa\u6bd2\u6027\u8f68\u8ff9\u56fe\u8ffd\u8e2a\u6c61\u67d3\u7269\u4f20\u64ad\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u8bc1\u636e\u8c03\u89e3\u6a21\u5757\u786e\u4fdd\u77e5\u8bc6\u4e00\u81f4\u6027\u3002", "motivation": "\u5fae\u7c92\u5b50\u548c\u7eb3\u7c92\u5851\u6599\u5728\u73af\u5883\u4e2d\u79ef\u7d2f\u5bfc\u81f4\u4e25\u91cd\u5065\u5eb7\u98ce\u9669\uff0c\u9700\u8981\u4ece\u79d1\u5b66\u6587\u672c\u4e2d\u6316\u6398\u53ef\u9760\u7684\u56e0\u679c\u5173\u7cfb\u77e5\u8bc6\u6765\u8fdb\u884c\u98ce\u9669\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u5173\u7cfb\u5143\u8def\u5f84\uff08\u591a\u8df3\u8bed\u4e49\u94fe\uff09\uff0c\u6784\u5efa\u6bd2\u6027\u8f68\u8ff9\u56fe\u8ffd\u8e2a\u6c61\u67d3\u7269\u4f20\u64ad\uff0c\u5e76\u96c6\u6210\u52a8\u6001\u8bc1\u636e\u8c03\u89e3\u6a21\u5757\u89e3\u51b3\u8bed\u4e49\u51b2\u7a81\u3002", "result": "\u65b9\u6cd5\u5728\u4ece\u566a\u58f0\u79d1\u5b66\u6587\u672c\u4e2d\u63d0\u53d6\u53ef\u9760\u3001\u9ad8\u6548\u7528\u7684\u5173\u7cfb\u77e5\u8bc6\u65b9\u9762\u8868\u73b0\u51fa\u8270\u5f3a\u6027\u80fd\uff0c\u4e3a\u9886\u57df\u7279\u5b9a\u8bed\u6599\u5e93\u4e2d\u6316\u6398\u590d\u6742\u56e0\u679c\u7ed3\u6784\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6316\u6398\u5fae\u7c92\u5851\u6599\u6c61\u67d3\u4e0e\u5065\u5eb7\u98ce\u9669\u4e4b\u95f4\u7684\u590d\u6742\u56e0\u679c\u5173\u7cfb\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u77e5\u8bc6\u63d0\u53d6\u548c\u8bc1\u636e\u8c03\u89e3\u673a\u5236\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u73af\u5883\u6c61\u67d3\u7269\u7684\u5065\u5eb7\u5f71\u54cd\u3002"}}
{"id": "2509.10858", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10858", "abs": "https://arxiv.org/abs/2509.10858", "authors": ["Ali Habibzadeh", "Farid Feyzi", "Reza Ebrahimi Atani"], "title": "Large Language Models for Security Operations Centers: A Comprehensive Survey", "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful tools capable of\nunderstanding and generating human-like text, offering transformative potential\nacross diverse domains. The Security Operations Center (SOC), responsible for\nsafeguarding digital infrastructure, represents one of these domains. SOCs\nserve as the frontline of defense in cybersecurity, tasked with continuous\nmonitoring, detection, and response to incidents. However, SOCs face persistent\nchallenges such as high alert volumes, limited resources, high demand for\nexperts with advanced knowledge, delayed response times, and difficulties in\nleveraging threat intelligence effectively. In this context, LLMs can offer\npromising solutions by automating log analysis, streamlining triage, improving\ndetection accuracy, and providing the required knowledge in less time. This\nsurvey systematically explores the integration of generative AI and more\nspecifically LLMs into SOC workflow, providing a structured perspective on its\ncapabilities, challenges, and future directions. We believe that this survey\noffers researchers and SOC managers a broad overview of the current state of\nLLM integration within academic study. To the best of our knowledge, this is\nthe first comprehensive study to examine LLM applications in SOCs in details.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u662f\u9996\u4e2a\u7cfb\u7edf\u6027\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u8fd0\u8425\u4e2d\u5fc3\u4e2d\u5e94\u7528\u7684\u7efc\u8ff0\uff0c\u5206\u6790\u4e86LLM\u5982\u4f55\u89e3\u51b3SOC\u9762\u4e34\u7684\u9ad8\u8b66\u62a5\u91cf\u3001\u8d44\u6e90\u6709\u9650\u7b49\u6311\u6218\uff0c\u4ee5\u53ca\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u5b89\u5168\u8fd0\u8425\u4e2d\u5fc3\u4f5c\u4e3a\u7f51\u7edc\u5b89\u5168\u524d\u7ebf\uff0c\u9762\u4e34\u7740\u9ad8\u8b66\u62a5\u91cf\u3001\u8d44\u6e90\u6709\u9650\u3001\u4e13\u5bb6\u77ed\u7f3a\u3001\u54cd\u5e94\u5ef6\u8fdf\u7b49\u6311\u6218\uff0c\u9700\u8981\u65b0\u6280\u672f\u6765\u63d0\u5347\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u7cfb\u7edf\u6027\u8c03\u67e5\u7814\u7a76\uff0c\u4ece\u7ed3\u6784\u5316\u89c6\u89d2\u5206\u6790\u751f\u6210\u5f0fAI\u548cLLM\u5728SOC\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u96c6\u6210\u80fd\u529b\u3001\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "result": "\u7814\u7a76\u8bc4\u4f30\u4e86LLM\u5728\u81ea\u52a8\u5316\u65e5\u5fd7\u5206\u6790\u3001\u7b80\u5316\u5206\u6d41\u3001\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u3001\u5feb\u901f\u83b7\u53d6\u5a01\u80c1\u667a\u80fd\u77e5\u8bc6\u7b49\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u8fd9\u4efd\u7efc\u8ff0\u4e3a\u7814\u7a76\u4eba\u5458\u548cSOC\u7ba1\u7406\u8005\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u5f53\u524d\u7814\u7a76\u72b6\u6001\u6982\u89c8\uff0c\u663e\u793a\u4e86LLM\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u548c\u53d1\u5c55\u524d\u666f\u3002"}}
{"id": "2509.12021", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.12021", "abs": "https://arxiv.org/abs/2509.12021", "authors": ["Benedikt Fein", "Florian Oberm\u00fcller", "Gordon Fraser"], "title": "LitterBox+: An Extensible Framework for LLM-enhanced Scratch Static Code Analysis", "comment": "ASE 2025 Tool Demonstration Track", "summary": "Large language models (LLMs) have become an essential tool to support\ndevelopers using traditional text-based programming languages, but the\ngraphical notation of the block-based Scratch programming environment inhibits\nthe use of LLMs. To overcome this limitation, we propose the LitterBox+\nframework that extends the Scratch static code analysis tool LitterBox with the\ngenerative abilities of LLMs. By converting block-based code to a textual\nrepresentation suitable for LLMs, LitterBox+ allows users to query LLMs about\ntheir programs, about quality issues reported by LitterBox, and it allows\ngenerating code fixes. Besides offering a programmatic API for these\nfunctionalities, LitterBox+ also extends the Scratch user interface to make\nthese functionalities available directly in the environment familiar to\nlearners. The framework is designed to be easily extensible with other prompts,\nLLM providers, and new features combining the program analysis capabilities of\nLitterBox with the generative features of LLMs. We provide a screencast\ndemonstrating the tool at https://youtu.be/RZ6E0xgrIgQ.", "AI": {"tldr": "LitterBox+\u6846\u67b6\u5c06Scratch\u79ef\u6728\u7f16\u7a0b\u8f6c\u6362\u4e3a\u6587\u672c\u8868\u793a\uff0c\u7ed3\u5408LLM\u80fd\u529b\u63d0\u4f9b\u4ee3\u7801\u67e5\u8be2\u3001\u8d28\u91cf\u5206\u6790\u548c\u4fee\u590d\u5efa\u8bae\uff0c\u5e76\u96c6\u6210\u5230Scratch\u754c\u9762\u4e2d", "motivation": "\u89e3\u51b3\u79ef\u6728\u5f0f\u7f16\u7a0b\u73af\u5883Scratch\u4e2dLLM\u65e0\u6cd5\u76f4\u63a5\u5904\u7406\u56fe\u5f62\u5316\u4ee3\u7801\u7684\u95ee\u9898\uff0c\u4e3a\u5b66\u4e60\u8005\u63d0\u4f9bAI\u7f16\u7a0b\u8f85\u52a9", "method": "\u6269\u5c55LitterBox\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u5c06\u5757\u72b6\u4ee3\u7801\u8f6c\u6362\u4e3a\u9002\u5408LLM\u7684\u6587\u672c\u8868\u793a\uff0c\u63d0\u4f9bAPI\u548cUI\u96c6\u6210", "result": "\u5f00\u53d1\u51fa\u53ef\u76f4\u63a5\u5728Scratch\u73af\u5883\u4e2d\u4f7f\u7528\u7684LLM\u8f85\u52a9\u5de5\u5177\uff0c\u652f\u6301\u4ee3\u7801\u67e5\u8be2\u3001\u8d28\u91cf\u95ee\u9898\u548c\u4fee\u590d\u751f\u6210", "conclusion": "LitterBox+\u6210\u529f\u6865\u63a5\u4e86\u79ef\u6728\u7f16\u7a0b\u4e0eLLM\u6280\u672f\uff0c\u4e3a\u6559\u80b2\u7f16\u7a0b\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684AI\u8f85\u52a9\u6846\u67b6"}}
{"id": "2509.11336", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11336", "abs": "https://arxiv.org/abs/2509.11336", "authors": ["William Farlessyost", "Sebastian Oberst", "Shweta Singh"], "title": "The power of dynamic causality in observer-based design for soft sensor applications", "comment": null, "summary": "This paper introduces a novel framework for optimizing observer-based soft\nsensors through dynamic causality analysis. Traditional approaches to sensor\nselection often rely on linearized observability indices or statistical\ncorrelations that fail to capture the temporal evolution of complex systems. We\naddress this gap by leveraging liquid-time constant (LTC) networks,\ncontinuous-time neural architectures with input-dependent time constants, to\nsystematically identify and prune sensor inputs with minimal causal influence\non state estimation. Our methodology implements an iterative workflow: training\nan LTC observer on candidate inputs, quantifying each input's causal impact\nthrough controlled perturbation analysis, removing inputs with negligible\neffect, and retraining until performance degradation occurs. We demonstrate\nthis approach on three mechanistic testbeds representing distinct physical\ndomains: a harmonically forced spring-mass-damper system, a nonlinear\ncontinuous stirred-tank reactor, and a predator-prey model following the\nstructure of the Lotka-Volterra model, but with seasonal forcing and added\ncomplexity. Results show that our causality-guided pruning consistently\nidentifies minimal sensor sets that align with underlying physics while\nimproving prediction accuracy. The framework automatically distinguishes\nessential physical measurements from noise and determines when derived\ninteraction terms provide complementary versus redundant information. Beyond\ncomputational efficiency, this approach enhances interpretability by grounding\nsensor selection decisions in dynamic causal relationships rather than static\ncorrelations, offering significant benefits for soft sensing applications\nacross process engineering, ecological monitoring, and agricultural domains.", "AI": {"tldr": "\u901a\u8fc7\u52a8\u6001\u56e0\u679c\u5206\u6790\u4f18\u5316\u89c2\u6d4b\u5668\u57fa\u4e8e\u7684\u8f6f\u4ef6\u4f20\u611f\u5668\uff0c\u5229\u7528LTC\u7f51\u7edc\u8bc6\u522b\u548c\u5265\u79bb\u5bf9\u72b6\u6001\u4f30\u8ba1\u56e0\u679c\u5f71\u54cd\u6700\u5c0f\u7684\u4f20\u611f\u5668\u8f93\u5165\uff0c\u5b9e\u73b0\u66f4\u7cbe\u7b80\u3001\u66f4\u51c6\u786e\u7684\u4f20\u611f\u5668\u9009\u62e9\u3002", "motivation": "\u4f20\u7edf\u4f20\u611f\u5668\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u7ebf\u6027\u89c2\u6d4b\u6027\u6307\u6570\u6217\u7edf\u8ba1\u76f8\u5173\u6027\uff0c\u65e0\u6cd5\u6293\u53d6\u590d\u6742\u7cfb\u7edf\u7684\u65f6\u95f4\u6f14\u5316\u7279\u5f81\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5206\u6790\u52a8\u6001\u56e0\u679c\u5173\u7cfb\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6db2\u4f53\u65f6\u95f4\u5e38\u6570(LTC)\u7f51\u7edc\uff0c\u901a\u8fc7\u8fed\u4ee3\u5de5\u4f5c\u6d41\uff1a\u8bad\u7ec3LTC\u89c2\u6d4b\u5668\u3001\u901a\u8fc7\u53d7\u63a7\u6270\u52a8\u5206\u6790\u91cf\u5316\u8f93\u5165\u56e0\u679c\u5f71\u54cd\u3001\u79fb\u9664\u53ef\u5ffd\u7565\u8f93\u5165\u3001\u91cd\u65b0\u8bad\u7ec3\u76f4\u5230\u6027\u80fd\u4e0b\u964d\u3002\u5728\u4e09\u4e2a\u673a\u68b0\u7cfb\u7edf\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u3002", "result": "\u56e0\u679c\u5bfc\u5411\u7684\u5265\u79bb\u80fd\u4e00\u81f4\u8bc6\u522b\u51fa\u4e0e\u57fa\u7840\u7269\u7406\u4e00\u81f4\u7684\u6700\u5c0f\u4f20\u611f\u5668\u96c6\uff0c\u540c\u65f6\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u80fd\u591f\u81ea\u52a8\u533a\u5206\u5fc5\u8981\u7269\u7406\u6d4b\u91cf\u4e0e\u566a\u58f0\uff0c\u5224\u65ad\u6d3e\u751f\u4ea4\u4e92\u9879\u7684\u8865\u5145\u6027\u4e0e\u5197\u4f59\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u57fa\u4e8e\u52a8\u6001\u56e0\u679c\u5173\u7cfb\u800c\u975e\u9759\u6001\u76f8\u5173\u6027\u6765\u57fa\u7840\u4f20\u611f\u5668\u9009\u62e9\u51b3\u7b56\uff0c\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u5728\u8fc7\u7a0b\u5de5\u7a0b\u3001\u751f\u6001\u76d1\u6d4b\u548c\u519c\u4e1a\u9886\u57df\u7684\u8f6f\u4ef6\u4f20\u611f\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2509.10895", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10895", "abs": "https://arxiv.org/abs/2509.10895", "authors": ["Fabian B\u00e4umer", "Marcel Maehren", "Marcus Brinkmann", "J\u00f6rg Schwenk"], "title": "Finding SSH Strict Key Exchange Violations by State Learning", "comment": "15 pages, 7 figures, accepted at ACM CCS 2025", "summary": "SSH is an important protocol for secure remote shell access to servers on the\nInternet. At USENIX 2024, B\\\"aumer et al. presented the Terrapin attack on SSH,\nwhich relies on the attacker injecting optional messages during the key\nexchange. To mitigate this attack, SSH vendors adopted an extension developed\nby OpenSSH called strict key exchange (\"strict KEX\"). With strict KEX, optional\nmessages are forbidden during the handshake, preventing the attack. In\npractice, this should simplify the state machine of an SSH handshake to a\nlinear message flow similar to that of TLS.\n  In this work, we analyze the design, implementation, and security of strict\nKEX in popular SSH servers, using black-box state learning, which can uncover\nthe hidden state machine of an implementation. In practice, it is limited by\nthe number of learned messages and the complexity of the state machine. Thus,\nlearning the complete state machine of SSH is infeasible. Previous research on\nSSH, therefore, excluded optional messages, learning only a partial state\nmachine. However, these messages are a critical part of the Terrapin attack. We\npropose to instead learn the complete state machine of the handshake phase of\nan SSH server, but with strict KEX enabled.\n  We investigate the security of ten SSH implementations supporting strict KEX\nfor up to five key exchange algorithms. In total, we learn 33 state machines,\nrevealing significant differences in the implementations. We show that seven\nimplementations violate the strict KEX specification and find two critical\nsecurity vulnerabilities. One results in a rogue session attack in the\nproprietary Tectia SSH implementation. Another affects the official SSH\nimplementation of the Erlang Open Telecom Platform, and enables unauthenticated\nremote code execution in the security context of the SSH server.", "AI": {"tldr": "\u5206\u6790SSH\u4e25\u683c\u5bc6\u94a5\u4ea4\u6362(strict KEX)\u5b9e\u73b0\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u591a\u4e2a\u5b9e\u73b0\u8fdd\u53cd\u89c4\u8303\u5e76\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u5305\u62ecTectia SSH\u7684\u6076\u610f\u4f1a\u8bdd\u653b\u51fb\u548cErlang SSH\u7684\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\u6f0f\u6d1e\u3002", "motivation": "SSH\u534f\u8bae\u5728USENIX 2024\u5e74\u906d\u53d7Terrapin\u653b\u51fb\u540e\uff0c\u5382\u5546\u91c7\u7528strict KEX\u4f5c\u4e3a\u9632\u5fa1\u63aa\u65bd\u3002\u672c\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1strict KEX\u5728\u5b9e\u9645\u5b9e\u73b0\u4e2d\u7684\u5b89\u5168\u6027\u548c\u5408\u89c4\u6027\u3002", "method": "\u4f7f\u7528\u9ed1\u76d2\u72b6\u6001\u5b66\u4e60\u6280\u672f\u5206\u679010\u4e2a\u652f\u6301strict KEX\u7684SSH\u5b9e\u73b0\uff0c\u9488\u5bf95\u79cd\u5bc6\u94a5\u4ea4\u6362\u7b97\u6cd5\u5171\u5b66\u4e6033\u4e2a\u72b6\u6001\u673a\uff0c\u68c0\u67e5\u5b9e\u73b0\u662f\u5426\u7b26\u5408\u89c4\u8303\u3002", "result": "\u53d1\u73b07\u4e2a\u5b9e\u73b0\u8fdd\u53cdstrict KEX\u89c4\u8303\uff0c\u8bc6\u522b\u51fa2\u4e2a\u5173\u952e\u5b89\u5168\u6f0f\u6d1e\uff1aTectia SSH\u7684\u6076\u610f\u4f1a\u8bdd\u653b\u51fb\u548cErlang SSH\u7684\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\u6f0f\u6d1e\u3002", "conclusion": "\u5c3d\u7ba1strict KEX\u8bbe\u8ba1\u4e0a\u80fd\u9632\u5fa1Terrapin\u653b\u51fb\uff0c\u4f46\u5b9e\u9645\u5b9e\u73b0\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u95ee\u9898\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u9a8c\u8bc1\u548c\u6d4b\u8bd5\u6765\u786e\u4fddSSH\u534f\u8bae\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2509.12087", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.12087", "abs": "https://arxiv.org/abs/2509.12087", "authors": ["Pengyu Xue", "Kunwu Zheng", "Zhen Yang", "Yifei Pei", "Linhao Wu", "Jiahui Dong", "Xiapu Luo", "Yan Xiao", "Fei Liu", "Yuxuan Zhang", "Xiran Lyu", "Xianhang Li", "Xuanyu Zhu", "Chengyi Wang"], "title": "A New Benchmark for Evaluating Code Translation with Third-Party Libraries", "comment": null, "summary": "In recent years, Large Language Models (LLMs) have been widely studied in the\ncode translation field on the method, class, and even repository levels.\nHowever, most of these benchmarks are limited in terms of Third-Party Library\n(TPL) categories and scales, making TPL-related errors hard to expose and\nhindering the development of targeted solutions. Considering the high\ndependence (over 90%) on TPLs in practical programming, demystifying and\nanalyzing LLMs' code translation performance involving various TPLs becomes\nimperative. To address this gap, we construct TransLibEval, the first benchmark\ndedicated to library-centric code translation. It consists of 200 real-world\ntasks across Python, Java, and C++, each explicitly involving TPLs from diverse\ncategories such as data processing, machine learning, and web development, with\ncomprehensive dependency coverage and high-coverage test suites. We evaluate\nseven recent LLMs of commercial, general, and code-specialized families under\nsix translation strategies of three categories: Direct, IR-guided, and\nRetrieval-augmented. Experimental results show a dramatic performance drop\ncompared with library-free settings (average CA decline over 60%), while\ndiverse strategies demonstrate heterogeneous advantages. Furthermore, we\nanalyze 4,831 failed cases from GPT-4o, one of the State-of-the-Art (SOTA)\nLLMs, revealing numerous third-party reference errors that were obscured\npreviously. These findings highlight the unique challenges of library-centric\ntranslation and provide practical guidance for improving TPL-aware code\nintelligence.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6784\u5efa\u4e86\u7b2c\u4e00\u4e2a\u4e13\u95e8\u8bc4\u6d4b\u7b2c\u4e09\u65b9\u5e93\u4e2d\u5fc3\u4ee3\u7801\u7ffb\u8bd1\u7684\u57fa\u51c6TransLibEval\uff0c\u53d1\u73b0LLM\u5728\u6d89\u53caTPL\u7684\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff08\u5e73\u5747CA\u4e0b\u964d\u8d8560%\uff09\uff0c\u5e76\u63ed\u793a\u4e86\u4e4b\u524d\u88ab\u6fc0\u6d1e\u7684\u7b2c\u4e09\u65b9\u5f15\u7528\u9519\u8bef\u3002", "motivation": "\u5b9e\u9645\u7f16\u7a0b\u4e2d\u8fc7\u8d8590%\u7684\u4ee3\u7801\u4f9d\u8d56\u7b2c\u4e09\u65b9\u5e93\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u96c6\u5728TPL\u7c7b\u522b\u548c\u89c4\u6a21\u4e0a\u6709\u9650\uff0c\u5bfc\u81f4TPL\u76f8\u5173\u9519\u8bef\u96be\u4ee5\u66b4\u9732\uff0c\u963b\u788d\u4e86\u6709\u9488\u5bf9\u6027\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efaTransLibEval\u57fa\u51c6\uff0c\u5305\u542b200\u4e2aPython\u3001Java\u548cC++\u5b9e\u9645\u4efb\u52a1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u660e\u786e\u6d89\u53ca\u6765\u81ea\u6570\u636e\u5904\u7406\u3001\u673a\u5668\u5b66\u4e60\u3001\u7f51\u9875\u5f00\u53d1\u7b49\u591a\u6837\u7c7b\u522b\u7684TPL\uff0c\u5177\u6709\u5168\u9762\u7684\u4f9d\u8d56\u8986\u76d6\u548c\u9ad8\u8986\u76d6\u6d4b\u8bd5\u5957\u4ef6\u3002\u8bc4\u4f307\u4e2a\u6700\u65b0LLM\uff08\u5546\u4e1a\u3001\u901a\u7528\u548c\u4ee3\u7801\u4e13\u4e1a\u7cfb\u5217\uff09\u5728\u4e09\u7c7b\u516d\u79cd\u7ffb\u8bd1\u7b56\u7565\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4e0e\u65e0\u5e93\u8bbe\u7f6e\u76f8\u6bd4\uff0cLLM\u7684\u6027\u80fd\u51cf\u9000\u663e\u8457\uff08\u5e73\u5747\u4ee3\u7801\u7cbe\u786e\u5ea6\u4e0b\u964d\u8d85\u8fc760%\uff09\uff0c\u4e0d\u540c\u7b56\u7565\u5c55\u73b0\u5f02\u8d28\u4f18\u52bf\u3002\u5bf9GPT-4o\u76844,831\u4e2a\u5931\u8d25\u6848\u4f8b\u5206\u6790\u63ed\u793a\u4e86\u4f17\u591a\u4e4b\u524d\u88ab\u6fc0\u6d1e\u7684\u7b2c\u4e09\u65b9\u5f15\u7528\u9519\u8bef\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u7a81\u51fa\u4e86\u5e93\u4e2d\u5fc3\u7ffb\u8bd1\u7684\u72ec\u7279\u6311\u6218\uff0c\u4e3a\u6539\u8fdb\u5177\u6709TPL\u610f\u8bc6\u7684\u4ee3\u7801\u667a\u80fd\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\uff0c\u5e94\u91cd\u70b9\u5173\u6ce8\u7b2c\u4e09\u65b9\u5e93\u76f8\u5173\u7684\u4ee3\u7801\u7ffb\u8bd1\u95ee\u9898\u3002"}}
{"id": "2509.11361", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11361", "abs": "https://arxiv.org/abs/2509.11361", "authors": ["Yichen Han", "Bojun Liu", "Zhengpeng zhou", "Guanyu Liu", "Zeng Zhang", "Yang Yang", "Wenli Wang", "Isaac N Shi", "Yunyan", "Lewei He", "Tianyu Shi"], "title": "MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt Optimization", "comment": null, "summary": "Prompt engineering is crucial for leveraging large language models (LLMs),\nbut existing methods often rely on a single optimization trajectory, limiting\nadaptability and efficiency while suffering from narrow perspectives, gradient\nconflicts, and high computational cost. We propose MAPGD (Multi-Agent Prompt\nGradient Descent), a framework integrating multi-agent collaboration with\ngradient-based optimization. MAPGD features specialized agents for task\nclarity, example selection, format design, and stylistic refinement; semantic\ngradient coordination to resolve conflicts; bandit-based candidate selection\nfor efficient exploration-exploitation; and theoretical convergence guarantees.\nExperiments on classification, generation, and reasoning tasks show MAPGD\noutperforms single-agent and random baselines in accuracy and efficiency.\nAblations confirm the benefits of gradient fusion, agent specialization, and\nconflict resolution, providing a unified, gradient-inspired multi-agent\napproach to robust and interpretable prompt optimization.", "AI": {"tldr": "MAPGD\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u63d0\u793a\u68af\u5ea6\u4e0b\u964d\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u68af\u5ea6\u4f18\u5316\u89e3\u51b3\u4f20\u7edf\u5355\u8f68\u8ff9\u63d0\u793a\u5de5\u7a0b\u7684\u5c40\u9650\u6027\uff0c\u5728\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u4f9d\u8d56\u5355\u4e00\u4f18\u5316\u8f68\u8ff9\uff0c\u5b58\u5728\u9002\u5e94\u6027\u5dee\u3001\u6548\u7387\u4f4e\u3001\u89c6\u89d2\u72ed\u7a84\u3001\u68af\u5ea6\u51b2\u7a81\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u4f18\u5316\u6846\u67b6\u3002", "method": "MAPGD\u6574\u5408\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e0e\u68af\u5ea6\u4f18\u5316\uff0c\u5305\u542b\u4efb\u52a1\u6e05\u6670\u5ea6\u3001\u793a\u4f8b\u9009\u62e9\u3001\u683c\u5f0f\u8bbe\u8ba1\u548c\u98ce\u683c\u4f18\u5316\u7b49\u4e13\u95e8\u667a\u80fd\u4f53\uff0c\u91c7\u7528\u8bed\u4e49\u68af\u5ea6\u534f\u8c03\u89e3\u51b3\u51b2\u7a81\uff0c\u57fa\u4e8ebandit\u7684\u5019\u9009\u9009\u62e9\u5b9e\u73b0\u9ad8\u6548\u63a2\u7d22-\u5229\u7528\u5e73\u8861\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\u3002", "result": "\u5728\u5206\u7c7b\u3001\u751f\u6210\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMAPGD\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u548c\u968f\u673a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u68af\u5ea6\u878d\u5408\u3001\u667a\u80fd\u4f53\u4e13\u4e1a\u5316\u548c\u51b2\u7a81\u89e3\u51b3\u7684\u6709\u6548\u6027\u3002", "conclusion": "MAPGD\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u3001\u68af\u5ea6\u542f\u53d1\u7684\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u63d0\u793a\u4f18\u5316\uff0c\u4e3a\u63d0\u793a\u5de5\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.11006", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.11006", "abs": "https://arxiv.org/abs/2509.11006", "authors": ["M. Z. Haider", "M. Dias de Assuncao", "Kaiwen Zhang"], "title": "A Range-Based Sharding (RBS) Protocol for Scalable Enterprise Blockchain", "comment": null, "summary": "Blockchain technology offers decentralization and security but struggles with\nscalability, particularly in enterprise settings where efficiency and\ncontrolled access are paramount. Sharding is a promising solution for private\nblockchains, yet existing approaches face challenges in coordinating shards,\nensuring fault tolerance with limited nodes, and minimizing the high overhead\nof consensus mechanisms like PBFT. This paper proposes the Range-Based Sharding\n(RBS) Protocol, a novel sharding mechanism tailored for enterprise blockchains,\nimplemented on Quorum. Unlike traditional sharding models such as OmniLedger\nand non-sharding Corda framework, RBS employs a commit-reveal scheme for secure\nand unbiased shard allocation, ensuring fair validator distribution while\nreducing cross-shard transaction delays. Our approach enhances scalability by\nbalancing computational loads across shards, reducing consensus overhead, and\nimproving parallel transaction execution. Experimental evaluations demonstrate\nthat RBS achieves significantly higher throughput and lower latency compared to\nexisting enterprise sharding frameworks, making it a viable and efficient\nsolution for largescale blockchain deployments.", "AI": {"tldr": "\u57fa\u4e8e\u8303\u56f4\u7684\u5206\u7247\u534f\u8bae(RBS)\uff0c\u4e3a\u4f01\u4e1a\u533a\u5757\u94fe\u63d0\u4f9b\u9ad8\u6548\u7684\u5206\u7247\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u63d0\u9ad8\u541e\u5410\u91cf\u548c\u964d\u4f4e\u5ef6\u8fdf\u6765\u89e3\u51b3\u53ef\u6269\u5c55\u6027\u95ee\u9898", "motivation": "\u533a\u5757\u94fe\u6280\u672f\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u9047\u5230\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u73b0\u6709\u5206\u7247\u65b9\u6848\u5728\u534f\u8c03\u5206\u7247\u3001\u6545\u969c\u5bb9\u8017\u548c\u5171\u8bc6\u5f00\u9500\u65b9\u9762\u5b58\u5728\u7f3a\u9677", "method": "\u63d0\u51fa\u8303\u56f4\u57fa\u5206\u7247\u534f\u8bae(RBS)\uff0c\u91c7\u7528\u63d0\u4ea4-\u66dd\u5149\u65b9\u6848\u8fdb\u884c\u5b89\u5168\u5206\u7247\u5206\u914d\uff0c\u5728Quorum\u4e0a\u5b9e\u73b0\uff0c\u901a\u8fc7\u5747\u8861\u8ba1\u7b97\u8d1f\u8f7d\u548c\u51cf\u5c11\u8de8\u5206\u7247\u4ea4\u6613\u5ef6\u8fdf\u6765\u63d0\u9ad8\u6027\u80fd", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793aRBS\u5728\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u4f01\u4e1a\u5206\u7247\u6846\u67b6\uff0c\u9002\u5408\u5927\u89c4\u6a21\u533a\u5757\u94fe\u90e8\u7f72", "conclusion": "RBS\u534f\u8bae\u4e3a\u4f01\u4e1a\u533a\u5757\u94fe\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u5206\u7247\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6848\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898"}}
{"id": "2509.12159", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12159", "abs": "https://arxiv.org/abs/2509.12159", "authors": ["Jingyu Xiao", "Zhongyi Zhang", "Yuxuan Wan", "Yintong Huo", "Yang Liu", "Michael R. Lyu"], "title": "EfficientUICoder: Efficient MLLM-based UI Code Generation via Input and Output Token Compression", "comment": null, "summary": "Multimodal Large Language Models have demonstrated exceptional performance in\nUI2Code tasks, significantly enhancing website development efficiency. However,\nthese tasks incur substantially higher computational overhead than traditional\ncode generation due to the large number of input image tokens and extensive\noutput code tokens required. Our comprehensive study identifies significant\nredundancies in both image and code tokens that exacerbate computational\ncomplexity and hinder focus on key UI elements, resulting in excessively\nlengthy and often invalid HTML files. We propose EfficientUICoder, a\ncompression framework for efficient UI code generation with three key\ncomponents. First, Element and Layout-aware Token Compression preserves\nessential UI information by detecting element regions and constructing UI\nelement trees. Second, Region-aware Token Refinement leverages attention scores\nto discard low-attention tokens from selected regions while integrating\nhigh-attention tokens from unselected regions. Third, Adaptive Duplicate Token\nSuppression dynamically reduces repetitive generation by tracking HTML/CSS\nstructure frequencies and applying exponential penalties. Extensive experiments\nshow EfficientUICoderachieves a 55%-60% compression ratio without compromising\nwebpage quality and delivers superior efficiency improvements: reducing\ncomputational cost by 44.9%, generated tokens by 41.4%, prefill time by 46.6%,\nand inference time by 48.8% on 34B-level MLLMs. Code is available at\nhttps://github.com/WebPAI/EfficientUICoder.", "AI": {"tldr": "EfficientUICoder\u662f\u4e00\u4e2a\u9488\u5bf9UI2Code\u4efb\u52a1\u7684\u9ad8\u6548\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u5143\u7d20\u611f\u77e5\u538b\u7f29\u3001\u533a\u57df\u611f\u77e5\u7ec6\u5316\u548c\u81ea\u9002\u5e94\u91cd\u590d\u6291\u5236\uff0c\u5728\u4fdd\u6301\u7f51\u9875\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b055%-60%\u7684\u538b\u7f29\u6bd4\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u65f6\u95f4\u5f00\u9500\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728UI2Code\u4efb\u52a1\u4e2d\u8ba1\u7b97\u5f00\u9500\u5de8\u5927\uff0c\u5b58\u5728\u56fe\u50cf\u548c\u4ee3\u7801\u4ee4\u724c\u7684\u663e\u8457\u5197\u4f59\uff0c\u5bfc\u81f4\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u5173\u952eUI\u5143\u7d20\u5173\u6ce8\u4e0d\u8db3\uff0c\u4ee5\u53ca\u751f\u6210\u5197\u957f\u65e0\u6548\u7684HTML\u6587\u4ef6\u3002", "method": "\u63d0\u51fa\u4e09\u7ec4\u4ef6\u538b\u7f29\u6846\u67b6\uff1a1)\u5143\u7d20\u548c\u5e03\u5c40\u611f\u77e5\u4ee4\u724c\u538b\u7f29\uff0c\u68c0\u6d4b\u5143\u7d20\u533a\u57df\u5e76\u6784\u5efaUI\u5143\u7d20\u6811\uff1b2)\u533a\u57df\u611f\u77e5\u4ee4\u724c\u7ec6\u5316\uff0c\u5229\u7528\u6ce8\u610f\u529b\u5206\u6570\u7b5b\u9009\u91cd\u8981\u4ee4\u724c\uff1b3)\u81ea\u9002\u5e94\u91cd\u590d\u4ee4\u724c\u6291\u5236\uff0c\u52a8\u6001\u51cf\u5c11HTML/CSS\u7ed3\u6784\u91cd\u590d\u751f\u6210\u3002", "result": "\u572834B\u7ea7MLLMs\u4e0a\u5b9e\u73b055%-60%\u538b\u7f29\u6bd4\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e44.9%\uff0c\u751f\u6210\u4ee4\u724c\u51cf\u5c1141.4%\uff0c\u9884\u586b\u5145\u65f6\u95f4\u51cf\u5c1146.6%\uff0c\u63a8\u7406\u65f6\u95f4\u51cf\u5c1148.8%\uff0c\u4e14\u4e0d\u635f\u5bb3\u7f51\u9875\u8d28\u91cf\u3002", "conclusion": "EfficientUICoder\u6709\u6548\u89e3\u51b3\u4e86UI2Code\u4efb\u52a1\u4e2d\u7684\u8ba1\u7b97\u5197\u4f59\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\uff0c\u4e3a\u9ad8\u6548UI\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.11431", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.11431", "abs": "https://arxiv.org/abs/2509.11431", "authors": ["Aadil Gani Ganie"], "title": "Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications", "comment": null, "summary": "The emergence of Large Language Models (LLMs) has significantly advanced\nsolutions across various domains, from political science to software\ndevelopment. However, these models are constrained by their training data,\nwhich is static and limited to information available up to a specific date.\nAdditionally, their generalized nature often necessitates fine-tuning --\nwhether for classification or instructional purposes -- to effectively perform\nspecific downstream tasks. AI agents, leveraging LLMs as their core, mitigate\nsome of these limitations by accessing external tools and real-time data,\nenabling applications such as live weather reporting and data analysis. In\nindustrial settings, AI agents are transforming operations by enhancing\ndecision-making, predictive maintenance, and process optimization. For example,\nin manufacturing, AI agents enable near-autonomous systems that boost\nproductivity and support real-time decision-making. Despite these advancements,\nAI agents remain vulnerable to security threats, including prompt injection\nattacks, which pose significant risks to their integrity and reliability. To\naddress these challenges, this paper proposes a framework for integrating\nRole-Based Access Control (RBAC) into AI agents, providing a robust security\nguardrail. This framework aims to support the effective and scalable deployment\nof AI agents, with a focus on on-premises implementations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u89d2\u8272\u7684\u8bbf\u95ee\u63a7\u5236(RBAC)\u6846\u67b6\uff0c\u7528\u4e8e\u4fdd\u62a4AI\u4ee3\u7406\u514d\u53d7\u5b89\u5168\u5a01\u80c1\uff0c\u7279\u522b\u662f\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u4ee5\u652f\u6301AI\u4ee3\u7406\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u6709\u6548\u548c\u53ef\u6269\u5c55\u90e8\u7f72\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5b58\u5728\u8bad\u7ec3\u6570\u636e\u9759\u6001\u548c\u901a\u7528\u6027\u9650\u5236\uff0cAI\u4ee3\u7406\u867d\u7136\u901a\u8fc7\u8bbf\u95ee\u5916\u90e8\u5de5\u5177\u548c\u5b9e\u65f6\u6570\u636e\u7f13\u89e3\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u4ecd\u7136\u9762\u4e34\u5b89\u5168\u5a01\u80c1\uff0c\u7279\u522b\u662f\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u8fd9\u5bf9\u5176\u5b8c\u6574\u6027\u548c\u53ef\u9760\u6027\u6784\u6210\u91cd\u5927\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u57fa\u4e8e\u89d2\u8272\u7684\u8bbf\u95ee\u63a7\u5236(RBAC)\u5230AI\u4ee3\u7406\u4e2d\u7684\u6846\u67b6\uff0c\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u5f3a\u5927\u7684\u5b89\u5168\u9632\u62a4\u63aa\u65bd\uff0c\u7279\u522b\u5173\u6ce8\u672c\u5730\u90e8\u7f72\u7684\u5b9e\u73b0\u65b9\u6848\u3002", "result": "\u8be5\u6846\u67b6\u65e8\u5728\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u5b89\u5168\u9632\u62a4\uff0c\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u8bbf\u95ee\u548c\u6076\u610f\u653b\u51fb\uff0c\u786e\u4fddAI\u4ee3\u7406\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u53ef\u9760\u8fd0\u884c\u3002", "conclusion": "\u901a\u8fc7\u96c6\u6210RBAC\u5b89\u5168\u6846\u67b6\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3AI\u4ee3\u7406\u9762\u4e34\u7684\u5b89\u5168\u6311\u6218\uff0c\u652f\u6301AI\u4ee3\u7406\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u5b89\u5168\u3001\u6709\u6548\u548c\u53ef\u6269\u5c55\u90e8\u7f72\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u9ad8\u5ea6\u5b89\u5168\u6027\u7684\u672c\u5730\u90e8\u7f72\u573a\u666f\u4e2d\u3002"}}
{"id": "2509.11120", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11120", "abs": "https://arxiv.org/abs/2509.11120", "authors": ["Qingzhao Zhang", "Shaocheng Luo", "Z. Morley Mao", "Miroslav Pajic", "Michael K. Reiter"], "title": "SoK: How Sensor Attacks Disrupt Autonomous Vehicles: An End-to-end Analysis, Challenges, and Missed Threats", "comment": null, "summary": "Autonomous vehicles, including self-driving cars, robotic ground vehicles,\nand drones, rely on complex sensor pipelines to ensure safe and reliable\noperation. However, these safety-critical systems remain vulnerable to\nadversarial sensor attacks that can compromise their performance and mission\nsuccess. While extensive research has demonstrated various sensor attack\ntechniques, critical gaps remain in understanding their feasibility in\nreal-world, end-to-end systems. This gap largely stems from the lack of a\nsystematic perspective on how sensor errors propagate through interconnected\nmodules in autonomous systems when autonomous vehicles interact with the\nphysical world.\n  To bridge this gap, we present a comprehensive survey of autonomous vehicle\nsensor attacks across platforms, sensor modalities, and attack methods. Central\nto our analysis is the System Error Propagation Graph (SEPG), a structured\ndemonstration tool that illustrates how sensor attacks propagate through system\npipelines, exposing the conditions and dependencies that determine attack\nfeasibility. With the aid of SEPG, our study distills seven key findings that\nhighlight the feasibility challenges of sensor attacks and uncovers eleven\npreviously overlooked attack vectors exploiting inter-module interactions,\nseveral of which we validate through proof-of-concept experiments.\nAdditionally, we demonstrate how large language models (LLMs) can automate\naspects of SEPG construction and cross-validate expert analysis, showcasing the\npromise of AI-assisted security evaluation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u81ea\u4e3b\u9a7e\u9a76\u8f66\u8f68\u9053\u4e2d\u4f20\u611f\u5668\u653b\u51fb\u7684\u53ef\u884c\u6027\uff0c\u63d0\u51faSEPG\u6a21\u578b\u6765\u5206\u6790\u9519\u8bef\u4f20\u64ad\uff0c\u53d1\u73b0\u4e8611\u4e2a\u65b0\u653b\u51fb\u6e20\u9053\uff0c\u5e76\u4f7f\u7528LLM\u81ea\u52a8\u5316\u5b89\u5168\u8bc4\u4f30\u3002", "motivation": "\u81ea\u4e3b\u9a7e\u9a76\u8f66\u4f9d\u8d56\u590d\u6742\u4f20\u611f\u5668\u7cfb\u7edf\u786e\u4fdd\u5b89\u5168\uff0c\u4f46\u5b9e\u9645\u7cfb\u7edf\u4e2d\u4f20\u611f\u5668\u653b\u51fb\u7684\u53ef\u884c\u6027\u4e0e\u5f71\u54cd\u4ecd\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5206\u6790\u9519\u8bef\u4f20\u64ad\u673a\u5236\u3002", "method": "\u6784\u5efa\u7cfb\u7edf\u9519\u8bef\u4f20\u64ad\u56fe(SEPG)\u6a21\u578b\uff0c\u7cfb\u7edf\u8c03\u7814\u5404\u79cd\u5e73\u53f0\u3001\u4f20\u611f\u5668\u6a21\u6001\u548c\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u539f\u578b\u5b9e\u9a8c\u9a8c\u8bc1\u53d1\u73b0\uff0c\u5e76\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316SEPG\u6784\u5efa\u3002", "result": "\u63d0\u70bc\u51fa7\u4e2a\u5173\u4e8e\u4f20\u611f\u5668\u653b\u51fb\u53ef\u884c\u6027\u7684\u5173\u952e\u53d1\u73b0\uff0c\u53d1\u73b011\u4e2a\u4e4b\u524d\u88ab\u5ffd\u89c6\u7684\u5229\u7528\u6a21\u5757\u4ea4\u4e92\u7684\u653b\u51fb\u6e20\u9053\uff0c\u591a\u4e2a\u901a\u8fc7\u539f\u578b\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "SEPG\u6a21\u578b\u80fd\u591f\u6709\u6548\u5206\u6790\u4f20\u611f\u5668\u653b\u51fb\u5728\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u7684\u4f20\u64ad\u673a\u5236\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u8bc4\u4f30\u81ea\u52a8\u5316\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4e3a\u81ea\u4e3b\u9a7e\u9a76\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2509.11173", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.11173", "abs": "https://arxiv.org/abs/2509.11173", "authors": ["Simin Chen", "Jinjun Peng", "Yixin He", "Junfeng Yang", "Baishakhi Ray"], "title": "Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers", "comment": "This paper is accepted to S&P 2026", "summary": "Deep learning (DL) compilers are core infrastructure in modern DL systems,\noffering flexibility and scalability beyond vendor-specific libraries. This\nwork uncovers a fundamental vulnerability in their design: can an official,\nunmodified compiler alter a model's semantics during compilation and introduce\nhidden backdoors? We study both adversarial and natural settings. In the\nadversarial case, we craft benign models where triggers have no effect\npre-compilation but become effective backdoors after compilation. Tested on six\nmodels, three commercial compilers, and two hardware platforms, our attack\nyields 100% success on triggered inputs while preserving normal accuracy and\nremaining undetected by state-of-the-art detectors. The attack generalizes\nacross compilers, hardware, and floating-point settings. In the natural\nsetting, we analyze the top 100 HuggingFace models (including one with 220M+\ndownloads) and find natural triggers in 31 models. This shows that compilers\ncan introduce risks even without adversarial manipulation.\n  Our results reveal an overlooked threat: unmodified DL compilers can silently\nalter model semantics. To our knowledge, this is the first work to expose\ninherent security risks in DL compiler design, opening a new direction for\nsecure and trustworthy ML.", "AI": {"tldr": "\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u5b58\u5728\u6839\u672c\u6027\u5b89\u5168\u6f0f\u6d1e\uff0c\u80fd\u591f\u5728\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u9759\u9ed8\u6539\u53d8\u6a21\u578b\u8bed\u4e49\u5e76\u690d\u5165\u9690\u85cf\u540e\u95e8\uff0c\u653b\u51fb\u6210\u529f\u7387100%\u4e14\u65e0\u6cd5\u88ab\u73b0\u6709\u68c0\u6d4b\u5668\u53d1\u73b0", "motivation": "\u63ed\u793a\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u8bbe\u8ba1\u4e2d\u7684\u56fa\u6709\u5b89\u5168\u98ce\u9669\uff0c\u7814\u7a76\u5b98\u65b9\u672a\u4fee\u6539\u7684\u7f16\u8bd1\u5668\u662f\u5426\u80fd\u5728\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u6539\u53d8\u6a21\u578b\u8bed\u4e49\u5e76\u5f15\u5165\u9690\u85cf\u540e\u95e8", "method": "\u7814\u7a76\u5bf9\u6297\u6027\u548c\u81ea\u7136\u4e24\u79cd\u573a\u666f\uff1a\u5bf9\u6297\u573a\u666f\u4e0b\u5236\u4f5c\u826f\u6027\u6a21\u578b\uff0c\u4f7f\u89e6\u53d1\u5668\u5728\u7f16\u8bd1\u524d\u65e0\u6548\u4f46\u5728\u7f16\u8bd1\u540e\u6210\u4e3a\u6709\u6548\u540e\u95e8\uff1b\u81ea\u7136\u573a\u666f\u4e0b\u5206\u6790HuggingFace\u524d100\u4e2a\u6a21\u578b\u5bfb\u627e\u81ea\u7136\u89e6\u53d1\u5668", "result": "\u57286\u4e2a\u6a21\u578b\u30013\u4e2a\u5546\u4e1a\u7f16\u8bd1\u5668\u30012\u4e2a\u786c\u4ef6\u5e73\u53f0\u4e0a\u6d4b\u8bd5\uff0c\u653b\u51fb\u5bf9\u89e6\u53d1\u8f93\u5165\u6210\u529f\u7387100%\uff0c\u4fdd\u6301\u6b63\u5e38\u7cbe\u5ea6\u4e14\u4e0d\u88ab\u6700\u5148\u8fdb\u68c0\u6d4b\u5668\u53d1\u73b0\uff1b\u53d1\u73b031\u4e2a\u6a21\u578b\u5b58\u5728\u81ea\u7136\u89e6\u53d1\u5668", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u5373\u4f7f\u672a\u7ecf\u5bf9\u6297\u64cd\u63a7\u4e5f\u80fd\u5f15\u5165\u98ce\u9669\uff0c\u63ed\u793a\u4e86\u88ab\u5ffd\u89c6\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u4e3a\u5b89\u5168\u53ef\u4fe1\u673a\u5668\u5b66\u4e60\u5f00\u8f9f\u4e86\u65b0\u7814\u7a76\u65b9\u5411"}}
{"id": "2509.11459", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11459", "abs": "https://arxiv.org/abs/2509.11459", "authors": ["Chen Jiang", "Kofi Osei", "Sai Deepthi Yeddula", "Dongji Feng", "Wei-Shinn Ku"], "title": "Knowledge-Guided Adaptive Mixture of Experts for Precipitation Prediction", "comment": "13 pages", "summary": "Accurate precipitation forecasting is indispensable in agriculture, disaster\nmanagement, and sustainable strategies. However, predicting rainfall has been\nchallenging due to the complexity of climate systems and the heterogeneous\nnature of multi-source observational data, including radar, satellite imagery,\nand surface-level measurements. The multi-source data vary in spatial and\ntemporal resolution, and they carry domain-specific features, making it\nchallenging for effective integration in conventional deep learning models.\nPrevious research has explored various machine learning techniques for weather\nprediction; however, most struggle with the integration of data with\nheterogeneous modalities. To address these limitations, we propose an Adaptive\nMixture of Experts (MoE) model tailored for precipitation rate prediction. Each\nexpert within the model specializes in a specific modality or spatio-temporal\npattern. We also incorporated a dynamic router that learns to assign inputs to\nthe most relevant experts. Our results show that this modular design enhances\npredictive accuracy and interpretability. In addition to the modeling\nframework, we introduced an interactive web-based visualization tool that\nenables users to intuitively explore historical weather patterns over time and\nspace. The tool was designed to support decision-making for stakeholders in\nclimate-sensitive sectors. We evaluated our approach using a curated multimodal\nclimate dataset capturing real-world conditions during Hurricane Ian in 2022.\nThe benchmark results show that the Adaptive MoE significantly outperformed all\nthe baselines.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u7528\u4e8e\u964d\u6c34\u7387\u9884\u6d4b\uff0c\u89e3\u51b3\u591a\u6e90\u5f02\u6784\u6c14\u8c61\u6570\u636e\u6574\u5408\u96be\u9898\uff0c\u5728\u98d3\u98ce\u4f0a\u6069\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u964d\u6c34\u9884\u6d4b\u5bf9\u519c\u4e1a\u548c\u707e\u5bb3\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u591a\u6e90\u89c2\u6d4b\u6570\u636e\uff08\u96f7\u8fbe\u3001\u536b\u661f\u3001\u5730\u9762\u6d4b\u91cf\uff09\u5728\u65f6\u7a7a\u5206\u8fa8\u7387\u548c\u7279\u5f81\u4e0a\u5b58\u5728\u5f02\u8d28\u6027\uff0c\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u96be\u4ee5\u6709\u6548\u6574\u5408\u8fd9\u4e9b\u5f02\u6784\u6a21\u6001\u6570\u636e", "method": "\u81ea\u9002\u5e94\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff0c\u6bcf\u4e2a\u4e13\u5bb6\u4e13\u6ce8\u4e8e\u7279\u5b9a\u6a21\u6001\u6216\u65f6\u7a7a\u6a21\u5f0f\uff0c\u91c7\u7528\u52a8\u6001\u8def\u7531\u5668\u5b66\u4e60\u5c06\u8f93\u5165\u5206\u914d\u7ed9\u6700\u76f8\u5173\u7684\u4e13\u5bb6\uff0c\u5e76\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u5de5\u5177", "result": "\u57282022\u5e74\u98d3\u98ce\u4f0a\u6069\u7684\u591a\u6a21\u6001\u6c14\u5019\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u81ea\u9002\u5e94MoE\u6a21\u578b\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u6a21\u5757\u5316\u8bbe\u8ba1\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u53ef\u89c6\u5316\u5de5\u5177\u652f\u6301\u6c14\u5019\u654f\u611f\u9886\u57df\u5229\u76ca\u76f8\u5173\u8005\u7684\u51b3\u7b56\u5236\u5b9a"}}
{"id": "2509.11123", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11123", "abs": "https://arxiv.org/abs/2509.11123", "authors": ["Aditya Kulkarni", "Tamal Das", "Vivek Balachandran"], "title": "ODoQ: Oblivious DNS-over-QUIC", "comment": null, "summary": "The Domain Name System (DNS), which converts domain names to their respective\nIP addresses, has advanced enhancements aimed at safeguarding DNS data and\nusers' identity from attackers. The recent privacy-focused advancements have\nenabled the IETF to standardize several protocols. Nevertheless, these\nprotocols tend to focus on either strengthening user privacy (like Oblivious\nDNS and Oblivious DNS-over-HTTPS) or reducing resolution latency (as\ndemonstrated by DNS-over-QUIC). Achieving both within a single protocol remains\na key challenge, which we address in this paper. Our proposed protocol --\n'Oblivious DNS-over-QUIC' (ODoQ) -- leverages the benefits of the QUIC protocol\nand incorporates an intermediary proxy server to protect the client's identity\nfrom exposure to the recursive resolver.", "AI": {"tldr": "\u63d0\u51faODoQ\u534f\u8bae\uff0c\u7ed3\u5408QUIC\u534f\u8bae\u548c\u4ee3\u7406\u670d\u52a1\u5668\uff0c\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u540c\u65f6\u964d\u4f4eDNS\u89e3\u6790\u5ef6\u8fdf", "motivation": "\u73b0\u6709DNS\u9690\u79c1\u534f\u8bae\u8981\u4e48\u4fa7\u91cd\u7528\u6237\u9690\u79c1\u4fdd\u62a4\uff08\u5982Oblivious DNS\uff09\uff0c\u8981\u4e48\u4fa7\u91cd\u964d\u4f4e\u5ef6\u8fdf\uff08\u5982DNS-over-QUIC\uff09\uff0c\u7f3a\u4e4f\u540c\u65f6\u5b9e\u73b0\u4e24\u8005\u7684\u5355\u4e00\u534f\u8bae", "method": "\u8bbe\u8ba1Oblivious DNS-over-QUIC (ODoQ)\u534f\u8bae\uff0c\u5229\u7528QUIC\u534f\u8bae\u7684\u4f18\u52bf\u5e76\u5f15\u5165\u4e2d\u95f4\u4ee3\u7406\u670d\u52a1\u5668\u6765\u4fdd\u62a4\u5ba2\u6237\u7aef\u8eab\u4efd\u4e0d\u88ab\u9012\u5f52\u89e3\u6790\u5668\u66b4\u9732", "result": "\u6210\u529f\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u540c\u65f6\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u548c\u964d\u4f4e\u89e3\u6790\u5ef6\u8fdf\u7684DNS\u534f\u8bae\u65b9\u6848", "conclusion": "ODoQ\u534f\u8bae\u6709\u6548\u89e3\u51b3\u4e86DNS\u9690\u79c1\u4fdd\u62a4\u4e0e\u6027\u80fd\u4f18\u5316\u7684\u53cc\u91cd\u9700\u6c42\uff0c\u4e3aDNS\u534f\u8bae\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411"}}
{"id": "2509.11712", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.11712", "abs": "https://arxiv.org/abs/2509.11712", "authors": ["Mohammad Olid Ali Akash", "Priyangana Saha"], "title": "A Holistic Approach to E-Commerce Innovation: Redefining Security and User Experience", "comment": null, "summary": "In the modern, fast-moving world of e-commerce, many Android apps face\nchallenges in providing a simple and secure shopping experience. Many of these\napps, often enough, have complicated designs that prevent users from finding\nwhat they want quickly, thus frustrating them and wasting their precious time.\nAnother major issue is that of security; with the limitation of payment options\nand weak authentication mechanisms, users' sensitive information can be\ncompromised. This research presents a new e-commerce platform that responds to\nthe above challenges with an intuitive interface and strong security measures.\nThe platform makes online shopping easy with well-organized categories of\nproducts and a fast, efficient checkout process. It also gives priority to\nsecurity by incorporating features such as Google authentication and\nSSL-secured payment gateways to protect user data and ensure secure\ntransactions. This paper discusses how a focus on user-friendliness, security,\nand personalization steps up the game for e-commerce platforms, providing\nworkable frameworks that match modern user needs and expectations. The findings\nshow the e-commerce user experience can be remodelled by the platform, hence\nopening ways for future developments in that respect.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7535\u5b50\u5546\u52a1\u5e73\u53f0\uff0c\u901a\u8fc7\u76f4\u89c2\u754c\u9762\u548c\u5f3a\u5927\u5b89\u5168\u63aa\u65bd\u89e3\u51b3Android\u8d2d\u7269\u5e94\u7528\u7684\u590d\u6742\u6027\u548c\u5b89\u5168\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u7535\u5b50\u5546\u52a1\u5e94\u7528\u9762\u4e34\u754c\u9762\u590d\u6742\u5bfc\u81f4\u7528\u6237\u6270\u60f1\u3001\u652f\u4ed8\u9009\u62e9\u6709\u9650\u548c\u8ba4\u8bc1\u673a\u5236\u5f31\u7b49\u6311\u6218\uff0c\u9700\u8981\u63d0\u4f9b\u66f4\u7b80\u5355\u5b89\u5168\u7684\u8d2d\u7269\u4f53\u9a8c\u3002", "method": "\u5f00\u53d1\u65b0\u7684\u7535\u5546\u5e73\u53f0\uff0c\u91c7\u7528\u76f4\u89c2\u754c\u9762\u8bbe\u8ba1\u3001\u4f18\u5316\u4ea7\u54c1\u5206\u7c7b\u548c\u9ad8\u6548\u7ed3\u8d26\u6d41\u7a0b\uff0c\u5e76\u96c6\u6210Google\u8ba4\u8bc1\u548cSSL\u52a0\u5bc6\u652f\u4ed8\u7f51\u5173\u7b49\u5b89\u5168\u63aa\u65bd\u3002", "result": "\u8be5\u5e73\u53f0\u80fd\u591f\u91cd\u6784\u7535\u5546\u7528\u6237\u4f53\u9a8c\uff0c\u63d0\u4f9b\u66f4\u7b80\u5355\u5b89\u5168\u7684\u5728\u7ebf\u8d2d\u7269\u73af\u5883\uff0c\u4e3a\u672a\u6765\u53d1\u5c55\u6253\u4e0b\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u91cd\u70b9\u5173\u6ce8\u7528\u6237\u53cb\u597d\u6027\u3001\u5b89\u5168\u6027\u548c\u4e2a\u6027\u5316\u9700\u6c42\uff0c\u53ef\u4ee5\u63d0\u5347\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u7684\u7ade\u4e89\u529b\uff0c\u6ee1\u8db3\u73b0\u4ee3\u7528\u6237\u7684\u671f\u671b\u3002"}}
{"id": "2509.11480", "categories": ["cs.AI", "cs.CV", "cs.ET", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.11480", "abs": "https://arxiv.org/abs/2509.11480", "authors": ["Amir Taherin", "Juyi Lin", "Arash Akbari", "Arman Akbari", "Pu Zhao", "Weiwei Chen", "David Kaeli", "Yanzhi Wang"], "title": "Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs", "comment": "To appear in the Asilomar Conference on Signals, Systems, and\n  Computers 2025", "summary": "Vision-Language-Action (VLA) models have emerged as powerful generalist\npolicies for robotic control, yet their performance scaling across model\narchitectures and hardware platforms, as well as their associated power\nbudgets, remain poorly understood. This work presents an evaluation of five\nrepresentative VLA models -- spanning state-of-the-art baselines and two newly\nproposed architectures -- targeting edge and datacenter GPU platforms. Using\nthe LIBERO benchmark, we measure accuracy alongside system-level metrics,\nincluding latency, throughput, and peak memory usage, under varying edge power\nconstraints and high-performance datacenter GPU configurations. Our results\nidentify distinct scaling trends: (1) architectural choices, such as action\ntokenization and model backbone size, strongly influence throughput and memory\nfootprint; (2) power-constrained edge devices exhibit non-linear performance\ndegradation, with some configurations matching or exceeding older datacenter\nGPUs; and (3) high-throughput variants can be achieved without significant\naccuracy loss. These findings provide actionable insights when selecting and\noptimizing VLAs across a range of deployment constraints. Our work challenges\ncurrent assumptions about the superiority of datacenter hardware for robotic\ninference.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8bc4\u4f30\u4e865\u79cd\u4ee3\u8868\u6027VLA\u6a21\u578b\u5728\u8fb9\u7f18\u548c\u6570\u636e\u4e2d\u5fc3GPU\u5e73\u53f0\u7684\u6027\u80fd\u6269\u5c55\u3001\u7cfb\u7edf\u6307\u6807\u548c\u529f\u8017\u60c5\u51b5\uff0c\u53d1\u73b0\u67b6\u6784\u9009\u62e9\u548c\u529f\u8017\u7ea6\u675f\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u6316\u6398\u4e86\u9ad8\u541e\u5411\u91cf\u4f18\u5316\u6f5c\u529b\u3002", "motivation": "VLA\u6a21\u578b\u4f5c\u4e3a\u673a\u5668\u4eba\u63a7\u5236\u7684\u901a\u7528\u7b56\u7565\u5f3a\u5927\u4f46\u6027\u80fd\u6269\u5c55\u7279\u6027\u3001\u786c\u4ef6\u5e73\u53f0\u9002\u914d\u6027\u548c\u529f\u8017\u9884\u7b97\u4ecd\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u8bc4\u4f30\u4ee5\u63d0\u4f9b\u90e8\u7f72\u9009\u62e9\u4f18\u5316\u6307\u5357\u3002", "method": "\u4f7f\u7528LIBERO\u57fa\u51c6\u6d4b\u8bd55\u79cd\u4ee3\u8868\u6027VLA\u6a21\u578b\uff08\u5305\u62ec\u72ec\u521b\u67b6\u6784\uff09\uff0c\u5728\u8fb9\u7f18\u529f\u8017\u7ea6\u675f\u548c\u9ad8\u6027\u80fd\u6570\u636e\u4e2d\u5fc3GPU\u914d\u7f6e\u4e0b\u6d4b\u91cf\u51c6\u786e\u7387\u3001\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u3001\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u7b49\u7cfb\u7edf\u7ea7\u6307\u6807\u3002", "result": "\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u8d8b\u52bf\uff1a1\uff09\u67b6\u6784\u9009\u62e9\u5982\u52a8\u4f5c\u6807\u8bb0\u5316\u548c\u6a21\u578b\u80cc\u699c\u5927\u5c0f\u5f3a\u529b\u5f71\u54cd\u541e\u5410\u91cf\u548c\u5185\u5b58\u5360\u7528\uff1b2\uff09\u529f\u8017\u7ea6\u675f\u8fb9\u7f18\u8bbe\u5907\u5b58\u5728\u975e\u7ebf\u6027\u6027\u80fd\u6cc4\u6ea2\uff0c\u67d0\u4e9b\u914d\u7f6e\u6027\u80fd\u8d85\u8fc7\u65e7\u7248\u6570\u636e\u4e2d\u5fc3GPU\uff1b3\uff09\u53ef\u4ee5\u5728\u4e0d\u4e25\u91cd\u635f\u5931\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u9ad8\u541e\u5410\u91cf\u53d8\u4f53\u3002", "conclusion": "\u7814\u7a76\u7ed9\u51fa\u4e86\u5728\u4e0d\u540c\u90e8\u7f72\u7ea6\u675f\u4e0b\u9009\u62e9\u548c\u4f18\u5316VLA\u6a21\u578b\u7684\u53ef\u884c\u6027\u5efa\u8bae\uff0c\u5e76\u6311\u6218\u4e86\u5f53\u524d\u8ba4\u4e3a\u6570\u636e\u4e2d\u5fc3\u786c\u4ef6\u5728\u673a\u5668\u4eba\u63a8\u7406\u4e2d\u4f18\u52bf\u7684\u5047\u8bbe\u3002"}}
{"id": "2509.11158", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11158", "abs": "https://arxiv.org/abs/2509.11158", "authors": ["Qianxue Wang", "Simin Yu"], "title": "Cryptanalysis and design for a family of plaintext non-delayed chaotic ciphers", "comment": null, "summary": "Plaintext non-delayed chaotic cipher (PNDCC) means that in the diffusion\nequation, plaintext has no delay terms while ciphertext has a feedback term. In\nexisting literature, chaotic cipher diffusions invariably take this form. Since\nits introduction, PNDCC has attracted attention but also doubts. Designers of\nchaotic ciphers usually claim PNDCC security by statistical tests, while\nrigorous cryptographic proofs are absent. Thus, it is necessary to re-examine\nits design rationale and empirical security. To address this issue, we present\na typical example of a three-stage permutation-diffusion-permutation PNDCC,\nwhich contains multiple security vulnerabilities. Although all of its\nstatistical indicators show good performance, we are able to break it using\nfour different attacks. The first is a differential attack based on homogeneous\noperations; the second is an S-PTC attack; the third is a novel\nimpulse-step-based differential attack (ISBDA), proposed in this paper, and the\nfourth is a novel chain attack, also introduced here. These results demonstrate\nthat the fulfilment of statistical criteria is not a sufficient condition for\nthe security of PNDCC. Then, based on a mathematical model of multi-stage\nPNDCC, we show that the proposed chain attack can successfully break a class of\nmulti-stage PNDCCs. The key technique of the chain attack depends on how to\nreveal all permutations. To address this key problem, we summarize the chaining\nrules and show that, from the attacker's perspective, if the same decryption\nchain can be reconstructed then all permutations can be deciphered. To that\nend, the entire diffusion process can be broken by solving a system of\nsimultaneous equations. Finally, as a secure improvement, we propose a new\nscheme termed plaintext-delayed chaotic cipher (PDCC) that can resist various\ncryptanalytic attacks.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u56db\u79cd\u653b\u51fb\u65b9\u6cd5\u7834\u89e3\u4e86\u4e00\u79cd\u5178\u578b\u7684\u4e09\u9636\u6bb5\u7f6e\u6362-\u6e0c\u6563-\u7f6e\u6362PNDCC\u5bc6\u7801\uff0c\u8bc1\u660e\u7edf\u8ba1\u6307\u6807\u4e0d\u80fd\u4fdd\u8bc1\u5b89\u5168\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u7684PDCC\u65b9\u6848\u3002", "motivation": "\u5bf9\u5e73\u6587\u65e0\u5ef6\u8fdf\u6df7\u6d8c\u52a8\u5bc6\u7801(PNDCC)\u7684\u8bbe\u8ba1\u7406\u5ff5\u548c\u5b9e\u8df5\u5b89\u5168\u6027\u8fdb\u884c\u91cd\u65b0\u5ba1\u89c6\uff0c\u56e0\u4e3a\u73b0\u6709\u6587\u732e\u4e2d\u7f3a\u4e4f\u4e25\u683c\u7684\u5bc6\u7801\u5b66\u8bc1\u660e\u800c\u4ec5\u4f9d\u9760\u7edf\u8ba1\u6d4b\u8bd5\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u79cd\u653b\u51fb\u65b9\u6cd5\uff1a\u57fa\u4e8e\u5747\u8d28\u64cd\u4f5c\u7684\u5dee\u5206\u653b\u51fb\u3001S-PTC\u653b\u51fb\u3001\u65b0\u9898\u51b2\u51fb-\u6b65\u8fdb\u57fa\u4e8e\u5dee\u5206\u653b\u51fb(ISBDA)\u548c\u94fe\u5f0f\u653b\u51fb\uff0c\u5e76\u5efa\u7acb\u4e86\u591a\u9636\u6bb5PNDCC\u7684\u6570\u5b66\u6a21\u578b\u3002", "result": "\u6210\u529f\u7834\u89e3\u4e86\u6240\u6709\u7edf\u8ba1\u6307\u6807\u90fd\u8868\u73b0\u826f\u597d\u7684PNDCC\u5bc6\u7801\uff0c\u8bc1\u660e\u7edf\u8ba1\u6807\u51c6\u4e0d\u662f\u5b89\u5168\u6027\u7684\u5145\u5206\u6761\u4ef6\uff0c\u94fe\u5f0f\u653b\u51fb\u80fd\u591f\u7834\u89e3\u4e00\u7c7b\u591a\u9636\u6bb5PNDCC\u3002", "conclusion": "\u5efa\u8bae\u91c7\u7528\u5e73\u6587\u5ef6\u8fdf\u6df7\u6d8c\u52a8\u5bc6\u7801(PDCC)\u4f5c\u4e3a\u5b89\u5168\u6539\u8fdb\u65b9\u6848\uff0c\u80fd\u591f\u62b5\u5fa1\u5404\u79cd\u5bc6\u7801\u5206\u6790\u653b\u51fb\u3002"}}
{"id": "2509.11836", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.11836", "abs": "https://arxiv.org/abs/2509.11836", "authors": ["Kai Tan", "Dongyang Zhan", "Lin Ye", "Hongli Zhang", "Binxing Fang"], "title": "A Practical Adversarial Attack against Sequence-based Deep Learning Malware Classifiers", "comment": null, "summary": "Sequence-based deep learning models (e.g., RNNs), can detect malware by\nanalyzing its behavioral sequences. Meanwhile, these models are susceptible to\nadversarial attacks. Attackers can create adversarial samples that alter the\nsequence characteristics of behavior sequences to deceive malware classifiers.\nThe existing methods for generating adversarial samples typically involve\ndeleting or replacing crucial behaviors in the original data sequences, or\ninserting benign behaviors that may violate the behavior constraints. However,\nthese methods that directly manipulate sequences make adversarial samples\ndifficult to implement or apply in practice. In this paper, we propose an\nadversarial attack approach based on Deep Q-Network and a heuristic\nbacktracking search strategy, which can generate perturbation sequences that\nsatisfy practical conditions for successful attacks. Subsequently, we utilize a\nnovel transformation approach that maps modifications back to the source code,\nthereby avoiding the need to directly modify the behavior log sequences. We\nconduct an evaluation of our approach, and the results confirm its\neffectiveness in generating adversarial samples from real-world malware\nbehavior sequences, which have a high success rate in evading anomaly detection\nmodels. Furthermore, our approach is practical and can generate adversarial\nsamples while maintaining the functionality of the modified software.", "AI": {"tldr": "\u57fa\u4e8e\u6df1\u5ea6Q\u7f51\u7edc\u548c\u542f\u5e94\u56de\u6eaf\u641c\u7d22\u7684\u5bf9\u6267\u653b\u51fb\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u7b26\u5408\u5b9e\u9645\u6761\u4ef6\u7684\u5e72\u6270\u5e8f\u5217\uff0c\u901a\u8fc7\u6e90\u4ee3\u7801\u6620\u5c04\u907f\u514d\u76f4\u63a5\u4fee\u6539\u884c\u4e3a\u5e8f\u5217\uff0c\u6709\u6548\u907f\u514d\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u6a21\u578b", "motivation": "\u73b0\u6709\u7684\u5bf9\u6267\u6837\u672c\u751f\u6210\u65b9\u6cd5\u901a\u8fc7\u5220\u9664\u3001\u66ff\u6362\u5173\u952e\u884c\u4e3a\u6216\u63d2\u5165\u826f\u6027\u884c\u4e3a\u6765\u6539\u53d8\u5e8f\u5217\u7279\u5f81\uff0c\u4f46\u8fd9\u4e9b\u76f4\u63a5\u64cd\u63a7\u5e8f\u5217\u7684\u65b9\u6cd5\u5bfc\u81f4\u5bf9\u6267\u6837\u672c\u96be\u4ee5\u5728\u5b9e\u8df5\u4e2d\u5b9e\u65bd\u6216\u5e94\u7528", "method": "\u4f7f\u7528\u6df1\u5ea6Q\u7f51\u7edc(Deep Q-Network)\u548c\u542f\u5e94\u56de\u6eaf\u641c\u7d22\u7b56\u7565\u6765\u751f\u6210\u7b26\u5408\u5b9e\u9645\u6761\u4ef6\u7684\u5e72\u6270\u5e8f\u5217\uff0c\u7136\u540e\u901a\u8fc7\u65b0\u9898\u7684\u8f6c\u6362\u65b9\u6cd5\u5c06\u4fee\u6539\u6620\u5c04\u56de\u6e90\u4ee3\u7801\uff0c\u907f\u514d\u76f4\u63a5\u4fee\u6539\u884c\u4e3a\u65e5\u5fd7\u5e8f\u5217", "result": "\u65b9\u6cd5\u80fd\u591f\u4ece\u771f\u5b9e\u4e16\u754c\u7684\u6076\u610f\u8f6f\u4ef6\u884c\u4e3a\u5e8f\u5217\u751f\u6210\u5bf9\u6267\u6837\u672c\uff0c\u5728\u907f\u514d\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u65f6\u5177\u6709\u9ad8\u6210\u529f\u7387", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u6709\u6548\uff0c\u800c\u4e14\u5b9e\u7528\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u4fee\u6539\u8f6f\u4ef6\u529f\u80fd\u7684\u540c\u65f6\u751f\u6210\u5bf9\u6267\u6837\u672c"}}
{"id": "2509.11507", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11507", "abs": "https://arxiv.org/abs/2509.11507", "authors": ["Jared Zhu", "Junde Wu"], "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "comment": null, "summary": "Decades' advances in digital health technologies, such as electronic health\nrecords, have largely streamlined routine clinical processes. Yet, most these\nsystems are still hard to learn and use: Clinicians often face the burden of\nmanaging multiple tools, repeating manual actions for each patient, navigating\ncomplicated UI trees to locate functions, and spending significant time on\nadministration instead of caring for patients. The recent rise of large\nlanguage model (LLM) based agents demonstrates exceptional capability in coding\nand computer operation, revealing the potential for humans to interact with\noperating systems and software not by direct manipulation, but by instructing\nagents through natural language. This shift highlights the need for an\nabstraction layer, an agent-computer interface, that translates human language\ninto machine-executable commands. In digital healthcare, however, requires a\nmore domain-specific abstractions that strictly follow trusted clinical\nguidelines and procedural standards to ensure safety, transparency, and\ncompliance. To address this need, we present \\textbf{MedicalOS}, a unified\nagent-based operational system designed as such a domain-specific abstract\nlayer for healthcare. It translates human instructions into pre-defined digital\nhealthcare commands, such as patient inquiry, history retrieval, exam\nmanagement, report generation, referrals, treatment planning, that we wrapped\nas off-the-shelf tools using machine languages (e.g., Python, APIs, MCP,\nLinux). We empirically validate MedicalOS on 214 patient cases across 22\nspecialties, demonstrating high diagnostic accuracy and confidence, clinically\nsound examination requests, and consistent generation of structured reports and\nmedication recommendations. These results highlight MedicalOS as a trustworthy\nand scalable foundation for advancing workflow automation in clinical practice.", "AI": {"tldr": "MedicalOS\u662f\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7406\u7684\u533b\u7597\u64cd\u4f5c\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u5c06\u4eba\u7c7b\u6307\u4ee4\u8f6c\u6362\u4e3a\u9884\u5b9a\u4e49\u7684\u533b\u7597\u547d\u4ee4\uff0c\u5b9e\u73b0\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u81ea\u52a8\u5316\u3002", "motivation": "\u73b0\u6709\u6570\u5b57\u533b\u7597\u7cfb\u7edf\u64cd\u4f5c\u590d\u6742\uff0c\u533b\u62a4\u4eba\u5458\u9700\u8981\u7ba1\u7406\u591a\u4e2a\u5de5\u5177\u3001\u91cd\u590d\u624b\u52a8\u64cd\u4f5c\uff0c\u82b1\u8d39\u5927\u91cf\u65f6\u95f4\u5728\u884c\u653f\u4e8b\u52a1\u800c\u975e\u60a3\u8005\u62a4\u7406\u4e0a\u3002LLM\u4ee3\u7406\u7684\u53d1\u5c55\u4e3a\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4e0e\u7cfb\u7edf\u4ea4\u4e92\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u4f46\u533b\u7597\u9886\u57df\u9700\u8981\u9075\u5faa\u4e34\u5e8a\u6307\u5357\u7684\u7279\u5b9a\u62bd\u8c61\u5c42\u3002", "method": "\u5f00\u53d1MedicalOS\u4f5c\u4e3a\u533b\u7597\u9886\u57df\u7279\u5b9a\u7684\u62bd\u8c61\u5c42\uff0c\u5c06\u4eba\u7c7b\u6307\u4ee4\u8f6c\u6362\u4e3a\u9884\u5b9a\u4e49\u7684\u533b\u7597\u547d\u4ee4\uff08\u5982\u60a3\u8005\u67e5\u8be2\u3001\u75c5\u53f2\u68c0\u7d22\u3001\u68c0\u67e5\u7ba1\u7406\u7b49\uff09\uff0c\u8fd9\u4e9b\u547d\u4ee4\u88ab\u5305\u88c5\u4e3a\u73b0\u6210\u5de5\u5177\u4f7f\u7528\u673a\u5668\u8bed\u8a00\uff08Python\u3001API\u3001MCP\u3001Linux\uff09\u3002", "result": "\u572822\u4e2a\u4e13\u79d1\u7684214\u4e2a\u75c5\u4f8b\u4e0a\u9a8c\u8bc1\uff0c\u663e\u793a\u51fa\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u3001\u4e34\u5e8a\u5408\u7406\u7684\u68c0\u67e5\u8bf7\u6c42\uff0c\u4ee5\u53ca\u4e00\u81f4\u7684\u7ed3\u6784\u5316\u62a5\u544a\u548c\u836f\u7269\u63a8\u8350\u751f\u6210\u3002", "conclusion": "MedicalOS\u4e3a\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u5de5\u4f5c\u6d41\u7a0b\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u4fe1\u8d56\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2509.11547", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11547", "abs": "https://arxiv.org/abs/2509.11547", "authors": ["Shanmuka Sadhu", "Arca Baran", "Preeti Pandey", "Ayush Kumar"], "title": "Task Decoding based on Eye Movements using Synthetic Data Augmentation", "comment": null, "summary": "Machine learning has been extensively used in various applications related to\neye-tracking research. Understanding eye movement is one of the most\nsignificant subsets of eye-tracking research that reveals the scanning pattern\nof an individual. Researchers have thoroughly analyzed eye movement data to\nunderstand various eye-tracking applications, such as attention mechanisms,\nnavigational behavior, task understanding, etc. The outcome of traditional\nmachine learning algorithms used for decoding tasks based on eye movement data\nhas received a mixed reaction to Yarbus' claim that it is possible to decode\nthe observer's task from their eye movements. In this paper, to support the\nhypothesis by Yarbus, we are decoding tasks categories while generating\nsynthetic data samples using well-known Synthetic Data Generators CTGAN and its\nvariations such as CopulaGAN and Gretel AI Synthetic Data generators on\navailable data from an in-person user study. Our results show that augmenting\nmore eye movement data combined with additional synthetically generated\nimproves classification accuracy even with traditional machine learning\nalgorithms. We see a significant improvement in task decoding accuracy from\n28.1% using Random Forest to 82% using Inception Time when five times more data\nis added in addition to the 320 real eye movement dataset sample. Our proposed\nframework outperforms all the available studies on this dataset because of the\nuse of additional synthetic datasets. We validated our claim with various\nalgorithms and combinations of real and synthetic data to show how decoding\naccuracy increases with the increase in the augmentation of generated data to\nreal data.", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528\u5408\u6210\u6570\u636e\u751f\u6210\u5668\uff08CTGAN\u3001CopulaGAN\u3001Gretel AI\uff09\u751f\u6210\u773c\u52a8\u6570\u636e\u6765\u652f\u6301Yarbus\u5047\u8bf4\uff0c\u8bc1\u660e\u53ef\u4ee5\u4ece\u773c\u52a8\u4e2d\u89e3\u7801\u4efb\u52a1\u7c7b\u522b\uff0c\u6570\u636e\u589e\u5e45\u540e\u5206\u7c7b\u51c6\u786e\u7387\u4ece28.1%\u63d0\u5347\u523082%", "motivation": "\u9a8c\u8bc1Yarbus\u7684\u5047\u8bf4\uff0c\u5373\u53ef\u4ee5\u901a\u8fc7\u89c2\u5bdf\u8005\u7684\u773c\u52a8\u89e3\u7801\u5176\u6267\u884c\u7684\u4efb\u52a1\uff0c\u5e76\u63d0\u9ad8\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5728\u773c\u52a8\u6570\u636e\u89e3\u7801\u4efb\u52a1\u4e2d\u7684\u6027\u80fd", "method": "\u4f7f\u7528CTGAN\u3001CopulaGAN\u548cGretel AI\u5408\u6210\u6570\u636e\u751f\u6210\u5668\u5728320\u4e2a\u771f\u5b9e\u773c\u52a8\u6570\u636e\u6837\u672c\u4e0a\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u5c06\u771f\u5b9e\u6570\u636e\u4e0e\u5408\u6210\u6570\u636e\u7ed3\u5408\u8fdb\u884c\u4efb\u52a1\u5206\u7c7b\u8bc6\u522b", "result": "\u6570\u636e\u589e\u5e45\u540e\u5206\u7c7b\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347\uff1aRandom Forest\u4ece28.1%\u63d0\u5347\u523082%\uff08Inception Time\uff09\uff0c\u4f7f\u75285\u500d\u6570\u636e\u589e\u5e45\u540e\u8fbe\u5230\u6700\u4f73\u6548\u679c", "conclusion": "\u901a\u8fc7\u5408\u6210\u6570\u636e\u589e\u5e45\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u773c\u52a8\u6570\u636e\u4efb\u52a1\u89e3\u7801\u7684\u51c6\u786e\u6027\uff0c\u5f3a\u70c8\u652f\u6301Yarbus\u5047\u8bf4\uff0c\u4e3a\u773c\u52a8\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u636e\u589e\u5e45\u65b9\u6cd5"}}
{"id": "2509.11187", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11187", "abs": "https://arxiv.org/abs/2509.11187", "authors": ["Doan Minh Trung", "Tien Duc Anh Hao", "Luong Hoang Minh", "Nghi Hoang Khoa", "Nguyen Tan Cam", "Van-Hau Pham", "Phan The Duy"], "title": "DMLDroid: Deep Multimodal Fusion Framework for Android Malware Detection with Resilience to Code Obfuscation and Adversarial Perturbations", "comment": null, "summary": "In recent years, learning-based Android malware detection has seen\nsignificant advancements, with detectors generally falling into three\ncategories: string-based, image-based, and graph-based approaches. While these\nmethods have shown strong detection performance, they often struggle to sustain\nrobustness in real-world settings, particularly when facing code obfuscation\nand adversarial examples (AEs). Deep multimodal learning has emerged as a\npromising solution, leveraging the strengths of multiple feature types to\nenhance robustness and generalization. However, a systematic investigation of\nmultimodal fusion for both accuracy and resilience remains underexplored. In\nthis study, we propose DMLDroid, an Android malware detection based on\nmultimodal fusion that leverages three different representations of malware\nfeatures, including permissions & intents (tabular-based), DEX file\nrepresentations (image-based), and API calls (graph-derived sequence-based). We\nconduct exhaustive experiments independently on each feature, as well as in\ncombination, using different fusion strategies. Experimental results on the\nCICMalDroid 2020 dataset demonstrate that our multimodal approach with the\ndynamic weighted fusion mechanism achieves high performance, reaching 97.98%\naccuracy and 98.67% F1-score on original malware detection. Notably, the\nproposed method maintains strong robustness, sustaining over 98% accuracy and\n98% F1-score under both obfuscation and adversarial attack scenarios. Our\nfindings highlight the benefits of multimodal fusion in improving both\ndetection accuracy and robustness against evolving Android malware threats.", "AI": {"tldr": "DMLDroid\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001\u878d\u5408\u7684Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7cfb\u7edf\uff0c\u7ed3\u5408\u6743\u9650\u610f\u56fe\u3001DEX\u6587\u4ef6\u56fe\u50cf\u548cAPI\u8c03\u7528\u5e8f\u5217\u4e09\u79cd\u7279\u5f81\u8868\u793a\uff0c\u901a\u8fc7\u52a8\u6001\u52a0\u6743\u878d\u5408\u673a\u5236\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u6297\u6df7\u6dc6/\u5bf9\u6297\u653b\u51fb\u9c81\u68d2\u6027\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u65b9\u6cd5\uff08\u57fa\u4e8e\u5b57\u7b26\u4e32\u3001\u56fe\u50cf\u548c\u56fe\uff09\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u9762\u5bf9\u4ee3\u7801\u6df7\u6dc6\u548c\u5bf9\u6297\u6837\u672c\u65f6\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u591a\u6a21\u6001\u5b66\u4e60\u867d\u7136\u524d\u666f\u5e7f\u9614\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u63d0\u51faDMLDroid\u591a\u6a21\u6001\u878d\u5408\u68c0\u6d4b\u6846\u67b6\uff0c\u6574\u5408\u4e09\u79cd\u7279\u5f81\uff1a\u6743\u9650\u610f\u56fe\uff08\u8868\u683c\u578b\uff09\u3001DEX\u6587\u4ef6\u8868\u793a\uff08\u56fe\u50cf\u578b\uff09\u3001API\u8c03\u7528\uff08\u56fe\u884d\u751f\u5e8f\u5217\u578b\uff09\uff0c\u91c7\u7528\u4e0d\u540c\u7684\u878d\u5408\u7b56\u7565\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5728CICMalDroid 2020\u6570\u636e\u96c6\u4e0a\uff0c\u52a8\u6001\u52a0\u6743\u878d\u5408\u673a\u5236\u8fbe\u523097.98%\u51c6\u786e\u7387\u548c98.67% F1\u5206\u6570\uff0c\u5728\u6df7\u6dc6\u548c\u5bf9\u6297\u653b\u51fb\u573a\u666f\u4e0b\u4ecd\u4fdd\u630198%\u4ee5\u4e0a\u7684\u51c6\u786e\u7387\u548cF1\u5206\u6570\u3002", "conclusion": "\u591a\u6a21\u6001\u878d\u5408\u80fd\u663e\u8457\u63d0\u5347Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u6709\u6548\u5e94\u5bf9\u4e0d\u65ad\u6f14\u53d8\u7684\u5a01\u80c1\u3002"}}
{"id": "2509.11572", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.11572", "abs": "https://arxiv.org/abs/2509.11572", "authors": ["Tuan Bui", "An Nguyen", "Phat Thai", "Minh Hua", "Ngan Pham L. N.", "Ngan Pham T. B.", "Dung Le", "Long Nguyen", "Thanh-Tung Tran", "Thang Bui", "Tho Quan"], "title": "Formal Reasoning for Intelligent QA Systems: A Case Study in the Educational Domain", "comment": "Published at the 2nd ACM Workshop in AI-powered Question & Answering\n  Systems (AIQAM '25), co-located with ACM Multimedia 2025", "summary": "Reasoning is essential for closed-domain QA systems in which procedural\ncorrectness and policy compliance are critical. While large language models\n(LLMs) have shown strong performance on many reasoning tasks, recent work\nreveals that their reasoning traces are often unfaithful - serving more as\nplausible justifications than as causally grounded derivations. Efforts to\ncombine LLMs with symbolic engines (e.g., Prover9, Z3) have improved\nreliability but remain limited to static forms of logic, struggling with\ndynamic, state-based reasoning such as multi-step progressions and conditional\ntransitions.\n  In this paper, we propose MCFR (Model Checking for Formal Reasoning), a\nneuro-symbolic framework that integrates LLMs with model checking to support\nproperty verification. MCFR translates natural language into formal\nspecifications and verifies them over transition models. To support evaluation,\nwe introduce EduMC-QA, a benchmark dataset grounded in real academic\nprocedures. Our results show that MCFR improves reasoning faithfulness and\ninterpretability, offering a viable path toward verifiable QA in high-stakes\nclosed-domain applications. In addition to evaluating MCFR, we compare its\nperformance with state-of-the-art LLMs such as ChatGPT, DeepSeek, and Claude to\ncontextualize its effectiveness.", "AI": {"tldr": "MCFR\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u6a21\u578b\u68c0\u6d4b\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u652f\u6301\u5c5e\u6027\u9a8c\u8bc1\uff0c\u63d0\u9ad8\u95ed\u57dfQA\u7cfb\u7edf\u4e2d\u7684\u63a8\u7406\u5fe0\u5b9e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709LLM\u63a8\u7406\u8f68\u8ff9\u5f80\u5f80\u4e0d\u5fe0\u5b9e\uff0c\u53ea\u662f\u770b\u4f3c\u5408\u7406\u7684\u89e3\u91ca\u800c\u975e\u56e0\u679c\u63a8\u5bfc\u3002\u7b26\u53f7\u5f15\u64ce\u4e0eLLM\u7ed3\u5408\u7684\u65b9\u6cd5\u5c40\u9650\u4e8e\u9759\u6001\u903b\u8f91\uff0c\u96be\u4ee5\u5904\u7406\u52a8\u6001\u3001\u57fa\u4e8e\u72b6\u6001\u7684\u591a\u6b65\u63a8\u7406\u3002", "method": "\u63d0\u51faMCFR\u6846\u67b6\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u4e3a\u5f62\u5f0f\u5316\u89c4\u8303\uff0c\u5e76\u5728\u8f6c\u79fb\u6a21\u578b\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002\u4f7f\u7528\u6a21\u578b\u68c0\u6d4b\u6280\u672f\u6765\u652f\u6301\u5c5e\u6027\u9a8c\u8bc1\u3002", "result": "MCFR\u5728EduMC-QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u7684\u5fe0\u5b9e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u9ad8\u98ce\u9669\u95ed\u57df\u5e94\u7528\u4e2d\u7684\u53ef\u9a8c\u8bc1QA\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002", "conclusion": "MCFR\u6846\u67b6\u901a\u8fc7\u6574\u5408LLM\u548c\u6a21\u578b\u68c0\u6d4b\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u72b6\u6001\u63a8\u7406\u7684\u6311\u6218\uff0c\u4e3a\u95ed\u57dfQA\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2509.11237", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11237", "abs": "https://arxiv.org/abs/2509.11237", "authors": ["Aleksejus Mihalkovi\u010d", "Lina Dindiene", "Eligijus Sakalauskas"], "title": "Implementation of Learning with Errors in Non-Commuting Multiplicative Groups", "comment": "18 pages, 1 figure", "summary": "In this paper, we demonstrate a way to generalize learning with errors (LWE)\nto the family of so-called modular-maximal cyclic groups which are\nnon-commuting. Since the group M2t has two cycles of maximal multiplicative\norder, we use this fact to construct an accurate criterion for restoring the\nmessage bit with overwhelming probability. Furthermore, we implement the\noriginal idea by O. Regev in the considered group to gain benefits from the\nnon-commutativity of M2t . Also we prove that using this approach we can\nachieve a level of security comparable to the original idea.", "AI": {"tldr": "\u5c06LWE\u63a8\u5e7f\u5230\u975e\u4ea4\u6362\u7684\u6a21\u6700\u5927\u5faa\u73af\u7fa4M2t\uff0c\u5229\u7528\u5176\u53cc\u5faa\u73af\u7ed3\u6784\u6784\u9020\u6d88\u606f\u6062\u590d\u51c6\u5219\uff0c\u5b9e\u73b0Regev\u539f\u59cb\u601d\u60f3\u5e76\u83b7\u5f97\u975e\u4ea4\u6362\u6027\u4f18\u52bf\uff0c\u5b89\u5168\u6027\u4e0e\u539f\u65b9\u6848\u76f8\u5f53", "motivation": "\u5c06\u5b66\u4e60\u9519\u8bef\u95ee\u9898(LWE)\u4ece\u4ea4\u6362\u7fa4\u63a8\u5e7f\u5230\u975e\u4ea4\u6362\u7fa4\uff0c\u5229\u7528\u975e\u4ea4\u6362\u7fa4\u7684\u7279\u6b8a\u7ed3\u6784\u6765\u83b7\u5f97\u5bc6\u7801\u5b66\u4f18\u52bf", "method": "\u4f7f\u7528\u6a21\u6700\u5927\u5faa\u73af\u7fa4M2t\uff08\u5177\u6709\u4e24\u4e2a\u6700\u5927\u4e58\u6cd5\u9636\u5faa\u73af\uff09\uff0c\u6784\u9020\u6d88\u606f\u6062\u590d\u51c6\u5219\uff0c\u5728\u975e\u4ea4\u6362\u7fa4\u4e2d\u5b9e\u73b0Regev\u7684\u539f\u59cb\u52a0\u5bc6\u601d\u60f3", "result": "\u6210\u529f\u5728\u975e\u4ea4\u6362\u7fa4M2t\u4e2d\u5b9e\u73b0\u4e86LWE\u7684\u63a8\u5e7f\uff0c\u80fd\u591f\u4ee5\u538b\u5012\u6027\u6982\u7387\u6062\u590d\u6d88\u606f\u6bd4\u7279", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u975e\u4ea4\u6362\u7fa4\u4e2d\u5b9e\u73b0\u4e86\u4e0e\u539f\u59cbLWE\u65b9\u6848\u76f8\u5f53\u7684\u5b89\u5168\u7ea7\u522b\uff0c\u540c\u65f6\u5229\u7528\u4e86\u975e\u4ea4\u6362\u6027\u7684\u4f18\u52bf"}}
{"id": "2509.11575", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11575", "abs": "https://arxiv.org/abs/2509.11575", "authors": ["Ching Chang", "Yidan Shi", "Defu Cao", "Wei Yang", "Jeehyun Hwang", "Haixin Wang", "Jiacheng Pang", "Wei Wang", "Yan Liu", "Wen-Chih Peng", "Tien-Fu Chen"], "title": "A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models", "comment": "This paper is currently under review", "summary": "Time series reasoning treats time as a first-class axis and incorporates\nintermediate evidence directly into the answer. This survey defines the problem\nand organizes the literature by reasoning topology with three families: direct\nreasoning in one step, linear chain reasoning with explicit intermediates, and\nbranch-structured reasoning that explores, revises, and aggregates. The\ntopology is crossed with the main objectives of the field, including\ntraditional time series analysis, explanation and understanding, causal\ninference and decision making, and time series generation, while a compact tag\nset spans these axes and captures decomposition and verification, ensembling,\ntool use, knowledge access, multimodality, agent loops, and LLM alignment\nregimes. Methods and systems are reviewed across domains, showing what each\ntopology enables and where it breaks down in faithfulness or robustness, along\nwith curated datasets, benchmarks, and resources that support study and\ndeployment (https://github.com/blacksnail789521/Time-Series-Reasoning-Survey).\nEvaluation practices that keep evidence visible and temporally aligned are\nhighlighted, and guidance is distilled on matching topology to uncertainty,\ngrounding with observable artifacts, planning for shift and streaming, and\ntreating cost and latency as design budgets. We emphasize that reasoning\nstructures must balance capacity for grounding and self-correction against\ncomputational cost and reproducibility, while future progress will likely\ndepend on benchmarks that tie reasoning quality to utility and on closed-loop\ntestbeds that trade off cost and risk under shift-aware, streaming, and\nlong-horizon settings. Taken together, these directions mark a shift from\nnarrow accuracy toward reliability at scale, enabling systems that not only\nanalyze but also understand, explain, and act on dynamic worlds with traceable\nevidence and credible outcomes.", "AI": {"tldr": "\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u6280\u672f\u8c03\u7814\uff1a\u5b9a\u4e49\u4e86\u4e09\u79cd\u63a8\u7406\u62d3\u6251\u7ed3\u6784\uff08\u76f4\u63a5\u63a8\u7406\u3001\u7ebf\u6027\u94fe\u63a8\u7406\u3001\u5206\u652f\u7ed3\u6784\u63a8\u7406\uff09\uff0c\u8de8\u8d8a\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u3001\u89e3\u91ca\u7406\u89e3\u3001\u56e0\u679c\u63a8\u65ad\u3001\u751f\u6210\u7b49\u9886\u57df\uff0c\u5e76\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u65b9\u6cd5\u548c\u5b9e\u8df5\u6307\u5357\u3002", "motivation": "\u5c06\u65f6\u95f4\u4f5c\u4e3a\u4e00\u7b49\u8f74\u5fc3\uff0c\u901a\u8fc7\u4e2d\u95f4\u8bc1\u636e\u76f4\u63a5\u878d\u5165\u7b54\u6848\u6765\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\uff0c\u8fdb\u800c\u652f\u6301\u7406\u89e3\u3001\u89e3\u91ca\u548c\u5728\u52a8\u6001\u4e16\u754c\u4e2d\u884c\u52a8\u3002", "method": "\u901a\u8fc7\u63a8\u7406\u62d3\u6251\u7ed3\u6784\u7ec4\u7ec7\u6587\u732e\uff1a\u76f4\u63a5\u63a8\u7406\u3001\u7ebf\u6027\u94fe\u63a8\u7406\u548c\u5206\u652f\u7ed3\u6784\u63a8\u7406\u3002\u7ed3\u5408\u5206\u89e3\u3001\u9a8c\u8bc1\u3001\u96c6\u6210\u3001\u5de5\u5177\u4f7f\u7528\u3001\u77e5\u8bc6\u8bbf\u95ee\u3001\u591a\u6a21\u6001\u3001\u4ee3\u7406\u5faa\u73af\u7b49\u6807\u7b7e\u96c6\u3002\u7efc\u8ff0\u5404\u9886\u57df\u65b9\u6cd5\u548c\u7cfb\u7edf\uff0c\u5206\u6790\u5404\u79cd\u62d3\u6251\u7ed3\u6784\u7684\u4f18\u7f3a\u70b9\u3002", "result": "\u63d0\u4f9b\u4e86\u7cbe\u9009\u7684\u6570\u636e\u96c6\u3001\u6d4b\u8bd5\u6846\u67b6\u548c\u8d44\u6e90\uff0c\u5f3a\u8c03\u4fdd\u6301\u8bc1\u636e\u53ef\u89c1\u6027\u548c\u65f6\u95f4\u5bf9\u9f50\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002\u7ec6\u5316\u4e86\u6839\u636e\u4e0d\u786e\u5b9a\u6027\u9009\u62e9\u62d3\u6251\u7ed3\u6784\u3001\u901a\u8fc7\u53ef\u89c2\u6d4b\u7ed3\u679c\u57fa\u7840\u3001\u7b56\u5212\u5047\u8bbe\u5047\u8bbe\u548c\u6d41\u5f0f\u5904\u7406\u3001\u5c06\u6210\u672c\u548c\u5ef6\u8fdf\u4f5c\u4e3a\u8bbe\u8ba1\u9884\u7b97\u7684\u5b9e\u8df5\u6307\u5357\u3002", "conclusion": "\u63a8\u7406\u7ed3\u6784\u9700\u5728\u57fa\u7840\u78b0\u649e\u548c\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\u4e0e\u8ba1\u7b97\u6210\u672c\u3001\u53ef\u590d\u73b0\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u672a\u6765\u8fdb\u5c55\u5c06\u4f9d\u8d56\u4e8e\u5c06\u63a8\u7406\u8d28\u91cf\u4e0e\u5b9e\u7528\u6027\u76f8\u7ed3\u5408\u7684\u6d4b\u8bd5\u6846\u67b6\uff0c\u4ee5\u53ca\u5728\u5047\u8bbe\u5047\u8bbe\u3001\u6d41\u5f0f\u548c\u957f\u671f\u9650\u8bbe\u7f6e\u4e0b\u8003\u8651\u6210\u672c\u4e0e\u98ce\u9669\u4ea4\u6613\u7684\u95ed\u73af\u6d4b\u8bd5\u5e8a\u3002\u8fd9\u4e9b\u65b9\u5411\u6807\u5fd7\u7740\u4ece\u7a84\u9698\u51c6\u786e\u6027\u5411\u5927\u89c4\u6a21\u53ef\u9760\u6027\u7684\u8f6c\u53d8\uff0c\u4ee5\u652f\u6301\u5177\u6709\u53ef\u8ffd\u8e2a\u8bc1\u636e\u548c\u53ef\u4fe1\u7ed3\u679c\u7684\u7cfb\u7edf\u3002"}}
{"id": "2509.11242", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11242", "abs": "https://arxiv.org/abs/2509.11242", "authors": ["Zhaofeng Yu", "Dongyang Zhan", "Lin Ye", "Haining Yu", "Hongli Zhang", "Zhihong Tian"], "title": "Exploring and Exploiting the Resource Isolation Attack Surface of WebAssembly Containers", "comment": "18 pages, 2 figures. Accepted at the 34th USENIX Security Symposium\n  (USENIX Security 2025)", "summary": "Recently, the WebAssembly (or Wasm) technology has been rapidly evolving,\nwith many runtimes actively under development, providing cross-platform secure\nsandboxes for Wasm modules to run as portable containers. Compared with Docker,\nwhich isolates applications at the operating system level, Wasm runtimes\nprovide more security mechanisms, such as linear memory, type checking, and\nprotected call stacks. Although Wasm is designed with security in mind and\nconsidered to be a more secure container runtime, various security challenges\nhave arisen, and researchers have focused on the security of Wasm runtimes,\nsuch as discovering vulnerabilities or proposing new security mechanisms to\nachieve robust isolation. However, we have observed that the resource isolation\nis not well protected by the current Wasm runtimes, and attackers can exhaust\nthe host's resources to interfere with the execution of other container\ninstances by exploiting the WASI/WASIX interfaces. And the attack surface has\nnot been well explored and measured. In this paper, we explore the resource\nisolation attack surface of Wasm runtimes systematically by proposing several\nstatic Wasm runtime analysis approaches. Based on the analysis results, we\npropose several exploitation strategies to break the resource isolation of Wasm\nruntimes. The experimental results show that malicious Wasm instances can not\nonly consume large amounts of system resources on their own but also introduce\nhigh workloads into other components of the underlying operating system,\nleading to a substantial performance degradation of the whole system. In\naddition, the mitigation approaches have also been discussed.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u5206\u6790WebAssembly\u8fd0\u884c\u65f6\u7684\u8d44\u6e90\u9694\u79bb\u6f0f\u6d1e\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u65b9\u6cd5\u53d1\u73b0WASI/WASIX\u63a5\u53e3\u5b58\u5728\u8d44\u6e90\u6d88\u8017\u653b\u51fb\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u5229\u7528\u7b56\u7565\u548c\u7f13\u89e3\u65b9\u6848\u3002", "motivation": "\u867d\u7136WebAssembly\u88ab\u8bbe\u8ba1\u4e3a\u66f4\u5b89\u5168\u7684\u5bb9\u5668\u8fd0\u884c\u65f6\uff0c\u4f46\u5f53\u524d\u8fd0\u884c\u65f6\u5728\u8d44\u6e90\u9694\u79bb\u65b9\u9762\u5b58\u5728\u7f3a\u9677\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7WASI/WASIX\u63a5\u53e3\u6d88\u8017\u4e3b\u673a\u8d44\u6e90\u5e72\u6270\u5176\u4ed6\u5bb9\u5668\u5b9e\u4f8b\u7684\u8fd0\u884c\uff0c\u8fd9\u4e2a\u653b\u51fb\u9762\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u548c\u91cf\u5316\u3002", "method": "\u63d0\u51fa\u591a\u79cd\u9759\u6001Wasm\u8fd0\u884c\u65f6\u5206\u6790\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u63a2\u7d22\u8d44\u6e90\u9694\u79bb\u653b\u51fb\u9762\uff0c\u57fa\u4e8e\u5206\u6790\u7ed3\u679c\u63d0\u51fa\u591a\u79cd\u5229\u7528\u7b56\u7565\u6765\u7834\u574fWasm\u8fd0\u884c\u65f6\u7684\u8d44\u6e90\u9694\u79bb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6076\u610fWasm\u5b9e\u4f8b\u4e0d\u4ec5\u80fd\u591f\u6d88\u8017\u5927\u91cf\u7cfb\u7edf\u8d44\u6e90\uff0c\u8fd8\u80fd\u7ed9\u5e95\u5c42\u64cd\u4f5c\u7cfb\u7edf\u5176\u4ed6\u7ec4\u4ef6\u5e26\u6765\u9ad8\u8d1f\u8f7d\uff0c\u5bfc\u81f4\u6574\u4e2a\u7cfb\u7edf\u6027\u80fd\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86Wasm\u8fd0\u884c\u65f6\u5728\u8d44\u6e90\u9694\u79bb\u65b9\u9762\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u8ba8\u8bba\u4e86\u7f13\u89e3\u65b9\u6848\uff0c\u4e3a\u63d0\u5347Wasm\u5bb9\u5668\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2509.11595", "categories": ["cs.AI", "cs.CE", "cs.CR", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.11595", "abs": "https://arxiv.org/abs/2509.11595", "authors": ["Sabin Huda", "Ernest Foo", "Zahra Jadidi", "MA Hakim Newton", "Abdul Sattar"], "title": "AMLNet: A Knowledge-Based Multi-Agent Framework to Generate and Detect Realistic Money Laundering Transactions", "comment": null, "summary": "Anti-money laundering (AML) research is constrained by the lack of publicly\nshareable, regulation-aligned transaction datasets. We present AMLNet, a\nknowledge-based multi-agent framework with two coordinated units: a\nregulation-aware transaction generator and an ensemble detection pipeline. The\ngenerator produces 1,090,173 synthetic transactions (approximately 0.16\\%\nlaundering-positive) spanning core laundering phases (placement, layering,\nintegration) and advanced typologies (e.g., structuring, adaptive threshold\nbehavior). Regulatory alignment reaches 75\\% based on AUSTRAC rule coverage\n(Section 4.2), while a composite technical fidelity score of 0.75 summarizes\ntemporal, structural, and behavioral realism components (Section 4.4). The\ndetection ensemble achieves F1 0.90 (precision 0.84, recall 0.97) on the\ninternal test partitions of AMLNet and adapts to the external SynthAML dataset,\nindicating architectural generalizability across different synthetic generation\nparadigms. We provide multi-dimensional evaluation (regulatory, temporal,\nnetwork, behavioral) and release the dataset (Version 1.0,\nhttps://doi.org/10.5281/zenodo.16736515), to advance reproducible and\nregulation-conscious AML experimentation.", "AI": {"tldr": "AMLNet\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5305\u542b\u76d1\u7ba1\u611f\u77e5\u7684\u4ea4\u6613\u751f\u6210\u5668\u548c\u96c6\u6210\u68c0\u6d4b\u7ba1\u9053\uff0c\u7528\u4e8e\u751f\u6210\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u7684\u5408\u6210\u53cd\u6d17\u94b1\u4ea4\u6613\u6570\u636e\u5e76\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u3002", "motivation": "\u53cd\u6d17\u94b1\u7814\u7a76\u7f3a\u4e4f\u53ef\u516c\u5f00\u5171\u4eab\u4e14\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u7684\u4ea4\u6613\u6570\u636e\u96c6\uff0c\u8fd9\u9650\u5236\u4e86AML\u5b9e\u9a8c\u7684\u53ef\u91cd\u590d\u6027\u548c\u76d1\u7ba1\u4e00\u81f4\u6027\u7814\u7a76\u3002", "method": "\u91c7\u7528\u77e5\u8bc6\u9a71\u52a8\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff1a1)\u76d1\u7ba1\u611f\u77e5\u4ea4\u6613\u751f\u6210\u5668\u751f\u6210\u5305\u542b\u6d17\u94b1\u6838\u5fc3\u9636\u6bb5\u548c\u9ad8\u7ea7\u7c7b\u578b\u7684\u5408\u6210\u4ea4\u6613\uff1b2)\u96c6\u6210\u68c0\u6d4b\u7ba1\u9053\u8fdb\u884c\u6d17\u94b1\u68c0\u6d4b\u3002", "result": "\u751f\u62101,090,173\u7b14\u5408\u6210\u4ea4\u6613(\u7ea60.16%\u6d17\u94b1\u9633\u6027)\uff0c\u76d1\u7ba1\u5bf9\u9f50\u5ea6\u8fbe75%\uff0c\u6280\u672f\u4fdd\u771f\u5ea6\u5f97\u52060.75\u3002\u68c0\u6d4b\u96c6\u6210F1\u5f97\u52060.90(\u7cbe\u5ea60.84\uff0c\u53ec\u56de\u73870.97)\uff0c\u5728\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u4e5f\u8868\u73b0\u826f\u597d\u3002", "conclusion": "AMLNet\u63d0\u4f9b\u4e86\u4e00\u4e2a\u591a\u7ef4\u8bc4\u4f30\u6846\u67b6\u548c\u516c\u5f00\u6570\u636e\u96c6\uff0c\u63a8\u52a8\u4e86\u53ef\u91cd\u590d\u4e14\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u7684\u53cd\u6d17\u94b1\u5b9e\u9a8c\u7814\u7a76\u3002"}}
{"id": "2509.11249", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11249", "abs": "https://arxiv.org/abs/2509.11249", "authors": ["Tao Wang", "Yushu Zhang", "Xiangli Xiao", "Kun Xu", "Lin Yuan", "Wenying Wen", "Yuming Fang"], "title": "Make Identity Unextractable yet Perceptible: Synthesis-Based Privacy Protection for Subject Faces in Photos", "comment": null, "summary": "Deep learning-based face recognition (FR) technology exacerbates privacy\nconcerns in photo sharing. In response, the research community developed a\nsuite of anti-FR methods to block identity extraction by unauthorized FR\nsystems. Benefiting from quasi-imperceptible alteration, perturbation-based\nmethods are well-suited for privacy protection of subject faces in photos, as\nthey allow familiar persons to recognize subjects via naked eyes. However, we\nreveal that perturbation-based methods provide a false sense of privacy through\ntheoretical analysis and experimental validation.\n  Therefore, new alternative solutions should be found to protect subject\nfaces. In this paper, we explore synthesis-based methods as a promising\nsolution, whose challenge is to enable familiar persons to recognize subjects.\nTo solve the challenge, we present a key insight: In most photo sharing\nscenarios, familiar persons recognize subjects through identity perception\nrather than meticulous face analysis. Based on the insight, we propose the\nfirst synthesis-based method dedicated to subject faces, i.e., PerceptFace,\nwhich can make identity unextractable yet perceptible. To enhance identity\nperception, a new perceptual similarity loss is designed for faces, reducing\nthe alteration in regions of high sensitivity to human vision.\n  As a synthesis-based method, PerceptFace can inherently provide reliable\nidentity protection. Meanwhile, out of the confine of meticulous face analysis,\nPerceptFace focuses on identity perception from a more practical scenario,\nwhich is also enhanced by the designed perceptual similarity loss. Sufficient\nexperiments show that PerceptFace achieves a superior trade-off between\nidentity protection and identity perception compared to existing methods. We\nprovide a public API of PerceptFace and believe that it has great potential to\nbecome a practical anti-FR tool.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86PerceptFace\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u6210\u6280\u672f\u4fdd\u62a4\u4eba\u8138\u9690\u79c1\uff0c\u5728\u963b\u6b62\u6df1\u5ea6\u5b66\u4e60\u8bc6\u522b\u7684\u540c\u65f6\u4fdd\u6301\u719f\u6089\u8005\u7684\u4eba\u8138\u8bc6\u522b\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u6279\u52a8\u57fa\u7840\u7684\u53cd\u4eba\u8138\u8bc6\u522b\u65b9\u6cd5\u5b58\u5728\u9690\u79c1\u4fdd\u62a4\u7684\u5047\u8c61\uff0c\u9700\u8981\u627e\u5230\u66f4\u53ef\u9760\u7684\u65b0\u65b9\u6848\u6765\u4fdd\u62a4\u7167\u7247\u4e2d\u7684\u4eba\u8138\u9690\u79c1\u3002", "method": "\u63d0\u51faPerceptFace\u65b9\u6cd5\uff0c\u5229\u7528\u5408\u6210\u6280\u672f\u6539\u53d8\u4eba\u8138\u56fe\u50cf\uff0c\u8bbe\u8ba1\u4e86\u65b0\u7684\u611f\u77e5\u76f8\u4f3c\u6027\u635f\u5931\u51fd\u6570\uff0c\u51cf\u5c11\u5728\u4eba\u773c\u654f\u611f\u533a\u57df\u7684\u6539\u52a8\uff0c\u4f7f\u5f97\u8bc6\u522b\u65e0\u6cd5\u88ab\u673a\u5668\u63d0\u53d6\u4f46\u4ecd\u53ef\u4ee5\u88ab\u719f\u6089\u8005\u611f\u77e5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aPerceptFace\u5728\u8bc6\u522b\u4fdd\u62a4\u548c\u8bc6\u522b\u611f\u77e5\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u5e73\u8861\uff0c\u8f83\u73b0\u6709\u65b9\u6cd5\u66f4\u52a0\u9ad8\u6548\u3002", "conclusion": "PerceptFace\u4f5c\u4e3a\u9996\u4e2a\u4e13\u95e8\u7528\u4e8e\u4e3b\u4f53\u4eba\u8138\u4fdd\u62a4\u7684\u5408\u6210\u65b9\u6cd5\uff0c\u5177\u6709\u6210\u4e3a\u5b9e\u7528\u53cd\u4eba\u8138\u8bc6\u522b\u5de5\u5177\u7684\u5f88\u5927\u6f5c\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u516c\u5f00API\u3002"}}
{"id": "2509.11645", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11645", "abs": "https://arxiv.org/abs/2509.11645", "authors": ["Zhaolong Wu", "Pu Luo", "Jason Pui Yin Cheung", "Teng Zhang"], "title": "Adapting and Evaluating Multimodal Large Language Models for Adolescent Idiopathic Scoliosis Self-Management: A Divide and Conquer Framework", "comment": "Accepted by MICCAI 2025 MLLMCP Workshop", "summary": "This study presents the first comprehensive evaluation of Multimodal Large\nLanguage Models (MLLMs) for Adolescent Idiopathic Scoliosis (AIS)\nself-management. We constructed a database of approximately 3,000\nanteroposterior X-rays with diagnostic texts and evaluated five MLLMs through a\n`Divide and Conquer' framework consisting of a visual question-answering task,\na domain knowledge assessment task, and a patient education counseling\nassessment task. Our investigation revealed limitations of MLLMs' ability in\ninterpreting complex spinal radiographs and comprehending AIS care knowledge.\nTo address these, we pioneered enhancing MLLMs with spinal keypoint prompting\nand compiled an AIS knowledge base for retrieval augmented generation (RAG),\nrespectively. Results showed varying effectiveness of visual prompting across\ndifferent architectures, while RAG substantially improved models' performances\non the knowledge assessment task. Our findings indicate current MLLMs are far\nfrom capable in realizing personalized assistant in AIS care. The greatest\nchallenge lies in their abilities to obtain accurate detections of spinal\ndeformity locations (best accuracy: 0.55) and directions (best accuracy: 0.13).", "AI": {"tldr": "\u9996\u6b21\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9752\u5c11\u5e74\u7279\u53d1\u6027\u810a\u67f1\u4fa7\u5f2f\u81ea\u6211\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u810a\u67f1X\u5149\u89e3\u8bfb\u548c\u4e13\u4e1a\u77e5\u8bc6\u7406\u89e3\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\uff0c\u901a\u8fc7\u5173\u952e\u70b9\u63d0\u793a\u548c\u77e5\u8bc6\u5e93\u589e\u5f3a\u53d6\u5f97\u4e00\u5b9a\u6539\u8fdb\uff0c\u4f46\u8ddd\u79bb\u4e2a\u6027\u5316\u8f85\u52a9\u4ecd\u6709\u8f83\u5927\u5dee\u8ddd\u3002", "motivation": "\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9752\u5c11\u5e74\u7279\u53d1\u6027\u810a\u67f1\u4fa7\u5f2f(AIS)\u81ea\u6211\u7ba1\u7406\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u63a2\u7d22\u5176\u5728\u533b\u7597\u8f85\u52a9\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b3000\u5f20X\u5149\u7247\u548c\u8bca\u65ad\u6587\u672c\u7684\u6570\u636e\u5e93\uff0c\u91c7\u7528'\u5206\u800c\u6cbb\u4e4b'\u6846\u67b6\u8bc4\u4f305\u4e2aMLLM\u6a21\u578b\uff0c\u5305\u62ec\u89c6\u89c9\u95ee\u7b54\u3001\u9886\u57df\u77e5\u8bc6\u8bc4\u4f30\u548c\u60a3\u8005\u6559\u80b2\u54a8\u8be2\u4e09\u4e2a\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u810a\u67f1\u5173\u952e\u70b9\u63d0\u793a\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u8fdb\u884c\u6539\u8fdb\u3002", "result": "MLLM\u5728\u590d\u6742\u810a\u67f1X\u5149\u89e3\u8bfb\u548cAIS\u62a4\u7406\u77e5\u8bc6\u7406\u89e3\u65b9\u9762\u5b58\u5728\u660e\u663e\u5c40\u9650\uff0c\u810a\u67f1\u5173\u952e\u70b9\u63d0\u793a\u5bf9\u4e0d\u540c\u67b6\u6784\u6a21\u578b\u6548\u679c\u4e0d\u4e00\uff0cRAG\u663e\u8457\u63d0\u5347\u77e5\u8bc6\u8bc4\u4f30\u4efb\u52a1\u8868\u73b0\uff0c\u4f46\u810a\u67f1\u7578\u5f62\u4f4d\u7f6e\u68c0\u6d4b\u6700\u4f73\u51c6\u786e\u7387\u4ec50.55\uff0c\u65b9\u5411\u68c0\u6d4b\u4ec50.13\u3002", "conclusion": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5c1a\u65e0\u6cd5\u80dc\u4efbAIS\u62a4\u7406\u7684\u4e2a\u6027\u5316\u8f85\u52a9\u4efb\u52a1\uff0c\u4e3b\u8981\u6311\u6218\u5728\u4e8e\u51c6\u786e\u68c0\u6d4b\u810a\u67f1\u7578\u5f62\u4f4d\u7f6e\u548c\u65b9\u5411\u7684\u80fd\u529b\u4e0d\u8db3\u3002"}}
{"id": "2509.11250", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.11250", "abs": "https://arxiv.org/abs/2509.11250", "authors": ["Yitong Zhang", "Ximo Li", "Liyi Cai", "Jia Li"], "title": "Realistic Environmental Injection Attacks on GUI Agents", "comment": null, "summary": "GUI agents built on LVLMs are increasingly used to interact with websites.\nHowever, their exposure to open-world content makes them vulnerable to\nEnvironmental Injection Attacks (EIAs) that hijack agent behavior via webpage\nelements. Many recent studies assume the attacker to be a regular user who can\nonly upload a single trigger image, which is more realistic than earlier\nassumptions of website-level administrative control. However, these works still\nfall short of realism: (1) the trigger's position and surrounding context\nremain largely fixed between training and testing, failing to capture the\ndynamic nature of real webpages and (2) the trigger often occupies an\nunrealistically large area, whereas real-world images are typically small. To\nbetter reflect real-world scenarios, we introduce a more realistic threat model\nwhere the attacker is a regular user and the trigger image is small and\nembedded within a dynamically changing environment. As a result, existing\nattacks prove largely ineffective under this threat model.\n  To better expose the vulnerabilities of GUI agents, we propose Chameleon, an\nattack framework with two main novelties. The first is LLM-Driven Environment\nSimulation, which automatically generates diverse and high-fidelity webpage\nsimulations. The second is Attention Black Hole, which transforms attention\nweights into explicit supervisory signals that guide the agent's focus toward\nthe trigger region. We evaluate Chameleon on 6 realistic websites and 4\nrepresentative LVLM-powered GUI agents, where it significantly outperforms\nexisting methods. Ablation studies confirm that both novelties are critical to\nperformance. Our findings reveal underexplored vulnerabilities in modern GUI\nagents and establish a robust foundation for future research on defense in\nopen-world GUI agent systems. The code is publicly available at\nhttps://github.com/zhangyitonggg/attack2gui.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Chameleon\u653b\u51fb\u6846\u67b6\uff0c\u9488\u5bf9LVLM\u9a71\u52a8\u7684GUI\u4ee3\u7406\u5728\u52a8\u6001\u7f51\u9875\u73af\u5883\u4e2d\u7684\u6f0f\u6d1e\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684\u73af\u5883\u6a21\u62df\u548c\u6ce8\u610f\u529b\u9ed1\u6d1e\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u73af\u5883\u6ce8\u5165\u653b\u51fb\u7814\u7a76\u5047\u8bbe\u8fc7\u4e8e\u7406\u60f3\u5316\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u7f51\u9875\u7684\u52a8\u6001\u6027\u548c\u5c0f\u5c3a\u5bf8\u89e6\u53d1\u56fe\u50cf\u7684\u73b0\u5b9e\u573a\u666f\uff0c\u9700\u8981\u66f4\u73b0\u5b9e\u7684\u5a01\u80c1\u6a21\u578b\u6765\u66b4\u9732GUI\u4ee3\u7406\u7684\u8106\u5f31\u6027\u3002", "method": "\u63d0\u51faChameleon\u653b\u51fb\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u521b\u65b0\uff1a1) LLM\u9a71\u52a8\u7684\u73af\u5883\u6a21\u62df\u81ea\u52a8\u751f\u6210\u591a\u6837\u5316\u9ad8\u4fdd\u771f\u7f51\u9875\u6a21\u62df\uff1b2) \u6ce8\u610f\u529b\u9ed1\u6d1e\u673a\u5236\u5c06\u6ce8\u610f\u529b\u6743\u91cd\u8f6c\u5316\u4e3a\u663e\u5f0f\u76d1\u7763\u4fe1\u53f7\uff0c\u5f15\u5bfc\u4ee3\u7406\u5173\u6ce8\u89e6\u53d1\u533a\u57df\u3002", "result": "\u57286\u4e2a\u771f\u5b9e\u7f51\u7ad9\u548c4\u4e2a\u4ee3\u8868\u6027LVLM GUI\u4ee3\u7406\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cChameleon\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e24\u4e2a\u521b\u65b0\u5bf9\u6027\u80fd\u90fd\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u4ee3GUI\u4ee3\u7406\u4e2d\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u6f0f\u6d1e\uff0c\u4e3a\u5f00\u653e\u4e16\u754cGUI\u4ee3\u7406\u7cfb\u7edf\u7684\u9632\u5fa1\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2509.11719", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11719", "abs": "https://arxiv.org/abs/2509.11719", "authors": ["Bingqing Wei", "Lianmin Chen", "Zhongyu Xia", "Yongtao Wang"], "title": "HeLoFusion: An Efficient and Scalable Encoder for Modeling Heterogeneous and Multi-Scale Interactions in Trajectory Prediction", "comment": null, "summary": "Multi-agent trajectory prediction in autonomous driving requires a\ncomprehensive understanding of complex social dynamics. Existing methods,\nhowever, often struggle to capture the full richness of these dynamics,\nparticularly the co-existence of multi-scale interactions and the diverse\nbehaviors of heterogeneous agents. To address these challenges, this paper\nintroduces HeLoFusion, an efficient and scalable encoder for modeling\nheterogeneous and multi-scale agent interactions. Instead of relying on global\ncontext, HeLoFusion constructs local, multi-scale graphs centered on each\nagent, allowing it to effectively model both direct pairwise dependencies and\ncomplex group-wise interactions (\\textit{e.g.}, platooning vehicles or\npedestrian crowds). Furthermore, HeLoFusion tackles the critical challenge of\nagent heterogeneity through an aggregation-decomposition message-passing scheme\nand type-specific feature networks, enabling it to learn nuanced,\ntype-dependent interaction patterns. This locality-focused approach enables a\nprincipled representation of multi-level social context, yielding powerful and\nexpressive agent embeddings. On the challenging Waymo Open Motion Dataset,\nHeLoFusion achieves state-of-the-art performance, setting new benchmarks for\nkey metrics including Soft mAP and minADE. Our work demonstrates that a\nlocality-grounded architecture, which explicitly models multi-scale and\nheterogeneous interactions, is a highly effective strategy for advancing motion\nforecasting.", "AI": {"tldr": "HeLoFusion\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u6784\u5efa\u5c40\u90e8\u591a\u5c3a\u5ea6\u56fe\u6765\u5efa\u6a21\u5f02\u6784\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u8f68\u8ff9\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u590d\u6742\u793e\u4ea4\u52a8\u6001\u7684\u4e30\u5bcc\u6027\uff0c\u7279\u522b\u662f\u591a\u5c3a\u5ea6\u4ea4\u4e92\u7684\u5171\u5b58\u548c\u5f02\u6784\u667a\u80fd\u4f53\u7684\u591a\u6837\u5316\u884c\u4e3a\u3002", "method": "\u6784\u5efa\u4ee5\u6bcf\u4e2a\u667a\u80fd\u4f53\u4e3a\u4e2d\u5fc3\u7684\u5c40\u90e8\u591a\u5c3a\u5ea6\u56fe\uff0c\u91c7\u7528\u805a\u5408-\u5206\u89e3\u6d88\u606f\u4f20\u9012\u65b9\u6848\u548c\u7c7b\u578b\u7279\u5b9a\u7279\u5f81\u7f51\u7edc\u6765\u5904\u7406\u667a\u80fd\u4f53\u5f02\u6784\u6027\u3002", "result": "\u5728Waymo Open Motion\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728Soft mAP\u548cminADE\u7b49\u5173\u952e\u6307\u6807\u4e0a\u8bbe\u7acb\u4e86\u65b0\u7684\u57fa\u51c6\u3002", "conclusion": "\u57fa\u4e8e\u5c40\u90e8\u6027\u3001\u663e\u5f0f\u5efa\u6a21\u591a\u5c3a\u5ea6\u548c\u5f02\u6784\u4ea4\u4e92\u7684\u67b6\u6784\u662f\u63a8\u8fdb\u8fd0\u52a8\u9884\u6d4b\u7684\u6709\u6548\u7b56\u7565\u3002"}}
{"id": "2509.11440", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11440", "abs": "https://arxiv.org/abs/2509.11440", "authors": ["Robert Dumitru", "Junpeng Wan", "Daniel Genkin", "Rick Kennell", "Dave", "Tian", "Yuval Yarom"], "title": "Thunderhammer: Rowhammer Bitflips via PCIe and Thunderbolt (USB-C)", "comment": null, "summary": "In recent years, Rowhammer has attracted significant attention from academia\nand industry alike. This technique, first published in 2014, flips bits in\nmemory by repeatedly accessing neighbouring memory locations. Since its\ndiscovery, researchers have developed a substantial body of work exploiting\nRowhammer and proposing countermeasures. These works demonstrate that Rowhammer\ncan be mounted not only through native code, but also via remote code\nexecution, such as JavaScript in browsers, and over networks.\n  In this work, we uncover a previously unexplored Rowhammer vector. We present\nThunderhammer, an attack that induces DRAM bitflips from malicious peripherals\nconnected via PCIe or Thunderbolt (which tunnels PCIe). On modern DDR4 systems,\nwe observe that triggering bitflips through PCIe requests requires precisely\ntimed access patterns tailored to the target system. We design a custom device\nto reverse engineer critical architectural parameters that shape PCIe request\nscheduling, and to execute effective hammering access patterns. Leveraging this\nknowledge, we successfully demonstrate Rowhammer-induced bitflips in DDR4\nmemory modules via both PCIe slot connections and Thunderbolt ports tunnelling\nPCIe.", "AI": {"tldr": "Thunderhammer\u653b\u51fb\u901a\u8fc7PCIe\u6216Thunderbolt\u6076\u610f\u5916\u8bbe\u5b9e\u73b0Rowhammer\u653b\u51fb\uff0c\u9996\u6b21\u5c55\u793a\u4e86\u4ece\u5916\u90e8\u8bbe\u5907\u89e6\u53d1DDR4\u5185\u5b58\u4f4d\u7ffb\u8f6c\u7684\u65b0\u653b\u51fb\u5411\u91cf", "motivation": "Rowhammer\u653b\u51fb\u4f20\u7edf\u4e0a\u901a\u8fc7\u672c\u5730\u4ee3\u7801\u6216\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\u5b9e\u73b0\uff0c\u4f46\u6b64\u524d\u4ece\u672a\u63a2\u7d22\u8fc7\u901a\u8fc7PCIe\u7b49\u5916\u90e8\u8bbe\u5907\u63a5\u53e3\u8fdb\u884c\u653b\u51fb\u7684\u53ef\u80fd\u6027", "method": "\u8bbe\u8ba1\u5b9a\u5236\u8bbe\u5907\u9006\u5411\u5de5\u7a0bPCIe\u8bf7\u6c42\u8c03\u5ea6\u53c2\u6570\uff0c\u5f00\u53d1\u7cbe\u786e\u65f6\u5e8f\u7684\u8bbf\u95ee\u6a21\u5f0f\uff0c\u901a\u8fc7PCIe\u63d2\u69fd\u548cThunderbolt\u7aef\u53e3\u6267\u884c\u653b\u51fb", "result": "\u6210\u529f\u5728DDR4\u5185\u5b58\u6a21\u5757\u4e0a\u901a\u8fc7PCIe\u8fde\u63a5\u548cThunderbolt\u7aef\u53e3\u5b9e\u73b0\u4e86Rowhammer\u8bf1\u5bfc\u7684\u4f4d\u7ffb\u8f6c", "conclusion": "Thunderhammer\u63ed\u793a\u4e86Rowhammer\u653b\u51fb\u7684\u65b0\u7ef4\u5ea6\uff0c\u8868\u660e\u6076\u610f\u5916\u8bbe\u4e5f\u80fd\u6784\u6210\u4e25\u91cd\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u65b0\u7684\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u8fd9\u7c7b\u786c\u4ef6\u7ea7\u653b\u51fb"}}
{"id": "2509.11880", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.11880", "abs": "https://arxiv.org/abs/2509.11880", "authors": ["Carlos Celemin", "Joseph Brennan", "Pierluigi Vito Amadori", "Tim Bradley"], "title": "Learning Representations in Video Game Agents with Supervised Contrastive Imitation Learning", "comment": null, "summary": "This paper introduces a novel application of Supervised Contrastive Learning\n(SupCon) to Imitation Learning (IL), with a focus on learning more effective\nstate representations for agents in video game environments. The goal is to\nobtain latent representations of the observations that capture better the\naction-relevant factors, thereby modeling better the cause-effect relationship\nfrom the observations that are mapped to the actions performed by the\ndemonstrator, for example, the player jumps whenever an obstacle appears ahead.\nWe propose an approach to integrate the SupCon loss with continuous output\nspaces, enabling SupCon to operate without constraints regarding the type of\nactions of the environment. Experiments on the 3D games Astro Bot and Returnal,\nand multiple 2D Atari games show improved representation quality, faster\nlearning convergence, and better generalization compared to baseline models\ntrained only with supervised action prediction loss functions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60(SupCon)\u5e94\u7528\u4e8e\u6a21\u4eff\u5b66\u4e60(IL)\uff0c\u901a\u8fc7\u5728\u89c6\u9891\u6e38\u620f\u73af\u5883\u4e2d\u5b66\u4e60\u66f4\u6709\u6548\u7684\u72b6\u6001\u8868\u793a\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u52a8\u4f5c\u76f8\u5173\u56e0\u7d20\u548c\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "\u76ee\u6807\u662f\u83b7\u5f97\u80fd\u591f\u66f4\u597d\u6355\u6349\u52a8\u4f5c\u76f8\u5173\u56e0\u7d20\u7684\u89c2\u6d4b\u6f5c\u5728\u8868\u793a\uff0c\u4ece\u800c\u66f4\u597d\u5730\u5efa\u6a21\u4ece\u89c2\u6d4b\u5230\u6f14\u793a\u8005\u6267\u884c\u52a8\u4f5c\u7684\u56e0\u679c\u5173\u7cfb\uff08\u4f8b\u5982\u73a9\u5bb6\u5728\u969c\u788d\u7269\u51fa\u73b0\u65f6\u8df3\u8dc3\uff09\u3002", "method": "\u63d0\u51fa\u5c06SupCon\u635f\u5931\u4e0e\u8fde\u7eed\u8f93\u51fa\u7a7a\u95f4\u96c6\u6210\u7684\u65b9\u6cd5\uff0c\u4f7fSupCon\u80fd\u591f\u5728\u4e0d\u53d7\u73af\u5883\u52a8\u4f5c\u7c7b\u578b\u9650\u5236\u7684\u60c5\u51b5\u4e0b\u64cd\u4f5c\u3002", "result": "\u57283D\u6e38\u620fAstro Bot\u548cReturnal\u4ee5\u53ca\u591a\u4e2a2D Atari\u6e38\u620f\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u4ec5\u4f7f\u7528\u76d1\u7763\u52a8\u4f5c\u9884\u6d4b\u635f\u5931\u51fd\u6570\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u8868\u793a\u8d28\u91cf\u3001\u52a0\u5feb\u4e86\u5b66\u4e60\u6536\u655b\u901f\u5ea6\u5e76\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u5347\u6a21\u4eff\u5b66\u4e60\u4e2d\u72b6\u6001\u8868\u793a\u7684\u8d28\u91cf\u548c\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2509.11451", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11451", "abs": "https://arxiv.org/abs/2509.11451", "authors": ["Ahaan Dabholkar", "Atul Sharma", "Z. Berkay Celik", "Saurabh Bagchi"], "title": "MAUI: Reconstructing Private Client Data in Federated Transfer Learning", "comment": null, "summary": "Recent works in federated learning (FL) have shown the utility of leveraging\ntransfer learning for balancing the benefits of FL and centralized learning. In\nthis setting, federated training happens after a stable point has been reached\nthrough conventional training. Global model weights are first centrally\npretrained by the server on a public dataset following which only the last few\nlinear layers (the classification head) of the model are finetuned across\nclients. In this scenario, existing data reconstruction attacks (DRAs) in FL\nshow two key weaknesses. First, strongly input-correlated gradient information\nfrom the initial model layers is never shared, significantly degrading\nreconstruction accuracy. Second, DRAs in which the server makes highly\nspecific, handcrafted manipulations to the model structure or parameters (for\ne.g., layers with all zero weights, identity mappings and rows with identical\nweight patterns) are easily detectable by an active client.\n  Improving on these, we propose MAUI, a stealthy DRA that does not require any\novert manipulations to the model architecture or weights, and relies solely on\nthe gradients of the classification head. MAUI first extracts \"robust\" feature\nrepresentations of the input batch from the gradients of the classification\nhead and subsequently inverts these representations to the original inputs. We\nreport highly accurate reconstructions on the CIFAR10 and ImageNet datasets on\na variety of model architectures including convolution networks (CNN, VGG11),\nResNets (18, 50), ShuffleNet-V2 and Vision Transformer (ViT B-32), regardless\nof the batch size. MAUI significantly outperforms prior DRAs in reconstruction\nquality, achieving 40-120% higher PSNR scores.", "AI": {"tldr": "MAUI\u662f\u4e00\u79cd\u65b0\u578b\u7684\u8054\u90a6\u5b66\u4e60\u6570\u636e\u91cd\u5efa\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ec5\u5229\u7528\u5206\u7c7b\u5934\u7684\u68af\u5ea6\u4fe1\u606f\uff0c\u5728\u4e0d\u4fee\u6539\u6a21\u578b\u67b6\u6784\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u6570\u636e\u91cd\u5efa\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u6570\u636e\u91cd\u5efa\u653b\u51fb\u5728\u8fc1\u79fb\u5b66\u4e60\u573a\u666f\u4e2d\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5f31\u70b9\uff1a1\uff09\u521d\u59cb\u5c42\u68af\u5ea6\u4fe1\u606f\u7f3a\u5931\u5bfc\u81f4\u91cd\u5efa\u7cbe\u5ea6\u4e0b\u964d\uff1b2\uff09\u9700\u8981\u4fee\u6539\u6a21\u578b\u67b6\u6784\u7684\u663e\u5f0f\u653b\u51fb\u5bb9\u6613\u88ab\u5ba2\u6237\u7aef\u68c0\u6d4b\u3002", "method": "MAUI\u4ec5\u5229\u7528\u5206\u7c7b\u5934\u7684\u68af\u5ea6\u4fe1\u606f\uff0c\u9996\u5148\u4ece\u68af\u5ea6\u4e2d\u63d0\u53d6\u9c81\u68d2\u7684\u7279\u5f81\u8868\u793a\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u7279\u5f81\u8868\u793a\u53cd\u6f14\u4e3a\u539f\u59cb\u8f93\u5165\u6570\u636e\u3002", "result": "\u5728CIFAR10\u548cImageNet\u6570\u636e\u96c6\u4e0a\uff0c\u9488\u5bf9\u591a\u79cd\u6a21\u578b\u67b6\u6784\uff08CNN\u3001VGG11\u3001ResNet\u3001ShuffleNet-V2\u3001ViT\uff09\u5747\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u91cd\u5efa\uff0cPSNR\u5206\u6570\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad840-120%\u3002", "conclusion": "MAUI\u8bc1\u660e\u4e86\u5373\u4f7f\u5728\u6ca1\u6709\u521d\u59cb\u5c42\u68af\u5ea6\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\uff0c\u4ec5\u901a\u8fc7\u5206\u7c7b\u5934\u68af\u5ea6\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u6548\u7684\u6570\u636e\u91cd\u5efa\uff0c\u4e14\u5177\u6709\u66f4\u597d\u7684\u9690\u853d\u6027\u3002"}}
{"id": "2509.11914", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11914", "abs": "https://arxiv.org/abs/2509.11914", "authors": ["Yiqun Yao", "Naitong Yu", "Xiang Li", "Xin Jiang", "Xuezhi Fang", "Wenjia Ma", "Xuying Meng", "Jing Li", "Aixin Sun", "Yequan Wang"], "title": "EgoMem: Lifelong Memory Agent for Full-duplex Omnimodal Models", "comment": null, "summary": "We introduce EgoMem, the first lifelong memory agent tailored for full-duplex\nmodels that process real-time omnimodal streams. EgoMem enables real-time\nmodels to recognize multiple users directly from raw audiovisual streams, to\nprovide personalized response, and to maintain long-term knowledge of users'\nfacts, preferences, and social relationships extracted from audiovisual\nhistory. EgoMem operates with three asynchronous processes: (i) a retrieval\nprocess that dynamically identifies user via face and voice, and gathers\nrelevant context from a long-term memory; (ii) an omnimodal dialog process that\ngenerates personalized audio responses based on the retrieved context; and\n(iii) a memory management process that automatically detects dialog boundaries\nfrom omnimodal streams, and extracts necessary information to update the\nlong-term memory. Unlike existing memory agents for LLMs, EgoMem relies\nentirely on raw audiovisual streams, making it especially suitable for\nlifelong, real-time, and embodied scenarios. Experimental results demonstrate\nthat EgoMem's retrieval and memory management modules achieve over 95% accuracy\non the test set. When integrated with a fine-tuned RoboEgo omnimodal chatbot,\nthe system achieves fact-consistency scores above 87% in real-time personalized\ndialogs, establishing a strong baseline for future research.", "AI": {"tldr": "EgoMem\u662f\u9996\u4e2a\u4e3a\u5168\u53cc\u5de5\u6a21\u578b\u8bbe\u8ba1\u7684\u7ec8\u8eab\u8bb0\u5fc6\u4ee3\u7406\uff0c\u80fd\u591f\u4ece\u539f\u59cb\u89c6\u542c\u6d41\u4e2d\u5b9e\u65f6\u8bc6\u522b\u591a\u7528\u6237\u3001\u63d0\u4f9b\u4e2a\u6027\u5316\u54cd\u5e94\uff0c\u5e76\u7ef4\u62a4\u7528\u6237\u7684\u957f\u671f\u77e5\u8bc6\u8bb0\u5fc6\u3002", "motivation": "\u73b0\u6709\u7684\u8bb0\u5fc6\u4ee3\u7406\u4e3b\u8981\u9762\u5411LLMs\uff0c\u65e0\u6cd5\u5904\u7406\u5b9e\u65f6\u5168\u53cc\u5de5\u6a21\u578b\u7684\u89c6\u542c\u6d41\u8f93\u5165\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u7ec8\u8eab\u3001\u5b9e\u65f6\u548c\u5177\u8eab\u573a\u666f\u7684\u8bb0\u5fc6\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u5f02\u6b65\u8fdb\u7a0b\uff1a\u68c0\u7d22\u8fc7\u7a0b\uff08\u52a8\u6001\u8bc6\u522b\u7528\u6237\u5e76\u6536\u96c6\u76f8\u5173\u4e0a\u4e0b\u6587\uff09\u3001\u5168\u6a21\u6001\u5bf9\u8bdd\u8fc7\u7a0b\uff08\u751f\u6210\u4e2a\u6027\u5316\u97f3\u9891\u54cd\u5e94\uff09\u3001\u5185\u5b58\u7ba1\u7406\u8fc7\u7a0b\uff08\u68c0\u6d4b\u5bf9\u8bdd\u8fb9\u754c\u5e76\u66f4\u65b0\u957f\u671f\u8bb0\u5fc6\uff09\u3002", "result": "\u68c0\u7d22\u548c\u5185\u5b58\u7ba1\u7406\u6a21\u5757\u51c6\u786e\u7387\u8d85\u8fc795%\uff0c\u4e0eRoboEgo\u5168\u6a21\u6001\u804a\u5929\u673a\u5668\u4eba\u96c6\u6210\u540e\uff0c\u5b9e\u65f6\u4e2a\u6027\u5316\u5bf9\u8bdd\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u5f97\u5206\u8d85\u8fc787%\u3002", "conclusion": "EgoMem\u4e3a\u5b9e\u65f6\u5168\u53cc\u5de5\u6a21\u578b\u5efa\u7acb\u4e86\u5f3a\u5927\u7684\u7ec8\u8eab\u8bb0\u5fc6\u57fa\u51c6\uff0c\u5b8c\u5168\u57fa\u4e8e\u539f\u59cb\u89c6\u542c\u6d41\u5904\u7406\uff0c\u9002\u5408\u7ec8\u8eab\u5b66\u4e60\u548c\u5177\u8eab\u667a\u80fd\u573a\u666f\u3002"}}
{"id": "2509.11555", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11555", "abs": "https://arxiv.org/abs/2509.11555", "authors": ["Shunfan Zhou", "Kevin Wang", "Hang Yin"], "title": "Dstack: A Zero Trust Framework for Confidential Containers", "comment": null, "summary": "Web3 applications require execution platforms that maintain confidentiality\nand integrity without relying on centralized trust authorities. While Trusted\nExecution Environments (TEEs) offer promising capabilities for confidential\ncomputing, current implementations face significant limitations when applied to\nWeb3 contexts, particularly in security reliability, censorship resistance, and\nvendor independence.\n  This paper presents dstack, a comprehensive framework that transforms raw TEE\ntechnology into a true Zero Trust platform. We introduce three key innovations:\n(1) Portable Confidential Containers that enable seamless workload migration\nacross heterogeneous TEE environments while maintaining security guarantees,\n(2) Decentralized Code Management that leverages smart contracts for\ntransparent governance of TEE applications, and (3) Verifiable Domain\nManagement that ensures secure and verifiable application identity without\ncentralized authorities.\n  These innovations are implemented through three core components: dstack-OS,\ndstack-KMS, and dstack-Gateway. Together, they demonstrate how to achieve both\nthe performance advantages of VM-level TEE solutions and the trustless\nguarantees required by Web3 applications. Our evaluation shows that dstack\nprovides comprehensive security guarantees while maintaining practical\nusability for real-world applications.", "AI": {"tldr": "dstack\u662f\u4e00\u4e2a\u5c06\u539f\u59cbTEE\u6280\u672f\u8f6c\u5316\u4e3a\u96f6\u4fe1\u4efb\u5e73\u53f0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4fbf\u643a\u5f0f\u673a\u5bc6\u5bb9\u5668\u3001\u53bb\u4e2d\u5fc3\u5316\u4ee3\u7801\u7ba1\u7406\u548c\u53ef\u9a8c\u8bc1\u57df\u7ba1\u7406\u4e09\u5927\u521b\u65b0\uff0c\u4e3aWeb3\u5e94\u7528\u63d0\u4f9b\u5b89\u5168\u53ef\u9760\u7684\u6267\u884c\u73af\u5883\u3002", "motivation": "Web3\u5e94\u7528\u9700\u8981\u4e0d\u4f9d\u8d56\u4e2d\u5fc3\u5316\u4fe1\u4efb\u673a\u6784\u7684\u673a\u5bc6\u8ba1\u7b97\u5e73\u53f0\uff0c\u4f46\u73b0\u6709TEE\u5b9e\u73b0\u5728\u5b89\u5168\u53ef\u9760\u6027\u3001\u6297\u5ba1\u67e5\u6027\u548c\u4f9b\u5e94\u5546\u72ec\u7acb\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u9650\u5236\u3002", "method": "\u63d0\u51fadstack\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1adstack-OS\u3001dstack-KMS\u548cdstack-Gateway\uff0c\u5b9e\u73b0\u4fbf\u643a\u5f0f\u673a\u5bc6\u5bb9\u5668\u3001\u53bb\u4e2d\u5fc3\u5316\u4ee3\u7801\u7ba1\u7406\u548c\u53ef\u9a8c\u8bc1\u57df\u7ba1\u7406\u4e09\u5927\u521b\u65b0\u6280\u672f\u3002", "result": "\u8bc4\u4f30\u663e\u793adstack\u5728\u63d0\u4f9b\u5168\u9762\u5b89\u5168\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e86\u5b9e\u9645\u5e94\u7528\u7684\u53ef\u7528\u6027\uff0c\u517c\u5177VM\u7ea7TEE\u89e3\u51b3\u65b9\u6848\u7684\u6027\u80fd\u4f18\u52bf\u548cWeb3\u5e94\u7528\u6240\u9700\u7684\u65e0\u4fe1\u4efb\u4fdd\u8bc1\u3002", "conclusion": "dstack\u6210\u529f\u5c06\u539f\u59cbTEE\u6280\u672f\u8f6c\u5316\u4e3a\u771f\u6b63\u7684\u96f6\u4fe1\u4efb\u5e73\u53f0\uff0c\u4e3aWeb3\u5e94\u7528\u63d0\u4f9b\u4e86\u5b89\u5168\u53ef\u9760\u7684\u6267\u884c\u73af\u5883\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.11922", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11922", "abs": "https://arxiv.org/abs/2509.11922", "authors": ["Xilei Dai", "Ruotian Chen", "Songze Guan", "Wen-Tai Li", "Chau Yuen"], "title": "BuildingGym: An open-source toolbox for AI-based building energy management using reinforcement learning", "comment": null, "summary": "Reinforcement learning (RL) has proven effective for AI-based building energy\nmanagement. However, there is a lack of flexible framework to implement RL\nacross various control problems in building energy management. To address this\ngap, we propose BuildingGym, an open-source tool designed as a\nresearch-friendly and flexible framework for training RL control strategies for\ncommon challenges in building energy management. BuildingGym integrates\nEnergyPlus as its core simulator, making it suitable for both system-level and\nroom-level control. Additionally, BuildingGym is able to accept external\nsignals as control inputs instead of taking the building as a stand-alone\nentity. This feature makes BuildingGym applicable for more flexible\nenvironments, e.g. smart grid and EVs community. The tool provides several\nbuilt-in RL algorithms for control strategy training, simplifying the process\nfor building managers to obtain optimal control strategies. Users can achieve\nthis by following a few straightforward steps to configure BuildingGym for\noptimization control for common problems in the building energy management\nfield. Moreover, AI specialists can easily implement and test state-of-the-art\ncontrol algorithms within the platform. BuildingGym bridges the gap between\nbuilding managers and AI specialists by allowing for the easy configuration and\nreplacement of RL algorithms, simulators, and control environments or problems.\nWith BuildingGym, we efficiently set up training tasks for cooling load\nmanagement, targeting both constant and dynamic cooling load management. The\nbuilt-in algorithms demonstrated strong performance across both tasks,\nhighlighting the effectiveness of BuildingGym in optimizing cooling strategies.", "AI": {"tldr": "\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u9886\u57df\u7f3a\u4e4f\u7075\u6d3b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u5f00\u6e90\u5de5\u5177BuildingGym\uff0c\u901a\u8fc7\u96c6\u6210EnergyPlus\u6a21\u62df\u5668\u548c\u5916\u90e8\u4fe1\u53f7\u63a5\u53e3\uff0c\u652f\u6301\u7cfb\u7edf\u7ea7\u548c\u623f\u95f4\u7ea7\u63a7\u5236\uff0c\u4e3a\u5efa\u7b51\u7ba1\u7406\u8005\u548cAI\u4e13\u5bb6\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684RL\u7b97\u6cd5\u8bad\u7ec3\u5e73\u53f0\u3002", "motivation": "\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u9886\u57df\u867d\u7136\u5f3a\u5316\u5b66\u4e60\u5df2\u7ecf\u8bc1\u660e\u6709\u6548\uff0c\u4f46\u7f3a\u4e4f\u4e00\u4e2a\u7075\u6d3b\u7684\u6846\u67b6\u6765\u5728\u5404\u79cd\u63a7\u5236\u95ee\u9898\u4e2d\u5b9e\u73b0RL\u7b97\u6cd5\u3002", "method": "\u5f00\u53d1BuildingGym\u5f00\u6e90\u5de5\u5177\uff0c\u96c6\u6210EnergyPlus\u4f5c\u4e3a\u6838\u5fc3\u6a21\u62df\u5668\uff0c\u652f\u6301\u5916\u90e8\u4fe1\u53f7\u8f93\u5165\uff0c\u63d0\u4f9b\u591a\u79cd\u5185\u7f6eRL\u7b97\u6cd5\uff0c\u652f\u6301\u7cfb\u7edf\u7ea7\u548c\u623f\u95f4\u7ea7\u63a7\u5236\u3002", "result": "\u901a\u8fc7BuildingGym\u9ad8\u6548\u8bbe\u7f6e\u4e86\u5236\u51b7\u8d1f\u8377\u7ba1\u7406\u8bad\u7ec3\u4efb\u52a1\uff0c\u5305\u62ec\u5e38\u89c4\u548c\u52a8\u6001\u5236\u51b7\u8d1f\u8377\u7ba1\u7406\u3002\u5185\u7f6e\u7b97\u6cd5\u5728\u4e24\u79cd\u4efb\u52a1\u4e2d\u90fd\u8868\u73b0\u51fa\u8270\u5f3a\u7684\u6027\u80fd\u3002", "conclusion": "BuildingGym\u5e73\u53f0\u6709\u6548\u5730\u4e3a\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u9886\u57df\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684RL\u63a7\u5236\u7b56\u7565\u8bad\u7ec3\u6846\u67b6\uff0c\u5e2e\u52a9\u5efa\u7b51\u7ba1\u7406\u8005\u83b7\u5f97\u6700\u4f18\u63a7\u5236\u7b56\u7565\uff0c\u540c\u65f6\u4e3aAI\u4e13\u5bb6\u63d0\u4f9b\u4e86\u7b97\u6cd5\u5b9e\u73b0\u548c\u6d4b\u8bd5\u73af\u5883\u3002"}}
{"id": "2509.11559", "categories": ["cs.CR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.11559", "abs": "https://arxiv.org/abs/2509.11559", "authors": ["Tarakaram Gollamudi", "Anitha Gollamudi", "Joshua Gancher"], "title": "ILA: Correctness via Type Checking for Fully Homomorphic Encryption", "comment": null, "summary": "RLWE-based Fully Homomorphic Encryption (FHE) schemes add some small\n\\emph{noise} to the message during encryption. The noise accumulates with each\nhomomorphic operation. When the noise exceeds a critical value, the FHE circuit\nproduces an incorrect output. This makes developing FHE applications quite\nsubtle, as one must closely track the noise to ensure correctness. However,\nexisting libraries and compilers offer limited support to statically track the\nnoise. Additionally, FHE circuits are also plagued by wraparound errors that\nare common in finite modulus arithmetic. These two limitations of existing\ncompilers and libraries make FHE applications too difficult to develop with\nconfidence.\n  In this work, we present a \\emph{correctness-oriented} IR, Intermediate\nLanguage for Arithmetic circuits, for type-checking circuits intended for\nhomomorphic evaluation. Our IR is backed by a type system that tracks low-level\nquantitative bounds (e.g., ciphertext noise) without using the secret key.\nUsing our type system, we identify and prove a strong \\emph{functional\ncorrectness} criterion for \\ila circuits. Additionally, we have designed \\ila\nto be maximally general: our core type system does not directly assume a\nparticular FHE scheme, but instead axiomatizes a \\emph{model} of FHE. We\ninstantiate this model with the exact FHE schemes (BGV, BFV and TFHE), and\nobtain functional correctness for free.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u6b63\u786e\u6027\u7684\u4e2d\u95f4\u8868\u793a\u8bed\u8a00ILA\uff0c\u7528\u4e8e\u540c\u6001\u52a0\u5bc6\u7535\u8def\u7684\u7c7b\u578b\u68c0\u67e5\uff0c\u901a\u8fc7\u7c7b\u578b\u7cfb\u7edf\u8ddf\u8e2a\u566a\u58f0\u8fb9\u754c\u548c\u5305\u88c5\u9519\u8bef\uff0c\u786e\u4fdd\u529f\u80fd\u6b63\u786e\u6027", "motivation": "\u73b0\u6709FHE\u5e93\u548c\u7f16\u8bd1\u5668\u5bf9\u566a\u58f0\u9759\u6001\u8ddf\u8e2a\u652f\u6301\u6709\u9650\uff0c\u4e14\u5b58\u5728\u6709\u9650\u6a21\u7b97\u672f\u7684\u5305\u88c5\u9519\u8bef\u95ee\u9898\uff0c\u5bfc\u81f4FHE\u5e94\u7528\u5f00\u53d1\u56f0\u96be\u4e14\u7f3a\u4e4f\u4fe1\u5fc3", "method": "\u8bbe\u8ba1ILA\u4e2d\u95f4\u8bed\u8a00\u548c\u7c7b\u578b\u7cfb\u7edf\uff0c\u91cf\u5316\u8ddf\u8e2a\u5bc6\u7801\u6587\u672c\u566a\u58f0\u7b49\u4f4e\u7ea7\u8fb9\u754c\uff0c\u4e0d\u4f9d\u8d56\u5bc6\u94a5\uff0c\u57fa\u4e8eFHE\u6a21\u578b\u62bd\u8c61\u5e76\u5b9e\u4f8b\u5316\u5230BGV\u3001BFV\u548cTFHE\u65b9\u6848", "result": "\u5b9e\u73b0\u4e86\u529f\u80fd\u6b63\u786e\u6027\u6807\u51c6\u7684\u8bc6\u522b\u548c\u8bc1\u660e\uff0cILA\u5177\u6709\u6700\u5927\u901a\u7528\u6027\uff0c\u6838\u5fc3\u7c7b\u578b\u7cfb\u7edf\u4e0d\u76f4\u63a5\u5047\u8bbe\u7279\u5b9aFHE\u65b9\u6848", "conclusion": "ILA\u4e3a\u540c\u6001\u8bc4\u4f30\u7535\u8def\u63d0\u4f9b\u4e86\u9759\u6001\u7c7b\u578b\u68c0\u67e5\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u566a\u58f0\u8ddf\u8e2a\u548c\u5305\u88c5\u9519\u8bef\u95ee\u9898\uff0c\u63d0\u5347\u4e86FHE\u5e94\u7528\u5f00\u53d1\u7684\u53ef\u9760\u6027\u548c\u4fe1\u5fc3"}}
{"id": "2509.11940", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11940", "abs": "https://arxiv.org/abs/2509.11940", "authors": ["Marcel van Gerven"], "title": "Neuromorphic Intelligence", "comment": "18 pages, 3 figures", "summary": "Neuromorphic computing seeks to replicate the remarkable efficiency,\nflexibility, and adaptability of the human brain in artificial systems. Unlike\nconventional digital approaches, which depend on massive computational and\nenergy resources, neuromorphic systems exploit brain-inspired principles of\ncomputation to achieve orders of magnitude greater energy efficiency. By\ndrawing on insights from artificial intelligence, neuroscience, physics,\nchemistry, and materials science, neuromorphic computing promises to deliver\nintelligent systems that are sustainable, transparent, and widely accessible. A\ncentral challenge, however, is to identify a unifying theoretical framework\ncapable of bridging these diverse disciplines. We argue that dynamical systems\ntheory provides such a foundation. Rooted in differential calculus, it offers a\nprincipled language for modeling inference, learning, and control in both\nnatural and artificial substrates. Within this framework, noise can be\nharnessed as a resource for learning, while differential genetic programming\nenables the discovery of dynamical systems that implement adaptive behaviors.\nEmbracing this perspective paves the way toward emergent neuromorphic\nintelligence, where intelligent behavior arises from the dynamics of physical\nsubstrates, advancing both the science and sustainability of AI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u4f5c\u4e3a\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u80fd\u591f\u6574\u5408\u4eba\u5de5\u667a\u80fd\u3001\u795e\u7ecf\u79d1\u5b66\u3001\u7269\u7406\u5b66\u7b49\u591a\u5b66\u79d1\u77e5\u8bc6\uff0c\u901a\u8fc7\u5229\u7528\u566a\u58f0\u4f5c\u4e3a\u5b66\u4e60\u8d44\u6e90\u548c\u5fae\u5206\u9057\u4f20\u7f16\u7a0b\u6765\u5b9e\u73b0\u81ea\u9002\u5e94\u884c\u4e3a\u3002", "motivation": "\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u65e8\u5728\u590d\u5236\u4eba\u8111\u7684\u9ad8\u6548\u6027\u548c\u9002\u5e94\u6027\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u6574\u5408\u591a\u5b66\u79d1\u77e5\u8bc6\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6838\u5fc3\u6311\u6218\uff0c\u4e3a\u795e\u7ecf\u5f62\u6001\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u91c7\u7528\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u4f5c\u4e3a\u7406\u8bba\u57fa\u7840\uff0c\u8be5\u7406\u8bba\u57fa\u4e8e\u5fae\u5206\u8ba1\u7b97\uff0c\u4e3a\u5efa\u6a21\u63a8\u7406\u3001\u5b66\u4e60\u548c\u63a7\u5236\u63d0\u4f9b\u539f\u5219\u6027\u8bed\u8a00\u3002\u901a\u8fc7\u5229\u7528\u566a\u58f0\u4f5c\u4e3a\u5b66\u4e60\u8d44\u6e90\uff0c\u5e76\u4f7f\u7528\u5fae\u5206\u9057\u4f20\u7f16\u7a0b\u6765\u53d1\u73b0\u5b9e\u73b0\u81ea\u9002\u5e94\u884c\u4e3a\u7684\u52a8\u529b\u7cfb\u7edf\u3002", "result": "\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u6210\u529f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u80fd\u591f\u6865\u63a5\u591a\u5b66\u79d1\u7684\u6846\u67b6\uff0c\u4f7f\u667a\u80fd\u884c\u4e3a\u80fd\u591f\u4ece\u7269\u7406\u57fa\u8d28\u7684\u52a8\u529b\u5b66\u4e2d\u6d8c\u73b0\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86AI\u7684\u79d1\u5b66\u6027\u548c\u53ef\u6301\u7eed\u6027\u3002", "conclusion": "\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u4e3a\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u795e\u7ecf\u5f62\u6001\u667a\u80fd\u7684\u53d1\u5c55\uff0c\u4f7f\u667a\u80fd\u7cfb\u7edf\u66f4\u52a0\u53ef\u6301\u7eed\u3001\u900f\u660e\u548c\u6613\u4e8e\u8bbf\u95ee\uff0c\u4e3aAI\u7684\u79d1\u5b66\u548c\u53ef\u6301\u7eed\u53d1\u5c55\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2509.11615", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11615", "abs": "https://arxiv.org/abs/2509.11615", "authors": ["Rimsha Kanwal", "Umara Noor", "Zafar Iqbal", "Zahid Rashid"], "title": "Cyber Threat Hunting: Non-Parametric Mining of Attack Patterns from Cyber Threat Intelligence for Precise Threats Attribution", "comment": null, "summary": "With the ever-changing landscape of cyber threats, identifying their origin\nhas become paramount, surpassing the simple task of attack classification.\nCyber threat attribution gives security analysts the insights they need to\ndevice effective threat mitigation strategies. Such strategies empower\nenterprises to proactively detect and defend against future cyber-attacks.\nHowever, existing approaches exhibit limitations in accurately identifying\nthreat actors, leading to low precision and a significant occurrence of false\npositives. Machine learning offers the potential to automate certain aspects of\ncyber threat attribution. The distributed nature of information regarding cyber\nthreat actors and their intricate attack methodologies has hindered substantial\nprogress in this domain. Cybersecurity analysts deal with an ever-expanding\ncollection of cyber threat intelligence documents. While these documents hold\nvaluable insights, their sheer volume challenges efficient organization and\nretrieval of pertinent information. To assist the cybersecurity analyst\nactivities, we propose a machine learning based approach featuring visually\ninteractive analytics tool named the Cyber-Attack Pattern Explorer (CAPE),\ndesigned to facilitate efficient information discovery by employing interactive\nvisualization and mining techniques. In the proposed system, a non-parametric\nmining technique is proposed to create a dataset for identifying the attack\npatterns within cyber threat intelligence documents. These attack patterns\nalign semantically with commonly employed themes ensuring ease of\ninterpretation. The extracted dataset is used for training of proposed machine\nlearning algorithms that enables the attribution of cyber threats with\nrespective to the actors.", "AI": {"tldr": "\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u548c\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177CAPE\uff0c\u81ea\u52a8\u5316\u7f51\u7edc\u5a01\u80c1\u5f52\u56e0\u5206\u6790\uff0c\u63d0\u9ad8\u653b\u51fb\u6a21\u5f0f\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387", "motivation": "\u73b0\u6709\u7f51\u7edc\u5a01\u80c1\u5f52\u56e0\u65b9\u6cd5\u51c6\u786e\u6027\u4f4e\u3001\u8bef\u62a5\u7387\u9ad8\uff0c\u800c\u5a01\u80c1\u60c5\u62a5\u6587\u6863\u6570\u91cf\u5de8\u5927\u7ec4\u7ec7\u56f0\u96be\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51faCyber-Attack Pattern Explorer (CAPE)\u5de5\u5177\uff0c\u91c7\u7528\u975e\u53c2\u6570\u6316\u6398\u6280\u672f\u4ece\u5a01\u80c1\u60c5\u62a5\u6587\u6863\u4e2d\u63d0\u53d6\u653b\u51fb\u6a21\u5f0f\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u548c\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u5a01\u80c1\u5f52\u56e0", "result": "\u6784\u5efa\u4e86\u53ef\u4ee5\u8bc6\u522b\u653b\u51fb\u6a21\u5f0f\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u6a21\u5f0f\u5728\u8bed\u4e49\u4e0a\u4e0e\u5e38\u7528\u4e3b\u9898\u4fdd\u6301\u4e00\u81f4\uff0c\u65b9\u4fbf\u89e3\u91ca\u548c\u5206\u6790", "conclusion": "CAPE\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5730\u652f\u6301\u5b89\u5168\u5206\u6790\u5e08\u8fdb\u884c\u7f51\u7edc\u5a01\u80c1\u5f52\u56e0\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6316\u6398\u548c\u53ef\u89c6\u5316\u5c55\u793a\u63d0\u9ad8\u4fe1\u606f\u53d1\u73b0\u6548\u7387"}}
{"id": "2509.11941", "categories": ["cs.AI", "cs.CL", "I.2.7; I.2.1"], "pdf": "https://arxiv.org/pdf/2509.11941", "abs": "https://arxiv.org/abs/2509.11941", "authors": ["Ilia Kopanichuk", "Petr Anokhin", "Vladimir Shaposhnikov", "Vladimir Makharev", "Ekaterina Tsapieva", "Iaroslav Bespalov", "Dmitry V. Dylov", "Ivan Oseledets"], "title": "How to Evaluate Medical AI", "comment": "10 pages, 7 fugures", "summary": "The integration of artificial intelligence (AI) into medical diagnostic\nworkflows requires robust and consistent evaluation methods to ensure\nreliability, clinical relevance, and the inherent variability in expert\njudgments. Traditional metrics like precision and recall often fail to account\nfor the inherent variability in expert judgments, leading to inconsistent\nassessments of AI performance. Inter-rater agreement statistics like Cohen's\nKappa are more reliable but they lack interpretability. We introduce Relative\nPrecision and Recall of Algorithmic Diagnostics (RPAD and RRAD) - a new\nevaluation metrics that compare AI outputs against multiple expert opinions\nrather than a single reference. By normalizing performance against inter-expert\ndisagreement, these metrics provide a more stable and realistic measure of the\nquality of predicted diagnosis. In addition to the comprehensive analysis of\ndiagnostic quality measures, our study contains a very important side result.\nOur evaluation methodology allows us to avoid selecting diagnoses from a\nlimited list when evaluating a given case. Instead, both the models being\ntested and the examiners verifying them arrive at a free-form diagnosis. In\nthis automated methodology for establishing the identity of free-form clinical\ndiagnoses, a remarkable 98% accuracy becomes attainable. We evaluate our\napproach using 360 medical dialogues, comparing multiple large language models\n(LLMs) against a panel of physicians. Large-scale study shows that\ntop-performing models, such as DeepSeek-V3, achieve consistency on par with or\nexceeding expert consensus. Moreover, we demonstrate that expert judgments\nexhibit significant variability - often greater than that between AI and\nhumans. This finding underscores the limitations of any absolute metrics and\nsupports the need to adopt relative metrics in medical AI.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u76f8\u5bf9\u7cbe\u5ea6\u548c\u76f8\u5bf9\u56de\u6389\u7387\u6307\u6807\uff08RPAD/RRAD\uff09\uff0c\u901a\u8fc7\u4e0e\u591a\u4e2a\u4e13\u5bb6\u610f\u89c1\u5bf9\u6bd4\u6765\u8bc4\u4f30AI\u8bca\u65ad\u6027\u80fd\uff0c\u89e3\u51b3\u4f20\u7edf\u6307\u6807\u65e0\u6cd5\u5904\u7406\u4e13\u5bb6\u5224\u65ad\u53d8\u5f02\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7684\u7cbe\u5ea6\u548c\u56de\u6389\u7387\u7b49\u8bc4\u4f30\u6307\u6807\u65e0\u6cd5\u8003\u8651\u533b\u5b66\u4e13\u5bb6\u5224\u65ad\u7684\u672c\u8d28\u53d8\u5f02\u6027\uff0c\u5bfc\u81f4\u5bf9AI\u6027\u80fd\u7684\u8bc4\u4f30\u4e0d\u4e00\u81f4\u3002\u867d\u7136Cohen's Kappa\u7b49\u4e00\u81f4\u6027\u7edf\u8ba1\u91cf\u66f4\u53ef\u9760\uff0c\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faRPAD\u548cRRAD\u6307\u6807\uff0c\u5c06AI\u8f93\u51fa\u4e0e\u591a\u4e2a\u4e13\u5bb6\u610f\u89c1\u8fdb\u884c\u5bf9\u6bd4\uff0c\u800c\u975e\u5355\u4e00\u53c2\u8003\u6807\u51c6\u3002\u901a\u8fc7\u5c06\u6027\u80fd\u5f52\u4e00\u5316\u5230\u4e13\u5bb6\u95f4\u4e0d\u4e00\u81f4\u6027\u6765\u63d0\u4f9b\u66f4\u7a33\u5b9a\u548c\u73b0\u5b9e\u7684\u8bca\u65ad\u8d28\u91cf\u6d4b\u91cf\u3002\u4f7f\u7528\u81ea\u52a8\u5316\u65b9\u6cd5\u786e\u5b9a\u81ea\u7531\u5f62\u5f0f\u4e34\u5e8a\u8bca\u65ad\u7684\u540c\u4e00\u6027\u3002", "result": "\u5728360\u4e2a\u533b\u7597\u5bf9\u8bdd\u4e0a\u8bc4\u4f30\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u50cfDeepSeek-V3\u8fd9\u6837\u7684\u9876\u7ea7\u6a21\u578b\u8fbe\u5230\u4e86\u4e0e\u4e13\u5bb6\u5171\u8bc6\u76f8\u5f53\u6216\u66f4\u9ad8\u7684\u4e00\u81f4\u6027\u3002\u4e13\u5bb6\u5224\u65ad\u5b58\u5728\u663e\u8457\u53d8\u5f02\u6027\uff0c\u751a\u81f3\u9ad8\u4e8eAI\u4e0e\u4eba\u7c7b\u4e4b\u95f4\u7684\u5dee\u5f02\u3002\u81ea\u52a8\u5316\u8bca\u65ad\u540c\u4e00\u6027\u786e\u5b9a\u65b9\u6cd5\u8fbe\u5230\u4e8698%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u4e13\u5bb6\u5224\u65ad\u7684\u663e\u8457\u53d8\u6027\u6027\u5f3a\u8c03\u4e86\u7edd\u5bf9\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u652f\u6301\u5728\u533b\u5b66AI\u4e2d\u91c7\u7528\u76f8\u5bf9\u6307\u6807\u7684\u5fc5\u8981\u6027\u3002\u65b0\u63d0\u51fa\u7684RPAD/RRAD\u6307\u6807\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u548c\u73b0\u5b9e\u7684AI\u8bca\u65ad\u6027\u80fd\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2509.11668", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11668", "abs": "https://arxiv.org/abs/2509.11668", "authors": ["Fizza Khurshid", "Umara Noor", "Zahid Rashid"], "title": "Cyber Attack Mitigation Framework for Denial of Service (DoS) Attacks in Fog Computing", "comment": null, "summary": "Innovative solutions to cyber security issues are shaped by the ever-changing\nlandscape of cyber threats. Automating the mitigation of these threats can be\nachieved through a new methodology that addresses the domain of mitigation\nautomation, which is often overlooked. This literature overview emphasizes the\nlack of scholarly work focusing specifically on automated cyber threat\nmitigation, particularly in addressing challenges beyond detection. The\nproposed methodology comprise of the development of an automatic cyber threat\nmitigation framework tailored for Distributed Denial-of-Service (DDoS) attacks.\nThis framework adopts a multi-layer security approach, utilizing smart devices\nat the device layer, and leveraging fog network and cloud computing layers for\ndeeper understanding and technological adaptability. Initially, firewall\nrule-based packet inspection is conducted on simulated attack traffic to filter\nout DoS packets, forwarding legitimate packets to the fog. The methodology\nemphasizes the integration of fog detection through statistical and behavioral\nanalysis, specification-based detection, and deep packet inspection, resulting\nin a comprehensive cyber protection system. Furthermore, cloud-level inspection\nis performed to confirm and mitigate attacks using firewalls, enhancing\nstrategic defense and increasing robustness against cyber threats. These\nenhancements enhance understanding of the research framework's practical\nimplementation and assessment strategies, substantiating its importance in\naddressing current cyber security challenges and shaping future automation\nmitigation approaches.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5c42\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u8bbe\u5907\u3001\u96fe\u8ba1\u7b97\u548c\u4e91\u8ba1\u7b97\u7684\u7ed3\u5408\uff0c\u5b9e\u73b0\u5bf9DDoS\u653b\u51fb\u7684\u81ea\u52a8\u5316\u7f13\u89e3\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u653b\u51fb\u68c0\u6d4b\uff0c\u800c\u81ea\u52a8\u5316\u7f13\u89e3\u9886\u57df\u88ab\u5ffd\u89c6\uff0c\u9700\u8981\u521b\u65b0\u65b9\u6848\u6765\u5e94\u5bf9\u4e0d\u65ad\u53d8\u5316\u7684\u7f51\u7edc\u5a01\u80c1\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e09\u5c42\u6846\u67b6\uff1a\u8bbe\u5907\u5c42\u4f7f\u7528\u667a\u80fd\u8bbe\u5907\u8fdb\u884c\u5305\u68c0\u67e5\uff0c\u96fe\u5c42\u901a\u8fc7\u7edf\u8ba1\u5206\u6790\u3001\u884c\u4e3a\u5206\u6790\u548c\u6df1\u5ea6\u5305\u68c0\u67e5\u8fdb\u884c\u68c0\u6d4b\uff0c\u4e91\u5c42\u4f7f\u7528\u9632\u706b\u5899\u8fdb\u884c\u786e\u8ba4\u548c\u7f13\u89e3\u653b\u51fb\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u8fc7\u6ee4DoS\u6570\u636e\u5305\uff0c\u5c06\u5408\u6cd5\u6570\u636e\u5305\u8f6c\u53d1\u5230\u96fe\u5c42\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u7f51\u7edc\u5b89\u5168\u4fdd\u62a4\u7cfb\u7edf\u3002", "conclusion": "\u8fd9\u79cd\u591a\u5c42\u81ea\u52a8\u5316\u7f13\u89e3\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5bf9\u7f51\u7edc\u5a01\u80c1\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u5f53\u524d\u7f51\u7edc\u5b89\u5168\u6311\u6218\u63d0\u4f9b\u4e86\u91cd\u8981\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u81ea\u52a8\u5316\u7f13\u89e3\u6280\u672f\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2509.11943", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.11943", "abs": "https://arxiv.org/abs/2509.11943", "authors": ["Antonin Sulc", "Thorsten Hellert"], "title": "Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics", "comment": "10 pages, 1 figure, Scaling Environments for Agents (SEA) Workshop at\n  NeuralIPS", "summary": "The development of intelligent agents, particularly those powered by language\nmodels (LMs), has shown the critical role in various environments that require\nintelligent and autonomous decision. Environments are not passive testing\ngrounds and they represent the data required for agents to learn and exhibit\nvery challenging conditions that require adaptive, complex and autonomous\ncapacity to make decisions. While the paradigm of scaling models and datasets\nhas led to remarkable emergent capabilities, we argue that scaling the\nstructure, fidelity, and logical consistency of agent reasoning within these\nenvironments is a crucial, yet underexplored, dimension of AI research. This\npaper introduces a neuro-symbolic multi-agent architecture where the belief\nstates of individual agents are formally represented as Kripke models. This\nfoundational choice enables them to reason about known concepts of\n\\emph{possibility} and \\emph{necessity} using the formal language of modal\nlogic. In this work, we use of immutable, domain-specific knowledge to make\ninfere information, which is encoded as logical constraints essential for\nproper diagnosis. In the proposed model, we show constraints that actively\nguide the hypothesis generation of LMs, effectively preventing them from\nreaching physically or logically untenable conclusions. In a high-fidelity\nsimulated particle accelerator environment, our system successfully diagnoses\ncomplex, cascading failures by combining the powerful semantic intuition of LMs\nwith the rigorous, verifiable validation of modal logic and a factual world\nmodel and showcasing a viable path toward more robust, reliable, and verifiable\nautonomous agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u6001\u903b\u8f91\u7684\u795e\u7ecf\u7b26\u53f7\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u7528\u4e8e\u5728\u590d\u6742\u73af\u5883\u4e2d\u8fdb\u884c\u53ef\u9760\u8bca\u65ad\u548c\u51b3\u7b56", "motivation": "\u5f53\u524dAI\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u548c\u6570\u636e\u7684\u89c4\u6a21\u5316\uff0c\u4f46\u5ffd\u89c6\u4e86\u667a\u80fd\u4f53\u5728\u73af\u5883\u4e2d\u63a8\u7406\u7ed3\u6784\u3001\u4fdd\u771f\u5ea6\u548c\u903b\u8f91\u4e00\u81f4\u6027\u7684\u89c4\u6a21\u5316\u9700\u6c42\u3002\u73af\u5883\u4e0d\u662f\u88ab\u52a8\u7684\u6d4b\u8bd5\u573a\uff0c\u800c\u662f\u9700\u8981\u667a\u80fd\u4f53\u5177\u5907\u81ea\u9002\u5e94\u3001\u590d\u6742\u548c\u81ea\u4e3b\u51b3\u7b56\u80fd\u529b\u7684\u6311\u6218\u6027\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u7b26\u53f7\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5c06\u4e2a\u4f53\u667a\u80fd\u4f53\u7684\u4fe1\u5ff5\u72b6\u6001\u5f62\u5f0f\u5316\u4e3aKripke\u6a21\u578b\uff0c\u4f7f\u7528\u6a21\u6001\u903b\u8f91\u8fdb\u884c\u53ef\u80fd\u6027\u548c\u5fc5\u7136\u6027\u63a8\u7406\u3002\u5229\u7528\u4e0d\u53ef\u53d8\u7684\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u4f5c\u4e3a\u903b\u8f91\u7ea6\u675f\uff0c\u6307\u5bfc\u8bed\u8a00\u6a21\u578b\u7684\u5047\u8bbe\u751f\u6210\uff0c\u9632\u6b62\u5f97\u51fa\u7269\u7406\u6216\u903b\u8f91\u4e0a\u4e0d\u53ef\u884c\u7684\u7ed3\u8bba\u3002", "result": "\u5728\u9ad8\u4fdd\u771f\u6a21\u62df\u7c92\u5b50\u52a0\u901f\u5668\u73af\u5883\u4e2d\uff0c\u7cfb\u7edf\u6210\u529f\u8bca\u65ad\u4e86\u590d\u6742\u7684\u7ea7\u8054\u6545\u969c\uff0c\u7ed3\u5408\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5927\u8bed\u4e49\u76f4\u89c9\u4e0e\u6a21\u6001\u903b\u8f91\u7684\u4e25\u683c\u53ef\u9a8c\u8bc1\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u6784\u5efa\u66f4\u9c81\u68d2\u3001\u53ef\u9760\u548c\u53ef\u9a8c\u8bc1\u81ea\u4e3b\u667a\u80fd\u4f53\u7684\u53ef\u884c\u8def\u5f84\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u903b\u8f91\u7ea6\u675f\u4e0e\u795e\u7ecf\u6a21\u578b\u7684\u7ed3\u5408\uff0c\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2509.11683", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11683", "abs": "https://arxiv.org/abs/2509.11683", "authors": ["Sawera Shahid", "Umara Noor", "Zahid Rashid"], "title": "An Unsupervised Learning Approach For A Reliable Profiling Of Cyber Threat Actors Reported Globally Based On Complete Contextual Information Of Cyber Attacks", "comment": null, "summary": "Cyber attacks are rapidly increasing with the advancement of technology and\nthere is no protection for our information. To prevent future cyberattacks it\nis critical to promptly recognize cyberattacks and establish strong defense\nmechanisms against them. To respond to cybersecurity threats immediately, it is\nessential to examine the attackers skills, knowledge, and behaviors with the\ngoal of evaluating their impact on the system and comprehending the traits\nassociated with these attacks. Creating a profile of cyber threat actors based\non their traits or patterns of behavior can help to create effective defenses\nagainst cyberattacks in advance. In the current literature, multiple supervised\nmachine learning based approaches considered a smaller number of features for\nattacker profiling that are reported in textual cyber threat incident documents\nalthough these profiles have been developed based on the security experts own\nperception, we cannot rely on them. Supervised machine learning approaches\nstrictly depend upon the structure data set. This usually leads to a two step\nprocess where we first have to establish a structured data set before we can\nanalyze it and then employ it to construct defense mechanisms, which takes\ntime. In this paper, an unsupervised efficient agglomerative hierarchal\nclustering technique is proposed for profiling cybercriminal groups based on\ntheir comprehensive contextual threat information in order to address the\naforementioned issues. The main objective of this report is to identify the\nrelationship between cyber threat actors based on their common features,\naggregate them, and also profile cyber criminal groups.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u805a\u7c7b\u6280\u672f\uff0c\u7528\u4e8e\u6839\u636e\u7f51\u7edc\u5a01\u80c1\u4fe1\u606f\u5bf9\u7f51\u7edc\u7a81\u51fb\u8005\u8fdb\u884c\u5206\u7ec4\u548c\u753b\u50cf\uff0c\u4ee5\u63d0\u524d\u6784\u5efa\u6709\u6548\u9632\u5fa1\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u7ed3\u6784\u5316\u6570\u636e\u96c6\u4e14\u7279\u5f81\u6570\u91cf\u5c11\uff0c\u4e0d\u80fd\u53ef\u9760\u5730\u8bc6\u522b\u7f51\u7edc\u653b\u51fb\u8005\u7684\u7279\u5f81\u548c\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u65e0\u76d1\u7763\u805a\u7c7b\u7b97\u6cd5\uff08\u805a\u7c7b\u5206\u6790\uff09\uff0c\u6839\u636e\u7f51\u7edc\u5a01\u80c1\u4fe1\u606f\u7684\u4e0a\u4e0b\u6587\u7279\u5f81\u5bf9\u7f51\u7edc\u72af\u7f6a\u96c6\u56e2\u8fdb\u884c\u5206\u7ec4\u548c\u753b\u50cf\u3002", "result": "\u8bc6\u522b\u4e86\u4e0d\u540c\u7f51\u7edc\u5a01\u80c1\u884c\u52a8\u8005\u4e4b\u95f4\u7684\u5173\u8054\u6027\uff0c\u5e76\u6839\u636e\u5171\u540c\u7279\u5f81\u5bf9\u5176\u8fdb\u884c\u805a\u5408\u5206\u6790\uff0c\u5b9e\u73b0\u4e86\u7f51\u7edc\u72af\u7f6a\u96c6\u56e2\u7684\u81ea\u52a8\u5316\u753b\u50cf\u3002", "conclusion": "\u65e0\u76d1\u7763\u805a\u7c7b\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5206\u6790\u7f51\u7edc\u5a01\u80c1\u6570\u636e\uff0c\u63d0\u4f9b\u66f4\u52a0\u51c6\u786e\u548c\u53ef\u9760\u7684\u7f51\u7edc\u653b\u51fb\u8005\u753b\u50cf\uff0c\u4e3a\u9884\u9632\u6027\u5b89\u5168\u9632\u5fa1\u63d0\u4f9b\u652f\u6491\u3002"}}
{"id": "2509.11944", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11944", "abs": "https://arxiv.org/abs/2509.11944", "authors": ["Susanta Mitra"], "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare", "comment": null, "summary": "Healthcare and medicine are multimodal disciplines that deal with multimodal\ndata for reasoning and diagnosing multiple diseases. Although some multimodal\nreasoning models have emerged for reasoning complex tasks in scientific\ndomains, their applications in the healthcare domain remain limited and fall\nshort in correct reasoning for diagnosis. To address the challenges of\nmultimodal medical reasoning for correct diagnosis and assist the healthcare\nprofessionals, a novel temporal graph-based reasoning process modelled through\na directed graph has been proposed in the current work. It helps in\naccommodating dynamic changes in reasons through backtracking, refining the\nreasoning content, and creating new or deleting existing reasons to reach the\nbest recommendation or answer. Again, consideration of multimodal data at\ndifferent time points can enable tracking and analysis of patient health and\ndisease progression. Moreover, the proposed multi-agent temporal reasoning\nframework provides task distributions and a cross-validation mechanism to\nfurther enhance the accuracy of reasoning outputs. A few basic experiments and\nanalysis results justify the novelty and practical utility of the proposed\npreliminary approach.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u5e8f\u56fe\u57fa\u4e8e\u591a\u6a21\u6001\u533b\u7597\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6709\u5411\u56fe\u6a21\u578b\u5316\u63a8\u7406\u8fc7\u7a0b\uff0c\u652f\u6301\u56de\u6eaf\u3001\u7cbe\u70bc\u548c\u52a8\u6001\u8c03\u6574\u63a8\u7406\u5185\u5bb9\uff0c\u4ee5\u63d0\u9ad8\u533b\u7597\u8bca\u65ad\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u533b\u7597\u9886\u57df\u7684\u591a\u6a21\u6001\u6570\u636e\u9700\u8981\u6709\u6548\u63a8\u7406\uff0c\u4f46\u73b0\u6709\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\u5728\u533b\u7597\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\u6709\u9650\u4e14\u51c6\u786e\u6027\u4e0d\u8db3\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u591a\u6a21\u6001\u533b\u7597\u6570\u636e\u3001\u652f\u6301\u52a8\u6001\u53d8\u5316\u548c\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u7684\u63a8\u7406\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65f6\u5e8f\u56fe\u57fa\u4e8e\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u901a\u8fc7\u6709\u5411\u56fe\u6a21\u578b\u5316\u63a8\u7406\u903b\u8f91\u3002\u8be5\u65b9\u6cd5\u652f\u6301\u56de\u6eaf\u8c03\u6574\u3001\u7cbe\u70bc\u63a8\u7406\u5185\u5bb9\u3001\u521b\u5efa/\u5220\u9664\u63a8\u7406\u6761\u76ee\u3002\u540c\u65f6\u8003\u8651\u4e0d\u540c\u65f6\u95f4\u70b9\u7684\u591a\u6a21\u6001\u6570\u636e\uff0c\u5e76\u4f7f\u7528\u591a\u4ee3\u7406\u65f6\u5e8f\u63a8\u7406\u6846\u67b6\u8fdb\u884c\u4efb\u52a1\u5206\u914d\u548c\u4ea4\u53c9\u9a8c\u8bc1\u3002", "result": "\u57fa\u7840\u5b9e\u9a8c\u548c\u5206\u6790\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u65b0\u9896\u6027\u548c\u5b9e\u9645\u7528\u9014\u3002\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u6a21\u6001\u533b\u7597\u6570\u636e\uff0c\u8ddf\u8e2a\u5206\u6790\u60a3\u8005\u5065\u5eb7\u72b6\u51b5\u548c\u75be\u75c5\u8fdb\u5c55\uff0c\u5e76\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1\u673a\u5236\u63d0\u9ad8\u63a8\u7406\u8f93\u51fa\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u65f6\u5e8f\u56fe\u57fa\u4e8e\u591a\u6a21\u6001\u533b\u7597\u63a8\u7406\u6846\u67b6\u4e3a\u533b\u7597\u8bca\u65ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u7684\u591a\u6a21\u6001\u6570\u636e\uff0c\u652f\u6301\u52a8\u6001\u63a8\u7406\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.11695", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11695", "abs": "https://arxiv.org/abs/2509.11695", "authors": ["Daniel Herzinger", "Linus Heise", "Daniel Loebenberger", "Matthias S\u00f6llner"], "title": "Time-Based State-Management of Hash-Based Signature CAs for VPN-Authentication", "comment": "17 pages, 6 figures", "summary": "Advances in quantum computing necessitate migrating the entire technology\nstack to post-quantum cryptography. This includes IPsec-based VPN connection\nauthentication. Although there is an RFC draft for post-quantum authentication\nin this setting, the draft does not consider (stateful) hash-based signatures\ndespite their small signature size and trusted long-term security.\n  We propose a design with time-based state-management that assigns VPN devices\na certificate authority (CA) based on the hash-based signature scheme XMSS. The\nCA then issues leaf certificates which are based on classical cryptography but\nhave a short validity time, e. g., four hours. It is to be expected that even\nlarge quantum computers will take significantly longer to break the\ncryptography, making the design quantum-secure. We propose strategies to make\nthe timekeeping more resilient to faults and tampering, as well as strategies\nto recognize a wrong system time, minimize its potential damage, and quickly\nrecover.\n  The result is an OpenBSD implementation of a quantum-safe and, regarding the\nleaf certificates, highly flexible VPN authentication design that requires\nsignificantly less bandwidth and computational resources compared to existing\nalternatives.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u91c7\u7528\u57fa\u4e8eXMSS\u54c8\u5e0c\u7b7e\u540d\u7684\u65f6\u95f4\u57fa\u72b6\u6001\u7ba1\u7406\u65b9\u6848\uff0c\u5b9e\u73b0\u91cf\u5b50\u5b89\u5168\u7684IPsec VPN\u8ba4\u8bc1\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u51cf\u5c11\u5e26\u5bbd\u548c\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u7684\u53d1\u5c55\u5fc5\u987b\u5c06\u6574\u4e2a\u6280\u672f\u6808\u8fc1\u79fb\u5230\u540e\u91cf\u5b50\u52a0\u5bc6\uff0c\u5305\u62ecIPsec VPN\u8ba4\u8bc1\u3002\u5f53\u524d\u7684RFC\u8349\u6848\u6ca1\u6709\u8003\u8651\u54c8\u5e0c\u57fa\u7b7e\u540d\uff0c\u800c\u8fd9\u79cd\u7b7e\u540d\u5177\u6709\u7b7e\u540d\u5c0f\u548c\u53ef\u9760\u957f\u671f\u5b89\u5168\u7684\u4f18\u52bf\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u65f6\u95f4\u7684\u72b6\u6001\u7ba1\u7406\u65b9\u6848\uff0c\u4f7f\u7528XMSS\u54c8\u5e0c\u7b7e\u540d\u65b9\u6848\u6784\u5efa\u8bc1\u4e66\u6388\u6743\u673a\u6784(CA)\uff0cCA\u53d1\u884c\u57fa\u4e8e\u7ecf\u5178\u52a0\u5bc6\u7684\u77e9\u4f4d\u8bc1\u4e66\uff08\u6709\u6548\u671f\u77ed\uff0c\u59824\u5c0f\u65f6\uff09\u3002\u63d0\u51fa\u4e86\u589e\u5f3a\u65f6\u949f\u5f39\u6027\u3001\u8bc6\u522b\u7cfb\u7edf\u65f6\u949f\u9519\u8bef\u4ee5\u53ca\u5feb\u901f\u6062\u590d\u7684\u7b56\u7565\u3002", "result": "\u5b9e\u73b0\u4e86\u4e00\u4e2aOpenBSD\u5e73\u53f0\u7684\u91cf\u5b50\u5b89\u5168VPN\u8ba4\u8bc1\u8bbe\u8ba1\uff0c\u4e0e\u73b0\u6709\u65b9\u6848\u76f8\u6bd4\uff0c\u9700\u8981\u66f4\u5c11\u7684\u5e26\u5bbd\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u540c\u65f6\u5177\u6709\u9ad8\u5ea6\u7075\u6d3b\u7684\u77e9\u4f4d\u8bc1\u4e66\u7ba1\u7406\u3002", "conclusion": "\u8be5\u65b9\u6848\u901a\u8fc7\u7ed3\u5408\u54c8\u5e0c\u57fa\u7b7e\u540d\u548c\u77ed\u671f\u7ecf\u5178\u52a0\u5bc6\u8bc1\u4e66\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u5b89\u5168\u7684\u91cf\u5b50\u5b89\u5168VPN\u8ba4\u8bc1\uff0c\u4e3a\u540e\u91cf\u5b50\u8fc1\u79fb\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.11973", "categories": ["cs.AI", "cs.MM", "cs.SD"], "pdf": "https://arxiv.org/pdf/2509.11973", "abs": "https://arxiv.org/abs/2509.11973", "authors": ["Markus J. Buehler"], "title": "MusicSwarm: Biologically Inspired Intelligence for Music Composition", "comment": null, "summary": "We show that coherent, long-form musical composition can emerge from a\ndecentralized swarm of identical, frozen foundation models that coordinate via\nstigmergic, peer-to-peer signals, without any weight updates. We compare a\ncentralized multi-agent system with a global critic to a fully decentralized\nswarm in which bar-wise agents sense and deposit harmonic, rhythmic, and\nstructural cues, adapt short-term memory, and reach consensus. Across symbolic,\naudio, and graph-theoretic analyses, the swarm yields superior quality while\ndelivering greater diversity and structural variety and leads across creativity\nmetrics. The dynamics contract toward a stable configuration of complementary\nroles, and self-similarity networks reveal a small-world architecture with\nefficient long-range connectivity and specialized bridging motifs, clarifying\nhow local novelties consolidate into global musical form. By shifting\nspecialization from parameter updates to interaction rules, shared memory, and\ndynamic consensus, MusicSwarm provides a compute- and data-efficient route to\nlong-horizon creative structure that is immediately transferable beyond music\nto collaborative writing, design, and scientific discovery.", "AI": {"tldr": "MusicSwarm\uff1a\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u3001\u65e0\u9700\u6743\u91cd\u66f4\u65b0\u7684\u7fa4\u4f53\u667a\u80fd\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c40\u90e8\u534f\u8c03\u5b9e\u73b0\u8fde\u8d2f\u7684\u957f\u7bc7\u97f3\u4e50\u521b\u4f5c\uff0c\u5728\u8d28\u91cf\u3001\u591a\u6837\u6027\u548c\u7ed3\u6784\u521b\u65b0\u65b9\u9762\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u7cfb\u7edf", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u7684\u7fa4\u4f53\u667a\u80fd\u5b9e\u73b0\u957f\u7bc7\u97f3\u4e50\u521b\u4f5c\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u548c\u53c2\u6570\u66f4\u65b0\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u8ba1\u7b97\u548c\u6570\u636e\u9ad8\u6548\u7684\u521b\u9020\u6027\u7ed3\u6784\u751f\u6210\u65b9\u6848", "method": "\u4f7f\u7528\u76f8\u540c\u7684\u51bb\u7ed3\u57fa\u7840\u6a21\u578b\u7ec4\u6210\u53bb\u4e2d\u5fc3\u5316\u7fa4\u4f53\uff0c\u901a\u8fc7\u4fe1\u606f\u7d20\u5f0f\u7684\u5bf9\u7b49\u4fe1\u53f7\u534f\u8c03\uff0c\u5305\u542b\u548c\u58f0\u3001\u8282\u594f\u548c\u7ed3\u6784\u7ebf\u7d22\u7684\u611f\u77e5\u4e0e\u6c89\u79ef\uff0c\u77ed\u671f\u8bb0\u5fc6\u9002\u5e94\u548c\u5171\u8bc6\u8fbe\u6210\u673a\u5236", "result": "\u7fa4\u4f53\u65b9\u6cd5\u5728\u7b26\u53f7\u3001\u97f3\u9891\u548c\u56fe\u8bba\u5206\u6790\u4e2d\u5747\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u8d28\u91cf\uff0c\u63d0\u4f9b\u66f4\u5927\u7684\u591a\u6837\u6027\u548c\u7ed3\u6784\u53d8\u5316\uff0c\u5728\u521b\u9020\u529b\u6307\u6807\u4e0a\u9886\u5148\uff0c\u5f62\u6210\u7a33\u5b9a\u7684\u4e92\u8865\u89d2\u8272\u914d\u7f6e\u548c\u5c0f\u4e16\u754c\u7f51\u7edc\u67b6\u6784", "conclusion": "MusicSwarm\u901a\u8fc7\u5c06\u4e13\u4e1a\u5316\u4ece\u53c2\u6570\u66f4\u65b0\u8f6c\u79fb\u5230\u4ea4\u4e92\u89c4\u5219\u3001\u5171\u4eab\u8bb0\u5fc6\u548c\u52a8\u6001\u5171\u8bc6\uff0c\u4e3a\u957f\u7bc7\u521b\u9020\u6027\u7ed3\u6784\u63d0\u4f9b\u4e86\u4e00\u6761\u9ad8\u6548\u8def\u5f84\uff0c\u53ef\u63a8\u5e7f\u5230\u534f\u4f5c\u5199\u4f5c\u3001\u8bbe\u8ba1\u548c\u79d1\u5b66\u53d1\u73b0\u7b49\u9886\u57df"}}
{"id": "2509.12034", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12034", "abs": "https://arxiv.org/abs/2509.12034", "authors": ["Emmanuel Adjei Domfeh", "Christopher L. Dancy"], "title": "Human-AI Use Patterns for Decision-Making in Disaster Scenarios: A Systematic Review", "comment": "10 pages, 2 figures", "summary": "In high-stakes disaster scenarios, timely and informed decision-making is\ncritical yet often challenged by uncertainty, dynamic environments, and limited\nresources. This paper presents a systematic review of Human-AI collaboration\npatterns that support decision-making across all disaster management phases.\nDrawing from 51 peer-reviewed studies, we identify four major categories:\nHuman-AI Decision Support Systems, Task and Resource Coordination, Trust and\nTransparency, and Simulation and Training. Within these, we analyze\nsub-patterns such as cognitive-augmented intelligence, multi-agent\ncoordination, explainable AI, and virtual training environments. Our review\nhighlights how AI systems may enhance situational awareness, improves response\nefficiency, and support complex decision-making, while also surfacing critical\nlimitations in scalability, interpretability, and system interoperability. We\nconclude by outlining key challenges and future research directions,\nemphasizing the need for adaptive, trustworthy, and context-aware Human-AI\nsystems to improve disaster resilience and equitable recovery outcomes.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u707e\u5bb3\u7ba1\u7406\u4e2d\u7684\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\uff0c\u8bc6\u522b\u51fa\u56db\u5927\u7c7b\u522b\uff1a\u4eba\u673a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3001\u4efb\u52a1\u8d44\u6e90\u534f\u8c03\u3001\u4fe1\u4efb\u900f\u660e\u5ea6\u3001\u6a21\u62df\u8bad\u7ec3\uff0c\u5206\u6790\u4e86AI\u5982\u4f55\u63d0\u5347\u707e\u5bb3\u54cd\u5e94\u6548\u7387\u4f46\u5b58\u5728\u53ef\u6269\u5c55\u6027\u7b49\u9650\u5236\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u707e\u5bb3\u573a\u666f\u4e2d\uff0c\u53ca\u65f6\u660e\u667a\u7684\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5e38\u53d7\u5230\u4e0d\u786e\u5b9a\u6027\u3001\u52a8\u6001\u73af\u5883\u548c\u6709\u9650\u8d44\u6e90\u7684\u6311\u6218\uff0c\u9700\u8981\u7814\u7a76\u4eba\u673a\u534f\u4f5c\u5982\u4f55\u652f\u6301\u707e\u5bb3\u7ba1\u7406\u5404\u9636\u6bb5\u7684\u51b3\u7b56\u3002", "method": "\u57fa\u4e8e51\u7bc7\u540c\u884c\u8bc4\u5ba1\u7814\u7a76\u7684\u7cfb\u7edf\u7efc\u8ff0\uff0c\u8bc6\u522b\u548c\u5206\u6790\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\uff0c\u5305\u62ec\u56db\u5927\u7c7b\u522b\u53ca\u5176\u5b50\u6a21\u5f0f\u5982\u8ba4\u77e5\u589e\u5f3a\u667a\u80fd\u3001\u591a\u667a\u80fd\u4f53\u534f\u8c03\u7b49\u3002", "result": "\u8bc6\u522b\u51fa\u56db\u5927\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\u7c7b\u522b\uff0c\u53d1\u73b0AI\u7cfb\u7edf\u80fd\u589e\u5f3a\u6001\u52bf\u611f\u77e5\u3001\u63d0\u9ad8\u54cd\u5e94\u6548\u7387\u3001\u652f\u6301\u590d\u6742\u51b3\u7b56\uff0c\u4f46\u4e5f\u5b58\u5728\u53ef\u6269\u5c55\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u7cfb\u7edf\u4e92\u64cd\u4f5c\u6027\u7b49\u5173\u952e\u9650\u5236\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u81ea\u9002\u5e94\u3001\u53ef\u4fe1\u8d56\u548c\u60c5\u5883\u611f\u77e5\u7684\u4eba\u673a\u7cfb\u7edf\u6765\u63d0\u5347\u707e\u5bb3\u97e7\u6027\uff0c\u786e\u4fdd\u516c\u5e73\u7684\u6062\u590d\u7ed3\u679c\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u5173\u952e\u6311\u6218\u548c\u65b9\u5411\u3002"}}
{"id": "2509.11745", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11745", "abs": "https://arxiv.org/abs/2509.11745", "authors": ["De Zhang Lee", "Han Fang", "Hanyi Wang", "Ee-Chien Chang"], "title": "Removal Attack and Defense on AI-generated Content Latent-based Watermarking", "comment": null, "summary": "Digital watermarks can be embedded into AI-generated content (AIGC) by\ninitializing the generation process with starting points sampled from a secret\ndistribution. When combined with pseudorandom error-correcting codes, such\nwatermarked outputs can remain indistinguishable from unwatermarked objects,\nwhile maintaining robustness under whitenoise. In this paper, we go beyond\nindistinguishability and investigate security under removal attacks. We\ndemonstrate that indistinguishability alone does not necessarily guarantee\nresistance to adversarial removal. Specifically, we propose a novel attack that\nexploits boundary information leaked by the locations of watermarked objects.\nThis attack significantly reduces the distortion required to remove watermarks\n-- by up to a factor of $15 \\times$ compared to a baseline whitenoise attack\nunder certain settings. To mitigate such attacks, we introduce a defense\nmechanism that applies a secret transformation to hide the boundary, and prove\nthat the secret transformation effectively rendering any attacker's\nperturbations equivalent to those of a naive whitenoise adversary. Our\nempirical evaluations, conducted on multiple versions of Stable Diffusion,\nvalidate the effectiveness of both the attack and the proposed defense,\nhighlighting the importance of addressing boundary leakage in latent-based\nwatermarking schemes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76AI\u751f\u6210\u5185\u5bb9\u6c34\u5370\u7684\u5b89\u5168\u6027\u95ee\u9898\uff0c\u53d1\u73b0\u4ec5\u51ed\u4e0d\u53ef\u533a\u5206\u6027\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u6297\u79fb\u9664\u653b\u51fb\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6c34\u5370\u8fb9\u754c\u4fe1\u606f\u7684\u65b0\u578b\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u9632\u5fa1\u673a\u5236\u3002", "motivation": "\u7814\u7a76\u6570\u5b57\u6c34\u5370\u5728AI\u751f\u6210\u5185\u5bb9\u4e2d\u7684\u5b89\u5168\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u9488\u5bf9\u79fb\u9664\u653b\u51fb\u7684\u62b5\u6297\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u57fa\u4e8e\u4e0d\u53ef\u533a\u5206\u6027\u7684\u6c34\u5370\u65b9\u6848\u5b58\u5728\u8fb9\u754c\u4fe1\u606f\u6cc4\u9732\u7684\u5b89\u5168\u9690\u60a3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u6c34\u5370\u5bf9\u8c61\u7684\u8fb9\u754c\u4f4d\u7f6e\u4fe1\u606f\u6765\u663e\u8457\u964d\u4f4e\u79fb\u9664\u6c34\u5370\u6240\u9700\u7684\u5931\u771f\uff1b\u540c\u65f6\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9632\u5fa1\u673a\u5236\uff0c\u901a\u8fc7\u79d8\u5bc6\u53d8\u6362\u6765\u9690\u85cf\u8fb9\u754c\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u65b0\u578b\u653b\u51fb\u6bd4\u57fa\u51c6\u767d\u566a\u58f0\u653b\u51fb\u5728\u7279\u5b9a\u8bbe\u7f6e\u4e0b\u53ef\u5c06\u79fb\u9664\u6c34\u5370\u6240\u9700\u7684\u5931\u771f\u964d\u4f4e\u9ad8\u8fbe15\u500d\uff1b\u9632\u5fa1\u673a\u5236\u80fd\u6709\u6548\u5c06\u653b\u51fb\u8005\u7684\u6270\u52a8\u7b49\u540c\u4e8e\u6734\u7d20\u767d\u566a\u58f0\u653b\u51fb\u8005\u7684\u6270\u52a8\u3002", "conclusion": "\u8fb9\u754c\u4fe1\u606f\u6cc4\u9732\u662f\u57fa\u4e8e\u6f5c\u5728\u7a7a\u95f4\u7684\u6c34\u5370\u65b9\u6848\u4e2d\u7684\u91cd\u8981\u5b89\u5168\u95ee\u9898\uff0c\u9700\u8981\u4e13\u95e8\u7684\u9632\u5fa1\u673a\u5236\u6765\u786e\u4fdd\u6c34\u5370\u7684\u5b89\u5168\u6027\uff0c\u4ec5\u9760\u4e0d\u53ef\u533a\u5206\u6027\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u6297\u79fb\u9664\u653b\u51fb\u80fd\u529b\u3002"}}
{"id": "2509.12060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12060", "abs": "https://arxiv.org/abs/2509.12060", "authors": ["Wei Cai", "Shujuan Liu", "Jian Zhao", "Ziyan Shi", "Yusheng Zhao", "Yuchen Yuan", "Tianle Zhang", "Chi Zhang", "Xuelong Li"], "title": "When Safe Unimodal Inputs Collide: Optimizing Reasoning Chains for Cross-Modal Safety in Multimodal Large Language Models", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are susceptible to the implicit\nreasoning risk, wherein innocuous unimodal inputs synergistically assemble into\nrisky multimodal data that produce harmful outputs. We attribute this\nvulnerability to the difficulty of MLLMs maintaining safety alignment through\nlong-chain reasoning. To address this issue, we introduce\nSafe-Semantics-but-Unsafe-Interpretation (SSUI), the first dataset featuring\ninterpretable reasoning paths tailored for such a cross-modal challenge. A\nnovel training framework, Safety-aware Reasoning Path Optimization (SRPO), is\nalso designed based on the SSUI dataset to align the MLLM's internal reasoning\nprocess with human safety values. Experimental results show that our\nSRPO-trained models achieve state-of-the-art results on key safety benchmarks,\nincluding the proposed Reasoning Path Benchmark (RSBench), significantly\noutperforming both open-source and top-tier commercial MLLMs.", "AI": {"tldr": "MLLMs\u5b58\u5728\u9690\u5f0f\u63a8\u7406\u98ce\u9669\uff0c\u65e0\u5bb3\u7684\u5355\u6a21\u6001\u8f93\u5165\u7ec4\u5408\u6210\u5371\u9669\u7684\u591a\u6a21\u6001\u6570\u636e\u4f1a\u4ea7\u751f\u6709\u5bb3\u8f93\u51fa\u3002\u7814\u7a76\u63d0\u51faSSUI\u6570\u636e\u96c6\u548cSRPO\u8bad\u7ec3\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5728\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u94fe\u63a8\u7406\u4e2d\u96be\u4ee5\u4fdd\u6301\u5b89\u5168\u5bf9\u9f50\uff0c\u5bfc\u81f4\u65e0\u5bb3\u7684\u5355\u6a21\u6001\u8f93\u5165\u7ec4\u5408\u6210\u5371\u9669\u7684\u591a\u6a21\u6001\u5185\u5bb9\u4ea7\u751f\u6709\u5bb3\u8f93\u51fa\u3002", "method": "\u63d0\u51faSSUI\u6570\u636e\u96c6\uff08\u5305\u542b\u53ef\u89e3\u91ca\u63a8\u7406\u8def\u5f84\uff09\u548cSRPO\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u63a8\u7406\u8def\u5f84\u4f7fMLLM\u7684\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u4e0e\u4eba\u7c7b\u5b89\u5168\u4ef7\u503c\u89c2\u5bf9\u9f50\u3002", "result": "SRPO\u8bad\u7ec3\u6a21\u578b\u5728\u5173\u952e\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u65b0\u63d0\u51fa\u7684RSBench\uff09\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u663e\u8457\u4f18\u4e8e\u5f00\u6e90\u548c\u9876\u7ea7\u5546\u4e1aMLLMs\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86MLLMs\u7684\u9690\u5f0f\u63a8\u7406\u98ce\u9669\u95ee\u9898\uff0c\u901a\u8fc7\u63a8\u7406\u8def\u5f84\u4f18\u5316\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5b89\u5168\u5bf9\u9f50\u3002"}}
{"id": "2509.11761", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.11761", "abs": "https://arxiv.org/abs/2509.11761", "authors": ["Manish Bansal", "Pramsu Shrivastava", "J. Harshan"], "title": "On Spatial-Provenance Recovery in Wireless Networks with Relaxed-Privacy Constraints", "comment": "Accepted for publication in IEEE Transactions on Dependable and\n  Secure Computing, September 2025", "summary": "In Vehicle-to-Everything (V2X) networks with multi-hop communication, Road\nSide Units (RSUs) intend to gather location data from the vehicles to offer\nvarious location-based services. Although vehicles use the Global Positioning\nSystem (GPS) for navigation, they may refrain from sharing their exact GPS\ncoordinates to the RSUs due to privacy considerations. Thus, to address the\nlocalization expectations of the RSUs and the privacy concerns of the vehicles,\nwe introduce a relaxed-privacy model wherein the vehicles share their partial\nlocation information in order to avail the location-based services. To\nimplement this notion of relaxed-privacy, we propose a low-latency protocol for\nspatial-provenance recovery, wherein vehicles use correlated linear Bloom\nfilters to embed their position information. Our proposed spatial-provenance\nrecovery process takes into account the resolution of localization, the\nunderlying ad hoc protocol, and the coverage range of the wireless technology\nused by the vehicles. Through a rigorous theoretical analysis, we present\nextensive analysis on the underlying trade-off between relaxed-privacy and the\ncommunication-overhead of the protocol. Finally, using a wireless testbed, we\nshow that our proposed method requires a few bits in the packet header to\nprovide security features such as localizing a low-power jammer executing a\ndenial-of-service attack.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cdV2X\u7f51\u7edc\u4e2d\u57fa\u4e8e\u76f8\u5173\u7ebf\u6027Bloom\u6ee4\u6ce2\u5668\u7684\u7a7a\u95f4\u6eaf\u6e90\u6062\u590d\u534f\u8bae\uff0c\u5728\u4fdd\u62a4\u8f66\u8f86\u4f4d\u7f6e\u9690\u79c1\u7684\u540c\u65f6\u6ee1\u8db3RSU\u7684\u5b9a\u4f4d\u9700\u6c42", "motivation": "\u89e3\u51b3V2X\u7f51\u7edc\u4e2d\u8f66\u8f86\u4e0d\u613f\u5206\u4eab\u7cbe\u786eGPS\u5750\u6807\u7684\u9690\u79c1\u987e\u8651\u4e0eRSU\u9700\u8981\u4f4d\u7f6e\u6570\u636e\u63d0\u4f9b\u670d\u52a1\u7684\u77db\u76fe", "method": "\u4f7f\u7528\u76f8\u5173\u7ebf\u6027Bloom\u6ee4\u6ce2\u5668\u5d4c\u5165\u4f4d\u7f6e\u4fe1\u606f\uff0c\u8003\u8651\u5b9a\u4f4d\u5206\u8fa8\u7387\u3001ad hoc\u534f\u8bae\u548c\u65e0\u7ebf\u6280\u672f\u8986\u76d6\u8303\u56f4", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\u5728\u653e\u677e\u9690\u79c1\u548c\u901a\u4fe1\u5f00\u9500\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u5b9e\u9a8c\u8bc1\u660e\u53ea\u9700\u5c11\u91cf\u5305\u5934\u6bd4\u7279\u5373\u53ef\u63d0\u4f9b\u5b89\u5168\u529f\u80fd\u5982\u5b9a\u4f4d\u4f4e\u529f\u7387\u5e72\u6270\u6e90", "conclusion": "\u63d0\u51fa\u7684\u653e\u677e\u9690\u79c1\u6a21\u578b\u548c\u7a7a\u95f4\u6eaf\u6e90\u6062\u590d\u534f\u8bae\u80fd\u6709\u6548\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u548c\u670d\u52a1\u9700\u6c42\uff0c\u5177\u6709\u4f4e\u5ef6\u8fdf\u548c\u4f4e\u901a\u4fe1\u5f00\u9500\u7684\u4f18\u52bf"}}
{"id": "2509.12091", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12091", "abs": "https://arxiv.org/abs/2509.12091", "authors": ["Hamied Nabizada", "Lasse Beers", "Alain Chahine", "Felix Gehlhoff", "Oliver Niggemann", "Alexander Fay"], "title": "Bridging Engineering and AI Planning through Model-Based Knowledge Transformation for the Validation of Automated Production System Variants", "comment": "Presented at the KEPS-Workshop, ICAPS 2025", "summary": "Engineering models created in Model-Based Systems Engineering (MBSE)\nenvironments contain detailed information about system structure and behavior.\nHowever, they typically lack symbolic planning semantics such as preconditions,\neffects, and constraints related to resource availability and timing. This\nlimits their ability to evaluate whether a given system variant can fulfill\nspecific tasks and how efficiently it performs compared to alternatives.\n  To address this gap, this paper presents a model-driven method that enables\nthe specification and automated generation of symbolic planning artifacts\nwithin SysML-based engineering models. A dedicated SysML profile introduces\nreusable stereotypes for core planning constructs. These are integrated into\nexisting model structures and processed by an algorithm that generates a valid\ndomain file and a corresponding problem file in Planning Domain Definition\nLanguage (PDDL). In contrast to previous approaches that rely on manual\ntransformations or external capability models, the method supports native\nintegration and maintains consistency between engineering and planning\nartifacts.\n  The applicability of the method is demonstrated through a case study from\naircraft assembly. The example illustrates how existing engineering models are\nenriched with planning semantics and how the proposed workflow is applied to\ngenerate consistent planning artifacts from these models. The generated\nplanning artifacts enable the validation of system variants through AI\nplanning.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u9a71\u52a8\u65b9\u6cd5\uff0c\u80fd\u591f\u5728SysML\u5de5\u7a0b\u6a21\u578b\u4e2d\u6307\u5b9a\u548c\u81ea\u52a8\u751f\u6210\u7b26\u53f7\u89c4\u5212\u4ef6\uff0c\u4ee5\u652f\u6301\u7cfb\u7edf\u53d8\u4f53\u7684\u9a8c\u8bc1\u548c\u6548\u7387\u8bc4\u4f30\u3002", "motivation": "\u89e3\u51b3MBSE\u6a21\u578b\u7f3a\u4e4f\u7b26\u53f7\u89c4\u5212\u8bed\u4e49\uff08\u5982\u524d\u63d0\u6761\u4ef6\u3001\u6548\u679c\u3001\u7ea6\u675f\uff09\u7684\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u7cfb\u7edf\u53d8\u4f53\u80fd\u5426\u5b8c\u6210\u7279\u5b9a\u4efb\u52a1\u7684\u8bc4\u4f30\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e13\u7528\u7684SysML\u914d\u7f6e\u6587\u4ef6\uff0c\u5f15\u5165\u53ef\u91cd\u7528\u7684\u6a21\u677f\u7528\u4e8e\u6838\u5fc3\u89c4\u5212\u6784\u5efa\uff0c\u901a\u8fc7\u7b97\u6cd5\u5904\u7406\u751f\u6210PDDL\u683c\u5f0f\u7684\u6709\u6548\u57df\u6587\u4ef6\u548c\u95ee\u9898\u6587\u4ef6\u3002", "result": "\u901a\u8fc7\u822a\u7a7a\u7ec4\u88c5\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u7528\u6027\uff0c\u80fd\u591f\u5728\u73b0\u6709\u5de5\u7a0b\u6a21\u578b\u4e2d\u6dfb\u52a0\u89c4\u5212\u8bed\u4e49\uff0c\u751f\u6210\u4e00\u81f4\u7684\u89c4\u5212\u4ef6\uff0c\u652f\u6301AI\u89c4\u5212\u8fdb\u884c\u7cfb\u7edf\u53d8\u4f53\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5de5\u7a0b\u6a21\u578b\u4e0e\u89c4\u5212\u4ef6\u7684\u672c\u5730\u96c6\u6210\u548c\u4e00\u81f4\u6027\u7ef4\u62a4\uff0c\u5145\u5206\u5229\u7528\u4e86\u73b0\u6709\u6a21\u578b\u4fe1\u606f\uff0c\u4e3a\u7cfb\u7edf\u53d8\u4f53\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u652f\u6301\u3002"}}
{"id": "2509.11786", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11786", "abs": "https://arxiv.org/abs/2509.11786", "authors": ["Dongyang Zhan", "Wenqi Zhang", "Lin Ye", "Xiangzhan Yu", "Hongli Zhang", "Zheng He"], "title": "Anomaly Detection in Industrial Control Systems Based on Cross-Domain Representation Learning", "comment": null, "summary": "Industrial control systems (ICSs) are widely used in industry, and their\nsecurity and stability are very important. Once the ICS is attacked, it may\ncause serious damage. Therefore, it is very important to detect anomalies in\nICSs. ICS can monitor and manage physical devices remotely using communication\nnetworks. The existing anomaly detection approaches mainly focus on analyzing\nthe security of network traffic or sensor data. However, the behaviors of\ndifferent domains (e.g., network traffic and sensor physical status) of ICSs\nare correlated, so it is difficult to comprehensively identify anomalies by\nanalyzing only a single domain. In this paper, an anomaly detection approach\nbased on cross-domain representation learning in ICSs is proposed, which can\nlearn the joint features of multi-domain behaviors and detect anomalies within\ndifferent domains. After constructing a cross-domain graph that can represent\nthe behaviors of multiple domains in ICSs, our approach can learn the joint\nfeatures of them by leveraging graph neural networks. Since anomalies behave\ndifferently in different domains, we leverage a multi-task learning approach to\nidentify anomalies in different domains separately and perform joint training.\nThe experimental results show that the performance of our approach is better\nthan existing approaches for identifying anomalies in ICSs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8de8\u57df\u8868\u793a\u5b66\u4e60\u7684\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u591a\u57df\u884c\u4e3a\u7684\u8054\u5408\u7279\u5f81\uff0c\u4f7f\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u5206\u522b\u8bc6\u522b\u4e0d\u540c\u57df\u7684\u5f02\u5e38", "motivation": "\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5206\u6790\u5355\u4e00\u57df\uff08\u7f51\u7edc\u6d41\u91cf\u6216\u4f20\u611f\u5668\u6570\u636e\uff09\uff0c\u4f46\u4e0d\u540c\u57df\u884c\u4e3a\u76f8\u5173\uff0c\u4ec5\u5206\u6790\u5355\u4e00\u57df\u96be\u4ee5\u5168\u9762\u8bc6\u522b\u5f02\u5e38", "method": "\u6784\u5efa\u8de8\u57df\u56fe\u8868\u793aICS\u591a\u57df\u884c\u4e3a\uff0c\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u8054\u5408\u7279\u5f81\uff0c\u91c7\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\u5206\u522b\u8bc6\u522b\u4e0d\u540c\u57df\u7684\u5f02\u5e38\u5e76\u8fdb\u884c\u8054\u5408\u8bad\u7ec3", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u8bc6\u522bICS\u5f02\u5e38\u65b9\u9762\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "\u8de8\u57df\u8868\u793a\u5b66\u4e60\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u80fd\u6709\u6548\u63d0\u5347\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u7684\u5168\u9762\u6027\u548c\u51c6\u786e\u6027"}}
{"id": "2509.12104", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12104", "abs": "https://arxiv.org/abs/2509.12104", "authors": ["Zongyue Xue", "Siyuan Zheng", "Shaochun Wang", "Yiran Hu", "Shenran Wang", "Yuxin Yao", "Haitao Li", "Qingyao Ai", "Yiqun Liu", "Yun Liu", "Weixing Shen"], "title": "JustEva: A Toolkit to Evaluate LLM Fairness in Legal Knowledge Inference", "comment": "This paper has been accepted at CIKM 2025 (Demo Track)", "summary": "The integration of Large Language Models (LLMs) into legal practice raises\npressing concerns about judicial fairness, particularly due to the nature of\ntheir \"black-box\" processes. This study introduces JustEva, a comprehensive,\nopen-source evaluation toolkit designed to measure LLM fairness in legal tasks.\nJustEva features several advantages: (1) a structured label system covering 65\nextra-legal factors; (2) three core fairness metrics - inconsistency, bias, and\nimbalanced inaccuracy; (3) robust statistical inference methods; and (4)\ninformative visualizations. The toolkit supports two types of experiments,\nenabling a complete evaluation workflow: (1) generating structured outputs from\nLLMs using a provided dataset, and (2) conducting statistical analysis and\ninference on LLMs' outputs through regression and other statistical methods.\nEmpirical application of JustEva reveals significant fairness deficiencies in\ncurrent LLMs, highlighting the lack of fair and trustworthy LLM legal tools.\nJustEva offers a convenient tool and methodological foundation for evaluating\nand improving algorithmic fairness in the legal domain.", "AI": {"tldr": "JustEva\u662f\u4e00\u4e2a\u5f00\u6e90\u8bc4\u4f30\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u6d4b\u91cf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u4efb\u52a1\u4e2d\u7684\u516c\u5e73\u6027\uff0c\u5305\u542b65\u4e2a\u6cd5\u5916\u56e0\u7d20\u6807\u7b7e\u7cfb\u7edf\u3001\u4e09\u4e2a\u6838\u5fc3\u516c\u5e73\u6027\u6307\u6807\u3001\u7edf\u8ba1\u63a8\u65ad\u65b9\u6cd5\u548c\u53ef\u89c6\u5316\u529f\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u7684\u96c6\u6210\u5f15\u53d1\u4e86\u5173\u4e8e\u53f8\u6cd5\u516c\u5e73\u6027\u7684\u62c5\u5fe7\uff0c\u7279\u522b\u662f\u7531\u4e8e\u5176\"\u9ed1\u76d2\"\u7279\u6027\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5de5\u5177\u6765\u786e\u4fdd\u516c\u5e73\u6027\u3002", "method": "\u5f00\u53d1\u4e86JustEva\u5de5\u5177\u5305\uff0c\u5305\u542b\u7ed3\u6784\u5316\u6807\u7b7e\u7cfb\u7edf\u3001\u4e09\u4e2a\u516c\u5e73\u6027\u6307\u6807\uff08\u4e0d\u4e00\u81f4\u6027\u3001\u504f\u89c1\u548c\u4e0d\u5e73\u8861\u4e0d\u51c6\u786e\u6027\uff09\u3001\u7edf\u8ba1\u63a8\u65ad\u65b9\u6cd5\u548c\u53ef\u89c6\u5316\u529f\u80fd\uff0c\u652f\u6301\u751f\u6210\u7ed3\u6784\u5316\u8f93\u51fa\u548c\u7edf\u8ba1\u5206\u6790\u4e24\u79cd\u5b9e\u9a8c\u7c7b\u578b\u3002", "result": "\u5b9e\u8bc1\u5e94\u7528\u663e\u793a\u5f53\u524dLLMs\u5b58\u5728\u663e\u8457\u7684\u516c\u5e73\u6027\u7f3a\u9677\uff0c\u7f3a\u4e4f\u516c\u5e73\u53ef\u4fe1\u7684\u6cd5\u5f8b\u5de5\u5177\u3002", "conclusion": "JustEva\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u6cd5\u5f8b\u9886\u57df\u7b97\u6cd5\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u4fbf\u5229\u5de5\u5177\u548c\u65b9\u6cd5\u8bba\u57fa\u7840\u3002"}}
{"id": "2509.11833", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11833", "abs": "https://arxiv.org/abs/2509.11833", "authors": ["Xuewei Feng", "Zhaoxi Li", "Qi Li", "Ziqiang Wang", "Kun Sun", "Ke Xu"], "title": "Off-Path TCP Exploits: PMTUD Breaks TCP Connection Isolation in IP Address Sharing Scenarios", "comment": null, "summary": "Path MTU Discovery (PMTUD) and IP address sharing are integral aspects of\nmodern Internet infrastructure. In this paper, we investigate the security\nvulnerabilities associated with PMTUD within the context of prevalent IP\naddress sharing practices. We reveal that PMTUD is inadequately designed to\nhandle IP address sharing, creating vulnerabilities that attackers can exploit\nto perform off-path TCP hijacking attacks. We demonstrate that by observing the\npath MTU value determined by a server for a public IP address (shared among\nmultiple devices), an off-path attacker on the Internet, in collaboration with\na malicious device, can infer the sequence numbers of TCP connections\nestablished by other legitimate devices sharing the same IP address. This\nvulnerability enables the attacker to perform off-path TCP hijacking attacks,\nsignificantly compromising the security of the affected TCP connections. Our\nattack involves first identifying a target TCP connection originating from the\nshared IP address, followed by inferring the sequence numbers of the identified\nconnection. We thoroughly assess the impacts of our attack under various\nnetwork configurations. Experimental results reveal that the attack can be\nexecuted within an average time of 220 seconds, achieving a success rate of\n70%.Case studies, including SSH DoS, FTP traffic poisoning, and HTTP injection,\nhighlight the threat it poses to various applications. Additionally, we\nevaluate our attack across 50 real-world networks with IP address\nsharing--including public Wi-Fi, VPNs, and 5G--and find 38 vulnerable. Finally,\nwe responsibly disclose the vulnerabilities, receive recognition from\norganizations such as IETF, Linux, and Cisco, and propose our countermeasures.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u8def\u5f84MTU\u53d1\u73b0(PMTUD)\u5728IP\u5730\u5740\u5171\u4eab\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u5229\u7528\u6b64\u6f0f\u6d1e\u8fdb\u884c\u79bb\u7ebfTCP\u62fc\u63a7\u653b\u51fb\uff0c\u6210\u529f\u7387\u8fbe70%\uff0c\u5e73\u5747\u65f6\u95f4220\u79d2\u3002", "motivation": "\u7814\u7a76PMTUD\u5728\u666e\u904dIP\u5730\u5740\u5171\u4eab\u5b9e\u8df5\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u56e0\u4e3a\u5f53\u524dPMTUD\u8bbe\u8ba1\u65e0\u6cd5\u6709\u6548\u5904\u7406IP\u5730\u5740\u5171\u4eab\u60c5\u51b5\uff0c\u9020\u6210\u53ef\u88ad\u7565\u7684\u5b89\u5168\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u89c2\u5bdf\u670d\u52a1\u5668\u4e3a\u516c\u5171IP\u5730\u5740\u786e\u5b9a\u7684\u8def\u5f84MTU\u503c\uff0c\u79bb\u7ebf\u653b\u51fb\u8005\u4e0e\u6076\u610f\u8bbe\u5907\u5408\u4f5c\u53ef\u4ee5\u63a8\u65ad\u5176\u4ed6\u5408\u6cd5\u8bbe\u5907\u7684TCP\u8fde\u63a5\u5e8f\u5217\u53f7\uff0c\u8fdb\u800c\u6267\u884cTCP\u62fc\u63a7\u653b\u51fb\u3002\u65b9\u6cd5\u5305\u62ec\u8bc6\u522b\u76ee\u6807TCP\u8fde\u63a5\u548c\u63a8\u65ad\u5e8f\u5217\u53f7\u3002", "result": "\u5728\u5404\u79cd\u7f51\u7edc\u914d\u7f6e\u4e0b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u653b\u51fb\u5e73\u5747\u8017\u65f6220\u79d2\uff0c\u6210\u529f\u7387\u8fbe70%\u3002\u572850\u4e2a\u771f\u5b9e\u7f51\u7edc\u4e2d\u53d1\u73b038\u4e2a\u5b58\u5728\u6f0f\u6d1e\u3002\u901a\u8fc7SSH DoS\u3001FTP\u6d41\u91cf\u6bd2\u5316\u548cHTTP\u6ce8\u5165\u6848\u4f8b\u8bc1\u660e\u4e86\u5176\u5a01\u80c1\u3002", "conclusion": "PMTUD\u5728IP\u5730\u5740\u5171\u4eab\u73af\u5883\u4e2d\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u53ef\u5bfc\u81f4\u79bb\u7ebfTCP\u62fc\u63a7\u653b\u51fb\u3002\u5df2\u5411IETF\u3001Linux\u548cCisco\u7b49\u673a\u6784\u8d1f\u8d23\u4efb\u66f4\u65b0\uff0c\u5e76\u63d0\u51fa\u4e86\u5bf9\u7b56\u63aa\u65bd\u3002"}}
{"id": "2509.12179", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.12179", "abs": "https://arxiv.org/abs/2509.12179", "authors": ["Yubo Li", "Weiyi Song"], "title": "Co-Alignment: Rethinking Alignment as Bidirectional Human-AI Cognitive Adaptation", "comment": null, "summary": "Current AI alignment through RLHF follows a single directional paradigm that\nAI conforms to human preferences while treating human cognition as fixed. We\npropose a shift to co-alignment through Bidirectional Cognitive Alignment\n(BiCA), where humans and AI mutually adapt. BiCA uses learnable protocols,\nrepresentation mapping, and KL-budget constraints for controlled co-evolution.\nIn collaborative navigation, BiCA achieved 85.5% success versus 70.3% baseline,\nwith 230% better mutual adaptation and 332% better protocol convergence.\nEmergent protocols outperformed handcrafted ones by 84%, while bidirectional\nadaptation unexpectedly improved safety (+23% out-of-distribution robustness).\nThe 46% synergy improvement demonstrates optimal collaboration exists at the\nintersection, not union, of human and AI capabilities, validating the shift\nfrom single-directional to co-alignment paradigms.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u5411\u8ba4\u77e5\u5bf9\u9f50(BiCA)\u6846\u67b6\uff0c\u5b9e\u73b0\u4eba\u7c7b\u4e0eAI\u7684\u76f8\u4e92\u9002\u5e94\uff0c\u5728\u534f\u4f5c\u5bfc\u822a\u4efb\u52a1\u4e2d\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u548c\u5b89\u5168\u6539\u5584", "motivation": "\u5f53\u524dRLHF\u5bf9\u9f50\u65b9\u6cd5\u53ea\u662f\u5355\u5411\u7684AI\u9002\u5e94\u4eba\u7c7b\u504f\u597d\uff0c\u5c06\u4eba\u7c7b\u8ba4\u77e5\u89c6\u4e3a\u56fa\u5b9a\u4e0d\u53d8\uff0c\u9700\u8981\u8f6c\u5411\u53cc\u5411\u5171\u540c\u5bf9\u9f50\u8303\u5f0f", "method": "\u4f7f\u7528\u53ef\u5b66\u4e60\u534f\u8bae\u3001\u8868\u5f81\u6620\u5c04\u548cKL\u9884\u7b97\u7ea6\u675f\u6765\u5b9e\u73b0\u53d7\u63a7\u7684\u5171\u540c\u8fdb\u5316\uff0c\u5305\u62ec\u53cc\u5411\u9002\u5e94\u673a\u5236", "result": "\u5728\u534f\u4f5c\u5bfc\u822a\u4e2d\u8fbe\u523085.5%\u6210\u529f\u7387(\u6bd4\u57fa\u7ebf70.3%\u63d0\u5347)\uff0c\u4e92\u9002\u5e94\u80fd\u529b\u63d0\u5347230%\uff0c\u534f\u8bae\u6536\u655b\u6027\u63d0\u5347332%\uff0c\u6d8c\u73b0\u534f\u8bae\u6bd4\u624b\u5de5\u534f\u8bae\u4f1884%\uff0c\u5b89\u5168\u6027\u63d0\u534723%", "conclusion": "\u6700\u4f18\u534f\u4f5c\u5b58\u5728\u4e8e\u4eba\u7c7b\u548cAI\u80fd\u529b\u7684\u4ea4\u96c6\u800c\u975e\u5e76\u96c6\uff0c\u9a8c\u8bc1\u4e86\u4ece\u5355\u5411\u5bf9\u9f50\u5411\u5171\u540c\u5bf9\u9f50\u8303\u5f0f\u8f6c\u53d8\u7684\u5fc5\u8981\u6027"}}
{"id": "2509.12194", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.12194", "abs": "https://arxiv.org/abs/2509.12194", "authors": ["Thomas A. Buckley", "Riccardo Conci", "Peter G. Brodeur", "Jason Gusdorf", "Sourik Beltr\u00e1n", "Bita Behrouzi", "Byron Crowe", "Jacob Dockterman", "Muzzammil Muhammad", "Sarah Ohnigian", "Andrew Sanchez", "James A. Diao", "Aashna P. Shah", "Daniel Restrepo", "Eric S. Rosenberg", "Andrew S. Lea", "Marinka Zitnik", "Scott H. Podolsky", "Zahir Kanjee", "Raja-Elie E. Abdulnour", "Jacob M. Koshy", "Adam Rodman", "Arjun K. Manrai"], "title": "Advancing Medical Artificial Intelligence Using a Century of Cases", "comment": null, "summary": "BACKGROUND: For over a century, the New England Journal of Medicine\nClinicopathological Conferences (CPCs) have tested the reasoning of expert\nphysicians and, recently, artificial intelligence (AI). However, prior AI\nevaluations have focused on final diagnoses without addressing the multifaceted\nreasoning and presentation skills required of expert discussants.\n  METHODS: Using 7102 CPCs (1923-2025) and 1021 Image Challenges (2006-2025),\nwe conducted extensive physician annotation and automated processing to create\nCPC-Bench, a physician-validated benchmark spanning 10 text-based and\nmultimodal tasks, against which we evaluated leading large language models\n(LLMs). Then, we developed \"Dr. CaBot,\" an AI discussant designed to produce\nwritten and slide-based video presentations using only the case presentation,\nmodeling the role of the human expert in these cases.\n  RESULTS: When challenged with 377 contemporary CPCs, o3 (OpenAI) ranked the\nfinal diagnosis first in 60% of cases and within the top ten in 84% of cases,\noutperforming a 20-physician baseline; next-test selection accuracy reached\n98%. Event-level physician annotations quantified AI diagnostic accuracy per\nunit of information. Performance was lower on literature search and image\ntasks; o3 and Gemini 2.5 Pro (Google) achieved 67% accuracy on image\nchallenges. In blinded comparisons of CaBot vs. human expert-generated text,\nphysicians misclassified the source of the differential in 46 of 62 (74%) of\ntrials, and scored CaBot more favorably across quality dimensions. To promote\nresearch, we are releasing CaBot and CPC-Bench.\n  CONCLUSIONS: LLMs exceed physician performance on complex text-based\ndifferential diagnosis and convincingly emulate expert medical presentations,\nbut image interpretation and literature retrieval remain weaker. CPC-Bench and\nCaBot may enable transparent and continued tracking of progress in medical AI.", "AI": {"tldr": "LLMs\u5728\u590d\u6742\u6587\u672c\u9274\u522b\u8bca\u65ad\u65b9\u9762\u8d85\u8d8a\u533b\u751f\u8868\u73b0\uff0c\u80fd\u591f\u6709\u6548\u6a21\u62df\u4e13\u5bb6\u533b\u5b66\u6f14\u793a\uff0c\u4f46\u5728\u56fe\u50cf\u89e3\u91ca\u548c\u6587\u732e\u68c0\u7d22\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002", "motivation": "\u8bc4\u4f30AI\u5728\u533b\u5b66\u8bca\u65ad\u63a8\u7406\u548c\u6f14\u793a\u65b9\u9762\u7684\u7efc\u5408\u80fd\u529b\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u6700\u7ec8\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u586b\u8865\u73b0\u6709AI\u8bc4\u4f30\u7684\u7a7a\u767d\u3002", "method": "\u4f7f\u75287102\u4e2aCPC\u6848\u4f8b\u548c1021\u4e2a\u56fe\u50cf\u6311\u6218\u521b\u5efaCPC-Bench\u57fa\u51c6\uff0c\u8bc4\u4f30\u9886\u5148LLMs\uff0c\u5e76\u5f00\u53d1Dr. CaBot AI\u8ba8\u8bba\u7cfb\u7edf\u6765\u751f\u6210\u4e66\u9762\u548c\u5e7b\u706f\u7247\u6f14\u793a\u3002", "result": "o3\u6a21\u578b\u572860%\u6848\u4f8b\u4e2d\u6392\u540d\u7b2c\u4e00\u8bca\u65ad\uff0c84%\u8fdb\u5165\u524d\u5341\uff1b\u56fe\u50cf\u4efb\u52a1\u51c6\u786e\u738767%\uff1b\u5728\u76f2\u6d4b\u4e2d74%\u7684\u533b\u751f\u65e0\u6cd5\u533a\u5206AI\u548c\u4eba\u7c7b\u751f\u6210\u7684\u9274\u522b\u8bca\u65ad\u3002", "conclusion": "LLMs\u5728\u6587\u672c\u8bca\u65ad\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u6709\u6548\u6a21\u62df\u4e13\u5bb6\u6f14\u793a\uff0c\u4f46\u56fe\u50cf\u548c\u6587\u732e\u68c0\u7d22\u4ecd\u9700\u6539\u8fdb\u3002CPC-Bench\u548cCaBot\u4e3a\u533b\u5b66AI\u8fdb\u5c55\u63d0\u4f9b\u4e86\u900f\u660e\u8ffd\u8e2a\u5de5\u5177\u3002"}}
{"id": "2509.11864", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11864", "abs": "https://arxiv.org/abs/2509.11864", "authors": ["Lichao Wu", "Sasha Behrouzi", "Mohamadreza Rostami", "Maximilian Thang", "Stjepan Picek", "Ahmad-Reza Sadeghi"], "title": "NeuroStrike: Neuron-Level Attacks on Aligned LLMs", "comment": null, "summary": "Safety alignment is critical for the ethical deployment of large language\nmodels (LLMs), guiding them to avoid generating harmful or unethical content.\nCurrent alignment techniques, such as supervised fine-tuning and reinforcement\nlearning from human feedback, remain fragile and can be bypassed by carefully\ncrafted adversarial prompts. Unfortunately, such attacks rely on trial and\nerror, lack generalizability across models, and are constrained by scalability\nand reliability.\n  This paper presents NeuroStrike, a novel and generalizable attack framework\nthat exploits a fundamental vulnerability introduced by alignment techniques:\nthe reliance on sparse, specialized safety neurons responsible for detecting\nand suppressing harmful inputs. We apply NeuroStrike to both white-box and\nblack-box settings: In the white-box setting, NeuroStrike identifies safety\nneurons through feedforward activation analysis and prunes them during\ninference to disable safety mechanisms. In the black-box setting, we propose\nthe first LLM profiling attack, which leverages safety neuron transferability\nby training adversarial prompt generators on open-weight surrogate models and\nthen deploying them against black-box and proprietary targets. We evaluate\nNeuroStrike on over 20 open-weight LLMs from major LLM developers. By removing\nless than 0.6% of neurons in targeted layers, NeuroStrike achieves an average\nattack success rate (ASR) of 76.9% using only vanilla malicious prompts.\nMoreover, Neurostrike generalizes to four multimodal LLMs with 100% ASR on\nunsafe image inputs. Safety neurons transfer effectively across architectures,\nraising ASR to 78.5% on 11 fine-tuned models and 77.7% on five distilled\nmodels. The black-box LLM profiling attack achieves an average ASR of 63.7%\nacross five black-box models, including the Google Gemini family.", "AI": {"tldr": "NeuroStrike\u662f\u4e00\u79cd\u65b0\u9896\u7684\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u4fee\u526a\u5b89\u5168\u795e\u7ecf\u5143\u6765\u7ed5\u8fc7LLM\u7684\u5b89\u5168\u5bf9\u9f50\u673a\u5236\uff0c\u5728\u767d\u76d2\u548c\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u90fd\u80fd\u6709\u6548\u653b\u51fb\uff0c\u6210\u529f\u7387\u9ad8\u8fbe76.9%", "motivation": "\u5f53\u524dLLM\u5b89\u5168\u5bf9\u9f50\u6280\u672f\uff08\u5982\u76d1\u7763\u5fae\u8c03\u548cRLHF\uff09\u5b58\u5728\u8106\u5f31\u6027\uff0c\u5bb9\u6613\u88ab\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5bf9\u6297\u63d0\u793a\u7ed5\u8fc7\uff0c\u4f46\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u4f9d\u8d56\u8bd5\u9519\u3001\u7f3a\u4e4f\u6cdb\u5316\u6027\u4e14\u53d7\u53ef\u6269\u5c55\u6027\u9650\u5236", "method": "\u767d\u76d2\u8bbe\u7f6e\uff1a\u901a\u8fc7\u524d\u5411\u6fc0\u6d3b\u5206\u6790\u8bc6\u522b\u5b89\u5168\u795e\u7ecf\u5143\uff0c\u5728\u63a8\u7406\u65f6\u4fee\u526a\u8fd9\u4e9b\u795e\u7ecf\u5143\uff1b\u9ed1\u76d2\u8bbe\u7f6e\uff1a\u63d0\u51fa\u9996\u4e2aLLM\u5256\u6790\u653b\u51fb\uff0c\u5728\u5f00\u6e90\u4ee3\u7406\u6a21\u578b\u4e0a\u8bad\u7ec3\u5bf9\u6297\u63d0\u793a\u751f\u6210\u5668\uff0c\u7136\u540e\u653b\u51fb\u9ed1\u76d2\u76ee\u6807", "result": "\u572820\u591a\u4e2a\u5f00\u6e90LLM\u4e0a\uff0c\u4fee\u526a\u76ee\u6807\u5c42\u4e2d\u4e0d\u52300.6%\u7684\u795e\u7ecf\u5143\uff0c\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u8fbe76.9%\uff1b\u5bf94\u4e2a\u591a\u6a21\u6001LLM\u5b9e\u73b0100%\u6210\u529f\u7387\uff1b\u9ed1\u76d2\u653b\u51fb\u57285\u4e2a\u9ed1\u76d2\u6a21\u578b\u4e0a\u5e73\u5747\u6210\u529f\u7387\u8fbe63.7%", "conclusion": "\u5b89\u5168\u795e\u7ecf\u5143\u5728\u4e0d\u540c\u67b6\u6784\u95f4\u5177\u6709\u6709\u6548\u8fc1\u79fb\u6027\uff0cNeuroStrike\u6846\u67b6\u63ed\u793a\u4e86\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u7684\u6839\u672c\u8106\u5f31\u6027\uff0c\u5bf9LLM\u5b89\u5168\u90e8\u7f72\u63d0\u51fa\u4e86\u91cd\u8981\u6311\u6218"}}
{"id": "2509.11870", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11870", "abs": "https://arxiv.org/abs/2509.11870", "authors": ["Xian Qin", "Xue Yang", "Xiaohu Tang"], "title": "Efficient Byzantine-Robust Privacy-Preserving Federated Learning via Dimension Compression", "comment": null, "summary": "Federated Learning (FL) allows collaborative model training across\ndistributed clients without sharing raw data, thus preserving privacy. However,\nthe system remains vulnerable to privacy leakage from gradient updates and\nByzantine attacks from malicious clients. Existing solutions face a critical\ntrade-off among privacy preservation, Byzantine robustness, and computational\nefficiency. We propose a novel scheme that effectively balances these competing\nobjectives by integrating homomorphic encryption with dimension compression\nbased on the Johnson-Lindenstrauss transformation. Our approach employs a\ndual-server architecture that enables secure Byzantine defense in the\nciphertext domain while dramatically reducing computational overhead through\ngradient compression. The dimension compression technique preserves the\ngeometric relationships necessary for Byzantine defence while reducing\ncomputation complexity from $O(dn)$ to $O(kn)$ cryptographic operations, where\n$k \\ll d$. Extensive experiments across diverse datasets demonstrate that our\napproach maintains model accuracy comparable to non-private FL while\neffectively defending against Byzantine clients comprising up to $40\\%$ of the\nnetwork.", "AI": {"tldr": "\u805a\u5408\u5b66\u4e60\u4e2d\u7684\u9632\u6cc4\u9732\u4e0e\u53cd\u5e0c\u62c9\u653f\u51fb\u7684\u65b0\u65b9\u6848\uff0c\u901a\u8fc7\u540c\u6001\u52a0\u5bc6\u548c\u7ef4\u5ea6\u538b\u7f29\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u3001\u7cbe\u795e\u7c92\u5b50\u9632\u5fa1\u548c\u8ba1\u7b97\u6548\u7387\u7684\u5e73\u8861", "motivation": "\u805a\u5408\u5b66\u4e60\u867d\u7136\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u4f46\u4ecd\u9762\u4e34\u68af\u5ea6\u66b4\u9732\u9690\u79c1\u548c\u6076\u610f\u5ba2\u6237\u653b\u51fb\u7684\u98ce\u9669\uff0c\u73b0\u6709\u65b9\u6848\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u9690\u79c1\u4fdd\u62a4\u3001\u7cbe\u795e\u7c97\u9c81\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u8981\u6c42", "method": "\u91c7\u7528\u540c\u6001\u52a0\u5bc6\u7ed3\u5408Johnson-Lindenstrauss\u53d8\u6362\u7684\u7ef4\u5ea6\u538b\u7f29\u6280\u672f\uff0c\u6784\u5efa\u53cc\u670d\u52a1\u5668\u67b6\u6784\uff0c\u5728\u52a0\u5bc6\u57df\u5b9e\u73b0\u5b89\u5168\u7684\u7cbe\u795e\u7c97\u9c81\u6027\u9632\u5fa1\uff0c\u5e76\u901a\u8fc7\u68af\u5ea6\u538b\u7f29\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500", "result": "\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(dn)\u964d\u81f3O(kn)\uff08k\u226ad\uff09\uff0c\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u7ecf\u9a8c\u9a8c\u8bc1\u80fd\u4fdd\u6301\u4e0e\u975e\u9690\u79c1\u805a\u5408\u5b66\u4e60\u76f8\u5f53\u7684\u6a21\u578b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u6709\u6548\u9632\u5fa1\u7f51\u7edc\u4e2d\u8fbe40%\u7684\u6076\u610f\u5ba2\u6237\u653b\u51fb", "conclusion": "\u8be5\u65b9\u6848\u6210\u529f\u89e3\u51b3\u4e86\u805a\u5408\u5b66\u4e60\u4e2d\u9690\u79c1\u4fdd\u62a4\u3001\u7cbe\u795e\u7c97\u9c81\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u4e89\u6263\uff0c\u4e3a\u5b89\u5168\u9ad8\u6548\u7684\u534f\u4f5c\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84"}}
{"id": "2509.11934", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.11934", "abs": "https://arxiv.org/abs/2509.11934", "authors": ["Praveensankar Manimaran", "Mayank Raikwar", "Thiago Garrett", "Arlindo F. da Concei\u00e7\u00e3o", "Leander Jehl", "Roman Vitenberg"], "title": "zkToken: Empowering Holders to Limit Revocation Checks for Verifiable Credentials", "comment": null, "summary": "Systems managing Verifiable Credentials are becoming increasingly popular.\nUnfortunately, their support for revoking previously issued credentials allows\nverifiers to effectively monitor the validity of the credentials, which is\nsensitive information. While the issue started to gain recognition, no adequate\nsolution has been proposed so far.\n  In this work, we propose a novel framework for time-limited continuous\nverification. The holder is able to individually configure the verification\nperiod when sharing information with the verifier, and the system guarantees\nproven untraceability of the revocation status after the verification period\nexpires. Different from existing systems, the implementation adopts a more\nscalable blacklist approach where tokens corresponding to revoked credentials\nare stored in the registry. The approach employs ZK proofs that allow holders\nto prove non-membership in the blacklist. In addition to theoretically proving\nsecurity, we evaluate the approach analytically and experimentally and show\nthat it significantly improves bandwidth consumption on the holder while being\non par with state-of-the-art solutions with respect to the other performance\nmetrics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u9650\u5236\u8fde\u7eed\u9a8c\u8bc1\u6846\u67b6\uff0c\u89e3\u51b3\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u7cfb\u7edf\u4e2d\u7684\u8ddf\u8e2a\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u9ed1\u540d\u5355\u65b9\u6848\u548c\u96f6\u77e5\u8bc1\u660e\u5b9e\u73b0\u9a8c\u8bc1\u5468\u671f\u540e\u64a4\u9500\u72b6\u6001\u7684\u4e0d\u53ef\u8ffd\u8e2a\u6027", "motivation": "\u73b0\u6709\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u7cfb\u7edf\u5728\u64a4\u9500\u65f6\u5141\u8bb8\u9a8c\u8bc1\u65b9\u76d1\u63a7\u51ed\u8bc1\u6709\u6548\u6027\uff0c\u8fd9\u662f\u654f\u611f\u4fe1\u606f\uff0c\u5b58\u5728\u8ddf\u8e2a\u98ce\u9669\uff0c\u4e14\u76ee\u524d\u6ca1\u6709\u9002\u5f53\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u91c7\u7528\u9ed1\u540d\u5355\u65b9\u6848\uff0c\u5c06\u64a4\u9500\u51ed\u8bc1\u7684\u4ee4\u724c\u5b58\u50a8\u5728\u6ce8\u518c\u8868\u4e2d\uff0c\u4f7f\u7528\u96f6\u77e5\u8bc1\u660e\u5141\u8bb8\u6301\u6709\u8005\u8bc1\u660e\u975e\u9ed1\u540d\u5355\u6210\u5458\uff0c\u6301\u6709\u8005\u53ef\u4ee5\u4e2a\u522b\u914d\u7f6e\u9a8c\u8bc1\u5468\u671f", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u5b89\u5168\u6027\uff0c\u5206\u6790\u548c\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\u5728\u4fdd\u6301\u5176\u4ed6\u6027\u80fd\u6307\u6807\u4e0e\u73b0\u6709\u65b9\u6848\u76f8\u5f53\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6301\u6709\u8005\u7684\u5e26\u5bbd\u6d88\u8017", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u7cfb\u7edf\u4e2d\u7684\u8ddf\u8e2a\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u9a8c\u8bc1\u5468\u671f\u540e\u64a4\u9500\u72b6\u6001\u7684\u4e0d\u53ef\u8ffd\u8e2a\u6027\u4fdd\u8bc1\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\u4f18\u52bf"}}
{"id": "2509.11974", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.11974", "abs": "https://arxiv.org/abs/2509.11974", "authors": ["Soumia Zohra El Mestari", "Maciej Krzysztof Zuziak", "Gabriele Lenzini"], "title": "Poison to Detect: Detection of Targeted Overfitting in Federated Learning", "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across\ndecentralised clients while keeping local data private, making it a widely\nadopted privacy-enhancing technology (PET). Despite its privacy benefits, FL\nremains vulnerable to privacy attacks, including those targeting specific\nclients. In this paper, we study an underexplored threat where a dishonest\norchestrator intentionally manipulates the aggregation process to induce\ntargeted overfitting in the local models of specific clients. Whereas many\nstudies in this area predominantly focus on reducing the amount of information\nleakage during training, we focus on enabling an early client-side detection of\ntargeted overfitting, thereby allowing clients to disengage before significant\nharm occurs. In line with this, we propose three detection techniques - (a)\nlabel flipping, (b) backdoor trigger injection, and (c) model fingerprinting -\nthat enable clients to verify the integrity of the global aggregation. We\nevaluated our methods on multiple datasets under different attack scenarios.\nOur results show that the three methods reliably detect targeted overfitting\ninduced by the orchestrator, but they differ in terms of computational\ncomplexity, detection latency, and false-positive rates.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8054\u90a6\u5b66\u4e60\u4e2d\u534f\u8c03\u5668\u64cd\u7eb5\u805a\u5408\u8fc7\u7a0b\u5bfc\u81f4\u7279\u5b9a\u5ba2\u6237\u7aef\u672c\u5730\u6a21\u578b\u8fc7\u62df\u5408\u7684\u5a01\u80c1\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u5ba2\u6237\u7aef\u68c0\u6d4b\u6280\u672f\u6765\u9a8c\u8bc1\u5168\u5c40\u805a\u5408\u7684\u5b8c\u6574\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u80fd\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u4f46\u4ecd\u6613\u53d7\u9690\u79c1\u653b\u51fb\uff0c\u7279\u522b\u662f\u534f\u8c03\u5668\u6545\u610f\u64cd\u7eb5\u805a\u5408\u8fc7\u7a0b\u5bfc\u81f4\u7279\u5b9a\u5ba2\u6237\u7aef\u8fc7\u62df\u5408\u7684\u5a01\u80c1\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u51cf\u5c11\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u4fe1\u606f\u6cc4\u9732\uff0c\u800c\u672c\u6587\u5173\u6ce8\u8ba9\u5ba2\u6237\u7aef\u80fd\u65e9\u671f\u68c0\u6d4b\u5230\u9488\u5bf9\u6027\u8fc7\u62df\u5408\uff0c\u4ece\u800c\u5728\u9020\u6210\u91cd\u5927\u635f\u5bb3\u524d\u9000\u51fa\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u68c0\u6d4b\u6280\u672f\uff1a(a)\u6807\u7b7e\u7ffb\u8f6c - \u901a\u8fc7\u7ffb\u8f6c\u6807\u7b7e\u6765\u68c0\u6d4b\u6a21\u578b\u5f02\u5e38\uff1b(b)\u540e\u95e8\u89e6\u53d1\u5668\u6ce8\u5165 - \u6ce8\u5165\u7279\u5b9a\u6a21\u5f0f\u6765\u9a8c\u8bc1\u6a21\u578b\u884c\u4e3a\uff1b(c)\u6a21\u578b\u6307\u7eb9\u8bc6\u522b - \u901a\u8fc7\u6a21\u578b\u7279\u5f81\u6765\u8bc6\u522b\u5f02\u5e38\u3002\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u4e0d\u540c\u653b\u51fb\u573a\u666f\u4e0b\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u4e09\u79cd\u65b9\u6cd5\u90fd\u80fd\u53ef\u9760\u5730\u68c0\u6d4b\u51fa\u534f\u8c03\u5668\u8bf1\u5bfc\u7684\u9488\u5bf9\u6027\u8fc7\u62df\u5408\uff0c\u4f46\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u68c0\u6d4b\u5ef6\u8fdf\u548c\u8bef\u62a5\u7387\u65b9\u9762\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u63d0\u51fa\u7684\u5ba2\u6237\u7aef\u68c0\u6d4b\u6280\u672f\u80fd\u6709\u6548\u8bc6\u522b\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9488\u5bf9\u6027\u8fc7\u62df\u5408\u653b\u51fb\uff0c\u4e3a\u5ba2\u6237\u7aef\u63d0\u4f9b\u4e86\u65e9\u671f\u68c0\u6d4b\u548c\u9000\u51fa\u7684\u673a\u5236\uff0c\u589e\u5f3a\u4e86\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2509.12181", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.12181", "abs": "https://arxiv.org/abs/2509.12181", "authors": ["Pujan Paudel", "Gianluca Stringhini"], "title": "LOKI: Proactively Discovering Online Scam Websites by Mining Toxic Search Queries", "comment": "Published in the Proceedings of the 33rd Network and Distributed\n  System Security Symposium (NDSS 2026)", "summary": "Online e-commerce scams, ranging from shopping scams to pet scams, globally\ncause millions of dollars in financial damage every year. In response, the\nsecurity community has developed highly accurate detection systems able to\ndetermine if a website is fraudulent. However, finding candidate scam websites\nthat can be passed as input to these downstream detection systems is\nchallenging: relying on user reports is inherently reactive and slow, and\nproactive systems issuing search engine queries to return candidate websites\nsuffer from low coverage and do not generalize to new scam types. In this\npaper, we present LOKI, a system designed to identify search engine queries\nlikely to return a high fraction of fraudulent websites. LOKI implements a\nkeyword scoring model grounded in Learning Under Privileged Information (LUPI)\nand feature distillation from Search Engine Result Pages (SERPs). We rigorously\nvalidate LOKI across 10 major scam categories and demonstrate a 20.58 times\nimprovement in discovery over both heuristic and data-driven baselines across\nall categories. Leveraging a small seed set of only 1,663 known scam sites, we\nuse the keywords identified by our method to discover 52,493 previously\nunreported scams in the wild. Finally, we show that LOKI generalizes to\npreviously-unseen scam categories, highlighting its utility in surfacing\nemerging threats.", "AI": {"tldr": "LOKI\u7cfb\u7edf\u901a\u8fc7LUPI\u548cSERP\u7279\u5f81\u84b8\u998f\u65b9\u6cd5\uff0c\u4ece\u641c\u7d22\u5f15\u64ce\u67e5\u8be2\u4e2d\u8bc6\u522b\u53ef\u80fd\u8fd4\u56de\u9ad8\u6bd4\u4f8b\u6b3a\u8bc8\u7f51\u7ad9\u7684\u67e5\u8be2\u5173\u952e\u8bcd\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bc8\u9a97\u7f51\u7ad9\u7684\u53d1\u73b0\u6548\u7387", "motivation": "\u73b0\u6709\u7535\u5546\u8bc8\u9a97\u68c0\u6d4b\u7cfb\u7edf\u867d\u7136\u51c6\u786e\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u7684\u5019\u9009\u7f51\u7ad9\u53d1\u73b0\u673a\u5236\u3002\u7528\u6237\u62a5\u544a\u53cd\u5e94\u6ede\u540e\uff0c\u4e3b\u52a8\u641c\u7d22\u65b9\u6cd5\u8986\u76d6\u7387\u4f4e\u4e14\u65e0\u6cd5\u9002\u5e94\u65b0\u578b\u8bc8\u9a97\u7c7b\u578b", "method": "\u57fa\u4e8e\u5b66\u4e60\u7279\u6743\u4fe1\u606f(LUPI)\u6846\u67b6\u548c\u641c\u7d22\u5f15\u64ce\u7ed3\u679c\u9875\u9762(SERP)\u7279\u5f81\u84b8\u998f\u7684\u5173\u952e\u8bcd\u8bc4\u5206\u6a21\u578b", "result": "\u572810\u4e2a\u4e3b\u8981\u8bc8\u9a97\u7c7b\u522b\u4e2d\u6bd4\u57fa\u51c6\u65b9\u6cd5\u63d0\u534720.58\u500d\u53d1\u73b0\u6548\u7387\uff0c\u4ec5\u75281,663\u4e2a\u5df2\u77e5\u8bc8\u9a97\u7f51\u7ad9\u79cd\u5b50\u96c6\u5c31\u53d1\u73b0\u4e8652,493\u4e2a\u672a\u62a5\u544a\u8bc8\u9a97\u7f51\u7ad9\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u8bc8\u9a97\u7c7b\u522b", "conclusion": "LOKI\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u53d1\u73b0\u7535\u5546\u8bc8\u9a97\u7f51\u7ad9\uff0c\u5177\u6709\u9ad8\u8986\u76d6\u7387\u548c\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5bf9\u53ca\u65f6\u53d1\u73b0\u65b0\u5174\u7f51\u7edc\u5a01\u80c1\u5177\u6709\u91cd\u8981\u5b9e\u7528\u4ef7\u503c"}}
