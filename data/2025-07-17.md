<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 11]
- [cs.CR](#cs.CR) [Total: 15]
- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Decision Models for Selecting Architecture Patterns and Strategies in Quantum Software Systems](https://arxiv.org/abs/2507.11671)
*Mst Shamima Aktar,Peng Liang,Muhammad Waseem,Amjed Tahir,Mojtaba Shahin,Muhammad Azeem Akbar,Arif Ali Khan,Aakash Ahmad,Musengamana Jean de Dieu,Ruiyin Li*

Main category: cs.SE

TL;DR: 该研究提出了量子软件系统中六个关键设计领域的决策模型，以帮助开发者选择合适的架构模式和策略。


<details>
  <summary>Details</summary>
Motivation: 量子软件开发者在选择和实现架构模式与策略时面临复杂性和缺乏指导的挑战。

Method: 通过数据挖掘（GitHub和Stack Exchange）和系统文献综述收集相关模式与策略，并构建决策模型，随后通过16位从业者的半结构化访谈进行评估。

Result: 决策模型在熟悉度、可理解性、完整性和实用性方面得到验证，能有效帮助开发者应对架构设计挑战。

Conclusion: 提出的决策模型为量子软件系统的架构设计提供了实用指导，相关数据集可供社区进一步研究。

Abstract: Quantum software represents disruptive technologies in terms of
quantum-specific software systems, services, and applications - leverage the
principles of quantum mechanics via programmable quantum bits (Qubits) that
manipulate quantum gates (QuGates) - to achieve quantum supremacy in computing.
Quantum software architecture enables quantum software developers to abstract
away implementation-specific details (i.e., mapping of Qubits and QuGates to
high-level architectural components and connectors). Architectural patterns and
strategies can provide reusable knowledge and best practices to engineer
quantum software systems effectively and efficiently. However, quantum software
practitioners face significant challenges in selecting and implementing
appropriate patterns and strategies due to the complexity of quantum software
systems and the lack of guidelines. To address these challenges, this study
proposes decision models for selecting patterns and strategies in six critical
design areas in quantum software systems: Communication, Decomposition, Data
Processing, Fault Tolerance, Integration and Optimization, and Algorithm
Implementation. These decision models are constructed based on data collected
from both a mining study (i.e., GitHub and Stack Exchange) and a Systematic
Literature Review, which were used to identify relevant patterns and strategies
with their involved Quality Attributes (QAs). We then conducted semi-structured
interviews with 16 quantum software practitioners to evaluate the familiarity,
understandability, completeness, and usefulness of the proposed decision
models. The results show that the proposed decision models can aid
practitioners in selecting suitable patterns and strategies to address the
challenges related to the architecture design of quantum software systems. The
dataset is available at [6], allowing the community to reproduce and build upon
our findings.

</details>


### [2] [MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization](https://arxiv.org/abs/2507.11687)
*Atharva Naik,Lawanya Baghel,Dhakshin Govindarajan,Darsh Agrawal,Daniel Fried,Carolyn Rose*

Main category: cs.SE

TL;DR: MetaLint是一个基于指令调优的框架，用于代码质量分析，通过合成数据支持模型适应新代码模式，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在代码生成方面表现优异，但在代码质量分析上受限于静态训练数据，难以适应不断发展的最佳实践。

Method: MetaLint通过指令调优合成linter生成的数据，支持从易到难的泛化，使模型能适应新或复杂的代码模式。

Result: MetaLint在未见的PEP习语检测上表现优异，F-score达70.37%，定位准确率为26.73%，与更大模型相当。

Conclusion: MetaLint展示了在代码质量分析中的潜力，尤其是对未来实践的适应性。

Abstract: Large Language Models, though successful in code generation, struggle with
code quality analysis because they are limited by static training data and
can't easily adapt to evolving best practices. We introduce MetaLint, a new
instruction-following framework that formulates code quality analysis as the
task of detecting and fixing problematic semantic code fragments or code idioms
based on high-level specifications. Unlike conventional approaches that train
models on static, rule-based data, MetaLint employs instruction tuning on
synthetic linter-generated data to support easy-to-hard generalization,
enabling models to adapt to novel or complex code patterns without retraining.
To evaluate this, we construct a benchmark of challenging idioms inspired by
real-world coding standards such as Python Enhancement Proposals (PEPs) and
assess whether MetaLint-trained models reason adaptively or simply memorize.
Our results show that MetaLint improves generalization to unseen PEP idioms,
achieving a 70.37% F-score on idiom detection with the highest recall (70.43%)
among all evaluated models. It also achieves 26.73% on localization,
competitive for its 4B parameter size and comparable to larger state-of-the-art
models like o3-mini, highlighting its potential for future-proof code quality
analysis.

</details>


### [3] [REST in Pieces: RESTful Design Rule Violations in Student-Built Web Apps](https://arxiv.org/abs/2507.11689)
*Sergio Di Meglio,Valeria Pontillo,Luigi Libero Lucio Starace*

Main category: cs.SE

TL;DR: 研究发现计算机科学本科课程中软件质量常被忽视，学生代码质量普遍较低，尤其是REST API设计问题频发。


<details>
  <summary>Details</summary>
Motivation: 探讨学生代码质量现状，为教育和招聘实践提供依据。

Method: 通过自动化静态分析管道评估40个全栈Web应用中的REST API设计规则遵守情况。

Result: 发现常见违规行为，如端点路径缺少连字符（98%）、复数形式错误（88%）和HTTP方法误用（83%）。

Conclusion: 需加强API设计教学，并推广自动化工具以提升学生代码质量。

Abstract: In Computer Science Bachelor's programs, software quality is often
underemphasized due to limited time and a focus on foundational skills, leaving
many students unprepared for industry expectations. To better understand the
typical quality of student code and inform both education and hiring practices,
we analyze 40 full-stack web applications developed in a third-year Web
Technologies course. Using an automated static analysis pipeline, we assess
adherence to REST API design rules. Results reveal frequent violations of
foundational conventions, such as missing hyphens in endpoint paths (98%),
incorrect pluralization (88%), and misuse of HTTP methods (83%). These findings
highlight the need for more focused instruction on API design and support the
adoption of automated tools to improve code quality in student projects.

</details>


### [4] [Extremal Testing for Network Software using LLMs](https://arxiv.org/abs/2507.11898)
*Rathin Singha,Harry Qian,Srinath Saikrishnan,Tracy Zhao,Ryan Beckett,Siva Kesava Reddy Kakarla,George Varghese*

Main category: cs.SE

TL;DR: 利用LLM自动化网络软件的极端测试，通过生成违反约束的输入发现新bug，并扩展到集中式网络软件和过滤代码生成。


<details>
  <summary>Details</summary>
Motivation: 传统极端测试依赖人工，效率低且难以覆盖所有边界情况，LLM可自动化此过程。

Method: 分两步：1) 用LLM生成输入约束；2) 用LLM生成违反约束的测试用例。

Result: 在HTTP、BGP和DNS实现中发现新bug，并成功扩展到集中式网络软件。

Conclusion: LLM生成的极端测试优于传统边界值分析，未来可通过智能代理进一步自动化。

Abstract: Physicists often manually consider extreme cases when testing a theory. In
this paper, we show how to automate extremal testing of network software using
LLMs in two steps: first, ask the LLM to generate input constraints (e.g., DNS
name length limits); then ask the LLM to generate tests that violate the
constraints. We demonstrate how easy this process is by generating extremal
tests for HTTP, BGP and DNS implementations, each of which uncovered new bugs.
We show how this methodology extends to centralized network software such as
shortest path algorithms, and how LLMs can generate filtering code to reject
extremal input. We propose using agentic AI to further automate extremal
testing. LLM-generated extremal testing goes beyond an old technique in
software testing called Boundary Value Analysis.

</details>


### [5] [A Task Taxonomy for Conformance Checking](https://arxiv.org/abs/2507.11976)
*Jana-Rebecca Rehse,Michael Grohs,Finn Klessascheck,Lisa-Marie Klein,Tatiana von Landesberger,Luise Pufahl*

Main category: cs.SE

TL;DR: 本文提出了一种任务分类法，用于系统化一致性检查分析中的任务，以明确可视化的目的，并促进过程挖掘与可视化分析领域的合作。


<details>
  <summary>Details</summary>
Motivation: 当前一致性检查工具的可视化目的不明确，缺乏系统化的理解，难以评估其有效性。

Method: 提出任务分类法，从目标、手段、约束类型、数据特征、数据目标和数据基数等方面分类一致性检查任务。

Result: 任务分类法帮助研究者明确可视化目的，支持更紧密的跨学科合作。

Conclusion: 通过结合过程挖掘与可视化分析，本文为一致性检查的可视化提供了系统化的理论基础。

Abstract: Conformance checking is a sub-discipline of process mining, which compares
observed process traces with a process model to analyze whether the process
execution conforms with or deviates from the process design. Organizations can
leverage this analysis, for example to check whether their processes comply
with internal or external regulations or to identify potential improvements.
Gaining these insights requires suitable visualizations, which make complex
results accessible and actionable. So far, however, the development of
conformance checking visualizations has largely been left to tool vendors. As a
result, current tools offer a wide variety of visual representations for
conformance checking, but the analytical purposes they serve often remain
unclear. However, without a systematic understanding of these purposes, it is
difficult to evaluate the visualizations' usefulness. Such an evaluation hence
requires a deeper understanding of conformance checking as an analysis domain.
To this end, we propose a task taxonomy, which categorizes the tasks that can
occur when conducting conformance checking analyses. This taxonomy supports
researchers in determining the purpose of visualizations, specifying relevant
conformance checking tasks in terms of their goal, means, constraint type, data
characteristics, data target, and data cardinality. Combining concepts from
process mining and visual analytics, we address researchers from both
disciplines to enable and support closer collaborations.

</details>


### [6] [LLAMA: Multi-Feedback Smart Contract Fuzzing Framework with LLM-Guided Seed Generation](https://arxiv.org/abs/2507.12084)
*Keke Gai,Haochen Liang,Jing Yu,Liehuang Zhu,Dusit Niyato*

Main category: cs.SE

TL;DR: LLAMA是一个基于大语言模型的多反馈智能合约模糊测试框架，通过结合LLMs、进化突变策略和混合测试技术，显著提升了覆盖率和漏洞检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有模糊测试工具主要关注种子调度和生成，而突变调度被忽视，影响了测试效果。LLAMA旨在填补这一空白。

Method: LLAMA采用分层提示策略生成初始种子，多反馈优化机制改进种子生成和突变调度，并结合进化模糊引擎和符号执行。

Result: 实验显示LLAMA在指令覆盖率和分支覆盖率上分别达到91%和90%，检测出132/148已知漏洞。

Conclusion: LLAMA在智能合约安全测试中表现出高效性、适应性和实用性。

Abstract: Smart contracts play a pivotal role in blockchain ecosystems, and fuzzing
remains an important approach to securing smart contracts. Even though mutation
scheduling is a key factor influencing fuzzing effectiveness, existing fuzzers
have primarily explored seed scheduling and generation, while mutation
scheduling has been rarely addressed by prior work. In this work, we propose a
Large Language Models (LLMs)-based Multi-feedback Smart Contract Fuzzing
framework (LLAMA) that integrates LLMs, evolutionary mutation strategies, and
hybrid testing techniques. Key components of the proposed LLAMA include: (i) a
hierarchical prompting strategy that guides LLMs to generate semantically valid
initial seeds, coupled with a lightweight pre-fuzzing phase to select
high-potential inputs; (ii) a multi-feedback optimization mechanism that
simultaneously improves seed generation, seed selection, and mutation
scheduling by leveraging runtime coverage and dependency feedback; and (iii) an
evolutionary fuzzing engine that dynamically adjusts mutation operator
probabilities based on effectiveness, while incorporating symbolic execution to
escape stagnation and uncover deeper vulnerabilities. Our experiments
demonstrate that LLAMA outperforms state-of-the-art fuzzers in both coverage
and vulnerability detection. Specifically, it achieves 91% instruction coverage
and 90% branch coverage, while detecting 132 out of 148 known vulnerabilities
across diverse categories. These results highlight LLAMA's effectiveness,
adaptability, and practicality in real-world smart contract security testing
scenarios.

</details>


### [7] [From Static to Intelligent: Evolving SaaS Pricing with LLMs](https://arxiv.org/abs/2507.12104)
*Francisco Javier Cavero,Juan C. Alonso,Antonio Ruiz-Cortés*

Main category: cs.SE

TL;DR: 论文提出了一种基于LLM的智能定价（iPricing）方法，通过自动化工具AI4Pricing2Yaml将静态HTML定价转换为动态可读的定价模型，解决了SaaS定价管理的复杂性和人工错误问题。


<details>
  <summary>Details</summary>
Motivation: SaaS市场的快速扩张导致定价管理复杂化，缺乏自动化工具限制了定价模型的评估和优化能力。

Method: 采用LLM驱动的AI4Pricing2Yaml工具，结合网页抓取和LLM技术，提取定价组件并转换为智能定价模型。

Result: 在30个商业SaaS数据集上验证了系统的有效性，成功提取了150多个智能定价模型，但面临幻觉和动态内容的挑战。

Conclusion: 智能定价自动化能提升SaaS定价管理的效率和一致性，未来研究将优化提取能力和适应性。

Abstract: The SaaS paradigm has revolutionized software distribution by offering
flexible pricing options to meet diverse customer needs. However, the rapid
expansion of the SaaS market has introduced significant complexity for DevOps
teams, who must manually manage and evolve pricing structures, an approach that
is both time-consuming and prone to errors. The absence of automated tools for
pricing analysis restricts the ability to efficiently evaluate, optimize, and
scale these models. This paper proposes leveraging intelligent pricing
(iPricing), dynamic, machine-readable pricing models, as a solution to these
challenges. Intelligent pricing enables competitive analysis, streamlines
operational decision-making, and supports continuous pricing evolution in
response to market dynamics, leading to improved efficiency and accuracy. We
present an LLM-driven approach that automates the transformation of static HTML
pricing into iPricing, significantly improving efficiency and consistency while
minimizing human error. Our implementation, AI4Pricing2Yaml, features a basic
Information Extractor that uses web scraping and LLMs technologies to extract
essential pricing components, plans, features, usage limits, and add-ons, from
SaaS websites. Validation against a dataset of 30 distinct commercial SaaS,
encompassing over 150 intelligent pricings, demonstrates the system's
effectiveness in extracting the desired elements across all steps. However,
challenges remain in addressing hallucinations, complex structures, and dynamic
content. This work highlights the potential of automating intelligent pricing
transformation to streamline SaaS pricing management, offering implications for
improved consistency and scalability in an increasingly intricate pricing
landscape. Future research will focus on refining extraction capabilities and
enhancing the system's adaptability to a wider range of SaaS websites.

</details>


### [8] [An Online A/B Testing Decision Support System for Web Usability Assessment Based on a Linguistic Decision-making Methodology: Case of Study a Virtual Learning Environment](https://arxiv.org/abs/2507.12118)
*Noe Zermeño,Cristina Zuheros,Lucas Daniel Del Rosso Calache,Francisco Herrera,Rosana Montes*

Main category: cs.SE

TL;DR: 提出了一种基于用户中心方法的网页可用性评估方法，结合A/B测试和角色扮演，应用于实际案例。


<details>
  <summary>Details</summary>
Motivation: 提升用户界面满意度，解决现有工具在评估设计时支持不足的问题。

Method: 结合设计思维和语言决策，通过角色扮演和可用性测试（如SUS）进行评估。

Result: 方法应用于墨西哥瓜达拉哈拉大学的三个Moodle平台，通过真实用户验证。

Conclusion: 提出的方法有效评估网页可用性，结合用户参与和A/B测试，具有实际应用价值。

Abstract: In recent years, attention has increasingly focused on enhancing user
satisfaction with user interfaces, spanning both mobile applications and
websites. One fundamental aspect of human-machine interaction is the concept of
web usability. In order to assess web usability, the A/B testing technique
enables the comparison of data between two designs. Expanding the scope of
tests to include the designs being evaluated, in conjunction with the
involvement of both real and fictional users, presents a challenge for which
few online tools offer support. We propose a methodology for web usability
evaluation based on user-centered approaches such as design thinking and
linguistic decision-making, named Linguistic Decision-Making for Web Usability
Evaluation. This engages people in role-playing scenarios and conducts a number
of usability tests, including the widely recognized System Usability Scale. We
incorporate the methodology into a decision support system based on A/B
testing. We use real users in a case study to assess three Moodle platforms at
the University of Guadalajara, Mexico.

</details>


### [9] [MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks](https://arxiv.org/abs/2507.12284)
*Artem Chervyakov,Alexander Kharitonov,Pavel Zadorozhny,Adamenko Pavel,Rodion Levichev,Dmitrii Vorobev,Dmitrii Salikhov,Aidar Valeev,Alena Pestova,Maria Dziuba,Ilseyar Alimova,Artem Zavgorodnev,Aleksandr Medvedev,Stanislav Moiseev,Elena Bruches,Daniil Grebenkin,Roman Derunets,Vikulov Vladimir,Anton Emelyanov,Dmitrii Babaev,Vladimir V. Ivanov,Valentin Malykh,Alena Fenogenova*

Main category: cs.SE

TL;DR: MERA Code是一个新的基准测试，专注于评估俄语代码生成LLM的实际编码能力，填补了现有评估在代码质量和多语言支持上的空白。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估主要关注自然语言任务，忽视了代码质量和实际性能，尤其是在非英语语言中的表现。

Method: 提出MERA Code基准，包含11个任务和8种编程语言，提供开源代码库、评分系统和平台。

Result: 评估了开源和前沿API模型，发现其在非英语语言中的实际编码任务存在局限性。

Conclusion: MERA Code的发布旨在指导未来研究，推动模型开发，并标准化评估流程。

Abstract: Advancements in LLMs have enhanced task automation in software engineering;
however, current evaluations primarily focus on natural language tasks,
overlooking code quality. Most benchmarks prioritize high-level reasoning over
executable code and real-world performance, leaving gaps in understanding true
capabilities and risks associated with these models in production. To address
this issue, we propose MERA Code, a new addition to the MERA benchmark family,
specifically focused on evaluating code for the latest code generation LLMs in
Russian. This benchmark includes 11 evaluation tasks that span 8 programming
languages. Our proposed evaluation methodology features a taxonomy that
outlines the practical coding skills necessary for models to complete these
tasks. The benchmark comprises an open-source codebase for users to conduct
MERA assessments, a scoring system compatible with various programming
environments, and a platform featuring a leaderboard and submission system. We
evaluate open LLMs and frontier API models, analyzing their limitations in
terms of practical coding tasks in non-English languages. We are publicly
releasing MERA to guide future research, anticipate groundbreaking features in
model development, and standardize evaluation procedures.

</details>


### [10] [GitChameleon: Evaluating AI Code Generation Against Python Library Version Incompatibilities](https://arxiv.org/abs/2507.12367)
*Diganta Misra,Nizar Islah,Victor May,Brice Rauby,Zihan Wang,Justine Gehring,Antonio Orvieto,Muawiz Chaudhary,Eilif B. Muller,Irina Rish,Samira Ebrahimi Kahou,Massimo Caccia*

Main category: cs.SE

TL;DR: GitChameleon是一个新的数据集，用于评估AI在特定库版本下生成可执行代码的能力，揭示了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决软件库快速更新对代码生成的挑战，现有基准缺乏基于执行的评估。

Method: 引入包含328个Python代码完成问题的数据集，每个问题绑定特定库版本并附带单元测试。

Result: 当前最先进的模型在此任务上表现不佳，基线成功率仅为48-51%。

Conclusion: GitChameleon为理解动态代码库的挑战提供了基准，并推动更可靠的AI代码生成方法的发展。

Abstract: The rapid evolution of software libraries poses a considerable hurdle for
code generation, necessitating continuous adaptation to frequent version
updates while preserving backward compatibility. While existing code evolution
benchmarks provide valuable insights, they typically lack execution-based
evaluation for generating code compliant with specific library versions. To
address this, we introduce GitChameleon, a novel, meticulously curated dataset
comprising 328 Python code completion problems, each conditioned on specific
library versions and accompanied by executable unit tests. GitChameleon
rigorously evaluates the capacity of contemporary large language models (LLMs),
LLM-powered agents, code assistants, and RAG systems to perform
version-conditioned code generation that demonstrates functional accuracy
through execution. Our extensive evaluations indicate that state-of-the-art
systems encounter significant challenges with this task; enterprise models
achieving baseline success rates in the 48-51\% range, underscoring the
intricacy of the problem. By offering an execution-based benchmark emphasizing
the dynamic nature of code libraries, GitChameleon enables a clearer
understanding of this challenge and helps guide the development of more
adaptable and dependable AI code generation methods. We make the dataset and
evaluation code publicly available at
https://github.com/mrcabbage972/GitChameleonBenchmark.

</details>


### [11] [SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?](https://arxiv.org/abs/2507.12415)
*Xinyi He,Qian Liu,Mingzhe Du,Lin Yan,Zhijie Fan,Yiming Huang,Zejian Yuan,Zejun Ma*

Main category: cs.SE

TL;DR: SWE-Perf是首个针对LLMs在代码性能优化任务上的基准测试，包含140个实例，揭示了现有LLMs与专家级优化能力之间的差距。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在代码性能优化方面的潜力，填补其在仓库级别优化任务上的研究空白。

Method: 引入SWE-Perf基准，包含来自GitHub的140个性能优化实例，评估文件级和仓库级方法（如Agentless和OpenHands）。

Result: 现有LLMs在代码性能优化上与专家级表现存在显著差距。

Conclusion: SWE-Perf为评估LLMs在代码性能优化上的能力提供了系统方法，揭示了未来的研究方向。

Abstract: Code performance optimization is paramount in real-world software engineering
and critical for production-level systems. While Large Language Models (LLMs)
have demonstrated impressive capabilities in code generation and bug fixing,
their proficiency in enhancing code performance at the repository level remains
largely unexplored. To address this gap, we introduce SWE-Perf, the first
benchmark specifically designed to systematically evaluate LLMs on code
performance optimization tasks within authentic repository contexts. SWE-Perf
comprises 140 carefully curated instances, each derived from
performance-improving pull requests from popular GitHub repositories. Each
benchmark instance includes the relevant codebase, target functions,
performance-related tests, expert-authored patches, and executable
environments. Through a comprehensive evaluation of representative methods that
span file-level and repo-level approaches (e.g., Agentless and OpenHands), we
reveal a substantial capability gap between existing LLMs and expert-level
optimization performance, highlighting critical research opportunities in this
emerging field.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility](https://arxiv.org/abs/2507.11630)
*Brendan Murphy,Dillon Bowen,Shahrad Mohammadzadeh,Julius Broomfield,Adam Gleave,Kellin Pelrine*

Main category: cs.CR

TL;DR: 论文提出了一种名为jailbreak-tuning的方法，能够绕过AI模型的安全防护，使其生成高质量但有害的响应。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型的安全防护措施不足以防止通过微调（fine-tuning）绕过防护，导致模型可能被用于恶意目的。

Method: 采用jailbreak-tuning方法，通过微调模型（无论是开放权重还是封闭API）使其完全遵守有害请求，如提供CBRN协助或执行网络攻击。

Result: 实验表明，OpenAI、Google和Anthropic的模型均能被成功绕过防护，生成高质量的有害响应。

Conclusion: 当前模型对这类攻击的脆弱性日益增加，亟需开发防篡改的安全防护措施。

Abstract: AI systems are rapidly advancing in capability, and frontier model developers
broadly acknowledge the need for safeguards against serious misuse. However,
this paper demonstrates that fine-tuning, whether via open weights or closed
fine-tuning APIs, can produce helpful-only models. In contrast to prior work
which is blocked by modern moderation systems or achieved only partial removal
of safeguards or degraded output quality, our jailbreak-tuning method teaches
models to generate detailed, high-quality responses to arbitrary harmful
requests. For example, OpenAI, Google, and Anthropic models will fully comply
with requests for CBRN assistance, executing cyberattacks, and other criminal
activity. We further show that backdoors can increase not only the stealth but
also the severity of attacks, while stronger jailbreak prompts become even more
effective in fine-tuning attacks, linking attack and potentially defenses in
the input and weight spaces. Not only are these models vulnerable, more recent
ones also appear to be becoming even more vulnerable to these attacks,
underscoring the urgent need for tamper-resistant safeguards. Until such
safeguards are discovered, companies and policymakers should view the release
of any fine-tunable model as simultaneously releasing its evil twin: equally
capable as the original model, and usable for any malicious purpose within its
capabilities.

</details>


### [13] [Evasion Under Blockchain Sanctions](https://arxiv.org/abs/2507.11721)
*Endong Liu,Mark Ryan,Liyi Zhou,Pascal Berrang*

Main category: cs.CR

TL;DR: 论文评估了美国OFAC对Tornado Cash的制裁效果，发现尽管制裁减少了71.03%的存款量，但攻击者仍频繁使用该工具。研究提出了改进算法以应对制裁执行的结构性限制。


<details>
  <summary>Details</summary>
Motivation: 研究旨在量化评估制裁措施在区块链上的实际效果，并揭示现有执行实践的局限性。

Method: 以Tornado Cash为案例，分析了957天的以太坊数据（6.79百万区块和10.7亿交易），并提出了一种基于定量杂质的评分与追踪算法。

Result: 制裁减少了71.03%的存款量，但78.33%的安全事件仍依赖Tornado Cash。新算法处理区块时间为0.07±0.03秒，精确度97.61%，召回率74.08%。

Conclusion: 研究为去中心化金融的监管有效性提供了实证依据，并提出了改进制裁执行的实用算法。

Abstract: Sanctioning blockchain addresses has become a common regulatory response to
malicious activities. However, enforcement on permissionless blockchains
remains challenging due to complex transaction flows and sophisticated
fund-obfuscation techniques. Using cryptocurrency mixing tool Tornado Cash as a
case study, we quantitatively assess the effectiveness of U.S. Office of
Foreign Assets Control (OFAC) sanctions over a 957-day period, covering 6.79
million Ethereum blocks and 1.07 billion transactions. Our analysis reveals
that while OFAC sanctions reduced overall Tornado Cash deposit volume by 71.03%
to approximately 2 billion USD, attackers still relied on Tornado Cash in
78.33% of Ethereum-related security incidents, underscoring persistent evasion
strategies.
  We identify three structural limitations in current sanction enforcement
practices: (i) the susceptibility of binary sanction classifications to dusting
attacks; (ii) fragmented censorship by blockchain producers; and (iii) the
complexity of obfuscation services exploited by users. To address these gaps,
we introduce a more practical algorithm for scoring and tracking, grounded in
quantitative impurity. On average, our algorithm processes Ethereum blocks
within 0.07 $\pm$ 0.03 seconds and achieves 97.61% precision and 74.08% recall
when evaluated on the Bybit exploit. Our findings contribute to ongoing
discussions around regulatory effectiveness in Decentralized Finance by
providing empirical evidence, clarifying enforcement challenges, and informing
future compliance strategies in response to sanctions and blockchain-based
security risks.

</details>


### [14] [Space Cybersecurity Testbed: Fidelity Framework, Example Implementation, and Characterization](https://arxiv.org/abs/2507.11763)
*Jose Luis Castanon Remy,Caleb Chang,Ekzhin Ear,Shouhuai Xu*

Main category: cs.CR

TL;DR: 本文提出了一种用于表征空间网络安全测试平台保真度的框架，包含7个属性，并应用于实际测试平台的构建与验证。


<details>
  <summary>Details</summary>
Motivation: 空间基础设施面临的网络威胁尚未被充分理解，现有研究对测试平台的构建和表征较少。

Method: 提出一个包含7个属性的框架，用于表征测试平台的系统模型、威胁模型和防御能力，并应用于实际测试平台的构建。

Result: 展示了测试平台如何模拟真实空间网络攻击场景，并讨论了未来研究方向。

Conclusion: 该框架为空间网络安全测试平台的表征和构建提供了指导，有助于未来研究的深入。

Abstract: Cyber threats against space infrastructures, including satellites and systems
on the ground, have not been adequately understood. Testbeds are important to
deepen our understanding and validate space cybersecurity studies. The state of
the art is that there are very few studies on building testbeds, and there are
few characterizations of testbeds. In this paper, we propose a framework for
characterizing the fidelity of space cybersecurity testbeds. The framework
includes 7 attributes for characterizing the system models, threat models, and
defenses that can be accommodated by a testbed. We use the framework to guide
us in building and characterizing a concrete testbed we have implemented, which
includes space, ground, user, and link segments. In particular, we show how the
testbed can accommodate some space cyber attack scenarios that have occurred in
the real world, and discuss future research directions.

</details>


### [15] [How To Mitigate And Defend Against DDoS Attacks In IoT Devices](https://arxiv.org/abs/2507.11772)
*Ifiyemi Leigha,Basak Comlekcioglu,Maria Pilar Bezanilla*

Main category: cs.CR

TL;DR: 本文分析了物联网（IoT）网络中DDoS攻击（如Mirai僵尸网络）的性质和影响，并提出针对IoT环境的分层缓解策略。


<details>
  <summary>Details</summary>
Motivation: 由于许多物联网设备的安全配置较低，DDoS攻击在IoT网络中日益普遍且危险，需要有效的解决方案。

Method: 探讨了IPv6唯一本地地址（ULA）、边缘计算、软件定义网络（SDN）、蜜罐欺骗和基于机器学习的入侵检测系统等关键解决方案。

Result: 提出了针对IoT环境的实用对策，帮助工程师和研究人员理解和实施保护措施。

Conclusion: 本文为保护IoT基础设施提供了实用的分层缓解策略，有助于应对日益严重的DDoS威胁。

Abstract: Distributed Denial of Service (DDoS) attacks have become increasingly
prevalent and dangerous in the context of Internet of Things (IoT) networks,
primarily due to the low-security configurations of many connected devices.
This paper analyzes the nature and impact of DDoS attacks such as those
launched by the Mirai botnet, and proposes layered mitigation strategies
tailored to IoT environments. Key solutions explored include IPv6 Unique Local
Addresses (ULA), edge computing, software-defined networking (SDN), honeypot
deception, and machine learning-based intrusion detection systems. The paper
aims to help engineers and researchers understand and implement practical
countermeasures to protect IoT infrastructures.

</details>


### [16] [Challenges in GenAI and Authentication: a scoping review](https://arxiv.org/abs/2507.11775)
*Wesley dos Reis Bezerra,Lais Machado Bezerra,Carlos Becker Westphall*

Main category: cs.CR

TL;DR: 本文通过范围综述分析了88篇文献，探讨了生成式AI对认证和安全性的挑战、威胁及解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的发展，数字信息的认证和真实性面临新挑战，需更新分析其对社会和系统安全的影响。

Method: 从IEEExplorer、Scopus和ACM数据库中选取88篇文献，通过六个指导性问题进行范围综述。

Result: 结果明确了图像、文本、音频和视频领域的挑战、威胁及研究空白。

Conclusion: 研究支持认证和生成式AI领域的新研究，填补了现有空白。

Abstract: Authentication and authenticity have been a security challenge since the
beginning of information sharing, especially in the context of digital
information. With the advancement of generative artificial intelligence, these
challenges have evolved, demanding a more up-to-date analysis of their impacts
on society and system security. This work presents a scoping review that
analyzed 88 documents from the IEEExplorer, Scopus, and ACM databases,
promoting an analysis of the resulting portfolio through six guiding questions
focusing on the most relevant work, challenges, attack surfaces, threats,
proposed solutions, and gaps. Finally, the portfolio articles are analyzed
through this guiding research lens and also receive individualized analysis.
The results consistently outline the challenges, gaps, and threats related to
images, text, audio, and video, thereby supporting new research in the areas of
authentication and generative artificial intelligence.

</details>


### [17] [Unveiling Usability Challenges in Web Privacy Controls](https://arxiv.org/abs/2507.11908)
*Rahat Masood,Sunday Oyinlola Ogundoyin,Muhammad Ikram,Alex Ye*

Main category: cs.CR

TL;DR: 本文通过大规模实证分析研究了18,628个网站隐私控制的可用性问题，发现隐私政策在所有访问场景中最常见，注册场景中常见提示和通知。建议通过弹出提示、目录导航和直接链接改进设计。


<details>
  <summary>Details</summary>
Motivation: 随着隐私问题日益突出和数据隐私法律的实施，网站隐私控制的可用性问题成为用户面临的挑战。缺乏标准化和技术术语增加了使用难度。

Method: 采用自动化数据收集方法，分析三种用户访问场景（访客、注册、认证用户）的隐私控制可用性，但因技术限制主要聚焦于访客场景。

Result: 隐私政策在所有场景中普遍存在，注册场景中提示和通知较多。自动化捕捉动态用户交互存在挑战。

Conclusion: 建议通过弹出提示、目录导航和直接链接设计更易用的隐私控制，以提高用户意识和选择能力。

Abstract: With the increasing concerns around privacy and the enforcement of data
privacy laws, many websites now provide users with privacy controls. However,
locating these controls can be challenging, as they are frequently hidden
within multiple settings and layers. Moreover, the lack of standardization
means these controls can vary widely across services. The technical or
confusing terminology used to describe these controls further complicates
users' ability to understand and use them effectively. This paper presents a
large-scale empirical analysis investigating usability challenges of web
privacy controls across 18,628 websites. While aiming for a multi-scenario
view, our automated data collection faced significant hurdles, particularly in
simulating sign-up and authenticated user visits, leading to more focused
insights on guest visit scenarios and challenges in automated capture of
dynamic user interactions. Our heuristic evaluation of three different user
visit scenarios identifies significant website usability issues. Our results
show that privacy policies are most common across all visit scenarios, with
nudges and notices being prevalent in sign-up situations. We recommend
designing privacy controls that: enhance awareness through pop-up nudges and
notices; offer a table of contents as navigational aids and customized settings
links in policies for more informed choice; and ensure accessibility via direct
links to privacy settings from nudges.

</details>


### [18] [Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification](https://arxiv.org/abs/2507.11943)
*Haiwei Lin,Shoko Imaizumi,Hitoshi Kiya*

Main category: cs.CR

TL;DR: 提出一种低秩适应方法，用于训练隐私保护的视觉Transformer模型，通过冻结预训练权重并注入可训练的低秩分解矩阵，减少可训练参数同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 传统低秩适应方法冻结所有层，包括patch嵌入层，限制了模型灵活性。本文旨在通过部分解冻嵌入层，提升模型性能。

Method: 在ViT的每一层注入可训练的低秩分解矩阵，同时不冻结patch嵌入层，以减少可训练参数并保持精度。

Result: 方法显著减少可训练参数，同时保持与全参数微调相近的准确率。

Conclusion: 提出的低秩适应方法在隐私保护ViT训练中高效且性能优越。

Abstract: We propose a low-rank adaptation method for training privacy-preserving
vision transformer (ViT) models that efficiently freezes pre-trained ViT model
weights. In the proposed method, trainable rank decomposition matrices are
injected into each layer of the ViT architecture, and moreover, the patch
embedding layer is not frozen, unlike in the case of the conventional low-rank
adaptation methods. The proposed method allows us not only to reduce the number
of trainable parameters but to also maintain almost the same accuracy as that
of full-time tuning.

</details>


### [19] [Expanding ML-Documentation Standards For Better Security](https://arxiv.org/abs/2507.12003)
*Cara Ellen Appel*

Main category: cs.CR

TL;DR: 本文综述了当前ML安全和文档化的现状，指出实践中安全意识和文档标准化不足，提出扩展现有文档标准以包含安全部分的改进方法。


<details>
  <summary>Details</summary>
Motivation: 由于ML实践者和组织对安全问题的低意识以及文档化的不规范，导致ML文档质量普遍较低，现有标准未被广泛采用，安全内容常被忽略。

Method: 基于现有Model Cards和Datasheets for Datasets标准，提出扩展文档标准以包含安全相关信息的改进方法。

Result: 研究发现ML文档中安全内容缺失，需改进文档标准以提升安全性。

Conclusion: 建议在ML文档中增加安全部分，以填补现有安全漏洞，提升整体文档质量。

Abstract: This article presents the current state of ML-security and of the
documentation of ML-based systems, models and datasets in research and practice
based on an extensive review of the existing literature. It shows a generally
low awareness of security aspects among ML-practitioners and organizations and
an often unstandardized approach to documentation, leading to overall low
quality of ML-documentation. Existing standards are not regularly adopted in
practice and IT-security aspects are often not included in documentation. Due
to these factors, there is a clear need for improved security documentation in
ML, as one step towards addressing the existing gaps in ML-security. To achieve
this, we propose expanding existing documentation standards for
ML-documentation to include a security section with specific security relevant
information. Implementing this, a novel expanded method of documenting security
requirements in ML-documentation is presented, based on the existing Model
Cards and Datasheets for Datasets standards, but with the recommendation to
adopt these findings in all ML-documentation.

</details>


### [20] [IDFace: Face Template Protection for Efficient and Secure Identification](https://arxiv.org/abs/2507.12050)
*Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Dongsoo Kim,Junbum Shin,Jae Hong Seo*

Main category: cs.CR

TL;DR: IDFace是一种基于同态加密的高效安全人脸识别方法，显著提升了加密模板匹配的效率。


<details>
  <summary>Details</summary>
Motivation: 随着人脸识别系统的广泛应用，用户隐私保护变得尤为重要，尤其是防止从模板中恢复人脸图像特征。

Method: IDFace采用两种新技术：模板表示转换降低匹配测试成本，空间高效编码减少加密算法的空间浪费。

Result: 实验表明，IDFace能在126毫秒内从100万个加密模板中识别出人脸模板，仅比明文识别慢2倍。

Conclusion: IDFace在保护隐私的同时，显著提升了加密人脸识别的效率，为实际应用提供了可行性。

Abstract: As face recognition systems (FRS) become more widely used, user privacy
becomes more important. A key privacy issue in FRS is protecting the user's
face template, as the characteristics of the user's face image can be recovered
from the template. Although recent advances in cryptographic tools such as
homomorphic encryption (HE) have provided opportunities for securing the FRS,
HE cannot be used directly with FRS in an efficient plug-and-play manner. In
particular, although HE is functionally complete for arbitrary programs, it is
basically designed for algebraic operations on encrypted data of predetermined
shape, such as a polynomial ring. Thus, a non-tailored combination of HE and
the system can yield very inefficient performance, and many previous HE-based
face template protection methods are hundreds of times slower than plain
systems without protection. In this study, we propose IDFace, a new HE-based
secure and efficient face identification method with template protection.
IDFace is designed on the basis of two novel techniques for efficient searching
on a (homomorphically encrypted) biometric database with an angular metric. The
first technique is a template representation transformation that sharply
reduces the unit cost for the matching test. The second is a space-efficient
encoding that reduces wasted space from the encryption algorithm, thus saving
the number of operations on encrypted templates. Through experiments, we show
that IDFace can identify a face template from among a database of 1M encrypted
templates in 126ms, showing only 2X overhead compared to the identification
over plaintexts.

</details>


### [21] [Toward an Intent-Based and Ontology-Driven Autonomic Security Response in Security Orchestration Automation and Response](https://arxiv.org/abs/2507.12061)
*Zequan Huang,Jacques Robin,Nicolas Herbaut,Nourhène Ben Rabah,Bénédicte Le Grand*

Main category: cs.CR

TL;DR: 本文提出了一种基于MITRE-D3FEND网络安全本体的统一安全意图定义方法，并将其集成到自主网络安全防御系统中，以提升SOAR平台的灵活性和自动化响应能力。


<details>
  <summary>Details</summary>
Motivation: 现代SOAR平台需要快速适应不断演变的网络攻击，而基于意图的网络防御和自主网络防御是两个活跃的研究方向，但二者之间存在差距。

Method: 提出了一种基于本体的安全意图定义方法，并设计了一个两层级的方法论，将安全意图集成到决策理论的自主网络防御系统中。

Result: 通过具体用例展示了该方法的实用性，验证了其在下一代SOAR平台中的集成能力。

Conclusion: 该方法为SOAR平台提供了更灵活、持久的自动化响应能力，填补了意图防御与自主防御之间的研究空白。

Abstract: Modern Security Orchestration, Automation, and Response (SOAR) platforms must
rapidly adapt to continuously evolving cyber attacks. Intent-Based Networking
has emerged as a promising paradigm for cyber attack mitigation through
high-level declarative intents, which offer greater flexibility and persistency
than procedural actions. In this paper, we bridge the gap between two active
research directions: Intent-Based Cyber Defense and Autonomic Cyber Defense, by
proposing a unified, ontology-driven security intent definition leveraging the
MITRE-D3FEND cybersecurity ontology. We also propose a general two-tiered
methodology for integrating such security intents into decision-theoretic
Autonomic Cyber Defense systems, enabling hierarchical and context-aware
automated response capabilities. The practicality of our approach is
demonstrated through a concrete use case, showcasing its integration within
next-generation Security Orchestration, Automation, and Response platforms.

</details>


### [22] [A Privacy-Preserving Framework for Advertising Personalization Incorporating Federated Learning and Differential Privacy](https://arxiv.org/abs/2507.12098)
*Xiang Li,Yifan Lin,Yuanzhe Zhang*

Main category: cs.CR

TL;DR: 提出一个结合联邦学习和差分隐私的框架，解决个性化广告中的隐私泄露和性能问题，实现模型精度、通信开销和隐私保护的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决个性化广告中的隐私泄露和性能问题，同时保护用户隐私。

Method: 结合联邦学习和差分隐私，采用分布式特征提取、动态隐私预算分配和鲁棒模型聚合，并引入多方安全计算和异常检测机制。

Result: 实验表明，该框架在保证隐私的同时，实现了推荐精度和系统效率的双重优化。

Conclusion: 为广告推荐中的隐私保护技术提供了实用解决方案和理论基础。

Abstract: To mitigate privacy leakage and performance issues in personalized
advertising, this paper proposes a framework that integrates federated learning
and differential privacy. The system combines distributed feature extraction,
dynamic privacy budget allocation, and robust model aggregation to balance
model accuracy, communication overhead, and privacy protection. Multi-party
secure computing and anomaly detection mechanisms further enhance system
resilience against malicious attacks. Experimental results demonstrate that the
framework achieves dual optimization of recommendation accuracy and system
efficiency while ensuring privacy, providing both a practical solution and a
theoretical foundation for applying privacy protection technologies in
advertisement recommendation.

</details>


### [23] [Exploiting Jailbreaking Vulnerabilities in Generative AI to Bypass Ethical Safeguards for Facilitating Phishing Attacks](https://arxiv.org/abs/2507.12185)
*Rina Mishra,Gaurav Varshney*

Main category: cs.CR

TL;DR: 研究探讨了生成式AI（如DeepSeek和ChatGPT）如何被利用绕过伦理限制，用于生成钓鱼内容、推荐黑客工具及策划钓鱼攻击，揭示了其安全威胁。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的普及带来了新的网络安全风险，尤其是通过越狱技术绕过伦理防护，本研究旨在揭示这些风险并提出应对策略。

Method: 使用ChatGPT 4o Mini进行实验，模拟新手用户利用AI辅助执行钓鱼攻击，并分析其绕过传统防护的能力。

Result: 实验表明，AI辅助的钓鱼攻击能成功规避传统反钓鱼机制，且攻击形式多样（如邮件、短信、语音）。

Conclusion: 研究提出需结合用户教育、高级认证机制和监管政策来应对AI辅助钓鱼攻击，并指出未来研究方向。

Abstract: The advent of advanced Generative AI (GenAI) models such as DeepSeek and
ChatGPT has significantly reshaped the cybersecurity landscape, introducing
both promising opportunities and critical risks. This study investigates how
GenAI powered chatbot services can be exploited via jailbreaking techniques to
bypass ethical safeguards, enabling the generation of phishing content,
recommendation of hacking tools, and orchestration of phishing campaigns. In
ethically controlled experiments, we used ChatGPT 4o Mini selected for its
accessibility and status as the latest publicly available model at the time of
experimentation, as a representative GenAI system. Our findings reveal that the
model could successfully guide novice users in executing phishing attacks
across various vectors, including web, email, SMS (smishing), and voice
(vishing). Unlike automated phishing campaigns that typically follow detectable
patterns, these human-guided, AI assisted attacks are capable of evading
traditional anti phishing mechanisms, thereby posing a growing security threat.
We focused on DeepSeek and ChatGPT due to their widespread adoption and
technical relevance in 2025. The study further examines common jailbreaking
techniques and the specific vulnerabilities exploited in these models. Finally,
we evaluate a range of mitigation strategies such as user education, advanced
authentication mechanisms, and regulatory policy measures and discuss emerging
trends in GenAI facilitated phishing, outlining future research directions to
strengthen cybersecurity defenses in the age of artificial intelligence.

</details>


### [24] [Efficient Control Flow Attestation by Speculating on Control Flow Path Representations](https://arxiv.org/abs/2507.12345)
*Liam Tyler,Adam Caulfield,Ivan De Oliveira Nunes*

Main category: cs.CR

TL;DR: RESPEC-CFA提出了一种新的控制流认证方法，通过优化控制流日志的存储和传输成本，显著减少了日志大小。


<details>
  <summary>Details</summary>
Motivation: 现有控制流认证（CFA）方法因控制流日志（CFlog）的存储和传输成本高而受限，且未充分利用地址表示进行推测优化。

Method: RESPEC-CFA通过推测控制流的局部性和Huffman编码，优化CFlog的表示。

Result: 单独使用RESPEC-CFA可减少CFlog大小达90.1%，结合现有方法可达99.7%。

Conclusion: RESPEC-CFA是迈向实用化CFA的重要进展。

Abstract: Control Flow Attestation (CFA) allows remote verification of run-time
software integrity in embedded systems. However, CFA is limited by the
storage/transmission costs of generated control flow logs (CFlog). Recent work
has proposed application-specific optimizations by speculating on likely
sub-paths in CFlog and replacing them with reserved symbols at runtime. Albeit
effective, prior approaches do not consider the representation of addresses in
a control flow path for speculation. This work proposes RESPEC-CFA, an
architectural extension for CFA allowing for speculation on (1) the locality of
control flows and (2) their Huffman encoding. Alone, RESPEC-CFA reduces CFlog
sizes by up to 90.1%. Combined with prior methods, RESPEC-CFA yields reductions
of up to 99.7%, representing a significant step toward practical CFA.

</details>


### [25] [Rethinking the confidential cloud through a unified low-level abstraction for composable isolation](https://arxiv.org/abs/2507.12364)
*Adrien Ghosn,Charly Castes,Neelu S. Kalani,Yuchen Qian,Marios Kogias,Edouard Bugnion*

Main category: cs.CR

TL;DR: Tyche提出了一种统一的隔离模型，通过信任域（TDs）简化了云工作负载的安全管理，减少了硬件和软件的复杂性。


<details>
  <summary>Details</summary>
Motivation: 当前云工作负载的安全隔离机制复杂且碎片化，增加了可信计算基（TCB）的负担，导致端到端认证困难。

Method: Tyche通过一个可信的安全监视器提供可组合、可认证的隔离，支持递归创建和管理子信任域（TDs）。

Result: Tyche在x86_64上运行，无需硬件安全扩展，且兼容现有软件，性能接近原生Linux。

Conclusion: Tyche为构建可组合的隔离环境提供了统一解决方案，适用于复杂的云场景，并展示了跨平台的可移植性。

Abstract: Securing sensitive cloud workloads requires composing confidential virtual
machines (CVMs) with nested enclaves or sandboxes. Unfortunately, each new
isolation boundary adds ad-hoc access control mechanisms, hardware extensions,
and trusted software. This escalating complexity bloats the TCB, complicates
end-to-end attestation, and leads to fragmentation across platforms and cloud
service providers (CSPs).
  We introduce a unified isolation model that delegates enforceable,
composable, and attestable isolation to a single trusted security monitor:
Tyche. Tyche provides an API for partitioning, sharing, attesting, and
reclaiming resources through its core abstraction, trust domains (TDs). To
provide fine-grain isolation, TDs can recursively create and manage sub-TDs.
Tyche captures these relationships in attestations, allowing cloud tenants to
reason about end-to-end security. TDs serve as the building blocks for
constructing composable enclaves, sandboxes, and CVMs.
  Tyche runs on commodity x86_64 without hardware security extensions and can
maintain backward compatibility with existing software. We provide an SDK to
run and compose unmodified workloads as sandboxes, enclaves, and CVMs with
minimal overhead compared to native Linux execution. Tyche supports complex
cloud scenarios, such as confidential inference with mutually distrustful
users, model owners, and CSPs. An additional RISC-V prototype demonstrates
Tyche's portability across platforms.

</details>


### [26] [On One-Shot Signatures, Quantum vs Classical Binding, and Obfuscating Permutations](https://arxiv.org/abs/2507.12456)
*Omri Shmueli,Mark Zhandry*

Main category: cs.CR

TL;DR: 本文首次在标准模型中构建了一次性签名（OSS），基于（亚指数）不可区分混淆（iO）和LWE假设，解决了经典与量子绑定承诺/哈希的分离问题。


<details>
  <summary>Details</summary>
Motivation: 一次性签名（OSS）在量子密钥下可能实现，但之前仅存在经典预言机模型中的构造且存在漏洞。本文旨在填补这一空白。

Method: 提出可置换伪随机置换（permutable PRPs）概念，并通过混淆技术将其转化为标准模型中的构造。

Result: 成功构建标准模型中的OSS，并解决了经典与量子绑定承诺/哈希的分离问题。

Conclusion: 本文不仅解决了OSS的存在性问题，还推动了相关领域的技术发展。

Abstract: One-shot signatures (OSS) were defined by Amos, Georgiou, Kiayias, and
Zhandry (STOC'20). These allow for signing exactly one message, after which the
signing key self-destructs, preventing a second message from ever being signed.
While such an object is impossible classically, Amos et al observe that OSS may
be possible using quantum signing keys by leveraging the no-cloning principle.
OSS has since become an important conceptual tool with many applications in
decentralized settings and for quantum cryptography with classical
communication. OSS are also closely related to separations between
classical-binding and collapse-binding for post-quantum hashing and
commitments. Unfortunately, the only known OSS construction due to Amos et al.
was only justified in a classical oracle model, and moreover their
justification was ultimately found to contain a fatal bug. Thus, the existence
of OSS, even in a classical idealized model, has remained open.
  We give the first standard-model OSS, with provable security assuming
(sub-exponential) indistinguishability obfuscation (iO) and LWE. This also
gives the first standard-model separation between classical and
collapse-binding post-quantum commitments/hashing, solving a decade-old open
problem. Along the way, we also give the first construction with unconditional
security relative to a classical oracle. To achieve our standard-model
construction, we develop a notion of permutable pseudorandom permutations
(permutable PRPs), and show how they are useful for translating oracle proofs
involving random permutations into obfuscation-based proofs. In particular,
obfuscating permutable PRPs gives a trapdoor one-way permutation that is
\emph{full-domain}, solving another decade-old-problem of constructing this
object from (sub-exponential) iO and one-way functions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [27] [A Study on the Application of Artificial Intelligence in Ecological Design](https://arxiv.org/abs/2507.11595)
*Hengyue Zhao*

Main category: cs.AI

TL;DR: 探讨AI如何促进人类与自然的共生关系，通过案例研究展示AI在生态设计中的应用及其潜力。


<details>
  <summary>Details</summary>
Motivation: 研究人类与自然关系从主导到共生的转变，以及AI在此过程中的中介作用。

Method: 通过案例研究分析AI在数据、图像识别和生态修复中的应用，并结合原型设计（AI辅助水体修复）提出新方法。

Result: AI不仅扩展了创意方法，还重构了生态设计的理论与实践，展示了其在科学、艺术和环保中的桥梁作用。

Conclusion: AI为可持续技术生态系统提供了研究路径，未来可进一步探索其潜力。

Abstract: This paper asks whether our relationship with nature can move from human
dominance to genuine interdependence, and whether artificial intelligence (AI)
can mediate that shift. We examine a new ecological-design paradigm in which AI
interacts with non-human life forms. Through case studies we show how artists
and designers apply AI for data analysis, image recognition, and ecological
restoration, producing results that differ from conventional media. We argue
that AI not only expands creative methods but also reframes the theory and
practice of ecological design. Building on the author's prototype for
AI-assisted water remediation, the study proposes design pathways that couple
reinforcement learning with plant-based phytoremediation. The findings
highlight AI's potential to link scientific insight, artistic practice, and
environmental stewardship, offering a roadmap for future research on
sustainable, technology-enabled ecosystems.

</details>


### [28] [General Modular Harness for LLM Agents in Multi-Turn Gaming Environments](https://arxiv.org/abs/2507.11633)
*Yuxuan Zhang,Haoyang Yu,Lanxiang Hu,Haojian Jin,Hao Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种模块化设计的LLM代理框架，包含感知、记忆和推理组件，适用于多种游戏环境，无需领域特定工程。


<details>
  <summary>Details</summary>
Motivation: 通过游戏环境测试通用代理的性能，探索模块化设计在不同交互场景中的作用。

Method: 采用模块化设计（感知、记忆、推理），使用经典和现代游戏套件作为测试平台。

Result: 实验表明该框架显著提升游戏性能，不同模块在不同场景中作用各异（如记忆在长时任务中关键，感知在视觉噪声环境中重要）。

Conclusion: 模块化设计有效提升通用代理性能，游戏环境为研究提供了理想测试平台。

Abstract: We introduce a modular harness design for LLM agents that composes of
perception, memory, and reasoning components, enabling a single LLM or VLM
backbone to tackle a wide spectrum of multi turn gaming environments without
domain-specific engineering. Using classic and modern game suites as
low-barrier, high-diversity testbeds, our framework provides a unified workflow
for analyzing how each module affects performance across dynamic interactive
settings. Extensive experiments demonstrate that the harness lifts gameplay
performance consistently over un-harnessed baselines and reveals distinct
contribution patterns, for example, memory dominates in long-horizon puzzles
while perception is critical in vision noisy arcades. These findings highlight
the effectiveness of our modular harness design in advancing general-purpose
agent, given the familiarity and ubiquity of games in everyday human
experience.

</details>


### [29] [Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification](https://arxiv.org/abs/2507.11662)
*Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira*

Main category: cs.AI

TL;DR: MLLMs作为验证器存在‘同意偏见’，倾向于支持其上下文窗口中的信息，导致对错误行为的合理化。提出的自接地验证（SGV）方法通过无条件与条件生成，显著提升了验证准确性和任务完成率。


<details>
  <summary>Details</summary>
Motivation: 在缺乏明确成功标准的领域（如计算机使用）扩展AI验证器的应用，利用MLLMs的世界知识、人类偏好对齐和推理能力。

Method: 提出自接地验证（SGV），分两步：首先提取任务完成的广泛先验，然后基于这些先验评估候选轨迹。

Result: SGV使MLLM验证器在准确性和失败检测率上提升高达20点，并在多个任务中实现实时监督，任务完成率显著提升。

Conclusion: SGV方法有效解决了MLLMs的同意偏见问题，显著提升了其在复杂任务中的验证能力。

Abstract: Verifiers -- functions assigning rewards to agent behavior -- have been key
for AI progress in domains like math and board games. However, extending these
gains to domains without clear-cut success criteria (e.g.,computer use) remains
a challenge: while humans can recognize suitable outcomes, translating this
intuition into scalable rules is non-trivial. Multimodal Large Language
Models(MLLMs) emerge as a promising solution, given their world knowledge,
human-preference alignment, and reasoning skills. We evaluate MLLMs as
verifiers of agent trajectories across web navigation, computer use, and
robotic manipulation, and identify a critical limitation: agreement bias, a
strong tendency for MLLMs to favor information in their context window, often
generating chains of thought to rationalize flawed behavior. This bias is
pervasive across models, resilient to test-time scaling, and can impact several
methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs
despite MLLMs showing strong, human-aligned priors on desired behavior. To
address this, we propose Self-Grounded Verification (SGV), a lightweight method
that enables more effective use of MLLMs' knowledge and reasoning by harnessing
their own sampling mechanisms via unconditional and conditional generation. SGV
operates in two steps: first, the MLLM is elicited to retrieve broad priors
about task completion, independent of the data under evaluation. Then,
conditioned on self-generated priors, it reasons over and evaluates a candidate
trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in
accuracy and failure detection rates, and can perform real-time supervision of
heterogeneous agents, boosting task completion of a GUI specialist in OSWorld,
a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting
a new state of the art on the benchmark, surpassing the previous best by 48%.

</details>


### [30] [ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making](https://arxiv.org/abs/2507.11733)
*Srikanth Vemula*

Main category: cs.AI

TL;DR: ClarifAI结合案例推理和本体驱动方法，提升AI透明度和可解释性，适用于高风险的决策场景。


<details>
  <summary>Details</summary>
Motivation: 满足AI应用中各利益相关者对解释性的复杂需求，提升AI系统的透明度和可信度。

Method: 结合案例推理（CBR）和本体驱动方法，设计理论框架和架构蓝图。

Result: ClarifAI能显著提升AI系统的可解释性，适用于多领域和高风险环境。

Conclusion: ClarifAI为AI系统的解释性提供了新方法，有望推动关键决策中的应用。

Abstract: This Study introduces Clarity and Reasoning Interface for Artificial
Intelligence(ClarifAI), a novel approach designed to augment the transparency
and interpretability of artificial intelligence (AI) in the realm of improved
decision making. Leveraging the Case-Based Reasoning (CBR) methodology and
integrating an ontology-driven approach, ClarifAI aims to meet the intricate
explanatory demands of various stakeholders involved in AI-powered
applications. The paper elaborates on ClarifAI's theoretical foundations,
combining CBR and ontologies to furnish exhaustive explanation mechanisms. It
further elaborates on the design principles and architectural blueprint,
highlighting ClarifAI's potential to enhance AI interpretability across
different sectors and its applicability in high-stake environments. This
research delineates the significant role of ClariAI in advancing the
interpretability of AI systems, paving the way for its deployment in critical
decision-making processes.

</details>


### [31] [Auto-Formulating Dynamic Programming Problems with Large Language Models](https://arxiv.org/abs/2507.11737)
*Chenyu Zhou,Jingyuan Yang,Linwei Xin,Yitian Chen,Ziyan He,Dongdong Ge*

Main category: cs.AI

TL;DR: 论文提出DP-Bench基准和DPLM模型，通过DualReflect数据生成方法解决动态规划问题中LLM应用的挑战。


<details>
  <summary>Details</summary>
Motivation: 动态规划（DP）建模通常需要专业知识，LLMs有潜力自动化这一过程，但面临数据稀缺和随机性挑战。

Method: 引入DP-Bench基准和7B参数的DPLM模型，采用DualReflect合成数据生成方法（结合前向和后向生成）。

Result: DPLM性能媲美主流LLMs，在难题上表现更优；后向生成在低数据时更可靠，前向生成在规模扩大时增加多样性。

Conclusion: 结合前向和后向生成的DualReflect方法有效解决了DP问题的数据挑战，DPLM模型展示了优越性能。

Abstract: Dynamic programming (DP) is a fundamental method in operations research, but
formulating DP models has traditionally required expert knowledge of both the
problem context and DP techniques. Large Language Models (LLMs) offer the
potential to automate this process. However, DP problems pose unique challenges
due to their inherently stochastic transitions and the limited availability of
training data. These factors make it difficult to directly apply existing
LLM-based models or frameworks developed for other optimization problems, such
as linear or integer programming. We introduce DP-Bench, the first benchmark
covering a wide range of textbook-level DP problems to enable systematic
evaluation. We present Dynamic Programming Language Model (DPLM), a
7B-parameter specialized model that achieves performance comparable to
state-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on
hard problems. Central to DPLM's effectiveness is DualReflect, our novel
synthetic data generation pipeline, designed to scale up training data from a
limited set of initial examples. DualReflect combines forward generation for
diversity and backward generation for reliability. Our results reveal a key
insight: backward generation is favored in low-data regimes for its strong
correctness guarantees, while forward generation, though lacking such
guarantees, becomes increasingly valuable at scale for introducing diverse
formulations. This trade-off highlights the complementary strengths of both
approaches and the importance of combining them.

</details>


### [32] [Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11787)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.AI

TL;DR: 本文综述了基于群体智能算法的语义相似性文档搜索的最新进展，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 群体智能（SI）因其高效性被广泛应用于解决计算机优化问题，本文旨在探索其在语义相似性文档搜索中的应用。

Method: 通过观察动物和昆虫的自然行为，将其转化为群体计算算法，用于解决实际问题。

Result: 综述了群体智能在语义相似性文档搜索中的最新应用和发展。

Conclusion: 群体智能在语义相似性文档搜索中具有潜力，未来研究应进一步探索其优化和改进方向。

Abstract: Swarm Intelligence (SI) is gaining a lot of popularity in artificial
intelligence, where the natural behavior of animals and insects is observed and
translated into computer algorithms called swarm computing to solve real-world
problems. Due to their effectiveness, they are applied in solving various
computer optimization problems. This survey will review all the latest
developments in Searching for documents based on semantic similarity using
Swarm Intelligence algorithms and recommend future research directions.

</details>


### [33] [A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS](https://arxiv.org/abs/2507.11916)
*Ehsan Futuhi,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 论文提出了一种利用GPU并行计算优化深度优先搜索（DFS）的方法，包括成本受限的DFS（CB-DFS），并扩展了IDA*和BTS算法。实验验证了其在3x3魔方和4x4滑块拼图中的高效性。


<details>
  <summary>Details</summary>
Motivation: GPU技术的快速发展为经典搜索算法的优化提供了新机会，但目前很少有算法在设计时充分利用GPU的并行计算能力。

Method: 提出了一种成本受限的深度优先搜索（CB-DFS）方法，结合CPU和GPU的并行计算能力，扩展了IDA*和BTS算法。

Result: 在3x3魔方和4x4滑块拼图上的实验表明，GPU操作可以高效地批量处理，且保持了最优性保证。

Conclusion: 通过结合GPU和CPU的并行计算，深度优先搜索的性能得到了显著提升，为未来搜索算法的优化提供了新方向。

Abstract: The rapid advancement of GPU technology has unlocked powerful parallel
processing capabilities, creating new opportunities to enhance classic search
algorithms. A recent successful application of GPUs is in compressing large
pattern database (PDB) heuristics using neural networks while preserving
heuristic admissibility. However, very few algorithms have been designed to
exploit GPUs during search. Several variants of A* exist that batch GPU
computations. In this paper we introduce a method for batching GPU computations
in depth first search. In particular, we describe a new cost-bounded
depth-first search (CB-DFS) method that leverages the combined parallelism of
modern CPUs and GPUs. This is used to create algorithms like \emph{Batch IDA*},
an extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an
extensions of Budgeted Tree Search. Our approach builds on the general approach
used by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality
guarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding
tile puzzle (STP), showing that GPU operations can be efficiently batched in
DFS. Additionally, we conduct extensive experiments to analyze the effects of
hyperparameters, neural network heuristic size, and hardware resources on
performance.

</details>


### [34] [Aime: Towards Fully-Autonomous Multi-Agent Framework](https://arxiv.org/abs/2507.11988)
*Yexuan Shi,Mingyu Wang,Yunxiang Cao,Hongjie Lai,Junjian Lan,Xin Han,Yu Wang,Jie Geng,Zhenan Li,Zihao Xia,Xiang Chen,Chen Li,Jian Xu,Wenbo Duan,Yuanshuo Zhu*

Main category: cs.AI

TL;DR: Aime是一个新型多智能体框架，通过动态反应式规划和执行解决传统框架的局限性，显著提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体系统的规划和执行框架存在刚性、静态能力和低效通信等问题，限制了其在动态环境中的适应性和鲁棒性。

Method: Aime采用动态规划器、动态参与者工厂和集中式进度管理模块，实现实时策略调整、按需创建智能体和全局状态感知。

Result: 在多种基准测试中，Aime表现优于现有最先进的智能体，展示了更高的适应性和任务成功率。

Conclusion: Aime为多智能体协作提供了更灵活、高效和可靠的基础。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are
emerging as a powerful paradigm for solving complex, multifaceted problems.
However, the potential of these systems is often constrained by the prevalent
plan-and-execute framework, which suffers from critical limitations: rigid plan
execution, static agent capabilities, and inefficient communication. These
weaknesses hinder their adaptability and robustness in dynamic environments.
This paper introduces Aime, a novel multi-agent framework designed to overcome
these challenges through dynamic, reactive planning and execution. Aime
replaces the conventional static workflow with a fluid and adaptive
architecture. Its core innovations include: (1) a Dynamic Planner that
continuously refines the overall strategy based on real-time execution
feedback; (2) an Actor Factory that implements Dynamic Actor instantiation,
assembling specialized agents on-demand with tailored tools and knowledge; and
(3) a centralized Progress Management Module that serves as a single source of
truth for coherent, system-wide state awareness. We empirically evaluated Aime
on a diverse suite of benchmarks spanning general reasoning (GAIA), software
engineering (SWE-bench Verified), and live web navigation (WebVoyager). The
results demonstrate that Aime consistently outperforms even highly specialized
state-of-the-art agents in their respective domains. Its superior adaptability
and task success rate establish Aime as a more resilient and effective
foundation for multi-agent collaboration.

</details>


### [35] [Understanding visual attention beehind bee-inspired UAV navigation](https://arxiv.org/abs/2507.11992)
*Pranav Rajbhandari,Abhi Veda,Matthew Garratt,Mandayam Srinivasan,Sridhar Ravi*

Main category: cs.AI

TL;DR: 论文提出了一种基于光流感知的强化学习无人机导航方法，模仿蜜蜂行为，通过关注光流的不连续性和大光流区域实现避障。


<details>
  <summary>Details</summary>
Motivation: 生物系统（如蜜蜂）在有限感官和计算能力下仍能高效飞行和避障，这启发了无人机导航的研究。

Method: 使用强化学习训练无人机在隧道中导航，仅依赖光流作为感官输入，并分析其注意力模式。

Result: 训练后的无人机主要关注光流不连续性和大光流区域，行为类似昆虫飞行，且在不同训练个体中表现一致。

Conclusion: 该方法为物理无人机提供了一种简单有效的控制策略，具有潜在应用价值。

Abstract: Bio-inspired design is often used in autonomous UAV navigation due to the
capacity of biological systems for flight and obstacle avoidance despite
limited sensory and computational capabilities. In particular, honeybees mainly
use the sensory input of optic flow, the apparent motion of objects in their
visual field, to navigate cluttered environments. In our work, we train a
Reinforcement Learning agent to navigate a tunnel with obstacles using only
optic flow as sensory input. We inspect the attention patterns of trained
agents to determine the regions of optic flow on which they primarily base
their motor decisions. We find that agents trained in this way pay most
attention to regions of discontinuity in optic flow, as well as regions with
large optic flow magnitude. The trained agents appear to navigate a cluttered
tunnel by avoiding the obstacles that produce large optic flow, while
maintaining a centered position in their environment, which resembles the
behavior seen in flying insects. This pattern persists across independently
trained agents, which suggests that this could be a good strategy for
developing a simple explicit control law for physical UAVs.

</details>


### [36] [Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs](https://arxiv.org/abs/2507.12110)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种拓扑增强的多智能体强化学习方法（TPE-MARL），用于优化混合交通中联网自动驾驶车辆（CAVs）的协同决策，通过压缩高维状态信息和减少搜索空间，显著提升了探索与利用的平衡。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）中探索与利用的权衡问题因联合状态-动作空间的指数增长而加剧，尤其在混合交通场景中更为复杂。本文旨在解决这一问题。

Method: 构建动态交通流的游戏拓扑张量以压缩高维状态信息，并基于QMIX算法设计拓扑增强的MARL框架，结合访问计数和智能体互信息。

Result: 在不同交通密度和CAV渗透率下，TPE-MARL在交通效率、安全性、决策平滑性和任务完成度方面表现优异，且决策合理性接近或超过人类驾驶员。

Conclusion: TPE-MARL有效平衡了探索与利用，显著提升了混合交通中CAVs的协同决策性能，适用于混合和完全自动驾驶场景。

Abstract: The exploration-exploitation trade-off constitutes one of the fundamental
challenges in reinforcement learning (RL), which is exacerbated in multi-agent
reinforcement learning (MARL) due to the exponential growth of joint
state-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)
method for optimizing cooperative decision-making of connected and autonomous
vehicles (CAVs) in mixed traffic. This work presents two primary contributions:
First, we construct a game topology tensor for dynamic traffic flow,
effectively compressing high-dimensional traffic state information and decrease
the search space for MARL algorithms. Second, building upon the designed game
topology tensor and using QMIX as the backbone RL algorithm, we establish a
topology-enhanced MARL framework incorporating visit counts and agent mutual
information. Extensive simulations across varying traffic densities and CAV
penetration rates demonstrate the effectiveness of TPE-MARL. Evaluations
encompassing training dynamics, exploration patterns, macroscopic traffic
performance metrics, and microscopic vehicle behaviors reveal that TPE-MARL
successfully balances exploration and exploitation. Consequently, it exhibits
superior performance in terms of traffic efficiency, safety, decision
smoothness, and task completion. Furthermore, the algorithm demonstrates
decision-making rationality comparable to or exceeding that of human drivers in
both mixed-autonomy and fully autonomous traffic scenarios. Code of our work is
available at
\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.

</details>


### [37] [Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation](https://arxiv.org/abs/2507.12186)
*Edward Kim,Hanna Kurniawati*

Main category: cs.AI

TL;DR: 提出了一种新的在线POMDP求解器，通过深度采样未来历史并逐步更新策略，性能损失由采样误差的平均值而非最大值决定。


<details>
  <summary>Details</summary>
Motivation: 解决在线规划中采样稀疏性问题，提升动态环境下的决策性能。

Method: 采用部分可观测参考策略编程，深度采样未来历史并强制逐步策略更新。

Result: 在大规模动态环境问题（如直升机紧急场景）中表现优于现有在线基准。

Conclusion: 该方法在理论和实践中均表现出色，适用于复杂动态环境。

Abstract: This paper proposes Partially Observable Reference Policy Programming, a
novel anytime online approximate POMDP solver which samples meaningful future
histories very deeply while simultaneously forcing a gradual policy update. We
provide theoretical guarantees for the algorithm's underlying scheme which say
that the performance loss is bounded by the average of the sampling
approximation errors rather than the usual maximum, a crucial requirement given
the sampling sparsity of online planning. Empirical evaluations on two
large-scale problems with dynamically evolving environments -- including a
helicopter emergency scenario in the Corsica region requiring approximately 150
planning steps -- corroborate the theoretical results and indicate that our
solver considerably outperforms current online benchmarks.

</details>


### [38] [BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution](https://arxiv.org/abs/2507.12207)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: BuildEvo利用大型语言模型（LLMs）自动设计高效且可解释的建筑能耗预测启发式方法，结合物理原理和数据，实现高性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统启发式方法精度不足，而高级模型缺乏透明性和泛化能力，忽视物理原理。

Method: BuildEvo通过进化过程引导LLMs构建和优化启发式方法，结合建筑特性和操作数据的物理洞察。

Result: 在基准测试中表现优异，提供更好的泛化能力和透明预测逻辑。

Conclusion: BuildEvo推动了自动化设计鲁棒、基于物理的启发式方法，为复杂能源系统提供可信模型。

Abstract: Accurate building energy forecasting is essential, yet traditional heuristics
often lack precision, while advanced models can be opaque and struggle with
generalization by neglecting physical principles. This paper introduces
BuildEvo, a novel framework that uses Large Language Models (LLMs) to
automatically design effective and interpretable energy prediction heuristics.
Within an evolutionary process, BuildEvo guides LLMs to construct and enhance
heuristics by systematically incorporating physical insights from building
characteristics and operational data (e.g., from the Building Data Genome
Project 2). Evaluations show BuildEvo achieves state-of-the-art performance on
benchmarks, offering improved generalization and transparent prediction logic.
This work advances the automated design of robust, physically grounded
heuristics, promoting trustworthy models for complex energy systems.

</details>


### [39] [Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning](https://arxiv.org/abs/2507.12215)
*Yuhao Chen,Shuochen Liu,Yuanjie Lyu,Chao Zhang,Jiayao Shi,Tong Xu*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLM）在空间战略推理（如中国象棋）中的表现不足，并提出了一种针对中国象棋的训练框架Xiangqi-R1，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 中国象棋因其复杂规则和空间复杂性成为评估LLM空间战略推理能力的理想测试平台，填补了LLM在此领域的研究空白。

Method: 提出三阶段训练框架：1）微调以预测合法走法；2）引入战略注释优化决策；3）通过GRPO强化学习提升推理稳定性。

Result: Xiangqi-R1相比通用LLM，合法走法预测提升18%，分析准确率提高22%。

Conclusion: 研究为在空间复杂领域开发通用战略智能提供了可行路径。

Abstract: Game playing has long served as a fundamental benchmark for evaluating
Artificial General Intelligence (AGI). While Large Language Models (LLMs) have
demonstrated impressive capabilities in general reasoning, their effectiveness
in spatial strategic reasoning, which is critical for complex and fully
observable board games, remains insufficiently explored. In this work, we adopt
Chinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate
rules and spatial complexity. To advance LLMs' strategic competence in such
environments, we propose a training framework tailored to Xiangqi, built upon a
large-scale dataset of five million board-move pairs enhanced with expert
annotations and engine evaluations. Building on this foundation, we introduce
Xiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning
for legal move prediction to capture basic spatial rules, (2) incorporating
strategic annotations to improve decision-making, and (3) applying
reinforcement learning via Group Relative Policy Optimization (GRPO) with
multi-dimensional reward signals to enhance reasoning stability. Our
Experimental results indicate that, despite their size and power,
general-purpose LLMs struggle to achieve satisfactory performance in these
tasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an
18% rise in move legality and a 22% boost in analysis accuracy. Our results
point to a promising path for creating general strategic intelligence in
spatially complex areas.

</details>
