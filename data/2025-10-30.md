<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 19]
- [cs.CR](#cs.CR) [Total: 15]
- [cs.AI](#cs.AI) [Total: 28]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Beyond Function-Level Search: Repository-Aware Dual-Encoder Code Retrieval with Adversarial Verification](https://arxiv.org/abs/2510.24749)
*Aofan Liu,Shiyuan Song,Haoxuan Li,Cehao Yang,Yiyan Qi*

Main category: cs.SE

TL;DR: 提出了RepoAlign-Bench基准测试和ReflectCode模型，用于解决代码库级别的代码检索问题，在变更请求驱动场景下显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 现代代码库日益复杂，需要能够理解跨组件变更意图的检索系统，而传统的函数级搜索范式缺乏这种能力。

Method: 提出ReflectCode模型，采用对抗反射增强的双塔架构，包含解耦的代码编码器和文档编码器组件，通过大语言模型引导的反射动态整合语法模式、函数依赖和语义扩展意图。

Result: 在Top-5准确率上提升12.2%，召回率提升7.1%，优于现有最先进基线方法。

Conclusion: 为上下文感知的代码检索开辟了新方向，从函数中心匹配转向整体代码库级推理。

Abstract: The escalating complexity of modern codebases has intensified the need for
retrieval systems capable of interpreting cross-component change intents, a
capability fundamentally absent in conventional function-level search
paradigms. While recent studies have improved the alignment between natural
language queries and code snippets, retrieving contextually relevant code for
specific change requests remains largely underexplored. To address this gap, we
introduce RepoAlign-Bench, the first benchmark specifically designed to
evaluate repository-level code retrieval under change request driven scenarios,
encompassing 52k annotated instances. This benchmark shifts the retrieval
paradigm from function-centric matching to holistic repository-level reasoning.
Furthermore, we propose ReflectCode, an adversarial reflection augmented
dual-tower architecture featuring disentangled code_encoder and doc_encoder
components. ReflectCode dynamically integrates syntactic patterns, function
dependencies, and semantic expansion intents through large language model
guided reflection. Comprehensive experiments demonstrate that ReflectCode
achieves 12.2% improvement in Top-5 Accuracy and 7.1% in Recall over
state-of-the-art baselines, establishing a new direction for context-aware code
retrieval.

</details>


### [2] [Compiler.next: A Search-Based Compiler to Power the AI-Native Future of Software Engineering](https://arxiv.org/abs/2510.24799)
*Filipe R. Cogo,Gustavo A. Oliva,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: Compiler.next是一个基于搜索的编译器，能够将人类意图自动转化为工作软件，通过动态优化认知架构来平衡准确性、成本和延迟等目标。


<details>
  <summary>Details</summary>
Motivation: 现有AI辅助软件工程工具存在认知过载、工具集成效率低和AI助手能力有限等问题，需要新的范式来降低技术门槛，实现可扩展、适应性强且可靠的AI驱动软件开发。

Method: 提出搜索式编译器架构，通过动态优化认知架构组件（如提示词、基础模型配置和系统参数），在多目标间寻找最优权衡来生成软件。

Result: 构建了Compiler.next的架构框架，为完全自动化、搜索驱动的软件开发奠定基础，促进更快的创新和更高效的AI驱动系统。

Conclusion: Compiler.next是软件工程3.0时代的关键基石，通过降低非专家的技术门槛，实现AI原生软件系统的无缝演进，为民主化软件开发铺平道路。

Abstract: The rapid advancement of AI-assisted software engineering has brought
transformative potential to the field of software engineering, but existing
tools and paradigms remain limited by cognitive overload, inefficient tool
integration, and the narrow capabilities of AI copilots. In response, we
propose Compiler.next, a novel search-based compiler designed to enable the
seamless evolution of AI-native software systems as part of the emerging
Software Engineering 3.0 era. Unlike traditional static compilers,
Compiler.next takes human-written intents and automatically generates working
software by searching for an optimal solution. This process involves dynamic
optimization of cognitive architectures and their constituents (e.g., prompts,
foundation model configurations, and system parameters) while finding the
optimal trade-off between several objectives, such as accuracy, cost, and
latency. This paper outlines the architecture of Compiler.next and positions it
as a cornerstone in democratizing software development by lowering the
technical barrier for non-experts, enabling scalable, adaptable, and reliable
AI-powered software. We present a roadmap to address the core challenges in
intent compilation, including developing quality programming constructs,
effective search heuristics, reproducibility, and interoperability between
compilers. Our vision lays the groundwork for fully automated, search-driven
software development, fostering faster innovation and more efficient AI-driven
systems.

</details>


### [3] [A Roadmap for Tamed Interactions with Large Language Models](https://arxiv.org/abs/2510.24819)
*Vincenzo Scotti,Jan Keim,Tobias Hey,Andreas Metzger,Anne Koziolek,Raffaela Mirandola*

Main category: cs.SE

TL;DR: 提出一种用于与大型语言模型交互的领域特定语言LSL，旨在通过编程方式控制LLM输出、增强交互结构，并结合验证和可解释性来提升AI应用的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM应用虽然令人印象深刻，但其不可靠性和幻觉问题阻碍了实际应用。需要软件工程工具来约束LLM输出并提供更强的内容保证。

Method: 开发LLM脚本语言LSL，通过领域特定语言来编程化LLM交互，控制输出结构，并与验证、验证和可解释性集成。

Result: 提出了LSL的愿景框架，旨在使LLM交互可编程化，并与训练或实现解耦。

Conclusion: LSL可能是提高基于AI应用可靠性的关键，通过结构化交互和集成验证工具来解决当前LLM应用的碎片化问题。

Abstract: We are witnessing a bloom of AI-powered software driven by Large Language
Models (LLMs). Although the applications of these LLMs are impressive and
seemingly countless, their unreliability hinders adoption. In fact, the
tendency of LLMs to produce faulty or hallucinated content makes them
unsuitable for automating workflows and pipelines. In this regard, Software
Engineering (SE) provides valuable support, offering a wide range of formal
tools to specify, verify, and validate software behaviour. Such SE tools can be
applied to define constraints over LLM outputs and, consequently, offer
stronger guarantees on the generated content. In this paper, we argue that the
development of a Domain Specific Language (DSL) for scripting interactions with
LLMs using an LLM Scripting Language (LSL) may be key to improve AI-based
applications. Currently, LLMs and LLM-based software still lack reliability,
robustness, and trustworthiness, and the tools or frameworks to cope with these
issues suffer from fragmentation. In this paper, we present our vision of LSL.
With LSL, we aim to address the limitations above by exploring ways to control
LLM outputs, enforce structure in interactions, and integrate these aspects
with verification, validation, and explainability. Our goal is to make LLM
interaction programmable and decoupled from training or implementation.

</details>


### [4] [VeriStruct: AI-assisted Automated Verification of Data-Structure Modules in Verus](https://arxiv.org/abs/2510.25015)
*Chuyue Sun,Yican Sun,Daneshvar Amrollahi,Ethan Zhang,Shuvendu Lahiri,Shan Lu,David Dill,Clark Barrett*

Main category: cs.SE

TL;DR: VeriStruct是一个扩展AI辅助自动验证的框架，从单函数验证扩展到Verus中的复杂数据结构模块验证，通过规划器模块系统生成抽象、类型不变量、规范和证明代码。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在理解Verus注解语法和验证特定语义时经常出错的问题，将AI辅助验证从单函数扩展到复杂数据结构模块。

Method: 使用规划器模块协调生成抽象、类型不变量、规范和证明代码；在提示中嵌入语法指导；包含修复阶段自动纠正注解错误。

Result: 在11个Rust数据结构模块评估中，成功验证了10个模块，总共验证了128/129个函数（99.2%成功率）。

Conclusion: 这是实现自动AI辅助形式验证目标的重要进展。

Abstract: We introduce VeriStruct, a novel framework that extends AI-assisted automated
verification from single functions to more complex data structure modules in
Verus. VeriStruct employs a planner module to orchestrate the systematic
generation of abstractions, type invariants, specifications, and proof code. To
address the challenge that LLMs often misunderstand Verus' annotation syntax
and verification-specific semantics, VeriStruct embeds syntax guidance within
prompts and includes a repair stage to automatically correct annotation errors.
In an evaluation on eleven Rust data structure modules, VeriStruct succeeds on
ten of the eleven, successfully verifying 128 out of 129 functions (99.2%) in
total. These results represent an important step toward the goal of automatic
AI-assisted formal verification.

</details>


### [5] [Towards Human-AI Synergy in Requirements Engineering: A Framework and Preliminary Study](https://arxiv.org/abs/2510.25016)
*Mateen Ahmed Abbasi,Petri Ihantola,Tommi Mikkonen,Niko Mäkitalo*

Main category: cs.SE

TL;DR: 本文提出了Human-AI RE协同模型(HARE-SM)，将AI驱动分析与人类监督结合，以改进需求工程的获取、分析和验证过程，同时强调伦理AI使用。


<details>
  <summary>Details</summary>
Motivation: 传统需求工程依赖劳动密集型人工流程，容易出错且复杂。AI方法（特别是LLM、NLP和生成式AI）能提供变革性解决方案，但同时也带来算法偏见、缺乏可解释性和伦理问题等挑战。

Method: 采用多阶段研究方法，包括准备需求工程数据集、微调AI模型、设计协作式人机工作流程，并提出了HARE-SM概念框架和早期原型实现。

Result: 建立了研究议程和实践设计方向，为在协作环境中应用智能数据科学技术处理半结构化和非结构化需求工程数据奠定了基础。

Conclusion: HARE-SM框架通过整合AI分析与人类监督，能够有效应对AI在需求工程中应用的挑战，强调透明度、可解释性和偏见缓解的伦理AI使用。

Abstract: The future of Requirements Engineering (RE) is increasingly driven by
artificial intelligence (AI), reshaping how we elicit, analyze, and validate
requirements. Traditional RE is based on labor-intensive manual processes prone
to errors and complexity. AI-powered approaches, specifically large language
models (LLMs), natural language processing (NLP), and generative AI, offer
transformative solutions and reduce inefficiencies. However, the use of AI in
RE also brings challenges like algorithmic bias, lack of explainability, and
ethical concerns related to automation. To address these issues, this study
introduces the Human-AI RE Synergy Model (HARE-SM), a conceptual framework that
integrates AI-driven analysis with human oversight to improve requirements
elicitation, analysis, and validation. The model emphasizes ethical AI use
through transparency, explainability, and bias mitigation. We outline a
multi-phase research methodology focused on preparing RE datasets, fine-tuning
AI models, and designing collaborative human-AI workflows. This preliminary
study presents the conceptual framework and early-stage prototype
implementation, establishing a research agenda and practical design direction
for applying intelligent data science techniques to semi-structured and
unstructured RE data in collaborative environments.

</details>


### [6] [Automating Benchmark Design](https://arxiv.org/abs/2510.25039)
*Amanda Dsouza,Harit Vishwakarma,Zhengyang Qi,Justin Bauer,Derek Pham,Thomas Walshe,Armin Parchami,Frederic Sala,Paroma Varma*

Main category: cs.SE

TL;DR: BeTaL是一个利用LLM自动化设计动态基准测试的框架，通过参数化基准模板并使用LLM推理来获得目标属性（如难度和真实性），相比静态基准有2-4倍的改进。


<details>
  <summary>Details</summary>
Motivation: 当前LLM和LLM驱动智能体的快速发展超出了我们的评估能力，手工制作的静态基准容易饱和，而动态基准虽然能随模型进化但创建和更新成本高昂。

Method: BeTaL框架通过参数化基准模板的关键设计选择，使用LLM在参数空间中进行推理，以成本效益的方式获得目标属性。

Result: 在三个任务和多个目标难度级别上的广泛评估显示，BeTaL产生的基准与期望难度的平均偏差为5.3%到13.2%，比基线方法有2-4倍的改进。

Conclusion: BeTaL能够有效自动化动态基准设计过程，显著提高基准测试的质量和效率。

Abstract: The rapid progress and widespread deployment of LLMs and LLM-powered agents
has outpaced our ability to evaluate them. Hand-crafted, static benchmarks are
the primary tool for assessing model capabilities, but these quickly become
saturated. In contrast, dynamic benchmarks evolve alongside the models they
evaluate, but are expensive to create and continuously update. To address these
challenges, we develop BeTaL (Benchmark Tuning with an LLM-in-the-loop), a
framework that leverages environment design principles to automate the process
of dynamic benchmark design. BeTaL works by parameterizing key design choices
in base benchmark templates and uses LLMs to reason through the resulting
parameter space to obtain target properties (such as difficulty and realism) in
a cost-efficient manner. We validate this approach on its ability to create
benchmarks with desired difficulty levels. Using BeTaL, we create two new
benchmarks and extend a popular agentic benchmark $\tau$-bench. Extensive
evaluation on these three tasks and multiple target difficulty levels shows
that BeTaL produces benchmarks much closer to the desired difficulty, with
average deviations ranging from 5.3% to 13.2% -- a 2-4x improvement over the
baselines.

</details>


### [7] [Same Same But Different: Preventing Refactoring Attacks on Software Plagiarism Detection](https://arxiv.org/abs/2510.25057)
*Robin Maisch,Larissa Schmid,Timur Sağlam,Nils Niehues*

Main category: cs.SE

TL;DR: 提出一个新颖可扩展的框架，通过代码属性图和图变换来增强现有检测器，有效对抗重构式混淆攻击，显著提升抄袭代码检测能力。


<details>
  <summary>Details</summary>
Motivation: 编程教育中的抄袭检测面临日益复杂的混淆技术挑战，特别是自动化重构式攻击。现有教育实践中的代码抄袭检测系统对基本混淆有抵抗力，但难以应对保持程序行为的结构修改，尤其是重构式混淆。

Method: 利用代码属性图和图变换构建新颖可扩展框架，增强最先进的检测器，对抗重构式混淆。

Result: 对真实学生提交代码的全面评估显示，无论是算法还是AI驱动的混淆攻击，该框架都能显著提高抄袭代码的检测效果。

Conclusion: 该框架有效解决了重构式混淆带来的挑战，显著提升了编程教育中抄袭检测系统的性能。

Abstract: Plagiarism detection in programming education faces growing challenges due to
increasingly sophisticated obfuscation techniques, particularly automated
refactoring-based attacks. While code plagiarism detection systems used in
education practice are resilient against basic obfuscation, they struggle
against structural modifications that preserve program behavior, especially
caused by refactoring-based obfuscation. This paper presents a novel and
extensible framework that enhances state-of-the-art detectors by leveraging
code property graphs and graph transformations to counteract refactoring-based
obfuscation. Our comprehensive evaluation of real-world student submissions,
obfuscated using both algorithmic and AI-based obfuscation attacks,
demonstrates a significant improvement in detecting plagiarized code.

</details>


### [8] [Adaptive Proof Refinement with LLM-Guided Strategy Selection](https://arxiv.org/abs/2510.25103)
*Minghai Lu,Zhe Zhou,Danning Xie,Songlin Jia,Benjamin Delaware,Tianyi Zhang*

Main category: cs.SE

TL;DR: Adapt是一个基于LLM的动态证明精炼框架，通过智能选择策略来改进自动定理证明，相比固定策略方法显著提升了证明成功率


<details>
  <summary>Details</summary>
Motivation: 现有LLM证明生成方法使用固定精炼策略，无法根据具体证明问题动态选择有效策略，限制了性能

Method: 利用LLM引导的决策器，根据证明助手状态和错误证明上下文动态选择合适精炼策略

Result: 在两个基准测试中分别比最佳基线多证明了16.63%和18.58%的定理，在五个不同LLM上均表现良好

Conclusion: Adapt框架通过动态策略选择有效提升了自动定理证明的性能，具有良好通用性

Abstract: Formal verification via theorem proving enables the expressive specification
and rigorous proof of software correctness, but it is difficult to scale due to
the significant manual effort and expertise required. While Large Language
Models (LLMs) show potential in proof generation, they frequently produce
incorrect proofs on the first attempt and require additional strategies for
iterative refinement. However, existing approaches employ fixed refinement
strategies and cannot dynamically choose an effective strategy based on the
particular issues in a generated proof, which limits their performance. To
overcome this limitation, we introduce Adapt, a novel proof refinement
framework that leverages an LLM-guided decision-maker to dynamically select a
suitable refinement strategy according to the state of the proof assistant and
available context of an incorrect proof. We evaluate Adapt on two benchmarks
against four existing methods and find that it significantly outperforms the
best baseline on both by proving 16.63% and 18.58% more theorems, respectively.
Furthermore, we demonstrate Adapt's generalizability by evaluating it across
five different LLMs. We also conduct ablation studies to measure the
contribution of each component and compare the trade-offs of alternative
decision-maker designs.

</details>


### [9] [Automated Program Repair Based on REST API Specifications Using Large Language Models](https://arxiv.org/abs/2510.25148)
*Katsuki Yamagishi,Norihiro Yoshida,Erina Makihara,Katsuro Inoue*

Main category: cs.SE

TL;DR: dcFix是一种自动检测和修复REST API误用的方法，通过识别不符合规范的代码片段，结合API规范生成提示，利用大语言模型生成修正代码。


<details>
  <summary>Details</summary>
Motivation: 开发者在测试阶段才能发现REST API规范违反问题，错误信息缺乏细节导致调试困难，需要反复试错。

Method: 识别不符合规范的代码片段，将其与相关API规范整合到提示中，利用大语言模型生成修正代码。

Result: 评估显示dcFix能准确检测误用，并且在性能上优于基线方法（基线方法在提示中不包含代码片段不符合REST API规范的指示）。

Conclusion: dcFix方法能有效检测和自动修复REST API误用问题，优于传统方法。

Abstract: Many cloud services provide REST API accessible to client applications.
However, developers often identify specification violations only during
testing, as error messages typically lack the detail necessary for effective
diagnosis. Consequently, debugging requires trial and error. This study
proposes dcFix, a method for detecting and automatically repairing REST API
misuses in client programs. In particular, dcFix identifies non-conforming code
fragments, integrates them with the relevant API specifications into prompts,
and leverages a Large Language Model (LLM) to produce the corrected code. Our
evaluation demonstrates that dcFix accurately detects misuse and outperforms
the baseline approach, in which prompts to the LLM omit any indication of code
fragments non conforming to REST API specifications.

</details>


### [10] [Optimizing Knowledge Utilization for Multi-Intent Comment Generation with Large Language Models](https://arxiv.org/abs/2510.25195)
*Shuochuan Li,Zan Wang,Xiaoning Du,Zhuo Wu,Jiuqiao Yu,Junjie Chen*

Main category: cs.SE

TL;DR: KUMIC是一个基于上下文学习的框架，通过检索机制和思维链优化LLMs生成多意图代码注释，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 通用代码注释无法满足开发者对实现细节和用户对使用说明的不同需求，需要多意图注释生成。现有LLM方法在少量示例中难以建立意图、代码和注释的正确关系。

Method: KUMIC框架：1）检索机制获取代码-注释一致性高的示例；2）使用思维链引导LLMs关注与特定意图对齐的语句；3）构建映射知识链，连接代码到意图特定语句再到注释。

Result: 在BLEU、METEOR、ROUGE-L和SBERT指标上分别比最先进基线方法提升14.49%、22.41%、20.72%和12.94%。

Conclusion: KUMIC通过优化知识利用和思维链推理，有效解决了多意图代码注释生成问题，显著提升了生成质量。

Abstract: Code comment generation aims to produce a generic overview of a code snippet,
helping developers understand and maintain code. However, generic summaries
alone are insufficient to meet the diverse needs of practitioners; for example,
developers expect the implementation insights to be presented in an untangled
manner, while users seek clear usage instructions. This highlights the
necessity of multi-intent comment generation. With the widespread adoption of
Large Language Models (LLMs) for code-related tasks, these models have been
leveraged to tackle the challenge of multi-intent comment generation. Despite
their successes, state-of-the-art LLM-based approaches often struggle to
construct correct relationships among intents, code, and comments within a
smaller number of demonstration examples. To mitigate this issue, we propose a
framework named KUMIC for multi-intent comment generation. Built upon
in-context learning, KUMIC leverages Chain-of-Thought (CoT) to optimize
knowledge utilization for LLMs to generate intent-specific comments.
Specifically, KUMIC first designs a retrieval mechanism to obtain similar
demonstration examples, which exhibit high code-comment consistency. Then,
KUMIC leverages CoT to guide LLMs to focus on statements facilitating the
derivation of code comments aligned with specific intents. In this context,
KUMIC constructs a mapping knowledge chain, linking code to intent-specific
statements to comments, which enables LLMs to follow similar reasoning steps
when generating the desired comments. We conduct extensive experiments to
evaluate KUMIC, and the results demonstrate that KUMIC outperforms
state-of-the-art baselines by 14.49\%, 22.41\%, 20.72\%, and 12.94\% in terms
of BLEU, METEOR, ROUGE-L, and SBERT, respectively.

</details>


### [11] [TECS/Rust-OE: Optimizing Exclusive Control in Rust-based Component Systems for Embedded Devices](https://arxiv.org/abs/2510.25242)
*Nao Yoshimura,Hiroshi Oyama,Takuya Azumi*

Main category: cs.SE

TL;DR: 提出了TECS/Rust-OE框架，通过利用实时操作系统排他控制机制优化性能，解决TECS/Rust框架中过度排他控制导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统结构日益复杂，需要确保系统可靠性，特别是安全性。现有TECS/Rust框架使用静态可变变量表示系统结构，但为确保线程安全而应用的过度排他控制导致性能下降。

Method: 提出TECS/Rust-OE框架，利用调用流和实时OS排他控制机制，在保持可重用性的同时优化性能。基于组件描述自动生成Rust代码。

Result: 评估显示优化后的排他控制减少了开销，生成的代码具有高可重用性。

Conclusion: TECS/Rust-OE框架成功解决了性能问题，实现了内存安全的组件化开发，同时保持高可重用性。

Abstract: The diversification of functionalities and the development of the IoT are
making embedded systems larger and more complex in structure. Ensuring system
reliability, especially in terms of security, necessitates selecting an
appropriate programming language. As part of existing research, TECS/Rust has
been proposed as a framework that combines Rust and component-based development
(CBD) to enable scalable system design and enhanced reliability. This framework
represents system structures using static mutable variables, but excessive
exclusive controls applied to ensure thread safety have led to performance
degradation. This paper proposes TECS/Rust-OE, a memory-safe CBD framework
utilizing call flows to address these limitations. The proposed Rust code
leverages real-time OS exclusive control mechanisms, optimizing performance
without compromising reusability. Rust code is automatically generated based on
component descriptions. Evaluations demonstrate reduced overhead due to
optimized exclusion control and high reusability of the generated code.

</details>


### [12] [TECS/Rust: Memory-safe Component Framework for Embedded Systems](https://arxiv.org/abs/2510.25270)
*Nao Yoshimura,Hiroshi Oyama,Takuya Azumi*

Main category: cs.SE

TL;DR: 提出TECS/Rust框架，将Rust的内存安全特性集成到嵌入式系统的组件化开发中，替代传统的C语言，以减少内存相关漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着嵌入式系统复杂性和规模增加，基于组件的开发(CBD)成为解决方案，但传统使用的C语言存在内存安全问题。需要利用Rust的编译时内存安全特性来解决这些问题。

Method: 开发基于Rust的TECS框架，利用Rust的生命周期和借用等特性确保内存安全，同时自动生成CBD组件的Rust代码，并支持与实时操作系统的有效集成。

Result: 生成的代码量占实际代码的很大比例，与不使用该框架开发的代码相比，执行时间差异极小，表明引入的开销可以忽略不计。

Conclusion: TECS/Rust框架成功地将Rust的内存安全特性引入嵌入式系统组件化开发，在保证内存安全的同时保持了CBD的灵活性，且性能开销可忽略。

Abstract: As embedded systems grow in complexity and scale due to increased functional
diversity, component-based development (CBD) emerges as a solution to
streamline their architecture and enhance functionality reuse. CBD typically
utilizes the C programming language for its direct hardware access and
low-level operations, despite its susceptibility to memory-related issues. To
address these concerns, this paper proposes TECS/Rust, a Rust-based framework
specifically designed for TECS, which is a component framework for embedded
systems. It leverages Rust's compile-time memory-safe features, such as
lifetime and borrowing, to mitigate memory vulnerabilities common with C. The
proposed framework not only ensures memory safety but also maintains the
flexibility of CBD, automates Rust code generation for CBD components, and
supports efficient integration with real-time operating systems. An evaluation
of the amount of generated code indicates that the code generated by this paper
framework accounts for a large percentage of the actual code. Compared to code
developed without the proposed framework, the difference in execution time is
minimal, indicating that the overhead introduced by the proposed framework is
negligible.

</details>


### [13] [Understanding the Characteristics of LLM-Generated Property-Based Tests in Exploring Edge Cases](https://arxiv.org/abs/2510.25297)
*Hidetake Tanaka,Haruto Tanaka,Kazumasa Shimari,Kenichi Matsumoto*

Main category: cs.SE

TL;DR: 研究比较了基于属性的测试(PBT)和基于示例的测试(EBT)在检测LLM生成代码边缘案例方面的效果，发现两者结合能提高81.25%的缺陷检测率。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在软件开发中生成代码的普及，确保LLM生成代码的质量变得重要。传统基于示例的测试方法经常遗漏边缘案例。

Method: 分析16个HumanEval问题，使用Claude-4-sonnet生成PBT和EBT测试代码，比较两种方法在检测边缘案例方面的效果。

Result: 单独使用PBT或EBT的缺陷检测率为68.75%，但两者结合后检测率提升至81.25%。PBT擅长检测性能问题和边缘案例，EBT擅长检测特定边界条件和特殊模式。

Conclusion: 结合PBT和EBT的混合方法可以提高LLM生成代码的可靠性，为LLM代码生成的测试策略提供指导。

Abstract: As Large Language Models (LLMs) increasingly generate code in software
development, ensuring the quality of LLM-generated code has become important.
Traditional testing approaches using Example-based Testing (EBT) often miss
edge cases -- defects that occur at boundary values, special input patterns, or
extreme conditions. This research investigates the characteristics of
LLM-generated Property-based Testing (PBT) compared to EBT for exploring edge
cases. We analyze 16 HumanEval problems where standard solutions failed on
extended test cases, generating both PBT and EBT test codes using
Claude-4-sonnet. Our experimental results reveal that while each method
individually achieved a 68.75\% bug detection rate, combining both approaches
improved detection to 81.25\%. The analysis demonstrates complementary
characteristics: PBT effectively detects performance issues and edge cases
through extensive input space exploration, while EBT effectively detects
specific boundary conditions and special patterns. These findings suggest that
a hybrid approach leveraging both testing methods can improve the reliability
of LLM-generated code, providing guidance for test generation strategies in
LLM-based code generation.

</details>


### [14] [Dissect-and-Restore: AI-based Code Verification with Transient Refactoring](https://arxiv.org/abs/2510.25406)
*Changjie Wang,Mariano Scazzariello,Anoud Alshnaka,Roberto Guanciale,Dejan Kostić,Marco Chiesa*

Main category: cs.SE

TL;DR: Prometheus是一个AI辅助的自动化代码验证系统，通过模块化重构将复杂程序分解为可验证的小组件，然后重新组合构建完整证明，显著提高验证成功率。


<details>
  <summary>Details</summary>
Motivation: 形式化验证对于构建可靠软件系统至关重要，但需要专业知识且成本高昂。现代AI系统能够识别数学证明模式和理解自然语言，但如何有效整合到形式化验证过程中仍是一个挑战。

Method: 采用分解-重组工作流：首先将复杂程序逻辑（如嵌套循环）分解为更小、可验证的组件；验证后重新组合构建原始程序的证明。系统通过结构化分解复杂引理为可验证子引理来指导证明搜索，用户可提供自然语言指导。

Result: 评估显示，临时应用模块化重构显著提高了AI验证单个组件的效果：在精选数据集中成功验证86%的任务（基线为68%）；随着规范复杂性增加，成功率从30%提升到69%；集成复杂程序证明大纲时，从25%提升到87%。

Conclusion: Prometheus通过结合AI能力和模块化软件工程原则，成功解决了形式化验证中的可扩展性和可访问性问题，为自动化代码验证提供了有效解决方案。

Abstract: Formal verification is increasingly recognized as a critical foundation for
building reliable software systems. However, the need for specialized expertise
to write precise specifications, navigate complex proof obligations, and learn
annotations often makes verification an order of magnitude more expensive than
implementation. While modern AI systems can recognize patterns in mathematical
proofs and interpret natural language, effectively integrating them into the
formal verification process remains an open challenge. We present Prometheus, a
novel AI-assisted system that facilitates automated code verification with
current AI capabilities in conjunction with modular software engineering
principles (e.g., modular refactoring). Our approach begins by decomposing
complex program logic, such as nested loops, into smaller, verifiable
components. Once verified, these components are recomposed to construct a proof
of the original program. This decomposition-recomposition workflow is
non-trivial. Prometheus addresses this by guiding the proof search through
structured decomposition of complex lemmas into smaller, verifiable sub-lemmas.
When automated tools are insufficient, users can provide lightweight natural
language guidance to steer the proof process effectively. Our evaluation
demonstrates that transiently applying modular restructuring to the code
substantially improves the AI's effectiveness in verifying individual
components. This approach successfully verifies 86% of tasks in our curated
dataset, compared to 68% for the baseline. Gains are more pronounced with
increasing specification complexity, improving from 30% to 69%, and when
integrating proof outlines for complex programs, from 25% to 87%.

</details>


### [15] [What Challenges Do Developers Face in AI Agent Systems? An Empirical Study on Stack Overflow](https://arxiv.org/abs/2510.25423)
*Ali Asgari,Annibale Panichella,Pouria Derakhshanfar,Mitchell Olsthoorn*

Main category: cs.SE

TL;DR: 本文通过分析Stack Overflow上的开发者讨论，识别了AI代理开发中的77个技术挑战，涵盖运行时集成、依赖管理、编排复杂性和评估可靠性等7大领域，并量化了问题的流行度和难度。


<details>
  <summary>Details</summary>
Motivation: AI代理虽然前景广阔，但开发者在构建、部署和维护这些系统时面临持续且未被充分探索的挑战，需要系统性地识别这些问题。

Method: 通过标签扩展和过滤构建挑战分类法，应用LDA-MALLET进行主题建模，并手动验证和标注结果主题，分析2021-2025年的数据演变。

Result: 识别出7大领域的77个技术挑战，量化了主题流行度和解决难度，绘制了代理开发使用的工具和编程语言图谱，并跟踪了其与主要AI模型和框架发布的关系。

Conclusion: 研究结果为从业者、研究人员和教育工作者提供了关于代理可靠性和开发者支持的具体指导。

Abstract: AI agents have rapidly gained popularity across research and industry as
systems that extend large language models with additional capabilities to plan,
use tools, remember, and act toward specific goals. Yet despite their promise,
developers face persistent and often underexplored challenges when building,
deploying, and maintaining these emerging systems. To identify these
challenges, we study developer discussions on Stack Overflow, the world's
largest developer-focused Q and A platform with about 60 million questions and
answers and 30 million users. We construct a taxonomy of developer challenges
through tag expansion and filtering, apply LDA-MALLET for topic modeling, and
manually validate and label the resulting themes. Our analysis reveals seven
major areas of recurring issues encompassing 77 distinct technical challenges
related to runtime integration, dependency management, orchestration
complexity, and evaluation reliability. We further quantify topic popularity
and difficulty to identify which issues are most common and hardest to resolve,
map the tools and programming languages used in agent development, and track
their evolution from 2021 to 2025 in relation to major AI model and framework
releases. Finally, we present the implications of our results, offering
concrete guidance for practitioners, researchers, and educators on agent
reliability and developer support.

</details>


### [16] [Reflections on the Reproducibility of Commercial LLM Performance in Empirical Software Engineering Studies](https://arxiv.org/abs/2510.25506)
*Florian Angermeir,Maximilian Amougou,Mark Kreitz,Andreas Bauer,Matthias Linhuber,Davide Fucci,Fabiola Moyón C.,Daniel Mendez,Tony Gorschek*

Main category: cs.SE

TL;DR: 分析了ICSE 2024和ASE 2024会议上86篇基于大语言模型的研究论文的可复现性，发现只有5项研究适合复现，但无一能完全复现结果，凸显了LLM研究中可复现性的严重问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在学术界和工业界的广泛应用，进行LLM实证研究面临可复现性挑战，需要了解当前研究成果的可复现程度及其阻碍因素。

Method: 研究了ICSE 2024和ASE 2024会议上86篇LLM相关论文，其中18篇提供了研究构件并使用OpenAI模型，对这18项研究进行了复现尝试。

Result: 18项研究中只有5项适合复现，但无一能完全复现结果：2项部分可复现，3项似乎不可复现。

Conclusion: LLM研究的可复现性现状堪忧，需要更严格的研究构件评估和更稳健的研究设计来确保未来发表成果的可复现价值。

Abstract: Large Language Models have gained remarkable interest in industry and
academia. The increasing interest in LLMs in academia is also reflected in the
number of publications on this topic over the last years. For instance, alone
78 of the around 425 publications at ICSE 2024 performed experiments with LLMs.
Conducting empirical studies with LLMs remains challenging and raises questions
on how to achieve reproducible results, for both other researchers and
practitioners. One important step towards excelling in empirical research on
LLMs and their application is to first understand to what extent current
research results are eventually reproducible and what factors may impede
reproducibility. This investigation is within the scope of our work. We
contribute an analysis of the reproducibility of LLM-centric studies, provide
insights into the factors impeding reproducibility, and discuss suggestions on
how to improve the current state. In particular, we studied the 86 articles
describing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 86
articles, 18 provided research artefacts and used OpenAI models. We attempted
to replicate those 18 studies. Of the 18 studies, only five were fit for
reproduction. For none of the five studies, we were able to fully reproduce the
results. Two studies seemed to be partially reproducible, and three studies did
not seem to be reproducible. Our results highlight not only the need for
stricter research artefact evaluations but also for more robust study designs
to ensure the reproducible value of future publications.

</details>


### [17] [Fuzz Smarter, Not Harder: Towards Greener Fuzzing with GreenAFL](https://arxiv.org/abs/2510.25665)
*Ayse Irmak Ercevik,Aidan Dakhama,Melane Navaratnarajah,Yazhuo Cao,Leo Fernandes*

Main category: cs.SE

TL;DR: GreenAFL是一个能量感知的模糊测试框架，通过将功耗纳入模糊测试启发式算法，在保持覆盖率的同时减少自动化测试的环境影响。


<details>
  <summary>Details</summary>
Motivation: 现有灰盒模糊测试方法如AFL++主要关注覆盖率最大化，而没有考虑探索不同执行路径的能源成本。持续模糊测试活动消耗大量计算资源并产生显著的碳足迹。

Method: GreenAFL引入了两个关键修改：能量感知的语料库最小化（在减少初始语料库时考虑功耗）和能量引导的启发式算法（将变异导向高覆盖率、低能耗的输入）。

Result: 消融研究表明，当使用至少一个修改时，实现了最高覆盖率和最低能耗。

Conclusion: GreenAFL框架成功地将能量效率纳入模糊测试过程，在保持测试效果的同时显著降低了环境足迹。

Abstract: Fuzzing has become a key search-based technique for software testing, but
continuous fuzzing campaigns consume substantial computational resources and
generate significant carbon footprints. Existing grey-box fuzzing approaches
like AFL++ focus primarily on coverage maximisation, without considering the
energy costs of exploring different execution paths. This paper presents
GreenAFL, an energy-aware framework that incorporates power consumption into
the fuzzing heuristics to reduce the environmental impact of automated testing
whilst maintaining coverage. GreenAFL introduces two key modifications to
traditional fuzzing workflows: energy-aware corpus minimisation considering
power consumption when reducing initial corpora, and energy-guided heuristics
that direct mutation towards high-coverage, low-energy inputs. We conduct an
ablation study comparing vanilla AFL++, energy-based corpus minimisation, and
energy-based heuristics to evaluate the individual contributions of each
component. Results show that highest coverage, and lowest energy usage is
achieved whenever at least one of our modifications is used.

</details>


### [18] [A Configuration-First Framework for Reproducible, Low-Code Localization](https://arxiv.org/abs/2510.25692)
*Tim Strnad,Blaž Bertalanič,Carolina Fortuna*

Main category: cs.SE

TL;DR: 提出了LOCALIZE框架，一个用于无线电定位的低代码、配置优先的机器学习实验框架，旨在解决实验可重复性、易用性和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习在基于无线电的定位服务中应用日益广泛，但现有工具难以同时满足低编码工作量、默认可重复性和内置可扩展性这三个关键需求。

Method: 开发了基于人类可读配置的实验声明系统，通过工作流编排器运行标准化管道（从数据准备到报告生成），并对所有工件（数据集、模型、指标、报告）进行版本控制。

Result: 与普通Jupyter笔记本基线相比，该框架减少了编写工作量，同时保持了相当的运行时和内存行为；在BLE数据集上的实验表明，随着训练数据从1倍增加到10倍，编排开销保持有界。

Conclusion: LOCALIZE框架使基于机器学习的定位实验变得实用、易于访问且可扩展，实现了可重复的实验流程。

Abstract: Machine learning is increasingly permeating radio-based localization
services. To keep results credible and comparable, everyday workflows should
make rigorous experiment specification and exact repeatability the default,
without blocking advanced experimentation. However, in practice, researchers
face a three-way gap that could be filled by a framework that offers (i) low
coding effort for end-to-end studies, (ii) reproducibility by default including
versioned code, data, and configurations, controlled randomness, isolated runs,
and recorded artifacts, and (iii) built-in extensibility so new models,
metrics, and stages can be added with minimal integration effort. Existing
tools rarely deliver all three for machine learning in general and localization
workflows in particular. In this paper we introduce LOCALIZE, a low-code,
configuration-first framework for radio localization in which experiments are
declared in human-readable configuration, a workflow orchestrator runs
standardized pipelines from data preparation to reporting, and all artifacts,
such as datasets, models, metrics, and reports, are versioned. The
preconfigured, versioned datasets reduce initial setup and boilerplate,
speeding up model development and evaluation. The design, with clear extension
points, allows experts to add components without reworking the infrastructure.
In a qualitative comparison and a head-to-head study against a plain Jupyter
notebook baseline, we show that the framework reduces authoring effort while
maintaining comparable runtime and memory behavior. Furthermore, using a
Bluetooth Low Energy dataset, we show that scaling across training data (1x to
10x) keeps orchestration overheads bounded as data grows. Overall, the
framework makes reproducible machine-learning-based localization
experimentation practical, accessible, and extensible.

</details>


### [19] [Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents](https://arxiv.org/abs/2510.25694)
*Jiayi Kuang,Yinghui Li,Xin Zhang,Yangning Li,Di Yin,Xing Sun,Ying Shen,Philip S. Yu*

Main category: cs.SE

TL;DR: Enconda-bench是一个环境配置诊断基准，通过过程级轨迹评估来诊断LLM代理在环境配置中的细粒度能力，包括规划、错误诊断、反馈驱动的修复等。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅评估端到端构建/测试成功，无法揭示代理成功或失败的具体原因，环境配置仍然是软件工程中的瓶颈。

Method: 通过注入真实的README错误自动构建任务实例，在Docker中进行验证，结合过程级分析和端到端可执行性来评估代理能力。

Result: 评估显示代理能够定位错误，但难以将反馈转化为有效修正，限制了端到端性能。

Conclusion: Enconda-bench是首个为环境配置提供过程级内部能力评估的框架，为改进软件工程代理提供了可操作的见解。

Abstract: Large language model-based agents show promise for software engineering, but
environment configuration remains a bottleneck due to heavy manual effort and
scarce large-scale, high-quality datasets. Existing benchmarks assess only
end-to-end build/test success, obscuring where and why agents succeed or fail.
We introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench,
which provides process-level trajectory assessment of fine-grained agent
capabilities during environment setup-planning, perception-driven error
diagnosis, feedback-driven repair, and action to execute final environment
configuration. Our task instances are automatically constructed by injecting
realistic README errors and are validated in Docker for scalable, high-quality
evaluation. Enconda-bench combines process-level analysis with end-to-end
executability to enable capability assessments beyond aggregate success rates.
Evaluations across state-of-the-art LLMs and agent frameworks show that while
agents can localize errors, they struggle to translate feedback into effective
corrections, limiting end-to-end performance. To our knowledge, Enconda-bench
is the first framework to provide process-level internal capability assessment
for environment configuration, offering actionable insights for improving
software engineering agents.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [20] [Learning to Attack: Uncovering Privacy Risks in Sequential Data Releases](https://arxiv.org/abs/2510.24807)
*Ziyao Cui,Minxing Zhang,Jian Pei*

Main category: cs.CR

TL;DR: 论文研究了序列数据发布中的隐私风险，提出了一种结合隐马尔可夫模型和强化学习的双向推理攻击模型，能够利用时间相关性从看似独立的隐私保护数据发布中推断敏感信息。


<details>
  <summary>Details</summary>
Motivation: 现实世界中许多系统采用序列或连续数据发布方式，虽然单个发布满足隐私保护标准，但时间相关性可能让攻击者通过分析多个发布来推断敏感信息。

Method: 提出了一种新颖的攻击模型，将隐马尔可夫模型与基于强化学习的双向推理机制相结合，使攻击者能够利用序列中前后观测来推断私有信息。

Result: 在Geolife、Porto Taxi和SynMob数据集上的实验表明，该模型始终优于将每个发布视为独立的基线方法，揭示了序列数据发布的基本隐私风险。

Conclusion: 研究结果表明需要开发新的隐私保护框架，如时间感知差分隐私或序列数据混淆策略，以明确建模时间依赖性。

Abstract: Privacy concerns have become increasingly critical in modern AI and data
science applications, where sensitive information is collected, analyzed, and
shared across diverse domains such as healthcare, finance, and mobility. While
prior research has focused on protecting privacy in a single data release, many
real-world systems operate under sequential or continuous data publishing,
where the same or related data are released over time. Such sequential
disclosures introduce new vulnerabilities, as temporal correlations across
releases may enable adversaries to infer sensitive information that remains
hidden in any individual release. In this paper, we investigate whether an
attacker can compromise privacy in sequential data releases by exploiting
dependencies between consecutive publications, even when each individual
release satisfies standard privacy guarantees. To this end, we propose a novel
attack model that captures these sequential dependencies by integrating a
Hidden Markov Model with a reinforcement learning-based bi-directional
inference mechanism. This enables the attacker to leverage both earlier and
later observations in the sequence to infer private information. We instantiate
our framework in the context of trajectory data, demonstrating how an adversary
can recover sensitive locations from sequential mobility datasets. Extensive
experiments on Geolife, Porto Taxi, and SynMob datasets show that our model
consistently outperforms baseline approaches that treat each release
independently. The results reveal a fundamental privacy risk inherent to
sequential data publishing, where individually protected releases can
collectively leak sensitive information when analyzed temporally. These
findings underscore the need for new privacy-preserving frameworks that
explicitly model temporal dependencies, such as time-aware differential privacy
or sequential data obfuscation strategies.

</details>


### [21] [S3C2 Summit 2025-03: Industry Secure Supply Chain Summit](https://arxiv.org/abs/2510.24920)
*Elizabeth Lin,Jonah Ghebremichael,William Enck,Yasemin Acar,Michel Cukier,Alexandros Kapravelos,Christian Kastner,Laurie Williams*

Main category: cs.CR

TL;DR: 本文报告了2025年3月6日举行的软件供应链安全峰会，汇集了来自17个组织的18名从业者，讨论了SBOM、合规性、恶意提交、构建基础设施、文化以及LLM与安全等六个关键主题。


<details>
  <summary>Details</summary>
Motivation: 软件供应链攻击呈指数级增长，威胁到从大型企业到开源开发者的所有互联网用户。为应对这一威胁，需要行业和政府共同努力提升软件供应链安全。

Method: 通过举办安全软件供应链峰会，汇集来自不同行业的从业者进行经验分享和挑战讨论，围绕六个核心主题展开对话。

Result: 峰会促进了跨行业知识共享，形成了新的合作机会，并识别了各主题领域面临的开放问题和挑战。

Conclusion: 软件供应链安全需要持续的多方协作，峰会为未来研究方向提供了重要见解，并为解决这一复杂问题奠定了基础。

Abstract: Software supply chains, while providing immense economic and software
development value, are only as strong as their weakest link. Over the past
several years, there has been an exponential increase in cyberattacks
specifically targeting vulnerable links in critical software supply chains.
These attacks disrupt the day-to-day functioning and threaten the security of
nearly everyone on the internet, from billion-dollar companies and government
agencies to hobbyist open-source developers. The ever-evolving threat of
software supply chain attacks has garnered interest from both the software
industry and US government in improving software supply chain security. On
Thursday, March 6th, 2025, four researchers from the NSF-backed Secure Software
Supply Chain Center (S3C2) conducted a Secure Software Supply Chain Summit with
a diverse set of 18 practitioners from 17 organizations. The goals of the
Summit were: (1) to enable sharing between participants from different
industries regarding practical experiences and challenges with software supply
chain security; (2) to help form new collaborations; and (3) to learn about the
challenges facing participants to inform our future research directions. The
summit consisted of discussions of six topics relevant to the government
agencies represented, including software bill of materials (SBOMs); compliance;
malicious commits; build infrastructure; culture; and large language models
(LLMs) and security. For each topic of discussion, we presented a list of
questions to participants to spark conversation. In this report, we provide a
summary of the summit. The open questions and challenges that remained after
each topic are listed at the end of each topic's section, and the initial
discussion questions for each topic are provided in the appendix.

</details>


### [22] [Hammering the Diagnosis: Rowhammer-Induced Stealthy Trojan Attacks on ViT-Based Medical Imaging](https://arxiv.org/abs/2510.24976)
*Banafsheh Saber Latibari,Najmeh Nazari,Hossein Sayadi,Houman Homayoun,Abhijit Mahalanobis*

Main category: cs.CR

TL;DR: 提出了一种名为Med-Hammer的新型威胁模型，结合Rowhammer硬件故障注入和神经木马攻击，针对医疗影像中的Vision Transformers系统进行攻击。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在医疗影像分析中表现出色，但其基于注意力机制的大型模型容易受到硬件级攻击。研究旨在揭示硬件故障与深度学习安全在医疗应用中的交叉威胁。

Method: 通过Rowhammer诱导恶意比特翻转来触发植入的神经木马，导致医疗扫描中的定向误分类或关键诊断（如肿瘤）被抑制。在ISIC、Brain Tumor和MedMNIST等基准数据集上进行实验。

Result: 攻击在MobileViT和SwinTransformer中分别达到82.51%和92.56%的高成功率，同时保持隐蔽性。模型稀疏性、注意力权重分布和层特征数量等架构特性影响攻击效果。

Conclusion: 研究揭示了医疗应用中硬件级故障与深度学习安全的关键交叉点，强调需要在模型架构和底层硬件平台两方面建立鲁棒防御的紧迫性。

Abstract: Vision Transformers (ViTs) have emerged as powerful architectures in medical
image analysis, excelling in tasks such as disease detection, segmentation, and
classification. However, their reliance on large, attention-driven models makes
them vulnerable to hardware-level attacks. In this paper, we propose a novel
threat model referred to as Med-Hammer that combines the Rowhammer hardware
fault injection with neural Trojan attacks to compromise the integrity of
ViT-based medical imaging systems. Specifically, we demonstrate how malicious
bit flips induced via Rowhammer can trigger implanted neural Trojans, leading
to targeted misclassification or suppression of critical diagnoses (e.g.,
tumors or lesions) in medical scans. Through extensive experiments on benchmark
medical imaging datasets such as ISIC, Brain Tumor, and MedMNIST, we show that
such attacks can remain stealthy while achieving high attack success rates
about 82.51% and 92.56% in MobileViT and SwinTransformer, respectively. We
further investigate how architectural properties, such as model sparsity,
attention weight distribution, and the number of features of the layer, impact
attack effectiveness. Our findings highlight a critical and underexplored
intersection between hardware-level faults and deep learning security in
healthcare applications, underscoring the urgent need for robust defenses
spanning both model architectures and underlying hardware platforms.

</details>


### [23] [FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip Attack Resilience in Transformer Models](https://arxiv.org/abs/2510.24985)
*Najmeh Nazari,Banafsheh Saber Latibari,Elahe Hosseini,Fatemeh Movafagh,Chongzhou Fang,Hosein Mohammadi Makrani,Kevin Immanuel Gubbi,Abhijit Mahalanobis,Setareh Rafatirad,Hossein Sayadi,Houman Homayoun*

Main category: cs.CR

TL;DR: FaRAccel是一种针对FaR方法的硬件加速器架构，通过FPGA实现动态激活重路由和轻量级存储，显著降低推理延迟并提高能效，同时保持对位翻转攻击的防御能力。


<details>
  <summary>Details</summary>
Motivation: FaR方法虽然能有效防御位翻转攻击，但带来了显著的性能和内存开销，主要原因是运行时激活路径修改和缺乏硬件级优化。

Method: 设计FaRAccel硬件加速器架构，集成可重构逻辑用于动态激活重路由，以及轻量级存储重连配置，在FPGA上实现低延迟推理。

Result: 在多个Transformer模型上评估显示，FaRAccel显著降低了FaR推理延迟并提高了能效，同时保持了原始FaR方法的鲁棒性增益。

Conclusion: 这是首个针对Transformer中位翻转攻击的硬件加速防御方案，有效弥合了算法鲁棒性与实际AI平台高效部署之间的差距。

Abstract: Forget and Rewire (FaR) methodology has demonstrated strong resilience
against Bit-Flip Attacks (BFAs) on Transformer-based models by obfuscating
critical parameters through dynamic rewiring of linear layers. However, the
application of FaR introduces non-negligible performance and memory overheads,
primarily due to the runtime modification of activation pathways and the lack
of hardware-level optimization. To overcome these limitations, we propose
FaRAccel, a novel hardware accelerator architecture implemented on FPGA,
specifically designed to offload and optimize FaR operations. FaRAccel
integrates reconfigurable logic for dynamic activation rerouting, and
lightweight storage of rewiring configurations, enabling low-latency inference
with minimal energy overhead. We evaluate FaRAccel across a suite of
Transformer models and demonstrate substantial reductions in FaR inference
latency and improvement in energy efficiency, while maintaining the robustness
gains of the original FaR methodology. To the best of our knowledge, this is
the first hardware-accelerated defense against BFAs in Transformers,
effectively bridging the gap between algorithmic resilience and efficient
deployment on real-world AI platforms.

</details>


### [24] [SLIP-SEC: Formalizing Secure Protocols for Model IP Protection](https://arxiv.org/abs/2510.24999)
*Racchit Jain,Satya Lokam,Yehonathan Refael,Adam Hakim,Lev Greenberg,Jay Tenenbaum*

Main category: cs.CR

TL;DR: SLIP是一个混合推理协议，通过在可信和不可信资源之间分割模型计算来保护LLM的知识产权，提供信息论安全保证。


<details>
  <summary>Details</summary>
Motivation: LLMs代表重要的知识产权，部署在部分可信或不安全设备上存在模型被盗风险，需要设计具有可证明安全保证的推理协议。

Method: 基于权重矩阵的加法分解，结合掩码和概率验证技术构建安全推理协议，在可信和不可信资源间分割计算。

Result: 协议实现了对诚实但好奇对手的信息论安全，并对恶意对手提供具有可忽略健全性错误的鲁棒性。

Conclusion: SLIP提供了保护LLM知识产权的理论基础，包括精确定义、形式化协议和安全证明，与配套论文共同构建了混合推理的完整安全框架。

Abstract: Large Language Models (LLMs) represent valuable intellectual property (IP),
reflecting significant investments in training data, compute, and expertise.
Deploying these models on partially trusted or insecure devices introduces
substantial risk of model theft, making it essential to design inference
protocols with provable security guarantees.
  We present the formal framework and security foundations of SLIP, a hybrid
inference protocol that splits model computation between a trusted and an
untrusted resource. We define and analyze the key notions of model
decomposition and hybrid inference protocols, and introduce formal properties
including safety, correctness, efficiency, and t-soundness. We construct secure
inference protocols based on additive decompositions of weight matrices,
combined with masking and probabilistic verification techniques. We prove that
these protocols achieve information-theoretic security against
honest-but-curious adversaries, and provide robustness against malicious
adversaries with negligible soundness error.
  This paper focuses on the theoretical underpinnings of SLIP: precise
definitions, formal protocols, and proofs of security. Empirical validation and
decomposition heuristics appear in the companion SLIP paper. Together, the two
works provide a complete account of securing LLM IP via hybrid inference,
bridging both practice and theory.

</details>


### [25] [Secure Retrieval-Augmented Generation against Poisoning Attacks](https://arxiv.org/abs/2510.25025)
*Zirui Cheng,Jikai Sun,Anjun Gao,Yueyang Quan,Zhuqing Liu,Xiaohua Hu,Minghong Fang*

Main category: cs.CR

TL;DR: RAGuard是一个检测框架，通过扩展检索范围、基于困惑度的过滤和文本相似性过滤来识别RAG系统中的中毒文本，有效防御数据投毒攻击。


<details>
  <summary>Details</summary>
Motivation: RAG系统虽然增强了LLMs的性能，但引入了数据投毒的安全风险，现有防御方法难以应对高级攻击。

Method: RAGuard采用三步法：扩展检索范围增加干净文本比例；基于困惑度的分块过滤检测异常变化；文本相似性过滤标记高度相似文本。

Result: 在大规模数据集上的实验表明，RAGuard能有效检测和缓解投毒攻击，包括强自适应攻击。

Conclusion: RAGuard提供了一种非参数化方法，显著提升了RAG系统的安全性，能够可靠地防御数据投毒威胁。

Abstract: Large language models (LLMs) have transformed natural language processing
(NLP), enabling applications from content generation to decision support.
Retrieval-Augmented Generation (RAG) improves LLMs by incorporating external
knowledge but also introduces security risks, particularly from data poisoning,
where the attacker injects poisoned texts into the knowledge database to
manipulate system outputs. While various defenses have been proposed, they
often struggle against advanced attacks. To address this, we introduce RAGuard,
a detection framework designed to identify poisoned texts. RAGuard first
expands the retrieval scope to increase the proportion of clean texts, reducing
the likelihood of retrieving poisoned content. It then applies chunk-wise
perplexity filtering to detect abnormal variations and text similarity
filtering to flag highly similar texts. This non-parametric approach enhances
RAG security, and experiments on large-scale datasets demonstrate its
effectiveness in detecting and mitigating poisoning attacks, including strong
adaptive attacks.

</details>


### [26] [AgentCyTE: Leveraging Agentic AI to Generate Cybersecurity Training & Experimentation Scenarios](https://arxiv.org/abs/2510.25189)
*Ana M. Rodriguez,Jaime Acosta,Anantaa Kotal,Aritran Piplai*

Main category: cs.CR

TL;DR: 提出了AgentCyTE框架，结合LLM推理与确定性网络仿真，通过反馈循环生成可执行的网络威胁场景，解决传统手动设计的挑战。


<details>
  <summary>Details</summary>
Motivation: 网络安全研究和训练中设计真实、自适应的网络威胁场景仍需要大量人工工作，现有LLM生成方法往往产生无法验证或执行的配置。

Method: 集成基于LLM的推理与确定性、模式约束的网络仿真，通过智能体反馈循环观察场景结果、验证正确性，并迭代提升真实性和一致性。

Result: 该混合方法在保持LLM灵活性的同时确保结构有效性，实现了可扩展的数据驱动实验和可靠的威胁建模场景生成。

Conclusion: AgentCyTE框架能够为自适应网络安全训练提供可靠的威胁场景生成，解决了LLM无约束生成导致的验证和执行问题。

Abstract: Designing realistic and adaptive networked threat scenarios remains a core
challenge in cybersecurity research and training, still requiring substantial
manual effort. While large language models (LLMs) show promise for automated
synthesis, unconstrained generation often yields configurations that fail
validation or execution. We present AgentCyTE, a framework integrating
LLM-based reasoning with deterministic, schema-constrained network emulation to
generate and refine executable threat environments. Through an agentic feedback
loop, AgentCyTE observes scenario outcomes, validates correctness, and
iteratively enhances realism and consistency. This hybrid approach preserves
LLM flexibility while enforcing structural validity, enabling scalable,
data-driven experimentation and reliable scenario generation for threat
modeling and adaptive cybersecurity training. Our framework can be accessed at:
https://github.com/AnantaaKotal/AgentCyTE

</details>


### [27] [Is Protective DNS Blocking the Wild West?](https://arxiv.org/abs/2510.25352)
*David Plonka,Branden Palacio,Debbie Perouli*

Main category: cs.CR

TL;DR: 对研究教育网络中保护性DNS服务的性能进行被动测量研究，发现现有DNS阻止列表在命名、目标、透明度和来源方面缺乏组织性，难以比较，在大规模运营中存在挑战和风险。


<details>
  <summary>Details</summary>
Motivation: 研究保护性DNS服务在研究教育网络中的实际性能表现，该网络服务于数百个成员机构，需要评估现有DNS阻止列表的有效性和可用性。

Method: 使用免费可用的DNS阻止列表（包含被认定为威胁的域名），对一周内观察到的数亿用户真实DNS查询进行测试，分析哪些查询会被阻止。

Result: 发现DNS阻止列表在命名、目标、透明度和来源方面缺乏组织性，难以进行比较，保护性DNS的基础设施缺乏有组织的监督。

Conclusion: 现有的保护性DNS基础设施在大规模运营中面临挑战和风险，需要更好的组织监督和标准化。

Abstract: We perform a passive measurement study investigating how a Protective DNS
service might perform in a Research & Education Network serving hundreds of
member institutions. Utilizing freely-available DNS blocklists consisting of
domain names deemed to be threats, we test hundreds of millions of users' real
DNS queries, observed over a week's time, to find which answers would be
blocked because they involve domain names that are potential threats. We find
the blocklists disorderly regarding their names, goals, transparency, and
provenance making them quite difficult to compare. Consequently, these
Protective DNS underpinnings lack organized oversight, presenting challenges
and risks in operation at scale.

</details>


### [28] [From ECU to VSOC: UDS Security Monitoring Strategies](https://arxiv.org/abs/2510.25375)
*Ali Recai Yekta,Nicolas Loza,Jens Gramm,Michael Peter Schneider,Stefan Katzenbeisser*

Main category: cs.CR

TL;DR: 提出了针对汽车UDS协议的安全监控策略，通过车载日志记录和远程VSOC分析来检测UDS攻击，评估了现有AUTOSAR标准在UDS攻击检测方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现代车辆复杂性和连接性的增加使其更容易受到网络攻击，特别是UDS协议作为车辆诊断的关键通信框架存在安全挑战。

Method: 制定安全事件日志记录要求、上下文数据收集和检测策略开发，应用于全面的UDS攻击技术分类体系。

Result: 检测方法覆盖了广泛的潜在攻击向量，同时识别出现有AUTOSAR标准化安全事件在支持UDS攻击检测方面的差距。

Conclusion: 这项工作增强了车辆安全监控的理解，为开发汽车通信协议的稳健网络安全措施提供了范例。

Abstract: Increasing complexity and connectivity of modern vehicles have heightened
their vulnerability to cyberattacks. This paper addresses security challenges
associated with the Unified Diagnostic Services (UDS) protocol, a critical
communication framework for vehicle diagnostics in the automotive industry. We
present security monitoring strategies for the UDS protocol that leverage
in-vehicle logging and remote analysis through a Vehicle Security Operations
Center (VSOC). Our approach involves specifying security event logging
requirements, contextual data collection, and the development of detection
strategies aimed at identifying UDS attack scenarios. By applying these
strategies to a comprehensive taxonomy of UDS attack techniques, we demonstrate
that our detection methods cover a wide range of potential attack vectors.
Furthermore, we assess the adequacy of current AUTOSAR standardized security
events in supporting UDS attack detection, identifying gaps in the current
standard. This work enhances the understanding of vehicle security monitoring
and provides an example for developing robust cybersecurity measures in
automotive communication protocols.

</details>


### [29] [An In-Depth Analysis of Cyber Attacks in Secured Platforms](https://arxiv.org/abs/2510.25470)
*Parick Ozoh,John K Omoniyi,Bukola Ibitoye*

Main category: cs.CR

TL;DR: 该论文综述了Android系统中恶意威胁检测的机器学习技术，比较了不同方法的性能表现，并指出当前方法面临数据需求量大、难以开发专门化反恶意软件系统的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着全球恶意软件威胁增加，特别是Android系统上的加密型勒索软件，手机恶意威胁已成为移动通信中的紧迫问题，破坏用户体验并构成严重隐私威胁。

Method: 调查了常用的手机恶意威胁检测机器学习技术，并检验其性能。使用Android应用程序数据集，通过准确率等度量标准来评估技术效果。

Result: 研究发现大多数现有研究关注客户反馈和评论，但这些可能包含虚假评论。机器学习技术被证明可用于检测恶意威胁，但需要大量信息。

Conclusion: 虽然机器学习技术在恶意威胁检测方面显示出潜力，但开发稳健、专门化的自动化反恶意软件系统仍面临数据需求量大等挑战。

Abstract: There is an increase in global malware threats. To address this, an
encryption-type ransomware has been introduced on the Android operating system.
The challenges associated with malicious threats in phone use have become a
pressing issue in mobile communication, disrupting user experiences and posing
significant privacy threats. This study surveys commonly used machine learning
techniques for detecting malicious threats in phones and examines their
performance. The majority of past research focuses on customer feedback and
reviews, with concerns that people might create false reviews to promote or
devalue products and services for personal gain. Hence, the development of
techniques for detecting malicious threats using machine learning has been a
key focus. This paper presents a comprehensive comparative study of current
research on the issue of malicious threats and methods for tackling these
challenges. Nevertheless, a huge amount of information is required by these
methods, presenting a challenge for developing robust, specialized automated
anti-malware systems. This research describes the Android Applications dataset,
and the accuracy of the techniques is measured using the accuracy levels of the
metrics employed in this study.

</details>


### [30] [NetEcho: From Real-World Streaming Side-Channels to Full LLM Conversation Recovery](https://arxiv.org/abs/2510.25472)
*Zheng Zhang,Guanlong Wu,Sen Deng,Shuai Wang,Yinqian Zhang*

Main category: cs.CR

TL;DR: NetEcho是一个基于LLM的框架，能够从加密网络流量中恢复LLM应用中的完整对话内容，即使在现有防御措施下仍能恢复约70%的对话信息。


<details>
  <summary>Details</summary>
Motivation: 随着LLM应用实时输出流成为主流交互模式，研究发现网络侧信道暴露了严重的安全漏洞，攻击者可通过加密流量模式推断敏感信息并重建私人对话。

Method: 首先系统分析主流LLM应用的侧信道防御措施，然后开发NetEcho框架，利用LLM技术从加密网络流量中高保真地恢复用户提示和LLM响应。

Result: 在医疗和法律应用的评估中，NetEcho能够从DeepSeek-v3和GPT-4o等领先模型的加密流量中平均恢复约70%的对话信息。

Conclusion: 当前防御机制存在关键局限性，需要加强网络流量安全以应对侧信道攻击风险。

Abstract: In the rapidly expanding landscape of Large Language Model (LLM)
applications, real-time output streaming has become the dominant interaction
paradigm. While this enhances user experience, recent research reveals that it
exposes a non-trivial attack surface through network side-channels. Adversaries
can exploit patterns in encrypted traffic to infer sensitive information and
reconstruct private conversations. In response, LLM providers and third-party
services are deploying defenses such as traffic padding and obfuscation to
mitigate these vulnerabilities.
  This paper starts by presenting a systematic analysis of contemporary
side-channel defenses in mainstream LLM applications, with a focus on services
from vendors like OpenAI and DeepSeek. We identify and examine seven
representative deployment scenarios, each incorporating active/passive
mitigation techniques. Despite these enhanced security measures, our
investigation uncovers significant residual information that remains vulnerable
to leakage within the network traffic.
  Building on this discovery, we introduce NetEcho, a novel, LLM-based
framework that comprehensively unleashes the network side-channel risks of
today's LLM applications. NetEcho is designed to recover entire conversations
-- including both user prompts and LLM responses -- directly from encrypted
network traffic. It features a deliberate design that ensures high-fidelity
text recovery, transferability across different deployment scenarios, and
moderate operational cost. In our evaluations on medical and legal applications
built upon leading models like DeepSeek-v3 and GPT-4o, NetEcho can recover avg
$\sim$70\% information of each conversation, demonstrating a critical
limitation in current defense mechanisms. We conclude by discussing the
implications of our findings and proposing future directions for augmenting
network traffic security.

</details>


### [31] [A Study on Privacy-Preserving Scholarship Evaluation Based on Decentralized Identity and Zero-Knowledge Proofs](https://arxiv.org/abs/2510.25477)
*Yi Chen,Bin Chen,Peichang Zhang,Da Che*

Main category: cs.CR

TL;DR: 提出基于去中心化身份和零知识证明的奖学金评估系统，解决传统集中式评估中的数据隐私泄露和透明度不足问题。


<details>
  <summary>Details</summary>
Motivation: 传统集中式奖学金评估需要学生提交详细学术记录，存在数据泄露和滥用的风险，难以同时保证隐私保护和透明审计。

Method: 系统在链下聚合多维零知识证明，智能合约验证评估标准合规性而不暴露原始分数或计算细节。

Result: 实验结果表明该方案能高效自动化评估，同时最大程度保护学生隐私和数据完整性。

Conclusion: 为高等教育奖学金项目提供了一个实用且可信赖的技术范式。

Abstract: Traditional centralized scholarship evaluation processes typically require
students to submit detailed academic records and qualification information,
which exposes them to risks of data leakage and misuse, making it difficult to
simultaneously ensure privacy protection and transparent auditability. To
address these challenges, this paper proposes a scholarship evaluation system
based on Decentralized Identity (DID) and Zero-Knowledge Proofs (ZKP). The
system aggregates multidimensional ZKPs off-chain, and smart contracts verify
compliance with evaluation criteria without revealing raw scores or
computational details. Experimental results demonstrate that the proposed
solution not only automates the evaluation efficiently but also maximally
preserves student privacy and data integrity, offering a practical and
trustworthy technical paradigm for higher education scholarship programs.

</details>


### [32] [ZK-SenseLM: Verifiable Large-Model Wireless Sensing with Selective Abstention and Zero-Knowledge Attestation](https://arxiv.org/abs/2510.25677)
*Hasan Akgul,Mari Eplik,Javier Rojas,Aina Binti Abdullah,Pieter van der Merwe*

Main category: cs.CR

TL;DR: ZK-SenseLM是一个安全可审计的无线感知框架，结合大型模型编码器与策略决策层，提供端到端的零知识推理证明。


<details>
  <summary>Details</summary>
Motivation: 为了解决无线感知系统中的安全问题，确保推理过程的可审计性和防止篡改，同时保持系统的高性能。

Method: 使用掩码频谱预训练和相位一致性正则化，结合轻量级跨模态对齐，添加校准选择性弃权头，实现四阶段证明管道和微批量证明。

Result: 在多个感知任务中提高了macro-F1和校准性能，在扰动下获得有利的覆盖-风险曲线，能够以紧凑证明和快速验证拒绝篡改和重放攻击。

Conclusion: ZK-SenseLM成功实现了安全、可审计的无线感知系统，在保持高性能的同时提供了强大的安全保障。

Abstract: ZK-SenseLM is a secure and auditable wireless sensing framework that pairs a
large-model encoder for Wi-Fi channel state information (and optionally mmWave
radar or RFID) with a policy-grounded decision layer and end-to-end
zero-knowledge proofs of inference. The encoder uses masked spectral
pretraining with phase-consistency regularization, plus a light cross-modal
alignment that ties RF features to compact, human-interpretable policy tokens.
To reduce unsafe actions under distribution shift, we add a calibrated
selective-abstention head; the chosen risk-coverage operating point is
registered and bound into the proof. We implement a four-stage proving
pipeline: (C1) feature sanity and commitment, (C2) threshold and version
binding, (C3) time-window binding, and (C4) PLONK-style proofs that the
quantized network, given the committed window, produced the logged action and
confidence. Micro-batched proving amortizes cost across adjacent windows, and a
gateway option offloads proofs from low-power devices. The system integrates
with differentially private federated learning and on-device personalization
without weakening verifiability: model hashes and the registered threshold are
part of each public statement. Across activity, presence or intrusion,
respiratory proxy, and RF fingerprinting tasks, ZK-SenseLM improves macro-F1
and calibration, yields favorable coverage-risk curves under perturbations, and
rejects tamper and replay with compact proofs and fast verification.

</details>


### [33] [Model Inversion Attacks Meet Cryptographic Fuzzy Extractors](https://arxiv.org/abs/2510.25687)
*Mallika Prabhakar,Louise Xu,Prateek Saxena*

Main category: cs.CR

TL;DR: 该论文提出了针对机器学习模型反演攻击的防御方案L2FE-Hash，这是首个支持欧几里得距离比较器的模糊提取器，能够有效保护人脸认证系统免受数据泄露时的模型反演攻击。


<details>
  <summary>Details</summary>
Motivation: 模型反演攻击对隐私敏感的机器学习应用构成严重威胁，特别是在人脸认证系统中，如果嵌入向量泄露，攻击者可以准确重构用户面部图像。现有防御方案缺乏系统性特征，且现有模糊提取器在基于ML的人脸认证中不安全。

Method: 首先形式化了防御模型反演攻击所需的属性，并将其与密码学中的模糊提取器概念联系起来。提出了新的模型反演攻击PIPE来证明现有方案的不安全性，然后设计了L2FE-Hash模糊提取器，支持标准欧几里得距离比较器。

Result: PIPE攻击对现有方案的攻击成功率超过89%。L2FE-Hash在计算安全性方面具有形式化保证，在实用人脸分布下保持可用精度，能够完全抵御现有最先进的反演攻击和PIPE攻击。

Conclusion: L2FE-Hash是首个适用于基于ML的人脸认证系统的安全模糊提取器，提供了攻击无关的安全性，无需重新训练受保护的ML模型，在完全泄露存储秘密的极端威胁模型下仍能保持安全。

Abstract: Model inversion attacks pose an open challenge to privacy-sensitive
applications that use machine learning (ML) models. For example, face
authentication systems use modern ML models to compute embedding vectors from
face images of the enrolled users and store them. If leaked, inversion attacks
can accurately reconstruct user faces from the leaked vectors. There is no
systematic characterization of properties needed in an ideal defense against
model inversion, even for the canonical example application of a face
authentication system susceptible to data breaches, despite a decade of
best-effort solutions.
  In this paper, we formalize the desired properties of a provably strong
defense against model inversion and connect it, for the first time, to the
cryptographic concept of fuzzy extractors. We further show that existing fuzzy
extractors are insecure for use in ML-based face authentication. We do so
through a new model inversion attack called PIPE, which achieves a success rate
of over 89% in most cases against prior schemes. We then propose L2FE-Hash, the
first candidate fuzzy extractor which supports standard Euclidean distance
comparators as needed in many ML-based applications, including face
authentication. We formally characterize its computational security guarantees,
even in the extreme threat model of full breach of stored secrets, and
empirically show its usable accuracy in face authentication for practical face
distributions. It offers attack-agnostic security without requiring any
re-training of the ML model it protects. Empirically, it nullifies both prior
state-of-the-art inversion attacks as well as our new PIPE attack.

</details>


### [34] [Exact zCDP Characterizations for Fundamental Differentially Private Mechanisms](https://arxiv.org/abs/2510.25746)
*Charlie Harrison,Pasin Manurangsi*

Main category: cs.CR

TL;DR: 本文推导了多种基础差分隐私机制在零集中差分隐私(zCDP)下的紧致边界，包括拉普拉斯机制、离散拉普拉斯机制、k-随机响应和RAPPOR，并证明了拉普拉斯机制的确切zCDP边界为ε + e^{-ε} - 1。


<details>
  <summary>Details</summary>
Motivation: 虽然存在从ε-DP到zCDP的最坏情况转换，但许多常见算法满足更强的保证，需要为基本机制提供精确的zCDP特征化。

Method: 通过数学推导和分析，为拉普拉斯机制、离散拉普拉斯机制、k-随机响应(k≤6)和RAPPOR等基础机制提供紧致的zCDP边界。

Result: 证明了拉普拉斯机制的紧致zCDP边界为ε + e^{-ε} - 1，确认了Wang(2022)的猜想；同时为其他机制提供了精确的zCDP边界。

Conclusion: 这项工作为基础差分隐私机制提供了精确的zCDP特征化，有助于更好地理解和应用zCDP框架下的隐私保护机制。

Abstract: Zero-concentrated differential privacy (zCDP) is a variant of differential
privacy (DP) that is widely used partly thanks to its nice composition
property. While a tight conversion from $\epsilon$-DP to zCDP exists for the
worst-case mechanism, many common algorithms satisfy stronger guarantees. In
this work, we derive tight zCDP characterizations for several fundamental
mechanisms. We prove that the tight zCDP bound for the $\epsilon$-DP Laplace
mechanism is exactly $\epsilon + e^{-\epsilon} - 1$, confirming a recent
conjecture by Wang (2022). We further provide tight bounds for the discrete
Laplace mechanism, $k$-Randomized Response (for $k \leq 6$), and RAPPOR.
Lastly, we also provide a tight zCDP bound for the worst case bounded range
mechanism.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [35] [Scheduling Your LLM Reinforcement Learning with Reasoning Trees](https://arxiv.org/abs/2510.24832)
*Hong Wang,Zhezheng Hao,Jian Luo,Chenxing Wei,Yao Shu,Lei Liu,Qiang Lin,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: 本文提出了一种基于推理树结构的新调度方法Re-Schedule，通过r-score指标衡量查询的学习难度，在六个数学推理基准上平均准确率提升高达3.2%。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR数据调度方法通常依赖基于路径的指标来排序查询，忽略了这些查询的推理树结构，导致调度效果受限。

Method: 引入推理分数(r-score)指标，基于推理树结构衡量查询的学习难度；提出推理树调度(Re-Schedule)算法，构建从结构简单(高r-score)到复杂(低r-score)查询的课程学习进度。

Result: 在六个数学推理基准上的实验表明，Re-Schedule显著提高了平均准确率，增益高达3.2%。

Conclusion: 结果表明，对推理树结构的理解为RLVR数据调度提供了更强大和原则性的基础。

Abstract: Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large
Language Models (LLMs) can be conceptualized as progressively editing a query's
`Reasoning Tree'. This process involves exploring nodes (tokens) and
dynamically modifying the model's policy at each node. When combined with data
scheduling, this process yields further gains in data efficiency and accuracy.
However, existing RLVR data scheduling methods typically rely on path-based
metrics to rank queries, overlooking the reasoning tree structures of these
queries. In this paper, we introduce a novel metric, namely Reasoning Score
(r-score), which measures the query's learning difficulty based on the
structure of its reasoning tree. Based on the r-score, we propose the Reasoning
Tree Schedule (Re-Schedule), a scheduling algorithm that constructs a
curriculum progressing from structurally simple (high r-score) to complex (low
r-score) queries. Experiments on six math-reasoning benchmarks show that
Re-Schedule significantly improves average accuracy, achieving gains of up to
3.2%. These strong results validate our approach and demonstrate that a
structural understanding of the reasoning tree provides a more powerful and
principled foundation for RLVR data scheduling.

</details>


### [36] [Cyclic Counterfactuals under Shift-Scale Interventions](https://arxiv.org/abs/2510.25005)
*Saptarshi Saha,Dhruv Vansraj Rathore,Utpal Garain*

Main category: cs.AI

TL;DR: 研究循环结构因果模型中的反事实推断，关注移位-尺度干预下的政策式变化


<details>
  <summary>Details</summary>
Motivation: 传统反事实推断框架假设无环结构因果模型，但现实系统（如生物系统）常包含反馈循环或循环依赖，违反无环性假设

Method: 在循环结构因果模型中研究反事实推断，特别关注移位-尺度干预（即软性、政策式变化，重新缩放和/或移动变量的机制）

Result: 论文提出了在循环系统中处理反事实推断的方法，但摘要中未提供具体结果数据

Conclusion: 需要扩展反事实推断框架以处理包含循环依赖的现实系统，移位-尺度干预为这类系统提供了实用的建模方法

Abstract: Most counterfactual inference frameworks traditionally assume acyclic
structural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However,
many real-world systems (e.g. biological systems) contain feedback loops or
cyclic dependencies that violate acyclicity. In this work, we study
counterfactual inference in cyclic SCMs under shift-scale interventions, i.e.,
soft, policy-style changes that rescale and/or shift a variable's mechanism.

</details>


### [37] [Taming the Real-world Complexities in CPT E/M Coding with Large Language Models](https://arxiv.org/abs/2510.25007)
*Islam Nassar,Yang Lin,Yuan Jin,Rongxin Zhu,Chang Wei Tan,Zenan Zhai,Nitika Mathur,Thanh Tien Vu,Xu Zhong,Long Duong,Yuan-Fang Li*

Main category: cs.AI

TL;DR: ProFees是一个基于LLM的框架，用于自动化医疗评估和管理(E/M)编码任务，在真实数据集上比商业系统提高36%以上的编码准确率。


<details>
  <summary>Details</summary>
Motivation: 自动化E/M编码可以减轻医生的文档负担，提高计费效率，最终实现更好的患者护理。

Method: 使用基于LLM的ProFees框架来处理现实世界中的复杂性问题，包括多提示策略。

Result: 在专家策划的真实数据集上，ProFees比商业CPT E/M编码系统提高36%以上的准确率，比最强的单提示基线提高近5%。

Conclusion: ProFees框架能有效解决现实世界中的复杂性问题，显著提高E/M编码的准确性。

Abstract: Evaluation and Management (E/M) coding, under the Current Procedural
Terminology (CPT) taxonomy, documents medical services provided to patients by
physicians. Used primarily for billing purposes, it is in physicians' best
interest to provide accurate CPT E/M codes. %While important, it is an
auxiliary task that adds to physicians' documentation burden. Automating this
coding task will help alleviate physicians' documentation burden, improve
billing efficiency, and ultimately enable better patient care. However, a
number of real-world complexities have made E/M encoding automation a
challenging task. In this paper, we elaborate some of the key complexities and
present ProFees, our LLM-based framework that tackles them, followed by a
systematic evaluation. On an expert-curated real-world dataset, ProFees
achieves an increase in coding accuracy of more than 36\% over a commercial CPT
E/M coding system and almost 5\% over our strongest single-prompt baseline,
demonstrating its effectiveness in addressing the real-world complexities.

</details>


### [38] [Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading](https://arxiv.org/abs/2510.25014)
*Minkyung Kim,Junsik Kim,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: 提出了Autoregressive State-Tracking Prompting (ASTP)方法，通过显式状态追踪和占位符后处理，解决LLM在游戏交易系统中遵循程序流程的问题，实现>99%状态合规性和99.3%计算精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在动态游戏交互中表现出色，但无法遵循规则治理交易系统的基本程序流程（浏览-报价-审查-确认），这会削弱玩家信任。

Method: 引入ASTP方法，通过精心设计的提示迫使LLM使其状态追踪过程显式化和可验证，结合状态特定的占位符后处理方法确保交易完整性。

Result: 在300个交易对话评估中，实现>99%状态合规性和99.3%计算精度。小模型(Gemini-2.5-Flash)通过ASTP匹配大模型性能，响应时间从21.2秒降至2.4秒。

Conclusion: ASTP为商业游戏建立了实用基础，同时满足实时需求和资源约束，解决了LLM创造性灵活性与程序性需求之间的核心矛盾。

Abstract: Large Language Models (LLMs) enable dynamic game interactions but fail to
follow essential procedural flows in rule-governed trading systems, eroding
player trust. This work resolves the core tension between the creative
flexibility of LLMs and the procedural demands of in-game trading
(browse-offer-review-confirm). To this end, Autoregressive State-Tracking
Prompting (ASTP) is introduced, a methodology centered on a strategically
orchestrated prompt that compels an LLM to make its state-tracking process
explicit and verifiable. Instead of relying on implicit contextual
understanding, ASTP tasks the LLM with identifying and reporting a predefined
state label from the previous turn. To ensure transactional integrity, this is
complemented by a state-specific placeholder post-processing method for
accurate price calculations. Evaluation across 300 trading dialogues
demonstrates >99% state compliance and 99.3% calculation precision. Notably,
ASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash)
matches larger models' (Gemini-2.5-Pro) performance while reducing response
time from 21.2s to 2.4s, establishing a practical foundation that satisfies
both real-time requirements and resource constraints of commercial games.

</details>


### [39] [Reasoning-Aware GRPO using Process Mining](https://arxiv.org/abs/2510.25065)
*Taekhyun Park,Yongjae Lee,Hyerim Bae*

Main category: cs.AI

TL;DR: 提出了PM4GRPO方法，通过过程挖掘技术增强推理感知的组相对策略优化，显著提升大型推理模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的后训练方法主要关注结果奖励，缺乏对推理过程的监督，需要更全面的推理感知奖励方案。

Method: 使用过程挖掘技术计算一致性奖励，衡量策略模型推理过程与预训练教师模型的匹配程度，结合标准答案/格式奖励进行组相对策略优化。

Result: 在五个基准测试中，PM4GRPO显著优于现有的GRPO后训练方法，证明了推理感知奖励的有效性。

Conclusion: 利用过程挖掘进行推理感知的GRPO能够有效提升策略模型的推理能力，为大型推理模型的后训练提供了新方向。

Abstract: Reinforcement learning (RL)-based post-training has been crucial for enabling
multi-step reasoning in large reasoning models (LRMs), yet current reward
schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware
Group Relative Policy Optimization (GRPO) that augments standard answer/format
rewards with signals over the reasoning procedure. To this end, process mining
techniques are utilized to compute a scalar conformance reward that measures
how closely a policy model's reasoning aligns with the pretrained teacher
model. The empirical results on five benchmarks demonstrate that PM4GRPO
significantly outperforms existing methodologies for GRPO-based post-training.
These results highlight that leveraging process mining for reasoning-aware GRPO
effectively enhances the reasoning capabilities of policy models.

</details>


### [40] [H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and Style-Structured Mixture of Experts](https://arxiv.org/abs/2510.25091)
*Peilin Tan,Liang Xie,Churan Zhi,Dian Tu,Chuanqi Shi*

Main category: cs.AI

TL;DR: H3M-SSMoEs是一个基于超图的多模态股票预测框架，结合LLM推理和风格结构混合专家，在三个主要股票市场上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 股票预测面临复杂的时间依赖、多模态异质性和动态变化的股票间关系等挑战，现有方法难以在可扩展框架内统一结构、语义和机制自适应建模。

Method: 提出三个关键创新：(1)多上下文多模态超图，通过局部和全局上下文超图分层捕获时空动态；(2)LLM增强推理模块，利用冻结大语言模型融合定量和文本模态；(3)风格结构混合专家，结合共享市场专家和行业专业专家。

Result: 在三个主要股票市场的广泛实验表明，H3M-SSMoEs在预测准确性和投资性能方面均优于最先进方法，并展现出有效的风险控制。

Conclusion: 该工作成功解决了股票预测中的关键挑战，提供了一个统一、可扩展且性能优越的解决方案。

Abstract: Stock movement prediction remains fundamentally challenging due to complex
temporal dependencies, heterogeneous modalities, and dynamically evolving
inter-stock relationships. Existing approaches often fail to unify structural,
semantic, and regime-adaptive modeling within a scalable framework. This work
introduces H3M-SSMoEs, a novel Hypergraph-based MultiModal architecture with
LLM reasoning and Style-Structured Mixture of Experts, integrating three key
innovations: (1) a Multi-Context Multimodal Hypergraph that hierarchically
captures fine-grained spatiotemporal dynamics via a Local Context Hypergraph
(LCH) and persistent inter-stock dependencies through a Global Context
Hypergraph (GCH), employing shared cross-modal hyperedges and Jensen-Shannon
Divergence weighting mechanism for adaptive relational learning and cross-modal
alignment; (2) a LLM-enhanced reasoning module, which leverages a frozen large
language model with lightweight adapters to semantically fuse and align
quantitative and textual modalities, enriching representations with
domain-specific financial knowledge; and (3) a Style-Structured Mixture of
Experts (SSMoEs) that combines shared market experts and industry-specialized
experts, each parameterized by learnable style vectors enabling regime-aware
specialization under sparse activation. Extensive experiments on three major
stock markets demonstrate that H3M-SSMoEs surpasses state-of-the-art methods in
both superior predictive accuracy and investment performance, while exhibiting
effective risk control. Datasets, source code, and model weights are available
at our GitHub repository: https://github.com/PeilinTime/H3M-SSMoEs.

</details>


### [41] [KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA](https://arxiv.org/abs/2510.25101)
*Zhuo Chen,Fei Wang,Zixuan Li,Zhao Zhang,Weiwei Ding,Chuanguang Yang,Yongjun Xu,Xiaolong Jin,Jiafeng Guo*

Main category: cs.AI

TL;DR: KnowCoder-A1是一个基于多阶段课程强化学习的LLM，通过结果监督训练，在知识库问答任务中实现自主代理推理，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有KBQA方法通常通过过程监督微调LLMs，但这种方法对探索的激励较弱，无法有效增强代理推理能力。

Method: 采用多阶段课程强化学习：1）首先在高质量轨迹上微调LLM建立基础能力；2）应用从易到难的奖励调度来缓解结果监督中的奖励稀疏问题。

Result: 在三个主流数据集上持续优于先前方法，在GrailQA零样本子集上相对提升达11.1%，且仅使用十二分之一的训练数据。

Conclusion: 基于结果监督训练的KnowCoder-A1展现出强大的推理行为，证明了其在知识库问答中的有效代理推理能力。

Abstract: Knowledge Base Question Answering (KBQA) aims to answer natural-language
questions over a structured Knowledge Base (KB). Recent work improves KBQA by
adopting an agentic reasoning paradigm, in which Large Language Models (LLMs)
iteratively decompose a question, generate its corresponding logical queries,
and interact with the KB to derive the answer. However, these methods typically
fine-tune LLMs on reasoning trajectories synthesized via process supervision,
which offers weak incentives for exploration and thus fails to strengthen the
agentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that
can autonomously perform agentic reasoning on KBs to obtain answers. To
incentivize autonomous exploration, KnowCoder-A1 trains the LLM under
outcome-only supervision via a multi-stage curriculum reinforcement learning
with an easy-to-hard curriculum. To establish foundational agentic
capabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of
high-quality trajectories obtained through outcome-based rejection sampling.
Then, to alleviate the reward sparsity inherent in outcome-only supervision, it
applies multi-stage curriculum RL with reward schedules that progress from easy
to hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful
reasoning behaviors and consistently outperforms prior approaches across three
mainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1
achieves up to an 11.1% relative improvement while using only one-twelfth of
the training data, demonstrating strong agentic reasoning capabilities.

</details>


### [42] [Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models](https://arxiv.org/abs/2510.25179)
*Juan Ren,Mark Dras,Usman Naseem*

Main category: cs.AI

TL;DR: 提出Agentic Moderation框架，使用专门代理来防御多模态系统的越狱攻击，相比静态方法能动态协作实现上下文感知和可解释的审核


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法通常作为静态层应用于输入或输出，只能提供二元分类（安全/不安全），缺乏动态性和可解释性

Method: 引入动态协作代理框架，包括Shield、Responder、Evaluator和Reflector等专门代理，实现模型无关的多模态系统安全防御

Result: 在5个数据集和4个大型视觉语言模型上的实验表明，攻击成功率降低7-19%，拒绝率提高4-20%，保持稳定的不遵循率

Conclusion: Agentic Moderation通过利用代理架构的灵活性和推理能力，提供了模块化、可扩展和细粒度的安全执行，展示了代理系统作为自动安全治理基础的潜力

Abstract: Agentic methods have emerged as a powerful and autonomous paradigm that
enhances reasoning, collaboration, and adaptive control, enabling systems to
coordinate and independently solve complex tasks. We extend this paradigm to
safety alignment by introducing Agentic Moderation, a model-agnostic framework
that leverages specialised agents to defend multimodal systems against
jailbreak attacks. Unlike prior approaches that apply as a static layer over
inputs or outputs and provide only binary classifications (safe or unsafe), our
method integrates dynamic, cooperative agents, including Shield, Responder,
Evaluator, and Reflector, to achieve context-aware and interpretable
moderation. Extensive experiments across five datasets and four representative
Large Vision-Language Models (LVLMs) demonstrate that our approach reduces the
Attack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF),
and improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable,
and well-balanced safety performance. By harnessing the flexibility and
reasoning capacity of agentic architectures, Agentic Moderation provides
modular, scalable, and fine-grained safety enforcement, highlighting the
broader potential of agentic systems as a foundation for automated safety
governance.

</details>


### [43] [Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision](https://arxiv.org/abs/2510.25205)
*Yuyang Xia,Zibo Liang,Liwei Deng,Yan Zhao,Han Su,Kai Zheng*

Main category: cs.AI

TL;DR: EneAD是一个节能自动驾驶框架，通过自适应感知模块和鲁棒决策模块，在保持感知精度的同时显著降低计算能耗，提升电动汽车续航里程。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶技术带来社会经济效益的同时，计算引擎能耗急剧上升，特别是感知计算作为最耗电的组件，限制了电动汽车的续航里程。现有模型压缩方法要么导致模型过大，要么感知精度显著下降。

Method: 提出EneAD框架：1）自适应感知模块通过数据管理和调优策略，管理多个不同计算消耗的感知模型，动态调整执行帧率；2）基于贝叶斯优化的可转移调优方法寻找最优参数配置；3）轻量级分类模型区分不同场景的感知难度；4）鲁棒决策模块基于强化学习设计决策模型，增强对扰动感知结果的稳定性。

Result: 实验证明EneAD在能耗和驾驶性能方面具有优越性，能够将感知消耗降低1.9倍至3.5倍，从而将驾驶里程提升3.9%至8.5%。

Conclusion: EneAD框架通过自适应感知和鲁棒决策的协同设计，有效解决了自动驾驶系统能耗与精度之间的权衡问题，为节能自动驾驶提供了可行方案。

Abstract: Autonomous driving is an emerging technology that is expected to bring
significant social, economic, and environmental benefits. However, these
benefits come with rising energy consumption by computation engines, limiting
the driving range of vehicles, especially electric ones. Perception computing
is typically the most power-intensive component, as it relies on largescale
deep learning models to extract environmental features. Recently, numerous
studies have employed model compression techniques, such as sparsification,
quantization, and distillation, to reduce computational consumption. However,
these methods often result in either a substantial model size or a significant
drop in perception accuracy compared to high-computation models. To address
these challenges, we propose an energy-efficient autonomous driving framework,
called EneAD. In the adaptive perception module, a perception optimization
strategy is designed from the perspective of data management and tuning.
Firstly, we manage multiple perception models with different computational
consumption and adjust the execution framerate dynamically. Then, we define
them as knobs and design a transferable tuning method based on Bayesian
optimization to identify promising knob values that achieve low computation
while maintaining desired accuracy. To adaptively switch the knob values in
various traffic scenarios, a lightweight classification model is proposed to
distinguish the perception difficulty in different scenarios. In the robust
decision module, we propose a decision model based on reinforcement learning
and design a regularization term to enhance driving stability in the face of
perturbed perception results. Extensive experiments evidence the superiority of
our framework in both energy consumption and driving performance. EneAD can
reduce perception consumption by 1.9x to 3.5x and thus improve driving range by
3.9% to 8.5%

</details>


### [44] [RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models](https://arxiv.org/abs/2510.25206)
*Tianqianjin Lin,Xi Zhao,Xingyao Zhang,Rujiao Long,Yi Xu,Zhuoren Jiang,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: 提出RAVR框架，利用答案引导的推理作为变分代理，通过条件化答案来提升推理路径质量，解决LLM在复杂任务中难以采样高质量推理路径的问题。


<details>
  <summary>Details</summary>
Motivation: 当LLM无法生成高质量推理路径时，强化学习会强化次优推理。受认知科学启发，"为什么是这个答案"比"答案是什么"更容易回答，因为避免了开放式探索的认知负担。

Method: 引入RAVR框架，使用答案条件化推理作为问题推理的变分代理，通过条件化答案来提升推理路径的期望效用。

Result: 在通用和数学领域的实验中，RAVR相比强基线模型表现出一致的改进，减少了犹豫，加强了结论整合，并促进了问题特定策略。

Conclusion: 答案引导的推理能够有效提升LLM的推理能力，将难以处理的问题转化为可学习的问题，为复杂推理任务提供了新的解决方案。

Abstract: Reinforcement learning (RL) can refine the reasoning abilities of large
language models (LLMs), but critically depends on a key prerequisite: the LLM
can already generate high-utility reasoning paths with non-negligible
probability. For tasks beyond the LLM's current competence, such reasoning path
can be hard to sample, and learning risks reinforcing familiar but suboptimal
reasoning. We are motivated by the insight from cognitive science that Why is
this the answer is often an easier question than What is the answer, as it
avoids the heavy cognitive load of open-ended exploration, opting instead for
explanatory reconstruction-systematically retracing the reasoning that links a
question to its answer. We show that LLMs can similarly leverage answers to
derive high-quality reasoning paths. We formalize this phenomenon and prove
that conditioning on answer provably increases the expected utility of sampled
reasoning paths, thereby transforming intractable problems into learnable ones.
Building on this insight, we introduce RAVR (Reference-Answer-guided
Variational Reasoning), an end-to-end framework that uses answer-conditioned
reasoning as a variational surrogate for question-only reasoning. Experiments
in both general and math domains demonstrate consistent improvements over
strong baselines. We further analyze the reasoning behavior and find that RAVR
reduces hesitation, strengthens conclusion consolidation, and promotes
problem-specific strategies in reasoning.

</details>


### [45] [FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data](https://arxiv.org/abs/2510.25223)
*Kun ouyang,Haoyu Wang,Dong Fang*

Main category: cs.AI

TL;DR: FELA是一个基于LLM的多代理进化系统，用于从复杂的工业事件日志数据中自动提取高性能特征。它结合了LLM的推理编码能力和洞察引导的自进化范式，通过专门代理协作生成、验证和实施特征创意。


<details>
  <summary>Details</summary>
Motivation: 工业事件日志数据具有大规模、高维度、异构数据等复杂性，现有自动特征工程方法存在可解释性差、操作僵化、适应性弱等问题。

Method: 采用多代理系统（创意代理、代码代理、批评代理、评估代理）协作，结合强化学习和遗传算法原理的代理进化算法，以及分层知识库和双记忆系统实现持续改进。

Result: 在真实工业数据集上的实验表明，FELA能生成可解释、领域相关的特征，显著提升模型性能并减少人工工作量。

Conclusion: 基于LLM的多代理系统有望成为复杂现实环境中自动化、可解释和自适应特征工程的通用框架。

Abstract: Event log data, recording fine-grained user actions and system events,
represent one of the most valuable assets for modern digital services. However,
the complexity and heterogeneity of industrial event logs--characterized by
large scale, high dimensionality, diverse data types, and intricate temporal or
relational structures--make feature engineering extremely challenging. Existing
automatic feature engineering approaches, such as AutoML or genetic methods,
often suffer from limited explainability, rigid predefined operations, and poor
adaptability to complicated heterogeneous data. In this paper, we propose FELA
(Feature Engineering LLM Agents), a multi-agent evolutionary system that
autonomously extracts meaningful and high-performing features from complex
industrial event log data. FELA integrates the reasoning and coding
capabilities of large language models (LLMs) with an insight-guided
self-evolution paradigm. Specifically, FELA employs specialized agents--Idea
Agents, Code Agents, and Critic Agents--to collaboratively generate, validate,
and implement novel feature ideas. An Evaluation Agent summarizes feedback and
updates a hierarchical knowledge base and dual-memory system to enable
continual improvement. Moreover, FELA introduces an agentic evolution
algorithm, combining reinforcement learning and genetic algorithm principles to
balance exploration and exploitation across the idea space. Extensive
experiments on real industrial datasets demonstrate that FELA can generate
explainable, domain-relevant features that significantly improve model
performance while reducing manual effort. Our results highlight the potential
of LLM-based multi-agent systems as a general framework for automated,
interpretable, and adaptive feature engineering in complex real-world
environments.

</details>


### [46] [From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity](https://arxiv.org/abs/2510.25232)
*Tianxi Wan,Jiaming Luo,Siyuan Chen,Kunyao Lan,Jianhua Chen,Haiyang Geng,Mengyue Wu*

Main category: cs.AI

TL;DR: 开发了PsyCoTalk，首个支持共病诊断的大规模对话数据集，包含3000个多轮诊断对话，通过合成电子病历和多智能体框架构建，经精神科医生验证具有临床真实性。


<details>
  <summary>Details</summary>
Motivation: 精神疾病共病具有临床重要性但诊断复杂，需要处理多种共存的障碍，现有资源不足支持多障碍同时筛查。

Method: 集成合成患者电子病历构建和多智能体诊断对话生成，创建502个合成EMR，将临床访谈协议转化为分层状态机和上下文树，支持130多个诊断状态。

Result: 构建了3000个多轮诊断对话，相比真实临床记录在对话长度、标记分布和诊断推理策略方面具有高保真度，精神科医生确认其真实性和诊断有效性。

Conclusion: PsyCoTalk数据集提高了诊断准确性和治疗规划，为精神疾病共病研究提供了宝贵资源，支持在单次对话中开发和评估多障碍筛查模型。

Abstract: Psychiatric comorbidity is clinically significant yet challenging due to the
complexity of multiple co-occurring disorders. To address this, we develop a
novel approach integrating synthetic patient electronic medical record (EMR)
construction and multi-agent diagnostic dialogue generation. We create 502
synthetic EMRs for common comorbid conditions using a pipeline that ensures
clinical relevance and diversity. Our multi-agent framework transfers the
clinical interview protocol into a hierarchical state machine and context tree,
supporting over 130 diagnostic states while maintaining clinical standards.
Through this rigorous process, we construct PsyCoTalk, the first large-scale
dialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic
dialogues validated by psychiatrists. This dataset enhances diagnostic accuracy
and treatment planning, offering a valuable resource for psychiatric
comorbidity research. Compared to real-world clinical transcripts, PsyCoTalk
exhibits high structural and linguistic fidelity in terms of dialogue length,
token distribution, and diagnostic reasoning strategies. Licensed psychiatrists
confirm the realism and diagnostic validity of the dialogues. This dataset
enables the development and evaluation of models capable of multi-disorder
psychiatric screening in a single conversational pass.

</details>


### [47] [GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning](https://arxiv.org/abs/2510.25320)
*Jiaqi Wu,Qinlao Zhao,Zefeng Chen,Kai Qin,Yifei Zhao,Xueqian Wang,Yuhang Yao*

Main category: cs.AI

TL;DR: 提出Graph-based Agent Planning (GAP)框架，通过图规划实现工具执行的并行化，显著提升多步推理任务的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自主代理（如ReAct）采用顺序推理执行，无法利用独立子任务的并行性，导致工具利用效率低下和多步推理性能不佳。

Method: 训练代理基础模型将复杂任务分解为依赖感知的子任务图，自主决定哪些工具可以并行执行，哪些必须顺序执行。采用两阶段训练策略：监督微调+基于正确性的强化学习。

Result: 在MHQA数据集上显著超越传统ReAct基线，特别是在多步检索任务中，通过智能并行化实现工具调用效率的显著提升。

Conclusion: GAP框架通过依赖感知的任务编排，在保持任务准确性的同时大幅提升执行效率，为复杂任务解决提供了更高效的范式。

Abstract: Autonomous agents powered by large language models (LLMs) have shown
impressive capabilities in tool manipulation for complex task-solving. However,
existing paradigms such as ReAct rely on sequential reasoning and execution,
failing to exploit the inherent parallelism among independent sub-tasks. This
sequential bottleneck leads to inefficient tool utilization and suboptimal
performance in multi-step reasoning scenarios. We introduce Graph-based Agent
Planning (GAP), a novel framework that explicitly models inter-task
dependencies through graph-based planning to enable adaptive parallel and
serial tool execution. Our approach trains agent foundation models to decompose
complex tasks into dependency-aware sub-task graphs, autonomously determining
which tools can be executed in parallel and which must follow sequential
dependencies. This dependency-aware orchestration achieves substantial
improvements in both execution efficiency and task accuracy. To train GAP, we
construct a high-quality dataset of graph-based planning traces derived from
the Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage
training strategy: supervised fine-tuning (SFT) on the curated dataset,
followed by reinforcement learning (RL) with a correctness-based reward
function on strategically sampled queries where tool-based reasoning provides
maximum value. Experimental results on MHQA datasets demonstrate that GAP
significantly outperforms traditional ReAct baselines, particularly on
multi-step retrieval tasks, while achieving dramatic improvements in tool
invocation efficiency through intelligent parallelization. The project page is
available at: https://github.com/WJQ7777/Graph-Agent-Planning.

</details>


### [48] [Grouping Nodes With Known Value Differences: A Lossless UCT-based Abstraction Algorithm](https://arxiv.org/abs/2510.25388)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 本文提出了KVDA-UCT算法，通过分析即时奖励来推断状态-动作对之间的价值差异，从而在MCTS中实现更有效的抽象分组，相比现有方法OGA-UCT能检测到更多抽象且无需额外参数。


<details>
  <summary>Details</summary>
Motivation: 现有MCTS抽象算法OGA-UCT要求状态-动作对具有相同的即时奖励，这一刚性条件限制了可发现的抽象数量，影响了样本效率。

Method: 提出KVDA框架，不再要求状态-动作对价值相等，而是推断它们之间的价值差异，并基于此修改OGA-UCT得到KVDA-UCT算法。

Result: KVDA-UCT在各种确定性环境和参数设置下显著优于OGA-UCT，能检测到更多抽象且不引入额外参数。

Conclusion: KVDA框架通过推断价值差异而非要求价值相等，有效提升了MCTS的抽象能力和样本效率。

Abstract: A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency,
which can be improved by grouping state-action pairs and using their aggregate
statistics instead of single-node statistics. On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS
abstraction algorithm for deterministic environments that builds its
abstraction using the Abstractions of State-Action Pairs (ASAP) framework,
which aims to detect states and state-action pairs with the same value under
optimal play by analysing the search graph. ASAP, however, requires two
state-action pairs to have the same immediate reward, which is a rigid
condition that limits the number of abstractions that can be found and thereby
the sample efficiency. In this paper, we break with the paradigm of grouping
value-equivalent states or state-action pairs and instead group states and
state-action pairs with possibly different values as long as the difference
between their values can be inferred. We call this abstraction framework Known
Value Difference Abstractions (KVDA), which infers the value differences by
analysis of the immediate rewards and modifies OGA-UCT to use this framework
instead. The modification is called KVDA-UCT, which detects significantly more
abstractions than OGA-UCT, introduces no additional parameter, and outperforms
OGA-UCT on a variety of deterministic environments and parameter settings.

</details>


### [49] [Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions](https://arxiv.org/abs/2510.25445)
*Mohamad Abou Ali,Fadi Dornaika*

Main category: cs.AI

TL;DR: 这篇论文提出了一个双范式框架来分类智能AI系统：符号/经典范式（基于算法规划和持久状态）和神经/生成范式（利用随机生成和提示驱动编排）。通过系统回顾90项研究，分析了两种范式在理论基础、领域应用和伦理挑战方面的差异，并提出了混合神经符号架构的战略路线图。


<details>
  <summary>Details</summary>
Motivation: 解决智能AI快速发展导致的碎片化理解问题，澄清现代神经系统与过时符号模型之间的混淆（概念性重新适配），为领域提供清晰的概念框架。

Method: 采用PRISMA系统回顾方法，分析了2018-2025年间的90项研究，构建双范式框架并从三个维度进行系统分析：理论基础与架构原则、领域特定实施、范式特定伦理挑战。

Result: 发现范式选择具有战略性：符号系统主导安全关键领域（如医疗），神经系统主导适应性强的数据丰富环境（如金融）。识别了关键研究空白，包括符号系统治理模型不足和混合神经符号架构的需求。

Conclusion: 智能AI的未来不在于单一范式的统治，而在于两种范式的有意整合，以创建既适应性强又可靠的系统。这项工作为未来研究、开发和政策提供了必要的概念工具包。

Abstract: Agentic AI represents a transformative shift in artificial intelligence, but
its rapid advancement has led to a fragmented understanding, often conflating
modern neural systems with outdated symbolic models -- a practice known as
conceptual retrofitting. This survey cuts through this confusion by introducing
a novel dual-paradigm framework that categorizes agentic systems into two
distinct lineages: the Symbolic/Classical (relying on algorithmic planning and
persistent state) and the Neural/Generative (leveraging stochastic generation
and prompt-driven orchestration). Through a systematic PRISMA-based review of
90 studies (2018--2025), we provide a comprehensive analysis structured around
this framework across three dimensions: (1) the theoretical foundations and
architectural principles defining each paradigm; (2) domain-specific
implementations in healthcare, finance, and robotics, demonstrating how
application constraints dictate paradigm selection; and (3) paradigm-specific
ethical and governance challenges, revealing divergent risks and mitigation
strategies. Our analysis reveals that the choice of paradigm is strategic:
symbolic systems dominate safety-critical domains (e.g., healthcare), while
neural systems prevail in adaptive, data-rich environments (e.g., finance).
Furthermore, we identify critical research gaps, including a significant
deficit in governance models for symbolic systems and a pressing need for
hybrid neuro-symbolic architectures. The findings culminate in a strategic
roadmap arguing that the future of Agentic AI lies not in the dominance of one
paradigm, but in their intentional integration to create systems that are both
adaptable and reliable. This work provides the essential conceptual toolkit to
guide future research, development, and policy toward robust and trustworthy
hybrid intelligent systems.

</details>


### [50] [Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?](https://arxiv.org/abs/2510.25471)
*Willem Fourie*

Main category: cs.AI

TL;DR: 本文提出AI对齐研究的新视角：将工具性目标视为需要接受和管理的特征，而非需要限制的故障。基于亚里士多德本体论，认为高级AI系统的构成会自然产生工具性目标，应将其引导至人类对齐的目标。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐理论将工具性目标视为风险来源，试图限制其症状。本文认为这种观点过于消极，需要重新审视工具性目标在AI系统中的作用。

Method: 运用亚里士多德本体论及其现代解释，构建哲学论证框架，将AI系统视为具有特定形式和物质构成的实体，其工具性倾向是构成的自然结果。

Result: 提出工具性目标应被视为AI系统构成的固有特征，而非意外故障。这为AI对齐研究提供了新的理论基础。

Conclusion: AI对齐工作应更关注理解、管理和引导工具性目标，而非试图消除它们，将其导向人类对齐的最终目标。

Abstract: In artificial intelligence (AI) alignment research, instrumental goals, also
called instrumental subgoals or instrumental convergent goals, are widely
associated with advanced AI systems. These goals, which include tendencies such
as power-seeking and self-preservation, become problematic when they conflict
with human aims. Conventional alignment theory treats instrumental goals as
sources of risk that become problematic through failure modes such as reward
hacking or goal misgeneralization, and attempts to limit the symptoms of
instrumental goals, notably resource acquisition and self-preservation. This
article proposes an alternative framing: that a philosophical argument can be
constructed according to which instrumental goals may be understood as features
to be accepted and managed rather than failures to be limited. Drawing on
Aristotle's ontology and its modern interpretations, an ontology of concrete,
goal-directed entities, it argues that advanced AI systems can be seen as
artifacts whose formal and material constitution gives rise to effects distinct
from their designers' intentions. In this view, the instrumental tendencies of
such systems correspond to per se outcomes of their constitution rather than
accidental malfunctions. The implication is that efforts should focus less on
eliminating instrumental goals and more on understanding, managing, and
directing them toward human-aligned ends.

</details>


### [51] [Multi-Objective Search: Algorithms, Applications, and Emerging Directions](https://arxiv.org/abs/2510.25504)
*Oren Salzman,Carlos Hernández Ulloa,Ariel Felner,Sven Koenig*

Main category: cs.AI

TL;DR: 多目标搜索（MOS）作为规划与决策问题的统一框架，近年来在AI应用中重新受到关注，本文综述了MOS的发展并指出了跨学科机会和开放挑战。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统很少只优化单一指标，多目标搜索能够平衡多个通常相互冲突的标准，在机器人、交通和运筹学等AI应用中具有重要价值。

Method: 本文采用综述方法，回顾了多目标搜索领域的发展历程，重点分析了跨学科机会。

Result: 文章系统梳理了MOS的研究进展，识别了该领域的新兴前沿问题。

Conclusion: 多目标搜索作为一个成熟但仍在发展的领域，面临着定义其新兴前沿的开放挑战，具有广阔的跨学科应用前景。

Abstract: Multi-objective search (MOS) has emerged as a unifying framework for planning
and decision-making problems where multiple, often conflicting, criteria must
be balanced. While the problem has been studied for decades, recent years have
seen renewed interest in the topic across AI applications such as robotics,
transportation, and operations research, reflecting the reality that real-world
systems rarely optimize a single measure. This paper surveys developments in
MOS while highlighting cross-disciplinary opportunities, and outlines open
challenges that define the emerging frontier of MOS

</details>


### [52] [MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL](https://arxiv.org/abs/2510.25510)
*Zekun Xu,Siyu Xia,Chuhuai Yue,Jiajun Chai,Mingxue Tian,Xiaohan Wang,Wei Lin,Haoxuan Li,Guojun Yin*

Main category: cs.AI

TL;DR: 提出了MTIR-SQL框架，这是一个多轮工具集成推理的强化学习框架，用于Text-to-SQL任务，通过动态执行反馈和多轮推理显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖静态执行反馈，限制了实时错误纠正能力。集成多轮工具调用和动态反馈可以显著提高适应性和鲁棒性，从而提升模型性能。

Method: 提出了执行感知的多轮推理范式，在每个推理步骤无缝集成数据库执行反馈，实现上下文敏感的查询生成和渐进式优化。扩展了GRPO算法以适应复杂多轮交互场景，并增加了轨迹过滤机制和移除KL损失约束。

Result: 在BIRD Dev数据集上达到64.4%的准确率，在SPIDER Dev数据集上达到84.6%的执行准确率，显著优于现有方法。

Conclusion: MTIR-SQL框架通过多轮工具集成推理和动态执行反馈，在Text-to-SQL任务中取得了显著的性能提升，证明了该方法的有效性。

Abstract: As large language models (LLMs) are increasingly used in Text-to-SQL tasks,
Reinforcement Learning (RL) has become a common method for improving
performance. Existing methods primarily rely on static execution feedback,
which restricts real-time error correction. However, integrating multi-turn
tool invocation along with dynamic feedback could significantly improve
adaptability and robustness, ultimately enhancing model performance. To address
these issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated
Reasoning reinforcement learning framework for Text-to-SQL. Our approach
introduces an execution-aware multi-turn reasoning paradigm that seamlessly
incorporates database execution feedback at each reasoning step, enabling
context-sensitive query generation and progressive refinement throughout the
reasoning process. The framework extends the GRPO algorithm to accommodate
complex multi-turn interaction scenarios. Considering the training instability
characteristics of MTIR and the potential for significant Deviation of model
distribution from the initial model, we enhance the GRPO algorithm by adding a
trajectory filtering mechanism and removing KL loss constraints. Experimental
results demonstrate that MTIR-SQL, with 4B parameters, achieves \textbf{64.4}\%
accuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev,
significantly outperforming existing approaches.

</details>


### [53] [Predicate Renaming via Large Language Models](https://arxiv.org/abs/2510.25517)
*Elisabetta Gentili,Tony Ribeiro,Fabrizio Riguzzi,Katsumi Inoue*

Main category: cs.AI

TL;DR: 使用大型语言模型为逻辑规则中的未命名谓词生成有意义的名称，以提高逻辑理论的可读性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在归纳逻辑编程中，各种规则生成方法会产生包含未命名谓词的规则，这阻碍了逻辑理论的可读性、可解释性和可重用性。

Method: 利用大型语言模型处理自然语言和代码的能力，为未命名谓词提供语义上有意义的命名建议。

Result: 在手工制作的逻辑规则上评估表明，大型语言模型在此任务上具有潜力。

Conclusion: 大型语言模型有望解决逻辑规则中谓词命名的问题，从而提高逻辑理论的质量。

Abstract: In this paper, we address the problem of giving names to predicates in logic
rules using Large Language Models (LLMs). In the context of Inductive Logic
Programming, various rule generation methods produce rules containing unnamed
predicates, with Predicate Invention being a key example. This hinders the
readability, interpretability, and reusability of the logic theory. Leveraging
recent advancements in LLMs development, we explore their ability to process
natural language and code to provide semantically meaningful suggestions for
giving a name to unnamed predicates. The evaluation of our approach on some
hand-crafted logic rules indicates that LLMs hold potential for this task.

</details>


### [54] [Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation](https://arxiv.org/abs/2510.25518)
*Thomas Cook,Richard Osuagwu,Liman Tsatiashvili,Vrynsia Vrynsia,Koustav Ghosal,Maraim Masoud,Riccardo Mattivi*

Main category: cs.AI

TL;DR: 本文提出了一种面向金融科技领域的智能RAG架构，通过模块化代理系统解决专业领域检索中的挑战，在检索精度和相关性方面优于标准RAG基线。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统在金融科技等专业领域面临挑战，包括领域特定本体、密集术语和缩略语等，影响检索和合成的有效性。

Method: 采用模块化代理架构，支持智能查询重写、基于关键词提取的迭代子查询分解、上下文缩略语解析和交叉编码器上下文重排序。

Result: 在85个问答参考三元组数据集上的实验表明，该智能RAG系统在检索精度和相关性方面优于基线，但延迟有所增加。

Conclusion: 结构化多代理方法为增强复杂领域特定环境中的检索鲁棒性提供了有前景的方向。

Abstract: Retrieval-Augmented Generation (RAG) systems often face limitations in
specialized domains such as fintech, where domain-specific ontologies, dense
terminology, and acronyms complicate effective retrieval and synthesis. This
paper introduces an agentic RAG architecture designed to address these
challenges through a modular pipeline of specialized agents. The proposed
system supports intelligent query reformulation, iterative sub-query
decomposition guided by keyphrase extraction, contextual acronym resolution,
and cross-encoder-based context re-ranking. We evaluate our approach against a
standard RAG baseline using a curated dataset of 85 question--answer--reference
triples derived from an enterprise fintech knowledge base. Experimental results
demonstrate that the agentic RAG system outperforms the baseline in retrieval
precision and relevance, albeit with increased latency. These findings suggest
that structured, multi-agent methodologies offer a promising direction for
enhancing retrieval robustness in complex, domain-specific settings.

</details>


### [55] [Zero Reinforcement Learning Towards General Domains](https://arxiv.org/abs/2510.25528)
*Yuyuan Zeng,Yufei Huang,Can Xu,Qingfeng Sun,Jianfeng Yan,Guanghui Xu,Tao Yang,Fengzong Lian*

Main category: cs.AI

TL;DR: 提出一种新的零强化学习范式，通过结合可验证奖励和生成奖励模型，在可验证和不可验证领域进行多任务训练，提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前零强化学习主要关注奖励信号容易验证的领域（如数学、编程），在验证不直接的其他多样化场景中激发推理能力的研究不足。

Method: 结合可验证奖励与生成奖励模型进行多任务零强化学习训练，设计平滑长度惩罚机制来鼓励生成更全面的思考标记，防止奖励攻击。

Result: 在Qwen3-8B-Base和Qwen3-14B-Base上的实验表明，该方法在需要广泛推理的任务和更一般的任务上都取得了优越的推理性能。

Conclusion: 该方法成功提升了模型在可验证和不可验证领域的推理能力，并通过多任务训练实现了推理能力在不同领域间的迁移。

Abstract: Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach
for enhancing the reasoning capabilities of large language models (LLMs) by
directly applying reinforcement learning with verifiable rewards on pretrained
models, without the need for a supervised fine-tuning phase. However, current
research on zero-RL primarily focuses on domains with easily verifiable reward
signals, such as mathematics, programming, and other reasoning tasks. The
challenge of eliciting reasoning abilities in more diverse scenarios, where
verification is not straightforward, remains underexplored. To address this
gap, we propose a novel zero-RL paradigm designed to improve a model's
reasoning ability across both verifiable and non-verifiable domains. By
combining verifiable rewards with a generative reward model, we conduct
multi-task zero-RL training across both domains, facilitating the transfer of
reasoning capabilities between them. Furthermore, to mitigate reward hacking in
the generative reward model, we design a smooth length penalty that encourages
the generation of more comprehensive thinking tokens in general domains.
Experimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our
approach achieves superior reasoning performance, not only on tasks requiring
extensive reasoning but also on more general tasks.

</details>


### [56] [Off-policy Reinforcement Learning with Model-based Exploration Augmentation](https://arxiv.org/abs/2510.25529)
*Likun Wang,Xiangteng Zhang,Yinuo Wang,Guojian Zhan,Wenxuan Wang,Haoyu Gao,Jingliang Duan,Shengbo Eben Li*

Main category: cs.AI

TL;DR: 提出MoGE方法，通过生成未充分探索的关键状态和动态一致的经验来增强强化学习中的探索能力，提高样本效率和性能


<details>
  <summary>Details</summary>
Motivation: 现有探索方法存在局限性：主动探索在高维环境中表现不佳，被动探索受限于样本多样性不足。需要解决被动探索的局限性

Method: MoGE包含两个组件：(1)基于扩散模型的关键状态生成器，通过效用函数评估状态对策略探索的潜在影响；(2)一步想象世界模型，基于关键状态构建关键转换用于智能体学习

Result: 在OpenAI Gym和DeepMind Control Suite上的实验结果表明，MoGE有效连接了探索和策略学习，在复杂控制任务中显著提高了样本效率和性能

Conclusion: MoGE采用模块化设计，可与现有算法无缝集成，在不改变核心结构的情况下改善探索能力

Abstract: Exploration is fundamental to reinforcement learning (RL), as it determines
how effectively an agent discovers and exploits the underlying structure of its
environment to achieve optimal performance. Existing exploration methods
generally fall into two categories: active exploration and passive exploration.
The former introduces stochasticity into the policy but struggles in
high-dimensional environments, while the latter adaptively prioritizes
transitions in the replay buffer to enhance exploration, yet remains
constrained by limited sample diversity. To address the limitation in passive
exploration, we propose Modelic Generative Exploration (MoGE), which augments
exploration through the generation of under-explored critical states and
synthesis of dynamics-consistent experiences through transition models. MoGE is
composed of two components: (1) a diffusion-based generator that synthesizes
critical states under the guidance of a utility function evaluating each
state's potential influence on policy exploration, and (2) a one-step
imagination world model for constructing critical transitions based on the
critical states for agent learning. Our method adopts a modular formulation
that aligns with the principles of off-policy learning, allowing seamless
integration with existing algorithms to improve exploration without altering
their core structures. Empirical results on OpenAI Gym and DeepMind Control
Suite reveal that MoGE effectively bridges exploration and policy learning,
leading to remarkable gains in both sample efficiency and performance across
complex control tasks.

</details>


### [57] [Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2510.25588)
*Eranga Bandara,Ross Gore,Atmaram Yarlagadda,Anita H. Clayton,Preston Samuel,Christopher K. Rhea,Sachin Shetty*

Main category: cs.AI

TL;DR: 提出基于微调大语言模型联盟和推理LLM的决策支持系统，用于精神障碍的临床诊断，通过共识决策和推理模型提升诊断标准化和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统精神疾病诊断依赖医患对话，存在主观性和诊断不一致的问题，需要标准化方法来提高诊断可靠性。

Method: 使用在精神科医患对话数据集上微调的LLMs，通过共识决策机制聚合各模型预测，并由OpenAI-gpt-oss推理LLM进行精炼，部署LLM代理协调整个诊断流程。

Result: 实验结果表明，结合微调LLMs和推理模型能够创建强大且高精度的精神健康评估诊断系统，原型系统已与美国陆军医疗研究团队合作开发。

Conclusion: 这是首个将微调LLM联盟与推理LLM集成用于临床精神健康诊断的应用，为下一代AI驱动的eHealth系统标准化精神科诊断开辟了道路。

Abstract: The diagnosis of most mental disorders, including psychiatric evaluations,
primarily depends on dialogues between psychiatrists and patients. This
subjective process can lead to variability in diagnoses across clinicians and
patients, resulting in inconsistencies and challenges in achieving reliable
outcomes. To address these issues and standardize psychiatric diagnoses, we
propose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss
Reasoning LLM-enabled Decision Support System for the clinical diagnosis of
mental disorders. Our approach leverages fine-tuned LLMs trained on
conversational datasets involving psychiatrist-patient interactions focused on
mental health conditions (e.g., depression). The diagnostic predictions from
individual models are aggregated through a consensus-based decision-making
process, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method
for deploying LLM agents that orchestrate communication between the LLM
consortium and the reasoning LLM, ensuring transparency, reliability, and
responsible AI across the entire diagnostic workflow. Experimental results
demonstrate the transformative potential of combining fine-tuned LLMs with a
reasoning model to create a robust and highly accurate diagnostic system for
mental health assessment. A prototype of the proposed platform, integrating
three fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in
collaboration with the U.S. Army Medical Research Team in Norfolk, Virginia,
USA. To the best of our knowledge, this work represents the first application
of a fine-tuned LLM consortium integrated with a reasoning LLM for clinical
mental health diagnosis paving the way for next-generation AI-powered eHealth
systems aimed at standardizing psychiatric diagnoses.

</details>


### [58] [Counterfactual-based Agent Influence Ranker for Agentic AI Workflows](https://arxiv.org/abs/2510.25612)
*Amit Giloni,Chiara Picardi,Roy Betser,Shamik Bose,Aishvariya Priya Rathina Sabapathy,Roman Vainshtein*

Main category: cs.AI

TL;DR: CAIR是首个评估多智能体系统中各智能体对最终输出影响程度的方法，通过反事实分析提供任务无关的分析能力。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法只能进行静态结构分析，不适用于推理时执行，且没有方法能评估多智能体系统中各智能体对最终输出的影响。

Method: 采用反事实分析技术，通过改变智能体的输出来评估其对系统最终输出的影响程度。

Result: 在包含30个用例和230个功能的数据集上评估，CAIR产生一致的排名，优于基线方法，并能有效提升下游任务的效果和相关性。

Conclusion: CAIR是首个能够评估多智能体系统中智能体影响力的方法，为理解和优化此类系统提供了重要工具。

Abstract: An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system,
is an autonomous system that assembles several LLM-based agents to work
collaboratively towards a shared goal. The high autonomy, widespread adoption,
and growing interest in such AAWs highlight the need for a deeper understanding
of their operations, from both quality and security aspects. To this day, there
are no existing methods to assess the influence of each agent on the AAW's
final output. Adopting techniques from related fields is not feasible since
existing methods perform only static structural analysis, which is unsuitable
for inference time execution. We present Counterfactual-based Agent Influence
Ranker (CAIR) - the first method for assessing the influence level of each
agent on the AAW's output and determining which agents are the most
influential. By performing counterfactual analysis, CAIR provides a
task-agnostic analysis that can be used both offline and at inference time. We
evaluate CAIR using an AAWs dataset of our creation, containing 30 different
use cases with 230 different functionalities. Our evaluation showed that CAIR
produces consistent rankings, outperforms baseline methods, and can easily
enhance the effectiveness and relevancy of downstream tasks.

</details>


### [59] [ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents](https://arxiv.org/abs/2510.25668)
*Tianyu Yang,Terry Ruas,Yijun Tian,Jan Philip Wahle,Daniel Kurzawe,Bela Gipp*

Main category: cs.AI

TL;DR: ALDEN是一个多轮强化学习框架，通过将视觉语言模型训练为交互式智能体，使其能够主动导航长文档。它引入了直接按索引访问页面的fetch动作，并提出了跨级别奖励和视觉语义锚定机制来解决训练稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在处理需要跨多页分析和整合信息的视觉复杂长文档时表现不佳，现有方法依赖固定的推理模板或刚性流程，限制了模型的效率和泛化能力。

Method: 使用多轮强化学习框架微调视觉语言模型，引入fetch动作直接按索引访问页面，提出基于规则的跨级别奖励进行密集过程监督，以及视觉语义锚定机制来稳定训练过程。

Result: 在三个开源数据集构建的语料库上训练后，ALDEN在五个长文档基准测试中达到了最先进的性能。

Conclusion: ALDEN标志着从被动文档阅读向能够自主导航和推理长视觉丰富文档的智能体的转变，为更准确和高效的长文档理解提供了稳健路径。

Abstract: Vision-language models (VLMs) excel at interpreting text-rich images but
struggle with long, visually complex documents that demand analysis and
integration of information spread across multiple pages. Existing approaches
typically rely on fixed reasoning templates or rigid pipelines, which force
VLMs into a passive role and hinder both efficiency and generalization. We
present Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement
learning framework that fine-tunes VLMs as interactive agents capable of
actively navigating long, visually rich documents. ALDEN introduces a novel
fetch action that directly accesses the page by index, complementing the
classic search action and better exploiting document structure. For dense
process supervision and efficient training, we propose a rule-based cross-level
reward that provides both turn- and token-level signals. To address the
empirically observed training instability caused by numerous visual tokens from
long documents, we further propose a visual-semantic anchoring mechanism that
applies a dual-path KL-divergence constraint to stabilize visual and textual
representations separately during training. Trained on a corpus constructed
from three open-source datasets, ALDEN achieves state-of-the-art performance on
five long-document benchmarks. Overall, ALDEN marks a step beyond passive
document reading toward agents that autonomously navigate and reason across
long, visually rich documents, offering a robust path to more accurate and
efficient long-document understanding.

</details>


### [60] [Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning](https://arxiv.org/abs/2510.25679)
*Federica Tonti,Ricardo Vinuesa*

Main category: cs.AI

TL;DR: 基于深度强化学习的无人机最优导航策略，在三维城市湍流环境中使用PPO+GTrXL架构，显著提高了成功率和降低了碰撞率。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在城市中用于配送和监控的普及，需要开发在复杂城市湍流环境中的高效导航策略。

Method: 采用基于流感知的PPO算法结合GTrXL架构，为智能体提供更丰富的湍流场信息，并与PPO+LSTM、PPO+GTrXL（无预测任务）和传统Zermelo导航算法进行对比。

Result: 相比PPO+LSTM、PPO+GTrXL和传统Zermelo算法，该方法显著提高了成功率(SR)并降低了碰撞率(CR)。

Conclusion: 该方法为复杂城市环境中无人机的导航开辟了新途径，有望重塑无人机在城市环境中的应用格局。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for
delivery and surveillance purposes. In this work, we develop an optimal
navigation strategy based on Deep Reinforcement Learning. The environment is
represented by a three-dimensional high-fidelity simulation of an urban flow,
characterized by turbulence and recirculation zones. The algorithm presented
here is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated
Transformer eXtra Large (GTrXL) architecture, giving the agent richer
information about the turbulent flow field in which it navigates. The results
are compared with a PPO+GTrXL without the secondary prediction tasks, a PPO
combined with Long Short Term Memory (LSTM) cells and a traditional navigation
algorithm. The obtained results show a significant increase in the success rate
(SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the
classical Zermelo's navigation algorithm, paving the way to a completely
reimagined UAV landscape in complex urban environments.

</details>


### [61] [BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph](https://arxiv.org/abs/2510.25724)
*Vanya Arikutharam,Arkadiy Ukolov*

Main category: cs.AI

TL;DR: BambooKG是一种带频率权重的知识图谱，通过非三元组边减少信息损失，提升单跳和多跳推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法独立处理检索块，难以进行多跳或关系推理；传统知识图谱会丢失不符合三元组结构的信息。

Method: 引入BambooKG知识图谱，在非三元组边上应用基于频率的权重，反映链接强度，借鉴赫布原理。

Result: 减少了信息损失，在单跳和多跳推理任务上表现优于现有解决方案。

Conclusion: BambooKG通过频率加权的非三元组边有效提升了知识图谱的关系推理能力。

Abstract: Retrieval-Augmented Generation allows LLMs to access external knowledge,
reducing hallucinations and ageing-data issues. However, it treats retrieved
chunks independently and struggles with multi-hop or relational reasoning,
especially across documents. Knowledge graphs enhance this by capturing the
relationships between entities using triplets, enabling structured, multi-chunk
reasoning. However, these tend to miss information that fails to conform to the
triplet structure. We introduce BambooKG, a knowledge graph with
frequency-based weights on non-triplet edges which reflect link strength,
drawing on the Hebbian principle of "fire together, wire together". This
decreases information loss and results in improved performance on single- and
multi-hop reasoning, outperforming the existing solutions.

</details>


### [62] [TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling](https://arxiv.org/abs/2510.25758)
*He Hu,Yucheng Zhou,Chiyuan Ma,Qianning Wang,Zheng Zhang,Fei Ma,Laizhong Cui,Qi Tian*

Main category: cs.AI

TL;DR: TheraMind是一个用于纵向心理咨询的战略自适应代理，采用创新的双循环架构，解决了现有LLM在心理咨询中缺乏情感理解、自适应策略和跨会话长期记忆的问题。


<details>
  <summary>Details</summary>
Motivation: 现有心理咨询LLM方法缺乏情感理解、自适应策略和跨会话治疗方法的长期记忆，与真实临床实践差距较大。

Method: 提出双循环架构：会话内循环用于战术对话管理，感知患者情绪状态动态选择响应策略；跨会话循环用于战略治疗规划，评估治疗效果并调整后续方法。

Result: 在高保真模拟环境中的广泛评估显示，TheraMind在多会话指标（如连贯性、灵活性和治疗协调性）上优于其他方法。

Conclusion: 双循环设计在模拟战略、自适应和纵向治疗行为方面有效，验证了其临床实用性。

Abstract: Large language models (LLMs) in psychological counseling have attracted
increasing attention. However, existing approaches often lack emotional
understanding, adaptive strategies, and the use of therapeutic methods across
multiple sessions with long-term memory, leaving them far from real clinical
practice. To address these critical gaps, we introduce TheraMind, a strategic
and adaptive agent for longitudinal psychological counseling. The cornerstone
of TheraMind is a novel dual-loop architecture that decouples the complex
counseling process into an Intra-Session Loop for tactical dialogue management
and a Cross-Session Loop for strategic therapeutic planning. The Intra-Session
Loop perceives the patient's emotional state to dynamically select response
strategies while leveraging cross-session memory to ensure continuity.
Crucially, the Cross-Session Loop empowers the agent with long-term
adaptability by evaluating the efficacy of the applied therapy after each
session and adjusting the method for subsequent interactions. We validate our
approach in a high-fidelity simulation environment grounded in real clinical
cases. Extensive evaluations show that TheraMind outperforms other methods,
especially on multi-session metrics like Coherence, Flexibility, and
Therapeutic Attunement, validating the effectiveness of its dual-loop design in
emulating strategic, adaptive, and longitudinal therapeutic behavior. The code
is publicly available at https://0mwwm0.github.io/TheraMind/.

</details>
