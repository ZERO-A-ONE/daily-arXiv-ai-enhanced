<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 8]
- [cs.CR](#cs.CR) [Total: 6]
- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [How (Not) To Write a Software Engineering Abstract](https://arxiv.org/abs/2506.21634)
*Lutz Prechelt,Lloyd Montgomery,Julian Frattini,Franz Zieris*

Main category: cs.SE

TL;DR: 论文分析了高质量软件工程会议摘要的结构，发现大多数摘要不完整或存在问题，建议采用结构化摘要格式并改进内容。


<details>
  <summary>Details</summary>
Motivation: 研究高质量软件工程会议摘要的结构，以发现其不足并提出改进指南。

Method: 通过定性开放编码和定量内容分析，分析了362篇摘要的结构和问题。

Result: 仅29%的摘要完整，4%的摘要质量良好；结构化摘要表现更好。

Conclusion: 大多数摘要不理想，结构化摘要更优，建议改进格式和内容。

Abstract: Background: Abstracts are a particularly valuable element in a software
engineering research article. However, not all abstracts are as informative as
they could be. Objective: Characterize the structure of abstracts in
high-quality software engineering venues. Observe and quantify deficiencies.
Suggest guidelines for writing informative abstracts. Methods: Use qualitative
open coding to derive concepts that explain relevant properties of abstracts.
Identify the archetypical structure of abstracts. Use quantitative content
analysis to objectively characterize abstract structure of a sample of 362
abstracts from five presumably high-quality venues. Use exploratory data
analysis to find recurring issues in abstracts. Compare the archetypical
structure to actual structures. Infer guidelines for producing informative
abstracts. Results: Only 29% of the sampled abstracts are complete, i.e.,
provide background, objective, method, result, and conclusion information. For
structured abstracts, the ratio is twice as big. Only 4% of the abstracts are
proper, i.e., they also have good readability (Flesch-Kincaid score) and have
no informativeness gaps, understandability gaps, nor highly ambiguous
sentences. Conclusions: (1) Even in top venues, a large majority of abstracts
are far from ideal. (2) Structured abstracts tend to be better than
unstructured ones. (3) Artifact-centric works need a different structured
format. (4) The community should start requiring conclusions that generalize,
which currently are often missing in abstracts.

</details>


### [2] [Experience converting a large mathematical software package written in C++ to C++20 modules](https://arxiv.org/abs/2506.21654)
*Wolfgang Bangerth*

Main category: cs.SE

TL;DR: 论文探讨了如何将大型数学软件包从传统的C++头文件接口转换为C++20模块系统，以deal.II有限元库为例，展示了转换的可行性和效果。


<details>
  <summary>Details</summary>
Motivation: 传统的C++头文件接口方式笨拙、不可靠且效率低，C++20引入的模块系统提供了更高效的替代方案。

Method: 通过deal.II库（约80万行代码）的实例，提出了一种同时支持头文件和模块接口的方法，并分析了转换中的挑战和实际效果。

Result: 转换后库本身的编译时间减少，但下游项目的编译时间无明显变化。转换工作虽非微不足道，但可行。

Conclusion: 论文提出了将整个数学软件生态系统逐步转换为模块系统的长期策略。

Abstract: Mathematical software has traditionally been built in the form of "packages"
that build on each other. A substantial fraction of these packages is written
in C++ and, as a consequence, the interface of a package is described in the
form of header files that downstream packages and applications can then
#include. C++ has inherited this approach towards exporting interfaces from C,
but the approach is clunky, unreliable, and slow. As a consequence, C++20 has
introduced a "module" system in which packages explicitly export declarations
and code that compilers then store in machine-readable form and that downstream
users can "import" -- a system in line with what many other programming
languages have used for decades.
  Herein, I explore how one can convert large mathematical software packages
written in C++ to this system, using the deal.II finite element library with
its around 800,000 lines of code as an example. I describe an approach that
allows providing both header-based and module-based interfaces from the same
code base, discuss the challenges one encounters, and how modules actually work
in practice in a variety of technical and human metrics. The results show that
with a non-trivial, but also not prohibitive effort, the conversion to modules
is possible, resulting in a reduction in compile time for the converted library
itself; on the other hand, for downstream projects, compile times show no clear
trend. I end with thoughts about long-term strategies for converting the entire
ecosystem of mathematical software over the coming years or decades.

</details>


### [3] [The DevSafeOps Dilemma: A Systematic Literature Review on Rapidity in Safe Autonomous Driving Development and Operation](https://arxiv.org/abs/2506.21693)
*Ali Nouri,Beatriz Cabrero-Daniel,Fredrik Törner,Christian Berger*

Main category: cs.SE

TL;DR: 本文通过系统文献综述，探讨了DevOps在自动驾驶开发中的应用，总结了挑战与解决方案，并指出仍需解决的安全性问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统开发复杂且需确保安全可靠，DevOps方法因其支持快速迭代和持续监控而显得有潜力。

Method: 采用系统文献综述方法，识别、分析并综合了与DevOps在自动驾驶开发中应用相关的广泛文献。

Result: 研究结果提供了DevOps应用于安全相关AI功能时的挑战与解决方案的结构化概述。

Conclusion: 尽管DevOps在自动驾驶开发中具有潜力，但仍需解决多个开放性问题以实现安全开发。

Abstract: Developing autonomous driving (AD) systems is challenging due to the
complexity of the systems and the need to assure their safe and reliable
operation. The widely adopted approach of DevOps seems promising to support the
continuous technological progress in AI and the demand for fast reaction to
incidents, which necessitate continuous development, deployment, and
monitoring. We present a systematic literature review meant to identify,
analyse, and synthesise a broad range of existing literature related to usage
of DevOps in autonomous driving development. Our results provide a structured
overview of challenges and solutions, arising from applying DevOps to
safety-related AI-enabled functions. Our results indicate that there are still
several open topics to be addressed to enable safe DevOps for the development
of safe AD.

</details>


### [4] [Using Generative AI in Software Design Education: An Experience Report](https://arxiv.org/abs/2506.21703)
*Victoria Jackson,Susannah Liu,Andre van der Hoek*

Main category: cs.SE

TL;DR: 论文探讨了在本科软件设计课程中引入生成式AI（如ChatGPT）的经验，分析了学生使用AI完成团队作业的效果，并总结了教育者的关键教训。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI工具的快速普及，软件工程教育者需要探索如何将其有效融入课堂，尤其是在软件设计等非编程领域。

Method: 学生在团队作业中使用ChatGPT，收集对话日志和反思，并进行定性分析。

Result: 学生发现ChatGPT在设计过程中提供了帮助，但也意识到需要批判性评估其回答。教育者从中总结了有效部署AI的关键教训。

Conclusion: 生成式AI在软件设计教育中具有潜力，能帮助学生设计并了解AI的优缺点。

Abstract: With the rapid adoption of Generative AI (GenAI) tools, software engineering
educators have grappled with how best to incorporate them into the classroom.
While some research discusses the use of GenAI in the context of learning to
code, there is little research that explores the use of GenAI in the classroom
for other areas of software development. This paper provides an experience
report on introducing GenAI into an undergraduate software design class.
Students were required to use GenAI (in the form of ChatGPT) to help complete a
team-based assignment. The data collected consisted of the ChatGPT conversation
logs and students' reflections on using ChatGPT for the assignment.
Subsequently, qualitative analysis was undertaken on the data. Students
identified numerous ways ChatGPT helped them in their design process while
recognizing the need to critique the response before incorporating it into
their design. At the same time, we identified several key lessons for educators
in how to deploy GenAI in a software design class effectively. Based on our
experience, we believe students can benefit from using GenAI in software design
education as it helps them design and learn about the strengths and weaknesses
of GenAI.

</details>


### [5] [KARMA Approach supporting Development Process Reconstruction in Model-based Systems Engineering](https://arxiv.org/abs/2506.22037)
*Jiawei Li,Zan Liang,Guoxin Wang,Jinzhi Lu,Yan Yan,Shouxuan Wu,Hao Wang*

Main category: cs.SE

TL;DR: 提出了一种基于KARMA语言和自然语言处理的模型重构方法，用于优化系统开发流程模型，并以飞机机载维护系统为例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前系统迭代设计过程中缺乏有效管理开发需求变化的方法，无法实现开发流程模型的重构。

Method: 利用KARMA语言统一形式化不同建模语言构建的流程模型，引入模型重构框架，通过自然语言处理分析需求文本，提取结构化和优化约束信息，最终生成满足需求的开发流程模型。

Result: 以飞机机载维护系统为例，验证了该方法能显著提升开发流程设计效率。

Conclusion: 该方法有效解决了开发需求变化管理问题，提升了系统开发流程的效率和适应性。

Abstract: Model reconstruction is a method used to drive the development of complex
system development processes in model-based systems engineering. Currently,
during the iterative design process of a system, there is a lack of an
effective method to manage changes in development requirements, such as
development cycle requirements and cost requirements, and to realize the
reconstruction of the system development process model. To address these
issues, this paper proposes a model reconstruction method to support the
development process model. Firstly, the KARMA language, based on the GOPPRR-E
metamodeling method, is utilized to uniformly formalize the process models
constructed based on different modeling languages. Secondly, a model
reconstruction framework is introduced. This framework takes a structured
development requirements based natural language as input, employs natural
language processing techniques to analyze the development requirements text,
and extracts structural and optimization constraint information. Then, after
structural reorganization and algorithm optimization, a development process
model that meets the development requirements is obtained. Finally, as a case
study, the development process of the aircraft onboard maintenance system is
reconstructed. The results demonstrate that this method can significantly
enhance the design efficiency of the development process.

</details>


### [6] [Autonomic Microservice Management via Agentic AI and MAPE-K Integration](https://arxiv.org/abs/2506.22185)
*Matteo Esposito,Alexander Bakhtin,Noman Ahmad,Mikel Robredo,Ruoyu Su,Valentina Lenarduzzi,Davide Taibi*

Main category: cs.SE

TL;DR: 提出基于MAPE-K和智能代理AI的框架，用于微服务的自主异常检测与修复，提升系统稳定性与安全性。


<details>
  <summary>Details</summary>
Motivation: 微服务的去中心化特性带来安全和管理的挑战，威胁系统稳定性。

Method: 基于MAPE-K框架，利用智能代理AI实现自主异常检测与修复。

Result: 提供行业实用的解决方案，增强系统稳定性、减少停机时间，并监控性能、弹性等质量属性。

Conclusion: 该框架可定制化，适用于研究和实践，助力微服务系统的稳定与安全。

Abstract: While microservices are revolutionizing cloud computing by offering
unparalleled scalability and independent deployment, their decentralized nature
poses significant security and management challenges that can threaten system
stability. We propose a framework based on MAPE-K, which leverages agentic AI,
for autonomous anomaly detection and remediation to address the daunting task
of highly distributed system management. Our framework offers practical,
industry-ready solutions for maintaining robust and secure microservices.
Practitioners and researchers can customize the framework to enhance system
stability, reduce downtime, and monitor broader system quality attributes such
as system performance level, resilience, security, and anomaly management,
among others.

</details>


### [7] [Can Large Language Models Help Students Prove Software Correctness? An Experimental Study with Dafny](https://arxiv.org/abs/2506.22370)
*Carolina Carreira,Álvaro Silva,Alexandre Abreu,Alexandra Mendes*

Main category: cs.SE

TL;DR: 论文研究了学生在解决形式化验证问题时使用LLM（如ChatGPT）的效果，发现使用ChatGPT的学生表现更好，但效果与提示质量相关。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在支持高认知需求任务（如程序验证）中的作用，填补当前研究空白。

Method: 采用混合方法研究，让硕士生在Dafny语言中完成验证问题，一组使用ChatGPT，另一组不使用。

Result: 使用ChatGPT的学生表现显著更好，但表现提升与提示质量相关。

Conclusion: 建议在形式化方法课程中更有效地整合LLM，设计促进学习的LLM感知挑战。

Abstract: Students in computing education increasingly use large language models (LLMs)
such as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding
tasks, like deductive program verification, remains poorly understood. This
paper investigates how students interact with an LLM when solving formal
verification exercises in Dafny, a language that supports functional
correctness, by allowing programmers to write formal specifications and
automatically verifying that the implementation satisfies the specification. We
conducted a mixed-methods study with master's students enrolled in a formal
methods course. Each participant completed two verification problems, one with
access to a custom ChatGPT interface, that logged all interactions, and the
other without. We identified strategies used by successful students and
assessed the level of trust students place in LLMs. %\todo{Our findings show
that something here} Our findings show that students perform significantly
better when using ChatGPT; however, performance gains are tied to prompt
quality. We conclude with practical recommendations for integrating LLMs into
formal methods courses more effectively, including designing LLM-aware
challenges that promote learning rather than substitution.

</details>


### [8] [What Makes ChatGPT Effective for Software Issue Resolution? An Empirical Study of Developer-ChatGPT Conversations in GitHub](https://arxiv.org/abs/2506.22390)
*Ramtin Ehsani,Sakshi Pathak,Esteban Parra,Sonia Haiduc,Preetha Chatterjee*

Main category: cs.SE

TL;DR: 分析686个开发者与ChatGPT的对话，发现62%对问题解决有帮助，ChatGPT在代码生成和工具推荐上表现最佳，但在代码解释上较弱。


<details>
  <summary>Details</summary>
Motivation: 研究开发者与ChatGPT对话的有效性，以优化问题解决效率。

Method: 分析对话类型、任务分类及多维度指标，区分有用与无用对话。

Result: ChatGPT在代码生成和工具推荐上效果显著，但代码解释不足；有用对话更简短、易读且语义对齐。

Conclusion: 研究结果为开发者互动策略、工具设计和LLM优化提供了指导。

Abstract: Conversational large-language models are extensively used for issue
resolution tasks. However, not all developer-LLM conversations are useful for
effective issue resolution. In this paper, we analyze 686 developer-ChatGPT
conversations shared within GitHub issue threads to identify characteristics
that make these conversations effective for issue resolution. First, we analyze
the conversations and their corresponding issues to distinguish helpful from
unhelpful conversations. We begin by categorizing the types of tasks developers
seek help with to better understand the scenarios in which ChatGPT is most
effective. Next, we examine a wide range of conversational, project, and
issue-related metrics to uncover factors associated with helpful conversations.
Finally, we identify common deficiencies in unhelpful ChatGPT responses to
highlight areas that could inform the design of more effective developer-facing
tools. We found that only 62% of the ChatGPT conversations were helpful for
successful issue resolution. ChatGPT is most effective for code generation and
tools/libraries/APIs recommendations, but struggles with code explanations.
Helpful conversations tend to be shorter, more readable, and exhibit stronger
semantic and linguistic alignment. Larger, more popular projects and more
experienced developers benefit more from ChatGPT. At the issue level, ChatGPT
performs best on simpler problems with limited developer activity and faster
resolution, typically well-scoped tasks like compilation errors. The most
common deficiencies in unhelpful ChatGPT responses include incorrect
information and lack of comprehensiveness. Our findings have wide implications
including guiding developers on effective interaction strategies for issue
resolution, informing the development of tools or frameworks to support optimal
prompt design, and providing insights on fine-tuning LLMs for issue resolution
tasks.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [9] [CyGym: A Simulation-Based Game-Theoretic Analysis Framework for Cybersecurity](https://arxiv.org/abs/2506.21688)
*Michael Lanier,Yevgeniy Vorobeychik*

Main category: cs.CR

TL;DR: 介绍了一种基于OpenAI Gym的网络安全模拟器，用于博弈论建模和分析，模拟真实网络防御场景，包括零日漏洞和防御机制，并应用于分析高级持续性威胁（如Volt Typhoon）。


<details>
  <summary>Details</summary>
Motivation: 旨在通过博弈论方法提升网络防御能力，特别是针对高级持续性威胁和零日漏洞的防御策略。

Method: 开发了一个OpenAI Gym框架下的模拟器，结合真实网络拓扑、漏洞和防御机制，并提出了基于PSRO的博弈论模型。

Result: 实验证明博弈论策略能有效分析网络对高级持续性威胁（如Volt Typhoon）和零日漏洞的韧性。

Conclusion: 该模拟器和博弈论框架为优化防御策略和主动威胁缓解提供了重要见解。

Abstract: We introduce a novel cybersecurity encounter simulator between a network
defender and an attacker designed to facilitate game-theoretic modeling and
analysis while maintaining many significant features of real cyber defense. Our
simulator, built within the OpenAI Gym framework, incorporates realistic
network topologies, vulnerabilities, exploits (including-zero-days), and
defensive mechanisms. Additionally, we provide a formal simulation-based
game-theoretic model of cyberdefense using this simulator, which features a
novel approach to modeling zero-days exploits, and a PSRO-style approach for
approximately computing equilibria in this game. We use our simulator and
associated game-theoretic framework to analyze the Volt Typhoon advanced
persistent threat (APT). Volt Typhoon represents a sophisticated cyber attack
strategy employed by state-sponsored actors, characterized by stealthy,
prolonged infiltration and exploitation of network vulnerabilities. Our
experimental results demonstrate the efficacy of game-theoretic strategies in
understanding network resilience against APTs and zero-days, such as Volt
Typhoon, providing valuable insight into optimal defensive posture and
proactive threat mitigation.

</details>


### [10] [On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling](https://arxiv.org/abs/2506.21874)
*Stanley Wu,Ronik Bhaskar,Anna Yoo Jeong Ha,Shawn Shan,Haitao Zheng,Ben Y. Zhao*

Main category: cs.CR

TL;DR: 研究探讨了通过对抗性攻击误导视觉语言模型（VLMs）生成错误标注，从而污染文本到图像生成模型的训练数据，实验证明攻击成功率高达73%。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在生成图像标注时易受对抗性攻击，这可能被利用来污染文本到图像模型的训练数据，影响其性能。

Method: 通过对抗性扰动生成看似无害但被VLMs错误标注的图像，注入少量“脏标签”样本到训练数据中。

Result: 攻击成功率高（73%），且防御措施可能被适应性攻击者绕过。

Conclusion: 对抗性攻击可能导致训练数据质量下降，增加模型开发成本，未来需更鲁棒的防御机制。

Abstract: Today's text-to-image generative models are trained on millions of images
sourced from the Internet, each paired with a detailed caption produced by
Vision-Language Models (VLMs). This part of the training pipeline is critical
for supplying the models with large volumes of high-quality image-caption pairs
during training. However, recent work suggests that VLMs are vulnerable to
stealthy adversarial attacks, where adversarial perturbations are added to
images to mislead the VLMs into producing incorrect captions.
  In this paper, we explore the feasibility of adversarial mislabeling attacks
on VLMs as a mechanism to poisoning training pipelines for text-to-image
models. Our experiments demonstrate that VLMs are highly vulnerable to
adversarial perturbations, allowing attackers to produce benign-looking images
that are consistently miscaptioned by the VLM models. This has the effect of
injecting strong "dirty-label" poison samples into the training pipeline for
text-to-image models, successfully altering their behavior with a small number
of poisoned samples. We find that while potential defenses can be effective,
they can be targeted and circumvented by adaptive attackers. This suggests a
cat-and-mouse game that is likely to reduce the quality of training data and
increase the cost of text-to-image model development. Finally, we demonstrate
the real-world effectiveness of these attacks, achieving high attack success
(over 73%) even in black-box scenarios against commercial VLMs (Google Vertex
AI and Microsoft Azure).

</details>


### [11] [One Video to Steal Them All: 3D-Printing IP Theft through Optical Side-Channels](https://arxiv.org/abs/2506.21897)
*Twisha Chattopadhyay,Fabricio Ceschin,Marco E. Garza,Dymytriy Zyunkin,Animesh Chhotaray,Aaron P. Stebner,Saman Zonouz,Raheem Beyah*

Main category: cs.CR

TL;DR: 论文提出了一种通过视频监控逆向工程3D打印指令的方法，展示了其高准确性和效率，并验证了知识产权盗窃的可行性。


<details>
  <summary>Details</summary>
Motivation: 3D打印行业快速发展，但远程监控可能引发网络安全问题，尤其是通过视频逆向工程窃取打印指令。

Method: 通过跟踪打印机喷嘴运动轨迹并映射为G代码指令，设计了一种旋转和平移不变的等价性检查器。

Result: 模型平均准确率达90.87%，生成的指令比现有方法少30.20%，成功复制了功能完整的伪造对象。

Conclusion: 研究表明视频监控可能成为3D打印知识产权的新威胁，需加强安全防护措施。

Abstract: The 3D printing industry is rapidly growing and increasingly adopted across
various sectors including manufacturing, healthcare, and defense. However, the
operational setup often involves hazardous environments, necessitating remote
monitoring through cameras and other sensors, which opens the door to
cyber-based attacks. In this paper, we show that an adversary with access to
video recordings of the 3D printing process can reverse engineer the underlying
3D print instructions. Our model tracks the printer nozzle movements during the
printing process and maps the corresponding trajectory into G-code
instructions. Further, it identifies the correct parameters such as feed rate
and extrusion rate, enabling successful intellectual property theft. To
validate this, we design an equivalence checker that quantitatively compares
two sets of 3D print instructions, evaluating their similarity in producing
objects alike in shape, external appearance, and internal structure. Unlike
simple distance-based metrics such as normalized mean square error, our
equivalence checker is both rotationally and translationally invariant,
accounting for shifts in the base position of the reverse engineered
instructions caused by different camera positions. Our model achieves an
average accuracy of 90.87 percent and generates 30.20 percent fewer
instructions compared to existing methods, which often produce faulty or
inaccurate prints. Finally, we demonstrate a fully functional counterfeit
object generated by reverse engineering 3D print instructions from video.

</details>


### [12] [Consumer Beware! Exploring Data Brokers' CCPA Compliance](https://arxiv.org/abs/2506.21914)
*Elina van Kempen,Isita Bagayatkar,Pavel Frolikov,Chloe Georgiou,Gene Tsudik*

Main category: cs.CR

TL;DR: 研究发现，加州数据经纪商在CCPA合规性方面存在普遍问题，40%以上未回应数据访问请求，且身份验证过程可能引入新的隐私风险。


<details>
  <summary>Details</summary>
Motivation: 探讨数据经纪商在CCPA下的合规情况，揭示消费者隐私保护的现状与问题。

Method: 对543家注册数据经纪商手动提交数据访问请求，并分析其回应情况。

Result: 40%以上经纪商未回应请求，部分在身份验证中要求额外个人信息，增加隐私风险。

Conclusion: 需加强执法、明确指南并标准化合规检查，以提升消费者隐私保护和经纪商责任。

Abstract: Data brokers collect and sell the personal information of millions of
individuals, often without their knowledge or consent. The California Consumer
Privacy Act (CCPA) grants consumers the legal right to request access to, or
deletion of, their data. To facilitate these requests, California maintains an
official registry of data brokers. However, the extent to which these entities
comply with the law is unclear.
  This paper presents the first large-scale, systematic study of CCPA
compliance of all 543 officially registered data brokers. Data access requests
were manually submitted to each broker, followed by in-depth analyses of their
responses (or lack thereof). Above 40% failed to respond at all, in an apparent
violation of the CCPA. Data brokers that responded requested personal
information as part of their identity verification process, including details
they had not previously collected. Paradoxically, this means that exercising
one's privacy rights under CCPA introduces new privacy risks.
  Our findings reveal rampant non-compliance and lack of standardization of the
data access request process. These issues highlight an urgent need for stronger
enforcement, clearer guidelines, and standardized, periodic compliance checks
to enhance consumers' privacy protections and improve data broker
accountability.

</details>


### [13] [Reliability Analysis of Smart Contract Execution Architectures: A Comparative Simulation Study](https://arxiv.org/abs/2506.22180)
*Önder Gürcan*

Main category: cs.CR

TL;DR: 研究评估了智能合约执行架构的安全性和可靠性，发现Execute-Order-Validate架构在可靠性和安全性方面更具优势。


<details>
  <summary>Details</summary>
Motivation: 随着自主系统复杂性和互联性增加，可靠的安全解决方案需求迫切，智能合约是潜在解决方案，但其不可变性和不同执行架构的性能差异需要评估。

Method: 开发了评估智能合约执行安全性的模型，并基于IoT能源案例进行模拟，测试文献中报告的智能合约安全漏洞。

Result: Execute-Order-Validate架构在可靠性和安全性方面表现更优。

Conclusion: 智能合约的Execute-Order-Validate架构更适合高安全性和可靠性需求的场景。

Abstract: The industrial market continuously needs reliable solutions to secure
autonomous systems. Especially as these systems become more complex and
interconnected, reliable security solutions are becoming increasingly
important. One promising solution to tackle this challenge is using smart
contracts designed to meet contractual conditions, avoid malicious errors,
secure exchanges, and minimize the need for reliable intermediaries. However,
smart contracts are immutable. Moreover, there are different smart contract
execution architectures (namely Order-Execute and Execute-Order-Validate) that
have different throughputs. In this study, we developed an evaluation model for
assessing the security of reliable smart contract execution. We then developed
a realistic smart contract enabled IoT energy case study. Finally, we simulate
the developed case study to evaluate several smart contract security
vulnerabilities reported in the literature. Our results show that the
Execute-Order-Validate architecture is more promising regarding reliability and
security.

</details>


### [14] [Under the Hood of BlotchyQuasar: DLL-Based RAT Campaigns Against Latin America](https://arxiv.org/abs/2506.22323)
*Alessio Di Santo*

Main category: cs.CR

TL;DR: 一篇关于针对拉丁美洲（尤其是巴西）的高级恶意邮件攻击的研究，攻击者利用钓鱼邮件和DLL侧加载技术传播BlotchyQuasar恶意软件，窃取敏感信息并建立持久性。


<details>
  <summary>Details</summary>
Motivation: 揭示近期针对拉丁美洲的恶意邮件攻击活动，分析其技术特点和威胁程度。

Method: 攻击者使用钓鱼邮件诱骗用户执行恶意MSI文件，通过DLL侧加载技术绕过安全防御，传播BlotchyQuasar恶意软件。

Result: 恶意软件能够窃取浏览器凭证和银行信息，通过键盘记录和数据加密外传，但代码存在缺陷。

Conclusion: 该攻击活动技术先进且威胁严重，凸显了加强网络防御的必要性。

Abstract: A sophisticated malspam campaign was recently uncovered targeting Latin
American countries, with a particular focus on Brazil. This operation utilizes
a highly deceptive phishing email to trick users into executing a malicious MSI
file, initiating a multi-stage infection. The core of the attack leverages DLL
side-loading, where a legitimate executable from Valve Corporation is used to
load a trojanized DLL, thereby bypassing standard security defenses.
  Once active, the malware, a variant of QuasarRAT known as BlotchyQuasar, is
capable of a wide range of malicious activities. It is designed to steal
sensitive browser-stored credentials and banking information, the latter
through fake login windows mimicking well-known Brazilian banks. The threat
establishes persistence by modifying the Windows registry , captures user
keystrokes through keylogging , and exfiltrates stolen data to a
Command-and-Control (C2) server using encrypted payloads. Despite its advanced
capabilities, the malware code exhibits signs of rushed development, with
inefficiencies and poor error handling that suggest the threat actors
prioritized rapid deployment over meticulous design. Nonetheless, the campaign
extensive reach and sophisticated mechanisms pose a serious and immediate
threat to the targeted regions, underscoring the need for robust cybersecurity
defenses.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents](https://arxiv.org/abs/2506.21669)
*Wanxin Tian,Shijie Zhang,Kevin Zhang,Xiaowei Chi,Yulin Luo,Junyu Lu,Chunkai Fan,Qiang Zhou,Yiming Zhao,Ning Liu Siyu Lin,Zhiyuan Qin,Xiaozhu Ju,Shanghang Zhang,Jian Tang*

Main category: cs.AI

TL;DR: 论文提出了SEEA-R1框架，通过Tree-GRPO和MGRM解决强化微调在具身智能中的稀疏奖励和泛化问题，并在ALFWorld基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决具身智能中强化微调面临的稀疏奖励和泛化限制，以实现自主进化的多模态交互智能体。

Method: 提出Tree-GRPO（基于树的组相对策略优化）和MGRM（多模态生成奖励模型），分别解决多步推理中的奖励稀疏性和任务泛化问题。

Result: 在ALFWorld基准测试中，SEEA-R1在文本和多模态任务中分别达到85.07%和36.19%的得分，超越包括GPT-4o在内的现有方法。

Conclusion: SEEA-R1展示了作为自主进化具身智能体的潜力，为未来可扩展的具身智能研究提供了新方向。

Abstract: Self-evolution, the ability of agents to autonomously improve their reasoning
and behavior, is essential for the embodied domain with long-horizon,
real-world tasks. Despite current advancements in reinforcement fine-tuning
(RFT) showing strong performance in enhancing reasoning in LLMs, its potential
to enable self-evolving embodied intelligence with multi-modal interactions
remains largely unexplored. Specifically, reinforcement fine-tuning faces two
fundamental obstacles in embodied settings: (i) the lack of accessible
intermediate rewards in multi-step reasoning tasks limits effective learning
signals, and (ii) reliance on hand-crafted reward functions restricts
generalization to novel tasks and environments. To address these challenges, we
present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework
designed for enabling the self-evolving capabilities of embodied agents.
Specifically, to convert sparse delayed rewards into denser intermediate
signals that improve multi-step reasoning, we propose Tree-based group relative
policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into
GRPO. To generalize reward estimation across tasks and scenes, supporting
autonomous adaptation and reward-driven self-evolution, we further introduce
Multi-modal Generative Reward Model (MGRM). To holistically evaluate the
effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing
state-of-the-art methods with scores of 85.07% (textual) and 36.19%
(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also
achieves scores of 80.3% without environmental reward, surpassing all
open-source baselines and highlighting its scalability as a self-evolving
embodied agent. Additional experiments and qualitative analysis further support
the potential of SEEA-R1 for future research in scalable embodied intelligence.

</details>


### [16] [Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)
*Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori*

Main category: cs.AI

TL;DR: HRM是一种新型递归架构，通过分层和多时间尺度处理解决AI推理问题，性能优越且高效。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）的推理方法（如Chain-of-Thought）存在任务分解脆弱、数据需求大和高延迟问题，受人类大脑启发，提出HRM以改进这些问题。

Method: HRM采用两个相互依赖的递归模块：高层模块负责慢速抽象规划，低层模块处理快速详细计算，无需中间过程显式监督。

Result: HRM仅需2700万参数和1000个训练样本，在复杂推理任务（如数独和迷宫路径规划）上表现优异，并在ARC基准测试中超越更大模型。

Conclusion: HRM展示了在通用计算和通用推理系统中的潜力，是迈向人工通用智能的重要进展。

Abstract: Reasoning, the process of devising and executing complex goal-oriented action
sequences, remains a critical challenge in AI. Current large language models
(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from
brittle task decomposition, extensive data requirements, and high latency.
Inspired by the hierarchical and multi-timescale processing in the human brain,
we propose the Hierarchical Reasoning Model (HRM), a novel recurrent
architecture that attains significant computational depth while maintaining
both training stability and efficiency. HRM executes sequential reasoning tasks
in a single forward pass without explicit supervision of the intermediate
process, through two interdependent recurrent modules: a high-level module
responsible for slow, abstract planning, and a low-level module handling rapid,
detailed computations. With only 27 million parameters, HRM achieves
exceptional performance on complex reasoning tasks using only 1000 training
samples. The model operates without pre-training or CoT data, yet achieves
nearly perfect performance on challenging tasks including complex Sudoku
puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms
much larger models with significantly longer context windows on the Abstraction
and Reasoning Corpus (ARC), a key benchmark for measuring artificial general
intelligence capabilities. These results underscore HRM's potential as a
transformative advancement toward universal computation and general-purpose
reasoning systems.

</details>


### [17] [THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?](https://arxiv.org/abs/2506.21763)
*Xin Wang,Jiyao Liu,Yulong Xiao,Junzhi Ning,Lihao Liu,Junjun He,Botian Shi,Kaicheng Yu*

Main category: cs.AI

TL;DR: 论文提出了THE-Tree框架，用于从科学文献中构建领域特定的技术演化树，通过验证逻辑和证据支持来提升科学发展的预测和评估能力。


<details>
  <summary>Details</summary>
Motivation: 现有验证方法（如LLMs或传统引用网络）无法有效评估AI生成的科学命题的新颖性和准确性，缺乏结构化、可验证且因果关联的科学演化数据。

Method: THE-Tree框架通过搜索算法构建演化树，采用“Think-Verbalize-Cite-Verify”流程，由LLM提出潜在进展并验证逻辑和证据支持。

Result: 实验表明，THE-Tree在图形补全、预测未来科学发展和评估重要论文方面显著优于传统方法。

Conclusion: THE-Tree为解决科学演化数据的结构化验证提供了有效工具，显著提升了科学发展的预测和评估能力。

Abstract: Large Language Models (LLMs) are accelerating scientific idea generation, but
rigorously evaluating these numerous, often superficial, AI-generated
propositions for novelty and factual accuracy is a critical bottleneck; manual
verification is too slow.Existing validation methods are inadequate: LLMs as
standalone verifiers may hallucinate and lack domain knowledge (our findings
show ~60\% unawareness of relevant papers in specific domains), while
traditional citation networks lack explicit causality and narrative surveys are
unstructured.This underscores a core challenge: the absence of structured,
verifiable, and causally-linked historical data of scientific evolution.To
address this,we introduce \textbf{THE-Tree} (\textbf{T}echnology
\textbf{H}istory \textbf{E}volution Tree), a computational framework that
constructs such domain-specific evolution trees from scientific
literature.THE-Tree employs a search algorithm to explore evolutionary paths.
During its node expansion, it utilizes a novel "Think-Verbalize-Cite-Verify"
process: an LLM proposes potential advancements and cites supporting
literature. Critically, each proposed evolutionary link is then validated for
logical coherence and evidential support by a recovered natural language
inference mechanism that interrogates the cited literature, ensuring that each
step is grounded.We construct and validate 88 THE-Trees across diverse domains
and release a benchmark dataset including up to 71k fact verifications covering
27k papers to foster further research.Experiments demonstrate that i) in graph
completion, our THE-Tree improves hit@1 by 8\% to 14\% across multiple models
compared to traditional citation networks; ii) for predicting future scientific
developments, it improves hit@1 metric by nearly 10\%; and iii) when combined
with other methods, it boosts the performance of evaluating important
scientific papers by almost 100\%.

</details>


### [18] [MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models](https://arxiv.org/abs/2506.21784)
*Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma*

Main category: cs.AI

TL;DR: MobiVerse是一个混合框架，结合轻量级领域特定生成器和LLMs，用于高效生成和动态调整大规模人口的活动链。


<details>
  <summary>Details</summary>
Motivation: 解决传统活动模型数据需求高、机器学习适应性差以及LLMs计算限制的问题。

Method: 采用混合框架，结合领域特定生成器和LLMs，支持动态调整和响应环境变化。

Result: 在洛杉矶Westwood的案例中，成功模拟了53,000名代理的动态行为，保持计算效率并提升行为真实性。

Conclusion: MobiVerse填补了移动模拟的空白，为交通系统规划和算法测试提供了可定制平台。

Abstract: Understanding and modeling human mobility patterns is crucial for effective
transportation planning and urban development. Despite significant advances in
mobility research, there remains a critical gap in simulation platforms that
allow for algorithm development, policy implementation, and comprehensive
evaluation at scale. Traditional activity-based models require extensive data
collection and manual calibration, machine learning approaches struggle with
adaptation to dynamic conditions, and treding agent-based Large Language Models
(LLMs) implementations face computational constraints with large-scale
simulations. To address these challenges, we propose MobiVerse, a hybrid
framework leverages the efficiency of lightweight domain-specific generator for
generating base activity chains with the adaptability of LLMs for context-aware
modifications. A case study was conducted in Westwood, Los Angeles, where we
efficiently generated and dynamically adjusted schedules for the whole
population of approximately 53,000 agents on a standard PC. Our experiments
demonstrate that MobiVerse successfully enables agents to respond to
environmental feedback, including road closures, large gathering events like
football games, and congestion, through our hybrid framework. Its modular
design facilitates testing various mobility algorithms at both transportation
system and agent levels. Results show our approach maintains computational
efficiency while enhancing behavioral realism. MobiVerse bridges the gap in
mobility simulation by providing a customizable platform for mobility systems
planning and operations with benchmark algorithms. Code and videos are
available at https://github.com/ucla-mobility/MobiVerse.

</details>


### [19] [CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation](https://arxiv.org/abs/2506.21805)
*Nicolas Bougie,Narimasa Watanabe*

Main category: cs.AI

TL;DR: CitySim利用大语言模型模拟人类行为，通过递归价值驱动方法生成真实日程，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖固定规则，难以模拟复杂行为和意图，CitySim旨在解决这一问题。

Method: 采用递归价值驱动方法，结合信念、长期目标和空间记忆，模拟真实人类行为。

Result: CitySim在微观和宏观层面更接近真实人类行为，并能模拟大规模集体行为。

Conclusion: CitySim是理解和预测城市现象的可扩展、灵活平台。

Abstract: Modeling human behavior in urban environments is fundamental for social
science, behavioral studies, and urban planning. Prior work often rely on
rigid, hand-crafted rules, limiting their ability to simulate nuanced
intentions, plans, and adaptive behaviors. Addressing these challenges, we
envision an urban simulator (CitySim), capitalizing on breakthroughs in
human-level intelligence exhibited by large language models. In CitySim, agents
generate realistic daily schedules using a recursive value-driven approach that
balances mandatory activities, personal habits, and situational factors. To
enable long-term, lifelike simulations, we endow agents with beliefs, long-term
goals, and spatial memory for navigation. CitySim exhibits closer alignment
with real humans than prior work, both at micro and macro levels. Additionally,
we conduct insightful experiments by modeling tens of thousands of agents and
evaluating their collective behaviors under various real-world scenarios,
including estimating crowd density, predicting place popularity, and assessing
well-being. Our results highlight CitySim as a scalable, flexible testbed for
understanding and forecasting urban phenomena.

</details>


### [20] [Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds](https://arxiv.org/abs/2506.21887)
*Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.AI

TL;DR: Active-MoSH是一个交互式框架，用于高风险决策中多目标优化，结合软硬边界和偏好学习，提升决策者信任和效率。


<details>
  <summary>Details</summary>
Motivation: 在高风险决策中，如近距离放射治疗，需平衡多个目标（如肿瘤覆盖率和器官剂量限制），但现有方法缺乏系统性偏好细化机制，且决策者需信任最终选择。

Method: Active-MoSH框架包含局部和全局组件：局部组件通过软硬边界和概率偏好学习动态优化Pareto子集；全局组件T-MoSH通过多目标敏感性分析识别潜在高价值点。

Result: 实验表明，Active-MoSH在合成和实际应用中表现优异，用户研究证实其能加速收敛、增强决策者信任并提供更灵活的偏好表达。

Conclusion: Active-MoSH通过交互式优化和信任构建机制，显著提升了高风险多目标决策的效率和可靠性。

Abstract: High-stakes decision-making involves navigating multiple competing objectives
with expensive evaluations. For instance, in brachytherapy, clinicians must
balance maximizing tumor coverage (e.g., an aspirational target or soft bound
of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard
bound of <601 cGy to the bladder), with each plan evaluation being
resource-intensive. Selecting Pareto-optimal solutions that match implicit
preferences is challenging, as exhaustive Pareto frontier exploration is
computationally and cognitively prohibitive, necessitating interactive
frameworks to guide users. While decision-makers (DMs) often possess domain
knowledge to narrow the search via such soft-hard bounds, current methods often
lack systematic approaches to iteratively refine these multi-faceted preference
structures. Critically, DMs must trust their final decision, confident they
haven't missed superior alternatives; this trust is paramount in
high-consequence scenarios. We present Active-MoSH, an interactive local-global
framework designed for this process. Its local component integrates soft-hard
bounds with probabilistic preference learning, maintaining distributions over
DM preferences and bounds for adaptive Pareto subset refinement. This is guided
by an active sampling strategy optimizing exploration-exploitation while
minimizing cognitive burden. To build DM trust, Active-MoSH's global component,
T-MoSH, leverages multi-objective sensitivity analysis to identify potentially
overlooked, high-value points beyond immediate feedback. We demonstrate
Active-MoSH's performance benefits through diverse synthetic and real-world
applications. A user study on AI-generated image selection further validates
our hypotheses regarding the framework's ability to improve convergence,
enhance DM trust, and provide expressive preference articulation, enabling more
effective DMs.

</details>


### [21] [AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms](https://arxiv.org/abs/2506.21996)
*Raphaël Boige,Amine Boumaza,Bruno Scherrer*

Main category: cs.AI

TL;DR: 论文提出了一种新的概率模型，通过引入祖先依赖关系生成更具挑战性的游戏树，分析了AlphaBeta和Scout等算法的平均复杂度，揭示了实际性能差异。


<details>
  <summary>Details</summary>
Motivation: 传统模型因独立性假设简化了游戏结构，导致算法分析结果失真。新模型旨在更真实地模拟游戏结构复杂性。

Method: 采用固定层级条件分布逐步构建游戏树，引入祖先依赖关系，生成可调整难度的问题。

Result: AlphaBeta在深层树中表现出比Scout更大的常数乘数，导致实际性能下降。

Conclusion: 新框架为经典游戏求解算法提供了更真实的分析工具，揭示了算法在复杂结构下的性能差异。

Abstract: Deterministic game-solving algorithms are conventionally analyzed in the
light of their average-case complexity against a distribution of random
game-trees, where leaf values are independently sampled from a fixed
distribution. This simplified model enables uncluttered mathematical analysis,
revealing two key properties: root value distributions asymptotically collapse
to a single fixed value for finite-valued trees, and all reasonable algorithms
achieve global optimality. However, these findings are artifacts of the model's
design-its long criticized independence assumption strips games of structural
complexity, producing trivial instances where no algorithm faces meaningful
challenges. To address this limitation, we introduce a new probabilistic model
that incrementally constructs game-trees using a fixed level-wise conditional
distribution. By enforcing ancestor dependency, a critical structural feature
of real-world games, our framework generates problems with adjustable
difficulty while retaining some form of analytical tractability. For several
algorithms, including AlphaBeta and Scout, we derive recursive formulas
characterizing their average-case complexities under this model. These allow us
to rigorously compare algorithms on deep game-trees, where Monte-Carlo
simulations are no longer feasible. While asymptotically, all algorithms seem
to converge to identical branching factor (a result analogous to those of
independence-based models), deep finite trees reveal stark differences:
AlphaBeta incurs a significantly larger constant multiplicative factor compared
to algorithms like Scout, leading to a substantial practical slowdown. Our
framework sheds new light on classical game-solving algorithms, offering
rigorous evidence and analytical tools to advance the understanding of these
methods under a more realistic, challenging, and yet tractable model.

</details>


### [22] [LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving](https://arxiv.org/abs/2506.22005)
*Naoto Onda,Kazumi Kasaura,Yuta Oriike,Masaya Taniguchi,Akiyoshi Sannai,Sho Sonoda*

Main category: cs.AI

TL;DR: LeanConjecturer是一个自动化生成数学猜想的工具，结合规则提取和LLM生成，解决了形式化定理证明中数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 解决形式化定理证明中训练数据稀缺的挑战。

Method: 结合规则提取和LLM生成，通过迭代生成和评估产生数学猜想。

Result: 生成了12,289个猜想，其中3,776个被验证为非平凡且语法有效。

Conclusion: 该方法为定理证明系统提供了可扩展的训练数据生成方案，并展示了在数学发现中的潜力。

Abstract: We introduce LeanConjecturer, a pipeline for automatically generating
university-level mathematical conjectures in Lean 4 using Large Language Models
(LLMs). Our hybrid approach combines rule-based context extraction with
LLM-based theorem statement generation, addressing the data scarcity challenge
in formal theorem proving. Through iterative generation and evaluation,
LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with
3,776 identified as syntactically valid and non-trivial, that is, cannot be
proven by \texttt{aesop} tactic. We demonstrate the utility of these generated
conjectures for reinforcement learning through Group Relative Policy
Optimization (GRPO), showing that targeted training on domain-specific
conjectures can enhance theorem proving capabilities. Our approach generates
103.25 novel conjectures per seed file on average, providing a scalable
solution for creating training data for theorem proving systems. Our system
successfully verified several non-trivial theorems in topology, including
properties of semi-open, alpha-open, and pre-open sets, demonstrating its
potential for mathematical discovery beyond simple variations of existing
results.

</details>


### [23] [Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/abs/2506.22056)
*Xuan Zhang,Ziyan Jiang,Rui Meng,Yifei Leng,Zhenbang Xiao,Zora Zhiruo Wang,Yanyi Shang,Dehan Kong*

Main category: cs.AI

TL;DR: 该论文提出了一种多模态轨迹检索方法，通过构建统一数据集和引入优化对比学习框架，显著提升了轨迹检索性能。


<details>
  <summary>Details</summary>
Motivation: 轨迹数据在增强AI代理能力方面潜力巨大，但其表示建模尚未系统解决。

Method: 构建UATD数据集和GAE-Bench基准，提出GAE-Retriever框架，结合视觉语言模型和优化对比学习。

Result: GAE-Retriever在多个数据集上表现优于基线，检索召回率显著提升。

Conclusion: 该方法有效推动了多模态轨迹检索的发展。

Abstract: Trajectory data, capturing human actions and environmental states across
various modalities, holds significant potential for enhancing AI agent
capabilities, particularly in GUI environments. However, how to model the
representation of trajectory-level data presents a significant challenge that
has not been systematically addressed amid explosive trajectory data growth. In
this work, we introduce Multimodal Trajectory Retrieval, bridging the gap
between universal retrieval and agent-centric trajectory modeling. We construct
the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and
states across diverse real-world scenarios. Based on this, we present
GAE-Bench, a benchmark containing a large number of trajectory-based retrieval
pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework
that adopts vision-language models and incorporates optimized contrastive
learning through a token selection and the GradCache mechanism. Comprehensive
evaluations across multiple datasets show that GAE-Retriever consistently
outperforms strong baselines in retrieval recall, highlighting its
effectiveness in advancing multimodal trajectory retrieval.

</details>


### [24] [Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios](https://arxiv.org/abs/2506.22068)
*Shengyue Yao,Runqing Guo,Yangyang Qin,Miangbing Meng,Jipeng Cao,Yilun Lin,Yisheng Lv,Fei-Yue Wang*

Main category: cs.AI

TL;DR: 论文提出“Query as Test”（QaT）概念，通过逻辑查询替代传统测试方法，并引入“Extensible Scenarios Notations”（ESN）数据框架，实现异构数据的语义融合和灵活测试。


<details>
  <summary>Details</summary>
Motivation: 解决交通领域AI应用中数据碎片化和测试方法缺乏灵活性的问题。

Method: 基于Answer Set Programming（ASP）的ESN框架，统一表示多模态数据，支持逻辑查询和验证。

Result: ESN框架支持复杂语义查询、决策可解释性和隐私保护，QaT范式提升了测试的表达力和严谨性。

Conclusion: 提出“Validation-Driven Development”（VDD），以逻辑验证驱动开发，加速迭代过程。

Abstract: With the deep penetration of Artificial Intelligence (AI) in the
transportation sector, intelligent cockpits, autonomous driving, and
intelligent road networks are developing at an unprecedented pace. However, the
data ecosystems of these three key areas are increasingly fragmented and
incompatible. Especially, existing testing methods rely on data stacking, fail
to cover all edge cases, and lack flexibility. To address this issue, this
paper introduces the concept of "Query as Test" (QaT). This concept shifts the
focus from rigid, prescripted test cases to flexible, on-demand logical queries
against a unified data representation. Specifically, we identify the need for a
fundamental improvement in data storage and representation, leading to our
proposal of "Extensible Scenarios Notations" (ESN). ESN is a novel declarative
data framework based on Answer Set Programming (ASP), which uniformly
represents heterogeneous multimodal data from the cockpit, vehicle, and road as
a collection of logical facts and rules. This approach not only achieves deep
semantic fusion of data, but also brings three core advantages: (1) supports
complex and flexible semantic querying through logical reasoning; (2) provides
natural interpretability for decision-making processes; (3) allows for
on-demand data abstraction through logical rules, enabling fine-grained privacy
protection. We further elaborate on the QaT paradigm, transforming the
functional validation and safety compliance checks of autonomous driving
systems into logical queries against the ESN database, significantly enhancing
the expressiveness and formal rigor of the testing. Finally, we introduce the
concept of "Validation-Driven Development" (VDD), which suggests to guide
developments by logical validation rather than quantitative testing in the era
of Large Language Models, in order to accelerating the iteration and
development process.

</details>


### [25] [A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety](https://arxiv.org/abs/2506.22183)
*Camille François,Ludovic Péran,Ayah Bdeir,Nouha Dziri,Will Hawkins,Yacine Jernite,Sayash Kapoor,Juliet Shen,Heidy Khlaaf,Kevin Klyman,Nik Marda,Marie Pellat,Deb Raji,Divya Siddarth,Aviya Skowron,Joseph Spisak,Madhulika Srikumar,Victor Storchan,Audrey Tang,Jen Weedon*

Main category: cs.AI

TL;DR: 论文探讨了开源基础模型对AI安全的影响，提出了研究议程、技术干预和安全工具，并强调开放性和多元治理对安全的促进作用。


<details>
  <summary>Details</summary>
Motivation: 随着开源基础模型的快速发展，如何确保AI系统的安全性成为迫切问题。

Method: 通过哥伦比亚AI开放与安全会议的参与式解决方案过程，工作组制定了研究议程、技术干预和安全工具。

Result: 研究发现开放性可增强安全性，但仍存在多模态和多语言基准不足等问题。

Conclusion: 提出了五项优先研究方向，为开放、多元和负责任的AI安全学科奠定基础。

Abstract: The rapid rise of open-weight and open-source foundation models is
intensifying the obligation and reshaping the opportunity to make AI systems
safe. This paper reports outcomes from the Columbia Convening on AI Openness
and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme
involving more than forty-five researchers, engineers, and policy leaders from
academia, industry, civil society, and government. Using a participatory,
solutions-oriented process, the working groups produced (i) a research agenda
at the intersection of safety and open source AI; (ii) a mapping of existing
and needed technical interventions and open source tools to safely and
responsibly deploy open foundation models across the AI development workflow;
and (iii) a mapping of the content safety filter ecosystem with a proposed
roadmap for future research and development. We find that openness --
understood as transparent weights, interoperable tooling, and public governance
-- can enhance safety by enabling independent scrutiny, decentralized
mitigation, and culturally plural oversight. However, significant gaps persist:
scarce multimodal and multilingual benchmarks, limited defenses against
prompt-injection and compositional attacks in agentic systems, and insufficient
participatory mechanisms for communities most affected by AI harms. The paper
concludes with a roadmap of five priority research directions, emphasizing
participatory inputs, future-proof content filters, ecosystem-wide safety
infrastructure, rigorous agentic safeguards, and expanded harm taxonomies.
These recommendations informed the February 2025 French AI Action Summit and
lay groundwork for an open, plural, and accountable AI safety discipline.

</details>


### [26] [Breaking Rank Bottlenecks in Knowledge Graph Completion](https://arxiv.org/abs/2506.22271)
*Samy Badreddine,Emile van Krieken,Luciano Serafini*

Main category: cs.AI

TL;DR: 论文研究了知识图谱补全（KGC）模型中由于输出层秩瓶颈导致的性能限制，并提出了一种基于混合的输出层（KGE-MoS）以解决该问题。


<details>
  <summary>Details</summary>
Motivation: 现有KGC模型在实体数量远大于嵌入维度时，输出层的秩瓶颈限制了模型表达能力，影响了排名准确性和分数分布保真度。

Method: 通过理论和实证分析秩瓶颈的影响，提出KGE-MoS，一种基于混合的输出层设计。

Result: 在四个数据集上的实验表明，KGE-MoS以较低参数成本提升了KGC模型的性能和概率拟合度。

Conclusion: KGE-MoS有效解决了秩瓶颈问题，提升了KGC模型的性能。

Abstract: Many Knowledge Graph Completion (KGC) models, despite using powerful
encoders, rely on a simple vector-matrix multiplication to score queries
against candidate object entities. When the number of entities is larger than
the model's embedding dimension, which in practical scenarios is often by
several orders of magnitude, we have a linear output layer with a rank
bottleneck. Such bottlenecked layers limit model expressivity. We investigate
both theoretically and empirically how rank bottlenecks affect KGC models. We
find that, by limiting the set of feasible predictions, rank bottlenecks hurt
ranking accuracy and the distribution fidelity of scores. Inspired by the
language modelling literature, we propose KGE-MoS, a mixture-based output layer
to break rank bottlenecks in many KGC models. Our experiments on four datasets
show that KGE-MoS improves performance and probabilistic fit of KGC models for
a low parameter cost.

</details>


### [27] [Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates](https://arxiv.org/abs/2506.22276)
*Reuth Mirsky*

Main category: cs.AI

TL;DR: 论文主张赋予AI队友智能不服从能力，使其在人类-AI团队中能自主贡献，并探讨了不同自主级别下智能不服从的表现。


<details>
  <summary>Details</summary>
Motivation: 当前合作型AI系统过于服从，可能不利于效率或安全，需研究AI的自主性以提升团队协作效果。

Method: 提出AI自主性级别量表，并通过代表性案例说明智能不服从的重要性。

Result: 强调了将AI自主性作为独立研究方向的必要性，并初步探讨了智能不服从的边界。

Conclusion: 建议将智能不服从作为AI核心能力进行研究，并提出了初步研究框架。

Abstract: Artificial intelligence has made remarkable strides in recent years,
achieving superhuman performance across a wide range of tasks. Yet despite
these advances, most cooperative AI systems remain rigidly obedient, designed
to follow human instructions without question and conform to user expectations,
even when doing so may be counterproductive or unsafe. This paper argues for
expanding the agency of AI teammates to include \textit{intelligent
disobedience}, empowering them to make meaningful and autonomous contributions
within human-AI teams. It introduces a scale of AI agency levels and uses
representative examples to highlight the importance and growing necessity of
treating AI autonomy as an independent research focus in cooperative settings.
The paper then explores how intelligent disobedience manifests across different
autonomy levels and concludes by proposing initial boundaries and
considerations for studying disobedience as a core capability of artificial
agents.

</details>


### [28] [Conceptual Topic Aggregation](https://arxiv.org/abs/2506.22309)
*Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme*

Main category: cs.AI

TL;DR: 提出了一种基于形式概念分析（FCA）的FAT-CAT方法，用于改进主题建模的可解释性和可视化效果。


<details>
  <summary>Details</summary>
Motivation: 传统主题建模方法难以提供可解释的表示，无法深入理解数据结构和内容。

Method: 利用FCA构建概念格，实现主题的层次化、结构化表示，支持多样主题和文件类型。

Result: 在ETYNTKE数据集上的实验表明，FAT-CAT比现有方法提供更直观、有意义的数据集组成分析。

Conclusion: FCA为基础的方法在主题建模中具有更高的可解释性和实用性。

Abstract: The vast growth of data has rendered traditional manual inspection
infeasible, necessitating the adoption of computational methods for efficient
data exploration. Topic modeling has emerged as a powerful tool for analyzing
large-scale textual datasets, enabling the extraction of latent semantic
structures. However, existing methods for topic modeling often struggle to
provide interpretable representations that facilitate deeper insights into data
structure and content. In this paper, we propose FAT-CAT, an approach based on
Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and
visualization of discovered topics. Our approach can handle diverse topics and
file types -- grouped by directories -- to construct a concept lattice that
offers a structured, hierarchical representation of their topic distribution.
In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our
approach against other representation methods to demonstrate that FCA-based
aggregation provides more meaningful and interpretable insights into dataset
composition than existing topic modeling techniques.

</details>


### [29] [Embodied AI Agents: Modeling the World](https://arxiv.org/abs/2506.22355)
*Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Jitendra Malik*

Main category: cs.AI

TL;DR: 研究探讨了具身AI代理的感知、学习与行动能力，提出世界模型是其推理与规划的核心，以提升自主任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 探索具身AI代理如何通过世界模型更接近人类的学习与互动方式，增强其与环境和用户的交互能力。

Method: 提出世界模型框架，整合多模态感知、推理规划、控制与记忆，并学习用户的心理世界模型。

Result: 具身AI代理能更有效地理解环境、预测用户意图和社会情境，从而自主执行复杂任务。

Conclusion: 世界模型是具身AI代理实现高效推理与规划的关键，未来可进一步优化人机协作。

Abstract: This paper describes our research on AI agents embodied in visual, virtual or
physical forms, enabling them to interact with both users and their
environments. These agents, which include virtual avatars, wearable devices,
and robots, are designed to perceive, learn and act within their surroundings,
which makes them more similar to how humans learn and interact with the
environments as compared to disembodied agents. We propose that the development
of world models is central to reasoning and planning of embodied AI agents,
allowing these agents to understand and predict their environment, to
understand user intentions and social contexts, thereby enhancing their ability
to perform complex tasks autonomously. World modeling encompasses the
integration of multimodal perception, planning through reasoning for action and
control, and memory to create a comprehensive understanding of the physical
world. Beyond the physical world, we also propose to learn the mental world
model of users to enable better human-agent collaboration.

</details>


### [30] [AI Model Passport: Data and System Traceability Framework for Transparent AI in Health](https://arxiv.org/abs/2506.22358)
*Varvara Kalokyri,Nikolaos S. Tachos,Charalampos N. Kalantzopoulos,Stelios Sfakianakis,Haridimos Kondylakis,Dimitrios I. Zaridis,Sara Colantonio,Daniele Regge,Nikolaos Papanikolaou,The ProCAncer-I consortium,Konstantinos Marias,Dimitrios I. Fotiadis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: 论文提出AI Model Passport框架，为AI模型提供标准化数字身份和验证工具，提升透明度和可追溯性，并通过AIPassport工具在医疗影像应用中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型透明度框架依赖人工文档，缺乏可扩展性和机器可读性，难以确保模型身份和真实性，限制了可重复性和信任。

Method: 提出AI Model Passport框架，标准化记录模型元数据，并开发AIPassport工具自动化元数据收集和版本管理。

Result: 在ProCAncer-I项目的医疗影像应用中验证了AIPassport的有效性，提升了透明度和可重复性。

Conclusion: AI Model Passport为AI驱动的医疗解决方案设定了新标准，增强了信任和合规性。

Abstract: The increasing integration of Artificial Intelligence (AI) into health and
biomedical systems necessitates robust frameworks for transparency,
accountability, and ethical compliance. Existing frameworks often rely on
human-readable, manual documentation which limits scalability, comparability,
and machine interpretability across projects and platforms. They also fail to
provide a unique, verifiable identity for AI models to ensure their provenance
and authenticity across systems and use cases, limiting reproducibility and
stakeholder trust. This paper introduces the concept of the AI Model Passport,
a structured and standardized documentation framework that acts as a digital
identity and verification tool for AI models. It captures essential metadata to
uniquely identify, verify, trace and monitor AI models across their lifecycle -
from data acquisition and preprocessing to model design, development and
deployment. In addition, an implementation of this framework is presented
through AIPassport, an MLOps tool developed within the ProCAncer-I EU project
for medical imaging applications. AIPassport automates metadata collection,
ensures proper versioning, decouples results from source scripts, and
integrates with various development environments. Its effectiveness is
showcased through a lesion segmentation use case using data from the
ProCAncer-I dataset, illustrating how the AI Model Passport enhances
transparency, reproducibility, and regulatory readiness while reducing manual
effort. This approach aims to set a new standard for fostering trust and
accountability in AI-driven healthcare solutions, aspiring to serve as the
basis for developing transparent and regulation compliant AI systems across
domains.

</details>


### [31] [The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements](https://arxiv.org/abs/2506.22419)
*Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach*

Main category: cs.AI

TL;DR: 论文提出了一个自动化LLM速度运行基准测试，用于评估AI代理在科学复现中的能力，发现当前LLM在复现已知创新时仍存在困难。


<details>
  <summary>Details</summary>
Motivation: 评估AI代理在科学复现中的能力，以推动LLM在科学进步中的应用。

Method: 利用NanoGPT速度运行的19个任务，结合不同提示格式，测试LLM复现已知创新的能力。

Result: 当前LLM即使结合先进框架和详细提示，仍难以复现已知创新。

Conclusion: 该基准测试为衡量LLM自动化科学复现能力提供了简单有效的工具，是自主研究代理的必要技能之一。

Abstract: Rapid advancements in large language models (LLMs) have the potential to
assist in scientific progress. A critical capability toward this endeavor is
the ability to reproduce existing work. To evaluate the ability of AI agents to
reproduce results in an active research area, we introduce the Automated LLM
Speedrunning Benchmark, leveraging the research community contributions on the
NanoGPT speedrun, a competition to train a GPT-2 model in the shortest time.
Each of the 19 speedrun tasks provides the agent with the previous records
training script, optionally paired with one of three hint formats, ranging from
pseudocode to paper-like descriptions of the new records improvements. Records
execute quickly by design and speedrun improvements encompass diverse
code-level changes, ranging from high-level algorithmic advancements to
hardware-aware optimizations. These features make the benchmark both accessible
and realistic for the frontier problem of improving LLM training. We find that
recent reasoning LLMs combined with SoTA scaffolds struggle to reimplement
already-known innovations in our benchmark, even when given detailed hints. Our
benchmark thus provides a simple, non-saturated measure of an LLMs ability to
automate scientific reproduction, a necessary (but not sufficient) skill for an
autonomous research agent.

</details>
