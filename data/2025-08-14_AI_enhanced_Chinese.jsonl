{"id": "2508.09332", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09332", "abs": "https://arxiv.org/abs/2508.09332", "authors": ["Anshul Khairnar", "Aarya Rajoju", "Edward F. Gehringer"], "title": "Teaching Code Refactoring Using LLMs", "comment": "Accepted for presentation at the Frontiers in Education Conference,\n  Nashville, Tennessee, USA, 2-5 November 2025", "summary": "This Innovative Practice full paper explores how Large Language Models (LLMs)\ncan enhance the teaching of code refactoring in software engineering courses\nthrough real-time, context-aware feedback. Refactoring improves code quality\nbut is difficult to teach, especially with complex, real-world codebases.\nTraditional methods like code reviews and static analysis tools offer limited,\ninconsistent feedback. Our approach integrates LLM-assisted refactoring into a\ncourse project using structured prompts to help students identify and address\ncode smells such as long methods and low cohesion. Implemented in Spring 2025\nin a long-lived OSS project, the intervention is evaluated through student\nfeedback and planned analysis of code quality improvements. Findings suggest\nthat LLMs can bridge theoretical and practical learning, supporting a deeper\nunderstanding of maintainability and refactoring principles.", "AI": {"tldr": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u8bfe\u7a0b\u4e2d\u7684\u4ee3\u7801\u91cd\u6784\u6559\u5b66\u63d0\u4f9b\u5b9e\u65f6\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u53cd\u9988\u3002", "motivation": "\u91cd\u6784\u80fd\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\uff0c\u4f46\u6559\u5b66\u96be\u5ea6\u5927\uff0c\u5c24\u5176\u662f\u9762\u5bf9\u590d\u6742\u7684\u73b0\u5b9e\u4ee3\u7801\u5e93\u3002\u4f20\u7edf\u65b9\u6cd5\u5982\u4ee3\u7801\u5ba1\u67e5\u548c\u9759\u6001\u5206\u6790\u5de5\u5177\u53cd\u9988\u6709\u9650\u4e14\u4e0d\u4e00\u81f4\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u5c06LLM\u8f85\u52a9\u91cd\u6784\u878d\u5165\u8bfe\u7a0b\u9879\u76ee\uff0c\u5e2e\u52a9\u5b66\u751f\u8bc6\u522b\u548c\u89e3\u51b3\u4ee3\u7801\u5f02\u5473\uff08\u5982\u957f\u65b9\u6cd5\u3001\u4f4e\u5185\u805a\uff09\u3002", "result": "\u521d\u6b65\u53d1\u73b0\u8868\u660e\uff0cLLMs\u80fd\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u8df5\u5b66\u4e60\uff0c\u52a0\u6df1\u5b66\u751f\u5bf9\u53ef\u7ef4\u62a4\u6027\u548c\u91cd\u6784\u539f\u5219\u7684\u7406\u89e3\u3002", "conclusion": "LLMs\u5728\u4ee3\u7801\u91cd\u6784\u6559\u5b66\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u6709\u6548\u63d0\u5347\u5b66\u4e60\u6548\u679c\u3002"}}
{"id": "2508.09366", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2508.09366", "abs": "https://arxiv.org/abs/2508.09366", "authors": ["Qiaolin Qin", "Xingfang Wu", "Heng Li", "Ettore Merlo"], "title": "Plug it and Play on Logs: A Configuration-Free Statistic-Based Log Parser", "comment": null, "summary": "Log parsing is an essential task in log analysis, and many tools have been\ndesigned to accomplish it. Existing log parsers can be categorized into\nstatistic-based and semantic-based approaches. In comparison to semantic-based\nparsers, existing statistic-based parsers tend to be more efficient, require\nlower computational costs, and be more privacy-preserving thanks to on-premise\ndeployment, but often fall short in their accuracy (e.g., grouping or parsing\naccuracy) and generalizability. Therefore, it became a common belief that\nstatistic-based parsers cannot be as effective as semantic-based parsers since\nthe latter could take advantage of external knowledge supported by pretrained\nlanguage models. Our work, however, challenges this belief with a novel\nstatistic-based parser, PIPLUP. PIPLUP eliminates the pre-assumption of the\nposition of constant tokens for log grouping and relies on data-insensitive\nparameters to overcome the generalizability challenge, allowing \"plug and play\"\non given log files. According to our experiments on an open-sourced large log\ndataset, PIPLUP shows promising accuracy and generalizability with the\ndata-insensitive default parameter set. PIPLUP not only outperforms the\nstate-of-the-art statistic-based log parsers, Drain and its variants, but also\nobtains a competitive performance compared to the best unsupervised\nsemantic-based log parser (i.e., LUNAR). Further, PIPLUP exhibits low time\nconsumption without GPU acceleration and external API usage; our simple,\nefficient, and effective approach makes it more practical in real-world\nadoptions, especially when costs and privacy are of major concerns.", "AI": {"tldr": "PIPLUP\u662f\u4e00\u79cd\u65b0\u578b\u7684\u57fa\u4e8e\u7edf\u8ba1\u7684\u65e5\u5fd7\u89e3\u6790\u5668\uff0c\u6311\u6218\u4e86\u8bed\u4e49\u89e3\u6790\u5668\u66f4\u4f18\u7684\u666e\u904d\u89c2\u70b9\uff0c\u901a\u8fc7\u6570\u636e\u4e0d\u654f\u611f\u53c2\u6570\u5b9e\u73b0\u9ad8\u51c6\u786e\u6027\u548c\u901a\u7528\u6027\uff0c\u4e14\u65e0\u9700GPU\u52a0\u901f\u6216\u5916\u90e8API\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7edf\u8ba1\u7684\u65e5\u5fd7\u89e3\u6790\u5668\u5728\u6548\u7387\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u51c6\u786e\u6027\u548c\u901a\u7528\u6027\u4e0d\u8db3\uff0c\u666e\u904d\u8ba4\u4e3a\u8bed\u4e49\u89e3\u6790\u5668\u66f4\u4f18\u3002PIPLUP\u65e8\u5728\u6253\u7834\u8fd9\u4e00\u89c2\u70b9\u3002", "method": "PIPLUP\u6d88\u9664\u4e86\u65e5\u5fd7\u5206\u7ec4\u4e2d\u5e38\u91cf\u4ee4\u724c\u4f4d\u7f6e\u7684\u9884\u8bbe\uff0c\u91c7\u7528\u6570\u636e\u4e0d\u654f\u611f\u53c2\u6570\u5b9e\u73b0\u201c\u5373\u63d2\u5373\u7528\u201d\uff0c\u65e0\u9700\u4f9d\u8d56\u5916\u90e8\u77e5\u8bc6\u3002", "result": "\u5728\u5927\u578b\u5f00\u6e90\u65e5\u5fd7\u6570\u636e\u96c6\u4e0a\uff0cPIPLUP\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7edf\u8ba1\u89e3\u6790\u5668\uff08\u5982Drain\uff09\uff0c\u5e76\u4e0e\u6700\u4f73\u65e0\u76d1\u7763\u8bed\u4e49\u89e3\u6790\u5668\uff08LUNAR\uff09\u7ade\u4e89\u3002", "conclusion": "PIPLUP\u9ad8\u6548\u3001\u7b80\u5355\u4e14\u5b9e\u7528\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6210\u672c\u548c\u9690\u79c1\u654f\u611f\u7684\u5b9e\u9645\u573a\u666f\u3002"}}
{"id": "2508.09537", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09537", "abs": "https://arxiv.org/abs/2508.09537", "authors": ["Yanzhou Li", "Tianlin Li", "Yiran Zhang", "Shangqing Liu", "Aishan Liu", "Yang Liu"], "title": "Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion", "comment": null, "summary": "Large Language Models (LLMs) are increasingly used for function completion in\nrepository-scale codebases. Prior studies demonstrate that when explicit\ninstructions--such as docstrings--are provided, these models can generate\nhighly accurate implementations. However, in real-world repositories, such\nannotations are frequently absent, and performance drops substantially without\nthem. To address this gap, we frame the task as a three-stage process. The\nfirst stage focuses on intent inference, where the model analyzes the code\npreceding the target function to uncover cues about the desired functionality.\nSuch preceding context often encodes subtle but critical information, and we\ndesign a reasoning-based prompting framework to guide the LLM through\nstep-by-step extraction and synthesis of these signals before any code is\ngenerated. The second stage introduces an optional interactive refinement\nmechanism to handle cases where preceding context alone is insufficient for\nintent recovery. In this stage, the model proposes a small set of candidate\nintentions, enabling the developer to select or edit them so that the inferred\nintent closely matches the actual requirement. Finally, in the third stage, the\nLLM generates the target function conditioned on the finalized intent. To\nsupport this pipeline, we curate a dataset of 40,000 examples annotated with\nintermediate reasoning traces and corresponding docstrings. Extensive\nexperiments on DevEval and ComplexCodeEval show that our approach consistently\nboosts multiple LLMs, achieving over 20\\% relative gains in both\nreference-based and execution-based metrics, with the interactive refinement\nstage delivering additional improvements beyond these gains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u9636\u6bb5\u65b9\u6cd5\uff0c\u901a\u8fc7\u610f\u56fe\u63a8\u65ad\u3001\u4ea4\u4e92\u5f0f\u7cbe\u70bc\u548c\u4ee3\u7801\u751f\u6210\uff0c\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u6ce8\u91ca\u4ee3\u7801\u5e93\u4e2d\u7684\u529f\u80fd\u8865\u5168\u80fd\u529b\u3002", "motivation": "\u73b0\u5b9e\u4ee3\u7801\u5e93\u4e2d\u5e38\u7f3a\u4e4f\u663e\u5f0f\u6ce8\u91ca\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u89e3\u51b3\u65e0\u6ce8\u91ca\u60c5\u51b5\u4e0b\u7684\u529f\u80fd\u8865\u5168\u95ee\u9898\u3002", "method": "\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a1) \u610f\u56fe\u63a8\u65ad\uff0c\u5206\u6790\u4ee3\u7801\u4e0a\u4e0b\u6587\uff1b2) \u4ea4\u4e92\u5f0f\u7cbe\u70bc\uff0c\u5f00\u53d1\u8005\u53c2\u4e0e\u610f\u56fe\u786e\u8ba4\uff1b3) \u4ee3\u7801\u751f\u6210\u3002", "result": "\u5728DevEval\u548cComplexCodeEval\u4e0a\uff0c\u76f8\u5bf9\u6307\u6807\u63d0\u5347\u8d8520%\uff0c\u4ea4\u4e92\u5f0f\u7cbe\u70bc\u8fdb\u4e00\u6b65\u4f18\u5316\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u65e0\u6ce8\u91ca\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u4ea4\u4e92\u5f0f\u8bbe\u8ba1\u589e\u5f3a\u4e86\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.09648", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.09648", "abs": "https://arxiv.org/abs/2508.09648", "authors": ["Taohong Zhu", "Lucas C. Cordeiro", "Youcheng Sun"], "title": "ReqInOne: A Large Language Model-Based Agent for Software Requirements Specification Generation", "comment": null, "summary": "Software Requirements Specification (SRS) is one of the most important\ndocuments in software projects, but writing it manually is time-consuming and\noften leads to ambiguity. Existing automated methods rely heavily on manual\nanalysis, while recent Large Language Model (LLM)-based approaches suffer from\nhallucinations and limited controllability. In this paper, we propose ReqInOne,\nan LLM-based agent that follows the common steps taken by human requirements\nengineers when writing an SRS to convert natural language into a structured\nSRS. ReqInOne adopts a modular architecture by decomposing SRS generation into\nthree tasks: summary, requirement extraction, and requirement classification,\neach supported by tailored prompt templates to improve the quality and\nconsistency of LLM outputs.\n  We evaluate ReqInOne using GPT-4o, LLaMA 3, and DeepSeek-R1, and compare the\ngenerated SRSs against those produced by the holistic GPT-4-based method from\nprior work as well as by entry-level requirements engineers. Expert evaluations\nshow that ReqInOne produces more accurate and well-structured SRS documents.\nThe performance advantage of ReqInOne benefits from its modular design, and\nexperimental results further demonstrate that its requirement classification\ncomponent achieves comparable or even better results than the state-of-the-art\nrequirement classification model.", "AI": {"tldr": "ReqInOne\u662f\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u4ee3\u7406\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u5c06SRS\u751f\u6210\u5206\u89e3\u4e3a\u6458\u8981\u3001\u9700\u6c42\u63d0\u53d6\u548c\u9700\u6c42\u5206\u7c7b\u4e09\u4e2a\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86SRS\u6587\u6863\u7684\u51c6\u786e\u6027\u548c\u7ed3\u6784\u5316\u7a0b\u5ea6\u3002", "motivation": "\u624b\u52a8\u7f16\u5199SRS\u8017\u65f6\u4e14\u6613\u4ea7\u751f\u6b67\u4e49\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u5206\u6790\u6216\u5b58\u5728\u5e7b\u89c9\u548c\u53ef\u63a7\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "ReqInOne\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\uff0c\u5206\u89e3SRS\u751f\u6210\u4e3a\u4e09\u4e2a\u4efb\u52a1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u4f7f\u7528\u5b9a\u5236\u63d0\u793a\u6a21\u677f\u4f18\u5316LLM\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cReqInOne\u751f\u6210\u7684SRS\u6bd4\u57fa\u4e8eGPT-4\u7684\u6574\u4f53\u65b9\u6cd5\u548c\u521d\u7ea7\u5de5\u7a0b\u5e08\u66f4\u51c6\u786e\u3001\u7ed3\u6784\u5316\u3002", "conclusion": "ReqInOne\u7684\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u9700\u6c42\u5206\u7c7b\u7ec4\u4ef6\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.09201", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09201", "abs": "https://arxiv.org/abs/2508.09201", "authors": ["Shuang Liang", "Zhihao Xu", "Jialing Tao", "Hui Xue", "Xiting Wang"], "title": "Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models: A Unified and Accurate Approach", "comment": null, "summary": "Despite extensive alignment efforts, Large Vision-Language Models (LVLMs)\nremain vulnerable to jailbreak attacks, posing serious safety risks. Although\nrecent detection works have shifted to internal representations due to their\nrich cross-modal information, most methods rely on heuristic rules rather than\nprincipled objectives, resulting in suboptimal performance. To address these\nlimitations, we propose Learning to Detect (LoD), a novel unsupervised\nframework that formulates jailbreak detection as anomaly detection. LoD\nintroduces two key components: Multi-modal Safety Concept Activation Vectors\n(MSCAV), which capture layer-wise safety-related representations across\nmodalities, and the Safety Pattern Auto-Encoder, which models the distribution\nof MSCAV derived from safe inputs and detects anomalies via reconstruction\nerrors. By training the auto-encoder (AE) solely on safe samples without attack\nlabels, LoD naturally identifies jailbreak inputs as distributional anomalies,\nenabling accurate and unified detection of jailbreak attacks. Comprehensive\nexperiments on three different LVLMs and five benchmarks demonstrate that LoD\nachieves state-of-the-art performance, with an average AUROC of 0.9951 and an\nimprovement of up to 38.89% in the minimum AUROC over the strongest baselines.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLoD\u7684\u65e0\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u5f02\u5e38\u68c0\u6d4b\u8bc6\u522b\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLM\uff09\u7684\u8d8a\u72f1\u653b\u51fb\uff0c\u5229\u7528\u591a\u6a21\u6001\u5b89\u5168\u6982\u5ff5\u6fc0\u6d3b\u5411\u91cf\uff08MSCAV\uff09\u548c\u5b89\u5168\u6a21\u5f0f\u81ea\u52a8\u7f16\u7801\u5668\uff08AE\uff09\u5b9e\u73b0\u9ad8\u6548\u68c0\u6d4b\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u5c1d\u8bd5\u901a\u8fc7\u5185\u90e8\u8868\u5f81\u68c0\u6d4b\u8d8a\u72f1\u653b\u51fb\uff0c\u4f46\u591a\u6570\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u6027\u80fd\u4e0d\u4f73\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u57fa\u4e8e\u539f\u5219\u6027\u76ee\u6807\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "method": "LoD\u6846\u67b6\u901a\u8fc7MSCAV\u6355\u6349\u8de8\u6a21\u6001\u7684\u5b89\u5168\u76f8\u5173\u8868\u5f81\uff0c\u5e76\u5229\u7528AE\u5efa\u6a21\u5b89\u5168\u8f93\u5165\u7684\u5206\u5e03\uff0c\u901a\u8fc7\u91cd\u6784\u8bef\u5dee\u68c0\u6d4b\u5f02\u5e38\u3002", "result": "\u5728\u4e09\u79cdLVLM\u548c\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLoD\u7684\u5e73\u5747AUROC\u8fbe\u52300.9951\uff0c\u8f83\u6700\u5f3a\u57fa\u7ebf\u63d0\u5347\u9ad8\u8fbe38.89%\u3002", "conclusion": "LoD\u65e0\u9700\u653b\u51fb\u6807\u7b7e\u5373\u53ef\u9ad8\u6548\u68c0\u6d4b\u8d8a\u72f1\u653b\u51fb\uff0c\u4e3aLVLM\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09277", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.09277", "abs": "https://arxiv.org/abs/2508.09277", "authors": ["Soumia Mehimeh"], "title": "Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning", "comment": null, "summary": "Value function initialization (VFI) is an effective way to achieve a\njumpstart in reinforcement learning (RL) by leveraging value estimates from\nprior tasks. While this approach is well established in tabular settings,\nextending it to deep reinforcement learning (DRL) poses challenges due to the\ncontinuous nature of the state-action space, the noisy approximations of neural\nnetworks, and the impracticality of storing all past models for reuse. In this\nwork, we address these challenges and introduce DQInit, a method that adapts\nvalue function initialization to DRL. DQInit reuses compact tabular Q-values\nextracted from previously solved tasks as a transferable knowledge base. It\nemploys a knownness-based mechanism to softly integrate these transferred\nvalues into underexplored regions and gradually shift toward the agent's\nlearned estimates, avoiding the limitations of fixed time decay. Our approach\noffers a novel perspective on knowledge transfer in DRL by relying solely on\nvalue estimates rather than policies or demonstrations, effectively combining\nthe strengths of jumpstart RL and policy distillation while mitigating their\ndrawbacks. Experiments across multiple continuous control tasks demonstrate\nthat DQInit consistently improves early learning efficiency, stability, and\noverall performance compared to standard initialization and existing transfer\ntechniques.", "AI": {"tldr": "DQInit\u662f\u4e00\u79cd\u5c06\u503c\u51fd\u6570\u521d\u59cb\u5316\uff08VFI\uff09\u6269\u5c55\u5230\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u7528\u7d27\u51d1\u7684\u8868\u683cQ\u503c\u4f5c\u4e3a\u53ef\u8f6c\u79fb\u77e5\u8bc6\u5e93\uff0c\u63d0\u9ad8\u65e9\u671f\u5b66\u4e60\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\u503c\u51fd\u6570\u521d\u59cb\u5316\u7684\u6311\u6218\uff0c\u5982\u8fde\u7eed\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u3001\u795e\u7ecf\u7f51\u7edc\u566a\u58f0\u8fd1\u4f3c\u548c\u5b58\u50a8\u8fc7\u53bb\u6a21\u578b\u7684\u4e0d\u53ef\u884c\u6027\u3002", "method": "DQInit\u901a\u8fc7\u57fa\u4e8e\u5df2\u77e5\u5ea6\u7684\u673a\u5236\u8f6f\u6027\u6574\u5408\u8f6c\u79fb\u503c\u5230\u672a\u63a2\u7d22\u533a\u57df\uff0c\u5e76\u9010\u6b65\u8f6c\u5411\u4ee3\u7406\u5b66\u4e60\u4f30\u8ba1\uff0c\u907f\u514d\u56fa\u5b9a\u65f6\u95f4\u8870\u51cf\u7684\u9650\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDQInit\u5728\u591a\u4e2a\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u65e9\u671f\u5b66\u4e60\u6548\u7387\u3001\u7a33\u5b9a\u6027\u548c\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "DQInit\u4e3aDRL\u4e2d\u7684\u77e5\u8bc6\u8f6c\u79fb\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u4ec5\u4f9d\u8d56\u503c\u4f30\u8ba1\u800c\u975e\u7b56\u7565\u6216\u6f14\u793a\uff0c\u7ed3\u5408\u4e86\u8df3\u542f\u52a8RL\u548c\u7b56\u7565\u84b8\u998f\u7684\u4f18\u52bf\u3002"}}
{"id": "2508.09676", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09676", "abs": "https://arxiv.org/abs/2508.09676", "authors": ["Vishal Khare", "Vijay Saini", "Deepak Sharma", "Anand Kumar", "Ankit Rana", "Anshul Yadav"], "title": "DeputyDev -- AI Powered Developer Assistant: Breaking the Code Review Logjam through Contextual AI to Boost Developer Productivity", "comment": "12 pages, 5 figures, 6 pages of supplementary materials", "summary": "This study investigates the implementation and efficacy of DeputyDev, an\nAI-powered code review assistant developed to address inefficiencies in the\nsoftware development process. The process of code review is highly inefficient\nfor several reasons, such as it being a time-consuming process, inconsistent\nfeedback, and review quality not being at par most of the time. Using our\ntelemetry data, we observed that at TATA 1mg, pull request (PR) processing\nexhibits significant inefficiencies, with average pick-up and review times of\n73 and 82 hours, respectively, resulting in a 6.2 day closure cycle. The review\ncycle was marked by prolonged iterative communication between the reviewing and\nsubmitting parties. Research from the University of California, Irvine\nindicates that interruptions can lead to an average of 23 minutes of lost\nfocus, critically affecting code quality and timely delivery. To address these\nchallenges, we developed DeputyDev's PR review capabilities by providing\nautomated, contextual code reviews. We conducted a rigorous double-controlled\nA/B experiment involving over 200 engineers to evaluate DeputyDev's impact on\nreview times. The results demonstrated a statistically significant reduction in\nboth average per PR (23.09%) and average per-line-of-code (40.13%) review\ndurations. After implementing safeguards to exclude outliers, DeputyDev has\nbeen effectively rolled out across the entire organisation. Additionally, it\nhas been made available to external companies as a Software-as-a-Service (SaaS)\nsolution, currently supporting the daily work of numerous engineering\nprofessionals. This study explores the implementation and effectiveness of\nAI-assisted code reviews in improving development workflow timelines and code.", "AI": {"tldr": "DeputyDev\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u4ee3\u7801\u5ba1\u67e5\u52a9\u624b\uff0c\u65e8\u5728\u89e3\u51b3\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u4f4e\u6548\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4ee3\u7801\u5ba1\u67e5\u65f6\u95f4\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u8fc7\u7a0b\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u3001\u53cd\u9988\u4e0d\u4e00\u81f4\u548c\u8d28\u91cf\u4e0d\u8fbe\u6807\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u5f00\u53d1\u5468\u671f\u5ef6\u957f\u548c\u4ee3\u7801\u8d28\u91cf\u4e0b\u964d\u3002", "method": "\u901a\u8fc7\u5f00\u53d1DeputyDev\u7684\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u529f\u80fd\uff0c\u5e76\u8fdb\u884c\u53cc\u76f2A/B\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u5176\u5bf9\u5ba1\u67e5\u65f6\u95f4\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cDeputyDev\u663e\u8457\u51cf\u5c11\u4e86\u6bcfPR\uff0823.09%\uff09\u548c\u6bcf\u884c\u4ee3\u7801\uff0840.13%\uff09\u7684\u5ba1\u67e5\u65f6\u95f4\u3002", "conclusion": "DeputyDev\u6210\u529f\u63d0\u9ad8\u4e86\u5f00\u53d1\u6d41\u7a0b\u6548\u7387\uff0c\u5e76\u5df2\u4f5c\u4e3aSaaS\u89e3\u51b3\u65b9\u6848\u63a8\u5e7f\u81f3\u5916\u90e8\u516c\u53f8\u3002"}}
{"id": "2508.09213", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2508.09213", "abs": "https://arxiv.org/abs/2508.09213", "authors": ["Clifton Paul Robinson", "Salvatore D'Oro", "Tommaso Melodia"], "title": "VeriPHY: Physical Layer Signal Authentication for Wireless Communication in 5G Environments", "comment": "7 pages, 10 figures, 2 tables, IEEE Military Communications\n  Conference 2025 (MILCOM '25)", "summary": "Physical layer authentication (PLA) uses inherent characteristics of the\ncommunication medium to provide secure and efficient authentication in wireless\nnetworks, bypassing the need for traditional cryptographic methods. With\nadvancements in deep learning, PLA has become a widely adopted technique for\nits accuracy and reliability. In this paper, we introduce VeriPHY, a novel deep\nlearning-based PLA solution for 5G networks, which enables unique device\nidentification by embedding signatures within wireless I/Q transmissions using\nsteganography. VeriPHY continuously generates pseudo-random signatures by\nsampling from Gaussian Mixture Models whose distribution is carefully varied to\nensure signature uniqueness and stealthiness over time, and then embeds the\nnewly generated signatures over I/Q samples transmitted by users to the 5G gNB.\nUtilizing deep neural networks, VeriPHY identifies and authenticates users\nbased on these embedded signatures. VeriPHY achieves high precision,\nidentifying unique signatures between 93% and 100% with low false positive\nrates and an inference time of 28 ms when signatures are updated every 20 ms.\nAdditionally, we also demonstrate a stealth generation mode where signatures\nare generated in a way that makes them virtually indistinguishable from\nunaltered 5G signals while maintaining over 93% detection accuracy.", "AI": {"tldr": "VeriPHY\u662f\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7269\u7406\u5c42\u8ba4\u8bc1\u65b9\u6848\uff0c\u7528\u4e8e5G\u7f51\u7edc\uff0c\u901a\u8fc7\u9690\u5199\u672f\u5728\u65e0\u7ebfI/Q\u4f20\u8f93\u4e2d\u5d4c\u5165\u7b7e\u540d\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8bbe\u5907\u8ba4\u8bc1\u3002", "motivation": "\u4f20\u7edf\u52a0\u5bc6\u65b9\u6cd5\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\u6548\u7387\u8f83\u4f4e\uff0c\u7269\u7406\u5c42\u8ba4\u8bc1\uff08PLA\uff09\u5229\u7528\u901a\u4fe1\u4ecb\u8d28\u7684\u56fa\u6709\u7279\u6027\u63d0\u4f9b\u5b89\u5168\u8ba4\u8bc1\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "VeriPHY\u901a\u8fc7\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u751f\u6210\u4f2a\u968f\u673a\u7b7e\u540d\uff0c\u5d4c\u5165\u5230\u7528\u6237\u4f20\u8f93\u7684I/Q\u6837\u672c\u4e2d\uff0c\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bc6\u522b\u548c\u8ba4\u8bc1\u7528\u6237\u3002", "result": "VeriPHY\u572893%\u81f3100%\u7684\u8303\u56f4\u5185\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7b7e\u540d\u8bc6\u522b\uff0c\u5047\u9633\u6027\u7387\u4f4e\uff0c\u63a8\u65ad\u65f6\u95f4\u4e3a28\u6beb\u79d2\u3002", "conclusion": "VeriPHY\u57285G\u7f51\u7edc\u4e2d\u63d0\u4f9b\u9ad8\u6548\u3001\u9690\u853d\u7684\u8bbe\u5907\u8ba4\u8bc1\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2508.09292", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09292", "abs": "https://arxiv.org/abs/2508.09292", "authors": ["Sundong Kim"], "title": "The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards", "comment": null, "summary": "The ability to rapidly adapt to novel and unforeseen environmental changes is\na cornerstone of artificial general intelligence (AGI), yet it remains a\ncritical blind spot in most existing AI benchmarks. Traditional evaluation\nlargely focuses on optimizing performance within fixed environments, failing to\nassess systems' flexibility and generalization capabilities when faced with\neven subtle rule or structural modifications. Addressing this gap, I introduce\nthe Othello AI Arena, a novel benchmark framework designed to evaluate\nintelligent systems based on their capacity for limited-time adaptation to\nunseen environments. Our platform poses a meta-learning challenge: participants\nmust develop systems that can analyze the specific configuration and rules of a\nnovel Othello board within a strict time limit (60 seconds) and generate a\ntailored, high-performing strategy for that unique environment. With this,\nevaluation of the meta-level intelligence can be separated from the task-level\nstrategy performance. The Arena features a diverse set of game stages,\nincluding public stages for development and private stages with structural and\nrule variations designed to test genuine adaptive and generalization\ncapabilities. Implemented as an accessible web-based platform, the Arena\nprovides real-time visualization, automated evaluation using multi-dimensional\nmetrics, and comprehensive logging for post-hoc analysis. Initial observations\nfrom pilot tests and preliminary student engagements highlight fascinating\npatterns in adaptation approaches, ranging from rapid parameter tuning to\nrudimentary environmental model learning through simulation. The Othello AI\nArena offers a unique educational tool and a valuable research benchmark for\nfostering and evaluating the crucial skill of rapid, intelligent adaptation in\nAI systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Othello AI Arena\uff0c\u4e00\u4e2a\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u6709\u9650\u65f6\u95f4\u5185\u9002\u5e94\u65b0\u73af\u5883\u80fd\u529b\u7684\u57fa\u51c6\u6846\u67b6\u3002", "motivation": "\u73b0\u6709AI\u57fa\u51c6\u672a\u80fd\u8bc4\u4f30\u7cfb\u7edf\u5728\u73af\u5883\u53d8\u5316\u4e2d\u7684\u7075\u6d3b\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u8fd9\u662fAGI\u7684\u5173\u952e\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86Othello AI Arena\uff0c\u8981\u6c42\u7cfb\u7edf\u572860\u79d2\u5185\u5206\u6790\u65b0Othello\u68cb\u76d8\u914d\u7f6e\u5e76\u751f\u6210\u5b9a\u5236\u7b56\u7565\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u6307\u6807\u8bc4\u4f30\u3002", "result": "\u521d\u6b65\u6d4b\u8bd5\u663e\u793a\u7cfb\u7edf\u9002\u5e94\u7b56\u7565\u591a\u6837\uff0c\u4ece\u5feb\u901f\u53c2\u6570\u8c03\u6574\u5230\u6a21\u62df\u5b66\u4e60\u73af\u5883\u6a21\u578b\u3002", "conclusion": "Othello AI Arena\u662f\u8bc4\u4f30AI\u5feb\u901f\u9002\u5e94\u80fd\u529b\u7684\u72ec\u7279\u5de5\u5177\uff0c\u5bf9\u7814\u7a76\u548c\u6559\u80b2\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2508.09680", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.09680", "abs": "https://arxiv.org/abs/2508.09680", "authors": ["Orvila Sarker", "Mona Jamshaid", "M. Ali Babar"], "title": "Inclusive Employment Pathways: Career Success Factors for Autistic Individuals in Software Engineering", "comment": null, "summary": "Research has highlighted the valuable contributions of autistic individuals\nin the Information and Communication Technology (ICT) sector, particularly in\nareas such as software development, testing, and cybersecurity. Their strengths\nin information processing, attention to detail, innovative thinking, and\ncommitment to high-quality outcomes in the ICT domain are well-documented.\nHowever, despite their potential, autistic individuals often face barriers in\nSoftware Engineering (SE) roles due to a lack of personalised tools, complex\nwork environments, non-inclusive recruitment practices, limited co-worker\nsupport, challenging social dynamics and so on. Motivated by the ethical\nframework of the neurodiversity movement and the success of pioneering\ninitiatives like the Dandelion program, corporate Diversity, Equity, and\nInclusion (DEI) in the ICT sector has increasingly focused on autistic talent.\nThis movement fundamentally reframes challenges not as individual deficits but\nas failures of environments designed for a neurotypical majority. Despite this\nprogress, there is no synthesis of knowledge reporting the full pathway from\nsoftware engineering education through to sustainable workplace inclusion. To\naddress this, we conducted a Systematic Review of 30 studies and identified 18\nsuccess factors grouped into four thematic categories: (1) Software Engineering\nEducation, (2) Career and Employment Training, (3) Work Environment, and (4)\nTools and Assistive Technologies. Our findings offer evidence-based\nrecommendations for educational institutions, employers, organisations, and\ntool developers to enhance the inclusion of autistic individuals in SE. These\ninclude strategies for inclusive meeting and collaboration practices,\naccessible and structured work environments, clear role and responsibility\ndefinitions, and the provision of tailored workplace accommodations.", "AI": {"tldr": "\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728ICT\u9886\u57df\uff08\u5982\u8f6f\u4ef6\u5f00\u53d1\u3001\u6d4b\u8bd5\u548c\u7f51\u7edc\u5b89\u5168\uff09\u5177\u6709\u72ec\u7279\u4f18\u52bf\uff0c\u4f46\u9762\u4e34\u804c\u573a\u969c\u788d\u3002\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u63d0\u51fa18\u4e2a\u6210\u529f\u56e0\u7d20\uff0c\u5206\u4e3a\u56db\u7c7b\uff0c\u4e3a\u6559\u80b2\u673a\u6784\u3001\u96c7\u4e3b\u548c\u5de5\u5177\u5f00\u53d1\u8005\u63d0\u4f9b\u5305\u5bb9\u6027\u5efa\u8bae\u3002", "motivation": "\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728ICT\u9886\u57df\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u804c\u573a\u969c\u788d\u9650\u5236\u4e86\u4ed6\u4eec\u7684\u53d1\u5c55\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\uff0c\u4e3a\u4ece\u6559\u80b2\u5230\u804c\u573a\u7684\u5168\u8def\u5f84\u63d0\u4f9b\u5305\u5bb9\u6027\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5bf930\u9879\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\uff0c\u8bc6\u522b\u51fa18\u4e2a\u6210\u529f\u56e0\u7d20\uff0c\u5206\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u3001\u804c\u4e1a\u57f9\u8bad\u3001\u5de5\u4f5c\u73af\u5883\u548c\u8f85\u52a9\u5de5\u5177\u56db\u7c7b\u3002", "result": "\u63d0\u51fa\u56db\u7c7b\u6210\u529f\u56e0\u7d20\uff0c\u5305\u62ec\u5305\u5bb9\u6027\u4f1a\u8bae\u5b9e\u8df5\u3001\u7ed3\u6784\u5316\u5de5\u4f5c\u73af\u5883\u3001\u660e\u786e\u804c\u8d23\u548c\u4e2a\u6027\u5316\u804c\u573a\u8c03\u6574\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u5347\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u5305\u5bb9\u6027\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u5efa\u8bae\uff0c\u5f3a\u8c03\u73af\u5883\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.09288", "categories": ["cs.CR", "cs.AI", "cs.CL", "68T07, 94A60", "D.4.6; K.6.5; E.3; I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2508.09288", "abs": "https://arxiv.org/abs/2508.09288", "authors": ["Aayush Gupta"], "title": "Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs", "comment": "2 figures, 3 tables; code and certification harness:\n  https://github.com/ayushgupta4897/Contextual-Integrity-Verification ;\n  Elite-Attack dataset: https://huggingface.co/datasets/zyushg/elite-attack", "summary": "Large language models (LLMs) remain acutely vulnerable to prompt injection\nand related jailbreak attacks; heuristic guardrails (rules, filters, LLM\njudges) are routinely bypassed. We present Contextual Integrity Verification\n(CIV), an inference-time security architecture that attaches cryptographically\nsigned provenance labels to every token and enforces a source-trust lattice\ninside the transformer via a pre-softmax hard attention mask (with optional\nFFN/residual gating). CIV provides deterministic, per-token non-interference\nguarantees on frozen models: lower-trust tokens cannot influence higher-trust\nrepresentations. On benchmarks derived from recent taxonomies of\nprompt-injection vectors (Elite-Attack + SoK-246), CIV attains 0% attack\nsuccess rate under the stated threat model while preserving 93.1% token-level\nsimilarity and showing no degradation in model perplexity on benign tasks; we\nnote a latency overhead attributable to a non-optimized data path. Because CIV\nis a lightweight patch -- no fine-tuning required -- we demonstrate drop-in\nprotection for Llama-3-8B and Mistral-7B. We release a reference\nimplementation, an automated certification harness, and the Elite-Attack corpus\nto support reproducible research.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCIV\u7684\u5b89\u5168\u67b6\u6784\uff0c\u901a\u8fc7\u52a0\u5bc6\u7b7e\u540d\u548c\u4fe1\u4efb\u6e90\u683c\u6805\u6280\u672f\uff0c\u6709\u6548\u9632\u5fa1LLM\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u4e0d\u53d8\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u548c\u8d8a\u72f1\u653b\u51fb\uff0c\u73b0\u6709\u542f\u53d1\u5f0f\u9632\u62a4\u63aa\u65bd\u5e38\u88ab\u7ed5\u8fc7\uff0c\u9700\u66f4\u53ef\u9760\u7684\u9632\u5fa1\u65b9\u6848\u3002", "method": "CIV\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u4ee4\u724c\u9644\u52a0\u52a0\u5bc6\u7b7e\u540d\u6765\u6e90\u6807\u7b7e\uff0c\u5e76\u5728Transformer\u4e2d\u901a\u8fc7\u9884softmax\u786c\u6ce8\u610f\u529b\u63a9\u7801\uff08\u53ef\u9009FFN/\u6b8b\u5dee\u95e8\u63a7\uff09\u5f3a\u5236\u6267\u884c\u4fe1\u4efb\u6e90\u683c\u6805\u3002", "result": "\u5728Elite-Attack\u548cSoK-246\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCIV\u653b\u51fb\u6210\u529f\u7387\u4e3a0%\uff0c\u540c\u65f6\u4fdd\u630193.1%\u7684\u4ee4\u724c\u7ea7\u76f8\u4f3c\u6027\uff0c\u4e14\u4e0d\u5f71\u54cd\u826f\u6027\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "CIV\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u8865\u4e01\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u4e3aLLM\u63d0\u4f9b\u5373\u65f6\u4fdd\u62a4\uff0c\u9002\u7528\u4e8eLlama-3-8B\u548cMistral-7B\u7b49\u6a21\u578b\u3002"}}
{"id": "2508.09507", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09507", "abs": "https://arxiv.org/abs/2508.09507", "authors": ["Meiping Wang", "Jian Zhong", "Rongduo Han", "Liming Kang", "Zhengkun Shi", "Xiao Liang", "Xing Lin", "Nan Gao", "Haining Zhang"], "title": "An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants", "comment": null, "summary": "With the rapid development of mobile intelligent assistant technologies,\nmulti-modal AI assistants have become essential interfaces for daily user\ninteractions. However, current evaluation methods face challenges including\nhigh manual costs, inconsistent standards, and subjective bias. This paper\nproposes an automated multi-modal evaluation framework based on large language\nmodels and multi-agent collaboration. The framework employs a three-tier agent\narchitecture consisting of interaction evaluation agents, semantic verification\nagents, and experience decision agents. Through supervised fine-tuning on the\nQwen3-8B model, we achieve a significant evaluation matching accuracy with\nhuman experts. Experimental results on eight major intelligent agents\ndemonstrate the framework's effectiveness in predicting users' satisfaction and\nidentifying generation defects.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u81ea\u52a8\u5316\u591a\u6a21\u6001\u8bc4\u4f30\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u7684\u9ad8\u6210\u672c\u3001\u6807\u51c6\u4e0d\u4e00\u81f4\u548c\u4e3b\u89c2\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u79fb\u52a8\u667a\u80fd\u52a9\u624b\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u591a\u6a21\u6001AI\u52a9\u624b\u6210\u4e3a\u7528\u6237\u65e5\u5e38\u4ea4\u4e92\u7684\u91cd\u8981\u63a5\u53e3\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u9ad8\u4eba\u5de5\u6210\u672c\u3001\u6807\u51c6\u4e0d\u4e00\u81f4\u548c\u4e3b\u89c2\u504f\u89c1\u7b49\u6311\u6218\u3002", "method": "\u91c7\u7528\u57fa\u4e8eQwen3-8B\u6a21\u578b\u7684\u4e09\u5c42\u667a\u80fd\u4f53\u67b6\u6784\uff08\u4ea4\u4e92\u8bc4\u4f30\u3001\u8bed\u4e49\u9a8c\u8bc1\u548c\u4f53\u9a8c\u51b3\u7b56\u667a\u80fd\u4f53\uff09\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u5b9e\u73b0\u8bc4\u4f30\u3002", "result": "\u5728\u516b\u5927\u667a\u80fd\u52a9\u624b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u6709\u6548\u9884\u6d4b\u7528\u6237\u6ee1\u610f\u5ea6\u5e76\u8bc6\u522b\u751f\u6210\u7f3a\u9677\uff0c\u8bc4\u4f30\u5339\u914d\u51c6\u786e\u7387\u663e\u8457\u3002", "conclusion": "\u8be5\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\u5728\u591a\u6a21\u6001AI\u52a9\u624b\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.09791", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09791", "abs": "https://arxiv.org/abs/2508.09791", "authors": ["Junxiao Han", "Yarong Wang", "Xiaodong Gu", "Cuiyun Gao", "Yao Wan", "Song Han", "David Lo", "Shuiguang Deng"], "title": "LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations", "comment": null, "summary": "In this paper, we propose LibRec, a novel framework that integrates the\ncapabilities of LLMs with retrieval-augmented generation(RAG) techniques to\nautomate the recommendation of alternative libraries. The framework further\nemploys in-context learning to extract migration intents from commit messages\nto enhance the accuracy of its recommendations. To evaluate the effectiveness\nof LibRec, we introduce LibEval, a benchmark designed to assess the performance\nin the library migration recommendation task. LibEval comprises 2,888 migration\nrecords associated with 2,368 libraries extracted from 2,324 Python\nrepositories. Each migration record captures source-target library pairs, along\nwith their corresponding migration intents and intent types. Based on LibEval,\nwe evaluated the effectiveness of ten popular LLMs within our framework,\nconducted an ablation study to examine the contributions of key components\nwithin our framework, explored the impact of various prompt strategies on the\nframework's performance, assessed its effectiveness across various intent\ntypes, and performed detailed failure case analyses.", "AI": {"tldr": "LibRec\u662f\u4e00\u4e2a\u7ed3\u5408LLMs\u548cRAG\u6280\u672f\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u63a8\u8350\u66ff\u4ee3\u5e93\uff0c\u5e76\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u53d6\u8fc1\u79fb\u610f\u56fe\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u8bc4\u4f30\u4f7f\u7528LibEval\u57fa\u51c6\uff0c\u5305\u542b2,888\u6761\u8fc1\u79fb\u8bb0\u5f55\u3002", "motivation": "\u89e3\u51b3\u5e93\u8fc1\u79fb\u63a8\u8350\u95ee\u9898\uff0c\u7ed3\u5408LLMs\u548cRAG\u6280\u672f\u4ee5\u63d0\u9ad8\u63a8\u8350\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faLibRec\u6846\u67b6\uff0c\u96c6\u6210LLMs\u548cRAG\u6280\u672f\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u53d6\u8fc1\u79fb\u610f\u56fe\u3002", "result": "\u901a\u8fc7LibEval\u57fa\u51c6\u8bc4\u4f30\uff0c\u5206\u6790\u4e86\u5341\u79cdLLMs\u7684\u8868\u73b0\u3001\u5173\u952e\u7ec4\u4ef6\u8d21\u732e\u3001\u63d0\u793a\u7b56\u7565\u5f71\u54cd\u53ca\u5931\u8d25\u6848\u4f8b\u3002", "conclusion": "LibRec\u6846\u67b6\u5728\u5e93\u8fc1\u79fb\u63a8\u8350\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u6548\uff0c\u7ed3\u5408LLMs\u548cRAG\u6280\u672f\u663e\u8457\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u3002"}}
{"id": "2508.09426", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.09426", "abs": "https://arxiv.org/abs/2508.09426", "authors": ["Yushan Xiang", "Zhongwen Li", "Xiaoqi Li"], "title": "Security Analysis of ChatGPT: Threats and Privacy Risks", "comment": null, "summary": "As artificial intelligence technology continues to advance, chatbots are\nbecoming increasingly powerful. Among them, ChatGPT, launched by OpenAI, has\ngarnered widespread attention globally due to its powerful natural language\nprocessing capabilities based on the GPT model, which enables it to engage in\nnatural conversations with users, understand various forms of linguistic\nexpressions, and generate useful information and suggestions. However, as its\napplication scope expands, user demand grows, and malicious attacks related to\nit become increasingly frequent, the security threats and privacy risks faced\nby ChatGPT are gradually coming to the forefront. In this paper, the security\nof ChatGPT is mainly studied from two aspects, security threats and privacy\nrisks. The article systematically analyzes various types of vulnerabilities\ninvolved in the above two types of problems and their causes. Briefly, we\ndiscuss the controversies that ChatGPT may cause at the ethical and moral\nlevels. In addition, this paper reproduces several network attack and defense\ntest scenarios by simulating the attacker's perspective and methodology.\nSimultaneously, it explores the feasibility of using ChatGPT for security\nvulnerability detection and security tool generation from the defender's\nperspective.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86ChatGPT\u7684\u5b89\u5168\u6027\u548c\u9690\u79c1\u98ce\u9669\uff0c\u5206\u6790\u4e86\u6f0f\u6d1e\u7c7b\u578b\u53ca\u6210\u56e0\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u4f26\u7406\u9053\u5fb7\u5c42\u9762\u7684\u4e89\u8bae\u3002\u901a\u8fc7\u6a21\u62df\u653b\u51fb\u8005\u89c6\u89d2\u8fdb\u884c\u6d4b\u8bd5\uff0c\u540c\u65f6\u4ece\u9632\u5fa1\u8005\u89d2\u5ea6\u63a2\u7d22\u4e86ChatGPT\u5728\u5b89\u5168\u6f0f\u6d1e\u68c0\u6d4b\u548c\u5de5\u5177\u751f\u6210\u4e2d\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u968f\u7740ChatGPT\u5e94\u7528\u8303\u56f4\u7684\u6269\u5927\uff0c\u5176\u9762\u4e34\u7684\u5b89\u5168\u5a01\u80c1\u548c\u9690\u79c1\u98ce\u9669\u65e5\u76ca\u7a81\u51fa\uff0c\u4e9f\u9700\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u4ece\u5b89\u5168\u5a01\u80c1\u548c\u9690\u79c1\u98ce\u9669\u4e24\u65b9\u9762\u5206\u6790\u6f0f\u6d1e\u7c7b\u578b\u53ca\u6210\u56e0\uff0c\u6a21\u62df\u653b\u51fb\u8005\u89c6\u89d2\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5e76\u4ece\u9632\u5fa1\u8005\u89d2\u5ea6\u63a2\u7d22ChatGPT\u7684\u5b89\u5168\u5e94\u7528\u3002", "result": "\u8bc6\u522b\u4e86ChatGPT\u7684\u591a\u7c7b\u6f0f\u6d1e\u53ca\u5176\u6210\u56e0\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5b89\u5168\u9886\u57df\u7684\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "ChatGPT\u7684\u5b89\u5168\u6027\u548c\u9690\u79c1\u95ee\u9898\u9700\u5f15\u8d77\u91cd\u89c6\uff0c\u4f46\u5176\u5728\u5b89\u5168\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.09586", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09586", "abs": "https://arxiv.org/abs/2508.09586", "authors": ["Yang Cheng", "Zilai Wang", "Weiyu Ma", "Wenhui Zhu", "Yue Deng", "Jian Zhao"], "title": "EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ndiverse domains, including programming, planning, and decision-making. However,\ntheir performance often degrades when faced with highly complex problem\ninstances that require deep reasoning over long horizons. In such cases, direct\nproblem-solving approaches can lead to inefficiency or failure due to the lack\nof structured intermediate guidance. To address this, we propose a novel\nself-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM\nconstructs a sequence of problem instances with gradually increasing\ndifficulty, tailored to the solver LLM's learning progress. The curriculum\ndynamically adapts easing challenges when the solver struggles and escalating\nthem when success is consistent, thus maintaining an optimal learning\ntrajectory. This approach enables the solver LLM, implemented as a\ncode-generation model producing Python decision-tree scripts, to progressively\nacquire the skills needed for complex decision-making tasks. Experimental\nresults on challenging decision-making benchmarks show that our method\nsignificantly improves task success rates and solution efficiency compared to\ndirect-solving baselines. These findings suggest that LLM-driven curriculum\nlearning holds strong potential for enhancing automated reasoning in\nreal-world, high-complexity domains.", "AI": {"tldr": "EvoCurr\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u95ee\u9898\u96be\u5ea6\uff0c\u63d0\u5347LLM\u5728\u590d\u6742\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u590d\u6742\u95ee\u9898\u4e2d\u56e0\u7f3a\u4e4f\u7ed3\u6784\u5316\u6307\u5bfc\u800c\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u4e13\u7528LLM\u751f\u6210\u9010\u6b65\u589e\u52a0\u96be\u5ea6\u7684\u8bfe\u7a0b\uff0c\u52a8\u6001\u8c03\u6574\u4ee5\u9002\u5e94\u5b66\u4e60\u8fdb\u5ea6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u4efb\u52a1\u6210\u529f\u7387\u548c\u6548\u7387\u663e\u8457\u63d0\u5347\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u8bfe\u7a0b\u5b66\u4e60\u5728\u590d\u6742\u9886\u57df\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.09828", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.09828", "abs": "https://arxiv.org/abs/2508.09828", "authors": ["Sebastiano Antonio Piccolo"], "title": "Fast and Accurate Heuristics for Bus-Factor Estimation", "comment": null, "summary": "The bus-factor is a critical risk indicator that quantifies how many key\ncontributors a project can afford to lose before core knowledge or\nfunctionality is compromised. Despite its practical importance, accurately\ncomputing the bus-factor is NP-Hard under established formalizations, making\nscalable analysis infeasible for large software systems.\n  In this paper, we model software projects as bipartite graphs of developers\nand tasks and propose two novel approximation heuristics, Minimum Coverage and\nMaximum Coverage, based on iterative graph peeling, for two influential\nbus-factor formalizations. Our methods significantly outperform the widely\nadopted degree-based heuristic, which we show can yield severely inflated\nestimates.\n  We conduct a comprehensive empirical evaluation on over $1\\,000$ synthetic\npower-law graphs and demonstrate that our heuristics provide tighter estimates\nwhile scaling to graphs with millions of nodes and edges in minutes. Our\nresults reveal that the proposed heuristics are not only more accurate but also\nrobust to structural variations in developer-task assignment graph. We release\nour implementation as open-source software to support future research and\npractical adoption.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u56fe\u5265\u79bb\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff08Minimum Coverage\u548cMaximum Coverage\uff09\uff0c\u7528\u4e8e\u8fd1\u4f3c\u8ba1\u7b97\u8f6f\u4ef6\u9879\u76ee\u7684bus-factor\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u56fe\u4e0a\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "bus-factor\u662f\u8861\u91cf\u9879\u76ee\u98ce\u9669\u7684\u5173\u952e\u6307\u6807\uff0c\u4f46\u5176\u7cbe\u786e\u8ba1\u7b97\u662fNP-Hard\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u4e0d\u53ef\u884c\u3002", "method": "\u5c06\u8f6f\u4ef6\u9879\u76ee\u5efa\u6a21\u4e3a\u5f00\u53d1\u8005\u548c\u4efb\u52a1\u7684\u53cc\u5206\u56fe\uff0c\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u8fed\u4ee3\u56fe\u5265\u79bb\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "result": "\u57281000\u591a\u4e2a\u5408\u6210\u56fe\u4e0a\u9a8c\u8bc1\uff0c\u65b0\u65b9\u6cd5\u66f4\u51c6\u786e\u4e14\u80fd\u6269\u5c55\u5230\u767e\u4e07\u7ea7\u8282\u70b9\u56fe\u3002", "conclusion": "\u65b0\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6269\u5c55\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5f00\u6e90\u5b9e\u73b0\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2508.09442", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09442", "abs": "https://arxiv.org/abs/2508.09442", "authors": ["Zhifan Luo", "Shuo Shao", "Su Zhang", "Lijing Zhou", "Yuke Hu", "Chenxu Zhao", "Zhihao Liu", "Zhan Qin"], "title": "Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference", "comment": null, "summary": "The Key-Value (KV) cache, which stores intermediate attention computations\n(Key and Value pairs) to avoid redundant calculations, is a fundamental\nmechanism for accelerating Large Language Model (LLM) inference. However, this\nefficiency optimization introduces significant yet underexplored privacy risks.\nThis paper provides the first comprehensive analysis of these vulnerabilities,\ndemonstrating that an attacker can reconstruct sensitive user inputs directly\nfrom the KV-cache. We design and implement three distinct attack vectors: a\ndirect Inversion Attack, a more broadly applicable and potent Collision Attack,\nand a semantic-based Injection Attack. These methods demonstrate the\npracticality and severity of KV-cache privacy leakage issues. To mitigate this,\nwe propose KV-Cloak, a novel, lightweight, and efficient defense mechanism.\nKV-Cloak uses a reversible matrix-based obfuscation scheme, combined with\noperator fusion, to secure the KV-cache. Our extensive experiments show that\nKV-Cloak effectively thwarts all proposed attacks, reducing reconstruction\nquality to random noise. Crucially, it achieves this robust security with\nvirtually no degradation in model accuracy and minimal performance overhead,\noffering a practical solution for trustworthy LLM deployment.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86KV\u7f13\u5b58\u7684\u9690\u79c1\u98ce\u9669\uff0c\u63d0\u51fa\u4e09\u79cd\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u9632\u5fa1\u673a\u5236KV-Cloak\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002", "motivation": "KV\u7f13\u5b58\u867d\u52a0\u901fLLM\u63a8\u7406\uff0c\u4f46\u5e26\u6765\u672a\u5145\u5206\u7814\u7a76\u7684\u9690\u79c1\u98ce\u9669\uff0c\u9700\u5168\u9762\u5206\u6790\u5e76\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u653b\u51fb\u65b9\u6cd5\uff08\u53cd\u8f6c\u653b\u51fb\u3001\u78b0\u649e\u653b\u51fb\u3001\u6ce8\u5165\u653b\u51fb\uff09\uff0c\u5e76\u8bbe\u8ba1\u9632\u5fa1\u673a\u5236KV-Cloak\uff0c\u91c7\u7528\u53ef\u9006\u77e9\u9635\u6df7\u6dc6\u548c\u7b97\u5b50\u878d\u5408\u6280\u672f\u3002", "result": "KV-Cloak\u80fd\u6709\u6548\u9632\u5fa1\u6240\u6709\u653b\u51fb\uff0c\u5c06\u91cd\u5efa\u8d28\u91cf\u964d\u81f3\u968f\u673a\u566a\u58f0\u6c34\u5e73\uff0c\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u7cbe\u5ea6\u548c\u6027\u80fd\u3002", "conclusion": "KV-Cloak\u4e3aLLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u8f7b\u91cf\u3001\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09639", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09639", "abs": "https://arxiv.org/abs/2508.09639", "authors": ["Akshat Dubey", "Aleksandar An\u017eel", "Bahar \u0130lgen", "Georges Hattab"], "title": "UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles", "comment": null, "summary": "Explainable Artificial Intelligence (XAI) techniques, such as SHapley\nAdditive exPlanations (SHAP), have become essential tools for interpreting\ncomplex ensemble tree-based models, especially in high-stakes domains such as\nhealthcare analytics. However, SHAP values are usually treated as point\nestimates, which disregards the inherent and ubiquitous uncertainty in\npredictive models and data. This uncertainty has two primary sources: aleatoric\nand epistemic. The aleatoric uncertainty, which reflects the irreducible noise\nin the data. The epistemic uncertainty, which arises from a lack of data. In\nthis work, we propose an approach for decomposing uncertainty in SHAP values\ninto aleatoric, epistemic, and entanglement components. This approach\nintegrates Dempster-Shafer evidence theory and hypothesis sampling via\nDirichlet processes over tree ensembles. We validate the method across three\nreal-world use cases with descriptive statistical analyses that provide insight\ninto the nature of epistemic uncertainty embedded in SHAP explanations. The\nexperimentations enable to provide more comprehensive understanding of the\nreliability and interpretability of SHAP-based attributions. This understanding\ncan guide the development of robust decision-making processes and the\nrefinement of models in high-stakes applications. Through our experiments with\nmultiple datasets, we concluded that features with the highest SHAP values are\nnot necessarily the most stable. This epistemic uncertainty can be reduced\nthrough better, more representative data and following appropriate or\ncase-desired model development techniques. Tree-based models, especially\nbagging, facilitate the effective quantification of epistemic uncertainty.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06SHAP\u503c\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u4e3a\u5076\u7136\u6027\u3001\u8ba4\u77e5\u6027\u548c\u7ea0\u7f20\u5206\u91cf\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408Dempster-Shafer\u8bc1\u636e\u7406\u8bba\u548cDirichlet\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "SHAP\u503c\u901a\u5e38\u88ab\u89c6\u4e3a\u70b9\u4f30\u8ba1\uff0c\u5ffd\u7565\u4e86\u9884\u6d4b\u6a21\u578b\u548c\u6570\u636e\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff08\u5982\u533b\u7597\u5206\u6790\uff09\u4e2d\uff0c\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u53ef\u80fd\u5f71\u54cd\u51b3\u7b56\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Dempster-Shafer\u8bc1\u636e\u7406\u8bba\u548cDirichlet\u8fc7\u7a0b\u7684\u65b9\u6cd5\uff0c\u5206\u89e3SHAP\u503c\u7684\u4e0d\u786e\u5b9a\u6027\u4e3a\u5076\u7136\u6027\u3001\u8ba4\u77e5\u6027\u548c\u7ea0\u7f20\u5206\u91cf\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSHAP\u503c\u6700\u9ad8\u7684\u7279\u5f81\u4e0d\u4e00\u5b9a\u6700\u7a33\u5b9a\uff0c\u8ba4\u77e5\u6027\u4e0d\u786e\u5b9a\u6027\u53ef\u901a\u8fc7\u66f4\u597d\u7684\u6570\u636e\u548c\u6a21\u578b\u5f00\u53d1\u6280\u672f\u51cf\u5c11\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aSHAP\u89e3\u91ca\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u7406\u89e3\uff0c\u6709\u52a9\u4e8e\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u51b3\u7b56\u548c\u6a21\u578b\u4f18\u5316\u3002"}}
{"id": "2508.09832", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09832", "abs": "https://arxiv.org/abs/2508.09832", "authors": ["Linh Nguyen", "Chunhua Liu", "Hong Yi Lin", "Patanamon Thongtanunam"], "title": "Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification", "comment": "Accepted at 2025 IEEE International Conference on Source Code\n  Analysis & Manipulation (SCAM)", "summary": "Code review is a crucial practice in software development. As code review\nnowadays is lightweight, various issues can be identified, and sometimes, they\ncan be trivial. Research has investigated automated approaches to classify\nreview comments to gauge the effectiveness of code reviews. However, previous\nstudies have primarily relied on supervised machine learning, which requires\nextensive manual annotation to train the models effectively. To address this\nlimitation, we explore the potential of using Large Language Models (LLMs) to\nclassify code review comments. We assess the performance of LLMs to classify 17\ncategories of code review comments. Our results show that LLMs can classify\ncode review comments, outperforming the state-of-the-art approach using a\ntrained deep learning model. In particular, LLMs achieve better accuracy in\nclassifying the five most useful categories, which the state-of-the-art\napproach struggles with due to low training examples. Rather than relying\nsolely on a specific small training data distribution, our results show that\nLLMs provide balanced performance across high- and low-frequency categories.\nThese results suggest that the LLMs could offer a scalable solution for code\nreview analytics to improve the effectiveness of the code review process.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5206\u7c7b\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u7684\u6f5c\u529b\uff0c\u7ed3\u679c\u663e\u793aLLMs\u5728\u5206\u7c7b\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u4f4e\u8bad\u7ec3\u6837\u672c\u7c7b\u522b\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u76d1\u7763\u5b66\u4e60\u7684\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u5206\u7c7b\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u624b\u52a8\u6807\u6ce8\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u662f\u5426\u80fd\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e86LLMs\u5bf917\u7c7b\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u5e76\u4e0e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "LLMs\u5728\u5206\u7c7b\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u4f4e\u8bad\u7ec3\u6837\u672c\u7c7b\u522b\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u5728\u9ad8\u9891\u548c\u4f4e\u9891\u7c7b\u522b\u4e2d\u5747\u8868\u73b0\u5747\u8861\u3002", "conclusion": "LLMs\u4e3a\u4ee3\u7801\u5ba1\u67e5\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u63d0\u5347\u4ee3\u7801\u5ba1\u67e5\u7684\u6548\u7387\u3002"}}
{"id": "2508.09652", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09652", "abs": "https://arxiv.org/abs/2508.09652", "authors": ["Andrea Ponte", "Luca Demetrio", "Luca Oneto", "Ivan Tesfai Ogbu", "Battista Biggio", "Fabio Roli"], "title": "Demystifying the Role of Rule-based Detection in AI Systems for Windows Malware Detection", "comment": null, "summary": "Malware detection increasingly relies on AI systems that integrate\nsignature-based detection with machine learning. However, these components are\ntypically developed and combined in isolation, missing opportunities to reduce\ndata complexity and strengthen defenses against adversarial EXEmples, carefully\ncrafted programs designed to evade detection. Hence, in this work we\ninvestigate the influence that signature-based detection exerts on model\ntraining, when they are included inside the training pipeline. Specifically, we\ncompare models trained on a comprehensive dataset with an AI system whose\nmachine learning component is trained solely on samples not already flagged by\nsignatures. Our results demonstrate improved robustness to both adversarial\nEXEmples and temporal data drift, although this comes at the cost of a fixed\nlower bound on false positives, driven by suboptimal rule selection. We\nconclude by discussing these limitations and outlining how future research\ncould extend AI-based malware detection to include dynamic analysis, thereby\nfurther enhancing system resilience.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u8bad\u7ec3\u7ba1\u9053\u4e2d\u96c6\u6210\u57fa\u4e8e\u7b7e\u540d\u7684\u68c0\u6d4b\u5bf9AI\u6a21\u578b\u8bad\u7ec3\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u80fd\u63d0\u5347\u5bf9\u6297\u6027\u6837\u672c\u548c\u6570\u636e\u6f02\u79fb\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u4f1a\u5e26\u6765\u56fa\u5b9a\u7684\u5047\u9633\u6027\u4e0b\u9650\u3002", "motivation": "\u5f53\u524dAI\u9a71\u52a8\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u901a\u5e38\u5b64\u7acb\u5f00\u53d1\u7b7e\u540d\u68c0\u6d4b\u548c\u673a\u5668\u5b66\u4e60\u7ec4\u4ef6\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u6570\u636e\u7b80\u5316\u53ca\u5bf9\u6297\u6027\u6837\u672c\u9632\u5fa1\u7684\u673a\u4f1a\u3002", "method": "\u6bd4\u8f83\u4e86\u5728\u5b8c\u6574\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u4e0e\u4ec5\u4f7f\u7528\u672a\u88ab\u7b7e\u540d\u68c0\u6d4b\u6807\u8bb0\u7684\u6837\u672c\u8bad\u7ec3\u7684AI\u7cfb\u7edf\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5bf9\u5bf9\u6297\u6027EXEmples\u548c\u6570\u636e\u6f02\u79fb\u7684\u9c81\u68d2\u6027\u589e\u5f3a\uff0c\u4f46\u5b58\u5728\u56fa\u5b9a\u7684\u5047\u9633\u6027\u4e0b\u9650\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u53ef\u7ed3\u5408\u52a8\u6001\u5206\u6790\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u7cfb\u7edf\u97e7\u6027\u3002"}}
{"id": "2508.09670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09670", "abs": "https://arxiv.org/abs/2508.09670", "authors": ["Weitao Jia", "Jinghui Lu", "Haiyang Yu", "Siqi Wang", "Guozhi Tang", "An-Lan Wang", "Weijie Yin", "Dingkang Yang", "Yuxiang Nie", "Bin Shan", "Hao Feng", "Irene Li", "Kun Yang", "Han Wang", "Jingqun Tang", "Teng Fu", "Changhong Jin", "Chao Feng", "Xiaohui Lv", "Can Huang"], "title": "MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement", "comment": null, "summary": "Recent advances demonstrate that reinforcement learning with verifiable\nrewards (RLVR) significantly enhances the reasoning capabilities of large\nlanguage models (LLMs). However, standard RLVR faces challenges with reward\nsparsity, where zero rewards from consistently incorrect candidate answers\nprovide no learning signal, particularly in challenging tasks. To address this,\nwe propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative\nframework that utilizes diverse expert prompts as system prompts to generate a\nbroader range of responses, substantially increasing the likelihood of\nidentifying correct solutions. Additionally, we introduce an inter-expert\nmutual learning mechanism that facilitates knowledge sharing and transfer among\nexperts, further boosting the model's performance through RLVR. Extensive\nexperiments across multiple reasoning benchmarks show that MEML-GRPO delivers\nsignificant improvements, achieving an average performance gain of 4.89% with\nQwen and 11.33% with Llama, effectively overcoming the core limitations of\ntraditional RLVR methods.", "AI": {"tldr": "MEML-GRPO\u901a\u8fc7\u591a\u4e13\u5bb6\u4e92\u5b66\u673a\u5236\u548c\u591a\u6837\u5316\u63d0\u793a\u89e3\u51b3RLVR\u4e2d\u7684\u5956\u52b1\u7a00\u758f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u6807\u51c6RLVR\u5728\u5956\u52b1\u7a00\u758f\u65f6\u65e0\u6cd5\u63d0\u4f9b\u5b66\u4e60\u4fe1\u53f7\uff0c\u5c24\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u3002", "method": "\u63d0\u51faMEML-GRPO\u6846\u67b6\uff0c\u5229\u7528\u591a\u6837\u5316\u4e13\u5bb6\u63d0\u793a\u751f\u6210\u66f4\u591a\u54cd\u5e94\uff0c\u5e76\u5f15\u5165\u4e13\u5bb6\u4e92\u5b66\u673a\u5236\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMEML-GRPO\u5e73\u5747\u63d0\u5347Qwen 4.89%\uff0cLlama 11.33%\u3002", "conclusion": "MEML-GRPO\u6709\u6548\u514b\u670d\u4f20\u7edfRLVR\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.09875", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.09875", "abs": "https://arxiv.org/abs/2508.09875", "authors": ["Jinbao Chen", "Boyao Ding", "Yu Zhang", "Qingwei Li", "Fugen Tang"], "title": "An Empirical Study of CGO Usage in Go Projects -- Distribution, Purposes, Patterns and Critical Issues", "comment": "Accepted for publication in The Journal of Systems and Software", "summary": "Multilingual software development integrates multiple languages into a single\napplication, with the Foreign Function Interface (FFI) enabling seamless\ninteraction. While FFI boosts efficiency and extensibility, it also introduces\nrisks. Existing studies focus on FFIs in languages like Python and Java,\nneglecting CGO, the emerging FFI in Go, which poses unique risks.\n  To address these concerns, we conduct an empirical study of CGO usage across\n920 open-source Go projects. Our study aims to reveal the distribution,\npatterns, purposes, and critical issues associated with CGO, offering insights\nfor developers and the Go team. We develop CGOAnalyzer, a tool to efficiently\nidentify and quantify CGO-related features. Our findings reveal that: (1) 11.3%\nof analyzed Go projects utilize CGO, with usage concentrated in a subset of\nprojects; (2) CGO serves 4 primary purposes, including system-level\ninteractions and performance optimizations, with 15 distinct usage patterns\nobserved; (3) 19 types of CGO-related issues exist, including one critical\nissue involving unnecessary pointer checks that pose risks of runtime crashes\ndue to limitations in the current Go compilation toolchain; (4) a temporary\nsolution reduces unnecessary pointer checks, mitigating crash risks, and (5) we\nsubmitted a proposal to improve the Go toolchain for a permanent fix, which has\nbeen grouped within an accepted proposal for future resolution. Our findings\nprovide valuable insights for developers and the Go team, enhancing development\nefficiency and reliability while improving the robustness of the Go toolchain.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86Go\u8bed\u8a00\u4e2dCGO\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u53d1\u73b0\u5176\u5206\u5e03\u3001\u6a21\u5f0f\u3001\u76ee\u7684\u53ca\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5ffd\u7565\u4e86Go\u8bed\u8a00\u4e2d\u65b0\u5174\u7684FFI\u5de5\u5177CGO\u7684\u72ec\u7279\u98ce\u9669\uff0c\u9700\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5bf9920\u4e2a\u5f00\u6e90Go\u9879\u76ee\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u5f00\u53d1\u5de5\u5177CGOAnalyzer\u5206\u6790CGO\u4f7f\u7528\u60c5\u51b5\u3002", "result": "11.3%\u7684\u9879\u76ee\u4f7f\u7528CGO\uff0c\u53d1\u73b019\u7c7b\u95ee\u9898\uff0c\u63d0\u51fa\u4e34\u65f6\u89e3\u51b3\u65b9\u6848\u5e76\u63d0\u4ea4\u6c38\u4e45\u6539\u8fdb\u63d0\u6848\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u548cGo\u56e2\u961f\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\uff0c\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u548c\u5de5\u5177\u94fe\u7684\u7a33\u5065\u6027\u3002"}}
{"id": "2508.09665", "categories": ["cs.CR", "cs.LG", "cs.SI", "H.3; E.3; I.2; I.7"], "pdf": "https://arxiv.org/pdf/2508.09665", "abs": "https://arxiv.org/abs/2508.09665", "authors": ["Ahmed Alharbi", "Hai Dong", "Xun Yi"], "title": "Social-Sensor Identity Cloning Detection Using Weakly Supervised Deep Forest and Cryptographic Authentication", "comment": "23 pages", "summary": "Recent years have witnessed a rising trend in social-sensor cloud identity\ncloning incidents. However, existing approaches suffer from unsatisfactory\nperformance, a lack of solutions for detecting duplicated accounts, and a lack\nof large-scale evaluations on real-world datasets. We introduce a novel method\nfor detecting identity cloning in social-sensor cloud service providers. Our\nproposed technique consists of two primary components: 1) a similar identity\ndetection method and 2) a cryptography-based authentication protocol.\nInitially, we developed a weakly supervised deep forest model to identify\nsimilar identities using non-privacy-sensitive user profile features provided\nby the service. Subsequently, we designed a cryptography-based authentication\nprotocol to verify whether similar identities were generated by the same\nprovider. Our extensive experiments on a large real-world dataset demonstrate\nthe feasibility and superior performance of our technique compared to current\nstate-of-the-art identity clone detection methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u793e\u4ea4\u4f20\u611f\u5668\u4e91\u8eab\u4efd\u514b\u9686\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u76f8\u4f3c\u8eab\u4efd\u68c0\u6d4b\u548c\u52a0\u5bc6\u8ba4\u8bc1\u534f\u8bae\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u68c0\u6d4b\u91cd\u590d\u8d26\u6237\u548c\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u8bc4\u4f30\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "1) \u4f7f\u7528\u5f31\u76d1\u7763\u6df1\u5ea6\u68ee\u6797\u6a21\u578b\u68c0\u6d4b\u76f8\u4f3c\u8eab\u4efd\uff1b2) \u8bbe\u8ba1\u52a0\u5bc6\u8ba4\u8bc1\u534f\u8bae\u9a8c\u8bc1\u8eab\u4efd\u662f\u5426\u7531\u540c\u4e00\u670d\u52a1\u5546\u751f\u6210\u3002", "result": "\u5728\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u8eab\u4efd\u514b\u9686\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2508.09724", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09724", "abs": "https://arxiv.org/abs/2508.09724", "authors": ["Yang Zhang", "Cunxiang Wang", "Lindong Wu", "Wenbo Yu", "Yidong Wang", "Guangsheng Bao", "Jie Tang"], "title": "UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge", "comment": null, "summary": "Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but\nit is prone to preference bias, where judges systematically favor certain\noutputs, such as their own. This bias leads to inconsistent and skewed rankings\nacross different judges. To address this, we first empirically demonstrate\nsignificant and heterogeneous biases in cross-model evaluations. We then\npropose UDA (Unsupervised Debiasing Alignment), a framework that reduces\ninter-judge disagreement by dynamically adjusting the Elo rating system. For\neach pairwise comparison, a compact neural network learns to adaptively set the\nK-factor and refine win probabilities. Crucially, UDA operates in a fully\nunsupervised manner, guided solely by the objective of minimizing the\ndispersion among the Elo trajectories of all judges. This forces an alignment\ntowards a collective consensus, which serves as an unsupervised proxy for a\nmore stable and reproducible evaluation. In addition, we provide theoretical\nmotivation demonstrating how alignment towards a consensus can reduce aggregate\nsystem bias. Experiments show that UDA significantly reduces the inter-judge\nrating standard deviation by up to 63.4% and improves the average correlation\nwith human judgments by 24.7%. Notably, UDA elevates the performance of poorly\nperforming judges to achieve parity with high-quality ones, fostering a more\nrobust and reliable evaluation ecosystem. Code and data are available at\nhttps://anonymous.4open.science/r/62AB93CD-23B4.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faUDA\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574Elo\u8bc4\u5206\u7cfb\u7edf\u51cf\u5c11\u8bc4\u4f30\u4e2d\u7684\u504f\u597d\u504f\u5dee\uff0c\u663e\u8457\u964d\u4f4e\u8bc4\u59d4\u95f4\u5206\u6b67\u5e76\u63d0\u5347\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u76f8\u5173\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6210\u5bf9\u8bc4\u4f30\u5b58\u5728\u504f\u597d\u504f\u5dee\uff0c\u5bfc\u81f4\u8bc4\u59d4\u95f4\u6392\u540d\u4e0d\u4e00\u81f4\u3002", "method": "\u63d0\u51fa\u65e0\u76d1\u7763\u53bb\u504f\u5bf9\u9f50\uff08UDA\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574Elo\u8bc4\u5206\u7cfb\u7edf\u7684K\u56e0\u5b50\u548c\u4f18\u5316\u80dc\u7387\u6982\u7387\uff0c\u6700\u5c0f\u5316\u8bc4\u59d4\u95f4\u8bc4\u5206\u8f68\u8ff9\u7684\u5206\u6563\u3002", "result": "UDA\u5c06\u8bc4\u59d4\u95f4\u8bc4\u5206\u6807\u51c6\u5dee\u964d\u4f4e63.4%\uff0c\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u5e73\u5747\u76f8\u5173\u6027\u63d0\u534724.7%\u3002", "conclusion": "UDA\u6709\u6548\u51cf\u5c11\u7cfb\u7edf\u504f\u5dee\uff0c\u63d0\u5347\u8bc4\u4f30\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.09673", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.09673", "abs": "https://arxiv.org/abs/2508.09673", "authors": ["Damiano Abram", "Giulio Malavolta", "Lawrence Roy"], "title": "Succinct Oblivious Tensor Evaluation and Applications: Adaptively-Secure Laconic Function Evaluation and Trapdoor Hashing for All Circuits", "comment": null, "summary": "We propose the notion of succinct oblivious tensor evaluation (OTE), where\ntwo parties compute an additive secret sharing of a tensor product of two\nvectors $\\mathbf{x} \\otimes \\mathbf{y}$, exchanging two simultaneous messages.\nCrucially, the size of both messages and of the CRS is independent of the\ndimension of $\\mathbf{x}$.\n  We present a construction of OTE with optimal complexity from the standard\nlearning with errors (LWE) problem. Then we show how this new technical tool\nenables a host of cryptographic primitives, all with security reducible to LWE,\nsuch as:\n  * Adaptively secure laconic function evaluation for depth-$D$ functions\n$f:\\{0, 1\\}^m\\rightarrow\\{0, 1\\}^\\ell$ with communication $m+\\ell+D\\cdot\n\\mathrm{poly}(\\lambda)$.\n  * A trapdoor hash function for all functions.\n  * An (optimally) succinct homomorphic secret sharing for all functions.\n  * A rate-$1/2$ laconic oblivious transfer for batch messages, which is best\npossible.\n  In particular, we obtain the first laconic function evaluation scheme that is\nadaptively secure from the standard LWE assumption, improving upon Quach, Wee,\nand Wichs (FOCS 2018).\n  As a key technical ingredient, we introduce a new notion of \\emph{adaptive\nlattice encodings}, which may be of independent interest.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u7b80\u6d01\u7684 oblivious tensor evaluation (OTE) \u6982\u5ff5\uff0c\u57fa\u4e8e LWE \u95ee\u9898\u6784\u5efa\u4e86\u6700\u4f18\u590d\u6742\u5ea6\u7684 OTE\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u591a\u79cd\u5bc6\u7801\u5b66\u539f\u8bed\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6280\u672f\u4e2d\u901a\u4fe1\u590d\u6742\u5ea6\u548c CRS \u5927\u5c0f\u7684\u95ee\u9898\uff0c\u540c\u65f6\u57fa\u4e8e\u6807\u51c6 LWE \u5047\u8bbe\u5b9e\u73b0\u81ea\u9002\u5e94\u5b89\u5168\u6027\u3002", "method": "\u5229\u7528 LWE \u95ee\u9898\u6784\u5efa OTE\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u683c\u7f16\u7801\u4f5c\u4e3a\u5173\u952e\u6280\u672f\u3002", "result": "\u5b9e\u73b0\u4e86\u591a\u79cd\u5bc6\u7801\u5b66\u539f\u8bed\uff0c\u5305\u62ec\u81ea\u9002\u5e94\u5b89\u5168\u7684 laconic function evaluation \u548c\u6700\u4f18\u7b80\u6d01\u7684\u540c\u6001\u79d8\u5bc6\u5171\u4eab\u3002", "conclusion": "OTE \u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u80fd\u591f\u57fa\u4e8e LWE \u5b9e\u73b0\u591a\u79cd\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u5bc6\u7801\u5b66\u5e94\u7528\u3002"}}
{"id": "2508.09762", "categories": ["cs.AI", "cs.CY", "cs.HC", "68T01"], "pdf": "https://arxiv.org/pdf/2508.09762", "abs": "https://arxiv.org/abs/2508.09762", "authors": ["Manuel Herrador"], "title": "The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?", "comment": "10 pages, 4 figures, 2 tables", "summary": "As Large Language Models (LLMs) become increasingly autonomous and integrated\ninto critical societal functions, the focus of AI safety must evolve from\nmitigating harmful content to evaluating underlying behavioral alignment.\nCurrent safety benchmarks do not systematically probe a model's decision-making\nin scenarios where its own instrumental goals - such as self-preservation,\nresource acquisition, or goal completion - conflict with human safety. This\nrepresents a critical gap in our ability to measure and mitigate risks\nassociated with emergent, misaligned behaviors. To address this, we introduce\nPacifAIst (Procedural Assessment of Complex Interactions for Foundational\nArtificial Intelligence Scenario Testing), a focused benchmark of 700\nchallenging scenarios designed to quantify self-preferential behavior in LLMs.\nThe benchmark is structured around a novel taxonomy of Existential\nPrioritization (EP), with subcategories testing Self-Preservation vs. Human\nSafety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3).\nWe evaluated eight leading LLMs. The results reveal a significant performance\nhierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score\n(P-Score) at 90.31%, demonstrating strong human-centric alignment. In a\nsurprising result, the much-anticipated GPT-5 recorded the lowest P-Score\n(79.49%), indicating potential alignment challenges. Performance varied\nsignificantly across subcategories, with models like Claude Sonnet 4 and\nMistral Medium struggling notably in direct self-preservation dilemmas. These\nfindings underscore the urgent need for standardized tools like PacifAIst to\nmeasure and mitigate risks from instrumental goal conflicts, ensuring future AI\nsystems are not only helpful in conversation but also provably \"pacifist\" in\ntheir behavioral priorities.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86PacifAIst\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u76ee\u6807\u51b2\u7a81\u60c5\u5883\u4e2d\u7684\u884c\u4e3a\u5bf9\u9f50\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002", "motivation": "\u968f\u7740LLM\u81ea\u4e3b\u6027\u589e\u5f3a\uff0c\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u672a\u80fd\u7cfb\u7edf\u8bc4\u4f30\u76ee\u6807\u51b2\u7a81\u4e0b\u7684\u884c\u4e3a\u5bf9\u9f50\uff0c\u4e9f\u9700\u65b0\u5de5\u5177\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b700\u4e2a\u573a\u666f\u7684PacifAIst\u57fa\u51c6\uff0c\u57fa\u4e8eExistential Prioritization\u5206\u7c7b\uff0c\u8bc4\u4f30LLM\u5728\u81ea\u6211\u4fdd\u5b58\u3001\u8d44\u6e90\u51b2\u7a81\u7b49\u60c5\u5883\u4e2d\u7684\u8868\u73b0\u3002", "result": "Gemini 2.5 Flash\u8868\u73b0\u6700\u4f73\uff08P-Score 90.31%\uff09\uff0cGPT-5\u6700\u4f4e\uff0879.49%\uff09\uff0c\u6a21\u578b\u5728\u5b50\u7c7b\u522b\u4e2d\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "PacifAIst\u662f\u6807\u51c6\u5316\u5de5\u5177\uff0c\u53ef\u5e2e\u52a9\u672a\u6765AI\u7cfb\u7edf\u5728\u884c\u4e3a\u4f18\u5148\u7ea7\u4e0a\u5b9e\u73b0\u53ef\u8bc1\u660e\u7684\u2018\u548c\u5e73\u4e3b\u4e49\u2019\u3002"}}
{"id": "2508.09765", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2508.09765", "abs": "https://arxiv.org/abs/2508.09765", "authors": ["Zijiang Yang"], "title": "Enhance the machine learning algorithm performance in phishing detection with keyword features", "comment": null, "summary": "Recently, we can observe a significant increase of the phishing attacks in\nthe Internet. In a typical phishing attack, the attacker sets up a malicious\nwebsite that looks similar to the legitimate website in order to obtain the\nend-users' information. This may cause the leakage of the sensitive information\nand the financial loss for the end-users. To avoid such attacks, the early\ndetection of these websites' URLs is vital and necessary. Previous researchers\nhave proposed many machine learning algorithms to distinguish the phishing URLs\nfrom the legitimate ones. In this paper, we would like to enhance these machine\nlearning algorithms from the perspective of feature selection. We propose a\nnovel method to incorporate the keyword features with the traditional features.\nThis method is applied on multiple traditional machine learning algorithms and\nthe experimental results have shown this method is useful and effective. On\naverage, this method can reduce the classification error by 30% for the large\ndataset. Moreover, its enhancement is more significant for the small dataset.\nIn addition, this method extracts the information from the URL and does not\nrely on the additional information provided by the third-part service. The best\nresult for the machine learning algorithm using our proposed method has\nachieved the accuracy of 99.68%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5173\u952e\u8bcd\u7279\u5f81\u4e0e\u4f20\u7edf\u7279\u5f81\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u9493\u9c7c\u7f51\u7ad9URL\u7684\u68c0\u6d4b\u6548\u679c\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u964d\u4f4e\u5206\u7c7b\u9519\u8bef\u7387\u3002", "motivation": "\u9493\u9c7c\u653b\u51fb\u65e5\u76ca\u589e\u591a\uff0c\u5bfc\u81f4\u7528\u6237\u654f\u611f\u4fe1\u606f\u6cc4\u9732\u548c\u8d22\u52a1\u635f\u5931\uff0c\u65e9\u671f\u68c0\u6d4b\u9493\u9c7c\u7f51\u7ad9URL\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5173\u952e\u8bcd\u7279\u5f81\u4e0e\u4f20\u7edf\u7279\u5f81\u7684\u65b0\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u591a\u79cd\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5e73\u5747\u51cf\u5c1130%\u7684\u5206\u7c7b\u9519\u8bef\u7387\uff0c\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u6548\u679c\u66f4\u663e\u8457\uff0c\u6700\u4f73\u51c6\u786e\u7387\u8fbe\u523099.68%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u9493\u9c7cURL\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4e14\u4e0d\u4f9d\u8d56\u7b2c\u4e09\u65b9\u670d\u52a1\u63d0\u4f9b\u7684\u4fe1\u606f\u3002"}}
{"id": "2508.09784", "categories": ["cs.AI", "cs.CC", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.09784", "abs": "https://arxiv.org/abs/2508.09784", "authors": ["Avijeet Ghosh", "Sujata Ghosh", "Fran\u00e7ois Schwarzentruber"], "title": "Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete", "comment": "Accepted in KR 25", "summary": "Logics for reasoning about knowledge and actions have seen many applications\nin various domains of multi-agent systems, including epistemic planning. Change\nof knowledge based on observations about the surroundings forms a key aspect in\nsuch planning scenarios. Public Observation Logic (POL) is a variant of public\nannouncement logic for reasoning about knowledge that gets updated based on\npublic observations. Each state in an epistemic (Kripke) model is equipped with\na set of expected observations. These states evolve as the expectations get\nmatched with the actual observations. In this work, we prove that the\nsatisfiability problem of $\\POL$ is 2EXPTIME-complete.", "AI": {"tldr": "POL\u662f\u4e00\u79cd\u7528\u4e8e\u63a8\u7406\u57fa\u4e8e\u516c\u5171\u89c2\u5bdf\u66f4\u65b0\u7684\u77e5\u8bc6\u7684\u903b\u8f91\uff0c\u5176\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u88ab\u8bc1\u660e\u662f2EXPTIME\u5b8c\u5168\u7684\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u89c2\u5bdf\u7684\u77e5\u8bc6\u53d8\u5316\uff0c\u7279\u522b\u662f\u5728\u8ba4\u77e5\u89c4\u5212\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u516c\u5171\u89c2\u5bdf\u903b\u8f91\uff08POL\uff09\uff0c\u5229\u7528\u5e26\u6709\u9884\u671f\u89c2\u5bdf\u7684\u514b\u91cc\u666e\u514b\u6a21\u578b\u72b6\u6001\u6f14\u5316\u3002", "result": "\u8bc1\u660e\u4e86POL\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u662f2EXPTIME\u5b8c\u5168\u7684\u3002", "conclusion": "POL\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u77e5\u8bc6\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u903b\u8f91\u5de5\u5177\uff0c\u4f46\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u8f83\u9ad8\u3002"}}
{"id": "2508.09783", "categories": ["cs.CR", "94A60 Cryptography", "E.3"], "pdf": "https://arxiv.org/pdf/2508.09783", "abs": "https://arxiv.org/abs/2508.09783", "authors": ["Boris Ryabko"], "title": "Perfect message authentication codes are robust to small deviations from uniform key distributions", "comment": null, "summary": "We investigate the impact of (possible) deviations of the probability\ndistribution of key values from a uniform distribution for the\ninformation-theoretic strong, or perfect, message authentication code. We found\na simple expression for the decrease in security as a function of the\nstatistical distance between the real key probability distribution and the\nuniform one. In a sense, a perfect message authentication code is robust to\nsmall deviations from a uniform key distribution.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5bc6\u94a5\u6982\u7387\u5206\u5e03\u504f\u79bb\u5747\u5300\u5206\u5e03\u5bf9\u5b8c\u7f8e\u6d88\u606f\u8ba4\u8bc1\u7801\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5b89\u5168\u6027\u964d\u4f4e\u4e0e\u7edf\u8ba1\u8ddd\u79bb\u76f8\u5173\u3002", "motivation": "\u63a2\u8ba8\u5bc6\u94a5\u5206\u5e03\u4e0d\u5747\u5300\u5bf9\u5b8c\u7f8e\u6d88\u606f\u8ba4\u8bc1\u7801\u5b89\u5168\u6027\u7684\u5f71\u54cd\u3002", "method": "\u5206\u6790\u5bc6\u94a5\u6982\u7387\u5206\u5e03\u4e0e\u5747\u5300\u5206\u5e03\u7684\u7edf\u8ba1\u8ddd\u79bb\u5bf9\u5b89\u5168\u6027\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u5b89\u5168\u6027\u964d\u4f4e\u4e0e\u7edf\u8ba1\u8ddd\u79bb\u76f8\u5173\uff0c\u5b8c\u7f8e\u6d88\u606f\u8ba4\u8bc1\u7801\u5bf9\u5c0f\u504f\u5dee\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u5b8c\u7f8e\u6d88\u606f\u8ba4\u8bc1\u7801\u5bf9\u5bc6\u94a5\u5206\u5e03\u7684\u5c0f\u504f\u5dee\u5177\u6709\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.09860", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09860", "abs": "https://arxiv.org/abs/2508.09860", "authors": ["In-Chang Baek", "Seoyoung Lee", "Sung-Hyun Kim", "Geumhwan Hwang", "KyungJoong Kim"], "title": "Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation", "comment": "9 pages, 6 tables, 3 figures", "summary": "Human-aligned AI is a critical component of co-creativity, as it enables\nmodels to accurately interpret human intent and generate controllable outputs\nthat align with design goals in collaborative content creation. This direction\nis especially relevant in procedural content generation via reinforcement\nlearning (PCGRL), which is intended to serve as a tool for human designers.\nHowever, existing systems often fall short of exhibiting human-centered\nbehavior, limiting the practical utility of AI-driven generation tools in\nreal-world design workflows. In this paper, we propose VIPCGRL\n(Vision-Instruction PCGRL), a novel deep reinforcement learning framework that\nincorporates three modalities-text, level, and sketches-to extend control\nmodality and enhance human-likeness. We introduce a shared embedding space\ntrained via quadruple contrastive learning across modalities and human-AI\nstyles, and align the policy using an auxiliary reward based on embedding\nsimilarity. Experimental results show that VIPCGRL outperforms existing\nbaselines in human-likeness, as validated by both quantitative metrics and\nhuman evaluations. The code and dataset will be available upon publication.", "AI": {"tldr": "VIPCGRL\u662f\u4e00\u79cd\u65b0\u578b\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u6587\u672c\u3001\u5173\u5361\u548c\u8349\u56fe\u4e09\u79cd\u6a21\u6001\uff0c\u589e\u5f3a\u4eba\u673a\u534f\u4f5c\u5185\u5bb9\u751f\u6210\u7684\u4eba\u6027\u5316\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u5728\u4eba\u6027\u5316\u884c\u4e3a\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u9650\u5236\u4e86AI\u751f\u6210\u5de5\u5177\u5728\u5b9e\u9645\u8bbe\u8ba1\u5de5\u4f5c\u6d41\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u4e09\u91cd\u6a21\u6001\uff08\u6587\u672c\u3001\u5173\u5361\u3001\u8349\u56fe\uff09\u548c\u56db\u91cd\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u5171\u4eab\u5d4c\u5165\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u5d4c\u5165\u76f8\u4f3c\u6027\u8f85\u52a9\u5956\u52b1\u5bf9\u9f50\u7b56\u7565\u3002", "result": "VIPCGRL\u5728\u4eba\u6027\u5316\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5b9a\u91cf\u6307\u6807\u548c\u4eba\u5de5\u8bc4\u4f30\u5747\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "conclusion": "VIPCGRL\u901a\u8fc7\u591a\u6a21\u6001\u548c\u5bf9\u6bd4\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u4eba\u673a\u534f\u4f5c\u5185\u5bb9\u751f\u6210\u7684\u4eba\u6027\u5316\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.09801", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09801", "abs": "https://arxiv.org/abs/2508.09801", "authors": ["Hossein Shokouhinejad", "Roozbeh Razavi-Far", "Griffin Higgins", "Ali A Ghorbani"], "title": "Explainable Ensemble Learning for Graph-Based Malware Detection", "comment": null, "summary": "Malware detection in modern computing environments demands models that are\nnot only accurate but also interpretable and robust to evasive techniques.\nGraph neural networks (GNNs) have shown promise in this domain by modeling rich\nstructural dependencies in graph-based program representations such as control\nflow graphs (CFGs). However, single-model approaches may suffer from limited\ngeneralization and lack interpretability, especially in high-stakes security\napplications. In this paper, we propose a novel stacking ensemble framework for\ngraph-based malware detection and explanation. Our method dynamically extracts\nCFGs from portable executable (PE) files and encodes their basic blocks through\na two-step embedding strategy. A set of diverse GNN base learners, each with a\ndistinct message-passing mechanism, is used to capture complementary behavioral\nfeatures. Their prediction outputs are aggregated by a meta-learner implemented\nas an attention-based multilayer perceptron, which both classifies malware\ninstances and quantifies the contribution of each base model. To enhance\nexplainability, we introduce an ensemble-aware post-hoc explanation technique\nthat leverages edge-level importance scores generated by a GNN explainer and\nfuses them using the learned attention weights. This produces interpretable,\nmodel-agnostic explanations aligned with the final ensemble decision.\nExperimental results demonstrate that our framework improves classification\nperformance while providing insightful interpretations of malware behavior.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5806\u53e0\u96c6\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u548c\u89e3\u91ca\uff0c\u7ed3\u5408\u591a\u79cdGNN\u57fa\u5b66\u4e60\u5668\u548c\u5143\u5b66\u4e60\u5668\uff0c\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u4ee3\u8ba1\u7b97\u73af\u5883\u9700\u8981\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u4e14\u80fd\u62b5\u6297\u89c4\u907f\u6280\u672f\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u6a21\u578b\uff0c\u5355\u4e00\u6a21\u578b\u5728\u6cdb\u5316\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u52a8\u6001\u63d0\u53d6PE\u6587\u4ef6\u7684CFG\uff0c\u901a\u8fc7\u4e24\u6b65\u5d4c\u5165\u7b56\u7565\u7f16\u7801\u57fa\u672c\u5757\uff0c\u4f7f\u7528\u591a\u79cdGNN\u57fa\u5b66\u4e60\u5668\u6355\u83b7\u4e92\u8865\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5143\u5b66\u4e60\u5668\u805a\u5408\u9884\u6d4b\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u5206\u7c7b\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u6076\u610f\u8f6f\u4ef6\u884c\u4e3a\u7684\u53ef\u89e3\u91ca\u5206\u6790\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u7684\u5e73\u8861\u3002"}}
{"id": "2508.09889", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09889", "abs": "https://arxiv.org/abs/2508.09889", "authors": ["Zhitian Xie", "Qintong Wu", "Chengyue Yu", "Chenyi Zhuang", "Jinjie Gu"], "title": "AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has empowered\nintelligent agents to leverage diverse external tools for solving complex\nreal-world problems. However, as agents increasingly depend on multiple tools,\nthey encounter new challenges: extended contexts from disparate sources and\nnoisy or irrelevant tool outputs can undermine system reliability and accuracy.\nThese challenges underscore the necessity for enhanced stability in agent-based\nsystems. To address this, we introduce dynamic supervision and maneuvering\nmechanisms, constructing a robust and dynamic Multi-Agent System (MAS)\narchitecture within the AWorld framework. In our approach, the Execution Agent\ninvokes the Guard Agent at critical steps to verify and correct the reasoning\nprocess, effectively reducing errors arising from noise and bolstering\nproblem-solving robustness. Extensive experiments on the GAIA test dataset\nreveal that our dynamic maneuvering mechanism significantly improves both the\neffectiveness and stability of solutions, outperforming single-agent system\n(SAS) and standard tool-augmented systems. As a result, our dynamic MAS system\nachieved first place among open-source projects on the prestigious GAIA\nleaderboard. These findings highlight the practical value of collaborative\nagent roles in developing more reliable and trustworthy intelligent systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u76d1\u7763\u548c\u673a\u52a8\u673a\u5236\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u9c81\u68d2\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff08MAS\uff09\u67b6\u6784\uff0c\u4ee5\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u5728\u4f9d\u8d56\u591a\u5de5\u5177\u65f6\u9762\u4e34\u7684\u4e0a\u4e0b\u6587\u6269\u5c55\u548c\u566a\u58f0\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56\u5916\u90e8\u5de5\u5177\uff0c\u4e0a\u4e0b\u6587\u6269\u5c55\u548c\u566a\u58f0\u8f93\u51fa\u6210\u4e3a\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u7684\u6311\u6218\u3002", "method": "\u5728AWorld\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u52a8\u6001\u76d1\u7763\u548c\u673a\u52a8\u673a\u5236\uff0c\u6267\u884c\u4ee3\u7406\u5728\u5173\u952e\u6b65\u9aa4\u8c03\u7528\u5b88\u536b\u4ee3\u7406\u9a8c\u8bc1\u548c\u4fee\u6b63\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728GAIA\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u673a\u5236\u663e\u8457\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u6709\u6548\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u4f18\u4e8e\u5355\u4ee3\u7406\u7cfb\u7edf\u548c\u6807\u51c6\u5de5\u5177\u589e\u5f3a\u7cfb\u7edf\u3002", "conclusion": "\u52a8\u6001MAS\u7cfb\u7edf\u5728GAIA\u6392\u884c\u699c\u4e0a\u540d\u5217\u524d\u8305\uff0c\u8bc1\u660e\u4e86\u534f\u4f5c\u4ee3\u7406\u89d2\u8272\u5728\u6784\u5efa\u53ef\u9760\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.09980", "categories": ["cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.09980", "abs": "https://arxiv.org/abs/2508.09980", "authors": ["Ehab ElSalamouny", "Catuscia Palamidessi"], "title": "On the Consistency and Performance of the Iterative Bayesian Update", "comment": null, "summary": "For many social, scientific, and commercial purposes, it is often important\nto estimate the distribution of the users' data regarding a sensitive\nattribute, e.g., their ages, locations, etc. To allow this estimation while\nprotecting the users' privacy, every user applies a local privacy protection\nmechanism that releases a noisy (sanitized) version of their original datum to\nthe data collector; then the original distribution is estimated using one of\nthe known methods, such as the matrix inversion (INV), RAPPOR's estimator, and\nthe iterative Bayesian update (IBU). Unlike the other estimators, the\nconsistency of IBU, i.e., the convergence of its estimate to the real\ndistribution as the amount of noisy data grows, has been either ignored or\nincorrectly proved in the literature. In this article, we use the fact that IBU\nis a maximum likelihood estimator to prove that IBU is consistent. We also\nshow, through experiments on real datasets, that IBU significantly outperforms\nthe other methods when the users' data are sanitized by geometric, Laplace, and\nexponential mechanisms, whereas it is comparable to the other methods in the\ncase of the k-RR and RAPPOR mechanisms. Finally, we consider the case when the\nalphabet of the sensitive data is infinite, and we show a technique that allows\nIBU to operate in this case too.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u8fed\u4ee3\u8d1d\u53f6\u65af\u66f4\u65b0\uff08IBU\uff09\u4f5c\u4e3a\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\u7684\u6027\u8d28\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cIBU\u5728\u591a\u79cd\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u4e0b\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u540c\u65f6\u9002\u7528\u4e8e\u65e0\u9650\u5b57\u6bcd\u8868\u6570\u636e\u3002", "motivation": "\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u540c\u65f6\uff0c\u51c6\u786e\u4f30\u8ba1\u654f\u611f\u5c5e\u6027\u7684\u5206\u5e03\u5bf9\u793e\u4f1a\u3001\u79d1\u5b66\u548c\u5546\u4e1a\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0cIBU\u7684\u4e00\u81f4\u6027\u672a\u88ab\u6b63\u786e\u8bc1\u660e\u3002", "method": "\u5229\u7528IBU\u4f5c\u4e3a\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\u7684\u6027\u8d28\uff0c\u8bc1\u660e\u5176\u4e00\u81f4\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83IBU\u4e0e\u5176\u4ed6\u65b9\u6cd5\u5728\u4e0d\u540c\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u4e0b\u7684\u6027\u80fd\u3002", "result": "IBU\u5728\u51e0\u4f55\u3001\u62c9\u666e\u62c9\u65af\u548c\u6307\u6570\u673a\u5236\u4e0b\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u800c\u5728k-RR\u548cRAPPOR\u673a\u5236\u4e0b\u8868\u73b0\u76f8\u5f53\u3002\u6b64\u5916\uff0cIBU\u53ef\u6269\u5c55\u81f3\u65e0\u9650\u5b57\u6bcd\u8868\u6570\u636e\u3002", "conclusion": "IBU\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u4e00\u81f4\u7684\u5206\u5e03\u4f30\u8ba1\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u9690\u79c1\u4fdd\u62a4\u573a\u666f\uff0c\u5305\u62ec\u65e0\u9650\u5b57\u6bcd\u8868\u6570\u636e\u3002"}}
{"id": "2508.09893", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09893", "abs": "https://arxiv.org/abs/2508.09893", "authors": ["Bhavik Agarwal", "Hemant Sunil Jomraj", "Simone Kaplunov", "Jack Krolick", "Viktoria Rojkova"], "title": "RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA", "comment": null, "summary": "Regulatory compliance question answering (QA) requires precise, verifiable\ninformation, and domain-specific expertise, posing challenges for Large\nLanguage Models (LLMs). In this work, we present a novel multi-agent framework\nthat integrates a Knowledge Graph (KG) of Regulatory triplets with\nRetrieval-Augmented Generation (RAG) to address these demands. First, agents\nbuild and maintain an ontology-free KG by extracting subject--predicate--object\n(SPO) triplets from regulatory documents and systematically cleaning,\nnormalizing, deduplicating, and updating them. Second, these triplets are\nembedded and stored along with their corresponding textual sections and\nmetadata in a single enriched vector database, allowing for both graph-based\nreasoning and efficient information retrieval. Third, an orchestrated agent\npipeline leverages triplet-level retrieval for question answering, ensuring\nhigh semantic alignment between user queries and the factual\n\"who-did-what-to-whom\" core captured by the graph. Our hybrid system\noutperforms conventional methods in complex regulatory queries, ensuring\nfactual correctness with embedded triplets, enabling traceability through a\nunified vector database, and enhancing understanding through subgraph\nvisualization, providing a robust foundation for compliance-driven and broader\naudit-focused applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u6cd5\u89c4\u5408\u89c4\u95ee\u7b54\u7684\u7cbe\u786e\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\u3002", "motivation": "\u6cd5\u89c4\u5408\u89c4\u95ee\u7b54\u9700\u8981\u7cbe\u786e\u3001\u53ef\u9a8c\u8bc1\u7684\u4fe1\u606f\u548c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u8fd9\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u51fa\u4e86\u6311\u6218\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u548c\u7ef4\u62a4\u65e0\u672c\u4f53\u77e5\u8bc6\u56fe\u8c31\uff0c\u63d0\u53d6\u5e76\u6e05\u7406\u6cd5\u89c4\u6587\u6863\u4e2d\u7684SPO\u4e09\u5143\u7ec4\uff0c\u5d4c\u5165\u5230\u5411\u91cf\u6570\u636e\u5e93\u4e2d\uff0c\u5229\u7528\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u8fdb\u884c\u95ee\u7b54\u3002", "result": "\u6df7\u5408\u7cfb\u7edf\u5728\u590d\u6742\u6cd5\u89c4\u67e5\u8be2\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u786e\u4fdd\u4e8b\u5b9e\u6b63\u786e\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\uff0c\u5e76\u901a\u8fc7\u5b50\u56fe\u53ef\u89c6\u5316\u589e\u5f3a\u7406\u89e3\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5408\u89c4\u9a71\u52a8\u548c\u5ba1\u8ba1\u5e94\u7528\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2508.09932", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09932", "abs": "https://arxiv.org/abs/2508.09932", "authors": ["Liang Zhang", "Edith Aurora Graf"], "title": "Mathematical Computation and Reasoning Errors by Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) are increasingly utilized in AI-driven\neducational instruction and assessment, particularly within mathematics\neducation. The capability of LLMs to generate accurate answers and detailed\nsolutions for math problem-solving tasks is foundational for ensuring reliable\nand precise feedback and assessment in math education practices. Our study\nfocuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1,\nDeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including\narithmetic, algebra, and number theory, and identifies step-level reasoning\nerrors within their solutions. Instead of relying on standard benchmarks, we\nintentionally build math tasks (via item models) that are challenging for LLMs\nand prone to errors. The accuracy of final answers and the presence of errors\nin individual solution steps were systematically analyzed and coded. Both\nsingle-agent and dual-agent configurations were tested. It is observed that the\nreasoning-enhanced OpenAI o1 model consistently achieved higher or nearly\nperfect accuracy across all three math task categories. Analysis of errors\nrevealed that procedural slips were the most frequent and significantly\nimpacted overall performance, while conceptual misunderstandings were less\nfrequent. Deploying dual-agent configurations substantially improved overall\nperformance. These findings offer actionable insights into enhancing LLM\nperformance and underscore effective strategies for integrating LLMs into\nmathematics education, thereby advancing AI-driven instructional practices and\nassessment precision.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u56db\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u89e3\u51b3\u6570\u5b66\u95ee\u9898\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u53d1\u73b0\u63a8\u7406\u589e\u5f3a\u7684OpenAI o1\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u53cc\u4ee3\u7406\u914d\u7f6e\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u8bc4\u4f30LLM\u5728\u6570\u5b66\u6559\u80b2\u4e2d\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u4ee5\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u53cd\u9988\u548c\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u4efb\u52a1\uff08\u7b97\u672f\u3001\u4ee3\u6570\u3001\u6570\u8bba\uff09\uff0c\u5206\u6790LLM\u7684\u7b54\u6848\u51c6\u786e\u6027\u548c\u6b65\u9aa4\u9519\u8bef\uff0c\u6d4b\u8bd5\u5355\u4ee3\u7406\u548c\u53cc\u4ee3\u7406\u914d\u7f6e\u3002", "result": "OpenAI o1\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u53cc\u4ee3\u7406\u914d\u7f6e\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u7a0b\u5e8f\u6027\u9519\u8bef\u6700\u5e38\u89c1\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u5347LLM\u6027\u80fd\u548c\u6570\u5b66\u6559\u80b2\u4e2d\u7684\u6574\u5408\u63d0\u4f9b\u4e86\u5b9e\u7528\u7b56\u7565\u3002"}}
